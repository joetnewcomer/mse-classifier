question_id,title,body,tags
4265654,If $f\left(\pi\right)=\pi$ and $\int_{0}^{\pi}\left(f\left(x\right)+f''\left(x\right)\right)\sin x\ dx\ =\ 7\pi$ then find $f\left(0\right)$,"$\color{orange}{\mathrm{Question:}}$ If $f\left(\pi\right)=\pi$ and $\int_{0}^{\pi}\left(f (x)+f''(x)\right)\sin x\ dx\ =\ 7\pi$ then find $f(0)$ given that $f(x)$ is continuous in $\left[0,\pi\right]$ $\color{green}{\mathrm{Solution:}}$ Given: $$\int_{0}^{\pi}\left(f(x)+f''(x)\right)\sin x\ dx\ =\ \int_{0}^{\pi}f(x)\sin x\ dx\ +\int_{0}^{\pi}f''(x)\sin x\ dx$$ By ILATE ( Integration by parts), keeping $f''(x)$ as the first function and $\sin x$ as the second function: $$7\pi\ =\int_{0}^{\pi}f(x)\sin x\ dx\ +\ \left[\sin x\cdot f'(x)-\int_{0}^{\pi}\cos x\cdot f'(x)dx\right]$$ $$7\pi\ =\int_{0}^{\pi}f(x)\sin x\ dx\ +\ \left[\sin x\cdot f'(x)-\left[\cos x\cdot f(x)-\int_{0}^{\pi}\left(-\sin x\right)\left(f(x)dx\right)\right]\right]$$ $$7\pi=\sin x\cdot f'(x)-\cos x\cdot f(x)$$ The limits being of integration being from $0$ to $\pi$ , (sorry i don't know Latex much :( ) $$7\pi=\left[\sin\pi\cdot f'(\pi)-\sin0\cdot f'(0)\right]-\left[\cos\pi\cdot f(\pi)-\cos0\cdot f(0)\right]$$ Solving this I  got $f(0)=6\pi$ , which is the correct answer, no issues with that but... $\color{pink}{\mathrm{Doubt}}$ When using the ILATE rule, we don't know what kind of function $f(x)$ is, so how can we decide whether to take it as the first function or the second function, I just did that for my convenience because I thought that will give me the solution. Secondly, what is the importance of the statement of the question: $f(x)$ is continuous? $\color{red}{\mathrm{Edit}}$ Basically it looks like ILATE is not a very good rule and Integration by parts is OP!","['contest-math', 'calculus', 'definite-integrals']"
4265661,How to calculate the rotation number of this system,"Consider the equation $\frac{dx}{dt}=\sin 2\pi x+c \sin 2\pi t$ with $|c|<1$ , I want to show that $\lim\limits_{t\to\infty} \frac{x(t)}{t}=0$ . For a given $x\in \mathbb R$ , there is a unique trajectory passing through $(0,x)$ . Let $A(x)$ be the value of this trajectory at $t=1$ . Since $\sin 2\pi x+c \sin 2\pi t$ is a double periodical function. $A:\mathbb R\to\mathbb R$ is a lifting of a map $S^1\to S^1$ . Therefore the limit we want to calculate is just the rotation number of $A$ . But I have no idea how to calculate this number.","['rotations', 'ordinary-differential-equations', 'dynamical-systems']"
4265693,Proof verification for proof by contraposition,"prove using contraposition that if a and b are integers: $a^2-4b-2\neq0$ So the contrapositive: $a^2-4b-2=0$ implies that at least one of either a or b are not integers Working from the above, I got: $a^2=4b+2$ $a^2=2(2b+1)$ If both a and b are integers, $2(2b+1)$ is a perfect square. In other words: $\sqrt{2(2b+1)}=k$ Where k is an integer I also realised that 2b+1 is an odd number so: $k=\sqrt{2}\sqrt{2b+1}$ I ended my proof by saying that since 2b+1 is odd, it does not have a multiple of 2 so k will always have  multiple or $\sqrt{2}$ which means that it cannot be an integer.","['proof-writing', 'solution-verification', 'discrete-mathematics']"
4265720,Find number of iterations in nested for-loops,"We are given a pseudocode: for ( int x1 = 1 ; x1 <= n ; x1++ )
   for ( int x2 = x1 ; x2 <= n ; x2++ ) 
      for ( int x3 = x2 ; x3 <= n ; x3++ )
    ‚Ä¶‚Ä¶
       ‚Ä¶‚Ä¶
          ‚Ä¶‚Ä¶
        for ( int xm = x(m-1) ; xm <= n ; xm++ )
            it++ ; We are required to find the number of iterations for $n=26$ and $m=25$ . I tried taking small cases and observed that for $m$ nested loops :
No. of iterations
= $$I = \sum_{i_m=1}^n(\sum_{i_{m-1}=1}^n(...\sum_{i_1=1}^n(1))$$ But I have no idea how to perform this for a large number of nested loops. Can someone suggest an alternative way to approach this?","['summation', 'sequences-and-series']"
4265731,Divisor exact sequence in the etale topology?,"In Milne's book Lectures on √©tale cohomlogy ( link ), there is the following proposition. Proposition 13.4 . Let X be a connected regular scheme with generic point $\eta$ . There is a short exact sequence on $X_{et}$ $$0 \to \mathbb{G}_m \to i_{\eta,\ast} \mathbb{G}_m \to \bigoplus_{\operatorname{codim}(Z)=1} i_{Z,\ast} \mathbb{Z} \to 0,$$ where the direct sum $Z$ runs over the Weil divisors of $X$ . I'm having trouble understanding what this sequence is, and why it is exact. I am perfectly happy with this exact sequence in the Zariski topology, but I don't understand its construction in the √©tale topology. The first map is an adjunction; that is fine. To construct the second map, we want to define it on an √©tale neighborhood $\pi : U \to X$ , so what we want a map $$\Gamma(\pi^{-1}(\eta), \mathbb{G}_m) \to \bigoplus_{Z} \Gamma(\pi^{-1}(Z), \mathbb{Z}_Z).$$ Now the left hand side is just the multiplicative group of invertible rational functions on $U$ , and the right hand side is, well, a $\mathbb{Z}^{\pi_0(\pi^{-1} Z)}$ for each Weil divisor $Z$ . Given a rational function on $U$ , I suspect this map will be something like ""evaluating"" its order of zero/pole at a connected component of $\pi^{-1} Z$ . Because $U$ is regular (being √©tale over a regular scheme), it looks well-defined. But the issue I run into is that $\pi^{-1} Z$ can have connected components that have multiple irreducible components. For a concrete example, I could take $X = \mathbb{A}^2$ , $Z$ a nodal curve in $X$ , and create $U$ so that $\pi^{-1} Z$ is finite √©tale over $Z$ has two irreducible components that are normalizations of $Z$ . We could try and define the order as the sum of the orders of the irreducible components of $\pi^{-1} Z$ . But even if we do that, the kernel has more things that what we want. We can have rational functions that have a pole of order $1$ on one irreducible component of $\pi^{-1} Z$ and a zero of order $1$ on the other component, so that they cancel out. This is definitely in the kernel, but not in $\Gamma(U, \mathbb{G}_m)$ . So the question is, is there something wrong with my reasoning? What is the correct definition of the maps, and why is the sequence exact? On the other hand, the book seems to use this sequence only in the case when $X$ is a curve over an algebraically closed field. In that case, the above issue doesn't arise. This is what the Stacks project does.","['etale-cohomology', 'exact-sequence', 'algebraic-geometry', 'divisors-algebraic-geometry']"
4265751,Untyped Œª-calculus: proof that for any binary relation $R \vDash \lozenge \Rightarrow R^* \vDash \lozenge$,"I'm currently in the process of reading Barendregt's ""The Lambda Calculus - Its Syntax and Semantics"" (1985 revised edition) and I've stumbled across a lemma whose proof I can't quite comprehend. The lemma (3.2.2) states that for all binary relations R on a set the following holds: $$R \vDash\lozenge\Rightarrow R^*\vDash\lozenge$$ , where $\lozenge$ is the diamond property of a relation: $$R\vDash\lozenge\iff\forall M,M_1,M_2\left[(M,M_1)\in R \wedge (M,M_2)\in R \Rightarrow \exists M_3[(M_1,M_3)\in R \wedge (M_2,M_3)\in R]\right]$$ , and $R^*$ is the transitive closure of $R$ : $$\forall M,N[(M,N)\in R\Rightarrow(M,N)\in R^*]$$ and $$\forall M,N,L[(M,N)\in R^*\wedge(N,L)\in R^*\Rightarrow(M,L)\in R^*)].$$ The proof makes use of category theory and is simply a diagram .
Trying to make sense of it, I thought the continuous lines meant the relation $R$ , and the dashed lines either the application of $\lozenge$ on the relation or $R^*$ , but I don't fully understand it. What exactly does the diagram mean and how does it prove the lemma? Is there a more rigurous approach to proving this rather than a drawing? Edit: in the (very clear) answer I received, it was pointed out to me that the diagram I couldn't understand doesn't have anything to do with category theory. I'm sorry for my lack of understanding and poor choice of words - I have striked out the observation.","['logic', 'discrete-mathematics', 'binary-operations', 'lambda-calculus', 'computability']"
4265780,Ambiguity of an equality of two limits,"It is often asked to prove an equality about two limits, say, $\lim_{x\to a}f\left(x\right)=\lim_{x\to a}g\left(x\right)$ .
But I'm confused by the interpretation of the equality, because it
seems that it has two interpretations: $f$ approaches $\lim_{x\to a}g\left(x\right)$ as $x$ approaches $a$ , or $g$ approaches $\lim_{x\to a}f\left(x\right)$ as $x$ approaches $a$ . But many proofs of this kind of equalities seem to only prove either
one of them. For instance, if the interpretation (2) is chosen, the
proof is like: let $l=\lim_{x\to a}f\left(x\right)$ then prove $l=\lim_{x\to a}g\left(x\right)$ .
Why is it possible that the proof can be valid considering only one
of the interpretations?","['limits', 'calculus']"
4265852,"Is this set countably infinite? If so, how do I exhibit a one to one correspondence between these two sets?","I am supposed to determine whether or not the set $A\times Z^{+}$ where $A=\{2, 3\}$ is countably infinite. If so, I should  exhibit a one to one correspondence between the set of positive integers and the set in question. Although I'm pretty sure that the set is countably infinite, I am struggling to find a one to one correspondence from the positive integers to the set since it seems to me that there are twice as many elements in the set $A\times Z^{+}$ than the set of positive integers since its cardinality is double due to the Cartesian product?","['elementary-set-theory', 'functions', 'discrete-mathematics']"
4265859,The intermediate value theorem implies a point at which function changes sign.,"Let $f$ be continuous in $[a,b]$ and $f(a)<0,\ f(b)>0$ . Then by the intermediate value theorem, $\exists c\in(a,b)$ such that $f(c)=0$ . I was wondering if it is also true that there exists $d\in(a,b)$ such that $f(d)=0$ and $f$ changes sign of the function at $d$ . (there is some $ùëü>0$ such that $ùëì(ùë•)<0$ when $ùë•\in(ùëë‚àíùëü,ùëë)$ and that $ùëì(ùë•)>0$ when $ùë•\in(ùëë,ùëë+ùëü)$ It seems clear but I am not sure how to prove if it is true.",['calculus']
4265862,Show that a number of the form $2^{n}+1$ can never be an integer raised to an odd power.,"Generally I tried analyzing cases such as: If there is $a\in\mathbb{Z}$ such that $2^n+1=a^{m}$ where $m$ is odd, then $a$ can not be negative. But a couldn't figure out what to do next. I also tried using the factorization: $a^{m}+1=(a+1)(a^{m-1}-a^{m-2}+\dots+1)$ that makes sense for $m$ odd. I applied it after summing $1$ to both sides of the equation. I did get some contradictions after concluding that $a+1$ divides $2(2^{n-1}+1)$ but I couldn't analyze all cases.","['number-theory', 'arithmetic']"
4265880,"In triangle $\Delta ABC$,$\frac{DA}{DB} = \frac{CA}{CB}$, $\angle ADB = \angle ACB+90^{\omicron}$, prove that $\frac{AB‚ÄßCD}{AC‚ÄßBD} = \sqrt{2}$.","I draw an arbitrary $\Delta ABD$ first and get point $E$ , then construct $C$ (as intersection of Apollonius circle according to $\Delta ABD$ and circumcircle of $\Delta ABE$ ). I want to prove that $\angle DCE = 45^{\omicron}$ so I can finish the proof. I have tried analytic geometry but it's too complicated. Please give me some hint or other way to prove, thank you very much.",['geometry']
4265882,Justification for g being a one to one function,"If $f$ and $f\circ g$ are one to one functions, is $g$ also a one to one function? Justify your answer. I am guessing that $g$ should be a one to one function. So a function $F$ is injective if: $\forall a \forall b(F(a)=F(b) \Rightarrow a=b)$ So since $f$ is injective: $\forall a \forall b(f(a)=f(b) \Rightarrow a=b)$ And $f\circ g$ is also injective: $\forall a \forall b(f \circ g(a)=f \circ g(b) \Rightarrow g(a)=g(b))$ $\forall a \forall b(g(a)=g(b) \Rightarrow a=b)$ Does this show that $g$ must also be injective?","['functions', 'discrete-mathematics']"
4265926,Eliminating $\theta$ from $\cos^3\theta +a\cos\theta =b$ and $\sin^3\theta +a\sin\theta =c$,Eliminate $\theta$ from the equations. $$\cos^3\theta +a\cos\theta =b$$ $$\sin^3\theta +a\sin\theta =c$$ Can anyone solve this question?,"['algebra-precalculus', 'trigonometry']"
4265927,The flux of a the negative gradient flow of a Morse-Bott function on a compact manifold converges to a critical value?,"Let $(M, g)$ be a compact Riemannian manifold and $f: M \rightarrow \mathbb{R}$ be a Morse-Bott function, i.e. the set a critical points of $f$ , $Crit(f)$ , has connected components which are smooth manifolds and which have as tangent spaces $T_x Crit(f) = \ker \nabla^2_x f$ , (where $\nabla^2_x f: T_x M \rightarrow T_xM$ is the linear operator obtained via $g$ from the hessian $f_{**,x} : T_x M \times T_x M \rightarrow \mathbb{R}$ defined as $f_{**,x}(v, w) = v(W(f))$ for $W \in \Gamma(TM)$ any extension of $w$ (this is well defined and symmetric at critical points) ) Let $\nabla f \in \Gamma(TM)$ be defined by $g(\nabla f, w) = w(f)$ and consider the flow of $-\nabla f$ denoted $\phi_t(y)$ . I am trying to see why for any $y \in M$ it happens that $\lim\limits_{t \rightarrow \infty} \phi_t(y) \in Crit(f)$ . My attempt: Since $M$ is compact, $\phi_t(y)$ is defined for all $t \in \mathbb{R}$ . If the set $A_y:= \{ \phi_t(y) : t \in \mathbb{R} \}$ were closed, then, since $M$ is compact, this set would also be compact, and by Weierstrass $f$ would have to attain its minimum on it. Since moving along the flowlines of the negative gradient can only decrease $f$ , this means that the minimum is attained at $x:= \lim\limits_{t \rightarrow \infty} \phi_t(y)$ , so then $x$ would be a critical value for $f|_{A_y}$ . But even ignoring the fact that I don't know why $A_y$ is necessarily closed, I don't see why if $x$ is a critical value for $f|_{A_y}$ , then it is a critical value for $f$ as well. I am thinking that this attempt not enough, as it doesn't use at all the fact that $f$ is a Morse-Bott function. But I don't see how to use this fact. I also know that $\nabla_x^2 f (v) = \nabla_V \nabla f$ for $x \in Crit(f)$ and $v \in T_xM$ and $V$ a vector field extending $v$ , where $\nabla_V (\cdot)$ in the RHS is the Levi-Civita connexion of $g$ , but I can't see how to use this either.","['gradient-flows', 'morse-theory', 'ordinary-differential-equations', 'differential-geometry']"
4265952,Inequality conjecture for convex pentagons,"Let $X_1, ..., X_5$ be the vertices of a convex pentagon with perimeter $p$ with its centroid at the origin, satisfying $d(X_i, X_j) < \frac{p}{3}$ for $1 \leq i,j \leq 5$ , where $d$ is the Euclidean distance. Let $X_m$ be a vertex of that pentagon with maximal distance to the origin and let $P$ be the orthogonal projection onto the straight line through $X_m$ and the origin. My question is: Is it true that $$\sum_{i=1}^5 d(X_m,PX_i) \leq \frac{1}{2\sin\left(\frac{\pi}{5}\right)}\sum_{i=1}^5 d(X_m,X_i)$$ and if yes, how could I prove it? A positive answer (and a proof) would provide a way to prove the result in this MSE post , because we can establish a lower bound for the left hand side of our inequality involving $\frac{1}{2\sin\left(\frac{\pi}{5}\right)}$ . The $\frac{p}{3}$ condition should guarantee that the pentagon is in some sense not too far away from a regular pentagon, so that on average the distance to the projected points is sufficiently smaller than the distance to their non-projected versions. I have verified the inequality for several pentagons (satisfying the $\frac{p}{3}$ condition) and it is holding up so far. Note that it's invariant under scaling, so we could assume something like $p = 1$ if necessary. We could also instead assume wlog that $X_m = (1, 0)$ , then if $X_i = (a_i, b_i)$ for all $i$ , we get $PX_i = (a_i, 0)$ and the inequality becomes $$\sum_{i=1}^5 \vert a_i-1 \vert \leq \frac{1}{2\sin\left(\frac{\pi}{5}\right)}\sum_{i=1}^5 \sqrt{(a_i-1)^2 + b_i^2}.$$ I'm looking primarily for a non-computer-assisted proof, but any kind of help is appreciated.","['contest-math', 'euclidean-geometry', 'geometry', 'polygons']"
4265994,Tangentially touching functions {y=ln(f(x)) and y=f(x)/e},I found some really interesting graphs like these: So basically through these graphs I want to ask that if we take 2 functions in the format of $$f_1 = ln(f(x))$$ and $$f_2 = \frac{f(x)}{e}$$ do they always intersect tangentially?,['functions']
4266062,Maximize equation involving sum over subsets,"I am trying to find the function $f(x)$ the maximizes the following equation. $$\sum_{S\subseteq \{1,\dots,n\}}(-1)^{n-|S|} \left(\sum_{i\in S}\int_{\frac{i-1}{n}}^{\frac{i}{n}}f(x)dx\right)^t$$ Where $t$ is a real constant greater than $1$ , $0\leq f(x)\forall x\in\left[0,1\right]$ and $\int_0^1f(x)dx=1$ . From trying out different functions I've come to believe $f(x)=1$ is the answer, however I haven't been able to proof this result.","['optimization', 'calculus', 'functions', 'sequences-and-series']"
4266125,Proving that a set is countable (or not),"Prove that the set $$\left \{ (u,v)\in\mathbb{Q}^2:u-v\in \mathbb{Z}  \right \}$$ is indeed countable and that $$\left \{ (u,v)\in\mathbb{R}^2:u-v\in \mathbb{Q}  \right \}$$ is not By instinct I would say the first set is countable as $u-v\in \mathbb{Z} $ and that the rationals are countable (and thus the cart. prod.) but how does one rigorously show that a set is either countable or uncountable? I know that a set $S$ is countable if its cardinality is less than or equal to $\aleph_0$ .
The second one instinctly is also not countable to me as the elements are from $\mathbb{R}^2$ .",['elementary-set-theory']
4266139,"If $x$ is given in degrees, are $\sin(x)$ and $\arcsin(x)$ algebric for $x$ rational?","If $x$ is given in degrees, are $\sin(x)$ and $\arcsin(x)$ algebric for $x$ rational? For the sin I think the answer is yes. We know that $\sin(1¬∞)=\frac{\sqrt[90]{i}-\sqrt[90]{-i}}{2i}$ , and we can construct $\sin(p x)$ using Chebyshev polynomials, and $\sin(x/q)$ by solving the root of a Chebyshev polynomial. Is this sound? For arcsin I don't think this is true, but I can't find any counter-example, nor a proof.","['trigonometry', 'algebraic-numbers']"
4266152,Dirichlet problem with separation of variables,"Use separation of variables to find a nonzero solution for the following Dirichlet problem: $\Delta u = 0$ in $\Omega$ with $u=0$ on $\partial \Omega$ , where $\Omega = \{(x,y) \in \mathbb{R}^{2}: 0 < y < \pi\}$ $\Omega \in \mathbb{R}^{2}$ is open and bounded, u is harmonic on $\Omega$ . If we assume that $u \in C^{2}(\Omega) \cap C(\bar{\Omega})$ , then according to the maximum principle for harmonic functions we have: $0 = \min_{y \in \partial \Omega} u(y) \leq u(x) \leq \max_{y \in \partial \Omega} u(y) = 0$ $\hspace{3mm} \forall x \in \Omega \hspace{3mm}$ (since $u = 0$ on $\partial \Omega$ ) Hence u(x) = 0 for all $x \in \Omega$ . I have the feeling that there does not exist a nonzero solution, because of this maximum principle. So how do I know that there does exist a nonzero solution and how can I find this solution. I think I need to assume that there exist a solution $u(x,y) = X(x) \cdot Y(y)$ . Then $0 = \Delta u = u_{xx} + u_{yy} = Y(y) \cdot X''(x) + X(x) \cdot Y''(y)$ . So $X''(x) + aX(x) = 0$ and $Y''(y) + b \cdot Y(y) = 0$ for some constants $a = a(y)$ and $b = b(x)$ . And then solve these ODEs for $X(x)$ and $Y(y)$ . So $u(x,y) = X(x) \cdot Y(y) = (c_{1} \cdot \cos(\sqrt{a}x) + c_{2} \cdot \sin(\sqrt{a} x)) \cdot (d_{1} \cdot \cos(\sqrt{b}y) + d_{2} \cdot \sin(\sqrt{b} y))$ And we know that $u = 0$ on $\partial \Omega$ . So that means that $u(x,0) = 0$ and $u(x,\pi) = 0$ .
And with these boundary values, I only find that $d_{1} = 0$ . So how to continue then?
And what does this Dirichlet problem tell is then about the maximum principle and what is wrong about my conclusion that $u(x) = 0$ for all $x \in \Omega$ ?","['maximum-principle', 'harmonic-functions', 'ordinary-differential-equations']"
4266177,Inequality related to standard normal distribution function,"I want to show that $$
2\Phi(x)^2 - \Phi(2x) \geq 0
$$ for all $x<0$ , where $\Phi$ is a cumulative distribution function of $N(0,1)$ . I am pretty sure that this holds since I've checked it with numerous $x$ 's, but I am struggling to prove it. I tried differentiating it, but it seems not working at least within my abilities. Could somebody help me with it? Thank you.","['statistics', 'cumulative-distribution-functions', 'probability-distributions', 'normal-distribution', 'inequality']"
4266249,Measure theoretic proof of Leibniz Rule for Differentiation under the Integral with varying integration limits,"I'm searching for a rigorous proof of Leibniz rule of integration for varying integration limits, i.e.: $$
\frac{d}{dx}\int^{b(x)}_{a(x)} f(x,t) dt = f(x,b(x)) \frac{db(x)}{dx} -
f(x,a(x)) \frac{da(x)}{dx} + \int^{b(x)}_{a(x)} \frac{\partial f(x,t)}{\partial x} dt.
$$ I've seen proofs of the statement above, but not in measure theoretic terms. Also, the proofs of Leibniz rule that use Measure Theory just prove for the case where the limits are fixed, i.e. (under proper hypothesis): $$
\frac{d}{dx} \int_\Omega f(x,t) dt = \int_\Omega \frac{\partial }{\partial x} f(x,t) dt.
$$ I've tried extending the proof by using the result above and using an indicator function to write the limits as a function inside of the integral. But, I then end up having to integrate an indicator function. If someone can prove the result or point me to a reference that does the complete proof, I'd really appretiate it.","['integration', 'measure-theory', 'derivatives']"
4266261,Asking for an example of stiff ODE,"I am currently studying on the numerical solutions of ODEs and I'm trying to calculate the difference of the exact solution to numerically evaluated solution and then just plot the absolute difference. I'm doing this so I can eventually see how good these numerical methods can actually calculate the error. For example, here is an example from numerical recipes: $$u' = 998u + 1998v$$ $$v' = -999u - 1999v$$ with boundary conditions $$u(0) = 1 $$ $$v(0) = 0$$ With the exact (analytical) solution of $$u = 2e^{-x} ‚àí e^{-1000x} $$ $$v = -e^{-x} + e^{-1000x} $$ Now when I use the BDF method with rtol=1e-12,atol=1e-30 and plot the differences, I get: Now the thing is, I think these equations aren't just stiff enough to really challenge the solver, and I'm looking for a multi-scale ODE with difference of at least $10^{10}$ which has an exact solution. Can anyone suggest such an ODE?","['numerical-methods', 'ordinary-differential-equations']"
4266406,Is every estimator a sufficient statistic?,"It is clear that not any sufficient statistic (s.s.) makes a good estimator (since a monotonic transform of a s.s. is still a s.s.).  But is a ""good"" estimator of the parameter always a s.s.? If not, under what conditions is this the case? I gather that the dimension of the s.s. may vary with the size of the data (e.g. Cauchy distribution), so perhaps we have to restrict ourselves to the exponential family of distributions for a start? I will leave open what ""good"" means, e.g. it could be unbiasedness or another condition under which this result holds.","['statistical-inference', 'statistics', 'parameter-estimation']"
4266408,Evaluating $\int \frac{1}{a+b\sec(x)}dx$,"I tried to find a closed-form expression for the integral $$\int\frac{1}{a+b\sec(x)}\>dx$$ and, afterwards, set $a=0$ , $b=1$ to recover the result for the simplified integral $$\int\cos(x)\>dx=\sin(x)+C$$ The above integral was inspired by Am√©rico Tavares‚Äôs rather illuminating solution to Ways to evaluate $\sec(t)$ , Here's the progress I've made which makes use of the integral $$(\star)\int\frac{dx}{m^2+n^2x^2}=\frac{1}{mn}\arctan\left(\frac{nx}{m}\right)\quad m,n>0$$ Using $\cos(x)=2\cos^2(x/2)-1$ , we get the following $$I=\int\frac{dx}{a+b\sec(x)}=\int\frac{\cos(x)}{a\cos(x)+b}dx=\int\frac{2\cos^2(x/2)-1}{2a\cos^2(x/2)+b-a}dx\\=2\underbrace{\int\frac{dx}{2a+(b-a)\sec^2(x/2)}}_\color\red{(1)}-\underbrace{\int\frac{\sec^2(x/2)}{2a+(b-a)\sec^2(x/2)}dx}_\color\red{(2)}$$ $\color\red{(2)}$ becomes $$\int\frac{\sec^2(x/2)}{2a+(b-a)\sec^2(x/2)}dx=\int\frac{\sec^2(x/2)}{a+b+(b-a)\tan^2(x/2)}dx\\=\frac{2}{\sqrt{b^2-a^2}}\arctan\left(\sqrt{\frac{b-a}{a+b}}\tan(x/2)\right)$$ from the substitution $u=\tan(x/2)$ and then applying $(\star)$ . For tackling $\color\red{(1)}$ , the same u-substitution and applying partial fractions converts the integral into $$\int\frac{dx}{2a+(b-a)\sec^2(x/2)}=2\int\frac{du}{(a+b+(b-a)u^2)(1+u^2)}\\=2\left[\frac{a-b}{2a}\int\frac{du}{(a+b+(b-a)u^2)}+\frac{1}{2a}\int\frac{du}{1+u^2}\right]$$ Thus $$\int\frac{dx}{2a+(b-a)\sec^2(x/2)}=\frac{a-b}{a\sqrt{b^2-a^2}}\arctan\left(\sqrt{\frac{b-a}{a+b}}u\right)+\frac{1}{a}\arctan(u)\\=\frac{a-b}{a\sqrt{b^2-a^2}}\arctan\left(\sqrt{\frac{b-a}{a+b}}\tan(x/2)\right)+\frac{1}{a}\arctan(\tan(x/2)))$$ However, the problem is that setting $a=0$ afterwards results in the denominator becoming zero. Also, I couldn't think another approach to this. Any help?","['integration', 'calculus', 'trigonometric-integrals']"
4266430,"How to prove that if c is an odd integer that divides the sum and the difference of two integers a and b, then c divides both a and b?","I have two questions regarding this. I'm new to proving so these may seem silly. Is it better to prove directly or by using its contrapositive? Directly, I could prove by applying a bit of algebra and using its contrapositive, I have to show that c does not divide a or c does not divide b would give c does not divide their sum and difference. I hope this is correct. Does c being odd have anything to do with the proof? If yes, how do I show it in the proof? Because when I try proving using c as any integer, I'm getting my answer.","['number-theory', 'solution-verification']"
4266460,A combinatorial question about odd and even numbers,"Consider an $n$ tuple. Each index of the tuple is filled with a symbol chosen from the following set comprising of four symbols: \begin{equation}
S = \{a, b, c, d\}.
\end{equation} Note that there are $4^{n}$ possible fillings. I want to count the number of possible tuples such that $b$ -s, $c$ -s, and $d$ -s all occur in it an even number of times (not necessarily the same even number for each.) For example, if $n = 4$ , then $bbba$ is not a valid tuple --- as it has $3$ $b$ -s, which is an odd number. However $bb cc$ is a valid tuple ‚Äî as both $b$ and $c$ occur an even number of times. For $n = 2$ , the valid choices are $aa, bb, cc, dd$ . Hence, the number of such tuples is $4$ . For $n = 3$ , the valid choices are $aaa, abb, acc, add, bba, cca, dda, bab, cac, dad$ . So, $10$ choices. Is there a general pattern?","['combinations', 'combinatorics', 'combinatorial-proofs']"
4266507,Equivalence-relations overcounting,"I posted this Cardinality of equivalence relations of $\mathbb R$ with 2 equivalence classes. but cant understand some important things. In general, lets say i want to find the cardinality of equivalence relations of $\mathbb R$ with $x\in \mathbb N$ equivalence classes. Take $x^\mathbb R$ , i cant understand why there are overcounting ? Suppose $x=\left\{0,1 \right\}$ then $|x|=2.$ Define: $A:=\left\{\text{The constant zero function }\right\}$ , $B:=\left\{\text{The constant one function }\right\}.$ $A,B$ are equivalence-relations with $1$ equivalence class. I cant understand why there are equivalence-relations overcounting and the cardinality is not just $|x^\mathbb R \setminus A \cup B.|$ I'd be grateful for your help!",['elementary-set-theory']
4266512,Do I miss something about a remark about topology in this lecture note?,"I'm reading a lecture note in topology. There is a remark Remark 1.2. A quick induction shows that any finite intersection $U_{1} \cap \cdots \cap U_{k}$ of open sets is open. It is important to point out that it is in general not true that an arbitrary (infinite) union of open sets would be open, and it is often difficult to decide whether it is so. I think the part about an arbitrary (infinite) union of open sets is wrong. Do I miss something here?",['general-topology']
4266541,The proof of $\chi_A:I\to \mathbb R$ is integrable $\iff $ $\chi_A:J\to \mathbb R$ is integrable.,"I'm studying the integration on Jordan measurable sets. Let $A\subset \mathbb R^n$ be bounded and $\chi_A$ be a characteristic function of $A$ Then, I want to prove that if $I\subset \mathbb{R^n}$ and $J\subset \mathbb{R^n}$ are intervals s.t. $A\subset I \subset J,$ then \begin{align}
\chi_A: I\to \mathbb R \ \mathrm{is \ Riemann \ integrable \ on\ } I \iff  \chi_A : J\to \mathbb R \mathrm{\ is\ Riemann \ integrable\ on\ } J
\end{align} For the proof of this, I think the theorem below is useful. Theorem Let $I\subset \mathbb{R^n}$ be a interval and $f:I\to \mathbb R$ be bounded. $f$ is integrable on $I$ if and only if for
all $\epsilon>0$ , there exists a partition of $I$ s.t. $S(f,\Delta)-s(f,\Delta)<\epsilon$ where $S$ is the upper sum and $s$ is the lower sum. Suppose $\chi_A : I\to \mathbb R$ is integrable on I. Let $\epsilon>0.$ Then, from the integrability of $\chi_A: I\to \mathbb R$ , there exists the partition of $I$ , $\Delta=\{I_k\}_{k=1}^M$ s.t. $S(\chi_A, \Delta)-s(\chi_A, \Delta)<\epsilon.$ Then, I have to find the partition of $J$ s.t. $S(\chi_A, \Delta')-s(\chi_A, \Delta')<\epsilon \  ($ or $a \cdot \epsilon \ (a>0)).$ I'm having difficulty in finding such $\Delta'.$ I'd like you to gime me any help. (This is the step of defining the integral on Jordan measurable sets.) Just so you know, the definition of the integrability of functions on a interval is here. Let $I\subset \mathbb R^n$ be an interval. $f:I\to \mathbb R$ is integrable on $I$ $\underset{\mathrm{def}}\iff$ $\overline{\displaystyle\int_I} f(x) dx=\underline{\displaystyle\int_I}f(x) dx,$ where $\overline{\displaystyle\int_I}$ is upper integral and $\underline{\displaystyle\int_I}$ is lower integral.","['multivariable-calculus', 'calculus', 'real-analysis']"
4266608,"Convexity, concavity doubts","Let $f$ be a numerical function, $f:D\to\mathbb{R}$ , and we want to algebraically determine if $f$ is convex. According to the definition, $f$ is convex if and only if $\forall~x_1,x_2\in D$ the line segment connecting $\big(x_1,f(x_1)\big)$ and $\big(x_2,f(x_2)\big)$ lies above the graph of $f$ . I have determined the function describing the line: $$g:[x_1,x_2]\to\mathbb{R},~g(x)=\frac{f(x_1)-f(x_2)}{x_1-x_2}x+\frac{x_1f(x_2)-x_2f(x_1)}{x_1-x_2}$$ I have taken an arbitrary $$s\in [x_1,x_2]\Rightarrow s=\lambda x_1+(1-\lambda)x_2,~\lambda\in[0,1]$$ and calculated $$g(s)=\lambda f(x_1)+(1-\lambda)f(x_2)$$ Using the definition the equivalence of convexity becomes $f(s)\le g(s)$ : $$f(\lambda x_1+(1-\lambda)x_2)\le \lambda f(x_1)+(1-\lambda)f(x_2)~\forall~x_1,x_2\in D,\lambda\in[0,1]$$ ... which is the official definition of convexity. For continous functions it is said that it is enough to check the inequality for a fixed $\lambda\in(0,1)$ , but why? If it is true for a single case does it imply it is true for any $\lambda$ ? EDIT1: If I think about it for $f(x)=\sin(x)$ this isn't even true... EDIT2: I think I have misunderstood, my counterexample for $\sin(x)$ isn't valid because it only analyzes a fixed pair $x_1,x_2$ , but for other pairs the inequality isn't true for the same $\lambda$ . Also I have looked over the proof ""midpoint convex, continuous implies convex"". Thanks to everyone for the help.","['functions', 'convexity-inequality']"
4266669,Lipschitz continuous gradient and quadratic bound property,"Let $\left\lVert \cdot \right\rVert$ denote the Euclidean norm. A differentiable function $f: D \subseteq \mathbb{R}^n \to \mathbb{R}$ is said to have Lipschitz continuous gradient with parameter $L > 0$ if $$ \left\lVert \nabla f(x) - \nabla f(y) \right\rVert  \leq L  \left\lVert x-y \right\rVert \text{for all } x, y \in D.  \tag{1}\label{1}$$ A standard result is that a function $f$ (not necessarily convex) with Lipschitz continuous gradient satisfies the following ""quadratic bound property"": $$|f(y) - f(x) - \nabla f(x)^T(y-x)| \leq \frac{L}{2} \left\lVert x - y \right\rVert^2 \text{ for all } x, y \in D. \tag{2}\label{2}$$ I am thinking about the converse, namely if a function $f$ satisfies \eqref{2}, does it necessarily satisfy \eqref{1}? In http://www.seas.ucla.edu/~vandenbe/236C/lectures/gradient.pdf (slide 17) it seems like if we for instance assume that $f$ is convex with co-coercive gradient, the quadratic bound property implies Lipschitz continuity of the gradient. However, without these assumptions I strongly suspect that \eqref{2} does not necessarily imply \eqref{1}. Just for fun, I have (without success) been trying to come up with an example of a function satisfying \eqref{2} but not \eqref{1}. Can anyone provide an example of such a function, or motivate why it does not exist?","['convex-optimization', 'multivariable-calculus', 'convex-analysis', 'lipschitz-functions']"
4266686,Calculate the limit of a quotient,I substituted big numbers in calculator as well as graph it. The limit is 0 instead of 1. I don't know which step goes wrong.. Question: $$\lim_{n\to+\infty} \frac{2^n \cdot (\sqrt{4^n+2n} - 2^n)}{n+1}$$ My solution: $$=\lim_{n\to+\infty}\frac{2^n\cdot(\sqrt{4^n+2n}-2^n)\cdot(\sqrt{4^n+2n}+2^n)}{(n+1)\cdot(\sqrt{4^n+2n}+2^n)}$$ $$=\lim_{n\to+\infty}\frac{2^n\cdot(4^n+2n-4^n)\div 2^n}{(n+1)\cdot(\sqrt{4^n+2n}+2^n)\div 2^n}$$ $$=\lim_{n\to+\infty}\frac{2n}{(n+1)\cdot(\sqrt{1+\frac{2n}{4^n}}+1)}$$ $$=\lim_{n\to+\infty}\frac{2}{(1+\frac{1}{n})\cdot(\sqrt{1+{2n}\cdot{(\frac{1}{4})^n}}+1)}$$ $$=\frac{2}{(1+0)\cdot(1+1)}$$ $$=1$$,"['limits', 'analysis']"
4266694,Finding functions $g$ such that the Fourier transform of $g(x+c)g(x)$ does not vanish,"Suppose that $f$ is a function of the form $$
f(x) = g(x+c)g(x),
$$ i.e. $f$ is a product of $g$ with a shifted $g$ . If $g$ is a Gaussian, so is $f$ for every $c \in \mathbb R$ . In particular, the Fourier transform of $f$ does not vanish. Does there exist other functions with this property or even a class of functions $g$ such that the Fourier transform of $x \mapsto g(x+c)g(x)$ does not vanish for every $c$ ?","['fourier-transform', 'fourier-analysis', 'functional-analysis', 'analysis']"
4266805,Zeros of a polynomial in a simple form,"Let $m\geq 3$ be a natural number and define $$f(x)=1-x^m-(1-x)(1+x)^{m-1}.$$ Then, if $m$ is even, the only real roots of $f$ are $x=-1,0,1$ and if $m$ is odd, the roots are $x=0,1$ . My work: for the case where $m$ is even, i proved that $$f(x)=\sum_{k=0}^{m-2}\left(\begin{pmatrix}
      m-1\\
      k+1
    \end{pmatrix}-
    \begin{pmatrix}
      m-1\\
      k
    \end{pmatrix}\right)x^{m-k-1}$$ on one hand. Decomposing it as $f(x)=(x-1)x(x+1)P(x)$ , where \begin{align*}
    P(x)=\sum_{k=0}^{m-4}b_kx^{m-k-4},
\end{align*} I get an alternative representation \begin{align*}
    f(x)=\sum_{k=0}^{m-2}(b_k-b_{k-2})x^{m-k-1},
\end{align*} with $b_{-2}=b_{-1}=b_{m-2}=b_{m-1}=0$ . Combining both I get \begin{align*}
    b_k-b_{k-2}=\begin{pmatrix}
      m-1\\
      k+1
    \end{pmatrix}-
    \begin{pmatrix}
      m-1\\
      k
    \end{pmatrix}.
\end{align*} From here I can clearly see that $b_k\geq 0$ , however this does not imply that $P>0$ as intended. I don't know how to proceed, any suggestions please? It is entirely possible that I approached the problem from the wrong perspective...","['functions', 'polynomials', 'real-analysis']"
4266809,Does Product Topology Distribute Over Disjoint Union?,"Is it generally true that if $X$ and $Y_i$ are topological spaces, then we have the homeomorphism: $$X\times\left(\bigsqcup_i Y_i\right)\cong\bigsqcup_i(X\times Y_i).$$ It doesn't seem like this should be the case since on the right hand side, the open set from $X$ could be taken to be arbitrary small as we go over the indices, although I might be mistaken. Could this hold if there are finite number of $Y_i$ ?","['general-topology', 'product-space']"
4266830,Non-probabilistic/non-combinatoric proof of $\sum_{k=n}^{2n} \frac{{k \choose n}}{2^k}=1$,"The summation $$S_n=\sum_{k=n}^{2n} \frac{{k \choose n}}{2^k}=1~~~~(1)$$ has been proved using probabilistic/combinatoric method in MSE earlier: Combinatorial or probabilistic proof of a binomial identity Here we give an analytic proof for (1): $$S_n=\sum_{k=n}^{2n} \frac{{k-1 \choose n-1}+{k-1 \choose n}}{2^k}~~~~~(2)$$ Let $k-1=p$ , then $$S_n=\sum_{p=n-1}^{2n-1} \frac{{p \choose n-1}+{p \choose n}}{2^{p+1}}~~~~(3)$$ Take the first term $$\sum_{p=n-1}^{2n-1} \frac{{p \choose n-1}}{2^{p+1}}=\sum_{p=n-1}^{2n-2} \frac{{p \choose n-1}}{2^{p+1}}+\frac{{2n-1 \choose n-1}}{2^{2n-1}}=\frac{S_{n-1}}{2}+\frac{{2n-1 \choose n-1}}{2^{2n}}~~~~~(4)$$ Now take the second term $$\sum_{p=n-1}^{2n-1} \frac{{p \choose n}}{2^{p+1}}=\sum_{p=n}^{2n} \frac{{p \choose n}}{2^{p+1}}+\frac{{n-1 \choose n}}{2^{n}}-\frac{{2n \choose n}}{2^{2n+1}}~~~~(5)$$ The second term in RHS vanishes and the third term is equal and opposite to the second term of the RHS of (4). Adding (4) and (5), we get $$S_n=\frac{S_{n-1}}{2}+\frac{S_{n}}{2} \implies S_n=S_{n-1}$$ So $S_n$ is a constant (independent of $n$ ) we can have $S_n=S_{n-1}=S_1=1$ The question is: What could be other analytic proofs of (1) without using the ideas of probability/combinatorics?","['summation', 'binomial-coefficients', 'binomial-theorem', 'sequences-and-series']"
4266903,Chain rule in Spivak's Calculus on Manifolds,"In the following example from Chain Rule of Chapter 2 in Spivak's Calculus on Manifolds, I am confused about the dot after the first equality sign. According to the chain rule, $D(g\circ f)(a)=Dg(f(a))\circ Df(a)$ . How is the circle changed to the dot? How to interpret this? Thanks in advance.","['multivariable-calculus', 'chain-rule', 'real-analysis']"
4266921,Selberg Integral - Change of Variables,"I am trying to evaluate a Selberg-Like integral and I need to make the integral separable (unbinding the variables), but I can't come up with an appropriate change of variables. The integral is: $$\underset{[0,1]^m}{\int\dots\int} d^2z_1\dots d^2z_m \prod_{i<j} |z_i-z_j|^{-\gamma^2} f(z_1,\dots, z_m).$$ I am thinking about this as a function of $\gamma$ , so the function $f(z_1,\dots, z_m)$ doesn't really matter yet. I need to introduce a change of variables such that $\prod_{i<j} |z_i-z_)|^{-\gamma^2}$ can be split into terms that include only one variable each. The case with $m=2$ is easy (polar coordinates). For $m=3$ , I tried the following: $x_1-x_2=y_1$ and $x_1-x_3=y_1y_2$ . This works fine when $m=3$ , but I am not sure it can be extended to any $m\in\mathbb{N}$ .","['complex-analysis', 'self-learning', 'change-of-variable']"
4266930,Direct proof that integral of $1/x$ is $\ln(x)$ [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question I was looking for a direct proof that for $x > 0$ we have $$\int \frac{1}{x} dx = \ln(x)$$ that did not rely on the fundamental theorem of calculus but could not find one. Is there such a proof? If so I would be glad if someone could point me to it or reproduce it as an answer. Thanks! EDIT: I define $\ln(x)$ to be the inverse function of $e^x$ which I define via the usual summation.,"['integration', 'calculus', 'logarithms']"
4266937,Calculating the point of reflection off a sphere,"I am trying to figure out a way to solve Alhazen's problem for a sphere. I have found a couple of resources online, but I am having issues modifying those to meet my requirements. The basic problem is I have a source of light which reflects off a sphere and is picked up by an observer. I know the location of the source and observer with respect to the center of the sphere, and I would like to find the location of the reflection with respect to the center of the circle. Here is a drawing of the situation. I am using this to calculate the specular point for the Earth, hence the use of satellites and Earth based symbols. Figure showing geometry of problem: A couple of notes: Theta 1 is the half angle of RST. Here I know r_R and r_T as well as i_R and i_T. r_E is the radius of the Earth. T refers to the source of light (transmitter) R refers to the observer (reciever) In some way, I am looking for the latitude and longitude of the point of reflection. I have found a couple of resources that do this, but I am uncertain on how to use them for my case. The first resource can be found here . This has the issue of presenting a 2D solution. I am uncertain how to bring this to 3D. The second resource I found is here . The issue I am having here is that it requires you to know the location of the observer and the source with respect to the reflection point. I am not sure how to get this information without first knowing the location of reflection, which is precisely what I am trying to find. I would also like to add that my background is not in mathematics, but rather engineering. So if the solution to my problem seems obvious that may be why. Thanks in advance for your help!",['geometry']
4267002,What are the sine and cosine of dyadic angles?,"What are the values of sine and cosine of dyadic angles ? We know $$\cos\pi = -1 \qquad \cos\frac{\pi}{2} = 0 \qquad \cos\frac{\pi}{4} = \frac{\sqrt{2}}{2}\,,$$ and we can calculate sine by appealing to symmetry. But I don't think I've seen the sine and cosine values, presented in terms of radicals, of $\pi/8$ , $3\pi/8$ , $\pi/16$ , $\pi/2^n$ , etc. Do these have nice algebraic presentations? How can we calculate these?","['algebra-precalculus', 'angle', 'trigonometry']"
4267052,"Discrete series representation of SO(2,1)","Since so(2,1) is a noncompact Lie algebra, its unitary representations are all infinite-dimensional. Now, I have seen that the unitary representations of so(2,1) can be divided into three categories: Discrete series - with a lowest or highest state satisfying $J_{\pm}|j,m\rangle = 0$ , where $C|j,m\rangle = -j(j+1) |j,m\rangle$ ( $C$ is the Casimir operator) and $J_3|j,m\rangle = m|j,m\rangle$ . Also $J_\pm = J_1 \pm iJ_2$ . Principal series. Complementary series. For principal and complementary series, there is no lower or upper bound for the $m$ values. Now, I have seen in most books and literature that for the discrete series, $j$ only takes integer or half-integer values rather than continuum values which gives the name discrete series. However, I cannot find any reason why should $j,m$ only can have integer or half-integer values if there is a lower bound on the $m$ values. In other words, starting with the assumption that there exists a lower or upper bound of the value $m$ , how can we conclude that $j$ has to be discrete?","['semisimple-lie-algebras', 'group-theory', 'representation-theory', 'lie-algebras']"
4267066,What is the inverse of the $q$-exponential?,"The $q$ -exponential function is given by the power series $$ e_q(x) = \sum_{n=0}^\infty \frac{x^n}{[n]!} $$ using the $q$ -integers $[k]:=q^{k-1}+\cdots+q+1=(q^k-1)/(q-1)$ and $q$ -factorials $[n]!=[n][n-1]\cdots[2][1]$ . What is the inverse function $\ln_q$ satisfying $\ln_q(e_q(x))=x$ and $e_q(\ln_q(1+x))=1+x$ ? I am treating $x$ and $q$ as either indeterminates for formal power series or complex variables in whatever domain yields an answer. By hand I calculated the first few terms $$ \ln_q(1+x)=x-\frac{1}{[2]}x^2+
\left(\frac{2}{\,[2]^2}-\frac{1}{[3][2]}\right)x^3-
\left(\frac{5}{\,[2]^3}-\frac{5}{[3][2]^2}+\frac{1}{[4][3][2]}\right)x^4+\cdots $$ A vast generalization might be to treat $[1],[2],[3],\cdots$ as independent formal variables and treat these coefficients above as rational functions of them. At worst, the series for $\ln_q$ is no simpler than this generalization. Curiously, this seems to be in no literature at all. Like, are these coefficients a special kind of polynomial? Is $\ln_q$ the $q$ -integral of something? Is there an analogous identity for the fact $e_q(x+y)=e_q(x)e_q(y)$ when $(xy)=q(yx)$ ? All mentions of $q$ -logarithms in search results seem to be talking about Tsallis statistics, which is an unrelated situation with a unrelated notion of $q$ -exponential.","['q-analogs', 'abstract-algebra', 'combinatorics', 'generating-functions']"
4267355,$X$ is compact iff $C_c(X)$ is Banach,"Problem: Let $X$ be a Hausdorff, $\sigma$ -compact and locally compact topological space. $C_c(X)$ is the space of  continuous functions on $X$ whose supports are compact equipped with the supremum norm. Prove $C_c(X)$ is a Banach space if and only if $X$ is compact. My attempts: I've already proved the closure of $C_c(X)$ is $C_0(X)$ , the space of  continuous functions vanishing at infinity. Actually I showed $C_c(X)$ is dense in $C_0(X)$ , using Urysohn's lemma for locally compact spaces. Now, I don't know how to apply $\sigma$ -compactness for the rest. Obviously, if $X$ is compact then $C_c(X)$ = $C(X)$ so I think it's just needed to prove $X$ is compact if $C_c(X)$ is Banach. This question and some related questions have been asked here but they were all missing $\sigma$ -compactness and there isn't an answer to any of them either. Any help would be highly appreciated.","['banach-spaces', 'general-topology', 'functional-analysis', 'real-analysis']"
4267430,Measuring distance in SO(n),"I'm trying to find a way to measure the distance between two rotation matrices. For my application, I need a measure that works in $SO(2)$ and one that works in $SO(3)$ , but apart from that, I am much more curious about the general $SO(n)$ case. I can find measures for $SO(2)$ and $SO(3)$ , but I have no idea how to approach the general case. For $SO(3)$ I found this very insightful blog post . It uses $P$ and $Q$ to denote 3x3 rotation matrices and $*$ to denote the matrix transpose. It then measures distance using $$\theta = \arccos\left(\frac{\mathrm{tr}(PQ^*) - 1}{2}\right).$$ For $SO(2)$ I can come up with a similar formula (with the help of Wikipedia ): $$\theta = \arccos\left(\frac{\mathrm{tr}(PQ^*)}{2}\right)$$ This makes me think that there should be a formula for $SO(n)$ , but how do I work that out? For context: My application is to do inverse kinematics on a kinematic chain. Which is buzzword bingo for ""I have a parameterized sequence of affine transformations (typically rotations and translations) and I am trying to find a set of parameters such that the transformation of the total sequence results in a desired translation and orientation"". In my case, I am interested in solving the above for a desired orientation only. One way to do so is via optimization, but for that, I need a way of measuring the distance between the current orientation and the desired orientation.","['trigonometry', 'rotations']"
4267463,$\mathrm{Iso}(X)$ is locally compact if $X$ is locally compact,"Let $(X, d)$ be a locally compact metric space. Define $\mathrm{Iso}(X)$ , the isometry group of $X$ , as the set of all surjective isometries of $X$ . Is it true that $\mathrm{Iso}(X)$ is locally compact when endowed with the compact-open topology (or, equivalently, the topology of uniform convergence on compact subset of $X$ )? I am not particularly sure how to see if this is true or not. I know that if $X$ is a proper metric space (i.e. closed balls are compact) then $\mathrm{Iso}(X)$ is indeed locally compact. This is because, for fixed $x \in X$ and $r > 0$ , we can consider the neighbourhood $$ N_r := \{f \in \mathrm{Iso}(X) \ \mid \ f(\overline{B}(x, r)) \subset \overline{B}(x, 2r) \} $$ of the identity map on $X$ , and one can quickly show that this set is relatively compact using the Arzela-Ascoli theorem. The hard part of the proof is to show that for every $y \in X$ , the set $$ \{f(y) \ \mid \ f \in N_r \} $$ is relatively compact in $X$ . However, for fixed $z \in \overline{B}(x, r)$ , we have that $$d(f(y), x) \leq d(f(x), f(z)) + d(f(z), x) \leq d(x, z) + 2r, $$ for every $f \in N_r$ , and so relative compactness follows immediately. The same argument works for an arbitrary isometry (not necessarily the identity map). However, if $X$ is only locally compact, then we know that each point in $X$ has arbitrarily small closed balls that are compact, but arbitrarily big closed balls may not necessarily be compact, which is why the above proof does not directly work in this case.","['general-topology', 'isometry', 'locally-compact-groups', 'metric-spaces']"
4267471,"Prove the limit $\lim_{(x,y)\to(0,0)} \frac{x^4+y^4}{xy}=0$.","Prove the limit $\lim_{(x,y)\to(0,0)} \frac{x^4+y^4}{xy}=0$ . Attempt. I tried to work with squeeze theorem, i.e. to find a function $h(x,y)$ (with limit $0$ at $(0,0)$ ) such that $|\frac{x^4+y^4}{xy}|\leqslant h(x,y)$ for all $(x,y)$ : $xy\neq 0$ , but it didn't work. Any suggestions for the upper bound? Thank you.","['limits', 'multivariable-calculus']"
4267517,Expected distance/ time for a bouncing ball to stop.,"I saw someone on YouTube glue half of a bouncy ball to a golf ball. I thought of an interesting expected value problem using it. Consider when you drop the ball it lands on the bouncy or non bouncy side with equal probability. When it lands on the bouncy side it returns to $a\%$ of its height before the bounce and if it lands on the golf side it bounces and returns to $b\%$ of its height before the bounce. With $0<b<a<100$ Lets say the ball stops bouncing when it first bounces up less than $m$ centimetres. For example, let $a = 50$ , $b=10$ and $m=1$ you drop the ball from $1$ metre and it lands on the bouncy side so returns to $50$ cm. It then bounces on the golf side so returns to $5$ cm. It then bounces on the bouncy side three times so goes $2.5$ , $1.25$ , $0.625$ and stops bouncing. I had a few problems that I am sure are very related. If you drop the ball from $1$ metre what is the expected number of bounces? If you drop the ball from $1$ metre what is the expected distance it travels before it stops bouncing. I am happy to consider only the second question and allow for infinite bouncing, I feel like the condition on stopping bouncing will make calculations very hard. Can we relate these two problems nicely? My ideas: Let $H$ denote the height of the ball after $n$ bounces. (Starting from $1$ metre) $H = a^X \cdot b^{n-X}$ Where $X\sim$ Bin( $n,\frac{1}{2}$ ) denotes the number of ""bouncy bounces"" We could probably uses logarithms to find out all different combinations that yield $H< m$ and binomial co-efficents then manually calculate EV We could say on average each bounce reduces our ball's height by $\frac{b+a}{2}$ and then think use logs to work out how many bounces it would take reducing at the rate of $\frac{b+a}{2}$ to stop. But I don't think this will give a very accurate answer because of the RV.s in the exponent. We can just run some code. Please no full solutions I want to tackle this myself! Just hints for now","['expected-value', 'statistics', 'probability']"
4267552,"How is $f(x) : \mathbb N \to \mathbb R,$ where $f(x) = \sin x,$ one-one?","$$ f(x) = \sin x,$$ where $f$ is defined as $$ f: \mathbb N \to \mathbb R.$$ The exercise is to check if the function was one-one or many-one. Here is my answer: $$
f(x_1) = f(x_2)
$$ $$ \sin x_1 = \sin x_2 $$ $$ x_1 = n\pi + (-1)^nx_2 $$ here we have 2 cases Case 1: If $n = 0,$ then we will get $$ x_1 = x_2.$$ Case 2: if $x \neq0,$ But this case can be rejected since $x_1$ can't be irrational as it a natural number. This just left us with one case,that is $ x_1 = x_2$ which means that the function is one-one. Here is my question: We got $f(x)$ as one-one, but confusingly we can get same value of $y$ for multiple values of $x,$ e.g., both $\sin30$ and $\sin150$ give the same $y=1/2.$ How is this possible?","['algebra-precalculus', 'functions', 'trigonometry']"
4267565,Chevalley-Eilenberg complexes of curved dg Lie algebras,"Let $k$ be a field of characterisitic $0$ . A curved dg Lie algebra (curved dgla) is a triple $(\mathfrak{g},d,w)$ where $\mathfrak{g}$ is a graded Lie algebra, $d$ is a derivation with degree $1$ and $w \in \mathfrak{g} _2$ such that $d(w) = 0$ and $d^2(x) = [w,x]$ . The element $w$ s called the curvature. For any curved dgla $(\mathfrak{g}, d, w)$ , we can construct a cochain complex CE $(\mathfrak{g},d,w)$ called Chevalley-Eilenberg complex.
CE $(\mathfrak{g},d,w)$ is isomorphic to Sym $(\mathfrak{g}[1])^*$ as a graded algebra. The differential $d'$ of CE $(\mathfrak{g},d,w)$ is a sum $d' = d'_0 + d'_1 +d'_2$ where the restriction is given by $d'_0$ : $(\mathfrak{g}[1])^* \rightarrow k$ is given by the evaluation on $w$ the curvature of $\mathfrak{g}$ . $d'_1$ : $(\mathfrak{g}[1])^* \rightarrow (\mathfrak{g}[1])^*$ is given by the differential on $g$ . $d'_2$ : $(\mathfrak{g}[1])^* \rightarrow S^2(\mathfrak{g}[1])^*$ is given by the bracket on $\mathfrak{g}$ . It seems that the evaluation of $w$ can be defined only on an element of $(\mathfrak{g}[1]_1)^*$ for me. How is define the evaluation of $w$ on an element of $(\mathfrak{g}[1]_i)^*$ $(i \neq 1)$ ?
And, is $d_0$ of degree $-1$ ?","['homological-algebra', 'abstract-algebra', 'lie-algebras']"
4267576,Birthday problem - expected number of shared birthdays,"Given $m$ people and an $n$ possible ""days of the year"", what is the expected number of days which 2 or more people share as a birthday (if the distribution of birthdays is iid uniform over the possible days) ? (Alternative formulation: We use $n$ distinct colors to paint $m$ objects. Each object gets colored with a uniformly iid randomly chosen color. What is the number of colors that color at least two objects?) Written more precisely, let $B_i$ be independent uniform random on $S = \{ 1, ..., n \}$ for $i = 1, ..., m$ . What is the expected cardinality of the set of $d \in S$ where there exist $i,j$ not equal with $B_i = B_j = d$ ? This sounds similar to birthday problem - expected number of collisions which asks for the number of collisions, but that question was about the number of people who share birthdays, not the number of days shared. The answer to that question is in the range $[0,m]$ while the answer to my question is in the range $[0,n]$ . Ultimately this is actually a question about hash collisions and prefix collisions in a prefix tree, but I deemed the birthday formulation the most familiar and most likely to be helpful to others searching for it in the future.","['birthday', 'probability']"
4267616,Does $a_n b_n \to e$ imply $b_n a_n \to e$ in a locally compact group?,"Let $G$ be a locally compact group and $(a_n),(b_n)$ be two sequences. Suppose $a_n b_n \to e$ as $n \to \infty$ Ôºådo we necessarily have $b_n a_n \to e$ ? If this is false in general, does it hold true for $G=SL(d,\mathbb R)$ ? The group I am mostly interested in is $SL(d,\mathbb R)$ . I have been trying to construct a counterexample here, but not successful.","['general-topology', 'topological-groups']"
4267689,Example of copositive matrix but neither positive semidefinite nor elementwise nonnegative?,An $n \times n$ real symmetric matrix $A$ is said to be copositive if $\mathbf{x}^{\top}A\mathbf{x} \geq 0$ for all $\mathbf{x}\in\mathbb{R}^{n}$ such that $\mathbf{x} \geq 0$ . I wonder whether the copositive matrix is also positive semidefinite or elementwise nonnegative. I think it is not true since positive semidefinite requires $\mathbf{x}^{\top}A\mathbf{x} \geq 0$ for all $\mathbf{x}\neq 0$ . Could anyone give me an example that is a copositive matrix but neither positive semidefinite nor elementwise nonnegative? Thanks.,"['matrices', 'convex-optimization', 'linear-algebra', 'copositivity']"
4267696,"Given two conics touching each other in two different points, prove the following collinearity","My friend recently played in GeoGebra and discovered an interesting fun fact: Given two conic sections such that they have two common tangents in two different points $A$ and $B$ (conics are touching, $A$ and $B$ lie on both of them, and as such, they have common tangents).
Let the intersection of those tangents be point $O$ . Let us denote conics $g$ and $h$ . Pick a point $F$ on $g$ and let $l$ be line tangent to $g$ in $F$ such that $l$ intersects $h$ in two points $C$ and $D$ . Let $c$ and $d$ be tangents to $h$ in $C$ and $D$ respectively and let $M$ be their intersection. Prove that $O$ , $M$ and $F$ are collinear. Of course, there are, in the Euclidean plane, degenerate cases where these points do not exist, but ignore them by assuming all intersections. We believe that this problem is easy in projective geometry, apart from the fact that there are no degenerate cases in it and talks only about incidence, but none of us had any experience, and neither did our geometry teacher succeed(we are high school students), so we ask for help. This problem turned out to have some significance to one of our projects so we would be really grateful to see some solution soon :)","['projective-geometry', 'conic-sections', 'geometry']"
4267724,Is the space of probability measures on a compact set is compact w.r.t Wasserstein metric?,"Let $(X, d)$ be a metric space and $C \subseteq X$ compact. Let $\Delta (C)$ be the set of all Borel probability measures on $C$ . We endow $\Delta(C)$ with Wasserstein distance $W_p$ for some $p \ge 1$ . Then $(\Delta(C), W_p)$ is a metric space by Proposition 2.2 . Is $(\Delta(C), W_p)$ compact? If the condition $C$ is compact is not sufficient, can $C$ is finite implies $(\Delta(C), W_p)$ is compact?","['probability-theory', 'functional-analysis', 'measure-theory', 'metric-spaces']"
4267782,A regular subset of a transitive group [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Given a group $G$ acts transitively on a finite set $X$ , we know that it is not necessarily true that it has a transitive subgroup of order $|X| $ ( transitive subgroup of an action ). However, I was wondering if $G$ has a subset $S$ , with order $|X|$ , such that for all $x$ , $y$ in $X$ , there is a unique element of $S$ that maps from $x$ to $y$ ?","['group-theory', 'group-actions', 'finite-groups']"
4267794,Approximating a measurable set by measurable rectangles,"Is the following claim correct? I couldn't find it in standard texts (say, Bogachev). Claim. Let $(X=\prod_{i=1}^n X_i,\mathcal{A}=\otimes_{i=1}^n \mathcal{A}_i)$ be a product of measurable spaces $(X_i,\mathcal{A_i})$ , and let $\mu$ be a finite measure on $\mathcal{A}$ . For every $Y\in \mathcal{A}$ and every $\varepsilon>0$ there exist finitely many disjoint measurable rectangles $R_j\in \mathcal{A}$ , i.e., sets of the form $R_j=\prod_{i=1}^n Y_i$ for $Y_i\in\mathcal{A}_i$ , such that $$\mu(Y\Delta \bigcup_j R_j)<\varepsilon,$$ where $\Delta$ denotes symmetric difference. Below is a short sketch that, if valid, is quite standard I suppose. My knowledge in measure theory is extremely basic though, so if this is utterly wrong, I wouldn't be surprised. Idea. Let $\mathcal{M}$ denote the set of $Y\in\mathcal{A}$ for which the claim is true. Finite unions of disjoint measurable rectangles are by definition contained in $\mathcal{M}$ , and they form an algebra. By the dominated convergence theorem, $\mathcal{M}$ is a monotone class. By the monotone class theorem, $\mathcal{M}=\mathcal{A}$ .","['measure-theory', 'probability-theory', 'real-analysis']"
4267834,"Prove that for if for every $n \in \mathbb N$ and $x\in \mathbb R$ and $f'(x) = \frac{f(x+m)-f(x)}{m}$, then $f$ is linear affine.","""
Prove that for $f:\mathbb R \to \mathbb R$ differenciable. If for every $m \in \mathbb N$ and $x\in \mathbb R$ , and $f'(x) = \frac{f(x+m)-f(x)}{m}$ . Then $f$ is linear affine."" This question appeared in one of my exams. I wasn't able to solve it back then. Now, I'm trying to solve it again, but I have been able to prove only for every $x \in \mathbb Z$ . Here is what I've done so far. For $n \in \mathbb N$ , $$
f'(0) = \frac{f(n) - f(0)}{n} \implies f'(0) n + f(0) = f(n).
$$ Hence, $\forall x \in \mathbb N, f(x) = f'(0) \cdot x + f(0)$ is linear affine. Now, for a negative integer, we have $$
f'(-n) = \frac{f(0) - f(-n)}{n}\implies f(-n) = -f'(-n)n + f(0)
$$ $$
f'(-n) = \frac{f(n)-f(-n)}{2n}\implies f(-n) = f(n) -2n f'(-n) = f'(0)n+f(0)-2nf'(-n)
$$ Therefore, $f'(0) n = f'(-n)n \implies f'(0) = f'(-n)$ , which give us that $f$ is linear affine for every integer. This is how far I went.","['analysis', 'real-analysis']"
4267861,"$y' = 3y^{\frac{2}{3}}$ non unique solution at $(1,1)$?","When considering the differential equation $y' = 3y^{\frac{2}{3}}$ , I can find solutions $y = (t-a)^3, t > a$ and $y= (t-b)^3, t < b$ . Also $y = 0$ is a solution. I am suppose to show in reference to these two solutions that there are infinite number of solutions to this differential equation satisfying $y(1) = 1$ , and why this does not contradict existence and uniqueness. Problem is, for $t > 0, y > 0$ $f$ and $f_y$ are continuous, so in the domain $y > 0$ the solution should be unique. Could someone explain my flaw in logic>","['initial-value-problems', 'ordinary-differential-equations']"
4267885,If a subset of $\mathbb{R}$ has positive Lebesgue measure then it almost contains an interval,"I want to show that if $E \subseteq \mathbb{R}$ is a Lebesgue measurable set, then for every $0 < \varepsilon < 1$ there is an interval $I \subseteq \mathbb{R}$ such that $m(E \cap I) > (1 - \varepsilon) m(I)$ . My proof is so easy that i doubt it's valid:
Notice that we only have to show it for $0 < m(E) < \infty$ , because if $m(E) = \infty$ then there is a subset $E' \subseteq E$ such that $0 < m(E') < \infty$ and therefore for all $0 < \varepsilon < 1$ there exists an interval $I \subseteq \mathbb{R}$ such that $m(E \cap I) \geq m(E' \cap I) > (1 - \varepsilon) m(I)$ . So suppose we have $0 < m(E) < \infty$ and fix $0 < \varepsilon < 1$ . Now suppose by contradiction that for all intervals $I \subseteq \mathbb{R}$ we have $m(E \cap I) \leq (1 - \varepsilon) m(I)$ . Choose a sequence $\{ I_n \}_{n=0}^\infty$ of intervals such that $E \subseteq \cup_{n=0}^\infty I_n$ and $m(E) \leq \sum_{n=0}^\infty
m(I_n) < m(E) + \frac{\varepsilon m(E)}{1 - \varepsilon}$ . This implies that $m(E) = m(E \cap \cup_{n=0}^\infty I_n) = m(\cup_{n=0}^\infty (E \cap I_n)) \leq \sum_{n=0}^\infty m(E \cap I_n) \leq (1 - \varepsilon) \sum_{n=0}^\infty m(I_n) < (1 - \varepsilon) \left( m(E) + \frac{\varepsilon m(E)}{1 - \varepsilon} \right) = m(E)$ , contradiction. Is my proof of this claim valid?","['real-numbers', 'measure-theory', 'lebesgue-measure', 'real-analysis', 'solution-verification']"
4267932,Are principal curvatures intrinsic when both are nonzero?,"If we start with a surface in $\mathbb{R}^3$ with nonzero principal curvatures $\kappa_1,\kappa_2\neq 0$ is it ever possible to choose an isometric embedding of that surface in $\mathbb{R}^3$ with different principal curvatures? We might choose a different normal vector, ""inverting"" the surface and giving principal curvatures $-\kappa_1,-\kappa_2$ but could we for example double one principal curvature while halving the other? Gauss's Theorema Egregium only implies that $\kappa_1 \kappa_2$ is an intrinsic invariant. If the surface is flat and $\kappa_1  \kappa_2=0$ then we can achieve any pair of principal curvatures $\kappa_1,\kappa_2$ such that $\kappa_1 \kappa_2=0$ with some isometric local embedding. Is it possible to change the principal curvatures by choosing a new isometric embedding when the surface isn't flat?","['isometry', 'curvature', 'differential-geometry']"
4267950,Understanding the informal intution behind Little Oh,"According to user137731 in the thread linked below, we define ""little oh"" as follows: Definition : A function $f$ is called little oh of $g$ as $x\to a$ , denoted $f\in o(g)$ as $x\to a$ , if $$\lim_{x\to a}\frac {f(x)}{g(x)}=0$$ Intuitively this means that $f(x)\to 0$ as $x\to a$ ""faster"" than $g$ does. Personally, I find the intuition behind ""little oh"" more difficult than the straightforward definition of it. So I need intuition for the intuition given above. Here below is my attempt at understanding it. Does that make sense? By definition, $\forall \epsilon > 0 \ \exists \delta \ |x - a| < \delta \implies \left|\frac{f(x)}{g(x)}\right| < \epsilon $ meaning for $x \in N_\delta(a)$ , we have $\left|\frac{f(x)}{g(x)}\right| = 0$ . But that only happens if $f(x) = 0, \ g(x) \neq 0.$ Is it the sense in which $f(x)$ is faster than $g(x)$ around $0$ ? How is the derivative truly, literally the ""best linear approximation"" near a point?","['limits', 'derivatives', 'real-analysis']"
4267969,Borel sigma algebra on $\mathbb{R}^2$.,"Consider the family of all circles on plane ( $S = \{S_{x_0, y_0, c} : (x-x_0)^2 + (y-y_0)^2 = c^2)\}$ ). We want to know that $\sigma(S) \ne \mathcal{B}(\mathbb{R}^2)$ .
Intuitively I have two explanations: It looks like if it was true, then the family $\{x:y = c\}\cap S$ should generate $\mathcal{B}(\mathbb{R})$ . But at the same time, these intersections are just singletons (or it's collections), hence we can't generate Borel sigma-algebra. The second idea is that there should be an analogy of countable-countable sigma-algebra on plane, which generated by $S$ and doesn't coincides with $\mathcal{B}(\mathbb{R}^2)$ . Any hint or directions to think about?","['borel-sets', 'measure-theory']"
4268020,Prove or disprove by counterexample $\sup_{x\in \mathbb{R}^n}\frac{[\nabla (\nabla \cdot f)]\cdot f}{(1+|\nabla\cdot f|)^2}<\infty$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Let $f\colon \mathbb{R}^n\to \mathbb{R}^n$ be twice continuously differentiable. Prove or disprove by counterexample that \begin{equation}
\sup_{x\in \mathbb{R}^n}\frac{[\nabla (\nabla \cdot f)]\cdot f}{(1+|\nabla\cdot f|)^2}<\infty,
\end{equation} where $``\cdot""$ denotes the dot product, $``\nabla""$ denotes gradient, and $``\nabla \cdot""$ denotes divergence. Any help is appreciated. Here is my attempt: If we know that the Taylor series of $f(x)$ converges to $f(x)$ , then I can show the claim at least for the scalar case. But I do not know how to do this rigorously for a general case.","['multivariable-calculus', 'vector-analysis']"
4268038,Binary strings with exactly $n$ ones but without 000 or 111,I am a newbie in binary strings and generating series. I have a problem of enumeration which can be transformed to the following: find the number of binary strings of exactly $n$ ones which do not contain three consecutive ones or three consecutive zeros. The answer can be given as a coefficient of a generating series. I don't know how to begin with. Thanks for any help!,"['combinatorics-on-words', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
4268078,What exactly is the relationship and are the differences between multivariable limits and complex limits?,"Edit : This question is wrong. Ignore it. I've already flagged to request for deletion. Please just go to that question: What exactly are the differences between real multivariable limits and complex limits? Say you want to disprove the existence of either of the ff $\lim_{z \to 0} \frac{Re(z)}{|z|^2}$ , $\lim_{z \to 0} \frac{Im(z)}{|z|^2}$ (as in here ). It seems we just change the limits to $\lim_{(x,y) \to (0,0)} \frac{x \ \text{or} \ y}{x^2+y^2}$ and then go about this calc2 way. So the rule is that complex limit doesn't exist if the $\mathbb R^2$ limit doesn't exist? In general, for $$\lim_{z \to z_0}[u(z)+iv(z)] \ \text{vs} \ \lim_{(x,y) \to (x_0,y_0)}[u(x,y)+iv(x,y)],$$ where $u$ and $v$ are real functions, is it that the LHS doesn't exist if the RHS doesn't exist? Here, the RHS equals by theorem or by definition to $$\lim_{(x,y) \to (x_0,y_0)}u(x,y)+i\lim_{(x,y) \to (x_0,y_0)}v(x,y)$$ BUT if the RHS exists, the LHS may or may not exist, i.e. existence of real limit is necessary but not sufficient for existence of complex limit? Please provide examples. Note : For now, I'll just say the real functions $u,v$ without specifying specific domains and hope the above makes sense. If need be, then I can edit this question to be more specific about $u,v,z_0$ , etc. Related questions : I've found several questions that talk about the relationship of complex derivative and real derivative, but what I'm not quite seeing is the general case/concept of complex vs real limits. Differences between the complex derivative and the multivariable derivative. Difference between the properties of differentiation in $\mathbb{C}$ and $\mathbb{R}^2$ Scalar field Derivative. Real vs Complex Limit defintion of a function that is $\mathbb{R}$-differentiable but not $\mathbb{C}$ differentiable.","['analysis', 'real-analysis', 'complex-analysis', 'multivariable-calculus', 'limits']"
4268082,How could I rewrite $\dfrac{6 + 4 {i}} { -9 - 4 {i}}$ in a+bi form?,"Peace to all. When I solve the problem I get $\dfrac{70} { 97}$ - $\dfrac{12{i}} {97}$ and it's the wrong answer. How exactly do you go about solving this problem? This is my work: I received that answer by multiplying both the numerator and denominator by the conjugate partner of ""-9 - 4i"" which is ""-9 + 4i"". $\dfrac{-54 + 24 {i} - 36{i} +16i^2} { 81 - 36 {i} + 36 {i} - 16i^2}$ Combining like terms: $\dfrac{-54 + 24 {i} - 36{i} +16(-1)} { 81 - 36 {i} + 36 {i} - 16(-1)}$ = $\dfrac{-70 - 12i} { 81 + 16}$ = $\dfrac{-70} { 97}$ - $\dfrac{12{i}} {97}$","['algebra-precalculus', 'complex-numbers']"
4268104,Number of $k$-parts in the set of all compositions of integer $n$.,"This seems like a basic question but I've been searching for the answer for a long time (days). Define $p^n_k$ as the number of $k$ -parts in the set of all compositions of integer $n$ . For example for $n=3$ , we have the compositions: [
(3), (2, 1), (1, 2), (1, 1, 1)
] There are five $1$ s, two $2$ s and one $3$ , so $p^3_1 = 5$ , $p^3_2 = 2$ , and $P^3_3 = 1$ . Is there a general expression for $p^n_k$ ?. Note that this is different from the commonly asked question about the number of compositions of length $k$ for the integer $n$ , for which the answer is ${n-1}\choose{k-1}$ . Thanks in advance for your help!",['combinatorics']
4268105,Telling First Order Linear vs Non Linear ODE from its Slope Field,"Is it possible to distinguish between a first order linear and non linear ODE just from its slope field? In autonomous vs non-autonomous, you can easily tell from whether the slope varies with $x$ . I can not think of patterns that would distinguish $y' +p(t)y = q(t)$ from $y\ = f(t,y)$ ... is this generally the case?",['ordinary-differential-equations']
4268120,Any interpretation for the fact that centroid = optimal point for maximising volume of such cuboid?,"(Visualising a sample case via the image at the bottom) Consider a plane $\frac xa+\frac yb+\frac zc=1$ so that it intercepts with the axis at $(a,0,0)$ , $(0,b,0)$ and $(0,0,c)$ , $a,b,c >0$ .  Now consider maximising the volume of such a cuboid, which it is in the first octant, with 3 faces in $x=0$ , $y=0$ , $z=0$ , and a vertex in the plane mentioned above.
Algebraically, we will always get the optimal vertex at the centroid of the triangle { $(a,0,0)$ , $(0,b,0)$ and $(0,0,c)$ } in the plane mentioned above. Any possible interpretation behind this relation? I get the logic in algebra but I can‚Äôt figure out the intuition geometrically. The question sounds vague because I don‚Äôt have much intuition behind this relation so I fail to use specific words to phrase my question. It seems to be an interesting coincidence and I want to know is there any non-algebraic interpretation behind. blue line indicating the plane. Red line indicating the cuboid. Green indicating the vertex.","['optimization', 'multivariable-calculus', 'centroid', 'geometry']"
4268128,(conceptual question) What kind of minima do we expect stochastic gradient descent to get stuck on and why?,"Suppose you want to find $k$ that minimises your cost function $J_D(k)$ for the whole dataset $D$ . We may want to apply batch gradient descent or stochastic gradient descent. Let's deliberately initialise $k$ with the same number $k_0 = 1$ for both BGD and SGD to see the difference in their behavior. If you apply BGD, the whole process may look like this: On the other hand if you apply SGD, this optimisation may look like this: In both pictures the blue solid curve represents the cost function $J_D(k)$ . But in the second picture there are also dotted curves. In my experiment I used batch size which was $10\text%$ of the whole dataset $D$ . So each dotted curve represents the cost function $J_B(k)$ for the current batch $B$ . From these dotted curves you can see that the gradient $\nabla J_B\left(k_0\right)$ happened to be large multiple times in a row for different batches $B$ . That's why the point was ""pushed"" to the deeper minimum. As I understand we use SGD hoping that there is such a big $\nabla J_B\left(k_0\right)$ for some batch $B$ so that the red point is ""pushed"" to jump out of this local minimum for another chance at arriving at a better minimum. But I'm stuck here. Why does stochastic gradient descent lead us to a minimum at all? Why can't it escape all the minima? Why do we think that another local minimum is going to be deeper than the initial one? I don't believe that we just hope that our new minimum is going to be good enough. With the same success we could randomly choose a value for $k$ . If we don't think that another local minimum is going to be deeper, then how is SGD supposed to avoid local minima problem? Our red point can end up in a minimum that is shallower (higher) than the initial one, e.g.: If BGD looks for the nearest minimum, then what kind of minimum does SGD look for? How do we know for certain that it's not going to escape a deeper minimum? How deep should it be? What kind of minima do we expect stochastic gradient descent to get stuck on and why do we think it's going to be deeper than the minimum we can obtain with a normal gradient descent? How SGD is supposed to avoid local minima problem if all it can is just push us to jump out of a local minimum? I mean it doesn't look for a better one but only wandering along the curvature. As a side note, $J_D(k) = \frac 1n\sum_{i=1}^n\left(\sin\left(kx_i\right) - y_i\right)^2$ . EDIT 1: Need some clarification of @WhoDatBoy's answer. Since we randomly selecting each batch, the single batch's distribution is going to be similar to that of the whole dataset. And this distribution uniquely determines the distribution of residuals of each batch. That's why each batch's gradient is going to be similar to that of the whole dataset. Is that right? Now, I perfectly understand why the red point can't usually escape from wide minima: it's very unlikely to select a batch with gradient that differs from the whole dataset multiple times in a row. However there is still a thing that confuses me. You said that SGD was not invented to be robust against local minima. But it's told to be likely to reach a better minimum than the initial one. And I can see why in the case when the red point was initialised in some local minimum near a wide minimum: there's a chance that some batch's gradient will push it from the shallow minimum towards the wider one. But what if our cost function looks like this: Some batch can push the point to the left in the shallower minimum. The point can stay there for a while and after that it can be pushed again towards even shallower minimum. Question 1: Is it highly unlikely case, since there are always batches seeking to push the point to the right? Or consider the following situation: Despite the fact that the initial minimum is deeper, but it's very narrow. So, the point can be easily pushed out of it towards the shallower minimum. In both these cases SGD can fail. Question 2: I'm not sure about the first one but in the second plot we definitely can't say that the red point is likely to find a better minimum, right? I mean, all the minima are too narrow for the point to stay there. Question 3: Is it true that only wide minima can hold the point (no matter deep or not)? And how wide should it be depends on the batch size we choose? Question 4: And since we don't know it in advance, we just try to guess its size, right? Question 5: It turns out then, the depth of the minimum doesn't play much role in holding the red point. It's the width of the minimum that matters? Question 6: Do we assume something before applying SGD? If yes, then what exactly? I mean is there some kind of assumption of the form: ""SGD is likely to find a better minimum if the curvature does not have only narrow minima and is not too hilly"". EDIT 2: All over this edit I assume that we have the same batch size and the same learning rate and, for the sake of simplicity, assume that all those minima $A$ , $B$ and $C$ (denoted below) have the same width (but different depth). CONFUSION 1 : In your Question 5 answer you said that the depth is important . Doesn't it mean that the deeper the minimum is, the harder it is for the red point to escape that minimum? Thus, we can conclude that the red point is likely to stuck in relatively deep minima when using SGD. The word ""relatively"" is used because the depth that is able to hold the red point depends on the batch size and the learning rate: the smaller the batch size and the bigger the learning rate, the deeper minima the red point is looking for . By ""looking for"" I mean that the red point is going to get stuck in such minima. However, we don't know how deep the minimum has to be in absolute value. CONFUSION 2 : It's still unclear why the red point is likely to get stuck in deeper minima. Suppose, for the sake of example, that we have a dataset of $100$ observation and 3 minima in our cost function curvature: $A$ , $B$ and $C$ . The respective errors (values of our cost function) at those minima are: $\mathrm{error}(A) = 100$ , $\mathrm{error}(B) = 10$ and $\mathrm{error}(C) = 0$ . Now, when the red point gets into the minimum $C$ , then each of $100$ observations has $0$ error and therefore $0$ gradient. So, whatever batch you choose it's going to have $0$ gradient, since its gradient is the sum of gradients of the observations the batch consists of. Consequently, it's impossible for the red point to escape from the minimum $C$ . And here is my main confusion . Why is the red point less likely to escape the minimum $B$ (the deeper one) than the minimum $A$ ? It would be nice to explain it in the following way: ""since the $\mathrm{error}(A) > \mathrm{error}(B)$ , then the gradient of each observation is smaller in the minimum $B$ and therefore every batch now has smaller gradient which causes smaller ability to push the red point out of the minimum $B$ "". But the problem is that we can NOT claim such a thing, since the error reduction in the minimum $B$ compared to the minimum $A$ could be caused by a single observation. I mean, if the error of a single observation, say the first one out of our 100 observations, reduced significantly, then it would cause a reduction in the error of our cost function. But the rest of the observations has the same error as before and therefore the same gradient. And since we're randomly picking the batch on each iteration, our red point can still be pushed out of the minimum $B$ with the same probability ( am I wrong in here regarding the same probability? ). CONFUSION 3 : It becomes even more confusing when the reduction in the error of a single observation is not the case, and the error of our cost function is reduced due to the fact that overall error reduced in some observations is greater than the overall error raised in other observations. The minimum would be deeper in this case, but how to show that the red point is now less likely to escape from this new deeper minimum? I want to note here that in my understanding, the reduction in the cost function does not mean either the reduction in the gradient of the whole dataset or the reduction in the gradient of some individual batch. Then how on earth can the reduction in the cost function (and this is exactly what the deeper minimum means) mean smaller ability to escape the minimum?","['machine-learning', 'stochastic-processes', 'multivariable-calculus', 'calculus', 'gradient-descent']"
4268138,"If a function vanishes at all points of a quasicompact scheme, then some power of it is zero","Let's fix a finite cover of $X$ by $\operatorname{Spec}(A_i)$ for various $A_i$ s. A ""function"" is an element of $\mathcal O_X(U)$ for some open $U$ (if I understand the definition on p.136 of Vakil's FOAG (where this exercise is from) correctly). In general, ""an element $f\in R$ vanishes at $P\in \operatorname{Spec}(R)$ ""
means that $f\in P$ . In our case, $f$ vanishes at all points of $X$ -- does it mean that it vanishes at all prime ideals of $\operatorname{Spec}(A_i)$ for all $i$ ? Then $f$ must lie in each $A_i$ , right? But we only know that $f$ lies in $\mathcal O_X(U)$ for some open $U$ . So I must be misunderstanding what's going on here. Then I need to find $n$ such that $f^n=0$ in the ring $\mathscr O_X(U)$ . But this is just an abstract ring from the definition of a sheaf, how to get hold of that $n$ without knowing anything about this ring? I also tried to approach this exercise from a different side (by understanding the suggested counterexample), but I don't understand it either.","['algebraic-geometry', 'schemes', 'commutative-algebra']"
4268169,Exponential populations that depend upon each other,"I have a question about how to solve an exponential problem that involves two populations, each which depends on the other. For example, let's say we have an initial population of $h$ humans that increases by $H$ percent each year. And let's say we have an initial population of $d$ dragons which increases by $D$ percent each year. Each dragon kills $K_h$ humans a year. And every human kills $H_d$ dragons each year. How can I figure out, in this obviously fictional example, how many dragons or humans there are after $t$ years? Please note: I am not particularly advanced in math; I apologize if this question is either trivial or nonsensical. Please bear with me.","['word-problem', 'systems-of-equations', 'exponential-function', 'ordinary-differential-equations']"
4268174,Why are commutative diagrams called commutative diagrams?,"Why are commutative diagrams called that way? I don't see what's commutative about them.
Here is the commutative diagram for the Fundamental Theorem of Homomorphisms, in case a particular diagram is needed for the answer. (I've only encountered commutative diagrams in the context of abstract algebra, I am not familiar with category theory or uses of this diagram outside of abstract algebra).","['abstract-algebra', 'soft-question', 'terminology']"
4268219,Solve the generalised diophantine equation: $x_1^2 + x_2^2 + \dots + x_n^2 = kx_1 x_2\dots x_n$,"Let $x_1 , x_2 , \dots , x_n$ be $n$ integers. If $k > n>1$ is an integer, prove that the only solution to $x_1^2 + x_2^2 + \dots + x_n^2 = kx_1 x_2\dots x_n$ is $x_1 = x_2 = ¬∑ ¬∑ ¬∑ = x_n = 0.$ Here is my progress. I used vietta jumping. Note that $x_1^2 + x_2^2 + \dots + x_n^2 \ge 0. $ Hence there  are even number of $x_i$ 's such that $|x_i|=-x_i.$ Let them be $a_1,a_2,\dots, a_{2k}.$ Note that we can always replace all the $a_i\rightarrow -a_i$ and it won't effect our equation. So WLOG, we can assume $x_1, x_2 , \dots , x_n$ to be positive ( if anyone is $0$ we get $x_1 = x_2 = ¬∑ ¬∑ ¬∑ = x_n = 0.$ ) Suppose  for some fixed $k$ let $$x_1>x_2>\dots>x_n$$ be the solution such that $(x_1+x_2+\dots +x_n)$ is minimal. Then let $$f(t)=t^2-ktx_2\dots x_n+x_2^2+ \dots + x_n^2.$$ Note that $x_1$ is a root. Let the other root be $w.$ Then since $$w=kx_2\dots x_n -x_1\implies w\in \Bbb Z.$$ And since $$w=\frac{x_2^2+ \dots + x_n^2}{x_1}\implies w>0.$$ So $w$ is a positive integer. Now $$f(x_2)=x_2^2-kx_2^2x_3\dots x_n+x_2^2 + \dots + x_n^2\le x_2^2(n-kx_3\dots x_n).$$ Now as $k>n\implies f(x_2)$ is negative. So by IVT, we get $w< x_2<x_1.$ Which is a contradiction as we are getting $(w+x_2+\dots+x_n)<(x_1+\dots+x_n).$ And we had assumed $(x_1+x_2+\dots +x_n)$ is minimal. So $$x_1>x_2\dots >x_n\implies x_1 = x_2 = ¬∑ ¬∑ ¬∑ = x_n = 0.$$ Now if we have $x_1=x_2.$ We get $$2x_1^2+x_2^2+\dots +x_n^2=kx_1^2x_3\dots x_n$$ Now this implies $x_1^2|x_2^2+\dots +x_n^2.$ I don't know how to proceed with this case, since it's not symmetric, so I can't use vietta jumping. I tried using modulo $l$ but did not progress as $n$ can we anything. Bounding wont work too as $k$ can be anything. Any hints?","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
4268228,Generating series for ternary strings without 000 and not ending with 0,"I would like to find a formula for $T_n$ , the number of ternary strings of length $n$ so that they do not contain three consecutive zeroes, and they do not end with $0$ as well. I can find a recurrence relation for $T_n$ , however I wonder if we can express $T_n$ as a coefficient of a generating series. Thanks for any help!","['combinatorics-on-words', 'recurrence-relations', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
4268234,"Intuitively, why is the solution to Dirichlet Problem on open disk a convolution? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question We know that, given a continuous function $f$ on unit circle $\Bbb T$ , we can find the solution to Dirichlet problem on the unit disk by $$ U(re^{2\pi it}) = P_r \star f $$ where $P_r$ is the Poisson kernel and $0<r<1$ . Is there an intuitive reason why this formula is a convolution for each fixed $r$ ? I understand that the Poisson kernels form a set of test functions that approach the $\delta$ - function as $r \to 1^-$ ; hence near the boundary $U$ approximates $f$ very well. Is there an intuitive reason why inside the disk these convolutions string together to give us a harmonic function?","['integration', 'laplacian', 'functional-analysis', 'partial-differential-equations']"
4268288,How to derive this representation of the Lambert W function?,"Lately I read this in some site about a closed-form representation of Lambert W function (all branch-cuts): $$\ln\bigg(\frac{W_k(z)-1}{ \ln(z)-1+2k\pi{i} }\bigg)=\frac{i}{2\pi}\int_0^\infty{\ln\bigg({\frac{t-\ln{t}+\ln{z}+(2k+1)\pi{i}}{t-\ln{t}+\ln{z}+(2k-1)\pi{i}}}\bigg)\frac{\mathrm{d}t}{t+1}}$$ where $\ln$ denotes the principal branch of natural logarithm. This site doesn't contain any references. Closed-form here refers to being able to be represented in a finite composition of integrals and all ''already-known and well-defined'' functions. Simply using of an iterative inverse denotion is not accepted. I also read Closed-form representations of the Lambert W function by Alexander Kheyfits , in which he the author introduced a very similar representation solved by contour integration. And btw is there some technique to derive a closed-form (integral is in desire) representation for almost any transcendental equations? I read some articles but they gave too many restrictions on the transcendental equation. (Riemann's method) So the question is Is this correct? If so, how to prove it? Is there some technique to derive a closed-form representation for almost any transcendental equations? and What is it? Any contribution is appreciated. :D","['integration', 'lambert-w', 'contour-integration', 'closed-form', 'transcendental-equations']"
4268291,Expected number of throws required so every face of die shows up,"Here's a question from my probability textbook: A die is thrown until every face has turned up at least once. Show that on average $14{7\over{10}}$ throws will be required. The easy way to do this is $$1 + {1\over{5\over6}} + {1\over{4\over6}} + {1\over{3\over6}} + {1\over{2\over6}} + {1\over{1\over6}} = 14 {7\over{10}}.$$ However, this is the solution in the back of my book: If the die be thrown $n$ times the number of ways is $6^n$ . Among which ace will be missing in $5^n$ , ace and deuce in $4^n$ , and so on. Hence the number of ways in which no face will be missing is $$6^n - 6(5^n) + 15(4^n) - 20(3^n) + 15(2^n) - 6(1^n);$$ and the chance of this is $$1 - 6\left({5\over6}\right)^n + 15\left({4\over6}\right)^n - 20\left({3\over6}\right)^n + 15\left({2\over6}\right)^n - 6\left({1\over6}\right)^n;$$ or if $f_n$ be the chance of failing in $n$ throws to turn every face $$f_n = 6\left({5\over6}\right)^n - 15\left({4\over6}\right)^n + 20\left({3\over6}\right)^n - 15\left({2\over6}\right)^n + 6\left({1\over6}\right)^n.$$ (Note that this reduces to unity if $n = 1, 2, 3, 4, 5$ .) I completely follow the solution up to this point. But it's the next claim that I do not follow at all: Hence success will be attained on an average in $s$ trials where $$s = 1 + f_1 + f_2 + \ldots$$ Why is this claim true? I don't see it. Any help would be well-appreciated. For the record, if we assume that claim then I can complete the problem: $$s = 1 + f_1 + f_2 + \ldots = 1 + {{6\left({5\over6}\right)}\over{1 - {5\over6}}} - {{15\left({4\over6}\right)}\over{1 - {4\over6}}} + {{20\left({3\over6}\right)}\over{1 - {3\over6}}} - {{15\left({2\over6}\right)}\over{1 - {2\over6}}} + {{6\left({1\over6}\right)}\over{1 - {1\over6}}} = 1 + 30 - 30 + 20 - {{15}\over2} + {6\over5} = 14{7\over{10}},$$ as desired. So really, I have two questions: Why is the claim that success will be attained on an average in $1 + f_1 + f_2 + \ldots$ trials true (from what follows before in the chronological order of the solution, rather than that the calculation obviously happens to give the desired result)? Can someone walk me step by step with how the book came up with that? What's the precise relationship between the solution I found (the easy way) and the solution in the back of my book (the hard way)? How are they in essence the same at some level? Update: The bounty is about to expire, but nobody has given a clear answer to my satisfaction yet. I just want to understand what's going on, but all the comments and answers so far just muddy the waters further by overcomplicating without giving a clear explanation.","['expected-value', 'coupon-collector', 'combinatorics', 'probability']"
4268357,Is the answer to this truth-statement evaluation wrong? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 2 years ago . Improve this question I have been working through an analysis course and the solutions to some of the exercies presented appear to make no sense.
The exercise reads as follows. Determine which of the following are true: $(\forall x \in \mathbb{Z} )(\exists y \in \mathbb{Z})(\frac{x}{y}>0) $ I view the evaluation of such truth statemets a bit like a game where a challenger(usually the statement that appears after the $\forall$ quantifier) picks numbers $x \in \mathbb{Z}$ and I am trying to find(usually whatever appears after the $\exists$ quantifier) a suitable number $y \in \mathbb{Z}$ that satisfies the condition for any possible $x$ the challenger could pick. My answer is as follows. The statement is false. This is because for $x = 0$ there exists no possible $y$ which satisfies $\frac{x}{y}>0$ . At best, we could have $\frac{x}{y} = 0$ which is NOT strictly larger than $0$ . Now, onto main issue. The source I am using appears to disagree entirely with my argument. Their answers are as follows. Please note that I am quoting the solutions verbatim. The first statement is true since one can take y = x. I disagree with this answer, because one can easily pick $ x = 0 $ and run into all sorts of trouble. Have I missed something? Thank you in advance for any help you may provide.","['logic', 'analysis', 'real-analysis']"
4268371,Five Porismatic Equations.,"Here is a really tough problem. If $$\boldsymbol{a\cos\alpha\cos\beta+b\sin\alpha\sin\beta+c=0}$$ $$\boldsymbol{a\cos\gamma\cos\delta+b\sin\gamma\sin\delta+c=0}$$ $$\boldsymbol{a\cos\beta\cos\gamma+b\sin\beta\sin\gamma+c=0}$$ $$\boldsymbol{a\cos\delta\cos\epsilon+b\sin\delta\sin\epsilon+c=0}$$ $$\boldsymbol{a\cos\epsilon \cos\alpha+b\sin\epsilon\sin\alpha+c=0}$$ prove that $$\boldsymbol{\frac{1}{a^3}+\frac{1}{b^3}+\frac{1}{c^3}=
\left(\frac{1}{b}+\frac{1}{c}\right)
\left(\frac{1}{c}+\frac{1}{a}\right)
\left(\frac{1}{a}+\frac{1}{b}\right)}$$ where all angles are unequal and between $0$ and $2\pi$ . I cannot work out the algebra on this problem.
This is a system of porsimatic equations. Meaning that it only has distinct solutions if some condition on the variables holds. The method is the following, in the case of a chain of three equations, $$a\cos\alpha\cos\beta+b\sin\alpha\sin\beta+c=0$$ $$a\cos\beta\cos\gamma+b\sin\beta\sin\gamma+c=0$$ $$a\cos\gamma\cos\alpha+b\sin\gamma\sin\alpha+c=0$$ We can show $$\tan\frac{1}{2}(\alpha+\beta)=\frac{b}{a}\tan \gamma$$ either by setting an equation in variable $t$ with solutions, $\tan\frac{1}{2}\alpha$ and $\tan\frac{1}{2}\beta$ and using Vietas formulas or more straighforwardly solving for $\sin\gamma$ and $\cos\gamma$ to get $\tan\gamma$ . Similarly $$\tan\frac{1}{2}(\alpha+\gamma)=\frac{b}{a}\tan \beta$$ $$\tan\frac{1}{2}(\gamma+\beta)=\frac{b}{a}\tan \alpha$$ and using these we get $$\tan\frac{1}{2}(\alpha-\beta)=\frac{ab\sin(\alpha-\beta)}{a^2\cos\alpha\cos\beta+b^2\sin\alpha\sin\beta}$$ then using the definition of $\tan=\frac{\sin}{\cos}$ and dividing by $\sin\frac{1}{2}(\alpha-\beta)$ we see that $$a\cos\alpha\cos\beta+b\sin\alpha\sin\beta+c=c-\frac{ab}{a+b}$$ In the case of a chain of five equations we get the fomulas, $$\tan\frac{1}{2}(\alpha+\gamma)=\frac{b}{a}\tan\beta$$ $$\tan\frac{1}{2}(\beta+\delta)=\frac{b}{a}\tan\gamma$$ $$\tan\frac{1}{2}(\gamma+\epsilon)=\frac{b}{a}\tan\delta$$ $$\tan\frac{1}{2}(\alpha+\delta)=\frac{b}{a}\tan\epsilon$$ $$\tan\frac{1}{2}(\epsilon+\beta)=\frac{b}{a}\tan\alpha$$ But how to proceed from there ? I guess you want $\tan\frac{1}{2}(\alpha-\epsilon)
$ as a function of $\alpha$ and $\epsilon$ .","['contest-math', 'algebra-precalculus', 'trigonometry']"
4268439,Is my understanding of derivatives correct?,"(Full disclosure: I'm a complete amateur at differentiation, and just trying to understand derivatives through this question) My explanation of derivatives: Consider the curve $y=x^3$ : (Let us only consider the 1st quadrant for now for simplicity) Now, what is the slope of this curve? Answer: it doesn't have a fixed slope like that of a straight line; its slope is constantly changing. Now, a better question is, where exactly does the slope change? I'll attempt to answer this question now: Consider this graph: Now, the graph of the above function does not have a fixed slope. It has 3 well-defined slopes in the regions OA, AB & BC. Now, where exactly do the slopes of the function change? Answer: it changes 2 times:  first, at point A before the start of segment A, and second at point B before the start of segment BC. Okay, good. Now, what if we made the regions OA, AB & BC smaller. Okay, that's fine; however, it won't be the same function anymore: Now, there are 6 regions with well-defined slopes, OA, AB, BC, CD, DE & EF, and the slope changes 5 times at the points A, B, C, D & E. Now, if we keep making the regions smaller and smaller, we will get the function that we started with, $y=x^3$ : Now, back to our original question, where exactly does the slope of the graph change? The answer is, at each of the infinitely many points of the graph! You can visualize this in this way: in our previous examples, there were a finite number of points where the slope changed. However, if we keep making the regions smaller and smaller, the number of regions and the number of times the slope changes will get bigger and bigger, and at one point, the regions will lose their 2-dimensionality: it will become one-dimensional, just a point, and we will get $y=x^3$ . But the slopes are still changing, so we can understand that the slopes are changing at every point of the curve! Where else is the slope changing?! Now, you might object that how can a point have a slope? You need two points to calculate a slope; you only have one point. Answer: you are right. A point in isolation can't have any slope; however, a point that is part of a graph can have a well-defined slope. Get this, if points can't have slopes, how is the slope of a curve changing at every point? The fact that the slope of the curve is changing at every point is proof that a point can have a slope.  Okay, now I will define what the slope of a point is. The slope of a point that is part of the graph of a function is the slope of the line that is tangent to the graph of the function at that point...(i) Now, how do we calculate this slope of the tangent line? Luckily, earlier mathematicians have worked this out for us: $$f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$$ $f'(x)$ is the slope of the line tangent to the graph of $f$ at $x$ . $f'(x)$ is also known commonly as the derivative of $f$ at $x$ : this is just another name for the slope of the tangent line. Questions: Is (i) a legitimate definition in mathematics? Is my explanation correct? Do you disagree with any parts of my explanation? Bonus question: (If you don't want to answer this, it's fine! However, if you do, it might be helpful for me.) Was my thinking process similar to that of the fathers of calculus? If not, what was their thinking process?","['calculus', 'derivatives']"
4268449,Why do we use *fractional* ideals in construction of the class group?,"I am trying to give a simplified explanation of the class group to students at the upper undergraduate level, who likely have a basic understanding of ring and group theory. While my motivation for constructing the class group as the quotient of the ideal group by the principal ideal group seems clear, I am struggling to justify the extension to fractional ideals. What necessitates this? In the example of $\mathbb{Z}[\sqrt{-5}]$ , we can show that the product of any two non-principal ideals is principal, which holds with the class group being $\mathbb{Z}/2\mathbb{Z}$ . What is the problem with regular ideals that necessitates the shift to fractional ideals?","['number-theory', 'ring-theory', 'ideal-class-group']"
4268451,term for polyhedra whose face normals intersect the center,"When doing certain things with polyhedra, like applying Conway's operations or developing frame models for 3D printing , it's helpful to know whether all the faces face directly away from the center of the polyhedron. In other words, would a line passing through the center of the polyhedron and the center of each face be perpendicular to that face? I've looked through terms for characteristics and symmetries of polyhedra such as here and here , and I don't see a term for that characteristic. For brevity, let's call this characteristic Y for purposes of this question. regular: too narrow. Archimedean solids appear to be Y but not regular. orthohedral: This set of articles defines orthohedral as having ""all faces... equidistant from the center."" I'm pretty sure this is too narrow as well, because it would exclude an Archimedean truncated tetrahedron . uniform: defined as having ""regular polygons as faces and is vertex-transitive"". This is closer, but again, I'm pretty sure it's too narrow. For example, the pseudorhombicuboctahedron (a Johnson solid) is Y but isn't uniform. A simpler example of a non-uniform Y polyhedron would be a rectangular cuboid. Archimedian: If defined as a subset of uniform polyhedra, this is also too narrow. Even if defined more weakly to include pseudo-uniform polyhedra, it excludes most rectangular cuboids. Catalan solid: a brief look at these suggests that they may all be Y. (But Catalan solids don't include all Y polyhedra.) Johnson solid: Too broad (and too narrow, unless it's defined as including uniform polyhedra). Plenty of Johnson solids, such as J7 , are not Y. canonical: All edges equidistant from the center. This isn't true for rectangular cuboids. circumscribable / equiradial : (Thanks to @OscarLanzi for suggesting this direction.) A polyhedron whose vertices all lie on the surface of a sphere, i.e. equidistant from the sphere's center. But the center of the sphere might not be what you expect as the center of the polyhedron... it might even lie outside the polyhedron . Which raises the point that in order to answer this question, one has to first specify what ""center"" of the polyhedron one has in mind as well as what we mean by the center of each face. Using circumcenter for both might give us a well-defined way to answer this question: Y is equivalent to circumscribable (if that's always true). So far, I have been using the arithmetic mean of the vertices as the center of each face and each polyhedron. That seems to work out fine for (true or pseudo) uniform polyhedra. And it has this advantage: For an operation like expansion , in which the faces ""are separated and moved radially apart,"" the center that faces are moving away from would have to be inside the polyhedron. Which isn't always true of the circumcenter. So, the question is, is there a term for Y (for some reasonable definition of 'center' of face and polyhedron)? If not, is there a term for an equivalent characteristic, i.e. a characteristic that is true for a polyhedron iff Y is true?","['polyhedra', 'geometry', 'terminology']"
4268502,The Schwartz genus of a fibration,"I'm working on the topological complexity of a path connected space, which is a particular case of the sectional category (or the Schwartz genus), but all the articles refer to an other article named ""the Schwartz genus of a fiber space"" published by A.S.Schwarz. enter link description here The problem is that it is written by Russian language. I can't find it in English. Can someone help me?","['algebraic-combinatorics', 'algebraic-geometry', 'translation-request', 'algebraic-topology']"
4268531,Rational point inside a rational polygon,"I have the following conjectures. Conjecture 1 : Hypotheses: Let $P = (v_1, v_2, ‚Ä¶. v_n)$ be a (convex or concave) polygon drawn on a plane. The lengths of the edges $(v_1, v_2)$ , $(v_2, v_3)$ ... $(v_n, v_1)$ are all rational numbers. Conclusion: There exists a point $x$ inside the polygon with rational coordinates such that the euclidean distances between the pairs $(x,v_1), (x,v_2), ‚Ä¶ (x,v_n)$ are all rational numbers. Conjecture 2 : Hypotheses: Let $P = (v_1, v_2, ‚Ä¶. v_n)$ be a (convex or concave) polygon drawn on a plane. The lengths of the edges $(v_1, v_2)$ , $(v_2, v_3)$ ... $(v_n, v_1)$ are all rational numbers. The co-ordinates of the vertices $v_1, v_2, ‚Ä¶. v_n$ are all rational numbers. Conclusion: There exists a point $x$ inside the polygon with rational coordinates such that the euclidean distances between the pairs $(x,v_1), (x,v_2), ‚Ä¶ (x,v_n)$ are all rational numbers. The above conjectures sound like a very natural topology problems. Note that the Conjecture 1 implies the Conjecture 2. What I know so far : The above conjectures are true for $n=3$ . This follows from the following theorem. Theorem : The set of points with rational distances to the vertices of a given triangle with sides of rational length is everywhere dense. Conjecture 1 is false for $n > 3$ . For a proof, see Robert Kleinberg's comment on my blogpost . Questions about Conjecture 2 : Is it true for $n=4$ ? Is it true for convex polygons ? Is it true for convex polygon with $n=4$ ? Is it true for any other special cases ? Are there any known generalizations to higher dimensions? A very special case I am very interested in : Let $Q = (v_1, v_2, v_3, v_4)$ be a polygon. The co-ordinates of the vertices $v_1, v_2, v_3, v_4$ are all rational numbers. The lengths of the edges $(v_1, v_2)$ , $(v_2, v_3)$ , $(v_3, v_4)$ and $(v_4, v_1)$ are all rational numbers. The distance between $v_1$ and $v_3$ is rational. Conjecture Q1 : There exists a point $x$ with rational coordinates inside $Q$ such that the euclidean distances between the pairs $(x,v_1), (x,v_2), (x,v_3), (x,v_4)$ are all rational numbers. Conjecture Q2 : Same as Conjecture Q1 when the polygon $Q$ is convex.","['euclidean-geometry', 'geometry', 'geometric-topology', 'rational-numbers']"
4268542,A question from Sheldon Axler Section 2A Exercise 5 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question The question would be : $A$ is a set of closed subsets of $\mathbb{R}$ such that $\bigcap_{F\in A}=\emptyset$ . Show that if $A$ contains at least one bounded set, that there exists an integer $n$ and $F_{1},\dotso, F_{n}$ in $A$ so that $\bigcap F_{i}=\emptyset$ .","['measure-theory', 'real-analysis']"
4268600,"Showing that if a plane curve $L$ is always perpendicular to a fixed vector, then $L$ is a line","I am working on the problem Suppose $f : \mathbb{R}^2 \to \mathbb{R}$ is a differentiable function whose gradient is nowhere zero and satisfies $\frac {\partial f}{\partial x} = 2 \frac {\partial f}{\partial y}$ everywhere. Find the level curves of $f$ . Source: Multivariable Mathematics by Ted Shifrin, page 120. I think I've mostly solved this, but I have several doubts about my solution. Could you please enlighten me about the dubious steps? Thank you! Partial Solution We see $$\nabla f =  [ \frac {\partial f}{\partial x} \ \ \ \frac {\partial f}{\partial y} ]^T = \frac {\partial f}{\partial y} [2 \ \ \ 1]^T$$ and $\frac {\partial f}{\partial y}$ is never $0$ .  Let $L$ be the level curve $L = \{(x, y)|f(x, y) = c \},$ and write it in parametric form $[x(t), y(t)]^T.$ Since the gradient is perpendicular to the level curve, we must have $$\forall t: \ \ 2x'(t) + y'(t) = 0$$ so $y(t) = - \frac 12 x(t) + k$ for some constant $k$ . Thus, we see that $L$ must be a $\textit{subset}$ of a line. My questions are: Can we prove that $L$ is indeed an entire, infinite line? How can we justify that we can write the set $L$ as the image of $[x(t) \ \ \ y(t)]$ for some functions $x, y$ ? Thank you!","['multivariable-calculus', 'differential-geometry', 'real-analysis']"
4268601,first term in the asymptotic expansion using method of steepest descent,"I am working with the following intgral: $\int_{0}^{\infty}t^{n}e^{-x(t+\frac{1}{t})}dt$ as $x\rightarrow \infty$ Now, I have been trying to solve this using the method of steepest descent. After finding the saddle points I think I have found the steepest descent path to be along the unit circle. However, I am not sure how I should now use that information to now deform the contour to do the asymptotic expansion. Any ideas?","['complex-analysis', 'gradient-descent', 'laplace-method', 'asymptotics']"
4268664,How solve with a short way a problem on the sequences for students of a high school?,"The equilateral triangle has side length $a=1$ ; suppose that the number of circles in the last row
(i.e. the circles tangent to the base of the triangle) is $n$ (the figure shows the special case where $n=10$ ), that of the penultimate row $n-1$ and so on, up to the first row, which contains only one circle. a. Express as a function of $n$ the area an of the region of the plane occupied altogether by the circles. b. When $n\to +\infty$ , do the circles fill the triangle completely? The picture is: Solution : Neighbouring circles are externally tangent to each other, so if $r$ is their common radius and we consider $k$ of them consecutive, from left to right just to fix the ideas, the distance between the left edge of the first circle and the right edge of the last one is $2rk$ . If we consider all the circles on the base (lower side), let us suppose them to be $n$ , and let us consider the first one on the left, tangent to both sides of the vertex on the lower left, and the last one on the right, tangent to both sides of the vertex on the lower right, there remain on the base between them $n-2$ , which must fill exactly the space left between the edge on the right of the first circle and the one on the left of the last circle. How is this space calculated? The edge on the right of the first circle is projected onto the base at a point at distance $x+r$ from the vertex on the left, and the same is done for the edge on the right of the last circle, at distance $x+r$ from the vertex on the right of the base; the space sought is therefore $a-2(x+r)$ , and must be filled exactly by $n-2$ circles of radius $r$ , from which $(n-2)(2r)=a-2(x+r)$ . Of course, not for every radius $r$ we have the desired set of circles, only for the $r$ for which the relation $(n-2)(2r)=a-2(x+r)$ is verified by a natural $n$ . In an angle of $\pi/3$ radians consider a circle of radius $r$ tangent to both sides (therefore with its centre on the bisector); let $x$ be the distance of the point of tangency from the vertex of the angle; then we have $r/x=\tan\pi/6=1/\sqrt3$ , therefore $x=r\sqrt3$ . If we consider the two circles at the extremity of the base of the triangle, there must be $n-2$ circles of radius $r$ between them, from which the relation $(n-2)(2r)=a-2(x+r)$ , where $a$ is the side of the equilateral triangle (in our case $a=1$ , but let $a$ be left). Therefore we have $$(n-2)2r=a-2r\,(\sqrt3+1)\iff r=\frac a{2(n+\sqrt3-1)}.$$ Each circle has area $\pi\,r^2=\pi a^2/(4(n+\sqrt3-1)^2)$ and there are $1+2+\dots+n=n(n+1)/2$ circles, so the total area of the circles is $$a_n=\frac{\pi\,n(n+1)}{8(n+\sqrt3-1)^2}\,a^2$$ as given in the problem. The area of the equilateral triangle is $(\sqrt3/4)\,a^2$ , the ratio between the areas is therefore: $$\frac{a_n}{(\sqrt3/4)\,a^2}=\dfrac\pi{2\,\sqrt3}\,\dfrac{n^2+n}{(n+\sqrt3-1)^2}$$ which tends, increasing, to $\pi/(2\sqrt3)\approx 0,907$ : even in the limit for $r\to 0^+$ , equivalently for $n\to\infty$ , the circles cover a little more than $90\%$ of the area of the triangle. My question : If I were to explain the problem to my high school students ( $17-18$ years old) step by step, it would take at least an hour of class time to do it, excluding explanations. Is there a faster and more immediate solution?","['euclidean-geometry', 'geometry', 'alternative-proof', 'education', 'sequences-and-series']"
4268711,Why does a space of symmetric traceless tensors form an irreducible representation of $SO(3)$?,"I have asked a similar question on Physics StackExchange , but did not get an answer. In the chapter IV.1 ""Reducible or Irreducible?"" of Zee's Group Theory book (p. 188-), the author breaks a 2nd rank tensor $T^{ij}$ into invariant subspaces with respect to the action of $\mathrm{SO(3)}$ group. The tensor $T^{ij}$ breaks into a five-dimensional (symmetric traceless), three-dimensional (antisymmetric) and one-dimensional invariant subspaces. Zee claims this five-dimensional space to be irreducible, i.e. it is implied that it does not have non-trivial invariant subspaces. Unfortunately, there is no proof. Can someone explain to me why symmetric traceless tensors form an irreducible representation $\mathrm{SO(3)}$ ? References to relevant literature would be helpful as well.","['group-theory', 'tensors', 'representation-theory']"
4268734,"Given a degree-two endomorphism of an elliptic curve, how to construct the following map to $\Bbb P^1$?","This is the first part of Hartshorne exercise IV.4.5. Let $(X,P_0)$ be an elliptic curve having an endomorphims $f:X\to X$ be of degree two. If we represent $X$ as a 2-1 cover of $\Bbb P^1$ by a morphism $\pi:X\to\Bbb P^1$ ramified at $P_0$ , then as in (4.4), show that there is another morphism $\pi':X\to \Bbb P^1$ and a morphism $g:\Bbb P^1\to\Bbb P^1$ , also of degree 2, such that $\pi\circ f=g\circ\pi'$ . Here's lemma IV.4.4 referenced above, where $X$ is used to denote an elliptic curve: Lemma : If $f_1:X\to\Bbb P^1$ and $f_2:X\to\Bbb P^1$ are any two morphisms of degree 2 from $X$ to $\Bbb P^1$ , then there are automorphisms $\sigma\in \operatorname{Aut} X$ and $\tau\in\operatorname{Aut} \Bbb P^1$ so that $f_2\circ\sigma=\tau\circ f_1$ . Proof : Let $P_1$ be a ramification point of $f_1$ and let $P_2$ be a ramification point of $f_2$ . Then since the group of automorphisms of $X$ is transitive, there is $\sigma\in\operatorname{Aut} X$ such that $\sigma(P_1)=P_2$ . On the other hand, $f_1$ is determined by the linear system $|2P_1|$ and $f_2$ is determined by $|2P_2|$ . Since $\sigma$ takes one to the other, $f_1$ and $f_2\circ\sigma$ correspond to the same linear system, so they differ only by an automorphism $\tau$ of $\Bbb P^1$ . I'm a little stuck in figuring out how to construct $\pi'$ and $g$ . It seems like I can't copy the proof of 4.4 directly, because $f$ is degree-two instead of an automorphism. But we can do something similar: $\pi$ is given by $|2P_0|$ , so $\pi\circ f$ is given by the map to $\Bbb P^1$ determined by $[(\pi\circ f)^*x:(\pi\circ f)^*y]$ where $(\pi\circ f)^*x$ and $(\pi\circ f)^*y$ are the images of $x,y\in\mathcal{O}_{\Bbb P^1}(1)$ under the composite pullback $\Gamma(\Bbb P^1,\mathcal{O}_{\Bbb P^1}(1))\to\Gamma(X,\mathcal{O}_X(2P_0))\to\Gamma(X,f^*\mathcal{O}_X(2P_0))$ . But I'm having trouble seeing how to factor this as $X\stackrel{\pi'}{\to}\Bbb P^1\stackrel{g}{\to}\Bbb P^1$ where $\pi'$ and $g$ both have degree two. I'm looking for help understanding what to do here. I did find this question which mentions the first two parts in passing, but it seems like they've got some things the wrong way around. Further attempts : By Riemann-Hurwitz and the assumption that our base field is not characteristic two, $f$ is unramified and therefore $f^{-1}(P_0)$ is two distinct points, say $Q_1,Q_2$ . Then $f^*\mathcal{O}_X(2P_0)\cong\mathcal{O}_X(2Q_1+2Q_2)$ , which has a four-dimensional space of global sections. I think I should be able to pick two linearly independent global sections with no common base point in here which are the squares of global sections from $\mathcal{O}_X(Q_1+Q_2)$ , and then use these to define the maps. But I'm not sure and would appreciate some confirmation.","['algebraic-geometry', 'elliptic-curves']"
4268745,"Mistake computing $\int_0^\infty\frac{x \ln(1+x^2)}{\sinh \pi x}\,dx=\frac{\ln 2}{3} - \log \pi - \frac{1}{2} + 6 \ln A $","Edit I found the mistake, see my answer below. I am trying to evaluate the integral $$\int_0^\infty\frac{x \ln(1+x^2)}{\sinh \pi x}\,dx=\frac{\ln 2}{3} - \log \pi - \frac{1}{2} + 6 \ln A $$ I know this integral was already evaluated in this post utilizing various different techniques. But I am trying to compute yet with another one, but due to a mistake which I cannot spot,  I  can¬¥t finish.
This is how I proceeded: First note that $$
\begin{aligned}
&\frac{1}{\sinh \pi x}=\frac{2}{e^{\pi x}-1}-\frac{2}{e^{2 \pi x}-1}\\
&\frac{1}{\sinh \pi x}=\frac{2}{e^{\pi x}-1}-\frac{2e^{-\pi x}}{e^{ \pi x}-e^{-\pi x}}\\
&\frac{1}{\sinh \pi x}=\frac{2}{e^{\pi x}-1}-\frac{e^{-\pi x}}{\sinh \pi x}\\
&\frac{e^{-\pi x}+1}{\sinh \pi x}=\frac{2}{e^{\pi x}-1}\\
&\frac{1}{\sinh \pi x}=\frac{2}{(e^{\pi x}-1)(e^{-\pi x}+1)}\\
&\frac{1}{\sinh \pi x}=\frac{1}{\sinh \pi x} \qquad \blacksquare\\
\end{aligned}
$$ Then consider the following more general integral, which upon letting $z \to 1$ recovers the goal integral. $$I(z)=\int_0^\infty\frac{x \ln(z^2+x^2)}{\sinh \pi x}\,dx $$ It can be rewritten as $$I(z)=2\int_0^\infty\frac{x \ln(z^2+x^2)}{e^{\pi x}-1}\,dx-2\int_0^\infty\frac{x \ln(z^2+x^2)}{e^{2\pi x}-1}\,dx \tag{1}$$ Differentiating $(1)$ w.r. to $z$ we obtain $$I^{\prime}(z)=4\int_0^\infty\frac{zx }{(z^2+x^2)(e^{\pi x}-1)}\,dx-4\int_0^\infty\frac{zx }{(z^2+x^2)(e^{2\pi x}-1)}\,dx \tag{2}$$ Now recall Binet¬¥s Integral representation for the Digamma function $$\int_0^\infty\frac{x }{(z^2+x^2)(e^{2\pi x}-1)}\,dx=\frac{\log(z)}{2}-\frac{\psi(z)}{2}-\frac{1}{4z} \tag{3}$$ Multiplying $(3)$ by $4 \, z$ $$4\int_0^\infty\frac{zx }{(z^2+x^2)(e^{2\pi x}-1)}\,dx=2z\log(z)-2z\psi(z)-1 \tag{4}$$ Also, making the change of variable $2x \mapsto x$ and multiplying by $4z$ in $(3)$ we get $$4\int_0^\infty\frac{zx }{(z^2+x^2)(e^{\pi x}-1)}\,dx=2z\log\left(\frac{z}{2}\right)-2z\psi\left(\frac{z}{2}\right)-2 \tag{5}$$ Plugging the R.H.S. of $(4)$ and $(5)$ back in $(2)$ we get $$\begin{aligned}
I^{\prime}(z)&=2z\log\left(\frac{z}{2}\right)-2z\psi\left(\frac{z}{2}\right)-2-2z\log(z)+2z\psi(z)+1\\
&=2\left(z\ln z-z \ln2 \right)-2z\psi\left(\frac{z}{2}\right)-2z\ln z+2 z \psi(z)-1\\
&=-2 \ln2 z -2z\psi\left(\frac{z}{2}\right)+2 z \psi(z)-1\\
\end{aligned}$$ Now integrate from $0 \,\, \text{to} \,\, z$ $$\begin{aligned}
I(z)&=-2 \ln2 \int_0^zx\,dx -2\int_0^z x\psi\left(\frac{x}{2}\right)\,dx+2 \int_0^z z \psi(x)\,dx-\int_0^z \,dx\\
&=-\ln2 z^2 -2\int_0^z x\psi\left(\frac{x}{2}\right)\,dx+2 \int_0^z x \psi(x)\,dx-z
\end{aligned}$$ Letting $z \to 1$ $$I(1)= -\ln2  -8\int_0^{1/2} x\psi\left(x\right)\,dx+2 \int_0^1 x \psi(x)\,dx-\ln e \tag{6}$$ The two integrals involving the Digamma function I computed as follows $$
\begin{aligned}
\int_0^1 x \psi(x)\,dx&=-\int_0^1 \ln \Gamma(x) dx\\
&=-\frac12 \ln 2 \pi
\end{aligned}
$$ $$
\begin{aligned}
\int_0^1 x \psi\left(\frac{x}{2}\right)\,dx&=4\int_0^{1/2} x \psi(x)\,dx \qquad \left(\frac x2 \to x\right)\\
&=4\left(x\ln \Gamma(x) \Big|_0^{1/2}-\int_0^{1/2} \ln \Gamma(x) dx \right)\\
&= \ln  \pi-4\left(\frac32 \ln A+\frac{5}{24}\ln 2+ \frac14 \ln \pi\right)\\
&=-\ln A^6-\frac56 \ln 2
\end{aligned}
$$ where in the last one I used the result $$\int_0^{1/2} \ln \Gamma(x) dx=\frac32 \ln A+\frac{5}{24}\ln 2+ \frac14 \ln \pi$$ Plugging back the values of the integrals in $(6)$ I got $$\begin{aligned}
I(1)&=-\ln2  +2\left(\ln A^6+\frac56 \ln 2 \right)- \ln 2 -\ln\pi-\ln e\\
&=-2\ln2  +2\ln A^6+\frac53 \ln 2  -\ln\pi -\ln e\\
\end{aligned}$$ Which does not match with the right answer. Can someone point me where is my mistake(s)?","['integration', 'digamma-function']"
4268754,"Is ""fattening"" countable sets a good way to compare their relative density within an uncountable set?","In a recent conversation, someone posed the following argument: The cardinality of the natural numbers and the rational numbers is the same, since they're both countable. So the probability of randomly selecting a natural number from the rational numbers is the same as selecting a non-natural number. This is obviously false for any finite interval (there are a finite number of natural numbers but an infinite number of rational numbers in that interval, after all), but it wasn't immediately clear to me how to properly extend to the entire real line. Cardinality is, of course, not a good way to think about probability on infinite sets, and ordinarily I would go to measure theory as the way to compare the sets' relative sizes (where, for the improper analogue of a uniform distribution, relative size is proportional to relative probability of selection). But the problem is that both sets are countable, and therefore both have measure zero using the usual measure on the real line. So I tried constructing something like a measure on the rationals, but a quick search of the literature suggested that such a thing wasn't possible, or at least wasn't likely to be at all well-behaved if it was. So, the solution I came upon was the following procedure: for any countable set $X$ , construct the ""fat"" version of $X$ , which we will call $X_d$ , by replacing each element of $x$ with an open* ball of some (small) radius $d$ , centered at $x$ ; then, $X_d$ is the union of all such open balls. In other words, we define: $$X_d=\bigcup_{x\in X}B(x,d)$$ where $B(x,d)$ is the open ball centered at $x$ of radius $d$ . This allows us to measure-theoretically compare the densities of countable subsets of an uncountable set. The set $\mathbb{Z}_d$ , or indeed the set $\mathbb{N}_d$ , has gaps for all $d<1$ . On the other hand, since the rationals are dense in the reals, we have that $\mathbb{Q}_d=\mathbb{R}$ for any $d$ . So the ratio of the sizes of $\mathbb{Z}_d$ and $\mathbb{Q}_d$ is roughly $d$ (""roughly"" because you could choose endpoints within a distance $d$ of an integer), regardless of the size of the interval. Sending $d$ to zero essentially recovers the original sets, along with the result that you will randomly select an integer from among the rationals with probability zero (thus, the same result holds for the natural numbers). Is this a reasonable way to get around the problems inherent in working with probability on the rationals? More generally, is it a reasonable way to compare the relative densities of countable subsets of uncountable sets? *As far as I can tell, the choice of open or closed ball doesn't matter for this procedure; I could be wrong on this, though.","['measure-theory', 'probability']"
4268756,Probability that the difference of two independent Binomials with the same $n$ is negative,"Suppose I have $X\sim \operatorname{Binom}(n,p_0)$ and $Y\sim \operatorname{Binom}(n,p_1)$ where $p_0>p_1$ , I need to bound $$P(X-Y\le 0)$$ One way to do is to write $X-Y$ as a sum of i.i.d. random variables which are differences of $\operatorname{Bern}(p_0)$ and $\operatorname{Bern}(p_1)$ and use Chernoff bound to get $$P(X-Y\le 0)\le \exp\left(-\frac{1}{2}n(p_0-p_1)^2\right)$$ I know that since Chernoff bound does not utilize the variance, one of Bernstein's inequalities could give a tighter bound. I have tried the Inequality (1) in given here . However, when I did so, I found a messy exponent in the upper bound which isn't always tighter than the one given by Chernoff bound. My main question is: Is there a way where I can prove a tighter or a normal-looking bound, with the first exponent of the form $$\exp\left(-\frac{1}{2} n\frac{(p_0-p_1)^2}{p_0(1-p_0)+p_1(1-p_1)}\right).$$ Thanks a lot!","['statistics', 'binomial-distribution', 'probability']"
4268834,Analytical formula for a summation,"I am looking for an ""analytical"" formula for the following summation; that is, write the following function without a summation sign: $$ f(n) = \sum_{k=0}^{n}(-1)^k \cdot {n \choose k} \cdot (n-k)^{3n-1} $$ defined for all natural numbers $ n \in \mathbb{N} $ . A disclaimer in beforehand: I actually do not know whether there is a solution to my problem, but I am grateful for any idea (also for asymptotically accurate results). My intuition was to somehow use the binomial expansion here, but I did not get anywhere...","['summation', 'binomial-coefficients', 'combinatorics']"
4268842,Gaussian Processes Clarification,"$\newcommand\mycolv[1]{\begin{bmatrix}#1\end{bmatrix}}$ Hi all, I've been trying to learn all about Gaussian processes for a few days but I find myself stuck on some notation. The book that I have been mainly reading and other articles I've found split up a given multivariate Gaussian distribution into two random vectors $\textbf{x}$ and $\textbf{y}$ where $\textbf{y}$ contains the observed points. This makes sense to me until the redefinition of the gaussian comes up: $$\mycolv{\textbf{x} \\ \textbf{y}} \sim N(\mycolv{\mu_x \\ \mu_y}, \begin{bmatrix}\Sigma_{xx} & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_{yy}\end{bmatrix})$$ Unfortunately I am not clear on how to compute the values in this definition. Are the mean vectors just the mean of all of the distribution in each random vector i.e some scalar? Or are they a vector simply containing all of the means of each distribution contained in the corresponding vector? As for the covariance matrix I can imagine having each $\Sigma$ be a covariance matrix, however, since this would cause the dimensions of the $\Sigma_{yx}$ and $\Sigma_{xy}$ matrices to be larger than the other matrices, making multiplication between those two matrices and the other two incompatible. This poses an issue since the product of $\Sigma_{yy}^{-1}$ and $\Sigma_{xy}$ is required when conditioning the multivariate. Sorry if I made any errors. Any help would be appreciated.","['statistics', 'gaussian', 'normal-distribution']"
4268883,Probability of random variable - set may not be in event space,"According to 2021 Wikipedia , given a probability space $(\Omega, \mathcal{F}, P)$ and a random variable $X : \Omega \to \mathbb{R}$ , the probability that $X$ takes on a value in $S \subseteq \mathbb{R}$ is defined as $$P(X \in S) := P \left( \{ \omega \in \Omega \ : X(\omega) \in S \} \right)$$ How do we know that the event space $\mathcal{F}$ contains $\{ \omega \in \Omega : X(\omega) \in S \}$ ? If $\Omega$ is countable, then $\{ \omega \in \Omega : X(\omega) \in S \}$ is a countable union of sets $\{ \omega \}$ and therefore in $\mathcal{F}$ . But what if there are uncountably many $\omega$ such that $X(\omega) \in S$ ? The event space is only closed under countable union...","['measure-theory', 'probability-theory', 'random-variables']"
4268898,Quantile function of two-term gaussian,"I'm trying to find the quantile function of the two-term gaussian. From https://statproofbook.github.io/P/norm-qf.html , I've got that I can take the inverse of the CDF of the two-term gaussian.  I've got the two-term CDF as $${1\over2}\left[2+erf\left({(x-\mu_1)\over\sqrt2\sigma_1}\right)+erf\left({(x-\mu_2)\over\sqrt2\sigma_2}\right)\right]$$ Sadly, $erf\left({x-\mu_1\over\sqrt2\sigma_1}\right)+erf\left({x-\mu_2\over\sqrt2\sigma_2}\right)$ is not equal to $erf\left({x-\mu_1\over\sqrt2\sigma_1}+{x-\mu_2\over\sqrt2\sigma_2}\right)$ . (I examined it numerically.) I tried to make a sum function $$erf\_sum(x,\mu_1,\sigma_1,\mu_2,\sigma_2) = {2\over\sqrt\pi}\left[\int_{0}^{x-\mu_1\over\sqrt{2}\sigma_1}e^{-t_1^2}dt_1+\int_{0}^{x-\mu_2\over\sqrt{2}\sigma_2}e^{-t_2^2}dt_2\right]$$ with the hope I could do some change-of-variables trickery to bring the two integrals together into an $erf$ -like form so I could still express the result using $erfinv$ , but I wasn't able to get very far.  The domains of the integrals look like they'll forever be different.  So, I'm stuck here.  Any help is appreciated.","['statistics', 'quantile-function', 'normal-distribution', 'calculus', 'error-function']"
