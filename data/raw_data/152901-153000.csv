question_id,title,body,tags
2567615,Does a 2D stable limit cycle always contain an unstable equilibrium point?,"I believe that the answer is yes (provided there are no further limit cycles within the first one). Let there be a stable limit cycle with no other limit cycles within it. By reversing time, $t \rightarrow -t$, we get a new system with trajectories bounded to the interior of the limit cycle. Using, say, Brouwer’s fixed point theorem, one can show that there must be a fixed point within the region. However, when reading different formulations of the Poincaré–Bendixson theorem, I often encountered the statements like this: If the trajectories are bounded and there are no fixed points, then the trajectories must converge to a limit cycle. Are these are just unlucky/incorrect formulations or there is something in it?","['ordinary-differential-equations', 'dynamical-systems']"
2567679,Product between a column vector and a row vector,"I know that matrices product is correct when the number of the columns of the first matrix is equal to the number of rows of the second matrix. Why I can't do the product between a column vector and a row vector? For example: $$\begin{bmatrix}1 \\ 2 \\ 3 \end{bmatrix} \, \begin{bmatrix}1 & 2 & 3\end{bmatrix}$$ Thank you so much.","['matrices', 'linear-algebra']"
2567709,Is it possible to solve this problem mathematically?,"On this day, after a total of $4-5$ hours, the following conclusion I reached: This is impossible. I think there's not a ""special"" way to do it.I don't even know where to start. I really want to know if at least this is possible or impossible.","['algebra-precalculus', 'number-theory']"
2567730,Is this a proof that $\mathbb Q$ is dense in $\mathbb R$?,"I read a proof that $\mathbb Q$ is dense in $\mathbb R$ which seemed unnecessarily complex. I was wondering if the following is also a valid proof. Say for the sake of argument that the existence of $\mathbb Q$ and $\mathbb R$, and the greatest-lower-bound property of the latter, have already been established. Also, that for any $u$ and $v$ in $\mathbb R$ such that $u>0$, there exists some positive integer $n$ such that $un>v$. Now let $x\in \mathbb R,y\in \mathbb R$ and $x<y$. I'll attempt to show that $(x,y)\cap \mathbb Q\neq\emptyset$. Let $n$ be a positive integer such that $y-x>\frac{1}{n}$. Let $S=\{z\in \mathbb Z:xn<z\}$. $S$ cannot be empty, because analogously to the above, there must exist a positive integer $z$ such that $\frac{1}{n}z>x$. Then $xn$ is a lower bound of $S$, and by the greatest-lower-bound property, $z=\inf S$ exists in $\mathbb R$. Since $S\subseteq\mathbb Z$, $z\in S$, and so $\frac{z}{n}>x$. It remains to show that $\frac{z}{n}<y$. Suppose $\frac{z}{n}\geq y$. Then $\frac{z}{n}\geq x+(y-x)$, $\frac{z}{n}>x+\frac{1}{n}$, and $\frac{z-1}{n}>x$. But then $z\neq \inf S$, which yields a contradiction. Thus $x<\frac{z}{n}<y$. Since $x$ and $y$ were arbitrary, $\mathbb Q$ is dense in $\mathbb R$. Edit: Removed incorrect assertion that $x$ was a lower bound of $S$.","['real-analysis', 'real-numbers', 'elementary-set-theory']"
2567754,Are all polynomials of degree 1 irreducible?,"Suppose we define an irreducible polynomial in the following way: Let $P(X) \in \{K[x] \text{ of degree at least 1}\}$ . $P(x)$ is irreducible over the ring $K$ iif: $$
\forall A(x), B(x)\in K[x]:A(x)B(x) = P(x) \implies (\text{deg}(A)=0 \text{ } \lor \text{deg(B)}=0)
$$ Now consider the following test question: Every polynomial of degree 1 from $K[x]$ is irreducible. Is this statement true or false?","['abstract-algebra', 'ring-theory', 'polynomials']"
2567790,"Definition of the term ""De Rham map""","I am a PhD student working in the field of numerical simulation. In several papers, the term ""De Rham map"" pops up (for instance in the very good thesis by Jérôme Bonelle : https://tel.archives-ouvertes.fr/tel-01116527v2/document ). I am unsure about the definition of this term. I have come to believe that this term generally means ""operation that have continuous objects correspond to discrete ones"" i.e. ""means of defining the actual values of the degrees of freedom of a discrete object from a continuous object"", but I gradually suspect that it might rather mean ""result of the integration of a cochain on a differentiable manifold"". Of course, the two notions coincide in the litterature I have come accross. So my question is : What is the definition of the term ""De Rham map"" ? Regards,","['manifolds', 'integration', 'differential-geometry', 'simulation']"
2567794,Show that $f$ is integrable iff $\sum\limits_{n\in\mathbb{Z}}2^n \mu(\{x\in S:2^n< \left|f(x)\right|\leq2^{n+1}\})<\infty.$,"I can use the following proposition: Proposition A: For a measurable function $f:S\to\overline{\mathbb{R}}$ the following are equivalent: i) $f$ is integrable. ii) $\left|f\right|$ is integrable. Now, let $f,g:S\to\overline{\mathbb{R}}$ be measurable functions. Exercise: Show that $f$ is integrable iff $\sum\limits_{n\in\mathbb{Z}}2^n \mu(\{x\in S:2^n< \left|f(x)\right|\leq2^{n+1}\})<\infty.$ Solution: Let $A_n = \{x\in S:2^n < \left|f(x)\right|\leq 2^{n+1}\}$ for $n\in\mathbb{Z}$. Then the $(A_n)_{n\in\mathbb{Z}}$ are disjoint. Let $C:=\sum\limits_{n\in\mathbb{Z}}2^n\mu(A_n)$. Let $g:=\sum\limits_{n\in\mathbb{Z}}2^{n+1}\mathbb{1}_{A_n}$ and $h:=\sum\limits_{n\in\mathbb{Z}}2^n\mathbb{1}_{A_n}$. Then $h\leq f\leq g$. Moreover, $$\int_Shd\mu=C\,\,\text{ and }\int_Sgd\mu = 2C.$$ From monotonicity we see that $C\leq \int_S \left|f\right|d\mu\leq 2C$, and the required equivalence follows from proposition A. There's a lot of things about this proof that I don't understand: Questions: How do we know that $f(x)\leq g(x)$? I understand that this is true if $x \in A_n$ for some $n\in\mathbb{Z}$, but isn't it possible that there exists an $x$ such that $x\notin A_n$ for any $n\in\mathbb{Z}$? If it's not possible that would mean that $\bigcup\limits_{n\in\mathbb{Z}}A_n = S$, right? But how do we know this is the case? Why do we have that $\int_S hd\mu = C$? $h$ is not a simple function right? Why do we know that from monotonicity we have that $C\leq \int_S \left|f\right|d\mu\leq 2C$? Isn't this supposed to be $C\leq \int_S fd\mu\leq 2C$, as we know that $h\leq f\leq g$? If I accept that the steps that I questioned above are true, I'm still not done. While I understand that constructing functions $h$ and $g$ in the way that is done in the solution would imply that $f$ is integrable, I don't understand how this proof shows the if and if only part of the exercise. Could you explain why this is the case? I understand that this is a lot to answer; feel free to present your own explanation that doesn't not directly answer any of the particular questions I posed, but explains the solution in a more general way. Thanks in advance!","['real-analysis', 'integration', 'lebesgue-integral', 'measure-theory']"
2567807,Evaluate $\int ydx + zdy + xdz$ using Stokes' Theorem?,"Evaluate $\int ydx + zdy + xdz$ where $C $ is intersection of $x+y=2$
  and $x^2+y^2+z^2=2(x+y) $ traversed counterclockwise as viewed from
  origin I am using Stokes' theorem to solve this question so We want $\int \int curl F.N \; dS$ where $N$ is the normal unit vector to surface S, where S is a surface bounded by $C$ $F = \langle  y,z,x\rangle$ $curl  F  = \langle -1,-1,-1 \rangle $ I take $S $  on the plane $x+y = 2$ $\nabla (x+y) = \langle 1,1,0 \rangle  = A(say)$ Then unit normal vector $N =  \langle -1/\sqrt2,-1/\sqrt2, 0\rangle $ {Multiplied by $-1$ because we are viewing it from origin } $curl F.N= \sqrt(2)$ Now intersection of $x+y=2 $ and $x^2+y^2+z^2 = 2(x+y) $ gives $x^2 + y^2 + z^2 = 4$ To get projection onto $xy$ plane $z=0$ we get $x^2 +y^2 =4$ Now I am stuck in finding $dS$ How do I get dS = $\sqrt{z_x^2 +z_y^2 +1}dA$  where $A:x^2 +y^2 =4$ This is because my $S:x+y=2$ has no $z$ term",['multivariable-calculus']
2567840,"If $E$ is Jordan measurable with measure zero, then $\int _E f=0$?","Is it true that if $E$ is a Jordan measurable set of measure zero, then $\int _E f=0 $ ? note that I'm talking about Riemann integral here. I managed to prove it when $E$ is compact: in that case I can take a finite amount of rectangles $R_i$ such that $E \subset \bigcup R_i $ and $\sum Vol(R_i)< \epsilon$, for every $\epsilon >0$ and then use Riemann sums on a rectangle that contains $E$. In the general case I might only have an infinite amount of rectangles that contains $E$, and in this case I'm stuck. How can I prove it?","['real-analysis', 'measure-theory', 'calculus', 'riemann-integration']"
2567847,Understanding Quotient of a Quotient Ring,"The question I am asking is very elementary I think.
Suppose $R$ is an integral domain. Let $I$ be an ideal of $R$. Then we can consider the quotient ring $R/I= I_R$. Now consider an ideal $J'$ of $R/I$ , then from the fourth isomorphism theorem of ring we can say that there is an ideal $J$ of $R$ containing $I$ such that $J' = J/I $ in $R/I$. Now if we consider the quotient ring $I_R$ , then we can again quotient it by the ideal $J'$ i.e by $J/I$, so we have a quotient ring $I_R/J'$ which is actually $(R/I)/(J/I)$ and from third isomorphism theorem we have $(R/I)/(J/I)$ i.e $I_R/J'$  isomorphic to $R/J$. Now while viewing some questions and answers about quotient ring on this site, I found this answer (question is attached with it) in which the  very 1st line is confusing to me. Why the ordering in quotient doesn't matter ? ( Regarding to the question if we see, then we have $R = \mathbb Z[x] , I =((x^2+x+1)(x^3 +x+1)) , I_R = \mathbb Z[x]/I, J' = (2)  $. So for $J'$ we have an ideal $J$ corresponding to it in $\mathbb Z[x] $ which contains $I$ . So we have $(R/I)/(J/I) $ isomorphic to $R/J$. I understand atmost to this extent. ) If I accept the 1st line, then I am ok with the proof. Next in this answer how $ \mathbb Z[√3] /(1+2√3) $ is isomorphic to $\mathbb Z[x]/((x^2-3),(1+2x))$ ? I am ok that $\mathbb Z[√3]$ is isomorphic to the ring $\mathbb Z[x]/(x^2-3)$, and I think $\mathbb Z[√3]/(1+2√3) $ is isomorphic to $(\mathbb Z[x]/(x^2 - 3))/(1+2√3)$. So is it permissible to write $(\mathbb Z[x]/(x^2 - 3))/(1+2√3)$ as $\mathbb Z[x] /( x^2-3, 1+ 2√3) $ ? If yes then why ? Here  $1+2√3$ is actually $1+2x$ because here $x^2=3$, so $x=√3 $, am I right ? All of my questions are very easy I think, but due to a bizzare view about the Polynomial Rings and there quotients I am unable to understand these. Also my question is large , but I need to understand the concept, so I am looking for a simple explanation. Thank you.","['abstract-algebra', 'polynomial-rings', 'quotient-spaces']"
2567848,Show that every integer eigenvalue of $A$ divides the determinant of $A$.,"Let $A$ be a square matrix of order $n$ whose entries are all integers.
  Show that every integer eigenvalue of $A$ divides the determinant of $A$. I am not able to understand how to show this.
We know that $\det A$ is the product of eigen values and so every eigen value must divide $\det A$. But if a matrix has eigen values $3$ and $\frac{4}{3}$ then if I do the product then the factor $3$  gets neutralized if I do the product then how does it appear as a factor of $\det A$? Please help.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2567868,Are open affine sets a base for the topology of a scheme?,"Let $X$ be a scheme. Then $X$ is covered by open affines $\operatorname{Spec} A_i$ for some rings $A_i$ , by definition. But do those necessarily give a base for the topology of $X$ ? Is it true that finite intersections of affines are again affine?","['general-topology', 'algebraic-geometry']"
2567902,Area of a hexagon (that made of three triangles),I want to find area of the hexagon that is in picture But I can't find area of two triangles that I marked with question mark . Would you please help me or give an Idea ? Thanks in advance.,"['algebra-precalculus', 'euclidean-geometry', 'trigonometry', 'geometry']"
2567931,Find the rates at which the volume V and the surface area S are changing with respect to time,"The dimensions of a rectangular box are linear functions of time, $l(t), w(t), h(t).$ If length and width are increasing at $2$ $in./sec$ and height is decreasing  at $3 \; in./sec$ . Find the rates at which the volume V and the surface area S are
changing with respect to time. If $l(0)=10$ and $w(0)=8$ and $h(0)=20$ . Is V increasing or decreasing when $t=5$ ? What about $S$ at $t=5$ My attempt :- $V = l(t)w(t)h(t) \Rightarrow \frac{dV}{dt} = \frac{dV}{dl} \frac{dl}{dt} + \frac{dV}{dw} \frac{dw}{dt} +\frac{dV}{dh} \frac{dh}{dt}= 2l(t)w(t) + 2l(t)h (t) -3l(t)w(t)$ ----> Equation 1 Similarly I can find it for the surface area. My problem here is how do I get $l(5), w(5)$ and $h(5)$ using: $l(0)=10$ and $w(0)=8$ and $h(0)=20$ ? Show I solve like this ? $\frac{dl}{dt} = 2 \Rightarrow l(t) = 2t + C \Rightarrow C = 10  \Rightarrow l(t) = 2t + 10 \Rightarrow l(5) = 20?$ and plug it in equation $1$ to get rate of change of volume at $t=5$ ? Please help me.","['multivariable-calculus', 'calculus']"
2567957,"Derivative of $f(x) = |x|^2 - 2\langle a, x \rangle$","Define the function $f\colon \mathbb{R}^n \to \mathbb{R}$ by $f(x) = |x|^2 - 2\langle a , x \rangle$ where $a \in \mathbb{R}^n$ is non-zero. We have: $$f(x + h) - f(x) = |x+h|^2 - 2\langle a, x + h\rangle - |x|^2 + 2\langle a, x\rangle \\
= |h|^2 - 2\langle x, h\rangle - 2\langle a, h\rangle$$ And thus we have $Df(x)(h) = -2\langle x, h\rangle -2\langle a, h\rangle$. The only critical point is $x = -a$, and given that $D^2f(x)(h, h) = -2|h|^2 < 0$, this critical point is a maxima. But now let's look at the particular case where $n = 2$ and $a = (1, 0)$. We have $f(x, y) = x^2 + y^2 - 2x$. It's derivative is given by: $$f'(x, y) = \begin{pmatrix}2x - 2 & 2y
\end{pmatrix}$$ This has a critical point at $x = 1$ and $y = 0$. Also, we have: $$f''(x, y) = \begin{pmatrix}2 & 0 \\ 0 & 2
\end{pmatrix}$$ This matrix is positive definite, so the critical point is actually a minima. What is wrong with the general case?","['derivatives', 'real-analysis', 'multivariable-calculus', 'maxima-minima', 'inner-products']"
2567972,"Find the general term of the sequence, starting with n=1","Find the general term of the sequence, starting with n=1, determine whether the sequence converges, and if so ﬁnd its limit. $$\frac{3}{2^2 - 1^2}, \frac{4}{3^2 - 2^2} , \frac{5}{4^2 - 3^2}, \cdots$$ Can you help me with this,I know how to solve the problem with n= 0 but is that different with n= 1?","['convergence-divergence', 'sequences-and-series', 'calculus', 'limits']"
2567987,"Do we adopt the term ""normed space"" which is over any ordered-field?","The definition of normed vector spaces , as far as I know, is only defined for vector space over $\Bbb R$ or $\Bbb C$, like this one: However, it seems no harm to talk about whether a vector space over a general ordered field forms a normed space. So do we adopt such situation? If not, why?","['functional-analysis', 'normed-spaces']"
2567988,proof of roots of characteristic polynomial are eigenvalues,How do I prove the 2 directions of this statement?,"['eigenvalues-eigenvectors', 'linear-algebra', 'linear-transformations']"
2567991,How to prove that an equivalence relation $E$ over a set $A$ satisfying $|A|^3=|A|$ will satisfy $|E|=|A|$?,"Given set $A$, $|A| = a$ and $a^{3} = a$. Let $E$ be an equivalence relation over $A.$ Prove that $|E| = a$ My Attempt - We know that there isn't any finite set $A$ such that $|A|^{3} = |A|$, therefore $A$ is an infinite set. By definition equivalence relation $E$ over and infinite set $A$ - $E$ is an equivalence relation $ \iff I_A \subseteq E$ (let $I_A$ be the identity relation over set $A$), and all equivalence relation $E$ over $A$ uphold $E \subseteq A \times A$ (that part am i not sure of). Therefore, $I_A \subseteq E \subseteq A \times A$, translating to cardinals of infinite sets - $a = |I_A| \le |E| \le |A \times A| = a$. $\Rightarrow |E| = a$ Am  i correct ? are my mathematical assumptions right ? Would love to hear your thoughts.","['equivalence-relations', 'cardinals', 'discrete-mathematics']"
2568009,What is $H_1(\operatorname{GL}_2(\mathbb{R}))$?,"I am trying to compute the cohomology groups of $\operatorname{GL}_2(\mathbb{R})$. I know that $\operatorname{GL}_2(\mathbb{R})$ has two connected components, so $H_0(\operatorname{GL}_2(\mathbb{R})) = \mathbb{R}^2$. Also, $\operatorname{GL}_2(\mathbb{R})$ is homotopically equivalent $O(2)$, the group of orthogonal matrices. Since $O(2)$ is 1 dimensional, this tells me that $H_k(\operatorname{GL}_2(\mathbb{R})) = 0$ for $k > 1$. But how do I compute $H_1(\operatorname{GL}_2(\mathbb{R})) = H_1(O(2))$?","['homology-cohomology', 'differential-geometry', 'lie-groups']"
2568029,A continuous root for $(z-a)(z-b)$,"Consider the function $f(z) = (z-a)(z-b)$ defined on $\Omega = \mathbb{C} - [a,b]$ where $a,b$ are different complex numbers. How can I show that it has a continuous square root on $\Omega$? In a previous part of this question I showed that this function doesn't have a continuous logarithm. In showing this I reasoned that for any real number $\alpha$, $arg_{\alpha}$, the inverse of $exp$ restricted to the set $S_\alpha = \{x + iy : y \in [\alpha, \alpha +2 \pi)\}$, cannot possibly be continuous on $\Omega$ because the image of $f$ must contain some spiral (in any open set actually), and hence points with any argument between $0$ and $2\pi$. However if the above is correct I have no hope in finding a branch for the square root to be continuous in. Can you assist me with these questions?","['logarithms', 'complex-analysis', 'roots']"
2568050,"If a seller sold half the amount and $\frac12$ a unit to each customer, and ended up selling the entire stock. How many units were sold?","The seller was asked how many cheese pieces he had sold. He replied: ""Today there were $4$ buyers, each buyer bought half of the remaining cheese pieces and half of one cheese."" As a result, all cheeses was sold.""
How many cheeses has been sold? All I got: $x$ - number of cheeses, $$x-\left({8 \over16}x+{1 \over64}x\right)-\left({4 \over16}x+{1 \over64}x\right)-\left({2 \over16}x+{1 \over64}x\right)-\left({1 \over16}x+{1 \over64}x\right)=0$$ But it doesn't seem right. Does anyone know how to solve this?",['algebra-precalculus']
2568064,Perfect square product among 17 integers,"Using pigeon hole principle prove that: a) among 17 positive integers solely consisting of prime factors 2,3,5,7 product of two of them is a perfect square b) among 49 positive integers solely consisting of prime factors 2,3,5,7 product of four of them is 4th power of a positive integer. Please judge my solution for part a: because we have more than 2 numbers and hence more than 2 different powers for each prime in each number,so certainly there are at least 2 odd or 2 even powers for each prime in 17 numbers,so the product of such numbers is certainly perfect square. By the way,I have no solution for part b.","['pigeonhole-principle', 'square-numbers', 'elementary-set-theory', 'combinatorics', 'discrete-mathematics']"
2568069,On a certain integral that involves a product of powers of logarithms.,"This is a follow-up question to the following questions: Evaluating $\int_0^1 \frac{\ln^m (1+x)\ln^n x}{x}\; dx$ for $m,n\in\mathbb{N}$ Closed form for ${\large\int}_0^1\frac{\ln^4(1+x)\ln x}x \, dx$ What is a closed form for ${\large\int}_0^1\frac{\ln^3(1+x)\,\ln^2x}xdx$? Let $p\ge 1$ and $q\ge 1$ be integers. We consider the following quantity:
\begin{equation}
{\mathfrak I}^{(p,q)}:= \int\limits_0^1 \frac{[\log(1+x)]^p}{x} [\log(x)]^q dx
\end{equation} By using the techniques developed in the questions above we computed the result for $p+q=5$. We have:
\begin{eqnarray}
{\mathfrak I}^{(5,0)} &=& -120 \text{Li}_6\left(\frac{1}{2}\right)-60 \text{Li}_4\left(\frac{1}{2}\right) \log ^2(2)-120 \text{Li}_5\left(\frac{1}{2}\right) \log (2)-\frac{35}{2} \zeta (3) \log ^3(2)+\frac{8 \pi ^6}{63}-\frac{5 \log
   ^6(2)}{3}+\frac{5}{4} \pi ^2 \log ^4(2)\\
{\mathfrak I}^{(4,1)} &=& -120 \text{Li}_6\left(\frac{1}{2}\right)-24 \text{Li}_4\left(\frac{1}{2}\right) \log ^2(2)-72 \text{Li}_5\left(\frac{1}{2}\right) \log (2)+12 \zeta (3)^2-3 \zeta (3) \log ^3(2)-2 \pi ^2 \zeta (3) \log (2)+\frac{3}{4} \zeta
   (5) \log (2)+\frac{26 \pi ^6}{315}-\frac{17 \log ^6(2)}{30}+\frac{1}{3} \pi ^2 \log ^4(2)-\frac{1}{60} \pi ^4 \log ^2(2)+24 {\bf H}^{(1)}_5(1/2) \\
{\mathfrak I}^{(3,2)} &=& -108 \text{Li}_6\left(\frac{1}{2}\right)-36 \text{Li}_5\left(\frac{1}{2}\right) \log (2)+12 \zeta (3)^2+6 \zeta (3) \log ^3(2)-3 \pi ^2 \zeta (3) \log (2)+\frac{9}{8} \zeta (5) \log (2)+\frac{143 \pi ^6}{2520}+\frac{3 \log
   ^6(2)}{20}-\frac{1}{4} \pi ^2 \log ^4(2)-\frac{1}{40} \pi ^4 \log ^2(2)+36 {\bf H}^{(1)}_5(1/2)\\
{\mathfrak I}^{(2,3)} &=& -72 \text{Li}_6\left(\frac{1}{2}\right)-8 \text{Li}_5\left(\frac{1}{2}\right) \log (8)+6 \zeta (3)^2+4 \zeta (3) \log ^3(2)-\pi ^2 \zeta (3) \log (4)+\frac{3}{4} \zeta (5) \log (2)+\frac{17 \pi ^6}{420}+\frac{\log
   ^6(2)}{10}-\frac{1}{6} \pi ^2 \log ^4(2)-\frac{1}{60} \pi ^4 \log ^2(2)+24 {\bf H}^{(1)}_5(1/2)\\
{\mathfrak I}^{(1,4)} &=& \frac{93}{4} \text{Li}_6\left(1\right)
\end{eqnarray} Here 
\begin{equation}
{\bf H}^{(p)}_q(x) := \sum\limits_{m=1}^\infty \frac{H_m^{(p)}}{m^q} x^m
\end{equation} Note that the term ${\bf H}^{(1)}_5(1/2)$ cannot be reduced to poly-logarithms only for the following reason. Clearly we have:
\begin{eqnarray}
&&{\bf H}^{(1)}_5(-1) = \int\limits_0^{-1} \frac{\log((-1)/t)^4}{(4)!}\cdot \frac{Li_1(t)}{t(1-t)} dt\\
&&\underbrace{=}_{u=\frac{t}{t-1}} \frac{1}{4!}\sum\limits_{p=0}^4 \binom{4}{p} (-1)^p \int\limits_0^{1/2} \frac{\log(u)^p \log(1-u)^{5-p}}{u} du\\&&=
-2 {\bf H}^{(1)}_5(1/2)+6 \text{Li}_6\left(\frac{1}{2}\right)-2 \text{Li}_4\left(\frac{1}{2}\right) \log ^2(2)+\text{Li}_4\left(\frac{1}{2}\right) \log (2) \log (4)+\text{Li}_5\left(\frac{1}{2}\right) \log (4)-\frac{\zeta (3)^2}{2}+\frac{1}{72} \pi
   ^2 \left(12 \zeta (3) \log (2)+\log ^4(2)\right)-\frac{1}{3} \zeta (3) \log ^3(2)-\frac{1}{16} \zeta (5) \log (2)-\frac{19 \pi ^6}{4320}-\frac{\log ^6(2)}{120}+\frac{1}{720} \pi ^4 \log ^2(2)
\end{eqnarray}
Since ${\bf H}^{(1)}_5(-1) = \zeta(-5,1)+Li_6(-1)$ and since it is known that $\zeta(-5,1)$ cannot be reduced to univariate zeta functions the same holds for ${\bf H}^{(1)}_5(1/2)$. To reiterate the quantity ${\bf H}^{(1)}_5(1/2)$ is not redundant in here. Now my question would be the usual one, meaning can we derive a closed-form expression for the quantity above for arbitary values of $p$ and $q$. From the results above we can see that some new quantity ${\bf H}^{(1)}_5(1/2)$ enters the result. Can this quantity be reduced to polylogarithms and elementary functions? If not then, for $p+q \ge 5$, what will be the minimal set of quantities that will appear in the result?","['special-functions', 'zeta-functions', 'euler-sums', 'integration']"
2568085,Reference for flag varieties G/P,"Is there a good reference for learning about flag varieties $G/P$? I'm already comfortable with the algebraic geometry and the example of Grassmannians, but I am not so comfortable with algebraic groups aside from basic Lie theory. For example, it would be nice to know which properties of the Grassmannian extend to more general $G/P$ (decomposition into Schubert cells, rules for intersecting classes, the Picard group and the Plücker embedding), so I know what sorts of arguments generalize cheaply and what arguments do not.","['reference-request', 'schubert-calculus', 'representation-theory', 'algebraic-geometry']"
2568103,In how many ways can $7$ white-suited and $5$ black-suited people be seated at a round table if none of the black-suited people are adjacent?,"In how many different arrangements can 7 white suited persons and 5 black suited persons sit in a round table of 12 seats so that none of the black suited persons gets to sit next to each other? The way I tried to approach this is by considering the possible arrangements of seating the black suited people and the white suited people as two groups. And for each of these arrangements the white suited guys can rearrange their positions in 7! ways and for each of those rearrangements the black suited guys can rearrange their positions in 5! ways. So, the number of total possible seating arrangements we get are $3\times7!\times5!$ Is this approach correct? Are there other better ways to approach the problem?","['permutations', 'combinatorics']"
2568147,Is the curve $ z = e^{i\theta}\left(\frac{7}{8} + \frac{1}{4} e^{6i\theta}\right) $ algebraic?,"Is this spirograph curve algebraic?  I an only write it in polar coordinates: $$ z = e^{i\theta}\left(\frac{7}{8} + \frac{1}{4} e^{6i\theta}\right) $$ and here is a picture.  It is a six-sided rose-shaped curve, a hypotrochoid . I read somewhere that all spirograph curves are algebraic, so this must be the solution of some polynomial equation $p(x,y) = 0$.  Then I could ask questions about this curve as a Riemann surface.","['algebraic-curves', 'riemann-surfaces', 'polar-coordinates', 'algebraic-geometry']"
2568157,Sums of $5$th and $7$th powers of natural numbers: $\sum\limits_{i=1}^n i^5+i^7=2\left( \sum\limits_{i=1}^ni\right)^4$?,"Consider the following: $$(1^5+2^5)+(1^7+2^7)=2(1+2)^4$$ $$(1^5+2^5+3^5)+(1^7+2^7+3^7)=2(1+2+3)^4$$ $$(1^5+2^5+3^5+4^5)+(1^7+2^7+3^7+4^7)=2(1+2+3+4)^4$$ In General is it true for further increase i.e., Is $$\sum_{i=1}^n i^5+i^7=2\left( \sum_{i=1}^ni\right)^4$$ true $\forall $ $n \in \mathbb{N}$","['sequences-and-series', 'perfect-powers', 'summation', 'power-series', 'elementary-number-theory']"
2568173,Proof by induction in trigonometry. [duplicate],"This question already has answers here : How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? (8 answers) Closed 6 years ago . Prove that $\cos x +\cos 2x + \cos 3x + ...+ \cos nx =\cos \left(\dfrac{n+1}{2}x\right) \sin \left(\dfrac{nx}{2}\right)\csc \dfrac{x}{2}$ Attempt: Clearly, $P(1)$ is true. Assume $P(m)$ is true. Thus,  $P(m+1) = (\cos x +\cos 2x + \cos 3x + ...+ \cos mx)+ \cos((m+1)x)$ $= \cos \left(\dfrac{m+1}{2}x\right) \sin \left(\dfrac{mx}{2}\right)\csc \dfrac{x}{2} + \cos((m+1)x) 
\\= \csc (\dfrac x 2)\left(\cos \left(\dfrac{m+1}{2}x\right) \sin \left(\dfrac{mx}{2}\right)+ (\cos(m+1)x)\sin (\dfrac x 2)\right)$ What do I do next?","['induction', 'proof-writing', 'trigonometry', 'trigonometric-series']"
2568197,Brutal gaussian integral of death $\int_{\mathbb{R}} x \Phi(x) \phi(Bx-b)$,"Ciao, I was making some computation and I've been stucked in this one. Let $B$ and $b$ be positive contant. We call $\phi(x)$ standard gaussian distribution and $\Phi(x)$ its cumulative function, i.e.
$$
\phi(x) = \frac{1}{\sqrt{2 \pi}}e^{-\frac{x^2}{2}}
$$
$$
\Phi(x) = \int_{-\infty}^x \phi(s) ds
$$ then compute $$
\int_{-\infty}^{+\infty}x\Phi(x)\phi(Bx - b) dx
$$ If it helps I can proove this result:
$$
\int_{-\infty}^{+\infty}x\Phi(x)\phi(x) dx = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty} e^{-x^2}= \frac{1}{\sqrt{2}}
$$ Any suggestion or hint will be appreciated,
thank you! Ciao AM","['provability', 'real-analysis', 'integration', 'calculus']"
2568300,Gauss-Bonnet Like Statement Connecting Parallel Transport and Curvature,"Let $M$ be a $2$-dimensional orientable Riemannian manifold and $p$ be a point in $M$.
Let $(U, \varphi)$ be a coordinate chart about $p$ such that $\text{Im}(\varphi)$ is a ball in $\mathbf R^2$.
Let $\gamma$ be a piecewise smooth simple loop based at a point $p$ in $M$ such that $\text{Im}(\gamma)$ is contained in $U$. I want to show that $\int_\Omega K\ dA \equiv \text{rot}_\gamma \pmod{2\pi}$ Here $K$ denotes the sectional curvature, $\Omega$ is the interior of $\gamma$, $dA$ is the Riemannian volume form, and $\text{rot}_\gamma$ is the rotation of $T_pM$ caused by parallel transport around the loop $\gamma$. The statement above is clearly true if $\gamma$ formed a geodesic triangles, for we can just apply the Gauss-Bonnet formula which states that the angle defect of the triangle is same as the integral $\int_\Omega K\ dA$. Similarly, one can prove this result if $\gamma$ was a geodesic polygon. From there perhaps one could try to argue by approximating an arbitrary $\gamma$ by geodesic polygons. But that seems inelegant to me.","['riemannian-geometry', 'differential-geometry', 'curvature']"
2568330,SDE for $e^\int$ expressions,"Consider the following processes:
$$X_t=e^{\int_0^t f(s,\omega)ds}$$
$$Y_t=e^{\int_0^t g(s,\omega)dB_s}$$
Assume $f$ and $g$ have whatever properties necessary to make this tractable, e.g. square integrable, etc. $B_t$ is standard 1D Brownian motion starting at the origin. I want to understand how to directly take the stochastic Ito differential of these. QUESTION: What are the stochastic differential equations for $dX_t$ and $dY_t$? Here is one attempt: $$d X_t=X_tf(t,\omega)dt
+X_t\left(\int_0^t f_{B_s}(s,\omega)ds\right)dB_t
+\frac12X_t\left(\int_0^t f_{B_sB_s}(s,\omega)ds\right)dt$$ $$d Y_t=Y_tg(t,\omega)dt
+Y_t g(t,\omega)dB_t
+\frac12Y_t g_{B_s}(t,\omega)dt$$ Of course, I am passing a derivative w.r.t. $B_t$ into the integral, and I am unsure about if that is ok here, or generally. Also, I thought about taking logs:
$$\log X_t=\int_0^t f(s,\omega)ds$$
So that 
$$d(\log X_t)=f(t,\omega)dt$$
but by the Ito formula it also is
$$d(\log X_t)=\frac{1}{X_t}dX_t-\frac12\frac{1}{X_t^2}(dX_t)^2.$$ The similar calculation with $Y_t$ gets me stuck in a similar situation. I'm not sure how to deal with the $(dX_t)^2$ here. I also tried integration by parts to no avail. I'm guessing there is a standard result or trick that can be applied or that I have some basic mistake here. Any help is appreciated.","['probability-theory', 'stochastic-integrals', 'brownian-motion', 'stochastic-calculus', 'stochastic-differential-equations']"
2568359,Identifying distinct colored cubes from faces of $2 \times 2 \times 2$ arrangement,"Note: The answer to Question 1 is ""never."" But Question 2 remains open! Consider cubes that can have their faces colored white or red, and let us say that two colorings of a cube are equivalent if one can be rotated to the other, and distinct otherwise. The number of distinct colorings for cubes that have at least one white face and at least one red face is $8$ (see post script for explanation). Suppose you have an arrangement of those distinct $8$ cubes into a larger, $2 \times 2 \times 2$ cube, and you can see all six of the larger cube's exposed faces. Question 1: Under what conditions can you tell, from the $2 \times 2 \times 2$ cube's exposed faces, how the original $8$ distinct cubes were arranged? Answer: This is never possible. For both questions: Although I would be quite pleased to see a ""pure mathematical"" approach, a [justified, reasoned] brute-force computation would be fine, too. Question 2: For any given ""view"" of the $2 \times 2 \times 2$ cube's six faces, there are multiple possible arrangements that could have yielded what one sees. So: What view maximizes the number of possible arrangements, and how many arrangements are there in this maximized scenario? Post Script. The number of possible cubes with one white face is clearly $1$; for two white faces, either they are adjacent or opposite, which yields $2$ in total; for three white faces, either they all meet at a corner or do not, which yields $2$ in total; for four white faces, it means two red faces, hence $2$ in total; and, for five white faces, it means one red face, hence $1$ in total. So, added up across all colorings of this nature, there are $1 + 2 + 2 + 2 + 1 = 8$ distinct colorings.","['problem-solving', 'combinatorics', 'recreational-mathematics', 'discrete-mathematics']"
2568360,Invariance of domain for smooth functions [duplicate],This question already has an answer here : Is there some elementary proof of invariance of domain? (1 answer) Closed 5 years ago . Let $f \colon U \to \mathbb R^n$ ($U \subset \mathbb R^n$ open) be of class $C^1$ and injective. Apparently there is an easy proof to show that $f(U)$ is open. In general it follows from the Invariance of domain theorem. Does someone know that proof?,['analysis']
2568361,Recovering Curvature Endomorphism out of Holonomy,"In $\S 3$ of this document the following is stated: Let $M$ be a $2$-dimensional Riemannian manifold and $R$ denote the curvature tensor. Let $p$ be a point in $M$ and $X_0, Y_0\in T_p M$ be linearly independent. Extend $X_0$ and $Y_0$ locally around $p$ to get commuting vector fields $X$ and $Y$. Thus $R(X, Y)= [\nabla_X, \nabla_Y]$, where $\nabla$ is the Levi-Civita connection.
For each $t>0$ small enough, let $\gamma_t$ be the loop formed by flowing for $\sqrt{t}$ time along $X$, then for $\sqrt{t}$ time along $Y$, then flowing for $\sqrt{t}$ time opposite to the flow of $X$, and lastly for $\sqrt{t}$ time opposite to the flow of $Y$. This actually gives a loop because $X$ and $Y$ are commuting. Then $R(X_0, Y_0) = \lim_{t\to 0}\frac{P_{\gamma_t}-I}{t}$ where $P_{\gamma_t}:T_pM\to T_pM$ is the parallel transport along $\gamma_t$. It is remarked in the document that this can be proved in a similar manner as one proves the Lie bracket of two vector fields is the Lie derivative of one with respect to the other. Since $X$ and $Y$ are commuting, we may assume that they are coordinate vector fields. But when trying to write down the coordinate expression for $[\nabla_X, \nabla_Y]$, I end up with a horrible mess featuring the Cristoffel coefficients and their derivatives. I am not able to see how to connect this to the parallel transport.","['holonomy', 'riemannian-geometry', 'differential-geometry', 'curvature']"
2568464,The proof of Holder's theorem for Gamma function(transcendentally transcendental),"Ι am doing a project about the Gamma Function defined on the complex plane (on an undergraduate level), and I want to write the main properties of this function. One that I want to is that gamma function is transcendentally transcendental, which means it does not satisfy any algebraic differential equation. This is a theorem proved by Holder. Where can i find a proof which fits to my undergraduate level? I've searched on the internet, and I found some articles such as 'A Survey of Transcendentally Transcendental Functions' from The American Mathematical Monthly Vol. 96  or 'Concerning transcendentally transcendental functions'from Mathematische Annalen Vol. 48, but they are far away from my purpose. I think the proof in 'Ueber die Eigenschaft der Gammafunction keiner algebraischen Differentialgleichung zu genügen' 'Band 28 Mathematische Annalen' is the best for me, but I cannot understand it because I don't know German. Also, I found one on Wikipedia, but I don't think that is as strictly as I want. I would appreciate any help.","['complex-analysis', 'ordinary-differential-equations', 'gamma-function']"
2568495,Solving PDE with Laplace transform,"Please help me to solve the following PDE with Laplace transform. In class we got less than 10 mins to study the topic (the semester ended and we were behind the schedule) and I am totally confused about how to handle/approach the problem. My texts do not show any relevant stuff for the problem. If fact I have only one sample and it confuses me a lot and explains nothing. I can solve ODEs and compute Laplace/inverse Laplace transforms well, so do not bother with it. Just please show me how to reduce the PDE problem to solving ODE and/or computations of (inverse)Laplace transform and I will be able to handle the rest. The problem: Find a (just one) solution of the equation:
 $$u_{xx}=u_{tt}, t>0, -\infty <x<+ \infty, u|_{t=0}=3x, u_t|_{t=0}=\sin 2x.$$ Thanks a lot for your help!","['laplace-transform', 'partial-differential-equations', 'calculus', 'ordinary-differential-equations', 'analysis']"
2568501,Measurable function satisfying $| \int_{E} fdx | \leq 1 $ for every Lebesgue-measurable set $E$ with $m(E) \leq 1 $ satisfies certain condition,"Let $f: \mathbb{R} \to \mathbb{R}$ be a measurable function satisfying $| \int_{E} fdx | \leq 1 $ for every Borel set $E$ with $m(E) \leq 1 $ . Prove that $$\lim_{n \to \infty} n m(\lbrace x \in \mathbb{R} : |f(x)| \geq n \rbrace) = 0.$$ $m$ is the standard Lebesgue measure. So this would be easy if the function were integrable, i.e. if $\int_{\mathbb{R}} fdx < +\infty$ , but this doesn't have to be the case, since for example $f(x) = \frac{1}{2}$ satisfies this condition. I've tried assuming the opposite, that there exists an $\varepsilon > 0$ and a subsequence $n_{k}$ such that $n_{k} m(\lbrace x \in \mathbb{R} : |f(x)| \geq n_{k} \rbrace) \geq \varepsilon$ for all $k \in \mathbb{N}$ . What I know is that this sequence of sets, $\{A_{k}\}_{k=1}^{\infty}$ , $A_{k} = n_{k} m(\lbrace x \in \mathbb{R} : |f(x)| \geq n_{k} \rbrace) \geq \varepsilon$ , is a decreasing (i.e. $A_{k+1} \subseteq A_{k}$ ) sequence, and that its limit is the empty set, so it would be nice if I could prove that $m(A_{k}) < +\infty$ for some $k$ so that I could apply continuity from below and conclude that $m(A_{k}) \to 0$ when $k \to \infty$ , but I can't even prove that. Also, I have no idea how to construct a contradiction using the given condition. Edit: Here's what I have so far: $$(\forall \alpha \in \mathbb{R})(\forall k \in \mathbb{N}) | \int_{\alpha}^{\alpha+k} fdx|<k;$$ From the opposite assumption, we have $$\int_{A_{k}} |f|dx \geq \varepsilon$$ for all $k \in \mathbb{N}$ .","['lebesgue-measure', 'measure-theory']"
2568540,Yang-Mills energy gap in dimension 2,"Let $(\Sigma,g)$ be a smooth genus $k$ closed oriented surface endowed with a Riemannian metric $g$. Let $P_\Sigma$ be a (necessarily) trivial $\mathrm{SU}(2)$-principal bundle over $\Sigma$. Let $\mathcal{A}_\Sigma$ be the space of connexions on $P_\Sigma$. Define $S:\mathcal{A}_\Sigma\to \mathbb R_{\geq 0}$ be the Yang-Mills functional $S(A):=\frac12\|F_A\|^2_{L^2}$ where $F_A\in \Omega^2(\Sigma;\mathrm{AdP}_\Sigma)$ is $A$'s curvature 2-form. It is well known that the critical set of $S$ is given by :
$$
\mathrm{crit}(S) = \{A\in \mathcal{A}_\Sigma | \delta_A F_A = 0\}
$$
where $\delta_A$ is the covariant codifferential (a.k.a $\mathrm{d}_A^*$ the $L^2$-adjoint of the covariant exterior derivative $\mathrm{d}_A$). Question : is there an $m\in \mathbb R_{>0}$ such that
$$
\mathrm{crit}(S) \cap \{A\in \mathcal{A}_\Sigma | 0<S(A)<m\} = \emptyset \qquad \text{?}
$$","['functional-analysis', 'gauge-theory', 'differential-geometry']"
2568545,Counting all $9 \times 8$ matrices with two restrictions (checking if I'm right),"I stumbled upon this problem today and I'm not 100% confident my approach is correct. The problem states: Count all $9 \times 8$ matrices that fulfill all three restrictions: 1) Every element in the matrix is either a 1 or a 0 2) Each Row and each Column of the matrix has at most one $1$ 3) The system of linear equations associated to the matrix has at most 3 free variables This was my approach: First, I interpreted the last condition by saying that $rank(A) = Nº$ of variables $- Nº$ of free variables. So I'm counting matrices that have rank 5, 6, 7 or 8 (max 8 because a 9x8 matrix is associated to a system of 8 variables) So I added disjoint cases: For a matrix of rank 8, I chose one row that would be empty (all zeroes): ${9 \choose 1}$. Now I have 8 ones to put in 8 rows and 8 columns. I can just line them up like an 8x8 identity and find the permutations I can get by moving the columns around: $8!$. So there's a total of $9!$ matrices of rank 8 For a matrix of rank 7, I now choose 2 rows and 1 column that must be empty, and then permute the non-empty columns. I get ${9 \choose 2}{8 \choose 1}7! = 4 \times 9!$ For rank 6 I do the same thinking process to get ${9 \choose 3}{8 \choose 2}6!$ And for rank 5 I get ${9 \choose 4}{8 \choose 3}5!$ So the total amount of matrices that fulfill all thre requirements is $5 \times 9! + {9 \choose 3}{8 \choose 2}6! + {9 \choose 4}{8 \choose 3}5! $ Is this correct? Is there another more ""amusing"" approach one could take?","['combinatorics', 'proof-verification', 'discrete-mathematics']"
2568549,Semimartingale characteristics for stochastic integral?,"I'm recently reading Limit Theorems for Stochastic Processes. A question came to my mind when going through the theory of Characteristics of Semimartingales in Ch. 2. How to figure out the characteristics for a general stochastic integral ? To be specific, Let $X$ be a $d$-dimensional semimartingale, with characteristics $(B,C,\nu)$ relative to a truncation function $h$, $H$ be a locally bounded predictable
  processes. Then it's well-known that, the stochastic integral $H\cdot X=\int_0^\cdot H_s dX_s$ is a semimartingale. The question is, what the characteristics of $H\cdot X$ look like? I cannot find it out within this book. Could anyone give some reference or comments? Appreciate!","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-analysis', 'stochastic-calculus']"
2568569,Almost complex structure on $\mathbb{S}^{3} \times \mathbb{S}^{5}$,"I would like to check, whether the product space $X = \mathbb{S}^{n} \times \mathbb{S}^{m}$ admits an almost complex structure for odd $m,n$. For example, if $m=1$ and $n=3$, then $X = \mathbb{S}^{1} \times \mathbb{S}^{3}$ -- in this case one can construct an almost complex structure as follows: (1) Since $\mathbb{S}^{k}$ is parallelizable for $k = 1, 3, 7$, there exist linearly independendent sections $e_{1}$, and $e_{1}', e_{2}', e_{3}'$ coresspondingly. By lifting up those vector fields to the globals sections of $T(\mathbb{S}^{1} \times \mathbb{S}^{3})$ we obtain a paralelization of the tangent bundle of a product. (2) Thus, we calculate the Lie bracket and seek for an endomorphism $J: T_{p}{(S^{1} \times S^{3})} \rightarrow T_{p}{(S^{1} \times S^{3})}$ of the tangent space that satisfies the $J^{2} = -I$. (3) Moreover, we can easily check the integrability condition in order to establish, whether the almost complex structure lifts to a complex one. Is it possible to deal with the general case somehow, i.e. that is not restricted by parallelization property?","['complex-geometry', 'almost-complex', 'differential-geometry']"
2568570,etale morphisms and equidimensionality,"Let $(R,m)\rightarrow (R',m')$ be a local ring map (of noetherian rings) which is étale local, namely it essentially of finite type, it is flat, $mR'=m'$ and the field extension $R/m\subset R'/m'$ is finite and separable. Which properties on $R$ ensure that $R'$ is equidimensional? 
For example, if $R$ is a domain, is it true that $R'$ is equidimensional?","['local-rings', 'algebraic-geometry', 'commutative-algebra']"
2568628,Rational canonical form of diagonal matrix,"I'm trying to determine the rational canonical form of a diagonal matrix 
$$
A=\begin{pmatrix}
a_1 & 0 & \cdots & 0\\
0 & a_2 & \cdots & 0\\
\vdots & \vdots & & \vdots\\
0 &0 & \cdots & a_n
\end{pmatrix}
$$ where the $a_i$'s are all different. If my intuition is correct, since the characteristic polynomial (in this case also the minimal polynomial) of $A$ is just the product $(x-a_1)\cdots(x-a_n)$ and all the factors are different we have that the $(x-a_i)$'s are the invariant factors of $A$. Then the rational canonical form of $A$ is again $A$. Is this correct? Is there a more formal way to work this problem? I'd appreciate any suggestions. Thanks in advance.","['abstract-algebra', 'free-modules', 'linear-algebra']"
2568629,Definition of smooth manifolds: What is the difference between differentiable structures and smooth structures?,We call an atlas smooth if each of its transition maps (or change of charts) is smooth (or $C^\infty$). A differential structure is a maximal smooth atlas. A smooth manifold is a topological manifold together with a smooth structure. These are the definitions of my lecture notes. I am also wondering now why we have not defined what a smooth structure is and if one has to replace smooth structure with differentiable structure instead. In Loring Tu's An Introduction to Manifolds it is also mentioned that it has to be a differentiable structure. But I tried to compare both definitions on Wikipedia and I can not really tell the crucial difference between these both terms. Both are somehow dealing with maximal atlases. Could you give me an explanation about the right definition about smooth manifolds? Thank you.,"['manifolds', 'smooth-manifolds', 'differential-geometry']"
2568633,Probability problem that involves number theory,"Let $k \in Z^+$. Assume integers 1, 2, 3, . . . , 3k+ 1 are written down randomly. Calculate the probability that at no time during this process, the sum of the integers is a positive integer divisible by 3? Attempt: I am trying to approach this by finding the complement of what's being asked which is the number times the sum of the integers is divisible by 3. The sample space I think is $\prod_{i = 0}^{3k+1}(3(i)+1)!$ since that's I think the number of trees we can generate by doing this process. I think my sample space is off. The right way is to
 figure out how many sequences can we have at some time i where $1 \leq i \leq 3k+1$ during the process. This is: $(3k+1) +(3K+1)(3k) + (3k+1)(3k)(3k-1)+ ... + (3k+1)!$ I also have the feeling that this is done by using states. There are just three state where the sum can be at any time and these are: 0mod3, 1mod3 and 2mod3. We have to find all the possible ways we can reach the state 0mod3 somehow.","['number-theory', 'probability']"
2568664,Stokes' theorem proof without FTC,To present time I have not found a proof of Stokes' Theorem for manifolds that does not involve the Fundamental Theorem of Calculus in some way. Is it possible to prove the general theorem without employing its famous special case? Or does it necessarily have to rely on the FTC?,"['stokes-theorem', 'integration', 'differential-geometry', 'manifolds-with-boundary']"
2568675,"If $f(\mathbb{R}) \subseteq \mathbb{Q}$, prove that $f$ is constant.","Let $f:\mathbb{R}\to \mathbb{R}$ is a function with $f(\mathbb{R})\subseteq \mathbb{Q}$ such that for every Cauchy sequence of rational numbers $(a_i)$, $\lim_{i\to \infty}f(a_i)$ exists. Prove that $f$ is constant. If I can prove that $f$ is continuous then I am able to do this problem, I am unable to prove the function is continuous. My try: Take $x\in \mathbb{R}$. Then there exists a sequence of rational nmber converging to that $x$, say $(x_n)$. After that can't think of what to do next.",['real-analysis']
2568690,Convergence or divergence of $a_n=\frac{(n-1)!^2 \cdot x^{2n-2}}{(2n-2)!}$,If $$a_n=\frac{(n-1)!^2 \cdot x^{2n-2}}{(2n-2)!}$$ where $x>0$ then find convergence or divergence my attempt: I applied d`alemberts ratio test i.e $$\frac{a_{n+1}}{a_{n}}=\frac{n!^2.x^{2}}{(2n)!}.\frac{(2n-2)!}{(n-1)!^2}=\frac{n^2.(n-1)!^2}{(2n).(2(n-1))!}.\frac{(2n-2)!}{(n-1)!^2}.x^2=\frac{n^2 \cdot x^{2}}{2n}=\frac{n \cdot x^{2}}{2}$$ so $$\lim_{n\to\infty}=\infty$$ diverge for all value of $x>0$. But actual answer is convergent for $$x^2<4$$ else diverge. please point out my mistake,"['limits', 'sequences-and-series', 'calculus', 'convergence-divergence', 'power-series']"
2568696,"Value of a determinant involving logarithmic, algebraic and trigonometric functions","If $D(x) = \begin{vmatrix}
x&(1+x^2)&x^3\\
\log(1+x^2)&e^x&\sin(x)\\
\cos(x)&\tan(x)&\sin^2(x)\\
\end{vmatrix}$, then
find the correct option. (a) $D(x)$ is divisible by $x$ (b) $D(x) = 0$ (c) $\frac{d}{dx}D(x) = 0$ (d) None of these I just found that the correct option is (a). My attempt: Elaborate expansion of the given determinant is not helping towards the solution. I wonder if there is an elegant way to solve this question. Any hint would be very helpful.","['derivatives', 'determinant']"
2568729,Why are pivot columns the basis of A?,"Why is it that when we determine the pivot columns of an m x n matrix $A$, the pivot columns form a basis for the $Range(A)$? I understand that the pivot columns are linearly independent (the reason why we chose them as the pivot columns), but how do we know that they also span the range of $A$? Also, why is that we're choosing the columns of $A$ to be the vectors that form a basis for $Range(A)$ rather than the columns of $U = rref(A)$?",['linear-algebra']
2568738,Example for a continuous function that has directional derivative at every point but not differentiable at the origin,"Can we find a function $f:\mathbb R^n\to\mathbb R$ that such that $f$ is continuous and $\partial_v f(p)$ exists for all $p\in\mathbb R^n$ and $v\in\mathbb R^n$. But $f$ is not differentiable at $0$? Is such function $f$ exists? Here give a example that has directional derivative everywhere, but it's not continuous at the origin.","['derivatives', 'real-analysis', 'analysis']"
2568770,"What's the difference between ""quadrature"" and ""integration""?","What is the difference between the terms ""quadrature"" and ""integration""? From what I gather, ""quadrature"" is the more archaic term for ""integration,"" but I see ""quadrature"" used frequently in the study of differential equations for when one can solve a differential equation by integration (cf. the phrase: ""can be integrated by quadrature""). I've also seen ""quadrature"" used as a shorthand for ""to integrate numerically."" Is that what's meant by ""quadrature"" most frequently today?","['terminology', 'integration', 'ordinary-differential-equations']"
2568807,square root of covariance of two variables,"I know that if you calculate variance, you can square root it to get the standard deviation. What does it mean / what is it called if you square root a scalar value which is the covariance of two variables?",['statistics']
2568866,Bijection between perfect matchings permutations with even cycles,"It is possible to proof that the number of perfect matching on a set of $2n$ elements is $n!!$, and on the other hand, it is also possible to proof that the number of permutations $\varphi$ of a set of $2n$ elements with the property that every cycle of $\varphi$ has even length is $(n!!)^2$. This implies that there exists a bijection between the aforementioned set and the pair of perfect matching. I wonder if someone has a nice interpretation for this bijection; meaning, how can we prove this constructing the bijection directly. Thanks!","['combinatorics', 'combinatorial-species', 'combinatorial-proofs']"
2568876,Null Space and Orthogonal Complement,"I'm having trouble understanding in a mathematical sense the reason why: (1) $$Null(A) = [R(A^{T})]^\perp $$ (2) $$Null(A^T) = [R(A)]^\perp$$ What I've tried so far is picking some arbitrary vector $\vec{v}$ in $[R(A^{T})]^\perp$ . Picking some arbitrary vector $\vec{y}$ in $R(A^T)$, we then have the relation that $<\vec{v}, \vec{y}> = 0$ if (1) is true. We can rewrite $\vec{y}$ as $A\vec{x}$ and subsitute that into the equation. This gives us: $$<\vec{v}, A\vec{x}> = 0$$ Which can be rewritten as: $$\vec{v}^T A\vec{x} = 0$$
$$[\vec{v}^T (A\vec{x})]^T = 0$$ since the LHS of the equation is just a 1x1 matrix. $$ (A\vec{x})^T \vec{v} = 0$$
$$ \vec{x}^T A^T \vec{v} = 0$$ Finally, we simplify to: $$<\vec{x}, A^T \vec{v}> = 0$$ which doesn't seem to help. How do I show that (1) and (2) are true?","['orthogonality', 'linear-algebra', 'linear-transformations']"
2568894,A problem on estimability of parameters.,"Let $Y_1,Y_2,Y_3$ and $Y_4$ be four random variables such that $E(Y_1)=\theta_1-\theta_3;\space\space E(Y_2)=\theta_1+\theta_2-\theta_3;\space\space E(Y_3)=\theta_1-\theta_3;\space\space E(Y_4)=\theta_1-\theta_2-\theta_3$, where $\theta_1,\theta_2,\theta_3$ are unknown parameters. Also assume that $Var(Y_i)=\sigma^2$, $i=1,2,3,4.$ Then which one is true? A. $\theta_1,\theta_2,\theta_3$ are estimable. B. $\theta_1+\theta_3$ is estimable. C. $\theta_1-\theta_3$ is estimable and $\dfrac{1}{2}(Y_1+Y_3)$ is the best linear unbiased estimate of $\theta_1-\theta_3$. D. $\theta_2$ is estimable. The answer is given is C which looks strange to me (because I got D). Why I got D? Since, $E(Y_2-Y_4)=2\theta_2$. Why I don't understand that C could be an answer? Ok, I can see, $\dfrac{Y_1+Y_2+Y_3+Y_4}{4}$ is an unbiased estimator of $\theta_1-\theta_3$, and its' variance is less than $\dfrac{Y_1+Y_3}{2}$. Please tell me where am I doing wrong. Any help appreciated. Thanks! Also posted here: https://stats.stackexchange.com/questions/319117/a-problem-on-estimability-of-parameters I recently reviewed the question and their is nothing written about $Y_i$'s being uncorrelated. So, please assume that $Y_i$'s are uncorrelated. Please!","['statistics', 'estimation']"
2568911,Integral involving $\phi$,$$\int_{0}^{\pi/2}\arctan\left({2\over \cos^2{x}}\right)\mathrm dx=\pi\arctan\left({1\over \sqrt{\phi}}\right)\tag1$$ $\phi$ is the golden ratio $2\sec^2{x}=2\tan^2{x}+2$ $u=\sec^2{x}$ then $\mathrm du=2{\tan{x}\over \cos^2{x}}\mathrm dx$ $$\int{\cos^2{x}\over \tan{x}}\arctan\left({2\over u}\right)\mathrm du\tag2$$ $$\int{1\over u\sqrt{u-1}}\arctan\left({2\over u}\right)\mathrm du\tag3$$ Not so sure what is next step... How do we show that $(1)=\pi\arctan\left({1\over \sqrt{\phi}}\right)$,['integration']
2568918,Give an example of a smooth distribution $D$ of dimension 1 which is not globally generated by only one vector field.,"The question is as follows: Give an example of a smooth distribution $D$ of dimension 1 which is not
globally generated by only one vector field. $\textbf{Some definitions:}$ The easiest way to introduce the notion of distribution $\Delta$ on a manifold $N$ is to consider a mapping assigning to each point $p$ of $N$ a subspace $\Delta(p)$ of the tangent space $T_pN$ to $N$ at $p$. Now if we assume for each point $p$ of $N$ there exist a neighborhood $U$ of $p$ and a set of smooth vector fields defined on $U$, denoted $\{ \tau_i \mid i \in I \}$, with the property that $\Delta(q) = \{ \tau_i(q): i \in I \}$ for all $q \in U$. Such an object will be called a smooth distribution on $N$. I do not know what  ""globally generated by only one vector field"" means? Can someone help me to understand this and to give me an example? Thanks!","['manifolds', 'smooth-manifolds', 'differential-geometry']"
2568920,How can I calculate $\lim_{x \to 0}\frac {\cos x- \sqrt {\cos 2x}×\sqrt[3] {\cos 3x}}{x^2}$ without L'Hôpital's rule?,How can I calculate following limit without L'Hôpital's rule $$\lim_{x \to 0}\frac {\cos x- \sqrt {\cos 2x}×\sqrt[3] {\cos 3x}}{x^2}$$ I tried L'Hôpital's rule and I found the result $2$.,"['radicals', 'limits', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2568923,"Suppose we want to make $|x^2 \sin(1/x)| < \varepsilon$ where $\varepsilon > 1$, why does it not suffice that $|x| < \varepsilon$?","I was reading Spivak's Calculus and came across this ( Spivak's Calculus Chapter 5 ) I'm confused because $f(x) = x^2 \sin(\frac{1}{x})$ has the following property: $|f(x)| < |x|$ for all $x ∈ \Bbb{R}$. If we set $|x| < \varepsilon$, then $|f(x)| < |x| < \varepsilon$ therefore $|f(x)| < \varepsilon$. Shouldn't it then suffice to set $|x| < \varepsilon$ if we want to make $|x^2 \sin(\frac{1}{x})| < \varepsilon$?","['real-analysis', 'calculus', 'limits']"
2568928,Geometric interpretation of forking and non-forking extensions in ACF; Concrete examples involve non geometrically irreducible varieties?,"Suppose $A\subseteq B\subseteq L$ for an algebraically closed field $L$. Make the identification of the model-theoretic type space $S_n(A)=SpecK[A][X_1,...,X_n]=\mathbb A^n_{K[A]}$ as the scheme theoretic affine space where $K[A]$ is the field generated by $A$ and similarly so for $B$. I wish to understand the meaning of nonforking and forking extensions in this language. I think I reduced the illustration to an analysis about varieties which are irreducible but not geometrically irreducible, and finding components in a base change which have strictly smaller degree, but am not sure. Algebraic geometry question (also see a more precise version below): Can someone give me an example of such a phenomena? Model theory question: Is this a correct and complete description? Given a type $p\in S_n(A)$, we can consider $p$ as an irreducible affine subvariety $X$. An extension of types $p\subseteq q$ where $q\in S_n(B)$ then corresponds to a pre-image $Y$ of $X$ under the morphism $\mathbb A_{K[B]}^n\rightarrow \mathbb A_{K[A]}^n$ induced by the inclusion $K[A]\hookrightarrow K[B]$.This means to take $X$ in $\mathbb A^n_{K[A]}$ and consider the larger set of points in $\mathbb A^n_{K[B]}$ and $Y$ is an irreducible component of that larger set of points. It is a theorem that Morley rank equals the geometric (and Krull) dimension in $ACF$. So I guess for $q$ to be a nonforking extension of $p$, this means $Y$ has the same dimension as $X$. So in order for there to be interesting example of both forking and non-forking extensions of $p$, the base change of $X$ to an algebraic closure must contain many irreducible component, of many different dimensions. Can someone give me an example of such a variety? Furthermore, it is a theorem that types have unique non-forking extensions. That means there is a unique $Y$ of same dimension as $X$. How to identify this $Y$? Precise geometry question: I am looking for an irreducible variety $X$ such that the base change to some field extension $Y$ is no longer irreducible, and contains components of many different dimensions. Furthermore (at least under certain conditions, see paragraph below), it seems like there must be a unique component of $Y$ of maximal dimension, equal to that of $X$. How to find the $Y$? But I seem to find some contradiction when considering a basic example. The Morley rank of $q$ is supposed to be bounded by the Morley rank of $p$. Specifically, take $A=\mathbb R$ and $B=\mathbb C$ and $X$ to be any variety without real points but having complex points, for example the curve $x^2+y^2=-1$. Then it is not even true that $\dim(Y)\leq \dim(X)$. But perhaps this is just due to some technical problem about the real points being empty? Reference on Forking: I used the definitions and facts from David Marker's book 'An introduction to Model theory'. But here is an article on the subject (albeit it does not list all the required theorems): http://modeltheory.wikia.com/wiki/Forking","['model-theory', 'affine-varieties', 'algebraic-geometry']"
2568931,"Help With Proof of Theorem 1.A. in ""Topics in Algebra""","Here is a statement of the theorem. I am attempting to prove the part starting from ""Conversely..."". The distinct equivalence classes of an equivalence relation on A provide us with a decomposition of A as a union of mutually disjoint subsets. Conversely, given a decomposition of A as a union of mutually disjoint, nonempty subsets, we can define an equivalence relation on A for which these subsets are the distinct equivalence classes. I found a similar thread discussing the problem, but it did not exactly answer the question I had: Proof of theorem about equivalence classes So far, I have proved that the binary relation, $\sim$ defined by $x \sim y$ if and only if $x, y \in A_{\alpha}$, is an equivalence relation where $A_{\alpha}$ is an element of my paritions. Whenever I tried to prove that the set of equivalence classes are the $A_{\alpha}$'s, I got a bit stuck. My thoughts so far are to fix an element, $i$, in my indexing set and choose an $x \in A_i$. Then $x \sim x$, so $x \in [x]$. Conversely, if $x \in [x]$, then I must prove that  $x \in A_i$. All I know so far is that $x \in A_j$ for some $j$ in my indexing set. I don't really know how to prove that $A_j = A_i$.","['abstract-algebra', 'equivalence-relations', 'elementary-set-theory']"
2568941,Can be iteratedly integrate w.r.t. all direction $\Rightarrow$ integrable?,"Let $f:[0,1]\times[0,1]\to\Bbb R$ be bounded. Suppose $\int_0^1(\int_0^1 f(x,y)dy)dx$ and $\int_0^1(\int_0^1 f(x,y)dx)dy$ are all exist and equal. Then is $f$ Riemann integrable on $[0,1]\times [0,1]$? I tried to use Fubini's theorem, but the condition of that theroem doesn't suit in this case. Can I avoid digging into $\epsilon-\delta$ proofs?","['real-analysis', 'integration', 'analysis']"
2568947,Dealing with dependent random variables using Measure Theory,"$\newcommand{\E}{\mathbb{E}} \newcommand{\PM}{\mathbb{P}}$
This question is inspired by this question where the user asks how to prove that $\E[XI_E]=0$ if $X$ is integrable and $E$ has zero probability measure. It already has an answer, but I was thinking about something alternative, but I was not sure about it. Here I will share my process of thoughts. First Thoughts. First I thought that the proof was easy because they are either independent or dependent. If they are independent it is trivial. If they are dependent then we must have them both in the same probability space $(\Omega,\mathcal F, \PM)$ hence:
\begin{align}\tag{1}
\E[XI_E]=\int_\Omega XI_E\, d\PM = \int_E X\,d\PM = 0
\end{align}
Because integrating over a null set gives zero. Second Thoughts. It cannot be that easy. The case I have written above when they are dependent is when they are fully dependent. So they can be either fully dependent and not fully dependent. For the second case we have them in seperate probability spaces $X$ in $(\Omega_1, \mathcal F _1,\PM_1)$ and $I_E$ in $(\Omega_2, \mathcal F_2, \PM_2)$. Note that these two probability spaces can be identical. We also have the product probability space $(\Omega_1\times \Omega_2 , \mathcal F_1\otimes \mathcal F_2, \PM)$. But then we have:
\begin{align}
\E[XI_E] = \iint_{\Omega_1\times\Omega_2} X(\omega_1)I_E(\omega_2)\, d\PM(\omega_1,\omega_2) =\iint_{\Omega_1\times\Omega_2} XI_E\,d\PM
\end{align}
This can be dealt with simple functions ($\star$). Question. Are my thoughts good? Especially the fully dependency case and not fully dependency case. If what I have written is wrong, how can I deal with dependent random variables using Measure Theory in this case ? (General case is also welcome of course!) Elaboration of $(\star)$ for the case my thoughts are good. There exists a simple function $Y_n$ that converges monotone increasing pointwise to $Y=|X|$. For a simple function we have: $Y_n = \sum_{i=1}^N a_iI_{A_i}$ and hence:
\begin{align}
\iint_{\Omega_1\times\Omega_2} Y_n I_E \,d\PM = \sum_{i=1}^Na_i\PM(A_i\times E)
\end{align}
We have $\PM(A_i\times E)\leq \PM(\Omega_1\times E) = \PM_2(E)=0$. So:
\begin{align}
\iint_{\Omega_1\times\Omega_2} Y_n I_E \,d\PM = 0 \ \ \ \forall_{n\in\mathbb{N}}
\end{align}
And the claim follows by MCT. Edit. I followed the suggestion of @Did, namely to grab the book and read it. I see where I went wrong.  In my lecture notes when discussing independency we had two random variables $X:(\Omega,\mathcal F)\to (\Omega_1,\mathcal F_1)$ and $Y:(\Omega,\mathcal F)\to (\Omega_2,\mathcal F_2)$. I was messing up with the domain and the target space. The domain is always the same when talking abot the components of a random vector, but the targer may differ. But now everything is indeed easy since we can write equation (1) aaaand we are done.","['probability-theory', 'measurable-functions', 'measure-theory', 'random-variables']"
2568958,${A_1}^k + {A_2}^k + \cdots +{A_n}^k = 0$ for all $k \in \mathbb N_{>0}$ $\implies$ $A_i$ are all nilpotent.,"Does the following statement hold true? Given $n$ real matrices $A_1, A_2, \cdots A_n$, if their $k$-th power sum is zero for all $k \in \mathbb N_{>0}$ then they are all nilpotent. Given $n$ real variables $x_1, x_2, \cdots x_n$, if their $k$-th power sum is zero for all $k \in \mathbb N_{>0}$ then they are all identical to zero. This can be shown by gathering up the same values and using the well known fact that the Vandermonte matrix is invertible. I tried the same method. The entry ${x_i}^j$ turns into ${A_i}^j \otimes I$ so the determinant is given by the product of ${(\det(A_i -A_j))}^n$ which is not necessarily nonzero. I got stuck here.","['matrices', 'linear-algebra']"
2568997,Show that smooth distribution $D$ of dimension 2 is not globally generated by only two vector field.,"The question is as follows: In $M = \mathbb{R}^3-\{0\}$ consider the vector fields $X$, $Y$ and $Z$ as follows
$$X = z \frac{\partial}{\partial y} - y \frac{\partial}{\partial z}, ~~~~ ~~~~ ~~~ 
 Y = x \frac{\partial}{\partial z} - z \frac{\partial}{\partial x}, ~~~~ ~~~~ ~~~ ~~ Z = y \frac{\partial}{\partial x} - x \frac{\partial}{\partial y}$$
Then the matrix whose columns are the components of the vector fields $X$, $Y$ and $Z$ relative to the usual coordinates $(x,y,z)$ of $\mathbb{R}^3$ is: $$\begin{pmatrix} 
0 & -z & y \\
z & 0 & -x \\
-y & x & 0
\end{pmatrix}$$
and has rank 2 everywhere. Hence, we have the 2-dimensional distribution
$D = \left<X, Y,Z\right>$. Now the question is to show that this distribution is not
globally generated by only 2 vector fields. Any hint on how to show this will be appreciated a lot! Also there is a similar question about one dimensional distribution here link to the result Thanks!","['manifolds', 'smooth-manifolds', 'differential-geometry']"
2569014,Union and intersection of two different relations,"Let's say I have a relation $\mathcal{R}$ that is equivalence (reflexive, transitive and symmetrical) and relation $\mathcal{S}$ that is partial order (reflexive, transitive and antisymmetrical). How can I find out what does their union $(\mathcal{R}∪S)$ and their intersection $(\mathcal{R}\cap \mathcal{S})$ will be like? I.e. whether it also must be symmetrical, reflexive (etc.) or not?","['equivalence-relations', 'relations', 'discrete-mathematics']"
2569022,Prove convergence / divergence of $\sum_{n=2}^\infty(-1)^n\frac {\sqrt n}{(-1)^n+\sqrt n}\sin\left(\frac {1}{\sqrt n}\right)$,"How can I prove or disprove the following series converges? $$\sum_{n=2}^\infty(-1)^n\cfrac {\sqrt n}{(-1)^n+\sqrt n}\sin\left(\frac {1}{\sqrt n}\right)$$ I tried several things, none of which worked. I wanted to use Abel's test or Dirichlet's test. I know that $\sin(\frac {1}{\sqrt n})$ is monotonically decreasing to $0$, but I wasn't able to show that $\Sigma_{n=2}^\infty(-1)^n\frac {\sqrt n}{(-1)^n+\sqrt n}$ is convergent, as it does not converge absolutely since $\frac {\sqrt n}{(-1)^n+\sqrt n}$ converges to 1. Neither was I able to show that the partial sum sequence of $\frac {\sqrt n}{(-1)^n+\sqrt n}$ is bounded. I'm at a loss. Would love any help. Note - This exact question was discussed here a few years ago, but was not answered then and the hint provided in the responses was not useful.","['real-analysis', 'sequences-and-series', 'calculus']"
2569034,Parallel Transport Along Nearby Curves Produces Nearby Vectors,"Let $(M, g)$ be a Riemannian manifold and $d$ denote the Riemannian distance function on $M$. Let $p$ and $q$ be two points on $M$ and $X$ be a vector in $T_pM$. Let $C$ be the set of all the smooth paths defined on the unit interval joining $p$ to $q$. Define a metric $D:C\times C\to \mathbf R_{\geq 0}$ on $C$ as
$$D(\gamma, \eta) = \sup_{t\in I} d(\gamma(t), \eta(t))$$ For $\gamma\in C$, let $P_\gamma:T_pM\to T_qM$ denote the parallel transport map corresponding to $\gamma$. I want to show the following: The map $C\to T_qM$ defined as $\gamma\mapsto P_\gamma X$ is continuous. In other words, if two paths in $C$ are nearby, then the resulting vectors got by parallel transporting along them gives two vectors which are also nearby. I wanted to apply the result I am trying to prove here . If $\gamma$ and $\eta$ are two curves in $C$ which do not intersect and are contained in a single chart, then it seems intuitively obvious that the area enclosed between $\gamma$ and $\eta$ is small, and the result just alluded may be applicable. But of course, $\gamma$ and $\eta$ can intersect badly.","['riemannian-geometry', 'differential-geometry']"
2569057,Meager set of number in base $2$,"For each real $x \in (0,1]$ let $(d_n(x))_{n\ge 1}$ be its unique binary expansion with infinitely many $1$, i.e.,
$$
x=\sum_{n\ge 1}\frac{d_n(x)}{2^n}.
$$ Question. Is it true that the set
  $$
\left\{x \in (0,1]: s(x)=\sum_{n:\, d_{2n}(x)=1}\frac{1}{n} \le 1\right\}
$$
  is meager?","['functional-analysis', 'binary', 'general-topology', 'baire-category']"
2569123,Prove that 2 lines intersect on the circumference,"I have a geometry problem that asks to prove that 2 lines intersect on the circumference of a circle. It goes like this: There are 2 circles, $O_1$ and $O_2$with centres $A$ and $B$ respectively, with the $A$ lying on the circumference of $O_2$. A point $P$ is chosen on $O_2$ so that it isn't in $O_1$. A line tangent to $O_1$ through $P$ meet $O_1$ at $S$, and it intersects $O_2$ again in $Q,$ with $Q$ and $P$ lying on the same side of $AB$. A line through $Q$ is tangent to $O_1$ again at $T$. A point $M$ is the foot of the perpendicular from $P$ to $AB$. Prove that $MT$ intersects $PS$ at $S$. I tried to use tan-chord theorem and joining the intersections of $O_1$ and $O_2$ and joining $A$ and $B$ with the points of tangency, and then finding equal angles using isosceles triangles, but I couldn't get anywhere from there. Is there a general way to prove that 2 lines intersect each other on the circumference?","['contest-math', 'geometry']"
2569145,How do I know when to use the Law of total probability?,"I am studying Probability Theory 1, and we have learned the Law of total probability and proved it. I know the theoretical intuition behind it and I know why it makes sense from it's proof. But when I see a new problem (that they solved it using this method) I just can't relate it to this law. Can you guide me of how and when should I use it, and what kind of problems can be solved using this theorem? I would like some simple example illustrating it's usage.",['probability']
2569180,Arclength Parameterization of the Trefoil Knot,"I would like to find an arclength parameterization of the trefoil knot The parameterizations I can find are: $(sin(t) + 2sin(2t),$ $cos(t) - 2cos(2t),$ $sin(3t))$ and $((2+cos(3t))cos(2t),$ $(2+cos(3t))sin(2t),$ $sin(3t))$ for $t \in [0,2\pi)$ writing $t = t(\theta)$, the magnitude of the derivatives wrt. $\theta$ of these two parameterizations are: $| \frac{d}{d\theta}  (sin(t) + 2sin(2t),$ $cos(t) - 2cos(2t),$ $sin(3t)) |$ = $| (cos(t) + 4cos(2t),$ $-sin(t) + 4cos(2t),$ $3cos(3t))\frac{dt}{d\theta} |$ = $\sqrt{cos^2(t) + sin^2(t) + 16[cos^2(2t) + sin^2(2t)] + 8[cos(t)cos(2t) - sin(t)sin(2t)] + 9cos^2(3t)}\frac{dt}{d\theta}$ = $\sqrt{17 + 8cos(3t) + 9cos^2(3t)}\frac{dt}{d\theta}$ and similarly $|\frac{d}{d\theta}((2+cos(3t))cos(2t),$ $(2+cos(3t))sin(2t),$ $sin(3t))|$ = $\sqrt{25 + 16cos(3t) + 4cos^2(3t)}\frac{dt}{d\theta}$ I need a solution to, for example $\int \sqrt{17 + 8cos(3t) + 9cos^2(3t)}dt$ so that I can get $t$ in terms of $\theta$ Wolfram alpha doesn't like either of these integrals, and I can see no way to solve them. There are two types of answers to this question: one would solve one of these integrals, another would tell me how to change the parameterization, reasonably, so that the integral, and the obtained formula for t, is solvable. I guess the third is to tell me that this question isn't solvable like this. My thoughts on the latter: Below, I make the integral solvable by changing the parameterization, but I can't solve for $t(\theta)$ The freedom in the parameterizations can be expressed as: $(sin(t) + Asin(2t),$ $cos(t) - Acos(2t),$ $Bsin(3t))$ where $A > 1$ and $B > 0$ which gives integrand: $\sqrt{1 + 4A^2 + 4Acos(3t) + 9B^2cos^2(3t)}$ To eliminate the $\sqrt{}$ we want some factorization: $(1 + 4A^2 + 4Acos(3t) + 9B^2cos^2(3t)) = (3Bcos(3t) + \lambda)^2$ where $\lambda^2 = 1 + 4A^2$ and $6B\lambda = 4A$ so $\lambda = \frac{2A}{3B} $ so $\frac{4A^2}{9B^2} = 1 + 4A^2$ ie. $4A^2\frac{9B^2 - 1}{9B^2} = -1$ or $4A^2 = \frac{9B^2}{1 - 9B^2} > 4$ so $9B^2 > 4/5$ and I will choose $9B^2 = 9/10$ giving: $B = \frac{1}{\sqrt{10}}$ $A = 3/2$ $\lambda = \sqrt{10}$ ie. the trefoil $(sin(t) + \frac{3}{2}sin(2t),$ $cos(t) - \frac{3}{2}cos(2t),$ $\frac{1}{\sqrt{10}}sin(3t))$ has arclength parameterization given by $t(\theta)$ where: $\int (\frac{3}{\sqrt{10}} cos(3t) + \sqrt{10}) dt = \theta$ $\frac{sin(3t)}{\sqrt{10}} + t\sqrt{10} = \theta$ But I want $t$ in terms of $\theta$","['knot-theory', 'parametrization', 'differential-geometry']"
2569217,Is predicate logic an extension of propositional logic?,"As I read in this thread , the difference between propositional and predicate logic is that in predicate logic you can use things like quantifiers, predicates and functions whereas in propositional logic you cannot. However, you can use things like letters, $\wedge$, $\vee$, $\neg$ in both propositional and predicate logic. Does this mean that everything we can use in propositional logic we can use in predicate logic? In other words, propositional logic $\subset$ predicate logic?","['propositional-calculus', 'predicate-logic', 'logic', 'discrete-mathematics']"
2569288,How many zeroes does the function $ f(x)=\exp(x)-3x^2$ have in $\mathbb{R}$?,"My try: Attempt (1):  $f(x)=0$, which gives $\exp(x)=3x^2$.
Since $\exp(x)$ and $3x^2$ intersect at exactly two points, therefore the function has two zeros. Attempt (2): I traced $f(x)=\exp(x)-3x^2$ which cuts the $X$-axis at three points, therefore $f(x)$ has three zeros. Which one is wrong? I need help.","['algebra-precalculus', 'calculus']"
2569341,What does 2 to the power x mean in set theory,In a mathematics assignments i encounter the following statement: We have a finite collection of combinatorial objects $S \subseteq 2^x$ (For example matchings or spanning trees) What does this notation $S \subseteq 2^x$ mean (Especially the $2^x$ part)?,"['combinatorics', 'notation', 'elementary-set-theory', 'matching-theory']"
2569373,Solve $\lim_{x\to 0} (\ln (x+e))^{\cot x}$ without l'Hôpital,"$$\lim_{x\to 0}  (\ln (x+e))^{\cot x}$$ Since we have an indeterminate form of $1^{\infty }$, we should simplify in a way that we can transform the expression into e to the power of something, but I can't find a way. The use of l'Hôpital's rule or series is prohibited.","['limits-without-lhopital', 'limits']"
2569423,"Comparaison of two version of Fractional sobolev spaces: what do we have $W^{s,p}(\mathbb{R}^{n})=H^{s,p}(\mathbb{R}^{n})$?","There are two version of Fractional sobolev spaces . Definition1: (Via Galiardo semi-norm) Let $1\leq p\leq +\infty$, $0<s<1$ and $\Omega\subseteq \mathbb{R}^n$ an open set. The fractional Sobolev space $W^{s,p}(\Omega)$ is defined to be $$ W^{s,p}(\Omega) = \left\{ u\in L^p(\Omega) : \frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p} + s}} \in L^p(\Omega\times\Omega) \right\} $$ equipped with the norm $$ \|u\|_{W^{s,p}(\Omega)} = \left( \int_\Omega |u|^p \; dx + \int_\Omega\int_\Omega \frac{|u(x)-u(y)|^p}{|x-y|^{n+ sp}} \; dx dy \right)^{1/p}. $$ Definition2:(Via Fourier Transform) For $s\in\mathbb{R}$, $1<p<\infty$, and $n\geq 1$, define the Sobolev space $H^{s,p}(\mathbb{R}^{n})$ by
    $$H^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}(\mathbb{R}^{n}) : \|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}<\infty\right\}$$,
equipped with norm
    $$\|f\|_{H^{s,p}}=\|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}$$ Where, $$\langle{\xi}\rangle^{s} =(1+|\xi|^2)^s$$ From these definitions I have a couples of questions 1) What are the value of $p\in[1,\infty)$ such that $W^{s,p}(\mathbb{R}^{n})$ and $H^{s,p}(\mathbb{R}^{n})$ coincide? I have found that this true for $p=2$ that is $$W^{s,2}(\mathbb{R}^{n})=H^{s,2}(\mathbb{R}^{n})$$ Do we still have equality or one side inclusion for some $p\neq 2$ if yes which one ? if no please provide me with some counter example or reference. 2) Next I would like to  know what are the advantage and disadvantage using one   the spaces  $W^{s,p}(\mathbb{R}^{n})$ and $H^{s,p}(\mathbb{R}^{n})$. I know that  the definition $W^{s,p}(\Omega)$
makes sense on any domain  which not the case for $H^{s,p}(\Omega)$ due to the lack of Fourier transforms.","['functional-analysis', 'banach-spaces', 'sobolev-spaces', 'fractional-sobolev-spaces']"
2569456,"Prove the function is constant on $(0, \infty)$","Let $a, b \in \mathbb{R}, 0 \lt a \lt b$ and $f:\mathbb{R} \rightarrow
\mathbb{R}$ such that: $$f(x^2 +ay) \ge f(x^2 +by), \forall x,y \in
\mathbb{R} \tag1$$ Prove $f$ is constant on $(0, \infty)$ I don't know how to start, any idea is appreciated. Playing a little bit with (1) I can get: For $y \lt 0, x= \sqrt {-y}$ from (1) $f(0) \ge f((b-a)y), \forall y \lt 0$ or, similar, $f(0) \ge f((a-b)y), \forall y \gt 0$ also $f(0) \ge f(y) \forall y \lt 0$ but it doesn't seem to be helpful.",['functions']
2569488,Find $f(0)$ if $f(f(x))=x^2-x+1$ [duplicate],"This question already has answers here : If $f(f(x))=x^2-x+1$, what is $f(0)$? (4 answers) Closed 2 years ago . Given $f : \mathbb{R} \to \mathbb{R}$ defined as $$f(f(x))=x^2-x+1$$ Find value of $f(0)$ I assumed $g(x)=f(f(x))$ we gave $$g(x)=(x-1)^2+(x-1)+1$$ Also $$g(x-1)=(x-1)^2-(x-1)+1$$ subtracting both we get $$g(x)-g(x-1)=2x-2$$ i have no clue from here any hint will suffice","['algebra-precalculus', 'polynomials', 'functions']"
2569489,$SL_2(\mathbb{Z})$ is an amalgamated product,"It is known that $SL_2(\mathbb{Z})= <S,R> $ where the generators are $S=\begin{pmatrix} 0 & -1\\ 1 & 0 \end{pmatrix}$ and  $R=\begin{pmatrix} 1 & -1\\ 1 & 0 \end{pmatrix}$ of orders 4 and 6 resp. Additionally it is known that- $$ PSL_2(\mathbb{Z})\cong <S | S^2>*<R|R^3>\cong <S,R | S^2, R^3>  $$ the free product of cyclic groups of order 2 and 3. With the generators being the images of $S$ and $R$ in $PSL_2(\mathbb{Z})$ I hope to find a proof (possibly using the previous known facts) that- $$SL_2(\mathbb{Z}) \cong <S,R | S^4,R^6, S^2=R^3> $$ That is, isomorphic to an amalgamated product. Hopefully it becomes easier when using the known facts...?","['free-product', 'group-theory']"
2569493,Spivak Calculus on Manifolds 2-37 Question,"I was working on problem 2-37(a) of Spivak's Calculus on Manifolds and I found that my approach to solving it was probably quite different from what was intended. To be clear, I understand the argument Spivak probably intended the reader to make. Also, just to clarify, I'm not saying my approach is better. Indeed I think the intended approach is preferable as it utilizes the theorems of the section and anticipates some of the ideas used to prove the Implicit Function Theorem in the section ahead. I just wanted to see if there was something wrong with my approach, as it doesn't require the same assumptions that were given in the problem. We are asked to show that if $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ is continuously differentiable then $f$ is not injective. We argue that, assuming $f$ is continuously differentiable (though we could use a weaker assumption than this) and injective, it follows that $f(x,y)$ is differentiable on $\mathbb{R}^2$ and therefore continuous on $\mathbb{R}^2$. So $f(x,0)$ and $f(0,y)$ are continuous and injective on the interval $[-1,1]\subset \mathbb{R}$. By connectedness of $[-1,1]$ and continuity of $f(x,0)$ and $f(0,y)$, the images of $[-1,1]$ by $f(x,0)$ and $f(0,y)$ are both connected. $f(0,0)$ being a maximum or minimum of either function on $[-1,1]$ contradicts with $f$ being injective. If $f(0,0)$ is not a maximum or a minimum, then it follows by connectedness that both images contain some open interval about $f(0,0)$, which, again, contradicts with injectivity of $f$. Thanks in advance.","['multivariable-calculus', 'inverse-function-theorem', 'proof-verification']"
2569510,Proof for sum of squares formula ( statistics - related ),"I'm new to the domain of statistics and i'm trying to accumulate as much info as i can right now. I've considered that this question should be asked here as it is related to mathematics. The problem is that from the get go most statistics books use the sum of squares formula : $SS= \sum{X^2} - \frac{(\sum(X))^2}{n} .$ Where can i find a proof for this formula? I've tried to prove it myself from $SS= \sum{(X-m_x)} $ , where $m_x$ is the mean of the population $X$ but to no avail.","['statistics', 'proof-explanation']"
2569557,"Implication in the $(ε,δ)$-definition of limit","I'm still confused by the use of  $\Rightarrow$  in (ε,δ)-definition of limit. Take for example the definition of $\underset{x\rightarrow x_{0}}{\lim}f\left(x\right)=l$ : $$\forall\varepsilon>0,\;\exists\delta>0\quad\mathrm{such\:that\quad}\forall x\in\mathrm{dom}\,f,\;0<\left|x-x_{0}\right|<\delta\;\Rightarrow\;\left|f\left(x\right)-l\right|<\varepsilon$$ My questions are: Why is $\left|f\left(x\right)-l\right|<\varepsilon$ not a sufficient condition for $0<\left|x-x_{0}\right|<\delta\;$? Or, stated in another way, shouldn't $\left|f\left(x\right)-l\right|<\varepsilon\;\Rightarrow\;0<\left|x-x_{0}\right|<\delta\;$ also be true ? 
If $f\left(x\right)$ becomes arbitrarily close to $l$, doesn't $x$  becomes arbitrarily close to $x_0$?","['limits', 'calculus', 'epsilon-delta', 'logic', 'definition']"
2569579,"The intersection of closure of span of infinite, linearly independent, closed, bounded, connected and disjoint subsets of $\ell^2$","Let $X$ and $Y$ be two subsets of $\ell^2$ space over $\mathbb{C}$ such that each of them is: infinite, linearly independent, closed, bounded, connected and $X \cap Y = \emptyset$ I would like to know if is it true that 
$$
\overline{
\operatorname{span}
X
}
\cap
\overline{
\operatorname{span}
Y
}
=
\{0\}
$$ thanks.","['functional-analysis', 'general-topology', 'hilbert-spaces']"
2569617,"Show linear independence of $\{1, \cos x, \sin x\}$","Linear independence of $f:\mathbb{R}\to\mathbb{R}$ given as
$$a+\cos(x)b+\sin(x)c=0$$
First I choose $x=-\frac{\pi}{2}$. I get
$$a+0b-1c=0\iff a=c$$
Then I choose $x=\pi$. I get
$$a-b+0c=0\iff a=b$$
We have that events $(\cos(x)=0\cap \sin(x)=0)=\emptyset$ as they are disjoint events, so we cannot conclude yet that $a=0$ must be true. If we use that $a=b=c$, we have:
$$a+\cos(x)b+\sin(x)c=a+\cos(x)a+\sin(x)a=0\iff 1+\cos(x)+\sin(x)=0\iff x=\pi\vee x=-\frac{\pi}{2}$$
For $x\neq\pi$ and $x\neq-\frac{\pi}{2}$ then $a=b=c=0$ for the equation to be true. Is this a proper way of showing that they are linear independent?","['trigonometry', 'linear-algebra']"
2569625,Solving the Differential equation: $y'=\frac{2}{x}y+x^3$,"We have the differential equation $$y'=\frac{2}{x}y+x^3$$ and we know $x \in (0, \infty)$. My attempt with variation of constants \begin{align}
\phi(x) &= \exp \left(\int \frac{2}{x} dx \right) \\
&= \exp(2\ln|x|) \\
&= x^2c
\end{align} and \begin{align}
\psi(x) &= (x^2c) \cdot \int \frac{x^3}{x^2} dx \\
&= (x^2c) \cdot \frac{x^2}{2}
\end{align} but this solution is wrong. Where is the mistake?","['real-analysis', 'integration', 'ordinary-differential-equations', 'calculus']"
2569661,Right triangle minimum area problem without calculus,"Consider two perpendicular lines $\ell_1$ and $\ell_2$ which intersect at $O$. There is another fixed point $P$ somewhere. We want to choose points $A$ and $B$ on the lines $\ell_1$ and $\ell_2$ such segment $AB$ contains $P$ and such that we minimize the area of triangle $\triangle OAB$. I think that we should choose the points where the circle centered at $P$ with radius $OP$ intersects the lines. How should you prove this? Here is a geogebra to play with (you can move point $A$ around until it intersects the circle): https://www.geogebra.org/m/wxQXjdmt There have been several questions along the same lines but all have been with an explicit point $P$ (given coordinates), and they use calculus: Minimum or maximum area of the triangle formed by a linear function and the axes and Optimization problem: given that a line passes through $(4,3)$ and it forms a triangle with x and y axis, find minimum area and Find equation of line such that area formed by line & positive coordinate axis is minimal for example. I would prefer an example that does not do a ""set coordinates and bash with calculus"" approach because that is ugly. This seems like a nice geometric fact, so a geometric proof with limited calculus would be best.","['euclidean-geometry', 'optimization', 'geometry']"
2569685,Way to find exact value of Riemann Zeta Function,"I have been considering the Riemann Zeta function, but with a limited domain. In this case I have been considering $$f(x)=\sum _{n=1}^{\infty }\:\frac{1}{n^x}, x>1$$
Considering that this is well define for every element in the domain, and the fact that this would have a horizontal asymptote at y=1 as the first term in the series will always be 1, is it possible to set this sum equal to some $n>1$ and find a closed form of the x that will give this result? I believe that this definition is continuous and is decreasing everywhere in the domain. What I mean by this question is a way to find $x$ in an equation such as $$3=\sum _{n=1}^{\infty }\:\frac{1}{n^x}, x>1$$ If not in closed form, perhaps a method to find the x to any level of accuracy as wanted, without just plugging this into wolphram alpha and solving for. Also, is the inverse of the Riemann Zeta function well defined and has it been studied?","['riemann-zeta', 'functions', 'limits']"
2569708,Optimal Compass and Straightedge Constructions,"I was recently looking over some Islamic geometry patterns, and was struck by the complexity of the constructions needed to create seemingly simple patterns. This got me wondering regarding optimal compass and straightedge constructions. To better define the question: One is given some initial collection of constructed points, and a new (constructable) point to be constructed. Are there known methods for finding the optimal construction (minimum needed number of arcs and lines)? If there isn't, are there any methods for reducing the search space, e.g. for computer assisted searches? Is there a known method for checking if a given solution is optimal?","['geometric-construction', 'optimization', 'euclidean-geometry', 'computational-complexity', 'geometry']"
2569710,A function whose partial derivatives exist at a point but is not continuous,"I am asked to determine whether or not a function can have all of its partial derivatives exist at a point but not be continuous at that point. I have tried to construct a counterexample but am unsure whether or not I have succeeded. Consider the following function: $$ f(x,y) = \left\{ \begin{array}{cc}
x & y=0 \\
0 & \text{otherwise}
\end{array}\right.
$$ Let $(x_0,y_0) \not= 0$ then we can compute the partials of $f$ at this point. Doing so is not difficult we just have to make sure we are careful about the partials with respect to $y$. $$
\begin{align*}
f_x(x_0,y_0) &= \lim_{h\rightarrow 0} \frac{f(x_0+h,y_0)-f(x_0,y_0)}{h} \\ 
\text{if $y_0=0$} & \implies \lim_{h\rightarrow 0} \frac{x_0+h-x_0}{h} = 1 \\
\text{if $y_0\not=0$} &\implies \lim_{h\rightarrow 0} \frac{0}{h} = 0 \\
f_y(x_0,y_0) &= \lim_{h\rightarrow 0} \frac{f(x_0,y_0+h)-f(x_0,y_0)}{h} \\
\text{if $y_0=0$} &\implies \lim_{h\rightarrow 0}\frac{x_0-x_0}{h} = 0 \\
\text{if $y_0\not=0$} &\implies \lim_{h\rightarrow 0} \frac{0}h = 0
\end{align*}
$$ In all of these cases the partials of $f$ exist, however it is clear that for $x_0\not=0$ we will have that $f$ is not continuous at $(x_0,0)$. Becuase along any path where $y\not=0$ we will have that the limit is $0$, but along the path $y=0$ we obtain the limit being $x_0$. So $f$ is not continuous, but its partials exist. Is this a valid construction? It felt kind of fishy, any advice would be appreciated.","['continuity', 'calculus', 'limits']"
2569757,Prove the solutions to the equation $z^n=1$.,"Fix a positive integer $n$. Prove that the solutions to the equation $z^n=1$ are precisely
$$z=e^{2\pi i \frac{m}{n}}$$
where $m \in \mathbb Z$. $Hint:$ To show that every solution of $z^n=1$ is of this form, first prove that it must be of the form $z=e^{2\pi i \frac{a}{n}}$ for some $a \in \mathbb R$, then write $a=m+b$ for some integer $m$ and some real number $0 \leq b <1$, and then argue $b=0$. I am confused about the hint, since by writing out
$$1=e^{i2m\pi}$$
where $m \in \mathbb Z$ we can get $$z=e^{2\pi i \frac{m}{n}}$$ immediately. So what does the hint mean? Thank you for any help!","['complex-analysis', 'complex-numbers']"
2569814,Fourier transform of sigmoid function,"I am wondering if there exists a closed form formula for the Fourier transform of the sigmoid function $f(x) = \frac{e^{x}}{(1 + e^{x}}$. More specifically I would need to calculate $F(w) = \int_{-\infty}^{\infty}(f(x)  e^{-iwx} dx)$. This can be expressed as   $F(w) = \int_{-\infty}^{\infty}(\frac{e^{x(1 - iw)}}{(1 + e^{x})}dx$. How would I go from here, or would there be a better way of finding the Fourier transform of the Sigmoid function? I have tried obtaining a result using the in-built $fourier$ matlab function, it did however not find a solution.","['fourier-analysis', 'calculus', 'fourier-transform']"
2569816,Directional derivative of smooth real values functions wrt. smooth curves,"Let $M$ be a $m$-dimensional smooth manifold, $p \in M$ a point and consider smooth curves $\alpha: (-\epsilon,\epsilon) \to M$, $\beta: (-\tilde{\epsilon},\tilde{\epsilon}) \to M$ centered at $p$, meaning $\alpha(0)=\beta(0)=p$. We define the following equivalence relation on these curves: $\alpha \sim \beta :\Longleftrightarrow $ for every chart $\varphi: U \to U'$ with $p \in U$ we have $(\varphi \circ \alpha)'(0) = (\varphi \circ \beta)'(0)$. We call an equivalence class a tangent vector . Let $\alpha$ be such a curve  through $p \in M$ and $f: V \to \mathbb{R}$ a smooth real valued function defined on an open neighborhood $V$ of $p$.
Then we call $(f \circ \alpha)'(0)$ the (directional) derivative of $f$ in direction $\alpha$. My notes say that this derivative only depends on the equivalence class of $\alpha$, so this must mean that if $\alpha \sim \beta$ we have $(f \circ \alpha)'(0) = (f \circ \beta)'(0)$. But I do not understand why this holds . I know that if $\alpha \sim \beta$ we have $(\varphi \circ \alpha)'(0) = (\varphi \circ \beta)'(0)$ for any chart $\varphi: U \to U'$ defined on an open neighborhood $U$ in $p$. But I do not know how to make the transition from $\varphi$, which maps to an open subset $U' \subset \mathbb{R}^m$, to $f$ which only maps to $\mathbb{R}$. Could you please explain this problem to me? Thank you!","['derivatives', 'differential-topology', 'smooth-manifolds', 'manifolds', 'differential-geometry']"
2569823,"Ax=0, why A must be singular matrix for having x different from 0?","For the given equation $Ax=0$ where $A$ is a square matrix and $x$ is a column vector, why $A$ must be a singular matrix (determinant $0$) in order to have $x$ different from null column vector?.","['matrices', 'linear-algebra']"
2569838,"""Limit form"" of non-autonomous linear ODE","Let us consider ODE
$$
f^{(n)} + a_{n-1}(t) f^{(n-1)} + \ldots + a_1(t) f + a_0(t) = 0
$$
with smooth coefficients s.t. $a_i(t) \to b_i \in \mathbb R$ when $t \to +\infty$. Is it true that fundamental solutions of the initial equation tend to solutions of ""limit equation"" with constant coefficients?
$$
f^{(n)} + b_{n-1} f^{(n-1)} + \ldots + b_1 f + b_0 = 0.
$$ I.e. for any solution $f$ of the first equation there exists solution $\tilde f$ of the second equation such that $|f(t) - \tilde f(t)| \to 0$ when $t \to +\infty$.",['ordinary-differential-equations']
2569859,Difference of the Closest Multiples of Two Real Numbers,"I am trying to find an algorithm / function for a computer program that I am working on. It looks like the following: $$F(f_1,f_2) = \Delta $$ where $\Delta$ is to be the smallest possible difference among a constrained set of integer multiples of $f_1$ and integer multiples of $f_2$. To put it another way, $$\Delta = \left\lvert n_1f_1 - n_2f_2\right\rvert\,\,s.t.\,\,\forall a_1,a_2 \in \{z_1,z_1+1,...,z_2\}, \left\lvert n_1f_1-n_2f_2 \right\rvert \le \left\lvert a_1f_1-a_2f_2 \right\rvert \; where\; z_1,z_2 \in \mathbb Z_{\gt 0}$$ Since I only need this for a very specific application, if it helps, we can also assume a few things about $f_1,\,f_2,\,z_1,$ and $z_2$: $f_1$ and $f_2$ are musical notes from a 12 note, equally tempered scale. This means that $f_1 = (\sqrt[12]{2})^{c_1}f_0$ and $f_2 = (\sqrt[12]{2})^{c_2}f_0$ for some integers $c_1$, $c_2$ and some fundamental frequency $f_0$. Typically $f_0$ is $440hz$. This cannot be assumed here, but we can assume that $f_0$ is some known constant. We can also assume that $z_1=1$ and $z_2=6$ Obviously, this problem could be solved very easily with a brute force computer program, as illustrated in the pseudo code below: function(f1,f2){
      var delta = f1 - f2
      var temp = 0
      for(i=1;i<7;i++) {
         for(k=1;k<7;k++){
            temp = abs(i*f1 - k*f2)
            if(temp < delta){
               delta = temp
            }
         }
      }

      return delta
   } But, there has to be a more elegant solution, right? Can someone help me out here?","['computer-science', 'factoring', 'functions', 'algorithms', 'special-functions']"
2569861,Algebraic numbers on both sides of trigonometric functions,"In this answer I learned about Niven's theorem . As I understand it, it says $$\left\{t\in\pi\mathbb Q\mid
0\le t\le\frac\pi2\wedge\sin(t)\in\mathbb Q\right\}
=\left\{0,\frac\pi6,\frac\pi2\right\}$$ In words and degrees: the angles between $0°$ and $90°$ inclusively for which a rational number of degrees results in a rational value of the sine function are exactly $0°,30°,90°$. Now I wonder, is there anything like this for algebraic numbers? Sure, a rational angle will always lead to an algebraic sine. But what about irrational algebraic angles? Is anything known about $$\left\{t\in\pi\left(\mathbb A\setminus\mathbb Q\right)\mid
0\le t\le\frac\pi2\wedge\sin(t)\in\mathbb A\right\}$$ In particular, are there any practical approaches to judge whether a given algebraic value can be written as the sine of an algebraic angle? In the past I've looked at high precision numeric computations and tried to reconstruct algebraic numbers from these, but so far I failed in each such case. I wouldn't be surprised if irrational algebraic angles leading to algebraic sines would be exceptionally rare or outright impossible.","['number-theory', 'trigonometry', 'transcendental-numbers', 'algebraic-numbers']"
2569890,Eigenvalues of same-row matrices,"It has previously been discussed here that the eigenvalues of an all-ones $n \times n$ matrix $A$ such as the following are given by $0$ with multiplicity $n - 1$ and $n$ with multiplicity $1$, hence a total multiplicity of $n$ which means that the given matrix is diagonalizable.
$$A =
\begin{bmatrix}
1 & 1 & \cdots & 1 \\
1 & 1 & \cdots & 1 \\
\vdots & \vdots & \ddots & \vdots \\
1 & 1 & \cdots & 1 \\
\end{bmatrix}
$$ I recently wrote an exam that asked us to diagonalize a matrix with multiple (3) rows that contained the same entries, so I was wondering if there was some general case to apply. Thus the question I am asking is given the following $n \times n$ matrix A, what are its eigenvalues?
$$A =
\begin{bmatrix}
a_1 & a_2 & \cdots & a_n \\
a_1 & a_2 & \cdots & a_n \\
\vdots & \vdots & \ddots & \vdots \\
a_1 & a_2 & \cdots & a_n \\
\end{bmatrix}
$$
For the sake of simplicity, lets first assume that $a_1, a_2, \ldots, a_n \in \mathbb{R} - \{0\}$; however, what happens if any (or all) are zero? It seems logical that there be the eigenvalue $0$ with $n - 1$ multiplicity since the rank of this matrix will be $1$ (assuming at least one nonzero entry), and that the other eigenvalue be the sum of entries on the diagonal by observation $a_1 + a_2 + \cdots + a_n$ with $1$ multiplicity. I could not, however, write a formal proof for that second statement.","['matrices', 'diagonalization', 'eigenvalues-eigenvectors', 'linear-algebra']"
