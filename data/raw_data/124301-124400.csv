question_id,title,body,tags
1877777,Checking if differential form $y^2xdx + ydy$ is exact,"I would like to check if the differential form $w = y^2xdx + ydy$ is exact. If $w$ would be exact we would have a function $f$ with $\partial f/\partial y =y$, thus $f = 1/2 y^2 +c$. $f$ would need to satisfy $\partial f/\partial x =  y^2x$ as well, so $c = 1/2 y^2 x^2 + c'$, where $c'$ may depend on $y$. Now differentiating our found expression for $f$ with respect to $y$ again we could say how $c'$ must look like, since we know that the differentiative has to be $y$ once again, and so on. I am struggling to get this argument to an end and to conclude, that $w$ cannot be exact. Any ideas to finish this? As an alternative I think the following should work: $w$ is not exact, since $w$ is not closed: $\partial w_1 /\partial y = 2yx \neq 0 = \partial w_2 / \partial x$ (for $x,y \neq 0$). Is this correct?","['real-analysis', 'analysis']"
1877809,Proving the limit $\lim _{n\to \infty }\left(\frac{1}{\sqrt{n^2+1}}+\frac{1}{\sqrt{n^2+2}}+...+\frac{1}{\sqrt{n^2+n}}\right)=1$,"I think I tried everything I know when trying to prove this limit 
$$\lim _{n\to \infty }\left(\frac{1}{\sqrt{n^2+1}}+\frac{1}{\sqrt{n^2+2}}+...+\frac{1}{\sqrt{n^2+n}}\right)=1$$
but I think that either there is some rule that I don't know or I am simply missing the creativity needed to solve it.. Help would be very appreciated.","['sequences-and-series', 'limits']"
1877856,"Is it true that the probability that an ""almost prime"" is prime, tends to $0.59$?","According to the estimation of the number of rough numbers I found in Wikipedia, the number of integers from $1$ to $x$ with no prime factor below $x^{1/u}$ tends to $\omega(u)\frac{x}{\ln(x^{1/u})}$ , if $x$ tends to $\infty$, where $\omega(u)$ is the Buchstab function. I concluded that the probability that a number $x$ without a prime factor smaller or equal to $x^{1/3}$ (Let us denote such a number ""almost-prime"", although this name might be a sysnonym for a semi-prime) tends to 
$\frac{\omega(3)}{\ln(x^{1/3})}$ , if $x$ tends to $\infty$. Since the probability that a number $x$ is prime tends to $\frac{1}{\ln(x)}$ , if $x$ tends to $\infty$, this implies that the probability that an ""almost-prime"" is prime tends to $\frac{\ln(x^{1/3})}{\omega(3)\ln(x)}=\frac{1}{3\omega(3)}=\frac{1}{3\cdot 0.564382}=0.5906$ Are my thoughts correct ? Calculations seem to backup the claim that the probability tends to roughly $59$% : almostprime(n)={local(w);w=factorint(n);w=component(w,1)~;w=w[1];w>sqrtnint(n,3)}

? q=0;r=0;for(m=10,100,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));prin
t(r,""    "",q,""     "",r/q*1.0)
21    32     0.6562500000000000000000000000
? q=0;r=0;for(m=100,1000,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));pr
int(r,""    "",q,""     "",r/q*1.0)
143    216     0.6620370370370370370370370370
? q=0;r=0;for(m=1000,10^4,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));p
rint(r,""    "",q,""     "",r/q*1.0)
1061    1667     0.6364727054589082183563287343
? q=0;r=0;for(m=10^4,10^5,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));p
rint(r,""    "",q,""     "",r/q*1.0)
8363    13608     0.6145649617871840094062316285
? q=0;r=0;for(m=10^5,10^6,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));p
rint(r,""    "",q,""     "",r/q*1.0)
68906    113951     0.6046985107633983027792647717
? q=0;r=0;for(m=10^6,10^7,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));p
rint(r,""    "",q,""     "",r/q*1.0)
586081    977543     0.5995449816529809941864449953
? q=0;r=0;for(m=10^7,10^8,if(almostprime(m)==1,q=q+1);if(isprime(m)==1,r=r+1));p
rint(r,""    "",q,""     "",r/q*1.0)
5096876    8559062     0.5954946932268979941960929831
? Can we expect that the probability will soon tend to $0.5906$, if we continue ? I do not expect a strictly motontone decreasing probability, but it should reach a value near $0.5906$ and then maybe oscillating around this value.
Can this be proven ?","['number-theory', 'probability', 'functions', 'prime-numbers']"
1877868,Cayley Hamilton Theorem,"Question is Substitute $A=SBS^{-1}$ into the product 
$$
(A-y_1I)(A-y_2I)\cdots(A-y_nI)
$$
and show that the product equals $0$ where $B$ denotes the diagonal form of $A$ with eigenvalues on the diagonal and $y$ denotes the eigenvalues Question says that this is related to the Cayley Hamilton Theorem . I know that Cayley Hamilton Theorem states that the eigenvalues in the characteristic polynomial of the matrix can be exchanged with the matrix itself. But I couldn't apply it here.","['matrices', 'linear-algebra']"
1877889,Can the Risch-algorithm actually prove that $e^{-x^2}$ has no closed-form antiderivative?,"The Risch algorithm is used to find closed-form antiderivatives. If I understand the article right, only heuristics are known. On the other hand, I came across the claim that it is known that $e^{-x^2}$ has no closed-form antiderivative. Is the Risch-algorithm successful in the case $f(x)=e^{-x^2}$ ? Is it actually proven that no closed-form antiderivative exist or just very probable because no form has been found using the Risch algorithm ? This question could well be a duplicate, but I am not sure whether the aspect of decidability has been asked.","['symbolic-computation', 'integration', 'calculus']"
1877893,Averaging averages without losing standard deviation information [duplicate],"This question already has an answer here : How do I obtain the ""final"" standard deviation from a series of values containing individual (also null) SD values? (1 answer) Closed 7 years ago . I've got a computerized procedure which runs a test and takes a few hundred samples during testing.  When finished, it spits back out the average and standard deviation of the samples. Now, I've run this test several times on test subjects that should be identical, but of course I get back slightly different average and standard deviation data each time.  I only have a record of the average and standard deviation returned at the end of the test, not of each individual sample point.  A typical data set will look something like the following: SUBJECT   AVG     STD
      1   129.2   31.0
      2   125.0   37.3
      3   123.6   34.7
      4   130.1   31.3
     ...   ...    ... Now, if I just average together the averages I get 127.0, but the standard deviation is only 3.2, when in fact the standard deviation between any actual samples is likely to be closer to 30.  Is there a way I can combine my summary statistics that preserves the information I have about the standard deviation between samples? Unfortunately, I don't have access to the size of the data sets which generated the outputs above (it's somewhere around a hundred points, but is different each time and not something I have access to records of).","['statistics', 'standard-deviation', 'average']"
1877932,Can a set be a member of its own power set?,"I'm new to set theory and I'm using actually an introduction to topology by Bert Mendelson that features some set theory questions. (side note, does anyone have a link to where the answers are for the books exercises?) My question is the following, and give reasons: true or false For each set $A$, $A \in 2^A$",['elementary-set-theory']
1877933,How to find the period of $\tan2x + \cos2x$?,"I need to find the period of the following trigonometric function:
$$f(x) = \tan2x + \cos2x$$ Any suggestions?",['trigonometry']
1877936,What exactly is the purpose of a coset?,"I'm having trouble understanding the motivation behind a coset. The book I'm using (A Book of Abstract Algebra) states: Let G be a group, and H a subgroup of G. For any element a in G, the symbol aH denotes the set of all products ah, as a remains fixed and h ranges over H. aH is called the left coset of H in G. It goes on to say the same about right cosets. I understand this definition (or I think I do), but what does this accomplish? Is it saying that given a subgroup H, you can generate a group G using cosets? Thank you in advance.","['abstract-algebra', 'group-theory', 'soft-question']"
1877985,Find $f(x)$ if $f(x+y)=f(x)+f(y) - 2xy + (e^x -1)(e^y -1) $,"Let $f$ be a differential function satisfying the relation $f(x+y)=f(x)+f(y) - 2xy + (e^x -1)(e^y -1)$$ \  \forall x ,   y \in\mathbb R $ and  $f'(0)=1$ My work Putting $y=0$
$$f(x)=f(x) + f(0)$$ $$f'(x)=\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$$
$$f'(x)=\lim_{h\to 0} \frac{f(x)+f(h) - 2xh + (e^x -1)(e^h -1)-f(x)}{h}$$
$$f'(x)=\lim_{h\to 0} \frac{f(h) - 2xh + (e^x -1)(e^h -1)}{h}$$
How to predict things after that?","['functions', 'functional-equations']"
1877991,Intuition behind intersection multiplicity for plane algebraic curves,"I am trying to understand what the intuition behind the intersection multiplicity of two plane algebraic curves is/should be. I know that there are different ways to define this value, but the book I am working with right now uses the following: Let $g,f \in k[x,y]$ s.t. $f$ and $g$ have no factor in common. Assume that $f(0,0)=g(0,0)=0$. Denote the associated curves with $F,G$. The intersection multiplicity of $F,G$ at $P=(0,0)$ is the number: $$ I(P,F\cap G):=\dim_k B  $$ where $B=(k[x,y]/(f,g))/(x,y)^n$ and $n$ is the  number s.t. $(x,y)^N=(x,y)^{N+1}$ for all $N\geq n$. Such a number exists because we know that $k[x,y]/(f,g)$ is a finite dimensional vector space. So far so good. I know what all of this means and I can work with it i.e. I can compute the dimension for examples. My question is: What is the intuition behind this definition? Or in other words: How does one come up with this definition? Here are my thougths so far: Let's assume $k=\mathbb{C}$ from here on. We can write the Taylor expansion for $f$ and $g$ at $P=(0,0)$ using multi indices . \begin{eqnarray}
f(x,y) &=& f(0,0) + \sum_{\vert\alpha \vert\geq 1}\dfrac{D^\alpha f(0,0)}{\alpha!}x^\alpha\\
g(x,y) &=& g(0,0) + \sum_{\vert\alpha \vert\geq 1}\dfrac{D^\alpha g(0,0)}{\alpha!}x^\alpha
\end{eqnarray} My intuition now tells me that $I(P,F\cap G)$ should agree with $\vert \alpha \vert$ s.t. $$f(x,y)-g(x,y)=\sum_{\vert \alpha \vert=I(P,F\cap G)}\dfrac{D^\alpha f(0,0)-D^\alpha g(0,0)}{\alpha!}x^\alpha+\text{higher order terms},$$ where of course the $\sum_{\vert \alpha \vert=I(P,F\cap G)}\frac{D^\alpha f(0,0)-D^\alpha g(0,0)}{\alpha!}x^\alpha \neq 0$. The intuition is coming from the geometric picture that the multiplicity at $P$ should somehow measure how ""tangent"" the two curves are to each other. I computed some examples and for those it is indeed true but I have a hard time proving it in full generality. And maybe it's wrong all together. I would appreciate if somebody could give me a proof or point to one or in general can give me more insight to my question above.","['abstract-algebra', 'taylor-expansion', 'differential-geometry', 'algebraic-geometry']"
1878002,Find the curl of $\mathrm a \times ( \mathrm b \times \mathrm r)$,"I'm trying to find the curl of $a \times (b \times r)$ where $a$, $b$ are constant vectors and $r = (x,y,z)$. I've worked through the problem to achieve the following answer: $$(\vec a \cdot \vec r) (\nabla \times \vec b) + \nabla (\vec a \cdot \vec r) \times \vec b - (\vec a \cdot \vec b) (\nabla \times \vec r) - \nabla (\vec a \cdot \vec b) \times \vec r$$ I know that the final answer is, $a \times b$, however I'm unsure of the steps in between to get there. Help would be greatly appreciated.","['multivariable-calculus', 'cross-product', 'vectors', 'derivatives']"
1878004,Problem in the solution of a trigonometric equation $\tan\theta + \tan 2\theta+\tan 3\theta=\tan\theta\tan2\theta\tan3\theta$,"I needed to solve the following equation:
  $$\tan\theta + \tan 2\theta+\tan 3\theta=\tan\theta\tan2\theta\tan3\theta$$ Now, the steps that I followed were as follows. Transform the LHS first:
$$\begin{split}
\tan\theta + \tan 2\theta+\tan 3\theta
 &= (\tan\theta + \tan 2\theta)
    + \dfrac{\tan\theta + \tan 2\theta}
            {1-\tan\theta\tan2\theta} \\
 &= \dfrac{(\tan\theta + \tan 2\theta)(2-\tan\theta\tan2\theta)}
          {1-\tan\theta\tan2\theta}
\end{split}$$ And, RHS yields
$$\begin{split}
\tan\theta\tan2\theta\tan3\theta
  &= (\tan\theta\tan2\theta)\dfrac{\tan\theta + \tan 2\theta}
     {1-\tan\theta\tan2\theta}
\end{split}$$ Now, two terms can be cancelled out from LHS and RHS, yielding the equation: $$
\begin{split}
2-\tan\theta\tan2\theta &= \tan\theta\tan2\theta\\
\tan\theta\tan2\theta &= 1,
\end{split}$$
 which can be further reduced as: $$\tan^2\theta=\frac{1}{3}\implies\tan\theta=\pm\frac{1}{\sqrt3}$$ Now, we can yield the general solution of this equation: $\theta=n\pi\pm\dfrac{\pi}{6},n\in Z$. But, setting $\theta=\dfrac{\pi}{6}$ in the original equation is giving one term $\tan\dfrac{\pi}{2}$, which is not defined. What is the problem in this computation?",['trigonometry']
1878010,"Trigonometric and absolute value integral $\int_0^{\pi/2} \left|\sin x - \cos2x\right| \, dx$","Problem:
Evaluate$$\int_0^{\pi/2} \left|\sin x - \cos2x\right| \, dx.$$ How would I go about this with the absolute value sign? Is there a general rule for absolute values and Integrals?","['integration', 'trigonometry']"
1878032,Why do we say the set of irrational numbers is bigger than the set of rational numbers?,Why do we say the set of irrational numbers is bigger than the set of rational numbers? I know that there are such questions like this one here . But after looking the answer they wrote that because rational numbers are countable but irrational numbers arn't. Now why do we say the uncountable sets are bigger than countable ones? Also it is better to post an answer that doesn't uses being countable or uncounatblity of sets.,['elementary-set-theory']
1878042,Is this the most general function vector space?,One can prove that the space of $p$ integrable functions and that other types of spaces (sequence spaces etc) are vector spaces by proving that they are subspaces of a more general vector space. Define $\mathfrak{F} = \{ f: X \to Y \}$ where $Y$ is a vector space over a field $\mathbf K$ and $X$ is any set.  Then $\mathfrak{F}$ is a vector space over $\mathbf K$ with the pointwise addition and scalar multiplication defined as usual. Is this the most general function vector space we can talk about? Thank you.,"['functional-analysis', 'linear-algebra', 'functions']"
1878101,Integration of a function on the simplex,"Let $$E = \{(x_1,\ldots,x_n) \mid x_1,\dots,x_n>0, x_1+\cdots+x_n<1 \}$$ and $f:[0,1]\to \mathbb{R}$ be continuously differentiable. Prove $$\int \cdots \int_E f(x_1+ \cdots +x_n) \, dx_1\cdots dx_n=\frac{1}{(n-1)!}\int_0^1 f(s)s^{n-1} \, ds$$ I think induction is the way to go here, the base was rather trivial but now I'm stuck. Any help?","['multivariable-calculus', 'simplex', 'integration', 'calculus']"
1878126,"What's the proof of the following formula: If f(x/y)= Constt., then dy/dx= y/x?","This formula (trick) is directly given in my study material. I have tried to prove it but its getting too long.Please help by giving proof of this condition, ie,formula.Thanks in advance.",['derivatives']
1878196,Question about whether $(x^2)^{0.5} = x$.,The Wikipedia page on exponentiation suggests that the following identity holds provided the base $b$ is non-zero: $$(b^m)^n = b^{mn}$$ Consider the following function: $$y = (x^2)^{0.5}$$ According to the identity above the following should hold: $$y = (x^2)^{0.5} = x^1$$ However consider the plots of the two functions: $$y = x$$ $$y = (x^2)^{0.5}$$ The functions are equal for $x \geq 0$ however for $x < 0$ there is a discrepancy. Could you comment on the use of exponentiation rules? Are there other circumstances that similar discrepancies can be found when applying exponentiation rules?,"['functions', 'exponentiation']"
1878202,how prove $\sum_{n=1}^\infty\frac{a_n}{b_n+a_n} $is convergent?,"Let$a_n,b_n\in\mathbb R$ and $(a_n+b_n)b_n\neq 0\quad \forall n\in \mathbb{N}$. The series $\sum_{n=1}^\infty\frac{a_n}{b_n} $ and $\sum_{n=1}^\infty(\frac{a_n}{b_n})^2 $ are convergent. How to prove that$$\sum_{n=1}^\infty\frac{a_n}{b_n+a_n} $$ is convergent. Thanks in advance","['contest-math', 'sequences-and-series', 'analysis']"
1878215,Derivative of $F^TF$ with respect to $F$,"I stacked with evaluating the derivatives
$$
\frac{\partial\left(F^TF\right)}{\partial F}~~ {\rm and}~~ \frac{\partial^2\left(F^TF\right)}{\partial F^2}
$$
in terms of $F\in\mathbb{R}^{3\times3}$. Any hint or any idea would be acknowledged.","['matrices', 'matrix-equations', 'matrix-calculus', 'derivatives']"
1878230,What is $\frac{dx}{d}?$,"The operator $\frac{d}{dx}$ is common in calculus to denote a derivative. However, this also begs the question, what is the operator $\frac{dx}{d}$? Is this operator used commonly? If so, what is it called/what does it do? I have played aroud with it before, and found a natural way to define it seems to be that $$\frac{dx}{d}\frac{1}{f(x)} := \frac{dx}{df} = \frac{1}{(\frac{df}{dx})}$$ I found also in my own playing around that this could define an odd thing when applying the operator twice: $$\frac{dx}{d}(\frac{dx}{df}) = \frac{dx}{d\frac{df}{dx}} = \frac{1}{\frac{d\frac{df}{dx}}{dx}} = \frac{1}{\frac{d^2f}{dx^2}}$$ Which would seem to imply a nice notation definition: $$\frac{dx}{d}(\frac{dx}{df}) := \frac{dx^2}{d^2f}$$ All this is purely my own speculation/invention, of course. I've never heard of any operation like this, and can't find it on the internet, because I don't have a name for it and can't find the notation anywhere. Is this operation already well-defined?","['derivatives', 'calculus']"
1878298,Spivak Calculus - Chapter 1 Question 4.6,"In Spivak's Calculus, Chapter 1 Question 4.6: Find all the numbers $x$ for which $x^2+x+1>2$ The chapter focuses on using the following properties of numbers to prove solutions are correct: Based on those properties, I am able to perform the following algebra: $
\begin{align}
x^2 + x + 1 &> 2 & \text{Given}\\
x (x + 1) + 1 &> 2 & \text{P9}\\
x (x+1) &> 1 & \text{P3 P2 and Addition}
\end{align}
$ And from there, I can note that: $
\begin{align}
x &\neq (x+1)^{-1}\\ 
x^{-1} &\neq (x+1)\\ 
\end{align}
$ By P6, because $x (x+1) > 1$ and $x (x+1) \neq 1$. However, in his book Spivak is able to find the following: $
\begin{align}
x &> \frac{-1+\sqrt{5}}{2} \text{ or}\\
x &< \frac{-1-\sqrt{5}}{2}
\end{align}
$ How does he come to that conclusion using only the properties listed above?","['proof-explanation', 'calculus', 'analysis']"
1878311,$\sigma$-additivity for measure of simple sets: $|\bigcup_{j=1}^{\infty}M_j|=\sum_{j=1}^{\infty}|M_j|$,"A hyperrectangle in $\mathbb{R}^d$ has the form $H = I_1 \times \ldots \times I_d$, where $I_1, \ldots, I_d$ are intervals. The natural volume $|H|$ is defined as $|H| : = |I_1| \cdot \ldots \cdot |I_d|$. A simple set $M \subset \mathbb{R}^d$ can be written as finite union $H_1 \cup \ldots \cup H_n$ of disjoint hyperrectangles and the natural measure of $M$ is defined as $|M| : = |H_1| + \ldots + |H_n|$. Now I want to prove the following theorem: Theorem. For disjoint simple sets $\{M_j\}_{j=1}^{\infty}$, where $\bigcup_{j=1}^{\infty} M_j$ is a simple set again, it holds that
  $$ \left| \bigcup_{j=1}^{\infty} M_j \right| = \sum_{j=1}^{\infty} |M_j|.$$ By trying to prove this theorem I realised that the function $|\cdot|$ on simple sets has properties we are used from measures. For example we have $M_1 \subset M_2 \Rightarrow |M_1| \leq |M_2|$. It follows from the definition of $|\cdot|$ that we have $$ \left| \bigcup_{j=1}^{n} M_j \right| =\left| \bigcup_{j=1}^{n} \bigcup_{i=1}^{k_j}H_{i,j} \right|=  \sum_{j=1}^{n} \sum_{i=1}^{k_j}|H_{i,j}| = \sum_{j=1}^{n} |M_j|.$$ At this point I have no idea how to extend this property to countable unions.","['volume', 'lebesgue-measure', 'measure-theory', 'elementary-set-theory']"
1878322,Find the general solution for: $\frac{dy}{dx} + \frac{y}{x}=\frac{1}{x^2}$,"Find the general solution for: $$\frac{dy}{dx} + \frac{y}{x}=\frac{1}{x^2} $$ I don't want to solve this using an integrating factor, I wanted to try solve this with a substitution $y=vx$ With the sub of $y=vx$ it implies that $dy = xdv+vdx$ and $\frac{y}{x}= v$ Hence the differential equation is transformed into $$ \frac{xdv + vdx}{dx} + v =\frac{1}{x^2}$$ $$ \Leftrightarrow \frac{xdv}{dx} + 2v = \frac{1}{x^2}$$ $$ \Leftrightarrow \frac{xdv}{dx} = \frac{1}{x^2} - 2v $$ $$ \Leftrightarrow \frac{dv}{dx} = \frac{1}{x^3} - \frac{2v}{x}$$ Now I am stuck  how should I continue? Is this substitution even correct for this question?","['integration', 'ordinary-differential-equations']"
1878344,The center of $A_n$ is trivial for $n \geq 4$,"I need to prove that the center of $A_n$ is trivial for $n \geq 4$. $Z(A_3) = A_3$, since $A_3 = \mathbb{Z}/3\mathbb{Z}$ is commutative. One idea is two use ""counting"" technique. First of, all we count cojugacy classes of even permutations in $S_n$.
It's the classes correspodning to the types $[\lambda_1, ..., \lambda_r]$ where $n \equiv r \mod 2$ Now, the conjugacy class in $S_n$ correspoding to the type $[\lambda_1, ..., \lambda_r]$ splits into two equal-sized classes in $A_n$ if $\lambda_1, ..., \lambda_r$ are distinct odd numbers. If they aren't then it is preserved in $A_n$. Then we can use ""the counting formula""( counting the number of elements in a conjugacy class of $S_n$ ) of elements in each ""even"" class of $S_n$ and divide one by $2$ if needed. Still, I'm not sure if it can be done. Seems to be a lot of work there. Maybe there are other, he easier ways? Or, maybe, it is the way, in this case, I wouild appreciate any advices.","['permutations', 'abstract-algebra', 'group-theory', 'symmetric-groups']"
1878348,"If every polynomial of degree $2$ and odd degree has a root in $k[x]$, then $k$ is algebraically closed.","Let $k$ be a field of characteristic zero. Assume that every polynomial in $k[X]$ of odd degree and every polynomial in $k[X]$ of degree two has a root in $k$. Show that $k$ is algebraically closed. What we need to show is that these two assumptions implies that given $f\in k[X]$ with deg $f = 2^nm,$ $m$ an odd integer, $f$ has a root in $k[X]$. We probably want to use induction on $n$. The case $n=0$ is good by assumption. Now assume $n>0$, and that $f$ is irreducible. And I don't know what to do after this point.","['abstract-algebra', 'galois-theory', 'field-theory']"
1878376,Paley-Weiner theorem and the Fourier transform of a non-analytic smooth function,"Many Paley-Weiner theorems are variations on the theme ""the faster a function $f(x)$ falls off as $x \rightarrow \infty$, the smoother its Fourier transform $\tilde{f}(k)$ is as $k \rightarrow 0$.""  In particular, we know that if $f(x)$ decays exponentially at large $x$ then $\tilde{f}(k)$ is analytic, and if $f(x) = 1/x^n$ (with $n \in \mathbb{Z}$) then $\tilde{f}(k) \propto k^{n-1} \mathrm{sgn}( k)$.  But I'm wondering about the (inverse) FT of $\tilde{f}(k) = 1 - e^{-1/k^2}$.  This function is smooth and falls off as $1/k^2$ at large $k$, so its inverse FT $f(x)$ should exist and not be too pathological.  It should fall off faster than any power-law at large $x$, or else some finite derivative of $\tilde{f}(k)$ would be discontinuous, but $\tilde{f}(k)$ is smooth.  But it cannot fall off as fast as an exponential, or else $\tilde{f}(k)$ would be analytic, which it isn't.  So its large-$x$ falloff must lie somewhere in between power-law and exponential.  But what is it?  I have no idea how to evaluate the Fourier transform because of the essential singularity at $k = 0$. Edit : Follow-up question: Is it true that any smooth function that falls off faster than any power-law but slower than any exponential has a non-analytic smooth FT?","['analyticity', 'complex-analysis', 'asymptotics', 'fourier-analysis']"
1878377,"What is ""calculus"" on a manifold?","I guess my question is about interpretation.  My (very rough) understanding of the way we do calculus on a smooth manifold is as follows... A smooth manifold is a topological space without necessarily any metrical structure- therefore, if we speak of ""calculus"" being done on smooth manifolds, then it is a calculus on spaces which are not generally metric.  How then do we define a ""derivative"" for such a calculus?  (In analysis we learn that a derivative is the (limit of) the ratio of distance functions evaluated on elements of two (functionally related) metric spaces.)  And how then do we define the derivative's inverse- the integral?  Now, I know that the objects which are differentiated and integrated on smooth manifolds are not functions, but differential forms.  The theory is developed in such a way that this calculus of forms reduces - via coordinates - to good old calculus of functions on R^n endowed with the Euclidean metric.  So a metric does sneak its way into this calculus on manifolds.  What's going on here?  Would it be fair to call calculus on manifolds a non-metrical calculus or not? Perhaps my question is ill-defined, but here's my attempt to answer it... The Euclidean metric only comes into play to allow us to do calculations (via the pullback).  The existence of many different (diffeomorphic) coordinate spaces in which to do these calculations means that the Euclidean metric in any one coordinate space cannot be interpreted as carrying metrical information about the underlying manifold.  Forms are the objects of calculus on a manifold precisely because the calculations we do with them (e.g. integration, exterior differentiation,...) can be defined without reference to coordinates (R^n) and are therefore invariant under coordinate transformations.  So, yes, the calculus on a manifold - which apparently is the calculus of forms - is a non-metrical calculus. I'm on my own here so any guidance is very much appreciated.","['metric-spaces', 'smooth-manifolds', 'differential-geometry', 'calculus']"
1878388,Prove/disprove: $\text{det}(A+B)\geq\text{det}(A)+\text{det}(B)$,"Let $A,B$ be non-neg $n$ by $n$ matrices over $\mathbb{C}$. Show $\text{det}(A+B)\geq\text{det}(A)+\text{det}(B)$. I attempted this problem in preparation for qualifying exams, but I'm a little unsure of the solution. My thought is to use the minmax theorem. Let $\eta_i,\lambda_i$ and $\zeta_i$ are the ith eigenvalues of $A$, $B$, and $A+B$. The determinant of each matrix is the product of the respective eigenvalues, and since the matrices are all positive, each eigenvalue is $>0$ and so each determinant is as well. Using the Rayleigh quotient, we have $R_{A+B}(v)=\frac{<v,Av>+<v,Bv>}{<v,v>}=R_A(v)+R_B(v)$ for each $v\neq 0$. Since the Rayleigh coefficients determinant the eigenvalues in increasing order, I would think this means that $\eta_i+\lambda_i=\zeta_i$. Hence, $\text{det}(A+B)=\prod_{i=1}^n\zeta_i=\prod_{i=1}^n(\eta_i+\lambda_i)\geq\prod_{i=1}^n\eta_i+\prod_{i=1}^n\lambda_i=\text{det}(A)+\text{det}(B)$. Does anyone see a flaw in this argument? If it is correct, does anyone know perhaps an easier argument?","['linear-algebra', 'proof-verification']"
1878399,"Identities with inverse hyperbolic and trigonometric functions, such as $\tanh^{-1} (\cos a)+\tanh^{-1} (\cos b)=\tanh^{-1} (\cos c)$","This was a very surprising discovery for me that identities like this exist: $$\tan \frac{c}{2}=\tan \frac{a}{2}\tan \frac{b}{2} \qquad \rightarrow$$ $$\tanh^{-1} (\cos c)=\tanh^{-1} (\cos a)+\tanh^{-1} (\cos b)$$ This is a fairly well known one, and can be proven by making substitutions: $$u=\tan \frac{a}{2}, \qquad v=\tan \frac{b}{2}$$ Another, interesting one exists (proven in the same way): $$\tan \frac{c}{2}=\frac{\tan \frac{a}{2}-\tan \frac{b}{2}}{\tan \frac{a}{2}+\tan \frac{b}{2}} \qquad \rightarrow$$ $$\tanh^{-1} (\sin c)=\tanh^{-1} (\cos b)-\tanh^{-1} (\cos a)$$ What other identities like this exist? What is the interpretation of such identities in terms of: Complex numbers Geometry Or is it just a coincidense with no particular significance?","['hyperbolic-functions', 'complex-analysis', 'trigonometry']"
1878410,Connected and locally path connected,"Suppose $X$ is connected and locally path connected, then $X$ is path connected. 
Proof
BWOC, let $Y$ is path component poper subset of $X$. Since $X$ is locally path connected then $Y$ is open and $X-Y$ is open. Then $Y$ is closed which is contradiction because $X$ is connected. My question how can I prove it directly from the definition without depending on theorem.","['general-topology', 'connectedness']"
1878432,Distance Between Two Ellipsoids,"Find the shortest distance between $\begin{align}
&\frac{x_1^2}{a_1^2}+...+\frac{x_n^2}{a_n^2}=1\\
&\frac{x_1^2}{a_1^2}+...+\frac{x_n^2}{a_n^2}=2
\end{align}$. My thinking is when $n=2$, we have two ellipses where the axes of the second are the same as the first scaled by a factor of $\sqrt{2}$. WLOG, assume $|a_1|<|a_2|$. Then the shortest distance would be $|a_1|(\sqrt{2}-1)$. For the ellipsoid case, I would say the shortest distance is $|a_{\text{min}}|(\sqrt{2}-1)$. I don't know how to prove this formally. I thought about using Lagrange multipliers but had difficulties even setting it up. Any suggestions?","['nonlinear-optimization', 'calculus', 'convex-optimization', 'euclidean-geometry', 'geometry']"
1878433,How can a set contain itself,"im reading a little about the Russell Paradox , and i dont really get what they mean by a set that contains itself , can anybody please explain ?",['elementary-set-theory']
1878484,Most general definition of Borel and parabolic Lie algebras?,"Let $\mathbb{K}$ be an arbitrary field, and $G$ an algebraic group (=group variety?) over this field. A Borel subgroup of $G$ is a connected solvable subgroup variety $B$ of $G$ such that $G/B$ is complete. A parabolic subgroup of $G$ is a subgroup variety $P$ such that $G/P$ is complete. Given a group $G$ with lie algebra $\mathfrak{g}$, I would expect that a parabolic Lie subalgebra $\mathfrak{p} \leq \mathfrak{g}$ should be a Lie subalgebra which is the Lie algebra of a parabolic subgroup, and likewise for Borel subalgebras $\mathfrak{b} \leq \mathfrak{g}$. Since distinct groups can obviously have isomorphic Lie algebras, I would expect that there should be a characterization of Borel and parabolic subalgebras in terms of Lie algebra properties alone, without reference to groups. However, it seems that in every source I've found that discusses Borel and parabolic subalgebras, that they are defined only for finite-dimensional semisimple and complex lie algebras $\mathfrak{g}$. A Borel subalgebra of a complex finite-dimensional semisimple Lie algebra $\mathfrak{g}$ is usually defined to be a maximal solvable subalgebra $\mathfrak{b} \leq \mathfrak{g}$, and a parabolic subalgebra $\mathfrak{p} \leq \mathfrak{g}$ is any subalgebra containing a Borel subalgebra. Is there a reason for restricting to complex semisimple Lie algebras? Does the definition not work for general Lie algebras? More generally, what is the relationship between parabolic subgroups and subalgebras? Does the relationship depend at all on the field $\mathbb{K}$ we are working with (characteristic, whether or not it if it is algebraically closed etc.)? Does it depend on the properties of the group (to connected, simply connected, etc.)? Unfortunately my algebraic geometry knowledge is very minimal. I'm working on stuff in parabolic differential geometry, so I'm hoping to get a better understanding of parabolic subgroups and algebras, especially in the real case.","['algebraic-groups', 'lie-algebras', 'algebraic-geometry', 'lie-groups']"
1878505,Inverse of an upper triangular matrix with all entries 1,I want to find the inverse of a large upper triangular matrix where all its entries are 1. Is there some trick to it or do I have to compute it using the usual way?,"['matrices', 'inverse']"
1878535,Random variable conditioned to gamma distribution,"Suppose that we have two random variable $X$ and $Y$, where $X$ ~
  $Gamma (2,1)$ and that $Y|X$ ~ $U(0,x)$. Find the distribution of Y. The way I approach it as follows: We know that $f_X(x) = xe^{-x}$ for $x\in(0,\infty)$ and that $f_{Y|X}(y|x) = 1/x$ for $y\in(0,x)$. To find the distribution we integrate:
$$f_Y(y) =\int_0^{\infty} f(x,y)dx = \int_0^{\infty} f_{Y|X}(y|x)f(x)dx = \int_0^{\infty} e^{-x}dx = 1$$ What distribution is this, since $y$ has the support $(0, \infty)$? Am I doing anything wrong?","['statistics', 'integration', 'probability', 'probability-distributions']"
1878541,Is this hypothesis necessary for Abel's Theorem?,I am reading up on Abel's Theorem from http://www.math.uconn.edu/~kconrad/blurbs/analysis/abelthm.pdf . Screenshot here for convenience: Q1): Is it necessary to have the hypothesis that $\sum c_nx^n$ converges for $|x|<1$? I ask this question since some sources do not have this hypothesis (e.g. https://proofwiki.org/wiki/Abel's_Theorem ) Hence I somehow suspect it can be deduced from the fact that $\sum c_n$ converges. I know that the comparison test works $\sum c_nx^n\leq\sum c_n$ works if $c_n$ are nonnegative. I do not know how to deduce it if $c_n$ are possibly negative. Thanks for any help!,"['real-analysis', 'analysis']"
1878574,Combinatorics Proof Suggestions and Feedback,"Problem. We are given $2000$ integers each with absolute value less than $1000$ and with the sum equal to $1$. Prove that we can choose some of them with sum equal to $0$. Here is my solution: Suppose the numbers are $X = \{a_1, a_2, ..., a_{2000} \}$. First choose a random $a_i$ and call it $x_1$. Let $S_1 = x_1$ and we construct $(S_i)_{1 \leq i \leq n}$ with the following recursive algorithm: Choose an element $x_i$ from $X$ that satisfies $|S_{i-1} + x_i| <1000$ and remove it from $X$. $S_i = S_{i-1} + x_i$, in particular, $|S_i| < 1000$. I claim that it is always possible to find such an $x_i$ to satisfy step $1$. Assume the contrary, that is, there exists $S_k = x_1 + x_2 + ... + x_k$ and no $x_{k+1}$ exists. WLOG, we can assume $S_k > 0$. So, for every $a_i \in X$, we have that $a_i \geq 1000 - S_k$. But this is impossible since $a_1 + a_2 + ... + a_{2000} = 1$. Thus we can generate \begin{align*}
S_1 & = x_1 \\
S_2 & = x_1 + x_2 \\
& \vdots \\
S_{2000} & = x_1 + x_2 + ... + x_{2000}
\end{align*} 
We know that $-999 \leq S_1, S_2, ..., S_{2000} \leq 999$ so by Pigeon-hole, at least two $S_i$ are equal. But we can subtract these two to get a subset of $a_i$ that sum to $0$. Does anyone have any feedback to make this clearer? Also I would love to see another solution!","['combinatorics', 'additive-combinatorics']"
1878586,Prove that the points can be covered by a heptagon of area $\dfrac{10}{3}$,"I am working on this problem: There is a finite number of points in the plane, any three points form a triangle of area 1 or less. Prove that the points can be covered by a heptagon of area $\dfrac{10}{3}$. In past, I solved a similar problem: "" There is a finite number of points in the plane, any three points form a triangle of area 1 or less. Prove that the points can be covered by a triangle of area 4 "". I think that the above statement is false, but I can find a counterexample. Anyone can help me solve this problem or find a counterexample?","['combinatorics', 'combinatorial-geometry', 'extremal-combinatorics']"
1878601,Apostol's proof of Arzelà's Bounded Convergence Theorem,"In the first edition of Apostol's Mathematical Analysis, there is a proof of Arzelà's bounded convergence theorem: $\textbf{Theorem 13-17}\,(\textit{Arzel}\grave{a})\textbf{.}$ Assume that $\lbrace f_{n}\rbrace$ is a uniformly bounded, pointwise convergent on $[a,b]$ and suppose that each $f_{n}$ is Riemann-integrable on $[a,b]$. Suppose also that the limit function $f(x):=\lim_{n}f_{n}(x)$ is Riemann-integrable on $[a,b]$. Then,
$$ \lim_{n}\int_{[a,b]}f_{n}=\int_{[a,b]}\lim_{n}f_{n}=\int_{[a,b]}f. $$
$\textit{Proof}.$ Let $g_{n}(x)=\left|f_{n}(x)-f(x)\right|$. We will prove that
$$ \lim_{n}\int_{[a,b]}g_{n}=0. $$
For this purpose we define a new sequence of functions $\lbrace h_{n}\rbrace$ as follows:
$$ h_{n}(x)=\sup_{m\ge n}f_{m}(x),\qquad\text{ if }x\in[a,b]\text{ and }n\in\mathbf{N}. $$
Note that, for each fixed $x$, we have
$$ 0\le g_{n}(x)\le h_{n}(x),\qquad h_{n+1}(x)\le h_{n}(x),\qquad \lim_{n} h_{n}(x)=0. $$
Hence, $0\le\int_{[a,b]}g_{n}=\mathop{\underline{\int}}_{[a,b]}g_{n}\le\mathop{\underline{\int}}_{[a,b]}h_{n}.$ (The lower integral $\mathop{\underline{\int}}_{[a,b]} h_{n}$ exists because each $h_{n}$ is bounded on $[a,b]$. However, $h_{n}$ need not to be Riemann-integrable. On the other hand, $g_{n}$ $\textit{is}$ Riemann-integrable, since both $f_{n}$ and $f$ are integrable.) Let $I_{n} = \mathop{\underline{\int}}_{[a,b]} h_{n}$. The proof will be complete if we can show that $I_{n}\to 0$ as $n\to\infty$. Observe that the sequence $\lbrace I_{n}\rbrace$ convergs to $\textit{some}$ non-negative limit. Let $I=\lim_{n}I_{n}$. We will show that the inequality $I>0$ leads to a contradiction.
Assume that $I>0$. Since $I_{n}\ge I > I/2$ for each $n$, there is a partition $P_{n}$ of $[a,b]$ and a lower Riemann sum $L(P_{n},h_{n})$ such that $L(P_{n},h_{n})>I/2.$ Let $\varepsilon=\tfrac{1}{2}I/(M+b-a)$, where $M$ is a uniform bound for $\lbrace h_{n}\rbrace$ on $[a,b]$. The lower sum $L(P_{n},h_{n})$ can be split into two parts as follows:
$$ L(P_{n},h_{n})=\sum_{i\in A_{n}}m_{i}(h_{n})\Delta x_{i}+\sum_{i\in B_{n}}m_{i}(h_{n})\Delta x_{i}, $$
where $m_{i}(h_{n})$ denotes the $\inf$ of $h_{n}$ in the $i$th subinterval of $P_{n}$ and
$$ A_{n}=\lbrace i: m_{i}(h_{n})>\varepsilon\rbrace,\quad B_{n}=\lbrace i:m_{i}(h_{n})\le\varepsilon\rbrace. $$
The inequality $L(P_{n},h_{n}) >I/2$ implies
$$ \tfrac{1}{2} I <\sum_{i\in A_{n}}M\Delta x_{i}+\varepsilon\sum_{i\in B_{n}}\Delta x_{i}\le M\sum_{i\in A_{n}}\Delta x_{i}+\varepsilon(b-a), $$
from which we obtain $\sum_{i\in A_{n}}>\varepsilon$. Since refinement of partitions increases lower sums, there is no loss in generality in assuming that the $P_{n}$ are such that $P_{n}\subset P_{n+1}.$
Now let $S_{n}$ denote the union of these subintervals $[x_{i-1},x_{i}]$ of $P_{n}$ for which $i\in A_{n}$. Then $S_{n}$ is a closed set and its Jordan content is
$$ c(S_{n})=\sum_{i\in A_{n}}\Delta x_{i}>\varepsilon. $$
This implies that there is ate least one $x$ belonging to infinitely many of the sets $S_{n}$. Hence, for this $x$ we have $h_{n}(x)>\varepsilon$ infinitely often, contradicting the fact that $h_{n}(x)\to 0$ as $n\to\infty$. Thus, $I=0$. Why does $c(S_{n})>\varepsilon$ for all $n$ imply that there exists some $x$ such that $x\in S_{n}$ for infinitely many $n$? Apostol doesn't prove this, but this claim doesn't seem to be entirely obvious. I would appreciate any help.","['real-analysis', 'analysis']"
1878626,Prove that $\displaystyle \sum_{1\leq k<j\leq n} \tan^2\left(\frac{k\pi}{2n+1}\right)\tan^2\left(\frac{j\pi}{2n+1}\right)=\binom{2n+1}{4} $,"Prove that
$$\sum_{1\leq k < j\leq n}\tan^2\left(\frac{k\pi}{2n+1}\right)\tan^2\left(\frac{j\pi}{2n+1}\right)=\binom{2n+1}{4}$$","['binomial-coefficients', 'summation', 'trigonometry']"
1878651,Inductive Probability in Mathematical Theory,"In M.G. Bullmer's Principles of Statistics (Dover edition 1979, though seems like nothing significant was changed from the 1967 second edition), he states in the conclusion to the first chapter that: ""It has been reluctantly concluded by most statisticians that inductive probability cannot in general be measured and, therefore, cannot be used in the mathematical theory of statistics...it does not seem possible to construct a numerical scale of such (inductive) probabilities."" This sentence struck me as odd, since Wikipedia's article on Inductive Probability seems to have a wealth of information referencing Bayes Theorem, Inference, and applications in A.I/Machine Learning. Is this due to the fact that the field of Inductive Probability has grown significantly since the 1960s/1980s?  Since I'm learning probability mainly for applying it to machine learning should I pick up another book on statistics, or are the fundamentals still helpful when applied to ml? Or is Bullmer's statement still correct? I guess I'm not really sure what a ""mathematical model"" is and whether the information in the wikipedia article qualifies as such.",['probability-theory']
1878708,Integration of a function on the simplex (with gamma function),"Let $$E = \{(x_1,\ldots,x_n) \mid x_1,\dots,x_n>0, x_1+\cdots+x_n<1 \} , p_1,\dots,p_n>0$$ and $f:[0,1]\to \mathbb{R}$ be continuously differentiable. Prove $$\int \cdots \int_E f(x_1+ \cdots +x_n) x_1^{p_1-1}...x_n^{p_n-1}\, dx_1\cdots dx_n=\
\frac{\Gamma(p_1)...\Gamma(p_n)}{\Gamma(p_1+...+p_n)}\int_0^1 f(s)s^{p_1+...+p_n-1} \, ds$$ I'm not sure if it helps but earlier we proved that $$\int \cdots \int_E f(x_1+ \cdots +x_n) \, dx_1\cdots dx_n=\frac{1}{(n-1)!}\int_0^1 f(s)s^{n-1} \, ds$$
using induction and the following change of basis: $$\begin{bmatrix} x_1 \\ \vdots \\ x_{n-1} \\ x_n \end{bmatrix} \mapsto \begin{bmatrix} x_1 \\ \vdots \\ x_{n-1} \\ x_1+\cdots + x_n \end{bmatrix} = \begin{bmatrix} x_1 \\ \vdots \\ x_{n-1} \\ s \end{bmatrix}
$$ I also believe we should use the following identity: $\int \cdots \int_E  x_1^{p_1-1}...x_n^{p_n-1}\, dx_1\cdots dx_n= \frac{\Gamma(p_1)...\Gamma(p_n)}{\Gamma(p_1+...+p_n+1)}$ Any help?","['calculus', 'multivariable-calculus', 'integration', 'gamma-function', 'analysis']"
1878722,Number of fixed points of torus action over partial flag variety,"Consider $g\in U(n)$ and $t\in T$, where $T$ is the diagonal maximal torus in $U(n)$. Some common manifolds may be obtained as quotients of the $U(n)$ like the complex grassmannian, $Gr(k,n)=U(n)/U(k)\times U(n-k)$ and the manifold of complete flags in $\mathbb{C}^n$, $F_n=U(n)/T$, and there is an induced action of $T$ coming from the action of $U(n)$ in them. Counting the fixed points of this action yields ${n\choose k}$ and $n!$, respectively. These numbers are precisely $|w_n|/(\,|w_{n-k}|\cdot|w_{k}|\,)$ and $|w_n|$, respectively, where $|w_k|$ denotes the order of the Weyl group of $U(k)$, i.e., $w_k=N_{U(k)}(T)/T$. From this there is a natural candidate to generalize the result for partial flag varieties $U(n)/U(k_1)\times\cdots\times U(k_d)$, where $k_1+\cdots+k_d=n$: the number of fixed points of this action will be
$$
\frac{|w_n|}{|w_{k_1}|\cdots|w_{k_d}|}=\frac{n!}{k_1!\cdots k_d!}=\frac{|N_{U(n)}(T)/T|}{|N_{U(k_1)}(T_1)/T_1|\cdots|N_{U(k_d)}(T_d)/T_d|},
$$
where $T_i$ is the diagonal maximal torus in $U(k_i)$. I would like some help on how to show this, in other words, how to show that there is a bijection between 
$$
\text{$g\in U(n)$ such that $g^*tg\in U(k_1)\times\cdots U(k_d)$ for all $t\in T$ (fixed points)} 
$$
and 
$$
\frac{N_{U(n)}(T)/T}{N_{U(k_1)}(T_1)/T_1\times\cdots\times N_{U(k_d)}/T_{k_d}}=\frac{N_{U(n)}(T)}{N_{U(k_1)}(T_1)\times\cdots\times N_{U(k_d)}}.
$$
I'v tried brute forcing some conditions on the matrices $g$, yet I don't see anything that is of help, so I think a conceptual proof may be the way to go.","['group-actions', 'schubert-calculus', 'differential-geometry', 'lie-groups']"
1878810,"Formula for $1^k+2^k+3^k...n^k$ for $n,k \in \mathbb{N}$","So I've been looking for a formula where I can input the parameter $k$ and it will give me a formula for $1^k+2^k+3^k...+ n^k$ with $n,k \in \mathbb{N}$. The result is always a polynomial with $k+1$ as highest power. I've taken the time to calculate the polynomes for $k=1$ to $k=10$ by hand and using the interpolation feature of Wolfram Alpha. Here are the results (I'll only show the coefficients for the sake of clarity. the coefficients are always from $n^{k+1}$ to $n^1$. the constant is always $0$. So $\frac{1}{2},-\frac{1}{2}$ becomes $\frac{1}{2}n^2-\frac{1}{2}n$): $k=1$ : $\frac{1}{2},-\frac{1}{2}$ $k=2$ : $\frac{1}{3},\frac{1}{2},\frac{1}{6}$ $k=3$ : $\frac{1}{4},\frac{1}{2},\frac{1}{4},0$ $k=4$ : $\frac{1}{5},\frac{1}{2},\frac{1}{3},0,-\frac{1}{30}$ $k=5$ : $\frac{1}{6},\frac{1}{2},\frac{5}{12},0,-\frac{1}{12},0$ $k=6$ : $\frac{1}{7},\frac{1}{2},\frac{1}{2},0,-\frac{1}{6},0,\frac{1}{42}$ $k=7$ : $\frac{1}{8},\frac{1}{2},\frac{7}{12},0,-\frac{7}{24},0,\frac{1}{12},0$ $k=8$ : $\frac{1}{9},\frac{1}{2},\frac{2}{3},0,-\frac{7}{15},0,\frac{2}{9},0,-\frac{1}{30}$ $k=9$ : $\frac{1}{10},\frac{1}{2},\frac{3}{4},0,-\frac{7}{10},0,\frac{1}{2},0,-\frac{3}{20},0$ $k=10$ : $\frac{1}{11},\frac{1}{2},\frac{5}{9},0,1,0,1,0,-\frac{1}{2},0,\frac{5}{66}$ There are a few things i notice: Firstly, the coefficient of the highest power seems to be $\frac{1}{k+1}$. Secondly, the coefficient of the second highest power seems to be $\frac{1}{2}$ with the exception of $k=1$. Thirdly, all coefficients of the fourth, sixth, eight highest power and so on seem to be $0$. 
What is the formula that will output the coefficients for any value of $k$?","['summation', 'polynomials', 'sequences-and-series']"
1878831,Infinite Sets and Natural Numbers,"Is it possible to find two infinite sets of non-negative integers, $A,B$, such that every non-negative integer can be written uniquely as a sum of two integers, one from $A$ and the other from $B$? It is easy to do this if we let one set be finite.  For example, take $A=\{0,1\}$ and let $B$ be the set of non-negative even integers.  Can it be done with two infinite sets? Remark:  the assumptions imply that $A\cap B=\{0\}$.  Indeed, the only way to write $0$ as the sum of two non-negative integers is $0=0+0$ so $0$ must be in both.  But then, if we had a non-zero $n\in A\cap B$, we could then write $n=n+0=0+n$, contradicting the uniqueness of the decomposition.","['abstract-algebra', 'infinite-groups']"
1878842,Interesting Open Questions In Wavelet Theory for UG Research?,"Just as background, I am going into my senior year of undergrad and I have a pretty light load this coming semester but I want to fill this time with something that will really make my grad school resume sparkle. As you might guess from my username, I am fascinated by wavelets (and harmonic analysis in general) and I have decided to try to at least attempt some research over the next year to close out my UG studies. I spoke with a professor about this and he said he'd be more than happy to help me as much as he can and get me credit for it but I'd need to come up with the topic and expect to do the vast majority of it on my own (I actually prefer working more independently). Anyways, I have been trying to find a problem that interests me enough that I can see myself working on 5-6 hours a day but I haven't had any luck. While I feel confident in my knowledge of wavelet theory, I don't really know which way is up when it comes to the actual research end of things. I know the major players like Daubechies, Mallat, Morlet, etc. but I am having a hard time figuring out what constitutes ""cutting edge"". Obviously, I expect that any research is going to be more on the applied end of things but I'd prefer it to be as ""pure"" (i.e. not computational) as possible just because I am limited in how much computing power I have access to (I've had my computer crash many many times from trying to do wavelet projects in MATLAB) and I am skeptical that the department will let me anywhere near the big guns. My knowledge base is sufficient that I can understand most of Mallat's ""A Wavelet Tour of Signal Processing: The Sparse Way"", though I find it to be quite a slog just because of the notation and lay out. I am particularly interested in some potential interplay between stochastic processes (sufficiently nice ones at least) and wavelet analysis. I do not have a great background in stochastic integration quite yet but I learn fast enough that I feel confident it wouldn't pose too much of barrier. I would be indebted to anyone who could point me in the right direction.","['stochastic-processes', 'wavelets', 'fourier-analysis', 'harmonic-analysis', 'functional-analysis']"
1878898,Does $\lim_{q\to \infty }f(q)$ has sense where $q\in \mathbb Q$?,"I wrote in a previous exam $$\lim_{\underset{q\in \mathbb Q}{q\to \infty} }f(q)=1\neq 0 =\lim_{\underset{r\in \mathbb R\backslash \mathbb Q}{r\to \infty }}f(r),$$ but my teacher told me that such limit has no sense, but I don't understand why. Is that really have no sense ? And if yes, why ?","['real-analysis', 'notation', 'limits']"
1878919,Why we can add an element on both sides like this?,Suppose $A$ is a set equipped with a binary operation $+$. How I can prove if $a=b$ then $a+c=b+c$? Why we can add an element on both sides like this?,"['logic', 'elementary-set-theory']"
1878956,Confusion about group theory; can you use the union as group operation?,"So I'm very, very new to group theory (I've know about it's existence for about a week now) and I'm a bit confused. I thought that for every set $S$,
$$(\{x\in\mathcal{P}(S)\ |\ |x|\leq0.5|S|\},\cup)$$
Is a group. So I checked the axioms. It is obvious that:
$$\forall A,B\subset S\ :\ A\cup B\subset S$$
with $|A\cup B|\leq |A|$ and $|A\cup B|\leq |B|$, but $|A\cup B|\geq 0$. So we have closure. Now:
$$\forall S\ :\ \emptyset\in\mathcal{P}(S)\wedge|\emptyset|=0\leq0.5|\mathcal{P}(S)|$$
$$\forall S\ :\ S\cup\emptyset=S$$
So $\emptyset$ is our identity element. We know that the union is associative. $S$ contains $|S|$ unique elements, but all elements of $\{x\in\mathcal{P}(S)\ |\ |x|\leq0.5|S|\}$ contains at most $0.5|S|$ unique elements, which means that:
$$\forall a \in\{x\in\mathcal{P}(S)\ |\ |x|\leq0.5|S|\}\ :\ (\exists b \in \{x\in\mathcal{P}(S)\ |\ |x|\leq0.5|S|\}\ :\ a\cup b = \emptyset)$$
Hence, we have inverses. All axioms are checked, so $(\{x\in\mathcal{P}(S)\ |\ |x|\leq0.5|S|\},\cup)$ should be a group for every set $S$. Now here's my problem; the cancellation law doesn't work and elements have multiple different inverses. It looks like the proofs of both the cancellation law and the unique inverse law are independent of the operation and only need the four axioms. So where did I go wrong?","['group-theory', 'elementary-set-theory']"
1878957,Prove that: $ \sum_{1}^{n}{ \cos^2{x_i}} \le n\cos^2{\frac{\pi}{2n}}$,"I am looking for a proof of the problem following: Let $0 < x_i < \pi/2$ for $i=1, 2, 3,..., n$ and $\sum_{1}^{n}{ x_i=\pi/2}$ . Prove that:  $ \sum_{1}^{n}{ \cos^2{x_i}} \le n\cos^2{\frac{\pi}{2n}}$","['inequality', 'trigonometry']"
1878973,Real function with complex antiderivative $\frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x}\sqrt{x^2+1}}$?,"Consider this indefinite integral (I'm interested in the interval $x>0$): $$\int \frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x}\sqrt{x^2+1}}dx$$ By substitution: $$u=\sqrt{\frac{1}{2}+\frac{1}{2}\sqrt{1+\frac{1}{x^2}}}, \qquad x=\frac{1}{2u \sqrt{u^2-1}}$$ We get a closed form antiderivative: $$\int \frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x}\sqrt{x^2+1}}dx=\sqrt{2} \tanh^{-1} \sqrt{\frac{1}{2}+\frac{1}{2}\sqrt{1+\frac{1}{x^2}}} +C$$ Now the inverse hyperbolic tangent is real only for the argument in $(-1,1)$. But in our case the argument for all real $x$ is $ > 1$. How can the function with real values on $x>0$ have a complex antiderivative? Edit To be clear, this is the correct antiderivative. I.e. by differentiating it we get the function under the integral. How would you explain this without appealing to complex analysis, i.e. branches? This is a real valued function for positive $x$, so this can be given as an assignment to a first year calculus student for example Edit 2 The derivation of the antiderivative after the substitution: $$\int \frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x}\sqrt{x^2+1}}dx=\sqrt{2} \int \sqrt{\frac{1}{2}+\frac{1}{2}\sqrt{1+\frac{1}{x^2}}} \frac{dx}{\sqrt{x^2+1}}=\sqrt{2} \int u \frac{dx}{\sqrt{x^2+1}}$$ $$\sqrt{x^2+1}=x(2u^2-1)$$ $$dx=-x\frac{2u^2-1}{u(u^2-1)}du$$ $$\frac{dx}{\sqrt{1+x^2}}=-\frac{du}{u(u^2-1)}=\frac{du}{u(1-u^2)}$$ $$\int \frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x}\sqrt{x^2+1}}dx=\sqrt{2} \int \frac{du}{1-u^2}=\sqrt{2} \tanh^{-1} u$$","['indefinite-integrals', 'complex-analysis', 'integration', 'calculus']"
1879001,To find area of the curves that are extension of ellipse,"I like to draw an ellipse via 2 fixed points and a rope between the fixed points (2 focuses). I wanted to extend the idea.  Point A,B,C,D are fixed points and Point E can move freely. Point E,B,C have small pulleys without friction and also their perimeters are very small. (Take zero for theoretical calculation) If we fix a rope on Point A then it goes Point E and then Point B then C then E and finally fix again on Point D as shown figure above. 
If we move E while the rope stretched, we can draw a curve similar to ellipse. We can express the  equation of the closed curve as shown graph above  : $$\sqrt{(x+a)^2+y^2}+\sqrt{(x+b)^2+y^2}+\sqrt{(x-a)^2+y^2}+\sqrt{(x-b)^2+y^2}=l-2b$$ Where $l$ is lenght of the rope. This is a symmetric curve over x and over y lines like ellipse. My questions: Is there any special name of this kind of curves? What is the area formula of such closed curve? Is the formula similar like circle and ellipse  starts with $\pi$ such as $\pi.f(a,b,l)$ ? I tried polar coordinate transform but I could not find the area. We can do many combinations with different number of fixed points. There is no limit of such closed curves : Another example is: 3 fixed points (one fixed point is with a small pulley) We can get this curve if we select Point B and C in same point $P(x_1,y_1)$ in figure above. $$\sqrt{(x+a)^2+y^2}+2\sqrt{(x-x_1)^2+(y-y_1)^2}+\sqrt{(x-a)^2+y^2}=l$$ First of all, I focused on the simplest case (2 fixed end point, 1 fixed point with pulley on origin) We can get this curve if we select $b=0$ in figure above. $$\sqrt{(x+a)^2+y^2}+2\sqrt{x^2+y^2}+\sqrt{(x-a)^2+y^2}=l$$
$x=r\cos \alpha$ $y=r\sin \alpha$ $$\sqrt{r^2+a^2-2ax}+2r+\sqrt{r^2+a^2+2ax}=l$$ $$2r^2+2a^2+2\sqrt{r^2+a^2-2ax}\sqrt{r^2+a^2+2ax}=(l-2r)^2$$ $$2\sqrt{r^2+a^2-2ax}\sqrt{r^2+a^2+2ax}=2r^2-4rl+l^2-2a^2$$ $$4(r^2+a^2-2ax)(r^2+a^2+2ax)=(2r^2-4rl+l^2-2a^2)^2$$ $$4(r^2+a^2)^2-16a^2x^2=(2r^2-4rl+l^2-2a^2)^2$$ $$4(r^2+a^2)^2-16a^2r^2\cos^2 \alpha =(2r^2-4rl+l^2-2a^2)^2$$ $$4(r^2+a^2)^2 -(2r^2-4rl+l^2-2a^2)^2=16a^2r^2\cos^2 \alpha$$ $$(4r^2-4rl+l^2)(4a^2+4rl-l^2)=16a^2r^2\cos^2 \alpha$$ If we expand the terms, We will have a polynomial with degree $3$. $r^3+(m+n\cos^2 \alpha)r^2+tr+k=0$ And my aim is to find  the area of the closed curve. $$A = 4 \int_{0}^{\pi/2} \frac{r^2}{2}  d \alpha $$ I am stuck in this point because I do not see the solution easy after here.
Please help me if you see how to solve the integral. Thanks a lot for helps Note:We can easily find the points on X axis of the curve ,$ (+\frac{l}{4},0) ; (-\frac{l}{4},0)$ And the point on Y axis of the curve , $(0,+\frac{l}{4}-\frac{a^2}{l}) ; (0,-\frac{l}{4}+\frac{a^2}{l})$","['polar-coordinates', 'elliptic-integrals', 'geometry', 'conic-sections', 'area']"
1879019,How to compute the limit of $\frac{n}{n^2+1^2}+\frac{n}{n^2+2^2}+\frac{n}{n^2+3^2}+\cdots+\frac{n}{n^2+n^2}$ without using Riemann sums?,How to compute the limit of $\frac{n}{n^2+1^2}+\frac{n}{n^2+2^2}+\frac{n}{n^2+3^2}+\cdots+\frac{n}{n^2+n^2}$ without using Riemann sums? My Try: I have Solved It using Limit as a Sum (Reinman Sum of Integral.) But I did not understand How can I solve it Using Sequeeze Theorem or any other way.,['limits']
1879028,"Is there any measure of ""randomly defined"" functions?","I was wondering about the following: Lets assume that you have a function like $f(x)=x$ and you measure your function by taking an integral from $0$ to $1$, which gives you: $$
\int_{0}^{1} x \; {\rm d}x = \frac{1}{2}
$$ Ok, now let's imagine that we randomly reorder in a unique way the function. I mean, once you've reordered it, every input $x \in [0, 1]$ will produce another value randomly from $f([0,1])$, but once this value $f(x)$ has been assigned to $x$, the function has been defined at x , which means that next time you evaluate $f$ at $x$, you will get the same $f(x)$ previously defined. And important: the function is bijective in our case. So let's call our randomly reordered function $f^R$. Here there is a ""summary figure"": So, my intuition says that: The set of points that belong to $f^R$ is dense in $\mathbb{R}^2$ at least for the square depicted in the figure. The integral from $0$ to $1$ should be the same and the are of this function between $0$ and $1$ should be $\frac{1}{2}$. This is not a strong intuition, but a doubt: is $f^R$ continuous? Am I right with my intuition? There exist any measure that allows to measure this set and assign it 1/2? Many thanks in advance!! EDIT: @Shai user has pointed something very disturbing. If we randomly reorder f, we could end up the curve $f^R = (x, x^2)$, so the area below the curve would be less than 1/2. This could be solved saying that we set a random reordered $f^R$ so any point $P \in [0,1]^2$ is an accumulation point of the points $Q = (x, f^R(x)) \in f^R$, which implies that the function is dense in $[0, 1]^2$ (by $[0, 1]^2$ I mean the square depicted in the figure).","['lebesgue-measure', 'continuity', 'integration', 'lebesgue-integral', 'measure-theory']"
1879048,Applications of Non-Standard Analysis to Number Theory and Topology?,"S.E friends, I am wondering what might be some useful applications of the non-standard analysis to the number theory and topology?  I am very interested in the set-theoretic topology and prime distributions, and I recently came across the field of non-standard analysis...The use of infinitesimal is interesting but I am not sure how can it be applied to my fields of interest. Do infinitesimals offer different perspective to the analytic number theory and topology?","['analytic-number-theory', 'nonstandard-analysis', 'number-theory', 'soft-question', 'general-topology']"
1879126,Examples of $c_1^2(L)$ of determinant line bundle of Spin^c structure,"I'm interested in $c_1^2(L)$ where $L$ is the determinant line bundle associated to a $Spin^c$ structure on a compact oriented four-manifold $X^4$. Specifically I'd like to know the numerical value of this characteristic number for some simple examples; let's say $\mathbb{CP}^2\#\overline{\mathbb{CP}^2}$ and $\mathbb{CP}^2\#\overline{\mathbb{CP}^2}\#\overline{\mathbb{CP}^2}$. I've seen this number show up while reading about Seiberg-Witten theory but I can never find any sources that give it's value on an actual manifold. Any reference to a source which has calculated some of this would be excellent. As an alternative or add-on, what methods are/would be used to calculate such a thing? My knowledge about characteristic classes is pretty weak. (Speaking of which, one misc. question: Is this class sensitive to orientation? i.e. does it change sign if one changes the orientation of $X$?) Thank you for any information.","['algebraic-topology', 'characteristic-classes', 'low-dimensional-topology', 'differential-geometry']"
1879149,Approximation of a monotone function by continuous functions,"Let $\mu$ be a Radon measure on $\mathbb{R}$. ( i.e. , a locally finite Borel measure) Let $I$ be an interval of $\mathbb{R}$. Let $\gamma : I \mapsto \mathbb{R}$ be a monotone function that is Lebesgue-Stieltjes integrable with respect to $\mu$:
$$\int_I \gamma(x) \mathrm{d}\mu (x) < \infty.$$ I would like a simple argument to prove that there exists a sequence $(\gamma_n)_{n\in\mathbb{N}}$ of continuous and monotone functions $\gamma_n : I \mapsto \mathbb{R}$ such that 
$$\int_I \gamma_n(x) \mathrm{d}\mu (x) < \infty$$
and
$$\lim_{n\to\infty} \int_I | \gamma(x) - \gamma_n (x)| \mathrm{d}\mu (x) =0.$$ I have thought I could use the Lusin theorem , but it would require to adapt its statement and proof to show the approximating functions are monotone.
Besides, my hypotheses are much simpler ($\mathbb{R}$, no compacity of the support of approximating functions). So maybe a weaker theorem could give the answer? I am interested by any reference to such theorem. N.B.: a proof of this is very common if $\mu$ is the Lebesgue measure, but here there is no absolute continuity assumption on $\mu$.","['approximation-theory', 'measure-theory']"
1879150,Proof verification: powers of a group element of finite order are distinct,"I'm finally attempting to conquer D&F (3rd ed) and I want to build good proof habits and fix mistakes early on. Here is the exercise (Ch. 1 ex. 32) and the following is my proof. Prove that for $x \in G$, where $G$ is a group and $x$ has finite order $n$, all of $1, x, x^2, \ldots, x^{n-1}$ are distinct and deduce that $|x| \leq |G|$. Proof. Let $a,b \in [0,n-1]\cap \mathbb{N}$ such that $x^a=x^b$. Then $1 = x^ax^{-a}=x^bx^{-a} = x^{b-a}$. Since $1 \leq a \lt n$ and $1 \leq b \lt n$, $b-a\lt n$. So $x^{b-a}=1 \implies b-a=0$ and $a=b$. Since $a$ and $b$ were arbitrarily chosen, $x^c$ is distinct for all $c \in [0,n-1] \cap \mathbb{N}$. We know $x^c\in G$ for all $c \in [0, n-1]\cap \mathbb{N}$ by definition of group closure, and $|[0,n-1]\cap \mathbb{N}|=n$. So $G$ contains at least $n$ elements, and $|x|\leq |G|$. Is this a convincing proof? I feel like there might be some circular logic, and perhaps not enough detail. I was thinking of establishing that the elements form a cyclic group, and show this group is a subgroup of $G$. Any tips or comments would be greatly appreciated.","['abstract-algebra', 'group-theory', 'proof-verification']"
1879177,"Example:$f_n\rightarrow f$, $f$ is continuous but $f_n\nrightarrow f$ uniformly.","I am trying to find a counter example to the converse of the statement ""uniform limit of continuous functions is continuous.""","['functional-analysis', 'real-analysis', 'calculus']"
1879181,Is the graph of $(\cos x)(\sec x)$ discontinuous?,"I suspect that the graph of $\cos x\times \sec x$ must be discontinuous because,at $x=90^0$ the function becomes $\frac{0}{0}$ so it must be undefined or just point to nothing on the graph at that point. But,Desmos and Wolfram gives me the plot of the function as a straight line passing through $(0,1)$ without any discontinuation. So,which one is correct?Am I wrong in thinking that $\cos x\times\sec x=1$ is not true for all values of $x$? Wolfram- Desmos- Note:-Same goes for $(\sin x)(\text{cosec} x)$ and $(\tan x)(\cot x)$.","['trigonometry', 'functions', 'graphing-functions']"
1879182,What is the $\lim_\limits{x \to 1+}\left(\frac{3x}{x-1}-\frac{1}{2 \ln(x)}\right)$?,"What is the limit of $$\lim_\limits{x \to 1+} \left(\frac{3x}{x-1}-\frac{1}{2 \ln(x)} \right)$$ I attemped the problem using L^Hopital's Rule. My Work $$\lim_\limits{x \to 1+} \left(\frac{3x}{x-1}-\frac{1}{2 \ln(x)} \right)$$
$$\lim_\limits{x \to 1+} \left(-\frac{3}{(x-1)^2}+\frac{1}{2 \ln^2(x)\cdot x} \right)$$
$$\frac{-3+1}{0}=\frac{-2}{0}$$ The answer is suppose to be $\infty$. I know what I did is probably not right.","['derivatives', 'calculus', 'limits']"
1879198,"What is the relation between Neighbourhood of a point,Interior point and open set?","I want to know what is the relation between of Neighbourhood of a point,Interior point and open set? Definition: A set $N \subset \mathbb{R}$ is called the $\textbf{neighbourhood}$ of a point a, if there  exists an interval I containing a and contained in N, i.e ,$$a\in I \subset N $$. Definition: A point x is an interior point of a set S if S is a nbd of x. In other words, x is an interior point of S if $\exists $ an open interval $(a,b)$ containing x and contained in S , i.e., $$x\in(a,b)\subseteq S$$. Definition: A set S is said to be open if it is a nbd of each of its point, i.e, $x\in S$, there exists an open interval $I_x$ such that $$mx \in I_x \subseteq S $$.","['general-topology', 'real-analysis']"
1879215,Extension of Likelihood-density,"Given an observation scheme, say $(X_1,X_2,\ldots,X_n)$ where $X_i$ evolves to one measure, one can define the likelihood function, a parameter dependend density of the form
$$
L_n:=L(X_1,\ldots,X_n\mid\theta)
$$
This is a density wrt to a  measure say $P^n$. Thus there exists a measure e $Q^n$, such that $L_n$ is the radon-nikodym-derivative. However, for assumptions about consistency of an estimator one lets $n\rightarrow \infty$ can we expect a measure $Q^{\infty}?$","['stochastic-processes', 'statistical-inference', 'probability-theory', 'statistics', 'probability']"
1879235,Likelihood function of $\sigma^2$ for two normal populations,"I'm working through problem 9.86 in Wackerly's ""Mathematical Statistics with applications, 7th ed."" The essence of the problem is: Given two samples: $X_1,X_2,\ldots,X_m$ from a normal population with mean $\mu_1$ and variance $\sigma^2$ and $Y_1,Y_2,\ldots,Y_n$ from a different normal population with mean $\mu_2$ but the same variance $\sigma^2$, find the maximum likelihood estimator for the common variance $\sigma^2$. Assume that $\mu_1$ and $\mu_2$ are unknown. The solution to this problem gives the likelihood function as $$L(\sigma^2)=(2\pi\sigma^2)^{\frac{-(m+n)}{2}}\exp\left(-\frac{1}{2\sigma^2}\left [\sum_{i=1}^m (x_i-\mu_1)^2-\sum_{i=1}^n (y_i-\mu_2)^2\right]\right)$$ However, I don't understand why there is a difference of sums in the exponential function. If I understand correctly, the likelihood function is obtained by taking the product of each sample density since they're independent, so $$L(\sigma^2)=\prod_{i=1}^m \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(\frac{-(x_i-\mu_1)^2}{2\sigma^2}\right) \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( \frac{-(y_i-\mu_2)^2}{2\sigma^2}\right)$$ which would simplify to $$L(\sigma^2) = (2\pi\sigma^2)^{\frac{-(m+n)}{2}} \exp\left(-\frac{1}{2\sigma^2}\left[\sum_{i=1}^m (x_i-\mu_1)^2+\sum_{i=1}^n (y_i-\mu_2)^2\right]\right)$$
where the two sums are added in the exponent. Did I go wrong somewhere or is it an error in the textbook?","['maximum-likelihood', 'statistics', 'probability-distributions']"
1879251,Role of Radon-Nikodym theorem in definition of conditional probabilities,"Let $(\Omega,\mathscr{F},P)$ be a probability space and $\mathscr{G}\subset\mathscr{F}$ a $\sigma$-field contained in $\mathscr{F}$. If we define the finite measure v on $\mathscr{G}$ by $\text{v}(G)=P(A\cap G)$ for all $G\in\mathscr{G}$, then my question concerns the role of the Radon-Nikodym theorem in the definition of conditional probabilities used by Patrick Billingsley (1995) in his textbook ""Probability and Measure"", which he denotes by $P[A\|\mathscr{G}]$, and defines by; i) $P[A\|\mathscr{G}]$ being measurable $\mathscr{G}$, ii) $\int_G P[A\|\mathscr{G}] \, dP=P(A\cap G):=\operatorname{v}(A\cap G)$ for all $G\in\mathscr{G}$. If $P_0$ is $P$ restricted to $\mathscr{G}$, then since $\operatorname{v}\ll P_0$ for $P_0<\infty$, and therefore $\operatorname{v}<\infty$, I think I can see that the Radon-Nikodym theorem guarantees the existence of a real-valued, non-negative and $\mathscr{G}$-measurable function $f$, integrable w.r.t $P_0$ and hence $P$, satisfying i) and ii). Billingsley then labels $f:=P[A\|\mathscr{G}]$ (note: the definition above uses $P$ not $P_0$ I think since $\operatorname{v}(G)=\int_G f \, dP=\int_G f \, dP_0$ for all $G\in\mathscr{G}$). My question is why does the Radon-Nikodym theorem guarantee that $f$ is a probability, since as far as I can tell it only guarantees it is non-negative? I can see that $f$ is a random variable with source probability space $(\Omega,\mathscr{F},P_0)$ and target space $(\mathbb{R},\mathscr{R},\mu)$ where $\mu$ is the distribution of $f$ satisfying $\mu(A)=P_0[f\in A]$ for all $A\in\mathscr{R}$, but that doesn't mean $f$ always lies in $[0,1]$ and so can be considered a probability?","['probability-theory', 'probability', 'measure-theory']"
1879252,Path integral of $1/(z^2-1)$ along $|z|=2$,"I would like to calculate the path integral $S$ of $1/(z^2-1)$ along the curve $|z|=2$. Using the parametrization $y: [0, 2\pi] \rightarrow \mathbb{C}, y(t)=4e^{it}$ and the partial fraction expansion $1/(z^2-1) = -(1/2)/(z+1) + (1/2) / (z-1)$ we get $S=\int_y 1/(z^2-1) dz = \int_y-(1/2)/(z+1) dz+ \int_y(1/2) / (z-1)dz$. So to calculate the first integral we would need to determine $\int_{[0, 2\pi]}e^{it}/(4e^{it}+1)dt$, and a similar expression for the second integral. How can we continue from here?","['complex-analysis', 'integration', 'contour-integration', 'analysis']"
1879257,"What does being ""Linear"" mean for a transformation and a function intuitively/graphically?","I was wondering what is the geometric meaning or intuition behind a transformation and function(separately)being linear. An example(or graph) illustrating the characteristics of a linear function/map would be much appreciated. Thanks in advance. EDIT: Also, I have read that if we ""zoom in"" the graphs of some functions, we see that they ""become linear around the point of magnification""(you can find it in Callahan's Advanced Calculus"". What does that mean?","['multivariable-calculus', 'linear-transformations', 'geometry', 'linear-algebra', 'vector-analysis']"
1879278,How does choice of sheaf affect what you’re measuring with cohomology?,"Can someone please explain, in intuitive terms, the difference between $H^1(X,\mathscr{O})$ and $H^1(X, \Omega)$ where $X$ is a Riemann surface, $\mathscr{O}$ is the sheaf of holomorphic functions on $X$, and $\Omega$ is the sheaf of holomorphic differential forms on $X$? It might be illuminating to refer to the case of $X = \mathbb{P}^1$, in which case $H^1(X,\mathscr{O})$ is trivial and $H^1(X, \Omega)$ is a one-dimensional vector space generated (in some sense) by $dz/z \in \Omega(\mathbb{P}^1 \setminus \{0,\infty\})$. First cohomology with respect to $\mathscr{O}$ measures the number of handles (the genus). The Riemann sphere has none of these. But what does the Riemann sphere have one of, according to $\Omega$?","['complex-geometry', 'algebraic-geometry']"
1879296,Evaluation of $\lim_{n \to \infty} ((n+1)!\ln (a_n))$,Consider the sequence $(a_n)_{n \geq1}$ such that $a_0=2$ and $a_{n-1}-a_n=\frac{n}{(n+1)!}$. Evaluate $$\lim_{n \to \infty} ((n+1)!\ln (a_n))$$ Could someone hint me as how to achieve value of $a_n$ from given information.,"['closed-form', 'calculus', 'limits']"
1879301,Motivation behind notation for tangent space,"The notes I am reading cover differential geometry at only a very basic level (say around Do Carmo's Differential Geometry of Curves and Surfaces ), so I apologize in advance if this question would be considered incredibly misguided for anyone with a substantial knowledge of the subject. Here is the definition of tangent space which I have: Let $M \subset \mathbb{R}^n$ be open. Then $TM := M \times \mathbb{R}^n$ is called the tangent bundle of $M$. For $p \in M$, $T_pM := \{ p \} \times \mathbb{R}^n$ is called the tangent space of $M$ at $p$. $\dots$ If now $f: M \subset \mathbb{R}^n \to \mathbb{R}^m$ smooth, then we consider the differential of $f$ to be a map $df: TM \to T\mathbb{R}^m,$ and $d_p f:T_p M \to T_{f(p)}\mathbb{R}^m$. $\dots$ Let $S \subset \mathbb{R}^3$ be an embedded surface, $q \in S$ be a point of $S$, and $f: U \to \mathbb{R}^3$ be a parametrization of $S$ such that $f(p)=q$. The tangent space of $S$ at $q$ is defined to be $T_q S := (d_p f)(T_p U) \subset T_{f(p)} \mathbb{R}^3$ and the tangent bundle $TS \subset T\mathbb{R}^3$ of $S$ is $TS := \bigcup\limits_{q \in S} T_q S$. My question: Why the notation $T_pU$? The $U$ here does not provide any useful information about the nature of the object. All it says is that $p \in U$, which seems almost redundant. The most important aspect of the definition is that $T_p U \simeq \mathbb{R}^n$, but this is impossible to deduce from the notation $T_pU$. I find it very difficult to understand any discussion of tangent spaces using this notation unless ample context about the ambient spaces is given nearby, which it usually isn't. Why would anyone care more about $p \in U$ than the fact that $T_p U \simeq \mathbb{R}^n$? What am I missing?","['terminology', 'notation', 'differential-geometry', 'soft-question']"
1879311,Finding Marginal PDF from Joint PDF [Problem with Limits of Integration],"$$f(x,y) = \begin{cases} \dfrac{x^2+y}{4} & 0<x<y<2 \\[8pt]
0 & \text{otherwise}
\end{cases}
$$ Find Marginal PDF for $x$ and $y$. I know the formula is 
$\int^\infty_{-\infty} f(x,y)\,dy = $ Marginal PDF for $x$ and the same for $y$ just the integral with respect to $x$. However I don't understand what limits for integration I should use or how to go about finding them.","['multivariable-calculus', 'probability-distributions']"
1879366,application of the Euler-Lagrange / Beltrami equation,Let $$S(\theta)=\int_0^{2\pi}\sqrt{\dot \theta^2(t)+\cos^2(\theta(t))}dt$$ a) How does the Euler-Lagrange equation for S look? b) Show that the solutions of the Euler-Lagrange equation are given by $\theta (t)=\arctan(a\sin(t)+b\cos(t))$. Use the substitution $u=\tan(\theta)$. What I did: a) I've got: $$-\frac{\sin\theta\cos\theta}{\sqrt{\dot\theta^2+\cos^2\theta}}-\frac{d}{dt}\frac{\dot\theta}{\sqrt{\dot\theta^2+\cos^2\theta}}=0$$ Is this correct? b) I've got for the Beltrami equation $\frac{\dot\theta^2}{\sqrt{\dot\theta^2+\cos^2\theta}}-\sqrt{\dot\theta^2+\cos^2\theta}=c$. So from this I get $-\cos^2\theta=c\sqrt{\dot\theta^2+\cos^2\theta}$. Now with $u=\tan\theta$ I get $1/c^2-1=u^2+\dot u^2$ with the chain rule. I think I did something wrong in the substitution. Is it ment $u(t)=\tan(\theta(t))$? Thats what I tried. Does someone know a link where I could read through some examples similar to this porblem? Maybe some with a boundary condition too?,"['reference-request', 'real-analysis', 'calculus-of-variations', 'ordinary-differential-equations']"
1879378,"A text that can accompany this Course on ""Geometry for theoretical physics""","Dr. Fredric Schuller has uploaded a course on youtube ( here ) that is intended to cover the geometry which is used the study of theoretical physics. His treatment is mathematically rigorous (I've watched the first $6$ lectures or so). He has mentioned a ""textbook"" many times during the lectures but he never explicitly mentions  the name of that textbook. I've sent him a message asking for the name of the textbook but a response was never received. So, I wonder if you can recommend any textbook that can go along with those lectures. The text need not  contain logic nor set theory nor general topology since those are familiar topics for me, so it's not an issue at all if the text does not cover those. The rest is what matters for me. Here are the topics covered in the lectures: Introduction/Logic of propositions and predicates- 01 Axioms of set Theory - Lec 02 Classification of sets - Lec 03 Topological spaces - construction and purpose - Lec 04 Topological spaces - some heavily used invariants - Lec 05 Topological manifolds and manifold bundles- Lec 06 Differentiable structures definition and classification - Lec 07 Tensor space theory I: over a field - Lec 08 Differential structures: the pivotal concept of tangent vector spaces - Lec 09 - Construction of the tangent bundle - Lec 10 Tensor space theory II: over a ring - Lec 11 Grassmann algebra and deRham cohomology - Lec 12 Lie groups and their Lie algebras - Lec 13 Classification of Lie algebras and Dynkin diagrams - Lec 14 The Lie group SL(2,C) and its Lie algebra sl(2,C) - lec 15 Dynkin diagrams from Lie algebras, and vice versa - Lec 16 Representation theory of Lie groups and Lie algebras - Lec 17 Reconstruction of a Lie group from its algebra - Lec 18 Principal fibre bundles - Lec 19 Associated fibre bundles - Lec 20 Conncections and connection 1-forms - Lec 21 Local representations of a connection on the base manifold: Yang-Mills fields - Lec 22 Parallel transport - Lec 23 Curvature and torsion on principal bundles - Lec 24 Covariant derivatives - Lec 25 Application: Quantum mechanics on curved spaces - Lec 26 Application: Kinematical and dynamical symmetries - Lec 28","['reference-request', 'tensors', 'mathematical-physics', 'geometry', 'manifolds']"
1879389,Markov chain state time,"I have a question regarding markov chains in continuous time. I have a birth/death process(for every step we go 1 up & or 1 down), queue with 4 states. Customers arrive with the intensity of lambda per hour and can be seen as poisson distributed. The time to serve each customer can be seen as exponentially distributed and independent. We start at time = 0 and state = 0. We are going to do 100 steps. State 0 => There is no customers. (Arrival rate = 2, Departure rate = 0) State 1 => There is one customer being served. (Arrival rate = 2, Departure rate = 10) State 2 => There is one customer being served + 1 in queue. (Arrival rate = 2, Departure rate = 10) State 3 => There is one customer being served + 2 in queue. (Arrival rate = 0, Departure rate = 10) Givens: 
Arrival rate = 2. 
Depature rate = 10. Is there a formula to calculate the total time spent in each state?","['markov-chains', 'statistics', 'queueing-theory']"
1879430,"Closed form for this integral with Beta function $\int_0^\infty x \mathrm B (x,x)~dx$","Is it possible to find the closed form of $$\int_0^\infty x \mathrm B (x,x)~dx=2.44333\dots$$ This integral converges because for small $x$ Beta function behaves like $2/x$. Using the integral definition of the Beta function, we can transform it to the following forms: $$\int_0^\infty x \mathrm B (x,x)~dx=\int_0^1 \frac{dt}{t(1-t) \ln^2 (t(1-t))}=^{t(1-t)=z}$$ $$=2 \int_0^{1/4} \frac{dz}{z \sqrt{1-4z} \ln^2 z}=^{4z=\sin^2 y}= \int_0^{\pi/2} \frac{dy}{\sin y \ln^2 (\sin (y)/2)}$$ Another substitution will get rid of the logarithm: $$=2 \int_0^{1/4} \frac{dz}{z \sqrt{1-4z} \ln^2 z}=^{z=\exp (-u)}=2 \int_{ \ln 4}^{\infty} \frac{du}{u^2\sqrt{1-4 \exp (-u)}}=^{v=1/u}$$ $$=2 \int_0^{ 1/ \ln 4} \frac{dv}{\sqrt{1-4 \exp (-1/v)}}$$ However, I have not been able to proceed further to some special function or even a series. It might surrender to residues, but I'm useless with them. Edit Trying integration by parts. Take $u=1/\sqrt{1-4z}$ and $dv=dz/(z \ln^2 z)$ $$\int_0^{1/4} \frac{dz}{z \sqrt{1-4z} \ln^2 z}=-\frac{1}{\ln z \sqrt{1-4z}} |_0^{1/4}+2 \int_0^{1/4} \frac{dz}{(1-4z)^{3/2} \ln z}$$ Not working out, the first part blows up at the limits. A series solution in terms of elementary functions would be acceptable too! I've found one, but with incomplete Gamma function, which is just an integral in disguise (see my answer).","['special-functions', 'integration', 'definite-integrals', 'beta-function']"
1879431,Adjoint Operator and Subspaces of Hilbert Spaces,"Let $H_1$ , $H_2$  Hilbert Spaces with $T:H_1 \to H_2$ adjoint operator  and $M_1 < H_1$ , $M_2 < H_2$ their subspaces. Show that: $T(M_1) \subset M_2 $ if, and only if, $T^*({M_2}^{\perp}) \subset {M_1}^{\perp} $","['functional-analysis', 'adjoint-operators', 'hilbert-spaces']"
1879460,Is the normal bundle of an orientable submanifold of an orientable manifold always trivial?,"There is another question on this site which confirms that for an orientable hypersurface of an orientable manifold, the normal bundle is trivial. However, I was wondering if this result generalises to arbitrary orientable submanifolds.","['vector-bundles', 'differential-geometry']"
1879480,number of combinations that each item has been exists at lease once with repetition?,"Suppose there exists 3 letters and it is required to choose 4 letter from them (repetition is allowed). This 3 letters should be selected at least once and the order is important. An example suppose we have letter a,b,c
we can have:
abca
abcb
abcc
cbaa
bacc
and 
so on. What is the formula for this example?
what is the general formula when we have n letter and combination with length r?","['combinations', 'discrete-mathematics']"
1879487,Union of two denumerable sets is denumerable,"Good night. I have a problem with this exercise: Prove that the union of two denumerable sets is denumerable. Proof: Be $A,B\subset\mathbb{R}$ where A and B are numerable, in other words $f:\mathbb{N\rightarrow}A$ biyective and $g:\mathbb{N\rightarrow}B$. Be $h:\mathbb{N\rightarrow}A\cup B$ and suppose: $A=\left\{ a_{1},a_{2},a_{3},...\right\} $ $B=\left\{ b_{1},b_{2},b_{3},...\right\} $ I construct a function biyective such that $1\rightarrow a_{1}$ $2\rightarrow b_{1}$ $3\rightarrow a_{2}$ $4\rightarrow b_{2}$ $.$ $.$ $.$ Where $h(x)=\begin{cases}
2k+1\rightarrow a_{k}\:k\epsilon\mathbb{N}\\
2k\rightarrow b_{k}\:k\epsilon\mathbb{N}
\end{cases}$ If we see the function $h(x)$ she is $\mathbb{N}$ in other words, $A\cup B$=$\mathbb{N}$ then $h:\mathbb{N\rightarrow}A\cup B$ is biyective. But i feel my proof is too bad, can someone help me?",['elementary-set-theory']
1879490,When is a disconnected subset of a topological space 'disconnected in the total space'?,"A subset $Y$ of a topological space $X$ is disconnected if the subspace topology on $Y$ is disconnected. I'll define $Y$ to be 'disconnected in $X$' if there exists open $U,V$ (in $X$) such that
$$ U \cup V \supseteq Y \qquad \mathrm{and} \qquad U \cap V = \varnothing \qquad \mathrm{and} \qquad U \cap Y \neq \varnothing \neq V \cap Y $$
In general, a disconnected subset $Y$ is not necessarily disconnected in $X$. As this question shows, we may be able to engineer a topology on $X$ that ensures any two open sets in $X$ that respectively contain the two disconnected components of $Y$ in the subspace topology always intersect, somewhere outside $Y$. To repeat the example, consider:
$$ Y = \{1,2\} \qquad X = \{1,2,3\} \qquad T_X = \{\varnothing, \{3\} ,\{1,3\},\{2,3\}, X\} $$
Then $T_Y$ is discrete and disconnected, but there are no two open sets in $X$ that satisfy the requirements above. My question, then, is: are there certain conditions on $X$ that ensure any disconnected subset of $X$ is 'disconnected in $X$'? For instance, a disconnected subset $Y$ will be 'connected in $X$' if the two disconnected components (taken as subsets of open sets in $X$) always intersect somewhere outside the subset, but it seems to me that this will force the space to be non-Hausdorff. However, I couldn't prove this was true, and my intuition for topology is not very good, so I wanted to ask a) whether disconnected subsets of Hausdorff spaces are always 'disconnected in $X$' and b) if not, whether there was some other class of topological space for which this was true. Thank you.","['general-topology', 'connectedness']"
1879498,Every subspace of the dual of a finite-dimensional vector space is an annihilator,"Exercise 26 page 115 of Linear Algebra Done Right by Sheldon Axler is the following: Suppose $V$ is finite-dimensional and $\Gamma$ is a subspace of $V'$. Show that $$\Gamma=\{v\in V:\varphi(v)=0\text{ for every }\varphi\in\Gamma\}^0$$ where $V'$ is the dual space of $V$ and, for any $S\subset V$, $S^0$ is the annihilator of $S$. Attempt: Let $S=\{v\in V:\varphi(v)=0\text{ for every }\varphi\in\Gamma\}$. Clearly, $\Gamma\subset S^0$.I tried to show that $S^0\subset\Gamma$ using some bases of $V$ and $V'$, but I failed. I also tried to show that $\dim{\Gamma}=\dim{V}-\dim{S}=\dim{S^°}$. If $s_1,\dots,s_n$ is a basis of $S$ and $s_1',\dots,s_n'$ its dual, and if $\psi_1,\dots,\psi_p$ is a basis of $\Gamma$, it's easy to see that $s_1',\dots,s_n',\psi_1,\dots,\psi_p$ is a linearly independent list of $V'$. Also, if you extend $s_1,\dots,s_n$ to a basis $s_1,\dots,s_n,v_1,\dots,v_m$ of $V$, then its dual $s_1',\dots,s_n',v_1',\dots,v_m'$ is a basis of $V'$; in fact $S^0=\text{span}\{v_1',\dots,v_m'\}$. Two remarkable facts:$$\forall i\in[1,m],\,\exists j\in[1,p],\,\psi_j(v_i)\neq0$$ because $v_j\notin S$, and $$\forall i\in[1,p],\,\exists j\in[1,m],\,\psi_i(v_j)\neq 0$$ because $\psi_i\neq 0$; in other words the matrix of the inclusion map from $\Gamma$ to $V'$ with respect to the basis of $\Gamma$ and the dual base of the chosen basis of $V$ has no $0$ row nor $0$ column. But this doesn't seem to provide a way to prove that any linear comination of the $(v_i')_{1\le i\le m}$ is a linear combination of the elements of the basis of $\Gamma$. I believe that $v_1,\dots, v_m$ should be chosen more carefuly but I fail to. Could you please help me? Thank you in advance!","['duality-theorems', 'linear-algebra', 'linear-transformations', 'vector-spaces']"
1879502,Derivative of a constant not making sense,"I'm studying calculus on my own and I came across something weird: The derivative of $x^n$ is $n\cdot x^{n-1}$, and the derivative of any constant is $0$. Also, any constant $x = x^1$. However, the derivative of $x^1$ ($x$ being any integer constant) seems to be $1$: $n\cdot x^{n-1} = 1\cdot x^{1-1} = x^0 = 1$. What's failing in my reasoning?","['derivatives', 'calculus']"
1879509,What is the total area belonging to only one of four unit circles?,"Please forgive the crudeness of this diagram. (I took an image from some psychobabble website and tried to delete the larger circle that's not relevant to my question). Let's say these are four unit circles joined together such that each circle shares some area with two other circles. Obviously the total area not shared with other circles is four times the area of this (again please forgive the crude diagram) Or I could calculate the total are of a single ""petal"" and multiply that by $4$. But I have truly forgotten all the calculus and trigonometry I was taught more than half a century ago. Am I on the right track? Is there a better way than either of the two ideas I've had so far? P.S. Not sure if osculating circle tag applies.","['circles', 'geometry']"
1879536,Geodesics with respect to time-dependent Riemannian Metric,"I'm not sure where to look to solve a problem of this variety.  Does it potentially have to do with Ricci flow? Suppose we consider Euclidean space $\mathbb{R}^n$ and append to it a time-dependent metric of $A(t)$ where $A: \mathbb{R} \to SPD(n)$ is a smooth curve in the manifold of symmetric positive definite matrices $SPD(n)$.  Define the metric on $\mathbb{R}^n$ as $\langle u, v\rangle_t = u^TA(t)v$, in other words a time-dependent metric.  I'm trying to figure out how to find geodesics in $\mathbb{R}^n$ with respect to the same parameter $t$ that the metric is parameterized by.  I know the geodesic equations for an ordinary Riemmanian manfiold are given by $$
\frac{d^2\gamma^k}{dt^2} + \Gamma_{ij}^k \frac{d\gamma^i}{dt} \frac{d\gamma^j}{dt} \;\; =\;\; 0
$$ with $$
\Gamma_{ij}^k \;\; =\;\; \frac{1}{2} g^{km} \left ( \frac{\partial g_{im}}{\partial x_j} + \frac{\partial g_{jm}}{\partial x_i} - \frac{\partial g_{ij}}{\partial x_m} \right ).
$$ It's not clear to me how to approach this problem or if it is even well-posed.  Another way I suppose I can phrase this is: how does a curve $\gamma$ naturally ""flow"" with respect to this metric given the initial conditions $\gamma(0)$ and $\gamma'(0)$?  Can anyone offer any insights or references?  I would appreciate it if I knew a general approach to this problem, or if the problem needs to be posed differently.","['riemannian-geometry', 'differential-geometry']"
1879541,Prove ${n \choose k}^2 = \sum_{i=0}^{k}{n \choose i}{n-i \choose k-i}{n-k \choose k-i}$ using a combinatorial argument,"I've been studying for a final exam. I have gotten stuck on this one question that asks us to prove using a double-counting proof that
$${n \choose k}^2 = \sum_{i=0}^{k}{n \choose i}{n-i \choose k-i}{n-k \choose k-i}$$ I wish I could give an attempted answer, but I don't really know where to begin with this.Could someone please help me out? Thank You","['combinatorics', 'combinatorial-proofs']"
1879566,$f$ conformal $\implies$ $f$ ACL?,"In An Introduction to Teichmüller Spaces , by Imayoshi and Taniguchi, we have the following definition for an absolutely continuous function : where, I suppose, a function $g:I\to \mathbb{C}$ , $I \subset \mathbb{R}$ interval, is said to be absolutely continuous if, $\forall \epsilon>0$ , $\exists \delta>0$ such that, $$[x_k,y_k]\subset I, k\in \{1,\dots,n\}\text{ pairwise disjoint intervals with }\sum_{k=1}^n|y_k-x_k|<\delta$$ $$\implies\sum_{k=1}^n|f(y_k)-f(x_k)|<\epsilon.$$ The authors want to define quasiconformal mappings which are, in particular, ACL. The very first example given for quasiconformal mappings is, of course, the conformal ones. But while giving this example in the book, it is not shown that the conformal map is ACL (it is only discussed the other requirements, which are indeed easier to see). So my question is: $f:D\to \mathbb{C}$ conformal $\implies$ $f$ ACL? Is this due to some classical result? Thank you very much!","['complex-analysis', 'quasiconformal-maps', 'conformal-geometry', 'teichmueller-theory']"
1879568,The number of isomorphisms from $\mathbb{Z}_{12}$ to itself is 4.,"In a problem I am working on, I am asked to find the number of isomorphisms from  $\mathbb{Z}_{12}$ to itself using the fact that if $x$ generates a group $G$ and $\phi$ is an isomorphism from $G$ to itself, then $\langle \phi(x) \rangle=G$. I know that $1,5,7,$ and $ 11$ generate $G$ individually. So I am guessing that either I have to count the number of bijections on a 4 element set or, since $\langle \phi(1) \rangle=G$ and $\phi(k)=\phi(1)^{k\ mod 12}$, count the number of possible ways to map 1 to the set containing $1,5,7,$ and $ 11$. My initial thought is that since $\phi(1)$ completely determines this whole space we just need to count the number of possible mappings for $1$. If $\phi$, for example, assigns 1 to 5 and 11 to 7, then $\phi$ need not be well defined, right?","['combinatorics', 'group-theory', 'group-isomorphism']"
1879583,Conditional Probability : Total probability,"Let $H_1$ and $H_2$ be set of mutually exclusive events of which one necessarily occurs (i.e. union of $H_1$ and $H_2$ is the sample space). A is any event that can occur in conjunction with some $H_i$. So it is well known that
$P(A)=P(A\mid H_1)\cdot P(H_1)+P(A\mid H_2)\cdot P(H_2)$. But what will be an upper bound on this probability $P(A)$? I read it somewhere that we can consider $P(A)\leq P(A\mid H_1)+P(\overline{H}_1)$ where $H_2=\overline{H}_1$. What is the intuition behind it?","['probability-theory', 'probability']"
1879595,Geometric interpretation of positive semi-definiteness of sum of matrices,"I am trying to solve some convex optimization problems. $$
C = \{x \in R^n \mid x^TAx + b^Tx + c \leq 0\}
$$ where $A\in S^n, b\in R^n$ and $c\in R$ Question is to show that the intersection of $C$ and the hyperplane defined by $g^Tx + h = 0$ with $g\neq 0$ is convex iff $A + \lambda gg^T \succeq 0$ for some $\lambda \in R$ I am having a hard time to geometrically interpret that. Like how $A + \lambda gg^T$ can become positive semi-definite. I have solution to it here (Page # 8 Exercise 2.10 b) I am thinking it like using toy example in $R^2$ let 
$$A = \left[ \begin{array}{ccc}
-1 & 0 \\
0 & -1
 \end{array} \right], g = \left[ \begin{array}{ccc} 
2 & 2 \end{array}  \right]^T$$ Though I did some basic sum of  $A + \lambda gg^T$ and it makes it positive semi-definite (psd) but I want to understand geometric intuition behind it. Also I understood some part of solution where it is taking intersection of $C$ and $H$, but then I have no clue how he shifted it to sum of matrices. One thing I know from previous exercise that if a matrix is psd then set generated by its quadratic inequality would be convex. It would be great help if: 1) Someone could help me in understanding how summation of two matrices which are not necessarily psd, can make it psd? 2) ""How"" the information from eigendecomposition of $A$ can be used here? 3) Also I noticed that other matrix has linearly dependent rows so is it necessary that it should be linearly dependent or the other matrix could make the sum psd. P.S. This is not a homework. This is my understanding to this question that they want us to know that sum of matrices can make the matrix psd and the set generated by it, convex. Other intuition behind this exercise would be great help as well. Thanks.","['positive-semidefinite', 'convex-optimization', 'linear-algebra', 'convex-analysis']"
1879604,Convergence in measure iff convergence pointwise a.e.,"Let $(X,\mu)$ be a measure space and $E$ a measurable subset of $X$.  We say that, for real valued functions, $\{f_n\}$ converges in measure to $f$ on $E$ so long as $\{f_n\}$ and $f$ are measurable functions and $\forall\  \eta>0$, $\ \lim_{n\to\infty}\mu(\{x\in E\ :\ |f_n(x)-f(x)|>\eta\})=0$.  It can be shown that if $\mu(E)<\infty$, then convergence in measure on $E$ is equivalent to the following statement: $$\textrm{Every subsequence of }\{f_n\}\textrm{ has a further subsequence that converges pointwise a.e. to } f\textrm{ on } E$$
However, I have recently discovered that the following statements are equivalent: $$\{x_n\}\textrm{ is a sequence of real numbers that converges to } x$$
and $$\textrm{Every subsequence of }\{x_n\}\textrm{ has a further subsequence which converges to }x.$$ I'm afraid I must be missing something obvious, but, from what I have above, it seems that convergence in measure and pointwise a.e. convergence are the same thing.  I know this is not the case since I also have a counter example that works on the set $[0,1]$ with Lebesgue measure.  I reach the conclusion by recalling that pointwise a.e. convergence on $E$ is, for every $x\in E$  except for a set of measure 0, convergence of the sequence of real numbers $\{x_n\}$, defined by $x_n=f_n(x)$, to the number $f(x)$. Where is my logic flawed? Edit:  I believe I have figured out where my logic is flawed, but I'd like to see if another finds the same flaw before I answer my own question. Here is a link to show the second equivalency.
The first equivalency is an exercise in Royden and Fitzpatrick's Real analysis.","['real-analysis', 'real-numbers', 'measure-theory', 'convergence-divergence']"
1879619,How many solutions are there to $x_1 + x_2 + ... + x_5 = 21$? [duplicate],"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . How many solutions are there to the equation $x_1 + x_2 + x_3 + x_4 + x_5 = 21$ where $x_1, i = 1,2,3,4,5$ is a nonnegative integer such that $0 ≤ x_1 ≤ 3, 1 ≤ x_2 < 4$, and $x_3 ≥ 15$? I have correctly completed the previous parts of the question but am having trouble with this particular restriction. The total number of solutions to the equation is $C(25,21) = 12650$. I have tried to do each restriction individually: For $0 ≤ x_1 ≤ 3$, I solved this by subtracting the number of solutions when $x_1 ≥ 4$ from the total number of solutions. This is $C(25,21) - C(21,17) = 5985$. For $1 ≤ x_2 < 4$, I have $C(24,20) - C(21,17) = 5985$. For $x_3 ≥ 15$, I have $C(10,6) = 210$. However, the restriction is when these are all together. I am not sure how to proceed. The answer is $106$.","['combinations', 'combinatorics']"
1879626,"Subgroups, Stabilizers, and Orbits of the Dihedral group D12. Faster way?","Let $G = D_6$ be the dihedral group of the rigid motions of a regular hexagon and $X = \{H \subseteq G \mid H \leq G\}$. Consider the action of $G$ on $X$ by conjugation, that is, for $g \in G$, $H \in X$:
  $$
  g \cdot H = g H g^{-1}.
$$
  a) Find the stabilizer $G_H$ of $H$, for all $H \in X$. b) Find the orbit $G(H)$ of $H$, for all $H \in X$. c) Find the set of all orbits $X/G$. I'm working on this problem (note $D_6 = D_{12}$ in the more common notation). So far I've: Found all the subgroups of $D_{12}$ (all 16, I hope). Found the normalizer of each subgroup to get the stabilizers for each subgroup. (Is this correct since the action is conjugation?) Found the orbits via brute force. Found all the cosets of each $H$ and started constructing the orbits. However, all this is taking an ENORMOUSLY long time. So much so that I feel I'm missing a much more clever solution. Is there one?","['abstract-algebra', 'group-theory']"
1879673,"Unique, Continuous, Surjective, Closed Extension of Identity from Stone-Čech Compactification to Compactification","I have woven the below incomplete proof of the following claim: Claim . If $X$ is completely regular and $Y$ is a compactification of $X$,
  then there is a unique, continuous, surjective, closed map
  $g:\beta\left(X\right)\to Y$ which is the identity on
  $X$. Here, $\beta\left(X\right)$ is the Stone-Čech compactification of $X$. Proof . Let $f:X\to Y$ be such that $x\mapsto x$. Then $f$ is continuous. Since $f$ is continuous and $Y$ is compact and Hausdorff, it is the case that $f$ extends uniquely to a continuous map $g:\beta\left(X\right)\to Y$. Then $g$ is the identity on $X$. Let $C\subseteq\beta\left(X\right)$ be closed. Since $\beta\left(X\right)$ is compact, it is the case that $C$ is compact. Since $g$ is continuous, it is the case that $g\left(C\right)$ is compact. Since $Y$ is Hausdorff, it is the case that $g\left(C\right)$ is closed. Then $g$ is closed... I do not know how to show that $g$ is surjective. Am I allowed to use the ""maximality"" of $\beta\left(X\right)$? If so, then I believe that it would follow that $Y\subseteq\beta\left(X\right)$, which would imply that $g$ is surjective. I am not sure because this ""maximality"" is not defined in terms of containment.",['general-topology']
1879711,The tricky arithmetic of passing credit card fees to customers,"TL;DR , if I reverse a 2.9% transaction fee, why do I increase my price by specifically 102.9866132% ? Background In many provinces/states/countries, it is illegal to charge a convenience fee or surcharge for a credit card transaction. This is in dispute and in fact being reversed in some places, but for this exercise, let's add a nominal price to our product prices, building in the prospective transaction fee into the sale price, so our original sale price (and desired revenue) is recovered. Think of this as what Walmart, McDonalds and other retail stores already do to cover salaries, electricity, rent, transportation, packaging, etc. but in this case we're only recovering one variable, credit card transaction fees. My equation The transaction fee in question is 2.9% or 0.029 . So I came up with this equation, trying to recover the original price of the good, $$original\_price * fee = money\_received$$
$$x * y = z$$
$$z = 0.971x$$ trying to recover the original price $x$ as money received $z$ creates, $$z = x = 0.971xk$$
$$x = 0.971xk$$ when I ran the numbers manually using trial & error ( also plugging this into Wolfram Alpha to verify ) my answer for $k$ was, $$k = 1.02987$$ This means I would have to increase my prices by 102.987% to recover the transaction fee before it occurs (assuming credit card fees occur 100% of the time). I then tried to bring this from 5 decimal points to 10 and $k$ became, $$k = 1.029866132$$ Why THAT solution? If I began with trying to recover a 2.9% transaction fee and have to increase my sale prices by 102.9866132% , I'm curious as to why it's THAT number. Why is it not 102.9% ? Is there a mathematical theory about how these numbers work? Should I just leave it as is and accept the answer and not over think it? My spreadsheet","['algebra-precalculus', 'percentages', 'arithmetic']"
1879720,Definition of Affine Grassmannian,"I am studying the geometric properties of affine Grassmannians and I came across a problem with respect to different definitions of affine Grassmannian. Let $k$ be a field and $R$ a $k$-algebra. By saying an $R$-family of lattices in $k((t))$, we mean a finitely generated projective $R[[t]]$-submodule $\Lambda$ of $R((t))$ such that $\Lambda\otimes_{R[[t]]}R((t))=R((t))^n$. Then we have the following definition. $\textbf{Definition 1.}$The affine Grassmannian $Gr_{GL_n}$ for $GL_n$ is the presheaf which takes every $k$-algebra $R$ to the set of $R$-families of lattices. While, there is a more general definition for any smooth affine $k$-group. $\textbf{Definition 2.}$Let $G$ be a smooth affine $k$-group.The affine Grassmannian $Gr_G$ of $G$ is defined to be the set of pairs $(\varepsilon,\beta)$, where $\epsilon$ is a $G$-torsor on the formal unit disk $D_R:=speck(R[[t]])$ and $\beta:\epsilon|_{D_R^{\times}}\simeq\epsilon^0|_{D_R^{\times}}$ is a trivialization. My question is, taking $G=GL_n$ in definition $2$, why is it equivalent to definition $1$? I appreciate any comments or answers. Thank you in advance.","['sheaf-theory', 'algebraic-geometry', 'representation-theory', 'algebraic-groups', 'vector-bundles']"
1879737,Confusion about Cech Cohomology,"According to page 158 of Andreas Gathmann's notes on Algebraic Geometry, http://www.mathematik.uni-kl.de/~gathmann/class/alggeom-2002/main.pdf , if we have some projective plane curve $X$ defined by an homogeneous equation of degree $d$ with coordinates $x_0,x_1,x_2$ not containing the point $(0:0:1)$, it states that $$H^1(X,\mathcal{O}_X)=\left\{\dfrac{x_2^i}{x_0^jx_1^k}:0\le i \le d-1  , j > 0,k > 0, \textrm{ and }i=j+k\right\}$$
and that the arithmetic genus is $\displaystyle{\dfrac{(d-1)(d-2)}{2}}$. In general, how would one go about finding $H^1(X,\mathcal{O}_X)$ if $X$ is not defined by the equation of a curve (for example, say I want to find $H^1(X,\mathcal{O}_X)$ for the smooth projective model of the singular affine curve $y^2=x^4+x^5$)? If we let $\bar{X}$ be the smooth projective model of $X$, can we use $H^1(X,\mathcal{O}_X)$ to find a basis for $H^1(\bar{X},\mathcal{O}_\bar{X})$? I suspect such a basis should be a subset of the basis of $H^1(X,\mathcal{O}_X)$, but I'm not too sure.","['algebraic-curves', 'algebraic-geometry']"
1879744,Ordering people with friendship constraints,"$n$ people have to be ordered in a line, one after the other. We say that: A person X sees a person Y, if X stands behind Y. A person X hears a person Y, if X stands at most $k$ positions in front of Y. Each person has two friends (friendship relation is not symmetric). An order is good if each person either sees or hears both his/her friends What is the largest value of $n$ (as a function of $k$) for which a good order always exists? Here are some examples. When $n\leq k+1$, a good order always exists, since each person can see or hear all other people. When $k=1$ and $n\geq k+2$, a good order never exists, since the front person sees nobody and hears at most a single friend. When $k=2$ and $n=4$. a good order always exists and can be found as follows. Put an arbitrary person (e.g. Alice) in the front. Put her two friends just behind her, so that she can hear both of them. Put the fourth person at the back. When $k=2$ and $n=5$, things are getting interesting. Suppose we put Alice in the front, and her friends are Bob and Carl. So the order has to start as either Alice-Bob-Carl or Alice-Carl-Bob. But, if Bob's friends are David and Eva and Carl's friends are also David and Eva, then one of them (the one just behind Alice) will not hear both his friends. We can try to put Bob at the front, then David and Eva. But, if both David's friends and Eva's friends are Alice and Carl, then one of them (the one just behind Bob) will not hear both his friends. In that case, we can order the agents as: Carl-David-Eva-Alice-Bob; this order satisfies all the requirements. Apparently, finding a good order becomes harder when $n$ is larger. Hence the question. UPDATE 1: when $n\leq 2k$, a good order always exists. Put an arbitrary agent (say, Alice) in the front. Put one of her friends (say, Bob) just behind her. Put one of Bob's friends (say, Carl) just behind him. Continue like this until $k$ people are placed. Then, at position $k+1$, put Alice's second friend (if not already placed). At position $k+2$, put Bob's second friend (if not already placed), and so on. So the people at positions $1,\dots,k$ can hear all their friends. Since $n\leq 2k$, the people at positions $k+1,\dots,2k$ can hear everyone behind them. Hence the order is good. This seems very not tight, since we just picked the front person arbitrarily. Surely we can do better by picking the front person more carefully, right? UPDATE 2: Based on Kevin's probabilistic argument, I tried the following counting argument. The friendship relation can be roughly represented by a vector of size $2n$. For each 2 positions in the vector, there are $(n-1)(n-2)$ options, so the total number of vectors is $\approx n^{2n}$. On the other hand, the total number of orderings is $n!$. Therefore, if we could prove that each order is good for less than $n^{2n} / n!$ vectors, then this would imply that some vectors have no good orders. Unfortunately, the latter claim is probably not true. Fix an order, and renumber the agents such that the order is $1,\dots,n$. To construct a vector for which this order is good, we have $k(k-1)$ options for the friends of person 1, $(k+1)k$ options for the friends of person 2, ..., $(n-2)(n-1)$ options for the friends of person $n-k$, and $(n-2)(n-1)$ options for the friends of the remaining people $n-k,\dots,n$. Multiplying all these numbers gives much more than $n^{2n} / n!$. So this counting argument does not work. UPDATE 3: This question is related: How many nodes do you need? If our friendship graph if $k$-dense (as defined in that question), then a good order does not exist. Proof: regardless of who we put in the first $k$ locations, these $k$ people have together $k+1$ friends besides themselves. So, one of these people will not hear one of his friends. So a lower bound of $n$ in that question implies an upper bound of $n-1$ in the current question. In particular, for $k=2$, there is a 2-dense graph with 7 nodes; hence the largest number of people for which a good order exists is at most 6 (Peter showed a better upper bound: 5).","['combinatorics', 'constraints']"
1879760,A largest subset of a cubic lattice with unique distances between its points,"Let $n$ be a positive integer. Consider a set $S_n=([1,n]\cap\mathbb N)^3$ having $n^3$ points in the Euclidean space $\mathbb R^3$ arranged in a cubic lattice. Let $a_n$ be the size of a largest subset of $S_n$ such that for each pair of points in the subset there are no other pair of points in the subset having the same distance between them (i.e. all distances between points in the subset are unique). Can you suggest an efficient way to compute $a_n$ , or find a general formula for this sequence? Or, at least, find $a_n$ for a few small positive integers? Update: Lower or upper bounds, or asymptotic behavior are welcome. Is the sequence $\{a_n\}$ strictly increasing? Update: The corresponding OEIS sequence: $A275672$ (only terms $n=0..6$ are currently known).","['combinatorial-geometry', 'number-theory', 'combinatorics', 'sequences-and-series', 'discrete-mathematics']"
