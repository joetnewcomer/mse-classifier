question_id,title,body,tags
4042364,Why does an exponential function eventually get bigger than a quadratic,"I have seen the answer to this question and this one . My $7$ th grade son has this question on his homework: How do you know an exponential expression will eventually be larger than any quadratic expression? I can explain to him for any particular example such as $3^x$ vs. $10 x^2$ that he can just try different integer values of $x$ until he finds one, e.g. $x=6$ . But, how can a $7$ th grader understand that it will always be true, even $1.0001^x$ will eventually by greater than $1000 x^2$ ? They obviously do not know the Binomial Theorem, derivatives, Taylor series, L'Hopital's rule, Limits, etc, Note: that is the way the problem is stated, it does not say that the base of the exponential expression has to be greater than $1$ . Although for base between $0$ and $1$ , it is still true that there exists some $x$ where the exponential is larger than the quadratic, the phrase ""eventually"" makes it sound like there is some $M$ where it is larger for all $x>M$ . So, I don't like the way the question is written.","['algebra-precalculus', 'quadratics', 'exponential-function']"
4042413,$\int \sin( \pi x) \cos( \pi x)\ dx$,"I would like some help computing this integral: $$\int \sin(\pi t)\cos(\pi t)dt$$ Apparently, the answer should be $\frac{\sin^2(\pi t)}{2\pi}+C$ but I get $\frac{-\cos(2 \pi t)}{4 \pi}$ +C instead. Here's what I did: I rewrote the integrand as $\frac{1}{2}\sin(2\pi t)$ . I took out the constant $\frac{1}{2}$ out of the integral, so my expression became $\frac{1}{2} \int \sin(2\pi t)dt$ . I evaluated the antiderivative of $\sin(2\pi t)$ , which I believe is $-\frac{\cos(2\pi t)}{2 \pi}+C$ . Lastly, I multiplied the antiderivative with $\frac{1}{2}$ , yielding my final answer. Would it be wrong to assume that both answers are equivalent, since the integral can either be rewritten using the half-angle formula or solved by U-substitution? If not, could you please explain why?","['integration', 'calculus', 'trigonometry']"
4042462,Probability of extinction in generation 3 [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question The branching process has offspring distribution $μ(0) = a, μ(1) = b, μ(2) = c$ and $μ(n) = 0$ , what is the probability that the population is extinct in the 3rd generation, given that it is not extinct in the 2nd generation? How would i solve this? How is it different from finding the probability of extinction in exactly generation 3?","['conditional-probability', 'markov-chains', 'probability']"
4042465,Loewy decomposition of differential operators,"The paper by Fritz Schwarz, ""Loewy decomposition of linear differential equations"" , contains the following lemma, which I try to prove in order to understand the algorithm which Schwarz describes and which goes back to Loewy: Lemma: Determining the right irreducible factors of an ordinary operator up to order three with rational function coeffictents amounts to finding rational solutions of Riccati equations. A second order operator (with $D=\frac{d}{dx}$ ) $D^2+AD+B, \; A,B \in \mathbb{Q}(x), \qquad \qquad (1)$ has a right factor $D+a, \; a \in \mathbb{Q}(x)$ , if $a$ is a rational solution of $a'-a^2+Aa-B=0. \qquad \qquad (2)$ A third order operator $D^3+AD^2+BD+C, \; A,B,C \in \mathbb{Q}(x), \qquad \qquad (3)$ has a right factor $D+a, \; a \in \mathbb{Q}(x)$ , if $a$ is a rational solution of $a''-3aa'+a^3+A(a'-a^2)+Ba-C =0. \qquad \qquad$ (4) It has a right factor $D^2+bD+c, \, b,c \in \mathbb{Q}(x)$ , if b is a rational solution of $ b''-3bb'+b^3+2A(b'-b^2)+(A'+A^2+B)b-B'-AB+C=0. \qquad \qquad $ (6) Then $c=-(b'-b^2+Ab-B). \qquad (7) \qquad$ End of the lemma. The author of the paper takes the proof to be obvious when dividing the given operator by the right factor and requiring that the division be exact, but I don't really see that for the second and the third case. What we want to do with the help of this lemma is decompose a differential operator $L$ in order to solve the corresponding differential equation $Ly=0$ , with y being the unknown function of x and A,B,C,a,b,c being rational functions of x. I understand that the operator product for differential operators is noncommutative and obeys the rule $Da=aD+a'. \qquad \qquad (5)$ So in order to proof the lemma's first statement, I do the following: Polynomial division (in D) of (1) by $D+a$ gives me $D+A-a$ , plus some rest $a^2-Aa+B$ . Ignoring the rest for the moment, I build and simplify the operator product, paying attention to the above rule (5): $(D+A-a)(D+a)= D^2+AD-aD+Da+Aa-a^2 = D^2+AD+a'+Aa-a^2 $ , and what follows is (2), if the division is to be exact. Now the same approach for proving the second statement. Polynomial division of (3) by $D+a$ gives $D^2+D(A-a)-Aa+a^2+B$ plus some rest. Again we build the product, multiply it out and try to simplify acording to (5): \begin{align}
&(D^2+DA-Da-Aa+a^2+B)(D+a) 
\\ &= D^3+DAD-DaD-AaD+a^2D+BD +D^2a+DAa-Da^2-Aa^2+a^3+Ba 
\\ &= D^3+((AD+A')D)-(D(Da-a'))-(DAa-(Aa)')+(Da^2-(a^2)')+BD+ \cdots
\\ &= D^3+ (AD^2+A'D)-(D^2a-Da')-(DAa-A'a-Aa')+(Da^2-2aa')+BD+ \cdots 
\\ &= D^3+AD^2+BD+A'D+Da'+A'a+Aa'-2aa'-Aa^2+a^3+Ba.
\end{align} But this does not bring me to (4). In particular, I don't know how to get rid of the terms $A'D$ and $Da'$ , where D still appears. What am I doing wrong? Or is my whole approach not valid?","['differential-operators', 'differential-algebra', 'noncommutative-algebra', 'ordinary-differential-equations']"
4042581,Complexity of computing the spectral radius of a non-symmetric square matrix,"Unfortunately, I was not able to find appropriate literature that describes the computational complexity (in O notation) for computing the spectral radius of a square matrix ( not symmetric! ). In particular, my matrix is of the form $A \in \mathbb{R}^{N \times N}$ , where $N$ is a finite integer. While there is some literature on graph theory, and therefore, for symmetric matrices (adjacency matrices), in the case of non-symmetric square matrices my search was unsuccessful. I would be very grateful for any leads, also regarding spectral radius approximations.","['asymptotics', 'matrices', 'spectral-radius', 'numerical-linear-algebra', 'computational-complexity']"
4042591,"How should we use differential ""dx"" in deriving Tabular formula","I am learning repeated integration with the  Tabular method. I see textbooks or web sites prove the method, but  most of the times, they  either do not explain each step or just skip with (...). I try to prove it myself  by going through  each step.  I am not sure if my manipulations of differential "" $dx$ "" are legitimate, and in general how to justify them. I started with  with  (uv)'=u'v+vu' $\frac {d(uv)} {dx} 
= \frac {du} {dx}v+ u\frac {dv} {dx}$ $\to$ (Q1: Can I  simply multiply both sides  by $dx$ ?) $d(uv)= vdu+udv$ $\int uv =\int udv+\int vdu$ $\int udv=\int uv -\int vdu$ $    $ (I) Set $\frac {du} {dx}=u^1$ , $\frac {dv^{-1}}{dx}=v$ $\to$ $du= u^1dx$ , $v=\frac {dv^{(-1)}} {dx}$ $\int vdu= \int u^1dx$$\frac {dv^{(-1)}} {dx}$ $\to$ $\int u^1dv^{-1}$ (Q2:  Can I directly cancel $dx$ from  both numerator and denominator?) $\int udv= uv -\int u^1dv^{-1}  $ Repeating similar steps $\to$ $\int udv=$$\sum_{i=0}^{n-1} (-1)^iu^i v^{-i} +\int (-1)^nu^n dv^{-n}$ $    $ $\int udv=$$\sum_{i=0}^{n} (-1)^iu^i v^{-i} +\int (-1)^{n+1}u^{n+1} dv^{-(n+1)}$ $    $ (II) which is equivalent to common expression $\int udv=$$\sum_{i=0}^{n} (-1)^iu^i v^{-i} +\int (-1)^{n+1}u^{n+1} v^{-(n)}dx$ $    $ (II')","['integration', 'derivatives']"
4042594,"Integral comparison test for $\frac{1}{x \ln(x)^2} $ or $\frac{1}{x \log(x)^2}$ on $(0, \frac{1}{2})$","I am trying to show $f(x) = \frac{1}{x \ln(x)^2}$ on the interval $(0,\frac{1}{2})$ is in $L^p$ only for $p=1$ and not for $p>1$ . I can show $||f||_{L^1( (0,\frac{1}{2}) )} < \infty $ but for $p>1$ , I have a hard time figuring out how to evaluate $\int_0^{\frac{1}{2}} \frac{1}{x^p \ln(x)^{2p}} dx$ . Change of variable with $u= \ln(x)$ gives me $\int_{-\infty}^{\ln(\frac{1}{2})} \frac{1}{(e^u)^{p-1} u^{2p}} du$ which looks like I should try an integral test instead.","['measure-theory', 'lebesgue-integral', 'analysis', 'functional-analysis', 'partial-differential-equations']"
4042602,Generate a random permutation of the first $n$ numbers on the fly,"I have a large number of people coming to my shop and want to assign ids from $1$ to at-most $n$ to all of them. While I don't know in advance how many people will arrive, I'll simply stop accepting people beyond $n$ , so its going to be $n$ in the worst case. I want to assign these in a random order (so as to minimize the information that the person can get on the ID he's going to be assigned by looking at the IDs that came before him; no more than the $O(n \log n)$ algorithm leveraging the Fisher Yates shuffle described in my first attempt below). I want to do this on the fly and without having to save the ID's I've already assigned in memory (the memory footprint should be no more than $O(\log n)$ due to the bits required to store a single ID). Is there an algorithm for this? If not, what are some good algorithms that work with $O(\log n)$ memory and do well on the objective function defined in the first edit below? EDIT-1: To make the objective function concrete, let's say every person is given a chance to guess their ID in advance when they arrive. If they get it right, they get a 1\$ discount on any purchase. We can assume these people are all very intelligent and will maximize their odds of getting the discount. My algorithm should be such that it minimizes the average discount I end up giving them. My attempts: If we can work with $O(n \log n)$ memory, we would simply store the numbers $1$ to $n$ in an array and permute it randomly with the Fisher-Yates shuffle. This makes all $n!$ permutations equally likely. Then, we loop through the permuted array as customers arrive and give them their IDs. Note that unless a given customer knows my permuted array and he comes in very late, he can't get much information about the ID that's going to be assigned to him by looking at the IDs that came before him. To do this with $O(\log n)$ memory (only the bits required for storing the IDs), one could express the numbers $1$ to $n$ in binary and permute the digits of the chronological order of any customer in some pre-specified way to get a new number. However, this doesn't make the order of the ID's a completely random permutation, since the number of 1's in binary representations of the chronological position and the assigned ID are the same. So, you could rule out certain ID's based on the chronological position. Looking at ID's assigned in the past, a customer could figure this out. EDIT-2: With the $O(n)$ memory algorithm involving the Fisher Yates shuffle, it's hard to say what the expected discount I end up giving will be if the people don't know $n$ (see here: Expected discount shop owner will have to shell out in a guessing game with customers ). But if they do know $n$ , I think it'll become: $$d = \sum\limits_{i=1}^{n}\frac{1}{i}$$ EDIT-3: @MishaLavrov pointed out that even if we assign id's per the chronological order, we need $O(\log(n))$ bits to store the ids. So, an $O(1)$ algorithm isn't possible.","['permutations', 'number-theory', 'information-theory', 'algorithms']"
4042637,Let $A$ be finite. Suppose $B$ is countably infinite. Is the set $B^A$ uncountably infinite?,"Let $A$ be a finite set. Suppose $B$ is countably infinite. Is the set $B^A$ uncountably infinite? I am new to infinite cardinality arguments, but my initial thinking is yes . However, I am uncertain if the claim requires the Axiom of Choice ... I am concerned that I am using the Axiom of Choice without realizing it, and I would like to not invoke the axiom if possible. The following is my pseudo-informal argument. Because $B$ is countably infinite, there exists an injection (possibly bijection) from $B$ to $\mathbb N$ . (i.e. $B \preceq \mathbb N)$ . Let $F$ be one such function so that $F:B \xrightarrow{1-1} \mathbb N$ . Knowing that $\mathbb N$ is well-ordered, I can conclude that all subsets of $\mathbb N$ are well-ordered. Thus every member of $\mathcal P(\mathbb N) \setminus \{\emptyset\}$ has a minimal element. Further, by Cantor's Diagonal argument $\mathcal P (\mathbb N)$ is uncountably infinite, which implies that $\mathcal P(\mathbb N) \setminus \{\emptyset\}$ is uncountably infinite as well. I believe a similar argument can be made for $\mathcal P(B)$ . Let $p_{_B}$ be an arbitrary element of $\mathcal P( B) \setminus \{\emptyset\}$ . I know that restricting $F$ 's domain to $p_{_B}$ will produce a subset in $\mathbb N$ . Call this subset $\mathbb N_{p_B}$ . (i.e. $F[p_{_B}]=\mathbb N_{p_B}$ ) Let $n_{0}$ be the minimal element of $\mathbb N_{p_B}$ . Let $b \in p_{_B}$ be the element that is mapped to through $F^{-1}$ ...i.e. $F^{-1}(n_0)=b$ . Because $F$ is injective, this is unambiguous. Now, consider the construction of a function $g_{p_B}$ . Let $g_{p_B}$ be the function that takes all elements of $A$ and maps them to the $b \in p_{_B}$ that corresponds to minimal element $n_0$ for a given $\mathbb N_{p_B}$ . ( This is where I am concerned ...I think I am using a valid invocation of the Axiom of Replacement, but perhaps it is actually the Axiom of Choice) Because there are an uncountably infinite number of $p_{_B}$ 's in $\mathcal P( B) \setminus \{\emptyset\}$ , there must necessarily be an uncountably infinite number of $g_{p_B}$ 's that satisfy the above definition. The collection of all such functions is a subset of $B^A$ . Therefore, if a subset of a given set is uncountably infinite, the set itself must be uncountably infinite. Edit Just to highlight an issue in my reasoning, here is one of my afterthoughts (confirmed by Arturo Magidin): ""Now that you mention it, it does seem like there is necessarily a chance that many of the $g_{p_B}$ 's are redundant...i.e. there may be a $p_{_B}\neq p'_{_B}$ that can be represented by the same $g$ function. Perhaps that is an issue as well.""","['elementary-set-theory', 'cardinals', 'solution-verification', 'set-theory']"
4042684,"""Summing"" the series $\sin(x)-\dfrac{1}{2}\sin(2x)+\dfrac{1}{3}\sin(3x)-...$","""Summing"" the series $\sin(x)-\dfrac{1}{2}\sin(2x)+\dfrac{1}{3}\sin(3x)-\dfrac{1}{4}\sin(4x)+...$ Pose $$S=\sin(x)-\dfrac{1}{2}\sin(2x)+\dfrac{1}{3}\sin(3x)-\dfrac{1}{4}\sin(4x)+...$$ $$C=\cos(x)-\dfrac{1}{2}\cos(2x)+\dfrac{1}{3}\cos(3x)-\dfrac{1}{4}\cos(4x)+...$$ $$C+iS = e^{ix}-\dfrac{1}{2}(e^{ix})^2+\dfrac{1}{3}(e^{ix})^3-\dfrac{1}{4}(e^{ix})^4+...$$ Let $t$ = $e^ix$ Then we have a series of $t-\dfrac{t}{2}+\dfrac{t}{3}-\dfrac{t}{4}+...=\log(1+t)$ Which is $\log(1+e^{ix})=\log(1+\cos(x)+i\sin(x))$ , use the formula $\log(A+iB)=\dfrac{1}{2}\log(A^2+B^2)+\arctan\left(\dfrac{B}{A}\right)$ $\log([1+\cos(x)]^2+i\sin(x))=\dfrac{1}{2}\log(\log([1+\cos(x)]^2+i\sin^2(x))+\arctan\left(\dfrac{i\sin(x)}{1+\cos(x)}\right)$ . Since we are interested only in the imaginary part, we have the sum for $S$ is: $$\arctan\left(\dfrac{i\sin(x)}{1+\cos(x)}\right)$$ I don't know what to do next. In his paper ""Subsidium Calculi Sinuum"", Euler wrote the series has the ""sum"" $$\sin(x)-\dfrac{1}{2}\sin(2x)+\dfrac{1}{3}\sin(3x)-\dfrac{1}{4}\sin(4x)+...=\dfrac{x}{2}$$ We obtained this by multiplying $dx$ integrating (his words is Illa autem series per $dx$ multiplicata et integrata dat:"" $$\cos(x)-4\cos(2x)+9\cos(3x)-16\cos(4x)...=0$$ I don't know how he obtains $\dfrac{x}{2}$ , since the left hand side is $0$ , how can it be $x/2$ . Returning to my own ""sum"", how can I obtain the $1/2$ This series is quite important because it appears in Fourier ""Analytical Theory of Heat"".","['trigonometric-series', 'trigonometry', 'sequences-and-series', 'real-analysis']"
4042722,Taylor expansion of a gaussian integral,"I tried Taylor expanding the following function for small $x \ll 1$ : \begin{align*}
f(x) = \frac{1}{\sqrt{2\pi}} \int\limits^{+\infty}_{-\infty} e^{\frac{-xy^4}{24}-\frac{y^2}{2}}\,\mathrm{d}y.
\end{align*} I already know that $f$ takes on finite values for $x \geq0$ . My goal is to get a series expression for $f$ of the following form: \begin{align*}
f_N(x) = \sum^N_{n = 0}a_n x^n.
\end{align*} So after using the formula (for $a = 0$ ) \begin{align*}
f(x) = \sum^\infty_{n = 0} \frac{f^{(n)}(a)}{n!}(x-a)^n,
\end{align*} I get up to the $N$ -th term: \begin{align*}
f_N(x) = \sum^N_{n = 0} \frac{1}{n!}\frac{(-x)^n}{24^n}(4n-1)!!
\end{align*} However, when plugging in a small value for $x$ (for example $x = 0.1$ ) in Wolfram Alpha, I get that till $N = 25$ the approximation is very good, but after around $N = 30$ the series diverges away from the true value ( $\approx 0.988306$ ). So for $N \rightarrow + \infty$ , the series seems to diverge. My questions are: How can this be ? I thought that for larger and larger $N$ the Taylor approximation would be more and more better ? (well, for small $x$ atleast) Does this mean that the radius of convergence is equal to $0$ and that the interval of convergence is just the point $x = 0$ ? If not, then what is the radius of convergence ? If yes, doesn't this contradict the fact that $f$ is finite for $x \geq1$ ?","['calculus', 'taylor-expansion', 'sequences-and-series', 'power-series', 'convergence-divergence']"
4042741,Struggling to understand basics of complete residue system,"I'm really struggling to understand the literal arithmetic being applied to find a complete residue system of modulo $n$ . Below is the definition my textbook provides along with an example. Let $k$ and $n$ be natural numbers. A set $\{a_1,a_2,...,a_k\}$ is called a canonical complete residue system modulo $n$ if every integer is congruent modulo $n$ to exactly one element of the set I'm struggling to understand how to interpret this definition. Two integers, $a$ and $b$ , are ""congruent modulo $n$ "" if they have the same remainder when divided by $n$ . So the set $\{a_1,a_2,...,a_k\}$ would be all integers that share a quotient with $b$ divided by $n$ ? After I understand the definition, this is a simple example provided by my textbook Find three residue systems modulo $4$ : the canonical complete residue system, one containing negative numbers, and one containing no two consecutive numbers My first point of confusion is ""modulo $4$ "". $a{\space}mod{\space}n$ is the remainder of Euclidean division of $a$ by $n$ . So what is meant by simply ""modulo $4$ ""? What literal arithmetic do I perform to find a complete residue system using ""modulo $4$ ""?","['modular-arithmetic', 'discrete-mathematics']"
4042804,"$A, B,$ and $C$ are all sets that lie in a common universal set. Prove $A = B$ given the following statements.","$(A \cup C) = (B \cup C)$ and $(A \cap C) = (B \cap C)$ I know I have to start with $A = ...$ to get to $B$ . I incorporated $A = A \cap (A \cup C)$ as the first step using absorption law, but I don't know where to go from here. How do I show that it equals $(A \cup C) = (B \cup C)$ ? I've looked at the set identities, and think that I have to use absorption law again to show that $A \cap (A \cup C) = (A \cap (A \cup C)) \cap ((A \cap (A \cup C)) \cup (B \cup C))$ . Can you guys please help me solve this problem, I'm stuck.","['elementary-set-theory', 'discrete-mathematics']"
4042826,Find all the points where a function is not differentiable,"Let $f\left( x \right)$ be a differentiable function $\mathbb{R}\to \mathbb{R}$ . Find all the points where the function $\left| f\left( x \right) \right|$ is not differentiable.
Of course, I understand that $\left| f\left( x \right) \right|$ is not differentiable where its graph has a corner because of the modulus, e.g., ${{\delta }_{+}}f\left( a \right)+{{\delta }_{-}}f\left( a \right)=0$ . Obviously, it is only possible where $f\left( x \right)$ changes its sign since $f\left( x \right)$ is be a differentiable function.
Is there any way to write this informal idea in a more formal manner?","['derivatives', 'real-analysis']"
4042828,Generalizing Contour Integration to Quaternions,"I have recently entertained the possibility of defining complex contour integration for the quaternions. I am somewhat aware that the Frobenius theorem dictates that no division algebra can exist in $\mathbb{R}^3$ ; however, Cayley-Dickinson constructions can generalize these division algebras to spaces of the form $\mathbb{R}^{2^n}$ at the expense of commutativity and later associativity. Even if the holomorphicity and analyticity are not equivalent (although they are for $\mathbb{C}$ )  generalizations of the Cauchy-Riemann equations have been made to higher dimensions with some success. [ 1 ] Additionally, a field analyzing differential quaternions exists in computer graphics, though I believe it is more concerned with aptly representing rotations in $\mathbb{R}^3$ . [ 2 ] Would it be reasonable to believe that contour integration may be generalized to one of these division algebras by designing a hypercomplex function on a 1-manifold map (i.e., one that is diffeomorphic to a subset of $\mathbb{R}$ .) Although Liouville's theorem requires that the amount of holomorphic maps significantly decreases as the dimensionality increases and those that do exist must be representable as a composition of Mobius transforms, would a reasonable definition of quaternion complex integration be the sum of standard contour integration along each component of the one manifold for a given basis? (I also assume that the result would have to be invariant of the choice of basis in order to be well-defined.) In particular, I'm wondering if a generalization of contour integration could be used to define a biholomorphic map (if not a holomorphic map) in the quaternions or complex-like numbers spaces above?
I'm very new to the topic and haven't the experience of many members on this website. As a semi-related question, why does the existence of quaternions not provide for the existence of division algebras in $\mathbb{R}^3$ ? I assume that taking the subset of all quaternions where only the same three components are nonzero would not suffice as the existence of a multiplicative inverse or closure under division would not hold. As a final soft question, does anyone suggest textbooks for hypercomplex numbers? I had considered purchasing Hypercomplex Numbers by Isaiah Kantor. Are there any papers that expound on the notion of integration on Hypercomplex Manifolds described on Wikipedia? [ 3 ] Thank you all.","['integration', 'conformal-geometry', 'quaternions']"
4042842,Convergence in probability of a random sample,"Let $X_1,X_2$ ,... be iid random variables and $S_n=X_1+...+X_n$ . I need to prove if $\frac{S_n}{n}$ converges in probability to 0, then $\frac{M_n}{n}$ also converges in probability to $0$ , where $M_n$ is maximum of $S_1,...S_n$ . My attempt : I tried to find a connection with Etemadi's or similar tools in maximal inequality things. But I have no idea on which one I should choose. Thanks for your help!","['convergence-divergence', 'probability-theory', 'random-variables']"
4042854,I roll a fair die 4 times. Let $X$ be the number of different outcomes that I see. Find $\mathbb{E}[X]$,"I roll a fair die 4 times. Let X be the number of different outcomes that I see. Find $\mathbb{E}[X]$ . My attempt: I know that I can write X as a sum of indicator random variables and then I can use the fact that $\mathbb{E}[1_A]=\mathbb{P}(A)$ . Thus, \begin{equation}
I_{A_1}=
\begin{cases}
1 & \text{if only one kind}\\
0 & \text{otherwise}
\end{cases}
\end{equation} \begin{equation}
I_{A_2}=
\begin{cases}
1 & \text{if two kinds}\\
0 & \text{otherwise}
\end{cases}
\end{equation} \begin{equation}
I_{A_3}=
\begin{cases}
1 & \text{if three kinds}\\
0 & \text{otherwise}
\end{cases}
\end{equation} \begin{equation}
I_{A_4}=
\begin{cases}
1 & \text{all different}\\
0 & \text{otherwise}
\end{cases}
\end{equation} Then the probabilities of event A happening for each is $$\mathbb{P}(I_{A_1})=\frac{6\cdot1\cdot1\cdot1}{6^4}$$ $$\mathbb{P}(I_{A_2})=\frac{6\cdot5\cdot2\cdot2}{6^4}$$ $$\mathbb{P}(I_{A_3})=\frac{6\cdot5\cdot4\cdot3}{6^4}$$ $$\mathbb{P}(I_{A_4})=\frac{6\cdot5\cdot4\cdot3}{6^4}$$ The sum of these should be my desired expectation. My question is whether or not I have found the probabilities correctly. This is my thought process for how I counted the number of choices for the numerator, using $I_{A_2}$ as an example: There are 6 choices for choosing the first number, then we don't want to get that number again so then there are 5 choices. After that, we only want to get the first or second number again, thus there are 2 choices for the third roll and 2 choices for the fourth roll. Hence, $6\times 5\times 2\times 2=120$ . Is this the correct way of thinking about it? Thanks","['expected-value', 'probability', 'random-variables']"
4043004,Manifold and action associated to a central extension of groups,"Let $X$ be a manifold equipped with a proper $G$ -action. Suppose we have a central extension $$0\to H\hookrightarrow G'\to G\to 0,$$ where $G\cong G'/H$ . Question 1: Can one construct a manifold $X'$ on which $G'$ acts properly, with the property that $X'/G'$ is homeomorphic to $X/G$ ? Question 2: If not, is there a topological obstruction to the existence of $X'$ ? In other words, I would like to know: given a class in $\alpha\in H^2(G,H)$ and a proper $G$ -manifold $X$ , is there a manifold $X'$ on which the extension defined by $\alpha$ acts? Remark: Since $G'$ is a fiber bundle over $G$ with fiber $H$ , my guess is that $X'$ should be a $H$ -bundle over $X$ , but I'm not sure how to write down $X'$ explicitly.","['exact-sequence', 'group-cohomology', 'group-theory', 'group-actions', 'differential-geometry']"
4043006,How to find the number of times a weather station registered a certain temperature?,"The problem is as follows: The temperature in the city of Daegu on March 1st, 2020 is given by: $15+5\sin\left(\frac{\pi t}{12}+\frac{\pi}{2}\right)$ in celcius, where $t\in [0,24]$ . Assume $t$ is the time elapsed in hours from midnight.
Using this information. Find how many times the temperature of the
city was measured to be $17.5$ celcius. What I've attempted to do in order to solve this problem isn't much. What I arrived was this: $$15+5\sin\left(\frac{\pi t}{12}+\frac{\pi}{2}\right)=17.5$$ Then this is reduced to: $$\sin\left(\frac{\pi t}{12}+\frac{\pi}{2}\right)=\frac{1}{2}$$ But now what? I could use the inverse sine function as: $$\frac{\pi t}{12}=\sin ^{-1}\left(\frac{1}{2}\right)-\frac{\pi}{2}$$ But from looking at this effort, I don't seem this would help me to get the value of $t$ , needless to say. Assuming that I could get that value. How can I get how many times that temperature was attained? . Therefore I need assistance in this problem.","['algebra-precalculus', 'trigonometry']"
4043007,"Topology on $\operatorname{Hom}(\mathbb{Q}, \mathbb{R}/\mathbb{Z})$","It is well-known that the Pontryagin dual of a discrete locally compact abelian group must be compact, which means that $\operatorname{Hom}(\mathbb{Q}, \mathbb{R}/\mathbb{Z})$ must be compact with the compact-open topology (where $\mathbb{Q}$ is taken with the discrete topology). However, one can prove that $\operatorname{Hom}(\mathbb{Q}, \mathbb{R}/\mathbb{Z}) = \mathbb{R}^2$ (or at least I think so, the below proof could have a mistake I have overlooked). This leaves me wondering what topology does $\mathbb{R}^2$ have to make it compact. We start with the short exact sequence $0 \to \mathbb{Z} \to \mathbb{R} \to \mathbb{R}/\mathbb{Z} \to 0$ . Since $\mathbb{R}$ is divisible, $\operatorname{RHom} (\mathbb{Q}, \mathbb{R}) = \mathbb{R}$ . Also, $\operatorname{RHom}(\mathbb{Q}, \mathbb{Z}) = \mathbb{R}[-1]$ (see this reference). Also, $\mathbb{R}/\mathbb{Z}$ is divisible so $\operatorname{Ext}(\mathbb{Q}, \mathbb{R}/\mathbb{Z}) = 0$ . We now use the induced long exact sequence $$ 0 \to \mathbb{R} \to \operatorname{Hom}(\mathbb{Q}, \mathbb{R}/\mathbb{Z}) \to \mathbb{R} \to 0$$ However, $\mathbb{R}$ is injective so $\operatorname{Ext}(\mathbb{R}, \mathbb{R}) = 0$ and the extension must be trivial. Hence, $\operatorname{Hom}(\mathbb{Q}, \mathbb{R}/\mathbb{Z}) \cong \mathbb{R}^2$ . Due to the indirect computation, I find it hard to see how the compact-open topology applies to this group. What topology does $\mathbb{R}^2$ have in these circumstances?","['homological-algebra', 'group-theory', 'group-extensions']"
4043010,Does the law of large numbers hold for covering numbers?,"I am self-studying empirical process theory.
I have encountered the covering number $N(\delta,\mathcal{G},P)$ , as well as the empirical version $N(\delta,\mathcal{G},P_n)$ .
It seems intuitive to expect some kind of convergence: $$
N(\delta,\mathcal{G},P_n)\rightarrow N(\delta,\mathcal{G},P)
$$ Yet, I have no idea how to prove this. Can such a result be shown? Or are there counterexamples? Definitions Covering number: Let $P$ be a probability measure on the Borel- $\sigma$ -algebra over $\mathbb{R}$ .
For $p\in[1,\infty)$ let $L^p(P)$ be the set of Borel-measurable mappings $\mathbb{R}\rightarrow\mathbb{R}$ , for which $\int_\mathbb{R} |f|^p dP<\infty$ .
Let $\mathcal{G}$ be a totally bounded subset of $L^p(P)$ .
For some $\delta>0$ , we can define the covering number of $\mathcal{G}$ as the smallest $N\in\mathbb{N}$ , such that there exists a finite subset $G\subset \mathcal{G}$ with the following property:
For any $g\in\mathcal{G}$ , there exists a $h\in G$ , such that $||g-h||_p<\delta$ .
This number is denoted by $N(\delta,\mathcal{G},P)$ . Empirical measure: Let $P$ be as above. Let $\{X_n\}_{n\in\mathbb{N}}$ be a sequence of independent $P$ -distributed random variables. If $\delta_{X_i}$ denotes the dirac-measure, the empirical measure $P_n$ is defined as: $$
P_n:\mathcal{B}(\mathbb{R})\rightarrow[0,1],\quad E\mapsto \frac{1}{n}\sum_{i=1}^n\delta_{X_i}(E)
$$","['statistics', 'probability-limit-theorems', 'machine-learning', 'empirical-processes', 'law-of-large-numbers']"
4043011,meaning of topology on a finite set,"I have just started learning topology on my own and it's been quite intuitive and well-motivated while it was defined on the set of real numbers. However, in many books authors, for the sake of simplicity,  usually begin demonstrating a topology on some small finite sets such as $\{1,2,3\}$ . For example, they say that $\{\{\}, \{1,2\}, \{1,2,3\}\}$ is a valid topology, since it satisfies three axioms. And i didnt get it. I cant grasp idea of topology on finite sets. Ideas of open sets, or open balls (when a metric defined) are clear on real numbers, but for me they lose the meaning on finite sets, however it should be vice versa. That's why i have a question: What does we obtain conceptually when we define a topology on a finite set? Sense of nearness, connectedness? May be by defining a topology $\{\{\}, \{1,2\}, \{1,2,3\}\},$ we show continuity within the $\{1,2\}$ and in a sense isolate $3$ ?",['general-topology']
4043027,Left coset and right coset of subgroup $H=\langle(234)\rangle$ in alternating group $A_4$,"My homework question is: Partition $G=A_4$ into left cosets of the subgroup $H=\langle (234)\rangle$ but I am not sure how to start with. I know that $$A_4= \{(1), (12)(34), (13)(24), (14)(23), (123), (132), (124), (142), (134), (143), (234), (243)\},$$ am I right? Also, the left coset of H is $xH=\{xh:h\in H\}$ .","['permutations', 'group-theory']"
4043073,Differential equation based on initial values,"I have a differential equation that looks like: $$y'=y(4-y)$$ I have identified the critical points to be $0$ and $4$ .
I need to identify the behavior of the equation as $t \rightarrow \infty$ and this behavior it seems depends on the initial value. Now depending on the differential equation I can say that If $y > 4$ , then $y$ is decreasing If $0<y<4$ , then $y$ is increasing If $y<0$ , then $y$ is decreasing And I infer this based on the slope values calculated from the $y'$ equation. So based on this I was able to conclude that as $t \rightarrow \infty$ , $y$ converges to $4$ and and diverges from $0$ . But how do I identify this behavior from initial values? I feel like I'm missing something here.",['ordinary-differential-equations']
4043087,Find $\lim_{x\to 0} \frac{1+\sin x-\cos x}{1+\sin(px)-\cos(px)}$,Find the limit of $$\lim_{x\to 0} \frac{1+\sin x-\cos x}{1+\sin(px)-\cos(px)}$$ without l'Hospital. I tried expanding $1-\cos(x)$ to get something this kind $$\lim_{x\to 0}\frac{\sin x}{x}$$ but couldn't solve it. The answer is $1/p$ .,"['limits-without-lhopital', 'analysis', 'real-analysis', 'calculus', 'limits']"
4043133,"Find the flux for the vector field $F =(x^2,y^2,z^2)$","Find the flux for the vector field $\vec{F}=(x^2,y^2,z^2)$ across the boundary to the ball given as $$(x-1)^2 +(y+1)^2 +(z-2)^2 \le 4$$ Edit: How much I've done: The center of the sphere is $(1,−1,2)$ (I've sketched it), thus $r(θ,ϕ)=(1+cosθsinϕ, −1+sinθsinϕ, 2+cosϕ)$ . Then to find the normal vector $\vec{N}$ , I've calculated $\frac{∂r(θ,ϕ)}{∂ϕ}=(cosθcosϕ,sinθcosϕ,−sinϕ)$ and $\frac {∂r(θ,ϕ)}{∂θ}=(−sinθsinϕ,cosθsinϕ,0)$ then $\frac{∂r(θ,ϕ)}{∂ϕ} \times \frac{∂r(θ,ϕ)}{∂θ}$ , and finally got $(sin2ϕ,sinθsin2ϕ,sinϕcosϕ)$ . Am I on the right track?","['vector-fields', 'multivariable-calculus', 'spheres', 'vector-analysis']"
4043136,Putting sheaves to work for algebraic topology?,"I'm refreshing my memory of covering space theory, and this time around, I know some sheaf theory. It feels like arguments are used to prove results about covering spaces, such as uniqueness of lifts, having something ""sheafy"" about them. For example, to prove uniqueness of lifts, we argue by trying to extend ""equality at a point"" to ""equality over a neighbourhood"" to ""equality over the entire domain"". It seems like the language of sheaves may make this clearer? Similarly, when it comes to covering spaces, there is something ""etale-like"" about them. Is there a reference that expands on this perspective?","['algebraic-geometry', 'algebraic-topology']"
4043143,Is there a good reason to use covariance and not correlation?,Correlation is a normalization of covariance by the standard deviation of each variable . So is there a good reason (and example) when we should (and have) to use covariance and not correlation ?,"['correlation', 'statistics', 'covariance', 'probability']"
4043163,Find the minimum of $\sqrt{4y^2-12y+10}+\sqrt{18x^2-18x+5}+\sqrt{18x^2+4y^2-12xy+6x-4y+1}$,"Find the minimum of $$f(x,y)=\sqrt{4y^2-12y+10}+\sqrt{18x^2-18x+5}+\sqrt{18x^2+4y^2-12xy+6x-4y+1}$$ It seems that $f_x=f_y=0$ is very hard to compute. Is there any easier idea?","['maxima-minima', 'calculus']"
4043221,Courses closely following Rudin's Real and Complex Analysis,"I am self-studying Rudin's Real and Complex Analysis, and for now, my goal is to work through the first two chapters - Abstract Integration and Positive Borel Measures. I am required by my supervisor (I am an undergraduate mathematics major, by the way) to learn from this book - but I find the exposition very terse, and sometimes it takes an hour to figure out the stuff on one page. I know that math demands time and effort, I am not shying away from that, I'm just looking for any course material online (lecture notes, slides, videos, problem sets, etc.) that could effectively supplement my reading of this text, and make my journey somewhat easier . Could you please help me out by suggesting any courses (in the form of videos, lecture notes/slides, problem sets, etc.) that could supplement my reading and make the job of understanding Rudin easier? If not, then it would be good to know of any other books that closely follow the content in Rudin but are easier to understand . Anyway, Rudin intended the book to be a text for graduate students - and as an undergraduate student, I guess I could use some help. Thanks a lot! To summarize the recommendations I've gotten so far: Gerald Folland's Real Analysis: Modern Techniques and Their Applications . Sheldon Axler's Measure, Integration & Real Analysis .","['self-learning', 'book-recommendation', 'analysis', 'reference-request']"
4043247,Is an ideal finitely generated if its radical is finitely generated?,"Let $R$ be a commutative ring. If $R$ is not Noetherian, we can ask if some some ideals is finitely generated. For examples: Is intersection of finitely generated ideals finitely generated? No, see for instance here . Is radical $\sqrt{I}=\{x \in R \mid x^n \in I \text{ for some } n\ge 1\}$ of a finitely generated ideal $I$ finitely generated? No, see for instance here . In the light of the previous two (sets of) counter-examples, I believe that claim If $\sqrt{I}$ is finitely generated, then $I$ is also finitely generated, is also false, but I wasn't able to construct a counter-example. It would be interesting for me to see counter-examples of various nature.","['abstract-algebra', 'examples-counterexamples', 'commutative-algebra', 'ideals']"
4043347,A recurrence of the second-order Eulerian polynomials,"Recently, some of the remarkable properties of second-order
Eulerian numbers $ \left\langle\!\!\left\langle n\atop k\right\rangle\!\!\right\rangle$ A340556 have been proved on MSE [ a , b , c ]
and in d the second-order Eulerian polynomials
were introduced. $$ \left\langle\!\left\langle x \right\rangle\!\right\rangle_n =
\sum_{k=0}^n \left\langle\!\!\left\langle n\atop k \right\rangle\!\!\right\rangle \, x^k $$ These polynomials can be computed recursively,  starting $ \left\langle\!\left\langle x \right\rangle\!\right\rangle_{0} \, = \, 1 $ , and then proceeding $$ \left\langle \! \left\langle x \right\rangle \! \right\rangle _n =
x\,(x-1)^{2n}\
\left(\frac{ \left\langle \! \left\langle x \right\rangle \! \right\rangle _{n-1}}{(1-x)^{2n-1}} \right)'
\quad (n \ge 1). $$ With this formula the polynomials can not only be calculated efficiently but also
may simplify the derivation of combinatorial identities.
For instance from Marko Riedel's thorough proof we know the following identity for Euler's tree function $\operatorname{T}(z) = - \operatorname{W}(-z)$ , where $\operatorname{W}$ is the principal branch of Lambert's function A000169 : $$  m^{m+n} \,  = \,
    m!\, [x]^{m} \frac{\left\langle \! \left\langle \, \operatorname{T}(x) \, \right\rangle \! \right\rangle _n}  {(1-\operatorname{T}(x))^{2n+1}} \quad ( n \ge 0) $$ The reader may enjoy to investigate what happens if we evaluate the function
at $ x = (2 \sqrt{e})^{-1}$ , ( A225170 , A006351 ).
Is someone willing to show us a proof of the recurrence of the second-order Eulerian polynomials
given above?","['lambert-w', 'eulerian-numbers', 'combinatorics']"
4043415,What's wrong with my method for this integral?,"So I have to solve $$\int_0^1\frac{1}{x^{2/3}(1-x)^{1/3}}dx.$$ To do this I made a branch cut from $z=0$ to $z=1$ and took the bone-shaped contour that straddles the real axis, going clockwise. Now on the line above the real axis, I took the angle with respect to $z=0$ to be $0$ and that with $z=1$ to be $\pi$ .  Then the corresponding line integral comes out to $e^{-\frac{i\pi}{3}}I$ and so the one below comes out to $-e^{\frac{i\pi}{3}}I$ with the second angle $-\pi$ . But this gives me the wrong answer. Most places I found online seem to take the first angle to be $0$ and the second one to go from $0$ to $2\pi$ . But why should this make a difference? Why is my way of taking the angles wrong?",['complex-analysis']
4043453,Teacher claims this proof for $\frac{\csc\theta-1}{\cot\theta}=\frac{\cot\theta}{\csc\theta+1}$ is wrong. Why?,"My son's high school teacher says his solution to this proof is wrong because it is not ""the right way"" and that you have to ""start with one side of the equation and prove it is equal to the other"". After reviewing it, I disagree. I believe his solution is correct, even if not ""the right way"", whatever that means. I asked my son how he did it: he cross-multiplied the given identity, simplified it to a known/obvious equality, and then reversed the steps for the proof. This was a graded exam, and the teacher gave him a zero for this problem. What do you think about my son's solution? Thanks! Problem: prove the following trigonometric identity \begin{align*}
\frac{\csc(\theta)-1}{\cot(\theta)}&=\frac{\cot(\theta)}{\csc(\theta)+1}\ .\\
\end{align*} Solution:  for all real $\theta$ not equal to an integer multiple of $\pi/2$ , we have \begin{align*}
\cot^2(\theta)&=\cot^2(\theta)\\[8pt]
\frac{\cos^2(\theta)}{\sin^2(\theta)}&=\cot^2(\theta)\\[8pt]
\frac{1-\sin^2(\theta)}{\sin^2(\theta)}&=\cot^2(\theta)\\[8pt]
\csc^2(\theta)-1&=\cot^2(\theta)\\[8pt]
\frac{\csc^2(\theta)-1}{\cot(\theta)}&=\cot(\theta)\\[8pt]
\frac{\csc(\theta)-1}{\cot(\theta)}&=\frac{\cot(\theta)}{\csc(\theta)+1}
\end{align*}","['algebra-precalculus', 'proof-writing', 'solution-verification', 'trigonometry']"
4043519,There's 8 black balls and 7 white balls. 3 of the balls are drawn at random. Probability of drawing 2 of one color and 1 of the other color?,"A bin has 8 black balls and 7 white balls. 3 of the balls are drawn at random. What is the probability of drawing 2 of one color and 1 of the other color? Here's what I tried: Case 1: 2 black balls and 1 white ball 8/15 * 7/14 * 7/13 = 392/2730 = 28/195 Case 2: 2 white balls, 1 black ball 7/15 * 6/14 * 8/13 = 336/2730 = 24/195 28/195 + 24/195 = 52/195 = 4/15 My teacher said it was wrong and I don't get why. She didn't give me the solutions either and just told me the answer was 4/5. Can someone tell me what I'm doing wrong? Thanks!","['combinatorics', 'probability']"
4043538,$N$ Poisson with parameter $\lambda$ and fixed $a>1$ calculate: $\lim \frac{\mathbb{P}(N\geq k)}{\mathbb{P}(N=k)}$,"For $N$ Poisson with parameter $\lambda$ and fixed $a>1$ calculate: \begin{equation}
            \lim \frac{\mathbb{P}(N\geq k)}{\mathbb{P}(N=k)},
        \end{equation} $\lambda \rightarrow \infty, k \rightarrow \infty, k/\lambda \rightarrow a$ . I'm thinking we can compute: \begin{align}
            \frac{\mathbb{P}(N\geq k)}{\mathbb{P}(N=k)} &= \frac{\sum_{i = k}^\infty \frac{\lambda^i e^{-\lambda}}{i!}}{\frac{\lambda^k e^{-\lambda}}{k!}}\\
            &= \sum_{i = 0}^\infty \frac{\lambda^i k!}{(i+k)!}
 \end{align} But I'm not sure how to simplify the last sum. Some hints would be greatly appreciated!",['probability-theory']
4043565,Is $f$ holomorphic in $\mathbb C$?,"Let $f:\mathbb C\to \mathbb C$ such that functions $z\mapsto \sin (f(z))$ and $z\mapsto \cos (f(z))$ are holomorphic on the entire complex plane. a) Is $f$ also holomorphic in $\mathbb C$ ? b) If we additionally assume that $f$ is continuous, is $f$ holomorphic in $\mathbb C$ ? Logic suggests that in point a) the correct answer is NO, and in b) YES, but I do not know how to prove it.",['complex-analysis']
4043583,How to find the second time when a piezoelectric crystal vibrates given a cubic trigonometric equation?,"The problem is as follows: In an electronics factory a quartz crystal is analyzed to get its
vibration so this frequency can be used to adjust their components. The length that it expands from a certain charge is given by: $6\tan\left(\frac{\pi t}{24}\right)\cdot\tan\left(\frac{\pi
 t}{24}+\frac{\pi}{3}\right)\cdot\tan\left(\frac{\pi
 t}{24}-\frac{\pi}{3}\right)$ micrometers. Assuming this interval $0\leq t \leq 12$ . Where $t$ is measured in
seconds. Find on which second the crystal expands $6$ micrometers? I'm not sure how to solve this question because I'm ending with a cubic equation and I don't really know how to solve that using precalculus tools. The thing is that all that equation is: $6\tan\left(\frac{\pi t}{24}\right)\cdot\tan\left(\frac{\pi t}{24}+\frac{\pi}{3}\right)\cdot\tan\left(\frac{\pi t}{24}-\frac{\pi}{3}\right)=6$ Hence: $\tan\left(\frac{\pi t}{24}\right)\cdot\tan\left(\frac{\pi t}{24}+\frac{\pi}{3}\right)\cdot\tan\left(\frac{\pi t}{24}-\frac{\pi}{3}\right)=1$ $\tan\left(\frac{\pi t}{24}\right)\cdot\left[\frac{\tan\frac{\pi t}{24}+\sqrt{3}}{1-\sqrt{3}\tan\frac{\pi t}{24}}\right]\cdot\left[\frac{\tan\frac{\pi t}{24}-\sqrt{3}}{1+\sqrt{3}\tan\frac{\pi t}{24}}\right]=1$ Then: $\tan\left(\frac{\pi t}{24}\right)\cdot\left[\frac{\tan \frac{\pi t}{24}-3}{1-3\tan^2\frac{\pi t}{24}}\right]=1$ $\tan\left(\frac{\pi t}{24}\right)\cdot\left[\tan \frac{\pi t}{24}-3\right]=1-3\tan^2\frac{\pi t}{24}$ $\tan^3 \left(\frac{\pi t}{24}\right)-3 \tan \left(\frac{\pi t}{24}\right)=1-3\tan^2\left(\frac{\pi t}{24}\right)$ $\tan^3 \left(\frac{\pi t}{24}\right) +3\tan^2\left(\frac{\pi t}{24}\right) -3 \tan \left(\frac{\pi t}{24}\right) -1 =0$ Then I landed here, now what? Because I'm not familiar with solving this sort of equation it would help me alot someone could guide on me what should be done next. The key from what I could notice is that if I could get that time, I would find when it gets its second value, hence the second time. But as I mentioned. I don't know how to do that.","['algebra-precalculus', 'trigonometry']"
4043598,Why is such function continuous?,"Can anyone help me see why the function $f: \bar{\mathbb{Q}} \to \mathbb{Q} $ where $\bar{\mathbb{Q}}$ denotes the set of algebraic numbers, $$f(x)=\begin{cases}1,&\ \text{if the real part of $x$ is greater than $\pi$, and}\\
0,&\ \text{otherwise.}\end{cases}$$ is continuous?","['general-topology', 'analysis']"
4043640,Does $\mathbb{E}[(1-\varepsilon_n)^{X_n}]\rightarrow 1$ imply that $\mathbb{P}(X_n\geq A_n)\rightarrow 0$?,"Let $X_n$ be a sequence of random variables taking values on the non negative integers which is finite almost surely (that is, for all $n\in\mathbb{N}$ , there exists $k=k(n)$ such that $\mathbb{P}(X_n>k)=0$ ), $\varepsilon_n\in(0,1)$ and $\varepsilon_n A_n\geq O(1)$ . Question: Does $\mathbb{E}[(1-\varepsilon_n)^{X_n}]\rightarrow 1$ imply that $\mathbb{P}(X_n\geq A_n)\rightarrow 0$ ? The main tool i've been using to relate these expressions is Markov Inequality, but in this case i get an inequality in the wrong direction. To illustrate this, here is my reasoning on why the converse is true if $\varepsilon_nA_n=o(1)$ . By the Markov Inequality, $$
\mathbb{P}(X_n\geq A_n)=1-\mathbb{P}(X_n<A_n)\geq 1- \frac{\mathbb{E}[(1-\varepsilon_n)^{X_n}]}{(1-\varepsilon_n)^{A_n}}.
$$ Now, as $(1-\varepsilon_n)^{A_n}=[(1-\varepsilon_n)^{1/\varepsilon_n}]^{A_n\varepsilon_n}$ and $\varepsilon_n A_n=o(1)$ , we have $(1-\varepsilon_n)^{A_n}\rightarrow 1$ , so $\mathbb{P}(X_n\geq A_n)\rightarrow 0$ implies $\mathbb{E}[(1-\varepsilon_n)^{X_n}]\rightarrow 1$ . I also think that the answer to my question could follow from some tail arguments in the expected value, but i'm not been able to formalize that.","['convergence-divergence', 'probability-theory', 'discrete-mathematics', 'random-variables']"
4043705,About the exactness of $n$-forms,"I have the following statement in my Analysis in $\mathbb{R}^n$ book: If $\omega$ is an $n$ -form on a orientable compact $n$ -manifold $M$ without boundary, then $\omega $ is exact if and only if $\int\limits_{M}\omega=0$ . In the comment on this post , it is mentioned that it is necessary that $M$ be connected. But in my book there is no comment on the need to be connected, can this be due to the definition of manifold? I am particularly interested in the volume form, I have that the volume form cannot be exact, the problem comes from using Stokes, the volume form would be zero (because the boundary is empty), can I still state this if the manifold is disconnected? A manifold of dimension $m$ and class $C^k$ in $\mathbb{R}^n$ is a set $M\subset R^n$ that can be covered by a collection of open $U\subset\mathbb{R}^n$ such that $V=U\cup M$ admits $C^k$ parameterization $\phi: V_0 \to V$ defined in an open $V_0\subset\mathbb{R}^m$ If I don't need connectivity because of my definition, what would be the definition that requires connectivity?","['manifolds', 'analysis', 'differential-geometry']"
4043815,"Combo problem, complementary counting","You have 5 blue nails in a column and 3 red nails in another column. You can attach a string between any red nail and blue nail. How many ways can we attach these strings such that every nail has at least 1 string attached to it? For example, drawing all possible strings would work. Or connecting the first 3 blue with first 3 red, then connecting the last 2 blue to any red would work. I approached this using Principle of Inclusion-Exclusion (if there is a simpler solution, let me know), but I am stuck. All I have is $(2^5-1)^3$ -something $(2^5-1)^3$ is the number of non-empty subsets of blue nails for the red nails to connect to, cubed because 3 red nails. I don't know what to subtract from this though","['combinations', 'combinatorics', 'problem-solving', 'recursion']"
4043860,Find $P(X_{(1)} < \mu < X_{(4)})$,"Let $X_1, X_2, X3, X4$ be iid random variables from a normal distribution with a mean of $\mu$ . Find $P(X_{(1)} < \mu < X_{(4)})$ My try: $P(X_{(1)} < \mu < X_{(4)})$ = $P(\mu < X_{(4)})$ - $P(\mu < X_{(1)})$ And I know how to get the distributions of $X_{(1)}$ and $X_{(4)}$ . But I think there must be a simpler way to find $P(X_{(1)} < \mu < X_{(4)})$ . Any suggestions would be great!","['statistics', 'probability-distributions', 'normal-distribution', 'probability']"
4043875,Two definitions of representation of a topological group,"Please compare the following two definitions: Definition 1 A representation of a topological group $G$ in a vector space ${\mathbb{V}}$ over complex numbers is a continuous map $$
  A\, :\quad G\times {\mathbb{V}}\longrightarrow{\mathbb{V}}\;\,,\qquad (g\,,\;v)\longmapsto A(g)\,v\;\,,\;\;\;\;\; g\in G\,,\;\;v\in{\mathbb{V}}\;\; \label{1}\tag{1}
  $$ with the following properties: (1) $\;\; A\,$ is a group action; (2) $\;\; A\,$ is linear, i.e. $$
  A(g)\,(\alpha\, v+\beta)=\alpha\, A(g)\, v+ A(g)\, w\quad \mbox{for}\quad\forall g\in G\,,\;\; v,\; w\in {\mathbb{V}}\,,\;\; \alpha\in{\mathbb{C}}\,\;.
  $$ Definition 2 A representation of a topological group $G$ in a vector space ${\mathbb{V}}$ is a homomorphism of $ G$ into the group of invertible linear transformations of ${\mathbb{V}}$ : $$
 A\,:\quad G\longrightarrow GL({\mathbb{V}})\;\,. \label{2}\tag{2}
 $$ $$
\,
$$ Definition 2 $\;\;\Longrightarrow\;\;$ Definition 1 , Indeed, the $A$ from Definition 2 is linear and ensures $\,(g\,,\;v)\longmapsto A(g)\,v\,$ . Also, Definition 2 says that $A$ is a homomorphism $-$ which guarantees the continuity of $\,(g\,,\;v)\longmapsto A(g)\,v\;$ in Definition 1 . QED To show that Definition 1 $\;\Longrightarrow\;$ Definition 2 , we must demonstrate that Definition 1 ensures \eqref{2} being a homomorphism. How to do this?","['group-theory', 'abstract-algebra', 'representation-theory', 'topological-groups']"
4043927,Learning roadmap and prerequisites for Isbell duality,"I'm looking for a roadmap to learning about Isbell duality . I know a reasonable amount about several of the ""specific"" dualities (Gelfand duality, AffSch - CRing, frames - locales, etc), especially affine schemes. However, I'm having trouble finding anything that amounts to a coherent presentation of the general case (with clear prerequisites), and how it ties back to the specific cases. The nlab article on space and quantity I can follow the ""idea"" part of, but when they get to the actual Isbell duality, I get lost at symmetric monoidal categories, $V$ -enriched categories, ends, coends... and what's more problematic is, I can't find a source that cleanly ties the general case back to the specific cases, or that discuss interesting examples where you have just an adjunction (instead of a full equivalence). Any guidance or resources are helpful, especially those with prerequisites clearly spelled out. I currently know basic category theory (first few chapters of Categories Work, chapter 1 of Vakil Algebraic Geometry).","['soft-question', 'category-theory', 'algebraic-geometry', 'gelfand-representation', 'duality-theorems']"
4043942,Binomial Distribution Word Problem,"A student gets at least 8 hours of sleep 45% of the nights; the sleeping schedule is independent from night to night. Let Xi indicate whether the student gets at least 8 hours of sleep during the next 4 night respectively for i = 1, 2, 3, and 4. Let X = X1 + X2 + X3 + X4. Find the variance of X. I'm struggling to understand what kind of distribution this problem is follow. I think it would be binomial. In that case wouldn't the variance of having x successes in 4 nights (trials) be modelled by the binomial. Hence the variance of X is (npq)^0.5 ? However, I feel like the question wants me to do some RV algebra. But a bit stuck.","['probability', 'random-variables']"
4043945,"Given a set of unitary matrices, can one find a vector whose images under these unitary matrices span the underlying Hilbert space?","Given a set of (linearly independent) $d\times d$ complex unitary matrices $\{U_i\}_{i=1}^n \subseteq M_d$ with $n\geq d$ , does there exist a vector $v\in \mathbb{C}^d$ such that $$\text{span} \{U_1v, U_2v, \ldots , U_nv\} = \mathbb{C}^d ?$$ The motivation for this question comes from the theory of mixed unitary quantum channels. A quantum channel $\Phi: M_d \rightarrow M_d$ is a completely positive and trace preserving linear map. Any such map admits a Kraus representation of the form $\Phi (X) = \sum_{i=1}^k A_i X A_i^*$ , where $\{A_i \}_{i=1}^k \subseteq M_d$ and $\sum_{i=1}^k A_i^* A_i = \mathbb{I}_d$ . We say that a quantum channel is mixed unitary if it can be expressed as a convex combination of unitary conjugations: $\Phi (X) = \sum_{i=1}^n p_i U_i X U_i^*$ . Our aim then is to look for a rank one input projector $X = vv^*$ for some $v\in \mathbb{C}^d$ such that the output $\Phi (vv^*) = \sum_{i=1}^n p_i (U_i v) (U_i v)^*$ has full rank. This is possible only if $n\geq d$ . To avoid trivial counterexamples, we can also assume that $\{ U_i\}_{i=1}^n \subseteq M_d$ is linearly independent. Follow-up question: Since it has been shown below that the question can be answered in the negative for $d\geq 4$ , the natural way of progression would be to ask if one can provide a classification of all the sets of (linearly independent) unitary matrices $\{U_i\}_{i=1}^n \subseteq M_d$ which allow for the existence of $v\in \mathbb{C}^d$ such that $$\text{span}\{U_1v, U_2v, \ldots ,U_nv\}=\mathbb{C}^d.$$ One can also try to answer this question for (linearly independent) sets of arbitrary complex matrices: $\{ A_i \}_{i=1}^k \subseteq M_d$ .","['matrices', 'unitary-matrices', 'linear-algebra']"
4043958,Infinity in ZFC vs infinity in the metatheory,"I was reading about different ways to formalize the notion of infinity in ZFC. The classic axiom is of course to have the existence of an inductive set, but you can also assert the existence of a Dedekind infinite set, and it turns out it is equivalent. (This question shows this: How can I define $\mathbb{N}$ if I postulate existence of a Dedekind-infinite set rather than existence of an inductive set? ) They both give a notion of infinity internal to the theory. However, I am not quite sure how much this coincides with a ""metatheoretic"" understanding of infinity. For instance, let $L=\{=,\in\}$ and let $T$ be the $L$ -theory consisting of all axioms of ZFC except for the axiom of infinity. Define a new language $L'=L\cup\{c\}$ with a single additional constant symbol, and define a new theory $$T'=T\cup\{\exists x_1\dots\exists x_n\bigwedge_{1\leq i<j\leq n}x_i\neq x_j\wedge\bigwedge_{i=1}^n x_i\in c:n\in\mathbb{N}\}.$$ This seems to be a very natural way to capture the notion of infinity, but I don't know whether we could prove that the realization of $c$ in a model of $T'$ is Dedekind-infinite in the sense of ZFC. Therefore, in light of the question I put a link to, my question is: is $T'$ equivalent to ZFC?","['elementary-set-theory', 'model-theory', 'infinity', 'set-theory']"
4044022,Evaluate $\frac{4}{\sin^2 20^\circ} - \frac{4}{\sin^2 40^\circ} + 64\sin^2 20^\circ$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Evaluate the following expression: $$\frac{4}{\sin^2 20^\circ} - \frac{4}{\sin^2 40^\circ} + 64\sin^2 20^\circ$$ I tried combining the whole into a single fraction and using double-angle identity, product/sum to sum/product, but it didn't work.","['algebra-precalculus', 'trigonometry']"
4044067,Analytic Properties of $f(x) = x^x$,"The function $f(x) = x^x, x > 0$ can be plotted on graphing software and inspected to see a local minimum around .367. The function is convex, decreasing from 0 to its minimum, and increasing thereafter. The derivative of the function can be found by implicit differentiation to be $f'(x) = x^x(\ln(x)+1)$ . Can the exact value of the local minimum be found? Can someone explain intuitively why the function first decreases and then increases? Is there anything interesting about the class of functions $\{ \, f(x) \, | \, f'(x) = f(x) \cdot g(x) \, \}$ Edit: I forgot, I'll be subject to a firing squad if I don't explain what I have tried! Setting the derivative equal to 0 doesn't do much for me. If this can be solved exactly without optimization algorithms, I suspect something really clever will need to happen. I tried thinking about what is happing for different types of inputs (irrational $x$ , rational $x$ , natural $x$ ). Still didn't get anywhere. Nothing to try really, does this class of functions come up anywhere in math?","['optimization', 'calculus', 'derivatives']"
4044094,To prove:- $|AB-I|+|BA-I| =0$ given that $A$ is any $3\times 2$ matrix and $B$ is any $2\times 3$ matrix.,"I was just told that for any given matrix if it is $n\times (n-1)$ and another of $(n-1)\times n$ then also the above kind of situation that is $$\det(AB-I)+\det(BA-I)=0,$$ where $I$ is the corresponding identity matrix of the square matrix so formed. Also in order to prove it I tried to solve it by any theorem that I know or so but was unable. So, I checked it for any random matrix with random variable and calculated the same thing via a matrix calculator, and shockingly it was correct. I searched it on internet and was unable to find any explanation.
So, I eventually turned to stack exchange. Any help would be appreciated!","['matrices', 'algebra-precalculus', 'determinant', 'real-analysis']"
4044114,Subsets sharing at most $i$ elements,"Assume I have a set $S$ of $N$ elements and I create subsets with $k$ elements from it. With no additional property the number of possible such subsets will be $N \choose k$ . Now I want my subsets to satisfy some additional rules $R_i$ : Given a set $X$ of subsets of $S$ with $k$ elements (i.e. $\forall A \in X, A \subset S , \#A=k$ ), $X$ satisfies $R_i$ if and only if for all $A$ and $B$ in $X$ , $A$ and $B$ share at most $i$ elements, i.e. $\forall A , B \in X, \#(A \cap B) \le i$ . Let's call $S_i$ the set of all such $X$ satisfying $R_i$ . I want to know how large a set satisfying $R_i$ can be, i.e. what is $M_i = \max_{X \in S_i} \#X $ For example if $N=1000$ and $k=10$ , trivially we have $M_9 = {1000 \choose 10}$ : the largest ensemble of subsets of $10$ elements that share at most $9$ with one another is exactly the set of all possible combinations of $10$ elements out of $1000$ . Similarly at the other extreme, still for $N=1000$ and $k=10$ , we have $M_0 = 1000/10=100$ . Is there a formula or clever (not brute force) algorithm to compute other less trivial cases for $i=1,2,\dots8$ ? BTW even if there is a nice formula, I'll ultimately want to implement a way to get a maximal $X$ ...",['combinatorics']
4044136,Is a partially ordered set (poset) a partial algebraic structure?,"If a partially ordered set $(S, \leq)$ is defined by a set $S$ and a partial homogeneous binary relation $\leq$ ,
then can it be expressed as a partial algebraic structure $(S, f)$ ,
where $f$ is a partial function $f : S^2 \to \{True, False\}$ ?","['elementary-set-theory', 'order-theory', 'functional-analysis', 'relations']"
4044193,Proving an Identity involving sums related to the $Z(N)$-Ising model,"Background: I am trying to construct meromorphic functions satisfying a number of axioms, so-called form factors which are important objects in integrable quantum models, following this paper . Building blocks for these form factors are functions $I_{n,\mathbf{m}}(\boldsymbol{\theta})$ . I am trying to understand their derivation by hand because higher orders are too complicated to be computable by a CAS. One example that I can compute with mathematica and try to compute by hand is: $$
I_{4,21}(\theta_1, \theta_2, \theta_3, \theta_4) = \frac{1}{2} \int_{C_{\theta}} \frac{dz_1 dz_2 dz_3}{R^3} \Big( \prod_{i=1}^3 \prod_{j=1}^4 \phi(z_i - \theta_j) \Big) \frac{1}{\phi(z_{12}) \phi(z_{21})}  \prod_{i=1}^2 \frac{1}{\phi(z_{i3})} ~,~~ z_{ij} := z_i - z_j 
$$ with $$ \phi(z) = \frac{1}{\sinh\frac{z}{2} \sinh\Big(\frac{z}{2} + \frac{i\pi}{4} \Big) } $$ and $C_\theta$ a contour going around each $\theta_j$ such that $\int_{C_\theta} \frac{dz}{R} \phi(z - \theta_j) =1$ for $j\in\{1,2,3,4\}$ . So far, I managed to evaluate the above contour integration and obtained: $$ I_{4,21}(\boldsymbol{\theta}) = \sum_{k=1}^4 \Big( \prod_{\substack{i=1 \\ i\neq k}}^4 \phi(\theta_{ik}) \Big) \sum_{\substack{l=1 \\ l \neq k}}^4 
	\Big( \prod_{\substack{i=1 \\ i\neq l,k}}^4 \phi(\theta_{li}) \Big) ~,~~ \theta_{ij} := \theta_i - \theta_j $$ My Question: Using mathematica, I can show that (for the definition of $\phi$ , see above): $$ \sum_{k=1}^4 \Big( \prod_{\substack{i=1 \\ i\neq k}}^4 \phi(\theta_{ik}) \Big) \sum_{\substack{l=1 \\ l \neq k}}^4 
	\Big( \prod_{\substack{i=1 \\ i\neq l,k}}^4 \phi(\theta_{li}) \Big) =32\sqrt{2} \Big( 2 + \sum_{\substack{i,j=1\\i<j}}^4 \cosh\theta_{ij} \Big) \prod_{\substack{i,j=1\\i<j}}^4 \frac{1}{\cosh\theta_{ij}} ~,~~ \theta_{ij} := \theta_i - \theta_j. $$ How can I prove this identity by Hand? My attempt: So far, I found the basic identity $\phi(\theta) + \phi(-\theta) = \frac{2\sqrt{2}}{\cosh\theta}$ . The identity can be rewritten as $$ I_{4,21}(\boldsymbol{\theta}) = \sum_{k=1}^4 \Big( \prod_{\substack{i=1 \\ i\neq k}}^4 \phi(\theta_{ik}) \Big) \sum_{\substack{l=1 \\ l \neq k}}^4 
	\Big( \prod_{\substack{i=1 \\ i\neq l,k}}^4 \phi(\theta_{li}) \Big) =\frac{1}{4} \Big( \frac{1}{\sqrt{2}} + \sum_{\substack{i,j=1\\i<j}}^4 \frac{1}{\phi(\theta_{ij}) + \phi(\theta_{ji})} \Big) \prod_{\substack{i,j=1\\i<j}}^4 \Big(\phi(\theta_{ij}) + \phi(\theta_{ji})\Big). $$ Also, I verified with mathematica the partial identity: $$ \sum_{\substack{l=1 \\ l \neq k}}^4 
	\Big( \prod_{\substack{i=1 \\ i\neq l,k}}^4 \phi(\theta_{li}) \Big) = 4 \Big( 1 + \sum_{\substack{i,j=1\\ i<j\\ i,j\neq k}}^4 \cosh\theta_{ij} \Big) \prod_{\substack{i,j=1\\ i<j\\ i,j\neq k}}^4 \frac{1}{\cosh\theta_{ij}} = \frac{1}{2} \Big( \frac{1}{\sqrt{2}} + \sum_{\substack{i,j=1\\ i<j\\ i,j\neq k}}^4 \frac{1}{\phi(\theta_{ij}) + \phi(\theta_{ji})} \Big) \prod_{\substack{i,j=1\\ i<j\\ i,j\neq k}}^4 \Big( \phi(\theta_{ij}) + \phi(\theta_{ji}) \Big)   $$ However, I am unable to show it by hand and do not know how to proceed from here. I suspect I am missing an identity involving $\phi$ which makes the identity more obvious, but I do not see it. I am thankful for any, even partial, help! I you need more detail on the question or background, please ask.","['physics', 'trigonometry', 'integrable-systems', 'summation']"
4044205,Moment generating function. A miner is trapped in a mine containing 3 doors.,"A miner is trapped in a mine containing 3 doors. The first door leads to a tunnel that will take him to safety after 3 hours of travel. The second door leads to a tunnel that will return him to the mine after 5 hours of travel. The third door leads to a tunnel that will return him to the mine after 7 hours. If we assume that the miner is at all times equally likely to choose any one of doors, what is the expected length of time until he reaches safety? I did it normally but I have been asked to solve through moment generating function. I don't know how to proceed","['conditional-probability', 'probability-distributions', 'probability-theory']"
4044206,Finding the particular solution of a differential equation using at least three different methods.,"Find the particular solution $(x^2+6y^2)dx-4xydy=0$ ; when $x=1$ , $y=1$ using at least three different methods. I have done the first two. Can somebody help me with the third method. Method 1: Homogenous Equation Let $y=vx; dy=vdx+xdv$ $(x^2+6x^2v^2)dx-4x(vx)(vdx+xdv)=0$ $(x^2+2x^2v^2)dx-4x^3vdv=0$ $(1+2v^2)dx-4xvdv=0$ $\int\frac{dx}{4x}-\int\frac{v}{1+2v^2}dv=0$ $\ln{x}-\ln{(2v^2+1)}=C$ $\ln{(\frac{x}{2v^2+1})}=\ln{C}$ $\frac{x}{2v^2+1}=\frac{1}{C}$ $C=3$ $3x=2v^2+1$ $3x^3=2y^2+x^2$ $2y^2=x^2(3x-1)$ The particular solution by method 1 is $2y^2=x^2(3x-1)$ . Method 2: Bernoulli Equation $2y\frac{dy}{dx}-\frac{x^2+6y^2}{2x}=0$ $2y\frac{dy}{dx}-\frac{3y^2}{x}=\frac{x}{2}$ Let $v=y^2; dv=2ydy$ $\frac{dv}{dx}-\frac{3v}{x}=\frac{x}{2}$ $P(x)=-3x^{-1}$ ; I.F. $=e^{-3\int x^{-1}dx}=x^{-3}$ $vx^-3=\frac{1}{2}\int\frac{dx}{x^2}$ $2vx^{-3}=-x^{-1}+C^{-1}$ $2y^2x^{-3}+x^{-1}=C^{-1}$ $C=\frac{1}{3}$ $2y^2+x^2=3x^3$ $2y^2=x^2(3x-1)$ The particular solution by method 2 is also $2y^2=x^2(3x-1)$ .","['solution-verification', 'ordinary-differential-equations']"
4044240,"Game theory, probability and snooker","I have a question that is very simple to understand and very complex to answer. If a snooker player could elect to forego potting a coloured ball (typically worth a handful of points) and instead move onto another (worth one), would they? For simplicity, assume that a player can pot any ball of their choosing with probability p. Their opponent can pot with probability q (where p can be greater than, equal to or less than q). The aim of the game is to gain more points than is left on the table. Importantly, I am assuming that in this mathematical snooker game, the coloured balls must be potted at the end, as in regular snooker. What is the optimal strategy for a player to take? Always reds? Always trying for colours? A mix? It depends what the opponent does? It depends on p and q? (You can assume p and q are approximately $0.9$ but varying these would be interesting) If you want to try doing this computationally, feel free to reduce the number of reds from 15 to 10 or 6 as is sometimes played, unless you think that would change the result.","['game-theory', 'recreational-mathematics', 'dynamic-programming', 'probability']"
4044259,Splitting field of a polynomial over Z_5,"Find the splitting field of the polynomial $$x^3+x+1$$ over $\mathbb{Z}_5$ . I can see that the given polynomial is irreducible over $\mathbb{Z}_5$ So, $$\dfrac{\mathbb{Z}_5 [x]}{(x^3+x+1)}$$ is a field and isomorphic to $\mathbb{Z}_5(\alpha)$ where $\alpha$ is the image of $x$ under the canonical map $$\pi \colon \mathbb{Z}_5[x]\to \dfrac{\mathbb{Z}_5 [x]}{(x^3+x+1)}.$$ So, $\alpha$ is a root of the polynomial over $\mathbb{Z}_5(\alpha)$ and it factorizes as $$x^3+x+1=(x-\alpha)(x^2+\alpha x+\alpha^2+1)$$ over $\mathbb{Z}_5(\alpha)$ . But now I can't conclude anything about $x^2+\alpha x+\alpha^2+1$ . Any help will be highly appreciated. Thank you!","['field-theory', 'galois-theory', 'abstract-algebra']"
4044263,"Find the volume of the solid in the first octant bounded by the three surfaces $z = 1-y^2$, $y=2x$, and $x=3$","I want to find the volume of the solid in the first octant bounded by the three surfaces $z = 1-y^2$ , $y=2x$ , and $x=3$ . It seems that would simply be to calculate the following triple integral: $\int_0^3 \int_0^{2x} \int_0^{1-y^2} z\,dz\,dy\,dx$ This is pretty straight-forward to do without any variable substitutions etc. which makes me think it's almost too simple (for a home assignment). Am I missing something or is the above correct?","['integration', 'multivariable-calculus']"
4044399,Characterizing simply connected spaces,"A topological space $X$ is simply connected if it is pathwise connected and each closed path $u : I = [0,1] \to X$ is path homotopic to the constant path at $x_0 = u(0) = u(1)$ . Recall that A closed path $u$ is one with $u(0) = u(1)$ . A closed path will also be called a loop and we write $\mathcal L'(X)$ for the set of all loops in $X$ . If we want to be more precise, we say $u$ is a loop based at $x_0 \in X$ provided $x_0 = u(0) = u(1)$ . By $\mathcal L'(X,x_0)$ we denote the set of all loops in $X$ which are based at $x_0$ . Also note that each constant path is a loop. Two paths $u, v : I \to X$ with the same initial point $x_0 = u(0) = v(0)$ and the same terminal point $x_1 = u(1) = v(1)$ are path homotopic , $u \simeq_p v$ , if there exists a  homotopy $H : I \times I \to X$ such that $H(t,0) = u(t)$ and $H(t,1) = v(t)$ for all $t$ and $H(0,s) = x_0, H(1,s) = x_1$ for all $s$ (such a homotopy $H$ is stationary on the boundary $\partial I = \{0,1\}$ ; it is called a path homotopy ). It is well-known that $\simeq_p$ is an equivalence relation on the set $\mathcal P(X)$ of all paths in $X$ . Clearly $\simeq_p$ restricts to an equivalence relation on $\mathcal L'(X)$ and to an equivalence relation on each $\mathcal L'(X,x_0)$ . The set of equivalence classes $\mathcal L'(X,x_0)/\simeq_p$ is nothing else than the fundamental group $\pi_1(X,x_0)$ with base point $x_0$ . Question: Find a list, as complete as possible, of properties characterizing topological spaces which are simply connected. Each of these properties can then be taken as an alternative definition of simply connected . Note that many questions in this forum deal with aspects of simple connectedness. The answer to the present question will hopefully cover most of them.","['general-topology', 'algebraic-topology']"
4044461,"How many arrangements of red and blue balls are there so that, the number of red balls with: the ball immediately to the right is also red, is $9$.","The question is too long to fit in the title, but I tried. $50$ balls: $23$ indistinguishable red balls; $27$ indistinguishable blue balls. The balls are arranged in a line. How many distinct arrangements of the balls are there so that the following property holds: The number of red balls such that the ball immediately to the right of it is also red, is $9.\quad (1)$ Can I please get my following solution verified. Also, feel free to post alternative solution of course. Let the number of red balls with property $(1)$ be $k$ . If we start by placing all $23$ red balls next to each other, then $k=22.\ $ Now between each red ball, we imagine there is a bin. We don't yet have a bin to the left of the first red or a bin to the right of the last red. There are $22$ bins between the first and last red ball. Each time you put a blue ball into one of these bins, you reduce the number $k$ by $1$ . So what we can first do is find the number of distinct ways to put $(22-9=)\ 13$ blue balls into $22$ bins so that no two balls are in the same bin. This is just $\binom{22}{13}.$ Now we have placed $13$ blue marbles into bins such that no two blue marbles are in the same bin, and we did this so that $k=9$ , and so property $(1)$ holds. We now have $27-13=14$ blue marbles remaining to put into bins. Ah, but not $22$ bins because that would ruin property $(1)$ , and not just $13$ bins: the ones that we have just put the blue balls into, but... Now we introduce a bin to the left of the first red and another bin to the right of the last red. We put the remaining $(27-13=)\ 14 $ blue balls into $(1+13+1=)\ 15$ bins! How many ways are there of doing this? Well, it is a classic stars and bars problem, in particular see Theorem 2 on wikipedia . The number of ways of putting the remaining $14$ blue balls into $15$ bins is $\binom{14+15-1}{14} =\binom{28}{14}.$ I believe all possible arrangements can be done like this, and there are no repeats in this method. Therefore the final answer is: $$ \binom{22}{13}\times\binom{28}{14} = 497420\times40116600 = 19954799172000$$","['combinations', 'combinatorial-proofs', 'solution-verification', 'combinatorics', 'binomial-coefficients']"
4044477,Inverse Matrix of a Special Matrix for Optimization,"For some portfolio optimization problems, it finally comes to an inverse matrix of a special matrix $$B=\begin{bmatrix}
A & \mathbf{1} \\
\mathbf{1}' & 0
\end{bmatrix}$$ where $A$ is a symmetric matrix and $\mathbf{1}=(1,\cdots,1)'\in\mathbb{R}^n$ . Can anyone help to find the inverse matrix of matrix $B$ ? Thanks a lot! Below is the background of the above problem: Assume $\omega$ is the weight vector of the portfolio, $\mu$ is the return vector and $\Sigma$ is the covariance matrix. The constraint is $\sum\omega=1$ . For different optimization problems, we will have different targets: For the optimization problem of minimum variance: $$\min_\omega\omega'\Sigma\omega$$ applying the Lagrange multiplier, we have the matrix equation $$\begin{bmatrix}
2\Sigma & \mathbf{1} \\
\mathbf{1}' & 0
\end{bmatrix}
\begin{bmatrix}
\omega \\
\lambda
\end{bmatrix}=
\begin{bmatrix}
\mathbf{0} \\
1
\end{bmatrix}$$ For the optimization problem of mean-variance optimization: $$\max_\omega\omega'\mu-\frac{1}{2}\delta\omega'\Sigma\omega$$ applying the Lagrange multiplier, we have the matrix equation $$\begin{bmatrix}
-\delta\Sigma & \mathbf{1} \\
\mathbf{1}' & 0
\end{bmatrix}
\begin{bmatrix}
\omega \\
\lambda
\end{bmatrix}=
\begin{bmatrix}
-\mu \\
1
\end{bmatrix}$$ Anyway, it comes to the problem of inverse matrix of $$B=\begin{bmatrix}
A & \mathbf{1} \\
\mathbf{1}' & 0
\end{bmatrix}$$","['matrices', 'matrix-equations', 'linear-algebra', 'matrix-calculus']"
4044571,"Find all functions satisfying $ f \left( m ^ 2 + f ( n ) \right) = f ( m ) ^ 2 + n $, for all $ m , n \in \mathbb N $","Find all functions $f:\mathbb{N}\to\mathbb{N}$ such that $$f(m^{2}+f(n))=f(m)^{2}+n\text {, for all }m,n\in \mathbb N$$ I was initially unable to solve this problem, so I referred to a hint. The hint is as follows: Let $f(1)=k$ . From the given equation, we get $f(m^{2}+k)=1+f(m)^{2}$ and $1+k^{2}=f(1+k)$ . Use this to prove that $$f(f(m))^{2}-f(k)^{2}=m^{2}-1 \ \ \ \ \ \ (*)$$ Taking $m=2$ , conclude that $f(k)=1 \ \ \ (*)$ . Obtain $f(f(m))=m$ for all $m\in \mathbb{N}$ . Use this to prove that $$f(n+1)=f(n)+k^{2} \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (*)$$ By induction $f(n+1)=f(1)+nk^{2}=k+nk^{2}$ . Conclude that $k=1$ and hence $f(n)=n$ for all $n\in \mathbb{N}$ This solution is very unclear to me. I have marked all unclear steps with $(*)$ . Please breakdown this solution and provide well explained arguments for the marked steps. Please try to use the same notation I have provided in the solution for ease of understanding. Thanks for all help :)","['contest-math', 'functional-equations', 'functions']"
4044578,Proof of Lemma 6.3 in Carothers' Real Analysis,"Lemma 6.3 (Chapter 6 - Connectedness) : Let $E$ be a subset of a metric space $(M,d)$ . If $U$ and $V$ are disjoint, open
sets in $E$ , then there are disjoint open sets $A$ and $B$ in $M$ such that $U= A \cap E$ and $V = B \cap E$ . The proof roughly goes as follows (I haven't typed it out exactly , but I have captured all the important details) - Since $U$ is open in $E$ , for each $x\in U$ , $\exists\epsilon_x > 0$ such that $E\cap B(x,\epsilon_x) \subset U$ . Since $V$ is open in $E$ , for each $y\in V$ , $\exists\delta_y > 0$ such that $E\cap B(y,\delta_y) \subset V$ . Since $U\cap V = \varnothing$ , we also have $E\cap B(x,\epsilon_x) \cap B(y,\delta_y) = \varnothing$ . Now, the author claims that : For every $x\in U$ and $y\in V$ , $$B\left(x,\frac{\epsilon_x}{2}\right) \cap B\left(y,\frac{\delta_y}{2}\right) = \varnothing$$ Why is this true? I'm trying to show this in the following way. Suppose $z \in B\left(x,\frac{\epsilon_x}{2}\right) \cap B\left(y,\frac{\delta_y}{2}\right)$ . So, $d(x,z) < \epsilon_x/2$ and $d(y,z) = \delta_y/2$ . To show that the intersection is non-empty would amount to showing $d(x,z) < \epsilon_x/2$ and $d(y,z) = \delta_y/2$ cannot hold together. How do I do this? Thus, $$A = \bigcup_{x\in U} B\left(x,\frac{\epsilon_x}{2}\right) \text{ and } B = \bigcup_{y\in V} B\left(y,\frac{\delta_y}{2}\right)$$ work. Why does this choice of $A, B$ work? All I need to show for this, is that $U = A\cap E$ and $V= B\cap E$ right? Is anything else needed to be done? Thank you. Picture for Reference: Attempting a Proof by Contradiction: As mentioned in an answer, $B(x,r/2)\subset B(x,r)$ . Suppose $\exists x \in U, \exists y\in V$ for which $B\left(x,\frac{\epsilon_x}{2}\right) \cap B\left(y,\frac{\delta_y}{2}\right) \ne \varnothing$ . Also, $$E\cap B(x,\epsilon_x) \subset U \implies E\cap B(x,\epsilon_x/2) \subset U$$ and $$E\cap B(y,\delta_y) \subset V \implies E\cap B(y,\delta_y/2) \subset V$$ What's next? I'm not able to find a contradiction. $U\cap V = \varnothing \implies E\cap B(x,\epsilon_x) \cap B(y,\delta_y) = \varnothing$ , and I believe this is what we want to contradict.","['proof-explanation', 'metric-spaces', 'analysis', 'real-analysis']"
4044579,Localization with respect to set that is NOT mutliplicatively closed,"All rings are assumed to be commutative with unity. Usually denoted $R$ Intro : I understand that there are two definitions of localization (or possibly more, but these two are somewhat canonical for me): 1 Defining ring of fractions with elements from multiplicative $S$ as denominators. 2 For any set $S$ by universal property of localization: $\alpha \in Hom(R, S^{-1}R)$ such that a) $\alpha(s)$ is invertible and b)If $\beta \in Hom(R, T)$ and $\beta(s)$ invertible in $T$ then there is $\gamma \in Hom(S^{-1}R, T)$ such that these ring homomorphisms commute. I understand the "" fractions definition"" and from this, I built some understanding of Categorical definition. We also had a proposition in my Alg. Geometry class showing that rings of fractions from the first definition (together with homomorphism $r->r/1$ ) are basically the same thing as  in the categorical definition. Question However, the categorical definition needs not the assumption of $S$ being multiplicatively closed. How does a (categorical) localization with respect to $S$ not multiplicatively closed looks like ? My thoughts Of course the definition does not say that such localization exists. But what looks more natural to me is take $S'\supset S$ the smallest multiplicatively closed set containing $S$ and consider localization with respect to $S'$ . I suppose that all elements from $S'$ would be invertible also in $S^{-1}R$ so maybe using universal property of localization should work?","['localization', 'universal-property', 'algebraic-geometry', 'commutative-algebra']"
4044654,Are continuous convex functions subharmonic?,"We say that a continuous function $u:\mathbb{R}^d\to \mathbb{R}$ is subharmonic if it satisfies the mean value property $$u(x)\leq \frac{1}{|\partial
 B_r(x)|}\int_{\partial B_r(x)}u(y)\,\mathrm{d}y \qquad (\star)$$ for
any ball $B_r(x)\subset \mathbb{R}^d$ . Let $u:\mathbb{R}^d\to \mathbb{R}$ be a convex function (hence,
continuous). Is $u$ subharmonic? If $u\in C^2(\mathbb{R}^d)$ , this is  true. Using a second-order Taylor expansion we have \begin{align*}\int_{\partial B_r(x)}(u(y)-u(x))\,\mathrm{d}y&=\int_{\partial B_r(x)}\left(\nabla u(x)\cdot(y-x)+\frac{1}{2}(y-x)D^2u(\xi)(y-x)^t\right)\,\mathrm{d}y.\end{align*} The first term in the above integral vanishes by symmetry, the second is non-negative because $D^2u(\xi)$ is a positive semi-definite matrix. Therefore, ( $\star$ ) is proven. If $d=1$ , the statement is true when $u$ is continuous, in general. Indeed since balls reduce to intervals, ( $\star$ ) is easily shown to be equivalent to $u$ being midpoint-convex. I'm not sure how to attack the problem in higher dimensions. Of course $(\star)$ is true for affine functions in any dimension, and I'd like to use the fact that the graph of a convex function lies below that of an affine function, loosely speaking. However, to close the estimate I would need $u$ to be equal to the affine function at the boundary of the ball, and this is not necessarily possible.","['convex-analysis', 'analysis']"
4044661,Find $ \lim_{r \to 1^{-}} \int_{-\pi}^{\pi} (\frac{1+2r^2}{1-r^2\cos2\theta})^{1/3}d\theta$,"Evaluate $$ \lim_{r \to 1^{-}} \int_{-\pi}^{\pi} \left[\frac{1+2r^2}{1-r^2\cos\left(2\theta\right)}\right]^{1/3}{\rm d}\theta  $$ Question - Can I take the limit inside the integral? My try- $$I= \lim_{r \to 1^{-}} \int_{-\pi}^{\pi} \left(\frac{1+2r^2}{1-r^2\cos2\theta} \right)^{1/3}\, d\theta  $$ $$ I= \int_{-\pi}^{\pi}   \lim_{r \to 1^{-}}  (\frac{1+2r^2}{1-r^2\cos2\theta})^{1/3}d\theta  $$ $$ I=3^{1/3} \int_{-\pi}^{\pi}  \frac{1}{(1-\cos2\theta)^{1/3}}d\theta  $$ $$ I= 3^{1/3}2\int_{0}^{\pi}    \frac{1}{(1-\cos2\theta)^{1/3}}   d\theta       $$ $$ I= 3^{1/3}4\int_{0}^{\pi/2}    \frac{1}{(1-\cos2\theta)^{1/3}}   d\theta       $$ $$ I= (3/2)^{1/3}4\int_0^{\pi/2} 
\sin^{-2/3}\theta  \  d\theta       $$ $$I= 4(3/2)^{1/3} \frac{\Gamma(1/6)\Gamma(1/2) }{\Gamma(2/3)}. $$","['integration', 'real-analysis', 'calculus', 'trigonometric-integrals', 'limits']"
4044670,What is the largest volume of a polyhedron whose skeleton has total length 1? Is it the regular triangular prism?,"Say that the perimeter of a polyhedron is the sum of its edge lengths. What is the maximum volume of a polyhedron with a unit perimeter? A reasonable first guess would be the regular tetrahedron of side length $1/6$ , with volume $\left(\frac16\right)^3\cdot\frac1{6\sqrt{2}}=\frac{\sqrt{2}}{2592}\approx 0.0005456$ . However, the cube fares slightly better, at $\frac{1}{1728}\approx 0.0005787$ . After some experimentation, it seems that the triangular prism with all edges of length $1/9$ is optimal, at a volume of $\frac{\sqrt{3}}{2916}\approx0.00059398$ . I can prove that this is optimal among all prisms (the Cartesian product of any polygon with an interval) and that there is no way to cut off a small corner from the shape and improve it. Is the triangular prism the largest polyhedron with a fixed perimeter? I can prove a weak upper bound of $\frac1{12\pi^2\sqrt{2}}\approx 0.00597$ on the volume of such a polyhedron, by combining the isoperimetric inequalities in both $2$ and $3$ dimensions (i.e., the fact that polygons cannot enclose more surface area than a circle and that a polyhedron cannot enclose more volume than a sphere of the same surface area) along with the observation that a single face of a polyhedron cannot take up the majority of its surface area. Note the number of leading zeros - this upper bound is a bit over $10$ times my lower bound! Edit: A friend of mine has confirmed with Mathematica that no polyhedron with $5$ or fewer vertices, or anything combinatorially equivalent to the triangular prism, improves on this bound. (With some work, this approach might be extended to all polyhedra on at most $k$ vertices, for $k$ on the order of $7$ to $10$ .)","['polyhedra', 'volume', 'calculus-of-variations', 'geometry', 'optimization']"
4044710,Figuring out Mechanics of How Chain Rule was Applied,"How do I go from system $(1)$ to system $(2)$ below? \begin{gather}
\begin{aligned}
S &= K e^{x}\\[7pt]
V(S,t) &= K v(x, \tau)\\
\tau &= (T-t) \frac{\sigma^{2}}{2}
\end{aligned}\tag{1}
\end{gather} \begin{gather}
\begin{aligned}
\frac{d}{dt}V &= -K \frac{\sigma^{2}}{2} \frac{d}{d \tau} v\\
\frac{d}{dS}V &= \frac{K}{S} \frac{d}{dx} v
\end{aligned}\tag{2}
\end{gather}","['calculus', 'change-of-variable', 'derivatives', 'chain-rule']"
4044728,Examples of the difference between Topological Spaces and Condensed Sets,"There is apparently cutting-edge research by Dustin Clausen & Peter Scholze (and probably others) under the name Condensed Mathematics, which is meant to show that the notion of Topological Space is not so well-chosen, and that Condensed Sets lead to better behaved structures. What is a simple low-tech example to see the difference? I am looking for some explicit construction with quite simple topological spaces where some bad behaviour occur, and how their condensed analog fix that. I am aware of the nlab entry and of an introductory text by F. Deglise on this page but it goes quite far too quickly and I am missing knowledge to grasp it.","['general-topology', 'topological-vector-spaces', 'functional-analysis', 'algebraic-topology']"
4044768,Cambridge Admissions Exam Statistics 1999,"My work: Since $f$ is the pdf we must have $\int_{0}^{1} Ax\,\mathrm dx=1 \implies A=2$ .  Let $Y$ be the number of currants in my portion. We have $Y\sim B(4,x)$ . For the expectation $$E(Y)=4x,$$ however I don't know how to continue. I had a thought of using the expectation for $x$ in this, however, I can't statistically justify it. For the second part, we require $$P\left(X\geq\frac{1}{2}\mid Y=4\right)=\frac{P\left(X\geq\frac{1}{2},Y=4\right)}{P(Y=4)}.$$ I am completely stuck on how to approach this. I checked the student room for solutions but they seem to disagree with themselves and with other solutions on other websites. If anybody could help me in understanding this problem, and the technique required for it I would be really thankful.","['statistics', 'probability-distributions']"
4044778,How can I prove that the l.h.s equals the r.h.s? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I can't move forward.  Can anyone help? $$\frac{k (2k) + 2 }{ k (k + 1) }= \frac{2k + 2 }{ k + 2}$$ I'm trying to prove that the left side equals the right side. It started like this $$\frac{2k }{ k + 1} + \frac{1}{1+2+3+...+(k+1)}= \frac{2(k + 1) }{ (k + 1) + 1}$$",['discrete-mathematics']
4044791,Counting numbers smaller than $N$ with exactly $k$ *distinct* prime factors,"Using common notation, $\omega(n)$ is the number of distinct prime factors on $n$ . Similiarly, $\Omega(n)$ is the number of prime factors of $n$ , not necessarily distinct: $120=2^{3}\cdot 3 \cdot 5$ , therefore $\omega(120)=3$ , $\Omega(120) = 5$ . If we let $W_k(N)$ be the count of numbers not exceeding $N$ with exactly $k$ distinct prime factors { $i | i \leq N , \omega (i) = k$ }, is there any way or formulation to calculate it? Or at least a relatively coincise algorithm for it, which does not include factoring each number and checking for $\omega$ individually? For example, one can easily find that $W_3(100)=8$ , $W_3(1000000)=379720$ , $W_4(1000000)=208034$ . Please note here I am not looking for an asymptotic approximation but rather an exact count. And $N$ can be large, with order of magnitude of $10^{12}$ and over. I have found that a solution exists for the $\Omega$ counterpart, known as k-Almost Primes , which admits closed-form formulas, but as for $\omega$ , I have found non.","['number-theory', 'combinatorics', 'prime-factorization', 'prime-numbers']"
4044827,Show the left shift $T$ and $T^{-1} $ are measurable.,"Let $X=\{0,1 \}^{\mathbb{Z}}$ . So an element of $X$ is given by a sequence $(x_i)_{i\in \mathbb{Z}}$ , where $x_i \in \{0,1 \}$ . Let $\mu_i$ be a probability measure on $(\{0,1 \}, \mathcal{P}(\{0,1 \}))$ , where $\mu_i(\{0\})= \mu_i (\{1 \})= \frac{1}{2}$ . Define $\mu = \Pi_{i\in \mathbb{Z}} \mu_i$ , and $B = \bigotimes_{i\in \mathbb{Z}} \mathcal{P}(\{0,1 \})$ . Let $T: X \rightarrow X$ be the Bernoulli shift defined by $T(x_i)=x_{i-1}$ for $i\in \mathbb{Z}$ . Show $T$ and $T^{-1}$ are measurable and $T$ is measure-preserving. Attempt: Let $A \in B$ . To show that $T$ is measurable, I want to show that $T^{-1}(A)= \{x_{i+1} :  (x_i)_{i\in \mathbb{Z}} \in A \} \in B$ . Define $H= \{A \subset X : T^{-1}(A) \in B \}$ . I showed that $H$ is a $\sigma$ -algebra. So $B \subset H$ . Thus, $T$ is measurable. To show that $T^{-1} $ is measurable, can I do the same thing using $\sigma$ -algebras? I'm not sure about this part. To show that $T$ is measure-preserving, I need to show that $\mu(A)= \mu(T^{-1}(A))$ for all $A\in B$ . I don't have any clues for this part either. Any help will be appreciated. Thank you!","['measure-theory', 'lebesgue-measure', 'product-measure']"
4044831,Saddle-node behaviour of planar systems,"I'm teaching a course on ODEs using Lawrence Perko's book. Having assigned Q3(c) of section 2.11, and both working out the solution using theorems in the sections and consulting the solution manual, I get an answer that seems to conflict with other calculations. The details are as follows: The system is: $$
\dot{x} = y, \qquad \dot{y} = x^4 + xy.
$$ According to a Thm 2.11.3 in Perko (see screenshot of Thms 2.11.2 and 2.11.3 below), taken from Andronov--Leontovich--Gordon--Maier , the critical point $(0,0)$ is a saddle-node, ""because"" the lowest order monomial of the form $x^k$ in the $\dot{y}$ equation is of even degree, the lowest order monomial of the form $x^ny$ has $n = 1$ , with coefficient $b_1 = 1 \not= 0$ , and $4/2 > 1$ . The solution manual concurs. Now from the equation, $\dot{x} > 0$ on $\{y > 0\}$ , $\dot{x} < 0$ on $\{y < 0\}$ . Moreover $\dot{y} = xy + O(|x,y|^4)$ , which means $\dot{y} > 0$ in the 1st and 3rd quadrants, and $\dot{y} < 0$ in the 2nd and 4th quadrants close to $(0,0)$ . And any way I draw this, it looks like a cusp near the critical point. Finally, winplot confirms this: . So my question is, is it known that Thm 2.11.3 is in fact not a theorem, or have I missed something?","['fixed-points', 'ordinary-differential-equations']"
4044857,On $C^1$ convex domain,"Let $D$ be a $C^1$ domain of $\mathbb{R}^d$ . Then we know that there exists a $C^1$ function $\rho:\mathbb R^d\rightarrow \mathbb R$ such that $$
D=\{x\in \mathbb R^d, \rho(x)<0\}, \quad \partial D=\{x\in \mathbb R^d, \rho(x)=0\},
$$ and $
x\in \partial D\Longrightarrow d\rho(x)\not=0.
$ Assume now that $D$ is convex. Can we choose $\rho$ to be convex with the same properties? I know that the first claim follows by the local definition and use of partition of unity, but I can't manage to prove existence of such convex function.","['euclidean-domain', 'convex-analysis', 'differential-geometry']"
4044911,Derivation of Product Rule for Finite Differences without Shift Operator,"Let $h(x)=f(x)g(x)$ , and let the $\Delta$ be the forward difference operator on functions be $$\Delta f := \frac{f_{j+1}-f_j}{\Delta x}$$ where $f_j = f(j\Delta x)$ Now I can derive the product rule for finite differences in terms of $\Delta f$ and $\Delta g$ easily $$\Delta h = \frac{h_{j+1}-h_j}{\Delta x} = \frac{f_{j+1}g_{j+1}-f_jg_j}{\Delta x} = \frac{f_{j+1}g_{j+1}\color{red}{-f_jg_{j+1} }{\color{blue}{+f_jg_{j+1}}}-f_jg_j}{\Delta x}=g_{j+1}\Delta f+f_j\Delta g$$ However, you can see in the first term that $g$ is shifted forward by $1$ step. But on Wikipedia for the finite differences the rule is express with a second order term: $$\Delta(fg) = f\Delta g + g \Delta f + \Delta f \Delta g$$ I have tried converting my expression to this with all sorts of algebra, and I even tried using the wiki's formula to go backwards to my equation, but nothing has worked. It's clear there must be some clever trick to convert the shift operator in terms of $f,\Delta f,\Delta g$ but I can't see how. Any ideas?","['calculus', 'derivatives', 'finite-differences', 'discrete-calculus']"
4044921,Optimal strategy for selling turnips,"You have a pile of $N$ turnips that you need to get rid of in $n$ days. The turnip price every day is independently and uniformly distributed in $[0, 1]$ . You can sell any amount of turnips every day, but you must sell everything by the last day. What strategy should you employ to maximize your profits? ( Context. This is related to the ""stalk market"" in Animal Crossing: New Horizons ; see edit history.)","['expected-value', 'optimization', 'probability']"
4044928,Understand if my proof is fallacious.,"I would like to know if my attempted solution to problem 4 of chapter 3.5 from Velleman's book How to Prove It is valid. My solution is different from the one suggested by the book and I want to know if my reasoning is fallacious to avoid repeating it in the future, if that is the case. The problem is as follows: Suppose $A\cap C \subseteq B \cap C$ and $A \cup C \subseteq B \cup C$ . Prove that $A\subseteq B$ . This is my proof attempt: Suppose $A\cap C \subseteq B \cap C$ and $A \cup C \subseteq B \cup C$ . Let $x$ be arbitrary and suppose $x \in A$ . Since $x \in A$ it follows that $x \in A \cup C$ . But we know that $ A \cup C \subseteq B \cup C$ , so $x \in B$ or $x \in C$ . We will consider these cases separately. Case $x \in B$ : then no further reasoning is needed. Case $x \in C$ : then $x \in A \cap C$ , so since $A\cap C \subseteq B \cap C$ it follows that $x \in B$ Thus $x \in B$ . Since $x$ was an arbitrary member of $A$ we can conclude that $A \subseteq B$ . $\blacksquare$ And this is the book's solution: Suppose $x \in A$ . We now consider two cases: Case $x\in C$ . Then $x \in A \cap C$ , so since $A\cap B \subseteq B \cap C$ , $x \in B \cap C$ and therefore $x \in B$ . Case $x \notin C$ . Since $x \in A$ , $x \in A \cup C$ , so since $A\cap B \subseteq B \cap C$ , $x \in B \cup C$ . But $x \notin C$ , so we must have $x \in B$ . Thus, $x \in B$ , and since $x$ was arbitrary, $A \subseteq B$ . $\blacksquare$ So, the book's proof uses a division into cases that are not suggested by any of the assumptions and that I did not think of. Is there any problem with my proof?","['elementary-set-theory', 'solution-verification', 'alternative-proof']"
4044963,Negation of a sentence written by Oscar Wilde,"If I am asked to negate a sentence such as: We are all in the gutter, but some of us are looking at the stars. would it be ""Either there exists someone who is not in the gutter or all of us are not looking at the stars?"" I broke it down into $(A$ and $B)$ and then $\sim(A$ and $B)\cong  A $ or $\sim B$ by De Morgan's law. Is this the right way?","['logic', 'discrete-mathematics']"
4044992,Differential geometry : crofton formula,"So I was reading an article, and it says that if a parametric curve $s(t)$ defined on I has values in a sphere $S^{2}$ , the length of $s$ , can be deduced by its intersection with great circles using the following formula: $$\operatorname{length}(s)=\frac{1}{4}\int_{S^{2}}\operatorname{card}\{t \in I/s(t).N=0\}\,\mathrm{d}N$$ Can someone give me an example where he applies the formula on a parametic curve so that I understand how it works and how to apply it.","['calculus', 'analysis', 'differential-geometry']"
4045049,Five points on a constant-width curve,"Is there a curve of constant width $1$ on which it is impossible to arrange the five points $A, B, C, D, E$ so that $\max(AB, BC, CD, DE, EA) \leqslant \sin (\frac{\pi}{5})$ ? For example, on a circle, you can place the points in the form of a regular pentagon, and the distance will be exactly $\sin (\frac{\pi}{5})$ . Does anyone have any idea how to place such points on an arbitrary curve of width $1$ ? And more general hypothesis: for any $n$ on any curve of constant width $1$ , we can place $n$ points $A_1, A_2, ..., A_n, A_{n+1}=A_1$ , such that $\max_{i=1..n} (A_{i}A_{i+1}) \leqslant \sin (\frac{\pi}{n})$ . Upd: this is true for $n \leqslant 4$ . $n=1$ and $n=2$ is trivial cases. For $n = 3$ , we can put the curve in a universal Pal's cover and then divide it into three parts of diameter $\sin(\frac{\pi}{3})$ . For $n=4$ , we can put the curve in a square with side $1$ , and divide it into four small squares of diameter $\sin(\frac{\pi}{4})$ .","['euclidean-geometry', 'plane-curves', 'geometry', 'combinatorial-geometry', 'plane-geometry']"
4045102,"If $z_1,z_2,z_3,z_4$ are consecutive vertices of a quadrilateral that lie on a circle prove the following","If $z_1,z_2,z_3,z_4$ are consecutive vertices of a quadrilateral that lie on a circle prove the following: $|z_1-z_3||z_2-z_4|=|z_1-z_2||z_3-z_4|+|z_1-z_4||z_2-z_3|$ . I know that you can prove this without using the cross-ratio, but I would like to complete this proof using it. Here are some things I know: The cross-ratio is real if and only if $(z_1,z_2,z_3,z_4)$ lie on the same circle. The cross-ratio is invariant under linear transformations, i.e. $(z_1,z_2,z_3,z_4)=(Tz_1,Tz_2,Tz_3,Tz_4)$ . I am not sure if (2) will be of any use, but I definitely think (1) would be helpful. Using (1) I can only get as far as: $|z_1-z_3||z_2-z_4|=C|z_1-z_4||z_2-z_3|$ , where $C \geq 0$ . Any help is appreciated. Edit: After playing with the equation for a while this is what I concluded: Of course by simple verification, one indeed finds that $(z_1-z_3)(z_2-z_4)=(z_1-z_2)(z_3-z_4)+(z_1-z_4)(z_2-z_3)$ . Then we have $$\frac{(z_1-z_3)(z_2-z_4)}{(z_1-z_4)(z_2-z_3)}=\frac{(z_1-z_2)(z_3-z_4)}{(z_1-z_4)(z_2-z_3)}+1.$$ Now our result is proven if we can show that both of these quotients are real and positive. Well, the real part follows from the fact that a cross-ratio is real if and only if all four points lie on the same circle. Now for the positive part: The quotient on the left is the cross ratio $(z_1,z_2,z_3,z_4)$ where $z_2 \rightarrow 1$ , $z_3 \rightarrow 0$ , $z_4 \rightarrow \infty$ . Now this transformation, which is bijective, takes the circle that passes through these points to the real line. Therefore the arc from $z_4$ to $z_2$ is taken to $[-\infty,1]$ , hence $(z_1,z_2,z_3,z_4) > 1$ . A similar argument works to show that the other cross-ratio is also positive. Is this reasoning correct? I guess we use the fact that continuous functions take connected sets to connected sets, so the image of these arcs must be connected.",['complex-analysis']
4045119,Regularized Incomplete Beta Function,"I try to solve this property of Regularized Incomplete Beta Function. How can you solve a statement : $I_x (a,a) = 1 - \frac{1}{2} I_{4x(1-x)}(a,\frac{1}{2})  $ where $1/2 \leq x \leq 1$ . Some definitions : $I_x (a,b) = \frac{B(x;a,b)}{B(a,b)}$ with B(x;a,b) is incomplete Beta function and B(a,b) is Beta function. I tried to use substitution rule with z = 1 - x. But it doesn't go any further. Could someone give me idea more please ?","['beta-function', 'statistics']"
4045129,Formula for the number of edges of complete $m$-partite graph,"The complete $m$ -partite graph on $n$ vertex in which each part has either $[\frac{n}{m}]$ ( $\frac{n}{m}$ rounded down to an integer) or $\{\frac{n}{m}\}$ ( $\frac{n}{m}$ rounded up to an integer) vertices is denoted by $T_{m,n}$ . Show that \begin{equation}
\epsilon(T_{m,n})=\binom{n-k}{2}+(m-1)\binom{k+1}{2},\mathrm{where} \;k=[n/m].
\end{equation} My efforts: Use induction. Obviously $\epsilon(T_{2,2})=1$ and the formula is correct. First fix $m$ and vary $n$ . Assume the formula holds for $n$ . Consider $\epsilon(T_{m,n+1})$ . One vertex is added to the partition with [ $n/m$ ] vertices. The new vertex can be connected to any vertex in the other partitions. Thus \begin{equation} 
\begin{split}
\epsilon(T_{m,n+1}) & = \epsilon(T_{m,n})+n-[n/m] \\
 & = \binom{n-[n/m]}{2}+(m-1)\binom{[n/m]+1}{2}+n-[n/m]
\end{split}
\end{equation} We need to consider two cases: $[(n+1)/m]=[n/m]$ and $[(n+1)/m]=[n/m]+1$ . (1) $[(n+1)/m]=[n/m]$ . \begin{equation}
\begin{split}
\epsilon(T_{m,n+1}) & = \binom{n-[\frac{n+1}{m}]}{2}+(m-1)\binom{[\frac{n+1}{m}]+1}{2}+\binom{n-[\frac{n+1}{m}]}{1} \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+(m-1)\binom{[\frac{n+1}{m}]+1}{2}
\end{split}
\end{equation} The formula is correct. (2) $[(n+1)/m]=[n/m]+1$ . This happens only if $(n+1)/m$ is an integer. \begin{equation} 
\begin{split}
\epsilon(T_{m,n+1}) & = \binom{n+1-[\frac{n+1}{m}]}{2}+\frac{1}{2}(m-1)([\frac{n}{m}]+1)[\frac{n}{m}]+n-[\frac{n}{m}] \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+\frac{1}{2}(m-1)([\frac{n+1}{m}])[\frac{n}{m}]+n-[\frac{n}{m}] \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+\frac{m-1}{2}([\frac{n+1}{m}])[\frac{n}{m}]+m[\frac{n+1}{m}]-[\frac{n+1}{m}] \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+\frac{m-1}{2}([\frac{n+1}{m}])[\frac{n}{m}]+(m-1)[\frac{n+1}{m}] \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+\frac{m-1}{2}[\frac{n+1}{m}]([\frac{n}{m}]+2) \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+\frac{m-1}{2}[\frac{n+1}{m}]([\frac{n+1}{m}]+1) \\
 & = \binom{n+1-[\frac{n+1}{m}]}{2}+\binom{[\frac{n+1}{m}]+1}{2}
\end{split}
\end{equation} The formula is again correct. Then I don't know how to do induction of fixing $n$ and varying $m$ . Is there any elegant counting method without using induction?","['graph-theory', 'combinatorics']"
4045138,Is it possible to solve this quadratic equation without calculating discriminant?,"I have the quadratic equation $\;\;5x^2+96x-576=0\;\;$ . I wonder can we solve it without using formula $x=\frac{-b\pm\sqrt{\Delta}}{2a}$ ? I suspect there is some way to do it because we have a lot of $24$ s , ( $96=24\times4$ and $576=24^2)$ but I can't find it.","['algebra-precalculus', 'quadratics']"
4045183,How to find the maximum distance between two paths over a time interval (diff eqn) AP Calc Question,"Alice and Bob go for a jog in the same direction along a straight path. For $0\leq t \leq20$ , Alice’s velocity at time t is given by $A(t)=\frac{6010}{t^2-3t+50.5}$ meters per minute, and Bob’s velocity at time t is given by $B(t)=8.5t^3e^{-0.45t}$ meters per minute. Both of these velocities are always positive. Alice is 12 meters ahead of Bob at time $t=0$ , and she remains ahead of Bob for $0\leq t\leq 20$ . What is the maximum distance between Alice and Bob over the time interval $0\leq t \leq 20$ ? The answer is $d=1413.23$ when $t=4.58$ . I'm confused on how to get this answer... I did $\int_0^{20} \frac{6010}{t^2-3t+50.5} - \int_0^{20} 8.5t^3e^{-0.45t}$ $\int_0^{20}\frac{6010}{t^2-3t+50.5} =1232.323$ $\int_0^{20} 8.5t^3e^{-0.45t}=1217.313$ and got $1232.323-1217.313=15.01=d$ I thought that the distance between Alice and Bob is $\int A(t)-\int(B(t)$ so I'm confused where I went wrong. How can I solve this?",['derivatives']
4045188,Smallest number of $45^\circ-60^\circ-75^\circ$ triangles that tile a rectangle,"In this wonderful question we learned that a square can be divided into forty six $45^\circ-60^\circ-75^\circ$ triangles. Now I am wondering what is the smallest number of $45^\circ-60^\circ-75^\circ$ triangles that can tile some rectangle ? In other words, from all tilings of rectangles with such triangles, I am looking for the one with the smallest number of triangles.","['recreational-mathematics', 'geometry', 'tiling']"
4045194,Proving that $SU(n)$ is a smooth manifold,"Considering this post: Show that $SL(n, \mathbb{R})$ is a $(n^2 -1)$ smooth submanifold of $M(n,\mathbb{R})$ I dont understand how the manipulations in the limit are done, for instance: $$ \det(A+tA)=(1+t)^n \det(A)$$ and how the limit overall evaluates to: $n \det(A)$","['determinant', 'smooth-manifolds', 'manifolds', 'lie-groups', 'differential-geometry']"
4045217,Converts into $\frac{\partial^2 W}{\partial u^2}+\frac{\partial^2 W}{\partial v^2}=0$,"Show that the substitution $u=x^2-y^2$ , $v=2xy$ converts the equation $\frac{\partial^2 W}{\partial x^2}+\frac{\partial^2 W}{\partial y^2}=0$ into $\frac{\partial^2 W}{\partial u^2}+\frac{\partial^2 W}{\partial v^2}=0$ I have $$\left\lbrace u=x^2-y^2 \atop v=2xy \right. $$ So $$\frac{\partial W}{\partial x} = \frac{\partial W}{\partial u}\frac{\partial u}{\partial x}+\frac{\partial W}{\partial v}\frac{\partial v}{\partial y} $$ and $$\frac{\partial W}{\partial y} = \frac{\partial W}{\partial u}\frac{\partial u}{\partial y}+\frac{\partial W}{\partial v}\frac{\partial v}{\partial y} $$ I can compute for example $\frac{\partial u}{\partial x}=2x$ , $\frac{\partial u}{\partial y}=-2y $ , $\frac{\partial v}{\partial x}=2y$ and $\frac{\partial v}{\partial y}=2x$ but how to find $\frac{\partial W}{\partial u}$ or $\frac{\partial W}{\partial v}$ ?",['multivariable-calculus']
4045234,How do you find $E(X^3)$ of a Poisson Distribution? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I know the proof to find the variance of a Poisson Distribution, and I tried to use that to find $E(X^3)$ , but I can't get it to work. Any help would be great!!","['statistics', 'poisson-distribution', 'probability', 'probability-distributions', 'poisson-summation-formula']"
4045236,Solving a pair of dual integral equations,"I have the equations $$
\int\limits_0^\infty dk \ A(k)k \sinh(ka)\cos(kx)=0 \ \ ; \ \ 1<|x|<\infty  \tag{1}
$$ $$
\int\limits_0^\infty dk \  A(k) \cosh(ka) \cos(kx)=1  \ \ ; \ \ |x|<1 \tag{2}
$$ Where $A(k)$ is unknown, $a$ is a real positive constant, and we expect $A=A(k,a)$ . I think the general idea is to write $$
\left[ A(k) \times \operatorname{convenient stuff}(k)\right]=\int\limits_0^1dx' \ g(x') \cos(kx') \tag{*}
$$ Where $g$ is the new unknown, and (*) is chosen such that (1) is satisfied, then substitute this into (2) so that the integral over $k$ may be performed. Question in brief: What substitution in (*) will allow me to make progress? Or is there a different 'trick' here altogether? Maybe an expansion on the right in something other than cosines? The rest of this post is background, and my current attempt. In a similar problem $$
\int\limits_0^\infty dk \ A(k) k \sin(kx) =0 \ \ ; \ \ 1<|x|<\infty \tag{3}
$$ $$
\int\limits_0^\infty dk \ A(k) \tanh(ka)\sin(kx)=1 \ \ ; \ \ |x|<1 \tag{4}
$$ Setting $$
A(k) k = \int\limits_0^1 dx' \ g(x') \sin(kx')
$$ Allows one to make progress by substituting into (4), and even (eventually) obtain $g$ analytically. I have tried the similar substitution $$
A(k) k \sinh(ak)=\int\limits_0^1 dx' g(x') \cos(kx')
$$ So that (1) is satisfied, but substituting this into (2) is not fruitful (divergent integral over $k$ ). It is possible that the Fourier expansion in $\cos$ on the RHS of (*) is not the way to go here. Maybe expanding in Bessel functions or something else; but I don't have the intuition to 'see' what is a good expansion. For example, in a (different) similar problem, a useful expansion is $$
\left[ A(k) \times \operatorname{convenient stuff}(k)\right]=\int\limits_0^1dx' \ g(x') J_0(kx')
$$ Where $J_0$ is a Bessel function of the first kind. The similar problems mentioned above are from: Mixed boundary value problems by Dean G. Duffy. Current progress By integrating (1) and (2) w.r.t. $x$ we obtain $$
\int\limits_0^\infty dk \ A(k) \sinh(ka)\sin(kx)=0 \ \ ; \ \ 1<|x|<\infty  \tag{1a}
$$ $$
\int\limits_0^\infty dk \  A(k) k^{-1} \cosh(ka) \sin(kx)=x  \ \ ; \ \ |x|<1 \tag{2a}
$$ With the ansatz $$
A(k) \cosh(ka) = \int\limits_0^1 dx' \ g(x') \sin(kx') \tag{**}
$$ After substituting (**) into (2a), and some algebra, we find $$
A(k) \cosh(ka) = J_1(k)
$$ However, to justify this we must show it satisfies (1a) $$
\int\limits_0^\infty dk \ \int\limits_0^1 dx' \ g(x') \sin(kx') \sin(kx) \tanh(ka) \stackrel{?}{=}0 \ \ ; \ \ 1<|x|<\infty  \tag{1b}
$$ Within the integral, we always have $x \neq x'$ , so it would be nice to say (distributionally) this is true, but I'm not sure that it is. Alternative question: is (1b) true? Update: Numerically integrating (1b) shows that it's not true.","['integration', 'integral-equations', 'special-functions', 'mathematical-physics', 'bessel-functions']"
4045330,Proof feedback: integral of a function with f(x)=0 is 0,"I'm attempting to prove the following statement, and having some difficulty: Let $f:[a,b] \rightarrow \mathbb{R}$ be continuous, $f(x)\ge 0$ for all $x$ and $\alpha(x)=x$ . Prove: If $\int_a^b f \, d\alpha=0$ then $f(x)=0$ for all $x\in[a,b]$ . My attempt, seeking to find a contradiction, goes as follows: Assume $\int_a^b f \,d\alpha=0$ and $f(c)=q>0$ for some $c \in [a,b].$ $Lemma \ 1:$ Let $f$ be continuous at $c$ and suppose $f(c)\neq 0$ . Then there exists $\delta>0$ and an interval $(c-\delta,c+\delta)$ in which $f$ has the same sign as $f(c)$ . Since $f(c)=q>0$ and $f$ is continuous on $[a,b]$ , we invoke $Lemma \ 1$ and get that there exists $x$ such that $f(x)>\frac{f(c)}{2}=\frac{q}{2}$ when $x\in (c-\delta,c+\delta)$ . Now, note that for any partition $P$ , we have $U(P,f,\alpha)>\delta\frac{q}{2}>0$ , since we would always at least have $f(x)$ in some arbitrarily small $\delta$ -interval. We then get that $$
    0<\frac{q}{2} \delta \leq \overline{\int_a^b} f \, d\alpha = \int_a^b f \, d\alpha=0
$$ which is a contradiction. So $f(x)=0$ $\forall x\in[a,b]$ . In general, I feel ok about this proof, but there are certainly some gaps that I can't seem to entirely justify. Any help is appreciated! Thanks.","['integration', 'analysis']"
4045353,"Why does ${x}^{x^{x^{x^{\,.^{\,.^{\,.}}}}}}$ bifurcate below $\sim0.065$?","When you calculate what ${x}^{x^{x^{x\cdots }}}$ converges to between $0$ and $1$ , before approximately $0.065$ the graph bifurcates. Why does this happen and is there a reason for it happens at that number?","['limits', 'tetration', 'bifurcation']"
4045361,"Prove that there exist four polynomials $p_1,p_2,p_3,p_4$ in $x,y,z$ so that $(x^2+y^2+z^2)^3-8(z^3x^3+x^3y^3+y^3z^3)=p_1^2+p_2^2+p_3^2+p_4^2$","Prove that there exist four polynomials $p_{1}, p_{2}, p_{3}, p_{4}$ in $x, y, z$ so that $$\left ( x^{2}+ y^{2}+ z^{2} \right )^{3}- 8\left ( z^{3}x^{3}+ x^{3}y^{3}+ y^{3}z^{3} \right )= p_{1}^{2}+ p_{2}^{2}+ p_{3}^{2}+ p_{4}^{2}$$ Source: AoPS/@Ji_Chen_ on.AoPS I like Ji Chen's sum of squares, which is very hard to make decomposition like they said. Here is the way of thinking of mine about this problem_ if $f= ab+ c= -ad+ e$ with $b, c, d, e\geq 0\Rightarrow f\geq 0,$ we have a new $f$ is an SOS $,\quad f:=\dfrac{cd+ e}{b+ d}$ I think finding SOS like this is very funny. One day, you try substitutions and you succeed, however, another day, that trick is not useful anymore. I found this formula_ on.StackMath 4 years ago. Very amazing result, I have thought of it till now, that's a travelled task.","['real-analysis', 'superalgebra', 'polynomials', 'sum-of-squares-method', 'substitution']"
4045398,Show that the quotient norms fail to be a norm in the quotient space $\ell^{\infty}/c_{00}$.,"Let $(V, \|\ \cdot\ \|)$ be a normed space over $\mathbb{R}$ or $\mathbb{C}$ and let $W\subset V$ be a linear subspace. We define the following equivalence relation on $W$ : $$x\sim y\iff x-y\in W.$$ Then, we can define the quotient space $$V/W=V/\sim=\{[x]:x\in V\},\ \ \text{where}\ \ [x]\ \ \text{is the equivalence class}.$$ And we define the quotient ""norm"" to be $$\|[x]\|_{V/W}=\inf_{y\in W}\|x-y\|.$$ It is known that $\|\ \cdot\ \|_{V/W}$ is a semi-norm, and when $W$ is not closed, it may fail to be a norm since it may fail the property that $$\|[x]\|_{V/W}=0\iff [x]=[0].$$ One counterexample has been given here: Concrete counterexample for norms on quotient spaces , but it seems that the definition of the quotient in this post is a little bit different than mine. Therefore, I tried to come up with an example by considering $c_{00}$ as a subspace of $\ell^{\infty}$ (as long as the elements in $c_{00}$ comes from $\ell^{\infty}$ , the subspace property is clear). Firstly note that $c_{00}$ is not closed in $\ell^{\infty}$ . Indeed, for each $n\in\mathbb{N}$ , set $$x_{n}:=\Bigg(1, \dfrac{1}{2},\dfrac{1}{3},\cdots,\dfrac{1}{n},0,0,\cdots\Bigg)\ \ \text{and}\ \ x=\Bigg(1, \dfrac{1}{2}, \dfrac{1}{3},\cdots\Bigg).$$ Then $(x_{n})_{n=1}^{\infty}\subset c_{00}$ and $\|x-x_{n}\|_{\infty}=\frac{1}{n+1}\longrightarrow 0$ , and thus $x_{n}\longrightarrow x$ in $\ell^{\infty}$ , but $x\notin c_{00}$ . However, I cannot come up with a sequence $x\in c_{00}$ (so that $[x]=0$ ) but $\|[x]\|_{\ell^{\infty}/c_{00}}\neq 0.$ Any idea? Thank you!","['normed-spaces', 'analysis', 'real-analysis', 'functional-analysis', 'quotient-spaces']"
4045431,Sum of elements of $A \cap(B \cup C)=400 \times 274$. Find the closed form of $C$.,"Question: $A=\{x: x=3$ digit natural number $\}$ $B=\{x: x=9 k+2 ; k \in N\}$ ${C}=\{{x}: {x}=9 {k}+I ; {k} \in {Z}\}, $ $0 \leq {I}<9$ Sum of elements of $A \cap(B \cup C)=400 \times 274 .$ Find the value of $I$ To be honest, I don't know how to start without making an assumption. $$A \cap(B \cup C)=(A \cap B)\cup (A \cap C)$$ Assuming that $(A \cap B)$ and $(A \cap C)$ doesn't have any element common, one can find the sum of elements of $(A \cap B)$ and $(A \cap C)$ which would be equal to $400 \times 274 $ . Sum of elements of $(A \cap B)$ : $$\sum_{k=11}^{110}(9k+2)=54450+200=54650$$ Sum of elements of $(A \cap C)$ : Elements of $C$ are $$\cdots\cdots90+I,99+I,108+I\cdots990+I,999+I\cdots\cdots$$ Elements of $A$ are $$100,101,102\cdots 999$$ So possible elements of $(A \cap C)$ [By keeping $0 \leq {I}<9$ in mind] must be: $$99+I,108+I\cdots990+I\tag1\label{eq1}$$ So $$\sum_{k=11}^{110}(9k+I)=54450+100I$$ Then after adding and solving $$I=5$$ And by luck $9k+2$ and $9k+5$ does not have any element common from $k=11$ to $k=110$ . How can this be solved without making that risky assumption? Any alternate. Seeing range in $\eqref{eq1}$ and guessing the elements of $(A \cap C)$ worked well in this question but there is a single value of $I$ so that won't work every time.","['elementary-set-theory', 'sequences-and-series']"
4045450,On the parity of $\left\lfloor{\frac{3^n}{2^n}}\right\rfloor$,"Let $a_n=(-1)^{\left\lfloor{\frac{3^n}{2^n}}\right\rfloor}$ and $$s_n=\sum_{k=1}^na_k.$$ Is it true that $s_n\le 0$ for all $n\geq 1$ ?  (This is true for $n\le 100000$ .) In other words, odd numbers are always more than even numbers on the sequence $\left\lfloor{\frac{3^n}{2^n}}\right\rfloor$ .
This is unexpected, I think they should be roughly equal, and even numbers will exceed odd numbers sometimes.",['number-theory']
4045454,"A dig at Ramanujan's: $\sum_{k=1}^{\infty} (-1)^{k-1} \frac{x^{pk}}{k(k!)^p} \sim p \ln x +p \gamma,~ p>0$","Ramanujan's claim on page 98, in the book (`Ramanujan's note book part 1' by Bruce C. Berndt) is that $$\sum_{k=1}^{\infty} (-1)^{k-1} \frac{x^{pk}}{k(k!)^p} \sim p \ln x +p \gamma,\qquad p>0\tag{1}\label{theclaim}$$ The proposed proofs for $p=1,2$ are reported to be incorrect. For $p>2$ the claim \eqref{theclaim} has been disproved. In the year 1996, my proofs for $p=1,2$ were evaluated to be correct by American Math. Monthly, however,  similar proofs were told to have been published in the year 1995, somewhere. The result (1) being asymptotic $x$ needs to be positive and large. The question here is: What is the latest about this result when $p\in (0,2]$ any information or proof is welcome.","['convergence-divergence', 'ramanujan-summation', 'sequences-and-series']"
4045481,Show that series $\sum_{n=2}^{\infty} \frac{1}{(\log(n))^{\log(\log(n))}}$ is divergent [duplicate],This question already has an answer here : Does $\sum_{n=3}^\infty \frac {1}{(\log n)^{\log(\log(n)}}$ converge? (1 answer) Closed 3 years ago . Show that series $$\sum_{n=2}^{\infty} \frac{1}{(\log(n))^{\log(\log(n))}}$$ is divergent . What inequality can we use here. i tried various method but none of these give any result. Any hint please .,"['convergence-divergence', 'sequences-and-series', 'analysis', 'real-analysis']"
