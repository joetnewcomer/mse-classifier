question_id,title,body,tags
1288858,Does a space with peoperty A have a topological name?,"As we know, If $X$ is a Tychonoff pseudocompact space, then for every decreasing sequence $\cdots\subset W_2\subset W_1$ of nonempty open subsets of $X$ the intersection $\bigcap_{i=1}^{\infty} \overline{W_i}$ is nonempty. In this result, the sequence $\{W_i\}$ is countable. If we change the cardinality of the sequence 
to be $\omega_1$, i.e., Property A: For every decreasing sequence $\cdots\subset W_\alpha\subset \cdots\subset W_2\subset W_1$ of nonempty open subsets of $X$ the intersection $\bigcap_{\alpha=1}^{\omega_1} \overline{W_i}$ is nonempty. Does a space with peoperty A have a topological name? Thanks for your help.","['reference-request', 'general-topology']"
1288890,Possible textbook redundancy concerning invertible mappings,"In my textbook (Modern Algebra by John Durbin, 6th Ed), there is the following theorem: Let $S$ denote any nonempty set. (a) Composition is an associative operation on $M(S)$, with identity element $\iota_S$. (b) Composition is an associative operation on the set of all invertible mappings in $M(S)$, with identity $\iota_S$. Here, $M(S)$ denotes the set of all mappings from $S$ to $S$. My question is simple: doesn't part (a) guarantee part (b)? After all, the set of all invertible mappings in $M(S)$ is simply a subset of all of the mappings in $M(S)$. Nonetheless, the author gives proofs for both parts of this theorem and doesn't address my point above. Where am I going wrong? Could someone confirm my reasoning or show my error by providing a counterexample perhaps?","['abstract-algebra', 'examples-counterexamples', 'functions']"
1288904,Show that matrices are not similar,"I have to show that the following matrices are not similar: $$A = \left[\begin{matrix} 1 & 3 & -3 \\ -3 & 7 & -3 \\ -6 & 6 & -2\end{matrix}\right]$$ and $$A' = \left[\begin{matrix} 5 & 0 & 0 \\ 0 & 4 & 0 \\ 0 & 0 & 3\end{matrix}\right]$$ I know that 2 matrices $A$ and $A'$ are similar if there exists an invertible matrix $B$, such that $$A'= B^{-1}AB$$ According to Wikipedia , similar matrices share some properties (for example they have the same eigen values), but I don't know how to start, since I have missed the last lectures of my linear algebra course, unfortunetely. Unfortuntely, life has not been so completely fair with me :( Should I just check if they have the same eigen values?","['linear-algebra', 'matrices']"
1288912,"Let $f: (X, d) \to (Y, d')$. Prove that the following are equivalent:","Let $f: (X, d) \to (Y, d')$ . Prove that the following are equivalent: a) $f$ is uniformly continuous in $X$ . b)For every pair of sequences $(x_n), (y_n) \subseteq X$ such that $ d(x_n, y_n) \to 0$ then $d'(f(x_n), f(y_n))\to .0$ c) For all $\varepsilon >0$ , there exists $\delta>0$ such that for all $E \subset X$ with $\mbox{diam}(E)<\delta$ then $\mbox{diam}(f(E))<\varepsilon$ I was able to prove that a) implies b) and that c) implies a), however when trying to proove that b)implies c) I am having difficulties. I've done the following; EDIT: Complete proof with some help. Now if b) stands lets suppose that c) does not. Then $\exists \epsilon>0$ such that for all $\delta>0$ there exists $E\subset X$ such that $\mbox{diam}(E)<\delta$ and $\mbox{diam}(f(E))\geq \epsilon$ . Take $\delta = \frac{1}{n}$ then for each $n \in \mathbb{N}$ there exists $E_n \subset X$ such that $\mbox{diam}(E_n)<\frac{1}{n}$ and $\mbox{diam}(f(E_n))\geq \epsilon$ . That is, for each $n\in \mathbb{N}$ , there exist $x_n,y_n \in E_n$ such that $d'(f(x_n),f(y_n)) \geq \frac{\epsilon}{2}$ . Making $n\to \infty$ we have that $d(x_n,y_n)\to 0$ and $d'(f(x_n),f(y_n)) \geq \frac{\epsilon}{2}$ which contradicts the hypothesis b).","['metric-spaces', 'uniform-continuity', 'real-analysis', 'general-topology']"
1288934,Computing line integral using Stokes´theorem,"Use Stokes´ theorem to show that $$\int_C ydx+zdy+xdz=\pi a^2\sqrt{3}$$ where $C$ is the curve of intersection of the sphere $x^2+y^2+z^2=a^2$ and the plane $x+y+z=0$ My attempt: By Stokes´ theorem I know that $$\int_S (\nabla \times F) \cdot n \ dS=\int_c F \cdot  d\alpha$$  In this case the intersection curve $C$ is a circle and $S$ is ""half"" of the sphere using $r(u,v)=(acos(u)sin(v), a sin(u)cos(u), acos(v))$ $0\le v \le \pi$, $-\pi/4 \le u \le 3\pi/4$ as a parametrization of the sphere and computing $\nabla \times F=(-1,-1,-1)$ (where $F=(y,z,x)$), and $${\partial r\over \partial u}\times {\partial r\over \partial v}$$ the surface integral becomes: $$\int_{-\pi/4}^{3\pi/4}\int_{0}^{\pi}({a^2sin(v)sin(2u)\over 2}-a^2sin(v)sin^2(u)+{a^2sin(2v)\over 2})dv\ du$$, but after computing the integral I don´t get the answer, Can you please tell me where is my mistake?","['surface-integrals', 'solution-verification', 'vector-analysis', 'multivariable-calculus']"
1288946,Solve second-order linear ODE,"everyone,
I've a ODE to find a solution for it. The ODE is: $y''+2y'+10y=x^2e^{-x}cos(3x)$ I'm trying to solve it and find $y_h(x)=c_1e^{-x}sin(3x)+c_2e^{-x}cos(3x)+y_p$.
The problem is to find $y_p$, the particular solution. I tryed to fint it, but a found a MONSTROUS algebric expression. Everyone have a tip to solve it more quickly? Thanks!","['calculus', 'ordinary-differential-equations', 'algebra-precalculus']"
1288952,Is the closure of $\mathbb Q \times \mathbb Q$ equal to $\mathbb R \times \mathbb R$?,"I know the closure of $\mathbb Q$ is $\mathbb R$, but does this imply that the closure of $\mathbb Q \times \mathbb Q$ equal to $\mathbb R \times \mathbb R$?","['elementary-set-theory', 'general-topology']"
1289019,Are $\mathbb{CP}^{n}$ and $\mathbb{RP}^{2n}$ diffeomorphic?,"I understand that they are homeomorphic but couldn't find a proof that they are diffeomorphic. If they are diffeomorphic and if the proof is simple enough, I would imagine it would look like the following: $$\mathbb{CP}^{n}=(\mathbb{C}^{n+1}/\{0\})/{\sim}_{\mathbb{C}}\simeq(\mathbb{R}^{2(n+1)}/\{0\})/{\sim}_{\mathbb{R}^2}\simeq(\mathbb{R}^{2n}/\{0\})/{\sim}_{\mathbb{R}}=\mathbb{RP}^{2n} $$ where the equalities hold by definition, equivalence is diffeomorphism, and $\sim_k$ denotes the equivalence class under the multiplication by nonzero $m\in k$. The first equivalence is by the fact that $\mathbb{R}^2\simeq\mathbb{C}$, but I don't know how to prove the second equivalence. Could anybody help me?","['differential-geometry', 'smooth-manifolds']"
1289027,An injective morphism between varieties that is not an immersion,"I believe this is relatively elementary, but I'm struggling to think of an example of a morphism $f: X \rightarrow Y$ between varieties which isn't an immersion in the sense of algebraic geometry. I'd prefer to see something ""geometric"", say of varieties over $\mathbb{C}$, to rule out ""algebraic"" counterexamples involving weird characteristic $p$ things (I believe the Frobenius map over a non-perfect field could possibly be an example?) or possibly different base fields. Bonus points if $X$ is projective (or proper, I suppose) so the map is closed and thus a topological embedding. Context: I'm reading - in Qing Liu's Algebraic Geometry and Arithmetic Curves , Chapter 7.4 -  about under what conditions a divisor $D$ on a projective curve $X$ is very ample. The argument proceeds by first showing the map is injective, then showing that the differential is injective. Intuitively, in the analogy with the complex analytic case, this latter step is verifying that the map ""preserves the complex structure"" in a differential-geometric sense.","['complex-geometry', 'algebraic-geometry']"
1289028,Conformal map from disk with smaller disk removed to upper half plane,"I'm working on a problem that was a previous complex qualifying exam at my university. I believe I have a solution, but I'm not entirely confident in it. The problem is as follows: Find a one-to-one conformal map of the region $\Omega=\{z\in\mathbb{C}\,|\,|z|<2\text{ and }|z-1|>1\}$ onto the upper half plane. Here's my attempt: The region $\Omega$ can be mapped to the vertical strip $\{z\in\mathbb{C}\,|\, -1/2<\text{Re }(z)<-1/4\}$ by the map $z\mapsto\frac{1}{z-2}$. Then $z\mapsto\left(\frac{4\pi}{z-2}+2\pi\right)i$  maps $\Omega$ to the horizontal strip $\{z\in\mathbb{C}\,|\,0<\text{Im }(z)<\pi\}$. Lastly
$$
z\mapsto \exp\left(\frac{4\pi}{z-2}i+2\pi i\right)
$$
or
$$
z\mapsto\exp\left(\frac{4\pi}{z-2}i\right)
$$
should map to the upper half plane. Is this correct? Is there any easier way to see this? Any input would be greatly appreciated, thanks in advance.","['complex-analysis', 'conformal-geometry']"
1289046,What does the ideal norm of matrix elements really mean?,"Say we have a number field $K$ (specifically, an imaginary quadratic field) and a $2\times2$ matrix $\sigma=\pmatrix{a&c\\b&d}$ with elements $a,b,c,d\in\mathcal O_k$, the ring of integers of $K$. Generally, what is the significance of the norm of the ideal in $\mathcal O_k$ generated by the matrix elements, written $N(a,b,c,d)$, to the matrix $\sigma$? For example, does the norm give us information about the eigenvalues of $\sigma$? If we write the norm as $N(\sigma)$, is the norm of a product $N(\sigma\tau)$ related to $N(\sigma)$ and $N(\tau)$ in a useful way, maybe involving determinants as well? Is $N$ or its square root a bona fide matrix norm ? I ask because in Vulakh (1994) ""Reflections in extended Bianchi groups"" , the extended Bianchi group is  represented by matrices for which $\det(\sigma)=\epsilon N(\sigma)$ where $\epsilon$ is a unit in $\mathcal O_k$. I don't really follow how one is led to write down that equation.","['normed-spaces', 'ideals', 'algebraic-number-theory', 'matrices']"
1289057,Finding a Radom-Nikodym derivative,"Let $(X,\Sigma,\mu)$ be a measure space. Let $f_1,f_2\in L^1(\mu)$ and consider the signed measures $$v_i(E):=\int_Ef_id\mu$$ for every $E\in\Sigma$. If $v_1\ll v_2$ and $v_2\ll v_1$, we must find $\dfrac{dv_1}{dv_2}$. First, I don't understand something. As states in Real Analysis (Folland), the Radon-Nikodym derivative exists when the signed measure in ""denominator"" is actually a measure. And of course $v_2$ need not be a measure. Is this ok? Anyways. Let $g:=\dfrac{dv_1}{dv_2}$, so $g$ is the unique $v_2$-a.e. function such that $v_1(E)=\displaystyle\int_Egdv_2$ (again, I don't know if this integral makes sense if $v_2$ is not a measure) for every $E\in \Sigma$. Then $$\int_Ef_1d\mu=\displaystyle\int_Egdv_2$$ for every $E\in\Sigma$. Can anyone give my a hint in order to find $g$? It seems I'm very lost. Thank you.","['real-analysis', 'measure-theory']"
1289063,$ \lim_{x\rightarrow 0^{+}}\frac{\sin ^{2}x\tan x-x^{3}}{x^{7}}=\frac{1}{15} $,"Can someone show me how is possible to prove that
\begin{equation*}
\lim_{x\rightarrow 0^{+}}\frac{\sin ^{2}x\tan x-x^{3}}{x^{7}}=\frac{1}{15}
\end{equation*}
but without Taylor series. One can use L'Hospital rule if necessary. I was not able.",['limits']
1289073,Why is the black-scholes model arbitrage free when $\sigma >0$?,"I want to show that: if $σ$ is positive then there is no arbitrage in the model, even if $r > µ$. Whilst I have satisfied this for $ r > \mu$, I cannot see why the conditioning on $\sigma>0 $ is necessary. Given:
$S_0 = 1$, $B_t$ = Brownian motion and $S_t$ = stock price
And our Black-scholes model:
$$dS_t = \mu S_t dt + \sigma S_t dB_t$$ Then this model is arbitrage free if there is some Equivalent Martingale Measure $\mathbb{Q}$ such that $S_t e^{-rt}$ is a martingale. So why do we require that $\sigma > 0$ for this to be arbitrage free? The solution to BSM:
$$S_T = S_0 e^{(r - \frac{1}{2}\sigma^2)T + B_T}$$ Now to discount it, let $X_t = S_T e^{-rT}$ So $$X_t = e^{(\mu - \frac{\sigma^2}{2} - r)T + \sigma(B_t)}$$
So we need to show $X_t$ is EMM under $\mathbb{Q}$ $$dX_t = \sigma S_t e^{-rt}( \frac{\mu - r}{\sigma}dt + dB_t)$$ then by Girsanov's theorem with $c = \frac{\mu - r}{\sigma}$, There's $\mathbb{Q}$ such that $ct + B_t = \hat B_t$ is a Brownian motion (is this called brownian motion with drift?) Gives: $$X_t = X_0 e^{\sigma \hat B_t - \frac{1}{2}\sigma^2t}$$ And this is an exponential martingale. BUT, why does this rely on $$\sigma >0$$","['probability-theory', 'brownian-motion', 'martingales']"
1289074,Interpreting d as an operator in differential calculus.,"I am enjoying this mathematics book for the general public called Measurement by Paul Lockhart.  For the most part, I am happy with his metaphors and intuitive explanations of the different concepts, but I occasionally come along something that I wish was discussed more rigorously. There are also times when I can't tell whether something is part of general mathematical practice or is just his own idiosyncratic invention. In particular, I want your help in interpreting what Lockhart calls the ""Leibniz d operator"". I had better quote an example passage from the book to show you how he treats this concept: How can we take the information 
  $$a^{2}=b^{2}+3$$
  $$c=2a+b$$
  and determine the ratios $da:db:dc$ ? The direct approach would be to give the mixing board a kick, check out the variation of the sliders, and figure out where their proportions are heading as the kick gets smaller. But here's the point: we don't actually need to go through this laborious process. Instead, we can simply apply the d- operator to both sides of the equations:
  $$d(a^{2})=d(b^2+3)$$
  $$dc=d(2a+b)$$
  After all, if two variables are always equal their rates must also be equal. Expanding these accordingly, we obtain the differential equations
  $$2a\:da=2b\:db$$
  $$dc=2da+db$$
  So for instance, at the moment when a = 2, b = 1, and c = 5 (which does in fact satisfy our original equations and so qualifies as an actual moment), we have
  $$4\:da=2\:db$$
  $$dc=2\:da+db$$
  Thus at that precise instant, b is moving twice as fast as a , and c is moving four times as fast. In other words, the ratio $da:db:dc$ is $1:2:4$. We now have a simple and direct method for solving any problem concerning relative rates of change$-$just $d$ everything! ""Kicking the mixing board"" is his metaphor for using the difference quotient. I recognize and understand this concept of the derivative from my first exposure to calculus. I am familiar with the $\frac{dy}{dx}$ notation, but this is not with respect to any variable; it is just this $d$-ing something arbitrarily that is unfamiliar to me. I suppose my question is a reference request related to this idea of $d$-ing both sides of an equation. I think I understand what he is doing, but I want to read a more rigorous discussion of how $d$ can act like some sort of function or operator. Sorry if this is a dumb question, but where can I find more information about this interpretation of taking a derivative?","['reference-request', 'calculus', 'ordinary-differential-equations']"
1289075,Expected value of geometric distribution,"I watched $\text{Statistics} \space 110$ from Harvard University through YouTube. From lecture 9, the expected value of the geometric distribution is:
$$\sum\limits_{k=0}^{\infty} kpq^k=p\sum\limits_{k=1}^{\infty}kq^k=\frac{pq}{p^2}=\frac{q}{p}$$
where $X$ = number of failures before the 1st success But I cannot understand the derivation below intuitively - what is the meaning of $0$, $p$, $q$ and $(1+c)$:
$$
c=E(X)=0\times p+(1+c)\times q =q+cq=\frac{q}{p}
$$",['statistics']
1289089,Continuity and differentiability of the function $x|x|$,"Let $f:\mathbb R \to \mathbb R$ defined by $f(x) = x|x|$, Is the function continous at all points? If it is, then is it differentiable at all points? Yes, the function is continuous everywhere but there is a slight confusion in differentiability. What I tried  is, $$\large{f(x) = \begin{cases} 
      x^2 & x\geq 0 \\
      -x^2 & x \leq 0 
   \end{cases}}$$ Then I applied left hand derivative limit and right hand derivative limit at $0$, then LDL comes to be $-x$ and RDL comes to be $x$, then the function is not differentiable at $0$. Am i right? and is the function not differentiable at some other points too.","['real-analysis', 'functions']"
1289092,Ricci flow on surfaces : step in proof,I am trying to realize the paper of richard hamilton's ricci flow on surfaces from the book of benett chow's Ricci flow : An Introduction.Here Hamilton denoted the trace free part of the Hessian of the potential $f$ of the curvature by $$\ M = \nabla \nabla f - \frac 12 \Delta f . g $$ Next taking divergence of $M$ we have $$(div M)_i = \nabla ^j M_{ji}=\nabla _j\nabla_i\nabla^jf-\frac 12 \nabla_i\nabla_j\nabla^jf=R_{ik}\nabla^kf+\frac 12\nabla_i\Delta f=\frac 12(R\nabla_if+\nabla_iR)$$....But in this calculation I can not find what the term $\nabla^j$ means.$\nabla_j$ is covariant derivative...But what about $\nabla^j$...Please anyone help me to understand the calculations...one more here $R_{ik}=\frac R2 g_{ik}$...,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
1289115,Gauss's lemma: More than a stepping stone on the way to proving $R[x]$ is a UFD when $R$ is?,"I'm reviewing my abstract algebra a bit. Currently looking at UFDs. In this context, Gauss's lemma (or part of it, at least) says that the product of two primitive polynomials over a UFD is primitive. It seems to me that Gauss's lemma follows pretty easily from the Theorem  that $R[x]$ is a UFD when $R$ is. However, this is a bit logically backwards, since I think Gauss's lemma is a sort of a preliminary step towards proving exactly that theorem? Argument: Let $R$ be a UFD. Suppose that $p(x)q(x)$ is not primitve, where $p(x),q(x) \in R[x]$. Thus, there must be some nonunit element of $R$ dividing $p(x)q(x)$. It follows that there is an irreducible $r$ of $R$ which divides $p(x)q(x)$. Now it is easy to see that an irreducible element of $R$ is still an irreducible element of $R[x]$ (degrees add, so you can't factor a constant into anything but constants). Since $R[x]$ is a UFD, its irreducibles are also prime, so $r$ is a prime element of $R[x]$. Then, from $r|p(x)q(x)$, we get that $r|p(x)$ or $r|q(x)$, so one of $p(x)$ or $q(x)$ is not primitive. My question is sort of a philisophical one: Question: Is it correct to think of Gauss's lemma as just a partial result which is then superseded by the Theorem: ""$R$ a UFD implies $R[x]$ a UFD"", or am I somehow missing out on something here? In other words, is this roughly how you think of Gauss's Lemma, or do you view it as a useful result in its own right?","['irreducible-polynomials', 'abstract-algebra', 'polynomials', 'factoring', 'unique-factorization-domains']"
1289151,Uniqueness of Rectifying Coordinates: Question for Arnold's ODE Book,"In section 7 of his book Ordinary Differential Equations , VI Arnold explains the `rectification theorem', that, given an ordinary differential equation $$\dot{\mathbb{x}} = \mathbb{v(x)}$$
where $\mathbb{v}$ is smooth, and given a point $\mathbb{x_0}$ such that $\mathbb{v(x_0)}\neq 0$, then in some sufficiently small neighbourhood of $\mathbb{x_0}$ one can choose a coordinate system $(y_1,\ldots, y_n)$ such that, in this coordinate system, the equation is transformed into: $$\dot{y}_1 = 1,\quad \dot{y}_2 =\cdots = \dot{y}_n=0$$ Then in problem 1 of section 7.2 he asks: Are the rectifying coordinates $y_i$ uniqely defined? Prove that in 1 dimension the coordinate $y$ is defined to within an affine transformation $\bar{y} = \alpha y + \beta$. I can't see how this can possibly be true. Suppose that
$$\dot{x} = v(x)$$
and we've cleverly chosen the rectifying coordinates
$$y = f(x)$$
so that
$$\dot{y} = \frac{dy}{dx}\frac{dx}{dt} = \frac{df}{dx} \dot{x} = 1.$$ Then if we consider $\bar{y} = \alpha y + \beta = \alpha f(x) + \beta$, then
$$\dot{\bar{y}} = \frac{d\bar{y}}{dy}\frac{dy}{dt} = \alpha \dot{y} = \alpha \neq 1.$$
so $\bar{y}$ cannot be a rectifying coordinate. Intuitively, I can see that rectifying coordinates remains such under translations (i.e. adding $\beta$), but multiplication by $\alpha$ scales the vector field, and I feel this should interfere with the $\dot{y}_1=1$ term, as the maths seems to show. Taking it as axiomatic that Arnold isn't wrong - where is my 
misunderstanding? :)",['ordinary-differential-equations']
1289152,Solve linear system with variables?,"I have a system of equations like the below: $$x + 3y - z = a \\
x + y + 2z = b \\
   2y - 3z = c$$ And have put it in an augmented matrix: $$\begin{bmatrix}
1 & 3 & -1 & a \\
1 & 1 & 2 & b \\
0 & 2 & -3 & c\end{bmatrix}$$ I need to find the conditions where the system is consistent (values of $a$, $b$, and $c$ whereby the system has a solution). I've attempted to reduce the matrix to row echelon form, but the last column is getting quite crazy. I have to wonder what I should do (if this is even the correct start) once it is reduced: I am left with things like: $$\begin{bmatrix}
1 & 0 & 0 & \text{a mess}\\
0 & 1 & 0 & \text{a mess}\\
0 & 0 & 1 & \text{a mess}\end{bmatrix}$$ If (or when) I get to the endpoint, and only if this is the right methodology, how do I determine the values of $a$, $b$, and $c$ in relation to $z_1$, $z_2$, and $z_3$?","['linear-algebra', 'matrices']"
1289166,Proving Hadamard lemma: how to apply FTC in first step?,"I wanted to prove Hadamard's lemma but got stuck on the first step: Let $f \in C^\infty (\mathbb R^n)$ and $x_0 \in \mathbb R^n$. Then there exist $g_i \in C^\infty (\mathbb R^n)$ such that $$ f(x) = f(x_0) + \sum_{i =1}^n g_i(x) (x-x_0)$$ on some neighbourhood of $x_0$. Proof: I want to apply the Fundamental Theorem of Calculus but in $n$-dimensions. Something like this: $$ f(x) = \color{red}{f(x_0) + \int_{x_0}^x {d \over dt} f(t) dt} = f(x_0) + \int_{0}^1 {d \over dt} f(t(x-x_0) + x_0)  dt $$ except, the part in $\color{red}{red}$ s not quite right yet (as $t$ is a scalar variable). The reason why I don't know how to fix it is: it should probably be a sum of partial derivatives but then I'd have the same sum in the next equality which is not the case: the last expression in the above display style equation seems fine as it is. So my question is: What is the correct expression (between $f(x_0)$
  and $f(x_0) + \int_{0}^1 {d \over dt} f(t(x-x_0) + x_0)  dt$ )that I
  should obtain after applying the FTC?","['differential-geometry', 'multivariable-calculus']"
1289170,Conditional probability to Conditional expectation,"My first related question is this link. enter link description here Expected value of geometric distribution is
$$c=E(X)$$
$$c=0\times p+(1+c)\times q =q+cq$$
$$c=\frac{q}{p}$$ when $X= number \ of \ failures \ before \ the \ 1st \ success$ I just learned about conditioning through $Statistics \ 110$, lecture in Harvard. So I want to proof that equation using conditioning. $$P(X)=P(X\mid A_1)P(A_1)+P(X\mid A_2)P(A_2)$$ So,
$$E(X)=\sum\limits_{x=1}^{\infty} xP(X=x)=\sum\limits_{x=1}^{\infty}xP(X=x\mid A_1)P(A_1)+\sum\limits_{x=1}^{\infty}xP(X=x\mid A_2)P(A_2)$$
$$when \ P(A_1)=P(1st \ success)=p, \ P(A_2)=P(1st \ failure)=q$$
I know
$$\sum\limits_{x=1}^{\infty}xP(X=x\mid A_1)P(A_1)=0$$ because $P(X=x\mid A_1)=0 \ ,\ for \ any \ positive \ integer \ x $. And now we have $q\sum\limits_{x=1}^{\infty}xP(X=x\mid A_2)$ only. But I have no idea that covert $\sum\limits_{x=1}^{\infty}xP(X=x\mid A_2)$ into $(1+c)$ algebraicly. I want to know that this process has any error and some idea to complete this proof.","['probability', 'statistics']"
1289188,Proving that $r{n \choose r}=n{n-1\choose r-1}$,For proving that: $r{n \choose r}=n{n-1\choose r-1}$ I attempted it with: $r{n\choose r}=\frac{rn!}{r!(n-r)!}=\frac{n!}{(r-1)!(n-r)!}$ $n{n-1\choose r-1}=\frac{n(n-1)!}{(r-1)!(n-(r-1))!}=\frac{n!}{(r-1)!(n-r+1)!}=\frac{n!}{(r-1)!(n-r+1)(n-r)!}$ $\frac{n!}{(r-1)!(n-r)!}=\frac{n!}{(r-1)!(n-r+1)(n-r)!}$ I need help on what I did wrong and what is the correct method to prove this.,"['binomial-coefficients', 'combinatorics']"
1289191,Integration of gaussian divided by square root of -log(1-x) - does the Meijer G function help me?,"After some modelling of my data I came to the following integral:
$$
\int_0^{1}\dfrac{exp{\left(-\dfrac{\left(x-\mu\right)^2}{2\,\sigma^2}\right)}}{\sqrt{-\log{(1-x)}}}
$$
I cannot solve it, and neither can mathematica, maxima or sympy. I would like to know how to solve such integrals in general and I will pursue any pointers. I know that often such integrals can be solved by expressing the function in forms of a confluent hypergeometric function or something even more general, like the meijer G function, but I do not know how to do that. I want to calculate this integral because I want to optimize the likelihood of the measurements, modelled as gaussian distributions, given the distribution. The overall distribution arises as the distribution of function values of a gaussian distribution where the values of x are randomly distributed. Note that the distribution itself can be integrated:
$$
\dfrac{d\,\mathrm{erf}\left({\sqrt{-\log{\left(1-x\right)}}}\right)}{dx} = \dfrac{1}{\sqrt{-log\left(1-x\right)}}
$$","['calculus', 'probability-distributions', 'maxima-software', 'statistics', 'integration']"
1289306,Parallel Transport on a Cone,"Suppose we have a cone and we wish to parallel transport a vector $w=(0,1,0)$ from  along the curve $\alpha(s)=(\sqrt{2}/2 \cos(v\sqrt{2}),\sqrt{2}/2 \sin(v\sqrt{2}),\sqrt{2}/2)$ from $p=\alpha(0)$ to $q=\alpha(\frac{\pi\sqrt{2}}{4})$ I take polar coordinates on the plane and construct the isometry $F:(\rho,\theta)\in (0,\infty)\times(0,\sqrt{2}\pi) \longrightarrow F(\rho,\theta)=\left(\frac{\sqrt{2}}{2} \rho\cos(\theta\sqrt{2}),\frac{\sqrt{2}}{2} \rho\sin(\theta\sqrt{2}),\rho\frac{\sqrt{2}}{2}\right)$. $F$ is a local isometry between the plane and the cone, so it is equivalent if we do parallel transport on the plane or on the cone. See this image from Do Carmo's Differential Geometry of Curves and Surfaces. So now I know the angle between the parallel transport of $w$ and the $\alpha'(\frac{\pi\sqrt{2}}{4})$. But how do I finish? How do I get the parallel transport of $w$?","['differential-geometry', 'riemannian-geometry']"
1289339,What is meant by the delta equivalent sign?,"What is the meaning of the delta equivalent ($\overset{\Delta}{=}$) sign? I met this in a communication theory text. It said, signaling rate: $r\overset{\Delta}{=} 1/D$ symbols/s or also called ‘baud’.","['notation', 'discrete-mathematics']"
1289344,$\int_{-\pi/2}^{\pi/2} \cos(a \cos\theta) e^{im\theta} e^{-ib\sin\theta} \mathrm{d}\theta $ Integration,"I am struggling to find the integration of the expression below,
$$\int_{-\pi/2}^{\pi/2} \cos(a \cos\theta) e^{im\theta} e^{-ib\sin\theta} \mathrm{d}\theta $$
where $a$ and $b$ are arbitrary constant and $m$ is an integer. I have found the result for $m = 0$ which contains $J_0(\sqrt{a^2 + b^2})$ term. I think for this integration, it will involve the $m$-th order of Bessel function of the first kind.","['bessel-functions', 'trigonometry', 'definite-integrals', 'integration']"
1289355,A Zariski open subset of a variety has the same dimension as the variety.,"I am reading Joe Harris' book Algebraic Geometry: A first course . In the book he says: The Grassmannian $G(k,n)$ contains, as a Zariski open subset, affine space $\mathbb{A}^{k(n-k)}$, and thus has dimension $k(n-k)$. Is it true that a Zariski open subset of a variety has the same dimension as the variety? I am trying to find it in Harris' book, but  I do not get it. Is it an inmediate consequence of any other result? I would appreciate if you could explain this fact to me, or if you could tell me a book where it is shown.","['algebraic-geometry', 'zariski-topology']"
1289377,transforming ordinary generating function into exponential generating function,I have seen a post here that says that you can convert an exponential generating function into an ordinary one with the aid of the Laplace transform. Is it possible to do the reverse transformation? i.e. I want to convert an ordinary generating function into an exponential one.,"['laplace-transform', 'generating-functions', 'combinatorics', 'special-functions']"
1289381,"How many ways are there to fill up a $2n \times 2n$ matrix with $1, -1$?","How many ways are there to fill up a $2n \times 2n$ matrix with $1, -1$ so that each column and each row has exactly $n $ $1$'s and $n$ $-1$'s  ? I tried for cases $n=1 , 2$ but the solutions were just case checking so I can't apply it to the general case.","['combinations', 'combinatorics', 'permutations']"
1289387,Trigonometric Substitution in $\int _0^{\pi/2}{\frac{ x\cos x}{ 1+\sin^2 x} dx }$,"Evaluate $$ \int _{ 0 }^{ \pi /2 }{ \frac { x\cos { (x) } }{ 1+\sin ^{ 2 }{ x } } \ \mathrm{d}x } $$
$$$$
The solution was suggested like this:$$$$
SOLUTION:
First of all its, quite obvious to have substitution $ \sin(x) \rightarrow x $
$$ I = \int_{0}^{1} \frac{\arcsin(x)}{1+x^2} \ \mathrm{d}x$$
Now using integration by parts,
$$ I = \frac{\pi^2}{8} - \int_{0}^{1} \frac{\arctan(x)}{\sqrt{1-x^2}} \ \mathrm{d}x$$
Could someone please explain these two steps to me? For example, how do we get $\arcsin(x)$ in the numerator?
Thanks a lot!","['trigonometry', 'calculus', 'definite-integrals', 'integration']"
1289430,Determination of quartic Gauss sums,"Typically, the Gauss sum over $\mathbb{F}_p$ of order $k$ means the quantity
$$\sum_{n=0}^{p-1} e^{2\pi i n^k/p}.$$
In the book Gauss and Jacobi Sums of Berndt, Evans and Williams, a more general sum is examined in the case $k=2$: namely for an arbitrary integer $m$,
$$\sum_{n=0}^{p-1} e^{2\pi i m n^2/p},$$
where the previous sum is obtained by setting $m=1$. The two sums differ by a factor of a Legendre symbol. Specifically, we have
$$\sum_{n=0}^{p-1} e^{2\pi i m n^2/p} = \left(\frac{m}{p}\right)\sum_{n=0}^{p-1} e^{2\pi i n^2/p}.$$
It seems that the authors consider no such generalization for any other values of $k$. In particular, I am interested in the case $k=4$. Is anything known about the quartic sums
$$\sum_{n=0}^{p-1} e^{2\pi i m n^4/p},$$
for $m\not\equiv 1\pmod{p}$? A lovely determination is given when $m=1$, but I cannot find a source that has considered other cases. Any perspective on the matter is welcome.","['exponential-sum', 'gauss-sums', 'number-theory', 'reference-request']"
1289431,How to prove that $C\cdot\aleph_0=C$,"How can I prove that $C\cdot\aleph_0=C$? I tried this: Given that
$k\cdot 1=k$ and $C\cdot C=C$ if $C\cdot C = C \wedge C\cdot 1 = C \wedge  C>|\mathbb N|>1$ then $C\cdot |\mathbb N|= C$ c is the size of the continuum and k is any cardinal. Is this correct?","['elementary-set-theory', 'discrete-mathematics', 'cardinals']"
1289460,Basic Logarithm question - I can't get both answers from quadratic,"Here's the Question : If  $xy$ = $64$ and $\log_x y + \log_y x = \frac{5}{2}$, find $x$ and $y$ I can get this to $$log_x y + \frac{1}{\log_x y} \frac{5}{2}$$ let $\log_x y = N$ $$N + \frac{1}{N} =  \frac{5}{2}$$ Multiply by 2 $$2N + \frac{2}{N} =  5$$ Multiply by N $$2N^2 + 2 =  5N$$ $$2N^2 - 5N + 2 = 0$$ $$(2N - 1)(N - 2)$$ Giving : 
$$N = \frac{1}{2}$$ $$N = 2$$ Therefore : $$\log_x y = \frac{1}{2} $$ $$\log_x y = 2$$ Giving $$x^2 = y$$ $$x^{\frac{1}{2}} = y$$ Part of the original question : $$xy = 64$$ As $x^2 = y$ $$x * x * x = 64$$ $$x^3 = 64$$ Therefore:
$$x = 4$$
$$y = 16$$ I can't seem to solve for $y = x^{\frac{1}{2}}$ though Solving for $x^{\frac{1}{2}} = y$ $$x^{\frac{1}{2}} * x^{\frac{1}{2}} = 64$$ $$x^{\frac{1}{2} + \frac{1}{2}} = 64$$
$$x= 64$$ $$xy= 64$$ $$64y= 64$$
Therefore $$x = 64$$ $$y = 1$$ This is wrong though. Answer : $$(4,16) or (16,4)$$ I don't see how they got the second part. The first part makes sense but I'm not able to solve for $y = x^{\frac{1}{2}}$","['algebra-precalculus', 'logarithms']"
1289497,Why has the Stein operator for normal approximations the form $(\mathcal Af)(x)=f^\prime(x)-xf(x)$?,"My Question: Why has the Stein operator $\mathcal A$ for normal approximations the form $(\mathcal Af)(x)=f^\prime(x)-xf(x)$? How can one deduce this form of the operator? Reason for my question: I try to understand Stein's method . So far I understand, that one can use this method to find estimates for distances between random variables $W$ and $N$ of the form $$\sup_{h\in\mathcal H} |E[h(W)]-E[h(N)]|$$ where $N$ shall be an approximation of $W$ (I am interested in the case, where $N$ has the standard normal distribution). First one sets $g(x)=h(x)-E[h(N)]$ such that $$|E[h(W)]-E[h(N)]| = |E[g(W)]|$$ Instead of estimating $|E[h(W)]-E[h(N)]|$ one can also estimate $|E[g(W)]|$ which doesn't include $N$ (this step is convincing for me). To find estimates easily one sets $(\mathcal A f)(x)=g(x)$ with a certain operator $\mathcal A$ (the Stein operator). For approximations against the normal distribution $(\mathcal Af)(x)=f^\prime(x)-xf(x)$ is used. Thus $$|E[h(W)]-E[h(N)]| = |E[f^\prime(W)-Wf(W)]|$$ I saw in the proof of the Berry-Esseen theorem , that $|E[f^\prime(W)-Wf(W)]|$ can be more easily estimated than $|E[h(W)]-E[h(N)]|$. What I do not understand, is why $(\mathcal Af)(x)=f^\prime(x)-xf(x)$ was chosen in the first place. Is it just a lucky guess?! Which chain of thoughts lead me to the choice $(\mathcal Af)(x)=f^\prime(x)-xf(x)$ for the normal approximation?","['probability-theory', 'estimation', 'normal-distribution', 'functional-analysis', 'operator-theory']"
1289526,Questions on integer-valued polynomials,"An integer-valued polynomial or numerical polynomial is a polynomial $f \in \mathbb Q[x]$ with the property that $f(\mathbb Z)\subseteq \mathbb Z$. The set of numerical polynomials forms a subring $\mathcal N$ of $\mathbb Q[x]$. Obviously $\mathbb Z[x]\subseteq \mathcal N$, but $\mathcal N$ is much larger than that. The binomial polynomials , given for each $n\geq 0$ by $${x \choose n} = \frac{x(x-1)\cdots(x-n+1)}{n!}.$$ They are numerical polynomials because the product of any $n$ consecutive integers is divisible by $n!$. In fact, one can show that the ${x \choose n}$ form a basis of $\mathcal N$ as a $\mathbb Z$-module: Any $f\in \mathcal N$ can be written in a unique way as a finite linear combination $\sum_n a_n {x \choose n}$ of binomial polynomials, where the $a_n$'s are integers. Now if $n,m$ are non-negative integers, then the product $${x \choose n}{x \choose m},$$ being a numerical polynomial, has an expansion as above. For instance, $${x \choose 2}^2 = \left(\frac{x(x-1)}{2}\right)^2 = 6{x \choose 4} + 6 {x \choose 3} + {x \choose 2}$$ or $${x \choose 5}{x \choose 8} = 1287{x \choose 13} + 3960 {x \choose 12} + 4620{x \choose 11} + 2520 {x \choose 10} + 630{x \choose 9} +56 {x \choose 8}.$$ I am interested in knowing more about these coefficients, as they determine completely the structure of the ring $\mathcal N$. Is there a nice formula for the coefficient of ${x \choose d}$ in the expansion of ${x \choose n}{x \choose m}$? With a computer I looked at quite a few examples, and noticed that: The coefficient of ${x \choose d}$ in the expansion of ${x \choose n}{x \choose m}$, call it $c_d(m,n)$, seems to vanish for
  $d<\max\{m,n\}$. You can see this in the examples above. The coefficients $c_d(m,n)$ all seem to be positive . Can we prove any one of these observations, or better even provide a useful formula for $c_d(m,n)$ which would explain these observations?","['elementary-number-theory', 'binomial-coefficients', 'combinatorics', 'integer-valued-polynomials']"
1289556,"How many $s,t,u$ satisfy: $s +2t+3u +\ldots = n$?","Given $n\in \mathbb{N}^+$, what is the possible number of combinations
  $s,t,u,\ldots\in\mathbb{N}$, such that: $$s +2t+3u +\ldots = n\quad?$$
  Additionally, is there an efficient way to find these combinations
  other than an elimination process? This problem comes from the formula for series reversion, and gives the number of terms in each inverse coefficient.","['power-series', 'diophantine-equations', 'combinatorics']"
1289577,System of DEs with constant term,"This is similar but not identical to standard examples in e.g. Paul's Notes , and while the math seems straightforward the results I get disagree with what I get from numerical simulation.  Given a 2D system $$x' = Ax + b$$ my solution is $$x = c_1e^{\lambda_1t}\eta_1 + c_2e^{\lambda_2t}\eta_2 + A^{-1}b$$ where $\lambda_i$ and $\eta_i$ are eigenvalues and eigenvectors of $A$, respectively.  The first two terms in the RHS of the above are straight out of the textbook and indeed my simulation is fine when $b = 0$.  Is the $A^{-1}b$ term incorrect?","['systems-of-equations', 'ordinary-differential-equations']"
1289593,How to find the value of this integral?,"This integral to the value \begin{align}
\int_0^1\frac{\ln^2(1+x)\ln^2 x}{1-x}\ dx=&\ \color{blue}{-\frac{13\pi^2}{24}\zeta(3)+\frac{47}{2}\zeta(5)-\frac15\ln^52+\frac{\pi^2}9\ln^32-\frac{49\pi^4}{360}\ln2+\frac{7}2\zeta(3)\ln^22}\\&\color{blue}{-8\operatorname{Li}_4\left(\frac12\right)\ln2-16\operatorname{Li}_5\left(\frac12\right)},
\end{align}
   How to find this result?
   In fact,I find that $$\int_0^1\frac{\ln(1+x)\ln{x}}{1-x}dx=\zeta(3)-\frac{\pi^2}{4}\ln2$$
   $$\int_0^1\frac{\ln^2(1+x)\ln{x}}{1-x}dx=\frac{21}{4}\zeta(3)\ln{2}-\frac{5\pi^2}{12}\ln^2{2}+\frac{1}{6}\ln^4{2}-\frac{7\pi^4}{144}+4\operatorname{Li}_4\left(\frac12\right)$$","['polylogarithm', 'calculus', 'definite-integrals', 'improper-integrals']"
1289600,The Diophantine Equation $x^2+y^4=2z^4$,"We know that the Diophantine equation $x^2+y^4=2z^4$ has infinitely many solutions . Some of them are shown below $$(y,z)=(1,1),(1,13),(1343,1525),(2372159,2165017).$$ I investigated the ratio of $\dfrac{z}{y}$ from 64 solutions (are the smallest) and found that $84.076$ is maximum. Do we know that the ratio $\dfrac{z}{y}$ is bounded or not.","['number-theory', 'diophantine-equations']"
1289626,Find the Range of the function $f(x) = |x-6|+x^2-1$,"find the Range of $f(x) = |x-6|+x^2-1$ $$ f(x) = |x-6|+x^2-1 =\left\{ 
\begin{array}{c}
x^2+x-7,& x>0 .....(b) \\ 
5,& x=0 .....(a) \\ 
x^2-x+5,& x<0 ......(c)
\end{array}
\right. 
$$ from eq (b) i got $$f(x)= \left(x+\frac12\right)^2-\frac{29}4 \ge-\frac{29}4$$ and from eq (c) i got $$f(x)= \left(x-\frac12\right)^2+\frac{19}4 \ge\frac{19}4$$ and eq(b) tells me that it also passes through 5 and so generalize all this and found its range is $\left[-\frac{29}4 , \infty\right)$ but the graph says its range is $(5, \infty)$",['functions']
1289643,Derivation of the moment generating function of the geometric distribution - why is this wrong?,"Let $P(k,X)=p(1-p)^{k-1}$. When deriving the moment generating function I start off as follows: $E[e^{kt}X]=\sum\limits_{k=1}^{\infty}e^{kt}p(1-p)^{k-1}$. How I end up rearranging this is as follows: $\frac{p}{1-p}\sum\limits_{k=1}^{\infty}e^{kt}(1-p)^k=\frac{p}{1-p}\sum\limits_{k=1}^{\infty}(e^{t}(1-p))^k=\frac{p}{1-p}\frac{1}{1-e^t(1-p)}$ I'm obviously not arriving at the correct answer, but I want to know why this derivation is wrong.","['probability', 'statistics']"
1289651,Find $\int_{\gamma}\frac{dz}z$,"If $\gamma$ is a path from $-i$ to $i$, whose image is contained in $\mathbb C\setminus\mathbb R^-$, find $\int_{\gamma}\frac{dz}z$ Does the integral converge ?, because the path $-i+2it, 0\le t\le1$ is also in $\mathbb C\setminus\mathbb R^-$ and for $t=1/2$ it is $0$ or can I use the fact that $f(z):=\frac1z$ is meromorphic with simple pole at $0$ and define $\alpha_{\rho}(t):=0+\rho e^{it}, t\in[0,\pi]$  and then $\displaystyle\int_{\alpha_{\rho}}f(z)dz=\text{res}_0(f)\cdot \pi i$ with $\text{res}_0(f)=a_{-1}$ where $a_{-1}$ is the Laurent coefficient of $f$ Is the result $1$ ?",['complex-analysis']
1289676,Finding the parameterization of a curve for a line integral problem,"I have to calculate the work of a particle that travel along a curve, given the following vector field: $F(x, y, z) = (2z-1, 0, 2y)$ and where the curve is the intersection between: $s1: z = x^2 + y^2$ and $s2: 4x^2 + 4y^2 + 1 = 4x + 4y$ using the definition of line integrals. What complicates me of this exercise is parameterize the curve, any help?","['line-integrals', 'vector-fields', 'calculus', 'multivariable-calculus']"
1289685,Intersection of affine varieties is affine,"Let $M,N\subset\mathbb{P}^n$ quasiprojective varieties such that there exist isomorphisms $i\colon M\rightarrow Z(a)\subset \mathbb{A}^m$ and $j\colon N\rightarrow Z(b)\subset \mathbb{A}^m$ for ideals $a,b\subset k[x_1,...,x_m]$ (here $Z(a)$ denotes the set of zeros of the functions on the ideal $a$). Prove that $M\cap N$ is isomorphic to an affine set $Z(c)\subset \mathbb{A}^k$ for some $k$ and some $c\subset k[x_1,...,x_k]$. I know that the intersection of zero sets is again a zero set, but here I can't assume that the zero sets $Z(a)$ and $Z(b)$ even have non-empty intersection. Composing the maps $i$ and $j^{-1}$ we can find and isomorphism between the subsets of $Z(a)$ and $Z(b)$ corresponding to the image of $M\cap N$. Thanks in advance for the help!","['algebraic-geometry', 'affine-geometry']"
1289706,Kurtosis of sum of Independent Random Variables,"Suppose that $X$ and $Y$ are independent random variables with different expected values and variances. Suppose we define kurtosis as $$Kurt(X)=\frac{E[(X- \mu)^4]}{E[(X- \mu)^2]^2}$$ My question is what is $Kurt(X+Y)=?$ Wikipedia claims that 
$$\operatorname{Kurt}\left(\sum_{i=1}^n X_i \right) =  \sum_{i=1}^n \frac{\sigma_i^{\,4} \cdot \operatorname{Kurt}(X_i)}{\left( \sum_{j=1}^n \sigma_j^{\,2} \right)^2}$$
I have not been able to show this. I also have seen it repeatedly fail in simulation. By this I mean if I simulate two independent random variables and apply Wikipedia's formula it never holds where well known results like $Var(X+Y) =Var(X) +Var(Y)$ always hold. This leads me to believe that the wiki result is wrong. Can some prove what the result should be?","['probability-theory', 'estimation', 'statistics']"
1289709,Choice function for collection of arbitrary finite sets. AC required?,"I understand how we can show the existence of a choice function for any (finite or infinite) collection of (finite or infinite) subsets of, say, $\mathbb{N}$ or $\mathbb{Z}$ without using the axiom of choice, by showing that a well-ordering over the union of sets in the collection exists. What I don't see though is how to do the same for what appears to be a much simpler case: a (possibly infinite) collection of finite sets, where nothing else is said about the sets other than that each of them is finite. I would need to show a well-ordering exists over the union of those sets, but since they were not explicitly defined to be subsets of $\mathbb{N}$ or $\mathbb{Z}$, I first need to show the following, for example: (i) there exists a surjection from $\mathbb{N}$ to $\bigcup X_i$ for an arbitrary collection of finite sets $X_i$ Correct so far? Alternatively, I'm on the wrong track, and this is precisely a case that (unintuitively for me then) requires application of the axiom. If so, I suppose I don't see why (i) wouldn't hold, when it seems that any definition within ZF of a finite number of elements is equivalent (in some sense to be made precise) to a finite subset of $\mathbb{N}$, so, given that the union of a collection of finite subsets of $\mathbb{N}$ is a subset of $\mathbb{N}$, the required well-ordering exists.","['elementary-set-theory', 'axiom-of-choice']"
1289711,A bad Cayley–Hamilton theorem proof [duplicate],"This question already has answers here : To prove Cayley-Hamilton theorem, why can't we substitute $A$ for $\lambda$ in $p(\lambda) = \det(\lambda I - A)$? (7 answers) Closed 8 years ago . Given $A\in M_{n \times n}(\mathbb{F})$ and $p_{A}(x)=\det(xI-A)$ why saying that $\det(AI-A)=0$ is not valid?",['linear-algebra']
1289742,Rao-Blackwell theorem and conditional distribution,"Let $X_1,..,X_n$ random sample of $X\sim\text{Exp}(\lambda)$ with
  $f(x;\lambda)=\frac{1}{\lambda}e^{-\frac{1}{\lambda}x}I_{[0,\infty]}(x)$ i) Find a unbiased estimator of $\lambda$ based only in
  $X_{(1)}=\min(X_i)$ ii) Apply the Rao-Blackwell theorem for find a
  estimator better that you find in i) For i) I find that $\hat{\lambda}=nX_{(1)}$ is unbiased estimator for $\lambda$. Now for the part ii) that is the problem. I know that $f(x;\lambda)\in$ the exponential family and $T=\sum X_i$ is a complete and sufficient statistic. Then since $\phi_T=E[nX_{(1)}|\sum X_i]$ produces a unbiased estimator, then it needs to be UMVUE. So I calculated the Cramer-Rao Lower Bound and find $\text{var}_\lambda\geq \frac{\lambda^2}{n}$, finally I just take $\phi_T=\frac{\sum X_i}{n}$ Now my doubts are:
i)My reasoning is correct? ii)I always need to calculate conditional distribution? iii)Is there any simple way to find this conditional? iv)How could I find the conditional in this case? I am unable to find that conditional","['conditional-expectation', 'probability', 'statistics', 'statistical-inference']"
1289778,Piece-wise probability density and cumulative distribution function exercise,"Given a random variable $X$ with the density function: $f(x) = a$ if $0 \leq x \leq b$      and $f(x) = b$ if $b < x < a + b$ I want to solve the following exercises regarding this distribution: a) How large is $a$ if $b = 3a$? b) $a = 0.5, b = 1$, then: i) What is $P(X>1)$? ii) What is $P(0.8<X<1.2)$ iii) What is $x_1$ s.t. $ P(X<x_1) = 0.05$? c) Calculate $F(x)$ My ideas: a) The area under the function has to sum up to $1$, hence I assume that $6a^2 = 1$ and hence $a = \sqrt{1/6}$ — is that correct? b) i) $[\frac{1}{2}x^2]_1^{1.5}$ ii) $ 0.5 * [\frac{1}{2}x^2]_{0.8}^{1} + [\frac{1}{2}x^2]_1^{1.2}$ iii) My idea would to solve for b in $\int_{0}^b f(x) x dx = 0.5 $ — but how exactly would I formulate $f(x)$? c) I would assume we end up with two $F(x)$, each one being the integral of the respective $f(x)$ and hence $0.5x$ and $x$ respectively, is that correct? Thanks","['probability', 'statistics']"
1289780,Easy application of the Riemann Mapping Theorem,"Riemann Mapping theorem Every simply connected region $\Omega \subset \mathbb C$ is
  conformally equivalent to the open unit disk (except $\Omega = \mathbb C$) What are application of this theorem? I mean an example of a problem that can be transformed to a different space and solved there, and then the solutions carried back. If it's possible something elementary, I am fairly new at complex analysis after all. On the book there is written that if you have a problem on $H(\Omega_2)$ (all holomorphic function on $\Omega_2$) you can transport it back to $H(\Omega_1)$ if you have a biholomorphic function $\varphi: \varphi(\Omega_1) = \Omega_2$ using the ring isomorphism $f\mapsto f \circ \varphi$ which maps $H(\Omega_2)$ onto $H(\Omega_1)$. If it's possible it would be nice to have an application along these lines! Thank you very much :)","['analysis', 'group-isomorphism', 'complex-analysis', 'conformal-geometry']"
1289781,$\cot^{-1}\frac{y}{\sqrt{1-x^2-y^2}} = 2\tan^{-1}\sqrt{\frac{3-4x^2}{4x^2}} - \tan^{-1}\sqrt{\frac{3-4x^2}{x^2}} $,Express $$\cot^{-1}\frac{y}{\sqrt{1-x^2-y^2}} = 2\tan^{-1}\sqrt{\frac{3-4x^2}{4x^2}} - \tan^{-1}\sqrt{\frac{3-4x^2}{x^2}} $$ as a rational integral equation between x and y. This is what I've done: Let $$t = \tan^{-1}\sqrt{\frac{3-4x^2}{x^2}}$$ $$2\tan^{-1}(t/2) - \tan^{-1}t = \tan^{-1}\frac{t^3}{4+3t^2}$$ $$\implies \frac{\sqrt{1-x^2-y^2}}{y} = \frac{t^3}{4+3t^2}$$ Substituting the value of t and squaring both sides leads to very long calculation. Is there any other way to solve this problem?,['trigonometry']
1289789,Complement of open set is finite in Zariski topology,"This problem has two parts: a) Let $M$ be a finitely generated module over a Noetherian ring $A$. Prove that $S=\{ P \in\operatorname{Spec}(A) : M_P \mbox{ is a free }A_P\mbox{-module} \}$ is an open subset of $\operatorname{Spec}(A)$. b) If $M \subset A^r$ and $A=K[X,Y]$ (where $K$ is a field), prove that the complement of $S$ (as defined above) is a finite set. I did the first part. I proved that for a prime ideal $P \in\operatorname{Spec}(A)$, if $M_P \mbox{ is a free }A_P\mbox{-module}$, then there exists $f_P \notin P$ and an $n \in \mathbb{N}$ such that $M_{f_P} \cong A_{f_P}^n$. If $D(f)=i^{*}(\operatorname{Spec}(A_f))$ (which are open in Zariski topology), then we can prove that $S= \cup_{P \in S} D(f_P)$ , hence $S$ is open. I cannot solve part two. It is weird, since to prove that the complement of an open set in $\operatorname{Spec}(K[X])$ is always a finite set, since it is a PID. But $K[X,Y]$ is not, so we need to use the structure of $S$. Unfortunately I do not know how. Thank you.","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
1289791,Theorem 7.2 in General Topology by S. Willard (characterization of continuity using $f(\overline E) \subset \overline{f(E)}$,"Theorem 7.2 If $X$ and $Y$ are topological spaces and $f:X \to Y$ , then the following are all equivalent :- I) $f$ is continuous. II) for each $E \subset X$ , $f(\bar E) \subset \overline{f(E)}$ . Proof:- (II) $\implies$ (I) Let $x\in X$ and let $V$ be an open neighbourhood of $f(x)$ . Set $E = X-f^{-1}(V)$ and $U=X-\bar E$ . It is easy to verify that, since $f(\bar E) \subset \overline{f(E)}$ , we have $x \in U $ . It is even clearer that $f(U)\subset V$ Hence $f$ is continuous at $x$ I don't understand this part of the proof. I cannot understand how $x\in U$ Can someone help?","['continuity', 'general-topology', 'proof-explanation']"
1289798,Evaluating a limit involving a definite integral,"I want to prove the following limit evaluates to $0$ without using any techniques that involve complex numbers. I already solved it using residues and it's pretty straight forward, but it feels rather unpleasant using such a tool. $$\lim_{n\to\infty} \int_{0}^{2\pi} \frac{\cos(nx)}{x^2+4}\,dx$$ I also tried differentiation under the integral sign, but I got to a point where things got too messy to be handled gracefully so I came here to ask for help. Thanks!","['limits', 'definite-integrals']"
1289819,Dense-in-itself open sets in a subspace of the real line,"Given an uncountable set $X\subset [0,1]$ it is easy to write $X$ as a disjoint union of a perfect set $P$ (perfect in the subspace $X$) and an at most countable set $C$: just take $P$ as the set of condensation points of $X$ and $C$ as its complement in $X$. (we consider $X$ equipped with the subspace topology.) I want to find an open set in $X$ which is dense-in-itself. Is this possible? An open set of a dense-in-itself/perfect space is itself dense-in-itself, but from this point onwards I am most unsure how to proceed correctly. Any comments will be appreciated. Thank you for your help.","['descriptive-set-theory', 'metric-spaces', 'general-topology']"
1289848,Two apparently different antiderivatives of $\frac{1}{2 x}$ [duplicate],"This question already has answers here : Two different solutions to integral (3 answers) Closed 5 years ago . What is right way to calculate this integral and why? $$
\int\frac{1}{2x}\text dx
$$ I thought, that this substitution is right:
$$
t = 2x
$$
$$
\text dt = 2\text dx
$$
$$
\frac{\text dt}{2} = \text dx
$$
$$
\int\frac{1}{2x}\text dx=\int\frac{1}{t}\frac{\text dt}{2}=\frac{1}{2}\ln|2x| + C .
$$ But it's not right, because this is the correct answer:
$$
\int\frac{1}{2x}\text dx=\frac{1}{2}\int\frac{1}{x}\text dx=\frac{1}{2}\ln|x| + C .
$$ Can someone explain me, why is the first way wrong? When I derive both results, I get the same result.","['indefinite-integrals', 'integration']"
1289856,When is the sum of divisors a perfect square?,"For $n=3$, $\sigma(n)=4$, a perfect square. Calculating further was not yielding positive results. I was wondering is there a way to find all such an $n$, like some algorithm? We know that if $n=p_1^{k_1}p_2^{k_2}\dots p_r^{k_r}$ then $\sigma(n)=\frac {p_1^{k_1+1}-1}{p_1-1} \frac{p_2^{k_2+1}-1}{p_2-1}\dots \frac {p_r^{k_r+1}-1}{p_r-1}$. So we have to find $n$ such that $\sigma(n)=\frac {p_1^{k_1+1}-1}{p_1-1} \frac{p_2^{k_2+1}-1}{p_2-1}\dots \frac {p_r^{k_r+1}-1}{p_r-1}=t^2$ for some integer $t$. If each $\frac{p_i^{k_i+1}-1}{p_i-1}$ is a square we will get some such numbers (not all though), but let us consider $\frac{p_i^{k_i+1}-1}{p_i-1}=m^2$. Working a example, If I take $p_i=17 $ , (or any prime such that $p_i-1$ is a perfect square), then if I can find a $k_i$ such that ${p_i^{k_i+1}-1}=16.m^2$ I will get an $n$, so now when can this happen, is something I have to try out. But out of curiosity I am asking has this been worked out before. Problem looks broad to me, Is there a solution to this problem?","['divisor-sum', 'number-theory', 'square-numbers', 'elementary-number-theory']"
1289866,Laurent Series Expansion of $\frac{-3z^2+8z+1}{(z-2)(z^2+1)}$,"Laurent Series Expansion of $\frac{-3z^2+8z+1}{(z-2)(z^2+1)}$ on the annulus $A(1,2)$ I think $A(1,2)$ denotes the set $\{z:1<|z-0|<2\}$, so it excludes the poles. using partial fraction decomposition I got; $\frac{-3z^2+8z+1}{(z-2)(z^2+1)}=\frac{1}{z-2}-\frac{2}{z+i}-\frac{2}{z-i}$ In general The Laurent Series of $\frac{1}{z-z_0}$ about $a$ If $|z-a|<|z_0-a|$ then $\frac{1}{z-z_0}=-\frac{1}{z_0-a}\sum\limits_{n=0}^{\infty}\left(\frac{z-a}{z_0-a}\right)^n$ If $|z-a|>|z_0-a|$ then $\frac{1}{z-z_0}=\frac{1}{z-a}\sum\limits_{n=0}^{\infty}\left(\frac{z_0-a}{z-a}\right)^n$ then I have about $0$ $\frac{1}{z-2}=-\frac{1}{2}\sum\limits_{n=0}^{\infty}\left(\frac{z}{2}\right)^n\quad$ for $|z|<2$ $\frac{2}{z+i}=-\frac{2}{z}\sum\limits_{n=0}^{\infty}\left(\frac{-i}{z}\right)^n\quad$ for $|z|>1$ $\frac{2}{z-i}=-\frac{2}{z}\sum\limits_{n=0}^{\infty}\left(\frac{i}{z}\right)^n\quad$ for $|z|>1$ Can you verify my steps, and Is then their difference or sum the laurent series on the annulus, or is there another one ?","['solution-verification', 'complex-analysis']"
1289867,Book which covers these contents of the same level of Fulton's book.,"My question is very specific. I'm studying Chapter 8 of Fulton's algebraic curves book and I would like to find another book (or online sources) which covers these contents: Divisors, the Vector Spaces $L(D)$ and Derivations and Differentials. I'm looking for beginner's books of the same level and language of Fulton's book but with more detailed explanations, examples and so on. I'm talking about specifically of these contents. I find Fulton's book very concise. I really need help, if anyone could help me, I would be very very grateful! Thanks a lot!","['book-recommendation', 'algebraic-geometry', 'reference-request', 'algebraic-curves']"
1289885,Prove equivalence between $X$ Hausdorff and $X$ finite with discrete topology,"We have a Noetherian topological space $X$. Show that the following are equivalent: $X$ is a Hausdorff space $X$ is finite and has discrete topology So far I've only got this: If $X$ has discrete topology, then any two points $x_1$ and $x_2$ are elements of the disjoint open sets $\{x_1\}$ and $\{x_2\}$ respectively. This implies $X$ is  Hausdorff. (So 2$\implies1$) I don't know how to prove ($1\implies 2$).","['abstract-algebra', 'separation-axioms', 'general-topology']"
1289890,Show that $T(t)$ and $N(t)$ are Orthogonal,"If $r(t)$ is the smooth parametrization of a curve $C$ in 3-space, then the unit tangent and unit normal vectors are denoted as $T$ and $N$, and are given by:
$$T(t)=\frac{r'(t)}{||r'(t)||},N(t)=\frac{T'(t)}{||T'(t)||}$$
How do I show that $T(t)$ and $N(t)$ are orthogonal for all $t$ at which they are defined. I cannot assume anything about the binormal vector $B$, so I want to know how to do this without assuming so.","['differential-geometry', 'multivariable-calculus']"
1289904,Only DVR's with quotient field $\mathbb{Q}$?,"Let $p \in \mathbb{Z}$ be a prime number. I know how to show  that $$\{r \in \mathbb{Q}: r = {a\over{b}},\text{ }a,b \in \mathbb{Z},\text{ }p\text{ doesn't divide }b\}$$ is a DVR with quotient field $\mathbb{Q}$. My question is though, are these the only DVR's with quotient field $\mathbb{Q}$?","['ring-theory', 'commutative-algebra', 'abstract-algebra', 'algebraic-geometry', 'geometry']"
1289909,Prove $f(z)$ is a polynomial if $|f(z)| \leq (1 + |z|)^n$,"Prove $f(z)$ is a polynomial if $f(z)$ is entire and $|f(z)| \leq (1 + |z|)^n$ $\forall z \in C$. Here is what I wrote for my proof: $f(z)$ can be represented as a power series $\sum\limits_{n=0}^\infty a_n z^n$ where $a_n = \frac{f^n(0)}{n!}$ if we choose $|z| = r$. Then by Cauchy's Estimates, we have that $|a_m| = \frac{|f^{(m)} (0)|}{m!} \leq \frac{(1+r)^n}{r^m}$ where $m > n$, so $a_m \to 0$ and $f(z)$ is a polynomial of degree $\leq n$. My solution was marked incorrect, but I didn't have any other ideas on how to approach this. What is the proper solution?",['complex-analysis']
1289915,"""Rationalizing"" an equation","$$x=\sqrt[3]{p}+\sqrt[3]{q}$$ I'm trying to figure out some way to ""rationalize"" the previous equation, meaning to rewrite it purely in terms of whole number powers of $p$, $q$, and $x$. It seems quite simple but I've been stuck trying to do it. I'd appreciate anyone's help with this.",['algebra-precalculus']
1289930,Finding Riemannian metric from this geodesic,"In a $d$-dimensional Riemannian manifold, given a geodesic equation $\gamma^i(t)=a^i\phi(tb^i),i\in 1\ldots d$, where $\phi:\mathbb{R}\rightarrow\mathbb{R}$ is an increasing function, $a^i,b^i$ are constants, is it possible to determine a Riemannian metric (and the corresponding Christoffel symbols) that derives such a geodesic?","['differential-geometry', 'riemannian-geometry']"
1289954,Computing $\int_{0}^{+\infty}\frac{\log(x)}{\sqrt x(1+{x^2})}dx$.,"I would like to compute the following integral :
$$\int_{0}^{+\infty}\frac{\log(x)}{\sqrt x(1+{x^2})}dx$$ using Residue theorem.
I took the contour corresponding to half of the ""donuts"" $\{r<|z|<R\}$.
So by theorem and an classical argument we have 
$I=2i\pi Res(f,i)$. 
My problem here, is that I need ton compute the residue for the principal argument of $\log(z)$ and $\sqrt{z}$. 
How can I do that ? Note Bene, apologies for the 'unclear' question but I am on my mobile.","['closed-form', 'contour-integration', 'complex-analysis', 'definite-integrals']"
1289957,how can I show this integral diverges?,"I want to show $E(T_a)=\infty$ $$E(T_a)=\int_0^{\infty}{{x|a|}\over\sqrt{2\pi}}x^{-3/2}e^{-a^2/x}dx$$ to show this I need to show this integral diverges. I know gamma function that $$\Gamma (\alpha)=\int_0^\infty x^{\alpha -1}e^{-x}dx$$ By benefit from gamma function, how can I show this integral diverges ? Thank you for helping","['gamma-function', 'calculus', 'real-analysis', 'integration', 'analysis']"
1289969,Differential equation of a pendulum,"Consider the nonlinear differential equation of the pendulum $$\frac{d^2\theta}{dt^2}+\sin \theta=0$$ with $\theta(0)=\frac{\pi}3$ and $\theta'(0)=0$. Using the series method, find the first four nonzero terms of the solution. Here is what I found from Maple so far: Text-only (for the series solution): \begin{align}
\theta(t)&=\frac{\pi}3-\frac 12\sin\left(\frac{\pi}3\right)t^2+\frac 1{24}\sin\left(\frac{\pi}3\right)\cos\left(\frac{\pi}3\right)t^4+O(t^6)\\
&=\frac{\pi}3-\frac{\sqrt{3}}4t^2+\frac{\sqrt{3}}{96}t^4+O(t^6)
\end{align} But how can one find this solution by hand, using the series method?",['ordinary-differential-equations']
1289975,Exercise 1.13 of II in Hartshorne algebraic geometry.,"The problem is following. 1.13 Espace Etale of a Presheaf. Given a presheaf $\mathscr F$ on $X$, we define a topological space $Spe(\mathscr F)$, called the espace etale of $\mathscr F$, as follows. As a set, $Spe(\mathscr F) = \bigcup _{P \in X} \mathscr F$. We define a projection map $\pi : Spe(\mathscr F )\to X$ by sending $s\in \mathscr F_P$ to $P$. For each open set $U \subseteq X$ and each section $s \in \mathscr F(U)$, we obtain a map $\bar s : U\to Spe(\mathscr F)$by sending $P \mapsto s_P$, its germ at $P$. This map has the property that $\pi \circ \bar s = id_U$, in other words, it is a ""section"" of $\pi$ over $U$. We now make $Spe(\mathscr F)$ into a topological space by giving it the strongest topology such that all the maps $\bar s : U\to Spe(\mathscr F)$ for all $U$, and all $s \in \mathscr F(U)$, are continuous. Now show that the sheaf $\mathscr F^+$ associated to $\mathscr F$ can be described as follows: for any open set $U \subseteq X, \mathscr F^+ (U)$ is the set of continuous sections of $Spe(\mathscr F)$ over $U$. In particular, the original presheaf $\mathscr F$ was a sheaf if and only if for each $U$, $\mathscr F (U)$ is equal to the set of all continuous sections of $Spe(\mathscr F)$ over $U$. I understood all but the last line. If $\mathscr F$ was a sheaf, $\mathscr F$ is isomorphic to $\mathscr F^+$ and so for each $U$, $\mathscr F (U)$ is equal to the set of all continuous sections of $Spe(\mathscr F)$ over $U$. But the converse is unclear to me. In general the map $\theta : \mathscr F \to \mathscr F^+$ is not injective since the injectivity requires sheaf conditions. In this situation how can we regard the elements of $\mathscr F(U)$ as sections of $Spe(\mathscr F)$ over $U$? Is injective the map $\theta : \mathscr F \to \mathscr F^+$ even in the case of presheaf $\mathscr F$? $\theta$ is defined by $ s \mapsto (\bar s : P \mapsto s_P )$.",['algebraic-geometry']
1289977,Limited partial sum of $\displaystyle \sum _{n=1} ^{k} \cos(nx)$ are limited?,I'm wondering if it's true that  $\displaystyle \sum _{n=1} ^{k} \cos(nx)$ has limited partial sum. I know it has representation $\displaystyle \frac{\sin\left(\frac{kx}{2}\right)\cdot\cos\left(\frac{(k+1)x}{2}\right)}{\sin\left(\frac{x}{2}\right)}$ and we have it defined for $x \in \mathbb{R}-\{ c\cdot\pi \}$ for some $c \in \mathbb{Z}$,"['sequences-and-series', 'calculus', 'trigonometry']"
1289985,Polynomial Functional Equation: $f(x)f(y)+2=f(x)+f(y)+f(xy)$,"Let $f(x)$ be a one-one, polynomial function such that $f(x)f(y)+2=f(x)+f(y)+f(xy) , \ \forall x,y \in \mathbb R \setminus \{0\}$ , $f(1) \ne 1$ , $f'(1)=3$ . Find $f(x)$ . I tried to find the degree of the polynomial from the equation by using suitable substitution, but it didn't work. Also, I found that $f(1)=2$ and then I substituted $y=\frac{1}{x}$ to get $f(x)f\left(\frac{1}{x}\right)= f(x) + f\left(\frac{1}{x}\right)$ . But I can't simplify further. Also, the answer given in my book is $f(x)=x^3+1$ . Any help will be appreciated. Thanks.","['calculus', 'functional-analysis', 'algebra-precalculus', 'functions', 'derivatives']"
1290025,"For which values of $\alpha \in \mathbb{R}$, does the series $\sum_{n=1}^\infty n^\alpha(\sqrt{n+1} - 2 \sqrt{n} + \sqrt{n-1})$ converge?","How do I study for which values of $\alpha \in \mathbb{R}$ the following series converges?
(I have some troubles because of the form [$\infty - \infty$] that arises when taking the limit.) $$\sum_{n=1}^\infty n^\alpha(\sqrt{n+1} - 2 \sqrt{n} + \sqrt{n-1})$$","['sequences-and-series', 'calculus', 'real-analysis']"
1290029,Describe all odd primes p for which 7 is a quadratic residue,"I need to describe all odd primes $p$ for which $7$ is a quadratic residue. Now let $\left(\frac{a}{b}\right)$ be the Legendre Symbol. Then if $7$ is a quadratic residue $p$ we must have:
$$1=\left(\frac{7}{p}\right)=(-1)^{\frac{3(p-1)}{2}} \left(\frac{p}{7}\right)$$
Here I have used Gauss theorem on Quadratic Reciprocity. This implies that $\left(\frac{p}{7}\right)=1$ and $(-1)^{\frac{3(p-1)}{2}} = 1$, or $\left(\frac{p}{7}\right)=-1$ and $(-1)^{\frac{3(p-1)}{2}} = -1$. HOWEVER at this step in the solutions, we are given that: $\left(\frac{p}{7}\right)=1$ and $p\equiv 1\bmod 4$ OR $\left(\frac{p}{7}\right)=-1$ and $p\equiv -1\bmod 4$ Why is this equivalent? So what I am basically asking is the following: Why is $(-1)^{\frac{3(p-1)}{2}} = 1$ equivalent to $p\equiv 1\bmod 4$? And $(-1)^{\frac{3(p-1)}{2}} = -1$ equivalent to $p\equiv -1\bmod 4$?","['number-theory', 'quadratic-reciprocity', 'congruences', 'legendre-symbol']"
1290054,Compute flux of vector field F through hemisphere,"I need help solving this question from my textbook. Compute the flux of the vector field: $$\vec F = 4xz\vec i + 2 y\vec k$$ through the surface $S$, which is the hemisphere: $x^2 + y^2 + z^2 = 9 ,  z \geq 0$ oriented upward. How do I continue?
Which theorem do I need to solve this problem?","['vector-fields', 'vectors', 'calculus', 'multivariable-calculus']"
1290096,Factorization of the sine,I am working on the Basel problem for a project for my Mathematics study. I need to prove that one could write the sine as a factorization of its linear roots. I know the proofs is in general done using the Weierstrass Factorization theorem but are there any other proofs specifically for the sine that are less complicated? P.S. I'm in my first year as a Mathematics student so my knowledge is limited.,"['analysis', 'number-theory', 'complex-analysis']"
1290104,How to solve this 2nd order ODE,"Consider $$\epsilon y''+yy'-y=0$$
with boundary conditions $y(0)=0$ and $y(1)=3$. I showed that the outer solution is $y_{in}(x)=x+2+O(\epsilon)$. Than for the inner solution, I wish to solve the follow ODE $$Y''(X)+Y(X) \cdot Y'(X) = 0$$ with only one boundary condition $y(0)=0$ and $X={x \over \epsilon}$. Can anyone show me how to do it?",['ordinary-differential-equations']
1290118,Solving an integral with trig substitution,"I'm looking to solve the following integral using substitution: $$\int \frac{dx}{2-\cos x}$$ Let $z=\tan\frac{x}{2}$ Then $dz=\frac 1 2 \sec^2 \frac x 2\,dx$ $$\sin x=\frac{2z}{z^2+1}$$ $$\cos x =\frac{1-z^2}{z^2+1}$$ $$dx=\frac{2\,dz}{z^2+1}$$ $$\int \frac{dx}{2-\cos x} = \int \frac{\frac{2\,dz}{z^2+1}}{2-\frac{1-z^2}{z^2+1}} =\int \frac{2\,dz}{3z^2+1}$$ But this is where things start to look at bit sticky.  If I integrate this last fraction, then I get a very complex expression that seems to defeat the point of z-substitution.  Any suggestions for where I may be going wrong? Thanks! Edit: Thank you for your feedback.  I've completed my work as per your suggestions: $$\int \frac{2\,dz}{3z^2+1} = 2\cdot\left(\frac{\tan^{-1} \frac{z}{\sqrt{3}}}{\sqrt{3}} \right) = \frac{2\tan^{-1} \left(\sqrt{3}\tan{\frac{x}{2}}\right)}{\sqrt{3}}+c$$","['trigonometry', 'calculus', 'integration']"
1290127,Solving a special Quartic Equation.,"Solve for $x$ $$(x^2-4)(x^2-2x)=2$$ I have tried the Rational Root Theorem and found that there are no rational roots. Further, the polynomial $p(x)=(x^2-4)(x^2-2x)-2$ is irreducible since when I tried expanding it and writing it as a product of two quadratics, there were no integer solutions for the coefficients. I also depressed the quartic polynomial $p(x)$ hoping that the coefficient of $x$ would also vanish along with the coefficient of $x^3$, giving me a biquadratic. But that didn't happen. I also tried using substitutions,  but none of them worked so far. Any help will be appreciated. Thanks.","['polynomials', 'roots', 'algebra-precalculus', 'functions']"
1290154,For what values of $x$ does the series $\sum_{n=1}^\infty \frac{1}{(\ln x)^{\ln n}}$ converge?,"I have to study the values of $x$ for which $$\sum_{n=1}^\infty \frac{1}{(\ln x)^{\ln n}}$$ converges. First we say that we must have $x>0$. Then, I have started by rewriting the series as $$\sum_{n=1}^\infty \frac{1}{e^{\ln\ln x\ln n}} = \sum_{n=1}^\infty \frac{1}{n^{\ln\ln x}}.$$ It converges if $\ln\ln x >1$. So it converges for $x>e^e$. Is my reasoning correct?","['sequences-and-series', 'calculus', 'real-analysis', 'proof-verification']"
1290161,Show that a particular set is not a limit ordinal (aim is to define ordinal subtraction),"Let $\alpha$ and $\beta$ be two ordinals with $\beta \leq \alpha$. Define $$ X:= \{\gamma \in \alpha^{+} : \beta + \gamma \leq \alpha\}.$$ I have shown this is an ordinal. Now I need to show it isn't a limit ordinal, but I'm stuck. Many thanks for your help.","['ordinals', 'elementary-set-theory']"
1290172,Geometrical Interpertation of Cauchy's Mean Value Theorem,"Cauchy MVT: If functions f and g are both continuous on the closed interval [a,b], and differentiable on the open interval (a, b), then there exists some c ∈ (a,b), such that $$\frac{f'(c)}{g'(c)}= \frac{f(b) - f(a)}{g(b)-g(a)}$$ Lately, after I proved the CMVT, I was trying to intuitively understand (using geometry of course) the meaning of CMVT by comparing it to the MVT; for, I know that the CMVT is just an extension of the MVT, such that the only difference is that $$g(x)=x$$ for the MVT. Yet, even though this is self-evident, I could not inhabit an intuition through a geometric representation of it; for, in all demonstrations of the MVT I have viewed, I only see one function $$f(x)$$ in the geometrical representation, which thusly implies there exists no $$g(x)$$ - not to my perspective at least.So, I searched for another demonstration of the CMVT and I found something related to parametric curves as follows: And,  since I have not encountered parametric curves, I could not fully grasp this demonstration. So, can anyone help me with my confusions over a graphical demonstration of the CMVT. (Note: If a explanation of this intuition requires a knowledge of parametric curves etc..., feel free to include it in the answer).","['calculus', 'real-analysis']"
1290189,Definition of Limit in Multivariable Calculus,"Let $f(x,y)$ be a function defined in some disk that is centered at $(x_0,y_0)$. Suppose that $L$ is some real number. Then in this case, what does it mean that:
$$\lim_{(x,y)\to (x_0,y_0)} f(x,y)=L$$
So basically I want the definition of limit in this case. I want it in a way that doesn't use non-mathematical words such as ""approaches"", ""close"", etc. Instead I want it to be in a mathematical context that is understandable to someone taking multivariable calculus for the first time with only the knowledge from multivariable calculus and calculus 1 and 2.","['multivariable-calculus', 'limits']"
1290195,Does the function have horizontal or vertical asymptotes?,"So I'm analyzing some functions here and I need to determine whether or not they have horizontal or vertical asymptotes.  The equations are: $f(x)=260$ $g(x)=1+24(0.9)^x$ $h(x)=f(x)/g(x)$ Now $f(x)$ I do not believe has asymptotes since it is linear.  $g(x)$ looks like by its graph that it could have either. $h(x)$ should not have a vertical asymptote but I am not sure if it has a horizontal asymptote. If someone could help me with this, that'd be appreciated :)","['graphing-functions', 'algebra-precalculus', 'functions']"
1290205,Conditional expectation and rao-blacwell,"I am studying on UMVUE, and I'm struggling to find that conditional expectation Let $X_1,\ldots,X_n$ random sample of $X\sim U[0,\theta]$.
i) Show that $2X_1$ is a unbiased estimator for $\theta$ and use the Rao-BlackWell Theorem for found the UMVUE for $\theta$. ii)Calculate $E[X_{(n)}]$ and explicitly find UMVUE for $\theta$ I already show that $2X_1$ is unbiased and also found that $X_{(n)}=\max(X_1,\ldots,X_n)$ is a complete and sufficient statistic for $\theta$, but I am having trouble finding the conditional, how I can calulate
$$E[2X_1\mid X_{(n)}]=2E[X_1\mid X_{(n)}]$$
How do I calculate the conditional distribution and the expectation?","['estimation', 'statistics', 'statistical-inference']"
1290233,"Geometrically, why do line bundles have inverses with respect to the tensor product?","Geometrically, why do line bundles have inverses with respect to the tensor product? Here my thoughts on the problem so far, please excuse their scatteredness. I know algebraically, it is just because they are locally modules generated by $1$ element. Basically, it is just the fact that if one has a finitely generated module $M$ over a local ring $R$, there exists $M^{-1}$ with $M \otimes M^{-1} = R$ only when $M$ is free of rank $1$. This is not hard to prove. Geometrically, we are taking a line bundle; we are sort of ""straightening the lines"" to make it trivial. In fact, line bundles are just trivial neighborhoods with transition functions to $\mathbb{A}^1$. We just take the reciprocal of the transition function, and that gives us the inverse line bundle. So one might think of the following: the tensor product corresponds to product of modules, and hence looks nice geometrically precisely when there is no ""torsion"" in a non-precise sence, i.e. locally free modules? Locally projective modules? Flat? (Projective is stronger than flat.) So those are morally vector bundles, and can be straightened consistently precisely when the rank equals $1$. As a counterthought to the above, the above isn't exactly true. ""Straightening"" only really makes sense in the rank $1$ case because the structure sheaf is itself a line bundle and not a higher vector bundle. So one can not, for obvious reasons, have a rank $2$ vector bundle that inverts another rank $2$ vector bundle. But in the case of a rank $1$, it is straightening the bundle, which can be done. For higher dimensional vector bundles, we can think of an ""inverse"" as $O^r$, but even then not all guys would be invertible (i.e. anything that does not split probably should not be invertible like this). Everything I have so far is rather verbose. On an intuitive level with respect to the original question, we can think of nontrivial line bundles as structures that force their sections to have zeros or poles. If we have a section that is regular and has no vanishing everywhere, we can use it to trivialize the line bundle. A nice geometric picture of this is the line bundle of the Möbius strip over the circle. Alternatively, we can always construct an inverse by taking the dual of a line bundle and then using the adjoint properties of the tensor product to show its an inverse. If we take a section, there will have to be some point in which the section crosses over the zero section. If we can find some section that has poles where the sections have zeros, their tensor product, which will have sections behaving like the product of the $2$ original sections will be regular. So now, we have to visualize what taking the dual means, or sending zeros to poles. Geometrically, this is kind of like flipping over our line bundle and gluing everything together at infinity. This makes the zeros become poles. But this is all still very algebraic. Anyways, we certainly know how it works for higher dimensional things because the tensor product multiplies the dimension of the vector space. At this point, one might wonder, what do I mean by ""if we take a section, there will have to be some point in which the section crosses over the zero section."" Why does a global section have to intersect the zero section? Think about the Möbius strip. Draw a circle in the middle; this is isomorphic to the circle. Thus, the Möbius strip is a line bundle over the circle (well, we need to extend the Möbius strip out to infinity). Now, draw some line along the Möbius strip that tries to avoid intersecting the zero section (the circle we drew). This is impossible because when we wrap around the Möbius strip, we will be on the other side of the Möbius strip, and thus, to be a well-defined section, we must cross the zero section. This line represents a section and thus, every section has a zero. This is how we know that this line bundle is not trivial. So every section vanishes. In fact, we know that a line bundle is trivial if it has nonvanishing section. Since we can construct a trivialization by considering the map from $X$ (where $X$ is the variety or scheme we are working over) $L$ (the line bundle) given by $L$ maps to $X \times \mathbb{A}^1$ by $(x, y)$ maps to $(yf(x))$, where $f$ is the nonvanishing regular section. This gives an isomorphism. Hence, the zeros or poles of the section really gives us the interesting information of a line bundle. This is really the significance of this Picard group construction. To any set of poles and zeros, i.e. a divisor we may associate a line bundle $O(D)$, and this gives an isomorphism if we mod out by linear equivalence (i.e. multiplication by rational sections over the variety). Hence, the line bundle is uniquely determined by zeros and poles up to adding the zeros and poles achievable by rational functions on $X$. In general, the statement ""nontrivial if and only if vanishing sections"" is obvious by monodromy. And one could formally understand the tensor/Hom adjunction used in the Picard construction. But what does it mean really? The Picard group, the way I think of it, is the set of all divisors. Group of all divisors finite linear combinations of coding simon $1$ subvarieties, i.e. points if we are working over a curve. And these correspond to zeros and poles of functions. To which we could ask, is this accurate? Isn't the Picard group more analogous to the class group? And even then, that is not always an isomorphism. To which we would respond, yes that is true. The class group which is the group we are describing above quotients out by $Z(f)$, which is us looking at the valuation of $a$, rational function $f$ at the set of all divisors, i.e. we determine its order of vanishing at all the different possible zeros and poles. But one is correct that it is not always an isomorphism. However, for smooth complete curves, it most certainly is, and that is what most of this theory is used for. We already have some issues if we do not work over algebraically closed fields because then we can not factor our polynomial all the way. (Wikipedia gives the construction explicitly of line bundles $\implies$ class group element, and the thing about nonvanishing global sections being trivial makes it clear why it is well-defined up to principal divisors.) The bad behavior comes when it is not a factorial scheme. So we ask, what is an example of a scheme where the germs are not unique factorization domains? We will have issues... for example, look at Weil and Cartier divisors, as Weil does not always imply Cartier . Now, in spite of all this rambling, I feel like I still do not have a deep geometric understanding as to why line bundles have inverses with respect to the tensor product. It's quite possible I'm missing a relatively simple way of thinking about it. Could someone assess my statements and tell me if they are correct and/or the right way to think about this problem, and possibly contribute some of their own intuitions/explanations? Thanks in advance.","['abstract-algebra', 'algebraic-geometry', 'geometry', 'commutative-algebra']"
1290244,For which $x\in \mathbb{R}$ does $\sum_{n=1}^\infty \left(\frac{x^{2n}}{n} - \frac{n^{2x}}{x}\right)$ converge?,"I have to study for which values of $x \in \mathbb{R}$ the following series converges: $$\sum_{n=1}^\infty \left(\frac{x^{2n}}{n} - \frac{n^{2x}}{x}\right)$$ I was only able to say that the necessary condition for the convergence of the series, $\left(\frac{x^{2n}}{n} - \frac{n^{2x}}{x}\right) \to 0$, is satisfied iff $-1<x<0$, but then I'm stuck. How would you complete the problem?","['sequences-and-series', 'calculus', 'real-analysis']"
1290246,Estimates for the normal approximation of the binomial distribution,"I'm interested in estimates of the normal approximation for binomial distributions, i.e. in estimates of $$\sup_{x\in\mathbb R}\left|P\left(\frac{B(p,n)-np}{\sqrt{npq}} \le x\right) - \Phi(x)\right|$$ From the Berry-Essen theorem I can deduce $$\sup_{x\in\mathbb R}\left|P\left(\frac{B(p,n)-np}{\sqrt{npq}} \le x\right) - \Phi(x)\right| \le \frac{C(p^2+q^2)}{\sqrt{npq}}$$ with $C \le 0.4748$. My question: Are there better estimates for the normal approximation of the binomial distribution? The Berry-Esseen theorem is quite general because it can be applied to each sum of i.i.d random variables. So I guess there are better estimates for the special case of the binomial distribution...","['probability-theory', 'probability-distributions', 'estimation', 'normal-distribution', 'reference-request']"
1290270,Can a nonempty set ever equal its Cartesian product with another set?,"Suppose that $S$ and $T$ are sets, with $S\neq \emptyset$. Would it be possible to have $S=S\times T = \{(s,t): s\in S, t\in T\}$? If such were the case, then we'd have
\begin{align*}
\{(s,t): s\in S, t\in T\} &= \{(s,t): s\in \{(s,t): s\in S,t\in T\}, t\in T\}\\ & = \{(s,t): s\in \{(s,t): s\in \{(s,t): s\in S,t\in T\},t\in T\}, t\in T\}\\
& = ... \text{and so on.}\\
\end{align*} Would this make any sense?",['elementary-set-theory']
1290291,"Identification of a quadrilateral as a trapezoid, rectangle, or square","Yesterday I was tutoring a student, and the following question arose (number 76): My student believed the answer to be J: square. I reasoned with her that the information given only allows us to conclude that the top and bottom sides are parallel , and that the bottom and right sides are congruent . That's not enough to be ""more"" than a trapezoid, so it's a trapezoid. Now fast-forward to today. She is publicly humiliated in front of the class, and my reputation is called into question once the student claims to have been guided by a tutor. The teacher insists that the answer is J: square (""obviously""... no further proof was given). Who is right? Is there a chance that we're both right? How should I handle this? I told my student that I would email the teacher, but I'm not sure that's a good idea.","['education', 'geometry', 'advice']"
1290296,Mean value theorem for random variables (inside an expectation value),"In a proof I am trying to understand a mean value theorem for random variables is used. It is stated that $$E[f(X+Y)]=E[f(X)+f^\prime(X+\Theta Y)]$$ for real valued random variables $X$ and $Y$ and $f\in C^1$ ( Note: I had to change the equation above ). The random variable $\Theta$ has values in $[0,1]$. My question: It is also stated, that the random variable $\Theta$ is uniformly distributed in $[0,1]$ and independent of $X$ and $Y$. Why is this the case? Can you point me to the used theorem? (In my textbook only the results but not the used theorems are mentioned...) Additional information: $X = \tfrac{1}{\sqrt{n}}\sum_{k=1, k\neq i}^n Y_k$ for standardized i.i.d random variables $Y_k$ and a certain $i\in\{1,2,\ldots,n\}$ $Y = \tfrac{1}{\sqrt{n}}Y_i$ Thus $X$ and $Y$ are independent. $f$ is the solution of a Stein equation for normal approximation Update 1: I just found out, that it is important to take the mean on both sides of the equation. I edited my question... Update 2: I found a solution for the question, why $\Theta$ is uniformly distributed (see my answer). It remains the question: Why is $\Theta$ independent of $X$ and $Y$?","['probability-theory', 'reference-request', 'random-variables', 'proof-explanation']"
1290374,Don't understand the Fundamental Theorem of Calculus,"If $f$ is continuous on $[a, b]$ and defining 
  $$
F(x) = \int_a^x \! f(t) \, dt
$$ 
  for $x \in [a, b]$, then $F'(x) = f(x)$ for $x \in (a,b)$. I don't understand what function the variable $t$ is for.  What is the definition of $f(t)$?  And is $F(x)$ a set?  Because it seems like $\int_a^x$ can have varying answers depending on what $x$ is.","['calculus', 'integration']"
1290386,What does d(something) mean?,"In a book I am reading on differential equations, the author writes the following: $$e^{\int P(x) \mathrm{d}x}\mathrm{d}y+P(x)e^{\int P(x) \mathrm{d}x}y\mathrm{d}x=Q(x)e^{\int P(x) \mathrm{d}x}\mathrm{d}x$$
  A shrewd observer now discerns that the left side is indeed
  $$\mathrm{d}\left(e^{\int P(x) dx}y\right)$$ What does this mean? This book was published around 1980s, so it may use different notation, but I am sure there is a meaning for this expression. What is it?",['ordinary-differential-equations']
1290402,Is there any explanation for the repetitions after decimal point on divisions like 24/7,"I was trying to divide 24 by 7 using a pen and a paper. After I had no more space on my checkerboard paper, I decided to put it on a calculator. The calculator returned 3.428571428571429 and I noticed it rounded up the last ( an 8 became 9) digit so the algorithm could stop. But in my accounts the number is 3.428571428571428571428571428571... So I calculated it on a high precision calculator, and I noticed the pattern 857142 will repeat indefinitely. I already knew this can happen when you do such divisions, now I always wondered myself and asked my teachers but never got an answer to why the numbers repeat themselves. I mean, I could have a whole sort of random numbers and that'd be ok, I just wonder why they have this pattern. Is there any article or study on that so I can read it?","['arithmetic', 'sequences-and-series']"
1290413,Converting a word problem into an equation? Trignometry and calculus [duplicate],"This question already has answers here : Intuitive explanation for formula of maximum length of a pipe moving around a corner? (3 answers) Closed 9 years ago . The problem is question 3 of what I am about to download into this question. I drew a diagram of what the problem actually is, my professor has verified it's correct. I don't want an exact answer to this question, just a way to convert question 3 into an equation so that I can use programming to solve. I have software I have created that can solve for zeros of functions and minimums of functions numerically. I am thinking that this is a problem of looking for some type of maximum because we want the biggest ladder that can fit through. Is this correct? It's probably a nooby question, but my trignometry is pretty rusty. I have a feeling it will be blatantly obvious","['calculus', 'trigonometry']"
1290435,Differential Equations in Milnor's Topology from the Differential Viewpoint,"On page $23$ Milnor states: Let $\varphi$ : $\mathbb{R}^n \rightarrow \mathbb{R}$ be a smooth function which satisfies $$\begin{cases} \varphi(x) > 0, & {\rm for}\,\|x\| < 1 \\ \varphi(x) = 0, &{\rm for}\,\|x\| \geq 1\end{cases}$$
  Given any fixed unit vector $c \in \mathbb{S} ^{n-1} $, consider the differential equations 
  $$\frac{dx_i}{dt} = c_{i} \cdot \varphi(x_1,x_2,\dots,x_n);  \hspace{10 mm} i = 1, \dots , n.$$
  For any $ \hat x \in \mathbb{R}^n$ these equations have a unique solution $x = x(t)$, defined for all real numbers which satisfies the initial condition 
  $$x(0)= \hat x.$$
  We will use the notation $x(t) = F_{t}( \hat x)$ for this solution. Then clearly 1) $F_{t}$ is defined for all $t$ and $ \hat x $ and depends smoothly on $t$ and $ \hat x $, 2) $F_{0}( \hat x ) =  \hat x $, 3) $F_{s+t}( \hat x ) = F_{s} \circ F_{t}( \hat x )$. 2) is quite clear, however I don't understand why 1) and 3) are valid. Could anybody explain that? Moreover on page $24$ Milnor states that clearly, with suitable choice of $c$ and $t$, the diffeomorphism $F_{t}$ will carry the origin to any desired point in the open unit ball. Is that really 'clear'? Wouldn't it be necessary to show that $x(t) \rightarrow c$ when $t \rightarrow \infty $? If it is, how? Thanks in advance. Source: http://www.maths.ed.ac.uk/~aar/papers/milnortop.pdf","['differential-geometry', 'ordinary-differential-equations']"
1290443,"Is 'Algebraic Number Theory' the study of the theory of algebraic numbers, or is it the study of the theory of numbers from an algebraic viewpoint?",Asked differently: Is Algebraic Number Theory the study of the theory of algebraic numbers? Or is it Number Theory from an algebraic viewpoint? Or is it both? I know I can just find a wiki article but I figure answers from the MSE community would be more intuitive and instructive.,"['soft-question', 'number-theory', 'abstract-algebra', 'self-learning', 'algebraic-number-theory']"
1290444,Are there more groups than rings?,"It seems pretty clear to me that both of these are at least uncountable (which I think I could prove with some work). It also seems that you should be able to make some diagonal argument about the two, but I'm not really sure how to make that. I've been trying to think of functions between groups and rings and ways to create groups out of rings and vice-versa, and I even think I've found some injective and/or surjective functions, but I didn't seem to be getting anywhere. Any suggestions would be great!","['abstract-algebra', 'cardinals', 'group-theory', 'ring-theory']"
1290458,Sub Sigma-Algebra and measurability,"If a random variable $X$ is measurable with respect to a sub $\sigma$-algebra (let's say $\beta_{1}$), such that $\beta_{1}$ $\subset$ $\beta$  , is $X$ -necessarily- measurable with respect to the main $\sigma$-algebra $\beta$ ? My intuition would be YES, since every point in the Borel $\sigma$-algebra would have an inverse image in the $\sigma$ algebra $\beta$. but the converse would not be true. 
Am i correct?","['probability-theory', 'real-analysis', 'measure-theory']"
