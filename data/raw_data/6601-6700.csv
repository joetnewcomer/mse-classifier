question_id,title,body,tags
49385,Local versus global implicit function,"Suppose the equation $f\left(x,y\right)=0$, with $x\in I_{1}$ and
$y\in I_{2}$, $I_{1}$ and $I_{2}$ being open intervals. Additionally,
consider that the conditions required to apply the Implicit Function
Theorem (IFT) are verified for all $\left(x_{0},y_{0}\right)\in I_{1}\times I_{2}$.
Hence, we can conclude that in a neighborhood containing the point
$\left(x_{0},y_{0}\right)$, the equation $f\left(x,y\right)=0$ defines
implicitly $y$ as a function of $x$. And my question is: Since the conditions of IFT hold for all $\left(x_{0},y_{0}\right)\in I_{1}\times I_{2}$,
is it true that the equation $f\left(x,y\right)=0$ defines implicitly
$y$ as a function of $x$ with the domain of this implicit function
being $I_{1}$?",['multivariable-calculus']
49396,injectivity of a group action,"The action of a group $G$ on $X$ is always ""injective"" in the following sense:
if $x\not = y$ then $\forall g\in G$, $gx\not = gy$ indeed if $gx=gy$ then $g^{-1}(gx)=(g^{-1})gx=x=g^{-1}(gy)=(g^{-1}g)y=y$. Is this why the second axiom of group action is set: $g(hx)=(gh)x$? and what is the importance of this ""injectivity""?","['general-topology', 'group-theory']"
49417,Diverging random walk,"I have a process $X_{n+1} = X_n\xi_n$ where $\xi_n\sim\mathcal N(1,1)$ and $\xi_n$ is independent of $X_n$. I need to prove that if $X_0\neq0$ then
$$
\mathsf P\{|X_n|>1\text{ for some }n\geq0\} = 1.
$$
From this I construct a random walk: $Y_n = \log|X_n|$ so
$$
Y_{n+1} = Y_n+\eta_n
$$
where $\eta_n = \log|\xi_n|$. I guess that from here I should apply the Law of Large Numbers - but I'm stacked with it. Could you help me? For now I should prove that $Y_n$ will eventually be positive a.s. starting from any point. On the other hand, $X_n$ is a martingale which maybe also useful for deriving the desired result. If it helps, one can take $\xi_n\sim\mathcal N(m,1)$ for some $m\geq1$.","['stochastic-processes', 'probability']"
49433,Nonhomogeneous Linear O.D.E,"I found this question and I cannot seem to answer it correctly and its kinda bothering. I am not seeing what I am not getting right with this particular problem. I took the same route as the OP and found the individual particular solutions of the RHS and added them together as a linear combination but to my surprise, get something totally different. Can someone look at this and let me know what I may be doing wrong. Original question is linked here: Solving Diff. Eq. $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~             {\textbf{Method of Undetermined Coefficients}}$ ${\bf{SOLUTION:}}$ $y(x)=y_{h}~+~y_{p}$ ${\text{Differential Equation:}}~~~~~~~~~~~~~~~~~$  $y^{(5)}+2y^{(3)}+y'=2x+\sin(x)+\cos(x)$. ${\text{Homogeneous Case:}}~~~~~~~~~~~~~~~~~~~~$  $y^{(5)}+2y^{(3)}+y'=0$. ${\text{Characteristic Polynomial:}}~~~~~~~~~$ $r^5+2r^3+r=0$. ${\text{Solved Roots of polynomial:}}~~~~~~$  $\bigg[\{r\rightarrow 0\},\; \{r\rightarrow -i\},\; \{r\rightarrow -i\},\; \{r\rightarrow i\},\; \{r\rightarrow i\}\bigg]$ $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ $${\text{General Form of the Homogeneous Solution}}$$ $$
y_{h}(x)=C_{1}e^{r_{1}x}+e^{ax}\Big(C_{2}\cos(bx)+C_{3}\sin(bx)+C_{4}x\cos(bx)+C_{5}x\sin(bx) \Big)
$$ $${\text{Homogeneous Solution to the Differential Equation}}$$
$$y_{h}(x)=C_{1}+C_{2}\cos(x)-C_{3}\sin(x)+C_{4}x\cos(x)-C_{5}\sin(x);~~\Big(~\because \sin(-x)=-\sin(x)~\Big).$$ Now we shall seek a particular solution. ${\text{Non-Homogeneous Case:}}~~~~~~~~~~~~~~~~$  $y^{(5)}+2y^{(3)}+y'=2x$ $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ $$ f(x)=2x $$ $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$Let, $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{array}{llll}
y_{p}(x)=Ax+b \\
y_{p}'(x)=A \\
y_{p}''(x)=0 \\
y_{p}^{(3)}(x)=0 \\
y_{p}^{(4)}(x)=0 \\
y_{p}^{(5)}(x)=0
\end{array}$ Substituting derivatives into differential equation: $(0)+2(0)+(A)=2x$. After equating the undetermined coefficient ${\underline{A}}$ we get: $
\begin{array}{l}
A=~0
\end{array}
$ Making our particular solution to become, $$ y_{p}(x)=0. $$ (2)$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~y^{(5)}+2y^{(3)}+y'=\sin(x)$
$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ $$ f(x)=\sin(x) $$ $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$Let, $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{array}{llll}
y_{p}(x)=A\sin(x)+B\cos(x) \\
y_{p}'(x)=A\cos(x)-B\sin(x) \\
y_{p}''(x)=-A\sin(x)-B\cos(x) \\
y_{p}^{(3)}(x)=-A\cos(x)+B\sin(x) \\
y_{p}^{(4)}(x)=A\sin(x)+B\cos(x) \\
y_{p}^{(5)}(x)=A\cos(x)-B\sin(x)
\end{array}$ Substituting derivatives into differential equation: $A\cos(x)-B\sin(x)+2\Big(-A\cos(x)+B\sin(x)\Big)+\Big(A\cos(x)-B\sin(x)\Big)=\sin(x)$. After equating the undetermined coefficients ${\underline{A}}$ and ${\underline{B}}$ we get: $
\begin{array}{l}
A=~0 \\
0\cdot B=1~~ ????~~ {\text{Huh}}
\end{array}
$ Making our particular solution to become, $$ y_{p}(x)=0~~?? $$ I guessed it will be the same situation for the $\cos(x)$ on the RHS when finding the particular solution, though I could be missing an important fact. Thanks.",['ordinary-differential-equations']
49442,Questions about right ideals,"The question is from the following problem: Let $R$ be a ring with a multiplicative identity. If $U$ is an additive subgroup of $R$ such that $ur\in U$ for all $u\in U$ and for all $r\in R$, then $U$ is said to be a right ideal of $R$. If $R$ has exactly two right ideals, which of the following must be true? I. $R$ is commutative. II. $R$ is a division ring. III. $R$ is infinite. I know the definition of every concept here. But I have no idea what is supposed to be tested here. Why is the ring $R$ which has exactly two right ideals special? What theorem does one need to solve the problem above? Edit. According to the answers, II must be true. For III, $R$ can be a finite field according to mt_ . What is the counterexample for I then?","['ring-theory', 'abstract-algebra']"
49448,method of moments of an uniform distribution,"Let  $ X_1, ... X_n $ a sample of independent random variables with uniform distribution $(0,$$
\theta 
$$
) $
Find a $ $$
\widehat\theta 
$$
 $ estimator for theta using the method of moments
Thanks I think using the indicatrix used in this type of problems that can not be derived, but not as used",['statistics']
49453,Several questions around the exponential law,"$\mathrm{DISCLAIMER~:~}$I am not interested in working with compactly generated spaces. This post is related to this one : Exponential Law for based spaces . I learned about the exponential law for topological spaces quite some time ago, and I thought I understood it well until I decided to reprove it today as I have been using it lately. What confuses me is that I 'seem' to have proven it with weaker conditions than those stated in the textbooks. To be precise, I think I have shown that there is a natural homeomorphism 
$$\mathrm{Map}(X\times Y,Z)\simeq\mathrm{Map}(X,\mathrm{Map}(Y,Z))$$
where $Z$ is any topological space, $X$ is Hausdorff and $Y$ locally compact $no$ $Hausdorff$ $condition$ $required\dots$ In all textbooks I 'm familiar with, none of which feature a proof of the above fact, the extra assumption is made that $Y$ be Hausdorff. The proof I gave is, I think, the one I learnt in Switzer's book (if I remember right) yet I see no need for Hausdorffness in $Y$. $\mathrm{QUESTION~1:~}$Is $Y$ Hausdorff really necessary? Also, the reference I am currently using, Algebraic Topology from the Homotopical Viewpoint [Aguilar, Gitler, Prieto, Springer Universitext], exercice $1.3.4$ asks to show that for $X,Y,Z$ topological spaces with $X$ and $Y$ locally compact Hausdorff spaces, composition $$\mathrm{Map}(X,Y)\times\mathrm{Map}(Y,Z)\rightarrow\mathrm{Map}(X,Z),(f,g)\mapsto g\circ f$$ is continuous. Yet I'm pretty sure all you need is for $Y$ to be locally compact$\dots$ $\mathrm{QUESTION~2:~}$ Are all these extra conditions necessary?","['general-topology', 'algebraic-topology']"
49457,Creating a matrix of rank r from r number of rank 1 matrices?,"I am told that all matrices of Rank $r$ can be formed out of the combinations of $r$ number of Rank 1 matrices. So that's the original matrix can be broken down into $r$ number of rank 1 matrices. But I don't understand and see how this is possible. Say for a matrix of this form:
$$
A=\begin{bmatrix}
1 & 3 & 2 & 6\\ 
3 & 0 & 1 & 4\\ 
2 & 1 & 1 & 4
\end{bmatrix}
$$
The $rank(A)= 3$. So if the claim was right, then I can form back the same matrix $A$ with the combination of 3 of Rank 1 matrices. I tried to ""emulate"" that idea but I just don't totally get how I could do it. Thanks for any help on this!","['matrices', 'linear-algebra']"
49461,Class field theory for function fields and a curious statement,"Let $X_0$ be a smooth curve over a finite field $\mathbb{F}_q$, and let $X$ be the base-change to the algebraic closure. I read that, according to class field theory in function fields, ""the image of $\pi_1(X, a)$ in the abelianized locally compact Weil group of $X_0$ is canonically isomorphic to the divisor class group $Pic^0$ of divisors of degree zero, which are rational over $\mathbb{F}_q$"" (Source: Kiehl and Weissauer's book on the Weil conjectures. Deligne makes this assertion in Weil II.) What is the justification for this? I thought ""class field theory for function fields"" would give an isomorphism of the abelianized absolute Galois group of the function field of $X_0$ and the group of idele classes of $X_0$. It's not obvious to me how this relates to the statement claimed.","['galois-theory', 'algebraic-geometry', 'class-field-theory', 'algebraic-number-theory']"
49467,"For which $n$ is $ \int \limits_0^{2\pi} \prod \limits_{k=1}^n \cos(k x)\,dx $ non-zero?","I can verify easily that for $n=1$ and $2$ it's $0$, $3$ and $4$ nonzero, $4$ and $5$ $0$, etc. but it seems like there must be something deeper here (or at least a trick).","['calculus', 'integration', 'real-analysis']"
49473,"Lagrange multipliers with inequality constraints: minimize $f$ on the region $0 \leq x,y \leq 1$","I do not have much experience with constrained optimization, but I am hoping that you can help. My current problem involves a more complex function, but the constraints are similar to the ones below. Just so that I can see how to apply Lagrange multipliers to my problem, I want to look at a simpler function. Suppose that I would like to minimize the function $$
f(x,y) = a + bx + cy
$$ subject to the constraints $$
0 \le x, y \le 1.
$$ If I understand the Lagrange multipliers technique correctly, I should create 4 constraint functions: $x = 0$ , $x = 1$ , $y = 0$ , and $y = 1$ . This would lead to minimizing the function $$
a + bx + cy - \lambda_1 x + \lambda_2 (x-1) - \lambda_3y + \lambda_4(y-1)
$$ with respect to $x,y,\lambda_1, \lambda_2,\lambda_3$ , and $\lambda_4$ . Does this look correct? If not, where did I go wrong? Your help is greatly appreciated.","['optimization', 'multivariable-calculus', 'calculus', 'lagrange-multiplier']"
49479,Ash's construction of the Lebesgue-Stieltjes Measure from a distribution function,"I'm reading this book Probability & Measure Theory by Ash. I think I've come across a part that is a little hand-wavy. We are trying to build a Lebesgue-Stieltjes measure from a distribution function $F$ ( in that the measure of interval $(a,b]$ is $F(b) - F(a)$ ). He starts by adding $+\infty$ and $-\infty$ to the real line so that we can work in compact space. He defines right-semiclosed as intervals of the form $(a, b]$ and $[-\infty, b]$ and $(-\infty, b]$ . He then constructs a field  by taking all finite unions of these right-semiclosed intervals. He defines a set function over this field defined in the intuitive way (the set function takes $(a,b]$ to $F(b) - F(a)$ ) , and he shows that this set function is countably additive. This is where I don't understand his argument. He seems to say, ignore these points $+\infty$ and $-\infty$ so that our field no longer uses the compact space, and our set function now becomes a proper measure over a real field. Then apply the Carathéodory Extension Theorem. I don't see how we can go from a compact space to a non-compact space without causing harm to the properties of our set function. I'm hoping that this construction method is widely used, and someone can explain where I am confused. This is Theorem 1.4.4 in Ash, 2nd Edition. The complete exposition can be found at http://books.google.com/books?id=TKLl3CGqsTEC&lpg=PP1&dq=probability%20and%20measure%20theory&pg=PA22#v=onepage&q&f=false from the bottom of page 22 to page 24.",['measure-theory']
49486,A Coincidence concerning 163 and the Monster?,"There is a McKay-Thompson series for the Monster group, namely $T_{1A}$, responsible for, $e^{\pi\sqrt{163}} \approx 640320^3 + 744$ Another one ($T_{2A}$) for, $e^{\pi/2\sqrt{232}} \approx 396^4 -104$ And a third one ($T_{3A}$) for, $e^{\pi/3\sqrt{267}} \approx 300^3 + 42$ It turns out, as proven by Conway, Norton, and Atkin, that this family of functions span a linear space of dimension 163 .  I found this so intriguing I had to write an article on it. See, "" The 163 Dimensions of the Moonshine Functions "" The Monster is the largest of the sporadic simple groups, and 163 is the largest d such that $Q(\sqrt{-d})$ has unique factorization. Do you think this is just a coincidence?","['sequences-and-series', 'group-theory', 'number-theory']"
49487,$\pi^{tame}(\mathbb{A}^1_k)$ is trivial,"Fixed an algebraically closed field of characteristic $p>0$, it is well known the result of the title: $\pi^{tame}(\mathbb{A}^1_k)\simeq 1$. Where the tame fundamental group, in this situation, classifies all the finite ètale coverings of $\mathbb{A}^1_k$ which are tamely ramified on the infinite point of $\mathbb{P}^1_k$. How is it proved? Following Hartshorne Chap IV Par. 2, and using the Riemann-Hurwitz formula , it can be proved that $\widehat{\pi}(\mathbb{P}^1_k)\simeq 1$, hence also $\pi^{tame}(\mathbb{P}^1_k)\simeq 1$. Where $\widehat{\pi}$ is the whole ètale fundamental group. I observed that it is crucial to look only at tamely ramified coverings on the infinite point, because there exist examples of finite ètale coverings of $\mathbb{A}^1_k$ which are wild ramified on the infinite point. I thought to approach the problem taking the completion $k[[x]]$ of the Zariski local ring of the infinite point, then cutting out the closed point from the neighborhood $Spec(k[[x]])$ of $\infty$ one would get $Spec(k((x^{-1},x]])$ (where $k((x^{-1},x]]$ is the fraction field of $k[[x]]$) which should be contained in $\mathbb{A}^1_k$ so covered by an ètale morphism. But I didn't get anything nor I'm sure that I didn't write rubbish. I also tried to control, in the Riemann-Hurwitz formula, the ramification index over $\infty$ with the degree of the covering map. In order to adjust the proof for $\mathbb{P}^1_k$ of Hartshorne. But again it didn't bring me anywhere. Thank you for your attention. Edit: I want to resume in the edit the progress I made thanks to the generous suggestions of Pete L. Clark. We are using the notations of corollary 2.4 of chapter IV of Hartshorne. We want to apply the Riemann-Hurwitz formula to a covering $f: X\rightarrow Y$, where $Y=\mathbb{P}^1_k$. Thanks to the fact that the restriction of the covering on $\mathbb{A}^1_k$ is ètale, and applying the same formula to the restricted covering, we can deduce that the degree of $f$ is $1$. Is this true? So the formula tells us, about the original covering, that $2g(X)=deg(R)$, where $R$ is the ramification divisor. Pete pointed out explicitely that the divisor is trivial everywhere except in one point, namely $\infty$. But I'm confused on how to use this fact for proving $deg(R)=0$.","['arithmetic-geometry', 'algebraic-geometry', 'abstract-algebra']"
49506,Reason for reversing the order when transpose and inverse of a group of matrices,"Whenever there is a transpose or inverse of a  group of matrices, I just reverse their order. For eg: $(ABC)^{-1} = C^{-1}B^{-1}A^{-1}$ and $(ABC)^{T} = C^{T}B^{T}A^{T}$ But usually, I am taking this reverse ""rule"" for granted without really knowing why I have to reverse their order whenever there is an inverse or transpose. What is the reason for reversing their order?","['matrices', 'linear-algebra']"
49510,Generating an independent set,"Suppose $f_1, f_2,...$ are a set of functions $\mathbb{R} \rightarrow \mathbb{R}$ so that each is the power of some non-constant function h. So $ f_ i=h^{n_i}$ for some natural number n. Is it possible for such a set to be linearly dependent? What additional conditions could ensure independence? I was thinking about this because I need to show that a set in linearly independent. And I was not convinced that having the functions be powered lhjlj would be sufficient.",['calculus']
49517,A hyperbola as a constant difference of distances,"I understand that a hyperbola can be defined as the locus of all points on a plane such that the absolute value of the difference between the distance to the foci is $2a$, the distance between the two vertices. In the simple case of a horizontal hyperbola centred on the origin, we have the following: $\frac{x^2}{a^2} - \frac{y^2}{b^2} = 1$ $c = \sqrt{a^2 + b^2} = a\varepsilon = a\sqrt{1 + \frac{b^2}{a^2}}$ The foci lie at $(\pm c, 0)$. Now, if I'm not wrong about that, then this should be pretty basic algebra, but I can't see how to get from the above to an equation given a point $(x,y)$ describing the difference in distances to the foci as being $2a$. While I actually do care about the final result, how to get there is more important. Why do I want to know this? Well, I'd like to attempt trilateration based off differences in distance rather than fixed radii.","['geometry', 'conic-sections', 'plane-curves', 'algebra-precalculus']"
49520,Express $\int^1_0x^2 e^{-x^2} dx$ in terms of $\int^1_0e^{-x^2} dx$,"(Apologies, this was initially incorrectly posted on mathoveflow) In the MIT 18.01 practice questions for Exam 4 problem 3b (link below), we are asked to express $\int^1_0x^2 e^{-x^2} dx$ in terms of $\int^1_0e^{-x^2} dx$ I understand that this should involve using integration by parts but the given solution doesn't show working and I'm not able to obtain the same answer regardless of how I set up the integration. Link to the practice exam: http://ocw.mit.edu/courses/mathematics/18-01-single-variable-calculus-fall-2006/exams/prexam4a.pdf","['calculus', 'integration']"
49524,What is the precise relationship between connections in differential geometry and Kähler differentials?,"I've been reading some differential geometry at my leisure, and I couldn't help but getting a very familiar feeling when I've read the definition of a connection: A derivation of $M$ (or in some notations, the derivation of the identity map $M\rightarrow M$) is defined as: a function, $D$, that takes tensor fields to tensor fields of the same type, such that $D(C \otimes A)=D(C) \otimes A + C\otimes D(A)$ for any two tensor fields $C$ and $D$, and such that $D(aA+bB)=aD(A)+bD(B)$ for any two tensor fields $A$ and $B$ and (real) scalars $a$ and $b$. A connection is defined as a function $\nabla$ that takes a vector field $X$ to a derivation $\nabla _X$, such that $\nabla$ satisfies: If $f$ is a function on $M$ then $\nabla_X(f)=Xf$, and $\nabla$ is linear (for the module of vector fields over the ring of $C^{\infty}$-functions), and such that $\nabla_X$ commutes with contraction. This was the first time I saw the definition of a connection formulated in this way, and it is very reminiscent of themes in Kähler differentials. I wonder if there is a rigorous relationship between the two notions.","['algebraic-geometry', 'differential-geometry']"
49531,holomorphic functions and fixed points,"I'm studying for a complex analysis exam, and I'm stuck on this problem from an old exam: Let $g$ be a holomorphic function on $|z|<R,R>1$, with $|g(z)|\leq 1$ for all $|z|\leq 1$. (a) Show that for all $t\in C$ with $|t|<1$, the equation $$z=tg(z)$$ has a unique solution $z=s(t)$ in the disc $|z|<1$. (b) Show that $t\mapsto s(t)$ is a holomorphic function on the disc $|t|<1$. (Hint: find an integral formula for $s$.)",['complex-analysis']
49543,maximum estimator method more known as MLE of a uniform distribution [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let  $ X_1, ... X_n $ a sample of independent random variables with uniform distribution $(0,$$
\theta 
$$
) $
Find a $ $$
\widehat\theta 
$$
 $ estimator for theta using the maximun estimator method more known as MLE",['statistics']
49555,Proving that the set of natural numbers is well-ordered,"Consider the following theorem: ""Every non-empty set of positive integers has a minimum element"". The proof I usually see is one that uses contradiction, and does not seem like the easiest possible proof. I think there is an easier proof, and I wonder why I never see it. Does it contain an invalid assumption? The proof goes as follows: First, prove by induction that the theorem is true for finite sets. Base case: It's true for a set of size 1, trivially. Induction step: Consider a finite set $S$ of size $n+1$. Let $s$ be a member of $S$. By I.H., $|S-s|$ has a minimum $s'$. If $s\lt s'$, then $s$ is the minimum of $S$. Otherwise, it is $s'$. Second, let $T$ be a any non-empty set of positive integers ($T$ could be infinite). Let $t$ be an element of $T$. Consider the set $T\cap [0,t]$. The set is clearly finite, so it has a minimum element $min$. Next, we show that $min$ is also a minimum element of $T$. Let $x$ be an element of $T$. If $t\lt x$, then $min\leq x$. Otherwise $x\in T\cap [0,t]$, so $min\leq x$. Is there a problem with this proof? I think when people prove that N is well-ordered, they do it in set theory books at a point where very little has been proven, so they can't assume much. Am I assuming too much in this proof? If not, why don't people ever use this very simple proof?",['elementary-set-theory']
49558,Status of single aperiodic tile,"What is known about the existence of a single tile, that tiles R^n only aperiodically? Has such a tile been found/proven to exist/not exist for any R^n?","['general-topology', 'tiling']"
49559,Graph of a function homeomorphic to a space implies continuity of the map?,"If $X,Y$ are topological spaces and $f: X \rightarrow Y$ is a continuous map then it can be shown that the graph of $f$, $G_{f}$, is homeomorphic to $X$. But is the converse true? That is: if $G_{f} \cong X$ via the map $(x,f(x)) \mapsto x$ is $f$ necessarily a continuous map? I suspect no but haven't had luck with a counterexample. Is this true/false?","['general-topology', 'continuity']"
49569,Find $\sin \theta$ and $\cos \theta$ given $\tan 2\theta$,"Can you guys help with verifying my work for this problem. My answers don't match the given answers. Given $\tan 2\theta = -\dfrac{-24}{7}$, where $\theta$ is an acute angle, find $\sin \theta$ and $\cos \theta$ I used the identity, $\tan 2\theta = \dfrac{2\tan \theta}{1 - tan^2 \theta}$ to try and get an equation in $\tan \theta$. $$
\begin{align}
-\dfrac{24}{7} &= \dfrac{2\tan \theta}{1 - \tan^2 \theta} \\
-24 + 24\tan^2 \theta &= 14 \tan \theta \\
24tan^2 \theta - 14\tan \theta - 24 &= 0 \\
12tan^2 \theta - 7\tan \theta - 12 &= 0 \\
\end{align}
$$ Solving this quadratic I got,
$$ \tan \theta = \dfrac{3}{2} \text{ or } \tan \theta = -\dfrac{3}{4}$$ $$\therefore \sin \theta = \pm \dfrac{3}{\sqrt{13}} \text{ and } \cos \theta = \pm \dfrac{2}{\sqrt{13}}$$ Or, $$\therefore \sin \theta = \pm \dfrac{3}{5} \text{ and } \cos \theta = \mp \dfrac{4}{5}$$ The given answer is, $$\sin \theta = \dfrac{4}{5} \text{ and } \cos \theta = \dfrac{3}{5}$$ I thought I needed to discard the negative solution assuming $\theta$ is acute. But they haven't indicated a quadrant. Do I assume the quadrant is I only? What am i missing? Thanks again for your help.","['trigonometry', 'algebra-precalculus']"
49570,Arbitrary product of simply connected space is simply connected?,Let $\lbrace X_\alpha\rbrace_{\alpha\in\Lambda}$ be a set of simply connected spaces. Is it true that $\pi_1(\prod\limits_{\alpha\in\Lambda} X_\alpha)=0$? cf) I know that $\pi_1(X\times Y)=\pi_1(X)\times\pi_1(Y)$.,['general-topology']
49580,"A construction in the proof of ""any local ring is dominated by a DVR""","Let $O$ be a noetherian local domain with maximal ideal $m$. I want to prove: for a suitable choice of generators $x_1,\dots,x_n$ of $m$, the ideal $(x_1)$ in $O'=O[x_2/x_1,\dots,x_n/x_1]$ is not equal to the unit ideal. This statement originates from Ex.4.11, Chapter 2 of Hartshorne.","['commutative-algebra', 'algebraic-geometry', 'valuation-theory']"
49582,Are there numerical algorithms for Roman numerals?,"In positional number systems there are algorithms for performing certain operations, like long division, to name one of the simplest. This works for positional systems, whatever base. I realize in number theory there are very advanced algorithms, typically for working with Very Long Numbers. ( disclaimer: except for a Fourier transform I don't know any of them, I'm not a mathematician. ) I was wondering how the Romans could do anything numerical with their odd Roman numerals. You can't divide MMDCCI by LXXIII using long division. So, question: are there numerical methods for Roman numerals, and if not, how did the Romans divide MMDCCI by LXXIII?","['math-history', 'algebra-precalculus', 'numerical-methods']"
49583,Is there a Stokes theorem for covariant derivatives?,"A $V$-valued differential $n$-form $\omega$ on a manifold $M$ is a section of the bundle $\Lambda^n (T^*M) \otimes V$. (That is, the restriction $\omega_p$ to any tangent space $T_p M$ for $p \in M$ is a completely antisymmetric map $\omega_p : T_p M \times T_p M \times \cdots \times T_p M \to V$.) $V$ is a vector space here. One can define a flat covariant derivative $\mathrm{d}\colon \Lambda^n (T^*M) \to \Lambda^{n+1} (T^*M)$ which is just the exterior derivative. It fulfills Stokes' theorem. Assume now an algebra structure on $V$, and a representation $\rho$ of $V$ on a vector space $W$.
For a chosen $V$-valued differential 1-form $\omega$, there is also a covariant derivative (like a principal connection) that acts on all $W$-valued differential forms $\phi$ by the formula $\mathrm{d}_\omega \phi := \mathrm{d} \phi + \omega \wedge_\rho \phi$. The product $\wedge_\rho$ is the composition of $\wedge$, which multiplies a $V$-valued $n$-form and a $W$-valued $m$-form to a $V \otimes W$-valued $(n+m)$-form, and $\rho$. Is there a generalisation for Stokes' theorem for $\mathrm{d}_\omega$? Maybe something like $\int_M \mathrm{d}_\omega \phi = \int_{\partial M}  \phi$ up to terms proportional to the curvature of $\mathrm{d}_\omega$?","['differential-forms', 'curvature', 'differential-geometry']"
49600,Logarithm rules,What can I do with these expression: $2^{\log _{\frac{4}{3}}n}$ and   $2^{\log _{4}n}$ if I don't want to have $n$ in the exponent? I tried nothing because I didn't have any good ideas. Thanks.,"['logarithms', 'algebra-precalculus', 'functions']"
49609,"The ""□□ □□"" polyomino","The polyomino '□□ □□' (two blocks of two squares with a gap) does not tile any rectangle, how do I prove/disprove that it tiles the plane?","['geometry', 'tiling']"
49612,An exact sequence in Arakelov theory(A proposition in Algebraic Number Theory by Neukirch),"The following proposition is from Algebraic Number Theory by Neukirch (Proposition 1.11, Chapter 3, p.191), but I doubt that exat sequence. Let $K$ be a number field, $O$ be the ring of integers. And $\mathfrak{p}\mid \infty$ means $\mathfrak{p}$ is a infinite place. Let $\Gamma=\lambda(O^{\star})$ denote the complete lattice of units in trace-zero space, $$H=\{(v_{\mathfrak{p}}) \in \prod_{\mathfrak{p}|\infty} \mathbb{R} \mid \sum_{\mathfrak{p}|\infty}{ v_{\mathfrak{p}}}=0 \}.$$ There is an exact sequence $$ 0\rightarrow H/ {\Gamma} \rightarrow CH^{1}(\bar{O})^{0} \rightarrow CH^{1}(O) \rightarrow 0\quad.$$ Let $Div(\bar{O})$ be a replete divisor (Arakelov divisor), $CH^{1}(\bar{O})=Div(\bar{O})/P(\bar{O})$ be a replete divisor class group. Let $CH^{1}(\bar{O})^{0}$ be the kernel of $\deg: CH^{1}(\bar{O}) \rightarrow \mathbb{R}$, which is $$\deg(\sum_{\mathfrak{p}}{v_{\mathfrak{p}} \mathfrak{p} })=\log(\prod_{\mathfrak{p}}\mathfrak{N}(\mathfrak{p})^{v_{\mathfrak{p}}}).$$ My question comes from the exactness of $$0\rightarrow H\stackrel{\alpha}{\longrightarrow} Div(\bar{O})^{0} \stackrel{\beta}{\longrightarrow} Div(O)\rightarrow 0,$$ which is crucial in the proof. $\beta$ is the projection map, mapping all the finite place part of $Div(\bar{O})^{0}$ to $Div(O)$. It is surjective. $\alpha$ is defined to be 
$$\quad \alpha((v_{\mathfrak{p}}))=\sum_{v_{\mathfrak{p}}\mid\infty}{\frac{v_{\mathfrak{p}}}{f_{\mathfrak{p}}} \mathfrak{p}}\quad$$
(where $f_{\mathfrak{p}}=[K_{\mathfrak{p}}: \mathbb{R}]$, $K_{\mathfrak{p}}$ is the completion of $K$ with respect to place $\mathfrak{p}$, actually one can show: for $\mathfrak{p}\mid \infty$, $f_{\mathfrak{p}}=1$ if $\mathfrak{p}$ is a real embedding, and $f_{\mathfrak{p}}=2$ if $ \mathfrak{p}$ is a complex embedding.) The point is that $Ker(\beta)$ is larger than $Im(\alpha)$. Say, one can pick $\mathfrak{p}_{1}$ as a finite place with $v_{\mathfrak{p}_{1}}=1$, and some infinite place $\mathfrak{p}_{2}$, such that $v_{\mathfrak{p}_{2}}=\log(p^{f_{\mathfrak{p}_{1}}})$. And  all the other $v_{\mathfrak{p}}=0$. This is  in the $Ker(\beta)$, but not in $Im(\alpha)$!","['algebraic-number-theory', 'number-theory']"
49617,Gradient nonzero extensions of a vector field on the circle,"Let $\mathbf{v}=(a,b)$ be a smooth vector field on the unit circle
$\mathbb{S}^{1}$ such that $a^{2}+b^{2}\neq0$ everywhere in $\mathbb{S}^{1}$
with degree $\deg\mathbf{v}=0$. Suppose also that $\int\limits_{\mathbb{S}
^{1}}a\mathtt{dx}+b\mathtt{dy}=0$. My question is whether the field
$\mathbf{v}$ may be extended to a nonzero gradient vector field $\overline
{\mathbf{v}}=(A,B)$ on the unit disk $\mathbb{D}$, i.e. whether there exist
smooth functions $A=A(x,y)$, $B=B(x,y)$, $\ (x,y)\in\mathbb{D}$, such that
$A|_{\mathbb{S}^{1}}=a$, $B|_{\mathbb{S}^{1}}=b$,  $A^{2}+B^{2}\neq0$
everywhere in $\mathbb{D}$ and finally $\frac{\partial B}{\partial x}
=\frac{\partial A}{\partial y}$ in $\mathbb{D}$. Let me make some remarks. The condition $\deg\mathbf{v}=0$ is necessary, for the field $\mathbf{v}$
to have an everywhere nonzero extension in the unit disk. The degree is
defined as usually as the degree of  $\mathbf{v/}\left\Vert \mathbf{v}
\right\Vert $ considered as a map $\mathbb{S}^{1}\rightarrow\mathbb{S}^{1}$. The condition $\int\limits_{\mathbb{S}^{1}}a\mathtt{dx}+b\mathtt{dy}=0$ is
also necessary for $\mathbf{v}$ to have a gradient extension $\overline
{\mathbf{v}}$, as following by Green's Theorem. I suppose that this proposition should have some elegant proof (if true :))
and may be probably something well-known, but I have only few examples, not a
proof. So, any references are welcome as well. Note also that this is somehow
a ""global"" proposition, not a ""local"" one. Thanks in advance.","['differential-topology', 'real-analysis']"
49620,Going from $\Lambda$ to a prime count,"A 1997 paper of Étienne Fouvry and Henryk Iwaniec, Gaussian primes , concerns the prevalence of primes that are of the form $n^2+p^2$ for prime $p$.  The asymptotic result is $$\sum_{n^2+p^2\le x}\Lambda(p)\Lambda(n^2+p^2)=kx+O(x(\log x)^{-A})$$ with $A>0$ arbitrary and
$$k=2\prod_{p>2}\left(1-\frac{\chi(p)}{(p-1)(p-\chi(p))}\right)\approx2.1564103447695$$
where $\chi(n)=(-1)^{(p-1)/2}$ is the nontrivial character mod 4.  The big-O constant is uniform, depending only on the choice of $A$. I would like to use this to find an asymptotic formula for $f(x):=|\mathcal{P}\cap\{n^2+p^2\le x\}|$.  It looks like $$f(x)=2k\frac{x}{(\log x)^2}(1+o(1))$$ but I'm not quite sure of my derivation, nor even of how to interpret the original result (are duplicate representations double-counted or not?).  Can someone confirm or deny my calculation? Bonus question: were Fouvry & Iwaniec the first to show that there are infinitely many of these primes?  They cite Rieger, Coleman, Duke, and Pomykala as related results but none had both prime restrictions.","['prime-numbers', 'analytic-number-theory', 'number-theory']"
49627,Weak version of Fortune's conjecture,"Let $p\#=2\cdot3\cdot5\cdots p$ denote the primorial and $N(x)$ the smallest prime greater than or equal to $x$.  Then Fortune's conjecture is that $N(p\#+2)-p\#$ is prime for all $p$. (Heuristic: to be composite the difference must be greater than $p^2$ which is large compared to the average gap of size $p$.)  This seems out of reach at the moment. A somewhat weaker version asks if the difference is composite only finitely often.  This, too, seems unassailable at present. A much weaker version asks if $N(p\#+2)-p\#$ is prime infinitely often.  Can this be proved with current technology? Edit: to clarify, my question is about the third problem I mention: can it be solved, has it been solved, and if so what is the solution?  It's 'obvious' that the second and third conjectures are correct (and the first one seems highly likely) but I'm interested in what's known.","['prime-numbers', 'analytic-number-theory', 'open-problem', 'number-theory']"
49628,Hardy Ramanujan Asymptotic Formula for the Partition Number,"I am needing to use the asymptotic formula for the partition number, $p(n)$ (see here for details about partitions ). The asymptotic formula always seems to be written as, $$ p(n) \sim \frac{1}{4n\sqrt{3}}e^{\pi \sqrt{\frac{2n}{3}}}, $$ however I need to know the order of the omitted terms, (i.e. I need whatever the little-o of this expression is). Does anybody know what this is, and a reference for it? I haven't been able to find it online, and don't have access to a copy of Andrews 'Theory of Integer Partitions'. Thank you.","['asymptotics', 'integer-partitions', 'number-theory']"
49639,What technique would be suitable to solve this: $\int \sin ^{5}\left( x^{2}\right) \left( x\cos \left(x^{2}\right)\right)\mathrm{d}x$,I think integration by parts might work but I'm now sure. Thanks very much.,"['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
49641,Integration of forms and integration on a measure space,"In Terence Tao's PCM article: DIFFERENTIAL FORMS AND INTEGRATION , it is pointed out that there are three concepts of integration which appear in the subject (single-variable calculus): the indefinite integral $\int f$ (also known as the anti-derivative), the unsigned definite integral $\int_{[a,b]} f(x) dx$ (which one would use to find area under a curve, or the mass of a one-dimensional object of varying density), and the signed definite integral $\int _a^b f(x) dx$ (which one would use for instance to compute the work required to move a particle from a to b). When one moves from single-variable calculus to several-variable calculus: The indefinite integral generalises to the notion of a solution to a differential equation , or of an integral of a connection, vector field, or bundle . The unsigned definite integral generalises to the Lebesgue integral , or more generally to integration on a measure space . Finally, the signed definite integral generalises to the integration of forms . While learning from this article, I tried to find the counterpart of the later two kinds of integration(as the title indicates) in the several-variable calculus I learned before. Now I am considering the following four kinds of integration: Line integral of a scalar field Line integral of a vector field Surface integrals of scalar fields Surface integrals of vector fields Here are my questions : What kinds of integration are these four ones according to the categories in the article? (I just guess generally the scalar one is the integration on a measure space and the vector one is the integration of forms.) How do they belong to the category respectively? (For example, if it is the integration on a measure space, then what exactly is the underlying measure space?)","['multivariable-calculus', 'integration', 'differential-geometry', 'measure-theory', 'real-analysis']"
49643,You see a route 14 bus on the moon. What is the most likely number of bus routes on the moon?,"This question was asked on a forum and while many argued that the answer is 14 (since the probability of you seeing bus 14 is maximum in this case), I argued against it that they were working backwards.
My claim is that this question is invalid as there is no method to determine the probability of number of bus routes. I'm looking for clarification as to the right answer (with proof obviously)","['statistics', 'probability', 'parameter-estimation']"
49649,Which steps I have to do to get this equation?,I don't know what to do to derive the right side from the left side: $$\frac{B}{1+r} = B - \frac{r B}{1+r}.$$,['algebra-precalculus']
49661,Connectedness problem: sequences of points with distances at most $\varepsilon$,"Here's problem 6.1.D (a), page $359$ from Engelking's book, stuck with it for a while. Verify that if a space $X$ with the topology induced by a metric $p$ is connected, then for every pair $x,y$ of points of $X$ and any $\varepsilon >0$ there exists a finite sequence $x_{1},x_{2},..,x_{k}$ of points of $X$ such that $x_{1}=x$, $x_{k}=y$ and $p(x_{i},x_{i+1})<\varepsilon$ for $i=1,2,..,k-1$.","['general-topology', 'connectedness', 'metric-spaces']"
49665,How to find an integral kernel for poisson's equation in the upper half plane,"In our lecture we have shown that $\forall f \in L^2(\mathbb{R}^n_+) $ there is a unique $ u $ in the Sobolev space $ H^2(\mathbb{R}^n_+) $ satisfying $ -\Delta u = f. $ Now in our exercise sheet we are asked to show that there is an integral kernel $ \Phi $
such that $ u(x) = \int_{\mathbb{R}^n} \ \Phi (x-y) \ f(y) \ dy $. Wikipedia tells me that there is an integral kernel and that it is of the form 
\begin{equation*} \Phi(x) \ = \ const. \ \cdot \ \frac{x_n}{({\sum_{i = 1}^{n} x_i^2})^{n/2}} \end{equation*} So now to my question: How can you show that this is indeed an integral kernel for poisson's equation? In particular, how can you differentiate under the integral sign and ""take the Laplacian"" of $ \Phi $ at $ x - y = 0 $ ? 
Moreover, do you know a priori that there has to be such an integral kernel? Thanks a lot in advance, I would really appreciate your help! Best regards Phil","['functional-analysis', 'partial-differential-equations']"
49667,Base of clopen and $T_{0}$ implies $X$ is Tychonoff,"Let $X$ be a topological space and assume $X$ has a base $\mathcal{B}$ of clopen sets. Show $X$ is completely regular and a $T_{0}$ space. My try: First it is not hard to show that if $B \subset X$ then $\chi_{B}$, the characteristic function of $B$ is cts iff $B$ is clopen. So let $F \subset X$ be a closed set and let $x \in X \setminus F$. Then since $X \setminus $ is open we can find $B \in \mathcal{B}$ such that $x \in B \subseteq X \setminus F$. Now define $\phi: X \rightarrow [0,1]$ by $\phi(x)= \chi_{B}(x)$ then since $B$ is clopen $\phi$ is a continuous map, $\phi(F)=\{0\}$ and $\phi(x)=1$, therefore $X$ is completely regular. EDIT: Sorry, Brian Scott is right, I'm trying to prove the following, if $X$ is $T_{0}$ and has a base of clopen sets then $X$ is completely regular and $T_{1}$. So I think the above proof is correct (i.e showing it is completely regular), how to show it is $T_{1}$?",['general-topology']
49675,"Weird quotient of $\langle\mathbb Q,+\rangle$?","after looking at this question I came to think on one particular case. I'm wondering if maybe I've missed something on the way. If anyone could give it a look that would be great: We start by considering a subset $H=\lbrace\frac{p}{q}\in\mathbb Q| p\text{ is even and }q\text{ is odd}\rbrace$ . Naturally $0=\frac{0}{1}\in\mathbb Q$ , and for any $\frac{p}{q}\in H$ : $\frac{-p}{q}\in H$ . Also, if $\frac{p_1}{q_1},\frac{p_2}{q_2}\in H$ then $p_1q_2+p_2q_1$ is even, and $q_1q_2$ is odd, so $H$ is indeed a sub-group of $\mathbb Q$ (sorry for going into too much detail, as I said- I'm trying to make sure I didn't miss anything) So- what's $\mathbb{Q}/H$ ? Let's see what we've got:
Let $r_1,r_2\in\mathbb{Q}$ be arbitrary. Write them down as $r_1=2^{t_1}\frac{p_1}{q_1}$ and $r_2=2^{t_2}\frac{p_2}{q_2}$ with $p_1,p_2,q_1,q_2$ all odd integers, and $t_1,t_2\in\mathbb{Z}$ We know that $$r_1=r_2\mod H\iff r_1-r_2\in H\iff \frac{2^{t_1}p_1q_2-2^{t_2}p_2q_1}{q_1q_2}\in H$$ WLOG assum $t_1\geq t_2$ then we have $$2^{t_2}\frac{2^{t_1-t_2}p_1q_2-p_2q_1}{q_1q_1}\in H$$ From here on I notice two cases: Case 1 : If $t_2>0$ than this is always true- meaning that any two elements of $\mathbb{Q}$ with a positive diadic valuation are congruent under $H$ (since $t_1\geq t_2>0$ ). EDIT - Not very suprising, as any element of positive diadic valuation is $0_{\mathbb Q/H}$ , by definition (Thanks to Brian for mentioning this). Case 2 : (and this is what's got me baffled) If $t_2\leq 0$ we need $2^{t_1-t_2}p_1q_2-p_2q_1$ to be an even integer, such that $2^{-t_2}$ divides it, for this number to be in $H$ . Since $p_2q_1$ is odd, it must hold that $2^{t_1-t_2}=1$ so $t_1=t_2$ . Also we have that $2^{-t_2}|p_1q_2-p_2q_1$ . Basically this is where I got stuck- what's the deal with Case 2 ? What kind of a group is this? Am I completely off track somewhere? or is this maybe a known result? If anyone can point me at some direction here I would be very thankful.","['group-theory', 'abstract-algebra', 'p-adic-number-theory']"
49676,How fast does the sequence $y_t$ defined by $y_{t+1}=y_t(1-y_t)$ decay to zero?,"The question is in the title; I'm looking for the exact decay rate. Naturally, assume the starting point $y_0$ belongs to $(0,1)$. This is motivated by one of the answers to a previous question of mine .",['sequences-and-series']
49699,About the notion of limsup and liminf,"Recently, I'm reading something about viscosity solution of a PDE, and the notions of limsup and liminf haunt me all the time. The following are some examples. The upper semi-continuous envelope of a function $z: \mathbb{R}^n \rightarrow \mathbb{R}$ is defined as
$$
z^*(x) := \limsup_{x' \rightarrow x}\ z(x')
$$ Suppose for every partition $P$ of the interval $[0,T]$, we are given a (continuous) function $V^P: [0,T]\times \mathbb{R}^2 \rightarrow \mathbb{R}$. Then, we define
$$
\bar{V}(t,x,y) := \limsup_{mesh(P)\rightarrow 0, (t',x',y')\rightarrow (t,x,y)} V^P(t',x',y')
$$
where $mesh(P)$ is the mesh size of the partition. Suppose we have a sequence of functions $f_n: \mathbb{R}^n \rightarrow \mathbb{R}$, then we can define 
$$
g(x) := \limsup_{n\rightarrow \infty}\ \sup_{x'\in\mathbb{R}^n} f_n(x')
$$ I have formally learned limsup and liminf only in terms of sequences, so I wonder How to interpret the above definitions of functions in precise mathematical language? ($\epsilon$-$\delta$ description will be great.) If there are two limiting processes like in the second example, is there any kind of order of computation? How to generalize the notions of limsup and liminf in more general settings?","['real-analysis', 'limsup-and-liminf']"
49707,$\sigma$ - compact and locally compact metric space,"Is the following sentence is true? Each complete, separable and $\sigma$ - compact metric space is locally compact. I suppose (but I'm not sure) it is a truth, becouse it was evidently used in the paper of  Łukasz Stettner ""Remarks on Ergodic Conditions of Markov Processes on Polish Spaces""(108 p.) which I am studyng now. full text of this work - http://www-bcf.usc.edu/~lototsky/InfDimErg/Stettner-InfDimMarkProc.pdf","['general-topology', 'metric-spaces']"
49710,Misunderstanding in Spivak's Proof of the Intermediate Value Theorem,"I am a student who has taken the basic calculus courses but I am working through Calculus (the fourth edition) by Spivak in my spare time in order to both review the material and to gain a more rigorous understanding of the concepts. I am currently in Chapter 8 where he supplies a proof of the basis of the Intermediate Value Theorem, Theorem 7-1 (pp. 135-136 of the fourth edition). It seems mostly straightforward but I think there is some nuance of it that I don't grasp. I am including in this post the statement Theorem 6-3 since he references it in the proof of Theorem 7-1 as well as part of Theorem 7-1 itself. Theorem 6-3 Suppose $f$ is continuous at $a$, and $f(a) > 0$. Then $f(x) > 0$ for all $x$ in some interval containing $a$; more precisely, there is a number $\delta > 0$ such that $f(x) > 0$ for all $x$ satisfying $|x-a| < \delta$. Similarly, if $f(a) < 0$, then there is a number $\delta > 0$ such that $f(x) < 0$ for all $x$ satisfying $|x-a| < \delta$. Problem 6-16 is also referenced. However,it is the same thing as Theorem 6-3 for one-sided limits. The following proof is the Theorem 7-1 up through the paragraph which I don't fully understand. Theorem 7-1: If $f$ is continuous on $[a,b]$ and $f(a) < 0 < f(b)$, then there is some number $z$ in $[a,b]$ such that $f(x) = 0$. Proof: Define the set $A$ as follows:

$$A = \{x : a \le x\le b, \mbox{ and } f \mbox{ is negative on the interval } [a,x] \}.$$

     Clearly $A \ne \emptyset$, since $a$ is in $A$; in fact, there is some $\delta > 0$ such that $A$ contains all points $x$ satisfying $a \le x < a + \delta$; this follows from Problem 6-16, since $f$ is continuous on $[a,b]$ and $f(a)<0$. Similarly, $b$ is an upper bound for $A$ and, in fact, there is a $\delta > 0$ such that all points $x$ satisfying $b-\delta < x \le b$ are upper bounds for $A$; this also follows from Problem 6-16, since $f(b) > 0$. From these remarks it follows that $A$ has a least upper bound $\alpha$ and that $a < \alpha < b$. We now wish to show that $f(\alpha) = 0$, by eliminating the possibilities $f(\alpha) < 0$ and $f(\alpha) > 0$. Suppose first that $f(\alpha) < 0$. By Theorem 6-3, there is a $\delta > 0$ such that $f(x) < 0$ for $\alpha - \delta < x < \alpha + \delta$. Now there is some number $x_0$ in $A$ which satisfies $\alpha - \delta < x_0 < \alpha$ (because otherwise $\alpha$ would not be the least upper bound of $A$). This means that $f$ is negative on the whole interval $[a,x_0]$. But if $x_1$ is a number between $\alpha$ and $\alpha+\delta$, then $f$ is also negative on the whole interval $[x_0,x_1]$. Therefore $f$ is negative on the interval $[a,x_1]$, so $x_1$ is in $A$. But this contradicts the fact that $\alpha$ is an upper bound for $A$; our original assumption that $f(\alpha) < 0$ must be false. The point I don't understand is in the final paragraph of the excerpt. Why does Spivak split the interval $[a,b]$ up into the subintervals $\lbrack a,x_0 \rbrack$ and $[x_0,x_1]$? Isn't it true that, because $\alpha$ is a least upper bound of $A$ and $f$ is continuous on $[a,b]$, it must be true that if $a \le x < \alpha$ then $f(x)<0$? I understand the need to pick out the $x_1$ but not the $x_0$. Especially perplexing is the statement ""there is some number $x_0$ in $A$ which satisfies $\alpha - \delta < x_0 < \alpha$ (because otherwise $\alpha$ would not be the least upper bound of $A$."" Wouldn't it be true that if there were some $x_0$ such that $a \le x_0 < \alpha$ and $f(x_0) \ge 0$ that $x_0$ would be an upper bound for $A$, contradicting that $\alpha$ is the least upper bound of $A$? Thanks for any help.","['calculus', 'real-analysis']"
49713,Proof: BEST-IN-GREEDY-Algorithm for Matroids maximizes all Bottleneck-Functions over Bases,"Let $(E,\mathcal{F})$ be a Matroid. Given is a Bottle-Neck -Function $$b(F)=\min\{b(e)|e\in F\}$$ I want to prove that the Best-In-Greedy -Algorithm maximizes every Bottle-Neck -Function over the Bases. The Best-In-Greedy -Algorithm works like this: Given a weight function $c:E\to\mathbb{R}_+$ sort $E=\{e_1,\dots ,e_n\}$ such that $c(e_1)\geq\dots\geq c(e_n)$. Define $F:=\emptyset$. Iterate above (the sorted) $E$ in descending order and add $e_i$ to the set $F$ if $(F\cup\{e_i\})\in\mathcal{F}$. If $(E, \mathcal{F})$ was only an Independent System , the algorithm would return a independent set $F\in\mathcal{F}$. Since $(E,\mathcal{F})$ is a Matroid it returns a Basis $B\in\mathcal{F}$. So how does the Algorithm maximizes the given Bottle-Neck -function? Let $I:=\{1,\dots ,n\}$ where $n=|E|$. Assuming $e_i\neq e_j$ for all $i,j\in I$ with $i\neq j$. Hence there is only one possible way of sorting $E$. The Algorithm adds elements to $F$ (which is empty at first) until $F$ is a Basis. Casting $b(F)$ returns the element with minimum weight in $F$. Since there is only one way of sorting in this case, the algorithm produces the same Basis $B$ everytime it runs. Hence $b(B)=c(e_1)$ is always maximal. Assuming, that there are $e_i = e_j$ for $i\neq j$ and $i,j\in I$ there are multiple possibilitys to sort E. (If $e_m = e_n$ both sortings
$$\dots \geq c(e_m)\geq c(e_n)\geq\dots$$
and
$$\dots \geq c(e_n)\geq c(e_m)\geq\dots$$
are valid. So it is possible, for the algorithm to produce (or better: detect) different Bases. For each detected Basis it is true that $b(B)=c(e_1)$ is always maximal. Are my conclusions correct? Every suggestion is appreciated. Thank you!","['matroids', 'discrete-mathematics', 'algorithms', 'combinatorics']"
49714,"Assuming $G=(V(G),E(G))$ is a graph what does $\Delta(G)$ mean?","Perhaps someone is kind enough to explain to me the meaning of this mathematical symbol, that I found in Discrete Mathematics (Matroid Theory)? Let $G=(V(G),E(G))$ be a graph. What does $$\Delta(G)$$ mean? From the context I can determine, that $\Delta(G)$ computes an integer $k\in\mathbb{N}$. But I don't know for what $k$ stands. The exercise is:
Let $k\in\mathbb{N}$ and $G$ be a graph. Define
$$\mathcal{F}_{G}:=\{F\subset E(G): \Delta((V(G),F))\leq k\}$$
etc.","['graph-theory', 'matroids', 'discrete-mathematics']"
49727,Dense and locally compact subset of a Hausdorff space is open,Let $X$ be a Hausdorff space and let $D \subseteq X$ be locally compact and dense in $X$. Why is $D$ open? I can see that $D$ is regular but don't see why $D$ is in fact open.,['general-topology']
49733,Prove in full detail that the set is a vector space,"So I'm doing a review test and I have this problem: Prove in full detail, with the standard operations in $\Bbb R^2$ , that the set $\{(x,2x): x \ \text{is a real number}\}$ is a vector space. Attempt: Given: $(x_1, 2x_1) \in \mathbb{R}^2$ and $(x_2, 2x_2) \in \mathbb{R}^2$ Addition: $(x_1, 2x_1) + (x_2, 2x_2) = (x_1 + x_2, 2x_1 + 2x_2) \in \mathbb{R}^2$ $ = (x_1 + x_2, 2(x_1 + x_2)) \in \mathbb{R}^2$ $ ≃ (x, 2x) \in \mathbb{R}^2$ Thus the set is closed under addition Scalar multiplication: $c(x_1, 2x_1) = (cx_1, 2(cx_1)) \in \mathbb{R}^2$ $ ≃ (x, 2x) \in \mathbb{R}^2$ Thus the set is closed under scalar multiplication Are these operations enough to prove that the set is a vector space? Or do I have to go through each of the following (or in other words do I have to to the same thing for each property in the definition):","['vector-spaces', 'linear-algebra']"
49734,Taking the second derivative of a parametric curve [duplicate],"This question already has answers here : Explanation behind Second Derivative of a Parametric Equation Formula (3 answers) Closed 3 years ago . I understand that for the parametric equations $$\begin{align*}x&=f(t)\\  
y&=g(t)\end{align*}$$ If $F(x)$ is the function with parameter removed then $\displaystyle F'(x) = \frac{\text{d}y}{\text{d}t}\big/\frac{\text{d}x}{\text{d}t}$ But the procedure for taking the second derivative is just described as "" replace $y$ with dy/dx "" to get $$\frac{\text{d}^2y}{\text{d}x^2}=\frac{\text{d}}{\text{d}x}\left(\frac{\text{d}y}{\text{d}x}\right)=\frac{\left[\frac{\text{d}}{\text{d}t}\left(\frac{\text{d}y}{\text{d}t}\right)\right]}{\left(\frac{\text{d}x}{\text{d}t}\right)}$$ I don't understand the justification for this step. Not at all. But that's all my book says on the matter then it launches in to plugging things in to this formula, and it seems to work well enough, but I don't know why. I often find answers about question on differentials are beyond my level, I'd really like to get this, it'd mean a lot to me if someone could break it down.",['calculus']
49748,How to prove that $\mathbb{Q} \subset \mathbb{R}$ is not locally compact directly?,"How to prove that $\mathbb{Q} \subset \mathbb{R}$ is not locally compact directly? That is, how to construct a cover of an arbitrary neighborhood (e.g. $[0, 1] \cap \mathbb{Q}$) that does not have a finite subcover?","['general-topology', 'compactness']"
49758,Proving that a union of countably infinite sets is countably infinite,"I am solving Real Analysis over the summer, and this is an exercise in the preliminaries. I need to start off with 2 countably infinite sets and prove that their union is countably infinite as well. I was hoping for some help with this. The book advises to replace the second set, $A_2$, with $B$, where $B=A_2$ \ $A_1$ since $A_1 \cup B$ = $A_1 \cup A_2$ but $A_1$ and $B$ are disjoint, which makes things easier. Can I just map all the odd elements to $\frac{n-1}{2}$ and even elements to $-\frac{n}{2}$? What if the members of the set aren't numbers but some objects, yet there are countably infinitely many of them? Thanks!",['elementary-set-theory']
49763,relationship between Brownian motion and $1 / 2 \Delta$,"I'll enjoy your kindness to ask this question, despite that  it seems   silly for you. 
Please show me  a document or a url;   emphasizing  in a concise manner,  the relationship between Brownian motion and Laplacian . 
With google, I found a lot of links;  but I can not get the link to Markov chain , heat kernel and half Laplacian . 
friendly.",['probability-theory']
49770,Hardness of finding eigenvalues over finite fields,"How hard is it (computationally) to find eigenvalues/eigenvectors of matrices over finite fields?  Suppose the field has size exponential in the input.  (Does the QR algorithm still converge?) How about sparse matrices?  What are the best known algorithms for finding eigenvalues/eigenvectors of a matrix which is exponential in the input size (number of non-zero entries)? In general, is there a setting in which finding eigenvalues/eigenvectors is computationally hard?  Or rather, not known to be computationally easy?","['finite-fields', 'linear-algebra', 'computational-complexity', 'algorithms']"
49781,Can a Gaussian integer matrix have an inverse with Gaussian integer entries?,"Is there any way to characterize the set of complex matrices with Gaussian integer entries whose inverses also have Gaussian integer entries? I'm aware of the numerous examples of integer matrices whose inverses also have integer entries (usually involving binomial coefficients), but I'm wondering if those constructions can be generalized to Gaussian integers.","['matrices', 'complex-numbers', 'linear-algebra']"
49787,Area Between Three Circles of Differing Radii,"From the link in wikipedia http://web.gnowledge.org/wiki/index.php/Area_Between_Three_Circles_of_Differing_Radii OPEN QUESTION: What is the equation, in three variables, relating the radii of three circles to the area between them, when each is tangent to the other two? But wiki says that it is an open question  and I am interested what is main reason of it? or is the author simply trying to understand if anybody can solve it (while it's answer is known?)","['geometry', 'circles', 'euclidean-geometry']"
49791,"Derivative, sensitivity and implicit function","I have this implicit function $$y=f(x) \iff \sin(x+y)=k \sin(x), \quad$$ where $k>1$ is a constant. I would like to know how a small variation in $x$ propagates on $y$. I think I need to do an implicit differentiation but then it is not so clear to me how to solve the problem. So the derivative of the LHS is $$\frac{\mathrm{d}}{\mathrm{d}x}(\sin(x+y)) = \cos(x+y)(1+\frac{\mathrm{d}y}{\mathrm{d}x})$$ and the derivative of the RHS is $$\frac{\mathrm{d}}{\mathrm{d}x}(k\sin(x)) = k\cos(x)$$ And solving for $\displaystyle \frac{\mathrm{d}y}{\mathrm{d}x}$ gives $$\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{k\cos(x)-\cos(x+y)}{\cos(x+y)}$$ and now how can I continue? Thank you.","['trigonometry', 'calculus']"
49830,A Min-Max-Theorem for self-adjoint operators,"I got a small question concerning the proof of a min-max theorem for selfadjoint operators that I'm currently trying to understand. The article I'm refering to is http://en.wikipedia.org/wiki/Min-max_theorem#Compact_operators Section: Compact operators. So my problem is the proof of showing that the intersection of S' and $S_{k}$ is non-empty.
First of all the proof is written down in a bit of confusing way. 
For example I suspect that S' is basically the space of all eigenvectors belonging to 
eigenvalues greater or equal to $\lambda_{k}$. 
(They don't really point out what the $u_{i}$ with i=k,k+1,... are. I suspect that they
are the eigenvectors. Nonetheless the notation is a bit misleading since it suggests that there's only one eigenvector $u_{k}$ for the eigenvalue $\lambda_{k}$.) 
Now the part that puzzles me starts:
First, they point out that S' has codimension k-1. Doesn't that mean that we only have one eigenvector for every eigenvalue $\lambda_{i}$ with i Second, they say that they use a ""dimension count argument"" to show that the intersection is non-empty. I figured out that argument for the finite dimensional (matrix) case but 
couldn't figure it out for the infinite dimensional case. I'm still a student, so I'd be happy if someone could show me just these two arguments in detail. My background is also more from physics, so I'm not an expert when it comes to infinite dimensional vectorspace. I'd be more than happy if someone could help me. 
Thanks in advance!!",['functional-analysis']
49834,"Show that $\mathcal{F}_{G}$ is an Independence System, but in general is no Matroid","Let $k\in\mathbb{N}$ and $G$ be a graph. Define
$$\mathcal{F}_{G}:=\{F\subset E(G): \Delta((V(G),F))\leq k\}$$ I want to show, that $(E(G),\mathcal{F}_{G})$ is always an Independence System but in general $(E(G),\mathcal{F}_{G})$ is no Matroid. My approach: The empty set is always in $\mathcal{F}_{G}$ for every $k$ since the maximum degree $\Delta((V(G),\emptyset))$ is always zero and there for smaller then any valid $k$. Let $B\in\mathcal{F}_{G}$ and $A\subset B$. Since $B\in\mathcal{F}_{G}$ it is true that the maximum degree $\Delta((V(G),B))\leq k$. And because $A$ is a subset of edges of $B$ it is true, that for every node $v\in A$: $\delta(v)_A\leq\delta(v)_B$, meaning $\Delta((V(G),A))\leq\Delta((V(G),B))\leq k$. To show, that this construction does not hold in general for Matroids, I tried to build an example, that breaks the exchange property ( M3 ) of Matroids. So have to find a set $A$ and a set $B$ such that $|A|>|B|$ and there is no edge e in $A$, that I can add to $B$ such that $\Delta((V(G),B\cup\{e\}))\leq k$ is true. Right? I considered loops and double edges in my counter examples, but I couldn't find one that actually breaks the property. Any suggestions?","['graph-theory', 'matroids', 'discrete-mathematics']"
49850,"A ""fast"" way to manually compute $3^{41}+7^{41} \pmod{13}$","The problem: Find the remainder of $3^{41}+7^{41}$
  when divided by $13$. My approach is by utilizing the cyclicity of remainders for examples $3^1,3^2,3^3,3^4,3^5 \text{ and }3^6$ when divided $13$ gives $3,9,1,3,\text{ and }9 $ respectively,so we can see that the cycle repeats after $3$ steps.Hence the remainder of $3^{41}$ when divided by $13$ will be same as $3^2$ i.e $9$ For $7$ the repetition will occur in $7^{13}$ which means the cycle is of step $12$, hence it will be same as $7^5$ which gives $11$. So the final answer is remainder of $(11+9)$ divided by $7$ which is $7$. But as you might noticed, the computation of step for $7$ is quite a bit tedious (we have to check till $7^{13}$). But, considering the fact that this problem is been taken from a exam which requires solution within $2$ mints, I am quite sure that there might be an easier method for finding the answer but I can't think of any other easier method, so could anybody suggest me a tricky method?","['modular-arithmetic', 'elementary-number-theory', 'abstract-algebra']"
49857,Pseudo Inverse Solution for Linear Equation System Using the SVD,"I read about the SVD theory and its usage for solving Linear Equation System.
I saw many papers mentioning property of the solution yet no proof of it. The Property:
The solution given the Pseudo Inverse ( $ V {\Sigma}^{-1} {U}^{H} $ ) minimizes both the error norm and the solution norm. The minimization of the error norm is easily proved using the Normal Equations ( $ \hat{x} $ is the Least Squares solution iff $ {A}^{H} A \hat{x} = {A}^{H} b $ ). Yet beyond the intuition of $ \hat{x} $ must lie in the Row Space of A hence its norm is minimized I couldn't find a formal proof for that. Moreover, Let's define $ A = U \Sigma {V}^{H} $ then when we calculate its pseudo inverse we we handle $ \Sigma $ with extra care, only reversing its non zero entries. What the formal reasoning for that? Thanks!",['linear-algebra']
49859,Basic questions about $\mathbb{Z}^{\mathbb{N}}$ with the product topology,"can someone please let me know if the following is correct: 1) Let $\mathbb{Z}$ be the integers endowed with the discrete topology and $\mathbb{N}$ the natural numbers. Is $\mathbb{Z}^{\mathbb{N}}$ a discrete space with the product topoogy? 2) Does $\mathbb{Z}^{\mathbb{N}}$ contain a compact infinite set? 3) Is $\mathbb{Z}^{\mathbb{N}}$ metrizable? My work: 1) I think this is false, let $A= \{0\} \times \{0\} \times ...$ Suppose $A$ is open in $\mathbb{Z}^{\mathbb{N}}$ then we can find a basic open set $U=\prod_{n \in \mathbb{N}} U_{n}$ such that $(0,0,0,...) \in U \subset A$. By definition of product topology there exists a natural number $J$ such that if $n>J$ then $U_{n} = \mathbb{Z}$. This in turn implies that: $U_{1} \times U_{2} ...\times U_{J} \times \mathbb{Z} \times \mathbb{Z} ... \subset  \{0\} \times \{0\} \times ...$ which is not true since we can pick $z \in \mathbb{Z} \setminus \{0\}$ then $(0,0,...0,z,z,z...)$ is the LHS while not in the RHS. 2) Can we simply say, take $\{0,1\}$ endowed with the discrete topolgy then $\{0,1\}$  is compact since it is finite. But then by Tychonoff theorem $\{0,1\}^{\mathbb{N}}$ is compact and clearly infinite. 3) I think this one is true right? $\mathbb{Z}$ is metrizable (e.g discrete metric) and the countable product of metrizable spaces is metrizable.","['general-topology', 'metric-spaces', 'the-baire-space']"
49860,Behaviour of a holomorphic function near a pole,"Apparently, the following statement is true: ""Let $D\subseteq \mathbb{C}$ be open and connected and $f:D\setminus \{a\}\longrightarrow \mathbb{C}$ holomorphic with a pole of arbitrary order at $a\in D$. For any $\epsilon > 0$ with $B_\epsilon(a)\setminus\{a\} \subseteq D$, there exists $r > 0$ so that $\{z \in \mathbb{C}: |z| > r\} \subseteq f(B_\epsilon(a)\setminus\{a\})$."" So far, I have been unsuccessful in proving this. I know that $f(B_\epsilon(a)\setminus\{a\})$ must be open and connected (open mapping theorem), as well as that for any  $r > 0$ there exists an $x \in B_\epsilon(a)$ so that $f(x) > r$ (because $\lim_{z\rightarrow a}|f(z)| = \infty)$, but I don't see how this would imply the statement in question. Any help would be appreciated.",['complex-analysis']
49864,if $A^2 \in M_{3}(\mathbb{R})$ is diagonalizable then so is $A$,"Prove or disprove: if $A^2 \in M_{3}(\mathbb{R})$ is diagonalizable then so is $A$. I'm pretty confident this is not true, but I've tried and tried to find a counter example without success. If someone contradicts this, I'd appreciate if you can outline your thought process when constructing the matrix $A$. Also, another question in the same batch, asks: Let $p(t)=t(t-0.25)(t-1)$ be the characteristic polynomial of $A^2$, is $A$ diagonalizable? I'm thinking this is suppose to answer the previous question, assuming the answer here is false. Here I know $A^2$ is diagonalizable, but I haven't made any substantial progress other than that. I know I can go from the eigenvalues of $A$ to the eigenvalues of $A^k$, but not the other way around.",['linear-algebra']
49875,"How to prove that $\lim\limits_{(x,y) \to (0,0)} \frac{\left | x \right |^{\frac{3}{2}}y^{2}}{x^{4} + y^{2}} \rightarrow 0$ [duplicate]","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 3 years ago . How can I prove that $$\lim_{(x,y)\to (0,0)} \frac{\left | x \right |^{\frac{3}{2}}y^{2}}{x^{4} + y^{2}} \rightarrow 0\;?$$ Thanks!","['multivariable-calculus', 'calculus', 'limits']"
49879,Showing the derivative of a differentiable function has a point of continuity,"The question goes like this - 
Let $f:[0,1]\rightarrow \mathbb{R}$ be a differentiable function. Show that $f'(x)$ has a continuity point. Thanks for the help!","['calculus', 'real-analysis']"
49886,endomorphisms of the jacobian of a general hyperelliptic curve,"Let $C$ be a curve of genus $g$. If $C$ is very general, we know that the Jacobian $JC$ of $C$ is simple and thus $End(JC)=\mathbb{Z}$. Do we know something about $End(JC)$ if $C$ is a very general hyperelliptic curve?","['algebraic-geometry', 'algebraic-curves']"
49890,"Uses for the generalised f-mean, functions with larger/smaller f-means","What are some uses of the generalized f-mean outside of the geometric mean and the power means? Also, is there a known way to compare two functions and find out which will yield a larger f-mean (ex: we know that the function $f(x)=x^2$ will yield a greater f-mean than $f(x)=x$)?",['algebra-precalculus']
49912,"If $|z| \leq \pi/2$ and $|\sin z| \leq 1/4$, then $|z| \leq (4 \sin(1/4))^{-1} |\sin z|$","I came across the following assertion and am having trouble justifying it: If $z$ is a nonzero complex number with $|z| \leq \pi/2$ and $|\sin z| \leq 1/4$, then
$$
\left| \frac{z}{\sin z} \right| \leq \frac{1/4}{\sin(1/4)} = 1.0104931\ldots
$$ I would appreciate some help. Thanks. EDIT: Andrew has pointed out that the above inequality fails if $z = \sin^{-1}(1/4) = 0.25268025\ldots$.  After more thought, I figured out that if $z$ is real with $|z| \leq \pi/2$ and $|\sin z| \leq 1/4$, then $|z| \leq \sin^{-1}(1/4)$ and $z / \sin z$ is increasing in $[0,\sin^{-1}(1/4)]$; consequently,
$$
\left| \frac{z}{\sin z} \right| \leq \frac{\sin^{-1}(1/4)}{1/4} = 1.0107210\ldots
$$
holds.","['trigonometry', 'complex-numbers', 'inequality']"
49916,How to minimize this function difference,"Sorry about this somewhat lengthy introduction to my question. I thought it might be useful to know what I'm trying to do. I decided that I would like to have sequence of polynomials in $\mathbb{P}_n (x)$ defined in domain $x\in[0,1]$ which gradually learn a function. So, given an initial polynomial $P_{\alpha_0}(x)=\sum_{i=1}^n a_i x^{i-1}$ where $\alpha_0 = (a_1,\ldots,a_n) \in \mathbb{R}^n$, I would introduce a new point $(x_0,y_0) \in [0,1]\times\mathbb{R}$ and try to find all $\beta \in\mathbb{R}^n$ such that 
$$
P_{\alpha_0 + \beta}(x_0)=y_0
$$
If the solution space to that is $S$, then the next step would be to find optimal solution which somehow minimises the non-local difference. Define a norm which penalizes non-local difference:
$$
{\lVert P_{\alpha} \rVert}_{(x_0)} = \int_0^1 {(x-x_0)}^2{(P_{\alpha}(x))^2} dx
$$
The objective would be to find such $\beta \in S$ that it minimises
$$
{\lVert P_{\alpha_0} -P_{\alpha_0+\beta}\rVert}_{(x_0)}
$$
and then have for the next round $\alpha_1 = \alpha_0 + \beta$. Looking at solutions for the standard basis $\beta_i=(0,\ldots,0,b_{i,i},0,\ldots,0)$ (i.e. all but the $i$:th element are zero) one finds easily that
$$
P_{\alpha_0+\beta_i}(x_0)=y_0
$$
when
$$
b_{i,i} = \frac{y_0 - P_{\alpha_0}(x_0)}{x_0^{i-1}}
$$
Let's use $b_i = b_{i,i}$ for short. The solution space $S$ is linear combination $\sum t_i \beta_i$ with the requirement that $\sum t_i = 1$. Now, do you have any elegant ways to find the minimum for
$$
{\lVert P_{\alpha_0} -P_{\alpha_0+\beta}\rVert}_{(x_0)} =
\sum_{i,j}^n t_i t_j b_i b_j g_{x_0}(i,j)
$$
where 
$$
g_{x_0}(i,j) = (\frac{1}{i+j+1} -\frac{2 x_0}{i+j} + \frac{x_0^2}{i+j-1})
$$
from the solution hyperplane $\sum t_i = 1$? It's rather easy to find the equation for the null space of the partial differentials
$$
\frac{d{\lVert P_{\alpha_0} -P_{\alpha_0+\beta}\rVert}_{(x_0)}}{d t_k} =
\sum_i t_i b_i g_{x_0}(k,j)
$$ 
This is a linear mapping of the form $M t = 0 $ where $M_{i,j} = b_i g_{x_0}(i,j)$. Testing numerically with some functions seems to indicate that $M$ is mostly of full rank and in those cases the solution would be $t=0$ which does not fulfill the requirement that $\sum t_i = 1$. Adding this requirement to the mapping gives overdetermined equation
$$
\left(
\begin{matrix}
M \\
1
\end{matrix}
\right) t =  
\left(
\begin{matrix}
0 \\
1
\end{matrix}
\right)
$$","['polynomials', 'interpolation', 'linear-algebra', 'analysis', 'functional-analysis']"
49918,Integrate $\frac{1}{\sqrt{1 - x^2}}$,"I have to calculate $\int \frac{1}{\sqrt{1 - x^2}} \operatorname{d}x$ forwards, using known rules like partial integration or substitution. What I'm not allowed to do is simply show that $\frac{\operatorname{d}}{\operatorname{d} x} \arcsin x = \frac{1}{\sqrt{1 - x^2}}$, but I don't see how I can use the proof backwards for integration either… Any pointers?","['trigonometry', 'calculus', 'integration']"
49925,3D picture of the 38-sided Engel space-filling polyhedron,"On page 220 of Peter Engel's Geometric Crystallography, he describes a 38-sided convex polyhedron that can fill space. I've seen this this accepted as the record in various places, but I've never seen a 3D picture.  Has anyone ever managed to make one?","['geometry', 'polyhedra', 'tiling']"
49927,Why is $dy dx = r dr d \theta$ [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Explain $\iint \mathrm dx\mathrm dy = \iint r \mathrm d\alpha\mathrm dr$ I'm reading the proof of Gaussian integration. When we change to polar coordinates, why do we get an ""extra"" r in there? \begin{align}
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-(x^2+y^2)}\ dx dy
&= \int_0^{2\pi} \int_0^{\infty} e^{-r^2}r\ dr\ d\theta\\
\end{align} I've looked at a few different proofs: http://www.math.uconn.edu/~kconrad/blurbs/analysis/probint.pdf ""The differential dx dy represents an element of area in cartesian
coordinates, with the domain of integration extending over the
entire xy-plane. An alternative representation of the last integral
can be expressed in plane polar coordinates r, $\theta$"" http://www.umich.edu/~chem461/Gaussian%20Integrals.pdf but none explain this step fully enough for me to really see why this happened.","['multivariable-calculus', 'ordinary-differential-equations', 'calculus', 'integration', 'polar-coordinates']"
49929,"Percentage of risk, Is my calculation correct?","X is the worst scenario. In order for X to occur, two things must happen, in sequence. An event with an occurrence chance on 1/120 must occur. This is EVENT A. if EVENT A occurs, another event with a 2/100 occurrence chance must occur. This is EVENT B. EVENT A + EVENT B occurring are X = the worst possible scenario. So, at the starting point. What are the chances of ""X"" to occur? I calculated it to be 0.01% percent. Am I correct? Based on Comments: following bloodwork, a statistical model used by OBGYN's determines that a fetus has 1/120 chance of having a certain disorder. If this is indeed the case, a certain test can detect it. But that test fails in 2% of the cases (failure=existing disorder not detected). What are the chances of that fetus to be born sick, if the test is taken and upon detection of the disorder he's aborted.",['statistics']
49936,"If the sequence $(a_n b_n)$ converges and $a_n \to 0$, when does $(b_n)$ converge too?","Given that the sequence $(a_n b_n)$ converges and $a_n \to 0$, are there conditions which can be placed on $(b_n)$ and/or $(a_n b_n)$ so that $(b_n)$ converges as well?","['complex-numbers', 'sequences-and-series']"
49941,calculate the rate of change,"I am trying to calculate the change frequency for a set of data. Each bit of data has the date-time it was created. I would like to say for a specific set of data the change frequency is hourly, daily, weekly, monthly or yearly. So far I have tried getting the list of dates and get the min/max which is easy to calculate an average from which can be converted into a human readable label such as hourly, daily etc How would i take into account the age of the last new bit of data. eg: say there were 50 dates all roughly an hour one after the other. This is hourly. but if the last one was 2 weeks ago, its not quite hourly. I am sure there is a formula to calculate this, but I don't know where to start. Thanks P.S. I took a guess at the tags, not sure if there are better ones to use for this question.","['statistics', 'approximation', 'algorithms', 'analysis']"
49949,What is the basis for the Universal Enveloping Algebra of su(2)?,"Given the standard basis for the Lie algebra $\mathfrak{su}(2)$ of SU(2), $\{i\sigma_1,i\sigma_2,i\sigma_3\}$ where $\sigma_1=\Biggl(\begin{array}{cc}
0&1\\
1&0\end{array}\Biggr),\quad\sigma_2=\Biggl(\begin{array}{cc}
0&-i\\
i&0\end{array}\Biggr),\quad\sigma_3=\Biggl(\begin{array}{cc}
1&0\\
0&-1\end{array}\Biggr),$ I want to find a basis for the universal enveloping algebra, $\mathcal{U}(\mathfrak{su}(2))$. By the Poincare-Birkoff-Witt Theorem I believe we have $\{i\sigma_1,i\sigma_2,i\sigma_3,-i\sigma_1\sigma_2,-i\sigma_1\sigma_3,-i\sigma_2\sigma_3,-i\sigma_1\sigma_2\sigma_3\}$, in other words all lexicographically ordered monomials. However, since products of the Pauli matrices are Pauli matrices (ie $\sigma_1\sigma_2=i\sigma_3$) it would seem that the two algebras have the same basis, just with the Lie bracket $[,]$ replaced with matrix multiplication. Can someone tell me if this is correct?","['lie-algebras', 'abstract-algebra']"
49951,Pushforward of pullback of a sheaf,Are there any reasonable hypotheses on a map $f: X \to Y$ and a sheaf $E$ on $Y$ so that $f_* f^* E \cong E$?,['algebraic-geometry']
49952,Generalizations of Tail Sigma Algebras,"If I have i.i.d. r.v.'s $X_1, X_2,...$ then the tail sigma algebra is defined as $\mathcal{T}:=\cap_n\sigma_n$ where $\sigma_n:=\sigma(X_n,X_{n+1},...)$. From this we get very nice results such as the Kolmogorov 0-1 law. I was wondering if it makes sense to consider limsup and liminfs in this fashion: $\bigcup_n\bigcap_{k\ge n}\sigma_k$ and $\bigcap_n\bigcup_{k\ge n}\sigma_k$. Do these have a sensible meaning and are there similar laws such as the 0-1 law pertaining to each?",['probability-theory']
49955,Motivation Behind Tschirnhaus Transformation and Cardano's Formula,"I have a general question about the cubic equation: Let $a,b,c \in \mathbb{C}$ with $a \neq 0$. The general cubic equation is $t^3+at^{2}+bt+c = 0$. To get Cardano's Formula, we first transform the equation so that $a= 0$ (i.e. $t^3+bt+c = 0$). Then we reduce this to a quadratic that we can solve. What is the motivation behind the transformations that reduce $t^3+at^2+bt+c = 0$ to $t^3+bt+c = 0$? In particular, if we let $y = t+ \frac{a}{3}$, then $t = y-\frac{a}{3}$ which cancels the $at^2$ term. This is called a Tschirnhaus transformation . We are left with an equation of the form $$y^3+py+q = 0$$ But how do we know what transformations to use to get Cardano's Formula, where $$p = \frac{a^2-2a^3+3b}{3}\quad\mathrm{and}\quad q = \frac{2a^3-9ab+27c}{27}\quad ?$$ Finally if we let $y = \sqrt[3]{u}+ \sqrt[3]{v}$ we eventually get a quadratic which leads to Cardano's Formula.","['soft-question', 'abstract-algebra', 'polynomials']"
49956,Value of cyclotomic polynomial evaluated at 1,"Let $\Phi_n(x)$ be the usual cyclotomic polynomial (minimal polynomial over the rationals for a primitive nth root of unity). There are many well-known properties, such as $x^n-1 = \Pi_{d|n}\Phi_d(x)$. The following fact appears to follow pretty easily: Fact: $\Phi_n(1)=p$ if $n$ is a prime power $p^k$. $\Phi_n(1)=1$ if $n$ is divisible by more than one prime. My question is, is there a reference for this fact? Or is it simple enough to just call it ""folklore"" or to just say it ""follows easily from properties of cyclotomic polynomials"".","['elementary-number-theory', 'algebraic-number-theory', 'number-theory']"
49959,Space-filling polyhedra (or honeycomb) survey?,"Is there a survey anywhere of space-filling polyhedra?  MathWorld's article, space-filling polyhedron , mentions about 400 being seen in pre-1981 books and papers. Wikipedia mentions 28 convex uniform honeycombs , and the article honeycomb . Is there a modern count anywhere for how many space-filling hexahedra or icosahedra exist?  Can the 3D coordinates be downloaded?","['geometry', 'recreational-mathematics', 'polyhedra']"
49960,Supremum and ordinals,"Question: Show that sup{$ \xi \dotplus 1 : \xi \in A  $} is the least ordinal that is greater than each element of $A$. I tried to get a better feel for this by letting $A=3=${$0,1,2$}. Then I know that the least ordinal greater than each element of $3$ is $3$ itself.
So, sup{$ \xi \dotplus 1 : \xi \in 3  $}=$\bigcup_{\xi \in 3}${$\xi \dotplus 1$}={$0 \dotplus 1$}$\cup${$1 \dotplus 1$}$\cup${$2 \dotplus 1$}$=${$1,2,3$}. I take it that {$1,2,3$} and {$0,1,2$} are the same because there's an order-preserving isomorphism from one to the other. Now I'm having trouble generalizing.","['ordinals', 'elementary-set-theory', 'order-theory']"
49963,Define a graph with segments or boundaries,"Is it possible to have a function such as: $y = x^2$ but to also state that from negative infinity to -10 and from 10 to positive infinite that $y = 7$ This is a simple example, but I just want to find out if it's possible to combine different functions into one. Cheers","['graphing-functions', 'functions']"
49986,A Universal Property Defining Connected Sums,"I once read (I believe in Ravi Vakil's notes on Algebraic Geometry) that the connected sum of a pair of surfaces can be defined in terms of a universal property. This gives a slick proof that the connected sum is unique up to homeomorphism. Unfortunately, I am unable to find where exactly I read this or remember what exactly universal property was; 
if anyone could help me out in either regard it would be much appreciated.","['general-topology', 'reference-request']"
49990,The p-adic numbers as an ordered group,"So I understand that there is no order on the field of $p$ -adic numbers $\mathbb{Q}_p$ that makes it into an ordered field (i.e.) compatible with both addition and multiplication. Now, from the responses to a couple of my previous questions, $\mathbb{Q}_p$ is a divisible abelian group under addition (being a field of characteristic $0$ ). $\mathbb{Q}_p$ is torsion-free. It admits an order compatible with the group operation (addition), since every torsion-free abelian group is orderable. My question is, can I write an explicit ordering of $\mathbb{Q}_p$ compatible with the group operation? By ""explicit"", I mean an ordering in which, given two $p$ -adic numbers, I can decide which is greater. P.S.: I was not sure how to classify this problem, so please feel free to change the tags.","['p-adic-number-theory', 'abstract-algebra', 'order-theory']"
50015,Set that is not algebraic [duplicate],"This question already has answers here : Prove that a set in $\mathbb R^3$ is not an algebraic set (2 answers) Closed 6 years ago . I'd like some hints for the problem: Show that the following set is not algebraic: $$ \{ (\cos(t),\sin(t),t) \in \mathbb{A}^3 : t \in \mathbb{R} \} $$ Thanks.","['algebraic-geometry', 'algebraic-curves']"
50026,Intuition behind problem in (classical) algebra,"To give some background, the question is to show that if $a=b+c$ then $$a^4+b^4+c^4 = 2a^2b^2+2b^2c^2+2c^2a^2$$ Which, for completeness, I was able to do by squaring twice $$(a-b-c)^2=0$$ gives $$a^2+b^2+c^2= 2(bc-ac-ab)$$ which on squaring gives the required identity. $$a^4+b^4+c^4 +2a^2b^2+2b^2c^2+2c^2a^2 = 4a^2b^2+4b^2c^2+4c^2a^2 + 8(a^2bc - ab^2c-abc^2)$$ $$a^4+b^4+c^4 =2a^2b^2+2b^2c^2+2c^2a^2 +8abc(a-b-c) $$ $$a^4+b^4+c^4 = 2a^2b^2+2b^2c^2+2c^2a^2$$ For the second part the statement is: ""explain why an unsymmetric equation gives such a symmetric expression."" I ignored this part while solving it as I did not have a very good impression of the author of the problem set from the previous problems and as no rigorous definition of symmetry was given the author was presumably requiring some kind of aesthetic appreciation. The reason as it turns out in the hint is that ""on squaring twice effect of minus signs gets cancelled."" If this statement is taken for granted, from this logic all the ring permutations of ($\pm a,\pm b,\pm c$),i.e 4 yield the same equation. It is indeed so as the factors turn out to be $$(a+b+c)(a-b-c)(a+b-c)(a-b+c)$$ However, by this same logic $(a+b+c)^4=(a-b+c)^4$ But it is not. The reason I am asking here  is that I can verify the above algebraically and see why everything is ok, but cannot explain it as the way algebra works for me is that I work it out all keeping care for all the minus signs then magically half the terms seem to cancel out and I am left with a single expression out of the blue. Sorry for the wall of text.",['algebra-precalculus']
50035,Proof that $\Delta$ generates analytic semigroup,"First off, I apologize for asking a question which I'm sure has been studied to death, but I can't seem to find an answer with google. I want to see a proof that the Laplace operator $\Delta$ with domain $W^{2,p}(\Omega) \cap W^{1,p}_0(\Omega)$ generates an analytic semigroup on $L^p(\Omega)$ where $\Omega$ is a reasonably nice domain and $1 < p < \infty$. I'm assuming this boils down to the applying the following theorem: If $A$ is closed and densely defined then $A$ generates an analytic semigroup iff there exists $\omega \in R$ such that the half plane Re $\lambda > \omega$ is contained in the resolvent set of $A$ and there is a constant $C$ such that the resolvent $R_{\lambda}(A)$ satisfies 
$$\|R_\lambda(A)\| \le C/|\lambda - \omega|$$
for all Re $\lambda > \omega$. That $\Delta$ is closed and densely defined is clear to me, but how do I prove the remaining 2 hypotheses? Thanks in advance.","['semigroup-of-operators', 'functional-analysis', 'partial-differential-equations']"
50044,Quotient Space of Hausdorff space,"Is it true that quotient space of a Hausdorff space is necessarily Hausdorff? In the book Algebraic Curves and Riemann Surfaces , by Miranda, the author writes: $\mathbb{P}^2$ can be viewed as the quotient space of $\mathbb{C}^3-\{0\}$ by the multiplicative action of $\mathbb{C}^*$ . In this way, $\mathbb{P}^2$ inherits a Hausdorff topology , which is the quotient topology from the natural map from $\mathbb{C}^3-\{0\}$ to $\mathbb{P}^2$ It is true that the complex projective plane $\mathbb{P}^2$ is Hausdorff, but the above reasoning by Miranda will be true if the statement in the question is true.","['general-topology', 'quotient-spaces', 'riemann-surfaces', 'separation-axioms']"
50049,"What is the probability of randomly selecting $ n $ natural numbers, all pairwise coprime?","It's known that the probability of selecting $ n $ natural numbers randomly and ending up with a greatest common divisor equal to one is $ \prod (1-p^{-n}) = 1/\zeta(n) $. However, a total GCD of 1 does not rule out any of the pairs among the set of $ n $ numbers sharing a common factor. What's the probability none of them share a common factor? (Since there's a possibility of ""random selection"" being ambiguous, let's take it to mean chosen with uniform probability from {$ 1,2,3,\dots, N$} as $N \to \infty $.)","['probability', 'number-theory']"
50051,Stricter permutation patterns,"A lot of work has been done on patterns in permutations , where a permutation is said to match a given pattern if it contains a subsequence of elements ordered according to the pattern (e.g., $\pi=(2\ 1\ 7\ 5\ 3\ 6\ 4)$ matches $4\ 1\ 3\ 2$ -- consider the subsequence $7\ 3\ 6\ 4$). One could be more restrictive and require that the subsequence of elements to be tested against the pattern not only follows the same order, but that the gaps between the elements (or between some, but not all, pairs of elements) is the same. In the above example, for instance, $7\ 3\ 6\ 4$ would no longer be a match for $4\ 1\ 3\ 2$ (but $6\ 3\ 5\ 4$ would, had it been a subsequence of $\pi$). Has there been work on such constrained patterns? If so, what are they called, and what would be good references to check? (I would have tagged this pattern-avoidance or pattern-matching , but I cannot create those tags)","['permutations', 'reference-request', 'combinatorics']"
50060,creating smooth curves with $f(0) = 0$ and $f(1) = 1$,"I would like to create smooth curves, which have $f(0) = 0$ and $f(1) = 1$ . What I would like to create are curves similar to the gamma curves known from CRT monitors. I don't know any better way to describe it, in computer graphics I used them a lot, but in math I don't know what kind of curves they are. They are defined by the two endpoints and a 3rd point. What I am looking for is a similar curve, what can be described easily in math. For example with a simple exponential function or power function. Can you tell me what kind of curves these ones are (just by lookin at the image below), and how can I create a function which fits a curve using the 2 endpoints and a value in the middle? So what I am looking for is some equation or algorithm what takes a midpoint value $f(0.5) = x$ , returns me $a, b$ and $c$ for example if the curve can be parameterized like this (just ideas): $a  \exp (bt) + c$ or $a  b^t + c$ Update : yes, $x^t$ works like this, but it gets really sharp when $t < 0.1$ . I would prefer something with a smooth derivative at all points. Thats why I had exponential functions in mind. (I use smooth here as ""not steep"")","['interpolation', 'geometry', 'calculus']"
50069,Level sets of a continuous function,Let $f$ be continuous on a compact subset $X$ of a metric space. If we put $A_h=\{x\in X:f(x)<h\}$ and $B_h=\{x\in X:f(x)\leq h\}$ - when is it true that $B_h = \overline{A_h}$? Is it true if and only if $A_h$ is not empty? Edited: Theo already showed that there are counterexamples. Is it true then that $A_h = B_h^\circ$?,['real-analysis']
50075,Convergence of a kind of difference quotient,"Let $f:\mathbb{R}\to \mathbb{R}$ be a measurable function and $(h_j)_j$ be a sequence of nonzero real numbers converging to zero as $j\to \infty$. Is it true that for almost every $x\in \mathbb{R}$:
$$\frac{1}{h_j}(\cos(f(x+h_j)-f(x))-1)\to 0\quad\mathrm{as}~~ j\to \infty~~?$$ It feels that the Lebesgue differentiation theorem or maybe some other measure-theoretic theorem must be used to prove it, if it is true at all.","['measure-theory', 'real-analysis']"
50085,Can a rectangle be cut into 5 equal non-rectangular pieces?,"How to prove that the only figure of which 3 copies can be used to tile a rectangle is a rectangle? Is it possible to cut a rectangle into 5 equal (modulo rotations/reflections) non-rectangular pieces, which type of pieces?","['geometry', 'tiling']"
50086,Simple question about closed sets,"I have two functions $f,g: \mathbb{R} \rightarrow \mathbb{R}$ which are continuous. Now in a proof one step that is not further explained says that the set $$M = \{x \in \mathbb{R}| f(x) \leq g(f(x))\}$$ is closed. I thought about it but could not find a short formal argument and I fear the answer is very trivial because the book explains all others steps very detailed. I noticed that if you instead say $f(x) < g(f(x))$ it is not true anymore because you could set $f(x)=\frac{1}{|x|+1}$ and $g(x)=1$ getting a contradiction for a sequence with $x_n \rightarrow 0$. Thank you in advance.","['general-topology', 'real-analysis']"
