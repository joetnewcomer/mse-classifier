question_id,title,body,tags
4613721,Evaluating $\lim_{n\to \infty} \sin(\sqrt{n^2+1}\pi)$. (WolframAlpha says it doesn't exist; I get $0$.),"I have tried to solve limit, which wolfram says that DNE, but according to my calculations it is equal to 0. Limit is given below $$\begin{align}
\lim_{n\to \infty} \sin(\sqrt{n^2+1}\pi)
&=\sin(\sqrt{n^2+1}\pi-n\pi+n\pi) \\
&=(-1)^n\sin(\sqrt{n^2+1}\pi-n\pi) \\
&=(-1)^n\sin\left(\frac{(\sqrt{n^2+1}\pi-n\pi)(\sqrt{n^2+1}\pi+n\pi)}{(\sqrt{n^2+1}\pi+n\pi)}\right) \\
&=(-1)^n\sin\left(\frac{n^2\pi^2+\pi^2-n^2\pi^2}{\sqrt{n^2+1}\pi+n\pi}\right) \\
&=(-1)^n\sin\left(\frac{\pi^2}{n\pi(\sqrt{1+\frac{1}{n^2}}+1}\right) \\
&=0 
\end{align}$$ It is because denominator of sin goes to infinity so everything inside sin goes to 0. as we know, sin of that would go to 0 too. And we know that $(-1)^n$ is bounded so we got that bounded * 0 has to be equal to 0.
Am I doing some mistake here ?",['limits']
4613778,Function to determine how many times an integer can be divided by $2$,"Is there a function that returns how many times a number can be divided by $2$ ? For example: $$f(7) = 0$$ $$f(38) = 1$$ $$f(48) = 4$$ I assume it would have to be some kind of trigonometric function but I can’t figure it out. $\cos^2\left(\frac{\pi}{2} \cdot x\right) + \cos^2\left(\frac{\pi}{4} \cdot x\right) $ gives $1$ for numbers divisible by two and $2$ for numbers divisible by $4$ but the pattern does not continue. Any and all help is welcome, thanks.","['algebra-precalculus', 'trigonometry', 'divisibility']"
4613787,Solve the equation $4x^3+13x^2-14x=3-\sqrt{15x+9}$,"I ran into this problem: $$4x^3+13x^2-14x=3-\sqrt{15x+9}$$ It makes no sense to square it. I thought it was necessary to make a replacement. What kind of substitution?
First of all, the root gets in the way, so you have to make a substitution that removes the root! I was able to find such a substitution $$x=\frac{9}{15}\cos 2t\Rightarrow \sqrt{15x+9}=3\sqrt{2}\cos t$$ We don't have to put the module, because the restrictions allow us to do so After we got rid of the root, then comes the second problem. How do we solve this equation? $$\frac{108}{125}\cos^32 t+\frac{117}{25}\cos^22t-\frac{42}{5}\cos 2t=3-3\sqrt{2}\cos t$$","['algebra-precalculus', 'polynomials']"
4613805,Parameterize a closed surface.,"We are told to find a tangent plane of the surface $$x^2 +2y^2+3z^2=36$$ at the point $(1,2,3)$ . Is it possible to parameterize this surface in 2 variables, perhaps with a spherical or cylindrical coordinate system? I attempted to solve it by creating $$F(x,y,z)=x^2 +2y^2+3z^2-36$$ and noting that the gradient of a function is normal to its surface, and all you need to define a tangent plane is a normal vector and a positional vector and you can denote the plane as $$r\cdot n=a\cdot n$$ Is this approach correct? Is there a better way to do this?",['multivariable-calculus']
4613813,Convexity of a ball in any normed space and in any metric space [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question I would like to show that an open (and closed) ball in a normed space is convex. Consider $(X,\lVert\rVert)$ a normed space and $B(X_0, r)$ an open ball centered in $X_0\in X$ . Take $X_1\in B(X_0, r)$ , $X_2\in B(X_0, r)$ and $s\in[0,1]$ Clearly we have : $\lVert sX_1 + (1-s)X_2 - X_0\rVert = \lVert sX_1 - sX_0 + (1-s)X_2 -(1-s)X_0\rVert $ $ =\lVert s(X_1 - X_0) + (1-s)(X_2 - X_0)\rVert\leq s\lVert X_1 - X_0\rVert + (1-s)\lVert X_2 - X_0\rVert < sr + (1-s)r = r $ In the same way we conclude for a closed ball in $X$ . I would like to know if this result can be extended to any metric space ? I have tried using the property of the distance function but I was not successfull, here is my attempt. Consider $(X,d)$ a metric space and $B(X_0, r)$ . Then for all $s\in[0,1]$ : $d(s(X_1-X_0) + (1-s)(X_2-X_0), X_0)\leq d(s(X_1-X_0) + (1-s)(X_2-X_0), s(X_1-X_0)) + d(s(X_1-X_0), X_0)$ and get stuck here because I don't see any property that could help me at this point, obviously I have tried to do something the triangle inequality but was not successfull. Any idea please ? I think I am missing something Thank you a lot ! EDIT : The question is not correct put in this way since we can define plenty of metric space where the notion of convexity has no meaning. We need to consider metric space over a vector space as did Esgeriath in his answer. Thus the question is the following : Is a ball in a metric space over a vector space convex ? Thanks to Esgeriath and geetha290krm for their helps.","['normed-spaces', 'convex-analysis', 'metric-spaces', 'analysis']"
4613838,Fourier Series Derivative of saw tooth-like function,"So I have this periodic signal x(t), $$x(t)=\begin{cases}
5t & \text{ if } x \in [0.2,0.4]\\
-10t & \text{ if } x \in [0.4,0.5] \\
0 & \text{ if } x \in [0.5, 0.6]
\end{cases}$$ and I was trying to calculate the regular Fourier Series coefficients. One way to do it is by using the regular expression: $$a_n = \frac{1}{(b-a)}\int_{a}^{b}x(t)e^{-i2\pi/(b-a)nt}dt \ (1)$$ But I decided to try something different, namely using the derivative of x(t). So if we consider $$x(t)' = \begin{cases}
5 & \text{ if } x \in ]0.2,0.4[\\
-10 & \text{ if } x \in ]0.4,0.5[ \\
0 & \text{ if } x \in ]0.5, 0.6[
\end{cases}=\sum_{n} b_ne^{-i2\pi/(b-a)nt}$$ we have: $$\frac{\mathrm{d} }{\mathrm{d} t}(\sum_{n} a_ne^{-i2\pi/(b-a)nt})=\sum_{n} b_ne^{-i2\pi/(b-a)nt} \\
\Rightarrow b_n = [-i2\pi/(b-a)n]\cdot a_n \ (2)$$ The problem comes when I try to calculate $b_n$ using (1) and then with (2) retrieve $a_n$ , as the $a_n$ calculated by this method doesn't coincide with the one directly calculated by (1). Am I doing any supposition wrong? I'm guessing maybe the fact $x'(t)$ is not defined everywhere could be problematic? Any help is welcomed.","['complex-analysis', 'functions', 'fourier-series', 'derivatives', 'piecewise-continuity']"
4613840,How to prove that a point cannot lie within a triangle based on statements about triangles containing points.,"I'm a total newb and bottom rung hobbyist mathematician, just fair warning. Say points a,b,c,d,e are in the plane (general position) and triangle abc contains point d, triangle ade contains point c. It seems intuitive that triangle bcd cannot contian point e, but I don't know how to prove it, without trying actual values for the coordinates. My first thought was to set up a system of inequalities, one for each statement of containment, similar to barrycentric coordinates (but using cross products), then somehow deduce a contradiction. The inequality list looks like this. I gather one would have to check a number of different sign conditions, and perhaps all possible orderings of x and y. I'm ok to assume a specific ordering, like $a_x < e_x < c_x < d_x < b_x$ and $a_y < b_y < d_y < c_y < e_y$ , if that helps. I already checked for simple sign conflicts (some orderings are easy to prove immediately via sign conflicts): ABC contains D $$(d_x - a_x) (c_y - a_y) - (c_x - a_x) (d_y - a_y)>0$$ $$(d_x - b_x) (a_y - b_y) - (a_x - b_x) (d_y - b_y)>0$$ $$(d_x - c_x) (b_y - c_y) - (b_x - c_x) (d_y - c_y)>0$$ ADE contains C $$(c_x - a_x) (e_y - a_y) - (e_x - a_x) (c_y - a_y)>0$$ $$(c_x - d_x) (a_y - d_y) - (a_x - d_x) (c_y - d_y)>0$$ $$(c_x - e_x) (d_y - e_y) - (d_x - e_x) (c_y - e_y)>0$$ BCD contains E $$(e_x - b_x) (d_y - b_y) - (d_x - b_x) (e_y - b_y)>0$$ $$(e_x - c_x) (b_y - c_y) - (b_x - c_x) (e_y - c_y)>0$$ $$(e_x - d_x) (c_y - d_y) - (c_x - d_x) (e_y - d_y)>0$$ Can it be shown, just with the above statements, that the three ""containment"" statements cannot co-exist? I guess we also need to say that no three points are colinear and no two points are the same. Here's an example drawing, but of course I'm looking to prove this without assuming any particular configuration of the points. While a geometric reasoning proof would be interesting, my goal is to be able to programatically prove these sorts of statements, so analytical is best. I'm happy to improve the question with any feedback. thanks!",['geometry']
4613856,$\underset{n\rightarrow\infty}{\lim} \frac{f_n^{(n)}(\frac{1}{n})}{n!}$,"I just try to solve a problem, but I'm not sure it's right or not. Here is the problem: Suppose $f_n(x)=x^n\ln{x}$ , $ n \in \mathbb{N}$ . Find $$
 \lim_{n\to\infty} \frac{f_n^{(n)}(\frac{1}{n})}{n!}
$$ My idea is by Leibniz product rule $$
\left[\left(\frac{1}{n}\right)^n\ln{\frac{1}{n}}\right]^{(n)}=\overset{n}{\underset{k=0}{\sum}}\binom{n}{k}\cdot k!\cdot n^{-2n-k}
$$ Since n approaches to infinity, I check the n-th term, $n!\cdot n^{-n}$ . With the denominator, $$ \lim_{n\to \infty}n^{-n}= e^{\lim_{n\to \infty}(-n\ln{n})}=0$$ I appreciate your feedback.","['calculus', 'analysis']"
4613879,Boundary Point of Subdifferential as the Limit of a Sequence of Gradients,"Let $\Omega\subset\mathbb{R}^n$ be an open convex set. Let $f:\Omega\to\mathbb{R}$ be a convex function. We know that $f$ is differentiable almost everywhere. The subdifferential of $f$ at $x\in\Omega$ is defined as $$
\partial f(x)=\{g\in\mathbb{R}^n:f(y)\ge f(x)+g^T(y-x)\ \forall\,y\in\Omega\}.
$$ My question: Is it true that for every $x\in\Omega$ , for every boundary point $g$ of $\partial f(x)$ , there always exists a sequence $\{x_n\}\subset\Omega$ such that $f$ is differentiable at each $x_n$ , $x_n\to x$ , and $\nabla f(x_n)\to g$ ? My attempt: This is not true for general $g\in\partial f(x)$ . For example, in $\mathbb{R}$ , the convex function $f(x)=|x|$ is differentiable on $\mathbb{R}\backslash{\{0\}}$ and $\partial f(0)=[-1,1]$ . Since $f'(y)\in\{-1,1\}$ for all $y\neq 0$ , then there does not exist $\{x_n\}\subset\mathbb{R}\backslash\{0\}$ such that $x_n\to 0$ and $\nabla f(x_n)\to 0\in\partial f(0)$ . I believe the statement is true at least in the speical case of $\mathbb{R}$ . Since $\partial f(x)\subset\mathbb{R}$ is closed and convex, then it must be an interval. So I suppose it should be true that $$
\partial f(x)=\left[\liminf_{y\to x}\frac{f(y)-f(x)}{y-x},\limsup_{y\to x}\frac{f(y)-f(x)}{y-x}\right].
$$ This should help prove the statement. I am a beginner in convex analysis. Any help would be appreciated.","['convex-optimization', 'real-analysis', 'multivariable-calculus', 'subgradient', 'convex-analysis']"
4613914,Extend the Picard Local Existence Theorem using the Arzelà–Ascoli Theorem,"This problem is taken from Royden and Fitzpatrick's Real Analysis, Fourth Edition (Chapter 10, Problem 44). The text proves the Picard Local Existence Theorem for a single differential equation. The exercise is to state and prove an analogous theorem  when $O$ is an open subset of $\mathbf{R} \times \mathbf{R}^n$ containing the point $(x_0, \mathbf{y}_0)$ , $\mathbf{g}: O \to \mathbf{R}^n$ is continuous, and the system of differential equations is \begin{align*}
\mathbf{f}'(x) &= \mathbf{g}(x, \mathbf{f}(x))\\ 
\mathbf{f}(x_0) &= \mathbf{y}_0
\end{align*} I thought I could just use a fixed point argument analogous to the proof in the single equation case (that also seems to be the approach taken in the Wikipedia article ). But the question includes the following hint: Approximate $\mathbf{g}$ by a Lipschitz mapping and then use the Arzelà–Ascoli Theorem. I'm lost on how to approach the problem with this hint.","['functional-analysis', 'ordinary-differential-equations', 'real-analysis']"
4613931,Interpreting combinatorics: how are these not the same question?,"Here are two allegedly different questions from Lovasz's Combinatorial Problems and Exercises : In a shop there are $k$ kinds of postcards. We want to send postcards to $n$ friends. How many ways can it be done? We have $k$ distinct postcards and want to send them all to our $n$ friends (a friend can get any number of them, including 0). How many ways can it be done? These appear to me to be the same question. How are they different?","['combinatorics', 'discrete-mathematics']"
4613934,"Why does paracompactness need to be not locally finite open subcollection, but refinement of opem covering?","In Munkres topology, he defines paracompactness as a generalization of compactness, as follows: $X$ is paracompact if every open cover of $X$ has locally finite open refinement that covers $X$ But why it should be ""refinement"" of open cover? In compact, we need ""subcollection"". Surely subcollection is more strong assumption, but then , is there any paracompact space that has refinement but not subcollection? If then, what important difference between refinement and subcollection does make difference of definition in paracompactness?",['general-topology']
4613947,Show that $\{A_{\alpha}: \alpha\in I\}$ is a set using the axiom of replacement in ZFC,"I'm reading Enderton's Elements of Set Theory . Let $I$ be a set, and for every $\alpha\in I$ , let $A_\alpha$ be a set. In order to apply the axiom schema of replacement to construct the set $\{A_{\alpha}: \alpha\in I\}$ , we need a formula $φ(x,y)$ （a formula is defined to be a string of symbles constructed from the atomic formulas $x\in y$ and $x=y$ by repeated applications of logical operators $\vee$ , $\wedge$ , etc). I know that we generally don't write out the formula itself (for the sake of convenience), but the fact of the matter is that we should be able to ""translate"" what we write into a legal formula. For instance, if one wished to prove the existence of the collection $\{\mathscr{P}(x):x\in A\}$ of all power sets of members of $A$ , one could use the ""illegal"" statement $P(x,y)：y=\mathscr{P}(x)$ , which can be rewritten as a legal formula $φ(x,y):\forall t(t\in y\leftrightarrow (\forall u(u\in t \rightarrow u\in x)))$ . When constructing the set $\{A_{\alpha}: \alpha\in I\}$ , the ""illegal"" statement we use is $P(\alpha,y): y=A_\alpha$ . But I have no idea how I shoud rewrite this statement as a legal formula. We can rewrite it first as $\forall t(t\in y\leftrightarrow t\in A_\alpha)$ . But how can I rewrite "" $t\in A_\alpha$ "" as a formula? Here is an example of how $\alpha\mapsto A_\alpha$ might be defined: $I=\{1,2,3\}, A_1:=\{2,3\},A_2:=\{3,4\},A_3:=\{4,5\}$ . Sorry for the language barrier.","['predicate-logic', 'first-order-logic', 'logic', 'elementary-set-theory', 'set-theory']"
4613958,"Extend a homomorphism $\mathrm{PSL}(2,3) \to \mathrm{PGL}(n, \mathbb{C})$ to a homomorphism $\mathrm{SL}(2,3) \to \mathrm{GL}(n, \mathbb{C})$","(Here by $\mathrm{SL}(2,3)$ , I am referring to $2 \times 2$ matrices of determinant $1$ over the field of order $3$ , and by $\mathrm{GL}(n, \mathbb{C})$ , I am referring to $n \times n$ nonsingular matrices over the complex numbers. The $\mathrm{P}$ prefix refers to quotienting one of these groups by its center, the subgroup of scalar matrices.) In learning about projective representations and Schur multipliers in group theory, I am attempting to prove that $\mathrm{SL}(2,3)$ is a cover of $\mathrm{PSL}(2,3)$ . The last step is to show that the “projective lifting property” holds: Let $v \colon \mathrm{SL}(2,3) \to \mathrm{PSL}(2,3)$ and $\pi \colon \mathrm{GL}(n,\mathbb{C}) \to \mathrm{PGL}(n,\mathbb{C})$ be the quotient maps. Then, for any homomorphism $\tau \colon \mathrm{PSL}(2,3) \to \mathrm{PGL}(n,\mathbb{C})$ , there exists a homomorphism $\overline{\tau} \colon \mathrm{SL}(2,3) \to \mathrm{GL}(n,\mathbb{C})$ such that $\pi \overline{\tau} = \tau v$ . $$
  \require{AMScd}
  \begin{CD}
    \mathrm{SL}(2, 3)
    @>{\overline{\tau}}>>
    \mathrm{GL}(n, \mathbb{C})
    \\
    @V{v}VV  @VV{\pi}V
    \\
    \mathrm{PSL}(2, 3)
    @>>{\tau}>
    \mathrm{PGL}(n, \mathbb{C})
  \end{CD}
$$ From the existence of a cover, we would then be able to immediately conclude what the Schur multiplier of $\mathrm{PSL}(2,3)$ is: it is isomorphic to the subgroup of scalar matrices of $\mathrm{SL}(2,3)$ , which is in turn isomorphic to $\mathbb{Z}_2$ . I am looking for a proof (using methods that a reader of Rotman’s An Introduction to the Theory of Groups can follow) that the highlighted “projective lifting property” above holds.","['group-theory', 'abstract-algebra', 'linear-algebra', 'projective-space']"
4613964,What kind of convergence actually takes place in the definition of ergodicity?,"We say that the stationary time series $(X_t)_{t \in \mathbb Z}$ , , with mean $\mu$ , is mean ergodic if the following converge in probability holds: \begin{equation}\label{a}\tag{M-E}
\hat{\mu}_T := \frac{1}{T}\sum_{t=1}^T X^t \overset{p}{\to} \mu
\end{equation} But, others define ergodicity when the converge in \ref{a} holds for other convergence. For example, here (slide 14) the author uses quadratic mean, and here (slide 5) , almost sure convergence. I know well that quadratic mean convergence and almost sure congergence, each one, implies convergence in probability.  So I have no problem defining mean-ergodicity using quadratic mean  convergence or almost sure. The problem is when it comes to showing that a certain process is not mean-ergodicity. For example, in the same lecture (slides 19 and 20) given above, it shows that it is not mean-ergodic by showing that quadratic mean convergence does not hold. However, it may still hold convergence in probability. I didn't check if in this case the convergence in probability doesn't hold too, but wouldn't it be better to prove the non-convergence in probability to avoid these cases? Which convergence to use when showing no-men-ergodicity?","['time-series', 'stochastic-processes', 'ergodic-theory', 'probability-theory']"
4613968,Area of isosceles triangle,"I need to solve following problem: The vertex of the isosceles triangle $ABC$ is the point $A(-1, 0)$ , and the vertices $B$ and $C$ belong to the parabola $y^2 = 4x$ . If the point $(0, 0)$ is the orthocenter of triangle $ABC$ , then its area is equal to ? I've tried to use fact that points C and B lies on parabola to express their coordinates $B(x,2\sqrt x)$ and $C(x,-2\sqrt x)$ Also i can express height and area of triangle as:
Area = $2\sqrt{x}(x+1)$ .
Height = $x+1$ Can you help me to figure it out ?","['analytic-geometry', 'geometry']"
4613991,Definition of ergodicity and ergodicity for second moments of a stochastic process,"According to this topic , we understand well the relation between the ergodicity for dynamical system and the mean ergodicity of a stochastic process. More exactly, we have the Ergodic Theorem (See page 413 of A. N. Shiryaev ) The following definition is about a random process $(Y_t)_{t \in \mathbb Z}$ where $\gamma_j := E(Y_t - \mu)(Y_{t-j} - \mu)$ , with $\mu=E Y_t$ . But now where does it come in or how do these ergodic concepts of dynamical systems relate to the concept of ergodicity for the second moments?","['time-series', 'stochastic-processes', 'ergodic-theory', 'probability-theory']"
4614000,Prove function property,"Given function $f\colon\mathbb{Z}^+\to\mathbb{Z}^+$ satisfy for every $x$ , $y$ that are positive integers, one and only one among these numbers $$f(x+1), f(x+2),\ldots,f(x+f(y))$$ is divisible by $y$ . Prove that there are infinite many $n$ so that $f(n)=n$ . I have tried to go in a path using contradictions on infinite properties of something relating to this functions. Precisely, I tried to prove that there are finite $n$ so that $f(n)>n$ . This came from the idea that if we chose m so that $f(m)>m$ then each of these groups $$(f(x+1),\ldots,f(x+f(m)),(f(x+f(m)+1),\ldots,f(x+2f(m)),\ldots$$ have one factor that divided by $m$ and each of these have $f(m)>m$ factors so there should be some $f(i)$ that are equal to $f(j)$ . However, this path is way too complicated IMO and can also be wrong in the first assumption. Can you guys help me?",['functions']
4614020,Intersection of projective varieties,"Is there any way to study varieties of the form below $$
X=V\left(\{ f_i,g_j|i\in I,j \in J \right\}) \subset \mathbb{P}^{m+n+1},
$$ where $$
f_i \in k\left[ x_0, \cdots , x_m  \right],\ g_j\in k\left[ y_0, \cdots , y_n  \right].
$$ I want to know the relationship between $ X$ and $X_1= V\left(\{ f_i|i\in I \}\right) \subset  \mathbb{P}^{m}$ , $X_2=V\left(\{ g_j|j\in J \}\right) \subset  \mathbb{P}^{n}$ . For example, if $X_1$ and $X_2$ are irreducible, then so is $X$ or not.(eg. $V\left( x_0x_3-x_1x_2,x_4x_7-x_5x_6 \right)$ corresponds to $\mathbb{P}^1 \times \mathbb{P}^1$ ) Another example I care about is, if we know the Hilbert polynomials of $X_1$ and $X_2$ , can we get the Hilbert polynomial of $X$ ？ I know similar question is ""product"" in case of affine, but I'm confused about projective case. I'm guessing it might be a relationship I haven't learned yet, but I haven't looked it up.I'm sorry if this question seems stupid.","['projective-varieties', 'algebraic-geometry', 'products']"
4614042,Uniform Integrability and Convergence,"I am trying to solve the following problem: A sequence $\{f_n\}_{n \in \mathbb{N}}$ is said to be uniformly integrable in $L(X,d\mu)$ if $$\lim_{t \to \infty}\sup_{n\ge1}\int_{\{|f|>t\}}|f_n| \, d\mu = 0.$$ Now, assume that $\mu(X) < \infty$ and $f_n \to f$ almost everywhere. If $\{f_n\}_{n \in \mathbb{N}}$ is uniformly integrable show that $f \in L(X,d\mu)$ and $$\lim_{n \to \infty}\int_{X}f_n \, d\mu = \int_{X}f \, d\mu.$$ My Intuitive Idea: Since, we have a finite measure space and pointwise convergent functions, we can use Egorov's Theorem to get uniform convergence. This allows us to get a convergence in the integral except for a set of small measure. Then, use uniform integrability to show that the integral over this small measure set vanishes. My Attempt: Fix $\epsilon > 0$ , then there exists a set $E \subset X$ such that $m(X/E) < \epsilon$ and $f_n$ converges $f$ uniformly on $E$ . Then, \begin{equation}
\begin{split}
\lim_{n \to \infty}\int_{X}f_n \, d\mu &= \lim_{n \to \infty}\int_{E}f_n \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \\
&= \int_{E}\lim_{n \to \infty}f_n \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \\
&= \int_{E}f \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu
\end{split}
\end{equation} I do not know how to handle $$\lim_{n \to \infty}\int_{X/E}f_n \, d\mu.$$ My Questions: (1) Am I on the right track? (2) What is the intuitive meaning of uniform integrability? (3) Is the result still true for $\sigma-$ finite measure spaces? Thanks, in advance.","['integration', 'uniform-integrability', 'measure-theory', 'real-analysis']"
4614058,"Calculating $\lim_{n\to\infty}\int_Xn\log(1+\frac{|f|^2}{n^2})\,dm$, where $m$ is a measure on a measurable space $X$, and $f\in L^1(m)$","Let $m$ be a measure on a measurable space $X$ and $f\in L^1(m)$ . How can we calculate: $$\lim_{n\to\infty}\int_Xn\cdot\log\left(1+\frac{|f|^2}{n^2}\right)\,\mathrm{d}m$$ My first thought was to use the DCT for the sequence $f_n(x)= \frac{1}{n}\cdot\log\left(1+\frac{|f(x)|^2}{n^2}\right)^{n^2}$ . We can easily prove that $|f_n|$ is bounded by $|f|^2$ but I cannot show that $|f|^2$ is integrable. Any ideas?",['measure-theory']
4614066,Does there exists infinite point $P$ which divideds a triangle in equal area?,"Given a $\Delta ABC$ , there exists a point $P$ such that $$[ABP]=[ACP]=[BCP]$$ How many such a points $P$ exists?
(Where $ [.]$ represents area) I previously belieced that $P$ is only a single point which is only median. Then after I realized that other points other than median also exists. Then I took a random point $(x,y)$ . And three sides of triangle represented by $(x_i,y_i)$ but I was not able to prove. Can someone help me figure it out?","['coordinate-systems', 'area', 'geometry']"
4614144,"Geometry: A circle inscribed in a triangle with sides lengths of 5, 8 and 9","A friend of mine sent me a geometry question a while ago, but unfortunately neither of us were able to find its source. Anyways, here it is: I had attempted to solve the problem but couldn't get near the answer. However, when I drew it out in Geogebra, I found that the length of the red line was 3. I am hoping that someone might be able to solve the question using geometric approaches or theorems. Any assistance would be greatly appreciated!","['euclidean-geometry', 'triangles', 'geometry']"
4614155,Is it possible to map one “entertaining” puzzle to a graph to consider a solution existence problem?,"There is a puzzle which presents a field with $n$ by $m$ cells. The cells are the parts of the field, and in general, depending on a task, the cells can be united in a square or rectangle or in another geometric figure, for example, in a sequence of rectangles connected by their edges. For simplicity let us consider squired fields with dimension $n$ by $n$ . The cells of the fields in this puzzle are of two types: empty and filled. The empty ones are marked as white, the filled ones – as blue. The empty ones allow walking through themselves, and the filled ones doesn’t allow it, they are like a wall. The goal is to draw a chain of lines following one after another without lifting a pencil. The lines can only be drawn vertically and horizontally until an obstacle meeting. The obstacle will be a filled cell, or an edge of field, or a cell with already drawn a part of the line or lines. It needs to keep going straight until it has met an obstacle. At meeting an obstacle it needs to turn left or right. To start drawing is allowed from any empty cell to any of four directions (up, down, left or right). Let us take a look at the first example: The task is to find a route satisfying the above requirements. Looking over several variants, it can be found the following solution: It can be intuitively supposed that the solution is unique. On starting from another cell to draw a line without lifting a pencil, cells with gaps appear, for instance: Two cells have got empty – without lines. It does not satisfy the conditions above and therefore it cannot be accepted as a solution. Let’s take a look at the second example: This combination of empty and filled cells gives several solutions. Moreover they are presented in pairs: These variants are solutions even at placing the start instead of the finish and vice versa. It is a kind of a “commutativity” between a start and finish. The next ones are symmetric relative to 180 degree rotation. If you, reader, have been interested and attracted by this puzzle and have a wish to try to solve something of that on your own, then the following examples for this purpose: Enumerating intuitively variants at small sizes of fields (5-to-5 for instance), to find solution is not so hard. It is much harder if a size of field presents two, three, four (etc.) digit numbers. At a big size of field, it would effectively be to use an algorithm implemented in a computer program. An algorithm for enumerating variants can be organized in different ways. Hypothetically there can exist such a way that the algorithm organized on it would work more effectively (would be optimized in computational complexity). But it’s another question. I guess it’s much more interested among the community of mathematicians to look at this problem analytically and to try to understand at which conditions of combining empty and filled cells a solution exists. A lot of questions appear afterwards – uniqueness of the solution as well, and others – e.g.: symmetry, rotation. But I suppose that the question about the existence of a solution would be basic. For instance, the following combinations don’t have any solutions (and it is once again the intuitive suggestion): If it could be possible to map such a field into a graph then the graph theory could be applied to this problem and then I guess that the solution existence problem finding could be quite similar to the problem about “Seven Bridges of Königsberg”. Question How do you suppose this problem is solvable in the graph theory?","['graph-theory', 'puzzle', 'discrete-mathematics']"
4614187,Dimension of a topological manifold,"According to Lee's book ""Introduction to topological manifolds"" (also I believe this is the standard way to define it) a topological manifold of dimension $n$ is a second countable Hausdorff space $\mathcal{M}$ such that for every $p \in \mathcal{M}$ there exists an open neighbourhood $U$ of $p$ and a homeomorphism \begin{equation}
\varphi\colon U \to \varphi(U)\subseteq \mathbb{R}^n.
\end{equation} Let us assume $\mathcal{M}$ is such an $n$ -dimensional topological manifold and take any $p\in \mathcal{M}$ . We know based on the definition above that there exists an open neighbourhood $U$ of $p$ and a homeomorphism $\varphi$ into a subset of $\mathbb{R}^n$ .
Now define the map \begin{align}
\tilde{\varphi}\colon U &\to \tilde{\varphi}(U)\\
x &\mapsto \tilde{\varphi}(x):= (\varphi(x),0).
\end{align} Then $\tilde{\varphi}$ is again a homeomorphism and further $\tilde{\varphi}(U) = \varphi(U)\times \{0\}\subseteq\mathbb{R}^{n+1}$ . Thus we can construct a homeomorphism
into a subset of $\mathbb{R}^{n+1}$ . The same manifold $\mathcal{M}$ could be therefore also interpreted to be a topological manifold of dimension $n+1$ . Where is my mistake?
I suppose you could just get rid of all such redundant "" $0$ "" components first and then define the dimension in a sense to be the ""minimal"" one. But I have not found any comment
on this yet.","['manifolds', 'general-topology']"
4614189,Tricky integral in a complex plane,"How to integrate using residues: $$\oint\limits_{|z|=2}\frac{1}{(z^6-1)(z-3)} dz $$ if the idea probably requires to change the sum of 6 residues to aditive inverse of residue at infinity. I believe that the sum of 6 residues is: $$2 \pi i\sum_{i=1}^6 Res_i \frac{1}{(z^6-1)(z-3)}=-2\pi i(Res_{\infty} \frac {1}{(z^6-1)(z-3)}+Res_3 \frac {1}{(z^6-1)(z-3)})$$ because $${3>|z|=2, \infty>|z|=2.}$$ Since $$\frac {1}{(z^6-1)(z-3)} = \frac {1}{(z^7)(1-\frac{1}{z^6})(1-\frac {3}{z})} = \frac {1}{z^7}+ \frac {3}{z^8}+ ...$$ $$=> -2\pi iRes_\infty \frac {1}{(z^6-1)(z-3)}=0$$","['complex-analysis', 'calculus']"
4614221,"Probability that of $5$ cards drawn from a shuffled deck the 1st, 3rd and 5th will be the same suit.","Given a well shuffled deck, what is the probability that the first, third and fifth card will be of the same suit. Initially I was inclined to quickly say $\frac{4 \times {13 \choose 3} \times 49 \times 48}{{52 \choose 5}}$ ( $4$ ways to choose $3$ of the same suit and the rest can be whatever) but clearly the order matters here. So it seems that the simple, brute force way to do it would be a lot of conditioning: i.e, the first card can be whatever. Now condition on whether or not the second card is of the same suit or not. And then each of these above splits into two more conditionals - whether the fourth card is the same suit or not. So you'll have a sum of $4$ probabilities: $\frac{52 \times 39 \times 12 \times 38 \times 11}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 12 \times 11 \times 39 \times 10}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 39 \times 12 \times 11 \times 10}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 12 \times 11 \times 10 \times 9}{52 \times 51 \times 50 \times 49 \times 48}$ This looks about right to me, but I'm guessing there is a sleeker, more compact way to express this? $\frac{4 \times {13 \choose 5}}{{52 \choose 5}} + \frac{4 \times {13 \choose 4} \times {39 \choose 1}}{{52 \choose 5}} \times 2 + \frac{4 \times {13 \choose 3}\times {39 \choose 2}}{{52 \choose 5}}$ This is clearly the same thing as the above, but I guess it makes me uncomfortable - the question very clearly enforces a kind of order, which isn't really being paid attention to in the combinations solution. Perhaps I'm overthinking it. Why can we ignore considerations of order in the expression above, or is it just the wrong solution entirely?","['permutations', 'conditional-probability', 'combinatorics', 'probability-theory', 'probability']"
4614269,"Given the curve $y=\frac{5x}{x-3}$. Find its asymptotes, if any.","Given the curve $y=\frac{5x}{x-3}$ . To examine its asymptotes if any. We are only taking rectilinear asymptotes in our consideration My solution goes like this: We know that, a straight line $x=a$ , parallel to $y$ axis can be a vertical asymptote of a branch of the curve $y=f(x)$ , iff $f(x)\to\infty$ when $x\to a+0$ , $x\to a-0$ or $x\to a$ . Similarly, a straight line $y=a$ , parallel to $x$ axis can be a horizontal asymptote of a branch of the curve $x=\phi(y)$ , iff $x\to\infty$ when $y\to a+0$ , $y\to a-0$ or $y\to a$ . Using these lemmas, we obtain $x=3$ and $y=5$ as the rectilinear asymptotes. This is because, $y=\frac{5x}{x-3}=f(x)$ , then as $x\to 3$ , $f(x)\to \infty$ . Also, since $y=\frac{5x}{x-3}$ , thus, $xy-3y=5x$ or $xy-5x=3y$ , hence $x=\frac{3y}{y-5}=\phi(y)$ . Due to which $\phi(y)\to \infty$ as $y\to 5$ . Now, I tried checking, if there is any oblique asymptote . We know that, $y=mx+c$ , is an oblique asymptote of $y=f(x)$ , iff $\exists $ a finite $m=\lim_{|x|\to\infty}\frac{y}{x}$ and $c=\lim_{|x|\to\infty} y-mx$ . Now, we have the function $y=\frac{5x}{x-3}$ and hence, $\frac{y}{x}=\frac{5}{x-3}$ and hence, $m=\lim_{|x|\to\infty}\frac{y}{x}=\lim_{|x|\to\infty}\frac{5}{x-3}=0$ . Hence, $c=\lim_{|x|\to\infty} y-mx=\frac{5x}{x-3}=\frac{5}{1-\frac 3x}=5$ . So, the oblique asymptote of the given curve is $y=mx+c=5$ , which is same as the horizontal asymptote, parallel to $x-axis$ as shown above. Is the solution correct? If not, where is it going wrong?","['analytic-geometry', 'functions', 'solution-verification', 'algebra-precalculus', 'rational-functions']"
4614304,Clarification in appendix 3 of Ulrich Complex Analysis,"I am reading Complex Analysis by David C. Ulrich. In appendix 3 titled ""Sin, Cos and Exp"", Ulrich defines $\exp , \sin , \cos$ by using the power series. After a few lines, he writes that The absolute convergence of the series shows that the terms can be
rearranged as desired, and it follows that \begin{align} \exp (iz) =
\cos (z) + i \sin (z) \end{align} But it looks to me that rearrangement is not really necessary from this question which I asked on this site. Although it is not necessary, how can it be done? I have tried a lot but I do not see it. Hints are appreciated!","['complex-analysis', 'exponential-function', 'real-analysis']"
4614337,"Let $f,g:X \to Y$ be continuous, $Y$ Hausdorff. Show $\{x:f(x)=g(x)\}$ is closed in $X$.","Let $f,g:X \to Y$ be continuous, $Y$ Hausdorff. Show $\{x:f(x)=g(x)\}$ is closed in $X$ . Here is my attempt. We seek to show $\{x: f(x)=g(x)\}^c \subset X$ is open. That is we aim to show if $x_0 \in \{x:f(x)=g(x)\}^c$ there exists a neighborhood $U$ of $x_0$ such that $U \subset \{x:f(x)=g(x)\}^c$ . If $x_0 \in \{x:f(x)=g(x)\}^c$ then $f(x_0) \neq g(x_0)$ which are in $Y$ who is Hausdorff thus there exists open sets $V,W \subset Y$ that are disjoint with $$f(x_0) \in V, g(x_0) \in W.$$ By continuity of $f$ their pre-images, $f^{-1}(V),f^{-1}(W) \subset X$ are open in $X$ and contain $x_0$ . So do I take the union or intersection of their pre-images  to find my $U$ orrr?? Any hints greatly appreciated. Also, am I going about this the right way?? BTW this is exercise $\S$ $31.5$ out of Munkres.","['continuity', 'general-topology']"
4614360,Defining Open Sets on a topological space,"Let $S$ be a set with continuously many elements, and $\_<\_:\_$ be a three-placed relation such that for any $x,y,z$ in $S$ , $x<y:z$ iff $x$ is closer to $z$ than $y$ is.
Also, by definition, for any $x,y$ and a given $z$ in $S$ , $\neg x<y:z \wedge \neg y<x:z$ if and only if $x \approx y:z$ , or $x$ and $y$ are equally far from $z$ . However, there is no distance definable between any two elements in S. S does not form a metric space. For any given $a$ in $S$ , the following holds for any $x,y,z$ in $S$ : (1) $\neg x<x:a$ (2) If $x<y:a$ , then $\neg y<x:a$ (3) If $x<y:a$ and $y<z:a$ , then $x<z:a$ In this case, what does it mean for a subset of S to be open?
Would the following work? A subset $S^*$ of S is an open set iff $\forall x _{\in S^*}(\forall y_{\in S^*}((x = y)   
 \vee(\exists z(y<z:x))))$ .",['general-topology']
4614386,Integral with gamma function,"Inspired by the limit $$
\lim_{n\to \infty}\frac{\sqrt[n]{n!}}{n} = e^{-1}
$$ and using desmos.com, I plotted the function $$
f(x)=\frac{\sqrt[x]{\Gamma(x+1)}}{x}-\frac{1}{e}
$$ and obtained the result bellow. Don't know why, but I had the feeling that the integral $$
\int_{0}^{\infty}\left(\frac{\sqrt[x]{\Gamma(x+1)}}{x}-\frac{1}{e}\right)dx
$$ would converge. Then I used Wolfram to test it. Here's it's solution: Using desmos.com, I started to test some values for the fraction $\frac{\sqrt[n]{n!}}{n}$ and for values greater than $n=169$ , the computer can't solve, but I know that that the value will converge to $e^{-1}$ , so large values of $n$ shouldn't be a problem. So the problem is the computer, which makes me think that Wolfram suffer the same type of issue. So, is there an analytic way to prove that the integral converges? Does the integral have a closed form? If it does not converge, how can I prove it? Thank you in advance.","['integration', 'improper-integrals', 'gamma-function', 'calculus', 'convergence-divergence']"
4614416,Show $Y_n = f(X_n) \stackrel{P}{\rightarrow} Y=f(0)=1$,"Problem Let $X_n \stackrel{P}{\rightarrow}0,$ where $(X_n)_{n\geq 1}$ is a sequence of real-valued random variables, such that $$P(X_n \neq 0) \rightarrow 0 \: for \: n\rightarrow \infty$$ and let $$f:\mathbb{R} \rightarrow \mathbb{R}$$ such that $$f(x)=\mathbb{1}_{\{0\}}(x)$$ Show $Y_n = f(X_n) \stackrel{P}{\rightarrow} Y=f(0)=1$ Attempt: Using the definition: $$\lim_{n\rightarrow \infty}P(|X_n-X|>\epsilon)=0$$ $$\lim_{n\rightarrow \infty}P(|Y_n-Y|>\epsilon)=\lim_{n\rightarrow \infty}P(|f(X_n)-f(0)|>\epsilon)=\lim_{n\rightarrow \infty}P(|f(X_n)-1|>\epsilon)=\lim_{n\rightarrow \infty}P(|f(X_n)|>\epsilon+1)=\lim_{n\rightarrow \infty}P(|X_n - 0|>f^{-1}(\epsilon+1))=0$$ I don't know if i'm in deep waters with the last equal sign... Am i on the right track?",['probability-theory']
4614418,How to calculate number of spanning trees of $K_5$ with extra vertex on one edge?,"Here we have $K_5$ complete subgraph that gives $5^3 = 125$ spanning trees (using Cayley's formula). Adding one vertex to arbitrary edge, gives me this graph for example. Using Mathematica, it gives me 200 spanning trees. But I don't know how to get this number using simple combinatorics rules etc. What is the simplest method to get the number of spanning trees for this graph? Thanks.","['graph-theory', 'trees', 'discrete-mathematics']"
4614501,"Proving if $v, T(v)\, ..., T^{k}(v)$ are linearly dependent for every $v$, then $I, T, ..., T^{k}$ are linearly dependent.","Suppose $V$ is a finite-dimensional vector space. Take a linear operator $T \in L(V)$ .
Now suppose that we know for every $v \in V$ , the set of vectors $\{v, T(v)\, ..., T^{k}(v)\}$ is linearly dependent. I want to show that this would imply that the set of linear operators $\{I, T, ..., T^{k}\}$ is also linearly dependent. Here are my thoughts so far: Define $A_v = \{ p(x) \in F[x]:p(T)(v)=0\}$ where $F$ is the scalar field of $V$ . Since $A_v$ is an ideal of $F[x],$ there exists a unique monic polynomial $g_v$ , such that $g_v$ generates $A_v$ : $$\langle g_v\rangle=A_v.$$ Now define $G=\{g_v(x): v \in V\}$ . If we take $q(x)=\operatorname{lcm}(G)$ (that is, if such a $q$ exists), then it would suffice to show that $\deg(q(x)) \leq k$ . If that's proven, then $\{I, T, ..., T^{k}\}$ would be linearly dependent. Edit : This statement actually follows from the Cyclic Decomposition Theorem (Linear Algebra (Ed2), Hoffman, Kunze, p233). As a corollary to this theorem, we have that there exists a vector $\alpha \in V$ such that $g_\alpha$ is the minimal polynomial of $T$ (Again, Hoffman, p237). Now by the hypothesis, for this $\alpha$ we have a polynomial $p(x)$ of degree at most $k$ such that $p(T)(\alpha)=0$ . By the definition of $g_\alpha$ , $g_\alpha(x)$ divides $p(x)$ . We also know that $g_\alpha(x)=m_{T}(x)$ . Thus $m_{T}(x)$ divides $p(x)$ and has a degree of at most $k$ . Hence, there exists a polynomial of degree less than or equal to $k$ such that its value at $T$ would be zero, which is equivalent to what we are trying to prove.
Although this completes the implication, I'm hoping to find a more elementary proof. Edit 2: Statement of the Cyclic Decomposition Theorem:
Let $T$ be a linear operator on a finite-dimensional vector space $V$ and let $W_0$ be a proper $T$ -admissible subspace of $V$ . There exist non-zero vectors $\alpha_1, ..., \alpha_r$ in $V$ with respective $T$ -annihilators $p_1, ..., p_r$ such that (i) $V=W_0 \bigoplus Z(\alpha_1; T) \bigoplus ... \bigoplus Z(\alpha_r; T)$ ; (ii) $p_k$ divides $p_{k-1}$ , $k=2, ..., r$ ( $Z(\alpha_i; T)$ is the cyclic subspace of $\alpha_i$ (smallest $T$ -invariant subspace of $V$ including $\alpha_i$ )). Edit 3: By a $T$ -admissible $W$ , we mean a $T$ -invariant subspace such that for every polynomial $f(x) \in F(x)$ , if $f(T)\beta$ is in $W$ , then there exists $\gamma \in W$ such that $f(T)\beta=f(T)\gamma$ . Statement of the CDT corollary: Let $T$ be a linear operator on a finite-dimensional vector space $V$ . There exists a vector $\alpha$ in $V$ such that the $T$ -annihilator of $\alpha$ is the minimal polynomial for $T$ .",['linear-algebra']
4614520,"Convergence of random variables, almost sure and L1","Let $Y_1, Y_2, ...$ be a sequence of random variables such that $Y_n \rightarrow 1 \ \text{a.s.}$ and $\mathbb{E}[Y_n] \rightarrow 1 \ \text{as} \ n \rightarrow \infty.$ I want to prove or disprove the following statement: $\mathbb{E}[|Y_n - 1|] \rightarrow 0 \ \text{as} \ n \rightarrow \infty.$ I think this statement is true. I know that since $\mathbb{E}[Y_n] \rightarrow 1$ , there exists some $C \in \mathbb{R}$ such that $\mathbb{E}[Y_n] < C$ and thus $\mathbb{E}[|Y_n|]$ is bounded, which means that $\mathbb{E}[|Y_n - 1|]$ is bounded. Assume that $\mathbb{E}[|Y_n - 1|]$ is bounded by some constant $D \in \mathbb{R}.$ Let $\epsilon > 0.$ Then, $$\mathbb{E}[|Y_n - 1|] = \mathbb{E}[|Y_n - 1| \mathbf{1}_{|Y_n - 1| \geq \epsilon}] + \mathbb{E}[|Y_n - 1| \mathbf{1}_{|Y_n - 1| < \epsilon}].$$ Thus, $$\mathbb{E}[|Y_n - 1|] \leq D P(|Y_n - 1| > \epsilon) + \epsilon.$$ The right hand side goes to $0.$ However, I am not sure that this works. I feel like the bounded thing I did in the beginning isn't totally valid. Can someone help me? Thanks.","['probability-theory', 'probability']"
4614562,"Is there any other simpler method to evaluate $\int_0^{\infty} \frac{x^n-2 x+1}{x^{2 n}-1} d x,$ where $n\geq 2?$","Though $n\geq 2$ is a real number, which is not necessarily an integer, we can still resolve the integrand into two fractions, $$\displaystyle I=\int_0^{\infty} \frac{x^n-2 x+1}{\left(1+x^n\right)\left(1-x^n\right)} d x=\int_0^{\infty}\left(\frac{x}{1+x^n}-\frac{1-x}{1-x^n}\right) d x=J-K\tag*{} $$ For the integral $J$ , we are going to transforms it into a Beta function by letting $y=\frac{1}{1+x^n}$ . $$\displaystyle \begin{aligned}J & =\frac{1}{n} \int_0^1 y^{-\frac{2}{n}}(1-y)^{\frac{2}{n}-1} d y \\& =\frac{1}{n} B\left(-\frac{2}{n}+1, \frac{2}{n}\right) \\& =\frac{\pi}{n} \csc \left(\frac{2 \pi}{n}\right) \quad \textrm{ (By Euler Reflection Formula)}\end{aligned}\tag*{} $$ Next, we are going to evaluate the integral $ \displaystyle K=\displaystyle \int_{0}^{\infty} \frac{1-x}{1-x^{n}} d x \tag*{} $ by the theorem $ \displaystyle \displaystyle \sum_{k=-\infty}^{\infty} \frac{1}{k+z}=\pi \cot (\pi z), \textrm{ where } z\notin Z.\tag*{} $ We first split the integral into two integrals $$ \displaystyle \displaystyle \int_{0}^{\infty} \frac{1-x}{1-x^{n}} d x=\int_{0}^{1} \frac{1-x}{1-x^{n}} d x+\int_{1}^{\infty} \frac{1-x}{1-x^{n}} d x \tag*{}$$ Transforming the latter integral by the inverse substitution $ x\mapsto \frac{1}{x}$ m, we have $$\displaystyle \displaystyle \int_{1}^{\infty} \frac{1-x}{1-x^{n}} d x=\int_{0}^{1} \frac{x^{n-3}-x^{n-2}}{1-x^{n}} d x \tag*{}  $$ Putting back yields $ \begin{aligned}\displaystyle K&=\int_{0}^{1} \frac{1-x+x^{n-3}-x^{n-2}}{1-x^{n}} d x\\\displaystyle &=\int_{0}^{1}\left[\left(1-x+x^{n-3}-x^{n-2}\right) \sum_{k=0}^{\infty} x^{n k}\right] d x\\ \displaystyle & =\sum_{k=0}^{\infty} \int_{0}^{1}\left[x^{n k}-x^{n k+1}+x^{n(k+1)-3}-x^{n(k+1)-2}\right] d x\\ & =\sum_{k=0}^{\infty}\left(\frac{1}{n k+1}-\frac{1}{n k+2}+\frac{1}{n(k+1)-2}-\frac{1}{n(k+1)-1}\right)\\ & =\sum_{k=0}^{\infty}\left[\frac{1}{n k+1}-\frac{1}{n(k+1)-1}\right]+\sum_{k=0}^{\infty}\left[\frac{1}{n(k+1)-2}-\frac{1}{n k+2}\right] \end{aligned}\tag*{} $ Modifying yields $$\displaystyle \begin{aligned} K&=\frac{1}{n}\left[\sum_{k=0}^{\infty} \frac{1}{k+\frac{1}{n}}+\sum_{k=-1}^{-\infty} \frac{1}{k+\frac{1}{n}}\right]+\frac{1}{n}\left(\sum_{k=1}^{\infty} \frac{1}{k-\frac{2}{n}}+\sum_{k=0}^{-\infty} \frac{1}{k-\frac{2}{n}}\right)\\& =\frac{1}{n}\left(\sum_{k=-\infty}^{\infty} \frac{1}{k+\frac{1}{n}}+\sum_{k=-\infty}^{\infty} \frac{1}{k-\frac{2}{n}}\right)\end{aligned} \tag*{} $$ By the Theorem, $$ \displaystyle \displaystyle \sum_{k=-\infty}^{\infty} \frac{1}{k+z}=\pi \cot (\pi z), \tag*{} $$ where $ \displaystyle z\notin Z,$ we have $$ \displaystyle \displaystyle K=\frac{1}{n}\left[\pi \cot \left(\frac{\pi}{n}\right)+\pi \cot \left(\frac{-2 \pi}{n}\right)\right]=\frac{\pi}{n}\left[\cot \left(\frac{\pi}{n}\right)-\cot \left(\frac{2 \pi}{n}\right)\right] =\frac{\pi}{n} \csc \frac{2 \pi}{n} =J\tag*{} $$ We can now conclude that $\displaystyle \boxed{I=J-K=0 }\tag*{} $ Is there any other simpler method to evaluate $\int_0^{\infty} \frac{x^n-2 x+1}{x^{2 n}-1} d x,$ where $n\geq 2?$","['integration', 'improper-integrals', 'definite-integrals', 'calculus', 'power-series']"
4614577,Prove that the set of all odd integers cubed is a proper subset of the odds,"I'm working through a ""transitions to higher math"" type of book and want to prove the following. (So no abstract algebra, number theory, etc. as the book only assumes up to some simple calculus.) Let $A = \{ (2n + 1)^3 | n \in \mathbb{Z} \}$ and $B = \{ 2n + 1 \vert n \in \mathbb{Z} \}$ . Prove that $A \subset B$ (i.e., $A$ is a proper subset of $B$ ). To show that $A \subseteq B$ , let $x \in A$ . Then $\exists n \in \mathbb{Z}: x = (2n + 1)^3$ . Expand the term and factor to get $x = 2 (4n^3 + 6n^2 + 3n) + 1$ . Since $n$ is an integer, the term in parentheses is as well, say $m = 4n^3 + 6n^2 + 3n$ . Then $x = 2m + 1$ and so $x \in B$ . To show that $A$ is a proper subset, I must also show that $A \neq B$ . This amounts to showing that $\exists b \in \mathbb{Z}: b \in B \land b \notin A$ . Suppose $n = 1$ . Then $b = 2n + 1 = 3$ and $3 \in B$ . We claim that $3 \notin A$ . Suppose otherwise. Then $\exists m \in \mathbb{Z}: 3 = (2m + 1)^3$ . $$
\begin{align}
3 & = (2m + 1)^3 \\
& = 8m^3 + 12m^2 + 6m + 1 \\
\iff 2 & = 2(4m^3 + 6m^2 + 3m) \\
\iff 1 & = 4m^3 + 6m^2 + 3m \\
\iff 1 & = m(4m^2 + 6m + 3) \\
\end{align}
$$ For the last equation to be true, we must have both $m = 1$ and $4m^2 + 6m + 3 = 1$ . If we set them equal to one another, after some algebra we get $4m^2 + 5m + 3 = 0$ . Simple execution of the quadratic formula shows that $m$ (both solutions) is complex, contradicting our assumption that $m \in \mathbb{Z}$ . Is this a correct proof? Is there a simpler or more elegant solution?","['algebra-precalculus', 'solution-verification']"
4614625,onto functions disproving method,"Let $f: \mathbb R^* \to \mathbb R$ with $f(x) = \frac{x+1}x,$ where $\mathbb R^*$ is the set of all real numbers different from zero. Determine whether or not $f$ is an onto function. I know that this is not onto. But how do I go about disproving it in a formal way. I know the range does not contain the element $1$ whilst the codomain does. And since the codomain is not equal to the range the function is not onto. But like I said how do I formally disprove it??",['functions']
4614693,"For any $\epsilon>0$, there exists arbitrarily large $x$ with $\cos( x^2)>1-\epsilon$ and $\cos[ (x+1)^2]<-1+\epsilon$","For any $\epsilon>0$ , there exists arbitrarily large $x$ with $\cos (x^2)>1-\epsilon$ and $\cos [(x+1)^2]<-1+\epsilon$ . This is an exercise in ""Uniform Distribution of Sequences"" by Kuipers, Niederreiter. If I remember correctly, I may have been given a hint that we need to use the fact that the sequence $\left\{\frac {n^2}{2\pi}\right\}_{n=1}^\infty$ is uniformly distributed modulo $1$ (although I'm not sure whether this was indeed the hint), but I can't figure out how to use that. Also, since this question sounds like a question from Calc I, is there a way to solve this using only properties of the cosine function without using results from Uniform Distribution of sequences? Note: AlvinL posted this link which does look like the first half of this question, but we should note that this question asks to prove that there are arbitrarily large $x$ which simultaneously satisfy the two given conditions.","['ergodic-theory', 'equidistribution', 'real-analysis']"
4614700,Prove $|f(y) − f(x)| \leq f(|y − x|)$ if $|y − x| ≤ 1/2$ given $f(x)=-x\log_2 x$,"How do I prove that whenever $|y − x| ≤ 1/2$ it follows that $|f(y) − f(x)| \leq f(|y − x|)$ given $f(x)=-x\log_2 x$ ? where $x,y\in[0,1]$ The graph of $f(x)=-x\log_2 x$ function is $$
f'(x)=-\log x-\frac{x}{x\ln 2}=-\log x-\frac{1}{\ln 2}=0\implies \log x=-\frac{1}{\ln 2}\\
\frac{\ln x}{\ln 2}=-\frac{1}{\ln 2}\implies \ln x=-1\implies x=1/e\approx 0.3679
$$ I was only able to write the following proof: When $0\le x\le y\le 1$ , \begin{align}
|f(x)-f(y)|&=|-x\log x+y\log y|\\
&=|-x\log x+\frac{x}{\ln 2}+y\log {y}-\frac{y}{\ln 2}+\frac{y}{\ln 2}-\frac{x}{\ln 2}|\\
&\leq |-(x\log x-\frac{x}{\ln 2})+(y\log y-\frac{y}{\ln 2})|+\frac{|y-x|}{\ln 2}\\
&=|\int_x^y \log tdt|+\frac{|y-x|}{\ln 2}=-\int_x^y \log tdt+\frac{|y-x|}{\ln 2}\\
&=-\int_x^{x+(y-x)} \log tdt+\frac{|y-x|}{\ln 2}\\
&\leq -\int_0^{y-x} \log tdt+\frac{|y-x|}{\ln 2}\\
&=-\Big(t\log t-t\Big)_0^{y-x}+\frac{|y-x|}{\ln 2}\\
&=-(y-x)\log(y-x)+(y-x)+\frac{|y-x|}{\ln 2}\\
&=f(|y-x|)+|y-x|+\frac{|y-x|}{\ln 2}
\end{align} My Attempt Thanks @Balajisb for the hint. If $f$ is a concave function then $f(a+b)\leq f(a)+f(b)$ for all $a,b>0$ $$
-y\log y=-(y-x+x)\log(y-x+x)\le-(y-x)\log(y-x)-x\log x\\
-y\log y-(-x\log x)\le -(y-x)\log(y-x)\\
f(y)-f(x)\le f(y-x)
$$ $$
D_{\log x}\in(0,\infty]\implies x,y,y-x\geq 0\implies 1\ge y>x>0\\
$$ $$
1>y-x>0\implies -(y-x)\log(y-x)>0
$$ $$
f(y)-f(x)\le f(|y-x|) \;\forall\;(x,y)\;|\;y>x>0\\f(x)-f(y)\le f(|y-x|) \;\forall\;(x,y)\;|\;x>y>0
$$ Therefore, $$
|f(y)-f(x)|\le f(|y-x|) \;\forall\;(x,y)\;|\;y>x>0\;\&\;f(y)>f(x)\\|f(y)-f(x)|\le f(|y-x|) \;\forall\;(x,y)\;|\;y<x<0\;\&\;f(y)<f(x)
$$ In order to prove $|f(y)-f(x)|\le f(|y-x|) \;\forall\;x,y>0$ we need to also consider the cases $y>x>0\;\&\;f(y)<f(x)$ and $x>y>0\;\&\;f(x)<f(y)$ . So I think that's where the condition $y-x\leq 1/2$ lies in. Case 1 : $y>x>0\;\&\;f(y)<f(x)$ $$
-y\log y<-x\log x\implies y\log y>x\log x\\
x\log x-y\log y<0\\x\log x-\frac{x}{\ln 2}-y\log y+\frac{y}{\ln 2}-\frac{y-x}{\ln 2}<0\\
\int_y^x \log t dt-\frac{y-x}{\ln 2}>0\\
y-x<\ln 2\int_y^x \log t dt=-\ln 2\int_x^y \log t dt=-\ln 2\int_x^y \frac{\ln t}{\ln 2}dt=-\int_x^y \ln t dt\\
<-\int_0^1 \log t dt=-1\times -1=1
$$ How do I obtain the condition $y-x\leq 1/2$ in this case ?","['information-theory', 'calculus', 'logarithms', 'inequality']"
4614754,Prove that $\lim_{x \to \infty} \frac{f(x)}{x}$ exists [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question This is a problem that has been asked in an old analysis 1 exam. I can't find it anywhere else online. Let $f$ be twice differentiable on $(1,\infty)$ such that $f\geq 0$ and $f''\leq 0$ . Show that $\lim_{x \to \infty } \frac{f(x)}{x} $ exists. I think you have to show that $\frac{f(x)}{x}$ is decreasing using the MVT, but I don't know how to do it.","['limits', 'derivatives', 'real-analysis']"
4614768,Quasi-coherent $\mathcal{F} \cong \tilde{M}$ on $\operatorname{Proj}B$ does not determine $M$,"I would like to understand in detail the fact that given $\tilde{M}\cong \tilde{N}$ on $\operatorname{Proj}B$ , then it is not always true in general that $M \cong N$ . I know this has to do with playing with the grading; so, as I understand, one fixes a $K\in \mathbb{N}$ and considers $N = \sum_{k \geq K} M_k$ and then proves that: i) $N$ is not isomorphic to $M$ , because in degrees $d<K$ one has $N = 0$ ; ii) one proves $\tilde{M} \cong \tilde{N}$ because for every homogenous element $f$ , one has $$\tilde{M}(D_+(f))=M_{(f)}\cong N_{(f)}=\tilde{N}(D_+(f))$$ Although I can buy it intuitively, I am bit lost on the concrete and specific details of this though. Can someone explain to me this example? Ps. This example is taken from Q. Liu's book (remark 1.18, 5.1.4), where he works with two abstract graded modules $M$ and $N$ , so the argument should work in this generality, and I would like to understand it this way.","['quasicoherent-sheaves', 'schemes', 'projective-schemes', 'algebraic-geometry', 'arithmetic-geometry']"
4614829,$\lim\limits_{x\to \infty}\frac{3x^3+x^2+\sin(e^x)}{5x-8x^3+\arctan(\log x)} $,"Compute the limit: $$\lim_{x\to \infty}\frac{3x^3+x^2+\sin(e^x)}{5x-8x^3+\arctan(\log x)} $$ I worked out this to be $\frac{-3}{8}$ . I believe this is correct. I used the sandwich theorem but my issue is that the denominator is sometimes negative which isn't helping me. I tried to use absolute values to get rid of this problem: $$\frac{3x^3+x^2+\sin(e^x)}{5x-8x^3+\arctan(\log x)} \leq \frac{3x^3+x^2+1}{5x-8x^3-\frac{\pi}{2}},$$ which I then could show is $\frac{-3}{8}$ using algebra of limits, but I am certain this is wrong. My other way of thinking is: $$\frac{3x^3+x^2+\sin(e^x)}{5x-8x^3+\arctan(\log x)} = \frac{3+\frac{1}{x}+\frac{\sin(e^x)}{x^3}}{\frac{5}{x^2}-8+\frac{\arctan(\log x)}{x^3}} 
$$ Note that $-1 \leq \sin(e^x) \leq 1$ , so for all $x>0$ , we have $\frac{-1}{x^3} \leq \frac{\sin(e^x)}{x^3} \leq \frac{1}{x^3}$ , so the limit is $0$ . Note that $\frac{-\pi}{2x^3} \leq \frac{\arctan(\log x)}{x^3} \leq \frac{\pi}{2x^3}$ , so the limit is $0$ . Now by taking limits: $$\frac{3+\frac{1}{x}+\frac{\sin(e^x)}{x^3}}{\frac{5}{x^2}-8+\frac{\arctan(\log x)}{x^3}} =\frac{3+0+0}{0-8+0} = -\frac{3}{8}.$$ I believe my second way of working is correct. Can someone please tell me if I am right ? Also, is there a way of doing with this with absolute values ?","['limits', 'analysis', 'real-analysis']"
4614838,"Using the implicit function theorem for a function $f(x,y,z)$ , what if $\frac{\partial f}{\partial (y,z)} $ is not a square matrix?","I want to use the implicit function theorem for a function $f:\mathbb{R}^3\rightarrow \mathbb{R}$ .
The set $M\subset \mathbb{R}^3$ is defined by the equation $f(x,y,z)=\text{function rule}=0$ for every $(x,y,z) \in M$ . I need to show that the equation $f(x,y,z)=0$ is locally solvable for one of the variables $x,y,z$ at every point of a set $M\subset \mathbb{R}^3$ i.e. if there exist a neighborhood $U\subset \mathbb{R}$ of $x$ and a continuous differentiable function $g: U\rightarrow \mathbb{R}^2$ with $g(x)=(y,z)$ and $f(x,g(x))=0$ for every $x\in U$ The best tool I have for this is the implicit function theorem : But if I calculate $$\frac{\partial f}{\partial (y,z)} =\begin{pmatrix}\frac{\partial f}{\partial (y)} (x,y,z)&,&\frac{\partial f}{\partial (z)} (x,y,z)\end{pmatrix}$$ I get a $1\times 2$ -Matrix of the form , so the Matrix cannot be invertable because $\frac{\partial f}{\partial (y,z)} $ is not a square matrix. It would only make sense to me if $\frac{\partial f}{\partial (z)}(x,y,z)=0$ for every $(x,y,z)\in M$ but that is not the case. Did I misunderstand the exercise and/or the meaning of the IFT? $(*)$ The function $f$ is part of a homework exercise. I don't want to post the function rule here because my question is more general and I have some reservations about posting homework questions online.
I hope my question is still clear.","['multivariable-calculus', 'implicit-function-theorem', 'real-analysis']"
4614839,Find number of solutions of the equation $2\sin|x|-x=0$,Find number of solutions of the equation $$2\sin|x|-x=0$$ This was asked in asked in my mock exam. My two friends said that the answer was $3$ justifying it from the theory of graphs. I just gave $1$ as the answer as I am not well versed with graphs. But wolframaplha is showing that there are only two solutions of the above equation one being $0$ and the other is $\approx 1.89$ Who is correct and who isn't $?$ How to find their number $?$ Should I take help from graphs or is there some method in calculus for this $?$,"['calculus', 'trigonometry']"
4614865,A typo or not in principles of Algebraic Geometry on page 29. (by Griffiths and Harris),"When I read page 29 of principles of algebraic geometry , it claims that any real differential form $\omega$ of type $(1,1)$ gives a hermitian form $H(\ ,\ )$ on each tangent space. The form $H$ will be positive definite if and only if for any $v\in T_z'(M)$ , $$
\sqrt{-1}\cdot \langle \omega(z),v\wedge \bar{v}\rangle>0. 
$$ I think this may be $<0$ ? Can anyone help about this? Thanks in advance.","['complex-geometry', 'algebraic-geometry']"
4614874,Solving $\sum_{m=1}^{11}\frac{1}{\sin(\theta+(m+1)\pi/4)\sin(\theta+m\pi/4)}=4\sqrt2$,For $0<\theta<\frac{\pi}{2}$ find all solutions of the equation $$\sum_{m=1}^{11}\frac{1}{\sin\left(\theta+\frac{(m+1)\pi}{4}\right)\sin\left(\theta+\frac{m\pi}{4}\right)}=4\sqrt2$$ I highly believe that this is a telescopic series but even after doing a lot of labour I couldn't find one. I tried using the method of differences but then I couldn't handle the expressions in the numerator. I tried it by breaking it into $$-\frac{k}{\sin\left(\theta+\frac{(m+1)\pi}{4}\right)}+\frac{k}{\sin\left(\theta+\frac{m\pi}{4}\right)}$$,"['trigonometry', 'sequences-and-series']"
4614881,Probability that the sum of $n$ unit vectors (2D dimention) has length less than one,"It is easy to show that the probability that the length of the sum of two random unit vector in a 2D-plane is less than one is $\frac13$ . As the picture above, assume the first vector is $\bar{AB}$ (by symmetricity, the direction of first vector could be any), and the second vector is any radius of circle B. So only when the head of the 2nd vector is in the red arc, the length of sum vector is less than 1. So the probability is $\frac13$ . Using a computer, it seems that the probability of the length of the sum of n random unit vectors being less than one is $\frac1{n+1}$ . #include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <math.h>

int n=5;
int m=10000;
int main(int argc, char *argv[]){
        if(argc>=2){
            n=atoi(argv[1]);
        }
        if(argc>=3){
                m=atoi(argv[2]);
        }
        srand(time(NULL));
        printf(""Test %d jump (total %d times)\n"",n,m);
        int i,j;
        int c=0;
        for(i=0;i<m;i++){
                double sx=0.0,sy=0.0;
                for(j=0;j<n;j++){
                        double t=rand();
                        sx+=cos(t);
                        sy+=sin(t);
                }
                if(sx*sx+sy*sy<=1.0){
                        c++;
                }
        }
        printf(""%d times in circle (ratio %f)\n"", c, (double)c/m);
        return 0;
} $ ./sa 5 1000000
Test 5 jump (total 1000000 times)
166728 times in circle (ratio 0.166728)
$ ./sa 5 10000000
Test 5 jump (total 10000000 times)
1667138 times in circle (ratio 0.166714)
$ ./sa 7 10000000
Test 7 jump (total 10000000 times)
1248881 times in circle (ratio 0.124888)
./sa 7 10000000
Test 7 jump (total 10000000 times)
1249432 times in circle (ratio 0.124943)
./sa 9 10000000
Test 9 jump (total 10000000 times)
1001222 times in circle (ratio 0.100122)
./sa 9 10000000
Test 9 jump (total 10000000 times)
999595 times in circle (ratio 0.099960) That's,
given n i.i.d random variables $x_k$ which are uniform distributed in [0,1), could we prove that $P(\left|\sum_{k=1}^n \exp(2\pi i x_k)\right|<1)=\frac1{n+1}$ .","['geometric-probability', 'probability']"
4614970,Prove limit $\lim\limits_{n\to\infty} \frac{2^{2n+1} \cdot r^{2n} \pi^n \cdot n!}{(2n+1)!} = 0$,I would like to prove that $\lim\limits_{n\to\infty}\dfrac{2^{2n+1} \cdot r^{2n} \pi^n \cdot n!}{(2n+1)!}=0$ I have thought of De L'Hospital but that would require me to differentiate the gamma function which doesn't seem very helpful.,"['limits', 'factorial']"
4614973,Is the canonical bundle of a projective complex surface an ample bundle if its self-intersection is positive?,"Let $X$ be a projective complex surface ( $\dim_\mathbb C X = 2$ ). If $(K_X, K_X) > 0$ , is it true that $K_X$ is an ample line bundle? I am trying to the affirmative answer using Nakai's criterion, which says that a line bundle $L$ on a compact surface is ample iff $(L,L)>0$ and $(L,D) > 0$ for every effective divisor $D$ on $X$ . By Riemann-Roch we have that $$ \dim H^0(X, O_X(D)) + \dim H^0(X, O_X(-D) \otimes K_X) - \dim H^1 (X, O_X(D) ) =  \chi(X) + 1/2( (D, D) - (D,K_X) )$$ I'm not sure where to go from here, or if RR helps at all.","['complex-geometry', 'algebraic-geometry', 'line-bundles']"
4615012,Measurable Projection Theorem and the Debut Theorem,"The measurable projection theorem (see the George Lowther blog ) asserts the following. Theorem. If $(\Omega,\mathcal{F},\mathbb{P})$ is a complete probability space and $A\in\mathcal{B}(\mathbb{R})\otimes\mathcal{F}$ then $\pi_{\Omega}(A)\in\mathcal{F}$ , where $\pi_{\Omega}:\mathbb{R}\times\Omega\rightarrow\Omega$ is defined as $\pi_{\Omega}(x,\omega)=\omega$ . In the same post , the author uses the theorem to prove this version of the Debut theorem: Theorem. Let $A\subseteq [0,\infty)\times\Omega$ be a progressively measurable set and let the filtration be right-continuous. Then its debut time $$
T_A(\omega) = \inf\{t\in[0,\infty) | (t,\omega)\in A \}
$$ is a stopping time. The proof proceeds in this way. First note that $$
\{ T_A<t \} = \pi_{\Omega}\left([0,t)\times\Omega \bigcap A\right),
$$ which is easy to be verified, for example with a graphical representation. By the measurable projection theorem, being, by progressive measurability, $A\in \mathcal{B}([0,t])\otimes\mathcal{F}_t$ ,  we have that the projection $\{T_A<t\}\in\mathcal{F}_t$ , so $T_A$ is optional. Having assumed the right-continuity of the filtration this is enough to guarantee that $\{T_A\leq t\}\in\mathcal{F}_t$ , so $T_A$ is a stopping time. My problem is, couldn't we just say that $$
\{ T_A\leq t \}  = \pi_{\Omega}\left([0,t]\times\Omega \bigcap A\right)\in\mathcal{F}_t 
$$ and remove the hypothesis of right-continuity? ps = I guess that in the Debut theorem we also have to assume that the filtration $\mathcal{F}_t$ is complete for all $t$ , otherwise the measurable projection theorem cannot be used.","['stochastic-processes', 'measure-theory', 'stopping-times', 'projection']"
4615040,"Showing that a sequence is Cauchy on $C[0,1]$.","Let $$f_k(t) = \begin{cases}0, \text{ if } t \in [0,1/2]\\
1, \text{ if } t \in [1/2 + 1/k, 1].\end{cases}$$ We will prove the sequence $(f_k)_{k \in \mathbb{N}}$ is Cauchy on $(C[0,1],\|\cdot\|_p)$ for $1 \leq p < \infty$ . (this can also be done for $\infty$ but for the sake of the exercise we shall omit that case). Notice that \begin{align}
\|f_n-f_n\|_p & = \left(\int_0^1|f_n(t)-f_m(t)|^pdt\right)^{1/p}\\
& \leq 2\left(\int_{1/2+1/n}^1|f_n(t)|^pdt - \int_{1/2 + 1/m}^1|f_m(t)|^pdt\right)^{1/p}\\
& \leq 2\left(\int_{1/2+1/n}^1dt - \int_{1/2+1/m}^1dt\right)^{1/p}\\
& \leq 2\left(1-1/2-1/n - 1 + 1/2 + 1/m\right)^{1/p}\\
& = 2\left(\frac{1}{m} - \frac{1}{n}\right)^{1/p}.
\end{align} And when $n,m \rightarrow \infty$ we have $\|f_n-f_m\| \rightarrow 0$ . Rigorously, we could pick $N > 0$ so that when choosing $n>m\geq N$ we have $1/m-1/n < \epsilon$ . Can anyone verify if my reasoning is correct? Thanks in advance!!","['complete-spaces', 'functional-analysis']"
4615055,Dual statement to the fundamental theorem of group homomorphism?,"Let $G$ and $H$ be groups. The fundamental theorem of group homomophism states that, for any surjection $f : G \to H$ , there exists an isomorphism $\eta : G/\text{ker}(f) \to H$ . I am wondering if there exists a dual statement to this theorem: starting with an injection $f : G \to H$ . It would be interesting to see $\text{im}(f)$ (or the cokernel of some map) appearing instead of $\text{ker}(f)$ , in some way. I've read that surjections and injections exist in opposite categories; I've thus tagged 'category theory', for potential reasoning in this area.","['group-homomorphism', 'category-theory', 'linear-algebra', 'group-theory', 'commutative-algebra']"
4615069,"If $K≤H≤G$, $[H:K] = n$, and $\{H': H≤H'≤G\}$ finite, does the same hold for $K$?","Let $G$ be a group and $K≤H≤G$ be subgroups such that $[H:K]=n$ $[H, G]_{\mathrm{sub}} = \{H' | H≤H'≤G\}$ is finite, Question: Do we necessarily have that there are only finitely many subgroups between $K$ and $G$ as well? If we use the correspondence between stabilizer supergroups and superblocks, we can note In the (transitive) action $G\curvearrowright G/K$ , we have that $K=G_{1K}$ , the stabilizer of the coset $1E$ $H$ corresponds to the finite block $G_{H/K}$ consisting of its cosets there are only finitely many blocks $ℬ\supseteq G_{H/K}$ . Question: Can we already deduce that there are only finitely many blocks $ℬ'\supseteq \{1E\}$ ?
If not, is there a counterexample? I've tried to see whether I can find a characterization for when $H'_1, H'_2$ both generate the same subgroup when adjoining $H$ in hopes there could be only finitely many such $H'_i$ , but I've gotten nowhere. I apologize if there is a trivial counterexample I overlooked.","['permutations', 'group-theory']"
4615115,Convergence of discrete eigenvalues of the heat equation,"Consider the eigenvalue problem associated with the heat equation \begin{equation}
\phi''(x) = \lambda \phi(x), \qquad \phi(0)=\phi(1)=1.
\end{equation} Whilst the eigenvalues can be calculated analytically, I want to calculate them numerically. To do this, consider the finite difference approximation \begin{equation}
\frac{\phi^{i+1}-2\phi^i+\phi^{i-1}}{h^2}=\lambda \phi^i
\end{equation} where $i=1,...,N+1$ and $h=1/N$ . This can be assembled into the matrix-vector form \begin{equation}
\boldsymbol{A}\boldsymbol{\phi} = \lambda \boldsymbol{\phi}
\end{equation} such that $\boldsymbol{\phi} = \big(\phi^2,...,\phi^j,...,\phi^N)^T$ and $\boldsymbol{A} $ is a tri-diagonal matrix of size $(N-1)\times (N-1)$ with $-2/h^2$ on the diagonals and $1/h^2$ on both the lower and upper diagonals. To find the eigenvalues, I use the $\texttt{eig}$ function in matlab, i.e. $\texttt{eig}(A).$ My issue is the following. As I increase $N$ (consequently decreasing the step size, $h$ ) my eigenvalues do not converge. I have attached a figure illustrating the eigenvalues for $N=100, N=200$ and $N=300$ . Why do the eigenvalues not converge? Is there something fundamentally wrong with my formulation, or is there a rational step that I'm missing that maps the eigenvalues calculated numerically to their continuous spectum? I have also found that my eigenvalues diverge like $1/h^2$ as I decrease $h$ .","['linear-algebra', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
4615148,Solve the equation $\log_{1-2x}(6x^2-5x+1)-\log_{1-3x}(4x^2-4x+1)=2$,"Solve the equation $$\log_{1-2x}(6x^2-5x+1)-\log_{1-3x}(4x^2-4x+1)=2$$ We have $$D_x:\begin{cases}1-2x>0\\6x^2-5x+1>0\\1-3x>0\\1-3x\ne1\\4x^2-4x+1>0\iff(2x-1)^2>0\iff x\ne\dfrac12\end{cases}\iff x\in(-\infty;0)\cup(0;\dfrac{1}{3})$$ Also the quadratic $6x^2-5x+1$ factors as $(2x-1)(3x-1)$ . The equation then becomes $$\log_{1-2x}(2x-1)(3x-1)-\log_{1-3x}(2x-1)^2=2\\\log_{1-2x}(2x-1)(3x-1)-2\log_{1-3x}(1-2x)=2,$$ as $\log_{1-3x}(2x-1)^2=2\log_{1-3x}|2x-1|,$ but we know from $D_x$ that $2x-1<0$ , $$\log_{1-2x}(2x-1)+\log_{1-2x}(3x-1)-\dfrac{2}{\log_{1-2x}(1-3x)}=2$$ I don't know what to do next.",['algebra-precalculus']
4615171,Does there exist a set $Y$ such that $Y \cong \Sigma^Y$ for a fixed set $\Sigma$?,"Suppose $\Sigma$ is a set.  I'm wondering if there exists a set $Y$ such that $Y \cong \Sigma^Y$ ?  Can this set be constructed as some kind of limit in Set ?  In which kinds of categories is such a construction possible?  If the answer to any of the above is yes, is there somewhere I can read more about this?","['elementary-set-theory', 'category-theory']"
4615177,Is a weak* limit of a sequence of tempered distributions indeed a tempered distribution?,"The question is as in the title. Let $\{ T_n \}$ be a sequence of tempered distributions such that $\{ T_n(f) \}$ converges for every Schwartz function $f$ . Let us denote the ""pointwise"" or weak* limit as $T(f)$ . Then, is $T$ a tempered distribution? Of course it is a linear functional on the Schwartz space, but I cannot see how to show temperedness. It seems quite confusing and nontrivial. Could anyone please clarify?","['functional-analysis', 'distribution-theory']"
4615247,Prove $\det((AB)^{n}-(BA)^{n})$ is a perfect cube.,"We have $A,B$ two $3×3$ matrices with integer numbers. We know that $(AB)^{2}+BA=(BA)^2+AB$ . a) Show that $\det((AB)^{n}-(BA)^{n})$ is divisible by $det(AB-BA)$ . b) Show that if $\det(AB-BA)=1$ , then $\det((AB)^{n}-(BA)^{n})$ is a perfect cube. I have tried taking the trace in the first  equality but nothing interesting. Maybe will help us rewriting $\det(AB-BA)$ as $Tr((AB-BA)^{3})/3$ ? It feels like we need to use some induction here but I dont know what is the ""induction general form"". I see we can rewrite $\det(AB-BA)=\det((AB)^{2}-(BA)^{2})$ . I think that perfect cube will come from a determinant rewriting in polynomial form, but I dont know how we can rewrite it as a polynomial.","['determinant', 'cayley-hamilton', 'matrices', 'characteristic-polynomial', 'matrix-decomposition']"
4615268,Some good books for ODE and Dynamical system.,"I am trying to shift my research area from Pure math to math bio for various reasons. So whatever time I invested in my algebra is not of much use plus I have to make the basics of ODE and the Dynamical system strong. I was reading Teschl's book on ODE and the Dynamical system and I felt it very hard to have a good hold on the base concept while reading the book. It is not the case that I don't understand it. Rather I can't grasp the inner concept well. I didn't read Strogatz Nonlinear Dynamics before but now I am enjoying it. Is there any other ODE-Dynamical system(if it is focused on oscillation theory that's a plus) undergraduate to graduate level bridging book and some books that give a deeper insight in an easier way and make the concept and problem-solving skills clearer? In pure math there are some books that state learning through problems and they try to build the conception with a series of easy problems. You can also refer to those books. This will be of great help because I believe in making my base strong. Please don't suggest me a hard book. When I am finding Teschl hard and Strogatz good. You can get an idea. E.g. I liked one undergraduate thesis on Floquet theory very helpful. It will be good if I get some easy to moderate to hard problems to solve with hints. What I really care for is learning about Existence,uniqueness, regularity
Sturm Liouville, Sturm comparison theorems
Linear stability, Liapunov stability, Hamiltonian, gradient systems
Poincare bendixson theorem
Some basic dynamical systems like omega limit sets
Floquet Theory
Linear ODEs etc etc.","['ordinary-differential-equations', 'book-recommendation', 'reference-request', 'mathematical-biology', 'dynamical-systems']"
4615275,Proof verification that the Hahn Banach theorem equivalent to existence of a finitely additive measure for boolean algebra over ZF,"Exercise 2.6.19 of Jech's Axiom of choice asks to show that the Hahn Banach theorem is equivalent to the existence of a real valued measure for all Boolean algebras over $ZF$ . This is a sketch at my attempt: Assuming the Hahn Banach theorem holds. And let $B$ be a boolean algebra, without choice we have that there is some set $S$ and a subalgebra $P\subseteq \mathcal{P}(S)$ such that there is a surjective homomorphism $h:P\rightarrow B$ . Consider the space $\ell^\infty(S)$ then I have that $g:\mathcal{P}(S)\rightarrow \ell^\infty(S)$ where each set is sent to its characteristic function. We can consider the subspace generated by $E=\text{span}(g(P))$ and it's subspace $H=\text{span}(g(\text{ker}(h)))$ Then we have a space $E/H$ which is a vector space and there is an inclusion of $B$ in $E/H$ . Consider the map that sends $1+H$ (the quotient class of the constant 1) to $1\in \mathbb{R}$ then by Hahn Banach it is extended to all of $E/H$ . We need to assure that the function it extends to is a measure so we need the image of $B$ to be sent to $[0,1]$ to this end I define $p(f)$ to be $0$ if $f\in -\text{span}(B)$ and $p(f)=\|f\|_{\infty,E/H}$ otherwise. This function is subadditive and any extension that is dominated by $p$ will induce a finitely additive measure on $B$ . As for the other direction we have that over $ZF$ the Hahn Banach theorem is equivalent to showing every Banach space has a non $0$ functional. I believe every Banach space can be embedded in some $L^\infty(X,\mathcal{A},\mu)$ . The dual of $L^\infty(X,\mathcal{A},\mu)$ is the set of finitely additive signed measures on $\mathcal{A}$ that are absolutely continuous with respect to $\mu$ but by assumption $\mathcal{A}/null(\mu)$ is a Boolean algebra and it will have a finitely additive measure which is non trivial. Is this correct? Edit: The second part is not correct since the embedding into $L^\infty $ requires Hahn Banach from what I recall Edit: I actually managed to find a proof out there which is different than mine. I will add it to this question for completeness. Let $B$ be a boolean algebra and consider the meet semilattice of the partitions of $B$ where $Q\leq P$ if $Q$ refines $P$ . Observe that a function $f:P\rightarrow \mathbb{R}$ can be extended to $f_Q:Q\rightarrow \mathbb{R}$ naturaly by setting $f_Q(q)=f(p)$ where $p\in P$ is the unique element such that $q\leq p$ . We define $S(B)=\{f:P\rightarrow \mathbb{R}: P \text{ is a partition of } B\}/\sim$ where $\sim$ is the relation where given $f:P\rightarrow \mathbb{R}$ and $g:Q\rightarrow \mathbb{R}$ we set $f\sim g$ iff $f_{Q\wedge P}=g_{Q\wedge P}$ . This has a natural structure as a vector space. We can endow $S(B)$ with the upper limit norm or $\|f\|=\sup_{p\in P}f(p)$ which is easy to verify is well defined on the equivalence classes. We can identify $b\in B$ to the function $f:\{b,b^c\}\rightarrow \mathbb{R}$ where $f(b)=1$ and $f(b^c)=0$ . We see that a finitely additive measure $m$ on $A\subseteq B$ will define on $E=\{f\in S(B): \text{dom}(f)\subseteq A
\}$ (to be more precise the classes that have a representative with domain contained in $A$ ) we define $\varphi:E\rightarrow \mathbb{R}$ to be the function $\varphi(f)=\sum_{p\in \text{dom}(f)}f(p)m(p)$ since $m$ is finitely additive it is easy to verify that its well defined on the equivalence classes. We can extend such a function to all of $S(B)$ by Hahn Banach so that it is still of norm $1$ and it will define on $B\subseteq S(B)$ a finitely additive measure. Source: ""EL TEOREMA DE HAHN-BANACH COMO PRINCIPIO DE ELECCIÓN"" by Xavier Caicedo & Germán Enciso","['axiom-of-choice', 'solution-verification', 'functional-analysis', 'hahn-banach-theorem']"
4615317,Why is this linear map $\mathrm d f_p: T_p M \rightarrow T_{f(p)} N$ unique?,"Given an $m$ -dimensional manifold $M$ and $p \in M$ , a tangent vector of $M$ at $p$ is any function $$
v:\{\text{charts of } M \text { around } p\} \rightarrow \mathbb{R}^m, \quad \chi \mapsto v^\chi,
$$ with the property that, for any two charts $\chi$ and $\chi^{\prime}$ around $p$ one has $$
v^{\chi^{\prime}} = \mathrm d c_{\chi, \chi^{\prime}} (\chi(p)) [v^\chi], \qquad \qquad (1.2)
$$ where $c_{\chi, \chi^{\prime}} :=\chi' \circ \chi^{-1}$ is the change of coordinates from $\chi$ to $\chi^{\prime}$ . We denote by $T_p M$ the vector space of all such tangent vectors of $M$ at $p$ (a vector space using the vector space structure on $\mathbb{R}^m$ , i.e. $(v+w)^\chi:=v^\chi+w^\chi$ , etc). For $p \in M$ , we define $$
\operatorname{Curve}_p (M) := \{\gamma: (-\epsilon, \epsilon) \to M \text{ smooth such that } \epsilon>0, \gamma (0)=p\}.
$$ Let $\gamma \in \operatorname{Curve}_p (M)$ and $\chi$ a chart around $p$ . Let $\gamma^\chi := \chi \circ \gamma$ be the representation of $\gamma$ w.r.t. $\chi$ . Consider the operation $$
\frac{\mathrm d \gamma}{\mathrm d t} (0):\{\text {charts of } M \text { around } p\} \rightarrow \mathbb{R}^m, \quad \chi \mapsto \frac{\mathrm d \gamma^\chi}{\mathrm d t}(0).
$$ Then $\frac{\mathrm d \gamma}{\mathrm d t} (0) \in T_pM$ by chain rule. I already proved that Theorem 1 Given a smooth map $f: M \rightarrow N$ between two smooth manifolds, and given $p \in M$ , there exists a unique linear map $$
\mathrm d f_p: T_p M \rightarrow T_{f(p)} N, \quad v \mapsto \mathrm d f_p(v)
$$ with the property that, for any chart $\chi$ of $M$ around $p$ and $\chi^{\prime}$ of $N$ around $f(p)$ , one has: $$
\left( \mathrm d f_p(v)\right)^{\chi^{\prime}} = \mathrm d f_{\chi, \chi^{\prime}} (\chi(p)) [v^\chi] \quad \forall v \in T_p M . \qquad \qquad (1.3)
$$ Here $f_{\chi, \chi'} := \chi' \circ f \circ \chi^{-1}$ with domain $D(f_{\chi, \chi^{\prime}}) = \chi(U \cap f^{-1} (U')$ is the representation of $f$ w.r.t. $\chi, \chi'$ . Now I would like to prove another characterization of the differential of a smooth map, i.e., Theorem 2 Given a smooth map $f: M \rightarrow N$ between two smooth manifolds, and given $p \in M$ , there exists a unique linear map $$
\mathrm d f_p: T_p M \rightarrow T_{f(p)} N, \quad v \mapsto \mathrm d f_p(v)
$$ with the property that $$
\mathrm d f_p \left(\frac{\mathrm d \gamma}{\mathrm d t}(0)\right) = \frac{\mathrm d (f \circ \gamma)}{\mathrm d t}(0) \quad \forall \gamma \in \operatorname{Curve}_p (M). \qquad \qquad (1.4)
$$ With the help of Theorem 1 , I'm able to show the existence of such map. Could you elaborate why such map is unique ? My attempt Let $F$ be the linear map given by Theorem 1 . Then we can verify that $F$ satisfies (1.4). Fix a chart $\chi$ of $M$ around $p$ and a chart $\chi^{\prime}$ of $N$ around $f(p)$ . By (1.3) and chain rule, $$
\begin{align}
\left [ F \left ( \frac{\mathrm d \gamma}{\mathrm d t}(0) \right ) \right ]^{\chi'} &= \mathrm d f_{\chi, \chi^{\prime}} (\chi(p)) \left [ \frac{\mathrm d \gamma}{\mathrm d t}(0) \right ]^\chi \\
&= \mathrm d f_{\chi, \chi^{\prime}} (\chi(p)) \circ \mathrm d (\chi \circ \gamma)(0)[1] \\
&= \mathrm d (\chi' \circ f \circ \chi^{-1}) (\chi(p)) \circ \mathrm d (\chi \circ \gamma)(0)[1] \\
&= \mathrm d (\chi' \circ f \circ \chi^{-1} \circ \chi \circ \gamma) (0) [1] \\
&= \mathrm d (\chi' \circ f \circ \gamma) (0) [1] \\
&= \left ( \frac{\mathrm d (f \circ \gamma)}{\mathrm d t}(0) \right )^{\chi'}.
\end{align}
$$ Update My proof of uniqueness is as follows. However, I'm happy to see other approaches. Let $v \in T_pM$ . There exists $\gamma \in \operatorname{Curve}_p (M)$ such that $v = \frac{\mathrm d \gamma}{\mathrm d t} (0)$ . It follows that $$
F (v) = \frac{\mathrm d (f \circ \gamma)}{\mathrm d t}(0).
$$ It suffices to prove that if $\gamma, \lambda \in \operatorname{Curve}_p (M)$ with $v = \frac{\mathrm d \gamma}{\mathrm d t} (0) = \frac{\mathrm d \lambda}{\mathrm d t} (0)$ , then $\frac{\mathrm d (f \circ \gamma)}{\mathrm d t}(0) = \frac{\mathrm d (f \circ \lambda)}{\mathrm d t}(0)$ . Fix a chart $\chi$ of $M$ around $p$ and $\chi^{\prime}$ of $N$ around $f(p)$ . Then we have $\frac{\mathrm d (\chi \circ \gamma)}{\mathrm d t} (0) = \frac{\mathrm d (\chi \circ \lambda)}{\mathrm d t} (0)$ . It suffices to show that $\frac{\mathrm d (\chi' \circ f \circ \gamma)}{\mathrm d t}(0) = \frac{\mathrm d (\chi' \circ f \circ \lambda)}{\mathrm d t}(0)$ . Indeed, $$
\begin{align}
\frac{\mathrm d (\chi' \circ f \circ \gamma)}{\mathrm d t}(0) &= \mathrm d (\chi' \circ f \circ \gamma)(0)[1] \\
&= \mathrm d (\chi' \circ f \circ \chi^{-1} \circ \chi \circ \gamma)(0)[1] \\
&= \mathrm d (\chi' \circ f \circ \chi^{-1}) (\chi (p)) \circ \mathrm d (\chi \circ \gamma)(0)[1].
\end{align}
$$ Similarly, $$
\frac{\mathrm d (\chi' \circ f \circ \gamma)}{\mathrm d t}(0)  = \mathrm d (\chi' \circ f \circ \chi^{-1}) (\chi (p)) \circ \mathrm d (\chi \circ \lambda)(0)[1].
$$ The proof is completed by $$
\frac{\mathrm d (\chi \circ \gamma)}{\mathrm d t} (0) := \mathrm d (\chi \circ \gamma)(0)[1]
\quad \text{and} \quad
\frac{\mathrm d (\chi \circ \lambda)}{\mathrm d t} (0) := \mathrm d (\chi \circ \lambda)(0)[1].
$$","['tangent-spaces', 'smooth-manifolds', 'differential-geometry']"
4615322,Proof that there exists a unique function $f:\emptyset \rightarrow \emptyset$ and this function is a bijection. Is my proof valid?,"First, these are the definitions I'm working with: A function can be defined by its domain, codomain and graph, so $g:A \rightarrow B$ is equal to the ordered triplet $g = (A, B, G)$ where $G \subseteq A \times B$ . Also, for it to be a function, $G$ must satisfy the following: 1 - $(\forall x)[x \in A \rightarrow (\exists y)(y \in B \land (x, y) \in G)]$ (Every element has an image) 2 - $(\forall x_1, x_2, y_1, y_2) [((x_1, y_1) \in G \land (x_2, y_2) \in G \land x_1 = x_2) \rightarrow y_1 = y_2]$ (The image of every element is unique) A function $g:A \rightarrow B$ is an injection if: $(\forall a_1, a_2 \in A) (g(a_1) = g(a_2) \rightarrow a_1  = a_2)$ A function $g:A \rightarrow B$ is a surjection if: $(\forall b \in B) (\exists a \in A)(g(a) = b)$ A function $g:A \rightarrow B$ is a bijection if: It is both an injection and a surjection. Now, first we need to determine, is there actually a function $f:\emptyset \rightarrow \emptyset$ ? If there is, then $f = (\emptyset, \emptyset, G)$ where $G \subseteq \emptyset \times \emptyset = \emptyset$ . This then mean that $G = \emptyset$ (by double inclusion). Then $f = (\emptyset, \emptyset, \emptyset)$ . Now, is this a function? Well it's just a matter of verifying that the two properties listed above hold for $\emptyset$ : 1- $(\forall x)[x \in \emptyset \rightarrow (\exists y)(y \in \emptyset \land (x, y) \in \emptyset)]$ . And this is vacuously true since $x \in \emptyset$ is always false. 2 - $(\forall x_1, x_2, y_1, y_2) [((x_1, y_1) \in \emptyset \land (x_2, y_2) \in \emptyset \land x_1 = x_2) \rightarrow y_1 = y_2]$ . Similarly, this is also vacuously true since $(x_1, y_1) \in \emptyset$ is always false, which impies $((x_1, y_1) \in \emptyset \land (x_2, y_2) \in \emptyset \land x_1 = x_2)$ is always false, which then implies that the complete statement is always true. So then $f = (\emptyset, \emptyset, \emptyset)$ is a function and is the only function that can be defined from $\emptyset$ to $\emptyset$ . To prove that $f$ is a bijection, we first prove that it is an injection and then that it is a surjection. First notice that $(\forall a_1, a_2 \in \emptyset) (f(a_1) = f(a_2) \rightarrow a_1  = a_2)$ can be rewritten as $(\forall a_1, a_2)(a_1 \in \emptyset \rightarrow (a_2 \in \emptyset \rightarrow (f(a_1) = f(a_2) \rightarrow a_1  = a_2)))$ . This is probably the part of the proof that I'm most unsure of. Looking at the second form of the definition of injectivity is clear that $f$ is injective since the statement is vacuously true. To prove that the function is surjective, suppose that it isn't, then $\neg (\forall b \in \emptyset) (\exists a \in \emptyset)(f(a) = b)$ is a true statement, then $(\exists b \in \emptyset) (\forall a \in \emptyset)(f(a) \neq b)$ , which is clearly false since there is no element in $\emptyset$ , hence a contradiction. Then the function is surjective and injective thus bijective, this concludes the proof. Are there any spots where my proof doesn't hold? can it be improved? Please let me know!","['elementary-set-theory', 'functions', 'solution-verification']"
4615352,Does finding slope of the tangent line to $y=x^2 +2x$ constitute division by zero when differentiating from first principles?,"When we consider a limit as $h \rightarrow 0$ when finding the slope of the tangent to a function at a particular point, we sometimes find ourselves in a form where the function may lead to a division by $0$ error. However, since this is a limit, I'm unsure whether or not this actually does lead to this particular problem. To illustrate the above problem, let's say that one wishes to find the slope of the tangent line at the point $(-1,-1)$ in the function $y=x^2 +2x$ We are told that $y=x^2 +2x$ and so we look for the slope at $(-1,-1)$ . We consider $f(-1+h)=(-1+h)^2+2(-1+h)=h^2 -1$ where $h \rightarrow 0$ ; so the closest point is $((-1+h),(h^2-1))$ . Finding the slope, we have $\frac{h^{2}-1-(-1)}{h-1-(-1)}=\frac{h^2}{h}=h$ . When $h$ approches $0$ , the slope is $0$ . I am wondering if when $h^2/h$ is simplified to $h$ , this would preclude us from taking the limit as $h$ approaches zero, as the expression has been divided by $h$ at one point. To take the limit when $h$ approaches zero, we plug in zero for $h$ - doesn't this constitute a zero division error? Thanks for any clarification.","['tangent-line', 'calculus', 'functions', 'limits', 'derivatives']"
4615388,Subset of a basis for a normed vector space cannot be Cauchy?,"In class, we showed that $e_n \in l^p$ converges weakly but not strongly for $p \in (1,\infty)$ and that $\sin(2\pi nx) \in L^2([0,1])$ converges weakly but not strongly. I was wondering if basis elements cannot converge strongly because if they do they are somehow not linearly independent? I know that these are Schauder bases vs. Hamel bases for the respective spaces, but don't have a good intuition for whether that should make a difference.","['cauchy-sequences', 'schauder-basis', 'normed-spaces', 'linear-independence', 'functional-analysis']"
4615395,Expected value of objects with a serial number greater than a given number,"I have $n$ objects, numbered $1$ to $n$ . If I take out $m$ objects randomly, then what is the expected value of the number of objects whose serial number is greater than to $x$ ? $ (1 \le x \le n) $ EDIT 1: Here's my best attempt. If I denote the probability that exactly $i$ objects have a serial number greater than $x$ as $p(i)$ , then the expected value is $\sum_{i=1}^{n} ip(i)$ There are $x$ objects whose serial number is not greater than $x$ and $n-x$ objects whose is. Therefore the probability that exactly $i$ objects have a serial number greater than $x$ is.... I'm not sure. I'm guessing $$ \frac{\binom{x}{m-i} \binom{n-x}{i}}{\binom{n}{m}} $$ I don't know if this is correct or whether this sum has a closed form","['combinatorics', 'probability']"
4615414,"If $|f(0)|\geq r$, then $|f(z)|\geq (r-|z|)/(1-r|z|)$ for $|z|<r$","The following is an exercise IX.1.5 in Gamelin Suppose that $f(z)$ is analytic and satisfies $|f(z)|\leq 1$ for $|z|<1$ . Show that if $|f(0)|\geq r$ , then $|f(z)|\geq (r-|z|)/(1-r|z|)$ for $|z|<r$ . Let $\varphi:\Bbb D\to\Bbb D$ be a Blaschke factor $\varphi(z) = {f(0)-z\over 1-\overline{f(0)}z}$ . Then applying Schwarz lemma on $\varphi\circ f$ , we get \begin{align*}
& |(\varphi\circ f)(z)|\leq |z|\Rightarrow \left|{f(0)-f(z)\over 1-\overline{f(0)}f(z)}\right|\leq |z|.\\
& |f(0)|-|f(z)|\leq |f(0)-f(z)|\leq |z||1-\overline{f(0)}f(z)|\leq |z|(1+|f(0)||f(z)|).\\
& r(1-|z||f(z)|)\leq |f(0)|(1-|z||f(z)|)\leq |z|+|f(z)|.\\
& {r-|z|\over 1+r|z|}\leq |f(z)|.
\end{align*} This is as far as I get. I wonder if there's a way to get the stated inequality.","['complex-analysis', 'inequality']"
4615426,What does the norm of the Jacobian represent?,"Let $f ∈ C^1(R^n, R)$ .
If $||Df(x_0)||≠0$ then
f increases most in the direction $Df(x_0)$ at $x_0$ and if it is =0, the derivative of f is 0 in any direction. Could someone try to explain what this means? How can we evaluate the norm of the Jacobian? Is it Euclidean norm? I would really appreciate any help in visualizing what it actually means as well. It's my first time studying this and I would appreciate it if it is explained in the simplest terms possible since I do not have much knowledge on topology and multivariable calculus. Thank you!","['jacobian', 'multivariable-calculus', 'differential-topology']"
4615444,Find the maximum value of $xy+yz+xz-2xyz$,"If $x+y+z=1$ and $0\le x,y,z\le1$ then find the maximum value of expression $$xy+yz+xz-2xyz$$ Solution that I have $$(1-2x)(1-2y)(1-2z)=1-2\sum x+4\sum xy-8xyz=4\sum xy-8xyz-1$$ $\implies$ $$\sum xy-2xyz=\frac{1+(1-2x)(1-2y)(1-2z)}{4}$$ Now $$\frac{\sum(1-2x)}{3}\ge\{(1-2x)(1-2y)(1-2z)\}^{\frac13}$$ $$\implies (1-2x)(1-2y)(1-2z)\le\frac{1}{27}$$ $$\implies xy+yz+xz-2xyz\le\frac{1+\frac{1}{27}}{4}=\frac{7}{27}$$ My own solution Consider $f(x,y,z)=xy+yz+zx-2xyz$ Since $f(x,y,z)$ is symmetric, it will achieve it's maximum value when $x=y=z=\frac13$ thereby giving $\frac{7}{27}$ as the answer. What I want to know, is whether there is any other practical method to solve this question as considering $(1-2x)(1-2y)(1-2z)$ seems somewhat impractical and unimpressive to me. Like how will one think of such expression. Any help is greatly appreciated.","['algebra-precalculus', 'inequality']"
4615472,What does the second derivative represent in a curve?,"I have a very simple question If I have a curve represented by four coefficients y= c0+c1x+c2x^2+c3x^3 and I take the derivative of dy/dx in a point, I believe that represents the tangent slope, am I wrong? Anyway, my question is what does the d2y/dx2 represents geometrically?","['curves', 'derivatives', 'geometry']"
4615490,There are two multisets of circles and squares. Probabilty of pulling a circle from second multiset after two transfers between the two sets,"I am trying to solve a probability problem with coins of two types. I will refer to them as circles and squares. The task is: A boy has 4 circles and 3 squares in his left pocket and 2 circles and 1 square in his right pocket. The boy transfers 2 random objects from his left pocket to his right pocket. Then he transfers two random objects from his right pocket back to his left pocket. The boy then pulls an object from his right pocket. What is the probability he has pulled a circle? I tried forming Hypotheses $H_{cc}, H_{cr}, H_{rr}, F_{cc}, F_{cr}, F_{rr}$ for the corresponding transfers: Let $H_{ij}$ , for $i,j\in\{c,r\}$ , represent taking two circles, a circle and a rectangle, or two rectangles in the transfer from the left to the right pocket. The definition of $F_{xy}$ is similar, but in the opposite direction. I realised it's unwise to then calculate $P(F_{xy}|H_{ij})$ , so I gave up on that idea.
I considered the following aproach instead: Let $k$ be the number of cirlces moved from the left pocket to the right pocket. Let $l$ be the number of circles moved from the right pocket to the left pocket. Thus the probability of moving $k$ circles to the right pocket is $\frac{C^k_4\times C^{2-k}_3}{C^2_7}$ moving $l$ circles back to the left pocket is: $\frac{C^l_{2+k}\times C^{2-l}_{1+2-k}}{C^2_5}$ pulling a circle out of the right pocket after moving two object from left to right and then two object from right to left is $\frac{2+k-l}{3}$ How can I calculate the probabilty? If $A=\{\text{pulling a circle from the right pocket after the transfers}\}$ , then $$P(A)=\sum{P(A|F_{xy})P(F_{xy})}$$ I am not sure what to do next. EDIT: If I rename my hypotheses as $H_k$ and $F_l$ , where $k$ and $l$ are the number of circles transferred, resp, left $\to$ right and right $\to$ left, then $$P(A)=\sum_{l=0}^2{P(A|F_l)P(F_l)}$$ but $P(F_l)$ should be $P(F_l|H_k)P(H_k)$ , therefore $$P(A)=\sum_{k=0}^2{\sum_{l=0}^2{\frac{2+k-l}{3}\times\frac{C^l_{2+k}\times C^{2-l}_{1+2-k}}{C^2_5}\times\frac{C^k_4\times C^{2-k}_3}{C^2_7}}}$$ Am I correct?","['conditional-probability', 'bayesian', 'probability']"
4615506,Basis for the cotangent space $T^\ast_p M$ and the maps $dx^i$,"Let $M$ be a manifold and $p \in M$ , then we have the tangent space $T_pM$ that has a basis $\left\{ \left(\frac{\partial}{\partial x^i}\right)_p \right \}$ . The cotangent space $T^\ast_p M$ has then a basis $\{ (dx^i)_p \}$ . I'm trying to figure out why the cotangent space has the proposed base. If $V$ is a finite dimensional vector space with base $\{e_1, \dots e_n \}$ , then $V^\ast$ has a basis $\{f^1, \dots f^n \}$ , where $f^i : V \to \Bbb R$ and $f^i(e_j) = \delta_i^j$ . In the cotangent space case $\{ (dx^i)_p \}$ would be a basis if $$(dx^i)_p\left(\frac{\partial}{\partial x^j}\right)_p = \delta_i^j.$$ Now $(dx^i)_p : T^\ast_p M \to \Bbb R$ is just any linear map so how can I know anything about $(dx^i)_p\left(\frac{\partial}{\partial x^j}\right)_p$ without defining what $(dx^i)_p$ does first? I'm told that $dx^i$ is ""just a notation"", but it should apparently be defined to be something in order for this to work out?",['differential-geometry']
4615509,How to count pairs with Catalan distribution,"Say I have a set of $n$ pairs, such that I have a total of $2n$ elements. I arrange them in pairs following a Catalan distribution, i.e. if I lay them in a 1D line, I have no crossing (See the following picture). My task is: Given a boundary of length L in this line, count the mean number of cut bonds. Here I define $Q(n,L)$ as the mean number of cuts, i.e. $Q=\frac{\#cuts}{\#permutations}$ My progress: Given n pairs, the total number of permutations is given by the Catalan number $C_n=\frac{(2n)!}{(n+1)!n!}$ . As I always have $L$ elements and $(2n-L)$ elements on the left/right side of the boundary, the mean number of cuts would be $Q(n,L)=L(2n-L)\frac{1}{C_n}$ , i.e. all possible pairings distributed in a Catalan way. However, this does not work! For the examples shown before, I get Q(2,1)=3/2 Q(2,2)=4/2 and Q(3,1)=5/5, Q(3,2)=8/5, and Q(3,3)=9/5.
Somehow I am overestimating the number of cuts and I cannot figure out how to solve it. Any help would be appreciated.","['permutations', 'catalan-numbers', 'combinatorics', 'bipartite-graphs']"
4615514,Swapping unknown number of balls from two drawers based on a coin toss [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question There are n balls labeled with at least one person's name. The balls are distributed in two drawers, with drawer 1 containing more balls. Each person tosses a fair coin,
if the outcome is heads, the person must put all the balls with their name from drawer 1 into drawer 2 and put the balls with their name from drawer 2 into drawer 1. Basically the balls are taken from both drawers and placed in the respective other one. Show that after each person tosses a coin, there is a positive probability that there are more balls in drawer 2 than in drawer 1. I encountered this problem in my textbook and don't know how to approach this question.","['statistics', 'probability']"
4615516,The cardinality of a finite sigma algebra is a power of 2?,"Let $X$ be a finite set. Let $\Sigma \subseteq P(X)$ be a finite sigma algebra on $X$ . I have been able to prove that the cardinality of $\Sigma$ is always an even number: the collection $$ \left\{\left\{Y{,}\ X\setminus Y\right\}:Y\in \Sigma\right\}$$ is a partition of $\Sigma$ . Thus, $$\left|\Sigma\right|=\left|\left\{\left\{Y{,}\ X\setminus Y\right\}:Y\in \Sigma\right\}\right|\cdot\left|\left\{Y{,}\ X\setminus Y\right\}\right|=2\left|\left\{\left\{Y{,}\ X\setminus Y\right\}:Y\in \Sigma\right\}\right|{,}$$ and the cardinality of $\Sigma$ is necessarily an even number. However, there is more: the cardinality of $\Sigma$ is a power of $2$ . This I am unable to prove. What would be an elementary way of showing that fact? I guess that one should construct some collection so that $\Sigma$ is its power set, thus having a cardinality of some power of $2$ .","['elementary-set-theory', 'measure-theory', 'combinatorics']"
4615546,Find the value of $\frac{a+b}{10}$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question If $\sin x+\cos x+\tan x+\cot x+\sec x +\csc x=7$ , then assume that $\sin(2x)=a-b\sqrt7$ , where $a$ and $b$ are rational numbers. Then find the value of $\frac{a+b}{10}$ . How to solve these kind of problems. I can make substitutions and convert all of them to $\sin$ and then solve for it but  it'll be very lengthy. Is there any other short and nicer method.","['algebra-precalculus', 'trigonometry']"
4615562,"Limit of $\frac 12$, $\frac{1\cdot 4}{2 \cdot 3}$, $\frac{1\cdot 4\cdot 5}{2\cdot 3\cdot 6}$, ...","The following is not a homework, just curiosity. Consider the integers grouped by consecutive pairs : $(1,2)$ , $(3,4)$ , ... What is the limit of the ""switching fractions"" where we alternatively use the largest number in a pair either upward or downward : $$\frac 12, \frac{1\cdot 4}{2 \cdot 3}, \frac{1\cdot 4\cdot 5}{2\cdot 3\cdot 6}, \frac{1\cdot 4\cdot 5\cdot 8}{2\cdot 3\cdot 6\cdot 7},\ldots?$$ A proof as elementary as possible would be nice, if not it could use standard results on prime distribution. Also, was it considered before? Any reference welcomed. Edit Numerically we have: $0.5, 0.6666... , 0.5555... , 0.6349206..,0.5714286..,0.6233766...$ More terms would certainly help.",['sequences-and-series']
4615581,Maximal Non-Hausdorff Compactification,"I have recently started to read about compactifications of topological spaces, however I would like to clear my mind on a few things. For starters, I am interested in generic topological spaces (not necessarily Tychonoff) although I imagine that not much can be said without imposing restrictions of some sort. Given a topological space $X$ , a $\textbf{compactification}$ (for me) is a $\textbf{compact}$ (not necessarily Hausdorff) space $X^*$ together with a continuous embedding $\phi:X\rightarrow X^*$ such that $\phi(X)$ is dense in $X^*$ . Now, I know a compactification always exists: either $X$ is already compact or we can consider the Alexandroff one-point extension, so that the Corona set $X^*\setminus X$ is, resp., empty or only contains one point. On the other side of the spectrum, there is the Stone-Čech compactification, which is in some sense the largest among Hausdorff compactifications (which exists if and only if the original space is Tychonoff), and this sense is made precise by its universal property. My question is now as follows: If $X$ is a generic topological space, is there any compactification which satisfies a similar universal property* (so that it can be thought as the biggest compactification and not just the biggest among the Hausdorff ones) ? Related to this, if $X$ is indeed Tychonoff and this ""biggest"" compactification exists (at least for specific $X$ ), does it coincide with the Stone-Čech one? Notes: As I understand the matter so far, I'm aware that one can carry out the Stone-Čech construction in general, but for non-Tychonoff spaces the map $\phi$ will not be an embedding. This is not what I'm looking for (at least for now) since I'm interested in not dropping the embedding requirement, and the same for the density one. I am not expecting any kind of constructional result (at least in general), the only issues of the sort that I'm usually interested in are foundational (e.g., does this need some version of the Axiom of Choice?). Any reference or direction is highly appreciated. *Edit for clarity: Honestly I'm not completely sure what the universal property would look like in general, but I mean something on the line of: for any topological space $Y$ and continuous map $f:X\rightarrow Y$ there is a unique (perhaps modulo some equivalence relation) continuous map $f^*:X^*\rightarrow Y$ such that $f^*\circ\phi=f$ .","['tychonoff-spaces', 'dense-subspaces', 'compactification', 'general-topology', 'compactness']"
4615591,"Understanding $\,\det(A+B)$","From this paper on Determinant of sums, where \begin{equation}
\det(A+B) = \sum_{r} \sum_{\alpha,\beta} (-1)^{s(\alpha) + s(\beta)} \det(A[\alpha|\beta])\det(B[\alpha|\beta]),
\end{equation} the meaning of $A[\alpha|\beta]$ , and how the sum runs over $\alpha, \beta$ is not clear to me. Would appreciate an explanation of this this result.","['matrices', 'determinant', 'notation']"
4615610,how many monotonically increasing functions with respect to subset relation are there?,"Let $f:[n]\to \mathcal{P}([k])$ be a weakly monotonic increasing function with respect to the subset relation if $\forall i,j\in [n]$ if $i\le j$ then $f(i)\subseteq f(j)$ , and strongly monotonic increasing with respect to the subset relation if $\forall i,j\in [n]$ if $i\le j$ then $f(i)\subsetneq f(j)$ . How many functions are there that are weakly \ strongly monotonic increasing? My attempt: for the weak case, I think it's like solving the equation $x_1 + x_2 +... + x_n =k$ because we can think of $n$ cells in which we need to put up to $k$ distinct items. for example, if the first cell has the set $\{1,2,3\}$ in the next cell we can put up to $k-3$ additional items (maybe we need to have n+1 cells, because we don't have to pick all of the items). So perhaps the answer is $S(n,k)$ . Then for the strong case we might need to subtract the amount of functions to avoid repetitions, so maybe $S(n,k-n)$ . I'm really not certain that's the right way to approach the problem though.",['combinatorics']
4615614,Why does the fractional/relative change concept by differentiation $dx/x$ not work on big changes?,"There's a term that I've studied about called 'Fractional/relative change'. Basically, if say: $$P = x^ay^bz^c$$ then, $$\log P = a\log x + b\log y + c\log z$$ By differentiation w.r.t $dp$ : $$\frac 1 P = \frac a x \frac {dx}{dp} + \frac  b y \frac {dy}{dp} + \frac c z \frac{dz}{dp}$$ , $$\frac {dP} P =  a \frac{dx}{x}  + b \frac{dy}{y}  + c \frac{dz}{z}. $$ If we increase any of the terms from x, y, z by any magnitude of percentage, then this formula should give the percentage change in 'P'.
But, that only works for small changes, not for large ones, Why? For example: $KE = (1/2)mv^2$ . If the velocity is increased by 2%, what will be the fractional change in K.E? To find this, shortest method would be to do this (in my opinion): $$\frac{d(KE)}{KE} = \frac{dm}{m} + 2 \frac{dv}{v}$$ (acc. to fractional change formula). So, $\frac{d(KE)}{KE} = 0 + 2\times2 = 4 \% $ , which is correct. But, if the same velocity is increased by 10%, then the change in kinetic energy goes up to more than 20%. As the change in velocity gets bigger, the change in K.E gets more than the double of the percentage change. I don't exactly get why does this happen. Even if it's a bigger increase and 'dx' is only used for small changes, it's eventually made up of small fractional changes that adds up to get a big increase. Why doesn't it follow the same pattern at bigger changes?","['calculus', 'functions', 'derivatives', 'error-propagation']"
4615616,Evaluating $\int \frac{x^3}{\sqrt{x^2 + 4x + 6}} dx$,"Question: Evaluate $\displaystyle\int \frac{x^3}{\sqrt{x^2 + 4x + 6}}\ dx $ . My attempt: $\begin{align} \int \frac{x^3}{\sqrt{x^2 + 4x + 6}}\ dx & = \int \frac{x^3}{\sqrt{(x+2)^2 + 2}}\ dx \\& \overset{(1)}= \int \frac{(\sqrt{2} \tan(t) - 2 )^3 \sqrt{2} \sec^2(t)\ }{\sqrt{2\tan^2(t) + 2}}\ dt\\& = \frac{1}{\sqrt{2}}\int\frac{(\sqrt{2} \tan(t) - 2 )^3 \sqrt{2} \sec^2(t)}{\sec(t)}\ dt\\& = \int(\sqrt{2} \tan(t) - 2 )^3 \sec(t)\ dt\\& = \int -8 \sec(t) + 2 \sqrt2 \tan^3(t) \sec(t) - 12\tan^2(t) \sec(t)\\&\qquad + 12 \sqrt2 \tan(t) \sec(t)\ dt\\\\& = -8\ln|\sec(t) + \tan(t)| + 12\sqrt{2} \sec{(t)}  \\
&\qquad + 2\sqrt{2} \int \tan^3(t) \sec(t) \ dt - 12\int\tan^2(t) \sec(t) \ dt\end{align}$ Now both of these integrals can be evaluated using some sort of substitution and integration by parts rule. This would give us, $$\boxed{-8\ln|\sec(t) + \tan(t)| + 12\sqrt{2} \sec{(t)}  + 2\sqrt{2}\left[\frac{\sec^3(t)}{3} - \sec(t)\right] - 12\left[\frac{-1}{2} \ln|\sec t + \tan t| + \frac12 \sec t \tan t \right] + C}$$ $(1)$ Here I've made a substitution $t = \tan^{-1}\left(\frac{x+ 2}{\sqrt 2}\right)$ . Wolframalpha gives answer as $$\boxed{\frac{1}{3}(x^2 - 5x + 18) \sqrt{x^2 +4x + 6}  - 2 \sinh^{-1}\left(\frac{x+2}{\sqrt{2}}\right) + C}$$ How would I simplify my answer equal to this? Undoing my substitution $t = \tan^{-1}\left(\frac{x+ 2}{\sqrt 2}\right)$ is also not an easy task I think.","['integration', 'indefinite-integrals', 'calculus']"
4615620,Decreasing permutation,"A permutation σ of the set [n] = {1, 2, ..., n} is decreasing if for every i < j, it holds that σ(i) > σ(j). How many decreasing permutations of [n] are there? My attempt: Since 1<i for all i in {2, ..., n}, we know that σ(1)=n. Otherwise we would have a j with σ(j)=n>σ(1), but 1<j.
Same argument: σ(2)=n-1
.
.
.
It follows, that there is exactly one decreasing permutation, if n is even. And there is no permutation if n is not even. I dont see what is wrong, but it also seems suspiciously easy. Can someone confirm?","['permutations', 'solution-verification', 'combinatorics', 'discrete-mathematics']"
4615641,Number of bijective functions on a finite set,"I was trying the following problem: Find the number of bijective functions $f:\{1,2,3,4\}\rightarrow \{1,2,3,4\}$ such that $f(1)\neq 3, f(2)\neq 1, f(3)\neq 4, f(4)\neq 2.$ My attempt is the following one: Consider the subsets of bijections $A_1=\{f: f(1)=3\}$ , $\;\;A_2=\{f: f(2)=1\}$ , $A_3=\{f: f(3)=4\}$ , $\;\;A_4=\{f: f(4)=2\}$ . So $\begin{align}\vert\cup_i A_i\vert&=\,^4C_1\!\cdot\!3!-\,^4C_2\!\cdot\!2!+\,^4C_3\!\cdot\!1!-\,^4C_4\!\cdot\!0!=\\&=24-12+4-1=15.\end{align}$ Hence the required answer is $\,24-15=9$ . Is my solution correct? If not please help.","['functions', 'combinatorics', 'solution-verification']"
4615692,Ordinary DEQ - Frobenius Method,"I have a DEQ: $$y''-\frac{6}{x}y'+\frac{12+x^2}{x^2}y=0$$ Then in series form: $$\sum_{m=0}^{\infty}(m+r)(m+r-1)a_mx^{m+r-2}-6\sum_{m=0}^{\infty}(m+r)a_mx^{m+r-2}+12\sum_{m=0}^{\infty}a_mx^{m+r-2}+\sum_{m=0}^{\infty}a_mx^{m+r}$$ The lowerst power is obviously $m+r-2$ , and we get the indicial equation $r(r-1)-6r=0 \rightarrow r_1=0, r_1=7$ Next, we equate the powers, since the first 3 are the same, we change the index on the 4th series: $$s_4=\sum_{m=2}^{\infty}a_{m-2}x^{m+r-2}$$ Rearranging the series: $$((m+r)(m+r-1)-6(m+r)+12)a_m+a_{m-2}=0$$ Let $r=0$ , i get: $$a_m=-\frac{a_{m-2}}{m(m-7)+12}$$ Then $$a_2=-\frac{a_0}{30}, a_4=-\frac{a_2}{56}=-\frac{a_0}{1680}.....$$ now that just doesn't seem very likely,,i triple-checked my solution, and don't know where i might have made a mistake, can someone have a look?","['frobenius-method', 'solution-verification', 'ordinary-differential-equations']"
4615694,How can I improve my proof of Stirling's Theorem?,"I'm trying to prove Robbin's inequality: $$
n! \le \sqrt{2 \pi n}(n/e)^n e^{1/(12n)}.
$$ Step 1 : I start from the integral formulation \begin{align}
n! = \int_0^\infty x^n e^{-x} dx
&=
(n/e)^n\int_0^\infty (x/n)^n e^{n-x} dx
\\&=
(n/e)^n\int_{-n}^\infty (1+x/n)^n e^{-x} dx
\\&=
(n/e)^n\int_{-n}^\infty \exp[-x + n\log(1+x/n)] dx
\\&=
(n/e)^n n \int_{-1}^\infty \exp[-x n + n\log(1+x)] dx.
\end{align} Step 2 : I want to use Laplace's method, so I pull out Taylor's theorem $$
\log(1+x)=x - x^2/2 + \frac{2}{(1 + \xi_x)^3}x^3/6,
$$ where $\xi_x \in [-x,x]$ . (Here we used $\frac{d^3\log(1+x)}{dx^3}=\frac{2}{(1+x)^3}$ .) Step 3 : I split the integral into segments: $[-1, 0]$ , $[0, L]$ and $[L, \infty)$ .
In the first interval I guess I should use $\xi_x=-1$ , but actually we know $\log(1+x)\le x - x^2/2$ , so we don't really need Taylor's theorem. (Good, since we would have had a zero divisor.)
In the interval $[0,L]$ we set $\xi_x=0$ since $x^3>0$ .
Finally in $[L,\infty)$ in use a simple linear bound: $$\log(1+x) \le \log(1+L) + \frac{x-L}{1+L}$$ since $\log(1+x)$ is a concave function. (We have $f(x) \le f(L) + (x-L)f'(L)$ for any concave function and constant $L$ .) Step 4 : I now do the integrals: Integral one from $-1$ to $0$ : \begin{align}
\int_{-1}^0 \exp[-x n + n\log(1+x)] dx
&\le \int_{-1}^0 \exp[-nx^2/2] dx
\end{align} Integral two from $0$ to $L$ : \begin{align}
\int_{0}^L \exp[-x n + n\log(1+x)] dx
&\le \int_{0}^L \exp[-nx^2/2 + nL^3/3] dx
\\&= e^{nL^3/3} \int_{0}^L \exp[-nx^2/2] dx
\end{align} Integral from $L$ to $\infty$ : \begin{align}
\int_{L}^\infty \exp[-x n + n\log(1+x)] dx
&\le\int_{L}^\infty \exp[n \log(1+L) - n(1+x)L/(1+L)] dx
\\&\le(1+L)^n \int_{L}^\infty \exp[- n(1+x)L/(1+L)] dx
\\&=(1+L)^n e^{-L n} \frac{1+L}{L n}
\\&\le \exp(-n L^2/2 + n L^3/3) \frac{1+L}{L n}.
\end{align} Step 5 : Combine the integrals.
First combining (1) and (2): \begin{align}
\int_{-1}^0 \exp[-nx^2/2] dx
+e^{nL^3/3} \int_{0}^L \exp[-nx^2/2] dx
&\le e^{nL^3/3} \int_{-1}^L \exp[-nx^2/2] dx
\\&\le e^{nL^3/3} \int_{-\infty}^\infty \exp[-nx^2/2] dx
\\&= e^{nL^3/3} \sqrt{2\pi/n}.
\end{align} Then combining (1) and (2) with (3): \begin{align}
\int_{-1}^\infty \exp[-x n + n\log(1+x)] dx
\le e^{nL^3/3}\left(\sqrt{2\pi/n} + \exp(-n L^2/2) \frac{1+L}{L n}\right)
\end{align} Step 6 : Choose $L$ . I choose $L=n^{-2/3}$ .
Putting it all together we have shown $$
n! \le (n/e)^n \left(
\sqrt{2\pi n} +  (1+n^{2/3})e^{-n^{1/3}/2}\right) e^{1/(3n)}.
$$ That is nearly the $(n/e)^n \sqrt{2\pi n} e^{1/(12n)}$ bound we wanted, but it is off by a factor $1/4$ in the error exponent, and we have that extra annoying $o(1)$ term added onto $\sqrt{2\pi n}$ . Question : How can I improve my proof?
I would like to get the full strength of Robbins's inequality, ideally  with similar methods.
If there are any tricks I can use to make the derivation easier, I'm also very interested.","['definite-integrals', 'laplace-method', 'real-analysis', 'gamma-function', 'inequality']"
4615702,Finding the value of given integral. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question It was asked to find the correct option(s) for the given integral: $$I_n = \displaystyle\int_{\frac{n}{2}}^{\frac{n+1}{2}}\dfrac{\sin{(\pi(\sin^2{\pi x}}))}{(\sqrt2)^x} \, dx$$ (a) $\dfrac{I_n}{I_{n+4}}=2$ (b) $\dfrac{I_n}{I_{n+4}}=\dfrac{1}{\sqrt2}$ (c) $\dfrac{\displaystyle\sum_{n=0}^\infty I_{8n}}{I_0}=\dfrac{4}{3}$ (d) $ \dfrac{\displaystyle\sum_{n=0}^\infty I_{n}}{I_0}=2$ I tried using King's property to solve this one, but it is not working here, instead it is making it more  complicated. Any help is appreciated :)",['integration']
4615720,Generalizing a proof of Cauchy's Theorem,"Let $G$ be a finite group and $p$ a prime dividing $|G|$ . There is a nice proof of Cauchy's Theorem in Aluffi's ""Algebra Chapter 0"" that makes use of an action (by cyclic permutation) of $\mathbb{Z}/p\mathbb{Z}$ on the set of tuples $(x_1,\ldots,x_p)$ with $x_i\in G$ such that $x_1\cdots x_p=1$ . Essentially, the argument shows that the set of fixed points of this action, namely, the collection of tuples of the form $(x,\ldots,x)$ with $x^p=1$ , must have size divisible by $p$ , and since $(1,\ldots,1)$ is in there, we get an element of order $p$ . I noticed that this argument can be extended to prove the following: If $G$ is a finite group, $p$ divides $|G|$ , $\emptyset\neq H\subseteq Z(G)$ , and $N$ denotes the number of $x\in G$ with $x^p\in H$ , then $p$ divides $N$ . For the proof, consider the set of tuples $S=\{(x_1,\ldots,x_p): x_i\in G, x_1\cdots x_p\in H\}$ . We can count the number of elements of $S$ as follows: For any $h\in H$ , we may choose $x_1,\ldots,x_{p-1}$ arbitrarily before $x_p=(x_1\cdots x_{p-1})^{-1}h$ is determined. This shows (I think) that $|S|=|G|^{p-1}|H|$ , a multiple of $p$ . Now, if $(x_1,\ldots,x_p)\in S$ , then $x_1\cdots x_p=h$ for some $h\in H$ . Since $h\in Z(G)$ , we have $x_2\cdots x_p=x_1^{-1}h=hx_1^{-1}\implies x_2\cdots x_px_1=h\implies (x_2,\ldots,x_p,x_1)\in S$ . So, we get an action of $\mathbb{Z}/p\mathbb{Z}$ on $S$ by cyclic permutation, as in the proof of Cauchy's Theorem. Again, the fixed points are the ""constant"" tuples in $S$ , and the formula $|S|=|\{$ fixed points $\}|+\sum\{$ sizes of nontrivial orbits $\}$ shows that $p$ divides $N$ . Of course, we can now quickly deduce Cauchy's Theorem by setting $H=\{1\}$ and noting that since $1^p=1$ , $N\geq p$ . My questions are: Is the above result well-known? Is it interesting? Am I overcomplicating something simple?","['permutations', 'group-theory']"
4615743,"For matrix-valued functions, does $\frac d {dt} \exp(A(t)) = A'(t)\exp(A(t))$ imply $A'(t)A(t)=A(t)A'(t)$?","The converse (that $A$ and $A'$ commuting implies $(\exp(A)' = A'\exp(A)$ ) is easy to show from the series for $\exp$ . In a class I'm TA for, one question on the students' exam was to find an example of a non-constant matrix function $A(t)$ such that $\exp(A)$ solves $\dot \Phi = \dot A \Phi$ . All the (correct) solutions I've seen satisfy $A\dot A = \dot A A$ , but I am wondering if this is actually necessary.","['matrix-calculus', 'ordinary-differential-equations']"
4615745,How could I evaluate $\sum_{r=1}^\infty{\frac{1}{r\sqrt{r+1}}}\;?$,"How could I evaluate $\displaystyle\,\sum_{r=1}^\infty{\frac{1}{r\sqrt{r+1}}}\;?$ I have tried the substitution $r=k^2-1$ , but this yields a sum with a square root as the starting point ( $\sqrt2$ ). $$\int_1^\infty{\frac{1}{\lfloor x^2 \rfloor}}=\int_1^\sqrt{2}{1}dx+\int_\sqrt{2}^\sqrt{3}{\frac{1}{2}}dx+\int_\sqrt{3}^\sqrt{4}{\frac{1}{3}}dx\,+...$$ I think.","['limits', 'summation']"
4615759,Intuition for Markov process,"Why is the process $Q(t)$ defined below a Markov process ? $$Q(t)=Q(0)+A(t)- S\left(\int_0^t Q(s)\,\mathrm ds\right)$$ where $A$ and $S$ are unit rate Poisson process. Since the integral depends on the past, shouldn't this be non-Markov ? What is the intuition for this ?","['stochastic-processes', 'markov-process', 'probability-theory', 'probability']"
4615760,"How much options are there to color a circular graph with $10,000$ nodes with $2023$ colors?","How much options are there to color a circular graph with $10,000$ nodes with $2023$ colors ? Let $ c_n $ the undirected simple circular graph on $n$ nodes. $E=\big\{\{1,2\},\ldots,\{n-1,n\},\{n,1\}\big\}.$ How many options there are to paint $c_n$ if $n= 1000$ and we demand that each adjacent node has different colour? I came to an estimation by using inclusion-exclusion principle and the binomial theorem, yet I am not certain this is right... $\displaystyle\sum_{k=0}^{10,000}\binom{10000}{k}(2023)^{10,000-k}\cdot(-1)^{k}=2022^{k}$ as also noted, the nodes are numbered so rotation and reflections do not apply here.","['graph-theory', 'coloring', 'combinatorics', 'discrete-mathematics']"
4615770,"How $ψ(x,y)$ can be equal to $C$ when $ψ'$ equals $0$ [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question I watched a lesson about exact equations in Khan Academy. Link to lesson In the video, there is a function called $ψ(x,y)$ . At the end, he found that : $$
\frac{d}{dx} ψ(x,y) = 0
$$ Then Sal khan said that we can integrate both sides of this equation and reach this: $$
ψ(x,y)=C
$$ but I can't understand how we can deduce that. We only know that it's derivative with respect to $x$ is zero. How we can say that the function equals to a constant value? Can't we have it as a function of y ?: $$
ψ(x,y)=f(y)
$$","['integration', 'derivatives', 'partial-derivative']"
4615780,Does there exist a group $H$ such that $|H/Z(H)| = 6$?,"Question: Does there exist a group $H$ such that $|H/Z(H)| = 6$ ? If there were to exist such a group then $H/Z(H) \cong C_6$ or $S_3$ . Note that if $H/Z(H) \cong C_6$ then $H$ would be abelian, implying that $H = Z(H)$ and hence $|H/Z(H)| = 1$ ; contradiction. So we must have $H/Z(H)\cong S_3$ if there is to exist such a group. If we take $H$ to be $S_3$ , then $Z(H) = \{e\}$ as if we have the permutation $(a_1 \space a_2 \dots a_k)$ then $(a_1 \space a_2)(a_1 \space a_2 \cdots a_k) = (a_2 \space a_3 \cdots a_k)$ but $(a_1 \space a_2 \cdots a_k)(a_1 \space a_2) = (a_1 \space a_3 \cdots a_k)$ . So $|S_3 / Z(S_3)| = \frac{|S_3|}{|Z(S_3)|} = \frac{3!}{1} = 6$ and so we have found such a group. Is this valid?","['quotient-group', 'group-theory', 'solution-verification']"
4615791,Having fun with arithmetic. Can I cover a circle with irrationals using unary operation?,"Got some time to have a fun with arithmetic, but quickly went beyond the picture I can imagine and explain to myself. Here would like to ask you what mathematical structures I deal with and if it is possible to continue my thoughts one more step further. The object I work with is a circle (like in geometry) with a ""starting"" point on it. There is an unary operation ""next"" which applies to a point and gives other ""next after starting"" point on a circle. Repeating the operation on it, gives one more ""next after next after starting"" point on a circle. After some number of iterations it loops back to a ""starting"" point. Case 1. Circumference is 17. Starting point is $0$ . Operation is increment by 1 mod 17. Repeating the operation constructs a set of integers {0..16}. Case 2. Circumference is 17. Starting point is $1$ . Operation picks next element in a somewhat reduced Stern-Brocot tree. Explanation follows. Cannot post images, I refer to this picture of Stern-Brocot tree: https://mathworld.wolfram.com/images/eps-svg/SternBrocotTree_1000.svg Reduced Stern-Brocot tree is a Stern-Brocot tree with right branches after 17 cut-off. Next element is a right neighbor on the same tree level (or leftmost one on next level). For instance, ""next after 2/3"" is 3/2 for it is on the right on the same level, while ""next after 3/1"" is 1/4. Repeating the operation, covers circle with rational numbers in a continuous range (0, 17). But I also need to loop it back to a ""starting"" point $1$ . Doubt if it makes sense, but I feel like I can go with infinite ordinal $\omega$ iterations and slightly modify the operation which picks ""next"" point in such a way, that $(\omega + n)$ th point is the same as $(n - 1)$ th point on my circle. Thus it mimics ""mod 17"" from case 1. Finally the problem. Can I define some unary operation on the circle to cover it continuously with irrational or real numbers from a range (0, 17) so that it loops back after some number of iterations?",['elementary-set-theory']
4615828,"Fixed field of $\mathbb{Q}(\xi)$ over $\big\lbrace \operatorname{Id}, \sigma^3, \sigma^6, \sigma^9 \big\rbrace$","What is the fixed field of $\mathbb{Q}(\xi)$ (as extension over $\mathbb{Q}$ ) over $H := \big\lbrace \operatorname{Id}, \sigma^3, \sigma^6, \sigma^9 \big\rbrace \leq S_3$ where $\sigma : \xi \mapsto \xi^2$ and $\xi = e^\frac{2\pi i}{13}$ ? What I've done so far: I first determined the permutation table for $\xi$ over $\sigma$ : $\operatorname{Id}$ $\sigma$ $\sigma^2$ $\sigma^3$ $\sigma^4$ $\sigma^5$ $\sigma^6$ $\sigma^7$ $\sigma^8$ $\sigma^9$ $\sigma^{10}$ $\sigma^{11}$ $\xi$ $\xi$ $\xi^2$ $\xi^4$ $\xi^8$ $\xi^3$ $\xi^6$ $\xi^{12}$ $\xi^{11}$ $\xi^9$ $\xi^5$ $\xi^{10}$ $\xi^{7}$ Then I calculated the fixed field for every element of $H$ (by comparing linear combination scalars): $\operatorname{Id}$ $\sigma^3$ $\sigma^6$ $\sigma^9$ $\mathbb{Q}(\xi)$ $\mathbb{Q}(\xi^2 + \xi^3 + \xi^{10} + \xi^{11}, \xi^4 + \xi^6 + \xi^7 + \xi^9)$ $\mathbb{Q}(\xi^2 + \xi^{11}, \xi^3 + \xi^{10}, \xi^4 + \xi^9, \xi^5 + \xi^8 + \xi^6 + \xi^7)$ $\mathbb{Q}(\xi^2 + \xi^{10} + \xi^{11} + \xi^3, \xi^4 + \xi^7 + \xi^9 + \xi^6)$ I'm not sure how to continue from here; is the entire fixed field just the intersection of these smaller ones? If my above hypothesis is true, is it also true in general? i.e. is $$\mathbb{L}^H = \bigcap_{\sigma \in H} \mathbb{L}^\sigma$$ for any Galois extension $\mathbb{L}/\mathbb{K}$ and a subgroup of the Galois group $H \leq \operatorname{Gal}(\mathbb{L}/\mathbb{K})$ true? My intuition tells me it is true. However, I do not know how I would prove it formally. Would I use the definition of a fixed field $\mathbb{L}^H = \big\lbrace x \in \mathbb{L} \mid \sigma(x) = x \quad \forall \sigma \in H \big\rbrace$ and argue that if it's in the intersection then it's fiexd by all elements of $H$ ? I've now moved this hypothesis into a separate question","['galois-theory', 'abstract-algebra']"
4615897,Calculating scalar curvature of a warped product $I \times N^n(k)$,"I'm trying to work out the details of this example by R. Bryant. He considers a Riemannian manifold $(N ^n, h)$ of constant sectional curvature $k$ and constructs the following quadratic form on $\mathbb{R}^+ \times N$ : $$
g = \frac{\mathrm{d}u^2}{k-a\,u^2+ b\,u^{1-n}} + u^2\,h
$$ on $M^{n+1} = \mathbb{R}^+\times N$ , where $a$ and $b$ are constants and $u>0$ is the coordinate on $\mathbb{R}^+$ . It is clear that If $I\subset\mathbb{R}^+$ is an interval on the $u$ -line on which $k-a\,u^2+ b\,u^{1-n} >0$ , then $g$ is a Riemannian metric on $I\times N$ . There are several claims of his that I thought would follow from straightforward calculations that I'm having a hard time verifying, though. One of them is the following: according to Bryant, the scalar curvature of this metric ( $g$ ) is constant and equal to $$S = n(n{+}1)a$$ Here's how I tried to calculate the scalar curvature: letting $\psi(u) = (k-a\,u^2+ b\,u^{1-n})^{-1}$ , we can define a metric $\widetilde{g}$ on $I$ by setting $\widetilde{g} = \psi \cdot \mathrm{d} u^2$ . This allows us to see $g$ as a warped product $g = \widetilde{g} + u^2 h$ . This is useful because the scalar curvature of a warped product has been calculated before several times in the literature. We have the following formula for a general multiply warped product: Let $M = B \times_{h_1} N_1^{d_1} \times \cdots \times_{h_k} N_{k}^{d_k}$ be a multiply warped product with metric $g = g_{B} \oplus h_1^2 g_{N_1} \oplus \cdots \oplus h_{k}^2 g_{N_k}$ . Then the scalar curvature of $M$ is given by $$
\begin{aligned}
R_{M} = R_{B} &- 2 \sum_{1 \leq i \leq k} d_i \frac{\Delta_B h_i}{h_i} + \sum_{1 \leq i \leq k} \frac{R_{N_i}}{h_i^2} - \sum_{1 \leq i \leq k} d_i(d_i - 1) \frac{\| \text{grad}_B h_i \|_B^2}{h_i^2} \\
&+ \sum_{1 \leq i \leq k} \sum_{\substack{1 \leq \ell \leq k \\
\ell \neq i  \\
}} d_i d_{\ell} \frac{g_B(\text{grad}_B h_i, \text{grad}_B h_{\ell})}{h_i h_{\ell}}
\end{aligned}
$$ So let's use this for our specific example, where $M = I \times N$ . Since $B = I$ is one-dimensional, $R_B = 0$ . Furthermore, we have the following formula for the Laplacian of a conformal change of metric (which we'll apply to $\widetilde{g} = \psi \cdot \mathrm{d} u^2 = e^{2 \varphi} \cdot \mathrm{d} u^2$ , where $\varphi = \frac{\ln(\psi)}{2}$ ) $$ \Delta_{\widetilde{g}} = e^{-2 \varphi} \Delta_g + (n-2) e^{-2 \varphi} g^{ij} \frac{\partial \varphi}{\partial x_j} \frac{\partial}{\partial x_i} $$ In our case, we have $\Delta_{ \mathrm{d} u^2} u = 0$ , which leads to $$\Delta_{\widetilde{g}} u = - \psi^{-1} \widetilde{g}^{11} (\partial_{1} \varphi) = - \psi^{-1} \cdot \left(au + \frac{1}{2} b (n-1) u^{-n} \right)$$ Therefore: $$- 2 \frac{n}{u} \Delta_{\widetilde{g}} u = \psi^{-1} \cdot \left( 2 n a + bn(n-1)u^{-n-1} \right)$$ It is also trivial that $\|\nabla u \|^2_{\widetilde{g}} = \psi$ , and since $N$ has constant sectional curvature $k$ , it is in particular an Einstein manifold with $R_{N} = n(n-1)k$ . So we get: $$R_{M} =\psi^{-1} \cdot \left( 2 n a + bn(n-1)u^{-n-1} \right) + \frac{n(n-1)k}{u^2}- \frac{n(n-1) \psi}{u^2}$$ instead of $R_M = n(n+1) a$ , as Bryant states. So I probably made a mistake in my calculations, but despite having tried really hard several times now, I fail to see where such a mistake could have occurred. Can anyone spot any mistakes in my calculations? I'd really appreciate any help (if anyone can think of an easier way to calculate the scalar curvature, please let me know!). Thanks in advance! EDIT : My mistake was in claiming ""It is also trivial that $\|\nabla u \|^2_{\widetilde{g}} = \psi$ "". It is most definitely not trivial. It is in fact wrong. While $\mathrm{d} f$ does not depend on the metric $g$ , the vector field $\nabla f$ DOES depend on the metric. Moreover, doing the calculations via the moving frame method (as per Deane's answer) is a lot better.","['riemannian-geometry', 'geometry', 'curvature', 'manifolds', 'differential-geometry']"
4615917,Find adjoint to integral operator from $H^1$ to $L_2$,"Let $k(x, y): \mathbb{R}^2 \to \mathbb{R}$ be a kernel and $T: H^1(a, b) \to L_2(c, d)$ $$ T u(x) = \int\limits_{a}^{b} k(x, s) u(s) ds$$ Find the adjoint operator $T^*$ . It is easy to see the if $T: L_2(a, b) \to L_2(c, d)$ , then $T^*$ can be expressed as $$ T^*v(s) = \int\limits_{c}^{d} k(x, s) v(x) dx$$ However, here we need $$ (Tu, v)_{L_2(c, d)} = (u, T^*v)_{H^1(a, b)} = (u, T^*v)_{L_2(a, b)} + (u', (T^*v)')_{L_2(a, b)}$$ I have tried to use the identity $$ \int\limits_{a}^{b} uv dx = \int\limits_{a}^{b} u'v dx + \int\limits_{a}^{b} uv' dx $$ Then $$ \int\limits_{c}^{d} \int\limits_{a}^{b} k(x, s) u(s) v(x) ds dx = 
\int\limits_{a}^{b} u(s) \left[ \int\limits_{c}^{d} k'_s(x, s) v(x) dx \right] ds +
\int\limits_{a}^{b} u'(s) \left[ \int\limits_{c}^{d} k(x, s) v(x) dx \right] ds $$ And it does not look like a form of adjoint operator... Thank you in advance for any help!","['integral-operators', 'adjoint-operators', 'functional-analysis']"
4615918,"How to prove the function $b : \mathbb Z × \mathbb Z → \mathbb Z$ defined by $b(m, n) = 3m + n$ is surjective?","How to prove the function $b : \mathbb Z × \mathbb Z → \mathbb Z$ defined by $b(m, n) = 3m + n$ is surjective? I believe it is surjective and I can explain it using words but not proof talk. Give me any integer in the codomain, I can always input $m$ as $0$ and $n$ to be that integer to output that integer. Any tips on how to prove it? Correct me if my reasoning is incorrect. I tend to struggle with proving a function is surjective much more than injective since I usually prove the contra positive.","['proof-writing', 'functions']"
