question_id,title,body,tags
1374627,Motivation behind the Archimedean norm on number fields .,"It is easy to justify the use of non-archimedean norms on number fields from an ""inside view"" as arising from the prime ideals and are therefore clearly useful a priori. However, it seems to me that the archimedean norms only make sense if one looks at the embedding of number fields inside $\Bbb C$ but there is no reason to consider this embedding before constructing the norm since $\Bbb C$ is defined as the closure under this norm. One possible justification would be that there is precisely one archimedean norm on $\Bbb Q$ and this would be satisfactory if one could explain why the axioms we use for a norm should be a priori important in the context of number theory. My question might be a little unclear and I will be happy to provide clarifications. I am basically looking for a reason why distances should matter in number theory. It is easy to see why we care about them in plane geometry and by extension analysis but they are also very useful in number theory and I do not see why they are useful a priori.","['number-theory', 'valuation-theory', 'algebraic-number-theory']"
1374632,Finding roots of cubic equation,"If $\alpha,\beta,\gamma $ are the roots of the equation $2x^3-3x^2-12x+1=0$.Then find the value of [$\alpha$]+[$\beta$]+[$\gamma$],where [.] denotes greatest integer function. My attempt: I first tried hit and trial to guess the first root but no luck.Then I tried rational root method, but its roots are not rational (both roots could not satisfy the equation.) I think its roots are irrational. Can someone help me finding its roots?","['polynomials', 'algebra-precalculus']"
1374673,Intuition about Blumenthal's 0-1 law,"I'm studying Brownian motion from Durrett. I'm trying to understand what  Blumenthal's 0-1 law really says about what Durrett calls the germ field , $\mathcal{F}_0^+$ . Let $\mathcal{F}_t^+ = \cap_{s > t} \mathcal{F}_s^0$ and $\mathcal{F}_t^0 = \sigma(B_s,s\le t)$ where $B_t$ is Brownian motion. Also let $P_x$ denote the usual measure on $\mathcal{C}[0,\infty)$ making $B_t(\omega) = \omega(t)$ a Brownian motion starting at $x$ . Blumenthal's 0-1 law: If $A \in \mathcal{F}_0^+$ then for all $x \in \mathbb{R}$ , $P_x(A) \in \{0,1\}$ . I have no trouble understanding this proof, but I'm not sure I understand why this is surprising/significant. Obviously, $\mathcal{F}_0^0$ is trivial. Is there any intuitive way to explain why we might not expect $\mathcal{F}_0^+$ to be trivial as well? Even though $\mathcal{F}_0^+$ seems to involve a tiny bit of information into the future past $t=0$ , since Brownian motion is continuous it would seem that we ought to expect no difference between the two fields.","['brownian-motion', 'probability', 'soft-question', 'stochastic-processes']"
1374679,Weak compactness of a set of translates in $C_0(\mathbb{R})$,"Let $f \in C_0(\mathbb{R})$. Consider the set of translates of $f$
$$ A = \{ f_t : t \in \mathbb{R} \}$$ 
where $f_t(x)=f(x+t), x\in \mathbb{R}$. I want to show that $A$ is relatively compact in the weak topology on $C_0(\mathbb{R})$. I have shown that every sequence in $A$ has a weakly convergent subsequence, using the fact that the dual is the space of Radon measures. If the closed ball in $C_0(\mathbb{R})$ is metrizable in the weak topology (I'm not sure if it is), then my proof is complete. 
[The problem is that $C_0(\mathbb{R})$ is not reflexive, and the dual is not separable either] Is there some result on the metrizability of the unit ball in $C_0(\mathbb{R})$? 
Or is there some other way to show that $A$ is relatively weak-compact?","['weak-convergence', 'functional-analysis', 'measure-theory']"
1374733,Flow of sum of non-commuting vector fields,"Let $V,W\in\Gamma(M)$ be any two vector fields. Is there any ""nice"" expression for the flow of $V+W$ in terms of the flow of $V$ and the flow of $W$? It would be sufficient for me to have some sort of expansion in $\epsilon$ for the flow of $V+\epsilon W$, at least the first few terms (or even just at the order of $\epsilon$). In the case where $[V,W]=0$, it is pretty easy to show that
$$\varphi_{V+W}^t = \varphi_V^t\circ\varphi_W^t,$$
but the non commuting case is of greater interest to me.","['differential-geometry', 'ordinary-differential-equations']"
1374734,What is the meaning of the cumulant generating function itself?,"If we define the characteristic function for a random variable X as $\Phi(t)=<e^{itX}>$ then it seems like we can think of it as essentially a spectral decomposition that measures the contributions of different frequencies to the probability distribution for X. I know how the moments are related to the derivatives at $t=0$, but I think that I might be missing some of the deeper connection between the moments and the spectral decomposition. If anybody had some thoughts on this then I would love to hear them, but I'm particularly interested in the same sort of question applied to the cumulants. We can then define the cumulant generating function in terms of $\Phi$ such that $\Psi(t)=\ln\Phi(t)$ and $\Psi^{\prime}(t)=\frac{\Phi^{\prime}(t)}{\Phi(t)}$ Now, what I'm really trying to ask, is what these equations are telling us about the meaning of the cumulant generating function. Again, I understand how the cumulants are determined, how they relate to the moments, why the generating function was defined this way, etc. What I don't understand is if there's a simple interpretation of either $\Psi(t)$ or $\Psi^{\prime}(t)$ at any given value of $t$. Is it valid to think of $\Psi(t)$ as a spectral decomposition of a second hypothetical probability distribution that has moments equal to the cumulants of the original distribution? Thanks for any answers!","['probability-theory', 'generating-functions', 'moment-generating-functions']"
1374744,Kolmogorov's sufficient and necessary condition for SLLN - What about pairwise uncorrelated RV?,"Kolmogorov proved, that, as one considers independent (not necessary equally distributed) Random Variables: $\{X_n\}_{n\ge0}\subseteq \mathcal L^2$ With $\mathrm{Var} (X_n)=\sigma^2_n$ and without loss of generality $E[X_n]=0$. If $\sum_{n=0}^\infty \frac{\sigma^2_n}{n^2} \lt \infty$ then SLLN holds, that is: $$\frac1n\sum_{k=0}^n X_k \rightarrow 0 \,\,\,\,\,\,\,\,\,\,\,\,\,\text{a.s.}$$ Something different: Also it is known, that if $\sup_{n\ge0}\sigma^2_n =: v \lt \infty$ pairwise uncorrelated $(X_n)_{n\ge0}$ will suffice for SLLN to hold. My question in view of this situation: Is it possible to weaken the condition of $(X_n)_{n\ge0}$ beeing independent and instead merely consider pairwise uncorrelated $(X_n)_{n\ge0}$?","['probability-theory', 'probability-limit-theorems', 'law-of-large-numbers']"
1374767,Proving that $1\cdot3+3\cdot5+5\cdot7+\cdots+(2n-1)(2n+1)={n(4n^2+6n-1) \over 3}$ by induction for $n\geq 1$,"Prove using mathematical induction that $$1\cdot3+3\cdot5+5\cdot7+\cdots+(2n-1)(2n+1)= {n(4n^2+6n-1) \over 3}.$$ Step 1: If we assume that the equation is true for a natural number, $n=k$ , then we get $$1\cdot3+3\cdot5+5\cdot7+\cdots+(2k-1)(2k+1)= {k(4k^2+6k-1) \over 3}$$ Step 2: When a statement is true for a natural number $n = k$ ,
then it will also be true for its successor, $n=k+1$ . Hence, we have to prove that it is also true for $n=k+1$ . $$1\cdot3+3\cdot5+5\cdot7+\cdots+(2k-1)(2k+1)+(2k+1-1)(2k+1+1) = {k(4k+1^2+6k+1-1) \over 3}$$ I replace the LHS by step 1. $${k(4k^2+6k-1) \over 3} + 2(k+1-1)(2k+1+1)={k(4k+1^2+6k+1-1) \over 3}$$ Now I need to make LHS equal to RHS.","['summation', 'induction', 'algebra-precalculus']"
1374777,sign of the conditional expectation,"I'm working on the following problem: Let $X$ be a random variable defined on $(\Omega,F,P)$ and $G$ a $\sigma$-algebra contained in $F$. Show that, if $E(|X|)<\infty$ and $E(X\mid G)$ has the same distribution as $X$, then $\operatorname{sgn}X=\operatorname{sgn}E(X\mid G)$ almost surely, where $\operatorname{sgn}$ is the sign function. I tried to find a contradiction when there's a set of events $B$ with positive probability where $X$ and $E(X\mid G)$ have different signs, but I don't know how to use the condition that they have the same distribution. With the definition of conditional expectation, we have $\int_A E(X\mid G)\,dP = \int_A X \, dP$ for all $A\in G$, so if $B\in G$ then there's a contradiction, while I only know it's in $F$. (Let $B= \{E(X\mid G)>0\} \cap\{X<0\}$). Could it be proved this way or it needs another approach? Thanks for any help.","['probability-theory', 'conditional-expectation', 'probability-distributions']"
1374836,Eigenvalues of the sum of two matrices: one diagonal and the other not.,"I'm starting by a simple remark: if $A$ is a $n\times n$ matrix and $\{\lambda_1,\ldots,\lambda_k\}$ are its eigenvalues, then the eigenvalues of matrix $I+A$ (where $I$ is the identity matrix) are $\{\lambda_1+1,\ldots,\lambda_k+1\}$. Moreover, if $\alpha\in\mathbb R$, the eigenvalues of $\alpha I+A$ are $\{\lambda_1+\alpha,\ldots,\lambda_k+\alpha\}$. Are there more general results for this topic? Specifically, if $A$ is a $n\times n$ matrix and $\{\lambda_1,\ldots,\lambda_k\}$ are its eigenvalues, what are the eigenvalues of $A+D$ (where $D$ is a diagonal matrix )? Edit (First): I was wondering if the solution is known in the case where the sum of the elements of every row of $A$ is $0$ and all the entries of $D$ is between $0$ and $1$. Edit (Second): I was wondering if the solution is known when the sum of the elements of every row of $A$ is $0$ and $D=\operatorname{diag}(1, 0,\dots,0)$.","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1374894,"How can I prove the integral $ \int_{1}^{x} \frac{1}{t} \, dt $ is $\ln x $ with this approach?","I have been trying to find a proof for the integral of $ \int_1^x \dfrac{1}{t} \,dt $ being equal to $ \ln \left|x \right| $ from an approach similar to that of the squeeze theorem. Is it possible to calculate the area under the curve $ f(x) = \dfrac{1}{x} $ as in the picture shown below? You may notice that both sums of the areas should converge to $\ln(x)$ as the base of the rectangles gets smaller and smaller. We approach from above and from below to get a limiting argument of the form: Area from below the curve as in the second graph $ \leq \int_a^b \dfrac{1}{x} \,dx \leq$ Area from above the curve as in the first graph The limiting argument would be to keep calculating and adding the areas of the rectangles which bases get smaller and thus showing that this amount is $\ln(x)$. How could I proceed in this way?","['calculus', 'real-analysis', 'integration']"
1374926,Asymptotic series of a matrix-valued function.,"Consider the following matrix $$f(\lambda)=\left( \frac{\lambda-1}{\lambda + 1} \right)^{\nu \sigma_3} \ \ \ \lambda \in \mathbb{C} \setminus [-1,1]$$ where $\sigma_3=\begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}$ is the third pauli matrix and $\nu $ is a negative real number. Clearly $f(\lambda) \to \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} $ as $\lambda \to \infty$. But my question is, what is the asymptotic series of $f(\lambda)$ as $\lambda \to \infty$ ? Any help is appreciated, Thanks.","['asymptotics', 'analysis', 'linear-algebra']"
1374943,How to find median from a probability distribution?,"Having trouble on something that should be really, really easy.  I need to find the median of the following probability distribution...but according to the website I linked below...I'm doing it incorrectly. Anyways, I computed the following probability table along with its mean and variance. x    0        1        2        3        4
P(x) 0.728303 0.240297 0.029732 0.001635 0.000034 Mean = .304802 Variance = .28158 Assuming I got this much right...do I just rearrange the probabilities in ascending order and choose the value in the middle (i.e. like every other time I've ever found the median)?  If so, why does the following link give 2 and not 1 for the median from the distribution below? Number of hits, x   0       1       2       3       4
Probability, P(x)   0.10    0.20    0.30    0.25    0.15

Arranged in ascending order...
Number of hits, x   0       4       1       3       2
Probability, P(x)   0.10    0.15    0.20    0.25    0.30 I chose that the median should be 1...but I guess the median is 2 according to the website.  Why doesn't my method work? http://stattrek.com/random-variable/mean-variance.aspx?Tutorial=AP What are the proper steps to finding the median in the first probability distribution given above?","['median', 'probability', 'statistics', 'probability-distributions']"
1374946,number of triangles determined by a rectangular grid,"Suppose we are given an $m\times n$ rectangular grid of lattice points, such as $S=\{(k,l): 0\le k\le n-1,\; 0\le l\le m-1, \;k,l\in\mathbb{Z}\}$, and we want to determine the number of (nondegenerate) triangles all of whose vertices are contained in this set. I believe that I can start with $\dbinom{mn}{3}$ and then have to subtract the number of sets of 3 vertices which lie on a line, and that there are 
$\displaystyle m\binom{n}{3}$ such triples which lie on a horizontal line and $\displaystyle n\binom{m}{3}$ such triples which lie on a vertical line; but what I would like to find out is how to systematically count all such triples which lie on a diagonal line. Furthermore, is there a simple formula for this number in terms of $m$ and $n$? (This question may have been asked before, but the closest question I could find was How many triangles can be created from a grid of certain dimensions? )","['discrete-mathematics', 'combinatorics']"
1374950,What is wrong with this proof of $0=1$?,"I am trying to understand what is wrong with the proof posted here that $0=1$ ( source ): Given any $x$, we have (by using the substitution $u=x^2/y$) $$\large\int_0^1\frac{x^3}{y^2}e^{-x^2/y}\,dy=\Biggl[xe^{-x^2/y}\Biggr]_0^1=xe^{-x^2}.$$
  Therefore, for all $x$,
  \begin{align}
e^{-x^2}(1-2x^2)&=\frac{d}{dx}(xe^{-x^2})\\[0.5em]
&= \frac{d}{dx}\int_0^1\frac{x^3}{y^2}e^{-x^2/y}\,dy\\[0.5em]
&= \int_0^1\frac{\partial}{\partial x}\Biggl(\frac{x^3}{y^2}e^{-x^2/y}\Biggr)\,dy\\[0.5em]
&= \int_0^1 e^{-x^2/y}\Biggl(\frac{3x^2}{y^2}-\frac{2x^4}{y^3}\Biggr)\,dy.
\end{align}
  Now set $x=0$; the left-hand side is $e^0(1-0)=1$, but the right-hand side is $\int_0^1 0\,dy=0$. Surely it must be incorrect somewhere however I am not sure at which step it fails.","['calculus', 'real-analysis', 'fake-proofs']"
1374977,Checking logarithm inequality.,"Which one of the following is true. $(a.)\ \log_{17} 298=\log_{19} 375 \quad  \quad  \quad  \quad (b.)\ \log_{17} 298<\log_{19} 375\\
(c.)\ \log_{17} 298>\log_{19} 375 \quad  \quad  \quad  \quad (d.)\ \text{cannot be determined} $ $17^{2}=289 $ it has a difference of $9$ and $19^{2}=361$ it has a difference of $14$ . I am not aware of any method if it is there to check such problems, I would also prefer a method without calculus unless necessary. I look for a short and simple way . I have studied maths up to $12$th grade.","['logarithms', 'algebra-precalculus', 'inequality']"
1375019,Show that $Y = \sum_{i=1}^n Y_i$ is distributed as $\chi _{2n}^2$.,"The Statement of the Problem: Suppose that $X_1,\ldots, X_n$ is a random sample from the $U(0,1)$ distribution and $$ Y_i = -2\log X_i. $$ Show that $Y = \sum_{i=1}^n Y_i$ is distributed as $\chi _{2n}^2$. Where I Am: Ok. So, I've got some dots that I can't seem to connect. Upon consideration of the cdf of $Y_i$... $$P(Y_i < x) = P(-2\log X_i < x) = P(\log X_i > -\frac{1}{2}x) = P(X_i > e^{-x/2}) = 1- P(X_i < e^{-x/2})$$ [EDITED MATERIAL BEGINS HERE] So, we see that $$ P(Y_i < x ) = 1 - P(X_i < e^{-x/2}) = 1 - F_{X_i}(e^{-x/2}) $$ and because $X_i \sim U(0,1)$ $$ 1 - F_{X_i}(e^{-x/2}) = 1 - \frac{e^{-x/2}-0}{1-0} = 1 - e^{-x/2} $$ which is the cdf of a chi-squared r.v. with $2$ degrees of freedom. Therefore $$ Y_i \sim \chi_{2}^2 $$ [EDITED MATERIAL ENDS HERE] Here, I feel like I'm getting close to the special case of the cdf of a chi-squared r.v. in which $k=2$, i.e. $$ F(x;2) = 1-e^{-x/2} \qquad \text{(thanks Wikipedia)}. $$ However, I assume it's not the case that $$ P(X_i > e^{-x/2}) = P(X_i < 1 - e^{-x/2}). \quad (*)$$ Or is that actually true? And, if it is, does that suffice to show that, indeed, $$ X_{i} \sim \chi _{2}^2? $$ I'm aware that $$ X \sim U(0,1) \implies -2\log(X) \sim \chi _{2}^2 \qquad \text{(thanks again Wikipedia)}$$ But, I don't know if this has sufficiently shown that. Finally, I know that the sum of independent chi-squared r.v.'s is also has a chi-squared distribution. From this property, it's clear that I have a sum of $n$ independent chi-squared r.v.'s, each with $2$ degrees of freedom, meaning, of course, that $$ Y \sim \chi _{2n}^2$$ completing the proof. So, yeah, it's just mostly putting this together into a coherent proof without relying too much on properties given by Wikipedia. Any help, of course, would be appreciated. Thanks!","['probability', 'statistics']"
1375028,$\int_0^\infty \frac{\log(x)}{x^2+\alpha^2}$ using residues,"I'm trying to find $\int_0^\infty \frac{\log(x)}{x^2+\alpha^2}dx$ where $\alpha>0$ is real.  My approach was to take an integral along the real line from $1/R$ to $R$, around the circle counterclockwise to $-R$, along the real line to $-1/R$, and then around the circle clockwise to $1/R$.  I have encountered 2 problems with this: This path encloses one pole, at $z=\alpha i$.  I found the residue at $z=\alpha i$ to be $\frac{\ln(\alpha)+i\pi/2}{2\alpha i}$.  However, this gives me that $\int_0^\infty \frac{\log(x)}{x^2+\alpha^2}dx=\frac{\pi(\ln(\alpha)+i\pi/2)}{2\alpha}$.  Since I have a real function integrated over the real line, there cannot be an imaginary part.  Where did I go wrong?  (Also, doing a few examples, the correct answer seems to be $\frac{\pi\ln(\alpha)}{2\alpha}$, the same as I have but without the imaginary part.) At first chose my path so instead of going all the way around the upper semicircle, it only went 3/4 of the way around, as I wanted to avoid anything that might go wrong with the discontinuity of $\log(x)$ at the negative real axis.  When I do this, though, I get a different answer than before (the denominator of the fraction is $\alpha(1-e^{3\pi i/4})$ instead of $2\alpha$.  What am I doing wrong that gives me different answers?","['complex-analysis', 'residue-calculus']"
1375033,Median of waiting time for $k$-th ace from bridge cards,"I can't figure out how to get median of a waiting time from the exercise 36 from W. Feller's book An Introduction to Probability Theory and Its Applications Vol.1 (bold in the quote): Distribution of aces among $r$ bridge cards . Calculate the probabilities $p_0(r), p_1(r), \dotso, p_4(r)$ that among $r$ bridge cards drawn at random there are $0, 1, \dotso, 4$ aces, respectively. Verify that $p_0(r) = p_4(52-r)$. Continuation: waiting times . If the cards are drawn one by one, find the probabilities $f_1(r), f_2(r), \dotso, f_4(r)$ that the first, ..., fourth ace turns up at the $r$th trial. Guess at the medians of the waiting times for the first, ..., fourth ace and then calculate them . $p_k(r)$ and $f_k(r)$ were easy (I'm not sure about $f_k(r)$ though): $$
p_k(r)
	= \frac{\binom{4}{k} \binom{48}{r-k}}{\binom{52}{r}}
	= \frac{\binom{4}{k} (r)_k (52-r)_{4-k}}{(52)_4}
$$ $$
f_k(r)
	= \frac{\binom{4}{k} \binom{r-1}{k-1} (48)_{r-k}}{(52)_r}
	= \frac{\binom{4}{k} \binom{r-1}{k-1} (52-r)_{4-k}}{(52)_4}
$$ In answers section, Mr. Feller introduces probabilities that the waiting times for the first,..., fourth ace exceed $r$ ($k$ is for k-th ace): $$
w_k(r) = \sum_{i=0}^{k-1} p_i(r)
$$ From this he arrives at $f_k(r)$: $$
f_k(r) = w_k(r-1) - w_k(r)
$$ And then he gives computed medians (see spoiler below) without any explanation of how they were derived. $9$, $20$, $33$, $44$ If I'm not mistaken, the median is the solution of
$$w_k(r) = 0.5$$
for $r$. This however leads to quite complicated equation with many factorials which I wasn't able solve even with Stirling approximation. How can I easily compute those medians? Graph of functions above:","['median', 'probability', 'combinatorics']"
1375036,Intuition on Martin-Löf-Test for finite strings,"The followng example is from An Introduction to Kolmogorov Complexity and Its Applications , Example 2.4.1. and is concerned with Martin-Löf-Tests for finite strings: A string $x_1 x_2 \ldots x_n$ with many initial zeros is not very random. We can test this aspect as follows. The special test $V$ has critical regions $V_1, V_2, \ldots$. Consider $x = 0.x_1 x_2\ldots x_n$ as a rational number, and each critical region as a half-open interval $V_m = [0, 2^{-m})$ in $[0,1)$, $m = 1,2,\ldots$. Then the subsequent critical regions test the hypothesis ""$x$ is random"" by considering the subsequent digits in the binary expansion of $x$. We reject the hypothesis on the significane level $\epsilon = 2^{-m}$ provided $x_1 = x_2 = \ldots = x_m = 0$. Now I have a problem with intuition. Consider some very irregular, uncompressible string $w$ of length $n$ which starts with zero, then $w \notin V_1$ and hence would be classified as not random by this test, just because its starts with zero but otherwise is very irregular (hence very ""random"")?","['probability-theory', 'random', 'statistics', 'algorithmic-randomness', 'computability']"
1375039,Cardinality of a set of natural sequences,"Let $a=(a_n)_{n\ge 1}$ a sequence such that for every $n\ge 1$ we have: a) $a_n \in\mathbb{N}$ b) $a_n\lt a_{n+1}$ c) Exists $\displaystyle\lim_{n\to \infty}  \frac{\#\{j\mid a_j\le n\}}{n}$ Let $A$ the set of the sequences that meet the aforementioned conditions. Which is the cardinal of $A$? I have no idea, I don't known how to interpret the last condition. Any hint?","['sequences-and-series', 'elementary-set-theory', 'cardinals']"
1375049,"Given a variable $X$ with a PDF, what is the PDF of $\sqrt{X}$","I feel this is simple and I'm overlooking something really basic. Let's say a have a variable $x$ which obeys the exponential distribution . So if collect 100000 occurrences of $x$ and plot its histogram along with the formula for the exponential distribution (with $\lambda=1$), we have the following graph, where the blue bars are the ""actual"" values taken experimentally and the green line is theoretical prediction. Now to my question: If instead I get the occurrences of $x^{1/2}$ instead of $x$ (with $x$ still obeying the same PDF), take the histogram of the 100000 positions array and plot it, I have something like the following graph. The problem is that I can't figure out the probability distribution in this case. I have found similar answers here and here but none of them quite solve it for me. Any help is appreciated. Thank you.","['probability', 'statistics', 'probability-distributions', 'random-variables']"
1375070,How do I use interpolation with the Z table?,"My textbook has an example of interpolation, but I am not sure how the book did it since it doesn't explain it. It says if we want $P(Z < 1.246)$ we must use interpolation and the steps given are: $$P(Z < 1.24) + (6/10)[P(Z < 1.25) - P(Z < 1.24)].$$ Can someone explain to me where the $(6/10)$ came from? Shouldn't it be $(6/1000)$ since the $1.24+0.006 = 1.246?$ I am very very confused about how they got the 6 out of 1.246.","['probability', 'statistics', 'interpolation']"
1375071,Understanding the definition of $P(Y = y \mid X = x)$,"Let $X: \Omega \rightarrow E_X$ and $Y: \Omega \rightarrow E_Y$ be random variables. By definition , we have that $P(Y = y \mid X = x)$ is defined as follows: $$
P(Y = y \mid X = x) = \frac{P(X = x \cap Y = y)}{P(X = x)}
$$ Question : Isn't it possible that $X$ and $Y$ have distinct probability distributions (say, $P_1$ and $P_2$)? If so, which probability distribution does this definition refer to when it uses $P(\cdots)$?",['probability-theory']
1375078,Algebraic proof that $\sum\limits_{i=0}^n \binom{i}{k} = \binom{n + 1}{k + 1}$,"I'm looking for an algebraic proof of this identity for $n, k \in \mathbb{N}$: $$\sum\limits_{i=0}^n \binom{i}{k} = \binom{n + 1}{k + 1}$$ So far, I've turned the left hand side of the equality into $\frac{1}{k!}\sum\limits_{m=0}^{n-k} \frac{(m+k)!}{m!}$, but I got stuck there and can't get any further.","['summation', 'algebra-precalculus', 'combinatorics', 'binomial-coefficients']"
1375082,Determine the value of $ p $ for which the following infinite series converges and for which it diverges.,"Determine the value of $ p $ for which the following infinite series converges and for which it diverges:
$$
\sum_{n = 2}^{\infty} \frac{\sqrt{n + 2} - \sqrt{n - 2}}{n^{p}}.
$$
I don’t know how to start.","['sequences-and-series', 'real-analysis']"
1375084,Find a plane with distance $3$ from $3x-y-z = 0$,"I need to find a plane such that its distance from the plane $3x-y-z = 0$ is $3$. Since distance is defined only for parallel planes, I already know that they have to be parallel, and then, the equation of the new plane will have the same normal vector $(3,-1,-1)$. Also, this plane intersects the origin, because $(0,0,0)$ satisfies its equation. So my idea was to normalize the normal vector, and then multiply it by $3$. I could then put it in the origin and see it as a point of distance $3$ from the origin (and also from the plane), and then this point should be in the new plane, so it must satisfy is equation, which is: $$3x-y-z + d = 0$$ I think this migth work, but I don't think it's the best way to solve this exercise. A friend of mine sent me a solution like this: $$3(x-x_0) -1(y-y_0) -1(z-z_0) = 0 \\3x -y -z + (-3x_0 +y_0+z_0) = 0$$ then we should find $P = (x_0,y_0,z_0)$ such that $-3x_0 +y_0+z_0 = 0$. Then, $3P$ should be a point of the new plane, and therefore satisfy its new equation. What's the best way to solve this, and could you explain my what my friend did in his solution?","['geometry', 'linear-algebra', 'analytic-geometry']"
1375090,"Am I getting the right answer for the integral $I_n= \int_0^1 \frac{x^n}{\sqrt {x^3+1}}\, dx$?","Let $I_n= \int_0^1 \dfrac{x^n}{\sqrt {x^3+1}}\, dx$. Show that $(2n-1)I_n+2(n-2)I_{n-3}=2 \sqrt 2$ for all $n \ge 3$. Then compute $I_8$. I get an answer for $I_8={{2 \sqrt 2} \over 135}(25-16 \sqrt 2)$, could somebody please check against my answer and see if I made a mistake.","['calculus', 'definite-integrals', 'integration']"
1375106,Riemannian metrics and how spaces look,"I thought I had a fairly good understanding of Riemannian metrics until I came across this exercise in Petersen's book. Construct paper models of the Riemannian manifolds ($\mathbb{R}^2, dt^2 + a^2t^2d \theta ^2$). If $\alpha = 1$, this is of course the Euclidean plane, and when $\alpha < 1$, they look like cones. What do they look like when $\alpha >1$? I fail to understand why changing the numbers that you assign to a pair of vectors in a tangent space (changing the Riemannian metric) would make a figure look different. If I give $\mathbb{R}^2$ Cartesian coordinates why would changing the inner product cause any difference in the way it looks? Is there some intuition behind Riemannian metrics that I am missing? Thank you.","['differential-geometry', 'riemannian-geometry']"
1375137,How do I determine the domain and range of the following relations using set builder notation?,"I have been given the following relations to find the domain and range of using builder notation. (The blue writing is what I have so far) I am just beginning to learn the whole concept of set builder notation, and I am running into a little confusion. I understand the x and y axis, as well as the form it is written in. I'm confused with question b and c, because of the arrow end points that 'keep going'.","['graph-theory', 'notation', 'algebra-precalculus', 'functions']"
1375144,"Integration validity of $\int\frac{1}{\sqrt{a^2 + x^2}}\,dx$","I'm just wondering if the following integration is valid. \begin{array}{l}
\int {\frac{1}{{\sqrt {{a^2} + {x^2}} }}} dx\\
{\rm{Let }}{u^2} = {a^2} + {x^2}\\
2udu = 2xdx\\
\frac{{du}}{x} = \frac{{dx}}{u}\\
{\rm{Let }}\frac{{du}}{x} = \frac{{dx}}{u} = A\\
du = Ax\\
dx = Au\\
\frac{{du + dx}}{{x + u}} = \frac{{Ax + Au}}{{x + u}} = A = \frac{{dx}}{u}\\
\int {\frac{1}{{\sqrt {{a^2} + {x^2}} }}} dx\\
 = \int {\frac{1}{{\sqrt {{u^2}} }}} dx\\
 = \int {\frac{1}{u}} dx\\
 = \int {\frac{{du + dx}}{{x + u}}} \\
 = \int {\frac{{d\left( {u + x} \right)}}{{x + u}}} \\
 = \ln \left| {x + u} \right| + C\\
 = \ln \left| {x + \sqrt {{a^2} + {x^2}} } \right| + C
\end{array}",['integration']
1375149,Should I use set notation or list notation when writing out a basis of vectors?,"I think in Sheldon Axler's Linear Algebra Done Right , he makes a comment about why the technically correct way is to write vectors in lists, such as $(v_1, ... v_n)$, while many books use set notation, such as $\{v_1, ... , v_n\}$. I believe set notation just includes the distinct vectors, while lists allow repeat vectors, such as this list $(v_1, v_2, v_2, ..., v_1, v_n)$. Or is it not important and both are acceptable?","['notation', 'vector-spaces', 'linear-algebra']"
1375156,"If $m$ divides $n$, find a free resolution of $\mathbb{Z}/m$ as a $\mathbb{Z}/n$-module.","If $m$ divides $n$, find a free resolution of $\mathbb{Z}/m$ as a $\mathbb{Z}/n$-module. I have tried this one and got $0 \leftarrow \mathbb{Z}/m \leftarrow \mathbb{Z}/n \leftarrow \mathbb{Z}/n$. The map $\mathbb{Z}/n \to \mathbb{Z}/n$ is multiplication by $m$, but I couldn't go further. Please help me.","['homological-algebra', 'abstract-algebra', 'modules', 'commutative-algebra']"
1375158,"$S$ and $T$ are two sets. Prove that if $|S-T|=|T-S|$, then $|S|=|T|$.","Here is the problem that I am currently working on: $S$ and $T$ are two sets. Prove that if $|S-T|=|T-S|$, then $|S|=|T|$. I have access to the answer for this proof, and wanted help with the first assumption. Here is the answer I have been given to the proof: Since $|S-T|=|T-S|$, there exists a bijective function $g\colon S-T\to T-S$. Let $i\colon S\cap T\to S\cap T$ be the identity function on $S\cap T$. Then we know that the function $f\colon S\to T$ defined by 
  $$
f(x)=
\begin{cases}
g(x) &\text{if $x\in S-T$}\\
i(x) &\text{if $x\in S\cap T$}
\end{cases}
$$
  is bijective. Now using the fact of cardinality $\Rightarrow |S|=|T|$. My first question is: how would I have known to make the leap into assuming that a bijective function exists? Would I need to consider that I am performing an operation on two sets, and that since I have that equal to another set (with operations), that I can allow this to exist as a bijective function? Or should I come to this assumption because I am showing that the cardinalities of two different groups of sets are the same, meaning that I am trying to show numerical equivalence (which requires a bijective function)? Assuming that I need the bijection to show numerical eq., my next question is regarding the identity function step. I'm not sure where or why we jump to that assumption... Thanks. I am studying for my final in proofs on Wednesday, and while I have a pretty good piecemeal understanding of each topic we've learned, I sometimes have a hard time piecing together multiple proof topic\techniques.","['elementary-set-theory', 'alternative-proof', 'proof-verification', 'proof-writing', 'cardinals']"
1375205,"A sequence inequality for $x_{2^n}$, the binary partition function.","Define the sequence $\{x_{n}\}$ recursively by  $x_{1}=1$ and 
  $$\begin{cases}
x_{2k+1}=x_{2k}\\
x_{2k}=x_{2k-1}+x_{k}
\end{cases}$$
  Prove that
  $$x_{2^n}>2^{\frac{n^2}{4}}$$ I have compute some term $x_{2}=2,x_{3}=2,x_{4}=4,x_{5}=4,x_{6}=6,x_{7}=6,x_{8}=10,\cdots,x_{16}=36,x_{32}=202$ I am unsure what to do from here, I know I somehow need to compare a form of this expression to $x_{2^n}?$, but how? Am I on the right lines?but I don't have any idea how to start proving it",['sequences-and-series']
1375212,Geometric intuition for $\pi /4 = 1 - 1/3 + 1/5 - \cdots$?,"Following reading this great post : Interesting and unexpected applications of $\pi$ , Vadim's answer reminded me of something an analysis professor had told me when I was an undergrad - that no one had ever given him a satisfactory intuitive explaination for why this series definition should be true (the implied assumption being that it is so simple, there should be some way to look at this to make it intuitive). Now it follows simply from putting $x=1$ in the series expansion $$ \tan^{-1}(x) = x - \frac{x^3}{3} + \frac{x^5}{5} - \cdots $$ but I don't see anything geometrically intuitive about this formula either!","['pi', 'number-theory', 'real-analysis', 'sequences-and-series', 'intuition']"
1375214,Infinite limit of trigonometric series,"The value of $\displaystyle\lim_{n\to\infty}(\sin^4x+\frac{1}{4}\sin^4(2x)+\cdots+\frac{1}{4^n}\sin^4(2^nx))$ is (A) $\sin^4x$ (B) $\sin^2x$ (C) $\cos^2x$ (D) does not exist My attempt:
$$\lim_{n\to\infty}(\sin^4x+\frac{1}{4}\sin^4(2x)+\cdots+\frac{1}{4^n}\sin^4(2^nx))=$$
$$=(\sin^4x+\frac{1}{4}16\sin^4x\cos^4 x+\cdots+\frac{1}{4^n}\sin^4(2^{n-1}x)\cos^4(2^{n-1}x)$$ i could not solve further.Any hint will be useful.",['trigonometry']
1375218,demostration of interger part integration.,"I need help for solving this demostration, I  appreciate your suggestions very much. $$\begin{array}{rclr}
\int ^{n}_{0}[x] dx= \frac{n(n-1)}{2} 
\end{array}$$ Pd. If you have any suggestion of a book that deepens on the subject please communicate it.","['definite-integrals', 'integration']"
1375223,A question on the Banach fixed point theorem.,"Suppose $f:(X,\tilde{d})\rightarrow(X,d)$ be a continuous function satisfying \begin{eqnarray}d(f(x),f(y))\leq \lambda d(x,y),\end{eqnarray} $\lambda > 1$. Let $\tilde{d}(x,y)=\lambda d(x,y)$. I observed that the topologies due to $d$ and $\tilde{d}$ are equivalent. Hence the ""contraction"" condition now reads as \begin{eqnarray}d(f(x),f(y))\leq \tilde{d}(x,y).\end{eqnarray} Can it concluded form here that a fixed point exists for $f$?. In other words I was wondering whether the Banach fixed point theorem holds if the metrics in the domain and the range spaces are equivalent and not exactly the same?.","['analysis', 'fixed-point-theorems', 'real-analysis', 'functional-analysis']"
1375232,Comparing $\text{tr}(A^{-1})$ and $\text{tr}(A(B+A)^{-2})$ for pd $A$ and psd $B$,"Suppose that $A$ is positive definite and $B$ positive semidefinite, both with dimension $n\times n$. Is there some inequality between
$$
\text{tr}(A^{-1})\quad\text{and}\quad\text{tr}(A(B+A)^{-2})?
$$ Progress so far : When $n=1$ with $A=a>0$, $B=b\geq 0$, we have
$$
\text{tr}(A(B+A)^{-2})=\frac{a}{(a+b)^2}\leq\frac{a}{a^2}=\frac{1}{a}=\text{tr}(A^{-1}).
$$
So it is suggestive that $\text{tr}(A(B+A)^{-2})\leq \text{tr}(A^{-1})$. I have tried
\begin{align*}
\text{tr}(A(B+A)^{-2})&=\text{tr}[A[B+A]^{-1}[B+A]^{-1}]\\
&=\text{tr}[A[A^{1/2}(A^{-1/2}BA^{-1/2}+I)A^{1/2}]^{-1}[A^{1/2}(A^{-1/2}BA^{-1/2}+I)A^{1/2}]^{-1}]\\
&=\text{tr}[AA^{-1/2}(A^{-1/2}BA^{-1/2}+I)^{-1}A^{-1}(A^{-1/2}BA^{-1/2}+I)^{-1}A^{-1/2}]\\
&=\text{tr}[A^{-1}(A^{-1/2}BA^{-1/2}+I)^{-2}]\\
&\leq\text{tr}[A^{-1}]\text{tr}[(A^{-1/2}BA^{-1/2}+I)^{-2}].
\end{align*}
If $e_1,\ldots,e_n\geq 0$ are the eigenvalues of $A^{-1/2}BA^{-1/2}$, then
$$
\text{tr}[(A^{-1/2}BA^{-1/2}+I)^{-2}]=\sum_{i=1}^n\frac{1}{(e_i+1)^2}\leq \sum_{i=1}^n\frac{1}{(0+1)^2}=n.
$$
Thus, we have proved
$$
\text{tr}(A(B+A)^{-2})\leq n\text{tr}[A^{-1}].
$$
But this isn't really what we seek. Plus, when $B$ is the zero matrix, $\text{tr}(A(B+A)^{-2})=\text{tr}[A^{-1}]$ so it seems the inequality can be made tigher.","['calculus', 'inequality', 'linear-algebra', 'matrices']"
1375285,Prove that $\tan\alpha =\tan^{2}\frac{A}{2}.\tan\frac{B-C}{2}$,"Given a triangle ABC with the sides $AB < AC$ and $AM, AD$ respectively median and bisector of angle $A$. Let $\angle MAD = \alpha$. Prove that $$\tan\alpha =\tan^{2}\frac{A}{2}\cdot \tan\frac{B-C}{2}$$","['geometry', 'triangles', 'trigonometry']"
1375287,Finding $P(X < Y)$ where $X$ and $Y$ are independent uniform random variables,"Suppose $X$ and $Y$ are two independent uniform variables in the intervals $(0,2)$ and $(1,3)$ respectively. I need to find $P(X < Y)$. I've tried in this way:
$$
\begin{eqnarray}
P(X < Y) &=& \int_1^3 \left\{\int_0^y f_X(x) dx\right\}g_Y(y) dy\\
&=& \frac{1}{4} \int_1^3 \int_0^y dx dy\\
&=& \frac{1}{4} \int_1^3 y dy\\
&=& \frac{1}{8} [y^2]_1^3\\
&=& 1
\end{eqnarray}
$$
But I'm suspicious about this result. It implies that $X<Y$ is a sure event, which is not at all true.","['probability', 'random-variables']"
1375322,"A result about commuting matrices in $ M(n, \mathbb{C} ) $","Let $ A $ be a matrix in $ M(n, \mathbb{C} ) $ and let $ A^{*} $ be its Hermitian adjoint. Suppose that the matrices $ A $ and $ AA^{*}-A^{*}A $ commute. Show that $ AA^{*} = A^{*}A $. Here is a sketch of my solution : Lemma : Let $ F $ be a field of characteristic $ 0 $ and $ S,T \in M(n, F) $. Suppose that $ ST-TS $ commutes with $ S $. Then, $ ST-TS $ is nilpotent. We have that $ A $ and $ B = AA^{*} - A^{*}A $ commute, so by the lemma, $ B $ is nilpotent. Also, $ B^{*} = AA^{*} - A^{*}A = B $, so $ B $ is Hermitian. But, $ B $ being both, nilpotent and Hermitian $ \implies $ $ B=0 $ $ \implies $ $ AA^{*} = A^{*}A $ I was wondering whether there is a simpler solution as mine uses some machinery. Any hints please?","['linear-algebra', 'linear-transformations']"
1375347,Find a probability density,"I am going through a paper trying to understand all the single steps, but I got stuck. I need to calculate $$p(x+\delta t) \mid x(t), t)= \int p(x(t+\delta t) \mid \mu , x(t), t)p(\mu\mid  x(t), t) d\mu  $$ where the first term is $$N(x(t+\delta t) \mid x+\mu\delta t, \delta t) $$
and the second term is $$N(\mu \mid x(t)/(t+\sigma ^{-2} ), 1/(t+\sigma ^{-2})) $$ I know that the resulting distribution is $$N(x(t+\delta t) \mid x(t)(1+\delta t /(t+\sigma ^{-2}), \delta t(1+ \delta t/(1+\sigma ^{-2}))) $$ However, I would like to know how to get there.
FYI, the paper is this one: http://www.jneurosci.org/content/32/11/3612.full and the calculation are in the paragraph ""belief transition densities"", by putting together pieces from previous equations. Note that there is a typo for $\delta t_{eff} $, which is equal to $\delta t /(t+ \sigma ^{-2} ) $.","['probability-theory', 'normal-distribution', 'probability', 'probability-distributions']"
1375384,Integral of an expression involving sine and cosine powers,"For integers $a,n\in \mathbb N$, consider the following integral
$$
I_n(a) = \frac{(-i)^x}{\pi}\int_0^\pi e^{i\theta(n-2a)} \sin^x \theta \cos^{n-x} \theta\; \mathrm  d\theta\;.
$$
How would one go around evaluating such an integral? To be completely honest, I am being a bit cheeky here since I know the answer to the question, as I obtained this integral by applying the Cauchy integral formula on the generating function of Kravchuk polynomials. To see the answer, you may point your mouse at the answer paragraph below. What I have been trying to find without success is a direct calculation of this integral (without using the Cauchy integral formula). I have no experience with integrals, so I am most interested in seeing what heuristic rules one takes when evaluating an integral of products of cosines and sines. I am guessing that such products of sines and cosines is seen frequently seen in integrals and hoping there is known way to work with them. Thank you! The value of $I_n(a)$: Consider the expression $\left(\frac{1-z}{2}\right)^x\left(\frac{1+z}{2}\right)^{n-x}$ as a function of $z$. The coefficient of $z^a$ is $\sum_{j=0}^a(-1)^j\binom{x}{j}\binom{n-x}{a-j}\Big/2^n $. Applying Cauchy integral formula on the above function, we get that the coefficient of $z^a$ is also $\frac{1}{2\pi}\oint_0^{2\pi}((1-z)/2)^x((1+z)/2)^{n-x}z^{-(a+1)}\;\mathrm d z$. Now substituting $z=e^{2i\theta}$, and integrating over the unit disk in the counter clockwise direction, we obtain that this latter integral is equivalent to $I_n(a)$.","['integral-transforms', 'trigonometry', 'definite-integrals', 'integration']"
1375397,Describe and count the set of sequences containing $20$ or $02$,"Let $X = \{ 0,1,2 \}$ be a ternary alphabet and denote by $X^*$ the set of finite sequences (i.e. strings) with three symbols. For $w \in X^*$ with $n$ the length of $w$ and $w = w_1 w_2 \cdots w_n$ denote by 
$$\delta(w) = |\{ i \in \{ 2,\ldots, n \} : w_{i-1}w_i \in \{ 02, 20 \}\}|$$ the number of occurrence of $02$ or $20$ as substrings. For some fixed $n$ and $m$ how could we determine
$$
 \{ w \in X^n : \delta(w) \ge m \}
$$
i.e. the set of length $n$ sequences such that the number of occurrences of $20$ or $02$ is greater than or equal to $m$? Also I am interested in the cardinality of this set, i.e. the number $|\{ w \in X^n : \delta(w) \ge m \}|$.","['combinatorics-on-words', 'automata', 'inclusion-exclusion', 'combinatorics', 'formal-languages']"
1375430,"If two matrices have the same trace and determinant, do their powers have the same trace?","Let $A,B$ be two $2 \times 2$ matrices over some finite field $\mathbb{F}_q$, such that they have the same trace and determinant. Does this imply that tr $A^k$ = tr $B^k$ for any integer $k$? I've checked the case $k=2$, which works and makes use of the fact that they have the same determinant as well as the same trace, but can't seem to generalise this to an induction proof. Do I need stronger hypotheses for this? Note that the answer is trivially true if the matrices are similar but I am more interested whether it holds even if they are not similar.","['linear-algebra', 'trace', 'matrices']"
1375431,Probability in knockout games.,"Suppose in a knockout tournament 32 players p1 , p2 .....p32 participate. In each round players are divided into pairs at random and winner goes to the next round. If p5 reaches semifinal what is the probability that p1 wins the tournament? All players are equally skilled.","['probability-theory', 'probability', 'probability-distributions']"
1375461,Arrangement counting problem,"This is my son's exercise: How many ways that 6 rabbits can be put in 10 cages. I count in 2 different ways: The first rabbit can be in any of 10 cages. Same for the second and so on. So in total, there will be $10^6$ ways. On the other hand, I list all possible cases: 6 rabbits in the same cage: there are $C^6_6*10=10$ ways of doing so. 5 rabbits in the same cage, the other one in a different cage. There will be: $C^6_5*10*9=540$ ways. ($6=5+1$) 4 rabbits in the same cage, the other 2 in a different cage. There will be $C^6_4*10*9=1350$ ways. ($6=4+2$) 4 rabbits in the same cage, 1 in different cage, 1 in another different cage. There will be $C^6_4*10*9*8=10800$ ways. ($6=4+1+1$) 3 rabbits in the same cage, 1 in different cage, 1 in another different cage and 1 in other cage. There will be $C^6_3*10*9*8*7=100800$ ways. ($6=3+1+1+1$) 3 rabbits in the same cage, 2 in different cage, 1 in another different cage. There will be $C^6_3*10*C^3_2*9*8=43200$ ways. ($6=3+2+1$) 3 rabbits in the same cage, 3 in different cage. There will be $C^6_3*10*9=1800$ ways. ($6=3+3$) 2 rabbits in the same cage, 2 in different cage and 2 in another different cage. There will be $C^6_2*10*C^4_2*9*8=64800 $ ways ($6=2+2+2$) 2 rabbits in the same cage, 2 in different cage, 1 in another different cage and 1 in other cage. There will be $C^6_2*10*C^4_2*9*8*7=453600$ ways. ($6=2+2+1+1$) 2 rabbits in the same cage, each of the other 4 is in different cage. There will be $C^6_2*10*9*8*7*6=453600$ ways ($6=2+1+1+1+1$) 6 rabbits in 6 different cages. There will be $C^{10}_6*6!=151200$ ways In total, there will be $1,281,700$ ways which doesn't match with the first calculation. Could anyone explain to me why?",['combinatorics']
1375470,Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen,"Suppose I have a set of 100 integers. I randomly choose 10 of those, make a note of which ones I selected, and repeat the process. What is the expected number of times this process must be repeated before I see all 100 integers? I'm also greatly interested in how this is calculated as I'm trying to increase the expected number of times this process is repeated by changing the set sizes.","['expectation', 'combinations', 'probability', 'optimization', 'coupon-collector']"
1375473,Question based on triangle inscribed in unit circle,"$ \bigtriangleup ABC $is inscribed in a unit circle.If angle bisectors of internal angles at A,B and C meet the circle at D,E and F respectively then value of $\frac{AD \cos\frac{A}{2}+BE \cos\frac{B}{2}+CF \cos\frac{C}{2}}{sin A+sinB+ sinC}$is ? My attempt:AD,BE,CF are angle bisectors,so they meet at incenter of triangle but i dont know whether this incenter will be the center of unit circle or not.If this incenter is not center of unit circle,then i have no clue to proceed.","['geometry', 'trigonometry']"
1375480,Reference request: The compactness and compact embedding in Besov Space?,"This post has been on MathOverflow for couple of days but receive no response. So I put it here hoping for more attentions. Thank you guys! Let $\Omega\subset \mathbb R^N$ be open bounded with smooth boundary. Let $0<s<1$, $1\leq p<\infty$, and $1\leq \theta\leq\infty$. We denote by $B^{s;p,\theta}(\Omega)$ the Besov space.  For definition of Besov space we refer to Leoni's book , Chapter 14, section 14.1. (Also this book by Adam, page 230, section 7.32.) Theorem 14.29 in Leoni's book states the continuous imbedding theorem for Besov space. (For simplification, let's assume $p=1$.) We have $B^{s;1,\theta}(\Omega)$ continuous imbedded in $L^{\frac{N}{N-s}}(\Omega)$ for $1\leq \theta\leq \frac{N}{N-s}$. We now take $r<\frac{N}{N-s}$. My question is: do we have $B^{s;1,\theta}(\Omega)$ is COMPACT imbedded in $L^{r}$? I think the answer is yes because according to this post , exercise 15, that sequences bounded in a high regularity space, and constrained to lie
  in a compact domain, will tend to have convergent subsequences in low
  regularity spaces. So I would think my conjecture is true. However, I did a deep search over the internet but has no lucky to find such result. If there is no such result, please let me know (and maybe a counterexample?). If there is, please direct me to a reference. Thank you!","['sobolev-spaces', 'real-analysis', 'functional-analysis', 'reference-request', 'partial-differential-equations']"
1375481,High computation in probability,"Six men and some number of women stand in a line in random order. Let $p$ be the probability that a group of at least four men stand together in the line, given that every man stands next to at least one other man. Find the least number of women in the line such that $p$ does not exceed 1 percent. Obviously: $$\overbrace{P(\text{at least four in a line})}^{P_T} = P(\text{4 in line}) + P(\text{5 in line}) + P(\text{6 in line})$$ But first the counting Aspect. We have lined up: $$MMMMMMWWWWWW...$$ To get exactly $2$ groups of $4$ men,  we have choices: $$MMWMMMM \space \text{AND} \space MMMMWMM$$ But I see that we could also have: $$MMWWWWWWWWWMMMM \space \text{AND} \space MMMMWWWWWWWWMM$$ So suppose we have $x$ women, so $x*W$ total. Then I am confused. To get two groups of four men together, how many ways are there? I would say $2$ but that doesnt use $x$ or $W$ then?","['contest-math', 'algebra-precalculus', 'elementary-number-theory', 'combinatorics', 'probability']"
1375495,The set of all real functions of a real variable,"How can I prove that the set of all real functions of a real variable,
  or even that the set of functions that take only the values 0 and 1,
  more than the continuum? I have one idea, but it's not remarkable for its rigor and formality. I suppose that the power of all real functions is $\mathfrak{c}^\mathfrak{c}$ and the power of all functions that take only the values 0 and 1 -- $2^\mathfrak{c}$. So how $$\mathfrak{c}^\mathfrak{c} = 2^{\aleph_{0}\mathfrak{c}}=2^\mathfrak{c}>\mathfrak{c}.$$
Could you give more rigorous proof?",['elementary-set-theory']
1375503,"Complement of the union of countably many , mutually disjoint , non-empty open balls in $\mathbb R^n , (n >1) $ is path connected?","Let $n \ge 2$ and $\{B_m\}_{m=1}^\infty$ be countably infinitely many , mutually disjoint , non-empty  open balls in $\mathbb R^n$ , then is $\mathbb R^n \setminus \cup_{m=1}^\infty B_m$ path-connected ?","['analysis', 'metric-spaces', 'normed-spaces']"
1375505,Diffeomorphism between $\Bbb{R}^{4}$ and the cube,"I'm looking for an explicit diffeomorphism between the four-dimensional euclidean space $\Bbb{R}^{4}$ and the four-dimensional open cube. I wonder whether there is a simple looking map, with simple looking derivatives (I need to induce a metric on the cube from the space, and I'd prefer it didn't look terribly complicated at the end). Is anybody able to help me with this?","['differential-topology', 'differential-geometry', 'riemannian-geometry']"
1375509,Union of sets proof,"Prove that $\{3t\}\cup\{3t+1\}\cup\{3t+2\}=\Bbb Z$, where $t$ is in the set of integers. It makes sense that you can get every integer from this Union of sets but how would you prove something like that?",['elementary-set-theory']
1375518,"Explicit construction of a nonmeasurable set, where only the proof of correctness uses choice?","By Solovay's theorem, assuming the existence of an inaccessible cardinal, the axiom of choice is necessary to prove the existence of nonmeasurable sets. In the past, I've thought that one consequence of this theorem is that if I construct a set without using choice (or even merely using dependent choice), then I don't have to worry about it being nonmeasurable. But now I realize that I was making an unjustified assumption. I'm not sure what the appropriate way to precisely phrase this question is, but I'm wondering: is there a non Lebesgue measurable set $E \subseteq \mathbb{R}$ which can be explicitly defined? I'm imagining that perhaps $E$ can be defined without invoking choice (unlike Vitali sets or their cousins), but then proving that $E$ is nonmeasurable requires choice. Is this possibility also ruled out by Solovay's theorem somehow?","['lebesgue-measure', 'logic', 'axiom-of-choice', 'measure-theory']"
1375531,evaluate $\frac 1{1+\sqrt2+\sqrt3} + \frac 1{1-\sqrt2+\sqrt3} + \frac 1{1+\sqrt2-\sqrt3} + \frac 1{1-\sqrt2-\sqrt3}$,Evaluate $\frac 1{1+\sqrt2+\sqrt3} + \frac 1{1-\sqrt2+\sqrt3} + \frac 1{1+\sqrt2-\sqrt3} + \frac 1{1-\sqrt2-\sqrt3}$ How to evalute this equation without using calculator?,"['contest-math', 'algebra-precalculus']"
1375549,Counterexample in relations: $(S \setminus T) \circ R \subseteq (S \circ R) \setminus (T \circ R)$,"Suppose $R$ is a relation from $A$ to $B$ and $S$ and $T$ are relations from 
$B$ to $C$. Can anyone produce a counterexample to  $(S \setminus T) \circ R⊆(S \circ R) \setminus (T \circ R)$?","['elementary-set-theory', 'function-and-relation-composition', 'examples-counterexamples', 'relations']"
1375550,The same topologies,"Let $L^1 (\mathbb{Z})$ be the space of all functions $f:\mathbb{Z}\rightarrow \mathbb{C}$ such that $\left\{\|f\|=\sum_{k\in \mathbb{Z}}|f(k)|<\infty\right\}$. Clearly,   $L^1 (\mathbb{Z})$  is a separable, commutative, unital Banach algebra  with usual convolution. It is easy to see that the character space of $L^1 (\mathbb{Z})$  is homeomorphic to
${T}=\{z\in \mathbb{C}:\ |z|=1\}$. Are the Gelfand and norm topologies equal, on the character space of $L^1 (\mathbb{Z})$?","['functional-analysis', 'banach-algebras', 'general-topology']"
1375583,An inequality for the dimension of the sum of subspaces,"The answer with the most of upvotes on MO is this answer on $\dim(U+V+W)$. Question : 1. Is it nonetheless true that every three vector subspaces $U$, $V$ and $W$ of a vector space $M$ satisfy $$ \dim(U +V + W) \le $$ $$ \dim U + \dim V + \dim W - \dim (U \cap V) - \dim (U \cap W) - \dim (V \cap W) + \dim(U \cap V \cap W) $$ ? 2. And, more generally, that $$\dim(\sum_{i = 1}^{n} U_i) \le \sum_{r=1}^{n} (-1)^{r+1} \sum_{i_1 < i_2 < \dots < i_r} \dim(\bigcap_{s=1}^{r}U_{i_s}) ? $$",['linear-algebra']
1375610,Is the real number $\sqrt{6}$ in $\mathbb{R}$ equal to the 5-adic number $\sqrt{6}$ in $\mathbb{Q}_5$?,"My question is as in the title. That is, consider solving the equation $x^2-6=0$ in $\mathbb{R}$ and in the 5-adic field $\mathbb{Q}_5$ respectively. We obtain one $\sqrt{6}\in\mathbb{R}$ and one $\sqrt{6}\in\mathbb{Q}_5$. Could you tell me whether the real $\sqrt{6}$ and the 5-adic number $\sqrt{6}$ are equal to each other? Thanks very much!","['p-adic-number-theory', 'number-theory', 'algebraic-number-theory']"
1375623,limit of $x \cot x$ as $x\to 0$.,"I was asked to calculate $$\lim_{x \to 0}x\cot x  $$
 I did it as following (using L'Hôpital's rule):
$$\lim_{x\to 0} x\cot x = \lim_{x\to 0} \frac{x \cos x}{\sin x} $$ We can now use L'Hospital's rule since the limit has indeterminate form $\frac{0}{0}$. Hence $$\begin{align}\lim_{x\to 0}\frac{(x \cos x)'}{(\sin x)'}   &= \lim_{x\to 0}\frac{-x\sin x + \cos x}{\cos x} \\ &= \lim_{x\to 0}\frac{-x\sin x}{\cos x} + 1 \\[4pt ]&= \lim_{x\to 0} - x \tan x + 1 \\[4pt] &= 1 \end{align}$$
I think that the result is correct but are the arguments correct?","['calculus', 'limits']"
1375624,find $\left( \frac{x}{x+y} \right)^{2007} + \left( \frac{y}{x+y} \right)^{2007}$,"I found this questions from past year maths competition in my country, I've tried any possible way to find it, but it is just way too hard. if $x, y$ are non-zero numbers satisfying $x^2 + xy + y^2 = 0$ , find the value of $$\left(\frac{x}{x+y} \right)^{2007} + \left(\frac{y}{x+y} \right)^{2007}$$ (A). $2$ (B). $1$ (C). $0$ (D). $-1$ (E). $-2$ expanding it would give us $$ \frac { x^{2007} + y^{2007}} {(x+y)^{2007}}$$ how do I calculate this? Very appreciate for all of those who had helped me","['contest-math', 'algebra-precalculus']"
1375642,Function of several variables which is continuous at single point,Examples of functions on $\mathbb{R}$ which are continuous at a single point are well known. But what about $f:\mathbb{R}^2\to \mathbb{R}$ which is continuous at a single point? I tried to proceed as the one dimension case. I wanted to define $f=g_1$ on $\mathbb{Q}\times \mathbb{Q}$ and $f=g_2$ on $(\mathbb{R}\setminus \mathbb{Q})\times (\mathbb{R}\setminus \mathbb{Q})$ where $g_1=g_2$ has a unique solution. But in here I am leaving out $\mathbb{Q}\times (\mathbb{R}\setminus \mathbb{Q})$ and $(\mathbb{R}\setminus \mathbb{Q})\times \mathbb{Q}$. And I don't know what to define on those sets. Some ideas? I want to generalize such examples to $f :\mathbb{R}^n\to \mathbb{R}^m$. Thanks a lot.,"['continuity', 'multivariable-calculus']"
1375643,Is every Hilbert space a Banach algebra?,"Let $H$ be a Hilbert space. Could we say that, always there is a multiplication on $H$, that makes it into a Banach algebra? If not, under which conditions does it exist?","['banach-algebras', 'harmonic-analysis', 'hilbert-spaces', 'functional-analysis']"
1375677,Proof of Cohn's Irreducibility Criterion,"I was looking for an elementary (or involving introductory level abstract algebra/analysis) proof of Cohn's Irreduciblity Criterion: If
  $$ a_0, a_1, \dots, a_n \in \Bbb{Z} $$ 
  and 
  $$ 0 \le a_i \le t$$ 
  and
  $$ a_0 + a_1t + a_2t^2 +\cdots + a_nt^n \in \{ \text{Primes} \} $$ 
  then the polynomial
  $$ a_0 + a_1 x + a_2 x^2 +\cdots+ a_nx^n $$ 
  is irreducible. I began to plot out a proof. Assume that we have a polynomial that does evaluate to a prime for some $t$ satisfying the inequalities above. Then it follows, that if this polynomial is factorable, it would be factored into $$ (b_0 + b_1x + b_2x^2 + \cdots+ b_rx^r )(c_0 + c_1x + c_2x^2 + \cdots+ c_jx^j) $$ Whereas Without loss of generality we can assume $$ c_0 + c_1t + c_2t^2 + \cdots+ c_jt^j = \pm P$$ (the prime in question is $P$) $$ b_0 + b_1t + b_2t^2 + \cdots+ b_rt^r = \pm 1 $$ From here I am not clear how to proceed. Another Idea: We can try to do something with induction. Lets start with the base case of the polynomial $b_0 + b_1x +\cdots $ being linear $$ b_0 + b_1 t = 1 $$ Tells us that 
$$ t = \frac{1 - b_0}{b_1} $$ But since $b_0 \ge 0, b_1 \ge 0 , t \ge 0$ it follows that $b_0 = 0$ (but then the value P never could have been prime since it would be divisible by t) So we conclude that the polynomial has no linear factors that way. On the flip side it could be that $$ b_0 + b_1 t = -1$$ $$ t = \frac{-1-b_0}{b_1} $$ Theres no $b_0 > 0$ that can make this expression greater than 0. So this case is covered. Thus we conclude there are NO linear factors. But I have no idea how to generalize this technique in a way that knocks out other polynomials too. especially given that from degree $5$ onwards there isn't even an algebraic formula for me to work with, expressing $t$.","['number-theory', 'irreducible-polynomials', 'abstract-algebra', 'polynomials', 'elementary-number-theory']"
1375705,coefficient of $x^{17}$ in the expansion of $(1+x^5+x^7)^{20}$,"I found this questions from past year maths competition in my country, I've tried any possible way to find it, but it is just way too hard. find the coefficient of $x^{17}$ in the expansion of $(1+x^5+x^7)^{20}$ (A)3400 (B)3410 (C)3420 (D)3430 (E)3440 so it would be $$x^{140} + ...... + 1$$ This requires binomial theorem and Multinomial theorem, but I'm not sure how to calculate it. Any tips or formula would be appreciate.","['contest-math', 'polynomials', 'algebra-precalculus']"
1375708,Is $1992! - 1$ prime?,"Consider the factorials, defined inductively by $1! = 0! = 1$ and $n! = n\cdot(n-1)!$ for $n \geq 2$. Question: Is $1992!-1$ a prime number? The question is from a book, maybe is contest math problem. Now I think 1992 is especial?","['prime-numbers', 'number-theory', 'elementary-number-theory']"
1375712,"$\mathbb{F}_p[T, 1/T]$ is discrete in $\mathbb{F}_p((T)) \times \mathbb{F}_p((1/T))$, adeles.","Let $p$ be a prime number. How do I show that $\mathbb{F}_p[T, 1/T]$ is discrete in $\mathbb{F}_p((T)) \times \mathbb{F}_p((1/T))$?","['abstract-algebra', 'algebraic-number-theory', 'class-field-theory', 'general-topology']"
1375726,Which Hilbert space is isometrically isomorphism with $B(E)$ for some Banach space $E$.,"Consider $H$ as a Hilbert space. How can I find a Banach space $E$, for that, $H=B(E)$ where $B(E)$ is the set of bounded linear operator on $E$?
(At least under some conditions on $H$) Also if the Hilbert space $H$ is Banach algebra, when we can find a Banach space $E$, such that $H$ is a Banach-algebra-isomorphism isometric with some Banach subalgebra of $B(E)$?","['banach-algebras', 'harmonic-analysis', 'hilbert-spaces', 'functional-analysis']"
1375747,"Determine the Galois group of $x^5+sx^3+t$ over $\mathbb{Q}(s,t)$","I'm trying to show that the Galois group of $x^5+sx^3+t$ over $\mathbb{Q}(s,t)$ is $S_5$ . By just looking at the discriminant, it has to be $S_5$ or $F_{20}$ .
I know i could distinguish between those 2 using the weber sextic resolvent, but this is a degree 6 polynomial with 2 parameters and i have no idea how to show that there is no root in $\mathbb{Q(s,t)}$ . Is there another way to see this more easily? Something else i would like to know is:
I think it s true under some conditions that if u specialize s,t in a polynomial as above the galois group can only become smaller. Does anyone know if this is a basic fact or needs more work? Thx in advance","['group-theory', 'galois-theory']"
1375772,Proving that the product of two numbers (in $\mathbb{R}$ or $\mathbb{C}$) is a continuous function.,"This is what is given in the textbook, I will highlight what is confusing me: Product in  field $\mathbb R$ or $\mathbb C$,on $X \times X$ defined as:
$$(x,y)\mapsto xy$$ (Let indicate that map with $B$), we have: $$\|B(x,y)-B(a,b) \|=\|B(x-a,b)+B(a,y-b)+B(x-a,y-b)\| \\ \leq\|B\|\|x-a\|\|b\|+\|B\|\|a\|\|y-b\|+ \|B\|\|x-a\|\|y-b\|$$ $$\leq\|B\|(2\|(a,b)\|\|(x-a,y-b)\|+\|(x-a,y-b)\|^2)=\|B\|\|(x,y)-(a,b)\|(2\|(a,b)\|+ \|(x,y)-(a,b)\|)$$ Where $\|B\|$ signifies the norm of product and $\|\ x \|=\| \ x \|_{\infty}= \max_{1 \leq i \leq k} \|x^i\|_i$, product product of norms on $X^1 \times X^2$. We take a $\delta$ such that at the same time $0< \delta <1 $ and $(2\|(a,b)\|+1)\delta < \epsilon $ are true. From there: $$\|(x,y)-(a,b)\|< \delta \implies \|B(x,y)-B(a,b)\|< \epsilon.$$","['proof-explanation', 'continuity', 'general-topology', 'functions']"
1375825,Are logarithms of prime numbers algebraically independent?,"From Baker's theorem it follows that a linear combination of natural logarithms of prime numbers with non-zero algebraic coefficients can never be zero. Has it been proved that the set of all natural logarithms of prime numbers is algebraically independent over $\mathbb Q$ ? In other words, can we be sure that expressions like the following are never exactly zero?
$$\frac{347}{75}\,\ln^22\cdot\ln3-\frac{173}{100}\,\ln2\cdot\ln^23+\frac{179}{180}\,\ln^32-\ln^33$$","['field-theory', 'prime-numbers', 'number-theory', 'logarithms', 'transcendence-theory']"
1375844,The existential theory is undecidable,"Lemma 1. For any $x$ in the ring $F[t,t^{-1}]$ ($F[t,t^{-1}]$: the polynomials in $t$ and $t^{-1}$ with coefficients in the field $F$), $x$ is a power of $t$ if and only if $x$ divides $1$ and $t-1$ divides $x-1$ (the divisibilities are meant, of course, in $F[t, t^{-1}]$). Lemma 2. Assume that the characteristic of $F$ is zero. Then for any $n$ in the ring $F[t, t^{-1}]$ ($F[t,t^{-1}]$: the polynomials in $t$ and $t^{-1}$ with coefficients in the field $F$), $n$ is a nonzero integer if and only if $n$ divides $1$ and either $n-1$ divides $1$ or $n+1$ divides $1$, and there is a power $x$ of $t$, so that $(x-1)/(t-1)
 \equiv n \pmod {t-1}$. THEOREM. Assume that the characteristic of $F$ is zero. Then the existential theory of $F[t, t^{-1}]$ in the language $\{+, \cdot , 0, 1, t\}$ is undecidable. PROOF. By Lemma 1, we can express the fact that an element $x$ in $F[t, t^{-1}]$ is a power of $t$ by an existential formula $\phi(x)$. By this and Lemma 2, we can express the fact that an element $n$ of $F[t, t^{-1}]$ is an integer by the existential formula $$(\exists x)(\exists y) [\phi (x) \wedge x-1 = (t-1)n+y(t-1)^2] \wedge (\exists z)(\exists w) (nz =1 \wedge  ((n+1)w=1 \text{ or } (n-1)w=1)$$ 
Call the last formula $\psi(n)$. Assume for the sake of contradiction, that the existential theory of $F[t, t^{-1}]$ is decidable. Then we can algorithmically examine the solvability of a diophantine equation in the rational integers in the following way: if $P(X_1, \dots , X_n)=0$ is a given diophantine equation, we consider the existential formula $$(\exists x_1) \dots (\exists x_n) P(x_1, \dots , x_n)=0 \wedge \psi(x_1) \wedge \dots \psi(x_n)$$ Clearly, the equation of whether this sentence is true in $F[t, t^{-1}]$ is equivalent to the question of whether $P=0$ has integral solutions. 
But this contradicts the negative answer to Hilbert's Tenth Problem; therefore, the theorem follows. $$$$ Could you explain to me the formula $\psi(n)$ ? Could you explain to me the reduction to Hilbert's Tenth Probelm? I haven't really understood it... $$$$ $$$$ EDIT: Can we change the theorem and its proof as follows? THEOREM. We suppose that the characteristic of $F$ is zero. Then the positive existential theory of $F[t, t^{-1}]$ in the language $\{+, \cdot , 0, 1, t\}$ is undecidable. Proof. We want to show that there is no algorithm, that given a positive existential sentence $\gamma$, it answers if $\gamma$ is true in the ring $F[t, t^{-1}$ or not. 
According to Matijasevic, there is no algorithm that with input a polynomial $P(x_1, \dots , x_n)$ with integer coefficients, always decides if the equation $P(X-1, \dots , x_n)=0$ has an integer solution. 
According to Lemma $1$, an element $x \in F[t, t^{-1}]$ is a power of $t$ iff $$x \mid 1 \ \ \land \ \ t-1 \mid x-1$$ 
So we can express the fact that an element $x \in F[t, t^{-1}]$ is a power of $t$ with the positive existential formula $$\phi (x) \ \ : \ \  \exists y \exists z ((xy=1) \land (x-1=(t-1)z))$$ 
According to Lemma $3$, $n$ is a nonzero integer iff $n \mid 1 \ \ : \ \ (\exists z)(nz=1)$ $n-1 \mid 1 \lor n+1 \mid 1 \ \ : \ \ (\exists w)((n+1)w=1 \text{ or } (n-1)w=1)$ there is a power $x$ of $t$ $\ \ : \ \ (\exists x) \phi (x)$ $(x-1)/(t-1) \equiv n \pmod {t-1} \ \ : \ \ (\exists y)((x-1)/(t-1)-n =y(t-1)) \Rightarrow (\exists y)(x-1-n(t-1)=y(t-1)^2) \Rightarrow (\exists y)(x-1=n(t-1)+y(t-1)^2)$ So we can express the fact that an element $n \in F[t, t^{-1}]$ is an integer with the positive existential formula $$\psi (n) \ \ : \ \ (\exists x)(\exists y)[\phi(x) \land x-1=(t-1)n+y(t-1)^2] \land (\exists z)(\exists w)(nz=1 \land ((n+1)w=1 \text{ or } (n-1)w=1)$$ 
We suppose that the positive existential formula of $F[t, t^{-1}]$ is decidable, so there is an algorithm that decides if a positive existential sentence is true in $F[t, t^{-1}]$. 
Then the problem if a diophantine equation has an integer solution is decidable: 
the diphantine equation $P(x_1, \dots , x_n)=0$ has an integer solution iff the positive existential sentence $$(\exists x_1) \dots (\exists x_n) ((\psi (x_1) \land \dots \land \psi (x_n)) \land P(x_1, \dots , x_n)=0)$$ is true in $F[t, t^{-1}]$. 
But the answer to the $10^{th}$ Hilbert's Problem, i.e., if there is an algorithm that decides if the diophantine equation has an integer solution, is negative. 
So we have a contradiction. 
That means that the positive existential theory of $F[t, t^{-1}]$ is undecidable.","['logic', 'number-theory', 'formal-languages', 'computability']"
1375848,Forming differential equation,I'm trying to get from: $$e^{\lambda t} (\frac{dN}{dt} + \lambda N) = re^{\lambda t} $$ To: $$ \frac {d}{dt}(Ne^{\lambda t}) = re^{\lambda t} $$ However I'm not sure what procedure to use to go about doing it. Thanks for the help in advance.,"['ordinary-differential-equations', 'exponential-function']"
1375893,Substitution for limits [duplicate],"This question already has answers here : Change of Variables in Limits (Part 1) (3 answers) Closed 8 years ago . How does substitution for limits exactly work? I see often answers that use the substitution $t=\frac1x$, then changing $x\rightarrow\infty$ to  $t\rightarrow0^+$. I have seen this question , this appears to solve my question in the finite case. How does it work when going to infinty? Books I'm using don't cover substitutions, but they seem very useful.","['substitution', 'calculus', 'limits']"
1375898,Simplify Square Root Expression $\sqrt{125} - \sqrt{5}$,$\sqrt{125}-\sqrt5$ simplify it. I thought it would be $\sqrt {5\cdot5\cdot5}-\sqrt 5$ which would be the square root of 25 which is 5 but it is not. Can you show how to simplify this?,"['arithmetic', 'square-numbers', 'algebra-precalculus']"
1375908,"Studying the family of curves $\beta(s,r) = \alpha(s) + r\,{\bf N}(s)$","I'm reviewing some stuff on plane curves, just because, and I would like to confirm some things. The whole exercise is: Let $\alpha(s) = (x(s),y(s))$ be a unit-speed parametrized curve, ${\bf N}(s)$ its normal vector and $\kappa(s)$ its curvature. Consider the family of curves $\beta(s,r) = \alpha(s) +r\,{\bf N}(s)$, $-\epsilon \leq r \leq \epsilon$. Check that $\beta(s,r_0)$ and $\beta(s_0, r)$ are regular curves for $\epsilon > 0$ small enough, check that they're orthogonal and that the curvature $\overline{\kappa}$ of $\beta(s,r_0)$ is $\frac{\kappa}{1+r_0\kappa}$. A direct computation gives: $$\left\|\frac{\partial \beta}{\partial s}(s,r_0)\right\| = |1-r_0\kappa(s)|, \quad \left\|\frac{\partial \beta}{\partial r}(s_0, r)\right\| = 1,$$ so that $\beta(s_0, r)$ is always regular. My first problem is with the first curve. If $|\kappa(s)|$ attained a maximum, say, $|\kappa^\ast|$, then I can take $0 < \epsilon < 1/|\kappa^\ast|$ and from this $|1-r_0\kappa(s)| > 0$ for all $s$. The exercise was written sloppily and I should assume that $\alpha$ is defined in a closed interval, so that I can obtain this maximum $|\kappa^\ast|$? Or there's a trick around it? The second part is too easy, no problems. For the final part, I think that the formula given is wrong. Because $$\frac{\partial \beta}{\partial s}(s,r_0) = (1-r_0\kappa(s))\,{\bf T}(s), \quad \frac{\partial^2\beta}{\partial s^2}(s,r_0)= -r_0\kappa'(s)\,{\bf T}(s) + (1-r_0\kappa(s))\kappa(s)\,{\bf N}(s)$$will give: $$\det\left(\frac{\partial \beta}{\partial s}(s,r_0),\frac{\partial^2\beta}{\partial s^2}(s,r_0)\right) = (1-r_0\kappa(s))^2\kappa(s)$$ and so: $$\overline{\kappa}(s) = \frac{\kappa(s)}{|1-r_0\kappa(s)|}.$$ Did I miss anything? In this question , for example, they take $\alpha (s)- r\,{\bf N}(s)$ in the beginning, which is coherent with my work above. But I think I have too many absolute values there, too. Is there a way to get rid of them?","['frenet-frame', 'differential-geometry', 'curves']"
1375925,When does $\sum_{i=1}^{\infty} X_i$ exist for random sequences $\{X_i\}_{i=1}^{\infty}$?,"Suppose $\{X_1, X_2, X_3, \ldots\}$ is an infinite sequence of random variables such that $E[X_i]=0$ for all $i$, and $E[X_iX_j]=0$ whenever $i \neq j$.  Further suppose the variances $\sigma_i^2 = E[X_i^2]$ are finite and satisfy $\sum_{i=1}^{\infty} \sigma_i^2 < \infty$. Define $S_n = \sum_{i=1}^nX_i$.  When can one conclude that $S_n$ converges almost surely as $n\rightarrow\infty$? I can show that, with prob 1, the limit exists (and is a real number) over a particular subsequence $n[m]$, so that $\lim_{m\rightarrow\infty}S_{n[m]}$ exists as a (random) real number.  I suspect that, in general, we do not have convergence.  However, counter-examples seem hard.","['probability-theory', 'stochastic-processes']"
1375932,"L'Hospital rule, exponental ratio","$$\lim_{x\to ∞} \frac {x^{1000000}} {e^x}$$
could anyone please provide some hits with what result I will end up? After all applyings of L'Hospital rule, I will get $\frac {n} {e^x}$, where $n$ is large number before I got out of the $x$ powers. So, will it be the limit $0$ then? Since the infinity is nothing I have $\frac {n} {0}.$ Or will it be just the $\infty$?","['calculus', 'limits']"
1375951,Tail field versus germ field of Brownian motion,"Continuing my foray into Brownian motion (apologies for the bombardment...), I'm trying to verify the details of a proof of Durrett of the following 0-1 property of the tail $\sigma$-algebra of Brownian motion, $\mathcal{T}$: If $A \in \mathcal{T}$, then for all $x$ either $P_x(A) = 0$ or
  $P_x(A) = 1$. So to set the stage, let $\mathcal{F}_t' = \sigma(B_s: s \geq t)$ so that $\mathcal{T} = \cap_{t \geq 0} \mathcal{F}_t'$. Also let $\mathcal{F}_0^+$ be $\cap_{t>0} \mathcal{F}_t^0$ where $\mathcal{F}_t^0 = \sigma(B_s: s \leq t)$. Finally set $X_t = t B(1/t)$. The proof of the above fact starts with the claim that $\mathcal{T}$ (for $B_s$) is the same as $\mathcal{F}_0^+$ for the time-inverted process $X_s$ . Now it seems pretty clear to me that
$$ \sigma(B_s: s \geq t) = \sigma(X_s: s \leq t) $$
But when I take intersections to get the tail $\sigma$-field, shouldn't the RHS be $\cap_{t \geq 0} \mathcal{F}_t^0$ instead of $\cap_{t > 0} \mathcal{F}_t^0$, which would reduce to the ordinary $\sigma$-field $\mathcal{F}_0^0$? I know that $\mathcal{F}_0^+$ is essentially the same as $\mathcal{F}_0^0$ by Blumenthal's 0-1 law, but I'm still having trouble seeing exactly if and how they differ, and exactly how much it matters. I get a sense that tail algebra events are somehow ""nicer"" than ones in the germ field because whether tail events happen or not is independent of the starting point $x$. I'm just trying to piece together how this relates to the ordinary Brownian motion $B_s$ and the time-inverted one, $X_s$.","['brownian-motion', 'probability', 'stochastic-processes']"
1375955,Finding the kernel of maps between (polynomial) rings,"If I have a map between rings like $f\colon k[x_1,x_2]\to k[t],x_1\mapsto t^2-1,x_2\mapsto t^3-t$, how can I prove that the kernel is $\mathfrak{a}=(x_2^2-x_1^2(x_1+1))$? I see that $\mathfrak{a}\subseteq \ker(f)$ as $x_2^2-x_1^2(x_1+1)$ is clearly mapped to $0$, but I don't see how to do the other direction. My idea was to assume $p\in\ker(f)$ which would imply $p(t^2-1,t^3-t)=0$, but I am missing the connection to $\mathfrak{a}$.","['abstract-algebra', 'commutative-algebra', 'ring-theory']"
1375995,Eigenvalues of Matrix Product.,"Is there a relationship between the eigenvalues of individual matrices and the eigenvalues of their product? What about the special case when one of these matrices is a diagonal (positive) matrix? I think that this topic is very difficult but, maybe, it could exist some particular case in which the answer to this question is known. Any pointers will be very helpful. Thanks.","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1376009,"Calculate $\int^{1/2}_0\int^{1-x}_x (x+y)^9(x-y)^9 \, dy \, dx$","How can I find the following integral: $$\int^{1/2}_0 \int^{1-x}_x (x+y)^9(x-y)^9 \, dy \, dx $$ My thoughts: Can we possibly convert this to spherical or use change of variables?",['multivariable-calculus']
1376016,"The word ""integral"" in calculus unrelated to ""integral"" / ""integer"" in algebra?","I think that the word integral in calculus is nothing to do with integer or integer numbers. But why is integral is chosen for integration? In algebra, integral means related to integers, and this is exactly the same as the word integral in calculus with a very different (?) meaning; are they connected? If not why from millions of words are they same?","['math-history', 'terminology', 'integers', 'integration']"
1376055,Are convex functions enough to determine a measure?,"Suppose we are talking about $\mathbb{R}^n$. We know that if $\mu$, $\nu$ are two finite Borel measures such that
$$\int_{\mathbb{R}^n}f(x) \, d\mu(x)=\int_{\mathbb{R}^n}f(x) \, d\nu(x),$$
for all continuous functions $f$, then $\mu$ and $\nu$ are really the same measure. Now, suppose the equation only holds for all convex functions. Is it still true that $\mu$ and $\nu$ are the same measure? Edit: As Emanuele Paolini has pointed out, there is a counterexample to the original question. So, what if we further restrict $\mu$ and $\nu$ to have compact support?","['convex-analysis', 'real-analysis', 'measure-theory']"
1376079,Proving $\pi \coth \pi a= \frac{1}{a}+ \sum_{n=1}^{\infty}\frac{2a}{n^2+a^2}$ using the Fourier series for $\cosh ax$,"The exercise wants me to prove the identity $$\pi \coth \pi a= \frac{1}{a}+ \sum_{n=1}^{\infty}\frac{2a}{n^2+a^2}$$ using the Fourier series of $\cosh ax, \; x \in [-\pi, \pi], \; a \neq 0$. Evaluating the coefficients ($b_n$ is actually zero as $\cosh ax$ is even) we have that: $\displaystyle {\color{gray} \blacksquare} \;\; a_0 = \frac{1}{\pi}\int_{-\pi}^{\pi}\cosh ax \, {\rm d}x= \frac{2\sinh \pi a}{\pi a}$ $\require{cancel}\displaystyle  {\color{gray} \blacksquare} \;\; a_n = \frac{1}{\pi}\int_{-\pi}^{\pi}\cosh ax \cos n x\, {\rm d}x= \frac{2[a \sinh \pi a \cos \pi n+ \cancelto{0}{n \cosh \pi a \sin \pi n}]}{\pi (a^2+n^2)}$ So far so good except one little problem. I get that $\cos \pi n$ in the nominator which is $(-1)^n$ so I get the alternating series not the wanted one. That is , this way I evaluated the series: $$\cosh ax = \frac{\sinh \pi a}{\pi a}+ \frac{2 a\sinh \pi a}{\pi}\sum_{n=1}^{\infty}\frac{ (-1)^n}{n^2 +a^2} \implies \\
\implies \pi\coth \pi a = \frac{1}{a}+ \sum_{n=1}^{\infty}\frac{2(-1)^n}{n^2+a^2}$$ and not what I want. Calculations of the coefficients were done by Wolfram because they were too tedious to be done by hand. However, I know that using contour integration using the kernel $\pi \cot \pi z$ that this series indeed evaluates to the LHS. What is wrong here?","['fourier-series', 'real-analysis']"
1376086,Proving space of skew-symmetric matrices is orthogonal complement of symmetric matrices,"Problem: Prove that $\left\{ A \in \mathbb{R}^{n \times n} \mid A \text{ is symmetric}\right\}^{\bot} = \left\{ A \in \mathbb{R}^{n \times n} \mid  A \ \text{is skew-symmetric}\right\}$ with $\langle A, B \rangle = Tr(A^T B)$. Attempt at proof: Let $A$ be symmetric, and $B$ skew-symmetric. I want to prove that $\langle A, B \rangle = 0$. So this is what I had so far: \begin{align*} \langle A, B \rangle &= Tr(A^T B) \\ &= Tr(AB) \\ &= \sum_{i=1}^n (AB)_{ii} \\ &= \sum_{i=1}^n \sum_{k=1}^n (a_{ik} b_{ki})
\end{align*} Now I need to use somewhere the fact that $b_{ii} = 0$, i.e. the diagonal elements of a skew-symmetric matrix are zero. But I don't know how to split up the summations? Help would be appreciated!","['linear-algebra', 'inner-products', 'matrices']"
1376110,Generalized Fourier series in $L^2$ that do not converge pointwise a.e.,"For a Hilbert space $L^2$ we have the notion of an orthonormal basis $\{f_j\}$ being a sequence of orthonormal elements such that any element $f$ in $L^2$ can be approximated by partial sums in terms of this basis
$$f = \sum_{j=1}^\infty \langle f, f_j \rangle f_j$$
Here the sum converges wrt the $L^2$ norm.  This is what I mean by generalized Fourier series. I have been reading about Carleson's Theorem that says specifically for Fourier series, the series converges pointwise almost everywhere to the approximated function.  I have also read that this is not true for a general orthonormal basis.  I was hoping someone would be able to provide me with an example demonstrating that statement on a finite measure space, maybe $L^2([0,1])$: A function whose partial sums in terms of the basis do not convergence pointwise almost everywhere.","['fourier-series', 'hilbert-spaces', 'functional-analysis']"
1376121,"For any $A, B \in SL(2, F)$, does knowing $\operatorname{tr}A$, $\operatorname{tr}B$, and $\operatorname{tr}AB$ specify $A$ and $B$?","In title, $F$ denotes a field. Does knowing the trace of two matrices and their product specify those two matrices? Up to some equivalence, perhaps?","['group-theory', 'trace', 'matrices']"
1376126,Proving $10\cdot n=0$ for all $n\in\mathbb{Z}$ with $n\geq 0$ using strong induction,"The question says $10\cdot n=0$ for all $n\in\mathbb{Z}$ with $n\geq 0$. Here is my proof by strong induction: Base case: $10\cdot0=0$. Let $k\geq 0$, and suppose that for any $m\leq k$ we have that $10\cdot m=0$. Consider $10\cdot(k+1)$. The number $k+1$ can be written as $m+l$ for some numbers $0\leq m,l\leq k$. By the induction hypothesis, $10\cdot m=0=10\cdot l$. But then: $10\cdot(k+1)=10\cdot(m+l) = 10\cdot m+10\cdot l=0+0=0$. Apparently something went wrong in my proof by strong induction, but I cannot seem to figure out what.","['induction', 'proof-verification', 'discrete-mathematics', 'proof-writing']"
1376143,When can you take the limit of a parameter before solving the differential equation?,"Short example: consider the differential equation
\begin{align*}
f'(x)=\frac{k^2}{k^2+k+1}xf(x)
\end{align*}
where $k$ is a parameter. Wolfram Alpha tells me that the solution to this equation is 
\begin{align*}
f(x)=ce^\frac{k^2 x^2}{2(k^2+k+1)}
\end{align*}
If I then take the limit as $k\rightarrow \infty$, the solution converges to
\begin{align*}
f(x)=ce^\frac{x^2}{2}.
\end{align*}
This is the same solution as if I had simply taken the limit before I tried to solve the differential equation, that is I instead solved
\begin{align*}
f'(x)=xf(x).
\end{align*} My question is, then, when is it appropriate to take a such a limit of a parameter BEFORE solving the differential equation. I haven't been able to find many references to this question. One book I found online (Ritger and Rose - ""Differential Equations with Applications,"" p. 69) claims that ""taking the limit of a parameter in a differential equation and then solving the differential equation is not always the same as solving the differential equation and then taking the limit of the parameter"" but doesn't give references or conditions. Any help (even just pointing me to the appropriate reference) would be appreciated!","['reference-request', 'ordinary-differential-equations']"
1376146,Accounting for signs in divergence thm. on Lorentzian manifold,"I am trying to learn about integration in Lorentzian manifolds (I will use signature -+++) and have some problems. Oft quoted (in books for GR) form of divergence theorem is: $\int _U div( X )vol_M=\int _{\partial U}(N,X)vol_{\partial U}$ With remark that orientation on (nonnull) boundary should be chosen such that normal vector is pointing inside if it is timelike and outwards if it is spacelike. I don't understand that. This is how I tried to do it (and got wrong results when confronted with made up example): choose $\omega = i_X vol _M$ and apply Stokes. We have: $\int _U d\omega=\int _U di_XvolM=\int_Udiv(X)vol_M$ $\int _{\partial U} \omega =\int _{\partial U}(N,N)(N,X)i_Nvol_M=\int _{\partial U}(N,N)(N,X)vol_{\partial U}$ So I would think I can use equality of two integrals above no matter what orientation of boundary, as long as I make sure that basis $(N,Y_1,Y_2,Y_3)$ is positively oriented, where $Y_i$ make up the basis that I use on boundary. What am I doing wrong?","['general-relativity', 'differential-geometry', 'semi-riemannian-geometry']"
1376147,Smooth Fano Polytopes and Hypersurfaces,"This is a rather extended question, so I will try to make it as compact and readable as possible. I am trying to practice with the Macaulay2 software, in particular the polyhedra and normaltoricvarieties packages. From the paper given here: http://arxiv.org/pdf/1209.3186v3.pdf , I have been using the polytope provided in Example 14, which is a smooth fano polytope in 4 dimensions. Inputting this as the matrix $$\begin{pmatrix}
1 & 0 & 0 & 0 & 1 & -1 & -1 & 0 & 1 & -1\\
0 & 1 & 0 & 0 & -1 & 1 & 0 & -1 & -1 & 1\\
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & -1 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & -1
\end{pmatrix} $$
However, when I input this into Macaulay2, and construct a normal toric variety using this, it returns false when asked if it is smooth. However, (cf. CLS Theorem 2.4.3), we know that a projective variety corresponding to a smooth polytope must be smooth. So, how exactly did I go wrong here? In addition, by definition, one would construct a Calabi-yau hypersurface from a reflexive polytope by taking the section of the sheaf of the anticanonical divisor, which is guaranteed to be cartier and ample, when working with Gorenstein fano toric varieties. How would one construct this explicitly in Macaulay2, starting with a polyhedra? Finally, it is straightforward to compute the hodge number computationally as per eqn (2.1) in http://arxiv.org/pdf/1411.1418v1.pdf . How would one compute this using the built-in functions of calculating the hodge numbers? Any explicit examples would be helpful. Thanks!","['polytopes', 'algebraic-geometry', 'polynomials', 'math-software', 'toric-geometry']"
1376150,How to Prove It Exercise 7.2.5,Prove that ${}^{\mathbb{Z}^+} \mathcal{P}(\mathbb{Z}^+) \sim \mathcal{P}(\mathbb{Z}^+)$ where ${}^A B$ means the set of all functions $f:A \rightarrow B$ and $\mathcal{P}(A)$ is the power set of $A$. To prove this I need to find a function $F:{}^{\mathbb{Z}^+} \mathcal{P}(\mathbb{Z}^+) \rightarrow \mathcal{P}(\mathbb{Z}^+)$ which is one-to-one and onto. Please can anyone give me a small hint on how to start defining this function. I am having difficulty in finding an unambiguous of taking an arbitrary function in ${}^{\mathbb{Z}^+} \mathcal{P}(\mathbb{Z}^+)$ and somehow associating with it a subset of $\mathcal{P}(\mathbb{Z}^+)$.,"['elementary-set-theory', 'functions']"
1376159,"A difficult logarithmic integral ${\Large\int}_0^1\log(x)\,\log(2+x)\,\log(1+x)\,\log\left(1+x^{-1}\right)dx$","A friend of mine shared this problem with me. As he was told, this integral can be evaluated in a closed form (the result may involve polylogarithms). Despite all our efforts, so far we have not achieved anything, so I decided to ask for your advice.
$$\int_0^1\log(x)\,\log(2+x)\,\log(1+x)\,\log\left(1+x^{-1}\right)dx$$ I found some similar questions here on MSE: (1) , (2) , (3) , (4) , (5) , (6) , (7) , (8) , (9) , (10) , (11) , (12) , (13) , (14) .","['closed-form', 'definite-integrals', 'logarithms', 'integration', 'polylogarithm']"
1376182,Limit calculation: $\lim_{x\to 0}\frac{1}{x}\ln\left(\frac{e^x − 1}{x}\right)=$?,"For some reason I'm having trouble calculating the limit of the following function : $$\lim_{x\to 0}\frac{1}{x}\ln\left(\frac{e^x − 1}{x}\right)$$ The function might, or might not converge. I've tried using the Euler limit but didn't get anywhere so far.","['calculus', 'limits']"
1376197,Suppose $A\subseteq \mathscr P (A)$. Prove that $ \mathscr P (A)\subseteq \mathscr P ( \mathscr P (A))$,"This is Velleman's exercise 3.3.4. Suppose $A\subseteq \mathscr P (A)$. Prove that $ \mathscr P (A)\subseteq \mathscr P ( \mathscr P (A))$. I started reexpressing the terms in their equivalent forms to discover relations I did not believe are possible. $A\subseteq \mathscr P (A)$ is equivalent to $\forall x(x\in A \rightarrow x \subseteq A)$. Is there such an x at all? Anyway, $ \mathscr P (A)\subseteq \mathscr P ( \mathscr P (A))$ is equivalent to $ \forall x (x\subseteq A \rightarrow x \subseteq \mathscr P (A))$. Setting x arbitrary I have: Givens: $x\in A \rightarrow x \subseteq A$ Goal:  $ x\subseteq A \rightarrow x \subseteq \mathscr P (A)$. Two question: How do I proceed with the proof? Can someone please show an example where these relations actually hold? Thanks in advance.","['elementary-set-theory', 'proof-verification', 'logic', 'proof-writing']"
