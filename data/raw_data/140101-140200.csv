question_id,title,body,tags
2256498,Prove that every element $a$ of a C*-algebra $A$ is a finite linear combination of unitary elements of $A$,"Prove that every element $a$ of a C*-algebra $A$ is a finite linear combination of unitary elements of $A$. I have no idea to figure it out, any help would be appreciated.","['functional-analysis', 'c-star-algebras']"
2256544,"Solve the equation in integers $a,b$: $20a^3-b^3=1$","Solve the equation in integers $a,b$: $$20a^3-b^3=1.$$ Assume that $a \neq 0$. Then simplifying and rearranging the equation gives $$20a^3 = 2^2 \cdot 5 \cdot a^3 = b^3+1 = (b+1)(b^2-b+1).$$ Note that neither factors can be divisible by $3$, since both of them must be divisible by $3$ but $b^2-b+1 \not \equiv 0 \pmod{9}$ and $b^2-b+1 = 3$ gives a contradiction. Also since $b$ is odd, then $b+1$ is even and $b^2-b+1$ is odd. Also, $b^2-b+1 \not \equiv 0 \pmod{5}$, so $b+1 \equiv 0 \pmod{20}$. Then since $$\gcd(b+1,b^2-b+1) = \gcd(b+1,-2b+1) = \gcd(b+1,3),$$ it follows that $(b+1)$ and $(b^2-b+1)$ are relatively prime. Thus $b+1 = 20n^3$ and $b^2-b+1 = m^3$ where $m,n$ are relatively prime. I then thought about bounding $b^2-b+1$ between two perfect cubes, but I didn't see how to do that. Then since two solutions for $(a,b)$ are $(0,-1)$ and $(7,19)$ I wanted to show that $(b+1) \mid 20$, or equivalently that $a$ and $b+1$ are relatively prime. So suppose that for some prime $p$ we have $a \equiv 0 \pmod{p}$ and $b+1 \equiv 0 \pmod{p}$. It then follows that $b+1 \equiv 0 \pmod{p^3}$, so that $b = p^3k-1$ for some integer $k$. Then we have $$(p^3k-1)^2-(p^3k-1)+1 = p^3k(p^3k-3)+3 = m^3.$$ How can we get a contradiction from here?",['number-theory']
2256594,Given $x+y+z=1$ Find Maximum value of $x^5y+y^5z+z^5x$,"$x,y,z$ are Non negative reals such that  $x+y+z=1$ Find Maximum value of $$E=x^5y+y^5z+z^5x$$ The only idea i have is $E$ can be written as $f(x,y)$ and using partial differentiation for maxima...but too lengthy","['inequality', 'a.m.-g.m.-inequality', 'optimization', 'algebra-precalculus', 'multivariable-calculus']"
2256595,Is there any significance to the derivative of the average?,"I have a set of time vs. concentration data that I'm trying to turn into an average derivative value for use in an equation (I'm worried a simple average of the first and last points ignores too much data). The most obvious way to do it would be to simply do $\frac{C - C_0}{t - t_0}$ for each point and take the average, but I'm wondering, is there any significance to the value $\frac{C_{avg}}{t_{avg}}$? Since I have uniform time intervals I think this is equivalent to $$\frac{1}{N} \sum_{i}{\frac{C_i}{\Delta}}$$ where $\Delta$ is the time interval length and $N$ is the number of samples. If possible, avoiding numerical differentiation would be great since I'm getting some weird values from that approach. Any advice would be greatly appreciated. Thanks!","['derivatives', 'numerical-methods', 'statistics']"
2256601,Number Theory: Prove that $p|m-n$,"Assume $p$ is an odd prime number, $\displaystyle q = \frac{3p-5}{2}$ and $$ S_q = \frac{1}{2.3.4} + \frac {1}{5.6.7} + ... + \frac{1}{q(q+1)(q+2)}$$.
  If $\displaystyle \frac{1}{p} - 2S_q = \frac{m}{n}$ and $m$ and $n$ are two integers, Prove that $p\  | \ m-n$. Any hints how to start the proof?","['number-theory', 'discrete-mathematics']"
2256618,Solve $2\cos^2{x}=\sqrt{3}\sin{2x}$.,"Problem: Solve $2\cos^2{x}=\sqrt{3}\sin{2x}$ and give the sum of all the solutions in the interval $0\leq x\leq2\pi.$ Attempt: Using the fact that $\sin{2\theta}= 2\cos{\theta}\sin{\theta}$ on the RHS I get $$2\cos^2{x}=2\sqrt{3}\cos{x}\sin{x}.$$ Dividing by $2\cos{x}$ I get $$\cos{x}=\sqrt{3}\sin{x}.$$ Dividing by $\cos{x}$ again I get $$\tan{x}=\frac{1}{\sqrt{3}} \ \Longleftrightarrow \ x=\pi k+\frac{\pi}{6}, \ \ \forall \in \mathbb{Z.}$$ But it's not correct. Why?",['trigonometry']
2256636,Help with inverse trig derivatives with L'Hopital rule,"so I have a problem with my teacher's notes and they have confused me. take this equation 
 \begin{align}
      \lim _{x\to0}  \frac{\arcsin x}{ \sin x} 
    \end{align} if we do the derivative of the top and bottom using l'hopitals rule we get \begin{align}
      (\arcsin x)'= \frac{1}{ \sqrt{1-x^2}} 
    \end{align}
\begin{align}
      (\sin x)'= \cos x 
    \end{align} but when my teacher put them together she did't explain how she somehow got this.
\begin{align}
       \lim _{x\to0}  \frac{\sqrt{1-x^2}}{ \cos x} 
    \end{align} Please help this makes no sense to me, why is the numerator no longer a fraction?","['trigonometry', 'calculus', 'limits']"
2256687,$\lim_{r\to +\infty}\int_{\partial D_r\left (0\right )}\frac{e^{iz}}{z}dz=0$,"Let $D_r\left (0\right )$ the disc of center $r$ with center $0$ in $\mathbb{C}$ and let $\partial D_r\left (0\right )$ be its boundary. Prove that
  $$\lim_{r\to +\infty}\int_{\partial D_r\left (0\right )}\frac{e^{iz}}{z}dz=0$$ I tried to solve this problem using estimation lemma, but the upper bound I found is $2\pi e^r$ which does not tend to zero. It is my first approach to integrals over curves defined on the complex plane, therefore I do not have much theory, but I am supposed to be able to solve this problem. Any help?","['complex-analysis', 'complex-numbers', 'complex-integration']"
2256701,"Prove that there are infinite sets of $(a, b, c)$ such that $ab + 1$, $ac + 1$ and $bc + 1$ are perfect square","Prove that there are infinite sets of integer numbers $(a, b, c)$ that $ab + 1$, $ac + 1$ and $bc + 1$ are perfect square. ($a$, $b$, $c$ are different numbers) Any hints how to prove the statement? I'm trying to find a way to turn that into a Pell's equation and then prove it has infinite answers.","['number-theory', 'discrete-mathematics']"
2256711,"How to prove the Continuity of $f(x_1,\ldots,x_n)=g(x_1)$","I want a help for this question: Let $g:\mathbb{R}\to\mathbb{R}$ a continuous function. Show that the function $f:\mathbb{R}^n\to\mathbb{R}$ defined by:
$$f(x_1,\ldots,x_n)=g(x_1),$$
is continuous? Thank you.","['continuity', 'functions']"
2256716,Check if the function is differentiable or not,"Consider $f: \mathbb{R^2} \to \mathbb{R}$ , $$f(x, y) = \begin{cases}\frac{xy^2}{x^2 + 2y^2} & (x, y) \ne (0,0)\\0 & (x, y) = (0,0)\end{cases}$$ Where is $f(x, y)$ differentiable over its domain? I am considering $(0, 0)$ as a point, but I am not sure how to go about proving it (or disproving)","['multivariable-calculus', 'calculus', 'analysis']"
2256720,Joint density with restrain,"I can't solve this problem...tried several areas for limits of integration but solution just doesn't match with solution from end of textbook (Stirzaker:Probability and random variables). Exercise 6.6.2
Let X and Y have joint density $$f(x,y)=e^{-y}$$ 
$$0<x<y<\infty$$ Find joint density for Z=X+Y. I just can't figure it up and became really frustrated, especially being self-learner. I haven't write any of my trials because I only ask for someone to please help me with bounds of integration(I know formula for joint density etc.) Many thanks!","['statistics', 'probability', 'probability-distributions']"
2256733,Construct large set of words with a property,"Let $[m]$ denote $\{1,\ldots,m\}$ and $(v)_i$ denote the $i$-ith coordinate of a vector $v$. Let $m$ and $k$ be positive integers. Then $[m]^k$ denotes the set of all words with letters from $[m]$ of length $k$. I am trying to find a large set $\mathcal{W}\subset [m]^k$ such that the following property holds. For every distinct $W_1,\ldots,W_m\in\mathcal{W}$ there exists a coordinate $i\in [k]$ such that $(W_1)_i,(W_2)_i,\ldots,(W_m)_i$ are all distinct (in other words, $\{(W_1)_i,\ldots,(W_m)_i\}=[m]$). Clearly, the size of $[m]^k$ is $m^k$. So I am looking for a set $\mathcal{W}$ such that its size is also exponential in $k$ (consider $m$ as a constant). In particular, I would like to find $\lambda=\lambda_m>1$ such that for every $k$ we can find a set of size at least $\lambda^k$ with the property. Also, I would prefer a deterministic construction (but nondeterministic constructions are of interest as well).","['combinatorics', 'combinatorics-on-words']"
2256752,Are open subsets of Lindelöf spaces themselves Lindelöf?,"Let $(X,\tau)$ be a Lindelöf space and $O$ an open subset of $X$. Is it true that $O$ is Lindelöf as well? Recall that a space is Lindelöf if every open cover admits a countable subcover, i.e., this is a weaker notion of compactness.","['general-topology', 'compactness']"
2256763,Why do distribution functions have Leibniz rule?,"Suppose I have two distribution functions $f, g: \mathbb{R} \rightarrow [0,1]$, I.e. Non-decreasing, right continuous with $\underset{t\rightarrow \infty}{\lim} = 1, \underset{t\rightarrow - \infty}{\lim}= 0$.  Why does the measure given by the product of the distribution functions obey the Leibniz rule: $d(f\cdot g)=g df + f dg$?  By $df$ I mean the Borel measure given by assigning the measure $f(b)-f(a)$ to the interval $(a,b]$.","['probability', 'analysis']"
2256772,"How many ways are there to place nine people in three boats, if in each boat we should place 3 people?","The task is: How many ways are there to place nine people in three boats, if in each boat we should place 3 people. 1) $\displaystyle \frac{9!}{3!\times6!}=84$ different triplets 2) $\displaystyle \frac{84!}{3!\times(84-3)!}=95284$ But the answer is $1680$. What did I wrong?",['combinatorics']
2256802,"The ""extending the automorphism"" theorem in Galois theory","I recently heard that the following statement is a theorem in Galois theory. Theorem. Let $F$ be a field and $L/K/F$ be a tower of field extensions of $F$.  Suppose that $L/F$ and $K/F$ are both Galois extensions.  Then for any $\sigma \in \text{Gal(K/F)}$, there exists  $\tilde{\sigma} \in \text{Gal}(L/F)$ such that
\begin{equation*}
\tilde{\sigma}|_{K} = \sigma
\end{equation*} I have a couple of questions: Is this theorem (as I have stated it) true? Is the $\tilde{\sigma}$ unique? Do you know of an online reference (lecture notes, wikipedia, etc.) that states this result?  I would like to read the proof, see the context, etc. Thanks so much!","['abstract-algebra', 'galois-theory', 'field-theory']"
2256831,Nonabelian second relative homotopy group,"Can anyone demonstrate a pair of spaces $(X,A)$ such that $\pi_1(A)$ is abelian but $\pi_2(X,A)$ is nonabelian? I have tried to consider a pair of form $(K(A,2),K(C,1))$ such that (the interesting part of) the homotopy exact sequence becomes $0\to A \to B \to C \to 0$ where $A,C$ are abelian groups but $B$ is nonabelian. I know a map $K(G,n) \to K(H,n)$ must come from a group homomorphism $G \to H$, but I don't know if there are similar results for maps between $K(G,n)$ of different $n$. I have also noted that it is easy to construct an example if one does not require $\pi_1(A)$ to be abelian, simply take $A$ to be the figure eight and $X=S^3$. But if one tries to abelianize $\pi_1(A)$ by, say, attaching a 2-cell so that it becomes a torus, the original nontrivial commutator $\alpha \beta \alpha^{-1} \beta^{-1}$ acquires a way to become nulhomotopic. I have tried to place obstructions on $S^3$ by punching holes or attaching handles to it, so that the nulhomotopy becomes invalid, but I did not have any success. Any help would be appreciated!","['algebraic-topology', 'eilenberg-maclane-spaces', 'group-theory', 'homotopy-theory']"
2256844,How to show that these functions are equivalent for $x \to 0$?,"Let $\{p_n(x)\}_{n=1}^{+\infty}$ be a set of functions such that for $\forall x \in \mathbb{R} \forall n \in \mathbb{N}: 0 < p_n(x) < 1$ and $\sum\limits_{n=1}^{+\infty} p_n(x) = x$. I wonder if it is always true that $1 - \prod\limits_{n=1}^{+\infty} (1-p_n(x)) \sim x$ as $x$ goes to $0$? So can someone prove the equivalence in general or provide a counterexample? If a counterexample exists , I'm interested in finding $\{p_n(x)\}_{n=1}^{+\infty}$ that minimizes the following limit: $$\lim\limits_{x \to 0}\dfrac{1- \prod\limits_{n=1}^{+\infty} (1-p_n(x))}{x}$$ If the limit above can be equal to $0$ for some $\{p_n(x)\}_{n=1}^{+\infty}$, I would be interested to see any example of such sequence. Any ideas, suggestions, hints and references related to the problem would be greatly appreciated.","['real-analysis', 'limits', 'calculus', 'products', 'sequences-and-series']"
2256845,Analytical evaluation of double integral,"I'm looking to evaluate the following integral: $$\int^a_{-a}\int^a_{-a}\frac{\sqrt{x^2+y^2}}{4a^2} \,\mathrm{d}x \mathrm{d}y,$$
where $a> 0$. Mathematica gives the following answer: $$ \frac{a}{3} (\sqrt{2} + \sinh^{-1}(1)).$$ This goes well beyond my basic calculus 101 training.
Is anybody able to give me a step-by-step analytical solution? Regards","['multivariable-calculus', 'integration']"
2256846,Choosing half of prefix and suffix,"Consider two lists: $(1,2,\dots,n)$ and $(a_1,a_2,\dots,a_n)$, where the second list is a permutation of the first. Does there exist a constant $c$ such that for any $n$ and for any second list, we can choose a subset $A\subseteq\{1,2,\dots,n\}$ of size at most $n/2+c$ so that for any prefix and suffix of either list of any length $k\in[1,n]$, at least $k/2$ of those elements are in $A$? The $n/2$ part is necessary: even if we just have the list $(1,2,\dots,n)$ and require the condition on the prefix, when taking $k=n$ we already need to include at least $n/2$ elements. If we only want the prefixes and suffixes of the first list, we can choose $A=\{1,3,5,\dots\}$ along with $n$ (if not already included), which comes to at most $n/2+1$ elements.","['permutations', 'combinatorics']"
2256849,Exact solution to $\frac{\mathrm dy}{\mathrm dx} = 1 + \frac{a}{y} + \frac{b}{x}$,"This equation arises from my attempt to study the quasi-steady state of a cross-diffusive system.
$$\frac{\mathrm{d}y}{\mathrm{d}x} = 1 + \frac{a}{y} + \frac{b}{x},$$
where $2>a > 1> b > 0$, $x,y \in \mathbb{R}^{+}$. I learned that it is a special case of the Chini equation, which typically does not have a closed form solution. But it looks so simply to not have a closed form solution! On the other hand, I have tried many different methods and substitution to try to obtain its closed form in vain. Could someone please help suggest a way to do this?","['ordinary-differential-equations', 'dynamical-systems', 'nonlinear-system']"
2256909,Valuations of integer valued polynomials,"Consider the ring $R=\text{Int}(\mathbb Z):=\{p(x)\in \mathbb Q[x]\ |\ p(n)\in \mathbb Z, \forall n\in \mathbb Z \}$. Let $K$ denote the fraction field of $R$. Fix an $a\in \mathbb Z$ and let $P$ be the prime ideal defined by
  $P:=\{q(x)\in R\ | \ q(a)\equiv 0 (\text{mod } p)\}$ and let $R_P$ denote the localization of $R$ at $P$. Let $\Gamma$ denote the totally ordered group $\mathbb Z \times \mathbb Z$, where the operation is componentwise addition and the order is the lexicographic one. Find a surjective valuation $v:K\rightarrow \Gamma$ such that its corresponding valuation ring is precisely $R_P$. Now when trying to find $v\left(\frac{f(x)}{g(x)}\right)=(c_1,c_2)\in \mathbb Z\times \mathbb Z$, I thought of using a similar expression as for the $p$-adic valuation on $\mathbb Q$, namely define $c_2=e_p(f(a))-e_p(g(a))$ for one of the components, however the issue with that is that it yields a positive value even when $\frac{f(x)}{g(x)}$ is not in $R_P$, namely say if $e_p(f(a))=2, e_p(g(a))=1$. I have been trying to find some nice functions $P(X,Y)$ so that $P(X_1+X_2,Y_1+Y_2)=P(X_1,Y_1)+P(X_2,Y_2)$ which would help here, but none of them were surjective on $\mathbb Z$.","['valuation-theory', 'abstract-algebra', 'integer-valued-polynomials', 'commutative-algebra']"
2256914,Doubt over the proof of Cayley- Hamilton heorem,"I am having some doubt in the proof of Cayley Hamilton theorem.  This theorem says that every matrix is a root if its characteristic polynomial. Proof goes as follows: Let us assume that matrix $A$ is of order $n\times n$. If $P(\lambda)$ be its characteristic polynomial, then by the definition of the characteristic polynomial $P(\lambda) = det (A - \lambda I) = P_0 + P_1\lambda + P_2 \lambda^2  +\ldots P_n \lambda^n$. Next, suppose that $Q(\lambda)$ be the adjoint matrix of $(A - \lambda I)$, such that $Q(\lambda) =Q_0 + Q_1\lambda + Q_2 \lambda^2  +\ldots Q_k \lambda^k$. I am not able to understand why the polynomial expression of $Q(\lambda)$ is of degree $k$? Can't I write $Q(\lambda)$ as follows (degree $n$ polynomial in $\lambda$) $Q(\lambda) =Q_0 + Q_1\lambda + Q_2 \lambda^2  +\ldots Q_n \lambda^n$. Thank you","['cayley-hamilton', 'linear-algebra']"
2256916,Can a cubic function have two tangents at a single point?,"I have a question regarding this question . The question posed is if from a point ($h,3−h$) exactly two distinct tangents are drawn to $f(x)=x^3−9x^2−px+q$ find $p$ and $q$ I've been waiting all week for someone smarter than me to answer this question, but no one has, so I have to ask my question. I have forgotten most of my calculus, but I can't see how there could be two distinct tangents at a given point. I know the first derivative gives the slope of the tangent line at a given point. If two tangents are distinct, then they must have different slopes (if they are at the same point), otherwise the lines will be parallel. But the first derivative only gives one slope. For two lines with the same slope to be distinct, they must be parallel. Thus the lines do not go through the same point. But the problem says they do. In my mind, then, there can't be two tangents at a single point because of this apparent contradiction. I have searched the web and nowhere could I find an example (even a strange, unique condition) where there are two tangents at a point. A function is either differentiable at a point, which means there is one tangent line, or the function is not differentiable, which means there can be any number of tangents. Further confusing me is this business with $(h, 3-h)$. Does this present some special situation where dual tangents are possible? I appreciate any light that you can shed on the subject.","['derivatives', 'tangent-line', 'calculus']"
2256942,"If the sum of eigenvectors is an eigenvector, then they all correspond to the same eigenvalue","I believe I am very close to finishing this proof, but I cannot figure out the last part. If anybody could check my work and maybe give me a little hint, it would be greatly appreciated! Let $V$ be a finite-dimensional vector space and $T \in \mathcal{L}(V)$, and let $\mathbf{u,v} \in V$ be eigenvectors of $T$. Claim :  If $\mathbf{u} + \mathbf{v}$ is an eigenvector of $T$, then $\mathbf{u}, \mathbf{v}$, and $\mathbf{u+v}$ all correspond to the same eigenvalue. Proof (So far!) : Suppose $T(\mathbf{u}) = \lambda_1 \mathbf{u}$ and $T(\mathbf{v}) = \lambda_2 \mathbf{v}$ with $\mathbf{u}, \mathbf{v} \neq \mathbf{0}$. Now suppose $T(\mathbf{u+v}) = \lambda_3(\mathbf{u+v})$ with $\mathbf{u+v}\neq \mathbf{0}$. Then, $$
T(\mathbf{u}) + T(\mathbf{v}) = \lambda_3 \mathbf{u} + \lambda_3 \mathbf{v}\\
\lambda_1\mathbf{u} + \lambda_2\mathbf{v} =  \lambda_3 \mathbf{u} + \lambda_3\mathbf{v}\\
\lambda_1\mathbf{u} + \lambda_2\mathbf{v} - \lambda_3 \mathbf{u} -\lambda_3\mathbf{v} = \mathbf{0}\\
(\lambda_1 - \lambda_3) \mathbf{u} + (\lambda_2 - \lambda_3)\mathbf{v} = \mathbf{0}
$$ Now I know in order to show that $\lambda_1 = \lambda_2 = \lambda_3$, I must show that the only solution to the last line is the trivial one. This would imply that $\mathbf{u}$ and $\mathbf{v}$ are linearly independent which I am unconvinced of! The only information I have to my advantage I haven't used yet is the fact that $\mathbf{u}, \mathbf{v}, \mathbf{u+v} \neq \mathbf{0}$. I really cannot see how this information can help me though. Perhaps I am going about this wrong, but that's why I want to ask! Thanks for your help.","['eigenvalues-eigenvectors', 'proof-writing', 'linear-algebra', 'proof-verification']"
2256980,Proving the sum rule for derivatives using the sequential definition,"Using this definition: If $f$ is a function and has derivative $f'(c)$ at the point $c$ in the domain of $f$ means that if ($a_n$)$_{n=1}^{\infty}$ is any sequence converging to $c$ such that $a_n$ $\not= c$is in the domain of $f$ for all $n \in \mathbb{N},$ then: $$\left[ \frac{f(x_n)-f(c)}{x_n-c}\right]_{n=1}^{\infty}$$converges to $f'(c)$ Assuming $f$ and $g$ are differentiable functions on (a,b) with $h(x)=f(x)+g(x),$ prove that $h'(x)=f'(x)+g'(x).$ Attempt so far: Using the definition above, 
$\left[ \frac{h(x_n)-h(c)}{x_n-c}\right]_{n=1}^{\infty}$ converges to $h'(c)$ <=> $\left[ \frac{f(x_n)-f(c)}{x_n-c}\right]_{n=1}^{\infty}$ + $\left[ \frac{g(x_n)-g(c)}{x_n-c}\right]_{n=1}^{\infty}$ since $h(x)=f(x)+g(x).$ I'm not sure if using the fact that If ($a_n$) converges to $L$ and ($b_n$) converges to $K$ then ($a_n+b_n$) converges to $L+K$  would help at all? I feel like this proof should be somewhat simple looking at how it is proven using the normal derivative definition, but I am having trouble coming up with an actual proof.","['derivatives', 'real-analysis', 'proof-verification']"
2256985,"Find $m\in\mathbb N$, $n\in\mathbb N$, and $f(0)$ where $f(x)=ax^3+bx^2+cx+d$ $(a,b,c,d\in\mathbb Z)$, $f(mn)=1$, $f(m)=n^2$, $f(n)=m^2$, ...","Question: Find $m\in\mathbb N$, $n\in\mathbb N$, and $f(0)$ where ($m,n\gt 1$) $f(x)=ax^3+bx^2+cx+d$ $(a,b,c,d\in\mathbb Z)$ $f(mn)=1$ $f(m)=n^2$ $f(n)=m^2$ $f(1)=m^2n^2$ What I tried so far was:
\begin{align}
&f(mn)-f(1)=(mn-1)\left(a(m^2n^2+mn+1)+b(mn+1)+c\right)=(mn-1)(mn+1)\\
&\therefore a(m^2n^2+mn+1)+(b-1)(mn+1)+c=0\tag1\\
&f(m)-f(n)=(m-n)\left(a(m^2+mn+n^2)+b(m+n)+c\right)=(m-n)(m+n)\\
&\therefore m=n,\quad\text{or}\quad a(m^2+mn+n^2)+(b-1)(m+n)+c=0\tag2\\
&\\
&m\ne n:\\
&(1)-(2)\Rightarrow (m-1)(n-1)\left(a(m+1)(n+1)+(b-1)\right)=0\\
&b-1=-a(m+1)(n+1)\\
&(2)\rightarrow c=-a(m^2+mn+n^2)+a(m+1)(n+1)(m+n)\\
&d=m^2n^2-a-b-c=mn(mn-a(m+n))-1\\
&f(x)=ax^3-a(m+1)(n+1)x^2+x^2-a(m^2+mn+n^2)x+a(m+1)(n+1)(m+n)x+mn(mn-a(m+n))-1\\
&
\end{align} And then I gave up...","['algebra-precalculus', 'elementary-number-theory']"
2256989,Area of a triangle where the three vertices are randomly chosen on a circle; also $3D$ version.,"My teacher gave us an interesting problem today. Consider a circle of radius $1$, choose three points on that circle at random and make a triangle connecting the three. On average what will the area of the triangle be? One kid eventually got it and he told him to do it with $4$ points on a sphere making a tetrahedron and to find the average volume. This was in a homeroom class, where the students in the class had him the previous year in AP Calc, so I'm not sure what the tags should be or what math is used.","['statistics', 'geometric-probability', 'geometry']"
2257017,Dilworth's Theorem and Mirsky's Theorem for Infinite Posets?,"I know that there is an infinite partially ordered set that violates Dilworth's Theorem and one that violates Mirsky's Theorem .  Unfortunately, I do not have access to the references for these counterexamples.  I have a few questions. Can somebody please provide an explicit counterexample for each theorem? I would like to know if there is an infinite partially ordered set that violates both theorems.  I am curious whether these theorems are true duals in the sense that a partially ordered set satisfies one of them if and only if it satisfies both. Let me call a partially ordered set $P$ Dilworth if the width of $P$ (i.e., the supremum of the cardinalities of antichains in $P$ ) is the same as the smallest cardinal number $c$ such that there exists a family $\mathcal{C}$ of chains in $P$ such that $P=\bigcup\mathcal{C}$ and $|\mathcal{C}|=c$ .  A partially ordered set $P$ is Mirsky if the height of $P$ (i.e., the supremum of the cardinalities of chains in $P$ ) is the same as the smallest cardinal number $a$ such that there exists a family $\mathcal{A}$ of antichains in $P$ such that $P=\bigcup\mathcal{A}$ and $|\mathcal{A}|=a$ . For example, finite and countably infinite partially ordered sets are both Dilworth and Mirsky.  More generally, a partially ordered set of finite width is Dilworth, whereas a partially ordered set of finite height is Mirsky.  That is, the questions above can be rephrased as follows. Please give me an example of a non-Dilworth partially ordered set and an example of a non-Mirsky partially ordered set. Is there a partially ordered set which is simultaneously non-Dilworth and non-Mirsky?  Does it hold that a partially ordered set is Dilworth if and only if it is Mirsky?","['cardinals', 'combinatorics', 'set-theory', 'order-theory']"
2257020,Understanding Zorn's lemma x,"Zorn's lemma is used on partially ordered sets. So, Why not total order or well-ordered sets? Can you explain?",['elementary-set-theory']
2257047,Why does solving $x=1+\sqrt{x}$ give an invalid solution?,"I was trying to solve the equation, $x=1+\sqrt{x}$ for real $x$. Though I didn't correctly solve it. I'm curious as to why that is, and what else I need to initially consider in the domain of the function. I started off by recognising that $x \geq 0$ for the square root to be real (I know when $x=0$ it is not a solution). Squaring both sides and rearranging;
$$x^2 -3x + 1=0$$
Finding the solutions to this equation you obtain; $x=\frac{3\pm\sqrt{5}}{2}$. Both of these solutions to that equation are greater than zero, but only $x=\frac{3 + \sqrt{5}}{2}$ is the solution to the original. Why is that? Is there some other ""domain"" restriction I must consider?
Or for every question where there inolves  root must I numerically test it (is there no way to get around this)? Thanks","['algebra-precalculus', 'radicals']"
2257057,Finding the derivative of $(3x^2 +5)^{\arctan x}$,"Can someone please explain how the power rule, brings natural log into the equation? Why is the derivative not $\arctan(x)(3x^2+5)^{\arctan(x)-1}$?","['derivatives', 'logarithms']"
2257066,"Two spaces, each a retract of the other, which are not homotopy equivalent","Hoping to find a simple example of spaces $X$ and $Y$ such that each is a retract of the other (i.e there exist continuous $i : X \to Y, p : Y \to X$ with $p\circ i = \mathrm{id}_X$ and also continuous $j : Y \to X, q : X \to Y$ with $q \circ j =\mathrm{id}_Y$) but such that $X$ and $Y$ are not homotopy equivalent. I think there should be a fairly simple example, since I don't care if the spaces $X$ and $Y$ are connected. A connected example would be nice, of course... Added: Actually, I just noticed it's not very hard to do this if we don't mind using some kind of infinite swindle. Lots of examples are possible along these lines.... Let $T_n$ denote the space which is the wedge of $n$ circles. Observe $T_n$ is a retract of $T_m$ when $m \geq n$. Thus,  $X = T_1 \sqcup T_3 \sqcup T_5 \sqcup \ldots$ and $Y =T_2 \sqcup T_4 \sqcup T_6 \sqcup \ldots$ are retracts of each other, but they shouldn't be homotopy equivalent. In light of this addition, let me change the question to: Revised Question: Can we find a nice example of two connected spaces, each a retract of the other, such that they are not homotopy equivalent?","['general-topology', 'examples-counterexamples', 'homotopy-theory']"
2257095,Exact period of simple pendulum.,"Edit : Here is in depth derivation. Suppose the pendulum is composed of a string of length $L$ and has a point mass of mass $m$ at the end of the string. Say we incline it at an angle $\theta_0 \in (0,\pi)$ counterclockwise from horizontal (counterclockwise counted positive and clockwise counted negative).  Let the mass at the vertical position posses $0$ potential energy.  Then it posses $mg(L-L\cos \theta_0)$ amount of Potential Energy at the signed angle of $\theta_0$ . At any angle the mass posses a Kinetic energy of $\frac{1}{2}mv^2=\frac{1}{2}m \left(L\frac{d\theta}{dt}\right)^2$ and a potential energy of $mg(L-L\cos \theta)$ . By conservation of mechanical energy, $$\frac{1}{2}m\left(L\frac{d\theta}{dt}\right)^2+mgL(1-\cos \theta)=mgL(1-\cos \theta_0)$$ As the pendulum counterclockwise from an angle of $-\theta_0$ to $\theta_0$ , $\frac{d\theta}{dt} \geq 0$ so, $$\frac{d\theta}{dt}=\sqrt{\frac{2g}{L}(\cos \theta-\cos \theta_0)}$$ This motion is half the cycle (to show this look at the equation counterclockwise motion from $\theta_0$ to $-\theta_0$ ), so it takes half the period to occur. From which we find, $$T=2\sqrt{\frac{L}{2g}} \int_{-\theta_0}^{\theta_0} \frac{1}{\sqrt{\cos \theta-\cos \theta_0}} d\theta$$ As the integrand is even we get, $$=4\sqrt{\frac{L}{2g}}\int_{0}^{\theta_0} \frac{1}{\sqrt{\cos \theta-\cos \theta_0}} d\theta$$ Now we make the substitution $\sin x=\dfrac{\sin \frac{\theta}{2}}{\sin \frac{\theta_0}{2}}$ . $x \in [0,\frac{\pi}{2}]$ and $\theta \in [0,\theta_0]$ correspond together, so let $x \in \left[0,\frac{\pi}{2}\right]$ . Then note the identities, $$1-2\sin^2 \left(\frac{\theta}{2}\right)=\cos \theta$$ $$1-2\sin^2 \left(\frac{\theta_0}{2} \right)=\cos \theta_0$$ Give, $$\sqrt{\cos \theta-\cos \theta_0}=\sqrt{2} \sin \frac{\theta_0}{2} \cos x$$ (If we let $\theta_0 \in (0,\pi]$ As $\cos x$ is nonnegative for $x \in \left[0,\frac{\pi}{2} \right]$ ). Also note the identity, $$\cos \frac {\theta}{2}=\sqrt{1-\sin^2 \frac{\theta}{2}}$$ For $0 \leq \theta \leq \theta_0 \leq \pi$ . The identities we found together convert the earlier expression we found for the period into, $$T=4 \sqrt{\frac{L}{2g}} \sqrt{2} \int_{0}^{\frac{\pi}{2}} \frac{1}{\sqrt{1-k^2 \sin^2 x}} dx$$ $$=4\sqrt{\frac{L}{g}} \int_{0}^{\frac{\pi}{2}} \frac{1}{\sqrt{1-k^2 \sin^2 x}} dx$$ Where $k=\sin (\frac{\theta_0}{2})$ . We also have the binomial series expansion, $$(1-k^2\sin^2 x)^{-\frac{1}{2}}=\sum_{n=0}^{ \infty} {-\frac{1}{2} \choose n} (-1)^n k^{2n} \sin^{2n} x$$ A standard exercise in many books is to show for integers $n \geq 2$ , $$\int_{0}^{\frac{\pi}{2}} \sin^{n} x dx=\frac{n-1}{n} \int_{0}^{\frac{\pi}{2}} \sin^{n-2} x dx$$ Hence showing for $n \geq 1$ , $$\int_{0}^{\frac{\pi}{2}} \sin^{2n} x dx=\frac{1 \cdot 3 \cdot 5 \cdots (2n-1)}{2 \cdot 4 \cdot 6 \cdots 2n} \frac{\pi}{2}$$ Using this gives, $$T=2\pi \sqrt{\frac{L}{g}}\left(1+ \sum_{n=1}^{\infty} \frac{1 \cdot 3 \cdot 5 \cdots (2n-1)}{2 \cdot 4 \cdot 6 \cdots 2n} {-\frac{1}{2} \choose n} (-1)^n k^{2n} \right)$$ Also a famous result for $n \geq 1$ is, $$(-1)^n {-\frac{1}{2} \choose n}=\frac{1 \cdot 3 \cdot 5 \cdots (2n-1)}{2 \cdot 4 \cdot 6 \cdots 2n}$$ So the exact period is, $$T=2\pi \sqrt{\frac{L}{g}}\left(1+ \sum_{n=1}^{\infty}\left( \frac{1 \cdot 3 \cdot 5 \cdots (2n-1)}{2 \cdot 4 \cdot 6 \cdots 2n} \right)^2 k^{2n} \right)$$ As claimed. The equation that models a simple pendulum is, $$-g\sin \theta=L \theta''$$ Where the derivative above is a time derivative. I read in my book that the period of of the pendulum starting from an angle of $\theta(0)=\theta_0$ is exactly, $$T=2\pi\sqrt{\frac{L}{g}}\left[1+\left(\frac{1}{2}\right)^2 \sin^2 \left(\frac{\theta_0}{2}\right)+\left(\frac{1 \cdot 3}{2 \cdot 4} \right)^2 \sin^4 \left(\frac{\theta_0}{2}\right)+\cdots \right]$$ My question is how to get it? Here's something I tried use $\sin (\theta)=\theta-\frac{\theta^3}{3}+\cdots$ to come up with a solution though I see if I include anything other than one other term I am lost. With one term I can get the first term in the period. Here's another thing I tried to do, take Laplace transforms on both sides to get: $$-g \int_{0}^{\infty} e^{-st} \sin (\theta(t))dt=L(s^2F(s)-s\theta(0)-\theta'(0))$$ But again it seems like there is no hope to solve that integral.","['physics', 'ordinary-differential-equations', 'calculus']"
2257097,"Show that if $E$ is not measurable, then there is an open set $O$ containing $E$ that has finite outer measure and for which $m^*(O-E)>m^*(O)-m^*(E)$","Let $E$ have finite (Lebesgue) outer measure. Now we need to show that if $E$ is not measurable, then there is an open set $O$ containing $E$ that has finite outer measure and for which $m^*(O-E)>m^*(O)-m^*(E)$. (Here $m^*(E)$ denotes the Lebesgue outer measure of $E$). The following is my attempt. Suppose $E$ is not measurable. Assume that for all open sets $O$ containing $E$ that has finite outer measure we have $m^*(O-E)\leq m^*(O)-m^*(E)$. Let $\epsilon >0$. Since $m^*(E)=\inf\{m^*(U)|E\subseteq U\ \text{and}\ U\ \text{is open}\}$, $\exists U\ \text{open with}\ E\subseteq U\ \text{such that}\ m^*(U)-m^*(E)<\epsilon$. Then $U$ has finite outer measure. So by assumption it follows that $m^*(U-E)<\epsilon$. Therefore $E$ is measurable; contradiction. Hence the result. Could someone please tell me if this proof is alright? Thanks.","['self-learning', 'measure-theory', 'proof-verification']"
2257099,Perturbation property of Orthonormal basis for Hilbert space,"Suppose $\{e_i\}_{i\in I}$ is an orthonormal basis for some Hilbert space. $\{f_i\}_{i\in I}$ is an orthonormal family with the property $\sum^\infty_{i\in I} \|e_i-f_i\|^2<\infty$, show that $\{f_i\}_{i\in I}$ is also orthonormal basis. I can think of for a $x$ with $(x,f_i)=0$ for all $i$, prove $x=0$. However, I don't know how to continue to the next step.","['functional-analysis', 'hilbert-spaces']"
2257150,Closed Form for an Alternating Sum Involving Binomial Coefficients,"Question. For integer $n \geq 0$, find the closed form for
  $$
S_n = \sum_{k \leq 2^n} \binom{2^n - k}{k}(-1)^k
$$ My Attempt: I tried some small $n$ and got $S_0 = 1$, $S_1 = 1$, $S_2 = 0$, $S_3 = -1$ and $S_4 = -1$, but failed to come up with some patterns. Could you please provide some hints so that I can complete the remaining part by myself?","['combinatorics', 'binomial-coefficients', 'discrete-mathematics']"
2257156,Prove $\sum_{k=0}^{n-2}{n-k \choose 2} = {n+1 \choose 3}$,"Prove 
  $$\sum_{k=0}^{n-2}{n-k \choose 2} = {n+1 \choose 3}$$ Is there a relation I can use that easily yields above equation?",['combinatorics']
2257158,Three Color Triangle Challenge,"Problem : There is an inverted triangle colored dots. The colors are red, blue and yellow. If the two dots above are the same color, then the third dot below matches both. If the two dots above are different colors, then the third one below is different from either. Above are some examples If you make a colored row of only 3 dots, can you predict the outcome? Is there a pattern? How about 4 dots. Try the same for 5 and 6 dots and see if you can find any simplifications. Use this pattern to predict a row of 28 dots. My Progress: I read a paper on this online and it seems the for an even number of dots for the top row the product of the two yields the final dot. For odd ones I can carve out two triangles and get the problem. However, I need a solution based on the simplification of 3/4 dot rows. I listed the possibilities for 3 dots: If all three colors are different then the middle one is the final one (e.g.  B R Y = R) If two colors are involved then If the odd one is in the middle, it is the color not involved (e.g.  YBY = R) If the odd one is the first or last it is that one (e.g YBB = Y) However I don't understand how I can apply the above pattern to 4, 5, and then 28 dots to come up with a quicker solution.","['puzzle', 'combinatorics', 'problem-solving']"
2257182,How to Compute Projective Closure in General?,"There have been a few questions about this on this site, but I think my question is different because a) my question isn't about Hartshorne 2.9, it's just inspired by that question, and b) the other questions don't ever seem to actually describe how to go about finding the ideal, just verifying some work. The question in Hartshorne is to find the ideal of the projective closure of the twisted cubic parameterized by $(t,t^2,t^3)$ over some field $k$, and show it's not the same as projectivizing the generators of the twisted cubic's ideal in affine space. All of this is well and good and I've done this with only minimal struggling. The problem is that at the end, I had to make a sort of leap of faith. By this I mean, I wrote down the projectivizations, and I could visualize that the equations I had written down were not going to cut out the twisted cubic as I wanted it by looking at the appropriate affine piece. I needed one more equation, which I was able to deduce, and then include, and convince myself that this was the projective closure. This is highly unsatisfying, because at the end of the day I had to consult my ability to visualize a variety, rather than just doing algebra, and I would like to be able to do this in general. In Hartshorne, we prove that $I(\bar{Y}) = \beta(I(Y))$ where $\beta$ is the projectivization map. This description is not helpful really since in general this ideal will have infinitely many elements and it's really not useful to describe an ideal by listing its elements. So, suppose that we are working in a more general setting, considering maybe $k[x_1, ..., x_n]/I$ where $I = (p_1, ..., p_m)$ for some polynomials in these variables. How can I write down the ideal for the projective closure?",['algebraic-geometry']
2257197,Significance of multiplication operators in operator theory,"I just read the three versions of the spectral theorem, one of which is the unitary equivalence to a multiplication operator.
Now I asked myself two things How significant are the multiplication operators? Some examples of questions we cannot answer via them for instance would be nice. Are there analogues of the Jordan form? Looking at the construction of spectral measures it looks like we could use this machinery on an arbitrary operator, not just as successfully.","['functional-analysis', 'soft-question', 'operator-theory']"
2257209,(Conditional) uniform asymptotic inference,"Let $(\Omega,\mathcal{F})$ be measurable space and $\mathcal{P}$ be a family of probability measures on $(\Omega,\mathcal{F})$. A ""typical"" statistical problem is to show that $$\tag{1}\label{1}
\limsup_{n\to \infty}\sup_{P\in \mathcal{P}}P\{A_n\}\le \alpha.
$$ for some constant $\alpha\in(0,1)$ and a sequence of sets $\{A_n\}_{n\ge 1}$. Violation of \eqref{1} means that there are $\epsilon>0$ and a subsequence $n_k$ s.t. $P_{n_k}\{A_{n_k}\}\ge\alpha+\epsilon$. Now let $\mathcal{G}\subset\mathcal{F}$. Is it possible to state a conditional version of \eqref{1} given $\mathcal{G}$ ? If $\mathcal{P}$ is a singleton, i.e. $\mathcal{P}=\{P_0\}$, then it's trivial:
$$\tag{2}\label{2}
\limsup_{n\to \infty}P_0\{A_n\mid \mathcal{G}\}\le \alpha \quad P_0\text{-a.s.}
$$ and violation of \eqref{2} means that on a set having positive $P_0$-probability $P_0\{A_n\mid \mathcal{G}\}(\omega)$ exceeds $\alpha$ infinitely often. Specifically in my application $\mathcal{G}$ is generated by a sequence of random variables $X\equiv\{X_i\}_{i\ge 1}$. Let $\mathcal{Q}$ be a family of random probability measures, i.e. each $Q\in\mathcal{Q}$ is a RCP given $X$. Consider the following $\omega$-by-$\omega$ version of \eqref{1}:
$$\tag{3}\label{3}
\limsup_{n\to \infty}\sup_{Q\in \mathcal{Q}}Q\{A_n\}(\omega)\le \alpha.
$$ Under what conditions I may argue that \eqref{3} holds for ""almost all"" realisations of $X$?","['probability-theory', 'statistics', 'statistical-inference']"
2257260,Leibniz's rule and proving that $x(t)$ satisfies integral,"The question is: Show that if $x(t)$ satisfies the integral equation $$x(t) = a + bt + \int_{0}^{t}(t-s)f(x(s))ds $$ then $x(t)$ is a solution to the initial value problem $$x''(t) = f(x(t))$$ for $t>0$, with $x(0) = a, x'(0) = b.$ This is what I've done and I'm not sure if it's even remotely correct. $$\frac{d}{dt}x(t) = \frac{d}{dt}\left(a + bt + \int_{0}^{t}(t-s)f(x(s))ds\right) \\ x'(t) = b + \frac{d}{dt} \left(\int_{0}^{t}(t-s)f(x(s))ds\right)  \\ x'(t) = b + \int_{0}^{t} \frac{\partial}{\partial t}(t-s)f(x(s))ds \\ x'(t) = b + \int_{0}^{t} f(x(s)) + \frac{\partial f(x(s))}{\partial t}(t-s)\frac{\partial x(s)}{\partial t} ds \qquad \text{by chain rule and product rule} $$
Then I take the derivative again, and I don't seem to get the required result. Can someone tell me if I did something wrong and guide me in the correct way?","['derivatives', 'integration']"
2257306,Summation splitting: $\sum_{n=1}^{\infty} \frac{n}{3\cdot 5\cdot 7 \dots (2n+1)}$,"$$\sum_{n=1}^{\infty} \frac{n}{3\cdot 5\cdot 7 \dots (2n+1)}$$ Can someone please help me in solving this problem, I tried to take the summation of the numerator and denominator individually but my teacher said that it is wrong to do the summation individually, can somebody please explain why is it wrong to take individual summation and please recommend the correct way of solving this problem","['summation', 'sequences-and-series']"
2257315,For what $r$ does the Lorenz attractor exist?,"The Lorenz equations are given by: $$\begin{aligned} \dot X &= \sigma(Y-X)\\ \dot Y &= rX - Y - XZ\\ \dot Z &= X Y - bZ \end{aligned}$$ I know that for $r\gt r_H$ all trajectories go over to a strange attractor, but this does not necessarily mean that the attractor exists for only $r\gt r_H$ . For what values of $r$ does this attractor exist and why?","['chaos-theory', 'ordinary-differential-equations', 'dynamical-systems']"
2257339,"Given the square, calculate $\tan{\alpha}.$","Problem: Given the square $ABCD$, let $M$ be the midpoint on the side $|CD|$ and designate $\alpha=\angle AMB$. Calculate $\tan{\alpha}.$ Attempt: We can, without compromising generality, assume that the side of the square is equal to 1. So drawing a figure we get I know the following: 1) That $|AM|=|BM|=\sqrt{1^2+\left(\frac{1}{2}\right)^2}=\frac{\sqrt{5}}{2}.$ 2) The area of $ABM$ can be expressed in two ways. One way with normal geometry for triangle and another way is by using the areakit involving $\sin{\alpha}$. So: $$\begin{array}{lcl}
A_1 & = & \frac{1\cdot 1}{2} = \frac{1}{2} \\
A_2 & = & \frac{|AM|\cdot|BM|\cdot\sin{\alpha}}{2} = \frac{5}{2}\cdot\sin{\alpha} \\
\end{array}$$ 3) I know that $\tan{\alpha}=\frac{\sin{\alpha}}{\cos{\alpha}},$ so finding $\sin{\alpha}$ and $\cos{\alpha}$ and dividing these two will solve this problem. Setting $A_1=A_2$ yields the equation $$\frac{5}{2}\sin{\alpha}=\frac{1}{2} \ \Longleftrightarrow \ \sin{\alpha} = \frac{1}{5}.$$ Using the law of cosines in the triangle $ABM$ I get $$\begin{array}{lcl}
|AB|^2 & = & |AM|^2+|BM|^2 -2|AM||BM|\cos{\alpha} \\
1 & = & \sqrt{5}-\sqrt{5}\cos{\alpha} \ \Leftrightarrow \ \cos{\alpha} = \frac{\sqrt{5}-1}{\sqrt{5}} \\
\end{array}$$ And finally we have $$\tan{\alpha}=\frac{\sin{\alpha}}{\cos{\alpha}}=\frac{\frac{1}{5}}{\frac{\sqrt{5}-1}{\sqrt{5}}} = \frac{5+\sqrt{5}}{20}.$$ But it's not correct. Any idea where I'm making the mistake in my attempt, and is there an easier way of solving this problem?","['trigonometry', 'geometry']"
2257366,Prove that integration and summation can be swapped,"$\def\d{\mathrm{d}}$Prove that integration and summation can be swapped in the following expression: $$\int_{0}^{\infty} \sum_{n=0}^{\infty} \frac{(itx)^n}{n!}f(x)\,\d x,$$ where $|t|<\lambda$ and $f(x)$ is the density function of the $\mathrm{Gamma}(\lambda, \alpha)$ distribution for any real $\alpha >0$. I know that I need to use Fubini's theorem and show: $$\int_{0}^{\infty} \sum_{n=0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x< \infty,$$ or
$$\sum_{n=0}^{\infty} \int_{0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x< \infty.$$ I have tried the following:
\begin{align*}
&\mathrel{\phantom{=}} \sum_{n=0}^{\infty} \int_{0}^{\infty} \left|\frac{(itx)^n}{n!}f(x)\right|\,\d x\\
&< \sum_{n=0}^{\infty} \int_{0}^{\infty} \frac{\lambda^nx^n}{n!}|f(x)|\,\d x\ \text{(Used $|t|<\lambda$)}\\
&=\sum_{n=0}^{\infty} \int_{x=0}^{\infty} \frac{\lambda^nx^n}{n!}\left|\frac{x^{\alpha-1}\lambda^{\alpha}e^{-{\lambda}x}}{\Gamma(\alpha)}\right|\,\d x\ \text{(Substituted in $f(x)$)}\\
&=\sum_{n=0}^{\infty} \int_{x=0}^{\infty} \frac{1}{n!}\frac{x^{n+\alpha-1}\lambda^{n+\alpha}e^{-{\lambda}x}}{\Gamma(\alpha)}\,\d x\\
&\mathrel{\phantom{=}}\text{(Combined exponents and removed absolute value)}\\
&=\sum_{n=0}^{\infty} \frac{\Gamma(n+\alpha)}{n!\Gamma(\alpha)} \int_{x=0}^{\infty}\frac{x^{n+\alpha-1}\lambda^{n+\alpha}e^{-{\lambda}x}}{\Gamma(n+\alpha)}\,\d x\\
&=\sum_{n=0}^{\infty} \frac{\Gamma(n+\alpha)}{n!\Gamma(\alpha)}\\
&\mathrel{\phantom{=}}\text{(As the integral of the density of Gamma($\lambda$, $n+\alpha$) is $1$)}
\end{align*} The problem now is I don't believe this sum converges. Any help would be appreciated!","['integration', 'probability']"
2257382,Finding the unit normal to a cone.,MY METHOD: I thought I would use the conventional method for finding the unit normal vector by calculating the gradient of S. Where $S: x^2 +y^2 - z^2 = 0$. $\hat n = \frac{\nabla S}{mag[\nabla S]}$ $\hat n = \frac{2x \hat i + 2y \hat j -2z \hat k}{\sqrt{(2x)^2 +(2y)^2 +(2z)^2   }}$ $\hat n = \frac{2x \hat i + 2y \hat j -2z \hat k}{\sqrt{(4x^2 +4y^2 +4z^2   }}$ $\hat n = \frac{2x \hat i + 2y \hat j -2z \hat k}{\sqrt{(4r^2 +4r^2}}$ giving $\hat n$ as: $\hat n = \frac{x \hat i + y \hat j -z \hat k}{\sqrt{2}}$ which is not equivalent to the solution above. Also does anyone know exactly what they did? I am having difficult to comprehend it. Why is are they calculating the cross product of the partials? Is it to do with multivariable chain rule - which is so can someone expand on this explanation by going more in depth? Addition Edit I saw this equation on the internet but am unsure why that is the case. Why are they multiplying again by the magnitude? Any help is much appreciated!!,"['calculus', 'multivariable-calculus', 'integration', 'surfaces', 'vector-analysis']"
2257417,"Is $f(x + dx) -f(x) = f'(x) \,\mathrm dx$ a valid equation?","$\def\d{\mathrm{d}}$We know that it is true that$$\lim_{\Delta x \to 0} \frac{f(x + \Delta x) -f(x)}{\Delta x} = \frac{f(x + \d x) -f(x)}{\d x} = f'(x),$$
where $\d x$ is define to be an infinitesimal. Then we could rearrange the equation and say that$$f(x + \d x) -f(x) = f'(x) \,\d x.$$ Will this last equation be valid or correct? Update. Do you agree that: $$f'(x) \,\d x = \int_{x}^{x+\d x}f'(x)\,\d x.$$ Is this last equation valid or making sense? Does it even mean anything if you put a $dt$ in the limit? What I meant by valid is that would it be possible to apply it like in the context of the question here","['derivatives', 'limits']"
2257428,Intuitive meaning of transitive action,"In the context of abstract algebra, following from Dummit's textbook. 
The action of $G$ on $A$ is called transitive if there is only one orbit. $i.e$, 
given any two elements $a,b \in A$, there is some $g \in G$ such that $a=g.b$. I want to know why we called this as transitive. From some basic set theory knowledge, In equivalence relation, transitivity, 
$a \sim b$, $b\sim c$ then $a\sim c$. Does the same thing happens in the group action?",['abstract-algebra']
2257454,Prove $(X \Delta Y\subseteq B \land Y \Delta Z\subseteq B) \to (X \Delta Z\subseteq B)$: is it legit to combine proof by cases and indirect proof?,"Prove $(X \Delta Y\subseteq B \land Y \Delta Z\subseteq B) \to (X \Delta Z\subseteq B)$, where $X \Delta Y$ means $(X \setminus Y)\cup (Y\setminus X)$. Take $s$ as an arbitrary element, then I am allowed to assume $s \in X\setminus Z \lor s \in Z\setminus X$ to prove $s\in B$. My question is, is it legit to combine both  indirect proof and proof by cases? i.e. Firstly assume $s\notin B$, then assume $s \in X\setminus Z$ and $s \in Z\setminus X$ in turn to derive a contradiction? Since if both components of a disjunction imply a contradiction, then surely that means no matter which disjunct is true, $\lnot (s\in B)$ is problematic and thus it cannot be true?  (I tried and eventually derived a contradiction from assuming either of the disjuncts) I tried to verify this by proving $\lnot (s \in X\setminus Z)$, and then deriving a contradiction from there; and that works. But I am not sure if this means combining both methods is mathematically valid.","['elementary-set-theory', 'proof-verification']"
2257458,A question about Schur-Zassenhaus Theorem,"I'm studying Schur-Zassenhaus Theorem right now. I have already known the existence of a complement. And according to the textbook, the conjugacy part will use some concepts of sovable groups, but some special case can be proved first.$$$$
Suppose a complement $H$ of a normal Hall subgroup $N$ of $G$ is abelian, then all complements to $N$ are conjugate.$$$$
What I have thought: Since H is abelian, then H is the direct product of its Sylow subgroups.(Suppose $H=P_1 \times P_2 ... \times P_n$) And since $( |H| ,|N| )=1$, Sylow subgroups of $H$ are also Sylow subgroups of $G$. Now let $K$ be another complement of $N$. Similar to the argument above, $K$ can be written as $Q_1 \times Q_2 ... \times Q_n$. Then use the second part of the Sylow theorem, every $P_i$ is conjugate to $Q_i$.(i.e $P_i = g_i Q_i {g_i}^{-1}$  for some $g_i$) And here's my question: if these $g_i$ are the same element of $G$, then $H$ and $K$ are conjugate, but how to prove it? I'm stucked here. Am I close to the answer? Or I just came to a wrong way? Thanks in advance.","['finite-groups', 'abstract-algebra', 'group-theory']"
2257531,An equivalence condition on chain and open subsets,"Let $U $ be an open subset of a topological space $X $, are the following equivalent: 1) $U$ is dense; 2) Every chain $A_1\subseteq  A_2\subseteq ... $  of open subsets of $X $ stops if the chain  $A_1 \cap U \subseteq  A_2 \cap U  \subseteq ... $ stops (not nessesarilly at the same step). If is is not true what conditions can be replace by 1)?","['geometric-topology', 'general-topology', 'differential-topology']"
2257548,Distances between randomly distributed points in a ball,"Say I have a 3-ball with radius $R$. If I randomly pick 2 points from the inside of the ball, the probability that the euclidean distance between the points (labeled 1 and 2) takes on a particular value $r = r_{12} = r_{21}$ is given by the probability density function (PDF) \begin{equation}
P_3 (r) = \frac{3 r^{2}}{R^3} - \frac{9 r^{3}}{4 R^4} + \frac{3 r^{5}}{16 R^6}
\end{equation} as described in https://arxiv.org/pdf/math-ph/0201046.pdf , equation 15. If I were to pick $N$ points from the inside of this ball simultaneously, there would be $N(N-1)/2$ distances between pairs of different points. Is it possible to express the PDF $P(r_1, r_2, \dots{}, r_{N(N-1)/2}$), where $r_1, r_2, \dots{}, r_{N(N-1)/2}$ are distances between pairs of different points, using the pair-wise PDF $P_3(r)$ ? Does there exist some other closed-form solution for such distribution, or a solution for some shape other than a ball ? In this case, it is obviously not $P_3(r) \times P_3(r) \times \dots{} \times P_3(r)$, because, for example, when 2 points are at a distance $2R$, a third point cannot be at a distance $2R$ from both of them, but such PDF would allow it.","['random', 'euclidean-geometry', 'probability', 'probability-distributions']"
2257617,Prove $M/N$ is free implies $M \cong N \oplus M/N$,"I am asked to prove that if $M/N$ is free then $M \cong N \oplus M/N$, where M is a module over a ring, R and $N \leq M$. My first thought is that if $S$ is the basis of $M/N$, then we can consider the function $\phi: S \rightarrow M$ via $\phi(s_i + N) = s_i$ which then extends to some module homomorphism $\Phi: M/N \rightarrow M$. However I don't really know what to do beyond this point. I thought maybe I could have a function $\Theta$ that maps from $N \times M/N$ to $M$ and that $\Theta(n, s + N) = \theta(n) + \Phi(s + N)$ for some appropriate function $\theta$ If I could then show that this is a bijective function then I'd be done. However, if this is the correct approach I am unsure of how I can construct such a function and how to show it'd be bijective. I am really thinking that there's something simple I've missed but I am unsure how to proceed with this question. Thank you for any help you might be able to offer.","['abstract-algebra', 'ring-theory', 'modules']"
2257653,Why can we simplify $\sqrt{1 - \sin^2 u} = \sqrt {\cos^2 u}$ to $\cos u$ instead of $|\cos u|$ when making a trigonometric substitution?,"$\def\d{\mathrm{d}}$I'm trying to calculate a very typical integral: $$ \int \frac{\d x}{\sqrt{1-x^{2}}}.$$ In the first step I make substitution: $$ x = \sin(u), \qquad \d x = \cos(u)\,\d u.$$ As a consequence, $$ \int\frac{\cos(u)}{\sqrt{\smash[b]{1-\sin^{2}(u)}}} \,\d u = \int \frac{\cos(u)}{\sqrt{\smash[b]{\cos^{2}(u)}}}\,\d u.$$ In this point I have a problem. For example from this video: integral the result of above integral is: 
 $$ \int \d u  =  u + C = \arcsin(x) + C.$$ I don't agree with that, because $ \sqrt{\cos^2{u}} = |\cos(u)| $, right? Why is this answer correct?
I will be grateful for an explanation. Best regards.","['substitution', 'integration', 'trigonometry', 'calculus']"
2257671,What is the meaning and importance of the Hodge codiferential?,"In differential geometry given a smooth manifold $M$ we can define the exterior derivative $d$ acting on $k$ forms giving back $k+1$ forms. It is a map $d : \Omega^k(M)\to \Omega^{k+1}(M)$ which is in principle not so hard to define. It is indeed the natural way to define a derivative of differential forms and it leads directly to Stokes' theorem: $$\int_M d\omega=\int_{\partial M}\omega.$$ That is all fine, but now comes the thing. If one has a metric and can define the Hodge dual $\star$ it is possible to define the Hodge codifferential on $k$ forms by $$\delta = (-1)^{k} \star^{-1}d\star.$$ When defining the product $(\cdot,\cdot)$ $$(\eta,\zeta)=\int_{M} \eta \wedge \star \zeta$$ it turns out $\delta$ is a sort of adjoint of $d$, in the sense that $$(d\eta,\zeta)=(\eta,\delta \zeta)$$ and finaly from it one defines the operator $\Delta = \delta d+ d\delta$ which would be a generalization of the laplacian on general differential forms. It is all nice, but there is a thing here. I don't understand the meaning of any of this in the sense of how to interpret these things geometricaly and recognize their real importance. Actually I'm interested on this because of theoretical Physics. In some texts about Clifford bundles this operator appears quite a lot, the reason why I'm interested on it. So my question is: what is the meaning of this operator? How do we understand it geometricaly? Why would one introduce it and what is its importance? And if possible, why this operator would be so considered in Physics anyway?","['riemannian-geometry', 'mathematical-physics', 'manifolds', 'hodge-theory', 'differential-geometry']"
2257690,"If X is second-countable, then X is Lindelöf.","Munkres in his book states that: Theorem 30.3 Suppose that $X$ has countable basis, then every open covering of $X$ contains a countable subcollection covering $X$ . $\textbf{Proof.}$ Let ${B_n}$ be a countable basis and $\mathcal{A}$ an open cover of $X$ . For each positive integer $n$ for which it is possible, choose an element $A_n$ of $\mathcal{A}$ containing the basis element $B_n$ . The collection $\mathcal{A'}$ of the sets $A_n$ is countable, since it is indexed with a subset $J$ of the positive integers. Furthermore, it covers X: given a point $x \in X$ , we can chosse an element $A$ of $\mathcal{A}$ containing $x$ . Since $A$ is open, there is a basis element $B_n$ such that $x \in B_n \subset A$ . Because $B_n$ lies in an element of $\mathcal{A}$ , the index $n$ belong to the set $J$ , so $A_n$ is defined; since $A_n$ contains $B_n$ , it contains $x$ . Thus $\mathcal{A'}$ is a countable subcollection of $\mathcal{A}$ that covers $X$ . My first doubt is when he states $A_n$ is indexed with $J \subset \mathbb{Z}^+$ . Why is this true? My second doubt is about the construction of $\mathcal{A'}$ : he states that $\mathcal{A'}$ is the collection of the sets $A_n$ , but could have $A, A^* \in \mathcal{A'}$ such that $B_n \subset A \ \cap \ A^*$ . In this case, I think that we need have one of these sets in $\mathcal{A'}$ to ensure that $\mathcal{A'}$ is countable, but how exactly do I do this? Thanks in advance!","['general-topology', 'second-countable', 'proof-explanation']"
2257711,Prove that every equation of degree $n$ in $x$ has $n$ roots and no more.,"Prove that every equation of degree $n$ in $x$ has $n$ roots and no more. My Attempt: Let us suppose $f(x)=0$ where
$$f(x)=a_0 x^n + a_1 x^{n-1}+.....+a_{n-1} x+a_n$$ According to the Fundamental Theorem of Algebra, the equation $f(x)=0$ has a root, real or complex. Let this root be $\alpha_1$; then by the Factor Theorem, $x-\alpha_1$ is a factor of $f(x)$. So, how do I proceed from here?","['algebra-precalculus', 'polynomials']"
2257717,Proving that the area of a circle is $\pi r^2$ without using $\lim\limits_{\theta \to 0}\frac{\sin\theta}{\theta}=1$ (or vice versa),"$\def\d{\mathrm{d}}$I've seen countless proofs for the area of a circle. There's the 'onion' proof, where we break up the circle into rings and integrate: 
$$\int_0^{r_0 }2\pi r\, \d r=\pi r_0^2.$$
Of course, this proof is made rigorous using multivariate substitution from Cartesian to polar coordinates: 
$$
\d x \d y =\begin{vmatrix}x_r & x_\theta\\ y_r& y_\theta\end{vmatrix}\,\d\theta\d r =r\,\d\theta \d r.
$$
Now we integrate over $D=\left\{(x,y)\,\big|\,x^2+y^2\leq r_0^2\right\}$:
$$
\iint_D\,\d x\d y =\int_0^{r_0}\int_0^{2\pi}r\, \d\theta\d r=\int_0^{r_0}2\pi r\, \d r.
$$
This is the same integral as the first one. Note that when making the substitution, we used the derivatives of $\sin\theta$ and $\cos\theta$, both of which rely on the following well known limit: 
$$\lim_{\theta\to 0}\frac{\sin\theta}{\theta}=1.$$
Instead of doing this, we can inscribe and circumscribe the circle with regular polygons. Doing this, we arrive at the following inequality: 
$$\frac{1}{2}nr_0^2\sin\frac{2\pi}{n}<A<nr_0^2\tan\frac{\pi}{n}.$$
In the above, $A$ denotes the area of the circle, and $n$ denotes the number of sides in the regular polygon. Taking the limit as $n$ goes to infinity: $$\lim_{n\to \infty}\frac{1}{2}nr_0^2\sin\frac{2\pi}{n}\leq \lim_{n\to \infty}A\leq\lim_{n\to \infty}nr_0^2\tan\frac{\pi}{n}$$
$$\pi r_0^2\leq   A\leq\pi r_0^2$$
Again, we've used the following well known limit: 
$$\lim_{\theta\to 0}\frac{\sin\theta}{\theta}=1.$$
Now, instead of doing this, we can integrate in Cartesian coordinates to find twice the area of a semicircle: 
\begin{align*}
&\mathrel{\phantom{=}} 2\int_{-1}^1\sqrt{1-x^2}\,\d x= 2\int_{-\pi/2}^{\pi/2}\cos\theta\sqrt{1-\sin\theta^2}\, \d\theta\\
&= 2\int_{-\pi/2}^{\pi/2}\cos^2\theta\, \d\theta = 2\int_{-\pi/2}^{\pi/2}\frac{1+\cos 2\theta}{2}\, \d\theta\\
&= 2\left.\left(\frac{\theta}{2}+\frac{\sin 2\theta}{4}\right)\right|_{-\pi/2}^{\pi/2} =\pi.
\end{align*}
Again, in the substitution we used the derivative of $\sin x$, which relies on the following well known limit:
$$\lim_{\theta\to 0}\frac{\sin\theta}{\theta}=1.$$
The problem I have with all of this is that the proof of the above limit relies on the area of a circle to obtain the following inequality: 
$$\frac{1}{2}\sin\theta<\frac{\theta}{2}<\frac{1}{2}\tan \theta.$$
After this, we can apply squeeze theorem. There are other proofs that rely on Taylor series or Euler's formula, but these are usually circular (pun intended). So, my question is, can we prove the area of a circle is $\pi r^2$ without using the above limit, or vice versa?","['calculus', 'geometry']"
2257724,Any volume form on a smooth $n$-dimensional manifold is locally a pullback of the standard volume form $dx_1\wedge ...\wedge dx_n$ on $\mathbb R^n$?,"Let $M$ be an $n$-dimensional smooth manifold equipped with a volume form $\omega$ , and let $\omega_0:=dx_1\wedge ...\wedge dx_n$ be the standard volume form on $\mathbb R^n$ , then is it true that for every $a \in M$ , there exists an open set $U$ containing $a$ in $M$ and a diffeomorphism $g:U \to \mathbb R^n$ such that $\omega = g^*\omega_0$ ?","['differential-forms', 'smooth-manifolds', 'differential-geometry', 'pullback']"
2257741,Exercise I-$43$(a) in Eisenbud-Harris,"This is exercise I-$43$(a) in Eisenbud/Harris, Geometry of Schemes. Let $k[t] \rightarrow k[x,u]/(xu)$ be a $k$-algebra homomorphism given by $t \mapsto x+u$. For $\alpha \in k$, the fiber ring corresponding to the prime ideal $(t-\alpha)$ of $k[t]$ is given by $k[x]/x(x-\alpha)$. This fiber ring has exactly two prime ideals if $\alpha \neq 0$ and one prime ideal otherwise. The authors say that for $\alpha=0$ the fact that $k[x]/x^2$ is a two-dimensional $k$-vector space reflects the local structure of the map at the point $(x,u) \in \operatorname{Spec}(k[x,u]/(xu))$. However, even if $\alpha \neq 0$, $k[x]/x(x-\alpha)$ is still two-dimensional as a $k$-vector space, so that i don't see how the vector space dimension of the fiber ring captures something special about the point $(x,u)$. On the other hand, i do see that $k[x]/x^2$ can not be isomorphic as a ring to $k \times k$ because the latter has two prime ideals. But now what is the ring isomorphism identifying $k[x]/x(x-\alpha)$ with $k \times k$? The obvious map that identifies these two as $k$-vector spaces seems not to be a ring homomorphism.",['algebraic-geometry']
2257748,Write the function $\frac{1}{(z+1)(3-z)}$ as a Laurent series.,"$$f(z)=\frac{1}{(z+1)(3-z)}=\frac{1}{4z+4} + \frac{1}{12-4z}$$ $$\frac{1}{4z+4}=\frac{1}{4z}\frac{1}{1-\frac{-1}{z}}=\frac{1}{4z}\sum_{k=0}^{\infty} \left(\frac{-1}{z}\right)^k$$ $$\frac{1}{12-4z}=\frac{1}{12}\frac{1}{1-\frac{z}{3}}=\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{z}{3}\right)^k$$ $$f(z)=\frac{1}{4z}\sum_{k=0}^{\infty} \left(\frac{-1}{z}\right)^k+\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{z}{3}\right)^k$$ I can rewrite that as $$f(z)=\frac{1}{4z}\sum_{k=-\infty}^{0} (-1)^k z^k+\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{1}{3}\right)^k z^k$$. I need to move the $\frac{1}{4z}$ and $\frac{1}{12}$ into the sums but finding a series that will converge to each, but I have no idea what to use for either. Any suggestions? Am I taking a wrong approach or is there an obvious series to use for this? Edit: The center is $0$ and the region in $1 \le |z| \le 3$. I think I can use a geometric sequence to say $\frac{1}{4z}=\sum_{k=0}^{\infty}\frac{1}{2}(\frac{1}{2})^{k-1}\frac{z}{k}$ and $\frac{1}{12}=\sum_{k=0}^{\infty}\frac{1}{36}(\frac{2}{9})^{k-1}\frac{z}{k}$. I'm pretty sure that's true, but it seems like it makes the whole thing a complicated mess.","['laurent-series', 'complex-analysis', 'sequences-and-series']"
2257782,Expectation of maximum of minimums of permutations,"Assume $n$ random permutations $\pi_1,\pi_2,\ldots,\pi_n: \lbrace 1,2,\ldots,m \rbrace \rightarrow \lbrace 1,2,\ldots,m \rbrace$. Let $X_i = \min(\pi_1(i),\pi_2(i),\ldots,\pi_n(i))$ and $Y = \max(X_1, X_2, \ldots, X_m)$. What is the expectation of $Y$, $E(Y)$, as function of $n$? An upper bound approximation for $E(Y)$ would also be very helpful. Obviously, 
we have $E(Y)=m$ for $n=1$ and $E(Y)=1$ for $n\rightarrow\infty$. I know that the distribution of $X_i$ is given by 
$P(X_i\leq k) = 1 - \left(1-\frac{k}{m}\right)^n$. However, since $X_1,X_2,\ldots,X_m$ are not independent, it is not possible to get the distribution of $Y$ by
$P(Y \leq k) = P(X_1 \leq k \wedge X_2 \leq k \wedge \ldots \wedge X_m\leq k) \neq P(X_1 \leq k)  \cdot P(X_2 \leq k)  \cdot\ldots \cdot P(X_m \leq k)$.","['permutations', 'statistics', 'probability']"
2257800,$n^{th}$ derivative of $y=(x \sqrt{1+x^2})^m$,"I was trying to find the $n^{th}$ derivative and $y_n(0)$(nth derivative at zero) of the function 
$$y=(x \sqrt{1+x^2})^m$$ 
Here is my approach:
$$y^2=(x^2 (1+x^2)^m$$
$$2yy_1=m(x^2 (1+x^2))^{m-1} \cdot(2x+4x^3)$$
$$2yy_1=m\frac{(x^2 (1+x^2))^{m}}{(x^2 (1+x^2)} \cdot(2x+4x^3)$$
$$2yy_1=m\frac{y^2}{(x^2 (1+x^2)} \cdot(2x+4x^3)$$
$$2yy_1((x^2 (1+x^2))=my^2(2x+4x^3)$$
$$y_1(x^2(1+x^2))=my(x+2x^3)$$ Derivating again I can write
$$y_2(x(1+x^2))+y_1(1+3x^2))=my_1(x+2x^3) + my(1+6x^2)$$
$$y_2(x(1+x^2))+y_1((1+3x^2)-m(x+2x^3))-my(1+6x^2)=0$$ Now my book says that the answer is 
$$y_n(0)=m^2(m^2-2^2)(m^2-4^2).......[m^2-(2n-2)^2]; n=odd$$
$$y_n(0)=m^2(m^2-1^2)(m^2-3^2).......[m^2-(2n-1)^2]; n=even$$ But after applying Leibnitz theorem for the derivative, I don't end up with anything like this. Can anybody please tell me how to approach this question.","['derivatives', 'calculus']"
2257806,Parity of solution,"Let $N_n$ denote the number of ordered $n-$tuples of positive integers
  $(a_1,a_2,... ,a_n)$ such that $\frac{1}{a_1}+ \frac{1}{a_2}+\cdots + \frac{1}{a_n}=1$. Determine whether $N_{10}$ is even or odd. The answer provided is ""$N_{10}$ is odd"". I tried finding number of solutions and got a wrong answer.Is there a more elegant method?","['number-theory', 'contest-math']"
2257809,"If $\mathbf{AA}^T=\mathbf{I}$, is $\mathbf A$ necessarily square?","If $\mathbf{AA}^T=\mathbf{I}$, is $\mathbf A$ necessarily square? I am starting to learn about matrices, and had the above question. When I have tried to think about this, I have not been able to progress using matrix multiplication, since $\textbf{A}$ and its transpose do not have inverses unless they are square. The only conclusion I could come to using matrix multiplication is that the product of a matrix and its transpose, whatever the dimensions, is square and symmetric. I also tried to consider this component-wise; for a 1x3 case, it was easy to see that there are no solutions. But the algebra for a 2x3 case was quite messy because it involved 6 variables. I am not sure how else to think about this. I have seen the proofs that a matrix must be square to have and inverse ( here ), but the answers all rely on the additional defining property of an inverse being that $\textbf{AA}^{-1}=\textbf{A}^{-1}\textbf{A}$, and if $\textbf{A}$ was not square, $\textbf{AA}^{-1}$ could theoretically be equal to $\textbf{I}$ but then it would not have the same dimensions as $\textbf{A}^{-1}\textbf{A}$, violating the above property. As a similar constraint is applied to orthogonal matrices, these qould also have to be square. However is it possible for a non-square matrix to be such that  $\textbf{AA}^T=\textbf{I}$, whether or not $\textbf{A^TA}=\textbf{I}$, where the identity matrix here could be of a different dimension? If so, does $\textbf{AA}^T=\textbf{I}$ mandate that $\textbf{A}^T\textbf{A}=\textbf{I}$?","['matrices', 'orthogonality', 'inverse']"
2257836,What is the difference between a reducible representation and a completely reducible representation?,"I came across the definition of a completely reducible representation of a group. The way I understand the definition there is no real difference between a reducible representation and a completely reducible representation. The book I'm currently reading states that ""This means that a completely reducible representation can be written, with a suitable choice of basis, as the direct sum of irreducible representations."". But, as far as I know, any representation is either reducible or irreducible so, eventually, any reducible representation can be written as a direct sum of irreducible representations. What am I missing? What is the difference between reducible and completely reducible? Thanks.","['representation-theory', 'group-theory']"
2257864,"What is the closure of the space of compact operators , on Hilbert space , in the space of bounded operators , under strong operator topology ?","Let $H$ be a Hilbert space over $\mathbb C$ , I know that the space of all compact operators on $H$ ($\mathcal K(H)$ ) is closed in $\mathcal L(H)$ in norm topology . I want to ask , what is the closure of $\mathcal K(H)$ in $\mathcal L(H)$ in strong operator topology ? Is the space of compact operators still closed then ?","['functional-analysis', 'compact-operators', 'hilbert-spaces']"
2257866,Why is generating function proof of Fibonacci formula correct?,"The proof goes as follows:- Let $F = 1 + x + 2x^2 + 3x^3 + 5x^4 + 8x^5 + ...$ Then $$\begin{align} 1 + Fx + Fx^2 &= 1 + (x + x^2 + 2x^3 + 3x^4 + ...) + (x^2 + x^3 + 2x^4 + 3x^5) \\
 1 + Fx + Fx^2 &= 1 + x + (x^2+x^2 + 2x^3+x^3 + 3x^4+2x^4 + ...) \\ 
 1 + Fx + Fx^2 &= F \\
  \frac{1}{1-x-x^2} &= F  \end{align} $$ We rearrange the terms and we get this result which can be then manipulated further to find formula for nth Fibonacci term. I want to focus on the rearrangement of terms in an infinite series . This is no different from results like $ 1 + 2 + 4 + 8 + ... = -1$. The usual answer given is that we cannot treat an infinite summation like this like real numbers and apply normal addition and subtraction rules . We must apply sophisticated techniques like limits to evaluate these sums. So $ 1 + r + r^2 + r^3 + ... $ only makes sense when $|r| < 1$. So going back to the Fibonacci proof above. We are applying normal addition rules for an infinite summation and also the result $\displaystyle  F = \frac{1}{1-x-x^2} $ doesn't make sense for any value of $x$. But we still use this result to complete the proof. Why does it work ? Isn't this the same as using the result $ 1 + 2 + 4 + 8 + ... = -1 $ to prove other results ? It would be absurd to use it as basis for other proofs. Please shed some light on this. I am really confused.","['generating-functions', 'fibonacci-numbers', 'sequences-and-series']"
2257878,Prove $f(x) =\ \frac{x^5}{5!} +\frac{x^4}{4!} +\frac{x^3}{3!}+\frac{x^2}{2!} +x+1$ has only one root.,We have to prove that the equation $\displaystyle  \frac{x^5}{5!} +\frac{x^4}{4!} +\frac{x^3}{3!}+\frac{x^2}{2!} +x+1=0$ have exactly one real root . My sir told me it is just an application of derivative . But I could not understand what he mean by that . Can anybody please explain me .,['derivatives']
2257898,What is the minimum number of people required?,"Let there be $k$ professions and let there be $b$ blocks. We have $n$ people who belong to these $k$ professions, and each person belongs to exactly one profession. We want to place these $n$ people in the $b$ blocks. For the $j$-th block, let $n_{ij}$ be the number of people belonging to profession $i$ in $j$-th block. Note, some of the $n_{ij}$ may be $0$. Let $n_j$ be the number of people in $j$-th block. Then $\sum_{i=1}^k n_{ij}=n_j$. Further, $n=\sum_{j=1}^b n_j$. Also assume $n_j>0$ for all $j$. We want to place the $n$ people in the $b$ blocks (ordering unimportant) such that for every $j,j'$ there exists $i$ such that $n_{ij}>0,n_{ij'}>0$. If $k,b$ are given, what can be the minimum possible value of $n$? I would love it if someone can help me get the solution. I believe the answer is $n>b+k-1$ (though unsure about it) but cannot really prove it.","['combinatorics', 'recreational-mathematics', 'discrete-mathematics']"
2257928,"$X$ and $Y$ Banach Spaces, $T \in B(X,Y)$, $Y = \operatorname{im}T \oplus M$, for $M \subseteq Y$, then $\operatorname{im}T$ is closed in $Y$","Let $X$ and $Y$ be Banach spaces. If $T \in B(X,Y)$, and $Y = \operatorname{im}T \oplus M$ for some closed linear subspace $M$ of $Y$, then $\operatorname{im}(T)$ is closed in $Y$. I am unsure if this statement is true or not. Nonetheless, I am having difficulty proving it, any suggestions or counterexample?",['functional-analysis']
2257951,Evaluate $ \lim_{n \to \infty} \int_0^n \frac{dx}{1 + n^2 \cos^2 x} $,Evaluate $$ \lim_{n \to \infty} \int_0^n \frac{dx}{1 + n^2 \cos^2 x}$$ I think this function is periodic with the period $T = \pi$ and I thought of rewriting it by changing the upper bound to $\pi$?  I don't know if I can or if it's  even desirable to do so. EDIT: I'd like to proceed without the use of Taylor series.,"['integration', 'limits']"
2257953,Find the least composite number that divides $2^n-2$,"The problem follows, What is the smallest composite number n, such that $n \vert 2^n-2$ Initially, I thought if we frame the question such that $2^n$ is congruent to $2 \mod n$, we can use the phi function. Through Fermat's little theorem we know that $2^{\phi(n)}$ is congruent to $1 \pmod n$. Thus I tried finding numbers such that the $\phi(n)\vert n$. However, the answer to this problem is 341 and it doesn't fall under the restrictions I gave it. What am I missing?","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
2257954,'Extended complex plane and infinity,"Ahlfors, in his Complex Analysis, while beginning the discussion on spherical representation of complex numbers,  says the following: ""...we can of course introduce an 'ideal' point which we call the point at infinity. The points in the plane together with the point at infinity form the extended complex plane. We agree that every straight line shall pass through the point at infinity. By contrast, no half plane shall contain the ideal point."" What does he mean by saying that every straight line passes through ""the point at infinity""? Also, with every straight passing through the ideal point, how come no half plane contains the ideal point?","['complex-analysis', 'complex-numbers']"
2257962,Why is a discrete subset of a compact space finite?,"I have a question about the proof of Lemma 5.13 in John Lee's text, the proof is shown below. My question is about the phrase underlined in red, why is a discrete subset of the compact set finite? Now, the author never gives a definition for discrete subset, he only gives it for discrete topology but from the phrase underlined in blue, I can tell that his definition of discrete set is as follows, $S$ is a discrete subset of a topological space $X$ if for each $ s \in S$, there exist a neighborhood $U$ of $X$ such that $ U \cap S = \{s\}$.  Is this correct? Then, if you take $X$ to be the closed interval $ [-1,1]$ with the subspace topology induced from $\mathbb{R}$, then $X$ is compact, and let $S = \{ {1 \over n}, n \in \mathbb{N} \} $, then according to the definition above, $S$ is discrete but $S$ is not finite?? I feel I'm missing something but I don't know what it is. Thank you.","['manifolds', 'general-topology']"
2257964,convergence of pdfs vs cdfs,"Let $X_n$ be a continuous rv with cdf $F_n(x)$ and pdf $f_n(x)$. Let $X$ be a continuous rv with cdf $F(x)$ and pdf $f(x)$. It is known that convergence in distribution, i.e., $F_n(x)\to F(x)$ as $n\to\infty$ at every continuity point $x$ of $F(x)$, does not generally imply that $f_n(x)\to f(x)$ as $n\to\infty$. This question offers a counterexample. My question is: Is there a class of continuous rvs for which $F_n(x)\to F(x)$ does imply $f_n(x)\to f(x)$? What additional conditions are these rvs to satisfy? Incidentally, according to this question , pointwise convergence of $f_n(x)$ to $f(x)$ is enough to have $F_n(x)\to F(x)$. I'm particularly interested in the case when $f_n(x)$ is supported on $[0,n]$ while $f(x)$ is supported on $[0,\infty)$. To boot, $f_n(x)$ is infinitely differentiable at every $x\in[0,n]$ for each $n$, and $f(x)$ is infinitely differentiable at every $x\ge0$. In fact, in my specific case, $f(x)=e^{-x}$, $x\ge0$.","['weak-convergence', 'probability-limit-theorems', 'probability-theory', 'statistics']"
2257978,"Closed subset of $C([0,1],\mathbb R$)","Let $B=\{f\in C^1[0,1]:\Vert f\Vert _\infty \le A\}$. Is $B$ a closed subset of $C([0,1],\mathbb R)$? Here's what I tried to do: Let $\{f_n\}$ be a sequences of functions of $B$ such that $f_n \to f$, with $f\in C([0,1],\mathbb R)$. If I prove that  $f\in B$, then I finish the proof, i.e. $B$ will be closed in  $C([0,1],\mathbb R)$. But I don't know how could I do that. Note:  $C([0,1],\mathbb R)$ is the space of continuous functions with domain $[0,1]$.","['real-analysis', 'normed-spaces', 'functional-analysis', 'sequences-and-series', 'analysis']"
2258014,Finding the derivative of function with domain empty set,"I was asked to find the derivative of the function
$$
\sin^{-1}(e^x + 3).
$$
First I was thinking of the chain rule, but something looked strange about the function. The domain of $\sin^{-1}$ is $[-1,1]$ and $e^x + 3$ is always strictly greater than $3$. I think that there is a mistake in the problem, but assuming that there isn't: what exactly is the derivative of a function like this one that ""doesn't exist""? (Is it true to say that the function doesn't exist?)","['derivatives', 'calculus', 'functions']"
2258034,The expected value as an integral,"Let $X \geq 0$ be continuous random variable with the CDF $F(x) := \displaystyle\int_0^x f(x) \; \mathrm dx$ where $f(x)$ is the PDF. I want to express the (finite) expected value $E[X] := \displaystyle\int_0^\infty x f(x) \; \mathrm dx < \infty$ as an integral that includes the failure rate function $r(t) = \frac{f(x)}{1 - F(x)}$ but not the PDF, CDF or survival function $G(x) = 1 - F(x)$.","['means', 'real-analysis', 'probability', 'statistics']"
2258041,Intuition behind the essential range,"We define the essential range in the following way. Let $F$ be a real-valued function on a measure space $\langle M , \mu \rangle$. We say $\lambda$ is in the essential range of $F$ if and only if $$\mu \{ m \ \vert \ \lambda - \epsilon < F(m) < \lambda + \epsilon \} > 0$$ for all $\epsilon >0$. Intuitively, should we think of the essential range as the range of $F$ seen by the measure? Does this at all relate to the essential supremum defined on $L^{\infty}?$","['functional-analysis', 'banach-spaces', 'operator-theory', 'hilbert-spaces']"
2258050,Weakly non-completable partial Latin square,"An empty cell in a partial Latin square (pLs) is said to be forced if it has a unique admissible entry (compatible with the definition of a Latin square).
Attempting to complete a given pLs, one can start by successively filling in these forced entries. If the pLs is completable, this can lead to the following two situations: The pLs can be completed solely by forcing. Such pLs are usually called strongly completable . Example: $\left(\begin{array}{ccc} 1&-&- \\-&3&- \\ -&-&- \end{array}\right)$; the middle entry in the top row is forced to be 2, and so on. The pLs cannot be completed solely by forcing. At some point one has to make a case analysis (there might still exist a unique completion). Such pLs are usually called weakly completable .
Example: $\left(\begin{array}{ccccc}-&-&-&-&5\\-&1&4&-&-\\3&-&5&-&-\\4&-&2&-&-\\-&-&-&2&4\end{array}\right)$; no forced entry, but nevertheless has a unique completion. However, I'm interested in partial Latin squares that are not completable. If we attempt to fill a non-completable pLS by forcing, we run into either of the following two situations: Forcing leads to a contradiction (i.e. there is a cell with no admissible entry). We might call such a pLs strongly non-completable . Example: $\left(\begin{array}{ccc}1&-&-\\-&3&-\\-&-&1\end{array}\right)$; both the left and right entry in the middle row are forced to be 2. Forcing does not lead to a contradiction; at some point we have to make a case analysis to show that the pLs is not completable. Let's call such a pLs weakly non-completable . Example: ??? Question :
All non-completable pLs I know of are strongly non-completable. Are there known examples of weakly non-completable partial Latin squares (maybe even a trivial one I'm missing)? Is there a way to systematically construct such examples? More generally, has the notion 4. been studied before?","['combinatorics', 'latin-square']"
2258056,Continuous function from real to natural number,"How can you prove that the only continuous function from real number with the Euclidean topology to natural number with the cofinite topology is the constant function (without metrics)? I tried to use disconnections and the fact that the preimage of a closed set is close if the function is finite, but I can't find anything, as N is connected with the cofinite topology... Thank you!","['general-topology', 'functions']"
2258129,Pre-image of random variable,"The definition from my lecture notes of a random variable is as follows: $\textbf{Definition} \hspace{2mm} \text{A random variable is a map X}:\Omega \rightarrow \mathbb{R} \text{ such that for any} A  \in \mathscr{B}(\mathbb{R}),$ $$X^{-1}(A) = \{\omega \in \Omega:X(\omega)\in A\} \in \mathscr{F}.$$ Surely, for example, if we take X to be the number of even numbers in two rolls of a die and we take some arbitrary interval in the set of Borel $\sigma$ -algebras of $\mathbb{R}$ , such as $(-1,2)$ , not every member of this set can be mapped back to a sample point? What would $X^{-1}(-1,2)$ represent? Edit: Also, what is $X(\emptyset)$ ?",['measure-theory']
2258135,How to find all integer solutions of an equation which are divisible by 8?,"I have to find out all integer solutions of $n^2+15$ which are divisible by 8. So my idea was to solve the following equation. $$n^2+15=8\cdot k \to n^2=8\cdot k-15 \to  n=\sqrt{8\cdot k-15}$$ But this doesn't work.I tried some numbers $n=1, n=3, n=5, n=7$ for these numbers I get integer solutions of $n^2+15$ which are divisible by 8. It seems to be that $n$ must be odd. How do I solve this correctly? Best regards","['discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2258139,Certain properties of numbers such that $n \mid 2^n+1$,"A natural number $n>1$ is called good if$$n \mid 2^n+1.$$ For example, $n=3$ is good, as $3 \mid 2^3+1=9$. Prove that if $N_1$ and $N_2$ are good, then: $\mathrm{lcm}(N_1,N_2)$ and $\gcd(N_1,N_2)$ are good, $N_1\cdot N_2$ is good. This seems pretty difficult for me. Any hints?","['number-theory', 'contest-math', 'divisibility']"
2258152,Probability of at least X consecutive failures over N period given P success rate,"I am trying to figure out the formula used to calculate the numbers of the spreadsheet that I just posted. To summarize, it is the probability of seeing at least (X) consecutive losing trades within a 50-trade period, given a list of defined winning percentages. I want the formula/model to solve this so I am able to calculate the probabilities with variables of different values. Example, the probability of seeing at least 15 consecutive losing trades over a 500-trade period, with a theoretical winning percentage of 45%. Thank you very much to anybody who can help","['probability-theory', 'statistics']"
2258170,Using contour line integrals to prove identities,I am looking for examples of how contour line integrals may be used to prove certain identities (that may seem unrelated to complex analysis) like this combinatoric one. Can anyone suggest more examples or links to them?,"['complex-analysis', 'real-analysis']"
2258175,smallest number of socks to guarantee that the selection contains at least $10$ pairs,"A drawer in a darkened room contains $100$ red socks, $80$ green socks, $60$ blue socks and $40$ black socks. A youngster selects socks one at a time from the drawer but is unable to see the color of the socks drawn. What is the smallest number of socks that must be selected to guarantee that the selection contains at lest $10$ pairs?
(A pairs of socks is two socks of the same color. No sock may be counted in more than one pair.) What is the smallest number of socks that must be selected to guarantee that the selection contains at least $10$ pairs? My attempt : $100 = a $ $ 60 = b$ $ 40 = c$ $ 80 = d$ $a + b +c +d =280 $ socks I know the probability of choosing each color on the first try are : $p(a) = 0,3571;\,\,  p(b) = 0,2142;\,\, p(c) = 0,1428;\,\, p(d) = 0,2857$ How can I find  the smallest number of socks that must be selected to guarantee that the selection contains at lest $10$ pairs?",['combinatorics']
2258204,"Derivative and Antiderivative: Suppose $F: [a,b]\rightarrow \mathbb{R}$ is differentiable on $[a,b]$.","Suppose $F: [a,b]\rightarrow \mathbb{R}$ is differentiable on $[a,b]$.
Does it follow that $\int_{a}^{b} F' = F(b)-F(a)$? This is an interesting question. Don't we have to assume that $F'(x)$ is always equal to $f(x)$ for this to work? In other words, does $F(x)$ being differentiable always guarantee that $F'(x)$ is integrable? Thanks!","['real-analysis', 'integration']"
2258225,Probability of rolling a value a certain number of times in a certain number of rolls,"I am familiar with the formula to calculate the probability of rolling a certain number at least once given $x$ rolls of a die with $y$ sides, that is: $$P_1(x, y) = 1 - \left(1 - \frac{1}{y}\right)^x$$ where the subscript $1$ indicates that the number should be rolled at least once. For example, the chance of rolling a 6 in 6 rolls of a D6 would be $P_1(6, 6) = 1 - \left(1 - \frac{1}{6}\right)^6 \approx 0.665$. This got me thinking what the probability would be to roll a number at least $n$ times given the same die conditions. I manually worked out the probability for n = 2: $$P_2(x, y) = \frac{x}{y}-\left(1 - \left(1 - \frac{1}{y}\right)^x\right)$$ This does work even if only two dice are rolled, in which case the probability should simply be $(\frac{1}{y})^2$, and it is. For a D20, $P_2(2, 20) = (\frac{1}{20})^2 = \frac{1}{400}$. After that I tried to figure out how to represent $P_3(x, y)$ but unfortunately I was unable to do so. Previously, I was effectively considering a binomial coefficient in geometric terms. Using $P_n(3, y)$ as an example and looking for rolls of 20 for simplicity's sake, I considered a cube of side length $y$ divided into $y^3$ unit cubes. For $P_1$ I took the face cubes, subtracted the edge cubes, and added back the corner to give me the number of rolls in which a 20 appeared. For $P_2$, the formula was edge cubes $-$ corner for all rolls in which two 20s appeared. I know this all involves binomial coefficient, but I never really took a proper stats class so my knowledge of its application is somewhat limited. To find a general case for $P_3$, I would have to consider a 4-cube which I tried and failed. I'm sure this could be done easily using binomial coefficient, but that's sort of why I'm asking about this. I'm fairly sure that my expression for $P_2$ only has that extra $\frac{x}{y}$ term because $\binom{3}{1}$ and $\binom{3}{2}$ happen to equal 3 and therefore could be algebraically reorganized. My question is this: Is there a general case formula for $P_n(x, y)$ that represents the probability of rolling a number $n$ times given $x$ rolls of a $y$-sided die. Additionally, would said formula be different if the requirement was to roll one number $n_1$ times and another number $n_2$ times and so on? Is there a different general case for $P_{{n_1}, {n_2}, ...}(x, y)$?","['binomial-theorem', 'binomial-coefficients', 'statistics', 'probability', 'dice']"
2258261,Not open set looks like the disjoint union of countably many open intervals.,"The set is the complement of $A$, where $A = \left\{\frac{n+1}{n} \, | \, n \in \{1,2,...\}\right\} \subset \mathbb{R}$ The complement of $A$ is not open in $\mathbb{R}$ because any ball with centre $1$, contains elements of $A$. But we proved a theorem in class showing that any open subset of $\mathbb{R}$ is the union of a countable collection of intervals. $A$ looks like its countable distinct points, so the compliment would be the union of a countable collection of disjoint open intervals. But then the complement of $A$ would be open, which it isn't. I'm very confused. I would greatly appreciate any clarification you could offer me.","['general-topology', 'metric-spaces', 'elementary-set-theory']"
2258308,show that $(n+1)(n+2)...(2n)$ is divisible by $2^n$ but not by $2^{n+1}$,"Is this proof correct? Suppose $2^k$ is the largest power of $2$ in the sequence $n+1, n+2, ... 2n$ Then we can compute the power of 2 in the product as $n/2 + n/2^2 + ... n/2^k = n(1 + 2 + .... 2^{k-1})/2^k = n$.","['number-theory', 'elementary-number-theory']"
2258319,Prove that cosine is norm decreasing,"Prove that: $|\cos(y) - \cos(x)| <|x-y| ,\forall (x,y)\in(\mathbb{R} \times \mathbb{R}) /\triangle(\mathbb{R})$ My attempt It looks like we need to prove that the cosine function is norm decreasing.So the goal is to show that $$d(f(x),f(y))<d(x,y),\forall x\neq y$$ By the mean value theorem, Let $f(x)=\cos(x)$ then $f'(x)=-\sin(x)$. So $$-\sin(c)= \frac{\cos(y)-\cos(x)}{y-x}$$
$$\Rightarrow (y-x)(- \sin(c))=\cos(y)-\cos(x) $$
I am not sure, but can we conclude anything about cosine being bounded here? Why or why not? By some trig identities we know that:
$$i) \sin(A+B)=\sin(A)cos(B) +\cos(A) \sin (B)$$ $$ii) cos(A+B)= \cos(A) \cos(B) - \sin(A) \sin(B) $$ $$iii) \cos(x)-\cos(y)= -2\sin(\frac{x-y}{2})(\sin\frac{x+y}{2})$$ Plugging $iii$) in $d(f(x)-f(y))<d(x,y)$: $$|-2\sin(\frac{x-y}{2})(\sin\frac{x+y}{2})|<|x-y|$$
$$= 2|\sin(\frac{x-y}{2})(\sin\frac{x+y}{2})|<|x-y|$$ Don't really know where to go from here Oh and another thing... why is the domain $\forall (x,y)\in(\mathbb{R} \times \mathbb{R}) /\triangle(\mathbb{R})$, what does this even mean?","['real-analysis', 'trigonometry', 'calculus']"
2258332,Nth derivative of $x^x$,"A few days ago, I was wondering about a series expansion for $$f(x) = \  x^x$$ so I tried taking a couple derivatives. From these I was able to guess at some formulas for the general coefficients of the first few terms of the nth derivative as well as the last term (where I put the terms of the derivative in the order  $$f^{(n)}(x) = c_1x^x + c_2x^{x-1} + c_3x^{x-2}\ + \ ... \ +\ c_nx^{x-(n-1)}$$ Please let me know if there is a general formula for the coefficients as a function of n. In my own fooling around, I found that $$\ln(x)+1$$ appears quite a bit, so I called this $a$ in my work. Since I would like to center my expansion at $1$, and this expression evaluated to $1$, at $x=0$, I was interested in writing my formulas as functions of $n$ and $a$. I found that you get something of the form (this could very well be completely incorrect):  $$f^{(n)}(x) = ax^x + a^{n-2}{\binom n2}x^{x-1} + a^{n-4}(3{\binom n4}-a{\binom n3})x^{x-2}\\ + a^{n-6}(15{\binom n6}-10{\binom n5}a+2{\binom n4}a^2)x^{x-3}\ + \ ... \ +\ (-1)^n(n-2)! \ x^{x-(n-1)}$$ An interesting property that seemed to recur for the various coefficients was  that once I found a recursion formula for the coefficient in question and plugged in my initial value, it always seemed to be the same as taking the integral of the previous coefficient with respect to $a$. That is to say, if I plugged in the nth coefficient (a polynomial of $a$) into my recursion formula for the $(n+1)$th coefficient, this gave me the same result as integrating. In general, as reflected by the few coefficient formulas above,  the formula for the coefficient of $$x^{x-c}$$ where c is an integer such that $$0\le c<n$$ ""Stabilized"" to a polynomial of a with c terms after the first few applications of the recursion formula. This stabilization occurred when $$n=2c$$ Also, as a direct result of the tentative and incomplete formula I have written above, the first nonzero-value for the coefficient of $$x^{x-c}$$ is $$(-1)^{c+1}(c-1)!$$ and appears in $$f^{(c+1)}(x)$$ If these various properties are indeed true, can anyone explain why this would be the case? I am aware that this function can be expanded using the expansion for $$e^x$$ with $$x\ln(x)$$ in the exponent. This does not strike me as particularly enlightening (let me know if I'm missing something). I am most interested in the coefficients on the binomial coefficients, since these are the only things that stand between me and a general formula for the coefficients (since the form is quite standard). These are: $$1$$ then $$3,-1$$ then $$15, -10,2$$The sum of these coefficients should also give the nth derivative evaluated at zero since $$f(1) = 1$$ and $$a(1) = 1$$ Anyway, please let me know what you think! I am currently stuck due to an inability to brute force my way any further and a complete lack of cleverness. My knowledge of mathematics is quite elementary, so please explain any higher level concepts if they are necessary to explain this problem.","['derivatives', 'exponential-function']"
2258338,"Finding the de Rham Cohomology group of $\mathbb{S}^2\backslash \{a,b,c\}$.","I am trying to understand how to compute the de Rham cohomology group. Could someone show me how I would find the cohomology group of $\mathbb{S}^2\backslash\{n\text{ points of } \mathbb{S}^2 \}$. I know I should find the de Rham cohomology group for $n=1,2,3,4,..$ till I see a pattern. However, I have little experience doing this and can't find a good example I could follow. Could someone show me how to compute these for several n-values?","['homology-cohomology', 'differential-geometry']"
2258340,Proving the p-series test using the mean value theorem,"So I am tasked with proving the p series test, i.e prove that for $r \in \mathbb{R}$, if $r>1$, then the series:
$$\sum_{n=1}^{\infty}\frac{1}{n^r}$$ converges. I was given a hint on the problem, that reads: Hint: To prove convergence, use the Mean Value Theorem on $f(x) = \frac{1}{x^{r−1}}$
Doing that I saw that there exists $c\in [n,n+1]$ such that $$\frac{1}{n^{r-1}} - \frac{1}{(n+1)^{r-1}} = \frac{r-1}{c^r}$$ I do not know where to go from here. I attempted a comparison and wasted much time with $\frac{1}{n^2+n}$ but then realized that only works for $r\geq2$. A hint would be appreciated.","['derivatives', 'real-analysis', 'sequences-and-series', 'functions']"
2258364,"Can commuting matrices $X,Y$ always be written as polynomials of some matrix $A$?","Consider square matrices over a field $K$. I don't think additional assumptions about $K$ like algebraically closed or characteristic $0$ are pertinent, but feel free to make them for comfort. For any such matrix $A$, the set $K[A]$ of polynomials in $A$ is a commutative subalgebra of $M_n(K)$; the question is whether for any pair of commuting matrices $X,Y$ at least one such commutative subalgebra can be found that contains both $X$ and $Y$. I was asking myself this in connection with frequently recurring requests to completely characterise commuting pairs of matrices, like this one . While providing a useful characterisation seems impossible, a positive anwer to the current question would at least provide some answer. Note that in many rather likely situations one can in fact take $A$ to be one of the matrices $X,Y$, for instance when one of the matrices has distinct eigenvalues , or more generally if its minimal polynomial has degree $n$ (so coincides with the characteristic polynomial). However this is not always possible, as can be easily seen for instance for diagonal matrices $X=\operatorname{diag}(0,0,1)$ and $Y=\operatorname{diag}(0,1,1)$. However in that case both will be polynomials in $A=\operatorname{diag}(x,y,z)$ for any distinct values $x,y,z$ (then $K[A]$ consists of all diagonal matrices); although in the example in this answer the matrices are not both diagonalisable, an appropriate $A$ can be found there as well. I thought for some time that any maximal commutative subalgebra of $M_n(K)$ was of the form $K[A]$ (which would imply a positive answer) for some $A$ with minimal polynomial of degree$~n$, and that a positive answer to my question was in fact instrumental in proving this. However I was wrong on both counts: there exist (for $n\geq 4$) commutative subalgebras of dimension${}>n$ (whereas $\dim_KK[A]\leq n$ for all $A\in M_n(K)$) as shown in this MathOverflow answer , and I was forced to correct an anwer I gave here in the light of this; however it seems (at least in the cases I looked at) that many (all?) pairs of matrices $X,Y$ in such a subalgebra still admit a matrix $A$ (which in general is not in the subalgebra ) such that $X,Y\in K[A]$. This indicates that a positive answer to my question would not contradict the existence of such large commutative subalgebras: it would just mean that to obtain a maximal dimensional subalgebra containing $X,Y$ one should in general avoid throwing in an $A$ with $X,Y\in K[A]$. I do think these large subalgebras easily show that my question but for three commuting matrices has a negative answer. Finally I note that this other answer to the cited MO question mentions a result by Gerstenhaber that the dimension of the subalgebra generated two commuting matrices in $M_n(K)$ cannot exceed$~n$. This unfortunately does not settle my question (if $X,Y$ would generate a subalgebra of dimension${}>n$, it would have proved a negative answer); it just might be that the mentioned result is true because of the existence of $A$ (I don't have access to a proof right now, but given the formulation it seems unlikely that it was done this way). OK, I've tried to build up the suspense. Honesty demands that I say that I do know the answer to my question, since a colleague of mine provided a convincing one. I will however not give this answer right away, but post it once there has been some time for gathering answers here; who knows somebody will prove a different answer than the one I have (heaven forbid), or at least give the same answer with a different justification.","['matrices', 'abstract-algebra', 'linear-algebra']"
