question_id,title,body,tags
853490,What is the inverse of $f(x) = \sqrt{x} + 2$?,I got $$f^{-1}(x) = (x-2)^2$$ Is this answer right?,['algebra-precalculus']
853526,Definition of cluster point,"I'm studying if the book Multidimensional Real Analysis by Duistermaat and the definition of cluster point is: A point $a \in \mathbb{R}^n$ is said to be a cluster point of a subset $A$ if for every $\delta >0$ we have $B(a; \delta) \cap A \neq \emptyset$, where $B(a; \delta) = \{x \in \mathbb{R}^n \;|\; ||x-a||<\delta\}$ But in many other books and internet says that: A point $a \in \mathbb{R}^n$ is said to be a cluster point of a subset $A$ if for every $\delta >0$ we have $(B(a; \delta)-{a}) \cap A \neq \emptyset$, where $B(a; \delta) = \{x \in \mathbb{R}^n \;|\; ||x-a||<\delta\}$ It's easy to see that it isn't equivalent definitions. For example,
by the first definition, the point $0$ is a cluster point of the set $S = \{0\}\cup[1,2]$, but it is not by the second one. Which definition is the usual?","['multivariable-calculus', 'real-analysis']"
853528,Find if a point lies in all given circles,"I have a set of n given circles. I want to find that if there exists at least one point that lies in all of the given circles. Is there a method to do so? I can definitely find a set of points and then iterate over them, but all I want is to find if a possibility exists, I have no use of the exact point(s). PS: Circles can be of any radii","['geometry', 'circles', 'algorithms']"
853546,Efficient polynomial irreducibility test over finite fields (analogue of Pocklington–Lehmer integer primality test),We've got Fermat's primality test to test if a number is probable prime. Is there an analogous test for polynomials in $\mathbb{F}_{p^n}[X]$ and irreducibility?,"['irreducible-polynomials', 'ring-theory', 'finite-fields', 'abstract-algebra', 'primality-test']"
853577,Maximal dimension and diagonalisable matrices,"What is the maximmal dimension of a vector subspace of $\mathcal{M}_n(\Bbb{R})$ formed by diagonalisable matrices $\mathcal{D}_n(\Bbb{R})$? Attempt : Let $\mathcal{S}_n(\Bbb{R})$ the set of symmetric matrices, wich is a subspace of $\mathcal{D}_n(\Bbb{R})$ of dimension $\frac{n(n+1)}{2}$ and denote $\mathcal{T}_n(\Bbb{R})$ the set of upper triangular matrice with zero diagonal , wich is a subspace of $\mathcal{D}_n(\Bbb{R})$ of dimension $\frac{n(n-1)}{2}$. Then $\mathcal{S}_n(\Bbb{R})$ and $\mathcal{M}_n(\Bbb{R})$ are in direct sum. How can I continue ? NB: I am also curious if we replace $\Bbb{R}$ by $\Bbb{C}$ ?","['matrices', 'linear-algebra']"
853581,Proving a property of hitting times of a simple random walk on $\mathbb{Z}$,"I'm reading the course notes of a probability course about martingales currently and I'm trying to solve some of the exercises, however I'm very much stuck with the following exercise: Let $\left\{ X_{n}\right\} _{n=1}^{\infty}$
  be a simple random walk on $\mathbb{Z}$
  started at $X_{0}=a$
 . Given $b\in\mathbb{Z}$
  denote by $T_{b}$ the first hitting time of $b$
 , show that $\mathbb{E}_{a}\left[T_{b}|\, T_{b}<T_{0}\right]=\frac{b^{2}-a^{2}}{3}$
 . Hint: Show that $M_{n}:=X_{n}^{3}-3nX_{n}$  is a martingale  and use the fact that $\left|M_{\min\left(T_{b},n\right)}\right|\leq b^{3}+3bT_{b}$ I've shown that indeed that is a martingale but I have no idea how to proceed, help would be appreciated. Thanks!","['stochastic-processes', 'random-walk', 'martingales', 'probability-theory', 'probability']"
853592,"Rolfsen exercise, chord theorem","Here's a problem from Rolfsen's Knots and Links that has me scratching my head: Show that there is always a counterexample to the ""chord theorem"" if $n$ is not an integer. [Hint: In attempting to draw a counterexample, try holding two pencils at once.]"" Here's the ""chord theorem"": If $C$ is a line segment of length $|C|$ with endpoints in a path-connected subspace $X \subset \mathbb{R}^2$, then for each $n \in \mathbb{Z}_{>0}$ there is a line segment parallel to $C$ of length $|C|/n$. Any hints would be greatly appreciated. My thoughts: I can't figure out how to make the ""pencil"" hint work. I'm currently trying to prove that if $\alpha \in \mathbb{R}_{>0}$ is not of the form $1/n$, then there exists a continuous function $f:[0,1]\to \mathbb{R}$ such that $f(0)=f(1)=0$ and $f(x) \neq f(x-\alpha)$ for all $x \in [\alpha,1]$. Then the graph of this function will be a ""counterexample"". Update: With the help of everybody's comments below, I've gotten most of the way to an answer, posted below.","['general-topology', 'geometry', 'plane-curves', 'knot-theory']"
853619,Sufficient conditions for closed infinite pasting lemma,"It's well known that the pasting lemma for infinitely many closed sets is false. It's reasonably easy to cook up examples such that for $X = \bigcup X_i$ with $X_i$ closed in $X$ such that $\left. f\right|_{X_i}$ is continuous for all $i$ but $f$ is not continuous. In Munkres book he places an additional condition in order to formulate an infinite pasting lemma for closed sets, that the collection $\{X_i\}$ be locally finite. What are other ""nice"" sufficient conditions that force the infinite closed pasting lemma to be true, or is this in some way ""minimal""? To restrict the problem a little more we can let $X$ be a metric space since that's the context I'm working in.","['general-topology', 'metric-spaces', 'continuity', 'soft-question']"
853622,"$n$ players roll a die. For every pair rolling the same number, the group scores that number. Find the variance of the total score.","This is problem 3.3.3.(b) in Probability and Random Processes by Grimmett and Stirzaker. Here's my attempted solution: We introduce the random variables $\{X_{ij}\}$, denoting the scores of each pair (player $i$ and player $j$), and the total score $Y = \sum_{i<j}X_{ij}$. We calculate the expected value of $Y$: 
$$ 
\mathbb{E}(Y) = \sum_{i<j}\mathbb{E}(X_{ij}) = {n\choose{2}}\mathbb{E}(X_{12}) =  
\frac{7}{12}{n\choose{2}}.
$$
Now, let's determine the variance of $Y$:
$$
\mathrm{var}(Y) = \mathbb{E}(Y^2) - \mathbb{E}(Y)^2 
= \mathbb{E} \left\{ \left( \sum_{i<j}X_{ij} \right)^2 \right\} - \mathbb{E}(Y)^2
= \mathbb{E} \left( \sum_{i<j,\space k<l}X_{ij}X_{kl} \right) - \mathbb{E}(Y)^2 .
$$
Further, we look closer at the sum 
$\sum_{i<j,\space k<l}X_{ij}X_{kl}$.
Here $X_{ij}$ and $X_{kl}$ are independent whenever $i\neq k$, $i\neq l$, $j\neq k$ and $j\neq l$. When both $i = k$ and $j = l$ we get the random variables $\{X_{ij}^2\}_{i<j}$, each having expected value 
$$
\mathbb{E}(X_{ij}^2) = \mathbb{E}(X_{12}^2) = \sum_{m=1}^6\frac{m^2}{36}=\frac{91}{36}.
$$
 When only three of the four inequalities above hold we get a random variable on one of the following forms: $X_{ij}X_{jl}$, $X_{ij}X_{il}$, $X_{ij}X_{ki}$ or $X_{ij}X_{kj}$. These have expected value 
$$
\mathbb{E}(X_{ij}X_{il}) = \mathbb{E}(X_{12}X_{13}) 
= \sum_{m=1}^6\frac{m^2}{216}=\frac{91}{216}.
$$
We note that each triple $\{a,b,c\}$, such that $1\leq a < b < c \leq n$, is associated to the following six terms $X_{ab}X_{ac}$, $X_{ac}X_{ab}$, $X_{ab}X_{bc}$, $X_{bc}X_{ab}$, $X_{ac}X_{bc}$, $X_{bc}X_{ac}$, all with the above expected value. Clearly there are ${n\choose{3}}$ such triples. This gives us the following:
$$
\mathrm{var}(Y) = 
\mathbb{E} \left( \sum_{i<j,\space k<l}X_{ij}X_{kl} \right) - \mathbb{E}(Y)^2
$$
$$
= {n\choose{2}}\mathbb{E}(X_{12}^2) + 
6{n\choose{3}}\mathbb{E}(X_{12}X_{13})+
\left\{{n\choose{2}}^2 - {n\choose{2}} - 6{n\choose{3}} \right\}\mathbb{E}(X_{12})^2 - \left\{{n\choose{2}}\mathbb{E}(X_{12})\right\}^2 
$$
$$
= \frac{35}{16}{n\choose{2}} + \frac{35}{72}{n\choose{3}}
$$ The book of solutions gives the answer $\frac{35}{16}{n\choose{2}} + \frac{35}{432}{n\choose{3}}$ though, which is what I would get if each triple $\{a,b,c\}$ only was associated with one term $X_{ab}X_{bc}$. So I guess I'm asking why(/if) that is the case!","['probability', 'expectation']"
853638,What is the limit of $\log_k(k^a + k^b)$ for $k \to +\infty$?,"I'm not very good with analysis (I never studied it) but because of my ""work"" on other topics of mathematics I came to this problem. $$\lim_{k \to +\infty }\log_k(k^a + k^b)=\max(a,b)$$ I'm sure that this is really ""reasonable"" because I tryed to graph it for really huge values of $k$ ... but ""reasonable"" is not enough in mathematics: I'd like to prve this.
 So I'm courious to know how one should go to prove it in a formal way ... if it is true (I hope). PS: I know nothing about Limits and their rules","['exponentiation', 'logarithms', 'proof-explanation', 'limits']"
853651,"How to prove that $F(x,y)=(f(x)h(y),g(y))$ is a diffeomorphism?","Let $F:\mathbb{R}^2\to\mathbb{R}^2$ be given by $F(x,y)=(f(x)h(y),g(y))$, where $h:\mathbb{R}\to\mathbb{R}$ is a diferentiable function and $f,g:\mathbb{R}\to\mathbb{R}$ are diffeomorphisms. Definition: a diffeomorphism is a bijective differentiable mapping whose inverse is also differentiable. The problem is to show that the following sentences are equivalent. (a) $F$ is a diffeomorphism. (b) $0\notin h(\mathbb{R})$. If $f,g,h$ are $C^1$ functions, then $F$ is a $C^1$ function and thus we can use the following fact. Theorem: Let $U\subset\mathbb{R}^m$ be an open set and $F:U\to\mathbb{R}^m$ a $C^1$ function. Then, $F$ is a local diffeomorphism if, and only if, $\det J_F(x)\neq 0$ for all $x\in U$. In that case, I think the solution can be done as below. (a) $\Rightarrow$ (b) Since $F$ is a diffeomorphism, it's a local diffeomorphism. Since $F$ is $C^1$, it follows from theorem above that $\det J_F(x,y)\neq 0$ for all $(x,y)\in\mathbb{R}^2$. But 
$$\det J_F(x,y)\neq 0\quad\Rightarrow\quad h(y)f'(x)g'(y)\neq0\quad\Rightarrow\quad h(y)\neq 0$$
so that $h(y)\neq 0$ for all $y\in\mathbb{R}$, that is, $0\notin h(\mathbb{R})$. (b) $\Rightarrow$ (a) Since $f,g$ are diffeomorphisms, $f'(x)g'(y)\neq 0$ for all $(x,y)\in\mathbb{R}^2$. Since $0\notin h(\mathbb{R}^2)$, it follows that
$\det J_F(x,y)=h(y)f'(x)g'(y)\neq0$ for all $(x,y)\in\mathbb{R}^2$. As $F$ is $C^1$, we conclude from theorem above that $F$ is a local diffeomorphism. But we can prove that $F$ is bijective (because $f,g$ are bijective). So, $F$ is indeed a diffeomorphism. However, the hypothesis $f,g,h\in C^1$ is not a part of the exercise. So, how can we solve it without that hypothesis? Thanks.","['multivariable-calculus', 'analysis']"
853690,How is addition different than multiplication?,"Is there a fundamental difference in the things we call multiplication and those we call addition? In a field, both binary operations obey exactly the same rules (commutativity, associativity, identity element, and inverse element [actually this one is the same for all but 1 element: namely $0$]).  In a ring, some of the multiplicative rules of a field are relaxed, but it seems like we could just as easily have relaxed the additive rules. It seems that even the distributive law could also be defined so that addition distributes over multiplication (opposite to the normal way), and thus is only a distinguishing property -- when it even applies -- because we've decided it should be. Other than the fact that often we require both operations on whatever set of ""numbers"" we're considering, is there some property of addition that is never shared by multiplication (and vice versa), no matter which generalization of each we choose?  That is, can we define the necessary and sufficient conditions for a binary operation to be called ""addition"" or ""multiplication""?","['binary-operations', 'soft-question', 'abstract-algebra']"
853696,trace of product of a diagonal and a matrix,"I would like to know if anything can be said about the trace of a product of two matrices, where one matrix is a diagonal matrix, i.e.,
$$\text{trace}(DA)=...$$
Are there some bounds in terms of $\text{trace}(D)$ and $\text{trace}(A)$ ?","['trace', 'matrices']"
853723,"Let $f$ be continuous and $U \subset \mathbb{R}^n$ open, if $f: U \rightarrow \mathbb{R}^m $ is injective then $n \leq m$?",I had intended to restrict the image then $f:U \rightarrow f(U) \subset \mathbb{R}^m $ is bijective. Therefore $\dim f(U) = n \leq m$. That's right?,"['calculus', 'functions', 'analysis']"
853745,Solution check for counting in a list,"This problem involves lists made from the letters T,H,E,O,R,Y, with repetition allowed. How many 4-letter lists are there that don’t begin with T, or don’t end in Y ? Just want to make sure my solution is right and my logic isn't flawed. My solution: A = 4 letter lists that don't begin with T B = 4 letter lists that dont end in Y $|A| = 5 * 6 * 6 * 6 = 1080$ $|B| = 6 * 6 * 6 * 5 = 1080$ $|A \cup B | = 1080 + 1080 = 2160$",['combinatorics']
853764,Estimating the sum of a series ($\ell^1$ norm) in terms of two weighted $\ell^2$ norms,"Does there exist a $C > 0$ such that 
$$
\sum_{n \geq 1} a_n
\leq C 
\left( \sum_{n \geq 1} 2^n a_n^2 \right)^{1/4}
\left( \sum_{n \geq 1} 2^{-n} a_n^2 \right)^{1/4}
$$
for all $a_n \geq 0$ with finite rhs? Progress . No single $\{a_n\}_n$ can be a counterexample, because $\sum_{n\geq1} 2^n a_n^2 < \infty$ implies $a_n^2 = O(2^{-n})$, from which the lhs is finite. The sharp value of $C$ for sequences of the form $a_n = 2^{-\delta n}$ with $\delta > 1/2$ is $C = (71 + 17\sqrt{17})^{1/4} / (2\sqrt{2}) \approx 2.20457$. This is to say that $C > 1$, if it exists.","['inequality', 'normed-spaces', 'sequences-and-series', 'functional-analysis']"
853787,Analytic Vectors (Nelson's Theorem),Is there a (simple) proof for Nelson's theorem that a symmetric operator is essentially selfadjoint if it contains a dense subset of analytic vectors?,"['operator-theory', 'operator-algebras', 'functional-analysis']"
853788,What is the proper definition of cylinder sets?,"in class we defined the terminal $\sigma$-algebra for a sequence of random variables $(X_i)$ with $X_i:\Omega \rightarrow \mathbb{R}$ as $G_{\infty}:=\bigcap_i G_i$, with $G_i:=\sigma(X_i,X_{i+1},...)$. The question I asked myself was what the proper definition of $\sigma(X_i,X_{i+1},...)$ is? I know what it is, if we are only dealing with finitely many functions(random variables). My lecturer told me that the proper definition involves cylinder sets, where you would only have to look at a finite set of these random variables. Actually these cylinder sets are supposed to 'create' this sigma-algebra. Unfortunately, I could not find a proper definition of cylinder set in this context. I found only one that involves projections. Could anybody here help me making sense out of this hint?","['probability-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
853808,Limit of a Rational Trigonometric Function $\lim_{x \to 0} \frac{\sin5x}{\sin4x}$,"When solving a trigonometric limit such as: $$\lim_{x \to 0} \frac{\sin(5x)}{\sin(4x)}$$ we rework the equation to an equivalent for to fit the limit of sine ""rule"": $$\lim_{x \to 0}\frac{\sin(x)}{x}=1$$ so, we move forward in such a manner as follows: $$=\lim_{x \to 0} \frac{\frac{5\sin(5x)}{5x}}{\frac{4\sin(4x)}{4x}}$$ $$=\frac{5}{4}\lim_{x \to 0} \frac{\frac{\sin(5x)}{5x}}{\frac{\sin(4x)}{4x}}$$ $$=\frac{5}{4}\cdot\frac{1}{1}$$
$$L=\frac{5}{4}$$ From that mindset, I am trying to find this trigonometric limit: $$\lim_{x\to 2} \frac{\cos(x-2)-1}{x^{2}+x-6}$$ I know the Limit ""rule"" for cosine is: $$\lim_{x\to 0} \frac{\cos(x)-1}{x}=0$$ If you use direct substitution in the original function you end up with an equation that is same in value to the rule presented. So, from that I am assuming that the answer is $0$. I am just trying to prove that in a step-by-step manner as I did with the sine limit. P.S. I searched through many many pages of questions and didn't find something that helped. So, if I am repeating a question, I apologize that I missed it. Thanks for the help!","['trigonometry', 'calculus', 'limits']"
853813,Nested radicals and n-th roots,"There are many beautiful infinite radical equations,
some relatively straightforward, some much more subtle:
$$
x = \sqrt{ x \sqrt{ x \sqrt{ x \sqrt{ \cdots } } } }
$$
$$
\sqrt{2} = \sqrt{ 2/2 + \sqrt{ 2/2^2 + \sqrt{ 2/2^4 + + \sqrt{ 2/2^8 + \sqrt{ \cdots}}}}}
$$
$$
3 = \sqrt{1 + 2\sqrt{1 + 3\sqrt{ 1 + 4\sqrt{ \cdots }}}}
$$ But I have seen far fewer analogous equations for $n$-roots.
Here is one:
$$
2 = \sqrt[3]{6 + \sqrt[3]{6 + \sqrt[3]{6 + \sqrt[3]{\cdots}}}}
$$ My question is: Q . Are there truly ""more"" beautiful infinite radical equations,
  or is it just our natural gravitation toward the simpler square-root equations that
  leads to collections emphasizing radicals? I am aware this question is vague, but perhaps some nevertheless have insights.","['radicals', 'nested-radicals', 'algebra-precalculus']"
853819,Proving $f'(x)<0$ using sequential criterion of limit.,"I'm trying to prove the following: Let $f:\mathbb R\rightarrow\mathbb R$ be a function twice differentiable such that $\forall x\in \mathbb R , f(x)>0$ $\forall x\in \mathbb R , f''(x)>0$ $\lim_{x\to +\infty}f(x)=0$ Prove that for all $M\in \mathbb R$ there exists $x>M$ such that $f'(x)<0$ The only idea I can come up with is by contradiction. Suppose that there exists $M\in \mathbb R$ such that for all $x>M$, $f'(x)\geq 0$. This implies that $f(x)$ is increasing. Let $x_n$ be a sequence such that $(x_n)\to\infty$. Then $f(x_n)$  is increasing. There are two possibilities: $f(x_n)$ is bounded or is not bounded. If $f(x_n)$ is bounded, then $f(x_n)$ converges to some real number greater than $0$ (it can't converge to $0$ because $f(x_n)$ is increasing and $f(x_n)>0$ by 1.)
 wich is a contradiction with 3. If $f(x_n)$ is not bounded, then $f(x_n)\rightarrow +\infty$ which is a contradiction with 3. I would like to know if the ideas are correct and if I could approach this other ways. Thank you in advance!","['derivatives', 'real-analysis']"
853821,Where did I go wrong on trying to solve this question on an exam?,"I took an exam yesterday, and I almost for a fact know I got this question wrong. I couldn't figure it out, since my answer wasn't an answer choice, so I ended up guessing. An explanation of what I did wrong and how to properly solve this would be great appreciated!
The question: 
Evaluate $f'(\frac{\pi}{6})$, where $f(x)=\tan^{-1}(\sin 2x)$. So these are the steps that I did. First using chain rule$$\frac{d}{dx}\tan^{-1}(\sin 2x)=\frac{1}{1+(\sin 2x)^2}\cdot\frac{d}{dx}\sin(2x)$$
$$\frac{d}{dx}\sin(2x)=\cos(2x)\cdot2$$so $$\frac{d}{dx}\tan^{-1}(\sin 2x)=\frac{1}{1+(\sin 2x)^2}*2\cos(2x)$$
Plugging in $(\frac{\pi}{6})$ I ended with $$$$
$$\frac{d}{dx}\tan^{-1}\left(\sin\frac{\pi}{3}\right)=\frac{1}{1+(\sin\frac{\pi}{3})^2}\cdot2\cos\left(\frac{\pi}{3}\right)$$I ended with some answer that didn't match up with any of the answer choices, did I go about solving this wrong? If so, how would I solve it correctly?  Thanks in advance.","['trigonometry', 'calculus', 'derivatives']"
853833,Linearly Independency of functions,"Show if the functions are linearly independent $x(t)=3$, $y(t)=3\sin^2t$, $z(t)= 4\cos^2t$ How can i show this?","['linear-algebra', 'ordinary-differential-equations']"
853836,Monotonicity Question in Enderton's text on Set Theory,"I am struggling to begin solving the following question in Enderton's textbook on set-theory : Assume that $F: P(A) \rightarrow P(A)$ and that $F$ has the monotonicity property: $X \subseteq Y \subseteq A \ \implies \ F(X) \subseteq F(Y)$. Define: $B = \bigcap \{ X \subseteq A \ | \ F(X) \subseteq X\}$ and $C = \bigcup  \{ X \subseteq A \ | \ X \subseteq F(X)\}$. (a) Show that $F(B) = B$ and $F(C) = C$. (b) Show that if $F(X) = X$, then $B \subseteq X \subseteq C$. \ Something I have tried so far is to assume that $x \in F(B)$ in order to show that $x \in B$. Beginning with this, I get $x\in$ ran $F$, and so $x = X$ for some $X \subseteq A$.  I also have, $F(B) \subseteq$ ran $F$ however I'm unsure how to proceed from here. Any advice anyone can provide would be much appreciated. Thank you in advance.",['elementary-set-theory']
853861,Is there a 'conjugation' on every algebraically closed field?,"Let $K$ be an algebraically closed field. Then the polynomial $x^2+1\in K[x]$ has two distinct roots (when $K$ doesn't have characteristic 2). Let's suggestively call them $i$ and $-i$. Does there exist an automorphism $\phi$ of $K$ such that $\phi(i)=-i$? This is something I've been wondering about for a while. I'm asking this question here because I, unfortunately, have very little background in field theory and have no clue on how to approach this problem. Any help is appreciated.","['abstract-algebra', 'field-theory']"
853877,Please help with absolute value $|x^2 - 3x| = 28$,"Just a question about solving an absolute value equation: $$|x^2 - 3x| = 28$$ Do I just solve this as if the absolute value brackets weren't even there? $$x^2 - 3x - 28 = 0$$ $$(x+4)(x-7) = 0$$ So $x=-4$ ; $x=7$ But I'm still confused why the absolute value signs would be there in the first place :( EDIT: So, I've found that $x=7, x=4, x=-4$ Just not $100\%$ now if they are correct as I've had a look at a few online abs value calculators to check my answers and only $x=-4$ and $x=7$ come up as answers. Am I correct? EDIT 2 Ok, $x=4$ can't work out. I found it by:
\begin{align*}
x^2 - 3x & = 28\\
x^2 - 3x - 28 & = 0\\
(x-7)(x-4) & = 0
\end{align*}
My answers here are $7$ and $4$. So I'm lost as to why I got that answer! :(","['absolute-value', 'algebra-precalculus']"
853924,Give example of a series $\sum a_n$ such that the series is conditionally convergent. and $\sum na_n$ is convergent,"I tried all the conditionally convergent series I know, I found $\sum na_n$ to be diverging for all of them. But I am sure the question is correct","['examples-counterexamples', 'sequences-and-series', 'calculus', 'algebra-precalculus']"
853959,Difference between abstract algebra and universal algebra,"Wikipedia give this answer ""Universal algebra (sometimes called general algebra) is the field of mathematics that studies algebraic structures themselves, not examples (""models"") of algebraic structures. For instance, rather than take particular groups as the object of study, in universal algebra one takes ""the theory of groups"" as an object of study."" Can someone please explain the difference in more specific terms.","['abstract-algebra', 'universal-algebra']"
853992,"Max. and Min. value of $|z|$ in $\left|z+\frac{2}{z}\right| = 2\,$","If $z$ is a complex no. such that $\displaystyle \left|z+\frac{2}{z}\right| = 2\,$ Then find max. and min. value of $\left|z\right|$. $\bf{My\; Try:}$ Given $\displaystyle \left|z+\frac{2}{z}\right| = 2\Rightarrow  \left|z+\frac{2}{z}\right|^2 = 2^2=4$. So $\displaystyle \left(z+\frac{2}{z}\right)\cdot \left(\bar{z}+\frac{2}{\bar{z}}\right) = 4\Rightarrow \left|z\right|^2+2\left(\frac{z}{\bar{z}}+\frac{\bar{z}}{z}\right)+\frac{1}{|z|^2} = 4$. Now how can I find the max. and min. values of $|z|$? Help me please. Thanks",['algebra-precalculus']
854001,Non-finitely generated groups with $|\text{Aut}(G)| = p$,"It is a fun exercise to prove that if $G$ is finitely generated, and $|\text{Aut}(G)| = p$ for some prime $p$, then $G$ is one of $\Bbb Z_3, \Bbb Z_6, \Bbb Z$, or $\Bbb Z \times \Bbb Z_2$. The finitely generated is essential (at least, in my proof), since the very end reduces to doing casework with the structure theorem on finitely generated abelian groups. But what about the more general case? Are there any non-finitely generated groups $G$ with $|\text{Aut}(G)| = p$? Some immediate comments: $G$ must still be abelian (because $\text{Inn}(G)$ is cyclic iff trivial); $p$ must be 2 (because being abelian means implies $a \mapsto a^{-1}$ is an automorphism, and this map is an involution, so $2\mid p$); and $G$ must be either indecomposable or an indecomposable times $\Bbb Z_2$ (because if $G = A \times B$, then $\text{Aut}(G) \times \text{Aut}(G)$ is a subgroup of $\text{Aut}(G)$; and the only groups with trivial automorphism group are the trivial group and $\Bbb Z_2$; and you can only stick one copy of $\Bbb Z_2$ in there, since otherwise there's an extra automorphism given by swapping two copies of $\Bbb Z_2$). But that's all I know.","['group-theory', 'abstract-algebra']"
854039,"Biology: How to find the probability of randomly generating multiple, sequentially identical sets","If I randomly generate a substring (example ""ATGCAGC"") with equal probability (1/X where X=4) for each digit with length (L) digits: What is the formula for finding the probability (P) of randomly generating that sequence (T) times, given a total string length (N)? Example:
Given ""ATGCAGC"" string length L=7, number of possible characters X=4 with equal probability of being randomly generated 1/X. In a case where N characters are generated, what is the probability that an exact substring with length L will occur T times? If I have randomly, sequentially generated N=7000 characters, what is the probability that any exact substring length L=7 ""ATGCAGC"" will occur T=2,3,4... times? P is my dependent variable. L, T, N, X are independent. In terms of dice: Example: If I sequentially roll a X=6 sided die N=7000 times: What is the P=probability I will roll the die sequentially the same (1,4,6,5,3,2,3) with sequence length L=7 for T=2 sequentially identical occurrences in the N=7000 sequential rolls of a single die? What is the probability in 7000 rolls I will have any 2 runs of 7 throws that have an exact sequential match? Example: (1,4,6,5,3,2,3 on rolls 201-207)  and (1,4,6,5,3,2,3) on rolls 5001-5007. It could be any number of (T) occurrences, on any roll numbers in (N) total die rolls. I am specifically solving for the probability, given any values for the independent variables. Overlapping or non-overlapping substrings or both are great. My question is related to ( How many times will a consecutive sequence of throws randomly appear if I throw a four-sided die N times? )","['dice', 'probability', 'biology']"
854061,Prove that $1 + \cos\alpha + \cos\beta + \cos\gamma = 0$,If $\alpha + \beta + \gamma = \pi $ and $\tan(\frac{-\alpha + \beta + \gamma}4)\tan(\frac{\alpha - \beta + \gamma}4)\tan(\frac{\alpha + \beta - \gamma}4) = 1$ Then prove that: $1 + \cos\alpha + \cos\beta + \cos\gamma = 0$. I have no idea how to go about this. Please help.,['trigonometry']
854063,Probability of $\alpha\beta\gamma=\gamma\beta\alpha$ for random permutations of a finite set?,"Following up on my previous question Probability that two random permutations of an $n$-set commute? , here's a related question for three elements. Q : If $\alpha,\beta,\gamma$ are chosen uniformly at random from the symmetric group on $n$ elements, what is the probability that $\alpha\beta\gamma=\gamma\beta\alpha$? For $n \leq 6$ we have the striking property $$\mathrm{Pr}[\alpha\beta=\beta\alpha]=\mathrm{Pr}[\alpha\beta\gamma=\gamma\beta\alpha].$$ as illustrated in the following table: \begin{array}{r|rr}
n & \mathrm{Pr}[\alpha\beta\gamma=\gamma\beta\alpha] & \mathrm{Pr}[\alpha\beta=\beta\alpha] \\
\hline
1 & 1 & 1 \\
2 & 1 & 1  \\
3 & 108\ /\ 3!^3 = 0.5 & 18\ /\ 3!^2 = 0.5\\
4 & 2880\ /\ 4!^3 \simeq 0.208 & 120\ /\ 4!^2 \simeq 0.208  \\
5 & 100800\ /\ 5!^3 \simeq 0.058 & 840\ /\ 5!^2 \simeq 0.058 \\
6 & 5702400\ /\ 6!^3 \simeq 0.015 & 7920\ /\ 6!^2 \simeq 0.015 \\
\end{array} computed using GAP .  Does this hold in general? Comments: The tools used in the previous question (e.g. the centralizer subgroup) do not seem to be usable here.  (Although, maybe I'm missing something important.) This doesn't seem to generalize: e.g. in $S_3$, we have $\mathrm{Pr}[\alpha\beta\gamma\delta=\delta\gamma\beta\alpha] \simeq 0.103$ which doesn't match. None of the permutations $(13),(23),(12) \in S_3$ commute, but $(13)(23)(12)=(23)=(12)(23)(13)$.","['permutations', 'group-theory', 'finite-groups', 'probability']"
854066,"Does there exist a $(m,n)\in\mathbb N$ such that $m^3-2^n=3$?","Question : Does there exist a $(m,n)\in\mathbb N$ such that $m^3-2^n=3$? I know that there is no $(m,n)\in\mathbb N$ such that $m^3-2^n=1$ and that there is no $(m,n)\in\mathbb N$ such that $m^3-2^n=2$. However, I don't have any good idea to solve the question. I'm afraid that it may be a famous unsolved question. I would like to know any relevant references.",['number-theory']
854079,$|A|=\mathcal c \ \ |B|=\aleph_0 \ \ A\cap B=\emptyset$ prove that $ |A\cup B|=\mathcal c$,"Let $|A|=\mathcal c, \ |B|=\aleph_0, \ A\cap B=\emptyset,$ Prove that $ |A\cup B|=\mathcal c$ So $|A\cup B|=|A|+|B|$ but this just leads to cardinal arithmetic which I don't think is the right approach. Maybe embedding could work ? There has to be a 1-1 function from $A$ to $(0,1)$ and from $B$ to the naturals, so $A\cup B = \{x\in [0,1], y | x\in \mathbb R, y\in \mathbb N\}$ and now it's enough to know that for all $x$ the cardinality of this set is $\mathcal c$.","['cardinals', 'elementary-set-theory']"
854112,"Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,\frac{t}{d})$, where $F$ is the Gauss' hypergeometric function","What is the Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,\frac{t}{d})$, where $\gamma >0 $ and $F$ is the Gauss' hypergeometric function. Note that I have the Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,-t)$. Thanks!","['improper-integrals', 'laplace-transform', 'integration', 'definite-integrals', 'probability']"
854144,$SU(2)$ as an algebraic group,The $\mathbb R$-valued points of the algebraic group $SU(2)$ can be identified with the real 3-sphere.  But how does one define $SU(2)$ over the base field $\mathbb R$ as an algebraic group?  What are its defining equations?  What is the Hopf algebra structure on its coordinate ring?,"['algebraic-geometry', 'algebraic-groups']"
854154,"When is $R \, A^{-1} \, R^t$ invertible?","In the context of a Gaussian model, I came across a matrix product $R \, A^{-1} \, R^t$ where $R$ is a $m \times n$ rectangular matrix and as implied $A$ is $n \times n$ and invertible. On which properties of $R$ does the existence of $(R \, A^{-1} \, R^t)^{-1}$ depend?","['matrices', 'linear-algebra', 'inverse-problems']"
854156,Prove that $\operatorname{ran} f \subseteq \operatorname{dom} g \implies\operatorname{dom} (g \circ f)=\operatorname{dom} f$,"Some preliminaries: A function $f$ is a binary relation such that $(x,y_1) \in f$ and $(x, y_2) \in f$ implies $y_1 = y_2$. $\operatorname{ran} f = \{y: \exists x$ such that $(x,y) \in f\}$ $\operatorname{dom} f = \{x: \exists y$ such that $(x, y) \in f\}$ $g \circ f = \{(x,y): \exists z$ such that $(x,z) \in f$ and $(z, y) \in g\}$ Can someone verify my proof? Prove that $\operatorname{ran} f \subseteq \operatorname{dom} g \implies\operatorname{dom} (g \circ f)=\operatorname{dom} f$ Let $x \in \operatorname{dom} f$. Then, $\exists y$ such that $(x,y) \in f$ Since $\operatorname{ran} f \subseteq \operatorname{dom} g$, we have $y \in \operatorname{dom} g$ But then, $\exists z$ such that $(y,z) \in g$ Since $(x,y) \in f$ and $y,z \in g$, $(x,z) \in g \circ f$ But then, $x \in \operatorname{dom} g \circ f$ So, $\operatorname{dom} f \subseteq \operatorname{dom} g \circ f$ Now, suppose $x \in \operatorname{dom} g \circ f$ Then, $\exists y$ such that $(x,y) \in g \circ f$. So, $\exists z$ such that $(x, z) \in f$ and $(z,y) \in g$ But then, $x \in \operatorname{dom} f$, since $(x,z) \in f$ So, $\operatorname{dom} g \circ f \subseteq \operatorname{dom} f$ Therefore, $\operatorname{dom} f = \operatorname{dom} g \circ f$","['elementary-set-theory', 'proof-verification']"
854162,How to prove $\left\lfloor\frac{\sigma{(n-1)}+1}{2}\right\rfloor\le f(n)<\left\lfloor\frac{\sigma{(n-1)}+1}{2}\right\rfloor+n$,"Question: let $x_{1},x_{2},\cdots,x_{n}$ be such that
  $$n\ge 3,x_{1}\le x_{2}\le\cdots \le x_{n},$$
  $$x_{1}x_{2}x_{3}\cdots x_{n}=x_{1}+x_{2}+\cdots +x_{n}.$$ Let the number of ordered pairs of postive integers $(x_{1},x_{2},\cdots,x_{n})$ be $f(n)$. Show that:  $$\left\lfloor{\dfrac{\sigma{(n-1)}+1}{2}}\right\rfloor\le f(n)<\left\lfloor{\dfrac{\sigma{(n-1)}+1}{2}}\right\rfloor +n$$ where $\lfloor{x}\rfloor$ is the largest integer not greater than $x$ and $\sigma(n)$ is the number of (positive) divisors of n.",['number-theory']
854180,Determinant of a non-square matrix,"I wrote an answer to this question based on determinants, but subsequently deleted it because the OP is interested in non-square matrices, which effectively blocks the use of determinants and thereby undermined the entire answer. However, it can be salvaged if there exists a function $\det$ defined on all real-valued matrices (not just the square ones) having the following properties. $\det$ is real-valued $\det$ has its usual value for square matrices $\det(AB)$ always equals $\det(A)\det(B)$ whenever the product $AB$ is defined. $\det(A) \neq 0$ iff $\det(A^\top) \neq 0$ Does such a function exist?","['matrices', 'linear-algebra', 'determinant', 'definition']"
854196,Gamma distribution Norming constant for extreme minima,"the norming constants for extreme maxima of Gamma distribution is known and is give in link.springer.com/article/10.1007/s10687-010-0125-3. I would like to know is there reference or paper that states the norming constant for the extreme minima. The exact problem is stated below: Let the random variable $Y_n$ be $Y_n=max(a_1,a_{2},\cdots, a_n)$ and $X_{n}$ be $X_n=min(a_1,a_{2},\cdots, a_n)$, where $a_i$s are Gamma random variables. It is well-known in extreme value theory that the CDF of $X_n$ and $Y_n$ converges (in distribution) as follows: $$\lim_{n\rightarrow \infty}~~~Pr\left(\frac{Y_n-\mu}{\sigma}\leq x\right)\rightarrow G_M(x)~~~~~~~~~~(P1)$$ $$\lim_{n\rightarrow \infty}~~~Pr\left(\frac{X_n-\mu_{1}}{\sigma_{1}}\leq x\right)\rightarrow W_m(x)~~~~~~~~~~(P2)$$ where $G_M(x)$ is the Gumbel and $W_m(x)$ is the Weibull CDFs for maxima and minima respectively and the values of $\mu$ and $\sigma$ can be given explicitly (see for example link.springer.com/article/10.1007/s10687-010-0125-3). My question is: Is there a literature that provides the norming constants $\mu_1$ and $\sigma_1$ for the minima?  will appreciate your answer and possible references.","['statistics', 'probability-distributions', 'probability', 'order-statistics']"
854200,"What do mathematicians mean by ""analytical solution of an equation""?","Given a PDE equations of the form: $\dfrac{\partial}{\partial t} u(t,x) = \left(\hat{L}+\hat{N_u}\right)u(t,x)    \;\;\;\;\;\;\hspace{10mm}(**)$ where $\hat{L}$ is a linear operator  and  $\hat{N_u}$ is a non linear operator what does mathematicians mean by: 1) ""eq ($**$) has a general exact solution""; 2) ""eq ($**$) has not a general exact solution, some particular solutions are exact other has to be found numerically"" 3) ""eq ($**$) has no exact solution, it can by solved in an approximated way using numerical methods"" Some examples: case 1)
the KdV equation $\dfrac{\partial u}{\partial t} +6 u \dfrac{\partial u}{\partial x} + \dfrac{\partial^3 u}{\partial x^3}=0$ admits a general exact solution via the inverse scattering transform .
(And in this case I have not understood why there is a substantial literature about KdV numerical solution if it admits an exact general solution). case 2)
The three body problem is famous for not admitting an exact general solution but
here http://www.physics.buffalo.edu/phy410-505-2009/topic3/lec-3-4.pdf I have read that Chenciner and Montgomery proved in
2000 that a numerical solution found by Moore with the three bodies chasing one another around a ﬁgure of eight path was exact. case 3) 
The Schroedinger equation of the Helium Atom.","['ordinary-differential-equations', 'partial-differential-equations', 'numerical-methods']"
854205,Find the sum of the series $\sum \limits_{n=3}^{\infty} \dfrac{1}{n^5-5n^3+4n}$,"Feel free to skip obvious steps, or use a calculator when required. I just want to understand the theme of the solution. Any help is appreciated EDIT : We can write$$ \dfrac{1}{n^5-5n^3+4n} =  -\dfrac{1}{6 (n-1)}+\dfrac{1}{4 n}-\dfrac{1}{ 6(n+1)}+\dfrac{1}{ 24(n+2)}+\dfrac{1}{ 24(n-2)}$$ How do I do telescopic sum !","['sequences-and-series', 'summation', 'calculus', 'algebra-precalculus']"
854209,Every unitary representation of a compact group is a direct sum of irreducible representations.,"I've read nice proofs of a few different variants of the Peter-Weyl theorem and its corollaries. For instance I know that for $G$ a compact group, $L^2(G)$ is a Hilbert space direct sum of the matrix coefficients of the irreducible representations of $G$, all of which are finite dimensional. However, there's one fact I'm not sure how to prove: If $G$ is a compact group and $\pi : G \rightarrow \mathcal{U}(H)$ is a unitary representation of $G$ on a Hilbert space $H$,  then $(\pi, H)$ is a Hilbert space direct sum of irreducible representations.","['representation-theory', 'functional-analysis', 'analysis']"
854223,Prove $\prod_{i=1}^{n-1} \sin(i\pi/n) = 2^{1-n} n$ without complex functions.,"Note that $i$ here refers to indexing variable, not $\sqrt{-1}$. $$\prod_{i=1}^{n-1} \sin\left(\frac{i \pi}{n}\right) = 2^{1-n} n$$
This formula was used here to give an 'elementary' proof of product of diagonals = N . Mathworld is the only place I can find the formula and that website cites a personal communication with 'T. Drane' I have tried to prove it on my own but this is the only progress I've made. Letting $n=2k+1$, I can show that $$\prod_{i=1}^{2k} \sin\left(\frac{i \pi}{2k+1}\right) = \prod_{i=1}^{k} \cos^2\left(\frac{(2i-1) \pi}{4k+2}\right)$$ I used the sine product formula $\quad\sin(a)\sin(b)=\dfrac{\cos(a-b)-\cos(a+b)}{2}\quad$ to pair of the first/last terms, etc. Then used the cosine double-angle formula $\quad \cos(2a)+1 = 2\cos^2(a)\quad$ on the resulting product. I don't know where to go on from on here and I was just investigating the special case of odd $n$. Any ideas on what to do next? Simpler approach that would also apply to $n=2k$? PS: It would be preferred if the proof avoided complex functions in order to complete the answer to the diagonals question reference earlier.",['trigonometry']
854227,Finite-dimensional subspace normed vector space is closed,"I know that probably this question has already been answered, but I'd like to present my attempt of solution. Let $(E,\|\cdot\|)$ be a normed vector space and let $F\subseteq E$ be a finite-dimensional subspace. Suppose that $\dim_{\mathbb{R}} F=n$ . First of all I proved the following lemma. Lemma 1 Every finite-dimensional normed vector space is complete. Then, I noticed that $(F,\|\cdot\|_{F})$ is a finite-dimensional normed vector space, where $\|\cdot\|_{F}$ is the induced norm. So, $F$ is complete by Lemma 1 . Lemma 2 If $(E,\|\cdot\|)$ is a normed vector space such that $\dim_{\mathbb{R}}{E}=n$ , then $E$ is algebraically and topologically isomorphic to $\mathbb{R}^{n}$ . By Lemma 2 , I can view $F$ as a complete subspace of $\mathbb{R}^n$ and, since $\mathbb{R}^n$ is itself complete, I can conclude that $F$ is closed. Here I used the fact that every complete subspace of a complete space is closed. Is there something wrong?","['vector-spaces', 'general-topology', 'normed-spaces', 'real-analysis', 'functional-analysis']"
854238,Convergence of $\sum_{n=1}^{+\infty}\frac{(-1)^{f(n)}}{n}$ where $f(n)$ is the number of prime divisors,"Let $f(n)$ be the number of prime divisors of a number $n$ counted with their multiplicities. Show that the series  $\sum_{n=1}^{+\infty}\frac{(-1)^{f(n)}}{n}$ converges and has sum $0$. Attempt :
The infinite product $$\prod_{p\text{ prime}}\left(1+\frac1p\right)^{-1}$$ diverges to zero. and we have,
$$\left(1+\frac1p\right)^{-1}=\sum_{k=0}^{\infty}\frac{(-1)^{k}}{p^{k}}$$ Formally we can write : $$\prod_{p\text{ prime}}\sum_{k=0}^{\infty}\frac{(-1)^{k}}{p^{k}}=\sum_{n=1}^{\infty}\frac{(-1)^{f(n)}}n$$ Unfortunatly I do not see how can I  make this rigourous.","['convergence-divergence', 'sequences-and-series', 'summation']"
854248,What is the value of $\lfloor{100N}\rfloor$,"What is the value of $\lfloor{100N}\rfloor$ where $\displaystyle N= \lim\limits_{a\,\rightarrow\,\infty}\sum\limits_{x=-a}^{a}\frac{\sin x}{x}$. This is a part of a bigger problem that I was solving. I need the exact integer value of $\lfloor{100N}\rfloor$ . I was only able to simplify $\displaystyle \lim\limits_{a\,\rightarrow\,\infty}\sum\limits_{x=-a}^{a}\frac{\sin x}{x}= 1+2\left(\lim\limits_{a\,\rightarrow\,\infty}\sum\limits_{x=1}^{a}\frac{\sin x}{x}\right)$. I don't know how to proceed further. Please help","['calculus', 'algebra-precalculus', 'limits']"
854252,"If rank$(A)=r$, show that rank$(A^\top A)=r$","Let $A$ be $m\times n$ matrix with rank $r=\min(m,n)$. How do we show that rank$(A^T A)$ is $r$.",['linear-algebra']
854265,To prove : If $f^n$ has a unique fixed point $b$ then $f(b)=b$,"If $f: \mathbb R \to \mathbb R$ be a  function such that for some $n_o \in \mathbb N$ , the $n_o$th iterate of $f$ has a unique fixed point $b$ , then how to prove that $f(b)=b$ ? I cant think of anything , please help . Thanks .","['functions', 'fixed-point-theorems', 'real-analysis']"
854275,$A$ is diagonalizable and $A^3 = A^2$,If $A$ is diagonalizable and $A^3 = A^2$. Is it necessary true that $A^2 = A$?,"['matrices', 'linear-algebra', 'diagonalization']"
854276,Variable substitution in second order PDE,"Consider the the PDE $$A(x, y)\partial_{xx} u + B(x, y)\partial_{xy}u + C(x, y)\partial_{yy}u=h(x, y) $$ Now I want to make a variable substitution $\xi=f(x, y), \eta=g(x,y)$, so I can get $u$ as a function of $\xi$ and $\eta$. So $$\partial_{x}u=\partial_{x}\xi\partial_{\xi}u + \partial_{x}\eta\partial_{\eta}u$$ Then $$\partial_{xx}u=\partial_{x}\left(\partial_{x}\xi\partial_{\xi}u + \partial_{x}\eta\partial_{\eta}u\right)\overset{?}{=}\partial_{xx}\xi\partial_{\xi}u + \partial_{x}\xi\partial_{x\xi}u + \partial_{xx}\eta\partial_{\eta}u + \partial_{x}\eta\partial_{x\eta}u$$ I am supposed to find terms like $\partial_{\xi\xi} u$, but how? The question-mark over the equality is that I am unsure if and how the chain rule should be applied.","['multivariable-calculus', 'ordinary-differential-equations', 'partial-differential-equations']"
854281,Good pair vs. cofibration,"It can be shown that $i:A\hookrightarrow X$ is a closed cofibration if and only if there is a map $\varphi:X\to I=[0,1]$ and a homotopy $H:U\times I\to X$ on some neighborhood $U$ of $A$ such that $A=φ^{-1}(0)$ and $φ^{-1}([0,1))\subseteq U$ $H(x,0)=x$, $H(a,t)=a$, and $H(x,1)\in A$ for all $x\in U, a\in A, t\in I$. The last condition says that the neighborhood $U$ is deformable in $X$ to $A$. However, this seems to be different from $U$ deformation retracting to $A$ since the path $H(\{x\}×I)$ need not stay in $U$. We can call $(X,A)$ a good pair (terminology from Hatcher's Algebraic Topology ) if $A$ is a closed subspace of $X$ and some neighborhood $V$ deformation retracts to $A$. I'd be interested to see an example of a closed cofibration which is not a good pair. Such an example would feature a neighborhood $U$ of $A$ whose inclusion in $X$ is homotopic to a retraction onto $A$ but for no neighborhood such a homotopy would stay within that set. At first I thought you could simply replace $U$ be the larger set $V=H[U\times I]$ and for each point $y\in V$ let the path start at $t_y$ the smallest point in time such that some $y=H(x,t_y)$ for some $x$ in $U$, and let $y$ be attached to $x$ on its path towards $A$, but this doesn't always give a well-defined map. In other words, the deformable neighborhood does not always give rise to a neighborhood which deformation retracts to $A$. Of course if someone comes up with a good pair which is not cofibered, that would be nice, too.","['general-topology', 'examples-counterexamples', 'homotopy-theory', 'algebraic-topology']"
854300,Submanifolds - same dimension,Let $M$ be a smooth manifold and $N$ a closed embedded submanifold. Assume that they have the same dimension. In this case are they equal? EDIT: M is connected.,"['smooth-manifolds', 'differential-geometry']"
854320,"Proof for $\forall x$, $\exists y$ s.t $1/2 \le |x-y|\le 1$ and $ |\cos \pi x - \cos \pi y|\ge 1$","I am trying to understand a certain proof for the indifferentiability of the Weierstrass function, that strongly uses the following lemma: For all $x \in \mathbb{R}$ there exists $y \in \mathbb{R}$ such that $\frac{1}{2} \le|x-y| \le 1$ and $|\cos \pi x - \cos \pi y|\ge 1$. As a consequent, it said that for 
$$u_k (x)= a^{-k} \cos\left( \pi b^k x \right)$$ and for $x_0 \in \mathbb {R}$ there exists $x_k$ s.t. $$\frac{1}{2} b^{-k} \le |x_k-x_0|\le b^{-k}$$ and $$|u_k (x_k)-u_k(x_0)|\ge a^{-k} \tag{*}$$ I couldn't prove the lemma nor to understand how * follows from it. Thanks for your help! EDIT: I understood how * follows from the lemma, but still unable to prove the lemma. I tried, using the identity (trig identities don't need proofs :-)) 
$$\cos x - \cos y = -2\sin \frac{1}{2}(x+y)\sin \frac{1}{2}(x-y)$$
to prove that given $x\in[0,\pi]$, there exists $y$ under the above constraints such that $\left|\sin \frac{\pi}{2}(x+y)\right| \left|\sin \frac{\pi}{2}(x-y)\right|\ge\frac{1}{2}$ but couldn't make progress.","['trigonometry', 'real-analysis']"
854380,How to distinguish between walking on a sphere and walking on a torus?,"Imagine that you're a flatlander walking in your world. How could you be able to distinguish between your world being a sphere versus a torus? I can't see the difference from this point of view. If you are interested, this question arose while I was watching this video about the shape of space by Jeff Weeks.","['geometry', 'algebraic-topology', 'big-list', 'soft-question', 'surfaces']"
854395,Can we prove that the solutions of $\int_0^y \sin(\sin(x)) dx =1$ are irrational?,Can we prove that the solutions of $$\int_0^y \sin(\sin(x)) dx =1$$ are irrational? Wolfram Alpha gives two approximate sets of solutions as $\{4.58+2\pi k|k\in\mathbb{Z}\}$ and $\{1.69+2\pi k|k\in\mathbb{Z}\}$. Can we prove they are irrational?,"['roots', 'calculus', 'integration', 'irrational-numbers']"
854405,How to define integration over the boundary of a curve?,"When learning about Stokes' theorem ($\int_{\partial \Omega} \omega=\int_{\Omega} \mathrm d \omega$), we are told that it is just a generalization of the 2nd Fundamental Theorem of Calculus $(\int_a^b F'(x)dx= F(b)-F(a))$.  In particular, we are told that we can consider $F(b) - F(a)$ to be an integral over the boundary of the curve $y=F'(x), x \in [a, b]$ -- the boundary is then the disconnected set of points $\{a, b\}$ with an orientation ""from $a$ to $b$"". Edit: user8268 indicates that this orientation should $-a$ and $+b$, though I'm not entirely sure why -- other than it makes the equation work. But is this really integration?  Doesn't the ""region of integration"" of a Riemann integral have to be connected? Edit: It's not really a region if it's not connected, but I don't know what else to call it. Is there any way to define a Riemann (or possibly Lebesgue) integral  $\int_A f(x)dx$ over $A=\{a,b : a \neq b\}$ (with some orientation)?","['multivariable-calculus', 'integration', 'differential-forms', 'geometric-algebras', 'real-analysis']"
854427,Which harmonic numbers have prime numerators?,"Let
$$1+\frac12+\frac13+\cdots+\frac1n=\frac{q}{p}$$
with $(p,q)=1$ and $q$ is a prime number. (I) Prove or disprove that the quantity of $n$ is limited. (II) Determine all $n$ satisfying the condition. I use the matlab and get some $n$ meeted the condition:$2,3,5,8,9,21,26,41,56,62,69,79,89,91,122,127,143,167,201,230,247,252,290,349,376,459,489,492,516,662,687,714,771,932,944,1061,1281,1352,1489,1730, 1969,2012,2116,2457,2663,2955,3083,3130,3204,3359,3494,3572,...$","['harmonic-numbers', 'fractions', 'number-theory']"
854447,How to evaluate the sum $\sum_{k = 0}^{n}2^k {{n}\choose {k}}$ [duplicate],"This question already has answers here : Combinatorial proof for $\sum_{k=0}^n 2^k \binom{n}{k} = 3^n$ (4 answers) Closed 9 years ago . How do I evaluate the sum:
$$\sum_{k = 0}^{n}2^k {{n}\choose {k}}$$
I know that $2^k = {n \choose 0} + {n \choose 1} + {n \choose 2} + {n \choose 3}... {n \choose k}$, but I don't know how to proceed from this.","['summation', 'combinatorics']"
854459,Why do determinants have their particular form?,"I know that for a matrix $A$, if $\det(A)=0$ then the matrix does not have an inverse, and hence the associated system of equations does not have a unique solution. However, why do the determinant formulas have the form they do? Why all the complicated co-factor expansions and alternating signs ? To sum it up: I know what determinants do, but its unclear to me why. Is there an intuitive explanation that can be attached to a co-factor expansion??..","['matrices', 'linear-algebra', 'determinant']"
854475,"Let F be a field of order 32. Show that the only subfields of F are F itself and {0,1}.","$F$ is a field of order $32$.
$F$ and {$0,1$} are trivial subfields of $F$. But how can we show that these are the only subfields of $F$?
Can someone give me a direction to this question?","['finite-fields', 'abstract-algebra', 'field-theory']"
854509,"Let $\alpha, \beta, \gamma$ be cardinals, $\beta \leq \gamma$, prove $\alpha ^{\beta}\le \alpha ^{\gamma}$","Let $|A|=\alpha, |B|=\beta, |C|= \gamma$ be cardinals and $\beta \leq \gamma$. Prove $\alpha ^{\beta}\le \alpha ^{\gamma}$. So from the given we know that there's an injection $f:B\to C$ and some functions $h:B\to A, g: C\to A$. We want to prove there's an injection $l_1:A\to C$. It appears that $f$ doesn't help here. Trying to take representatives from $A$ and show they're in $C$ and there's an injection doesn't work so maybe the function should be $l_2: h \to g$ but I don't know how to work with it.","['cardinals', 'elementary-set-theory']"
854510,Sequence problem,"I have a calculus final two days from now and we have a test example. There's a sequence question I can't seem to solve and hope someone here will be able to help.
With $a_1$ not given, what are the possible values of it so that the sequence $a_{n+1}=\sqrt{3+a_n}$ will converge. If it does, what is the limit? I have no clue what so ever on what doing here. I mean, I can't prove the sequence is monotone. I assume that $a_1$ $\ge $ -3 and can also approach infinity. Any help is appreciated,
Regards,","['sequences-and-series', 'convergence-divergence', 'calculus', 'limits']"
854535,How can I find the smallest enclosing circle for a rectangle?,I have the four vertices of a rectangle. I need to find it's smallest enclosing circle. For example: I need to find the radius of the circle.,"['geometry', 'circles']"
854541,Prove that $X_nY_n\overset{\mathcal D}\rightarrow Xc$.,"Let $X_n$ converge in distribution to $X$ and let $Y_n$ converge in probability to a constant $c$. Show that $X_nY_n\overset{\mathcal D}\rightarrow Xc$ and $\frac{X_n}{Y_n}\overset{\mathcal D}\rightarrow\frac{X}{c}$ (where, $\overset{\mathcal D}\rightarrow$ means convergence in distribution) For a contiuous, bounded and Lipschitz function $f$ with $k$ as Lipschitz constant and $\alpha:=\sup|f(x)|$, we have to show $|\mathbf E(f(X_nY_n)-f(X_nc))|\to 0$, but $|\mathbf E(f(X_nY_n)-f(X_nc))|\le\mathbf E(|f(X_nY_n)-f(X_nc)|\mathbf1_{|X_nY_n-X_nc|\le\epsilon})+\mathbf E(|f(X_nY_n)-f(X_nc)|\mathbf1_{|X_nY_n-X_nc|>\epsilon})\le k\epsilon+2\alpha\Pr(|X_nY_n-X_nc|>\epsilon)\le k\epsilon+\Pr(|Y_n-c|>\frac{\epsilon}{|X_n|})$ If $|X_n|\neq0$, otherwise it is automatically satisfied. Can you verify my steps ? Thanks.","['probability-theory', 'weak-convergence', 'proof-verification']"
854543,Irreducibility of some polynomial,"Let $p(x) = (1+ \cdots +x^k)^2 + (1+ \cdots +x^k) + 1$, for some $k \geq 2$ fixed. I would like to know if $p(x)$ is irreducible in $\mathbb{Q}[x]$.","['irreducible-polynomials', 'algebra-precalculus', 'abstract-algebra', 'polynomials']"
854576,How does the area of $A+A$ compare to the area of $A-A$?,"The Minkowski sum of two sets $A$ and $B$ in the plane is defined as 
$$A+B = \{ a + b \mid a \in A, b \in B \}.$$
The Minkowski difference $A-B$ is defined similarly. For any convex set $A$, is it always true that $$|A-A| \ge |A+A|?$$ For example, if $A$ is a triangle, then $|A - A| = \frac{3}{2} |A + A|$. If $A$ is symmetric about a point, then $|A-A| = |A+A|$.",['geometry']
854578,Some questions about the pseudoinverse of a matrix,"For every mxn-matrix A with real entries, there exist a unique nxm-matrix B, also 
 with real entries, such that $$ABA = A$$
$$BAB = B$$
$$AB = (AB)^T$$
$$BA = (BA)^T$$ B is called the pseudoinverse of A.
There is also a complex version, but I am only interested in the real one.
Now my questions : If A has rational entries, must B also have rational entries ? How can I calculate the pseudoinverse of a matrix with PARI/GP ? Is there a simple method to calculate the pseudoinverse by hand for
small matrices ? Under which condition are the entries of the pseudoinverse integers ? I know some special properties, for instance, that for invertible square 
matrices A, the pseudoinverse is simply $A^{-1}$ , or that the pseudoinverse
of a zero-matrix is its transposition, but I have not much experience with
general pseudoinverses.","['matrices', 'pseudoinverse', 'linear-algebra', 'inverse']"
854592,I'm missing the right substitute $\sqrt3\cos x=1-\sin x$,"Please show me how to solve the following equation for $x$.
I've tried multiple substitutes but can't seem to find the right one. $$\sqrt3\cos x=1-\sin x$$","['trigonometry', 'algebra-precalculus']"
854612,The probability that x birthdays lie within n days of each other,"This is a question that has bugged me for quite some time: what is the chance that x people happen to have their birthdays within n days of each other? A bit more specific, since this is how a colleague one phrased it: what is the probability that 5 people have their birthdays within 40 days? Both the birthdays and the ""distance"" are supposed to be random: there is no fixed time span (e.g., April 1 to May 10) that the birthdays are to lie within. The birthdays should be such, that two birthdays are always within 40 days of each other. The thing that bugs me, is that it seems to be some kind of recursive calculation, and that I can't find a way to put it into a straightforward mathematical formulation. To explain that, consider 2 people: the first person is free to have his or her birthday $b_1$ any day of the year, and the second person has 81 days to pick a birthday date $b_2$ from (the 40 day timespan is inclusive , so up to 40 days before $b_1$, plus up to days after $b_1$, plus one on $b_1$ itself. This may be more logically phrased as 41 days for some; I don't know what is best, so please be clear about it in your answer). Now, for the third person, the number of birthdays he or she can have, is limited by the second person's birthday: if $b_2 = b_1$, then $b_3$ can be among 81 days, but if $b_2 = b_1 + 1$ or $b_2 = b_1 - 1$, there are only 80 days for each option, and 79 for $\|b_1 - b_2\| = 2$, etc. For the fourth person, the limitation is given by person 2 and 3, complicating things; the fifth person makes things even more complicated. I've also tried to go the ""exclusion"" way (what is the chance that 5 people do not share their birthdays within 40 days of each other), but I didn't get anywhere that way. But perhaps I'm going entirely the wrong way about this. By now, I've computed it in various way, and I'm quite confident of the answer, but I'm still looking for the mathematical formulation of the general (x birthdays, n days) problem. The answer I've got, btw, is $7.581428 \cdot 10^{-4}$, or $\frac{13456201}{365^4}$. NB: this obviously assumes no leap years. NB2: Extension of the Birthday Problem appears related, though I can't readily see if I can use any of that formulation here.",['probability']
854636,If $f'(z_0)\neq 0$ then $f$ has an holomorphic inverse.,"Problem: Let $U\subset\mathbb{C}$ be an open set, $f:U\to\mathbb{C}$ an holomorphic function of class $C^1$ and $z_0\in U$. Prove that if $f'(z_0)\neq 0$ then there exists a neighborhood $V$ of $z_0$ such that the restriction of $f$ to $V$ has an holomorphic inverse. I would like to know if the solution below is correct/acceptable. This exercise was taken of a section that studies the Inverse Function Theorem for mappings from $U\subset\mathbb{R}^m$ to $\mathbb{R}^m$. Solution: Since 
\begin{matrix}
f & : & U& \longrightarrow & \mathbb{C}\\ 
 &  & (x,y) & \longmapsto & (u(x,y),v(x,y))
\end{matrix}
is holomorphic, we conclude that $u,v:U\longrightarrow\mathbb{C}$ are differentiable and
$$\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y},\quad\frac{\partial u}{\partial y}=-\frac{\partial v}{\partial x}.$$
It follows that
$$\det J_f(z_0)=\left(\frac{\partial u}{\partial x}(z_0)\right)^2+\left(\frac{\partial u}{\partial y}(z_0)\right)^2\neq0$$
because
$$\left(\frac{\partial u}{\partial x}(z_0),-\frac{\partial u}{\partial y}(z_0)\right)=f'(z_0)\neq 0.$$
So, by Inverse Function Theorem, there exists a neighborhood $V$ of $z_0$ and an open set $W\ni f(z_0)$ such that $f|_V:V\to W$ is a diffeomorphism and thus has a differentiable inverse
\begin{matrix}
(f|_V)^{-1} & : & W& \longrightarrow & V\\ 
 &  & (x,y) & \longmapsto & (\tilde{u}(x,y),\tilde{v}(x,y))
\end{matrix}
Furthermore, for all $v\in \mathbb{R}^2$,
$$\left((f|_V)^{-1}\right)'(f(z_0))\cdot v=(f'(z_0))^{-1}\cdot v=
\begin{vmatrix}
\frac{\partial u}{\partial x} (z_0)& \frac{\partial u}{\partial y}(z_0)\\ 
-\frac{\partial u}{\partial y}(z_0)& \frac{\partial u}{\partial x}(z_0)
\end{vmatrix}^{-1}v=
\frac{1}{\det J_f(z_0)}\begin{vmatrix}
\frac{\partial u}{\partial x}(z_0) & -\frac{\partial u}{\partial y}(z_0)\\ 
\frac{\partial u}{\partial y}(z_0)& \frac{\partial u}{\partial x}(z_0)
\end{vmatrix}v$$
and thus $$\frac{\partial \tilde{u}}{\partial x}(f(z_0))=\frac{\partial \tilde{v}}{\partial y}(f(z_0)),\quad 
\frac{\partial \tilde{u}}{\partial y}(f(z_0))=-\frac{\partial \tilde{v}}{\partial x}(f(z_0)).$$ For any point $p=f(z)\in W$, we have $\det J_f(z)\neq 0$ (because $f|_V$ is a diffeomorphism) so that we can apply a similar argument to conclude that 
$$\frac{\partial \tilde{u}}{\partial x}(f(z))=\frac{\partial \tilde{v}}{\partial y}(f(z)),\quad 
\frac{\partial \tilde{u}}{\partial y}(f(z))=-\frac{\partial \tilde{v}}{\partial x}(f(z)).$$
Hence, $(f|_V)^{-1}$ is holomorphic. $\blacksquare$ Thanks.","['multivariable-calculus', 'proof-verification', 'complex-analysis']"
854644,"Are vector bundles just modules over $C^{\infty}(M)$, or are ""locality"" conditions required?","In this question the asker defines 1-forms on a (real, smooth) manifold $M$ to be $C^{\infty}(M)$-module homomorphism[s] from $Vec(M)$ to $C^{\infty}(M).\:\:\:\:(*)$ I'm wondering if this is correct. I've previously seen 1-forms defined as being homomorphisms from $TM$ to $\mathbb{R}\times M$ as vector-bundles-over-$M$. It's easy to see that a 1-form in this sense defines a 1-form in the first sense, but I can't see why the converse is true. It seems like an extra condition ought to be added to $(*)$ saying that given a supposed 1-form $\eta$ taking a vector $X$ to a scalar $f$, the value of $f$ at $x\in M$ should depend only on the value of $X$ at $x$. Or something like that. Are all $C^{\infty}(M)$-modules given by spaces of sections of vector bundles? Are all $C^{\infty}(M)$-homomorphisms between the spaces of sections of bundles given by corresponding maps between the bundles themselves?","['vector-bundles', 'differential-geometry']"
854664,Harmonic non-surjective functions are constant,"Let $u:\mathbb R^2 \to \mathbb R$ be a non-surjective harmonic function. $(i)$ Show that $u$ is bounded from below or from above. $(ii)$ Prove that $u$ is constant (and therefore any harmonic function is constant or surjective) I know how to prove $(i) \implies (ii)$: Suppose $|u|\leq B$, by hypothesis, there exists an entire function $f$ such that $f(x+iy)=u(x,y)+iv(x,y)$. If I consider $e^{f(z)}$, then $e^{f(z)}$ is an entire function and $$|e^{f(z)}|=|e^{u+iv}|$$ $$=e^u|e^{iv}|$$ $$\leq e^B.1$$ $$=c \in \mathbb R_{\geq 0}$$ This proves $e^{f(z)}$ is bounded so, by Liouville's theorem, $e^{f(z)}$ is constant. In this exercise Application of Liouville's theorem exercise it is proven that $e^{f(z)}$ constant $\implies$ $f(z)$ constant. I am having problems with the first part ($(i)$) of the exercise. Suppose $u$ is not surjective, then there exists $u_0 \in \mathbb R$ such that $u(x,y) \neq u_0$ for all $(x,y) \in \mathbb R^2$. I have no idea how to deduce $u$ is not bounded from this hypothesis, I would appreciate any hints.","['harmonic-functions', 'complex-analysis']"
854692,Substituting for Taylor series,So my question is simple: Why is substitution valid? I mean it seems counter-intuitive to me mainly because of the chain rule. For example: The Taylor series of $e^{x^2}$  is  simply done by substituting $x^2$ wherever $x$ goes in the original sum of the Taylor series for $e^x$. But if I do the Taylor series manually for the function $e^{x^2}$  I have to apply the chain rule and so I get other terms and it's not immediately obvious to me why it is that the same series comes up. For what reason is this substitution valid? Thanks.,"['calculus', 'taylor-expansion']"
854745,number of combinations of ordered sequences of N integers,"suppose a N-tuple of N integers, such that every element in the tuple is bigger than or equal to the last one and each element in the sequence ranges from 1 to K. Is there any closed formula for the number of combinations possible? For those who think this is trivial, try to think about it for one minute. I have done so: let $a_i \in \{1, 2, ..., K\}, i \in \{1..N\}$. We want to count the number of N-tuples $(a_1, a_2, ..., a_N)$ such that $a_i>=a_{i-1}$. I know how to solve for $N=2$: given $a_1 \in \{1, 2, ... K\}$, the number of possibilities  for $a_2>=a_1$ is $K-a_1+1$. Thefore, the number of pairs $(a_1,a_2)$ is: $U=K+(K-1)+(K-2)+...+1$ which is easy to compute since it equals $K(K+1)/2$. Now, how to generalize for N-tuples?",['combinatorics']
854746,Is there a closed form solution to $e^{-x/b}(a+x) = e^{x/b}(a-x)$?,"I have the following equation $$e^{-x/b}(a+x) = e^{x/b}(a-x)$$ where $b > 0$ , and $a > 0$ I need to solve for $x$ . I can do it numerically, but would prefer if there was a closed form solution. It seems to me that there likely is no closed form solution, but thought I'd ask the experts here, just in case.","['closed-form', 'algebra-precalculus']"
854755,What is the expected value of the number of randomly chosen real numbers between $0$ and $1$ needed to reach a sum of $1$? [duplicate],"This question already has answers here : Choose a random number between $0$ and $1$ and record its value. Keep doing it until the sum of the numbers exceeds $1$. How many tries do we need? (8 answers) Closed 9 years ago . My friend told me that the answer to this question was $e$, which intrigued me, but he refused to tell me why. My initial intuition was completely wrong. I thought that since the expected value of any one of these numbers (uniformly distributed on $[0,1]$) was $1/2$, the expected number of them you'd need to get a sum of $1$ would be two. I realized this was rather stupid. This is my attempt at calculating the expected value term-by term. Let $N$ be the number of numbers between $0$ and $1$ necessary for their sum to exceed $1$, and let $P(N=k)$ be the probability that it takes $k$ such numbers. Then the expected value of $N$ is $$E(N) = P(N=2) \cdot 2 + P(N=3) \cdot 3 + P(N=4) \cdot 4 + \cdots$$ I then calculated the first term: $$P(N=2) \cdot 2 = \frac{1}{2} \cdot 2 = 1$$ Unfortunately, the second and higher terms aren't as easy ...","['calculus', 'probability', 'expectation']"
854757,maximum curvature of 2D Cubic Bezier,"Given a 2D cubic Bezier segment defined by $P_0, P_1, P_2, P_3$, here's what I want: A function that takes the segment and outputs the maximum curvature without using an iterative approach. I have a function that finds the maximum curvature at the moment, but does this using Brent's Method to search a range of $t$ on $[0, 1]$. It fails to find the maximum curvature $5\%$ of the time. In addition, I really need the Jacobian of the method to help my optimization algorithms. Brent's Method (or any kind of iterative search) makes this impossible. I recognize that this is a difficult function to deal with by hand, but perhaps someone with access to some nice software and a fancy machine could crank out a function to find the maximum curvature of a cubic Bezier? Something that symbolically returns the roots of solving the derivative of the curvature? Thanks for your time.","['curvature', 'bezier-curve', 'derivatives']"
854767,How to recognize when a function is secretely holomorphic,"Let $f : M \rightarrow N$ be a holomorphic map between complex manifolds (I'd be interested even in the case $M=N=\mathbb{C}$ which should not be much different). Now take $K$ a compact subset of $M$, say with no isolated point for the question to be non trivial, and consider the restriction of $f$ to $M$. How can one recognize intrinsically (ie only looking at the values of $f$ on $K$) that $f_{|K}$ is secretely the restriction of a holomorphic map (in a neighborhood of $K$) ? Obviously such a restriction has to be locally lipschitz ; but it should also have some stronger, more constraining properties.",['complex-analysis']
854771,Why is the Ideal Norm Multiplicative?,"I had asked this question before and got a partial answer.  Let $A$ be a Dedekind domain with quotient field $K$, $L$ a finite separable extension of $K$ of degree $n$, and $B$ the integral closure of $A$ in $L$.  The ideal norm $N_{L/K}$ is usually defined multiplicatively by the formula $N_{L/K}(\mathfrak P) = P^f$, where $P = \mathfrak P \cap A$ and $f = f(\mathfrak P / P)$. Another way to define it is as follows: for fractional ideals $M$ and $N$ of $B$, the localizations $M_P$ and $N_P$ are free $A_P$-modules, so there is a $K$-module automorphism $\psi$ of $L$ for which $\psi(M_P) = N_P$.  One then defines the module index $[M_P : N_P]_{A_P}$ to be $Det(\psi)A$.  More generally one defines the module index $[M : N]_A$ to be $$ \prod\limits_P P^{\nu_P [M_P : N_P]_{A_P}}$$ If $M$ is a fractional ideal of $B$, one can define the norm $N_{L/K}(M)$ to be $[B : M]_A$.  (see Cassels and Frohlich, first section of Algebraic Number Theory) I have seen a proof using Smith Canonical Form that these definitions agree when $M$ is a prime ideal, but I have yet to see a simple general proof that the norm (defined in the latter way) is multiplicative.  The ""long"" way of doing this is to look at the completions of $K$ with respect to the $\nu_P$, and then look at the ways in which $\nu_P$ may be extended to $L$ (which correspond to the prime ideals lying over $P$).  The special case $A = \mathbb{Z}$ is more clear, because the module index $[B : M]_{\mathbb{Z}}$ is just the ideal generated by the cardinality of $B/M$.","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'dedekind-domain', 'modules']"
854782,The number of holomorphic coverings (with given degree) of the punctured sphere is finite.,"I'm looking  for a  proof of the following theorem: Fix a finite set $B=\{y_1,\ldots,y_k\}\subseteq \mathbb P^1(\mathbb C)$, then there is only a finite number of isomoprhism classes of holomorphic coverings of $\mathbb P^1(\mathbb C)$ with the following properties: Their branch locus is contained in $B$ They have the same degree $d$ One way to proceed is by proving the correspondence between coverings and monodromy representations (see Miranda's book), but this way is a bit long and moreover it demonstrates much more than I want. I'm interested only on the cardinality of the set of all possible holomorphic coverings of given degree (up to isomorphism) . Is there a 'quick way' to prove the above theorem? Addendum: I need that result only when $k=3$, namely $B=\{y_1,y_2,y_3\}$,  therefore I will accept also answers for this particular case. Thanks in advance.","['alternative-proof', 'riemann-surfaces', 'covering-spaces', 'complex-analysis']"
854796,Combination small challenge problem,"How many ways can 3 different Scientific Groups be formed using 5 students such that Each student is at least be a member of one committee and
each two committee has exactly 2 students in common? I tried this solution: $$\left(\binom{5}{4}×4!\times\binom{3}{1}=360\right) + \left(\binom{5}{2}+\binom{5}{3}\right) = 460$$ But I think I'm'm wrong. Any ideas? Thanks.","['discrete-mathematics', 'combinatorics']"
854801,"If $k>0$ is a positive integer and $p$ is any prime, when is $\mathbb Z_p[\sqrt{k}] =\{a + b\sqrt k~|~a,b \in\mathbb Z_p\}$ a field.","If $k>0$ is a positive integer and $p$ is any prime, when is $\mathbb Z_p[\sqrt{k}] =\{a + b\sqrt k~|~a,b \in\mathbb Z_p\}$ a field? Find necessary and sufficient condition. Attempt: Since we know that a finite integral domain is a field and since $\mathbb Z_p[\sqrt{k}]$ is finite, it suffices to find the condition when $\mathbb Z_p[\sqrt{k}] =\{a + b\sqrt k~|~a,b \in \mathbb Z_p\}$ forms an integral domain. The given set forms a commutative ring with unity. Hence, the only condition that needs to be satisfied is the absence of any zero divisors. $(a_1+b_1 \sqrt k)(a_2+b_2 \sqrt k) = (a_1a_2+b_1b_2k)+(a_1b_2+a_2b_1)\sqrt k$ Case $1$: When $k$ is not a perfect square $(a_1+b_1 \sqrt k)(a_2+b_2 \sqrt k)=0 \implies (a_1a_2+b_1b_2k) \bmod p=0~~ \& ~~ (a_1b_2+a_2b_1) \bmod p =0$ Case $2$: When $k$ is a perfect square $ = u^2$ $(a_1+b_1 \sqrt k)(a_2+b_2 \sqrt k) = 0 \implies (a_1a_2+b_1b_2 u^2 + (a_1b_2+a_2b_1)u ) \bmod p=0 $ Both the above cases can have many cases and seems a bit complicated. Am I missing out on something? The book which I am reading (Gallian) hasn't introduced Quadratic Residues as of yet. Thank you for the help.","['ring-theory', 'finite-fields', 'abstract-algebra', 'field-theory']"
854832,"Is $f(t)=(\cos(t),\sin(t))$ a function?","In the Linear Algebra book we're using (Linear Algebra with Applications, Bretscher, p.129), the author defines this as the function of the unit circle. I understand why the equation of a circle can't be a function. In this case however, I could see how despite failing the vertical line test, $f(t)=(\cos(t),\sin(t))$ still outputs a unique value for any $t$ and is therefore technically a function. Is that the rationale, or is $f(t)=(\cos(t),\sin(t))$ not really a function despite what the author states?","['linear-algebra', 'functions']"
854860,Is There a Difference Between $d^2x$ and $(dx)^2$?,"I've just started reading through Calculus Made Easy by Silvanus Thompson and am trying to solidify the concept of differentials in my mind before progressing too far through the text. In Chapter 1 Thompson describes a differential $dx$ as ""a little bit of $x$"" or ""an element of $x$"" and then proceeds to describe $\int dx$ as ""the sum of all the little bits of $x$."" I'm okay upto this point. In Chapter 2 he begins discussing the various degrees of ""smallness"" and this is where I begin to lose track. At times his explanation seems to make sense, and then again it does not. Thompson starts his discussion of degrees of smallness with an appeal to time. Obviously 1 minute is a very small quantity of time compared with a
  whole week. Indeed, our forefathers considered it small as compared
  with an hour, and called it ""one minute,"" meaning a minute fraction -
  namely one sixtieth - of an hour. When they came to require still
  smaller subdivisions of time, they divided each minute into 60 still
  smaller parts, which, in Queen Elizabeth's days, they called ""second
  minutes"" (i.e. small quantities of the second order of minuteness). Now, at this time it seems as though Thompson is making the point that $(dx)^2$ may be considered to be ""a little bit of $dx$"" or ""a little bit of a little bit of $x$,"" which seems intuitive, but perhaps not consistent with the language. However, a little later he describes $(dx)^2$ as ""a little bit of a little bit of $x^2$. And in doing so, he backs up his statement with a figure of a square with sides of length $x + dx$ and notes that any one of the corners of the square represents the magnitude $(dx)^2$. While not necessarily appealing to my intuition, this description does seem to be more in line with his description of $dx$. a little bit $\cdot$ $x$ $\cdot$ a little bit $\cdot$ $x$ $=$ a little bit $\cdot$ a little bit $\cdot$ $x^2$ Yet, I don't see how this second description is making the case for $(dx)^2$ being any less significant than $dx$. From the diagram, it actually seems more significant than $dx$, being $dx$ times greater than $dx$. So I'm wondering, is there a difference between $d^2x$ and $(dx)^2$? Should I read $d^2x$ as ""a little bit of a little bit of $x$"" and $(dx)^2$ as ""a little bit of a little bit of $x^2$?"" Am I missing the point entirely? Have I gone completely mad? In hopes of further clarifying the question, I'm including a little more of what Thompson said: If $dx$ be a small bit of $x$, and relatively small of itself, it does
  not follow that such quantities as $x \cdot dx$, or $x^2 \cdot dx$, or
  $a^x \cdot dx$ are negligible. But $dx \cdot dx$ would be negligible,
  being a small quantity of the second order. Furthermore, he states: [I]n all cases we are justified in neglecting the small quantities of the second - or third (or higher) - orders , if only we take the
  small quantity of the first order small enough in itself.","['differential', 'calculus']"
854870,How can I evaluate $\lim_{x \to \infty} (2^x + 3^x)^{1/x}$?,"Someone can explain how can I resolve this limit please? $$
\lim_{x \to \infty} (2^x + 3^x)^{1/x}
$$ I tried to convert to exponential $$
\lim_{x \to \infty} \exp \left(\tfrac{1}{x} \ln(2^{x} + 3^{x})\right)
$$ $$
\exp \left( \lim_{x \to \infty} \tfrac{1}{x}\ln(2^{x} + 3^{x}) \right)
$$ In this part I think applied L'Hospital
$$
\exp \left( \lim_{x \to \infty} \frac{\ln(2^{x} + 3^{x})}{x} \right)
$$ I noticed that I can't get to  answer","['calculus', 'limits']"
854881,Show that the function $F(x) =(x-a)^2 (x-b)^2 +x$ has the value $(a+b)/2$ at some point $x$,"Show that the function $$F(x) =(x-a)^2 (x-b)^2 +x$$ has the value $\frac{a + b}{2}$ at some point $x$. I think it might be something with the the intermediate-value theorem, not sure though. anyone have any idea about how to go about this problem?","['calculus', 'algebra-precalculus']"
854902,$f:\mathbb{R}\to \mathbb{R}$ continuous and $\lim_{h \to 0^{+}} \frac{f(x+2h)-f(x+h)}{h}=0$ $\implies f=$ constant.,Let $f:\mathbb{R} \to \mathbb{R}$ be a continuous function with the property that $$\lim_{h \to 0^{+}} \dfrac{f(x+2h)-f(x+h)}{h}=0$$ for all $x \in \mathbb{R}$. Prove that $f$ is constant.,"['contest-math', 'continuity', 'real-analysis', 'analysis', 'limits']"
854907,Rate of convergence of a martingale,"I have a question related to convergence rates of martingales: Assume that there is a sequence of maximized likelihood ratios: $ \frac{f_{\hat{\theta}_{n}} \left ( Y_{1},Y_{2},\dots,Y_{n} \right ) }{f_{0} \left (Y_{1},Y_{2},...Y_{n} \right )} $ where $O$ denotes the true parameter and $\hat{\theta}_{n} \in \Theta - \{0\}$ is the maximum likelihood estimate of the unknown parameter at time $n$. Moreover the observation sequence $Y_{1},Y_{2},...Y_{n}$ can in general be dependent.
An important information is that the parameter set $\Theta$ is finite. I.e. without loss of generality say $\Theta = \{0,1,2,...,K\} \Leftrightarrow |\Theta|=K+1$. The sequence of such ratios is known that forms a submartingale that converges to $0$ almost surely. I am trying to estimate the convergence rate (of the general dependent case) but I can't.
Can anybody suggest something on that?","['statistics', 'martingales', 'probability', 'probability-theory']"
854929,Zombie outbreak on a $k$-regular graph,"Suppose we have a zombie outbreak on a connected $k$-regular graph of order $n$.  There are $n_0$ initially infected zombie nodes, and each turn, each zombie infects its neighbors with probability $p$.  Let $z(t)$ denote the number of infected nodes on turn $t$. What is the expected number of turns until zombies have taken over the world?  (that is, until $z(t)=n$?) Is it true that $z(t)\approx \dfrac{n}{1+(n-n_0)e^{-rt}}$?  If so, what is $r$?","['stochastic-processes', 'asymptotics', 'graph-theory', 'probability-distributions', 'probability']"
854942,How many decimal representations are possible for the number 1,I know that there at least two $0.\overline{9}$ and 1 Is there a neat and more concrete way to understand this problem.,"['elementary-number-theory', 'sequences-and-series', 'summation', 'calculus']"
854988,"Does there exist a function$f: [0,1]\rightarrow \mathbb{R}$ almost everywhere $0$ but whose range is equal to $\mathbb{R}$","Does there exist a function$f: [0,1]\rightarrow \mathbb{R}, f=0,a.e$  but whose range is equal to $\mathbb{R}$? I can't image what this kind function looks like.",['real-analysis']
854992,best intuitive books/video lectures to read topology and functional analysis,"What are the best intuitive books/video lectures to read topology and functional analysis ? I am aware of basic linear algebra, analysis and measure theory.","['book-recommendation', 'general-topology', 'reference-request', 'online-resources', 'functional-analysis']"
855002,"What does the decomposition, weak union and contraction rule mean for conditional probability and what are their proofs?","I was reading Koller's book on Probabilistic Graphical Models and was wondering what the decomposition, weak union and contraction properties of conditional probability mean. But before I ask exactly what I am confused about let me introduce some of Koller's notation so that we are all in the same page (anything else is unclear feel free to ask in the comments). Let capital non-bold stand for random variables say $X$ is a r.v. Let little non bold stand for the assignment to a random variable say $(X = x)$. Also, let me define captial bold letters as sets of random variables. For example $\textbf{X}, \textbf{Y}, \textbf{Z}$ are three sets of random variables. Let small bold letters denote assigments to these sets $\textbf{x}, \textbf{y}, \textbf{z}$ i.e. it denotes assigments of values to the variables in these sets. Let $Val(\textbf{X})$ be the values that the set of random variables can take. Now, these are the properties/theorems I am trying to prove and understand: Decomposition: $$( \textbf{X} \perp \textbf{Y}, \textbf{W} \ | \ \textbf{Z}) \implies (\textbf{X} \perp \textbf{Y} \  | \ \textbf{Z})$$ Weak union: $$(\textbf{X} \perp \textbf{Y}, \textbf{W} \ | \ \textbf{Z}) \implies (\textbf{X} \perp \textbf{Y} \ | \ \textbf{Z}, \textbf{W})$$ Contraction: $$(\textbf{X} \perp \textbf{W} \ | \ \textbf{Z}, \textbf{Y}) \ \& \ (\textbf{X} \perp \textbf{Y} \ | \ \textbf{Z}) \implies (\textbf{X} \perp \textbf{Y}, \textbf{W} \ | \ \textbf{Z})$$ Intersection: $$(\textbf{X} \perp \textbf{Y} | \textbf{Z}, \textbf{W}) \ \& \  (\textbf{X} \perp \textbf{W} | \textbf{Z}, \textbf{Y}) \implies (\textbf{X} \perp \textbf{Y}, \textbf{W} | \textbf{Z})$$ Let's take the first statement. I think its a notational problem (though, not sure). Does the first statement mean, ""X is conditionally independent of Y and W Given Z""? i.e. is the first statement the same as $(\textbf{X} \perp (\textbf{Y},\textbf{W}) \ \perp \ \textbf{Z})$. If that is true, then would the first statement imply two things: $$(\textbf{X} \perp \textbf{Y}, \textbf{W} \ | \ \textbf{Z}) \implies (\textbf{X} \perp \textbf{Y} \  | \ \textbf{Z})$$ and $$(\textbf{X} \perp \textbf{Y}, \textbf{W} \ | \ \textbf{Z}) \implies (\textbf{X} \perp \textbf{W} \  | \ \textbf{Z})$$ ? I actually intended to prove them as an exercise to myself, however, not being sure if I understood the notation or not made it pretty hard to even attempt a proof (and it also made it hard to try to understand the intuition behind each of the statements, an important thing I wanted to also do, understand it intuitively). Providing one proof as an example and explaining the notation might be good enough for me as an example so that I can attempt the other too. Bounty Section Now that I have tried to prove them, I have had more difficulties than I expected, I wanted to see a proof for each one as I was unable to find them on the internet. I tried proving the first one and this is what I have so far: we want an expression for $(\textbf{X} \perp \textbf{Y} \mid \textbf{Z}, \textbf{W} )$ using property $(\textbf{X} \perp \textbf{Y}, \textbf{W} \mid \textbf{Z} )$ so lets consider: $P(\textbf{X},\textbf{Y} | \textbf{Z}, \textbf{W}) = \frac{P(\textbf{X} ,\textbf{Y} , \textbf{Z} , \textbf{W} )}{P(\textbf{Z} , \textbf{W})} = \frac{P(\textbf{Z})P(\textbf{X}, \textbf{Y} , \textbf{W} \mid \textbf{Z})}{P(\textbf{Z} , \textbf{W})}$ Now we can use the property we need by noting that $P(\textbf{X}, \textbf{Y} ,\textbf{W} \mid \textbf{Z}) = P( \textbf{X} | \textbf{Z} )P(\textbf{Y} , \textbf{W} \mid \textbf{Z})$ (due to assumption/property $(\textbf{X} \perp \textbf{Y}, \textbf{W} \mid \textbf{Z})$), thus: $\frac{P(\textbf{Z})P(\textbf{X},\textbf{Y},\textbf{W} \mid \textbf{Z} )}{P(\textbf{Z}, \textbf{W})} = \frac{P(\textbf{Z})P(\textbf{X}|\textbf{Z})P(\textbf{Y} , \textbf{X} | \textbf{Z} )}{P(\textbf{Z} , \textbf{W})}$ and that was as far as I got for Weak Union. I couldn't get it to be the same as: $P(\textbf{X},\textbf{Y}|\textbf{Z},\textbf{W}) = P(\textbf{X}|\textbf{Z},\textbf{W})P(\textbf{Y}|\textbf{Z},\textbf{W})$","['probability-theory', 'conditional-probability']"
855008,When does the integral preserve strict inequalities?,"Hi everyone: Suppose that $f(t)$ is a continuous function on $[a,b]$, where we also have 
$$\alpha<f<\beta.$$
 Under which condition(s) do the above strict inequalities are preserved by taking the integral: 
$$\alpha<\frac{1}{b-a}\int_{a}^{b}f(t)dt<\beta?$$ Thanks for your reply.",['real-analysis']
855018,Examples of differentiable functions that are not of bounded variation,"It is known that a function with bounded variation is differentiable almost everywhere. There are also functions with unbounded variation that are differentiable almost everywhere (e.g. take $f:[0,1]\rightarrow\mathbb{R}$ with $f(0)=0$ and $f(x)=1/x$ otherwise). But does there exist a function on $[0,1]$ with unbounded variation that is everywhere differentiable?","['bounded-variation', 'examples-counterexamples', 'real-analysis']"
855019,The set of zeros of a holomorphic function is finite in compact sets,"Statement Let $f:\mathbb \Omega \to \mathbb C$ be a holomorphic function, $f \neq 0$ ($\Omega$ is a region, i.e., an open, nonempty, connected set). Prove that in every compact subset $K$ of $\Omega$, the set of zeros of $f$ is finite. I've read in Stein's textbook a proof of the statement ""Suppose $f$ is a holomorphic function in a region $\Omega$ that vanishes on a sequence of distinct points with a limit point in $\Omega$. Then $f$ is identically zero."" From that statement, one can easily deduce that the zeros of $f$ are isolated. I've written a proof of the original statement using that fact. I would like to know if my proof is correct and also to encourage to give an answer to anyone who has an alternative solution (or my corrected solution, should some step of mine be wrong). Proof of statement The proof is by contradiction. I'll denote $S=\{z \in K : f(z)=0\}$. Define $\{F_j\}_{\{j \in \mathcal J\}}$ to be $\{F_j\}_{\{j \in \mathcal J\}}=\bigcup_{\{i \in \mathcal I\}} B(z_i,\delta_i) \cup \ C$, where $C$ is an open cover for $S^c$, and  $B(z_i,\delta_{i})$ is an open ball centered at $z_i$ with a radius chosen such that $z \not \in B(z_i,\delta_{i})$ for $z \in S$ different from $z_i$, for each $z_i \in S$ . It is clear that $\{F_j\}_{\{j \in \mathcal J\}}$ is an open cover for $K$. Now, since $K$ is compact, there exists a finite subcover $\{F_{j'}\}_{\{j' \in \mathcal J' \subset J\}}$, with $J'$ finite. By the way the original cover was defined, the subcover must be of the form  $\{F_{j'}\}_{\{j' \in \mathcal J' \subset J\}}=\bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'}) \cup \ C'$, where $I'$ is a finite subset of $I$ and $C'$ is a finite subcover extracted from $C$. Now choose $z \in S$ with $z \neq z_{i'}$ for all $i' \in I'$ (we can do this since the set of zeros is supposed to be infinite). By the way the open balls were chosen, $z \not \in \bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'})$, but $z \in K=\bigcup_{\{i' \in \mathcal I'\}} B(z_{i'},\delta_{i'}) \cup \ C'$, so $z$ must be in $C'$, but this is clearly absurd since $C'$ is a cover of $S^c$. The absurd comes from the assumption that $S$ is infinite, then $S$ must be finite.","['compactness', 'complex-analysis']"
855032,About p-adic numbers,"I'm studying the dual group of the diadic rationals, $\widehat{\mathbb{Z}[1/2]}$, where the dual is the dual of Pontryagin of $\mathbb{Z}[1/2]$.
In some papers says that $\widehat{\mathbb{Z}[1/2]}$, is naturally a compact metric space.
The problem is, that I don't know which metric I have to use for this. Can you help me? Greetings !","['harmonic-analysis', 'p-adic-number-theory', 'analysis']"
