question_id,title,body,tags
813780,Trace of a measure on a subset (or restriction of a measure to a subset),"This is an exercise from Measure Theory by Cohn. Given a measurable space $(X,\mathcal{A})$ and subset $C$ which may not be measurable, we can form the trace of $\mathcal{A}$ on $C$ denoted $\mathcal{A}_C$ (a sigma algebra of sets $A\cap C$ where $A\in\mathcal{A}$). Now if we have a finite measure $\mu$ defined on $(X,\mathcal{A})$, we can define a measure on $\mathcal{A}_C$ as follows: there exists $C_1\in\mathcal{A}$, $C\subseteq C_1$ such that $\mu(C_1)=\mu^*(C):=\inf\{\mu(A):A\in\mathcal{A}, C\subseteq A\}$, and we can define $\mu_C(A\cap C)=\mu(A\cap C_1)$. We are asked to check $\mu_C$ is well defined: (single-valued) if $A_1\cap C=A_2\cap C$ then $\mu(A_1\cap C_1)=\mu(A_2\cap C_1)$, and (independent of $C_1$) in fact $\mu_C(A\cap C)=\mu^*(A\cap C)$. $\mu_C$ is a measure on $(C,\mathcal{A}_C)$, called the trace of $\mu$ on $C$. If the subset $C$ is measurable, much of the difficulty of this exercise disappears. In trying to solve this exercise, I usually need to use the following property: if there exists $C_1\in\mathcal{A}$, $C\subseteq C_1$ such that $\mu(C_1)=\mu^*(C)$, then $\mu^*(C_1-C)=0$. Is this property true in general? If yes, could you give me a hint? Also, if you have other approaches to this problem, please leave a hint in the comments as well. Thanks a lot!",['measure-theory']
813803,Prove $\displaystyle\frac{a}{b+3}+\frac{b}{c+3}+\frac{c}{d+3}+\frac{d}{a+3}\le 1$. [duplicate],"This question already has an answer here : Prove $\frac{a}{b+3}+\frac{b}{c+3}+\frac{c}{d+3}+\frac{d}{a+3}\le 1$ for $a^2+b^2+c^2+d^2=4$ (1 answer) Closed 10 years ago . Given $a,b,c,d\ge 0$ and $a^2+b^2+c^2+d^2=4$ show the following holds :
$$\displaystyle\frac{a}{b+3}+\frac{b}{c+3}+\frac{c}{d+3}+\frac{d}{a+3}\le 1$$
Now I tried to fully expand but that becomes too ugly. I want a non-expand proof of this fact. For some motivation I solved a three variable version which I assumed to be true and it came out to be true!
That one is :
$a,b,c\ge 0$ and $a^2+b^2+c^2=3$ show that :
$\displaystyle \frac{a}{b+2}+\frac{b}{c+2}+\frac{c}{a+2}\le 1$. The second one is easier and I DO NOT NEED a solution of the second one. Please help me out on the first one because it is similar but not solvable by a similar method.","['inequality', 'algebra-precalculus']"
813867,Proof that $\sqrt{x}=-\sqrt{x}$ [duplicate],"This question already has answers here : Why $\sqrt{-1 \times -1} \neq \sqrt{-1}^2$? [duplicate] (9 answers) Closed 10 years ago . $\sqrt{x}=\sqrt{1\cdot x}=\sqrt{(-1)^2\cdot x} = \sqrt{(-1)^2} \cdot \sqrt{x} = (-1) \cdot \sqrt{x}=-\sqrt{x}$ The idea popped into my head while I was evaluating an integral. I have a feeling that I made some obvious mistake because the ""proof"" is so simple, but I don't see any flaw. Of course, there must be a flaw somewhere. What is it?","['algebra-precalculus', 'fake-proofs']"
813947,Joint density problem. Two uniform distributions,"This is the problem: An insurer estimates that Smith's time until death is uniformly distributed on the interval [0,5], and Jone's time until death also uniformly distributed on the interval [0,10]. The insurer assumes the two times of death are independent of one another. Find the probability that Smith is the first of the two to die. The solution manual first multiplies them by one another and does this: $$\int_0^{5}\int_s^{10}\frac{1}{50}\ dj\ ds$$ I don't get how this integral describes smith's time of death happening faster. They have a rectangle they drew with a shaded reason that I don't quite understand how describes this problem either. Can someone help me out here. I feel like I'm missing something obvious","['uniform-distribution', 'statistics', 'probability-theory', 'probability-distributions', 'probability']"
813952,Deduce that the product of uncountably many copies of the real line $\mathbb{R}$ is not metrizable.,"Deduce that the product of uncountably many copies of the real line $\mathbb{R}$ is not metrizable. Let $J$ be an uncountable set. Suppose that for $x = (x_j)_{j \in J} \in \prod_{j \in J} \Bbb{R}$ there exist $\{U_n\}_{n \in \Bbb{N}}$ satisfying the conditions for first countability. By the definition of product topology, for each $U_i = \prod_{j \in J} U_{i,j}$, there are at most finitely many $U_{i,j} \not= \Bbb{R}$. Let $k_i = \{ j \in J | U_{i,j} \not= \Bbb{R} \}$. So $k_i$ is a finite set. Now let $K = k_1 \cup k_2 \cup ...$. Since $K$ is the countable union of countable sets, it must be countable. Define $f: K \rightarrow J$ to be the inclusion. Since $K$ is countable and $J$ is not, $f$ cannot be surjectie. i.e. there exists $l \in J$ such that $f^{-1}(l)$ is the empty set. If we pick a neighborhood $V = \prod_{j \in J} V_j$  with $V_l \subsetneq \Bbb{R}$, then for all $i \in \Bbb{N}$, $U_i \nsubseteq V$. A contradiction. Is my proof correct?","['general-topology', 'proof-verification']"
813954,How do I solve this ODE?,"$$ty' +y= 2t$$ 
I just don't get how to solve it.
I tried dividing the equation by $t$ but that didn't lead me anywhere
someone please help me with this",['ordinary-differential-equations']
813976,An exercise from Steins's complex analysis.,"This is an exercise from Steins's complex analysis chapter $8$ : Suppose $F(z)$ is  holomorphic near $z=z_0$ and $F(z_0)=F'(z_0)=0$ , while $F''(z_0)\neq 0$ .show that there are two curves $\Gamma_1$ and $\Gamma_2$ that pass through $z_0$ , are orthogonal at $z_0$ ,and so that $F$ restricted to $\Gamma_1$ is real and has a minimum at $z_0$ ,while $F$ restricted to $\Gamma_2$ is also real but has a maximum at $z_0$ . This hint is also given: Write $F(z)=(g(z))^2$ for $z$ near $z_0$ , and consider the mapping $z \rightarrow g(z)$ and its inverse. I really have no idea. Thanks",['complex-analysis']
813978,Correspondence theorem for rings.,Could someone provide a reference that includes a full and honest proof of the Correspondence Theorem for rings? Let $A$ be a multiplicative ring with identity and $I$ an ideal of $A$. There is a one-to-one correspondence between the ideals of $A$ that contain $I$ and the ideals of the quotient ring $A/I$.,"['ring-theory', 'reference-request', 'abstract-algebra']"
813987,Convolution integral $\int_0^t \cos(t-s)\sin(s)\ ds$,"How can I calculate the following integral? $$\int_0^t \cos(t-s)\sin(s)\ ds$$ I can't get the integral by any substitutions, maybe it is easy but I can't get it.","['multivariable-calculus', 'calculus', 'integration', 'definite-integrals', 'trigonometry']"
814028,Integer Partition into Powers,"Is there any way to count the number of integer partitions of a number $N$ into powers of two such that each size is repeated a power of two times? Ok, so the recurrence can be expressed by: $a(0)=1$, $a(2n+1)=a(n)$, $a(2n) = a(n)+a(n-1)+\ldots+a(n-2^m)+\ldots$ $= a(n)+\sum_{i=0}^{\lfloor\log_{2} n\rfloor}a(n-2^i)$ Is there any asymptotic upper bound on this recurrence? Many Thanks","['asymptotics', 'integer-partitions', 'combinatorics']"
814036,A trigonometric integral with sin(cos(x)) in exponent,"Evaluate:
$$\int_0^{\pi} x\csc^{\sin(\cos x)}(x)\,dx$$ I honestly don't know how to deal with this case. If I apply the property $\int_a^b f(x)\,dx=\int_a^b f(a+b-x)\,dx$, I get:
$$\int_0^{\pi} (\pi-x) \frac{1}{(\sin x)^{-\sin(\cos x)}}\,dx$$
but I don't think this is going to help. Any help is appreciated. Thanks!","['definite-integrals', 'trigonometry', 'calculus', 'integration']"
814038,Is $\dot u/\dot \phi$ is the same as $\mathrm du / \mathrm d\phi$?,"I have two functions $u$ and $\phi$ given. I am not sure what they depend on, but I think that it is a common variable $\tau$. So $u(\tau)$ and $\phi(\tau)$. Then $\dot u$ is the derivative of $u$ with respect to $\tau$. The derivation of a problem works if
$$\frac{\dot u}{\dot \phi} = \frac{\mathrm du}{\mathrm d\phi}.$$ Is that legitimate? Within thermodynamics, where an equation of state like $f(u, \phi) = 0$ holds, I learned that I the reciprocal of a derivative is the derivative the other way around, allowing to “cancel chain rules”. I am not sure whether this would hold here as well. This is probably just a duplicate of how to calculate $\frac{d\dot{x}}{dx}$ ? I can just cancel the $\mathrm d\tau$?",['derivatives']
814082,Computing the Zariski cotangent space,"I'm an extreme beginner with algebraic geometry and am trying to get used to things. Say I have some (algebraically closed) field $k$, in $k^2$ I want to compute the Zariski cotangent space, let's say of something simple, $V(Y-X^2)$, at the origin. The definition I have is that it is the quotient $\mathfrak{m}_{(0,0),V}/\mathfrak{m}_{(0,0),V}^2$ where $\mathfrak{m}_{(0,0),V}$ is the unique maximal ideal (consisting of rational functions which vanish at the origin) of the local ring of $V$ at $(0,0)$, $\mathcal{O}_{(0,0),V}$ (consisting of those rational functions that are defined at the origin). I'd like to do the computation directly using this definition (rather than the multivariable calculus way I've been seeing more often). So to get this I first think about what $\mathcal{O}_{(0,0),V}$ looks like. This will be the rational functions which are (equivalent to a) quotient of polynomials modulo $(Y-X^2)$, say $g(X,Y) + (Y-X^2)$ and $f(X,Y) + (Y-X^2)$ where the latter is the denominator, such that $f(0,0) + (Y-X^2) \neq 0$ in $k[X,Y]/(Y-X^2)$ which is the same as saying $f(0,0) \neq 0$ in $k$, so we're looking at quotients where the constant term of $f$ is non-zero. Now for $\mathfrak{m}_{(0,0),V}$. Here by similar reasoning we're looking for quotients where the numerator polynomial has zero constant term and the denominator polynomial has non-zero constant term as before. I can't see any nice descriptions coming here, nice enough for me to compute the quotient $\mathfrak{m}_{(0,0),V}/\mathfrak{m}_{(0,0),V}^2$. I can see that the coordinate ring $k[X,Y]/(Y-X^2)$ is isomorphic to $k[X]$ and so by passing to there perhaps things would simplify but doing this I get the exact same things as before except now the polynomials are in just the one variable. Please help.","['affine-geometry', 'ideals', 'algebraic-geometry']"
814092,Prove that any unbounded sequence has a subsequence that diverges to $∞$.,"To prove that any unbounded sequence has a subsequence that diverges to ∞, is it enough to say that you can take a subsequence $(a_{m(k)})$ where $m(k)=k$, as you know that this diverges to infinity, you are done?","['sequences-and-series', 'proof-verification', 'real-analysis', 'analysis']"
814127,Can a bijection be constructed between $\mathbb{Q}$ and $\mathbb{R}$,"Can a bijection be constructed between $\mathbb{Q}$ and $\mathbb{R}$, such that $f:\mathbb{Q} \to \mathbb{R}$ is a bijective function? I understand that there exists no bijection between $\mathbb{N}$ and $\mathbb{R}$, and that the real numbers are not a countable set, however, since the rational numbers form a dense subset of the real numbers, I wondered if some bijective function might exist?","['elementary-set-theory', 'functions']"
814149,DeRham Cohomology of the Circle and the Torus,"I want to compute the first DeRham cohomology group of the circle. In symbols $H^1_{dR}(S^1)$. Let $p(x)=e^{ix}$ the map from $\mathbb{R}$ to the circle $S^1$, $\Omega^1(S^1)$ the set of all $1$-forms on $S^1$. Then for $\alpha\in\Omega^1(S^1)$ we have $p^*\alpha=f(t)dt$ for some function $f$. I want to deduce an isomorphism $\psi:H^1_{dR}(M)\rightarrow\mathbb{R}$. Therefore define $\tilde{\psi}:\Omega^1(S^1)\rightarrow\mathbb{R}$ by $\tilde{\psi}(\alpha)=\int_0^{2\pi}f(t)$. The claim is that this determines an isomorphism $\psi:H^1_{dR}(S^1)\rightarrow\mathbb{R}$. I already show that this map $\psi$ is well-defined and $\mathbb{R}$ linear. I now have to show that if $\psi(\alpha)=0$ that this implies that $\alpha$ is exact. I think you have to consider the function $p^*g(t)=\int_0^tf(\tau)d\tau$ but I don't see how. Can someone say me how to get the conclusion I want? Does all this imply directly that we have the isomorphism? Can i also do the same argument for $H^1_{dR}(S^1\times S^1)$?","['differential-topology', 'differential-geometry']"
814162,Find $\lfloor {\alpha}^6 \rfloor$,"If $\alpha$ is a real root of the equation $$x^5-x^3+x-2=0$$ find the value of $\lfloor {\alpha}^6 \rfloor$. This one totally stumped me. We are asked to calculate $\lfloor {\alpha}^6 \rfloor$ without actually calculating the root or using wolfram alpha or any other calculator. I found that the above equation has only one real root by sketching its graph using calculus. I was also able to use the intermediate value theorem to conclude that $1<\alpha<2$ , but this is of little use while calculating $\lfloor {\alpha}^6 \rfloor$. Please help!","['algebra-precalculus', 'roots', 'polynomials']"
814174,Weak topology is not metrizable: what's wrong with this proof?,"Let $(X,\|\cdot\|)$ be an infinite-dimensional normed vector space. Suppose that the weak topology of $X$ is metrizable by a metric $d$. 
Denote by $B^d(x,r)$ the open balls with respect to $d$; they are therefore weakly open. We have that for every $n$ the ball $B^d(0,\frac{1}{n})$ contains a non-trivial subspace. We could then argue as follows: Choose in each $B^d(0,\frac{1}{n})$ an $x_n$ such that $\|x_n\|=n$. We have $x_n\rightharpoonup x$  but $\|x_n\|\to \infty$. Which is an absurd, because we know that the sequence $(\|x_n\|)_{n=1}^\infty$ must be bounded. My question lies in the fact that in the Brezis book (Exercise 3.8) there is a proof which uses Baire's theorem! I don't know why they use such a complicated demonstration when there is so much simpler proof, if my proof is correct of course.","['general-topology', 'weak-convergence', 'proof-verification', 'real-analysis', 'functional-analysis']"
814192,"N/C theorem : If $\Psi$ is a homomorphism, then $N(H)/ C(H) ~\approx~ \Psi[N(H)]$. Is $\Psi[N(H)]$ a subgroup of $\operatorname{Aut}(H)$","If $H$ is a subgroup of $G$ , then if $N(H) = \{g \in G~|~gHg^{-1}=H\} ; ~~C(H) = \{g \in G ~|~ ghg^{-1}=h ~\forall~h \in H\}$ , then I have proved that : $\Psi: N(H) \rightarrow \operatorname{Aut}(H)$ given by $\Psi(n) = nhn^{-1} ~\forall~h \in H,~ n \in N(H)$ is a homomorphism and its kernel is $C(H)$ Hence, by the first isomorphism theorem, $N(H)/ C(H) ~\approx~ \Psi[N(H)]$ I am confused how is $\Psi[N(H)]$ a subgroup of $\operatorname{Aut}(H)$ as per the statement of the $N/C$ theorem. I know that $Inn(H)$ is a subgroup of $\operatorname{Aut}(H)$ Is $\Psi[N(H)]$ a subgroup of $\operatorname{Inn}(H)$ by any chance? Help will be appreciated. Thank you.","['automorphism-group', 'group-theory', 'abstract-algebra']"
814195,Explicit solution for this ODE,"I've recently come across a very simple ODE in my work: $$x'(t) = 1 + \frac{x}{t}$$ Obviously, if the constant were not there then the solution would be easy to obtain by the usual ``separate and integrate'' trick. I was thinking that there must be a simple closed form for the solution, but I don't see what it would be. Motivation: there will surely be others, but this parametrizes the curve of discontinuity that naturally arises from certain initial conditions for a Riemann problem for the Burgers equation. Is there a trick to solve something like this?","['ordinary-differential-equations', 'calculus']"
814196,Cutting a strangely shaped cake in half,"You have baked a rectangular sheet cake for your two brothers, and are about to cut it and serve it to them when the dog eats a rectangular portion of the cake. Now the cake looks a little like this: Your job now is to cut the cake so that each brother gets the same amount of cake. This is of course a three dimensional cake, but cutting the cake parallel to the top is not allowed, because each brother need to get the same amount of frosting. You are given only string, and have no measuring tools, though you can mark points on the outside of the cake. Usually I give some ideas on how I might solve this problem, but for this particular one, I have very few. I've given some variables to the sides, and figured out how much cake each brother is supposed to get, but I can't for the life of me figure out how to cut it. Any help would be appreciated.","['geometry', 'area']"
814218,"Compute $F_{1000} \bmod 1001$, where $F_n$ denote the Fibonacci numbers","Compute $F_{1000} \bmod 1001$, where $F_n$ denote the Fibonacci numbers. I have tried using the fact that $F_{n^k} \bmod F_n = 0, k=1,2,3,...$ but that doesn't get me anywhere. Thanks!","['fibonacci-numbers', 'modular-arithmetic', 'discrete-mathematics']"
814268,"a ""natural"" real number that is not computable","Most of the examples of non-computable real numbers use some kind of a diagonalization construction over some turing computable model of computation. See Are there any examples of non-computable real numbers? . I want to know if there are ""natural"" real numbers that are not computable. I'm having difficulty in formalizing what I mean by ""natural"".
Here is a necessary condition for naturality: The description of that number should not mention any turing computable model of computation. Ideally, this number should have existed in the literature even before Turing invented Turing machines.
Somehow this is analogous to the way Solomon Feferman says: Finally, we must take note of the fact that up to now, no previously (w.r.t. the day Gödel announced his incompleteness theorems) formulated open problem from number theory or finite combinatorics, such as the Goldbach conjecture or the Riemann Hypothesis or the twin prime conjecture or the P=NP problem, is known to be independent of the kinds of formal systems we have been talking about,not even of PA. in http://math.stanford.edu/~feferman/papers/newaxioms.pdf .
The parts in parenthesis have been added by me to put his quote in proper context.
My question was partly motivated by this quote.","['logic', 'constructive-mathematics', 'real-analysis']"
814272,What is the dual space in the strong operator topology?,"Let $X$ be a Banach space, the strong operator topology on the space of bounded linear operators $\mathcal{B}(X)$ is defined by the family of continuous semi-norms $A\to\|Ax\|$, $x\in X$. What is the dual space to $\mathcal{B}(X)$ in this topology? Can it be identified with something recognizable at least when $X$ is Hilbert or reflexive? For the weak operator topology I think that the dual space can be identified with the space of finite rank operators. I'll appreciate any references. I am also interested in similar questions for the ultraweak and the ultrastrong topologies.","['operator-theory', 'hilbert-spaces', 'functional-analysis', 'banach-spaces']"
814292,Probability of a gaussian distribution in another gaussian distribution,"Assume we have a Gaussian distribution $p(x) \sim  \mathcal{N}(\mu_p,\Sigma_p)$ For any point $X$, it is easy to compute the density of $x$ in $p$:
$$p(x) = \frac{1}{|2\pi \Sigma_p|^\frac{1}{2}}e^{-\frac{1}{2}(x-\mu_p)^T\Sigma_p^{-1}(x-\mu_p)}$$ Now suppose that we have another Gaussian distribution  $q(x) \sim  \mathcal{N}(\mu_q,\Sigma_q)$ ** What is the expectation of q(x) in p(x) . I mean, if we randomly sample a point $x$ from P, what is the **expected probability of x in Q? NOTE: I need the solution in closed form. Thanks!","['statistics', 'normal-distribution', 'probability-distributions']"
814308,Inverse Function Theroem in $R^1$,"I have a question about the inverse function theorem in R1. The version of the theorem that I know says: Let $y = f(x)$ be a continuously differentiable function defined on an open interval $I$
 in $R$. If $f'(x_0) \neq 0$ at some point $x_0$ in $I$, then there exists a function $f^{-1}(x) $ defined on some neighbourhood $N$ of $f(x_0)$ such that $f(f^{-1}(y)) = y$ for each $y \in N$. I want to relax the hypotheses of the theorem a little bit, so the following questions came to my mind. Instead of $f(x)$ being continuously differentiable on the whole interval $I$, if I only know that $f(x)$ is differentiable at the point $x_0$ and $f'(x_0) \neq 0$, would I still be able to find an inverse function $f^{-1}(x)$? In other words, can I guarantee the existence of an (local) inverse function just from the differentiability of the function at the single point and its derivative there not equal to zero?","['derivatives', 'real-analysis']"
814311,Proof regarding derivatives and Mean Value Theorem.,"Original question: $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$. Show that for any $c \in (a,b)$ that is not a point of maximum or minimum for $f'$, there exist $x_1, x_2 \in (a,b)$ such that $f'(c)=\frac{f(x_2)-f(x_1)}{x_2 - x_1}$ What I have done: We argue by contradiction. Suppose there doesn't exist such $x_1$ and $x_2$, then $\forall x_1,x_2 \in (a,b)$, we have $f'(c)=\frac{f(x_2)-f(x_1)}{x_2 - x_1}$. By assumption, since $f$ is differentiable on $(a,b)$, then according to Mean Value Theorem, $\exists k \in (a,b)$ such that $f'(k)=\frac{f(x_2)-f(x_1)}{x_2 - x_1}$. Since $f'(c) \ne f'(k)$, we must have either $f'(c) < f'(k)$ or $f'(c) > f'(x)$. But we know that $c$ is not a point for maximum or minimum for $f'$, so this is a contradiction. My concern: Is it possible that we are missing some of the $k$ in $(a,b)$? Because if that's the case, then we wouldn't end up with a contradiction any more. I'm thinking since the choise of $x_1, x_2$ are arbitrary and since $k$ must lie between them, so we should be able to capture all the $k$'s, but how should I formalize that?","['calculus', 'proof-verification', 'real-analysis', 'proof-writing', 'derivatives']"
814320,"Why does restriction of Weil divisors ""clearly"" preserve principal-ness?","( EDIT June 4, 2014: I've reposted this to MathOverflow due to lack of response here. ) Let $Q$ be the subvariety of $\mathbb{P}^3$ given by $\{x_0x_1=x_2x_3\}$. Given a prime divisor $Y$ of $\mathbb{P}^3$, Hartshorne (II, Example 6.6.2) defines a divisor $Y\cdot Q$ on $Q$ as follows: [O]n each standard open set $U_i$ of $\mathbb{P}^3$, $Y$ is defined by a single function $f$; we can take the value of this function (restricted to $Q$) for each valuation of a prime divisor of $Q$ to define the divisor $Y\cdot Q$. He then extends this linearly to each divisor $D$ of $\mathbb{P}^3$ (ignoring the $Q$-components) . My Question: Hartshorne then says that this ""clearly"" takes principal divisors to principal divisors. However, I'm unable to see why this doesn't require a proof. Maybe the proof I came up with (see below) is making things to difficult? My Proof: (I write $\operatorname{div}(f)$ to mean the divisor of $f$. For any divisor $D$ and any prime divisor $Z$, I denote by $D(Z)$ the coefficient of $Z$ in $D$.) Let $F\in K^\times$, where $K$ is the function field of $\mathbb{P}^3$. Assume $v_Q(F)=0$, so that $F$ restricts to a well-defined non-0 element $f$ of $K(Q)$. Claim: For any prime divisor $Z$ of $Q$, 
$$ \operatorname{div}(f)(Z) = (\operatorname{div}(F)\cdot Q)(Z).$$
$\because$) Have $Z\cap Q_i\neq \emptyset$ for some $i$, where $Q_i=Q\cap U_i$. Write $A=\mathcal{O}(U_i)$. Without loss of generality, assume $F\in A$. Let $I$ be the ideal of $Q_i$ in $A$, and let $\mathfrak{p}$ be the ideal of $Z$ in $A/I$. Let $Y_1,\ldots,Y_r$ be the (distinct) prime divisors of $\mathbb{P}^3$ containing $Z$ such that $n_j=v_{Y_j}(F)\neq 0$. Note that since $Z\cap Q_i\neq \emptyset$, each $Y_j$ intersects $U_i$; write $Y_j\cap U_i=\{G_j=0\}$, where $G_j\in A$ is a nonconstant irreducible. Set $g_j=G_j|_{Q_j}=G_j+I$. Then 
$$ (\operatorname{div}(F)\cdot Q)(Z) = \sum_{j=1}^r n_j v_Z(g_j) = v_Z(g),$$
where $g=g_1^{n_1}\cdots g_r^{n_r}$. On the other hand, 
$$  \operatorname{div}(f)(Z) = v_Z(f).$$
Thus, we just need to show that $v_Z(f/g)=0$, i.e. that $f/g\in \mathfrak{p}$. Consider the rational function $G=G_1^{n_1}\cdots G_r^{n_r}$. By definition of the $G_j$'s and $n_j$'s,
$$ F= HG $$
for some $H\in A$. Since $F\notin I$ and $I$ is prime, $H\notin I$; so, $h=H|_{Q_i}$ is a well-defined non-0 regular function and is equal to $f/g$. If $H\in A^\times$, we're done. Otherwise, if $h\in \mathfrak{p}$, then $H\in P$, and so $P$ contains a minimal prime $P'$ of $(H)$. By Krull's PID Theorem, $P'$ must have height 1. But then $Y=V(P')$ is a prime divisor of $\mathbb{P}^3$ containing $Z$ with $v_Y(F)\neq 0$. Since $Y\neq Y_j$ for all $j$ by construction, we have a contradiction. Thus, $f/g=h\notin \mathfrak{p}$.",['algebraic-geometry']
814323,"Property (ii) of increasing functions in Chung's ""A Course in Probability Theory""","I am a bit confused by the line of reasoning on page 2 of Kai Lai Chung's ""A Course in Probability Theory"" . In particular, he is considering a real-finite valued function $f$ which is defined and increasing on $(-\infty,+\infty)$. That is, for any two real numbers $x_1$ and $x_2$, $$
x_1<x_2 \Rightarrow f(x_1) \le f(x_2).
$$ Next, he goes on to state and prove a number of properties of such functions (with an eventual eye on distribution functions). The first property is stated as: (i) For each x, both unilateral limits $$
\lim_{t \uparrow x} f(t) = f(x-) \quad \text{and} \quad \lim_{t \downarrow x} f(t) = f(x+) $$ exist and are finite. Furthermore the limits at infinity $$
\lim_{t \downarrow -\infty} f(t) = f(-\infty) \quad \text{and} \quad \lim_{t \uparrow +\infty} f(t) = f(+\infty)
$$
  exist; the former may be $-\infty$, the latter may be $+\infty$. This follows from monotonicity; indeed
  $$
f(x-) = \sup_{-\infty<t<x} f(t) \, , \; f(x+) = \inf_{x<t<+\infty} f(t).
$$ I understand (i) without any problems: the set $S = \left\{ {f(t) \mid -\infty<t<x}\right\}$ is bounded above by $f(x)$, since $f$ is increasing by hypothesis, and $S$ is nonempty implying that that the supremum of $S$ exists in $\mathbb{R}$. Furthermore, $\sup S$ can be shown to be equal to the left-limit in terms of the usual $\epsilon \text{-}\delta$ definition of one-sided limits by invoking the approximation property of the supremum and manipulating inequalities. A similar argument applies to the infimum of $f$ over $(x,\infty)$. It is the next stated property and its supporting text that seems confusing/misleading: (ii) For each $x$, $f$ is continuous at $x$ if and only if $$ f(x-) = f(x) = f(x+). $$ To see this, observe that the continuity
  of a monotone function $f$ at $x$ is equivalent to the assertion that
  $$ \lim_{t \uparrow x} f(t) = f(x) = \lim_{t \downarrow x} f(t). $$ First of all, this ""observation"" is true not just for monotone functions, but in fact for all functions (a function is continuous at a point iff its limit exists and its limit equals the function's value at that point; the limit of a function exists iff the left- and right-limits of the function exist and are equal). So, it seems misleading to state the ""observation"" in this manner; but not incorrect per se, since it is also true for monotone functions in particular. Furthermore, since $f(x+)$ and $f(x-)$ are just a notational shorthand for the one-sided limits, the first sentence in (ii) seems to be immediate from this observation. However, he goes on to state: By (i), the limits above exist as $f(x-)$ and $f(x+)$ and $$ f(x-) \le f(x) \le f(x+) $$ from which (ii) follows. Now I understand the inequality, since $f(x)$ is an upper bound for the set $S$ described above and similarly a lower bound for an analogous set whose infimum gives $f(x+)$. However, I do not see why we need to bother considering this inequality to show (ii). As mentioned, it seems like this follows immediately from the definition of continuity (for monotone functions or otherwise) and the fact that $f(x+)$ and $f(x-)$ are just symbols that are used to denote the left- and right-limits when they exist (which they always do for monotone functions on all of $\mathbb{R}$). What am I missing?","['probability-theory', 'real-analysis']"
814332,$f'$ strictly increases and $f'(c)=0$. There exist $x_1 < c < x_2$ such that $f'(c)=\frac{f(x_2)-f(x_1)}{x_2 - x_1}$,"Question: Let $f$ be continuous on $[a,b]$ and differentiable on $(a,b)$. Assume that $f'$ is strictly increasing. Show that for any $c\in(a,b)$ such that $f'(c)=0$, there exist $x_1, x_2 \in [a,b], x_1 < c < x_2$ such that $f'(c)=\frac{f(x_2)-f(x_1)}{x_2 - x_1}$. What I've done: We argue by contradiction. Assume that for all $x_1<c<x_2$, we have $f'(c) \ne \frac{f(x_2)-f(x_1)}{x_2 - x_1}$. Without losing generality, we assume that $f'(c) < \frac{f(x_2)-f(x_1)}{x_2 - x_1}$. If we take limit on both side, we have $\displaystyle \lim_{x_2 \to x_1} f'(c) \le \lim_{x_2\to x_1}\frac{f(x_2)-f(x_1)}{x_2 - x_1} $. ( I am not sure if this step is correct or make any sense ) So we have $f'(c) \le f'(x_1)$. But since $f'$ is strictly increasing, and we know that $x_1<c$, so this cannot be the case. Contradiction.","['proof-verification', 'proof-writing', 'real-analysis', 'limits']"
814355,Connectedness of parts used in the Banach–Tarski paradox,"A quote from the Wikipedia article ""Axiom of choice"" : One example is the Banach–Tarski paradox which says that it is
  possible to decompose the 3-dimensional solid unit ball into finitely
  many pieces and, using only rotations and translations, reassemble the
  pieces into two solid balls each with the same volume as the original. I know that at least some of the parts (called pieces here) must be non-measurable sets. I wonder if each of them can be chosen to be a path-connected set (otherwise it's really misleading to call them pieces , I think).","['set-theory', 'paradoxes', 'measure-theory', 'axiom-of-choice', 'connectedness']"
814374,"Every element of a group has order $2$. Why, intuitively, is it abelian? [duplicate]","This question already has answers here : Order of nontrivial elements is 2 implies Abelian group (5 answers) Closed 7 years ago . What is the intuition behind the fact that if every element in a group is of order $2$, we have that the group is abelian? I can prove it, but I do not know the intuition behind it.","['group-theory', 'abstract-algebra']"
814380,The shortest path connecting three points,"I have 3 points X,Y,Z, lets call them buildings. I need to find the shortest amount of path that connects the 3 buildings, these buildings can be in any sort of shape and any distance from each other, lets call the distance between each building xy, xz, yz. I know that the paths need to converge at a point, but I am unsure how to get there given the information I have. If they formed an equilateral triangle it would look like (or at least I think): X
    |           
   / \
  Y   Z But they can be in any shape and that's only one of them, I need help finding the equation(s) that will give the shortest path connecting all 3 of the buildings. I was thinking of using the Pythagorean Theorem but am not 100% sure, I was also thinking about using Lagrange Multipliers but with the information given am not sure how to implement them. I'm just looking for a push in the right direction, I don't need the full solution (it would help but not needed.) If you need any more information about the problem I can try my best but this is about all I have.","['geometry', 'multivariable-calculus', 'calculus', 'lagrange-multiplier', 'graph-theory']"
814387,Looking for a good book on Morse-Bott functions.,"I am looking for a book to study for the first time Morse-Bott functions. Does anyone know one that is easy to follow and detailed? If there is one connecting this subject with symplectic geometry, it would be useful too. Thanks!","['differential-topology', 'symplectic-geometry', 'differential-geometry', 'morse-theory']"
814410,How does $\frac{t^2}{t+1}$ equal $t-1+\frac{1}{t+1}$?,I do the long division: 1: t+1 goes into $t^2$ t times 2: Subtract $t^2$ + 1 from $t^2$ and get -1 3: Answer:  t - $\frac{1}{t+1}$ Am I missing something here?,"['algebra-precalculus', 'polynomials']"
814435,A problem based on pigeonhole,"Numbers 1 to 1994 are divided into 6 sets.Show that at least in one  group there will be two numbers whose sum is also in that group ? We can prove that at least one group will contain more than 332 elements. A set is called sum free if it DOES NOT  CONTAIN sum of any two of its elements or does not contain twice of an element
If a set contains natural numbers from 1 to $2n+1$ its sum free subsequence will contain $n+1 $elements.Or in other word if we take the last half numbers $(\frac{n}{2} $ or $\frac{n+1}{2}$ according to number of elements of the set) it will be free. But I cannot proceed further because my selection need not be consecutive numbers. I have to prove that if a set contains more than 332 numbers it cannot be sum free..But How..?","['number-theory', 'combinatorics']"
814436,Quick question on poles,"Consider this function for $0 < a < b$: $$f_{(z)} = \frac{z^4}{z^2(z-\frac{a}{b})(z-\frac{b}{a})}$$ This function has a pole of order $2$ at $z=0$, a pole of order 1 at $z=\frac{a}{b}$, but what about the pole at $z=\frac{b}{a}$? Why isn't it mentioned in the book? Here's the original question: Evaluate $$I = \int_0^{2\pi} \frac{\cos 2\theta}{a^2 + b^2 -2ab \cos \theta} d\theta$$ Then by using subsitution of $z = e^{i\theta}$ we arrive at the form above. Is the reason they are ignoring the $z=\frac{b}{a}$ term because it is greater than 1, so it lies outside the circle, where residue theorem doesn't work?","['functions', 'complex-analysis', 'contour-integration']"
814441,"Constructing a function similar to x^3 between [0,1]","I'm trying to construct a function $f$, in order to normalize a dataset(obviously where all the element come from $[0,1] \in \mathbb{R}$. The big picture is that the envisioned $f: [0,1] \rightarrow [0,1]$ pushes the values that fall to the right side of the initial average of the dataset to $1$, and similarly the values that fall to the left side of the average to $0$. But I want the function to act on the relatively very big and very small numbers in a stronger manner. So basically the function will look similar to $x^3$'s general pattern. Additionally I'd like to fix some values as follows: f(0) = 0, f(1) = 1, f(avg) = avg, where avg stand for the average of the initial dataset. Currently I'm having problem with fixing the endpoints. For instance $(x-avg)^3+avg$ would get me $f(avg)=avg$ but not the other two. I open to using some other formula as long as it adheres to my desired properties. Please let me know if something regarding the problem description is not clear.","['discrete-mathematics', 'statistics', 'functions', 'linear-algebra', 'continuity']"
814467,Eigenvalues of a symmetric matrix with Lagrange multipliers,"Problem: Using Lagrange multipliers, prove that all symmetric matrices $A \in \mathbb{R}^{n \times n}$ have all real eigenvalues. Proof: Consider $f: \mathbb{R}^n \rightarrow \mathbb{R}$ defined by $f(x) = \langle Ax,x \rangle$, where $\langle \cdot,\cdot \rangle$ is the usual intern product of $\mathbb{R}^n$ and $S^{n-1} = \{ x \in \mathbb{R}^n : \| x \| = 1 \}$. I have found that $f'(x) = 2\langle Ax,h \rangle$, but I'm stuck here. I appreciate all your comments. Thanks!!!","['matrices', 'linear-algebra', 'real-analysis', 'lagrange-multiplier']"
814482,Multiplication of odds vs. multiplication of probabilities,"I always believed that probabilities could be multiplied, until I encountered a statement in Machine Learning by Peter Flach about odds: ""Bayes’ rule tells us that we should simply multiply them: 1:6 times 4:1 is 4:6 , corresponding to a spam probability of $0.4$ ."" But converting to probabilities, $1:6 = 1/7$ and $4:1 = 4/5$ .
Multiplying the probabilities we get $4/35$ ~ $= 0.11$ Does Bayes' Theorem work differently for odds and probabilities? What seems to be the problem?","['statistics', 'bayes-theorem', 'probability']"
814495,Sphere homeomorphic to plane?,"I just took a course in general topology about a month back, and I was wondering whether it was possible to explain why the Earth seems flat from our point of view but is in fact a sphere using the concept of a homeomorphism? Is it the fact that the sphere and plane are homeomorphic to each other the reason for this?","['general-topology', 'soft-question']"
814499,"If $AB = BA^2$ and $B^5 = I,$ Then how can we prove $A^{31} = I.$","If $A$ and $B$ are two non singular matrices, $AB = BA^2$ and $B^5 = I,$ then how can we prove $A^{31} = I$ ? $\bf{My\; Trial::}$ Using $B^5 = I\Rightarrow B^5A^5 = IA^5 = A^5\Rightarrow B^4BA^2A^3 = A^5$ Now Using $BA^2 = AB$ , we get $B^4ABA^3 = A^5\Rightarrow B^4ABA^2A=A^5\Rightarrow B^4A^2BA=A^5$ I did not understand How can I prove it. plz Help me Thanks","['matrices', 'linear-algebra']"
814580,Does Hyperbolic + Not Asymptotically Linearly Stable imply Not Asymptotically Stable?,"Topic: Stability of Autonomous Non-linear ODEs I'm wondering whether having a hyperbolic critical point that's not asymptotically linearly stable (ALS) in the linearisation of a system implies that the critical point is not asymptotically stable (AS) in the full non-linear system... I know that in general, not ALS doesn't imply not AS, but it seems that the Hartman-Grobman theorem should make it true for hyperbolic critical points. I'll lay out an example, just to make it a bit clearer. Say we have the system: \begin{align}
\dot{x} &= -6y + 2xy - 8\\
\dot{y} &= y^2 - x^2
\end{align} With critical points $(-1, -1)$ and $(4, 4)$. The Jacobian is: $$
DF(x, y) = \begin{bmatrix}
	2y & 2x - 6\\
	-2x & 2y
\end{bmatrix}
$$ Now, for $(4, 4)$ the linearisation is: $$
DF(4, 4) = \begin{bmatrix}
	8 & 2\\
	-8 & 8
\end{bmatrix}
$$ Which has trace $\tau = 16$ and determinant $\delta = 80$. The eigenvalues are $8 \pm 4i$. Hence, $(4, 4)$ is hyperbolic in the linearisation and describes a spiral source. By the Hartman-Grobman theorem, we can conclude that the critical point also ""looks like"" a spiral source in the full non-linear system. My question is, in general, is it safe to conclude that the critical point is not asymptotically stable, i.e. it is not the case that solutions in some neighbourhood tend to the critical point as time goes to infinity? In this case, plotting the thing with Mathematica reveals that it is properly unstable at $(4, 4)$ (sorry about the lack of axes).","['dynamical-systems', 'nonlinear-system', 'ordinary-differential-equations']"
814599,Finding the sum of a conditionally convergent double series,"I am interested in the double series $$\sum_{m=1}^{\infty}\sum_{n=1}^{\infty}\frac{(-1)^{m+n}mn}{(m+n)^2}.$$ I believe that this series is not absolutely convergent but converges by rows or columns, $$\sum_{m=1}^{\infty}\left[\sum_{n=1}^{\infty}\frac{(-1)^{m+n}mn}{(m+n)^2}\right]=\sum_{n=1}^{\infty}\left[\sum_{m=1}^{\infty}\frac{(-1)^{m+n}mn}{(m+n)^2}\right]=S.$$ and would like to find both a proof of convergence and the value of $S$ in closed form. As a first step, I considered the double power series: $$F(x,y) = \sum_{m=1}^{\infty}\sum_{n=1}^{\infty}\frac{(-1)^{m+n}mn}{(m+n)^2}x^my^n$$ which I believe converges absolutely for $|x|,|y|<1$. For $x=y$, I was able to sum diagonally $$F(x,x) = \sum_{m=2}^{\infty}\sum_{k=1}^{m-1}\frac{(-1)^{m}k(m-k)}{m^2}x^m =\sum_{m=2}^{\infty}\frac{(-1)^{m}x^m}{m^2}\sum_{k=1}^{m-1}k(m-k)=\sum_{m=2}^{\infty}\frac{(-1)^{m}x^m}{6}\Big(m-\frac{1}{m}\Big)=\frac{1}{6}\Big[\log(1+x)-\frac{x}{(1+x)^2}\Big].$$ and find the limit $$\lim_{x\rightarrow1-}F(x,x) = \frac{1}{6}\Big(\log2-\frac{1}{4}\Big).$$ Note that the diagonal sum of $F(1,1)$ does not converge, but oscillates between $\pm \infty.$ My conjecture is that $S = \frac{1}{6}\Big(\log2-\frac{1}{4}\Big)$ but I have not found a way to directly sum by rows or columns. I also wonder if some extension of Abel's limit theorem can be applied here.",['sequences-and-series']
814662,Energy-momentum vector is orthogonal to itself,"Let the energy-momentum covector $k$ be
$k_idx^i$ in Einstein summation notation where $x^0=t$.
Let ${}^3k=k_1dx^1+k_2dx^2+k_3dx^3$ be the space part of $k$. Let $Ee^{ik_{\mu}x^{\mu}}$ be the electric field of a plane wave, where $E=E_jdx^j$. The Maxwell equation implies
$${}^3k\wedge E=-ik_0 \star_S E.$$ The subscript $S$ means that the Hodge star is only applied in the space part of Minkowski space-time. Now, the exercice in my book asks to show the following: Prove that $k_{\mu}k^{\mu}=0$. This just means that $\langle k,k\rangle =0$. And the Hodge star is also defined in terms of this inner product:
$\omega \wedge \star  \mu = \langle \omega, \mu \rangle vol$. So, I tried to take the wedge of the above equation with an appropriate 1-form, but I did not find one that worked. Another possible approach would be to apply $d$ and then take the wedge with something, but I have no intuition in which direction to go. Can someone give me a hint? Of course, a full solution is also appreciated, but I am well capable of doing calculations, so I am mainly interested in seeing what to do and why to do it.",['differential-geometry']
814665,An explanation for a Jordan normal form proof from the Kaye and Wilson book,"In this proof of Jordan normal form in the Kaye and Wilson book, then for a transformation $T$ with minimal polynomial $m(x) = (x-e)^k$, they take a basis of $\texttt{ker}\;T$, extend it to a basis of $\texttt{ker}\;T^2$, ..., extend it to a basis of $\texttt{ker}\;T^k$. They then take the elements $a_1,...,a_n$ in $\texttt{ker}\;T^k$ but not $\texttt{ker}\;T^{k-1}$ then take $b_i = T(a_i)$ and claim the $b_i$,$a_j$ form a linearly independent set, so then they extend the list of the $b_i$ so that the span of the $a_j$, $b_i$ is $\texttt{ker}\;T^{k-1}$ not $\texttt{ker}\;T^{k-2}$. They then take $c_i = T(b_i)$ and carry on this process. After the proof they say the crucial point is that the basis modification does give a basis. Then the lemma they prove is:
If $ \{u_1,...,u_r \}$ is a basis for $\texttt{ker}\;T^j$ is extended to a basis of $\texttt{ker}\; T^{j+1}$ $\{u_1,...,u_r,v_1,...,v_s\}$ and to a basis $\{u_1,...,u_r,v_1,...,v_s,w_1,...,w_t\}$ of $\texttt{ker}\;T^{j+2}$ then $\{u_1,...,u_r,T(w_1),...,T(w_t)\}$ is a linearly independent subset of $\texttt{ker}\;T^{j+1}$. I can't work out why they prove $\{u_1,...,u_r,T(w_1),...,T(w_t)\}$ is linearly independent - where does this come into the proof for Jordan normal form? For the proof for Jordan normal form surely they'd want to show that $\{w_1,...,w_t,T(w_1),...,T(w_t)\}$ is linearly independent since in the proof they claim the $b_i$,$a_j$ form a linearly independent set (in which case they wouldn't need to extend the basis of $u_i$ to a basis of $u_i$,$v_j$ and then to a basis $u_i$,$v_j$,$w_k$ - they wouldn't need the $u_i$ at all).","['jordan-normal-form', 'linear-algebra', 'proof-explanation']"
814670,Finding the number of zeros of $f(z) = z^n$ if $|f(z)| < 1 $ for all $z$ with $|z|=1$.,"Suppose $f: \overline{\mathbb{D}} \to \mathbb{C}$ is continuous, analytic
in $\mathbb{D}$ and satisfies $|f(z)|<1$ for $|z|=1$. Find the number of solutions
to the equation $f(z) = z^n$ where $n$ is a positive integer. ($\mathbb{D}$ is the unit disk). Some of my own attempts:
Using the Maximum/Minimum Principle, we can split up the the problem in $2$ parts:
Suppose $f$ is constant. It then holds that $z^n = c$ has exactly $n$ zeros because of the fundamental theorem of algebra. Suppose $f$ is not constant. It holds that $f$ has at least one zero 
in $\mathbb{D}$. It of course also holds that $z^n$ has a zero of multiplicity $n$ at the origin. I think I'm supposed to hit with stuff like Rouché's theorem, the Argument Principle or Schwartz lemma, but nothing seems to fit. Thanks in advance.","['analyticity', 'complex-analysis', 'analysis']"
814720,Square root of a Hermitian operator exists,"There are a lot of questions here about square root operators, but none of them addresses the basic question of existence, and I didn't find a very beefy section in Wikipedia talking about this, so I'll ask it here. Let $A$ be a bounded positive-semidefinite Hermitian operator on Hilbert space. The claim is that there exists a positive-semidefinite Hermitian operator $B$ such that $B\circ B=A$. I've got no idea how you would prove this. Any tips or references would be appreciated.","['operator-theory', 'linear-algebra', 'hilbert-spaces', 'functional-analysis']"
814742,Evaluating the following integral: $ \int \frac{x^2}{\sqrt{x^2 - 1}} \text{ d}x$,"For this indefinite integral, I decided to use the substitution $x = \cosh u$ and I've ended up with a $| \sinh u |$ term in the denominator which I'm unsure about dealing with: $$\int \dfrac{x^2}{\sqrt{x^2 - 1}} \text{ d}x \ \overset{x = \cosh u}= \int \dfrac{\cosh^2 u \cdot \sinh u}{\left| \sinh u \right|} \text{ d}u$$
How would I deal with the denominator?","['hyperbolic-functions', 'absolute-value', 'integration']"
814754,Inner product on $C(\mathbb R)$,"With axiom of choice it is possible to construct an inner product on $C(\mathbb R)$ . My question is, is it possible to explicitly construct an inner product on $C(\mathbb R)$ ? I.e. to give a closed formula to calculate the inner product?
I know it is straight-forward to write down a scalar product using a Hamel basis. This is not the answer I am looking for. This question came to me, when a student asked me in the lecture today 'whether there are vector spaces without inner products'. So I tried to find scalar produces for function spaces. I think I managed to write one down for $L^1((0,1))$ . But I failed to construct one for $C(\mathbb R)$ .","['linear-algebra', 'inner-products', 'functional-analysis', 'axiom-of-choice']"
814755,Showing that a group with a presentation is free/not free,"Show that the group with presentation $\langle a, b, c \mid a^2cb^3\rangle$ is free with basis $\{a, b \}$. Show that the group with presentation $\langle a, b, c \mid a^3b^3 \rangle$ is not free. I'm not really sure how to get going with this - clearly I need to get rid of the relations but I didn't think Tietze transformations will be able to do that - any help appreciated!","['geometric-group-theory', 'group-theory', 'group-presentation']"
814766,Expected in-sample error of linear regression with respect to a dataset D,"In my textbook, there is a statement mentioned on the topic of linear regression/machine learning, and a question, which is simply quoted as, Consider a noisy target, $ y = (w^{*})^T \textbf{x} + \epsilon  $ , for generating the data, where $\epsilon$ is a noise term with zero mean and $\sigma^2$ variance, independently generated for every example $(\textbf{x},y)$ . The expected error of the best possible linear fit to this target is thus $\sigma^2$ . For the data $D =  \{ (\textbf{x}_1,y_1), ..., (\textbf{x}_N,y_N)  \}$ , denote the noise in $y_n$ as $\epsilon_n$ , and let $ \mathbf{\epsilon}   = [\epsilon_1, \epsilon_2, ...\epsilon_N]^T$ ; assume that $X^TX$ is invertible. By following the steps below, show that the expected in-sample error of linear regression with respect to $D$ is given by , $ \mathbb{E}_D[E_{in}( \textbf{w}_{lin} )] = \sigma^2 (1 - \frac{d+1}{N})$ Below is my methodology, Book says that, In-sample error vector, $\hat{\textbf{y}} - \textbf{y}$ , can be expressed as $(H-I)\epsilon$ , which is simply, hat matrix, $H= X(X^TX)^{-1}X^T$ , times, error vector, $\epsilon$ . So, I calculated in-sample error, $E_{in}( \textbf{w}_{lin} )$ , as, $E_{in}( \textbf{w}_{lin} ) = \frac{1}{N}(\hat{\textbf{y}} - \textbf{y})^T (\hat{\textbf{y}} - \textbf{y}) =  \frac{1}{N}  (\epsilon^T (H-I)^T (H-I) \epsilon)$ Since it is given by the book that, $(I-H)^K = (I-H)$ , and also $(I-H)$ is symetric, $trace(H) = d+1$ I got the following simplified expression, $E_{in}( \textbf{w}_{lin} ) =\frac{1}{N}  (\epsilon^T (H-I)^T (H-I) \epsilon) = \frac{1}{N} \epsilon^T (I-H) \epsilon = \frac{1}{N} \epsilon^T \epsilon - \frac{1}{N} \epsilon^T H \epsilon$ Here, I see that, $\mathbb{E}_D[\frac{1}{N} \epsilon^T \epsilon] = \frac {N \sigma^2}{N}$ And, also, the sum formed by $ - \frac{1}{N} \epsilon^T H \epsilon$ , gives the following sum, $ - \frac{1}{N} \epsilon^T H \epsilon = - \frac{1}{N} \{ \sum_{i=1}^{N} H_{ii} \epsilon_i^2 + \sum_{i,j \ \in \ \{1..N\} \ and \ i \neq j}^{} \ H_{ij} \ \epsilon_i \ \epsilon_j \}$ I undestand that, $ - \frac{1}{N} \mathbb{E}_D[\sum_{i=1}^{N} H_{ii} \epsilon_i^2] = - trace(H) \ \sigma^2 = - (d+1) \ \sigma^2$ However, I don't understand why, $ - \frac{1}{N} \mathbb{E}_D[\sum_{i,j \ \in \ \{1..N\} \ and \ i \neq j}^{} \ H_{ij} \ \epsilon_i \ \epsilon_j ] = 0$ $\ \ \ \ \ \ \ \ \ \ \ \ (eq \ 1)$ $(eq 1)$ should be equal to $0$ in order to satisfy the equation, $   \mathbb{E}_D[E_{in}( \textbf{w}_{lin} )] = \sigma^2 (1 - \frac{d+1}{N})$ Can any one mind to explain me why $(eq1)$ leads to a zero result ?","['statistics', 'regression', 'probability', 'machine-learning']"
814774,Difference between operators and functions,"Binary operators are maps on a set into itself, for example $* : R \rightarrow R$. There are also unary and trinary operators. What is the difference between, say a trinary operator of three arguments, and a function of three arguments?",['functions']
814795,Ample tangent bundle,"I am looking for definition of ample tangent bundle or positive tangent bundle 
and why on a complex manifold , positive bisectional curvature means ample tangent bundle?","['complex-geometry', 'differential-geometry', 'kahler-manifolds', 'manifolds', 'algebraic-geometry']"
814805,How do I evaluate integrals that involve the signum ($\text{sgn}$) function?,"For example, I want to evaluate $$ \displaystyle \int_{0}^{2\pi} \left| \sin x \right| \text{ d}x $$ and I already know that: $$ \displaystyle \begin{aligned} \int \left| \sin x \right| \text{ d}x & = \int \sin x \text{ sgn}\left( \sin x \right) \text{ d}x \\ & = -\cos x \text{ sgn}\left( \sin x \right) + \mathcal{C} \end{aligned}$$ How would I evaluate the definite integral involving the signum function?","['calculus', 'integration', 'definite-integrals', 'functions', 'trigonometry']"
814857,The Stable Manifold Theorem Applications,"Definition: Let $\phi_t(x)$ be the flow of the nonlinear system $x'=f(x)$. The global stable manifold of $x'=f(x)$ at $0$ is defined by: $$W^s(0)=\bigcup_{t\leq 0}\phi_t(S)$$
Where $S$ is a $k$-dimensional differentiable manifold tangent to the stable subspace $E^s$ of the linear system $x'=Ax$ where $A=Df(0)$ and $0$ is a hyperbolic equilibrium point.
Show that $W^s(0)$ is unique and invariant with respect to the flow $\phi_t(x)$ ; furthemore, for all $x\in W^s(0)$, $$\lim_{t \rightarrow \infty} \phi_t(x)=0.$$","['dynamical-systems', 'multivariable-calculus', 'nonlinear-system', 'ordinary-differential-equations', 'analysis']"
814879,Find a generator of the multiplicative group of $\mathbb{Z}/23\mathbb{Z}$ as a cyclic group,"I need to find a generator of the multiplicative group of $\mathbb{Z}/23\mathbb{Z}$ as a cyclic group. Since $\mathbb{Z}/23\mathbb{Z}$ only has $23$ elements and ord$(x)$ where $x$ is a generator must divide $23$, then does this mean the generator can only be $1$ or $23$? Or have I got the wrong idea? It would help if someone can provide the solution to this problem, I don't find hints very useful.","['cyclic-groups', 'group-theory', 'abstract-algebra']"
814882,"Prove: for $\forall x\ne 0, \cos x < 1 - {x^2\over 2} + {x^4\over 24}$","Prove: for $\forall x\ne 0, \cos x < 1 - {x^2\over 2} + {x^4\over 24}$ What I did: We can prove: $${\cos x -1 + {x^2\over 2} \over {x^4\over 24}} < 1$$ Lets define: $f(x) = \cos x -1 + {x^2\over 2}$ and $g(x)= {x^4\over 24}$ By LMVT: $${{f(x) - f(0)} \over {g(x) - f(0)}} = {f'(y)\over g'(y)} = {{-\sin y + y} \over {4x^3\over 24}} = {{-\sin y + y} \over {x^3\over 6}}\text{ where }y\in(0,x)$$ I tried to show the last expression is smaller than $1$, but without success. What's the trick? Maybe the $f(x), g(x)$ are wrong?","['functions', 'calculus', 'real-analysis']"
814906,What's the largest domain needed for $ f(x)=(x-1)^2$ to be injective?,"Given $f(x)=(x-1)^2$, to make it injective and to obtain $f^{-1}(x)$, we need to restrict the domain, either from $(-\infty, 1]$ or $[1,\infty)$. Which is the larger domain? I'm thinking that it's $(-\infty, 1]$ since $0$ is the midpoint of $(-\infty,\infty)$, it makes sense that it's the larger domain. Is my reasoning sound or is it flawed? Thanks.",['functions']
814928,Regarding a paper relating surfaces and integrable mappings,"I'm reading the paper "" A classification of two-dimensional integrable mappings and rational elliptic surfaces "". I have two questions: Let $X$ be a generalized Halphen surface (e.g. an elliptic surface), $D = -K_X$, $\omega$ a 2-form on $X$ with $Div(\omega) = -D_{red}$ and let $Q$ the root lattice defined as the orthogonal complement of $D$ with respect to intersection.  On page 5 the period mapping from $Q$ to $\mathbb{C}$ is defined as 
$\chi(\alpha) := \int_\alpha \omega $. Later on page 12 the authors use the 2-form $\omega = \frac{1}{2\pi i}\frac{dx\wedge dy}{xy}$ to compute the period mapping. I do not understand why it is possible to use this 2-form (on $\mathbb{P} \times \mathbb{P}$, defining the divisor $D'_{red}=-H_x-H_y$ on $\mathbb{P} \times \mathbb{P}$) instead of a 2-form on $X$ defining $D_{red}$.
Later in the paper (p.17 almost at the bottom) the authors even say ""The anti-canonical divisor $xy=0$"" which confuses me even more. I guess this has something to do with the fact that those forms behave well under blow ups (Since $X$ is a blow up of $\mathbb{P} \times \mathbb{P}$)? On p. 7 the mapping $\Phi :\mathbb{P} \times \mathbb{P}\rightarrow\mathbb{P} \times \mathbb{P}$ is defined via $\Phi(x,y) = (y,-x\frac{(y-a)(y-1/a)}{(y+a)(y+1/a)})$.He then describes how the ""induced bundle mapping $\Phi_*$"" acts on $Pic(X)$. What is this $\Phi_*$ and how do I calculate it? $\Phi$ induces an automorphism on $X$ and thus an automorphism on $Pic(X)$, but that's obviously not it (since this would act differently). Edit: Got some pages wrong, should be fixed. Edit2: I decided to ask this question on MO, here's the link for anyone who might be interested in this question.",['algebraic-geometry']
814995,Help Needed Showing that $\chi(\overline{G \times H}) \leq \chi(\overline{G}) \times \chi(\overline{H})$,"Where $\chi(G)$ denotes the chromatic number, $\overline{G}$ the graph complement, and $\times$ the Cartesian Graph Product: I need to show that  $(\forall G,H)( \chi(\overline{G \times H}) \leq \chi(\overline{G}) \cdot \chi(\overline{H}))$. This is a stepping stone in a proof I am writing, but I am having difficulty showing this. It would be good if I could show that $\chi(\overline{G \times H}) \leq \chi(\overline{G}) \cdot \chi(\overline{H})$ is equivalent to $\chi(G \times H) \leq \chi(G) \cdot \chi(H)$, as it is a known result (Sabidussi 1957) that $\chi(G \times H) = \max \{ \chi(G),\chi(H)\}$. However, I am not sure if those two cases are really equivalent. Specifically, I am not sure if it holds for all $G,H$ that $\overline{G} \times \overline{H} = \overline{G \times H}$. Any help?","['graph-theory', 'discrete-mathematics', 'combinatorics']"
814998,Conditional measure with respect to a sigma-algebra generated by the level sets of a function has full measure on its level set.,"Let $(X,\mathscr{B},\mu,T)$ be a measure-preserving system, where $X$ is a compact metric space, $\mathscr{B}$ its Borel $\sigma$-algebra, $\mu$ a Borel probability measure and $T$ continuous. Let $f:X \to Y$ be a measurable map where $Y$ is another compact metric space. Let $\mathscr{A}$ be the $\sigma$-algebra generated by the level sets of $f$. Denote by $\mu_x^\mathscr{A}$ the conditional measure of $\mu$ at $x$ with respect to $\mathscr{A}$. Is there any reason why for $\mu$-almost every $x$, $\mu_x^\mathscr{A}(f^{-1}(x))=1$? If the $\sigma$-algebra $\mathscr{A}$ is countably generated, then this would be true, as the atom of $x$ (the smallest element of $\mathscr{A}$ containing $x$) is contained in $f^{-1}(x)$ and $\mu_x^\mathscr{A}([x]_\mathscr{A})=1$, where $[x]_\mathscr{A}$ is the atom of $x$. But is this still true if $\mathscr{A}$ is not countably generated? Or is there a argument why the $\sigma$-algebra $\mathscr{A}$ is always countably generated? In my case the function $f$ has the following additional property: If the ergodic component of $\mu$ in $x$ is the same as the ergodic component in $y$ then $f(x)=f(y)$, i.e. the function $f$ depends only on the ergodic components. By this we get that the conditional measure are invariant under $T$, but I don't think (or I just don't see) how this property can be helpful to solve the above question.","['probability-theory', 'ergodic-theory']"
815004,Determine which Fibonacci numbers are even,"(a) Determine which Fibonacci numbers are even. Use a form of mathematical induction to prove your conjecture. (b) Determine which Fibonacci numbers are divisible by 3. Use a form of mathematical induction to prove your conjecture I understand that for part a that all multiples of 3 of n are even. So F(0),F(3),F(6)... I just don't understand how to prove it. For part B it is the same thing except multiples of 4 Please help, thank you!","['fibonacci-numbers', 'induction', 'discrete-mathematics']"
815058,Antiderivative of discontinuous function,"I am having confusion regarding anti-derivative of a function. $$f(x)  =
\left\{\begin{array}{ll}
-\frac{x^2}{2} + 4 & x \le 0  \\
\phantom{-} \frac{x^2}{2} + 2 & x > 0
\end{array} \right.
$$ Consider the domain $[-1, 2]$.
Clearly the function is Riemann integrable as it is discontinuous at finite number of point. However is there a function $g(x)$ such that $g'(x) = f(x) \forall x \in [-1,2] $ ?","['integration', 'real-analysis']"
815060,Proving divergence of a limit,"$(a_n)_{n\ge 1}$ be a sequence of positive reals such that $a_1+a_2+\cdots +a_n<n^2$ for all $n\ge 1$. Prove that 
$$\displaystyle \lim_{n\to \infty}\left(\frac{1}{a_1}+\frac{1}{a_2}+\cdots+\frac{1}{a_n}\right)=\infty $$
My attempt :
Suppose eventually $a_{n+1}<2n+1$ then we have our condition is satisfied but also $$\displaystyle \sum \frac{1}{a_{n+1}}>\sum \frac{1}{2n+1}$$ but the right hand side diverges. Though I am not sure if this process is correct and probably it is not but any and all help will be welcomed. Thanks in advance.","['sequences-and-series', 'limits']"
815065,Prove the convergence of integral,$$\int^{\pi /2}_{0} \frac{\ln(\sin x)}{\sqrt x}dx$$ Use the segment integral formula? The $\sqrt x$ is zero at $x=0$ and $\ln\sin x$ is $-\infty$,['integration']
815103,Harmonic Numbers series I,"Can it be shown that
\begin{align}
\sum_{n=1}^{\infty} \binom{2n}{n} \ \frac{H_{n+1}}{n+1} \ \left(\frac{3}{16}\right)^{n} = \frac{5}{3} + \frac{8}{3} \ \ln 2 - \frac{8}{3} \ \ln 3
\end{align}
where $H_{n}$ is the Harmonic number and defined as
\begin{align}
H_{n} = \sum_{k=1}^{n} \frac{1}{k} = \int_{0}^{1} \frac{1-t^{n}}{1-t} \ dt. 
\end{align}","['closed-form', 'sequences-and-series', 'catalan-numbers', 'harmonic-numbers', 'generating-functions']"
815113,Is there a general formula for estimating the step size h in numerical differentiation formulas?,"Using three-point central-difference formula $$
f^{\prime}(x_0)\approx \frac{f(x_0+h)-f(x_0-h)}{2h}
$$ and for $f(x)=\exp(x)$ at $x_0=0$ we have $$
\begin{array}{c, l, r}
   h & f^{\prime}(0) & error \\
   \hline
   10^{-01} & 1.0017 & 1.6675\times 10^{-03} \\
   10^{-02} & 1 & 1.6667\times 10^{-05} \\
   10^{-03} & 1 & 1.6667\times 10^{-07} \\
   10^{-04} & 1 & 1.6669\times 10^{-09} \\
   10^{-05} & 1 & 1.2102\times 10^{-11} \\
   10^{-06} & 1 & -2.6755\times 10^{-11} \\
   10^{-07} & 1 & -5.2636\times 10^{-10} \\
   10^{-08} & 1 & -6.0775\times 10^{-09} \\
   10^{-09} & 1 & 2.7229\times 10^{-08} \\
   10^{-10} & 1 & 8.2740\times 10^{-08} \\
   10^{-11} & 1 & 8.2740\times 10^{-08} \\
   10^{-12} & 1 & 3.3389\times 10^{-05} \\
   10^{-13} & 9.9976\times 10^{-01} & -2.4417\times 10^{-04} \\
   10^{-14} & 9.9920\times 10^{-01} & -7.9928\times 10^{-04} \\
   10^{-15} & 1.0547 & 5.4712\times 10^{-02} \\
   10^{-16} & 5.5511\times 10^{-01} & -4.4489\times 10^{-01} \\
\end{array}
$$ From $10^{-1}$ down to $10^{-5}$ the results are evident (because the rate of convergence of the three-point central-difference formula is $O(h^2)$). As you see because of the round-off error, the error deteriorate rapidly as $h$ decrease. My question is: Is there a general formula for estimating the step size $h$ in numerical differentiation formulas to get the best result?","['derivatives', 'numerical-methods']"
815138,"Derivative of determinant, which is correct?",I've seen two different results on the derivatives of determinants of matrices: $$\frac{\partial |X|}{\partial X_{ij}}=X_{ij}.\tag1$$ $$\frac{\partial\det(X)}{\partial X}=|X|(X^{-1})^{T}.\tag2$$ These seem to imply different things. Which is right and why? Can't find it proven anywhere.,"['linear-algebra', 'derivatives']"
815166,$\operatorname{Aut}(A_4)\simeq S_4$,"I have to prove that $\operatorname{Aut}(A_4)\simeq S_4$. If $G$ is a finite group, $p$ divides $|G|$, $n=n_p(G):=|\operatorname{Syl}_p(G)|$ then we know that $\operatorname{Aut} G\le S_n$. I used this to prove that $\operatorname{Aut}(A_4)\le S_4$, since $n_3(A_4)=4$. But now, how can I show the inverse inclusion, i.e. that $S_4\le \operatorname{Aut}(A_4)$? I know that $S_4\simeq \operatorname{Aut}(S_4)$ but I don't know if it could help. Any hint would be appreciated! Thanks!",['group-theory']
815170,Does the Hodge star operator commute with 0-forms?,"Consider the three differentiable functions $\alpha,\beta,h: \mathbb{R}^2 \to \mathbb{R}$ and the associated 1-forms $d\alpha, d\beta$, with $d$ being the exterior derivative. Let $*$ be the Hodge star operator. Then, is the following relation true: $$*(h d\alpha \wedge d\beta) = h *(d\alpha \wedge d\beta),$$ namely that the 0-form $h$ can be swapped with the Hodge star operator? If so, how can one prove it in general?",['differential-geometry']
815240,"How to integrate this formula with secant, exponential, and tangent?",How to integrate this? $$\int \sec^2(3x)\ e^{\large\tan (3x)}\ dx$$,"['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
815256,Tricks to solve inequalities,"I am wondering if there are some tricks to solve inequalities which are not manageable analytically. For example consider the inequality (say we restrict on positive $x$): $\displaystyle
\frac {\text e^{-x^2}}{x^2}<1
$ Let's say I want to find a good lower bound for $x$ which solves this inequality. But I can not solve it analytically to end up with a statement like: For all $x>...$ the inequality is fulfilled. Unfortunately I just know the two usual tricks like estimate $\frac {\text e^{-x^2}}{x^2}$ against some other function which is manageable. For example I know that $\frac {\text e^{-x^2}}{x^2}<1/x^2$ and $1/x^2<1$ for all $x>1$. So $x>1$ gives me a lower bound for $x$. try some value and use the fact that $\frac {\text e^{-x^2}}{x^2}$ is strictly decreasing. So I find that $x=0.8$ solves the inequality which gives me the slightly improved bound: $x>0.8$ Are there some more tricks? Some general treatments how to deal with inequalities where I have a precise expression of $x$ but can not solve it for $x>...$ analytically?","['estimation', 'inequality', 'real-analysis', 'analysis']"
815300,Number Theory or Algebra?,"Prove that if $4^m-2^m+1$ is a prime number, then all the prime divisors of $m$ are smaller than $5$ I initially thought about putting $4^m-2^m+1=p$ where $p$ is some prime and after eliminating initial cases of $p<5$ , setting $p=6k \pm 1$ . However, since I'm just a beginner in Number Theory,  I couldn't figure out anything else. What is more surprising that my teacher gave this problem in an Algebra worksheet, so perhaps there is some good algebraic way to do this. So, thinking on Algebraic lines, I made a substitution $2^m=x$ and did some manipulations to the quadratic thus made. However, still no luck (despite the fact that I'm pretty confident about my Algebraic skills) I look forward for some help with this one. Any (or both) method will do. Thanks in advance!","['elementary-number-theory', 'algebra-precalculus', 'prime-numbers']"
815311,"Topologists glueing, cutting and so on. When is this rigorous?","I often see that things in topology are explained very non-rigorously recently.
Thereby I mean that it is said that we can cut something and glue something together and so on in order to identify two objects. Sure, in general one would need to write down a map, but this is often very very cumbersome. Therefore, I understand that people tend to illustrate things. Despite, we never talked about actual does and dont's and I would like to understand the following. How do I know that I am allowed to cut something or glue something together? Where do I need to pay attention?","['general-topology', 'calculus', 'real-analysis', 'analysis']"
815315,What does a dot in a circle mean?,"I'm looking at some formulas involving matrices (in the context of machine learning, but I'm not sure it's relevant) and I came across $\odot$. What could this mean? The context is $M \odot N$, where $M$ is a matrix and $N$ might be a vector, or a matrix, or a scalar, it's a bit dense so it's hard to tell. I have reason to believe it may be the Hadamard product , is there anything else it could mean?","['notation', 'linear-algebra']"
815332,Solve multivariable limit,"$$\lim_{(x,y) \to (0,0)} \frac{x^3 + y^4}{x^2 + y^2}$$ I am almost sure it is equal to $0$ but I can't prove it. Please give me some hint.","['multivariable-calculus', 'calculus', 'limits']"
815350,Expected time to completely cover a square with randomly placed smaller squares,"Suppose I have the unit square $[0,1]^2$ and I choose a point $(x_1, y_1)$ randomly in a uniform manner inside $[0,1]^2$ and draw a filled in square of side length $1/N$ with center $(x_1, y_1)$. And suppose I do this again and again, picking points $(x_n, y_n)$ and filling in squares with side length $1/N$. What is the expected time $T(N)$ it takes to completely fill in the unit square? Restated somewhat more formally, if $S_N(x,y) = [x-2/N, x+2/N] \times [y-2/N, y+2/N]$, then I am asking for $X_i$, $Y_i$, I.I.D. and uniformly distributed and $T$ the minimal $n$ such that $[0,1]^2 \subseteq \cup_{i=1}^n S_N(x_i, y_i)$, what is the expected value of $T$? I'll probably be happier with a less technical answer at the expense of nailing down the exact function $E[T(N)]$. Clearly there is the lower bound $E[T(N)] \geq N^2$. But, this problem may be simple enough, compared to the circle problem mentioned in the comments, to get an exact solution. P.S. I was motivated to ask this question from some fooling around I have done with programming. Specifically, this image which is composed in the manner just described but using many, many circles. Notice the gaps in the circles even though there is a lot of overlap elsewhere.","['geometry', 'coupon-collector', 'probability', 'geometric-probability']"
815377,Resolvent: Definition,"Given a Banach space $E$ . Consider linear operators: $$T:E\supset\mathcal{D}(T)\to E:\quad T(\kappa x+\lambda y)=\kappa T(x)+\lambda T(y)$$ (No other assumptions on the operator!) Denote for shorthand: $$R_\lambda:\mathcal{R}_\lambda\to\mathcal{D}_\lambda:\quad R_\lambda:=(\lambda-T)^{-1}$$ The standard definition for the resolvent set: $$\rho(T):=\{\lambda\in\mathbb{C}:\mathcal{N}_\lambda=(0),\mathcal{R}_\lambda=E,\|R_\lambda \|<\infty\}$$ An alternative definition for the resolvent set: $$\rho(T):=\{\lambda\in\mathbb{C}:\mathcal{N}_\lambda=(0),\overline{\mathcal{R}_\lambda}=E,\|R_\lambda\|<\infty\}$$ (See Werner or Weidmann resp. Kubrusly or Kreyszig.) Do these definitions really agree? Clearly for closed operators they do.","['operator-theory', 'spectral-theory', 'functional-analysis', 'banach-spaces']"
815401,What is the meaning of $dA$ in double integrals?,"What is the meaning of $dA$ in $\iint_E\dots dA$, where $E$ is a region in the $xy$ plane? In some integrals   we use $dA=dx\,dy$, but in others $dA=\hat{k}\,dx\,dy$. (Here $\hat {k}$ is the unit vector in the $z$ direction.) Why this difference? Also, is there a general formula for $dA$?","['vector-analysis', 'multivariable-calculus', 'integration']"
815418,Why does $\sqrt{n\sqrt{n\sqrt{n \ldots}}} = n$?,"Ok, so I've been playing around with radical graphs and such lately, and I discovered that if the nth x = √(1st x √ 2nd x ... √nth x); Then $$\text{the ""infinith"" } x = x$$ Example: $$\sqrt{4\sqrt{4\sqrt{4\sqrt{4\ldots}}}}=4$$ Try it yourself, type calc in Google search, hit  then a number, such as $4$, and repeat, ending with $4$, (or press the buttons instead). I'm a math-head, not big enough though, I think this sequence is divergent or convergent or whatever, too lazy to search up the difference. However, can this be explained to me? Like how the Pythagorean Theorem can be explained visually.","['radicals', 'nested-radicals', 'sequences-and-series']"
815432,What does mod and congruence mean in algebra.,I have sometimes seen notations like $a\equiv b\pmod c$. How do we define the notation? Have I understood correctly that $c$ must be an element of some ring or does the notation work in magmas in general?,"['notation', 'modular-arithmetic', 'ring-theory', 'congruence-relations', 'abstract-algebra']"
815438,CW complex adjunction map,"In topology we defined a quotient topology for glueing in the following way:
Let $(X,O)$ and $(Y,O)$ be topological spaces and $f:A \subseteq X \rightarrow Y$ a continuous map, then we have that $X \cup_f Y = (X \cup Y)/(a \tilde \  f(a))$ is a quotient space. So far so good. Now, we had to deal with CW complexes. I know the definition, but I don't know how this concept is used to build up a CW complex. Let's take the n-sphere. The only thing I know is that this concept of adjunction is used to build CW-structure, but how exactly is that done? Wikipedia says that we have one 0-cell $e_0$ and one n-cell $e_n$. It does not say how exactly these two look like. I guess $e_0$ is just the northpole and $e_n$ the rest. Actually, if I am correct so far, we don't need the concept of adjunction because we could just write down a homeomorphism $\phi : B(0,1) \subset \mathbb{R}^n \rightarrow S^{n}\backslash\{(0,...,0,1\} \subset \mathbb{R}^{n+1}.$ Something like a stereographic projection should do this(although I did not really think about the details), but how would one build up this complex with the use of adjunction maps?","['calculus', 'algebraic-topology', 'real-analysis', 'cw-complexes', 'analysis']"
815451,What is the Atiyah-Singer index theorem about?,"I was just a little bit curious about the general statement of this theorem. Honestly, I am not at all interested in fully understanding this, so it is not that I am too lazy to read plenty of books about it, but I would like to know a little bit more, what this means. Therefore I would like to go with an example: Let $(Tf)(x):= \frac{df}{dx}(x)+\sin(x)f(x)$ be a differential operator on $[0,L]$ for some $L \>>0$ . Apparently, the first question would be: Is this operator Fredholm? I do understand what 
it means for an operator to be Fredholm and I understand the definition of the Fredholm index, but I don't see whether this one actually is such an example of a Fredholm operator. In case that this is true. Where does topology come into play? I know the definition of an index for a path, but this topological index seems to be different. Maybe this example is not that good, as we are not studying something on any abstract manifolds, but still, could anybody elaborate on this?","['general-topology', 'algebraic-topology', 'real-analysis', 'analysis', 'functional-analysis']"
815494,"Integrating a discrete 3D surface, in spherical coordinates","I have an matrix which contains height information for a sheet suspended in air. Like a checkerboard, each value in the matrix represents a sampled height. Here's the hard parts: the data in the matrix is recorded in spherical coordinates (azimuth and elevation) at a distance R. Here is an example of a simple matrix: Two questions: How can I compute the volume under this 3D surface? How can I compute the surface area?","['discrete-mathematics', 'spherical-geometry', 'matrix-calculus', 'area', 'numerical-methods']"
815502,Hook Length Formula and Triangular Number,"Show that the number of odd hook lengths minus the number of even hook lengths of a partition $\lambda$ is a triangular number. My attempt: Catalan number is equivalent to the hook-length formula so I tried using it to derive to the triangular number $k(k+1)/2$ but I am not so sure what to do next. Please show me how to do it, if there's any better way. Thanks in advance.",['combinatorics']
815571,Integral $\int^{ \pi /2}_{0} \ln (\sin x)\ dx$ [duplicate],This question already has answers here : Computing the integral of $\log(\sin x)$ (11 answers) Closed 10 years ago . $$\int^{ \pi /2}_{0} \ln (\sin x)\  dx$$ The answer is $- \frac{\pi}{2} \ln 2$. I have changed it into $$\frac{1}{2} \int^{1}_{0} t d \ln t^{2}$$ But I didn't get the answer with it.,['integration']
815580,How to calculate the range of $x\sin\frac{1}{x}$?,"I want to find the range of $f(x)=x\sin\frac{1}{x}$ . It is clearly that its upper boundary is $$\lim_{x\to\infty}x\sin\frac{1}{x}=1$$ but what is its lower boundary? I used software to obtain the result $y\in[0.217234, 1]$ and the figure is How to calculate the value '0.217234'? Thank you!","['trigonometry', 'calculus', 'functions']"
815586,Find the general solution to the ODE...,"I've been attempting to solve this ODE the past few days: $$(1): [e^{-x^2}u'(x)]' = u(x) + xu'(x).$$ What I did was differentiate the left hand side and move things around a bit to obtain $$(2):e^{-x^2}u''(x) - [2x*e^{-x^2} + x]u'(x) - u(x) = 0.$$ We can see that we are dealing with a homogenous second-order linear differential equation. The problem: I simply just don't know how to solve this. Observing the equation, Cauchy-Euler is not possible. Since we're not dealing with constant coefficients, Principle of Superposition doesn't work as is. And, since this equation is homogenous, we cannot use the method of Undetermined Coefficients or Variation on Parameters. I've attempted to to use v-substitution on (1), setting v(x)=u'(x),  but this just hit dead ends. I came to a solution that I realized was absolutely preposterous (I had forgotten v was a function of x and integrated incorrectly so I got a very wonky answer). Anyone able to give a hand?",['ordinary-differential-equations']
815591,Determining the angles of a triangle given the ratio between its edges,"Given that a triangle has edges of ratio 2 : 3 : 4, the task is to determine the three angles, say in degrees. I started by drawing 4 cm segment on the paper, then drew perpendicular segments of lengths 2 and 3 cm going up from the endpoints of the original segment. With a compass I drew arcs from the endpoints of the perpendicular segments, and their intersection allowed me to determine a triangle s.t. its edges meet the 2 : 3 : 4 (cm) ratio requirement. Visually: As happy as I am for being able to construct the triangle, I don't quite know how to proceed. I feel that the 2-4 angle (sorry I forgot to label) is 45°, the 3-4 one 30°, leaving 105° for the 2-3 angle. But I need some guidance as to how to approach actually proving those (or if those guesses are wrong, how to determine the actual angles). Thanks in advance for any hints/suggestions.","['geometry', 'trigonometry', 'algebra-precalculus']"
815648,Developing intuition in algebraic geometry through differential geometry?,"I'm interested in algebraic geometry (I'm working through Ravi Vakil's notes and also have worked with curves and general varieties in the past), and I have seen some basic definitions from differential geometry, e.g. vector bundles, (co)tangent spaces, differential forms. However, I don't have great intuition for such objects and as a result I feel a bit hindered as far as developing good geometric intuition in AG. Are there any suggestions as to resources I can look at for efficiently gaining a solidly intuitive, but not necessarily deep, understanding of differential geometry specifically for the purpose of motivating related ideas in algebraic geometry? Or, perhaps, is it essential that I learn differential geometry as thoroughly as I can before trying to study algebraic geometry seriously?","['algebraic-geometry', 'intuition', 'reference-request', 'differential-geometry']"
815650,Yet another difficult integration question,"For $r \in (0,1)$ and $k \in \mathbb Z^+$, prove
$$ \frac{1}{\pi} \int_{0}^\pi \ln\left(1 + r \cos(u)\right) \ln \left( 1 + r \cos(3^k u)\right) du = \left(\ln\left(\frac{2(1-\sqrt{1-r^2})}{r^2}\right)\right)^2.$$
Given that for any $n \in \mathbb Z^+$
$$ - \frac{1}{\pi} \int_{0}^\pi \ln\left(1 + r \cos(nu)\right) du = \ln\left(\frac{2(1-\sqrt{1-r^2})}{r^2}\right).$$
In my mind, the strategy should be to use the fact that $\cos(u)$ and $\cos(3^ku)$ are orthogonal. Write $[0,\pi]$ as a product space where $\cos(u)$ and $\cos(3^ku)$ are constant along the (orthogonal) fibres. Then use Fubini's theorem. But I am having difficulty in putting the pieces together. Thanks for your help.","['definite-integrals', 'integration']"
815662,"a question about how to prove mutivariable integral, I am struggling about it!","If $f(x)$ is Riemann integrable in $[a,b]$, and then how to prove $$\int_{a}^{b} f(x_1) \, dx_1 \int_{a}^{x_1}f(x_2) \, dx_2 \cdots \int_{a}^{x_{n-1}}f(x_n) \, dx_n={1\over n!} \left[\int_a^b f(x) \, dx \right]^n$$ I really don't know how to solve it! I prefer to use mathematical induction,but it doesn't work. Can someone can help me to solve it? I will appreciate you very much.","['multivariable-calculus', 'calculus', 'integration', 'analysis']"
815680,If $y=x^{x^{x^{x^{x^{.^{.^{.}}}}}}}$ then how $y=x^y$?,"In questions like, find the derivative of $f(x)=x^{x^{x^{x^{x^{.^{.^{.}}}}}}}$, how can we formally show that $y=x^y$? We use this technique for all type of iterations, e.g. $y=\sqrt{6+\sqrt{6+\sqrt{6+\cdots}}}$, we say $y= \sqrt{6+y}$ and solve the quadratic equation. Intuitively they seem to use the fact that $\infty +1=\infty$, that is the expression has an infinite number of terms so adding or deleting one term won't change the expression. But This logic is quite informal or we can say non-rigorous. Can we somehow show this formally, e.g. by using the $\epsilon - \delta$ definition of limit or something like that ?","['infinity', 'tetration', 'limits']"
815687,Are Exponential and Trigonometric Functions the Only Non-Trivial Solutions to $F'(x)=F(x+a)$?,"Are exponential & trigonometric functions the only non-trivial solutions to $F'(x)=F(x+a)$? $F(x)=0$ would be the trivial solution. Then, for $a=0$ (or  $a=2\pi i$), we have $F(x)=e^x$, and for $a=\dfrac\pi2$ there are $F(x)=\sin x$ and $F(x)=\cos x$. But the three are connected by Euler's formula $e^{ix}=\cos x$ $+i\sin x$. Indeed, on a more general note, letting $F(x)=e^{\lambda x}$, we have $\lambda=\dfrac{W(-a)}{-a}$ where W is the Lambert W function . My question would be if these are the only ones, due to the special properties of the number e and the exponential function , or if there aren't by any chance more , which do not belong in the same family or category as these, i.e., which are not exponential or trigonometric in nature ? Thank you.","['ordinary-differential-equations', 'functional-equations', 'analysis']"
815721,Dual of Schanuel lemma,"This is an exercise from Rotman, Introduction to homological algebra. Given exact sequences of $R$-modules \begin{array}{ccccccccc}
0 & \longrightarrow & M & \overset{i}{\longrightarrow} & E & \overset{p}{\longrightarrow} & Q & \longrightarrow & 0\\
0 & \longrightarrow & M & \overset{i'}{\longrightarrow} & E' & \overset{p'}{\longrightarrow} & Q' & \longrightarrow & 0
\end{array} where $E$ and $E'$ are injective, then there is an isomorphism $$Q \oplus E' \cong Q'\oplus E$$ What I have done: I completed the diagram using diagram chasing and the injectivity of E' \begin{array}{ccccccccc}
0 & \longrightarrow & M & \overset{i}{\longrightarrow} & E & \overset{p}{\longrightarrow} & Q & \longrightarrow & 0\\
 &  & id\downarrow &  & h\downarrow &  & k\downarrow\\
0 & \longrightarrow & M & \overset{i'}{\longrightarrow} & E' & \overset{p'}{\longrightarrow} & Q' & \longrightarrow & 0
\end{array} Then I tried to define an exact sequence \begin{array}{ccccccccc}
0 & \longrightarrow & E & \overset{r}{\longrightarrow} & Q\oplus E' & \overset{s}{\longrightarrow} & Q' & \longrightarrow & 0\\
\end{array} because in this case we could conclude $$Q\oplus E' \cong Q'\oplus E$$ due to the injectivity of $E$. I defined $$r : E \to Q\oplus E'$$ $$e \mapsto (p(e),h(e))$$ $$s : Q\oplus E' \to Q'$$ $$(a,b) \mapsto k(a) - p'(b)$$ Then it's easy to see that $$\text{im}(r) \subseteq \ker(s)$$ But I can't show that $\ker(s) \subseteq \text{im}(r)$, what's wrong ?","['modules', 'homological-algebra', 'proof-verification', 'abstract-algebra']"
815738,Velleman's How to prove it. Partial order proof.,"Theorem: Suppose that $R$ is a partial order on $A$, $B_1 ⊆ A$, $B_2 ⊆ A$, $x_1$ is the least
upper bound of $B_1$, and $x_2$ is the least upper bound of $B_2$. Prove that if
$B_1 ⊆ B_2$ then $x_1Rx_2$. Analysis: The goal is to prove $(x_1,x_2)\in R$. This means $x_2$ is LARGER than $x_1$. The givens are: 1) $R$ is a partial order on $A$, $B_1 ⊆ A$, $B_2 ⊆ A$ 2)$x_1$ is the least upper bound of $B_1$($x_1$ is an upper bound of $B_1$ AND $x_1$ is the smallest element of $U_1$). Translated to logic symbols mean: $\forall b_1 \in B_1[(b_1,x_1)\in R]$ $\land$ $\forall a\in U_1[(x_1,a)\in R]$. Where $U_1$ is the set of all upper bounds of $B_1$. 3)$x_2$ is the least upper bound of $B_2$. Translated to logic symbols mean: $\forall b_2 \in B_2[(b_2,x_2)\in R]$ $\land$ $\forall c\in U_2[(x_2,c)\in R]$. Where $U_2$ is the set of all upper bounds of $B_2$. 4)$B_1 \subseteq B_2$ 5)Obviously $x_1\in U_1 \land x_2 \in U_2$.Both are also $\in A$. Am stuck at this point. I tried contrapositive, direct, contradiction but to no avail. I tried cases like $x_1=x_2 \lor x_1\neq x_2$ but to no avail. Some person wrote this proof: Suppose $B_1 \subseteq B_2$. Let $b_1$ be arbitrary element of $B_1$, then $(b_1 R x_1)$. It follows from our assumption that $b_1 \in B_2$. So $(b_1 R x_2)$, hence $x_2$ is also an upper bound of $B_1$. Since $x_1$ is least upper bound of $B_1$, so it is smaller than any other upper bound of $B_1$, hence $(x_1 R x_2)$. But I think it is wrong since the step ""Let $b_1$ be arbitrary element of $B_1$"" is unjustified(The only way to justify it is to have an existential quantifier[like $B_1$ is not a null set] in the givens which we don't have. Also the last part of it isn't justified(it assumes $x_1\in B_2$). Am I right ? Can someone lend a hand here ? It would be great if you just gave a hint then write the answer in a hidden box.","['proof-writing', 'elementary-set-theory', 'proof-verification']"
815742,Moore-Penrose Pseudo-inverse of a matrix on adding 1 new row/column,"Given that I know the pseudo-inverse of a matrix(not necessarily a square matrix), how to calculate the pseudo-inverse of the matrix I get by adding a single row/column to the original matrix? i.e, Is there any way to compute the MP inverse of [A v] if I know the MP inverse of A?
(The new matrix is just the original matrix A with an additional column v)","['svd', 'matrices', 'linear-algebra', 'inverse']"
815760,If number of homomorphisms from $G \mapsto H$ is $n$. How many homomorphisms are there from $G \oplus G\cdot\cdot \cdot \oplus~ G ( s $ times) to $H$,"Suppose that the number of homomorphisms from $G \mapsto H$ is $n$. If $H$ is abelian, How many homomorphisms are there from $G \oplus G\cdot\cdot \cdot \oplus~ G ( s $ times) to $H$ Attempt Number of homomorphisms $\Psi: G \mapsto H$ is $n$ and we need the number of homomorphisms $G \oplus G\cdot\cdot \cdot \oplus~ G ( s $ times) to $H$ I have very little idea how to proceed further. Help will be appreciated. Thank you","['group-theory', 'abstract-algebra']"
815786,Expected area of an inscribed triangle in a sphere,"On the surface of a unit sphere, three points $A$, $B$ and $C$ are
  chosen in the following way: Points $A$ and $B$ are chosen randomly and independently on the whole surface After $A$ and $B$ are fixed, $C$ is a point on sphere that maximises the area of $\triangle ABC$. Find the expected area of $\triangle ABC$. (which I assume to be the triangle cutting through the sphere, not on the spherical surface) I am looking for a solution for this question from a test, hopefully a ""smart"" one that uses a quick approach. This was my approach: I quickly chose $C$ to be the mid-point of the major arc of the great circle through $A$ and $B$. To find the area, first I attempted to find the distribution of the angle between two random points, $\angle AOB$ with $O$ being the centre of sphere. I tried to use the fact that bands of equal width on sphere have the same area, and hope that it would link area with the angle $\angle AOB$, but I failed to find the distribution. Lastly I planned to take the expectation of $$\frac12\sin\angle AOB+\sin\frac{2\pi-\angle AOB}2$$ Yet this approach appears to be too lengthy for my test. Edit: I seem to find the distribution of $\Theta=\angle AOB$ as 
$$f_\Theta(\theta) = \begin{cases}\frac12\sin\theta&0\le\theta\le\pi\\
0&\text{otherwise}\end{cases}$$ And the expected value to be
$$\int_0^\pi\left(\frac12\sin\theta+\sin\frac{2\pi-\theta}2\right)\frac12\sin\theta\,d\theta = \frac\pi8+\frac23$$","['geometric-probability', 'probability-distributions', 'probability', 'euclidean-geometry']"
