question_id,title,body,tags
2565284,Let $\|\cdot\|$ be a norm on $\mathbb R^2$. Show that the perimeter of the closed unit ball is between $4$ and $12$.,"Let $\|\cdot\|$ be a norm on $\mathbb R^2$. The length of a polygon line is given by this norm. Let $A$ be a non-empty bounded convex part of  $\mathbb R^2$. The perimeter of $A$ is defined as the upper bound of the perimeters of the convex polygons included in $A$. Show that the perimeter of the closed unit ball is between $4$ and $12$. Not very familiar with geometry, I do not not see how to deal with this problem from an oral exam (if not to frame the unit ball with polygons). If you have an idea ... Note that the norm is not necessarily euclidean (i.e. issue from a scalar product).","['convex-geometry', 'general-topology', 'geometry']"
2565305,Do both of these functions define the same branch of $\sqrt{z^2 - 1}$?,"Let $\sqrt{\cdot}$ be the function defined by 
\begin{align}
\sqrt{z} &= r^\frac{1}{2} e^{i \frac{\theta}{2}}, \\ 
r &= |z|, \\ 
\theta &= \arg(z), \\ 
-\pi &< \theta \le \pi
\end{align} Let $$f(z) = z\sqrt{1 - \frac{1}{z}}\sqrt{1 + \frac{1}{z}}$$
and let 
$$g(z) = \sqrt{z +1}\sqrt{z - 1}.$$
The functions $f$ and $g$ are both branches of the multivalued function implicitly defined by $w^2 = z^2 - 1$. Indeed $f^2(z) = g^2(z) = z^2 - 1$.
Furthermore $f(x) = g(x)$ for $x > 1$, therefore $f = g$ on $\mathbb C \setminus [-1, 1]$ 
by the Identity theorem . Is there a more direct way to see this from how $\sqrt{\cdot}$ depends on the argument of a number?
It's tempting to factor $\sqrt{z}$ from both factors of $g$ however for $\alpha, \beta \in \mathbb C$, in general $\sqrt{\alpha\beta} \neq \sqrt{\alpha}\sqrt{\beta}$. Thanks.","['complex-analysis', 'complex-numbers', 'complex-integration', 'branch-cuts']"
2565314,Solve for $\frac{dy}{dx}$ if $x = y \ln (xy)$,"Solve for $\frac{dy}{dx}$: $x = y \ln (xy)$ The first idea to solve this that springs to my mind is, of course, to apply implicit differentiation, but this is not an obvious function and so I got stuck. I simply don't know how to tackle this. Because, if I take the derivative with respect to $x$ of both sides, I get $$1 = \frac{d}{dx}[y\ln(xy)] = \frac{d}{dx}[y]\ln(xy)+y\frac{d}{dx}[\ln(xy)] = \frac{dy}{dx}[\ln(xy)] + y\frac{dy}{dx}[\ln(xy)] \\ 
2 \frac{dy}{dx}[\ln(xy)] = 1 \iff \frac{dy}{dx} = \frac{1}{2\ln(xy)}$$ Is it the right way to solve this?","['derivatives', 'implicit-differentiation', 'calculus']"
2565331,$x''+(x^2+2x'^2-1)x'+x=0$ has a non trivial periodic solution.,"I'm trying to prove that $x''+(x^2+2x'^2-1)x'+x=0$ has a non trivial periodic solution. I've written it as a 2x2 system and found that the only equilibrium point $(0,0)$ is strictly unstable. Therefore I'm trying to find a invariant set that contains the origin so I can apply Poincaré-Bendixson, but I haven't had any luck. Any suggestions? also, do you know of a better way to prove this? Thank you!","['ordinary-differential-equations', 'dynamical-systems']"
2565333,Determining the first $3$ nonzero terms in each of two linearly independent solutions,"In preparation for an upcoming exam I have came across a question that I am a little confused with. Given the following different equation, $$xy''+y'-y = 0$$ I am trying to find the first $3$ nonzero terms in each of two linearly independent solutions. I have determined the indicial equation to be, $$r^2 = 0$$ Therefore the roots are, $$r_1=0, r_2=0$$ So the roots are separated by a integer I have calculated the recurrence solution to be, $$a_n = \frac{a_{n-1}}{(n+r)^2}$$ So therefore the first solution would be the following, $$y_1(x) = 1+ x + \frac{1}{4}x^2 + \frac{1}{36}x^3...$$ However it is determining the second solution where I am having problem, so I am looking for some help with showing how this answer is calculated, thanks! The solution to the second solution is, $$y_2(x) = y_1(x)\ln x -2x - \frac{3}{4}x^2-\frac{11}{108}x^3$$","['ordinary-differential-equations', 'sequences-and-series']"
2565356,Let X be a set with 30 elements. How many equivalence relations can be defined on X if every class of the relation must have exactly 6 elements?,"I am not really sure about my approach. I'm thinking of the ways to partition the set X into 5 classes with 6 elements each. I am thinking of the ""word"" $a_1a_2a_3a_4a_5a_6|a_7\dots a_{30}$ that has $30$  $a_i$ elements and 4 bars. I am thinking of the permutations of this word with fixed bars, and dividing the total of permutations by 6! repeated cases I'd get since every partition is appearing 6! times. But permutating with fixed bars is the same as them not being there at all, so the answer is the total number of permutations divided by 6! $Var(30,24) = \frac{30!}{6!}$ Is this correct? Is there another way to think this problem?","['permutations', 'combinatorics', 'discrete-mathematics']"
2565364,Separation of variables for partial differential equations - Shallow Wave Equation,"Question: I've tried countless times to prove this problem, but I keep getting hung up on the indices for derivatives. Could somebody please point me in the right direction? Given Solution","['partial-derivative', 'ordinary-differential-equations']"
2565403,Condtional Expectation of Order Statistic,"Given a a random sample $X_1, X_2, X_3, X_4$ and family of densities $\mathcal{P} = \left\{ f_\theta: \theta \in \Theta \right\}$, where $f_\theta(x) = \frac{1}{2}\mathbb{I}_{[\theta-1, \theta + 1]}$, we can estimate $\theta$ by $\hat{\theta} = X_{(2)} + \frac{1}{5}$. Now we also know that $(S, T)= (X_{(1)}, X_{(4)})$ is a sufficient statistic for $\theta$ so we may Rao-Blackwellize our estimator:
$$ \hat{\theta}^*= \mathbb{E}(\hat{\theta}|(X_{(1)},X_{(4)})) = \mathbb{E}(X_{(2)}|(X_{(1)},X_{(4)})) + \frac{1}{5}.$$
Unfortunately I haven't been able to compute the last conditional expectation. Any input would be greatly appreciated! :)","['order-statistics', 'probability-theory', 'probability', 'statistics']"
2565431,Permutation count for non identical letters,"Question: Find the number of permutations of letters of the word ’COMBINATORICS’ where $2$ consecutive letters are never identical. What I have tried: ""COMBINATORICS"" has $13$ characters with repeated elements $2$ ""I"", $2$ ""O"", and $2$ ""C"". I know that $13!/2!\cdot 2!\cdot 2!$ would give us the count of their combination. However, I am trying to get the count where no $2$ consecutive letters are identical. Here is my attempt: $\frac{13!}{2!\cdot 2!\cdot 2!} - \left( \left(\frac{12!}{2!\cdot 2!}\right) + \right(\frac{12!}{2!\cdot 2!}\left) + \left(\frac{12!}{2!\cdot 2!}\right) \right)$ I used $12$ because I assumed the $2$ I to be as one unit so the total letters would be $12$ and so on for the rest. Is it correct?","['number-theory', 'discrete-mathematics']"
2565435,"Prove that, for all sets A, B and C, if A ⊆ C and B ⊆ C then A ∪ B ⊆ C.","First of all, I am sorry to ask this question on math.stackexchange.com but its very urgent/important. I have asked on other sites to this question before asking on math stackechange but no response. Tomorrow I have Discrete Math exam and I almost spend 3 hours to prove this but I don't know how can I prove it. Again the question is Prove that, for all sets A, B and C, if A ⊆ C and B ⊆ C then A ∪ B ⊆ C. So far, I have tried : 
X ∈ P(A ∩ B) 
      iff X ⊆ A ∩ B 
      iff X ⊆ A and X ⊆ B... can't proceed.","['proof-writing', 'proof-explanation', 'elementary-set-theory', 'discrete-mathematics']"
2565466,Applicability of L'Hôpital rule on infinite sum.,"$$\lim_{n \to \infty} \left( \frac{n}{n^2+1} + \frac{n}{n^2+2} + \frac{n}{n^2+3} + \space  ... \space + \frac{n}{n^2+n}\right) $$ As $n$ is not $\infty$ but tends to $\infty$ I can split the limit of sums into sum of limits. i.e. $$\lim_{n \to \infty} \frac{n}{n^2+1} +\lim_{n \to \infty} \frac{n}{n^2+2} +\lim_{n \to \infty} \frac{n}{n^2+3} + \space  ... \space +\lim_{n \to \infty} \frac{n}{n^2+n} $$ 
Applying L'Hôpital rule.
$$\lim_{n \to \infty} \frac{1}{2n} +\lim_{n \to \infty} \frac{1}{2n} +\lim_{n \to \infty} \frac{1}{2n} + \space  ... \space +\lim_{n \to \infty} \frac{1}{2n} $$ 
$$= \lim_{n \to \infty} \left( \frac{1}{2n} + \frac{1}{2n} + \frac{1}{2n} + \space  ... \space + \frac{1}{2n} \right) = \lim_{n \to \infty} 
\frac{n}{2n} $$
$$ =\lim_{n \to \infty } \frac{1}{2} = \frac{1}{2}$$ Whereas applying Sandwich theorem with $g(x) \leq f(x) \leq h(x)$, where
$$g(x) = \frac{n}{n^2+n} + \frac{n}{n^2+n} + \frac{n}{n^2+n} + \space  ... \space + \frac{n}{n^2+n} = \frac{n^2}{n^2+n}$$
and
$$h(x) = \frac{n}{n^2+1} + \frac{n}{n^2+1} + \frac{n}{n^2+1} + \space  ... \space + \frac{n}{n^2+1} = \frac{n^2}{n^2+1 }$$
Yields
$$\lim_{n \to \infty} g(x) = \lim_{n \to \infty} h(x) = 1
\implies \lim_{n \to \infty} f(x) = 1
$$ Sandwich theorem is very intuitive to discard hence I suppose there is some issue with the application of L'Hôpital's rule.
Is there any special condition involved with converting limit of sums to sum of limits ?","['infinity', 'limits']"
2565490,L'Hospital Rule with Trigonometry [duplicate],"This question already has answers here : Evaluating limit (iterated sine function) (4 answers) Closed 6 years ago . I've been working on this question for the final exam, yet I could not come to a closure. I'd appreciate if you can help me. What is $$\lim_{x\to 0} \frac{\sin(\sin(\sin x)) - x}{x^3}\qquad?$$","['derivatives', 'trigonometry', 'calculus', 'limits']"
2565496,Shortcut to $x\uparrow \uparrow n$ for very large $n$ and $x\approx e^{(e^{-1})}$?,"If the number $x$ is very close to $e^{(e^{-1})}$ , but a bit larger, for example $x=e^{(e^{-1})}+10^{-20}$, then tetrating $x$ many times can still be small. With $x=e^{(e^{-1})}+10^{-20}$ , even $x\uparrow \uparrow (10^8)$ (This is a power tower of $10^8$ $x's$ calculated from above) is smaller than $e$ Is there any shortcut to calculate such huge power-towers ? In other words, can I efficiently calculate $x\uparrow\uparrow n$ reasonably exact (lets say, with $6$ digits accuracy) ? The brute force method is quite slow and I am not sure whether it is even numerically stable.","['complex-dynamics', 'tetration', 'calculus', 'power-towers']"
2565584,"Find $\int_\gamma \frac{dz}{(z-\frac{1}{2}-i)(z-1-\frac{3i}{2})(z-1-\frac{i}{2})(z-\frac{3}{2}-i)}\, $","Let $f(z)=\frac{1}{[(z-\frac{1}{2}-i)(z-1-\frac{3i}{2})(z-1-\frac{i}{2})(z-\frac{3}{2}-i)]}$ and let $\gamma$ be the polygon $[0,2,2+2i,2i,0]$. Find $\int_{\gamma}^{} f$ . I'm trying to use the partial fractions decomposition method, but it's getting too long and I'm lost in the accounts. I do not know if the author expects me to do so. Can anybody help me?
Conway, pg. 96, prob., 7.","['complex-analysis', 'integration', 'curves']"
2565588,Is $\Bbb P^1_k$ simply the blow up of $\operatorname{Spec}k$?,"I was playing around with the definition of a blow up when I encountered something interesting. Theorem IV-23 Eisenbud & Harris Let $X$ be a scheme and $Y\subset X$ a closed subscheme. Let $\mathcal J \subset \mathcal  O_Y$ be the ideal sheaf of $Y$ in $X$ . If $\mathscr A$ is the sheaf of graded $\mathcal O_X$ -algebras $$\mathscr A = \bigoplus_{n=0}^\infty \mathcal J^n$$ then the scheme $\operatorname {Proj}\mathscr A \to X$ is the blowup of $X$ along $Y$ . Now taking $X$ to be $\operatorname{Spec} k$ for some algebraically closed field $k$ we should have a variety with a single point. There is only one blow up that can be done, this gives the ideal sheaf as $k$ thus $\mathscr A \cong \mathcal k[t]$ . This gives the blow up of $X$ along (essentially) $X$ to be $\operatorname{Proj}k[t]=\Bbb P_k^1$ . I have never heard of a description of protective space over an algebraically closed field $k$ as simply being the blow up of $\operatorname{Spec} k$ . So my questions are as follows: Is $\Bbb P^1_k$ simply the blow up of $\operatorname{Spec}k$ ? Does this generalise to $\Bbb P^1_S$ of some reduced scheme $S$ being the blow up of $S$ at a point? I suppose it isn't quite $\Bbb P^1$ every time... Is this point of view helpful for understanding the geometry of $\Bbb P^1$ ?","['algebraic-geometry', 'projective-geometry', 'schemes', 'projective-space', 'blowup']"
2565659,Assumptions Need on a Measure Space to Guarantee the Existence of a Certain Set,"First question: If $f : X \to [0,\infty]$ is a measurable function and $A$ and $B$ are disjoint measurable sets in $X$, then is it true that $$\int_{A \cup B} f \, d \mu = \int_A f \, d \mu + \int_B f \, d \mu?$$ Second question:Let $X$ be some space with $\sigma$-algebra $\frak{M}$ and measure $\mu : {\frak M} \to [0,\infty]$.  what are the assumptions on $X$ and $\frak{M}$ on it, minimal in number, such that there exists an $E \in \frak{M}$ with $0 < \mu(E),\mu(E^c) < \infty$? Regarding the first, I didn't feel it justified its own post, since it is essentially a yes or no question (asked in chat but no responses). Regarding the second question, if we need to put conditions on $\mu$ that rule out trivial answers, please do so.","['complex-analysis', 'real-analysis', 'measure-theory']"
2565670,Openness of a map of $G$-spaces,"This is question 10 from chapter 1 of Bredon, Introduction to Compact Transformation Groups . Let $G$ be a compact group, $X$ and $Y$ be $G$-spaces (Hausdorff spaces with a continuous $G$-action), and $f: X \to Y$ a $G$-equivariant map. Suppose that $f$ restricts to a homeomorphism of each orbit $f: G(x) \overset{\cong} \to G(f(x))$, and that the induced map $f': X/G \to Y/G$ is open. Prove that $f$ is open. This intuitively feels true, but I haven't been able to come up with a formal argument. Given $U \subset X$ open, the projection $f(U) \to Y \to Y/G$ has open image, and the fibers $f(U) \cap G(y)$ are relatively open in the orbits, but that alone doesn't get you there. I believe I could do it if there were local sections of $Y \to Y/G$, but those don't necessarily exist. Anyone point me in the right direction?","['group-actions', 'compactness', 'general-topology', 'group-theory', 'open-map']"
2565726,Integrating $\int_0^{\frac{\pi}{2}} x (\log\tan x)^{2n+1}\;dx$,"Does anybody have any thoughts about how to integrate $$I=\int_0^{\frac{\pi}{2}} x (\log\tan x)^{2n+1}\;dx$$ for integral $n$ where $n\ge 1$ In the case $n=0$ $$\int_0^{\frac{\pi}{2}} x \log\tan x \;dx=\lambda(3)=\frac{7}{8}\zeta(3)$$ I have managed to integrate the function when the exponent is even, that is $(\log\tan x)^{2n}$, using the substitution $y=\left(\frac{\pi}{2}-x \right)$ over the two intervals $[0,\frac{\pi}{4}]$ and $[\frac{\pi}{4},\frac{\pi}{2}]$, but the same trick does not apply in regard to the odd powers. Basically via integration by parts I am left with the repeated integral $$\int_0^{\frac{\pi}{2}} \int_0^x  (\log\tan u)^{2n+1}\;du\;dx$$ As far as I know $(\log\tan u)^{2n+1}$ does not have a definite integral I can use, so I am stuck. I've tried a few substitutions and those have not helped. Any ideas how I might proceed? Some Added Background Notes To obtain a function more suitable for numerical integration use the substitution $u=\log \tan x$ to give $$\int_0^{\frac{\pi}{2}} x (\log\tan x)^{n}\;dx=\int_{-\infty}^{+\infty} \arctan(e^u)\frac{u^n}{e^u+e^{-u}} \;du$$ This shows that the integral $I$ is closely related to the standard integral for the $\beta(n)$ function. The analogous integral $\int_0^{\infty} x (\log\tanh x)^{n}\;dx$ via a similar change of variables is seen to be related to the standard integral for the $\lambda(n)$ function.","['improper-integrals', 'integration', 'definite-integrals']"
2565754,Is my understanding of Likelihood Ratio Tests and Likelihood Functions correct?,"I'm trying to understand Likelihood Ratio Tests, Likelihood Functions and Hypotheses Tests, which makes up a significant amount of what we're supposed to learn in my statistics for beginners course. But I'm very new to this level of maths, so a lot of the rigorous knowledge and intuitive understanding is unfortunately missing for me; my apologies then for the length of the post from my over explaining some things. I was wondering if you could tell me from my summation if my understanding of these processes is correct/where I've gone wrong? My understanding so far: Imagine you have collected a sample of data from some population; say you know the type of distribution that models the population, but you are unsure of the value of one of the parameters. So you construct a Likelihood Function, and work out the value of your parameter $\theta$ that maximises the probability of your sample data under that distribution. And you do this by taking the (Log) Likelihood Function, differentiating and setting equal to zero, then solving for $\theta$. I.e. if you were to graph 'Probability of your sample occurring' on the Y-axis vs the potential values of your parameter $\theta$ on X-axis, you would be finding the $\theta$ that maximises this function on your graph. So now comes Likelihood Ratio Tests. As I understand it so far, the purpose of an LRT is to workout whether the parameter you've identified as maximising is better than some null-hypothesis parameter, by a statistically significant level. Otherwise without doing an LRT, it might be that your proposed maximising $\theta$ was only marginally better, and maybe only for this sample, than the null value due to something like sampling error, yet you thought it was definitively better. Now if I understand Null Hypotheses Tests right, in the case where your null hyp is rejected, the test doesn't then specifically tell you which other hyp is the actual true one, a hypothesis test just tells you whether or not the null-hyp is true or not (if it's not true though, you know the true hypothesis will be a member of the null's complement). Then, let: $H_0 = {}$'$\theta_\text{Null-Hyp}$ is the value of the parameter that maximises your Likelihood Function.' $H_1 = {}$'$\theta_\text{Null-Hyp}$ is not the maximising value (and thus the max value $\theta \in \Theta_\text{Alt-Hyp}$, where $\Theta_\text{Alt-Hyp} = \theta_\text{Null-Hyp}^c)$.' $L(\theta) = {}$Likelihood Function with $\theta$ as your maximising parameter. The Likelihood Ratio is then: $$\frac{L(\theta_\text{Null-Hyp})}{L(\Theta_\text{Alt-Hyp})} \leqslant K$$ So, constructing your LRT: when setting up your LRT you first pick the confidence lvl (say 95%) you want. Then you work out the K that corresponds to this confidence lvl (more on this later). Now for every $\theta$ $\in$ $\Theta_\text{Alt-Hyp}$, s.t. the ratio is $\leqslant K$, you can say with 95% confidence that these $\theta$ output, by a statistically significant amount, a higher value for the Likelihood Function than $\theta_\text{Null-Hyp}$. So you reject the null hypothesis. And of course, you already knew the $\theta \in \Theta_\text{Alt-Hyp}$ that maximises the Likelihood Function, but now you're very confident this value wasn't produced from your sample erroneously, e.g. from things like sampling error, etc. That's my summation of the process, which I thought was approximately right - though please let me know where I've gone wrong. However, it's in the the process of the below example that I am most confused. In this example about honey pots, https://onlinecourses.science.psu.edu/stat414/node/309 the author is trying to find the mean weight of the population from a sample of pots. They construct an LRT with an (as far as I understand it) arbitrarily chosen value for the $H_0$ pop mean of $\theta_\text{Null-Hyp} = 10,$ and Sig Lvl of $\alpha = 0.05.$ Their variable for $\theta_\text{Alt-Hyp}$ is $\bar X$. The author takes the Likelihood Ratio, manipulates the algebra, and arrives at the equation: $$Z= \frac{\bar X-10}{\sigma / \sqrt n} = f(K) $$ From this they look up the Z statistic for $\alpha = 0.05$ to say that $f(K) = 1.96.$ They then find the inverse of $f(K)$ to find their value of $K.$ Here's why I'm confused. If in the end they use the Z-Statistic to calculate their value of K, why don't they just skip straight to calculating the Z-stat in the first place, instead of doing the LRT? If they work to make sure they can input $\bar X$ into the Z-stat to be able to decide whether to reject $H_0$, why do they then continue with the LRT, or use it in the first place? On top of this, what determines what value you should choose for the null hypothesis? Clearly I'm missing something in my understanding (as well as any holes in my explanations above), so if anyone could fill in my knowledge gaps I'd really appreciate it. I apologise that this is such a long post, thanks for your time so far. Any help you could offer would be greatly appreciated. Cheers","['descriptive-statistics', 'statistics', 'order-statistics']"
2565763,Probability of no moves in solitaire [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question I was playing a standard solitaire game on my mobile app and I came across a round where I couldn't perform a single move thus resulting in a loss. I was then thinking as to what the probability of this event to happen in a single game. Would anybody know this probability and show the calculations given a standard deck of 52 cards? Here is a link to the rules: https://www.wikihow.com/Play-Solitaire Note: There are three cards turned at a time but you can only play the second card after you played the top card. Also, the game is klondike.","['statistics', 'probability']"
2565764,Is it possible for linear homogeneous differential equation to have solutions $x$and $sin(x)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Is it possible to make a linear homogeneous second order differential equation whose general solution is: $f(x) = c_1 x + c_2 \sin(x)$",['ordinary-differential-equations']
2565802,"Calculate the area of the region bounded by $z=0, z=1,$, and $(z+1)\sqrt{x^2+y^2}=1$","Calculate the volume of the region bounded by $z=0, z=1,$, and $(z+1)\sqrt{x^2+y^2}=1$ The integral is $\int_{B}z\text{ dV}$ The area is like the thing between the top two green places. The first place is $z=1$, second is $z=0$ Clearly we have $0\leq z\leq 1$, but I'm not sure what to bound next? Should I be using cylindrical? Would it be correct in saying $0\leq r\leq \dfrac{1}{z+1}$","['multivariable-calculus', 'integration', 'calculus']"
2565806,Evaluate the exact differential,"Found this question in my study guide but the answer I got was wrong but I don't see how come. $$\int^{(1,1,1)}_{(0,0,0)}3x^2y^{10}z^{10}dx+10x^3y^9z^{10}dy+10x^3y^{10}z^9dz$$ I took the integral of each variable giving me: $$\int^{(1,1,1)}_{(0,0,0)}3x^2y^{10}z^{10}dx+\int^{(1,1,1)}_{(0,0,0)}10x^3y^9z^{10}dy+\int^{(1,1,1)}_{(0,0,0)}10x^3y^{10}z^9dz$$ $$x^3y^{10}z^{10}+x^3y^{10}z^{10}+x^3y^{10}z^{10}=3x^3y^{10}z^{10}$$ $$3x^3y^{10}z^{10}\bigg|^{(1,1,1)}_{(0,0,0)}=3$$
$$Answer=1$$","['multivariable-calculus', 'integration', 'definite-integrals', 'calculus']"
2565870,A criterion for having Fredholm index 0,"In reading a paper, I ran into the following Lemma: Let $T$ be a bounded linear operator from a Hilbert space, $H$, into $H$. Let $T$ have a kernel of dimension $d<\infty$. Assume $T$ has closed range and that $T^*-T$ is a compact operator. Then the range of $T$ has codimension $d$ also. The authors omit the proof since it is ""simple"", but I got no idea after several hours of thinking. Can somebody help me?","['functional-analysis', 'operator-theory']"
2565922,Probability that no three consecutive heads occur,"Suppose we flip a fair coin $n$ times, what is the probability that no three consecutive heads occur? I understand the proof for the case with no two consecutive heads, where we can consider the number of sequences that start with $H$ and $T$ and get the recurrence relations $$F(n+1) = F(n) + F(n-1) $$ where $F(n)$ is the number of sequences with no consecutive heads which leads to $$Q_n = \frac{1}{2}Q_{n-1} + \frac{1}{4}Q_{n-2}$$ However, I'm having trouble extending to the case of no three consecutive heads. What would the recurrence relations be for the number of sequences?",['probability']
2565930,"Are there ""natural"" non-noetherian schemes?","In algebraic geometry's books, there are many propositions like ""let $f : X \to Y$ be a morphism of locally finite presentation, then such-and-such..."", but every time I face on such propositions, the question comes up to my mind. I'm a beginner in studying algebraic geometry, but I feel that almost all schemes in practice are noetherian, like that almost all rings are noetherian.
And these propositions becomes so clear if schemes are noetherian.
So I want to restrict the situations to  noetherian schemes, if it will not have any problems. So the question is: are there non-noetherian schemes in practice? p.s.
I want to study arithmetic geometry, so if there is, please give me any examples of this field.","['arithmetic-geometry', 'algebraic-geometry']"
2565968,"Fundamental theorem of line integrals, what if the curl DOESN'T equal 0?","I am getting really frustrated here and have had many arguments with people. Is it true or not, that if you compute the curl, and you get something other than 0, THEN you can NOT use the fundamental theorem? My understanding is that, logically, conservative F implies curl=0, therefore, curl=/=0 implies F not conservative, (if not q then not p) therefore you can not use the theorem. Thank you to anyone who clarifies this.",['multivariable-calculus']
2565974,General Solution of an ODE,"Let $f$ be a continuous function. Can anyone please help me out to find the solution of the ODE: 
$$y\left( \frac{dy}{dx} + a y + b\right) = f(x)$$",['ordinary-differential-equations']
2566004,"Four Relations on $\{1,2,3\}$","Define four relations on $\{1, 2, 3\}$ . Both transitive and symmetric. Transitive and not symmetric. Symmetric but not transitive. Neither transitive nor symmetric. I have: $R= \{(1,2),~(2,1),~(2,2),~(1,1)\}$ Transitive and Symmetric $R= \{(1,1),~(2,2),~(1,2)\}$ Transitive and Not Symmetric $R= \{(1,2),~(2,1),~(2,3),~(3,2)\}$ Not Transitive and Symmetric $R= \{(1,1),~(1,2),~(2,3)\}$ Not Transitive and Not Symmetric Am I understanding what the question was asking correctly and are my relations correct?","['relations', 'elementary-set-theory']"
2566028,Quadratic equation estimating changes in b and c,"If $x^2 + bx + c=0$ is an equation the roots are $$
\begin{aligned}
x&=\frac{-b + \sqrt{b^2 - 4c}}{2}\\
x&=\frac{-b - \sqrt{b^2 - 4c}}{2}
\end {aligned}$$ What is the effect of small changes in $b$ or $c$? For example if I have $\sqrt{a}$ then to estimate a small change in this equation I would write $$\sqrt{a + \Delta a}$$ and set $v = \sqrt{a}$ and $$v + \Delta v =\sqrt{a + \Delta a}$$ Therefore $a + \Delta a = (v + \Delta v)^2$ which is roughly
$v^2 + 2v \times \Delta v$ (ignoring $\Delta v^2$ as it's too small) and thus $$\Delta a = 2\sqrt{a} \times \Delta v$$ so with some rearranging $\Delta v$ is roughly $\frac{1}{2\sqrt{a}} \times\Delta a$
(to the first order) and this lets me estimate square roots. How can I use a method like this to estimate small changes in $b$ and $c$?",['algebra-precalculus']
2566057,Showing equality of sets via the tableau method - Translation to propositional logic,"Let A and B be sets. Show that the following equality holds: $$(A-B) \cup (B-A)=(A \cup B)-(A \cap B)$$ So, if one want to show that this equality holds via the tabluea method, one needs to translate the above into propositional logic. Is the following translation correct? $$(A \wedge \neg B) \vee (B \wedge \neg A) \Leftrightarrow (A \vee B) \wedge (\neg A \wedge \neg B) $$","['propositional-calculus', 'elementary-set-theory', 'discrete-mathematics']"
2566058,"Find all real solutions for the system: $x^3=y+y^5$, $y^5=z+z^7$, $z^7=x+x^3.$","Given: $$\left\{
\begin{array}{l}
x^3=y+y^5\\ 
y^5=z+z^7\\
z^7=x+x^3 
\end{array}
\right. 
$$
  Find: all real solutions for the system. From a book on preparation for math contests. The answer states there is just one solution. My problem is showing that this is indeed the case. My attempt: it is easy to see that one solution is $(x,y,z)=(0,0,0)$. And, adding the equations, we get to $x+y+z=0$. But my problem is showing that this solution is indeed unique, if the answer provided in the book is right. Hints and answers are appreciated. Sorry if this is a duplicate.","['algebra-precalculus', 'contest-math', 'inequality', 'systems-of-equations']"
2566096,Property of function: why only subset relation for intersection?,"I'm reading a text book about functions. They present a set of properties of functions, one of them: Given $f: A \to B$ , the following properties hold for any $C_1, C_2 \subseteq A$ a) $f(C_1 \cup C_2) = f(C_1) \cup f(C_2)$ b) $f(C_1 \cap C_2) \subseteq f(C_1) \cap f(C_2)$ ... The author then adds a remark: Part b) only gives a subset relation. The reason is: having $y \in f(C_1)$ and $y \in f(C_2)$ does not necessarily mean that $y$ is the image of the same element. Since $f$ can be many-to-one, it is possible to have $x_1 \in C_1 - C_2$ and $x_2 \in C_2 - C_1$ such that $f(x_1) = f(x_2) = y$ . There is also an example and I understand in general what is meant, but I can't wrap my head around why we have an 'equals' in the a) property but only a subset-equals in the b) property.","['elementary-set-theory', 'functions', 'discrete-mathematics']"
2566131,Relation between probability distribution for area and diameter of circle,"If the area of a circle is normally distributed with mean $\mu$ and standard deviation $\sigma$, what distribution does the diameter follow? Edit:
I should clarify my question a bit. I found a reference suggesting the cross sectional  area (of a reinforcement bar) follows a normal distribution with CoV=0.02. But the model I'm working with takes the bar diameter as input. Thus I want to find what distribution to use for input, to have similar uncertainty. That is, when I run a large number of simulations of  $\phi$, the resulting diameter  $\pi\phi^2/4$ should be normally distributed with CoV 0.02. I have found that a CoV of 0.01 gives the intended result through trial and error, but would like to have a derivation. Best regards,
Mattias","['statistics', 'probability-distributions']"
2566134,if $a^{(p-1)/2}$≡ -1(mod p) then the order of a mod p is p-1,"Prove or disprove Suppose that p is an odd prime , if $a^{(p-1)/2}$≡ -1(mod p) then the order of a mod p is p-1 I think it is true statement , $a^{(p-1)/2}$≡ -1(mod p) by squaring both side we get $a^{(p-1)}$≡ 1(mod p) then the order of a mod p is p-1 is that right answer ?","['number-theory', 'elementary-number-theory']"
2566170,probability involving rerolling dice,"The question go like the following. You roll one 6 sided dice one time. You get the same money as the number of dots face up. But if you roll a six, you get nothing and re-roll. If your re-roll gets a six again, you reroll again and again. What is the expercted value of money get. I guess i should go like the following $$E(x)=\frac16+\frac26+\frac36+\frac46+\frac56+\frac16 E(x)$$",['probability']
2566193,Confidence interval for mean,"Let's say we draw $49$ numbers from $1,\ldots,100$ without returning them back. Then we use the arithmetic mean from the sample.
$$M=\frac{1}{49}\sum_{i=1}^{49}X_i$$ They gave me the hint that $M$ is roughly normal distributed despite the dependencies in the draws. Now I have to determine an symmetric intervall $J$ around the mean with $\mathbb{P}(M\in J)\approx0.95$ My idea was to use the variance and covariance to solve this problem. $$Var\left(\frac{1}{49}\left(X_1+\ldots+X_{49}\right)\right)$$ $$=\frac{1}{49^2}\left(49\cdot Var(X_1)+49\cdot48Cov(X_1,X_2\right))$$ But I'm not sure how this works","['probability-theory', 'probability', 'normal-distribution', 'probability-distributions']"
2566206,Notation for cartesian product except one set?,"Let's say I have a list of sets $S_i$, for $i=1,\ldots,n$. We often write the cartesian product of all these sets, with the exception of $S_k$ as: $$S=S_1\times\cdots\times S_{k-1}\times S_{k+1}\times\cdots\times S_n$$ Is there a more succinct way to write it?","['notation', 'elementary-set-theory']"
2566229,$x^2\sin(x)$ continuous using $\epsilon\delta$ method,"I would like to prove that the function : $f: \mathbb{R} \rightarrow \mathbb{R}$, $f(x) = x^2 \sin(x)$ is continuous. I know that a function $f: \mathbb{R} \rightarrow \mathbb{R}$ is continuous iff : $\forall x \in \mathbb{R}, \forall \epsilon > 0, \exists \beta > 0, \forall y \in \mathbb{R}, \mid x-y \mid \leq \beta\Rightarrow \mid f(x)-f(y)| < \epsilon$ That's why here in order to proove that $f$ is continuous I must find a $\beta$ such that : $\mid x - y \mid \leq \beta \Rightarrow \mid x^2\sin(x) -y^2\sin(y) \mid < \epsilon$ I tried to use the fact that $\sin(x) \in [-1, 1]$ but it doesn't seem to help a lot.","['continuity', 'real-analysis', 'calculus', 'functions']"
2566277,Time and Work. How much work does C do per hour?,"A, B and C need a certain unique time to do a certain work. C needs 1
  hours less than A to complete the work. Working together, they require
  30 minutes to complete 50% of the job. The work also gets completed if
  A and B start working together and A leaves after 1 hour and B works
  for a further 3 hours. How much work does C do per hour? (A)16.66% (B)33.33% (C)50% (D)66.66% My attempt: Let the total work be 100 units. Let the work done by A,B and C be a units/hour,b units/hour,c units/hour respectively. Let the time taken by A alone to complete the work be t hours. ATQ:
\begin{align*}
(a+b+c) \cdot \frac{1}{2} & =50 \tag{1}\\
(a+b) \cdot 1+b \cdot 3 & =100 \tag{2}\\
c \cdot (t-1)& =100 \tag{3}\\
at & =100 \tag{4}
\end{align*}
Please help me solve these equations. When I am solving it is getting cumbersome. Also if someone tells us some other way of solving, that would be helpful as well. Thanks.","['algebra-precalculus', 'arithmetic']"
2566297,A generalization of Kolmogorov's maximal inequality,"Suppose $X_1, X_2, \ldots$ are independent random variables with $E(X_n) = 0$ for all $n$. For $\varepsilon > 0$, define $A_n = \left\{\max\limits_{1 \leqslant k \leqslant n} |S_k| \geqslant \varepsilon\right\}$ for all $n$, where $S_n = \sum\limits_{k = 1}^n X_k$ for all $n$. Prove that for any real $r \geqslant 1$,$$\varepsilon^r P(A_n) \leqslant E(|S_n|^r I_{A_n}) \leqslant E(|S_n|^r). \quad \forall n \geqslant 1$$ This is from the problem set of my homework and it appears to be a really nice generalization of Kolmogorov's inequality. However, when I was trying to imitate the standard proof of Kolmogorov's inequality and the proof given by Sergio for cases in which $r$ is an even integer, there occurred the problem that binomial expansion cannot be properly applied to general cases in which $r$ is an arbitrary real. I wonder if the step that uses binomial expansion in the proof of Kolmogorov's inequality is correct for this generalization or if there is a proof that avoids this particular step. Thanks!","['inequality', 'probability']"
2566304,Simplify: $\arctan \sqrt{\frac{1-\cos x}{1+\cos x}};$ $0<x<\pi$,"$$\arctan \sqrt{ \frac{1-\cos x}{1+\cos x} } $$ There are two ways you can procced with this: 1. $$=\arctan{\sqrt{\left(\frac{2\sin^2{\frac{x}{2}}}{2\cos^2{\frac{x}{2}}}\right)}}$$
$$=\arctan{\left(\tan\frac{x}{2}\right)}$$ $$=\frac{x}{2}$$ 2. $$=\arctan{\sqrt{\left(\frac{\sin^2{\frac{x}{2}}+\cos^2{\frac{x}{2}}-2\cos\frac{x}{2}\sin \frac{x}{2}}{\sin^2{\frac{x}{2}}+\cos^2{\frac{x}{2}}+2\cos{{\frac{x}{2}}}\sin{\frac{x}{2}}}\right)}}$$ $$=\arctan{
\sqrt{
       \left(\frac
                   {\cos \frac{x}{2} -\sin \frac{x}{2} }{\cos \frac{x}{2} +\sin \frac{x}{2} } \right) ^2
}
}$$ $$=\arctan \left(\frac{\cos\frac{x}{2}-\sin\frac{x}{2}}{\cos\frac{x}{2} + \sin\frac{x}{2}}\right)$$ Dividing by $\cos \frac{x}{2}$ $$=\arctan \left(\frac{1-\tan \frac{x}{2}}{1+\tan \frac{x}{2}}\right) $$ $$=\arctan\left[ \tan \left( \frac{\pi}{4}-\frac{x}{2} \right)\right] $$ $$=\frac{\pi}{4}-\frac{x}{2}$$ So, are both these answers correct? or one of them is incorrect?",['trigonometry']
2566319,The figures from $1$ to $120$ were made in $15$ rows. Which column has the largest sum of the numbers?,Question : The figures from $1$ to $120$ were made in $15$ rows. Which column has the largest sum of the numbers? ( Starting from the left ) I tried only with calculating. I could not find an elegant way. I'm looking for a simple solution that does not require calculation. Because this is the exam question. We have up to maximum 2-3 minutes.,"['algebra-precalculus', 'number-theory']"
2566325,Why does this power series defined on the open unit disk take on every complex number infinitely often?,"This is a problem from Rudin's Real and complex analysis. Let us take a sequence of integers $\{n_k\}$ with $n_1 >1$ and $n_{k+1} > 2kn_{k}.$ We let 
$$f(z) = \sum_{k=1}^\infty 5^k z^{n_k}.$$
It is not too hard to prove that this series converges for $|z|<1,$ and that $f$ has no finite radial limits. However, from what I understand, it is also true that $f$ attains every value $z \in \mathbb{C}$ infinitely often. I am stuck in how to prove this. One idea was to use Rouche's theorem, but that didn't get me too far. Any hint, or solution, is welcome. EDIT Here is an idea, which I do not know if it is correct or not. Let $a \in \mathbb{C}$ and suppose that $f(z) = a$ for only finitely many values $z$ in the open unit disk. Then if we consider $f(z) -a,$ there is a polynomial $P(z)$ with the same zeros as $f(z)-a.$ Then if we let $$g(z) = P(z)/(f(z)-a),$$ $g$ is holomorphic in the open unit disk. If we had that $g$ could be extended to a holomorphic function on some open containing $D^1,$then we would be done, since $g(z) = 0$ on the boundary of the unit disk would contradict the maximal modulus principle. However, it is to me far from clear that $g$ extends. EDIT 2 Maybe it is true that we do not need that $g$ extends. Namely, since $g$ has no zeros inside of $D,$ it is true that $g(0) \neq 0.$So $|g(0)| >0.$ however, since $g(z) \to 0$ on the radial limits, this means that we should be able to derive a contradiction to the maximum modulus principle.","['complex-analysis', 'analysis']"
2566338,Understanding the definition of free and bound occurrence,"I am struggling to understand the following definitions. $\textbf{Definition}$. Let $x$ be a variable symbol and let $F$ be a formula. For each occurrence of the symbol $x$, which does not immediately follow a quantifier, in the formula $F$, we define whether the occurrence of $x$ is $\textbf{free}$ or $\textbf{bound}$ inductively as follows. (1) If $F$ is a formula of one of the forms $y = z$ or $y \in z$, where $y$ and $z$ are variable symbols (possibly equal to $x$), then every occurrence of $x$ in $F$ is free, and no occurrence is bound. (2) If $F$ is a formula of one of the forms $\neg G, (G \land H), (G \lor H), (G \rightarrow H), (G \iff H)$, where $G$ and $H$ are formulas, then each occurrence of the symbol $x$ is either an occurrence in the formula $G$ or an occurrence in the formula $H$, and each free (respectively, bound) occurrence of $x$ in $G$ remains free (respectively, bound) in $F$, and similarly for each free (or bound) occurrence of $x$ in $H$. $\textbf{Question}.$ These two last paragraphs are completely vague to me. Can someone please explain to me what these two notions (free and bound occurrence) mean, preferably with an example or two? $\textbf{PS}$. I can read the set notations like $\neg G, (G \land H), (G \lor H), (G \rightarrow H), (G \iff H)$. I just don't understand the notion of free and bound.","['predicate-logic', 'first-order-logic', 'logic', 'elementary-set-theory']"
2566339,Solve $f(x+f(2y))=f(x)+f(y)+y$,"Find all $f:\mathbb{R}^+\to \mathbb{R}^+$ such that for each $x$ and $y$ in $\mathbb{R}^+$, $$f(x+f(2y))=f(x)+f(y)+y$$ Note:
$f(x)=x+b$ is a solution for all  $b\in\mathbb{R}^+$ but I can not prove it.","['real-analysis', 'real-numbers', 'functions', 'functional-equations']"
2566358,unbiased estimator of sigma in normal distribution,"It's mathematical statistics, but i couldn't find the category of it.
Anyway, i am not sure that i did it right. I need help.
r.s is random sample,
and u.e is unbiased estimator.","['statistics', 'estimation']"
2566381,Lie derivative of volume form,"The volume from on an oriented 4-dimensional (pseudo-) Riemannian manifold $(M,g)$ is given by $$\Omega :=\sqrt{\lvert g\rvert}\,dx^{0}dx^{1}dx^{2}dx^{3}:=\sqrt{\lvert g\rvert}\,d^{4}x$$ where $g=\text{det}(g_{\mu\nu})$ is the determinant of the metric tensor $g_{\mu\nu}$ (apologies for my sloppy physicist notation). Given a diffeomorphism $\phi:M\rightarrow M$, the volume form $\Omega$ should change by a Lie derivative, i.e. $$\delta\Omega =\mathcal{L}_{X}\Omega$$ where $X$ is the vector field generating the diffeomorphism. Now I know that $$\delta\left(\sqrt{\lvert g\rvert}\right)=\mathcal{L}_{X}\left(\sqrt{\lvert g\rvert}\right) =\frac{1}{2}\sqrt{\lvert g\rvert}g^{\mu\nu}\delta g_{\mu\nu}=\sqrt{\lvert g\rvert}g^{\mu\nu}\nabla_{\mu}X_{\nu}$$ where I have used that $\delta g_{\mu\nu}=\mathcal{L}_{X}g_{\mu\nu}=\nabla_{\mu}X_{\nu}+\nabla_{\nu}X_{\mu}$. And so, so far I have $$\mathcal{L}_{X}\Omega=\mathcal{L}_{X}\left(\sqrt{\lvert g\rvert}\right)d^{4}x+\sqrt{\lvert g\rvert}\,\mathcal{L}_{X}\left(d^{4}x\right)=g^{\mu\nu}\nabla_{\mu}X_{\nu}\,\Omega+\sqrt{\lvert g\rvert}\,\mathcal{L}_{X}\left(d^{4}x\right)$$ However, I'm not sure how $d^{4}x$ transforms, so my question is: what is the Lie derivative of $d^{4}x$? i.e. what is $$\mathcal{L}_{X}\left(d^{4}x\right)\;?$$ I'm a physicist and so my knowledge of differential geometry is not that extensive, any help would be much appreciated.","['lie-derivative', 'riemannian-geometry', 'differential-geometry']"
2566405,On the proof of the Hermitian functions being a basis of $L^2(R)$ space.,Define $h_k(x) = H_k(x) e^{- x^2/2} $ where $H_k(x)$ is the k-th Hermitian polynomial. Assuming already having shown that the $h_k(x)$ form an orthonormal system in $L^2(R)$ with the usual inner product how can one prove that they are a basis?,"['functional-analysis', 'real-analysis', 'hilbert-spaces']"
2566406,Possible set theoretic hazzard with this definition?,"I don't know much about ZFC set theory, other than that it exist, and my thinking of set theory more or less corresponds to ""naive set theory"". However, I just formulated a set for a problem, and I'm thinking it may cause set-theoretic problems because it is based on an iterative definition: $$X=\{a\}\cup\{f_i(x)|x\in X,i=1,..,n \}$$ Intuitively, I'm adding one element $a$ to the set $X$, and then saying: for every $x$ in $X$, $f_i(x)$ (for a finite number of $i$) is also in $X$. Does this cause set-theoretic problems?",['elementary-set-theory']
2566410,Expected value of exactly one ball in n balls in n boxes,"$n$ balls are placed randomly into $n$ boxes. Let $N_1$ be the number of boxes with exactly one ball. Find $E(N_1)$. Show it is about $\frac{n}{e}$ I tried breaking it into indicator variables, where $N_1 = L_1 + L_2 + ... + L_n$
Where $L_i = 1$ if box i has ball 1, and $0$ otherwise, Then (I think) $P(L_i = 1) = \frac{(n-1)^{n-1}}{n^n}$ And since this is a binomial distribution, $E(N_1) = n\frac{(n-1)^{n-1}}{n^n}$ But I'm not sure how to get this to $\frac{n}{e}$","['combinatorics', 'probability']"
2566423,Integral of exponential of Gaussian process has a known distribution?,"If $f(x)$ is Gaussian process, i.e., $$
f(x) = GP [m(x), \kappa(x, x')]
$$ can we say anything about the distribution of the integral of the exponential of this, i.e., $$
F = \int e^{f(x)} dx 
$$ or, if it's more helpful, the logarithm $ln[F]$? This previous post uses the Riemann sum to show the distribution of the integral of a Gaussian process is Gaussian, though I've had no luck applying the same idea to the above problem. This post discusses a similar problem but for the complex case. A paper linked in that post discusses the distribution of $\int_0^T exp(u X(t)) dt$ where $X(t)$ is Brownian motion, though I'm not sure I understand the connection between Gaussian processes and Brownian motion enough for this to help.","['stochastic-processes', 'probability', 'probability-distributions']"
2566473,Analyze the convergence of the series: $\sum_{n=1}^{\infty} \frac{n^n}{(n+1)!}$,"In analyzing the convergence of the following series: $$\sum_{n=1}^{\infty} \frac{n^n}{(n+1)!}$$ Using the quotient criteria, I get the following: $$
\frac{a_{n+1}}{a_n} = \frac{\frac{(n+1)^{n+1}}{(n+2)!}}{\frac{n^n}{(n+1)!}} = \frac{(n+1)^{n+1}(n+1)!}{(n+2)!n^n} = \frac{(n+1)^{n+1}(n+1)!}{(n+2)(n+1)!n^n} = \frac{(n+1)^{n+1}}{(n+2)n^n}
$$ Now I am trying to find the limit of $\frac{a_{n+1}}{a_n}$: $$
\lim_{n \to \infty}\frac{a_{n+1}}{a_n} = \lim_{n \to \infty}\frac{(n+1)^{n+1}}{(n+2)n^n} = ?
$$ But I am having trouble solving this. What steps do I need to follow to simplify and solve this limit?","['sequences-and-series', 'limits']"
2566483,Can we use simultaneous row and column operations in solving same determinant?,Please help.. Can both(row and column) operations be used simultaneously in finding the value of same determinant means in solving same question at a single time?,"['matrices', 'determinant']"
2566491,"Baby algebra (Minimal polynomials, etc.)","I wonder if it's legal to post a question that you already know the answer to, just because people might find it interesting. In case not there are two questions at the bottom, one of which I don't know the answer to. Throughout all this $T$ will  be a $2\times 2$ real matrix. First, context - my work so far: I recently posted an answer to a question about $T$, where I essentially proved this: If $T^3=I$ then $T=I$ or $T^2+T+I=0$. First version: Note that $t^3-1=(t-1)(t-\alpha)(t-\overline\alpha)$, where $\alpha=e^{2\pi i/3}$. Note that the minimal polynomial has degree no larger than $2$. Bringing in complex numbers seems like cheating. Second version: Note that $t^3-1=(t-1)(t^2+t+1)$. Since $t^2+t+1$ is irreducible the minimal polynomial must be $t-1$ or $t^2+t+1$. Was happier with that. Then I realized that I'd implicitly used the fact that $\mathbb R[t]$ is a UFD. Wasn't too hard to verify that. (Why not just open a book? The only things I feel I really understand or ever remember are things I've worked out for myself.) What I'd shown was this: If $R$ is a PID and every element of $R$ is a product of irreducibles then $R$ is a UFD. It's clear that every polynomial is a product or irreducibles, so $\mathbb R[t]$ is a UFD. But this finally reminded me of something from an algebra class years ago: Of course every PID is a UFD. Was stuck for a bit showing that in a PID every element is a product of irreducibles. Realized I needed to show ACC. Mentioned this to a guy at the office, and he said that in fact A ring satisfies ACC if and only if every ideal is finitely generated. (So in particular every PID has ACC, finishing the proof that every PID is a UFD.) He said he didn't recall the proof. In fact it's more or less obvious: Say $I$ is an ideal which is not finitely generated. Let $x_1\in I$. We can recursively choose $x_n\in I$ so $x_{n+1}\notin<x_1,\dots,x_n>$, and there's your ascending chain of ideals. Conversely, say every ideal is finitely generated, and suppose $I_1\subset I_2\dots$ is a chain of ideals. Let $I=\bigcup I_n$. If $g_1,\dots,g_n$ generate $I$ there exists $N$ with $g_1,\dots, g_n\in I_N$. Hence $I=I_N$. Finally the questions. First the fun one: Question 1. Saying every ideal is countably generated is equivalent to what ACC-ish condition? (The answer will be immediately obvious to various readers. If you're one of them please give the kids a chance to try to figure it out.) And a question I don't know the answer to: Question 2. Say $T$ is a $2\times 2$ real matrix and $T^2+T+I=0$. That is, $T$ has eigenvalues $\alpha$ and $\overline\alpha$, where $\alpha$ is as above, so $T$ is $\mathbb C$-diagonalizable. Does it follow that $T$ is $\mathbb R$-similar to a rotation by $\pm 2\pi/3$? I can't imagine what else $T$ could be, but I haven't proved it. If the answer is yes that says a good deal more about what's really going on in the linear-algebra MSE question that started all this.",['abstract-algebra']
2566503,"Show that if $c$ is a point of $\Bbb{R}^n$ sufficiently close to $0$, then the equation $f(x)=c$ has a solution.","Let $f:\Bbb{R}^{k+n}\xrightarrow{}\Bbb{R}^n$ be of Class $C^1$; suppose that $f(a)=0$ and that $Df(a)$ has rank $n$. Show that if $c$ is a point of $\Bbb{R}^n$ sufficiently close to $0$, then the equation $f(x)=c$ has a solution. My attempt: Since, $Df(a)$ has full rank we know that the $\det Df(a) \ne 0$, as we all $f\in C^1$ and $f(a)=0$. So we can apply the implicit function theorem giving us an open neighbourhood $B$ of $a$. Such that $c\in B(0,\epsilon)$ then $f(x)=c$ must have a solution. How can I improve my answer?","['real-analysis', 'proof-verification', 'multivariable-calculus', 'matrix-rank', 'linear-algebra']"
2566524,"Understanding terminology of, fibers, clutchings and Hopf.","I have some questions regarding the terminology of fiber bundles as used in section 3 of this paper; http://www.sciencedirect.com/science/article/pii/S0723086907000151 The section starts off by recalling the Hopf Fibration $S^7\hookrightarrow S^{15}\rightarrow S^8$.  It says that because the fibers of this bundle are (diffeo to) $S^7$, it intersects with an 8-dimensional vector space of $\mathbb{R}^{16}$.  I'm not sure why the 7 dimensional $S^7$ it intersects an 8-dimensional space though, is it because the way it is parameterized with 8 variables/embedded in $\mathbb{R}^8$? It goes on to say that these fibers form an ""8-plane vector bundle $\zeta$ over $S^8$"".  In the texts I've been consulting I have not come across this term ""8-plane"" bundle, and google is no help.  Does this just literally mean 8 planes? I think that would be sensible since we're considering the 8 dimensional spaces that intersect $S^7$ over $S^8$, and if I'm understanding $\zeta$ correctly it's fibers are those 8 dimensional sub-spaces of $\mathbb{R}^{16}$ that intersect $S^7$. We then get that the clutching function for $\zeta$ is the map $a\rightarrow A(x)=ax$.  Now I'm pretty new to clutching functions (A la' Cohen and Hatcher texts on fiber bundles), and I'm not sure how to realize this as the clutching function.  My guess is that since we're dealing with a vector bundle we need the ""linearity"", and this map should be similar to the clutching function for the $S^7$-bundle which I believe is just rotation by octonions.  Also since our map is just repeated multiplication, $x^n$ I think that has a role to play, but that's just a heuristic guess. I've been pouring through texts and papers for days trying to get my head around all of this, so any clarity you can bring would be greatly appreciated!","['fiber-bundles', 'octonions', 'hopf-fibration', 'k-theory', 'differential-geometry']"
2566531,Prove that $f \in L^2(\mathbb{R})$ and $||f||_2 \leq 1$.,"The entire question reads: Let $f$ be a Lebesgue measurable function on $\mathbb{R}$ with the property that $\sup_{\{g \in L^2(\mathbb{R}):||g||_2 \leq 1\}}\int_{\mathbb{R}}|fg|d \lambda \leq 1$. Prove that $f \in L^2(\mathbb{R})$ and $||f||_2 \leq 1$. I'm not quite sure where to begin on this problem. I'm trying to get more practice with $L^p$ spaces, but it's clear I'm still lacking in skill and know-how. Any tips or tricks are greatly appreciated.","['real-analysis', 'lp-spaces']"
2566552,Basic math explanation (related to estimating linear regression with no intercept),"I have a question on the Cross Validated Stack Exchange site where I ask how to update the exponential regression coefficient of a vertically translated depreciation curve . A Cross Validated community member has been kind enough to provide an answer to my question. The solution has been explained as follows: ...the equation you need to
estimate is $$y=21-e^{ax},$$ which is equivalent to $$21-y=e^{ax}.$$ If you take logarithms both sides (you can do it because $y<21$ ), then $$log(21-y)=ax.$$ Renaming $log(21-y)=z$ , this is of the form $$z=ax,$$ which is a linear regression with no intercept that can be estimated
with many standard software packages. I think I understand everything up to, and including this part: If you take logarithms both sides (you can do it because $y<21$ ), then $$log(21-y)=ax.$$ However, as someone who has limited math skills, I'm having difficulty understanding a couple of things: Why would I want to rename $log(21-y)=z$ --as-- $z=ax$ ? How do I estimate the ""linear regression with no intercept""? Could #1 and #2 be explained, in layman's terms?","['statistics', 'linear-regression']"
2566607,Line integral over a non-central ellipse.,"I have to find the integral $$ \int_C ydx + x^2dy$$ over the curve $C$ given as a intersection of plane $z=0$ and surface $\frac{x^2}{a^2} + \frac{y^2}{b^2}=\frac{x}{a}+\frac{y}{b} $, curve $C$ is positively oriented $(a\geq b>0)$. This is what i have this far: given plane is $xy$ plane, it's intersection with this surface (whatever it is in the three-dimensional space) should be some sort of ellipse (non-origin ellipse) obviously, and the limits of integration should be from $0$ to $2\pi$. Now, after little bit of algebraic manipulation of the surface equation i got the following equation: $$\frac{(x-\frac{a}{2})^2}{\frac{a^2(a^2+b^2)}{4}} + \frac{(x-\frac{b}{2})^2}{\frac{b^2(b^2+a^2)}{4}}=1$$ Which is indeed an ellipse eqation, now , i suppose i should introduce polar coordinates here, in order to get the parametric equations for this curve, for this ellipse they should look something like this: $x=\frac{a}{2}+\frac{a^2(a^2+b^2)}{4}\cos t \\y=\frac{b}{2}+\frac{b^2(a^2+b^2)}{4}\sin t \\ dx=-\frac{a^2(a^2+b^2)}{4}\sin t \\dy=\frac{b^2(a^2+b^2)}{4}\cos t $ Now, all i should do is to insert this into the given integral, but, i am not quite sure is this legitimate approach. Any suggestions or comments if this is incorrect is appreciated or if it is correct, any advice on how to do this more easily is appreciated too.","['multivariable-calculus', 'integration']"
2566609,Manipulating infinitely small $dx$,"From basic infinitesimal calculus, we know that the $$\frac{dy}{dx}=1$$ implies $$dy=dx.$$ However, what is the exact argument behind this result? Now, consider $$\frac{d^2y}{dx^2}=1.$$ Why can't we say that $$d^2y=dx^2?$$","['derivatives', 'infinitesimals']"
2566626,Different approach to classic pigeonhole principle problem yields different results. Why?,"This starts with a classic pigeonhole principle question, which has appeared on Mathematics Stack Exchange before , in various forms: During a month with 30 days, a baseball team plays at least one game a
  day, but no more than 45 games. Show that there must be a period of
  some number of consecutive days during which the team must play
  exactly 14 games. The standard solution involves defining the total number of games played by the end of day $i$ (where $i$ ranges from 1 to 30) as $a_{i}$. Since at least 1 game is played each day, $a_{1}...a_{30}$ is strictly increasing, and we can say that $1 \leq a_{i} < 45$. To find out if 14 games over some series of consecutive days is possible, we add 14 to all elements of this inequality, which yields $15 \leq a_{i}+14 < 59$, a second strictly increasing sequence. Between the two lists, we have 60 values, but each value can only be an integer ranging from 1 to 59. Therefore, by the pigeonhole principle, there must be at least 1 duplicate value in the range. Since there cannot be a duplicate value within either strictly increasing list, the duplicates must be on different lists. Therefore, there is a sequence of days on which the team must play 14 games. To me, this is a wholly unsatisfying answer. When reading the question, it seems like the 30 days should quite obviously be the pigeons, and we need to work out how many pigeonholes there are. Here's the approach I developed. In this problem, we need to find possible values that have a difference of 14. Start by dividing all the values from 1 to 45 into 14 sets, where each set contains all the numbers from 1 to 45 which share a common congruence modulo 14. For example, set $1$ is $\{1, 15, 29, 43\}$, set 2 is $\{2, 16, 30, 44\}$, and set 3 is $\{3, 17, 31, 45\}$. Solutions to pigeonhole principle problems often involve considering the worst-case scenario, so the next step is to try to see how many numbers from 1 to 45 could be chosen while managing to avoid 2 numbers with a difference of exactly 14. When any of these sets is in an ascending arrangement (as shown above), any 2 consecutive elements will have a difference of 14. You can only choose the maximum number of elements from such a set in an ascending arrangement by choosing every other element. Therefore, the maximum amount of elements which can be chosen from a set with an even order $n$ is $n/2$, The maximum amount of elements which can be chosen from a set with an odd order $n$ is $\lceil n/2 \rceil$. We can use $\lceil n/2 \rceil$ as a formula for a set of any order, to determine the maximum amount of elements which can chosen without choosing 2 elements which differ by exactly 14. Sets 1, 2, and 3, as shown above, are sets of order 4. The remaining 11 sets, $\{4, 18, 32\},\{5, 19, 33\},...\{14, 28, 44\}$ are sets of order 3. From the order 4 sets, you can choose a maximum of $\lceil 4/2 \rceil=2$ elements without having any 2 differ by exactly 14. From the order 3 sets,you can choose a maximum of $\lceil 2/2 \rceil=2$ elements without having any 2 differ by exactly 14. Therefore, from the set of integers from 1 to 45, we can choose at most $(3)(2)+(11)(2)=28$ elements where no 2 differ by exactly 14. They aren't hard to find, either. For example, choosing the numbers 1 through 14, avoiding the numbers 15 through 28, and then choosing the numbers 29 through 42 gives you 28 numbers, none of which differ by exactly 14. Also note that choosing just 1 more value means you must choose a number that differs from an already-chosen number by 14. We now know that we can choose a maximum of 28 different values from this range in such a way that any 2 value do not differ by exactly 14. Since we're choosing 30 values, there must be at least 1 pair of values that differ by exactly 14. I prefer this approach, as it doesn't add extra sets or values outside the original range, and in the process, you learn exactly the maximum amount of values you can choose in a range without having a specific difference. I've also found an important difference in these 2 approaches. What happens if we keep the original question, but change it to ask about, say, consecutive days where the team must play 16 games. If you use the standard approach, you still get 60 values as the pigeons, but a range of possible values from 1 to 61 as the number of pigeonholes. This suggests that we can't apply the pigeonhole principle to this problem. If you use the approach I developed, you work out that you can choose a maximum of $(13)(\lceil 3/2 \rceil)+(3)(\lceil 2/2 \rceil)=29$ different integer values (such as 1 through 16 and 33 through 45) from 1 to 45 without having any 2 differ by exactly 16. By the pigeonhole principle, it is impossible to choose 30 values from 1 to 45 without some 2 of those values having a difference of 16. Here's my question: Both of these can't be right. What is the reason for the different answers? Is my approach flawed somehow? If so, how? Am I missing some assumption for the standard approach which doesn't apply to 16?","['combinatorics', 'pigeonhole-principle', 'discrete-mathematics']"
2566662,Solve $\sqrt{x^2+1}-\sqrt{4x^4-4x^2+2}=2x^3-x-1$,"Could you please help me solve for $x$ in
  $$\sqrt{x^2+1}-\sqrt{4x^4-4x^2+2}=2x^3-x-1.$$ I tried this way. But I could not solve further. Please help me. $$(\sqrt{x^2+1}-\sqrt{4x^4-4x^2+2})^2=(2x^3-x-1)^2$$","['algebra-precalculus', 'radicals']"
2566694,How can I prove that this polynomial has distinct roots?,"I have a polynomial $$
\gamma_k(x) = x^{2k+2} - m x^{2k} - n x^k - 1
$$ where $m$ and $n$ are positive real numbers and $k$ is a positive even integer. How can I prove $\gamma_k(x)$ has distinct roots for any $m$,$n$ and $k$ ?","['roots', 'polynomials', 'functions']"
2566695,Why a short sequence of modules is exact if and only if the short sequence of their localization at any prime ideal is exact?,"The following problem is a part of the exercise 10 of Chapter III of S. Lang's Algebra , which turns out to be a little difficult: Let $A$ be a unital commutative ring and $M$, $M'$, $M''$ be $A$-modules. Then $$0\to M'\to M\to M''\to 0$$ is exact if and only if $$0\to M'_\mathfrak{p}\to M_\mathfrak{p}\to M''_\mathfrak{p}\to 0$$ is exact for each prime ideal $\mathfrak p\subset A$, where $M_\mathfrak{p}=S^{-1}M$ (here $S=A\setminus\mathfrak p$) is the localization at $\mathfrak p$. The ""only if"" part is a direct corollary of a previous exercise (exercise 9 of Chapter III, precisely) of this book and the ""if"" part is what really makes me stuck. I tried reduction to absurdity,  but had not idea how to choose a proper prime ideal $\mathfrak p$ to get a contradiction. So I would like to ask how to carry on the proof the necessity of this problem... Thanks in advance...","['localization', 'abstract-algebra', 'exact-sequence', 'modules']"
2566751,Uniqueness of connection $1$-forms and curvature $2$-forms,"If $(M,\langle\cdot,\cdot\rangle)$ is a pseudo-Riemannian manifold and $\nabla$ denotes the Levi-Civita connection of the metric, we can define the connection $1$-forms and curvature $2$-forms relative to any frame $(E_1,\ldots,E_n)$, not necessarily orthonormal, by $$\nabla_XE_j = \sum_i \omega^i_{\;j}(X)E_i \quad \mbox{and}\quad R(X,Y)E_j = \sum_i \Omega^i_{\;j}(X,Y)E_i,$$ok. Then, if $(\theta^1,\ldots,\theta^n)$ denotes the dual coframe, one proves the structure equations $${\rm d}\theta^i = \sum_{j} \theta^j \wedge \omega^i_{\;j}\quad\mbox{and}\quad\Omega^i_{\;j} = {\rm d}\omega^i_{\;j}+\sum_k \omega^i_{\;k}\wedge \omega^k_{\;j}.$$I recall seeing somewhere that these structure equations actually characterize the connection and curvature forms, but I don't recall where. So I'd like a reference or proof for this result. More precisely: If $\widetilde{\omega}^i_{\;j}$ and $\widetilde{\Omega}^i_{\;j}$ satisfy$${\rm d}\theta^i = \sum_{j} \theta^j \wedge \widetilde{\omega}^i_{\;j}\quad\mbox{and}\quad\widetilde{\Omega}^i_{\;j} = {\rm d}\widetilde{\omega}^i_{\;j}+\sum_k \widetilde{\omega}^i_{\;k}\wedge \widetilde{\omega}^k_{\;j},$$then $\widetilde{\omega}^i_{\;j} = \omega^i_{\;j}$ and $\widetilde{\Omega}^i_{\;j} = \Omega^i_{\;j}$? Thanks. Edit: inspired by the comments... do we get the desired characterization adding the assumption that $${\rm d}g_{ij}=\sum_k (g_{ik}\omega^k_{\;j}+g_{jk}\omega^k_{\;i})$$ ? I use the conventions $R(X,Y)Z = \nabla_X\nabla_YZ - \nabla_Y\nabla_XZ - \nabla_{[X,Y]}Z$; $\alpha \wedge \beta = \frac{(k+\ell)!}{k!\ell!}{\rm Alt}(\alpha\otimes\beta)$, for $\alpha \in \Omega^k(M)$ and $\beta \in \Omega^\ell(M)$; ${\rm Alt}\gamma= \frac{1}{r!}\sum_{\sigma \in S_r}(-1)^{|\sigma|} \gamma^\sigma$, where $\gamma \in \Omega^r(M)$.","['semi-riemannian-geometry', 'riemannian-geometry', 'differential-geometry', 'exterior-algebra']"
2566754,"Is it true that $\langle \psi, \omega\rangle$ is the dimension of $Hom(V,W)$?","If $(\psi,V)$ and $(\omega,W)$ are two characters of two representations of a  group $G$ , then $$
\langle \psi, \omega\rangle = \dim \operatorname{Hom}_G(V,W)?
$$ Here $\langle\cdot,\cdot\rangle$ is the standard inner product of characters of representations and $\operatorname{Hom}_G(V,W)$ is the vector space of intertwining operators from $V$ to $W$ . I am guessing this is true from examples I have seen. I think that Schur's lemma in fact says that this is true when $V,W$ are irreducible. But is it true in general? If so, how might one go about proving it? (I am not asking for a complete proof, just the basic idea of it.) I should maybe add that as a definition the character of a representation is the trace thing.","['abstract-algebra', 'representation-theory', 'characters']"
2566777,What is the theory behind rigorous hypothesis testing?,"I understand that hypothesis testing is essentially a statistical form of proof by contradiction. In proof by contradiction, you assume P, then show that it leads to a result Q, which you know to be false. Since we assume logical consistency, Q and ~Q cannot both be true, therefore ~P. In hypothesis testing, you start with a hypothesis H and you make an observation, O. If you find that P(O | H) << 1, then we can say that H is unlikely, in a similar way to proof by contradiction, but this reasoning is a heuristic one. What is the formal mechanism behind this result? How do you get from P(O | H) << 1 to P(H | O) << 1?","['probability-theory', 'probability', 'statistics', 'hypothesis-testing']"
2566783,Differentiating under the integral sign and $C^1$ class,"Suppose that $f\in C^1(\mathbb{R}^n; \mathbb{R})$ and $g(x)=\int_{0}^{1}f(x+ty)dt$, where $y \in \mathbb{R}^n$. How to rigorously show that the function $g(x)$ is continuously differentiable? Since the function $f(x+ty)$ is continuously differentiable for both $x \in \mathbb{R}^n$ and $t \in ]0,1[$ that result seems very reasonable, but I don't know what is the true mathematical reason behind that result.","['multivariable-calculus', 'real-analysis', 'calculus', 'analysis']"
2566817,"$\|S\|=\sup\{|\langle Sx\;,\;y\rangle |;\;\|x\| \leq 1,\, \|y\| \leq 1\}\,?$","Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on a complex Hilbert space $F$. Let $S\in \mathcal{B}(F)$. The norm of $S$ is defined us
$$\|S\|:=\sup_{\substack{x\in F\\ x\not=0}}\frac{\|Sx\|}{\|x\|}$$ Why
$$\|S\|=\sup_{\substack{\|x\| \leq 1,\\ \|y\| \leq  1}}|\langle Sx\;,\;y\rangle |?$$ Thanks.",['functional-analysis']
2566850,Derive formula for number of tilings of an $m \times n$ board.,I have tried to find the derivation of the formula for the number of tilings of an $m \times n$ board with $2 \times 1$ tiles which is the following. $$\prod_{k=1}^{m}\prod_{l=1}^{n} \left(4\cos^2{\frac{k\pi}{m + 1} + 4\cos^2{\frac{l\pi}{n + 1}}}\right)^{\frac{1}{2}}$$ Could anyone show me how to derive it or where I could find the derivation for this incredible formula?,"['matrices', 'combinatorics', 'recreational-mathematics', 'tiling']"
2566860,Exterior derivative of a $0$-form,"Let $n\in\mathbb{N}$, $f \in F_1(\mathbb{R}^n)$, say, $$f = \sum_{j=1,...,n}f_jdx_j,$$ with $df=0$. Define for each $x\in\mathbb{R}^n$, $$u(x)=\sum_{j=1,...,n}\int_{[0,1]}f_j(tx)p_j(x)dt$$ ($p_j$'s are projections). Then $u \in F_0(\mathbb{R}^n)$ and $du=f$. It seems to me that it is clear $u$ is a $0$-form, correct? Now, what I (think I) can do so far is $$du = d\sum_{j=1,...,n}\int_{[0,1]}f_j(t-)p_j(-)dt = \sum_{j=1,...,n}d\int_{[0,1]}f_j(t-)p_j(-)dt =$$ $$ \sum_{j=1,...,n}\sum_{k=1,...,n}\partial_k(\int_{[0,1]}f_j(t-)p_j(-)dt)dx_k = \sum_{j=1,...,n}\sum_{k=1,...,n}\int_{[0,1]}\partial_k(f_j(t-)p_j(-))dtdx_k =$$ $$\sum_{j=1,...,n}\sum_{k=1,...,n}\int_{[0,1]}(t(\partial_k(f_j))(t-)p_j(-)+f_j(t-)\partial_k(p_j)(-))dtdx_k = ...$$ am I still good here, or did I go astray? If I'm good, how do I continue? Am I making things more complicated than they are? Also, I realize that the hypothesis is that $$0 = df = \sum_{j=1,...,n}\sum_{k=1,...,n} \partial_k(f_j) dx_k \wedge dx_j.$$ Thanks in advance.","['differential-forms', 'differential-geometry']"
2566920,Why is the hypotenuse in trig always positive regardless of the quadrant?,"I see an image like this: In quadrant 2, even though the cosine is negative, because the x coordinate goes to the left, the hypothenuse is still positive. Why is this? It seems like the direction of x matters when determining if cos is positive or negative, why doesn't this hold for the hypothenuse too? Why is the hypotenuse always positive? Why do some people talk about trig using triangles vs unit circles? Is one more correct than the other?",['trigonometry']
2566954,Is there a good way of visualizing Grassmann manifolds?,"I am trying to explain $Gr_{\mathbb{R}}(m,n)$, the Grassmann manifold of the collection of $n$-dimensional linear subspaces of the $\mathbb{R}^m$ 
 space. After I used the projective space homeomorphic example $Gr_{\mathbb{R}}(3,1)$ and $Gr_{\mathbb{R}}(2,1)\cong S^1$ to illustrate the ""shape"" of Grassmann manifolds, I was then asked if there is an uniformly used or visually intuitive way of visualizing $Gr_{\mathbb{R}}(m,n)$? At least for low dimensions?","['algebraic-topology', 'visualization', 'manifolds', 'algebraic-geometry']"
2566961,Deriving the asymptotic estimate (9.62) in Concrete Mathematics,"I was reading Chapter 9: Asymptotics in Graham, Knuth, Patashnik: Concrete Mathematics, and I got stuck while deriving the following asymptotic estimate on page 466:
$$
\begin{equation}
  g_n = \frac{e^{\pi^2/6}}{n^2} + O(\log n / n^3) \, ,
  \quad \text{for } n > 1 \, . \tag{9.62}
\end{equation}
$$
The value $g_n$ is the coefficient of $z^n$ in the generating function
$$
\begin{equation}
  G(z) = \exp\left(\sum_{k \geq 1} \frac{z^k}{k^2}\right) \, . \tag{9.57}
\end{equation}
$$ To derive the estimate, one starts by differentiating $(9.57)$:
$$
  G'(z) = \sum_{n \geq 0} n g_n z^{n-1} = \left( \sum_{k \geq 1} \frac{z^{k-1}}{k} \right) G(z) \, .
$$
Equating coefficients of $z^{n-1}$ on both sides leads to the following recurrence for $g_n$:
$$
\begin{equation}
  n g_n = \sum_{0 \leq k < n} \frac{g_k}{n-k} \, . \tag{9.58}
\end{equation}
$$
Next, one proceeds with the following bootstrapping trick. Start with a rough initial estimate $g_n = O(1)$, obtained by showing that $0 < g_n \leq 1$ for $n \geq 0$. Plug the initial estimate into the recurrence to get a better estimate $g_n = O(\log n / n)$. By repeatedly plugging new estimates back into the recurrence and massaging the recurrence when needed, one gets successively better estimates, leading up to the following one that is one step away from $(9.62)$ (note the differently placed exponent in the $O$ term):
$$
\begin{equation}
  g_n = \frac{e^{\pi^2/6}}{n^2} + O(\log n / n)^3 \, ,
  \quad \text{for } n > 1 \, . \tag{9.61}
\end{equation}
$$
Another bootstrapping step is supposed to give $(9.62)$. However, I fail to carry out the calculation. Here are some of the attempts I made. Attempt 1 Let me denote the constant $e^{\pi^2 / 6}$ by $c$. When I plug $(9.61)$ directly into $(9.58)$, I get the following:
$$
\begin{align}
  n g_n = {} & \frac{1}{n} + \sum_{0 < k < n} \frac{c}{k^2 (n-k)} + \sum_{0 < k < n} \frac{O(\log n)^3}{k^3 (n-k)} \\
  = {} & \frac{1}{n} + c \sum_{0 < k < n} \left( \frac{1}{n k^2} + \frac{1}{n^2 k} + \frac{1}{n^2(n-k)} \right) \\
  & {} + O(\log n)^3 \sum_{0 < k < n} \left( \frac{1}{n k^3} + \frac{1}{n^2 k^2} + \frac{1}{n^3 k} + \frac{1}{n^3 (n-k)} \right) \\
  = {} & \frac{1}{n} + c \left( \frac{1}{n} H^{(2)}_{n-1} + \frac{2}{n^2} H_{n-1} \right) + O(\log n)^3 \left( \frac{1}{n} H^{(3)}_{n-1} + \frac{1}{n^2} H^{(2)}_{n-1} + \frac{2}{n^3} H_{n-1} \right) \, .
\end{align}
$$
(In the last step, $H^{(i)}_{n-1}$ stands for generalized harmonic numbers, and $H_{n-1}=H^{(1)}_{n-1}$.) This seems to be worse than what I started with, since for example
$$ \frac{1}{n} H^{(3)}_{n-1} O(\log n)^3 = O\left( \frac{(\log n)^3}{n} \right) \, , $$
so $O((\log n)^3 / n^2)$ appears in the final estimate for $g_n$. Attempt 2 Another attempt involves the trick of ""pulling out the largest part."" This trick is used in Concrete Mathematics to derive $(9.61)$. We can massage the recurrence $(9.58)$ to obtain the following:
$$
\begin{align}
  n g_n & = \sum_{0 \leq k < n} \frac{g_k}{n} + \sum_{0 \leq k < n} g_k \left( \frac{1}{n-k} - \frac{1}{n} \right) \\
  & = \frac{1}{n} \sum_{k \geq 0} g_k - \frac{1}{n} \sum_{k \geq n} g_k + \frac{1}{n} \sum_{0 \leq k < n} \frac{k g_k}{n-k} \, .
\end{align}
$$
The first sum is $G(1)=c$. For the second sum, I have
$$
\begin{align}
  \sum_{k \geq n} g_k
  & = \sum_{k \geq n} \frac{c}{k^2} + O\left( \sum_{k \geq n} \frac{(\log k)^3}{k^3} \right) \\
  & = c \left( \frac{\pi^2}{6} - H^{(2)}_{n-1} \right) + O\left( \frac{(\log n)^3}{n^2} \right) \, .
\end{align}
$$
It doesn't look like I'm going to end up with anything as nice as $(9.62)$, but at least the final asymptotic error is still within $O(\log n / n^3)$. However, things fail again when I analyze the third sum:
$$
\begin{align}
  \sum_{0 \leq k < n} \frac{k g_k}{n-k}
  & = \sum_{0 < k < n} \frac{c}{k (n-k)} + \sum_{0 < k < n} \frac{O(\log n)^3}{k^2 (n-k)} \\
  & = \frac{c}{n} \sum_{0 < k < n} \left( \frac{1}{k} + \frac{1}{n-k} \right) + O(\log n)^3 \left( \frac{1}{n} H^{(2)}_{n-1} + \frac{2}{n^2} H_{n-1} \right) \\
  & = \frac{2c}{n} H_{n-1} + O(\log n)^3 \left( \frac{1}{n} H^{(2)}_{n-1} + \frac{2}{n^2} H_{n-1} \right) \, .
\end{align}
$$
Similarly as in Attempt 1, there is a term
$$ \frac{1}{n} H^{(2)}_{n-1} O(\log n)^3 = O\left( \frac{(\log n)^3}{n} \right) \, , $$
leading to $O(\log n / n)^3$ in the final estimate for $g_n$. Attempt 3 After pulling out $1/n$ in Attempt 2, we see that the first sum gives us exactly the leading term in $(9.62)$, so that sum should stay as it is. The second and the third sum are problematic. Each on its own contributes too much, so I guess the trick is to somehow fuse them together. One idea is to try pulling out another $1/n$ from the third sum:
$$
\sum_{0 \leq k < n} \frac{k g_k}{n - k}
= \frac{1}{n} \sum_{0 \leq k < n} k g_k + \frac{1}{n} \sum_{0 \leq k < n} \frac{k^2 g_k}{n-k} \, .
$$
Now the sum $\sum_{0 \leq k < n} k^2 g_k / (n-k)$ is fine: with the same kind of analysis as in previous attempts we conclude it is $O((\log n)^4 / n)$, so with all the pulled-out parts it contributes $O(\log n / n)^4$ in the final estimate. What to do with $\sum_{0 \leq k < n} k g_k$? My idea was to decompose it as in Attempt 2:
$$
\sum_{0 \leq k < n} k g_k = \sum_{k \geq 0} k g_k - \sum_{k \geq n} k g_k \, .
$$
Unfortunately, this doesn't work, because now the first sum is $G'(1)$, and this doesn't converge. What am I doing wrong? Do I need to massage the recurrence in some other way? There must be something obvious that I just don't see.","['generating-functions', 'recurrence-relations', 'asymptotics', 'discrete-mathematics']"
2566966,Why does sheafification functor being left adjoint imply that the presheaf kernel is a sheaf kernel,"I want to understand Ravi Vakil's remarks to 2.4.L . I wonder why sheafification functor being left adjoint implies that the presheaf kernel is a sheaf kernel. By his 1.6.12, kernel, which is a limit, commutes with right adjoints. But sheafification functor is left adjoint (so I don't now why he refers to 1.6.12).","['sheaf-theory', 'algebraic-geometry']"
2566979,$\overline{B_1(0)}$ is not weakly* sequentially compact in $(l^\infty)$',"I know the following theorem from the lecture: Let $X$ be a seperable Banachspace. Then $\overline{B(0)}$ is weakly* sequentially compact in $X'$. Since it is specified that $X$ has to be separable, I want to look at an example where $\overline{B_1(0)}$ is not necessarily weakly* sequentially compact in $X'$, if we choose a Banachspace $X$ that is not separable. I found out from a book that $\overline{B_1(0)}$ is not weakly* sequentially compact in $(l^\infty)'$. $l^\infty$ is not separable ( I showed that already), but how can we now show that $\overline{B_1(0)}$ is not weakly* sequentially compact in $(l^\infty)$'?","['functional-analysis', 'weak-convergence']"
2566981,$A^3\cdot B^3=X^3+Y^3$.,"Prove that if $A,B\in M_n (\mathbb {C}) $ then there exists $X,Y \in M_n (\mathbb {C}) $ s.t. $A^3\cdot B^3=X^3+Y^3$. If $A,B $ commutes then it's clear. But what about the other case?","['matrices', 'abstract-algebra', 'linear-algebra']"
2566987,"If $E$ is measurable, then there is an interval $I$ such that $m(E \cap I) > \frac{9}{10} m(I)$ or $m(E^c \cap I) > \frac{9}{10} m (I)$.","Here is my answer at the moment: Suppose not! Then for all $I$, $m(E \cap I) \leq \frac{9}{10} \chi(I)$ and $m(E^c \cap I) \leq \frac{9}{10} \chi(I)$. Suppose $E$ has finite measure and let $E \subset \bigcup^{\infty}_{n=1} I_n$. Then
$$m(E) = m \left(E \cap \bigcup^{\infty}_{n=1} I_n \right) = m\left(\bigcup^{\infty}_{n=1} E \cap I_n \right) \leq m(E \cap I_n) \leq \frac{9}{10} \sum^{\infty} _{n =1} m (I_n)$$
Thus for all covers of $E$, $m(E) \leq \frac{9}{10} \sum^{\infty} _{n =1} m(I_n)$. But, by definition 
$$m(E) = \inf \{m(I_n) : E \subset \bigcup^{\infty}_{n=1} I_n\}$$
Hence 
$$m(E) \leq \frac{9}{10} m(E) \implies m(E) = 0$$
Now for $E$ with any measure, 
$$m(E \cap(-n,n) \cap I_n) \leq m(E \cap I) \leq \frac{9}{n}m(I_n)$$
Hence $m(E \cap (-n,n)) = 0$ for all $n$ where 
$$m(E) = m \left(\bigcup^{\infty}_{n=1} (E \cap(-n,n)) \right) \leq \sum^{\infty}_{n=1} m(E \cap (-n,n)) = 0$$
Note the same proof works for $m(E^c) = 0$. I am not certain that this argument works, or is complete. Is there any more to add, or change to make this proof complete? Thanks in advance!","['real-analysis', 'measure-theory']"
2566996,Difference between polynomial and power series,"My lecture notes say: A polynomial on $\mathbb{R}$ is a function $f: \mathbb{R} \to \mathbb{R}$ with $x \mapsto \sum_{k=0}^n a_k x^k$ with $n \in \mathbb{N}$ and $a_k \in \mathbb{R}$ . A power series in $x \in \mathbb{R}$ is the expression $\sum_{k=0}^\infty a_k x^k$ with $a_k \in \mathbb{R}$ . I don't really understand the difference here. What should ""expression"" mean in this case? Except that the second sum goes to infinity the definitions look the same to me. Can somebody explain me the differences?","['real-analysis', 'power-series', 'functions']"
2567082,Normal Distribution vs. Standard Normal Distribution vs. Gaussian Distribution?,"I know that Normal Distribution and Gaussian Distribution are the same thing, but today in class my teacher said that the mean of Gaussian Distribution = 0. I know that this isn't consistent with normal distributions, but rather standard normal distributions. Is the gaussian distribution the same as a normal distribution or a standard normal distribution, or am I wrong in thinking that the mean of every normal distribution can't be 0?","['statistics', 'probability']"
2567129,Reality of the Spectrum of Unbounded Self-Adjoint Operators,"Let $D$ be a closed unbounded operator densely defined on a Hilbert space $\cal{H}$. If $D$ is self-adjoint, then it is clear that its eigenvalues are real. Is it also clear that the elements of its spectrum are real?","['functional-analysis', 'operator-algebras', 'unbounded-operators']"
2567158,Looking for a proof of an interesting identity,"Working on a problem I have encountered an interesting identity: $$
\sum_{k=0}^\infty \left(\frac{x}{2}\right)^{n+2k}\binom{n+2k}{k}
=\frac{1}{\sqrt{1-x^2}}\left(\frac{1-\sqrt{1-x^2}}{x}\right)^n,
$$
where $n$ is a non-negative integer number and $x$ is a real number with absolute value less than 1 (probably a similar expression is valid for arbitrary complex numbers $|z|<1$). Is there any simple proof of this identity?","['power-series', 'sequences-and-series']"
2567170,What is an integral?,"I'm in a Real Analysis course at my school right now, and I've only just been introduced to integrals other then the Riemann integral. Some integrals from what I can tell seem to be much more generic, and have very little to do with what my previous notion of an integral was (the inverse of a derivative or the area under a curve). So my question is what actually makes something an integral? Must it have the Riemann integral as a special case, or are the all in some loose conceptual way related to the area under a curve, or the inverse of a derivative, or am I completely missing the point?","['integration', 'analysis']"
2567194,Proving limit without using dominated convergence theorem,"Since $|x^{1/n} \sin (x)| \leq \pi$ for $x \in [0,\pi]$ it is an easy result of the Dominated Convergence Theorem to say: $$\lim_{n \to \infty} \int_0^\pi x^{1/n} \sin(x) dx = \int_0^\pi \lim_{n \to \infty} x^{1/n} \sin(x) dx = \int_0^\pi \sin(x)dx = 2. $$ I would like to see how to get  the limit directly and rigorousl y using an $\epsilon - N$ type of argument if possible.  The convergence $x^{1/n} \to 1$ is not uniform on $[0,\pi]$ which rules out one approach.","['real-analysis', 'limits']"
2567211,Quotient of group given by presentation is finite,"Consider the group $$G = \langle a,b,c ~ \mid ~ a^2 = b^3 = c^5 = abc \rangle$$
Prove that $\mathbf{(a)}$ $abc$ is an element of the center of $G$; and $\mathbf{(b)}$ $G/ \langle abc \rangle$ is a finite group. To prove $\mathbf{(a)}$, we can show that $abc$ commutes with the generators $a,b,c$:
$$a(abc) = a(a^2) = a^3 = a^2(a) = abc(a)$$
$$b(abc) = b(b^3) = b^4 = b^3(b) = abc(b)$$
$$c(abc) = c(c^5) = c^6 = c^5(c) = abc(c)$$ But I'm not sure how to prove part $\mathbf{(b)}$... any hints would be appreciated.","['abstract-algebra', 'group-theory', 'group-presentation']"
2567224,Suppose I drew every chord in a circle. Is the chord/area ratio uniform or non-uniform?,"I graphed a finite number of cords whose endpoints are nicely placed around a circle (a nice case). This graph seems to suggest that there are more chords in certain regions than in others (for example, there are lots of chords near the end points and also in the center of the circle). For lack of terminology, let's describe a chord 'density' as the number of chords around a very small rectangular region (in the image above for example, the density of any endpoint of a chord is 15). Instead of a finite number of chords, let's say I drew every chord on a circle, then the density around any point would be infinity. But is the density uniform in the circle? That is, even if there are infinitely many chords, would some point have more chords than some other point? Sorry if I'm butchering the concept of infinity here. If the density is not uniform, can we find a density function that describes the relative line density of any point in the circle? Does a question like this even make sense? Does it make sense to describe a region's density if it's infinite? This graph may illustrate what I mean by density (point to line segment, where density is highest at the bottom and increases to the left): Edit: There may be a need to specify what a random chord is. In this case I define a random chord as a chord whose endpoints are randomly picked from the circle. Use infinitesimally small rectangular or circular (or other regions) as you see fit. Sorry if the question is confusing. Please let me know what topic this should be under.",['geometry']
2567229,Find the volume of the solid bounded by $x=\sqrt{y^2+z^2}$ and $x=6-y^2-z^2$,"We are given an image:
The left hand cone is $x=\sqrt{y^2+z^2}$, and right hand parabola is $x=6-y^2-z^2$ I see that I can fix $x$. $\sqrt{y^2+z^2}\leq x \leq 6-y^2-z^2$ Should I use cylindrical or spherical coordinates here? Or none? It is not obvious to me if I should be or not. Because the projection on the $yz$ plane has square roots in it, and so I think I'm supposed to be using cylindrical or spherical. Use a triple integral","['multivariable-calculus', 'integration', 'polar-coordinates', 'calculus']"
2567332,Probability of drawing all 4 balls,"A Greek urn contains a red, blue, yellow, and orange ball. A ball is drawn from the urn at random and then replaced. If one does this $4$ times, what is the probability that all $4$ colors were selected? I approached this questions by doing $(1/4)^4$ because there's always a $1/4$ chance of selected a specific color ball if it's replaced. I also tried doing if not the correct ball was selected; so I did $(3/4)^4$ but that didn't work either. What am I doing wrong?",['probability']
2567374,Proving $\arctan(\mathrm{e}^{-v}) = \text{arccot}(\mathrm{e}^v)$ [duplicate],"This question already has answers here : Are $\mathrm{arccot}(x)$ and $\arctan(1/x)$ the same function? (2 answers) Closed 6 years ago . Is this a correct way to prove that 
$$ \arctan(\mathrm{e}^{-v}) = \text{arccot}(\mathrm{e}^v) $$ 
$$\tan x = \frac{1}{\mathrm{e}^v} $$ 
Turn $\tan x$ into $\sin x$ and $\cos x$
$$\frac{\sin x}{\cos x} =  \frac{1}{\mathrm{e}^v}$$
Multiply $\cos x$
$$ \sin x = \frac{\cos x}{\mathrm{e}^v} $$
$$ \mathrm{e}^v \sin x = \cos x$$
$$ \mathrm{e}^v = \frac{\cos x}{\sin x}$$
Multiply by $\mathrm{e}^v$ and divide by $\sin x$
$$ \mathrm{e}^v = \cot x$$
$$\text{arccot}(\mathrm{e}^v) = x$$","['algebra-precalculus', 'trigonometry', 'proof-verification']"
2567387,"Maximum likelihood estimator for uniform distribution $U(-\theta, 0)$","Consider $X_1,X_2,...,X_n$ i.i.d $U(-\theta,0)$. I want to find the maximum likelihood estimator of $\theta$. I know that $f(x,\theta)=\frac{1}{\theta}$ for $-\theta < x < 0$ and that $L_n(\theta, x)= \frac{1}{\theta^n}$. If we were looking at $U(0,\theta)$, then the MLE of $\theta$ would be $x_{(n)}$ because $L_n(\theta, x)= \frac{1}{\theta^n}$ is decreasing from $0 < x < \theta$ and would thus be maximized at the max $x_i$, which is $x_{(n)}$. For my case, since $L_n(\theta, x)= \frac{1}{\theta^n}$ is an increasing function for $-\theta < x < 0$, then $L_n(\theta, x)= \frac{1}{\theta^n}$ will be maximized at the max $x_i$, and thus the MLE of $\theta$ will be $x_{(n)}$ as well. I think this is correct, but it seems very silly to me that for both cases you can just say that it will be maximized at the max $x_i$. Could someone better explain this to me?","['maximum-likelihood', 'statistics']"
2567399,The set of all equivalence classes of an equivalence relation on a uncountable set may be countable or uncountable. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question The set of all equivalence classes of an equivalence relation on a
   an uncountable set may be countable or uncountable. Can you please give examples of each. $x$~$y$:x is connected via a path. The equivalence class is entire $\mathbb R$ is an equivalence class. right? I couldn't find an example of The set of all equivalence classes of an equivalence relation on an uncountable set be uncountable. Please help me. I have found one example. I don't know, revising the question with an attempt is legal or not. sorry for an incorrect attempt.","['examples-counterexamples', 'cardinals', 'equivalence-relations', 'elementary-set-theory']"
2567412,Fractional Sobolev spaces are Banach spaces,"Let $1\leq p\leq +\infty$, $0<s<1$ and $\Omega\subseteq \mathbb{R}^n$ an open set. The fractional Sobolev space $W^{s,p}(\Omega)$ is defined to be $$ W^{s,p}(\Omega) = \left\{ u\in L^p(\Omega) : \frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p} + s}} \in L^p(\Omega\times\Omega) \right\} $$ equipped with the norm $$ \|u\|_{W^{s,p}(\Omega)} = \left( \int_\Omega |u|^p \; dx + \int_\Omega\int_\Omega \frac{|u(x)-u(y)|^p}{|x-y|^{n+ sp}} \; dx dy \right)^{1/p}. $$ It is a well known result that this is a Banach space, but every reference I read says that this is true, without giving a proof. Adam's Sobolev Spaces uses techniques from interpolation theory to prove this result, but I'm no familiar with the theory, so I'm asking for an ""elementary proof"", that is, as usual, proving that every Cauchy sequence has a limit in the space. Here is my ""attempt"": Let $(u_n)$ be a Cauchy sequence in $W^{1,p}(\Omega)$, then $(u_n)$ is a Cauchy sequence in $L^p(\Omega)$, so there exists $u\in L^p(\Omega)$ such that $u_n\to u$ in $L^p(\Omega)$. I would like to prove that $u\in W^{s,p}(\Omega)$ and that $u_n\to u$ in $W^{s,p}(\Omega)$. But I don't know how to proceed here. Thanks for the help!","['functional-analysis', 'banach-spaces', 'sobolev-spaces']"
2567420,Integer solutions of $2x+3y=n$,"What is the smallest $m$ such that for all $n\geq m$, the equation $2x+3y=n$ has solutions with $x,y \in \mathbb{Z}$ and $x,y\geq2$? My approach. We can write the solutions in terms of the parameter $t$ as:
$$x(t)=-n-3t$$ and 
$$y(t) = n+2t$$ Setting both of those greater than or equal to $2$, we have $-n-3t\geq2$ and $n+2t\geq2$. Solving for $t$, we find $\dfrac{-n-2}{3} \geq t \geq\dfrac{2-n}{2}$. Solving the resulting inequality, we get
$$-2n-4\geq6-3n$$
So $n\geq10$. This seems to be right. For $n=10$, take $(2,2)$. But, suppose $n=11$. Then, $2x+3y=11$ clearly has no solution where both $x,y\geq2$. Is my solution incorrect? Can someone point me in the right direction? EDIT: Thanks for the great answers!","['number-theory', 'linear-diophantine-equations', 'elementary-number-theory']"
2567436,"How can I prove, that this formula is related to the binomial series?","I am trying to solve the following formula: $$\sum^{\lfloor (n-1)/2\rfloor}_{m=k}\binom{m}{k}\binom{n}{2m+1} = \binom{n-k-1}{k}2^{n-2k-1}$$ However, I haven't got a clue. Can anybody shed some light on this?","['combinatorics', 'summation', 'binomial-coefficients']"
2567448,Minimum mean squared error of uniform distribution,"Let $X_1,X_2,\ldots,X_n$ be i.i.d $\operatorname{Uniform}(-\theta,0)$.
Now consider all of the estimates of the form $S_\rho=\rho \hat{\theta}_\text{MLE}$. I have to find which of these estimates has the minimum mean squared error. I found that the MLE of $\theta$ is $\hat{\theta}_\text{MLE}=-x_{(1)}$. I know that the mean squared error is $\operatorname{MSE}(\hat{\theta})=\operatorname E_{\hat{\theta}}[(\hat{\theta}-\theta)^2]$ and that the minimum (best) mean squared error is $\operatorname{MMSE} = \operatorname E[X\mid Y]$. However I wouldn't know how to apply these to $S_\rho=\rho \hat{\theta}_\text{MLE}$. Is there a better (more intuitive) way to see which estimate is the best without using these? Is the best estimator simply the MLE? This is from a past exam of 5 years ago and seems very foreign to me, so it is possible that this was never covered in class. Any hint is appreciated.","['maximum-likelihood', 'statistics', 'mean-square-error']"
2567490,Prove that every integer greater than 1 is sum of square and squarefree.,"I tried to put some sieve method on this. Here, we denote the classic squarefree sieve function $\sum_{d^2|a}\mu(d)$ (notice that if $a$ is squarefree, the value is 1, and if not squarefree, the value is 0, which is exactly what we want). 
I can take $A(n)=\lbrace n-1, n-4, n-9,...,n-[\sqrt n]^2\rbrace$ and take the sieve function to try to prove the following sum if positive.
$$\sum_{a\in A(n)}\sum_{d^2|a}\mu(d)$$
which is clearly the same value as following.
$$\sum_{1 \leq d \leq \sqrt{n-1}}\mu(d)A_{d^2}$$
Now all we have to do is calculate $A_{d^2}$ which is (with some calculation,)
$\left[\frac{[\sqrt n]}{d^2}\right]\prod_{p_{i}|d}\left(1+\left(\dfrac{n}{p_{i}}\right)\right) $
where $p_{i}$ denote primes and $()$ is legendre simble.
Now my question is, clearly if my conjecture is true, then above formula must sum up to a positive integer. However since I  lack so much on multiplicative number theory, I don't know what to do with the formula I have above. Can someone help me?","['analytic-number-theory', 'square-numbers', 'number-theory', 'sieve-theory', 'elementary-number-theory']"
2567504,Describing all plane curves with constant curvature,"I know that by Frenet-Serret, we have (I know this is only for curves parametrized by arclength, but since every plane curve can be reparametrized by arclength, there's no loss of generality): $t'(s) = k(s)n(s) \Rightarrow t''(s) = k(s)n'(s)$ (since $k(s)$ is constant) $n'(s) = -k(s)t(s)$ Since the curvature is constant, I can call $k(s) = c$ and get: $t''(s) = -c^2 t(s)$ $t''(s) + c^2t(s) = 0$ which has solutions: $t(s) = A_1 \cos(cs) + A_2 \sin(cs)$ (where I also assume $||t|| = ||n|| = 1$) so $a(s) = \frac{1}{c} (A_1 \sin(cs) - A_2 \cos(cs)) + A_3$ is the form all regular curve planes are (I forgot to add regular in the beginning, but it's in the exercise) ""Squaring"" both sides, we get: $||a(s) - A_3||^2 = \frac{1}{c^2} ||A_1||^2 \Rightarrow ||a(s) - A_3||^2 = \frac{1}{c^2} \Rightarrow ||a(s) - A_3|| = \frac{1}{c}$, which is clearly the equation of a circle (I used Gribouillis' answer in the middle of these steps)",['differential-geometry']
2567528,Any examples of unbounded linear operators between $\ell^\infty$ and $\ell^\infty$? $\ell^p$ and $\ell^p$? $\ell^p$ and $\ell^\infty$?,"Let $X$ and $Y$ be normed spaces, either both real or both complex. Let $f \colon X \to Y$ be a linear operator. Then $f$ is said to be bounded if there exists a real number $r > 0$ such that 
$$ \lVert  f(x) \rVert_Y \leq r \lVert x \rVert_X \mbox{ for every } x \in X. $$
If there is no such $r$, then $f$ is said to be unbounded . Now my question is, can we find an example of an unbounded linear operator (i) $f \colon \ell^\infty \to \ell^\infty$? (ii) $f \colon \ell^p \to \ell^p$, where $p$ is such that $1 \leq p < +\infty$? (iii) $f \colon \ell^\infty \to \ell^p$? (iv) $f \colon \ell^p \to \ell^\infty$? (v) $f \colon \mathrm{C}[a, b] \to \mathrm{C}[a, b]$? Or, examples of unbounded linear operators between any other pairs of these normed spaces? By definition, $\ell^\infty$ is the normed space of all the bounded sequences of (real or complex) numbers, with the normed defined by 
$$ \left\lVert \left( \xi_n \right)_{n \in \mathbb{N} } \right\rVert \colon= \sup \left\{ \ \left\lvert \xi_n \right\rvert \ \colon \ n \in \mathbb{N} \ \right\}. $$ For any real number $p$ such that $1 \leq p < +\infty$, the normed space $\ell^p$, by definition, is the vector space of all the sequences $\left( \xi_n \right)_{n \in \mathbb{N} }$ of (real or complex) numbers, for which the series $\sum \left\lvert \xi_n \right\rvert^p$ converges, that is, 
$$ \sum_{n=1}^\infty \left\lvert \xi_n \right\rvert^p < +\infty,  $$ 
with the norm given by the formula 
$$ \left\lVert \left( \xi_n \right)_{n \in \mathbb{N} } \right\rVert \colon= \sqrt[p]{ \sum_{n=1}^\infty \left\lvert \xi_n \right\rvert^p }. $$ For any real numbers $a$ and $b$ such that $a < b$, the space $\mathrm{C}[a, b]$ is the normed space of all the real or complex-valued functions defined and continuous on the closed interval $[a, b]$ of the real line, with the norm defined by $$ \lVert x \rVert \colon= \max \{ \ \lvert x(t) \rvert \ \colon \ a \leq t \leq b \ \}.  $$ Right now, the only example of an unbounded linear operator that I can recall is that of the differentiation operator of the normed space of all the continuously differentiable functions on a closed interval $[a, b]$ with the maximum norm into this normed space itself. So any other examples, please? I would appreciate references to some elementary-level text on analysis where examples of such unbounded linear operators can be found.","['real-analysis', 'normed-spaces', 'functional-analysis', 'unbounded-operators', 'analysis']"
2567556,What is this angle calculation rule with $2$ parallel lines?,"The rule is that when line n and m are parallel, $$b=a+c$$ What's the name of this rule? - You won't believe how many books I've checked.","['terminology', 'geometry']"
