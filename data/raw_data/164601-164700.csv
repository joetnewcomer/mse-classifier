question_id,title,body,tags
2859095,"Approximating a multinomial as $p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right)$","Question Suppose we have a multinomial distribution with $N$ possible outcomes, with probabilities $p_1,\ldots,p_N$. We sample this $n$ times, and denote the observed frequency of the $i$th outcome as $\xi_i$. In [1] the author claims that the distribution of the $\xi_i$ in the limit of large $n$ is: $$p(\xi_1,\ldots,\xi_N)\propto\exp\left(-\frac{n}{2}\sum_{i=1}^N\frac{(\xi_i-p_i)^2}{p_i}\right).\;\;\;\;\;(1)$$ We can see immediately that this must be an approximation, as it assigns nonzero probabilities for $\xi_1+\cdots+\xi_N>1$. However we can see that these have vanishing probability in the limit $n\rightarrow\infty$. My question is how do we derive (1) from the multinomial distribution, and show that they match in the $n\rightarrow\infty$ limit? My thoughts My first thought would be to appeal to the central limit theorem. The multinomial distribution has mean $\mu_i=p_i$ and covariance matrix $\Sigma_{ij}=\delta_{ij}p_i-p_ip_j$, so we would expect this in the large $n$ limit to be described by a multivariate Gaussian with mean $\mu$ and covariance $\frac{1}{n}\Sigma$. However, things are complicated by the fact that the multinomial covariance is singular (since $\xi_N$ is determined by the other $\xi_i$s), and so the multivariate Gaussian is not defined. To address this, we may try and consider only the first $\xi_1,\ldots,\xi_{N-1}$, which have a non-singular covariance matrix and hence well-defined multivariate Gaussian distribution. Let's take the Binomial distribution $N=2$. The frequency $\xi_1$, this has mean $p_1$ and variance $p_1(1-p_1)$, so this would be described the the Gaussian:
$$\propto\exp\left(-\frac{n}{2}\frac{(\xi_1-p_1)^2}{p_1(1-p_1)}\right).\;\;\;\;\;(2)$$
The expression (1) gives:
$$\propto\exp\left(-\frac{n}{2}\left(\frac{(\xi_1-p_1)^2}{p_1}+\frac{(\xi_2-p_2)^2}{p_2}\right)\right).\;\;\;\;\;(3)$$
If we substitute $\xi_2\rightarrow 1-\xi_1$, $p_2\rightarrow 1-p_1$ into (3), we can verify that this gives the same answer as (2). I have verified that this also works for $N=4$. I'm sure that if I just bashed out the algebra for general $N$ we would get agreement between the central limit theorem and (1) when we restrict the latter to $\xi_1+\cdots+\xi_N=1,p_1+\cdots+p_N=1$. However, how can we start with the multinomial distribution and derive (1) as a limit which is valid everywhere? One idea would be to say that (1) goes to zero as $n\rightarrow\infty$ when you are not on that plane, however I am a bit uncomfortable with this as it goes to zero everywhere except the mean as $n\rightarrow\infty$, so I don't know if that argument is good enough. [1] Wootters, William K. ""Statistical distance and Hilbert space."" Physical Review D 23.2 (1981): 357.","['probability-limit-theorems', 'statistics', 'probability-distributions']"
2859118,"Find an ""upper bound"" for a given sequence.","Let $a_1=5$ and let $$a_{n+1}=\frac{a_n^2}{a_n^2-4a_n+6}$$
Find the biggest integer $m$ not bigger than $a_{2018}$, that is $m\leq a_{2018}$. My go:
Apparently the limit must satisfy $$l=\frac{l^2}{l^2-4l+6}\Leftrightarrow l=0\vee l=3\vee l=2$$ Computing first few terms i see that $a_n\to 3$ as $n\to\infty$. The sequence seems to converge to 3, so i tried to show that $\forall n\geq 2,a_n\leq3$ proceeding by induction, we find that $a_1=5,a_2=25/11\approx2,27\leq3$. Now let $a_n\leq 3\Rightarrow a_{n+1}=\frac{a_n^2}{a_n^2-4a_n+6}\leq\frac{9}{a_n^2-4a_n+6}$ but here I'm stuck again, no idea what to do with the denominator. Any help appreciated.","['limits', 'sequences-and-series']"
2859153,Understanding this math notation in probability?,"I don't get this notation at all and cannot find a place to start with understanding this: $$\mathcal L_D=-\mathbb E_{x\sim P}[\log(D(x))]-\mathbb E_{\hat x\sim Q}[\log(1-D(\hat x))]$$ I don't get $\mathbb E$ there. Does it mean expectation? The equation says it's ""negative log-likelihood"". I understand that $D(x)$ is either 1 or 0. What does the $\mathbb E_{x\sim P}$ mean, especially in the context of statistics? Assuming that $E$ is expectation, what does it mean to have an expectation of a probability distribution $P$ ? Does it imply the mean of the distribution, and in that case what does $\hat x$ typically mean? Unfortunately the paper I'm reading doesn't spell these out so I'm guessing I lack a bit of statistics background here.","['notation', 'statistics', 'probability']"
2859196,Point wise maximum of the difference of two convex functions is also a difference of two convex functions,"Define function $f^i := h^i - g^i$ , where $f^i$ , $g^i$ are real-valued convex functions for all $i = 1,\dots, 10$ . Do there exist real-valued convex functions $h$ , $g$ where $h - g = \max\limits_{i} f^i$ ? I don't even know how to even approach this problem.","['functions', 'convex-analysis', 'real-analysis']"
2859232,"Evaluate $\lim\limits_{x\to\infty}\frac1x\int_0^x\max\{\sin t,\sin(t\sqrt2)\}dt$","I want to evaluate
$$L=\lim_{x\to\infty}\frac1x\int_0^x\max\{\sin t,\sin(t\sqrt2)\}dt$$ My attempt $$L=\lim_{x\to\infty}\frac1{2x}\int_0^x\Big(\sin t+\sin(t\sqrt2)+\big|\sin t-\sin(t\sqrt2)\big|\Big)dt\\
=\lim_{x\to\infty}\frac1{2x}\int_0^x\big|\sin t-\sin(t\sqrt2)\big|dt\\
=\lim_{x\to\infty}\frac1x\int_0^x\bigg|\cos\frac{\sqrt2+1}2t\cdot\sin\frac{\sqrt2-1}2t\bigg|dt$$
Denote $s_n$ the $n$th zero point of $\cos\frac{\sqrt2+1}2t\cdot\sin\frac{\sqrt2-1}2t\ (t\ge0)$. Since $1$, $\sqrt2$ and $\pi$ are linear independent in $\mathbb Q$, the order of the zero points should be $1$. According to the squeeze theorem, we have
$$L=\lim_{n\to\infty}\frac1{s_{n+1}}\sum_{k=0}^n(-1)^k\int_{s_k}^{s_{k+1}}\big(\sin t-\sin(t\sqrt2)\big)dt\\
=\lim_{n\to\infty}\frac1{s_{n+1}}\sum_{k=0}^n(-1)^k\bigg(\cos s_k-\cos s_{k+1}+\frac{\cos\sqrt2s_k-\cos\sqrt2s_{k+1}}{\sqrt2}\bigg)dt$$
I can't go further. I think the zero points of that function is the key point.","['integration', 'calculus', 'definite-integrals']"
2859284,How to use Kullback-Leibler Divergence if probability distributions have different support?,"I have two discrete random variables $X$ and $Y$ and their distributions have different support. Assume $X$ and $Y$ can both take on the same number of values. Lets say $X$ takes values in $\{10,13,15,17,19\}$ and $Y$ takes values in $\{12,14,16,18,20\}$. I would like to use the Kullback-Leibler Divergence but it requires that Q dominates P. Is it possible to modify the support of each random variable so that they have the same support? If not, are there any measures of statistical distance that do not require $X$ and $Y$ to have the same support? One solution I have created is to make kernel density estimators with a gaussian kernel using the datasets collected on $X$ and $Y$. Now the densities $\hat{f}(x)$ and $\hat{g}(y)$ have support on $( -\infty, \infty)$ and with suitable bandwidth they are multimodal with modes centered around the support of the original random variables. It remains to be seen how wise or foolish of an idea this is. Note: Since the KL divergence of a finite gaussian mixture does not have a closed form solution, I used monte carlo methods to estimate it.","['probability-distributions', 'probability', 'information-theory']"
2859299,$f(x+1)-f(x)=f'(x)$: prove $f(x)$ linear function [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If I have a differentiable function $f:\mathbb{R}\to\mathbb{R}$ satisfies $f(x+1)-f(x)=f'(x)$ and $\lim_{x\to\infty}f'(x)=A$. Can I show $f(x)=ax+b$?","['calculus', 'ordinary-differential-equations']"
2859304,Eigenvalues of a matrix with repeating pattern of entries,"I observed that if $$A = \begin{bmatrix} a & b  \\ c & d \end{bmatrix}$$ with non-zero eigenvalues $\alpha$ and $\beta$, then $$\begin{bmatrix} A & A\\ A & A \end{bmatrix}$$ has eigenvalues $2 \alpha$, $2 \beta$, and $0$. Also, $$\begin{bmatrix} A & A & A \\ A & A & A \\ A & A & A \end{bmatrix}$$ has eigenvalues $3 \alpha$, $3 \beta$, $0$. Therefore, my conjecture is that for some $r$, $A^{[r]}$ has eigenvalues $(r+1) \alpha$, $(r+1) \beta$, $0$. Is it correct? Is there some theorems related to this? How about their eigenvectors? Can you please send me links that can help me with this kind of problem? PS. This is my first time asking here. I am an undergrad math student. Please help me.  Thank u so much.","['matrices', 'linear-algebra', 'block-matrices', 'eigenvalues-eigenvectors']"
2859312,What is $\log(n+1)-\log(n)$?,What is gap $\log(n+1)-\log(n)$ between log of consecutive integers? That is what precision of logarithms determines integers correctly?,"['numerical-methods', 'logarithms', 'real-analysis']"
2859353,Charged particles,"We are creating a circular hub consisting of charged 0 and 1 particles next to each other, beginning with four of them: 0, 1, -0 and -1 in this order. Every 1 sec we randomly select one of each kind and add it next to the last one. Whenever a 0 particle finds itself next to a -0 or a 1 particle next to a -1, they both vanish. Assuming it is equally likely to select each of the 4 kinds, what is the probability that at some point the hub vanishes completely? I assume it is not as easy as $\frac {1}{4}.\frac {1}{3}.\frac {1}{2}$, right? I can't figure out of anything else... Any help?",['probability']
2859382,Compute $\lim\limits_{x\to \infty }\sum\limits_{n=1}^\infty \frac{1}{n(n+x)}$,"I want to compute $$\lim_{x\to \infty }\sum_{n=1}^\infty \frac{1}{n(n+x)}.$$ Can I do as follow? Consider the measurable space $(\mathbb N,\mathcal P(\mathbb N),\mu)$ where $\mu(A)=\#A$. Then,
$$\sum_{n=1}^\infty \frac{1}{n(n+x)}=\int_{\mathbb N}\frac{1}{n(n+x)}d\mu(n).$$
Suppose $|x|\geq 1$. Then
$$\left|\frac{1}{n(n+x)}\right|\leq \frac{1}{n(n+1)}\in L^1(\mathbb N),$$
and thus, using DCT, we finally obtain $$\lim_{x\to \infty }\sum_{n=1}^\infty \frac{1}{n(n+x)}=\sum_{n=1}^\infty \lim_{x\to \infty }\frac{1}{n(n+x)}=0.$$ Does it work ?","['measure-theory', 'sequences-and-series', 'summation', 'real-analysis']"
2859507,Eigenvalues of sum of non-symmetric matrices,"Assume $A, B$ are real matrices. Weyl's inequalities provide bounds on the eigenvalues of $A + B$ if both are symmetric. Is there any bound if neither are symmetric? I am particularly interested about the case where $A$ and $B$ are positive stable , that is, have eigenvalues with positive real part. For instance, can one always produce $A, B$ positive stable such that $A+B$ has eigenvalues with arbitrarily negative real part?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
2859515,Two types of coins are being tossed,"Let's assume we have two types of unfair coins. One has $70\%$ probability of getting head, and the other has $70\%$ change of getting tail. Now if we throw coin A $k$ times and coin B $n$ times. What will be the probability of getting at least $w$ heads. $w < k+n.$ I have it figured out when it comes to one coin. By using Normal distribution (aproximating Binomial distribution). But things get too complicated with second coin. Could you help me out?","['statistics', 'probability']"
2859554,Curve shortening flow with boundary,"Let $(M^2,g)$ be a 2-dimensional complete Riemannian manifold (e.g. $(\mathbb{R}^2,\delta_{ij})$) and $p,q\in M$ two points with $p\neq q$. Let $\gamma:I\to M$ be a smooth embedded curve starting at $p$ and ending at $q$. When does the curve shortening flow starting at $\gamma$ converge to a geodesic segment joining $p$ and $q$, i.e. the ""shortest"" curve joining the two points? I am aware of Grayson's result that an embedded closed curve in a 2-manifold either shrinks to a round point or converges to a geodesic. What results are known for curve shortening flow for line segments? Is the flow even well defined?","['mean-curvature-flows', 'partial-differential-equations', 'differential-geometry']"
2859666,Multivariable Taylor's formula and approximation (big O),"I post here because I encounter a problem to understand something. To begin, let consider $f : \mathbb{R}^n \rightarrow \mathbb{R}$ a n times differentiable function. Then, we have, by the Taylor's formula : $$ \forall a, h \in \mathbb{R}^n \quad f(a+h)=f(a)+Df_a(h) + ... + \frac{1}{n!}D^nf_a(h^n) + o_o(||h||^n)$$ So, when $n=1$, it's easy to see that each term of the taylor expansion is ""bigger"" than the next one, i.e for $k \in \mathbb{N}$, we have : $D^kf_a(h^k)=f^{(k)}(a)h^k$ and then $o(h^k) = o(D^kf_a(h^k))$, but I've some trouble when $n>1$. Actually, for $n=2$ and the taylor formula at the order 2, we have : $D^2f_a((x_1, x_2), (x_1,x_2)) = \frac{\partial ^2 f}{\partial x_1^2}(a) x_1^2 + 2\frac{\partial ^2 f}{\partial x_1 \partial x_2}(a) x_1x_2 + \frac{\partial ^2 f}{\partial x_2^2}(a) x_2^2$ And I want to show that : $o(||(x_1,x_2)||^2) = o(||D^2f_a((x_1, x_2), (x_1,x_2))||)$. By considering (and utilizating the equivalence of the norm in finite dimension), if I consider the norm $||(x_1,x_2)|| = \max (|x_1|, |x_2|)$, then I have : $D^2f_a((x_1, x_2), (x_1,x_2)) = O(||(x_1,x_2)||^2)$, but I whould like to have $||(x_1,x_2)||^2 = O(||D^2f_a((x_1, x_2), (x_1,x_2))||)$. But, still with the norm max, if I consider $x_1x_2$, I should have : $x_1x_2$ which verify : $x_1x_2 \geq C||(x_1,x_2)^2||$, but if I consider $(x_1,x_2) = (e, e^2)$, for $e<<0$, I have : $e^3 \geq Ce^2$, which is not true. So, I'm kind of lost. And here, I've only considered $\mathbb{R}^n$, but what happen if I consider a vector space of infinite dimension ? (cause I could not use the equivalence of norm)","['multivariable-calculus', 'derivatives', 'real-analysis']"
2859673,"There are $n$ different $3$-element subsets $A_1,A_2,...,A_n$ of the set $\{1,2,...,n\}$, with $|A_i \cap A_j| \not= 1$ for all $i \not= j$.","Determine all possible values of positive integer $n$ , such that there are $n$ different $3$ -element subsets $A_1,A_2,...,A_n$ of the set $\{1,2,...,n\}$ , with $|A_i \cap A_j| \not= 1$ for all $i \not= j$ . Source: China Western Olympiad 2010 Attempt: It is quite clear that for $n=4k$ such a system exist. For $n=4$ , we have $A_1 =\{1,2,3\}$ , $A_2 =\{1,2,4\}$ , $A_3 =\{2,3,4\}$ , $A_4 =\{1,3,4\}$ . It is not hard to see that induction $n\to n+4$ works. Now I would like to prove that there is no such system if $4\nmid n$ . I thought about linear algebra approach. Observe the given sets as vectors in $\mathbb{F}_2^n$ . Then since $A_i\cdot A_i =1$ and $A_i\cdot A_j = 0$ for each $i\ne j$ these vectors are linear independent: $$ b_1A_1+b_2A_2+...+b_nA_n = 0\;\;\;\; /\cdot A_i$$ $$ b_1\cdot 0+b_2\cdot 0+...+b_i\cdot 1+...b_n\cdot 0 =0\implies b_i=0$$ But now, I'm not sure what to do...","['contest-math', 'algebraic-combinatorics', 'linear-algebra', 'combinatorics']"
2859674,Restriction of a scheme to an open subset.,"If $(X,\mathscr O_X)$ is a scheme and $U$ an open subset of $X$, how does it follow that $(U,\mathscr O_X{_{|U}})$ is a scheme? I found this as a remark in Bosch's book, 'Algebraic Geometry and Commutative Algebra'  just after the definition of a scheme. I don't get this even when the scheme is affine(except when the open set is basic).","['algebraic-geometry', 'schemes']"
2859692,How can I know if the general solution of this ODE is convex?,I would like to know if the set of solutions of the following third order linear ODE is convex. $$y''' + y'' -2y' + y = e^x $$ Can I do that by solving it? Can I infer that from the fact that $y(x) = e^x$ is a particular solution and is a convex function?,"['convex-analysis', 'ordinary-differential-equations']"
2859708,Critical Points Clarification,"I'm uncertain if I have all the critical points required of the system I do $\frac{dx}{dt} = x(x-2) + y^2$...and likewise..I do $\frac{dy}{dt}= y(1-x)$ I then set both equations to zero If we set $x = 0$ in the first equation, we solve the second equation $y = 0$
If we set $y = 0$ in the second equation, we solve the first equation for $x = 0$ and $x = 2$. 
Likewise, I solve for y - xy = 0. Then xy = y so x = 1. We plug this solution into the first equation so that y^2 = 1 and hence, have (1,1),(1,-1) as our results as well. Hence, my critical points are then $(0,0);(2,0)$;(1,1);(1,-1) Is this the correct approach for this particular question? Likewise, what does it mean to determine the stability of the critical point and the type of critical point? Is it referring to stable , unstable , and semi-stable ? Likewise, is the type of critical point choosing amongst center , node , saddle point , and spiral ? Thank you","['nonlinear-system', 'homogeneous-equation', 'ordinary-differential-equations']"
2859732,Cantor set with pairs of points identified,"Consider the middle-thirds Cantor set in $[0,1]$.  I want to identify points in the following way. First, identify the two points $1/3$ and $2/3$. Then, idenfity $1/9$ with $2/9$, and also identify $7/9$ with $8/9$. At the third step there will be four pairs of points: $1/27\sim 2/27$; $7/27\sim 8/27$; $19/27\sim 20/27$; $25/27\sim 26/27$. Continue. Essentially I am squeezing together the consecutive gaps in the Cantor set. I would like to know of the resulting space is homeomorphic to $[0,1]$.","['general-topology', 'cantor-set']"
2859772,Using inverse Laplace transform to solve differential equation,"The differential equation is as follows- $$\frac{d^2 x}{dt^2} + 5 \frac{dx}{dt} + 6x = e^t $$ I use laplace transform to make it to become - $$X(s) = \frac{1}{(s-1)(s+3)(s+2)}$$
where $X(s)$ is the Laplace transform of $X(t)$ So now I am trying to find $X(t)$ using inverse transform. From partial fractions- $X(s) = \frac{1}{(s-1)(s+3)(s+2)} = \frac{A}{s-1} + \frac{B}{s+3} + \frac{C}{s+2} $ Numerator - $ 1 = A(s+3)(s+2) + B(s-1)(s+2) + C(s-1)(s+3) $ I am stuck from here on how to carry on this partial fraction Can I sub all s values to be 0 ? For example $1 = A(0+3)(0+2)$ $1= B(0-1)(0+2) $ $1 = C (0-1)(0+3) $","['partial-fractions', 'laplace-transform', 'ordinary-differential-equations']"
2859820,Fermat's Last Theorem and Faltings' Theorem.,"I apologise for all these questions of Fermat's Last Theorem, but I am fascinated by the topic, even if I cannot understand all of it. I must admit that I am not well versed in the language of modular forms or elliptic equations, but they seem quite complicated to me. However, while reading Simon Singh's book ""Fermat's Last Theorem"", I found one particular bit very interesting. I immediately thought that there was an easier way to prove Fermat's Last Theorem. It was to do with Falting's Theorem and the geometrical representations of equations like $x^n + y^n = 1$. I quote: ""Faltings was able to prove that, because these shapes always have more than one hole, the associated Fermat equation could only have a finite number of whole number solutions."" Surely, now all that is needed is to prove that a Fermat equation has infinite solutions. Suppose we take the original equation:
$$A^3 + B^3 = C^3$$
Surely we can find infinite solutions to this by doubling $A, B, C$
$$(2A)^3 + (2B)^3 = (2C)^3$$
$$8A^3 + 8B^3 = 8C^3$$
$$A^3 + B^3 = C^3$$
Surely this means there are infinitely many solutions to these equations.
But now we have a contradiction, so therefore our original assumption, that $A^3 + B^3 = C^3$ has solutions, is false. Who can point out my error as this seems a very simple step to take from Falting's to Fermat's. And surely that step wouldn't have taken years to take, especially for Andrew Wiles.",['number-theory']
2859827,"A closed form for $\int_0^\pi \lvert \sin(m t) \cos(n t) \rvert \, \mathrm{d} t$","Motivated by this nice question I have been trying to compute the function $f: \mathbb{R}^+ \to \left[0,\frac{1}{2}\right]$ defined by $$f(\alpha) = \lim_{x \to \infty} \frac{1}{x} \int \limits_0^x \lvert\sin(\alpha s) \cos(s)\rvert \, \mathrm{d} s \, .$$ Note that $f(\alpha) \leq \frac{1}{2}$ follows from the Cauchy-Schwarz inequality. In the answers to the original question the equidistribution theorem is used to show that $f(3 - 2 \sqrt{2}) = \frac{4}{\pi^2}$ holds. This argument can be extended to every irrational number, so we have $f(\alpha) = \frac{4}{\pi^2} \approx 0.405285$ for any $\alpha \in \mathbb{R}^+ \setminus \mathbb{Q}^+$ . For rational arguments we can take $m , n \in \mathbb{N}$ with $\gcd(m,n) =1$ . The change of variables $s = n t$ yields $$ f \left(\frac{m}{n}\right) = \lim_{x \to \infty} \frac{1}{x} \int \limits_0^x \lvert\sin(m t) \cos(n t)\rvert \, \mathrm{d} t \, .$$ The integrand is periodic with period $\pi$ , so $$ f \left(\frac{m}{n}\right) = \lim_{x \to \infty} \frac{1}{x} \left[\bigg\lfloor \frac{x}{\pi} \bigg\rfloor \int \limits_0^\pi \lvert\sin(m t) \cos(n t)\rvert \, \mathrm{d} t + \mathcal{O} (1)\right] = \frac{1}{\pi} \int \limits_0^\pi \lvert\sin(m t) \cos(n t)\rvert \, \mathrm{d} t\, .$$ Now the idea is to split the interval of integration into subintervals on which the sign of the product is constant and then use $$ \sin(m t) \cos(n t) = \frac{\sin[(m+n)t] + \sin[(m-n)t]}{2}$$ to find the integrals. The result is basically given by a finite sum of cosines evaluated at the zeroes of the integrand. The first few results are \begin{align}
f(1) &= \frac{1}{\pi} \approx 0.318301 \, , \\ 
f(2) &= \frac{4}{3 \pi} \approx 0.424413 \, , \\
f\left(\frac{1}{2}\right) &= \frac{2(2\sqrt{2}-1)}{3\pi} \approx 0.388004 \, .
\end{align} Interestingly, most of the other values (especially those with large $m$ and $n$ ) seem to be very close to $\frac{4}{\pi^2}$ . This method can be used (at least in principle) to compute $f$ at every rational argument, but it becomes increasingly complicated for larger values of $m$ and $n$ . Maybe I am overlooking a simple trick, maybe there is a better method. My question is: How can we find a general expression for $f\left(\frac{m}{n}\right)$ with arbitrary coprime $m,n \in \mathbb{N}$ ? Edit 1 July 2020 Thanks to Zacky's bounty and River Li's and asgeige's nice answers we have some closed-form results for special cases and a promising (but still somewhat complicated) conjecture for the general case. Using similar methods, I have also found $$ f(m) = \frac{2}{\pi (m^2-1)} \left[m \csc \left(\frac{\pi}{2m}\right) \cos \left(\frac{\pi}{2m} 1_{2\mathbb{N}}(m)\right) - 1_{2 \mathbb{N}-1}(m)\right]$$ for $m \in \mathbb{N} \setminus \{1\}$ ( $1_A$ is the indicator function of the set $A$ ), which implies $\lim_{m \to \infty} f(m) = \frac{4}{\pi^2}$ . While a simple expression for general values of $m,n$ seems unlikely, it may be possible to show that $\lim_{n \to \infty} f \left(\frac{m}{n}\right) = \frac{4}{\pi^2}$ and $\lim_{m \to \infty} f \left(\frac{m}{n}\right) = \frac{4}{\pi^2}$ do indeed hold for fixed $m \in \mathbb{N}$ and $n \in \mathbb{N}$ , respectively. Edit 11 January 2021 Thanks to River Li's second answer we now have a proof of the conjectured limits. We can even use partial fractions and the pole expansions of $\csc$ and $\cot$ to simplify the remaining series and obtain the following general result (valid for $m, n \in \mathbb{N}$ coprime and not both equal to $1$ ): $$ f\left(\frac{m}{n}\right) = \frac{g_m\left(\frac{\pi}{2m}\right) - g_m \left(\frac{\pi}{2n}\right)}{m^2-n^2} \, , \, g_m = \begin{cases} x \mapsto \frac{\csc(x)}{x} &, \, m \in 2 \mathbb{N} - 1 \\ x \mapsto \frac{\cot(x)}{x} &, \, m \in 2 \mathbb{N}\end{cases} \, . $$","['integration', 'definite-integrals', 'calculus', 'trigonometric-integrals', 'limits']"
2859843,How to get the shaded region of the rectangle?,"I have this problem: So my development was: Denote side of rectangle with: $2a, 2b$. So, $4ab= 64, ab = 16$ Denote shaded region with $S$ Denote area of triangle $DGH = A_1$ and triangle $FBE = A_2$. So, $A_1 + A_2 + S = 64$ $S = 64 - A_1 - A_2$ The triangles $A_1, A_2$ are congruent because $LAL$ congruence criterion. The area of $A_1$ and $A_2$, is the same and i got it with this way: Since, the $\angle{GDH} = 90$ and the median from this angle to the base $HG$, that is the altitude of the triangle $DGH$,  will measure the half of the $HG$ side. And the $HG$ side by Pythagorean theorem, will be $\sqrt{a^2 + b^2}$, that will be the base of the triangle. And the altitude will be: $\frac{\sqrt{a^2 + b^2}}{2} $, So the Area of $A_1 = \frac{a^2 + b^2}{4}$ So, $A_1 + A_2 = \frac{a^2 + b^2}{2}$ Then, $64 - (\frac{a^2 + b^2}{2}) = S$ And, $-(a^2 - 8ab + b^2) = 2S$ And I have not been able to continue from here, what should I do? Thanks in advance.",['geometry']
2859859,"Example of a noncompact operator on $L^2([0,1])$","For $f \in L^2([0,1])$, define operator $Tf: x \mapsto \frac{1}{x}\int_0^x f(y)dy$. Show that $T$ is not a compact operator on $L^2([0,1])$ and that $T$ is bounded. For the second part, I can show $T$ is bounded by looking at $\|Tf\|_2$ and rewriting it by integration by parts and then apply the Cauchy-Schwartz inequality. However, I was not able to find a bounded sequence of $L^2$ functions so that its image under $T$ is not precompact in $L^2$. Any help is tremendously appreciated.","['compact-operators', 'functional-analysis', 'real-analysis']"
2859871,Number of distinct scatterplots from $p$ variables in a data set,"Consider the following quote from the text An Introduction to Statistical Learning: In practice, we often encounter data
  sets that contain many more than two variables. In this case, we cannot
  easily plot the observations. For instance, if there are p variables in our
  data set, then p(p − 1)/2 distinct scatterplots can be made, and visual
  inspection is simply not a viable way to identify clusters. What exactly do the authors mean by the fact that $$\frac{p(p-1)}{2}$$
distinct scatterplots can be made?  The quote is not referring to any specific data or any specific example, so this is the only context. I understand that this question would be a better post for the Cross Validated Stack Exchange; however, this site is more popular and more active, so I thought I would post it here.  Nevertheless, it is still math. Thanks in advance!","['data-analysis', 'statistics']"
2859872,"$X$ compact, $C(X)$ equipped with inner product, evaluation maps continuous, prove $X$ is finite","I'm working on the following problem from Conway V.4. Let $X$ be compact and supppose there is a norm on $C(X)$ that is given by an inner product making $C(X)$ into a Hilbert space such that for every $x \in X$ the functional $\Lambda_x : f\mapsto f(x)$ is continuous with respect to the Hilbert space norm.  Show $X$ is finite. Idea on approach: I think we need to assume $X$ is infinite and come to some sort of contradiction. Facts noted: $\text{ball}{(C(X))}$ is weakly compact. $X^* \subset C(X)$, $X^*$ is definitely a subspace, and if it is closed under the norm induced by the inner product we have $X^*$ is Hilbert and hence reflexive. (Since I am not sure of the closedness of $X^*$ under the norm, I am not sure if this could be useful.) The hypothesis is allowing us to extend the notion of a weak-$*$ topology on $X^*$ to $C(X)$. The continuity of the $\Lambda_x$'s and Riesz Rep theorem imply that there is a $g \in C(X)$ such that $\Lambda_x(f) = \langle f,g \rangle = |f(x)| \leq M \langle f,f\rangle^{1/2}$. I'm not entirely sure how to put these pieces together.  I was hoping to take a $X \supset \{x_n\}$ with $x_n \to x$, and by weak compactness we have for any sequence $\{f_j\} \subset \text{ball}(C(X))$ there is a subsequence such that $f_{j_k}$ converges weakly to some $f \in \text{ball}(C(X))$, which by our hypotheses implies that $f_{j_k}(x_n) \to f(x_n)$ as $k \to\infty$.  We also know that $f_{j_k}(x_n) \to f_{j_k}(x)$ as $n\to \infty$.  But there is nothing contradictory I can see coming from this observation. Any hints would be appreciated. Thanks. Edit: Also not entirely sure how $X$ compact fits in exactly, as I don't think I've taken much advantage of that fact in my observations except for claiming there is a convergent sequence.","['hilbert-spaces', 'functional-analysis', 'compactness']"
2859905,How the Bayes rule for density functions is formulated in probability theory?,"Given a probability space
$\left( \Omega\mathcal{,F,}\mathbb{P} \right)$, and two
$\mathcal{F}$-measurable real-valued random variables $X,Y$, then the
joint random variable $\left( X,Y \right)$ can be defined on a product space
$\left( \Omega^{2},\sigma\left( \mathcal{F}^{2} \right),\mathbb{P \times P} \right)$
where $\mathbb{P \times P}$ is the product measure of $\mathbb{P}$. Let
$f\left( x,y \right),f_{X}\left( x,y \right),f_{Y}\left( y \right)$ be
the density functions (Randon-Nikodym derivatives) of
$\left( X,Y \right),X,Y$ respectively, and let
$f_{X|Y}\left( x,y \right)$ be the density function of $X$ conditioned on $Y$. Anyone can help with a construction, or proof or related materials about the Bayes rule
$f_{X|Y}\left( x|y \right) = \frac{f\left( x,y \right)}{f_{Y}\left( y \right)}$? 
We may also instead consider the other version $f_{X|Y}\left( x|y \right) = \frac{f_{Y|X}\left( y|x \right)f_{X}\left( x \right)}{f_{Y}\left( y \right)}$ which does involve the joint random variable. I do not understand how the this Bayes rule is formulated in measure theory. This is a widely used formula, while I cannot find any construction or proof from my probability books. I can find related definition for ""conditional density"" in the following way. There could be other definitions. We denote the integration w.r.t. the measure
  $\mathbb{P \circ}X^{- 1}$ of a RV as
  $\int_{B}^{}{dX} := \int_{B}^{}{d\left( \mathbb{P \circ}X^{- 1} \right)}$
  for simplicity. Define the conditional probability measures $\mathbb{P}_{y},y \in Y\left( \Omega \right)$ as a family of probability
  measures on $\left( \Omega\mathcal{,F} \right)$ s.t. two axioms hold: 1)
  $\mathbb{P}_{y}\left( A \right)$ is
  $\left( \mathbb{R,}\mathcal{B}\left( \mathbb{R} \right) \right)$-measurable
  for any $A \in \mathcal{F}$ (given a fixed
  $A \in \mathcal{F}$,$\ \mathbb{P}_{y}\left( A \right)$ is a
  $\mathbb{R \rightarrow}\left\lbrack 0,1 \right\rbrack$ function w.r.t.
  index $y$); and 2) the general version of law of total
  probability $$\int_{B}^{}{\mathbb{P}_{y}\left( A \right)dY}\mathbb{= P}\left( A\bigcap Y^{- 1}\left( B \right) \right),\forall A \in \mathcal{F}, B \in \mathcal{B}\left ( \mathbb R \right)$$ We then denote
  $\mathbb{P}\left( A|Y = y \right) = \mathbb{P}_{y}\left( A \right),\forall A \in \mathcal{F}$
  as the conditional probability measure given event $Y = y$. Then for any RV $X$, the conditional probability density function $f_{X|Y}\left( x|y \right)$ is the Radon-Nikodym derivative of
  distribution $\mathbb{P}_{y} \circ X^{- 1}$ I list all relations I can conceive, based on above definition, $$\int_{B}^{}{\mathbb{P}_{y}\left( A \right)dY}\mathbb{= P}\left( A\bigcap Y^{- 1}\left( B \right) \right),\forall A\mathcal{\in F,}B \in \mathcal{B}\left( \mathbb{R} \right)$$ $$\int_{B}^{}{\mathbb{P}_{x}\left( A \right)dY}\mathbb{= P}\left( A\bigcap X^{- 1}\left( B \right) \right),\forall A\mathcal{\in F,}X \in \mathcal{B}\left( \mathbb{R} \right)$$ $$\int_{B}^{}{f_{X|Y}\left( x|y \right)} = \mathbb{P}_{y}\left\{ X^{- 1}\left( B \right) \right\},\forall B \in \mathcal{B}\left( \mathbb{R} \right)$$ $$\int_{B}^{}{f_{Y|X}\left( y|x \right)} = \mathbb{P}_{x}\left\{ X^{- 1}\left( B \right) \right\},\forall B \in \mathcal{B}\left( \mathbb{R} \right)$$ $$\int_{B}^{}{f_{Y}\left( y \right)} = \mathbb{P}\left\{ Y^{- 1}\left( B \right) \right\},\forall B \in \mathcal{B}\left( \mathbb{R} \right)$$ $$\int_{B}^{}{f_{X}\left( x \right)} = \mathbb{P}\left\{ X^{- 1}\left( B \right) \right\},\forall B \in \mathcal{B}\left( \mathbb{R} \right)$$","['measure-theory', 'probability-theory', 'probability', 'real-analysis']"
2859954,How many elements have to verify the associativity property in a group?,"If this is a duplicate please mark it down. We know that if $(G,\ast)$ is a group then it must verify the associative property, that is, $$\forall x,y,z\in G:\quad x\ast(y\ast z)\quad=\quad(x\ast y)\ast z\,.$$ My question is how many elements have to verify the associativity in a group ? I suspect that it must be $$\frac{n!}{3!},$$ where $n$ is the order of $G$. Is that right? Thank you! EDIT: as you have opined I would like to know the worst case, that is, in those where we have not realized the inheritance that can have an operation within the group or any other factor that reduces the number of check rows (yes, ""silly"" mode activated!) . If you want, you can propose the best level if certain restrictions occur (be Abelian, etc.) :) !","['group-theory', 'finite-groups', 'associativity']"
2859956,Conormal bundle and lagrangian submanifold,"Let $Q_1^{n_1},Q_2^{n_2}$ be smooth manifolds, $\phi:Q_1\to Q_2$ a smooth map and:
  $$R_\phi:=\{(x, \xi, y,\eta)\mid y=\phi(x), \xi=(d\phi)^*\eta\}\subset T^*Q_1\times T^*Q_2$$
  $$\text{graph}(\phi)=\{(q,\phi(q))\mid q\in Q_1\}\subset Q_1\times Q_2$$
  verifiy that $R_\phi$ is a Lagrangian submanifold and describe the relation between $R_\phi$ and the conormal bundle $N^*\text{graph}(\phi)$. I was able prove that $R_\phi$ is Lagrangian, but I don't know where the conormal bundle fits into the picture. Since $R_\phi$ is Lagrangian, it has dimension $n_1+n_2$, while $N^*\text{graph}(\phi)$ has dimension $n_2$. Is the conormal bundle embbeded in $R_\phi$, maybe? If so,  why is this interesting?","['symplectic-geometry', 'tangent-bundle', 'differential-geometry']"
2859964,What is the classification of 1-dimensional commutative formal group laws over $\mathbb{Z}$ up to isomorphism?,"All 1-dimensional commutative formal group laws over a field $k$ of characteristic $\geq$ 0 are classified up to isomorphism by the characteristic of $k$ and their height. This is result of Michel Lazard. Additionally, all 1-d commutative formal group laws over $\mathbb{Q}$ are isomorphic. What is known about the classification of 1-dimensional commutative formal group laws over rings of characteristic 0?","['algebraic-geometry', 'formal-groups', 'abstract-algebra', 'algebraic-topology']"
2859970,"Calculate $E[(F^{-1}(U)-G^{-1}(U))^2]$, where $F^{-1}(t)=\inf\{x\in\Bbb{R}|F(x)>t\}$.","Let $F$ and $G$ be the cumulative functions of $N(\mu_1,\sigma_1^2)$ and $N(\mu_2,\sigma_2^2)$. Let $U$ be a uniformly distributed random variable on $[0,1]$. How to calculate $E[(F^{-1}(U)-G^{-1}(U))^2]$, where $F^{-1}(t)=\inf\{x\in\Bbb{R}|F(x)>t\}$? For standard normal random variables, $F^{-1}$ is named as probit function, but I cannot find a direct expression to calculate the expectation as an integration.","['probability-theory', 'normal-distribution']"
2859999,An algebraic proof that every finite extension of $\mathbb Q$ is ramified?,"A basic result in algebraic number theory is that every proper finite extension of $\mathbb Q$ is ramified over $\mathbb Q$.  This is proved by considering Minkowski's lower bound on the discriminant. I read somewhere that there is no known proof of this result which is purely algebraic.  However, can we argue like this? Let $A$ be a ring, and let $B$ be an algebra over $A$ which is finite and projective as an $A$-module.  Then the trace map $\operatorname{Tr}: B \rightarrow A$ can be defined.  We say that $B$ is separable over $A$ if $b \mapsto \phi_b, \phi_b(b') = \operatorname{Tr}(bb')$ defines an isomorphism of $A$-modules $B \rightarrow \operatorname{Hom}_A(B,A)$.  Let's say that $B$ is etale over $A$ if it is finite, projective, and separable over $A$. Then the result that every proper finite extension of $\mathbb Q$ is ramified follows from these two results: (i): Let $A$ be a Dedekind domain with quotient field $K$, and let $B$ be the integral closure of $A$ in a finite separable extension $L$ of $K$.  If no prime of $A$ ramifies in $B$, then $B$ is etale as an $A$-algebra. (ii): Every etale ring extension of $\mathbb Z$ is of the form $\mathbb Z^n$. As far as I can tell, these two results are not hard.  The first follows from the answer to my question here , and I'm currently working out the second. Does this argument give a simple proof for why there are no unramified extensions of $\mathbb Q$?  It seems a little too easy.","['algebraic-number-theory', 'algebraic-geometry', 'commutative-algebra']"
2860057,How many n-colour points are needed to force a regularly-spaced set of one colour?,"As part of a proof in finding the minimum coloured grid that is guaranteed to have some four points that form an aligned square of one colour , I formed a technique that requires finding the smallest line of $n$-coloured points, or equivalently the shortest string of $n$ different letters, that is guaranteed to have a regularly-spaced set of the same colour (letter). For two colours and looking for a regularly spaced set of three points, we require $9$ points as shown in the following cases, forced from the initial patterns (shown red): $\mathtt {\color{red}{OOXO}OXX?}$ $\mathtt {\color{red}{OOXX}OOX?X}$ $\mathtt {\color{red}{OXOO}XOXX?}$ $\mathtt {\color{red}{OXOX}XOXO?}$ $\mathtt {\color{red}{OXX}OOXXO?}$ Where in each case the $\mathtt{?}$ creates a regularly-spaced triplet whether filled with $\mathtt{O}$ or $\mathtt{X}$. For example in the final case we produce either a regular set of $\mathtt{X}$s on a 3-step or a regular set of $\mathtt{O}$s on a 4-step pattern. Is there a method of finding a bound on the number of total points required to be sure of a regularly-spaced set of $k$ points all of the same colour in an $n$-colouring?","['number-theory', 'combinatorics', 'ramsey-theory']"
2860061,How to calculate the following $ \frac{\partial}{\partial x} \log (\det X(x))$?,How to calculate the following $$ \frac{\partial}{\partial x} \log (\det X(x))$$ where $X$ is a matrix in $\mathbb{R}^{n\times n}$ which is a function of $x\in \mathbb{R}^d$?,"['derivatives', 'multivariable-calculus', 'matrix-calculus', 'linear-algebra']"
2860099,Constraints on conical coffee cup constructions of cardioids & catacaustics,"The Mathologer video Times Tables, Mandelbrot and the Heart of Mathematics discusses several relationships. For the n=2 and 3 cases, the cardiod and catacaustic (or nephroid per @Rahul's comment ) curves are shown in reflections in coffee cups. In the case of the cardiod the cup must be conical but presumably not cylindrical, for the catacaustic it must be a cylinder. Question: If I wanted to construct these caustics using Blender , what are the specific constraints on the shapes of the coffee cups and directions of illumination? Can the former be any converging or diverging cone, and does the illumination direction need to have the same angle as that of the cone? Must the later be a perfect cylinder and the illumination only oblique? ""Bonus points"" for a description of any possible cup and illumination configuration that could work for n=4.","['curves', 'geometry', 'geometric-construction']"
2860137,Kernel of a bilinear form - Structural Mechanics,"If I have a bilinear form $$a : (H^1(\Omega))^3 \times (H^1(\Omega))^3 \mapsto \mathbb{R} \hspace{0.9in} a(\vec{u}, \vec{v}) = \int_{\Omega}{(D\vec{u})^T C (D\vec{v})\, d\Omega} $$ I would like to find the kernel of this bilinear form when $u \in V$ such that,
$$V = \{ (u_x, u_y, u_z) \in (H^1(\Omega))^3 | u_x(0,0,0) = u_y(0,0,0) = u_z(0,0,0) = 0 \}$$ I would like to comment what  are C and D operators.
D is Symmetric derivative operator.
$$D\vec{u} = \begin{bmatrix} \frac{\partial u_x}{\partial x} \\ \frac{\partial u_y}{\partial y} \\ \frac{\partial u_z}{\partial z} \\ \frac{1}{2}( \frac{\partial u_x}{\partial y} + \frac{\partial u_y}{\partial x}) \\ \frac{1}{2}( \frac{\partial u_y}{\partial z} + \frac{\partial u_z}{\partial y}) \\ \frac{1}{2}( \frac{\partial u_x}{\partial z} + \frac{\partial u_z}{\partial x})\end{bmatrix} : \Omega \mapsto \mathbb{R}^6$$
C is fourth order isotropic elasticity tensor in voigt notation. http://web.mit.edu/16.20/homepage/3_Constitutive/Constitutive_files/module_3_with_solutions.pdf pg no - 18","['bilinear-form', 'functional-analysis']"
2860143,What exactly is $\frac{\partial}{\partial x^i}\bigg|_p$?,"Let me give the reason I ask this question. We know that for a point $p = (x^1, \dots, x^n) \in \mathbb{R}^n$, the tangent space at $p$ denoted by $T_p(\mathbb{R}^n)$ has as basis $$\left\{\frac{\partial}{\partial x^1}\bigg|_p, \dots, \frac{\partial}{\partial x^n}\bigg|_p\right\}$$ where $$\frac{\partial}{\partial x^i}\bigg|_p \text{ is defined by } \left(\frac{\partial}{\partial x^i}\bigg|_p\right)(f) = \frac{\partial f}{\partial x^1}(p)$$ Now my question is what exactly are these: $$\frac{\partial}{\partial x^i}\bigg|_p$$  precisely? They are usually just called derivations , and not much further is explained in most books, but to me they seem like they are functions taking as inputs functions and returning real numbers. If so what is their domain, is it the set of all functions on $\mathbb{R}^n$? What I'm basically looking for is a way to make the construction of the basis for the tangent space of $\mathbb{R}^n$ at a point more rigorous, because at the moment it seems very symbolic based on the definition above.","['smooth-manifolds', 'multivariable-calculus', 'calculus', 'differential-topology', 'differential-geometry']"
2860144,Real world application of Lebesgue measure as opposed to Jordan measure [closed],Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question Are there real world applications of Lebesgue measure? I think Jordan measure is sufficient to solve real world problems.,"['measure-theory', 'lebesgue-measure', 'applications', 'real-analysis', 'soft-question']"
2860161,"""Rectangularity"" measure of a polygon","For an arbitrary polygon, I want to be able to calculate how ""rectangular"" it is. Does any work exist which has tried to do this? I found An Efficiently Computable Metric for Comparing Polygonal Shapes (Arkin et al., 1991) , which develops a metric for comparing arbitrary polygons. So one way to do what I want might be to use this metric and compare the polygon to some rectangle.","['geometry', 'reference-request']"
2860163,"Is there a way to classify all metabelian finite groups $G$, such that $ \operatorname{Aut}(G) \cong G$?","Is there a way to classify all metabelian finite groups $G$ , such that $ \operatorname{Aut}(G) \cong  G$ ? I know that the trivial group is the only abelian group that satisfies this condition. I also know two non-abelian groups that satisfy this condition: $S_3$ and $D_4$ . But I do not know if there are any other groups. Any help will be appreciated. EDIT: Now I also know that $Hol(Z_n)$ satisfies this condition for every odd natural $n$ . But still, is there anything else?","['automorphism-group', 'finite-groups', 'metabelian-groups', 'abstract-algebra', 'group-theory']"
2860192,Does this geometric rigidity condition forces the map to be the identity?,"$\newcommand{\Cof}{\operatorname{cof}}$
$\newcommand{\id}{\operatorname{Id}}$
$\newcommand{\End}{\operatorname{End}}$
$\newcommand{\GL}{\operatorname{GL}}$
Let $V$ be a real $d$-dimensional vector space of dimension $d > 6$. Let $B \in \GL(\bigwedge^2V) $, and suppose that $$ B(v_1) \wedge B(v_2) \wedge B(v_3)=v_1 \wedge v_2 \wedge v_3 \in \bigwedge^6V  \tag{*} $$ for every multi-vectors $v_1,v_2,v_3 \in \bigwedge^2V $. Is it true that $B=\text{Id}_V$? If it helps, we can also assume that $B$ maps decomposable elements to decomposable elements. It is important that $\dim V>6$. If $\dim V=6$, one can take any $B=\bigwedge^2 A$, where $A \in \GL(V)$ has determinant one. Edit: This seems to be true for diagonal maps $B$. Thus it also holds for diagonalizable maps (by multiplicativity). Indeed, suppose $v_i$ is a basis for $ \bigwedge^2V $, and that $Bv_i=\lambda_i  v_i$. Then condition $(*)$ implies $\lambda_{i_1} \lambda_{i_2} \lambda_{i_3}=1$ for every distinct triplet $1\le i_1,i_2,i_3 \le \binom{d}{2}=\dim(\bigwedge^2V )$. Now we think of the diagonal matrix $A=\text{diag}(\lambda_i)$ as a linear map $W \to W$, where $W=\bigwedge^2V$ is a $\binom{d}{2}$-dimensional vector space. Then the $3$-th exterior power of $A$, $\bigwedge^3 A=\text{Id}_W$. Since $3 < \dim(W)$, this implies $A=\text{Id}$, so $B=\text{Id}$ as required. We might try to generalize this claim for non-diagonalizable maps, perhaps via some density argument (over $\mathbb{C}$), but at the moment I don't see how to do this.","['determinant', 'differential-geometry', 'representation-theory', 'linear-algebra', 'exterior-algebra']"
2860196,"Kahler form lies in $H^2(X,\mathbb Z)$?","$X$ is a Kahler manifold. Then is it true that the class of Kahler form $[\omega]$ lies in $H^2(X,\mathbb Z)$? In fact I am not sure I understand $H^2(X,\mathbb Z)$ correctly. Why can we talk about $H^2_{dR}(X,\mathbb Z)$? Because I don't think ""forms with integer coefficients"" is well-defined. Edit I didn't make question clear. As Tsemo Aristide's answer suggests, if $\omega$ is a kahler form, then so is $c \omega$. So I really want to ask is: can we always find a $c$ such that $c\omega$ lies in $H^2(X,\mathbb Z)$?","['complex-geometry', 'algebraic-geometry', 'kahler-manifolds']"
2860199,"find extrema of $f(x,y,z)=z$ with domain","$D=\{(y^2+z^2)/6\le x,x^2+y^2=z^2+16\}$ in $\mathbb R$ on $f:D \to R ,f(x,y,z)=z$ First off just with a brief look at my function I can say that there are no critical points ($f_x=0,f_y=0,f_z=1$), (morover its an open set which means that the max and min cannot occur ? correct me if I'm wrong) I can now analyze the domain $D$, what I can say is that : $(y^2+z^2)/6\le x\Longrightarrow$ It's a kind of Paraboloid $x^2+y^2=z^2+16 \Longrightarrow$ It's a Hyperboloid of One Sheet If I want to find the boundary of $D$, I need to put those two equations in a system, finding: $x^2-2z^2+6x-16=0$ which is the intersection between those two surfaces. Now in order to find possible min/max points, I can use the Lagrange multiplier system with  $x^2-2z^2+6x-16=0$ as a constraint. $$\lambda (2x+6)=0$$ $$0=0$$ $$1+\lambda (-2z)=0$$ $$x^2-2z^2+6x-16=0$$ From the first equation I can say that it is TRUE for $\lambda = 0$ or $x=-3$ , but $\lambda$ cannot be zero becouse It doesn't satisfy the third equation . What I can do instead is using $x=-3$ in the forth equation , but here is the problem : I remain with $-z^2=25$ and I conclude that I didn't find any points. Even if I use the rhird equation finding $z$ and putting it inside the forth equation it still gives me something like $\lambda^2 $  equal to a negative number. Where did I make the mistake? (maybe the boundary ?)","['multivariable-calculus', 'calculus', 'lagrange-multiplier']"
2860229,"If $ab \mid c(c^2-c+1)$ and $c^2+1 \mid a+b$ then prove that $\{a, b\}=\{c, c^2-c+1 \}$","If $ab \mid c(c^2-c+1)$ and $c^2+1 \mid a+b$ then prove that $\{a, b\}=\{c, c^2-c+1 \}$ (equal sets), where $a$, $b$, and $c$ are positive integers. This is math contest problem (I don't know the source). I was struggling to solve this, but I cannot find a way to make it easier. Can you help me? All I did was like this:
$$a+b=d(c^2+1)=d(c^2-c+1+c) \\ c(a+b)=dc(c^2-c+1)+dc^2 \\ c(a+b)=deab+dc^2=d(eab+c^2)$$
I suppose this is a quadratic in $c$ and determine its discriminant. But it doesn't make the problem any easier!","['contest-math', 'number-theory', 'elementary-number-theory', 'diophantine-equations']"
2860262,Another way proof $1/2-1/3=1/6$ by using picture?,We know that $\dfrac{1}{2} -\dfrac{1}{3} =\dfrac{1}{6}$. I proved it by picture What is (are) another way (ways) by using picture?,"['alternative-proof', 'algebra-precalculus', 'proof-writing']"
2860287,Uniformly integrable local martingale,"Can someone give me an example of a uniformly integrable local martingale that is not a martingale? Or are all U.I. local martingales true martingales (continuous, of course).","['local-martingales', 'martingales', 'uniform-integrability', 'probability-theory']"
2860289,Minimum mean squared error of an estimator of the variance of the normal distribution [duplicate],"This question already has an answer here : Variance with minimal MSE in normal distribution (1 answer) Closed 4 years ago . I am trying to find the estimator of the variance $\sigma^2$ of a normal distribution with the minimum mean square error. From reading up, I know the unbiased estimator of the variance of a Guassian is  $\frac{1}{n-1}\sum_{i=1}^{n}(X_i - \bar{X})^2$ and that the estimator I am looking for is a scaled version of this unbiased estimator. The question is from a problem sheet from the last academic year. The specific question is: Let $X_1, \dots, X_n$ be a simple random sample from a normal distribution with unknown mean $\mu$ and variance $\sigma^2$. Consider estimators of $\sigma^2$ of the form $k \sum_{i=1}^{n}(X_i - \bar{X})^2$ and find the value of $k$ that minimises the mean square error. What is the efficiency of the usual unbiased estimator relative to this estimator, if the relative efficiency is defined as the ratio of the mean squared error? For the first part, I think I am meant to rewrite the MSE of the estimator as an expectation and then take derivatives with respect to $k$. This is what I have so far: $$
\begin{align}
MSE(\hat{\theta}) &= \mathbb{E} \left[ (\hat{\theta} - \theta)^2 \right] \\
&= \mathbb{E} \left[ \left(k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 - \sigma^2 \right)^2 \right] \\
&= \mathbb{E} \left[ \left(k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X} )^2 \right)^2 - 2 \left( k \frac{1}{n-1} \sum_{i=1}^{n}(X_i - \bar{X})^2 \right) \sigma^2 + \sigma^4 \right] 
\end{align}
$$ But however else I continue from here, I can't find a way that gets me to $ k = \frac{1}{n + 1}$, which the Wikipedia article linked to below suggests is the answer. For the second part, I think I can use the MSE of the unbiased estimator given in the Wikipedia article to find the efficiency, although it would be really helpful to see the steps that one takes to calculate this MSE, as in the article it is just stated. My question is linked to this one , although less advanced. The Wikipedia article on the MSE linked to in the question above is also relevant, although there they also calculate $ \mathbb{E} [S^4_{n-1}]$, which I'm not sure about.","['statistics', 'variance', 'mean-square-error', 'parameter-estimation', 'normal-distribution']"
2860352,How do we understand 6 people trying something is not 6 times the success rate? [duplicate],"This question already has answers here : What's 4 times more likely than 80%? (6 answers) Closed 5 years ago . Let's say if a task has a success rate of $20\%$, or $0.2$, meaning if a person tries it, then there is a $20\%$ chance he can succeed. One example is, if we generate a random number from 1 to 10, and getting the number 9 or 10 is considered to be a success. Now, if we let 6 people try it, and one person succeeding is considered a success, we cannot say the success rate is $6$ times as much, because then the success rate is $20\% \times 6 = 120\%$, and probability cannot be greater than $100\%$.  So the success rate is not 6 times as much. However, if we let 1 person try it $1,000,000$ times, the Law of Large Numbers says that the number of times he will succeed is $200,000$. And if we let 6 people try $1,000,000$ times each, then the number of success is indeed $200,000 \times 6 = 1,200,000$ which is $6$ times.  How can we understand this? In a real life example, say, each time when we catch a Pokemon, let's say there is a special type of Pokemon that when you tap on it, it can be ""shiny"", and the probability is $1/256$.  Now if one player try to tap on $300$ Pokemon, the probability of getting at least one shiny is not $1$, but less than $1$.  If we let 6 people, each try to tap on $300$ Pokemon (and a Pokemon can be non-shiny for player 1 but is shiny for player 2, meaning it is independent), then the probability of getting at least one shiny is not $6$ times. Now, however, if we let all 6 players, each tap on $3,000,000$ Pokemon, then the number of shiny Pokemon they will get is in fact $6$ times  if we only allow 1 player to play.  How can we understand this ""6 times yes and no"" dilemma?",['probability']
2860434,Why can $y=0$ be considered the asymptote of $f(x)=\frac{\sin x}{x}$?,"Why can $y=0$ be considered the asymptote of $f(x)=\frac{\sin x}{x}$ when the two graphs don't get any closer when $x$ approaches infinity? Because isn't the asymptote something that a graph will touch and stay on once the graph reaches infinity? And yet, in $f(x)=\frac{\sin x}{x}$, the size of $x$ has no effect on the graph's proximity to the asymptote. It just keeps fluctuating around $y=0$! So that suggests that the graph won't touch and stay on the asymptote at infinity? And if it doesn't, how can $y=0$ still be considered the asymptote of $f(x)=\frac{\sin x}{x}$?","['algebra-precalculus', 'asymptotics']"
2860453,"Prove that for $E$ of finite measure, $T(f) = \int_E\phi\circ f$ is continuous on $L^p(E)$ if $\phi(x)$ in continuous on $R$ and $\phi(x)<a+b|x|^p$.","In Chapter 8 of Real analysis , 4th edition by Royden, a functional is continuous if $f_n \rightarrow f$ in $L^p$ implies $T(f_n)\rightarrow T(f)$. Royden had given a proof of this proposition in Collary 18 in that Chapter but there seems to be a mistake in it. Let $\{f_n\}$ be a sequence in $L^p$ that convergences strongly to $f$ in $L^p(E)$. By taking a subsequence if necessary and relabelling , we suppose $\{f_n\}$ is rapidly Cauchy. Therefore, according to Theorem 6 of Chapter 7, $\{f_n\}$ convergences pointwise a.e. on $E$ to $f$. Since $\phi$ is continuous, ${\phi\circ f_n}$ convergences pointwise a.e. on E to $\phi\circ f$. Moreover, by the completeness of $L^p(E)$, since ${f_n}$ is rapid Cauchy in $L^p(E)$, the function
  $$g = |f_1| + \sum_{n=1}^{\infty} |{f_{n+1}-f_n}| $$
  belongs to $L^p(E)$. It is clear that
  $$ |f_n| \le g \text{ a.e. on E for all } n. $$
  and hence, by the inequality (33),
  $$ |\phi\circ f_n| \le a + b \cdot |f_n|^p \le a + b\cdot g^p \text{ a.e. on E for all }n.$$
  We infer from the Dominated Convergence Theorem that
  $$ \lim_{n\rightarrow \infty} \int_E \phi\circ f_n = \int_E\phi\circ f. $$
  Therefore T is continuous on $L^p(E)$. But, why could one take a subsequence if necessary as in the boldface text above? If this was done, it occur to me that it is only proven that for the subsequence $T(f_{n_k})\rightarrow T(f)$ rather than for the original sequence $T(f_n)\rightarrow T(f)$.","['lp-spaces', 'functional-analysis', 'real-analysis']"
2860474,"about $C([0,1])$ with sup metric","Define the space $C([0,1])$ as the space of continuous functions $f : [0,1] \mapsto \Bbb R$ with   $C([0,1])$ $$ d(f,g) = \sup _{x \in [0,1]}{|f(x)-g(x)|} ,  $$
so  let $$A= \left\{f \in C([0,1])\ \middle| \ 0 <\int_0^1 f(x)  \ \mathrm{d}x  < 1\right\}$$  now is $A$ open , close , bounded , connect or compact ? I think $A$ is open because for every $f \in A $ we have $B_t (f) \subseteq A $ such that $t:= 1- \int_0^1 f(x)  \ \mathrm{d}x $.(note that $B_t (f) $ is open ball with center $f$ and radios $t)$. $A$ is not close because if we let $f_n (x)= \frac{1}{n}$ then $ 0< \int_0^1 f_n(x)  \ \mathrm{d}x=\frac{1}{n} <1 $ and for every $1< n \in \mathbb{N}$ ,$  f_n(x) \in A$ and $lim_{n \to \infty} f_n(x)=0$  then $  \int_0^1 lim_{n \to \infty} f_n(x)  \ \mathrm{d}x=0  $ then 
 $ lim_{n \to \infty} f_n(x) \notin A$ hence $A$ is not close and yet $A$ is not compact .","['connectedness', 'normed-spaces', 'metric-spaces', 'general-topology', 'compactness']"
2860491,Explain why a given function does not contradict Fubini's Theorem,"Suppose $\{I_n\}$ is a pairwise disjoint sequence of sub intervals of $[0,1]$ of positive length. For each $n$ let $a_n$ be the reciprocal of the length of $I_n$, and let $g_n$ be the characteristic function of $I_n$ multiplied by $a_n$. Define $f$ by $$f(x,y)=\sum_{n=1}^{\infty} [g_n(x)-g_{n+1}(x)]g_n(y)$$ for $0\leq x, y\leq 1$. I have shown that $$\int_0^1 \int_0^1 f(x,y) dx dy = 0 \qquad \int_0^1 \int_0^1 f(x,y) dy dx = 1 $$ I now need to explain why this does not contradict Fubini's Theorem. My guess is that $|f(x,y)|$ is not integrable, but I'm not sure how to calculate that integral to prove that.","['measure-theory', 'lebesgue-integral']"
2860518,Projective cubic curve passing through seven points in $\mathbb{C}^2$,"Let $x_1,...,x_7$ be distinct points in $\mathbb{C}^2$. Prove that there exists a cubic curve passing through these points which has a singularity at the point $x_1$. My attempt so far... A related question was: show that for every five points $a_1,...,a_5\in\mathbb{P}^2$, there is a conic containing them. In the given solution it was (roughly) argued, that the space of quadratic forms is a $6$-dimensional vector space and that the condition $q(a_i)=0$ for the conic $q=0$ is a linear equation in the coefficients of $q$. Now, imposing $5$ linear conditions on a $6$-dimensional vector space leaves at least a $1$-dimensional space of solutions - which is the desired conic. Is there a way to apply this approach to the given question? If so, I assume the space of cubic forms has dimension $10$, is this correct? I don't know how the singularity would show up here.","['algebraic-curves', 'algebraic-geometry', 'projective-geometry']"
2860582,Taylor's formula with remainder for vector-valued functions,Let $f: \mathbb{R}^n \to  \mathbb{R}^n $. Does there exist a generalization of Taylor's Theorem with Lagrange Remainder for such a vector-valued function?,"['real-analysis', 'multivariable-calculus', 'calculus', 'taylor-expansion', 'vector-analysis']"
2860585,"Does the set of characters, $\Omega(\mathcal{A})$, over a C${}^{\ast}$-algebra, $\mathcal{A}$, generate a weakly dense subspace of $\mathcal{A}'$?","Let $\mathcal{A}$ be an abelian C${}^{\ast}$-Algebra with unit. We know that $\mathcal{A}\cong C(\Omega(\mathcal{A}))$, where $\Omega(\mathcal{A})\subseteq\mathcal{A}'_{\geq 0}$. Note that for $\varphi\in\mathcal{A}'$ we define $\varphi\geq 0$ exactly in case $\langle f,\varphi\rangle$ for all $f\in\mathcal{A}$ with $f\geq 0$ (whereby the order relation is the usual one on C${}^{\ast}$-Algebras). Consider now the linear hull $\langle\Omega(\mathcal{A})\rangle$. Question 1. Is this dense in $\mathcal{A}'$ under the weak topology, that is, is it $\sigma(\mathcal{A}',\mathcal{A}'')$-weakly dense? Application. Suppose that $\xi,\eta\in\mathcal{A}''$ satisfy $\xi\leq\eta$ on $\Omega(\mathcal{A})$, that is $\langle\xi,\varphi\rangle\leq\langle\eta,\varphi\rangle$ for all $\varphi\in\Omega(\mathcal{A})$. If the above is true, then it holds that $\xi\leq\eta$, that is, that $\langle\xi,\varphi\rangle\leq\langle\eta,\varphi\rangle$ for all $\varphi\in\mathcal{A}'$ with $\varphi\geq 0$. It is trivial to show this for $\xi,\eta\in\mathcal{A}$ (viewed as a subspace of $\mathcal{A}''$ in the canonical fashion), but I cannot seem to show this without the above result. Perhaps there is a counterexample, so that the desired application fails and the above result is necessarily false. Further observations. Due to the Riesz-Representation theorem, and since $\Omega(\mathcal{A})$ is compact Hausdorff for abelian C${}^{\ast}$-Algebras with a unit, we have $\mathcal{A}'\cong C(\Omega(\mathcal{A}))'=\langle\{T_{\mu}\mid\mu~\text{(reg.) prob. meas. on $\Omega(\mathcal{A})$}\}\rangle$, where $T_{\mu}:f\in C(\Omega(\mathcal{A}))\mapsto\int f~\mathrm{d}\mu$. So it is necessary and sufficient to show that all probability measures on $\Omega(\mathcal{A})$ can be weakly approximated by linear combinations of characters. Here we replace/identify each character $\tau\in\Omega(\mathcal{A})$ with $\hat{\tau}:\hat{a}\in C(\Omega(\mathcal{A}))\mapsto \tau(a)=\hat{a}(\tau)$, where $a\in\mathcal{A}\mapsto\hat{a}\in C(\Omega(\mathcal{A}))$ is the canonical Gelfand-C${}^{\ast}$-isomorphism. That is, each character is the identified with the point measure $\hat{\tau}=\delta_{\tau}$. Now, the convex hull of the set of point measures can be easily shown to be $w^{\ast}$-dense in the set of probability measures identified as a subspace of $C(K)'$, where $K=\Omega(\mathcal{A})$. Is it also $w$-dense? Hence the reduced problem: Question 2. Is the convex hull of the set of point measures over a compact Hausdorff space weakly dense in the set of probability measures?","['c-star-algebras', 'banach-spaces', 'measure-theory', 'weak-topology', 'dual-spaces']"
2860643,Decomposing Square Matrix Into Two Matrices Which Are Transposes of Each Other,"Let $X$ be a real-valued square $n \times n$ matrix. Is there decomposition $X = \Lambda \Lambda^\top$ where $\Lambda$ is a a real-valued $n \times k$ matrix, that always exists?","['matrices', 'linear-algebra', 'matrix-decomposition']"
2860668,evalute $\int_{0}^{3} \int_{0}^{x} \frac{1}{\sqrt{x^2+y^2}} dy \ dx$ by polar coordinates,"$$\int_{0}^{3} \int_{0}^{x} \frac{1}{\sqrt{x^2+y^2}} dy \ dx$$ After I sketch the area required, it is a right angle triangle with vertices $(0,0), (3,0), (3,3)$. Now I have to change it to polar coordinates to solve it. So, I know that $ dA = dx \ dy = r\ dr\ d{\theta}$ by solving the jacobian. the new integral should be something like $$ \iint_{D*}^{} 1\ dr\ d{\theta}$$ but I am having trouble determining the limits of $r$ and $\theta$.
I think it should be $$0\le \theta \le \frac{\pi}{4}$$ and $$0\le r\le3.$$ Though I'm not sure about $r$.","['integration', 'multivariable-calculus']"
2860711,"General method to prove density, continuous and compact embedding of space into another","We say that a set $X$ is dense into another one $X'$ if for any $x$ $\in$ $X'$ there exists a sequence $x_n$ that is in $X$ such that $$\lim\limits_{n\to \infty}x_n=x$$ we say that a set $X$ is compactly embedded into $Y$ if from any uniformly bounded sequence $x_n$ of $X$ one can extract a subsequence $x_{\varphi(n)}$ that converges in $Y$. Finally a set $X$ is said to be continuously embedded into $Y$ if $$\|x\|_Y\leq \|x\|_X$$ whenever $x$ belongs to $X$. Now, the question is: is there any general method or even a set of several methods to postulate whether a space is dense into another or not,  continuously embedded or not compactly embedded or not?","['general-topology', 'compact-operators', 'functional-analysis']"
2860715,How to solve Black Scholes equation directly without using probability,"Given constants $r,\sigma, K>0$, considering the Black-Scholes PDE of a Europoean call:
\begin{cases}
\frac{\partial c}{\partial t}+rs\frac{\partial c}{\partial s}+\frac{1}{2}\sigma^2s^2 \frac{\partial^2 c}{\partial s^2}-rc = 0\\
c(T,s) =(s-K)^+\\
c(t,0) = 0
\end{cases}
I learned that we can do the substitution like this:
\begin{cases}
\tau=T-t\\
u=ce^{r\tau}\\
x=\ln\frac{s}{K}+(r-\frac{1}{2}\sigma^2)(T-t)
\end{cases}
Set $u=u(\tau,x)$, then $c(t,s)=e^{-r\tau}u(\tau,x)$. Then we have:
\begin{gather*}
\frac{\partial c}{\partial t}
= re^{-r\tau}u+e^{-r\tau}(\frac{\partial u}{\partial \tau} \frac{d \tau}{dt} + \frac{\partial u}{\partial x} \frac{\partial x}{\partial t})
= e^{-r\tau}[ru-\frac{\partial u}{\partial \tau}- (r-\frac{1}{2}\sigma^2)\frac{\partial u}{\partial x}]\\
\frac{\partial c}{\partial s} = e^{-r\tau}\frac{\partial u}{\partial x} \frac{\partial x}{\partial s} = e^{-r\tau}\frac{1}{s}\frac{\partial u}{\partial x}\\
\frac{\partial^2 c}{\partial s^2} = e^{-r\tau}[-\frac{1}{s^2}\frac{\partial u}{\partial x}+\frac{1}{s^2}\frac{\partial^2 u}{\partial x^2}]=e^{-r\tau}\frac{1}{s^2}(\frac{\partial^2 u}{\partial x^2}-\frac{\partial u}{\partial x})
\end{gather*}
Thus:
\begin{align*}
\frac{\partial c}{\partial t}+rs\frac{\partial c}{\partial s}+\frac{1}{2}\sigma^2s^2 \frac{\partial^2 c}{\partial s^2}-rc 
&= e^{-r\tau}[-\frac{\partial u}{\partial \tau}- (r-\frac{1}{2}\sigma^2)\frac{\partial u}{\partial x} + r\frac{\partial u}{\partial x} + \frac{1}{2}\sigma^2(\frac{\partial^2 u}{\partial x^2}-\frac{\partial u}{\partial x})]\\
&= e^{-r\tau}[-\frac{\partial u}{\partial \tau} + \frac{1}{2}\sigma^2\frac{\partial^2 u}{\partial x^2}]\\
&=0
\end{align*}
Namely we get the heat equation with boundary condition:
\begin{cases}
\frac{\partial u}{\partial \tau} = \frac{\sigma^2}{2}\frac{\partial^2 u}{\partial x^2}\\
u(0,x)=K(e^x - 1)^+\\
u(\tau, -\infty) = 0
\end{cases}
I am stuck here. Since the boundary condition is not integrable, I cannot use Fourier transformation with regard to $x$ here. I know there is a probabilistic way of doing it, by computing the conditional expectation. I want to solve the PDE directly. After getting the heat equation here, what should I do next to solve it? Besides, is there any way to start directly from the PDE of $c$, without change of variable? And, how do we know that change of variable work here? It seems to me very coincidentally the PDE becomes a heat equation in the end. Thank you so much!","['heat-equation', 'finance', 'probability', 'partial-differential-equations']"
2860739,Pontryagin class $p_1$ on (non-)spin manifolds,"Pontryagin classes are cohomology groups with degree a multiple of four, which are defined for real vector bundles. Let us consider $p_1$ of $SO(N)$ bundle, the 4th Pontryagin class of $SO(N)$, for $N=3$. How can we prove that $p_1$ can be only an even integer on the spin manifold? How can we prove that $p_1$ can be an integer on the non-spin manifold? (What are explicit examples for $p_1 \in \mathbb{Z}$, or $p_1=1$ on which non-spin manifold? e.g. $\mathbb{CP}^2$ or $\mathbb{RP}^4$ and what elses?) Two References I find may be helpful to answer this (somewhat technical) are here: Chern-Simons invariants, SO(3) instantons, and Z/2-homology cobordism,
by Matthew Hedden, Paul Kirk On the Pontryagin Classes of Certain SO(n)-Bundles Over Manifolds, by Michel A. Kervaire Note added: Given any  $SO(3)$ connection $A$ on a bundle $E$ over a 4-manifold $M$, let $F(A)$ denote its curvature 2-form.  Define the Pontryagin charge of $A$  to be the real number 
$$
p_1(A)=-\frac{1}{8\pi^2}\int_{M}  \operatorname{Tr}(F(A)\wedge F(A)) ,
$$
provided this integral converges.  When $M$ is closed, $p_1(A)=\langle p_1(E),[M]\rangle\in \mathbb{Z}$ at the least, but it could also be $2\mathbb{Z}$ or $4\mathbb{Z}$. It looks that we need to use some properties of instanton solution whose curvature form satisfies the equation $F(A)=-\star F(A)$ to prove the above two statements I made. However, it is not obvious to me that how the spin or non-spin manifold enter to affect the instanton solution. I suppose we need to use $w_1(M)$ and $w_2(M)$ as zeros or non-zeros neatly in order to show the (1) and (2).","['fiber-bundles', 'general-topology', 'differential-topology', 'characteristic-classes', 'differential-geometry']"
2860741,"adapted process, translation between measurable and information?","Although there are plenty of questions and answers on understanding the intuition for adapted process like this post and this post I am still unclear on how an adapted filtration 'captures the information of the process up to time $t$.' First some notation, let $(\Omega, \mathcal{F}, P)$ be a probability space. $X:T\times \Omega \to (S, \Sigma)$ be a stochastic process.  That is $X_t:= X(t,\cdot)$ is an $(\mathcal{F}, \Sigma)$-measurable function for all $t\in T.$ $\{\mathcal{F}_t\}$ such that $\mathcal{F}_s\subset \mathcal{F}_t$ for $s\leq t$ be a filtration of $\mathcal{F}.$ Definition: We say $X_t$ is adapted to the filtration $\{\mathcal{F}_t\}$ if $X_t$ is $\mathcal{F}_t$-measurable for all $t.$ The definition is clear as day but I am confused about the interpretation/intuition/motivation.  A classic example is the price of a stock, $S_t$ which is adapted to the natural filtration of the Brownian motion on which it is modeled $S_t = \exp(ut + \sigma B_t).$  The interpretation on the adapted filtration condition is that we only know the current price of the stock (and its history) but we don't know the future price of the stock. Question: (stock version): Why does the stock being adapted filtration have anything to do with knowing its current and historical prices? I don't see the connection mathematically. In real life we have a stock and we know its price and its history.  I can't see the connection between this and that condition that $S_t$ be $\mathcal{F}_t$-measurable.  A discrete example might help illustrate my confusion. Discrete Example Consider the example of flipping a coin 3 times. With $X_i$ being 1 if the $i$th flip is heads and $X_i$ is 0 if the $i$th flip is tails.  Let 
$$\Omega = \{hhh, hht, hth, htt,ttt, tth, tht, thh\}$$ be the state space of the experiment and $\mathcal{F}$ all subsets of $\Omega.$  Then we define the stochastic process $X$ by $$X:\{1,2,3\}\times \Omega \to (S,\Sigma)$$ with $S=\{0,1\}$ and $\Sigma$ all subsets of $S.$ The smallest possible filtration to which $X$ is adapted is the natural filtration .  We compute $$\begin{align}
\mathcal{F}_1 &= \sigma(\{X_1^{-1}(A)| A\in \Sigma\})\\
              &= \sigma(\{X_1^{-1}(\emptyset), X_1^{-1}(0), X_1^{-1}(1), X_1^{-1}(\{0,1\})\}\\
              &= \{\emptyset, \{ttt,tth,tht,thh\}, \{hhh,hht,hth,htt\}, \Omega\}
              \end{align}$$ In this case adaptability translates to forcing $X_1$ to constant on the sets $\{ttt,tth,tht,thh\}$ and $\{hhh,hht,hth,htt\}.$  But how does this help us?  It certainly doesn't tell us which set happened and which didn't.  I can see that $X_2$ is not $\mathcal{F}_1$-measurable, but so what?  Knowing $\mathcal{F}_1$ doesn't give us any knowledge about the result of the first toss, other that it was either a heads or a tails, which we already knew.  So now I am ready to state my more general question Question Why does the $\sigma$-algebra $\mathcal{F}_t$  'contain information' about the process up to time $t$ and what does this mean?  How can we use it to say something concrete about what has actually happened up to time $t$ and how can we justify this mathematically?","['stochastic-processes', 'measure-theory', 'finance', 'filtrations']"
2860762,Derivative of a composition of differentiable function and a continously differentiable curve,"Let $f:\mathbb{R}^2\to\mathbb{R}$ be a differential function at the origin, and $\gamma_1,\gamma_2: (-1,1)\to \mathbb{R}^2$ continously differentiable curves at the origin, s.t. $\gamma_1(0)=\gamma_2(0)=(0,0)$, and $\forall t\in(-1,1) :\gamma_2(t)=\gamma_1(t)+(t^2,t^3)$. Show $\frac {d (f(\gamma_1(t))} {dt}\bigg\rvert_{t=0} = \frac {d (f(\gamma_2(t))} {dt} \bigg\rvert_{t=0}$. I tried applying the chain rule the following way: 1)$D_{f\circ\gamma_1(t)}(0)=D_f(0)D_{\gamma_1}(0)$. 2)
$D_{f\circ\gamma_2(t)}(0)=D_f(0)D_{\gamma_2}(0)=D_f(0)D_{\gamma_1+(t^2,t^3)}(0)=^*D_f(0)(D_{\gamma_1}+(2t,3t^2)(0)=D_f(0)D_{\gamma_1}(0)$ (*)- From linearity of the derivative operation Is this use of the chain rule correct? And if so, where did I use continuity of the derivatives of $\gamma$?","['multivariable-calculus', 'derivatives']"
2860800,"Show that $\langle\,23 \rangle\ =\langle\, 23 , \alpha-10\rangle^2 \langle\, 23, \alpha-3 \rangle$","Let $\alpha$ be a root of $x^3-x-1$ and $K=\mathbb{Q}(\alpha)$. (i) Show that $\langle\,23 \rangle\ =\langle\, 23 , \alpha-10\rangle^2 \langle\, 23, \alpha-3 \rangle$ (ii) Show that $\langle\,1 \rangle\ =\langle\, 23, \alpha-10, \alpha-3 \rangle\ $ I have shown $\mathcal{O}_K=\mathbb{Z}[\alpha]$.
It's quite messy to simplify $\langle\, 23 , \alpha-10\rangle^2 \langle\, 23, \alpha-3 \rangle$ using $\langle a,b \rangle \langle c, d \rangle=\langle ac, bd, ad, bc \rangle$ unlike some quadratic extensions. How do I show (i), (ii) using some theorems?","['number-theory', 'algebraic-number-theory']"
2860803,"ODE $\ x(y+4)+\frac{dy}{dx}=0 $, with conditions leading to a log of negative number?","Trivial ODE and trivial question: $$\ x(y+4)+\frac{dy}{dx}=0 $$ with initial conditions $y=-5, x=0$ After we separate variables we get:
$$\ -\frac{dy}{y+4}=x\,dx $$ Integrate left and write parts: $$-\ln(y+4)=\frac{1}{2}x^2 + C $$ Here we see that if $y=-5 $ we have a log of negative number. 
Trying not to think about it, I proceed as follows: Exponentiation of both parts: $$y = e^{-1/2x^2-C}  - 4$$ 
And then:
$$y = e^{-1/2x^2}e^{-C} - 4$$ 
$$y = e^{-1/2x^2}C - 4$$ 
(this new $C $ to $e^{-C}$ and cannot be negative)
$$-5 = e^{0}C - 4$$
$$C=-1$$
(but we see that it is in fact negative under given initial conditions) which gives us the correct answer: $$y = -e^{-1/2x^2} - 4$$ Now I feel that I've cheated somewhere. My only guess that I was able to deal with a log of a negative number and get negative $C $ (which shouldn't be negative) is because I have involved complex numbers between the lines. Is it so? If not, how can I make this solution rigorous? Thanks!",['ordinary-differential-equations']
2860810,What is the role of the genus in the double cover of a rational normal curve by a hyperelliptic curve?,"My question concerns the following problem from Rick Miranda's Algebraic Curves and Riemann Surfaces (p. 167): [S]how that if $v^2 = h(u)$ defines a hyperelliptic curve of genus $g$, then $\phi = [1 \colon u \colon u^2 \colon \cdots \colon u^{g-1}]$ defines a degree 2 map onto a rational normal curve of degree $g-1$ in $\mathbb{P}^{g-1}$, and that the hyperplane divisors of $\phi$ have degree $2g-2$. Constructing $\phi$ is easy: just compose the projection of the hyperelliptic curve onto $u$ with the standard map from $\mathbb{P}^1$ onto the rational normal curve of degree $g-1$. What I don't understand is why the genus is of importance. Can't we simply obtain a degree 2 map from any hyperelliptic curve onto any rational normal curve in exactly the same way, even if the genus and degree don't match up?","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry']"
2860816,Is $\int V^2e^{-V}d\text{vol}<\infty$ on a manifold such that $\text{Ric}+\text{Hess(V)}>0$?,"Suppose we have a measure $\mu(dx)= e^{-V(x)}d\text{vol}$ on a Riemannian manifold M with $V\in C^2(M)$, $\int e^{-V}d\text{vol} = 1$ and $\text{Ric}+\text{Hess(V)}>0$.
Is it then true that $\int V^2e^{-V}d\text{vol}<\infty$?
This holds on $\mathbb{R}^n$ and of course on any compact manifold, which tempts me to believe that it is always true, but I do not know for sure.","['riemannian-geometry', 'differential-geometry']"
2860841,Showing that the skyscraper sheaf is a sheaf.,"$\DeclareMathOperator{\res}{res}$Let $X$ be a topological space, $p \in X$ a point, $U \subset X$ an open subset covered by $\bigcup_{i \in I}U_i$, and $S$ a set (or an abelian group). I'm trying to show that the skyscraper sheaf $i_pS$ given by
$$ i_pS(U) = \begin{cases} S & \text{if } \, p \in U \\ \{ e \} & \text{else} \, \end{cases} $$
is indeed a sheaf. Here's what I've tried so far. First I want to show the gluing axiom, so I take sections $a_i \in i_pS(U_i)$ such that $\res^{U_i}_{U_i \cap U_j} a_i = \res^{U_j}_{U_i \cap U_j} a_j$. We need for there to exist a section $a \in i_pS(U)$ such that $\res^U_{U_i}a = a_i$ for all $i \in I$. But here's my problem - since the sections are elements of the set (or abelian group) $S$, I'm not sure what the restriction of one of these sections actually is (as opposed to the clear nature of a restriction when we talk about, say, the sheaf of differentiable functions). I tried to do it case-wise, so say $p \in U_i$ and $p \notin U_j$ (so $p \notin U_i \cap U_j$) for example. Then $a_j \in \{e\}$ so $a_j =e$, and by our assumption, $\res^{U_i}_{U_i \cap U_j} a_i = e$ which means that $a_i$ is $e$ on the part of $U_i$ which overlaps with $U_j$. Does this mean that $a_i$ must be $e$ on the whole of $U_i$? I feel not, because then by this logic I think we would end up with $i_pS(U)= \{e \}$. But then if the $a_i$ take different values on different parts of $U$, how does one glue them together to construct a valid $a$, and what does this $a$ even look like? I haven't yet attempted the other axiom for sheaves, but I think I'd run into similar problems with the above reasoning. Thank you for any help.","['general-topology', 'algebraic-geometry', 'sheaf-theory']"
2860920,"Approach to Polar Change of Variable in $\int_0^ {ae^{{\pi}/4}} \int_{2 \log(r/a)}^{\pi/2} f(r, \theta) r dr d \theta$.","$$\int_0^ {ae^{{\pi}/4}} \int_{2 \log(r/a)}^{\pi/2}  f(r, \theta) \ r \ dr \ d \theta$$ In the above integral, for evaluating and sketching it, I have to change the order of integral, but I am not able to get the right approach. Is there any  general method to handle change of order of integration in polar coordinates? The answer is $\theta$ varies from $0$ to $\pi/2$ and $r$ varies from $a$ to $ae^{\theta/2}$.","['integration', 'multivariable-calculus', 'calculus', 'polar-coordinates']"
2860938,"If it exists, the inverse of a compact linear operator in infinite dimensional space cannot be bouded","I have been reading some posts on here that I think are related such as this and this . I am still having a tough time coming up with a nice proof for my question. Question: If a compact linear operator $T:X \rightarrow X$ on an infinite dimensional normed space $X$ has an inverse which is defined on all of $X$, show that the inverse cannot be bounded. I found this in $8.3.8$ of Erwin Kreyszig functional analysis.","['inverse', 'functional-analysis', 'compact-operators']"
2860943,Involution On elliptic curve,"In an elliptic curve E given by $y^2=x^3 + ax^2 +bx+ c$ and origin at the point of infinity, why does the map $i$ sending $(x, y)$ to $(x, -y)$ send $i(P)=-P$, where $-P$ denotes the inverse of $P$ under the the group operation on $E$? One way is to use the explicit formula in terms of x,y for the inverse, I suppose. But in the book I’m reading (Hida’s Geometric Modular Forms) the group structure on $E$ is not defined via the usual secant line process,but via the isomorphism $E$ with $Pic^0$ sending $P$ to $I(P)^{-1} \otimes I(O)$ where $I(P)$ is the ideal sheaf of the point $P$ and $O$ is the origin. Somehow it seems, from the highlighted part in the excerpt below, we need to use something about how the group operation interacts with the a non-vanishing 1-form - we’ve seen earlier that all such are invariant under pullback via addition/translation by given point of $E$","['arithmetic-geometry', 'algebraic-geometry', 'elliptic-curves']"
2860963,Evaluate $\int_1^e\frac{1+x^2\ln x}{x+x^2 \ln x} dx$,"$$\int_1^e\dfrac{1+x^2\ln x}{x+x^2 \ln x} dx$$ Attempt: I have tried substitutions like $\ln x = t$, but they are just not helping. I end up with : $\displaystyle\int_0^1 \dfrac{1+e^{2t}t}{1+ e^t t} dt $ Here method of substitution isn't really possible and integration by parts won't help. How else do I solve it?","['integration', 'calculus', 'definite-integrals']"
2860985,Equivalent forms Optimization,"We were told to assume in class that the below optimization formulations are equivalent- $$\min_w\max_{\delta:||\delta||_F\leq\epsilon}||(X+\delta)w-y||_2^2$$ $$\min_{w}||Xw-y||_2^2+\lambda||w||_2^2 $$ for appropriately chosen $\lambda$. $X,\delta\in R^{m\times n},~w\in R^{n\times1},~y\in R^{m\times1}$ Can someone please explain why this is true? A reference paper pointing this out would also be appreciated.","['quadratic-programming', 'convex-optimization', 'matrices', 'least-squares', 'optimization']"
2861020,"Are ""pair, triple, quadruple"" considered to be sets?","I have always interpreted ""pair, triple, quadruple"" as ""sets containing two, three and four elements"". I have never checked this assumption. Consider the following examples: The pair $(V, \|\cdot\|)$ is a normed space. Another example is that of a graph with vertices and edges $(V, E)$. The triple (triplet) $(S, (u_i)_{i \in S}, (a_i)_{i \in S})$ is a
game. The quadruple $(V, F, +, \times)$ is a vector space. Are these things sets? For example, I have seen people defining ""sub-graph"", ""sub-game"", etc. which essentially implied to me that these things are sets. It occurred to me that it might be strange to think of them as sets, because the set elements are vastly different from each other, e.g. the vector space example, or a digraph, where we insert an additional operation $o$ that specifies the orientation. What sort of mathematical structures are these objects? Is there anyway to define operations on these objects? What are all the operations that can be defined on these objects?","['elementary-set-theory', 'definition']"
2861022,When is a surjective polynomial map proper?,"Suppose $F: \mathbb{C}^n \to \mathbb{C}^n$ is a surjective function such that $F$ is defined by a polynomial in each coordinate, i.e. 
$$ F = (f_1,\ldots,f_n) \quad f_i \in \mathbb{C}[x_1,\ldots,x_n] \: \forall i \leq n $$ I know that for $n = 1$, $F$ is simply a polynomial function in one variable, and therefore the fact that $F$ is surjective implies $F$ is proper. Furthermore I know that for $n > 1$, each $f_i$ is not proper as a map $f_i: \mathbb{C}^n \to \mathbb C$. My question is, under what circumstances is the map $F$ a proper map in general? Is this dependent or independent of whether $F$ is a submersion?","['polynomials', 'differential-geometry']"
2861032,Jordan block size,"I was wondering about the size of the Jordan blocks of the following matrix. $$\begin{bmatrix}
0 & 1 & 0\\
0 & 0 & 1\\
0 & 0 & 0 
\end{bmatrix}$$ I know that Jordan blocks have $1$'s on the superdiagonal. So are these $3$ blocks of size $1 \times 1$ or is this one block of size $3 \times 3$? I'm not sure how to tell the difference. Thanks in advance.","['matrices', 'jordan-normal-form']"
2861049,Binomial Coefficient Identity Conjecture,"The following (conjectured) identity has come up in a research problem that I am working on: for even $a$
$$\sum_{i=0}^{a-1} (-1)^{a-i}\binom{a}{i} \binom{2m-i-2}{m-i-1}=0;$$
and for odd $a$
$$\sum_{i=0}^{a-1} (-1)^{a-i}\binom{a}{i} \binom{2m-i-2}{m-i-1}=-2\binom{2m-a-2}{m-a-1},$$ where $a,m$ are positive integers with $1\le a\le m-2$. I've verified the identity holds for small values of $a,m$. The closest problem I have found is Help with a Binomial Coefficient Identity . Any suggestion how to apply that identity or to find another proof?","['binomial-coefficients', 'combinatorics']"
2861089,Is there any function whose limit at $x_0$ is unknown?,"I would like to know if there is any non trivial function $f(x)$ and a $x_0$ such that $$\lim_{x\to\ x_0} f(x)$$ is currently not known, with $x_0 \in \mathbb{R}\cup \{-\infty, +\infty \}$. An example of a ""trivial"" function is $A(x)$ where $A(x)$ denotes the number of perfect numbers not greater than $x$. It is an open problem to find the value of  $\lim_{x\to\infty} A(x)$, since we don't know if there are infinitely many perfect numbers. I would prefer a limit which can be recognized by a high school student.","['limits', 'open-problem', 'real-analysis']"
2861093,"Law of large numbers for sequence of running minima of i.i.d. Uniform (0,1) random variables","Let $(X_i)$ be i.i.d. Unif$(0,1)$. Define $M_n=\min\{X_1,\ldots,X_n\}$ and $T_n=\sum\limits_{k=1}^n M_k$ for every $n\ge1$. Show that $$\dfrac{T_n}{E(T_n)}\stackrel{P}{\to} 1$$ The problem I am encountering is that the random variables $M_n$ are not independent or uncorrelated so $\operatorname{Var}(T_n)$ does not seem to have a nice expression.","['law-of-large-numbers', 'probability-limit-theorems', 'uniform-distribution', 'probability-theory']"
2861111,Is $\left( {{2}^{x}}-1 \right)\left( {{5}^{x}}-1 \right)$ a square number for integer $x>1$,"Motivated by this question . How to prove that $\left( {{2}^{x}}-1 \right)\left( {{5}^{x}}-1 \right)$ is not a  square number for integer $x>1$? Thanks for any suggestions. Edition by the notification of @gimusi: The answer of this post that is mentioned by @crskhr,  is provided by the dear user @Robert Z . Thanks to all users that have been contributed in this post.","['number-theory', 'square-numbers', 'elementary-number-theory']"
2861132,Is there a name for a matrix whose n-th power is the identity matrix,"I am new to this community so my apologies it this is a duplicate, feel free to flag it. I am currently working on cyclically symmetric structural mechanics and we exploit the finite group linear representation. In this theory, properties of rotation matrices are used, specifically the fact that for a rotation matrix $\mathbf{R}$ of angle $2\pi/N$, $\mathbf{R}^{N} = \mathbf{I}$. Matrices such that $\mathbf{R}^{N} = \mathbf{0}$ are called nilpotent matrices, but is there a name for the mentioned rotation matrices ?","['matrices', 'linear-algebra', 'terminology']"
2861153,How to compute the Fourier coefficients of $\exp(f(x))$ given the Fourier coefficients of $f(x)$,"In an attempt to solve a certain differential equation numerically with the Galerkin method I bumped into this problem: Given the real function $f(x) = \sum_{n = -N}^{N} a_n \, \exp(inx) $ compute the Fourier coefficients with indices between $-N$ and $N$ of the function $\exp(f(x))$. Of course the coefficients can be computed to any required accuracy by brute force numerical methods such as Gaussian Quadrature. In terms of computation time the $O(N^2)$ operations needed by the Gaussian quadrature are however to expensive in this case. What I am looking for is therefore a closed formula or algorithm for the coefficients such that the $2N+1$ coefficients can be computed with $O(N \log N)$ operations or less. Here is what I have tried: Let $b_p$ denote the $p$'th Fourier coefficient of $\exp(f(x))$. For notational convinience we will consider the coefficient $b_{-p}$, which can be calculated as $$b_{-p} = \frac{1}{2 \pi} \int_{0}^{2 \pi} \exp(f(x)) \exp(ipx) \, dx. $$ Inserting the expansion for $f$ into this expression yields $$b_{-p} = \frac{1}{2 \pi} \int_{0}^{2 \pi} \exp\bigg( \sum_{n = -N}^{N} a_n \exp(inx) \bigg) \exp(ipx) \, dx. $$ We now rewrite this as a contour integral along the unit circle in the complex plane. One parametrization of the unit circle is $\gamma(x) = \exp(ix)$ where $0 \le x \le 2 \pi$ and by definition of a complex contour integral we therefore have $$b_{-p} = - \frac{i}{2 \pi} \int_{\gamma} \exp\bigg( \sum_{n = -N}^{N} a_n z^n \bigg)  \, z^{p-1} dz. $$ By the residue theorem of Cauchy this integral is easily calculated if the residues of the function $\exp\bigg( \sum_{n = -N}^{N} a_n z^n \bigg)  \, z^{p-1}$ are known but this is where I get stuck. To get the residues I have tried to rewrite the exponential as $$ \exp\bigg( \sum_{n = -N}^{N} a_n z^n \bigg)  = \exp(a_{-N} z^{-N}) \exp(a_{-N+1} z^{-N+1}) \cdots \exp(a_{N-1} z^{N-1}) \exp(a_{N} z^{N}) $$ and then expanded each of the exponential functions as a Taylor series (the positive powers of $z$) or a Laurent series (the negative powers of $z$). This unfortunately creates a mess and I have not been able to extract a useful formula for $b_{-p}$ from it.","['complex-analysis', 'numerical-methods', 'fourier-analysis']"
2861184,Increasing multivariate function: interpreting the definition,"I have doubts on how to interpret the following definition of $L$-increasing function. Let $\bar{\mathbb{R}}\equiv \mathbb{R}\cup \{-\infty, +\infty\}$, where $\mathbb{R}$ denotes the real line. Let $\bar{\mathbb{R}}^L$ be the $L$-fold Cartesian product for a positive integer $L$. Let $\mathcal{U}\equiv \mathcal{U}_1 \times ... \times \mathcal{U}_L \subseteq \bar{\mathbb{R}}^L$ with $ \mathcal{U}_l\subseteq \bar{\mathbb{R}}$ $\forall l \in \{1,...,L\}$. Definition $F: \mathcal{U}\rightarrow ...$ is $L$-increasing if $\forall u{'}, u{''}\in \mathcal{U}$ with $u{'}\leq u{''}$ component-wise $$
\text{Vol}_{F}(u{'}, u{''})\equiv \sum_{u\in \text{Vrt}(u{'}, u{''})}\text{sgn}_{u{'}, u{''}}(u)F(u)\geq 0
$$
 where $\text{Vrt}(u{'}, u{''})\equiv \{u\in \mathcal{U} \text{: } u_l\in \{u_l{'}, u_l{''}\} \text{ }\forall l\in \{1,...,L\}\}$ $\text{sgn}_{u{'}, u{''}}(u)\equiv \begin{cases}
1 & \text{ if $u_l=u_l{'}$ for an even number of $l\in \{1,...,L\}$}\\
-1 & \text{ if $u_l=u_l{'}$ for an odd number of $l\in \{1,...,L\}$}\\
\end{cases}$ $\text{Vol}_{F}(u{'}, u{''})$ is the $F$-volume of the $L$-box $[u_1{'}, u_1{''}]\times ... \times [u_L{'}, u_L{''}]$ and the elements of the set $\text{Vrt}(u{'}, u{''})$ are the vertices of the $L$-box Question I am confused on the last part of the definition: ""$\text{Vol}_{F}(u{'}, u{''})$ is the $F$-volume of the $L$-box $[u_1{'}, u_1{''}]\times ... \times [u_L{'}, u_L{''}]$ and the elements of the set $\text{Vrt}(u{'}, u{''})$ are the vertices of the $L$-box"". Could you help me to understand why $\text{Vol}_{F}(u{'}, u{''})$ is a volume? I have tried to picture an example for $L=2$ The green area is $F$. Suppose $u'\equiv (2,2)$ and $u''\equiv (4,3)$. Hence, $\text{Vrt}(u{'}, u{''})\equiv \{u', u'', A, B\}$ with $A\equiv (u'_1, u''_2)$ and $B\equiv (u''_1, u'_2)$. Thus, we get $$
\text{Vol}_{F}(u{'}, u{''})\equiv 1*F(u')+1*F(u'')-1*F(A)-1*F(B)
$$ Why this is a volume? It looks like just the difference between points' heights.","['functional-analysis', 'functions', 'geometry']"
2861212,Evaluating $\sum (-1)^{n+1} (n+1 + \frac{1}{n+1})/n!$,"Let $a_{n}=n+\dfrac{1}{n}$ for $n \in \mathbb{N}$. Find the sum of series $$\sum_{n=1}^{\infty}(-1)^{n+1}\dfrac{a_{n+1}}{n!}.$$
This becomes: $$\begin{align}
\sum_{n=1}^{\infty}(-1)^{n+1}\Big[\dfrac{(n+1)+\dfrac{1}{n+1}}{n!}\Big] &\implies
\sum_{n=1}^{\infty}(-1)^{n+1}\Big[\dfrac{(n+1)}{n!}+\dfrac{1}{(1+n)!}\Big] \\
&\implies \sum_{n=1}^{\infty}(-1)^{n+1}\dfrac{(n+1)}{n!}+\sum_{n=1}^{\infty}(-1)^{n+1}\dfrac{1}{(1+n)!}\\
& \implies \sum_{n=1}^{\infty}(-1)^{n+1}\dfrac{(n+1)}{n!}+e^{-1}-1
\end{align}$$ I don't know how to simplify further.","['calculus', 'sequences-and-series', 'real-analysis']"
2861217,Proof of the Symmetry Lemma,"I'm hoping someone can check that my proof of the Symmetry Lemma below is okay. (I'm actually proving a version of the result restricted to geodesic variations, because that's what I'm primarily interested in.) Note: I have seen the proof done with local coordinates, e.g., in John M. Lee's book; I want to avoid using coordinates. Let $\gamma : [0,T] \to M$ be a geodesic in a Riemannian manifold $(M,g)$, and let $\sigma : (-\varepsilon,\varepsilon) \times [0,T] \to M$, $(s,t) \mapsto \sigma(s,t)$ be a smooth geodesic variation of $\gamma$ (i.e., $\sigma(0,\cdot) = \gamma$, and $\sigma(s,\cdot)$ is a geodesic for every $s$). We can define vector fields along $\sigma$ as follows:
$$
  J(s,t) = T_{(s,t)}\sigma\cdot\left.\frac{\partial}{\partial s}\right|_{(s,t)}
         =: \frac{\partial\sigma}{\partial s}(s,t)
 \quad\text{and}\quad
  Z(s,t) = T_{(s,t)}\sigma\cdot\left.\frac{\partial}{\partial t}\right|_{(s,t)}
         =: \frac{\partial\sigma}{\partial t}(s,t).
$$
(Here $s$ is the coordinate on $(-\varepsilon,\varepsilon)$, and $t$ is that on $[0,T]$.) So we have $\dot{\gamma} = Z(0,\cdot)$, and $J(0,\cdot)$ is a Jacobi field along $\gamma$. Claim: $\frac{D}{ds}Z = \frac{D}{dt}J$. Proof : Let $\widetilde{J},\widetilde{Z} \in \mathfrak{X}(M)$ be (smooth) extensions of $J$ and $Z$, resp., to an open neighbourhood of $\sigma$, i.e., $\widetilde{J}(\sigma(s,t)) = J(s,t)$ and $\widetilde{Z}(\sigma(s,t)) = Z(s,t)$. Since $\partial/\partial s$ and $\widetilde{J}$ are $\sigma$-related, likewise $\partial/\partial t$ and $\widetilde{Z}$, we then get that
$$
  [\widetilde{J},\widetilde{Z}]\circ\sigma
    = T\sigma\cdot\left[\frac{\partial}{\partial s},\frac{\partial}{\partial t}\right]
    = 0.
$$
Thus, since the Levi-Civita connection $\nabla$ is symmetric:
\begin{align*}
  0 & = T(J(s,t),Z(s,t))\\
    & = T(\widetilde{J},\widetilde{Z})(\sigma(s,t))\\
    & = \nabla_{\widetilde{J}}\widetilde{Z}(\sigma(s,t)) - \nabla_{\widetilde{Z}}\widetilde{J}(\sigma(s,t)) - [\widetilde{J},\widetilde{Z}](\sigma(s,t))\\
    & = \nabla_{J(s,t)}(\widetilde{Z}\circ\sigma) - \nabla_{Z(s,t)}(\widetilde{J}\circ\sigma)\\
      & = \frac{D}{ds}Z(s,t) - \frac{D}{dt}J(s,t).
\end{align*}
(End of proof.) My main concern with this argument is the existence of the extensions $\widetilde{J}$ and $\widetilde{Z}$ (and hence that $[\widetilde{J},\widetilde{Z}]\circ\sigma = 0$). Clearly they won't exist on the entire image of $\sigma$, but if we restrict to a sufficiently small open subset $A \subset (-\varepsilon,\varepsilon) \times [0,T]$, then can we be assured that they exist on $\sigma(A)$? (Everything else in the proof seems okay to me, but I could be mistaken.) Edit: my claim was originally written incorrectly ($J$ and $Z$ were on the wrong sides); I've corrected this.","['riemannian-geometry', 'differential-geometry']"
2861228,"Given continuous $f:\{0,1\}^S\to[0,1]$ with S uncountable and $f(\sigma)=1$, show that $f(\tau)=1$ for some $\tau\neq\sigma$","Let $S$ be an uncountable set and consider the space $\{0,1\}^S$ under the product topology where $\{0,1\}$ is discrete. Let $f:\{0,1\}^S\to[0,1]$ be a continuous function and suppose $f(\sigma)=1$ for some $\sigma\in\{0,1\}^S$. I need to show that $f(\tau)=1$ for some $\tau\in\{0,1\}^S\setminus\{\sigma\}$. My first instinct was to take note of the cardinalities. Since $S$ is uncountable, $\{0,1\}^S$ has a cardinality of at least $2^{\aleph_1}$ whereas $[0,1]$ has a cardinality of only $2^{\aleph_0}$, so $f$ cannot be injective. Furthermore, every nonempty basis element in the product topology is a product of subsets of $\{0,1\}$ uncountably many of which must be $\{0,1\}$. So, every nonempty basis element, and therefore every nonempty open set in $\{0,1\}^S$, must have a cardinality of at least $2^{\aleph_1}$. Since $f$ is continuous, $(a,1]$ is open in $[0,1]$, and $f(\sigma)=1$, $\ f^{-1}(a,1]$ must have a cardinality of at least $2^{\aleph_1}$, so $f$ cannot be one-to-one on any interval containing $1$. In fact, for any interval $(a,1]$, there must exist $b\in(a,1]$ such that $f^{-1}(\{b\})$ is uncountable. My problem is that I have no idea how to use this to conclude that $f^{-1}(\{1\})$ contains more than just $\sigma$. Another potentially useful thing is that $\{0,1\}^S$ is compact since it is a product of compact sets which means the Extreme Value Theorem applies here.",['general-topology']
2861229,Question on the space of probability measures,"Define the total variation norm in the space of probability measures $\mathcal{P}(\mathbb{R}^d)$ by 
$$
\Vert \mu - \nu \Vert = \sup_D\lbrace | \mu(D) - \nu(D)| \rbrace.
$$
I am to show that for every $\varepsilon > 0$, I find a $\delta > 0$ such that whenever $\Vert \mu - \nu \Vert < \delta$, there are measures $\tau, \mu', \nu'$ such that
\begin{align*}
\mu &= (1-\varepsilon)\tau + \varepsilon \mu', \\
\nu &= (1- \varepsilon)\tau + \varepsilon \nu'.
\end{align*}
It would suffice to show that there is a $\tau$ such that $\mu, \nu \geq (1-\varepsilon)\tau$. I have tried doing this by choosing $\tau$ as the center of a ball of diameter $\delta$ containing $\mu$ and $\nu$ so that $(1-\varepsilon)\tau$ would then drop too far from the ball, causing the inequality, but this obviously isn't working since $\tau$ can be very close to $0$ and the difference between $(1 - \varepsilon)\tau$ and $\tau$ would be insignificant compared to $\delta$. Playing with minimums of $\mu(D), \nu(D)$ isn't working either since I can't build a $\sigma$-additive measure by combining them. I know that the space we are in is a complete metric space.","['measure-theory', 'probability-theory', 'metric-spaces']"
2861238,Reversal of Brownian motion from first hitting time,"Let $(B_t)_{t \ge 0}$ be a (standard) Brownian motion, and for fixed $C>0$ define the first hitting time
$$T_C := \inf \{t \ge 0: B_t = C\}.$$ I am interested in the reversal of the Brownian motion from the first hitting time $T_C$, i.e. a description of the distribution of the path
$$(B_{T_C - s} - C)_{s \le T_C}.$$ My question is whether this has the same law as
$$(\widetilde{B}_s)_{s \le S_{-C}}$$
where $(\widetilde{B}_s)_{s \ge 0}$ is a Brownian motion conditioned to stay non-positive, and $S_{-C}$ is the last time that the process $(B_s)$ hits $-C$. My guess above comes from the analogous problem for Brownian motion with negative drift. I was told that the following is true (I would appreciate a reference for that): Fix $m > 0$ and $C > 0$ as before. Let $T_C$ (resp. $S_{-C}$) be the first hitting time of $C$ (resp. last hittimg time of $-C$) of the Brownian motion with negative drift $(B_s -ms)_{s \ge 0}$. Then
  $$(B_{T_C - s} + m(T_C - s) - C)_{s \le T_C} \overset{d}{=} (\widetilde{B}_s - ms)_{s \le S_{-C}}$$
  where $(\widetilde{B}_s - ms)_{s \ge 0}$ is a Brownian motion with drift $-m$ conditioned to stay non-positive. As a heuristic I can send $m \to 0$ and that would recover my claim above, but this does not constitute a mathematical proof. It would be great if someone could tell me that my claim is correct and point me to references where a proof can be easily found.","['stochastic-processes', 'stopping-times', 'brownian-motion', 'probability-theory']"
2861254,"Given a set and an element, can we say that the element is subset of the given set? [duplicate]","This question already has answers here : Set theory: difference between belong/contained and includes/subset? (7 answers) Closed 5 years ago . Let us consider a set $A = \{1, 2, 3, 4, 5\}$ and an element say $1$. Can we say that  $1$ is subset of set $A$. If not, please explain.",['elementary-set-theory']
2861272,Prove that the equation: ${a^k + b^k \equiv c^k}\mod{p}$ has no solutions under the following conditions,"Prove that the equation:  ${a^k + b^k \equiv c^k}\mod{p}$ has no solutions where, $ p $ is a prime $ > 3 $, $k = \frac{p - 1}{2} $, and the condition $ 0 < a, b, c < p$ holds. See my follow up question here Check whether $k \in [0, p]$ in the equation: ${a^k + b^k \equiv c^k}\mod{p}$ has no solutions under the following conditions","['systems-of-equations', 'modular-arithmetic', 'number-theory', 'proof-verification', 'prime-numbers']"
2861273,Shadow cast by a wall; coordinate geometry/ calculus problem,"Out for a walk yesterday, I noticed something curious about the shadow cast by a certain wall. This wall had a height that grew approximately linearly. The base of the wall followed a smooth curve (hugging a bend in the road). The sun was fairly high in the sky behind the wall, causing the wall to cast a shadow. The extent of this shadow remained at approximately a constant perpendicular distance from the wall. In some sense, the curve in the wall ""cancelled out"" the increasing height of the wall. My question: what curve causes this phenomenon? I have managed to sketch out the setup in Geogebra, at the following link: https://ggbm.at/jtrnv9ds ... and here’s a pencil sketch of the setup: ... but I haven't got very far analytically. Can anybody help me? Thanks a lot!","['curves', 'calculus', 'arc-length', 'geometry']"
2861327,"A Strange Mistake in Application of Residue theorem $\int_0^{2\pi}\frac {\cos(2\theta)} {5+4\cos(\theta)}\, d\theta.$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question $$\int_0^{2\pi}\frac {\cos(2\theta)}  {5+4\cos(\theta)}\, d\theta.$$ While applying the calculus of residues to the above problem I'm getting the answer as
 $  19\pi/24$. I have tried many times and rechecked the calculations but getting the same answer. However in my book the answer given is $\pi/6.$ Can someone check and tell me whether I'm correct or the book? Please help.","['integration', 'complex-analysis', 'residue-calculus']"
2861332,Sequences and Sums,"There is a list of numbers $a_{1} , a_{2} , …, a_{2010}$ . For $1 \leq n \leq 2010$, where $n$ is positive
integer, let $a_1+a_2+ \ldots +a_n = S_n$ . If $a_1 = 2010$ and $S_n = a_nn^2$ for all n, what is
the value of $a_{2010}$ ? I've been trying to manipulate the formula but I cant seem to find a good relationship between $a_1$  and $a_{2010}$ like
$$
a_{2010} = \frac{a_1 +a_2 ... +a_{2010}}{2010^2}
$$ 
Then tried to use the definition $S_n = a_nn^2 $ over and over again but I cant find a good formula.",['sequences-and-series']
2861340,What is the motivation for Axiom of Regularity?,"In my textbook A Course in Mathematical Analysis by Professor Garling, he utilized Axiom of Regularity to prove one of the properties of models of natural numbers, and afterwards he never mentions Axiom of Regularity anymore. I know that we need other axioms to resolve some paradoxes such as Russell's paradox. And this paradox is mentioned frequently in Analysis textbook. But I have not observed the same motivation for Axiom of Regularity. I think there must be another deeper motivation for adopting this axiom into ZF, but i'm just recently exposed to set theory. Please give me some explanations!","['elementary-set-theory', 'intuition']"
2861368,Prove that the ordering relation $<_Z$ on the integers is well defined.,"I am in the beginning of learning set theory, and the author constructs $\mathbb{R}$, $\mathbb{Q}$ and lastly $\mathbb{Z}$, before $\mathbb{N}$. Definition of $\sim$ The relation $\sim$ between ordered pairs of natural numbers is defined as: 
$a+d = c+b \implies (a,b)\sim (c,d)$ Definition of an Integer The equivalence class under this equivalence relation for an ordered pair $(a,b)$, i.e. the set $\{(c,d)\in \mathbb{N}\times \mathbb{N}: (a,b)\sim (c,d)$} Question Assume $(a,b),(a',b'),(c,d),(c',d') \in \mathbb{N}\times \mathbb{N}$ and $(a,b)\sim (a',b')$ and $(c,d)\sim (c',d')$. Use the standard properties of $\mathbb{N}$ to show that $a+_N d <_N c+_N b \iff a'+_N d'<_N c'+_N b'$. (The reason for the title is that later $<_Z$ is defined as: integer$(a,b) <_Z $integer$(c,d)$ if $a+_Nd<c+_Nb$) Attempt As far as I understand, since we work with $\mathbb{N}$ to define $\mathbb{Z}$, subtraction and division are not generally defined. I know the following (all operations are those defined in $\mathbb{N}$): (1.) $a+b'=a'+b$ (2.) $c+d'=c'+d$ I start by assuming $a+d < c+b$ and want to show that then $a'+d' < c'+b'$ From here I just feel stuck, because I would have wanted to maybe from (1.) and (2.) rewrite $a,b,c,d$ in terms of $a',b',c',d'$ but that requires subtraction or division which is not well defined. Overall I just feel very limited to do any algebra that I am used to when working with inequalities and equations because that usually requires subtraction or division. I would appreciate a hint how to start, and possibly if you have time a solution underneath so that I can try to solve it myself.","['elementary-set-theory', 'integers', 'natural-numbers']"
2861397,What is the correct way to read $f\circ g$?,"Let $f : X \to Y$ and $g : Y \to Z$ be functions. We define the composition $g \circ f : X \to Z$ by $g \circ f(x) = g(f(x))$ for each $x \in X$. I have also heard the composition read out like this: ""The composition of $f$ with $g$ is . . ."" ""Consider the function $g$ composed with $f$ , given by . . ."" ""The function $g$ of $f$ is . . ."" Is this an appropriate way to speak of $g \circ f$? It sometimes happens that I (or my teachers) reverse the order of $f$ and $g$ when describing $g \circ f$ in any of the above ways. Surely, it can't be that both ways are correct. It doesn't cause confusion because the function being talked about is quite straightforward. But I'm still interested in knowing what the ""correct"" way/s to describe $g \circ f$ is/are among the above. I know that some people prefer the functional notation that operates the other way, but this question is not about that scenario.","['functions', 'function-and-relation-composition', 'terminology']"
2861410,Prove $\frac{BC}{CA} \cdot \frac{AE}{EF} \cdot \frac{FD}{DB} = 1$ in Convex hexagon,"Let $ABCDEF$ be a convex hexagon such that $\angle B+\angle D+\angle F=360^{\circ }$and $\frac{AB}{BC} \cdot \frac{CD}{DE} \cdot \frac{EF}{FA} = 1$ . Prove that $\frac{BC}{CA} \cdot \frac{AE}{EF} \cdot \frac{FD}{DB} = 1$. I know it is an old but nice question it belongs to IMO shortlist in 1998.you can find out some proof in below link but unfortunately there is no synthetic solution in the link https://artofproblemsolving.com/community/c6h1117p3488 I think we should consider this fact that the circumcircles of triangles $ABC, CDE, EFA$ have a common point $P$. Because, if $P$ is the intersection of circumcircles $CDE, EFA$ , then: $\angle EPC=180-\angle D$ $\angle APE=180-\angle F$ then: $\angle APC=360-(\angle D+\angle F)=\angle B$ and it means that $P$ is on circumcircle of $ABC$ ,too. Please post synthetic answers. Thanks!","['analytic-geometry', 'geometry', 'plane-geometry', 'differential-geometry']"
2861432,Complicated differential operator and application of the Zassenhaus formula,"I have a differential operator $$D_x =  \frac{1}{x} \left[ (x^2 - a^2) \frac{d}{dx} \left( \frac{1}{x} \frac{d}{dx} \right) + 2 \frac{d }{dx} \right], $$ and I would like to compute $$ e^{i \lambda D_x} ~j_0(x) = \sum_{n=0}^\infty \frac{(i\lambda)^n}{n!} [D_x]^n ~j_0(x), $$ where $~j_0(x) = \sin(x)/x~$ is the spherical Bessel function. 
Is there some nice way I could do this? I tried using the Zassenhaus formula , using the splitting $$ D_x = A_x + B_x, ~~{\rm where}~~ 
A_x=\frac{(x^2 - a^2)}{x}\frac{d}{dx} \left( \frac{1}{x} \frac{d}{dx} \right), ~~B_x = \frac{2}{x} \frac{d }{dx},$$
but it does not seem like a promising path, given that higher commutators $[A_x,B_x],~[A_x,[A_x,B_x]],\ldots$ get more and more complicated. I also tried just brute force derivation that would give me a 
series representation as 
$$\sum_{n=0}^\infty \frac{(i\lambda)^n}{n!} [D_x]^n ~j_0(x)
= \sum_{n=0}^\infty \frac{(i\lambda)^n}{n!} \left[ f_n(x) \sin(x) + g_n(x) \cos(x) \right],$$
but I couldn't find close formulas for $f_n(x)$ and $g_n(x)$ functions.
What else could I do?","['derivatives', 'noncommutative-algebra']"
2861433,"Find a function that maps (0,1) into, but not onto","Find a $1–1$ function that maps $(0,1)$ into, but not necessarily onto, $S$. Where $S$ is the set of points in the open unit square; that is, $S = {(x, y) : 0 < x, y < 1}.$ (This is easy.) After thinking and rereading about an hour I give up trying answer the question. Especially, when the author states, that it is trivial. Nothing comes to my mind :(. Can you, please, help me? In general, are there any systematic ways to answer such kind of questions, rather than guessing a function (as it is so far in the textbook: Understanding Analysis, Stephen Abbott)?","['elementary-set-theory', 'analysis']"
2861449,Parameterizations of the unit simplex in $\mathbb{R}^3$,"The unit simplex in $\mathbb{R}^3$ is $$\Delta^3 = \left\{(t_1,t_2,t_3)\in\mathbb{R}^{3}\mid t_1+t_2+t_3 = 1 \mbox{ and } t_i \ge 0 \mbox{ for all } i\right\}$$
When trying to describe it parametrically, an obvious choice is
$$ (x,y,1-x-y)$$
over an approriate two-dimensional domain. This particular parameterization is not symmetric, as the third coordinate plays a different role than the first two. Are there any other parameterizations of the unit simplex $\Delta^3$ which are more natural? For example, ones in which the distance to the edge can be easily read. If so, I would appreciate some examples. Thank you!","['coordinate-systems', 'geometry', 'simplex']"
