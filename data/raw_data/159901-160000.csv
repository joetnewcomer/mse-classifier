question_id,title,body,tags
2757713,Derivatives of eigenvalue with respect to boundary location,"I have considered the Sturm–Liouville problem in a form of one-dimensional Schrodinger equation with Dirichlet boundary conditions:
$$
\left\{\begin{array}{l}
\displaystyle-\frac{\hbar^2}{2m}\varphi''(x)+V(x)\varphi(x)=E\varphi(x),\quad a\leqslant x\leqslant b,\\
\varphi(a)=\varphi(b)=0.\end{array}\right.
$$
If we obtained some specific eigenvalue $E_n$ and eigenfunction $\varphi_n(x)$, then the eigenvalue $E_n$ should somehow depend on the boundary point locations $a$ and $b$ . I have found that
$$
\frac{\partial E_n}{\partial a}=\frac{\hbar^2}{2m}|\varphi'_n(a)|^2,\qquad
\frac{\partial E_n}{\partial b}=-\frac{\hbar^2}{2m}|\varphi'_n(b)|^2.
$$ I suppose this is a well-known result in the theory of differential equations or in the functional analysis, so could anyone give any additional information about this problem (any books or papers, who first obtained this result, what is its higher-dimensional generalizations etc.).","['functional-analysis', 'eigenvalues-eigenvectors', 'sturm-liouville', 'ordinary-differential-equations']"
2757761,Does there exist a formula for product of the primitive $ n $th roots of unity.,I know there is a formula for the sum of the primitive $ n $th roots of unity which is the Mobius function of $ n $. See: The Möbius function is the sum of the primitive $n$th roots of unity. I am curious about the existence of a formula for the product of the primitive $ n $th roots of unity.,"['number-theory', 'abstract-algebra', 'cyclotomic-polynomials']"
2757777,"For a matrix with all integer called entries, any integer eigenvalue will divide the determinant.","I have to show that for a matrix with all integer valued entries, any integer eigenvalue will divide the determinant. I know that the product of the eigenvalues is the determinant, but there can be non integral eigenvalues too. Also I know the sum of the eigenvalues, which is the trace of the matrix, is also integral. Any hint will be good. Thank you.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2757796,British Maths Olympiad (BMO) 2002 Round 1 Question 3 Proof without Cauchy-Schwarz?,"The question states: Let $x,y,z$ be positive real numbers such that $x^2 + y^2 + z^2 = 1$ Prove that $x^2yz + xy^2z + xyz^2 ≤ 1/3$ I have a proof of this relying on the fact that: $x^2/3 +y^2/3 + z^2/3 \geq (x+y+z)^3/9  $ (A corollary of C-S I believe) Is there an elementary proof without this fact (or C-S in general)?","['inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality', 'algebra-precalculus', 'contest-math']"
2757870,Prove the even integers are countable (by explicitly giving a bijection $\mathbb{N} \to E$),"I've come to this:
$$f: \mathbb{N} \to \{\ldots, -6,-4,-2,0,2,4,6, \ldots\},\qquad f(n) =
\begin{cases}
2n & \text{ if } n \text{ is odd} \\ 
-n & \text{ if } n  \text{ is even}
\end{cases}$$ I don't know what to do with this though. I never know how to format a proof correctly.","['proof-writing', 'elementary-set-theory']"
2757876,"The minimal primes of $\mathscr{O}_{X,p}$ are in canonical bijection with the irreducible components of $X$ passing through $p$.","I wonder how to prove Let $X$ be a scheme. The minimal primes of $\mathscr{O}_{X,p}$ are in canonical bijection with the irreducible components of $X$ passing through $p$.( Source ) This is easy when $X=\operatorname {Spec} A$. In general, I think I need to find a generic point of some irreducible component based on this minimal ideal. But I don't know how to construct the bijection. I feel like this is a theorem in algebraic geometry textbooks. If the proof is rather complicated, I really appreciate it if you can show me where to find it.","['schemes', 'algebraic-geometry']"
2757881,Properties of the 1-d Heat Kernel,"Let $H$ be the one dimensional heat kernel, i.e the function $H(t,x,y)$ such that the Dirichlet problem:
$$
\begin{cases}
u_t - u_{xx} = 0 & x\in(0,1) , t \in (0,\infty) 
\\
u(t,1) = u(t,0) =0 & t>0 
\\
u(0,x)  = f(x)
\end{cases}
$$
is solved by:
$$
u(t,x) = \int_0^1 f(y)  H(t,x,y) \mathrm{d}y
$$
Prove that: $H$ is nonnegative The integral of $H$ with respect to $y$ is non-increasing with respect to $t$. I believe that these properties of $H$ can be derived without using the explicit (Fourier sine series) representation of $H$. I am not sure however how to derive the first (I have not started on the second). Would anyone be able to provide a hint (I am not looking for a complete answer, at least not right now). I know that $H$ itself solves the heat equation, but I am not entirely sure how to use this property, as taking derivatives of $H$ without using the explicit representation seems to be an arduous task.","['multivariable-calculus', 'heat-equation', 'partial-differential-equations']"
2757944,Solving least squares problem using partial derivatives,"Let's say we want to solve a linear regression problem by choosing the best slope and bias with the least squared errors. As example, let the points be $x=[1, 2, 3]$ and $y=[1,2,2]$ . This quadratic minimization problem can also be represented as: $||Ax-b||^2=||e||^2=e^2_1+e^2_2+e^2_3$ Linear Algebra We could solve this problem by utilizing linear algebraic methods. We could use projections. For projecting on the $0+$ dimensional subspaces. Projection equation $p = Ax = A(A^TA)^{-1}A^Tb$ could be utilized: $A^T(b-Ax)=0$ $A^TAx = A^Tb$ $x = (A^TA)^{-1} A^Tb$ We know the inner product of $A^T$ and $e=b-p=b-Ax$ is $0$ since they are orthogonal (or since $e$ is in the null space of $A^T$ ). Which is the reason why we got the equation above. Now we need to present the quadratic minimization problem in linear algebra $Ax=b$ : $\begin{bmatrix}1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix}\begin{bmatrix}c \\m\end{bmatrix} = \begin{bmatrix}1 \\ 2 \\ 2 \end{bmatrix}$ where $c$ is bias and $m$ is slope. We can see that matrix $A$ is a basis for the column space, $c$ and $m$ are linear coefficients and $b$ represents range of the function. Considering that this equation doesn't have direct solution, then we are looking for projection of the vector $b$ on the column space of matrix $A$ . Solution : Let $Proj(x)$ be the projection function (where $x$ contains unknown coefficients that we are trying to find, in this case $[c, m]^T$ ): $Proj(x) = Proj\left(\begin{bmatrix}c \\ m \end{bmatrix}\right) = (A^TA)^{-1}A^Tb = \left(\begin{bmatrix}1 & 1 & 1 \\ 1 & 2 & 3\end{bmatrix}\begin{bmatrix}1 & 1 \\ 1 & 2 \\ 1 &  3\\ \end{bmatrix}\right)^{-1} \begin{bmatrix}1 & 1 & 1 \\ 1 & 2 & 3\end{bmatrix}\begin{bmatrix}1 \\ 2 \\  2\\ \end{bmatrix} = \left(\begin{bmatrix}3 & 6 \\ 6 & 14 \end{bmatrix}\right)^{-1}\begin{bmatrix}5 \\ 11 \end{bmatrix}=\left(\frac{1}{3(14)-6(6)}\begin{bmatrix}14 & -6 \\ -6 & 3  \end{bmatrix}\right)\begin{bmatrix}5 \\ 11 \end{bmatrix}=\begin{bmatrix}2.33333333 & -1 \\ -1 & 0.5  \end{bmatrix}\begin{bmatrix}5 \\ 11 \end{bmatrix} = \begin{bmatrix}0.66666667 \\ 0.5 \end{bmatrix}$ Multivariable Calculus At this point of the lecture Professor Strang presents the minimization problem as $A^TAx=A^Tb$ and shows the normal equations. Then he proceeds solving minimization problem using partial derivatives, although I couldn't quite understand how could partial differentiation be used to solve this problem. From what I know, partial derivatives can be used to find derivatives for the structures that are in higher dimensions. Since for example finding full derivative at certain point of a 3 dimensional object may not be possible since it can have infinite tangent lines. Although, by treating one variable as a constant can be utilized to solve the differentiation problem, and this process is called partial differentiation from my knowledge. Question How does partial differentiation solution exactly work? How can it be compared to the linear algebraic orthogonal projection solution? Thank you!","['least-squares', 'projection', 'partial-derivative', 'multivariable-calculus', 'linear-algebra']"
2757946,Complex Values in Second Order Differential Equations,"Recently I've learned that second order linear homogeneous differential equations can be solved by assuming the function to be something like this. 
$$Ay''+By'+Cy=0$$
$$y = e^{St} $$
$$AS^2+BS+C=0$$
When encountering underdamped systems, the value of S would be imaginary, leaving you with Euler's identity.
$$e^{i\alpha}=\cos(\alpha t)+i\sin(\alpha t)$$ When solving for the fundamental solutions our professor disregarded the imaginary coefficient and claimed that the fundamental solutions are the imaginary component and the real component. How is this so??","['ordinary-differential-equations', 'complex-numbers']"
2757967,Understanding an Algebra over a Field,"I am trying to understand the components of an algebra over a field . an algebra over a field (often simply called an algebra) is a vector space equipped with a bilinear product. I am familiar with the definition of a field, and sort of familiar with vector spaces. I am not familiar with bilinear products and the meaning of a ""vector space over a field"". Wikipedia says a bilinear map is a set of 3 vector spaces over the same field. I am wondering the following: What it means to be a vector space over a field . Wondering if it's different than just a vector space. Since the 3 vector spaces are different, but they all ""work on"" the same underlying set, wondering how their operations are compatible. It would be helpful to see an example of a bilinear map/product as vector spaces over a field. If ""an algebra"" in this context is the same as the generic definition of an algebra as ""a set plus a set of operations on that set"".","['abstract-algebra', 'field-theory']"
2757983,Map $F$ open and $F(\mathbb{R})$ is a submanifold,"Let $F: \mathbb{R} \rightarrow S^1 \times S^1$ defined by
$$F(t) = ((\cos2\pi t, \sin2 \pi t), (\cos2\pi \alpha t, \sin2 \pi \alpha t))$$. For which values ​​of $\alpha$ the map $F$ is open? For which values ​​of $\alpha$ the set $F(\mathbb{R})$ is a submanifold? ps.: my initial idea was to verify what is required for the coordinate functions $F_1$ and $F_2$ to be a local diffeomorphismos. Hence he would find conditions on the $\alpha$. And it would use that local diphomorphism product is local diffeomorphism and therefore open. But I did not succeed.","['submanifold', 'smooth-manifolds', 'differential-geometry', 'open-map']"
2757990,How do I prove that $a_n=\sum_{k=1}^{n} \frac{1}{k}$ is not a Cauchy sequence?,"First, I have to say that it does not make sense to me, because I know for sure that $\sum_{k=1}^{n}\frac{1}{k^2}$ is a Cauchy sequence so naturally in my mind the discussed one ""should"" converge too. But this is a homework so I guess my intuition is wrong this time.
This is what I have done so far:
There exists $N\in \mathbb{N}$. So,
$$
\begin{aligned}
|a_{n+N}-a_n| =|\sum_{k=1}^{n+N} \frac{1}{k}-\sum_{k=1}^{n} \frac{1}{k}|=
|\frac{1}{n+1}+\frac{1}{n+2}+...+\frac{1}{n+N}|=\frac{1}{n+1}+\\
\frac{1}{n+2}+...+\frac{1}{n+N} \geq \frac{N}{n+N} \geq \epsilon
\end{aligned}
$$
I probably not skilled enough in algebra to continue from here. Edit: I have to find an $\epsilon$ that satisfies this expression.","['cauchy-sequences', 'sequences-and-series', 'limits']"
2758024,"Can $2^s+3^s+\cdots +q^s$ , $q$ odd prime , $s\ge 2$ be a perfect power?","Let $q$ be an odd prime and $s\ge 2$ be an integer. Define the sum $$S(q,s):=\sum_{p\ prime,p\le q} p^s=2^s+3^s+\cdots +q^s$$ Can $S(q,s)$ be a perfect power ? Among other searches, I searched for $s\le 1000$ and $q\le1000$ and did not find an example.","['reference-request', 'number-theory', 'perfect-powers', 'summation', 'prime-numbers']"
2758052,Proof by induction. Two matrices are equal. [duplicate],"This question already has answers here : Matrix Power Formula (5 answers) Closed 3 days ago . I think i have this proof figured out but I just want a second opinion. We have matrices $A=B$. $$A=\begin{pmatrix}a&1\\0&a\end{pmatrix}^n$$   $$B=\begin{pmatrix}a^n&n a^{n-1}\\0&a^n\end{pmatrix}$$ My base case I used $n=1$ and I was able to get them to equal.
Next with my induction step I set $n=k$ and assumed that the base cases holds. So then I let $n=k+1$ and I got matrix $A$ to look nice. However when i did this process with matrix $B$ it did not equal matrix $A$. So with this i continued to solve through and i have gotten them almost identical but i feel like i am missing a step. Thank you!","['matrices', 'induction', 'proof-verification']"
2758068,Show that there are infinitely many positive integers that are not the sum of $15$ fourth powers,"The Question: Show that there are infinitely many positive integers that are not the sum of $15$ fourth powers. My Attempt: I am completely stuck. The previous parts of this question were to show that there are infinitely many positive integers that are not the sum of: (i) $3$ squares (ii) $8$ sixth powers (iii) $11$ tenth powers For example, I did (i) by showing that all squares are congruent to either $0$, $1$, or $4 \pmod 8$ and hence all numbers of the form $7+8k$ cannot be the sum of three squares. Similarly, I found $9+27k$ for (ii) and $12+50k$ for (iii) through exhaustive trial and error. However, I couldn't do $15$ fourth powers, even with the help of a computer efficiently computing all the modulos for me. Is there a better way to do this?","['number-theory', 'modular-arithmetic']"
2758092,A Problem Dealing with putting balls in bin and Expected Value - possible wrong answer,"Please consider the problem below. Is my answer correct. If is not correct then where did I go wrong? Problem: You keep tossing balls into $n$ bins until one of the bins has two balls. For each toss there is a $\frac{1}{n}$ probability that the ball you toss lands in any one of the bins. What is the expected number of tosses? Answer: Let $p_i$ be the probability that after $i$ tosses we have at least one bin
with two balls.
\begin{eqnarray*}
p_1 &=& 0 \\
p_2 &=& 1 - ( 1 - \frac{1}{n} ) = \frac{1}{n} \\
p_3 &=& 1 - (1 - \frac{1}{n})(1 - \frac{1}{n-1}) \\
p_3 &=& 1 - (\frac{n-1}{n})(\frac{n-1-1}{n-1}) \\
p_3 &=& 1 - (\frac{n-2}{n}) = \frac{2}{n} \\
p_4 &=& 1 - (1 - \frac{1}{n})(1 - \frac{1}{n-1})(1 - \frac{1}{n-2}) \\
p_4 &=& 1 - ( \frac{n-1}{n} )( \frac{n-2}{n-1} )( \frac{n - 2 -1}{n - 2} ) \\
p_4 &=& 1 - \frac{n-3}{n} = \frac{3}{n} \\
\end{eqnarray*} Now for $1 <= i <= n$ we have: $p_i = \frac{i-1}{n}$.
\begin{eqnarray*}
E &=& 2p_2 + 3p_3 + 4p_4 + ... (n+1)p_{n+1} \\
E &=& \sum_{i = 1}^{n} \frac{i(i+1)}{n} = \frac{1}{2n} \sum_{i=1}^{n} i^2 + i \\
E &=& \frac{1}{2n}(\frac{n(n+1)(2n+1)}{6} + \frac{n(n+1)}{2} ) \\
E &=& \frac{n+1}{4n} ( \frac{2n+1}{3} + 1 ) \\
\end{eqnarray*} Here is an update to my answer: Let $p_i$ be the probability that after $i$ tosses we have at least one bin
with two balls.
\newline
\begin{eqnarray*}
p_1 &=& 0 \\
p_2 &=& 1 - ( 1 - \frac{1}{n} ) = \frac{1}{n} \\
p_3 &=& 1 - (\frac{n-1}{n})( \frac{n-2}{n}) \\
p_3 &=& 1 - \frac{(n-1)(n-2)}{n^2} = \frac{n^2 - (n^2 - 3n + 2)}{n^2} \\
p_3 &=& \frac{3n-2}{n^2} \\
p_4 &=& 1 - (\frac{n-1}{n})(\frac{n-2}{n})(\frac{n-3}{n}) \\
p_4 &=& 1 - \frac{(n^2-3n+2)(n-3)}{n^3}\\
p_4 &=& 1 - \frac{n^3-3n^2+2n - 3n^2 +9n - 6}{n^3}\\
p_4 &=& \frac{3n^2-2n + 3n^2 - 9n + 6}{n^3}\\
p_4 &=& \frac{3n^2 + 3n^2 - 11n + 6}{n^3}\\
\end{eqnarray*} \begin{eqnarray*}
E &=& 2p_2 + 3p_3 + 4p_4 + ... (n+1)p_{n+1} \\
\end{eqnarray*}
Now, am on the right track? That is, is what I have so far correct? Thanks, Bob","['combinatorics', 'probability']"
2758107,Convergence a.s. $\Longleftrightarrow$ Convergence in P,"Let $\{Y_n\}'s$ be independent r.v.'s, $S_n = \sum^n_{i=1}Y_i$, a. Prove that for arbitrary $\epsilon >0$, $$P\left(\sup_{\{k\geq1\}}|S_k|>4 \epsilon\right) \leq 4\sup_{\{k\geq1\}}P(|S_k|>\epsilon)$$ 
  and for each integer $n$, $\epsilon >0$, 
  $$P\left(\sup_{\{n\geq k\geq1\}}|S_k|>4 \epsilon\right) \leq 4\sup_{\{n\geq 
   k\geq1\}}P(|S_k|>\epsilon).$$ b. Use (a) to prove $\sum^{\infty}_{i=1}Y_i$ convergence in probability implies it convergence almost surely. I am very confused about how to solve this question, by my intuition, convergence in probability dose not implies convergence almost surely.","['real-analysis', 'probability', 'probability-theory']"
2758158,Is the sum of digits of $\left(16^k - 1\right)$ less than $6k$ for $k > 223$?,"I had been researching the OEIS sequence A165722 , which is the sequence of positive integers $k$ such that the sum of digits of $\left(16^k - 1\right)$ is equal to $6k$. I used computational power to determine that the sum of digits is less than $6k$ for $223 < k < 10^6$. I made a conjecture that $6k$ would continue to grow at a faster rate than the digit sum, and thus the sequence is finite. I and several others, however, were unsure how one would go about proving this. I thought that perhaps there would be some way to show a regularity in the digits of $16^k - 1$, but I would not know how to go about finding or proving this regularity.","['number-theory', 'recreational-mathematics', 'sequences-and-series']"
2758184,The altitude of a triangle bisects a segment joining vertices of squares erected upon two sides of that triangle,We start with $\triangle ABC$ with $AD$ as its altitude. We then construct squares $\square ABEF$ and $\square ACGH$ outwards from $AB$ and $AC$. We then connect $F$ and $H$. $DA$ is extended so it intersects $FH$ at $M$. How do we prove that $FM$ = $MH$? I tried proving that $\triangle FAH$ is similar or congruent to $\triangle ABC$ but the angles don't match. I tried connecting $FD$ and $HD$ to form $\triangle FDH$ but I don't know how to proceed from there. I also tried connecting $FB$ and $HC$ to form $FBCH$ but I'm not sure if this helps. Am I missing something?,"['euclidean-geometry', 'congruences-geometry', 'triangles', 'geometry']"
2758249,What does it mean when I say that addition/multiplication for an equivalence relation is well defined?,"I have trouble understanding this concept. Why is it necessary to prove that addition or multiplication is well defined in equivalence classes? My understanding of equivalence classes is that it must be reflexive, symmetric and transitive. Doesn't proving it automatically imply that addition and multiplication can be done? Why the additional need to prove that it is 'well defined'? Apologies if this question is too trivial; my understanding of this topic is limited.","['abstract-algebra', 'equivalence-relations', 'modular-arithmetic', 'relations']"
2758252,Differential Equations involving exponentials,"It's been sometime since I've had to solve a differential equation involving an exponential.
The DE is a separable $$\begin{align}
& 2\cdot\frac{\mathrm{d}y(x)}{\mathrm{d}x} + e^{y(x)} = 0\\
\implies& \frac{\mathrm{d}y(x)}{\mathrm{d}x} = -\frac{1}{2}e^{y(x)}\\
\implies& \frac{1}{e^{y(x)}}\cdot\frac{\mathrm{d}y(x)}{\mathrm{d}x} = -\frac{1}{2}\\
\implies& \int e^{-y(x)}\ \mathrm{d}y(x) = -\frac{1}{2}\int \mathrm{d}x\\
\implies& - e^{y(x)}= -\frac{1}{2}x+C\\
\implies& y(x) = \ln\left(\frac{1}{2}x+C\right)\\
\end{align}$$ I think this is the answer, but for some reason Wolfram Alpha gives $y(x) = -\ln\left(\frac{1}{2}x + C\right)$. Where did the negative come from?",['ordinary-differential-equations']
2758273,martingale central limit theorem,"Suppose $(X_{n},\mathcal{F}_n)_{n\ge 1}$ be a martingale with $\sigma_n:= \|{X_n}\|_2<\infty$, and $\Delta_n=X_n-X_{n-1}$. Under the following assumptions (i) $\sigma_n \to \infty$ as $n\to\infty$, (ii) for any $\varepsilon >0$,
$\frac{1}{\sigma_n^2}\sum_{i=1}^n E\left( \Delta_i^2\mathbb{1}_{\{|\Delta_i| \ge \varepsilon \sigma_n \}}\right) \to 0 \text{ as } n\to\infty$ . (iii) Define $G_n^2:= \sum_{i=1}^n E(\Delta_i^{2}\mid\mathcal{F}_{i-1})$, we have $ \sigma_n^{-2}G_n^2\to 1$ in Prob as $n\to\infty$. (iv) $\sup_n\sigma_n^{-2}G_n^2\le a<\infty$ a.s. Show that
$
\frac{X_n}{\sigma_n}\Rightarrow \text{N}(0,1)\text{ as } n\to\infty. $ I got a hint that using Lindeberg technique to prove $E\exp(i t \sigma_n^{-1}X_n + \frac12\sigma_n^{-2}G_n^2t^2) \to 1$ as $n\to\infty$ for all $t\in\mathbb R$. Is this one type of martingale CLT? How I can prove it under the assumption (i)-(iv)?","['stochastic-processes', 'probability-theory', 'statistics', 'probability', 'measure-theory']"
2758277,The nonexistence of a Jordan normal form over a finite field,"Since finite fields are not algebraically closed, this suggests to me that there may be matrices over finite fields whose characteristic polynomials don't split over that finite field, and thus do not have Jordan normal forms. As a simple example, is it the case that there exists a $3 \times 3$ matrix with entries from $\mathbb{F}_3$ that does not have a Jordan normal form? I'm wondering if I can just find a polynomial $f \in \mathbb{F}_3[x]$ that doesn't split in $\mathbb{F}_3[x]$ and then try to build a matrix whose characteristic polynomial is $f$, but I'm not sure that this is a feasible approach to constructing such a matrix.","['matrices', 'finite-fields', 'jordan-normal-form', 'linear-algebra']"
2758291,"if $|az^2+bz+c|\le 1$, find the maximum of $|a|+|b|$","Let $a,b,c$ be complex numbers, and $f(z)=az^2+bz+c$, such that if the complex number $|z|\le 1$, then we have $|f(z)|\le 1$. Find the maximum of $|a|+|b|$. if we $a,b,c$ be real and $z$ be real, I can find the maximum is $2$,because $f(z)=2z^2-1$ such  it. and
$$a=\dfrac{1}{2}[f(1)+f(-1)]-f(0),b=\dfrac{1}{2}[f(1)-f(-1)]$$
so
$$|a|+|b|=\dfrac{1}{2}|f(1)+f(-1)-2f(0)|+\dfrac{1}{2}|f(1)-f(-1)|\le 2$$But for complex, maybe this answer is also $2?$,I'm not sure.","['complex-analysis', 'inequality', 'contest-math']"
2758329,"Showing that if the limit of norms converges, then the sequence converges","Let $H$ be a hilbert space, and $C \subset H$ a convex set. Let $(x_n)_{n\in \mathbb{N}}$ be a sequence in $C$ with $\lim_{n\to \infty}||x_n|| = \inf_{x\in C}||x||$. Show $x_n$ converges in $H$. So far I have: Let $P_C(0) = \{x \in C: ||x|| = \inf_{x \in C}||x||\}$ be the projection of $0$ onto $C$. If we consider $\bar{C}$ (the closure of $C$), then there is a theorem that tells us since $\bar{C}$ is closed and convex, there is exactly one $y \in \bar{C}$ with $y=P_{\bar{C}}(0)$, i.e., $||y|| = \inf_{x\in \bar{C}}||x||$. Since the infimum of a set's closure equals the infimum of the set, we also have $||y|| = \inf_{x\in C} ||x||$. Now, I need to show that since the norms converge to the norm of a unique element ($y$), the sequence itself must converge to this element. This makes sense intuitively, but I can't make it rigorous! Any hints would be appreciated.","['functional-analysis', 'convergence-divergence', 'hilbert-spaces']"
2758362,Formulating a function $f$ such that $\nabla f = F$,"Example:
Let $F = (2xy)i+(x^2-\cos{z})j+(y\sin{z})k$. Find a function $f$ so that $\nabla f=F$. I understand that I can essentially go backwards and determine a solution from guesswork. My question is, what is a more systematic process that can be followed to get to the same solution? Thanks!",['multivariable-calculus']
2758364,The Jacobson radical of polynomial ring,"Let $R$ be a commutative ring with $1$ and $R[x]$ be the polynomial ring over $R$. We know that the Jacobson radical $J(R[x] )$ of  $R[x]$ is the intersection of all maximal ideals of $R[x]$. Now let $M$ be a fixed (but arbitrary) maximal ideal of $R[x]$. How can we show that $J(R[x])=\cap_{M\not=N\in \mathrm{Max}(R[x])}N$, where $\mathrm{Max}(R[x])$ is the set of all maximal ideals of $R[x]$?","['maximal-and-prime-ideals', 'algebraic-geometry', 'commutative-algebra']"
2758368,Is there a well defined difference between $\nabla$ and $D$?,"When we apply $\nabla$ or $D$ to a function $f:\mathbb R^n\to \mathbb R$, then they in principle do the same operation. However, in textbooks $\nabla$ is often written as a column vector $(\partial_1,...,\partial_n)^T$, whereas $D$ is written as a row vector $(\partial_1,...,\partial_n)$. Is there a well defined difference between these two operators when they are applied to a single-valued real function?",['derivatives']
2758372,Let $x_1=a>0$ and $x_{n+1}=x_n+\frac{1}{x_n} \forall n\in \mathbb N$. Check whether the following sequence converges or diverges.,"Let $x_1=a>0$ and $x_{n+1}=x_n+\frac{1}{x_n} \forall n\in \mathbb N$ .
  Check whether the following sequence converges or diverges. When I was in UG my teacher used derivative test for monotonicity. $f(x)=x+\frac{1}{x}, f'(x)=1-\frac{1}{x^2}>0(x>1).$ So, $f(x)$ is increasing. How to prove the sequence is monotonic? Differentiation is coming after the sequences and series. By AM-GM inequality sequence is bounded below. $x_{n+1}=x_n+\frac{1}{x_n}\ge 2\sqrt{x_n.\frac{1}{x_n}}=2  \forall n\in \mathbb N$ . How can I judge whether the sequence bounded above or not? Please help me.","['real-analysis', 'sequences-and-series']"
2758388,Is there any known explicit value of dimension of space of Maass forms?,"It is known that there exists a simple formula of the dimension of space of (holomorphic) modular forms on $\mathrm{SL}_{2}(\mathbb{Z})$ in terms of its weight. Also, we have similar but rather complicated formula for the case of congruence subgroups. (I heard that there is an algorithm that computes these dimensions, right?) However, we don't know much about dimension of Maass forms. As I know, it is widely conjectured that dimension of the space of Maass cusp forms on $\mathrm{SL}_{2}(\mathbb{Z})$ with given eigenvalue is 0 or 1. Also, as we can see in this post and answers , it seems that there are some known upper bounds of dimension of level $q$ Maass wave forms in terms of $q$. 
Is there any concrete example that computes the exact value of dimensions?","['number-theory', 'automorphic-forms']"
2758418,"Deriving the power series for cosine, using basic geometry","Looking for the derivation of cosine lead to https://www.quora.com/How-do-I-calculate-cos-sine-etc-without-a-calculator and the MacLauren series . $$\cos(x)=1−\frac{x^2}{2!}+\frac{x^4}{4!}−\frac{x^6}{6!}+\dotsc$$ Wondering if one could show how the cosine series function is derived, starting from basic geometry. Looking at that equation above, I'm not sure where the numbers and variables came from. Note, I am hoping for a derivation starting with ""A triangle has 3 sides"", super simple, not from the Taylor series or idea of derivatives which already has a lot of context (but I would like to see derivatives and Taylor series in the process). I would like to see the connections from: basic geometry $\to$ stuff stuff $\to$ taylor series taylor series $\to$ stuff stuff $\to$ cosine power series","['trigonometry', 'geometry']"
2758428,Quotient ring being isomorphic to the initial ring,"This may be a very basic question. Let $R$ be a commutative ring with unity (may be assumed to be an integral domain, if necessary) and $I$ be an ideal of $R$ . Assume that $R/I$ is isomorphic to $R$ . Does this mean $I=(0)$ ?","['abstract-algebra', 'ring-theory']"
2758463,What is the use of Null Space?,"This answer explains what is null space very effectively. In brief Null Space is the set of vectors which have 0 effect on the system when applied. So, what is the use of finding null-space? Is it just that it gives us what not to use and whether the matrix is invertible or not or is there a better use for null space? May be something like, ""we know adding null-space-vectors won't change the system but improves the stability of the system?"" (I'm just guessing) Any practical examples (like the ones given in the answer referred) are greatly appreciated. Theoretical ones will also be helpful. Thanks","['examples-counterexamples', 'linear-algebra', 'vector-spaces']"
2758473,Reference Request: Equivariant cup product in singular cohomology,"I've been looking around for a standard treatment of what I think sould be called ""equivariant cup product in singular cohomology"", but couldn't find anything promissing. I did played around with what I expect this to be, so maybe you can tell me whether (a) this is known and written out somewhere (idealy in some axiomatic way), or (b) this is the right way to define the cup product in this setting. So  let's get started: Consider an oriented finite dimensional smooth Riemannian manifold $(M,g)$ together with a regular covering map $$\pi \colon \tilde{M} \to M,$$ where $\tilde{M}$ is equipped with the pullback metric $\tilde{g}:=\pi^*g$. Let us assume that the group of deck transformations $\Gamma$ is isomorphic to $\mathbb{Z}^k$, for some $k$ positive integer. Then we can define the cochain complex $$\left(S^{\bullet}(\tilde{M};\mathbb{Z}) \otimes_{\mathbb{Z}[\Gamma]}N, \delta \otimes \text{id}\right),$$ where $\mathbb{Z}[\Gamma]$ is the group ring w.r.t. $\Gamma$ and $N$ is some module over this group ring (note that we don't have to specify left and right actions, for $\mathbb{Z}[\Gamma]$ is commutative). $S^{\bullet}$ obviously denotes singular cohomology. My idea now was to define a ""cochain cup product"" on this chain complex as follows: $$\cup \colon \left(S^p(\tilde{M};\mathbb{Z})\otimes_{\mathbb{Z}[\Gamma]}N\right) \otimes_{\mathbb{Z}[\Gamma]}\left(S^q(\tilde{M};\mathbb{Z})\otimes_{\mathbb{Z}[\Gamma]}N\right) \longrightarrow S^{p+q}(\tilde{M};\mathbb{Z})\otimes_{\mathbb{Z}[\Gamma]}\left(N\otimes_{\mathbb{Z}[\Gamma]}N\right),$$ where $$(\varphi  \otimes n_1)\cup (\psi \otimes n_2):=(\varphi \cup \psi) \otimes (n_1\otimes n_2)$$ and the cup on the RHS is the usual cup product in singular cohomlogy. Note that lots of the assumption I made are superfluous or could be phrased more generally, but this is more or less the setting I'm working with (maybe it turns out that in this setting some complications become trivial and so on...). And $\mathbb{Z}_2$ coefficients are sufficient for what I need (maybe this also makes things easier as $\mathbb{Z}_2$ is a field). Every helpful comment is greatly appreciated, thank you! EDIT 1: It seems that my guess was incorrect. In Eilenberg and Steenrod's ""Foundations of Algebraic Topology"" on page 209 there is a definition of equivariant homology AND cohomology. Applying this general definition to our special case gives us the following equivariant cochain complex $$\left(\hom_{\mathbb{Z}[\Gamma]}\left(S_{\bullet}(\tilde{M};\mathbb{Z}),N\right),\delta\right).$$ Also, they claim in the book that equivariant homology/cohomology is a homology theory (where everything is equivariant, roughly speaking). So maybe understanding the corresponding Eilenberg-Zilber morphism and the induced map coming from the diagonal embedding (or more generally any diagonal approximation) migth lead to an answer... EDIT 2: I found some more papers by Eilenberg and by Steenrod. Eilenberg gives a definition of an equivariant cup product in equivariant singular cohomology (see ""Homology of Spaces with Operators""), but he uses an extra assumption that ensures that the cup product of two equivariant cochains is an equivariant cochain again. This assumption however, does not hold in my setting (if I understand correctly). The paper by Steenrod ""Homology with Local Coefficients"" gives a definition using a CW-decomposition and cellular homology, which seems too far away from what I possibly want.","['reference-request', 'abstract-algebra', 'algebraic-topology', 'general-topology', 'differential-geometry']"
2758488,Using Norms to Determine Factorisations in the Gaussian Integers,"In the set $\mathbb{Z}[i]:=\{a+bi:a,b\in\mathbb{Z}\}$ of Gaussian Integers, we define the norm to be $N:\mathbb{Z}[i]\to\mathbb{Z}$ by
$$
N(\alpha)=\alpha\alpha^*=a^2+b^2,\ \forall\alpha=a+bi\in\mathbb{Z}[i].
$$
We then use this to determine factorisations of Gaussian integers. Since if $\alpha\mid\beta$ in $\mathbb{Z}[i]$, then $N(\alpha)\mid N(\beta)$ in $\mathbb{Z}$. Further, we know that if $\eta$ is a highest common factor of $\alpha$ and $\beta$ in $\mathbb{Z}[i]$, and $h$ is a highest common factor of $N(\alpha)$ and $N(\beta)$ in $\mathbb{Z}$, it follows that $N(\eta)\mid h$. My question is this: When does $N(\eta)\neq h$? Is it possible to characterise such a case in terms of a prime factorisation? I feel as though this is related to Fermat's theorem regarding the parity of the exponents of primes $q\equiv 3 \pmod 4$, i.e. an integer $n$ is a sum of squares (and therefore a norm of a Gaussian integer) iff in a prime factorisation
$$
n=2^{a_0}p_1^{a_1}\dotsm p_r^{a_r}q_1^{b_1}\dotsm q_s^{b_s} \qquad (*)$$
where $p_i\equiv 1\pmod 4,\  q_i\equiv 3\pmod 4$ are prime and $a_i,b_i\in\mathbb{Z},\ \forall i$, has that all $b_i$ are even, but I've struggled to relate the two. Thanks in advance. Edit: I've been trying to construct examples with some level of difficulty, and I'll share my attempts here. First of all, we know that since $N(\eta)\mid h$ and $N(\eta)\neq h$, we must have that $h\neq 1$. Then $N(\alpha)$ and $N(\beta)$ must not be coprime. Further, for such Gaussian integers to exist, they must have the form of $(*)$. Then pick primes congruent to $1\bmod 4$, $\ p_1,p_2,p_3,p_4$ (or equivalently, take primes congruent to $3\bmod 4$, but square them) and let
$$
N(\alpha)=p_1p_2p_3, \quad N(\beta)=p_1p_2p_4.
$$
Then $h=p_1p_2$, and we may have $N(\eta)=p_1$ or $N(\eta)=p_2$, in particular, $N(\eta)\neq h$. Does this seem to be a reasonable method? Or is there some easier way.","['number-theory', 'prime-numbers', 'algebraic-number-theory']"
2758491,The group cohomology of the character group,"Let  $G$ be  an abelian group and $M$  be  a  $G$-module. The  group of complex  valued  characters  of  $M$  is  denoted  by $\widehat M$. There is  an obvious  $G$-module  structure  on $\widehat M$. Is there any relation between group cohomologies $H^n(G,M)$ and  $H^n(G,\widehat M)$?","['group-cohomology', 'group-theory', 'characters']"
2758492,Evaluating $\int \sqrt{\frac{\cos x - \cos^3 x}{1-\cos^3 x}}dx$,Evaluate $\int \sqrt{\frac{\cos x - \cos^3 x}{1-\cos^3 x}}dx$ My attempt : $I=\int \sqrt{\frac{\cos x - \cos^3 x}{1-\cos^3 x}}dx=\int \sqrt{\frac{\cos x(1-\cos^2 x)}{1-\cos^3 x}}dx=\int \sqrt{\frac{\cos x\sin^2 x}{1-\cos^3 x}}dx=\int \sin x\sqrt{\frac{\cos x}{1-\cos^3 x}}dx=\int\sqrt{\frac{\cos x}{1-\cos^3 x}}(\sin x)dx=-\int \sqrt{\frac{\cos x}{1-\cos^3 x}}(-\sin x)dx$ Let $z=\cos x$ $\therefore dz=(-\sin x)dx$ $\therefore I=-\int\sqrt{\frac{z}{1-z^3}}dz$ I cannot understand how to proceed further. Please help.,"['indefinite-integrals', 'integration', 'calculus']"
2758508,The Poissonian PDF tends to a Gaussian for $\lambda\rightarrow\infty$,"I found an argument for the title in this question , using the Stirling approximation and defining $x=\lambda-k$,
$$   \frac{\lambda^k}{k!}e^{-\lambda}=\frac{\lambda^{\lambda-x}e^{-\lambda}}{(\lambda-x)!}
   \approx \frac{e^{-\lambda}\lambda^{\lambda-x}}{(\lambda -x)^{\lambda -x} e^{-(\lambda -x)} \sqrt{2\pi (\lambda -x)} } =\\
   = \frac{e^{-x}}{\sqrt{2\pi}} \frac{\lambda^{\lambda-x}}{(\lambda -x)^{\lambda -x}} (\lambda -x)^{-\frac{1}{2}}=\\
   = \frac{e^{-x}}{\sqrt{2\pi}} (\lambda -x)^{-\frac{1}{2}} \left(\left(1-\frac{1}{\lambda /x}\right)^{\lambda /x}\right)^{\frac{x^2-\lambda x}{\lambda}}\approx\frac{1}{\sqrt{2\pi\lambda}}e^{-\frac{(k-\lambda)^2}{\lambda}}$$
as $\lambda\rightarrow\infty$.
The problem is that the final pdf at which they arrive isn't normalized in reason of the missing factor of 2 in the denominator inside the exponential. I can't see where that factor is lost, any help?","['probability-theory', 'poisson-distribution', 'statistics', 'normal-distribution']"
2758510,Derivative of $\mathrm{tr}(X^\top A) A$,"Let A be a constant matrix. Define
$$
Y:= \mathrm{tr}(X^\top A) A
$$ I want to find
\begin{align}
\frac{\partial Y}{\partial X} \label{A}
\end{align} I know that 
$$
\frac{\partial\,\mathrm{tr}(X^\top A)}{\partial X} = A \label{B}
$$ Of course, I should be able to extend this to the case I want. But I am a bit confused as to how I should notate the result. What I did to find \eqref{A} was to vectorize both sides and then use the fact in \eqref{B}. $$
\mathrm{vec(Y)} = \mathrm{tr}(X^\top A)\mathrm{vec}(A)
$$ I also knwo that I can write 
$$
\mathrm{tr}(X^\top A) = \mathrm{vec}(A)^\top \mathrm{vec}(X)
$$ 
So the desired the derivative should be
$$
\mathrm{vec}(A) \otimes \mathrm{vec}(A)
$$
Is this correct?.","['matrices', 'matrix-calculus', 'derivatives']"
2758516,Find recurrence for $I_n$.,Let $I_n=\int_{0}^{1/2} \frac {x^n}{\sqrt{1-x^2}}dx.$ I must find a recurrence for this so I just started using interation by parts: Let $$f'(x)=x^n\to f(x)=\frac{x^{n+1}}{n+1}$$ and $$g(x)=\frac 1{\sqrt{1-x^2}}\to g'(x)=\frac x{\sqrt{(1-x^2)^3}}$$ Therefore: $$I_n=\frac {x^{n+1}}{(n+1)\sqrt{1-x^2}} - \int_{0}^{\frac 12}\frac{x^{n+2}}{(1-x^2)\sqrt{1-x^2}}dx$$ And I can't continue from here.. I tried rewriting $x^{n+2}=x^2x^n=(1-x^2+1)x^n$ but it's no good.,"['recurrence-relations', 'integration', 'calculus']"
2758525,Exchange a limit with a $\limsup$ or $\liminf$,"Let $f_{n}:\,\mathbb{R}\rightarrow\mathbb{R}$ a sequence of $C^{1}\left(\mathbb{R}\right)$ functions such that $$\left|f_{n}\left(x\right)\right|\leq M,\ \forall x\in\mathbb{R},\,\forall n\in\mathbb{N}$$and assume that $$\lim_{n\rightarrow\infty}f_{n}\left(x\right)=f\left(x\right)$$ for all $x$ in $\mathbb{R}$. Can I conclude that $$\lim_{n\rightarrow\infty}\limsup_{h\rightarrow0}\frac{f_{n}\left(x+h\right)-f_{n}\left(x\right)}{h}=\limsup_{h\rightarrow0}\lim_{n\rightarrow\infty}\frac{f_{n}\left(x+h\right)-f_{n}\left(x\right)}{h}$$ $$=\limsup_{h\rightarrow0}\frac{f\left(x+h\right)-f\left(x\right)}{h}?$$ I know that there are some theorems that allow to switch two limits, like the dominated convergence theorem, but what can I say in this situation? I have not more information about these functions. Note that I'm interested also in the case that the limit is not convergent. In other words: is it true that $$\lim_{n\rightarrow\infty}\limsup_{h\rightarrow0}\frac{f_{n}\left(x+h\right)-f_{n}\left(x\right)}{h}=L\Leftrightarrow\limsup_{h\rightarrow0}\frac{f\left(x+h\right)-f\left(x\right)}{h}=L,\,L\in\mathbb{R}$$ or $$\lim_{n\rightarrow\infty}\limsup_{h\rightarrow0}\frac{f_{n}\left(x+h\right)-f_{n}\left(x\right)}{h}\text{ does not exist}\Leftrightarrow\limsup_{h\rightarrow0}\frac{f\left(x+h\right)-f\left(x\right)}{h}\text{ does not exist}$$ or $$\lim_{n\rightarrow\infty}\limsup_{h\rightarrow0}\frac{f_{n}\left(x+h\right)-f_{n}\left(x\right)}{h}=\infty\,(-\infty)\Leftrightarrow\limsup_{h\rightarrow0}\frac{f\left(x+h\right)-f\left(x\right)}{h}=\infty\,(-\infty)?$$","['real-analysis', 'limsup-and-liminf', 'calculus', 'limits']"
2758532,Multivariable Calculus surface integral over a square,"Thanks for any help in advance. I'm currently working on a question which is as follows: Find the area of the part of the sphere of radius a at the origin which is above the square in the (x,y) plane bounded by:
$$
 x = \frac{a}{\sqrt{2}} , 
x = -\frac{a}{\sqrt{2}} ,
y = \frac{a}{\sqrt{2}} ,
y = -\frac{a}{\sqrt{2}}
$$ Hint for evaluating the integral: change to polar coordinates and evaluate the $r$ integral first. I have found the surface element in terms of spherical polar coordinates, $a^2\sin\theta$, where $\theta$ is the angle from the $z$ axis, but i am having difficulty projecting it onto the square in the $(x,y)$ plane which does not agree with spherical coordinates.",['multivariable-calculus']
2758545,Show that a linear projection is continuous if it is continuous in 0,"Here is a perfectly fine answer to the question: Linear functional $f$ is continuous at $x_0=0$ if and only if $f$ is continuous $\forall x\in X$? However, I am in a set and topology course and my professor proved this using sequences.
I am going over the proof and am unsure of one step. Let X with $\lVert{X}\rVert$ and Y with $\lVert{Y}\rVert$ be normed vector spaces(Over ${\rm I\!R}$). Let T: X -> Y be a linear projection. Show that if T is continuous in $\overline{0}$ it is continuous*. Solution: Let a $\in$ X. Let $x_{n}$ -> a. $x_{n}$ - a -> $\overline{0}$ $\quad$ Because X is a vector space and $x_{n}$ converges to a. T($x_{n}$ - a) -> $\overline{0}$ $\quad$ ** T($x_{n}$) - T(a) -> $\overline{0}$ $\quad$ b/c T is a linear projection T($x_{n}$) -> T(a) $\quad$ Which implies T is continuous in a. *In every point I suppose ** Why is this ok? Is there some clever rule I'm missing? /Regards","['limits', 'normed-spaces', 'continuity', 'linear-transformations', 'general-topology']"
2758562,What causes a set of functions to form a group under composition?,"In my textbook the following functions are given and are said to form a group under composition: $f_1(x) = x$,
  $f_2(x) = \frac{1}{x}$,
  $f_3(x) = 1-x$,
  $f_4(x) = \frac{1}{1-x}$,
  $f_5(x) = \frac{x-1}{x}$,
  $f_6(x) = \frac{x}{x-1}$ As I understand it, composition means simplifying all possibilities of $f_n(f_m(x))$, and then testing for the group checks. I understand that they form a group due to the fact that they satisfy the four axioms (closure, associativity, identity, inverse), but wish to understand exactly what about the functions causes this. The best way I can put this is, if you needed to create another set, where would you start? I assume $f_1(x)$ is the only possible Identity Element for composition of functions, is there something else about the given functions that cause them to form a group? As of now, this is all I notice: $f_1(x)^{-1} = f_2(x), f_3(x)^{-1}=f_4(x),f_5(x)^{-1}=f_6(x)$","['function-and-relation-composition', 'group-theory', 'functions']"
2758588,"Problem in the ""proof"" of Eisenstein's criterion on irreducibility.","I have a problem about a line inside the following proof which is actually from the book Abstract Algebra by Dummit & Foote Proposition (Eisenstein's Criterion) . Let $P$ be a prime ideal in the integral domain $R$ and let $~f(x)=x^n+a_{n-1}x^{n-1}+\dots +a_0$ be a polynomial in $R[x]$ $(n\ge1)$. Suppose $a_{n-1},\dots ,a_0$ are all elements of $P$ and $a_0$ is not an element of $P^2$. Then $f(x)$ is irreducible. Proof. Suppose $f(x)$ is reducible, say $f(x)=a(x)b(x)$ in $R[x]$, where $a(x),b(x)$ are non-constant polynomials. Reducing this equation modulo $P$ and using the assumptions on the coefficients of $f(x)$ we obtain the equation $x^n=\overline{a(x)b(x)}$ in $(R/P)[x]$, where bar denotes the polynomials with coefficients reduced mod $P$. Since $P$ is prime ideal, $R/P$ is an integral domain, and it follows that both of $\overline{a(x)}$ and $\overline{b(x)}$ have $0$ constant term , i.e, the constant term of both $a(x)$ and $b(x)$ are elements of $P$. But then constant term of $a_0$ of $~f(x)$ as the product of these two would be an element of $P^2$, a contradiction. This completes the proof. But I cannot understand the line which I have bold in the proof. What I understand is that since $x^n=\overline{a(x)b(x)}$, so comparing the coefficients on both sides we get the product of the constant terms of $~\overline{a(x)}$ and $~\overline{b(x)}$ is zero in $(R/P)[x]$, which is a Integral domain.....then either the constant term of $~\overline{a(x)}=0$ or constant term of $~\overline{b(x)}=0$...But how does both of them is zero? Please help.","['irreducible-polynomials', 'abstract-algebra', 'ring-theory']"
2758593,Show that the following space curve $c$ is $C^{\infty}$ and Compute binormal.,"Consider the space curve $c : (-\frac{1}{2},\frac{1}{2}) \rightarrow \mathbb{R^3}$
, $$c(x)= \begin{cases}
(x,e^{-\frac{1}{x^2}},0) 
&\ x<0\\ \ \\ (0,0,0)&\ x=0 \\ \ \\ (x,0,e^{-\frac{1}{x^2}}) &\ x>0
\end{cases} $$ Show: $\cdot$ $c$ is a regular $C^{\infty}$  curve and $ \kappa: (-\frac{1}{2},\frac{1}{2}) $ $\rightarrow \mathbb{R_{\geq 0}}$ a $C^{\infty}$ function. $\cdot$ $B(x) =(0,0,1)$ for $x < 0$ and $B(x) = (0,-1,0)$ for $x>0$ . $\kappa$ = curvature with $\kappa(x)$ := $\frac{|| c' \times c''||(x)}{||c'(x)||^3} $. $B$ = binormal with $B(x)$ := $T(x) \times N(x)$ $\tau$ = torsion with $\tau(x)$ := $\frac{det(c',c'',c''')(x)}{|| c' \times c''||^2(x)} $ $T(x)$ := $\frac{1}{||c'(x)||} \cdot c'(x) $. $N(x)$ := $\frac{1}{||T'(x)||} \cdot T'(x) $. My thoughts : a curve is regular, if $|| c'(x) || \neq 0$. $$c'(x)= \begin{cases}
(1,\frac{2}{x^3}e^{-\frac{1}{x^2}},0) 
&\ x<0\\ \ \\ (1,0,0)&\ x=0 \\ \ \\ (1,0,\frac{2}{x^3}e^{-\frac{1}{x^2}}) &\ x>0
\end{cases} $$  Do I have a mistake here?
Next point: It's clear to me that $c$ is a $C^{\infty}$ function for $x \neq 0$, but I have problems with $x=0$. Next point: for the curvature we need $c''$.$$c''(x)= \begin{cases}
(0,-\frac{(6x^2-4)}{x^6}e^{-\frac{1}{x^2}},0) 
&\ x<0\\ \ \\ (0,0,0)&\ x=0 \\ \ \\ (0,0,-\frac{(6x^2-4)}{x^6}e^{-\frac{1}{x^2}}) &\ x>0
\end{cases} $$ $$\kappa(x) \begin{cases}
\frac{|\frac{(6x^2-4)}{x^6}e^{-\frac{1}{x^2}}|}{(1+(\frac{2}{x^3} e^{-\frac{1}{x^2}})^2)^{\frac{3}{2}}}
&\ x<0\\ \ \\ 0&\ x=0 \\ \ \\ \frac{|\frac{(6x^2-4)}{x^6}e^{-\frac{1}{x^2}}|}{(1+(\frac{2}{x^3} e^{-\frac{1}{x^2}})^2)^{\frac{3}{2}}} &\ x>0
\end{cases} $$ I know that my result looks terrible. I really need help here. Is there a trick?  How can I solve the other claims? I mean how can I solve them, if my results looks so terrible.","['derivatives', 'curves', 'differential-geometry', 'curvature']"
2758622,A linear map from matrices to matrices,"Let $M_n(k)$ denote the set of matrices over the field $k$, which could be viewed as a linear space of dimension $n^2$. Suppose $\varphi: M_n(k) \rightarrow M_n(k)$ is a nonzero linear map such that
$$ \forall A, B \in M_n(k):~\varphi(AB) = \varphi(A) \varphi(B).$$ 
How to prove that there exists a nonsingular matrix $C \in GL_n(k)$ with $$\forall A \in M_n(k):~\varphi(A) = CAC^{-1}?$$","['matrices', 'linear-algebra']"
2758665,How do we define $D^2$ formally in differential geometry?,"In this question @barto explains the definition of $Df|_p$ in differential geometry. This question is about the formal definition of $D^2f|_p$, given a function $f:M\to \mathbb R$ for some manifold $M$. Given that $Df_p$ gives us a mapping from the tangent space of $f$ at $p\in M$ to $\mathbb R$, we can state that $D$ is a map $(M\to \mathbb R)\times M \to (T(M)\to \mathbb R)$, where $T(M)$ is the union of tangent spaces on $M$ at all points. (I am not sure if the way I defined this is correct now.) My question is, is $D^2$ defined rigorously as an operator? By $D^2$ I mean the operator that takes $f:M\to\mathbb R$, $p\in M$, such that $D^2f|_p=D(Df|_p)$. Basically, $D^2$ should map $f$ and $p$ to a linear operator that is represented by the Hessian matrix .","['hessian-matrix', 'notation', 'differential-geometry']"
2758673,How to solve the following system : $ \begin{cases} \ \ \ ab^2 = 2 \\ a+b = -1 \end{cases} $?,"Could you explain to me please, how to solve the following system of $ 2 $ equations in $ \mathbb{R} $ or $ \mathbb{C} $ :
$$ \begin{cases} \ \ \ ab^2 = 2 \\ a+b = -1 \end{cases} $$
According to my opinion, this system seems to correspond to a system in the form :
$$ \begin{cases} \ \ \ ab = 2 \\ a+b = -1 \end{cases} $$
which we can solve by solving the following equation of second degree : $ x^2 + x + 2 = 0 $ But here, there is a number in exponent of $ b$ : $ 2 $ in $ ab^2 = 2 $, which doesn't help me to solve the system. Can you help me please ? Thank you.","['algebra-precalculus', 'polynomials', 'systems-of-equations']"
2758675,The probability that the quadratic equation has real roots,"I have this problem on which I would appreciate some help. ""Consider the quadratic equation $x^2 + Bx + C = 0$ where $B$ and $C$
  are independent and are uniformly distributed on $[-n,n]$. Find the
  probability that the equation has real roots. What happens as $n
> \longrightarrow \infty $?"" So, my attempt goes like this. First note that since their uniformly distributed on $[-n,n]$ we know that $f_B(x) = 1/2n$ and $F_C = \frac{x+n}{2n}$. Obviously, we are looking for $P(C\leqq(B/2)^2)$. Now, if we condition on $B=x$ we can use the law of total probability $P(C\leqq(B/2)^2)=\displaystyle \int_{-\infty}^{\infty} P(C\leqq(B/2)^2 | B=x)f_B(x)dx=\displaystyle \int_{-\infty}^{\infty} P(C\leqq(x/2)^2 | B=x)f_B(x)dx$ which is equal to $\displaystyle \int_{-\infty}^{\infty} P(C\leqq(x/2)^2)f_B(x)dx = \int_{-\infty}^{\infty} F_C((x/2)^2)f_B(x)dx$ because of their independence. Thus, $P(C\leqq(B/2)^2) = \frac{1}{4n^2}\displaystyle \int_{-\infty}^{\infty} (\frac{x}{2})^2 + n dx$ and because we know that $x \in [-n,n]$ we get $P(C\leqq(B/2)^2) = \frac{1}{4n^2}\displaystyle \int_{-n}^{n} (\frac{x}{2})^2 + n dx$ which evaluates to $\frac{n}{24} + \frac{1}{2}$. However, my text book says that the right answer is $\frac{n}{24} + \frac{1}{2}$ for $n\leqq 4$ and $1-2/(3\sqrt{n})$ for $n \geqq 4$. What am I doing wrong in my solution above? Clearly I must do something right, because I get partially the right answer. Any ideas?
Thanks!","['probability-theory', 'probability', 'random-variables']"
2758687,Holomorphicity of the square of a function,"I am trying to figure out whether the following statement is true. If $f$ is such that $f^2$ is holomorphic on an open set $\Omega \subset \mathbb{C}$ then $f$ itself is holomorphic on $\Omega$. My feeling would be that since the function mapping $z$ to $\sqrt{z}$ is multivalued that this should not be the case, but I am struggling to come up with a counterexample.","['complex-analysis', 'holomorphic-functions', 'examples-counterexamples']"
2758707,Interchanging limits in a special case,"In general, one may not interchange limits (eg, $\lim_k f_k(\lim_n x_n)\neq \lim_n\lim_k f_k(x_n)$ in most cases) without requiring that the family $\{f_k\}$ is uniformly continuous. However, can you help me in the following situation? Let $X$ be a compact metric space (think unit interval $[0,1]$ if you prefer), with $f:X\rightarrow X$ a homeomorphism (so, 1-1 continuous with continuous inverse). We do not know that the family $\{f^n\}_{n\in\mathbb{Z}}$ is uniformly continuous, but we do know that there is a convergent sequence $\{f^{k'}\}$ (where by convergent we mean pointwise convergent) and that there is also a convergent sequence $\{f^{n'}(x)\}$ (where here convergence is of a sequence of points in $X$ with its compact metric topology). Are we allowed to do the following:
$$
\lim_{k'\rightarrow +\infty} f^{k'}(\lim_{n'\rightarrow+\infty}f^{n'}(x))=\lim_{n'\rightarrow+\infty}\lim_{k'\rightarrow+\infty} f^{k'+n'}(x)= \lim_{n'\rightarrow +\infty} f^{n'}(\lim_{k'\rightarrow+\infty}f^{k'}(x))
$$ I think the answer is 'no', but a counterexmple would be useful. I've also looked at this question , but it's not quite what I'm looking for. Thanks!","['limits', 'calculus', 'analysis']"
2758751,Covariance between Wiener process and stochastic integral,"I want to calculate $cov($$w_t$ , $\int_0^{t}s^{n}dw_s)$ .
I have tried integration by parts:
$$\int_0^{t}s^{n}dw_s = t^{n}w_{t} - n\int_{0}^{t}s^{n-1}w_sds$$ Further, I think to use this formula $n$ times, but I can't do it on this step. My idea was to get the equation at the end that will contain next components (maybe with some coefficients): $\int_0^{t}sdw_s$, $\int_0^tw_sds$, $w_t$ and the component that if I count a mathematical expactation from it I will get the $cov($$w_t$, $\int_0^{t}s^{n}dw_s)$ (the mathemetical expectation for the first three components I know). And from this equation I would count the covariance, but I can't understand how I can continue. I'll be happy for any idea.","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'brownian-motion', 'stochastic-calculus']"
2758773,Given certain conditions show $f'''(x)\ge3$,"Suppose $f$ is a real valued continuous function defined on $[-2,2]$ and is the times differentiable in $(-2,2)$. If $f(2)=-f(-2)=4$ and $f'(0)=0$ then show there exists $x\in(-2,2)$ such that $f'''(x)\ge3$. I have tried using MVT to no avail. Tried to back calculate assuming $f'''(x)\ge3$ and then integrating. Couldn't do it.","['real-analysis', 'functions']"
2758777,Determine order of approximation for the finite difference method,"I try to solve the following task. It is given a finite difference:
        $$g(x)=f'(x)\approx\frac{f(x+h)-f(x)}{h}$$
        $$g'(x)\approx\frac{g(x)-g(x-h)}{h}\approx\frac{\frac{f(x+h)-f(x)}{h}\;-\;\frac{f(x)-f(x-h)}{h}}{h}$$
        $$\iff g'(x)\approx\frac{f(x+h)-2f(x)+f(x-h)}{h^2}\approx f''(x)$$
I shall determine the order of approximation of $f''$ depending on Big-O. The order of approximation should say something about the quality of the approximation (size of the possible error?). There wasn't much explanation in the lecture so I am not sure. But they want us to give the order of approximation depending on $\mathcal(O)$ (Landau symbol). (Definition of Big-O is clear) On our frames is only a barely explained example in which something with Taylor Expansions is done. Still without further explanations it is hard for me to understand what I have to do... I really hope for your help - please explain very detailed because I am a computer scientist and not a mathematician and could probably missing some more in detail information about certain subjects.","['derivatives', 'finite-differences', 'computational-complexity', 'approximation']"
2758809,Probability that the experiment was performed using given die,"I have coin $A$ and coin $B$, and probabilities of obtaining heads are 
$\theta_A=0.79$ for coin $A$ and $\theta_B=0.58$ for coin $B$. Given that the result of the experiment of $10$ tosses of one of the two coin was $HTTHHHTTHT$ which coin is more likely to produce it. I have met this problem when taking expectation maximisation module. I am really struggling to understand how to use empirical observation to calculate the chances of using each die.","['statistics', 'probability']"
2758866,Heat equation - solving with Laplace transform,"Question The temperature profile $\theta(x, t)$  in a semi-infinite rod obeys the heat
diffusion equation $$
\frac{\partial }{\partial t} \theta(x, t) = 
\frac{\partial^2}{\partial x^2} \theta(x, t)
$$ With initial temperature distribution $\theta(x) = T_0$ At $t=0$, the temperature at the left end of the rod is changed instantaneously
to $\theta(0, t) = 0$  and kept at this temperature for all $t > 0$. Use the
Laplace transform method with respect to $t$  to find the solution to the
differential equation. Working The laplace of the left hand side : \begin{equation}
  \begin{aligned}
    L\left(
      \frac{\partial }{\partial t} \theta(x, t) 
    \right)
    &= s \Theta(x, s) - \theta(x, 0) \\
    &= s \Theta(x, s) - T_0
  \end{aligned}
\end{equation} And of the right hand side : \begin{equation}
  \begin{aligned}
    L\left(
      \frac{\partial^2}{\partial x^2} \theta(x, t)
    \right) 
    = \frac{\partial^2}{\partial x^2} \Theta(x, s)
  \end{aligned}
\end{equation} Which gives \begin{equation}
  \begin{aligned}
    s \Theta(x, s) - T_0
    &=
    \frac{\partial^2}{\partial x^2} \Theta(x, s)
    \\
    \frac{\partial^2}{\partial x^2} \Theta(x, s) - s \Theta(x, s) &= T_0 \\
    \frac{\partial^2 \Theta}{\partial x^2}  - s \Theta &= T_0
  \end{aligned}
\end{equation} I'm a bit unsure how to proceed from here though, in terms of what I can do to solve this. What I'm considering is \begin{equation}
  \begin{aligned}
    \Theta'' - s\Theta = T_0
  \end{aligned}
\end{equation} Then this has the particular integral of \begin{equation}
  \begin{aligned}
    \Theta'' - s\Theta = 0
  \end{aligned}
\end{equation} With auxiliary equation \begin{equation}
  \begin{aligned}
    m^2 - s & = 0 \\
    m &= \pm \sqrt{s}
  \end{aligned}
\end{equation} And from here this is solved by considering cases for $s$ , those being
$s<0,s=0,s>0$. For $s<0$, $m$ is imaginary and the solution for $\Theta$ is \begin{equation}
  \begin{aligned}
    \Theta &= c_1 \cos(\sqrt{s}x) + c_2 \sin(\sqrt{s}x)
  \end{aligned}
\end{equation} But this must be wrong as I've not considered any separation of variables. I'm unsure how to proceed, and whether what I've done is valid. Posts I've viewed Solving Heat Equation with Laplace Transform , I didn't really follow some of the notation here, such as: I am setting $\mathcal{L}_t(u(x,t)) = U(x,s)|_s$ $\mathcal{L}(u'')=\mathcal{L}(\dot u) \rightarrow U''(x,s)=\frac s 4U(x,s)-\frac 14u(x,0)$ Problem with Heat Equation and Laplace
Transform ,
this is more relating to Fourier transforms it seems. I couldn't follow it and
apply it to my confusion here at least.","['heat-equation', 'ordinary-differential-equations', 'laplace-transform', 'partial-differential-equations']"
2758901,Edge length of an equilateral triangle if distances from a point $P$ to its vertices is given,"A point $P$ is located inside an equilateral triangle and is at a distance of 5, 12, and 13 from its vertices. Compute the edge length of the triangle. The answer is $\sqrt{169 + 60\sqrt(3)}$. If $s$ is the edge length of the triangle, and if $x$ is the measure of the angle with vertex at $P$ and with sides of lengths 5 and 12, and if $y$ is the measure of the angle with vertex at $P$ and with sides of lengths 5 and 13, according to the Law of Cosines,
\begin{equation*}
s^{2} = 169 - 120\cos(x)
\end{equation*}
\begin{equation*}
s^{2} = 194 - 130\cos(y)
\end{equation*}
and since $\cos(360 - (x + y)) = \cos(x + y)$,
\begin{equation*}
s^{2} = 313 - 312\cos(x+y)
\end{equation*}
So,
\begin{align*}
\cos{x} = - \frac{s^{2} - 169}{120} , \\
\cos{y} = - \frac{s^{2} - 194}{130} , \\
\cos(x+y) = - \frac{s^{2} - 313}{312} .
\end{align*}
For any real numbers $\theta$ and $\phi$,
\begin{equation*}
\bigl[\cos{\theta}\cos{\phi} - \cos(\theta + \phi)\bigr]^{2}
= \sin^{2}\theta\sin^{2}\phi
= \bigl(1 - \cos^{2}\theta\bigr)\bigl(1 - \cos^{2}\phi\bigr) .
\end{equation*}
So,
\begin{align*}
&\left[\frac{s^{2} - 169}{120} \cdot \frac{s^{2} - 194}{130} + \frac{s^{2} - 313}{312}\right]^{2} \\
&\qquad \qquad = \left(1 - \left(\frac{s^{2} - 169}{120}\right)^{2}\right)\left(1 - \left(\frac{s^{2} - 194}{130}\right)^{2}\right)
\end{align*}
or equivalently, by multiplying by $(120^{2})(130^{2})312$,
\begin{align*}
&\Bigl[312(s^{2} - 169)(s^{2} - 194) + (120^{2})(130^{2})(s^{2} - 313)\Bigr]^{2} \\
&\qquad \qquad
= 312 \Bigl((120^{2})(130^{2}) - 130^{2}(s^{2} - 194)\Bigr)
\Bigl((120^{2})(130^{2}) - 120^{2}(s^{2} - 194)\Bigr) .
\end{align*} How is the quartic equation in the variable $s$ to be solved?","['euclidean-geometry', 'trigonometry']"
2758962,Trouble Understanding Fermat's Little Theorem for Non-Coprime Case,"For the case where some integer, $n$ is coprime to a prime modulus, $p$, I have proven and understood Fermat's Little Theorem as it is nothing more than Euler's Theorem applied to a prime modulus. For the case where some integer $n$ is not coprime to $p$ 
$$ \gcd(n,p) \neq 1 \implies p | n $$
This would mean that 
$$ n \equiv 0\mod p.$$
So far so good.
But how does one then go from here to $$0 \equiv n^p \equiv n \mod p$$
as is done by Herstein on page 44 of topics in algebra. Any help or way-pointing is more than appreciated.","['number-theory', 'congruences', 'prime-numbers', 'modular-arithmetic']"
2758984,A topology on the set of all complete theories of a first order language,"Let $L$ be a first order language and $\mathcal T$ be the collection of all complete $L$ theories. For each $L$-sentence (closed $L$-formula) $\phi$, define $B_\phi :=\{T \in \mathcal T : \phi \in T\}$. Let $\mathcal B:=\{ B_\phi : \phi \in T \}$ . I can see that if $T \in B_{\phi_1} \cap B_{\phi_2}$, then $\phi_1,\phi_2 \in T$, then for every model $M$ of $T$, $M \vDash \phi_1, M \vDash \phi_2$ [since $T$ is complete and $\phi_1, \phi_2$ are $L$-sentences ] , and then $M \vDash \phi_1  \land \phi_2 $ , so $T \vDash \phi_1 \land \phi_2$ , so $T\in B_{\phi_1 \land \phi_2} \subseteq  B_{\phi_1} \cap B_{\phi_2} $. Thus $\mathcal B$ forms a base for a topology on $\mathcal T$ . How to show that this topology is compact and Hausdorff ?","['model-theory', 'general-topology', 'first-order-logic']"
2758999,Range of function doesn't contain any value belonging to an interval,"If the range of the function $f(x)= \dfrac {x-1}{p-x^2+1}$ does not contain any values belonging to the interval $\left[-1, -\dfrac{1}{3}\right]$, then the true set of values of $p$ is? Attempt: I set the function $= y$ And got $yx^2 + x-py-y-1 = 0$ For real values of $x$, $\Delta \ge 0$ Using this I got: $4y^2(p+1)+4y +1 \ge 0$ And $p\ge \dfrac{-1-4y}{4y^2}-1$ I am  unable to proceed. How do I continue from here?","['algebra-precalculus', 'calculus', 'functions']"
2759011,Probability that the two segments intersect,P and Q are uniformly distributed in a square of side AB. What is the probability that segments AP and BQ  intersect?,"['probability', 'geometry']"
2759052,Martingale and Super-Martingale,"A auto-machine pick up a ball uniformly randomly from a box filled with green balls and red balls in every minute. When the # of green balls or red balls = 0, the auto-machine do not pick. Otherwise, if the auto-machine picked a red ball, it will replace one green ball with a red ball . if the auto-machine picked a green ball, it will replace one red ball with a green ball. Suppose the total # of balls is fixed. At each odd minute, you can throw away any non-negative number of red balls, $\textbf{the goal is to maximize the expected number of green in the end} $ (when either red ball count or green ball count goes down to zero). Each step includes: your change, and then change by the auto-machine. Consider the plan $\bf{A}$: Every time you find $r \ge g>0$, $r=$ the # of red balls and $g=$ # of green balls, you bring the red ball count to $g-1$ by throwing away $r-g+1$ red balls. Let $W(r,g)$ be the expected # of green balls in the end,  following Plan $\bf{A}$ starting with $r$ red balls and $g$ green balls at start. (a) Show that $W(0,g)=b, W(r,0)=0, W(r,g)=W(r-1,g)$ for $r\ge g>0$ and $W(r,g) = \frac{r}{r+g}W(r+1,g-1)+\frac{g}{r+g}W(r-1,g+1) \text{ for }0<r<g.$ (b) Prove that $W(R_{n}^{A},G_{n}^{A})$ be martingale w.r.t. some filtration where $R_{n},G_{n}$ are the red and green ball count after the $n$-th change by the auto-machine and when following plan $\bf{A}$ (c) Assuming that (no need to prove it), for all $r,g>0$
\begin{align*}
W(r,g)\ge W(r-1,g) \text{ and  }
W(r,g) \ge \frac{r}{r+g}V(r+1,g-1)+\frac{g}{r+g}V(r-1,g+1),
\end{align*}
prove that $W(R_{n}^{B},G_{n}^{B})$ is a non-neg supermartingale for any other plan $\bf{B}$. (d) Show that the plan $\bf{A}$ is the best plan for maximizing the expected # of green balls in the end. Is there any hint for solving this question? Or is there any reference for this question? 
Thank you!","['stochastic-processes', 'expectation', 'probability-theory', 'martingales', 'polya-urn-model']"
2759067,Expected number of hamiltonian paths in a tournament,"The following theorem is from Alon&Spencer's The probabilistic method, in the beginning of chapter 2: Theorem 2.1.1: There is a tournament $T$ with $n$ vertices and at least $\frac{n!}{2^{n-1}}$ Hamiltonian paths. Briefly the theorem is proved by looking at $X_\sigma$ the indicator random variable for a permutation $\sigma$ giving a Hamiltonian path, that is, satisfying $(\sigma(i),\sigma(i+1))\in T$ for $1\leq i \lt n$. Then $\sum \mathbb{E}\left[X_\sigma\right] = \frac{n!}{2^{n-1}}$. I don't understand where did this value ($\frac{n!}{2^{n-1}}$) came from! could someone explain it please?","['combinatorics', 'graph-theory', 'hamiltonian-path', 'probabilistic-method']"
2759085,Use of partitions of unity,"So, I'm working through introduction to smooth manifolds, and I've seen the fact that partitions of unity exist . They seem like extremely useful theoretical tools, but I haven't seen them used yet. I'd like some nice examples as to where they can be used, and why they're ""special"" in some sense (I don't have a good intuition as to why you need a smooth manifold to exhibit this partition). What's the intuition with partitions of unity? asks the intuition of this object. I am after uses. Non-Theoretical Applications of Partitions of Unity asks about, well, applied uses. I want something along the lines of ""what is the most dazzling thing you can do with this tool"" - Something like the awesome uses of orthogonalization, or the spectral theorem you would see in linear algebra.","['real-analysis', 'differential-geometry', 'differential-topology']"
2759110,Finding zeroes and poles of the Weierstrass $\wp$ and $\wp^{'}$ function associated with a lattice.,"I have a lattice, $\Omega$, with basis $\lbrace 2+i, 1+3i\rbrace$ and fundamental region (square) $P$ with vertices $1+2i,\ 2, \ -1+i\ $ and $-i$. I want to find the zeroes and poles of $\wp$ and $\wp^{'}$ in $P$, along with their orders; where $$\wp=\frac{1}{z^2}+\sum_{\omega\in \Omega\backslash\lbrace0\rbrace}\left(\frac{1}{\left(z-\omega\right)^2}-\frac{1}{\omega^2}\right),$$ and $$\wp^{'}=-\frac{2}{z^3}+\sum_{\omega\in \Omega\backslash\lbrace0\rbrace}\left(\frac{-2}{\left(z-\omega\right)^3}\right)=-2\sum_{\omega\in \Omega}\frac{1}{\left(z-\omega\right)^3}.$$ I'd appreciate any guidance you may have to offer.","['complex-analysis', 'elliptic-functions']"
2759166,Prove that $\sum_{k=0}^{n}(-1)^k{n\choose k}\frac{1}{(k+1)(k+2)}=\frac{1}{n+2}$,"Deduce that $\displaystyle {n \choose 0}\dfrac{1}{1\cdot2}-{n \choose 1}\dfrac{1}{2\cdot3}+{n \choose 2}\dfrac{1}{3\cdot4}+...(-1)^n{n \choose n}\dfrac{1}{(n+1)\cdot(n+2)}=\dfrac{1}{n+2}$ We know $\dfrac{1}{n+2}=\displaystyle \int_{0}^{1}t^{n+2-1}dt$ Now $\displaystyle {n \choose 0}\dfrac{1}{1\cdot2}-{n \choose 1}\dfrac{1}{2\cdot3}+{n \choose 2}\dfrac{1}{3\cdot4}+...(-1)^n{n \choose n}\dfrac{1}{(n+1)\cdot(n+2)}=\displaystyle \sum_{k=0}^{n}{n\choose k}(-1)^k\bigg(\dfrac{1}{(k+1)(k+2)}\bigg)=\displaystyle \sum_{k=0}^{n}{n\choose k}(-1)^k\bigg(\dfrac{1}{(k+1)}-\dfrac{1}{k+2}\bigg)$ $=\displaystyle \sum_{k=0}^{n}{n\choose k}(-1)^k\bigg(\dfrac{1}{(k+1)}\bigg)-\displaystyle \sum_{k=0}^{n}{n\choose k}(-1)^k\bigg(\dfrac{1}{(k+2)}\bigg)$ $=\displaystyle \sum_{k=0}^{n}{n\choose k}(-1)^k\int_{0}^1 t^{k+1-1}dt \space - \space \displaystyle \sum_{k=0}^{n}{n\choose k}(-1)^k \int_{0}^1 t^{k+2-1}dt$ $=\displaystyle \int_{0}^1 t^{1-1}\bigg(\sum_{k=0}^{n}{n\choose k}(-t)^k\bigg) dt- \int_{0}^1 t^{2-1}\bigg(\sum_{k=0}^{n}{n\choose k}(-t)^k\bigg) dt$ $=\displaystyle  \int_{0}^1 t^{1-1}(1-t)^{n}dt \space - \space  \int_{0}^1 t^{2-1}(1-t)^{n}dt$ $=\displaystyle \large \beta(1,n+1)$-$\displaystyle \large\beta(2,n+1)$ $=\dfrac{\Gamma(1)\Gamma(n+1)}{\Gamma(1+n+1)}-\dfrac{\Gamma(2)\Gamma(n+1)}{\Gamma(2+n+1)}= \underbrace{\dfrac{1}{n+2}}_{\text{which is exactly what I  proved}}$ PS @Chappers Thankyou all users for correcting one nasty mistake.","['integration', 'definite-integrals', 'sequences-and-series', 'gamma-function', 'beta-function']"
2759171,Show that the composition operator is a bounded linear operator.,"Problem: Fix a continuous function $\phi:[0,1]\to[0,1]$ and define the operator $C_\phi:C([0,1])\to C([0,1])$ by $(C_\phi f)(x)=f(\phi(x)).$ Prove that this is a bounded linear operator with $\|C_\phi\|\le1$. Attempt: Consider $\|C_\phi\|_{op}$, now, $$\|C_\phi\|_{op}=\sup\{\|C_\phi f\|_\infty:f\in C([0,1])\}=\sup\{\sup\{|(C_\phi f)(x)|:x\in[0,1]\}:f\in C([0,1])\}$$ Regard the ""inner supremum"" on it's own for the time being. Using the definition of $C_\phi$ we see that, $$\sup\{|(C_\phi f)(x)|:x\in[0,1]\}=\{\sup\{|f(\phi(x))|:x\in[0,1]\}$$ Since $\phi:[0,1]\to[0,1]$ it is clear that $\phi(x)=y$ where $y\in[0,1]$, we get that, $$\sup\{|f(\phi(x))|:x\in[0,1]\}=\sup\{|f(y)|:y\in[0,1]\}=\|f\|_\infty$$ So that, going back to the ""sup of the sup"" we had before, $$\sup\{\sup\{|(C_\phi f)(x)|:x\in[0,1]\}:f\in C([0,1])\}=\sup\{\|f\|_\infty:f\in C([0,1])\}=\|f\|_\infty$$ But then, putting this all together, we have that $\|C_\phi\|_{op}=\|f\|_\infty$, and I don't believe that this is right. I think that it is, rather, an incorrect means to approach the problem. -- On the other hand if we just considered, $$\|C_\phi f\|_\infty=\sup\{|(C_\phi f)(x)|:x\in[0,1]\}=\sup\{|f(y)|:y\in[0,1]\}=\|f\|_\infty$$ So that in particular, $\|C_\phi f\|_\infty=\|f\|_\infty$ which would mean that $\|C_\phi\|_{op}=1$. Now saying that something is equal to something does still satisfy saying that it is less than or equal to something. So I have to wonder, is this sufficient to answer the problem? Or have I done something wrong, this second time round, which has made it seem easier than it should?","['real-analysis', 'normed-spaces', 'operator-theory', 'functions', 'functional-analysis']"
2759256,Why does this relation of binomials hold?,Why does $\sum_{m=n}^N m\binom {m-1}{n-1}=\sum_{m=n}^N n \binom mn=n \binom{N+1}{n+1}$ is true? Is there some special formula for it?,"['algebra-precalculus', 'real-analysis', 'binomial-coefficients']"
2759337,Difference of two compact sets is compact,"Consider this question: Let $K_{1}$ and $K_{2}$ be compact sets. Define $A=\{||x_{1}-x_{2}||:x_{1} \in K_{1}, x_{2} \in K_{2}\}$. Show that $A$ is compact. My atempt consist in prove that $A$ is compact using the notion of sequentially compact. $\textbf{My answer}$: Let $K_{1}$ and $K_{2}$ be compact sets. Therefore, every sequence has convergent subsequence. Consider the sequences $(x_{n}^{1})_{n \in \mathbb{N}} \in K_{1}, \forall n \in \mathbb{N}$, and $(x_{n}^{2})_{n \in \mathbb{N}} \in K_{2}, \forall n \in \mathbb{N}$. Hence, $\exists (x_{n_{j}}^{1})_{j \in \mathbb{N}} \in K_{1}:x_{n_{j}}^{1} \to x^{1}$, and $\exists (x_{n_{j}}^{2})_{j \in \mathbb{N}} \in K_{2}:x_{n_{j}}^{2} \to x^{2}$. Since both $K_{1}$ and $K_{2}$ are compact sets, $x^{1} \in K_{1}$ and $x^{2} \in K_{2}$. Therefore, the sequence defined as $y_{n}=x_{n_{j}}^{1}-x_{n_{j}}^{2} \to (x^{1}-x^{2}) \in A$, hence, $A$ is compact. Is this a valid proof?","['real-analysis', 'compactness', 'sequences-and-series']"
2759379,How to find the number of solutions to $ 2x^{4}+x^{3}-4x+11\equiv 0 \pmod{1000000}$?,I know that for a quadratic equation we can look at if $ b^2-4ac $ is a quadratic residue and conclude that there are two solutions but I am not sure how to do this with a quartic equation. Is there a way I could apply the method above or is there another way?,"['number-theory', 'abstract-algebra', 'elementary-number-theory']"
2759384,Is this an example of a regular surface with planar point that is strictly locally convex?,"Definition of locally convex: (Definition) (Local Convexity and Curvature). A surface $S\subset \mathbb{R}^3$ is locally convex at a point $p\in S$ if there exists a neighborhood $V \subset S$ of $p$ such that $V$ is contained in one of the closed half-spaces determined by $T_p(S) $ in $\mathbb{R}^3$. If, in addition, $V$ has only one common point with $T_p(S)$, then $S$ is called strictly locally convex at $p$. Consider the surface $S \subset \mathbb{R}^3$ generated by revolving the function $z = x^4$ about the $z$ axis. Then this surface can be parameterized by $f(x,y) = (x,y,(x^2+y^2)^2)$. which has zero normal curvature at $(0,0,0)$, in every direction, in particular, the principal direction, so it must be a planar point. Yet, we know that every point is above the $z$ axis, so it's strictly locally convex. So strictly locally convexity at a point does not demand that the principal curvature need to be non-zero. Is this right?",['differential-geometry']
2759389,Intuitive method of finding probability of getting an onto function from all possible functions from a set to another.,"The question I was dealing with is as follows: Let sets $A$ and $B$ have $7$ and $5$ elements, respectively. If one function is selected from all possible defined functions from $A$ to $B$, what is the probability that it is onto? Now, this is how my thought process was: For a relation to classify as a function only an element of $A$ should possess only one image in the co-domain $B$. Thus, each element of $A$ has $5$ elements to choose as its image. Since it is a function from $A$ to $B$, two elements from $A$ mapping to the same image is allowed. And so the total number of possible functions would be $= 5^7$ Next, to choose the number of onto functions, what I thought was: each element of $B$ must be mapped, but not to the same element. Therefore, the first element of $B$ would have $7$ options to choose from, the next one would have $6$ and so on... After every element of $B$ is mapped, there would be $2$ remaining elements in $A$ and they have to be mapped to any element of $B$ so as to become a function. Therefore, those two elements would have to choose any $2$ out of $5$ elements of $B$. Thus the total number of possible onto functions would be = $$(7 \cdot 6 \cdot 5 \cdot 4 \cdot 3) \cdot (5 \cdot 5) = \frac{7! \cdot 5^2}{ 2!}$$ Thus the probability required = $$\frac{\frac{7! \cdot 5^2}{2!}}{5^7}$$ But, the answer was $$\frac{7! \cdot 2}{3 \cdot 5^6}$$ Where did I go wrong?","['combinatorics', 'probability', 'functions']"
2759407,The probability that Student $1$ performs better than Student $2$ on an examination,"Suppose there's a exam with 5 questions.
If the probability that Student $1$ correctly answers question $i$ is $P_{1.i}$, then $P_{1.1} = 0.3$ , $P_{1.2} = 0.4$ , $P_{1.3} = 0.9$, $P_{1.4} = 0.7$ , $P_{1.5} = 0.1$ For Student $2$, $P_{2.1} = 0.4$ , $P_{2.2} = 0.5$ , $P_{2.3} = 0.2$, $P_{2.4} = 0.8$ , $P_{2.5} = 0.1$ What is the probability that Student $1$ performs better than Student $2$ ? How to solve something like that? I want an expression to do this.","['statistics', 'probability']"
2759419,"2D Random walk, probability of remaining in a distance to a line","On a grid with corners $(0,0)$ and $(r,k)$, a random walker starts from point $(0,0)$. Each time we flip a fair coin to decide to go to $(x+1,y)$ or $(x,y+1)$, from the point $(x,y)$. The walker is confined to this grid, if it reaches the border and the coin says to pass the border, it does not do anything and flips another coin. We do this until the walker reaches the corner $(r,k)$. For each point $(x_0,y_0)$ on the grid  where $x_0,y_0$ are non-negative integers, calculate the probability of the event that walker's distance to the line $y=(k/r)x$ remains less than the distance between point $(x_0,y_0)$ and the same line? I can calculate the probability that the walker's path contains the point $(x_0,y_0)$, but I don't know how to calculate above.","['stochastic-processes', 'random-walk', 'probability-theory', 'probability', 'stochastic-calculus']"
2759476,"Definition of a Sheaf, making sense of","I have started to read an english translation of Serre's FAC. Immediately a sheaf is defined. The more categorical definition given on wikipedia actually makes more sense to me, but I would like to understand this one as it is written since I will be working through this paper. I give the definition, then pose some questions. Definition: Let $X$ be a topological space. A sheaf of abelian groups on $X$ (or
  simply a sheaf ) consists of: (a) A function $x \to \mathscr{F}_x$, giving for all $x \in X$ an
  abelian group $\mathscr{F}_x$, (b) A topology on the set $\mathscr{F}$, the sum of the sets
  $\mathscr{F}_x$. If $f$ is an element of $\mathscr{F}_x$, we put $\pi(f) = x$; we call
  the mapping of $\pi$ the projection of $\mathscr{F}$ onto $X$; the
  family in $\mathscr{F} \times \mathscr{F}$ consisting of pairs
  $(f,g)$ such that $\pi(f) = \pi(g)$ is denoted by
  $\mathscr{F}+\mathscr{F}$. Having stated the above definitions, we impose two axioms on the data
  (a) and (b): (I) For all $f \in \mathscr{F}$ there exist open neighborhoods $V$ of
  $f$ and $U$ of $\pi(f)$ such that the restriction of $\pi$ to $V$ is
  a homeomorphism of $V$ and $U$.(In other words,  is a local
  homeomorphism). (II) The mapping $f \mapsto -f$ is a continuous mapping from
  $\mathscr{F}$ to $\mathscr{F}$, and the mapping $(f, g) \mapsto f + g$
  is a continuous mapping from $\mathscr{F}+\mathscr{F}$ to
  $\mathscr{F}$. Questions: 1) At the very beginning of this definition, what are we taking
  $\mathscr{F}$ to be? It seems we are referring to it indirectly as the
  category of abelian groups. In this definition is $\mathscr{F}$ just
  some unspecified class of abelian groups? They refer to $\mathscr{F}$ as a set in (b), but I don't believe the category of abelian groups is small. What should I be taking $\mathscr{F}$ as? 2) After this definition, which thing(s) exactly is (are) the sheaf?
  Is it the pair $(f,\tau)$ where $f$ is the function from (a) and
  $\tau$ the topology from (b)? The function from (a) seems to be
  playing the role of the functor from the definition on wikipedia,
  except that the functor pairs open sets of $X$ to objects, not points of the
  space $X$. 3) In part (b), a priori of the rest of the definition, is it just
  stating that any topology can be on $\mathscr{F}$? Why do they say
  'the sum of the sets $\mathscr{F}_x$'. 4) In I and II, how am I to make sense of $-f$ and $f+g$ if $f,g$ are
  abelian groups? does this have to do with the topology we put on the
  collection of sets? 5) Is this definition actually equivalent to the one on wikipedia? Of
  course this is just for abelian groups, and the one on wikipedia
  allows the target category to be Sets, Rings, etc.. But in the case of
  the target category being abelian groups, are they equivalent? EDIT: Perhaps question 3 actually answers question 1. Are they defining the 'set' $\mathscr{F}$ to be the sum of all the images of the function? In what set theoretic way are we summing them? The disjoint union seems to be plausible? Also, -f and f+g do make sense, I just realized that $f,g$ are elements of the group $\mathscr{F}_x$. In light of these edits, can I take $$\mathscr{F} = \bigcup_{x \in X} (\{x\} \times \mathscr{F}_x) \hspace{2mm} ?$$ then the mapping $\pi$ mentioned in the definition would really be mapping from $(x,f) \mapsto x$? Although maybe trivial at this level, this seems important since in the case of the constant sheaf the same group element would be going to each $x \in X$ but in this disjoint union that would still be well defined. The definition of the map $\pi$ seems very 'not universal' since it depends on the elements of the groups? The definition of $\mathscr{F} + \mathscr{F}$ seems very strange, it is just forming all tuples of elements that came from the same group?","['sheaf-theory', 'algebraic-geometry', 'abstract-algebra', 'coherent-sheaves', 'sheaf-cohomology']"
2759488,Subset of matrix rows with half of column sums,"Consider the following problem. We are given a matrix $A = (a_{ij})_{i,j = 1}^{m,n}$ with $m$ rows and $n$ columns, all $a_{ij}$ are nonnegative . Prove that there exists a subset $S$ of rows , $|S| \leq m/2 + n/2$, such that, for every column $j$, sum of all elements from $S$, that were in the column $j$, is at least a half of the sum of all elements in the whole column $j$.
That is, if $S = \{i_1,\ldots,\ i_s\}$, $$\forall j = 1\ldots n: \qquad\sum_{k = 1}^sa_{i_kj} \geq \frac{1}{2}\sum_{i = 1}^ma_{ij}.$$ It is said that this problem is somehow connected to linear programming. I tried to consider the corresponding integral minimization problem and its LP relaxation, but still have no insight of the solution. Any advice appreciated.","['matrices', 'combinatorics', 'linear-programming']"
2759498,"An $n$ element set can be written as a union of disjoint sets, in $B_n$ different ways. But what if the sets are not disjoint?","If we let $X=\{1,2,3,\ldots n\}$ then what is the value of $\left|\{\mathcal{F}\subseteq\wp(X):\bigcup\mathcal{F}=X\}\right|?$ I know that if one requires the sets in $\mathcal{F}$ be pairwise disjoint this is just the the $n^{\text{th}}$ bell number. However I'm interested in counting all the set covers of an $n$ element set. Could anyone point me to a reference?","['combinatorics', 'bell-numbers', 'elementary-set-theory']"
2759518,Coordinate transformation of ODEs,"I have the following system of ODEs: $x' = \alpha x - y - x(x^2 + y^2), y' = x + \alpha y - y(x^2+y^2)$, where $\alpha \in \mathbb{R}$ is a free parameter. I have to make a coordinate transformation using polar coordinates, $x = r \cos \theta, y = r \sin \theta$. I recognize that the $(x^2 + y^2) = r^2$. I am having difficulty in substituting the derivatives. I get that: $x'(t) = r'(t) \cos (\theta (t))-r(t) \theta '(t) \sin (\theta (t))$, and $y'(t) =r'(t) \sin (\theta (t))+r(t) \theta '(t) \cos (\theta (t))$ The problem as you can see is that this autonomous system of ODEs that originally just had an $x'(t)$ and $y'(t)$, now has a $r'(t)$ and $\theta'(t)$ in one ODE. I am unable to write down a system of ODEs as: $r'(t) = ... $ and $\theta'(t) =...$","['coordinate-systems', 'ordinary-differential-equations', 'dynamical-systems', 'polar-coordinates']"
2759580,Understanding the concept of Groups,"Currently, I am studying Math's C in grade 11 and we have started a unit known as Groups. I'm really struggling to understand the concepts of how all of this works, as the maths that we do is unlike anything that I have ever done before. These are the 'concepts' that we started off with, we then had to use these to determine whether or not equations were closed or associative as well as finding identities and inverses of operations. This is the point where the course really started to lose me. This is an example of the sort of questions we have been asked to do. My teacher does go through and explain the solutions to us, however; I barely understand why most things are done and how the final 'solution' actually proves anything. The above solution was provided by my teacher, yet, I fail to see how either of the solutions answer the questions. Additionally, I don't understand where a majority of the variable came from e.g. a, b, 2x, 2y and 2z. I just need some clarity on how this topic works, because the math seems so strange to me, and I just don't understand appropriate methods of solving the questions given to me.",['group-theory']
2759627,Are all Monte Carlo algorithms to approximate $\pi$ equivalent?,"There are several ways one can approximate $\pi$ using a Monte-Carlo type algorithm. For example, one can draw random points in the unit square, and approximate $\pi$ via the ratio of points that fall in the unit disk. Another way would be to use an algorithm based on Buffon's needle problem: from the proportion of needles that fall across the parallel lines, one can approximate $\pi$. One can presumably devise many other random algorithms to estimate $\pi$. My question is: in terms of speed of convergence, are all these algorithms equivalent? Or are there some that will yield correct decimals of $\pi$ faster? What is the Monte Carlo method to estimate $\pi$ that has the fastest convergence?","['algorithms', 'simulation', 'probability', 'approximation']"
2759636,Prove that $\frac{1}{n + 1}{2n\choose n}$ is a positive integer for $n \ge 0$.,"I attempted to use Pascal's triangle identity to help out, but I do not know how to deal with $\frac{1}{n+1}$.",['combinatorics']
2759653,Is $\mathbb{Z}[\sqrt{29}] $ a PID,"Question as in title. I think that unique factorization fails, perhaps via either $ (\sqrt{29} - 1)(\sqrt{29} + 1) = 2^2 \cdot 7 $ or $ (\sqrt{29} - 5)(\sqrt{29} + 5) = 2^2 $, but I have trouble proving either of these two claims. How to solve this problem?","['abstract-algebra', 'ring-theory']"
2759660,"Is there a clear, universal test for a separable diferential equation?","I understand that an equation of the form:
$$\frac{dy}{dx} = f(x, y)$$
is separable, if $f(x, y)$ can be rewritten as $g(x)\cdot h(y)$. But is there a way to test if the equation can be separated without having to guess until you find a valid separation? If there exists no universal method, is there a way to prove that a certain equation of a specific form cannot be separated, for example,$$ y' = \frac{x+y}{x}? $$",['ordinary-differential-equations']
2759702,"What does $D_{12}f$ mean compared to $D_{1}f$, for example?","What does $D_{12}f$ mean in the context of partial derivatives, with $f: \mathbb{R}^2 \to \mathbb{R}$, for example? This is used in Rudin's Principles of Mathematical Analysis. It is clear to me what that $D_1 f$ is the partial derivative of $f$ with respect to $x$. Is $D_{12}f$ a row vector
$
\begin{bmatrix}
D_1f & D_2f
\end{bmatrix}
$?","['multivariable-calculus', 'partial-derivative', 'notation']"
2759716,Almost done solving IVP using Laplace transform .. Need advice/guidance,"I have the following IVP:
$$\begin{cases}y''-2y'+5y = -8e^{-t},\\ \ \\  y(0) = 2\\ \ \\ y'(0) = 12\end{cases}$$ I will show my steps so far. After taking the transform of each term I get: $$s^2Y(s) - 2sY(s) + 5Y(s) - 2s - 8 = \frac {-8}{s+1}$$ I simplified the L.H.S and got:
$$ Y(s)(s^2-2s+5) = \frac {-8}{s+1} + 2s+ 8 $$ Then the R.H.S becomes: $$ Y(s)(s^2-2s+5) = \frac {2s^2+10s}{s+1}$$ I then get: $$Y(s) =  \frac {2s^2+10s}{(s+1)(s^2-2s+5)}$$ I then used partial fraction decomposition and got $A = -1, B = 3$, and $C = 5$ I then have the following: $$Y(s) = \frac {-1}{s+1} + \frac {3s+5}{s^2-2s+5}$$ I am now stuck finding the inverse Laplace transform of the second term. Please can someone check my work and let me know if I did this right and, if so, what is that inverse Laplace transform I mentioned at the last step? Help is greatly appreciated. Thank you.","['ordinary-differential-equations', 'laplace-transform']"
2759753,The Mabinogion sheep problem,"$\textbf{The Mabinogion sheep problem}$ By David Williams There is a magical flock of sheep, some black, some white. We sacrifice poetry for precision in specifying its behaviour. At each of times 1,2,3,… a sheep (chosen randomly from the entire flock, independently of previous events) bleats; if this bleating sheep is white, one black sheep (if any remain) instantly becomes white; if the bleating sheep is black, then one white sheep (if any remain) instantly becomes black. No births or deaths occur. The controlled system. Suppose now that the system can be controlled in that just after time 0 and just after every magical transition time 1,2,…, any number of white sheep may be removed from the system. (White sheep may be removed on numerous occasions.) The object is to maximize the expected final number of black sheep. Policy $\bf{A}$ : at each time of decision, do nothing if there are more
  black sheep than white sheep or if no blakc sheep remain; otherwise,
  immediately reduce the white population to one less than the black
  population. We define the value function $V : Z^{+} × {Z} ^{+} → [0, ∞)$ so that $V (w, b)$ is the expected final number of
  black sheep under Policy $\bf{A}$ if there are $w$ white sheep and $b$ black sheep at the start. As a result,
  V has the following properties, a1) $V(0,b)=b, V(w,0)=0$ . a2) $V(w,b)=V(w-1,b)$ whenever $w\ge b>0$ a3) $V(w,b) = \frac{w}{w+b}V(w+1,b-1)+\frac{b}{w+b}V(w-1,b+1)$ whenever $0<w<b$ $\textbf{Question (a)}$ : Show that under the policy $\textbf{A}$, $V(W_n,B_n)$ is a martingale w.r.t. filtration $\mathcal{F}$, where $\{W_n,B_n\}$ is number of white and black sheep after $n_{th}$ time. $\textbf{Question (b)}$ : Suppose $V(w,b) \ge \frac{w}{w+b}V(w+1,b-1)+\frac{b}{w+b}V(w-1,b+1)$ and $V(w,b) \ge V(w-1,b)$ whenever $w\ge0$ and $b \ge 0$. Show that for any other policies, $V(W_n,B_n)$ is a super-martingale w.r.t. filtration $\mathcal{F}$. Recently, I am studying martingale and its application. And I am very curious about this question in the textbook. This is a famous stochastic control problem by David Williams, called The Mabinogion sheep problem. The following is described in (Williams, David (1991), Probability with martingales, Cambridge Mathematical Textbooks, Cambridge University Press) In the David Williams's book, he just mentioned about a1)-a3) three properties but not proved them. $\textbf{My attempt}$: $\textbf{The property a1)-a3) are what we have known, they are very easy to show.}$ $\textbf{For my proof to Question (a)}$ $E\{V(W_{n+1},B_{n+1})|\mathcal{F_n}\} = \frac{W_n}{W_n+B_n}V(W_{n}+1,B_{n}-1) + \frac{B_n}{W_n+B_n}V(W_{n}-1,B_{n}+1) =V(W_{n},B_{n})$. Therefore, $V(W_{n},B_{n})$ is a martingale w.r.t. $\mathcal{F_n}$ $\textbf{For my proof to Question (b)}$ $E\{V(W_{n+1},B_{n+1})|\mathcal{F_n}\} = \frac{W_n}{W_n+B_n}V(W_{n}+1,B_{n}-1) + \frac{B_n}{W_n+B_n}V(W_{n}-1,B_{n}+1)  < V(W_{n},B_{n})$. Therefore, $V(W_{n},B_{n})$ is a super-martingale w.r.t. $\mathcal{F_n}$ Do I miss some points for proving (a) and (b)? Could you help me to check my answer? $\textbf{Edit:}$ . $\textbf{This question has not been answered for Question (a) and (b)}!$ . $\textbf{Could I get some helps from these two question? Thank you so much!}$","['stochastic-processes', 'probability-theory', 'markov-chains', 'probability', 'martingales']"
2759764,"If the range of $f(x)= \frac{x^2+x+c}{x^2+2x+c}, x\in \mathbb R$ is $\left[\frac 56, \frac 32\right]$ then what is $c$?","If the range of the function $f(x)= \dfrac{x^2+x+c}{x^2+2x+c}, x\in \mathbb R$ is $\left[\dfrac 56, \dfrac 32\right]$ then $c$ is equal to? Attempt: $y=  \dfrac{x^2+x+c}{x^2+2x+c}$ For real values of $x$ , $\Delta \ge 0$ $\implies 4y^2(1-4c) +1-4y(1-2c) - 4c \ge 0$ What do I do next? I am really unable to understand the concept to be followed after this. Could someone explain that? The answer is: $c= 4$","['calculus', 'functions']"
2759800,Counting Zeros with Rouche's Theorem,"I'm attempting to answer the question, ""Prove that for any positive number $\epsilon$, the function $f(z)=\frac{1}{z+i} + \sin(z)$ has infinitely many zeros on the strip $|Im(z)|<\epsilon$"". My Work So Far: I know that I want to apply Rouche's Theorem. Assuming I understand Roche's Theorem correctly, I want to think of a function $g(z)$ that has infinitely many zeros in the strip $|Im(z)| < \epsilon$ and then show that $|f(z)-g(z)|$ is less than either $|g(z)|$ or $|f(z)|$. To this end, I thought of $g(z) = sin(z)$ since it has infinitely many zeros in the region of interest, which in of itself seems fairly indicative. However, when I attempt to use this $g(z)$, I end up with $|\frac{1}{z+i}|$, which seems like it can become arbitrarily small for $\epsilon \geq i$. As such, I can't bound this term by either $|g(z)|$ or $|f(z)|$. Am I missing something in my application of Roche's Theorem, or am I perhaps looking at the wrong $g(z)$ to begin with? To address a more general question for the community, am I perhaps misapplying Rouche's Theorem, or is there perhaps a different way/trick that I should be thinking when addressing Roche's Theorem and problems of a similar nature to this one?","['complex-analysis', 'roots', 'rouches-theorem']"
2759849,Between the center of a quotient group and the total center,i have a question on centers of a group and quotients. Consider $G$ a group and $H$ any normal subgroup of $G$. Is there any relation between the center of the quotient $Z\left(G/H\right)$ and the total center $Z(G)$? I am looking for some kind of isomorphism between $Z\left(G/H\right)$ and a quotient on $G$ involving $Z(G)$ but i cannot figure it out. Maybe there is just an injection? Thanks in advance!,"['abstract-algebra', 'normal-subgroups', 'group-theory', 'quotient-group']"
2759864,Partial fractions integral. Compute $\int_{0}^{1} \frac {x^4+1}{x^6+1}dx$,"Evaluate $\int_{0}^{1} \frac {x^4+1}{x^6+1}dx$. I directly approached this with partial fractions and rewritten $x^6+1=(x^2)^3+1=(x^2+1)(x^4+x^2+1)$. Therefore the integral is: $$\int_{0}^{1} \frac {x^4+1}{(x^2+1)(x^4+x^2+1)}dx=-2\int_{0}^{1} \frac {x}{1+x^2}dx+2\int_{0}^{1}\frac 1{1+x^2}dx-\int_{0}^1\frac {(x-1)^2}{(x^2+1)^2+(\frac {\sqrt{3}}2)^2}dx$$ But I don't know how to solve the last term. I answered the question... I realized my silly mistake, sorry for bothering...","['integration', 'definite-integrals', 'calculus']"
2759901,How to find the sum $1+\frac{1}{2}-\frac{1}{4}-\frac{1}{5}+\frac{1}{7}+\frac{1}{8}-\frac{1}{10}-\frac{1}{11}+\cdots =\ ?$,"Let $\phi(x)=\begin{cases}0, & 0\lt x\lt 1\\ 1, & 1\lt x\lt3 \end{cases}$ We have that the Fourier cosine series is given by $$\phi(x)=\begin{cases}0, & 0\lt x\lt1\\ \frac{4}{3}+\displaystyle\sum_{m=1}^{\infty}\frac{-2\sin\frac{m\pi}{3}}{m\pi}\cos\frac{m\pi x}{3}, & 1\lt x\lt3 \end{cases}$$ Put $x=0$ to find the sum $\displaystyle 1+\frac{1}{2}-\frac{1}{4}-\frac{1}{5}+\frac{1}{7}+\frac{1}{8}-\frac{1}{10}-\frac{1}{11}+\cdots$ I tried the following $$\phi(0)=\frac{4}{3}+\sum_{m=1}^{\infty}\frac{-2\sin\frac{m\pi}{3}}{m\pi}\\=\frac43-2\frac{\sin\frac{\pi}{3}}{\pi}-\frac{\sin\frac{2\pi}{3}}{\pi}-2\frac{\sin\pi}{3\pi}-\frac{\sin\frac{4\pi}{3}}{2\pi}-\cdots\\=\frac{4}{3}-\frac{\sqrt3}{\pi}-\frac{\sqrt3}{2\pi}-0+\frac{\sqrt3}{4\pi}\dots=\frac{4}{3}-\frac{\sqrt3}{\pi}(1+\frac{1}{2}-\frac{1}{4}\dots)=\ ? $$ And I'm stuck here, What can I do here? I greatly appreciate any assistance you may provide.","['fourier-series', 'fourier-analysis', 'convergence-divergence', 'summation', 'sequences-and-series']"
2759906,How many functions $f: B\to B$ map even numbers to even numbers?,"How many functions $f: B\to B$ map even numbers to even numbers if $B=\{5,2,7,4,9,6\}$? Because there's a requirement to map even numbers to even numbers then the domain and the range of $f$ is $B'=\{2,4,6\}$ as far as I understand. Then the number of possible functions is $|B'|^{|B'|}=3^3$. Not sure regarding the correct answer.","['combinatorics', 'functions', 'proof-verification']"
2759909,What is the rank of $B$?,"Let $A=(a_{ij})$ be the square matrix of size $2018$ defined by $$ a_{ij} = \begin{cases} 2 & \text{if } i+1=j\\ \frac{1}{3} & \text{if } i =j+1\\ 0 & \text{otherwise}\end{cases}$$ Let $B$ be the leading principal minor of $A$ of order $1009$ (i.e., the submatrix of $A$ formed by the first $1009$ rows and columns). What is the determinant of $A$? What is the rank of $B$? My solution For question 1: For an $n$ dimensional matrix of the form $$ A_n =\begin{pmatrix} 
0 & u & 0 & & \cdots  & 0 \\ 
l & 0 & u & & \cdots &  \\ 
0 & l & 0 \\
\vdots & & & \ddots & & \vdots \\ 
0 & \cdots & & & 0 & u \\
0 & \cdots & & & l & 0
\end{pmatrix} $$ The determinant is $$ {\rm det} [A_n] = \begin{cases} 0 & n=\mbox{odd} \\
(-l u)^{\frac{n}{2}} & n=\mbox{even} \end{cases} $$ For  case $n=2018$, $u=2$ and $l=\frac{1}{3}$ $$ {\rm det}[A_{2018}] = \left( -\frac{2}{3} \right)^{1009}. $$ I'm stuck at question 2. Any hints?","['tridiagonal-matrices', 'matrices', 'determinant', 'matrix-rank', 'linear-algebra']"
2759922,Simple differential equation solution mismatches given answer,Solve $$\left(y-x\frac{dy}{dx}\right)=a\left(y^2+\frac{dy}{dx}\right)$$ I solved it by dividing both sides with $y^2/dx$: $$\frac{(ydx-xdy)}{y^2}=a\left(dx+\frac{dy}{y^2}\right)$$ and then integrate to get $$x/y=ax-a/y+c$$But that doesn't match the answer given by SymbolLab : $$y=\frac{ac_1+xc_1}{a\left(-1+xc_1+ac_1\right)}$$ What's the problem here? Why doesn't my simple differential equation solution match with the given answer?,['ordinary-differential-equations']
2759926,Reconstruct a function $f: \mathbb{R}^3 \to \mathbb{R}$ from two identities on its partial derivatives,"I'd like to find some non-constant function $f: \mathbb{R}^3 \to \mathbb{R}$ such that
$$
\begin{cases}
    \displaystyle \frac{ \partial f } { \partial y } = -2 \frac{ \partial f } { \partial x }, \\[4pt]
    \displaystyle \frac{ \partial f } { \partial z } = - \frac x z \frac{ \partial f } { \partial x }.
\end{cases}
$$
If it helps, it can be assumed that $f$ is as smooth as needed. Given the nature of the underlying physical problem, I initially tried looking for solutions of the form $f(x,y,z) = ( a x + b y ) z^c$, to no avail (I get $f=0$). I then tried the more general form $f(x,y,z) = g(x,y) h(z)$, which did not pan out either. I tried more complicated forms using some symbolic computation software, but I could not find a suitable non-constant answer. I am starting to suspect that there are no non-constant functions satisfying these identities. However, I do not see how to go about proving that. My question is: can we find a non-constant function satisfying these identities? If not, how can we prove that the only solution would be a constant function?","['multivariable-calculus', 'partial-derivative', 'calculus']"
2759929,Smooth homotopy of proper maps,"Suppose $M$ is a manifold. We call a map $F:M \rightarrow \mathbb{R}^m$ proper if for every compact subset $K \subset \mathbb{R}^m$ we have that $F^{-1}(K) \subset M$  is compact. Suppose now that $F: M \times [0,T) \rightarrow \mathbb{R}^m$ is a smooth family of immersions such that $F(\cdot ,0)$ is proper. Is it true that $\forall t \in [0,T): F(\cdot, t)$ is proper?","['general-topology', 'homotopy-theory', 'differential-geometry', 'differential-topology']"
2759941,$L^p$ convergence of composition,"Let $f \in L^{p}(U)$ and $(t_{n})$ be a sequence of functions from $U$ to $U$ such that $$t_{n} \rightarrow \operatorname{id},$$ in the space $L^{\infty}(U)$ . Does the following hold: $$f \circ t_{n} \rightarrow f,$$ in the space $L^{p}(U)$ ? I tried using the dominated convergence theorem for $p_{n}(x)=\left|f(x) - f(t_{n}(x))\right|^{p}$ to show that the statement is true, but I couldn't find the ""dominating"" function.","['sequences-and-series', 'lp-spaces', 'measure-theory', 'convergence-divergence', 'analysis']"
2759945,Condition insuring a convex body is a ball,"Let $K$ be a convex centered body in $\mathbb{R}^{n}$ and suppose that for every $\theta\in{S^{n-1}}$ we have $|K\cap{\theta^{\perp}}|=C$. Does this imply that $K$ is the euclidian ball? One can consider a refinement of the first version, assuming moreover that all such sections are identical. Is it now the euclidian ball? BTW, centered means that $\int_{K}xdx=0$ Thanks.","['convex-geometry', 'convex-analysis', 'functional-analysis', 'geometry', 'analysis']"
2759971,Is my proof of Cantor-Bernstein-Schröder theorem correct?,"Please check if my proof contains any error! Cantor-Bernstein-Schröder theorem: Suppose $f:A \to B$ and $g:B \to A$ are injections. Then there exists a bijection $h$ between $A$ and $B$. Proof: First, let $A_0=A\setminus g[B]$ and $B_0=B\setminus f[A]$. We define recursively $B_{n+1}=f[A_n]$ and $A_{n+1}=g[B_n]$ for all $n \in \mathbb N$. Second, let $A'=A\setminus\bigcup_{n\in\mathbb N}A_n$ and $B'=B\setminus\bigcup_{n\in\mathbb N}B_n$. Finally, our sequences look like: $$A_0 \rightarrow B_1 \rightarrow A_2 \rightarrow B_3 \rightarrow A_4 \rightarrow \cdots$$ $$B_0 \rightarrow A_1 \rightarrow B_2 \rightarrow A_3 \rightarrow B_4 \rightarrow \cdots$$ Note that for all $n\in\mathbb N$, $f\upharpoonright A_n$ is a bijection from $A_n$ to $B_{n+1}$, and $g\upharpoonright B_n$ is a bijection from $B_n$ to $A_{n+1}$. $\{A_n \mid n \in \mathbb N\} \cup \{A'\}$ and $\{B_n \mid n \in \mathbb N\} \cup \{B'\}$ are partitions of $A$ and $B$ respectively Let $T=\{n \in \mathbb N \mid A_n \cap A_m =\varnothing \text{ and } B_n \cap B_m =\varnothing \text{ for all } m \neq n\}$. It suffices to prove $T=\mathbb N$. $A_{n+1}=g[B_n] \subseteq g[B]$ and $A_0=A\setminus g[B]$ $\implies A_0 \cap A_{n+1} =\varnothing \space \forall n \in \mathbb N$, or equivalently $A_0 \cap A_m =\varnothing \space \forall m \neq 0$. Similarly, $B_0 \cap B_m =\varnothing \space \forall m \neq 0$. Thus $0 \in T$. Assume $k\in T$, then $A_k \cap A_m =\varnothing$ and $B_k \cap B_m =\varnothing$ for all $m \neq k$. Thus $B_k \cap B_{m-1} =\varnothing \space \forall m-1 \neq k \implies g[B_k] \cap g[B_{m-1}] =\varnothing \space \forall m \neq k+1$ [Since $g$ is injective] $\implies A_{k+1} \cap A_m = \varnothing \space \forall m \neq k+1$. Similarly, $B_{k+1} \cap B_m = \varnothing \space \forall m \neq k+1$. Thus $k+1 \in T$. By principle of induction, $T=\mathbb N$. $f:A' \to B'$ is bijective If $a\in A'$, then $f(a) \in f(A\setminus\bigcup_{n\in\mathbb N}A_n)=f(A)\setminus\bigcup_{n\in\mathbb N}f(A_n)$ [Since $f$ is injective] $=(B\setminus B_0)\setminus \bigcup_{n\in\mathbb N}B_{n+1}=B\setminus (B_0 \cup \bigcup_{n\in\mathbb N}B_{n+1})=B\setminus \bigcup_{n\in\mathbb N}B_n=B'$. If $b \in B'$, then $b \in B\setminus \bigcup_{n\in\mathbb N}B_n=B\setminus (B_0 \cup \bigcup_{n\in\mathbb N}B_{n+1})=B\setminus ((B\setminus f(A)) \cup \bigcup_{n\in\mathbb N}B_{n+1})$. Thus $b\in B$ and $b \notin B\setminus f(A) \implies b \in f(A) \implies$ there exits $f^{-1}(b) \implies f^{-1}(b) \notin A_n$ for all $n \in \mathbb N$ [if not, there exists $n\in \mathbb N$ such that $f^{-1}(b)\in A_n \implies f(f^{-1}(b))\in f(A_n) \implies$ $b \in B_{n+1}$. This contradicts the fact that $b \in B'$] $\implies f^{-1}(b) \in A'$. We generate the desired function $h$ as follows $$
h:A\to B:a\mapsto\begin{cases}
f(a)&\text{if }a\in A'\cup\bigcup_{n\in \mathbb N}A_{2n} \\
g^{-1}(a)&\text{if }a\in \bigcup_{n\in \mathbb N}A_{2n+1}
\end{cases}
$$
$$\tag*{$\blacksquare$}$$","['proof-writing', 'elementary-set-theory', 'proof-verification']"
