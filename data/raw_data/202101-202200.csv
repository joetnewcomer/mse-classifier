question_id,title,body,tags
3977716,"Continuity, differentiability and double-differentiability of $\sum_{k=1}^{\infty} \frac{\sin(x/k)}{k}$ and $\sum_{k=1}^{\infty}\frac{\sin(kx)}{k^3}$",I have solved the following exercise except for the last point and I would like to know if I have made any mistakes and I would appreciate any hint about how to complete the last question in part (b) about $g$ being twice-differentiable; thanks. Consider $f(x)=\sum_{k=1}^{\infty} \frac{\sin(x/k)}{k}$ and $g(x)=\sum_{k=1}^{\infty}\frac{\sin(kx)}{k^3}$ . (a) Where is $f$ defined? Continuous? Differentiable? Twice-differentiable? (b) Show that $g(x)$ is differentiable and that $g'(x)$ is continuous (c) Can we determine if $g(x)$ is twice-differentiable? My solution: (a) f defined Let $x\in\mathbb{R}$ : then $|\frac{1}{k}\sin(\frac{x}{k})|\leq\frac{1}{k}|\sin(\frac{x}{k})|\leq\frac{1}{k}\frac{|x|}{k}=\frac{|x|}{k^2}$ (where we have used the fact that $|\sin(x)|\leq |x|$ for all $x\in\mathbb{R}$ ) and since $\sum_{k=1}^{\infty}\frac{|x|}{k^2}=|x|\sum_{k=1}^{\infty}\frac{1}{k^2}<\infty$ by Comparison Test it must be $\sum_{k=1}^{\infty}|\frac{1}{k}\sin(\frac{x}{k})|<\infty$ which implies $\sum_{k=1}^{\infty}\frac{1}{k}\sin(\frac{x}{k})<\infty$ by Absolute Convergence Test. $f$ is thus well-defined for all $x\in\mathbb{R}$ . f continuous and differentiable $|f'_k(x)|=|\frac{1}{k^2}\cos(\frac{x}{k})|\leq\frac{1}{k^2}$ and $\sum_{k=1}^{\infty}\frac{1}{k^2}<\infty$ so $\sum_{k=1}^{\infty} f'_k(x)$ converges uniformly on $\mathbb{R}$ by Weierstrass M-test and since $\sum_{n=1}^{\infty}f_n(0)=0$ by Term-by-Term Differentiability Theorem we have that $f$ si differentiable (and hence continuous) on $\mathbb{R}$ and $f'(x)=\sum_{k=1}^{\infty}f'_k(x)=\sum_{k=1}^{\infty}\frac{1}{k^2}\cos(\frac{x}{k})$ . f twice-differentiable $|f''_k(x)|=|-\sin(\frac{x}{k})\frac{1}{k^3}|\leq\frac{1}{k^3}$ and $\sum_{k=1}^{\infty}\frac{1}{k^3}<\infty$ so $\sum_{k=1}^{\infty}f''_k(x)$ converges uniformly on $\mathbb{R}$ by Weierstrass M-Test and since $\sum_{k=1}^{\infty} f'_k(x)=\sum_{k=1}^{\infty}\frac{1}{k}\cos(\frac{0}{k})=\sum_{k=1}^{\infty}\frac{1}{k^2}<\infty$ by Term-by-Term Differentiability Theorem we have that $f'(x)$ is differentiable on $\mathbb{R}$ and $f''(x)=\sum_{k=1}^{\infty}f''_k(x)=\sum_{k=1}^{\infty}-\frac{1}{k^3}\sin(\frac{x}{k})$ . (b) g differentiable with g' continuous $|g'_k(x)|=|\frac{\cos(kx)}{k^2}|\leq\frac{1}{k^2}$ and $\sum_{k=1}^{\infty}\frac{1}{k^2}<\infty$ so $\sum_{k=1}^{\infty}g'_k(x)$ converges uniformly on $\mathbb{R}$ by Weierstrass M-Test and since $\sum_{k=1}^{\infty}\frac{\sin(k\cdot 0)}{k^3}=0$ by Term-by-Term Differentiability Theorem $\sum_{k=1}^{\infty}g_k(x)$ converges uniformly to a differentiable function $g(x)=\sum_{k=1}^{\infty}g_k(x)=\sum_{k=1}^{\infty}\frac{\sin(kx)}{k^3}$ on $\mathbb{R}$ and $g'(x)=\sum_{k=1}^{\infty}g'_k(x)=\frac{\cos(kx)}{k^2}$ and since each $g'_k$ is continuous by Term-by-Term Continuity Theorem $g'$ is continuous too. g twice-differentiable? Here I have tried the estimates $|g''_k(x)|=|-\frac{\sin(kx)}{k}|\leq\frac{1}{k}$ which tells me nothing and neither does the estimate $|g''_k(x)|=|-\frac{\sin(kx)}{k}|\leq\frac{k|x|}{k}=|x|$ since in both of these cases I can't use Weierstrass M-Test so I don't see how I could prove that $g$ is twice differentiable.,"['sequence-of-function', 'real-analysis', 'solution-verification', 'uniform-convergence', 'derivatives']"
3977745,Why does replacing dx and dy with finite values yield this result?,"Consider the change in the function $f(x)=x^2$ at $x=1$ when $x$ is changed by some value $\Delta x$ . $$
\Delta y = f(x+\Delta x)-f(x)\\
\to \Delta y = (1+\Delta x)^2-1^2
$$ Let's set this value $\Delta x$ to $0.1$ . Then $$
\Delta y = (1+0.1)^2-1^2=0.21
$$ Now let's consider this change in the function utilizing its derivative. $$
\frac{dy}{dx}=2x\\
dy=2x(dx)
$$ Let's replace the infinitesimal differences $dx$ and $dy$ with a finite difference (is this valid?). $$
\Delta y = 2x(\Delta x)
$$ Again, let's set $\Delta x$ to 0.1. $$
\Delta y = 2x(0.1)\\
\to\Delta y=2(1)(0.1) = 0.2
$$ Why does $\Delta y$ end up being different than it was previously? I would think that since we're replacing $dx$ with a finite difference, $dy$ would be the same as $\Delta y$ in #1. There must be a flaw in my thinking somewhere. Edit:
Thanks for the answers. Here's the justification I worked out. $$
\frac{\Delta y}{\Delta x} = \frac{(x + \Delta x)^2 - x^2}{\Delta x}\\
\frac{\Delta y}{\Delta x}=\frac{x^2+2x\Delta x + (\Delta x)^2 - x^2}{\Delta x}\\
\frac{\Delta y}{\Delta x}= 2x+\Delta x\\
\to\Delta y = \Delta x(2x + \Delta x)\\
$$ As $\frac{\Delta y}{\Delta x}$ approximates $\frac{dy}{dx}$ with smaller and smaller values of $\Delta x$ , a remainder term is always present. Since $x^2$ is exponential, $\Delta y$ must be greater than multiplying the current growth rate, $f'(x)$ by $\Delta x$ . Using 0.1 for $\Delta x$ gives us $$
\Delta y = 0.1(2(1) + 0.1) = 0.21 
$$ the same value calculated in #1.","['calculus', 'derivatives']"
3977794,What does the output of a derivative actually say in real life?,"Perhaps the wording of the question will need to be adjusted, but I do not know how else to convey what I am looking for in one sentence. Here is what I understand: The derivative of a function in essence shows the ""rate of change"" of a function at any given point. In practical application, determining the current speed of a car at a given time along it's route, as opposed to the average speed of a car over it's entire route. The value (output) given by the derivative function expressed mathematically is the ""slope of a line"",the tangent, at any given point (output) of the function as displayed on a graph, which represents the how much the output of the function has changed with the input. But what exactly is the output of the derivative telling me about this change? If the output of the derivative of some 'x' is '2', what is this '2'? It is a slope, yes, but what is this slope telling me in real life? Here is an example of what I am trying to understand. We will use the following function... $$f(x)=x^2$$ and its derivative... $$f'(x)=2x$$ Let us imagine I have an extremely unique and completely absurd job that lasts for a '1' hour shift each day, and that has a pay rate of f(x)=x^2 per minute, where 'x' is the number of minutes worked in the shift so far. If we look at just the first five minutes of the shift, both the 'pay rate per minute' and the 'rate of change (slope) of pay per minute', we get... $$f(0\text{min})=$0;f'(0\text{min})=0$$ $$f(1\text{min})=$1;f'(1\text{min})=2$$ $$f(2\text{min})=$4;f'(2\text{min})=4$$ $$f(3\text{min})=$9;f'(3\text{min})=6$$ $$f(4\text{min})=$16;f'(4\text{min})=8$$ $$f(5\text{min})=$25;f'(5\text{min})=10$$ Now, again, the output for the derivative, if graphed , is the slope of the line at any given point along the main function. But what does that mean in practice ? If I asked someone, ""How much more money am I earning from minute '4' of my shift?"", and that someone answered, ""according to the derivative of the money earned, 8."" , what is that? '8' what? Dollars? Percent? No unit? Just '8"", or any output given by the derivative, doesn't give me any useful understanding of what is changing. The question-answer bit I gave at the end may be worded incorrectly. (let me know what I should change it to, if so), but I hope the point of this question accross. Also, I am not looking for proofs in the answer. Proofs are not hard to find. I am looking for answers that are not written in proofs.","['calculus', 'functions', 'derivatives']"
3977813,Conditional expectations of $X$ with respect to a filtration converges to $X$,"Let $\mathbb F = \left( \mathcal F_n\right)_{n \in \mathbb N}$ be a filtration, and let $\mathcal F_\infty = \sigma\left(\mathcal F_n : n \geq 1\right)$ . I want to try proving the following result: If $X \in \mathcal L^1\left(\mathcal F_\infty\right)$ , then $\mathbb E\left[X|\mathcal F_n\right] \to X$ as $n \to \infty$ almost surely. It’s easy to show that $\left(\mathbb E\left[X|\mathcal F_n\right]\right)_{n \in \mathbb N}$ is a martingale with respect to $\mathbb F$ , and since $X$ is integrable, one can show that $$
\sup_{n \geq 1} \mathbb E\left[\mathbb E\left[X|\mathcal F_n\right]^+\right] \leq \mathbb E[|X|] < \infty
$$ So by the martingale convergence theorem, $\left(\mathbb E\left[X|\mathcal F_n\right]\right)_{n \geq 1}$ converges almost surely, say to the random variable $\tilde X$ . But why does $X = \tilde X$ a.s.? How can I show that $\left| X - \mathbb E\left[X|\mathcal F_n\right]\right| \to 0$ ? I’m wondering if there’s a functional analytic reason, considering the projections $\mathbb E\left[\cdot|\mathcal F_n\right] : \mathcal L^1\left(\mathcal F_\infty\right) \to \mathcal L^1\left(\mathcal F_n\right)$ , but I haven’t gotten very far with this approach. Or is there an obvious reason for this that I’m just overlooking?","['conditional-probability', 'conditional-expectation', 'martingales', 'probability-theory', 'filtrations']"
3977963,The measure of the image of the exponential of real matrices,"It is known that the matrix exponential over the real matrices $\exp : M_n(\mathbb{R}) \to GL_n(\mathbb{R})$ is not surjective and that its image $S
$ is the subset of all invertible matrices that are the square of a real matrix. My question is about the ""size"" of that set within $GL_n(\mathbb{R})$ equipped with the Lebesgue measure of $\mathbb{R}^{n^2}$ . Do we know if $S$ has full measure ? Or is it a null set ?","['matrices', 'measure-theory', 'matrix-exponential', 'linear-algebra']"
3977995,It is wanted to create an e-mail password.It should have the following properties :,"When I glimpse on my old combinatorics book , I saw a question. It seems very trivial and I still think like that, but the answer is different from what I expected. Question: It is wanted to create an e-mail password. It should have the following properties : $1-)$ It will consist of six characters $2-)$ It will have three digits ( $10$ possibilities) and three letters ( $26$ possibilities) My answer : $10^3 \times 26^3 \times \frac{6!}{3! \times 3!}$ , ( $\frac{6!}{3! \times 3!}$ means the arrangements among letters and digits.) Answer of book : $10^3 \times 26^3 $ The book does not mention about any other restriction.I thought that we should arrange the letters and digits as well. However, the book ignores it. I have never encounter wrong answer in this book before. Am I missing something in this question?","['solution-verification', 'combinatorics', 'discrete-mathematics']"
3978039,The symmetry of conjugacy classes of a subgroup of a finite group,"I have been solving some exercise in group theory and came up with two observations, the first and second below. Then I tried to generalize the fact from that exercise and got an idea of other two observations (the third and fourth below), but was unable to prove or disprove them. Any further observations about them is welcome, and a proof or disproof would resolve my problem. Let $G$ be a finite group, let $H\leq G$ be its subgroup, and let's define the notation $[x]_A$ to be the conjugacy class of element $x\in A$ of group $A\in \{G,H\}$ . It holds that $(\forall x\in H)\Big(\frac{|[x]_G|}{|[x]_G\cap H|}\text{ divides }[G:H]\Big)$ . It holds that $(\forall x\in H)[x]_H\subseteq [x]_G$ . Does it hold that $(\forall x,y\in H)\big(\text{some of the numbers }\frac{|[x]_G|}{|[x]_G\cap H|}\text{ and }\frac{|[y]_G|}{|[y]_G\cap H|}\text{ divides the other one}\big)$ ? Does it hold that $(\forall x\in H)(\forall a,b \in[x]_G\cap H)|[a]_H|=|[b]_H|$ ? The exercise that I was solving was the next one: Let $n\in\mathbb{N}$ be a natural number. And let $H\leq S_n$ , $[S_n:H]<n$ be a subgroup of symmetric group $S_n$ of order less than $n$ . If $n=5$ , prove that $H$ is either $A_n$ or $S_n$ . To prove that, I used the first statement from above. Then I tried to generalize this exercise and replace the condition $n=5$ with $n\geq 5$ and came up with the third and fourth statements as possibly useful lemmas.","['group-theory', 'finite-groups']"
3978097,How to obtain the maximum integer value for $\frac{\tan \theta}{10}$?,"The problem is as follows: The diagram from below shows a cruiser which has departed from an
allied shore. A nearby lighthouse is located on point $A$ . Assume the
height between the bottom of the lighthouse on $A$ to the top of the
lighthouse $P$ is equal to $\textrm{10 m}$ . The cruiser is located at $1.2\,km$ from the lighthouse ( $MA=1.2\,km$ ). After advancing $1\,km$ in a straight line the cruiser makes a stop on point $N$ to do
maintenance and repairs. Assuming the amount of sailors which needs to
be rescued is given by $\frac{12E}{7}$ where $E$ is the maximum
integer value, which it can take $\frac{\tan \theta}{10}$ and $\angle
> APN=\theta$ , find the amount of people who will be rescued. The alternatives given on my book are as follows: $\begin{array}{ll}
1.&\textrm{48 sailors}\\
2.&\textrm{36 sailors}\\
3.&\textrm{24 sailors}\\
4.&\textrm{42 sailors}\\
\end{array}$ This problem I don't know how to approach it correctly. The thing which confuses me the most is how to make sure \tan\theta is maximum? I do remember that: If it mentions that \theta is acute then this means it lies in the first quadrant. Hence: $0\leq \tan \theta < +\infty$ In short what it is asking is how to get maximimum integer value for: $E=\frac{\tan\theta}{10}$ But given such condition it isn't very logical to find the maximum because it is on the positive infinity side. What to do next?. I've attempted using derivatives, but it wouldn't make much sense as it would confirm that given this situation you can find the minimum: $\tan\theta'=\sec^2\theta=\frac{1}{\cos^2\theta}$ And to equate the previous equation to zero would mean that the denominator has to be infinity. So what to do here? . I don't know how to relate the other information provided. In other words the height of the lighthouse and the distance covered by the cruiser. Can someone help me here please?.","['trigonometry', 'optimization', 'calculus', 'algebra-precalculus']"
3978121,Does the orientation bundle not depend on the choice of cover?,"In Bott and Tu's book on page 84 they give a cover $(U_{\alpha},\phi_{\alpha})$ of some smooth manifold $M$ and define the ""orientation bundle"" to be the line bundle over $M$ given by transition functions sgn $J(g_{\alpha \beta})$ where $J(g_{\alpha \beta})$ denotes the Jacobian determinant of $g_{\alpha \beta} = \phi_{\alpha} \circ \phi_{\beta}^{-1}$ . Does this bundle not depend on the choice of open cover? I assume it must not as they go on to say "" $M$ is orientable if and only if its orientation bundle is trivial"". I also do not see how this claim follows either (they write that it follows ""directly from the definition"").","['smooth-manifolds', 'algebraic-topology', 'differential-geometry']"
3978123,"How comes that integrating factor = $1/(x\,y)$","I'm just curious how the integrating factor m(x,y) = $\frac{1}{x\,y}$ of $\frac{\mathrm{d}}{\mathrm{d}x}f(x,y) = x+y-\frac{x^2}{y}\,y'(x)$ was determined. It was just given. When I was introduced to this topic this week, my fist impression was that integrating factor just can depend on x or y. Because determinations like $m(x) = \exp(\int \alpha(x)\mathrm{d}x)$ whereas $\alpha(x) = \frac{\partial_y\partial_x(f(x,y))-\partial_x\partial_y(f(x,y))}{\partial_xf(x,y)}$ or such just seem to work this way. So loosely speaking: Are there other methods?",['ordinary-differential-equations']
3978141,The proofs of limit laws and derivative rules appear to tacitly assume that the limit exists in the first place,"Say I was trying to find the derivative of $x^2$ using differentiation from first principles. The usual argument would go something like this: If $f(x)=x^2$ , then \begin{align} f'(x) &= \lim_{h \to
0}\frac{(x+h)^2-x^2}{h} \\ &= \lim_{h \to 0}\frac{2hx+h^2}{h} \\
&= \lim_{h \to 0} 2x+h \end{align} As $h$ approaches $0$ , $2x+h$ approaches $2x$ , so $f'(x)=2x$ . Throughout this argument, I assumed that $$
\lim_{h \to 0}\frac{f(x+h)-f(x)}{h}
$$ was actually a meaningful object—that the limit actually existed. I don't really understand what justifies this assumption. To me, sometimes the assumption that an object is well-defined can lead you to draw incorrect conclusions. For example, assuming that $\log(0)$ makes any sense, we can conclude that $$
\log(0)=\log(0)+\log(0) \implies \log(0)=0 \, .
$$ So the assumption that $\log(0)$ represented anything meaningful led us to incorrectly conclude that it was equal to $0$ . Often, to prove that a limit exists, we manipulate it until we can write it in a familiar form. This can be seen in the proofs of the chain rule and product rule. But it often seems that that manipulation can only be justified if we know the limit exists in the first place! So what is really going on here? For another example, the chain rule is often stated as: Suppose that $g$ is differentiable at $x$ , and $f$ is differentiable at $g(x)$ . Then, $(f \circ g)$ is differentiable at $x$ , and $$
(f \circ g)'(x) = f'(g(x))g'(x)
$$ If the proof that $(f \circ g)$ is differentiable at $x$ simply amounts to computing the derivative using the limit definition, then again I feel unsatisfied. Doesn't this computation again make the assumption that $(f \circ g)'(x)$ makes sense in the first place?","['limits', 'calculus', 'derivatives', 'real-analysis']"
3978143,How to prove inequality including natural log?,"Let $0<p<1$ and $0<q<1$ be real numbers and $0 < p + q < 1$ .
How can I prove the following inequality is correct or not? $$q > \frac{\ln(\frac{p}{1-q})}{\ln(\frac{p}{1-q}) + \ln(\frac{q}{1-p})}$$ $\ln$ is natural logarithm.","['statistics', 'probability-limit-theorems', 'discrete-mathematics', 'probability-theory', 'probability']"
3978204,a semi-hard problem on combinatory,"I ran into a nice interview question. the problem is as follows: We have array of $n$ integers. for $1 \leq i \leq j \leq n$ . we want to set $c_{ij}$ = Sum of all values in the range $i$ to $j$ of this array. we want to finding average of all possible $c_{ij}$ in this array. if 4 basic operation in math $(+,-,*,/)$ can be done in $O(1)$ . the best algorithm can be works in $O(n)$ . And this is the solution here: Suppose that some entry of the array has value $k$ . What is its contribution to the average of the $c_{ij}$ ? It is counted in some $c_{ij}$ iff $i \leq k \leq j$ . Out of the $\binom{n+1}{2}$ many $c_{ij}$ 's, there are exactly $k(n+1-k)$ in which the entry is counted, therefore its contribution to the average is $$
\frac{k(n+1-k)}{\binom{n+1}{2}} \cdot k = \frac{2k^2(n+1-k)}{(n+1)n}.
$$ Summing this over all values in the array, we obtain the desired $O(n)$ algorithm. Anyone can describe me very easily how this formula is archived?  small example or any intuitive and simple idea?","['computer-science', 'combinatorics', 'discrete-mathematics', 'algorithms']"
3978222,Question regarding inward pointing vector fields help,"Let $M$ be a n manifold with boundary and $p\in \partial{M}$ . $v\in T_pM\backslash T_p\partial{M}$ is inward pointing if there exists some $\epsilon>0$ and a smooth curve $c:[0,\epsilon)\rightarrow M$ such that $c(0)=p$ and $c((0,\epsilon))\subseteq intM$ and $c'(0)=v$ . Problem: Let $M$ be a smooth n manifold and $p\in \partial{M}$ . Let $(U,x^1,.....,x^n)$ be a chart about $p$ . $v=\sum_{i=1}^nv^i\frac{\partial}{\partial{x^i}} \in T_pM$ is inward pointing if and only if $v^n>0$ . My attempt: Suppose $v\in T_pM$ is inward pointing. This means $v\notin T_p\partial{M}$ and there exists some $\epsilon>0$ and a smooth curve $c:[0,\epsilon)\rightarrow M$ such that $c(0)=p,$ $c((0,\epsilon))\subseteq intM$ and $c'(0)=v$ . By definition of $\mathbb{H}^n$ , we have that on $U$ , $x^n\geq 0$ . Also, it is easy to show that $v^n=\frac{d}{dt}|_{t=0}(x^n\circ c)$ . Also note that we may assume $x^n>0$ ; for otherwise, $v\in T_p\partial{M}$ . However, I'm not sure what else to say. If $(U,\phi)$ was centered at $p$ , then I can prove the result, but in this case, the chart may not necessarily be centered at p.,","['smooth-manifolds', 'manifolds', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
3978300,Total variation and bounded variation epsilon inequality,"I have been trying to solve a certain exercise which i found in my Real Analysis book but have not been able to solve it. Context/Relevant definitions: Given $f:[a, b] \rightarrow \mathbb{R}$ , for each partition $P=\left\{t_{0}, \ldots, t_{n}\right\}$ in $[a, b]$ let: $$V(f ; P)=\sum_{i=1}^{n}\left|f\left(t_{i}\right)-f\left(t_{i-1}\right)\right|$$ When the set $\{V(f ; P) ; P=$ partition of $[a, b]\}$ is bounded , one says that f is a function of bounded variation and writes that: $$
V_{a}^{b}(f) = \sup _{p} V(f ; P)
$$ Problem: Let $f$ be a continuous function of bounded variation. Show that, for each $\epsilon > 0$ , there exists $\delta > 0$ such that: $$|P|<\delta \Rightarrow\left|V(f ; P)-V_{a}^{b}(f)\right|<\varepsilon$$ where $|P|$ stands for the length of the partition. (The book does not say it, but I am thinking that $|P| = t_{n} - t_{0}$ does that make sense?) What have I tried so far? Given $f$ a continuous function of bounded variation and $\epsilon > 0$ we observe that: $$\left|V(f ; P)-V_{a}^{b}(f)\right| = \left|V(f ; P)-\sup _{p} V(f ; P)\right|$$ Now, by using the triangle inequality, we obtain that: $$
\begin{split}
\left|V(f ; P)-V_{a}^{b}(f)\right| & = \left|V(f ; P)-\sup _{p} V(f ; P)\right| \\
& \leq \left |V(f ; P)\right|+\left| \sup _{p} V(f ; P) \right|
\end{split}$$ Now, since $f$ is of bounded variation, the set $V(f ; P)$ is bounded and we can write that: $$\left|V(f ; P)\right|+\left| \sup _{p} V(f ; P) \right| \leq $$ $$\leq M + \left| \sup _{p} V(f ; P) \right|$$ Here I got stuck. I just don't know how to proceed. Second attempt: I tried writing what $\sup _{p} V(f ; P)$ means to see if i could do something meaningful with it, but i was only able to write that if: $$ V_{a}^{b}(f) = \sup _{p} V(f ; P)$$ Then, given $\epsilon > 0$ there exists $\Phi \in V(f ; P)$ such that: $$V_{a}^{b}(f) - \epsilon < \Phi \leq V_{a}^{b}(f)$$ which means that: $$V_{a}^{b}(f) - \epsilon < \sum_{i=1}^{n}\left|f\left(t_{i}\right)-f\left(t_{i-1}\right)\right| \leq V_{a}^{b}(f)$$ But got nothing good out of it. I also tried reverse engineering the inequality, but did not go so well. Can someone help? I would greatly appreciate it.
Thanks in advance, Lucas","['bounded-variation', 'inequality', 'supremum-and-infimum', 'real-analysis']"
3978334,"Express roots of equation $acx^2-b(c+a)x+(c+a)^2=0$ in terms of $\alpha, \beta, $ [duplicate]","This question already has an answer here : Find the roots of $acx^2-b(c+a)x+(c+a)^2=0$ (1 answer) Closed 2 years ago . If roots of the equation $ax^2+bx+c=0$ are $\alpha, \beta, $ find roots of equation $acx^2-b(c+a)x+(c+a)^2=0$ in terms of $\alpha, \beta$ Here's what I have tried so far, I know that $\alpha+ \beta=\frac{-b}{a} $ and $\alpha \beta=\frac{c}{a} $ So I can express $b=-a(\alpha+\beta)$ $c=a.\alpha\beta$ Once I substitute for b and c in the equation I can get, $$\alpha\beta x^2+(\alpha+\beta)(\alpha\beta+1)x+(\alpha\beta+1)^2=0$$ I want to know whether there is any different approach other than this method? Any hint is higly valued. thank you!","['roots', 'substitution', 'polynomials', 'algebra-precalculus', 'quadratics']"
3978399,A Negative binomial problem $P(X \ge 5)$ equals?,"Consider a sequence of independent Bernoulli trials with the
probability of success in each trial being $\dfrac{1}{3}$ . Let $X$ denote the number of trials required to get the second success. Then $P(X \ge 5)$ equals. $A=\dfrac{3}{7}$ $B=\dfrac{16}{27}$ $C=\dfrac{2}{3}$ $D=\dfrac{9}{13}$ This is a problem of negative binomial $r=2$ $P(X=x)= {x+r-1 \choose r-1}p^rq^x ;\ \ x=0,1,2..$ $P(X\ge5)=1-P(X < 5) \implies 1-(P(X = 0)+P(X = 1)+P(X = 2)+P(X = 3)+P(X = 4))$ This is very time consuming how do I save time on this problem. How do I utilize CDF of negative binomial distribution in this problem? ${\displaystyle k\mapsto 1-I_{p}(k+1,\,r),}$ the regularized incomplete beta function","['statistics', 'probability-distributions', 'probability']"
3978417,"Does $G$ being a subgroup of $GL(n, \mathbb Z/p\mathbb Z)$ for all odd primes $p$ imply it is a subgroup of $GL(n, \mathbb{Z})$?","It is known that any finite subgroup of $GL(n, \mathbb{Z})$ is isomorphic to a subgroup of $GL(n, \mathbb Z/p\mathbb Z)$ for any odd prime $p$ (see here ). I am wondering if there is a converse to to this: Does $G$ being isomorphic to a subgroup of $GL(n, \mathbb Z/p\mathbb Z)$ for all odd primes $p$ imply it is isomorphic to a subgroup of $GL(n, \mathbb{Z})$ ? If this does hold, I'd be curious if it could be strengthened (perhaps being a subgroup for any infinite set of primes, or all but finitely many primes, would work), and if it doesn't, I'd be curious if any weaker form could be salvaged.","['group-theory', 'linear-groups', 'finite-groups']"
3978490,What can we say about $\frac{1}{2(1-z)}-\sum_{n=0}^\infty\{n\sqrt{2}\}z^n$ in the vicinity of $z=1$?,"Let $\{x\}$ denote the fractional part of $x$ , what can we say about $$\frac{1}{2(1-z)}-\sum_{n=0}^\infty\{n\sqrt{2}\}z^n$$ in the vicinity of $z=1$ ? It seems that there is no limit, but the partial sums seem bounded.","['complex-analysis', 'ergodic-theory', 'asymptotics']"
3978521,If $a_n \rightarrow a$ Then $\frac{1}{n} \sum_{k=1}^{n} a_k \rightarrow a$,"If $a_n \rightarrow a$ as $n \rightarrow \infty$ , then can we say that $\frac{1}{n} \sum_{k=1}^{n} a_k \rightarrow a$ as $n \rightarrow \infty$ ? If we consider $\frac{1}{n} \sum_{k=1}^{n} a_k$ as average of terms, it seems obvious intuitively. But how can I prove it rigorously? My idea was followings: Since $a_n \rightarrow a$ , given arbitary $\epsilon>0$ , there is some $N$ s.t. $n \geq N \implies \lvert a_n-a\rvert<\epsilon$ \begin{align}
\left\lvert\frac{1}{n} \sum_{k=1}^{n} a_k-a\right\rvert & \leq \frac{1}{n} \sum_{k=1}^{N} \lvert a_k-a\rvert + \frac{1}{n} \sum_{k=N+1}^{n} \lvert a_k-a\rvert \\ &\leq \frac{1}{n} \sum_{k=1}^{N} \lvert a_k-a\rvert + \frac{n-N-1}{n}\epsilon \\& \leq \frac{2}{n}A + \frac{n-N+1}{n}\epsilon
\end{align} where $A = \sup a_n <\infty$ as $a_n$ converges. Then by letting $n \rightarrow \infty$ gives \begin{equation}
\left\lvert \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{k=1}^{n} a_k-a\right\rvert \leq \epsilon
\end{equation} for arbitary $\epsilon$ , so our claim is proved. Is there any non-rigorous part or wrong in my proof? (I'm a beginner at analysis.)
Thanks","['solution-verification', 'sequences-and-series', 'real-analysis']"
3978574,When do homotopies have continuous measure?,"Let $X$ be a topological space and $h:X\times[0,1]\to\mathbb{R}^n$ be a homotopy. I am interested in the function $m:[0,1]\to\mathbb{R}_+$ given by $t\mapsto\lambda(\textrm{range}(h_t))$ . Specifically, under what conditions is $m$ continuous? I have proven that if $X$ is compact, then $m$ is upper-semicontinuous, but have come up with an example with each $h_t$ injective that is not lower semi-continuous. I have proven that if $X$ is an open subset of $\mathbb{R}^n$ and each $h_t$ is injective then $m$ is lower-semicontinuous, but have come up with an example with each $h_t$ injective and differentiable that is not upper-semicontinuous. Putting these and differentiable functions preserving measure zero sets together we have that if $X$ is a compact subset of $\mathbb{R}^n$ with $\lambda(\partial X)=0$ and each $h_t$ is injective and differentiable, then $m$ is continuous, but that is the best I've been able to do. I suspect that the injectivity condition could be dropped there, but any reasonable condition for continuity would be nice. EDIT: I’ve realised that if $X$ is a compact subset of $\mathbb{R}^n$ with $\lambda(\partial X)=0$ and $h$ is $C^1$ then $m$ is continuous.","['measure-theory', 'homotopy-theory']"
3978649,Person X and Y throw a Fair die one after another. Whoever throws 6 first wins. What is the probability that X wins? [duplicate],"This question already has answers here : Alternate moves, first one to roll a 6 wins: what's the probability of winning? (3 answers) Closed 11 months ago . Two people take turns rolling a fair die. Person $X$ rolls first, then
person $Y$ , then $X$ , and so on. The winner is the first to roll a $6$ . What is the
probability that person $X$ wins? Our teacher in class solved this question as follows: Probability of winning in 1st round = Probability that 6 occurs = 1/6 So Probability of $Y$ losing in first round becomes $= 5/6$ Where it is assumed that X starts the game. suppose if X throws and if 6 comes then the game will stop and X will win. but if X loses then Y will throw the die (here Y will have to lose because according to question we want X to win the game) and then X will throw . and so on. it will be like $$X+ \neg X\neg YX+ \neg X\neg Y\neg X\neg YX+\dots$$ HERE $X$ denotes X wins and $\neg X$ means X loses i.e. 6 does not come . similarly $\neg Y$ means Y loses. This will form an infinite geometric progression series. Converting into probabilities we have $$(1/6) + (5/6)(5/6)(1/6) + (5/6)(5/6)(5/6)(5/6)(1/6)+ \dots$$ The sum of this geometric series is the answer. MY question is:
how the probability of $X$ in $2nd$ toss is $(5/6)(5/6)(1/6)$ and similarly in the following tosses? Why these terms are in multiplication not addition?","['dice', 'probability']"
3978681,Characteristic polynomial of a A agrees with its minimal polynomial if and only if all matrices that commutes with A is a polynomial of A,"Let $A \in \mathcal{M}_n (\mathbb{C})$ . Over $\mathbb{C}$ , show that the following two statements are equivalent: Characteristic polynomial of a $A$ agrees with its minimal polynomial; All matrices that commutes with $A$ is a polynomial of $A$ . For 1 > 2, from 1 I can only get that $A$ has a Jordan canonical form that each eigenvalue has only one Jordan block (i.e. maximum size), and I have no idea afterwards. 2 > 1 is a complete no-go for me. Any hints or solutions are appreciated.","['matrices', 'jordan-normal-form', 'linear-algebra', 'characteristic-polynomial']"
3978689,"$ \mathcal{F}_n = \sigma(\{0\},\{1\},\{2\}, \dots , \{n\})$ showing $\cup_{n\geq0} \mathcal{F}_n $ is not a sigma algebra, do not understand.","Isn't this countable union equal to the sigma algebra generated by the singletons of the natural numbers, which is the class of subsets of the natural numbers where the set is either or countable or its complement is countable. And we know that this class IS a sigma algebra. So isn't saying this isn't a sigma algebra a contradiction.","['measure-theory', 'real-analysis']"
3978696,Showing equality based on 2 equations,Having the following equations: $h_1 + l_2 = 3^n = l_1 + h_2$ and $l_1 + h_1 = l_2 + h_2$ we are supposed to infer that $h_1 = h_2$ and $l_1 = l_2$ I can prove it as follows: $l_1 + h_1 = l_2 + h_2$ $l_1 + 3^n - l_2 = l_2 + 3^n - l_1$ $l_1 - l_2 = l_2 - l_1$ $2l_1 = 2l_2$ $l1 = l2$ And then: $h_1 + l_2 = 3^n$ $h_1 = 3^n - l_2 = 3^n - l_1$ (since $l_1 = l_2$ ) $h2 = 3^n - l_1$ Hence $h_1 = h_2$ Is my approach correct? I have a feeling that there is a shorter way to do the inference that I am missing,"['algebra-precalculus', 'systems-of-equations', 'discrete-mathematics']"
3978828,"Given a triangle $ABC$ and its incenter I. If $P,Q$ are points on BI and CI so that $2PAQ=BAC$. Prove that $PDQ=90$","Given a triangle $ABC$ and its incenter I. If $P,Q$ are points on $BI$ and $CI$ so that $2\angle PAQ=\angle BAC$ . If $D$ is the point where the inscribed circle of $ABC$ intersects $BC$ , prove that $\angle PDQ=90$ . If $X\in BI$ we state $f(X)$ is the only point on $CI$ which is collinear with $A$ and is the points which becomes of X if we rotate $X$ around $A$ by angle $\frac{1}{2}\angle ABC$ . Hence $f(P)=Q$ .  We also have that $f(B)=I$ and $f(I)=C$ . Also if $I_1$ and $I_2$ the incenter of $\triangle ABD, \triangle ACD$ respectively then $f(I_1)=f(I_2)$ This is as far as I got. I believe it should be able to finish like this, but I've gotten stuck. Could you please help me finish it off?","['euclidean-geometry', 'triangles', 'angle', 'geometry']"
3978833,"For any $S \subseteq \mathbf{R}$, if $\partial S$ denotes the boundary of $S$, prove that $\partial(\partial S) \subseteq \partial S$.","I am self-learning Real Analysis from Understanding Analysis by Stephen Abbott. I learnt the trick of constructing a $\delta$ -neighborhood of a random point $y \in (x - \epsilon, x+ \epsilon)$ to always reside in this $\epsilon$ -neighborhood of $x$ . I tried to write a proof for the below assertion, and would like to ask if my proof checks out. For any $S \subseteq \mathbf{R}$ , if $\partial S$ denotes the boundary of $S$ , prove that $\partial(\partial S) \subseteq \partial S$ . My Attempt . Let $x$ be an element of $\partial(\partial S)$ . By definition of the boundary of a set $S$ , for every $\epsilon > 0$ , the open interval $(x - \epsilon, x + \epsilon)$ contains at least one element of $\partial S$ and at least one element of $(\partial S)^C$ . We are interested to prove that, $\forall \epsilon>0$ , the open interval $(x - \epsilon, x + \epsilon)$ contains at least one element of $S$ and at least one element of $S^C$ . Pick an arbitrary element $y \in (x - \epsilon, x + \epsilon)$ , such that $y \in \partial S$ . Then, for every $\delta > 0$ , the open interval $(y - \delta, y + \delta)$ contains atleast one element of $S$ and atleast one element of $S^C$ . If we choose, \begin{align*}
\delta = \delta_0 = \min \left\{\frac{y - (x-\epsilon)}{2},\frac{(x + \epsilon) - y}{2}\right\}
\end{align*} Then, $(y - \delta_0,y + \delta_0) \subseteq (x - \epsilon, x + \epsilon)$ . So, we found a small $\delta_0$ -neighborhood, $(y - \delta_0,y + \delta_0)$ inside of $(x - \epsilon, x + \epsilon)$ , which contains at least one element of $S$ and at least one element of $S^C$ , for all $\epsilon>0$ . Consequently, we have shown that, $\forall \epsilon > 0$ , $(x - \epsilon, x + \epsilon)$ contains at least one element of $S$ and at least one element of $S^C$ . So, $x \in \partial S$ . Hence, $\partial(\partial S) \subseteq \partial S$ . This closes the proof.","['general-topology', 'solution-verification', 'real-analysis']"
3978837,"How many ways to arrange 5 different dogs, 1 cat and 1 rat such that the rat is always left to the cat (not necessarily near).","How many ways to arrange 5 different dogs, 1 cat and 1 rat such that the rat is always left to the cat (not necessarily near). I started out by arranging the 5 different dogs which is $5!$ , and from here basically I got stuck, I tried to do it by cases, like if I arranged the 5 dogs, I have 6 places to put the cat in,starting from the right, the rat also can be put in 6 places (can be near the cat from the left), and moving one to the left each case, so I got: $6*6+5*5+4*4+3*3+2*2+1*1=91$ and this multiplied by the number of ways to arrange the dogs gave me the answer: $91*5!=10920$ , now this seems clearly wrong and I messed up since $7!=5040$ , which is the number of ways to arrange all seven, I am trying to understand my mistakes and how to deal with this question. Thanks in advance to any help.","['permutations', 'combinatorics', 'discrete-mathematics']"
3978915,"Find a function $f(x)$ on $(0,\infty)$ with arclength $(x+1)^2$","Give an analytic definition for a function $f(x)$ defined on $(0,\infty)$ for which the arclength from $0$ to $d$ is always $(d+1)^2$ . I’m generally pretty competent with calculus, and I think that my setup ought to be $$(d+1)^2=\lim_{a\to 0^+}\int_a^d \sqrt{1+f’(x)^2}dx$$ But I’m kind of lost as to how to actually evaluate this. For one thing, I know that the arclength integral usually has no “nice” antiderivative, but I don’t think that’s a problem because I’m just asking about a case in which it does . Next, I think the function has some sort of vertical asymptote at $0$ (because at $x=\varepsilon$ for $\varepsilon$ arbitrarily close to $0$ , the arclength is already $(1+\varepsilon)^2>1$ , and in particular $>\varepsilon$ ). Otherwise, I’m pretty much stumped. I could maybe take the derivative of both sides? But then I don’t know how to show that the derivative necessarily commutes inside the limit, and I’m not sure what to do with what would come out of that anyway. I got this question by modifying a similar one asked on a math LinkedIn group that asked about arclength $d^2$ , for which I noted that the arclength would by shorter than that of a straight line for $0<x<1$ , so no such function could exist. But I’m pretty sure no similar argument would work for this function because $(x+1)^2>x$ (and in particular $(x+1)^2\not<x$ ) for all real $x$ . Any help or even hints would be appreciated. Thanks!","['calculus', 'functions', 'arc-length']"
3978919,Prove that: $ \sum_{i=0}^{\infty} \frac{\tan \frac{\theta}{2^i}}{2^i}= \frac{1}{\theta} - 2 \cot 2 \theta$,"My attempt: Consider the following series: $$ S = \sum_{i=0}^n \ln( \sec \frac{x}{2^i} )$$ Notice that $ \lim_{n \to \infty} \frac{dS}{dx}$ is the required sum. Simplfying S, $$ S = - \ln \left(  \cos x \cdot \cos \frac{x}{2} ... \cos \frac{x}{2^n} \right)$$ or, $$ S = - \ln \left(  \frac{ \sin(2x)}{2^{n+1} \sin (\frac{x}{2^n})} \right)= \ln(2^{n+1}) + \ln( \sin \frac{x}{2^n}) - \ln( \sin(2x) )$$ Now, $$ \frac{dS}{dx}  = \frac{1}{2^n} \cot \frac{x}{2^n} - 2 \cot(2x)$$ The problem I'm having is proving that $$ \lim_{ n \to \infty} \frac{1}{2^n} \cot \frac{x}{2^n} = \frac{1}{x}$$","['limits', 'sequences-and-series']"
3978959,"How to determine shape of level curves of $V(y,z)= \ln{ \left( \frac{y^2 + (z+z_o)^2}{y^2 + (z-z_o)^2}\right)} $?","Context: I expect that a circle will be written as $$R^2 = (x-a)^2 + (y-b)^2,$$ where $R$ is the radius, and $(a,b)$ is the center of the circle. Question: How to determine analytically that the level lines of $$V(y,z)=  \ln{ \left(  \frac{y^2 + (z+z_o)^2}{y^2 + (z-z_o)^2}\right)}$$ are circles?","['multivariable-calculus', 'visualization']"
3978969,Difference of induction and divide and conquer,"I have seen that induction and divide and conquer are used as problem solving techniques but they are treated either as something different or the former as a way to support the latter. To me it seems that they are both exactly the same thing i.e. defining the problem in a way that has (can be composed of) smaller instances of the same original problem, having a base case and a way to build a solution for instance $n  + 1$ having the solution to instance $n$ . So in my understanding they (induction and divide and conquer) are exactly the same thing/exactly the same problem solving approach or at least different terms for the same thing/topic . Am I misunderstanding something? If yes what is the difference I am overlooking? If not why are they treated as different things in texts?","['puzzle', 'discrete-mathematics', 'algorithms', 'induction', 'problem-solving']"
3978982,Is the space of real analytic functions a freely generated algebra?,"Let us consider the space $C^{\omega}(\mathbb{R})$ of all the functions $f \colon \mathbb{R} \to \mathbb{R}$ which are analytic on the whole real line. It is clear that $\mathcal{C}^\omega(\mathbb{R})$ is an algebra, because it is closed under addition, multiplication by scalars and inner multiplication. However, is it true that $\mathcal{C}^\omega(\mathbb{R})$ is freely $\mathfrak{c}$ -generated? That is: Is there a set $S \subseteq \mathcal{C}^\omega(\mathbb{R})$ of cardinality $\mathfrak{c}$ such that the algebra generated by $S$ is $\mathcal{C}^\omega(\mathbb{R})$ and whenever a polynomial $P \in \mathbb{R}[X_1, \dotsc, X_p]$ with $P(0, \dotsc, 0) = 0$ satisfies $P(s_1, \dotsc, s_p) = 0$ for some $s_1, \dotsc, s_p \in S,$ then $P = 0?$ If so, how can it be proven?",['real-analysis']
3979012,Number of elements of order $p$ in a (possibly infinite) group,"If a group is finite, then it's easy to see by group action that $n_p\equiv-1\pmod p$ . However, is the result true for an infinite group? My conjecture is that if $n_p$ is non-zero and finite, then $n_p\equiv-1\pmod p$ of infinite groups. I proved the result for $n_2$ , but don't know whether it is true for all primes.","['group-theory', 'infinite-groups']"
3979026,"Compute $\iint_D (x^4-y^4) \,dx\,dy$","How should I proceed? the question is : $$\iint_D (x^4-y^4) \,dx\,dy$$ $$D= \left\{(x,y):1<x^2-y^2<4, \quad \sqrt{17}<x^2+y^2<5,\quad x<0,\ \  y>0\right\}$$ I've tried to solve it with change of variable: $$u=x^2-y^2, \quad v=x^2+y^2$$ $$|J|=\frac{1}{8xy}, \quad \frac{1}{8}\iint uv\frac{1}{xy} \,du\,dv$$ How should I proceed? Any suggestion would be great, thanks","['integration', 'multivariable-calculus', 'multiple-integral']"
3979029,There exists a differentiable function for which $f'\left(x\right)=\begin{cases} \frac{\cos x-1}{x^{2}} & x\ne0\\ 1 & x=0 \end{cases}$,"Prove or disprove: There exists a differentiable function for which $$f'\left(x\right)=\begin{cases} \frac{\cos x-1}{x^{2}} & x\ne0\\ 1 & x=0 \end{cases}$$ My way : False. Assume towards a contradiction that there exists such function. Then we have: $$f'\left(0\right)=1$$ $$f'\left(2\pi\right)=0$$ By Darboux's theorem, there exists $$0<c<2\pi$$ such that: $$f'\left(c\right)=\frac{1}{2}$$ Thus: $$f'\left(c\right)=\frac{1}{2}=\frac{\cos c-1}{c^{2}}\Rightarrow$$ $$\cos c=1+\frac{c^{2}}{2}>1$$ Contradiction! . My question is - would it been easier to disprove by integrating and trying to find the original function? Even if not, could I see the shortest method on this case please? Thank you.","['integration', 'calculus', 'solution-verification', 'trigonometry', 'derivatives']"
3979039,Finding the intersection of 3 sets when given all information (except the intersection),"Info: 104 students were asked if they like math, science or humanities. 35 don't like either 21 students like math only 17 students like science only 4 students like humanities only 15 students like math and humanities 13 students like math and science 17 students like humanities and science Question: how many students like all three subjects? Work: I'm not even sure what the formula is for finding n(A∩B∩C) is. But when I used the following formula, this is what I got: formula: n(A∩B∩C) = n(A) + n(B) + n(C) - n(A∪B∪C) established facts: where n(A) = 49 (21 + 13 + 15) where n(B) = 47 (13 + 17 + 17) where n(C) = 36 (15 + 17 + 4) where n(A∪B∪C) = 69 (104 [total] - 35 [neither]) substitution: n(A∩B∩C) = 49 + 47 + 36 - 69
n(A∩B∩C) = 132 - 69
n(A∩B∩C) = 63?! Could someone please let me know what I am doing wrong?? Or if there is a formula that is applicable to this particular situation (missing intersection) could someone please let me know of that??
Because the intersection cannot be 63...","['combinatorics', 'discrete-mathematics']"
3979059,Proof that $\mathbb{R}$ is not countable,"I know that this proof may sound ridiculous, but I'm really curious to find out if it's logically correct(and whether there are some circularities). Since $|[0,1]|=|\mathbb{R}|$ , we have  to simply show that $[0,1]$ is not countable. This theorem holds: $f:[a,b]\to \mathbb{R} \\ \text{Let } D_f \text{ be the set of discontinuities of }f \\ |D_f|\leq\aleph_0 \Rightarrow f \text{ is Riemann-integrable in }[a,b] $ Now I can define the Dirichlet function in $[0,1]$ : $\chi(x)=\begin{cases} 1 \ \ \text{if }x\in\mathbb{Q} \\ 0 \ \ \text{otherwise} \end{cases}$ Clearly $D_\chi=[0,1]$ . By contradiction, if $|[0,1]|=\aleph_0$ , then it would mean that $\chi$ is Riemann-integrable in $[0,1]$ , but it's not: this is a contadiction! So $|[0,1]|>\aleph_0$ .","['integration', 'real-numbers', 'cardinals', 'real-analysis', 'continuity']"
3979138,"Determine if $f$ is differentiable, and computing $f '(x)$","I would like to know if I did this correctly: Let $$f(x)=\left\{\begin{matrix}
\frac{\sin(x^2)}{x} & x \ne 0\\
0&x=0
\end{matrix}\right. , x_{0}=0$$ So $$f'(x)=\lim_{x \to 0}\frac{f(x)-f(0)}{x-0}=\lim_{x \to 0}\frac{\frac{\sin(x^2)}{x}-0}{x-0}=\lim_{x \to 0}\frac{\sin(x^2)}{x^2}=\lim_{t \to 0}\frac{\sin(t)}{t}=1$$ Is that correct? I didn't use the part that $f(x)=0$ if $x=0$ so I think that I'm missing something here. Thanks a lot!","['limits', 'calculus', 'solution-verification', 'derivatives']"
3979160,Probability: Shoes in a row,"20 shoes, from 10 pairs of shoes, are lined randomly. What is the
probability that there is a set of 10 consecutive shoes with 5 shoes
left and 5 right shoes? I thought that would be a good idea imagine 10 shoes as one unique object, as follow:
Instead enumerate 20 objects, let's separate 10 shoes and think them as another object (call it X), so that there is 11 in total. There is 11! ways to permute each objects. The problem is to know how to count X. I mean, the first way i thought was: $|X| = \frac{10!}{5!}\frac{10!}{5!}$ , so that the answer would be: $\frac{\frac{10!}{5!}\frac{10!}{5!}*11!}{20!}$ . But so i realized that |X| that i counted was wrong, what actually i counted for |X| was counting first the 5 possible right shoes, and after this, the 5 possible let shoes. So i am stuck in how to count |X| right. I thought that we could first choose $C_{10,5} = 10!/(5!5!)$ right shoes, $C_{10,5}$ left shoes. Now the probability for one aleatory choice of X is: $\frac{\frac{10!}{5!}*11!}{20!}$ , but X have more than one option, so the probability will be the sum of all possibility for X,
namely $C_{10,5}*C_{10,5}*\frac{{10!}*11!}{20!}$ . But this is greater than 1 (...), i have no idea what to do now.","['combinatorics', 'probability']"
3979179,Surface in $\mathbb{R}^3$ implicitely defined by a $C^1$-function is locally similar to $xy$-plane,"Let $F:\mathbb{R}^3\to \mathbb{R}$ be a $C^1$ -function and suppose that $(dF)(x,y,z)\not=0$ wherever $F(x,y,z)=0$ . Call $$O = \{(x,y,z)\mid F(x,y,z)=0\}.$$ Then, for every point $p\in O$ , there is an open neighborhood $V\subseteq \mathbb{R}^3$ of $p$ and an open neighborhood $U\subseteq\mathbb{R}^3$ of $(0,0,0)$ and a bijective $C^1$ -map $\varphi:U\to V$ with a $C^1$ -inverse such that $\varphi(U\cap(\mathbb{R}^2\times\{0\}))=V\cap O.$ Proof: Choose an arbitrary point $p\in O$ . We first note that the rank of $(dF)(p)$ is $1$ , since $(dF)(p)$ is a $1\times 3$ non-zero matrix. Hence, since it only has one row, it has full rank i.e it has rank $1$ . Now it is possible to parameterize $O$ with a $C^1$ -map $$g:U_0\subseteq \mathbb{R}^2\to \mathbb{R}^3$$ such that $g(0,0) = p$ , where $U_0\subseteq \mathbb{R}^2$ is an open neighborhood of $(0,0)$ and $V_0\subseteq \mathbb{R}^3$ is an open neighborhood of $p$ and $g(U_0)=V_0\cap O.$ Since $F$ is $C^1$ , so too is $g$ . We now define the map $$\tilde{\varphi}:U_0\times\mathbb{R}\to\mathbb{R}^3:(x,y,z)\mapsto g(x,y)+(z,z,z).$$ It is easily verified that for all $(x,y,z)\in U_0\times \mathbb{R}$ , the total derivative $(d\tilde{\varphi})(x,y,z)$ is invertible and that $\tilde{\varphi}$ is a $C^1$ -map. The inverse function theorem now tells us that there are open neighborhoods $U\subseteq U_0\times\mathbb{R}$ of $(0,0,0)$ and $V\subseteq \mathbb{R}^3$ of $p=\tilde{\varphi}(0,0,0)$ such that $\tilde{\varphi}\mid_U:U\to V$ is $C^1$ -bijection with a $C^1$ -inverse. Call this restriction $\varphi$ . Then it is easily seen that $\varphi(U\cap(\mathbb{R}^2\times\{0\}))=V\cap O$ . Could someone verify if this proof is correct?","['solution-verification', 'inverse-function-theorem', 'analysis', 'differential-geometry']"
3979260,Proving $n\leq3^{n/3}$ for $n\geq0$ via the Well-Ordering Principle [2],"I know this question was already asked in here , but it was never marked as answered and all the solutions base themselves on the fact that $3(m-1)^3 < m$ , what comes from assuming $3^m < m$ and it's not clear to me. I tried multiple ways to understand why this assumption was made, but I can't figure it out. My first assumption was that since $m \in S$ it's true that: $m > 3^{m/3}$ and by consequence: $m^3 > 3^{m}$ but it still does not prove $3^m < m$ . Any help is very appreciated.","['well-orders', 'proof-writing', 'natural-numbers', 'discrete-mathematics', 'induction']"
3979264,"If a polynomial $P$ has only real roots, so does $P'-2xP$",Let $P$ be a polynomial such that all of the roots of $P$ are real. Prove that all the roots of $P'-2xP$ are also real. I know a proof for this fact but it is very computational and messy. Is there an elegant solution?,"['roots', 'polynomials', 'real-analysis']"
3979275,Is $A$ countable or uncountable?,"Let $A=\{0,1\}^\mathbb{N}$ , that is the set of all functions from the natural numbers to the set $\{0,1\}$ . Is $A$ countable or uncountable? Prove your answer. $\textbf{Proof:}$ Let $A = \{0,1\}^\mathbb{N}$ . Let $f: \mathbb{N} \rightarrow A$ . Define $\overline{a} = \{\overline{a_1}, \overline{a_2}, \overline{a_3},...\}$ where $\overline{a_1} = \{a_{11}, a_{12}, a_{13}, ...\}$ , where $a_{11} = 0 \, \text{or} \, 1$ , $a_{12} = 0 \, \text{or} \, 1$ , ... . . . Pick $\overline{a_n} = \{a_{11}^c, a_{22}^c, a_{33}^c, ... \}$ . So if $a_{11} = 1$ , then $a_{11}^c = 0$ , ... Then $\nexists n \in \mathbb{N}$ such that $f(n) = \{ a_{11}^c, a_{22}^c, ...\}$ because $\{a_{11}^c, a_{22}^c, ...\} \subset A$ , but each element $a_{11}^c, a_{22}^c, ...$ is not mapped by any $n \in \mathbb{N}$ since the compliment does not follow $f(1) = \overline{a_1} = \{a_{11}, a_{12}, ...\}$ $f(2) = \overline{a_2} = \{a_{21}, a_{22}, ...\}$ Thus, $\nexists$ surjection $f: \mathbb{N} \rightarrow A$ . $\therefore A$ is uncountable.","['elementary-set-theory', 'solution-verification']"
3979288,Is $B$ countable or uncountable?,"Let $B=\mathbb{Z}^{\{0,1\}}$ , that is the set of all functions from the set $\{0,1\}$ to the integers. Is $B$ countable or uncountable? Prove your answer. $\textbf{Proof:}$ Let $B = \mathbb{Z}^{\{0,1\}}$ . $\forall f \in B$ , $f \leftrightarrow (a,b) \in \mathbb{Z} \times \mathbb{Z} \implies f(0)=a \in \mathbb{Z}$ , $f(1)=b \in \mathbb{Z} \times \mathbb{Z}$ Surjectivity: $\forall (a,b) \in \mathbb{Z} \times \mathbb{Z} \,\, \exists f$ such that $f(0)=a$ , $f(1)=b$ Injectivity: If $(a_1,b_1) = (a_2,b_2)$ , then $a_1 = a_2$ and $b_1 = b_2$ where $f(0)=a_1$ and $f(1)=b_1$ $\forall (a,b) \in \mathbb{Z} \times \mathbb{Z}$ $\therefore \, \exists$ bijection $f \leftrightarrow \mathbb{Z} \times \mathbb{Z}$ . $\mathbb{Z} \times \mathbb{Z}$ is countable by using the map $f((0,0))=1$ , $f((1,0))=1$ , $f((1,1))=2$ , $f((0,1))=3$ , and so on (this can be seen as spiraling the lattice points of $\mathbb{R}^2$ ) where $f:\mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{N}$ . $\therefore B$ is countable. $\blacksquare$","['elementary-set-theory', 'solution-verification']"
3979363,How to show that $D_{f}$ is a Borel function,"How to show that $D_{f}$ is a Borel function. Well I have one Lipschitz function $f:\Bbb{R}^{n}\to \Bbb{R}$ and I want to proof that $D_{f}:D\to L(\Bbb{R}^{n},\Bbb{R})$ is Borel function, where $D=\{ x\in \Bbb{R}^{n}: f'(x) \text{ exists in the Fréchet sense }\}$ I try with the definition to show that $\forall U$ Borel set in $ L(\Bbb{R}^{n},\Bbb{R})$ imply $D_{f}^{-1}(U)$ is Borel set. Then let $U$ Borel set in $L(\Bbb{R}^{n},\Bbb{R})$ hence $D_{f}^{-1}(U)=\{x\in \Bbb{R}^{n}: D_{f}(x)\in U\}$ but $D_{f}(x)$ is one linear transformation (using or not using Fréchet sense) so $D_{f}^{-1}(U)=\{x\in \Bbb{R}^{n}: T(x)\in U \}$ can to say : Like $T$ is continuous because is linear transformation then $D_{f}^{-1}(U)$ is measurable imply is Borel set?, can somebody help me please or give me one hint...thank you","['borel-sets', 'frechet-derivative', 'multivariable-calculus', 'lebesgue-measure']"
3979365,"Let $G$ be a group with center $Z<G$. Prove that if every element in $G\setminus Z$ has finite order, then $G$ is periodic.","Here we say that a group $G$ is periodic if every element of $G$ has finite order. $G$ needs not be abelian. Problem. Let $G$ be a group with center $Z<G$ . Prove that if every element in $G\setminus Z$ has finite order, then $G$ is periodic. My proof is as follows: Assume $z\in Z$ has infinite order. Select an element $a\in G\setminus Z$ . By construction, there exists some $b\in G\setminus Z$ such that $ab\neq ba$ . On the one hand, the element $za$ is not in the center as $$(za)b=z(ab)\neq z(ba)=(zb)a=(bz)a=b(za).$$ On the other hand, the element $za$ also has infinite order: Suppose $(za)^m=(za)^n$ . By assumption, $a$ has finite order, say $k$ , then we have $$(za)^{mk}=(za)^{nk}\implies z^{mk}a^{mk}=z^{nk}a^{nk}\implies z^{mk}=z^{nk},$$ contradicting the assumption that $z$ has infinite order. However, by assumption, since $za\in G\setminus Z$ , it should have finite order, giving a contradiction. Therefore, every element in the center $Z$ also has finite order and hence $G$ is periodic. $\square$ Hope anyone can help to check my proof. Different approaches are highly welcomed.","['group-theory', 'abstract-algebra', 'solution-verification', 'torsion-groups']"
3979368,"Prove that $f$ is differentiable on $[0,∞)$","Assuming that $e^x$ is differentiable on $\mathbb{R}$ , prove that $$f(x)=\begin{cases}\dfrac{x}{1+e^{1/x}},&x \neq 0\\ 0, &x=0\end{cases}$$ is differentiable on $[0,∞)$ . Is $f$ differentiable at $0$ ? Here is my textbook problem. when I asked some help from our madam she said that this is not differentiable on $[0,∞)$ it should be $(0,\infty)$ and she said $[0,∞)$ would be typo But I think she is wrong but I don't know exactly whether I am correct or not I know $|x|$ is not differentiable at $0$ but it is differentiable on $[0,\infty)$ or $(-\infty,0]$ Am I wrong?","['limits', 'derivatives', 'real-analysis']"
3979390,Is there a continuous transition between deterministic and stochastic?,"This is perhaps a more philosophical question. Hence, I'm looking for philosophical answers but more concrete ones or maybe directions to books or articles about it would also be of help. During my different studies in mathematics it seems like the field has always been separated into two branches: 'stochastic mathematics' and 'deterministic mathematics' (and after this, more branches). 'Stochastic' involves some sort of probability and we always deal with distributions. Deterministic however involves no randomness. Even though it logically seems right to completely separate these, I've wondered if there exists a continuous transition between the two. Just think of pseudo-random systems. Most computer programs dealing with stochastic values is actually not stochastic. Is it theoretically possible to make a pseudo-random process that ultimately becomes random? I don't know much about how to create pseudo-random processes - maybe that would be a point of departure towards an answer? What do you think? Are those two fields meant to be separated or does it make sense to ask my question?","['mathematical-modeling', 'probability']"
3979392,On the Hahn-Banach Theorem,"I just started a self-study of functional Analysis from ""Functional analysis, Sobolev spaces and partial differential equations"" by Haim Brezis. I struggle to understand the underlying assumptions for the proof of Hahn-Banach theorem on the extension of function. In brief, the theorem is written as follows Let $p : E \rightarrow \mathbb{R} $ be a Minkowski function. Let $G \subset E$ , $g : G \rightarrow \mathbb{R} $ such that $g \leq p $ is a linear function. Then there exists a linear function $f$ such that $f=g,  \forall x \in G $ and $f \leq p, \forall x \in E$ . The definition of a Minkowski is $1. p(\lambda x) = \lambda p(x) \forall \lambda > 0$ , $2. p(x+y) \leq p(x)+p(y)$ . My question is why we need the first strict condition for this theorem. Why any convex function does not work with the condition $p(\lambda x) \leq \lambda p(x), \forall \lambda \geq 1$ .","['hahn-banach-theorem', 'functional-analysis']"
3979476,Obtain the conditional distribution of $X$ given $X^2=t$,"Consider the model $X \sim N(\theta, 1)$ for $\theta \in \mathbb R$ . Obtain the conditional distribution of $X$ given $X^2=t$ for $t\ge 0$ . Hint: This is a discrete distribution. Current work: $f(X=x|X^2=t)=\displaystyle \frac{f(X=x, X^2=t)}{f(X^2=t)}=\frac{f(X=x, X^2=t)}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}=\frac{f(X=\sqrt t)}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}=\frac{\frac{1}{\sqrt {2\pi}}e^{-(\sqrt t-\theta)^2/2}}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}$ ? But this can't be right because there's no $x$ in the answer. What does one do here?","['conditional-probability', 'probability-distributions', 'normal-distribution', 'probability']"
3979499,A problem about a rank's inequality of a complex matrix,"Let $X,Y \in M_{n\times n}(\mathbb{C})$ such that $X^{2}=Y^{2}=I_{n}$ . Prove that $$\operatorname{rank}((X+I_n)(Y-I_n))+\operatorname{rank}((X-I_n)(Y+I_n))=\operatorname{rank}(X-Y)$$ My approach: Using the well-known inequality: $\operatorname{rank}(X)+\operatorname{rank}(Y)\geq \operatorname{rank}(X+Y)$ , we can see that $$\operatorname{rank}(X-Y)=\operatorname{rank}(X-XY+XY-Y)\leq \operatorname{rank}(X-XY)+\operatorname{rank}(XY-Y)$$ but, how can I continue from here?",['linear-algebra']
3979618,No of possible binary sequences with at most 2 consecutive zeroes,The problem: How many such sequences of ten $1's$ and ten $0's$ are possible such that they don't contain three or more consecutive zeroes? (Eg. $00101001001101110011$ ) I know there are $20!/10!10!$ total sequences. How do I filter out the ones which have more than two consecutive zeroes somewhere?,['combinatorics']
3979672,Interpreting the logarithm as a sum of simple poles along the negative real axis,"I've heard it remarked that you can basically consider $\log z$ to be a function which has simple poles everywhere on the negative real axis (with a constant ""residue density"" at each pole).  This would be something like $$ \log z = \int_0^\infty \frac{dx}{z + x} $$ But of course the integral on the right-hand side actually diverges.  We actually get $$ \int_0^\infty \frac{dx}{z + x} = \lim_{b \to \infty} \int_0^b \frac{dx}{z + x} = \lim_{b \to \infty} \left( \log(z + b) - \log(z) \right) = \infty $$ In physics, there are a variety of methods for subtracting out the divergent part of such a limit to get a finite answer (various flavors of regularization and renormalization ).  I'm wondering whether there is a standard approach here so that something similar can be done to ""rescue"" the first equation above from the divergent part of the integral. Another way of phrasing the problem above is that I showed that the Stieltjes transform of a constant on the interval $(-\infty, 0]$ does not exist.  But perhaps there is another density function $\rho$ so that $\log z$ is the Stieltjes transform of $\rho$ . $$ \log z = \int_0^\infty \frac{\rho(x)}{z + x} dx $$ What is $\rho$ ?  Well, the Stieltjes inversion formula says that it should be given by $$ \begin{align} \rho(x) &= \lim_{\epsilon \to 0} \frac{\log(x+i\epsilon) - \log(x-i\epsilon)}{2\pi i} \\ &= \frac{(\log |x| + \pi i) - (\log |x| - \pi i)}{2\pi i} \\ &= 1 \end{align} $$ But this gets me exactly back to the integral that I started with, which is divergent!  Hopefully I am just missing something obvious. Edit: Alternate statement of question There has been a lot of confusion in the comments below about what I am looking for, so let me restate it in a very narrow way.  I would be satisfied with either of the following: A sequence of meromorphic functions $f_n(z)$ with simple poles along the negative real axis with the following properties: a. The poles become dense in the limit $n \to \infty$ . b. $\lim_{n \to \infty} f_n(z) = \log z$ A proof that there is no such sequence.","['complex-analysis', 'divergent-integrals', 'integral-transforms', 'logarithms']"
3979700,Solving $\sin(r\cos\theta)=r\sin\theta$ for $r$,"So, I was trying to find the polar equation for a sine curve and here's what I did : Now, some assumptions that I've made here are : $\theta\in\left(0,\dfrac\pi2\right)$ and $C_x<\pi$ , where $C_x$ is the abscissa of $C$ . So, $\sin\theta=\dfrac{BC}{r}\implies BC=r\cdot\sin\theta$ and $\cos\theta=\dfrac{AB}{r}\implies AB=r\cdot\cos\theta$ . Also, if the length of $AB$ is $k$ units, then $$\sin(k~\mathrm{rads})=BC\quad\implies\quad\color{red}{\sin(r\cdot\cos\theta)=r\cdot\sin\theta}$$ which is the trigonometric equation that we need to solve. My knowledge of trigonometry is only limited to 11th grade and so far, I haven't been able to think of any way to approach this equation. Now, I don't have any formal education regarding polar coordinates and I am just trying to do this for fun, which means that my belief that solving for $r$ in terms of $\theta$ will give the equation of the sine curve when plotted in the polar plane might be wrong but I'm still fairly confident that at least the part of the sine wave lying in the interval $(0,\pi)$ will be plotted. I would greatly appreciate any help and hints, thank you!","['trigonometry', 'polar-coordinates']"
3979808,$\sum_{i\in I}\kappa_i$ vs. $\prod_{i\in I}\kappa_i$,"Let $I$ be an arbitrary set and $(\kappa_i)_{i\in I}$ a family of cardinals. What can be said about the relationship between $$\sum_{i\in I}\kappa_i \qquad\text{and}\qquad  \prod_{i\in I}\kappa_i\qquad?$$ I know that for $I=2$ , they are equal. But what if $I$ is an arbitrary set with at least two elements, does it always hold that $$\sum_{i\in I}\kappa_i\leq\prod_{i\in I}\kappa_i$$ or even $$\sum_{i\in I}\kappa_i=\prod_{i\in I}\kappa_i?$$ What else can be said?","['elementary-set-theory', 'logic', 'set-theory']"
3979875,Can $S_n=a_1a_2+a_2a_3+\cdots+a_na_1=0$ if $a_i=±1$ for $n=28$ and $n=30$?,"Let $$S_n=a_1a_2+a_2a_3+\cdots+a_na_1$$ If $a_i=\pm 1$ , can $S_{28}=S_{30}=0$ ? My approach: Start from small $n$ if we can see a pattern For $n=1$ : $S_1=a_1=±1 \neq0$ For $n=2$ : $S_2=a_1a_2+a_2a_1=2a_1a_2=±2 \neq0$ For $n=3$ : $S_3=a_1a_2+a_2a_3+a_3a_1$ Because $a_1a_2$ , $a_2a_3$ and $a_3a_1$ are odd numbers and $0$ is an even number, $S_3$ cannot be $0$ . (this can be applied to other $S_n$ if $n$ is an odd number) For $n=4$ : $S_4=a_1a_2+a_2a_3+a_3a_4+a_4a_1=(a_1+a_3)(a_2+a_4)$ However, I can't do the same with $n=6$ and above...","['algebra-precalculus', 'sequences-and-series']"
3979930,Estimate true probabilities from weighted sampling without replacement,"Suppose we have a random event with $n$ outcomes, with (unknown) true probabilities $p_1, p_2, \dots, p_n$ . We have performed a study of this event,  sampling it in batches of $k < n$ . From this we have found a good estimation of $q_i$ : the probability that outcome $i$ occurs in a batch of $k$ events. However, there is a crucial issue with our study. Each event $i$ can only occur once in a batch. Once an event $i$ has occurred, that event's probability becomes $0$ for the remainder of the batch (and the rest of the probability distribution normalized to sum to $1$ ). If we'd assume $\hat p_i = q_i$ then the most frequent outcomes are underestimated, and the lesser frequent overestimated. Can we do better, that is, find a good corrected estimate $\hat {\bf p}$ from $\bf q$ and $k$ ? Note that we don't know the order of the events within each batch, otherwise we could use the first event as an unbiased indicator. Nevertheless even if we did know the order within each batch it would be nice to also use the information in the events after the first in each batch effectively and correctly.","['independence', 'probability']"
3979935,Prove that $\int^1_0|f'(x)|dx \le 2\int^1_0 |f(x)|dx+\int^1_0|f''(x)|dx.$,"$f(x),f'(x),f''(x)$ are  continuous functions, $f(0)f(1) \ge 0$ , prove that $$\int^1_0|f'(x)|dx \le 2\int^1_0 |f(x)|dx+\int^1_0|f''(x)|dx.$$ This problem comes from here .","['integration', 'calculus', 'definite-integrals', 'integral-inequality']"
3979936,Two definitions of the injectivity radius,"For a Riemannian manifold $M$ , usually, the injectivity radius of $p \in M$ is defined by the supremum of positive numbers $r$ such that $\exp_p|_{B(0, r)}$ is a diffeomorphism onto the image. Here, $B(0,r)$ is the geodesic ball of radius $r$ . However, in Klingenberg's book, the injectivity radius is defined by by the supremum of positive numbers $r$ such that $\exp_p|_{B(0, r)}$ is injective . Are these two definitions equivalent? Considering the global rank theorem, I tried to prove the exponential map at $p$ is of constant rank, but it seems that this try does not work. In fact, Klingenberg frequently says that the exponential map is just injective instead of saying the map is a diffeomorphism. To guarantee that the exponential map at $p$ is a diffeomorphism on a geodesic ball, is it enough to show that it is injective? Thanks!","['riemannian-geometry', 'differential-geometry']"
3979981,"If $\frac{\cos x+\cos y+\cos z}{\cos(x+y+z)}=\frac{\sin x+\sin y+\sin z}{\sin(x+y+z)}=k$, then find $\cos(x+y)+\cos(y+z)+\cos(z+x)$. [duplicate]","This question already has answers here : Hard contest type trigonometry proof (3 answers) Closed 3 years ago . If $x,y,z \in\mathbb{R}$ and $$\frac{\cos x+\cos y+\cos z}{\cos \left(x+y+z\right)}=\frac{\sin x+\sin y+\sin z}{\sin \left(x+y+z\right)}=k$$ Find the value of $\cos(x+y)+\cos(y+z)+\cos(z+x)$ . I was working through this problem and found an interesting solution to it. How would you solve it? Edit: I found the same question here and here . So, this should be marked as duplicate.",['trigonometry']
3979992,Which Hecke algebra is used in representation theory?,"Which Hecke algebra is used in representation theory or more specifically in the study of Langlands's conjecture ? From here , the Hecke algebra is constructed from a locally compact topological group and its closed subgroup. While from here , the Hecke algebra is defined in terms of Hecke operators which are coming  from Modular forms. This makes me confused. Are the above two definition literally and mathematically equivalent ? If not, which one is used in the study of Local/Global Langlands's conjecture ? Any explanation will help me.","['number-theory', 'hecke-algebras', 'langlands-program', 'representation-theory']"
3980007,Determining all the possible values of $n$ under restrictions on number of factors of $n(n+2)(n+4)$,"Determine all positive integers $n$ such that the number $n(n+2)(n+4)$ has at most $15$ positive divisors. I wanted to verify my approach for the problem. It goes like this: My Approach: There can be two cases: Let $n$ be even. Now it is evident that $2|n$ , $2|n+2$ and $2|n+4$ This means that $2^3|n(n+2)(n+4)$ Since we have $3$ consecutive even numbers. It is evident that either $4|(n+2)$ , or $4|n$ and $4|n+4$ Suppose $4|(n+2)$ , this means that there would be one more factor of $2$ than the initial number dividing the number, thus $2^4|n(n+2)(n+4)$ It is also evident that $3|n(n+2)(n+4)$ So now $n(n+2)(n+4)=2^4\cdot 3\cdot p_1^{a_1}\cdot p_2^{a_2}\cdots p_r^{a_r}$ This means that $\tau (n(n+2)(n+4))=5\times 2\times (a_1+1)\times (a_2+1)\times \cdots \times (a_r+1)$ . Observe that if any of the $a_i\geq 1$ , then $\tau (n(n+2)(n+4))\geq 5\times 2\times 2>15$ . $\therefore $ All $a_i=0$ . Thus $n(n+2)(n+4)=2^4\times 3=48=2\times 4\times 6$ , which means that $\boxed{n=2}$ Suppose $4|n$ and $4|n+4$ , and since we have two consecutive factors of 4, one of them must be divisible by $8$ . Thus there are $3$ additional factors of $2$ in $n(n+2)(n+4)$ . So $n(n+2)(n+4)=2^6\cdot 3\cdot p_1^{a_1}\cdot p_2^{a_2}\cdots p_r^{a_r}$ Now using the same argument as used in the previous case, we know that $a_i=0$ for all $i$ . $\therefore n(n+2)(n+4)=2^6\times 3=4\times 6\times 8$ which means that $\boxed{n=4}$ . Let $n$ be odd. Now $3|n(n+2)(n+4)$ . Also any two of them taken in pair are relatively prime. Let $n(n+2)(n+4)=(3\times k)\cdot p_1^{a_1}\cdot p_2^{a_2}\cdots p_r^{a_r}\cdot q_1^{b_1}\cdot q_2^{b_2}\cdots q_s^{b_s}$ Now $k$ can be from the set $\{1, 3, 5,\ldots\}$ . Suppose $\tau (3k)\geq 4$ , then $\tau (n(n+2)(n+4))\geq 4(a_1+1)(a_2+1)\ldots (a_r+1)(b_1+1)(b_2+1)\cdots (b_s+1)$ We need $4(a_1+1)(a_2+1)\ldots (a_r+1)(b_1+1)(b_2+1)\cdots (b_s+1)\leq 15$ or $(a_1+1)(a_2+1)\ldots (a_r+1)(b_1+1)(b_2+1)\cdots (b_s+1)\leq 3$ . But there would be at least one $a_i>1$ and $b_i>1$ because the numbers not divisible by three are greater than 1. Thus $(a_1+1)(a_2+1)\ldots (a_r+1)(b_1+1)(b_2+1)\cdots (b_s+1)\geq 4$ which is contradictory. $\therefore \tau (3k)\leq 3$ . Now if $3\not | k$ and $k\neq 1$ , then it is evident that $\tau (3k)\geq 4$ which doesn't satisfy our conditions. $\therefore 3|k$ . Since $\tau(3k)\leq 3$ , the only possible values for $k$ are ${1,3}$ or $3k=3$ or $3k=9$ . Which means the triplets can be $(1,3,5), (3,5,7), (5,7,9), (7,9,11)$ and $(9,11,13)$ . This means that $\boxed{n=1,3,5,7,9}$ Considering both the cases together, we get $\boxed{n=1,2,3,4,5,7,9}$ Please check my approach for any mistakes. Also please provide an alternate solution less convoluted than this if possible. THANKS","['number-theory', 'functions', 'solution-verification']"
3980054,Which reflection groups contain central inversion?,"Question: Which finite irreducible reflection groups $\Gamma\subseteq\mathrm O(\Bbb R^d)$ contain the central inversion $-\mathrm{Id}$ , and how can this be spotted from the Coxeter diagram ? The following groups do not have central inversion: $I_2(n)$ for odd $n\ge 3$ , $A_d$ for all $d\ge 3$ , $D_d$ for odd $d\ge 3$ , and $E_6$ . I am not sure about $E_7$ and $E_8$ . All others do have central inversion.
The emphasize of my question is on the second part: is there combinatorial data in the Coxeter diagram from which to infer whether $-\mathrm{Id}\in\Gamma$ ?","['discrete-geometry', 'representation-theory', 'geometry', 'group-theory', 'symmetry']"
3980094,Slicing a bar in three pieces - probability,I have the following problem: If you split a bar of length 1 in three pieces by choosing two cut points randomly. What is the probability that the lenght of at least one of them is less than 1/5?. I think that $P(a<1/5)=P(1-b<1/5)=P(b-a<1/5)=1/5$ But now I am confused how to use this in the porpouse of compute the total probability. I would bet that 3/5 is the answer (because you either have that a<1/5 or 1-b<1/5 or a-b<1/5) but it is not crystal clear to me.,['probability']
3980162,"The subspace $C$ of the space $(X,d)$ is compact","Let: $(X,d)$ - complete metric space. $K_1,K_2,\dots $ - compact sets in the space $(X,d)$ (sequence $K_1,K_2,\dots$ need not be descending) $C_n=\{x\in X: \text{dist} (x,K_n)\le \frac 1n \}$ for $n=1,2,\dots$ $C=\bigcap\limits_{n=1}^{\infty} C_{n}\subset X$ Claim: The subspace $C$ of the space $(X,d)$ is compact My attempts: We want to show that $\bigcap\limits_{n=1}^{\infty} C_{n}$ is compact. Let's establish $V=\{ \bigcup\limits_{\alpha}:\alpha \in A\}$ - cover of $\bigcap\limits_{n=1}^{\infty} C_{n}$ . From this $V$ we want to choose finite subcover for $\bigcap\limits_{n=1}^{\infty} C_{n}$ . I think that we can use the total limitation of space $C$ with metric $d$ truncated to $C$ . However I don't have idea how I can do it.","['general-topology', 'metric-spaces', 'compactness']"
3980173,How can you solve this Bessel's equation?,"From what I've learned, the Bessel's equation in its standard form is $$x^2y''+xy'+(x^2+v^2)y=0\tag{1}$$ But, for example I have this equation $$x^2y''+xy'+\frac{1}{4}xy=0\tag{2}$$ How can you solve the 2nd equation by using the Bessel's standard form?","['special-functions', 'ordinary-differential-equations', 'bessel-functions']"
3980178,"Find $K_{3,4}$ subgraph in a graph","I'm trying to find $K_{3,4}$ subgraph in the following graph: I'm trying for hours however I can't find it. Can you please help me?","['graph-theory', 'discrete-mathematics']"
3980184,How to simplify $(\frac{\sin\alpha - \sin\beta}{\cos\beta -\cos\alpha})\cdot \cos\alpha \cdot \cos\beta$?,"There is this problem: $$\left(\frac{\sin\alpha - \sin\beta}{\cos\beta -\cos\alpha}\right)\cdot \cos\alpha \cdot \cos\beta = \frac{1}{\tan\alpha -\tan\beta}$$ I started as $$\left(\frac{\sin\alpha - \sin\beta}{\cos\beta -\cos\alpha}\right)\cdot \cos\alpha \cdot \cos\beta = \frac{\sin2\alpha \cos\beta-\sin2\beta \cos\alpha}{2(\cos\beta -\cos\alpha)}$$ but I'm stuck here, because I don't see how could I use $\sin(x-y)$ but also don't see how could I use any other identity without complicating this even more.",['trigonometry']
3980201,Show that this set is denumerable [duplicate],This question already has answers here : Prove that the set of integer coefficients polynomials is countable (3 answers) Closed 3 years ago . Let $A=\mathbb{Z}[x]_{deg\leq n}$ denote the set of all polynomials in $x$ with degree less than or equal to $n$ . Show that A is denumerable. I know that set of all polynomials with integer coefficients is countable but how can I prove this problem ?,['elementary-set-theory']
3980211,Want to verify my approach,"If repetition of digit is not allowed, then how many five digit numbers which are divisible by $3$ can be formed
using the digits? My approach is that i made 3 sets of digits according to the remainder they give on dividing by $3$ - $ A:(0,3,6,9)$ , $B:(1,4,7)$ , $C:(2,5,8)$ , Now the following cases are possible: Any $1$ digit from $A$ $+$ Any $2$ digit from $B$ $+$ Any $2$ digit from $C$ , Now $0$ should not come at Ten thousandths place So handling it in two subcases , when $0$ is chosen from $A$ $\big(1 \cdot {3 \choose 2} \cdot {3 \choose 2}\cdot4\cdot4\cdot3\cdot2\cdot1 \big) + $ when $0$ not chosen $\big({3 \choose 1} \cdot {3 \choose 2} \cdot {3 \choose 2}\cdot5\cdot4\cdot3\cdot2\cdot1 \big)$ Any $2$ digit from $A$ $+$ Any $3$ digit from $B$ $+$ Any $0$ digit from $C$ , Now $0$ should not come at Ten thousandths place So handling it in two subcases , when $0$ is chosen from $A$ $\big(1\cdot {3 \choose 1} \cdot {3 \choose 3} \cdot {3 \choose 0}\cdot4\cdot4\cdot3\cdot2\cdot1 \big) + $ when $0$ not chosen $\big({3 \choose 2} \cdot {3 \choose 3}\cdot5\cdot4\cdot3\cdot2\cdot1 \big)$ Any $2$ digit from $A$ $+$ Any $0$ digit from $B$ $+$ Any $3$ digit from $C$ , Now $0$ should not come at Ten thousandths place So handling it in two subcases , when $0$ is chosen from $A$ $\big(1 \cdot {3 \choose 1}\cdot {3 \choose 0} \cdot {3 \choose 3}\cdot4\cdot4\cdot3\cdot2\cdot1 \big) + $ when $0$ not chosen $\big({3 \choose 2} \cdot {3 \choose 3}\cdot5\cdot4\cdot3\cdot2\cdot1 \big)$ Any $3$ digit from $A$ $+$ Any $1$ digit from $B$ $+$ Any $1$ digit from $C$ , Now $0$ should not come at Ten thousandths place So handling it in two subcases , when $0$ is chosen from $A$ $\big(1 \cdot {3 \choose 2}\cdot {3 \choose 1} \cdot {3 \choose 1}\cdot4\cdot4\cdot3\cdot2\cdot1 \big) + $ when $0$ not chosen $\big({3 \choose 3} \cdot {3 \choose 1}\cdot {3 \choose 1}\cdot5\cdot4\cdot3\cdot2\cdot1 \big)$ . Total $= 9072$ pls verify my approach and answer, other methods will also be appreciated ,Thanks.","['solution-verification', 'combinatorics']"
3980216,Evaluating $\sum_{r=1}^{\infty} \cot^{-1}(ar^2+br+c)$,"Evaluate the series $$S=\sum_{r=1}^{\infty} \cot^{-1}(ar^2+br+c)$$ I have tried many values of $(a,b,c)$ and plugged into Wolframalpha, it always converges. I know that for particular values of $a,b,c$ , we solve it by forming a telescoping series by using the fact that $\displaystyle \arctan x-\arctan y=\arctan\left(\dfrac{x-y}{1+xy}\right)$ and converting it into a form $f(r+1)-f(r)$ . But I think that we cannot convert all types into this form. Even if this was possible, what is the way for us to know what $f$ to use? In particuar, I was evaluating $\displaystyle \sum_{r=1}^{\infty} \cot^{-1}\left(3r^2-r-\frac13\right)$ , but couldn't convert it into telescoping series. So, how then, do we solve this? and for what values of $(a,b,c)$ is the sum convergent?","['trigonometry', 'telescopic-series', 'sequences-and-series']"
3980233,Why does $\log^{100}(n)$ grow asymptotically slower than $n^{7/8}$,"More formally:
How do I compute the following limit: $$
\lim _{x \rightarrow \infty} \frac{\log ^{100}(x)}{x^{7 / 8}}
$$ I would start using l'Hôpital's rule and notice the pattern, is there some other procedure? (without knowing it)",['limits']
3980255,I solved the problem. But I have some doubts on the solution.,"Given the sequence $a_n = \sin(n)$ , where $n$ is an integer. Prove that limit superior is $1$ . My solution: by previous theorems we know that if $x,y \in \Bbb R$ and the ratio of $x$ and y is irrational, then there exists the integers $a$ and $b$ such that $$\forall \epsilon, \quad  0<ax+by<\epsilon$$ So we can put integrs $m$ ands $n$ such that $$0<\frac{n}{m}-\frac{\pi}{2}<\epsilon$$ And we are done. But here m should be in form of $m=4k+1,\, k\in \Bbb Z$ . My question is, how we can be sure that we can find such $m$ ?","['limits', 'sequences-and-series', 'real-analysis']"
3980267,Infinite strictly decreasing sequence of ordinals,"I know that on a linearly ordered set $X$ , $\leq$ is a well order if and only if $X$ contains no strictly decreasing sequence. However this conflicts in my head with the following problematic 'intuition' which I do not know where it fails. Let $\alpha$ be a limit ordinal such that $\alpha\geq \omega_1$ . All ordinals strictly less than $\alpha$ are a proper set and therefore we should not be able to find an infinite strictly decreasing sequence of ordinals. However since there uncountably many ordinals lesser than $\alpha$ , it seems like we should be able to choose a strictly decreasing sequence in some complicated way. Aside from this proposition, can someone explain to me why a decreasing sequence must stablize? I know there is probably some simple point which has not fully clicked for me.","['elementary-set-theory', 'ordinals', 'well-orders']"
3980305,Trinomial distribution conditional mean,"Let $(X_1,X_2)$ have the trinomial distribution with $n=5$ , $p_1=0.2$ , $p_2=0.3$ $f\left(x_1,x_2\right)=\frac{5!}{x_1!x_2!\left(5-x_1-x_2\right)!}\left(0.2\right)^{x_1}\left(0.3\right)^{0.3}\left(0.5\right)^{5-x_1-x_2}$ we want to find the conditional mean $E\left(X_2|X_1>0\right)$ . $\because X_2|X_1=x_1\sim Binomial\left(n-x_1,\ \frac{2}{7}\right)$ $ X_2|X_1=1\sim Binomial\left(4,\ \frac{2}{7}\right)$ $\Rightarrow E\left(X_2|X_1=1\right)=4\times \frac{2}{7}$ $X_2|X_1=2\sim Binomial\left(3,\ \frac{2}{7}\right)$ $\Rightarrow 
E\left(X_2|X_1=2\right)=3\times \frac{2}{7} $ $X_2|X_1=3\sim Binomial\left(2,\ \frac{2}{7}\right)$ $\Rightarrow 
E\left(X_2|X_1=3\right)=2\times \frac{2}{7} $ $X_2|X_1=4\sim Binomial\left(1,\ \frac{2}{7}\right)$ $\Rightarrow 
E\left(X_2|X_1=4\right)=1\times \frac{2}{7} $ $X_2|X_1=5=0 $ $\Rightarrow E(X_1|X_1=5)=0$ So $E\left(X_2|X_1>0\right)=\left(5-n\right)\times \frac{2}{7},\ n=1,2,3,4,5$ , is the answer correct?","['statistics', 'probability']"
3980309,Proof verification : Is my modified moduli problem still representable?,"I came across a moduli problem which looks very similar to another one appearing in a little lemma by Rapoport and Zink. I tried to prove that mine is also representable, but as a newbie in this topic I would appreciate some proof verification. Could somebody please confirm if what I wrote is correct ? Lemma 2.10 in Rapoport and Zink's book ""Period spaces for $p$ -divisible groups"" reads the following Let $S$ be any scheme and let $\alpha : \mathcal M \to \mathcal L$ be a morphism of $\mathcal O_S$ -modules, with $\mathcal L$ being finite and locally free. Let $F$ denote the functor from the category of $S$ -schemes to that of sets, sending an $S$ -scheme $T$ to the set $$F(T):= \{\phi \in \mathrm{Hom}(T,S) \,|\, \phi^*\alpha = 0\}$$ The functor $F$ is representable by a closed subscheme of $S$ . Here, $\phi^*\alpha$ denotes the morphism $\mathcal M_T \to \mathcal L_T$ induced by base change to $T$ . The proof is not that difficult. Because we have an isomorphism $$\mathrm{Hom}(\mathcal M,\mathcal L) \simeq \mathrm{Hom}(\mathcal M \otimes \mathcal L ^{*},\mathcal O_S)$$ where $\mathcal L^{*} := \mathrm{Hom}(\mathcal L,\mathcal O_S)$ , the morphism $\alpha$ corresponds to some $\tilde{\alpha}:  \mathcal M \otimes \mathcal L ^{*} \to \mathcal O_S$ . The image of $\tilde{\alpha}$ is a sheaf of ideals in $\mathcal O_S$ , which defines the desired closed subscheme. I am interested in the following similar moduli problem. Let $R$ be a DVR with maximal ideal $\mathfrak m$ . Let $S$ be any scheme over $R$ , and denote by $\overline S$ its special fiber, that is the fiber over $\mathfrak m$ . It is a closed subscheme of $S$ , defined over the field $R/\mathfrak m$ . Let $\overline{\alpha}:\overline{\mathcal M} \to \overline{\mathcal L}$ be a morphism of $\mathcal O_{\overline S}$ -modules, with $\overline{\mathcal L}$ being finite and locally free. Let $F$ denote the functor from the category of $S$ -schemes to that of sets, sending an $S$ -scheme $T$ to the set $$F(T):= \{\phi \in \mathrm{Hom}(T,S) \,|\, \overline{\phi}^*\alpha = 0\}$$ Here, $\overline{\phi}$ is the induced morphism $\overline T \to \overline S$ on the special fibers (the structure morphism $T\to \mathrm{Spec}(R)$ being given by means of $\phi$ ). Is $F$ representable by a closed subscheme of $S$ ? I believe the answer to be affirmative, for a simple reason : a composition of closed immersions is again a closed immersion. To be more precise, let $\overline F$ denote the same functor as in Rapoport and Zink's lemma, but over $\overline S$ . It is represented by a closed subscheme of $\overline S$ . Now, we may see it as a closed subscheme of $S$ as a whole, by composition of closed immersions. This should be our desired closed subscheme. Is everything ok with my statement and justification ?","['algebraic-geometry', 'solution-verification', 'schemes', 'moduli-space']"
3980313,"Equinumerous sets, power set","(ZF) Prove that for an arbitrary set A the following holds: $ \bar{A} = \bar{A ∪  [{A}]} ⇒ \bar{P(A)} =\bar{(P(A) ∪ [P(A)])}$ ; $ \bar{A} =  \bar{(A ∪ [A])} ⇒  \bar{P(P(A))} =  \bar{P(P(A) × P(P(A))} $ . What I have made so far is: By def, A and B are equinumerous if there is a bijection f: A->B. Let $ x  \subset A =>x \subset \bar{A ∪ {A}} $ . Then $ Dom(f) \subseteq A$ and $Rng(f) \subseteq \bar{A ∪  [{A}]} $ . Obviously this is injection since $x\subset A$ or $x \equiv sing A $ . But because $ x \in A \Rightarrow x\in P(A).$ But $f(x)\subseteq P(A)$ and $f(x)\subseteq A\Rightarrow f(x) \in P(A)\cup [A].$ Hence there is a function $g$ for which $g(f(x))$ is $P(A)\mapsto (P(A)∪[P(A)])¯  $ ;
And hence they are equinumerous. We know that $ (X)^(B∪C)=X^B×X^C $ . But afterwards I do not know what to do. With [x] I denote the singleton of the set x.
I am sorry for the syntax, but I am a beginner in Math Text Editors. I will be really thankful to anyone who share the ideas he/she has about the problem since I am stuck on it.
I tried to explain what I think that will be useful with the solution even though I am not quite sure what to do about 2.
Thanks in advance!","['elementary-set-theory', 'set-theory']"
3980315,Could exists a vector field on $\mathbb{S}^{2}$ with exactly $n$ zeroes?,"I just started to learn index theory of tangent vector fields. I'm aware of two examples on the sphere $\mathbb{S}^{2}$ with exactly one zero, which, which are $F(x,y) = (1-x^2-y^2)\partial x$ thought on $\mathbb{D}^2$ and then identify the boundary, I think it is And one with two zeroes should be something like this I was wondering, it exists a tangent vector field with $n$ zeroes on the sphere ? I thought that if I have $n$ zeroes (isolated), then thanks to the Poincarè-Hopf theorem the sum of the indices must be $\chi(\mathbb{S}^{2}) = 2$ . I thought that some combination of $-1$ and $1$ and a final zero of index $2$ could do the job, but can this vector field actually exist?
Something like defining a polynomial with $n$ distinct zeroes $p : \mathbb{C} \longmapsto \mathbb{C}$ can be extended to $\mathbb{S}^{2}$ to gain a tangent vector field on the sphere? Thanks in advance, any help would be appreciated.","['spheres', 'vector-fields', 'smooth-manifolds', 'compact-manifolds', 'differential-geometry']"
3980318,Subset of countable set is countable proof,"I'm self studying Understanding Analysis and there's an exercise that asks to prove that if $ A\subseteq B $ and $B$ is countable, then $A$ is either countable or finite. I want to be sure that my proof is not wrong or badly written. Being finite is trivial, so let's suppose it's not.
In the exercise, we assume there exists $f:N \to B$ which is 1-1 and onto and $n_1=\min\{n\in N:f(n)\in A\}$ . As a start to a definition of $g:N \to A$ , we set $g(1)=f(n_1)$ . These are given by the exercise and we're asked to continue the process inductively. I construct sets $a_n=\{n_c \text{ for } c \le n\}$ for example $a_1=\{n_1\}$ , $a_2=\{n_1, n_2\}$ etc. Then I construct: $$n_c=\min\{n\in N:f(n)\in A\ and\ n\notin a_{n_{c-1}}\}$$ and thus $g(c)=f(n_c)$ for every $c\in N$ gives us a $1-1$ function from $N$ onto $A$ . I would love to hear any sort of feedback, thank you!","['elementary-set-theory', 'proof-writing', 'discrete-mathematics', 'real-analysis']"
3980328,How to construct abstractly and symmetrically the map $𝛬^{n+k}M⊗𝛬^kN→𝛬^nM$ given a pairing $M⊗N→R$?,"Let $R$ be a commutative ring and let $M,N$ be $R$ -modules. Let $\langle-,-\rangle$ be a pairing $M⊗N→R$ . We can construct a pairing $\Lambda^kM⊗\Lambda^kN→R$ by sending $(a_1∧⋯∧a_k)⊗(b_1∧⋯∧b_k)$ to $\det(\langle a_i, b_j \rangle)_{ij}$ .
We can more generally construct a map $\Lambda^{n+k} M ⊗ \Lambda^n N → \Lambda^k M$ that can be defined recursively by $$ \langle a_1∧⋯∧a_{n+k}, b_1∧⋯∧b_k \rangle = \sum_{i=1}^{n+k} (-1)^{i-1} \langle a_i,b_1\rangle \langle a_1∧⋯∧\widehat{a_i}∧⋯∧a_{n+k}, b_2∧⋯∧b_k \rangle $$ where $\widehat{a_i}$ means that $a_i$ is omitted. The result is a sum over all injections $f : [\![1,k]\!] → [\![1,n+k]\!]$ of $$± \bigg(\prod_{i=1}^k \langle a_{f(i)}, b_i \rangle \bigg) \bigwedge_{j \not\in \operatorname{image}(f)} a_j.$$ Bourbaki gives an abstract construction of these maps as follows, but it is not symmetrical and I don't know how to prove the symmetry of the definition without referring to the formula. Here is the construction of Bourbaki (Algèbre III): We start by defining a coalgebra structure on $\Lambda M$ by applying $\Lambda$ to the coalgebra structure on $M$ given by the diagonal $M→M⊕M$ and the zero map $M→0$ . We get a comultiplication $\Lambda M → \Lambda(M⊕M) = \Lambda M ⊗ \Lambda M$ and a counit $\Lambda M→𝛬0=R$ . Dualizing degreewise this structure, we get an algebra structure on the graded dual $$(\Lambda M)' = \bigoplus_{k=0}^∞ (\Lambda^k M)^*.$$ This is an anticommutative alternating graded algebra (which can be deduced from the fact that $\Lambda M → \Lambda (M⊕M)$ is a morphism of algebras, without computation), so by the universal property of $\Lambda (M^*)$ , the morphism $M^* → (\Lambda M)'$ gives an algebra morphism $\Lambda (M^*) → (\Lambda M)'$ and thus an action on $\Lambda M$ . So this construction gives the pairing $\Lambda^k M ⊗ \Lambda^k M^* → R$ and if we have a morphism $N→M^*$ , we can deduce the pairing $\Lambda^k M ⊗ \Lambda^k N → \Lambda^k M ⊗ \Lambda^k M^* → R$ . Is there an other abstract construction that is more symmetrical than Bourbaki's? PS: I include the tag ""category theory"" because perhaps people watching this tag know an answer.","['category-theory', 'abstract-algebra', 'linear-algebra', 'tensor-products', 'multilinear-algebra']"
3980334,Continuously extend this function to the unit sphere.,"Given a nonzero vector $u$ , I can define the map $$
f_{u} : S^2 \to \mathbb{R}^3 \\
f_{u}(x) = \frac{u-(u\cdot x)x}{({(u \cdot x)^2}/(u\cdot u))-1}
$$ which is well-defined everywhere except when $u$ and $x$ are parallel. So, I have two questions: Does $f_{u}$ have limits at those two points where it is not well-defined, and what are those limits? Is there a simple geometric interpretation of what $f_{u}$ does to the unit sphere?","['limits', 'vectors', '3d']"
3980364,Why is $\log_{-7}49$ undefined instead of $2$?,"When you have $\log_{7}49$ , you can tell that it is equal to $2$ because $7^2 = 49$ . But, when you have $\log_{-7}49$ , isn't this also equal to $2$ because $(-7)^2 = 49$ also? Instead, this is undefined. Can someone explain why this is?","['algebra-precalculus', 'logarithms']"
3980374,Negative base of log if working in $\mathbb{C}$?,"Would a negative base of a logarithm be allowed if one were working in the field of complex numbers, $\mathbb{C}$ ?","['complex-analysis', 'complex-numbers', 'logarithms']"
3980377,Uniform convergence implies pointwise convergence,"I am having trouble proving a simple proposition regarding uniform convergence and pointwise convergence in Real Analysis . Problem: Suppose that $\left(f_{n}\right)$ is a sequence of functions $f_{n}: A \rightarrow \mathbb{R}$ such that $\left(f_{n}\right)$ converges uniformly to $f: A \rightarrow \mathbb{R}$ . Prove that $\left(f_{n}\right)$ also converges pointwise to $f: A \rightarrow \mathbb{R}$ Relevant definitions/Notations: One says that $f_{n} \rightarrow f$ uniformly on $A$ if, for every $\epsilon>0,$ there exists $N \in \mathbb{N}$ such that $n>N$ implies that $$\left|f_{n}(x)-f(x)\right|<\epsilon$$ for all $x \in A$ . Finally, we say that $f_{n} \rightarrow f$ pointwise on $A$ if, given $\epsilon>0,$ for each $x \in A$ there exists $N \in \mathbb{N}$ such that $n>N$ implies that $$\left|f_{n}(x)-f(x)\right|<\epsilon$$ Attempts: I tried to write down the definition of uniform convergence and then arguing that, in particular, since $N \in \mathbb{N}$ from uniform convergence works for any given point in $x \in A$ , then it must work for a given point and from that conclude pointwise convergence. I also checked some proofs like the one that states that uniform continuity implies continuity and write something similar, but i just dont know how to do it. I would highly appreciate a detailed proof regarding this fact, i am trying to become proeficient at proof writing. Thanks in advance, Lucas","['proof-writing', 'real-analysis', 'solution-verification', 'uniform-convergence', 'sequences-and-series']"
3980396,Are there any non-casework proofs of the $18$-point problem?,"There is a cute little problem stated as follows: Choose a sequence $x_1,x_2,x_3,\ldots$ with $x_i\in[0,1)$ such that $x_1$ and $x_2$ are in different halves of the unit interval, $x_1,x_2,$ and $x_3$ are in different thirds, and so on. How long can such a sequence be? It turns out the answer is exactly $17$ ; it is not possible to find a length- $18$ sequence obeying these constraints. See Wolfram Mathworld for more. Berkelamp and Graham's original 1970 paper proves this with a rather involved casework argument on the relative positions of various terms in the sequence, though later in the paper they present a non-casework argument that implies the sequence can be at most $63$ terms long. I am curious whether a more direct or ""natural"" argument has been developed in the 50 years hence; I wouldn't be surprised if getting an exact bound ultimately required a fairly casework-y approach, but it seems plausible that at least better upper bounds could be reached with some other method. Is anything more known about this problem?","['alternative-proof', 'number-theory', 'combinatorics', 'reference-request']"
3980438,Infinite minimal left ideals,"Let $R$ be an infinite field and let $S$ be the ring $$S = \begin{pmatrix}
R & R & R\\
0 & R & 0\\
0 & 0 & R
\end{pmatrix}$$ Show that there are infinite minimal left ideals of $S$ . I tried to consider the possible minimal left ideals of $S$ . Given a nonzero matrix $A$ in one of these ideals, say $I$ , I think I could multiply only once, or maybe twice in the left by some matrices of $S$ to get a matrix $B$ whose nonzero entries are in the same positions as $A$ , but $B's$ nonzero entries are simply $1$ 's, so that, since $B$ is in the ideal $I$ , we can get any matrix with the nonzero entries in the same positions as $A$ but being any elements of $R$ . Hence, since there are finitely many possible choices for the positions of the nonzero entries of a matrix $3$ x $3$ , it seems to follow that $S$ has finitely many minimal left ideals... contradicting what I'm supposed to prove. Any help would be appreciated.","['matrices', 'field-theory', 'ring-theory', 'abstract-algebra', 'ideals']"
3980453,"Existence of a path between two sides of a square, which is contained in the intersection of two open subsets of it","Denote by $I$ the interval $[0,1]$ . Let $A,B$ be two open subsets of the square $I\times I=I^2$ such that $A\cup B=I^2$ , $\{0\}\times I\subseteq A$ and $\{1\}\times I\subseteq B$ . In more geometric terms, the left edge of the square is contained in $A$ and the right edge is contained in $B$ . My question is: does there exist a continuous path $\gamma:I\to A\cap B$ such that $\gamma(0)\in I\times\{0\}$ and $\gamma(1)\in I\times\{1\}$ ? In other words, is there a curve connecting the two horizontal sides of the square, whose trace is contained in $A\cap B$ ?","['general-topology', 'geometry', 'connectedness']"
3980472,"When can the Killing form be put in the form $\kappa_{ij}=-\kappa\delta_{ij}$, and thus be treated as an Euclidean dot product?","Let $\mathfrak{g}$ be a Lie algebra and $\mathfrak{h}$ is a Cartan subalgebra. We know when the lie algebra is semi simple then the killing form, $\kappa(X,Y) = Tr(X^{ad}Y^{ad})$ , is non degenerate in $\mathfrak{g}$ and more importantly in $\mathfrak{h}$ . So it is a bilinear form analogous to the metric providing an isomorphism between $\mathfrak{h}$ and $\mathfrak{h}*$ and allowing us to take the inner product across these spaces. One thing that isn't clear fromt the literature I've read (and from my Universities lecture notes) is when we are able to to put the killing form in the form $\kappa_{ij} = -\kappa \delta_{ij}$ and so we can treat the inner product  as the normal euclidean dot product. Some notes I have read say this is only true for compact groups, others I have read say you can always do it and some don't even mention it (my lecture notes).","['group-theory', 'lie-algebras', 'lie-groups']"
3980491,Conventions for defining inductive base case,"I was reading a problem that stated: There are a certain number of objects all of which have the same
weight except for one which has a different weight. In all other
aspects the objects are identical. Determine the unique one that has
the different weight using a pair of scales optimally. Show by induction on $n$ that at most $2*n$ comparisons are needed to identify the object when the total number of objects is $3^n$ My original thought was that the base case has to be $n = 1$ where we have a total of $3^1$ objects which we can figure out the one we are searching for with 2 comparisons. But the solution uses as base case $n = 0$ considering in that case that the $3^0 = 1$ object is the one we are searching for. I originally rejected $n = 0 $ as base case because with $1$ object we can't do any comparison so we can't know if it is the one we search for or not. So my question is: how do we determine in such cases how do we treat the base case? Could we also not have considered that for $n = 0$ the $1$ coin can not be the one we are searching for? Or even that as I originally thought that it is not meaningful to use $n = 0$ as base case? Is there something in the problems we need to be cautious of, or some convention that exists that helps define the base case? In this particular problem, it makes me think that there is some subtle implication that the specific unique object under search must be part of the set even if all the rest are missing which I did not pick up. Is that so? Is there some convention for inductive approaches?","['puzzle', 'discrete-mathematics', 'algorithms', 'induction', 'problem-solving']"
3980494,$ \sqrt n \log \sqrt n$ is lower than $n$ ?!,I see an example in asymptotic notation that not very sensible for me. what is the intuitive idea to understand $ \sqrt n \log \sqrt n$ is lower than $n$ in concept of asymptotic view?,"['computer-science', 'asymptotics', 'discrete-mathematics', 'algorithms']"
3980521,"How far would Rebecca walk if she walks 100 feet in a straight line and turns $165^{\circ}$ clockwise, repeating this pattern until...","If Rebecca walks 100 feet in a straight line. She turns $165^{\circ}$ clockwise and walks another 100 feet, and turns $165^{\circ}$ clockwise again. If she continues this pattern until she reaches the point where she started. How far did she walk? I can't see how she would ever get back to her origin.
She turns $\frac{11}{24}$ of full rotation each time, this will not form a regular polygon.
It only makes sense she gets back to start if she turns for example $20^{\circ}$ - convenient factor of $360$ , here I can use the fact the exterior angles of polygon add up $360^{\circ}$ to find the number of angles formed and derive an answer.","['euclidean-geometry', 'geometry']"
3980537,"Show that $\int_0^\pi \log( 1 - 2r\cos(t) + r^2)\, dt=0$","Show that for $r \in (-1,1)$ $$ \int_0^\pi \log( 1 - 2r\cos(t) + r^2)\, dt = 0$$ Here's what I did so far: $$f(r,t) = \log(1 - 2r\cos(t) + r^2) = \log( (1-re^{it})(1-re^{-it}))$$ The Leibniz rule states that $$\dfrac{d}{dr} \int_0^\pi f(r,t)\ dt = \int_0^\pi \dfrac{\partial}{\partial r} f(r,t) \ dt$$ After calculating the right part I found $2\pi r$ which means that $\displaystyle\int_0^\pi f(r,t)\ dt = \pi r^2$ when it should be $0$ . Thanks in advance.","['integration', 'calculus', 'leibniz-integral-rule']"
3980576,More Examples of Positive Measures on Manifolds,"Given a smooth manifold $M$ , there are several ways of constructing measures on $M$ . The most common procedure I've seen is by starting with a $(0,2)$ tensor field $T$ on $M$ , and defining for each chart $(U,x)$ , the function $\rho_x := \sqrt{|\det T_{(x), ij}|}$ . These functions then give us a non-negative scalar density, $\rho$ on $M$ . Using this scalar density, we can essentially (chart by chart) ""pull back"" the Lebesgue measure to get a well-defined positive measure $\lambda_{\rho}$ on $M$ . For example if we're on a (pseudo)-Riemannian manifold, we can use the metric tensor to get the usual Riemannian volume measure. If we're on a symplectic manifold, we can use this same recipe with the symplectic form $\omega$ (or equivalently we just take $\left|\frac{\omega^n}{n!}\right|$ ... where we think of a scalar density as a section of an appropriate bundle). Now, my question is, can someone provide me some interesting examples where other types of measures naturally arise; for example are there some other structures which are studied (aside from Riemannian/symplectic, since these are the only two I know) in more advanced areas of geometry/analysis from which a natural notion of a positive measure on a manifold arises. Also, could you provide a (brief) explanation of where such a construction is used/why it is useful. I'm mainly asking to just broaden my perspective. Thanks in advance.","['symplectic-geometry', 'volume', 'riemannian-geometry', 'geometric-measure-theory', 'differential-geometry']"
3980584,Prove that a sequence of random variables is almost surely a Cauchy sequence,"Let $ \left(X_{n}\right)_{n} $ be a sequence of random variables such that for any $ \varepsilon >0 $ we have: $ \lim_{n,m\to\infty}\mathbb{P}\left(|X_{n}-X_{m}|>\varepsilon\right)>0 $ I want to prove that $ X_n $ has a subsequence wich is Cauchy. So, here's what I've tried: For any $ k $ we'll choose $ n_k $ such that for any $ n,m \geq n_k $ we have: $ \mathbb{P}\left(|X_{n}-X_{m}|>2^{-k}\right)<2^{-k} $ . We could also choose the $ n_k$ 's such that $ n_{k+1} > n_k $ . So denote: $ Y_k=X_{n_k}$ . I want to show that $ (Y_k)_k $ is a cauchy sequence. Define $ F=\limsup_{k}\left\{ |Y_{k}-Y_{k+1}|>2^{-k}\right\} =\bigcap_{n}\bigcup_{k\geq n}\left\{ |Y_{k}-Y_{k+1}|>2^{-k}\right\}  $ (This is the event which $ \left\{ |Y_{k}-Y_{k+1}|>2^{-k}\right\}  $ occurs infinitly many times). I proved, using Borel-Cantelli Lemma, that $ \mathbb{P}\left(F\right)=0 $ . All I have left to do is to conclude that $ Y_k $ is cauchy, so it sufficies to show that the probability that $ Y_k $ is not cauchy is $ 0 $ . Denote the event that $(Y_k) $ is not a Cauchy sequence as $ B $ . If I'll show that $ B\subset F $ that will finish the proof. But actually I cannot see how's this even true; Given a sequence, such that for any $ n\in \mathbb{N} $ we can find $ k\geq n $ such that $ |Y_{k+1}-Y_{k}|>2^{-k} $ dosent seem to imply that $ Y_k $ is not Cauchy. So what can I do to conclude the desirable conclusion? Thanks in advance.","['probability-theory', 'probability']"
3980608,How do we solve the equation $3\sec^{2}(x) - 4 = 0$?,"I am confused about the answer to this question: $$3\sec^{2}(x) - 4 = 0$$ I got the answer $$x = \frac{\pi}{6} + 2n\pi\quad\text{or}\quad x = \frac{5\pi}{6} + 2n\pi$$ However, the book's answer is $\pi/6 + n\pi, 5\pi/6 + n\pi$ Isn't the period of a secant function $2\pi$ ? If so, why is the answer saying $\pi$ ?","['periodic-functions', 'trigonometry']"
3980613,Condition for probability of even number heads to be $1/2$,"Suppose we flip $n$ coins (each flip is independent, but not necessarily identically distributed). Under what conditions will the probability that we flip an even number of heads be exactly $1/2$ ? I know that when all the coins are fair, then the probability is half (see e.g. this thread ). But I'm not sure how to handle the case if the coins aren't fair.","['combinations', 'discrete-mathematics', 'probability']"
3980643,Troubles with the Fokker–Planck equation,"I have read in several references that claims the following result: Given a 1-dimensional SDE $$dX_t = a(X_t,t)dt + \sigma(X_t,t) dW_t $$ where $W_t$ is a brownian motion and $\alpha,\sigma:\mathbb R\times \mathbb R\to\mathbb R$ are smooth functions (with $\sigma>0$ ), then the Fokker-Plank equation $$\frac{\partial }{\partial t}p(x,t) = -\frac{\partial}{\partial x}\left(a(x,t)p(x,t)\right)+\frac{1}{2}\frac{\partial}{\partial x^2}\left(\sigma^2 (x,t) p(x,t)\right),$$ correspond to the equation of the density function of the solution of the SDE (for instance, on the Wikipedia page it is possible to see this result). I have seen several ""derivations"" of the Fokker-Plank equation (for instance in the book ""Green functions for second-order parabolic integro-differential problems""- M.G. Garroni and J. L. Menaldi). My problem is that in all references that I have seen, they seem to start assuming that the measure $$\mu(A) = \mathbb P(X_t\in A),$$ is absolutely continuous with respect to the Lebesgue measure. Therefore, my question is the following, is it possible for the inverse path? If $p$ satisfies the Fokker-Plank equation is it possible to show that $p$ is the probability density function o the SDE solution $X_t$ ? A reference would be enough for me. All the best.","['measure-theory', 'statistics', 'stochastic-differential-equations', 'partial-differential-equations', 'probability-theory']"
3980660,Properties of Measuring Points in perspective drawing,"In his Complete Guide to Perspective Drawing, Craig Attebery defines a central concept in two-point perspective: Measuring Points, which can be used to determine depth in lines going away from the viewer. Attebery states, without proof, that the distance from Vanishing Points to Measuring Points should be the same as the distance from Vanishing Points to the Station Point (artist’s eye). That is, Measuring Points can be obtained using a compass: A different theory, still, comes from Joseph D’Amelio’s Perspective Drawing Handbook. From the latter’s definition, Measuring Points would be Vanishing Points themselves. As each set of parallel lines has its Vanishing Point, this would imply each Vanishing Point to have not a single, but infinite Measuring Points: Both theories, as interpreted above, cannot be right: Vanishing Points have either a single or infinite measuring points. The question is, thus: How many Measuring Points does each Vanishing Point has? If only one, why should Attebery’s statement hold: that the distance from Vanishing Points to Measuring Points  be the same as the distance from Vanishing Points to the Station Point?","['projective-geometry', 'geometry']"
3980674,Why is this etale cohomology computation going wrong?,"Suppose $f: X \to Y$ is a finite, galois map (with galois group $\Gamma$ ) of curves over a finite field $\mathbb F_q$ . If I pick a constant sheaf $\Lambda (\cong \mathbb Z/\ell^n$ , say), then $f_*(\Lambda) \cong \Lambda^\Gamma$ (by which I simply mean $\deg(f) = |\Gamma|$ many copies of $\Lambda$ ) since $X\times_Y X \cong \bigsqcup_{\Gamma}X$ . Moreover, the Leray spectral sequence converges immediately since all the higher pushforwards are zero (since $f$ is finite) and so $$H^p(X,\Lambda) \cong H^p(Y,f_*\Lambda) \cong H^p(Y,\Lambda)^\Gamma.$$ However, I don't think this will be true. I don't think this is true even for $p=0$ . Where am I going wrong?","['galois-theory', 'algebraic-geometry', 'etale-cohomology']"
