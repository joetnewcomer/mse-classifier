question_id,title,body,tags
2243048,How should the order of application of rotation transformation be interpreted (in PowerPoint)?,"For a university assignment, I have a question about rotating a picture in PowerPoint. In PowerPoint, a picture can have four transformations. Rotate right (90°), rotate left (90°), flip horizontally and flip vertically. Let's call them $R(r)$, $R(l)$, $F(v)$ and $F(h)$ for short. We are then asked to compute the matrix multiplication for every pair of possible transformations. For example, $R(r)*R(r)$ or $R(r)*F(h)$. All of that seems fairly simple to me, but they specified something in the question I don't understand. $R(r)*R(l)$ is read from right to left as ""rotate left"" then ""rotate
  the result right"", because Powerpoint transformations are performed in world coordinates . Can someone explain to me why I would read that left to right? And does that mean when I multiply the matrices together I would, in fact, do $R(l)*R(r)$ when asked to do $R(r)*R(l)$? Why would world co-ordinates effect this? Would I read all transformations as left to right or just some?","['matrices', 'rigid-transformation', 'rotations', 'linear-transformations']"
2243054,Showing subsets of $L^2=\{(x_n) : \sum_{n=1}^\infty x_n^2 < \infty \}$ are compact,"Show whether the following subsets of $l^2$ are compact. Let $$l^2=\left\{(x_n):\sum_{n=1}^{\infty}x_n^2<\infty\right\},$$ equipped with the norm $$\|(x_n)\|=\left(\sum_{n=1}^{\infty}x_n^2\right)^{1/2}.$$ State and explain if the following subsets of $l^2$ are compact: $A=\left\{(x_n)\in l^2:\sum_{n=1}^{k}x_n^2\leq1  \right\}$ where $k\in\mathbb{N}$ is fixed; $B=\left\{(x_n)\in l^2:\sum_{n=1}^{\infty}x_n^2\leq1, x_n=0\text{ for all } n>k  \right\}$ where $k\in\mathbb{N}$ is fixed; $C=\left\{(x_n)\in l^2:\sum_{n=1}^{\infty}x_n^2\leq1\right\}$ . I only know the sequentially compact definition of compactness.
I also have the theorem which states that all compact metric spaces are closed and bounded.
I think that $A$ is not compact, as it is not bounded (this was easy to show using a sequence which became a constant after k)
I think $C$ might not be compact, but only because I have seen that the unit ball in an infinite dimensional vector space is not compact, but I don't know how to prove it.
I think $B$ might be compact, but I'm unsure. Any help would be appreciated!","['general-topology', 'metric-spaces', 'compactness', 'analysis']"
2243096,"$\lim_{x\to 1; x\in (0,\infty)-\{1\}} \frac{x^{\alpha} -1}{x-1}, \alpha\in\mathbb{R}$","I'm trying to evaluate this limit (taken from T.Tao's Analysis 1 book) without logarithms and without knowing that the function $f:(0,\infty)\to\mathbb{R}, f(x):=x^{\alpha}, \alpha\in\mathbb{R}$ is differentiable on $(0,\infty)$ (infact the book asks to use this limit to show that $f$ is differentiable with limit $f'(x)=\alpha x^{\alpha -1}$. Now, I've tried to use the fact that $x^{\alpha}, \alpha\in\mathbb{R}$ is defined as $x^{\alpha}:=\lim_{n\to\infty} x^{q_n}$ where $(q_n)_{n=1}^\infty$ is any sequence of rational numbers converging to $\alpha$ (hence a bounded sequence) and the fact (that I've already proved) that $\lim_{x\to 1; x\in (0,\infty)-\{1\}} \frac{x^q-1}{x-1}=q\ \forall q\in\mathbb{Q}$ to use the squeeze theorem somehow but I haven't gotten anywhere so far. Any hints? Best regards, lorenzo.","['derivatives', 'real-analysis', 'limits']"
2243122,Right Hand Limits,"I was told to evaluate the following limit: $$\lim_{x \to 0^+} x^{x^2}$$ I know that the limit at 0 is equal to one since $0^0 = 1$, but I don't know what the correct way to do a RHL/LHL is. Do I just sub in a value > 0?","['calculus', 'limits']"
2243139,Hidden patterns in $\sin(a x^2)$,"I discovered unexpected patterns in the plot of the function $$f(x) = \sin(a\ x^2)$$ with $a = \pi/b$ , $b=50000$ and integer arguments $x$ ranging from $0$ to $100000$ . It's easy to understand that there is some sort of local symmetry in the plot but the existence of intricate global patterns like these astonished me. Is there a somehow simple explanation of these regular patterns that emerge when combining such ""incommensurate"" functions like $\text {sine}$ and squaring? Especially of their specific shapes, their increasing distinctness and the distances between them? Added: This pattern I found only today somewhere in the middle of the plot: Do you see the ""corridors""? They long for explanation.",['trigonometry']
2243146,"Is it possible to choose uniformly from $(0,1)$?","Can a method be constructed to choose one number uniformly from $(0,1)$? It has been argued that an event which is possible can have zero probability - such as the probability of selecting any given number when selecting uniformly from $(0,1)$. But I hold that an event with zero probability can never happen, and therefore I conclude that it is impossible to choose uniformly from  $(0,1)$. Can a method be constructed to choose uniformly from $(0,1)$?  I've a feeling that if there is a method, there's no guarantee it ever stops.",['probability-theory']
2243155,Proof for the equation of a line passing through the intersection of two lines(family of lines).,"Let $L_1$ be a line,   $a_1X + b_1Y+ c_1 =0$,
      $L_2$ be a line, $a_2X + b_2Y+ c_2= 0$. Then prove that the equation of line(s) passing through the intersection of these two line is of type   $\mathbf{L_1 + KL_2 = 0}$. We can prove it by multiply two equations with different constants and then adding them..., this proof didn't worked for me,therefore  i need a best proof, prove it  directly or give me  some awesome  hints.",['geometry']
2243189,Can we say that an element is not a subset of a set?,"I am creating a multiple choices question for students that should be as follows: Which of the following is true? 1) $8\in \mathbb{Z^{+}}$ 2) $8\notin \mathbb{Z^{+}}$ 3) $8\subset \mathbb{Z^{+}}$ 4) $8 \not\subset \mathbb{Z^{+}}$ Should choices Number (1) and (4) be considered as valid answers?
My understanding is that we can't deal with an element with either $\subset$ or $\not\subset$. Please give me references supporting your answer if there.",['elementary-set-theory']
2243206,How does this integration work when solving a DE?,"$\def\d{\mathrm{d}}$I understand what differential equations are and what they are useful for. They're very interesting, but I'm not quite sure what is going on when actually solving one. This is what I'm trying to solve: $$\frac{\d y}{\d x} = 2y + 3.$$ As far as I know, this is a first-order linear ordinary differential equation. Seems fairly simple. The first step that I am told to do is to 'separate the variables'. So I multiply both sides of the equation by $\d x$ and then divide both sides by $2y + 3$ to end up with: $$\frac{\d y}{2y+3} = \d x.$$ So now I've got all of my $y$ terms on one side, and all of my $x$ terms on the other. The fact that I can split apart the $\frac{\d y}{\d x}$ does seem a bit strange to me, but I'm told that it's sensible and I'm willing to believe, for now, that that's an OK thing to do. After this, I'm told to 'integrate both sides' and I'm shown this as the next step: $$\int \frac{\d y}{2y+3} = \int \d x$$ Normally when integrating, I would denote the 'integral of [integrand] with respect to $x$' using the standard notation: $$\int \text{[integrand]}\,\d x$$ In definite integration, the $\int$ represents an infinite sum, and the $\d x$ represents, as usual, a very small change in $x$ that is being multiplied by the value of the function at that point in order to, as $\d x$ approaches zero, generate the exact value of the area under the curve. For now I will just accept that we also write it in this fashion when doing indefinite integration. However, the second step in the solution to the DE confuses me because it doesn't seem to follow this notation. If you want to integrate both sides, then that means we must be integrating $\d x$ on the right hand side. If this is true, then I would normally write it as $\int \d x\,\d x$, because it is the integral of $\d x$ with respect to $x$ . However, in the solution it simply shows $\int \d x$ as if we have lost the $\d x$ that we would have put in as notation. The other side of the equation also doesn't have a $\d y$ at the end, as I would expect it to. My real question is: What do $\d x$ and $\d y$ represent on their own ? I understand that $\dfrac{\d y}{\d x}$ represents the derivative of $y$ with respect to $x$, and that it is representing an instantaneous rate of change because it is essentially representing an infinitesimally small change in $y$, divided by an infinitesimally small change in $x$ (the gradient at a point). However, when I see something like $\d x$ on its own, I'm not sure what the meaning of it is any more. It's an infinitesimally small change in $x$, right? How do we integrate that? What does it mean ? I want to be very clear that I'm not asking someone to walk me through solving it, because the web is full of examples of solving these types of equations. I'd be much more grateful for a conceptual answer to my question. And as an extra question: How does integrating both sides of an equation with respect to different variables make sense? Surely the two sides would no longer be equal.","['integration', 'ordinary-differential-equations', 'calculus']"
2243237,"Is $C_c^{\infty}(\mathbb{R}^n)$ dense in $L^p(M,d\sigma)$, $1\leq p<\infty$, where $M$ is an $n-1$ regular surface in $\mathbb{R}^n$?","I know that, given an open set $\Omega\subseteq\mathbb{R}^n$, $C_c^{\infty}(\Omega)$ (smooth functions with compact support) is dense in $L^p(\Omega)$, $1\leq p<\infty$. Let $M$ be a smooth $n-1$ regular surface in $\mathbb{R}^n$, and let $d\sigma$ be the surface measure. Is it true that $C_c^{\infty}(\mathbb{R}^n)$ is dense in $L^p(M,d\sigma)$, $1\leq p<\infty$? That is, if $\int_M |f|^p\,d\sigma<\infty$, can we find $\{f_m\}\subseteq C_c^{\infty}(\mathbb{R}^n)$ such that $\lim_m \int_M|f-f_m|^p\,d\sigma=0$? If not, which spaces would be dense in $L^p(M,d\sigma)$?","['surface-integrals', 'differential-geometry', 'measure-theory']"
2243248,One-sided limits of $f'(x)$ at a point vs. one-sided limits of the difference quotient at that point,"I know that if a function is piecewise, then when differentiating it one needs to deal separately with the points of intersection of the pieces, because the derivative may not be defined there. Also, if a one-sided limit of $f'(x)$ at these ""crucial points"" is infinite or doesn't exist, it doesn't preclude the limit of the difference quotient from existing and being finite. For example, take $f(x)=x^2\sin\frac1x, f(0)=0$: $f'(x)= 2x\sin\frac1x-\sin\frac1x $ has no limit as $x\to0$ but $\lim\limits_{h\to0}\frac{f(h)-f(0)}{h}=0=f'(0)$. On the contrary, looking at $f(x)=\sin x +\lvert \sin x\rvert $ on $[0,2\pi]$ one has $f'(x)=2\cos x$ on $(0,\pi) $ and $f'(x)=0$ on $(\pi,2\pi)$ so $\lim\limits_{h\to0^+}f'(\pi+h)\ne\lim\limits_{h\to0^-}f'(\pi+h)$, but they are both finite. And in this case it's easy to find that they agree with the one-sided limits of the difference quotient. Why? Does the finiteness of the former imply that they agree with the latter? Is this also true if the one-sided limits of $f'$ at the crucial points agree with each other?","['derivatives', 'real-analysis', 'calculus', 'piecewise-continuity']"
2243277,Is this a sheaf?,"Let $X$ be a topological space. For each open $U\subset X$ let $\mathcal{F}(U)$ be the ring of real functions on $U$ (not necessarily continuous). Is this a sheaf? If $\mathcal{F}(U)$ is the ring of continuous functions from U to a topological space Y, this is a sheaf. But in the proof that this is a sheaf, where do we use continuity?","['sheaf-theory', 'algebraic-geometry']"
2243293,How does this follow from the definition of a stalk?,"Let $X$ be a topological space and $\mathcal{F}$ a presheaf on $X$. The stalk of $\mathcal{F}$ at $x$ is defined as $$\mathcal{F}_x = \varinjlim_{x\in U} \mathcal{F}(U)$$ In some books I read, that this is equivalent to $\mathcal{F}_x$ being the set of equivalence classes of pairs $(U,s)$ where $U$ is an open neighborhood of $x$ and $s\in \mathcal{F}(U)$ with the equivalence relation $(U_1,s_1) \sim (U_2,s_s)$ if and only if there exists an open neighborhood $V$ of $x$ with $V\subset U_1 \cap U_2$ such that $s_1|_V = s_2|_V$. Why are these definitions equivalent? I know what the definition of the colimit is, but I experience it as difficult to handle. What is a good source to understand limits and colimits better?","['sheaf-theory', 'algebraic-geometry']"
2243310,Sum of series using complex numbers,In this I just know $e^{im}=\cos m +i\sin m$ but in this none of the terms are cancelling . The answer of this question is 1008,"['complex-analysis', 'complex-numbers']"
2243325,What should be the number of functions with this condition.,"The condition is very simple $A=\{1,2,3,4\}$ is the domain of a function $f(x)$. We have to find total number of $f(x)$ such that  $fof(x)=x$. Obviously, It means that $f$ ought to be inverse of itself. What i tried was Making pairs of elements in Domain and then seeing total such possible mappings. Example: Let $(1,2) and (3,4)$ be the respective pairs and they end up with mapping $\{1\rightarrow2 and 2\rightarrow1 \}$ or $\{2\rightarrow2 and 1\rightarrow1 \}$  and same case with $(3,4)$ This should be giving me an answer of $^4C_2*2=12$ But my book says it's 13. Please someone explain my error or provide a better and elegant method for the same.","['transfinite-recursion', 'functions']"
2243369,The Cramér–Wold theorem for complex random vectors,"The Cramér–Wold theorem states that $k$-dimensional real random vectors $X_n$ converge in distribution to a $k$-dimensonal real random vector $X$ if and only if $a^TX_n\xrightarrow{d}a^T X$ for all vectors $a\in\mathbb R^k$. Now suppose that $X_n$ are complex random vectors, i.e. random vectors with values in $\mathbb C^k$. Does the same result hold for complex random vectors? Does it still suffice to check the convergence of $a^TX_n$ for all $a\in\mathbb R^k$ or do we have to check for all $a\in\mathbb C^k$? Any help is much appreciated!","['probability-theory', 'weak-convergence', 'convergence-divergence', 'sequences-and-series', 'vectors']"
2243423,Prove if $B^2=I+BA$ and $A^2=AB$ then $A=0$,"I need to prove that if $B^2=I+BA$ and $A^2=AB$ then $A=0$, $A$ and $B$ are square matrices. I'm not sure if my answer is correct but I thought of this: $$
A^2-B^2=A^2+AB-BA-B^2=A^2+A^2-(B^2-I)-B^2=2(A^2-B^2)+I 
$$
$$
\Rightarrow B^2-A^2=I=(B-A)(B+A)
$$ This means that $(B-A)$ is invertible. It is also given that $I=B^2-AB$ then:
$$
B^2-AB=B^2-A^2
$$
$$
\Leftrightarrow B(B-A)=(B+A)(B-A)
$$ Because we proved that $(B-A)$ is invertible then we can simplify and get $B=B+A \Rightarrow A=0$","['matrices', 'linear-algebra', 'proof-verification']"
2243431,How to show that this function is differentiable in $x=0$ but not in $x=1$,"I am stuck with showing that this function is differentiable at $x=0$ but not at $x=1$. $f(x) = \begin{cases}
x^2, & \text{if x}\in{\mathbb{Q}}\\
x^3, & \text{if x}\notin{\mathbb{Q}}\\
\end{cases}$ So for $x=0$: Case 1: $h \in \mathbb{Q}$ $\lim\limits_{h \to 0}{\frac{f(0+h)-f(0)}{h}} = \lim\limits_{h \to 0}{\frac{f(h)}{h}} = \lim\limits_{h \to 0}{\frac{h^2}{h} =  \lim\limits_{h \to 0}{ h} = 0} $ Case 2: $h \notin \mathbb{Q}$ $\lim\limits_{h \to 0}{\frac{f(0+h)-f(0)}{h}} = \lim\limits_{h \to 0}{\frac{f(h)}{h}} = \lim\limits_{h \to 0}{\frac{h^3}{h} = \lim\limits_{h \to 0}{ h^2} = 0} $ I am unsure on how to continue from here. I thought I need to show that for $x=0$ the right and left hand side limits are the same, and for $x=1$ they are different.",['derivatives']
2243461,Bound of $\mathbb {P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace$ using Chernoff-Hoeffding inequality,"From the Chernoff-Hoeffding inequality, we know that for $t \geq 0$ we have $$\mathbb{P} \lbrace \vert X-\mathbb{E}X\vert >t\rbrace \leq 2 \exp\left(-\dfrac{t^{2}}{2}\mathbb{E}X\right).$$ What can I say about  $\mathbb{P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace$, is it possible to extend this result for this special case? Is it true that 
$$\mathbb{P} \lbrace \vert X Y-\mathbb{E}X\mathbb{E}Y\vert >t \rbrace \leq \mathbb{P} \lbrace \vert X-\mathbb{E}X\vert >t \rbrace + \mathbb{P} \lbrace \vert Y-\mathbb{E}Y\vert >t \rbrace \leq 4 \exp\left(-\dfrac{t^{2}}{2}(\mathbb{E}X+\mathbb{E}Y) \right)$$ ? Any help or suggestions are welcomed.","['inequality', 'probability', 'sequences-and-series']"
2243470,"If $A^2=O$, then prove that $I+A$ is invertible and find $(I+A)^{-1}$","So I'm stuck on this Linear Algebra question. My first (naive) train of thought here was to go through with an implication that $A^2=O$ implies $A=O$. Then this got quickly debunked having read up on nilpotent matrices. So I'm back to square one without a clue as to how to proceed. Any hints will be much appreciated on where to begin with this, has been pestering me for at least one day now. EDIT: Thank you everyone, very happy for all your assistance.","['matrices', 'linear-algebra', 'inverse']"
2243484,Why are differential forms built up on alternating forms?,What properties make alternating forms so desirable in differential geometry?,"['differential-forms', 'differential-geometry']"
2243498,Suppose $f\in\mathbf{C^2}(\mathbb{R})$ and is periodic with period $2\pi$. Prove the Fourier series of $f$ converges uniformly in any finite interval.,"Suppose $f\in\mathbf{C^2}(\mathbb{R})$ and is periodic with period $2\pi$. Prove that the Fourier series of $f$ converges uniformly in any finite interval. My attempt: $|a_n~\cos(nx)+b_n~\sin(nx)|\le|a_n|+|b_n|$. So, by M-test, we just need to show $\displaystyle\sum_{n=1}^\infty |a_n|+|b_n|$ converges. $$\begin{equation}\begin{aligned}
a_n=\frac{1}{\pi} \int_{-\pi}^\pi~f(x)~\cos(nx)~dx &= -\frac{1}{n\pi}\int_{-\pi}^{\pi}~ f'(x)~\sin(nx)~dx \\ &=\frac{1}{n^2\pi}~ f'(x)~\cos(nx)~dx\Bigg|_{-\pi}^{\pi}-\frac{1}{n^2\pi}~f''(x)~\cos(nx)~dx\\
\end{aligned}\end{equation}$$
$$=\frac{1}{n^2\pi}[f(\pi)~\cos(nx)-f(-\pi)~\sin(nx)]+\frac{1}{n^2\pi}\int_{-\pi}^{\pi} f''(x)~\cos(nx)dx$$ $f\in\mathbf{C^2}(\mathbb{R})\Rightarrow |f|,|f''|\leq K$ on $[-\pi,\pi]$ for some $K$. We can get $a_n\leq \frac{4K}{n^2}$.
 Similarly, $b_n\leq\frac{4M}{n^2}$. So, $M_n=\displaystyle\sum_{n=1}^\infty |a_n|+|b_n|$ converges. So, the Fourier series $\displaystyle\sum_{n=1}^\infty [a_n~\cos(nx)+b_n~\sin(nx)]$  converges unifomly. Is my proof correct? It seems that for any $x\in \mathbb{R}$, the Fourier series converges uniformly.
Why we cannot conclude that the Fourier series of $f$ converges uniformly on $\mathbb{R}?$","['functional-analysis', 'real-analysis', 'fourier-analysis', 'analysis']"
2243528,Proof that the reals are uncountable by Königsberger,"I found this proof in Chapter 2 (Satz 7) of ""Analysis 1"" by Königsberger (hope it is not a duplicate) It begins by defining an ""Intervallschachtelung"" (I don't know any good translation), which is a sequence $I_1,I_2,...$ of closed intervals (in the real line) such that: $I_{n+1}\subset I_n$ for every $n\in\Bbb N$ For every $\epsilon\gt0$ there is one intervall $I_n$ with length $\vert I_n\vert\lt\epsilon$ The book gives the next as a principle: For every Intervallschachtelung in $\Bbb R$ there is a real number that belongs to every interval (Intervallschachtelungprinzip) Now the proof: Let $\Bbb R=\{x_1,x_2,...\}$ be the countable set of every real number. Now we construct an Intervallschachtelung $(I_n)$ such that $$x_n\notin I_n$$ beginning by setting $I_1=[x_1+1,x_1+2]$ and getting $I_{n+1}$ from $I_n$ by recursion: divide $I_n$ in three equal parts and choose $I_{n+1}$ to be the one that doesn´t contain $x_{n+1}$. $(I_n)$ is an Intervallschachtelung and therefore there is a number $s\in I_n$ for every $n\in\Bbb N$ but if $s$ had been some $x_k$ in $\Bbb R$, then $x_k=s\in I_k$ which is a contradiction and thus $\Bbb R$ is uncountable Now my question: isn't this the same as Cantor's diagonal argument? You are ""making"" a number different from the ones that you have listed, if so, why is it necessary the some unproven principle? (I haven´t found any proof anywhere) Why is it important to divide each interval into three parts? I'm asking because in a previous Staz, two (equal) parts were enough. I think it only serves to avoid having $x_{n+1}$ right between the two parts but could two non-equal parts also do the job (given that you have a procedure of avoiding that)? Thanks","['real-numbers', 'elementary-set-theory']"
2243551,"Is the intersection of an open set with a closed set open, closed, or neither?","I was trying to determine whether the following set is open or not: $$C:=\{(x,y,z) \in \mathbb{R}^3 : x^2 + y^2 + z > 3 , z \ge -1 \} .$$ To do so, I tried to show that the following two other sets (whose intersection, $C_1 \cap C_2$, equals $C$) were both open:
$$C_1:=\{(x,y,z) \in \mathbb{R}^3 : x^2 + y^2 + z > 3\}$$
$$C_2:=\{(x,y,z) \in \mathbb{R}^3 : z \ge -1\}$$ I found that $C_1$ was open, but that $C_2$ was not. If this is correct, I guess it means that $C$ is not open, but I was not 100% sure about that since the property I used only says that ""the finite intersection of open sets is an open set"". It doesn't say anything about the intersection of an open set with a closed set... So, how can I be certain that $C$ is not open? And is there any way to show that such a set could be closed (or not) as well? Thanks in advance for the help.",['general-topology']
2243558,What is a geometric characterization of the smooth real-valued functions $f$ on an open set $U \subset \Bbb R^n$ satisfying $df \wedge dx^1 = 0$?,"Let $U \subset \Bbb R^n$ be open. What is a geometric characterization of the smooth real-valued functions $f$ on $U$ satisfying the condition $$df \wedge dx^1 = 0 ?$$ I've expanded the expression according to the definition of $df$, and am not sure my solution is correct. $f$ is defined on an arbitrary open subset $U$ of $R^n$. $$df = \sum_{i =1} ^{n} \frac{\partial f}{\partial x^i}dx^i$$ Thus: $$\begin{align}df \wedge dx^1 &= \sum_{i =1} ^{n} \frac{\partial f}{\partial x^i}dx^i \wedge dx^1\\&= \sum_{i =2} ^{n} \frac{\partial f}{\partial x^i}dx^i \wedge dx^1 .\end{align}$$ Thus for our given expression to be true, we require $\frac{\partial f}{\partial x^i}dx^i \wedge dx^1 = 0$ for all $i \neq 1$. Now, for these $i,$ we know that $dx^i \wedge dx^1 \neq 0.$ Thus these must be smooth functions that are constant along each $x^{i \neq 1}$ axis. Am I wrong anywhere?","['real-analysis', 'differential-forms', 'calculus', 'differential-geometry', 'analysis']"
2243571,Find $\sin A$ and $\cos A$ if $\tan A+\sec A=4 $,"How to find $\sin A$ and $\cos A$ if
$$\tan A+\sec A=4 ?$$ I tried to find it by $\tan A=\dfrac{\sin A}{\cos A}$ and $\sec A=\dfrac{1}{\cos A}$, therefore
$$\tan A+\sec A=\frac{\sin A+1}{\cos A}=4,$$
which implies 
$$\sin A+1=4\cos A.$$
Then what to do?",['trigonometry']
2243583,"What the expected value of $X$, $E(X)$, if the joint pdf $f(x,y) = \frac{e^{-y}}{y} $ for values $0 < x < y,\ 0 < y < \infty$?","What is $E(X)$ if the joint PDF of $X$ and $Y$ is $$f(x,y) = \begin{cases}
\frac{e^{-y}}{y}, &0 < x < y, \ 0 < y < \infty\\
0, &\text{otherwise}.
\end{cases}$$ $$E(X) = \int_{-\infty}^{\infty}x f_X(x)\,dx$$ $$f_X(x)=\int_{-\infty}^{\infty}f(x,y)\,dy = \int_0^\infty \frac{e^{-y}}{y} \,dy$$ But I'm not sure how to compute the integral for $f_X(x).$ So I tried to compute the entire double integral $E(X).$ $$E(X) = \int_{-\infty}^{\infty}x f_X(x)\,dx =\int_{0}^{y}x\int_0^\infty \frac{e^{-y}}{y}\, dy .$$ I remember there is a trick to swap the bounds of integration so that it can make integration easier, but I'm confused how to do this.","['multivariable-calculus', 'probability']"
2243586,Finding $\lim_{n\rightarrow \infty}\frac{1+2^2+3^3+4^4+\cdots +n^n}{n^n}$ [duplicate],"This question already has answers here : Finding $\lim\limits_{n \to \infty}{\frac{1^1+2^2+3^3+\cdots+n^n}{n^n}}$ (4 answers) Closed 7 years ago . Finding $$\lim_{n\rightarrow \infty}\frac{1+2^2+3^3+4^4+\cdots +n^n}{n^n}$$ Attempt: $$\lim_{n\rightarrow \infty}\bigg[\frac{1}{n^n}+\frac{2^2}{n^n}+\frac{3^3}{n^n}+\cdots \cdots +\frac{n^n}{n^n}\bigg] = 1$$ because all terms are approaching to zero except last terms but answer is not $1$ , could some help me to solve it , thanks","['limits', 'exponential-function', 'sequences-and-series', 'calculus', 'fractions']"
2243598,"How to show $\int_{0}^{\infty}{{\gamma+\ln x\over e^x}}\cdot{1-\cos x\over x} \,\mathrm dx={1\over 2}\cdot{\pi-\ln 4\over 4}\cdot{\pi+\ln4\over 4}?$","Consider this integral $(1)$ $$\int_{0}^{\infty}\color{red}{{\gamma+\ln x\over e^x}}\cdot{1-\cos x\over x}\,\mathrm dx={1\over 2}\cdot{\pi-\ln 4\over 4}\cdot{\pi+\ln 4\over 4}\tag1$$ Recall a well-known integral for $\gamma$: $$\int_{0}^{\infty}e^{-x}\ln x\,\mathrm dx=-\gamma.$$ Making an attempt: I am not sure, what to do... Recall: $\cos x={e^{ix}+e^{-ix}\over 2}$, then $(1)$ becomes $$\int_{0}^{\infty}{\gamma+\ln x\over e^x}\cdot{2-e^{ix}-e^{-ix}\over 2x}\,\mathrm dx\tag2$$ Or using $e^{-x}$ series, then $(1)$ becomes $$\sum_{n=0}^{\infty}{(-1)^n\over n!}\color{blue}{\int_{0}^{\infty}(\gamma+\ln x)(1-\cos x)x^{n-1}\,\mathrm dx}\tag3$$ $$\color{blue}{blue}=\int_{0}^{\infty}(\gamma+\ln x)x^{n-1}\,\mathrm dx-\int_{0}^{\infty}(\gamma+\ln x)\cos(x) x^{n-1}\,\mathrm dx=I_1-I_2\tag4$$ Indefinite integral of $$I_1={x^n\over n^2}(n\ln x+n\gamma-1)+C$$ Put in the limit and $I_1$ is diverges and $I_2$ it is a lengthy IBP and it also diverges. How to prove (1)?","['integration', 'definite-integrals', 'calculus', 'euler-mascheroni-constant']"
2243604,Set of all true first-order statements about set,"Today a TA claimed that ""set of all true first-order statements about sets"" is actually a set. After searching around on the net, all I can find is this question on this site, which is about completely different things. So, can anyone give me a proof that this is a set? EDIT: Or if this is definitely not a set, can someone give me a proof? EDIT: if you don't believe in the existence of a world we live in so that the notion of truth is meaningful, the question can be rephrase as follow: let $M$ be a model of ZFC, and for each statements (in the first-order language for ZFC) that is true about $M$, we can compute the Godel encoding of such statements in $M$ (where the computation is carried out according to $M$). Now is there an element of $M$ such that (according to $M$) it contains exactly those Godel encoding as above? EDIT: Let me clarify this, since some people are confused about the crux of the problem and confuse this with a basic question. We are looking for a set with some properties about its elements. Specifically, a set $T$ such that $\sigma\in T$ if and only if $\sigma$ is a true statement. Generally, specifying properties of elements are not sufficient to guarantee the existence of a set; for example the ""set"" $S$ of all natural number $x$ such that $x\notin S$ does not exist. However, in standard set theory, the axiom schema of restricted comprehension does in fact guarantee the existence of a set $S$ of all elements $a\in A$ that satisfy a first-order property $\phi(x)$. So the obvious attempt to solve this problem is to find a first-order formula $TRUE(\tau)$ that pick out all the true statement. But by Tarski's undefinability of truth, no such formula exist. So if this can be proven to be a set, you need to do something clever. In fact, you might need some sort of proof by contradiction otherwise you will run into the undefinability of truth still. But my feeling is that this one is not a set, but I can't prove it either. Thank you.",['elementary-set-theory']
2243607,"Presentation of wreath product $G=S_3 \wr S_3$ of symmetric groups. What is the isomorphism type of $G/[G,G]$?","I'm trying to answer the first part of a group theory question as revision for an exam that goes as follows; Let $G = S_3 \wr S_3$ , the permutational wreath product of two symmetric groups of degree three. Give a presentation for $G$ and determine the isomorphism type of $G/[G, G]$ . I'm not sure how to go about finding generators for the wreath product itself. Is there a method for combining the generators of the symmetric groups to form generators for the wreath prouct? Any pointers would be much appreciated, thanks in advance!","['finite-groups', 'combinatorial-group-theory', 'group-presentation', 'wreath-product', 'group-theory']"
2243617,Expected Angle of a Random 2D Vector,"I was playing around a bit until I noticed that the definition of sample correlation coefficient of two variables is literally the definition of the dot product of two realizations of the variable $$ r\equiv \frac{\mathbf{x}\cdot\mathbf{y}}{|x||y|} = \cos\phi$$ Given a single observation $\mathbf{x} = (x_1,x_2) \in \Omega_{X,Y}$, note $$\cos\phi = \frac{\mathbf{x}\cdot\hat{i}}{|x|}=\frac{x}{|x|}$$ In which case 
$$\mathbb{E}[\cos\phi] = \int\limits_{\mathbf{x}\in\Omega}\cos(\phi|\mathbf{x})\mathbb{P}(x_1,x_2)$$ The continuous correlation coefficient is: $$\rho \equiv \frac{\mathbb{E}[XY]}{\sigma_X\sigma_Y}$$ I'm wondering if the correlation coefficient can be interpreted as the expected angle of a random 2D vector? If not, can you interpret the correlation coefficient of a 2D vector geometrically?","['statistics', 'probability']"
2243621,Lines rotation - problem,"Given $3$ infinite lines $L_1$, $L_2$, $L_3$ in $R^3$ ($3D$ space), each line is represented by two $3D$ points, the line $L_1$ is rotating around the axis line $L_3$ until it intersects with the line $L_2$ (or in other words, until there's a plane that $L_1$ and $L_2$ span).
Rotation of a line around axis line means that every point on the line is always in the same distance from the axis line. I need to find the angle that $L_1$ needs to rotate (around $L_3$) in which it intersects with $L_2$ (or none if the lines don't intersect).
  Anyone knows how to find it? I've been trying to solve it for quite a while. A few things I already tried: The surface of revolution created by rotating the line $L_1$ around $L_3$ is hyperboloid (rotated in space). I was trying to find the equation of the hyperboloid (given $L_1$ and $L_3$) and then to find the intersection point(s) between the hyperboloid and the line $L_2$. But I didn't succeed to find the hyperboloid equation. Also, I wrote code (in matlab) that rotates a line around another line. so I can have the equation of $L_1$ rotated by the angle theta around $L_3$ (equation depending by one variable - theta ($\theta$)). and I need to find for which $\theta$ there's a point intersection between $L_1$ and $L_2$. The problem is that the equation is extremely long so I couldn't really continue and find the theta in which there's an intersection point. I'd be happy for any suggestion that can help. Thank you very much David","['linear-algebra', 'calculus', 'geometry']"
2243626,Answering questions from a Character Table,"I have been studying a course on Representation Theory, specifically Character Tables. I am able to construct a character table, but I cannot seem to understand working backwards with receiving the table. The question on a past paper exam is: Consider the character table below of the finite group $G$ . where $i\in\mathbb{C}$ with $i^2=−1.$ (a) Determine $|G|$ and $|C_G(g_i)|$ for $i=1,...,6$ . (b) Show that $G/[G, G]$ is cyclic of order 4. (c) Deduce that $G$ has a normal Sylow 3-subgroup $P$ . (d) Show that $C_P(g_5)=1$ . (e) Deduce that $P$ isomorphic to $C_3\times C_3$ . Any help is much appreciated!","['representation-theory', 'group-theory', 'characters']"
2243674,Solve the ODE $\frac{\mathrm dx}{\mathrm dt}=(x+t)t$,"$\def\d{\mathrm{d}}$How to solve this ODE? (From a real analysis course, existence and uniqueness of ODE)
$$\frac{\d x}{\d t}=(x+t)t. \quad \forall t\in [0,1], \quad x(0)=0$$ My attempt: $$\dot{x}=\frac{\d x}{\d t}=V(x(t),t)=(x+t)t$$ So we can use $\phi_v(x)$ such that $$\phi_v^1(x,t)=x(0)+\int_{0}^{t}(x+t)t\,\d t= \frac{t^3}{3}+\frac{t^2x}{2}$$
with $x(0)=0$. Applying $\phi_v$ to approximate $\phi^n_v$: $$
\phi_v^2(x,t)=\int_{0}^{t} \left( \frac{t^3x}{2}+\frac{t^4}{3}+t^2 \right) \, \d t= \frac{t^4x}{8}+\frac{t^5}{15}+\frac{t^3}{3},\\
\phi_v^3(x,t)=\int_0^t \left( \frac{t^5x}{8}+\frac{t^5}{15}+t^4 \right) \,\d t= \frac{t^6x}{48} +\frac{t^7}{106}+\frac{t^3}{15}+\frac{t^3}{3}.
$$ Am I on the right track? How should I finish this?",['ordinary-differential-equations']
2243695,"""Moving"" Gauss' Circle Problem","GCP (Gauss' Circle Problem) asks for a closed form for the number of square-lattice points inside a circle, centered at the origin, of radius $r$. Let's denote by $N(r)$ the number of these points. Then, $N(r)$ is the number of integer solutions (pairs of integers $x$ and $y$) to the inequality $$x^2+y^2 \le r^2$$ But, what would happen if, instead of setting the center of the circle at the origin, we moved the circle $1/2$ units in the X-axis? The number of lattice points $N^*(r)$ would be the number of integer solutions to $$(x+1/2)^2+y^2 \le r^2$$ It is easy to show that $N^*(r)$ would also be the number of solutions to $$x^2+(y+1/2)^2 \le r^2$$ For last, let's denote by $N^{**}(r)$ the number of lattice points of a circle centered at $(1/2, 1/2)$; that is, the number of integer solutions to $$(x+1/2)^2+(y+1/2)^2 \le r^2$$ Then, my question is: Is there any direct relationship between $N(r)$, $N^*(r)$ and $N^{**}(r)$ ? Thank you.","['number-theory', 'inequality', 'integer-lattices', 'geometry']"
2243716,"If something has a $12\%$ probability of occurring every decade, what is the probability that it will occur in $100$ years?","If something has a $12\%$ probability of occurring every $10$ years, what is the probability that it will occur in $100$ years? And also in $150$ years? Is the formula for this as simple as $1-{0.88}^{10}$ or is it more complicated?","['statistics', 'probability']"
2243720,How to use Green's theorem?,"$\def\d{\mathrm{d}}$I'm thinking about this differential equation $$\frac{3}{2} x\,\d x + \frac{x}{y}\,\d y = 0.$$ If functions $P(x,y), Q(x,y)$ are difined as$$P = \frac{3}{2} x,\ Q = \frac{x}{y},$$ this differential equation can be rewritten as $$P\,\d x + Q\,\d y = 0.$$ By differentiating $P$ and $Q$, one can easily get $$\frac{\partial P}{\partial y} = 0,\ \frac{\partial Q}{\partial x} = \frac{1}{y} \Longrightarrow \frac{\partial P}{\partial y} \neq \frac{\partial Q}{\partial x}.$$ According to Green's theorem, $$\oint _C (P\,\d x + Q\,\d y) = \iint _R \left( \frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y} \right) \,\d x \d y.$$ Now $P\,\d x + Q\,\d y = 0$, so that $\oint _C (P\,\d x + Q\,\d y)$ is always zero, and thus$$\iint _R \left( \frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y} \right) \,\d x \d y$$
is always zero. This results in $$\frac{\partial Q}{\partial x} = \frac{\partial P}{\partial y}.$$ Why is my way of using Green's theorem incorrect?","['ordinary-differential-equations', 'greens-theorem']"
2243725,"what does ""solve the equation for x"" mean?","I'm not expert for the mathematics, and familiar with this.
But when I learn the math in high school, I've got the sort of the below equation things from teacher or books. Solve the equation for $x$:
    $$(x^2 + 6x -7)(2x^2 - 5x-3) = 0$$ After $10$ years, now I'm looking the math book again.
Especially, I have one question what I don't know. Why? Do we have to solve that equation which has equal to 'zero' and what does it mean some equation is the same to zero? 
why do we set the zero to equation to solve that sort of equations?",['algebra-precalculus']
2243730,Extending continuous functions to the completion (metric spaces).,"I'm am trying to fill in an omitted detail from my lecture notes on Functional Analysis. Let $f:X\to Y$, where $X$ and $Y$ are metric spaces, with $Y$ complete. Suppose $f$ maps Cauchy sequences to Cauchy sequences (so is continuous in particular). Denote by $\mathrm{Comp}(X)$ the completion of $X$. Since $X$ densely embeds into $\mathrm{comp}(X)$ (and metric spaces are Hausdorff), there is at most one continuous extension of $f$ to $\mathrm{comp}(X)$, which we denote also by $f$. Existence is what's bothering me. Presumably for $[(a_n)]\in\mathrm{comp}(X)$, one defines $$f([a_n]):=\lim_{n\to \infty}f(a_n).$$ Is it obvious that (1) this extension is well-defined and (2) it's a continuous function? One defines the metric $d$ on the completion by $d([a_n], [b_n]):=\lim_n d(a_n, b_n)$. Many thanks!","['metric-spaces', 'analysis']"
2243741,"If $f$ is differentiable everywhere and $|f(y)-f(x)| \leq |x-y|^n$ for all $n >1$, then $f^{\prime}(x)= 0 $ for all $x$.","Suppose $f:\mathbb{R} \rightarrow \mathbb{R}$ is a differentiable function and satisfies $|f(x) - f(y)| \leq |x-y|^n$ for all $n > 1.$ Show that $f^{\prime}(x)=0$ for all $x\in \mathbb{R}.$ My first attempt: Choose $x < y$ such that $y - x < 1$. By the Mean Value Theorem on $[x,y]$, we have $\frac{f(y) - f(x)}{y-x} = f^{\prime}(c)$ for some $c \in (x,y).$ Note that we have $| f^{\prime}(c) | = \frac{|f(y) - f(x)|}{y-x} \leq |x-y|^{n-1}$. Since it holds for any $n > 1$, we have $\displaystyle\lim_{n \rightarrow \infty}|f^{\prime}(c)| \leq \displaystyle\lim_{n \rightarrow \infty}|x-y|^{n-1}.$ Since $y - x < 1,$ we have $\displaystyle\lim_{ \rightarrow \infty}|x-y|^{n-1} = 0$. Hence, $|f^{\prime}(c)| = \displaystyle\lim_{n \rightarrow \infty}|f^{\prime}(c)| = 0 .$ Therefore, $f^{\prime}(c) = 0$. Since it holds for any interval $[x,y]$ that shrinks to a point in it, we can have $f^{\prime}(x)=0$ for all $x \in \mathbb{R}.$ My second attempt: Since $f$ is differentiable everywhere, we have for any $x \in \mathbb{R}, f^{\prime}(x) = \displaystyle\lim_{y \rightarrow x }\frac{f(x)-f(y)}{x-y}.$ Therefore, $|f^{\prime}(x)| = \displaystyle\lim_{y \rightarrow x }\frac{|f(x)-f(y)|}{|x-y|} \leq \displaystyle\lim_{y \rightarrow x} |x-y|^{n-1} = 0.$ Hence, $|f^{\prime}(x)| = 0$, which implies that $f^{\prime}(x) = 0.$ Since it holds for any $x \in \mathbb{R}$, we have $f^{\prime}(x) = 0$ for any $x \in \mathbb{R}.$ Are my two attempts correct? I am quite doubtful about my first attempt on the choosing $x$ and $y$ part.","['derivatives', 'real-analysis', 'proof-verification']"
2243837,"Spectrum of $ T(x_1, x_2, x_3, x_4, \ldots )=(-x_2, x_1, -x_4, x_3, \ldots). $","Find the spectrum of the operator $T: l^p\to l^p$, $1\leq p\leq \infty$
$$
T(x_1, x_2, x_3, x_4, \ldots )=(-x_2, x_1, -x_4, x_3, \ldots).
$$ My attempt I have that $Tx = \lambda x$
$$ \implies \lambda (x_1, x_2, x_3, x_4, \ldots )=(-x_2, x_1, -x_4, x_3, \ldots)$$
$$ \implies \lambda (x_1, x_2, x_3, x_4, \ldots ) - (-x_2, x_1, -x_4, x_3, \ldots) = 0$$
$$ \implies   (\lambda x_1 + x_2, \lambda x_2 - x_1, \lambda x_3 + x_4, \lambda x_4  - x_3 , \ldots ) = 0$$
 $$ \implies x_1 = \lambda x_2, x_2 = - \lambda x_1$$ and similarly for $x_3, x_4 \cdots \cdots$. we then have
$$ \implies  \lambda = +i, -i.$$
Then what is the spectrum? Does it only consist of the eigen spectrum?",['functional-analysis']
2243847,Do quasi-isometries of semi direct products of free groups preserve fibres,"Is it true that any quasi-isometry between semi direct products $Z^{n} \times_{f} F, Z^{n} \times_{f'} F$ for $F$ finitely generated free non-abelian group (for $F$ abelian it is obviously false) sends $Z^{n} \times \lbrace{f \rbrace}$ uniformly close to $Z^{n} \times \lbrace{f' \rbrace}$ for some $f' \in F $ and all $f \in F$? I've read in lecture notes - ""Homology and dynamics in quasi-isometric rigidity
of once-punctured mapping class groups"" that it is true for direct product $ Z^{n} \times F $ and semi-direct products $Z^{n} \times_{f} F$ seem to be more dynamically complicated. Thank you for all your answers.","['geometric-group-theory', 'group-theory', 'free-groups']"
2243865,Compute line integral and prove statement about simply connected space of set,"Let C be circumference in $\mathbb{R^2}$ with centre in $(0,0)$ which we bypass counterclockwise.
Compute :
$$\oint_C -\frac{y}{x^2 + y^2}dx + \frac{x}{x^2 + y^2}dy$$
and then prove that set $\big\{(x, y) \big| 0 < x^2 + y^2 \le 1 \big\}$ is not simply connected space. So, I computed integral and obtain $2\pi$. Expression under integral sign is total derivative and I know that line integral of total derivative by closed curve in simply connected space is zero, but our integral is not zero. But my teacher said that is not full proof. Could you complement my solution or give any tips for this?","['multivariable-calculus', 'integration', 'vector-analysis']"
2243900,What exactly is calculus?,"I've researched this topic a lot, but couldn't find a proper answer to this, and I can't wait a year to learn it at school, so my question is: What exactly is calculus? I know who invented it, the Leibniz controversy, etc., but I'm not exactly sure what it is. I think I heard it was used to calculate the area under a curve on a graph. If anyone can help me with this, I'd much appreciate it.","['terminology', 'soft-question', 'calculus', 'definition']"
2243915,Do commutative Banach algebras with totally disconnected spectrum have linearly dense idempotents?,"Suppose that $A$ is a unital commutative Banach algebra. It is a nice application of the Shilov idempotent theorem that if the spectrum of $A$ is totally disconnected, then $A$ is regular. Can we show that idempotents in $A$ are linearly dense if the spectum of $A$ is totally disconnected? I think it must be known. This is really asking for the converse to this fact .","['functional-analysis', 'reference-request', 'operator-algebras', 'banach-algebras']"
2243917,"Why does the integral for the average value of a complex function on a circle normalize by $2\pi$, rather than $2\pi R$?","In Gamelin's Complex Analysis , the expression for the average value of a complex function on a circle is introduced before Cauchy's integral theorem. It says that the average value of $h(z)$ on the circle $|z-z_0|=R$ is given by
$$
A(r) = \frac{1}{2 \pi}
       \int_0^{2 \pi} h\left(z_0 + re^{i \theta}\right) d \theta.
$$ I'm puzzled as to why we are normalizing by $2\pi$ instead of $2\pi R$.",['complex-analysis']
2243947,Most Markov chain definitions are false,"When introducing discrete, time-homogenouos Markov chains $(X_n)_{n\geq 0}$, a lot of introductory lecture notes simply seem to assume the existence of a probability measure $\mathbb{P}$  on the common domain $\Omega$ of the $X_n$, given the  distribution of $X_0$ and the transition matrix $T$. (We need $\mathbb{P}$  to talk about things like $$\mathbb{P}(X_7=u \land X_{23}=v)$$ resp. $$\mathbb{P}((X_n)_{n\geq 0}=(s_n)_{n\geq 0}),$$for some $u,v$ from the state space $S$ resp.  a sequence of values $(s_n)_{n\geq 0}$ ins $S$, a measure $\mathbb{P}$ is required.) Only one set of lecture notes , out of many that I've consulted, have in passing mentioned that there is a thing such as the Ionescu-Tulcea theorem that shows that such probability measure $\mathbb{P}$ indeed exist (hence the title). This theorem is interestingly is not yet on Wikipedia - only on the german Wikipedia .The theorem is way above my head to understand it, as it is formulated. My questions are: Do we really need this theorem? If most lectures notes gloss over it, perhaps it is trivial that $\mathbb{P}$ exists? Since the Ionescu-Tulcea theorem seems to apply for general Markov chains, does its statement (which I don't fully understand currently) and proof perhaps simplify significantly for discrete, time-homogenuous Markov chains (perhaps if we additionally assume a finite state space)? I'd be very happy, if I could understand it's proof.","['definition', 'markov-chains', 'measure-theory', 'probability-distributions']"
2243967,How many distinct Unruly boards are there?,"Unruly is a puzzle game played on a board of $2n × 2n$ squares. Each square must be colored either black or white, with the following constraints: Each column must have $n$ white squares and $n$ black squares. Each row must have $n$ white squares and $n$ black squares. Nowhere on the board may 3 white squares or 3 black squares appear consecutively, whether horizontally or vertically. I define two Unruly boards to be equivalent if one can be transformed to the other with any combination of 90° rotations, horizontal flips, vertical flips, or color inversions (i.e., changing all whites to blacks and blacks to whites). For each $n$, how many non-equivalent Unruly boards are there?","['puzzle', 'combinatorics']"
2243976,Prove $\sqrt{n+1}-\sqrt{n}\lt \frac{1}{2\sqrt{n}}$,"I'm having some trouble figuring out where to start for this proof. Prove for all positive integers $n$ , $$\sqrt{n+1}-\sqrt{n}\lt \frac{1}{2\sqrt{n}}$$ Any help will be greatly appreciated.","['induction', 'discrete-mathematics']"
2243991,A proof that $\displaystyle\sum_{i=1}^{n}P''(r_i)/P'(r_i)=0$ for a degree $n$ polynomial,"Let $P(x)$ be a degree $n$ polynomial with distinct roots $r_1, r_2, \cdots r_n$. Prove that $$\displaystyle\sum_{i=1}^{n}\frac{P''(r_i)}{P'(r_i)}=0$$ My proof: We can equivalently rewrite the polynomial as $(x-r_1)(x-r_2)\cdots(x-r_n)$ and if we plug in the roots in the polynomial, we get that all of them are equal to $0$ so their first derivatives are equal to $1$ and then their second derivatives are equal to $0$ which means that all quotients are equal to $0$ and there for the sum is as well, $Q.E.D$ Don't show the solution please, but if you have a hint, feel free. Thank you.","['derivatives', 'summation', 'polynomials']"
2244026,Pointwise convergence of $f_n(x) = (x+1)\arctan(x^n)$,"I want to study the pointwise convergence of $f_n(x) = (x+1)\arctan(x^n)$ on $R$ but I have trouble establishing pointwise convergence on the interval $I = [-\infty, -1)$. My reasoning is the following: When $x\in I$, $x^n$ diverges, hence, $\arctan(x^n)$ is also divergent. Since $\arctan(x^n)$ diverges as $n \to \infty$, $f_n(x)$ is also divergent. Is my reasoning correct or does this count as a rigorous proof at all? Thanks.","['real-analysis', 'pointwise-convergence', 'functions']"
2244059,Show that $e^{f(x)}$ is convex.,"Let $f : (0,\infty) \to \mathbb{R}$ be a convex function. Prove that $e^{f(x)}$ is a convex function on $(0,\infty)$ . My original idea was to try and show that the second derivative is positive, but this will not work since $f(x)$ need not be differentiable. Here's my second attempt: By definition, since $f$ is convex, we have that $f(\lambda x+(1-\lambda)y)\leq\lambda f(x)+(1-\lambda)f(y)$ for any $\lambda \in (0,1)$ and $x,y \in (0,\infty)$ . Then, by applying the exponential to both sides we have that $e^{f(\lambda x+(1-\lambda)y))}\leq e^{\lambda f(x)+(1-\lambda)f(y)}$ . Applying rules of exponents, $e^{f(\lambda x+(1-\lambda)y))} \leq e^{\lambda f(x)}e^{(1-\lambda)f(y)}$ . From here, I want to bring the $\lambda$ and $1-\lambda$ terms down in front of the exponential, but I am stuck as to how to do this.","['real-analysis', 'convex-analysis']"
2244086,Why is a holomorphic map between compact connected Riemann surfaces a branched covering?,"I have seen it claimed that a non-constant holomorphic map $f:X \rightarrow Y$ between compact connected Riemann surfaces is a branched covering i.e. surjective and there is a finite set $\Sigma \subset Y$ and $r \in \mathbb{Z}_+$ such that $|f^{-1}(q)|=r$ for all $q \in Y \setminus \Sigma$. I can see why such a map is surjective, but I don't understand why the rest of the statement is true.","['riemann-surfaces', 'complex-analysis']"
2244103,Compute Ricci curvature for constant curvature Riemannian manifold,"If we have a Riemannian manifold $(M,g)$ with constant sectional curvature $C$ I have proven that the $(1,3)$ curvature tensor
$$R(X,Y)Z = C(\langle Y,Z\rangle X - \langle X,Z\rangle Y)$$
and that the $(0,4)$ Riemannian curvature tensor is given by
$$\operatorname{Rm}(X,Y,Z,W) = C(\langle X,W\rangle\langle Y,Z\rangle - \langle X,Z\rangle \langle Y,W\rangle)$$
now I would like to prove that the Ricci curvature, defined by $\operatorname{Ric}(X,Y) = \sum_{i=1}^n \operatorname{Rm}(X,e_i,e_i,Y)$ is given by $C(n-1)g(X,Y)$. I'm sure this should be a somewhat simple exercise given that we know what the Riemannian curvature is in this situation, but I cannot get any further than:
$$C\sum_{i=1}^n (g(X,Y)g(e_i,e_i) - g(X,e_i)g(Y,e_i))$$ Any help is appreciated!","['riemannian-geometry', 'differential-geometry']"
2244122,Understanding how a proof was developed,"Basically, my question is about methods of approaching a given proof. Let me elaborate on that with an example. Proposition: Suppose $a$ and $b$ $\in R$ and $a < b$. There is always a rational number, say $x$, in the range $a < x < b$. Proof: Chose N $\in N$ sufficiently large that $\frac{1}{N} < (b-a)$. Chose the least integer $z$ such that $b$N $\leq z$. $z$ being the least such integer, $(z-1) < b$N. Thus $\frac{(z-1)}{N} < b$. From then on, proof applies some inequality manipulation to show that this number is also greater than $a$. At this step, we conclude by noting that $\frac{(z-1)}{N}$ is a rational number. Now I picked this example since it is simple but the following things I'll say plagues me in most analysis proofs, since I started studying it. I consider a proof understood if I can fully see how the mathematician might have come up with the proof. Here, for example, it took me a lot of time to make sense why we chose N in such a way. Verifying the deductive steps is easy most of the time but uncovering the intention behind each step takes significant time. Studying rigorous real analysis for the first time, I feel like my approach to understanding proofs makes me waste a lot of time. Should I skim faster and skip details at first reading, should I abandon my obsession with justifying each step? I expected studying rigorous mathematics to take more time then my past engineering math efforts but this feels painful at times and makes you feel like giving up. Is there a book that teaches the skills needed, if there is any such skills, to better uncover the intention behind proofs?","['real-analysis', 'proof-writing', 'analysis']"
2244125,Subset of natural numbers without certain limit,"I'll lay out the whole problem first, then the part which I'm having trouble with. Let $\mathbb{N}$ be the set of natural numbers, $A_{n} = \{1, 2, ..., n\}$, $\mathscr{A}$ the collection of all subsets of $\mathbb{N}$ such that $$\lim_{n \to \infty} \frac{\#(A \cap A_{n})}{n}$$ exists. Denote the function which maps $\mathscr{A}$ to the aforementioned limit as $\alpha$. Prove that $\alpha$ is additive on the family $\mathscr{A}$ (for disjoint sets!), but that $\mathscr{A}$ is not closed for (finite) unions. The additive part is easy, as $|(A \sqcup B) \cap A_{n}| = |A \cap A_{n}| + |B \cap A_{n}|$. I can't think of an example of two (or more) sets which have this limit, but whose union does not.","['functions', 'elementary-number-theory']"
2244126,Probability using Bayes rule,"Suppose that in answering a question on a true/false test, an examinee either knows the answer with probability $p$ or s/he guesses with probability $1-p$. Assume that if the examinee knows the answer to a question, the probability that s/he gives the correct answer is $1$, and if s/he guesses then s/he only gives the correct answer with probability $0.5$. Use Bayes rule to compute the probability that an examinee knew the answer to a question given that s/he has correctly answered it. First I wrote out all the probabilities from the question. $$
P(\text{Wrong}) = 0.5 \\
P(\text{Correct}) = 0.5 \\
P(\text{Correct} \mid \text{Known}) = 1 \\
P(\text{Wrong} \mid \text{Known}) = 0 \\
P(\text{Correct} \mid \text{Guess}) = 0.5 \\
P(\text{Wrong} \mid \text{Guess}) = 0.5 \\
$$
I tried creating two equations with two unknowns to get a value of $p$ shown below: $$
(1)\quad 0.5 = \frac{P(\text{Guess} \mid \text{Correct})\cdot0.5}{1 - p}
$$ $$
(2)\quad 1 = \frac{P(\text{Known} \mid \text{Correct})\cdot0.5}{p}
$$ Then rearranged $(2)$ to get the following: $$
P(\text{Known} \mid \text{Correct}) = 2p
$$ And $P(\text{Guesses} \mid \text{Correct})$ is equal to $1 - P(\text{Knows} \mid \text{Correct})$ so I substituted that back into $(1)$ $$
(1)\quad 0.5 = \frac{(1 - 2p)\cdot0.5}{1 - p}\\
(1)\quad 0.5 = \frac{0.5 - p}{1 - p}\\
(1)\quad 0.5 - 0.5p = 0.5 - p\\
0.5p = 0\\
p = 0
$$ But this is can't be right, the question is only 5% so doesn't seem like it would be this much work, am I missing something simple here? The main equation that needs to be solved: $$
P(\text{Known} \mid \text{Correct}) = \frac{P(\text{Correct} \mid \text{Known}) P(\text{Known})}{P(\text{Correct})}
$$","['bayes-theorem', 'statistics', 'probability']"
2244137,Misunderstanding With Basic One-To-One Set Theory,"True or False: A function $f:A\to B$ is one-to-one iff for every $a \in A$ there exists exactly one $b \in B$ such that $(a,b) \in f$. I answered this statement as being true, using the logic that a function must map every element of $A$, and additionally a one-to-one function forbids the mapping of more than one element of $A$ to the same value. Therefore, there must be a single value in $B$ for every element of $A$, which is just a restatement of the question. However, the statement is actually false, and no explanation is provided. Where am I going wrong?","['elementary-set-theory', 'functions']"
2244138,Stationary Excess Expectation Proof,"Let $X$ be a positive random variable whose moments are all finite. Define the stationary excess $X_{e}$ to be the random variable with distribution $$P\{X_{e}\leq t\} = \frac{1}{\mathbb{E}X} \int_0^t P\{X>s\} ds$$ Show that if $f$ is a differentiable function where $\mathbb{E}[f(X)]$ and $\mathbb{E}[f'(X_e)]$ are well defined, then $$\frac{\mathbb{E}[f(X)-f(0)]}{\mathbb{E}X} = \mathbb{E}[f'(X_e)]$$. My attempt: By the fundamental theorem of calculus, $$ \begin{eqnarray}
\mathbb{E}[f(X)-f(0)] &=& \mathbb{E}\left[\int_0^X f'(\xi)  \ d\xi \right] \\
&=& \mathbb{E}\left[\int_0^\infty \mathbb{1}_{X\geq \xi} f'(\xi)  \ d\xi \right] \\
&=& \int_0^\infty P\{X\geq \xi\} f'(\xi)  \ d\xi
\end{eqnarray}$$ But I'm not sure how to proceed. Many thanks in advance!","['probability-theory', 'probability', 'expectation', 'probability-distributions']"
2244148,Is it mathematically problematic to consider the complex space of real(!)-valued functions?,"$L^2(ℝ)$ is obviously a real Hilbert space, and $L^2(ℂ)$ a complex Hilbert space. However it recently occured to me that it might also make sense to consider $L^2(ℝ)$ as a complex vector space, with
$$
  (μ \cdot f)(x) = μ \cdot f(x)
$$
in the usual way for real $μ$, but
$$
  (iμ \cdot f)(x) = μ \cdot H(f)(x)
$$
where $H : L^2(ℝ)\to L^2(ℝ)$ is the Hilbert transform . Why? Well, physicists and engineers seem to be using that space all the time: it's generally understood that there's no such thing as an imaginary, measurable physical quantity, and when we consider “phase rotation by 90°” (i.e. multiplication with $i$) we actually mean that a sinusoidal signal is shifted by a quarter wavelength – precisely what the Hilbert transform does. Can all of this be made rigorous?","['functional-analysis', 'hilbert-spaces', 'complex-numbers', 'soft-question']"
2244177,Counterfeit Coin Problem Variant - Two Counterfeits,"So there's a counterfeit coin variant that I stumbled across and I'm not sure exactly how to solve it. It goes as follows: You have eight coins, two of which are counterfeit. One of the two is slightly heavier than normal, the other is slightly lighter. The two counterfeit coins have the same combined weight as two normal coins. You have a balance. How many weighings are necessary to identify both the heavier and lighter coin? I can do it in five, but I strongly suspect you can do it in fewer. EDIT: Solution for five weighings: Label your coins 1 through 8. Weigh 1 against 2, 3 against 4, 5 against 6, 7 against 8. If we get three balanced scales and one imbalanced scale, we know which two coins are counterfeit. If we get two balanced scales and two imbalanced scales, assume without loss of generality that 1 was heavier than 2 and 3 was heavier than 4. From this we can deduce that either 1 is the heavy counterfeit and 4 is the light counterfeit, or 2 is the light counterfeit and 3 is the heavy counterfeit. Therefore, we weigh 1 against 4. If they are balanced, then 2 is the light counterfeit and 3 is the heavy counterfeit. Otherwise, 1 is heavy and 4 is light. EDIT: As mentioned by Mees de Vries below, 3 weighings with 3 possible outcomes each can only distinguish between 27 possible scenarios. We have 56 total possible configurations, and so 4 weighings must be optimal if it is possible.","['recreational-mathematics', 'discrete-mathematics']"
2244203,"The minimum ""height"" of a convex polygon on $\mathbb{N}^2$.","I've defined a new OEIS sequence but I'm having trouble figuring out a reasonable way to compute more terms. A285521 : Table read by rows: the $n$-th row gives the lexicographically earliest sequence of length $n$ such that the convex hull of $(1, a(1)), \ldots, (n, a(n))$ is an $n$-gon with minimum height. The table begins: $$\begin{array}{l}
    1\\
    1,1\\
    1,1,2\\
    1,1,2,2\\
    1,1,3,2,3\\
    1,2,1,3,2,3\\
    1,3,1,4,4,2,3\\
    2,3,1,1,4,4,2,3\\
\end{array}$$ For example rows 5–8 are represented like this: $$\begin{array}{ccccc|cccccc|ccccccc|cccccccc}
5\colon&&&&&
6\colon&&&&&&
7\colon&&&&&&&
8\colon&&&&&&&\\
 & & & & & & & & & & & & & &.&.& & & & & & &.&.& &\\
 & &.& &.& & & &.& &.& &.& & & & &.& &.& & & & & &.\\
 & & &.& & &.& & &.& & & & & & &.& &.& & & & & &.&\\
.&.& & & &.& &.& & & &.& &.& & & & & & &.&.& & & &\\
\end{array}$$ By an exhaustiveness check, I've confirmed that the 9-gon in the ninth row must have a height greater than five, and I can construct one by hand with height six. Any ideas on how to determine (or put a bound on) the minimum height required for the $n$-th row? Any heuristics or tricks that can be used to compute more terms of the sequence? (for example, no value can appear more than twice in a single row.)","['combinatorics', 'algorithms', 'oeis', 'discrete-mathematics']"
2244218,totient function series diverges?,"Earlier today I thought I proved that the following series diverged: $$\sum_{n=2}^\infty\frac{\phi(n)}{n^2}$$ as a result of a misapplication of the prime number theorem. I mistook $\phi(n)$ for $\pi(n)$ in the statement. Is this salvageable? I've been trying to find lower bounds for $\phi(n)$ that I may pass to, but the literature on this is a bit dense for me. Thanks","['number-theory', 'sequences-and-series', 'totient-function']"
2244224,"Given three distinct points on a sphere, find the unique round circle they live in","Say you have three (distinct) points on the unit sphere in Euclidean space $$p_1, p_2, p_3 \in S^n = \{ x \in \mathbb R^{n+1} : |x| = 1 \}$$ I'd like to find, as efficiently and robustly as possible, a description of the unique round circle in $S^n$ that contains the three points.  By round circle I mean the intersection of an affine $2$ -dimensional subspace of $\mathbb R^{n+1}$ with $S^n$ . I'm mostly interested in the $n=3$ case, although the $n>3$ cases are of some interest to me as well. Off the top of my head the most sensible way to accomplish this would be: Find the smallest-norm convex-combination of the $p_i$ 's, i.e. solve $$\min \left\|\sum_i \alpha_i p_i\right\|, \hskip 1cm \sum_i \alpha_i = 1$$ which is a calculus problem. Replace the $p_i$ 's by $p_i - q$ where $q$ is the above norm-minimizer. Compute the orthogonal complement of $span(p_1, p_2, p_3)$ . If $q_1, q_2, \cdots, q_{n-2}$ is a basis for the orthogonal complement then that would give a system of equations describing the circle. $$q_i \cdot (x-p_j) = 0$$ for all $i,j$ (these equations would technically be independent of j). The nice thing about this setup is it's just linear algebra.  One problem with this solution is step (2) -- if the norm-minimizer results in a very small but non-zero norm there might be numerical instabilities.  In the application I have in mind, there will be (potentially) billions of such computations and these kinds of instabilities will be difficult to avoid. The $n=2$ case has a rather cute, stable and efficient solution which (off the top of my head) I don't see how to generalize $$Det \pmatrix{ x & y & z & 1 \cr \cdot & \cdot & \cdot & 1 \cr \cdot & \cdot & \cdot & 1 \cr \cdot & \cdot & \cdot & 1} = 0$$ where you plug the three points $p_1, p_2, p_3$ into the dotted rows. If there was a more general solution of this kind, that would be wonderful as it solves the stability issue.  On top of that, it's a simple closed-form solution and my application could use a solution that is easily differentiated.  I don't need that, but it would be useful. edit: I need an answer that gives the ""universal bundle"" description of the circle, i.e. an equation of the plane the circle lives in.  You could think of this as a point in the Grassmannian $G_{n+1,2}$ together with a vector in the orthogonal complement of the 2-dimensional subspace.  This is because I need ready access to the Hausdorff distance function (minimum distance) from points in the sphere to the circle.  i.e. a parametrization of the circle is not enough. edit 2: in my comment below I refer to the matrix formulation of the Grassmannian.  In this formulation, the space of 2-dimensional subspaces of $\mathbb R^n$ is the space of $n\times n$ matrices $A$ such that: $A^t = A, A^2=A, \text{ and } tr(A) = 2$ .  From this perspective the matrix $A$ represents the orthogonal projection map onto its image, which is a $2$ -dimensional subspace.","['spheres', 'configuration-space', 'geometry']"
2244234,What is the most efficient way to calculate $R^2$?,"Hello I am working on a question from an old exam paper and wondered what is the best way to tackle parts ii and iii. Given the data it is easy to find $\hat{\beta_0}=-1.071$ and $\hat{\beta_1}=2.741$. Now for part ii) I have the formula $R^2=1-SSE/SST$ where $SST=\sum(y_i-\bar{y})^2$ (easy to work out) and $SSE=\sum e_i^2=\sum (y_i-\hat{y_i})$. Likewise I have for part iii) An unbiased estimate of $\sigma^2$ is $\sum e_i^2/(n-2)$. Question: I wondered if there is a nice and more efficient way to work
  out $\sum e_i^2$ or do I have to calculate each predicted value based
  on the model take it away from the actual value square that value and
  then sum all the values up?","['regression', 'statistics']"
2244257,Examples of compact negatively curved constant curvature manifold,I am looking for concrete examples of negatively curved constant curvature manifold. The only example of negatively curved constant curvature manifold is the hyperbolic plane. Are there any easy examples of such manifolds which are compact.,['differential-geometry']
2244312,Does the graph of a measurable function always have zero measure?,"Question: Let $(X,\mathscr{M},\mu)$ be a measure space and $f\colon X \to [0,+\infty[$ be a measurable function. If ${\rm gr}(f) \doteq \{ (x,f(x)) \mid x \in X \}$, then does it always satisfy $$(\mu \times \newcommand{\m}{\mathfrak{m}} \m)({\rm gr}(f)) = 0$$even if the domain space is not $\sigma$-finite? Here $\m$ denotes Lebesgue measure in $[0,+\infty[$. Context: define the ""shadows"" $$\begin{align*} G_{f,<} &\doteq \{ (x,y) \in X \times \left[0,+\infty\right[ \mid y < f(x)
 \} \\ G_{f,\leq} &\doteq \{ (x,y) \in X \times \left[0,+\infty\right[ \mid y \leq f(x)\}.\end{align*}$$One can prove that $$(1) \qquad (\mu \times \m)(G_{f,<}) = \int_X f(x)\,{\rm d}\mu(x)$$ and that, if $\mu$ is $\sigma$-finite , that $$(2) \qquad(\mu \times \m)(G_{f,\leq}) = \int_X f(x)\,{\rm d}\mu(x).$$This implies that if $\mu$ is $\sigma$-finite, then $(\mu \times \m)({\rm gr}(f)) = 0$. But is this hypothesis really needed? I have the following proofs, in case this helps anyone think: Proof of (1) without $\sigma$-finiteness: If $A \in \mathscr{M}$ and $f = \chi_A$, then $$(\mu \times \m)(G_{f,<}) \stackrel{(\ast)}{=} (\mu \times \m)(A \times [0,1[) = \mu(A)\m([0,1[) = \mu(A) = \int_X \chi_A(x)\,{\rm d}\mu(x),$$where $(\ast)$ holds because points have zero Lebesgue measure. The above clearly implies that the formula is valid for simple positive functions. If $f$ is measurable and positive, take a sequence $(\varphi_n)_n$ of simple and positive functions that converge to $f$, increasing. Then $\bigcup_n G_{\varphi_n,<} = G_{f,<}$, so upper continuity of the product measure and the Monotone Convergence Theorem give $$\begin{align*}(\mu \times \m)(G_{f,<})&=(\mu \times \m)\left(\bigcup_n G_{\varphi_n,<}\right) = \lim_n (\mu \times \m)(G_{\varphi_n,f})\\ &= \lim_n \int_X \varphi_n(x)\,{\rm d}\mu(x) = \int_X f(x)\,{\rm d}\mu(x),\end{align*}$$as wanted. This fails for $G_{f,\leq}$, since that set equality need not be true anymore. If we still had equality of measures, it would be fine, but I think that amounts to my initial question. Proofs assuming $\sigma$-finitess: apply Fubini-Tonelli as follows: $$\begin{align*} (\mu \times \m)(G_{f,<}) &= \int_{X \times [0,+\infty[} \chi_{G_{f,<}}(x,y)\,{\rm d}(\mu \times \m)(x,y) \\ &= \int_X \int_{[0,+\infty[} \chi_{[0,f(x)[}(y)\,{\rm d}\m(y)\,{\rm d}\mu(x) = \int_X f(x)\,{\rm d}\mu(x)\end{align*}$$Since points have zero Lebesgue measure, the same argument with $[0,f(x)]$ instead of $[0,f(x)[$ gives the formula for $G_{f,\leq}$. And using $\{f(x)\}$ instead along with $\m(\{f(x)\}) =0$ gives $(\mu \times \m)({\rm gr}(f))=0$. Bonus track: does anyone know any results in this direction if we had another measure space as co-domain? Is it possible to have ""fat"" graphics?","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2244314,Taking the logarithm of the integrand,"Say you have a function, $f(x)$. Is there any way to write the expression, $$ \int \ln(f(x)) \, \mathrm{d} x$$ in terms of $$ \int f(x) \, \mathrm{d} x$$ Or just some other way to simplify or deal with the logarithm inside the integral?","['logarithms', 'integration', 'calculus', 'functions']"
2244315,How to solve the homogeneous differential equation?,"EDITED WITH FINAL ANSWER: Solve the following differential equation:
$$y' = \frac{2xy}{x^2-y^2}$$ Someone please help me to finish this problem.
My solution so far:
$$\frac{dy}{dx} = \frac{\frac{1}{x^2}(2xy)}{\frac{1}{x^2}(x^2-y^2)}$$
$$\frac{dy}{dx}= 2\frac{y}{x} * \frac{1}{1-{\frac{y^2}{x^2}}}$$
Let $v = \frac{y}{x}$, $y=vx$ then $\frac{dy}{dx} = v+x\frac{dv}{dx}$
$$\frac{dy}{dx} = \frac{2v}{1-v^2}$$
Setting the two equations equal to one another:
$$v+x\frac{dv}{dx} = \frac{2v}{1-v^2}$$
$$x\frac{dv}{dx} = \frac{2v}{1-v^2} - \frac{v-v^3}{1-v^2}$$
$$x\frac{dv}{dx} = \frac{v+v^3}{1-v^2}$$
$$xdv = \frac{v+v^3}{1-v^2}dx$$
$$\frac{1-v^2}{v+v^3}dv = \frac{1}{x}dx$$
$$\int\frac{1-v^2}{v+v^3}dv = \int\frac{1}{x}dx$$
$$\ln \left|v\right|-\ln \left|v^2+1\right| = ln|x| + c$$
Substituting $\frac{y}{x}$ back for $v$:
$$\ln \left|\frac{y}{x}\right|-\ln \left|\frac{y^2}{x^2}+1\right| = ln|x| + c$$
$$\ln \left|{y}\right|-\ln|x|-\ln \left|\frac{y^2}{x^2}+1\right| = ln|x| + c$$
Taking $e$ to everything we obtain:
$$y - x - (\frac{y^2}{x^2}+1) = x + e^c$$
$$y - (\frac{y^2}{x^2}+1) = 2x + e^c$$
$$y - \frac{y^2}{x^2} - 1= 2x + e^c$$
$$y - \frac{y^2}{x^2} = 2x + e^c + 1$$
$$\frac{x^2y-y^2}{x^2} = 2x + e^c + 1$$
$$x^2y-y^2 = 2x^3 + x^2e^c + x^2$$
$$0 = y^2 - x^2y + 2x^3 + x^2e^c + x^2$$ Using the quadratic formula we obtain
$$y = \frac{x^2±\sqrt{x^4-8x^3-4x^2e^c-4x^2}}{2}$$
$$y = \frac{x^2±\sqrt{x^2(x^2-8x-4e^c-4)}}{2}$$
$$y = \frac{x^2±x\sqrt{x^2-8x-4e^c-4}}{2}$$","['functional-analysis', 'real-analysis', 'ordinary-differential-equations', 'calculus']"
2244317,Does eventually polynomial imply finitely generated?,"I was considering converses to the theorem of Hilbert that the Hilbert function of a finitely generated graded module over $k[x_0,\dots,x_n]$ is eventually polynomial.  I asked the following question and I'm curious if it's true or to have a counterexample. Let $k$ be a field and $R\subseteq k[x_0,\dots,x_n]$ be generated by homogeneous elements.  Let $\varphi(l)=\dim_k R_l$.  Suppose that $\varphi(l)$ is eventually polynomial.  Does this imply that $R$ is finitely generated?  Feel free to add extra conditions, if necessary.","['algebraic-geometry', 'commutative-algebra']"
2244325,All $\mathbb{Z}$-submodules of $\mathbb{Z}\oplus\mathbb{Z}$ are free.,"We are looking for a somewhat direct proof that all $\mathbb{Z}$-submodules of $\mathbb{Z}\oplus\mathbb{Z}$ are free. We already know that if $A$ is a P.I.D. and we have a free $A$-module $M$, then every sub $A$-module of $M$ is free. However, the proof for this requires quite advanced arguments and we have a strong feeling that a simple proof can be provided for our specific case. We tried using projections but did not manage to write a coherent proof of the statement. Thank you very much in advance for your tips and tricks.","['modules', 'abstract-algebra', 'principal-ideal-domains', 'ring-theory', 'free-modules']"
2244328,Maximum Likelihood Parameter Estimation: Assuming Mean of Observations,"I'm currently in a probability class learning about parameter estimation using the maximum likelihood estimator. The problem is as follows: we have a list of independent observations Y y[1]...y[n], that came from some probability distribution $f_Y(y,\lambda) $ with an unknown parameter $\lambda $. (For example, exponential, Gaussian, Poisson, etc.) We want to estimate the parameter $\lambda$ by maximizing the likelihood that we see the observations we do. Since all observations are independent, we have probability $P(Y,\lambda)= \prod_{i=1}^{n} f_Y(y_i,\lambda)$. To maximize this, we take the derivative with resepect to $\lambda$ and set to 0.
$$ \hat\lambda= \arg \max_{\lambda} \left[ P(Y,\lambda) \right]$$ Something I noticed: for every example of this I've seen so far (only about 2 or 3 now), the end result is always the same: the value of the parameter is whatever makes the mean of your observation vector equal $E[f_Y(y,\lambda)] $. For example, for an exponential distribution, we get $$\hat\lambda=\frac{1}{\frac{1}{n}\sum_{i}y_i} = \frac{1}{\mu_Y} $$
This makes intuitive sense, because for an exponential distribution, the expected value is $1/\lambda $. My question is this: can you always assume that the mean of your observations is the mean of your probability distribution and just solve for the unkown parameters using that assumption? Just because it works for the few cases I've seen, I don't know whether this can be generalized to any probability distribution. I'm completely new to these topics, so any additional info would be appreciated. Thanks in advance!","['parameter-estimation', 'statistics', 'probability', 'probability-distributions']"
2244377,Construction of the Čech-Stone compactification: why is $\iota$ an embedding?,"I have been reading a post on Terence Tao's blog about the Čech-Stone compactification.  He constructs a compactification as follows (see his exercise 3).  Let $X$ be a locally compact Hausdorff space.  Let $C\left(X,\left[0,1\right]\right)$ be the set of continuous functions from $X$ to $\left[0,1\right]$.  Let $Q=\left[0,1\right]^{C\left(X,\left[0,1\right]\right)}$ with the product topology. Let $\iota\colon X\rightarrow Q$ be given by $\iota\left(x\right)=\left(f\left(x\right)\right)_{f\in C\left(X,\left[0,1\right]\right)}$ for all $x\in X$.  Let $\beta X$ be the closure of $\iota\left(X\right)$ in $Q$.  Then $\left(\beta X,\iota\right)$ is a Čech-Stone compactification of $X$. I'm trying to see why $\left(\beta X, \iota \right)$ is a compactification.  I am able to show that $\beta X$ is compact and that $\iota$ is a continuous bijection whose image is a dense subset of $\beta X$, but I have been unable to see why $\iota$ must be an embedding. In particular, suppose $X=\mathbb{N}$.  Then $\iota\left(\{0\} \right) = \{\left(f\left(0\right)\right)_{f\in C\left(\mathbb{N}\rightarrow \left[0,1\right]\right)}\}$, which is not, it seems to me, open in $\beta X$ as a subspace of $Q$ with the product topology.  I am sure I am misunderstanding something, as my topology experience is limited. Edit My counterexample of $\iota\left(\{0\}\right)$ is wrong, as explained in the comments of @user254665's answer.  Implicitly, I was assuming that $\iota\left(\mathbb{N}\right) = \Pi_{f\in C\left(\mathbb{N} \rightarrow \left[0,1\right]\right)}f\left(\mathbb{N}\right)$, which is incorrect.  Moreover, the following argument shows that $\iota\left(\{0\}\right)$ is in fact open in $\iota\left(\mathbb{N}\right)$.  Let $f \colon \mathbb{N} \rightarrow \left[0,1\right]$ be given by $f\left(0\right)=1$ and $f\left(n\right)=0$ for $n\ne 0$. Let $U = \{q\in Q \vert q_{f}=1\}$.  Then $U$ is open in $\iota\left(\mathbb{N}\right) \subset Q$, $\iota\left(0\right) \in U$, and if $n\ne 0$ then $\iota\left(n\right) \notin U$.","['general-topology', 'compactification', 'compactness']"
2244392,How to compute $E[X(Y)]$?,"I am concerned about how to compute $E[X(Y)]$. That is $Y$ is a random variable, and for each $Y=t$, $X(t)$ is a random variable. The question raised from the following problem: Consider the following system. Suppose that there is a Poisson arrival process, by which jobs
arrive to the system at rate $\lambda$. When a job arrives, it first arrives to an infinite-server queueing system $S_1$, in which processing times are i.i.d. exponentially distributed with rate 3 (mean $3^{-1}$). After
completing at $S_1$, a given job moves to a second infinite-server system $S_2$, where processing times are also
i.i.d. exponentially distributed with rate 3. After finishing at $S_2$, there is a third infinite-server
system $S_3$, and a fourth, etc. In fact, there is an endless chain of infinite-server systems. Whenever a job
completes at system $S_i$
, it moves to system $S_{i+1}$, at which its processing time is also i.i.d. exponentially
distributed with rate 3. Suppose it takes zero time to move between systems. Suppose that whenever
a job first arrives to the system $S_1$, it is given 1 dollar. Every time it begins service at a new system, its
wealth doubles. Thus when it arrives to $S_2$, its wealth goes from 1 dollar to 2 dollars, etc. Also suppose
that at time 0, the system is empty. Let $Z$ denote an exponentially distributed r.v. with rate 8 (mean $8^{-1}$),
independent of all else. Let Dollars($t$) denote the total amount of money collectively had by all jobs in the
system by time t, namely the sum, over all jobs in the system at time t, of the amount of money each of
those jobs has at time $t$. Thus if there are 4 jobs in the system, and one has 1 dollar, 2 have 4 dollars, and
1 has 16 dollars, Dollars($t$) would equal 25. Compute $E[\text{Dollars}(Z)].$ It seems $\text{Dollars}$ is a random variable about time, and $Z$ itself is a random variable. I try to use $E[\text{Dollars}(Z)]=\int_0^\infty \text{Dollars}(t)P(Z=t)dt$, while the $\text{Dollars(t)}$ is not deterministic. I wonder if $E[\text{Dollars}(Z)]$ is a random variable. I don't know how to compute such expectation. And to solve the whole problem, I suspect we need to use Poisson splitting for non-homogeneous Poisson process.","['stochastic-processes', 'markov-chains', 'probability-theory', 'probability']"
2244395,Closed-form solution for a second order ODE,"I have a series of second order ODE's that are in the form: $$
Ay''+By'+Cy=\frac{1}{1+e^{-t}}
$$ ($y'' = \frac{d^2}{dt^2}y(t)$,  $y' = \frac{d}{dt}y(t)$ ) The initial conditions are known: $y(0)=y_0$, $y'(0)=y'_0$ Clearly, the general solution for the homogeneous form $Ay''+By'+Cy=0$ is trivial; I'm stuck in finding the particular solution. Is there a hope that I can come up with a closed-form solution parametrized by $A$, $B$, $C$ and the initial conditions (All in $\mathbb{R}$)? Background: Initially I was trying to solve the ODE with the step function (the heavy-side function: $u(t)=1~if~t>0; ~0~ow$) on the right-hand side and a different set of coefficients on the left-hand side: $$
(A_1t+A2)y''+(B_1+B2)y'+(C_1t+C2)y=\frac{1}{1+e^{-t}}
$$ But, I thought maybe I could find the solution with a smooth function on the RHS, and a simpler ODE in the first place. Therefore, a solution to the original (either with affine or with constant coefficients) problem will be helpful too. Thanks for any help!",['ordinary-differential-equations']
2244402,What is an example of a smooth function in $C^\infty(\mathbb{R}^2)$ which is not contained in $C^\infty(\mathbb{R})\otimes C^\infty(\mathbb{R})$,"When looking at the tensor product of the ring of smooth functions on $\mathbb{R}^n$, there is only an injection
$$
C^\infty(\mathbb{R}^n)\otimes_\mathbb{R}C^\infty(\mathbb{R}^m) \to C^\infty(\mathbb{R}^{n+m})
$$
This motivates the construction of the completed tensor product which gives an isomorphism. What is an example of a smooth function which in
$$
C^\infty(\mathbb{R}^2)
$$
which does not lie in the standard tensor product?","['tensor-products', 'smooth-manifolds', 'differential-geometry', 'algebras']"
2244541,"Finitely additive measure over $\mathbb{N}$, under AD.","Under the axiom of choice, there are lots of non-trivial (that is, a measure vanishes every finite set) finitely-additive measures over $\mathbb{N}$ : for example, ultrafilters over $\mathbb{N}$ or measures occur in other answers . However, as far as I know, $\mathsf{AD}$ proves every ultrafilter is $\aleph_1$ -complete and hence every ultrafilter over $\mathbb{N}$ is principal. My question is: does the same result hold for (real-valued) measures? That is, I wonder whether $\mathsf{AD}$ proves every finitely-additive measure is $\sigma$ -additive. Thanks for any help.","['descriptive-set-theory', 'set-theory', 'measure-theory']"
2244545,The length of $f(\partial B_r)$ is at least $2 \pi r|f^{\prime}(0)|$.,"Let $f$ be a function analytic in the unit disk. The circle with center
  at the origin and radius $r$ is mapped by $f$ onto a curve whose length is
  denoted by $L(r)$. Prove the inequality $L(r) \geq 2r \pi |f^{\prime}(0)|$. Is it sharp? I am trying to use the Schwarz lemma, since it is the only theorem in my book that talks  about $|f^{\prime}(0)|$, but I cannot . Can you please help me?",['complex-analysis']
2244570,Weak derivative of a given function,"$\def\d{\mathrm{d}}$Find the weak derivative of the following function:
  $$u(x)=\begin{cases}x; & x\in(0,1]\\2; & x\in (1,2]\end{cases}.$$ We have,\begin{align*}
\int_0^2v(x)\phi(x)\,\d x&=\int_0^2 u'(x)\phi(x)\,\d x=-\int_0^2 u(x)\phi'(x)\,\d x\\
&=-\int_0^1x\phi'(x)\,\d x-\int_1^22\phi'(x)\,\d x.
\end{align*}
Then how I can proceed to find the weak derivative of $u(x)$?","['functional-analysis', 'weak-derivatives', 'analysis']"
2244666,"Isn't $\mathbb{E}[X^2|X\in[-b,b]]\leq \mathbb{E}[X^2]$ true?","Let $X$ be a centered random variable such that $\mathrm{support}(X)\subseteq[-B,B]$, $B>0$, with discrete or continuous density $f$. Now, consider an event $\xi=\{X\in [-b,b]\}$, $b\in[0,B)$, with $\mathbb{P}(\xi)\in(0,1)$. Then we have
$$\mathbb{E}[X^2|\xi]=\frac{1}{\mathbb{P}(\xi)}\int x^2\mathbb{1}_{[-b,b]}(x)f(x)\ \mathrm{d} x\leq \frac{1}{\mathbb{P}(\xi)}\int x^2f(x)\ \mathrm{d} x= \frac{1}{\mathbb{P}(\xi)}\mathbb{E}[X^2].$$
(Where the integral is meant in the Lebesgue- or Dirac- sense.) However, intuitively, in this setting I would expect $\mathbb{E}[X^2|\xi]\leq \mathbb{E}[X^2]$. So my questions are: If the latter result is true, how can it be proved? If it is wrong, can you provide a counter-example?","['conditional-expectation', 'probability', 'random-variables']"
2244675,Why does bayes theorem frequently have sum in denominator?,"I frequently see Bayes Theorem phrased in two different ways. Simple Bayes Theorem:
$$P(X|Y) = \frac{P(X)P(Y|X)}{P(Y)}$$ Complex Bayes Theorem:
Let $X_1, \dots, X_k$ be a partition of the sample space.
$$P(X_i|Y) = \frac{P(X_i)P(Y|X_i)}{\sum_{j = 0}^k P(X_j)P(Y|X_j)}$$ The second version follows pretty quickly from the first by noticing
$$\sum_{j = 1}^k P(X_j | Y) = 1.$$ Thus $$P(Y) = \sum_{j = 1}^k P(Y)P(X_j | Y) = \sum_{j = 1}^k P(X_j)P(Y | X_j)$$ My question is, why is the second version even mentioned? Is it used in that form frequently? How often can I easily find $P(X_j)P(Y|X_j)$ for each $j$, but not know $P(Y)$ off hand?",['probability']
2244692,Points in $ \mathbb{R}^{n} $,"Let $ a_{1}, \dots a_{m} \in \mathbb{R}^{n} $ such that $ ||a_{i}-a_{j}||=1 \, \forall i \neq j $, where $ || \cdot || $ denotes the usual norm on $ \mathbb{R}^{n} $. Prove that $ m \leq n+1 $. 
I did it for the easy case when $ n=1 $ by explicit computation using the modulus, but I can't think of a clever argument for the general case. I think I should use some inequalities like Minkowski, Cauchy-Schwarz or the triangle inequality, but I don't see how. 
I would appreciate any help. Thank you!","['inequality', 'euclidean-geometry', 'geometry']"
2244696,Which matrix $P$ makes two matrices $A$ and $B$ similar,"Two square matrices $A,\ B$ are similar if $\exists P : PAP^{-1} = B$. In order to find $P$ for two given $A,\ B$ one can try to solve $PA-BP = 0$. I worked out this equation for abstract $3 \times 3$ matrices: $A = \left(\begin{matrix}a_{00} & a_{01} & a_{02}\\a_{10} & a_{11} & a_{12}\\a_{20} & a_{21} & a_{22}\end{matrix}\right),\ 
B = \left(\begin{matrix}b_{00} & b_{01} & b_{02}\\b_{10} & b_{11} & b_{12}\\b_{20} & b_{21} & b_{22}\end{matrix}\right),\ 
P = \left(\begin{matrix}p_{00} & p_{01} & p_{02}\\p_{10} & p_{11} & p_{12}\\p_{20} & p_{21} & p_{22}\end{matrix}\right)$ If one considers $3 \times 3$ matrices as vectors of a $9$ dimensional vector space, using the following matrix expressions: $PA \mapsto \left(\begin{matrix}a_{00} & a_{10} & a_{20} & 0 & 0 & 0 & 0 & 0 & 0\\a_{01} & a_{11} & a_{21} & 0 & 0 & 0 & 0 & 0 & 0\\a_{02} & a_{12} & a_{22} & 0 & 0 & 0 & 0 & 0 & 0\\0 & 0 & 0 & a_{00} & a_{10} & a_{20} & 0 & 0 & 0\\0 & 0 & 0 & a_{01} & a_{11} & a_{21} & 0 & 0 & 0\\0 & 0 & 0 & a_{02} & a_{12} & a_{22} & 0 & 0 & 0\\0 & 0 & 0 & 0 & 0 & 0 & a_{00} & a_{10} & a_{20}\\0 & 0 & 0 & 0 & 0 & 0 & a_{01} & a_{11} & a_{21}\\0 & 0 & 0 & 0 & 0 & 0 & a_{02} & a_{12} & a_{22}\end{matrix}\right)\left(\begin{matrix}p_{00}\\p_{01}\\p_{02}\\p_{10}\\p_{11}\\p_{12}\\p_{20}\\p_{21}\\p_{22}\end{matrix}\right)$ $BP \mapsto \left(\begin{matrix}b_{00} & 0 & 0 & b_{01} & 0 & 0 & b_{02} & 0 & 0\\0 & b_{00} & 0 & 0 & b_{01} & 0 & 0 & b_{02} & 0\\0 & 0 & b_{00} & 0 & 0 & b_{01} & 0 & 0 & b_{02}\\b_{10} & 0 & 0 & b_{11} & 0 & 0 & b_{12} & 0 & 0\\0 & b_{10} & 0 & 0 & b_{11} & 0 & 0 & b_{12} & 0\\0 & 0 & b_{10} & 0 & 0 & b_{11} & 0 & 0 & b_{12}\\b_{20} & 0 & 0 & b_{21} & 0 & 0 & b_{22} & 0 & 0\\0 & b_{20} & 0 & 0 & b_{21} & 0 & 0 & b_{22} & 0\\0 & 0 & b_{20} & 0 & 0 & b_{21} & 0 & 0 & b_{22}\end{matrix}\right)\left(\begin{matrix}p_{00}\\p_{01}\\p_{02}\\p_{10}\\p_{11}\\p_{12}\\p_{20}\\p_{21}\\p_{22}\end{matrix}\right)$ the equation to solve can be expressed as: 
$$ 
(I \otimes A^t - B \otimes I)p = 0
$$ Where $\otimes$ stands for the Kronecker product of square matrices and $I$ is the identity matrix.
The question is if this can be proven for arbitrary dimensions?","['matrices', 'linear-algebra']"
2244709,How can we prove that $8\int_{0}^{\infty}{\ln x\over x}\left(e^{-x}-{1\over \sqrt[4]{1+8x}}\right)\mathrm dx=-32C+4\gamma^2-5\pi^2?$,"An integral exhibits $3$ interesting constants. $$8\int_{0}^{\infty}{\ln x\over x}\left(e^{-x}-{1\over \sqrt[4]{1+8x}}\right)\mathrm dx=-32\color{red}C+4\color{blue}\gamma^2-5\color{green}\pi^2\tag1$$ I am only interested in $(1)$, because rarely Catalan's constant and Euler-Masheroni's constant they appear together! Making an attempt: It is too difficult here to make an attempt, apart from differentiating under the integral $$I(a)=8\int_{0}^{\infty}{\ln x\over x^{a}}\left(e^{-x}-{1\over \sqrt[4]{1+8x}}\right)\mathrm dx\tag2$$ $$I{'}(a)=8\int_{0}^{\infty}{1\over x^{a}}\left(e^{-x}-{1\over \sqrt[4]{1+8x}}\right)\mathrm dx\tag3$$ I guess $(3)$ diverges How may we prove $(1)?$","['integration', 'definite-integrals', 'calculus']"
2244723,Generalization of real induction for topological spaces?,"Real induction is a useful proof technique which can be thought as a version of ""continuous"" induction. I will include here version from Pete L. Clark's text mentioned in this answer , 1 where it is formulated like this: 2 Let $a < b$ be real numbers. Let a subset $S \subseteq [a,b]$ be inductive , i.e.: (RI1) $a\in S$ . (RI2) If $a\le x<b$ , then $x\in S$ $\implies$ $[x,y]\subseteq S$ for some $y > x$ . (RI3) If $a < x \le b$ and $[a,x)\subset S$ , then $x \in S$ . Then $S=[a,b]$ . Stated informally (and a bit vaguely and imprecise), if I want to prove that some property holds for all points of the interval $[a,b]$ , I can prove this ""from left to right"" by checking that: The leftmost point $a$ has the required property. If $x$ has the given property, then I can show that at least some points near $x$ to the right have this property. If I can find points with this property arbitrarily close on left from $x$ , then also $x$ has this property. (This does not correspond exactly to the three conditions above, but if you consider that the property we are trying to prove is "" $[a,x]\subseteq S$ "", then the correspondence between these three bullet points and the conditions (RI1), (RI2), (RI3) seems to be more natural.) The linked text also discusses some generalization of this principle to linearly ordered sets and ordered fields. There is also this question on MathOverflow which asks about generalization to partial orders: A principle of mathematical induction for partially ordered sets with infima? I wonder whether we can generalize this to some context where we do not have ordering. Question. Are there some natural generalizations of the above method to topological spaces or metric spaces? Are there some references where they are studied? Are there some interesting applications? When I tried to mimic the three above conditions, I was only able to come up with this. If $X$ is connected then we get $S=X$ for any set which fulfills these conditions: $S\ne\emptyset$ . If $x\in S$ then there exists an open set $U$ such that $x\in U\subseteq S$ . If $x\in\overline S$ , then $x\in S$ . The second condition only says that $S$ is open. The third condition basically says that $\overline S=S$ , i.e., that $S$ is closed. But I wanted to formulate it in such way that it resembles the formulation of real induction given above. This is a very naive version, since it only says that the only non-empty clopen subset of a connected space $X$ is the whole space. This version seems not very satisfactory since when we view the real induction informally (as described above) as a process in which the set $S$ is ""growing"" until it is the whole $x$ , this is entirely lost in the above formulation. Another reason is that real induction feels a bit like the correct generalization should also be related to compactness. I could try also to define some sets by transfinite induction: $S_0$ is a singleton. $S_{\alpha+1}$ is an open neighborhood os $\overline{S_\alpha}$ . If $\alpha$ is a limit ordinal, then $S_\alpha=\bigcup\limits_{\beta<\alpha} S_\beta$ . The claim would than be that there is an $\alpha$ such that $S_\alpha=X$ . (For example, if $X$ is connected.) This seems a bit closer to my informal description above in the sense, that we have some set which is ""growing"". But it seems to be unnecessarily complicated way to write more-or-less the same thing without actually gaining anything. So I still wonder whether there is some reasonable generalization, which would resemble real induction and be actually useful. (Although I fear without some kind of partial order or at least pre-order we have changed too much to expect something nice and useful.) 1 Pete L. Clark: The Instructor's Guide to Real Induction, https://arxiv.org/abs/1208.0973 , http://alpha.math.uga.edu/~pete/realinduction.pdf 2 In fact, in this text it is shown that $S$ is inductive if and only if $S=[a,b]$ . However, the other implication is obvious. I have only included the direction which is relevant for correctness of this proof technique.","['induction', 'general-topology']"
2244769,Relationship between analytic and holomorphic,Is every analytic function holomorphic? But not every holomorphic function is analytic?,"['analyticity', 'complex-analysis']"
2244792,Bound on projection to finite dimensional subspace of Banach Space,"Let $M$ be a finite dimensional subspace of a Banach space $X$ with basis $\{x_1,\dots,x_n\}$ (through scaling we can assume each basis element has unit norm). We can construct a projection $P:X\to M$ as follows. For $i\in \{1,\dots ,n\}$ consider the linear coefficient functional $f_i':M\to \mathbb{F}$ defined on the basis elements by $f_i'(x_k)=\delta^i_k$. Now from Lemma 2.4-1 [1] we know that there exists a $c>0$ such that for any $i\in\{1,\dots,\}$ and $x=\sum_{k=1}^n\alpha_k x_k\in M$ we have that
$$|f_i'(x)|=|\alpha_k|\leq \sum_{k=1}^n|\alpha_k|\leq c\|x\|_M\quad(1).$$
Hahn-Banach allows us to extend each $f'_i$ to $f_i:X\to \mathbb F$, where $f_i$ has all the regular properties of an extended functional. We can now define $Px=\sum_{k=1}^nf_k(x)x_k$ for each $x\in X$. It is easy to see that $P$ is linear, idempotent, and from $(1)$ that $\|P\|\leq cn$. I would like to know whether there is any way to improve this bound? I think critically I would like to know more about the behaviour of the constant $c$. Kreyzsig uses proof by contradiction to prove the existence of the $c$, and I have not been able to find another direct proof so I can figure out a way to bound $c$. My intuition says that $c$ should be bounded, perhaps even equal $1$, as I've now spent some time being unable to come up with a counter-example. However, I have been unable to to come up with any bound either. I've played around with trying to use Riesz's Lemma, but without success. Any ideas and/or references would be greatly appreciated. References: [1]
Erwin Kreyzsig. Introductory Functional Analysis with Applications. Wiley, 1st edition, 1989.","['functional-analysis', 'inequality', 'banach-spaces']"
2244793,Determine generator of $C_0$-semigroup,"I try to solve the following problem: Let $X$ locally compact and $a \in C(X)$ such that $\text{Re } a \leq w$. Further let $T(t)f := e^{ta}f$ for all $f \in C_0(X)$ and $t \geq 0$. Determine the generator of $(T(t))_{t \geq 0}$. I figured out that the generator must be the multiplication operator of $a$ defined by $M_a f = a f$ for all $f \in C_0(X)$. So I need to show that $$ \lim_{t \to 0} \left\Vert \frac{T(t)f - f}{t} - M_a f \right\Vert_\infty = 0 \qquad \text{for all } f \in C_0(X).$$
So let $\epsilon > 0$, $(t_n)_{n \in \mathbb N}$ in $\mathbb R_+$ with $t_n \to 0$ and $f \in C_0(X)$. So I need a $N \in \mathbb N$ with $$ \left\Vert \frac{T(t_n)f - f}{t} - M_a f \right\Vert_\infty  = \sup_{x \in X} \left\vert \frac{1}{t_n}(e^{t_n a(x)} - 1) - a(x) \right\vert \vert f \vert < \epsilon \qquad \text{for all } n \geq N$$ So its enough to show that $\left\vert \frac{1}{t_n}(e^{t_n a(x)} - 1) - a(x) \right\vert < \epsilon/\Vert f \Vert_\infty$ for all $n \geq N$ and $x \in X$. By L'Hopital I know that $\frac{1}{t}(e^{t a(x)} - 1) \to a(x)$ for $t \to 0$. Thus for a $x \in X$ I get by continuity: $$\forall \epsilon > 0\ \exists \delta > 0\ \forall \vert t \vert < \delta: \left\vert\frac{1}{t}(e^{t a(x)} - 1) - a(x)  \right\vert < \epsilon. $$ At this point I don't know how to proceed because I think that $\delta$ depends on the $x$, so that I don't get the estimate for all $x \in X$. Another idea of mine is to show 
$$ \lim_{t \to 0} \left\Vert \frac{T(t)f - f}{t} - M_a f \right\Vert_\infty = 0 \qquad \text{for all } f \in C_c(X)$$
and use the fact that $C_c(X)$ is dense in $C_0(X)$. But I figured out that I would have the same issues with that idea... I would appreciate some hints on the topic :)","['functional-analysis', 'complex-analysis', 'real-analysis', 'semigroup-of-operators']"
2244806,Problems on finite collection of non-empty subsets of a universe,"Question Suppose $(S_{1}, S_{2},...,S_{m})$ is a finite collection of non-empty subsets of a universe U. Note that the sets in this collection need not be distinct. Consider the following basic step to be performed on this sequence. While there exist sets $S_{i}$ and $S_{j}$ in the sequence, neither of which is a subset of the other, delete them from the sequence, and a. If $S_{i}\cap S_{j}\neq \emptyset $ , then add the sets $S_{i}\cup S_{j}$ and $S_{i}\cap S_{j}$ to the sequence; b. If $S_{i}\cap S_{j} = \emptyset$ , then add only the set $S_{i}\cup S_{j}$ to the sequence. In each step, we delete two sets from the sequence and add at most two sets to the sequence. Also, note that empty sets are never added to the sequence. Which of the following statements is TRUE ? The size of the smallest set in the sequence decreases in every step. The size of the largest set in the sequence increases in every step. The process always terminates. The process terminates if $U$ is finite but might not if $U$ is infinite. There is a finite collection of subsets of a finite universe $U$ and a choice
of $S_{i}$ and $S_{j}$ in each step such that the process does not terminate. My Attempt case $1$ if $S_{i} \subseteq S_{j}$ then the sequence will be like $S_{1}\,\,S_{2}\,\,S_{3}\,\,S_{4}\,\,\cdot\,\,\cdot\,$ will go on Example-: $S_{1}$ = $\left \{1,2,3 \right \}\,\,S_{2}=\left \{1,2,3,4 \right \}\,\,S_{3}=\left \{1,2,3,4,5 \right \}\,\,\,\,\cdot\,\cdot\,\cdot\,\cdot$ Case $2_{a}$ if $S_{i}$ and $S_{j}$ are not the  subset of each other then Example-: $S_{1}$ = $\left \{1,2,3 \right \}\,\,S_{2}=\left \{3,4,5 \right \}\,\,S_{3}=\left \{4,5,6,7 \right \}\,\,\,\,\cdot\,\cdot\,\cdot\,\cdot$ then the sequence will be like $S_{1}\,\,S_{2}$ , Hold on , $S_{1}\,\nsubseteq\,S_{2}$$\Rightarrow$ Remove $S_{1}\,\,S_{2}$ , $\Rightarrow$ Add $S_{1}\,\cup \,S_{2}$ and add $S_{1}\,\cap \,S_{2}$ Let $S_{x}=S_{1}\,\cup \,S_{2}$ Let $S_{y}=S_{1}\,\cap \,S_{2}$ Now my Sequence is $S_{x}\,\,S_{y}\,\,\cdot\,\,\cdot\,$ Considering case 2 $_{b}$ in the same way,i think that the sequence is nothing but $Power set$ of $\left \{1,2,3,\,\cdot\,\,\cdot\,\,m\right \}$ Leading me to choose option $4$ i.e The process terminates if U is finite but might not if U is infinite. Am i going Right? Please help me out","['elementary-set-theory', 'functions']"
2244809,Is this a necessary and sufficient condition for the derivative to exist at $C$?,"Suppose we want to prove that the derivative of a function across an interval exists at $C$, but the derivative at $C$ cannot be found. We know the function must be continuous. Can we take the limit of derivative from the negative and positive direction of $C$ and show that if they are equal, the derivative at $C$ exists and is equal to the limit obtained? Is this a necessary and sufficient condition? EDIT: Sufficiency - If a function is a derivative along some interval, it does not have a removable singularity at $C$. Necessity - There is no interval of a derivative of some function in which a jump or essential discontinuity occurs. There are two  cases in which the condition is met if this is a necessary and sufficient condition. One is where the derivative is continuous, the other is where there is a removable discontinuity in the derivative. Is the latter possible?","['functional-analysis', 'real-analysis', 'analysis', 'derivatives']"
2244818,Unbounded operator between normed spaces,"For every infinite sequence $x = (x_1, x_2, x_3, ...)$ of complex numbers define $S(x)$ by $S(x_1, x_2, x_3, ...) = (x_1, 2x_2, 3x_3, ...)$. Is $S$ in $\mathcal{L}(\mathcal l^1, \mathcal l^\infty)$? I argue that $S$ is unbounded and hence not in $\mathcal{L}(\mathcal l^1, \mathcal l^\infty)$. Proof: Firstly, using $|| x||_\infty \geq || x||_1$, we have that $$||S(x)||_\infty = \sup_n|S(x_n)| = \sup_n|n\cdot x_n|= n\cdot|| x||_\infty \geq n\cdot||x||_1.$$ This means that $$\frac{||S(x)||_\infty}{|| x||_1} \geq n \rightarrow\infty$$ and hence, $S$ is unbounded with $||\cdot||_\infty$ norm and not a member of $\mathcal{L}(\mathcal l^1, \mathcal l^\infty)$ .","['functional-analysis', 'normed-spaces', 'calculus', 'proof-verification']"
2244851,Exact solution of overdetermined linear system,"Given a (possibly) overdetermined linear system $Ax=b$, where $A$ is full rank and $A \in \mathbb{R}^{m \times n}, \quad m \ge n$ Does the least squares method provide an exact solution (instead of an approximation) if and only if $m=n$ (the system is square and well-determined)? In other words can an overdetermined full rank system have an exact solution? If yes, when and how can you predict it?","['matrices', 'matrix-equations', 'linear-algebra', 'least-squares']"
2244864,Does $\bigcup_{i=1}^\infty$ represent the arbitrary union ? Does the union here reach up to $i=\infty$?,"I think the answer to this question is yes. Since up to this union it will cover all the natural as well as transfinite numbers.
But since the term $arbitrary$ has wide area what about others (like $empty\ union$ ) ?
However sometimes we have seen this symbol for countable union, while some authors use this for arbitrary union (in definition of topology). Please clarify. What I'm missing ?","['math-history', 'infinity', 'elementary-set-theory', 'general-topology', 'analysis']"
2244875,Conditions for existence of KL divergence,"I am interested in understanding when the KL divergence exists between two distributions $P$ and $Q$. Recall that this quantity is defined as $$
D_{KL}(P|Q) := \int \log \frac{dP}{dQ} \, dP.
$$ In general, we always require $P \ll Q$ for this definition to make sense, but it seems that we also need $\log dP/dQ \in L^1(P)$, and so my question is essentially whether there exist useful conditions on $P$ and $Q$ that are sufficient to ensure this holds. For simplicity, let's assume $P \ll Q \ll \mu$ for some $\sigma$-finite measure $\mu$, so that $$
D_{KL}(P|Q) = \int \log \frac{p}{q} \, dP = \int \log p - \log q \, dP
$$ where $p$ and $q$ are respectively the densities of $P$ and $Q$ with respect to $\mu$. It seems therefore what we want to characterise are conditions for $$ \tag{*} \label{*}
\log p, \log q \in L^1(P).
$$ There are examples for which this doesn't hold: e.g., when P is a standard Cauchy distribution and Q is a standard Gaussian, then $\log p \in L^1(P)$ but $\log q \notin L^1(P)$, so $D_{KL}(P|Q)$ does not exist - see this question . However, do certain assumptions about $P$ and $Q$ guarantee \eqref{*}? I would also be interested to hear answers to the following: Is it possible to have $\log p \notin L^1(P)$ and $\log q \in L^1(P)$? Is it possible to have $\log p, \log q \notin L^1(P)$, but $\log p - \log q \in L^1(P)$?","['probability-theory', 'measure-theory']"
2244899,Isometries between dual factor space and annihilator,"Let $X$ be a normed space and $Y$ a closed subspace of $X$ and $Y^0=\{f \in X^*|f(x)=0,\forall y \in Y\}$. Prove that $Y^0$ is isometricaly isomorphic with $(X/Y)^*$. I have to find  a function specifically between $Y^0 $ and $(X/Y)^*$. One idea is the function $S: Y^0 \longrightarrow (X/Y)^*$ such that $S_{f}(x+Y)=f(x)$ but i have a difficult time to proved that it is bounded and an isometry. Can someone help me please or give another idea for an bijection? Thnak you in advance.","['functional-analysis', 'banach-spaces', 'dual-spaces']"
2244907,"The number of linear functions from $\left\{0, 1\right\}^{n}$ to $\left\{0, 1\right\}$","I know it is a duplicate of this question. But still, i am posting this because I am completely stuck.I think i have not understand the question itself. I am posting my attempt.Please guide me to move further. Question For $x, y\in \left\{0, 1\right\}^{n}$, let $x ⊕ y$ be the element of $\left\{0, 1\right\}^{n}$ obtained by the component-wise exclusive-or of $x$ and $y$. A Boolean function $F:\left\{0, 1\right\}^{n}\rightarrow\left\{0, 1\right\}$ is said to be linear if $F(x ⊕ y)= F(x) ⊕ F(y)$, for all $x$ and $y$. The number of linear functions from $\left\{0, 1\right\}^{n}$ to $\left\{0, 1\right\}$ is. Attempt let the value of $n$=4 Now we have the size of domain as $2^{4}$ which are $\left\{0000,0001,0010,0011,0100\,\,\cdot\cdot\cdot\cdot
1111\right\}$ Total number of binary function possible $F:\left\{0, 1\right\}^{n}\rightarrow\left\{0, 1\right\}$ =$2^{2^{4}}=2^{16}$ We have to find actually the size of domain. Now among $16$ possible combination of $\left \{0, 1\right\}^{4}$, Let $x=0010$  and $y=1010$ Now $$x ⊕ y=1000$$ Now$F(x ⊕ y)$=$F(0010)$=$F(x)⊕ F(y)$=???? Completely stuck !!,no clue what to do !Even the accepted answer is not clear to me ! Please help me out using this example!",['functions']
2244916,Equations of motion for the n-body problem,"The Lagrange function is defined as $\mathcal{L}(q,\dot{q}) = T(q,\dot{q}) - V(q,\dot{q})$ where $T$ defines the kinetic energy and $V$ the potential energy. The equations of motion are given by
$\frac{\partial \mathcal{L}}{\partial q_i} - \frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot{q_i}} = 0$. In the $n$-body problem we have $n$ planets with masses $m_1, \dots, m_n \in \mathbb{R}_+$. The kinetic and potential energy is given by $T = \sum_i \frac{1}{2} m_i  \Vert \dot{q_i} \Vert_2^2$ and $V = G \cdot \sum_{i<j} \frac{m_i m_j}{\Vert q_i - q_j \Vert_2}$ where $G$ denotes a gravitational constant. Furthermore, $q_i(t) \in \mathbb{R}^3$ decribes the position of the $i$-th planet at time $t$. Now I need to calculate the equations of motions. But now I do not understand how to deal with $\frac{\partial \mathcal{L}}{\partial q_i}$. The first thing which confuses me is that $q_i$ is a three-dimensional vector. The second thing would be the derivative of the norm because in calculus we have learned that the norm is not differentiable. Could anyone explain this problem to me? Any help is really appreciated.","['euler-lagrange-equation', 'physics', 'mathematical-physics', 'classical-mechanics', 'ordinary-differential-equations']"
2244924,"Let $f:[0,\alpha]\to \mathbb{R}$ solution of a Cauchy problem , prove $\alpha <3.$","Let $f:[0,\alpha] \to \mathbb{R}$ be a solution of the Cauchy problem 
$$ 
\begin{cases}
f'(t)=f(t)^2+t, \\
f(0)=0.
\end{cases}
$$
Prove that $\alpha <3.$ I know that I should try to prove that $f$ blows up to $+\infty$ before time $t=3$. I tried to apply the comparison theorem, but I cound't find a suitable function to use. Any help is appreciated.","['derivatives', 'real-analysis', 'ordinary-differential-equations']"
2244983,Everywhere singular Jacobian implies non injectivity?,"When I was studying analysis some time ago, the next problem arose: Let $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be a differentiable function, not necessarily $C^1$, such that $\det(f'(a))=0$, for all $a$ in $\mathbb{R}^n$, where $f'(a)$ stands for the Jacobian matrix at $a$.   Is $f$ not injective? I do not have a proof, but I do have the conviction that this must be true. If $f$ is $C^1$, we can find, for each point, a direction in wich the directional derivative is 0, and the directions change smoothly. Then we could find an integral curve where all the points have the same image. I don't have a formal proof of this idea either. I think there must be a simpler argument that solves the general case. We do not need a whole curve of points with the same image, just two of them, so maybe the argument can be simplified. Any sugestiond through a solution or even a complete proof would be highly apreciated.","['problem-solving', 'determinant', 'multivariable-calculus', 'jacobian', 'analysis']"
