question_id,title,body,tags
3513954,Solving $y = x + \log_2x$ for $x$,"Can you solve for $x$ in $y = x + \log_2x$ and show how you do it? Looking at the graph it seems like the inverse of this function can exist and be defined on the entire domain. I have no idea what to do with the $\log_2$ , exponentiating both side doesn't seem to lead anywhere for me. Also, I found through guesswork that $y\ =\ x-2^{-x}$ seem to be a 45 degree symmetry to the solution.","['algebra-precalculus', 'transcendental-equations', 'logarithms']"
3514002,"Showing $P(X_1+X_2<1)=\frac12$ where $X_1,X_2$ are i.i.d $U(0,1)$ variables","I am given that $X_1$ and $X_2$ are iid $U(0,1)$ and want to show that $$Pr[X_1+X_2<1]=0.5$$ My approach is to evaluate $$\int_0^1\int_0^{1-x_1}1 \quad dx_2dx_1$$ but there seems to be a geometric approach to this that significantly simplifies the answer. May I have some assistance?","['probability-distributions', 'uniform-distribution', 'probability']"
3514004,Unexpected use of polynomials in combinatorics,"Can someone please post some (relatively easy, say high school level) combinatorial problems which can be solved with polynomials but NOT generating functions. Related to this post in ME.SE .","['big-list', 'soft-question', 'combinatorics', 'polynomials']"
3514070,One-sided heavy tailed distribution,"I seek a univariate distribution with analytically expressible density function that approximates (a vertically scaled version of) the standard normal distribution around the origin, but with a heavy tail extending in the positive direction (only). The distribution should be smooth and unimodal, with at least one parameter for specifying the heaviness of the one tail. My first thought is to mix a standard normal distribution with an exponential distribution (which decays slower than a normal distribution), but this causes a step change at the origin, making the distribution unsmooth. Trying to replace the exponential distribution with other positive distributions (such as Chi-squared, Beta prime, Chi, Dagum, F-distribution, Gamma, Erlang), it is possible to preserve smoothness, but this potentially introduces bimodality, depending on the parameters chosen. Can you suggest any idea for a distribution that: has analytically expressible PDF approximates (a vertically scaled version of) the standard normal distribution for $x<0$ is unimodal is smooth has a heavy tail in the $+x$ direction (with at least one parameter for specifying heaviness of the tail)","['distribution-tails', 'statistics', 'probability-distributions', 'normal-distribution']"
3514078,"Let $G=(V,E)$ be a graph with $|V|=6,|E|=10$. Prove there exists vertex $v$ such that $\deg v=4$ or $\deg v=5$- Possible pigeonhole solution?","I know it's a very basic question both in graph theory and discrete math but unfortunately it's kind of had for me to wrap my head around this one. Let $G=(V,E)$ be a simple graph with $|V|=6,|E|=10$ . Prove there exists vertex $v$ such that $\deg v=4$ or $\deg v=5$ . I managed to prove it using contradiction and the fact that $\sum_{v\in V}\deg(v)=2|E|$ and Of course I'm fine with this proof but the first thing I thought about when I saw this problem is solving using the pigeonhole principle- but couldn't do it. Some thoughts I had before resorting to proof by contradiction were: There can be only one vertex $v$ such that $\deg v=0$ because for any number $<5$ even the complete graph won't have enough edges. And if there exists such vertex then we have $5$ vertices left to connect and then the number of edges in the complete graph with $5$ edges is $\binom{5}{2}=10$ and the number of edges is $10$ so every vertex would have a degree of 4 and we're done. So we can assume that for any $v\in V$ we have $0<\deg v<6$ . Not sure it helps though! So my question is: Is there a way to prove this claim using pigeonhole principle? Is the proof I wrote some how equivalent to the pigeonhole principle? Sorry if it's too basic, and thanks for any help!","['graph-theory', 'pigeonhole-principle', 'discrete-mathematics']"
3514107,Divide $ yy' = (y + 1)^2 $ by $ (y + 1)^2 $,"I was reading from Ordinary Differential Equations (Lesson 4C page 36) and came across this question: Find a 1-parameter family of solutions of the differential equation $$ (a) \quad yy' = (y + 1)^2 $$ and the particular solution for which $\quad y(2) = 0$ The first step was to divide $ (a) $ by $ (y + 1)^2 $ and they had $$ \int{\frac{y}{(y + 1)^2} dy } = \int dx \quad,\quad y \neq -1$$ but when I was trying to divide $ (a) $ by $ (y + 1)^2 $ I had $$ \frac{yy'}{(y+1)^2} = \frac{(y+1)^2}{(y+1)^2} $$ $$ => \quad \frac{yy'}{(y+1)^2} = 1$$",['ordinary-differential-equations']
3514135,Swapping integral and sum using dominated convergence theorem,"Show that $$
\sum_{n=1}^\infty \int_0^\infty t^{s/2-1}e^{-\pi n^2t}dt
 = \int_0^\infty t^{s/2-1} \sum_{n=1}^\infty e^{-\pi n^2t} dt
$$ with $s > 1$ using the dominated convergence theorem. If I have understood correctly, I can define $f_k:= \sum_{n=1}^k t^{s/2-1}e^{-\pi n^2t}$ which I have already been able to show integrable and that it converges pointwise ( $f = \lim_{k \rightarrow \infty} f_k$ ). Now the last part of the requirements of the theorem: I struggle to find an integrable function $g$ with $|f_k| \leq g$ for all $k \in \mathbb{N}$ .","['integration', 'summation', 'lebesgue-integral', 'real-analysis']"
3514239,"If $A$ is Compact, all Continuous Functions on $A$ are Bounded","There are a lot of question asking for the converse, but not this direction (that I could find). Let $A$ be a compact set, and let $V = \{ f:A \rightarrow \mathbb{R} ; \; f \text{ is continuous}  \}$ . Claim: $$V = \{ f:A \rightarrow \mathbb{R} ; \; f \text{ is continuous} \; \}$$ $$ = V_b = \{ 
f:A \rightarrow \mathbb{R} ; \; f \text{ is continuous and bounded} \;\}.$$ I know that $A$ being compact means that all sequences have convergent subsequences. I don't know how to get from convergent sequences to bounded functions. I also know that $A$ is totally bounded and complete, but that seems even less helpful.","['continuity', 'functions', 'compactness', 'real-analysis']"
3514276,Find area of ellipse $5x^2 -6xy +5y^2=8$,"Find the  area of ellipse whose  equation in the $xy$ - plane  is given by $5x^2 -6xy +5y^2=8$ My attempt  : I know  that area   of ellipse $ = \pi a b$ ,where $a$ is  semi-major axis and $b$ is  semi minor axis Now  if we make  matrix $\begin{bmatrix} 5 & -3 \\-3& 5\end{bmatrix}$ Here  eigenvalue $\lambda_1=  8 ,\lambda_2=2$ That  is area of ellipse $ = \pi \frac{1}{\sqrt\lambda_2} \frac{1}{\sqrt\lambda_1}= \pi \frac{1}{2\sqrt 2}\frac{1}{\sqrt2}$ Is its  correct ?","['linear-algebra', 'geometry']"
3514287,"Given that $a,b,d$ are positive integers, if $(a+b)! d! = (a+d)! b!,$ then do we have $b= d?$","Question: Given that $a,b,c,d$ are positive integers satisfying $$\binom{a+b}{a} = \binom{c+d}{c} \quad \text{and} \quad a = c,$$ do they imply that $b = d$ ? From assumption, we have $$\frac{(a+b)!}{a!b!} = \frac{(c+d)!}{c!d!}$$ $$\Rightarrow \frac{(a+b)!}{b!} = \frac{(a+d)!}{d!}$$ $$\Rightarrow (a+b)! d! = (a+d)! b!.$$ Can we deduce that $b=d$ from equation above?","['algebra-precalculus', 'combinatorics']"
3514308,"Limiting distribution of $\frac {X_n -Y_m -(n-m)}{\sqrt{X_n+Y_m}}$ where $X_n,Y_m$ are independent Poisson","Let $X_n$ , $Y_m$ be independent Poisson variables with means $n$ , $m$ . $$\frac {X_n -Y_m -(n-m)}{\sqrt{X_n+Y_m}}$$ Find the limiting distribution as $n,m \to \infty$ I know that $\frac{X_n-n}{\sqrt{n}} \to N(0,1)$ but don't know what the next step would be.","['central-limit-theorem', 'probability-theory', 'weak-convergence']"
3514318,Evaluating $\sum_{n=1}^\infty\frac{\overline{H}_nH_{n/2}}{n^2}$,"I ma trying to prove $$S=\sum_{n=1}^\infty\frac{\overline{H}_nH_{n/2}}{n^2}=\frac1{24}\ln^42-\frac14\ln^22\zeta(2)+\frac{21}{8}\ln2\zeta(3)-\frac{9}{8}\zeta(4)+\operatorname{Li}_4\left(\frac12\right)$$ where $\overline{H}_n$ is the alternating harmonic number and $H_n$ is the harmonic number. I need this sum to complete my solution here . Here is my trial, Following @user97357329's note in the comments of the same link above $$\sum_{n=1}^\infty f(n)=\sum_{n=1}^\infty f(2n-1)+\sum_{n=1}^\infty f(2n)$$ Giving us $$S=\underbrace{\sum_{n=1}^\infty\frac{\overline{H}_{2n-1}H_{n-1/2}}{(2n-1)^2}}_{\large S_1}+\frac14\underbrace{\sum_{n=1}^\infty\frac{\overline{H}_{2n}H_{n}}{n^2}}_{\large S_2}$$ I managed to evaluate $S_2$ using $\overline{H}_{2n}=H_{2n}-H_n$ . Regarding $S_1$ , I used $\overline{H}_{2n-1}=H_{2n}-H_n+\frac1{2n}$ and $H_{n-1/2}=2H_{2n}-H_n-2\ln2$ therefore $$S_1=2\sum_{n=1}^\infty\frac{H_{2n}^2}{(2n-1)^2}-\color{blue}{\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n-1)^2}}-2\ln2\sum_{n=1}^\infty\frac{H_{2n}}{(2n-1)^2}+\color{red}{\sum_{n=1}^\infty\frac{2H_{2n}-H_n-2\ln2}{2n(2n-1)^2}}$$ and I am stuck with the blue and red sums, any idea? Thank you.","['integration', 'harmonic-numbers', 'calculus', 'closed-form', 'sequences-and-series']"
3514413,Stochastic integral is progressive,"If I want to show that a stochastic integral, namely $$Y_t=\int_0^t\phi_s dB_s$$ where B is the standard Brownian motion, is progressive, is it enough to show that the integrand $\phi_s$ it is progressive? Could you provide some comments?","['stochastic-integrals', 'stochastic-processes', 'measure-theory', 'brownian-motion']"
3514451,Finding Generator of finite field,"The task is to show that $x^2 + 1$ is irreducible over $\mathbb{F}_{743}$ and then find a generator of $\mathbb{F}_{743}[x]/(x^2+1)$ . This question has already been asked but not really answered here I've shown that $x^2+1$ is irreducible, since $ 743 \equiv 3\pmod{4}$ and therefore $-1$ is not a quadratic residue mod 743. But I don't understand how to find a generator of $\mathbb{F}_{743}[x]/(x^2+1)$ . I assume I need to look for an element of order $743^2-1$ , but is there an obvious way to do this, or is it just done by trying?","['number-theory', 'finite-fields', 'abstract-algebra']"
3514546,A diagonalizable matrix's proof,"I came a cross the following question today at class If a matrix has $n$ eigenvalues and it is known all of them are different from each other then $A$ is a diagonalizable matrix to best of my knowledge, if the eigenvalues are different from each other (and let's say you got $n$ of those), you can make $n$ bases vectors using those eigenvalues, but I'd love to see a proper proof :) cheers","['matrices', 'diagonalization', 'eigenvalues-eigenvectors']"
3514547,How can I find the cross product of an inner sum and difference between two vectors?,"The problem is as follows: The figure from below shows vectors $\vec{A}$ and $\vec{B}$ . It is known that $A=B=3$ . Find $\vec{E}=(\vec{A}+\vec{B})\times(\vec{A}-\vec{B})$ The alternatives are: $\begin{array}{ll}
1.&-18\hat{k}\\
2.&-9\hat{k}\\
3.&-\sqrt{3}\hat{k}\\
4.&3\sqrt{3}\hat{k}\\
5.&9\hat{k}\\
\end{array}$ What I've attempted here was to try to decompose each vectors $\vec{A}=\left \langle 3\cos 53^{\circ}, 3 \sin 53^{\circ} \right \rangle$ $\vec{B}=\vec{A}=\left \langle 3\cos (53^{\circ}+30^{\circ}), 3 \sin (53^{\circ}+30^{\circ}) \right \rangle$ But by attempting to use these relationships do seem to extend the algebra too much. Does it exist another way? some simplification?. Or could it be that am I overlooking something? Can someone help me with this?.","['cross-product', 'euclidean-geometry', 'algebra-precalculus', 'vectors']"
3514566,Is there a term for functions where $f(x) - x$ is periodic?,"Title says it all really. I'm working with a type of function $f: \mathbb{R} \rightarrow \mathbb{R}$ with the property that $f(x+k) = f(x)+k$ for integers $k$ , or equivalently, $f(x) - x$ is periodic with period $1$ . Is there a name in common usage for this type of function? Or if not, what would be an appropriate name? ""Semi-periodic""? ""Periodically increasing""?","['periodic-functions', 'functions', 'analysis', 'real-analysis']"
3514574,"Why are all subset sizes equiprobable if elements are independently included with probability uniform over $[0,1]$?","A probability $p$ is chosen uniformly randomly from $[0,1]$ , and then a subset of a set of $n$ elements is formed by including each element independently with probability $p$ . In answering Probability of an event if r out of n events were true. I realized that the probability $$
\int_0^1\binom nrp^r(1-p)^{n-r}\mathrm dp=\frac1{n+1}
$$ of obtaining a subset of size $r$ is independent of $r$ ; so all $n+1$ subset sizes are equiprobable. This is a neat fact that I wasn’t aware of before. There must be a nicer, more insightful way to show this than to evaluate this integral (which can be done using integration by parts).","['uniform-distribution', 'binomial-distribution', 'probability']"
3514623,Two rays/vectors that satisfy $\Delta \mathbf{k} = \mathbf{k} - \mathbf{k}_0$ make the same angle with perpendicular plane?,"This question is from physics, but I think the answer is more-so fundamentally a fact of mathematics, rather than physics which is why I'm posting it here. My textbook, Solid-State Physics, Fluidics, and Analytical Techniques in Micro- and Nanotechnology , by Madou, presents the following image and explanation in a section on x-ray diffraction and Laue equations : Bragg’s law is equivalent to the Laue equations in one dimension as can be appreciated from an inspection of Figures 2.24 and 2.25, where we use a two-dimensional crystal for simplicity. Suppose that vector $\Delta \mathbf{k}$ in Figure 2.24 satisfies the Laue condition; because incident and scattered waves have the same magnitude (elastic scattering), it follows that incoming ( $\mathbf{k}_0$ ) and reflected rays ( $\mathbf{k}$ ) make the same angle $\theta$ with the plane perpendicular to $\Delta \mathbf{k}$ . So this passage seems to be saying that, if two vectors $\mathbf{k}$ and $\mathbf{k}_0$ satisfy the condition $\Delta \mathbf{k} = \mathbf{k} - \mathbf{k}_0$ , where $\mathbf{k}_0$ is an incoming ray, and $\mathbf{k}$ is a reflected, outgoing ray, and if these rays have the same magnitude, then it must be that the rays make the same angle $\theta$ with the plane perpendicular to $\Delta \mathbf{k}$ . Is this a mathematical fact? And if so, then does anyone have a proof of this? I would greatly appreciate it if people would please take the time to clarify this.","['physics', 'trigonometry', 'geometry']"
3514628,Solution verification:$\lim_{x\to 2}\frac{\ln(x-1)}{3^{x-2}-5^{-x+2}}$,"Evaluate without L'Hospital: $$\lim_{x\to
 2}\frac{\ln(x-1)}{3^{x-2}-5^{-x+2}}$$ My attempt: I used: $$\lim_{f(x)\to 0}\frac{\ln(1+f(x))}{f(x)}=1\;\&\;\lim_{f(x)\to 0}\frac{a^{f(x)}-1}{f(x)}=\ln a$$ $$
\begin{split}
L &= \lim_{x\to 2} \frac{\ln(x-1)}{3^{x-2}-5^{-x+2}} \\
  &= \lim_{x\to 2} \frac{\dfrac{\ln(1+(x-2))}{x-2}\cdot(x-2)}
                        {(x-2)\cdot\dfrac{3^{x-2}-1+1-5^{-x+2}}{x-2}} \\
  &= \lim_{x\to 2} \frac{\dfrac{\ln(1+(x-2))}{x-2}}
                        {\dfrac{3^{x-2}-1}{x-2}+\dfrac{5^{2-x}-1}{2-x}} \\
  &=\frac{1}{\ln3+\ln5} \\
  &=\frac{1}{\ln(15)}
\end{split}
$$ Is this correct?","['calculus', 'solution-verification', 'limits-without-lhopital']"
3514632,Are results found of an Elliptic Curve by SageMathCell proven (does there exists no more solutions)?,"Well, I have for example the following SageMathCell -code: sage: E = EllipticCurve(QQ, [0,63,-2205,-12348,0])
sage: E
sage: for P in E.integral_points():
....:     Q = -P 
....:     print( ""P = %8s and -P = %8s"" % (P.xy(), Q.xy()) ) This code computes the integral points of the Elliptic Curve that is defined by: $$[0,63,-2205,-12348,0]\space\space\space\to\space\space\space y^2 - 2205y = x^3 + 63x^2 - 12348x\tag1$$ Are these results I get, proven to be the only ones out there? Or can there be more solutions that SageMathCell did not find? Bytheway, the code gives the following output: P = (-174, 1161) and -P = (-174, 1044)
P = (-147, 2205) and -P = (-147, 0)
P = (-98, 2548) and -P = (-98, -343)
P = (-68, 2528) and -P = (-68, -323)
P = (-54, 2484) and -P = (-54, -279)
P = (0, 2205) and -P =   (0, 0)
P = (57, 2052) and -P = (57, 153)
P = (84, 2205) and -P =  (84, 0)
P = (147, 3087) and -P = (147, -882)
P = (231, 4851) and -P = (231, -2646)
P = (309, 6840) and -P = (309, -4635)
P = (375, 8730) and -P = (375, -6525)
P = (378, 8820) and -P = (378, -6615)
P = (711, 20691) and -P = (711, -18486)
P = (1176, 42336) and -P = (1176, -40131)
P = (2107, 99127) and -P = (2107, -96922)
P = (2886, 157716) and -P = (2886, -155511)
P = (5412, 401472) and -P = (5412, -399267)
P = (5572, 419293) and -P = (5572, -417088)
P = (37275, 7203735) and -P = (37275, -7201530)
P = (26162409, 133818797385) and -P = (26162409, -133818795180)","['number-theory', 'solution-verification', 'sagemath', 'elliptic-curves']"
3514635,Hoeffding-Type Bounds for Noncentered Variables,"Hoeffding's Tail Bound is well-known for subgaussian variables. It can be written in the following way: Assume $X_i$ for $1\leq i\leq n$ satisfies: $$
\mathbb{P}(|X_i-\mu|>t)\leq 2\exp\left(\frac{-t^2}{2\sigma_i^2}\right)
$$ Then for $t\geq 0$ , we have that: $$
\mathbb{P}(|\frac{\sum_i X_i}{n}-\mu|>t)\leq 2\exp\left(\frac{-n^2t^2}{2\sum_i \sigma^2}\right)
$$ I am wondering if this can be generalized to the case when the constant is not the mean. i.e. assume that for $X_i$ we have the bounds: $$
\mathbb{P}(|X_i-a_i|>t)\leq 2\exp\left(\frac{-t^2}{2\sigma_i^2}\right)
$$ Where $\mathbb{E}(X_i)\neq a_i$ . Then can we bound: $$
\mathbb{P}(|\frac{\sum_i X_i-a_i}{n}|>t)
$$ similarly to Hoeffding's bound? I feel like I am missing something obvious but I am quite stuck.","['distribution-tails', 'statistics', 'probability', 'random-variables']"
3514645,Bijective map from upper half plane and $x$-axis to the whole of $\mathbb{R} ^{2} $.,"Is it possible to find a bijective map from $ \{ (x,y) \in \mathbb{R} ^{2} : y \geq 0 \} $ to the whole of $\mathbb{R} ^{2} $ (or consider it $ \mathbb{C} $ if needed)?",['functions']
3514664,A problem regarding the rank of a matrix,"$\mathbf {The \ Problem \ is}:$ If $A$ and $B$ be two $n\times n$ square matrix such that $A^2=A$ and $B^2=B,$ then show that $r(A-B)=r(A-AB)+r(AB-B)$ where $r(A)$ denotes rank of the square matrix $A.$ $\mathbf {My \ approach} :$ Actually I have tried that, from the two equations, $A(A-B)=(A-AB)$ and $(A-B)B=(AB-B)$ , we have $r(A-AB)+r(AB-B) \leq r(A)+r(B)$ and again $A(AB-B)=0$ and $(A-AB)B=0$ , then $r(A)+r(AB-B)\leq n$ and $r(B)+(A-AB)B\leq n$ , but I can't draw any further conclusion to show that $r(A-AB)+r(AB-B) \leq r(A-B)$ . And the other side is obvious by the rank-inequality $r(P+Q)\leq r(P)+r(Q).$ A small hint is warmly appreciated .","['matrices', 'matrix-rank', 'linear-algebra']"
3514694,"What does ""relation induced by a partition"" mean?","The question is: What is the equivalence relation R, induced by the partition P of A? (A, P are given) I don't get what ""induced by"" means.","['set-partition', 'equivalence-relations', 'discrete-mathematics', 'elementary-set-theory', 'terminology']"
3514707,Second derivative statement,"I have to prove the following: $$f''(x)=\lim_{h\rightarrow0} \frac{f(x+h)+f(x-h)-2f(x)}{h^2}$$ I tried to just apply the definition of derivative, namely: $$f'(x)=\lim_{h\rightarrow0} \frac{f(x+h)-f(x)}{h}$$ Then this: $$f''(x)=\lim_{h\rightarrow0} \frac{f'(x+h)-f'(x)}{h}$$ $$f''(x)=\lim_{h\rightarrow0} \frac{\lim_{h\rightarrow0} \frac{f(x+2h)-f(x+h)}{h}-\lim_{h\rightarrow0} \frac{f(x+h)-f(x)}{h}}{h}$$ $$f''(x)=\lim_{h\rightarrow0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2}$$ But what now? I came to the conclusion that this is true for $f''(x-h)$ , but not for $f''(x)$ . How can I solve this problem?","['calculus', 'derivatives']"
3514782,Proof verification of von Neumann's ergodic theorem by spectral theorem,"I would like to make sure the following proof is correct. Spectral theorem, simplest form I will be using- Let $H$ be a separable Hilbert space and $T:H \to H$ normal, then we may wlog assume $H = L^2 (X,u)$ where $X$ is a second countable locally compact Hausdorff (these properties are easy since $X$ will be a countable union of compact subsets of $C$ ), and $u$ is a complete probability regular measure (the Riesz-Markov gives that it's complete so let's take that for fun), and $T$ acts by $M_f$ . Von Neumann's ergodic theorem- Suppose $T : L^2 (Y,v) \to L^2 (Y,v)$ is unitary, let $U$ denote the closed fixed subspace of $T$ , and $P_U$ the projection. Then for any $h \in L^2(Y,v)$ , $ \frac{1}{n} \sum_{i=1}^n T^i(h) \to P_U(h)$ . Proof - Since unitary is normal, we use the spectral theorem to transfer our world to that of $H=L^2(X,u)$ , $T = M_f$ . Since $T$ is unitary, the spectrum lies in $S^1$ (this is because it is contained in the disk of radius $1$ , and $T^*(T-r) = 1-rT^*$ , and the right is invertible when $|r|<1$ by the geometric series). This lets us assume wlog that $f$ takes only values on $S^1$ (because where it doesn't, is of measure $0$ , since the support of the pushforward of the measure to $\mathbb{C}$ is the spectrum). Now, $U$ is identified as the functions with a representative supported in $f=1$ , and multiplying by the indicator of $f=1$ is thus the projection. Now for any fixed function $g \in L^2 (X,u)$ $\frac{1}{n} \sum_{i=1}^n f^ig \to P_U(g)$ pointwise, by DCT (dominated by max( $10g^2,10)$ ) this gives the desired convergence.","['ergodic-theory', 'solution-verification', 'functional-analysis']"
3514811,My Proof for a Set Theory Question,"So, I have the following proof question that I'm doing and I'm hoping that someone can look over the structure of my proof and give me comments. Let $A \subset U$ and $B \subset U$ . Then, prove that $A \subset B \iff (U-B) \subset (U-A)$ Proof Let $A \subset U$ and $B \subset U$ . Since the given proposition is a biconditional, we have to prove it in two directions. We will, first, prove the following: $A \subset B \implies (U-B) \subset (U-A)$ Let $x$ be an object such that $x \in U-B$ . Then: $x \in U-B \iff (x \in U) \land \lnot{(x \in B)}$ By the Law of Simplification: $(x \in U) \land \lnot{(x \in B)} \implies \lnot{(x \in B)}$ $(x \in U) \land \lnot{(x \in B)} \implies (x \in U)$ Hence, it is true that $x \in U$ and $\lnot{(x \in B)}$ . Since $A \subset B$ , it follows that: $A \subset B \iff \forall x \in U: \lnot{(x \in B)} \implies \lnot{(x \in A)}$ This shows that $\lnot{(x \in A)}$ is true. Hence, the following conjunction must be true as well: $\lnot{(x \in A)} \land (x \in U) \iff (x \in U-A)$ That proves the forward conditional. Now, we have to prove that: $(U-B) \subset (U-A) \implies (A \subset B)$ Let $x$ be an object such that $x \in A$ . Then, $x \in U$ , since $A \subset U$ . Hence, $\lnot{(x \in U-A)}$ is true. This implies that $\lnot{(x \in U-B)}$ is true as well as this is just the contrapositive of the hypothesis. This just means that $x \in U-B$ must be false. Since we know that $x \in U$ is true, it follows that $\lnot{(x \in B)}$ must be false and, hence, $x \in B$ must be true. This proves that $A \subset B$ . By proving the conditionals in both directions, we have proven the original biconditional. Seems like a rather long proof so I'm hoping to see a relatively shorter one suggested by someone. Thanks in advance.","['elementary-set-theory', 'solution-verification']"
3514829,An interesting real analysis problem involving integrals,"If $f$ is continuos in $[0,1]$ and $\int_0^1 f(x)dx=0$ , then $f(c)=\int_0^c f(x)dx$ for some $c\in (0,1)$ . My attempt: I defined the fuction $g:[0,1]\to \mathbb{R}$ by $g(s)=f(s)-\int_0^{s}f(x)dx$ , for all $s\in [0,1]$ . Notice that $g(0)=f(0)$ and $g(1)=f(1)$ . I considered cases for $f(0)$ and $f(1)$ . For example, if $f(0)f(1)<0$ , then using the Intermediate Value Theorem, we can find $c\in (0,1)$ such that $g(c)=0$ , that is $f(c)=\int_0^c f(x)dx$ . But, I don't know how to proceed in the other case: $f(0)f(1)\geq 0$ .","['integration', 'real-analysis']"
3514873,Lines tangent to a parabola,"Consider two points $A$ and $B$ on a parabola $p$ . Call $I$ to the intersection point of the tangent lines to $p$ at $A$ and $B$ and let $P$ be the point on $p$ such that the line defined by $I$ and $P$ is parallel to the symmetry axis of $p$ . How can we prove geometrically that the tangent line to $p$ passing through $P$ is parallel to the line segment joining $A$ and $B$ ? I was able to prove it using analysis (assuming that $p$ is the graph of a quadratic function and proving that the lines that I want to prove that are parallel have the same slopes), but I would like to have a more geometrical proof (or a reference to a textbook with such a proof).","['tangent-line', 'conic-sections', 'geometry']"
3515007,Ricci flow diffeomorphism invariance and evolution of curvature using Uhlenbeck's trick,"My question, while related to the posts Ricci flow preserves isometries , The invariance of the Ricci tensor under diffeomorphisms and its non-ellipticity. , and Diffeomorphism invariance of the Ricci tensor , is slightly different. Namely, when using Uhlenbeck's trick in the Ricci flow the Riemann tensor evolves by: $\frac {\partial } {\partial t} R_{abcd} = \iota_a^i \iota_b^j \iota_c^k \iota_d^l\Delta R_{ijkl} + 2(B_{abcd} - B_{abdc} - B_{adbc} + B_{acbd})$ where $\ B_{abcd} = h^{eg}h^{fi}R_{aebf}R_{cgdi}$ and $\iota : (V,h) \rightarrow (TM,g(t)) $ is a 1-parameter family of isometries from the fixed vector space V with metric h to the evolving tangent space TM with metric g(t) such that $ h=\iota^* g(t)$ for all t. However, according to the diffeomorphism invariance of the curvature $\iota^* Rm[g(t)]=Rm[\iota^* g(t)] $ and $ h=\iota^* g(t) $ and h is fixed. Shouldn't then $\frac {\partial } {\partial t} R_{abcd} = \frac {\partial } {\partial t} \iota^* Rm[g(t)]=\frac {\partial } {\partial t}Rm[\iota^* g(t)]=\frac {\partial } {\partial t}Rm[h]=0 ?$ Here $\ Rm[g(t)] $ denotes the Riemann tensor of the metric g(t). Clearly I am not understanding something correctly. What am I missing? My reference for this material is: Andrews, Ben, and Christopher Hopper. The Ricci flow in Riemannian geometry: a complete proof of the differentiable 1/4-pinching sphere theorem. springer, 2010.","['ricci-flow', 'riemannian-geometry', 'differential-geometry']"
3515025,Why does putting the eigenvectors as columns in a matrix give us the diagonalizing matrix?,"For $A$ of $n \times n$ if we have $n$ eigenvectors,  we can put them as columns in a matrix and get the diagonalizing matrix - why does it work?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3515027,Maximum number of cycles of length $4$,"If a simple graph has $m$ edges, prove that it has at most $\frac{m^2}{2}$ cycles of length $4$ .","['graph-theory', 'extremal-combinatorics', 'combinatorics', 'discrete-mathematics', 'extremal-graph-theory']"
3515040,Definite integral containing log and cot functions,"Consider the following integral $$c=\int_0^{\pi/2}\log(1-x\cot x)\, \mathrm{d}x\approx-3.35333726288947201778500718670823032.$$ I suspect it can be analytically computed because by expanding the $\log$ function, $$
c=\sum_{k=1}^{\infty}\frac1k\int_0^{\pi/2}(x \cot x)^k\, \mathrm{d}x
$$ it can be integrated term by term, albeit in involved form (combination of logarithms and $\zeta$ -functions) $$
\int_0^{\pi/2}x \cot x\, \mathrm{d}x=\frac{1}{2} \pi  \log2,\\
\int_0^{\pi/2}x^2 \cot^2 x\, \mathrm{d}x=-\frac{\pi ^3}{24}+\pi \log2,\\
\int_0^{\pi/2}x^3 \cot^3 x\,\mathrm{d}x=-\frac{\pi^3}{16} (1+2\log 2)+\frac{3 \pi}{16}  (8\log 2+3 \zeta(3)),
$$ and so on. Just to provide some background to this question, the integral has some significance in theoretical physics. It enters the high-density asymptotics of the quasiparticle renormalization factor of the 3D homogeneous electron gas, see eq. 35 in  Phys. Rev. B 70, 035111 (2004) or eqs. 8 and 9 in Phys. Rev. 120, 2041 (1960): $$ Z_{qp}=1+\frac{c}{\pi^2}\alpha r_s$$ However, since there is no parametric dependence, and since it is easy to compute numerically, no one cared to find the analytic form. However, I find it is a lovely little problem.",['integration']
3515076,power of integral,I don't know how to put this properly but Is there any some kind of equality or inequality like in case we know that $|\int_a^b f| \leq \int_a^b |f|$ $\Big[\int_a^b f(x) \Big]^{T}$ where $T \in \mathbb{R}^{+}$ ( positive real number) and $f(x)$ is positive for all $x$,"['integration', 'real-analysis']"
3515088,Determinant as measure of overall orthogonality of columns,"My understanding is that the determinant of a matrix can be thought of as the volume of a parallelepiped formed by the column vectors and copies of them linked to themselves. From this I can conclude making the vectors longer, or more orthogonal should increase the determinant. So if were to divide each column separately by its length (to get rid of the effect from longer vectors) and take the determinant of the resulting matrix, it should give me a sort of overall orthogonality score — the closer to $1$ the more orthogonal all the column vectors are to one another. Is there a name for this technique/number? I could see it being useful in statistics where each column is a feature and rows are observations, but when I try to Google it I just get results about orthogonal matrices, the end case where the determinant is $1$ , rather than discussion of this sort of score.","['statistics', 'determinant', 'orthogonality', 'matrices', 'linear-algebra']"
3515105,What does that fact that $AB = I_3$ tell us about $A$ and $B$?,"If we have to two matrices $A$ and $B$ such that, $A \in \mathbb{R^{3 \times 4}}$ and $B \in \mathbb{R^{4 \times 3}}$ . What does that fact that $AB = I_3$ tell us about $A$ and $B$ ?","['matrices', 'linear-algebra']"
3515115,Log-Likelihood function of log-Normal distribution with right censored observations and regression,"EXERCISE Find the log-likelihood function for the regression model of log-Normal Distribution considering the right-censored observations ATTEMPT: So, we know that the probability density function of log-normal distribution is: $$f(t)=\dfrac{1}{\sqrt{2πσ^2}\cdot t}\cdot exp(-\frac{(lnt-μ)^2}{2σ^2})$$ At first, we have to show that $S(t)$ (reliability function) is in this form: $$S(t;x)=S_0(tg(x))$$ where $S_0$ is a basic function and we usually have $g(x)=exp(-β'x)$ . In other words we have to show that we have an accelerated life model My first question is how can I show this, considering that I have to use the log-Normal distribution Afterwards, we take the log-likelihood function with right-censored observations $$L(μ,σ)=\prod\limits_{i=1}^n f(t_i)^{δ_i}S(t_i)^{1-δ_i}
\Rightarrow l(μ,σ)=lnL(μ,σ)=\sum\limits_{i=1}^n( δ_ilnf(t_i)+(1-δ_i)lnS(t_i)	)$$ I also know that I have to use that in accelerated life models, we have that: $$lnT_x=μ_0+β'x+σε$$ So, if $T_x$ follows Normal distribution, $lnT_x$ will follow log-Normal distribution. So I have to use that we speak about regression model but actually I do not have any idea how to use this. Can anyone give me a thorough solution/explanation of this problem because I do not have previous experience in this type of problems for any distribution. Thanks, in advance!","['regression', 'statistics', 'reliability']"
3515259,"Why are orthogonal polynomials ""unique""?","I am reading Numerical Analysis by Walter Gautschi, and the autor says (I quote): [Talks about $\{1, t, t^2, ..., t^n \}$ ] Since a linearly independent set can be orthogonalized by Gram-Schmidt, any measure $d \lambda$ of the type considered generates a unique [emphasis mine] set of (monic) orthogonal polynomials $\pi_j(t) = \pi_j(t; d \lambda)$ , $j=0, 1, 2, ...,$ satisfying $$\deg \pi_j = j, j = 0, 1, 2, ...,$$ $$\int_{\mathbb{R}} \pi_k(t) \pi_{\ell}(t) d \lambda (t) = 0 \text{ if } t \not = \ell.$$ There are called orthogonal polynomials relative to the measure $d \lambda$ . From what I understand, the author is saying that (for example) if we take the space spanned by $1, t, t^2$ and we have a fixed inner product $(u, v) = \int_a^b u(t)v(t)w(t) dt$ , then there exists a unique set of three monic, orthogonal polynomials which span this space. Furthermore, the author seems to say that this follows directly from the Gram-Schmidt process. I can sort of see a reason why these polynomials are unique; having made an orthogonal set $\{p_0, p_1, ..., p_{n-1} \}$ of $n$ polynomials, we want the $p_{n}$ (which has $n+1$ coefficients) to satisfy $$(p_k, p_n) = 0 \text{ for } k = 0, 1, ..., n-1$$ $$\text{leading coefficient = 1}$$ which is a system of $n+1$ equations in $n+1$ variables, so it could just have a unique solution. But I don't see why this system has to be non-singular.","['numerical-methods', 'linear-algebra', 'analysis']"
3515266,Identify line bundles on $\mathbb{P}^n$,"The base field is $\mathbb{C}$ throughout the question. Consider the projective space $\mathbb{P}^n$ . It corresponds to a principal $\mathbb{C}^*$ -bundle $$ \mathbb{C}^* \to \mathbb{C}^{n+1}-0 \to \mathbb{P}^n,$$ where $\mathbb{C}^*$ acts on $\mathbb{C}^{n+1}-0$ by multiplication $$ t\cdot(z_0,\dots,z_n) = (tz_0,\dots,tz_n).$$ Now fix an integer $d$ . We can change the fiber $\mathbb{C}^*$ to $\mathbb{C}$ by considering the action of $\mathbb{C}^*$ on $\mathbb{C}$ , $$ t \cdot z = t^d z.$$ Then we obtain a line bundle $\left(\mathbb{C}^{n+1}-0\right) \times_{\mathbb{C}^*} \mathbb{C}$ over $\mathbb{P}^n$ , where $\mathbb{C}^*$ acts on $\left(\mathbb{C}^{n+1}-0\right) \times \mathbb{C}$ by $$t \cdot ((z_0, \dots, z_n),z) = ((tz_0, \dots, tz_n), t^d z). $$ Is the line bundle $\left(\mathbb{C}^{n+1}-0\right) \times_{\mathbb{C}^*} \mathbb{C} \cong \mathcal{O}(d)?$ The following is my attempt to identify $\left(\mathbb{C}^{n+1}-0\right) \times_{\mathbb{C}^*} \mathbb{C}$ with $\mathcal{O}(d)$ . I use the standard open cover $\{U_i\}_{i=0,\dots,n}$ of $\mathbb{P}^n$ (i.e., $x_i \neq 0$ on $U_i$ ) and trivialize the line bundle over each $U_i$ as follows: $$
\begin{aligned}
\left( \left(\mathbb{C}^{n+1}-0\right) \times_{\mathbb{C}^*} \mathbb{C} \right) |_{Ui} & \to U_i \times \mathbb{C} \\
[(z_0, \dots, z_n),z] & \mapsto ([z_0, \dots, z_n], z_i^{-d}z).
\end{aligned}
$$ This is well defined because another representative $((tz_0,\dots,tz_n),t^d z)$ maps to the same element. The transition function from $U_i$ to $U_j$ is then $$
\begin{aligned}
g_{ji}: U_i \cap U_j & \to \mathbb{C}^* \\
[z_0, \dots, z_n] & \mapsto (z_j/z_i)^{-d}. 
\end{aligned}
$$ So these $g_{ji}$ 's are transition functions for $\mathcal{O}(d)$ . Does everything above look right?","['complex-geometry', 'vector-bundles', 'algebraic-geometry', 'principal-bundles']"
3515337,A supremum of independent increments is independent of the brownian motion,"I am now having difficulty in showing that $\sup_{t \geq 1} (W_t - W_1)$ is independent of $W_1$ , where the $W_i$ is a Brownian motion. I know that $W_t - W_1$ is independent of $W_1$ for all $t \geq 1$ due to the independent increment property. But, how can I show that the supremum is also independent of $W_1$ ? I thought that it suffices to show that $\sup_{t \geq 1} (W_t - W_1)$ is $\sigma((W_t - W_1)_{t\geq1})$ -measurable, because $\sigma((W_t - W_1)_{t\geq1})$ is independent of $\sigma(W_1)$ . Thus, instead of any Borel set, it suffices to show that the set $\big(\sup_{t \geq 1} (W_t - W_1) > a \big)$ is in $\sigma((W_t - W_1)_{t\geq1})$ for any $a \in \mathbb{R}.$ First, let me define, as C, the set on which $(W_t-W_1)_{t\geq1}$ has continuous sample paths. Then, clearly $\mathbb{P}(C)=1$ due to the defining property of Brownian motion, where $\mathbb{P}$ is the underlying probability measure. Now, I tried to prove in this way : $$\big(\sup_{t \geq 1} (W_t - W_1) > a \big) = \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C \bigg) \sqcup \bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg)$$ For $\bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C \bigg),$ using continuity, I can take rationals so that the set $\big(\sup_{t \geq 1} (W_t - W_1) > a \big)$ can be expressed as a countable union of sets contained in $\sigma(W_t - W_1)_{t\geq1}.$ Now, it remains to show that $C$ and $\bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg)$ are both contained in $\sigma(W_t - W_1)_{t\geq1}.$ But, then, I feel that there appears some delicacy that I find it somewhat hard to deal with. How can I show rigorously that $C$ is contained in $\sigma(W_t - W_1)_{t\geq1}.$ ? Assuming that $C$ is in $\sigma(W_t - W_1)_{t\geq1},$ $C^\complement$ is also in $\sigma(W_t - W_1)_{t\geq1}, $ and the measure of $C^\complement$ is evidently zero. Then, I feel that I need to use the completeness of the underlying probability measure $\mathbb{P}$ to deduce that $\bigg(\big(\sup_{t \geq 1} (W_t - W_1) > a \big) \cap C^\complement \bigg)$ is contained in $\sigma(W_t - W_1)_{t\geq1}.$ If my guess were right, then, if needed at all, on which probability space(triple) is the completion taken? Thank you so much for reading and anything correcting my logic will be enormously appreciated!","['measure-theory', 'brownian-motion', 'probability', 'real-analysis']"
3515570,Is this a trigonometric identity? $ \sum_{k=1}^n \frac 2 {1 - \cos\left((2k-1)\pi/n \right)} = n^2$,"Is this a trigonometric identity? $$
\sum_{k=1}^n \frac 2 {1 - \cos\left( \frac{2k-1} n \cdot\pi \right)} = n^2
$$ If I'm not mistaken, I can prove this when $n$ is a power of $2$ , by induction on the exponent. Numerical evidence suggests it is true of positive integers $n$ in general. Can it be proved?","['trigonometry', 'special-functions']"
3515582,Directional derivative at local maximum,"Suppose that $u(x, y)$ has a local maximum at $(0,0) .$ Show that for any direction $\frac{\partial u(0,0)}{\partial \vec{V}}=0$ . So I want to show that directional derivative is zero. So finally I get ${u(ah,bh) - u(0,0)}$ / $h$ as limit $h$ tends to zero ; how to proceed after that.","['maxima-minima', 'multivariable-calculus', 'derivatives']"
3515649,conditional probability or Bayes' theorem?,"My try : we can deal three different cases of removing two biased coin and 1 unbiased coin. Individual probability is known $$\frac9{10} , \frac2{25},\frac1{50}$$ After that total is 49 as one is removed.
now what to do conditional probability or Bayes' theorem ? i dont know how to implement ?","['combinations', 'conditional-probability', 'combinatorics', 'probability-theory', 'probability']"
3515677,How to interpret clusters on Markov chain time characteristics?,"I have a complex network $G=(V,E)$ from multivariate financial time series in which a single vertex $v_i$ represents the types of states corresponding to the combination of the fluctuations of the prices on a given time frame, a single edge $(v_i,v_j)$ denotes the transition from node $v_i$ to node $v_j$ . Then, I associated the graph $G$ with a first-order discrete-time Markov Chain as follows.
The node set $$V(G)= \{v_1, v_2, \ldots, v_n\}$$ is the finite discrete state space and the edge set $$E(G) \subseteq V(G) \times V(G)$$ determined by the rule $e=(v_i, v_j) \in E(G)$ for $v_i, v_j \in V(G)$ , corresponds to states’ transitions, and the edge weight is the transition probability between two states $v_i$ and $v_j$ . I have computed the eigenvalues of the transition matrix. All eigenvalues ​​lie in a unit circle (except 1) and the spectral gap equals $1- |\lambda_2|=0.38$ . The Markov chain is aperiodic (because self-loops exist) and is irreducible. I have found the mean recurrence time (left graph) and then sorted mean recurrence time (right graph). As on the left graph as on the right graph, one can see three 'clusters' (sets). I think that is not a typical case. 
Maybe the transition matrix has a specific form? My question is: How to interpret obtained clusters (subgraphs) for Markov chain time characteristics? I am looking for a possible practical interpretation. Edit 1. I have plotted the original graph $G$ with tree 'clusters'. Then densities, diameters for subgraphs were calculated. cluster vertexN edgeN     density diameter
       1      35   105  0.088235294  1.30119
       2      23    12  0.023715415  1.00000
       3      46    10  0.004830918  2.00000 Density of original graph is 0.0229649. Refs Meyn S P and Tweedie R L 2005 Markov Chains and Stochastic Stability Zhang  N. Prediction of financial time series with hidden markov models: Shandong university, China, 2001","['hidden-markov-models', 'transition-matrix', 'markov-chains', 'markov-process', 'probability']"
3515786,A generalization of the (in)famous IMO 1988 problem 6: If $\frac{a^2 + b^2 - abc}{ab + 1}$ is a positive integer then it is a square.,"This question is motivated by the famous IMO $1988$ problem $6$ . Is the following true? Let $a,b$ be positive integers and $c \ge 0$ be a non-negative integer. If $\dfrac{a^2 + b^2 - abc}{ab + 1}$ is a positive integer then it is a square.","['divisibility', 'number-theory', 'elementary-number-theory', 'vieta-jumping', 'square-numbers']"
3515809,Two applications of Goursat's lemma in Group theory,"I am reading the first chapter of Finite Groups by Serre, in which he invokes Goursat's Lemma for subgroups of a direct product $G\times H$ of groups. Using this link and this post by Arturo Magidin I came to an understanding of this lemma, and of why although it seems to be a classification of only subdirect products of $G\times H$ , it actually is  a classification of all subgroups of $G\times H$ . First of all, I am now trying to test my knowledge on the following elementary practice problem, which is to determine all subgroups of the direct product $C_5\times S_4$ . The only subgroups of $C_5$ are $1$ and $C_5$ itself. An isomorphism from the trivial group (quotient of $C_5$ by itself) needs to go to the trivial group (quotient of $S_4$ by itself), which gives rise by Goursat's Lemma to $C_5\times S_4$ itself. On the other hand, since $\#S_4=2^3\cdot 3$ , there don't exist $H,K$ such that $H\lhd K<S_4$ and $|K/H|=5$ , so by Goursat's lemma there doesn't exist a subgroup induced by an isomorphism $C_5\stackrel{\sim}{\to}H/K$ . What am I missing here? In particular, what is the required isomorphism from the lemma from which I get the trivial subgroup? The second question is about the application of Goursat's Lemma in Galois theory. I read about it in Serre, but it would be very useful to have a concrete example of it being applied. Any help is much appreciated.",['group-theory']
3515835,Differentiation of a log likelihood function,"I am trying to maximize a particular log likelihood function but I am stuck on the differentiation step. Given: $ \Theta_1 + ....... + \Theta_k = 1  $ The likelihood function is: $f_n(x|\Theta_1,.........,\Theta_k) = \Theta^{n_1}_1........\Theta^{n_k}_k$ Let $L(\Theta_1,......,\Theta_k) = log\,\,f_n(x|\Theta_1,.........,\Theta_k)$ and let $\Theta_k = 1 - \sum_{i=1}^{k-1} \Theta_i \qquad - (i)$ Then, $$ \frac {\partial L(\Theta_1,.......,\Theta_k)}{\partial\Theta_i} = \frac{n_i}{\Theta_i} - \frac{n_k}{\Theta_k}\qquad for \,\; i=1,.....,k-1 \qquad - (ii)$$ Case 1: We may write L as $\quad\sum_{i=1}^{k-1}n_i\,ln\,\Theta_i\,+\,n_k\;ln(1\,-\,\sum_{i=1}^{k-1} \Theta_i)\quad$ if we make the substitution in (i) Case 2: We may write L as $\quad\sum_{i=1}^{k}n_i\,ln\,\Theta_i\quad$ if we don't make the substitution in (i) For Case 1 derivative would be: $\quad\frac{n_i}{\Theta_i} - \frac{n_k}{\Theta_k}\qquad for \,\; i=1,.....,k-1$ For Case 2 derivative would be: $\quad\frac{n_i}{\Theta_i}\qquad for \,\; i=1,.....,k$ Thus for an $i\neq k$ depending upon if we make the substitution in (i) or not, we get two different results for the same partial derivative i.e. $\frac{\partial L}{\partial\Theta_i}$ Case 1 is the solution. But by this logic derivative can be anything depending on our choice of k in the set. Where am I going wrong in Case 2? Am I making an error by not making the  substitution and simply differentiating L. Please help.","['derivatives', 'log-likelihood', 'maximum-likelihood']"
3515857,Find $\Pr(\textbf{R}^2=\mathbf{0})$ if $\textbf{R}_{4\times 4}$ is a matrix with 1 in 2 random positions and zeros otherwise,"Find $\Pr(\textbf{R}^2=\mathbf{0})$ if $\textbf{R}_{4\times 4}$ is a matrix with 1 in 2 random positions and zeros otherwise. (ITA entrance exam, Brazil, 2020) My attempt : let $\textbf{R}=[r_{ij}]$ and $\textbf{R}^2=[r^2_{ij}]$ , so that $$r^2_{ij}=\sum_{t=1}^4 r_{it} r_{tj},\forall i,j\in\{1,..,4\}\ \ \ (*).$$ (1) there are ${16\choose 2}=120$ ways to position the 2 ones in the matrix. And it is direct to see that if at least one 1 is in diagonal, $\textbf{R}^2\not =\mathbf{0}$ . (2) let us count the number of $\textbf{R}$ matrices leading to $\textbf{R}^2\not =\mathbf{0}$ considering  3 cases: Case 1 - Two 1s in the diagonal: ${4\choose 2}=6$ ways. Case 2 - One 1 in the diagonal  and the other off diagonal: ${4\choose 1}{12\choose 1}=48$ ways. Case 3 - Both ones off diagonal. Considering the notation on expression (*) above, let us consider $t=1$ for instance, so that $i$ and $j$ $\in \{2,3,4\}$ , to avoid elements in the diagonal. There are $3^2=9$ possible ways to have $r_{i1}r_{1j}=1$ in this case. Considering $t\in \{2,3,4\}$ , using the same argument, will lead to a a total of $4\times 3^2=36$ matrices $\textbf{R}$ with two 1s off diagonal leading to $\textbf{R}^2\not =\textbf{0}.$ By adding Cases 1 to 3, there are $6+48+36=90$ matrices $\textbf{R}$ , leading to $\textbf{R}^2\not =\textbf{0}$ or $120-90=30$ matrices $\textbf{R}$ with $\textbf{R}^2 =\textbf{0}.$ And the asked probability would be $30/120$ But this last answer is wrong as the argument for case 3 overcounts, as the total should be 30 and not 36, with final correct answer $36/120=3/10$ Asked: Please point me out the mistake I'm doing the counting in Case 3. And advise on an efficient and straightforward way to count cases in situations like this.","['matrices', 'combinatorics', 'probability', 'contest-math']"
3515864,Example of a sigma compact space which is not locally compact,"A search through this site yielded plenty of examples where a space is locally compact but not sigma compact, but not the other way around. The fact that there is a term of sigma locally compact suggests that there are counter-examples, but I am having trouble finding one. I would appreciate any such counter-examples. Also I was wondering about the validity if the following condition would imply local compactness:
Let $X$ be a topological space such that $X=\cup_{n=1}^\infty K_n$ where $K_n$ is compact. If $\{K_n \}_{n=1}^\infty$ is locally finite, then $X$ is locally compact. This argument seems to work even if we have a general locally finite compact cover (every set is compact) and not just countable.  Under such conditions can we conclude local compactness?","['general-topology', 'solution-verification', 'examples-counterexamples', 'compactness']"
3515885,Why does the derivative equation of the unit semicircle equation intersect the semicircle at $x=-\frac{1}{\phi}$?,"I was playing around in desmos and I discovered something interesting, but I am nowhere near advanced enough to tackle this. The circle equation $f(x)=\sqrt{1-x^2}$ and its derivative (I don't know how to find the equation - if possible could you explain this as well?) intersect at or extremely close to (as in I zoomed in as far as I could in desmos) the point where x is equal to $\frac{-1}{\phi}$ where $\phi$ is 1.6180339... I don't know whether all 3 lines actually cross at this point, but it seems like it's too perfect to be false. Is anybody able to come up with a reason why this happens?","['golden-ratio', 'graphing-functions', 'derivatives', 'circles']"
3515900,Find the minimum value of $(\tan C – \sin A)^2 + (\cot C – \cos B)^2$ for the following given data,"Let $A, B, C$ be real numbers such that (i) $(\sin A, \cos B)$ lies on a unit circle centered at origin. (ii) $\tan C$ and $\cot C$ are defined. Find the minimum value of $(\tan C – \sin A)^2 + (\cot C – \cos B)^2$ . My multiple attempts are as follows:- Attempt $1$ : $$\sin^2A+\cos^2B=1$$ $$\tan^2C+\sin^2A-2\sin A\tan C+\cot^2C+\cos^2 B-2\cot C\cos B$$ $$(\tan^2C+\cot^2C)+1-2\left(\dfrac{\sin A\sin C}{\cos C}+\dfrac{\cos C\cos B}{\sin C}\right)$$ $$(\tan^2C+\cot^2C)+1-2\left(\dfrac{\sin A\sin^2 C+\cos^2 C\cos B}{\sin C\cos C}\right)$$ $$(\tan^2C+\cot^2C)+1-2\left(\dfrac{\sin^2C(\sin A-\cos B)+\cos B}{\sin C\cos C}\right)\tag{1}$$ Now from here how to proceed further. Attempt $2$ : $$\sin^2A+\cos^2B=1$$ $$\sin^2A=\sin^2B$$ $$A=n\pi\pm B$$ Considering only the principal range, $A=B$ , $A=-B$ , $A=n\pi-B$ , $A=n\pi+B$ Case $1$ : $A=B,A=-B$ Put $B=A$ or $B=-A$ in equation $(1)$ $$(\tan^2C+\cot^2C)+1-2\left(\dfrac{\sin A\sin^2 C+\cos^2 C\cos A}{\sin C\cos C}\right)$$ $$(\tan^2C+\cot^2C)+1-2\sqrt{\sin^4C+\cos^4C}\cdot\dfrac{\sin(A+\alpha)}{\sin C\cos C}$$ $$(\tan^2C+\cot^2C)+1-2\sqrt{\tan^2C+\cot^2C}\cdot \sin(A+\alpha)$$ So minimum value will be $3-2\sqrt{2}$ Case $1$ : $A=n\pi-B,A=n\pi+B$ Put $B=n\pi-A$ or $B=A-n\pi$ $$(\tan^2C+\cot^2C)+1-2\left(\dfrac{\sin A\sin^2 C-\cos^2 C\cos A}{\sin C\cos C}\right)$$ $$(\tan^2C+\cot^2C)+1-2\sqrt{\sin^4C+\cos^4C}\cdot\dfrac{\sin(A-\alpha)}{\sin C\cos C}$$ $$(\tan^2C+\cot^2C)+1-2\sqrt{\tan^2C+\cot^2C}\cdot\sin(A-\alpha)$$ So minimum value will be $3-2\sqrt{2}$ Any other way to solve this question?","['optimization', 'trigonometry', 'maxima-minima', 'geometry']"
3515950,"How to find a set $R$, such that $R+R=X$ for a given finite set of natural numbers $X$?","Given two finite sets of natural numbers $A$ and $B$ , denote the set $\lbrace a+b \mid a \in A \text{ and } b \in B \rbrace$ as $A+B$ .
What is the best known algorithm of finding a set of natural numbers $R$ , such that $R+R=X$ for some finite set of natural numbers $X$ ? A brief discussion of this problem is here .","['number-theory', 'computational-complexity', 'combinatorics']"
3515964,Quotient of measurable subspace measurable?,"Let $E$ be a Banach space, $N\subset E$ a closed linear subspace and $q:E\rightarrow E/N$ the natural quotient map. Question. If $X\subset E$ is a Borel-measurable linear subspace, is $q(X)\subset E/N$ also Borel-measurable (w.r.t. the quotient topology)? I am not sure whether the condition that $X$ is a linear subspace is really needed. Ideally it could be left away By the open mapping theorem, $q$ is an open map and thus  the collection of sets $\mathcal{S}=\{A\subset E: q(A) \text{ is Borel measurable }\}$ contains all open sets. If $\mathcal{S}$ was a Dynkin system, then we would be done, but this does not seem to be the case (e.g. I don't see why $q(A^c)$ should be measurable, when $q(A)$ is). The example I have in mind is $E=C(M)$ for a closed manifold $M$ . Then for $\alpha>\dim M/2$ one can show that the Sobolev space $X=H^\alpha(M)\subset E$ is measurable. I am interested whether this generalises to a smooth domain $\Omega\subset M$ , i.e. after taking the quotient with respect to $N=\{u: u\vert_{M\backslash \Omega} = 0\}$ .","['measure-theory', 'real-analysis', 'functional-analysis', 'borel-sets', 'probability-theory']"
3516048,Why the wrong answer in integral calculus?,"Calculate the volume of the solid obtained by rotating the region about the $x$ -axis, and bounded by $y=x^2+1, y=3-x^2$ . My calculations: $V=\pi \int_a^b f^2(x) dx; \; V = V_1 + V_2 = \pi \int_{-1}^1 (3-x^2)^2 dx - \pi \int_{-1}^1 (x^2+1)^2 dx;$ $V_1 = \pi \int_{-1}^1 (3-x^2)^2 dx = \pi \int_{-1}^1 (9-3x^2-3x^2+x^4) dx = \pi (9x-2x^3+\frac{x^5}{5} \; |_{-1}^1 )=14.4 \pi;$ \begin{align*}
V_2 & = \pi \int_{-1}^1 (x^2+1)^2 dx\\
    & = \pi \int_{-1}^1 (x^2+1)(x^2+1) dx\\ 
    & = \pi \int_{-1}^1 (x^4+x^2+x^2+1) dx\\ 
    & = \pi\left(\frac{x^5}{5}+\frac{2}{3} x^3+x \; \bigg|_{-1}^1\right)\\
    & = \pi\left(\frac{1}{5}+\frac{2}{3}+1+\frac{1}{5}+\frac{2}{3}+1\right)\\             
    & = 2\pi\left(\frac{1}{5}+\frac{2}{3}+1\right)\\
    & =2\pi\left(\frac{3}{15}+\frac{10}{15}+1\right)\\
    & =\left(2+\frac{26}{15}\right)\pi;
\end{align*} My answer: $V=14.4\pi - (2+\frac{26}{15})\pi;$ , but this answer does not fit.","['integration', 'calculus']"
3516076,Avoiding Circular Reasoning: How to Define Congruent Shapes,"I apologize for being overly verbose here, but the question I want to know is at the very bottom. I am going to be honest and say I have no idea how to axiomatically handle congruence in geometry and want to understand it. I have always held SSS, SAS, and CPCTC to be axiomatic where SSS and SAS are definitions to tell whether or not two triangles are congruent. Later, I realized I should not do that here ... Why does everyone say two shapes (e.g. triangles here) are congruent iff there is an isometry between the figures? I honestly view the word ""isometry"" as a made up word describing SSS by a Euclidean metric function that all of the sudden discusses ""types of rigid motions"". Clearly, if the distances between points are the same in context of triangles, then they satisfy SSS and vice versa. I am confused why the word isometry is discussed with rotations in particular... What is a rotation and how does that preserve distance here? How can a figure possibly be rotated in space by the means of a function this early on in geometry? We rotate points in space in terms of sine and cosine. We derive rotational matrices in terms of sine and cosine by double angle formulas. We define sine and cosine in terms of similarity which is done by similarity and axioms using SSS and SAS. We define similarity just like congruence with a scale factor . This leads me to this question again... Question: How are figures rotated by functions in terms of axioms in the context of isometries?","['congruences-geometry', 'geometry', 'rotations']"
3516127,Shortest Distance between two skew lines.,"I am trying to understand the Shortest dostance between two skew lines. 
I know the process. But I can not understand the process. My doubts are following. First: A line segment , which is perpendicular to both lines , is drawn . (My doubt --- How you are sure to have a segment like that? There may not exist such kind of segment.) Second: Two points P & Q,  one from each line, are taken and we determine the length of the projection of PQ on the segment. The length of the projection on the segment , which is perpendicular to both the lines,  is nothing but the length of the segment .This length is shortest distance. ( My question : PQ and the segment, which is perpendicular to both the lines, may not be coplanar. Then how we take the projection of PQ on the segment. ) Can someone please help me to clear my doubts?","['analytic-geometry', 'geometry', 'plane-geometry']"
3516138,Multivariate normal distribution moments,"I would like to evaluate the following higher order moments of a multivariate normal distribution in the case of mean $0$ and in the case of mean $\mu$ : \begin{equation}
E[X_i^{2 n}] \qquad E[(X_i^2 X_{i+1}^2)^n]
\end{equation} In the $0$ mean case I understand from the Wick Theorem that we should have $E[X_i^{2 n}]= \frac{(2 n -1)!}{2^{n-1}(n-1)!}E[X_i^{2}]^n$ but I cannot obtain the combinatorial factors of the other. In the non-central case I am quite lost.","['quantum-field-theory', 'statistics', 'normal-distribution', 'probability']"
3516140,Please explain this example of Rosen's book,"In Kenneth Rosen’s book example number 13 of Chapter 1.5 says, There is a woman who has taken a flight on every airlines In the example the solution is like this: Let $P(w,f)$ $:$ $w$ has taken $f$ $Q(f,a)$ $:$ $f$ is a flight in $a$ And the answer is $∃w∀a∃f(P(w,f)∧Q(f,a))$ My question is why the answer is not $∃w∀a∃f(Q(f,a)\to P(w,f))$ ? What is the difference between these two answers? Please explain.","['propositional-calculus', 'discrete-mathematics']"
3516145,Hall and Knight question,If n is any positive integer show that the integral part of $$(3+\sqrt7)^n$$ is a odd number I have no idea how to begin this problem but it is given in the chapter of binomial theorem so I hope that it is found using that only,"['algebra-precalculus', 'binomial-theorem']"
3516189,Prove existence of evaluation points such that the matrix has nonzero determinant,"I've been struggling with the following exercise for quite some time already: Consider a linear space $\mathbb{V} = \mathcal{C}\left(\left[a, b\right]\right)$ and let $f_{1},\ldots, f_{n}$ be linearly independent functions in $\mathbb{V}$ . Prove there exist numbers $a \leq x_{1} < \cdots < x_{n} \leq b$ such that $$ \det \begin{bmatrix}
f_{1}(x_{1}) & f_{1}(x_{2}) & \cdots & f_{1}(x_{n})\\
f_{2}(x_{1}) & f_{2}(x_{2}) & \cdots & f_{2}(x_{n}) \\
\vdots & \vdots  & \ddots & \vdots     \\
f_{n}(x_{1}) & f_{n}(x_{2}) & \cdots & f_{n}(x_{n})
\end{bmatrix} \neq 0.$$ The statement is extremely easy to prove by means of induction. However, I'm interested if there's another (and more elegant) proof which doesn't involve induction . Any hints appreciated.","['matrices', 'determinant', 'linear-algebra', 'functional-analysis']"
3516216,Is there an undetermined Banach-Mazur game in ZF?,"Given a topological space $\mathcal{X}=(X,\tau)$ , the Banach-Mazur game on $\mathcal{X}$ is the (two-player, perfect information, length- $\omega$ ) game played as follows: Players $1$ and $2$ alternately play decreasing nonempty open sets $A_1\supseteq B_1\supseteq A_2\supseteq B_2\supseteq ...$ . Player $1$ wins iff $\bigcap_{i\in\mathbb{N}} A_i=\emptyset$ . ZFC implies that there is a subspace of $\mathbb{R}$ with the usual topology whose Banach-Mazur game is undetermined; on the other hand, it's consistent with ZF+DC (and indeed adds no consistency strength!) that no subspace of $\mathbb{R}$ does this (""every set of reals has the Baire property""). However, when we leave $\mathbb{R}$ things get much weirder. My question is: Does ZF alone prove that there is some space $\mathcal{X}$ whose Banach-Mazur game is undetermined? Controlling the behavior of all possible topological spaces in a model of ZF is extremely hard for me, and I suspect the answer to the question is in fact yes . In fact, I recall seeing a pretty simple proof of this; however, I can't track it down or whip up a ZF-construction on my own (specifically, everything I try ultimately winds up being a recursive construction killed by having too many requirements to meet in the given number of steps).","['logic', 'axiom-of-choice', 'general-topology', 'infinite-games', 'set-theory']"
3516241,Find $m$ such that $x^4 - (2m - 1)x^2 + 4m -5 = 0$ has real roots,"Consider the equation: $$ x ^ 4 - (2m - 1) x^ 2 + 4m -5 = 0 $$ with $m \in \mathbb{R}$ . I have to find the values of $m$ such that the given equation has all of its roots real. This is what I did: Let $ u = x^2, \hspace{.25cm} u\ge 0$ We get: $$ u ^ 2 - (2m - 1)u + 4m -5 = 0 $$ Now since we have $$ u = x ^ 2$$ That means $$x = \pm \sqrt{u}$$ That means that the roots $x$ are real only if $u \ge 0$ . So we need to find the values of $m$ such that all $u$ 's are $\ge 0$ . If all $u$ 's are $\ge 0$ , that means that the sum of $u$ 's is $\ge 0$ and the product of $u$ 's is $ \ge 0 $ . Using Vieta's formulas $$S = u_1 + u_2 = - \dfrac{b}{a} \hspace{2cm} P = u_1 \cdot u_2 = \dfrac{c}{a}$$ where $a, b$ and $c$ are the coefficients of the quadratic, we can solve for $m$ . We get: $$S = - \dfrac{-(2m - 1)}{1} = 2m - 1$$ We need $S \ge 0$ , so that means $m \ge \dfrac{1}{2}$ $(1)$ $$P = \dfrac{4m - 5 }{1} = 4m - 5$$ We need $P \ge 0$ , so that means $m \ge \dfrac{5}{4}$ $(2)$ Intersecting $(1)$ and $(2)$ we get the final answer: $$ m \in \bigg [ \dfrac{5}{4}, \infty \bigg )$$ My question is: Is this correct? Is my reasoning sound? Is there another way (maybe even a better way!) to solve this?","['algebra-precalculus', 'quadratics']"
3516270,A strange bijection without fixed points,"Is it possible to construct a bijection $F:\mathbb Z \to \mathbb Z$ without fixed points (i.e. such that $F(i)\neq i$ for all $i \in \mathbb Z$ ) such that for all $j\in\mathbb Z_{\neq 0}$ , $$\lim_{n\to \infty} \frac{1}{n}\sum_{k=0}^{n-1}F(jk)-jk=0?$$ For the moment I'm just able to do the following observation: Since $F(jk)-jk\neq 0$ for all $j\in\mathbb Z_{\neq 0}, k\in \mathbb{Z}_{\geq 0}$ , then for every fixed $j \in \mathbb Z_{\neq 0}$ there must be infinitely many $k\geq 0$ s.t. $F(jk)-jk>0$ and infinitely many $k\geq 0$ s.t. $F(jk)-jk<0$ . This, in my mind, implies that $F$ has to be ""really chaotic"" and at the moment I do not know how to construct such a bijection. Any idea? Any help?","['ergodic-theory', 'functions', 'combinatorics', 'discrete-mathematics']"
3516302,show that the relation give by $\vert x \vert=\vert y \vert$ is an equivalence relation,"For the relation $$\vert x \vert = \vert y \vert$$ this consists of all the pairs $(\vert -a \vert,\vert a \vert)$ Clearly $$\vert x \vert = \vert x \vert$$ and $$\vert y \vert = \vert y \vert$$ for example $\vert 2 \vert = \vert 2 \vert$ and say $\vert 4 \vert = \vert 4 \vert$ Thus the relation is reflexive Clearly if $\vert x \vert = \vert y \vert$ then $\vert y \vert = \vert x \vert$ for example $\vert 3 \vert =\vert -3 \vert$ or $\vert -3 \vert = \vert 3 \vert$ Thus the relation is symmetric If $\vert x \vert = \vert y \vert$ and $\vert y \vert = \vert z \vert$ Clearly $\vert x \vert = \vert z \vert$ Thus the relation is transitive. Not sure how to show an example for the transitive property. I feel like this relation is pretty much self explanatory. Am I right that this consists of the pairs $(\vert -a \vert,\vert a \vert)$ ? Are my proofs without the examples acceptable? Are my examples correct? Can I improve my answer at all?","['equivalence-relations', 'algebra-precalculus', 'relations']"
3516310,Projections of the standard twisted cubic on $\mathbb{P}^2$ (Harris 3.8),"As in the title, I am trying to find the equation of the projection of the twisted cubic $$\mathscr{C}=V(Z_0Z_2=Z_1^2, \quad Z_0Z_3=Z_1Z_2,\quad Z_1Z_3=Z_2^2)\subset\mathbb{P}^3$$ on an hyperplane $\mathbb{P}^2$ from the points $p=[1:0:0:1]$ and $p=[0:0:1:0]$ . Since worjing with the resultant of polynomials is computationally inefficient my idea is the following, let us consider the second case, which I think is neater: Call $X=\pi(\mathscr{C})$ the projection. Fix $p=[0:0:1:0]$ and $\mathbb{P}^2=V(Z_2)$ , with coordinates $Z_0,Z_1,Z_3$ . Then $q=(z_0,z_1,z_3)\in X$ if and only if the line $\bar{pq}$ meets $\mathscr{C}$ . I translate this condition as: $$\exists\lambda\neq 0\ | (z_0,z_1,\lambda,z_3)\in\mathscr{C}$$ Then I plug this condition in the equations and develope the computation trying to delete $\lambda$ to obtain the desired equation Then I ask: Is the approach correct? Is the condition I fixed correct? I believe the other case is analogous and I would do it it by chosing $\mathbb{P}^2=V(z_0+z_3)$ , is it the right idea? The excercise then asks to show that any other projection is projectvely equivalent to one of the two above: I have no idea about how to prove this.","['algebraic-geometry', 'solution-verification', 'projective-space', 'projective-geometry']"
3516321,Find radius of convergence for a complicated series for $f'(f(x)) = f(f'(x))$,"Several months ago, I answered this question asking for solutions to the functional equation $f'(f(x)) = f(f'(x))$ by expanding as a formal Taylor series around some arbitrary fixed point of $f$ . This gives a formal solution, and if the series is convergent it gives an analytic solution. I'm wondering if there's a way to prove that this series has nonzero radius of convergence? I tried some crude tricks (like inductively proving $|f^{(n)}(c)| < n! a^n$ for some $a$ ) but didn't get anywhere. Proving existence of an analytic solution would also suffice, but I haven't found a simpler way to prove that either, except in some special cases. Is there a way to prove non-zero radius of convergence for this series given arbitrary $c$ and $\lambda$ ?","['functional-equations', 'complex-analysis', 'taylor-expansion', 'sequences-and-series', 'power-series']"
3516340,Eigendecomposing real matrices without knowing complex numbers,"Let $A$ be a real squared matrix. A scalar $\lambda\in\mathbb C$ is an eigenvalue for $A$ iff $$Av=\lambda v \tag A$$ for some complex vector $v$ . This condition can be equivalently written in terms of purely real quantities as the following system: $$\begin{cases}
  (A-\lambda_1 I)v_1 = - \lambda_2 v_2, \\
  (A-\lambda_1 I)v_2 = \phantom{-}\lambda_2 v_1,
\end{cases} \tag B$$ as can be seen by decomposing the quantities in (A) into real and imaginary parts: $\lambda=\lambda_1+i\lambda_2$ and $v=v_1+i v_2$ .
If we didn't know anything about complex numbers, we would be working directly on (B), asking for a pair of reals $\lambda_1,\lambda_2\in\mathbb R$ such that (B) is satisfied for some real vectors $v_1,v_2$ . This pair of conditions can be seen to imply to the following ones: $$\begin{cases}
  [(A-\lambda_1 I)^2 + \lambda_2^2 I ]v_1 = 0, \\
  [(A-\lambda_1 I)^2 + \lambda_2^2 I ]v_2 = 0.
\end{cases} \tag C$$ This follows from applying $(A-\lambda_1 I)$ twice to either $v_1$ or $v_2$ , and using (B).
This, on the other hand, is equivalent to the condition $$\det[(A-\lambda_1 I)^2 + \lambda_2^2 I] = 0. \tag D$$ See also this post about the equivalence of (A) and (D). From complex analysis we know that, given an arbitrary real matrix $A$ , there must be a pair of reals $\lambda_1,\lambda_2$ such that (D) is verified. Not knowing what complex numbers are, how would we go in finding such values for a given $A$ ? The determinant equation gives a polynomial of two variables which I'm not sure how to handle.","['matrices', 'complex-analysis', 'linear-algebra', 'eigenvalues-eigenvectors']"
3516342,Small resolution of threefold with a node,"I heard that a one-parameter family of surfaces acquiring a node (explicitly below) can be made into a smooth family through a small resolution of the ambient threefold . I want to know why. Explicity, consider a one parameter family of (analytic) surfaces $$X=\{x^2+y^2+z^2+t^2=0\}\xrightarrow{f} \Delta, \ \ \ \ (x,y,z,t)\mapsto t$$ in a small neighborhood of $0\in \mathbb C^4$ over a disk $\Delta$ . Then both the fiber $X_0=f^{-1}(0)$ and the total space $X$ have a node at $0$ . It is claimed that a small resolution $\hat{X}$ of the total space $X$ produces a smooth family of surfaces $\hat{X}\to \Delta$ . Here ""small"" means exceptional locus has dimension one , or (in this case) is simply a copy of $\mathbb P^1$ . Assuming such resolution exists, I'd like to ask: Question 1 : How to show $\hat{X}\to \Delta$ is smooth? Remark: This is intuitively true to me because topologically $X_0$ can be obtained from nearby $X_t$ by contracting the vanishing cycle $\cong S^2$ . On the other hand, the small resolution replace the node by a $\mathbb P^1\cong S^2$ , so it seems to reverse the process and make $\hat{X}_0$ topologically the same to $X_t$ . However, I want to see how this is worked out in local coordinates. I also heard/read that such a small resolution is obtained by big blowup $Bl_0X$ with an exceptional divisor $E\cong \mathbb P^1\times \mathbb P^1$ a smooth quadric surface, then blowdown one of the ruling. By my computation, the normal bundle of a ruling to $Bl_0X$ is $\mathcal{O}_{\mathbb P^1}(-1)+\mathcal{O}_{\mathbb P^1}$ , but I'd like to ask Question 2 : What is the criterion to blowdown a ruling of quadric surface in a threefold? Thanks in advance if anyone has a solution or reference!","['complex-geometry', 'algebraic-geometry', 'deformation-theory', 'birational-geometry']"
3516379,Lie derivative of vector fields and flows of vector fields: Is this formula right?,"In the lecture we have defined the Lie derivative as $$\mathcal{L}_{X}Y:=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}\Phi_{t}^{\ast}Y$$ where $X,Y\in\mathfrak{X}(\mathcal{M})$ are vector fields on a manifold $\mathcal{M}$ and $\Phi$ is the flow of X. My goal is now to plug in the definition of the pull-back in order to rewrite this formula without the pull-back....I am often confused with the different definition and notations in diffgeo and therefore I would be fine if someone can say if the following is correct: (1) The push-forward of a tangent vector (viewed as a derivation) is for a function $f:\mathcal{M}\to \mathcal{N}$ between two manifolds and a tagent vector $v\in T_{p}\mathcal{M}$ defined as $$f_{\ast}v:=\mathrm{d}_{p}f(v)$$ or in other words: for some function $h\in C^{\infty}(N)$ : $$(f_{\ast}v)(h):=[\mathrm{d}_{p}f(v)](h):=v(h\circ f).$$ (2) For a vector field $X\in\mathfrak{X}(M)$ , the push-forward is defined pointwise: $$(f_{\ast}X)_{q}:=\mathrm{d}_{f^{-1}(q)}(X_{f^{-1}(q)})$$ for some $q\in\mathcal{N}$ , where we have to require that f is a diffeomorphism. (3) Therefore we find with the flow $\Phi_{t}:\mathcal{M}\to \mathcal{M}$ for $p\in\mathcal{M}$ and $f\in C^{\infty}(\mathcal{M})$ : $$(\Phi_{t}^{\ast}Y)_{p}(f):=(\Phi^{-1}_{t\ast}Y)_{p}(f)=[\mathrm{d}_{\Phi_{t}(p)}\Phi_{t}^{-1}(Y_{\Phi_{t}(p)})](f)=Y_{\Phi_{t}(p)}(f\circ \Phi_{t}^{-1})$$ (4) Using that $\Phi^{-1}_{t}=\Phi_{-t}$ this yields the formula: $$(\mathcal{L}_{X}(Y))_{p}(f)=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}Y_{\Phi_{t}(p)}(f\circ \Phi_{-t}) $$ If we now view vector fields as derivation on $C^{\infty}(\mathcal{M})$ , namely $X:C^{\infty}(\mathcal{M})\to C^{\infty}(\mathcal{M})$ instead of $X:\mathcal{M}\to T\mathcal{M}$ , this can also be written as: $$(\mathcal{L}_{X}(Y))(f)=\frac{\mathrm{d}}{\mathrm{d}t}\bigg\vert_{t=0}Y(f\circ\Phi_{-t})\circ\Phi_{t}$$ Are the steps and the final formula right?","['vector-fields', 'lie-derivative', 'differential-geometry']"
3516412,Parametric Equations for A Logarithmic Sine-wave With Alternately Offset Points of Hyperbolic Tangency,"I've been trying to derive the parametric equations for a specific type of sine-wave for quite some time, and now I think I know how to do it in principle but lack the skill in practice. So, I'd be very thankful for some help! The wave I want is essentially the same as the one graphed here with one key difference. The sine-wave in my graph has the following properties: 1. It has points of tangency to $y\cdot x=\pm 1$ (See my Graph.). 2. The vertical distance between these points of tangency on the respective sides increase by powers of $\varphi$ ( STARTING AT $\varphi^1$ WHEN ONLY POSITIVE NUMBERS ARE GRAPHED ) on alternate sides. (See my fig: $B$ is $\varphi$ times $A$ .) The Pattern goes on repeating forever up the graph. ( $\varphi$ is the Golden Ratio Constant: $1.618\ldots$ , or $0.618\ldots$ ). 3. The graph starts at $(0, 1)$ for all positive numbers graphed. 4. Leaving aside the "" $\sin(t)$ "" The function for $x(t)$ is the inverse of the function for $y(t)$ . That's why it has points of tangency to $y\cdot x=\pm 1$ . 5. The vertical distance between the aforementioned points of tangency are always powers of $\varphi$ times a constant $\alpha$ . Ok, so, I want to retain properties 1. through 4. ( This Is Very Important!! ), while being able to change the value of $\alpha$ . To be specific, I want to be able to set $\alpha$ equal to $\varphi^{-2}$ (that is $1.618^{-2}$ ). In essence, that's it. A little note on the overall nature of the problem: At first you might think of dividing / multiplying the function(s) ( $\varphi^t/PI$ and $\varphi^-t/PI$ ) by something to solve the problem. But, I found that this is the same as using $\cos(t)$ , and the issue with it and the thing that makes the problem rather tricky is that this will make it so that the graph does not start at $(0, 1)$ (for positive numbers). This is where the Key difficulty lies. My graph and image should provide any other information you might need. I'm very excited to find an answer and can't wait for a response. Thank you all so much! NOTES: A: This question is cross-posted here B: Make sure to look carefully at my graph; it shows the definition of α and shows points of tangency and more... C: Please give answers in terms of "" $\sin(t)$ "", not "" $\cos(t)$ "", thank you!"". D: A version of this question with $\alpha=1$ is asked and answered in the question ""Deriving Parametric Equations For A Hyperbolic PHI Sine-Wave"" .","['golden-ratio', 'calculus', 'wave-equation', 'trigonometry', 'algebra-precalculus']"
3516431,Bizarre Definite Integral,"Does the following equality hold? $$\large \int_0^1 \frac{\tan^{-1}{\left(\frac{88\sqrt{21}}{215+36x^2}\right)}}{\sqrt{1-x^2}} \, \text{d}x = \frac{\pi^2}{6}$$ The supposed equality holds to 61 decimal places in Mathematica, which fails to numerically evaluate it after anything greater than 71 digits of working precision. I am unsure of it's correctness, and I struggle to prove it's correctness. The only progress I have in solving this is the following identity, which holds for all real $x$: $$\tan^{-1}{\left( \frac{11+6x}{4\sqrt{21}} \right )} + \tan^{-1}{\left( \frac{11-6x}{4\sqrt{21}} \right )} \equiv \tan^{-1}{\left(\frac{88\sqrt{21}}{215+36x^2}\right)}$$ I also tried the Euler Substitution $t^2 = \frac{1-x}{1+x}$ but it looks horrible. Addition: Is there some kind of general form to this integral? Side thoughts: Perhaps this is transformable into the Generalised Ahmed's Integral, or something similar.","['integration', 'pi', 'definite-integrals']"
3516469,Find sum of the series $\sum\limits_{n=0}^{\infty}\frac{1}{2n+1}\left ( \frac{1}{2} \right )^{n}$,"Find sum of the series: $\sum\limits_{n=0}^{\infty}\frac{1}{2n+1}\left ( \frac{1}{2} \right )^{n}$ . I just thought that this series is the derivation of the original one, but it is not. Then I know that: $\sum\limits_{n=0}^{\infty}x^{n}=\frac{1}{1-x}$ , so in my case $x=\frac{1}{2}$ , but I really do not know, how I should get the fraction. Can anyone please help me?","['calculus', 'sequences-and-series']"
3516492,Splitting up students into groups,"Mr. Porter has 12 students in his combinatorics class. In the first week of class, he
tells his students to break up into 4 groups of 3 people each to work on a project.
In the second week, he assigns another project, and he tells his students to break
up into 6 groups of 2 people each, such that none of the people in each group were
in the same group in the first week. In how many ways can the students form the
groups in the second week? (Assume that the order in which they form the groups
does not matter.) (A) 1296 (B) 2546 (C) 2995 (D) 3348 (E) 10395 First, I pick some random person named Joe. Then, he has 9 choices for who he can be paired up with. This step eliminates B and C. Now we pick another person from Joe's group. He has 8 people to choose from, but we need to divide by 2 for overcounting to get $9\cdot 8/2=36$ . The final person has $7$ ways. But, none of the answers are multiples of $\text{lcm}(36,7)=252$ . Help?","['contest-math', 'combinatorics']"
3516525,The value of the series: $\sum_{p=1}^{n} \sin(\frac{p}{n^2})$,"Find the limit as $n\rightarrow \infty$ of: $$\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right)$$ This question seems odd to me because it was included in my differentiability problems set . My Attempt: We have: $\sin(x) \le x $ , Thus clearly: $$\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right) \le \sum_{p=1}^{n} \frac{p}{n^2}$$ I have to prove that: $$\sum_{p=1}^{n} \frac{p}{n^2} \rightarrow \frac12$$ And: $$\frac{1}{2}\le\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right)$$ To conclude that the series converges to $\frac12$ . Though, I think there exists another solution that uses derivative or something similar. Update: I proved by double summation that: $$\sum_{p=1}^{n} \frac{p}{n^2} = \frac{1+\frac1n}{2}$$ So it clearly goes to $\frac12$","['derivatives', 'sequences-and-series']"
3516567,"Solve the equation $\min \{ \sin x, \cos x \} = \frac{\pi}{4}$ in $[0, 2\pi]$.","Consider the following equation: $$\min \{ \sin x, \cos x \} = \dfrac{\pi}{4}$$ I have to solve this equation for $x$ in $[0, 2\pi]$ . What I want to know is how can I solve this without going to a site like Desmos and plotting $y = \min \{ \sin x, \cos x \}$ and $y = \dfrac{\pi}{4}$ and see that these two functions have no intersection, therefore there are no solutions. How would I approach this on paper?",['trigonometry']
3516603,Find the equivalence class of this relation,"The set R: $R = $ {(0,1), (0,0), (1,0), (1,1), (2,3), (2,2), (3,2), (3,3) (4,5), (5,4), (4,4), (6,6), (5,5) 
(6,7), (7,6), (7,7)} I was just wondering if I've found the right equivalence classes for this relation? My working: The relation is an equivalence relation. Therefore, $[X]_R = $ { {0,1}, {2,3}, {4,5}, {6,7} }","['equivalence-relations', 'relations', 'discrete-mathematics']"
3516621,Homomorphisms between matrix groups,"I was having a discussion with my friend, who is a physics major, but nevertheless enjoys taking math courses. He believes that a non-trivial homomorphism as I describe below cannot exist. My gut tells me that that is not true, but I am not able to find an example. Could anyone define a group homomorphism from a matrix group that is a subgroup of $GL_n(\mathbb{Z}[x, x^{-1}])$ to a matrix group that is a subgroup of $GL_n(\mathbb{Z})$ ?","['matrices', 'group-homomorphism', 'group-theory', 'linear-algebra']"
3516714,Term by term integration of series on infinite intervals,Suppose $f(x)=\sum a_n x^n$ is given by its Taylor series such that $\int_0^{\infty} f(x)dx$ exists. Under what conditions can we integrate term by term by replacing $f(x)$ by its Taylor series?,"['lebesgue-integral', 'analysis', 'real-analysis', 'calculus', 'functional-analysis']"
3516754,Question about the relation between integration and differentiation (From Calculus by Apostol),"I got stuck while doing exercise of the Apostol's Calculus, the exercise 28 of Section 5.5. Here's the question Given a function $f$ such that the integral $A(x) = \int_a^xf(t)dt$ exists for each $x$ in an interval $[a, b]$ . Let $c$ be a point in the open interval $(a, b)$ . Consider the following ten statements about this $f$ and this A: And there are five (a) ~ (e) statements on the left, and five ( $\alpha$ ) ~ ( $\epsilon$ ) statements on the right. The author asks the reader to decide the implicative relation from statements on the left to statements on the right. I thought I answered correctly but the solution at the end tells different. I don't know why this is wrong. (d) $f'(c)$ exists. $\implies$ ( $\epsilon$ ) $A'$ is continuous at c. This is my argument:
By the Example 7 of Section 4.4, the differentiability of $f$ at c implies the continuity of $f$ at c. Since $f$ is differentiable at c, $f$ is continuous at c, so that $A'$ , which equals to $f$ , should continuous at c. But the solution at the end says (d) does not implies ( $\epsilon$ ). Sorry for the partializing the problem, it maybe tough to point out what is wrong.","['integration', 'continuity', 'calculus', 'real-analysis']"
3516795,Prove a function is constant under certain conditions,Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be smooth and such that for every $x$ $$\int_{-\infty}^{\infty}\frac{|f(x)-f(y)|}{|x-y|^2}dy < \infty$$ Prove that $f$ is constant.,"['integration', 'improper-integrals', 'analysis', 'real-analysis']"
3516796,Full Rank Exponential Families,I am trying to better understand the importance of full rank exponential families of distributions i.e. a family of populations dominated by a $\sigma$ -finite measure such that the radon-nykodym derivative can be written as $$ f_\theta(x)=h(x)e^{\eta(\theta)^tT(x)-\zeta(\theta)} $$ I am trying to understand why the statistic $T(x)$ is minimally sufficient only when the family of populations $f_\theta$ is of full rank i.e that there exists an open set within the parameter space of our family of populations. What happens if full rank is not satisfied?,"['statistical-inference', 'statistics', 'exponential-distribution', 'sufficient-statistics']"
3516841,Expected number of ﬂips needed that at least two heads and one tail have been ﬂipped,"The original question is shown below (References from the book of Introduction to Probability Models Tenth Edition): A coin, having probability $p$ of landing heads, is continually ﬂipped until at least one head and one tail have been ﬂipped. (a) Find the expected number of ﬂips needed. (d) Repeat part (a) in the case where ﬂipping is continued until a total of at least two heads and one tail have been ﬂipped. I solve the question (a), but I am not sure my answer for question (d). My answer is shown: Let $N$ is the number of flips at least two head and one tail. $$
\begin{align*}
E[N] &= E[E[N|Y]]\\ &= E[N|HH]P(H)P(H) + E[N|HT]P(H)P(T) + E[N|TH]P(T)P(H)
\end{align*}
$$ $E[N|HH]$ means the first two are heads until a tail appeared; $E[N|HT]$ means the first two are head and tail until a head appeared; $E[N|TH]$ means the first two are head and tail a head appeared; Let $E[T] = 1/q = 1/1-p$ , $E[H] = 1/p$ Then, $E[N] = (2+1/q)pp + (2+1/p)p(1-p) + (2+1/p)p(1-p)$ ←Ans. I am not sure whether I am right? Thanks a lot.","['expected-value', 'probability']"
3516872,"Sum of hypergeometric series, but I don't understand hypergeometric series.","Today, a friend and I have been trying to find a general formula for the partial sums of a series that goes like this: $$ 1, 2, 8, 64, 1024, \cdots $$ we came up with a recursive formula for it: $$a(n) = 2^n\\ b(0) = 1\\ b(n>0) = a(n)\cdot b(n-1)$$ and I've managed to determine that it's some form of hypergeometric series. I've tried deciphering the Wikipedia page on the generalized hypergeometric series but there's far too much information overflow for me to properly understand it, and therefore I've been unable to find the formula we've been looking for. What I'm asking is for a more simplified (doesn't need to be in layman's terms, but still understandable to someone with only high-school and olympiad math experience) explanation of generalized hypergeometric series and what the formula is for the partial sums of the sequence, and how you got the formula. as always, any assistance would be appreciated. Thanks.","['power-series', 'algebra-precalculus', 'geometric-series', 'hypergeometric-function']"
3516889,isn't right to prove that $\sqrt{2}$/4 is irrational number?,"Assume $\sqrt{2}$ /4 is rational number. rational number have p/q in the lowest term. \begin{align}\sqrt{2}/4 = p/q\\
\sqrt{2}=4p/q\\ 
2=16p^2/q^2\\
2q^2=16p^2\\
2q^2=2(8p^2) \\ 
q^2=2(4p^2)\\
\end{align} Then we know that q is even number according to if $q^2$ is even then $q$ is even. Also,we have $2q^2$ = $16p^2$ in the above,we know that $16p^2$ is a even number. So we can construct the form in the below: \begin{align}2(16a)=16p^2\\p^2=2a
\end{align} Then we know that p is even number according to if $p^2$ is even then $p$ is even. Since we  assumed that $\sqrt{2}$ /4 is in the lowest form of rational number,but the result showed p and q have the common factor 2.It causes to contradiction  and means that our assumption is wrong. Therefore, $\sqrt{2}$ /4 is irrational number.","['solution-verification', 'logic', 'discrete-mathematics']"
3516906,Minimum number of triangles in a graph,"I got the following question during a Discrete Mathematics exam. I have absolutely no clue how to even start solving and I just wanted to share it since it looks like an interesting problem, perhaps someone is able to provide a nice proof :). Let $G = (V,E)$ be a graph, such that $|V| = n$ and $|E| = \left\lfloor{\dfrac{n^2}{4}}\right\rfloor + 1$ . Show that there are at least $\left\lfloor{\dfrac{n}{2}}\right\rfloor$ triangles in $G$ .","['graph-theory', 'triangles', 'discrete-mathematics']"
3516916,Group freely generated by monoid,"There are several ways to define the group freely generated by a monoid, all of which (necessarily) produce isomorphic groups. One way starts with a presentation of the monoid, and simply reinterprets this as a presentation of the group. Another way is to formally adjoin the inverse of every element of the monoid. Yet another approach is to do something akin to the construction of the field of fractions of a ring, by considering equivalence classes of pairs of elements in the monoid. (Actually what I had in mind for that last one only works in the commutative case.) As far as I can tell, all of these approaches involve making drastic changes to the underlying sets, and I am wondering whether there is a way of doing this that literally extends the underlying set. More formally, I ask the following: Question. Given a set $S$ together with a multiplication $m$ and an identity $e$ satisfying the monoid axioms, how do we explicitly construct (in terms of $S,m,e$ ) a set $T$ , a multiplication $m'$ , and an inverse $i$ such that: $S\subseteq T$ $m'|_{S\times S}=m$ $(T,m',i,e)$ is a group For example, any such construction would presumably embed the additive monoid $\mathbb N$ in $\mathbb Z$ , whereas the multiplicative monoid $\mathbb N^{\times}$ would presumably be embedded in $\mathbb Q^+$ . It will be a nice bonus if this construction is functorial (i.e., there is a way of extending the definition such that it associates to each monoid homomorphism a group homomorphism between the constructed groups). This question is motivated by some variations in which I do know of such a construction: namely, the construction of free monoids on a set and free groups on a set. The former case, which I will shortly describe, is quite simple and elegant while the latter case is more ugly and complicated. So I was wondering if there was a nicer way to ""factorize"" the construction of a free group into two pieces, each nicer on their own than the composite: first build the free monoid on the set, then build the free group on the constructed monoid. The free monoid construction. Given a set $S$ , let $$
S^\star=\bigsqcup_{n=0}^{\infty}S^n.
$$ Turn $S^\star$ into a monoid by defining a multiplication $m\colon S^n\times S^m\to S^{n+m}$ in the obvious way (i.e. concatenation of tuples). The identity is the unique element of $S^0$ . This construction is functorial in an obvious way. The free group construction. I won't spell out the details since they are ugly. Given the generating set $S$ , one considers a subset of $$
\bigsqcup_{n=0}^{\infty}(S\sqcup S)^n
$$ consisting of ""reduced words"" (where the second copy of $S$ is thought of as formal inverses to the first copy of $S$ ) and the multiplication consists of concatenation followed by reduction. This is also functorial, but requires some work to show this explicitly. One more comment: a (functorial) answer to my question will yield (after composing with the forgetful functor from groups to monoids) an interesting monad in the category of monoids, whose Eilenberg-Moore category is equivalent to the category of groups. (This is actually what I am trying to find an explicit description for, but I have phrased my question in a more elementary way since I think it better focuses the question on where my difficulties lie.)","['monads', 'monoid', 'category-theory', 'free-groups', 'group-theory']"
3516970,"Can $\operatorname{Re}(a+bi)^{n}$ be overlapped with $a,b\in\mathbb{Z}$ fixed?","Is there any integer solution for $$\operatorname{Re}((a+bi)^{m})=\operatorname{Re}((a+bi)^{n})$$ except $(m,n)=(0,1),(1,3)$ , where $0\leq m<n,\ |a|\neq |b|,\ a\neq 0,\ b\neq 0$ ? In other words, Can $\operatorname{Re}(a+bi)^{n}$ be overlapped with $a+bi\in\mathbb{Z}[i]$ fixed except for some trivial cases? This is a generalization of my earlier question, Is there any integer solution for $\operatorname{Re}(a+bi)^n=\pm1$ , where $n\geq 2$ , except $(a,b)=(\pm1,0),(0,\pm1)$ ? .
The answer to this question is no. So, we have no solution for $m=0$ . I checked for every $0<|a|,|b|\leq 10000,\ |a|\neq|b|,\ 0\leq m<n\leq 1000$ , then only found these: $(a,b,m,n)=(\pm 2,\pm 1,1,3), (\pm 7,\pm 4,1,3), (\pm 26,\pm 15,1,3), (\pm 97,\pm 56,1,3), (\pm 362,\pm 209,1,3), (\pm 1351,\pm 780,1,3), (\pm 5042,\pm 2911,1,3)$ They are the integer solutions for $\operatorname{Re}(a+bi)^{1}=\operatorname{Re}(a+bi)^{3} \iff a^2-3b^2=1$ . I couldn't find any solutions for $(m,n)\neq (1,3)$ . PS Just for your information, I also checked for $\operatorname{Im}(a+bi)^n$ ,
then I found these solutions: $(a,b,m,n)=(-2,\pm4,2,3),(8,\pm24,4,5),(9,\pm15,2,3),(-32,\pm56,2,3),(121,\pm209,2,3),(-450,\pm780,2,3),(1681,\pm2911,2,3)$ Except for $(a,b,m,n)=(8,\pm24,4,5)$ , they are the integer solutions for $\operatorname{Im}(a+bi)^{2}=\operatorname{Im}(a+bi)^{3} \iff 3a^2b-b^3=2ab \iff 3a^2-2a=b^2$ . I would appreciate any help. Thank you for your cooperation.","['gaussian-integers', 'number-theory', 'elementary-number-theory', 'diophantine-equations', 'complex-numbers']"
3516994,Forecasting time series,"I am trying to solve the following problem. Let the time series $S_t$ , $t\in \{1,...N\}$ and consider its corresponding return $R_t$ defined as \begin{equation}
R_t=\log(\frac{S_t}{S_{t-1}})=\mu_t+\sigma_t
\end{equation} Let $\Psi=\{\Psi_t\}$ be a $\sigma$ -algebra where $\Psi_t=\sigma(\{S1,..,S_t\})=\sigma(\{R_1,..,R_t\})$ . The model is described as follow: \begin{equation}
\mu_t=c+\theta_1R_{t-1}+\theta_2R_{t-2}
\end{equation} \begin{equation}
\sigma_t=\sigma_{t,1}+\sigma_{t,2}
\end{equation} where \begin{equation}\sigma_{t,1}|\Psi_{t-1}\sim N(0,h) \;\;\;\;\;\;\;\sigma_{t,2}=\sum_{k=1}^{N_t}V_{t,k}-\lambda\phi
\end{equation} with $N_t \sim Poiss(\lambda)$ and $V_{t,k} \sim N(\phi,\theta^2)$ i.i.d. for $k=1,2...$ . $\;\;$ So $E[\sigma_{t,2}|\Psi_{t-1}]=0$ . The model parameters are $\{c,\theta_1,\theta_2,h,\lambda,\phi,\theta\}$ and 
I have already estimated them by maximizing the log-likelihood function. Now, I would like to compute a forecast for $\hat{S_t}=\hat{S_{t-1}}e^{\hat{R_t}}$ , $t\in\{N+1,...,N'\}$ with $N'>N$ , but I don't know how to do it. I have already tried taking conditional expectation $E[S_t|\Psi_{t-1}]$ but the result is a straight line and I think it is a too rough solution. Any kind of help would be appreciated.","['conditional-probability', 'statistical-inference', 'statistics', 'probability']"
3517011,Notation to select column from matrix,"Consider a matrix $X \in \mathbb{R}_{n \times m}$ . One compact yet unclear notation to select a row or column from this matrix is: $$x \in X$$ How do you clearly select a row or column from a matrix? I know $X = (x_{ij})$ is a standard notation to select elements. Though I haven't seen this used, $x_i \in X_{ij}$ for rows and $x_j \in X_{ij}$ for columns might make sense. This is motivated by a similar notation I have seen, namely $\sum\limits_{i}X_{ij}$ for row sum or $\sum\limits_{j}X_{ij}$ for column sum.","['matrices', 'notation', 'vectors']"
3517040,Gershgorin circle theorem and similarity transformations,"Consider the following problem, that was part of an old exam I am studying for: Let $$ A = \begin{pmatrix} 4 & 0 & 2\\
 -2 & 8 & 2\\ 0 & 2 & -4 \end{pmatrix}$$ Using the Gershgorin circle theorem, show that $A$ has exactly one eigenvalue with a negative real part. Find three disjunct circles, such that each contains exactly one eigenvalue. Give an approximation for the biggest eigenvalue that is as close as possible. Hint: For 2. and 3., consider $\hat{A} = D^{-1}AD$ with $D = diag(1,c,1),\: c>0$ . For 3., choose $c$ to yield an optimal
  approximation. Now, we dealt with the Gershgorin circle theorem in class, and I can apply it well in the first part of the problem. My issue is with the second and last parts - I have never seen the use of similarity transforms in combination with the theorem. I only know that such transformations keep the eigenvalues intact, and that in some cases, it can be used to extract more information from the Gershgorin circles. My question is though: How do I select such a $c$ to retrieve an optimal approximation? What is the strategy here? What I have tried so far: I calculated the Matrix $D^{-1}AD$ parameterized by $c$ : $$D^{-1}AD = \begin{pmatrix}4 & 0 & 2 \\ -\frac{2}{c} & 8 & \frac{2}{c}  \\ 0 & 2c & -4\end{pmatrix}$$ The three resulting Gershgorin circles are therefore: $C_1 = (4, 2)$ $C_2 = (8, \frac{4}{c})$ $C_3 = (-4, 2c)$ $C_3$ immediately solves the first part of the problem, since for $c=1$ it's the only circle that is on the negative side of the real axis.
For the second part, I need to find a $c$ such that $C_1$ and $C_2$ dont overlap anymore (which they do for $A$ ), which means that: $$\frac{4}{c} < 2$$ This is easily the case for $c > 2$ , for example $c = 2.1$ . But how do I pick an optimal $c$ for the last part of the problem? The circle with the biggest ""magnitude"" $C_2 = (8, \frac{4}{c})$ just gets smaller in radius for bigger $c$ .","['gershgorin-sets', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'similar-matrices']"
3517056,Exact coefficient in equivalence of norm in finite dimensional space.,"Let $X$ be a $d$ -dimensional Banach space with norm $\| \cdot \|$ and bases $e _1 , e _2 , \ldots , e _ d$ . 
By the equivalence of all norms in finite dimensional space, there exists $c> 0$ such that $$
\left \| \sum ^{d}_{i=1} \lambda _i e _i \right \|
\geq c \sqrt{\sum ^{d}_{i=1} \lambda ^2 _i} 
$$ holds for any real numbers $\lambda _1 , \lambda _2 ,\ldots ,\lambda _d$ .
As far as I see the proof, constant $c> 0$ possibly depends on the choice of basis
and it is difficult to deduce explicit formula of $c $ . However, in J. Lindenstrauss, Bull. Amer. Math. Soc. 72 (1966), 967–970,
the following fact is used:
there exist a basis $e ' _1 , e '_2 , \ldots , e '_ d$ such that $\| e '_i \| =1 $ and $$
\left \| \sum ^{d}_{i=1} \lambda _i e' _i \right \|
\geq \frac{ \sqrt{\sum ^{d}_{i=1} \lambda ^2 _i} }{d^2}
$$ holds for any $\lambda _1 , \lambda _2 ,\ldots ,\lambda _d$ .
This mean that we can choose a suitable normal basis
so that we can take $c = 1 / d ^2 $ above. Do you know how to prove it or construct such a basis
that $c$ only depends on the dimension $d$ (not necessarily $c =1 / d^ 2 $ )?","['banach-spaces', 'normed-spaces', 'functional-analysis']"
3517058,Finding the limit of the given series,"What is the best way to find the following limit: $$\lim_{n \to \infty} \frac{((n+1)(n+2)\cdots(n+n))^{\frac1n}}{n} $$ And what is the final value? I tried finding patterns of $\frac i n$ in the limit, but haven’t reached any conclusion.","['definite-integrals', 'analysis', 'sequences-and-series', 'limits', 'exponential-function']"
3517077,The equation $a^{4n}+b^{4n}+c^{4n}=2d^2$,"Recently, I found that if $a+b=c$ , then $a^4+b^4+c^4=2d^2$ for some positive integer $d$ . The parametric equation is: $$m^4+n^4+(m+n)^4=2(m^2+mn+n^2)^2$$ The condition $a+b=c$ (assuming $c \geqslant a,b$ ) isn't necessary. For example: $$7^4+7^4+12^4=2 \cdot 113^2$$ We can note that when we make the equation in the form $a^{4n}+b^{4n}+c^{4n}=2d^2$ , and we impose the condition $a^n+b^n=c^n$ for the parametric solution: (i) When $n=1$ , we can have any positive integers $a+b=c$ (ii) When $n=2$ , we can have any Pythagorean Triple $(a,b,c)$ . (iii) When $n>2$ , there are no solutions by Fermat's Last Theorem. Checking when $n=2$ , I saw that there are no solutions for $a \leqslant b \leqslant c \leqslant 3000$ where $a^2+b^2 \neq c^2$ . I have not run a program for any value $n>2$ though. For positive integers $a \leqslant b \leqslant c$ where $\gcd(a,b,c)=1$ : $1$ . Are there any solutions for $a^8+b^8+c^8=2d^2$ where $a^2+b^2
 \neq  c^2$ ? $2$ . Are there any solutions for $a^{4n}+b^{4n}+c^{4n}=2d^2$ where $n>2$ ? $3$ . For the solutions of $a^4+b^4+c^4=2d^2$ which do not follow $a+b=c$ , is there any way of generating more solutions from primitive
  solutions? From primitive solution $(a,b,c,d)$ , can we get more
  solutions $(A,B,C,D)$ ? EDIT : First off, it suffices to focus on solutions for $a^{4n}+b^{4n}+c^{4n}=2d^2$ for prime $n$ alone, since if we have a solution for some $n$ , then we have a solution for the divisors of $n$ as well. An accepted answer would be one of: $(i)$ Verifying problem $1$ for $a \leqslant b \leqslant c \leqslant
 1000000$ . $(ii)$ Verifying problem $2$ for $a \leqslant b \leqslant c \leqslant
 100000$ (for odd primes $n<100$ ). $(iii)$ Verifying problem $1$ for $a \leqslant b \leqslant c \leqslant
 100000$ and problem $2$ for $a \leqslant b \leqslant c \leqslant
 10000$ (for odd primes $n<100$ ). $(iv)$ Proof or Counterexample for either problems $1$ or $2$ . $(v)$ Relations, generation or parametric characterization of the
  non-trivial solutions of $$a^4+b^4+c^4=2d^2$$","['number-theory', 'diophantine-equations']"
3517082,On the relation between the closure of the range of $A$ and the closure of the range of $\overline A$,"Let $A:D(A)\subseteq H\to H$ be a densely defined, closable linear operator on the Hilbert space, $H$ . We denote it's closure by $\overline A$ . Suppose that $D(A)$ is also a core for $\overline A$ . Let $B:D(B)\subseteq H\to H$ , a closed, potentially unbounded linear operator We denote by $R(\cdot)$ and $N(\cdot)$ the range and kernel, respectively. Suppose that $R(A)\subseteq N(B)$ . Then, $\overline{R(A)}\subseteq N(B)$ , since the kernel of a closed linear operator is closed. My problem : How exactly is it that one deduces $$\overline{R(A)}\subseteq N(B)\implies\overline{R(\color{red}{\overline A})}\subseteq N(B)$$ from the fact that $D(A)$ is a core for $\overline A$ ? In addition, it seems me that we actually have the equality $\overline{R(A)}=\overline{R(\overline A)}$ . I know that I should use that $D(A)$ is a core for $\overline A$ in order to pass from the range of $A$ to the range of $\overline A$ , but I'm not sure on how it actually works.","['operator-theory', 'analysis', 'hilbert-spaces', 'functions', 'functional-analysis']"
3517188,Convergence of $A_n^{'}A_n$ to $I_k$ in probability implies $A^{-1}_n$ bounded in probability.,"Let $(A_n)$ be a sequence of random $k\times k$ matrices and suppose $A_n^{'}A_n \overset{p}{\to} I_k$ . Then $(i)$ $A_n$ is invertible with probability approaching $1$ $(ii)$ $A_n=O_p(1)$ $(iii)$ $A^{-1}_n=O_p(1)$ I was able to prove $(i)$ using continuity of the determinant, but am having trouble with $(ii)$ and $(iii)$ . I know that for an orthogonal $k\times k$ matrix $A$ we have $\sqrt{k}=\left\lVert I_k \right\rVert = \left\lVert A^{'}A\right\rVert =  \left\lVert A\right\rVert^2 $ (Frobenius norm) but am not sure how to use it. Any help is greatly appreciated. Edit $1$ : I think I might also need the Neumann series representation $\big(I_k-A_n^{'}A_n\big)^{-1}=\sum_{s=0}^{\infty}(A_n^{'}A_n)^{s}$ , provided one show convergence of the series. Edit 2: Here is an attempt. I will use the following inequalities for the Frobenius norm: $$\sigma_{min}(A_n)\left\lVert A_n\right\rVert \leq \left\lVert A_n^{'}A_n\right\rVert \leq \sigma_{max}(A_n)\left\lVert A_n\right\rVert $$ or $$\sqrt{\lambda_{min}(A_n^{'}A_n)}\left\lVert A_n\right\rVert \leq \left\lVert A_n^{'}A_n\right\rVert \leq \sqrt{\lambda_{max}(A_n^{'}A_n)}\left\lVert A_n\right\rVert $$ where $\sigma,\lambda$ denotes singular values and eigenvalues respectively. Now, since eigenvalues are continuous functions on the space of all square matrices and the square root function is continuous, I can invoke the continuous mapping theorem and deduce $$\sqrt{\lambda_{min}(A_n^{'}A_n)}\overset{p}{\to}\sqrt{\lambda_{min}(I_k)}=1$$ $$\sqrt{\lambda_{max}(A_n^{'}A_n)}\overset{p}{\to}\sqrt{\lambda_{max}(I_k)}=1$$ Similarly, the Frobenius norm is a continuous function on the space of all matrices so we have $$\left\lVert A_n^{'}A_n\right\rVert \overset{p}{\to} \left\lVert I_k\right\rVert=\sqrt{k}$$ Rearranging the previous inequality we get $$\frac{\left\lVert A_n^{'}A_n\right\rVert }{\sqrt{\lambda_{min}(A_n^{'}A_n)}} \leq \left\lVert A_n\right\rVert \leq \frac{\left\lVert A_n^{'}A_n\right\rVert }{\sqrt{\lambda_{max}(A_n^{'}A_n)}} $$ with division justified by the fact that $\sqrt{\lambda_{min}(A_n^{'}A_n)}>0$ and $\sqrt{\lambda_{max}(A_n^{'}A_n)}>0$ with probability approaching one. By the previous arguments, both the left and right side converge in probability to $\sqrt{k}$ , which implies that $\left\lVert A_n\right\rVert\overset{p}{\to}\sqrt{k}$ . Since convergence in probability implies boundedness in probability, we have shown $(ii)$ . Finally, for $(iii)$ I can use $(i)$ and the fact that the inverse is a continuous function on the space of invertible matrices to deduce $(A_n^{-1})(A_n^{-1})^{'}\overset{p}{\to}I_k$ . I can then apply the same argument as in $(ii)$ to conclude that $A_n^{-1}$ is bounded in probability. Is this proof correct?","['asymptotics', 'orthogonal-matrices', 'random-matrices', 'convergence-divergence', 'probability-theory']"
3517296,A problem involving injective and surjective functions,"Let $f,g:\mathbb{N}\to\mathbb{N}$ be functions such that $f$ is onto and g is one-one. If $f(n)\ge g(n)$ for all $n\in\mathbb{N}$ , show that $f=g$ .",['functions']
3517309,Stokes’s theorem and compact 2-manifolds in $\mathbb{R}^2$,"I am trying to solve the following problem of Andrew Browder: ""Mathematical Analysis; An Introduction"" (Springer Undergraduate Texts in Mathematics): Find THE compact $2$ -manifold $M$ in $\mathbb{R}^2$ with area $\pi$ for which $$
\int_{\partial M} {y^3dx + (3x - x^3)dy}
$$ is maximal. The definition of Manifold in the book is: Definition I have tried to use the Stokes’s theorem but I don't know how to find a such manifold $M$ . Thanks in advance.","['integration', 'manifolds-with-boundary', 'stokes-theorem', 'differential-geometry']"
3517337,Upper Bound on Ramsey $R(k)$,"If $R(k)$ is the minimum number of vertices that ensures a monochromatic $k$ clique in an arbitrary edge 2 coloring of $K_{R(k)}$ (Complete Graph), I read a proof that establishes an upper bound of $2^{2k}$ on $R(k)$ in a very elegant manner which is as follows - Consider a vertex $x_1$ , given a $2$ -coloring of $K_{2^{2k}}$ . A set $A_1$ of at least $2^{2k-1}$ vertices is such that every edge from $x_1$ to $A_1$ is of the same color. Now consider a vertex $x_2$ inside $A_1$ . We can find a set of $2^{2k-2}$ vertices $A_2$ , contained inside $A_1$ such that every edge from $x_2$ to $A_2$ is of the same color. Continuing like this, we get $\{x_1, x_2, \cdots ,x_{2k}\}$ and $\{A_1, A_2,\cdots,A_{2k}\}$ such that $A_i$ contains $x_{i+1}, x_{i+2}, \cdots$ and all edges from $x_i$ to $A_i,A_{i+1},A_{i+2},\cdots,A_{2k}$ are of the same color. Therefore color of edge $\{x_i,x_j\}$ only depends on $\min\{i,j\}$ . Therefore, by pigeonhole we can find a set of $k$ vertices among $\{x_1, x_2, \cdots ,x_{2k}\}$ that have same color edges among one another and hence form a monochromatic clique. How does one extend this argument to get a upper bound of $R(k)<$$ {2k}\choose{k}$ ?","['combinatorics', 'ramsey-theory']"
3517369,A Game in Probability,You and n other players ( $n \ge 1$ ) play a game. Each player chooses a real number between 0 and 1. A referee also chooses a number between 0 and 1. The player who chooses the closest number to the referee's number wins. What should be your choice. Will it depend on $n$ ? Assume that the n players (other than yourself) and the referee choose the numbers uniformly between 0 and 1. Can someone give a sketch of the solution? I've been trying this but unable to produce an answer. Edit:You may ignore two or more players choosing the same number,"['game-theory', 'probability']"
