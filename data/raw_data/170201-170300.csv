question_id,title,body,tags
3003012,Ideal in polynomial ring extension [duplicate],"This question already has answers here : $Q\mid P\ {\rm in}\ \Bbb R[X]\,$ if $\,Q\mid P\ {\rm in}\ \Bbb C[X]\ $ [divisibility stable under polynomial coef. ring extension] (4 answers) Closed 5 years ago . Let $K \subset L$ be a field extension, $K[X]$ and $L[X]$ the corresponding polynomial rings (in one variable) and $I \subset K[X]$ an ideal. I want to show that $I=K[X] \cap IL[X]$ , where $IL[X]$ denotes the ideal generated by $I$ in $L[X]$ . I was told that while there are many ways to show this abstractly, there is supposed to be a very simple proof only  involving Linear Algebra. I don't really know where to start here. The inclusion from left to right is trivial, but I haven't got much more. Any help - even just a hint - would be appreciated.","['algebraic-geometry', 'abstract-algebra', 'linear-algebra', 'ideals']"
3003034,What is the cardinality of a lone element?,"I know that elements which are not sets do not have cardinality, but hear me out. Suppose that $A=\{u,\{\{v,w\},x,\{y,\{z\}\}\}\}$ . The nesting of the sets allows you to uniquely identify particular elements by there ""depth"" in $A$ . For example $z$ is the only element $e\in^4A$ ( $\in^4$ is an abuse of notation meant to suggest that $e$ is an element of an element of an element of an element of $A$ ). However, this type of statement is not sufficient for uniquely identifying any element other than $z$ , as, for example, the set of all $e\in^2 A$ contains $\{v,w\}$ , $x$ , and $\{y,\{z\}\}$ . It is still possible to distinguish between each of these elements, though; $e\in^2A\ and\ |e|\neq2$ defines $x$ , $e\in^2A\ and\ \nexists\ b\in e:|b|=1$ defines $\{u,w\}$ , and $e\in^2A\ and\ \exists\ b\in e:|b|=1$ defines $\{y,\{z\}\}$ . The statement used to identify $x$ is true because $x\in^2A$ and $|x|\neq2$ , the latter because $x$ is not a set, and therefore cannot have a cardinality of 2. Similarly, $\{y,\{z\}\}\in^2A$ , and $|\{z\}|=1$ . Now, since I've used cardinality to differentiate the elements $e\in^2A$ from one another, I should like to define the cardinality of each such element. While this is no problem for the sets $\{u,v\}$ , $\{y,\{z\}\}$ , and the singleton set $\{z\}\in^3A$ , it is an issue for the elements $x$ and $y$ . The statement $|x|\neq1$ , while true, cannot be evaluated if $x$ does not have cardinality. Since $\{x\}\neq x$ , the cardinality of $x$ cannot be 1. One possibility is that the cardinality of $x$ is 0, but this runs the risk of equating the element $x$ with the empty set, which would violate the axioms of ZFC if $x$ is considered to be a set. On the other hand, you could say that the empty set is the only set whose cardinality is zero, and that $x$ is not a set: thus, $|x|=0\not\implies x=\emptyset$ . But this runs into the problem of defining what a set is . So, what is the best way to define the cardinality of an element? If there isn't one, then is there a good way to describe how a lone element is unlike a set, in set theoretic terms?","['elementary-set-theory', 'definition']"
3003066,Is this function of bounded variation?,"Consider Riemann's function defined on $\mathbb{R}$ , $$ R(x) = \sum_{n=1}^\infty \frac{\sin n^2 x}{n^2} . $$ If you graph it, you can see that it shows a lot of zigzags. Hence, the question is, is this function of bounded variation in $(0,2 \pi )$ ?","['fourier-series', 'fourier-analysis', 'analysis', 'real-analysis']"
3003076,Applying the Pigeonhole Principle to a Set of Subsets,"Let $A$ be a set of six positive integers each of which is less
  than $15$ . Show that there must be two distinct subsets of $A$ whose elements when added up give the same sum. This is what I've tried so far. There are $2 ^ 6 = 64$ subsets of $A$ . We can also calculate the largest possible sum of a subset to be $14+13+12+11+10+9 = 69$ . The smallest possible sum for a subset is $0$ . Thus, there are $70$ possible sums, but only $63$ possible subsets $($ assuming we exclude the empty set $)$ . Is there something I am missing so that I can apply the pigeonhole principle?","['pigeonhole-principle', 'discrete-mathematics', 'probability']"
3003077,Prove order of a group is even,"I am trying to solve this question and wanted to know whether my proof was correct. Suppose that $n \geq 3$ , $n$ is odd, $G$ is a non-trivial group and $\varphi : D_{2n} \rightarrow G$ is a surjective homomorphism. (a) Prove that $|G|$ is even.
(b) Prove that every proper normal subgroup of $G$ has odd order. My attempt for a : Since $G$ is not trivial and is equal to $\varphi(D_{2n})$ , then either $\varphi(s) \not = 1$ or $\varphi(r) \not = 1$ . If $\varphi(s) \not = 1$ , then we have $\varphi(s)^2 = 1$ and we have found an element of order 2 in $G$ so it must be even. If $\varphi(r) \not = 1, \varphi(s) = 1$ , then we have that $\varphi(sr) = \varphi(r^{-1}s) \Rightarrow \varphi(s)\varphi(r) = \varphi(r)^{-1}\varphi(s) \Rightarrow \varphi(r) = \varphi(r)^{-1} \Rightarrow \varphi(r)^2 = 1$ and since $\varphi(r) \not = 1$ , we have again found an element of order 2 in $G$ . My attempt for b : I'm not sure about this one, but I first note that by the first isomorphism theorem, $G \cong D_{2n}/\ker(\varphi)$ . Any proper normal subgroup of $G$ now has to be isomorphic to one of $D_{2n}/\ker(\varphi)$ . Then, by the fourth isomorphism theorem, it has to be isomorphic to a normal subgroup of $D_{2n}$ . Now I don't know how to proceed.","['group-theory', 'abstract-algebra', 'finite-groups', 'dihedral-groups']"
3003085,Three lines moving at same velocity form a triangle. What is the formula for their lengths at time t?,"Three infinite lines on a plane forming a triangle where they cross. The lines are travelling perpendicular to their length at a constant speed $v=1$ such as the triangle is getting smaller. The lengths of the sides of the triangle at time $t=0$ are $(x_0,y_0,z_0)$ . Find the lengths of the sides of $t$ . This is a question I invented while thinking about physics. Extra marks for an intuitive solution without using vectors. Considering the space-time diagram at some time $t$ all three lines will meet a point forming a triangular pyramid in space-time. Maybe this gives a clue to solving it.","['geometry', 'dynamical-systems']"
3003102,Zeros of partial sums of the exponential [duplicate],"This question already has answers here : Complex zeros of the polynomials $\sum_{k=0}^{n} z^k/k!$, inside balls (3 answers) How prove this $|z|>1$ with $1+z+\frac{z^2}{2!}+\cdots+\frac{z^n}{n!}=0$ (1 answer) Closed 5 years ago . I am trying to show that if $$f_n(z)=1+z+\frac{z^2}{2!}+...+\frac{z^n}{n!}$$ Then $f_n(z)$ don’t have zeros inside the unitary disk. 
I have tryied to use Rouche’s theorem or use that in the limit the polinomial converges to the exponential, but i dont get hoy to do this.","['complex-analysis', 'power-series', 'taylor-expansion']"
3003117,Information theory - Intuition of channel capacity,"Question As stated in Elements of Information theory , given $p(y|x)$ , the Information channel capacity formula is $C = \max_{p(x)} I(X; Y)$ where $X, Y$ are input and output symbols, $p(x)$ is the p.m.f of the distribution of $X$ Can anyone tell me the intuition of this formula ? My understanding $C = \max_{p(x)} I(X; Y) = \max_{p(x)} [H(X) - H(X|Y)]$ $H(X)$ can be understood as the expected amount of unknown information (measured in bits) of $X$ . $H(X|Y)$ is the expected the expected amount of remaining unknown information (measured in bits) of $X$ given $Y$ is known. Thus, $I(X; Y)$ is the expected amount of known information (measured in bits) about $X$ given by $Y$ . Thus, $C =\max_{p(x)} I(X; Y)$ gives the maximum number of bits in $X$ , which can be exactly given by $Y$ . There are two problems with my understanding: According to my understanding, for any input symbol $X$ , there are only $I(X; Y)$ bits can be transmitted without error (i.e. no matter whether $H(X)$ exceeds the channel capacity $C$ or not) In Elements of Information theory , $C$ is usually written as $C = \max_{p(x)}[H(Y) - H(Y|X)]$ , instead of $\max_{p(X)}[H(X) - H(X|Y)]$ (i.e. my formula). I think $H(Y) - H(Y|X)$ says something about the right intuition of the formula $C = \max_{p(x)} I(X; Y)$ .","['statistics', 'entropy', 'probability', 'information-theory']"
3003135,"How to prove Penrose ""Bianchi symmetry"" with non-zero torsion tensor using abstract indexing?","I want to prove $R_{[αβγ]}^{\ \ \ \ \ \ \ δ} + ∇_{[α}T_{βγ]}^{\ \ \ \ δ} + T_{[αβ}^{\ \ \ \ ρ}\ T_{γ]ρ}^{\ \ \ \ δ} = 0$ EDIT: A brief discussion of the solution found by Matt is at the bottom of this post. The equation is called the ""Bianchi symmetry"" in Vol. 1 of ""Spinors and space-time"" by Penrose and Rindler, and is given there in equation (4.2.39) (with index $σ$ in place of the $δ$ here).  The definitions of $T$ , $R$ and all other symbols are taken from that same text, e.g: $T_{αβ}^{\ \ \ \ γ}$ = Torsion tensor, satisfying $T_{αβ}^{\ \ \ \ γ} \ ∇_γf =  ∇_α∇_βf - ∇_β∇_αf$ , for scalars $f$ $R_{αβγ}^{\ \ \ \ \ \ \ δ}$ = Curvature tensor, satisfying $∇_α∇_βV^δ - ∇_β∇_αV^δ - T_{αβ}^{\ \ \ \ γ}\ ∇_γV^δ = R_{αβγ}^{\ \ \ \ \ \ \ δ}\ V^γ$ , for vectors $V^γ$ , and for covariant vectors, $V_δ$ : $\ \ \ \ \ \ \ \ \ \ \ \ \ ∇_α∇_βV_γ - ∇_β∇_αV_γ - T_{αβ}^{\ \ \ \ ρ}\ ∇_ρV_γ = -R_{αβγ}^{\ \ \ \ \ \ \ δ}\ V_δ$ I am trying to use the manner suggested in the text that is ""along the same lines"" as , but ""more elaborate"" than how the torsion-free version (4.2.37) is derived there, but also without using (4.2.52).  The approach I have taken looks like this: The first two (identical) equations below are shown as merely modest reformulations of others published (for other purposes) in the book as indicated (noting the fairly obvious book-typo in the first), so I am virtually certain the setup preceding the third equation here is correct. What then follows are just some fairly straightforward transformations, so I am suspecting the tensor $T_{[αβ}^{\ \ \ \ δ}\  ∇_{γ]}∇_δf$ highlighted at the end must be zero, but am unable to show why, perhaps because it isn't. ( edit: In fact it isn't.  See end of question.) As in (4.2.40), but with f in place of $V^δ$ (not the $V^γ$ -typo appearing in my edition): $2∇_{[[α}∇_{β]}∇_{γ]} f = T_{[αβ}^{\ \ \ \ ρ}∇_{|ρ|}∇_{γ]}f − R_{[αβγ]}^{\ \ \ \ \ \ \ δ}\ ∇_δf$ . Equivalently, as in (4.2.35), but symmetrized in α, β, and γ and including T: $−R_{[αβγ]}^{\ \ \ \ \ \ \ δ}∇_δ f = 2∇_{[[α}∇_{β]}∇_{γ]}f − T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}f$ $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = 2∇_{[α}∇_{[β}∇_{γ]]}f − T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}f$ $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = ∇_{[α}Δ_{βγ]}f − T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}f\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $ (with $Δ_{βγ} := 2∇_{[β}∇_{γ]}$ ) $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = ∇_{[α}T_{βγ]}^{\ \ \ \ δ}\ ∇_δf − T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}f\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $ (4.2.22 applied to first term above) $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = ∇_{[α}T_{βγ]}^{\ \ \ \ ρ}\ ∇_δf + T_{[αβ}^{\ \ \ \ ρ}\ T_{γ]ρ}^{\ \ \ \ δ}\ ∇_δf − T_{[αβ}^{\ \ \ \ ρ}∇_{γ]} ∇_ρf\ \ $ (4.2.22 applied to last term above) $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = ∇_{[α}T_{βγ]}^{\ \ \ \ δ}\ ∇_δf + T_{[αβ}^{\ \ \ \ ρ}\ T_{γ]ρ}^{\ \ \ \ δ}\ ∇_δf − T_{[αβ}^{\ \ \ \ δ}∇_{γ]}∇_δf$ Comparing to (4.2.39), $T_{[αβ}^{\ \ \ \ δ}\  ∇_{γ]}∇_δf$ must be zero.  ( edit: Not so.  See discussion at end of question below.) Hints about either why this might be true, or if not where I have been misled along the way will be greatly appreciated!  ( edit: See below for why not.) P.S.:  This book is a fabulous way for getting familiar with tensor indexing.  I'm almost half way through reading it, and up until this point have figured out pretty much every single formula, minor aside and fottnote on my own (except for the curious bits on ""irreducibility"" at the end of 3.3) and savored every minute of it. P.P.S.:  This is my first post to the forum, and am very impressed by how easy it was to figure out everything I needed, especially using MathJax, a non-trivial bit of software that actually is implemented in an extremely self-explanatory way, unlike so much else that claims to be, but hardly ever is.  I also find all the suggestions for making effective posts very sensible and helpful, something else that is very rare.  I hope they are adequately reflected in this post! Making this post has been truly a lot of fun, and I look forward to much more. Cheers! EDIT: Discussion of Solution due to Matt As he points out, the Leibnitz expansion applied to the first term in the last line of my derivation cancels the last term on that line.  The reason I missed this was failing to use parentheses in the relevant expression: $\ ∇_{[α}(T_{βγ]}^{\ \ \ \ δ}\ ∇_δf) = (∇_{[α}T_{βγ]}^{\ \ \ \ δ})\ ∇_δf + T_{[αβ}^{\ \ \ \ δ}(\  ∇_{γ]}∇_δf)$ Penrose's abstract indexing is commutative and associative for the tensor objects themselves, which is one its greatest advantages.  His covariant operators $∇_δ$ on the other hand are neither commutative (as he makes very clear) nor associative when followed by two or more tensors.  While the latter is not specifically mentioned in the text, it becomes obvious with a small amount of thought, with this non-trivial example serving as a perfect illustration. From this momentary stumbling block and the resulting great discussion and help on MSE, I have learned much.  So now, because it is so much fun, I will show how to derive what Penrose calls the ""Bianchi identity"" that is actually a simpler formula than the ""Bianchi symmetry"", though more complicated to derive (it actually depends on the ""symmetry"" formula): Derivation of ""Bianchi identity"" This is equation (4.2.43) (as well as Fig. A-9) in Vol. 1 of ""Spinors and space-time"" by Penrose and Rindler, and uses the notation and other concepts and references from that text: $2∇_{[[α}∇_{β]}∇_{γ]}V^δ = T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}V^δ + R_{[αβ|ρ|}^{\ \ \ \ \ \ \ \ \ δ}\ ∇_{γ]}V^ρ - R_{[αβγ]}^{\ \ \ \ \ \ \ \ ρ}\ ∇_ρV^δ\ \ \ \ \ \ \ $ (4.2.40) (LHS expanded using ""generalized Ricci identity"" as defined by Penrose) $2∇_{[α}∇_{[β}∇_{γ]]}V^δ = ∇_{[α}(T_{βγ]}^{\ \ \ \ ρ}\ ∇_{ρ}V^δ) + R_{[αβ|ρ|}^{\ \ \ \ \ \ \ \ \ δ}\ ∇_{γ]}V^ρ + V^ρ∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ}\ \ \ \ \ \ $ (4.2.41) (LHS expanded using definition of $R$ and Leibnitz law) Subtracting the first from the second gives (since LHSs are equal): $0 = V^ρ∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ} - T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}V^δ$ $\ \ \ \ \ + ∇_{[α}(T_{βγ]}^{\ \ \ \ ρ}\ ∇_{ρ}V^δ) + R_{[αβγ]}^{\ \ \ \ \ \ \ \ ρ}\ ∇_ρV^δ$ $\ \ = V^ρ∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ} - T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}V^δ$ $\ \ \ \ \ + (∇_{[α}\ ∇_{|ρ|}V^δ)T_{βγ]}^{\ \ \ \ ρ} + (∇_{[α}T_{βγ]}^{\ \ \ \ ρ})\ ∇_ρV^δ + R_{[αβγ]}^{\ \ \ \ \ \ \ \ ρ}\ ∇_ρV^δ$ $\ \ \ \ \ \ \ $ (using Leibnitz law) $\ \ = V^ρ∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ} - T_{[αβ}^{\ \ \ \ ρ}\ ∇_{|ρ|}∇_{γ]}V^δ + T_{[αβ}^{\ \ \ \ ρ}\ ∇_{γ]}\ ∇_ρV^δ$ $\ \ \ \ \ - T_{[αβ}^{\ \ \ \ ρ}\ T_{γ]ρ}^{\ \ \ \ σ}\ ∇_σV^δ - R_{[αβγ]}^{\ \ \ \ \ \ \ \ ρ}\ ∇_ρV^δ + R_{[αβγ]}^{\ \ \ \ \ \ \ \ ρ}\ ∇_ρV^δ$ $\ \ \ \ \ \ \ $ (using Bianchi symmetry) $\ \ = V^ρ∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ} + T_{[αβ}^{\ \ \ \ ρ}\ R_{γ]ρσ}^{\ \ \ \ \ \ \ δ}\ V^σ$ $\ \ \ \ \ \ \ $ (using Ricci identity) $\ \ =\ (∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ}\ )V^ρ + T_{[αβ}^{\ \ \ \ σ}\ R_{γ]σρ}^{\ \ \ \ \ \ \ δ}\ V^ρ$ So we have arrived at the two Penrose formulas for Bianchi symmetry: $\ \ -R_{[αβγ]}^{\ \ \ \ \ \ \ δ} = ∇_{[α}T_{βγ]}^{\ \ \ \ δ} + T_{[αβ}^{\ \ \ \ ρ}\ T_{γ]ρ}^{\ \ \ \ δ}$ Bianchi identity: $\ -∇_{[α}R_{βγ]ρ}^{\ \ \ \ \ \ \ δ} = T_{[αβ}^{\ \ \ \ σ}\ R_{γ]σρ}^{\ \ \ \ \ \ \ δ}$","['tensors', 'general-relativity', 'index-notation', 'differential-geometry']"
3003184,What am I doing wrong finding $\lim_{x\to 0} \left( \frac{1+x\cdot2^x}{1+x\cdot3^x} \right)^{1/x^2}$?,"It has an answer here , but I'd like to know where my solution went wrong. $$\lim_{x\to 0} \left( \frac{1+x\cdot2^x}{1+x\cdot3^x} \right)^{\frac{1}{x^2}} $$ $$\lim_{x\to 0} \left( \frac{1+x\cdot2^x +x\cdot 3^x-x\cdot 3^x}{1+x\cdot3^x} \right)^\frac{1}{x^2} $$ $$\lim_{x\to 0} \left( 1 + \frac{x\cdot2^x-x\cdot 3^x}{1+x\cdot3^x} \right)^\frac{1}{x^2} $$ $$\lim_{x\to 0} \left( 1 + \frac{x\cdot2^x-x\cdot 3^x}{1+x\cdot3^x} \right)^{\frac{1}{x^2}\cdot \frac{1+x\cdot 3^x}{x\cdot2^x-x\cdot 3^x}\cdot\frac{x\cdot2^x-x\cdot 3^x}{1+x\cdot3^x}} $$ $$\lim_{x\to 0}  e^{\frac{1}{x^2}\cdot \frac{x\cdot2^x-x\cdot 3^x}{1+x\cdot3^x}} $$ $$\lim_{x\to 0}  e^{\frac{1}{x}\cdot \frac{2^x-3^x}{1+x\cdot3^x}} $$ $$\lim_{x\to 0}  e^{\frac{1}{x}\cdot \frac{(1+1)^x-(2+1)^x}{1+x\cdot3^x}} $$ $$\lim_{x\to 0}  e^{\frac{1}{x}\cdot \frac{1+x+o(x)-1-x2-o(x)}{1+x\cdot3^x}} $$ $$\lim_{x\to 0}  e^{\frac{-1}{1+x\cdot3^x}} $$ $$e^{-1}$$ The answer in the book is $\frac{2}{3}$ .","['limits', 'calculus', 'limits-without-lhopital']"
3003208,Prove that $\frac{1}{\sin\frac{\pi}{15}}+\frac{1}{\sin\frac{2\pi}{15}}-\frac{1}{\sin\frac{4\pi}{15}}+\frac{1}{\sin\frac{8\pi}{15}}=4\sqrt{3}$,I'm trying to calculate the expression: $$\frac{1}{\sin\frac{\pi}{15}}+\frac{1}{\sin\frac{2\pi}{15}}-\frac{1}{\sin\frac{4\pi}{15}}+\frac{1}{\sin\frac{8\pi}{15}}$$ and show that it is equal $4\sqrt{3}$ . I was trying to group the summands and calculate sums of $$\frac{1}{\sin\frac{\pi}{15}}+\frac{1}{\sin\frac{2\pi}{15}} \hspace{0.5cm}\text{and} \hspace{0.5cm} -\frac{1}{\sin\frac{4\pi}{15}}+\frac{1}{\sin\frac{8\pi}{15}}$$ where we get $$\frac{2\cos\frac{2\pi}{15}+1}{\sin\frac{2\pi}{15}}-\frac{2\cos\frac{4\pi}{15}-1}{\sin\frac{8\pi}{15}}$$ but unfortunately this sum is not simplified. How to prove this equality?,"['trigonometric-series', 'trigonometry']"
3003253,Sum-to-zero constraints in a two-way ANOVA model,"I'm reviewing my lecture notes on sum-to-zero constraints and I am having a tough time understanding the concept. Say the constraints are $\sum_{i=1}^{a} \alpha_i = 0$ , $\sum_{j=1}^{b} \beta_j = 0$ , $\sum_{i=1}^{a} (\alpha \beta)_{ij} = 0$ for $j = 1,...,b$ and $\sum_{j=1}^{b} (\alpha \beta)_{ij} = 0$ for $i = 1,...,a$ . Here are the following questions I have: 1) Why does this represent $a + b + 1$ independent constraints and not $a + b + 2$ independent constraints? 2) How do I determine that there are $a-1$ linearly independent $\alpha_i$ 's, $b-1$ linearly independent $\beta_j$ 's and $(a-1)(b-1)$ linearly independent $(\alpha \beta ) _{ij}$ 's? Thanks in advance.","['statistics', 'linear-algebra']"
3003352,Variation of Polya’s urn problem?,"I was asked this question at an interview and was stumped by it. The problem is as follows: Alice is playing an online game. She wins the first round and loses the second. The probability she then wins subsequent rounds is proportional to the number of wins. Calculate the probability that after 100 games, the number of wins and losses are equal. I am unsure of how to proceed. At the interview, I was originally thinking of using a simple sum of $$\sum_i \alpha w_i \delta_i,$$ where $\alpha$ is normalisation constant, $w_i$ is the number of wins at the $i$ th game and $\delta_i$ is either 0 or 1. However, I doubt this is a correct approach, and $w_i$ is dependent on the $\delta$ ’s for $j<i$ . I was discussing with a mathematician friend who said that this is a possible variation of Polya’s urn, but I can’t see the connection. Could anyone help me with this visualisation and provide hints on how to move forward? Thank you!","['polya-urn-model', 'statistics', 'game-theory', 'probability-theory', 'probability']"
3003362,Proving that a bijection exists,"Let $f$ be a bijective function from $A$ to $B$ . Let $x \in A$ and $y \in B$ . Prove that there exists a bijection $g$ defined from $A$ to $B$ such that $g(x)=y$ . Here is my solution but i don't know if it is correct.
Assume that $f(x) \neq y$ , because if they were equal taking $g$ the same bijection as $f$ would work. Since $f$ is a bijection  we have $|A|=|B|$ and there exists $x_1 \in A$ and $y_1 \in B $ such that $f(x_1)=y$ and $f(x)=y_1$ Now taking $g(a)=f(a)$ if $a \neq x_1$ or $ x$ ,   and $g(x)=y $ and $g(x_1)=y_1$ completes the proof.","['functions', 'discrete-mathematics', 'analysis']"
3003386,What is the intuition behind the method of undetermined coefficients?,"Our teacher has recently begun teaching second-order differential equations and the methods used for solving them. The method which we are taught to solve linear differential equations is currently the method of undetermined coefficients. I would like to know if there is a reason as to why the method works. My chief question is about why we're able to just ""step-up"" our guesses by an x term (i.e. if $$e^{ax}$$ does not work we're simply able to amend our guess to $$xe^{ax}$$ Secondly, why is it that when doing so the terms in between seem to nicely cancel out? An example is the differential equation in one of our tutorials $$\frac{d^2y}{dx^2}-6\frac{dy}{dx}+9y=e^{3x}$$ As the solution to the characteristic polynomial has repeated roots 3, I understand why guesses of the form $$Ae^3x$$ $$Axe^3x$$ fail to work (because they get ""absorbed"" into the general solution of the complementary solution) and as a result why my ""guess"" has to be $$Ax^2e^{3x}$$ but I do not understand why when plugging in the solved integrals that somehow I get this mess of an equation $$A(9x^2e^{3x}+12xe^{3x}+2e^{3x}-18x^2e^{3x}-12xe^{3x}+9x^2e^{3x})=e^{3x}$$ that somehow resolves nicely to $$A(2e^{3x})=e^{3x}$$ Thank you for taking the time to read this.",['ordinary-differential-equations']
3003430,Why is the validity range for Maclaurin Series $\ln(1+x)$ : $-1\lt x\le 1$?,"I only seem to know that $\ln\;(0$ or any negative real  number)  doesnt exist hence $-1\lt x$ but what about $x \le1$ ? Has this got to do with the convergence of the series? If so, why would convergence make it valid but for any $x$ more than $1$ would make it invalid ? Pardon if there's any mistakes in my understanding because this is relatively new topic for me.","['taylor-expansion', 'sequences-and-series']"
3003449,Trying to prove $e$'s irrationality,"Knowing that $\lim\limits_{x\to\ 0}\ $$\frac{\sin(x)}{x}$$= 1$ , $\frac{1}{n+1}<n!r_n<\frac{1}{n}$ , where $r_n=e- \sum _{ k=0 }^{ \ n}{ \frac { 1 }{k!}} $ By studying $\lim\limits_{n\to\infty}\ n\sin(2πn!r_n)$ I have to show that : $$\lim\limits_{n\to\infty}\ n\sin(2πn!e)= 2π,$$ and then prove that $e$ is irrational ?","['limits', 'irrational-numbers', 'exponential-function']"
3003482,I have 100 boxes. C of them have a gift. I can open up to 16 boxes. What is the number of C that will give me probability over 0.5 to find a gift?,"Details:
We start by opening a box. If nothing is in there, we open another one. Once we find a gift, we can stop. Each empty box that was opened is discarded (no revisit).
I can find the number of $C$ that will give probability over $0.5$ by writing a program to try for $C=1, C=2$ .. etc.. , but I can't solve the equation for $C$ to find a more ""mathematical"" and elegant answer. My work until now is: 1) Found in 1st box: $P(1) = \frac{C}{N}$ 2) Found in 2nd box: $P(2) = \frac{1-C}{N}\cdot\frac{C}{N-1}$ 4) Found in 3rd box: $P(3) = \frac{1-C}{N}\cdot\frac{1-C/}{N-1}\cdot\frac{C}{N-2}$ Etc... Adding them up makes things very complicated to solve for $C$ . Any ideas? Thank you in advance!","['probability-theory', 'probability']"
3003512,"Maximal ideal of $K[x_1,\cdots,x_n]$ such that the quotient field equals to $K$","I was wondering whether a maximal ideals of $K[x_1,\cdots,x_n]$ such that the quotient field equals to $K$ must be the form of $(x_1-a_1,\cdots,x_n-a_n)$ ? Here $K$ is not necessary to be algebraically closed. I tried to consider the Zariski's lemma, if $\mathfrak m$ is a maximal ideal  of finitely generated $K$ -algebra $A$ , then $A/\mathfrak m$ is a finite extension of $K$ . But I don't know the degree $[A/\mathfrak m:K]=1$ means what?","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3003578,"Proving that $d(x,\ker f) = \frac{|f(x)|}{\|f\|}$ if $f \in X^*$","Exercise : Let $(X,\|\cdot\|)$ be a normed space and $V\subseteq X$ . The distance of one point $x \in X$ to $V$ is defined by : $$d(x,V)=\inf\{\|x-v\|: v \in V\}$$ Show that if $f \in X^*=B(X,\mathbb R)$ which is the space of the bounded linear functionals, thefe for all $x \in X$ it is : $$d(x,\ker f)=\frac{|f(x)|}{\|f\|}$$ Attempt - thoughts : So, first of all, since $f$ is a bounded linear functional, then there exists some $M>0$ such that : $$\|f(x)\| \leq M\|x\|$$ Also, the operator norm is given by : $$\|f\| = \sup\bigg\{\frac{\|f(x)\|}{\|x\|} : x \in X, x \neq 0\bigg\}$$ Now, the kernel of the function $f$ is defined as : $$\ker f = \{x \in X : f(x) = 0\}$$ Essentialy, we need to calculate : $$d(x,\ker f) = \inf\{\|x-v\|:v \in \ker f\}$$ Now, of course, the kernel of $f$ is a subspace of $X$ and also, we know that : $$\text{co}\dim\{\ker f\} = 1$$ I can't see how to combine these facts yielded by the hypothesis of the exercise, though, to continue to an attempted solution. Any hints, tips or thorough elaborations will be greatly appreciated !","['operator-theory', 'functional-analysis', 'real-analysis']"
3003608,First de Rham Cohomology group of the 2-torus,"Show that for the de Rham cohomology, $H^{1}_{dR}({T^{2}})$ is isomorphic to $\mathbb{R}^{2}$ by showing that the following map: $[\alpha] \to (\int_{S^{1}}f^{*}_{1}\alpha,\int_{S^{1}}f^{*}_{1}\alpha)$ , where $f_{1}=(\theta,c_{1}), f_{2}=(c_{2},\theta)$ for $c_{1},c_{2}$ constants (seen as maps $S^{1} \to S^{1} \times S^{1}$ )  is an isomorphism. I have shown that the map is well-defined, linear and independent of the constants chosen. However, I'm having trouble with showing that it is surjective and injective. Surjectivity seems to be easy to show, but I'm not sure on how to go about it. For injectivity, it suffices to show that if the integrals are $0$ , then $\alpha$ is an exact form, yet I'm having troubles with it as well. What would be a good way to tackle this problem?","['differential-forms', 'smooth-manifolds', 'algebraic-topology', 'differential-geometry']"
3003649,Example of a Baire metric space which is not completely metrizable,"I know that some Baire metric spaces are not complete metric spaces but all examples, that I know, are completely metrizable. Help me to find an example of Baire metric space which is not completely metrizable. $[$ Please give some short proofs or references $]$","['general-topology', 'baire-category', 'metric-spaces']"
3003672,Convert infinite 2D plane integer coords to 1D number,"Say I have an infinte 2D grid (ex. a procedurally generated world) and I want to get a unique number for each integer coordinate pair. How would I accomplish this? My idea is to use a square spiral, but I cant find a way to make a formula for the unique number other than an algorythm that just goes in a square spiral and stops at the wanted coords. The application for this converstion could be for example a way to save an n dimensional shape to a file where each line represents a chunk of the shape (by using $u(x, y, z) = u(u(x, y), u(y, z))$ ), or have a very unique random seed for each integer point (ex. a way to hash an integer vector to a data point in an n dimensional array)",['geometry']
3003758,Proving trigonometric identities [duplicate],"This question already has answers here : Need help in proving that $\frac{\sin\theta - \cos\theta + 1}{\sin\theta + \cos\theta - 1} = \frac 1{\sec\theta - \tan\theta}$ [closed] (5 answers) Closed 5 years ago . I’ve had a bit of difficulty of this question:
(1+sinA+cosA)/(1-sinA+cosA)=(1+sinA)/cosA I tried to do:
(SinA)^2+(CosA)^2+sinA+cosA/(SinA)^2+(CosA)^2-sinA+cosA=(1+sinA)/cosA
But then I’m kind of lost. Any help will be appreciated! Additionally, I am not allowed to move one side to another (over the equal sign).",['trigonometry']
3003817,Are factors corresponding to a sub-$\sigma$-algebra unique?,"Let $X$ be a compact metric space and $\mathcal B$ be its Borel $\sigma$ -algebra.
Let $\mu$ be a Borel probability measure on $X$ and $T:X\to X$ me an invertible measure preserving transformation.
Let $U_T:L^2(X, \mu)\to L^2(X, \mu)$ be the associated Koopman operator.
Let $\mathcal A$ be the smallest sub- $\sigma$ -algebra on $X$ with respect to which all the eigenfunctions of $U_T$ are measurable.
Theorem 6.10 in Einsiedler and Ward's Ergodic Theory with a View Towards Number Theory [EW] states the following: Theorem. The factor of $(X, \mathcal B, \mu, T)$ corresponding to $\mathcal A$ is the largest factor of $(X, \mathcal B, \mu, T)$ which is isoomorphic to a rotation on some compact abelian group. I do not follow why are we allowed to use the definite article ""the"" when asking for a factor corresponding to the sub- $\sigma$ -algebra $\mathcal A$ . I ask this question because the following theorem [EW, Theorem 6.5] only guarantees 'a' factor. Theorem. Let $(X, \mathcal B, \mu, T)$ be a measure preserving system, where $X$ is a compact metric space and $\mathcal B$ is its Borel $\sigma$ -algebra.
  Let $\mathcal A$ be a $T$ -invariant sub- $\sigma$ -algebra on $\mathcal B$ .
  Then there is a measure preserving system $(Y, \mathcal B_Y, \nu, S)$ , where $Y$ is a compact metric space with Borel $\sigma$ -algebra $\mathcal B_Y$ , and a factor map $\phi:X\to Y$ with $\mathcal A=\phi^{-1}(\mathcal B_Y)\pmod \mu$ . Is is perhaps true that any two factors corresponding to a given sub- $\sigma$ -algerba $\mathcal A$ are isomorphic? P.S. I have changed the wording of the theorems I have taken from [EW]. Also, in [EW] the theorems are stated for Borel probability spaces, which are more general than compact metric spaces.","['measure-theory', 'ergodic-theory']"
3003867,Does Radon-Nikodym imply Riesz Representation Theorem?,"In Axler's Linear Algebra Done Right we have the theorem 6.42:  (Riesz Representation Theorem) Suppose $V$ is a finite dimensional inner product space and $\phi$ is a linear functional on $V$ . Then there is a unique vector $u \in V$ such that $$\phi(v) = \langle v, u\rangle$$ for every $v \in V$ I'm currently learning measure theory and have came across Radon-Nikodym (Radon-Nikodym) Consider a measurable space $(X,\mathcal{M})$ on which two $\sigma$ -finite signed measures $\mu,\nu$ are defined such that $\nu << \mu$ ( $\nu$ is absolutely continuous with respect to $\mu$ ) then there is a $\mu$ -integrable function $f: X \to  \mathbb{R}$ such that $$\nu(E) = \int_E f d\mu$$ for every $E \in \mathcal{M}$ and any other function $g$ satisfying this is equal to $f$ almost everywhere with respect to $\mu$ . These two theorems seems very similar. Is it possible to go from Radon-Nikodym and get Riesz Representation? The integral in Radon-Nikodym ""acts"" like the inner product in Riesz Representation, the function $f$ ""acts"" like the vector $u$ in Riesz, and the signed measure $\nu$ acts like the linear functional $\phi$ . I am inclined to think that somehow we can recover Riesz from Radon-Nikodym. To start, we would need to somehow get a $\sigma$ -algebra, $\mathcal{M}$ on $V$ so that $(V, \mathcal{M})$ is a measurable space. This has to be a very particular $\sigma$ -algebra so that somehow the integral can be reduced to the inner product on $V$ . We would also need to show that the linear functional is absolutely continuous with respect to the inner product. So is it possible to recover Riesz from Radon-Nikodym? If so, how? If not, what's the issue?","['measure-theory', 'riesz-representation-theorem', 'analysis', 'real-analysis', 'linear-algebra']"
3003869,IID random variables $(X_n)$ have $\sum e^{X_n} c^n < \infty$ a.s.,"I'm working on the following exercise: Let $X_1, X_2, \ldots$ be i.i.d. nonnegative random variables. By virtue of the Borel-Cantelli lemma, show that for every $c \in (0,1)$ , $$
\sum_{n=1}^\infty  e^{X_n} c^n \begin{cases}
< \infty \textrm{ a.s.} & \textrm{if } \mathbb E[X_1] < \infty; \\
= \infty \textrm{ a.s.} & \textrm{if } \mathbb E[X_1] = \infty
\end{cases}
$$ I'm trying to show $\sum_{n=1}^\infty \mathbb P\left[\sum_{k=1}^n e^{X_k} c^k \geq M\right] < \infty$ for some large $M > 0$ . For then, Borel-Cantelli gives us that $$ \mathbb P\left[\limsup \left\{ \sum_{k=1}^n e^{X_k} c^k \geq M\right\}\right] = \mathbb P\left[\sum_{k=1}^\infty e^{X_k} c^k \geq M\right] = 0$$ and we're done. But I don't know how to show $\sum_{n=1}^\infty \mathbb P\left[\sum_{k=1}^n e^{X_k} c^k \geq M\right] < \infty$ . Any suggestions?","['measure-theory', 'borel-cantelli-lemmas', 'convergence-divergence', 'probability-theory', 'probability']"
3003880,Integral $\int_a^\infty \frac{\arctan(x+b)}{x^2+c}dx$,"I was playing around with some integrals and noticed that some integrals of the form: $$I(a,b,c)=\int_a^\infty \frac{\arctan(x+b)}{x^2+c}dx$$ Does have a closed form.
I am trying to find for what constant $c$ will this work. In case you wonder why only $c$ is problematic, I will try to show by an example. $$I=I(1,3,16)=\int_1^\infty \frac{\arctan(x+3)}{x^2+16}dx$$ Let's start by letting $x-1=t\,$ thus: $$I=\int_0^\infty \frac{{\arctan(\color{blue}{t+4})}}{t^2+2t+17}dt$$ With $\displaystyle{t=\frac{17}{y}\rightarrow dt=-\frac{17}{y^2}dy}$ $$I=\int_0^\infty \frac{{\arctan\left(\color{red}{\frac{17}{y}+4}\right)}}{\left(\frac{17}{y}\right)^2 +\frac{34}{y}+17 }\frac{17}{y^2}dy\overset{y=t}=\int_0^\infty \frac{{\arctan\left(\color{red}{\frac{17}{t}+4}\right)}}{t^2+2t+17}dt$$ $$2I=\int_0^\infty \frac{{\arctan(\color{blue}{t+4})+{\arctan\left(\color{red}{\frac{17}{t}+4}\right)}}}{t^2+2t+17}dt$$ $${\arctan(\color{blue}{t+4})+{\arctan\left(\color{red}{\frac{17}{t}+4}\right)}}=\arctan\left(\frac{\color{blue}{t+4}+\color{red}{\frac{17}{t}+4}}{1-(\color{blue}{t+4})\left(\color{red}{\frac{17}{t}+4}\right)}\right)$$ $$=\arctan\left(\frac{x^2+8x+17}{x}\frac{x}{-4(x^2+8x+17}\right)=\pi-\arctan\left(\frac14\right)$$ Above follows since the original integral is positive so we take $\arctan(-x)$ as $\pi-\arctan x $ and therefore getting a negative answer will not be an issue. $$I=\frac12 \left(\pi -\arctan\left(\frac14\right)\right)\int_0^\infty \frac{1}{t^2+2t+17}dt$$ Well, now the inner integral is not hard to compute and the final answer happens to be: $$I=\frac12 \left(\pi -\arctan\left(\frac14\right)\right)\frac14\arctan\left(\frac{t+1}{4}\right)\bigg|_0^\infty =\frac{\pi^2}{16}-\frac{3\pi}{16}\arctan\left(\frac14\right)+\frac18\arctan^2\left(\frac14\right) $$ There are more examples that I found by checking and try such as: $$I(1,2,9)=\int_1^\infty \frac{\arctan(x+2)}{x^2+9}dx$$ $$I(2,1,6)=\int_2^\infty \frac{\arctan(x+1)}{x^2+6}dx$$ $$I(2,2,13)=\int_2^\infty \frac{\arctan(x+2)}{x^2+13}dx$$ And so on... All those can be solved by the same method: First substitute $x-a=t$ , then let $t=\frac{\alpha}{y}$ , where $\alpha$ is the ""free of x"" coefficient from the denominator. The problem is that I tried more than $100$ combinations to get those integrals which is not that nice. How can we ""smartly"" find $c$ so that $I(a,b,c)$ is evaluable by symmetry? Or put in other word what should be $c$ if one wants to compute by symmetry $I(7,13,c)$ ?","['integration', 'definite-integrals', 'closed-form']"
3003881,Difficult inequality with three real variables,"For any real $e, t, \sigma$ such that \begin{aligned}
\label{s}
     0&<e<1\,,\\
     0&<t<\pi\,,\qquad\qquad\qquad(1)\\
-\pi/2&\leqslant\sigma\leqslant\pi/2
\end{aligned} the inequality \begin{aligned}
(1-e^2\cos^2\sigma)\eta&+(1+e\cos(t-\sigma))(e\eta\cos\sigma\cos t
                                                         +e\sin t)>\\
                       &>(1+e\cos(t-\sigma))\sqrt{1-(e\eta\cos\sigma\sin t-
                                                    e\cos t)^2}\,,\qquad(2)
\end{aligned} where $\eta=\sqrt{1-e^2}$ , holds. I have ""proved"" (2) numerically by three-dimensional brute-force method over the set (1). I used a three-dimensional grid with a high partition density in my C++ program. So I am sure that (2) holds on (1). Moreover, I proved (2) analitically for special case $\sigma=-\pi/2$ . In order to prove (2) analitically, I suppose that one have to do as follows. Denote for shortness \begin{aligned}
\tau&=1-e^2\cos^2\sigma\,,\\
\gamma&=1+e\cos(t-\sigma)\,,\\
\delta_1&=\eta\cos\sigma\cos t+\sin t\,,\\
\delta_2&=\eta\cos\sigma\sin t-\cos t\,.
\end{aligned} It is easy to prove that the expression under the root in (2) is positive on (1). Further, suppose that the left-hand side of (2) is also positive (at least nonnegative) on (1). Then (2) holds if and only if the square of the left-hand side of (2) is greater than the square of its right-hand side. After squaring both sides of (2) and noticing that $$
\delta^2_1+\delta^2_2=1+\eta^2\cos^2\sigma
$$ one obtains after some computations the following inequality \begin{equation}
\frac{\tau\eta}{\gamma^2}+\frac{2e\delta_1}{\gamma}>\eta\qquad\qquad(3)
\end{equation} that has to be proved. So if the left-hand side of (2) \begin{equation}
\tau\eta+e\gamma\delta_1\geqslant0\,\qquad\qquad\qquad(4)
\end{equation} on (1), it only remains to establish the validity of (3) on (1). In my opinion the task (1), (3), (4) is simpler than the original task (1), (2), but I am stuck at this stage. Maybe there are some other ways to deal with (1), (2), for example without the squaring (2)? Any ideas?","['trigonometry', 'geometric-inequalities', 'inequality', 'real-analysis']"
3003900,Weak convergence in $H^1(\mathbb R^3)$ implies convergence of integrals,"Suppose that $f_n \rightharpoonup f$ in $H^1(\mathbb R^3)$ (weak convergence). Then $$\int_{\mathbb R^3} \frac{\lvert f_n(x) \rvert^2}{\lvert x \rvert} dx \stackrel{n\to \infty}{\longrightarrow} \int_{\mathbb R^3} \frac{\lvert f(x) \rvert^2}{\lvert x \rvert}dx.$$ Approach: I tried to use the fact that $\mathbb 1_{\Omega} \,f_n(x) \to \mathbb 1_{\Omega} \, f_(x)$ in $L^2(\mathbb R^3)$ for each bounded $\Omega$ :
  Note that $$ \left \lvert \int_{\mathbb R^3} \frac{\lvert f_n(x) \rvert^2}{\lvert x \rvert} dx - \int_{\mathbb R^3} \frac{\lvert f(x) \rvert^2}{\lvert x \rvert}dx\right \rvert = \left \lvert \int_{\mathbb R^3} \frac{\lvert f_n(x) \rvert^2 - \lvert f(x) \rvert^2}{\lvert x \rvert}dx\right \rvert \\ =    \left \lvert \int_{|x| \leq R}\frac{\lvert f_n(x)|^2 - \lvert f(x)\rvert ^2}{|x|} dx + \int_{|x| > R}\frac{\lvert f_n(x)|^2 - \lvert f(x)\rvert ^2}{|x|} dx\right \rvert \\ \leq \int_{|x| \leq R} \frac{\lvert \lvert f_n(x)|^2 - \lvert f(x)\rvert ^2 \rvert }{|x|} dx + \frac{1}{R} \int_{|x| > R} \lvert \lvert f_n(x) \rvert - \lvert f(x) \rvert \rvert dx.$$ Now the left term can be bounded by the Sobolev inequality, but is that helpful? I suppose that not necessarily we have $\nabla f_n  \mathbb 1_{\Omega} \to \nabla f \mathbb 1_{\Omega}$ in $L^2$ . Any hints?","['lp-spaces', 'sobolev-spaces', 'functional-analysis', 'quantum-mechanics', 'convergence-divergence']"
3003917,"$n$ guests, each guest brings a prize, how many ways may the prizes be given out so nobody gets the prize that they brought?","Each person attending a party has been asked to bring a prize. The person
planning the party has arranged to give out exactly as many prizes as there
are guests, but any person may win any number of the prizes. If there are $n$ guests, in how many ways may the prizes be given out so that nobody gets
the prize that they brought? My answer was $(n-1)^n$ , for I thought that there are $(n-1)$ possible prizes for each of the $n$ guests. However, my answer is wrong. I'm given a hint that it will involve with the inclusion-exclusion principle, I'm not sure how to interpret the problem in this direction.","['inclusion-exclusion', 'combinatorics', 'discrete-mathematics']"
3003926,"In any group of 17 people, where each person knows 4 others, you can find 2 people, which don't know each other and have no common friends.","I have a problem with proof of this (graph theory): In any group of 17 people, where each person knows exactly 4 people, you can 
  find 2 people, which don't know each other and have no common friends. I translated this to proving, that there exists a pair of vertices $\{v,w\}$ , which aren't connected, that is, there isn't edge $(v,w)$ and for any other vertex $x$ from $V$ applies $(x, v) \veebar (x, w)$ or there is no edges between $x$ and $v$ and between $x$ and $w$ , but then I am stuck. I tried using Pigeonhole Principle, but I couldn't use it correctly, I think. I couldn't use Ramsey theory too. Any help and hints would be appreciated. I drew two examples of these graphs for help:","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3003931,Express $e^z$ as a Taylor series around the point $z_0 = 1$. Determine the set in $\mathbb{C}$ on which the series converges.,"I am a bit confused about how to approach this question / not sure if I'm on the right track. I know we can write $e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!}$ . Further: $e^z$ $= e^{z_0}(e^{z-z_0})$ $= e^{z_0} \sum_{n=0}^{\infty} \frac{(z - z_0)^n}{n!}$ Replacing $z_0$ with $1$ we get: $e^z= e^{1} \sum_{n=0}^{\infty} \frac{(z - 1)^n}{n!}$ Is the above equation the correct Taylor Series for $e^z$ around $z_0 = 1$ ? Also: if $|z-1| < R$ for some fixed $R > 0$ then: $e^{1} \sum_{n=0}^{\infty} \frac{|(z - 1)^n|}{n!} \leq e \sum_{n=0}^{\infty} \frac{|R^n|}{n!}$ Using the ratio test: $L = \lim_{n \to \infty}|\frac{R^{n+1}}{(n+1)!}*\frac{n!}{R^n}| = \frac{R}{n+1}$ Since $L = 0$ for any fixed $R$ , does this mean that the Taylor Series converges everywhere? I'm a little confused on how to put everything together, so any insight is appreciated!","['complex-analysis', 'convergence-divergence', 'taylor-expansion']"
3004007,"Is the double series $\sum_{n,k\geq 1}\frac{1}{n^2+k^2}$ divergent?","I thought that since the function $f(x,y)=(x^2+y^2)^{-1}$ is not integrable in $\mathbb{R}^2$ (I mean away from the origin) the same integral but with counting measure may behave the same. I tried this approach (similar to polar coordinates in some sense) $$
 \sum_{n,k\geq 1}\frac{1}{n^2+k^2}=\sum_{t\geq1}\frac{r(t)}{t}
$$ where $r(t)$ is the function that counts how many ways an integer $t$ can be written as sum of two squares. Does it exists any esteem or asymptotic behaviour for this function? Or maybe a different way to solve the problem? Thanks in advance!","['integration', 'number-theory', 'sequences-and-series']"
3004013,Finding $f(1)$ from the given integral function,"Consider the function- $$g(x)=\begin{cases} 1, \text{ if } x\in[-1,1]\\ 0, \text{ otherwise } \end{cases}$$ and $$f(x)=\lim_{h\to0}\frac{1}{2h}\int_{x-h}^{x+h}g(y)dy$$ then what is the value of $f(1)?$ My attempt: We get, $$f(1)=\lim_{h\to0}\frac{1}{2h}\int_{1-h}^{1+h}g(y)dy$$ Applying Newton-Leibnitz for the nuemerator after applying L'Hopital for this $0/0$ limit, we get $$f(1)=\frac{g(1+h)+g(1-h)}{2}=1$$ Am I correct?","['integration', 'calculus']"
3004018,Properties of Counting Measures Restricted to a Particular Sigma Algebra,"Define $\mathcal{F}=\{A\subseteq\mathbb{R} \ \vert \ 0\in A^{\mathrm{o}} \ or \ \ 0 \in (A^c)^{\mathrm{o}} \}$ , where $A^{\mathrm{o}}$ is the interior of $A$ . It can be shown quite easily that $\mathcal{F}$ is an algebra of sets, and that $\sigma(\mathcal{F})$ contains the singletons of $\mathbb{R}$ . If $\gamma$ is the counting measure on $(\mathbb{R},\mathcal{P}(\mathbb{R}))$ , let $\alpha(A)=\gamma(A \ \cap \ \{\frac{1}{n} \ \vert\ n \in \mathbb{N} \})$ and $\beta(A)=\gamma(A \ \cap \ \{\frac{1}{n} \ \vert\ n \in \mathbb{N} \} \ \cup \  \{0\})$ . If we define $\mu := \left.\alpha \ \right|_{\sigma(\mathcal{F})}$ and $\nu := \left.\beta \ \right|_{\sigma(\mathcal{F})}$ (the restrictions of $\mu$ and $\nu$ to $\sigma(\mathcal{F})$ ) then it turns out that: a) both $\mu$ and $\nu$ are $\sigma$ -finite. b) $\mu$ and $\nu$ coincide on $\mathcal{F}$ (that is, $\mu(A)=\nu(A)$ , $\forall A \in \mathcal{F}$ ). c) $\mu \neq \nu(A)$ on $\sigma(\mathcal{F})$ . I am having trouble in proving these 3 facts, and any help/hints to help push me towards the right direction will be much appreciated. In particular, I'm having difficulty in working with any general set $A\in \sigma(\mathcal{F})$ ; I currently have no clue on how to construct a sequence $(A_n)_{n=1}^{\infty}$ in $\sigma(\mathcal{F})$ such that $\bigcup\limits_{n=1}^{\infty}A_n = \mathbb{R}$ with $\mu(A_n)<\infty$ and $\nu(A_n)<\infty$ . EDIT: I've actually made some progress with this since asking: I have solutions to b) and c), and have partial work for a). The struggle in part a) remains with constructing such a sequence of sets. Best I've come up with is $(A_k)_{k=1}^{\infty}=(-k,-\frac{1}{k}] \cup [\frac{1}{k},k)$ , and in this case, $0 \in (A_k^c)^{\mathrm{o}}$ with $\mu(A_k)<\infty$ and $\nu(A_k)<\infty$ . Problem here is that the countable union isn't the whole real line (it misses $\{0\}$ !). Similarly, I've also considered the sequence $(A_k)_{k=1}^{\infty}=(-k,0] \cup [\frac{1}{k},k)$ , whose countable union is all of $\mathbb{R}$ , $\mu$ and $\nu$ are finite $\forall k$ , but this sequence is not in $\mathcal{F}$ .","['measure-theory', 'analysis', 'real-analysis']"
3004021,Inclusion of closed subschemes.,"Let $X$ be a scheme and $Y$ and $Z$ closed subschemes. What does it mean for $Y$ to be contained in $Z$ ? This question adresses the same question, but it covers only the affine case and it uses a different definition of a closed subscheme. So for the non-affine case, let $(Y, \mathcal{O}_Y)$ and $(Z, \mathcal{O}_Z)$ be two closed subschemas of a scheme $(X, \mathcal{O}_X)$ . Then $\mathcal{O}_Y$ and $\mathcal{O}_Z$ are quotients of the structure sheaf $\mathcal{O}_X$ by a quasi-coherent sheaf of ideals, that is, $$\mathcal{O}_Y = \mathcal{O}_X/\mathcal{I}$$ and $$\mathcal{O}_Z = \mathcal{O}_X/\mathcal{J} \, .$$ Then, to say that $Y \subset Z$ , we would like to say that $|Y| \subset |X|$ as topological spaces, and that $\mathcal{O}_Y$ is a sub sheaf of $\mathcal{O}_Z$ . I believe we can sharpen it a bit more by saying that the quasi-coherent sheaf $\mathcal{J}$ is a subsheaf of $\mathcal{I}$ . Would this suffice?","['algebraic-geometry', 'schemes', 'sheaf-theory']"
3004068,"Natural density of set $\{4^nk\}$, where $k$ is odd","A starting point is this problem: $P \subset Z_n = \{1, 2, \dots, n\}$ is binary , if there exists a number $k$ such that both $k \in P$ and $2k \in P$ , otherwise it is antibinary . One is supposed, for given $n$ , to show antibinary set with maximum amount of elements (there might be many sets satisfying this property). One can show that set $P_n = \{4^m(2k + 1) \mid m, k \in \mathbb{N}\} \cap Z_n$ is a proper solution. My question is: how big is this set? I'm looking for $\displaystyle\lim_{n \to \infty} p_n$ , where $p_n = \dfrac{|P_n|}{n}$ . Simple program I wrote in Python suggests that the answer is $\dfrac{2}{3}$ , but I don't know, how to prove it.","['elementary-number-theory', 'sequences-and-series']"
3004122,About residual sets and dense sets,"Suppose $E\subset X$ is some subset of a (complete) metric space $X$ . To each $p\in E$ we associate a small ball $B(p,\epsilon_p)$ centered at $p$ , and we want to consider the union $$
\hat E:=\bigcup_{p\in E} B(p,\epsilon_p)
$$ Question: When $E$ is only a dense subset, then $\hat E$ may not be the total space. A counter example is that $E=\mathbb Q$ and $X=\mathbb R$ . If we further require $E$ is residual, can we conclude $\hat E=X$ ? If not, any counter example?","['general-topology', 'metric-spaces']"
3004222,"Limit of matrix $A$ raised to power of $n$, as $n$ approaches infinity.","I understand that the limit of $n$ approaching infinity of a matrix $A^n$ , can be computed, in some cases, by looking at the diagonalization of that matrix, and then looking at the limit of $n$ going to infinity of the resulting diagonal matrix, $D$ , whose elements are raised to the power $n$ . What I do not understand is when we do not raise the matrix, call it $P$ , consisting of the eigenvectors of $A$ , and its inverse, to the power of $n$ as well? So: $ P^{-1}AP = D    $ $A = PDP^{-1}  $ $A^n = (PDP^{-1})^n$ $A^n = P^nD^n(P^{-1})^n$ Why do the matrices $P^n$ and $(P^{-1})^n$ not have to be taken into account when looking at the limit of $n$ going to infinity?","['matrices', 'limits', 'linear-algebra']"
3004263,Why is the gaussian free field a distribution but Brownian motion is a function?,"As I understand it, a GFF is a generalisation of Brownian motion to dimensions greater than one. However, they seem like very different objects. Brownian motion is just a continuous function (even though it is nowhere differentiable). By contrast, the Gaussian free field is not a function but only a distribution (it does not have well defined values at points, but only under integrals). What makes these two objects 'the same'? and why does moving from dimension one to two lead to such different behaviour?","['stochastic-processes', 'stochastic-pde', 'probability-theory', 'stochastic-calculus']"
3004332,Complex integration lemma: shorter proof?,"The black line is the branch cut. Lemma $$\lim_{\Delta\to0^+}\left(\int_{\gamma_1}+\int_{\gamma_2}\right)f(z)\ln(z-s)dz=-2\pi i\int_{pe^{i\theta}}^{qe^{i\theta}}f(t)dt$$ where $\arg(z-s)\in[\theta,\theta+2\pi)$ , $f$ being holomorphic on the path of integration. Many advanced users on this site use this lemma without stating, letting alone proving it. I wrote a proof here , but it is quite long. Is there a shorter proof of this lemma?","['complex-analysis', 'complex-integration']"
3004394,How do we know you can only flip something’s orientation two times?,"I was exploring what the determinant’s sign means geometrically. For 2-D, you can swap the axes and you’ve flipped orientation, and once you swap them again, you get the original orientation. Why should this be the case for higher dimensions? Why is it not possible that in 3-D, I can swap i and j, then swap j and k, and I get a “third orientation”? How is orientation defined anyway?",['linear-algebra']
3004570,Proving that there is an element common to all $35$ sets given certain set restrictions,"Consider the $35$ sets $A_1,A_2,\dots,A_{35}$ such that $|A_i|=27$ for all $1\leq i \leq 35$ , and every triplet of sets have one exactly one element in common to all three. Prove that there is at least one element common to all $35$ sets. This was a problem given to me by a friend - he asked me to help him with this but I am unable to figure out the answer. He suggested something about contradiction and the pigeonhole principle, but I'm not sure how to continue. He mentioned it was from some sort of Olympiad, but I dont remember which one (something middle eastern?) I found this similar question online: https://artofproblemsolving.com/community/q1h1699161p10908761 but this doesn't include any restrictions on cardinality, and is only a case for a pairwise disjoint set.","['contest-math', 'algebra-precalculus', 'combinatorics']"
3004575,Limit of a sequence of integrals involving continued fractions,"The following question was asked in a calculus exam in UNI, a Peruvian university. It is meant to be for freshman calculus students. Find $\lim_{n \to \infty} A_n $ if $$ A_1 = \int\limits_0^1 \frac{dx}{1 + \sqrt{x} }, \; \; \; A_2 =
 \int\limits_0^1 \frac{dx}{1 + \frac{1}{1+\sqrt{x}} }, \; \; \; A_3 =
 \int\limits_0^1 \frac{dx}{1 + \frac{1}{1+\frac{1}{1+\sqrt{x}}} },
 ...$$ First of all, I think this is a hard question for a midterm exam, but anyway, notice that we can calculate $A_1$ by making $t=\sqrt{x}$ $$ A_1 = \int\limits_0^1 \frac{2 t dt }{1+t} = 2 \int\limits_0^1 dt - 2 \int\limits_0^1 \frac{dt}{1+t}=2-2(\ln2)=2-\ln2^2 $$ Now, as for $A_2$ I would do $t = \frac{1}{1+\sqrt{x}}$ which gives $d t = \frac{ dx}{2 \sqrt{x} (1+\sqrt{x})^2} = \frac{t^2 dx}{2 (t-1)}$ thus upon sustituticion we get $$ A_2 = - \int\limits_1^{1/2} \frac{2 (t-1) }{t^2(1+t) } dt $$ which can easily solved by partial fractions or so. But, apparently this is not the way this problem is meant to be solved as this exam contained 4 questions to be solved in an hour. What is the trick, if any, that can be used to solve this problem without doing the unellegant  partial fractions?","['continued-fractions', 'limits', 'calculus', 'definite-integrals']"
3004608,Specific case of Mean Value Theorem for partial derivatives,"Let $f: \Omega \subseteq \mathbb{R}^{n} \longrightarrow \mathbb{R}$ be a continuous function in the closed segment $[x,y] \subset \Omega $ , such that the partial derivative with respect to the j-th variable $( \frac{\partial f(x)}{ \partial x_{j}})$ is defined in the segment $ (x,y) $ . Prove that $ \exists z \in (x,y) $ such that: $$f(y) - f(x) = \frac{\partial f(z)}{ \partial x_{j}} (y_{j} - x_{j})$$ Honestly I'm really surprised that I ended up having to ask this, because at first I thought the prove would just  closely follow the same structure from similar theorems. But my main problem is that the conditions I'm given restrict me from using the theorems that I am comfortable with. Most similar questions I've found (like this or this ) refer to different MVTs (which I actually already know), but can't seemingly be applied here. The proof for the first one (it's Theorem 36, just using this as a reference) doesn't work here because it only proves the existence of a directional derivative, where the direction is the one from the segment, so for example in my case it could only prove the directional derivative in the direction $ \frac{y-x}{||y-x||} $ . In fact, the proof does require that the limit $ \lim_{t \rightarrow t_{0}} g(t)$ is only evaluated for points that are in the segment, because otherwise you can't guarantee that the composition of f and g are continuous, and can't apply the single-variable MVT. The second one does imply existence of all partial derivatives, but it requires differentiability so that's out of the question. What I gathered from both proofs is that they are usually revolved around reducing the multivariable functions down to functions in $ \mathbb{R} $ , where we can use the MVT for the single-variable case. However, I don't know how to do that in this case. I think that my main problem comes from the fact that I don't know what is the direction of the segment $[x,y]$ . Could anyone please give me a hint on how to build a function that lets me reduce this problem to a single-variable case? Or should I take a completely different approach?","['partial-derivative', 'multivariable-calculus', 'real-analysis']"
3004752,Binomial Theorem with Three Terms,$(x^2 + 2 + \frac{1}{x} )^7$ Find the coefficient of $x^8$ Ive tried to combine the $x$ terms and then use the general term of the binomial theorem twice but this does seem to be working. Does anyone have a method of solving this questions and others similar efficiently? Thanks.,"['binomial-coefficients', 'combinatorics']"
3004766,How to calculate the surface area of parametric surface?,"Suppose you have the surface $z=3xy$ and you want to find the area that lies within the cylinder $x^2+y^2\leq 1$ . My homework is forcing me to use the parameterization $$\textbf{r}_1(s,t)= <s\cos(t), s\sin(t), 3s^2\sin(t)\cos(t)>$$ I am having a difficult time visualizing this parameterization, and I do not have any graphing software to graph the surface, but I want to make sure I understand this concept. This is quite obvious, but I want to be sure; using the above parameterization, I am not parameterizing the entire surface, right? If I wanted to, I assume the parameterization would be $$\textbf{r}_2(s,t) = <s,t,3st>$$ Instead, is $\textbf{r}_1$ just the parameterization adjusted for the region - the region being the cylinder $x^2+y^2\leq 1$ ? That is, are we just making a revolution around $z=3xy$ ? Any insight would be helpful.","['multivariable-calculus', 'surfaces', 'vectors', 'parametrization']"
3004835,Is the Lambert W function analytic? If not everywhere then on what set is it analytic?,"I would appreciate if someone can help me answer the following questions. Although I read several papers and documents on the Lambert W function, I could not assess on what set is this function (or at least its principle branch) analytic (or holomorphic)? Hence, on what set can one apply the identity theorem on it?
I know that the principal branch of the function admits a convergent Taylor series at $0$ with a positive radius of convergence $1/{\rm e}$ given by $$
W_0(z)=\sum\limits_{n=0}^\infty \frac{(-n)^{n-1}}{n!}z^n
$$ Hence, $W_0(z)$ is analytic at $0$ . However, is it also analytic elsewhere in the complex plane? According to Wikipedia, ""The function defined by this series can be extended to a holomorphic function defined on all complex numbers with a branch cut along the interval $(−\infty, −1/\text{e}]$ ; this holomorphic function defines the principal branch of the Lambert W function"".
I don't quite understand this statement. How can the extended function of this set be defined on all complex numbers away from the branch cut, if it only converges for $-\frac{1}{\text{e}}<z<\frac{1}{\text{e}}$ and diverges for all other $z$ . From my understanding, a function is said to be analytic on an open set $D$ , if the function converges to its Taylor series in a neighborhood of every point in the set $D$ . 
If the Taylor series of the function $W_0(z)$ at an arbitrary $z_0$ is not known to have a closed-form, does this mean that this function is not analytic at $z_0$ ? or could it be analytic without a known Taylor series expansion for arbitrary $z_0$ ? 
And if the Taylor series around an arbitrary point $z_0$ is not known in closed-form, how can one obtain the radius of convergence of the series? Does the radius of convergence play any role in applying the identity theorem? In How to derive the Lambert W function series expansion? , there is an example showing how to write the Taylor series expansion of the Lambert W function around $\text{e}$ . However, it is not clear to me if this applies to an arbitrary point $z_0$ (oher than $0$ and $\text{e}$ ) and how can one obtain the radius of converge of this non-closed form series and whether can one claim that the function is analytic at $z_0$ ? If we extend the function to the complex domain, it is known that the lambert W function has the derivative $\frac{\text{d}W}{\text{d}z}=\frac{W(z)}{z+\text{e}^{W(z)}}=\frac{W(z)}{z(W(z)+1)}$ for $z\neq \{0,-1/\text{e}\}$ . 
If we differentiate this infinite number of times, and the derivative exists at $z_0$ , then the function is infinitely differentiable $z_0$ . In this case, it only remains to prove that the function is equal its own Taylor series at a neighborhood of every point of its domain (or some open set) for the function to be holomorphic, right?  Can this be shown for arbitrary $z_0$ ? And hence for some open set? I tried to apply the Lagrange inversion theorem to get the Taylor series of $W_0(z)$ at arbitrary $z_0$ , but I could not converge to a closed-form. In Short, in my problem, i need to use the identity theorem on the Lambert W function. However, i need to check first on what set this theorem applies. In other words, on what set is the Lambert W function analytic? Any help is appreciated. Thanks a lot in advance.","['analytic-continuation', 'lambert-w', 'holomorphic-functions', 'taylor-expansion', 'analytic-functions']"
3004849,"Show that $\lim_n \sum_{k=1}^n\frac{B_k}{k!}\,\frac{n^\underline{k-1}}{n^{k-1}}=\sum_{k=1}^\infty\frac{B_k}{k!}$","I need to show that $$\lim_{n\to\infty} \sum_{k=1}^n\frac{B_k}{k!}\,\frac{n^\underline{k-1}}{n^{k-1}}=\sum_{k=1}^\infty\frac{B_k}{k!}$$ where $n^\underline{k-1}:=\prod_{j=0}^{k-2}(n-j)$ is a falling factorial and the $B_k$ are the Bernoulli numbers, and I know that the RHS of above converges to $1/(e-1)$ . I had two attempts: 1) First I tried to use the dominated convergence theorem setting $a_n(k):=\frac{B_k}{k!}\,\frac{n^\underline{k-1}}{n^{k-1}}\chi_{[1,n]}(k)$ , then clearly $\lim_n a_n(k)=B_k/k!$ for each $k\in\Bbb N_{\ge 1}$ , however I dont know if $\sum_{k=1}^\infty|B_k|/k!$ converges, and I dont know any absolutely convergent series that dominates, so Im stuck at this step. 2) A more elementary approach $$\left|\sum_{k=1}^\infty a_n(k)-\sum_{k=1}^\infty\frac{B_k}{k!}\right|\le\left|\sum_{k=1}^M(a_n(k)-B_k/k!)\right|+\sum_{k=M+1}^n\left|1-\frac{n^\underline{k-1}}{n^{k-1}}\right|+\left|\sum_{k=n+1}^\infty\frac{B_k}{k!}\right|$$ such that $|B_k/k!|<1$ for $k\ge M+1$ . Then taking limits above we have that $$\lim_{n\to\infty}\left|\sum_{k=1}^\infty\left(a_n(k)-\frac{B_k}{k!}\right)\right|\le\lim_{n\to\infty}\sum_{k=M+1}^n\left(1-\frac{n^\underline{k-1}}{n^{k-1}}\right)$$ for any fixed enough large $M$ . Then if I can show that for each $\epsilon>0$ there is some $M\in\Bbb N$ such that $$\lim_{n\to\infty}\sum_{k=M+1}^n\left(1-\frac{n^\underline{k-1}}{n^{k-1}}\right)<\epsilon$$ then Im done. However it is not clear how to accomplish (or if it is possible) this task. I thought about use the Stirling approximation on $n^\underline{k-1}/n^{k-1}$ , however it is not clear that I can apply an asymptotic expression inside a series, so Im again stuck. There is some easy way (the more elementary the better) to show the converge of the limit of the title? Thank you.","['limits', 'convergence-divergence', 'real-analysis']"
3004854,Checking whether a number is prime or not,"Is it true that a natural number $n>1$ is prime if and only if $n|\left ( \frac{1+\sqrt{5}}{2} \right )^n+\left ( \frac{1-\sqrt{5}}{2} \right )^n-1$ ? We know that $11$ is a prime number, but let us assume that we do not know, and let us also assume that the statement is true; $$\left ( \frac{1+\sqrt{5}}{2} \right )^{11}+\left ( \frac{1-\sqrt{5}}{2} \right )^{11}-1=198.$$ Clearly, $11|198$ . Therefore, as our assumption that the statement is true, the number $11$ is a prime number.","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3004856,Every ordinal $\alpha>0$ can be expressed uniquely as $\alpha=\omega^{\beta_1}\cdot k_1+\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n$,"Every ordinal $\alpha>0$ can be expressed uniquely as $$\alpha=\omega^{\beta_1}\cdot k_1+\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n$$ where $\beta_1>\beta_2>\cdots>\beta_n$ and $k_1>0,k_2>0,\cdots,k_n>0$ are finite. Does my attempt look fine or contain logical flaws/gaps? Any suggestion is greatly appreciated. Thank you for your help! My attempt: Existence Assume that $\xi$ can be expressed as normal form for all $\xi<\alpha$ . Let $\beta=\max\{\xi\in\rm Ord\mid\omega^\xi\le\alpha\}$ . Then there is $\delta$ and $\rho<\omega^\beta$ such that $\alpha=\omega^\beta\cdot\delta+\rho$ . Since $\rho<\omega^\beta$ , $\rho<\alpha$ and thus $\delta>0$ . I claim that $\delta$ is finite. If not, $\delta$ is infinite and thus $\delta\ge\omega$ . Then $\omega^{\beta+1}=\omega^\beta\cdot\omega\le\omega^\beta\cdot\delta\le\alpha$ and thus $\omega^{\beta+1}\le\alpha$ . This contradicts the maximality of $\beta$ . Thus $\delta$ is finite. Let $\beta_1=\beta$ and $k_1=\delta$ . If $\rho=0$ , then $\alpha=\omega^{\beta_1}\cdot k_1$ . If $\rho>0$ , then $\rho=\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n$ for some $\beta_2>\cdots>\beta_n$ and finite $k_2,\cdots,k_n>0$ by inductive hypothesis. We have $\omega^{\beta_2}\le\rho<\omega^{\beta_1}$ , then $\beta_2<\beta_1$ . As a result, $\alpha=\omega^{\beta_1}\cdot k_1+\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n$ as desired. We observed that $\beta<\gamma\implies\forall k\in\omega:\omega^\beta\cdot k<\omega^\gamma$ . This is because $\omega^\beta\cdot k<\omega^\beta\cdot\omega=\omega^{\beta+1}\le\omega^\gamma$ . It follows that if $\alpha=\omega^{\beta_1}\cdot k_1+\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n$ is in normal form and $\beta_1<\gamma$ , then $\alpha<\omega^\gamma$ . Uniqueness Assume that the normal form of $\xi$ is unique for all $\xi<\alpha$ . Let $\alpha=\omega^{\beta_1}\cdot k_1+\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n=\omega^{\gamma_1}\cdot l_1+\omega^{\gamma_2}\cdot l_2+\cdots+\omega^{\gamma_m}\cdot l_m$ . The previous observation implies that $\beta_1=\gamma_1$ . Let $\delta=\omega^{\beta_1}=\omega^{\gamma_1}$ , $\rho=\omega^{\beta_2}\cdot k_2+\cdots+\omega^{\beta_n}\cdot k_n$ , and $\sigma=\omega^{\gamma_2}\cdot l_2+\cdots+\omega^{\gamma_m}\cdot l_m$ . Then $\alpha=\delta\cdot k_1+\rho=\delta\cdot l_1+\sigma$ where $\rho<\delta$ and $\sigma<\delta$ . Thus $k_1=l_1$ and $\rho=\sigma$ . By inductive hypothesis, the normal form of $\rho$ is unique and thus $m=n$ , $\beta_2=\gamma_2,\cdots,\beta_n=\gamma_n, k_2=l_2,\cdots,k_n=l_m$ . It follows that the normal form of $\alpha$ is unique.","['elementary-set-theory', 'ordinals']"
3004894,Restricting domain of surjective function to make bijection,"Statement:
 For every surjective function $f:A \to B$ there exists set $C\subseteq A$ such that function $f:C \to B$ is bijection. As I see it, this is obviously true for finite sets, in way that for every multiple occurrence of some element in $B$ , it is possible to just eliminate all elements in $A$ whose image is that specific element in $B$ but one. However I am not sure about infinite sets, as I can't quite come up with counterexample, if there is one. Thanks for help.",['functions']
3004924,If $A^k$ commutes with $B$ then $A$ commutes with $B$.,Let $A$ and $B$ are two $n \times n$ Complex matrices. Assume that $(A-I)^n=0$ and $A^kB=BA^k$ for some $k \in \mathbb{N}$ . Then I want to prove that $AB= BA$ . Clearly $1$ is the only eigen value of $A$ and also $A^k$ and $B$ are simultaneously triangulable. But how do I get down to $A$ to commute with $B$ . Any help will be appreciated. Thanks.,"['matrices', 'abstract-algebra', 'linear-algebra', 'field-theory']"
3004963,Natural density of solvable quintics,"A recent question asked about the topological density of solvable monic quintics with rational coefficients in the space of all monic quintics with rational coefficients. Robert Israel gave a nice proof that both solvable and unsolvable quintics are dense in $\Bbb Q^5$. A natural (non-topological) way to ask about the relative density of solvable quintics in all quintics is to ask about their natural density, as follows: Write our quintics as $x^5+a_0x^4 + \dots + a_4$, with $a_i \in \Bbb Z$. Write $$f(N) := \frac{\text{# of solvable quintics with } |a_i| < N}{(2N+1)^5}.$$ Robert Israel's answer to the linked question gives some data that supports our intuition that yes, the solvable quintics are in fact extremely rare. Do we indeed have $\lim_{N \to \infty} f(N) = 0$? Are there known nice asymptotics for $f(N)$?","['galois-theory', 'number-theory', 'polynomials']"
3004973,Bad reduction at prime numbers for the elliptic curve $y^2+y=x^3-x^2+2x-2$,"Consider the elliptic curve $$E:y^2+y=x^3-x^2+2x-2.$$ My goal is to compute the conductor of the elliptic curve, the example is from https://planetmath.org/conductorofanellipticcurve . My problem isn't about the actual definition  of the conductor but the definition of the different types of bad reductions that may occur. Please, correct me if something I have typed is wrong, since I am not totally sure about anything of what I have written here. Let $K$ be a field. We have that $E/K$ is singular if and only if $\Delta_E=0$ ( $\Delta_E$ is the discriminant of the curve $E$ ). I start by computing the discriminant $$\Delta_E=-875=-5^3\cdot 7.$$ If I do reduction modulo $p=5$ , we have $$\Delta_E\equiv_p 0.$$ Similarly I do a reduction modulo $q=7$ ; $$\Delta_E\equiv_q 0.$$ Thus, they are bad primes. My next task is to classify the reductions modulo $p$ and $q$ respectively. In the link they claim that a reduction modulo $p$ is an additive reduction while modulo $q$ is a multiplicative reduction. Before we try to solve this problem, let me just mention: (This is taken from The Arithmetic of Elliptic curves written by Silverman). The Weierstrass equation is given by $$y^2+a_1xy+a_3y=x^3+a_2x^2+a_4x+a_6.$$ We furthermore define, $$
\begin{cases}
b_2=a_1^2+4a_4\\
b_4=2a_4+a_1a_3\\
c_4=b_2^2-24b_4.
\end{cases}
$$ Case 1 (Reduction Modulo $p$ ): In the link https://planetmath.org/badreduction , they define the reduction to be additive if the reduction has a cusp which holds if and only if both $\Delta_E$ and $c_4$ are equivalent to $0$ . Notice that $a_1=0$ and $a_4=2$ . this gives us $$b_2=8,$$ and $$b_4=4.$$ Thus $$c_4=8^2-24\cdot 4=-32\equiv_p 3.$$ Thus, I would not claim that the reduction is additive, but multiplicative. The same holds if I reduce it modulo $q$ , then it is not $0$ in $\mathbb{F}_q$ and thus I would also claim that this reduction is multiplicative, since the reducion is multiplicative if $\Delta_E$ is equivalent to $0$ , while $c_4\not = 0$ . Probably I have misunderstood the definition of bad reduction and the different types that can occur. I would be really happy if someone could explain this concept to me and how I may finish this example.","['algebraic-number-theory', 'algebraic-geometry', 'elliptic-curves', 'arithmetic-geometry']"
3005105,Continuous map between $L^p$ spaces,"The following theorem appears in Appendix B of Rabinowitz' book Minimax Methods in Critical Point Theory: Let $\Omega \subset \Bbb{R}^n$ be bounded and $g\in C(\overline{\Omega}\times \Bbb {R},\Bbb {R})$ such that there exist constants $r,s\ge 1$ and $a_1,a_2\ge 0$ such that for all $x \in \overline{\Omega}, y\in \Bbb{R}$ $$|g(x,y)|\le a_1 + a_2|y|^{r/s}$$ Then the map $\varphi(x)\mapsto g(x,\varphi(x))$ belongs to $C(L^r(\Omega),L^s(\Omega))$ . In the proof, he says ""To prove the continuity of this map, observe that it is continuous at $\varphi$ if and only if $f(x,z(x)) = g(x,z(x)+\varphi(x))-g(x,\varphi(x))$ is continuous at $z=0$ . Therefore we can assume $\varphi = 0$ and $g(x,0)=0$ ."" I don't understand how this assumpion can be made without loss of generality, and was unable to finish the proof without it. Any help would be appreciated. Edit: I have found a partial answer in a different thread: Continuity proof of a function between $L^p$ spaces In the post it says:
Using the growth estimate, one can derive a similar estimate for $f$ of the form: $$
|f(x,z(x))|\leq A_1+A_2 |\phi_0(x)|^{r/p}+A_3|z(x)|^{r/p}
$$ This would solve my problem, since the former two constants don't depend on $z$ and can be thrown together, leaving the case that was already proven. However, I couldn't derive this estimate. edit2: I was wrong in assuming this solves the problem since, as pointed out by the users supinf and Peter Melech, the constant may not depend on x.","['lp-spaces', 'functional-analysis', 'analysis', 'real-analysis']"
3005128,Does $y'=|y|^a$ have any global solutions?,"Assume the differential equation $$
y'=|y|^a
$$ My intuition tells me that since it involves an absolute value, there might not be any solutions defined everywhere, except for the case $a=0$ , where $y(x)=x+c$ . To show this, let $$
f(y)=|y|^a$$ $\bullet\,$ For $a<0$ : $f$ is not defined for $y=0$ plus it's not bounded $\bullet\,$ For $a=0$ : $$y'=1 \iff y(x)=x+c, \quad x \in \mathbb{R}$$ $\bullet\,$ For $a>0$ : $f$ is defined $\forall y \in \mathbb{R}$ , but it's not bounded Can we thus conclude that the only global solution of $y'=|y|^a$ is $y(x)=x+c$ ?","['initial-value-problems', 'stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems']"
3005275,"Prove there is a unique connected simple graph with degree sequence $2,2,\dots,2,1,1$.","My attempt: Assume that graph is connected, that unique graph is basically a ""line"" with vertices on it. The vertices with degree $1$ and these vertices can only be on the two ends, and vertices with degree $2$ are in the middle. Am I correct? Is there a formal way to present it?","['graph-theory', 'discrete-mathematics']"
3005288,"Looking for alternative argument $(x^2 - y^3, y^2 - z^3)\subset k[x,y,z]$ is prime ideal.","Consider $I=(x^2 - y^3, y^2 - z^3)\subset k[x,y,z]$ as an ideal with $k$ a field. $\textbf{Q:}$ I am Looking for alternative argument to conclude $I$ is prime ideal. It is clear that I can use parametrization $k[x,y,z]\to k[t]$ by parametrization $(x,y,z)\to (t^9, t^6, t^4)$ and argue this descends to a monomorphism under quotient $k[x,y,z]/I$ . Note this map is clearly not surjection. Hence this is not isomorphic to $A^1_k$ and this is already indicated by singularity at $(0,0,0)$ . Can I conclude primeness of ideal $I$ by some other better argument? Say intersection,grobner basis,...","['algebraic-geometry', 'abstract-algebra']"
3005291,Functions on a manifold,"I am learning about diff geometry and I have a question about ways of defining a function on a manifold. So if we think about manifolds in general we can define a chart on it. Then, through composition of a function and a chart we can analyze this function. My question is this. How can we define a function in the first place since it is on points P which need not be numbers. Dont we need to define the function on a chart in order for it to be defined on a manifold? And dont we then need to define a manifold through charts also? But in order for it to be defined properly we have to look for chart independent ptoperties which are read off the charts... I am confused.","['manifolds', 'differential-geometry']"
3005376,Help understanding the cause of this pattern when writing π as an infinite series with double factorials,"I made a post about a year and a half ago: $\pi$ as an Infinite Series using Taylor Expansion on Equation of a Circle where essentially I used the Taylor series expansion on $\ y = \sqrt{r^2-x^2}$ (the equation of a circle in Cartesian coordinates with radius $r$ ). Integrating term by term from $0$ to $r$ in order to obtain a representation of $\pi$ gave a pattern which I wrote as: $$\ \pi = \sum_{n=1}^\infty \frac{-4[(2n-3)!!]^2}{(2n-3)(2n-1)!}$$ This can be written differently as: $$\ -\frac{\pi}{4} = \sum_{n=1}^\infty \frac{(2n-5)!!}{(2n-1)(2n-2)!!}$$ Furthermore what I have noticed is (and what I'm trying to understand but cannot for some reason): $$\ \frac{\pi}{16} = \sum_{n=1}^\infty \frac{(2n-7)!!}{(2n-1)(2n-2)!!}$$ $$\ -\frac{\pi}{96} = \sum_{n=1}^\infty \frac{(2n-9)!!}{(2n-1)(2n-2)!!}$$ $$\ \frac{\pi}{768} = \sum_{n=1}^\infty \frac{(2n-11)!!}{(2n-1)(2n-2)!!}$$ This pattern continues when adjusting the numerator (double factorial term) with odd integers... 5, 7, 9, 11, 13, and so on. Those series will converge to fractions of pi and alternate as positive or negative fractions of pi. I do not understand what is happening here. 
Also, it is interesting to note that it seems: $$\ \frac{\pi}{2} = \sum_{n=1}^\infty \frac{(2n-5)!!}{(2n-3)(2n-2)!!}$$","['factorial', 'pi', 'taylor-expansion', 'sequences-and-series', 'convergence-divergence']"
3005389,The operator norm of the composition of linear bounded operators between Banach spaces.,"The set $B(X, Y )$ is a normed linear space with the operator norm. If $T ∈ B(X, Y)$ and $S ∈ B(Y, Z)$ for $X, Y , Z$ normed linear spaces, then the composition $ST ∈ B(X, Z)$ and $\|ST\| ≤ \|S\| \|T\|.$ I don't know how to prove this. Here is my trial. Since the composition if exist of 2 linear operators is a linear operator then $ST$ is a linear operator. To prove it is bounded we prove that $\|ST x\| < \infty$ . if $\|T\| = \sup_{\|x\|=1}\|Tx\| < \infty$ . and $\|S\| = \sup_{\|y\|=1}\|Sy\| < \infty$ . I don't know how to continue.","['operator-theory', 'proof-verification', 'functional-analysis', 'linear-transformations']"
3005438,Show any two edges in a 2-connected graph lie on a cycle,"So I found some proofs on any two vertices would lie on a cycle, but stuck on dealing with edges. We can say any two edges are connected, but does that just imply they will be on a common cycle?","['graph-theory', 'graph-connectivity', 'connectedness', 'discrete-mathematics']"
3005538,"Prove that if $a,b\in \mathbb{R}$, $a>0$, then $\lim \frac{n^b}{(1+a)^n}=0$ as $n\to\infty$","As the title says, i want to show that $$\lim_{n\to \infty} \frac{n^b}{(1+a)^n}=0$$ where $a,b\in \mathbb{R}$ with $a>0$ . I tried to bound the sequence $x_n =  \frac{n^b}{(1+a)^n}$ and use the sandwish theorem, but have no results. My problem is the exponent in the denominator, maybe it could be bounded with Bernoulli inequality ( $(1+a)^n\geq 1+na$ ) but then the problem is de numerator $n^b$ . I'm grateful for any hints for doing this problem, or some steps to clarify.","['limits', 'calculus', 'sequences-and-series']"
3005544,I need help finding the general solution to the differential equation $y''(t)+7y'(t)=-14$,"What I've tried: I have the inhomogeneous differential equation: $$y''(t)+7y'(t)=-14$$ I find the particular solution to be on the form $$kt$$ by inserting the particular solution in the equation $$(kt)''+7(kt)'=-14$$ and isolating for k, I get that: $$k=-2$$ and therefore the particular solution is $$y(t)-2t$$ I also need the general solution for the homogenous equation $$y''(t)+7y'(t)=0$$ by finding the roots of the characteristic polynomial $$z^2+7z=z(z+7)=0$$ $$z_1=0$$ $$z_2=-7$$ I get the general solution: $$c_1e^{0t}+c_2e^{-7t}=c_1+c_2e^{-7t}$$ Now, according to my textbook, the general solution of an inhomogeneous differential equation is given by $$y(t)=y_p(t)+y_{hom}(t)$$ Where $y_p(t)$ is the particular solution and $y_{hom}(t)$ is the general solution to the homogenous equation. Therefore I get the general solution to be $$y(t)=c_1+c_2e^{-7t}-2t$$ This is not consistent with Maple's result however Can anyone see where I've gone wrong?",['ordinary-differential-equations']
3005591,"Use the Euclidean Algorithm to find $a, b, c, d$ such that $225a + 360b +432c +480d = 3$","I wish to find the integers of $a,b,c$ and $d$ such that: $$225a + 360b +432c +480d = 3$$ which is equal to: $$75a + 120b +144c+ 160d =1$$ I know I have to use the Euclidean algorithm. And I managed to do it for two integers $x$ and $y$ . But can't figure out, how to do it with $4$ integers.",['number-theory']
3005615,"Prove that if $E \subset \mathbb{R}^n $ has finite perimeter, then almost every vertical slice has finite perimeter too.","Before explaining my problem, I recall the definitions: Let $E \subset \mathbb{R}^n$ be a Lebesgue measurable set. We say that $E$ is a set of locally finite perimeter if for every compact set $K \subset \mathbb{R}^n$ it holds that \begin{equation*} \label{eq:deflocfiniteperimeter}
M_K := \sup \left\{ \int_{E} div\, T(x) \,dx : T \in C^1_c( \mathbb{R}^n; \mathbb{R}^n), spt \,T \subset K, \| T \| \leq 1 \right\} < \infty.
\end{equation*} Moreover, if $$
\sup\left\{M_K:K \subset  \mathbb{R}^n, K\text{compact}\right\}< \infty,$$ then we say that $E$ is a set of finite perimeter. Now suppose that $E$ is a set of finite perimeter. I have to prove that for $\mathcal{L}^{n-1}$ -a.e. $z \in \mathbb{R}^{n-1}$ the vertical slice $E_z \subset \mathbb{R}$ is a set of finite perimeter; where, by definition, $E_z := \{ t \in \mathbb{R} : (z,t ) \in E\}$ . I can only prove that for a.e. $z \in \mathbb{R}^{n-1}$ the vertical slice is a set of LOCALLY finite perimeter. Here I descrive my attempt: Let $\rho$ is a regulatizing kernel and consider the sequence $ u_{h} : = \chi_E * \rho_{1/h}$ : I already know (from a previous result) that $$ \limsup_{h \to \infty} \int_K |\nabla u_h(x)| dx \leq P(E;K)$$ for all compact sets $K \subset \mathbb{R}^{n}$ . Now fix a compact $J \subset \mathbb{R}$ . I have proved that if $T \in C^1_c(\mathbb{R})$ satisfies $\|T\| \leq 1$ and $J \supset spt T$ , then for a.e. $z \in \mathbb{R}^{n-1}$ it holds $$ \left| \int_{E_z} T'(t) \, dt \right| \leq \liminf_{h \to \infty} \int_{J} |\nabla u_h (z,t)| \, dt .$$ Taking the sup among the functions $T \in C^1_c(\mathbb{R})$ with $\|T\| \leq 1$ and $J \supset spt T$ and integrating on a compact set $H \subset \mathbb{R}^{n-1}$ , we get $$ \int_H \sup \left\{ \left| \int_{E_z} T' \right| : T \in C^1_c(\mathbb{R}), \, \|T\| \leq 1 , \, J \supset spt T \right\}  \leq \liminf_{h \to \infty} \int_{H \times J} |\nabla u_h| \leq P(E; H \times J ) \leq P(E) < \infty. $$ If the integral of a function is finite then the function is a.e. finite. Hence for a.e. $z$ we have $$ M_{J} := \sup \left\{ \left| \int_{E_z} T' \right| : T \in C^1_c(\mathbb{R}), \, \|T\| \leq 1 , \, J \supset spt T \right\} < \infty.$$ This proves that the set has locally finite perimeter but I can't find a uniform bound for $M_{J}$ . Any help would be really appreciated!","['integration', 'measure-theory', 'geometric-measure-theory', 'real-analysis']"
3005690,"Prove that the polynomial is $g(x,y)(x^2 + y^2 -1)^2 + c$","This is from a Brazilian math contest for college students (OBMU): Let $f(x,y)$ be a polynomial in two real variables such that the polynomials $$\frac{\partial f}{\partial x}(x,y)$$ $$\frac{\partial f}{\partial y}(x,y)$$ are divisible by $x^2+y^2-1$ . Prove that there's a polynomial $g(x,y)$ and a constant $c$ such that $$f(x,y) = g(x,y)(x^2+y^2 -1)^2 +c$$","['contest-math', 'multivariable-calculus', 'multivariate-polynomial', 'real-analysis']"
3005731,"$F(x)=\int_{-2}^{2} dy f(x,y)$ is an even function, is $G(x)=\int_{-2}^{2} dy [f(x,y)]^2$ even?","I have a real valued function in two real variables $f(x,y)$ which is essentially a black box. The only thing I really know is that $$
F(x)=\int_{-2}^{2} f(x,y) dy
$$ is even and that $$
\int_{-\infty}^{\infty} F(x) dx=1
$$ Can I conclude that $$
G(x)=\int_{-2}^{2} \left[f(x,y)\right]^2 dy
$$ is also even? I looked for a counterexample, but couldn't find one. I intuitively feel like this should be true, but am struggling to make that more rigorous. Any ideas? Thanks!","['even-and-odd-functions', 'multivariable-calculus', 'calculus', 'real-analysis']"
3005750,Eigenfunctions for Laplacian on increasing domains,"I was wondering if we can compare the eigenfunctions of the Laplacian for increasing domains. In particular, I want to look at the eigenfunction for the principal eigenvalue with integral $1$ . Is it possible that we could get pointwise boundedness? I have seen that the eigenvalues themselves decrease as the domains increase.","['partial-differential-equations', 'functional-analysis', 'analysis', 'real-analysis']"
3005754,Show composition mapping is continuous with compact-open topology,"Let $X$ be a compact Hausdorff space, and $H(X)$ be the set of homeomorphisms from $X$ to $X$ , with the compact-open topology. Prove that the mapping $h:H(X)\times H(X)\rightarrow H(X)$ , $h(f,g)=f\circ g$ is continuous. Note, if $C(X,X)$ is the set of all continuous mappings from $X$ to $X$ , the compact-open topology on $C(X,X)$ is generated by subsets of the form $B(K,U)=\{f:f(K)\subset U\}$ where $K$ is compact in $X$ and $U$ is open in $X$ . I honestly have no clue how to work with the compact open topology and would appreciate any hints. Let's take $U$ open in $H(X)$ . I want to show that $h^{-1}(U)$ is open in $H(X)\times H(X)$ . I believe I am overthinking this, and apologize for the lack of work, I am just really confused how to show this. Any help would be much appreciated.",['general-topology']
3005764,Why does $\int_1^\sqrt2 \frac{1}{x}\ln\left(\frac{2-2x^2+x^4}{2x-2x^2+x^3}\right)dx$ equal to $0$?,"In this question, the OP poses the following definite integral, which just happens to vanish: $$\int_1^\sqrt2 \frac{1}{x}\ln\bigg(\frac{2-2x^2+x^4}{2x-2x^2+x^3}\bigg)dx=0$$ As noticed by one commenter to the question, the only zero of the integrand is at $x=\sqrt[3]{2}$ , meaning that the integral of the integrand from $x=1$ to $x=\sqrt[3]{2}$ is the additive inverse of the integral of the integrand from $x=\sqrt[3]{2}$ to $x=\sqrt{2}$ . This suggests some sort of symmetry obtainable by a substitution, but I cannot find an appropriate substitution or cancellation. It seems like the answer should be much simpler than those posted to the linked question. Any ideas? EDIT: I believe that this more general integral also vanishes: $$\int_1^{\sqrt{t}}\frac{1}{x}\ln\bigg(\frac{t-sx^2+x^4}{tx-sx^2+x^3}\bigg)dx=0$$","['integration', 'symmetry', 'definite-integrals', 'logarithms']"
3005788,Construct a regular expression,"The problem asks me to construct a regular expression for the set of strings in $\{a,b\}^*$ that have even number of $a$ and $b$ . What I have tried is $(aa)^* + (bb)^* + (aabb)^*$ but I believe it does not cover a string like $abbbaaba$ . Many thanks,","['regular-expressions', 'discrete-mathematics']"
3005795,Comparison of Bounded Operator Topologies,"I'm looking at the topologies on the set of bounded operators between Banach spaces, $L(X,Y)$ , and while I see how uniform convergence implies strong convergence implies weak convergence, I'm struggling to see why we have that the weak operator topology is weaker than the strong operator topology which in turn is weaker than the uniform operator topology: $$
\tau_{\rm weak}\subset \tau_{\rm strong}\subset\tau_{\rm uniform}
$$","['general-topology', 'functional-analysis']"
3005808,What is the orthogonal complement of $H^1_0$ in $H^1$?,"Let $\Omega$ be a closed domain with smooth boundary in $\mathbb{R}^n$ . Let $H^1_0(\Omega)$ be the closure of compactly supported smooth functions under the norm $\|u\|_1 = \int_\Omega u^2 + |\nabla u|^2\ dx$ and let $H^1(\Omega)$ be the closure of smooth, continuous functions under the same norm. Any $H^1$ function which has nonvanishing trace cannot be approximated by any sequence of functions in $H^1_0$ . So $H^1_0$ is a closed subspace of the Hilbert space $(H^1, \|\cdot\|_1)$ , hence has an orthogonal complement. What is a generating set of the orthogonal complement of $H^1_0$ in $H^1$ ? Motivation is to get my hands on some concrete examples, rather than to just appeal to theorems that establish the existence of a right inverse to a trace operator. Of course if anyone has references, I'm happy to follow them up. I've skimmed through Gilbarg-Trudinger and Evans and found nothing, but maybe I'm looking in the wrong place.","['trace', 'sobolev-spaces', 'functional-analysis']"
3005835,"Polar form of normal random vector , angle and length are independent ,and angle is spherical distribution","Represent $g \sim N(0,I_n)$ in polar form as $g=r \theta$ where $r = \|g\|_2$ is the length  and $\theta = \frac{g}{\|g\|_2} $ is the direction prove that $r$ and $\theta$ are independent ? prove that $\theta$ is uniformly distributed on sphere $S^{n-1}$ for first one :
The only things I know how to do is to show the product pdf of both of $\theta$ and $r$ is same as  n-dimeinal pdf of of standard Gaussian vector ? but  how to find pdf of $\|g\|_2$ ? I have some problem in trasformation of random variable in this case . since the transformationare not bijective , is any simple way to do that?","['independence', 'normal-distribution', 'probability-theory', 'probability', 'random-variables']"
3005846,Calculation of probability with arithmetic mean of random variables for a total of 3 times,"Thanks to @Ben W for his answer to my previous question , now I can calculate and have 3 equal probabilities: $P(X_1) = P(X_2) = P(X_3) \approx 0.000148646896$ with $X_1 = X_2 = X_3 = 1620$ Following up, once that the 4 people got 405 as the arithmetic mean of the number on their cards, then they repeat the drawing 2 more time (3 in total). So, I would like to calculate the probability that the arithmetic mean of the number on their cards is 405 for a total of 3 times. How to make that? Some explanation is welcome.","['statistics', 'probability']"
3005859,Spivak Differential Geometry 1 Chapter 1 Problem 8,"Problem $8$ in Chapter $1$ of Spivak's A Comprehensive Introduction to Differential Geometry, Vol. 1 reads: 8. For this problem, assume (The Generalized Jordan Curve Theorem) If $A\subset \mathbb{R}^n$ is homeomorphic to $S^{n-1},$ then $\mathbb{R}^n-A$ has $2$ components, and $A$ is the boundary of each. If $B\subset\mathbb{R}^n$ is homeomorphic to $D^n=\{x\in\mathbb{R}^n:d(x,0)\le 1\},$ then $\mathbb{R}^n-B$ is
  connected. (a) One component of $\mathbb{R}^n-A$ (the ""outside of $A$ "") is
  unbounded, and the other (the ""inside of $A$ "") is bounded. (b) If $U\subset\mathbb{R}^n$ is open, $A\subset U$ is homeomorphic to $S^{n-1}$ and $f:U\to \mathbb{R}^n$ is one-to-one and continuous (so that $f$ is a homeomorphism on $A$ ), then $f(\text{inside of }A)=\text{inside of }f(A)$ . (c) Prove Invariance of Domain, i.e. if $U\subset \mathbb{R^n}$ is open and $f:U\to\mathbb{R}^n$ is one-to-one and continuous, then $f(U)\subset \mathbb{R}^n$ is open. I have solved (a) and (c), which I will present here. Proof of (a): $A$ is homeomorphic to $S^{n-1},$ and so is compact. It follows that $A$ is bounded. Let $B$ be a closed ball containing $A.$ Then $\mathbb{R}^n-B\subset \mathbb{R}^n-A$ is connected and clearly unbounded. It must lie in a connected component of $\mathbb{R}^n-A,$ and so one of the components of the latter set is unbounded. It must then be that the other connected component of $\mathbb{R}^n-A$ is contained in $B,$ so that this connected component is bounded. Proof of (c): Let $y\in f(U)$ and consider the preimage of $y$ under $f$ , call it $x$ , in $U$ . Then there is some closed ball $B$ about $x$ in $U$ . The boundary $A$ of $B$ is homeomorphic to $S^{n-1}$ and $x$ lies in the inside of $A$ , so by part (b) $f(\text{inside of }A)=\text{inside of }f(A)$ is an open ball which contains $y$ . We have thus found a neighborhood of $y$ contained in $f(U)$ , so $f(U)$ is open in $\mathbb{R}^n$ . I do not know how to solve (b). I am completely and utterly stuck. I'm clearly missing something obvious. Any hint or even just the solution would be appreciated.","['continuity', 'general-topology', 'open-map', 'differential-geometry']"
3005882,$\{ x \in X : |f(x)| \geq \epsilon \}$ is compact then $f$ is uniformly continuous on $X$.,"Past year paper question. Let $(X, d)$ be a metric space and let $f: X \to \mathbb{R}$ be a continuous function, where $\mathbb{R}$ is given the standard metric. Assume that for any $\epsilon > 0$ , the set $\{ x \in X : |f(x)| \geq \epsilon \}$ is a compact metric subspace of $X$ . Show that $f$ is uniformly continuous on $X$ . Attempt: Let $\epsilon >0$ be given. Let $K := \{ x \in X : |f(x)| \geq \frac{\epsilon}{2} \}$ . $f$ is continuous on $K$ $\implies f$ is uniform continuous on $K$ . Then there exists $\delta$ such that $d(x,y)<\delta \implies |f(x)-f(y)| < \frac{\epsilon}{2}$ . Take any $2$ points $x,y \in X$ , such that $d(x,y)<\delta$ . If $x,y \in K$ , then $|f(x)-f(y)| < \frac{\epsilon}{2} < \epsilon$ . If $x,y \notin K$ , then $|f(x)-f(y)| \leq |f(x)|+|f(y)| \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} \leq \epsilon$ . But I am stuck here, because what if $x \in K$ and $y \notin K$ .","['metric-spaces', 'analysis']"
3005883,Lie algebra generated by elements of the symmetric group $S_N$,"For an arbitrary group $G$ , the group algebra $\mathbb{C}(G)$ is defined as the set of all formal linear combinations of the elements of $G$ : $\mathbb{C}(G)=\{c_1g_1+c_2g_2+\ldots+c_n g_n|c_i\in \mathbb{C},g_i\in G\}$ . Multiplication in $\mathbb{C}(G)$ is induced by the group multiplication of $G$ and extends to $\mathbb{C}(G)$ by linearity. In a similar fashion, we can define a ""group Lie algebra"" $\mathfrak{L}(G)=\{c_1g_1+c_2g_2+\ldots+c_n g_n|c_i\in \mathbb{C},g_i\in G\}$ , which is the same as $\mathbb{C}(G)$ as a linear vector space, but in $\mathfrak{L}(G)$ only the Lie bracket $[,]:\mathfrak{L}(G)\times \mathfrak{L}(G)\to \mathfrak{L}(G)$ is defined, to be the commutator in $\mathbb{C}(G)$ , i.e. $[l_1,l_2]=l_1\cdot l_2-l_2\cdot l_1$ , where "" $\cdot$ "" is the multiplication in $\mathbb{C}(G)$ . My problem is to determine the structure of the Lie algebra $\mathfrak{L}(G)$ for the symmetric group $G=S_N$ . Let us take $S_3$ as an example. Since $|S_3|=6$ , the group algebra $\mathbb{C}(S_3)$ of $S_3$ is 6-dimensional, spanned by $\{1,P_{12},P_{23},P_{13},P_{12}P_{23},P_{23}P_{12}\}$ . It is easy to see that $\{1,I,I^2\}$ are central elements (i.e. commute with everything in $\mathbb{C}(S_3)$ ), where $I=P_{12}+P_{23}+P_{13}$ . The 3-dimensional subspace orthogonal to these central elements is spanned by $\{P_{12}-P_{23},P_{12}-P_{13},[P_{12},P_{23}]\}$ , which forms an $\mathfrak{su}(2)$ Lie algebra, their relation to the spin generators are $$P_{12}-P_{23}=\sqrt{6}(s_x-s_y),~~P_{12}-P_{13}=\sqrt{6}(s_x-s_z),~~[P_{12},P_{23}]=2i(s_x+s_y+s_z),$$ where $[s_i,s_j]=i\epsilon_{ijk}s_k$ . Therefore we conclude that $\mathfrak{L}(S_3)=\mathfrak{u}(1)^3\oplus \mathfrak{su}(2)$ . But when trying to determine the structure of $\mathfrak{L}(S_N)$ for arbitrary $N$ ,  this kind of brute force calculation seems hopeless. I don't  even know the structure of $\mathfrak{L}(S_4)$ . For large $N$ , I want to know this: if $\mathfrak{L}(S_N)$ is a direct sum of simple Lie algebras, let $d_N$ be the dimension of its largest irreducible(simple) component (e.g. $d_3=3$ ). Does $d_N$ grow algebraically fast or exponentially fast with $N$ ? Any hints, suggestions, or relevant references will be welcomed. Thanks.","['permutations', 'symmetric-groups', 'abstract-algebra', 'lie-algebras']"
3005887,Construction involving regular polygons inside a circle,"Let's make a construction involving regular polygons: ► First, we begin with a equilateral triangle, with side $\ell_3 = 1;$ ► After, we draw a square on the middle point each side of the initial triangle, with side $\ell_4 = \frac{1}{2} = \frac{\ell}{2}.$ Now, the construction continues, taking one of these steps: ► If the regular polygon have an even number of sides $n$ with length $\ell_n$ , then we draw two regular polygons with $n + 1$ sides of length $\ell_{n+1} = \frac{\ell_n}{2},$ from the middle point of the extreme segments. ► If the regular polygon have an odd number of sides $n$ with length $\ell_n$ , then we draw one regular polygons with $n + 1$ sides of length $\ell_{n+1} = \frac{\ell_n}{2},$ from the middle point of the unique extreme segment in this case. To clarify the explanation, we will obtain a figure like the one below: I have two questions about this: Q1 . This figure is inside a circumference with center in the incenter of the initial equilateral triangle? In affirmative case, what is the radius $R$ of the circumference? Q2 . The sequence of the lengths I adopted in the construction is $$\ell_n = \frac{1}{2^{n-3}}, \quad \forall n \ge 3 $$ If I consider other sequence $\ell_n$ , when exists a circumference with center in the incenter of the initial equilateral triangle and radius $R$ in which the figure is inside?","['euclidean-geometry', 'circles', 'geometry', 'polygons', 'sequences-and-series']"
3005902,Double Infinite sum of $1/n^2$,"I am trying to use an identity we showed on our homework: $$ \sum_{-\infty}^{\infty} \frac{1}{(n+a)^2}  = \frac{\pi^2}{\sin^2(\pi a)} $$ to show that $$ \sum_{1}^{\infty} \frac{1}{n^2}  = \frac{\pi^2}{6}.$$ I have broken the first double infinite sum into the sum from $-\infty$ to $1$ plus the the $0^{th}$ term, plus the sum from $1$ to $+\infty$ and then I want to take the limit of $a$ going to $0$ . This results in taking the limit of the following: $$\lim_{a\to 0} \frac{\pi^2}{\sin^2(\pi a)} - \frac{1}{a^2}   .$$ Which I know should result in $\frac{\pi^3}{3}$ from Wolfram Alpha, as desired, but I am struggling with showing it analytically. 
My idea was to try and find the Maclaurien Expansion of $\sin^2(\pi a)$ , but then taking that series to the exponent of negative 1 since it is in the denominator is causing issues. 
Is there a trick I am not seeing or a possible better way to use the above property to show the other infinite sum? This question is also for a complex analysis class, so perhaps there is a way to use complex Laurent or power series?","['power-series', 'limits', 'sequences-and-series']"
3005909,"What do we call the algebraic closure of $\mathbb{R}(x)$, and how can we describe it?","$\mathbb{R}(x)$ is not algebraically closed, as can easily be seen by considering the equation $xy^2=1$ ; there is no rational function $r(x)$ with the property that $xr(x)^2=1$ .  However, everyone knows how to solve this equation for $y$ , obtaining $$y=\frac{1}{\sqrt{x}}, y=-\frac{1}{\sqrt{x}}$$ as the two solutions. So the solutions exist, but in order to find them we have to go beyond $\mathbb{R}(x)$ to a larger collection of functions. The algebraic closure of $\mathbb{R}(x)$ would contain not only all rational functions, but also roots of all orders, plus some things we don't have names or notation for (solutions of polynomials with coefficients in $\mathbb{R}(x)$ of degree 5 or higher that are not solvable by radicals , for example).  (The word ""functions"", here, is used somewhat casually, as most of these things are partial functions at best.)  I guess it would have to contain $\mathbb{C}$ as well, come to think of it. What is the algebraic closure called?  Does it have a conventional name?  I think of it as the ""field of algebraic functions"" but I don't know if that's standard terminology or if there's another, more commonly-used name.  Is there a notation for it?  Does it contain any other exotic things, besides what I have already mentioned?","['field-theory', 'functions', 'extension-field']"
3005922,If $f$ is a linear map. Show that $Df(a)=f(a)$,Suppose $f:\Bbb R^n\to \Bbb R^m$ is a linear map. Show that $Df(a)=f(a)$ . Tried using limit definition: $$\lim\limits_{h \to 0}\frac{\Vert f(a+h)-f(a)-f(a)h\Vert}{\Vert h\Vert}$$ $$=\lim\limits_{h \to 0}\frac{\Vert f(a)+f(h)-f(a)-f(a)h\Vert}{\Vert h\Vert}$$ $$=\lim\limits_{h \to 0}\frac{\Vert f(h)-f(a)h\Vert}{\Vert h\Vert}$$ Want to show this is $0$ but can't see where to go from here. Unless I misunderstand what $Df(a)=f(a)$ means.,['multivariable-calculus']
3005932,"Is there anything that non-newtonian calculus can do, which newtonian calculus cannot?","As well, are there problems where non-newtonian calculus leads to a more elegant or simple solution than regular calculus?","['calculus', 'derivatives', 'problem-solving']"
3005935,"Conditional Expectation of One Member of a Multinomial Distribution, Conditioned on a Second Member","I have a homework problem, which asks: Let X = $(X_1, X_2, X_3, X_4, X_5) \sim \text{Mult}_5(n, p)$ with p = $(p_1, p_2, p_3, p_4, p_5)$ . (a) Find $E(X_1 | X_2) \text{ and } Var(X_1 | X_2)$ . (b) Find $E(X_1 | X_2 + X_3)$ . So here is my approach to part (a): To find $E(X_1|X_2 = x_2)$ , I think of $X_2$ being set at a fixed value and remove it from the distribution. So first I have to normalize p, so say that: $$ p_1^{'} = \frac{p_1}{1-p_2}, p_3^{'} = \frac{p_3}{1-p_2}, p_4^{'} = \frac{p_4}{1-p_2}, p_5^{'} = \frac{p_5}{1-p_2} $$ then let $p^{'} = (p_1^{'}, p_3^{'}, p_4^{'}, p_5^{'})$ So with $X_2$ fixed, I have a new distribution: $\text{Mult}_4(n-X_2, p^{'})$ . And to find the probability of $(X_1|X_2)$ , I can treat it like any other marginal of a multinomial distribution, and say that: $(X_1|X_2 = x_2) \sim \text{Bin}(n-X_2, p_1^{'})$ I know that the expected value for a binomial distribution is $n \cdot p$ and the variance is $n \cdot p(1-p)$ , so I can say that: $$ E(X_1|X_2) = p_1^{'}(n-X_2)$$ $$ Var(X_1|X_2) = p_1^{'}(n-X_2)(1-p_1^{'}) $$ So I have two questions. Is this approach OK? If so, can I simply take the same steps for (b) but adding $X_2$ and $X_3$ together?","['expected-value', 'statistics', 'conditional-expectation', 'probability']"
3005952,Prove a limit involving the ceiling function,"I found a pattern that I want to prove: $$f(x) = 2^{\lceil \log_2(3^x)\rceil} - 3^x\quad \{x\in\mathbb{Z}^+\} $$ $$ \lim_{x\rightarrow\infty} f(x) = \infty $$ Discussion: $$ f(x) = 2^{\lceil \log_2(3^x)\rceil} - 3^x = 3^x(2^{\lceil \log_2(3^x)\rceil-\log_2(3^x)}-1)$$ $$0<\lceil \log_2(3^x)\rceil-\log_2(3^x)<1\ \Rightarrow\ 0<f(x)<3^x$$ $f(x)$ 's lower bound is zero and its upper bound tends to infinity. As far as I know, $f(x)$ can oscillate anywhere in between. However, after checking a few first thousands values of $f$ , I am convinced that the function indeed tends to infinity. I guess the fact that $x$ is an integer plays a role in that. If $\lceil \log_2(3^x) \rceil$ was really close to $\log_2(3^x)$ , $f(x)$ would be really close to $0$ , so the limit would not hold. Experimental results suggest the limit exists, so I guess there are some restrictions on how close $\log_2(3^x)$ can be to its ceiling integer. I don't know how to proceed from that.","['number-theory', 'limits', 'irrational-numbers', 'ceiling-and-floor-functions']"
3005959,Prove that $ { \lim_{n\to\infty} \left( 1-\frac{1}{n} \right)^n = e^{-1} } $.,"I want to prove that $$  { \lim_{n\to\infty} \left( 1-\frac{1}{n} \right)^n = 
 e^{-1} } $$ . I came up with a proof, but want to make sure that it is correct. Here is my proof: $$  { \lim_{n\to\infty} \left( 1-\frac{1}{n} \right)^n = \lim_{n\to\infty} \left(\frac{n-1}{n} \right)^n = \lim_{n\to\infty} \left(\frac{n}{n-1} \right)^{-n} = \\
\lim_{n\to\infty} \left((1+\frac{1}{n-1} )^n\right)^{-1} = \lim_{n-1\to\infty} \left((1+\frac{1}{n-1} )^{n-1}(1+\frac{1}{n-1})\right)^{-1} = \\
\lim_{n-1\to\infty} \left(e(1+\frac{1}{n-1})\right)^{-1} = e^{-1}}  $$ Is it valid proof? I know there are other proofs, but I want to know about this one. In particular can we substitude $e$ instead of $(1+\frac{1}{n-1} )^{n-1}$ and $1$ instead of $(1+\frac{1}{n-1})$ in the limit? Thank you for your answers.","['limits', 'proof-verification']"
3005971,All the 2-d polygons that can be used to form 3-d polyhedrons,"The requirement is that we start with a 2-d polygon and using just copies of this polygon, cobble them together into a closed 3-d polyhedron (no gaps). I want to find a way to identify all such 2-d polygons. Here are the ones I'm aware of - All the platonic solids obviously satisfy this requirement. So, the equilateral triangle which can be used to form the Tetrahedron, Octahedron and Icosahedron. Then there is the square which can be used to form the Cube and finally the regular pentagon which can be used to form the Dodecahedron. Apart from these, scalene triangles can also be used to form corresponding Tetrahedra and Icosahedra in the same way as equilateral triangles. Any quadrilateral that has two consecutive sides equal can be used to form a Hexahedron and any pentagon that has two consecutive sides equal to (say) a and the next two consecutive sides equal to (say) b, leaving the third side free can be used to form a Tetartoid. Some of these pentagons have internal angles greater than 360/3 = 120 degrees. So, I'm not sure we can rule out some sort of irregular hexagons that can be used in this way as well. What I have here is a list with no obvious way to proceed in terms of verifying that it is exhaustive. Can someone give me a hint as to how I can make progress?","['solid-geometry', 'geometry', 'platonic-solids']"
3005975,2D limit with exponentials,"I want to show that $$\lim_{(a,b)\to (0,0)^+} \frac{ 1-e^{-(a+b)} }{ (1-e^{-a})(1-e^{-b}) } - \frac 1a - \frac 1b =0 $$ where the + means that the limit is taken only with respect to paths in the nonnegative quarter .(i.e, a,b are non-negative)","['multivariable-calculus', 'exponential-function', 'real-analysis']"
3006106,An AMM-like integral $\int_0^1\frac{\arctan x}x\ln\frac{(1+x^2)^3}{(1+x)^2}dx$,"How can we evaluate $$I=\int_0^1\frac{\arctan x}x\ln\frac{(1+x^2)^3}{(1+x)^2}dx=0?$$ I tried substitution $x=\frac{1-t}{1+t}$ and got $$I=\int_0^1\frac{2 \ln \frac{2 (t^2+1)^3}{(t+1)^4} \arctan \frac{t-1}{t+1}}{t^2-1}dt\\
=\int_0^1\frac{2 \ln \frac{2 (t^2+1)^3}{(t+1)^4} (\arctan t-\frac\pi4)}{t^2-1}dt$$ I'm able to evaluate $$\int_0^1\frac{\ln \frac{2 (t^2+1)^3}{(t+1)^4}}{t^2-1}dt$$ But I have no idea where to start with the rest one.","['integration', 'calculus', 'definite-integrals']"
3006109,Proof for Cauchy-Schwarz inequality for Trace [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Cauchy-Schwarz inequality applied to Trace of two products $\mathbf{Tr}(A'B)$ has the form $$
\mathbf{Tr}(A'B) \leq \sqrt{\mathbf{Tr}(A'A)} \sqrt{\mathbf{Tr}(B'B)}
$$ I saw many places where people use this inequality.  But did not see a formal proof.  Is it difficult to prove ?  Anyone can give a simple proof ?","['trace', 'cauchy-schwarz-inequality', 'linear-algebra']"
3006127,"If a function is continuous everywhere, but undefined at one point, is it still continuous?","This is a question regarding the definition of continuity. My understanding of continuity is that a function is continuous at a point when it holds that $$\lim_{x\to a^-}f(x) = f(a) = \lim_{x\to a^+}f(x) \quad \quad (1)$$ The book I'm currently reading has this image: Note here that $f(x)$ is defined for $x=3$ , but $g(x)$ is not. This is followed by text stating that g(x) is continuous because $D_g = [0, 6]\text{\\}\{3\}$ , thus it is continuous for all values in its domain. My point of contention here is that, how can we say that it is continuous at $x=3$ when $g(3)$ does not exist? Referring to the aforementioned definition $(1)$ that the limits converge to the actual value at this point. I would have immediately declared both cases as jump discontinuities. Am I mistaken here? Does $g(x)$ illustrate an exception to $(1)$ ?","['limits', 'continuity', 'piecewise-continuity']"
3006265,Find all the intervals in which $ -x^4 + x + 3 \ge 0 $,"How do I find all the intervals in which $$-x^4 + x + 3 \ge 0$$ ? First of all, I let $f(x) = -x^4 + x + 3$ . Then I used the derivative $f'(x) = -4x^3 + 1$ to study its growth. I used the expression $a^3-b^3 = (a-b)(a^2+ab+b^2)$ to write $f'(x)$ as the following $$f'(x) = (1 - x\sqrt[3]{4})(1 + x \sqrt[3]{4} + (x \sqrt[3]{4})^2 )$$ from which I clearly have the solution $x = 1/\sqrt[3]{4}$ . For $4^\frac{2}{3}x^2  + x\sqrt[3]{4} + 1$ we have $\Delta = 4^\frac{2}{3}-4\cdot4^\frac{2}{3}\cdot1 < 0 $ which means that there are no solutions in $\mathbb{R}$ . As $f'(2) < 0$ it means that the function is decreasing on $(1/\sqrt[3]{4}, \infty)$ and increasing on $(-\infty, 1/\sqrt[3]{4})$ . But was thinking about an approach to use Rolle's theorem but to no avail as I won't be able to pinpoint solutions of the equation.","['calculus', 'functions']"
3006343,Where is the local structure theory of étale morphisms needed?,"MO crosspost . In Stacks 02GH it is mentioned étale morphisms are locally standard étale. This seems to be the analogue of the local form of local diffeomorphisms in the smooth category. In the latter, local structure plays a big role. Where is the local structure of étale morphisms needed further on in the theory? Which important proofs crucially require actually knowing an explicit local form?","['algebraic-geometry', 'schemes']"
3006372,Probability of winning/losing a lonely card game when you shout an integer progressively each time you draw,"Take a standard face-down 52-deck of cards, including 13 ranks of four suits (for simplicity, assign value 1 to 13 from ace to King). Draw the cards one by one, shouting the integers from 1 to 13 (and then starting again) in the natural order (i.e. {1,2,3,4...}) at each draw. For example, you shout 'one' and draw a 7, then you shout 'two' and draw an ace, then you shout 'three' and draw a King, and so on and so forth. You lose instantly if the number you've shouted coincide with the rank of the card you've just drawn. What is the probability of winning/losing the game (whichever is easier to compute)? **Additional information:
The problem is related to the first-encounter probability of two walks (one deterministic and one random): a deterministic walk jumping to the right by one lattice site at each time-step, and resetting after 13 steps, and another walk randomly jumping among the same thirteen sites (with the constraint that no site can be visited more than four times).","['combinatorics', 'card-games', 'random-walk']"
3006395,How can I find $\lim_{n\rightarrow\infty}(1+\frac{x}n)^{\sqrt{n}}$?,"How can I find $$\lim_{n\rightarrow\infty}\left(1+\frac{x}n\right)^{\sqrt{n}}\;?$$ I know $\lim_{n\rightarrow\infty}\left(1+\frac{x}n\right)^{n}  = \exp (x)$ but I don't know how can I put the definition in this particular limit. I know then, that $\lim_{n\rightarrow\infty}\big(1+\frac{x}n\big)=1$ , but I don't think this is right to consider.","['limits', 'sequences-and-series', 'exponential-function', 'real-analysis']"
3006463,"Let $H$ be a Hilbert space with projections $P,Q$, then $\lim_{n\to\infty}(PQ)^nx= Rx$ for all $x\in H$, where $R$ is the projection to $PH\cap QH$","Suppose we have a Hilbert space $\mathcal H$ , with projections $P,Q$ , and let $R$ be the projection onto $P\mathcal H\cap Q\mathcal H$ , then I would like to show that $(PQ)^n\to R$ strongly. We can clearly reduce to the case where $P\mathcal H\cap Q\mathcal H=0$ and $P\mathcal H+Q\mathcal H=\mathcal H$ , in which case we must show that $(PQ)^n\to0$ strongly. Now, if the limit $y=\lim_{n\to\infty}(PQ)^n x$ exists, then if it is nonzero, then $$\|y\| = \|PQ y\|<\|Q y\|\le\| y\|$$ which is a contradiction, so once we have convergence, we're done. However, I don't see quite how to show convergence in a general infinite dimensional case.","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
3006477,Why is the Rational Rotation Algebra not a Matrix Algebra?,"Let $A_{\theta}$ be the rotation C $^{*}$ -algebra with rotation $\theta$ . I.e., $A_{\theta}=C^{*}(u,v)$ , where $vu=e^{2\pi i \theta}uv$ . Suppose that $\theta=p/q$ , where $p$ and $q$ are non-zero positive integers that are relatively prime. I am trying to show that $A_{\theta}$ is not simple. Consider the C $^{*}$ -algebra $M_{q}(\mathbb{C})$ and the two unitary matrices $$
U = \begin{pmatrix}0 & 1 & 0 & \cdots & 0\\
0 & 0 & 1 & \cdots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \cdots & 1\\
1 & 0 & 0 & \cdots & 0
\end{pmatrix}
\quad\text{and}\quad V=\begin{pmatrix}
1 & 0 & 0 & \cdots & 0\\
0 & e^{2\pi i \theta} & 0 & \cdots & 0\\
0 & 0 & e^{4\pi i \theta} & \cdots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \cdots & e^{2(q-1)\pi i\theta} 
\end{pmatrix}
$$ in $M_{q}(\mathbb{C})$ . It is easy to check that $VU=e^{2\pi i \theta}UV$ . It follows by the universal property of $A_{\theta}$ that there is a $*$ -homomorphism $\pi\colon A_{\theta}\to M_{q}(\mathbb{C})$ such that $\pi(u)=U$ and $\pi(v)=V$ . If $\pi$ is not injective, then we are finished, since $\ker\pi$ is a non-zero proper ideal in $A_{\theta}$ . So, we may suppose $\pi$ is injective. Now note that $\pi$ is an irreducible representation. Otherwise, it would decompose into a direct sum of smaller irreducible ones, which is impossible . But then it must be that $\pi(A_{\theta})=M_{q}(\mathbb{C})$ since irreducible representations acting on a finite-dimensional space are surjective . Thus, we can conclude that $A_{\theta}=C^{*}(u,v)=C^{*}(U,V)=M_{q}(\mathbb{C})$ . I am looking for a straight-forward way to get a contradiction here.","['c-star-algebras', 'functional-analysis', 'operator-algebras']"
