question_id,title,body,tags
2993345,"Prove that the function $f\colon \mathbb{R} \to \mathbb{R}$ , $f(x) = x*|x|$ is a bijection","I needed help proving this This is what I tried, I broke it into two cases $x>0$ and $x<0$ Case 1 $x>0$ Injectivity $|x|=x$ $f(x) = x^2$ $f(x)$ is a injection if $f(x)$ = $f(m)$ then $x=m$ $x^2 = m^2$ $x=m$ since $x>0$ Surjectivity for every $x∈R$ $f(√x) = x $ therefore it is surjective I needed help proving the case $x<0$","['proof-explanation', 'functions']"
2993369,(when) is a map of schemes determines by values on Zariski dense subset?,"The motivation for this question is to justify/understand a particular abuse of notation in the world of group schemes, namely people write things like $m:(g_1,g_2) \mapsto g_1g_2$ when discussing the multiplication or action maps $G \times_k G \to G$ when $G$ is a group scheme over $k$ . This bothers me because over a general base field $k$ , identifying points in the fibered product $G \times_k G$ as pairs $(g_1,g_2)$ only makes sense on $k$ -rational points. However, suppose we are in the situation where the $G(k) \hookrightarrow G$ is Zariski dense, and $G$ is a variety, so in particular (geometrically) reduced, separated, etc. Then I would think that a map on $k$ -rational points, given by polynomials, determines uniquely a map of schemes. So the question is, suppose $X$ is a variety of a general base field $k$ such that $X(k)$ is Zariski dense in $X$ . Then does a regular map $X(k) \to Y$ , $Y$ separated, determine uniquely a morphism $X \to Y$ .","['algebraic-geometry', 'schemes']"
2993406,"Proving that ${\rm vec}(A\,{\rm Diag}(b)\,C) = ((C^T\otimes 1_a)\odot(1_c\otimes A))\,b$","Given the following vectors and matrices $$\eqalign{
 &A\in{\mathbb R}^{a\times b},\,\,\,\,
 &B\in{\mathbb R}^{b\times b},\,\,\,\,
 &C\in{\mathbb R}^{b\times c} \cr
 &1_a\in{\mathbb R}^{a\times 1},\,\,\,\,
 &b\in{\mathbb R}^{b\times 1},\,\,\,\,
 &1_c\in{\mathbb R}^{c\times 1} \cr
}$$ where $B={\rm Diag}(b)\,$ and $\,1_n$ denotes a vector of all ones of length $n$ . I would like to show that the vector $\,v={\rm vec}(ABC)\,$ can be expanded as $$\eqalign{
v &= \Big((C^T\otimes 1_a)\odot(1_c\otimes A)\Big)\,b
}$$ where $(\otimes, \odot)$ denote the Kronecker and Hadamard products, respectively. I am aware of several other expressions for this vector $$\eqalign{
 v &= (C^T\otimes A)\,{\rm vec}(B) \cr
 v &= \Big((C^T\otimes 1_a1_b^T)\odot(1_c1_b^T\otimes A)\Big)\,{\rm vec}(B) \cr
}$$ but I don't see how to arrive at the desired formula. Update After studying Omnomnomnom's answer, I realized that I needed to exploit several esoteric properties to prove the formula. 1) The outer product of two vectors vectorizes to their Kronecker product $$\eqalign{
 {\rm vec}(ab^T) &= b\otimes a \cr
}$$ 2) Vectors from the canonical basis distribute over a Hadamard product $$\eqalign{
 (M\odot N)e_k &= (Me_k)\odot(Ne_k) \cr
}$$ 3) The distribution property of the Kronecker product of 2 arbitrary vectors and a matrix $$\eqalign{
 (C^T\otimes 1)e &= {\rm vec}(1(e^TC)) = (C^Te)\otimes 1 \cr
 (1\otimes A)e &= {\rm vec}((Ae)1^T) = 1\otimes(Ae) \cr
}$$ 4) A rule for mixed Kronecker/Hadamard products $$\eqalign{
 (M\odot N)\otimes(P\odot Q) &= (M\otimes P)\odot(N\otimes Q) \cr\cr
}$$ Use these rules to evaluate the $k^{th}$ column of the anticipated solution $$\eqalign{
&\big((C^T\otimes 1_a)\odot(1_c\otimes A)\big)\,e_k \cr
&(C^T\otimes 1_a)e_k\odot(1_c\otimes A)e_k \cr
&(C^Te_k\otimes 1_a)\odot(1_c\otimes Ae_k) \cr
&(C^Te_k\odot 1_c)\otimes(1_a\odot Ae_k) \cr
&(C^Te_k)\otimes(Ae_k) \cr
}$$ which matches the $k^{th}$ column of Omnomnomnom's matrix. Update #2 I also like O's second approach, which I interpret as $$\eqalign{
&\Big((C^T\otimes 1_a1_b^T)\odot(1_c1_b^T\otimes A)\Big)\,{\rm vec}(B)\cr
&=\sum_k b_k\,\,\big((C^T\otimes 1_a1_b^T)\odot(1_c1_b^T\otimes A)\big)\,\big(e_k\otimes e_k\big) \cr
&=\sum_k b_k\,\,\big((C^T\otimes 1_a1_b^T)(e_k\otimes e_k)\big)\odot\big((1_c1_b^T\otimes A)(e_k\otimes e_k)\big) \cr
&=\sum_k b_k\,\,\big(C^Te_k\otimes 1_a1_b^Te_k\big)\odot\big(1_c1_b^Te_k\otimes Ae_k\big) \cr
&=\sum_k b_k\,\,\big(C^Te_k\otimes 1_a\big)\odot\big(1_c\otimes Ae_k\big) \cr
&=\sum_k b_k\,\,\big((C^T\otimes 1_c)\odot(1_a\otimes A)\big)e_k \cr
&=\big((C^T\otimes 1_c)\odot(1_a\otimes A)\big)\,b \cr
}$$","['matrices', 'linear-algebra']"
2993418,Mnemonic for Integration by Parts formula?,"The Integration by Parts formula may be stated as: $$\int uv' = uv - \int u'v.$$ I wonder if anyone has a clever mnemonic for the above formula. What I often do is to derive it from the Product Rule (for differentiation), but this isn't very efficient. One mnemonic I have come across is ""ultraviolet voodoo"", which works well if we instead write the formula as: $$\int u \ \textrm{d}v = uv - \int v \ \textrm{d}u.$$ I am however looking for a mnemonic for the first formula.","['integration', 'mnemonic']"
2993504,Existence of Periodic Orbit,Consider the planar system $\dot x_1 = x_2 - x_1^3$ $\dot x_2 = -x_1$ Prove that there exists no periodic orbit in this system. I tried to use the Bendixson criteria. The divergence is equal to $-3x_1^2$ which is equal to zero on the $x_2$ axis and therefore we cannot use the Bendixson criteria.,"['control-theory', 'ordinary-differential-equations', 'dynamical-systems']"
2993583,Bounded operator to a space with two different norms,"$X$ is a Banach space and $Y$ is a normed linear space. $(Y,\lVert\cdot\rVert_1)$ is not complete and $(Y,\lVert\cdot\rVert_2)$ is complete, while $\lVert\cdot\rVert_2\ge\lVert\cdot\rVert_1$ . Let $T: X\to( Y,\lVert\cdot\rVert_1)$ be a bounded linear operator. Prove that $T: X\to( Y,\lVert\cdot\rVert_2)$ is also a bounded linear operator. For example, $Y$ can be $C([0,1])$ . $\lVert\cdot\rVert_1$ is $L_1$ norm and $\lVert\cdot\rVert_2$ is sup norm.",['functional-analysis']
2993658,Existence of vector bundle isomorphism iff there exists a frame of sections,"In class, we defined a vector bundle morphism in the following way: Definition: Let $\pi_i : E_i \rightarrow B_i$ be a vector bundle $(i = 1,2)$ . A smooth map $F : E_1 \rightarrow E_2$ is a vector bundle morphism if there exists a smooth map $f : B_1 \rightarrow B_2$ such that $ \pi_2 \circ F = f \circ \pi_1$ and such that $\forall p \in B_1$ , the map $ F: (E_1)_p \rightarrow (E_2)_{f(p)}$ is linear. I now have the following problem: Problem: Let $\pi: E \rightarrow M$ be a vector bundle of rank $n$ . Show that $E$ is isomorphic to the vector bundle $ \Phi: M \times \mathbb{R}^n \rightarrow M$ if and only if there exists a frame of sections of $E$ (defined over the whole of $M)$ . Given such a frame, construct explicitly an isomorphic $E \cong M \times \mathbb{R}^n$ . Attempt: ( $\Leftarrow$ ) Assume there are sections $\left\{ s_1, \ldots, s_n \right\}$ of $E$ such that for each $p \in M$ , the set $\left\{s_1 (p), \ldots, s_n(p) \right\}$ is a basis for $E_p$ (the fiber over p). I then wanted to construct the map $F$ in the definition as follows: $$ F: M \times \mathbb{R}^n \rightarrow E : (p, x^{1}, \ldots, x^{n}) \mapsto \sum_{i=1}^n x^{i} s_i (p).$$ For the map $f$ in the definition I take the identity, i.e. $f = Id$ . It is clear the map $F$ I constructed is linear. Then I have to show that $\pi \circ F = f \circ \Phi$ . I calculated $$ \pi(F(p, x^{1}, \ldots, x^{n})) = \pi (\sum_{i=1}^n x^{i} s_i (p)) = \sum_i x^{i} \pi (s_i (p)) = \sum_i x^{i} p $$ by definition of what a section is. Since $\Phi$ is the product bundle, it is just projection onto the first factor. Then I get $$ f(\Phi(p, x^{1}, \ldots, x^{n})) = f(p) = p. $$ It seems the diagram doesn't commute, and I don't know where I went wrong. Any help? Also, I don't know how to prove the converse. How do I find this frame of sections, i.e. maps $\sigma_i : M \rightarrow E$ with the desired property?","['vector-bundles', 'differential-geometry']"
2993734,Is it a norm or not? Checking by 3 axioms.,"Task: On the set $C^2[a, b] := \lbrace f: [a, b]\to R \text{ are twice continuous differentiable function} \rbrace$ are defined functions $F_i :C^2[a, b]\to R, i \in\{ 1, 2, 3\}$ . We have 3 specific functions: $$F_1(f)=\max_{a\le t\le b} |f(t)|$$ $$F_2(f)=\max_{a\le t\le b} |f'(t)|$$ $$F_3(f)=\max_{a\le t\le b} |f''(t)|$$ Is it a norm of $C^2[a, b]$ : (a) $\Vert f\Vert =\vert f(b)-f(a)\vert  + F_2(f) + F_3(f)$ (b) $\Vert f\Vert =\vert f(b)\vert+\vert f(a)\vert + F_3(f)$ (c) $\Vert f\Vert = \int_{a}^ b \vert f(t)\vert dt   + F_3(f)$ My solution for (a) is: I need to check 3 axioms: 1) $\Vert f\Vert  \ge 0$ . (it is true because of absolute values) and $\Vert f\Vert  = 0 \iff f=0$ ( here I have some problems to show it is true ). 2) $\Vert \mathcal L f\Vert = \vert\mathcal L \vert \Vert f \Vert$ Proof: \begin{align*}
\Vert \mathcal L f\Vert & = \vert\mathcal L f(b) - \mathcal L f(a) \vert + F_2(\mathcal L f) + F_3(\mathcal L f)\\
& = \vert\mathcal L (f(b) - f(a)) \vert + \mathcal L F_2(f) + \mathcal L F_3(f) \\
&= \vert \mathcal L \vert ( \vert (f(b) - f(a)) \vert + F_2(f) + F_3(f)) \\
&= \vert\mathcal L \vert \Vert f \Vert
\end{align*} So it is true. 3) $\Vert  f+ g \Vert \le \vert f \vert + \vert g \vert$ . True, because of $ F_2(f+g) \le F_2(f) + F_2(g)$ . Question: The same I did with (b) and (c) and my result is that all of them are norms. Is my proof correct? What about (b) and (c)? Maybe I cannot notice something and make mistake? It looks for my strange that I got 3 norms here.","['normed-spaces', 'functions', 'proof-verification', 'functional-analysis']"
2993741,"Can a non-perfect-Polish topology have the same ""sequential convergence structure"" as a perfect Polish topology?","Given a topological space $X$ , by its sequential convergence structure I mean the full information about the convergent sequences in $X$ together with their limits. (I guess to be formal, it is the subset of $X^{\mathbb{N}} \times X$ consisting of all pairs $( ( x_n )_{n=0}^\infty , x )$ such that $x = \lim_{n \to \infty} x_n$ .) It is well-known that a topology is not in general characterized by its sequential convergence structure. For example, if you give an uncountable set $X$ both the discrete and the co-countable topologies, then the convergent sequences are exactly the eventually constant sequences which have the obvious limit. Other examples can be found in the answers to the following question: Is the topology that has the same sequential convergence with a metrizable topology equivalent as that topology? Recall that a topological space $X$ is called Polish if it is separable and completely metrizable. It is called perfect Polish if, in addition, it has no isolated points. The discrete topology on $\mathbb{N}$ is a common example of a Polish space, however it is very far from being perfect Polish (since all points are isolated).  This brings me to my question: Question: Are there examples of topologies $\mathcal{O}_p$ , $\mathcal{O}_n$ on a set $X$ such that $( X , \mathcal{O}_p )$ is a perfect Polish space, and $( X , \mathcal{O}_n )$ is not a perfect Polish space, and $( X , \mathcal{O}_p )$ and $( X , \mathcal{O}_n )$ have the same ""sequential convergence structure""?",['general-topology']
2993773,Show that $BP+BQ=2PQ $,"Let consider a circle of diameter $CA $ and $B\in CA $ such that $A\in [CB] $ and $AB=\frac {CA}{2} $ . If $M \in [CA] $ such that $AM=\frac {CA}{3} $ and $P, Q $ on circle such that $P, M, Q $ collinear. Show that $BP+BQ=2PQ $ My idea. I notice that $M $ is the middle of $[CB] $ . I take the middle of $[CP] $ and $[CQ] $ . Now I am stuck.","['euclidean-geometry', 'circles', 'geometry']"
2993786,Is the function is contraction? How to find fixed point?,"Task 1) Show that function $T:C[0, 1] \to C[0, 1]$ is a contraction, then $$T(f)(x)=\int_{0}^x (x-t) f(t) dt,$$ $$x\in [0,1], f\in C[0, 1].$$ 2) Find a fixed point of $T(f)(x)$ . My progress 1) I have to show that $$\vert T(f)(x)-T(g)(x)\vert \le \mathcal L \vert f - g \vert,$$ $$\mathcal L \lt 1.$$ Solution: $\vert T(f)(x)-T(g)(x)\vert =
\vert \int_{0}^x (x-t) f(t) dt - \int_{0}^x (x-t) g(t) dt \vert = \vert \int_{0}^x (x-t) (f(t) - g(t)) dt \vert \le \int_{0}^x \vert (x-t) (f(t) - g(t)) \vert dt \le \int_{0}^x \vert x-t\vert dt  \int_{0}^x \vert f(t)-g(t)\vert dt = \vert x^2-\frac{x^2}{2} \vert \int_{0}^x \vert f(t)-g(t)\vert dt \le \vert \frac{x^2}{2}\vert \vert f-g\vert$ So $$\vert Tf-Tg \vert \le \vert \frac{x^2}{2}\vert \vert f-g\vert.$$ Then I check if $\vert \frac{x^2}{2}\vert \lt 1.$ If $x\in [0,1]$ , the biggest value I get then $x=1$ and it is $\frac{1}{2}$ . So $\mathcal L \lt 1.$ Question: Is the part 1) correct? And what about part 2)?","['contraction-operator', 'functions', 'functional-analysis', 'fixed-point-theorems']"
2993861,Help constructing a counterexample subset of a non-abelian group,"I am asked whether or not there exists an $r$ such that given any subset $A$ of any group (abelian or not) then: $$|A\cdot A| \leq K|A| \Rightarrow |A\cdot A\cdot A| \leq K^r |A|$$ (where $|A \cdot A| = \{a \cdot b | a,b \in A\}$ ) I suspect that this result is false. However, since we have proved that this result is true when the group is abelian, I am hoping to construct a counter example using non-abelian groups. Specifically I am hoping to find a family of groups $G_n$ and subsets $A_n \subset G_n$ such that $|A_n \cdot A_n| \leq K|A_n|$ but $\forall r, \exists n \in \mathbb N$ such that $|A_n \cdot A_n \cdot A_n| > K^r|A_n|$ . Sadly, I have been unable to construct such a family. Is it possible to find such a counter example or is this result in fact true?","['group-theory', 'discrete-mathematics']"
2993909,Solving differential equation with linearization and Lyapunov method,"For homework, I have to say something about the stability of the zero solution of the differential equation $v''+v+f(v')=0$ ,  where $f$ is a differentiable function satisfying $f(0)=0$ and $f'\geq0$ . I am asked to use the linearization method and if it leads nowhere, then try the Lyapunov method. The second one seems easier, I think that a function of the type $\frac{1}{2}\left ( (v')^{2}+v^2 \right )$ , or something like that including $f$ somehow, will offer a solution. But as far as the first method is concerned, I am stuck. How am I supposed to turn this system in the familiar form $\dot{y}=g(y)$ and linearize it? Any help would be very much appreciated.","['stability-in-odes', 'ordinary-differential-equations', 'dynamical-systems']"
2993984,How to evaluate $\lim_{n\to\infty} \dfrac{1^p+2^p+...+n^p}{n^p}-\frac{n}{p+1}$? [duplicate],"This question already has answers here : Evaluating $\lim\limits_{n\to\infty} \left(\frac{1^p+2^p+3^p + \cdots + n^p}{n^p} - \frac{n}{p+1}\right)$ (7 answers) Closed 5 years ago . $$\lim_{n\to\infty} \dfrac{1^p+2^p+...+n^p}{n^p}-\frac{n}{p+1}\text{ with } p\in\mathbb N$$ I don't really know how to start, I mean... I could try substituting by $\Big(\dfrac{n(n+1)}{2}\Big)^p$ but that would do me anything? Any hints?","['limits', 'limits-without-lhopital', 'analysis']"
2993998,Calculation of valuation ring of a valuation associated to a blowup,"Let $\mathfrak{m} = (x,y) \subset k[x,y]$ . Then the valuation $v$ of $k(x,y)$ associated to the exceptional divisor of the blowup should be defined by $$v(f) = \mathrm{sup}(n|f \in \mathfrak{m}^n), f\in \mathfrak{m}$$ How does one extend $v$ to all of $k(x,y)$ ? The valuation ring $\mathcal{O}_v$ will be the elements with nonnegative valuation. What is good way to represent the elements of $\mathcal{O}_v$ ? How to calculate the residue field $k(v) = \mathcal{O}_v/\mathfrak{m}$ ? How would these calculations differ for blowups at other ideals supported at $\mathfrak{m}$ , like $(x^2,y), (x^3,xy,y^2)$ ? Thank you.","['algebraic-geometry', 'blowup', 'commutative-algebra']"
2994057,What's the meaning of multiplicative errors and additive errors?,"Such skewed, thick-tailed data suggest a model with multiplicative errors instead of additive errors. A standard solution is to transform the dependent variable by taking the natural logarithm. Can anyone explain multiplicative errors and additive errors here? Many thanks in advance!",['statistics']
2994058,Find the tangent line to a curve,"Find the tangent line to the curve $x^2y - y^2 + x = 11$ at the point $(3,1)$ I tried to solve it using parametric equations \begin{cases}
y = t \\[4px]
x = -\dfrac{1}{2t} + \dfrac{\sqrt{1+4t^3 + 44t}}{2t}
\end{cases} and the derivative of $x(t)$ , $y(t)$ , $t= 1$ gives the direction vector $( 5/7 , 1 )$ so the line that passes through $(3,1)$ l: $(3,1) + s(5/7 , 1) $ Is it correct? Because using desmos the line doesn't seem to be tangent to the curve.","['multivariable-calculus', 'tangent-line']"
2994078,"Show the abelianization of braid broup $B_n$,$n\geq 2$ is isomorphic to $\mathbb{Z}$","I need to show that the abelianization of braid group $B_n$ , for $n\geq2$ is isomorphic to $\mathbb{Z}$ , and that the commutator subgroup $[B_n,B_n]$ is exactly the set of braids represented by words with total exponent sum zero in the generators $\sigma_{i}$ . I was able to show all generators $\sigma_i$ are conjugate to each other. Here is the question:","['group-theory', 'braid-groups']"
2994090,"Find $f$ such that : $f$ is absolutely integrable, $f'$ is absolutely integrable and such that $f$ is not $1/2$-Hölder","I am trying to find a function $f: \mathbb{R}^+ \to \mathbb{R}^+$ that fullfils the following conditions $$f \in \mathcal{C}^1(\mathbb{R}^+,\mathbb{R}^+)$$ $$\int_{\mathbb{R}^+} f \in \mathbb{R}^+$$ $$\int_{\mathbb{R}^+} \mid f' \mid \in \mathbb{R}$$ $$f \text{is not $\frac{1}{2}$-Hölder}$$ I've tried functions with smooth spikes but I am unable to express this function as combinations of usual functions. Moreover, I know from this post that if $f'^2$ is integrable then $f$ is necessarily $\frac{1}{2}-$ Hölder. Thank you. Note: all the integrals are taken in the Riemann sense.","['integration', 'real-analysis', 'calculus', 'sobolev-spaces', 'indefinite-integrals']"
2994120,"Solve $2x''\ln (x') =x' \,\, x(0)=1, x'(0)=e$","Solve $2x''\ln (x') =x'  \,\, x(0)=1, x'(0)=e$ . My attempt $p=x' \implies x''=pp'.$ $2pp'\ln p=p$ . $p(2p' \ln p-1)=0$ . We have that $p=0 \implies x(t)=c$ and also that $2p'\ln(p)=1 \implies \int \ln(p)dp=\frac 12 \int dx$ . $p\ln (p)-p=\frac 12x+c$ . In the picture you can See that I try to write in a different form","['initial-value-problems', 'ordinary-differential-equations']"
2994156,Prove that $\prod_{k=2}^{+\infty} (1+1/k^2) = \sinh(\pi)/(2 \pi)$. [duplicate],"This question already has answers here : What is the value of $\prod_{n=1}^\infty (1+\frac{1}{n^2})$? (2 answers) Closed 4 years ago . My attempt 1 : Let $x_n=\left(1+\frac{1}{2^2} + \cdots + \frac{1}{n^2} \right)$ , and we have $x_{n+1}>x_n$ . Since $$
1+\frac{1}{n^2} \le 1+ \frac{1}{(n-1)(n+1)} = \frac{n}{n-1} \cdot \frac{n}{n+1},
$$ then $ x_n < \frac{2n}{n+1} <2$ . Hence $\{x_n\}_{n=2}^{\infty}$ converges. Let $$
\lim_{n \to \infty} x_n =a,
$$ and notice that $x_{n+1}=\left(1+\frac{1}{(n+1)^2}\right)x_n $ . By this, we can only get $a=a$ . We can't know the value of $a$ . My attempt 2 : We write $$
\prod_{k=2}^n \left(1+\frac{1}{k^2} \right)=\exp\left(\sum_{k=2}^n \log\left(1+\frac{1}{k^2}\right)\right)
$$ So it suffices to know what's the limit of the serise on the right. I still don't know how to finish it. Finally,I used Mathematica to calculate the limit, and it tells me that is $\frac{\sinh(\pi)}{2\pi}$ . But I don't know how to know it without computer. Can you help me?","['limits', 'calculus', 'analysis']"
2994161,Proof without words of a simple conjecture about any triangle,"Given the midpoint (or centroid) $D$ of any triangle $\triangle ABC$ , we build three squares on the three segments connecting $D$ with the three vertices. Then, we consider the centers $K,L,M$ of the three squares. My conjecture is that The area of the triangle $\triangle KLM$ is equal to half of the area of the triangle $\triangle ABC$ . This is for sure a well known result (well, if true!). In this case, sorry for the trivial problem! However, It would be great to have suggestions for developing a proof without words of such simple claim (again, if true), i.e. avoiding trigonometry, etc. Thanks for your help! EDIT: The conjecture can be easily extended to any regular polygon built on the described segments (e.g. equilateral triangles yield to $1/3$ of the $\triangle ABC$ area, etc.). EDIT (2): The (extended) conjecture appears to be true also by building the segments starting from the orthocenter (red, left), instead of the centroid (grey, right). The area of the final triangle $\triangle KLM$ is however the same!","['euclidean-geometry', 'triangles', 'geometry', 'geometric-construction']"
2994221,Why should K be closed to ensure X/K is complete?,"If $K$ is a closed subspace of Banach space $X$ , then $X/K$ is complete. But I think the usual proof of this theorem doesn't make use of the fact that $K$ is closed. Would anyone explain it to me? Thanks a lot.",['functional-analysis']
2994234,Minimum of random variables iid,"I have lots of problems trying to solve problems involving maximum and minimum of random variables. For example: Let $X_{1},X_{2},...,X_{n}$ random variables iid and $f_{X}(x)= \frac{1}{x^{2}}$ when $x\geq 1$ and $f_{X}(x)=0$ in other case. My problem is that I have no idea how to deal with the $Z=min\{X_{1},...,X_{n}\}$ , I should be able to find $F_{Z}(z)$ and $f_{Z}(z)$ . Thanks so much in advance for all your help.","['statistics', 'probability']"
2994275,On the integral $I(a)=\int_0^1\frac{\log(a+t^2)}{1+t^2}\mathrm dt$,"Consider the parameter integral $$I(a)=\int_0^1\frac{\log(a+t^2)}{1+t^2}\,{\rm d}t\tag1$$ Where $a\in\mathbb{C}$ . I am struggling to evaluate this integral in a closed-form. However, first of all lets just concentrate on some particular values of $a$ for which I was actually able to evaluate the integral exactly $$\begin{align}
&a=0:&&\int_0^1\frac{\log(t^2)}{1+t^2}\,{\rm d}t=-2G\\
&a=1:&&\int_0^1\frac{\log(1+t^2)}{1+t^2}\,{\rm d}t=\frac{\pi}2\log(2)-G
\end{align}$$ Here $G$ denotes Catalan's Constant. The first case is just one of many integral definitions of Catalan's Constant whereas the second case can be reduced to integrals of this type by the substitution $t=\tan(y)$ . Furthermore WolframAlpha is capable of providing a closed-form for the case $a=-1$ $$a=-1:\int_0^1\frac{\log(t^2-1)}{t^2+1}\,{\rm d}t=\frac{\pi}4\log(2)+\frac{i\pi^2}4-G$$ It seems like the general anti-derivative of the case $a=-1$ can be expressed in terms of the Polylogarithm (the term can be found within the given link but is far to complicated to be included here). For other values of $a$ I was not able to get anything done. I tried to expand the $\log$ and respectively the denominator as a series which ended up in an infinite summation of Hypergeometric Functions $($ of the kind $_2F_1(1,k+1;k+2;-1/3)$ paired with a denominator depending on $k$$)$ I was not able to express explicit. Furthermore I tried to apply Feynman's Trick, i.e. differentiate w.r.t. to $a$ in order to get rid of the $\log$ . The so occurring integral was easily evaluated by using partial fraction decomposition. Anyway I did not managed to find suitable borders for the integration w.r.t. $a$ afterwards. Applying a trigonometric substitution $($ to be precise $t=\tan(x)$$)$ lead to the logarithmic term $\log(1+\cos^2(x))$ which I was not sure how to handle without invoking several powers of the cosine function $($ i.e. by using the Taylor series expansion of the natural logarithm $)$ . The first approach aswell as the last one resulted in an infinite double summation. My knowledge about double sums, especially their evaluation, is quite weak. Maybe someone else is able to finish this up. I have doubts that it is possible to derive an explicit closed-form expression for $I(a)$ . Nevertheless for the case that the upper bound is given by $\infty$ instead of $1$ there actually exists a closed-form expression which makes me curious $$I(a,b,c,g)=\int^\infty_0 \frac{\log(a^2+b^2x^2)}{c^2+g^2x^2}\,{\rm d}x = \frac{\pi}{cg}\log\left(\frac{ag+bc}{g}\right)\tag2$$ I am not familiar with the way this elegant relation was deduced since I just stumbled upon this one within this post . I would highly appreciate an explicit expression for $I(a)$ , maybe similar to the one given for $(2)$ , even though I am not sure whether such a term exists. However, I am especially interested in the case $a=3$ for another integral I am working on  right now. Thanks in advance!","['integration', 'definite-integrals', 'closed-form']"
2994301,"Probability theory - Logic, Notation, simulation","i need some help in probability theory. The thing is im not sure if im thinking about this correctly and if i express my thoughts correctly. I really got lost in all the dice examples of the internet. Let $\ X\ \in \{1,0\} $ a binary outcome. Eg. missing the train in the morning, or not. Let $\ p\ $ be the probability of missing the train. $$
P(X=1) = p
$$ $$
P(X=0) = 1-p
$$ Lets say we use the train $\ n$ times, where each event is independent and identically distributed.
Then im pretty sure that the probability of missing the train at least 1 time is: $$
1-[(1-p)^n]
$$ What is the correct notation for this Probability? This cant be correct: $$
P(X>=1 |\ n\ )
$$ What about the probability of missing the train exactly one time in $n$ events?
I would guess its just $$
P(X=1|\ n \ ) = (1-p)^n \ * \ p
$$ Also is the notation correct here? Now how can i answer this question : ""For which n there is a 100% probability of missing the train?"" and should i use P(""at least one time"" | n ) or P(""exactly one time"" | n ) to answer this question ? Besides the questions above i have one more (less important) question : Is there some kind of distribution which describes this case, given $(p, n)$ and how to simulate a process like this in general. I am using numpy and python.","['notation', 'statistics', 'conditional-probability', 'probability']"
2994404,Hints about the limit $\lim_{x \to \infty} ((1+x^2)/(x+x^2))^{2x}$ without l'Hôpital's rule?,"I've tried to evaluate $\lim_{x \to \infty} \left(\frac {1+x^2}{x+x^2}\right)^{2x}$ as $$\lim_{x \to \infty} \left(\left(\frac {1+ \frac{1}{x^2}}{1+ \frac{1}{x}}\right)^{x}\right)^{2}$$ So the denominator goes to $e^2$ , but I don't know how to solve the numerator, because of the $x^2$ . Any hint? Thanks in advance!","['limits', 'calculus', 'functions', 'limits-without-lhopital']"
2994441,Prove that $n^{-2}\sum_{k=1}^nS_k$ converges in probability,"Let $\{X_n\}$ be a sequence of uncorrelated random variables with common mean $\mu$ , such that $\sup_n$ Var $(X_n)<\infty$ . If $S_n=\sum_{k=1}^n X_k$ , show that $n^{-2}\sum_{k=1}^nS_k$ converges in probability as $n\to\infty$ and identify the limit. I know that using Weak Laws of Large Numbers, it is easily proven that $\frac{S_n}{n}\to\mu$ in $L^2$ , and thus converges to $\mu$ in probability as well. But I'm having trouble using this result to prove that $n^{-2}\sum_{k=1}^nS_k$ converges in probability. I think it would help to know the limit (at least intuitively) to prove this, but I'm a bit stuck on this problem. My attempt: First note that $$\frac{\sum_{k=1}^nS_k}{n^2}\leq\frac{nS_n}{n^2}=\frac{S_n}{n}$$ Then since we know $E(\lvert \frac{S_n}{n}-\mu\rvert^2)\to 0$ , $E(\lvert\frac{\sum_{k=1}^nS_k}{n^2}-\mu \rvert^2)\leq E(\lvert \frac{S_n}{n}-\mu\rvert^2)$ by monotonicity (since expectations are integrals, and monotonicity holds for integals), and thus $E(\lvert\frac{\sum_{k=1}^nS_k}{n^2}-\mu \rvert^2)\to 0$ as $n\to\infty$ . Now using Markov's inequality, I can conclude that $\frac{\sum_{k=1}^nS_k}{n^2}\to\mu$ in probability. I kind of get the feeling that my answer may be incorrect. I would love for someone to provide some hints/point me in the right direction. Thanks","['measure-theory', 'proof-verification', 'probability-theory', 'real-analysis']"
2994446,Show that support function of any set in $\mathbb{R}^n$ is lower semi-continuous function.,"Let $A \subseteq \mathbb{R}^n$ . The support function of set $A$ is defined as the following $$
S_A(x)=\sup_{y \in A} x^Ty
$$ where $x \in \mathbb{R}^n$ . To show it is lower semi-continuous we have two choices. 1- Epi graph of a lower semi-continuous is closed. 2- Show that for any $x_c\in \mathbb{R}^n$ and $\forall \epsilon>0$ and $\forall x \in \mathbb{R}^n$ such that $\|x-x_c\| < \delta$ $\rightarrow$ $$
f(x_c)-\epsilon \leq f(x)
$$ I have tried both: First method: To show $epi(S_A)$ is closed we need to take a convergent sequence $(x_n,t_n)$ in $epi(S_A)$ whose limit point is $(x_l,t_l)$ and show that $(x_l,t_l)$ is indeed in the $epi(S_A)$ . So let $(x_n,t_n)$ be a convergent sequence in $epi(S_A)$ , then $$
\sup_{y \in A} x_n^Ty \leq t_n
$$ If we take the limit we have $$
\lim \sup_{y \in A} x_n^Ty \leq \lim t_n =t_l
$$ How I can show that $\sup_{y \in A} \leq t_l$ using the above statement? Also, how I can proof the lower semi-continuity using the second method?","['metric-spaces', 'semicontinuous-functions', 'functions', 'functional-analysis', 'convergence-divergence']"
2994460,hard exercice in Lieb--Loss Analysis book,"I am looking the solution of the exercice 7.4 in the book Analysis of Lieb--Loss: Suppose that $f\in H^1(\mathbb R^n)$ . Show that for each $1\leq i\leq n$ $$
\int_{\mathbb R^n}|\partial_if|^2=\lim_{t\to 0}\frac{1}{t^2}\int_{\mathbb R^n}|f(x+t\mathbf{e}_i)-f(x)|^2{\rm d}x
$$ where $\mathbf{e}_i$ is the unit vector in the direction $i$ . My approach is to approximate $f\in H^1(\mathbb R^n)$ by a sequence of $C_c^\infty(\mathbb R^n)$ functions. Then we can check the above identity for this smooth with compact support function. But then I do not know how to go back to the function in $H^1(\mathbb R^n)$ .","['sobolev-spaces', 'functional-analysis']"
2994468,"Total probability of a match, where first to $n$ games wins.","In a match between two players A and B, the first to win $n$ games wins the match. Player A wins a game with probability $p$ , the outcomes of each game are independent. (The probability of player B winning a game is $q=1-p$ .) I've found that the probability that A wins the match with a scoreline of $n:k$ is $${n+k-1\choose k}p^nq^k\ .$$ Here is my problem: how to prove that the total probability is $1$ , i.e. $$p^n\bigg[1+{n\choose 1}q+{n+1\choose2}q^2+\cdots+{2n-2\choose n-1}q^{n-1}\bigg]+q^n\bigg[1+{n\choose 1}p+{n+1\choose2}p^2+\cdots+{2n-2\choose n-1}p^{n-1}\bigg]=1?$$ I've tried induction but it seems impenetrable.",['probability']
2994508,Relation between transport functor of a fibration and a Hurewicz connection on it,"Let $A\overset{\alpha}{\rightarrow}B$ be a (Hurewicz) fibration. The homotopy lifting property w.r.t a fiber $\alpha ^{-1}(b)$ furnishes for each path $b\to b^\prime$ in the base a continuous map $\alpha ^{-1}(b)\to \alpha ^{-1}(b^\prime)$ . Moreover, this
assignment extends to a functor $\pi_1B\longrightarrow
   \mathsf{hTop}$ . On the other hand, as a fibration $\begin{smallmatrix}A\\\downarrow\\B\end{smallmatrix}$ admits a Hurewicz connection $s$ . Given such a connection it is tempting to send a path $b\overset{\gamma}{\to} b^\prime $ in the base to the following set function (analogously to covering space theory) $$\alpha^{-1}(b)\longrightarrow \alpha ^{-1}(b^\prime),\quad a\mapsto \operatorname{eval}_1s(a,\gamma).$$ I suspect this set function might be continuous, but I see no reason for it to be a homotopy equivalence, since $s(a,\gamma)$ need not be related in a nice way to lifts of opposite path $b\overset{\bar\gamma}{\leftarrow} b^\prime $ . Questions. Is fiber transport along a Hurewicz connection continuous? (Assuming continuity) Is fiber transport along a Hurewicz connection functorial? (Assuming continuity) Does it coincide with the first transfer functor? Suppose the fibers are all homeomorphic. Are there any interesting conditions that make the transport functor $\pi_1B\longrightarrow \mathsf{hTop}$ lift to $\mathsf{Top}$ ? That is, can we obtain such homeomorphisms via transport? I thought about possible functoriality of the transport along the Hurewicz connection. We want $\operatorname{eval}_1(a,\delta \ast \gamma)=\operatorname{eval}_1s(\operatorname{eval}_1s(a,\gamma),\delta,)$ . We may consider the concatenation $s(\operatorname{eval}_1s(a,\gamma),\delta)\ast s(a,\gamma)$ which seems to lift $\delta \ast \gamma$ , but I'm not quite sure where to go from here. Added. Crossposted to MO.","['general-topology', 'fibration', 'homotopy-theory', 'algebraic-topology']"
2994540,Computing Pontryagin Square,"Suppose $v$ is a $\mathbb{Z}_2$ cochain on a four dimensional spin manifold $M$ , i.e. $v\in H^1(M, \mathbb{Z}_2)$ . I am interested in evaluating the quantity $$\exp \bigg(i \frac{\pi}{2}\int_M \mathcal{P}_2 (v\cup v)\bigg)$$ where $\mathcal{P}_2$ is the Pontryagin square which maps $H^2(M, \mathbb{Z}_2)$ to $H^4(M, \mathbb{Z}_4)$ . My questions are: Is the above quantity in general takes value $\pm 1$ ? I would think so because since $M$ is a spin manifold, any $\int_{M} \mathcal{P}_2 (v\cup v)$ is an even integer, so $\int_{M} \frac{\mathcal{P}_2 (v\cup v)}{2}\in \mathbb{Z}$ is an integer. Hence $\exp(i \pi \mathbb{Z})=\pm 1$ follows. $~$ If the above is correct, do we have the following expression? $$\int_{M} \mathcal{P}_2 (v\cup v)=2\int_{M} v\cup v\cup v\cup v\mod 4 $$ Thanks in advance!","['general-topology', 'group-cohomology', 'homology-cohomology', 'algebraic-topology']"
2994554,Question about Vitali Covering,"Show that the Vitali Covering Lemma does extend to the case in which the covering collection
consists of nondegenerate general intervals. I do not understand what does ""nondegenerate general intervals"" mean exactly. Thank you.","['measure-theory', 'lebesgue-measure']"
2994567,Show that $A^2+2A+5I=0$ has a solution if and only if $n$ is even.,"I have a real square matrix $A$ . I am told to prove that there is $A$ such that $A^2+2A+5I=0$ if and only if $n$ is even. (If $A$ is 6x6, $n=6$ ) I honestly have no clue how to start. Maybe I could turn this into a question with minimal polynomial and use $x^2+2x+5$ . This polynomial doesn't have a root, and it is making me even more confused. Could someone help? Thank you.","['matrices', 'abstract-algebra', 'linear-algebra']"
2994635,General way of solve $ax^2+by+c=0$,"For example ,the diophantine equation $$x^2+1=25y$$ we can solve this by finding particular solution $(x,y)=(7,2)$ and using this , we can get general solution. My question is 
""To solve $ax^2+by+c=0$ $(a, b, c \in \mathbb{Z})$ we must find particular solution or 
not?""","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
2994700,How is the notation $\frac{d}{dx} (f^3)(1)$ interpreted?,"How is the following notation interpreted? $$\frac{d}{dx} (f^3)(1)$$ Does this evaluate to $3\cdot f(1)^2\cdot f'(1) $ , or is it simply the derivative of a constant and equal to 0?","['calculus', 'derivatives']"
2994721,Counting Distinguishable Dominoes,"Pg. 19 of Counting: The Art of Enumerative Combinatorics, George E. Martin How many distinguishable dominoes are there, (each of the 2 ends of a domino has 0 to 6 dots carved on it)? My answer is the following: $\frac{{7+2-1}\choose{2}}{2!}$ I would like to know if this answer is correct and if not what is the correct answer and you was it derived?","['combinatorics', 'discrete-mathematics']"
2994723,"Other ways to find a limit where the denominator produces $0$, besides factoring and cancellation?","So I came across a seemingly innocent looking integral: $$\int_{-2}^1 \frac{1}{x^2}dx$$ Now of course, when taking the antiderivative then plugging in the values, we can see that we get a nonzero/ $0$ which causes problems (because the function is discontinuous). Now to solve this we can split up the integral into two limits, both tending to $0$ from either side: $$\left(\lim_{b\to0^-} \int_{-2}^b \frac{1}{x^2}dx\right) + \left(\lim_{a\to0^+} \int_{a}^1 \frac{1}{x^2}dx\right)$$ This would, in theory, solve the problem except for one issue, the same issue: nonzero/ $0$ when plugging in the numbers to the integral from the limit. So naturally, I thought to try and factor it somehow but within a few seconds, it became obvious that it wasn't possible. So the integral $\int_{-2}^1 \frac{1}{x^2}dx$ diverges Now I'm wondering, is there any way to solve a limit where the denominator would produce $0$ , besides factoring and cancellation? tl;dr: A limit produces $0$ in the denominator and it is unfactorable (in the sense that you cannot cancel out the bottom term). Is there any way to solve it, using another method besides factoring and cancellation?","['integration', 'limits']"
2994725,"Is there a categorification of ""(virtually) solvable""?","If this question doesn't make sense or is otherwise poor quality, then I'm sorry. Motivation: As part of my research, I study virtually solvable (1) groups. These are goups that have a solvable subgroup of finite index. I am interested in looking at this group theoretic property from a wider perspective to see if I can get inspiration for proving various things about virtually solvable groups. The Question: What would be a categorification of the property of being (virtually) solvable for groups? Thoughts: I think that if I have a categorification of solvable, then a categorification of virtually solvable would follow by using things like subobjects. Whether or not I could form such a definition would depend on the nature of the first categorification. A good place to start might be group extensions , which, as far as I understand, are categorical; they're essentially short exact sequences . In fact, I think the latter (with a few bells & whistles) are pretty much a categorification of ""solvable"" anyway but I'm not sure. My understanding of these is minimal though. I would appreciate help with them. Some Extra Context: I'm completely self-taught when it comes to category theory. However, I have asked some questions of modest difficulty about category theory here on MSE in the past and the answers seem to make sense to me. Please help :) (1) See the ""Related Concepts"" section of the article linked to.","['categorification', 'category-theory', 'normal-subgroups', 'group-theory', 'solvable-groups']"
2994732,Representing a Banach space as a function space,"When I think about a vector space, I like to see them as spaces of parameters. Although finite dimensional spaces have been generalized to Banach spaces, I see function spaces as the best generalization, at least heuristically, for a space of parameters. Given the function space $L^p(X,\Omega,\mu)$ , for simplicity $L^p(X)$ , the set of Dirac's deltas at each point works as a kind of canonical base, so when we choose a function, we are specifying somehow $|X|$ number of parameters; $|X|$ is the cardinality of $X$ . My first question is: what are sufficient and necessaries conditions for a Banach space to be a function space? To be more precise: When is a Banach space $B$ isometric to some space $L^p(X)$ ? (isometric representation) When is there a linear isomorphism between $B$ and some $L^p(X)$ , that is, a linear operator $A:B\to L^p(X)$ such that $c\lVert x\rVert_B\le \lVert Ax\rVert_{L^p}\le C\lVert x\rVert_B$ ? (continuous representation) When is there a space $X$ and a continuous operator $A:C_c(X)\to B$ , such that $A$ is 1-1 and the image of $A$ is dense? $C_c(X)$ is the space of compactly supported functions on $X$ ; we can endow it with the usual topology. (weak representation) The definition I like the most is the third, I think it's the weaker. The first two definitions involve $L^p$ spaces, and they are not the sole function spaces out there, so these definitions are incomplete. Can you imagine a weaker way of representing a Banach space? If $B$ is a Hilbert space, take an orthonormal expansion, so every vector is $f=\sum_{i\in I} f(i)e_i$ and we have an isometric representation with $L^2(I)$ , but this is not the most appealing representation, and it leaves more questions. What can we say about $X$ ? If you take $L^2(\mathbb{R}^n)$ , you can use a partition of unity and Fourier series to write every function $f$ as a sum $\sum_{i\in I} f(i)e_i$ , where $I$ is countable and the $e_i$ form an orthonormal base. But, what is then the difference between $L^2(\mathbb{R}^2)$ and $L^2(\mathbb{R})$ ? Doesn't the structure of the space $X$ matter? I feel uneasy. Many times in my work I have encountered operators like $A:L^p(X)\to L^q(Y)$ , where $X$ and $Y$ are topological spaces of dimensions $N$ and $M$ , respectively; for simplicity, suppose that $A$ is injective. Heuristically I apply the finite dimensional logic, for example take $N=M$ , and I think: the cokernel of $A$ is like a ""tiny"" function space, compared with $X$ or $Y$ , over a topological space $Z$ of dimension $<M$ . And I'm ""always"" right, I can even guess properties of the function space $Z$ , like $\text{dim}(Z)$ , from topological properties of $X$ and $Y$ . Then, what does it happen with $L^2(\mathbb{R}^n)$ ? Can we, under additional assumption, prove a kind of invariance of domain theorem for function spaces? It may help the reader to think about the operator $\iota:C_c(\mathbb{R})\to C_c({\mathbb{R}^2})$ , given by $\iota f(x,y)\mapsto f(x)\varphi(y)$ , where $\varphi$ is supported near to zero, and the quotient $C_c({\mathbb{R}^2})/\iota C_c(\mathbb{R})$ ; we can think that the dimension of the cokernel is "" $\mathbb{R}^2-\mathbb{R}\approx \mathbb{R}^2$ "".","['banach-spaces', 'functional-analysis']"
2994751,Prove $\int^{\infty}_{-\infty}\frac{1}{(x^2+x+1)^3}dx=\frac{4\pi}{3\sqrt3}$.,"I have no idea how to do this question. I'm given $\int^{\infty}_{-\infty}\frac{1}{x^2+2ax+b^2}dx=\frac{\pi}{\sqrt{b^2-a^2}}$ if $b>|a|$ and I'm asked to prove $\int^{\infty}_{-\infty}\frac{1}{(x^2+x+1)^3}dx=\frac{4\pi}{3\sqrt3}$ . What I've tried: $\int^{\infty}_{-\infty}\frac{1}{(x^2+x+1)}dx=\frac{2\pi}{\sqrt3}$ . I've tried setting a variable as the power, ie: $I(r)=\int^{\infty}_{-\infty}\frac{1}{(x^2+x+1)^r}dx$ but differenciating the inside w.r.t to $r$ doesn't seem to form any differential equation that can be solved. Answers and hints appreciated!","['integration', 'calculus']"
2994784,Random Variable with Characteristic function $\frac{1}{2-\phi(t)}$,"I am given that $X$ has c.f. $\phi(t)$ , I need to find the random variable whose c.f. is equal to $\frac{1}{2-\phi(t)}$ in terms of $X$ . My idea is that express $\frac{1}{2-\phi(t)}$ as a series, since $|\phi(t)| \leq 1$ so we have $$
\frac{1}{2-\phi(t)} = \sum_{n = 0}^{\infty}\frac{\phi(t)^n}{2^{n+1}}
$$ From the question asked here , I am guessing that this c.f. corresponds to the random variable (I may be wrong): $$
Z = \sum_{n = 0}^{\infty}I(A = n)Z_n
$$ where $P(A = n) = \frac{1}{2^{n+1}}, \ n = 0,1,2,...$ and $Z_n = \sum_{i = 1}^{n}Y_i$ , $Z_0 = 0$ , $Y_i$ are iid r.v.'s s.t. $Y_i \sim X$ . But I don't know how to prove this, can anyone point out a general direction? Thanks so much!","['characteristic-functions', 'probability']"
2994798,"Is a function's derivative continuous on $(a,b)$ if it is injective on $[a,b]$?","Say a differentiable function $f: I \rightarrow \mathbb{R}$ is defined on an open interval $I$ , and there is a closed bounded interval $[a,b] \subseteq I$ . If $f'$ is injective on $[a,b]$ , is it continuous on $(a,b)$ ?","['calculus', 'derivatives', 'real-analysis']"
2994829,Finding number of solutions when condition is given.,"Q - Find number of solutions when it is given that Re(z²) = 0 and |z| = a $\sqrt{2}$ , where z is a complex number and a>0. First I assumed $z = x + iy$ and then squared it and equated the real part to $0$ .
I don't know how to approach after that. 
Please guide.","['complex-analysis', 'complex-numbers']"
2994849,Complex Polynomial Inequality Proof,"I'm trying to solve this question but I am having trouble connecting the dots. The question reads: Assume that we have a complex polynomial: $$P(z) = a_0+a_1z+...+a_nz^n$$ Satisfies $|P(z)|\leq 1$ whenever $|z|=1$ . Show that $|a_n|\leq 1 \>\>\forall n$ . So, I have simplified $|P(z)|\geq|a_n|\left|1-\frac{|a_{n-1}|}{|a_n|} -...-\frac{|a_0|}{|a_n|}\right|$ , using the fact that $|z|=1$ . Now, I'm confused by how to proceed. There's no indication that the sequence is decreasing? Am I on the right track?","['complex-analysis', 'sequences-and-series']"
2994854,"Non linear differential equation , instead of y it is $ y^2$","$$ \frac{dy} {dx}  +x \sin ^2 y = x ^3 \cos ^2 y$$ I attempted like this, divide by $ \cos ^2y$ and putting $\tan x = t$ it converted to $$ \frac{dt} {dx}  + x t ^ 2 = x ^3 $$ now it is not LDE of first order so i am not able to use INTEGRATING FACTOR method. how to further solve?","['integration', 'calculus', 'ordinary-differential-equations']"
2994865,Stability of a Degenerate Equilibrium Point in a Planar ODE,"Consider the planar ODE $\dot x_1 = x_2$ $\dot x_2 = - x_1^2 - 2 x_1 - 1$ Obliviously, $(x_1,x_2)=(-1,0)$ is an equilibrium point. The Jacobian matrix at this point is $$J = \begin{bmatrix} 
0  & 1 \\
0  & 0 
\end{bmatrix}$$ Thus, linearizarion fails in determining the stability. How can we determine the stability of this equilibrium point?","['control-theory', 'ordinary-differential-equations', 'dynamical-systems']"
2994899,Angles of triangle $\triangle XYZ$ do not depend on the position of point $P$ (proof needed),"Let $ABCD$ be a fixed convex quadrilateral and $P$ be an arbitrary point. Let $S,T,U,V,K,L$ be the projections of $P$ on $AB,CD,AD,BC,AC,BD$ respectively. Let $X,Y,Z$ be the midpoints of $ST,UV,KL$ . Is it true that the angles of triangle $\triangle XYZ$ do not depend on the position of $P$ ? I drew a figure on my computer and it seems that the angles of triangle $\triangle XYZ$ do not change with the position of point P: (my original research)","['euclidean-geometry', 'quadrilateral', 'geometry', 'triangles', 'geometric-transformation']"
2994929,Prove $\tan\frac\pi{16}+2\tan\frac\pi8+4=\cot\frac{\pi}{16}$,"Prove that $\tan\dfrac{\pi}{16}+2\tan\dfrac{\pi}{8}+4=\cot\dfrac{\pi}{16}$ My Attempt \begin{align}
&\tan\dfrac{\pi}{16}+2\tan\dfrac{\pi}{8}+4=\dfrac{1}{\cot\dfrac{\pi}{16}}+\dfrac{2}{\cot\dfrac{\pi}{8}}+4\\
&=\dfrac{1}{\cot\dfrac{\pi}{16}}+2\dfrac{2\cot\dfrac{\pi}{16}}{\cot^2\dfrac{\pi}{16}-1}+4=\dfrac{\cot^2\dfrac{\pi}{16}-1+4\cot^2\dfrac{\pi}{16}+4\cot^3\dfrac{\pi}{16}-\cot\dfrac{\pi}{16}}{\cot\dfrac{\pi}{16}(\cot^2\dfrac{\pi}{16}-1)}\\
&=
\end{align} I don't think its going anywhere with my attempt, Is there an easy way to prove this ? I have checked a similar post Reducing $\tan\frac{\pi}{16} + 2\tan\frac{\pi}{8}+4$ to $\cot\frac{\pi}{16}$ , but as it was a multiple choice question hope there \d be any direct way to solve this.",['trigonometry']
2994933,Is a random vector multivariate normal if and only if every linear combination of its coordinates is normal?,The first sentence of this Wikipedia article ( https://en.wikipedia.org/wiki/Gaussian_process ) seems to imply that a vector of random variables is multivariate normal if (and only if) every linear combination of its coordinates is normal. (I know the only if part is true) Is the if part true? How can one prove it? Thanks!,"['probability-distributions', 'linear-algebra', 'probability-theory', 'normal-distribution']"
2994938,Is the limit of a strictly increasing function always $\infty$?,"If $f(x)$ is strictly increasing, is $\lim_{x\to\infty} f(x) = \infty$ ? Also is $\lim_{x\to -\infty} = 0?$ I think the answer is yes.
A good example is $e^{x}$ . I don't know how to show this claim though. Is it true?","['limits', 'calculus']"
2994982,Using Laplace Transforms to solve $\int_{0}^{\infty}\frac{\sin(x)\sin(x/3)}{x(x/3)}\:dx$,"So, I've come across the following integral (and it's expansion) many times and in my study so far, Complex Residues have been used to evaluate it. I was hoping to find an alternative approach using Laplace Transforms. I believe the method I've taken is correct, but I'm concerned there may certain theorems/tests I should have applied first $$I = \int_{0}^{\infty} \frac{\sin\left(\frac{x}{1}\right)\sin\left(\frac{x}{3}\right)}{\left(\frac{x}{1}\right)\left(\frac{x}{3}\right)}\:dx$$ The first step is to make a slight change of variable $x = 3u$ , which gives us $$I = \int_{0}^{\infty} \frac{\sin\left(3u\right)\sin\left(u\right)}{u^2} \: du $$ Here I employ the Feynman Trick but with two variables, i.e. $$I(a,b) = \int_{0}^{\infty} \frac{\sin\left(3ua\right)\sin\left(ub\right)}{u^2}\: du$$ Take the Laplace Transform w.r.t ' $a$ ' $$\mathscr{L}_{a} \left[I(a,b)\right] = \int_{0}^{\infty} \frac{\mathscr{L}_{a}\left[\sin\left(3ua\right)\right]\sin\left(ub\right)}{u^2}\: du = \int_{0}^{\infty} \frac{3u\sin\left(ub\right)}{\left(s^2 + 9u^2\right)u^2}\: du $$ Or $$ \overline{I}(s,b) = \int_{0}^{\infty} \frac{3\sin\left(ub\right)}{\left(s^2 + 9u^2\right)u}$$ Now apply the Laplace Transform w.r.t ' $b$ '. Here $\omega$ will be used as the alternate ' $s$ ' variable. Hence we arrive at $$ \mathscr{L}_{b}\left[\overline{I}(s,b)\right] = \int_{0}^{\infty} \frac{3\mathscr{L}_{b}\left[\sin\left(ub\right)\right]}{\left(s^2 + 9u^2\right)u}\:du =  \int_{0}^{\infty} \frac{3u}{\left(s^2 + 9u^2\right)u\left(\omega^2 + u^2\right)}\:du $$ Or $$\overline{\overline{I}}\left(s,\omega\right) = \int_{0}^{\infty} \frac{3}{\left(s^2 + 9u^2\right)\left(\omega^2 + u^2\right)}\:du = \frac{3\pi}{2s\omega}\left(\frac{1}{s + 3\omega} \right)$$ In no specific order we now take the Inverse Laplace Transform w.r.t. ' $\omega$ ' $$\overline{I}\left(s,b\right) = \mathscr{L}_{\omega}^{-1}\left[\frac{3\pi}{2s\omega}\left(\frac{1}{s + 3\omega} \right) \right] = \frac{3\pi}{2}\left[\frac{1}{s^2} - \frac{e^{\frac{sb}{3}}}{s^2}\right]$$ We now take the Inverse Laplace Transform w.r.t. ' $s$ ' $$I(a,b) = \frac{3\pi}{2}\mathscr{L}_{s}^{-1}\left[ \frac{1}{s^2} - \frac{e^{\frac{sb}{3}}}{s^2}\right] = \frac{3\pi}{2}\left[a - \left(a - \frac{b}{3} \right)\mathcal{H}\left(a - \frac{b}{3}\right) \right]$$ And so, $$I = I(1,1) = \frac{3\pi}{2}\left[1 - \left(1 - \frac{1}{3} \right)\mathcal{H}\left(1 - \frac{1}{3}\right) \right] = \frac{\pi}{2}$$ As required. Is this a stroke of luck? or is it just employing the Dominated Convergence Theorem and Fubini's Theorm (as I believe is valid here).","['integration', 'inverse-laplace', 'definite-integrals', 'laplace-method', 'laplace-transform']"
2995015,"Kernel of a zero diagonal, non-negative symmetric matrix","Let $A\in M^n(\mathbb{R})$ a symmetric matrix with zero principal diagonal and with strictly positive off-diagonal entries. What is the highest possible dimension of $\,\mathbf{Ker(A)}$ ? When $n=2,3$ it turns out that $A$ is invertible. If $n=4$ then $A$ can be singular, with $dim(Ker(A))=1$ . I would like to understand if there is a method to study the case of a generic $n$ . Thank you for any suggestion.","['matrices', 'linear-algebra']"
2995025,Is it possible to prove Fubini’s Theorem without Dynkin’s Theorem or the Monotone Class Theorem?,"Fubini’s Theorem for Lebesgue integrals states that if $X$ and $Y$ are Sigma-finite measure spaces then the integral of a (well-behaved) function $f(x,y)$ with respect to the product measure on $X\times Y$ is equal to the iterated integral of $f$ with respect to the measure on $X$ and the measure on $Y$ . The standard way to prove Fubini’s theorem is to prove it first for characteristic functions, then for simple functions, then for non-negative measurable functions, etc. The hard part is proving it for characteristic functions.  You first prove it for characteristic functions of measurable rectangles, i.e. Cartesian products of measurable sets in $X$ and measurable sets in $Y$ . Then you have to somehow use that to prove it for characteristic functions of all measurable sets in the product measure space.  This is usually done using one of two theorems: Dynkin’s pi-lambda theorem , which states that if a pi-system of sets is contained in a lambda-system of sets, then the sigma algebra generated by the pi-system is also contained in the lambda system. Halmos’ monotone class theorem , which states that if an algebra of sets is contained in a monotone class of sets, then the sigma algebra generated by the algebra is also contained in the monotone class. Both these theorems apply because the collection of measurable rectangles is both a pi-system and an algebra, and the collection of sets whose characteristic functions satisfy Fubini’s theorem is both a lambda-system anda monotone class. My question is, is it possible to prove Fubini’s theorem without using either of these results?  I assume that there would be some way, considering that Fubini proved his theorem long before Eugene Dynkin and Paul Halmos were even born.","['measure-theory', 'lebesgue-integral', 'alternative-proof', 'multiple-integral', 'math-history']"
2995030,Verifying $\int_1^x t^{-1} dt = \ln|x|$ by Riemann sums definition of integral,"My objective is evaluate the integral $\int_1^x t^{-1} dt$ using the Riemman sums definitions: $\int_{a}^{b}f(x)dx = \lim_{n \to \infty} \sum_{k=1}^{n} f(x_k^*) \Delta x$ , where a partition of $[a,b]$ is chosen. $[1,x] = \displaystyle \bigg[1,1+\frac{x-1}{n}\bigg]\cup\bigg[1+\frac{x-1}{n},1+\frac{2(x-1)}{n}\bigg]\cup ... \cup\bigg[1+\frac{(n-1)(x-1)}{n},x\bigg]$ , $\displaystyle\Delta x = \frac{x-1}{n}$ , $\displaystyle x_k^*=1+k\frac{x-1}{n}=\frac{n+kx-k}{n}$ Then: $\displaystyle\int_{1}^{x} \frac{1}{t} dt = \lim_{n\to\infty}\sum_{k=1}^{n}\frac{1}{x^*_k}\Delta x=\lim_{n \to \infty}\sum_{k=1}^{n}\bigg( \frac{n}{n+kx-k}\bigg)\frac{x-1}{n}=\lim_{n \to \infty}\sum_{k=1}^n\frac{x-1}{n+kx-k}$ I already verified in Wolfram that the last limit indeed equals to $\ln|x|$ , but I do not know how to evaluate it. Solving the summation first also seems complicated, as Wolfram shows digamma functions... is there a better way to avoid this obstacle, maybe changing the partition? But if there is a way of solving this limit I would also appreciate. Thanks.","['integration', 'logarithms', 'real-analysis', 'calculus', 'riemann-integration']"
2995054,"$\cos^8x.\sec^6y,\frac12,\sin^8x.\csc^6y$ in AP if $\cos^4x.\sec^2y,\frac12,\sin^4x.\csc^2y$ in A.P","If $\cos^4x.\sec^2y,\dfrac{1}{2},\sin^4x.\csc^2y$ are in A.P, then prove that $\cos^8x.\sec^6y,\dfrac{1}{2},\sin^8x.\csc^6y$ in AP. My Attempt $$
\cos^4x.\sec^2y+\sin^4.x\csc^2y=\frac{\cos^4x}{\cos^2y}+\frac{\sin^4x}{\sin^2y}=1\\
\implies\sin^2y.\cos^4x+\cos^2y.\sin^4x=\sin^2y.\cos^2y
$$ $$
\cos^8x.\sec^6y+\sin^8x.\csc^6y=\frac{\cos^8x}{\cos^6y}+\frac{\sin^8x}{\sin^6y}
$$ How do I know that the given terms are in A.P, G.P or H.P ?",['trigonometry']
2995069,Conformal mapping maps the unit disc in a convex domain.,"Statement of the problem: For the conformal mapping $f:\mathbb{D}\to\mathbb{D}$ , we suppose that the domain $f(\mathbb{D})$ is convex. Prove that for $\mathbb{D}_r=\{z\in \mathbb{C}:|z|<r\}$ the domain $f(\mathbb{D}_r)$ is convex My approach: I considered the function $$g(z)=f^{-1}(tf(z)+(1-t)f(0)), t\in[0,1]$$ This function is holomorphic , maps the unit disc to itself, and $g(0)=0$ . So we can apply Schwarz's lemma. After using it, we have that $$|f^{-1}(tf(z)+(1-t)f(0))|\leq|z|$$ which means that $$g(\mathbb{D}_r)\subset \mathbb{D}_r,\Longrightarrow f^{-1}(tf(z)+(1-t)f(0))\in \mathbb{D}_r \Longrightarrow tf(z)+(1-t)f(0) \in f(\mathbb{D}_r)$$ so all of these line segments belong to our domain, but in order to show that the domain is convex I need to prove that this happens for every $f(z),f(w)$ and not only for $f(z),f(0).$ At this stage I considered the function $$\phi^{-1}\circ g\circ \phi:\mathbb{D}\to \mathbb{D}, \phi(z)=\frac{z-w}{1-\bar{w}z},z,w \in \mathbb{D}$$ and i applied Schwarz's lemma again and I tried to prove it for all $z,w \in \mathbb{D}$ but got stuck. I would be grateful if you give me just the smallest possible hint and not a whole solution. Thanks in advance",['complex-analysis']
2995166,Are second-countable metric spaces $\sigma$-compact?,"I was curious about the relations between second-countable, separable, Lindelöf and $\sigma$ -compact topologies in the context of metric spaces. I am aware of the following implications in general topological spaces: second-countable $\Rightarrow$ separable $\not \Rightarrow$ Lindelöf, $\;$ [thanks bof ] $\sigma$ -compact $\Rightarrow$ Lindelöf second-countable + locally compact $\Rightarrow$ $\sigma$ -compact as well as the reversed implications in the case of metric spaces: Lindelöf $\Leftrightarrow$ separable $\Leftrightarrow$ second-countable Since all the proofs I've seen so far require the LC condition I assume it is not true in general that second-countable topological spaces are $\sigma$ -compact (although seeing an actual counterexample would be nice). So what about metrizable topological spaces? Ideas so far: If we can proof that every subset of a $\sigma$ -compact space is again $\sigma$ -compact, then this would follow from the fact, that every separable metric space is homeomorphic to a subset of the Hilbert cube (which is compact). $\;$ [debunked by bof ]","['general-topology', 'metric-spaces']"
2995192,How to understand this example in Do Carmo?,"I'm reading the book $Riemannian$ $Geometry$ written by Do Carmo. Here is an example in which I cannot understand the explanation he gave. I really don't understand what he said about why $\alpha$ is not an embedding...
No worry about my knowledge on topology. Can anyone help me “translate” it to the common language that's easy to understand?","['curves', 'general-topology', 'riemannian-geometry', 'differential-geometry']"
2995208,"If $g(x)\in \mathbb{Z} [x]$, $g(x)=a^{k}$ for all $x\in\mathbb{Z}$ and a fixed $k\in\mathbb{N}$ then $g(x)=h^{k}(x)$","I've been trying to prove this using Hilbert's Irreducibility Theorem for a while now. I have proved the case for $k=2$ as follows:
 Suppose $g(x)\in\mathbb{Z}[x]$ is a perfect square for all integer values $x$ . Let $f(x,t)=y^{2}-g(x)$ . Note that we either have that $f$ is irreducible, in which case we have $$f(x,y)=y^{2}-g(x)$$ or $f$ is reducible, giving $$f(x,y)=(y-A(x))(y-B(x))$$ for some functions $A(x),B(x)\in\mathbb{Z}[x]$ . Expanding out the latter case we get the following: \begin{equation*}
\begin{split}
y^{2}-g(x) & = (y-A(x))(y-B(x)) \\
 & = y^{2}-(A(x)+B(x))y+A(x)B(x).
\end{split}
\end{equation*} Comparing $y$ coefficients we deduce that $A(x)=-B(x)$ , thus \begin{equation*}
\begin{split}
y^{2}-g(x) & = (y-A(x))(y-A(x)) \\
 & = y^{2}+A^{2}(x) 
\end{split}
\end{equation*} $$\implies g(x)=A^{2}(x)$$ Now suppose $f(x,y)=y^{2}-g(x)$ is irreducible. Then by Hilbert's Irreducibility Theorem there exist infinite $x_{0}$ such that $f(x_{0},y)=y^{2}-g(x_{0})$ is irreducible in $\mathbb{Q}[y]$ . By definition of $g(x)$ we have that $g(x_{0})=a_{0}^{2}$ for some $a_{0} \in \mathbb{Z}$ and hence $$f(x_{0},y)=y^{2}-a_{0}^{2}=(y-a_{0})(y+a_{0})$$ which is reducible in $\mathbb{Z}[y]$ giving a contradiction. Thus $g(x)=h^{2}(x)$ for some $h(x)\in \mathbb{Z}[x]$ When trying to generalise this to higher $k$ , I can only seem to get a result if $y^{k}-g(x)$ has a linear factor in $y$ , i.e. $$f(x,y)=(y-h(x))(y^{k-1}+g_{k-2}(x)y^{k-2}+\ldots+g_{1}(x)y+g_{0}(x))$$ for some $h(x),g_{i}(x)\in \mathbb{Z}[x]$ . We can then use induction to find $g(x)=h^{k}(x)$ . My arguement seems to break down for $k=4$ as if $$y-g(x)=(y^{2}+A(x)y+B(x))(y^{2}+C(x)y+D(x))$$ Then we find $g(x)=B^{2}(x)$ but this does not seem to show that $g(x)$ is a 4th power of another polynomial. Is my method too specific to generalise this for $k=5$ and above or am I just missing a trick to make the whole proof fit together?
Other answers on here have refered to the paper ""Polynomials of certain special types"" by Davenport, Lewis, Schinzel but the results in this are slightly too general to help with my understanding of this problem.","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'polynomials']"
2995273,"What method for mentally computing 2-digit multiplication problems, minimizes the amount of mental steps?","So I've been practicing alot of mental math recently and ofcourse as a part of that, multiplying a double-digit number by another double-digit number. I have been doing some research into what the quickest way to computing the outcome of such a multiplication is but I still find myself having to go through too many steps in my head for each exercise. The goal is to have someone tell you a problem and then, without having them repeat the problem, computing the answer. Let's take as an example: $63*88$ I will go over multiple methods that I know for computing this mentally, and explain my problems with each of them. 1) The elementary method. I think this is the first method of multiplying that everyone learns. It finds the answer by brute force multiplication and addition. Using this method on our example exercise would mean we take the following steps: First simplify the left factor and multiply it with the complete right factor, yielding: $60*88=60*80+60*8=4800+480=5280$ Then multiply the remaining $3$ with our right factor and add it to the result above, yielding: $3*88=264 \rightarrow 5280+264=5544$ It immediately becomes clear that this method takes too long and can turn into quite a complicated mess, because you have to quickly combine non-trivial multiplication and addition. With this method you have to memorize the problem, then the outcome of the first multiplication, then do the second multiplication and remember all outcomes in order to add them together. We could think of every ' $=$ ' sign as a mental step. 2) The second method comes from a branch called Vedic math. On paper this way of multiplying looks more complicated but with slight practice it becomes apparant that it's much quicker. It works like this: First multiply the two right most digist with eachother, yielding: $3*8=24$ We carry the $2$ and the $4$ is the last digit of our final answer. We then do a cross multiplication where we multiply the right digit of the second factor by the left digit of the first factor and vice versa, and add the outcomes together (not forgetting the carried $2$ ), yielding: $8*6+8*3+2=48+24+2=74$ From this we see that our second to last digit is also $4$ , and we will again carry the $7$ . For the last step we multiple the left digit of the first factor with the left digit of the right factor (not forgetting our carried $7$ ). This gives: $6*8+7=48+7=55$ We now know that our first two digits are $5$ and $5$ , yielding our total answer of $5544$ Again, on paper this looks like many more steps than the brute force method but its much easier to keep track of the things you have to remember for the final answer. 3) An optional third method could be similar to the above method but instead of doing the cross multiplication as a second step, we do it as our first step and then do the original first step. I would imagine opinions on whether this is really quicker are divided but it helps with limiting the amount of calculations to remember. 4) Finally, the standard method could be to round up one of the factors to the nearest ten multiple and then subtracting whatever excess you added. In this case that would yield: $63*90=5670 \rightarrow 5670-2*63=5544$ This method becomes much more complicated however when we try to compute something like $44*86$ because rounding to the nearest ten leaves us with much more excess. Maybe the answer to my relatively broad question is simply: ""fast multiplication comes from experience"". However, I'm very curious to hear any other methods that are out there. Apologies for the long post but I hope I clarified my thought process enough.","['mental-arithmetic', 'algebra-precalculus', 'soft-question', 'arithmetic']"
2995335,How is the differential of a Sobolev function on a manifold regarded as an a.e. defined section of $T^*M$?,"Let $(M,g)$ be a smooth compact Riemannian manifold , and let $f \in W^{1,p}(M)$ for $p\ge 1$ . (I don't assume $p>\dim M$ ). I have seen in various sources that people refer to the weak derivative of $f$ as a linear functional $T_pM \to \mathbb{R}$ , which is defined for almost every $p \in M$ . (an a.e.defined section of $T^*M$ ). How exactly is this object defined? I couldn't find any precise details about this. I define $W^{1,p}(M)$ to be the completion of the space of compactly supported smooth functions $C_c^{\infty}(M)$ w.r.t the $\|\cdot\|_{1,p}$ norm. Optional: I suggest below $2$ approaches; I would like to know if they are compatible, i.e. if they both produce the same element in $(T_pM)^*$ . (Regarding the second approach, I am not even sure if it produces a well-defined functional). Approach 1: Given $f \in W^{1,p}(M)$ , there exist $f_n \in C_c^{\infty}(M)$ , $f_n \to f$ in $W^{1,p}$ . $df_n \in \Gamma(T^*M)$ is a Cauchy sequence in $L^p(M,T^*M)$ , where $L^p(M,T^*M)$ is the completion of the space of smooth sections $\Gamma(T^*M)$ w.r.t the natural $p$ -norm. By completeness, $df_n$ converges to an element in $L^p(M,T^*M)$ , which we can realize as a measurable section $T^*M$ . We set $df=\lim_{n \to \infty} df_n$ . Approach 2 (""Local picture""): Let $\phi:U\subseteq M \to \mathbb{R}^n$ be a surjective coordinate chart around $p \in M$ , and $\phi(p)=0$ . Set $f_{\phi}=f|_U \circ \phi^{-1} :\mathbb{R}^n \to \mathbb{R}$ . Then $f_{\phi} \in W^{1,p}(\mathbb{R}^n)$ (we might need to shrink $U$ to ensure nothing will explode). We define $df_p$ by the equation $$ df_p \circ d(\phi^{-1})_0(e_i):= d(f_{\phi})_0(e_i)=(\partial_i f_{\phi})(0). \tag{1}$$ Does equation $(1)$ well-defines an element in $T_p^*M$ independently of the coordinate chart?  Does it coincide with $\lim_{n \to \infty} df_n$ from the previous approach?","['smooth-manifolds', 'sobolev-spaces', 'differential-topology', 'weak-derivatives', 'differential-geometry']"
2995441,Laplace transform of exponential distributed random varibale,Let $T\sim Exp(\lambda)$ . I want to calculate the laplace transform $$E[e^{-\delta T}]$$ So far I get $$E[e^{-\delta T}]=\int_0^\infty e^{-\delta x}\lambda e^{-\lambda x}dx=\lambda\int_0^\infty e^{-(\delta+\lambda) x}dx=\lambda\cdot\bigg[-\frac{1}{\delta+\lambda}e^{-(\delta+\lambda)x}\bigg]_0^\infty=\frac{\lambda}{\delta+\lambda}$$ Is this right?,"['probability-theory', 'functional-analysis', 'probability']"
2995453,Rhythm combinations in a 16 notes bar. [duplicate],"This question already has answers here : Musical and combinatorial proof (2 answers) Closed 5 years ago . How many combinations are possible between a note-event and a silence-event (i.e. a played note and a pause) over 16 consecutive beats? In other words, if one musical bar is divided into 16 parts (16th notes) of equal duration, filled with either a sound or a silence, how many combinations of the two are possible within the given structure of 16 events? I hope this is clear enough...sorry, musician here, therefore almost completely unprepared to approach the question. I am not even sure if I am asking about combinations or permutations. An example: (1= sound 0= pause) . 1000 0010 0011 0011 1111 0000 0111 1010",['combinatorics']
2995507,"Find a function $f$ analytic at $x_{0} = 0$ so that $f\left(\frac{1}{n}\right) = \frac{n}{n + 1}, n = 1, 2, \ldots$.","I am learning about real analytic functions on my own right now. I've been 
 having trouble with one of the exercises, and it isn't much help that most of the resources online for analytic functions are for Complex Analysis. I am talking about real analytic functions. For reference, here is a definition that I have been using: A real function $f(x)$ is analytic at $x_{0}$ if there is a $r > 0$ : $$f(x) = \sum_{n = 0}^{\infty} a_{n}(x - x_{0})^{n}, |x - x_{0}| < r$$ i.e. there is some power series which converges to the function. Using this definition, I want to solve the following exercise problem: Find a function $f$ analytic at $x_{0} = 0$ so that $f\left(\frac{1}{n}\right) = \frac{n}{n + 1}$ , $n = 1, 2, \ldots$ . Show that such a function cannot be analytic on $(-2, 0)$ . So, working backwards, I found out that $\frac{1}{1 + x}$ satisfies the property $f(\frac{1}{n}) = \frac{n}{n + 1}$ . I'm really not so sure how to prove the analytic properties though. I think that now I need to show $\frac{1}{1 + x}$ is analytic, and then I need to prove the second part of the claim, which is that such a function cannot be analytic on $(-2, 0)$ . I have an example in my book which shows $1 + x + x^{2} + x^{3} + \cdots$ is analytic. Here's how they do it: A prototypical example is the geometric series $$1 + x + x^{2} + \cdots = \lim_{n\to\infty} 1 + x + x^{2} + \ldots x^{n} = \lim_{n\to\infty}\frac{1 - x^{n + 1}}{1 - x}$$ for which it is well known equals $f(x) = \frac{1}{1 - x}$ for $|x| < 1$ . To verify that the function is analytic, we need to expand about any point $x_{0} \neq 1$ : $$
\begin{align*}
\frac{1}{1-x} = \frac{1}{1 - x_{0} - (x - x_{0})} = \frac{1}{1- x_{0}}\left(1 - \frac{x - x_{0}}{1 - x_{0}}\right)^{-1}
\end{align*}
$$ I tried outlining this example, but I couldn't make any progress. I would really appreciate some sort of help.","['complex-analysis', 'functions', 'analyticity', 'real-analysis']"
2995629,"Find the critical points of each of the functions below and classify them as a local maximum, minimum, or neither","$f ( x , y ) = \ln ( 2 + \sin ( x y ) )$ . Consider only the critical point $(0,0)$ . I have solved for the first and second partial derivatives and I see that they are both equal to $0$ at $(0,0)$ . One of the exercises in my textbook mentions the Hessian matrix and I think I should be using that, but I am not sure how it works. $f ( x , y ) = \left( x ^ { 2 } + 3 y ^ { 2 } \right) e ^ { 1 - x ^ { 2 } - y ^ { 2 } }$ For this problem, I took the first and second partial derivatives and I observed that the critical points are at $(0,1)$ , $(0,-1)$ , and $(0,0)$ . Do I have to use the Hessian here as well? How would that work?","['multivariable-calculus', 'calculus', 'vector-analysis']"
2995641,Computing $\;\lim\limits_{x\to 4}\left (\frac{\frac{\pi}{6} - \arcsin\left(\frac{\sqrt{x}}{4}\right)}{\sqrt[3]{2x-7}-1}\right) $ without L'Hôpital?,"$$
\lim_{x\to 4}\left(\frac{\frac{\pi}{6} - \arcsin\left(\frac{\sqrt{x}}{4}\right)}{\sqrt[3]{2x-7}-1}\right)
$$ Hello! I need to solve this limit. I had solved it with the rule of L'Hôpital, but i can't without it. I tried multiplication by conjugate expression and using Special Limits. Please help me, I must solve it using only Special Limits and simple transformations. I can't use derivatives.","['limits', 'calculus', 'limits-without-lhopital', 'sequences-and-series']"
2995661,Counting problem.How many different bowls can be made if:,"An ice-cream shop sells ten kinds of ice-cream, including mango and lemon. For a bowl, one chooses at random 4 kinds.How many different bowls can be made if:a)The 4 kinds are different
b)The 4 kinds are not necessarily different;
c)The bowl contain lemon, but no mango?;
d)The bowl contains both lemon and mango. For point a) I thought of associating each kind of ice-cream to a number, from 1 to 10 and then I thought how many bowls can I create in such a way that each number will appear only once per bowl and the same set of numbers will not be repeated: {1,2,3,4},{1,2,3,5}...{1,2,3,10} {1,2,4,5},{1,2,4,6}...{1,2,4,10} ... {1,2,8,9},{1,2,8,10} {1,2,9,10} and the result would be 1+2+3+4+5+6+7=28 (but I don't really like this method, and I'm not even sure if it's correct) but for the rest I am completely clueless so I would really appreciate some help P.S. I'm new to counting problems so if you find any mistakes in my way of thinking please do tell me, I really want to learn how to think this kind of problems but I'm having a hard time finding solved examples.",['combinatorics']
2995692,Does it hold that $\displaystyle\sum_{j=2}^{n-1}\sum_{k=1}^{j-1}\Big(\frac{2}{kj}-\frac{1}{k(n-j)}\Big)=0$?,"I am assigned in a homework to find the value of $s_{n,3}$ , the Stirling number of the 1 $^{\text{st}}$ kind with $k=3$ . I came to a point where $$s_{n,3}=n!\sum_{k=1}^{n-2}\sum_{j=k+1}^{n-1}\frac{1}{3kj(n-j)}\text{.}$$ However, for some small $n$ , because of some typo in computer, I accidentally found that $$s_{n,3}=(n-1)!\Big(H_{n-1}H_{n-2}-\sum_{k=1}^{n-2}\frac{H_k}{k}\Big)\text{,}$$ where $H_n$ is the $n^{\text{th}}$ harmonic number. I was so happy because this is a more elegant form, only to find that I have a difficulty to prove it. After some routine work, the problem reduced to answer whether $$\sum_{j=2}^{n-1}\sum_{k=1}^{j-1}\Big(\frac{2}{kj}-\frac{1}{k(n-j)}\Big)=0$$ holds. I also found that this is equivalent to ask whether $$\sum_{k=1}^{n-1}\frac{1}{k^2}=\sum_{k=1}^{n-1}\sum_{j=n-k}^{n-1}\frac{1}{kj}$$ holds. That is, whether the sum of squares of reciprocal over diagonal equals the sum of reciprocal of products over upper right triangle of $[n-1]\times[n-1]$ . Can anyone here give me some hint? By the way, any other better form of $s_{n,3}$ is appreciated. Thanks!",['combinatorics']
2995699,"Minimum distance required to travel to ""see"" all points on a hypercube","You begin on a hypercube of dimension N at the origin i.e. $(0,0,0,0,...,0)$ When at the origin you are able to ""see"" one and only one step away from you. So from the origin you can see vertices $(1,0,0,0..,0), (0,1,0,...,0),... (0,0,0,...,1)$ What is the function $f(M)$ that gives the total number of vertices seen after $M$ steps? (When $f(M=m)=2^N$ in this function then $m$ will be the minimum number of steps to see all vertices) Step $0$ : $\mathbf{(0,0,0)}, (0,0,1), (0,1,0), (1,0,0)$ 4 vertices Step $1$ : $\mathbf{(0,0,1)}, (0,1,1), (1,0,1)$ +2 vertices Step $2$ : $\mathbf{(1,0,1)}, (1,1,1)$ +1 vertex Step $3$ : $\mathbf{(1,1,1)}, (1,1,0)$ +1 vertex","['graph-theory', 'discrete-geometry', 'geometry', 'information-theory']"
2995751,"Proof matrix $A=\begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}^n , \text{ when } n \in \mathbb{N}$ [duplicate]","This question already has answers here : How can I show that $\begin{pmatrix} 1 & 1 \\ 0 & 1\end{pmatrix}^n = \begin{pmatrix} 1 & n \\ 0 & 1\end{pmatrix}$? (7 answers) Closed 5 years ago . Problem Find generalitazion for matrix A exponents, when $n\in\{1,2,3,\dots\},n \in \mathbb{N}$ $$A^n=\begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}^n , \text{ when } n \in \mathbb{N}$$ Proof generalization by induction. Attempt to solve By computing a set of $A$ exponent's $n\in \{\ 1,2,3,4 \}$ . It is possible  to form generalization that is applicable for set $n\in \{1,2,3,4 \}$ $$ A^1=\begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix},A^2=\begin{bmatrix} 1 & 2 \\ 0 & 1 \end{bmatrix},A^3=\begin{bmatrix} 1 & 3 \\ 0 & 1 \end{bmatrix},A^4=\begin{bmatrix} 1 & 4 \\ 0 & 1 \end{bmatrix} \dots A^n =\begin{bmatrix} 1 & n \\ 0 & 1 \end{bmatrix} $$ Induction proof Induction hypothesis Assume expression is valid when $n=k$ $$
A^k = \begin{bmatrix} 1 & k \\ 0 & 1\end{bmatrix}
$$ Base case When $n=1$ $$
A^1=\begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}
$$ which is valid by definition. Induction step When $n=k+1$ $$ A^{k+1} = \begin{bmatrix} 1 & k+1 \\ 0 & 1\end{bmatrix}$$ $$ A^{k+1}=A^kA^1 $$ By utilizing induction hypothesis we have $$ \implies A^{k+1}=\begin{bmatrix} 1 & k \\ 0 & 1\end{bmatrix}\begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} $$ By utilizing matrix multiplication we have $$ \implies A^{k+1} \begin{bmatrix} 1\cdot 1 + k\cdot 0 & 1 \cdot 1 + 1 \cdot k \\ 0 \cdot 1 + 1 \cdot 0 & 0 \cdot 1 + 1 \cdot 1 \end{bmatrix} $$ $$ \implies A^{k+1}=\begin{bmatrix} 1 & k+1 \\ 0 & 1 \end{bmatrix} $$ $$ \tag*{$\square$} $$ EDIT The point of posting this was to have comment on if my solution seems correct or not. If you can notice something that doesn't look right, let me know !","['matrices', 'induction', 'proof-verification']"
2995762,Directional derivatives for vector-valued functions,"Do we only calculate directional derivatives for scalar-valued functions? Is it not possible to calculate directional derivatives for vector-valued functions? How about using the vector of directional derivatives of the components of the given vector function? Would there be any useful physical or geometric meaning? For a specific (randomly chosen) example, if $\vec v(x,y,z)$ is given by $$
\vec v(x,y,z)=
\begin{bmatrix}
x^3+y^2+z\\ 
ze^x\\
xyz-9xz\\ 
\end{bmatrix}
$$ how can we interpret the directional derivative of $\vec v$ at the point $(1,2,3)$ in the direction of the vector $\vec u=2i+3j-5k$ ?",['multivariable-calculus']
2995887,"Proving Equivalence Relations, Constructing and Defining Operations on Equivalence Classes","I think I have an intuitive sense of how ordered pairs can function to specify equivalence classes when used in the construction of integers and rationals, for example. I put the cart before the horse, however, and am less well versed in how to prove an equivalence relation, construct equivalence classes, and define operations on equivalence classes. I have received feedback that one may not define operations on equivalence classes by appealing to individual elements (e.g., it is insufficient to indicate [(a,b)] + [(c,d)] = [(a+c,b+d)]). How does one prove equivalence relations, construct equivalence classes, and define operations on those classes? If the answer is too long for this forum, is there a good demonstration available online?","['elementary-set-theory', 'equivalence-relations', 'foundations', 'relations']"
2995894,"Prove that, the function $f$ is injective: $f \big(f(x)f(y)\big) + f(x +y) = f(xy).$","I need to learn,  by which method,  I can prove that the function $f$ is injective. I would like to ask you to explain this problem using more detailed, more understandable, clearer and simpler English words. There's only one way I can understand. For example; Let $f:  \mathbb{R} \to\mathbb{R}$ and $f(x)=x-10$ . We have, $f(y)=y-10$ , then $f(x)=f(y)$ , we get $f(x)=f(y) \Rightarrow x-10=y-10 \Rightarrow x=y$ . So, $f$ is injective. And here is my problem: Why can't we apply this method to this problem? $f:  \mathbb{R} \to\mathbb{R}$ and $f(0)≠0$ , such that, for all real numbers $x$ and $y$ , $$f \big(f(x)f(y)\big) + f(x +y) = f(xy).$$ Prove that, $f$ is injective. Thank you very much for teaching.","['contest-math', 'functional-equations', 'proof-writing', 'alternative-proof', 'algebra-precalculus']"
2995911,Definition of the tensor product of representations,"I'm a bit confused about the following definition: Let $\rho_1:G \to Aut(V_1)$ , $\rho: G \to Aut(V_2) $ be two representations of the same group $G$ .
Then a tensor product of representations is defined as: $$ \rho_1 \otimes\rho_2:G \to Aut(V_1 \otimes V_2)\\
    g \mapsto (\rho_1\otimes\rho_2)(g):= \rho_1(g)\otimes \rho_2(g) $$ Question : Isn't object $\rho_1(g)\otimes \rho_2(g)$ belongs to something like $Aut(V_1)\otimes Aut(V_2)$ (since $\rho_i(g) \in Aut(V_i)$ ), and not to $Aut(V_1 \otimes V_2)$ ?. But, honestly, then I don't understand if the tensor product of two non-abelian group is even defined.","['group-theory', 'representation-theory', 'tensor-products']"
2995915,Why $\mathbb E\left[\sup\frac{|Y_t-Y_s|}{|t-s|^\alpha }\right]<\infty$ imply $(Y_t)_t$ continuous?,"Let $(Y_t)_t$ a stochastic process s.t. $$\mathbb E\left[\sup_{s,t\in [0,1], s\neq t}\frac{|Y_t-Y_s|}{|t-s|^\alpha }\right]<\infty,$$ with $\alpha >0$ . Why does this implies that $(Y_t)_t$ is continuous a.s. ? Does it come from the fact that if $\mathbb E[X]<\infty$ then $\mathbb P\{X<\infty\}=1$ , and thus $$\mathbb P\left\{\sup_{s,t\in [0,1], s\neq t}\frac{|Y_t-Y_s|}{|t-s|^\alpha }<\infty\right\}=1.$$ Also $$\mathbb P\left\{\sup_{s,t\in [0,1], s\neq t}\frac{|Y_t-Y_s|}{|t-s|^\alpha }<\infty\right\}\leq \mathbb P\left\{\frac{|Y_t-Y_s|}{|t-s|^\alpha}<\infty\right\}=1.$$ 1) How can I continue ? Does it implies that there is $C>0$ s.t. $$\mathbb P\{|Y_t-Y_s|<C|t-s|^\alpha \}=1,$$ or that $$\mathbb P\{\exists C>0: |Y_t-Y_s|\leq C|t-s|^\alpha \}=1 \ \ ?$$ 2) And will it implies that $$\mathbb P\{\lim_{t\to s}|Y_t-Y_s|\}=1 \ \ ?$$ If yes, why ? I don't understand why I can put the limit inside.","['stochastic-processes', 'probability']"
2995933,Limit of $\frac{\tan{(\sin{(x)}})}{\sin{(\tan{(x)}}}$ when x approaches 0,How would one approach finding this limit without using Taylor's series? $$\lim_{x \to 0} \frac{\tan{(\sin{(x)}})}{\sin{(\tan{(x)}})}$$,"['limits', 'trigonometry', 'real-analysis']"
2995939,"A first-countable, separable Hausdorff space has at most the continuum cardinality $c$","Show that if $X$ is first-countable, separable Hausdorff topological space, then $X$ has at most the continuum cardinality. I do not know how to start.","['general-topology', 'cardinals']"
2995943,Finite etale covers and Grothendieck groups,"Let $X$ be a smooth projective variety over $\mathbb{C}$ , and let $X' \to X$ be a finite etale cover. How Grothendieck groups $K_0(X)$ and $K_0(X')$ are related in this situation? Set $G$ to be the group of deck transformations of the cover, is it true that $K_0(X) \cong K_0(X') \otimes_{\mathbb{Z}} K_0(\mathbb{C}[G])$ ?","['complex-geometry', 'algebraic-geometry', 'reference-request']"
2995973,Inverse powers of Bessel process not a martingale,"I am trying to show that $X_t^{1-2a}$ is not a martingale, where the solution $X_t$ to $$dX_t = \frac{a}{X_t} \ dt + \ dB_t, \ \ X_0=1$$ for $a>1/2$ . I am able to do this directly for $a = (d-1)/2$ , because then $X_t$ is the norm of the standard $d-$ dimensional Brownian motion starting on the sphere of radius $1$ . I also have the following facts: $X_t \to \infty$ almost surely as $t \to \infty$ , as well as $$\mathbb{P}(X_t \text{ hits } R \text{ before } \epsilon) = \frac{1- \epsilon^{1-2a}}{R^{1-2a} - \epsilon^{1-2a}}.$$ Here $\epsilon < 1<R$ . If $X_t$ had started at $x$ we would replace $1$ there with $x^{1-2a}$ . But I am not sure how to use these facts to show that $M_t\equiv X_t^{1-2a}$ is not a martingale. I can't seem to justify the limit swap to show $\mathbb{E}[M_t] \to 0$ . In particular there doesn't seem to be anything I can dominate with. If there were some uniform integrability I could use Egorov and be done, but I just don't know enough about the Bessel process to know if this is true. Does anyone have any hints?","['probability', 'real-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
2995979,Punch 2000 holes in 2000 polygons with 1000 needles,"You have two identical perfectly square pieces of paper. The area of each paper is 1000 units. On each paper, draw 1000 convex, non-overlapping polygons with all polygons having the same area (exactly 1 unit). Obviously, the polygons are covering both papers completely and edges of paper also serve as edges of some polygons). Polygons may have different shapes and number of sides and the drawing on the first paper is completely different from the drawing on the second paper. Now put the first paper on top of the second and align paper edges perfectly. Prove that it is always possible to punch a hole in all 2000 polygons with 1000 needles (each needle goes through both papers). What have I tried? This problem came from my son who likes to torture his father with difficult problems brought back from his math school. My first try was to steal his clever analysis book while he was sleeping and find the right page in the answer section. Alas, this problem had no solution, which basically means that it's either too simple (and I'm too stupid) or it's too difficult. So I decided to read some theory and discovered that I had some pretty huge gaps in my math education. This problem is definitely about functions. You have a set of 1000 polygons on one side and a set of 1000 polygons on the other side. I have to prove that there is a bijective function between these two sets. Needles are just lines connecting the dots. However, all my attempts to construct such function ended miserably. I guess there has to be some clever theorem than can be applied to problems like this one but I would have to read a pretty thick book to find it. Thanks for the hint.",['functions']
2996004,Homotopic maps and attaching spaces,"Let $f, g : \mathbb{S}^{n-1} \to X$ be two continuous maps from the sphere into a compact and Hausdorff space $X$ . I want to show that if $f$ and $g$ are homotopic, then attaching an $n$ -cell to $X$ via $f$ or via $g$ yields spaces with the same homotopy type: $D^n \cup_f X \cong D^n \cup_g X$ . This has been answered in this post , but I didn't completely understand the answer. So I would like some help in the following steps: I know that there is a deformation retraction $r : (D^n \times I) \to (D^n \times \{0\}) \cup (\mathbb{S}^{n-1} \times I)$ , where $I = [0,1]$ .
Let $H : \mathbb{S}^{n-1} \times I \to X$ be a homotopy between $f$ and $g$ and let $$\pi : (D^n \times I) \,\dot{\cup} \, X \to (D^n \times I) \cup_H X$$ and $$\rho : ((D^n \times \{0\}) \cup (\mathbb{S}^{n-1} \times I)) \, \dot{\cup} \, X \to ((D^n \times \{0\}) \cup (\mathbb{S}^{n-1} \times I)) \cup_H X $$ be the projection maps. How do I show that $r$ descends to the quotient to a deformation retraction $$R : (D^n \times I) \cup_H X \to ((D^n \times \{0\}) \cup (\mathbb{S}^{n-1} \times I)) \cup_H X \,\,?$$ How do I show that $$((D^n \times \{0\}) \cup (\mathbb{S}^{n-1} \times I)) \cup_H X$$ is homeomorphic to $$D^n \cup_f X \,\, ?$$ PS.: I know nothing about cofibrations.","['general-topology', 'cw-complexes', 'algebraic-topology', 'quotient-spaces']"
2996010,Prove a property of a bijective function $f$,"Function $f: \mathbb{N} \times \mathbb{N} \to  \mathbb{N} \times \mathbb{N}$ is a bijection. ( $0 \in \mathbb{N}$ .) It has the following property: $f(x+y) = f(x) + f(y)$ , where $(a,b)+(c,d) = (a+c, b+d)$ How do I prove (if possible) that this must hold: $f((a,b)) = (c,d) \implies a+b=c+d$ This is an intuition I have (otherwise there would be ""holes"" in $\mathbb{N} \times \mathbb{N}$ , but that can't be since $f$ is a bijection), but I can't think of a formal proof. Actually when I try to ""materialize"" my intuition: I have the feeling that in this case $f(f(x)) = x$ must hold. But I have no idea how to prove it.","['elementary-set-theory', 'functions']"
2996038,Area of standard simplex,"The standard $n$ -simplex contains all points $\vec{x} \in \mathbb{R}^{n + 1}$ such that $0 \le x_i \le 1$ and $\vec{x} \cdot \vec{1} = 1$ The standard 2-simplex is an equilateral triangle with side length $\sqrt{2}$ and vertices at (1, 0, 0), (0, 1, 0), and (0, 0, 1). The area is $\sqrt{3}/2$ . The standard 1-simplex is a line with vertices at (1, 0) and (0, 1). The length is $\sqrt{2}$ What is the area of the standard $n$ -simplex? Is it $\sqrt{n + 1} / n!$ ?","['calculus', 'geometry']"
2996039,Is there an (efficient) algorithm to determine whether an equation of two terms in the language of elementary set theoretic operators is an identity?,"By elementary set theoretic operations I refer to those which are usually imaged in Venn diagrams -- union, intersection, set difference, etc. In the formulation of my question I included the word ``efficient'' between parentheses
because in computing complexity this term is used with different meanings and here I am not very interested in complexity. I would like to learn about any algorithm which would not just ""exhaust all possibilities"" (like substituting 0s and 1s, in case of boolean terms), an algorithm which would be useful or instructive when implemented as a computer program. This question naturally came after another question of mine: Is the equational theory of generalized boolean algebras decidable?","['elementary-set-theory', 'logic']"
2996046,"Rearranging $nk$ distinct objects among $n$ boxes, $k$ objects per box. Probability no box is the same?","The title is pretty self-explanatory as to what my question is, I think. If we have distributed $nk$ distinct elements among $n$ boxes such that each box has $k$ objects in it, and we then randomly redistribute the objects so that each box still has $k$ objects, what is the probability that the contents of every box have changed? My first thought was to compute the number of ways of rearranging the elements in which no box has the same contents as before via inclusion exclusion. My work is as follows: For each $i \in [n]$ , there are $n \choose i$$\frac{(nk-ik)!}{(k!)^{n-i}}$ ways of rearranging so that there are at least $i$ boxes which remained the same. The total number of ways of rearranging is $\frac{(nk)!}{(k!)^n}$ , (which is the multinomial $nk \choose k, k, ..., k$ ). So the probability that we want is: $\sum_{i=0}^n {n \choose i}\frac{(nk-ik)!(k!)^i(-1)^i}{(nk)!}$ That is, unless I have made a mistake along the way. If my answer so far is correct, then here is the issue which I am having- I don't see how to simplify it further. Is it possible to find a closed form of the probability that we want here, or is my answer essentially as good as it gets?","['discrete-mathematics', 'combinatorics', 'probability']"
2996053,Evaluating Derivative of $\sqrt{1+\sqrt{1+\sqrt{1-2x}}}$,"Did I evaluate the following derivative correctly? I know I have not simplified to the utmost extent, but I want to know if this method is correct. Consider, $\sqrt{1+\sqrt{1+\sqrt{1-2x}}}$ Let A = $1+\sqrt{1+\sqrt{1-2x}}$ Let B = $1+\sqrt{1-2x}$ Let C = $1-2x$ $$\left(\sqrt{1+\sqrt{1+\sqrt{1-2x}}}\right)' = \frac{1}{2}A^{-\frac{1}{2}} \cdot \frac{1}{2}B^{-\frac{1}{2}} \cdot \frac{1}{2}C^{-\frac{1}{2}} \cdot -2 = \frac{-1}{4\sqrt{ABC}}$$","['calculus', 'derivatives']"
2996088,How to find $\lim_{n\to\infty}(pa_n + qb_n)^n$ with $p + q = 1$?,"Suppose $a_n$ and $b_n$ are sequences of positive numbers, such that $$
\lim_{n\to\infty}a_n^n = a,\quad \lim_{n\to\infty}b_n^n = b,\qquad a,b\in (0, \infty).
$$ Find limit $$
\lim_{n\to\infty}(pa_n + qb_n)^n,
$$ where $p, q$ are nonnegative numbers such that $p + q = 1$ .","['limits', 'calculus', 'sequences-and-series']"
2996092,Why is the maximum of i.i.d. Gaussians asymptotically $\sqrt{2 \log n}$?,"Assuming that $\xi$ is bounded (as a function of $x$ ?), the claim is that given the equation: $$\xi \frac{\sqrt{2\pi}}{n} = \frac{1}{x} e^{-\frac{x^2}{2}} \left( 1 + O\left(\frac{1}{x^2} \right) \right)  $$ one can solve (""after some calculation"") for $x$ to get: $$x = \sqrt{2 \log n} - \frac{\log \log n + \log 4 \pi}{2 \sqrt{2 \log n}} - \frac{\log \xi}{\sqrt{2 \log n}} + O\left( \frac{1}{\log n} \right) \,. $$ Question: Would it be possible to get some hints about how to solve for $x$ in this situation? There are several issues about this which I don't understand: How is the assumption that $\xi$ is bounded used or otherwise relevant? Why is the ""imprecise knowledge of $x$ transferred to $n$ "" when solving for $x$ , and not ""transferred"" to some other variable? If we require an assumption on $\xi$ , then why isn't the ""imprecise knowledge transferred"" to $\xi$ ? (Why don't we get an $O(f(\xi))$ term for some $f$ ? Do we have to use/calculate some inverse function to $g(x) := \frac{1}{x} e^{-\frac{x^2}{2}}$ ? This function isn't even defined, strictly speaking, at $x=0$ , but perhaps it has a continuous extension over the entire real line? If it does have a continuous extension over $\mathbb{R}$ , is that continuous extension even an invertible function, such that talking about $g^{-1}(x)$ even makes sense? If we do calculate such an inverse function, do we then basically proceed by applying that function to both sides of the equation and ignoring the $O(x^{-2})$ term, with the understanding that the ""uncertainty"" contained within it now needs to be transferred somewhere else? If so, this leads back to the above question about where the $O((\log n)^{-1})$ term could come from. Context: I don't think the context is actually relevant to solving this problem, but for the record this comes up on p. 374 of Cramer's 1946 Mathematical Methods of Statistics where an asymptotic form for the maximum of i.i.d. Gaussian random variables is sought.","['statistics', 'asymptotics', 'order-statistics', 'problem-solving', 'probability']"
2996121,Why does this method fail for finding the Fourier series for $\cos\left(\frac{x}{2}\right)$ on the interval $-\pi \lt x \lt \pi$?,"This question is strongly related to this question (that does not have an answer). From ""Riley, Hobson and Bence - Mathematical methods for physics and engineering"", Section 12.5 - ""Non-periodic functions"", page 417 $$a_n=\frac{2}{L}\int_{x_0}^{x_0+L}f(x)\cos\left(\frac{2\pi nx}{L}\right)dx\tag{1}$$ similarly $$b_n=\frac{2}{L}\int_{x_0}^{x_0+L}f(x)\sin\left(\frac{2\pi nx}{L}\right)dx\tag{2}$$ where $x_0$ is arbitrary but is often taken as $0$ or $-\frac{L}{2}$ and $L$ is the period of $f(x)$ . The following question I asked on ""Chegg Study"" website is here : Show that the Fourier series of $f(x)=\cos\left(\frac{x}{2}\right)$ for $-\pi\lt x \lt \pi$ is given by $$f(x)=\frac{2}{\pi}+\frac{4}{\pi}\sum_{n=1}^{\infty}\frac{(-1)^{n+1}\cos(nx)}{4n^2 - 1}$$ So my attempt at the finding the Fourier series for $\cos\left(\frac{x}{2}\right)$ on the interval $-\pi \lt x \lt \pi$ is by first noting that since $\cos\left(\frac{x}{2}\right)$ is not periodic on $-\pi \lt x \lt \pi$ , $\,$ I must therefore make the function periodic by extending the interval to $-2\pi \lt x \lt 2\pi$ . By the Dirichlet conditions for convergence the function must be periodic. Now that the function is symmetric and periodic about $x=0$ the $b_n=0 \,\forall \,n \in \mathbb N$ A plot of the extended function is shown below: Now by $(1)$ , $$\begin{align}a_n &=\frac{2}{L}\int_{x_0}^{x_0+L}f(x)\cos\left(\frac{2\pi nx}{L}\right)dx \\&=\frac{2}{4\pi}\int_{-2\pi}^{2\pi}\cos\left(\frac{x}{2}\right)\cos\left(\frac{2\pi nx}{4\pi}\right)dx\\&=\frac{1}{2\pi}\int_{-2\pi}^{2\pi}\cos\left(\frac{x}{2}\right)\cos\left(\frac{nx}{2}\right)dx\\&=0\end{align}$$ and this has been verified here by Wolfram Alpha. All I did was substitute the value of the period $L$ into the argument of the cosine, the limits and the denominator in front of the integral. Why is this giving me the wrong answer when it clearly works for other functions like $x^2$ on $0 \lt x \le 2$ as can be seen here ""Riley, Hobson and Bence - Mathematical methods for physics and engineering"", Section 12.5 - ""Non-periodic functions"", page 422 and 423 ? The method used in the $x^2$ and $\cos(x/2)$ case was general and did not specify any restrictions on the function being extended. So, put in another way, is there some kind of rule that says extending a trigonometric function to a full period is always forbidden since integrating over the period will be zero?","['fourier-analysis', 'calculus', 'trigonometric-integrals', 'fourier-series', 'trigonometry']"
2996122,Integrating on a Manifold,"I'm new to working with differential forms and integrating over manifolds. I think that I have the following problem solved, but I'm not all that confident in my work. Let $D=\{(x,y,z)\in\mathbb{R}^{3}~:~y=x^{2}+z^{2},y\leq 4\}$ , and let the region be oriented by the $2$ -form $\sigma=dz\wedge dx$ . Evaluate $\int_{D}\omega$ , where $\omega=z~dx\wedge dy$ . Here's my work: We parametrize the region with the map $\psi:(0,2]\times(-\pi,\pi)\to\mathbb{R}^{3}$ given by $$\psi(r,\theta)=(r\cos\theta,r^2,r\sin\theta)$$ (I think that the open intervals are okay, because we only need to cover the manifold modulo sets of measure zero). We now check orientations by computing the pullbacks $\psi^{*}\sigma$ and $\psi^{*}\omega$ . We have \begin{align}
\psi^{*}\sigma&=\psi^{*}(dz\wedge dx)\\
&=d(r\sin\theta)\wedge d(r\cos\theta)\\
&=(\sin\theta~dr+r\cos\theta~d\theta)\wedge(\cos\theta~dr-r\sin\theta~d\theta)\\
&=-r\sin^{2}\theta~dr\wedge d\theta+r\cos^{2}\theta~d\theta\wedge dr\\
&=-r\sin^{2}\theta~dr\wedge d\theta-r\cos^{2}\theta~dr\wedge d\theta\\
&=-r~dr\wedge d\theta
\end{align} and we have \begin{align}
\psi^{*}\omega&=\psi^{*}(z~dx\wedge dy)\\
&=r\sin\theta~\left[d(r\cos\theta)\wedge d(r^{2})\right]\\
&=r\sin\theta~\left[(\cos\theta~dr-r\sin\theta~d\theta)\wedge(2r~dr)\right]\\
&=r\sin\theta~(-2r^{2}\sin\theta~d\theta\wedge dr)\\
&=(2r^{3}\sin^{2}\theta)~dr\wedge d\theta.
\end{align} Since $\psi^{*}\sigma$ is everywhere negative and $\psi^{*}\omega$ is everywhere positive, we have $\int_{D}\omega=-\int_{(0,2]\times(-\pi,\pi)}\psi^{*}\omega$ . Hence, \begin{align}
\int_{D}\omega&=-\int_{-\pi}^{\pi}\int_{0}^{2}(2r^{3}\sin^{2}\theta)dr~d\theta\\
&=-8\int_{-\pi}^{\pi}\sin^{2}\theta~d\theta\\
&=-4\int_{-\pi}^{\pi}(1-\cos(2\theta))~d\theta\\
&=-4(\theta-\frac{1}{2}\sin(2\theta))\bigg|_{-\pi}^{\pi}\\
&=-4\pi-(-4)(-\pi)\\
&=-8\pi.
\end{align} Does my work look correct? I've tried this several times and I've gotten a couple of different answers, but I think this one is correct (I went through the steps methodically and tried not to make any stupid mistakes). Any help is appreciated.","['integration', 'proof-verification', 'smooth-manifolds', 'differential-forms', 'differential-geometry']"
2996142,Spherical Laplacians on an Exponential,"I looked around a bit and couldn't find a resolution to this. I was curious about the scalar function $u(r) = e^{-r}$ with $r \in [0,\infty)$ and acting Spherical Laplacians on it. $$\Delta u(r) = \frac{1}{r^{2}}\frac{\partial}{\partial r}\Big(r^{2}\frac{\partial u}{\partial r}\Big).\tag{1}$$ Laplacian is straight forward to compute: $$\Delta u = \Big(1 - \frac{2}{r}\Big)u.\tag{2}$$ But computing a second one seems to introduce some ambiguity: $$\Delta^{2}u = \Delta \Delta u = \Delta \Big(1-\frac{2}{r}\Big)u = \Delta\Big(u -\frac{2u}{r}\Big) = \Big(1-\frac{2}{r}\Big)u - \Delta\Big(\frac{2u}{r}\Big) .\tag{3}$$ With the rightmost term being the confusing part to me; If I proceed with distributing the $\Delta$ : $$\Delta\Big(\frac{u}{r}\Big) \overset{?}{=}\  u\ \Delta\Big(\frac{1}{r}\Big) +2\ \nabla u \cdot \nabla\Big(\frac{1}{r}\Big) + \frac{1}{r}\Delta u.\tag{4}$$ As I understand it all of these objects are defined, with: $$\nabla\Big(\frac{1}{r}\Big) = -\frac{1}{r^{2}}\hat{r}\qquad \text{and}\qquad\Delta\Big(\frac{1}{r}\Big) = -4\pi\delta^3(r).\tag{5}$$ Where $\delta^3(r)$ is the 3D Dirac delta distribution. This all seems to suggest that: $$-2\Delta\Big(\frac{u}{r}\Big) = -2\Big(-4\pi\delta^3(r) u + 2\frac{u}{r^{2}} + \frac{1}{r}\Big(1 - \frac{2}{r}\Big)u \Big)\tag{6}$$ $$\require{cancel}-2\Delta\Big(\frac{u}{r}\Big) = -2\Big(-4\pi\delta(r) u + \cancel{2\frac{u}{r^{2}}} + \frac{1}{r}\Big(1 - \cancel{\frac{2}{r}}\Big)u \Big)\tag{7}$$ $$-2\Delta\Big(\frac{u}{r}\Big) = 8\pi\delta^3(r)u - \frac{2u}{r}.\tag{8}$$ Leaving me with: $$\Delta^{2}u = \Big(1 -\frac{4}{r} + 8\pi\delta^3(r)\Big)u.\tag{9}$$ Now the heart of my question is: Are these manipulations correct, or have I assumed something I should have not? Why does $\Delta\Big(\Delta e^{-r}\Big)$ contain a discontinuity (the $\delta^3(r)$ ) when all the $r$ -derivatives exist?","['multivariable-calculus', 'dirac-delta', 'vector-analysis', 'distribution-theory']"
2996157,the sum of two arbitrary different numbers in the sequence is always coprime with the sum of three arbitrary different numbers,"Does there exist a sequence of infinite positive integers $a_1,a_2,...$ such that the sum of two arbitrary different numbers in the sequence is always coprime with the sum of three arbitrary different numbers in the sequence? Assume that there exist such sequence. For every prime $p$ , if there exist three numbers from the sequence $a_i,a_j,a_k$ that are divisible by $p$ , then $a_i+a_j$ is not coprime with $a_i+a_j+a_k$ , contradiction. Thus $p$ can divide at most two numbers from the sequence. Therefore there are at most two even numbers from the sequence and there are infinite odd numbers from that sequence. However, if there are two even numbers, then the sum of two odd numbers is not coprime with the sum of two odd numbers and an even one, since both of the sum are greater than $2$ and are both even. Hence there are no even numbers in the sequence. Here I am stuck. How can I progress ? Is there a better way to solve the problem ?","['number-theory', 'calculus', 'combinatorics', 'elementary-number-theory']"
2996201,How to evaluate $\int_{-\infty}^{\infty}dx \frac{x^2 e^x}{(e^x+1)^2}$,My physics textbook makes use of the result: $$\int_{-\infty}^{\infty}dx \dfrac{x^2 e^x}{(e^x+1)^2} = \dfrac{\pi^2}{3}$$ I'm really curious on how I can derive this but I honestly don't know what to search for. My instinct is to transform to polar coordinates but I would like some guidance. Any help appreciated!,"['integration', 'definite-integrals']"
2996240,Decompose rational numbers into sum of rational numbers of the form $\frac{1}{a}$.,"I need to show that Given $n>0$ and a rational number $q$ there are only finitely many n-tuples $(c_1,...,c_n)$ of natural numbers such that $q=1/c_1+...+1/c_n$ . This result can be used to show that there are finitely many groups with a fixed number of conjugacy classes. i.e, we have a group $G$ of size $lcm(c_1,...,c_n)$ for each n-tuple $(c_1,...,c_n)$ such that $1=\frac{1}{c_1}+\frac{1}{c_2}+...+\frac{1}{c_n}$ . Ok so for example, when $n=5$ and $q=1$ , $1=\frac{1}{5}+\frac{1}{5}+\frac{1}{5}+\frac{1}{5}+\frac{1}{5}$ , so $(5,5,5,5,5)$ is a 5-tuple that work. There might be other.We need to show there are finitely many of them. It is in remark in the following picture:","['group-theory', 'discrete-mathematics']"
2996254,Need Help Solving Or Finding The Solution To The Following Darboux System Of Nonlinear Equations.,"I am working on a personal math project of mine and in order for me to continue I need to know the solution to this following system of nonlinear equations I am attaching as a photo. This equation is referenced in this paper https://arxiv.org/pdf/gr-qc/9409025.pdf and the solution is further referenced in F. J. Bureau, Sur des syst emes diff´erentiels du troisi eme ordre et les ´equations
diff´erentielles associ´ees, Bulletin de la Classe des Sciences LXXIII (1987) 335–353. My native language is Japanese and I can't read a word of french to save my life. In addition I can't even find this book or paper. I looked using two college libraries and Google Scholars. I would rather not need to duplicate effort and re derive the solution of these equations in terms of Hermite modular elliptic functions. If anyone who has worked with these equations before has reference with an English solution that would be nice. Or if anyone knows where I can find the french reference that would help also. If non can be found then I would appreciate any hints on how to re derive the solution. My project did not intend to run into such formidable looking differential equation, it is a bit outside of my specialty of geometry. Any guidance will be appreciated thanks!","['riemann-sum', 'systems-of-equations', 'ordinary-differential-equations']"
2996285,Is $S^2\times S^2$ homeomorphic to $\mathbb{CP}^2\#\mathbb{CP}^2$?,"Is $S^2\times S^2$ homeomorphic to $\mathbb{CP}^2\#\mathbb{CP}^2$ ? My idea: by the product formula for the Euler characteristic, we have $\chi(S^2\times S^2)=\chi(S^2)^2=4$ . By the sum formula for Euler characteristic we have $\chi(\mathbb{CP}^2\#\mathbb{CP}^2)=2\chi(\mathbb{CP}^2)-\chi(S^4)=4$ . So both manifolds have the same Euler characteristic. By the sum formula for the signature, $\sigma(\mathbb{CP}^2\#\mathbb{CP}^2)=2$ . Is the signature of $S^2\times S^2$ also 2? I'm not sure how to compute it. If so, then I think we can conclude that the two manifolds must be homeomorphic by Friedman's classification of simply connected manifolds. Is this reasoning correct?","['general-topology', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
2996301,How to integrate over the standard $n$-simplex directly in $\mathbb{R}^{n+1}$?,"Definition of standard $n$ -simplex The standard $n$ -simplex contains all points $\vec{x} \in \mathbb{R}^{n + 1}$ such that $0 \le x_i \le 1$ and $\vec{x} \cdot \vec{1} = 1$ . My definition of the area of $n$ -simplex $$A_{n} =  \frac{\sqrt{n+1}}{n!}.$$ The standard $2$ -simplex is an equilateral triangle with side length $\sqrt{2}$ and vertices at $(1, 0, 0)$ , $(0, 1, 0)$ , and $(0, 0, 1)$ . The area is $A_{2} = \dfrac{\sqrt{3}}2$ . The standard $1$ -simplex is a line with vertices at $(1, 0)$ and $(0, 1)$ . The length is $A_{1} = \sqrt{2}$ I found the area of the standard $n$ -simplex by first moving the simplex from $\mathbb{R}^{n+1}$ to $\mathbb{R}^{n}$ . Area of standard simplex Question How to directly integrate over the standard $n$ -simplex with the coordinates of $\mathbb{R}^{n+1}$ ? I can't use the change of coordinate formula because the Jacobian of the transformation from $\mathbb{R}^{n}$ to $\mathbb{R}^{n+1}$ is rectangular. Thanks.","['integration', 'geometry', 'multivariable-calculus', 'calculus', 'linear-algebra']"
2996474,Square coloring problem only using 2 colors,"""We need to color $4×4$ square using $4$ black color and $12$ white color. Then, how many cases it may be? Flip is prohibited but rotating is ok"" I tried case by case (inner square and rest) anf obtained answer 389. But I don't know if it's correct. Help me please.","['polya-counting-theory', 'combinatorics', 'coloring']"
