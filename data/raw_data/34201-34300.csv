question_id,title,body,tags
326107,$\sum_{i=0}^m \binom{m-i}{j}\binom{n+i}{k} =\binom{m + n + 1}{j+k+1}$ Combinatorial proof,"Is there a simple combinatorial proof for the following identity? $$\sum_{0\leq i \leq m} \binom{m-i}{j}\binom{n+i}{k} =\binom{m + n + 1}{j+k+1}$$
where $m,j \geq 0$, $k \geq n \geq 0$.","['summation', 'binomial-coefficients', 'combinatorics']"
326128,How can I define a function to show that $\{3^n\mid n\in\mathbb{Z}\}$ is countably infinite?,"I have to answer the following question for an assignment: Is the set $A=\{3^{n}\mid n\in\mathbb{Z}\}$ finite, countably infinite, or uncountable? I've defined what I originally thought to be a proper function rule showing a bijection from $\mathbb{N}$ to $A$, but I've since realized that I'm missing some elements in the codomain. \begin{equation*}
  f:\mathbb{N}\to A:\left\{
    \begin{array}{ll}
      n\mapsto 3^{n},&\text{if $n=2k-1$ for some $k\in\mathbb{N}$}\\
      n\mapsto 3^{-n},&\text{if $n=2k$ for some $k\in\mathbb{N}$}
    \end{array}\right.
\end{equation*} Here, I noticed that I'm missing all the odd negative numbers and all the even positive numbers. Is this even doable this way, or do I need to draw a diagram? I'd much prefer to have a function definition if possible.",['elementary-set-theory']
326129,"Show that the subset $D= \{(x,y)~|~x \ne 0, y \ne 0\}$ of the plane is open","$D= \{(x,y)~|~x \ne 0, y \ne 0\}$ I'm thinking I can show that the set is open for $x \gt 0$ and $y \gt 0$ using disks. Maybe I could do the same for $x \lt 0$ and $y \lt 0$. But this process seems too long.",['general-topology']
326135,Convergence of a sequence function,"Show that the sequence of function $F_n(z)=\frac{z^n}{z^n-3^n},\
 n=1,2,...,\ $ converges to zero for $|z|<3$ amd to $1$ for $|z|>3$. How can I show this? I can see why it will converge to zero when $|z|<3$, but can't see why it converges to $1$ when $|z|>3$.",['complex-analysis']
326145,A locally compact subset of a Hausdorff space is locally closed,"Let $X$ be a Hausdorff space. Show that if $Y \subset X$ is locally compact, then $Y$ is locally closed, in essence $Y$ is an open subset of $\overline{Y}$ , where $\overline{Y}$ has the subspace topology inherited by $X$ . I really don't have any ideas how to go about this. Any help will be most appreciated!","['general-topology', 'compactness']"
326147,Bounds on a sum of gcd's,"Does there exist a positive real number $C$ and a positive integer $M$ such that for all $n > M$ we have: $$\sum_{i=1}^n\sum_{j=1}^n\gcd (i, j)\ge Cn^2 \log n$$ This originally appeared as an Olympiad problem in the case of $4n^2$ on the RHS. This case was much simpler; simply let $i$ only range on primes values and one quickly derives a $\omega \left ( n^2 \log \log \frac{n}{\log n} \right )$ bound if I didn't mess up. The motivation for above bound is derived from the fact that $$\sum_{j=1}^n \gcd(i,j) \approx \frac{n}{i} \sum_{d|i} \varphi(i/d) \cdot d \approx n \cdot \tau(i) \cdot \frac{6}{\pi^2}$$
So we have:
$$\sum_{i=1}^n\sum_{j=1}^n\gcd (i, j) \approx \frac{6n^2}{\pi^2} \sum_{i=1}^n \frac{1}{i} \approx \frac{6}{\pi^2} n^2 \log n$$ However, this is pretty unrigorous  reasoning. Does anybody have any ideas as to how to rigorously prove this bound? Of course, showing that the sum in fact gets ""close"" to $\frac{6}{\pi^2} n^2 \log n$ as $n \to \infty$ would be even better.","['analytic-number-theory', 'number-theory']"
326152,Error analysis for 4th order Runge-Kutta,Could anyone explain to me how to reduce the error propagated by using Runge-Kutta of order 4? Or can anyone give me a nice reference to it?,"['ordinary-differential-equations', 'approximation', 'runge-kutta-methods', 'reference-request', 'numerical-methods']"
326154,Is every open subset of $ \mathbb{R} $ uncountable?,"Is every open subset of $\mathbb{R}$ uncountable?  I was crafting a proof for the theorem that states every open subset of $\mathbb{R}$ can be written as the union of a countable number of disjoint intervals when this question came up.  I feel like the answer is yes, but I'm not sure how to go about proving it or whether there is a crazy construction (like the Cantor Set)  that creates a countable, open subset of $\mathbb{R}$. Any ideas?","['general-topology', 'real-analysis']"
326161,example of a totally bounded but not bounded,I have got an question:- is there any counter-example of totally bounded but not bounded space can anyone help me please.thanks for your help,['general-topology']
326166,Is any finite set necessarily closed and compact?,"If $X$ is a finite set, then $X$ is compact since any finite set is compact. $X$ is closed since its complement $\emptyset$ is open (in any topology on $X$). Something wrong?",['general-topology']
326172,The $ l^{\infty} $-norm is equal to the limit of the $ l^{p} $-norms. [duplicate],"This question already has answers here : Limit of $L^p$ norm (4 answers) Closed 10 years ago . If we are in a sequence space, then the $ l^{p} $-norm of the sequence $ \mathbf{x} = (x_{i})_{i \in \mathbb{N}} $ is $ \displaystyle \left( \sum_{i=1}^{\infty} |x_{i}|^{p} \right)^{1/p} $. The $ l^{\infty} $-norm of $ \mathbf{x} $ is $ \displaystyle \sup_{i \in \mathbb{N}} |x_{i}| $. Prove that the limit of the $ l^{p} $-norms is the $ l^{\infty} $-norm. I saw an answer for $ L^{p} $-spaces, but I need one for $ l^{p} $-spaces. Besides, I didn’t really understand the $ L^{p} $-answer either. Thanks for your help!","['functional-analysis', 'sequences-and-series', 'normed-spaces', 'real-analysis', 'lp-spaces']"
326180,"Multiply the matrices A1, A2, A3 of sizes 20 × 5, 5 × 50, 50 × 5? Ans is 1750 multiplications? how?","What is the most efficient way to multiply the matrices A1, A2, A3 of sizes 20 × 5, 5 × 50, 
50 × 5?
Answer is : A1(A2 A3), 1750 multiplications. how did they get the answer ? could someone show me please","['matrices', 'discrete-mathematics']"
326182,Billingsley's solution to 3.18 (b),"Problem 3.18(b) in Billingsley's Probability and Measure (3e) is Show that if $\lambda^*(E)>0$, then $E$ contains a nonmeasurable
  subset. [Here $\lambda^*$ is the Lebesgue outer measure.] In the ‘Notes on  the Problems’, on page. 556 the following solution is given If the $E \cap (H \oplus r)$ are all Borel sets, they all have
  Lebesgue measure $0$, and so $E$ is a Borel set of measure $0$. [Here $H$ is the Vitali set , $r$ implicitly ranges over all rational numbers and $\oplus$ denotes addition modulo 1.] It seems to me that the solution offered is wrong since the quoted sentence only implies that either $E$ is not Borel or one of $E \cap (H \oplus r)$ is not Borel. From this it does not follow that $E$ has a nonmeasurable subset. Am I right in thinking this? It also seems to me that it is not possible to solve this question given the material covered so far in Billingsley. Am I right in this? Just to clarify: I am aware that the statement to be proved is a standard theorem and I have found its proof in other books. My question is specifically regarding Billingsley solution/hint and whether the problem is solvable at this point in the text.","['probability-theory', 'measure-theory']"
326195,Chi-Square goodness-of-fit test on sample space or quantiles?,"I think there are two ways to perform the chi-Square goodness-of-fit test: Divide the sample space into bins of equal size and see how many observed values fall in each bin. where the expected per bin depends on the fit. Divide the cdf of the fit into B bins of equal size (e.g., five bins of size .2 each, or 8 bins of width .125 each) and see where each observed value would belong into. -> count observed values per bin of size  > calculate the chi square statistic ( where the expected nr per bin is n/B or observations/bins , since the quantiles are distributed uniformly) Is 2. a valid approach? And is there anything noteworthy about the second approach?",['statistics']
326197,The equivalence between Cauchy integral and Riemann integral for bounded functions,"Definitions Suppose $P\colon a=x_0<x_1<\dotsb<x_n=b$ is a partition of $[a,b]$. Let $\Delta x_k=x_k-x_{k-1}$ and $\lVert P\rVert$ denotes $\max_{0<k\le n}\Delta x_k$. The Cauchy integral of a function $f$ on closed interval $[a,b]$ equals to $I$ if and only if for each $\epsilon>0$, there's some $\delta>0$, for each partition $P$ of $[a,b]$ such that $\lVert P\rVert<\delta$, we have $\left\lvert\sum_{k=1}^nf(x_k)\Delta x_k-I\right\rvert<\epsilon$. Problem If $f$ is bounded on $[a,b]$ whose Cauchy integral equals to $I$, then $f$ is Riemann-integrable and $\int_a^bf=I$. Background It's an exercise from our calculus(analysis) problemset book, and there's a hint: consider the partitions whose $x_k-x_{k-1}$ is a constant for different $k$'s, and try to estimate the Riemann sum for each of these partitions through the Cauchy integral. I have no idea about such estimation. After drawing some pictures, I discouraged. I googled on the Internet and found an article . I realized that it's a quite different approach and with some advanced techniques (such as the analysis of a positive measure set -- discontinuities). I hope there will be some simpler approachers, just as the hint says. I need a more detailed hint, or a solution. Can anybody help me? Thanks!","['definite-integrals', 'integration', 'real-analysis']"
326200,Orthogonal intersection in a Riemannian manifold,"Following is a question which I also asked in stats.stackexchange where I haven't got a response yet.  Here is a link . Let $S$ be the set of all probability distributions on $\mathbb{R}$ and $S_n=\{p_\theta\}$ be an $n$ dimensional submanifold of parameterized family of probability distributions on $\mathbb{R}$ where $\theta=(\theta_1,\dots, \theta_n)\in \Theta$ are called parameters of the probability density $p_\theta(x)$ and $\Theta$ is an open set homeomorphic to $\mathbb{R}^n$. It is also assumed that $p_\theta(x)>0$ for all $x$. For example, $$p_{\theta=(\mu,\sigma)}(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$$ where $\mu\in \mathbb{R},\sigma>0$ forms a $2$-dimensional submanifold. On this manifold, a Riemannian metric is defined by the following, called Fisher information metric. $$ g_{i,j}(\partial_i,\partial_j)=\int \partial_i \log p_\theta(x) ~\partial_j \log p_\theta(x) ~p_\theta(x)~dx$$ where $\partial_i=\frac{\partial}{\partial \theta_i}$. My question is regarding a point in page 384 from this Ann. Stat. paper by Amari. In the above mentioned paper, when he says a curve $\{q_t(x)\}$ in $S$, where $q_0(x)=p_\theta(x)$ intersects orthogonally $S_n$ at $p_\theta(x)$, he means $$\int \partial_i \log p_\theta(x) ~\frac{d}{dt} \log q_t(x)\lvert_{t=0} ~q_0(x)~dx=0$$. Why? Could somebody make me understand by giving intuitive explanation of these concepts?","['statistics', 'riemannian-geometry']"
326231,How to show $\phi(X)$ contains a non-empty open set of its closure $\overline{\phi(X)}$?,"From T.A.Springer, Linear Algebraic Groups, the end of Chapter 1. Assume $X\rightarrow Y$ is a morphism of varieties. Using a covering of $Y$ by affine open sets, we reduce the proof to the case that $Y$ is affine. Similarly we can also assume $X$ is affine. Now I need to prove $\phi(X)$ contains a non-empty open set of its closure $\overline{\phi(X)}$. Here $k$ is algebraically closed. Let $A=k[\overline{\phi(X)}]$, $B=k[X]$, What I know is there exist some $a\in A$ such that for any homomorphism from $A$ to $k$ such that $f(a)\not=0$, there is an extension  $f:B\rightarrow k$ with $f(1)\not=0$. It seems to me that any homomorphism $A\rightarrow k$ is a morphism of varieties $A^{1}\rightarrow \overline{\phi(X)}$ via the duality. So the fact that any such map non-vanishing on $a$ can be ''extended'' to $A^{1}\rightarrow X$ should give us what we wants. But this is far away from having a principle open set of the type $D_{f}=f(x)\not=0,x\in \overline{\phi(X)}$. I feel the logic at here is a bit inverted and I need some help to straighten it back. If anyone can give a hint how to prove this via Noether's normalization lemma I would be grateful.",['algebraic-geometry']
326238,In Helmholtz decomposition - why are the second components of the decomposition zero when $V$ is $\mathbb{R}^3$?,"$\varphi(\mathbf{r})=\frac{1}{4\pi}\int_{V}\frac{\nabla'\cdot\mathbf{F}(\mathbf{r}')}{\left|\mathbf{r}-\mathbf{r}'\right|}\mathrm{d}V'-\frac{1}{4\pi}\int_{S}\frac{\mathbf{F}(\mathbf{r}')\cdot\mathbf{\mathrm{d}S}'}{\left|\mathbf{r}-\mathbf{r}'\right|},$ $\mathbf{A}(\mathbf{r})=\frac{1}{4\pi}\int_{V}\frac{\nabla'\times\mathbf{F}(\mathbf{r}')}{\left|\mathbf{r}-\mathbf{r}'\right|}\mathrm{d}V'+\frac{1}{4\pi}\int_{S}\frac{\mathbf{F}(\mathbf{r}')\times\mathbf{\mathrm{d}S}'}{\left|\mathbf{r}-\mathbf{r}'\right|}.$ If $V$ is $\mathbb{R}^3$ itself (unbounded), and $F$ vanishes sufficiently fast at infinity, then the second component of both scalar and vector potential are zero. That is, $\varphi(\mathbf{r})=\frac{1}{4\pi}\int_{V}\frac{\nabla'\cdot\mathbf{F}(\mathbf{r}')}{\left|\mathbf{r}-\mathbf{r}'\right|}\mathrm{d}V',$ $\mathbf{A}(\mathbf{r})=\frac{1}{4\pi}\int_{V}\frac{\nabla'\times\mathbf{F}(\mathbf{r}')}{\left|\mathbf{r}-\mathbf{r}'\right|}\mathrm{d}V'.$ Why is it true that second components of these two potentials are zero?",['multivariable-calculus']
326240,Proof of Cartesian product intersection [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Let $A, B, C, D$ be sets. How to prove $( A \times B ) \cap ( C \times D ) = ( A \cap C ) \times ( B \cap D )$ ?",['elementary-set-theory']
326252,If radial projection is bijective then is it a homeomorphism?,"Suppose $S$ is a regular surface in $\mathbb{R}^3 $ and $0\not\in S$. Now consider the radial projection $f: S\to\mathbb{S}^2$ given by $$f(x)=\frac{x}{||x||} \hspace{5mm}\mbox{ for all $x\in S$}$$ Now suppose $f$ is bijective, then does this imply that $f$ is a homeomorphism ? If not in general, is it true when $S$ is compact ?","['general-topology', 'surfaces']"
326253,$\lim_{n\to\infty}(\sqrt{n^2+n}-\sqrt{n^2+1})$,How to evaluate $$\lim_{n\to\infty}(\sqrt{n^2+n}-\sqrt{n^2+1})$$ I'm completely stuck into it.,"['sequences-and-series', 'real-analysis']"
326281,Does there exist a finite group with the following presentation?,"Let $G$ be a finite group (with only two generators and $m=n$) presented as $$ G = \langle a, b : a^m = b^n = (W(a,b))^p= \ldots\text{other-such-relations}\ldots= 1 \rangle $$ where $m,n,p>1$ , and taking the smallest $p$ for each $W(a,b)$ which is  made out of products of $a$ and $b$, e.g. $(ab)^2$, $(ab^2ab^{-1})^3$ etc. I know three examples 1) Dihedral groups of order $n$:  $ G = \langle a, b : a^2 = b^2 = (ab)^n= 1 \rangle $ 2) Another two from the following paper (page 2) and presented as : J. Howie, V. Metaftsis, and R. M. Thomas. Finite generalized triangle groups. Trans. Amer. Math. Soc., 347(9):3613–3623, 1995 $$ G = \langle a, b : a^3 = b^3 = (abab^2)^2= 1 \rangle $$ of order 180 and $$ G = \langle a, b : a^3 = b^3 = (aba^2b^2)^2= 1 \rangle $$ of order 288. Now, after going through the list of finite group presentations, I could not find any other finite group with such a presentation (i.e only two generators and  $m=n$). So, are there any other examples? Or is it possible to give arguments why there might not exist any other example? References will also be useful. Thank you.","['abstract-algebra', 'finite-groups', 'reference-request', 'group-presentation', 'group-theory']"
326283,"Finding the sum $\sum\limits_{n=1,n\neq m^2}^{1000}\left[\frac{1}{\{\sqrt{n}\}}\right]$,","Find the value 
$\displaystyle\sum_{n=2,n\neq m^2}^{1000}\left[\dfrac{1}{\{\sqrt{n}\}}\right]$, by $\{x\}=x-[x]$,
$[x]$was bracket function,for example:$[5.4]=5, [2.9]=2,[-1.1]=-2 $and so on.",['sequences-and-series']
326287,Is the union of two cartesian products equal to the product of their unions? [duplicate],"This question already has answers here : Is it always true that $(A_1 \cup A_2) \times (B_1 \cup B_2)=(A_1\times B_1) \cup (A_2 \times B_2)$ (4 answers) Closed 11 years ago . Can we prove that
$$(A \times B)\cup (C \times D) = (A \cup C) \times (B \cup D)  \;?$$
If my understanding is correct, we cannot prove because we do not know if $A \times B$ and $C \times D$ share common elements or not. Please tell me if I'm wrong.",['elementary-set-theory']
326293,"Can commuting matrices $X,Y$ always be written as polynomials of some matrix $A$?","Consider square matrices over a field $K$. I don't think additional assumptions about $K$ like algebraically closed or characteristic $0$ are pertinent, but feel free to make them for comfort. For any such matrix $A$, the set $K[A]$ of polynomials in $A$ is a commutative subalgebra of $M_n(K)$; the question is whether for any pair of commuting matrices $X,Y$ at least one such commutative subalgebra can be found that contains both $X$ and $Y$. I was asking myself this in connection with frequently recurring requests to completely characterise commuting pairs of matrices, like this one . While providing a useful characterisation seems impossible, a positive anwer to the current question would at least provide some answer. Note that in many rather likely situations one can in fact take $A$ to be one of the matrices $X,Y$, for instance when one of the matrices has distinct eigenvalues , or more generally if its minimal polynomial has degree $n$ (so coincides with the characteristic polynomial). However this is not always possible, as can be easily seen for instance for diagonal matrices $X=\operatorname{diag}(0,0,1)$ and $Y=\operatorname{diag}(0,1,1)$. However in that case both will be polynomials in $A=\operatorname{diag}(x,y,z)$ for any distinct values $x,y,z$ (then $K[A]$ consists of all diagonal matrices); although in the example in this answer the matrices are not both diagonalisable, an appropriate $A$ can be found there as well. I thought for some time that any maximal commutative subalgebra of $M_n(K)$ was of the form $K[A]$ (which would imply a positive answer) for some $A$ with minimal polynomial of degree$~n$, and that a positive answer to my question was in fact instrumental in proving this. However I was wrong on both counts: there exist (for $n\geq 4$) commutative subalgebras of dimension${}>n$ (whereas $\dim_KK[A]\leq n$ for all $A\in M_n(K)$) as shown in this MathOverflow answer , and I was forced to correct an anwer I gave here in the light of this; however it seems (at least in the cases I looked at) that many (all?) pairs of matrices $X,Y$ in such a subalgebra still admit a matrix $A$ (which in general is not in the subalgebra ) such that $X,Y\in K[A]$. This indicates that a positive answer to my question would not contradict the existence of such large commutative subalgebras: it would just mean that to obtain a maximal dimensional subalgebra containing $X,Y$ one should in general avoid throwing in an $A$ with $X,Y\in K[A]$. I do think these large subalgebras easily show that my question but for three commuting matrices has a negative answer. Finally I note that this other answer to the cited MO question mentions a result by Gerstenhaber that the dimension of the subalgebra generated two commuting matrices in $M_n(K)$ cannot exceed$~n$. This unfortunately does not settle my question (if $X,Y$ would generate a subalgebra of dimension${}>n$, it would have proved a negative answer); it just might be that the mentioned result is true because of the existence of $A$ (I don't have access to a proof right now, but given the formulation it seems unlikely that it was done this way). OK, I've tried to build up the suspense. Honesty demands that I say that I do know the answer to my question, since a colleague of mine provided a convincing one. I will however not give this answer right away, but post it once there has been some time for gathering answers here; who knows somebody will prove a different answer than the one I have (heaven forbid), or at least give the same answer with a different justification.","['matrices', 'linear-algebra', 'abstract-algebra']"
326299,Two proofs concerning Hölder's inequality,"I am studying functional analysis and I have come across two statements which can be proven by using Hölder's inequality, but I don't know how/why. Reminder: let $a\in l^p$ and $b\in l^q$, then:
$$
||ab||_1 = \sum_{i}|a_ib_i| \leq ||a||_p||b||_q = (\sum_i |a_i|^p)^{1/p}(\sum_j |b_j|^q)^{1/q},
$$
for $1/p + 1/q = 1$. 1) Proof that $l^p$ is a normed space.
I guess I should use this inequality when showing that for arbitrary $x$ and $y$ $$||x+y||_p\leq||x||_p +||y||_p,$$ but I really can't see how to use Hölder's inequality as it involves products rather than sums. 2) Proof that $l^q\subseteq (l^p)^*$, where the star denotes the dual space. I guess I should prove that for an arbitrary $x\in l^q$ we have that $x$ defines a map $x:l^q \rightarrow \mathbb{R}$, but I have no clue how to do this.","['normed-spaces', 'inequality', 'functional-analysis', 'lp-spaces']"
326320,Good problems in Algebraic Geometry,"I am now using Fulton's book Algebraic Curves to learn algebraic geometry from and have just finished chapter 2. However I feel that the problems are not very inspiring (at the moment at least) and lack some depth. Where is a good source of problems in algebraic geometry that I can find at least at the level of Fulton? I don't mind if people recommend specific problems from Hartshorne say as long as I can do them with the tools I have from Fulton. To be more specific, the next chapter of Fulton is on local properties of plane curves and computing intersection numbers, so if one can recommend problems for these, it would be good. Thanks.","['algebraic-geometry', 'reference-request']"
326328,The minimum number of mice required to find a poisoned bottle.,"Here's an interesting question. There are $1000$ mice and $1000$ bottles (numbered $1,2,3....1000$). One of the bottles is poisoned.  You can mix the solution with the other bottles any number of times.  Even a fraction of poison can kill a mouse.  Whats the minimum number of mice required to check which bottle is poisoned? There's a proof which involves grouping (which I'm aware of).  I want a better mathematical proof.","['puzzle', 'elementary-set-theory']"
326334,A question about the arctangent addition formula.,"In the arctangent formula, we have that: $$\arctan{u}+\arctan{v}=\arctan\left(\frac{u+v}{1-uv}\right)$$ however, only for $uv<1$. My question is: where does this condition come from? The situation is obvious for $uv=1$, but why the inequality? One of the possibilities I considered was as following: the arctangent addition formula is derived from the formula: $$\tan\left(\alpha+\beta\right)=\frac{\tan{\alpha}+\tan{\beta}}{1-\tan{\alpha}\tan{\beta}}.$$ Hence, if we put $u=\tan{\alpha}$ and $v=\tan{\beta}$ (which we do in order to obtain the arctangent addition formula from the one above), the condition that $uv<1$ would mean $\tan\alpha\tan\beta<1$, which, in turn, would imply (thought I am NOT sure about this), that $-\pi/2<\alpha+\beta<\pi/2$, i.e. that we have to stay in the same period of tangent. However, even if the above were true, I still do not see why we have to stay in the same period of tangent for the formula for $\tan(\alpha+\beta)$ to hold. I would be thankful for a thorough explanation.",['trigonometry']
326343,$\lim_{x\to\infty}\sqrt [n] {p_n(x)}-\sqrt [m] {p_m(x})$ where $p_k(x)$ is polynomial of order k.,"What is the easiest way to evaluate 
$$
\lim_{x\to\infty}\sqrt [n] {p(x)}-\sqrt [m] {q(x})
$$ where $p,q\in\mathbb{R}[x]$ with $\deg p= n$, $\deg q=m$ .","['polynomials', 'real-analysis', 'limits']"
326351,Nice corollaries to Poincaré-Bendixson theorem,"I am interested in applications of Poincaré-Bendixson theorem not (explicitely) related to ODEs. Let $X \in C^1(\mathbb{R}^2,\mathbb{R}^2)$ , $(t_0,x_0) \in \mathbb{R} \times \mathbb{R}^2$ and $x \in C^1(\mathbb{R},\mathbb{R}^2)$ a solution to the IVP $\begin{cases}x'=X(x) \\ x(t_0)=x_0\end{cases}$ The $\omega$ -limit of $x_0$ (or of $x$ ) is $\omega(x_0)=\{ y \in \mathbb{R}^2 : \exists (t_n) \ \text{such that} \ t_n \to + \infty, \ x(t_n)\to y \}$ . Theorem (Poincaré-Bendixson) If $\omega(x_0)$ is nonempty, compact and does not contain any zero of $X$ , then $\omega(x_0)$ is a periodic orbit. Some consequences: Theorem ( $C^1$ -version of Brouwer's fixed point theorem in dimension two) Let $f : \overline{D} \to \overline{D}$ be a $C^1$ function from the closed unit disk to itself. Then $f$ has a fixed point. Theorem ( $C^1$ -version of the hairy ball theorem in dimension two) A $C^1$ -vector field on $\mathbb{S}^2$ has a zero. Do you know other consequences of Poincaré-Bendixson theorem not related to differential equations? For example, can the fundamental theorem of algebra be proved like that?","['dynamical-systems', 'ordinary-differential-equations']"
326358,A question about the quotient of a $K$-algebra by its radical.,"Let $A$ be a $K$-algebra and $B=A/\operatorname{rad} A$, where $\operatorname{rad}A$ is the radical of $A$ (intersection of all maximal right ideals of $A$).  Let $e$ be an idempotent of  $A$ and $\bar{e}=e+\operatorname{rad} A$. How to show that $eA/\operatorname{rad} eA$ is isomorphic to $\bar{e}B$? We have $\bar{e}B=(e+\operatorname{rad} A)(A/\operatorname{rad} A)$. The elements in $\bar{e}B$ is of the form $ea+\operatorname{rad} A$, where $a \in A$. But the elements of $eA/\operatorname{rad} eA$ is of the form $ea+\operatorname{rad} eA$, where $a \in A$. This question comes from the reading of the book (page 21, line 1 of the proof of Proposition 4.5 of the book Elements of the Representation Theory of Associative Algebras: Volume 1 ). Another question is how to show that $\operatorname{rad} eA = eA \operatorname{rad} A = e \operatorname{rad} A$? Thank you very much.","['modules', 'representation-theory', 'abstract-algebra']"
326360,Ext between two coherent sheaves,"Let $X$ be a smooth projective variety over a field $k = \overline k$. From Hartshorne we know, that $\textrm{dim} \, H^i (X,F)<\infty$ for any coherent sheaf $F$. How to show, that all $Ext^i (F,G)$ are finite-dimensional for coherent $F$ and $G$? And how to show, that for $F,G \in D^b (Coh(X))$ : $Ext^i (F,G)$ are finite-dimensional? May be, we should use a spectral sequence $E^{p,q}_2 = Ext^p (F, H^q(G)) \Rightarrow Ext^{p+q} (F,G)$?","['derived-functors', 'homological-algebra', 'algebraic-geometry']"
326365,On the ambiguity of the definition of Lie algebras of real matrix groups,"I have been studying Rossmann's Lie Groups . In the context of this book, a linear group $G$ is a group of invertible real or complex matrices, and its Lie algebra $\mathfrak{g}$ consists of those matrices $X$ for which the exponential $e^{tX}$ belongs to $G$ for every $t\in\mathbb{R}$. As far as I understand, the matrices $X$ which are candidates to be an element of $\mathfrak{g}$ are taken a priori to be real if $G$ consists of real matrices. However, we can of course regard any such $G$ as a group of complex matrices as well; in any case, one should get the same $\mathfrak{g}$. This is what I want to prove. It is clearly enough to show this for $G=\mathrm{GL}(n,\mathbb{R})$. Therefore, I want to show that any complex matrix $X$ for which $e^{tX}$ is real for every $t\in\mathbb{R}$ is itself real. This is easy to see if $X$ is diagonal, but what about general $X$? Any reference or sketch of proof is welcome.","['matrices', 'lie-algebras', 'lie-groups']"
326371,Limit $\lim_{n\to\infty}\frac{1}{n}\sum_{k=0}^n\cos\frac{\pi k}{2n}=\frac{2}{\pi}$,"Please help me to show that
$$\lim_{n\to\infty}\dfrac{1}{n}\sum_{k=0}^n\cos\dfrac{\pi k}{2n}=\dfrac{2}{\pi}$$ I'm absolutely clueless. A hint rather than a complete solution would be more appreciated!","['sequences-and-series', 'real-analysis']"
326375,Looking for a logically coherent book for the self-study of differential equations,"I'm looking for a logically coherent book for the self-study of differential equations. Let me clarify. By logically coherent, I don't mean proofs of the limit laws, uniqueness theorems etc. By logically coherent, I do mean that the writer goes beyond the ""scratchwork"" (Phase 1) and does the remainder of the problem (Phases 2,3 and 4). For example, here's a more or less acceptable solution to the problem $y' = y.$ Phase 1 - Scratchwork. Assume $y' = y$. (Scratchwork always begins with the assumption of the equation to be solved). Assume also that $y \neq 0$. (In the scratchwork phase, you can just assume things like this without justification). Then $\dfrac{y'}{y} = 1$, or in other words $\dfrac{1}{y}\dfrac{dy}{dx}=1$. Therefore, there exists $C$ such that $$\int \frac{dy}{y} = x + C.$$ Thus, there exists $C$ such that $$\log y = x + C.$$ This same $C$ must therefore satisfy $y = e^x e^C$. Thus, there exists $C$ such that $y = Ce^x$. Conclusion : For all real $C$, we have a prospective solution of the form $y = Ce^x$. Phase 2 - Soundness. We will show that for all real $C$, if $y=Ce^x$, then $y'=y$. Proof . Assume $C$ is real and that $y=Ce^x$. Then since $y = Ce^x$, it follows that $y' = Ce^x$, thus $y'=y$, as required. Phase 3 - Proliferation. This is a phase that is sometimes needed, wherein we produce new solutions from the one's we've already found. e.g. if we only knew that $y=e^x$ was a solution, then we could use the linearity of the DE to show that $y=Ae^x$ is a solution. This isn't necessary, in this particular case. Phase 4 - Completeness. We will show that for all real $C$, if its not the case that $y=Ce^x$ everywhere, then its not the case that $y'=y$ everywhere. Proof . By [Insert Theorem Here], the result follows.","['ordinary-differential-equations', 'self-learning', 'reference-request']"
326382,Having trouble solving question involving parametric equations,"I have been given the following: $$y = a \cdot \cos^3t$$  $$x = a \cdot \sin^3t$$ $$0 \leqslant t \leqslant {\frac\pi2}$$ I am supposed to show that the mean value of $y$ over the interval $0\leqslant x \leqslant a$ is given by: $$m = 3a\int^{\frac12\pi}_0(\cos^4t-\cos^6t)dt$$ I know that the mean fomula is given by: $$m=\frac1{b-a}\int^b_aydx$$ But I'm having trouble finding an equation for $y$ in terms of $x$. In addition, I am confused as to how the final answer will be given as an integral in terms of $t$. I thought I should differentiate $y$, $x$ in terms of $t$ then maybe I would find a substitution: $$\frac{dy}{dt} = -3a \cdot \cos^2t \cdot \sin t$$
$$\frac{dx}{dt} = 3a \cdot \cos t \cdot \sin^2t$$ $$\frac{dy}{dx} = \frac{dy}{dt} \cdot \frac{dt}{dx} = \frac{-3a \cdot \cos^2t \cdot \sin t}{3a \cdot \cos t \cdot \sin^2t} = -\frac{\cos t}{\sin t} = -\cot t$$ Now I'm facing two problems: I can't integrate both sides to get $y$ in terms of $x$ because the trigonometric function on R.H.S. is still in terms of $t$ Even if I did integrate this method seems too inefficient What's the most appropriate method of solving this?","['parametric', 'algebra-precalculus', 'integration']"
326383,Is $-\frac47$ a proper fraction?,"I was asked this question by a kid: Is $- \frac{4}{7}$ a proper fraction or not? As per my knowledge, $\frac{4}{7}$ is a proper fraction. If it has a negative number, does it make any difference? Definition says: A number whose numerator is smaller than denominator is called a proper fraction. Can we consider $- \frac{4}{7}$ as a proper fraction? If not, why? Please explain. EDIT: I have got these links from comments wiki link and a link form math world and both contradicting each other. Thank you.","['fractions', 'algebra-precalculus']"
326394,Product of two regular varieties over an imperfect field,"I am trying to find a counterexample to the following, but am unable to find one. Any help would be appreciated, and also an explanation of why it works. I am trying to show that over an imperfect field k, the fiber product of two regular varieties can fail to be regular. For an algebraically closed field, every product of regular varieties is regular, but the same shouldn't hold for imperfect.",['algebraic-geometry']
326400,"How does one show that $K_1 \cap K_2 $ is compact, when $K_1 , K_2$ are compact?","Let $(X,d_X) $ be a metric space and $K_1 , K_2 $ be compact subspaces of $X$. Question: how does one show that $K = K_1 \cap K_2$ is compact? I tried proving this by noting the following theorem: Let $Y \subseteq X$.
If $X$ is compact and $Y$ is closed in $X$, then $Y$ is compact. We know, that compact spaces are closed. So in particular, we know that $K_1$ and $K_2$ are closed. We also know, that intersections of closed subspaces are closed, so $K$ is closed in $\Omega$. We also know, that $K \subseteq K_1$. We can apply this theorem, if we can show that $K$ is closed in $K_1$. Question: how do we do this? Can we do this at all, given the information above? Furthermore, I was wondering whether I'm on the right track, or if there's some other, perhaps ""easier"" way to show that $K$ is compact?","['general-topology', 'metric-spaces']"
326403,"Solving a sine inequality, need intuition","We have the function $f(x) = \sin (2x - \dfrac{1}{3} \pi)$ on the domain $ [0, 1\dfrac{1}{2} \pi ]$. Solve the inequality: $f(x) > \dfrac{1}{2}$ So I got to this point (I wrote it as in equality first): $$x= \dfrac{1}{4} \pi + k\pi \vee x = \dfrac{7}{12} \pi + k\pi$$ This would yield the solutions $\dfrac{1}{4}\pi$, $1\dfrac{1}{4}\pi$ and $\dfrac{7}{12}\pi$. But my problem is, I don't know when $f(x) > 0.5$. I need some intuition (preferably using the unit circle) to figure out what the conditions would be.",['trigonometry']
326405,finding the derivative using quotient rule and product rule,"find dy/dx; a) $\frac{1-2x}{\sqrt{2+x}}$ b.) $3x(1-x^2)^{1/3}$ My attempt at a)
use the quotient rule: so $dy/dx = -2 \sqrt{2+x}+ (1-2x)0.5(2+x)^{-1/2}$
but then I get stuck there, cannot simplify it, wolfram gives a nice simplified answer but not sure how to get it. b.) Product rule: $dy/dx= 3(1-x^2)^{0.5} + 3 \times 1/3 \times (1-x^2)^{-2/3}$ and again i can't seem to simplify that either to a nice wolfram answer.","['calculus', 'derivatives']"
326417,Finding the $x$ and $y$ values such that the partial derivatives are zero simultaneously,"$f(x,y) = x^2 + 4xy + y^2 -4x + 16y + 3$ So, I proceeded with taking the partial derivatives: $f(x,y)_x = 2x + 4y - 4$ and $f(x,y)_y = 4x + 2y + 16$ and $f(x,y)_x = f(x,y)_y = 0$ $2x + 4y - 4 = 4x + 2y + 16$. This leads to a linear equation. However, they came out with a specific ordered pair, $(-6, 4)$ What did I do wrong?","['multivariable-calculus', 'algebra-precalculus']"
326436,Every subset of A is f-saturated,"Let $f:A\rightarrow B$ be a function such that $\forall X\subseteq A[ f^{-1}[f[X]]=X]$ (In other words, every subset of $A$ is $f$-saturated). Does the property of the function $f$ have a name ? I understand that there might not be a name (In this case I will delete my question). In case there is a term, I don't want to miss it. Thank you","['terminology', 'functions']"
326443,Finding the sum of values,"The number $2001$  can be written in the form of $x^2-y^2$ when $x,y$ are positive integers  in four different ways ,then how to find the the sum of $x$ values",['algebra-precalculus']
326452,If $\operatorname{Spec} A$ is not connected then there is a nontrivial idempotent,"I'm solving a problem from Atiyah-Macdonald. I have to show that if $X=\operatorname{Spec} A$ is not connected then $A$ contains idempotents $e \neq 0,1$ . The converse is easy. If $e \in A$ is an idempotent then $(e)+(1-e)=(1)$ and $(e)\cdot(1-e)=0$ so that $$
  V(e) \cup V(1-e) = V(  (e) \cdot(1-e))=V(0) = X, \\
  V(e) \cap V(1-e) = V( (e)+(1-e))=V(1)=\varnothing
$$ then $V(e)$ and $V(1-e)$ are both closed and open and $X$ is not connected. Now let $\mathfrak{a}$ and $\mathfrak{b}$ be ideals in $A$ such that $V(\mathfrak{a}) \cup V(\mathfrak{b})=X$ , $V(\mathfrak{a}) \cap V(\mathfrak{b}) = \varnothing$ . Then $$
   V(\mathfrak{a}) \cup V(\mathfrak{b}) = V( \mathfrak{a} \cap \mathfrak{b} ) = X,
$$ i.e. $\left\{ \mathfrak{p} - \text{prime} \mid \mathfrak{a} \cap \mathfrak{b} \subseteq \mathfrak{p}  \right\} = X$ , i.e. $\mathfrak{a} \cap \mathfrak{b} \subseteq \cap \mathfrak{p} = \mathfrak{n}$ (nilradical). On the other hand since $$
  V(\mathfrak{a}) \cap V(\mathfrak{b}) = V(\mathfrak{a}+\mathfrak{b})=\varnothing
$$ we have $\left\{ \mathfrak{p} - \text{prime} \mid \mathfrak{a}+\mathfrak{b} \subseteq \mathfrak{p} \right\} = \varnothing$ . Then $\mathfrak{a}+\mathfrak{b}=(1)$ because any ideal that is not equal to $(1)$ is contained in some maximal ideal. Then $\mathfrak{a}$ and $\mathfrak{b}$ are comprime and $\mathfrak{a} \cdot \mathfrak{b} = \mathfrak{a} \cap \mathfrak{b}$ . So I have two ideals $\mathfrak{a}$ and $\mathfrak{b}$ with properties $$
   \mathfrak{a} + \mathfrak{b} = (1), \\
   \mathfrak{a} \cdot \mathfrak{b} = \mathfrak{a} \cap \mathfrak{b} = \mathfrak{n}.
$$ I don't see any way to obtain a nontrivial idempotent $e \in A$ here. Please help me.","['commutative-algebra', 'ideals', 'algebraic-geometry']"
326483,"Show that $f(z)$ has no antiderivative in $\,S=\mathbb{C}\setminus \{-i,i\}$",$f(z)=\frac{1}{z^{2}+1}$ I know that you can do this using a proof by contradiction and by showing that if you assume it has an anti-derivative that it wouldn't follow the fundamental theorem of calculus which would be a contradiction but I don't know how to show this.,"['integration', 'complex-analysis']"
326498,Find separable irreducible $g$ such that $f(x)=g(x^{p^d})$,"This is an exercise from VII.4. in Algebra: Chapter 0 . Let $\mathcal{k}$ be a field of characteristic $p$, and $f(x)\in\mathcal{k}[x]$ an inseparable irreducible polynomial. Find a separable irreducible $g\in\mathcal{k}[x]$ such that \begin{equation}f(x)=g(x^{p^d})\end{equation}for some $d\in\mathbb{N}$. I have been looking at this problem for a while but I guess I am missing some tricks. I guess Frobenius map would come up somewhere. Also it might help to know that $f$ must be of the form \begin{equation}
f(x)=a_0+a_1x^p+a_2x^{2p}+\cdots+a_sx^{sp}.
\end{equation} Can someone give a hint? Thanks!","['field-theory', 'abstract-algebra', 'polynomials']"
326505,Sipser Pumping Lemma Clarification,"In a Theory of Computation book I am using, the explanation of Pumping Lemma is not bad, but some parts of it are not clear to me. Here is the Definition of Pumping Lemma: If A is a regular language, then there is a number p (the pumping length) where, if s is any string in A of length at least p, then s may be divided into three pieces, s = xyz, satisfying the following conditions: for each $i \ge 0$, $xy^iz\in A$, $|y| > 0$ $|xy|\le p$ Now while explaining why the classic language $B=\{0^n1^n\mid n \ge 0\}$, is not a regular, Sipser gives the following explanations: Assume the contrary is regular, assume $B$ is regular. Let $p$ be the pumping length given by the pumping lemma. Choose $s$ to be the string $0^p1^p$. Because $s\in B$ and $s$ has length more than $p$, the pumping lemma guarantees that $s$ can be split into three pieces, $s=xyz$, where for any $i\ge 0$ the string $xy^iz\in B$. However, these cases make this impossible (causing a contradiction): Case 1 . The string $y$ consists only of $0$s. In this case the string $xyyz$ has more $0$s than $1$s and so it is not a member of $B$, violating condition 1 of the pumping lemma. Question: I don't understand why assuming $y$ consists of only $0$s, automatically means that the tring $xyyz$ may have more $0$s than $1$s. The string $x$ may be comprised of any number of $0$s and the string $y$ may be comprised of any number of $1$s? My question is, how come the string $xyyz$ results in there being more $0$s than $1$s? Case 2. The string $y$ consists of both $0$s and $1$s. In this case the string $xyyz$ may have the same number of $0$s and $1$s, but they will be out of order with some $1$s before $0$s. Hence it is not a member of $B$. Question: Again, with this explanation, I don't understand how they concluded that the string $xyyz$ may have both $0$s and $1$s but out of order, causing a contradiction. I appreciate any clarification. Many thanks in advance!","['discrete-mathematics', 'proof-writing']"
326507,Application of the Banach fixed-point theorem,"I am looking for a function $f:[0,1]\rightarrow\mathbb R$ which satisfies $$\int_{0}^{1}\frac{\sin(f(t)-y)}{2}\,\mathrm dy=f(t)$$ for $t\in[0,1]$. The first thing I do is to define a function $A:M\rightarrow M$ where $M=C([0,1])$ with $$A(f)(t)=\int_{0}^{1}\frac{k(f(t),y)}{2}\,\mathrm dy.$$ Set $$k(x,y)=\sin(x-y).$$ Then $k$ is Lipschitz-continuous with respect to the first variable with Lipschitz constant $1$. Therefore I am looking for a unique function $f$ which satisfies $A(f)=f$. How can it be calculated explicitly?","['fixed-point-theorems', 'general-topology', 'functions', 'real-analysis', 'functional-analysis']"
326509,A question on generic point and a question on Hartshorne,"On page 134, Weil divisors, example 6.5.2, he said: ""The divisor of $y$ is $2Y$, because $y=0$ implies $z^2=0$, and $z$ generate the maximal ideal of the local ring at the generic point of $Y$."" I was stupid and can not figure this out. Can someone give a down to earth computation what is the generic point of $Y$(Depict it using prime ideals), and what is the local ring at the generic point of $Y$? Further, you are give a closed subset of $X$, cut out by several polynomials, how can you compute the generic point of this subset at once?",['algebraic-geometry']
326510,Sequences in $\ell_1$ which converge in the weak*-topology (wrt $c_0$) but not weakly,Consider $\ell_1$ as a dual of $c_0$. It is well known that there must exist sequences of elements in $\ell_1$ which converge in the weak*-topology (wrt $c_0$) but not weakly. Can one give an example (likely using ultrafilters / Banach limits) of such a sequence?,"['functional-analysis', 'examples-counterexamples', 'banach-spaces', 'weak-convergence', 'lp-spaces']"
326512,Show that we can define a connection on any manifold using partitions of unity,"Suppose that $(U,\varphi)$ is a chart on manifold $M$, and $X,V$ are vector fields on manifold $M$, then we can write:
$$X=\sum_{i=1}^{i=n}X^{i}\frac{\partial}{\partial x^{i}}$$ on $U$, and define a connection on $U$ by: $$D_{V}X=\sum_{i=1}^{i=n}(VX^{i})\frac{\partial}{\partial x^{i}}\cdots\tag{1}$$ Let $\{U_{j}\}_{j=1}^{\infty}$ be a locally finite covering of $M$, where each $U_{j}$ is coordinate neighborhood on $M$. Let $D^{j}$ be the connection on $U_{j}$ defined by (1) respectively .
and let $\{f_{j}\}$ be the partitions of unity on $M$ that are subordinate to $\{U_{j}\}$. Show that: $\sum_{j=1}^{\infty}f_{j}D^{j}$ is a connection on $M$. Another question: suppose  $X,V$ are two vcetor fields on manifold $M$, with the connection $\sum_{j=1}^{\infty}$ $f_{j}D^{j}$ defined above, how do we know that the new vector field $(\sum_{j=1}^{\infty}f_{j}D^{j})_{V}X$ is well defined on some intersections of the coordinate neighborhood, say $U_{j_{1}}$ and $U_{j_{2}}$ .","['differential-topology', 'differential-geometry']"
326527,Proof of Covariance,"I am dealing extremely often with the covariance during my statistics classes. However, the only proof I have found so far is  that. My question is, how to deal with the double integral of the covariance or is there another proof for the covariance? \begin{align}\text{Cov}(X,Y)& = \mathbb{E}(X- \mathbb{E}(X))(Y- \mathbb{E}(Y))\\ &= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\;(x- \mathbb{E}(X))(y- \mathbb{E}(Y))f(x,y)dx\;dy\\&= \mathbb{E}(XY)- \mathbb{E}(X)\mathbb{E}(Y)\; .\end{align} UPDATE Could that also be true? \begin{align}\text{Cov}(X,Y)&=\mathbb{E}(XY -X\mathbb{E}Y -Y\mathbb{E}X + \mathbb{E}X\mathbb{E}Y)\\&=\mathbb{E}(XY)- \mathbb{E}X\mathbb{E}Y -\mathbb{E}Y\mathbb{E}X + \mathbb{E}X \mathbb{E}Y\\&= \mathbb{E}(XY)- \mathbb{E}X \mathbb{E}Y \; . \end{align}","['statistics', 'integration']"
326540,Method of expressing the product of first n integers,"I am trying to show a pattern whereby the first term is 140 the next term is $140\times139$ and the next $140\times139\times138\dots$
I can do this as follows: $\frac{140!}{(140-n)!}$ but that doesnt hold for negative numbers i.e. $140\times139\dots\times-1\times\dots$ How can I do this?","['algebra-precalculus', 'recreational-mathematics']"
326542,Join and Zariski closed sets,"A set in $\mathbb{C}^n$ is called Zariski-closed if it can be written as the set of zeroes of some set of polynomial equations $$ V(f_1,...,f_m) = \left\{ z \in \mathbb{C}^n \mid f_1(z)=...=f_m(z)=0 \right\}  $$ and in general as $V(I)$ where $I \subset \mathbb{C}[x_1,...,x_n]$ is an ideal. The Zariski-closed sets form a topology called ""Zariski topology"". A Zariski-closed set embedded in the affine space $\mathbb{C}^n$ is called affine variety . An open set of an affine variety is called a quasi-affine variety . It is easy to see that in the case of 1-dimensional affine space $\mathbb{C}$ the Zariski-closed sets are $\emptyset, \mathbb{C}$ and all the finite sets $\{ z_1,...,z_k \}$ (since a polynomial has only a finite number of roots). Then $$ [0,1] = \{ z \in \mathbb{R} \subset \mathbb{C} \mid 0 \le z \le 1 \}$$ is clearly not Zariski-closed, but it isn't evident it is Zariski open. So I ask: is it Zariski open? I think it is niether, since its complement is also infinite and hence not Zariski-closed. Second question, suppose $W$ is an affine variety (and hence Zariski closed), is $W \times [0,1]$ (embedded in higher dimensional affine space) is Zariski closed or Zariski open? Or quasi-affine variety? A typical example is a band or a strip, let $\mathbb{C}^2$ and $W = \{ (x,y) \mid x = 0 \} \in \mathbb{C}^2$ and then $$ W \times [0,1] \cong \{ (x,y,z) \mid x = 0 \mbox{ and } 0 \le z \le 1 \}$$ but there are more complicated examples. The next generalization is as follows.
Suppose we have two affine varieties in $\mathbb{C}^n$ , call them $X$ and $Y$ . The join $J(X,Y)$ of $X$ and $Y$ is defined as follows: $$J(X,Y) = \bigcup_{p \in X, q \in Y} \overline{pq} $$ where $p \in X$ and $q \in Y$ are points in $\mathbb{C}^n$ and $\overline{pq}$ is the line segment joining them, $$ \overline{pq} = \left\{ \lambda p + (1-\lambda)q \mid \lambda \in [0,1] \right\} \ . $$ I want to determine if the join is Zariski closed, Zariski open, a quasi-affine variety or niether of these? Again, a (relatively) simple example is the join of $y=0$ and $y=1$ in $\mathbb{C}^2$ . Remark: it is hard to visualize the varieties involved since we work over the algebraically closed field $\mathbb{C}$ and not over $\mathbb{R}$ so the Euclidean geometry may give wrong intuition. References for definitions from Wikipedia: https://en.wikipedia.org/wiki/Zariski_topology and https://en.wikipedia.org/wiki/Join_(topology)","['general-topology', 'algebraic-geometry']"
326545,Limit of definite sum equals $\ln(2)$ [duplicate],"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 11 years ago . I have to show the following equality: $$\lim_{n\to\infty}\sum_{i=\frac{n}{2}}^{n}\frac{1}{i}=\log(2)$$ I've been playing with it for almost an hour, mainly with the taylor expansion of $\ln(2)$. It looks very similar to what I need, but it has an alternating sign which sits in my way. Can anyone point me in the right direction?","['sequences-and-series', 'calculus', 'limits']"
326605,Dissecting an equilateral triangle into equilateral triangles of pairwise different sizes,"It is know that a square can be dissected into other square such that no two of the squares have the same size.
This is the simplest dissection of that kind: Is it also possible to dissect an equilateral triangle into equilateral triangles such that no two of them have the same size?","['discrete-geometry', 'recreational-mathematics', 'tessellations', 'combinatorics']"
326617,How to calculate the asymptotic expansion of $\sum \sqrt{k}$?,"Denote $u_n:=\sum_{k=1}^n \sqrt{k}$. We can easily see that
$$ k^{1/2} = \frac{2}{3} (k^{3/2} - (k-1)^{3/2}) + O(k^{-1/2}),$$
hence $\sum_1^n \sqrt{k} = \frac{2}{3}n^{3/2} + O(n^{1/2})$, because $\sum_1^n O(k^{-1/2}) =O(n^{1/2})$. With some more calculations, we get
$$ k^{1/2} = \frac{2}{3} (k^{3/2} - (k-1)^{3/2}) + \frac{1}{2} (k^{1/2}-(k-1)^{-3/2}) +  O(k^{-1/2}),$$
hence $\sum_1^n \sqrt{k} = \frac{2}{3}n^{3/2} + \frac{1}{2} n^{1/2} + C + O(n^{1/2})$ for some constant $C$, because $\sum_n^\infty O(k^{-3/2}) = O(n^{-1/2})$. Now let's go further. I have made the following calculation
$$k^{1/2} = \frac{3}{2} \Delta_{3/2}(k) + \frac{1}{2} \Delta_{1/2}(k) + \frac{1}{24} \Delta_{-1/2}(k) + O(k^{-5/2}),$$
where $\Delta_\alpha(k) = k^\alpha-(k-1)^{\alpha}$. Hence :
$$\sum_{k=1}^n \sqrt{k} = \frac{2}{3} n^{3/2} + \frac{1}{2} n^{1/2} + C + \frac{1}{24} n^{-1/2} + O(n^{-3/2}).$$
And one can continue ad vitam aeternam, but the only term I don't know how to compute is the constant term. How do we find $C$ ?","['radicals', 'sequences-and-series', 'summation', 'calculus']"
326628,The classification all finite groups which possess a single proper non-trivial normal subgroup,"We know that For $n≥5$, $A_n$ is the only proper nontrivial normal subgroup of $S_n$. I am kindly asking to know the possible presented references including the following point, if anybody is aware of them.: The classification all finite groups G whose possess a single proper non-trivial normal subgroup. Thanks for your time.","['reference-request', 'finite-groups', 'group-theory']"
326639,"If $\{f_n\}$ is a measurable sequence of functions, then $\{x : \lim f_n(x) $ exists $\}$ is measurable","Was hoping someone could help me out on this problem (self-study not hw). If $\{f_n\}$ is a sequence of measurable functions on $X$, then $\{x : \lim f_n(x) $ exists $\}$ is a measurable function. Thank you","['measure-theory', 'real-analysis']"
326641,Methods to solve this type of equations,"Is there any method to solve (find the number of solutions or in some problems find the solutions) problems of following type: 1.${}\quad x=\log_e x^2-1$ 2.${}\quad \tan x+2x^2-3=0$ other than by separating polynomial function and other types of functions (like exponential, logarithmic) writing them on two sides of equality and drawing their graphs and noting where the two curves intersect? Any sort of approach or method is welcome as long as it leads to an elegant solution and as is elementary.","['algebra-precalculus', 'functions']"
326652,Is there a combinatorial interpretation for this sum?,"Is there a combinatorial interpretation for: $$\sum_{i=0}^{n}\binom{3i}{i}\binom{3(n-i)}{n-i}?$$ I do not think there is a simple closed form for it, like: $$\sum_{i=0}^{n}\binom{2i}{i}\binom{2(n-i)}{n-i} = 4^{n}.$$ Several types of combinatorial proofs are given for this identity.","['summation', 'combinatorics']"
326655,Which angle to pick for trigonometric substitution?,"first timer on this stack exchange so I apologize if this is the wrong place to ask this question I was wondering how one is supposed to properly pick an angle when using trig substitution to solve an integral. Say I have 
$$
\int \frac{1}{\sqrt{a^2 - x^2}} \,\mathbb{d}x
$$
First I see that the triangle that goes along with this is |
                                / |
                              /   |
                            /  phi|
                          /       |
                        /         |
                      /           |
              a     /             |
                  /               |
                /                 |
              /                   |
            /                     |
          /                       |
        /                         |
      /                           | sqrt(a^2-x^2)
    /                             |
  /                               |
/    theta                        |
----------------------------------
               x So my question is why do we pick phi in this picture rather than theta to base all of the formulas around. In other words why don't we use $\cos\theta = \frac{x}{a}$ but use $\sin\phi = \frac{x}{a}$ for our substitutions? If we use theta to base all of our formulas around then
$$
x = a\cos\theta \\
dx = -a \sin\theta\, \mathbb{d}\theta
$$
so the integral becomes
$$
\int \frac{1}{a\sqrt{1-\cos^2 \theta}} (-a \sin\theta) \; \mathbb{d}\theta \\
= -1 \int \frac{\sin \theta}{\sqrt{1-\cos^2 \theta}}\,\mathrm{d}\theta
$$
And since $\sin^2 \theta + \cos^2 \theta = 1 \implies \sin \theta = \sqrt{1-\cos^2 \theta}$ the integral becomes
$$
-1 \int \frac{\sin \theta}{\sin \theta} \,\mathbb{d} \theta \\
= -1 \int 1 \,\mathbb{d}\theta \\
= -\theta + C
= - \arccos \left(\frac{x}{a} \right) + C
$$
But this is wrong as according to everything I have looked at... so why do we choose the phi in that diagram and not the theta ?? I apologize if this is a silly question Thanks in advanced!! EDIT: I just wanted to add an example with limits and a real value for a, so let's do
$$
\int_0^{\pi} \frac{1}{\sqrt{1-x^2}} \, \mathbb{d}x
$$
By the work above we know that this becomes
$$
- \arccos{x} |_0^{\pi} \\
= - \arccos{\pi} - (- \arccos{0}) \\
= \arccos{0} - \arccos{\pi}
$$
Now if we use the sin this becomes
$$
\arcsin{x} |_0^{\pi} \\
= \arcsin{\pi} - \arcsin{0}
$$
So I am still a bit confused unless those turn out to be the same value
EDIT * 2:
Just realized that they are in fact the same :P thanks Andre for helping me out!","['trigonometry', 'calculus']"
326658,"Conclusion about Zeros of a polynomial ,when sum of it's coefficients is zero","I have a polynomial of the form: $$\sum_{m=0}^k\frac{(-1)^{m+1}(4k-2m)!x^{2k-2m}}{m!(2k-m)!(2k-2m+1)!}$$
or identically: $$\sum_{m=0}^k\frac{(-1)^{m+1}(4k-2m)!(x^{2})^{k-m}}{m!(2k-m)!(2k-2m+1)!}$$ where we can see that the sum of the coefficients is always zero. Now , my question is that : what can be concluded from this (i.e sum of the coefficients being zero)  about zeros (roots) of the polynomial? edit: except the fact that 1 is a root.","['elementary-number-theory', 'algebra-precalculus', 'polynomials']"
326668,Families of vectors in finite dimensional Hilbert space,"This is an exercise left for the reader in proof of Proposition 1.12 in Pisier's book ""Introduction to Operator Space Theory"". Assume that we have $n$ vectors $x_1, \dots, x_n$ in $\ell_2^N$ (where $n>N$) which satisfy inequality $\sum_{k=1}^{n} \|x_k\|^2 \leq 1$. Now, we would like to find $n \times N$ matrix $(b_{jk})$ of norm (considered as an operator from $\ell_2^N$ to $\ell_2^n$) not greater than $1$ and $N$ vectors $y_1, \dots, y_N$ in $\ell_2^N$ which, again, satisfy $\sum_{k=1}^{N} \|y_k\|^2 \leq 1$ and
$$x_j = \sum_{k=1}^{N} b_{jk}y_{k}.$$ I have an idea that maybe one should try to attack this problem in a somewhat abstract fashion, probably using separation theorem or something similar; most certainly I am missing something obvious. Anyway, any help will be appreciated.","['linear-algebra', 'functional-analysis']"
326675,Factorize the differential operator $[D^2-(x^2+1)]$ into two first order linear operators,I am Trying to factorize the differential operator $[D^2-(x^2+1)]$ into two first order linear operators. But I have not been able to. I am trying to split it into $[D+A][D-B]f=[D^2-(x^2+1)]f$. But at the end I get a really ugly differential equation that I cannot solve (It should be an easy one). Is there any hint? Thanks,['ordinary-differential-equations']
326679,Double Jumps of a Poisson Process,"If $N_t$ be a Poisson Process with rate $\lambda>0$, surely for any prescribed $t>0$, the probability that $N_t$ ""jumps (at least) twice"" at $t$ is zero, i.e. $\lim_{\epsilon\rightarrow0}P\{N_t-N_{t-\epsilon}\geq 2\}=0$ (is this even a proper way to state what I want to say?) Now my intuition tells me that the probability that $N_t$ ""jumps twice"" at any point in time should still be zero, but clearly you can't claim this by ""integrating"" zero over $t\in\mathbb{R}$ - that would be just like saying a uniform variable $X$ over $[0,1]$ has zero probability of being any point $t\in[0,1]$, and so $X$ has a zero probability of being in $[0,1]$. You would have to say, the probability of $X$ being in a small interval of length $dx$ is $1\cdot dx$, and the integral of that over $[0,1]$ is $1$. Also I notice that the probability that $N_t$ ""jumps at least once"" at some point in time should be one, since that equivalent to the probability $\lim_{t\rightarrow\infty}1-P\{N_t=0\} =1- e^{-\lambda t} = 1$. But again the probability of $N_t$ jumping at any $t>0$ is $0$. The issue, I think, is me trying to claim you can sum probabilities over an uncountable set, when you actually have to do something like put a measure on the $t$'s. Can someone explain what's going on with a little more rigour than I in my best efforts have been able to muster here (shouldn't be hard)?","['measure-theory', 'probability']"
326688,Why does the $n$-th power of a Jordan matrix involve the binomial coefficient?,"I've searched a lot for a simple explanation of this. Given a Jordan block $J_k(\lambda)$, its $n$-th power is: $$
J_k(\lambda)^n = \begin{bmatrix}
\lambda^n & \binom{n}{1}\lambda^{n-1} & \binom{n}{2}\lambda^{n-2} & \cdots & \cdots & \binom{n}{k-1}\lambda^{n-k+1} \\
 & \lambda^n & \binom{n}{1}\lambda^{n-1} & \cdots & \cdots & \binom{n}{k-2}\lambda^{n-k+2} \\
 &  & \ddots & \ddots & \vdots & \vdots\\
 &  & & \ddots & \ddots & \vdots\\
 &  & &  & \lambda^n & \binom{n}{1}\lambda^{n-1}\\
 &  &  &  &  & \lambda^n
\end{bmatrix}$$ Why does the $n$th power involve the binomial coefficient?","['matrices', 'linear-algebra', 'jordan-normal-form', 'exponentiation', 'binomial-coefficients']"
326695,Nonlinear differential equation,"Question:
Solve the following first-order equation. $(1+e^x)y'+e^y=0$",['ordinary-differential-equations']
326702,"A group such that $a^m b^m = b^m a^m$ and $a^n b^n = b^n a^n$ ($m$, $n$ coprime) is abelian?","Let $(G,.)$ be a group and $m,n \in\mathbb Z$ such that $\gcd(m,n)=1$. Assume that
$$ \forall a,b \in G, \,a^mb^m=b^ma^m,$$
$$\forall a,b \in G, \, a^nb^n=b^na^n.$$ Then how prove $G$ is an abelian group? Some context : Some of these commutation relations often imply that $G$ is abelian, for example if $(ab)^i = a^i b^i$ for three consecutive integers $i$ then $G$ is abelian , or if $g^2 = e$ for all $g$ then $G$ is abelian . This looks like another example of this phenomenon, but the same techniques do not apply.","['group-theory', 'abstract-algebra', 'abelian-groups']"
326713,help in a continuity problem of piecewise function,"If $f(x)=x^2-2|x|$ , then we have to test the differentiability of $g(x)$ in the interval $[-2,3] $ ,where $$g(x) =
       \begin{cases}
       \min\{f(t); -2≤t≤x\}&: x \in [-2,0)\\
       \max\{f(t);0≤t≤x\},&: x \in [0,3]
       \end{cases}
        $$ My solution We can write $f(x) $ as $x^2+2x$ when $-2≤x≤0$ and $f(x)=x^2-2x$ for $ 0<x≤3$ . Now by drawing graph of $f(x)$ we see that it is decreasing in $[-2,-1]$ and $[0,1]$ and is increasing in $[-1,0]$ and $[1,3]$ , so $$g(x) = 
\begin{cases}
   x^2+2x,&:x \in [-2,-1]\\      
 -1,&:x \in (-1,0]\\
0,&:x \in (0,1]\\
x^2-2x,&:x \in (1,3]
\end{cases}
$$ We now draw the graph of obtained $g(x)$ and find the points off discontinuity and indifferentiability as $0,1$ and $0,1$ , respectively. But the answer on back of book says the $g(x)$ is discontinuous at $x=0$ only and is indifferentiable at $x=0,2$ . I explained my approach to the problem and its solution as best I could. Can anyone tell where I'm wrong? I know the mistake is somewhere in deciding the function $g(x)$ in the interval $(0,1]$ , but I'm not able to figure that out . Please help.","['calculus', 'piecewise-continuity', 'derivatives', 'solution-verification']"
326714,Need help proving this integration,"If $a>b>0$, prove that : $$\int_0^{2\pi} \frac{\sin^2\theta}{a+b\cos\theta}\ d\theta = \frac{2\pi}{b^2} \left(a-\sqrt{a^2-b^2} \right) $$","['integration', 'complex-analysis']"
326725,Showing that the group of Unitary matrices $(U_n)$ is non-abelian for $n \geq 2$,"I know I could show this by counter-example, finding two unitary square matrices of size $2 \times 2$ at least, and conclude $U_n$ is non-abelian. The problem with this, is I think it's somewhat time consuming trying to work out two unitary matrices and showing they don't commute, so I'm hoping there's a more concise, and clever, way of doing it. I've tried looking at contradiction, assuming for two unitary matrices $A$ and $B$ we have $AB = BA$ $A^{-1}ABB^{-1} = A^{-1}BAB^{-1}$ $I_n = \bar{A}^T BA \bar{B}^T$ Then maybe trying to show $(I_n)_{11} = 1 = \left(\bar{A}^T BA \bar{B}^T \right)_{11}$ Doesn't hold for all unitary matrices $A$ and $B$, but short of actually finding $A$ and $B$ to disprove this I'm unsure what could be done. Any ideas greatly appreciated.","['matrices', 'abstract-algebra']"
326728,Linear least squares: overdetermined system necessary? and finding solutions?,"The wikipedia article on linear least squares only considers overdetermined systems (rows $\geq$ columns). I'm confused if this assumption is really necessary or not. Given any matrix $A, \|Ax - b\|^2$ is convex and differentiable so the minimum is given by solving the normal equations $A^T Ax = A^T b$. If $A$ has full rank then $A^TA$ is invertible and a unique $x$ exists. If $A$ does not have full rank, then I still know that there is a unique $z \in \operatorname{range}(A)$ that minimizes the least squares problem by the projection theorem. So I have some $x_0$ such that $z = Ax_0$. Question 1: In the case that $A$ does not have full rank, the projection theorem gives the existence of a minimizer $x_0$. How can I prove the existence of $x_0$ directly from the normal equations $A^TAx = A^Tb$? aPriori, it doesn't appear that this system needs to be consistent. Now that I have $x_0$ as a solution, I want to find all other solutions. From my differential equations class, I would guess that all other minimizers are given by $x_0+\ker(A)$. To prove this (I think) I suppose that $y$ is any other minimizer. Then by the uniqueness of $z$, I have $Ay = z$. And so $Ay - Ax_0 = 0$ and $y-x_0 \in \ker(A)$, which says $y\in x_0 + \ker(A)$. However, these two observations look contradictory: Suppose A has full rank and a non trivial kernel (overdetermined and full rank). The second observation says that $y\in x_0 + \ker(A)$ is a minimizer, indeed, $\|Ay - b\| = \|A(x_0+x) -b\| = \|Ax_0 -b\| =$ minimum. However, $A^TA$ is invertible, so the normal equations say that $x_0$ is unique and given by $x_0 = (A^TA)^{-1}A^Tb.$ Question 2: When $A$ has full rank and a nontrivial kernel, the normal equations says the minimizer $x_0 := (A^TA)^{-1}A^Tb$ is unique. Direct verification shows this is not the case, as any $x\in x_0 + \ker(A)$ is a minimizer. Where is the error in my reasoning that led me to this paradox?",['linear-algebra']
326734,How to integrate $\int\frac{1}{1+\cos{x}}\ dx$?,"I've looked at wolfram alpha for a possible solution, but it does something that makes no sense to me... It says to let $u=\tan(\frac{x}{2})$ with no clear reason as to why... So what would be a first step to approaching this? I've thought of converting it to $\frac{\sec{x}}{\sec{x}+1}$, but that seems to be fruitless...","['calculus', 'integration']"
326743,Obscure Probability Question,"Suppose that blood chloride concentration (mmol/L) has a normal distribution with mean 104 and standard deviation 5 (information in the article “Mathematical Model of
  Chloride Concentration in Human Blood,” J. of Med. Engr. and Tech., 2006: 25–30, including a normal probability plot as described in Section 4.6, supports this assumption). a.What is the probability that chloride concentration
  equals 105? Is less than 105? Is at most 105? b.What is the probability that chloride concentration
  differs from the mean by more than 1 standard deviation? Does this probability depend on the values of $\sigma$ and $\mu$ c. How would you characterize the most extreme .1% of chloride concentration values? I am having trouble with part c). I'm just not quite sure what it is asking.","['statistics', 'probability']"
326749,Making a standard theoretical physics argument rigorous,"In theoretical physics one often encounters the following rationale:
if $f$ and $g$ are functions on $\mathbf{R}^n$ , satisfying some technical conditions, and $\displaystyle\int_\Omega f=\int_\Omega g$ for all open sets $\Omega$ , then $f=g$ . (For instance, one obtains from Gauss law in ""integral form"" $\displaystyle\int_\Omega\mathrm{div} \ E = \int_\Omega \rho$ and its ""differential form"" $\mathrm{div} \ E=\rho$ .) Now my problem is: I want to know these technical conditions. Of course, it is a seemingly obvious statement, but it disturbs me not to know under what conditions this reasoning is legit. Is there some theorem which answers this question? Of course, I am also happy with a good reference.","['physics', 'reference-request', 'real-analysis']"
326758,Intuition for the Frobenius method,"I'm teaching a differential equations class now and I am hoping to give a reason for the Frobenius series method beyond simply ""we guess these solutions"".  Now, for the Euler equation
$$t^n x^{(n)}(t) + a_{n - 1} t^{n - 1} x^{(n - 1)}(t) + \dots + a_0 x(t) = 0$$
there is a good, easy explanation for why the fundamental solutions are of the form $x(t) = t^r$, where $r$ solves the indicial equation and repeated roots are handled by multiplying by powers of $\ln t$: just make the change of variables $s = \ln t$ and verify that this makes $t^n x^{(n)}(t)$ a constant-coefficient linear combination of the $x^{(k)}(s)$'s, and copy down the solutions to a constant-coefficient linear equation: $s^k e^{rs}$, with $k$ less than the multiplicity of $r$ as a root of the characteristic polynomial, which turns out here to be exactly the indicial polynomial. But there isn't an apparent generalization of this analogy to arbitrary differential equations with regular singular points,
$$t^n x^{(n)}(t) + a_{n - 1}(t) t^{n - 1} x^{(n - 1)}(t) + \dots + a_0(t) x(t) = 0,$$
with the $a_i(t)$ analytic around $t = 0$.  You can make the same change of variables and render the equation non-singular, but it will: still have variable coefficients; even if you got the solutions as power series, the substitution $s = \ln t$ would make them into series in $\ln t$, which is not desirable; when two roots differ by an integer then one of the solutions won't even be of the desired form; when there's a repeated root, the second solution looks like
$$x_2(t) = x_1(t) \ln t + x^r v(t),$$
where $v(t)$ is some other power series, anyway, which is not what you'd get from the change of variables in any obvious way.  Now, it is true that there is the following relationship between $x_1(t)$ and $v(t)$:
$$x_1(t) = \sum_{i = 0}^\infty b_i(r) t^{n + r} \qquad
    v(t) = \sum_{i = 0}^\infty b_i'(r) t^{n + r}$$
where we differentiate the coefficients with respect to $r$, considered somehow as a continuous variable. So, my question: Is there some connection, via a transform, change of variables, or approximation, that produces the Frobenius method by analogy with non-singular equations?  Perhaps just when the roots of the indicial polynomial do not differ by integers?","['ordinary-differential-equations', 'sequences-and-series', 'intuition']"
326761,Intuition behind $\nabla \times \mathbf{F}$,"Is there a simple explanation why this form for the curl of a vector field $\mathbf{F}$,
$$\nabla \times \mathbf{F}=\begin{vmatrix}
\hat{x} & \hat{y}  &\hat{z}  \\ 
 \frac{\partial}{\partial x}& \frac{\partial}{\partial y} &\frac{\partial}{\partial z} \\ 
 F_x& F_y &F_z 
\end{vmatrix}$$
Corresponds to the amount of 'twiting' of $\mathbf{F}$ (and any other qulities of $\nabla \times \mathbf{F}$)? When I first saw the equation, it seemed, very roughly, to be a measure of how much a component of $\mathbf{F}$ is affected by the other two components. However, this only really differentiates between $0$ and ' not $0$' curl, and anyway  there are thousands of possible equations that would give the same first impression. What's so unique about this one?","['multivariable-calculus', 'intuition']"
326763,Is it possible for a Jordan curve in the plane to enclose a set with area zero?,"I read about the Isoperimetric Inequality the other day. It says that for any Jordan curve,
$$
\frac{4 \pi A}{L^{2}} \leq 1,
$$
where $ L $ is the length of the curve and $ A $ is the area of the region that it encloses. Is it possible for this quotient to be zero (i.e., $ A = 0 $)?","['general-topology', 'geometry', 'plane-curves', 'inequality']"
326764,Reproducing Kernel Hilbert Spaces for Dummies,"I am in the middle of some machine learning paper that states that for function $f$,  imposing the norm constraint, $\|f \|=1$,  corresponds to an orthogonal projection onto the direction selected in reproducing kernel Hilbert space. I do not get this. I am lacking solid background in RKHS, so can anyone shortly tell me what it tries to say? How is an equality bounded norm  related to orthogonality? Do I need to study functional analysis?","['linear-algebra', 'hilbert-spaces', 'functional-analysis', 'machine-learning']"
326770,Probability of finding specific set of coloured balls within larger set of random-drawn balls,"In this question I was helped with calculating the probability of drawing specific set of M coloured balls from a set of N coloured balls. Now I am looking for a solution for an extended problem: what is the probability of finding my specific set of M balls among Q balls (where Q > M), drawn from the same pool of N balls. For example: there are 100 balls in the box: 50 red, 30 blue and 20 white. I randomly draw (without replacement) 15 balls from the box. What is the probability of finding among them a set of 6 balls, where 2 of them are red, 2 blue and 2 white? Using the variables:
N = 100: n1 = 50, n2 = 30, n3 = 20
M = 6: m1 = 2, m2 = 2, m3 = 2
Q = 15 While there are methods how to calculate the result for any specific input values, I am looking for a universal algorithm that would give result for any input values. Right now, I find it hard how to make a jump from the simpler problem of drawing exactly M balls: while it feels there should be some kind of multiplier that corrects for the extra freedom of drawing additional Q-M balls, this surely is not simple one, because these extra balls can themselves contain the set M, or there is partial overlapping, so there should be some smart way how to deduct all those duplicate combinations. Edit: complemented with empirical data from virtual experiment. I went forward to build a program to perform virtual experiments. Of course, computer random generators are not true random, but that's the best I have and for the sake of this experiment, I think, they are random enough. So, I created the pool: a set of 2 red, 3 blue and 4 white balls. My sample size is 6 balls, and I consider the sampling a success, if it contains (at least) 1 red, 1 blue and 1 white ball. Running the simulation one million times I get probability of 90.4858%. That does not necessarily exactly matches the calculated probability (whatever it is), but should be pretty close. So, I'd expect that the formula gives such result, given the input parameters.",['combinatorics']
326778,Laplace transform of the Bessel function of the first kind,"I want to show that $$ \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx = \frac{(\sqrt{a^{2}+b^{2}}-a)^{n}}{b^{n}\sqrt{a^{2}+b^{2}}}\ , \quad \ (n \in \mathbb{Z}_{\ge 0} \, , \text{Re}(a) >0 , \,  b >0 ),$$ where $J_{n}(x)$ is the Bessel function of the first kind of order $n$. But the result I get using an integral representation of $J_{n}(bx)$ is off by a factor of $ \displaystyle \frac{1}{b}$, and I don't understand why. $$ \begin{align} \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx &=  \frac{1}{2 \pi} \int_{0}^{\infty} \int_{-\pi}^{\pi}  e^{i(n \theta -bx \sin \theta)} e^{-ax} \, d \theta \, dx \\ &=  \frac{1}{2 \pi} \int_{-\pi}^{\pi} \int_{0}^{\infty} e^{i n \theta} e^{-(a+ib \sin \theta)x} \, dx \, d \theta \\ &=  \frac{1}{2 \pi} \int_{-\pi}^{\pi} \frac{e^{i n \theta}}{a + ib \sin \theta} \, d \theta  \\  &= \frac{1}{2 \pi} \int_{|z|=1} \frac{z^{n}}{a+\frac{b}{2} \left(z-\frac{1}{z} \right)} \frac{dz} {iz} \\ &= \frac{1}{i\pi} \int_{|z|=1} \frac{z^{n}}{bz^{2}+2az-b} \, dz  \end{align}$$ The integrand has simple poles at $\displaystyle z= -\frac{a}{b} \pm \frac{\sqrt{a^{2}+b^{2}}}{b}$. But only the pole at $\displaystyle z= -\frac{a}{b} + \frac{\sqrt{a^{2}+b^{2}}}{b}$ is inside the unit circle. Therefore, $$ \begin{align} \int_{0}^{\infty} J_{n}(bx) e^{-ax} \, dx &= \frac{1}{i \pi} \, 2 \pi i \ \text{Res} \left[ \frac{z^{n}}{bz^{2}+2az-b}, -\frac{a}{b} + \frac{\sqrt{a^{2}+b^{2}}}{b} \right] \\ &= {\color{red}{b}} \  \frac{(\sqrt{a^{2}+b^{2}}-a)^{n}}{b^{n}\sqrt{a^{2}+b^{2}}} . \end{align}$$","['improper-integrals', 'laplace-transform', 'complex-analysis', 'contour-integration']"
326784,Prove that the rank of a block diagonal matrix equals the sum of the ranks of the matrices that are the main diagonal blocks.,"If $A$ and $B$ are matrices, $0$ is a zero matrix, and \begin{equation*}
X=
\begin{pmatrix}
A& 0
\newline
0& B
\end{pmatrix},
\end{equation*} prove that $\mathrm{rank}(X)=\mathrm{rank}(A)+\mathrm{rank}B)$ . Also, if the upper right zero matrix would be replaced with matrix $C$ , that is, \begin{equation*}
X=
\begin{pmatrix}
A& C
\newline
0& B
\end{pmatrix}
\end{equation*} would it still be true that $\mathrm{rank}(X)=\mathrm{rank}(A)+\mathrm{rank}B)$ ?","['matrices', 'matrix-rank', 'block-matrices']"
326795,Question from Folland on modes of convergence,"I have been reading through Folland, and I am having a hard time answering the following question.  Any help will be much appreciated. Suppose $\lvert f_n \rvert \leq g \in L^1$ and $f_n \rightarrow f$ in measure. Prove the following: (a) $\int f = \lim\int f_n.$ (b) $f_n \rightarrow f$ in $L^1.$","['lebesgue-integral', 'measure-theory', 'convergence-divergence', 'real-analysis']"
326798,Showing that $\max\{f+g\} \leq \max f + \max g$,"Given real-valued continuous functions $f, g$, is the following (and why?) inequality true? $$\max \{f + g \} \leq \max f + \max g$$ Can someone give me a proof? I suspect the min is the reverse inequality","['inequality', 'algebra-precalculus']"
326819,Points on a plane,I have been assigned this problem and am not sure how to approach it! Please help me figure out what I should do! Let $S$ be a finite set of points in a plane chosen to have the property that for each $P\in S$ there is exactly one point $Q_P \in S \setminus \{P\}$ nearest to $P$. Join each point $P$ of $S$ to the point $Q_P$. Prove the following: The diagram obtained contains no closed polygon. No two of the lines cross each other. No one point is joined to more than 5 other points.,"['geometry', 'graph-theory']"
326820,Analytic function f constant if $f(z) = 0$ or $f'(z) = 0$ for all $z$.,"Let $f: \mathbb{C} \rightarrow \mathbb{C}$ be analytic and suppose that for all $z \in \mathbb{C}$, at least one of $f(z)$ and $f'(z)$ is equal to 0. Proof that $f$ is constant. Any ideas? Thanks.",['complex-analysis']
326826,On the Definition of Posets...,"In my book, the author defines posets formally in the following way: Let $P$ be a set, and let $\le$ be a relationship on $P$ so that, $a$. $\le$ is reflective. $b$. $\le$ is transitive. $c$. $\le$ is antisymmetric. Say for $a$, does this merely mean that if some element $x\in P$, $x$ should always have the same relation to itself? and for $b$ if $x$ has the relation to $y$ and $y$ has the relation to $z$, this implies that $x$ has the relation to $z$? Moreover, when trying to determine if a something is a poset,do I just have to determine if such a relationship exists? And that relationship is not necessarily the usual meaning of ""$\le$""","['relations', 'discrete-mathematics', 'elementary-set-theory']"
326829,Equivalence of definitions of $S^\infty$,"Consider the following two definitions of the infinity-sphere $S^\infty$. Why do they define homeomorphic spaces? $1)$ The set of points in $\mathbb R^\infty$ with distance $1$ from the origin. $2)$ The CW complex with $2$ $0$-cells, $2$ $1$-cells, $2$ $2$-cells, and so on, with $2$ $n$-cells for each $n$ in general, such that the $n$-skeleton is $S^n$. I can show (thanks to a helpful answer on a prior question I asked) that the CW-complex for $S^n$ is the same as the Euclidean space definition of $S^n$ for finite $n$, but I do not see how to show these limit spaces are homeomorphic. I have a vague idea that the proof might involve the idea of a colimit, but I know nothing about category theory. Any more elementary suggestions are also welcome.","['general-topology', 'geometric-topology']"
326831,"In polar/cylindrical coordinates, does $r dr d\theta=r d\theta dr$?","In polar/cylindrical coordinates, does $r dr d\theta=r d\theta dr$? For example, I believe the integral for the area of a half-circle is given by
$$\int_0^1\int_0^{\pi}{rd\theta dr}.$$ What would this integral be if the order were reversed? I find it hard to visualize taking $dr$ first.","['multivariable-calculus', 'calculus']"
326832,Determine complex polynomial,"Problem Let $P(z) = z^n + a_{n−1}z^{n−1} + \cdots + a_1z + a_0$ be a polynomial of degree $n > 0$. Show
that if $\lvert P(z) \lvert \le 1$ whenever $\lvert z \rvert = 1$ then $P(z) = z^n$. I have tried to see $\dfrac{P(z)}{z^n}$, but nothing happens. I wonder which theorems should I use to solve this. I think hints are enough. Thanks.","['maximum-principle', 'complex-analysis', 'polynomials']"
326841,Probability of selecting jellybeans,8 red and 9 blue jellybeans are distributed randomly to 4 students. What is the probability that each student got at least one jellybean of each color? I am getting $\binom{7}{3} \binom{8}{3} / \binom{23}{3}$ Is this correct or is my calculation off,"['discrete-mathematics', 'probability']"
326848,Selecting books from a shelf,"A shelf contains 24 books. How many ways can 6 books be selected from these 24 with
the restriction that no two selected books can be adjacent? So first we want to divide by 2 to fulfill the adjacent requirement this give us 12 then we use the bars and star method to get (17 choose 6), is this correct?","['discrete-mathematics', 'probability', 'combinatorics']"
326849,Definition of conditional expectation/independence,"Conditional probability and conditional independence are unique almost surely, but relative to what: the conditioning field or the underlying field? More precisely, consider the case of conditional independence. Let $\left(\Omega, \mathcal{A}, P\right)$ be a probability space, let $\mathcal{B}$ be a sub-$\sigma$-algebra of $\mathcal{A}$ and let $D,E\in\mathcal{A}$. Then by definition (see, e.g. Kallenberg (1995) p. 86) $D,E$ are conditionally independent given $\mathcal{B}$ iff
$$P\left(\left.D\cap E\right|\mathcal{B}\right)=P\left(\left.D\right|\mathcal{B}\right)P\left(\left.E\right|\mathcal{B}\right)\space\space\mathrm{a.s}$$
But does ""a.s."" mean ""up to a null set $F\in\mathcal{A}$"" or ""up to a null set $F\in\mathcal{B}$""?","['probability-theory', 'conditional-probability']"
326859,How do I solve $\int\frac{\cos^2(x)}{\sin(x)}\ dx$ without using Weierstass Substitution?,"Every problem that I've put into wolfram alpha lately gives me instructions to substitute $\tan(\frac{x}{2})$, but I haven't been taught how to do that, nor can I understand how it works anyhow...","['trigonometry', 'calculus', 'integration']"
326876,Translation of : The disjunction of two contingencies can be a tautology.,"The statement is: ""The disjunction of two contingencies can be a tautology.""
The predicates are: 
$C(x)$: ""$x$ is a contradiction.""
$T(x)$: ""$x$ is a tautology."" The book says the answer is 
$$\exists{x}\exists{y}(\lnot T(x) \wedge \lnot C(x) \wedge \lnot T(y) \wedge \lnot C(y) \wedge T(x\lor y)) $$
However, I was thinking something more along the lines of
$$\exists{x}\exists{y}(\lnot T(x) \wedge \lnot C(x) \wedge \lnot T(y) \wedge \lnot C(y) \rightarrow T(x\lor y)) $$ What's wrong with my line of thinking?","['predicate-logic', 'quantifiers', 'discrete-mathematics']"
326881,Frequency response,"We consider the response $x(t)$ when the frequency of the input y(t) varies. $$x''+bx'+kx=ky(t), y(t)=\cos \omega t$$ 1) If $k=3.24$, what is the natural ($b=0$) frequency $\omega_n$? I think we have $\omega_n=\frac{\sqrt{3.24}}{2\pi}$ 2) If $k=3.24$ and $b=0.8$, what is the amplitude gain from the input $y(t)=\cos \omega_n t$?
I need to report the ratio of the amplitude of x to amplitude y. Thank you",['ordinary-differential-equations']
326886,"Entire, $|f(z)|\le1+\sqrt{|z|}$ implies $f$ is constant","I am stuck on the following question. Given that $f$ is an entire function with $|f(z)|\le1+\sqrt{|z|}$ for all $z\in \mathbb{C}$, show that $f$ is constant. Can anyone give me a hint to get me started? OK, based on one of the hints below, I define:
$$g(z)=\frac{f(z)-f(0)}{z}$$
Now, let me assume that this is entire by defining $g(0)=f'(0)$. Is that fair, and if so, why? Continuing,
$$\begin{align*}
\left|g(z)\right|
&=\left|\frac{f(z)-f(0)}{z}\right|\\
&\le \left|\frac{f(z)}{z}\right|+\left|\frac{f(0)}{z}\right|\\
&=\frac{|f(z)|}{|z|}+\frac{|f(0)|}{|z|}\\
&\le\frac{1+\sqrt{|z|}}{|z|}+\frac{|f(0)|}{|z|}\\
&=\frac{1}{|z|}+\frac{\sqrt{|z|}}{|z|}+\frac{|f(0)|}{|z|}\\
&=\frac{1}{|z|}+\frac{1}{\sqrt{|z|}}+\frac{|f(0)|}{|z|}\\
&\le 1+1+|f(0)|\\
&=2+|f(0)|,
\end{align*}
$$
provided $|z|\ge 1$. Next, $g$ is entire on the disk $D=\{z:\,|z|\le 1\}$, which is compact, so it must assume a maximum value on this disk, say $|g(z)|\le M$ on $D$. Taking $M_s$ as the smaller of $2+|f(0)|$ and $M$, we have $|g(z)\le M_s$ for all $z\in C$. Now, by Liouville's Theorem, $g$ is constant. However, going back to the beginning of the argument, my only worry is whether $g$ is made entire by defining $g(0)=f'(0)$. I am not sure that is valid. Can someone comment on this and also comment on the above if there are errors? Thanks.",['complex-analysis']
