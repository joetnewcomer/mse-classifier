question_id,title,body,tags
2196346,Compute $\int\frac{x+2}{\sqrt{x^2+5x}+6}~dx$,"Question: Compute this integral $$\int\frac{x+2}{\sqrt{x^2+5x}+6}~dx$$ My Approach: $$\int\frac{x+2}{\sqrt{x^2+5x}+6}~dx$$ $$=\int\frac{x+2}{\sqrt{x^2+5x}+6}\times \frac{{\sqrt{x^2+5x}-6}}{{\sqrt{x^2+5x}-6}}~dx$$ $$\int\frac{(x+2)(\sqrt{x^2+5x})}{x^2+5x-36}~dx~~- \underbrace {~\int\frac{(6x+12)}{x^2+5x-36}~dx~}_{\text{This one I know how to deal with} }$$ $$\text{Now:} ~\int\frac{(x+2)(\sqrt{x^2+5x})}{x^2+5x-36}~dx$$ $$=\frac{1}{2}\int\frac{(2x+5-1)(\sqrt{x^2+5x})}{x^2+5x-36}~dx$$ $$=\frac{1}{2}\int\frac{(2x+5)(\sqrt{x^2+5x})}{x^2+5x-36}~dx~~- \frac{1}{2}\int\frac{(\sqrt{x^2+5x})}{x^2+5x-36}~dx$$ $$\Big( \text{Let} ~ x^2+5x=t \implies (2x+5)~dx = dt \Big)$$ $$ \underbrace{\frac{1}{2}\int \frac{\sqrt{t}}{t-36}~dt}_{\text{I can deal with this}} ~~- \frac{1}{2}\int \frac{\sqrt{x^2+5x}}{x^2+5x-36}~dx$$ Now I'm stuck. I am unable to calculate: $$ \int \frac{\sqrt{x^2+5x}}{x^2+5x-36}~dx$$ P.S.: I am high school student so please try to use elementary integrals only; i.e. integration by parts and substitution. I don't know how to use complex numbers in integration, multiple integrals, error function, etc. (I don't know if it can be used here or not, just clarifying.) As answered by @Kanwaljit Singh: Finally I have to compute: $$\int \frac{1}{\sqrt{x^2+5x}-6}$$ But if I was able to compute it, I would have done it in the very first step, id est ; $$\int \frac{x+2}{\sqrt{x^2+5x}+6}~dx = 
\frac{1}{2}\int \frac{2x+5-1}{\sqrt{x^2+5x}+6}~dx
\\ \frac{1}{2}\int \frac{2x+5}{\sqrt{x^2+5x}+6}~dx ~- \frac{1}{2}\int \frac{1}{\sqrt{x^2+5x}+6}~dx
\\ \Big( \text{Let} ~ x^2+5x=t \implies (2x+5)~dx = dt \Big)
\\ \underbrace{\frac{1}{2}\int \frac{1}{t+6}~dt}_{\text{Doable}} ~-~\frac{1}{2}\int \frac{1}{\sqrt{x^2+5x}+6}~dx
\\ \int \frac{1}{\sqrt{x^2+5x}+6}~dx $$ Reached to a similar step by a short path. But how do I compute this one?","['indefinite-integrals', 'integration']"
2196371,How to approximate $\sin(x)$ using Padé approximation?,"I need to write a function for $\sin(x)$ using Padé approximation. I found here a formula, but I don't know how to achive this. Thanks in advance.","['pade-approximation', 'calculus', 'functions', 'matlab', 'numerical-methods']"
2196413,A commutative ring with group of invertible elements isomorphic to $\mathbb{Z}$ has characteristic 2,"Let $R$ be a commutative ring. Denote by $R^*$ the group of invertible elements (this is a group w.r.t multiplication.) Suppose $R^*\cong  \mathbb{Z}$. I need to show that $1+1=0$ in $R$. I have no clue about why such statement should be true. I don't even have an example for a ring that satisfies these assumptions, so I'd be glad to see one. Hints (or partial solutions) will be welcomed.
Thank you!","['abstract-algebra', 'ring-theory']"
2196420,Volumn definition in high dimensional Euclidean space?,"This may be a simple question to some folks, but I've searched for quite a while without finding a definitive answer, so I figure I'd ask/confirm it here.  My apology if it was answered before.  In that case, I'd greatly appreciate a link/reference. (1) Does the following constitute the formal definition of the volumn of some arbitrary shape (subset) $\Omega$ in $\mathbb R^k$ Euclidean space? $\mathrm{vol}(\Omega) \triangleq \int_{\Omega} 1 \:dx_1dx_2...dx_k$ Or are there other definitions for other applications/purposes? (2) What's the motivation behind this definition?  Is it just to be consistent with our usual notion of volumn of square, circle, ball, ... etc in $\mathbb R^2$ and $\mathbb R^3$?  Does it also has to do with the definition of multi-variate probability density function (pdf) in probability theory?  It appears to me that this definition also works nicely/naturally with the pdf, since we require $$\int f(x_1, x_2, ..., x_k) dx_1 dx_2...dx_k = 1.$$ So, for example, if $(X_1, ..., X_k)$ are random variables uniformly distributed in $\Omega \subset \mathbb R^k$, i.e. $f(x_1, x_2, ..., x_k)=c$ for $(x_1, x_2, ..., x_k)\in \Omega$ (and zero elsewhere), then $$1=\int_{\Omega} f(x_1, x_2, ..., x_k) dx_1 dx_2...dx_k=c\:\mathrm{vol}(\Omega).$$ Therefore, the probability density is $c=\frac{1}{\mathrm{vol}(\Omega)}$ over $\Omega$, which is consistent with our usual notion of density. Are there other important motivations/considerations that I missed?  Thanks a lot!","['probability', 'measure-theory', 'geometry']"
2196446,How do I determine all $z\in \mathbb{C}$ which satisfy the equation $\left | z^2-1 \right |< r$?,"Let $r>0$. How do I determine all $z\in \mathbb{C}$ which satisfy the equation $\left | z^2-1 \right |< r$? How do I sketch and determine the values of r for which the set M ${z\in \mathbb{C}:  \left | z^2-1 \right |< r}$ is related? It’s clear that $z$ satisfies the equation
$z^2-1=de^{i\theta}$ for some $d <r$.
Solving, we get
$z=\pm\sqrt {1+de^{i\theta}}$
We want to write this in the form
$z=\pm ae^{it}$
Thus
$a^2e^{i2t}=1+d\cos (\theta)+id\sin (\theta)=\sqrt {(1+d\cos\theta)^2+d^2\sin^2\theta}\exp [i\tan^{-1}(\frac {d\sin\theta}{1+d\cos\theta})]$.
Therefore $z$ is
$z=\pm (1+d^2+2d\cos\theta)^{1/4}\exp [\frac {i}{2}\tan^{-1}(\frac {d\sin\theta}{1+d\cos\theta})]$
With $d <r$ and $0\leq\theta\leq2\pi$. I have tried this but it's not correct. Can someone help me?","['complex-analysis', 'complex-numbers']"
2196468,Infinite sum of recursive integrals,"Given, $$I_n = \int_0^1 e^{x}x^{n}dx\ $$ Find:  $$\left\lceil \lim_{n\to \infty}\sum_{k=1}^n\frac{I_{k+1}}{I_k} \right\rceil$$ I tried to define $I_n$ using a recursive pattern in the following way: \begin{align}
I_n &= \int_0^1e^{x}x^{n}\text{d}x\\
&=  e - \int_0^1 e^{x}\cdot n\cdot x^{n-1}\text{d}x\  \text{(using integration by parts)}\\
&= e - n\cdot  I_{n-1}
\end{align}
Equivalently, $ \frac{I_{n+1}}{I_n} = \frac{e}{I_n} - (n+1) $ So, the sum becomes: 
\begin{align}
&\ e(\frac{1}{I_{n}} + \frac{1}{I_{n-1}} + \frac{1}{I_{n-2}} +\cdots + \frac{1}{I_{1}}) - ((n+1) + n + (n-1) + \cdots+2)\\
&=\ e(\frac{1}{I_{n}} + \frac{1}{I_{n-1}} + \frac{1}{I_{n-2}} +\cdots + \frac{1}{I_{1}}) +1 - (\frac{(n+2)(n+1)}{2})
\end{align} But now I am stuck and don't know how to proceed, I also found out that $ I_0 = e-1 $ and $ I_1 = 1 $ and few more $I_n$ but that did not lead me anywhere, or at least, I could not get anything from there. Thank you in advance!","['summation', 'integration', 'calculus', 'limits']"
2196489,What would be good example of antisymmetry for this relation?,"We have set $X=\{a,b,c,d\}$ and relation $R=\{(a,a),(a,b),(a,c),(a,d),(b,b),(c,c),(d,b),(d,c),(d,d)\}$. It is obvious that it is not symmetric and I suppose that it is antisymmetric but I can't come up with some good example to show it. I know the rule of antisymmetry $xRy \wedge yRx \rightarrow x = y$, but I am not sure how to apply it on this relation.","['equivalence-relations', 'relations', 'discrete-mathematics']"
2196498,Nonlinear Grönwall inequality,"Let $T>0$, $\alpha,\beta>0$ and consider a non-negative continuous function $x$ on $[0,T]$ such that for all $t \in [0,T]$ one has
$$x(t) \leq \alpha+\beta\left(\int_0^t x(s)\,\mathrm ds \right)^{1/2}.$$
Does anyone knows what kind of Grönwall inequality I can get from this ? It would be fantastic if I can get something like $x(t) \leq Ct$.","['real-analysis', 'integral-inequality', 'functional-inequalities']"
2196522,Inscribed Square in Inscribed Circle in Square,"A square has an inscribed circle which has an inscribed square in, as shown. Show that the area of the  white bit is approximately 28.5% of the whole shape. I started by calling the circle's radius r, so the length and width of the blue square is r and the area is $r^2$. The area of the circle would be $r^2* π$. I then searched my formula book about areas of inscribed shapes but I didn't find any. Can anyone help me? P.S. I 'm just a Year 7 and this is Year 9 work so please explain clearly how you found the solution",['geometry']
2196534,Why is the de Rham complex elliptic?,"I need to show that the exterior derivative $$ \mathrm{d} : \Omega^r(M) \to \Omega^{r+1}(M) $$ is an elliptic differential operator. As far as I understand it, an elliptic operator is one such that the symbol $\sigma(\mathrm{d},\xi)$ is an invertible linear map for all non-zero $\xi$. In this case, we have $$ \sigma(\mathrm{d},\xi) = \xi  \,\wedge  $$ (up to a factor of $i$ perhaps), which is clearly not invertible. Indeed, the dimensions of the fibres it maps between are different! I'm sure I'm missing something blindingly obvious here, but I've searched all over the web and haven't found anything that clears this up. Thanks.","['de-rham-cohomology', 'elliptic-equations', 'differential-geometry', 'partial-differential-equations']"
2196546,Special reptiles - repeating shapes and fractals,"Let me first explain what a reptile is. A reptile is a two-dimensional object, a shape, that can be dissected into smaller, equally sized copies of the same shape. To illustrate this, see here a couple of reptiles: A shape is called an $n$-reptile, or $n$-rep for short, if the shape can be dissected into $n$ smaller, equally sized copies. So above you see a $2$-rep (recognize the shape? Yup, it's A4 paper! Could be any of the A-series in fact) a $3$-rep (a Sierpinski triangle ) and a random $4$-rep. Now obviously, if a shape is an $n$-rep, it's also a $n^2$-rep; simply dissect it once in $n$ pieces, and dissect every piece you made again in $n$ pieces. One can repeat this pattern to see that in fact, if a shape is an $n$-rep, then it must be an $n^k$-rep for integer $k\geq 1$. These dissections in $n^k$ pieces aren't very interesting though, since they're all based on the base case with $n$ pieces. This got me thinking, and so here's my question: Does there exist an $n$-reptile that is simultaneously an $m$-reptile with $n$ and $m$ coprime?","['fractals', 'geometry']"
2196556,derivative of $y = |x|$ and contradiction with the intermediate value property,"The Unit step function(derivative of $y = |x|$) does not take the values from $(0, 1)$. It is said that this function cannot be a derivative of any real valued function. But isn't $y = |x|$ a real valued function, whose domain and range are both real numbers? So, how is this unit step function not a derivative of any real valued function?","['derivatives', 'functions']"
2196583,Any II$_1$-factor contains the hyperfinite II$_1$-factor,"I want to show that any II$_1$-factor $N$ contains the hyperfinite II$_1$-factor $R$. The hyperfinite factor is constructed to be the weak closure of $A:= \bigotimes_{n = 1}^\infty \text{Mat}_{2 \times 2}(\mathbb{C})$ in the GNS-space $L^2(A)$. My idea was to construct a sequence $A_1 \subset A_2 \subset \cdots$ of subalgebras of $N$ such that $A_i \cong \bigotimes_{j = 1}^i \text{Mat}_{2 \times 2}(\mathbf{C})$ as algebras, and then use that the trace is unique on a factor. However, I don't really know how to construct this sequence of subalgebras... So my question is: Am I on the right track? And if yes, how can I construct those subalgebras? Thanks a lot!","['functional-analysis', 'operator-algebras', 'operator-theory', 'von-neumann-algebras']"
2196601,How to prove an ordinary differential equation is not separable?,"Some elementary exercises require one to determine whether or not an ordinary differential equation is separable. For example, it is understood that the equation $$y'=\frac{1-2xy}{x^2}$$ is not separable. An easier example is $y'=x+y$. Usually this is intuitive understandable; however, can one give a strict proof that the right hand of these equations cannot be written as a product of the form $p(y)q(x)$? I am aware of this question , but am not sure if the method mentioned in one of the answers is a good approach.","['ordinary-differential-equations', 'functions']"
2196622,Piecewise Composite Functions and Surjective/Injective,"I understand how to work out a composite function when it is just one function but have no clue when it comes to piecewise composite functions like follows: $$  f(x) =
\begin{cases}
x-1,  & \ x\ge0 \\
x^3, & \ x < 0
\end{cases}
$$ $$  g(x) =
\begin{cases}
x+1,  & \ x\ge0 \\
2x, & \ x < 0
\end{cases}
$$ How would I go about working out  $ f \circ g $ and $g \circ f$? Also, how can I tell if a piece wise function is surjective or injective? By graphing both of them I have worked out (if I am correct) that $f(x)$ is not injective as $f(0) = f(-1)$ and $g(x)$ is injective. Thanks in advance.","['piecewise-continuity', 'functions']"
2196650,Proof that $y^2=x^3+21$ has no integral solution with elementary methods?,"I tried to prove that $$y^2=x^3+21$$ has no integral solution in the way as shown here : http://www.math.uconn.edu/~kconrad/blurbs/gradnumthy/mordelleqn1.pdf My work so far : $x$ cannot be even because we would have $y^2\equiv 5\mod 8$ , which is a contradiction. Hence, $x$ is odd and $y$ is even. We have $$x\equiv x^3=y^2-21\mod 8$$ , which gives the possibilities $x=3\ ,\ y=0\ or \ 4$ and $x=7\ ,\ y=2\ or\ 6$ modulo $8$ . Now I tried various factorizations to get a contradiction with quadratic residues : $1)$ : $y^2+6=x^3+27=(x+3)(x^2-3x+9)$ $2)$ : $y^2-13=x^3+8=(x+2)(x^2-2x+4)$ $3)$ : $y^2-20=x^3+1=(x+1)(x^2-x+1)$ but in no case I found a contradiction with quadratic residues. Can this particular equation be shown to be non-solveable in integers in the described way ? How can I find systematically a suitable factorization in general leading to the desired contradiction, assuming the equation actually has no integral solution ?","['number-theory', 'mordell-curves', 'modular-arithmetic', 'quadratic-residues']"
2196654,Proof of Intermediate value theorem in non-standard analysis.,"A real function is continuous on $[a,b]$ such that either $f(a) > 0 >f(b)$ or $f(a) < 0 < f(b)$, then prove that $f(c) = 0$ for some $c \in (a,b)$. Proof :- We divide $[a,b]^*$ in $H$ equal parts, where $H$ is a positive infinite hyperinteger. We get, $$a, a +\delta, a+2\delta,\ ... \ , a+ H\delta = b$$ Let $a + K\delta$ be the last partition point at which $f(a+ K\delta) <0$, Thus $$f(a+K\delta) < 0 \le f(a+(K+1)\delta)$$ Since $f$ is continous $f(a+K\delta) \approx f(a+(K+1)\delta)$, thus $f(a+K\delta) \approx 0$, Let $c = st(a+ K\delta)$ Therefore $f(c)= st(f(a+ K\delta)) =0 $ I have two questions, Shouldn't it be $f^*(x)$ everywhere instead of $f(x)$ because a real function won't have a hyperreal number in its domain. Like it should be $f^*(a+K\delta) <0$ in the third line because $a+K\delta$ is not a real number it is a hyperreal number. Why does $f(a+K\delta) \approx f(a+(K+1)\delta)$ ? Can't it be $f(a+K\delta) = 1000$ and $f(a+(K+1)\delta) = 2000$ ? Then those two are not infinitely close, right?","['derivatives', 'real-analysis', 'continuity', 'nonstandard-analysis']"
2196662,Writing a probability in terms of the edges of a simplex,"I describe the problem dimension $2$, but it could be generalized to $n$ dimensions. So we have $X_{1}, X_{2}, X_{3}$ three $iid$ random variables of continuous law $F(x,y)$ on $\Bbb R^2$. Let's denote by $S[X_{1}, X_{2}, X_{3}]$ the simplex generated by those random variables. Given a point $(x,y)$, is it possible to write $P((x,y)\in S[X_{1}, X_{2}, X_{3}])$ as a function $g$ of $F(x,y)$ ? For example, in dimension $1$, $P(x\in [X_{1}, X_{2}]) = 2F(x)(1-F(x))$. Thank you","['probability-theory', 'probability', 'geometric-probability', 'geometry']"
2196676,Behavior of the spectral radius of $A_1^k\ldots A_j^k$ when $k\to \infty$,"First formulation of my problem : Let $A_1,\cdots,A_j$ be hermitian definite positive matrices of dimension $n$ with all their eigenvalues in $(0;1]$. We also add the condition that $\|A_1\cdots A_j\|_2^2<1$. I am wondering if the quantity $$\frac{-1}{k}\log\left(\rho\left(A_1^k\cdots A_j^k\right)\right)$$ has a (positive and finite) limit when $k$ goes to infinity. Here $\rho(M)$ denote the spectral radius of the matrix $M$. Second formulation : The same problem can be reformulated in terms of ordinary differential equation : let $a : [0;1]\to \mathscr H_n^{+}$ be a bounded, piecewise continuous function from $[0;1]$ to the space of hermitian semi definite positive matrices and define $G_a :[0;1]\to \mathscr{M}_n(\mathbf C)$ as the solution of the following differential equation $$
\left\{ 
\begin{array}{rcl}
G_a(0)&=&\mathrm{Id}\\
G_a'(t)&=&-a(t)G(t).
\end{array}
\right.
$$
We moreover assume that $\|G_a(1)\|_2^2<1$. I want to know if the quantity 
$$\frac{-1}{k}\log\big(\rho\left(G_{ka}(1)\right)\big)$$
has a finite positive limit when $k\to \infty$. This is indeed a reformulation of the first problem if we take $a$ to be piecewise constant on every interval $[\frac{i-1}{j};\frac{i}{j})$ and such that $\exp(-a(i-1)/j)=A_i$. By an argument of density the two problems are equivalent. What I already know : Note that in dimension $1$ ( ie the matrices are just real numbers) the answer to my question is trivially yes. The few numerical simulations i have done (and my intuition) seems to indicate that the answer to my question is yes : there is a positive finite limit. Finally, i was able to prove an upper and a lower bound for the first formulation of the problem, these bounds are not sharp and i will only sketch the proof of the bounds : first bound : All the $A_i^k$ are contractions of $\mathbf C^n$ so $\rho\left(A_1^k\cdots A_j^k\right)<1$ and thus $\det\left(A_1^k\cdots A_j^k\right)<1$ but $\det\left(A_1^k\cdots A_j^k\right)=\det\left(A_1\cdots A_j\right)^k$ and thus $\rho\left(A_1^k\cdots A_j^k\right)\geq \det\left(A_1\cdots A_j\right)^{k}$, giving us the first bound. second bound : One can show that all the coefficients of $A_1^k$ are of the form $C(\alpha+o(1))^k$ for some $C$ and $\alpha$. The product and the sum of two of this expressions can still be exprimed in that way. From that we deduce that the coefficients of the characteristic polynomial of $A_1^k\cdots A_j^k$ are also of the form $C(\alpha+o(1))^k$, so it's an exponentially small perturbation of the polynomial $X^n$. Since the roots of a polynomial (of degree $n$) are $1/n$-Hölder functions of the coefficients we get the other bound on $\rho\left(A_1\cdots A_j\right)^k$. This second bound suggest to concider the matrices $A_1^k\cdots A_j^k$ as small perturbations of the null matrix, maybe this approach is fruitfull but i don't know much about perturbation theory.","['limits', 'matrices', 'perturbation-theory', 'ordinary-differential-equations', 'linear-algebra']"
2196698,Strict minimizer versus strong minimizer,"Let $X$ be a Banach sapce and $f$ be a lower semicontinuous mapping from $X$ to $\mathbb{R}$. We consider the following definitions: $x_0\in X$ is called a strict minimizer of $f$ if $f(x)>f(x_0)$ for all $x\in X$ and $x\ne x_0$; $x_0\in X$ is called a strong minimizer of $f$ if $f(x_0)=\inf_Xf$ and every sequence $(x_n)$ along which $f(x_n)\rightarrow f(x_0)$ obeys $\|x_n-x_0\|\rightarrow 0$; $x_0\in X$ is called a strict local minimizer of $f$ if there exists $\varepsilon>0$ such that $f(x)>f(x_0)$ for all $x\in X$ such that $x\ne x_0$ and $\|x-x_0\|\leq\varepsilon$; $x_0\in X$ is called a strong local minimizer of $f$ if there exists $\varepsilon>0$ such that $f(x_0)=\inf_{\|x-x_0\|\leq\varepsilon}f(x)$ and every sequence $(x_n)$ along which $\|x_n-x_0\|\leq\varepsilon$ and  $f(x_n)\rightarrow f(x_0)$ obeys $\|x_n-x_0\|\rightarrow 0$; From definitions, it is easy to verify that: strong minimizer is strict minimizer strong local minimizer is strict local minimizer For the function $f(x)=x^2e^x$, $x_0=0$ is the strict minimizer of $f$ but $x_0$ is not the strong minimizer of $f$. Question. I would like to construct a lower semicontinuous function $f:X\rightarrow\mathbb{R}$ and a point $x_0$ such that $x_0$ is the strict local minimizer of $f$ but $x_0$ is not the strong local minimizer of $f$. My attempt. When $X=\mathbb{R}^n$ and $f$ is lower semicontinuous, we could prove that strong local minimizer is actually strict local minimizer. Therefore, we have to to construct counterexample in infinite dimensional setting. Thank you for all kind help and suggestion.","['banach-spaces', 'optimization', 'functions']"
2196707,The conditions $a^2b^2=b^2a^2$ and $a^3b^3=b^3a^3$ make the group $G$ abelian?,"Let $G$ be a group. Assume that $a^2b^2=b^2a^2$ and $a^3b^3=b^3a^3$ for all $a, b \in G$ . Prove that the group $G$ is abelian. Also please tell me whether there is any standard approach in proving commutativity of groups like this problem.","['abstract-algebra', 'group-theory']"
2196733,$Z(I)$ is homeomorphic to $\operatorname{Spec}(R/I)$,"Let $R$ be a commutative ring. How do you prove that $Z(I)$ is homeomorphic to $\operatorname{Spec}(R/I)$, where $Z(I)$ is equipped with the topology induced from the Zariski topology on $\operatorname{Spec}R$? It is clear that this is bijection. And the maps are defined in this question Correspondence theorem for rings. What is the easiest way to prove that they are continuous? I tried to show that both maps are closed but I didn't succeed.","['algebraic-geometry', 'commutative-algebra']"
2196743,Function notation with term before f(x),"I saw an exam question using this notation: $$x^2\,f(x) = x^2 + 7x + 3\,.$$ I didn't understand it, so I checked the answer and I saw that was equal to: $$f(x) = \frac{x^2 + 7x + 3}{x^2}\,.$$ Is the former a common function notation? Where or how can I find more information about it? Thanks in advance.","['notation', 'functions', 'rational-functions']"
2196765,Affine plane curves classification,"Define an affine plane conic as $\operatorname{Spec}A$ where $A=k[x,y]/(f)$ and $f$ a quadratic polynomial with no multiple factors. Define an equivalence relation on the set of alline plane conics by: two conics are equivalent if tere is a polynomial change of variables that maps one conic to the other one. How do I describe the set of equivalence classes under this relation? I have no idea how to approach this.","['polynomials', 'affine-geometry', 'geometry', 'algebraic-curves', 'ideals']"
2196789,Solve $\int \frac{1}{\sin ^{\frac{1}{2}}x \cos^{\frac{7}{2}}x}dx$,So it's given this indefinite integral $$\int \frac{1}{\sin ^{\frac{1}{2}}x \cos^{\frac{7}{2}}x}dx$$ Is there anyone could solve this integral? Thanks in advance.,"['indefinite-integrals', 'integration', 'calculus']"
2196815,If $f:\mathbb{R}\to\mathbb{R}$ then $|f(\mathbb{N})|\leq\aleph_0$ [duplicate],"This question already has an answer here : Image of the set of natural numbers under any function is denumerable. (1 answer) Closed 7 years ago . I am stuck at this problem for long time: Prove that if $f:\mathbb{R}\to\mathbb{R}$ is some real-valued function, Then $|f(\mathbb{N})|\leq\aleph_0$. In other words, prove that there exists a one-to-one function from $f(\mathbb{N})=\{f(n)|n\in\mathbb{N}\}$ to $\mathbb{N}$. If $f(\mathbb{N})$ is finite then it is clear that $|f(\mathbb{N})|\leq\aleph_0$,
But if $f(\mathbb{N})$ is infinite then I got stuck. Thanks for any hint/help.","['cardinals', 'elementary-set-theory']"
2196846,How do we prove this $\int_{0}^{\infty}e^{-x}\sin^n x\left({1\over x}+{1\over x^2}+{1\over x^3}+\cdots+{1\over x^n}\right) =\arctan(n)?$,"Given the integral $(1)$ $$\int_{0}^{\infty}e^{-x}\sin^n x\left({1\over x}+{1\over x^2}+{1\over x^3}+\cdots+{1\over x^n}\right)dx
=\arctan(n)\tag1$$ An attempt: Rewrite $(1)$ as $$\sum_{j=1}^{n}\int_{0}^{\infty}e^{-x}\sin^n x\cdot{\mathrm dx\over x^j}\tag2$$ Maybe if we know the closed form for $(3)$, it could be useful $$\sum_{j=1}^{n}{1\over x^j}?\tag3$$ Employing $e^{-x}$ series $(2)$ becomes $$\sum_{j=1}^{n}\int_{0}^{\infty}\sin^n x\left(x^{-j}-x^{1-j}+{x^{2-j}\over 2!}-{x^{3-j}\over 3!}+\cdots \right)\mathrm dx\tag4$$ I guess we may use integration by parts to integrate term by term, it may results in a lengthy process. How else may integral $(1)$ be prove?","['sequences-and-series', 'calculus', 'integration', 'definite-integrals', 'power-series']"
2196847,For which parameter p will the following series be convergent?,"$$ \sum_{n=1}^{\infty} \sin \frac{1}{n^p} $$ Well, as I know this is pretty similar to the Riemann zeta function, and as I checked this will be divergent if $p \leq 1$. And it will be convergent if $p>1$. How can I continue the problem solving?","['sequences-and-series', 'analysis']"
2196851,Boundary of boundary of a set in boundary,"I know that:
$x \in \partial E \Longleftrightarrow $ every neighborhood of x contains at least one point in the set and at least one point not in the set. And I also know that $$\partial (\partial E) \subseteq \partial E $$
assuming that $E \subset X$, and $(X, d)$ metric space. The question is : When is it that $$\partial (\partial E) \subset \partial E$$ ? It depends on the interior points of $\partial E$ , but how can I prove that? And, above all , how can I imagine a set with this kind of boundary? Hints are accepted, thanks in advance!",['general-topology']
2196858,What does a transitive set exactly imply?,"In set theory, what does it mean for a set to be transitive, and what does it have to do with transitivity of a relation?",['elementary-set-theory']
2196863,Bounding the minimum singular value of a block triangular matrix,"Question: What is the sharpest known lower bound for the minimum singular value of the block triangular matrix
$$M:=\begin{bmatrix}
A & B \\ 0 & D
\end{bmatrix}$$
in terms of the properties of its constituent matrices? Motivation: Block triangular matrices are ubiquitous in numerical linear algebra, and the minimum singular value is a basic property of any matrix. So, it would be useful to have a canonical answer to this question in an easily searchable place on the internet. A matrix of this form came up in my research on numerical methods, and I need to estimate its minimum singular value in order to understand the stability of a method I'm working on. My bound: I was able to come up with the bounds
$$\boxed{\frac{1}{\sigma_\text{min}(M)} \le \sqrt{\left\Vert A^{-1}\right\Vert^2\left(1 + \left\Vert BD^{-1} \right\Vert^2 \right) + \left\Vert D^{-1} \right\Vert^2}}$$
and
$$\boxed{\frac{1}{\sigma_\text{min}(M)} \le \sqrt{\left\Vert D^{-1}\right\Vert^2\left(1 + \left\Vert A^{-1}B \right\Vert^2 \right) + \left\Vert A^{-1} \right\Vert^2}.}$$
using the following argument (for the first bound, the second one is the same argument but on the transpose): The minimum singular value of a matrix is the inverse of the norm of the inverse matrix:
$$\frac{1}{\sigma_\text{min}(M)} = \left\Vert M^{-1} \right\Vert.$$
But inverse of a block triangular matrix has the following exact formula :
$$M^{-1} = \begin{bmatrix}
A^{-1} & -A^{-1}BD^{-1} \\
0 & D^{-1}
\end{bmatrix}.$$
Estimating the norm of the inverse directly from the definition and using the submultiplicative property of norms yields the boxed bound above:
\begin{align*}
\left\Vert M^{-1} \right\Vert^2 &= \sup_{||u||^2+||v||^2=1} \left\Vert \begin{bmatrix}
A^{-1} & -A^{-1}BD^{-1} \\
0 & D^{-1}
\end{bmatrix} \begin{bmatrix}u \\ v\end{bmatrix} \right\Vert^2 \\
&= \sup_{||u||^2+||v||^2=1} \left\Vert A^{-1} u - A^{-1}BD^{-1}v \right\Vert^2 + \left\Vert D^{-1} v\right\Vert^2 \\
&\le \left\Vert A^{-1}\right\Vert^2 \left\Vert\begin{bmatrix}I & -BD^{-1}\end{bmatrix}\right\Vert^2 + \left\Vert D^{-1} \right\Vert^2 \\
&= \left\Vert A^{-1}\right\Vert^2\left(1 + \left\Vert BD^{-1} \right\Vert^2 \right) + \left\Vert D^{-1} \right\Vert^2.
\end{align*} Conjectured bound: The obvious conjecture based on the two bounds above is the following symmetrized version:
$$\frac{1}{\sigma_\text{min}(M)} \overset{?}{\le} \sqrt{\left\Vert D^{-1} \right\Vert^2 + \left\Vert A^{-1}BD^{-1} \right\Vert ^2 + \left\Vert A^{-1} \right\Vert ^2},$$
which I have been unable to prove. If one applies the triangle inequality to the blocks of $M^{-1}$, one gets the similar looking bound:
$$\frac{1}{\sigma_\text{min}(M)} \le \left\Vert D^{-1} \right\Vert + \left\Vert A^{-1}BD^{-1} \right\Vert + \left\Vert A^{-1} \right\Vert,$$
but this is strictly worse than the conjectured bound since it is a sum rather than the square root of a sum of squares. Edit: After getting no answers here, I posted on mathoverflow , where it was answered. The conjectured bound is true.","['matrices', 'singular-values', 'block-matrices', 'linear-algebra']"
2196917,Diagonalized matrix - Is each column an eigenvector?,"Everything below is correct. But I got a question at the bottom (yellow). Given is matrix $A=\begin{pmatrix}
11 &  0 &  -6\\ 
 0 &  5 &  -6\\ 
-6 & -6 &  -2
\end{pmatrix}$ which is diagonalizable . The eigenvalues are $$\lambda_1= -7\text{ }\text{ }\text{ }\text{ }\text{ }\text{ } \lambda_2= 7\text{ }\text{ }\text{ }\text{ }\text{ }\text{ } \lambda_3=14$$ The eigenspaces are $E_{A}(\lambda_1) = \left\{ \begin{pmatrix}
\frac{z}{3}\\ 
\frac{z}{2}\\ 
z
\end{pmatrix} \mid z \in \mathbb{R}\right\}, E_{A}(\lambda_2) = \left\{ \begin{pmatrix}
\frac{3}{2}z\\ 
-3z\\ 
z
\end{pmatrix} \mid z \in \mathbb{R}\right\}$ $E_{A}(\lambda_3) = \left\{ \begin{pmatrix}
-2z\\ 
-\frac{2}{3}z\\ 
z
\end{pmatrix} \mid z \in \mathbb{R}\right\}$ Let's say I was supposed to to determine an orthonormal basis
  $(v_1,v_2,v_3) \in \mathbb{R}^{3}$ of the eigenvectors of $A$, can I
  just write the matrix in its diagonalized form and continue there
  determining an orthonormal basis? It should be possible iff each
  column is an eigenvector of the eigenspace, right? Is it? So matrix A diagonalized is $A_D= \begin{pmatrix}
-7 & 0 & 0\\   0 & 7 & 0\\   0 & 0 & 14 \end{pmatrix}$ Now can I say that $v_1= \begin{pmatrix}
-7\\  0\\  0 \end{pmatrix}, v_2= \begin{pmatrix} 0\\  7\\  0 \end{pmatrix}, v_3= \begin{pmatrix} 0\\  0\\  14 \end{pmatrix}$ and
  determine the orthonormal basis with these? Sorry for making this question so long, I didn't know how to keep it short. I hope you can help me anyway.","['eigenvalues-eigenvectors', 'matrices', 'abstract-algebra', 'linear-algebra', 'vector-spaces']"
2196938,"Finding explicit elements in $\text{SL}(3,\mathbb{R})/\text{SO}(3)$ whose simultaneous stabilizer in $\text{SL}(3,\mathbb{R})$ is the identity","Consider the action of $\text{SL}(3,\mathbb{R})$ on $M=\text{SL}(3,\mathbb{R})/\text{SO}(3)$ (via left multiplication). I want to find explicitly a minimal number of elements $s_1,\ldots,s_k \in M$ with the property that the simultaneous stabilizer of all the $s_i$ in $\text{SL}(3,\mathbb{R})$ is the identity matrix. Robert Bryant commented here that probably $k=3$ is the minimal number, but I am not sure of this. (I am interested in the representatives $A_i$ s.t $s_i=A_i\text{SO}(3)$. In fact, I am only interested in $A_iA_i^T$ since this is the information needed for constructing a left invariant metric on $\text{SL}(3,\mathbb{R})$- context is provided below if you are interested). Motivation: I am trying to realize concretely Robert's idea to construct a left invariant metric on $\text{SL}(n,\mathbb{R})$. The smallest non-trivial dimension  is $n=2$. However, as mentioned by Robert, we must embed $\text{SL}(2,\mathbb{R})$ in $\text{SL}(3,\mathbb{R})$ for his approach to work (since $-I$ acts trivially on $M$). The reason I am interested in left invariant metrics on $\text{SL}(n,\mathbb{R})$, is that such metrics can be used to construct left invariant metrics on $\text{GL}(n,\mathbb{R})$, as explained in this unanswered question .","['group-actions', 'homogeneous-spaces', 'group-theory', 'lie-groups']"
2196954,Prove continuity of a function.,"Let $$f(x) = \begin{cases}1 \ \ \ \ 1 \le |x| \\ 1/n \ \ \ \ 1/n \le |x| \lt 1/(n-1), \ \ n \in \mathbb{Z} \text{ and } n \ge 2 \\ 0  \ \ \ \ x = 0\end{cases}$$
  Prove that $f$ is continuous at $x= 0$ but discontinuous at $x = \pm 1/n$ Let $f^*$ be a hyperreal extension of $f$. $$\lim_{x \to 0} f^*(x) = st(f^*(|\varepsilon|))$$ Now for any infinitesimal $\varepsilon$ we can find a infinite hyperinteger $K$ such that $${1\over K} \le |\varepsilon| \lt {1\over K-1}$$ Therefore $$ f^*(|\varepsilon|) = {1\over K} = \delta$$
Since $ \lim_{x \to c} f(c) = st(f^*(c))$
$$\therefore \lim_{x \to 0} f(x) = st(f^*(\varepsilon)) = st(\delta) = 0  = f(0)$$ Hence $f$ continous at $0$. Similarly, $$\lim_{x \to 1/n} f^*(x) = st(f^*(1/n + \epsilon))$$ Let $n$ be a infinite hyperinterger $H$, $$f^*(1/H + \varepsilon) = f^*(\delta + \epsilon)$$ Like the proof above we can find a $J$ such that $\displaystyle {1\over J} \le |\delta + \epsilon| \le {1\over J- 1}$ $$\therefore st(f^*(\delta + \epsilon)) = st\left({1\over J}\right) \ne {1\over H} = f^*(1/ H)$$ Therefore $f^*$ is discontinuous at $\pm 1/n$ and therefore $f$ is also discontinuous. I getting a feeling like I have used too many symbols that mean nothing and my proof is wrong. I think the second part is probably is wrong. Please tell me if this proof is correct and if not then how to correct it ?","['derivatives', 'real-analysis', 'continuity', 'nonstandard-analysis']"
2196980,What statistical test to use to compare effectiveness of drugs used to fight a disease,So let's say that I want to collect some data on a sample of people who has the same type of disease. One group will take a drug A Another one will take drug B Third type will take both of them. I want to perform a statistical test to see whether taking both of the drugs simultaneously results in getting back to health quicker. Can anyone tell me what test would I use and what hypothesis would I state? Assumptions that I would make? I need to plan a research project (Without actually doing it) and I thought about doing something like this but I am not sure how to start.,"['statistics', 'mathematical-modeling']"
2197020,Prove $f(c) = c$ under a condition.,"Suppose $f(x)$ is continuous on $[0,1]$ and $f(0) = 1, f(1) = 0$. Prove that there is a point $c$ in $(0, 1)$ such that $f(c) = c$. let $l(x) = x$ and $d(x) = f(x) - l(x)$. We have $d(1) = f(1) - l(1) = -1$ and
$d(0) = 1$. We divide $[-1, 1]$ in $H$ equal parts , where $H$ is a infinite hyperinterger. $$-1, -1 + \delta, -1 + 2\delta, \ ... \  , -1 + H\delta = 1$$ Let $-1 + K\delta$ be the last partition point such that $d^*(-1 + K\delta) < 0$ $$\therefore d^*(-1 + K\delta) < 0 < d^*(-1 + (K+1)\delta)$$ $$\therefore f^*(-1 + K\delta) < -1 + K\delta  < f^*(-1 + (K+1)\delta) - \delta$$ Since $f^*(-1 + K\delta) \approx  f^*(-1 + (K+1)\delta) - \delta$, therefore $f^*(-1 + K\delta) \approx -1 + K\delta$ Let $c = st(-1 + K\delta)$ By taking standard part of the $f^*(-1 + K\delta) \approx -1 + K\delta$ , we get $f(c) = c$. I think this is probably correct but to be on the safe side please check my proof.","['derivatives', 'real-analysis', 'nonstandard-analysis', 'calculus', 'continuity']"
2197065,Is there a Baire Category Theorem for Complete Topological Vector Spaces?,Baire category theorem is usually proved in the setting of a complete metric space or a locally compact Hausdorff space. Is there a version of Baire category Theorem for complete topological vector spaces? What other hypotheses might be required?,"['functional-analysis', 'reference-request', 'general-topology', 'baire-category']"
2197068,Can Fourier techniques still be useful in situations where we don't have perfect periodicity (such as a missing point in a lattice)?,"If we are dealing with a problem with a periodic component, for example a infinite lattice of particles in one or more dimensions and we want to calculate a solution numerically we can use Fourier techniques such as the Poisson summation formula to accelerate the convergence of of slowly convergent series and make them exponentially convergent. But what if we have an 'almost periodic' problem in that we still have the infinite lattice but we take away or two points on it. So its perfectly periodic except for this defect. Can the Fourier type techniques still be made to work in such a situation or are they all or nothing, that is, if we don't have perfect periodicity are Fourier techniques completely unusable?","['fourier-series', 'fourier-analysis', 'convergence-acceleration', 'convergence-divergence', 'sequences-and-series']"
2197151,Distributing n different items to r different people with everyone getting at least one item,"sorry cannot comment _ answer already here Distributing $n$ different things among $r$ persons Sum of digits of permutations and combinations of a given set of digits I was trying to come up with solution for this. First I tried to find number of ways in which $n$ distinct things can be distributed to $r$ different persons. This should be $r^n$. This can be explained as follows: First item can be assigned to any of the $r$ persons, Second item can be assigned to any of the $r$ persons and so on. Thus we get, $\underbrace{r\times r \times ... \times r}_{\text{n times}}=r^n$ Then I thought of ways in which n distinct things can be distributed to r different persons so that every person gets at least one should be $r^n-({}^rP_1+{}^rP_2+...+{}^rP_{r-1})$, where ${}^rP_x$ is the number of ways $x$ persons does not get any item. However, later I felt that I am not correct with ""${}^rP_x$ is the number of ways $x$ persons does not get any item"". It should be ${}^rP_x\times (r-x)^n$ as there are ${}^rP_x$ ways to choose persons who don't get any item and we can distribute the $n$ items to the remaining persons in $(r-x)^n$ ways. So the final solution can be: $r^n-({}^nP_1 \times (r-1)^n +{}^nP_2 \times (r-2)^n+...+{}^nP_{n-1}\times (r-(r-1))^1)$ This looks very bad to me. Am I correct with this? Is there any better solution?","['permutations', 'combinatorics', 'combinations']"
2197183,Separable Hilbert space has a countable orthonormal basis,"I 'm studying about Hilbert Spaces this semester, and the following is a Proposition from yesterday's class which I can't completely understand. ""Obviously,the closed linear span of $V\;$ coincides with $H$."" It doesn't seem so obvious to me. It might be really silly, but how do I know that the closed linear span of a dense subset of $H$ is also dense in $H$? I have the feeling that it's quite elementary but I'm new to Functional Analysis. I would appreciate any help. Thanks in advnace!!","['functional-analysis', 'hilbert-spaces', 'proof-explanation']"
2197234,Pushforward of module sheaf along morphism of affine schemes,"Let $f\colon\operatorname{Spec}A\to\operatorname{Spec}B$ be a morphism of affine schemes, corresponding to the ring homomorphism $\varphi\colon B\to A$ and let $M$ be an $A$-module. I'm trying to understand why $$f_*\widetilde{M}\cong\widetilde{M_{/B}},$$ where the index $_{/B}$ denotes restriction of coefficients. Let $g$ be an element of $B$. Then $\widetilde{M_{/B}}(D(g))=(M_{/B})_g$ by definition. On the other hand, $f_*\widetilde{M}(D(g))=\widetilde{M}(D(\varphi(g))=M_{\varphi(g)}$. So what I need to show is that $M_{\varphi(g)}\cong(M_{/B})_g$ as $B_g$-modules.","['sheaf-theory', 'algebraic-geometry', 'commutative-algebra']"
2197309,Convexity of matrix trace functions $A\mapsto \operatorname{Tr} (Bf(A))$,"Any function $f:\mathbb{R}\rightarrow\mathbb{R}$ is can be extended to a function on self-adjoint $n\times n$ matrices by
$$
f(A) = \sum_{i=1}^n f(a_i)v_iv_i^*
$$
where $A = \sum_{i=1}^n a_iv_iv_i^*$ is the spectral decomposition of $A$. If $f:\mathbb{R}\rightarrow\mathbb{R}$ is convex, then the function $A\mapsto  \operatorname{Tr}(f(A))$ is also convex as a function of matrices. (See e.g. Theorem 3.27 in Introduction to Matrix Analysis and Applications, or see proof below). My question : If $f:\mathbb{R}\rightarrow\mathbb{R}$ is convex, is the function 
$$\tag{1}
A\mapsto \operatorname{Tr}(Bf(A))
$$
convex for any self-adjoint positive matrix $B\geq 0$? I'm wondering if the following proofs might be adapted to show convexity of (1). Here I show that $A\mapsto\operatorname{Tr}f(A)$ is a convex function as long as $f$ is convex. I can't get a similar proof to work to show convexity of $A\mapsto\operatorname{Tr}(Bf(A))$, nor can I find a counterexample. Lemma. Suppose $f:\mathbb{R}\rightarrow\mathbb{R}$ is convex and let $A$ be a self-adjoint $n\times n$ matrix. For any orthonormal basis $\{u_1,\dots,u_n\}$ of $\mathbb{C}^n$, it holds that
$$
\operatorname{Tr}f(A)\geq \sum_{j=1}^n f(u_j^*Au_j).
$$ Proof. Let $A = \sum_{i=1}^n a_iv_iv_i^*$ be the spectral decomposition of $A$. Then $\sum_{j=1}^{n}|u_j^*v_i|^2=1$ for each $j$ and \begin{align*}
\operatorname{Tr}f(A) 
&= \sum_{j=1}^n\sum_{i=1}^n f(a_i) |u_j^*v_i|^2\\
& \geq \sum_{j=1} f \left(\sum_{i=1}^na_i |u_j^*v_i|^2\right)= \sum_{j=1}f (u_j^*Au_j)
\end{align*}
where the inequality is due to the convexity of $f$. $\Box$ Theorem. Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be convex. Then $A\mapsto \operatorname{Tr}f(A)$ is convex as a function of matrices. Proof. Let $A$ and $B$ be self-adjoint $n\times n$ matrices and let $t\in(0,1)$. We will show that $$t\operatorname{Tr}f(A)+(1-t)\operatorname{Tr}f(B)\geq \operatorname{Tr}(f(tA+(1-t)B)).$$ Let $\{u_1,\dots,u_n\}$ be the eigenbasis of $tA+(1-t)B$. By the Lemma,
\begin{align*}
t\operatorname{Tr}f(A)+(1-t)\operatorname{Tr}f(B)
& \geq t\sum_{j=1}^n f(u_j^*Au_j) + (1-t)\sum_{j=1}^nf(u_j^*Bu_j)\\
& = \sum_{j=1}^n\bigl(tf(u_j^*Au_j) + (1-t)f(u_j^*Bu_j)\bigr)\\
& \geq \sum_{j=1}^nf\bigl(tu_j^*Au_j+ (1-t)u_j^*Bu_j)\\
& = \sum_{j=1}^nf\bigl(u_j^*(tA+(1-t))Bu_j)\\
& = \operatorname{Tr}(f(tA+(1-t)B)),
\end{align*}
as desired, where the second inequality is due to convexity of $f$. $\Box$","['matrices', 'trace', 'matrix-equations', 'convex-analysis']"
2197318,On convex hulls of polyhedra and transitivity,"It's easy to prove that the convex hull of any vertex-transitive polyhedron is vertex-transitive. Specifically, any symmetry of the original polyhedron that moves any vertex to another will also move the same vertices on the convex hull, but since it will preserve the general shape of the original polyhedron (and therefore the set of vertices) it must preserve the convex hull. However, my question is the following: Are the convex hulls of edge-transitive polyhedra edge-transitive, and are the convex hulls of face-transitive polyhedra face-transitive? I have gathered evidence backing up this, mostly from uniform polyhedra, but I can't use the same technique as before to support my claim. Does anyone know why is it true or does anyone have a counterexample?","['polyhedra', 'convex-hulls', 'symmetry', '3d', 'group-theory']"
2197325,Geometric proof for trigonometric angle sum formulas.,"For some reason I'm starting to get nit picky about everything I have learned. In Geometry/ Algebra I learned how to prove the angle sum formulas, which follow from this picture (and a slightly different picture with $a$ and $b$ instead of $\beta$ and $\alpha-\beta$ : But now that I realize it this argument only works if the angle sum $x$ follows the inequality $0<x<\frac{\pi}{2}$. And every angle is larger than $0$, in radians. How can we geometrically prove (to a high school student taking algebra/geometry)  the trigonometric sum formulas but for all angles? Definition Here is what I'll take to be the definition of sine and cosine (if you know of another definition I'd appreciate it if you share): Let $(x,y)$ be a point in the Cartesian plane, let $\theta$ be the counterclockwise angle in radians from the positive $x$ axis to the segment connecting $(x,y)$ to the origin. Let a clockwise angle of $\theta$ be equivalent to  a counterclockwise  angle of $-\theta$, and vice versa. Take ""sin"" and ""cos"" to be $2\pi$ periodic functions. Let $r$ be the distance from $(x,y)$ to the origin. In other words $r=\sqrt{x^2+y^2}$. Then define: $$\sin (\theta)=\frac{y}{r}$$ $$\cos (\theta)=\frac{x}{r}$$",['trigonometry']
2197328,Stationary point of a smooth function $f:\Bbb R^2\to \Bbb R$,"Let $f \in C^{\infty}(\mathbb{R^{2}})$ be a function such that: $$\lim_{y \to \pm \infty} f(x,y)=+\infty, \ \forall x \in \mathbb{R},$$ and that $$\lim_{x \to \pm \infty} f(x,y)=-\infty, \ \forall y \in \mathbb{R}.$$
With this hypothesis, does a stationary point necessarily exist? I'm looking for either a proof of the existence or a counterexample.  It sounds false to me, but I didn't find a counterexample.","['multivariable-calculus', 'real-analysis', 'calculus']"
2197334,Conditional expectation of independent identically distributed random variables,"Let $X, Y, Z$ -- independent identically distributed random variables. I need to calculate the conditional expectation $\mathbb{E}(3X - 3Y + Z | X + Y + Z)$. I use linearity property: $3\mathbb{E}(X| X + Y + Z) - 3\mathbb{E}(Y | X + Y + Z) + \mathbb{E}( Z | X + Y + Z)$. But what about the right side conditional expectation?","['statistics', 'conditional-expectation', 'probability']"
2197345,Find conditional expectation $E(\xi|\xi^2)$,"The problem is to find the conditional expectation $E(\xi | \xi^2)$, where $\xi$ is a uniform random value on $[-1, 1]$. The approach I tried to implement is to prove somehow that $E(\xi|\xi^2)=E(-\xi|\xi^2)$, since $\xi$ is from $[-1,1]$, that is, symmetrical, but I don't know how to continue the solution.","['uniform-distribution', 'statistics', 'conditional-expectation', 'probability']"
2197387,Characterization of the sinus,"I am looking for a simple proof of this result: If  $f\in C^{\infty}(\mathbb{R})$ fulfills $f'(0)=1$ and $|f^{(n)}(x)|\leq 1$  for any $x\in\mathbb{R}$ and any $n\in\{0,1,2,\ldots\}$, then $f(x)=\sin(x)$. A proof (through the Paley-Wiener theorem and complex analysis) can be found here: http://www.math.sciences.univ-nantes.fr/~nicoleau/sinus.pdf","['complex-analysis', 'real-analysis']"
2197404,Is A a proper set of its power set?,"I originally believed that the answer is yes, as all elements of A are subsets of A that would be included in its power set. And, the empty set would be in the power set but not in A.
However, the textbook states that this is sometimes but more often not the case. Would someone mind explaining?",['elementary-set-theory']
2197431,"Prove each of these statements from each other $\exists x, y: ax +by = 1$ and $\exists u,v: au = bv + 1 $","Hello I am trying to prove the following: We have show that two numbers a and b are relatively prime if and only if some integer linear combination of them equals 1, that is, if:
 $$\exists x, y: ax +by = 1$$ 
where x and y range over the integers, and $$\exists u,v: au = bv + 1 $$ where u and v range over the naturals. Prove each of these two statements from each other. How would I go about this? I decided that I would start by trying to prove the second statement from the first. I started off by instantiating two variables in the first statement for some integer f and g and isolating the ax term: $$ ∃x,y:ax+by=1 $$
$$ a(f) + b(g) = 1 \space for \space integers \space f \space and \space g $$ $$ a(f) = 1 - b(g)$$ I do not know how to continue on after this point.","['divisibility', 'gcd-and-lcm', 'elementary-number-theory', 'proof-explanation', 'discrete-mathematics']"
2197450,Find the value of $\tan^6(\frac{\pi}{7}) + \tan^6(\frac{2\pi}{7}) + \tan^6(\frac{3\pi}{7})$,"I wish to find the value of  $\tan^6(\frac{\pi}{7}) + \tan^6(\frac{2\pi}{7}) + \tan^6(\frac{3\pi}{7})$ as part of a larger problem. I can see that the solution will involve De Moivre's theorem somehow, but I cannot see how to apply it. I have looked at solutions of $z^7 - 1 = 0$ but to no avail. Can anyone suggest a method for solving this problem?","['trigonometry', 'complex-numbers']"
2197463,"Showing $ A \cup B \cup C $ is countable if $ A, B $ are countable and $C$ is finite.","How does one go about showing $ A \cup B \cup C $ is countable if $ A, B $ are countable and $C$ is finite? I understand most of the confusion for resolving set theory questions online seem to be the definition. For my course we consider the following definitions: countable: Finite or $A \sim\mathbb{N}$ uncountable: not countable finite: The empty set or $A \sim J_n$ where $n \in \mathbb{N}$ infinite: not finite So I'm not sure if I have this right but looking at the above definitions the way I'm looking to approach this is to consider 6 different cases. Where C is the empty set and A, B are both finite sets Where C is the empty set and A is finite and B is countably infinite Where C is the empty set and both A, B are countably infinite 4 - 6. Repeated above but with C being a non-empty finite set This seems like quite a round about way but intuitively it seems to me like the only way to cover all bases according to the definitions. I'm hoping I might be absolutely wrong on this. Is there a simpler way to prove this?",['elementary-set-theory']
2197483,What is an algebraic scheme?,"In Sernesi's book ""Deformations of Algebraic Schemes"", on page 2 (""Terminology and Notation""), he defines ""(schemes)"" to be the category of locally noetherian separated $k$-schemes, where $k$ is a fixed alg. closed field. Then he writes ""(algschemes) = the category of algebraic schemes"", but does not explain what the adjective ""algebraic"" means. What does this mean? I suspect it might mean ""finite type over $k$"", but I've never heard of this terminology before so hopefully someone here might be able to confirm this.",['algebraic-geometry']
2197519,Must a quasicoherent sheaf which is zero on a dense open subset be torsion?,"Let $X$ be a scheme, and $F$ a quasi-coherent sheaf of $\mathcal{O}_X$-modules on $X$, such that for some dense open $U\subset X$, we have $F|_U = 0$. Under these assumptions, must $F$ be a torsion module? I'm happy to assume $X$ is noetherian and reduced if necessary.",['algebraic-geometry']
2197531,Distinction between stable and asymptotically stable equilibria,"I read the book A Linear Systems Primer by Antsaklis, Panos J., and Anthony N. Michel (Vol. 1. Boston: Birkhäuser, 2007) and I am confused by the definition of stable . It is defined as: \begin{equation} 
\dot{x}=f(x), f(0)=0\tag{4.8} 
\end{equation} Definition 4.6 . The equilibrium $x = 0$ of (4.8) is said to be stable if for every $\epsilon > 0$, there exists a $\delta(\epsilon)>0$, such that
  \begin{equation} 
||φ(t, x_0 )|| < \epsilon  ~for ~all~ t ≥ 0  \end{equation}
  whenever $||x_0||<\delta(\epsilon) $ In this definition, does it mean that $ \lim_{t\to\infty} φ(t, x_0 ) = 0$ because $\epsilon$ could be any arbitrarily small positive number? If this is true, then the definition of stable equals to that of asymptotically stable which should NOT be correct. So what is the wrong part in my thought?","['ordinary-differential-equations', 'stability-theory']"
2197561,Does a Galois group being $S_3$ correspond to the extension being the splitting field of a cubic?,"If $f(x)$ is an irreducible cubic, then $\operatorname{Gal}(f(x))\cong S_3$ or $A_3$. But what about the converse? That is, if $\operatorname{Gal}(K/F)\cong S_3$, is it necessarily true that $K$ is the splitting field of some irreducible cubic in $F[x]$?","['abstract-algebra', 'galois-theory', 'group-theory']"
2197600,Why are free variables free?,"I'm having trouble understanding this: The free variables are called free because they can take on any value; none of the equations relates any of them to each other. Why can we set free variables to an arbitrary s or t? Example: Say we have $A = \begin{bmatrix}
1 & 2 & 2 & 2 \\
0 & 0 & 2 & 4 \\
0 & 0 & 0 & 0
\end{bmatrix}$ and we are looking for solutions to $Ax = 0$ . Here, we have column $1$ and $3$ as our pivot columns (and $x_1$ , $x_3$ are pivot varibles ) and column $2$ and $4$ as our free columns (and $x_2$ , $x_4$ are free variables )[1]. To find a solution vector $x =\begin{bmatrix} x_1 \\ x_2 \\x_3 \\ x_4\end{bmatrix}$ , we can set any arbitrary values to $x_2$ and $x_4$ which will lead to some values for $x_1$ and $x_3$ , thus giving us our solution. The confusion: setting arbitrary initial values to the ""pivot variables"" ( $x_1$ and $x_3$ ) and then finding the values of ""free variables"" also leads to a solution. Then why do these ""free variables"" exist? And why are they called ""free""? [1] Page 80, Strang, Gilbert , Linear algebra and its applications, Boston, MA: Brooks/Cole, Cengage Learning (ISBN 978-0-534-42200-4). 496 p. (2007). ZBL1329.15004 . Lecture by Gilbert Strang illustrating this example: https://youtu.be/VqP2tREMvt0?t=322","['matrices', 'linear-algebra']"
2197603,"Proving $\lim_{(x,y)\to (0,0)}\frac{xy}{\sqrt{x^2 +y^2}}=0$ in a strange way: Does it even make sense?","I need to prove that $$\lim_{(x,y)\to (0,0)}\frac{xy}{\sqrt{x^2 +y^2}}=0$$ And I have already found some questions with the exact same question but I guess I proceeded in a somewhat different way. The limit exists if for each $\epsilon>0$, there is $\delta>0$ such that $$\left|\cfrac{xy}{\sqrt{x^2+y^2}} -L\right|<\epsilon$$ And $|x-a|<\delta,|x-a|<\delta$ or $|(x,y)-(a,b)|<\delta$ and $x\neq a, y \neq b $. I made a somewhat experimental approach and would like to talk about it. I learned that we can try to approach the limit with some paths: polar coordinates, lines, etc. So I give a shot: As the limit goes to $(0,0)$, it seemed natural to try: $x \to \frac{1}{m} $ as $m \to \infty $, and $y\to \frac{1}{n}$ as $n\to \infty$, this gives me: $$\left|\cfrac{1}{\sqrt{m^2+n^2}}\right|<\epsilon$$ $$\left|\frac{1}{m}\right |<\delta \quad \quad  \left|\frac{1}{n}\right|<\delta $$ And with this, I guess that we can see that we can approach $0$ arbitrarily. But if we take the other form: $$\left|\sqrt{\frac{1}{m^2}+\frac{1}{n^2}}\right|<\delta$$ $$\left|\sqrt{\frac{m^2+n^2}{m^2n^2}}\right|<\delta$$ $$\left|\frac{\sqrt{m^2+n^2}}{ mn} \right|<\delta$$ But now it seems that we can't have a $\delta$ for every $\epsilon$ chosen. So how can they be equivalent? I may be missing something. Also, one important question: Q: I learned the definitions with $\epsilon, \delta$ and the idea of looking for a possible limit by some paths as different ways: The first one seems to be used to prove that there is a limit, but the second one seems to be a cheap method to gather evidence that it couldn't be (if the value is different for two paths, then the limit does not exist), but in the above example, I merged them both. Is this usually viable or do I incur the same problem of not having the same value for different paths implies the non-existence of the limit? I had also the (incomplete?) idea of trying to approach the limit with a circle $a^2+b^2=c^2$ and take the limit of $c\to 0$ but am a little confused if it could be done. $$\left|\frac{\sqrt{c^2-a^2} \sqrt{c^2-b^2}}{\sqrt{-a^2-b^2+2 c^2}}-0\right|<\epsilon$$ $$\left|\frac{\sqrt{c^2-a^2} \sqrt{c^2-b^2}}{\sqrt{-a^2-b^2+ c^2+c^2}}\right|<\epsilon\tag{$c^2-a^2-c^2=0$}$$ $$\left|\frac{\sqrt{c^2-a^2} \sqrt{c^2-b^2}}{c}\right|<\epsilon$$ As $b^2=c^2-a^2$ and $a^2=c^2-b^2$, then: $$\left|\frac{ba}{c}\right|<\epsilon$$ As $c\to 0$, I guess we can make the substitution $c:= \frac{1}{n}$ with $n\to \infty$, then: $$\left|abn\right|<\epsilon$$ And here, as $n\to \infty $, $c\to 0$ and due to $a^2+b^2=c^2$, then $a,b\to 0$. As for the $\delta$, then: $$\left|\left( \sqrt{c^2-a^2},\sqrt{c^2-b^2} \right) -(0,0)\right|<\delta$$ $$\left| \left( \sqrt{c^2-a^2+c^2-b^2  }\right)\right|<\delta\tag{$c^2-a^2-c^2=0$}$$ $$|c|<\delta$$ Are these moves acceptable? If not, do you know at least one counterexample? I'd like to see why it doesn't work - if it doesn't work.","['multivariable-calculus', 'real-analysis', 'limits']"
2197604,Why don't we take clopen maps as morphisms of the category of topological spaces?,"Here, by clopen maps I mean a function mapping an open set into an open set and a closed set into a closed set. We say continuous maps are the morphisms of the category of the topological spaces. But isn't it more natural to consider clopen maps instead of continuous maps? For example, we say group homomorphisms are the morphisms, and a group homomorphism $h:G\rightarrow H$ preserves the group structure of ""$G$"" in ""$H$"". On the other hand, in some sense, a continuous map $f:X\rightarrow Y$ preserve the topological structure of ""$Y$"" in ""$X$"". The direction is reversed. I am wondering if there is any good explanation for this. Thanks!","['category-theory', 'abstract-algebra', 'general-topology', 'morphism']"
2197606,Could we practically forgo education in degrees in favor of radians? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 7 years ago . Improve this question I've never been a fan of degrees and I'm still a bit resentful that my brain has been programmed to think in terms of them. Would it be practical to not teach them to children in primary education and just use radians from the start? Maybe if not in the public education sector, what about something more custom like home schooling?","['angle', 'trigonometry']"
2197655,Finding the probability that $2$ socks are the same color,"Question: A drawer contains $6$ blue socks and $4$ white socks. Two socks are chosen randomly without replacement. What is the probability that the $2$ socks are the same color? Should I approach this problem by adding the probabilities of selecting $2$ blue socks and selecting $2$ white socks? If so, is the formula unordered without replacement? Can somebody direct me with the right formula to solving this?","['statistics', 'probability']"
2197682,Describe and draw the half-strip $R$ under the mapping $f(z) = z^2$,"Describe mathematically and draw what happens to the half-strip $R = \{z=x+iy: 0 \leq x \leq 1, y \geq 0 \}$ under the mapping $f(z) = z^2$ I need help with describing and drawing the mapping. solution: For, $z = x+iy$ and $w=f(z)=z^2$ $\Rightarrow w=(x+iy)^2 = (x^2-y^2) + 2xyi$. So $w=u+iv \Rightarrow u=x^2-y^2$ and $v = 2xy$ case i: $u=x^2-y^2 = c_1, c_1 >0$ The graph in the $xy$-plane is the hyperbola cutting the $x$-axis. The $uv$-plane $u=c_1$ represents a vertical line. That is, hyperbolas in the  $xy$-plane are mapped to vertical lines in the $uv$-plane. caseii: $v = 2xy = c_2, c_2>0$ $v=c_2$ represents a horizontal line. The hyperbolas in the  $xy$-plane are mapped to horizontal lines in the $uv$-plane. drawing:",['complex-analysis']
2197698,Second Countability Preserved under CLOSED Continuous Surjection,"In my General Topology course we were recently shown the theorem that says that Second Countability Preserved under Open Continuous Surjection and the natural question is if we can switch the ""Open"" condition for ""Closed"": Conjecture : Let $T_A=(S_A,\tau_A)$ and $T_B = (S_B,\tau_B)$ be topological spaces. Let $p:T_A \rightarrow T_B$ be a surjective closed mapping that is also continuous . If $T_A$ is second countable then $T_B$ is second countable I tried proving it and failed, because being closed is very limiting when I'm trying to apply the function to a basis so the proof for the open case can't be easily adapted :( then I tried looking it up and nothing showed up and then I found this other thread which has a similar question but it adds the extra hypothesis that for every $y \in Y$ , $p^{-1}(y)$ is compact. So now my current guess is that it's probably false without that extra assumption. Also, I haven't been able to give a counterexample and I couldn't find on in Lynn Steen's Counterexamples in Topology Can anyone hint at me in the direction of a counterexample or proof? Thanks.","['general-topology', 'second-countable']"
2197757,"How can I show that the closed unit ball in $L^1([0,1])$ is not compact?","Consider the following subset of $L^1([0,1])$, $S=\left\{f\in L^1([0,1]):{\|f\|}_1\leq1\right\}$. Prove that $S$ is not compact. Should I start with an open cover and prove that it has no finite subcover or find a convergent sequence that has no convergent sub-sequence? I am quite confused.","['general-topology', 'real-analysis', 'lp-spaces', 'compactness']"
2197783,Relationship between unit circle and cosine wave?,"If you plot these two relations: $$y=cos(x)$$ $$x^2 + y^2 = 1$$ The cosine wave seems to ""hug"" the unit circle shown below. I'm wondering the calculus explanation for this, as I believe it must have to do with the relationship between the implicit derivative of the unit circle, where the slope of the tangent line at any point is found using the negative cotangent function.  But this doesn't seem to explain why the unit circle is wrapped around the cosine function like this as the derivative is asymptotic at $\frac{\pi}{2}$ . And even then, is there a geometric intuition for why they behave so similarly around 0?","['algebra-precalculus', 'trigonometry', 'calculus', 'geometry']"
2197784,How to solve given differential equation?,"$$ 4x^{3}y''(x)+6.y'(x^{2})-2x^{2}y'(x)-3y(x^{2})+2.xy(x)=\dfrac{1}{2(1-x^{2})} $$
I have tried to express $y$ as a power series and then expanding the right side to binomial coefficients but I'm getting stuck there, I cant invert it to standard functions.","['ordinary-differential-equations', 'calculus']"
2197788,Prove a graph be a planar graph,"Q: Prove that a graph in which triangular regions are permitted is planar if and only if $e \le 3v-6$. This is one of the exercise questions from a discrete mathematics textbook. I feel this questions is wrong. Basically, we can prove that a graph in which triangular regions are permitted is planar implies $e \le 3v-6$. But we cannot prove the converse. If all the regions are triangular, then we have $3r \le 2e$. So $e+2 =r+v \le \frac23e+v$ after simplification, we get $e\le 3v-6$. A graph in which triangular regions are permitted. $\Rightarrow e\le 3v-6$ The textbook has another exercise as follows: Q: Prove that a bipartite graph can only be planar if $e\le 2v-4$. Basically, this question is equivalent to prove if a bipartite graph is planar, then  $e\le 2v-4$. Am I right to say that?","['graph-theory', 'logic', 'discrete-mathematics']"
2197800,AM-GM giving wrong result on applying to trigonometric functions,"Question: Find the range of $f(x)=\operatorname{cosec} ^2x+25\sec^2x$ My attempt: Applying AM-GM:
$$f(x) \geq 2\sqrt{\operatorname{cosec}^2x\cdot25\cdot \sec^2x}$$
$$f(x) \geq 10\cdot \left|\operatorname{cosec}x\cdot \sec x\right| = \frac{20}{\left|\sin2x\right|}\geq20$$ Hence, my answer is $[20, \infty)$ But my book used the expansion for $\operatorname{cosec}^2x$ and $\sec^2x$ and arrived at $36$ as the minimum bound. I agree with their method as well, but I don't seem to find any problem my own method as well! Why am I getting a different result? What did I do wrong? Hints appreciated! UPDATE: Thanks to explanation in comments, the problem appears to be that I've got a number for the range, but I haven't proved that it is the lowest number $f(x)$ can be equal to. It is entirely possible $f(x)$ can be greater than $30$ as well. We need to prove that as well. Now, I am stuck on this part, proving that $f(x)=20$ is possible or not. It seems the issue's like using two different values of $sin(2x)=1 and 5/13$ in the same question, the former as used above and the latter used for the fact that for AM-GM to actually take the minimum value, $\operatorname{cosec} ^2x=25\sec^2x$. Can there be more clarification on this?","['inequality', 'a.m.-g.m.-inequality', 'optimization', 'trigonometry', 'cauchy-schwarz-inequality']"
2197821,Show that the Gram Matrix G(B) is Positive Definite,"Suppose we have $\boldsymbol P_{\leqslant 1}=\operatorname{span}\{1,x\}$ that is an inner product space with respect to $\int^1_0p(x)q(x)dx$ . Consider the basis $B=\left\{b_1 = 1, b_2 = x\right\}$ . Finding the Gram matrix $G(B)$ I would have $G(B)=\begin{bmatrix}\int^1_01dx & \int^1_0xdx\\ \int^1_0xdx & \int^1_0x^2dx \end{bmatrix} = \begin{bmatrix}1&\frac12\\\frac12&\frac13\end{bmatrix}$ I want  to show that $G(B)$ is positive definite. It is obvious that $G(B)$ is symmetric since $G_{12} = G_{21}$ . Now, to calculate the eigenvalues, I have found that $\lambda_1 = \frac{4+\sqrt{13}}{6}$ $\lambda_2 = \frac{4-\sqrt{13}}{6}$ Since $4 > \sqrt{13}$ , then $\lambda_2 > 0$ . Is this enough to show that this is positive definite? The reason that I am skeptical is because I had a homework question similar to the one above, but with a longer basis and with $\textbf{P}_{\leq 2}=\operatorname{span}\{1,x,x^2\}$ : consider the basis $B = \{b_1 = 1, b_2 = x, b_3 = x^2\}$ The Gram matrix is then $G(B)=\begin{bmatrix}1&\frac12&\frac13\\\frac12&\frac13&\frac14\\\frac13&\frac14&\frac15\end{bmatrix}$ I attempted to show that $G(B)$ is positive definite by first showing that the matrix is symmetric, and that its eigenvalues $\lambda$ are positive. However, it seems to be extremely unfeasible to find the eigenvalues of $G(B)$ . Is there another way I could go about and prove this?","['matrices', 'positive-definite', 'linear-algebra', 'inner-products']"
2197875,suppose we wish to distribute 15 presents to 5 children so that each child gets at least one. How many ways are there to do this?,"Is this similar if not the same to the distribution of pennies since they did not mentioned that the presents are different? In which case we can say that there is  $ \binom{n-1}{k-1}$ choices or is my thinking wrong?
(where $n$  are the presents and $k$ are the children)","['combinatorics', 'discrete-mathematics']"
2197911,Proving $\int_{0}^{1}{1\over \sqrt[4]{\ln \left({1\over x}\right)+\ln^2\left({1\over x}\right)}}\cdot{\mathrm dx\over x}=\cdots$,"Consider this integral $(1)$ $$\int_{0}^{1}{1\over \sqrt[4]{\ln \left({1\over x}\right)+\ln^2\left({1\over x}\right)}}\cdot{\mathrm dx\over x}=-\Gamma\left(-{2\over 4}\right)\cdot{\Gamma\left({3\over 4}\right)\over \Gamma\left({1\over 4}\right)}\tag1$$ How can one prove $(1)$? An attempt: Rewrite $(1)$ as $$\int_{0}^{1}(-\ln x+\ln^2(x))^{-1/4}\cdot{\mathrm dx\over x}\tag2$$ $u=\ln x \implies x\mathrm du =\mathrm dx$ then $(2)$ becomes $$\int_{0}^{\infty}(u^2-u)^{-1/4}\mathrm du\tag3$$ May be we can split it into partial decomposition of fraction $${1\over u^{1/4}(u-1)^{1/4}}={A\over u^{1/4}}+{B\over (u-1)^{1/4}}$$ Then $(3)$ becomes $$\int_{0}^{\infty}{\color{red}{A\over u^{1/4}}}+{B\over (u-1)^{1/4}}\mathrm du\tag4$$ But the red part diverges, how else can we tackle $(1)?$","['integration', 'definite-integrals', 'calculus']"
2197915,Structure of locally free $\mathcal{O}_{X}$-module on affine open set,"Suppose $X$ is a scheme. I have been studying (finite rank) locally free $\mathcal{O}_{X}$-modules, and more generally, quasi-coherent sheaves on $X$ mainly from Ravi Vakil's excellent notes as well as Hartshorne. Let $\mathcal{F}$ be any quasi-coherent $\mathcal{O}_{X}$-module and let $\mathcal{G}$ be a locally free $\mathcal{O}_{X}$-module. I understand that for any affine $U = \text{spec}A \subset X$, we can fine an $A$-module $M$ such that $\mathcal{F} \vert_{U} \simeq \widetilde{M}.$ Hence this property also holds for locally free $\mathcal{O}_{X}$-modules. However, how do I know that for any such affine subset that there holds $\mathcal{G} \vert_{U} \simeq \mathcal{O}_{X}^{\oplus^{n}}$? I know that there exists a cover (not necessarily affine) $\left\lbrace U_{i} \right\rbrace_{i \in I}$ such that this holds locally at each $U_{i}$, but I am not sure how to show that the ""freeness"" property must then hold for any affine subset. I strongly suspect an argument can be made from the transition functions, but I haven't been able to make any progress. Any help is appreciated. Thanks","['quasicoherent-sheaves', 'sheaf-theory', 'algebraic-geometry']"
2197929,"Should I join a group, or stay an individual?","I have just taken part in a draw and it has left me wondering whether I made the right decision to enter the draw as an individual or whether I should have entered as a group, and if so, what size group would have been optimal. For this draw my partner and I signed up as individuals. Neither of us wanted to deprive the other of a place if we didn't get in, but since I got a place and she didn't, and I now know the mechanics of the draw, I'm prompted to question our choices. The set up is as follows. A game has 30 places for male players and 30 places for female players. † 100 players have signed up for the game (half male and half female † ), so not everyone can play. Players can either register as individuals, or register in a group, such as a couple, family or fraternity of friends. No-one can register more than once. Individuals are assigned a single draw number. If an individual is selected before all places for their gender are filled they get in the game, otherwise they are placed on a wait list. Groups are also assigned a single draw number. If a group is selected before all places required for that group are taken they all get in the game, otherwise they are all placed on a wait list. For example, let's say the distribution is as follows: 35 Male 35 Female 11 couples (FM) 2 fraternities of four (MFFM) This means that there are 83 draw numbers, but each draw could allocate 1, two or 4 places, or add that number of players to the wait list. As an individual, do I have the same chance of getting a place as I would if I were registered as a couple? What about if I registered as part of a larger group? Looking at this naively, I would assume that since there are 30 places for 50 players of each gender, both my partner and I would have a 60% chance of getting a place, a 36% chance that both of us would get a place and a 16% chance that neither of us would get a place. Even more naively I assumed that if we registered as a couple, we would still have a 60% chance of getting a place, and thus 40% chance of not getting a place, but is that true? † This is a simplification, the actual draw also had a small number of gender neutral players and places.",['probability']
2197990,Solving a second order linear differential equation,"Am having difficulty obtaining a solution for this ODE. 
$ (\omega^2-x^{\alpha})\psi^{''} - \alpha x^{\alpha-1}\psi^{'} - \gamma \psi = 0 $
where $ \omega $ and $ \gamma $ are positive constants, $ x $ is the independent variable and $ \psi $ is a function of $ x $. I need the solution for this ODE for general $ \alpha $. I tried using the series method of solution to solve (frobenius) but I wasn't successful.",['ordinary-differential-equations']
2198091,How can I prove this trigonometric equation with squares of sines?,"Here is the equation: $$\sin^2(a+b)+\sin^2(a-b)=1-\cos(2a)\cos(2b)$$ Following from comment help, $${\left(\sin a \cos b + \cos a \sin b\right)}^2 + {\left(\sin a \cos b - \cos a \sin b\right)}^2$$ $$=\sin^2 a \cos^2b + \cos^2 a \sin^2 b + \sin^2 a \cos^2 b + \cos^2 a \sin^2 b$$ I am stuck here, how do I proceed from here? Edit: from answers I understand how to prove,but how to prove from where I am stuck?",['trigonometry']
2198129,About the method of Lagrange multipliers to extremize a function,"Suppose that by the using the method of Lagrange multipliers to extremize the function $f(x,y)$
subject to the constraint $g(x,y)$, we find that $f(x,y)$ has only one critical point. 
How can we deduce the critical point is minumum or maximum?","['multivariable-calculus', 'lagrange-multiplier']"
2198145,"Prove that every infinite metric space $(X, d)$ contains an infinite subset $A$ such that $(A, d)$ is discrete.","A metric space $X$ is said to be discrete if every point is isolated. A
point $x ∈ A ⊂ X$
is an isolated point of $A$ if some open ball centred at $x$ contains
no members of $A$ other than $x$ itself. I am having troubles with proving the following statement: Every infinite metric space $(X, d)$ contains an infinite subset $A$ such that $(A, d)$ is discrete. I have spent some time on this problem. I am thinking that a constructive proof may be impossible. But even if I tried proof by contradiction, I still did not get much progress. Can someone help me? Thanks so much.","['general-topology', 'metric-spaces']"
2198165,"Is $f(x)(y)$ the same as $f(x,y)$?","I have a slight confusion with the notation $f(x)(y)$ . Does $f(x)(y)$ mean the same as $f(x,y)$ ? Or does it mean something else? Particularly I saw the notation $f(x)(y)$ in the following definition for Eulerian derivative of a functional $J: \Omega \rightarrow J(\Omega)$ to the direction of the vector field $V$ : $$dJ(\Omega;V) = \lim_{t\rightarrow 0}\frac{J(\Omega_t)-J(\Omega)}{t}$$ where $\Omega_t = T_t(V)(\Omega).$","['multivariable-calculus', 'notation']"
2198198,Equivalent characterizations of discrete valuation rings,"Let $R$ be a commutative ring with identiy, then the following are equivalent: $R$ is a DVR $R$ is a local Euclidean domain that is not a field. $R$ is a local PID that is not a field. $R$ is a local Dedekind domain that is not a field. $R$ is a UFD with a unique irreducible element up to a unit. There is a non-nilpotent non-unit element $\pi \in R$ such that every $a \in R \setminus\{0\}$ has a unique expression $a = u \pi^n$ , where $u \in R^\times$ and $n\in \mathbb{N}$ . $R$ is a Noetherian valuation ring and not a field. $R$ is a Noetherian local ring with a principal maximal ideal generated by a non-nilpotent element. $R$ is a regular local Noetherian ring of dimension $1$ . $R$ is a local Noetherian domain that is not a field such that every non-zero ideal is a power of the maximal ideal. Here is what I tried so far: $(1.) \Rightarrow (2.)$ Every valuation ring is local .
Suppose $v$ is a discrete valuation on the fraction field of $R$ such that $v^{-1}(\mathbb{N}) \cup \{0\} = R$ . We claim that $v$ is actually also a Euclidean function for $R$ . Let $x,y \in R$ , $y \neq 0$ , if $\frac{x}{y} \in R$ , we have $x = y \frac{x}{y} + 0$ , so we are done. If $\frac{x}{y} \notin R$ , then $0 > v(\frac{x}{y}) = v(x)- v(y)$ , so $v(y) > v(x)$ . Now we have $v(x) = v(y + (x - y)) \geq \min(v(y), v(x - y))$ , but as $v(y) > v(x)$ , it must be the case that $v(x) \geq v(x-y)$ . Now we write $x = 1\cdot y + (x - y)$ and $v(y) > v(x) \geq v(x-y)$ . $(2.) \Rightarrow (3.)$ Every Euclidean domain is a PID . $(3.) \Rightarrow (4.)$ Every PID is a Dedekind domain . $(3.) \Rightarrow (5)$ Every PID is a UFD and every irreducible element generates a maximal ideal in a PID and every maximao ideal is generated by an irreducible element (As $R$ is not a field, the maximal ideals are non-zero). As all these maximal ideals must coincide, there is exactly one irreducible element up to a unit. $(5.) \Rightarrow (6.)$ A domain does not contain nontrivial nilpotents. So we can take $\pi$ to be the unique irreducible element. $(1.) \land (3.) \Rightarrow (7.)$ Every PID is Noetherian . $(7.) \Rightarrow (3.)$ Every valuation ring is a local Bezout domain. Noetherian Bezout domains are PIDs. $(4.) \Rightarrow (10.)$ Let $R$ be a local Dedekind domain that is not a field. Then $R$ is one-dimensional, so every nonzero prime ideal is maximal, but there is only one maximal ideal as $R$ is local, so there is only one non-zero prime ideal. As $R$ is Dedekind, every non-zero ideal is a product of prime ideals, thus every non-zero ideal is a power of the maximal ideal. $(8.) \Rightarrow (9.)$ Let the maximal ideal $m$ be generated by $x$ , then the image of $x$ generates $m/m^2$ . If $m/m^2 = 0$ , $m = m^2$ , but then $m 
= 0$ by Nakayama's lemma , so $m/m^2 \neq 0$ , thus $\operatorname{dim}_{R/m}m/m^2 = 1$ . It follows from Krull's principal ideal theorem that $\operatorname{dim}R= 1$ . $(9.) \Rightarrow (8.)$ Let $m$ be the maximal ideal and $\bar{x}$ be a generator of $m/m^2$ and let $x$ be a preimage of $\bar{x}$ under the natural
quotient map. We then have $m = m^2 + (x)$ , so $m = (x)$ by a corollary to Nakayama's lemma. Now we need to show that $x$ is not nilpotent. As $\operatorname{dim}R = 1$ , $m$ properly contains a minimal prime ideal $p$ . If $x$ was nilpotent, then $x \in p$ , but this implies $m \subset p$ , which is impossible. $(10.) \Rightarrow (8.)$ Let $m$ be the maximal ideal. Note that we cannot have $m^2 = m$ or else $m = 0$ by Nakayama's lemma, but $R$ is not a field. Choose $x \in m \setminus m^2$ , then $(x)$ is a power of $m$ , but by our choice of $x$ the only possibility is that $m = (x)$ . As $R$ is a domain, $(x)$ is not nilpotent. $(8.) \Rightarrow (6.)$ Let $m = (\pi)$ be the maximal ideal. We first show that every nonzero $x_0 \in R$ has an expression of the required form. First, if $x_0$ is a unit, then we are done. If $x_0$ is not a unit, then $x_0 \in m$ , so $x_0 = x_1 \cdot \pi$ . Then, do the same for $x_1$ . If $x_1$ is a unit, then we are done, if $x_1$ is not a unit $x_1 \in m$ , so we can write $x_1 = x_2 \cdot \pi$ etc. To see that this process must terminate, we note that if it doesn't, we have $x \in m^n$ for all $n\in \mathbb{N}$ which contradicts Krull's intersection theorem . Now that every nonzero element is of the form $u\pi^n$ we have to show uniqueness. If we take two non-zero elements write them as $u_{1}\pi^n$ and $u_{2}\pi^k$ , then their product $u_{1}u_{2}\pi^{n+k}$ is non-zero, as $\pi$ is not nilpotent. This shows that $R$ is an integral domain, thus the multiplicative monoid is cancellative, from this, the uniqueness follows easily, if we have $u_1 \pi^n = u_2 \pi^k$ Assume wlog that $n \geq k$ , then we have $u_1 = u_2 \pi^{n-k}$ . Now if $n > k$ , the LHS is a unit while the RHS is not, which is absurd. Thus $n = k$ and $u_1 = u_2$ . $(6.) \Rightarrow (1.)$ $R$ is an integral domain by the same argument as in $(8.) \Rightarrow(6.)$ Now define a valuation on $R$ via $v(u\pi^n)=n$ We have $v(u_1\pi^n\cdot u_2 \pi^k) = n+k = v(u_1\pi^n)+v(u_2\pi^k)$ Assume wlog that $k \leq n$ , then $v(u_1\pi^k+u_2\pi^n)=v( (u_1+u_2\pi^{n-k})\pi^k) \geq k = \min(v(u_1\pi^k),v(u_2\pi^n))$ . Extend $v$ to the fraction field of $R$ by setting $v(\frac{a}{b})=v(a)-v(b)$ , then it is obvious that $R$ is the valuation ring of $v$ . My question is, is this all correct? Do you know any other characterization of DVRs? If so, why is it equivalent? For example, wikipedia has the following $R$ is a (edit: Noetherian) domain that is not a field, and every nonzero fractional ideal of $R$ is irreducible in the sense that it cannot be written as finite intersection of fractional ideals properly containing it. But I have no idea how to show that it is equivalent.","['abstract-algebra', 'ring-theory', 'commutative-algebra', 'valuation-theory', 'solution-verification']"
2198208,The Continuous Differential Operator,"I was playing around a bit this morning until I realized that one could write the arbitrary derivative of $\cos x$ as $$(\cos x)^{(n)} = \cos\big(\frac{\pi}{2}(n-1) \big)\sin x + \cos\big(\frac{\pi}{2}n\big)\cos x$$ Similarly, writing $$\sin x=\cos \left(x-\frac{\pi}{2}\right)$$ we see that $$\frac{d^n}{dx^n}\sin x = \frac{d^n}{dx^n} \cos \left(x-\frac{\pi}{2}\right)$$ which evaluates to (I think I'm using the chain rule properly in this case): $$\cos\big(\frac{\pi}{2}(n-1) \big)\sin \left(x-\frac{\pi}{2}\right) + \cos\big(\frac{\pi}{2}n\big)\cos\left(x-\frac{\pi}{2}\right)$$ simplifying $$(\sin x)^{(n)} = \cos\big(\frac{\pi}{2}(n-1) \big)\cos x + \cos\big(\frac{\pi}{2}n\big)\sin x$$ where we have that $n \in \mathbb{R}$ These two results can be expressed as a complex exponential too. Because these functions happens to be continuous, in some ways the differential operator is now continuous for cosine and sine. I'm wondering if anyone can interpret this for me a I haven't studying real analysis and only have a nonrigorous calculus background. Question After doing some reading, I realized that because every function can be written as a Fourier transform, one ought to be able to simply use the above definitions to take the nth derivative of the fourier transform of an arbitrary function to an arbitrary degree of precision (by choosing how many terms to include). Is the hypothesis true? If so, can you summarize it in a way I would be able to understand and use. Assume I know the definition of the fourier transform. All I am looking for now is a general equation for the continuous differential operator of a function.","['derivatives', 'trigonometry', 'fourier-analysis']"
2198210,A Drunken Prison Guard. [duplicate],"This question already has answers here : Prison problem: locking or unlocking every $n$th door for $ n=1,2,3,...$ (2 answers) Closed 7 years ago . This is a number theory exercise I've been stuck on for a while. It was set during a lecture I attended once. It goes something like this . . . Suppose there's a full circular prison with 100 cells and one prison guard who hates his job. He gets drunk one night and decides to play a game while the prisoners were asleep. He walks the circular prison and, the first time, he opens every cell; the second time, he closes every even numbered cell; the third time, he touches every third cell, and if that cell is open, he closes it, and he opens it otherwise; the fourth time, he touches every fourth cell, and if that cell is open, he closes it, and he opens it otherwise; and so on until his hundredth time around the prison. He then falls asleep. By the morning, after the prison guard's hundredth lap, every prisoner in an open cell escapes. Which prisoners escape? Thoughts: I've thought of trying a modified use of the Sieve of Eratosthenes but there's got to be a more elegant, less brute-force solution.","['number-theory', 'recreational-mathematics']"
2198250,A star shaped domain,"We say that $\Omega$ is a star-shaped domain (with respect to the origin) of $\mathbb R ^n$ if : $\Omega  = \{x\in \mathbb R ^n : \left \| x \right \| < g(\frac{x}{\left \| x \right \|})\} $ and 
 $\partial \Omega  = \{x\in \mathbb R ^n : \left \| x \right \| = g(\frac{x}{\left \| x \right \|})\} $
with $g$ is a continuous, positive function on the unit ball.
I have two questions: 1) I know what star-shaped means Geometrically, but it doesn't get linked with the definition given above. Can you help me understand.. 2)Is there a map (bijection) between $\Omega$ and the unit sphere $B$? I appreciate your answers and your help. EDIT: $g$ is a function on a unit sphere.","['real-analysis', 'functional-analysis', 'euclidean-geometry', 'geometry', 'analysis']"
2198254,How form a linear mapping $f:\mathbb{R}^{4} \rightarrow \mathbb{R}^{3}$ to a matrix correctly?(solved),"Given is $f: \mathbb{R}^4 \rightarrow \mathbb{R}^3$ $f(x)= \begin{pmatrix}
x_1-2x_2+x_4\\ 
-2x_1+5x_2+x_3-4x_4\\ 
x_1+2x_3-3x_4
\end{pmatrix}$ How can I form this to a matrix correctly? We have $f: \mathbb{R}^4 \rightarrow \mathbb{R}^3$, and we have $x_1,x_2,x_3,x_4$ I think because we go to $\mathbb{R}^3$, we will only have $x_1,x_2,x_3$ So when I form a matrix, I will ignore $x_4$: \begin{pmatrix}
 1 & -2 &  0\\ 
-2 &  5 &  1\\ 
 1 &  0 &  2
\end{pmatrix} Is it fine like that?","['matrices', 'abstract-algebra', 'linear-algebra', 'linear-transformations']"
2198256,Does this infinite isohedron with the surface topology of the gyroid have a name?,"I was experimenting  with discretizations of the gyroid minimal surface in Rhino (3d modelling software), and modelled this infinite polyhedron, and wondered what it is called. I didn't find any documentation of it yet, but perhaps I am not searching for the right terms. All its faces are the same isosceles triangle (with angles of approx. 56.8°, 56.8°, 66.4°), and it has 2 types of vertices (with either 6 or 8 surrounding faces): Applying Loop subdivision to this mesh gives a good approximation of the gyroid periodic minimal surface. I found some other examples of infinite polyhedra with gyroid topology here: https://theinnerframe.wordpress.com/2015/10/23/the-gyroids-algorithmic-geometry-iii/ but so far nothing with the same polyhedron as in my model.","['polyhedra', 'minimal-surfaces', 'geometry']"
2198294,Does this Abel sum related power series diverge to $-\infty$ at $1$?,"Define $a_n$ for $n\geq 2$ to be $1$ if the second most significant digit of $n$ in binary is $1$ and $-1$ otherwise. For example for $n=23$, in binary $n=10111_2$ and so $a_n=-1$, becuase the second digit of $n$ was $0$. The limit in question is $\lim_{x\to 1} f(x)=\lim_{x\to 1}\sum_{n=2}^\infty a_nx^n$. Intuition: The coefficients of this power series are only $-1$ and $+1$. There is (starting from $2$) $a_n=-1,1,-1,-1,1,1,-1,-1,-1,-1,1,1,1,1,\ldots$ followed by 8 times $-1$ and so on with the number of $\pm 1$ being increasing powers of $2$. The negative powers of $x$ therefore come earlier and should be more significant, resulting the limit in being $-\infty$. Approaches: The limit and the sum sadly cannot be interchanged. I tried summing the finite geometric series, which occur in the sum. This results in $$\sum_{n=1}^\infty -x^{2^n} \frac {1-x^{2^{n-1}+1}}{1-x} +x^{2^n+2^{n-1}}\frac {1-x^{2^{n-1}+1}}{1-x} $$ and does not look promising for me. Maybe this still works somehow?! (Might have mistakes, I wrote this from memory) I found the following functional equation for $f$: $$(1+x)f(x^2)-x^2+x^3=f(x)$$ and plugging in $x=1$ yields $2f(1)=f(1)$, which leaves only $f(1)=\pm \infty,0$ . $+\infty$ is easily excluded, because $f$ is negative on $(0,1)$ and this also lacks an argument for the convergence after all. Another approach with simply the definition of limits failed miserably. But again this might be my fault. Any hints or maybe even solutions are appreciated.","['real-analysis', 'divergent-series', 'power-series', 'limits']"
2198303,$f:X\times Y \to \mathbb{R}$ product measurable if separately measurable and semicontinuous?,"Let $(X,\Sigma)$ be a measure space and let $(Y,\mathcal{B})$ be a separable metric space (can assume Polish if necessary) with Borel $\sigma$-algebra $\mathcal{B}$. Suppose $f:X \times Y \to \mathbb{R}$ is such that $f(x,\cdot)$ is upper semicontinuous for each $x$ and $f(\cdot, y)$ is measurable for each $y$. Can I conclude that $f$ is product measurable? I know this would be true if $f(x,\cdot)$ would be continuous for each $x$, but this doesn't hold for the case I'm interested in.","['general-topology', 'measure-theory']"
2198335,Potential uses for viewing discrete wavelets constructed by filter banks as hierarchical random walks.,"I have some weak memory that some sources I have encountered a long time ago make some connection between random walks and wavelets, but I am quite sure it is not in the same sense. What I was thinking is to in the matrices representing filtering operations replace every $a\in \mathbb{R}$: $$\cases {\phantom{-}a\to \begin{bmatrix}a&0\\0&a\end{bmatrix}\\-a\to \begin{bmatrix}0&a\\a&0\end{bmatrix}}$$
Assuming filter taps are real numbers to start with, we will then have made our matrix positive in the sense that each element $\geq 0$, furthermore we can choose to normalize so that the matrix becomes stochastic. All operations will then preserve the positivity because they will be permutations and subsamplings concatenated with new filterings which are in turn constructed in the same way. And more generally : not necessarily filter banks, but any sequence of convolutions (assuming filters and signals consisting of real numbers) could be translated in the same way. What would the implications of such a construction be? What could it be useful for? What would ""happen"" to the signal in this new probabilistic sense and how to make use of it? Own work / example : The Haar system is usually considered one of the easiest to learn when introduced to the subject. It has a lowpass and a highpass filter of two taps each ( sum and difference ): $$\left[\begin{array}{rr}1&1\\1&-1\end{array}\right] \to \frac{1}{2}\cdot \left[\begin{array}{rr|rr}1&0&1&0\\0&1&0&1\\\hline 1&0&0&1\\0&1&1&0\end{array}\right]$$ where the factor $\frac 1 2$ is normalization factor to get a stochastic matrix and the horizontal/vertical lines are just to make the block structure clearer. The stationary distribution (eigenvalue 1) has 1/4 in each bin.","['wavelets', 'matrices', 'signal-processing', 'random-walk', 'convolution']"
2198349,Second order non linear recurrence relation,"$$  G_n= G_{n-1}+ (\frac{3}{4})^n G_{n-2}, \quad with \quad  G_0=1,G_1=1 $$ I am trying to find the limit $ \lim\limits_{n \rightarrow +\infty} G_n$ which converges to $ 5.457177946$. Or to find an upper bound of $g_n$ that still converges to a constant. Fibonacci sequence does not converges to a constant although it is an upper bound. I do not need an exact solution, I just a tip or a method name that I could use. I tried to find the general form of the coefficients, but it seems hard to find.","['recurrence-relations', 'fibonacci-numbers', 'limits']"
2198358,How to know when to put calculator in radian or degree mode?,"For a take home test that I have, I have some questions that say Find the exact function value, if it exists. $\sin\left(60^\circ\right)$ $\tan\left(-45^\circ\right)$ $\cos (5\pi/2)$ $\sec (3\pi)$ The second part says Find the function values. Round to four decimals places.¨: $\cos \left(111.4^\circ\right)$ $\sin \left(-18^\circ\right)$ $\sec (9π/10)$ $\tan (42.5)$ How do I know when my calculator should be in radian or degree mode? Hopefully this makes sense...",['trigonometry']
2198360,Solving a homogenous differential equation with two complex eigenvalues,"A physical scenario in which a spring is hanging with a weight of mass $m$ on it yelds the following differential equation for the position $z(t)$ : $$mz'' = mg - f(z - z_0)$$ In order to solve for $z$ we first need to solve the homogenous equation: $$mz'' + fz = 0$$ Assume $z(t) = e^{\lambda t}$ : $$\lambda^2 m e^{\lambda t} + fe^{\lambda t} = 0$$ $$\lambda_{1,2} = \mp i\sqrt{\frac{f}{m}}$$ Having two eigenvalues, the general solution of the homogenous differential equation is a linear combination of the two: $$z_{\rm hom.}(t) = c_1e^{-i\sqrt{\frac{f}{m}}t} + c_2e^{i\sqrt{\frac{f}{m}}t}$$ We're in the context of physics and this is an oscillation, so we want to transform this result using trigonometric functions to make it more explicit. According to the solution supplied to me this is how it goes: \begin{align} z_{\rm hom.}(t) &= c_1e^{i\sqrt{\frac{f}{m}}t} + c_2e^{-i\sqrt{\frac{f}{m}}t} \\
&= c_1\left(\cos\left(\sqrt{\frac{f}{m}}t\right) + i\sin\left(\sqrt{\frac{f}{m}}t\right)\right) + c_2\left(\cos\left(\sqrt{\frac{f}{m}}t\right) - i\sin\left(\sqrt{\frac{f}{m}}t\right)\right) \\
&= (c_1+c_2)\cos\left(\sqrt{\frac{f}{m}}t\right) + (c_1-c_2)i\sin\left(\sqrt{\frac{f}{m}}t\right) \end{align} And here it gets funny: let $c_1+c_2 = A\cos(\phi)$ and $(c_1-c_2)i = A\sin(\phi)$ : \begin{align} z_{\rm hom.}(t) &= A\cos(\phi)\cos\left(\sqrt{\frac{f}{m}}t\right) + A\sin(\phi)\sin\left(\sqrt{\frac{f}{m}}t\right) \\ &= A\cos\left(\sqrt{\frac{f}{m}}t - \phi\right) \end{align} So, my question is: why can we say that $c_1+c_2 = A\cos(\phi)$ and $(c_1-c_2)i = A\sin(\phi)$ , with the same $A$ and $\phi$ ? It is awfully convenient, but how come $c_1$ and $c_2$ are related just this way? I'm guessing it has to do with the fact that the two eigenvalues $\lambda_{1,2}$ are complex conjugates, but exactly how escapes me. Any help would be appreciated!","['eigenvalues-eigenvectors', 'ordinary-differential-equations', 'complex-numbers']"
2198407,Evaluating $\int \frac{x^2-1}{x\sqrt{x^2+ax+1}\sqrt{x^2+bx+1}} dx$,The question is to evaluate $$\int \frac{x^2-1}{x\sqrt{x^2+ax+1}\sqrt{x^2+bx+1}} dx$$ I tried to rewrite the integral as $$\frac{ab}{b-a}\int \frac{1/a(x^2+ax+1)-1/b(x^2+bx+1)}{x\sqrt{x^2+ax+1}\sqrt{x^2+bx+1}} dx-2\int \frac{1}{x\sqrt{x^2+ax+1}\sqrt{x^2+bx+1}} dx$$ For the second integral I rewrite it as $$\int \frac{1}{x^3\sqrt{\frac1{x^2}+\frac{a}{x}+1}\sqrt{\frac1{x^2}+\frac{b}{x}+1}} dx$$ Now I used the substitution $x\to 1/x$ to yield $$-\int \frac{1}{x\sqrt{x^2+ax+1}\sqrt{x^2+bx+1}} dx$$ which makes the second integral to vanish.However i could not proceed with the first integral.Any ideas.Thanks.,"['indefinite-integrals', 'integration', 'calculus']"
2198499,Reverse-engineering the number of cases used in an experiment I,"Sometimes a published article will report experimental results in terms of percentages, but not state how many subjects or cases they used. I have seen ways to estimate these numbers based on common divisors etc., in the reported percentages, but I cannot find any such algorithm right now. Anyone know what I am talking about? For example, I'm reading a paper where all the accuracy results (correct / $N$) are whole numbers or end in either .6667 or .3333 . Clearly the number of cases is a multiple of 3, but what is the total? The values include 34 , 84 , 60.6667 , and 69.3333 . Based also on other clues, it seems that $N = 150$ would account for these numbers. But what is the general algorithm? (PS. I am not asking this on statistics.so because as I remember it is simple combinatorics.)","['combinatorics', 'statistics']"
2198513,Area swept by a moving line,"Consider a line segment on an $\Bbb R^2$ plane with one end (call it $p_1$) fixed along x-axis and another end (call it $p_2$) fixed along y-axis. The point $p_1$ starts at $(0,0)$ and the point $p_2$ starts at $(0,1)$. I allow the line segment to move with one of the following constraints: $1$. The point $p_1$ moves to the right with the constraint that the length of the line segment is fixed. The line segment stops moving when $p_1$ reaches $(1,0)$. $2$. The point $p_1$ moves to the right and the point $p_2$ moves downward with the constraint that the distances travelled by each of the points are equal at any moment, i.e. when $p_1$ moves by $(t,0)$, $p_2$ shall move by $(0,-t)$. The line segment stops moving when $p_1$ reaches $(1,0)$. In each of both cases, there is a region swept by the line segment. What are their areas respectively? It may look like a simple integration problem, but I have absolutely no idea how to find the function for the curve above the region. Do I miss out something obvious, or is it really a non-trivial problem?",['geometry']
2198538,About a particular solution of the equation $y''-y=e^x$,"ODE:  $y''-y=e^x$. I found  that complemantary solution of the ode is
$y_c=c_1e^x+c_2e^{-x}$. No problem. But, I don' t understand why do we suppose that trial solution is $y_p=Axe^x$ instead of $y_p=Ae^x$ ? What is the key point for selection of a particular solution of an ODE?",['ordinary-differential-equations']
2198563,Do pseudo-topological spaces generate unique topologies?,"Suppose you have two pseudo-topological spaces $(X,p_1)$ and $(X,p_2)$ where $p_1$ and $p_2$ are relations between the set of ultrafilters on $X$ and the points in $X$. We can define a topological space using the relation $p_1$ or $p_2$ by saying that $U\subseteq X$ is open if $\forall x\in U $ whenever an ultrafilter $F\rightarrow x$ (i.e. the relation contains $(F,x)$ pair) we have $U\in F$. If $p_1 \neq p_2$ then are the generated topologies different? Clearly if the pseudo-topological space is topological -  that is ultrafilters converge in the pseudotopological space iff they converge in the topological space - then the generated topologies are unique. But not every pseudo-topological space is topological and I can't seem to show  if pseudo-topologies always generate unique topologies. Is it true?","['general-topology', 'convergence-divergence', 'filters']"
2198574,"Order of a permutation, how to calculate","I know this is a basic question however I am slightly confused what to do if the permutation contains the same element twice in cycle notation. For example: the permutation $(1  2  3)(2  4  1)$, how would I calculate the order when $2$ maps to $3$ and $4$? Is it just the same? Does $p=3$","['permutations', 'abstract-algebra', 'combinatorics']"
2198639,This algorithm will find a basis for the span of some vectors. How/why does it work?,"Say I want to find a basis for $span((1,2,5),(2,4,10),(-3,-5,-13),(2,1,4),(-4,-6,-16))$. Google tells me that to get the answer, I'm supposed to write down the vectors as columns of a matrix: $$
        \begin{pmatrix}
        1 &  2 &  -3 & 2 & -4 \\
        2 &  4 &  -5 & 1 & -6 \\
        5 & 10 & -13 & 4 & -16 \\
        \end{pmatrix}
$$ ... then bring said matrix to row echelon form... $$
        \begin{pmatrix}
        1 &  2 & 0 & -7 & 2 \\
        0 &  0 & 1 & -3 & 2 \\
        0 &  0 & 0 &  0 & 0 \\
        \end{pmatrix}
$$ ... then look at the pivots; in this case the first and third rows contain pivots, therefore the first and third columns of the original matrix are linearly independent while the others are linearly dependent, and therefore those two vectors are a basis of the span. Okay, that's simple enough to remember and use in the exam but it still feels like magic to me. How does this work? Why do the pivots show which vectors are linearly independent?",['linear-algebra']
2198645,"Prove that if $a+b =1$, then $\forall n \in \mathbb{N}, a^{(2b)^{n}} + b^{(2a)^{n}} \leq 1$.","Inspired by this question . Note that $a,b \in [0,1]$. In my attempts to crack the link above, I decided to try and generalize and use an inductive method. Having plugged this into Mathematica for $n = 0,1,...,9,10$, I'm fairly confident that this claim is true. I've sunk about two weeks into this and gotten nowhere so I really want to see a proof for this. It's becoming sort of an internal demon of mine.","['inequality', 'calculus']"
2198661,Integer upper bound to a subset of real numbers?,"Exploring the properties of real numbers from "" Mathematical Thinking "" by John P. D'Angelo, I am asked to prove that For every positive real number $r$ there exists an integer $k$ such
  that $5 \lt |k|r$ I would say that it is true by the Completeness Axiom, I think that this means ""There exists an integer $k$ that is an upper bound to the set of real numbers of the form $\frac 5r$ where $r$ is a positive real number, which I would express as: $$(\exists\,k \in \Bbb Z)\,(\forall \,r\in \Bbb R^+) \,:\, k=\,\sup \bigg\lbrace \frac 5r \bigg |\; r \in \Bbb R^+\bigg \rbrace$$ I'm not sure whether my reasoning is correct or how I would go about proving it though.","['predicate-logic', 'real-numbers', 'integers', 'elementary-set-theory']"
2198744,Compact operators satisfying a certain relation must be finite-rank,"Let $H$ be an infinite-dimensional Hilbert space, equipped with a given Hilbert basis $(e_i)_{i \in \mathbb{N}}$. Consider the following introductory problem : can we find a compact operator $A$ in $H$ that satisfies the relation $$ \sum \limits_{k=0}^n c_kA^k=0$$ for some given $(c_k)_k$, $c_k \in \mathbb{R}^{n+1}$ for all $k=0,...,n$ ? Two cases arise : $c_0 \neq 0$ : Suppose that $A$ is a compact operator satisfying the given relation. We can rewrite it as 
$$c_nA^n+...+c_1A=-c_0Id$$
Factoring by $A$ and using the fact that $c_0 \neq 0$, we get that $$ \underbrace{A}_\text{compact} \circ(\underbrace{\frac{-c_n}{c_0}A^{n-1}+...+\frac{c_1}{c_0}Id}_\text{bounded})=Id$$ Set $B=\frac{-c_n}{c_0}A^{n-1}+...+\frac{c_1}{c_0}Id$. The composition $A \circ B$ will compact, because $A$ is compact and $B$ is a bounded operator. Therefore the $Id$ operator is compact, which is absurd because $H$ is infinite-dimensional. Therefore such an A cannot exist . $c_0=0$ : In this case we can find a compact operator with relative ease. Consider 
$$ V= vect\left\{e_n : n \in \left\{0,...,N\right\}\right\}$$ where the $(e_n)$ are elements of the basis of $H$. It is finite-dimensional and thus closed, so let $A$ be the well-defined projection operator on $V$. We then have that 
$$ A \circ A = A \iff A^2-A=0$$
and can thus create a relation of the given form.
Since $dim(V) < +\infty$, $A$ is finite-rank, and thus compact. Now consider again the case where $c_0=0$. My question is the following : If $A$ is a compact operator satisfying this type of relation for given $(c_k)_k$, then must $A$ be finite-rank ? I suspect that the answer is yes (maybe an analogy can be made to the case of matrices that have $0$ as an eigenvalue), but don't really have a good idea of where to start. Decomposing a finite-rank operator in $(e_i)$ might shed some light on this but appart from that I am not sure of how to proceed.","['functional-analysis', 'compact-operators', 'spectral-theory', 'operator-theory']"
