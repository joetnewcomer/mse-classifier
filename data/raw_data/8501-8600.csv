question_id,title,body,tags
64343,$f:\mathbb{C}\rightarrow\mathbb{C}$ entire function and $f(z)=u(x)+iv(y)$ then $f$ is a polynomial,"I was going through my introduction to complex analysis homework, when I came across this exercise: If $f:\mathbb{C} \rightarrow \mathbb{C}$ is an entire function of the form $f(z)=u(x)+iv(y)$, prove that $f$ is a polynomial. I've got completely stuck on this one. I think it might be something to do with $f$ being analytical, but I'm not so sure, because I was sick and couldn't watch the class. ): Any hints are appreciated, thanks.",['complex-analysis']
64350,What is the difference between the rowspace and the columnspace in linear algebra?,"The question is essentially all in the title, What is the difference between the rowspace and the columnspace? Additionally, do they have the same solution space?","['vector-spaces', 'matrices', 'linear-algebra']"
64353,twice differentiable function (question from exam),"$f$ is twice differentiable, $f(0)=f(1)=0$ and $f''$ is continuous. Prove that there exists $c\in[0,1]$ such that $$\int_0^1f(x)dx=-\frac1{12}f''(c).$$ I haven't progressed much on this problem. A lot of ideas came up to my mind but none seems to work. Obviously, this has something to do with mean value theorem. In fact, we only need to show that there exist $a,b\in[0,1]$ such that $\int_0^1f(x)dx=\frac{f'(a)-f'(b)}{a-b}$. By mean value theorem, there exists $c\in[a,b]$ such that $f''(c)=\frac{f'(a)-f'(b)}{a-b}$. But this does not seem to be the correct path, because we haven't used that $f''$ is continuous. This leads to the second idea to show that $f''(x)$ attains some values below and above $\int_0^1f(x)dx$. So I think we need to work out some inequalities, which I don't have any idea. Anyway, I just started learning calculus for a few weeks. This question is from the previous exam paper, it's the only question I can't solve. Any help is appreciated, thanks.",['analysis']
64362,Not understanding this division problem,"$\frac{52}{x}=13$ It says to next step $\frac{52}{13}=x$ Ok, I can do future problems like this, but is there a rule that explains this? What just happened to both sides of the equal sign?",['algebra-precalculus']
64365,Homework: Stuck on last step of simplifying,"This is for homework, and I could really use help on the last step.
This is the original equation. I'm working on simplifying it. My math book is for Intermediate Algebra.
$$
 \dfrac{ 5x }{ x^2-25 } - \dfrac{5}{x+5}
$$ I created the common denominator by multiplying both sides by their missing factor. $$
 \dfrac{ 5x^2+25x}{ (x^2-25)(x+5) } - \dfrac{5x^2-125}{(x^2-25)(x+5)}
$$ I combined the terms, which gave me: $$
 \dfrac{ 25x+125 }{ (x^2-25)(x+5) }
$$ I believe the answer is below, based on wolfram alpha. I'm not sure how to simplify from here, to get the answer. $$
 \dfrac{25}{x^2-25}
$$",['algebra-precalculus']
64366,Measurability of $\xi$ in the mean value theorem,"Suppose $f\in C^1(\mathbb{R})$, by mean value theorem, for any $x\in (0,\infty)$, there exists $\xi(x)\in (0,x)$ such that $$\frac{f(x)-f(0)}{x}=f'(\xi(x)).$$ My question is: Question : Can $\xi(x)$ always be chosen to be a measurable function in $x$?",['real-analysis']
64371,Showing group with $p^2$ elements is Abelian,"I have a group $G$ with $p^2$ elements, where $p$ is a prime number. Some (potentially) useful preliminary information I have is that there are exactly $p+1$ subgroups with $p$ elements, and with that I was able to show $G$ has a normal subgroup $N$ with $p$ elements. My problem is showing that $G$ is abelian, and I would be glad if someone could show me how. I had two potential approaches in mind and I would prefer if one of these were used (especially the second one). First: The center $Z(G)$ is a normal subgroup of $G$ so by Lagrange's theorem, if $Z(G)$ has anything other than the identity, it's size is either $p$ or $p^2$ . If $p^2$ then $Z(G)=G$ and we are done. If $Z(G)=p$ then the quotient group of $G$ factored out by $Z(G)$ has $p$ elements, so it is cyclic and I can prove from there that this implies $G$ is abelian. So can we show there's something other than the identity in the center of $G$ ? Second: I list out the elements of some other subgroup $H$ with $p$ elements such that the intersection of $H$ and $N$ is only the identity (if any more, due to prime order the intersected elements would generate the entire subgroups). Let $N$ be generated by $a$ and $H$ be generated by $b$ . We can show $NK= G$ , i.e every element in G can be written like $a^k b^l $ . So for this method, we just need to show $ab=ba$ (these are not general elements in the set, but the generators of $N$ and $H$ ). Do any of these methods seem viable? I understand one can give very strong theorems using Sylow theorems and related facts, but I am looking for an elementary solution (no Sylow theorems, facts about p-groups, centrailzers) but definitions of centres and normalizers is fine.","['p-groups', 'finite-groups', 'group-theory', 'abelian-groups']"
64377,"Birthday attack/problem, calculate exact numbers? [duplicate]","This question already has answers here : Closed 12 years ago . Possible Duplicate: Birthday-coverage problem An example of what I wish to do is the following: https://stackoverflow.com/questions/4681913/substr-md5-collision/4785456#4785456 How would I calculate how many people would be required, as in the link above, to reach 50% or 0.001% or n % probability of collision exactly? I am able to calculate the likelyhood of a collision in say a hash, with $1-e^\frac{-n^2}{(2*10^6)}$ 10^6 being six numerical digits from zero to nine. However, I would have to guess a lot of times before I got the exact number of people it would take to reach exactly 50%, which may be a fraction (i.e. 20.2 people) How would I be able to find this?","['statistics', 'birthday', 'probability']"
64378,Special Orthogonal Group and Cayley-Hamilton theorem,"One of the questions on my University's algebra qual had us prove that given an arbitrary $\mathbf{A}\in SO_{3}(\mathbb{R})$, there is some constant, $-1\leq\alpha\leq3$, such that $$\mathbf{A}^{3}-\alpha\mathbf{A}^{2}+\alpha\mathbf{A}-\mathbf{I}_{3}=0.$$ Appealing to the Cayley-Hamilton theorem, and the fact that $\det\mathbf{A}=1$, I was able to (through good old fashioned number crunching) show that $$\mathbf{A}^3-(\text{tr }\mathbf{A})\mathbf{A}^2+\beta\mathbf{A}-\mathbf{I}_{3}=0,$$ where $\beta=-a_{12}a_{21} + a_{11}a_{22} - a_{13}a_{31} - a_{23}a_{32} + a_{11}a_{33} + a_{22}a_{33}$. So naturally I assumed that the $\alpha$ they were looking for was $\alpha=\text{tr }\mathbf{A}$, and that (by the restrictions placed on $\mathbf{A}$ by its orthogonality) $\beta=\alpha$. I also suspected that since $\text{tr }\mathbf{I}_{3}=3$ and $\text{tr }\begin{bmatrix}
  1 & 0 & 0\\
  0 & -1 & 0\\
  0 & 0 & -1
\end{bmatrix}=-1$ (both of which are in $SO_{3}(\mathbb{R})$) then these might contribute to the proposed bounds on $\alpha$, however I was not able to formally show anything. Any help in proving the bounds on $\alpha$ or on showing that $\alpha=\beta$ (of which I'm pretty certain is indeed true, after trying a number of specific examples) is much appreciated.","['matrices', 'linear-algebra']"
64385,Prove $\det(\mathbf I+\mathbf A^T\mathbf A) = \det (\mathbf I+\mathbf A\mathbf A^T)$,"Given a matrix $\mathbf A\in \mathbb R^{m\times n}$ and an identity matrix $\mathbf I$ of appropriate dimensions, how do you prove $\det(\mathbf I+\mathbf A^T\mathbf A) = \det (\mathbf I+\mathbf A\mathbf A^T)$?",['linear-algebra']
64387,Is there any number greater than 8 of the form $2^{2k+1}$ which is the sum of a prime and a safe prime?,"Is there any number greater than 8 of the form $2^{2k+1}$ which is the sum of a prime and a safe prime ?  While answering @pedja's question about the existence of any such representations I was surprised to discover that $32$, $128$, $512$, and $2048$ cannot be represented in this way, and I've since found that the same is true for $8192$, $32768$, $131072$, $524288$, $2097152$, and $8388608$.  Is there any counterexample?  If not, how can it be proved?","['prime-numbers', 'number-theory']"
64398,Reference: Group Theory,"I want to read a book on group theory ""Endliche Gruppen I"" by Huppert, Blackburn etc. I do not know, whether it is translated in English. Can one suggest a way for this- ""Online Mathematics dictionary, German to English"", or whether book translated in English, or any other?","['reference-request', 'group-theory']"
64406,How can you show there are only 2 nonabelian groups of order 8?,"It's often said that there are only two nonabelian groups of order 8 up to isomorphism, one is the quaternion group, the other given by the relations $a^4=1$, $b^2=1$ and $bab^{-1}=a^3$. I've never understood why these are the only two. Is there a reference or proof walkthrough on how to show any nonabelian group of order 8 is isomorphic to one of these?","['group-theory', 'abstract-algebra']"
64420,Is there a faster way to calculate a few diagonal elements of the inverse of a huge symmetric positive definite matrix?,"I asked this on SO first , but decided to move the math part of my question here. Consider a $p \times p$ symmetric and positive definite matrix $\bf A$ (where $p=70000$ , i.e., $\bf A$ is roughly 40 GB using 8-byte double s). We want to calculate the first $3$ diagonal elements of the inverse matrix, $({\bf A}^{-1})_{11}$ , $({\bf A}^{-1})_{22}$ and $({\bf A}^{-1})_{33}$ . I have found this paper by James R. Bunch who seems to solve this exact problem without calculating the full inverse $\bf A^{-1}$ . If I understand it correctly he first calculates the Cholesky decomposition, i.e. the upper triangular matrix $\bf R$ which satisfies $\bf A=R^T R$ , which needs $\frac16p^2+\frac12p^2-\frac23p$ floating point operations (multiplications/divisions) using the LINPACK function SPOFA . He then proceeds to calculate individual diagonal elements of the inverse $({\bf A^{-1}})_{ii}$ using an expression which exploits the sparsity of ${\bf R}^T{\bf y}={\bf e}_j$ and which requires $\frac12(p-i)^2+\frac52(p-i)+2$ floating point operations. (I don't understand the full details of this, so I can't currently sum it up correctly). The paper is based on LINPACK; it isn't cited by anyone, so it seems nobody cared for the last 23 years? After reading this , I'm wondering whether this is still the best way of doing things, or whether a modern LAPACK-based approach could avoid the Cholesky decomposition? In short, is there a quicker way to calculate those diagonal elements of the inverse ?","['positive-definite', 'symmetric-matrices', 'matrices', 'inverse', 'numerical-linear-algebra']"
64422,On Partial Derivative,"I am having issues with this mathematical concept, but i couldn't point out where, I've tried rereading thomas and stewart for more than 3 times already but still had no clue. I'll try to explain my thought process and will anyone of you please point out my mistakes? given a function $f(x,y)=|xy|^{0.5}$, how do we determine if the partial derivative is defined at a point, lets say (0,0)? I've figured out there are 3 methods. method 1: $$\frac{d}{dx} |xy|^{0.5} =\frac{(x^2*y^2)^{1/4}}{2x}$$ then at $(0,0)$, it is undefined due to division-by-zero, therefore the P.D is undefined. method2: $f(x,0)=0$ $$\frac{df}{dx}(0,0) = \frac{d}{dx}f(x,0)\vert_{y=0} = 0$$
then at $(0,0)$, $f_x(0,0) = 0$. (P.D is defined) method 3: $$\lim_{h\to 0}\frac{f(0+h,0)-f(0,0)}{h} = 0$$ therefore, $f_x(0,0) = 0$ (P.D is defined) So what the differences between these method?? Did i apply those methods correctly? If so, why do i have contradicting solutions? Thanks a lot for the help.","['multivariable-calculus', 'calculus']"
64423,Proof that $\dfrac{n(\ln(n)-2\ln(2))}{2\ln(n)(\ln(n)-\ln(2))^2} > 1$ for all $n\ge20$,How to prove this inequality: $\dfrac{n(\ln(n)-2\ln(2))}{2\ln(n)(\ln(n)-\ln(2))^2} > 1$ for all $n\ge20$ I tried to apply this approach but I get a large first differentiate $u'(x)$ whose sign is not easy to determine,"['inequality', 'algebra-precalculus']"
64426,Question regarding counting poker dice,"Problem Poker dice is played by simultaneously rolling 5 dice. How many ways can we form ""1 pair"", ""2 pairs""? For one pair, I got the answer right away. First I consider there are 5 spots for 5 dice. Then I pick 2 places out of 5, which means there are 3 places left, so we have to choose 3 out of 3 which is 1 way. Hence, I have: $${{5}\choose{2}} \cdot 6 {{3}\choose{3}} \cdot 5 \cdot 4 \cdot 3 = 3600.$$ However, I couldn't figure out why I got two pairs wrong.
First, I pick 2 places for the first pair, then its rank. Next, 2 places for the second pair, and its rank. Since there is only 1 place left, I pick the rank for the last dice. $${{5}\choose{2}} \cdot 6 {{3}\choose{2}} \cdot 5 \cdot 4 \cdot 3 = 3600.$$ But the correct answer is 1800, which means I need to divide by a factor of 2. I guess that might be the order of two pairs can be switched, but I wonder is there a better way to count it? I'm so confused! Any idea?","['probability', 'combinatorics']"
64430,"Find extra arbitrary two points for a plane, given the normal and a point that lies on the plane","For a plane, I have the normal $n$, and also a point $P$ that lies on the plane. Now, how am I going to find extra arbitrary two points ($P_1$ and $P_2$) for the plane so that these three points $P$, $P_1$ and $P_2$ completely define the plane? The solution here suggests that one assumes a certain $x$ and $y$ to substitute into the plane equation and find the remaining  $z$. But this method is only suitable for hand calculation; it breaks down for plane $z=0$. As such, it is not suitable for computer implementation. I would need an algorithm that is robust and can handle all the cases, any idea how to construct it? There is a similar question here , and the answer suggests me to use  Gram-Schmidt, but I don't see how it can be applied in my case here.","['analytic-geometry', 'geometry', 'linear-algebra']"
64432,What is so special about $\alpha=-1$ in the integral of $x^\alpha$?,"Of course, it is easy to see, that the integral (or the
antiderivative) of $f(x) = 1/x$ is $\log(|x|)$ and of course for
$\alpha\neq - 1$ the antiderivative of $f(x) = x^\alpha$ is
$x^{\alpha+1}/(\alpha+1)$. I was wondering if there is an intuitive (probably geometric)
explanation why the case $\alpha=-1$ is so different and why the
logarithm appears? Some answers which I thought of but which are not convincing: Taking the limit $\alpha=-1$ either from above or below lead to diverging functions. Some speciality of the case $\alpha=-1$ are that both asymptotes are non-integrable. However, the antidrivative is a local thing, and hence, shouldn't care about the behavior at infinity.","['calculus', 'integration']"
64440,All possible permutations on a Rubik cube ($3\times3\times 3$) can be reached from the initial state?,"If I were to represent a state in the Rubik cube as a permutation of the colors on the 9 tiles per side on all sides of the cube, could I reach all possible states (i.e. colorings) by the permutations allowed by the cube alone?
In other words, is there a legal coloring such that it's unreachable from the initial state (every side of the cube has only its own distinct color) ? many thanks!","['permutations', 'recreational-mathematics', 'rubiks-cube', 'combinatorics']"
64448,A value has 'reduced by factor of 3'. Does this make mathematical sense?,"I'm just reading some statistics. Last year there were 3000 observations, this year there are only 1000.  This is described as showing a ""fall by a factor of 3"". This phrase doesn't ring true.  If a factor of 3 is a 1/3, then a fall by a third would be down to 2000.  So the phrase is meant to represent a fall to a third. Am I right in thinking the phrase 'by a factor of' can only refer to an increase?",['statistics']
64449,A Boolean function with total influence 1 must be a dictatorship,"Let $f:\{-1,1\}^n\to\{-1,1\}$ be a boolean function.
Define the influence of the $i$'th coordinate of $f$ as follows:
$$\operatorname{Inf}_i(f)=\Pr_{x}[f(x)\neq f(\hat x_i)]$$
where $x$ is uniformly picked from $\{-1,1\}^n$, and $\hat x_i$ is $x$ with its $i$'th coordinate flipped (e.g., say $x=(1,1,1,1,-1)$, then $\hat x_3=(1,1,-1,1,-1)$). How do I show that if $f$ is balanced ($\mathbb{E}_x[f(x)]=0$ ) and holds $\displaystyle\sum_{i=1}^n{Inf}_i(f)=1$ then $f$ must be a dictatorship function ($dict_i(x_1,\ldots,x_i,\ldots,x_n)=x_i$) up to a sign, i.e., $\pm dict_i$ ?","['boolean-algebra', 'extremal-combinatorics', 'probability', 'combinatorics']"
64450,Difficult Integral: $\int\frac{x^n}{\sqrt{1+x^2}}dx$,How to calculate this difficult integral: $\int\frac{x^2}{\sqrt{1+x^2}}dx$? The answer is $\frac{x}{2}\sqrt{x^2\pm{a^2}}\mp\frac{a^2}{2}\log(x+\sqrt{x^2\pm{a^2}})$. And how about $\int\frac{x^3}{\sqrt{1+x^2}}dx$?,"['calculus', 'integration']"
64461,Integer matrix with particular Jordan's form,For teaching purposes I would like to find integer matrices with a particular Jordan's form. Is there some kind of technique to find nice examples? For example for $$\begin{pmatrix}1&1&0\\0&1&0\\0&0&1\end{pmatrix}.$$,"['matrices', 'linear-algebra']"
64477,Evaluate the integral $\int_0^\infty \frac{t}{e^t-1}\mathrm dt$,An integral related to the zeta function at the point $2$ is given by $$\zeta(2) = \int\nolimits_0^\infty \dfrac{t}{e^t - 1}\mathrm dt$$ How to calculate this integral?,"['calculus', 'integration']"
64489,Prove ranks are uniformly distributed,"We have n IID random variables $X_1, X_2, \ldots, X_n$.  Let $R_i$ be $X_i$'s rank in the set $\{X_1, X_2, \ldots, X_3 \}$ when we order from large to small.  How to prove $R_i, \forall i \in \{1, 2, \ldots, n\}$, is uniformly distributed on $\{1, 2, \ldots, n\}$? My first guess is that, for any position $j$ in ordered sequence of $X$s, as $X_1, X_2, \ldots, X_n$ are equally likely to be the $j$th largest, $$\Pr \{ R_i = j \} = \frac 1 n.$$ So $R_i$ is uniformly distributed on $\{1, 2, \ldots, n\}$. Another way to think about it, is to count how many possible cases are there when $R_i = j$.  As $X_i$'s position in ordered sequence is fixed at $j$, then we can just permute the rest of $X$s to get all possible ordered sequence.  Since there are $n-1$ variables left, there are $(n-1)!$ situations.  As for any $R_i = j, 1 \le j \le n$, there are always $(n-1)!$ possible ordered sequences, we can say $R_i$ is uniformly distributed on $\{1, 2, \ldots, n\}$. Are these 2 proof rigorous? Edit: As cardinal pointed out, an additional condition is needed for the proof, and a sufficient such condition is that $X_i$ to be a continuous random variable.",['probability']
64492,Automorphisms inducing automorphisms of quotient groups,"Let $G$ be a group, with $N$ characteristic in $G$ . As $N$ is characteristic, every automorphism of $G$ induces an automorphism of $G/N$ . Thus, $\operatorname{Aut}(G)\rightarrow \operatorname{Aut}(G/N)$ . I was therefore wondering, Under what conditions is the induced homomorphism $\operatorname{Aut}(G)\rightarrow \operatorname{Aut}(G/N)$ a monomorphism? an epimorphism? an isomorphism? I believe it should work for (semi-?)direct products $N\times H$ where $\operatorname{Aut}(N)$ is trivial and $N\not\cong H$ (for example, $C_2\times C_3$ , $N=C_2$ ). But I can't prove even that!",['group-theory']
64498,Probability that two random numbers are coprime is $\frac{6}{\pi^2}$,"This is a really natural question for which I know a stunning solution. So I admit I have a solution, however I would like to see if anybody will come up with something different. The question is What is the probability that two numbers randomly chosen are coprime? More formally, calculate the limit as $n\to\infty$ of the probability that two randomly chosen numbers, both less than $n$ are coprime.","['riemann-zeta', 'elementary-number-theory', 'probability', 'prime-numbers', 'integers']"
64523,Proving an inequality with Cauchy-Schwarz,"In the ""User's guide to viscosity solutions"" by Crandall, Ishii and Lions ( link ), they make the following claim (inequality (A.4) p. 58) : Given $x$ , $\xi$ $\in \mathbb{R}^n$ , $A \in \cal{S}(n)$ (space of symmetric $n \times n$ matrices) , for all $\varepsilon >0$ , the Cauchy-Schwarz inequality yields $$\langle Ax,x \rangle \leq \langle (A+\varepsilon A^2) \xi,\xi \rangle+\left(\frac{1}{\varepsilon} + \|A\|\right)|x-\xi|^2,$$ where I guess $\|A\|$ is the spectral radius of $A$ . I have tried without success to prove this inequality and would appreciate some help.","['cauchy-schwarz-inequality', 'inequality', 'quadratic-forms', 'linear-algebra', 'hilbert-spaces']"
64551,Summing the prime power counting function up to equal some value $n$,"I want to find $c_k$ for $n = 1 + c_1 \Pi(n) + c_2 \Pi(\frac{n}{2})+ c_3 \Pi(\frac{n}{3})+ c_4 \Pi(\frac{n}{4})+ c_5 \Pi(\frac{n}{5})+...$, assuming there are such coefficients, where $\Pi(n) = \pi(n) + \frac{1}{2}\pi(n^\frac{1}{2})+ \frac{1}{3}\pi(n^\frac{1}{3})+ \frac{1}{4}\pi(n^\frac{1}{4})+...$ and $\pi(n)$ is the prime counting function. Are there known techniques for solving a problem like this? EDIT -
I was really asking this to figure out how tough of a question this is.  At least for anon, not very tough, it would seem. In case any of you are curious, one way to calculate these coefficients is like so: If $C_k$ are the Gregory Coefficients, the first few terms being $-1, \frac{1}{2}, \frac{1}{12}, \frac{1}{24}, \frac{19}{720}, \frac{3}{160},...$, and we have the strict divisor function such that $d_0'(j) = 1$ if $n = 1$, $0$ otherwise $d_1'(j) = 1$ if $n \neq 1$, $0$ otherwise $d_k'(n) = \sum\limits_{j | n} d_1'(j) d_{k-1}'(n/j )$ then $c_k = \sum\limits_{a=0} -1^a C_a d_a'(k)$ There's a straightforward reason why the Gregory coefficients show up, involving Linnik's identity $\sum\limits_{k=1} \frac{-1^{k+1}}{k} d_k'(n) = \frac{\Lambda(n)}{\log n}$and multiplicative inverses of series coefficients, but I won't go into that. Anyway, good job, anon.",['number-theory']
64566,"Riemann's $\zeta$ function and the uniform distribution on $[-1,0]$","It seems that the $n$th cumulant of the uniform distribution on the interval $[-1,0]$ is $B_n/n$, where $B_n$ is the $n$th Bernoulli number. And also $-\zeta(1-n) = B_n/n$, where $\zeta$ is Riemann's $\zeta$ function. Is there some reason why one should expect these to be the same, as opposed to proofs that convince you that they are?","['riemann-zeta', 'probability-theory', 'analytic-number-theory', 'bernoulli-numbers', 'complex-analysis']"
64569,Powers as a complete residue system modulo $p$?,"Question 1. With $0 < a < p$, $p$ prime and $\gcd(a,p-1)=1$, is it true that $0, 1, 2^a, ...,(p-1)^a$  is a complete residue system modulo $p$?  If not, will a similar statement hold? Question 2. I was told it works for $a = 3$, does anyone know a simple proof of it in this particular case?","['prime-numbers', 'elementary-number-theory', 'number-theory']"
64575,Prove that every element of a finite group has an order,"I was reading Nielsen and Chuang's ""Quantum Computation and Quantum Information"" and in the appendices was a group theory refresher. In there, I found this question: Exercise A2.1 Prove that for any element $g$ of a finite group, there always exists a positive integer $r$ such that $g^r=e$. That is, every element of such a group has an order. My first thought was to look at small groups and try an inductive argument. So, for the symmetric groups of small order e.g. $S_1, S_2, S_3$ the integer $r$ is less than or equal to the order of the group. I know this because the groups are small enough to calculate without using a general proof. For example, in $S_3$ there is an element that rearranges the identity $\langle ABC \rangle$ element by shifting one character to the left e.g. $s_1 = \langle BCA \rangle$. Multiplying this element by itself produces the terms $s_1^2 = \langle CAB \rangle$; and $s_1^3 = \langle ABC \rangle$ which is the identity element, so this element is equal to the order of the group, which is three. I have no idea if this relation holds for $S_4$ which means I am stuck well before I get to the general case. There's a second question I'd like to ask related to the first. Is the order or period of any given element always less than or equal to the order of the group it belongs to?",['group-theory']
64591,Prove that $(2-x)^nx^{n-1}$ decreases with $n$ for $0 <x<1$?,"How can I show that:
$$(2-x)^nx^{n-1}$$ is decreasing with $n$ when $0<x<1$?  I think this is generally true, but specifically I am concerned with $n$ as an integer $\geq 2$ and showing that the maximum of the function is when $n=2$ (its minimum) for all $x$.
When I take the derivative with respect to $n$, I just get  $$(2 - x)^n x^n \log(2 - x) + (2 - x)^n x^n \log x ,$$ but I don't know how to show that that is negative either. 
I guess it comes down to showing that the absolute value of $\log(2-x)$ is less than the absolute value of $\log(x)$... but I don't know how to do that with logs, or if that's necessarily the right approach.","['inequality', 'calculus', 'algebra-precalculus', 'optimization']"
64607,"Probability with Intersections, Unions, and Complements","I just want to make sure I'm doing this correctly. Here is the problem: Let $A$ and $B$ be sets such that $P(A \cap B)=\frac{1}{4}, P(\tilde{A})=\frac{1}{3},$ and $P(B)=\frac{1}{2}$. What is $P(A \cup B)$? My answer is $\frac{11}{12}$ and here is my reasoning: $P(\tilde{A})=\frac{1}{3}$, therefore, $P(A)=\frac{2}{3}$. $P(A \cup B)=P(A)+P(B)-P(A \cap B)=\frac{2}{3} + \frac{1}{2} - \frac{1}{4}=\frac{11}{12}$ Question: Does this make sense or I am just making stuff up?","['discrete-mathematics', 'probability']"
64610,Probability with my Facebook friends,"If I have 5000 Facebook friends, what is the probability that a day with no one having that birthday exists? I assume there are 365 days in a year, and a uniform distribution of the dates of birth. I guess that it's easier to calculate the opposite, and to subtract it from one.","['probability', 'combinatorics']"
64611,Showing the countable direct product of $\mathbb{Z}$ is not projective,"I am trying to prove that the direct product $M = \mathbb{Z} \times \mathbb{Z}\times \cdots$ is not a projective $\mathbb Z$-module and I am stuck near the end of the proof because of the authors use of the word infinitely divisible. I will list the sketch of the proof and try to explain where I am stuck. We proceed by contradiction so suppose $M$ is contained in some free module $F$ with basis $B$.  Set $N = \mathbb{Z} \oplus \mathbb{Z} \oplus\cdots$ and observe that $N$ is a submodule of $M$. Since $N \subset F$ there exists $B' \subset B$ such that $B'$ is a basis for $N$ and consider the free module $F' \subset F$ determined by $B'$. Notice $F'+M \subset F$ gives $M/(M \cap F') \cong (F'+M)/F' \subset F/F'$ so we have $M/(M \cap F') $ The next step in the proof requires to consider sequences of signs so let $s = (s_1, s_2, \ldots)$ be a sequence of plus and minus signs and consider an element $m_s := (s_1 , 2 s_2, \ldots , k! s_k, \ldots) \in M$ The next point in the proof is what I don't understand, the notes I am using say $m_s +(M \cap F')$ is infinitely divisible in $F/F'$ and use this to show $M$ cannot be contained in any free $Z$ module.  My question is How do we show $m_s +(M \cap F')$ is infinitely divisible in $F/F'$ and how do translate the word infinitely divisible into definitions from Hungerford or Dummite and Foote?","['modules', 'linear-algebra', 'abstract-algebra']"
64625,Distance and time,"So basically I have a said distance.  There is one object moving at said speed from one side to the other(lets call it A to B), and another object moving at a different speed(faster speed) from the other side (B to A). How would I find the time it would take for the second object to reach the first?","['algebra-precalculus', 'physics']"
64627,Intuitive understanding a theorem in analysis,"Is there a way to intuitively understand/visualize the following theorem in analysis? Let $(f_n)$ be a sequence of real functions differentiable in a finite/infinite open interval $(a,b)$. Suppose that $(f_n(x))$ converges for at least one $x\in(a,b)$ and that $(f_n')$ converges uniformly on every finite closed subinterval of $(a,b)$. Then (i) $(f_n)$ converges uniformly on every finite closed subinterval of $(a,b)$ (ii)$f=\lim_{n\to\infty}f_n$ is differentiable in $(a,b)$ and $\forall x\in(a,b)$, $f'(x)=\lim_{n\to\infty}f_n'(x)$ Thanks.","['visualization', 'real-analysis', 'analysis']"
64629,Linear algebra question involving principal submatrices,"Let $A$ $\in$ $M_n (C)$. For each $1 \leq i \leq n$, let $A_i$ be the $(n-1)\times(n-1)$ principal submatrix of $A$ resulting from deleting the $i^\text{th}$ row and $i^\text{th}$ column. Prove that for $1 \leq k \leq n-1$,
$\sum\limits_{i=1}^n E_{k}(A_{i}) = (n-k)E_{k}(A)$. EDIT: The notation is consistent with Horn and Johnson's Matrix Analysis book. On page 40, it says that there are $\binom{n}{k}$ different k-by-k principal minors of the matrix $A=[a_{ij}]$, and the sum of these is denoted by $E_{k}(A)$ I have been trying different formulas involving the trace and the determinant, but I think I am missing some insight into this question. Any help will be appreciated, thanks.","['matrices', 'linear-algebra']"
64631,matrix multiplication by columns,"Yo, I need some help with understanding matrix multiplication by columns. Consider the two matrices: $\left( \begin{array}{ccc}
1 & 2 & 3 \\
6 & 5 & 4 \\
7 & 8 & 9 \end{array} \right)  \left( \begin{array}{ccc}
3 & 2 & 1 \\
4 & 5 & 6 \\
9 & 8 & 7 \end{array} \right)  $ So I'm familiar with the standard algorithm where element $AB_{ij}$ is found by multiplying the $i^{th}$ row of A with the $j^{th}$ column of B. Apparently there is another way to multiply matrices where you work with whole columns of A to get the product AB. Does anyone know how to do that? If so, could you please provide a general algorithm? I've never heard of it and I can't find it anywhere.",['matrices']
64647,Why this determinant is conformally invariant?,"While I was reading a paper about random analytic function I found a statement that I was not able to prove and after try brute force and search for some references I decided to ask for a help here. The statement is the following: Denote by $\mathbb{D}$ the unit dic on the complex plane, and consider the function $p:\mathbb{D}^n\to\mathbb{C}$ given by $$
p(z_1,\dots,z_n)\, =\, 4^{-n}\, \det\left(\frac{(1-|z_i|^2)(1-|z_j|^2)}{|1-z_i\overline{z}_j|^2}\right)_{i,j=1}^{n}\,
$$ 
then for any fixed $u\in\mathbb{D}$ the function $p$ is invariant for the Möbius transformation $$
\phi(u,z)=\frac{u+z}{1+\overline{u}z},
$$
in the sense that $$
p(z_1,\dots,z_n)\, = p(\phi(u,z_1),\ldots,\phi(u,z_n)).
$$ I appreciate any reference or hint to prove this fact. Edition: The denominator was modified as point out for David and Anon.","['complex-analysis', 'determinant']"
64651,Expected Value of a Continuous Random Variable,"I've been reviewing my probability and statistics book and just got up to continuous distributions. The book defines the expected value of a continuous random variable as: $E[H(X)] = \int_{-\infty}^{\infty} H(x)f(x)~dx$ provided that $\int_{-\infty}^{\infty} |H(x)|f(x)~dx$ is finite. While I understand the integral to calculate the expected value, I'm failing to see why the 'provided' takes the absolute value of $H(X)$. Why isn't it enough to just define is as: $E[H(X)] = \int_{-\infty}^{\infty} H(x)f(x)~dx$ provided that it is finite.","['statistics', 'probability']"
64679,For how many functions $f$ is $f(x)^{2}=x^{2}$?,"How many functions $f$ are there that satisfy $f(x)^{2}=x^{2}$ for all $x$? My text (Spivak's Calculus ; chapter 7 problem 7) asks this question for continuous $f$, for which the answer is, of course 4:$$f(x)=x$$ $$f(x)=-x$$ $$f(x)=\lvert x \rvert$$ $$f(x)=-\lvert x \rvert,$$ and I want to make sure I'm correct that if $f$ does not have to be continuous, there are infinitely many: any piecwise combination of them (infinitely many of which are one of the above, and infinitely many of which are not).","['graphing-functions', 'functions', 'analysis']"
64680,A linear operator on a finite dimensional Hilbert space is continuous,"How do I show that a linear function from a Hilbert space $H$ to itself is continuous if $H$ is finite dimensional? Also, what would be an example of a linear function from a Hilbert space to itself which is not continuous?","['hilbert-spaces', 'functional-analysis']"
64682,Can you reduce an inequality by taking a derivative?,"If I have some equality $f(x) < g(x)$ that I want to prove to be true over some bounded interval for $x$, can I take the derivative wrt $x$ on both sides?  Then, if I can reduce that to the point where it's obviously true over the bounds in question of $x$, does that prove the original case?  I know the bounds on $x$ for $f'(x) < g'(x)$ are not the same as for $f(x) <g(x)$, but are they always less restrictive in the derivative case, allowing you to make implications for the non-derivative case?","['calculus', 'algebra-precalculus']"
64701,Normalizing a conditional probability to within range of a Sigmoid function,"Given the following scenario from another post of mine where we are building a matrix that expresses the probability of first order transitions from one character to another in an english text. We take a book, and count the number of times the letter 'e' occurs in that book -- say 15,000.  Then we count the number of times the next letter is 'f' -- say, 200.  With this in hand, we put $M(\text{'e'}, \text{'f'}) = 200/15000 = 1.33\%$. Say instead we want to normalize this conditional probability to a range between 0 - 1, but discluding the absolute values 0 or 1 (only getting infinitesimely close to each extreme). Is there an accepted way to use a sigmoid function for this sort of normalization of a probability? I don't know if this is a common practice, however, I think it would be useful in an AI application I am working on.","['statistics', 'matrices', 'linear-algebra', 'probability']"
64703,Negative Radicals,"I do not understand this question at all! Could someone please help out a person who is horrible at math? I'm desperate!
$\sqrt{−x^2}$ is defined only for
$x = 0$, but $\sqrt{−x}$ is defined for all non‐positive real numbers.
Explain why these expressions have these domains.",['algebra-precalculus']
64705,"If $E$ has measure zero, then does $E^2$ have measure zero?","Currently I'm just working through measure theory just to see if its something I would like to take. Unfortunately I am stuck on this problem from Carothers. If $m^*(E)=0$, then $m^*(E^2)=0$. Where $m^*$ denotes outer measure and
$$E^2=\{x^2:x\in E\}.$$ I toyed with the idea that $I_k < 1 \Rightarrow I^2_k < I_k$.  However I am at a loss as to how to set up a chain of inequalities (which is what I am assuming I need).",['measure-theory']
64712,How to multiply a matrix of block matrices?,"I came across a question on SE Math and was reading a proof on Sylvester's Determinant Theorem posted by anon. But I have a few doubts as I'm reading it. I will re-produce from the pdf file on the part that I don't understand so that it makes it easier for reference. In Theorem 9, it says if matrix $A$ and $D$ are invertible, then in the block matrix below,
$$
\begin{vmatrix}
A_{m \times m} & B_{m \times n}\\ 
C_{n \times m} & D_{n \times n}
\end{vmatrix}
=
\left | A \right |\left | D-CA^{-1}B \right | 
= \left | D \right |\left | A-BD^{-1}C \right |
$$ The proof given to the claim was:
$$\begin{align*}
\begin{bmatrix}
A_{m \times m} & B_{m \times n}\\ 
C_{n \times m} & D_{n \times n}
\end{bmatrix}
&=
\begin{bmatrix}
A_{m \times m} & 0_{m \times n}\\ 
C_{n \times m} & I_{n \times n}
\end{bmatrix}

\begin{bmatrix}
I_{m \times m} & A^{-1}B_{m \times n}\\ 
C_{n \times m} & D-CA^{-1}B_{n \times n}
\end{bmatrix}\\
&=

\begin{bmatrix}
I_{m \times m} & B_{m \times n}\\ 
0_{n \times m} & D_{n \times n}
\end{bmatrix}

\begin{bmatrix}
A-BD^{-1}C_{m \times m} & 0_{m \times n}\\ 
D^{-1}C_{n \times m} & I_{n \times n}
\end{bmatrix}
\end{align*}$$ First, I don't understand how $\begin{bmatrix} A_{m \times m} & 0_{m \times n}\\ C_{n \times m} & I_{n \times n} \end{bmatrix} \begin{bmatrix} I_{m \times m} & A^{-1}B_{m \times n}\\ C_{n \times m} & D-CA^{-1}B_{n \times n} \end{bmatrix}$ was derived from $\begin{bmatrix} A_{m \times m} & B_{m \times n}\\ C_{n \times m} & D_{n \times n} \end{bmatrix}$. Second, when I did a multiplication between the matrices, 
$$
\begin{align*}
&\begin{bmatrix} A_{m \times m} & 0_{m \times n}\\ C_{n \times m} & I_{n \times n} \end{bmatrix} \begin{bmatrix} I_{m \times m} & A^{-1}B_{m \times n}\\ C_{n \times m} & D-CA^{-1}B_{n \times n} \end{bmatrix}
=\\
&\begin{bmatrix}
A_{m \times m}I_{m \times m}+0_{m \times n}C_{n \times m} & A_{m \times m}A^{-1}B_{m \times n}+0_{m \times n}(D-CA^{-1}B_{m \times n})\\
C_{n \times m}I_{m \times m}+I_{m \times m}C_{n \times m} & 
C_{n \times m}A^{-1}B_{m \times n}+I_{n \times n}(D-CA^{-1}B_{m \times n})
\end{bmatrix}=\\
&\begin{bmatrix}
A_{m \times m} & B_{m \times n}\\\
2C_{n \times m} & D_{n \times n}
\end{bmatrix}\neq
\begin{bmatrix}
A_{m \times m} & B_{m \times n}\\ 
C_{n \times m} & D_{n \times n}
\end{bmatrix}
\end{align*}$$
It's weird that in my multiplication doesn't get back the original matrix. How was the first equation being derived by sort of ""splitting"" the matrix into 2 matrices?
Also, why doesn't my multiplication get back the original matrix? Thanks for any help.","['matrices', 'linear-algebra', 'block-matrices']"
64726,Finding upper segments of intersecting parabolas,"I have multiple parabolas ($y = ax^2 + bx + c$) which may intersect with each other (or some of them may not intersect). I am trying to find upper segments of these parabolas, e.g. bold part in the picture: I need to find it in $O(n\log n)$. There's a solution for line version of this problem: https://stackoverflow.com/questions/7420193/how-to-find-upper-envelopes-of-intersected-lines-in-onlogn But I cannot find a way to apply this solution to quadratic version since there are $a$, $b$ and $c$ variables to consider. Any help will be appreciated.","['geometry', 'conic-sections', 'algorithms']"
64739,Extension of $3\sigma$ rule,"For the normally distributed r.v. $\xi$ there is a rule of $3\sigma$ which says that 
$$
\mathsf P\{\xi\in (\mu-3\sigma,\mu+3\sigma)\}\geq 0.99.
$$ Clearly, this rule not necessary holds for other distributions. I wonder if there are lower bounds for 
$$
p(\lambda) = P\{\xi\in (\mu-\lambda\sigma,\mu+\lambda\sigma)\}
$$
regardless of the distribution of real-valued random variable $\xi$. If we are focused only on  absolute continuous distributions, a naive approach is to consider the variational problem
$$
\int\limits_{\int\limits xf(x)\,dx - \lambda\sqrt{\int\limits x^2f(x)\,dx-(\int\limits xf(x)\,dx)^2}}^{\int\limits xf(x)\,dx + \lambda\sqrt{\int\limits x^2f(x)\,dx-(\int\limits xf(x)\,dx)^2}} f(x)\,dx \to\inf\limits_f
$$
which may be too naive. The other problem is that dsitributions can be not necessary absolutely continuous. So my question is if there are known lower bounds for $p(\lambda)$?","['statistics', 'probability']"
64742,Expanding and understanding the poison pills riddle,"You might have heard of the riddle that asks you to identify one fake pill (poisoned) among 12 pills of identical appearance, with the fake pill being either lighter or heavier than the others. You have a pair of comparative scales at your disposal, but must only use it three times. (To increase suspense, the lives of your friends depend on your correct and timely solution of this problem.) I would like to discuss the underlying principles of information theory and use the results of that discussion to expand the riddle. As I have found out, it is also possible to solve this riddle if you have 13 pills, one of them poisoned. Edit : This only works if you do not have to know whether the poisoned pill is heavier or lighter than the others (however it can be unknown). The key theme in solving this riddle is to arrange the scalings such that you get as much information as possible in the worst case scenario . Consider the idea to scale 6 pills against 6 other pills. If they have the same weight, you can be 100% certain that the 13th pill is the fake one (best case scenario), but if their weight differs, you have learnt almost nothing (namely, that the 13$^{th}$ pill is not poisoned, and that 6 specific pills are heavier than 6 others.) The information content of an event is inversely related to its likelihood, so as it is very likely (12:1) that the 13$^{th}$ pill is not the fake one, the worst case information content is low. As there are three possible outcomes in a scaling process (left is heavier, right is heavier, and same weight) you should start by putting about a third of the pills away in the first weighting process. Furthermore, you have to make sure to get as much information as possible from each weighting process. For starters, that means you should not do the same weighting twice (obvious, isn’t it?). Instead, rearrange the pills in a systematic way to allow for the result of the weighing to reflect different possible scenarios. I.e, if you have identified a group of 4 pills as “light” after the first weighing, put one aside, substitute one with a “heavy”, one with a “safely unpoisoned” and leave one one the same scale pan as it was before, and observe what change this causes. Following these rules, it will be quite easy to figure out the solution to this riddle, at least it is by far easier than trying out all possible combinations of weighings and wondering whether that gave you enough information to identify the fake pill or not. Question 1: These “rules” seem intuitive to me, but I wonder if there is some more solid information theory behind them? Also, since a more complex riddle is a better riddle, I wonder how many pills could be tested for one fake pill, if you had 4 weighings? (Question 2). There is an obvious minimum number, for which a solution can be easily found: 25. The easy solution is: Put 13 pills aside and weigh 6 against 6. If they have equal weight, proceed with the 13 remaining pills as above. If they have different weight, proceed with the 12 pills as above. However, this wastes a lot of information, so I guess it should be possible with a much higher number of pills, although I do not know how to find that number. My third question is to what degree would complexity of this problem rise if there were 2 poisoned fake pills (either of same or of potentially different weight) ? Best wishes,
Martin","['information-theory', 'puzzle', 'combinatorics']"
64745,Maximal Subgroups and order of a group,"I encountered the following exercise in Isaacs' Algebra : ""Suppose a group $G$ has only one maximal subgroup. Prove that the order of $G$ must be a power of a prime"". I think I've proven this for the case when $G$ is cyclic, based on the observation that in a cyclic group $G$ with a subgroup $H$, $H$ is maximal iff $\frac{|G|}{|H|}$ is prime. However  if $G$ is not cyclic, I cannot use the property that there always exists a subgroup of order some divisor of $|G|$. I have run out of ideas in solving this problem, how can I proceed from here? Please do not post complete solutions.","['finite-groups', 'group-theory']"
64747,The definition of independent discrete random variables,"In probability books, the definition of independent discrete random variables are often given as The random variables $X$ and $Y$ are said to be independent if
  $\mathbb P(X \leq x, Y \leq y) = \mathbb P(X \leq x) \mathbb P(Y \leq y)$
  for any two real numbers $x$ and $y$, where $\mathbb P(X \leq x, Y \leq y)$ represents the
  probability of occurrence of both event $\{X \leq x\}$ and event $\{Y \leq y\}$. or $\mathbb P(X \in A, Y \in B) = \mathbb P(X \in A) \mathbb P(Y \in B)$ And the 2 definitions are alleged to be identical.  But the proof is often omitted.  Although it's intuitively correct, I still want to see a proof.  Could anyone show me how to prove this?",['probability']
64770,Is every submodule of a free module of finite rank finitely generated?,Surely it is true? But somehow I can't think of a way to prove it. Let's assume the ring is commutative with identity.,"['modules', 'abstract-algebra']"
64775,"When aren't Christoffel symbols symmetrical with respect to bottom indices, and why?",When aren't Christoffel symbols symmetrical with respect to the bottom indices? Why isn't the symmetry of second derivatives true in this case?,['differential-geometry']
64791,Going down theorem fails,"Maybe this exercise comes from some textbook, but I do not know. It said that this ring extension $k[x(x-1),x^2(x-1),z]\subset k[x,z]$ does not have the Going-Down property. I observe that $$k[x(x-1),x^2(x-1)]=\{f(x)\in k[x]\mid f(0)=f(1)\},$$ and $$k[x(x-1),x^2(x-1),z]\simeq k[x,y,z]/(y^2-xy-x^3).$$ We have a morphism from $\mathrm{Spec}\ k[x,y,z]/(y^2-xy-x^3)$ to $\mathbb{A}^2$ . But I still have not solved the exercise. And I do not know how one found this counterexample. Why did he consider this? Thanks.","['commutative-algebra', 'algebraic-geometry']"
64793,Proof $f(\emptyset)=\emptyset$,"How to prove that $f(\emptyset)=\emptyset$ for $f: X \rightarrow Y$ ? I already have these: Two things to prove: $f(\emptyset) \subseteq \emptyset$ and $\emptyset \subseteq f(\emptyset)$ . First prove that $\emptyset \subseteq f(\emptyset)$ :
Suppose $x \in \emptyset$ , than $x \in f(\emptyset)$ so $\emptyset \subseteq f(\emptyset)$ . But how can I prove that the subset of the function applied to the empty set is a subset of the empty set? Regards,
Kevin","['elementary-set-theory', 'functions']"
64796,Equicontinuous set,"Let $\mathcal E$ be the set of all functions $u\in C^1([0,2])$ such that $u(x)\geq 0$ for every $x\in[0,2]$ and $|u'(x)+u^2(x)|<1$ for every $x\in [0,2]$. Prove that the set $\mathcal F:=\{u_{|[1,2]}: u\in\mathcal E\}$ is an equicontinuous subset of $C^0([1,2]).$ The point I am stuck on is that i can't see how to combine the strange hypothesis imposed on every $u\in\mathcal E$, in particular i solved the two differential equations $$u'(x)=1-u^2(x),\qquad u'(x)=-1-u^2(x),$$ which result to be the extremal case of the condition given. In particular the two solutions are $$u_1(x)=\frac{ae^t-be^{-t}}{ae^t+be^{-t}},\qquad u_2(x)=\frac{a\cos(x)-b\sin(x)}{a\cos(x)+b\sin(x)}.$$ I feel however i'm not ong the right path so any help is appreciated. P.S. Those above are a big part of my efforts and thoughts on this problem so i hope they won't be completely useless :P Edit In the first case the derivative is $$u'_1(x)=\frac{2ab}{(ae^t+be^{-t})}\geq 0$$
while for the other function we have, for $x\in[0,2],$ $$u'_2(x)=-\frac{\sin(2x) ab}{(a\cos(x)+b\sin(x))^2}\leq 0.$$ Moreover $u_1(1)>u_2(1)$, since $$\frac{ae-b^{e-1}}{ae+be^{-1}}>\frac{a\cos(1)-b\sin(1)}{a\sin(1)+b\cos(1)}\Leftrightarrow (a^2e+be^{-1})(\sin(1)-\cos(1)),$$ and $\sin(1)>\cos(1).$ Now, all this bounds i've found are useful to solve the problem?",['functional-analysis']
64797,Gradient of an integral,"Let's suppose that we have a three dimensional function $f(\vec{x})$ which is the integral of some another function $g(\vec{x},\vec{y})$ , i.e $f(\vec{x})=\int_{\mathbb{R}^3}g(\vec{x},\vec{y})d^3 \vec{y}$ What is the gradient of the $f(\vec{x})$ ? Can the operator pass inside the integral? $\nabla f(\vec{x})=\nabla_x\int_{\mathbb{R}^3}g(\vec{x},\vec{y})d^3 \vec{y}=\int_{\mathbb{R}^3}\left[\nabla_x g(\vec{x},\vec{y})\right]d^3 \vec{y}$ The quantity $\nabla g(\vec{x},\vec{y})$ is a vector and it doesn't make sense to me integrating a vector. In the case of the Laplacian operator $\nabla^2$ can it pass inside the integral? Edit: The question was inspired from a physics problem where we have a potential $V(\textbf{x})=-\int_{\mathbb{R}^3}\frac{G}{|\textbf{x}-\textbf{y}|}\rho(\textbf{y})d^3\textbf{y}$ and we take a gradient to find the accelaration: $g(\textbf{x})=-\nabla V(\textbf{x})=\nabla_x\int_{\mathbb{R}^3}\frac{G}{|\textbf{x}-\textbf{y}|}\rho(\textbf{y})d^3\textbf{y}$ .","['multivariable-calculus', 'integration']"
64798,Which way is length and which way is width?,"I hear people refer to the dimensions of things as ""$2$ by $4$"" etc. and I know its length by width, but I can't tell if the length dimension is vertical (up and down) or horizontal (side to side). Does anyone know?","['geometry', 'terminology']"
64809,Existence of an antiderivative in $U \cup V$ if it exists in both $U$ and $V$,"I'm doing this exercise where I know that a function $f$ that is holomorphic in $U \cup V$, has a holomorphic antiderivative in $U$ and also another holomorphic antiderivative in $V$, where $U, V \subseteq \mathbb{C}$ are open sets such that $U \cap V \neq \emptyset$ and $U \cap V$ is connected. Then the question is to prove that $f$ has a holomorphic antiderivative in the union $U \cup V$, and provide a counterexample to show that the hypothesis on the intersection $U \cap V$ are required for the result to be true. My attempt I thought that since there are holomorphic functions $F: U \rightarrow \mathbb{C}$ and $G: V \rightarrow \mathbb{C}$ such that $F' = f$ in $U$ and $G' = f$ in $V$, then in the intersection both derivatives coincide so in $U \cap V$ we have $F' = G'$ and so $F = G + C$ in $U \cap V$, where $C$ is a constant. But now my problem is that I don't see how to extend this to the whole union $U \cup V$, and I don't see where I'll use the connectedness assumption. So if you could help me with my argument I would be most grateful. By the way, if you could also give me a hint to construct a counterexample that would be great. Thanks.",['complex-analysis']
64812,Simplifying Exponents in Fractions,From my Algebra 2 class. Not homework. $$4x^3/2x^5y^2$$ Divide the bases and subtract the exponents: $$2x^{-2}y^2$$ Get rid of negative exponent by division: $$2y^2/x^2$$ Then the answer should be: $$2x^2y^2$$ Is this correct?,['algebra-precalculus']
64818,Inequality of ODE solutions,"Says I have two (scalar) ODE: $u' = f(u,t)$ and $v' = g(v,t)$ where Both $f$ and $g$ are piecewise-continuous and locally Lipschitz, for existence & uniqueness of solutions $u(t)$ and $v(t)$. $f(x,t) \leq g(x,t)$ for all $x$ and $t$. I believe that if $u(0) \leq v(0)$ then $u(t) \leq v(t)$ for all $t \geq 0$. But I don't know if there is such theorem, or if not, how to prove it.","['ordinary-differential-equations', 'inequality']"
64825,Need for computation in pure Mathematics at the highest level?,"I'm fourth year undergrad student and I've noticed the skills that I've built up to do computation isn't actually being used. A good example is algebraic topology, I've never really used calculus in it or PDEs technique. It just seems everything that has been developed is useless to algebraic topology. Only thing I use is group theory and then most of it like common sense reasoning with pictures and heavy use of category theory. So the soft question is, what computation do you need in algebraic topology/algebraic geometry? As it seems you need none apart from group theory and commutative algebra in AG. Algebraic topology seems to be more understanding as opposed to calculation. Edited: What should really asked is this. What mechanical skills do you need in high end Algebraic topology and geometry. As I've read that Grothendieck didn't know that 57 wasn't a prime and that Bourbaki was saying that you don't need heavy calculations. So was wondering is it worth it to revise all of analysis and skills like solving PDEs, relearning Linear algebra e.t.c., when it seems the skills are useless. Because I really don't want to relearn computations and certainly don't want to relearn analysis and complex analysis. Plus, I've been reading you don't need it. I suppose the big problem is that undergraduate algebraic geometry looks nothing like graduate text books in algebraic geometry. So what computational skills do you need for graduate level AG.","['algebraic-geometry', 'algebraic-topology', 'soft-question']"
64832,Proving the uniform convergence of $\sin(\frac{x}{n}) e^{-x^2}$,"How might one show that $\left(\sin(\frac{x}{n})e^{-x^2}\right)_n$ converges uniformly? I tried finding the supremum by setting the 1st derivative to $0$, but that gives a hard-to-solve equation. There must therefore be a looser bound, but I am not seeing it. Thanks.","['real-analysis', 'analysis']"
64838,"Integral domain that is integrally closed, one-dimensional and not noetherian","I've tried to construct examples of rings that match all except one of the properties in the definition of a Dedekind domain. (This is an old number theory qual question from Berkeleys MGSA website). The only starting point that I can think of would be $R:=K[X_1,X_2,\ldots]$ for $K$ a field. This is clearly integrally closed as any polynomial relation is contained in $K(X_1,\ldots,X_n)$ for some large enough $n$ and $K[X_1,\ldots,X_n]$ is integrally closed being a UFD. The problem is then to get rid of enough ideals from this ring $R$, so that its dimension would be 1, but I can't seem to figure out what to do. Anyone have any other ideas for rings that could work as a starting point? The polynomial ring with an infinite number of variables is pretty much the only example that I know of for how to construct a non-noetherian ring that's still a domain.",['abstract-algebra']
64839,The nature of eigenvectors of a given eigenvalue,"I am working on a problem  where I have an ($n \times n $) matrix A and an eigenvalue of A, $\lambda$, where $\lambda$ has geometric multiplicity 1. The right and left eigenvectors of A corresponding to $\lambda$ are component-wise positive. How can I show that there are no other component-wise non-negative eigenvectors?, with the exception of scalar multiples of these?","['control-theory', 'matrices', 'eigenvalues-eigenvectors']"
64846,About $\operatorname{Spin}^\mathbb{C}$ structures,"Let $X$ be a orientable 4-manifolds. I know that $X$ can be endowed with $\operatorname{Spin}^\mathbb{C}$ structures by the choice of integral lift of $w_2(X)$ (second Stiefel-Whitney class of tangent bundle of $X$) in $H^2(X;\mathbb{Z})$. (I know that this is always possible.) Then, my question is what is the set of $\operatorname{Spin}^\mathbb{C}$ structures on $X$? 1st candidate : In Fintushel's Budapest 2004 conference Lecture note, it says that 
""$\operatorname{Spin}^\mathbb{C}$ structures are classified by the lifts of $w_2(X)$ to $H^2(X;\mathbb{Z})$ up to the action of $H^1(X;\mathbb{Z}/2)$. 2nd candidate: In Taubes' introduction of famous SW->GW JAMS paper , Taubes says that the set of equivalence classes of $\operatorname{Spin}^\mathbb{C}$ structures ($\operatorname{Spin}$, in his notation) has naturally the structure of a principal $H^2(X;\mathbb{Z})$ bundle over a point. (Hence, it should be equal to $H^2(X;\mathbb{Z})$.) I think that 1st candidate is right answer. Is it right?","['spin-geometry', 'symplectic-geometry', 'differential-geometry']"
64848,"How does $(12\dots n)$ and $(a\, b)$ generate $S_n$? [duplicate]","This question already has an answer here : Necessary and Sufficient conditions for $(i \, j)$ and $(1 \, 2 \, \dotsc \, n)$ generate $S_n$. (1 answer) Closed 4 years ago . I know that $S_n$ is generated by a number of things, like all transpositions, all transpositions of the form $(1\,a)$ , the transpositions $(1\,2),(2\,3),\dots,(n-1\, n)$ , and  just the two elements $(123\dots n),(1\,2)$ . Suppose $n$ is prime. If you just have $(123\dots n)$ and some arbitrary transposition $(a\, b)$ , how does this also generate $S_n$ ? Can you somehow get to $(1\,2)$ or reduce it to some other previous case?","['permutations', 'symmetric-groups', 'abstract-algebra']"
64849,What is the significance of the three nonzero requirements in the $\varepsilon-\delta$ definition of the limit?,"What are the consequences of the three nonzero requriments in the definition of the limit: $\lim_{x \to a} f(x) = L \Leftrightarrow \forall$ $\varepsilon>0$, $\exists$ $\delta>0 :\forall$ $x$, $0 < \lvert x-a\rvert <\delta \implies \lvert f(x)-L \rvert < \varepsilon$ I believe I understand that: if $0 = \lvert x-a\rvert$ were allowed the definition would require that $f(x) \approx L$ at $a$ ($\lvert f(a)-L \rvert < \varepsilon$); if $\varepsilon=0$ and $\lvert f(a)-L \rvert \le \varepsilon$ were allowed the theorem would require that $f(x) = L$ near $a$ (for $0 < \lvert x-a\rvert <\delta$); and if $\delta=0$ were allowed (and eliminating the tautology by allowing $0 \le \lvert x-a\rvert \le \delta$) the definition would simply apply to any function where $f(a) = L$, regardless of what happened in the neighborhood of $f(a)$. Of course if (2'.) $\varepsilon=0$ were allowed on its own, the theorem would never apply ($\lvert f(a)-L \rvert \nless 0$). What I'm not clear about is [A] the logical consequences of (3'.) allowing $\delta=0$ its own, so that: $\lim_{x \to a} f(x) = L \Leftrightarrow \forall$ $\varepsilon>0$, $\exists$ $\delta≥0 :\forall$ $x$, $0 < \lvert x-a\rvert <\delta \implies \lvert f(x)-L \rvert < \varepsilon$ and [B] whether allowing both 1. and 2. would be equivalent to requiring continuity?","['calculus', 'real-analysis', 'limits']"
64857,Painting the faces of a cube with distinct colours,"I don't think this is solved by Burnside's Lemma since there is a condition that each side is painted a different colour. The question is as follows. If I had a cube and six colours, and painted each side a different colour, how many (different) ways could I paint the cube? What about if I had $n$ colours instead of 6? The answer given in an old thread on a different site is $6!$ for the first question, and $n(n-1)(n-2)(n-3)(n-4)(n-5)$ for the second question. However, this doesn't actually hold up because a few of the paintings are isomorphic. The original thread assumes we can somehow tell the difference between two paintings which actually look identical if you rotate the cube, which I don't think is what the question intended. The answer I got for the first question is $4! + 4 = 28$. But this was just through a case-bash, and I'm not sure whether it's correct or whether it generalizes.","['group-theory', 'combinatorics']"
64860,Proving : $ \bigl(1+\frac{1}{n+1}\bigr)^{n+1} \gt (1+\frac{1}{n})^{n} $,"How could we prove that this inequality holds $$ \left(1+\frac{1}{n+1}\right)^{n+1} \gt \left(1+\frac{1}{n} \right)^{n} $$ where $n \in \mathbb{N}$, I think we could use the AM-GM inequality for this but not getting how?","['inequality', 'algebra-precalculus']"
64862,Subexponential growing functions,What is the most common definition of a subexponential growing function ? It seems there are different notions in literature.,"['functions', 'definition']"
64868,How to prove $a^2 + b^2 + c^2 \ge ab + bc + ca$?,How can the following inequation be proven? $$a^2 + b^2 + c^2 \ge ab + bc + ca$$,"['inequality', 'algebra-precalculus', 'multivariate-polynomial', 'polynomials']"
64881,Proving the AM-GM inequality for 2 numbers $\sqrt{xy}\le\frac{x+y}2$,"I am having trouble with this problem from my latest homework. Prove the arithmetic-geometric mean inequality. That is, for two positive real
numbers $x,y$, we have
$$ \sqrt{xy}≤ \frac{x+y}{2} .$$
Furthermore, equality occurs if and only if $x = y$. Any and all help would be appreciated.","['inequality', 'means', 'algebra-precalculus']"
64892,Sequence of numbers with prime factorization $pq^2$,"I've been considering the sequence of natural numbers with prime factorization $pq^2$, $p\neq q$; it begins 12, 18, 20, 28, 44, 45, ... and is A054753 in OEIS . I have two questions: What is the longest run (a subsequence that consists of consecutive integers)? The first run of length 3 is 603, 604, 605. There are another 256 runs of length 3, and no longer runs, less than $10^7$. Can it be shown that runs of length 4 and 5 are not possible? All I've managed to work out is that runs of length 6 are impossible (because one of the numbers would have to have 6 as a factor), and that any run of length 5 needs to consist of the numbers $48k+i$ for some $k$ and $i=1 \dots 5$. Are there more even or odd numbers in the sequence? More specifically, what is the asymptotic ratio, $\rho=\lim\limits_{N\to\infty}E_N/O_N$, of the number of even elements to the number of odd elements less than $N$. The following two graphs suggest that $E_N$ exceeds $O_N$ for large $N$. The first plots $E_N-O_N$, and the second $E_N/O_N$, against $N$. It appears that even numbers finally gain the ascendancy for good at $N=222436$. All I've managed to determine is that $E_N \sim\frac{N}{4 \log \left(\frac{N}{4}\right)}+\frac{\sqrt{2N}}{\log \left(\frac{N}{2}\right)}$. I'm also pretty sure than $O_N$ is also $\Theta(\frac{N}{\log N})$ and hence $\rho$ is a constant. I'm not a number theory expert (more an amateur combinatorialist), so I've no idea how hard these questions are. Any insight would be gratefully received.","['sequences-and-series', 'number-theory', 'asymptotics', 'analytic-number-theory', 'prime-numbers']"
64897,Is there a general formula for creating close approximations of regular polygons on a regular lattice?,"Prompted by the question What regular polygons can be constructed on the points of a regular orthogonal grid? : A regular octagon can be approximated on a quad lattice (grid) to about $1\text{%}$ error by knowing that the length of the diagonal of a square is $\sqrt{2}$ (~$1.414$) times as long as its side.  With that information we can draw a ""regular"" octagon by marking the four lattice points 7 orthogonal lengths from a center point and marking the four lattice points 5 diagonal lengths from the same center point. Is there a general rule that can be applied to create close approximations of other regular polygons on a quad-lattice (triangle, pentagon, enneagon, decagon, dodecagon, etc.)?",['geometry']
64902,Surjectivity of a map between a module and its double dual,"Let $\mathbb{Z} = R$ be our base ring.  I am trying to show for a countable direct product of $\mathbb{Z}$ modules there is an isomorphism between it and its dual. I am stuck on the part about surjectivity and I am a little confused because according to Dummit and Foote you can only get surjectivity of the map if the modules are projective and finitely generated. Let me explain the problem in detail: Let $P = \oplus_{i \in \mathbb{N}} A_i$ where each $A_i = \mathbb{Z}$ .  How do we  to show the map $c_P : P \rightarrow P^{**}$ given by $x \mapsto (y^{*} \mapsto \left< x, y^{*} \right>$ is surjective? I know how to compute the dual of $\mathbb{Z}^{*} = Hom_{\mathbb{Z}}(\mathbb{Z},\mathbb{Z})$ by showing the mapping of each $y* \in \mathbb{Z}^{*}$ given by $y^{*} \mapsto y^{*}(1)$ is an isomorphism so $\mathbb{Z}^{*} \cong \mathbb{Z}$ .  Now since the dual of a direct sum is the direct product of corresponding duals we have $P^{*} \cong \prod_{i \in \mathbb{N}} \mathbb{Z} \cong \mathbb{Z} \times \mathbb{Z} \times \ldots $ From here I don't know what to do to prove the map $c_p$ is surjective.  I am confused about the statements I have read saying we need the module to be projective and finitely generated.  Is it just the fact that the dual of a direct product should be the direct sum of the duals?","['modules', 'linear-algebra', 'abstract-algebra']"
64903,"$a/b=c$, how to move the numerator to the right side of the equation","Given an equation of the form $a/b=c$, how do you move $a$, the numerator, over to the other side so that you get $b =c?$ (where $?$ denotes my ignorance of what the right side should look like).",['algebra-precalculus']
64904,"Thinking more intuitively about complex analysis, in particular regarding Schwarz's Lemma","In a proof of Schwarz's Lemma (Sarason, ""Complex Function Theory"", pp. 91-92) the function $g$ is defined in the disk by $$g(z) = \begin{cases}\frac {f(z)}z&\mbox{ for } 0 < |z| < 1\\

f'(0)&\mbox{ for } z = 0.\end{cases}$$ The proof goes on to say that for $0 < r <1$, $g$ is bounded by $\frac {1}{r}$ on the circle $|z| = r$ and thus has the same bound in the disk $|z| \le r$ by the maximum modulus principle. This being true for all $r$ in $(0,1)$,  $g$ is bounded in absolute value by $1$. This makes perfect sense formally. Here are my questions: 1) Intuitively when I see something is bounded by $\frac {1}{r}$ and $r$ has values in $(0,1)$, I would naturally think of $r$ being close to $0$, and  $\frac {1}{r}$ getting quite large. Then along comes the max. modulus principle and shuts it all down to a bound of $1$. How can I think intuitively about complex analysis to see how my naive instinct does not apply here? 2) In the statement of the Lemma, we are given that $f(0) = 0$. It seems to me that this comes into play in defining $g$. Again, how can I get an intuitive insight as to the power this stipulation has in providing the criterium for the conclusion of the Lemma. And on a larger scale, how do I train myself to ""think more complex""? Thanks",['complex-analysis']
64906,Integers in $p$-adic field,Let $K$ be a finite extension of $\mathbb Q_p$. How to prove that if an element of $K$ has non negative valuation then it is algebraic over $\mathbb Z_p$? I would like also a reference for this proof (e.g. is it somewhere in Algebraic Number Theory by Neukirch ?).,"['p-adic-number-theory', 'number-theory']"
64907,Correspondences between linear transformations and matrices,"EDIT: I value all the answers given to me in this question, and upon reading them and thinking about the question for some time, I have come up with my own answer and explanation for this question. I have typed this up and submitted it as an answer here, so that people may read it and can hopefully let me know if my current understanding is fully correct and useful. And furthermore if it is incorrect I would very much appreciate corrections and amendments to my answer. Thank you. I am a bit confused about representing linear transformations as matrices, I will try to explain my confusion here, and hopefully someone can clear it up. Note: Let $V$ and $V'$ be finite dimensional vector spaces over an arbitrary field $F$ such that $\operatorname{dim}(V) = n$ and $\operatorname{dim}(V') = m$, $V$ has basis $B$, and $V'$ has basis $B'$. Now we want to create an isomorphism: $f: \operatorname{Hom}(V,V') \rightarrow M_{m\times n}(F)$ According to notes we map 
$$ h \mapsto [h]^{B'}_{B} = [P^{-1}_{B'}hP_{B}] =
 \left(
\begin{array}{cc}
P^{-1}_{B'}\circ h\circ P_B \begin{pmatrix} 1\\ 0 \\ \vdots \\ 0\end{pmatrix} &\cdots &P^{-1}_{B'}\circ h\circ P_B\begin{pmatrix} 0\\ 0 \\ \vdots\\ 1\end{pmatrix}
\end{array}
\right)$$ Where $P_B : F^n \rightarrow V$ is defined by $$\begin{pmatrix} a_1 \\ \vdots \\ a_n \end{pmatrix} \mapsto a_1v_1 + ... + a_nv_n$$ Now, I'm quite confused as to where this mapping came from, and furthermore I'm confused as to exactly what matrix we are mapping $h$ to, and why is this matrix called the matrix of $h$ with respect to $B$ and $B'$ ($[h]^{B'}_{B}$). I apologize if the question isn't quite clear and thank you in advance for any answers.","['matrices', 'linear-algebra']"
64919,Biased Random Walk and PDF of Time of First Return,"I have a random walk process where each step the probability of $+1$ is $p$ and $-1$ is $q$, with $p+q=1$. $p$ may not equal $q$. The walker starts at zero. I want to know the probability that the first return to zero occurs at $t$. Obviously, the number of increases will equal the number of decreases and both will equal $t/2$. So obviously $t$ must be even. So far, all I have seen is the unbiased random walk PDF for first return time and that when $p>q$ there is a probability that the walker may ever reach zero. It seems like that for any finite $t$, it should simply be a question of getting the right number of permutations. Or perhaps it is as easy as a rewrite of the unbiased PDF? Additionally, if possible, I'd like to condition on the first step being to $1$. Thank you!","['probability-theory', 'random-walk', 'probability-distributions']"
64923,Why can't we interchange differentiation with taking a limit of a series of functions?,"While learning a little Fourier analysis, I ran into this interesting phenomenon: Consider a series of sawtooth waves such that the height and width of the sawteeth shrinks to zero, but the slope of the sawteeth remains the same.  To be specific, let $$f_n(x) = \frac{nx - \lfloor nx\rfloor}{n}$$ Then define $$F(x) = \lim_{n\to\infty}f_n(x)$$ It seems intuitively clear that $F(x) = 0$ for all $x$ because the global maximum of $f_n$ is $\frac{1}{n}$. If $F(x) = 0$, then we should have $F'(x) = 0$ as well.  However, if we choose an irrational value of $x$, then $f'_n(x) = 1$ for all $n$, so if $F'(x)$ is found instead by taking $$F'(x) = \lim_{n\to\infty}f'_n(x)$$ we do not get $F'(x) = 0$. It seems like the derivative of a limit is not the same as the limit of a derivative, which is pretty counterintuitive to me. What's going on?","['real-analysis', 'limits']"
64926,"If G is not commutative, then is there always a subgroup that is not a normal subgroup?","I was having a discussion with a friend of mine about some normal group properties and then came up with the question ""if G is not commutative, then is there always a subgroup that is not a normal subgroup?"" It's probably more easy to solve this in the following form:$$\forall H \leq G : H  \lhd G \Rightarrow \forall a,b \in G : ab=ba$$
My question is, can anybody give a proof, or a counter-example (because I don't think it holds) of this theorem? Thanks!","['group-theory', 'abstract-algebra']"
64936,Is this relation transitive if $n=m$?,"If $X$ is a set and $n \in \mathbb N$, then $[X]^n$ will denote the set of all subsets of $X$ with exactly $n$ elements. For a set $X$ and natural numbers $n$ and $m$ define a relation $R$ on $[X]^n$ and $[X]^m$ by $R(A,B)$ holds if and only $A \cap B = \emptyset$. Is $R$ transitive if $n = m$? Need an example or proof","['relations', 'proof-writing', 'elementary-set-theory', 'problem-solving']"
64937,"Volume of a sphere by ""adding"" half-spheres of lower dimension","I'm wondering about different ways to compute the volume of an $n$-sphere.  Please see the wikipedia page for one method to compute the volume via hyperspherical coordinates: http://en.wikipedia.org/wiki/N-sphere#Hyperspherical_volume_element Suppose now I want to compute the volume $V(n)$ of an $n$-sphere by integrating the volumes $V(n-1)$ of a whole bunch of $(n-1)$-spheres.  Assuming that this $(n-1)$-sphere is aligned with the first $n-1$ coordinate axes, I don't see a way to just integrate $(n-1)$-spheres with the variable being the last angular coordinate.  I'm also more generally interested in this question when we integrate $(n-k)$-spheres with volumes $V(n-k)$ with the variables being the last $k$  angular coordinates.  Any thoughts?","['geometry', 'multivariable-calculus']"
64945,"Is there one-tailed version of Vysochanskiï–Petunin inequality, like Chebyshev?","The Vysochanskiï–Petunin inequality gives a tighter bound than Chebyshev for unimodal distributions . I'm just wondering if there is a one tailed version of it, like that of Chebyshev inequality ? Please help.","['probability-theory', 'inequality']"
64948,Smoothness of a real-valued function on $\mathbb{R}^n $,"Let 
$$ f(x)=
\begin{cases}
\exp\left(\frac{-1}{1-|x|^2}\right), &\text{ if } |x| < 1,
\\
0, &\text{ if } |x|\geq  1.
\end{cases}
$$ Prove that $f$ is infinitely differentiable everywhere. ($x$ belongs to $\mathbb{R}^n$ for fixed $n$.) Well, this is obvious for $|x|>1$ and easy enough for the first derivative at $|x|=1$, but I can't seem to use the definition of the Gateaux derivative to show it for $|x|<1$. Any advice would be appreciated. (This is not homework.)",['real-analysis']
64971,Proof $\sum\limits_{k=1}^n \binom{n}{k}(-1)^k \log k = \log \log n + \gamma +\frac{\gamma}{\log n} +O\left(\frac1{\log^2 n}\right)$,"More precisely, $$\sum_{k=1}^n \binom{n}{k}(-1)^k \log k = \log \log n + \gamma +\frac{\gamma}{\log n} -\frac{\pi^2  + 6 \gamma^2}{12 \log^2 n} +O\left(\frac1{\log ^3 n}\right).$$ This is Theorem 4 from Flajolet, Sedgewick (1995) and was obtained using Hankel integration. It is related to analysis of quadtrees and digital search trees. I know from 'Concrete Mathematics' that similar-looking sums can be obtained and solved using discrete form of derivatives, $\nabla f(x)=f(x+1)-f(x)$ and so $n^{\text{th}}$ difference is $$\nabla^n f(x)=\sum_{k=0}^{n} \binom{n}{k} (-1)^{n-k} f(x+k) $$ and I know how to use it for simple functions such as $f(x)=\dfrac1{x}$, but I have no idea how solve something like the one above.","['asymptotics', 'algorithms', 'complex-analysis', 'combinatorics']"
64982,Is every quotient of a finite abelian group $G$ isomorphic to some subgroup of $G$?,"I'm having difficulty with exercise 1.43 of Lang's Algebra . The question states Let $H$ be a subgroup of a finite abelian group $G$. Show that $G$ has a subgroup that is isomorphic to $G/H$. Thinking about this for a bit, the only reasonable approach I could think of was to construct some surjective homomorphism $\phi\colon G\to K$ for $K\leq G$, and $\ker\phi=H$, and then just use the isomorphism theorems to get the result. After a while of trying, I've failed to come up with a good map, since $H$ seems so arbitrary. I'm curious, how can one construct the desired homomorphism? This is just the approach I thought of, if there's a better one, I wouldn't mind seeing that either/instead. Thank you.","['group-theory', 'abstract-algebra', 'abelian-groups']"
64983,Name for a Partition in which Every Block Has the Same Size,Is there a standard name for a partition of a set in which every block (i.e. the subsets comprising the partition) has the same size? Regular? Uniform? Something else? Nothing else (so I'm free to make up my own)?,"['terminology', 'elementary-set-theory']"
64987,Prove using mathematical induction: $1 \cdot 2 \cdot 3 + \ldots + n \cdot (n+1) \cdot (n+2) =  \frac{n(n+1)(n+2)(n+3)}{4}$,"So I have the easy stuff done. However, I'm not sure how to go about doing the inductive step with such an awkward proof. :/ Statement: 
$$ 1 \cdot 2 \cdot 3 + … + n \cdot (n+1) \cdot (n+ 2) = \frac{n \cdot (n + 1) \cdot (n + 2) \cdot (n +3)}{4} .$$ Base step: $n = 1$: 
$$ 0  \cdot (0 + 1) \cdot (0 + 2) + 1 \cdot (1 + 1) \cdot (1 +2) = \frac{ 1 \cdot (1+ 1) \cdot (1 + 2) \cdot (1 + 3) }{4} .$$ $$ 0 \cdot (0 + 1) \cdot (0 + 2) +1 \cdot (1 + 1) \cdot (1 +2) = 0 + 6 = 6$$ $$ \frac{ 1 \cdot (1+ 1) \cdot (1 + 2) \cdot (1 + 3) }{4} = \frac{24}{ 4} = 6 .$$ $$6 = 6.$$ Inductive step: $n = n + 1$",['algebra-precalculus']
64995,Symmetric difference of a Vitali subset and a Lebesgue measurable sets,"Could anyone help to show the following? Thanks! Let $V \subset [0,1]$ be a Vitali set. Let 
$$
M= \{ A \Delta B \,:\, A \subset [0,1] \text{ is Lebesgue measurable}, B\subset V \}
,$$ 
where $\Delta$ denote the symmetric difference. Prove that $M$ is a sigma-algebra.",['measure-theory']
65002,Are one-by-one matrices equivalent to scalars?,"I am a programmer, so to me $[x] \neq x$—a scalar in some sort of container is not equal to the scalar. However, I just read in a math book that for $1 \times 1$ matrices, the brackets are often dropped. This strikes me as very sloppy notation if $1 \times 1$ matrices are not at least functionally equivalent to scalars. As I began to think about the matrix operations I am familiar with, I could not think of any (tho I am weak on matrices) in which a $1 \times 1$ matrix would not act the same way as a scalar would when the corresponding scalar operations were applied to it. So, is $[x]$ functionally equivalent to $x$? And can we then say $[x] = x$? (And are those two different questions, or are entities in mathematics ""duck typed"" as we would say in the coding world?)","['matrices', 'linear-algebra', 'soft-question']"
65004,Proving $n^4-4n^2$ is divisible by $3$ using induction,"$n^4 – 4n^2$ is divisible by $3$ for all $n \geq 0$. Okay so the help earlier has been working on the questions up until now. I cannot figure out how to ""factor"" this one. So once I prove the base case for $n = 0$ (I also did for $n =1$) I proceed to the inductive step. However I'm a little confused. Normally I understand that if we $S(N) = X$ condition. We do induction by,
$S(N) + \text{(N +1 additive)} = S(N+ 1)$. However no idea how to do this here. I need help. <,< Sorry!","['induction', 'algebra-precalculus', 'discrete-mathematics']"
65011,How to prove that the Binet formula gives the terms of the Fibonacci Sequence?,"This formula provides the $n$th term in the Fibonacci Sequence, and is defined using the recurrence formula: $u_n = u_{n − 1} + u_{n − 2}$, for $n > 1$,  where $u_0 = 0$ and $u_1 = 1$. Show that $$u_n = \frac{(1 + \sqrt{5})^n - (1 - \sqrt{5})^n}{2^n \sqrt{5}}.$$ Please help me with its proof. Thank you.","['fibonacci-numbers', 'recurrence-relations', 'sequences-and-series']"
65012,"If matrices $A$ and $B$ commute, $A$ with distinct eigenvalues, then $B$ is a polynomial in $A$","If $A\in M_{n}$ has $n$ distinct eigenvalues and if $A$ commutes with a given matrix $B\in M_{n}$, how can I show that $B$ is a polynomial in $A$ of degree at most $n-1$? I think first I need to show that $A$ and $B$ are simultaneously diagonalizable, but I don't know how to begin. Any advice is much appreciated.","['control-theory', 'linear-algebra']"
