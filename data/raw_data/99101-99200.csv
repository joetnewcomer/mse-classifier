question_id,title,body,tags
1371366,Limit and limit points,"What is the basic difference between limit and limit points, and if a sequence has one unique limit how it can have a lot of limit points","['sequences-and-series', 'limits', 'real-analysis']"
1371380,Identifying two points on an algebraic curve,"Given a smooth algebraic curve $C$, say projective over an algebraically closed field $k$, is it always possible to identify two distinct closed points $x, y$ on $C$ to produce a curve with a single node? In more precise terms, does there always exist a nodal curve $C'$ whose normalization is $C$ such that $x, y$ are the points above the node? Thanks in advance!","['algebraic-geometry', 'algebraic-curves']"
1371395,Line integrals - Surface area,"Here is my task: Calculate surface area of $2(x^{2}+y^{2})^{2}=xy$ between surface $x^{2}+y^{2}=z$ and $z=0$. Here is my attempt to solve this problem.
Firstly, I transformed line $2(x^{2}+y^{2})^{2}=xy$ to polar form, putting $x=\rho\cos \phi$ and $y=\rho\sin \phi$. I got $\rho=\frac{1}{2}\sqrt{\sin 2\phi}$. It looks like this: http://s13.postimg.org/wvwox80s7/math.png To use formula surface_area=$\int z(x,y)ds$ (I don't know how to write line integral symbol in latex so I used symbol for ""ordinary"" integral instead), we must find first $ds$, which by definitions equals $$ds=\sqrt{(\frac{\mathrm{d} x}{\mathrm{d} \phi})^{2}+(\frac{\mathrm{d} y}{\mathrm{d} \phi})^{2}}d\phi$$
We have:
$x=\rho\cos \phi=\frac{1}{2}\sqrt{\sin 2\phi}\cos\phi$, $y=\rho\sin \phi=\frac{1}{2}\sqrt{\sin 2\phi}\sin\phi$. After differentiating $x$ and $y$ with respect to $\phi$ and putting it in expression for $ds$, we get (if I didn't make mistake somewhere in calculations) $ds=\frac{1}{2\sqrt{\sin 2\phi}}d\phi$. Now we can put everything in our expression for surface area: $\int z(x,y)ds$=$4\int_{0}^{\pi/4}\left [ (\frac{1}{2}\sqrt{\sin 2\phi}\cos\phi)^{2} + (\frac{1}{2}\sqrt{\sin 2\phi}\sin\phi)^{2} \right ]\frac{1}{2\sqrt{\sin 2\phi}}d\phi=4\int_{0}^{\pi/4}\frac{1}{4}\sin2\phi(\cos^{2}\phi+\sin^{2}\phi)\frac{1}{2\sqrt{\sin 2\phi}}d\phi=\frac{1}{2}\int_{0}^{\pi/4}\frac{\sin{2\phi}}{\sqrt{\sin{2\phi}}}d\phi$ I have no idea how to solve this integral. Any suggestion?","['surfaces', 'area', 'multivariable-calculus', 'integration']"
1371410,Geodesic of Stiefel manifold,"Define a metric on Stiefel manifold $V_{n,p}$ as
$$\left<\Delta_1,\Delta_2\right>=\text{tr}\Delta_1^T\left(I-\frac{1}{2}YY^T\right)\Delta_2$$
$\forall \Delta_1,\Delta_2\in T_YV_{n,p}$ how to calculate geodesic through the variation problem $$\min\limits_{Y(t)}\int\left<\dot{Y},\dot{Y}\right>^{\frac{1}{2}}dt$$
$Y(t)$ is the curve in $V_{n,p}$. Any advice is helpful. Thank you.","['stiefel-manifolds', 'riemannian-geometry', 'calculus-of-variations', 'differential-geometry', 'geodesic']"
1371428,Prove that the Torus is not homotopy equivalent to $S^1\vee S^1\vee S^2$,"Prove that the Torus is not homotopy equivalent to $S^1\vee S^1\vee S^2$. I need to show that a homotopy equivalence between them doesn't exist, but it seems like the homology groups of the spaces are equal. How can I show it? maybe using fixed point theorem?","['homotopy-theory', 'homology-cohomology', 'algebraic-topology', 'general-topology']"
1371431,Definition of an infinite $\sigma$-algebra,"What is the formal definition of an infinite $\sigma$-algebra? I cannot find this definition anywhere! But based on the context I have read it in I think it is either: (A)  A $\sigma$-algebra defined on an infinite set $S$ that contains finitely many infinite sets. (i.e. $\{ \emptyset, S\}$ ) (B) A $\sigma$-algebra defined on an infinite set $S$ that contains an infinite number of finite or infinite sets (C) Any $\sigma$-algebra defined on an infinite set $S$ (i.e. both (A) or (B) are possible)","['real-analysis', 'measure-theory']"
1371434,Point of intersection of $f(x)=\sin(2x)+\cos(2x)$ and the $x$-axis,"How can I algebraically (without looking at the graph) find the point of intersection of $f(x)=\sin(2x)+\cos(2x)$ and $x$-axis, in the interval $[0, \pi]$?","['calculus', 'algebra-precalculus', 'trigonometry']"
1371455,What is a martingale array - its definition and importance?,"What is a martingale array? What is the importance of defining such an array, instead of using a martingale itself? A common example of this definition is a martingale difference array.","['probability-theory', 'stochastic-processes', 'martingales', 'analysis', 'probability']"
1371473,Prove that a non-constant harmonic function is an open map.,"I'm trying to solve the following exercise of the book Functions of one complex variable, John B. Conway on page 255: 4. Prove that a harmonic function is an open map. (Hint: Use the fact that the connected subsets of $\mathbb{R}$ are intervals.) I assumed the harmonic functions $u: U \rightarrow \mathbb{R}\ (U \subset \mathbb{C} $ is open)  of the exercise are not constant. If U is connected using the hint, the solution is relatively simple by Maximum Principle (or Minimum). Maximum principle : Be $U$  open, connected and $ u: U \rightarrow \mathbb{R} $  harmonic. If exists $ a \in U $ such that $u(z)\leq u(a),\ \forall z\in U$, then u is constant. But the case where $U$ is not connected I could not solve. This exercise is correct? If not, is there any counterexample? Thank you","['harmonic-functions', 'complex-analysis', 'general-topology']"
1371487,Bound on function increment,"consider the function $$
f(x,y) = \dfrac{x^{1/3}}{(x+ay^3)^{1/3}}
$$
where $a>0$ is a constant and $x,y\geq 0$. It is easy to see that, outside of the origin, $0\leq f\leq 1$. $f$ itself is not continuous (consider the restriction on the $x,y$ axis and then consider limit towards the origin), but $xyf(x,y)$ should be and should also be differentiable, but with a differential that is not bounded on $[0,+\infty)\times [0,+\infty)$. Now, I have the following expression $$
\Delta = x_1y_1f(x_1,y_1) - x_2y_2f(x_2,y_2).
$$ My question is: can we get a bound on $\Delta$ of the form $$
\Delta\leq A|x_1-x_2|+B|y_1-y_2|\quad \mbox{or}\quad \Delta\leq C|x_1-x_2||y_1-y_2|
$$ with $A,B,C$ constants? If not (as I think), can we get at least a bound of the form $$
\Delta\leq A|x_1-x_2|^\alpha+B|y_1-y_2|^\beta\quad \mbox{or}\quad \Delta\leq C|x_1-x_2|^\alpha|y_1-y_2|^\beta
$$
or a combination of those, with $\alpha\leq 4/3$? Note:, if $\beta>0$, then B must be as small as possible. Edit: It would be enough to get a bound on $\Delta\cdot(y_1-y_2)$.","['lipschitz-functions', 'multivariable-calculus', 'real-analysis', 'inequality']"
1371521,sequence of primes in arithmetic progression,"The question is: Suppose $p_1<p_2<...<p_{15}$ is a sequence of prime numbers in arithmetic progression, with common difference $d$. Prove that $d$ is divisible by $2,3,5,7,11$ and $13$. Let $p_n = a+(n-1)d$, by the definition of an arithmetic sequence. It is easy to see that $a$ is odd, and I can prove that $d$ is even easily enough. I could then show $d$ is divisble by 3 by using the technique of letting $d=3x+c$, and $a=3y+d$, and by going through each possible value of c and d, d not equal to zero, I showed that the only solution where a and d were still prime was when $c=0$ or $3$. While I could do the same thing for showing d is divisible by 5,7,11 and 13, this is a very laborious process that takes quite a long time. Are there any faster ways of proving this? I feel there is a way to do it using modular arithmetic, but I'm not very competent with regards to modular arithmetic, so I can't think of anything.","['prime-numbers', 'sequences-and-series']"
1371535,Every non-increasing sequence of polynomial towers stabilizes -- Finitary proof,"In this question we are concerned only with positive integers $\mathbb N$ and other finitary objects that can be encoded using integers.  A term function means a total computable function $\mathbb N^n\to\mathbb N$ with one or multiple arguments. Letters $m,n,k$ range over $\mathbb N$. Letters $f,g$ range over functions. A term sequence of functions $f_m(n)$ is just a different name for two-argument total computable function $f(m,n)$. An element of a sequence is a one-argument function obtained by fixing the first argument, e.g. $f_2(n)=f(2,n)$. We say that a one-argument function is a polynomial tower iff it can be constructed in a finite number of steps using the following 3 rules: The constant function $f(n)=1$ is a polynomial tower. If $f(n)$ is a polynomial tower, then $n^{f(n)}$ is a polynomial tower. If $f(n)$ and $g(n)$ are polynomial towers, then $f(n)+g(n)$ is a polynomial tower. Obviously, all polynomial towers are total computable functions. Some examples are $5,n^3+7n+2, n^{n^{n^5+10n}+n^3+1}+2n^{n^2+5}+5n^7+2n+3$. A function $f(n)$ is dominated by a function $g(n)$ iff $f(n)<g(n)$ for all sufficiently large $n$; formally $\exists k\,\forall n\ge k,f(n)<g(n)$. A sequence of functions $f_m(n)$ is non-increasing iff none of its elements is dominated by the next element. A sequence of functions $f_m(n)$ stabilizes iff all its elements are the same for all sufficiently large $m$; formally $\exists k\,\forall m\ge k\,\forall n,f_m(n)=f_k(n)$. Proposition. Every non-increasing sequence of polynomial towers stabilizes. Apparently, the proposition can be formalized as a purely arithmetical statement. I'm interested in a proof of this proposition that would not appeal to infinite sets in any way. For example, it should not use arbitrary infinite sequences or real numbers, except computable ones that can be represented by a corresponding algorithm, and it should not borrow any results from analysis, except those that can be proved in constructive analysis. We could use a theory of hereditary finite sets with natural numbers, computable functions, or any other finitary objects as urelements (they can be encoded as hereditary finite sets anyways). A relatively easy infinitary proof can be outlined as follows. Observe, that a shape of a polynomial tower written as an expression resembles the Cantor normal form of some ordinal below $\varepsilon_0$ . Indeed, there a bijection between them (obtained by replacing $n$ with $\omega$ or vice versa), and it's not difficult to see that this bijection preserves order (where polynomial towers are ordered by domination, and ordinals ordered, as usual, by $\in$). So, the set of polynomial towers is order isomorphic to $\varepsilon_0$. Now, because every ordinal is well-ordered , we see that the set of polynomial towers is also well-ordered -- in other words, there is no infinite decreasing sequence of them. So, every infinite non-increasing sequence must stabilize. Of course, this proof uses many terms and lemmas that usually introduced and proved in terms of infinite sets. E.g. we need to define $\omega$ and $\varepsilon_0$, define well-order , bijection and isomorphism , prove that every ordinal below $\varepsilon_0$ has a unique non-recursive Cantor normal form -- all that is usually done using infinite sets. I'm not a finitist in any way, but it feels that all that could be avoided for purposes of proving this relatively simple arithmetic statement (of course, not as simple if you want to write in completely formalized form -- but we do not want that). It sometimes even looks obvious, if I think of it long enough :) Every step either decreases a number of steps remaining (if you already below $n$), or requires you to make a decison about how many steps remaining (when you go from $n$ to some constant below), or requires you to make a decision about how many times more you can make a decision that you will be able to review later (when you go from $n^2$ below), or about number of decisions about number of decisions about number of decisions ..., or about number of clauses in the previous ellipsis, and so on towards an inevitable end. But I hope to find a finitary proof can rigorously capture the idea from the previous paragraph, perhaps by constructing a chain of applications of the induction principle, and then using some meta-reasoning by induction that this chain can be made arbitrarily long. I heard (but never seen a proof of it) that the proposition from my question cannot be proved from axioms of Peano arithmetic alone, so we are free to invoke new meta-axioms like ""everything provable from Peano axioms is true"", or ""everything provable from Peano axioms plus the previous axiom is true"", and so on. I consider this as a valid finitary reasoning.","['computability', 'logic', 'number-theory', 'algorithms']"
1371546,Logarithmic Integral II,"While reviewing an old calculus book the following integral was assigned:
\begin{align}
\int_{0}^{1} \left( x^{a-1} - x^{n-a-1} \right) \, \frac{\ln^{2}x \, dx}{1-x^{n}} = \frac{2 \, \pi^{3} \, \cos\left(\frac{a \pi}{n}\right)}{n^{3} \, \sin^{3}\left(\frac{a \pi}{n}\right)}
\end{align}
for $a \neq n$. The proposed questions here are: What are some methods to prove the given integral? What are the changes if the power of the logarithm is lowered to one or raised to 3? The old calculus book is: Ralph A Roberts, ""A treatise on the integral calculus; part 1"", 1887. The propoblem presented here is found on page 354 as example 36. The book can be found in the Google Books collection.","['logarithms', 'calculus', 'definite-integrals', 'integration']"
1371553,Translation invariance of Brownian motion,"Beginner here. I'm working through Durrett's textbook's and am just getting into the section on Brownian motion. He gives a 2-line proof for a simple fact but I'm a little stuck understanding the details. Let $B_t$ be a one-dimensional Brownian motion. The simple fact is: $\{B_t - B_0, t \geq 0\}$ is independent of $B_0$ and has the same
  distribution as Brownian motion with $B_0 = 0$. Durrett's proof: Let $\mathcal{A}_1 = \sigma(B_0)$ and $\mathcal{A}_2$ be events of the form
$$\{B(t_1)-B(t_0) \in A_1, \ldots, B(t_n)-B(t_{n-1}) \in A_n\}$$
The $\mathcal{A}_i$ are $\pi$-systems that are independent, so the desired result follows from the $\pi-\lambda$ theorem. $\blacksquare$ So I'm assuming that this hinges on $\sigma(\mathcal{A}_2) = \sigma\{B_t-B_0, t \geq 0\}$. But what's the easiest way to see this? I know it has to do with finite-dimensional distributions, but I'm getting hung up somehow.","['brownian-motion', 'probability']"
1371559,How to classify/ solve this PDE?,"I am searching how to solve the PDE below but I can not seem to find a decent example online. My major did not focus much in solving PDEs so I feel very deficient. I know how to solve for the steady state - but I am wondering if I can solve the following analytically, not numerically. \begin{gather*}
\frac{\partial F(x, t)}{\partial t} = -g(x)F(x, t)
-A\frac{\partial F(x, t)}{\partial x}-B\frac{\partial^{2}F(x, t)}{\partial x^{2}} \\
\\
IC: F(x, 0) = 1
\end{gather*} I thought about doing a Fourier transform but I end up with a convolution in freq space - and that would be hard to handle. I also know that this is an advection - diffusion - convection PDE but its not specific enough to return any nice Google searches. Any suggestion or advice would be greatly appreciated. Thank you in advance! Follow up: Consider Case 1, where function g(t) is only a function of time. \begin{gather*}
g(t) :  = \frac{\alpha \left(\frac{t}{\beta }\right)^{\alpha -1}}{\beta } \\
\\
\frac{\partial F(x, t)}{\partial t} = -\left(\frac{\alpha \left(\frac{t}{\beta }\right)^{\alpha -1}}{\beta }\right)F(x, t) 
-A\frac{\partial F(x, t)}{\partial x}-B\frac{\partial^{2}F(x, t)}{\partial x^{2}}
\\
\\
\frac{\partial\tilde{F}(\omega , t)}{\partial t} = -\left(\frac{\alpha \left(\frac{t}{\beta }\right)^{\alpha -1}}{\beta }\right)\tilde{F}(\omega , t) 
-A(i2\pi \omega )\tilde{F}(\omega , t)+B(i2\pi \omega )^{2}\tilde{F}(\omega , t) \\
\\
\frac{\partial\tilde{F}(\omega , t)}{\partial t} = \left[-\left(\frac{\alpha \left(\frac{t}{\beta }\right)^{\alpha -1}}{\beta }\right)-A(i2\pi \omega )+B(i2\pi \omega )^{2}\right]\tilde{F}(\omega , t)
\\
\\
\mbox{The DE is of the form:} \\
y^{\prime}+ay = 0\mbox{ so when I solve I get: }\
\\
\\
\tilde{F}(\omega , t) =  
Ce^{\left(\frac{t}{\beta }\right)^{\alpha }+(A(i2\pi \omega )-B(i2\pi \omega )^{2})t} \\
\\
\mbox{-At this point I don't know how to apply the IC but if I assume C=1,} \\ \mbox{and take the inverse Fourier - I get the solution below - which looks good.} \\
\\
F(x, t) =  
\frac{e^{\left(\frac{t}{\beta }\right)^{\alpha }-\frac{(x+At)^{2}}{4Bt}}}{2\sqrt{\pi }\sqrt{Bt}}
\end{gather*} When I plug in fixed values for all variables - I get the same values but opposite signs. This is somewhat good news but still I am a little confused. Additional evidence Here is the Mathematica ourput for the two derivative terms. Note the second derivative becomes positive. A-Term: In[2]:= FourierTransform[-A*D[f[t, x], x], x, w, FourierParameters -> {0, -2 Pi}]

Out[2]= -2 i A Pi w FourierTransform[f[t, x], x, w] B-Term: In[1]:= FourierTransform[-B*D[f[t, x], x, x], x, w, FourierParameters -> {0, -2 Pi}]

Out[1]= 4 B Pi^2 w^2 FourierTransform[f[t, x], x, w] I kept everything consistent with Mathematica; therefore, I am confident my signs should be right. I really hope someone can shed some light into this!!! I am almost depressed about it.","['fourier-analysis', 'calculus', 'ordinary-differential-equations', 'partial-differential-equations']"
1371588,How to intuitively arrive at the total derivative limit and the jacobian matrix?,"I'm following this PDF and I need to understand how to arrive at the definition of total derivative geometrically. For now, what I understand is that, from the original definition of derivative: $$\lim_{h\to 0} \frac{f(p+h)-f(x)}{h} = m \implies \lim_{h\to 0}\frac{f(x+p)-f(x)-mh}{h} = 0$$ Which is the same as $$\lim_{|h|\to 0}\frac{|f(x+p)-f(x)-mh|}{|h|} = 0$$ and the advantage of this is that we can know define the existence of the derivative, but now for a multivariable function $f$ from $\mathbb R^m \to \mathbb R^n$. Besides not giving any geometrial interpretation, I quite accept this result. But then, the PDF starts just defining what the total derivative would be. I need an intuitive way to arrive at this, and then, a way to start from the limit definition of the total derivative and arrive at the jacobian matrix. Also, how it was historically derivated for the first time?","['calculus', 'real-analysis', 'multivariable-calculus']"
1371589,Differentiate the Function: $y=x^x$,$y=x^x$ Use $\frac{d}{dx}(a^x)=a^x \ln a$ My answer is: $x^x \ln x$ The book has the answer as $x^x\ (1+ \ln\ x)$ Am I missing a step?,"['calculus', 'derivatives']"
1371590,Level set as the orbit of the action of a Lie Group?,"I'm wondering the following. Given a smooth function $f:\mathbb R^n\rightarrow \mathbb R^m$ with $m<n$ and level sets $\mathcal O(y)=\{x\in\mathbb R^n| f(x)=y \}$. What are the conditions on $f$ for which $\mathcal O(y)$ are the orbits of a Lie group action on $\mathbb R^n$? I think that also there are necessary conditions on the kind of action, e.g. that it ought to be proper?","['lie-groups', 'differential-geometry', 'lie-algebras', 'group-actions']"
1371613,Can we speak of derivatives of sets?,"Suppose we have a monotone sequence of sets: $$A_1,\ldots,A_n$$
$$A_i \subseteq A_{i+1}$$ I think this is a function from $\mathbb N$ to a space of sets. Can we define a function from $\mathbb R$ to a space of sets? Could we then define a derivative of this function?",['calculus']
1371616,Conditional Radon Nikodym,"I am having some trouble conceptualizing and calculating a conditional RN derivative. When using this definition: I can see that if $\mathbb{Q} \ll \mathbb{P}$:
$$\mathbb{E}_\mathbb{Q}(g) = \int g(\omega) \mathbb{Q}(\mathsf d\omega) = \int g(\omega) f(\omega) \mathbb{P}(\mathsf d\omega) = \mathbb{E}_\mathbb{P}(gf)$$ where $f$ is the RN derivative defined by: 
$$f = \frac{\mathsf d\mathbb{Q}}{\mathsf d\mathbb{P}}$$ Im having trouble with the following relation:
$$\mathbb{E}_\mathbb{Q}(g\mid\mathcal{Y}) \stackrel{?}{=} \mathbb{E}_\mathbb{P}(g \tilde{f}\mid \mathcal{Y})$$ where $\tilde{f}$ is something like a conditional RN derivative:
$$\tilde{f} \stackrel{?}{=} \frac{d\mathbb{Q}_{(\cdot \mid \mathcal{Y})}}{d\mathbb{P}_{(\cdot \mid \mathcal{Y})}} \stackrel{?}{=} \frac{\frac{d\mathbb{Q}}{d\mathbb{P}}}{?}$$ I tried searching for ""conditional RN derivative"" and the like but couldn't find an appropriate source. If someone could help me conceptually understand as well as mechanically calculate this I'd very much appreciate it! EDIT: 
To clarify, If I start from $\mathbb{P}$ and $\mathbb{Q}$ and form the conditional measures (from Bayes rule) $\mathbb{P}(\cdot | \mathcal{Y})$ and $\mathbb{Q}(\cdot | \mathcal{Y})$ after gathering some evidence/observations, I know I can write: $$\mathbb{E}_{\mathbb{Q}(\cdot|\mathcal{Y})}(g|\mathcal{Y}) = \int g(\omega) \mathbb{Q}( \cdot | \mathcal{Y})$$ What is the $\tilde{f}$ that makes the following true? $$\mathbb{E}_{\mathbb{Q}(\cdot|\mathcal{Y})}(g|\mathcal{Y}) = \mathbb{E}_{\mathbb{P}(\cdot | \mathcal{Y})}(g \tilde{f} | \mathcal{Y})$$","['probability-theory', 'conditional-expectation', 'measure-theory']"
1371628,"Is this inequality true? If yes, for what functions?","Let $B=B(0,1)\subset \mathbb R^2$. Let $u$ be a radially symmetric differentiable function on $B$ and $v=Ax+b$ be a linear function where $A$ is a $2\times 2$ matrix satisfies $A=-A^T$, and $b=(b_1,b_2)$ is any constant. Define for $a=(a_1,a_2)\in\mathbb R^2$, $|a|=\sqrt{a_1^2+a_2^2}$. I want to prove
$$
\int_B |\nabla u|\,dx\leq \int_B|\nabla u-Ax-b|\,dx. \tag 1
$$
I think this inequality probability is not true but I can not find a counterexample... Please help me to find a counterexample and if possible, what kind of assumptions should I add to $u$ so that equation $(1)$ is true? Thank you!","['multivariable-calculus', 'calculus', 'real-analysis', 'integration']"
1371643,Diagonalize a symmetric matrix,"let $$A = \left(\begin{array}{cccc} 1&2&3\\2&3&4\\3&4&5 \end{array}\right)$$ I need to find an invertible matrix $P$ such that $P^tAP$ is a diagonal matrix and it's main diagonal may have only the terms from the set $\{ 1,-1,0 \}$ I'd be glad if you could explain to me how to solve this. I haven't found the right theorem/algorithm. Thanks.","['linear-algebra', 'diagonalization', 'matrices']"
1371651,I dont see how this algebraic manipulation is valid (trig functions),"So they have two equations: $v_{x}=V_0 \cos\theta-2\Omega V_o \sin\lambda \sin \theta *t$ $v_{y}=-V_0 \sin\theta -2 \Omega V_o \sin\lambda \cos \theta *t$ And they say ""to lowest order in $\Omega$, the above equations are equivalent to"" $v_{x}=V_0 \cos(\theta+2\Omega \sin\lambda t)$ $v_{y}=-V_0 \sin(\theta + 2\Omega \sin\lambda t)$ So... how did they obtain this? What would ""lowest order in omega"" mean here? I've gotten these equations from http://farside.ph.utexas.edu/teaching/336k/Newton/node58.html Thanks.","['algebra-precalculus', 'trigonometry']"
1371667,A ring is a connected set,"I not know how to prove this: For example $$A=\{(x,y,z)\in \mathbb{R^3}\mid 1 < x^2 + y^2 + z^2<2 \}$$ I know that $$\partial A=S(0,1)\cup S(0, \sqrt{2})$$ can that help me at all? I was also thinking about making this set using a function that maps a connected set into this one, but which is continuous. Again, I think that could be done using spherical coordinates, but I do not know how to do this. If anyone knows how, what if the ring in question were ellipses, or a combination of a inner ellipse and outer sphere, or vice versa ?","['calculus', 'continuity', 'functions', 'connectedness', 'general-topology']"
1371668,Equation to place points equidistantly on an Archimedian Spiral using arc-length,"I am looking for a way to place points equidistantly along an Archimedes spiral according to arch-length (or an approximation) given the following parameters: Max Radius,
Fixed distance between the points,
Number of points I have been lurking around on this site for a few days and have found a lot of great advice but am struggling with the syntax of some of the proposed responses (not a native coder but I have had small exposure to Python and Matlab). This example 1 seems to be exactly what I am looking for but I am just struggling with the code, it is not clear to me what variables are used or how the program executes. Example 2 and example 3 were also helpful but I am definitely missing something when it comes to solving the equation numerically as the resulting spiral does not have equal spacing. My goal is to use a spreadsheet (MS Excel) to drive a solid modeling program to generate a hole pattern per the parameters above. Cheers!","['geometry', 'linear-algebra', 'polar-coordinates']"
1371676,On defining homology groups,"I have been trying to understand what homology groups are ""talking about,"" and  now I am wondering if the following works as a definition of homology. But first, some illustration of what it is inspired by: if $D\subset\Bbb C$ is a domain it seems elements of $H_1(D)$ can be interpreted as contours to integrate over, considered with orientation (sign) and multiplicity. If $\oint_\gamma f(z)dz=0$ for all of the functions $f\in{\cal O}(D)$ (i.e. holomorphic $f:D\to\Bbb C$) then we treat $\gamma$ as $0$ in $H_1(D)$. Thus, loops are trivial if they can be contracted to a point within the domain $D$. On the other hand, if a loop goes around a punctured point in $D$, there will be holomorphic functions in ${\cal O}(D)$ with a simple pole at the point and integrating such a function over the contour will yield a nonzero value. There are some more relations satisfied by these contours-with-multiplicity. If $-\gamma$ is the same contour as $\gamma$ but traversed in the opposite direction then $\oint_{-\gamma} f(z)dz=-\oint_\gamma f(z)dz$ and hence $\oint_{\gamma+(-\gamma)}f(z)dz=0$ for all $f$, so we may conclude $\gamma+(-\gamma)=0$. And if $\gamma_1$ and $\gamma_2$ go around two distinct punctures respectively (and no others) with the same orientation then $\gamma_1+\gamma_2$ is equivalent to any contour that loops around both punctures (but no others) in the same direction. Without loss of generality I think we can consider $H_1(D)$ to be generated by simple loops. To generalize to $n$ dimensions, we need vector calculus and differential forms to replace complex analysis. From what I understand, Stokes' and de Rham's theorems say that elements of homology are oriented domains of integration for differential forms counted with multiplicity. (I have not delved more deeply than this intuitive understanding, though.) In that spirit, I want to define my chain groups $C_n({\cal M})$ as $\Bbb Z$-linear combinations of closed, compact, oriented $n$-dimensional submanifolds, subject to the following two relations: If $\cal A, B$ intersect only on their boundary and $\cal A\cup B$ has a consistent orientation then we identify $\cal A\cup B$ with $A+B$. I believe an equivalent condition is that if $\cal A\cap B\ne\varnothing$ and have the same restricted orientation on $\cal A\cap B$ then $\cal A+B=(A\cup B)+(A\cap B)$. If $\cal C,C'$ are the same submanifold but with opposite orientations, then $\cal C'=-C$. One may take the usual topological boundary (in which orientation is inherited) and extend linearly to obtain the boundary maps $\partial_n:C_n({\cal M})\to C_{n-1}({\cal M})$. Then $\partial^2=0$ and we may define the homology group $H_n({\cal M})$ as generated by the boundaryless chains modulo boundaries in the usual fashion ($H_n=\ker(\partial_n)/{\rm img}(\partial_{n+1})$). Does this work as a viable definition? Just as with contours in complex analysis, it seems we can homotope any submanifold and still represent the same element of homology. (For instance, consider a sphere $\cal A$ around the origin in $\Bbb R^3-0$ with orientation chosen to make outward-pointing normals by the right-hand-rule. Say we homotope this to a smaller sphere $\cal B$ within $\Bbb R^3-0$. Then $\cal A-B$ will be the oriented boundary of some oriented annular region and hence $\cal A-B\equiv{\rm 0}~\Rightarrow A=B$ in $H_2(\Bbb R^3-0)$. If we put a nice CW complex structure on $\cal M$, it feels like any submanifold (a generator) in the chain group $C_n({\cal M})$ may be homotoped to one comprised entirely of oriented cells from the complex. Thus, using CW complexes should represent a ""discretization"" of the definition I'm submitting that allows for finite computations to be humanly carried out. Moreever, every compact manifold can be triangulated, so it seems we can also relate it to singular homology. So, anyway, to repeat my question: does this work as a viable definition of homology? Does this idea have a name? Does it seem more natural than other definitions? Are there technical obstacles to relating it to usual definitions of homology? If this doesn't work, why not? One idea offered in chat is that I may not be able to homotope (or isotope, whatever may be necessary to make things work out) two knots in a way that can be broken apart into annuli (if annuli bound the before/after submanifolds, that would make them all equal in $H_1$). The moral of that lesson is that we might need to introduce a third relation in $C_n({\cal M})$, that isotopic submanifolds are equal.","['homology-cohomology', 'differential-geometry', 'algebraic-topology']"
1371678,"Maximize $J[f] = \int_\mathbb{R} f(x)\log f(x)\,dx$ over smooth surjections $f : \mathbb{R}\to (0, \alpha)$ subject to $\int_\mathbb{R} f(x)\,dx = 1$.","Maximize $J[f] = \int_\mathbb{R} f(x)\log f(x)\,dx$ over smooth surjections $f : \mathbb{R}\to (0, \alpha)$, where $\alpha$ is a real number, subject to $\int_\mathbb{R} f(x)\,dx = 1$. I have no idea how to do this. I came across this while I was pondering some differential entropy problems.","['calculus', 'integral-equations', 'functions', 'functional-equations', 'calculus-of-variations']"
1371682,Wanted : for more formulas to find the area of a triangle?,"I know some formulas to find a triangle's area, like the ones below. Is there any reference containing most triangle area formulas? If you know more, please add them as an answer $$s=\sqrt{p(p-a)(p-b)(p-c)} ,p=\frac{a+b+c}{2}\\s=\frac{h_a*a}{2}\\s=\frac{1}{2}bc\sin(A)\\s=2R^2\sin A \sin B \sin C$$ 
Another symmetrical form is given by :$$(4s)^2=\begin{bmatrix}
a^2 &  b^2 & c^2  
\end{bmatrix}\begin{bmatrix}
-1 & 1  & 1\\ 
1 &  -1 & 1\\ 
1 & 1 & -1
\end{bmatrix} \begin{bmatrix}
a^2\\ 
b^2\\ 
c^2
\end{bmatrix}$$ Expressing the side lengths $a$, $b$ & $c$ in terms of the radii $a'$, $b'$ & $c'$ of the mutually tangent circles centered on the triangle's vertices (which define the Soddy circles)
$$a=b'+c'\\b=a'+c'\\c=a'+b'$$gives the paticularly pretty form $$s=\sqrt{a'b'c'(a'+b'+c')}$$
If the triangle is embedded in three dimensional space with the coordinates of the vertices given by $(x_i,y_i,z_i)$ then $$s=\frac{1}{2}\sqrt{\begin{vmatrix}
y_1 &z_1  &1 \\ 
 y_2&z_2  &1 \\ 
y_3 &z_3  &1 
\end{vmatrix}^2+\begin{vmatrix}
z_1 &x_1  &1 \\ 
 z_2&x_2  &1 \\ 
z_3 &x_3  &1 
\end{vmatrix}^2+\begin{vmatrix}
x_1 &y_1  &1 \\ 
 x_2&y_2  &1 \\ 
x_3 &y_3  &1 
\end{vmatrix}^2}$$
When we have 2-d coordinate $$ s=\frac{1}{2}\begin{vmatrix}
x_a &y_a  &1 \\ 
x_b &y_b  &1 \\ 
x_c &y_c  & 1
\end{vmatrix}$$ In the above figure, let the circumcircle passing through a triangle's vertices have radius $R$, and denote the central angles from the first point to the second $q$, and to the third point by $p$ then the area of the triangle is given by:
$$ s=2R^2|\sin(\frac{p}{2})\sin(\frac{q}{2})\sin(\frac{p-q}{2})|$$","['area', 'geometry', 'triangles', 'trigonometry', 'reference-works']"
1371686,A question about a curve on the surface of a sphere,"Let the three points A,B,C be the vertices of a moving spherical triangle on the surface of a sphere. The triangle moves so that while the vertices A,B remain fixed, the angle BCA at the vertex C stays constant. What is the locus of the moving vertex C? Is there a special name for the curve traced out by C? If A,B,C were the vertices of a plane triangle, the corresponding locus would be the arc of a circle. I have made some calculations, which-if they do not contain errors-lead me to believe that, in the spherical case, the locus I am seeking is not the arc of a small circle (on the sphere). But, if so, I do not know what type of curve it is.",['geometry']
1371696,Sum of Bell Polynomials of the Second Kind,"A problem of interest that has come up for me recently is solving the following. $$\frac{d^{n}}{dt^{n}}e^{g(t)}$$ There is a formula for a general $n$ -th order derivative of a composition as shown above: http://mathworld.wolfram.com/FaadiBrunosFormula.html In terms of the Bell Polynomials, we can write $$\frac{d^{n}}{dt^{n}}e^{g(t)}=e^{g(t)}\sum_{k=0}^{n}B_{n,k}(g'(t),g''(t),\cdots)$$ And the Bell polynomials of the second kind are shown in the Wolfram link above. I am wondering if there is a closed-form solution for the sum of the series of Bell Polynomials.","['bell-numbers', 'calculus', 'exponentiation', 'sequences-and-series', 'polynomials']"
1371717,Relation between real roots of a polynomial and real roots of its derivative,"I have this question which popped in my mind while solving questions of maxima and minima. First Case :Let $f(x)$ be an $n$ degree polynomial which has $r$ real roots.
Using this can we say anything about the number of real roots of $f'(x)$? Second Case :Suppose, $f(x)$ has all  $n$ real roots. Then will all of its derivatives also have all real roots? Also, if any of its derivatives do not have all real roots, then will $f(x)$ also have not all real roots?
If the above is true then what about its converse? Comment Case :For the third case:Suppose f'(x) is a 5 degree polynomial with 3 real roots.Then f(x) will be a 6 degree polynomial.(correct me if I am wrong).What are the possible no. of roots that f(x) can have(3,4,5 etc.?).Basically I am asking for an example.Also it would be great if you follow all cases with an example like in the 4th case.","['polynomials', 'calculus', 'roots']"
1371763,Proof of Sobolev imbedding theorem in Adams,"I am struggling to understand the proof of the Sobolev embedding theorem given in Sobolev Spaces by Adams. Specifically section 4.25 (2003 edition). The aim is to prove $W^{m,1}(\Omega) \to L^{q}(\Omega_{k})$ for $1 \le q \le \frac{k}{n-m}$, where $k>n-m$, and $n \gt m$ $\Omega \subset \mathbb{R}^{n}$ is open and satisfies the cone condition and $\Omega_{k}$ is the intersection of $\Omega$ with a k-dimensional plane in $\mathbb{R}^{n}$. Lemma 4.24 gives $W^{m,1}(\Omega) \to W^{m-1,p}(\Omega)$ for $1\le p \le \frac{n}{n-1}$ Since $k \gt n-m$, we have $k \ge n-m+1 \gt n-(m-1)r$ $\forall r \gt 1$ The proof (with some obvious misprints) now claims (from previous parts of the proof) that 
$W^{m-1,r}(\Omega) \to L^{q}(\Omega_{k})$ $\forall 1 \le q \le r^{*}$
But I can only see that this is true for $r \le q \le r^{*}$. Hence finally I get 
$W^{m,1}(\Omega) \to L^{q}(\Omega_{k})$ for $1 \lt q \le \frac{k}{n-m}$. Am I missing something very obvious?","['sobolev-spaces', 'functional-analysis']"
1371784,Find $p_{ij}^{(n)}$ for the transition matrix,"Let
  $$P=\begin{bmatrix}\frac{1}{3}&0&\frac{2}{3}\\\frac{1}{3}&\frac{2}{3}&0\\\frac{1}{3}&\frac{1}{3}&\frac{1}{3}\end{bmatrix}$$
  find $p_{11}^{(n)},p_{12}^{(n)},p_{13}^{(n)}$ Since the characteristic function is $$-\mu^3+\frac{4}{3}\mu^2-\frac{1}{3}\mu=0$$
the eigenvalues are $$\mu_0=1,\mu_1=\frac{1}{3},\mu_2=0$$
Here the problem starts, from what I understood from the book, we need to found three constants such that $$p_{ij}^{(n)}=\mu_0^nA+\mu_1^n+\mu_2^nC=A+\left(\frac{1}{3}\right)^nB$$ But how can I find the values of A and B?","['self-learning', 'probability', 'stochastic-processes', 'matrices']"
1371823,A matrix as a point in $\mathbb{R}^{nm}$,"I just had a really quick question to ask. I was reading a book on linear algebra and have just been trying to wrap my head around what exactly a matrix represents. At one point, the book said ""In a more formal sense an $m × n$ matrix $A$ can be thought of as a point in $\mathbb R^{nm}$, with the agreement that the entries are ordered into rows and columns rather than a single row or single column."" I didn't really understand what this meant. What is a point in $\mathbb R^{nm}$ from an intuitive/not so abstract perspective? Does it mean literally the vector space $\mathbb R^{n × m}$ e.g a $2 × 3$ matrix represents a point in $\mathbb R^{6}$ except instead of the 6-tuple written with 6 entries in one row or 6 entries in one column they are written in both rows and columns?","['linear-algebra', 'intuition', 'matrices']"
1371872,"Cubic Planar Graphs have $2^m-1$ Hamilton Cycles, contradicting Bosak...","I looked at the symmetric difference of hamilton cycle (HC) in cubic planar graphs and found that, together with the empty graph, they build a subgroup of the abelian group $\Omega$ of symmetric differences of cycles. This is easily illustrated by the HCs of Frucht graph: Check yourself that the symmetric difference of any pair gives the third HC!
(Also interesting to note that the set of cuts of pairs builds a $3$-edge coloring of the graph!) Now the cycle space is spanned by the faces $f_k\in F$ of $G$ and is kind of a power set of faces, since in the total symmetric sum, you turn on/off a certain face. This results in a $F$ dimensional vector space over $\mathbb Z_2$, which has $2^F$ elements, which are the group elements of $\Omega$. Now I wonder if it is true in general, that the number of HCs plus $1$ divides $2^F$, since the subgroup is normal, even central. As shown in a reference here we will always have three HCs in cubic graphs. Fine, but this opposes what I read somewhere else (trying to provide a reference) that bicubic graphs always have four HCs. Or don't these four build a single subgroup, but rather a set of subgroups? What happens in the bicubic case and is it true for cubic ones that they always have $2^m-1$ HCs? I'm confused,  since I found this quote ""Every cubic bipartite graph has an even number of Hamilton cycles ."" from J. Bosak, Hamiltonian lines in cubic graphs,Theory of Graphs, International Symposium, Rome, July 1966 , Gordon & Breach, New York, (1967), 35–46. for example here , contradicting my assumption...","['abelian-groups', 'graph-theory', 'group-theory', 'finite-groups']"
1371888,Smooth maps preserve dimension,"I stumbled over a useful consequence, that is apparently wrong for only continuous maps.
Imagine $A \subset \mathbb{R}^{n-1}$ is a compact set and $F : \mathbb{R}^{n-1} \rightarrow S^{n}$ a smooth map, then we cannot have $F(A) = S^{n}.$ In other words: Smooth maps must preserve the dimension somehow. Does anybody know how to show this?","['calculus', 'real-analysis', 'differential-topology', 'analysis', 'differential-geometry']"
1371889,Evaluating line integral technique.,I'm trying to do a few questions set by a lecturer on line integrals. I was struggling with a few of them and decided to look at the solutions: Often when $$\int_C \vec{F}\cdot d\vec{r}$$ is tricky to evaluate he will say $$\int_C~ \vec{F}\cdot d\vec{r}=\int_C ~(\vec{F}-\nabla f)\cdot d\vec{r}$$ I have never seen this method before and don't understand what he is doing how the two are equal or even where the function $f$ comes from. Could anyone explain in the simplest way possible or give me something to research so I know what is going on. Thanks.,['multivariable-calculus']
1371905,"Proving $f(x)=1/x$ on $(0,1 )$ is not uniformly continuous","My questions are about the reasoning made in the note http://folk.uib.no/st00895/MAT112-V12/unif-kont.pdf (which is in Norwegian). To prove that $f(x)=\frac{1}{x}$ is not uniformly continuous, the authors use the following ""result"" (Sats 2.12 in the note, which I translate below): Result 2.12: If for every $h>0$ we have that $|f(x+h)-f(x)|$ is unbounded on $I$, then $f$ is not uniformly continuous on $I$. Proof: The result follows directly from the definition of uniform continuity. In Example 2.14 (Eksempel 2.14), the authors look at $$|f(x+h)-f(x)|=\left|\frac{1}{x+h}-\frac{1}{x}\right|=\left|\frac{h}{x(x+h)}\right|.$$
They then claim that the above quantity is not bounded for any $h>0$, since $$\lim_{x\rightarrow 0}\left|\frac{h}{x(x+h)}\right|=\infty.$$ Question 1: Is it not possible to choose $h=x^2$, thereby obtaining $$\frac{h}{x(x+h)}=\frac{1}{\frac{x}{h}(x+h)}=\frac{1}{x(1/x+1)}=\frac{1}{x(1/x+1)}=\frac{1}{1+x}\rightarrow1 \text{ as }x\rightarrow 0.$$ Therefore, |f(x+h)-f(x)| is not unbounded, so we cannot use the result ""Result 2.12"". Is my argumentation correct?? Is it OK to choose $h$ like I have done? Question 2 : However, it seems correct to me that my argumentation is all you need to prove that  $f(x)=\frac{1}{x}$ is not uniformly continuous on (0,1). Here $x_1=x,x_2=x+x^2$, so that $|x_1-x_2|$ can be made arbitrarily small. However $|f(x_1)-f(x_2)|=1$, which stays the same regardless of how small we make $|x_1-x_2|$. Is this correct?","['uniform-continuity', 'real-analysis']"
1371911,What is the value of this function?,"Consider the three-variable function defined at the following way for all natural numbers $n,x,y$ : $f(0,x,y) = x+y $ $f(n,x,0) = x$ $f(n,x,y) = f(n-1, $ $ $ $f(n,x,y-1) , $ $ $ $f(n,x,y-1)+y ) $. For some values calculating the function is easy and for others I am having a very hard time...
Can someone tell me what are the exact values of  $f(2,1,3),f(3,3,3), f(2,3,1)$?
If possible I would also like to know how could calculate it more efficiently.","['computational-mathematics', 'functions']"
1371921,What is the equation of a 3D line which represents the intersection between two 3D planes?,"The intersection defined by the two planes  $v \bullet \begin{pmatrix} 8 \\ 1 \\ -12 \end{pmatrix} = 35$
and
$v \bullet \begin{pmatrix} 6 \\ 7 \\ -9 \end{pmatrix} = 70$
is a line. What is the equation of this line? This is what I have so far: I set $v = \begin{pmatrix} a \\ b \\ c \end{pmatrix}$. I was able to simplify both LHS of the two given equations to: $8a+b-12c = 35$ $6a+7b-9c = 70$ I could find the values of $a, b, c$, but I don't know if it will be helpful. How can I find the equation of the line of intersection?","['calculus', 'matrices', 'algebra-precalculus', 'geometry', 'trigonometry']"
1371950,infinite-order elements of $Out(\widehat{F_2})$,"Let $\widehat{F_2}$ be the pro-$\ell$ completion of the free group of rank 2, where $\ell$ is some prime. Every outer automorphism of $F_2$ induces an outer automorphism of $\widehat{F_2}$, hence an injection $Out(F_2)\rightarrow Out(\widehat{F_2})$. Of course in $Out(F_2)$ there are plenty of automorphisms of finite order. My question is: Does every automorphism of $Out(\widehat{F_2})$ of finite order lie in the closure $\overline{Out(F_2)}$ inside $Out(\widehat{F_2})$?","['algebraic-geometry', 'group-theory']"
1371971,Why does the Hessian work?,"I am working through Leonard Susskind's The Theoretical Minimum (on physics, but it also includes some maths). In particular, there is an interlude for which he discusses partial differentiation. He discusses a surface, a function of two variable. Let $A=f(x,y)$ \begin{pmatrix}
 \frac{\partial^2A}{\partial x^2} & \frac{\partial^2A}{\partial x \partial y} \\
 \frac{\partial^2A}{\partial y \partial x} & \frac{\partial^2A}{\partial y^2}
\end{pmatrix} I understand individually what the partial derivatives are doing (though shouldn't the second and third entries into the matrix be equivalent?). I can also accept that they can be arranged into a matrix. However, he then says If the determinant and the trace are positive, the point is a local minimum. If the determinant is positive and the trace negative, the point is a local maximum. If the determinant is negative, the point is a saddle point. I'm sure I could apply these rules, but why do these rules work?","['calculus', 'matrices', 'hessian-matrix', 'scalar-fields', 'multivariable-calculus']"
1371974,A question regarding a proof in Ahlfors,"Ahlfors says the following: if $f (z) $ is analytic on a disc, then its integral along any closed path contained in the disc is $0$. The proof for this is the following: Let $F (z)=\int_\sigma  {f (z)dz}$ where $\sigma$ is a rectangular path that starts at a fixed point $z_0$ (they say in the middle of the disc),  and ends at $z$. Rectangular path in the sense that if we have a path from $(x_0, y_0) to (x, y)$, then we move from $(x_0, y_0)\to (x, y_0)\to (x, y)$, or $(x_0, y_0)\to (x_0, y)\to (x, y)$. So anyway, we have $F (z)= \int {f (z)dx+if (z)dy}$. Moving along the first rectangular path and differentiating wrt y, we get $dF/dy=if (z)$. Similarly, moving along the second path, we get $dF (z)/dx =f (z)$. This shows that $F (z)$ is analytic. We also have the fact that $\int {f (z) dz} $ is an exact differential, and hence dependant only on its end points. This proves that the integral on any closed path will be $0$. My question is that this proof works for any function $f (x, y)$ integrable on all rectangular paths, and in any open set (not just a disc). So what role does the analyticity of $f (z)$ and the shape of the disc have to play in this proof?",['complex-analysis']
1372001,Show that $ \tan (A + \theta) $ can be simplified to $- \cot \theta$ as A tends to $\frac{\pi}{2}$,"So far I have used the identity, $$\tan\left(\frac{\pi}{2} + \theta\right) = \frac{\tan A + \tan \theta}  {1 - \tan A \tan \theta}$$ As $A  \to \frac{\pi}{2}$, $\tan A \to \infty$, so my reasoning is, $\infty + \tan \theta = \infty$, which gives: $$\frac{\infty}  {- \infty  \tan \theta}$$ $\infty$ cancels to $-1$ leaving $\frac{-1}{\tan \theta}$ as the answer, or $-\cot \theta$ My approach seems a bit iffy, and I was hoping someone could confirm if this is right or not. Thanks",['trigonometry']
1372025,martingale and expectation,"The following is an old exam problem: Let $\{X_n\}$, $n\geq0$, be a process adapted to a filtration $F_n$. Prove that $(X_n,F_n)$ is a martingale, if and only if for all bounded $F_n$-stopping time $\tau$, $EX_{\tau}=EX_0$ holds. I know if $X_n$ is a martingale, then $X_{\tau}$ is a martingale by optional stopping theorem. Hence $E(X_{\tau})=E(E(X_{\tau}|F_{0}))=E(X_0)$. However I have trouble connecting the expectation to the conditional expectation for the other direction. It seems like it needs some smart way to define $\tau$ while I haven't thought of one. Thanks for any help.",['probability']
1372026,"Sum of a Finite Sequence of Terms:$18, 25, 32, 39, ... ,67$","Ok I know this question maybe too easy. What is the sum of a finite sequence of terms? $$18, 25, 32, 39, ... ,67$$ The answer is $340$. I use the formula: $${ S = \frac{n}{2} \times (a_1 + a_n) }$$ $${ n = \frac{a_n-a_1}{7} }$$ whrere $7$ is the difference between every iteration I get $297.5$ Am I missing something or is the problem set wrong? Any Hint?","['sequences-and-series', 'algebra-precalculus']"
1372032,"Given the differential equation, how to solve the y function with x as the independent variable?","$y\frac{dy}{dx} = x(y^4 + 2y^2 + 1)$ $y = 1$ when $x = 4$ I tired to integrate by substitution, but it doesn't seem to work out.","['ordinary-differential-equations', 'integration']"
1372044,Show that there is always a way to achieve det(A) > 0,"a) Assume that $(a_1, ..., a_9)$ are different positive numbers. Let us make a $3 \times 3$ matrix $A_s$ by placing them arbitrarily into $9$ positions available. Show that there is always a way to assemble them so that $\det(A_s) > 0$. b) Assume now that some of $a_i, i =1,\dots,9$ are equal and the total number of different values taken by the $a_i$ is $N \in \{1,2,...,9\}$.  What is the minimal $N$ which guarantees the existence of $A_s$ as above with $\det(A_s) >0$? Give a proof. For part (a), I tried to show that, with row operations, $\det(A_s)$ can never equal $0$, so that the matrix is invertible, with determinant either negative or positive. Then if the determinant is positive, the proof is complete; if not, then simply interchange any two rows, which negates the determinant, giving a positive determinant as required. However, this proof doesn't work. Using just the numbers $1 \dots 9$, then $(7,8,9)$ is in the span of $(1,2,3)$ and $(4,5,6)$. Since the question is asking to show that there is always a way, i.e., there exists  a way to achieve $\det(A_s)>0$, I feel that I should work on a contradiction, and assume first that there is no way to achieve it. Perhaps I can use the fact that $\rm{trace} \, A_s$ must be positive, but I don't see it right now. Any hints would be greatly appreciated. Thanks.","['determinant', 'linear-algebra', 'trace', 'permutations']"
1372076,Change of variable for a limit inside Lebesgue integration?,"To calculate $\lim\limits_{n \to \infty } \int_A \cos (nx) \, dx $ where $A$ is a compact set, say $[0,1]$, the objective is to show the integral $\rightarrow 0$. My question is can I first exchange the integration and limit and then do the change of variable ? Since $| \cos (nx)| \le 1$ and $1$ is measurable on $A$, so $\lim\limits_{n \to \infty } \int_A \cos (nx) \, dx  = \int_A \lim\limits_{n \to \infty } \cos (nx) \, dx $ by dominated convergence theorem. If we can do change of variable, then $t = nx$ and we have $$\int\limits_A \lim\limits_{n \to \infty } \cos (nx) \, dx  = \int\limits_A \lim\limits_{n \to \infty } \cos (t)\frac{1}{n} \, dt =0.$$ But I feel it has problem. If this is not right, what is the correct way to solve the problem? Added :
I realized this is wrong by Michael Hardy's comment. Now can I first do exchange of variable and then do exchange of limit and integration? $\mathop {\lim }\limits_{n \to \infty } \int_A {\cos (nx)dx}  = \mathop {\lim }\limits_{n \to \infty } \int_A {\frac{{\cos (t)}}{n}dt}  = \int_A {\mathop {\lim }\limits_{n \to \infty } \frac{{\cos (t)}}{n}dt}  = 0$","['real-analysis', 'measure-theory']"
1372084,Determine the null space of a linear map,"Let $P_k(x)$ denote the space of polynomials of at most degree $k$. Let $D$ denote differentiation with respect to $x$. Regard the differential operator $L: P_k\rightarrow P_k$ such that $L=\frac{1}{n!}D^n+\frac{1}{(n-1)!}D^{n-1}+...+D+I$ . If $k\leq n$, find the dimension of the kernel of $L-T$ where $T:P_k\rightarrow P_k$ is given by $T(p(x))=p(x+1)$. To minimize the amount of calculation, I start with finding the matrix representation of $D$ w.r.t $\{1,x,x^2,...,\}$ basis, which is a matrix with $1,2,3,..,n$ on the super diagonal and 0 everywhere else. Then should I find $D^k$ for each $k$? The computation seems to be insane. Are there any easier way? Any shortcuts?",['linear-algebra']
1372092,Sum of an infinite series $(1 - \frac 12) + (\frac 12 - \frac 13) + \cdots$ - not geometric series?,"I'm a bit confused as to this problem: Consider the infinite series: $$\left(1 - \frac 12\right) + \left(\frac 12 - \frac 13\right) + \left(\frac 13 - \frac 14\right) \cdots$$ a) Find the sum $S_n$ of the first $n$ terms. b) Find the sum of this infinite series. I can't get past part a) - or rather I should say I'm not sure how to do it anymore. Because the problem asks for a sum of the infinite series, I'm assuming the series must be Geometric, so I tried to find the common ratio based on the formula $$r = S_n / S_{n-1} = \frac{\frac 12 - \frac 13}{1 - \frac 12} = \frac 13$$ Which is fine, but when I check the ratio of the 3rd and the 2nd terms: $$r = \frac{\frac 13 - \frac 14}{\frac 12 - \frac 13} =\frac 12$$ So the ratio isn't constant... I tried finding a common difference instead, but the difference between 2 consecutive terms wasn't constant either. I feel like I must be doing something wrong or otherwise missing something, because looking at the problem, I notice that the terms given have a pattern: $$\left(1 - \frac 12\right) + \left(\frac 12 - \frac 13\right) + \left(\frac 13 - \frac 14\right) + \cdots + \left(\frac 1n - \frac{1}{n+1}\right)$$ Which is reminiscent of the textbook's proof of the equation that yields the sum of the first $n$ terms of a geometric sequence, where every term besides $a_1$ and $a_n$ cancel out and yield $$a_1 \times \frac{1 - r^n}{1 - r}.$$ But I don't know really know how to proceed at this point, since I can't find a common ratio or difference.","['summation', 'sequences-and-series']"
1372144,different definitions of Hopf algebras,"(i). In the book Algebraic Topology, A. Hatcher, p. 283 ， the notion Hopf algebra is defined as follows: (ii). However, in the book Bialgebras and Hopf algebras, J.P. May , the notion Hopf algebra is defined as follows: Question: why the definition in (ii) is much more complicated than the definition in (i)? Are the two definitions of Hopf algebra in (i) and (ii) equivalent or different? I do not understand the definition in (ii). Another question: for an $H$-space (we can strengthen to topological monoid up to homotopy) $X$ and coefficient ring $R$, will the homology
$$
H_*(X;R)
$$
be a Hopf algebra according to the definition in (ii)?","['ring-theory', 'homology-cohomology', 'abstract-algebra', 'hopf-algebras', 'algebraic-topology']"
1372150,Help with $\int_0^\infty {\frac{{\sin t}}{{{e^t} - x}}dt} = \sum\limits_{n = 1}^\infty {\frac{{{x^{n - 1}}}}{{{n^2} + 1}}} $,The question is to show $\int_0^\infty  {\frac{{\sin t}}{{{e^t} - x}}dt}  = \sum\limits_{n = 1}^\infty  {\frac{{{x^{n - 1}}}}{{{n^2} + 1}}} $ for $-1<x<1$. The integration is a Lebesgue integration. I have worked on this for half an hour but I still don't know how to solve it except for I can brutally show the Taylor expansion of the left-hand side is consistent with the right-hand side. Hope someone can help on this. Thank you!,"['real-analysis', 'measure-theory']"
1372166,A = UL factorization [duplicate],This question already has an answer here : Using permutation matrix to get LU-Factorization with $A=UL$ (1 answer) Closed 8 years ago . How do I calculate $A=UL$ factorization where $U$ is upper triangular matrix with 1's along the diagonal and $L$ is lower triangular matrix? How is this similar to the $LU$ factorization?,['matrices']
1372176,Limit of the sequence $\sin \left( {2\pi \sqrt {{n^2} + n} } \right)$,I would like to calculate the following limit: ${\lim _{n \to \infty }}\sin \left( {2\pi \sqrt {{n^2} + n} } \right)$ I am not sure if this limit exists...,['limits']
1372183,Prove that $f'(0)=L$.,"Let $f$ be continuous at $0$. Suppose $\displaystyle \lim _{x\rightarrow 0} \frac{f(2x)-f(x)}{x} =L$. Prove that $f'(0)=L$. My Work: $\displaystyle \Bigg|\frac{f(x)-f(0)}{x}-L\Bigg|=\Bigg|\frac{f(x)-f(2x)+f(2x)-f(0)}{x}-L\Bigg|$ $\displaystyle \leq \Bigg|\frac{f(x)-f(2x)}{x}-L\Bigg|+\Bigg|\frac{f(2x)-f(0)}{x}\Bigg|$. Since $f$ is continuous at $0, |f(2x)-f(0)|$ goes to $0$ as $x$ goes to $0$. Now I want to get rid of $|x|$ of the second term. How can I do it? Can somebody please help me?","['continuity', 'calculus', 'real-analysis', 'derivatives']"
1372195,How to construct examples of functions in the Spaces of type $\mathcal{S}$,"There are $3$  $\mathcal{S}$-type Spaces, namely $\mathcal{S}_\alpha\:,\: \mathcal{S}^\beta\:,\:\mathcal{S}_\alpha^\beta$. They are defined by: $\mathcal{S}_\alpha: |x^k\varphi^{(q)}(x)|\le C_qA^kk^{k\alpha}\qquad (k,q=0,1,2,...)$ $\mathcal{S}^\beta: |x^k\varphi^{(q)}(x)|\le C_kB^qq^{q\beta}\qquad (k,q=0,1,2,...)$ $\mathcal{S}_\alpha^\beta: |x^k\varphi^{(q)}(x)|\le CA^kB^qk^{k\alpha}q^{q\beta}\qquad (k,q=0,1,2,...)$ where the constants $A,B,C_k,C_q$ depend on $\varphi \:\&\:\alpha+\beta\ge1$. In the first space we have functions which are rapidly decaying as $|x|\to \infty$. The second space imposes conditions on the growth of derivatives of these functions as $|x|\to \infty$. The third space $$\mathcal{S}_\alpha^\beta\subset\mathcal{S}_\alpha\cap \mathcal{S}^\beta$$In general the converse also holds which is a classical result due to Kashpirovsky. I want to construct examples to get a better understanding of these definitions. From the definition it is clear that every function in these spaces is at least $C_c^\infty$. So intuitively the first thing that comes to my mind is Gaussian-like functions. Now say I consider $\mathcal{S}_1^2(\mathbb{R})$. Which type of functions belong to this space ? How to come up with suitable constants ? Reference: Generalized Functions, Volume 2 by I.M.Gelfand and G.E. Shilov","['gelfand-shilov-spaces', 'real-analysis', 'functional-analysis']"
1372224,Which graph with an automorphism group isomorphic to the quaternion group $Q_8$ minimizes $|V|+3|E|$?,"In Symmetries of partial Latin squares , it is shown that for any graph $\Gamma=(V,E)$ with automorphism group $G$, there is a partial Latin square with $|V|+3|E|+49$ filled cells whose autotopism group is isomorphic to $G$. Hence my question... Which graph with an automorphism group isomorphic to the quaternion group $Q_8$ minimizes $|V|+3|E|$? The answer to the question Smallest graph with automorphism group the quaternion $8$-group, $Q_8$ gives an example of a 16-vertex 48-edge graph with automorphism group $Q_8$.  It could be one that minimizes $|V|+3|E|$. I'm looking to find partial Latin rectangles that (a) have symmetry groups isomorphic to a given group $G$, and (b) have low weight [number of filled cells].  The quaternion group is among the groups of smallest order I have yet to compute examples.  The answer to this question will give an upper bound on the weight.","['graph-theory', 'latin-square', 'combinatorics', 'algebraic-graph-theory']"
1372252,Is the subset of squares of a group a subgroup?,"Let $G$ be a group and
$$S:=\{g^2 \mid g\in G\}$$
the subset of all squares of $G$. Is $S$ then a subgroup? I would say no since I don't see why $g^2h^2$ should be a square in the non-abelian case. But I didn't find any counter-example. Even if we take $G=S_4$ (a very non-abelian group) I computed $S=A_4$.",['group-theory']
1372267,Characterisation of the squares of the symmetric group,"I found out that for $n\le 4$ we have $S_n^2=A_n$ with $G^2$ defined by
$$G^2:=\{g^2 \mid g\in G\}$$
for any group $G$. Surely we have $S_n^2\subseteq A_n$ for all $n\in\mathbb N$. Is there a characterisation of the squares of the symmetric group? When is $S_n^2$ a group and what does it look like in general? Edit: So far we found out, that $S_n^2$ generates $A_n$ because each 3-cycle is a square (since we have $g=g^{-2}$) and $A_n$ is generated by the 3-cycles. So we simplified the original question to the question for which $n$ we have $S_n^2=A_n$ and how to characterise the elements which a missing in case we don't have the equality.","['group-theory', 'permutations']"
1372268,Variance of least square estimator,I have two random variables X and Y with $X\sim Exp(a)$ and $Y \sim Exp(\frac a2)$. I have a least square estimator $a=\frac {2x +y}{2.5}$. I want to calculate the variance of the estimator and to do this I'm trying to find the joint distribution (to calculate $E[XY]$). Is there a way of knowing if they are independent? It confuses me that they have different means.I tried to use the moment generating function on E[XY] but I'm not really sure how to go about it.,"['statistics', 'statistical-inference']"
1372293,How many ways I can put $k$ bishops on $n\times n$ chessboard?,Is there a formula how to count in how many ways I can put $k$ bishops on $n\times n$ chessboard such that no two bishops threaten each other?,"['recreational-mathematics', 'combinatorics']"
1372318,homogeneous first order differential equation,"is there a method to solve $$\dfrac{dy}{dx} = f(x,y)$$, where $f(x,y)$ is a homogeneous function. I found some examples like $f(x,y)=(x+y)^2$ where it can be solved after converting it to Ricatti's equation. thanks",['ordinary-differential-equations']
1372353,Ito's formula and Infinitesmal generator,"Consider an Ito process $$
dX_t = \sigma_t dB_t
$$ where $\sigma_t$ is a two-state continuous-time Markov chain with state space
$\{ \sigma_1, \sigma_2 \}$ that switches state with Poisson intensity $\lambda$ and $B_t$ is standard Brownian motion. Questions: What does Ito's formula for $X_t$ looks like? Is there a formula to compute the quadratic variation $[X, X]_t$ when $X$ is an integral against a semi-martingale...? What is the infinitesmal generator $A$, defined for sufficiently nice $f$ by $$
Af(x) = \lim_{s \rightarrow 0} \frac{E^x[f(X_{t+s})] - f(x)}{s}?
$$ Is the correlation property between $\sigma_t$ and $B_t$ relevant for these questions?","['probability-theory', 'stochastic-calculus', 'stochastic-integrals', 'stochastic-processes', 'reference-request']"
1372360,Algebraically flavoured functional analysis book,"I'm looking for a book on functional analysis that would suit someone who is more algebraically/geometrically oriented and seeks to learn the subject with the goal of using it later for geometric analysis and/or topological k-theory (and maybe noncommutative geometry in the far future). What would be a good book fitting this description? I have the relevant background in basic measure theory, complex analysis and linear algebra.","['book-recommendation', 'reference-request', 'functional-analysis']"
1372370,Matrix Exponential and Logarithm,"Consider the following matrix $A$: $A = \begin{bmatrix}
    \cos^2(1) & -\sin(2) & \sin^2(1) \\
    \cos(1)\sin(1) & \cos(2) & -\cos(1)\sin(1) \\
    \sin^2(1) & \sin(2) & \cos^2(1)\\
\end{bmatrix}$ I want to find a matrix $B$ such that $\exp(B)=A$ (or essentially finding $\log(A))$. Is there a systematic way to approach these kinds of problems? I was thinking of using some properties involving diagonalization to get to the answer, which should be (obtained using Mathematica): $B = \begin{bmatrix}
    0 & -2 & 0 \\
    1 & 0 & -1 \\
    0 & 2 & 0\\
\end{bmatrix}$ However, I'm not sure how to get to this result. Thank you for your help.","['linear-algebra', 'matrix-calculus', 'matrices']"
1372391,Sphere packing question,"I'm a secondary school maths teacher, currently on my holidays working through some maths problems for fun. Here is one I have done, but it felt too easy, so if you could check if there's any mistakes, I'd be grateful. Suppose there are 8 spheres, radius r. They are positioned touching each other such that the centre points of each sphere would join to make a cube. The question is ""What is the largest possible radius of a ninth sphere in the centre of this arrangement?"" I think I have answered it, but I would be grateful for any input. I don't know how to draw this digitally, so I hope my description is sufficient. So far I have imagine the problem in 2d... four circles touching to form a square. The radius is r. The square created from the centre points will have side length 2r, therefore using pythag the diagonal is $2r\sqrt2$. Half of this will give you the distance from the centre of a circle to the centre of the arrangement: $r\sqrt2$. Therefore, subtract the initial radius, r and you have the maximum possible radius of the smaller circle: $r\sqrt2-r=r(\sqrt2 - 1)$. Taking to 3D, the cube created by the centres 8 spheres will have a diagonal of $2r\sqrt2$ along the base and height $2r$, so again using pythag, the longest diagonal of the cube will be: $\sqrt((2r\sqrt2)^2+(2r)^2)=\sqrt(8r^2 + 4r^2)=2r\sqrt3$ Divide this by 2 to find the distance from centre-of-sphere to centre-of-cube: $r\sqrt3$ Subtract the initial radius to find radius of smaller sphere: $r(\sqrt3 - 1)$","['geometry', 'spheres', '3d']"
1372405,Differentiate $y^2-2xy+3y=7x$ w.r.t. $x$. Hence show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx}).$,"Differentiate $y^2-2xy+3y=7x$ w.r.t. $x$. Hence show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx}).$ I differentiated $y^2-2xy+3y=7x$ w.r.t. $x$ and got: $$\frac{dy}{dx}=\frac{7+2y}{2y-2x+3}$$ Differentiating one more time, I get: $$\frac{d^2y}{dx^2}=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)^2}$$ Multiplying by $(2y-2x+3)$ I get: $$\frac{d^2y}{dx^2}(2y-2x+3)=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)}$$ Now if I understand correctly the question wants me to show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx})$ So from what I already got, I guess I need to show that $$\frac{dy}{dx}(4-2\frac{dy}{dx})=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)}$$ But I don't know how to do this and I'm not sure if I've been following the question correctly. I reckon I might be over-complicating things too. Grateful for any hints/guidance.","['implicit-differentiation', 'calculus', 'derivatives']"
1372406,"What properties do the rings of infinite, upper-triangular matrices have?","I'm very familiar with the ring of $n\times n$ matrices over a field , the ring of $n\times n$ upper triangular matrices over a field , and the ring of infinite column-finite matrices over a field . But until now, I haven't asked myself about infinite upper triangular matrix rings over a field (sides indexed by some infinite set $I$ which has a linear order.) ""Upper triangular"" means, of course, that the $i,j$ entries are zero if $i >j$. Let's call the ring $R$, and assume $I=\Bbb N$ for simplicity. This ring can be realized as a subring of the linear transformations of a countable dimensional vector space in the following way: select a chain of subspaces $V_i$ of dimension $i$ for each natural number $i$, with $V_i\subseteq V_{i+1}$ for all $i$. The set of transformations which map $V_i$ into $V_i$ for all $i$ is represented by the ring we are speaking of. What can be said about $R$'s ring-theoretic properties? It seems to satisfy quite few positively. Structurally: It is clearly a subring of the ring of column-finite matrices indexed with $I$. it seems the Jacobson radical $J(R)$ is still the strictly upper triangular matrices. The Jacobson radical isn't nilpotent anymore when $I$ is infinite (it is not even nil). I have read that the elements with no zeros on the diagonal are invertible. (Perhaps these are all the units?) It looks like the powers of $J(R)$ form an infinitely long filtration of ideals with intersection $\{0\}$. Some observations on properties: It's certainly not Artinian or Noetherian on either side. It isn't even semiprime: $e_{12}Re_{12}=0$ for the matrix units $e_{ij}$. Unlike the ring of column-finite matrices, the ring of upper triangular matrices is Dedekind finite since it has a commutative quotient ring (namely $R/J(R)$.) To give a few concrete questions: is it hereditary, semihereditary or coherent on either side? is it stably finite? What do its socles look like? What do its left/right singular ideals look like? I can split the question into two halves, perhaps, if the need arises.","['abstract-algebra', 'noncommutative-algebra', 'infinite-matrices', 'ring-theory']"
1372424,Evaluate $\sin(\sin(\cdots\sin(\sin(a)+a)\cdots+a)+a)$ limit as the number of terms goes to infinity,"I need help evaluating this limit: $$ \lim_{n \to \infty }\underbrace{\sin( \sin( \cdots \sin( \sin(}_{\text{$n$ compositions}}\,\underbrace{a)+a)\cdots +a)+a)}_{\text{$n$ compositions}},$$ I know that it converges to a specific number, for example when one takes a to be $1$, the limit is at $0.9345632\ldots$","['calculus', 'limits']"
1372434,How to find the Summation S,"Given function $f(x)=\frac{9x}{9x+3}$.
Find S:
$$
S=f\left(\frac{1}{2010}\right)+f\left(\frac{2}{2010}\right)+f\left(\frac{3}{2010}\right)+\ldots+f\left(\frac{2009}{2010}\right)
$$","['sequences-and-series', 'functions']"
1372444,Calculate $\ln 97$ and $\log_{10} 97$,"Calculate $\ln 97$ and $\log_{10} 97$ without calculator accurate up to $2$ decimal places. I have rote some value of logs of prime numbers up to $11$. $97$ is a little big. In case it would have been a multiple of smaller primes, I would have used the trick of logarithm identities . But I am confused how to do it, or will it be ok to approximate it to $96$ or $98$. I also don't know much calculus except differentiation and integration. I look for a short and simple way. I have studied maths up to $12$th grade.","['algebra-precalculus', 'logarithms']"
1372468,Coupled second-order differential equations,"I am trying to solve the following system of coupled ODEs:
\begin{align}
-x^2 f'' - 3xf' + (1-2a)f - (a+1)x^2g'' + (2-4a)xg' + (4a-2)g &= 0,\\
(a-1)x^2 f'' + (4a+2)xf' + (12-6a)f + 12xg' + (12a-24)g &= 0,
\end{align}
where $f$ and $g$ are function of $x$ and $a$ is a constant. What method do you suggest for solving this system? Any suggestion will be appreciated! Thanks!","['systems-of-equations', 'ordinary-differential-equations']"
1372477,if $(1-a)(1-b)(1-c)(1-d) = \frac{9}{16}$ then minimum integer value of $\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d} = ?$,"Given  $a,b,c,d > 0$, how do we find the minimum integer value of $n=\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d}$ such that   $(1-a)(1-b)(1-c)(1-d) = \frac{9}{16}$.","['polynomials', 'algebra-precalculus', 'inequality']"
1372495,Symbol of the differential operator on vector bundles,"Suppose that we have a differential operator $D:C^{\infty}(\mathbb{R}^n) \to C^{\infty}(\mathbb{R}^n)$ of the form $(Df)(x)=\sum_{|\alpha| \leq k}a_{\alpha}(x)\frac{\partial^{|\alpha|}f}{\partial x_1^{\alpha_1} ... \partial x_n^{\alpha_n}}$ where we use standard multiindices notation. Here $a_{\alpha}$ are scalar valued functions. For such $D$ we can consider the expression coming from the highest order term in $D$, where we replace each partial derivative $\frac{\partial^{|\alpha}|}{\partial x_1^{\alpha_1} ... \partial x_n^{\alpha_n}}$ by $\xi^{\alpha}:=\xi_1^{\alpha_1}...\xi_n^{\alpha_n}$ where $\xi=(\xi_1,...,\xi_n) \in \mathbb{R}^n$ (note that some authors insert also factor $i$ in order to make fulfill some positivity conditions). This is rather standard and this construction may be generalized: the most general case is when everything takes place over some (say closed) manifold $M$ and two vector bundles $E,F$ over $M$. Then the symbol may be interpreted in the following way: let $T^*_0(M)$ be the cotangent bundle with the zero section deleted and $p:T^*_0M \to M$ be a canonical projection. One considers the pullback bundles $p^*(E),p^*(F)$ and symbol is defined as homomorphism $\sigma \in Hom(p^*(E),p^*(F))$ in the following way: for $(x,v) \in T^*_0(M)$ and $e \in E$ we pick $g \in C^{\infty}(M)$ and $s \in \Gamma^{\infty}(M,E)$ (a smooth section) such that $dg_x=v$ $g(x)=0$ and $s(x)=e$. Then we define $\sigma(D)(x,v)e=D(\frac{i^k}{k!}g^ks)(x)$. My question are then following: Why this is well defined? At least I can see that everything lands in the correct spaces and also all expressions makes sense: also it is clear for me that such choices are always possible. What is not clear for me, that this definition does not depend from the choices made. Moreover I really would like to understand How this definition relates to the most simple situation for example $M$ being euclidean space and $E,F$ be trivial bundles (but not necessarily of rank 1). I would appreciate any explanation or references where this is explained in detail: I really would like to learn this material in detail.","['differential-geometry', 'vector-bundles']"
1372554,Find $\lim_\limits{x\to -1}{f(x)}$,"Let $f:\mathbb{R}\mapsto\mathbb{R}$ be a function such that: $$f(x)=f(1-x), \forall x \in\mathbb{R}$$ $$\lim_\limits{x\to 2}{\frac{f(x)+4}{x-2}}=1$$ Find $\lim_\limits{x\to -1}{f(x)}$. I have tried the following: $$\lim_\limits{x\to 2}{\frac{f(x)+4}{x-2}}=1\Leftrightarrow \lim_\limits{h\to 0}{\frac{f(2+h)+4}{h}}=1\Leftrightarrow \lim_\limits{h\to 0}{\frac{f(-h-1)+4}{h}}=1$$ So, I may need to show that $f(-h-1)=f(h+1)$ and I am done. Any hint?","['limits-without-lhopital', 'limits']"
1372558,Differentiate the Function: $y=\sqrt{x^x}$,"$y=\sqrt{x^x}$ How do I convert this into a form that is workable and what indicates that I should do so? Anyway, I tried this method of logging both sides of the equation but I don't know if I am right. $\ln\ y=\sqrt{x} \ln\ x$ $\frac{dy}{dx}\cdot \frac{1}{y}=\sqrt{x}\ \frac{1}{x} +\ln\ x\ \frac{1}{2}x^{-\frac{1}{2}}$ $\sqrt{x}\cdot (\sqrt{x}\ \frac{1}{x} +\ln\ x \ \frac{1}{2}x^{-\frac{1}{2}})$","['calculus', 'derivatives']"
1372591,Partitions of a power set and equivalence classes,"I got the set: $$
M=\{1,2,3,4\}. 
$$ I could split the power set of M into the following subsets: $$
P_{0}=\{\emptyset\} \\
P_{1}=\{\{1\},\{2\},\{3\},\{4\}\} \\
P_{2}=\{\{1,2\},\{1,3\},\{1,4\},\{2,3\},\{2,4\},\{3,4\}\} \\
P_{3}=\{\{1,2,3\},\{1,2,4\},\{1,3,4\},\{2,3,4\}\} \\
P_{4}=\{\{1,2,3,4\}\}
$$ The set of those subsets would give me a partition of the power set: $$
P=\{P_{0},P_{1},P_{2},P_{3},P_{4}\} \\
$$ We can interpret the partition as a set of equivalence classes. The equvalence relation would be then defined as: $$
aRb :\Leftrightarrow |a|=|b|
$$ Is this correct?",['elementary-set-theory']
1372610,Are random variables independent of their tail sigma-algebra?,"Let $X_1, X_2, ...$ be independent random variables. Define $$\mathscr{T}_n = \sigma(X_{n+1}, X_{n+2}, \ldots)$$ and $$\mathscr{T} = \bigcap_{n} \mathscr{T}_n,$$ the tail σ-algebra of $(X_1, X_2, \ldots)$. Are $\sigma(X_1), \sigma(X_2), ...$ independent of $\mathscr{T}$? If so, why? If not, why, and what about $$\sigma(X_1), \sigma(X_2), ..., \sigma(X_k) \ \;\forall k \in \mathbb{N}\quad?$$ All I got so far is that if $X_1, X_2, \ldots$ were events instead of random variables, $X_1, X_2, \ldots, X_k \ \forall k \in \mathbb{N}$ would be independent of some events in $\mathscr{T}$ such as $\limsup X_n$.","['probability-theory', 'proof-verification', 'random-variables', 'independence', 'limsup-and-liminf']"
1372616,The probability of two consecutive non-leap years having 52 Fridays each is $\frac{5}{7}$. How?,"I took a test on probabilities, and there was this question about finding the probability of two consecutive non-leap years having 52 Fridays each. I figured it would be $\frac{6}{7} \times \frac{5}{7}$, which is the product of the probability of there being 52 Fridays in a non-leap year and the probability of there being 52 Fridays in the successive year if the previous year had 52 Fridays. The teacher told me the answer was $\frac{36}{49}$, which is obviously incorrect. I explained my reasoning, but he didn't budge. I got home and actually analysed years from 1800 to 2000 to find out what the correct answer is. It is actually $\frac{5}{7}$. I cannot seem to figure out how, though, but it must have something to do with the leap years not being taken into consideration. A year is a leap year if it is divisible by 4. If it is divisible by 100, but not by 400, it is not a leap year. I changed $\frac{2}{3}$ in my original question to $\frac{5}{7}$ because that is actually the correct answer (which Christian Blatter proves correct in his answer). The $\frac{2}{3}$ came about due to faulty coding.","['probability', 'statistics']"
1372657,Notation of an infinite union,"Is there any difference between: $$
\bigcup_{n =1}^\infty a_{n} \\
\bigcup_{n \in \mathbb{N}} a_{n} 
$$ From my understanding they both define an infinite union. Is this correct?","['elementary-set-theory', 'notation']"
1372675,"Computing $\max_{1/2 \leq x \leq 2} ( \min_{1/3 \leq y \leq 1} f(x,y) )$ where $f(x,y) = x(y \log y - y) - y \log x$.","Let $f(x,y)=x(y\ln y-y)-y\ln x.$ Find $\max_{1/2\le x\le 2}(\min_{1/3\le y\le1}f(x,y))$. This problem is quite easy and it is from Spivak ; it is the part $c)$ of the general exercise 2-41 page 43 Calculus on manifolds ; here it is: Let $f:\mathbb{R}\times \mathbb{R}\to \mathbb{R}$ be twice continuously differentiable. For each $x\in \mathbb{R}$ define $g_x(y)=f(x,y)$. Suppose that for each $x$ there is a unique $y$ with $g'_x(y)=0$; let $c(x)$ be this $y$. $a)$: If $D_{2,2}f(x,y)\ne0$ for all $(x,y)$ show that $c$ is differentiable and $c'(x)=-\frac{D_{2,1}f(x,c(x))}{D_{2,2}f(x,c(x))}$ $b)$: Show that if $c'(x)=0$, then for some $y$ we have $D_{2,1}f(x,y)=0$, $D_2f(x,y)=0$. I cannot visualize how part c) relates to the previous ones. Can you give me a hint?",['multivariable-calculus']
1372692,Does positive definite Hessian imply the Jacobian is injective?,"Suppose $f(x):\mathbb{R}^n \mapsto \mathbb{R}$ is an infinitely differentiable function. If $\nabla^2 f(x)$, the hessian of $f$ is positive definite everywhere, does this imply that the gradient(first order derivative) $\nabla f:x\mapsto \nabla f(x)$ from $\mathbb{R}^n$ to $\mathbb{R}^n$ is injective? It is the case for $n=1$ but not sure if it is the case for general $n$. I have tried to prove thinking along the inverse function theorem. But that one is local while I need a global property. Maybe there is a simple counter example I have not seen.","['differential-geometry', 'multivariable-calculus', 'real-analysis']"
1372724,How to evaluate this double infinite sum (Catalan number),"Let  $C_n = \dfrac{1}{n+1}\binom{2n}{n}$. Is it possible to find the exact value of this infinite sum ?
$$\sum_{n=1}^\infty \sum_{k=n}^\infty \frac{\left(C_{n+1}-2C_n\right)\left(C_{k+1}-C_k\right)}{4^{n+k}}$$ In general, is it possible to evaluate 
$$\sum_{n=1}^\infty \sum_{k=n}^\infty \frac{\left(C_{n+1}-2C_n\right)\left(C_{k+1}-C_k\right)}{x^{n+k}}$$
in term of $x$? Thanks in advances.","['sequences-and-series', 'generating-functions', 'combinatorics']"
1372734,Folding a paper such that the size of one sides be as minimum as possible?,Suppose that we have an A4 paper like this: How to fold this paper such that the bottom-right corner overlap the left edge of the paper and that the size of AB side be as minimum as possible. It should be noted that the size of a typical A4 paper is 210*297mm.,"['optimization', 'geometry', 'derivatives']"
1372761,Trying to understand Bienaymé formula,"In Bienaymé formula, it states that $var(\bar X) = \large\frac{\sigma^2}{n}$.
However, when I was going through the proof here , it says the variances of $X_1,X_2,X_3......X_n$ are the same(assuming they are all independent). Can anyone explain the reason behind it? I am confused about how different random variables can have the same variance.","['probability', 'statistics']"
1372767,"Integral $\int_0^1\frac{\log(x)\log(1+x)}{\sqrt{1-x}}\,dx$","I'm trying to evaluate this definite integral:
$$\int_0^1\frac{\log(x) \log(1+x)}{\sqrt{1-x}} dx$$
It's clear that the result can be expressed in terms of derivatives of a hypergeometric function with respect to its parameters. I obtained the following form:
$$4 \left(1 - \log 2\right){_2F_1}^{(0,1,0,0)}\left(1, 0; \tfrac{3}{2}; -1\right) - 2 {_2F_1}^{(1,1,0,0)}\left(1, 0; \tfrac{3}{2}; -1\right) - 2{_2F_1}^{(0,1,1,0)}\left(1, 0; \tfrac{3}{2}; -1\right)$$
Is it possible to expand these derivatives to some explicit form and further simplify this result? Or maybe you could suggest a different way to evaluate this integral that gives a simpler result without going through hypergeometric functions?","['calculus', 'definite-integrals', 'logarithms', 'integration', 'hypergeometric-function']"
1372775,Expected value of a mean when previous values determine stopping point,"I recently came across this brain teaser: There's an island and every family on the island wants to have a boy.
  So each family continues having kids until they have a boy, then they
  stop having kids. What's the ratio of boys to girls on this island? I worked out the answer (the math required isn't really the topic of this question) and found that the ratio of boys to girls on the island is 1:1. Then I realized that I think it's 1:1 no matter what criteria families use to decide when to stop having kids. In discussions with friends the above seemed counter-intuitive to some. So slightly more formally (and apologies if this isn't formal enough, it's been a while since I've studied this): We are going to sample a random variable some (possibly infinite) number of times and consider the sum of these values. Is it true that looking at previous values to decide when to stop sampling cannot alter the expected value of the mean? The values of each sample are independent and identically distributed.",['probability-theory']
1372801,Can one build a homology theory using submanifolds and their boundaries?,"Consider a manifold $M$, and denote by $\Delta _p M$ the set of all submanifolds of dimension $p$ (with or without boundary) of $M$. Define $G_pM$ to be the free abelian group generated by $\Delta_p M$, and define $\partial : G _p M \rightarrow G_{p-1} M$ to be the linear extension of the boundary ""operator"" on manifolds: which takes a manifold $M$ and gives back the boundary $\partial M$. Does this give rise to an homology theory? If so, is it interesting in any way?","['manifolds', 'homology-cohomology', 'differential-geometry', 'algebraic-topology']"
1372825,Evaluating numerically $\int_0^{\infty}e^{-t^2 /100} \sin \pi t $,"What is an appropriate method to approximate $$I=\int_0^\infty e^{-t^2 /100} \sin \pi t \ dt?$$ This is for a Physics problem, but in fact I need this in general, as my professor and book taught us nothing about numerical methods for integrals. Also, I found on the internet various techniques for proper ones, but I'm having trouble with making $I$ manageable. Finally, note that I have indeed come to know $$\int_0^\infty e^{-t^2 /\alpha} \sin \pi t \ dt =\sqrt{\alpha}F\left(\frac{\sqrt{\alpha} }{2}\pi\right),$$ where $F$ is Dawson's integral , however what I'm asking for is approximations.","['real-analysis', 'improper-integrals', 'definite-integrals', 'integration', 'numerical-methods']"
1372833,Proof of $f^{-1}(B_{1}\setminus B_{2}) = f^{-1}(B_{1})\setminus f^{-1}(B_{2})$,"I want to prove the following equation: $$
f^{-1}(B_{1}\setminus B_{2}) = f^{-1}(B_{1})\setminus f^{-1}(B_{2})
$$ Is this a valid proof? I am not sure, because at one point I am looking at $f(x) \in B_1$, but then $x \in f^{-1}(B_1)$ could be actually some different points. $$\begin{align*}
x \in f^{-1}(B_{1}\setminus B_{2}) &\iff f(x) \in B_{1}\setminus B_{2} \\
&\iff f(x) \in B_{1} \land f(x) \notin B_{2} \\
&\iff x \in f^{-1}(B_{1}) \land x \notin f^{-1}(B_{2}) \\
&\iff x \in f^{-1}(B_{1})\setminus f^{-1}(B_{2})
\end{align*}$$","['elementary-set-theory', 'functions']"
1372869,Hypercube and Hyperspheres,"Let $n,k\in\mathbb{N}$ .  In this problem, the geometry of $\mathbb{R}^n$ is the usual Euclidean geometry. The lattice hypercube $ Q(n,k)$ is defined to be the set $ \{1,2,...,k\}^n \subseteq\mathbb{R}^n$ .  If we want to cover this hypercube with the $m$ distinct $(n-1)$ -dimensional hyperspheres $S_1$ , $S_2$ , $\ldots$ , $S_m$ .  By ""covering $Q(n,k)$ ,"" I mean that $Q(n,k)\subseteq
 \bigcup\limits_{j=1}^m\,S_j$ .   What is the least possible value of $ m$ ? Using a simple Combinatorial Nullstellensatz argument, we can show that if $ \mu(n,k)$ is the minimum possible $ m$ , then $$ 1 + n\left\lfloor\dfrac{k - 1}{2}\right\rfloor \leq \mu(n,k) \leq 1 + n\left\lfloor\left(\dfrac{k - 1}{2}\right)^2\right\rfloor \,.
$$ However, the lower bound is not sharp for large $ k$ .  All I know is that the lower bound is exact for $ k = 1$ , $ 2$ , $ 3$ , and $ 4$ , as well as when $ n = 1$ , and for a special case with $ n = 2$ and $ k = 5$ (as shown in the attached figure below).  While my bounds give $5\leq \mu(2,6) \leq 13$ , I believe that $\mu(2,6)=6$ .  Can you verify this? Can anyone help improve these bounds?  Note that the bounds also work if the $S_j$ 's can be $(n-1)$ -dimensional hyperellipsoids, but what will be the value of the smallest $m$ in this case (which, to avoid confusion, we shall use $\nu(n,k)$ for this smallest $m$ )?  In other words, we also have $$ 1 + n\left\lfloor\dfrac{k - 1}{2}\right\rfloor \leq \nu(n,k) \leq 1 + n\left\lfloor\left(\dfrac{k - 1}{2}\right)^2\right\rfloor \,.
$$ For example, $\nu(1,k)=\left\lceil\dfrac{k+1}{2}\right\rceil=\mu(1,k)$ for all $k\in\mathbb{N}$ and $\nu(2,k)=1+2\left\lfloor\dfrac{k-1}{2}\right\rfloor$ for $k=1,2,3,4,5$ .  Observe that the lower bound for $\nu(2,6)$ is also sharp (i.e., $\nu(2,6)=5$ ). What happens if the $S_j$ 's can be any nondegenerate $(n-1)$ -dimensional hyperconic sections (where my Combinatorial Nullstellensatz argument no longer works, so the lower bound I have obtained no longer holds)?  In this most general form, we shall use the notation $\rho(n,k)$ for the smallest $m$ .  The only known bound for $\rho(n,k)$ is $$ \rho(n,k) \leq 1 + n\left\lfloor\left(\dfrac{k - 1}{2}\right)^2\right\rfloor \,.
$$ For example, $\rho(1,k)=\left\lceil\dfrac{k+1}{2}\right\rceil=\mu(1,k)$ for all $k\in\mathbb{N}$ .  However, $\mu$ , $\nu$ , and $\rho$ do not always coincide.  Known values are $\rho(2,1)=1=\rho(2,2)$ and $\rho(2,3)=2<\mu(2,3)$ , while we have $\rho(2,4)\leq 3=\mu(2,4)$ , $\rho(2,5)\leq 4 <\mu(2,5)$ , and $\rho(2,6)\leq 5\leq\mu(2,6)$ .","['euclidean-geometry', 'extremal-combinatorics', 'integer-lattices', 'algebraic-geometry', 'combinatorial-geometry']"
1372920,Question 7.7 in measure theory on Radon measure from Folland's Real Analysis Second Edition,"Hello all I was presented with this question from Folland's real analysis second edition on Radon measures which I am stuck on and so would really appreciate the help on.
I m a novice in Radon measures especially in the concepts and abstractions so any help would be appreciated. It is problem #7 on page 220
It reads as follows: Just in case, the definition of Radon Measure used in the book is:
A Radon measure on X is a Borel measure that is finite on all
compact sets, outer regular on all Borel sets, and inner regular on all open sets.
I also know for a fact that Radon measures are also inner regular on all their sigma finite sets.
I have tried to attack the problem many times but to no avail as for some reason I cannot seem to incorporate the given assumption that X is sigma finite.
Also the assumption is X is locally compact Hausdorff space.
I would really appreciate the help Thanks EDIT: I figured it is obviously finite on compact sets Possible direction I have:
I have studied in the Folland book that all $ \sigma-finite $ Radon measures are regular therefore for all Borel sets A and E we have $ \mu_A(E)=\mu(E \cap A) $ is the supremum on measure of all compact subsets in $ E \cap A $. How do I move further? I need inner regularity on open sets E meaning the supremum on measures of compact subsets of E not $ A \cap E $ as I have.","['real-analysis', 'general-topology', 'measure-theory']"
1372939,Weak convergence and convergence almost everywhere,"If a bounded sequence $(u_n)$ converge weakly to $u$ in $W^{1,p}(\Omega)$ (where $\Omega$ is an open bounded subset of $\mathbb{R}^N$ with $N>p$), is it true that $u_n(x)$ converges to $u(x)$ for almost every $x\in \Omega$? thank you","['sobolev-spaces', 'weak-convergence', 'real-analysis', 'functional-analysis']"
1372945,"The sequence $f_n=x^n$ is not weakly convergent in $C[0,1]$","Let's consider the sequence $f_n=x^n$ for $n \in \mathbb{N}$ in $C[0,1]$ equipped with the usual supremum norm. How can we show that $f_n$ does not converge weakly in $C[0,1]$ without using an explicit description of the dual (e.g. as a space of measures)? This was a question in an exam in functional analysis this semester and I can't really figure out a way how to solve this without knowing how the dual of $C[0,1]$ looks like.","['weak-convergence', 'functional-analysis']"
1372958,New Idea to prove $1+2x+3x^2+\cdots=(1-x)^{-2}$,"Given $|x|<1 $ prove that $\\1+2x+3x^2+4x^3+5x^4+...=\frac{1}{(1-x)^2}$. 1st Proof: Let $s$ be defined as
$$
s=1+2x+3x^2+4x^3+5x^4+\cdots
$$ Then we have $$
\begin{align}
xs&=x+2x^2+3x^3+4x^4+5x^5+\cdots\\
s-xs&=1+(2x-x)+(3x^2-2x^2)+\cdots\\
s-xs&=1+x+x^2+x^3+\cdots\\
s-xs&=\frac{1}{1-x}\\
s(1-x)&=\frac{1}{1-x}\\
s&= \frac{1}{(1-x)^2}
\end{align}
$$ 2nd proof: $$
\begin{align}
s&=1+2x+3x^2+4x^3+5x^4+\cdots\\
&=\left(1+x+x^2+x^3+\cdots\right)'\\
&=\left(\frac{1}{1-x}\right)'\\
&=\frac{0-(-1)}{(1-x)^2}\\
&=\frac{1}{(1-x)^2}
\end{align}
$$ 3rd Proof: $$
\begin{align}
s=&1+2x+3x^2+4x^3+5x^4+\cdots\\
=&1+x+x^2+x^3+x^4+x^5+\cdots\\
&+0+x+x^2+x^3+x^4+x^5+\cdots\\
&+0+0+x^2+x^3+x^4+x^5+\cdots\\
&+0+0+0+x^3+x^4+x^5+\cdots\\
&+\cdots
\end{align}
$$
$$
\begin{align}
s&=\frac{1}{1-x}+\frac{x}{1-x}+\frac{x^2}{1-x}+\frac{x^3}{1-x}+\cdots\\
&=\frac{1+x+x^2+x^3+x^4+x^5+...}{1-x}\\
&=\frac{\frac{1}{1-x}}{1-x}\\
&=\frac{1}{(1-x)^2}
\end{align}
$$ These are my three proofs to date. I'm looking for more ways to prove the statement.","['sequences-and-series', 'big-list']"
1372960,$\mathrm E [X \mid X=x] = x$?,"I've gotten so caught up in measure-theoretic probability that I'm actually having trouble showing this simple result.  Let $X$ be an integrable random variable.  Then
$$
\mathrm E[X \mid X=x] = \int_{\Omega} X(\omega)\, P^X(\mathrm d\omega \mid x) = \int_{X(\Omega)} x \, P_{X\mid X}(\mathrm dx | x) = ?
$$
The first equality is the definition of the conditional expectation of a random variable w.r.t. an event with zero probability, and so $P^X(\cdot \mid \cdot)$ is the regular conditional probability of $P$ given $X$.  I then tried to push forward this integral onto the range of $X$ using the conditional distribution of $X$ given $X$, $ P_{X\mid X}(\cdot | \cdot)$, but it's not clear to me either of these integrals equals $x$. I'm clearly missing something pretty obvious and would appreciate an extra eye!","['probability-theory', 'conditional-expectation', 'probability']"
1372968,The set is closed (resp. open) iff the complement set is open (resp. closed),"There's a theorem in my small danish course book. Let $(M,d)$ be a metric space. Theorem : The concepts of open and closed are dual: A set $A\subseteq M$ is closed (resp. open) if and only if the complement set $\complement A$ is open (resp. closed). Proof : The formula $\complement \overline{A}=(\complement A)^{\circ}$ shows that $A=\overline{A}$ only if $(\complement A)^{\circ}=\complement A$, that is $A$ is closed, only if $\complement A$ is open. Using this on $\complement A$ insted of $A$, we get that $A$ is open only if $\complement  A$ is closed. I don't think the proof is useful. Here's what I want to prove;
\begin{align*}
\overline{A}=A\iff (\complement A)^{\circ}=\complement A\tag{1}\\
A^{\circ}=A\iff \overline{\complement A}=\complement A\tag{2}.
\end{align*} Note this course book has some of few formulas without proofs added. Case $(1)$. $\implies:$ Assume that $\overline{A}=A$. We'll use the formula $\complement \overline{A}=(\complement A)^{\circ}$. Since $\complement \overline{A}= \complement A$, we have $\complement A=(\complement A)^{\circ}$. $\impliedby:$ Assume that $\complement A=(\complement A)^{\circ}$. We'll use the formula $\overline{A}=\complement((\complement A)^{\circ})$. We have $\overline{A}=\complement((\complement A)^{\circ})=\complement(\complement A)=A$. Case $(2)$. $\implies:$ Assume that $A^{\circ}=A$. We will use the formula $\overline{A}=A^{\circ}\cup \partial A$. We have
$$\overline{\complement A}=(\complement A)^{\circ}\cup \partial(\complement A)=(\complement A)^{\circ}\cup \partial A=M\setminus A^{\circ}=M\setminus A=\complement A.$$ $\impliedby:$ This one I need help with. What do you think about my proof so far? I know that there are other proofs available in some websites but I would like to write it differently.","['elementary-set-theory', 'proof-verification', 'general-topology']"
1372977,Adjoint representation is Lie algebra homomorphism,"Let $T_g:=L_g R_{g^{-1}}: G \rightarrow G$ be the standard automorphism of a Lie algebra, then $Ad_g:=DT_g(e): \mathfrak{g} \rightarrow \mathfrak{g} $is called the adjoint representation. Now, I want to show that $[Ad_g \xi, Ad_g  \eta] = Ad_g [\xi,\eta].$ Here, $\xi,\eta \in \mathfrak{g}.$ So the goal is to see that $Ad$ respects also the Lie-Bracket. Unfortunately, I don't see how this can be shown.  (and I cannot use more properties here, as I only have this basic definitions available).","['lie-groups', 'abstract-algebra', 'differential-topology', 'differential-geometry', 'lie-algebras']"
1372980,Penrose's remark on impossible figures,"I'd like to think that I understand symmetry groups. I know what the elements of a symmetry group are - they are transformations that preserve an object or its relevant features - and I know what the group operation is - composition of transformations. Given a polyhedron or wallpaper tiling or whatever, I could probably start spotting the symmetries, which would entail listing out elements of the symmetry group, and then I could start filling in the multiplication table. Penrose attaches a group to impossible figures to capture their inherent ambiguity, and I'd like to grok these groups like I do symmetry groups. Take a prototypical example, the tribar: He names the ""ambiguity group"" $G=\Bbb R^+$ (positive numbers under multiplication) to describe possible distances of points. We can split the figure up into three components, as above, and interpret them as being disconnected from each other in three-space but from our perspective they seem to make a single figure. For convenience, I think we should let $A_{ij}$ denote points on the figures as well as represent their distances from the origin, interchangeably. One can define the relative distances by $d_{ij}=A_{ij}/A_{ji}$. Since $d_{ji}=d_{ij}^{-1}$, there are only three relevant proportions: $d_{12}$, $d_{23}$, and $d_{31}$. According to Penrose, the $d_{ij}$s do not actually depend on our choice of overlapping points $A_{ij}$, but this seems wrong to me: varying the points $A_{ij}$ through the overlap regions will change them linearly and so any ratio $d_{ij}$ will only remain invariant if $d_{ij}=1$ to begin with. But probably this quibble is unimportant. One can scale the distances the components $Q_1,Q_2,Q_3$ are from the origin without affecting our perception of them. (Perhaps consider our ""perception"" of them to be their radial projection onto the unit sphere, or something.) The effect of scaling one of these $Q_i$ by a factor of $\lambda$ on the $d_{12},d_{23},d_{31}$ is to scale one of them by $\lambda$, a second by $\lambda^{-1}$, and leave the third unchanged. If the $Q_1,Q_2,Q_3$ were compatible and could be combined into a single figure, then such a configuration would have $(d_{12},d_{23},d_{31})=(1,1,1)$. If they were compatible but the components were separated by independent scalings $q_1,q_2,q_3$ (respectively) then we'd have $$(d_{12},d_{23},d_{31})=\left(\frac{q_1}{q_2},\frac{q_2}{q_3},\frac{q_3}{q_1}\right). \tag{1}$$ Note that $\tau=d_{12}d_{23}d_{31}$ is an invariant , in the sense that scaling the components independently does not change the value of $\tau$. The compatibility situation $(1)$ occurs precisely when $\tau=1$. Penrose defines the group $H$ to be the tuples $(d_{12},d_{23},d_{31})\in(\Bbb R^+)^3$ modulo the rescalings by $\lambda$ and modulo the elements of the form $(1)$. As I understand it, the invariant $(d_{12},d_{23},d_{31})\mapsto\tau$ is a bijection $H\to\Bbb R^+$. But now here are my questions. $\hskip 1.4in$ $\sf \color{Fuchsia}{(A)}$ How do we know what the ambiguity group is? The tribar's ambiguity group is $G=\Bbb R^+$. With the Necker cubes above, Penrose says the ambiguity group is $G=\Bbb Z_2$. Is the ambiguity group meant to parametrize the possible positions of the individual pieces of the figure? Where does the group operation of $G$ actually come into play? $\sf \color{Fuchsia}{(B)}$ How do we know what pieces to cut a figure up into? Since the tribar has obvious threefold symmetry, that kind of inspires the choice of three pieces. But it seems that with the congruence relation used to define $H$, we could choose to put any two of those pieces together into one component and fix its position, only letting the last component vary (which would be one degree of freedom, exactly as $H\cong\Bbb R^+$ predicts). So we could have cut into two pieces. Or we ould cut into six pieces, or any number of pieces. Will it never matter how many pieces we choose? Why would we break apart the tribar's corners but not break apart the faces of the Necker cubes? What figures would we cut into pieces, and what figures would we do something else to? And with the latter figures, what would we do to find their $H$ group? $\sf \color{Fuchsia}{(C)}$ What are the group elements and what is the group operation? As I mentioned with symmetry groups, it's intuitive what their elements are and what the operation is. But what about with $H$? It seems the elements are physically realizable configurations consistent with our perception, modulo altering the configuration in a way that wouldn't change our perception. The identity element would be the configurations in which our perception is actually correct and sensible. And the group operation seems to be ... I don't know. Presumably we could use componentwise multiplication of the representative tuples $(d_{12},d_{23},d_{31})$, or equivalently multiplication of the invariants $\tau$, which would make $H\to\Bbb R^+$ a group isomorphism, but how would this operation be meaningful or relevant? $\sf \color{Fuchsia}{(D)}$ Why is this called a cohomology group? Yes, our $H^1(Q,G)$s are being called cohomology groups. I deliberately put off using that word as long as possible. (And so you've read this far. Suckers.) But in what sense are these groups cohomological? Are there higher cohomology groups $H^n(Q,G)$ and coboundary operators? Is this cohomology dual to some kind of homology of impossible figures? Probably I will be unable to understand answers to this question, as I don't really know what cohomology is in the first place. No time like the present? Ultimately, I'd like to be able to look at an impossible figure and systematically derive its cohomology group, just like I can derive a figure's symmetry group. Or alternately, create impossible figures with given cohomology group. But perhaps the analogy isn't tenable, as cohomology groups aren't really symmetry groups at all. Source: On the Cohomology of Impossible Figures .","['homology-cohomology', 'symmetry', 'geometry', 'recreational-mathematics']"
