question_id,title,body,tags
1673097,Application of Riemann roch-Calculation of index,"Sorry for an ambiguous title. Let me know if you can think of anything better please! Trying to figure out the reason for an equality from a paper. Let $k$ be a function field over a finite field (namely a global function field) and let $A=\prod_PP^{v_P(A)}$ be a sufficiently large divisor of $k$ such that $\mathbb{A}_k=k+\prod_P{P}^{-v_P(A)}.$ (This is possible as Adeles over global field is compact.) Then we are supposed to have $[k\cap \prod_P P^{-v_P(A)}:0]=$deg$(A)$ ""by Riemann-Roch"" which I don't quite see. I see that right hand side is precisely the dimension of Riemann-Roch space and I thought index of specialty has to be $0$ due to the specially chosen divisor $A$. This should give LHS=deg$(A)-g+1$ from my understanding but $g$ is not necessarily 1 (where $g$ is genus of $k$ over its constant field). It might be the case that we could make sure that $k$ is a finite $p$-extension of $\mathbb{F}_{p^n}(T)$ but even so I don't see how this could change anything. For those who are interested what paper I am reading it's Class formation II by Kawada-Satake.","['number-theory', 'algebraic-geometry']"
1673098,Continuity of cartesian product of functions between topological spaces,"I want to prove the following theorem: If $f:X\rightarrow X'$ and $g:Y\rightarrow Y'$ are continuous functions between topological spaces, then the mapping between product spaces $$f\times g:X\times Y\rightarrow X'\times Y', (x,y)\mapsto(f(x),g(y)) $$ is continuous. I am using the theorem written below: Theorem. Let $X, Y$ be topological spaces and $X\times Y$ their product space. If $Z$ is a topological space and $f:Z\rightarrow X\times Y$ a mapping, then $f$ is continuous iff $p\circ f, q\circ f$ are continous, where $p:X\times Y\rightarrow X, q:X\times Y\rightarrow Y$ are projections. Assume that $f:X\rightarrow X'$ and $g:Y\rightarrow Y'$ are continuous functions between topological spaces. Let $p':X'\times Y'\rightarrow X',q':X'\times Y'\rightarrow Y'$ be projections. Then let's assume that $p'\circ f\times g, q'\circ f\times g$ are continous. Let $W\subseteq X'\times Y'$ be open. Then there exists open sets $U_{i}\subseteq X'$ and $V_{i}\subseteq Y'$ $(i\in I)$ such that $U_i$ is open in $X'$ and $V_{i}$ is open in $Y'$ for every $i\in I$ and also $W=\bigcup_{i\in I} U_i\times V_i$ . Because $$(f\times g)^{-1}(W)=(f\times g)^{-1}\bigg(\bigcup_{i\in I} U_i\times V_i\bigg)=\bigcup_{i\in I}(f\times g)^{-1}(U_{i}\times V_{i}), $$ it's enough to show that $(f\times g)^{-1}(U_{i}\times V_{i})$ is open for every $i\in I$ . Now, $U_{i}\times V_{i} = (U_{i}\times Y')\cap (X'\times V_{i})=p'^{-1}(U_i)\cap q'^{-1}(V_i)$ . Then, $$\begin{align*}(f\times g)^{-1}(U_{i}\times V_{i})&=(f\times g)^{-1}(p'^{-1}(U_i)\cap q'^{-1}(V_i))\\
&=(p'\circ f\times g)^{-1}(U_{i})\cap(q'\circ f\times g)^{-1}(V_i).
\end{align*}$$ Now, there are also projections $p:X\times Y\rightarrow X, q:X\times Y\rightarrow Y$ . Because functions $f,g$ are continuous, then $f\circ p, g\circ q$ are continuous. And forward, because $f\times g\circ p' = f\circ p$ and $f\times g\circ q' = g\circ q$ we can continue $$(p'\circ f\times g)^{-1}(U_{i})\cap (q'\circ f\times g)^{-1}(V_i)=(f\circ p)^{-1}(U_i)\cap (g\circ q)^{-1}(V_{i})$$ which is open. Fixed.","['continuity', 'product-space', 'general-topology', 'solution-verification']"
1673123,Is Gaussian integral the only one that can be easily solved by this double integral trick?,"For a lot of people the favorite way of solving Gaussian integral $I=\int^{\infty}_{-\infty} e^{-x^2} dx$ is to find $I^2$ in polar coordinates and then take a root. The trick may be useful in this case, but I struggle to find any other integral it can be applied to. The obvious condition for the integrated function is: $$f(x) \cdot f(y)=g(x^2+y^2)=h(|r|)$$ I don't know any other function aside from $e^{bx^2}$ that meets this condition. Moreover, the limits for the argument should be infinite. Otherwise we can't equate integration in the square $x,y \in (-a,a)$ with integration in the cirlce $r \in (0,a)$. But maybe this method can be generalized? For example, there may be some functions that give elementary integrals in polar form when multiplied $f(x)f(y)$ even if their product depends on the angle too?","['integration', 'definite-integrals']"
1673133,Do all primes occur as a factor of $p_{k}-2$ for some k?,"Can we prove that for any prime p, sufficiently large n, and $$A_n=\prod_{k=2}^n (p_k-2)$$ that $p|A_n$? I checked through $p=p_{50}.$","['number-theory', 'prime-factorization', 'prime-numbers']"
1673170,Integrating a function of tan inverse,"How would I carry out the following integration?
$$\int_0^12\arctan x^2$$ I tried to substitute $x^2 = \tan\theta$
From there I wrote the integral as:
$$\int_0^{\pi/4}\theta\cdot \frac{\sec^2\theta}{\sqrt{\tan\theta}}\ d\theta$$ Now, is my only option to use integration by parts? Or is there a better method to solve this integral?","['integration', 'trigonometry']"
1673176,When $\sum_{p*\leq n}\frac{1}{p*}\sim \log\log\log n$?,I have weird and vague question. We know the reciprocal of numbers $$\sum_{k\leq n}\frac{1}{k}\sim \log n$$ and reciprocal of primes $$\sum_{p\leq n}\frac{1}{p}\sim \log\log n$$ Now consider reciprocal of some sort of primes $$\sum_{p*\leq n}\frac{1}{p*}\sim \log\log\log n$$ where $p*$ is the element of a subset of the prime number set.  What would $p*$ be?,"['number-theory', 'asymptotics', 'prime-numbers']"
1673207,surface lying on one side of another surface,"I was studying the strong maximum principle for minimal surfaces and came across the statement that surface A lies on one side of the surface B. Can you please tell me what does it mean mathematically? The Theorem Statement is: "" If $\Sigma_1 ,\Sigma_2 \subset \mathbb{R}^n $ are complete connected minimal hypersurfaces (without boundaries), $\Sigma_1 \cap \Sigma_2 \neq \emptyset,  $ and $\Sigma_2$ lies on one side of $\Sigma_1$, then $\Sigma_1 = \Sigma_2$.",['differential-geometry']
1673236,Is this property of continuous maps equivalent to properness?,"For the purposes of my question, a continuous map $f : X \to Y$ is proper if it is closed and the preimage of every compact subspace of $Y$ is a compact subspace of $X$. Say a continuous map $f : X \to Y$ is semiproper if, for every continuous map $y : T \to Y$ where $T$ is compact, the space $T \times_Y X = \{ (t, x) \in T \times X : y (t) = f (x) \}$ is compact. It is a fact that a closed map is proper if and only if it is semiproper. Question. Are semiproper maps always closed? If $Y$ is a compactly generated Hausdorff space, then it is easy to check that every semiproper map $f : X \to Y$ is closed – indeed, we only need the defining property for subspace inclusions $y : T \to Y$. On the other hand, if we weaken the definition by restricting to subspace inclusions $y : T \to Y$, then there are easy counterexamples. That leaves non-(compactly generated Hausdorff) spaces. Perhaps there is a counterexample there?","['general-topology', 'compactness', 'limits']"
1673237,Clifford Algebra Isomorphic to Exterior Algebra,"Let $E$ be a vector space over a field $k$ and $Q$ be a quadratic form, that is, $$Q:E\to k$$ such that $$Q(\lambda e)=\lambda^2Q(e)\forall\lambda\in k\,e\in E$$ and such that $P_Q:E^2\to k$ is bilinear, where $$ P_Q(e_1,e_2):=\frac{1}{2}\left[Q(e_1+e_2)-Q(e_1)-Q(e_2)\right]$$ We define the tensor algebra $T(E)$ from $E$ as $$T(E):=\bigoplus_{n=0}^{\infty}E^{\otimes n}$$where $E^{\otimes 0}\equiv k$ and $E^{\otimes n}\equiv E\otimes\dots\otimes E$ (n factors) with the product $$ (e_1\otimes\dots\otimes e_n)\cdot(\tilde{e}_1\otimes\dots\otimes \tilde{e}_\tilde{n}) :=  e_1\otimes\dots\otimes e_n\otimes\tilde{e}_1\otimes\dots\otimes \tilde{e}_\tilde{n} \in E^{\otimes (n+\tilde{n})} $$extended to the whole of $T(E)$ by requiring linearity. Let $I(E,Q)\subseteq T(E)$ be the ideal generated by the set $$ \{ e\otimes e-Q(e)\cdot1_k  \,|\, e\in E\}$$ The the Clifford algebra associated with $E$ and $Q$ is defined as $$ Cl(E,Q) := T(E)/I(E,Q)$$ In Atiyah et al's monograph ""Clifford Modules"" (page 5 point (1.4)) it is claimed that $$ G(Cl(E,Q)) \cong\Lambda(E) $$where $$\Lambda(E)\equiv T(E)/J(E)$$ where $J(E)\subseteq T(E)$ is the ideal generated by the set $$ \{ e\otimes e  \,|\, e\in E\}$$ and $G$ is the associated graded algebra to the filtering of $Cl(E,Q)$ which is induced by the filtering of $T(E)$ given by $$F^q T(E):=\bigoplus_{n=0}^{q}E^{\otimes n}$$ for all $q\in\mathbb{N}_{\geq0}$ This isomorphism is only as vector spaces, not as algebras. My question is: can anyone please write down explicitly what this isomorphism is and describe it? In Wikipedia they give another explicity isomorphism between $Cl(E,Q)$ itself and $\Lambda(E)$, mention the one I'm after, but do not provide it. Because of the complicated nature of the associated graded algebra to a filtered algebra, I'm a bit stumped by this.","['clifford-algebras', 'quadratic-forms', 'linear-algebra']"
1673267,$T^3=\frac{1}{2}(T+T^*) \rightarrow$ T is self adjoint,"Let $T$ be a normal transformation on a finite-dimensional Hilbert space; that is, $TT^*=T^*T$, where $T^*$ is the adjoint of $T$. Prove that if $T^3=\frac{1}{2}(T+T^*)$, then $T$ is self adjoint. I have tried to do some math on $(Tv,u)$ but I was not successful in proving the following: $(Tu,v)=(u,Tv)$ which is what I need for self-adjoint transformation. Edit: $(T^3,v)=\frac{1}{2}\left(\left(T+T^*\right),u \right)= \left( Tu,v\right)+  \left( T^*u,v\right)=\left( u,T^*v\right)+\left( u,Tv\right)=\left( u,T^3v\right)$
Therefore, $T^3$ is self adjoint. Does it mean that $T$ is self adjoint? Thanks!","['linear-algebra', 'linear-transformations']"
1673276,How to compute derivatives of functions with vectors inside?,"Suppose $\vec{w}=\frac{g}{||\vec{v}||} \vec{v}$, what is the derivative of $\vec{w}$ w.r.t. $\vec{v}$? Don't know how to deal with the norm of $\vec{v}$ here... Thanks in advance. :-) Edit: $L$ is a function of $\vec{w}$ and $g$. Based on $\vec{w}=\frac{g}{||\vec{v}||} \vec{v}$, we have
$$\nabla{g}{L}=\frac{\nabla{\vec{w}}{L} \cdot \vec{v}}{||\vec{v}||}$$
$$\nabla{\vec{v}}{L}=\frac{g}{||\vec{v}||}\nabla{\vec{w}}{L}-\frac{g\nabla{g}{L}}{||\vec{v}||^2}\vec{v}$$ Could you show how to get exactly the second equation? It seems a bit weird to me.","['derivatives', 'partial-derivative']"
1673283,Reference on manifolds with corners,"Is there a systematic treatment of (finite dimensional) manifolds with corners in the literature which carefully introduces all usual differential topological notions (submanifolds, embeddings, etc.) and which includes proofs of the usual statements in geometric topology like the existence of collars or isotopy extension theorems in the generality of manifolds with corners? Most of the common textbooks treat the case without corners nor boundary and mention the case of boundaries. Some of them take care of boundaries more closely, but I am not aware of a detailed reference covering the situation with corners.","['differential-topology', 'reference-request', 'manifolds', 'geometric-topology', 'differential-geometry']"
1673288,Identity for bracket operator in tangent space at identity,"Let $G$ be a Lie group and $X,Y\in T_eG$. Show that $$[X,Y]=\left.\frac{\partial}{\partial s}\right\vert_{s=0}\left.\frac{\partial}{\partial t}\right\vert_{t=0}\exp(sX)\exp(tY)\exp(-sX)\exp(-tY).$$ No matter how I approach this I end up with the same wrong result. By definition $$[X,Y]=\operatorname{ad}(X)Y=(T_e(\operatorname{Ad})X)Y$$ which in turn is $$(T_e(\operatorname{Ad})X)Y=\left.\frac{\partial}{\partial s}\right\vert_{s=0}\operatorname{Ad}(\exp(sX))Y=\left.\frac{\partial}{\partial s}\right\vert_{s=0}\left.\frac{\partial}{\partial t}\right\vert_{t=0}\exp(\operatorname{Ad}(\exp(sX)tY))$$ and by a hint given on the sheet that's equal to $$\left.\frac{\partial}{\partial s}\right\vert_{s=0}\left.\frac{\partial}{\partial t}\right\vert_{t=0}\exp(sX)\exp(tY)\exp(-sX)$$ What's my mistake? Edit: The exact text of the question is: Let now $G$ be a Lie group. The commutator of two elements $x,y\in G$ is the element $c(x,y):=xyx^{-1}y^{-1}$. Show that for all $X,Y\in T_eG$ we have $$[X,Y]=\left.\frac\partial{\partial s}\right\vert_{s=0}\left.\frac\partial{\partial t}\right\vert_{t=0}c(\exp sX,\exp tY).$$ Hint: use relations like $x\exp Yx^{-1}=\exp(\operatorname{Ad}(x)Y)$.","['differential-geometry', 'lie-algebras', 'lie-groups']"
1673289,Find the value of $(a - b)^2$ given $a + b = 2$ and $a^2 + b^2 = 6$,"$$a + b = 2\\
a^2 + b^2 = 6$$ Find the value of $(a-b)^2 $ My workings till I got stuck - $$(a-b)^2 = a^2 - 2ab + b^2 \\
= a^2 + b^2 - 2ab\\ 
= 6 - 2 ab $$ I'm stuck at how to find $ab$ . Can I get hints on how to find $ab$? Thanks a lot.",['algebra-precalculus']
1673291,A property of union closed families,"Some tests gave me the impression that the following statement is right : If a union closed family of sets (""union closed"" means that the union of two sets from the family is always a member of the family) has at least ${k \choose r} + 1$ members with cardinality $r$, then this family has at least two members with cardinality $\geq k$. Could anybody indicate a proof or literature ? Thanks in advance.",['combinatorics']
1673341,"Cauchy Principal Value of $\int_0^\infty \frac{x}{(x^2 + a^2) \, \sin(\mu x)} dx$","The problem here is to evaluate 
$$ \int_0^\infty \frac{x}{(x^2 + a^2) \, \sin(\mu x)} dx  $$
for $a,\mu >0.$ Clearly this integral doesn't converge in the usual sense, but we can calculate its Cauchy Principal Value. My attempt was to integrate the function in the complex domain along a quartercircle-contour in the first quadrant, with little bumps at $z=ia$ and $z = \frac{n \pi}{\mu}, n \in \mathbb{N}_{>0}.$ The infinitely many poles along the positive real axis worry me. The residue at $\frac{n \pi}{\mu}$ is $ \frac{(-1)^n}{ a^2\mu^2 + \pi^2 n^2}$, so we should evaluate $\sum_{n=1}^{\infty} \frac{(-1)^n}{ a^2\mu^2 + \pi^2 n^2}. $ How can we do that? How can we evaluate this integral? I'd really appreciate an approach with contour integration. Note:
The solution is 
$$  PV \int_0^\infty \frac{x}{(x^2 + a^2) \, \sin(\mu x)} dx = \frac{\pi}{2 \, \sinh(\mu a)},$$
but I want to prove it.","['complex-analysis', 'contour-integration', 'residue-calculus', 'cauchy-principal-value']"
1673348,If we take $f$ be integrable function then can we prove $\int_{\Bbb R} f(x)\cos(nx)dx \to 0$ as $n \to \infty$,In Riemann-Lebesgue Lemma i.e http://kurser.math.su.se/pluginfile.php/15735/mod_resource/content/1/RiemannLebesgueVretblad.pdf in this link If we take $f$ to be an (improperly) integrable function then can we prove $\int_{\Bbb R} f(x)\cos(nx)dx \to 0$ as $n \to \infty$? Note here $f$ is not absolutely convergent. I am thinking that we will have a problem when we move to unboundedness of $\mathbb R$ otherwise in a compact subset of $\mathbb R$ we will not have any problem. But I can't find any counter-example.,"['integration', 'lebesgue-measure', 'measure-theory']"
1673390,Questions on a nonreduced scheme,"I am reading Foundations of Algebraic Geometry by Ravi Vakil. On page 131, the author says, We should picture $\mathbb C[x]/(x^2)$ in terms of the information the quotient remembers.
  The image of a polynomial $f(x)$ is the information of its value at $0$, and its derivative. The author gives a hint as to understanding this. This hint is: for $f(x) \in \mathbb C[x]$, what is $f(x+\varepsilon)$ in $\mathbb C[x,\varepsilon]/(\varepsilon^2)$? I think this is $f(x) +f'(x)\varepsilon$. But this knowledges fails to give me enough light. So would anyone please explain to me the meaning of The image of a polynomial $f(x)$ is the information of its value at $0$, and its derivative. More exactly, how is the information given? 6.3.11 on page 184 is picturing maps of schemes when nilpotents are present . The picture of $\text{Spec}\mathbb C[x]/(x^2)$ is a point with a ""fuzz"", and the picture of $\text{Spec}\mathbb C[x]$ is a line plus a generic point. Let the morphism from one to the other be corresponding to the ring homomorphism $\mathbb C[x] \rightarrow \mathbb C[x]/(x^2),x \mapsto ax$
for $a \in \mathbb C$. Then for $a =0$ and $a \neq 0$, how does the pictures of the morphisms of schemes differ? Does the happens on the ""fuzz"", and why? I think better conderstanding on these problems may clear many of my confusions on nonreduced schemes. Thanks to everyone.",['algebraic-geometry']
1673403,A continuous function with positive and negative values but never zero?,"Well, it is easy to prove that $e^z$ is never zero and $z$ is any complex number. Also, $e^z$ can be both positive and negative. On the other hand, $e^z$ is continuous. How that's possible that a continuous function can be negative and positive but never meets zero? Detailed simple explanations would be much appreciated.","['complex-analysis', 'real-analysis']"
1673427,"What makes a norm ""appropriate""? Why can't testfunctions be normed appropriately","I often hear the term ""using an appropriate norm"". Then I once read that the $C^\infty_0(\Omega)$ cannot be appropriately normed. Why is that?
Furthermore, when doing some numerical analysis you often use (Sobolev-)spaces which have various norms, why in these cases not use just the $L^2$-norm?
What makes a norm appropriate and why are often different norms necessary? Edit: I asked various questions which I believe have the same answer, hope this is ok. Edit2: For all who are interested, I want to give an answer to my own question, inspired by the comments below and some further thinking about the topic. To motivate the norms in Sobolev spaces: To make a Sobolev space a Banach space we need convergence of every Cauchy sequence to an element that also lies in $W^{k,p}$. We demand the elements of $W^{k,p}$ to have a weak derivative that lies in $L^p$ (actually multiple wead derivatives, depending on k). Assume we only used the $L^p$-norm to check for completeness, we would allow a sequence to converge to an element that only lies in $L^p$ but not in $W^{k,p}$. We would have a Cauchy sequence in $W^{k,p}$ that converges to an element in $L^p$ thus we would not have $W^{k,p}$ a Banach space (since it does not converge in the space). To avoid that we need a norm that only allows for sequences (to be Cauchy) that indeed converge to an element in $W^{k,p}$. 
The original $W^{k,p}$-norm allows for that because we need not only our function $f_n \rightarrow f$ in $L^p$ but also the respective weak derivatives. This is only due to the norm. Short: The norm tells us, what we need to look at when checking for completeness. And only an appropriate norm covers all demanded requirements for the space. So if we use the wrong norm we converge to an element that does not fulfill the requirements and therefore does not lie in the requested Sobolev space. So far the question, what the term appropriate means, this may have been crystal clear to the pros, to me it was not, I felt confused by the seemingly arbitrary choice of norms. This leads to the second question: Why cannot the test functions be normed appropriately? Exactly for that reason: whatever norm I chose I cannot make a sequence in $C^\infty_0$ converge to an element of this very space. 
How a topology does the job better is not exactly clear to me, but that is not what the initial question was about. 
Thanks to all people that helped me to shed some light on this.","['functional-analysis', 'normed-spaces', 'sobolev-spaces']"
1673432,What are some applications of Chebotarev Density Theorem?,"Let $L/K$ be a Galois extension of number fields and let $\mathcal{C}$ be a conjugacy class in $Gal(L/K)$. Let $\mathbb{P}(K)$ be the set of all prime ideals in $K$ and let $\left(\frac{L/K}{\mathfrak{p}} \right)$ correspond to the associated conjugacy class of Frobenius elements living over $\mathfrak{p}$(of course unramified) and suppose $A=\left\lbrace \mathfrak{p}\in P(K) \mid \left(\frac{L/K}{\mathfrak{p}} \right)=\mathcal{C} \right\rbrace$. Then the Chebotarev Density Theorem states that $\delta(A)=\frac{|C|}{[L:K]}$. This also is a generalisation of Frobenius density theorem. For positive integers $a,n$ such that $\gcd(a,n)=1$ CDT for $K=\mathbb{Q}$ and $L=\mathbb{Q}(\zeta_n)$ and $\mathcal{C}=\lbrace \zeta_n \to \zeta_n^a \rbrace$ gives Dirichlet's theorem of infinitude of primes in arithmetic progression. I wish to ask what other applications are of this theorem.","['number-theory', 'applications', 'algebraic-number-theory']"
1673452,Inequality from Analysis Qual [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $\{a_j\}_{j=1}^N$ be a finite set of positive real numbers. Suppose $$\sum_{j=1}^{N} a_j = A,$$ prove $$\sum_{j=1}^{N} \frac{1}{a_j} \geq \frac{N^2}{A}.$$ Hints on how to proceed?","['real-analysis', 'inequality', 'measure-theory', 'analysis']"
1673497,Separable field extensions *without* using embeddings or automorphisms,"If $K\subseteq L$ is a field extension and $x\in L$ is algebraic, we say that $x$ is separable over $K$ iff its minimal polynomial $f$ over $K$ is separable (i.e., $f$ is relatively prime with its derivative).  We say that $L$ is a separable algebraic extension iff every element of $L$ is separable algebraic. These definitions, of course, are quite standard.  Now what I'd like to find is a proof of such standard facts as ""if $x$ is algebraic separable over $K$ then $K(x)$ is separable"" and ""if $L$ is algebraic separable over $K$ and $M$ is such over $L$ then $M$ is such over $K$"", or a definition of the separable degree of an extension, all without using field automorphisms or the trick of counting embeddings in an algebraic closure. (There can be a number of reasons to want this: for pedagogical purposesout of a desire to postpone a discussion of Galois theory at a later point, or because embeddings/automorphisms are computationally or logically more complex objects than field extensions, or simply because it seems that the point of view in the first paragraph above should be more natural, or to compare different points of view.) Now every textbook I could find on field extensions uses at some point a comparison between the number of embeddings of $L$ in the algebraic closure of $K$ and the degree $[L:K]$.  But surely this can be avoided (we can, instead, work explicitly with roots of polynomials and perhaps elementary symmetric functions). So, does someone know a place where separable field extensions are introduced without counting embeddings or similar objects, staying as close as possible to the definition I gave above? Edit : Maybe the nicest definition of an algebraic $x$ being separable over $K$ of characteristic $p$ is that $K(x) = K(x^p)$.","['abstract-algebra', 'field-theory', 'reference-request', 'extension-field']"
1673521,"Flows and Lie brackets, $\beta$ not a priori smooth at $t = 0$","Let $X$ and $Y$ be smooth vector fields on $M$ generating flows $\phi_t$ and $\psi_t$ respectively. For $p \in M$ define$$\beta(t) := \psi_{-\sqrt{t}} \phi_{-\sqrt{t}} \psi_{\sqrt{t}} \phi_{\sqrt{t}}(p)$$for $t \in (-\epsilon , \epsilon)$ where $\epsilon$ is sufficiently small. Does it follow that$$[X, Y](f)(p) = \lim_{t \to 0} {{f(\beta(t)) - f(\beta(0))}\over t}?$$ Thoughts. I know that $\beta$ is not a priori smooth at $t = 0$ because of the $\sqrt{}$ terms. But I do not know what do from here. Could anybody help?","['differential-topology', 'manifolds', 'differential-geometry', 'lie-algebras', 'lie-groups']"
1673527,If and only if criterion for something to be a differential ideal,"Let $I \subset \Omega^*(M)$ be a ($2$-sided) ideal (i.e. $I$ is a vector subspace, and for any $\alpha \in I$ and $\omega \in \Omega^*(M)$ we have $\omega \wedge \alpha \in I$). We say $I$ is a differential ideal if $d\omega \in I$ whenever $\omega \in I$. Suppose $I$ is generated as an ideal by $\omega_1, \omega_2, \ldots, \omega_r$. Is $I$ is a differential ideal if and only if$$d\omega_i = \sum_j \omega_{ij} \wedge \omega_j$$for suitable $1$-forms $\omega_{ij}$?","['differential-topology', 'exterior-algebra', 'multilinear-algebra', 'manifolds', 'differential-geometry']"
1673554,What is the derivative of $\mathrm{trace}((S^T S)^{-2})$ w.r.t. $S$,I would like to compute the derivative of $\mathrm{trace}((S^T S)^{-2})$ w.r.t. $S$. I know that $\frac{\partial \mathrm{trace}((S^T S)^{-1})}{\partial S} = -2S(S^T S)^{-2}$ but I have a higher order in my expression. Any help would be really appreciated.,"['derivatives', 'trace', 'linear-algebra', 'inverse']"
1673567,Asymptotic expansion of the harmonic numbers,"I was skimming through Atle Selberg's ""Elementary Proof of the Prime Number Theorem"", and I got stumped at the part where he introduced equation 2.7 $(\sum_{v\leq z} \frac{1}{v} = log z + c_{1} + O(z^{-1/4}))$ (of which he only says that it is well known). I've seen a similar equation and it's proof $(\sum_{v\leq z} \frac{1}{v} = log z + \gamma + O(\frac{1}{z}))$, but I can't find the former anywhere else.","['number-theory', 'asymptotics', 'prime-numbers']"
1673578,What does an asterisk on top of a set mean?,"I'm reading an article which defines something called a hash function. Let $n\in\mathbb{N}$ and let $H:\{0,1\}^*\to\{0,1\}^n:m\to h=H(m)$... I know that $\{0,1\}^n$ is the cartesian product of the set with itself $n$ times, but I am not familiar with the meaning of the asterisk in this context for $\{0,1\}^*$ Is anyone familiar with the notation?","['notation', 'elementary-set-theory']"
1673598,Probability distribution of the difference of two uniform variables,"What is the PDF or CDF of $|X_1 - X_2|$ (absolute value of the difference of two variables). When both $X_1$ and $X_2$ has different Uniform distribution. Note: We can look at the as the distribution of the range of 2 ordered-statistics; However, the formula I am aware of, is just for iid statistics (same distribution)","['uniform-distribution', 'statistics', 'order-statistics', 'probability-distributions']"
1673602,N-th derivative of a product in binomial expansion?,"I believe that the following is true: $$\frac{d^n}{dx^n}f(x)g(x)=\sum_{i=0}^{\infty}\frac{n!}{i!(n-i)!}f^{(n-m)}(x)g^{(m)}(x)$$ The rational part of the summation is binomial expansion constants and $f^{(n)}(x)=\frac{d^n}{dx^n}f(x)$ I have tested it for some values of $n$ where $f$ and $g$ are either polynomials or exponential functions and it appears to hold true. The question is whether or not the above is true with a proof. For those who concern, $n$ may or may not be a positive integer or even an integer at all because I wish to use this in Fractional Calculus allowing $n\in\mathbb{C}$.","['derivatives', 'binomial-theorem', 'calculus']"
1673603,a number n as pa+qb,"How can we express a number $n$ as $pa+qb$ where $p \geq0$ and $q \geq 0$ and $p$ and $q$ can't be fraction. In contest I got a puzzle as if we can express $c$ as sum of $a$ and $b$ in form $pa+qb$.
Suppose $a$ is $3$ and $b$ is $4$ and $c$ is $7$ so we can express $7$ as $3+4$.
Suppose $a$ is $4$ and $b$ is $6$ and $c$ is $15$ but we can't express $15$ as sum of $4 \cdot p+6 \cdot q$. NOTE: $p$ AND $q$ CAN'T BE FRACTIONS. I came up with an approach to take $\gcd$ of $a$ and $b$ and check if their $\gcd$ leaves zero as remainder when $\gcd$ divides $c$.
Is there any general method to check this ?","['number-theory', 'gcd-and-lcm', 'divisibility']"
1673638,"$\cos x=12/13$, where $0 \lt x \lt 90$ degrees. What is the value of $\sin(2x)?$","apologies if this is an overly simplistic question to answer: I have the value of $\cos x = \frac{12}{13}$, and I need to find the value of $\sin(2x)$, where $x$ is between $0$ and $90$ degrees (first quadrant). I have $\sin(2x)=2\sin x(\frac{12}{13})$ but I am stumped trying to find the value of $\sin x$. Any help would be greatly appreciated",['trigonometry']
1673643,Open immersion pulls back symplectic form to symplectic form?,"If $M$ is symplectic, and $f: W \to M$ is an open immersion, i.e. an immersion where $W$ and $M$ have the same dimension, does $f$ necessarily pull back a symplectic form on $M$ to a symplectic form on $W$?","['differential-topology', 'multivariable-calculus', 'symplectic-geometry', 'manifolds', 'differential-geometry']"
1673652,Finding x given that $\lim_{n\to\infty } x^{x^{n-1}}=5$,"Given a sequence $\{a_n\}^\infty_{n=1}$ defined in the following way: $ a_1=x, \ a_2=x^x, \  a_3=x^{x^{x}}, a_4=x^{x^{x^{x}}} ... \ (x>0)$ what would be the value of $x$ if  $\lim_{n\to\infty } a_n=5$","['ordinary-differential-equations', 'sequences-and-series', 'calculus', 'limits']"
1673657,When is $991n^2 +1$ a perfect square?,What should be the value of $n$ so that the number obtained after adding $1$ to $991$ times its square is itself a perfect square?  Can you please give me a few hints on this topic with a few specific reasons?,"['diophantine-equations', 'number-theory', 'congruences', 'pell-type-equations', 'modular-arithmetic']"
1673685,"How Were Sine, Cosine and Tangent Formulas Conceived? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I am looking mostly, for a visual answer since I am not so advanced in mathematics. When solving for the opposite side, for example, how does the formula convert degrees to a measurement, say 2 inches? I have read about certain "" tables "" being used to aid these formulas. Why do we need these tables? Why is it so complex to find the length of a side of a triangle? My ideal answer is one that explains the why of the complexity of these formulas as they were being developed. P.S. To answer below comment, by ""complex"" I meant that coming up with the formula for sine, cosine etc is no trivial task. So... I would like to know why it's not so simple to create said formulas, in a visual manner if possible.",['trigonometry']
1673708,In what sense does analyticity guarantee the following equality?,"I was reading a paper$^1$ on particle physics, and at some point it is stated that, provided $f(x)$ is analitic, we have
$$
f(x)-f(0)=\frac{x}{\pi}\int_0^\infty \frac{\text{Im}\;f(y)}{y(y-x-i\varepsilon)} \;\mathrm dy\tag{1}
$$
where the $i\varepsilon$ is supposed to be taken $\varepsilon\to 0^+$ after integrating. This looks very similar to (what we physicists) call the Kramers-Kronig relations , though I believe in mathematics it is called the Sokhotski-Plemelj theorem :
$$
\int_a^b\frac{f(x)}{x-i\varepsilon}\mathrm dx=i\pi f(0)+\mathcal P\!\int_a^b\frac{f(x)}{x}\mathrm dx \tag{2}
$$
where $\mathcal P$ means Cauchy principal value. My questions : is the relation $(1)$ true in general? under what circumstances? is it possible to prove $(1)$ from $(2)$? or is $(2)$ irrelevant here? $^1$ The Muon g-2 , by F. Jegerlehner and A. Nyffelerpage, arXiv:0902.3360v1 , page 39.","['complex-analysis', 'integration', 'mathematical-physics', 'cauchy-principal-value']"
1673712,$2$-dimensional subbundle of tangent bundle of closed $3$-manifold integrable if and only if $\alpha \wedge d\alpha = 0$?,"Let $M$ be a closed $3$-manifold, and let $\xi$ be a $2$-dimensional subbundle of $TM$. From here and here , I know that there is a nowhere zero $1$-form $\alpha$ on $M$ with $\alpha(X) = 0$ for any vector field $X$ which is a section of $\xi$, and that any two $1$-forms $\alpha$, $\alpha'$ with this property satisfy $\alpha = f\alpha'$ for some smooth nowhere zero function $f$. My question now is, do we have that $\xi$ is integrable, i.e. tangent to the leaves of a foliation $\mathcal{F}$, if and only if $\alpha \wedge d\alpha = 0$ for any $\alpha$ as above? Edit. I was wondering if anybody could supply a direct proof in this case? The full Frobenius theorem seems a bit overpowered...","['differential-topology', 'differential-forms', 'manifolds', 'vector-bundles', 'differential-geometry']"
1673733,Friendship Theorem: Finding a simple proof,"I'm working with a first-year professor for a Discrete Mathematics course at my university, and we're trying to come up with a proof for the friendship theorem that's simple enough to show and explain to a group of students just a few weeks into graph theory lectures. We believe it's possible to find one, we just haven't had any luck by ourselves and the ones online all appear to be a bit too complex. Does anyone here have a simple proof or can outline how we could approach finding one? Thanks!","['reference-request', 'graph-theory', 'discrete-mathematics']"
1673735,Compute Gradient from Jacobian,"I have some trouble understanding a formula from a report : https://www.samba.org/tridge/UAV/madgwick_internal_report.pdf It is formula (20) (Page 7). Could you tell me where it comes from? 
I can't find anything that resembles in litterature... Here is an image of the formula: http://www.les-mathematiques.net/phorum/addon.php?4,module=embed_images,url=http%3A%2F%2Fs21.postimg.org%2Ft89ej68k7%2Fpourlesmaths.png The author claims that ""Equation (20) computes the gradient of the solution
surface defined by the objective function and its Jacobian""and I don't even understand what he means by gradient since f is a function that goes from R^4 into R^3. Thanks in advance for your answer","['analysis', 'vector-analysis']"
1673809,Complex Log of the product is the sum of the Logs,"Let $z_1, \dots ,z_n$ be complex numbers such that $\Re(z_k)>0$ and $\Re(z_1 \dots z_n)>0$ for $1 \leq k \leq n$. Show that $$\log(z_1 \dots z_n) = \log(z_1)+\dots +\log(z_n)$$ where $\log$ is the principal branch of the logarithm. If the restrictions on the $z_k$ are removed, does the formula remain valid. My Solution Let $z_1, \dots ,z_n$ be complex numbers such that $\Re(z_k)>0$ and $\Re(z_1 \dots z_n)>0$ for $1 \leq k \leq n$. Consider \begin{align*}
							\log(z_1 \dots z_n)&=\ln(|z_1||z_2|\dots|z_n|)+i\arg(z_1 \dots z_n)\\
							&= \ln(|z_1|) + \dots + \ln(|z_n|) + i\arg(z_1)+\dots i\arg(z_n)\\
							&=\log(z_1) + \dots + \log(z_n)
						\end{align*} Now, clearly we must always exclude any $z_k=0$. My Question The log function loses continuity if I include the negative real axis (I'm pretty sure at least.) but I am having trouble determining if the function is still valid if the restriction $\Re(z_k)$ is removed. Thanks for your help! Edit As pointed out in the comments my solution is fallacious. I have found an example that shows it fails if $\Re(z)<0$. 
So, we are assuming that $-\dfrac{\pi}{2}<\arg(z_k)<\dfrac{\pi}{2}$. We need to show that $\arg(z_1 \dots z_n)=\arg(z_1)+ \dots+\arg(z_n)$ NOT $\arg(z_1 \dots z_n)=\arg(z_1)+ \dots+\arg(z_n) \quad \text{ mod }2 \pi$. I am not sure how to go about this from here.","['complex-analysis', 'complex-numbers', 'analysis']"
1673820,Gaussian process with independent increments,"Suppose that we have a continuous Gaussian process $(X_t)_{t \ge 0}$ with independent increments and $X_0=0$. If the increments are also identically distributed, meaning that $X_b-X_a \stackrel{D}{=} X_t-X_s$ whenever $b-a=t-s$, then $\mathbb{E}[X_t]=ct$ and $Cov(X_t,X_s)=\sigma (s \wedge t)$, where $c$ and $\sigma$ are constants. Let $a(t)=\mathbb{E}[X_t]$. Since $X_0=0$, we have that the function $a$ satisfies $a(t+s)=a(t)+a(s)$, for all $s,t \ge 0$. Also, notice that if $s<t$, then $Cov(X_t,X_s)=Cov((X_t-X_s)+(X_s-X_0),X_s-X_0)=Var(X_s)$. Putting $b(t)=Var(X_t)$ implies by independence that $b(x+y)=b(x)+b(y)$, for all $x,y \ge 0$. So, if we proof that $a(t)$ and $b(t)$ are continuous functions, we are done, since every continuous function $f$ which satisfies the identity $f(u+v)=f(v)+f(u)$ for all $u, v \in \mathbb{R}$ is linear. So, how can I proof that $\mathbb{E}[X_t]$ and $Var(X_t)$ are continuous functions on $t$?","['stochastic-processes', 'normal-distribution', 'probability-theory', 'continuity', 'brownian-motion']"
1673833,Symmetric Difference Inequality in a Probability Space,"Let (Ω, $\mathcal B$, $P$) be a probability space with $\mathcal B$ = σ($\mathcal A$), where $\mathcal A$ is an algebra of subsets
of Ω. Show that for $B$ ∈ $\mathcal B$ and all $\epsilon > 0$, there exists a set $A_\epsilon$ ∈ $\mathcal A$ such that
P($B\Delta A_\epsilon$) < $\epsilon$  and so $|P(B) − P(A_\epsilon)|$ < $\epsilon$ My attempt: Let $\epsilon > 0 $ be given. Consider the countable disjoint set $ \{A_i\}_{i =1}^\infty \subseteq \mathcal A $ such that $ B \subseteq \bigcup_{i =1}^\infty A_i $ and $ P(\bigcup_{i =1}^\infty A_i) = \sum_{i =1}^\infty P( A_i) \le \frac{\epsilon}{2} + P(B) $. Since $ P(B) \le 1 $ then $ \sum_{i =1}^\infty P( A_i) $ converges which means we can find some $ N_\epsilon \in \mathbb N $ such that for every $ n \ge N_\epsilon, \; \sum_{i =n+1}^\infty P( A_i) < \frac{\epsilon}{2} \; $. Let $ A_\epsilon = \sum_{i =1}^n P( A_i) $. \begin{align} P(B \Delta A_\epsilon) & = P(B \setminus A_\epsilon) + P(A_\epsilon \setminus B) \\\\ & \le P(\bigcup_{i=n+1}^\infty A_i) + P(\left(\bigcup_{i=1}^\infty A_i \right) \setminus B) \\\\
& \le \sum_{i=n+1}^\infty P(A_i) + \sum_{i=1}^\infty P(A_i) - P(B) \\\\
& \le \epsilon  \end{align} So suppose $ B$ and $A_\epsilon$ are disjoint. Then $|P(B)-P(A_\epsilon)| \le P(B \Delta A_\epsilon) =  P(B) + P(A_\epsilon)  < \epsilon. $ I cant figure out how to show this ineqality if $ B$ and $A_\epsilon$ are not disjoint. Also how do I show that such a such a set like $ \{A_i\}_{i =1}^\infty $ exists?","['real-analysis', 'elementary-set-theory', 'probability-theory']"
1673859,Does $A$ commute with $e^{\int A \: dt}$,"I have been studying the linear system of the form: $$D_tX = AX + \textbf{b}$$ Where $A$ is not necessarily constant Suppose we aim to find an integrating factor $M$ such that: $$M[D_tX - AX] = D_t(MX)$$ This gives: $$MD_tX - MAX = (D_tM)X + M(D_tX)$$ By equating coefficients we get: $$D_tM = -MA$$ Solving this gives: $$M = e^{-\int A \: dt}$$ But $$D_t(e^{-\int{A} \: dt}) = -Ae^{-\int{A} \: dt} = -AM$$ So can we conclude that these two matrices commute? edit I have proven that $$AM = MA$$ if and only if $$A\left(\int{A} \: dt \right ) = \left (\int{A} \: dt \right ) A$$ edit 2 After looking further into the question, it appears that for non-constant matrices $$D_te^{A(t)} \neq \left ( D_tA(t) \right ) e^{A(t)}$$ more can be found here","['dynamical-systems', 'ordinary-differential-equations', 'linear-algebra', 'systems-of-equations']"
1673864,Find the upper bound of the derivative of an analytic function,"The question is: if $f(z)$ is analytic and $|f(z)|\leq M$ for $|z|\leq r$, find an upper bound for$|f^{(n)}(z)|$ in $|z|\leq\frac{r}{2}$. My attempt:
Since $f(z)$ is analytic where $|z|\leq r$, we know that
$$f^{(n)}(z)=\frac{n!}{2\pi i}\int_{|z|=r}\frac{f(w)}{(w-z)^{n+1}}dw,$$
and $f(z)$ is bounded by $M$.
We know that $\bigg|\int_Cf(z)dz\bigg|\leq\max|f(z)|\cdot\text{(length of C)}$, so 
$$\bigg|f^{(n)}(z)\bigg|=\bigg|\frac{n!}{2\pi i}\int_{|z|=r}\frac{f(w)}{(w-z)^{n+1}}dw\bigg|\leq n!\cdot M_n\cdot2\pi r,$$
where $M_n:=\max|\frac{f(w)}{(w-z)^{n+1}}|$, for a fixed $z$. Is this correct? Just finding an upper bound seems like it shouldn't be too difficult, but I feel that I didn't do it correctly.
Also, on a somewhat related note, since $f(z)$ is analytic, and its derivatives are analytic, shouldn't $\int_{|z|=r}f^{(n)}(z)dz=0$?","['cauchy-integral-formula', 'complex-analysis', 'integral-inequality', 'complex-integration']"
1673909,Does a monodromy matrix depend on the initial condition?,"My Floquet theory is little bit rusty so I have a trivial question. Does a monodromy matrix depend on the initial conditions? On the surface it should since it is given as $B=X^{-1}(0)X(T)$ where $T$ is periodicity of my system 
$\dot{x}=A(t)x$, $A(t+T)=A(t)\mbox{, } T>0$. However $B$ actually doesn't depend on the choice of the fundamental matrix do I am not sure that it depends on the initial condition?",['ordinary-differential-equations']
1673914,On the meaning of set-valued mappings,"here one question that may look stupid. Why in general one insists on naming in a different way functions and set-valued functions just because one is single valued and the other is not? I mean, from topology, we define as function an object that maps one topological space $X$ into another one $Y$, we never require this mapping to be single-valued! Thanks!",['functions']
1673928,Max and min of $5 \sin\left(\frac{\pi}{6} x\right)+10 \cos\left(\frac{\pi}{6}x\right) +11.2$ without graphing,"$$P(x)= 5 \sin\left(\frac{\pi}{6} x\right)+10 \cos\left(\frac{\pi}{6} x\right) +11.2$$
  How would you mathematically find the the max and min points of $P(x)$ without graphing? I know that individually if say $5 \sin\left(\frac{\pi}{6} x\right)+11.2$ is of $c(x)$ then max and min would be when $\sin\left(\frac{\pi}{6} x\right)= 1$ or $-1$ ( max = 16.2 min = 6.2) thanks in advance",['trigonometry']
1673953,Evaluation of sum $\sum\sum_{0\leq i<j \leq n}j\cdot\binom{n}{i}$,"Evaluation of sum $\displaystyle \sum{\hspace{-0.3 cm}\sum_{0\leq i<j \leq n}}j\cdot \binom{n}{i}$ $\bf{My\: Try::}$ We can write it as  $$\displaystyle 1\cdot \binom{n}{0}+2\cdot \left[\binom{n}{0}+\binom{n}{1}\right]+3\cdot \left[\binom{n}{0}+\binom{n}{1}+\binom{n}{2}\right]+.....+n\cdot \left[\binom{n}{0}+\binom{n}{1}+\binom{n}{2}......+\binom{n}{n}\right]$$ Now I did not understand  How can i solve after that, Help me Thanks. If there is any combinational prove, Then plz explain here, Thanks",['combinatorics']
1673955,Shortest path between points on intersecting planes,"I have two intersecting planes and two arbitrary points $\mathbf{p}_1$ and $ \mathbf{p}_2$, one on each plane. I would like to calculate the minimum distance of a path from one point to the other with the path constrained to the planes. This is my current method for calculating the minimum distance: Find an equation for the intersection of the two planes, let's call it $\mathbf{\ell}(t)$. Then by minimizing the following distance function I should get the minimum distance: $\| \mathbf{\ell}(s)-\mathbf{p}_1 \| + \|\mathbf{\ell}(s)-\mathbf{p}_2 \|$. We differentiate to get $\frac{(\mathbf{\ell}(s) - \mathbf{p}_1) \cdot \nabla \mathbf{\ell}}{\| \mathbf{\ell}(s) - \mathbf{p}_1 \|}+\frac{(\mathbf{\ell}(s) - \mathbf{p}_2) \cdot \nabla \mathbf{\ell}}{\| \mathbf{\ell}(s) - \mathbf{p}_2 \|}=0$ I can solve this equation; however, the formula is rather unruly. I was wondering if there is a simple solution to this or a better approach. For instance is the shortest path the projection of the straight line (in $\mathbb{R}^3$) between $\mathbf{p}_1$ and $\mathbf{p}_2$ onto the two planes? Thanks in advance.",['multivariable-calculus']
1673966,Is it always possible to find one non-trivial homomorphism between modules?,"I believe this question is a elementary one, and it may have a very simple answer, of which I'm not aware yet. Given two non-trivial modules over the same non-trivial ring (or two groups, or two rings, whatever..) is it always possible to find a non-trivial homomorphism between them? Not any special type of homomorphism, just a non-trivial one. If not, could you give me a counter-example? I am thinking if I can make a commutative diagram like this: be $X$, $Y$ and $Z$ non-trivial modules over the same ring, and be $\lambda: Z \rightarrow X$ a module-homomorphism, whose image $\text{Img}(\lambda)$ is a proper submodule of $X$. So the quotient module $X/\text{Img}(\lambda)$ is a non-trivial module. Can I guarantee existence of a non-trivial module-homomorphism between $X/\text{Img}(\lambda)$ and $Y$, my arbitrary module? And by that, I have a induced non-trivial homomorphism between $X$ and $Y$.","['abstract-algebra', 'modules']"
1673978,Does $|X|<|Y|$ imply $\mathcal{P}(X)<\mathcal{P}(Y)?$ [duplicate],"This question already has an answer here : Bijection between power sets of sets implies bijection between sets? [duplicate] (1 answer) Closed 8 years ago . This might be a terribly simple question, but I cannot convince myself whether the answer is yes or no. Maybe I am missing something simple. I am not well-versed in the area of elementary set theory so excuse the simplicity of the question. Note within a world where $\mathsf{GCH}$ is true we clearly have a yes; but with $\mathsf{GCH}$ false the answer is no longer obvious to me. Exclude the triviality of finite sets. If $|X|<|Y|$ then $|X|<|Y\setminus X|$ so say $|X|=\kappa$, then $|Y|=\kappa+\lambda$ with $\kappa<\lambda$. But then proving $2^{\kappa}<2^{\lambda}$ is equivalent to the initial problem. Am I being silly or is it consistent with $\mathsf{ZFC}$ that this implication is false?","['cardinals', 'elementary-set-theory']"
1673980,What can we move $dx$ around and integrate both sides when solving ODE?,"It is a common practice to move the $dx$ around when solving ODE and we take for granted when we integrate both sides. However, I've been rather uncomfortable with this. From an analysis perspective, $dx$ itself doesn't make sense to me. Instead, we always consider $\frac{df(x)}{dx}$, or the operator $\frac{d}{dx}$ by itself. Now, some people argue that both $dy$ and $dx$ are infinitesimal things that are not equal to zero, and thus we can move them around. But that doesn't convince me neither. Shouldn't we concretely define what $dy$ and $dx$ are before we do anything to them? Is it possible to justify moving $dx$ around by using $\delta-\epsilon$ analysis? As for integrating both sides, what annoys me is that sometimes extra terms (usually the constant $C$) appear. It's tempting to think of ""integrating both sides"" as a kind of operations (maybe not binary?) just like add or subtract, but that doesn't seem right because by apply indefinite integral a function we actually get a bunch of functions. What is the right way to think of this process? Should we think about this process under the framework of algebra, maybe? Hope my questions make sense. Thanks.","['ordinary-differential-equations', 'calculus']"
1674027,Proving that if $|W(-\ln z)| < 1$ then $z^{z^{z^{z^...}}}$ is convergent,"Let $z \in \mathbb{C}$ and let $W$ be the Lambert $W$ function. In this post it is shown that if $|W(-\ln z)| > 1$ then the infinite power tower $z^{z^{z^{z^...}}}$ does not converge, that is $|W(-\ln z)| \leq 1$ is a necessary condition for the convergence of $z^{z^{z^{z^...}}}$. Here I would like to show that $|W(-\ln z)| < 1$ is a sufficient condition, that is if $|W(-\ln z)| < 1$ then $z^{z^{z^{z^...}}}$ is convergent.","['complex-numbers', 'lambert-w', 'complex-analysis', 'tetration', 'sequences-and-series']"
1674079,Why isn't there a formula for $\zeta(k)=\sum_{n=1}^\infty\frac{1}{n^k}$ involving $\pi$ when $k$ is odd?,"Now we know that $\sum \frac{1}{n}=\text{divergent}, \sum \frac{1}{n^2}=\frac{\pi^2}{6}$ but now this for $\sum \frac{1}{n^3}=1.20....$ and again $\sum \frac{1}{n^4}=\frac{\pi^2}{90}$ .Now somewhere there is a general term when $n$ has power $2k$ where $k$ is a positive integer. Why doesn't there exist a $\pi$ series for odd numbers like $n^3$, $n^5$?","['riemann-zeta', 'sequences-and-series', 'pi']"
1674126,On how to solve the ODE $v'-\frac{1}{v}=x$...,"I've been having trouble finding the general solution of $v$ for $v'-\frac{1}{v}=x$. I've attempted various substitutions in attempts of obtaining separation of variables or recognizable form to apply the method of the integrating factor. A couple of substitutions I've attempted:
$$\alpha=\frac{1}{v}$$
$$\beta=\frac{1}{\alpha^2}$$
I tried others but threw out the scratch paper (yeah...would've helped now to see the other substitutions that didn't work so I don't reattempt them...). Does anyone have an idea of how to get this DE into a form we can play with? Please don't supply the final to the DE. I'm simply looking for direction down the proper path.","['substitution', 'integration', 'ordinary-differential-equations']"
1674131,Does elementwise matrix inequality extend to norms?,"The elements of $A$ and $B$ are non-negative and $0 \le A_{ij} \le B_{ij}$ $\forall i,j$ . Is it true that $\Vert A \Vert_p \leq \Vert B \Vert_p$ ? The norm is the operator norm induced by the usual vector $p$ -norm. This is an exercise problem from A Brief Introduction to Numerical Analysis by E. Tyrtyshnikov and am using the book for self-study. My intuition is that it is true, when I think of vectors with all non-negative components, but am unable to give a proof in general.","['matrices', 'normed-spaces', 'linear-algebra', 'operator-theory']"
1674231,Closed form solution to an ordinary differential equaiton,"How to solve the following ordinary differential equation? $$y'(x)=
\frac{C_1}{y(x)}
+C_2 C_3 \cos\left(C_3 x\right) +C_4$$ where $C_1, C_2, C_3, C_4\in \mathbb{R}$ are all constants. It looks simple but difficult to solve.","['ordinary-differential-equations', 'fundamental-solution', 'closed-form']"
1674257,What's wrong with this logarithm calculation?,"We know that $\displaystyle\log_a(xy)=\log_ax+\log_ay$. Consider the following: $$\displaystyle\ln(1)=\displaystyle\ln((-1)\times(-1))=\displaystyle\ln(-1)+\displaystyle\ln(-1)
$$ $\displaystyle\ln(1) $ is a completely valid statement, but I'm not sure if $\displaystyle\ln(-1)+\displaystyle\ln(-1) $ is. $\displaystyle\ln(-1) $ doesn't exist, but $\displaystyle\ln((-1)\times(-1)) $ does, and if I plug $\displaystyle\ln((-1)\times(-1)) $ into my calculator it gives a 0 as the answer (which is correct), but if I plug in $\displaystyle\ln(-1)+\displaystyle\ln(-1) $ it says that there is a domain error (which there is). So my question is, what is wrong with the highlighted equation?","['algebra-precalculus', 'logarithms']"
1674258,All hill-stations have a lake. Ooty has two lakes?,"All hill-stations have a lake. Ooty has two lakes. Which of the statement(s) below is/are logically valid and can be inferred from the above sentences? $(i)$ Ooty is not a hill-station. $(ii)$ No hill-station can have more than one lake. $(i)$ only $(ii)$ only both $(i)$ and $(ii)$ neither
            $(i)$ nor $(ii)$ My attempt : Statement $(i)$ can be false, since all hill-stations has lake, but if a city has lakes, that does not mean that city is a hill-station. For statement $(ii)$, a lake means may be any lake means number is not given. I've not formal way, this statement given false. Can you explain in formal way, please?","['first-order-logic', 'predicate-logic', 'propositional-calculus', 'logic', 'discrete-mathematics']"
1674302,Does pointwise convergence implies uniform convergence when the limit is continous?,"Suppose we have a series of functions $f_n: \mathbb R \rightarrow [0,1]$ and continous function $f: \mathbb R \rightarrow [0,1]$. Suppose that $f_n \rightarrow f$ pointwise as $n \rightarrow \infty$. Is it true, that $f_n$ converges uniformly also? What is the case if all $f_n$ and $f$ are monotone functions? Edit1 : Consider the case when $f_n$ and $f$ are distribution functions. All are monoton, continous functions with $$\lim_{x\to -\infty}f(x)=0$$ and $$\lim_{x\to\infty}f(x)=1.$$ There are numerous question on the site already, the most relevant is this: Does pointwise convergence against a continuous function imply uniform convergence? In the marked answer, there are two counterexamples, but I think both example series of functions converge to a $g(x)=\delta(x)$, which is not continous . Am I right? If yes, how the original statement could be proved? I am also aware of Dini's Theorem, but that applies only to function on closed intervals.","['real-analysis', 'probability-distributions', 'uniform-convergence', 'probability-theory']"
1674335,Limit definition of curvature and torsion,"Given two point, $P$ and $Q$, lying on a curve $\gamma: \mathbb{R} \to \mathbb{R}^3$, curvature at $P$ can be defined via limit $$\kappa (P) = \lim_{Q \to P} \sqrt{\frac{24 (s(P,Q) - d(P,Q))}{s(P,Q)^3}},$$ where $s(P,Q)$ is the arc length of the curve $\gamma$ between the points $P$ and $Q$, and $d(P,Q)$ is the length of a line segment from $P$ to $Q$. Is there a similar geometrical definition of torsion at $P$?","['differential-geometry', 'geometry']"
1674338,The $n$th integral of $\ln(x)$ and fractional derivatives,"For a related question, I need to know the $n$th integral of $\ln(x)$ and the fractional derivative of $\ln(x)$. A break down of how fractional derivatives may be found on the Wikipedia. In particular, I need to calculate $\frac{d^{1/2}}{dx^{1/2}}\ln(x)$ and $\frac{d^{-n}}{dx^{-n}}\ln(x)$ where that is the $n$th integral of $\ln(x)$. The fractional derivative in this scenario is given by: $$\frac{d^{1/2}}{dx^{1/2}}\ln(x)=\lim_{h\to0}\frac{(-1)^{1/2}}{h^{1/2}}\sum_{0\le m<\infty}\frac{\Gamma(1.5)}{\Gamma(m+1)\Gamma(1.5-m+1)}\ln(x+mh)$$ It is rather difficult to take the limit from my skills, so I was hoping someone could solve it.  (I do accept power series answers or anything the cannot be written in easy closed form) Secondly, I have attempted to find the $n$th integral of $\ln(x)$ and this is what I found $$\frac{d^{-n}}{dx^{-n}}\ln(x)=\frac{x^n[\ln(x)-\sum_{i=1}^{n}\frac1i]}{\Gamma(n+1)}$$ Two problems about this formula, I'm unsure if it works fully, and I need it to work for non whole $n$. Thanks for your time and efforts.","['limits', 'logarithms', 'calculus', 'fractional-calculus', 'summation']"
1674342,Integrating when power is -1,"I'm studying acceleration as a function of velocity and displacement as part of my mechanics module, but I'm not sure how to integrate this acceleration expression. If you had a situation were $a = \frac{1}{s + 2}$ and you wanted to find $s$ when $v$ is equal to a certain value, you would have to integrate the above equation like $\int v dv = \int \frac{1}{s + 2} ds$, or as far as I understand anyway.  But if you bring $s + 2$ to negative index form you get $s^{-1} + 2^{-1}$, and if you were to integrate that expression you would get powers of $0$ and it would not work.  Obviously I'm doing it wrong, but that is my thought process.","['integration', 'functions']"
1674343,What are the elements of a filtration generated by a Wiener process?,"I understand the concept of filtration intuitively, and I can wrtite down the elements of a filtration for example in the case of a coin toss game, but what are the sets in the filtration of a Wiener process at a given time? How do they look like?","['stochastic-processes', 'probability-theory', 'probability']"
1674433,Probability measure on $\mathbb N$ such that $P(n \mathbb N) =1/n$ for all $n \ge 1$ cannot exist,"How to prove that $\mathbb N$ cannot be endowed to a probablity space $(\mathbb N, \mathcal F, P)$ such that for all integer $n \ge 1$ we have $$P(n \mathbb N)=\frac{1}{n}$$ I imagine that divergence of the harmonic series and inclusion-exclusion principle are good ingredients to be used... But I don't know how up to now!","['probability-theory', 'integers']"
1674448,"When is ${{x^2y} \over {(x^2+y^2)^\alpha}}$ continuous, using polar-coordinates","Given $$f ({x,y})= \begin{cases} {{x^2y} \over {(x^2+y^2)^\alpha}},&(x,y) \ne {(0,0)}\\ 0,&(x,y)={(0,0)} \end{cases}$$ For what values of $\alpha$, $f$ is continuous in ${(0,0)}$? I set $\space x=r \cos \theta$, $\space y=r \sin \theta$ and get
$${{x^2y} \over {(x^2+y^2)^\alpha}} = r^{3-2 \alpha}\cos ^2 \theta\sin \theta $$ so it goes to $f(0,0)=0$ if $\space {3-2 \alpha}>0$, namely $\alpha < {3 \over 2}$. But Can I say this is iff ? And also the limit is not $f(0,0)=0$ (or not exist) if $\alpha \ge {3 \over 2}$?","['real-analysis', 'polar-coordinates', 'calculus', 'multivariable-calculus', 'continuity']"
1674455,limit $ \lim \limits_{n \to \infty} {\left(\frac{z^{1/\sqrt n} + z^{-1/\sqrt n}}{2}\right)^n} $,"Calculate the limit $ \displaystyle \lim \limits_{n \to \infty} {\left(\frac{z^{1/\sqrt n} + z^{-1/\sqrt n}}{2}\right)^n} $ I now the answer, it is $ \displaystyle e^\frac{\log^2z}{2} $, but I don't know how to prove it. It seems like this notable limit $\displaystyle \lim \limits_{x \to \infty} {\left(1 + \frac{c}{x}\right)^x} = e^c$ should be useful here. For example I tried this way: $$ (z^{1/\sqrt n} + z^{-1/\sqrt n}) = (z^{1/(2 \sqrt n)} - z^{-1/(2 \sqrt n)})^2 + 2 $$ $$ \displaystyle \lim \limits_{n \to \infty} {\left(\frac{z^{1/\sqrt n} + z^{-1/\sqrt n}}{2}\right)^n} = \displaystyle \lim \limits_{n \to \infty} {\left(1 + \frac{(z^{1/(2 \sqrt n)} - z^{-1/(2 \sqrt n)})^2}{2}\right)^n} $$ where $ (z^{1/(2 \sqrt n)} - z^{-1/(2 \sqrt n)})^2 $ seems close to $ \frac{\log^2 z}{n} $. Also we can say that $$ \left(\frac{z^{1/\sqrt n} + z^{-1/\sqrt n}}{2}\right)^n = e^{n \log {\left(1 + \frac{\left(z^{1/(2 \sqrt n)} - z^{-1/(2 \sqrt n)}\right)^2}{2}\right)}}$$ and $ \log {\left(1 + \frac{(z^{1/(2 \sqrt n)} - z^{-1/(2 \sqrt n)})^2}{2}\right)} $ can be expand in the Taylor series. But I can't finish this ways. Thanks for the help!","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
1674466,Why isn't the limit of $\sin(1/x)/(1/x)$ as x goes to zero 1?,"The proof of $\lim\limits_{x \to 0}\dfrac{\sin x}{x} = 1$ I remember says that because $\cos x \leq \dfrac{\sin x}{x} \leq 1$ for all $-\pi/2< x< \pi/2$ and both $\cos x$ and $1$ is going to $1$ as $x$ goes to $0$, $\frac{\sin x}{x}$ must also be going to $1$. But if you replace $x$ with $1/w$ for all $w$ in $(-2/\pi, 2/\pi)$. But the problem is $\frac{\cos (1)}{0}$ is not a definite value. I don't know how I can use Squeezing Theorem here, help!","['trigonometry', 'limits']"
1674470,When is random selection skewed (untrustworthy)?,"Imagine there is a population of 100 people, out of which 3 are to be randomly selected each day for alcohol testing. After a month of such selections (after 20 selections), how many times somebody needs to be selected before I need to worry about the randomness in the process? Real data: I got two people selected 3 times each; seven people selected 2 times, and a bunch of them selected 1 time (and another bunch never selected) in the previous month. If the same person gets selected everyday for 20 days, there certainly ( about 99.9999999999% ) is something wrong. What's the chance that there's something when a person is selected 5 times? What is he's selected 4 times? 3 times? What if two people get selected 4 times each? ... When should I start thinking about making weighted selections? How do I go about making these kind of calculations?","['statistics', 'probability', 'random']"
1674488,What is $\tan(\operatorname{arcsec} (x))$?,"What is $\def\arcsec{\operatorname{arcsec}}\tan(\arcsec(x))$ simplified and why? More specifically, I followed this reasoning, but apparently it is wrong: $\tan(\arcsec(x))=\sqrt{\sec^2(\arcsec(x))-1}=\sqrt{x^2-1}$ What is wrong with this reasoning? Apparently the answer is: $\sqrt{x^2-1}$ for $x\ge1$ and $-\sqrt{x^2-1}$ for $x\le1$ Why is this the right answer?","['trigonometry', 'calculus']"
1674498,Solve the limit $\lim _{x\to \infty \:}\left(\frac{\left(\left(2x\right)!\right)}{x^xx!}\right)^{\frac{1}{x}}$,"We need to solve this limit $\lim _{x\to \infty \:}\left(\frac{\left(\left(2x\right)!\right)}{x^xx!}\right)^{\frac{1}{x}}$
 we guess that the answer is 1, as n approach infinity 1/n => 0 so anything besides 0 to the power of 0 = 1 (except 0 of course). We need to ensure if we had the right answer, please write some hints here.","['limits-without-lhopital', 'calculus', 'limits']"
1674515,If $X$ has non-singular normalization $\dim (\mathrm{Sing(X)})=\dim (X)-1$?,"Let $X\subseteq\mathbb{P}^{N}$ be an algebraic variety, and let 
$$
\nu:X^{\nu}\rightarrow X
$$
be its normalization. Let us suppose that $X^{\nu}(\neq X)$ is smooth. I wonder if in this case
$$
\dim (\mathrm{Sing(X)})=\dim (X)-1.
$$
I think Serre's Normality Criterion (See Lemma 12.5 of this text) has something to do with it, but I can't see how. Maybe
$$
X^{\nu} \text{ smooth }\Rightarrow
$$
$$
\Rightarrow
 X\text{ satisfies the property $(S_{2})$ (i.e. $\forall$ $x\in X, \mathrm{depth}(\mathcal{O}_{X,x})\geq \min\{2,\dim(\mathcal{O}_{X,x})\}$)},
$$
in which case the equality follows from the fact that $X$ is reduced, not normal, and would satisfy $(R_{1})$ if 
$$
\dim (\mathrm{Sing(X)})<\dim (X)-1.
$$
Is that implication true? At least, is the equality true?",['algebraic-geometry']
1674576,How does law of cosines work with vectors?,"I just recently started physics for fun and started with the basics but something is already bugging me. It is about the implementation of law of cosines to sum of vectors. I know how it works with triangles. I get the logic about the interaction between the two edges and the angle between them. But there is something I don't understand about choosing which angle we should use for the formula. In the following visual: Orange vector's magnitude is $2$ and angle is $0^\circ$. Green vector's magnitude is $2$ and angle is $45^\circ$. Grey is sum. Blue is X line. Red is Y line. Now angle $\angle B = 45^\circ$ and therefore $\angle A = 135^\circ$. If we consider the shape as a triangle, then in order to find the grey line, we must implement the law of cosines with $\cos 135^\circ$. Like this: $$V_\text{grey}=\sqrt{{V_\text{orange}}^2 + {V_\text{green}}^2 - 2V_\text{orange}\cdot V_\text{green}\cos 135^\circ}$$ However, on the tutorial I have seen on the internet, when calculating the sum of vector forces, they use $\cos 45^\circ$ in the formula instead, saying we must use the angle between the vectors (in the tutorial they both originate from the $(0,0)$ point). But then, when generating the shape geometrically, we technically don't use the angle that is facing the edge we want to find the value of. Can someone explain why we use $\cos 45^\circ$ and not $\cos 135^\circ$?","['vectors', 'geometry']"
1674594,On the probability of getting the same number for three dice,"I found the probability of having the same number when throwing 3 dice to be $1\times\left(\frac16\right)^2$. In addition, I don't understand how do people get the equation $\left(\frac16\right)^3\times6=\frac1{36}$, like why do we have to multiply $\left(\frac16\right)^3$ by six?","['probability', 'dice']"
1674600,Calculating $\int_0^\infty \frac{\sin(x)}{x} \frac{\sin(x / 3)}{x / 3} \frac{\sin(x / 5)}{x / 5} \cdots \frac{\sin(x / 15)}{x / 15} \ dx$,"I found the following result on this webpage : $$\int_0^{\infty } \left(\prod _{k=0}^7 \frac{\sin \left(\frac{x}{2 k+1}\right)}{\frac{x}{2 k+1}}\right) \, \mathbb{d}x= \frac{\pi}{2} - \frac{6879714958723010531}{935615849440640907310521750000} \pi $$ However, I can't determine how to prove it.","['closed-form', 'products', 'improper-integrals', 'integration', 'trigonometric-integrals']"
1674660,"Minimal prime ideals of $\mathcal O_{X,x}$ correspond to irreducible components of $X$ containing $x$","Let $X$ be an algebraic variety over an algebraically closed field $K$.  By definition, $X$ is a separated prevariety, and $x \in X$.  I'm trying to show (i): The minimal primes of $\mathcal O_{X,x}$ are in bijection with the irreducible components of $X$ containing $x$. Since $\mathcal O_{X,x}$ is reduced, this shows in particular that (ii): $\mathcal O_{X,x}$ is an integral domain if and only if $x$ lies in only one irreducible component. The affine case is pretty easy.  Here $X = \textrm{Max } A$ for some reduced finitely generated $K$-algebra $A$.  If $m \in X$, the stalk $\mathcal O_{X,m}$ is canonically isomorphic to $A_m$, and prime ideals here are in bijection with primes $P$ of $A$ contained in $m$, i.e. primes $P$ for which $m \in V(P) = \{ \mathfrak m \in X : P \subseteq \mathfrak m\}$.  Primes $P$ correspond to irreducible closed sets $V(P)$, with minimal primes corresponding to irreducible components, done. This is apparently supposed to generalize to the nonaffine case, but I'm just not seeing it.  If $X_1, ... , X_s$ are all the irreducible components of $X$, and $x$ lies only in $X_1, ... , X_t$, and if I pick an affine open set $U$ containing $x$, then a subset of $X_1 \cap U, ... , X_s \cap U$ are the irreducible components of $U$, and a subset of $X_1 \cap U, ... , X_t \cap U$ are the components containing $x$.  On account of the fact that intersecting the $X_i$ with $U$ may produce some repetition or loss of information, I do not think that (i) is true in general. What do you think?","['ringed-spaces', 'algebraic-geometry', 'commutative-algebra']"
1674691,Branch of the cube root,"Let $f(z)=z^{1/3}$ be the branch of the cube root whose domain of definition is given by $0<\theta<2\pi$, $z\neq 0$ (i.e. the branch cut is along the ray $\theta=0$.) Find $f(-i)$. Could someone please help me understand the question? I'm not too clear on ""branches"" and ""branch cuts"".","['complex-analysis', 'complex-numbers']"
1674699,Explanations for why someone cannot divide by $x-4$ for $x(x-4)=x(x-4)(x-5)$,"A student divides both sides by $x-4$ and lost a solution $x=4$. How could you explain to the student that they are not allowed to divide by $x-4$ Here is the problem: $x(x-4)=x(x-4)(x-5)$ I am having a hard time putting this in words for some reason. We know if the student divides by $x-4$ on both sides, not only do they lose a solution but technically they are dividing by $0$. Does anyone have any other explanations","['algebra-precalculus', 'problem-solving']"
1674720,Does the first derivative test always work for finding minima and maxima?,"Suppose you want to find the max of the function $\ f(x)=\sqrt{x} - x$.
Using the first derivative test you get, $f'(x)= \frac{1}{2\sqrt{x}} - 1$ .
If we equate this to $0$ we get $x =\frac{1}{4}$. Taking as $x$ as $0.20$ and $0.30$, we get that the first derivative doesn't change signs (remains positive). However, if x is taken as $x > 1$, then the first derivative becomes negative. Graphing the function reveals that $x =\frac{1}{4}$ is indeed the maximum point. Taking the second derivative $\ f\prime\prime(x)= \frac{-1}{4x^\frac{3}{2}}$ and using the second derivative test at the point $x =\frac{1}{4}$ shows the second derivative is negative, indicating a maximum. My question therefore is does the first derivative test necessarily always show the maximum? Both the graphs and second derivatives indicate a maximum; however if the first derivative is taken with $x < 1$ then the first derivative test fails. Can someone explain how this could happen?","['derivatives', 'calculus']"
1674755,Proving that $\mathbb{R}P^n$ is a manifold,"Consider $\mathbb{R}P^n$ as the quotient space of $S^n$ with antipodal points identified. Prove that $\mathbb{R}P^n$ is a manifold of dimension $n$. (I'd like to clarify that I've seen the solution to this exersice when we see $\mathbb{R}P^n$ as the quotient of $\mathbb{R}^{n+1}$ with lines identified. I'd like to know if the same answer would solve the problem when it is quotient of $S^n$.) I already proved $\mathbb{R}P^n$ is $T_2$ and second countable. By doing the same thing when $\mathbb{R}P^n$ is quotient of $\mathbb{R}^{n+1}$, I consider the open set: $$V_i=\{x\in S^n:x_i\neq 0\},\quad \quad i=1,...,n+1,$$ and $$F_i:V_i\to\mathbb{R}^n,\quad F_i(x_1,...,x_{n+1})=\dfrac{1}{x_i}(x_1,..,x_{i-1},x_{i+1},...,x_n).$$ And then one should prove that $\phi_i:\pi(V_i)\to\mathbb{R}^n$ given by $\phi_i(\pi(x))=F_i(x)$ is a homeomorphism (where $\pi$ is the projection, which is open). I already proved $\phi _i$ is injective and continuous, but I can't prove that it is surjective. If we take any $(x_1,..,x_n)\in\mathbb{R}^n$, the natural choice would be: $$F_i(x_1,...,x_{i-1},1,x_{i},...,x_n)=(x_1,...,x_n).$$ But $(x_1,...,x_{i-1},1,x_{i},...,x_n)$ need not be in $S^n$.
Also, what would be $\phi^{-1}$? (In order to prove the inverse is continous...) Or maybe $\phi_i$ is not surjective and we need another function. Any help? Thank you.","['differential-geometry', 'differential-topology']"
1674783,Diffeomorphism preserves open set?,"This question might be elementary, but I am a little confused. Does diffeomorphism preserve open sets? Suppose I have two coordinate charts $(U,\varphi)$, $(V,\psi)$ and atlas $\mathcal{A}=\{(U_{\alpha},\varphi_{\alpha})\}$ such that the two charts are compatible with $\mathcal{A}$. Then clearly $\varphi_{\alpha}(U\cap U_{\alpha})$ and $\varphi_{\alpha}(V\cap U_{\alpha})$ are open. How can I conclude then that $\varphi_{\alpha}(U\cap V\cap U_{\alpha})$ is also open? I know that $U\cap V\cap U_{\alpha}$ is open, so is the openness preserved by $\varphi_{\alpha}$?","['smooth-manifolds', 'differential-geometry']"
1674787,Is the product $f_ng_n$ of weak-star convergence sequences $(f_n)$ and $(g_n)$ in $L^\infty$ also weak-star convergent?,"Suppose $X$ is a finite measure space, and $f_n$ is uniformly bounded and converges to $f$ in the weak-star topology of $L^\infty(X)$. This means $\int f_n\phi \to \int f\phi$ for all $\phi\in L^1(X)$. If also $g_n$ is uniformly bounded and converges to $g$ in the weak-star topology of $L^\infty(X)$, does the product $f_ng_n$ converge weak-star to $fg$? Thank you.","['functional-analysis', 'lp-spaces', 'weak-convergence']"
1674799,Expected squared prediction error conditioned on training set,"I'm reading Elements of Statistical Learning by Hastie and Tibshirani, and I am thoroughly confused by the way they conditioned expected squared prediction error in section 2.5 (p.26):
\begin{align*}
EPE(x_0) &= E_{y_0|x_0} E_{\mathcal{T}} (y_0 - \hat{y}_0)^2
\end{align*} I think $\mathcal{T}$ refers to the training set, and $(x_0, y_0)$ is the testing set. What is the joint distribution that $EPE(x_0)$ is evaluated with?  I can't make sense of what the distribution $f(y_0|x_0)*\pi(\mathcal{T})$ even means.  I've seen many questions asked about their earlier definition of the $EPE$ (p.18):
\begin{align*}
EPE(f) &= E_X E_{Y|X} ([Y - f(X)]^2|X)
\end{align*}
Here, the conditioning makes sense.  I can see that the $EPE$ is with respect to the joint distribution of $X$ and $Y$, where $X$ is the input vector and $Y$ is the output vector.  Could someone please explain why the $EPE(x_0)$ written on top makes sense?","['machine-learning', 'statistics', 'probability']"
1674800,Addition is to Integration as Multiplication is to ______,"Addition is to Integration as Multiplication is to ______ ? Everyone knows that definite integration  is ""a way to sum continuum-many terms"" in a rough sense. Can we ""multiply continuum-many factors""  in a similar sense?","['calculus', 'analysis']"
1674831,Minimizing a functional in the Sobolev space $H_0^1$,"I am trying to show that, given $f \in H^{-1}(U)$, there exists a unique $u \in H_0^1(U)$ such that:
$$\int_U \nabla u\cdot\nabla v \, \mathrm{d}x= \langle f,v \rangle_{H^{-1}} \, , \quad \forall \, v \in H_0^1(U) \, .$$
To this end, I define the functional $J \colon H_0^1(U) \to \mathbb{R}$ by:
$$J(v):=\int_U \left\| \nabla v \right\|^2 \, \mathrm{d}x- \langle f,v \rangle_{H^{-1}}.$$
Then I would like to do the following: Show that $J(v)$ is bounded from below; Show that there is a weakly convergent sequence whose limit in $H_0^1(U)$ minimises $J$ (hence the inf is achieved); Show that this limit satisfies the problem and it is unique. Number 3 is quite easy, but I am stuck on 1 and 2. I am not sure how to proceed. So far I have oly been able to use the definition of $\|\cdot\|_{H^{-1}}$ to get:
$$J(v) \geq \int_U \left\| \nabla v \right\|^2 \, \mathrm{d}x- \|f \|_{H^{-1}} \|v\|_{H_0^1} \, .$$
Any pointers would be very helpful. P.S.: I am aware that this could be shown by applying Lax-Milgram but I need to take this direct approach.","['optimization', 'normed-spaces', 'functional-analysis', 'weak-convergence', 'sobolev-spaces']"
1674833,"T/F: If $\frac{x}{y}=\frac{x}{z}$ where $y,z \neq 0$","T/F: If $\dfrac{x}{y}=\dfrac{x}{z}$ where $y,z \neq 0$ then $y=z$ I think this is true but my teacher is known for giving trick questions. If x=2 then for the left side and right side to be equal, the denominators must be equal. Any counterexamples or explanations?",['algebra-precalculus']
1674841,When do you use indicator random variables?,"One of the most difficult concepts that I can't seem to get my head around are indicator random variables. I understand what they are and I understand what to do. But when I am faced with a question, I never think to use them. When do you actually use indicator random variables in statistics questions such as estimation questions, questions about random variables and probability distributions etc Thanks!","['statistics', 'probability']"
1674889,$\lim_{n\to \infty}\left(\frac{\sqrt[n]{a}+\sqrt[n]{b}}{2}\right)^n\stackrel{?}{=}\sqrt{ab}$,"I found this interesting equality, but I could not find a way to prove it. Any (beautiful) idea? $$\lim\limits_{n\to \infty}\left(\frac{\sqrt[n]{a}+\sqrt[n]{b}}{2}\right)^n=\sqrt{ab}$$","['logarithms', 'radicals', 'calculus', 'limits']"
1674944,B is an element of some power set of A such that A is an element of F.,"$$B \in \{\,\mathcal P(A) \mid A \in F\,\}$$ I can't quite figure this out. My textbook says this statement is equivalent to $$\exists A \in F\ \forall x\ (x \in B \leftrightarrow \forall y\ (y \in x \rightarrow y \in A))$$ How do you derive the last statement from the first? And how would you read this in a natural language?","['elementary-set-theory', 'quantifiers']"
1674963,Meaning of two solutions to $\sin^2(x)+\cos^2(x)=1$,I understand that $\sin^2(x)+\cos^2(x)=1$ Does that mean that $\sin(x)=\pm\sqrt{1-\cos^2(x)}$? Specifically: I don't understand the meaning of the $\pm$ sign: what is the difference between the positive and the negative solution? How to know what solution to pick?,"['trigonometry', 'calculus']"
1674990,Rational Points on $\sin x$ and $\cos x$,"Are there any values for $x$ such that both $\sin x$ and $\cos x$ are rational besides $\displaystyle\frac{n\pi}{2}$ and $n\pi$ , where $n$ is an integer? I also only want to include $x$ values that are rational multiples of $\pi$ . If not, how could one prove that there aren't? I was thinking that a proof may use the fact that $\displaystyle\frac{\sin x}{\cos x}=\tan x$ , but I don't see how this could be done. I suspect that no such points exist since this page shows exact values of many angle and none of them are rational. That being said,  I can't prove anything for certain.","['trigonometry', 'irrational-numbers']"
1675005,Lagrange multipliers on manifolds in Lee's book,"Here is Problem 11-11 on page 301 of John Lee’s book: Let $ M $ be a smooth manifold, and $ C \subset M $ be an embedded sub-manifold. Let $ f \in {C^{\infty}}(M) $ , and suppose $ p \in C $ is a point at which $ f $ attains a local maximum or minimum value among points in $ C $ . Given a smooth local defining function $ \Phi: U \to \mathbb{R}^{k} $ for $ C $ on a neighborhood $ U $ of $ p $ in $ M $ , there are real numbers $ \lambda_{1},\ldots,\lambda_{k} $ (called Lagrange multipliers ) such that $$
\mathrm{d} f_{p} = \sum_{i = 1}^{k} \lambda_{i} \cdot \mathrm{d} \Phi^{i}|_{p}.
$$ I got confused when I was trying to solve it. Here are my questions: (1) He didn’t say anything about the dimension of $ M $ and $ C $ , nor did he put corrections here . Is it necessary to assume that $ \operatorname{dim}(M) = n > k $ and $ \operatorname{dim}(C) = n - k $ , or do these results implicitly follow from the conditions of this problem? (2) Why do we need the condition that $ C $ is an embedded sub-manifold? Assume $ \operatorname{dim}(C) = n - k $ ; then Theorem 5.8 on page 102 tells us that $ C $ satisfies the local $ k $ -slice condition (this is the only theorem I can think of that is related to this condition), but what good can this condition do for us? (3) I think I need to apply the Lagrange Multiplier Theorem (see page 113) in multi-variable calculus, but we need to make sure that the rank of the Jacobian matrix of $ \Phi $ is of rank $ k $ at the point $ p $ . However, there aren’t any extra conditions on $ \Phi $ . You can either answer my questions separately or show me a detailed proof of it. Thank you in advance!","['multivariable-calculus', 'smooth-manifolds', 'differential-geometry', 'lagrange-multiplier']"
1675006,Sum and difference formula for $\tan$ - I keep getting positive instead of negative answer,"Sorry if this question is long/repetitive. I'm trying to list every single step to see where I've messed up. The question is to find $\tan(\frac{\pi}{4} + \frac{\pi}{3})$. Using a calculator, I get $-3.72$ or $-2 -\sqrt{3}$. This will be used to check my answer. I know that the sum and difference formula for $\tan$ is: $$\tan(\alpha \pm \beta) = \frac{\tan(\alpha) \pm \tan(\beta)}{1 \mp \tan(\alpha) \tan(\beta)}$$ Plugging the values in, I get: $$\tan(\frac{\pi}{4} + \frac{\pi}{3}) = \frac{\tan(\frac{\pi}{4}) + \tan(\frac{\pi}{3})}{1 - \tan(\frac{\pi}{4}) \tan(\frac{\pi}{3})}$$ $$\frac{1 + \sqrt3}{1 - (1)(\sqrt3)}$$ $$\frac{1 + \sqrt3}{1 - \sqrt3}$$ Now in order to rationalize this, I must multiply by the conjugate of $\sqrt3 - 1$: $$\frac{(\sqrt3 + 1)(\sqrt3 + 1)}{(\sqrt3 - 1)(\sqrt3 + 1)}$$ The formulas for easy FOIL is: $$(x + a)(x + a) = x^2 + 2ax + a^2$$
$$(x + a)(x - a) = x^2 - a^2$$ Resulting in: $$\frac{3 + 2\sqrt3 + 1}{3 - 1}$$
$$\frac{4 + 2\sqrt3}{2}$$
$$2 + \sqrt3$$ As you can see, the answer is correct, but the signs are incorrect. Where did I screw up?",['trigonometry']
1675010,Why does $\sum_{n=0}^{\infty} \cos^n(n)$ converges?,"Consider the series $$\sum_{n=0}^{\infty}\cos^n(n)$$ I think that the root test is inconclusive, because $$\limsup_n \sqrt[n]{|\cos^n(n)|}=\limsup_n|\cos(n)|\leq 1$$ once we can approximate $\pi$ by rational numbers, there will always be some $i$ and $j\in\mathbb{N}$ such that $|j\pi-i|<\varepsilon$, for every $\varepsilon>0$ that we choose. And in this case $|\cos(i)-1|<\delta$. Nevertheless, it seems that it converges . I can't think of any other convergent series to compare with it. My question is: how can I prove that this series converges? Edit : Actually, this series diverges, as you can see in tmyklebu's answer. I made a fortran program  and here are some values of the sequence of the partial sums: n     S_n
10    1.5898364866640549
100   7.8365722183614510
1000  24.825953005207236
10000 79.232008037801393","['real-analysis', 'sequences-and-series', 'trigonometric-series']"
1675021,Why is the trivial vector space the smallest vector space?,"My book (Elementary Linear Algebra by Andrilli) says: The set $\mathcal{{V}}$ = {${\mathbb {0}}$} is a vector space AND is
  the smallest vector space. Then the book asks why $\mathcal{{V}}$ is the smallest vector space. I have no idea where to even start to explain why $\mathcal{{V}}$ is the smallest space. It seems like an odd question to ask.",['linear-algebra']
1675074,Torus-cylinder intersection.,"The standard equation for a torus rotated about the $z$ axis is:
$$(x^2+y^2+z^2+R^2-r^2)^2 = 4R^2 (x^2+y^2)$$ The cylinder of interest is parallel to the $x$ axis and offset along the $y$ axis by $R$: $$z^2 +(y-R)^2=r^2$$ I'm trying to evaluate some function $H(x,y,z)$ over the surface created by the intersection of a torus and a cylinder as in https://i.sstatic.net/MxOLT.png . I'm aware that a solution exists ( https://mathematica.stackexchange.com/questions/5968/plotting-implicitly-defined-space-curves ), but I can't find a solution where the result is actually written fully. From the intersection curve, I'm planning to find the ''shadow region'' $D$. I'd like to evaluate the integral using the following standard surface integral method, $$\int \int_S H(x,y,z) d \sigma = \int \int_D H(x,y,z) \frac{|{\nabla F}|}{|\nabla F\cdot p|} dA$$ I cannot manage to find intersection curve. My first three attempts just hung in both Maple and Matlab when trying to evaluate the integral.","['integration', 'geometry']"
1675086,Find the probability distribution of the random variable X.,"A fair coin is flipped $3$ times. Consider a random variable $X$ which is the number of runs. Number of runs is the number of changes of letter $H$ and $T$. For example, $HHH$ has one run, $TTH$ has two runs and $THT$ has three runs. Find the probability distribution of the random variable $X$. My work: I don't understand the phrasing of this question. In examples in my textbook and online $X$ is defined as the number of heads or tails. But I can't follow where the example in this question is going. I would think that $TTH$ and $THT$ would both have 2 runs since $HHH$ only has one. I don't know what zero runs would be either. Can anyone give me guidance on what exactly this question means? I'm pretty sure I can solve it once I understand what the number of runs means. The outcomes would be: $HHH$ $X=1$ $HTH$ $HHT$ $THH$ $TTH$ $X=2$ $HTT$ $THT$ $X=3$ $TTT$ I don't know what number of $X$ would correspond with each.","['probability-theory', 'probability', 'statistics']"
1675092,Methods for efficiently factoring the cubic polynomial $x^3 + 1$,"$$x^3 + 1$$ factors as $$(x^2 - x + 1)(x + 1) .$$ It would have taken me a few minutes to identify this. What are the various approaches to determining rapidly that it is factorable, and factoring it?",['algebra-precalculus']
1675128,Example of a partially ordered set whose Hasse diagram would look like a full binary tree,"I am starting to study partially ordered sets and I was curious as to if there is an example of a poset whose Hasse diagram would look like a full-binary tree. A full binary tree (sometimes proper binary tree or 2-tree) is a tree in which every node other than the leaves has two children Also, are there any infinite posets which would have the form of a full binary tree? Would Zorn's Lemma apply to such a poset? Thanks","['graph-theory', 'elementary-set-theory']"
