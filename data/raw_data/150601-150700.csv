question_id,title,body,tags
2508249,Proving $\lim_{\vec{h}\to 0}\frac{\|f(\vec{u}+\vec{h})-f(\vec{u})\|}{\|\vec{h}\|} = \|J_f(\vec{u})\|_{\text{op}}$?,"I'm looking to prove the limit in the title statement for $f:\mathbb{R}^n\to\mathbb{R}^m$ differentiable in the necessary open set, where $\|A\|_{\text{op}}$ is the operator norm. I proceeded as follows:
$$
\begin{aligned}
\left|\frac{\|f(\vec u+\vec h) - f(\vec u)\|}{\|\vec h\|} - \|J_f(\vec u)\|_{\text{op}}\right| & = \left|\frac{\|f(\vec u+\vec h)-f(\vec u)\|-\|J_f(\vec u)\|_{\text{op}}\|\vec  h\|}{\|\vec h\|}\right| \\
& \le \left|\frac{\|f(\vec u+\vec h) - f(\vec u)\|-\|J_f(\vec u)\vec h\|}{\|\vec  h\|}\right| \\
& \le \frac{\|f(\vec u+\vec h)-f(\vec u)-J_f(\vec u)\vec h\|}{\|\vec h\|}
\end{aligned}
$$
where we use $\|Av\|\le\|A\|_{\text{op}}\|v\|$ to go from the first line to the second line, and the reverse triangle inequality to go from the second line to the third line. Then by the squeeze theorem we have $$
\begin{aligned}
0 & \le\lim_{\vec h\to 0}\left|\frac{\|f(\vec u+\vec h)-f(\vec u)\|}{\|\vec h\|} - \|J_f(\vec u)\|_{\text{op}}\right| \\
& \le\lim_{\vec h\to 0}\frac{\|f(\vec u+\vec h)-f(\vec u)-J_f(\vec u)\vec h\|}{\|\vec h\|} \\
& = 0
\end{aligned}
$$
Looks alright, right? Well I realized there's a tiny detail: Suppose $z<y$. Then clearly, $x-y<x-z$. However , it is not necessarily true that $|x-y|<|x-z|$. This means we can't use the fact that $\|Av\|\le\|A\|_{\text{op}}\|v\|$ to go from the first line to the second line above. Is this ""proof"" salvageable? Is what I'm trying to prove even true? If not, what does the limit actually evaluate to?","['multivariable-calculus', 'real-analysis', 'derivatives']"
2508257,Show that if $''(x_0)$ then,"Prove that $f$ has a simple zero at $x_0$ if and only if:
$$f(x) =g(x)(x-x_0),$$ where $g$ is continuous at $x_0$ and differentiable on a deleted neighborhood of $x_0$, and $g(x_0)\neq{0}$ I know that a function has a simple zero at $x_0$ if $f$ is differentiable at $x_0$ and $f(x_0) = 0$, while $f'(x_0)\neq{0}$ But I am unsure how to start on the proof. Any help is appreciated.","['derivatives', 'real-analysis', 'roots']"
2508318,Does $x^2 \equiv 3$ (mod $q$) (where $q$ is an odd prime) have infinite solutions?,"Not sure how to prove/disprove this. One thought I had for proving this was doing an indirect proof, assuming there are only finitely many solutions $x_1,x_2,...,x_n$ and perhaps: 1) constructing a new solution using these solutions or 2) taking the largest of the solutions and show an even larger solution exists","['proof-verification', 'number-theory', 'elementary-number-theory', 'modular-arithmetic', 'discrete-mathematics']"
2508321,Showing that parts of a contour integral vanish,"I'm trying to compute the integral $\int_{0}^{\infty}\frac{x}{x^6+1}dx$ using contours in the complex plane. To do this I take the function $f(z)=\frac{z}{z^6+1}$ and integrate along the contour consisting of the positive real line, a circle of infinite radius going counter clockwise from the positive real axis to the positive imaginary axis, and a line going back to the origin. Since there is a singularity on the imaginary axis I introduce an additional contour going clockwise around it. Using residues I can compute the integral of $f(z)$ along this contour, however, in order to equate it to the real integral I must show that the integrals along the imaginary axis vanish. Can this be done by simply applying the ML estimate, as I do to show that the integral along the semicircle vanishes, or am I missing something?","['complex-analysis', 'contour-integration']"
2508348,How do I use Leibniz formula to solve this difficult equation?,"Suppose there exists a $y$ such that $$y \equiv \frac{d^n}{dx^n}e^{-x^2/2}$$. Prove that $$\frac{d^2y}{dx^2} + x\frac{dy}{dx} + (n+1)y = 0$$ I'm not sure where to start as Leibniz formula require at least 2 functions to begin with. There are no clear two functions in this problem. My thought process: I could possibly factor out the y in all 3 terms, but this will make the derivatives invalid, wouldn't it? So since approach 1 wouldn't work, I could try integrating the whole equation, but I wouldn't get an exponential somewhere. I can try to sub in y into the equation, but I don't know how to proceed from here.","['ordinary-differential-equations', 'calculus']"
2508368,"If $\sum\limits_i\sum\limits_j\alpha_{ij}x_iy_j$ converges for every square integrable $(x_n)$ and $(y_n)$, then the order of the sums commutes","Let $(\alpha_{ij})$ be a square infinite matrix such that for all $x=(\xi_{n}),y=(\eta_{n}) \in \ell ^{2}$ we have that ${\displaystyle \sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\alpha_{ij}\xi_{i}\eta_{j}}$ converges. The question: Is it correct to say that
$$\sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\alpha_{ij}\xi_{i}\eta_{j}=\sum_{j=0}^{\infty}\sum_{i=0}^{\infty}\alpha_{ij}\xi_{i}\eta_{j} \:\:?. \tag{$\bigstar$}$$ Remark: We know that if the serie converges absolutely, then every rearrangement  converges. I do not know if in this case it is necessary to show that the series converges absolutely to be able to demonstrate $(\bigstar)$, however, I have not been able to show this absolute convergence.","['real-analysis', 'functional-analysis', 'convergence-divergence', 'sequences-and-series', 'infinite-matrices']"
2508434,Prove geometrically $\lim_{x\to0} \sin (x)=0$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Prove geometrically $\lim_{x \rightarrow 0} \sin (x)=0$ It is easily seen that the statement is true.
but how to prove it geometrically?","['calculus', 'limits']"
2508458,Using Lagrange Multipliers to find the minimum distance of a point to a plane,"My exercise is as follows: Using Lagrange multipliers ﬁnd the distance from the point $(1,2,−1)$
  to the plane given by the equation $x−y + z = 3. $ My thought process: Langrange Multipliers let you find the maximum and/or minimum of a function given a function as a constraint on your input. For example, if I'm told to find the maximum value of some plane given the constraint $x^2+y^2 = 1$, the only $x$ values I can take are ones on the unit circle. It does this by assuming that any intersecting contour lines of the function and constraining function must have the condition $\nabla f = \lambda \nabla g$. Intersecting contour lines are necessary for the constraining function and function to be equal to eachother. In this case, we are trying to find the distance from the point $(1,2,-1)$ to the plane of equation $x-y+z=3$. Now, given my intuition, $x-y+z=3$ ought to be $g(x,y,z)$ since in these types of problems some function equal to a constant will be this $g(x,y,z)$ (although I'm not exactly sure why). This leads me to ponder what form $f(x,y,z)$ will have such that $F(x,y,z) = f(x,y,z) - \lambda g(x,y,z)$. The minimum distance from a point to a plane should be a straight line, and that line should be perpendicular to the plane. That means it should be the normal vector, or gradient, of that plane. However, I don't know how that helps me. I need a function $f(x,y,z)$ to use. Here's my lecturer's answer: We want to minimize $$d = \sqrt {(x-1)^2+(y-2)^2 + (z+1)^2}$$ Equivalent to minimizing $(x-1)^2+(y-2)^2 + (z+1)^2$ with the same constraint. Thus, it is rendered to $$F(x,y,z) = (x-1)^2+(y-2)^2 + (z+1)^2 - \lambda (x-y+z-3)$$ Upon solving $\lambda$ apparently didn't need to be considered when minimizing, as it dropped out in row operations and back-substitutions from the simultaneous equations you get from considering the partial derivatives. This leaves me with the following questions: Why are we working with the distance from the origin to the point rather than the point to the plane? Is what is meant by ""minimize"" is find the smallest output value for the plane given the constraint its inputs must also satisfy $(x-1)^2+(y-2)^2 + (z+1)^2$? How did he reach the conclusion $\sqrt{(x-1)^2+(y-2)^2 + (z+1)^2}$ is equivalent to minimizing $(x-1)^2+(y-2)^2 + (z+1)^2$ subject to the same constraint? Why is my thinking in normal vectors a bad idea? The values that solve the linear equations are the points needed for minimum distance. Why is that?","['multivariable-calculus', 'maxima-minima', 'lagrange-multiplier']"
2508465,Conditional expectation of random variable given a sum,"Let $(X_i)_{i\geq1}$ i.i.d in $\mathcal{L}^1(\Omega,\mathcal{F},p)$ Is it true that $E(X_j|\sum_{i=1}^nX_i)=\frac{1}{n}\sum_{i=1}^nX_i$ For each $j$ where $1\leq j \leq n$. I think it is true, because given the information of the sum the best forecast for $X_j$ is the mean value. I wonder if this can be proven formally using the defining relation of the conditional expected value $(i.e \quad E(E(X|\mathcal{G})I_A)=E(XI_A))$ where $A$ is any set in $\mathcal{G}$ and $\mathcal{G}$ is a sub $\sigma-$algebra of $\mathcal{F}$.","['probability-theory', 'conditional-expectation']"
2508564,A compact property of linear operators.,"Let $\Omega\subset\mathbb{R}^{n}$ be a smoothly, open,
bounded set and let $1<p<q<\infty$. Is it true that any (linear) continuous operator $T:L^{p}\left(\Omega\right)\rightarrow L^{q}\left(\Omega\right)$
is a compact operator? Is it true that any (linear) continuous operator $T:W^{2,p}\left(\Omega\right)\rightarrow W^{2,q}\left(\Omega\right)$
is a compact operator? Here $W^{2,p}$ denotes the usual Sobolev space. Thanks. I think, in general, 1. is false and 2. is true. Any reference is enough for my purpose.","['functional-analysis', 'real-analysis', 'compact-operators', 'sobolev-spaces']"
2508615,"Prove that any set of $3n+1$ numbers taken from $\{1,2,...,4n\}$ contains three different numbers $a$, $b$, $c$ such that $a|b$ and $b|c$.","For arbitrary integer $n>0$, prove that any set of $3n+1$ numbers taken from $\{1,2,...,4n\}$ contains three different numbers $a$, $b$, $c$ such that $a|b$ and $b|c$. I have tried using mathematical induction, but can't proceed from $k$ to $k+1$ since it is not clear how to choose three new integers from the enlarged set. From my experience, the answers to this kind of problems may appear as a (mind-blowing) construction of pigeon holes, but I can't think of a way to complete such construction.","['discrete-mathematics', 'pigeonhole-principle', 'induction', 'elementary-number-theory']"
2508617,Congruence of constructed circle chords,"My uncle gave me the following puzzle, hoping there was a mathematical proof to his conjecture. Let $A$, $B$, and $C$ be points on a circle of some fixed radius. The radius for $C$ bisects the chord $AB$. Let $P$ be any point on the segment $AC$. Construct a second circle of the same radius which passes through $P$ and $C$. Let $Q$ be the point of intersection of this new circle and the line $BC$. (See image below.) My Uncle's Conjecture : $|AB| = |PQ|$. I have created a proof which uses the Inscribed Angle Theorem a few times. The gist of it is below. Reference the following diagram. Let $O$ be the center of the original circle, and let $\alpha = \angle COA$.
Notice that also $\alpha = \angle COB$. By the Inscribed Angle Theorem, we have $\angle CBA = \alpha/2$.
By symmetry, $\angle CAB = \alpha/2$.
Hence $\angle ACB = 180^\circ - \alpha$. Next, let $R$ be the center of the constructed circle, and label $\beta = \angle CQP$ and $\gamma = \angle CPQ$.
Then $\beta + \gamma = \alpha$. Also, we have $\angle CRP = 2\beta$, and $\angle CRQ = 2\gamma$ by the same Inscribed Angle Theorem as before.
Thus $\angle PRQ = 2\beta + 2\gamma = 2\alpha$. Now, by SAS, $\Delta AOB \cong \Delta PRQ$.
In particular, $|AB| = |PQ|$. So, my question: Does this Theorem have a name or appear in the literature anywhere?","['circles', 'reference-request', 'geometry']"
2508633,Algebraic structure of Riemann Sphere,"Does Riemann sphere have any algebraic structure (Field, Ring, Algebra)? It appears that 'as a set', construction of Riemann Sphere is similar to the construction of the ring of polynomials over a field. At least the first step is same. Consider the set $ \mathbb{C} $. Insert a symbol $ \infty $ in that set. That is $ \hat{\mathbb{C}} = \mathbb{C} \cup \{\infty\} $ (Then define the topology suitably) On the other hand. Consider any field $ F $. Insert a symbol $ x $ in that set. (Then insert a whole lot more (all 'powers' of x, and formal sums of F-coefficient 'powers' of x etc.) Clearly, in Riemann Square, the extra symbol inserted in the set does not produce linearly independent elements $ \infty, \infty^2  ... $ But I am having a hard time understanding how the 'algebra' of the set $ \mathbb{C} $ is disrupted by this new symbol.","['abstract-algebra', 'ring-theory', 'complex-analysis']"
2508659,Are all proper maps continuous,Some textbooks define proper maps as continuous maps which have inverse images of compact sets compact. Whereas wikipedia defines them to be having inverse images of compact sets compact. Wikipedia definition does not include continuity? Does continuity follow anyway? I couldn't figure out. Thanks.,['general-topology']
2508720,"If $f \circ g$ is one-to-one, is $f$ one-to-one?","I said: $X,Y,Z \subseteq\mathbb{R}$
$$
g:X→Y, f:Y→Z\\
g(x)=\sqrt x,\quad f(x)=x^2
$$
so $f(g(x))=x$ Therefore $f(g(x))$ is one-to-one but $f(x)$ is not. Is this the correct approach?","['function-and-relation-composition', 'functions']"
2508766,Maximum and minimum values of function,"For any number $c$ we let $f_c(x)$ be the smaller of the two numbers
  $(x-c)^2$ and $(x-c-2)^2$. Then we define $g(c)=\int_0^1f_c(x)dx$.
  Find the maximum and minimum values of $g(c)$ if $-2\le c \le 2$. So the maximum/minimum values are either $g(\pm2)$ (the endpoints) or $g(c)$ where $g'(c)=0$. $$g(2)=\int_0^1f_2(x)dx=\int_0^1\min((x-2)^2,(x-4)^2)dx\\=\int_0^1(x-2)^2dx=\frac{(1-2)^3}{3}-\frac{(0-2)^3}{3}=\frac{7}{3}$$
The last step I was thinking was because on the interval $[0,1]$, $|x-2|$ is always smaller than $|x-4|$. In the same way, $$g(-2)=\int_0^1f_{-2}(x)dx=\int_0^1\min((x+2)^2,x^2)dx\\=\int_0^1x^2dx=\frac{1}{3}$$ So $7$ thirds and $1$ third for the endpoints. When the derivative is zero, I am having trouble. I am struggling to understand how the derivative and antiderivative of $g$ and $f_c$ would operate. Thanks. Problem Source: James Stewart, Calculus, Integrals Chapter","['maxima-minima', 'integration', 'calculus', 'functions']"
2508834,Counterexample to Bolzano-Weierstrass in infinite dimension,"From Bolzano-Weirerstrass we can demonstrate that in a normed vector space $E$ of finite dimension, every bounded sequence admits a limit point. What are some counterexamples in infinite dimension? Does there exist a counterexample in every infinite dimensional normed space? I believe this one works: Let $E$ be the space of sequences of real numbers with finite support, equipped with the norm $\| (a_k)_{k \in  \mathbb{N} } \|=\sup |a_k|$. Then take define the sequence $(s_n)$ as follows: $s_n$ is the sequence whose $n$th term is $1$ and every other term is $0$. Then $(s_n)$ is bounded, and we can easily show that it has no limit point.","['real-analysis', 'vector-spaces']"
2508838,I'm trying to negate these statements.,"I'd appreciate it if someone could tell me where I've gone wrong and how to fix my mistakes! The original statements to be negated are below and after are the my attempts at negations. Thank you.
1) $∀b ∈ R, ∃x ∈ R : x^
2 − 4bx + 4b^
2 ≤ 0$ 2) $∃a ∈ Z : ∀b ∈ N, −3 > 5a − 2b$ 3) $∀S ⊆ R
2
, ∃(x, y) ∈ S : x − y = 0$ My answers are: 1) $∃b∉R:x^2-4bx+4b^2>0, ∀x∉R$ 2) $∀a∉Z:∃b∉N, -3≤5a-2b$ 3) $∃S⊄R^2:x-y≠0,∀(x,y)∉S $",['elementary-set-theory']
2508842,Prove that if $\lim \frac{x_{n+1}}{x_n}=L<1$ then it converges to $0$.,"I'm stuck with this problem from ""An Introduction to Analysis by James Kirkwood"" on page 48 exercise 24. Let $\{x_n\}$ be a sequence of real positive numbers such that $\displaystyle\lim_{n\to \infty} \frac{x_{n+1}}{x_n}=L$ exists. Prove that if $L<1$ then $\{x_n\}$ converges to $0$. I'm thinking (I got it from this similar question ) By definiton of limit I have that for any $\epsilon>0$ in particular for $0<\epsilon<1$ such that $L+\epsilon < 1$, exists $N_{\epsilon}\in \mathbb{N}$ such that $n>N_{\epsilon}$ implies that, $$|\frac{x_{n+1}}{x_n}-L|<\epsilon \Rightarrow \frac{x_{n+1}}{x_n}<L+\epsilon \Rightarrow x_{n+1}<(L+\epsilon)x_n<(L+\epsilon)^{n}x_n \\ \text{This will always happen even as $n \rightarrow \infty$, as long as $n>N_{\epsilon}$} $$ Since $\lim_{ N_{\epsilon}\to\infty }r^{N_{\epsilon}}=0$, when $0<r<1$, and because $0<(L+\epsilon)<1$ we must have that $x_{x+1}<0$ however because $x_n$ is a sequence of real positive numbers we have that $x_{n+1}$ must also be always greater than $0$. So $\{x_{n+1}\}$ converges to $0$, and therefore $\{x_n\}$ converges to $0$. But I'm not sure about this thinking, since I think a possible contradiction might arise with $L$ being zero or something. Your thoughts?","['real-analysis', 'sequences-and-series']"
2508851,An over-zigzag (if not silly) writing of definition of analyticity in Amann's Analysis Book.,"In a famous textbook, Amann's Analysis I , the author introduce the analyticity as the below picture. Notice that the author defined this terminology with respect to a set $D$, rather than a point $c$. Actually, there is no a definition for being able to say something like ""a function $f$ is analytic at a point $c$"" in this book. And then, in Remarks (c) , the author said that ""analyticity"" is a local property; that is, for $f:E\to\Bbb R$, if ($\forall x\in E,~f$ is analytic on a neighborhood of $x$), then $f$ is analytic on the whole domain $E$. Let's stop here, and look at how the same thing is discussed in Terrence Tao's Analysis I : The difference is that Tao first defined what is called analytic at a point $c$, then simply extend to what is called analytic on a set $E$, which is more straightforward and intuitive. Actually, Amann didn't really get rid of defining the ""one point"" version. Look closer at Amann's definition, his definition is essentially equivalent to say $f$ is called analytic on $D$ if for each $x_o\in D$, $f$ is ""somewhat analytic at $x_0$"", the remaing all words is his original definition that I omitted is just the definition of ""$f$ is somewhat analytic at $x_0$"". So I think the way he write is quite zigzag and unnatural, if not silly. Why not give the version of one-point analytic first? On the other hand, if he had stated the ""one point"" definition first, then ""set version"", then his Remark (c) might been at least quite easy enough, if not too trivial. Am I correct? Or is there other reason that he chose so?","['complex-analysis', 'real-analysis', 'power-series', 'analysis']"
2508858,"Original Proof of Riesz Representation Theorem for $C([0,1])^*$","It is well known that Riesz Representation Theorem states that every positive linear functional $\Psi$ on $C_c(X),$ where $X$ is a locally compact Hausdorff space, can be realize as integration 
$$\Psi(f)=\int_X f(x)d\mu(x)$$
for a unique regular Borel measure $\mu$ on $X.$ Question: In the Wiki article linked above, there is this sentence: The theorem is named for Frigyes Riesz (1909) who introduced it for continuous functions on the unit interval. I would like to know that how Riesz proved the statement himself. It would be good if someone can provide me a paper where he provided a proof.","['riesz-representation-theorem', 'duality-theorems', 'reference-request', 'functional-analysis', 'measure-theory']"
2508871,Markov Chains Queueing Theory: Sojourn Time for $M/M/1$,"My question is the following. An $M/M/1$ queue has arrival rate $\nu$ and service rate $\mu$, where $\rho = \nu/\mu < 1$. Show that the sojourn time (ie the queueing time plus the service time) of a typical customer is exponentially distributed with parameter $\mu - \nu$. (Call this time $T$.) Now, we're looking at a 'typical' customer, so we consider the chain in equilibrium (eg justified by the PASTA property). Now, I am able to solve this question . For example, one simply observes that if a customer joins a queue of size $j$, then she waits $\Gamma(j+1,\mu)$. Plus in the numbers, including the cdf for $\Gamma(j+1,\mu)$, and bash out some algebraic manipulation. I'm interested in a more refined approach, however. The cdf for $\Gamma(j+1,\mu)$ isn't so nice, I feel. Of course, since $j$ is an integer here, we can just see it as a sum of Poisson probabilities -- alternatively, one could derive the waiting time when the queue has size $j$ like this. I'd like to prove this lemma by showing that the time $T$ has the memoryless property. We then need only calculate the expectation. The expectation of $\Gamma(\alpha,\beta) = \alpha/\beta$ for any $\alpha$ and $\beta$, so it's fairly straightforward to show that $E(T) = 1/(\mu - \nu)$. So my issue is the following. Show directly that the time $T$ has the memoryless property.","['queueing-theory', 'markov-chains', 'probability-theory', 'probability']"
2508872,"Connection of $\mathcal{O}_{\mathbb{P}^1 \times \mathbb{P}^1}(a,b)$","In this question- Connection of $\mathcal{O}(n)$ on a toric manifold , it is explained that the covariant derivative on $\mathcal{O}(n)$ is given by 
$$
\nabla=d+nA,
$$
where $A$ is the connection on a $U(1)$ bundle, $P$, such that the covariant derivative on $\mathcal{O}(1)$ is $\nabla=d+A$. How does this generalize to $\mathcal{O}_{\mathbb{P}^1 \times \mathbb{P}^1}(a,b)$, which is discussed here - Proof of $\mathcal{O}_{\mathbb{P}^1 \times \mathbb{P}^1}(a,b)$ is ample $\iff$ $a,b >0$. ? Would it be correct to say that the line bundle $\mathcal{O}_{\mathbb{P}^1 \times \mathbb{P}^1}(a,b)$ is associated to a $U(1)\times U(1)$ bundle, whereby the covariant derivative is given by 
$$
\nabla=d+nA^{(1)}+mA^{(2)},
$$
where $A^{(1)}$ and $A^{(2)}$ are the components of the $U(1)\times U(1)$ connection, such that the covariant derivative on $\mathcal{O}_{\mathbb{P}^1 \times \mathbb{P}^1}(1,1)$ is $\nabla=d+A^{(1)}+A^{(2)}$? References would be appreciated.","['complex-geometry', 'algebraic-geometry', 'holomorphic-bundles']"
2508880,What is the difference between $f(x_1) \geq f(x_2)$ and $(f(x_1) > f(x_2))$?,I am studying for my math course and I come across this definition. I am really struggling to understand the difference the parentheses make in the inequality. Can somebody please explain and why? Thank you.,['functions']
2508909,Year 10 Maths Question Range of Function,Can someone explain to me the range for this particular function please $$ y= \frac {2} {\sqrt{4-x^2}} $$ I'm in Year 10 so can someone explain this to me in a simple way. Don't really get why it is y larger than or equal to 1 But I know the bottom cannot be equal to 0,['functions']
2509005,An alternative definition for expected value?,"I'm struggling with proving the following claim: $\mathbb{E}_{x \sim D}[x] = \arg\min_{u \in \mathbb{R}} \mathbb{E}_{x\sim D}[|x-u|]$. Is it true? If so, how to prove it?","['probability-theory', 'probability', 'statistics']"
2509023,Equivalence Roth's Theorem,"I am trying to prove that the infinitary version of Roth's theorem (1) implies the finitary version of it (2): (1) Any subset $A \subseteq \mathbb{N}$ of positive upper density contains a 3-term AP. (2) $\forall \delta > 0$, $\exists N_0$ so that for all $N \ge N_0$ and all $A \subseteq [N]$ with $|A| \ge \delta N$, $A$ contains a 3-term AP. I started by taking a bad $\delta > 0$ and positive integers $N_1 < N_2 < \dots$ with corresponding $A_j \subseteq [N_j]$ so that $|A_j| \ge \delta N_j$ and $A_j$ does not contain a 3-term AP. Then, each $(1_{A_j}(n))_{n=1}^\infty$ is an element of $\{0,1\}^\mathbb{N}$ which is compact (under product topology) and metrizable, so it has a convergent subsequence: say $(1_{A_{j_k}}(n))_{n=1}^\infty$ converges to some $(\omega_n)_{n=1}^\infty =: \omega$ as $k \to \infty$. It is easy to see that $\omega$ cannot have a 3-term AP. However, I am struggling to see why $\omega$ must have positive upper density. Couldn't it conceivably be the case that $A_j$ contains no elements of $[N_{j-1}]$ so that $\omega$ will just end up being the $0$ sequence? Is my whole proof attempt invalid or is my reasoning above incorrect? Thanks.","['combinatorics', 'general-topology', 'compactness']"
2509048,Calculation of Lie derivative,"Picture below is from 4th page of A mean curvature type flow in space forms , I try to calculate the red line, but I got a different result.
$$
\mathcal L_V d\rho^2 = d(\mathcal L _V \rho^2)=d(\phi(\rho)\partial_\rho(\rho^2))
=d(2\rho \phi(\rho))=2\rho \phi' d\rho+2\phi d\rho
$$
why the $2\phi d\rho$ vanish ?","['riemannian-geometry', 'differential-geometry']"
2509068,Is point $p$ in triangle $ABC$? [duplicate],"This question already has answers here : Determining if an arbitrary point lies inside a triangle defined by three points? (8 answers) Closed 6 years ago . Is point $p$ in triangle $ABC$? If I have triangle $ABC$ and point $p$, how I can detect if point $p$ is in the triangle or not?","['triangles', 'geometry']"
2509151,$f_m(x)= E[|V+x|^m]-|x|^m$ is constant iff $m=2$.,"Let $V$ be a symmetric non-degenerate random variable. Now define
\begin{align}
f_m(x)= E\big[|V+x|^m\big]-|x|^m,
\end{align} Is the following claim true: $f_m(x)$ is constant if and only if $m=2$. Clear for $m=2$ we have that $f_2(x)=E[V^2]$ and is constant for all $x$. I am interested in the other direction.  To show that the function is non-constant we can show that the derivative of $f_m(x)$ is non-zero. The derivative is given by \begin{align}
f^{\prime}(x)= m \left( E\big[|V+x|^{m-1} {\rm sign}(V+x)\big] -\text{sign}(x) |x|^{m-1} \right),   x\neq 0. 
 \end{align} However, I am not sure how to show that $f^{\prime}(x)$ has values  such that $f^{\prime}(x)\neq 0$.","['probability-theory', 'expectation']"
2509230,Understanding Serre-Chevalley relations,"I was studying Chevalley-Serre relations, which can be summed up to these $$\tag{S1}\left[h_{i},\,h_{j}\right]=0$$ $$\tag{S2}\left[e_{i},\,f_{i}\right]=h_{i}  \quad   \left[e_{i},\,f_{j}\right]=0  \quad\text{for } i\neq j$$ $$\tag{S3} \left[h_{i},\,e_{j}\right]=A_{ij}e_{j}
\quad \left[h_{i},\,f_{j}\right]=-A_{ij}f_{j}$$ $$\tag{S4} \text{ad}\left(e_{i}\right)^{1-A_{ij}}\left(e_{j}\right)=0
\quad\;\; \text{ad}\left(f_{i}\right)^{1-A_{ij}}\left(f_{j}\right)=0 \quad\text{for } i\neq j$$ where $A_{ij}$ are the coefficients of the Cartan matrix. Now it seems to me that relations (S1),(S2), and (S3) are really quite natural, but I don't fully understand relations in (S4). Does anybody has an insight on what does those relations mean?","['abstract-algebra', 'representation-theory', 'lie-algebras', 'lie-groups']"
2509264,If a function has an infinite amount of automorphisms would that imply that it is periodic?,"Let $\phi(x)$ be continuous and differentiable everywhere and its automorphisms be bijections $\gamma_{n}$ such that $\phi(\gamma_{n}(x))=\phi(x)$. If the order of $Aut(\phi)$ is infinite, would that mean that $\phi(x)$ is periodic? I can think of an example of the top of my head: $\phi(x)=sin(x)$ with automorphisms of the form $\gamma_{n}(x)=x+2\pi n$. Could this be applied to any general function $\phi$?","['real-analysis', 'periodic-functions', 'group-theory', 'automorphism-group']"
2509272,Convergence in probability from Cesaro mean,"If $X_n \ge 0$ be sequence of non-negative random variables (not necessarily independent) such that: $$\displaystyle \frac{1}{n}\sum\limits_{k=1}^{n} X_k \overset{P}{\longrightarrow} 1$$ Then does it follow that $$\displaystyle \frac{1}{n}\max\limits_{1 \le k \le n} X_k \overset{P}{\longrightarrow} 0 \qquad \text{ or } \qquad \frac{1}{n}\min\limits_{1 \le k \le n} X_k \overset{P}{\longrightarrow} 0 \quad ?$$ It's an exercise in Amir Dembo's lecture notes (Exercise 2.3.27 here ). If the first result for 'max' can be verified the remaining exercise, asks us to show $\displaystyle \frac{1}{n^r}\sum\limits_{k=1}^{n} X_k^r \overset{P}{\longrightarrow} 0$ for any fixed $r>1$ (which follows by passing to a a.s. convergent subsequence). The result for independent sequence of random variables has been mentioned here to be affirmative (Dugue 1957).","['probability-limit-theorems', 'probability-theory']"
2509309,A clue to solve the system of equation,"$$\begin{cases} x +y=\sqrt[2107]{z}\\y +z=\sqrt[2107]{x}\\z +x=\sqrt[2107]{y}\end{cases}$$ 
It is obvious that $(0,0,0)$ is an answer , but How can be sure for other solution (If other solution exists ) ?
thanks in advance.","['algebra-precalculus', 'calculus', 'systems-of-equations']"
2509316,Construct a function exactly belongs to $H^1(\mathbb{R})$,"Question: How to construct a function exactly belongs to $H^1(\mathbb{R})$ but does not belong to $H^{1+s}(\mathbb{R})$ for any $s>0$? My try: An obviously try is $u(x)=|x|$. However, I find that $u(x)\in H^{1+1/2-\epsilon}(\mathbb{R})$ actually. Is there any way to find out this function? Thanks in advance.","['derivatives', 'sobolev-spaces']"
2509329,Is a Hamel basis dense?,"Consider a basis $B$ of the vector space $\Bbb{R}$ over the field $\Bbb{Q}$ , known as a Hamel basis. Is $B$ necessarily dense in $\Bbb{R}$ ? It seems hard to answer this question since we can't actually construct a Hamel basis and I don't know any of its properties other than that it exists!","['linear-algebra', 'hamel-basis']"
2509355,Placing 8 people around a table so that 2 people never sit together,"The Question: ""Eight people are to be seated around a table; the chairs don't matter, only who is next to whom, but left and right are different. Two people, X and Y, cannot be seated next to each other. How many seating arrangements are possible?"" My Method: First, I imagined the combinations of just seating 8 people at the table, by placing a person in a chair. This leaves 7! total possible combinations of seating arrangements. However, this is too many combinations - it includes the combinations where X and Y are sitting together. To correct this, I determined how many invalid options we created by seating X and Y together. By treating X and Y as a single entity, XY, taking up 2 seats, I treated the new problem as picking 7 seats with 7 people. As before, I placed a person in a seat, giving a total of 6! unique combinations too many. However, this overshoot (6!) is still not correct, as it only takes into account the combination XY (YX would have also been counted in the original number of total combinations). Since there are 2 ways that X and Y can be combined, the actual overshoot is 2$*$6!. With this, we can say that 7! gives the total possible combinations, while 2$*$6! gives the overshoot, meaning that there are 7!-(2$*$6!) combinations (3600 combinations). Does this method work and produce the correct answer? If it does produce the correct answer, is there a better (or more ideal) way to view this problem? If it does not work, where did I go wrong? I am working my way through ""Introduction to Combinatorics and Graph Theory"", by David Guichard (which is where this problem comes from) on my own, and I don't have any real way to determine how well I am grasping the material yet (I haven't found a solutions manual to verify even the numbers are correct, let alone the method to reach the solution)","['combinatorics', 'proof-verification']"
2509357,Why is negative divergence an adjoint of gradient?,"In my notes, I have $\langle F, \nabla f\rangle_{L^2(\mathcal{TX})} = \langle 
 \nabla^* F, f\rangle_{L^2(\mathcal{X})} = \langle -\operatorname{div} F, f\rangle_{L^2(\mathcal{X})}$, where $f$ is a scalar field, $F$ is a vector field, $\mathcal X$ is a manifold and $T\mathcal X$ is a tangent plane. My question is why is negative divergence an adjoint of gradient?",['differential-geometry']
2509444,"Gradient of a function $f \colon L^2[0, 1] \rightarrow \mathbb{R}$.","I want to think of $L^2[0, 1]$ as a generalization of the finite-dimensional $\mathbb{R}^n$. In this case, the gradient of a function $f \colon \mathbb{R}^n \rightarrow \mathbb{R}$ is 
$$ \nabla f = \left( \partial_1 f, \partial_2 f, ..., \partial_n f \right). $$ The question is: what is $\nabla f$ for the case $f \colon L^2[0, 1] \rightarrow \mathbb{R}$? The ultimate purpose is to be able to take directional derivatives of maps $L^2[0, 1] \rightarrow \Bbb R$ with respect to elements of $L^2[0, 1]$ by using the inner product on $L^2[0,1]$. $$\nabla_\mathbf{u} f = \langle \nabla f , \mathbf{u} \rangle $$ Knowing a simple form for the ""gradient"" would help make calculations of the covariant derivative easy. The functional derivative seems to be an option, but the calculation doesn't seem to be straightforward because of the use of the Riesz Theorem.","['functional-analysis', 'real-analysis', 'differential-geometry']"
2509480,"Prove there is an increasing function on closed bounded interval that is continuous only at points in $[a,b] \setminus C$","Let $C$ be a countable subset of $(a,b)$ . Then there is an increasing function on $(a,b)$ that is continuous only on $(a,b)\setminus C$ This is an example from Royden's real analysis book. The function defined on $(a,b)$ is $f(x)=\sum_{\{n:q_n \le x\}}\frac{1}{2^n}$ where $\{q_n\}$ is an enumeration of $C$ . To show continuity on $(a,b)\setminus C$ he says let $x_0$ be in $(a,b)\setminus C$ and let $n$ be any natural number. Then there exists an interval, $I$ , that contains $x_0$ . In addition, $q_n$ is not in $I$ for $1\le k \le n$ . Then this implys that $|f(x)-f(x_0)| < \frac{1}{2^n}$ for $x \in I$ . I understand this part. Then there is a problem right after this proof says: Let $C$ be a countable subset of the nondegenerate closed bounded interval $[a,b]$ . Then there is an increasing  function on $[a,b]$ that is continuous only on $[a,b]\setminus C$ . I was wondering, if we define $$f(a)=0 \text{ and } f(b)=\sum^{\infty}_{n=1}\frac{1}{2^n}=1$$ Is the proof still hold? Did I miss something here? Are the proof of these two problems similar? Thank you! Thank you for the solution I accepted, and I added something new here. Show that there is a strictly increasing function on $[0,1]$ that is continuous only at the irrationals in $[0,1]$ . Let $f$ be a monotone function on a subset $E$ of $\mathbb R$ . Show that $f$ is continuous except possibly at a countable number of points n $E$ . Let $E$ be a subset of $\mathbb R$ and $C$ a countable subset of $E$ . Is there a monotone function on $E$ that is continuous only at points $E \setminus C$ ? These are four successive problems on Page 109 from Royden's real analysis book. So I think for problem 2, we can just use the result from problem 1 and let $C$ be the rationals. Did I miss something here? And for 3 and 4, what are the difference between them? I mean if 3 is true which means we do have this function. Or did I misunderstand something here? Thank you!","['functional-analysis', 'real-analysis', 'calculus']"
2509485,Place $8$ rooks on a $10\times 10$ board.,"The Problem :- ""In chess, a rook attacks any piece in the same row or column as the rook, provided no other piece is between them. In how many ways can $8$ rooks be placed on a $[8\times8]$ chessboard so that no two attack each other? What about $8$ rooks on a $10\times10$ board? "" I believe I have an answer for the first part of the question. When placing the first rook, there are 8 places on any particular column (or row) to place the rook, leaving just 7 places on a different column (or row) for the next rook, and so on, providing 8! possible ways to place the rooks in such a way that they cannot attack each other ($P(8,8) = 8!/(8-8)! = 8!$). However, I am not sure I fully understand how this would work for a board where there are more rows and columns than pieces (such as on a 10x10 board). Does it become $P(10,8) = 10!/(10-8)! = 10!/2$ ? If so, why? If not, how should I approach this problem? This problem was found in ""Introduction to Combinatorics and Graph Theory"" by David Guichard.",['combinatorics']
2509509,"Topological Hausdorff Group: $ A$ closed, $B$ compact $\Longrightarrow AB$ closed","I'm dealing with a puzzling problem and hope some of you can help me. Let be $(G,\cdot ) $ be a Hausdorff-group and let $A,B \subseteq G$. Show that if $A$ is closed and $B$ is compact, then $AB$ is closed. Due to I'm considering a topological Hausdorff-group, we have two continous maps:
$\psi: G \times G \rightarrow G, (x,y) \mapsto xy$  and  $ \phi: G \times G \rightarrow G, (x,y) \mapsto x{y}^{-1} $ My idea was to show that $(AB)^{c}$ is open instead. First we observe, that if $A$ is closed, then $A^{c}$ is open and due to $\phi$ is continous $\phi^{-1}(A^{c})$ is also open. Now let's choose an arbitrary $x \in (AB)^{c}$. We see that $\forall y \in B: \phi(x,y)=xy^{-1} \in A^{c}$. (because if it wasn't it would be in $A$ we could conclude $\psi(xy^{-1},y)=xy^{-1}y \in AB$, what would be opposed to the chosen x) So we know that $\phi(x,y)=xy^{-1} \in A^{c} \Rightarrow (x,y) \in \phi^{-1}(A^{c})$, which is open. Then we find neighbourhoods $U$ from $x$ and $V$ from $y$ such that:
$\forall y \in B \exists U_{y} \exists V : (x,y) \in U_{y} \times V \subseteq \phi^{-1}(A^{c})$ If I could manage to show, that $U:= \cap_{y \in B} U_{y}$ is open (I don't know this, because it might be an infinite intersection) i think my proof is complete. Because then I can show that $U \subseteq (AB)^{c}$, so that for arbitrary $x$ $(AB)^{c}$ is a neighbourhood of x. This means that $(AB)^{c}$ is open. Can anybody give me a hint how I can show, that this intersection is finite? I suppose it must follow from the compactness of B, because I haven't used it yet, but I have no clue how? Thank you!","['general-topology', 'compactness', 'group-theory']"
2509513,"How to find: $~\min\limits_{f\in E}(\int_0^1f(x) \,dx)$","I came across to the following  problem: Let $E$ be the set of all continuous function $f:[0,1]\to \mathbb{R}$ such that $$f(x)+f(y)\ge |x-y|\qquad\forall\,x,y\in [0,1]$$ Then find $$\min_{f\in E}\left(\int_0^1f(x) dx\right)$$ My attempt: I took the double integral on both side which yields $$ 2\int_0^1f(x)dx =\int_0^1\int_0^1f(x) +f(y)dydx \ge \int_0^1\int_0^1|x-y|dxdy =\frac{1}{3} $$
Thus, 
$$~\min\limits_{f\in E}(\int_0^1f(x) \,dx) \ge \frac{1}{6}$$
Unfortunately I don't know How to get the minimizer. Please give help me with a hint or an answer. Minimize $\min_{f\in E}\left(\int_0^1f(x) dx\right)$","['contest-math', 'real-analysis', 'optimization', 'calculus']"
2509514,On the diagonalizability of two-dimensional metrics,"Assume that $M$ is a two dimensional manifold with (pseudo-)Riemannian metric $g$. In some local chart $(\tau,\sigma)$ we have $$ g=A(\tau,\sigma)d\tau^2+B(\tau,\sigma)d\sigma^2+C(\tau,\sigma)(d\tau\otimes d\sigma+d\sigma\otimes d\tau ). $$ I am aware that this metric is always diagonalizable (in fact, all two dimensional metrics are conformally flat), however if we make the additional condition that we must keep the $\sigma$ coordinate fixed, I'm stuck. It is clear that the metric is diagonized, if we find an exact form $dt$ which is orthogonal to $d\sigma$. This orthogonality may be expressed in local coordinates as $$ g^{ij}\partial_i t\partial_j \sigma=g^{i \sigma}\partial_i t=0. $$ Renaming $g^{i \sigma}=V^i$, this is just $V^i\partial_i t=0$. The functions $A,B,C$ are arbitrary (as long as they form a metric), so the inverse metric functions $g^{\tau\sigma},g^{\sigma\sigma}$ are essentially arbitrary. So the problem is equivalent to asking whether an arbitrary smooth vector field (in 2 dimensions) has a (locally) exact annulator. I can feel this is very easy to prove, but I am unable to. I have no idea how to show that the equation $$ V^\tau(\tau,\sigma)\frac{\partial t}{\partial\tau}+V^\sigma(\tau,\sigma)\frac{\partial t}{\partial \sigma}=0 $$ is soluble. Any other method is also welcome. I tried to look for situations in which Poincaré's lemma or Frobenius' theorem can be applied to help out - to no avail, but as I said, I think I'm missing something trivial and obvious.","['riemannian-geometry', 'differential-geometry', 'partial-differential-equations']"
2509548,Final topology equals subspace topology with a closed subset,"Let $(X_n)_{n \in \mathbb{N}}$ be a collection of topological spaces, let $X$ be a set and let $X_n \hookrightarrow X$ be a collection of injective maps. Consider in $X$ the final topology given by these maps, so $G \subseteq X$ is open $\iff$ $G \cap X_n \subseteq X_n$ is open for all $n$. Now consider $Y \subseteq X$ be a closed subspace, and set $Y_n := Y \cap X_n$. Question. Is it true that the subspace topology on $Y$ is the same that the final topology given by $Y_n \hookrightarrow Y$? In
  other words, $G \subseteq Y$ is open $\iff$ $G \cap Y_n \subseteq Y_n$ is open for
  all $n$.",['general-topology']
2509549,Topology of $C_c^\infty(\Omega)$,"I am reading Rudin Functional Analysis, there is one point he said (Remark 6.9, page 156) that it is obvious that $\mathcal{D}_K$ has empty interior relative to $\mathcal{D}(\Omega)$, can anyone explain it to me? For each compact set $K\subset \Omega \subset \mathbb{R}^n$, we define $\mathcal{D}_K$ be the set of function $f$ smooth with support in $K$, i.e., $\mathcal{D}_K = C_c^\infty(K)$ while $\mathcal{D}(\Omega) = C_c^\infty(\Omega)$.","['functional-analysis', 'distribution-theory']"
2509607,Expected number of rolls to get all sixes,"I'm struggling with the following problem: I have $N$ balanced 6-sided dice. I roll the dice simultaneously, and remove any sixes that occur. I roll the remaining dice again, and remove any more sixes. I repeat the process until there are no dice remaining. What is the expected number of rolls this will take? So far I have calculated that by the $n^{th}$ dice roll there will be $N\left(\frac56\right)^n$ dice remaining: If we start with $N$ dice, on the first roll we expect $\frac{N}{6}$ sixes. Therefore, on the second roll we expect to have $N-\frac{N}{6}$ dice and hence expect $\frac{5N}{36}$ sixes, meaning after the second roll there are $\frac{25}{36}N$ dice remaining.  Repeating this calculation gives the sequence $N, \frac{25}{36}N, \frac{125}{216}N...$ which is equal to $N\left(\frac56\right)^n$ where $n$ is the roll number. I'm struggling with the next part: My thinking is we must find the expected number of rolls $n$ such that $N\left(\frac56\right)^n\lt0.5$, and therefore $n>\frac{\ln(\frac{0.5}{N})}{\ln(\frac56)}$. Taking $N$ to be $8$, the expected number of rolls is then about $15.21$. I used MATLAB to run the experiment $200,000$ times, and it gave me an average number of rolls of $15.4$. I seem to be close to the right answer, but I'm not sure what I've done wrong. What is the solution?","['probability', 'dice']"
2509647,About proof of Morley's theorem,"I am trying to understand the generalized version of Morely's theorem proved in this paper by Alain Connes . I am stuck at the step where the generalized version is specialized for the field $\mathbb{C}.$ I will use the notation from the paper. I am not able to understand what exactly is $g_1.$ The paper tells it is ""the rotation with center
$A$ and angle $2a$"". So I assume $$g_1(x) = (x-A)e^{i2a}$$ But this does not seem to add up because I do not obtain $g_1^3g_2^3g_3^3=1.$ I think my understanding is wrong, can someone please explain what exactly is the affine transform $g_1.$","['field-theory', 'geometry']"
2509654,$ \lim_{n \to \infty} \left(\frac 1{n^2+1}+\frac 2{n^2+2}+\frac 3{n^2+3}+\cdots +\frac n{n^2+n}\right)$,"Evaluate: $$ L=\lim_{n \to \infty} \left(\frac 1{n^2+1}+\frac 2{n^2+2}+\frac 3{n^2+3}+\cdots +\frac n{n^2+n}\right)$$ My approach: Each term can be written as $$ \frac k{n^2+k}=\frac {n^2+k-n^2}{n^2+k}=1-\frac {n^2}{n^2+k}$$ $$ \therefore \lim_{n \to \infty}\frac k{n^2+k}=\lim_{n \to \infty}\left(1-\frac {n^2}{n^2+k}\right)=0$$ hence, $$ L=0$$ Problem: The correct answer is 1/2, please indicate the flaw in my approach or post a new solution. Thank You","['algebra-precalculus', 'proof-writing', 'calculus', 'proof-verification']"
2509670,"$\int _{C} (z^3 + 2z +{\bf Re} z)\,dz$ where C is a triangle of vertices $z=0$, $z=1+2i $ and $z=1$.","How do I compute 
  $ \int _{C} (z^3 + 2z +{\bf Re} z)\,dz$ where C is a triangle of vertices $z=0$, $z=1+2i $ and $z=1$. The solution given is $i$ Anyone showing me how to deal with these problems will be extremely helpful, as this entire subject quite unclear to me.","['cauchy-integral-formula', 'complex-analysis', 'complex-numbers']"
2509676,Rewrite operator $(\beta \partial/\partial\beta)^n$,"I am trying to calculate the following thing
$$e^{A \cdot \beta \frac{\partial}{\partial \beta}}e^{i\eta \beta},$$
where $A,\eta$ are constants. Any idea how to write $e^{A \beta \partial/\partial\beta}$ in series?
In general
$$e^{A \cdot \beta \frac{\partial}{\partial \beta}} = \sum\limits_{n=0}^{\infty} \frac{A^n}{n!}\left(\beta \frac{\partial}{\partial \beta} \right)^n$$
and for $n=2$ I get
$$\left(\beta \frac{\partial}{\partial \beta} \right)^2 = \beta \frac{\partial}{\partial \beta} \beta \frac{\partial}{\partial \beta} = \beta \frac{\partial}{\partial \beta} + \beta^2 \frac{\partial^2}{\partial\beta^2}$$","['derivatives', 'calculus']"
2509693,Weird Combinatorial Identity: $n = \frac{n+1}{n^n - 1} \sum_{k=1}^{n/2} \binom{n-k}{k-1} n^k (n - 1)^{n+1-2k}$,"A friend of mine came across this rather odd combinatorial identity. We've spent a while but haven't been able to prove it. Any ideas? The following holds exactly for even integers $n$, and is approximately true for odd integers $n$: $$n = \dfrac{n+1}{n^n - 1} \sum_{k=1}^{n/2} \dbinom{n-k}{k-1} n^k (n - 1)^{n+1-2k}$$","['combinatorics', 'summation', 'binomial-coefficients']"
2509702,conditional expectation deck of cards,"Let $X1, \ X2, \ X3, \ X4$ denote the number of hearts, diamonds, clubs, and spades drawn from 10 draws with replacement from a standard 52 card deck of playing cards. What is $E\ [X2\ |\ X1 + X4 = 5]$  ? Is the answer $1/4 * 5 = 5/4$ ? My reasoning is that we know that 5 of the 10 cards are not $X2$, so we are only concerned with the other 5. So we multiply the other 5 by the probability of getting a heart, i.e. $1/4$. Thanks in advance","['expectation', 'probability-theory', 'statistics', 'probability', 'conditional-expectation']"
2509706,Why does $\sum\limits_{i=0}^{100} \binom{100}{i} \sum\limits_{j=i+1}^{101}\binom{101}{j}$ equal $2^{200}$?,"According to WolframAlpha , the following is true: $$\sum_{i=0}^{100} \frac{ \binom{100}{i} }{2^{100}}\sum_{j=i+1}^{101}\frac{ \binom{101}{j} }{2^{101}} = \frac{1}{2}$$ Can anyone tell me why that is? I'm quessing it has something to do with the hypergeometric function.","['combinatorics', 'hypergeometric-function', 'summation']"
2509713,"Hey guys, I have a question about differentiability of the function of two variables","Is the function
$$ f(x, y) = \begin{cases}y^2 \over x^2 + y^2 & (x,y) \neq (0, 0) \newline
 0 & (x, y) = (0, 0)\end{cases} $$
differentiable at $(0,0)$? The thing is that first we have checked for function's continuity and it turned out that $\lim_{k \to 0} f(k,0)=0$ and $\lim_{k \to 0} f(0,k) \to 1$ which basically implies a discontinuity of our initial function which in turn asserts the impossibility of our function being differentiable. But it seems too easy. Any help would be appreciated.","['derivatives', 'calculus', 'functional-analysis', 'continuity', 'multivariable-calculus']"
2509733,Type I and II Errors,"Good evening,
I am a little confused about type I errors. If you are given a population of students doing hypothesis tests for a certain condition at a certain significance level, is it possible to calculate: (a) how many students will fail to reject the null hypothesis given that the null hypothesis is false (b) how many students will reject the null hypothesis given that the null hypothesis is true. I have tried searching online but so far all sites only show how to calculate the probability that at least one type I error will be made. Any assistance will be greatly appreciated. Thanks!",['statistics']
2509735,Partition generates sigma algebra,"I was reading (Countable) partition generated $\sigma$-algebra but I can't understand few parts. First, we know that in order to show that a partion $\mathcal{C}=\left\{C_{1},C_{2},...,C_{n}\right\}$ of a set E, generates a sigma algebra that contains all the unions of elements of C, we have to do the following steps: We define the sigma algebra $\sigma(\mathcal{C})$ We also define $\mathcal{E}$ that we want to show that is generated from $\mathcal{C}$ as $\mathcal{E}=\left\{\bigcup_{i\in I}C_{i}:I\subset \mathbb{N}\right\} $ and we show that is sigma algebra And the last part is to show that $\sigma(C)=\mathcal{E}$ Back to the proof, at first step, they show that E $\in \mathcal{C}$ : $\mathcal{C}$ is a partition of E, so $\cup \mathcal{C}=E.$ Since $\mathcal{C}$ is countable, $\cup \mathcal{C}$ is the union of countably many members of $\mathcal{C}$ . But we shouldn't do that $E\in\mathcal{E}$ and not $E\in \mathcal{C}$ ? As we want to show that $\mathcal{E}$ is a sigma algebra. And on the third part of the proof, they show that $\mathcal{E}$ is closed under complement: Let $A \in \mathcal{C}$ , so there exists a countable $\mathcal{C}_A \subseteq \mathcal{C}$ such that $A = \cup \mathcal{C}_A.$ Let $\mathcal{D} = \mathcal{C} \setminus \mathcal{C}_A$ ; then $\mathcal{D}$ is a countable subset of $\mathcal{C}$ , and if $D =\cup \mathcal{D},$ then $D \in \mathcal{C}.$ Since $\mathcal{C}$ is a partition on E, $D = E \setminus A = A^c$ , and so $A^c\in \mathcal{C}$ . But how do we conclude that $\mathcal{E}$ is closed under complements? Here we showed that C is closed under complements. And also what is this $\mathcal{C}_{A}$ ? Is it a new partition that contains A? Any advice would be helpful.","['measure-theory', 'elementary-set-theory']"
2509739,"Finding $cdf$ of the sample minimum, $X_{(1)}$","Consider iid random variables $X_1$ and $X_2$, having $pdf$ $$f_X(x) =
 4(1−2x)I_{(0,1/2)}(x)$$ Give the $cdf$ of the sample minimum,
  $X_{(1)}$. $$\begin{align*}
F_{X(1)}(x) 
&= P(X_{(1)} \leq x) \\\\
&= 1 - P(min{\{X_1, X_2}\} \gt x) \\\\
&= 1 - P(X_1 \gt x, X_2 \gt x) \\\\
&= 1 - P(X_1 \gt x)\cdot P(X_2 \gt x) \\\\
&= 1 - [1-F_X(x)]^2 \\\\
&= 1 - [1-\int4(1-2x)]^2 \\\\
&= 1 - [1-(4x-4x^2)]^2 \\\\
\end{align*}$$ Did I do this correctly?","['statistics', 'probability', 'proof-verification', 'random-variables']"
2509761,Frechet differential in $L^\infty$ spaces,"define $L :L^\infty([0,1]) \to L^\infty([0,1])$, $f \to \cos f$. Show that this operator is not Frechet differentiable at $f = 0$. My idea was just to use the taylor expansion:
$$\cos (f+h) = \cos f + h \sin f + \mathcal{o}(\|h\|)  $$
to conclude that the derivative is given by $L'(f)(h)=h \sin f$. Is this correct? Thanks for any hints.","['functional-analysis', 'lp-spaces', 'frechet-derivative']"
2509795,Determinant of matrix with binomial coefficients entries,"I try that find the way for calculate the determinant of the following matrix of size $n\times n$. The determinant is $\displaystyle\binom{k+n}{k}x^{n}$. I wait that you can help me. THE OMITTED ENTRIES ARE ZERO $$A=\left(
  \begin{array}{ccccc}
    \binom{k+1}{k}x & \binom{k+1}{k+1} &  &  &  \\\\
    \binom{k+2}{k}x^2 & \binom{k+2}{k+1}x & \binom{k+2}{k+2} &  &  \\\\
    \vdots & \vdots & \cdots &  &  \\\\
    \binom{k+n-1}{k}x^{n-1} & \binom{k+n-1}{k+1}x^{n-2} & \binom{k+n-1}{k+2}x^{n-3} &\cdots  &\,\,\,\,\,\,\,\,\,\,\binom{k+n-1}{k+n-1}  \\\\
    \binom{k+n}{k}x^{n} & \binom{k+n}{k+1}x^{n-1} & \binom{k+n}{k+2}x^{n-2} &\cdots  & \binom{k+n}{k+n-1}x \\
  \end{array}
\right)$$ In other words, the $\left(i, j\right)$-th entry of the matrix is $\dbinom{k+i}{k+j-1} x^{i-j+1}$ when $j \leq i+1$, and otherwise is $0$.","['matrices', 'matrix-calculus', 'matrix-decomposition', 'determinant', 'linear-algebra']"
2509810,How to prove the existence and uniqueness of Cholesky decomposition?,"Given a real Hermitian positive-definite matrix $A$ is a decomposition of the form $A=L L^T$ where L is a lower triangular matrix with positive diagonal entries. I read some proofs about the existence of Cholesky decomposition. Most of them start from LDU decomposition. Then the proof shows that $U^T=L$ and $A=LDU=LD^{\frac{1}{2}} D^{\frac{1}{2}}L^T=CC^T$ where $C=L D^\frac{1}{2}$. How can I prove the existence of Cholesky decomposition without any preassumption like LDU decomposition exists? Or how can I prove LDU decomposition exists? I know it may be easy. But I just cannot figure it out. For uniqueness, I think it's not hard to prove.","['cholesky-decomposition', 'matrices', 'positive-definite', 'matrix-decomposition', 'linear-algebra']"
2509811,Annihilator of an annihilator,"Let X be a normed space and X' the dual space of X. The annihilator of a vector subspace $M\subset X$ is defined by:
  $$M^{\perp}:=\{f\in X'|f(y)=0 \forall y\in M\}\subset X'$$ Is $N\subset X'$ a vector subset of a dual space, then the annihilator of N in X is defined by:
  $$N^\perp:=\{x\in X|f(x)=0 \forall \in N\}\subset X$$
  Show:
  i)$(M^\perp)^\perp=\overline M$ ii) $\overline N\subset (N^\perp)^\perp$ I found the following proof online, but I have some difficulties understanding the notation: 1) $(A^\perp)^\perp$ is a closed span of A 2)$(B^\perp)^\perp$ is a weak* closed span of B 1)We know $A\subset (A^\perp)^\perp$, and $(A^\perp)^\perp$ is a closed subspace. Since $\overline{span}$ A is the smallest closed subspace containing A, it suffices to show that $(A^\perp)^\perp \subset\overline{span}A$. Suppose not, and pick $x\in (A^\perp)^\perp/\overline{span}A$. Then, since $\overline{span}A$ is a closed subspace, by the Hahn-Banach Theorem we can choose $f\in X'$ such that $f(x)\neq0$ and $f(y)=0$ for all $y\in\overline{span}A$. In particular, $f(y)=0$ for all $y\in A$, so $f\in A^\perp$. Since $f(x)\neq0$ we have $x\notin(A^\perp)^\perp$, and this is a contradiction. What exactly is the closed span of A? I tried to google it but I didn't find much. Same with the weak* closed span. Is $\overline{span}$ the closed span?. How exactly did we use the Hahn-Banach Theorem to find this f? Can someone help me?",['functional-analysis']
2509831,Determine if the differential equation will have an unique solution on D,"Consider the following differential equation $$y'=xe^{-y^{2}}$$
the boundary condition is $y(1)=e$ and $D=\{(x,y):x,y\in R, 1\le x \le 2\}$ I need to figure out if this has an unique solution on $D$ I have solved the differential equation as far as I could to be $$\frac{1}{2} \sqrt{\pi}erfi(y)=\frac{x^2}{2}+c_1$$
Now from here I am unsure how to ""solve for y"" and how do I come to a conclusion if this has a unique solution or not.","['integration', 'ordinary-differential-equations']"
2509833,What is wrong with this attempt at figuring out the probability of drawing a 5-card poker hand with at least one pair?,"What is the probability that a 5-card poker hand has at least one pair? Note that this is the same as: probability of exactly one pair + probability of exactly two pairs + probability of exactly 3 of a kind + probability of exaclty 4 of a kind. Let us study a reduced example to help us figure out how to tackle the problem. Imagine that there are 3 balls numbered 1 to 3, coloured red, and 3 similarly numbered balls coloured black. What is the probability of picking 3 balls out of the 6 such that at least two of the balls have the same number value. There are ${6 \choose 3} = 20$ ways of picking out 3 balls from 6:
    \begin{align*}
    &R1, R2, R3 \quad B1, B2, B3 \\
    &\color{blue}{R1, R2, B1} \quad \color{blue}{R1, R2, B2} \quad R1, R2, B3 \\
    &\color{blue}{R1, R3, B1} \quad R1, R3, B2 \quad \color{blue}{R1, R3, B3} \\
    &R2, R3, B1 \quad \color{blue}{R2, R3, B2} \quad \color{blue}{R2, R3, B3} \\  
    &\color{blue}{R1, B1, B2} \quad R1, B2, B3 \quad \color{blue}{R1, B1, B3} \\
    &\color{blue}{R2, B1, B2} \quad \color{blue}{R2, B2, B3} \quad R2, B1, B3 \\
    &R3, B1, B2 \quad \color{blue}{R3, B2, B3} \quad \color{blue}{R3, B1, B3}
\end{align*} We see through brute force that the probability of picking 3 balls where at least two balls have the same number value is $12/20 = 3/5$. Let us attempt to arrive at this answer computationally. Now, there are 6 ways from which we can make the initial selection of a ball. There is only one choice for the second ball, since it must have the same number value as the first. There are 4 balls left now, and from it we can choose any one, so there are 4 choices. Thus, in total, there $6 \times 1 \times 4$ ways of making this choice, but $6 \times 4 = 24 > 20$, so $24/20 > 1$. One could imagine that what is going wrong is that we are making subtle assumptions regarding the order in which the balls are picked! So, let's say we divided the numerator out by the number of ways in which we can arrange 3 balls, $3! = 6$; then we get $4/20 = 1/5$, which is still not the right answer. Let us attempt to get rid of order entirely when constructing our solution. There are 3 number values from which we can pick a pair of balls. There are now 4 balls left, and out of them we can pick any ball. So, we have $3 \times 4 = 12$, and indeed $12/20 = 3/5$. Let us apply this method to yet another case: get rid of balls $R3$ and $B3$, so our scenario only has 4 balls. What is the probability of picking two balls with the same value? Well, there are 2 number values from which we can pair of balls, but ${4 \choose 2} = 6$ ways we can pick a pair of balls overall, so the probability of picking two balls with the same value should be $2/6 = 1/3$. Let us verify that this is the case using brute force:
    \begin{align*}
    &R1, R2 \quad B1, B2 \\
    &\color{blue}{R1, B1} \quad R1, B2 \\
    &R2, B1 \quad \color{blue}{R2, B2}
\end{align*}
Okay, so it works here too. Another simple case is 3 colours (say, red, black and white), but only 2 values---what is the probability of picking out a pair of balls with the same number value? In this case, there are 2 choices for the value from which we can pick a pair of balls, but ${6 \choose 2}$ ways of picking out a pair of balls in general. So the answer should be $2/15$? Let us verify using brute force:
    \begin{align*}
    &R1, R2 \quad B1, B2 \quad W1, W2 \\
    &\color{blue}{R1, B1} \quad R1, B2 \\
    &\color{blue}{R1, W1} \quad R1, W2 \\
    &R2, B1 \quad \color{blue}{R2, B2} \\
    &R2, W1 \quad \color{blue}{R2, W2} \\
    &\color{blue}{B1, W1} \quad B2, W1 \\
    &B2, W1 \quad \color{blue}{B2, W2}
\end{align*}
The correct answer is actually $6/15 = 2/5$, and it seems the counting method we developed so far does not account for more than 2 colours. There are 3 ways we can pick 2 colours out of 3. There are the 2 number values. So, there are $3 \times 2 = 6$ ways of picking out a pair of balls with the same number value. Hence, the probability of picking out 2 balls with the same number value is $6/15$. Let us apply this method then to the original problem: there are 4 suites from which we can pick 2 out of. There are 13 number values from which we can pick a pair of cards. There are now 50 cards left, so there are ${50 \choose 3}$ ways of picking out out the remaining cards. So the probability should be:
    $$\frac{{50 \choose 3} \times {13 \choose 1} \times {4 \choose 2}}{{52 \choose 5}} = 0.59$$ We can no longer brute force to verify, but we can use the work of others to help us. It has been determined that the probability of drawing a hand with no interesting characteristics (i.e. only a high card) is approximately $0.5$. Since probabilities must add up to $1$, there is no way that the probability of drawing at least one pair is greater than approximately $0.5$, so our above answer is incorrect. What is the method developed to help count in such problems missing?","['combinatorics', 'probability']"
2509858,A curious way of generating series expansion for $\cos x$,"If we take the approximation $\sin x  \approx x$, then, using the trigonometric identity $1- \cos 2x = 2\sin^2 x$, and take $2\sin^2 x \approx 2x^2$, we get, after making the substitution $x \to x/2$, that $$\cos x \approx 1 - \frac{x^2}{2}$$ Now, using the trigonometric identity $$\cos(2x)=2\cos^2(x)-1$$ and using the last approximation  $\cos x \approx 1 - \frac{x^2}{2}$, then we get a new approximation for $\cos x$, namely $$\cos(2x)\approx2\left(1-\frac{x^2}2\right)^2-1=1-2x^2+\frac{x^4}2$$ Then let $x\to\frac x2$ to get $$\cos(x)\approx1-\frac{x^2}2+\frac{x^4}{32}$$ So, we repeat: $$\cos(2x)=2\cos^2(x)-1\approx2\left(1-\frac{x^2}2+\frac{x^4}{32}\right)^2-1$$ and so on. This seems to generate a series expansion for $\cos x$, similar to Taylor's series, but with greater denominators. The question is: Does the iterative procedure described above generates better and better approximations to $\cos x$, that is, a Taylor-like series one, or this iterative procedure doesn't converge to $\cos x$ to arbitrary accuraty for real $x$?","['taylor-expansion', 'trigonometry', 'trigonometric-series', 'convergence-divergence', 'sequences-and-series']"
2509859,What domains can we give the Laplacian on the sphere $\mathbb{S}^2$ as an unbounded closed operator?,"Recall from the theory of spherical harmonics on the sphere $\mathbb{S}^2$ that $L^2(\mathbb{S}^2)$ has an orthonormal basis of smooth eigenfunctions $Y_\ell^m$ for integer $\ell,m$ such that $-\ell \le m\le\ell$, with $$\Delta Y_\ell^m + \ell(\ell+1)Y_\ell^m \;=\; 0$$ Now, if we denote by $D$ the span of the $Y_\ell^m$, then we know that $D$ is dense in $L^2(\mathbb{S}^2)$. But is the operator $\overline{\Delta|_D}$ self-adjoint, where by $\overline{\Delta|_D}$ we mean the closure of the operator $\Delta$ defined on $D$. If not, what precisely is the domain $\mathcal{D}(\overline{\Delta|_D})$?","['harmonic-functions', 'partial-differential-equations', 'potential-theory', 'functional-analysis', 'differential-geometry']"
2509869,"What is the abelianization of $SL(2,\mathbb{Z}_p)$?","What is the abelianization of the groups $SL_2(\mathbb{Z}_p)$ where $p$ is a prime number and $\mathbb{Z}_p$ denotes $p$-adic integers? I'm guessing that it's $\mathbb{Z}/4$ for $p = 2$ and $\mathbb{Z}/3$ for $p = 3$, though I would like to see a reference or a proof.","['number-theory', 'group-theory']"
2509891,Showing that a 7-manifold has $G_{2}$ holonomy,I have to show that the direct product of the multi-center Taub-NUT metric with $\mathbb{R}^{3}$ corresponds to a 7-manifold with G2 holonomy. The metric of the Taub-NUT is: $ds_{TN}^{2}=V(r)(dr^{2}+r^{2}d\Omega _{2}^{2})+\frac{1}{V(r)}\left ( dy+R\mbox{sin}^{2}\left ( \theta /2  \right )d\phi\right )^{2}$ with $d\Omega _{2}^{2}=d\theta ^{2}+\mbox{sin}^{2}\theta d\phi^{2}$ and $V(r)=1+\frac{R}{2r}$ I don´t know if it will be enough to show that it is Ricci-flat ($R_{mn}=0)$ or trying to find the associative calibration $\Phi$ and show that $\nabla^{g}\Phi=0$ but in this case I don't know how to obtain the components of the three-form $\Phi_{abc}$... Is there a better way to do so? (I don´t know even if my option would be correct...),"['holonomy', 'riemannian-geometry', 'differential-geometry', 'calibrated-geometry']"
2509902,Prove a divisibility property in $\Bbb Z$,"I am stuck on how to prove the following question: Let $a,b,d \in \mathbb Z$. Now suppose that $d\mid ab$. Prove that there exists $e,f \in \mathbb Z$ such that $d=ef$ and $e\mid a$ and $f\mid b$. Thanks for your help.","['abstract-algebra', 'ring-theory', 'elementary-number-theory']"
2509907,"Are bounded level curves of a continuous function $f(x,y)$ closed?","Let's say I consider all the points $(x,y)$ such that $f(x,y) = c$ for some $c$, given $f$ continuous, and let's assume the set of this points is bounded. Now consider any of the connected components of this set. I get the impression that the only way for a connected component not to be a closed curve (closed in the sense of curves, not in the sense of sets) is for the values $f(x,y)$ to be local extrema. Is this right? If not, can anyone come up with an example of a continuous function that has a bounded non closed level curve, which is not comprised of local extrema? If yes, does the answer extend to higher dimensions? (e.g., closed surfaces for a continuous function $f(x,y,z)$)","['multivariable-calculus', 'real-analysis', 'functions']"
2509950,What other ways can I go about finding the solution to this limit: $\lim\limits_{x \to 0} \frac{9^x - 4^x}{2^x - 3^x}$,"I'm searching for another way to solve 
$\lim\limits_{x \to 0} \frac{9^x - 4^x}{2^x - 3^x}$. I used L'Hospital's rule making it $\frac{\ln9(9^x) - \ln4(4^x)}{\ln2(2^x) - \ln3(3^x)}$ This gave me an answer of -2. I'm searching for another way I can do this problem. I tried multiplying by the conjugate of both the top and bottom but it always becomes 0. Does anyone have any suggestions on another way I can do this? Am I missing something fundamental and obvious about limits?",['limits']
2509989,"If we can construct lines of distance $1$ and $x$, then how do we construct a line of distance $x^2$?","The author is trying to prove it is impossible to square a circle of radius $1$ under the assumption that $\pi$ is transcendental. Even with this assumption, the author explains that if the circle can be squared, then we could draw a line with distance $\pi^{1/2}$. Everything good at the moment. Then he claims that, if such construction is possible, we could also draw a line of distance $\pi$, and that the proof would, under the stated assumption, be complete. The thing I don't get is how, from a line with distance $\pi^{1/2}$, we could create a line with distance $\pi$.","['abstract-algebra', 'galois-theory', 'field-theory', 'geometry']"
2509995,Set Theory: Simplify ((A∩(B∪C))∩(A−B))∩(B∪Cc),I am attempting to simplify this expression: $((A\cap(B\cup C))\cap(A−B))\cap(B\cup C^c)$ With venn diagrams I am able to figure out that I should be able to simplify it down to an empty set. But I am getting stuck trying to write a proper proof for it. I have gotten this so far: $((A\cap(B\cup C))\cap(A−B))\cap(B\cup C^c)$ $((A\cap(B\cup C))\cap(A\cap B^c))\cap(B\cup C^c)$ Set Difference Law $(((A\cup B)\cap(A\cup C))\cap(A\cap B^c))\cap(B\cup C^c)$ Distributive law what are the next steps?,"['elementary-set-theory', 'discrete-mathematics']"
2509996,"Support of cocycles, coboundaries and cohomology of a Koszul complex","Let $X$ be a variety, $F$ is a vector bundle of rank $r$ on $X$ and $s \in \Gamma(X,F)$ a section. Then we have dual section $s^\vee: F^\vee \to \mathcal{O}_X$, cokernel of the dual section is the structure sheaf of the vanishing locus $Z$ of $s$ i.e. $\operatorname{coker}(s^\vee)=\mathcal{O}_Z$. Extending $s^\vee$ by the product rule on the exterior algebra of $F^\vee$ we get the Koszul complex $K(F,s)$:
$$
0\to \wedge^r F^\vee \to \ldots \to \wedge^2 F^\vee \to F^\vee \to \mathcal{O}_X
$$ Is it true that cocycles $Z^i$, coboundaries $B^i$ and cohomology $H^i$ of the Koszul complex are sheaves supported on $Z$?","['reference-request', 'homological-algebra', 'algebraic-geometry']"
2510006,Convergence of supremum of the series of a signed measure,"Let $(X, \Sigma, \mu)$ be a measure space of finite measure and $f\in L^1 (\mu)$. For every $E\in \Sigma$ we define: $$v(E) = \int _ E f d\mu$$ Suppose that $f\in L^p (\mu)$ for some $p \in [1, + \infty)$. Show that $$\sup _{\pi} \sum_i \dfrac{|v(E_i)|^p}{\mu (E_i) ^{p-1}}  < +\infty ,$$ where the sums are countable and the elements of $\pi$ are all measurable, countable partitions of $X$ (i.e. $X= \bigcup E_i$, $E_i \in \Sigma$, $E_i \cap E_j = \emptyset$ if $i\neq j$) such that $\mu (E_i) > 0$ $ \forall i.$ I dont have any clue on how to bound all of those sums, so I would appreciate very much your help! Thanks!","['signed-measures', 'real-analysis', 'lp-spaces', 'measure-theory']"
2510021,"A trigonometric, non-trivially telescopic sum","Evaluate
$$\sum_{k=1}^n\frac{\tan\frac x{2^k}}{2^{k-1} \cos\frac x{2^{k-1}}}$$
I am struck with calculation for this question
Though i was provided the following hint from this forum and i circulated this question to my friends nobody were able to solve it. Do please help me after this hint Hint:$$2\cot (2x)=\cot x-\tan x\\ \to \tan x=2\cot (2x)-\cot x$$so 
$$\frac{\tan\frac x{2^k}}{2^{k-1} \cos\frac x{2^{k-1}}}=\\
\frac{2\cot (2\frac x{2^k})-\cot \frac x{2^k}}{2^{k-1} \cos\frac x{2^{k-1}}}$$","['algebra-precalculus', 'sequences-and-series']"
2510022,Power Series Solution for an ODE which has trigonometric coefficient functions,"The ODE for which we seek a power series solution is:
$$y''+ \cos(x)y' + x\sin(x)y = 0,\hspace{0.4cm} y(0) = 1,\hspace{.1cm} y'(0) = 0$$ I need to find the partial sum up to five, from the initial conditions I know $a_0=1$ and $a_1=0$, I also know I need to find the recurrence relation to get the coefficients but therein lies my issue.
I'm as far as: $$\sum_{n=2}^{\infty}n(n-1)a_n x^{n-2} + \cos (x)\sum_{n=1}^{\infty} n a_n x^{n-1} + x\sin(x)\sum_{n=0}^{\infty}a_nx^n = 0$$ I believe I need to use the power series representation of cosine and sine then take the Cauchy product to simplify. Is this the right track? If so could someone help me understand how exactly the algebra of the Cauchy product in this case works out, I've only ever used it in the simple cases before. So I figured I'd update this post so anyone who may have a similar question somewhere down the line isn't left hanging. Thanks again to Ian for helping with this. First of all rather than using the full series representation of sine and cosine you really only need: $$\cos (x) = 1 - \frac{x^2}{2} + \frac {x^4}{24} + ..., \hspace{0.4cm} x\sin (x) = x^2 - \frac {x^4}{6}+ ...$$ You only need these terms because you're looking for the partial sum up to five. Now bear with me the next part is long. Substitute this along with the power series for $y =\sum_{n=0}^{5}a_nx^n$ again just use the first five terms. Then: \begin{align}
y & = (2a_2 +6a_3 +12 a_$x^2 + 20a_3x^3)\\
&\hspace{.4cm} +(1 - \frac{x^2}{2} + \frac {x^4}{24})(2a_2x+3a_3x^2 +4a_4x^3+5a_5x^4)\\
&\hspace{.4cm} +(x^2-\frac{x^4}{6})(1+ a_2x^2+a_3x^3+a_4x^4+a_5x^5)
\end{align} Now just collect the constants on like-ordered terms, for example: $$x^0 \to 2a_2 = 0 \Rightarrow a_2 = 0 $$ or $$x^2 \to 12a_4 +3a_3 +1 + a_2 = 0 \Rightarrow a_4 = \frac {-1}{12} $$ Just remember to do them in order since the constants ""build"". That is $a_0, a_1, \text{and } a_2 \text{ are needed to get } a_3 $. Finally just stick the constants into $y = \sum_{n=0}^{5}a_nx^n$ and then you can use it to approximate some value for $y(x)$. Sorry about the sort of messy formatting, I'm not overly familiar with MathJax formatting.","['cauchy-product', 'ordinary-differential-equations', 'power-series']"
2510024,How to characterize the net convergence in final topology?,"Given a set $X$ and an indexed family $\{(Y_i,\mathscr T_i)\}_{i\in I}$ of topological spaces with functions $f_i:Y_i\to X$ . Let $\tau_{\text{final}}$ be the final topology in $X$ w.r.t. $\{f_i\}_{i\in I}$ , that is, it's the finest topology such that each $f_i:(Y_i,\mathscr T_i)\to (X,\tau_{\text{final}})$ is continuous. Now consider a net $\{x_\alpha\}_{\alpha\in A}\subset X$ . The question is how to characterize the convergence of the net $\{x_\alpha\}_{\alpha\in A}$ in $(X,\tau_{\text{final}})$ ? It's easy to get the following characterization for net convergence in initial topology : Given a family of functions $g_i:X\to Y_i$ , let $\tau_{\text{initial}}$ be the initial topology w.r.t. $\{g_i\}_{i\in I}$ , that is, it's the coarsest topology such that each $g_i:(X,\tau_{\text{initial}})\to (Y_i,\mathscr T_i)$ is continuous. Then the net $\{x_\alpha\}_{\alpha\in A}\to x$ in $(X,\tau_{\text{initial}})$ if and only if for all $i\in I$ , $\{g_i(x_\alpha)\}_{\alpha\in A}\to g_i(x)$ in $(Y_i,\mathscr T_i)$ . So is there any analogous characterization for that of final topology? Any comments or hints will be appreciated!","['category-theory', 'general-topology', 'nets', 'convergence-divergence']"
2510042,"If a line and its points are removed from a projective plane, is the resulting structure an affine plane?","I've worked through an example using the Fano Plane, and it seems to be the case. However, I'm finding it hard to prove this. Particularly, I am having trouble showing: 1) Take a line M in the plane and consider a point Q not on that line M. It should be the case that some other line, say M', contains Q and is parallel to M. I intuitively get this, and I observed with the Fano Plane that removing one line causes certain lines to become parallel with one another. But, I still can't formulate a general argument to prove 1).","['projective-geometry', 'affine-geometry', 'geometry', 'differential-geometry', 'discrete-mathematics']"
2510044,Uniqueness of Left Adjoint,"On nLab, it says that the left adjoint of a functor is unique, but it does not give a proof. Most of the proofs I have seen use the Yoneda lemma, but the book I am using states this fact (without proof) before stating the Yoneda lemma. How is this fact proven?","['category-theory', 'abstract-algebra', 'adjoint-functors']"
2510047,Statistics. How are standard error and confidence intervals useful without knowing population size?,"I understand standard error and confidence intervals as formulas, but not as concepts. Can you help me understand them better? A smaller standard deviation (smaller spread of your data) and a larger sample size both give you a smaller standard error. That in turn gives you a narrower confidence interval. In layman's terms: As your data points move closer to the sample mean; and as your sample size (n) gets closer to your population size (N), you can be more confident that your sample statistic matches your population parameter. But how do you calculate your sample confidence is your don't know your population size? An example I threw together in Excel: You want to know how the median sick days workers in your town take each year. You survey companies and get responses for 36 workers. The mean for the 36 workers is 14.64 days (I'm rounding). The standard deviation is 9.30. That gives you a standard error of 1.55 and a 95% confidence interval of +-3.15. You conclude, ""I'm 95% sure that workers in our town take between 11 and 17 sick days per year."" But how do you know that estimate is even close? If your little town has only 100 workers, then a survey of 36 is pretty accurate. If you have 100,000 workers in your town, your sample is probably way off. The formulas for standard error and confidence interval (as well as standard deviation) don't have N in their calculations. In many cases, you don't even know N (number of frogs in a national park; amount of drugs smuggled through an area; tons of ore in a mine). So how do you calculate (percent of frogs with a disease; percentage of drugs stopped; quantity of ore per ton of rock) without knowing N? Is a thousand frogs sufficient? Is a hundred bricks of pot a good job? If we extract 16 tons, what do we get? Corollary to this: If we know N, can we use ti change our statistics for n? This is a repeat of How is it that the required sample size for a specified error and confidence is not dependent on population size? , but I don't grasp the concept of infinite populations.","['statistics', 'standard-deviation', 'confidence-interval', 'standard-error']"
2510056,Question about definition of signed measures [Stein and Shakarchi],"In Stein and Shakarchi's Real Analysis , p. 285-6, they define a signed measure $\nu$ on a $\sigma$-algebra $\mathcal M$ of subsets of a set $X$ as a function that Is extended, in the sense that $\nu$ is a function $\mathcal M\to(-\infty,+\infty]$. If $\{E_j\}_{j=1}^\infty$ are disjoint subsets of $\mathcal M$, then
$$\nu\bigg(\bigcup_{j=1}^\infty E_j\bigg) = \sum_{j=1}^\infty \nu(E_j).$$ Then they say, ""Note that for this to hold the sum $\sum \nu(E_j)$ must be independent of the rearrangement of terms, so that if $\nu(\bigcup_{j=1}^\infty E_j)$ is finite, it implies that the sum converges absolutely."" This definition seems off to me. I understand that for $\nu(\bigcup_{j=1}^\infty E_j)$ to be well-defined, the right-hand side must be independent of rearrangement, but it doesn't make sense to me to say ""if $\nu(\bigcup_{j=1}^\infty E_j)$ is finite, it implies that the sum converges absolutely"" because we could take $E_j$ to be disjoint sets of measure $(-1)^{j+1}/j$ for $j=1,2,3,\dots,$ and then we would have
$$
\nu(E_1\cup E_2\cup E_3\dotsb) = 1-\frac{1}{2}+\frac{1}{3}-\dotsb = \ln(2),
$$
so the sum is finite, but the series does not converge absolutely. So what is the correct way to state this definition? Or where am I misinterpreting the definition?","['real-analysis', 'measure-theory']"
2510068,Show that the function is a bijection and find the inverse function.,"Is my answer correct for the following question? Show that the function $f : \mathbb{R} − {3} \to \mathbb{R} − {2}$ defined by $f(x) = \frac{2x−3}{x-3}$ is a bijection, and find the inverse function. I don't necessarily have to prove anything. To show it's a bijection, I need to show that it's one-to-one and onto. A function is one-to-one iff. $f(a)=f(b)$ implies that $a=b$ $\frac{2a-3}{a-3} =\frac{2b-3}{b-3}$ $(2a-3)(b-3)=(a-3)(2b-3)$ $2ab-6a-3b+9=2ab-3a-6b+9$ $-3b=-3a$ $b=a$ When $f(a)=f(b)$, $b=a$, therefore, this function is one-to-one. A function is onto iff. for every $b\in B$, there is an $a \in A$ such that $f(a)=b$ For any $b\in R$-{2}, there's $a\in R$-{3} such that $f(a)=b$ Since $f(x)$ is one-to-one and onto, it is a bijection. Finding the inverse: $f^{-1}(x)=f(y)$ $f(y)=x$ $x= \frac{2y-3}{y-3}$ $xy-2y=3x-3$ $y(x-2)=3x-3$ y= $\frac{3x-3}{x-2}$","['functions', 'proof-verification']"
2510091,Generating valid currency by cutting notes,"Consider the following problem: A $\$50$ is still considered valid currency if you have $70\%$ of the full note. The $70\%$ of the full note can consist of at-most two pieces. The two pieces are glued together, and agree on their boundary. Let us assume that each complete note is $100\%$ identical. (To avoid identification codes etc). Can we generate new valid currency by cutting up full $\$50$ notes? If not, what is the largest percentage of the full note (as opposed to $70\%$) that would allow us to generate new currency. Evidently if $70\%$ was changed to $50\%$, we could just cut any note into halves, and obtain two valid notes. Side note: I don't plan to deface currency, which is illegal, this is just a curiosity, that I couldn't solve as of yet.","['recreational-mathematics', 'geometry']"
2510147,Floquet multipliers of $x'=f(t)A_ox$,I am trying to find the Floquet multipliers of $x'=f(t)A_ox$ where f(t) is a scalar T-periodic function and $A_o$ is a constant matrix with real distinct eigenvalues. I know that the floquet multipliers are the eigenvalues of L where the fundamental matrix $X(t)=e^{Lt}$. I guess my first problem is that I don't know how to find the fundamental matrix of $x'=f(t)A_ox$. It doesn't fit any of the standard forms I have learned. Thanks for any help you can give.,"['periodic-functions', 'ordinary-differential-equations']"
2510175,Show that the array is infinitesimal,"Suppose that $\left\{X_{n,j} : n ∈ N, j = 1, \dots , k_n\right\}$ is a triangular array that satisfies
  the hypotheses of the Lindeberg-Feller central limit theorem. In particular, $E(X_{n,j}) = 0$ and $\sum_{j=1}^{k_n}E(X^2_{
n,j} ) = 1.$ Show that the array is infinitesimal, that is, $\lim_{n→∞}
\max\{P(|X_{n,j} | > ε : j = 1, . . . , k_n\} = 0$ for every $ε > 0$ . In particular, conclude that $\lim_{n\rightarrow \infty} k_n = +∞.$ My Try: $$\{P(|X_{n,j} | > ε : j = 1, . . . , k_n\}=\Pi_{j=1}^{k_n} \{P(|X_{n,j} | > ε\}\leq \frac{1}{((\epsilon n)^2)^{k_n}} \Pi_{j=1}^{k_n}E(X^2_{
n,j} )$$ By the hypotheses I know that $E(X^2_{
n,j} )$ 's are positive and strictly less than $1$ . So, I understand why we must prove $\lim_{n\rightarrow \infty} k_n = +∞.$ . But I am stuck how to prove it. Any help please.","['probability-limit-theorems', 'probability-theory', 'central-limit-theorem', 'random-variables']"
2510179,Is there a geometric realization in integer-sided squares of $70^2 =\sum_{j=1}^{24} j^2 $?,"I saw this in the NAdigest mailing list,
and it was obviously suggested by
$70^2
=\sum_{j=1}^{24} j^2
$: From: Gerhard Opfer [email protected] Date: November 06, 2017 Subject: Mathematics, combinatorial Is it known, whether a square Q of size 70 x 70 can be covered
by little squares q_j of size j x j, j=1,2,...,24. Can one say something about this problem in general. I don't know. My first thought
was to
look at the unit square.
However,
I realized that it was possible
to surround the unit square
with larger squares. The fact that it is possible
to square the square
(i.e., fill an integer-sided square
with distinct integer-sided squares -
see https://en.wikipedia.org/wiki/Squaring_the_square )
means that some property
of 70 and 1 through 24
is needed if
it is not possible. It just might be impossible to square
a 70 x 70 square. Your turn.","['tessellations', 'sums-of-squares', 'geometry']"
2510206,Convert a rotated ellipse to sheared ellipse,"Given an ellipse centred at the origin with major and minor axes and slope of the major axis specified: How can I convert those three parameters into parameters that would express a scaled and sheared ellipse at the origin? What I need is the width and height of the green parallelogram and the slope of the blue line when the red line is lying flat. I might also be interested in versions with angles rather than slopes. I'm assuming it's easier with slopes but I could be wrong. (I only have maybe highschool level maths so please excuse my ignorance of proper terminology. The images are not mine, just ""close enough"" ones I found on the net, the angles should actually match. I hope they are clear enough.) Proposed rewording by @Blue. A rotated ellipse can be interpreted as a (horizontally-)sheared ellipse. For instance, ""an ellipse with radii $a$ and $b$, transformed by rotation through angle $\theta$"" is just as well described as ""an ellipse with radii $p$ and $q$, transformed by (horizontal) shear of angle $\phi$"". I want to know how to convert from one set of parameters to the other. That is, $$\text{Given $a$, $b$, $\theta$, what are $p$, $q$, $\phi$?}$$ It may be easier to express the amount of rotation and shear as slopes rather than angles . For the shear, I'm more interested the height of the bounding parallelogram ($q$ in the figure) not the transformed radius ($q^\prime$). (Of course, these are related by $q = q^\prime \sin\phi$.)","['parametric', 'conic-sections', 'geometry']"
2510236,Composition of Flow Maps for ODEs,"The definition of a flow map given here: http://www.math.sjsu.edu/~simic/Fall05/Math134/flows.pdf states that if $$\phi_t(X_0) = \phi(t, X_0)$$ is a flow of some ODE $X' = F(X)$ then ""because of uniqueness of solutions"" $\phi_{s+t} = \phi(s) \circ \phi(t)$. I don't see how that result follows from uniqueness of solutions. Can someone make this more explicit?","['ordinary-differential-equations', 'analysis']"
2510245,Fourier transform of $e^{-i\pi x^2}$,"I am looking for the Fourier transform of the function 
$$
f(x):=e^{-i\pi x^2},
$$
where we define 
$$
\hat f(\xi):=\int_{\mathbb R}f(x)e^{-2\pi i x\xi}dx.
$$
First of all, the function $f$ is not integrable, but it is bounded and hence it can be regarded as a tempered distribution on $\mathcal S$, the Schwartz function space. Completing squares as usual, it strongly suggests that its Fourier transform, in the sense of tempered distributions, is given by
$$
\frac 1 {\sqrt i} e^{ i\pi \xi^2}.
$$
The only problem is that I dont know how to determine the branch of $\sqrt i$. Any suggestions?","['complex-analysis', 'complex-numbers', 'fourier-transform']"
2510328,Every order interval in $l^1$ is norm compact,"Let $l^1$ denote the space of sequences $(x_n)\subset \mathbb{R}$ with $\Vert (x_n)\Vert_1:=\sum_{n\geq 1} |x_n|<\infty$. We say that $(x_n^1)\leq (x_n^2)$ whenever $x_n^1\leq x_n^2$ for every $n\in\mathbb{N}$. It is well-known that  $(l^1,\Vert\cdot\Vert_1)$ is a Banach space. Given $(x_n^1),(x_n^2)\in l^1$ with $(x_n^1)\leq (x_n^2)$ we define the order interval $$[(x_1^n),(x_2^n)]:=\{ (y_n)\in l^1\colon (x_n^1)\leq (y_n)\leq (x_n^2)\}.$$ I suspect that this set is norm compact. Any hint to prove that?","['functional-analysis', 'lp-spaces', 'compactness']"
2510342,"Representation theory of $\mathrm{GL}(n,\mathbb{K})$ where $\mathbb{K}$ is a (not necessarily algebraically closed) field of characteristic zero","I would like to know about irreducible representations of $\mathrm{GL}(n,\mathbb{K})$ where $\mathbb{K}$ is a field of characteristic zero, and topics such as irreducible representations of  $\mathrm{GL}(n,\mathbb{K})$, Young tableaux, Schur functors, Schur-Weyl duality etc. Unfortunately, essentially every representation theory textbook I have looked at only discusses representations over $\mathbb{C}$, and does not give any indication whether any of the results generalize to other fields, and if they do, how to extract such information from the complex rep theory. Is there anywhere I could learn about representation theory of the general linear group over other fields of characteristic zero, which are not necessarily algebraically closed? Even just $\mathbb{K}=\mathbb{R}$ would suffice since that is the case I am most interested in.","['reference-request', 'representation-theory', 'group-theory', 'linear-algebra', 'lie-groups']"
2510357,Large finitely generated subgroups of locally compact groups,"Let $G$ be a compactly generated locally compact group, let $H$ be a subgroup (not necessarily closed) and let $U$ be a compact identity neighbourhood in $G$.  Suppose that $G = HU$.  Does there exist a finitely generated subgroup $K$ of $H$ such that $G = KU$? If not, what happens if we assume $H$ is dense?  What if $G$ is a connected Lie group?","['topological-groups', 'group-theory', 'lie-groups']"
2510381,Converse of the projection theorem,"I am trying to prove the converse of the projection theorem: If for every $f\in H$ there is a $p\in M$ such that $\|p−f\|=\inf\limits_{v\in M}\|v−f\|$ , then $M$ is closed. Is my proof correct? Let $p_n\in M,n=1,2,\ldots,$ be a sequence converging to $g\in H$ . Then there is a $p\in M$ such that $\|p−g\|=\inf\limits_{v\in M}\|v−g\|$ , so $\|p−g\|\leq \|p_n-g\|\,$ for all $n$ . Now as $n$ goes to infinity the RHS goes to zero, so $g=p\in M$ . Therefore, $M$ contains all its limit points and is closed.","['functional-analysis', 'hilbert-spaces', 'analysis']"
2510385,Rigorous statement on the possible shapes of branch cuts,"I have read on numerous occasions, e.g. in this answer that a branch cut of the complex logarithm can be any curve that connects origin and complex infinity and does not intersect itself. I am looking for a more rigorous version of that statement. My question: Is it possible to define a branch cut as a curve in the complex plane given by an implicit equation $F(x,y)=0$? If so, what are the conditions on $F$ so that it represents a branch cut?","['riemann-surfaces', 'complex-analysis']"
2510459,White Noise Sequence,"Would this process be a white noise sequence? Consider the process $\{tY_t\}_{t = 1, . . . , 100}$, where $Y_t$ are independently, normally distributed with mean 0 and variance 1. The process holds for the two first conditions which are: $$ E(Y_t) = 0 $$ $$ Var (Y_t) = 1 $$ I am unsure about the third condition which states that: $$ E(Y_t,Y_s) = 0  $$ My intuitive guess would be that this condition will still hold as the sequence is independent.","['statistics', 'noise', 'sequences-and-series']"
2510487,For measurable function with $h(x+a)=h(x)$ almost everywhere exists $g=h$ where it holds for all $x$,"Excuse the question, I found it hard to word it compactly. Say I have $a \in \mathbb{R}^n\backslash \{0\}$ and  $h:  \mathbb{R}^n \rightarrow  \mathbb{R} $ and $$h(x+a)=h(x)$$ for almost all $x$ ( i.e. up until a zero measure set ) and where h is measurable. I want to show then, that there exists $ g:  \mathbb{R}^n \rightarrow  \mathbb{R} $ and $g(x+a)=g(x)$ for ALL $x$ and also $h=g$ almost everywhere. I'm not looking for a solution , but I've never done such an exercise before and I'm not sure how to approach it. So I'm thinking we just have to define a set first, i.e. $A:= \{x \in\mathbb{R}^n | h(x) \neq h(x+a)\}$ and then a function $$
g(x)= 
\begin{cases}
h(x) &x \not\in A \\
h(x+a) &x \in A
\end{cases}
$$ and actually, shouldn't $g$ have all the wanted properties now? I don't think the exercise is that simple and I do think I need to use the measurability of $f$ somewhere, but I don't see why or how. Is my approach correct? If not,  how can I approach it?","['real-analysis', 'measure-theory']"
2510490,I'm trying to prove that any finite partially ordered set has a minimal element.,"Is this correct: Induction hypothesis: Any partially ordered,finite set, A, of k=n elements has a 
minimal element. For k = 1: The set clearly has a minimal element. For k = n+1: Divide the set A into two subsets; A': containing n elements and
the set containing the single element $x_{n+1}$. Then
$A= A'\cup \{x_{n+1}\}$.
By the IH A' contains a minimal element, let's call it $y$ and the set
$\{x_{n+1}\}$ has a minimal element, namely $x_{n+1}$. Now we have 3 cases: Case 1: $y\leq x_{n+1}$ in which case $y$ is the minimal element of A. Case 2: $x_{n+1} \leq y$ in which case $x_{n+1}$ is the minimal element of A. Case 3: $y$ and $x_{n+1}$ are incomparable in which case they're both
minimal elements of A. Edit: And also if I were to show that a totally ordered set contains a least element, could I just do the exact same thing, but skip case 3 (since all
elements in a toallay ordered set are comparable) ?",['elementary-set-theory']
2510496,If $AT=TA$ with $A\geq0$. Why $A^{1/2}T=TA^{1/2}$?,"Let $\mathcal{H}$ be a complex Hilbert space. Let $T\in \mathcal{B}(\mathcal{H})$ and let $A\in \mathcal{B}(\mathcal{H})^+$ (i.e. $A^*=A$ and $\langle Ax\;| \;x\rangle \geq0,\;\forall x\in \mathcal{H}$). Assume that $AT=TA$. Why $A^{1/2}T=TA^{1/2}$? Thank you","['functional-analysis', 'operator-algebras', 'operator-theory', 'hilbert-spaces']"
2510592,Can I use Dirac $\delta$ as forcing function of a linear differential equation?,"$$\begin{cases}y'+y=\delta(t) \\ y(0)=0\end{cases}$$ I have used Laplace transform: $$\mathscr{L} \{ \delta(t) \}=1$$ $$\mathscr{L} \{ y'+y \}=sY(s)-0 +Y(s)=sY(s)+Y(s)$$ $$sY(s)+Y(s)=1$$ $$(s+1) Y(s)=1$$ $$Y(s)=\frac{1}{s+1}$$ Inverse Laplace transform: $$y(t)=e^{-t}$$ But, $y(0)=1 \ne 0 $ Where is the problem? Thanks!","['ordinary-differential-equations', 'transformation', 'laplace-transform']"
