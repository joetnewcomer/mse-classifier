question_id,title,body,tags
3699527,Calculating Distance From a Line To Point,Hello everyone I have a point $P$ and a line $l$ . And I need to find all the $X$ points that for them the distance from $X$ to $P$ is the half distance from $X$ to $l$ in $2d$ . I tried to use the distance formula but I didn't success.,"['linear-algebra', 'geometry']"
3699551,When two Algebraic vector bundles on a Noetherian quasi-affine scheme are equal in $K_0$ of the scheme,"Let $X$ be a (connected) Noetherian scheme and $K_0(X)$ denote the Grothendieck group of the category of Algebraic vector bundles (coherent sheaves that are locally free and of constant rank ( as $X$ is connected) ). My question is: If for two Algebraic vector bundles $\mathcal F, \mathcal G$ on $X$ , we have $[\mathcal F]=[\mathcal G]$ in $K_0(X)$ , then is it necessarily true that $\mathcal F \oplus \mathcal O_X^{\oplus n}\cong \mathcal G \oplus \mathcal O_X^{\oplus n}$ for some integer $n\ge 0$ ? I know this is true if $X$ is affine, but I'm not sure what happens otherwise. I'm most interested in the case where $X$ is quasi-affine.","['algebraic-k-theory', 'algebraic-vector-bundles', 'coherent-sheaves', 'algebraic-geometry', 'schemes']"
3699566,Show that not exists any polynomial function such that $f(x) = \log (1+x)$. [duplicate],"This question already has answers here : Show that, for $t>0$, $\log t$ is not a polynomial. (9 answers) Closed 4 years ago . Does anyone have any idea on that problem? Let $f : \mathbb{R} \to \mathbb{R}$ be a polynomial function. Show that not exists any $f$ such that $f(x) = \log (1+x)$ . It's easy to show that $a_0 = 0$ and $a_1 = 1$ . But after i don't have any idea. Any point? Thanks!","['calculus', 'derivatives', 'polynomials']"
3699577,"Connectedness of the set $\{(z,w)\in S^3\subset \Bbb C^2:z^m+w^n=0\}$ where $m,n\in \Bbb N$","For positive integers $m,n$ , let $A_{m,n}$ denote the set $\{(z,w)\in S^3\subset \Bbb C^2:z^m+w^n=0\}$ . I am trying to show that this set is connected if and only if $\text{gcd}(m,n)=1$ . Also, in this case, I want to compute the length of $A_{m,n}$ . But I have no idea how to start for both statements. Can I get a little bit of hints? Thanks in advance.","['connectedness', 'general-topology', 'complex-numbers', 'differential-geometry']"
3699601,Find any values of $k$ for which $f$ is continuous,"Sketch this function for $k = 1$ . Is it continuous? Find any values of $k$ for which $f$ is continuous. $$f(x)= 
\begin{cases}
kx+3, & \text{$x≤1$} \\
(kx)^2-5, & \text{$x>1$}
\end{cases}$$ I would imagine that for the left side, I would get $4 (x+3$ , which $1$ is plugged into $x$ ) and for the right side, I would get $-4$ (plug in $1$ for $x$ , squared $- 5$ to get $-4$ ). I would guess these limits don't match, as one is positive and the other is negative. As they don't match, we wouldn't have a rational function, so this function is discontinuous at $x=1$ and the discontinuity is a jump discontinuity, as the $4$ and $-4$ don't match. Am I on the right path here? If not, where did I go wrong? Much appreciated in advance! :) UPDATE - Thank you all for the replies! Have a lovely week. :)","['limits', 'calculus', 'functions']"
3699653,Can a trajectory pass through a critical point for a plane autonomous system? (Differential equations),"Set up: I am considering a plane autonomous system where there exists two ODEs, $\frac{dx}{dt}=X(x,y),\frac{dy}{dt}=Y(x,y)$ . We then usually draw trajectories on the phase plane to indicate the solutions on the plane. Question : I often see trajectories sometimes cross at critical points, however I was wondering, if a trajectory does contain a critical point, wouldn't this trajectory just stay at that critical point rather than passing through that critical point since at that point $X=Y=0$ and so just becomes stationary? I am not too sure if I made much sense with my question but any help is appreciated!","['stationary-point', 'ordinary-differential-equations']"
3699659,"For given positive integers $s$ and $t$, how many integer solutions are there to $x^2+7y^2=3^411^s23^t$?","For given positive integers $s$ and $t$ , how many solutions $(x,y)\in\mathbb{Z}\times\mathbb{Z}$ are there to $$x^2+7y^2=3^411^s23^t\,?$$ Working in $\mathbb{Z}[\sqrt{-7}]$ , I know that I am trying to find how many $\alpha$ have norm equal to $3^411^s23^t$ .
I have so far found examples of $\alpha$ with norms of $11$ and $23$ ---these are $2 \pm \sqrt{-7}$ and $4 \pm \sqrt{-7}$ , but this is as far as I have gotten. Any help is appreciated, thanks!","['algebraic-number-theory', 'number-theory', 'elementary-number-theory', 'unique-factorization-domains', 'diophantine-equations']"
3699673,How to write $x= \sqrt{n^2+2}$ as a continued fraction and prove that x is irrational?,"I have to write $x= \sqrt{n^2+2}$ as a continued fraction, where $n \in N^*$ . I tried something like this: $$n< \sqrt{n^2+2}<n+1 \text{ so } [a_{0}]=n\\ x_1= \frac{1}{x-a_0}=\frac{1}{2}(\sqrt{n^2+2}+n), [a_1]=n $$ but for $x_2$ I obtained $\frac{2}{\sqrt{n^2+2}}$ . From here I don't know how to proceed.","['fractions', 'continued-fractions', 'functions', 'birational-geometry']"
3699698,Can quasiconformal mappings converge uniformly to a homeomorphism that is NOT quasiconformal?,"My question concerns the following situation: Let $G$ be a domain in $\mathbb{C}$ and $f_n: G \rightarrow \mathbb{C}$ be a sequence of quasiconformal mappings. Suppose that $f_n$ converges uniformly on $G$ , i.e. with respect to the supremum metric on $G$ , to a homeomorphism $f: G \rightarrow \mathbb{C}$ . My question is: Is it possible that the limit mapping $f$ is NOT quasiconformal, even though being a homeomorphism? Note that the answer is surely ""NO"" if the $f_n$ are all $K$ -quasiconformal for some fixed $K < \infty$ , by well-known convergence results on quasiconformal mappings; in this case, the limit mapping $f$ will be $K$ -quasiconformal again. Hence the interesting part of my question is when the condition "" the $f_n$ are $K$ -quasiconformal mappings "" is dropped, i.e. the maximal dilatations of the $f_n$ are not uniformly bounded by some constant $K$ ...I do not know what could possibly happen in this situation (maybe the situation at hand actually forces the $f_n$ to be $K$ -quasiconformal?), unfortunately all convergence results on quasiconformal mappings I am aware of deal with the situation that the $f_n$ are all $K$ -quasiconformal. Any kind of help is highly appreciated - thanks in advance!","['complex-analysis', 'quasiconformal-maps', 'uniform-convergence']"
3699927,Finite numbers that cannot be represented with $4m+7k$ using complete induction,"I need to prove that there exist finite amount of numbers that cannot be represented with $n=4m+7k~ |~ m,k \in \mathbb{N}$ . Starting: We say that $A = \{n \in \mathbb{N} | n=4m+7k \geq 18   ~~~ m,k \in \mathbb{N} \} \cup \{1,2, \dots 17\}$ We say that: $18,10,20,21 \in A$ (by hand) And assume each number between $18 \leq m \leq n-1 | n\geq 22$ are in A. And so: $n-4 \geq 18$ because $n\geq22$ We know that $n-4 \in A$ So: $n-4 = 4m +7k \rightarrow  n = 4m+4+7k \rightarrow n=4(m+1)+7k$ And we proved that $n \in A$ And thus $A = \mathbb{N}$ an infinite set and $\{n \in \mathbb{N} | n=4m+7k \geq 18   ~~~ m,k \in \mathbb{N} \}$ is infinite. so: $\{1...17\}$ is finite set. QED. I am not sure about this proof because it seems ""specific"" about $n-4$ , and what about $n-3$ ? I would appreciate your help!","['solution-verification', 'discrete-mathematics']"
3699958,"Square roots modulo $pq$ where $p$, $q$ are distinct primes - confusion with quote","I have a doubt about the following quote from a book: The Chinese Remainder Theorem implies that, if $p$ and $q$ are
  distinct primes, then $s$ is a square modulo $pq$ if and only if $s$ is a square modulo $p$ and $s$ is a square modulo $q$ . In particular,
  if $s \equiv x^2 \equiv (x')^2 \pmod p$ where $x \neq x'$ , and
  likewise $x \equiv y^2 \equiv (y')^2 \pmod q$ , then $s$ has exactly
  four square roots modulo $pq$ , namely, $$s \equiv (xy)^2 \equiv (x'y)^2 \equiv (xy')^2 \equiv (x'y')^2 \pmod{pq}$$ As an attempt to understand the quote, suppose I want to find the square roots of $11$ modulo $133$ . So, I have $s = 11$ , and, since $133 = 7 \times 19$ , I have $p = 7$ and $q = 19$ . I first need to separately find the roots of $11$ modulo $7$ and of $11$ modulo $19$ : To find the roots modulo $7$ , solve $x^2 \equiv 11 \pmod 7$ . Since $11 \equiv 2^2 \equiv 5^2 \pmod{7}$ , the roots are $x = 2$ and $x' = 5$ . To find the roots modulo $19$ , solve $x^2 \equiv 11 \pmod{19}$ . Since $11 \equiv 7^2 \equiv 12^2 \pmod{19}$ , the roots are $y = 7$ and $y' = 12$ . The quote is saying that $xy$ , $x'y$ , $xy'$ and $x'y'$ are roots of $s$ modulo $pq$ . However, this seems to be untrue in my example: $xy = 2 \times 7 = 14$ , but $11 \not\equiv 14^2 \pmod{133} $ . $xy' = 2 \times 12 = 24$ , but $11 \not\equiv 24^2 \pmod{133} $ . $x'y = 5 \times 7 = 35$ , but $11 \not\equiv 35^2 \pmod{133} $ $x'y' = 5 \times 12 = 60$ , but $11 \not\equiv 60^2 \pmod{133} $ Am I missing something?","['elementary-number-theory', 'discrete-mathematics']"
3699983,"Confused about the relation between linear transformations, matrices and basis vectors","I was watching 3blue1brown's video series on linear algebra. My understanding till now is :- A linear transformation takes in a vector and outputs another vector. The above statement is equivalent to multiplying a unique matrix to the given vector. 3b1b shows the linear transformation using a new coordinate system, and shows that $\hat{i}$ and $\hat{j}$ change. When he discusses change of basis, he states that it helps us move between different coordinate systems. 3b1b also states that a matrix implicitly assumes coordinate systems, as it represents the landing spots of basis vectors after linear transformation. He shows how to transform a rotation matrix in a conventional Cartesian coordinate system, to Jennifer's coordinate system (one where basis vectors are not perpendicular to one another). Points 4,5 and 6 have really confused me and now I doubt even points 1,2 and 3. When we write a matrix what basis vectors does it assume? I have never seen any text stating that this assumes a Cartesian coordinate system. I always assumed that it is somehow independent of coordinate systems. My second question: I thought that a linear transformation doing a 90° counter-clockwise rotation is represented by a unique matrix \begin{equation*}
A = 
\begin{pmatrix}
0 & -1  \\
1 & 0
\end{pmatrix},
\end{equation*} but, as was shown in the video for Jennifer's choice of basis vectors the same 90° counter-clockwise rotation linear transformation is in fact \begin{equation*}
B = 
\begin{pmatrix}
1/3 & -2/3  \\
5/3 & -1/3
\end{pmatrix}.
\end{equation*} It seems like a linear transformation has a one-one mapping to a unique matrix only for a given set of basis vectors. Thus, the same matrix can refer to different linear transformations if we choose a different basis vector. In case, I am correct, could you provide a mathematically rigorous way of writing this down (using math symbols). I feel that I understand concepts better if I can write it in a mathematical form, instead of relying solely on intuition.","['matrices', 'coordinate-systems', 'linear-algebra', 'linear-transformations']"
3700076,What sample size is needed to ensure a majority?,"The results of a sample of voters showed that $55\%$ voted for a given candidate. It was determined that at a confidence level of $0.95$ that candidate would be the winner (i.e. would receive the majority of the votes). What sample size is needed to ensure the accuracy of that statement? Given the mean, standard deviation, and sample size, I can find a confidence interval using $Z_{1-\alpha/2}$ and without the standard deviation with $t_\alpha(n-1)$ . This question, however, doesn't seem to give the necessary information to use either approach. Perhaps the possible $5\%$ difference between $55\%$ and ""majority"" should be used in the calculation, but I don't know how to approach making the correct formulas.","['statistics', 'confidence-interval', 'sampling']"
3700082,Infinite binary sequences countable set,"I know that the set of all binary sequences is uncountable, and I'm asked to prove that the set of all binary sequences that are constant from a certain point ( $n\in\mathbb{N}$ ) is countable, meaning the set: $\{\eta:\eta\in\{0,1\}^{\mathbb{N}}\land\exists n\in\mathbb{N}\forall m>n(\eta(m)=\eta(n))\}$ is countable. 
How does the fact that all binary sequences in this set are constant from a certain point make it countable?","['elementary-set-theory', 'binary', 'sequences-and-series']"
3700119,"Let S be the set of all real numbers in the interval (0; 1) whose decimal expansions contain only 0's, 4's and 8's. Prove that S is uncountable.","I just prove
$$S_1=\{0.4,0.8\}$$
$$S_2=\{0.04,0.08,0.44,0.48,0.84,0.88\}$$
...
So I can calculate the number of elements in $S_n = 2 \times 3^{n-1}$ I just prove it is countably infinite.","['elementary-set-theory', 'real-numbers', 'cardinals']"
3700153,Need explanation for a combinatorics riddle (full answer provided),"11 people in a certain company have access to a safe. The company
  owner wants any group of six people out of the 11 to open the safe,
  But no five-person group can open the safe itself. To achieve this
  goal he decided to put more than one lock on The safe, and give each
  person keys only to some of the locks. How many locks he has to put on the safe and how many keys each person
  will have to achieve his goal (the company owner wants to reduce the
  number as much as possible The locks, and as much as possible reduce
  the number of keys each person receives)? Answer: Each subgroup of 5 people will not be able to open the safe, so each subgroup should have a lock so that the members of the group do not have a key for it. On the other hand, a key for the same lock is shared for all but 5 members of the subgroup. We achieved two goals in this: each sub-group of 5 people could not open the safe and any subset of 6 you can. so we need $\binom{11}{5}$ Locks and $\binom{10}{5}$ keys My question: Can I get more elaboration on the answer?","['combinations', 'combinatorics', 'discrete-mathematics']"
3700161,algebraic de Rham cohomology of blowup of relative line,"Let $$T = \mathbb{A}^1_k,\,\,\, Y = \mathbb{P}^1_T,\,\,\, X = \mathscr{B}(Y),$$ the blowup of $Y$ at a point. I am trying to compute the de Rham cohomology $H^1_{dR}(X/T)$ , but I could use some help. I would like to be able to work over a field like $k = \mathbb{Q}$ , but ultimately I will be wanting to compute with something in positive characteristic, like $\mathbb{F}_p$ . I have already calculated everything to my satisfaction for the projective line $Y \to T$ (even in positive characteristic), with a $2$ x $2$ double complex, but things become substantially messier when using this $3$ x $3$ complex (especially with the infinite dimensional terms arising from the positive characteristic stuff). I have computed a Cech cover and each term and map involved in the de Rham complex, and I have computed bits and pieces of kernels and cokernels of the double complex, but I keep ending up stuck in a big mess. Is there a better perspective or technique here, like spectral sequences, Mayer-Vietoris, excision sequences, etc? I'm really weak with spectral sequences, so as of yet I haven't been able to understand how to apply them. We can define the situation as follows: Let $R = k[t], R_0 = k[t,y^{-1}], R_1 = k[t,y], R_2 = k[t,y,x]/(t - xy), R_3 = k[t,y,x^{-1}]/(x^{-1}t - y)$ and denote $U_i := \mathrm{Spec}R_i$ . $$T = \mathrm{Spec} R$$ $$Y = \mathrm{Proj}R[y_0,y_1] = \mathrm{Spec}R_0 \cup \mathrm{Spec}R_1$$ $$X = \mathrm{Spec}R_0 \cup \mathrm{Spec}R_2 \cup \mathrm{Spec}R_3$$ The intersections are given by $U_{ij} = \mathrm{Spec}R_{ij}$ and $U_{ijk} = \mathrm{Spec}R_{ijk}$ with $$ R_{02} = k[t, y^{\pm 1}]$$ $$ R_{23} = k[t, x^{\pm 1}]$$ $$ R_{03} = k[t^{\pm 1}, y^{\pm 1}]$$ The de Rham cohomology is the hypercohomology of the following double complex: $$\begin{matrix} 
\mathcal{O}_X(U_0)\oplus\mathcal{O}_X(U_2) \oplus \mathcal{O}_X(U_3) & \to & \Omega^1_{X/T}(U_0)\oplus\Omega^1_{X/T}(U_2)\oplus\Omega^1_{X/T}(U_3) & \to & \Omega^2_{X/T}(U_0)\oplus\Omega^2_{X/T}(U_2)\oplus\Omega^2_{X/T}(U_3)\\
\downarrow & & \downarrow & & \downarrow\\
\mathcal{O}_X(U_{02})\oplus\mathcal{O}_X(U_{23}) \oplus \mathcal{O}_X(U_{03}) & \to & \Omega^1_{X/T}(U_{02})\oplus\Omega^1_{X/T}(U_{23})\oplus\Omega^1_{X/T}(U_{03}) & \to & \Omega^2_{X/T}(U_{02})\oplus\Omega^2_{X/T}(U_{23})\oplus\Omega^2_{X/T}(U_{03})\\
\downarrow & & \downarrow & & \downarrow\\
\mathcal{O}_X(U_{023}) & \to & \Omega^1_{X/T}(U_{023}) & \to & \Omega^2_{X/T}(U_{023})\\
\end{matrix}$$ Which simplifies to $$\begin{matrix} 
R_0\oplus R_2 \oplus R_3 & \to & R_0\cdot \langle dy^{-1} \rangle \oplus M_2 \oplus R_3\cdot \langle dx^{-1} \rangle & \to & 0\oplus N_2 \oplus 0\\
\downarrow & & \downarrow & & \downarrow\\
R_{02}\oplus R_{23} \oplus R_{13} & \to & R_{02} \cdot \langle dy^{-1} \rangle \oplus R_{23} \cdot \langle dx^{-1} \rangle \oplus R_{03} \cdot \langle dy^{-1} \rangle & \to & 0 \oplus 0\oplus 0\\
\downarrow & & \downarrow & & \downarrow\\
R_{023} & \to & \Omega^1_{X/T}(U_{023}) & \to & 0 \\
\end{matrix}$$ Where $M_2, N_2$ are straightfoward to compute. I doubt it would be helpful for me to put in the rest of the mess that makes up my calculation. I'm not even too sure of it, but I feel there has to be a better approach. Could anyone provide me some guidance on this? Thank you.","['algebraic-geometry', 'blowup', 'de-rham-cohomology', 'positive-characteristic']"
3700194,"$X_1,X_2, \ldots$ be i.i.d. Show that $\mathbb{E}|X_1| < \infty $ iff $ \frac{X_n}{n} \to 0$ a.s","Suppose $X_1,X_2, \ldots$ be i.i.d. Show that $\mathbb{E}|X_1| < \infty \Leftrightarrow   \frac{X_n}{n} \to 0$ a.s I tried using Markov but I don't know anything about the $ \mathbb{E}X $ . I was also thinking of borel Cantelli, to show $ \sum P\left[\frac{X_n}{n}>\varepsilon\right]< \infty $ for each $\varepsilon>0$ , then invoke First Borel Cantelli but I am confused on how to even get to the sum is less than infinity part","['borel-cantelli-lemmas', 'probability-theory']"
3700209,"Proof on ""No rectangles"" on a grid","I was solving a problem of the UVA judge called ""No rectangles"".  The problem is about picking points from an $n\times n$ grid such that $k$ points are chosen from each row and column but no $4$ of the points form a rectangle with sides parallel to the grid. They claim the following in the statement of the problem It can easily be shown that for any given value of $k$ , $k^2 − k + 1$ is a
  lower bound on the value of $n$ , and it can be shown further that $n$ need
  never be larger than this. Proving this statement is not necessary to solve the problem. However, I've been thinking on how to prove it and I do not know how I could do it. Any hints/clues?",['combinatorics']
3700276,Proving non-differentiability of $f:\mathbb{R}^2 \to \mathbb{R}$,"Question: Given $f:\mathbb{R}^2 \to \mathbb{R}$ defined by $f(x, y) =
\begin{cases}
x,  & \text{if $y=x^2$} \\
0, & \text{otherwise}
\end{cases}$ , show $f$ is not differentiable at $(0, 0)$ . Attempt: I know a few things about $f$ : it is continuous at $(0, 0)$ and has continuous directional derivatives (but am yet to prove these). To prove non-differentiability, I need to show that there does not exist a linear mapping $A$ from $\mathbb{R}^2$ to $\mathbb{R}$ (which can be represented by the $2 \times 1$ matrix $\begin{bmatrix}
    a \\
    b \\
    \end{bmatrix}$ ) so that $\lim_{h \to 0, h \in \mathbb{R}^2} \frac{\Vert f(x+h) - f(x) - Ah \Vert}{\Vert h \Vert} = 0$ where $x=(0, 0)$ . To do this, I considered the LHS of the equation and intend to show that it does not limit to $0$ . Letting $h=(h_1, h_2)$ gives $$\lim_{(h_1, h_2) \to 0} \frac{\Vert f((0, 0)+(h_1, h_2)) - f(0,0) - A(h_1, h_2) \Vert}{\Vert (h_1, h_2) \Vert}=\lim_{(h_1, h_2) \to 0} \frac{\Vert f(h_1, h_2) - A(h_1, h_2) \Vert}{\sqrt{h_1^2+h_2^2}}$$ however I am unsure of how to further evaluate this since we do not know $f(h_1, h_2)$ and I am unsure of what $A(h_1, h_2)$ evaluates to. Any help would be greatly appreciated.","['analysis', 'real-analysis', 'continuity', 'multivariable-calculus', 'calculus']"
3700286,Uniqueness of the Frechet Derivative: the role of $x \in int_X(T)$,"I'm currently trying to learn some functional analysis as a way to improve my ability to read economic theory papers. I've come across what I thought was a simple proof but on reflection I don't think I'm grasping it. I'm not a mathematician so I apologise if this question is rather trivial! My problem lies in the proof of the uniqueness of the Frechet derivative. Here is the definition that I'm using (From Efe OK's book Real Analysis with Economic Applications). Definition Let $X$ and $Y$ be two normed linear spaces and $T$ a subset of $X$ . For any $x \in int_X(T)$ , a map $\Phi : T \rightarrow Y$ is said to be Frechet differentiable at $x$ if there is a continuous linear operator $D_{\Phi,x}\in \mathcal{B}(X,Y)$ such that \begin{equation}
\lim_{\omega \rightarrow x} \frac{\Phi(\omega)-\Phi(x)-D_{\Phi,x}(\omega-x)}{\left\lVert \omega-x \right\rVert} = \mathbf{0}
\end{equation} The linear operator $D_{\Phi,x}$ is called the Frechet derivative of $\Phi$ at $x$ . The proof proceeds by taking any two $K,L \in \mathcal{B}(X,Y)$ that satisfy the definition of the Frechet derivative, with $D_{\Phi,x} = K$ and $D_{\Phi,x} = L$ . We must then have \begin{equation}
\lim_{\omega \rightarrow x} \frac{(K-L)(\omega-x)}{\left\lVert \omega-x \right\rVert} = \mathbf{0}
\end{equation} The next step is where I'm confused. Since $int_X(T)$ is open, this is equivalent to saying that \begin{equation}
\lim_{v \rightarrow \mathbf{0}} \frac{(K-L)(v)}{\left\lVert v \right\rVert} = \mathbf{0}
\end{equation} The rest of the proof is reasonably straightforward. The author provides a warning in the footnotes that if $x \notin int_X(T)$ the final two displayed equations are not equivalent, and the Frechet derivative in this case is not unique. It seems intuitively reasonable that the final two expressions are equivalent but I'm not sure how to show it. My initial thought is that, with $x$ in the boundary, it limits the directions from which one can converge to it.","['frechet-derivative', 'derivatives', 'functional-analysis']"
3700300,Dificulty to prove chromatic number of directed planar graphs,So I was reading this question and tried to prove it but I don't understand the statements that the answer and comments say since I don't what is a 2-dim sphere and can't understand why $D$ can be divided into 3 forests Can someone explain or help me prove this statement?,"['graph-theory', 'directed-graphs', 'discrete-mathematics', 'planar-graphs']"
3700350,Looking to optimise my Runescape grind (probability),"I know there's gaming stackexchange for gaming questions, but I believe this is purely maths related. I'll try to avoid using game jargon and keep it simple. I'm collecting keys in game, each key taking a fair bit of time to obtain. They open a chest, which generates one random reward from a predeterimed table. On the loot table, there are five different armor pieces, each with a chance of 1/1000 to obtain. The catch is, because of game's inventory limitations, I can't open the chest every time I get a key and just get the five armor pieces that way - I have to do big openings of multiple keys at once. If I don't get a full set, but, for example, 4 out of 5 pieces, it would limit the speed of obtaining future keys. Which is why I would like to count an optimal amount of keys to have to get the full set at once. Is there a set method or a formula for similar problems? If the above explaination is too convoluted, I can try to further simplify it if needed.",['probability']
3700360,"What's the distribution of $xy+xz+yz$ where $x,y,z $ are independent standard normal?","We know the product of two independent Normal random variables has a normal product distribution, or Variance Gamma distribution if they are correlated. But, what if there are three Normal random variables? So, here is the question: Suppose $x,y,z$ are three independent normal random variables ( $x, y, z\sim N(0,1)$ ), what's the distribution of $xy+xz+yz$ ?","['probability-distributions', 'normal-distribution', 'probability']"
3700367,Average distance from a square's perimeter to its center,"What is the average distance from any point on a unit square's perimeter to its center? The distance from a square's corner to its center is $\dfrac{\sqrt{2}}{2}$ and from a point in the middle of a square's side length is $\dfrac{1}{2}$ . A visual explanation of what I'm trying to explain So, what would the average distance be, accounting for all the points along a square's perimeter? Also if possible, a general formula for finding the average distance from center to edge of any $n$ -sided regular polygon would be super awesome.","['calculus', 'geometry']"
3700436,If $f(x)$ is integrable can we say that $f(x)^n$ is integrable?,"Suppose $f(x)$ is a positive and continuously differentiable functions. In addition, it is well-known that $\int_{0}^{\infty} f(x)dx$ is bounded. My point of view is that $\int_{0}^{\infty} f(x)^mdx$ (where $m \in \mathbb N$ ) is bounded. I will be gratefull if you would propose me a conterexample. If this claim is true, how can I prove it?",['integration']
3700465,"Index of subgroups in a finite solvable group, with trivial Frattini subgroup (Exercise 3B.12 from Finite Group Theory, by M. Isaacs)","Let G be a finite solvable group, and assume that $\Phi(G) = 1$ where $\Phi(G)$ denotes the Frattini subgroup of G. Let M be a maximal subgroup of G, and suppose that $H \subseteq M$ . Show that $G$ has a subgroup with index equal to $|M:H|$ . This is question 3B.12 from Finite Group Theory, by M. Isaacs. Here is my approach so far. I am completely stuck and would welcome any hints or ideas. Suppose otherwise. Among all of the counter examples choose $G$ of minimum order. Since $G$ is a counterexample it must be the case that $|G| > 1$ . Since $G$ is a counter example there is a maximum subgroup $M$ and a subgroup $H \subset M$ , such that every subgroup of $G$ does not have the same index as $|M:H|$ . So it must be the case that $H$ is properly contained within $M$ . This is where I get stuck. I want to use a minimal normal subgroup $N$ of $G$ which exists. But my argument devolves into a series of cases about whether or not $N$ intersects $H$ and/or $M$ non-trivially. I do know that $G$ must have a non-normal maximal subgroup, since if they all were normal then it would be nilpotent and since G is finite this implies supersolvable, then $G$ would have a subgroup for any divisor of its order. Since $\Phi(G)=1$ is the intersection of all the maximal subgroups of $G$ I suspect this should help but I'm not sure where to go from here.","['group-theory', 'frattini-subgroup', 'finite-groups', 'solvable-groups']"
3700498,Why linear regression choose to minimize the residual on y-axis but not the absolute error between prediction and measurement?,"Does anyone know why linear regression choose to minimize only $(y_{predict} - y_{measured})^2$ , but not $(y_{predict} - y_{measured})^2 + (x_{predict} - x_{measured})^2 $ ?","['linear-regression', 'statistics']"
3700533,Understanding $\mathcal F_\tau$ and showing that $X_\tau$ is $\mathcal F_\tau$-measurable where $\tau$ is a stopping time.,"Let $(\Omega ,\mathcal F,\{\mathcal F_t\},\mathbb P)$ be a filtered probability space. Let $\tau$ be a stopping time. We have that $$\mathcal F_\tau:=\{A\in \mathcal F\mid A\cap \{\tau\leq t\}\in \mathcal F_t\}.$$ Q1) What exactly is $\mathcal F_\tau$ ? I know it's a $\sigma $ -algebra, but don't really see the motivation behind its definition. My teacher says that $A\in \mathcal F_\tau$ means that even if $A\notin \mathcal F$ , you know that $A$ occurs or not whenever $\tau\leq t$ . But to be honest, I don't really understand what it means. Can someone illustrate or explain it a bit more? Q2) Let $(X_t)$ a stochastic process. Then $X_\tau$ is $\mathcal F_\tau$ -measurable. How can I prove that? I guess that I have to prove that $\{X_\tau\leq x\}\cap\{\tau\leq t\}\in \mathcal F_t$ . I know that $\{X_s\leq x\}\in \mathcal F_t$ for all $s\leq t$ . I guess that $\{X_\tau\leq x\}\cap \{\tau\leq t\}$ if and only if there is $s\leq t$ s.t. $\{X_s\leq x\}$ , i.e. $$\{X_\tau\leq x\}\cap \{\tau\leq t\}=\bigcup_{s\leq t}\{X_s\leq x\},$$ but I'm not so sure how to continue. Maybe if $(X_t)$ is continuous, then $$\bigcup_{s\leq t}\{X_s\leq x\}=\bigcup_{\substack{s\leq t\\ s\in \mathbb Q}}\{X_s\leq x\}\in \mathcal F_t,$$ but how can I conclude this whenever $(X_t)$ is not continuous?","['stochastic-processes', 'stopping-times', 'probability-theory']"
3700549,Can this function be defined in a way to make it continuous at $x=0$?,"We have $$f=\frac{x}{\vert x-1 \vert - \vert x +1 \vert}$$ If we want to ""define"" this function to be continuous at $x=0$ , it's limit at $0$ must equal $f(0)$ . So we should find this limit and assign it to be equal to $f(0)$ , then the function is continuous at $0$ . Since we are looking at the function when $x\to 0$ , $x\neq 0$ . Lets divide both sides by $x$ . $$f=\frac{x}{\vert x-1 \vert - \vert x +1 \vert}=\frac{1}{\frac{\vert x-1 \vert}{x}-\frac{\vert x+1\vert}{x}}=\frac{1}{\vert 1-\frac{1}{x}\vert - \vert 1+ \frac{1}{x}\vert }$$ We can use $\lim \phi(x)^{-1}=\frac{1}{\lim \phi(x)}$ here ( the limit $\neq$ 0, by hypothesis ). The inverse of the limit of $\phi(x)=\vert 1 - \frac{1}{x} \vert-\vert 1+\frac{1}{x}\vert$ , when $x\to 0$ . If $x<1$ , we have that $$\frac{1}{x}>1\implies0>1-\frac{1}{x}\implies \Bigg\vert 1-\frac{1}{x}\Bigg\vert=-\Big(1-\frac{1}{x}\Big)$$ Now if $x>0$ , we have that $$\Bigg\vert 1 - \frac{1}{x} \Bigg\vert-\Bigg\vert 1+\frac{1}{x}\Bigg\vert=-2$$ and if $x<0$ , then $$\Bigg\vert 1 - \frac{1}{x} \Bigg\vert-\Bigg\vert 1+\frac{1}{x}\Bigg\vert=1-\frac{1}{x}-1-\frac{1}{x}=\frac{(-2)}{x}$$ The limit of $f$ when $x\to 0$ appears to be $\frac{-1}{2}$ . Could anyone tell me what errors I made in the limit finding process?","['limits', 'continuity', 'real-analysis']"
3700558,"A new type of manifold, is such a construction interesting? Is it relevant for the Euler-Lagrange equations","Recently, I've been wondering how to rewrite the standard Euler-Lagrange equations: \begin{align}
\dfrac{\partial L}{\partial q^i} - \dfrac{d}{dt} \left(\dfrac{\partial L}{\partial \dot{q}^i}\right) &= 0
\end{align} (all derivatives being evaluated at appropriate points along a stationary curve of the action functional) without referencing the coordinates $(q^1, \dots q^n, \dot{q}^1, \dots, \dot{q}^n)$ on the tangent bundle. So, I tried to rewrite things as much as possible using only ""natural operations"" on the tangent bundle, like Lie-derivative, exterior derivative etc. Of course, I didn't succeed (and any articles I tried to search online were too abstract to understand), so what I did was expand the total time derivative: \begin{align}
\dfrac{\partial L}{\partial q^i} - \left[\dfrac{\partial^2 L}{\partial q^j\partial \dot{q}^i}\dot{q}^j + \dfrac{\partial^2 L}{\partial \dot{q}^j\partial \dot{q}^i}\ddot{q}^j \right] &= 0.
\end{align} This gave me the idea that perhaps thinking of the Lagrangian, $L$ , as a function on the tangent bundle $TQ \to \Bbb{R}$ is perhaps not the most appropriate/natural setting. It seems that the tangent bundle only has coordinates $(q, \dot{q})$ , whereas the Euler-Lagrange equations which are second order differential equations, involving $\ddot{q}$ . So, it seemed to me that it would be nice to construct a new manifold $M$ , from the original ""configuration manifold"" $Q$ , so that on the new manifold $M$ , we have local coordinates $(q^i, \dot{q}^i, \ddot{q}^i)$ , for $1 \leq i \leq n$ . To formalize this idea of introducing a larger manifold with extra coordinates for higher derivatives, my plan was to mimic the construction of $TQ$ as much as possible. Let $k \geq 1$ be an integer and let $Q$ be a smooth manifold modeled on a Banach space $E$ . Now, we define a relation $\sim_k$ on the set of all smooth curves $\gamma:I \to Q$ , where $I$ is an open set in $\Bbb{R}$ containing $0$ , by declaring $\gamma_1 \sim_k \gamma_2$ if and only if there is a chart $(U, \alpha)$ of $Q$ such that (the composition below makes sense and) for every $r \in \{0, \dots, k\}$ , we have \begin{align}
(\alpha \circ \gamma_1)^{(r)}(0) &= (\alpha \circ \gamma_2)^{(r)}(0).
\end{align} A tedious, but straight forward induction exercise and chain rule shows that this relation doesn't depend on the choice of chart $(U, \alpha)$ , so we're actually justified with using the notation $\sim_k$ without referencing the chart. This is also an equivalence relation. For the lack of a better name, I shall denote the quotient set of equivalence classes as \begin{align}
C^kQ := (\text{smooth curves in $Q$})/\sim_k,
\end{align} and I shall call it ""the $k^{th}$ order contact manifold of curves in $Q$ "" . Given a smooth curve $\gamma$ , we shall indicate the equivalence class either as $C^k\gamma$ or $[\gamma]$ , whichever is more convenient. Next, I outline how I put a manifold structure. I realized that this space has quite a bit of structure: we can define a projection map $\pi_k : C^kQ \to Q$ by sending $C^k \gamma \mapsto \gamma(0)$ . We can even make this into a smooth manifold as follows: given a chart $(U, \alpha)$ on $Q$ , we define the chart $(C^kU, C^k \alpha)$ by defining $C^kU := \pi_k^{-1}[U]$ and $C^k \alpha : C^kU \to \alpha[U] \times E^k$ , \begin{align}
C^k \alpha([\gamma]) &:= \left( (\alpha \circ \gamma)(0), (\alpha \circ \gamma)'(0), \dots (\alpha \circ \gamma)^{k}(0) \right)
\end{align} This is a well-defined map because of how the equivalence relation was defined. It is also easily seen to be a bijective map, and also, if $(V, \beta)$ is another chart on $Q$ with $U \cap V \neq \emptyset$ , then using the chain rule, it is straightforward (though tedious) to seem that $(C^k \beta) \circ (C^k \alpha)^{-1}$ is a smooth map between open subsets of Banach spaces. Also, I only just recently read up about fiber bundles, but I believe that based on what I've constructed, we have that $\pi_k :C^kQ \to Q$ is a fiber bundle, with typical fiber $E^k$ , whereby the maps $C^k\alpha$ defined above provide us with the local trivializations. Is this the correct way of using the terminology? Here are my questions: Have people considered such spaces $C^kQ$ ? Are they interesting manifolds to study, and am I right in thinking that these manifolds would be a more appropriate setting to formulate Lagrangian mechanics? I believe that this is true, because if for some reason we decided to consider a Lagrangian which depends on higher derivatives of the curve, then the tangent bundle alone is insufficient to capture such information. In any case, I would appreciate some confirmation/denial along with references (if any). Is it possible to formulate the Euler-Lagrange equations in a coordinate-free manner, perhaps using such spaces? If yes, I'd appreciate some references (which hopefully aren't too abstract). For $k=1$ , this construction yields precisely the tangent bundle, in which case, the fiber over each point $x \in Q$ , namely $T_xQ$ can be given a natural vector space structure. However, for $k>1$ , am I right in saying that we cannot endow each fiber with a vector space structure? Of course, if we choose a particular chart $(U, \alpha)$ , we can establish a bijection between the fiber $\pi_k^{-1}(\{x\})$ and $E^k$ , and hence inherit a vector space structure that way, but I believe that this is not a chart-independent construction. Is this right?","['fiber-bundles', 'smooth-manifolds', 'euler-lagrange-equation', 'mathematical-physics', 'differential-geometry']"
3700613,"Solutions for $ \int_0^{\infty} \frac{1}{\sqrt{t^3\left(t+\tau\right)^3}}\exp\left[- \frac{2t+\tau}{t\left(t+\tau\right)}\right] \, dt $","I am trying to find an analytical solution to the above integral. The context is as follows: I am interested in obtaining an expression for the autocovariance function of the change in groundwater level in an idealised aquifer following a unit pulse input. The governing equation for fluid motion in this idealised aquifer is given by: \begin{equation}
\frac{\partial h}{\partial t} = \frac{T}{S}\frac{\partial^2 h}{\partial x^2}
\end{equation} where $T$ and $S$ are characteristics of the aquifer system. The unit impulse-response function is given by: \begin{equation}
h^{\delta}\left(x,\, t\right) = \frac{Sx^2}{4T}\left(t^*\right)^{-\frac{3}{2}}\mathrm{e}^{-1/t^*} \quad \mbox{where} \quad t^* = \frac{4Tt}{Sx^2}
\end{equation} The autocovariance function, $\gamma\left(x,\,\tau\right)$ for the causal system is given by: \begin{equation}
\gamma\left(x,\, \tau\right) = \int_0^{\infty} h^{\delta}\left(x,\,t\right)h^{\delta}\left(x,\,t+\tau\right) dt = \left(\frac{Sx^2}{4T}\right)^2 \int_0^{\infty} \left(t^*\right)^{-\frac{3}{2}}\mathrm{e}^{-1/t^*}\left(t^*+\tau\right)^{-\frac{3}{2}}\mathrm{e}^{-1/(t^*+\tau)}\,  dt^*
\end{equation} I have noted that: \begin{equation}
\int_0^{\infty} \left(t^*\right)^{-\frac{3}{2}}\mathrm{e}^{-1/t^*} \, dt^* = \sqrt{\pi} \quad \mbox{and} \quad \int_0^{\infty} \left(t^*+\tau\right)^{-\frac{3}{2}}\mathrm{e}^{-1/(t^*+\tau)} \, dt^* = \sqrt{\pi} \,\mathrm{erf}\left[\frac{1}{\tau}\right]
\end{equation} but can get no further. Any assistance or thoughts would be much appreciated.","['integration', 'convolution']"
3700638,Real-world application where strong LLN is needed (weak LLN is not enough) [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question Do you know of any real world (algorithm, physics, ...) application of the law of large numbers where we need the strong LLN and the weak LLN by itself is not enough to prove that the application is working as expected ?","['statistics', 'weak-convergence', 'applications', 'law-of-large-numbers', 'probability']"
3700688,Constant function composition,"I have the following Problem: Let $g \in C^1(\mathbb{R^2};\mathbb{R})$ . Show that an injective $f \in C^1 ((-1,1);\mathbb{R^2})$ exists, so $g \circ f$ is constant. The hint asks if there is a $(x,y) \in \mathbb{R^2}$ with ${\rm grad}(F(x,y)) \ne 0$ . However I have no  idea how to tackle this problem, I saw some examples here: Composition of functions is constant .
But these functions are partially constant and therefore not injective, has anyone ideas?","['derivatives', 'real-analysis']"
3700710,Pulling a partial derivative out,"Though the following seems intuitive, is it correct precisely? Suppose $T:\mathbb{R}^2\to\mathbb{R}$ is a smooth function. Then $$\Big({\partial\over\partial y}{\partial T\over\partial x}\Big)(0, y_0) = {d\over dy}\Big({\partial T\over\partial x}(0, y)\Big)(y_0)$$ for all $y_0\in\mathbb{R}$ . What I expect is to ""see"" the mathematical machinery that gets me from the LHS to the RHS. Thanks! Note: I'm a physics undergraduate, who is trying to understand the math (as precisely as possible) that the physics textbooks often sweep under the rug. Also, to prevent abuse of notation, I think that RHS is better written as $\mathcal{T}'(y_0)$ , where $\mathcal{T}:\mathbb{R\to R}$ is a function defined by $\mathcal{T}(y):={\partial T\over\partial x}(0, y)$",['multivariable-calculus']
3700773,Prove the difference is more than $n$ and less than $2n$,"We chose $n + 2$ numbers from the set $\{1,2,....3n\}$ . Prove that there are always two among the chosen numbers whose difference is more than $n$ but less than $2n$ . Though I can understand it by taking examples but I really struggle when it comes to prove. Also is there really good book that will structure my thinking so that I can proof these type of questions.","['pigeonhole-principle', 'combinatorics', 'discrete-mathematics']"
3700784,"$f(0)=f(1)=0$, $f(x)=\frac{f(x+h)+f(x-h)}{2}$ implies $f(x)=0$ for $[0, 1]$","Question: Suppose $f$ is continuous on $[0, 1]$ with $f(0)=f(1)=0$ . For $\forall x\in (0, 1)$ , there $\exists h>0$ with $0\le x-h<x<x+h\le1$ such that $f(x)=\frac{f(x+h)+f(x-h)}{2}$ . Show that $\forall x\in(0, 1), f(x)=0$ . I tried to prove that $f$ is differentiable on $(0, 1)$ using the fact that $\frac{f(x+h)-f(x)}{h}=\frac{f(x)-f(x-h)}{h}$ , but I realized that not all $h$ holds the equation, but there exists a particular $h$ in every $x$ . So, this is not a proper approach. I also thought about the concavity of $f$ . Since $\forall x\in(0, 1),\exists h>0$ with $0\le x-h<x<x+h\le1$ such that $$f(x)=f\left(\frac{x-h}{2}+\frac{x+h}{2}\right)\ge {1\over2}f\left(x-h\right)+{1\over2}f\left(x+h\right)$$ , which implies $f$ is concave downward, and $$f(x)=f\left(\frac{x-h}{2}+\frac{x+h}{2}\right)\le {1\over2}f\left(x-h\right)+{1\over2}f\left(x+h\right)$$ , which implies $f$ is concave upward. Two facts might imply that $f$ is constant, which in turn $\forall x\in[0, 1], f(x)=0$ since $f(0)=f(1)=0$ . Is this approach correct? I thought it has to be more precise, so I wanted to use the second derivative. But I actually failed to prove that $f$ is differentiable. Could you please give me some ideas about the question? Thanks a lot.","['calculus', 'jensen-inequality', 'derivatives']"
3700796,How to prove that $\wp''$'s zeros are not at half-periods?,"This is an exercise adapted from Apostol. The problem is stated as Prove that $$\wp''\left(\frac{\omega_1}{2}\right)=2(e_1-e_2)(e_1-e_3)$$ where $\omega_1,\omega_2$ generates the lattice for $\wp$ . I could see that by Weierstrass' differential equation, we have $$2\wp''\wp'=4\wp'((\wp-e_1)(\wp-e_2)+(\wp-e_2)(\wp-e_3)+(\wp-e_3)(\wp-e_1))$$ and $$2\wp'''\wp'+2\wp''^2=4\wp''(\cdots)+4\wp'(\cdots)$$ At $z=\frac{\omega_1}{2}$ we have $\wp'''=\wp'=0$ since they are odd elliptic functions. Therefore, $$2\wp''^2\left(\frac{\omega_1}{2}\right)=4(e_1-e_2)(e_1-e_3)\wp''$$ Now if $\wp''\left(\frac{\omega_1}{2}\right)\neq0$ we are done. However, I find it very difficult to prove the claim. I tried the following steps: first, we assume $\wp'(z)\neq 0$ . Then by the expanded differential equation, $$\wp''=6\wp^2-\frac{1}{2}g_2=6\left(\wp-\sqrt{\frac{g_2}{12}}\right)\left(\wp+\sqrt{\frac{g_2}{12}}\right)$$ Since $\wp(z)\pm\sqrt{\frac{g_2}{12}}$ are double zeros of $\wp''$ and the order of $\wp''$ is $4$ , if I could prove that $\pm\sqrt{\frac{g_2}{12}}\neq e_i$ , $i=1,2,3$ then we are done. I tried to use the fact that $g_2=2(e_1^2+e_2^2+e_3^2)$ , but it left me with the problem of proving $$\frac{e_1^2+e_2^2+e_3^2}{6}\neq e_i^2$$ for all $i$ . How can I proceed? or is there a simpler argument that applies? I must have missed something. Please help me. Thanks in advance.","['number-theory', 'elliptic-functions', 'derivatives', 'roots']"
3700803,Derivative of a unit vector,"Consider a vector function $r: \mathbb{R} \to \mathbb{R}^n$ defined by $r(t)$ . We use $\hat{r}$ to denote its normalized vector, and $\dot{r}$ to denote $\frac{d}{dt}r(t)$ . We know that the derivative of a normalized vector is orthogonal to itself. It would be suggestive to write \begin{equation} \label{eq_ddtrt}
	\frac{d}{dt} \hat{r}(t) = a(t) N(\hat{r}(t)), \tag{1}
\end{equation} where $a(t)$ is a scalar function and $N(\hat{r}(t))$ is a vector orthogonal to $\hat{r}(t)$ and it is a function of $\hat{r}$ explicitly . Consider the 2D case; that is, $n=2$ . Then we can find out that \begin{equation} \label{eq_ddtrt2}
	\frac{d}{dt} \hat{r}(t) = \underbrace{\left(-\frac{1}{\Vert r\Vert} \hat{r}^T E \dot{r} \right)}_{a(t)} \underbrace{E \hat{r}}_{N(\hat{r}(t))}, \tag{2}
\end{equation} where $E=\begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix}$ is a rotational matrix. So $N(t)=E \hat{r}$ is indeed orthogonal to $\hat{r}(t)$ and it is explicitly a function of $\hat{r}$ . The advantage is that I could take $N(\hat{r}(t))$ out, and combine different coefficients, say, $a_i(t)$ , to simplify some other computations. The detailed calculation can be seen in the appendix. The problem is that this seems to work for $n=2$ , but it is difficult to obtain similar result for $n>2$ . Question : How to obtain a similar equation like \eqref{eq_ddtrt} for the higher-dimensional case where $n>2$ ? By similarity, I mean it can be written as $a(t)N(\hat{r}(t))$ , where $N(\hat{r}(t))$ is explicitly a function of $\hat{r}$ . Equation \eqref{eq19c} is not in this form. Question : Is it possible to write $N(\hat{r}(t))$ as a cross product of $\hat{r}(t)$ and some function? Appendix: Calculation of \eqref{eq_ddtrt2} \begin{equation} 
\frac{d}{dt}{\frac{r(t)}{\Vert r(t)\Vert}} = \frac{d}{dt}{r(t)} \cdot \frac{1}{\Vert r(t)\Vert} + r(t) \cdot \frac{d}{dt}{\frac{1}{\Vert r(t)\Vert}} = \left(\frac{I}{\Vert r\Vert} - \frac{r r^T}{\Vert r\Vert^3}\right) \dot{r} \label{eq19c} \tag{3}
\end{equation} If we define an operator $\hat{\cdot}: \mathbb{R}^n \rightarrow \mathbb{R}^n$ such that $\hat{r}=\frac{r}{\Vert r\Vert}$ , then \eqref{eq19c} can be re-written as follows: \begin{equation} 
\frac{d}{dt}{\hat{r}(t)} = \frac{1}{\Vert r\Vert}(I - \hat{r} \hat{r}^T) \dot{r} = -\frac{1}{\Vert r\Vert} E \hat{r} \hat{r}^T E \dot{r} = \left( -\frac{1}{\Vert r\Vert}  \hat{r}^T E \dot{r} \right) E \hat{r},
\end{equation} where note that $$
	I - \hat{r} \hat{r}^T = (E \hat{r}) (E \hat{r})^T = - E \hat{r} \hat{r}^T E.
$$","['geometry', 'real-analysis', 'multivariable-calculus', 'linear-algebra', 'derivatives']"
3700868,Integrate from $0$ to $2\pi$ with respect to $\theta$ the following $(\sin \theta +\cos \theta)^n$,$$\int_0^{2\pi} (\sin \theta +\cos\theta)^n d\theta$$ First I think about De Moivre's formula given by $$(\cos x +i \sin x)^n=\cos (nx)+i\sin (nx)$$ I tried to apply it but I found myself lost ! Any tips or information how to solve this integral ? Thanks in advance !,"['integration', 'trigonometry', 'definite-integrals']"
3700873,Calculate a triangle based on one angle and the lengths on either side of the perpendicular,"Considering a standard triangle as shown here: h is perpendicular to c . I know the lengths p and q, and angle C. It seems to me like that should completely define the triangle. The trouble is I cannot come up with the formulas to calculate the other lengths and angles. The best solution I came up with so far is an iterative process: c = p + q Split angle C in C1 = C * p / c and C2 = C * q / c Next, calculate: p / tan C1 - q / tan C2 If that is positive, add a small amount to C1 and subtract the same amount from C2. If negative, do the opposite. Repeat the calculation and reduce the amount applied to the angles until I get ""close enough"". But I expect there should be a more direct approach. A simple example: q = 80, p = 45, and C = 90 degrees (π/2 rad). Another example: q = 45, p = 32, and C = 64.9423845817 degrees (1.133458435047 rad). Note: I initially asked this question on stackoverflow.com, but was told that math.stackexchange.com would be a better place for such questions.","['trigonometry', 'geometry']"
3701082,Which Smirnov is behind the Smirnov topology?,"Good old Steen and Seebach discuss the Smirnov deleted sequence topology in their Counterexamples in Topology (2nd ed. 1978). This is also reported as the $K$ -topology, in e.g. Wikipedia etc. However, none of the sources that I've found tell us which particular Smirnov is behind it. I am guessing it's Yurii Mikhailovich Smirnov as of all the Smirnovs I know of in mathematics, he is the one who has greatest involvement in topology. (For example: Vladimir Ivanovich is known for a 5-volume textbook, and Nikolai Vasilyevich made a name for himself in statistics.) Yurii Mikhailovich is of course the mathematician whose name is associated with the Nagata-Smirnov metrization theorem, so it's more than plausible it's the same one. Can anyone point me towards a source that can confirm this?","['general-topology', 'math-history', 'reference-request']"
3701312,"Function satisfying $f(v,w) = f(Uv,Uw)$ for any vectors $v,w$ and unitary $U$","If I have a function $f: V\times V\to \mathbb{R}$ where $V$ is an inner product space over $\mathbb{R}$ and for all unitary matrices $U \in \mathcal{L}(V)$ I have $$f(v,w) = f(Uv,Uw)$$ can I conclude that $f$ is a function of the inner products $v\cdot w, v\cdot v, w\cdot w$ alone? I am motivated to ask this because I do not know of any other ways to combine two vectors into a real number which is invariant under $v\to U v$ (i.e. orthonormal basis independent). But I am failing to find a way to prove it. How about if the target space is not necessarily $\mathbb{R}$ ?","['linear-algebra', 'functional-analysis', 'mathematical-physics']"
3701340,Prove $\lim_{n \rightarrow \infty} f(x) f(2^2x) f(3^2x) \cdots f(n^2x) = 0$ for $f: \mathbb{R} \rightarrow \mathbb{R}$ in $L^1(\mathbb{R})$.,"Here's another question that I'm stuck on from my studies for an upcoming exam.  This one comes from another practice preliminary exam. Problem Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be  a Lebesgue integrable function.  Prove that for almost every $x \in \mathbb{R}$ that $$ \lim_{n \rightarrow \infty} f(x) f(2^2x) f(3^2x) \cdots f(n^2x) = 0$$ I.e. given that $\int_\mathbb{R} |f(x)| dx < \infty$ , prove the above limit. Please, correct me if I'm wrong, confirm my thoughts, or provide hints towards a solution.  Thanks in advance! My Partial Attempt Break the support into three cases.  Either $S := \{ x \in \mathbb{R} | f(x) \neq 0\}$ (1) has $\mu(S) = 0$ , (2) finite $\mu(S) > 0$ , or (3) $\mu(S) =  \infty$ ,. (1) We have immediately that the integral $\int_\mathbb{R} |f(x)| dx = 0$ because the function is supported by a set of measure zero.  Hence, the function is zero almost everywhere and we have our result. (2) This is the tricky case for me.  This is where I'm looking for guidance if my case-by-case method is in fact a method for solution.  Otherwise, provide a hint or an alternative solution method. (3) Help here too.","['limits', 'measure-theory', 'lebesgue-integral', 'real-analysis']"
3701342,"Prove that (Q, ∘ , *) is unitary commutative ring","The question is: Is (Q,∘ ,*) a commutative and unitary ring, where: a ∘ b = a + b + ab a * b = ab My observation: Q has the property of closure under ∘ and has the property of closure under *, since the results of both operations are elements of Q. Then ∘ is associative since: ∀ a, b, c ∈ Q: a ∘ ( b ∘ c ) = ( a ∘ b ) ∘ c And an element e ∈ Q is an identity element since: ∀ x ∈ Q: x ∘ e = x = e ∘ x where e=0 But then -1 does not have an inverse element since: ∀ a, a' ∈ Q : a ∘ a' =  a' ∘ a = e a + a' + aa' = 0 a' = (-a)/(1+a) which means that a can't be equal to -1, does that mean that (Q,∘ ,*) is not a commutative and unitary ring? Any help would be appreciated, thank you.","['ring-theory', 'abstract-algebra', 'discrete-mathematics']"
3701352,Prove that if $ \lim_{x\to\infty}f\left(x\right)=L $ then $ \lim_{n\to\infty}\intop_{0}^{1}f\left(n\cdot x\right)dx=L $.,"let $ f $ be integrable function in any interval such [0,M].
assume $ \lim_{x\to\infty}f\left(x\right)=L $ for some $ L\in \mathbb{R} $ and prove that $ \lim_{n\to\infty}\intop_{0}^{1}f\left(n\cdot x\right)dx=L $ . I've managed to prove that $ \intop_{0}^{1}f\left(n\cdot x\right)dx=\frac{1}{n}\intop_{0}^{n}f\left(x\right)dx $ . Im not sure how to continue. Thanks in advance","['integration', 'limits', 'calculus', 'riemann-integration']"
3701355,Prove: Three tangents to a parabola form a triangle with an orthocenter on the directrix and a circumcircle passing through the focus,"Prove the following: The intersection points of any three tangents to a parabola given by the formula $y(y-y_0)=2p(x-x_0)$ are vertices of a triangle whose orthocenter belongs to the directrix of the parabola and the circumcircle of the triangle passes through the focus of the parabola. My attempt: Orthocenter problem part- edited (old notes deleted to be less chaotic and I believe there is still some space for improvement of the first part): In the meantime, I realized it would be better to just use the condition of tangency and plug some of its parameters into the formula for a line in the $xy$ plane. Let $y=k_ix + l_i,\ i=1,2,3$ be a tangent line to a parabola. Then $$p=2k_il_i\implies l_i=\frac{\frac{p}2}{k_i}$$ Now, our equation becomes: $$\boxed{y=k_ix+\frac{\frac{p}2}{k_i}}$$ We can substitute $\frac{p}2$ by $\alpha$ , so $$\boxed{y=k_ix+\frac{\alpha}{k_i}}$$ This way, our computations are getting easier.
The equations of the three arbitrary tangents to a parabola are: $$\begin{aligned}y&=k_1x+\frac{\alpha}{k_1}\\y&=k_2x+\frac{\alpha}{k_2}\\y&=k_3x+\frac{\alpha}{k_3}\end{aligned}$$ The intersection point of the $i-$ th and $j-$ th tangent line: $$k_ix+\frac{\alpha}{k_i}=k_jx+\frac{\alpha}{k_j}\implies x=\alpha\frac{\frac1{k_j}-\frac1{k_i}}{k_i-k_j}=\frac{\alpha}{k_ik_j}$$ $$y=k_i\cdot\frac{\alpha}{k_ik_j}+\frac{\alpha}{k_i}=\alpha\left(\frac1{k_i}+\frac1{k_j}\right)$$ $$\boxed{S_{ij}=\left(\frac{\alpha}{k_ik_j},\alpha\frac{k_i+k_j}{k_ik_j}\right)}$$ Now, we have to find the line perpendicular to the $k-$ th tangent line passing through the point $S_{ij}$ . $k_\perp=-\frac1{k_k}$ E.g., one altitude of the formed triangle belongs to the line: $$\begin{aligned}y-y_{S_{1,2}}&=k_\perp(x-x_{S_{1,2}})\iff &y&=-\frac1{k_3}x+\frac{\alpha}{k_1k_2k_3}+\alpha\left(\frac1{k_1}+\frac1{k_2}\right)\\&&y&=-\frac1{k_3}x+\alpha\left(\frac1{k_1}+\frac1{k_2}+\frac1{k_1k_2k_3}\right)\end{aligned}$$ So, the $x$ coordinate of the intersection of the three tangent lines: $$\begin{aligned}y&=-\frac1{k_3}x+\alpha\left(\frac1{k_1}+\frac1{k_2}+\frac1{k_1k_2k_3}\right)\\y&=-\frac1{k_2}x+\alpha\left(\frac1{k_1}+\frac1{k_3}+\frac1{k_1k_2k_3}\right)\\y&=-\frac1{k_1}x+\alpha\left(\frac1{k_2}+\frac1{k_3}+\frac1{k_1k_2k_3}\right)\end{aligned}$$ $$\begin{aligned}-\frac1{k_3}x+\alpha\left(\frac1{k_1}+\frac1{k_2}+\frac1{k_1k_2k_3}\right)&=-\frac1{k_2}x+\alpha\left(\frac1{k_1}+\frac1{k_3}+\frac1{k_1k_2k_3}\right)\\\left(\frac1{k_2}-\frac1{k_3}\right)x&=\left(\frac1{k_3}-\frac1{k_2}\right)\alpha\\x&=-\alpha=-\frac{p}2\end{aligned}$$ End of the first part. The rest remains the same not to be off-topic . Since the points $P_1,P_2, P_3$ are close to the directrix, $\triangle ABC$ in my picture is obtuse and its orthocenter is outside the triangle, but it doesn't have to be so at all. Let $A,B,C$ be the intersection points of the tangents. $P_2\in\overline{AC}$ due to $P_1\preceq P_2\preceq P_3$ . Let $A'\in\overline{BC}$ s.t. $AA'\perp BC$ , $B'\in\overline{AC}$ s.t. $BB'\perp AC$ and $C'\in\overline{AB}$ s.t. $CC'\perp AB$ . The center $S$ of the circumscribed circle $q$ of $\triangle ABC$ is the intersection point of the bisectors $s_1,s_2,s_3$ of the sides $\overline{AB},\overline{BC}$ and $\overline{AC}$ respectively. Furthermore, $\underline{\text{each side bisector is parallel to one of the sides of the triangle}}$ , i.e., $$s_1\parallel\overline{AA'}\ \&\ s_2\parallel\overline{BB'}\ \&\ s_3\parallel\overline{CC'} $$ If the orthocenter $T$ is an orthogonal projection of the point $P_2$ onto the directrix $x=-\frac{p}2$ of the parabola, and if the circumscribed circle $q$ really passes through the focus $$\boxed{F\left(\frac{p}2,0\right)\ \text{or}\ F\left(\frac{p}2+x_0,y_0\right)}$$ then $|TP_2|=|P_2F|$ . Picture: zoomed: According to the notation in the picture: $$\begin{aligned}\measuredangle AA'B&=\measuredangle A'CT=\measuredangle BFL\\\measuredangle B'TA&=\measuredangle ACA'=\measuredangle AFB\end{aligned}$$ I can see: $$\triangle AB'T\sim\triangle BB'C\sim\triangle A'AC\sim AFB'$$ In particular: $\boxed{\triangle AB'T\cong\triangle AFB'\implies\ |TB'|=|B'F|\implies\triangle TFP_2\ \text{is isosceles}\ \implies |TP_2|=|P_2F|\ }$ Also:
we can prove the orthogonal projections of the focus onto the three tangents belong to the tangent passing through the vertex of the parabola , meaning those projections are collinear, which, by the Simson theorem , implies the focus belongs to the circumcircle of the triangle. May I ask for advice on solving this task and improve the parts I might have done correctly to be concise as possible? Thank you in advance! P. S. I found a related paper , but almost none of the information has been covered in our official literature. Just in case, I found an answer by @JeanMarie recalling the fact the orthocenter of the observed triangle lies on the directrix of the parabola, but I couldn't think of proof. Update on a special case: I've also read the directrix is the set of all the points in the plane we can draw two mutually perpendicular tangents from (which can be proven via Vieta's formulae and the condition of tangency ). In a right-triangle, the orthocenter is obviously in the vertex opposite to the hypothenuse.","['analytic-geometry', 'conic-sections', 'geometry', 'tangent-line']"
3701368,Find the value of $n$ if $\frac{a^{n+1}+b^{n+1}}{a^n+b^n}=\frac{a+b}{2}$,"Now, this question looks simple, it did to me too, at first, but I got stuck at a point and can't get out. This is how I did it, take a look : $$\dfrac{a^{n+1}+b^{n+1}}{a^n+b^n}=\dfrac{a+b}{2}$$ By cross multiplication, we get : $$2a^{n+1}+2b^{n+1}=(a+b)(a^n+b^n) = a^{n+1}+b^{n+1}+ab^n+a^nb$$ Transposing the first two terms of RHS to LHS , we obtain : $$a^{n+1}+b^{n+1}=ab^n+a^nb$$ Now, what I did the first time I attempted this question was that I transposed $a^nb$ to the LHS and $b^{n+1}$ to the RHS but my friend suggested that we could also transpose $ab^n$ to LHS and $b^{n+1}$ to RHS and obtain different results. I suggested that we look at some constraints and arrive at condition based answers. Here's how I proceeded : $1^{st}$ method : $$a^{n+1}-a^nb=ab^n-b^{n+1}$$ $$\implies a^n(a-b)=b^n(a-b)$$ Now, instead of just cancelling out $a-b$ , I thought of putting a condition that would enable the cancellation to be possible. That condition is that $a-b$ should not be equal to $0$ , so $a \neq b$ Now, on assuming that $a \neq b$ , we get : $$a^n=b^n$$ Now, there are two cases when this is possible, one, when $n=0$ , so $a^n=b^n=1$ and other, when $a=b$ , but, we have already assumed that $a \neq b$ to arrive at this result, which means that the case that suggests that $n = 0$ is true. So, the $1^{st}$ method gives us the conclusion that $a \neq b \implies n = 0$ Here's the $2^{nd}$ method : $$a^{n+1}-ab^n=a^nb-b^{n+1}$$ This time, we take $a$ and $b$ common on the LHS and the RHS respectively to obtain : $$a(a^n-b^n)=b(a^n-b^n)$$ Now, we can cancel out $(a^n-b^n)$ from both LHS and RHS if $a^n-b^n \neq 0 \implies a^n \neq b^n$ Now, this can be true only if $a \neq b$ and $n \neq 0$ because if any of these two cases end up being true, then $a^n$ will be equal to $b^n$ . So, we assume that $a \neq b$ and $n \neq 0$ and cancel optu $a^n-b^n$ from both LHS and RHS to obtain : $$a=b$$ This is the part that confuses me. We assume that $a \neq b$ to arrive at a conclusion that $a = b$ , is it possible? Do outcomes like this appear frequently (this is the first time I have encountered something like this)? Did I make some mistake? How do I get out of this? In my opinion (which is most probably wrong), the second method gives us no useful outcome and tells us that $a$ can not be equal to $b$ which is almost surely wrong because I don't see any restriction that would show that $a \neq b$ . I do think that a better approach would be to take two cases : $a \neq b$ and $a = b$ and then expand them and then combine the outcomes. But I'd like to know what's wrong with this approach and how do I correct it? Thanks!",['algebra-precalculus']
3701433,"About continuous local martingales, question on Le-Gall's book","Background Hello, I'm working on question 4.24 on Le-Gall's Brownian motion(...) and I would ask you to check if my ideas are correct. The question is as follows: $(M_t)$ is a cont. local martingale w/ $M_0=0$ . Let $T_n=\inf_{t\geq 0}\{|M_t|=n\}$ , show that $$\{\lim_{t\to\infty}M_t\ \text{exists and is finite}\}=\bigcup_{n\geq 1}\{T_n=\infty\}\subseteq\{\langle M,M\rangle_\infty<\infty\},\ \text{almost surely}.$$ Let $S_n=\inf_{t\geq 0}\{\langle M,M\rangle_t=n\}$ , show that $$\{\langle M,M\rangle_\infty<\infty\}=\bigcup_{n\geq 1}\{S_n=\infty\}\subseteq\{\lim_{t\to\infty}M_t\ \text{exists and is finite}\}.$$ Conclude that $\{\lim_{t\to\infty}M_t\ \text{exists and is finite}\}=\{\langle M,M\rangle_\infty<\infty\}$ almost surely. Here $\langle M,M\rangle_t$ denotes the quadratic variation of $(M_t)$ . My progress So I worked on part 1 on the most natural way I could think of: Let $\omega\in\{\lim_{t\to\infty}M_t\ \text{exists and is finite}\}$ , then $$M_\infty(\omega)=\lim_{t\to\infty}M_t(\omega)<\infty.$$ Now since $(M_t)$ has cont. sample paths, $|M_t(\omega)|$ is bounded by some $C>0$ . Next $T_m(\omega)=\infty$ for all $m>C$ since the event $|M_t(\omega)|=m>C$ never occurs. Then $\omega\in\{T_m=\infty\}$ for $m>C$ and with this we have proven the first inclusion $$\{\lim_{t\to\infty}M_t\ \text{exists and is finite}\}\subseteq\bigcup_{n\geq 1}\{T_n=\infty\}.$$ I'm stuck on the other side, I take an $\omega\in\{T_m=\infty\}$ for some $m\geq 1$ and therefore $\omega\in\{T_n=\infty\}$ for $n\geq m$ , since $M_t$ has cont. sample paths. This last statement implies that $M_t(\omega)$ is bounded but I cannot reach the fact that the limit exists since I feel that $M_t(\omega)$ could oscillate wildly and therefore never reach a limit. Also on the flipside if I want to show that such $\omega$ is in $\{\langle M,M\rangle_\infty<\infty\}$ I would like to use the fact that for bounded (true) martingales in $L^2$ it occurs that $E\langle M,M\rangle_\infty<\infty$ . However, mine is not a true martingale but a cont. local martingale. This is theorem 4.13 on Le-Gall's book. I don't know how to prove this fact without using such theorem. With the same strategy as before I can prove $$\{\langle M,M\rangle_\infty<\infty\}\subseteq\bigcup_{n\geq 1}\{S_n=\infty\}.$$ EDIT1:
The same problem does not occur in the other inclusion. since I don't know if $M_t(\omega)$ has a limit by knowing that $\langle M,M\rangle_t$ is bounded. Since $\langle M,M\rangle_t$ is an increasing process and it's bounded then it converges to a limit. Therefor it follows that the set and the union are equal. On the final inclusion I would like to use again the fact that $EM_\infty^2=E\langle M,M\rangle_\infty$ but once more this is only valid for bounded martingales in $L^2$ . Questions Is there something I'm not seeing or I'm overlooking? Can you help me see it more clearly or give me a pointer in the right direction? Is my idea on proving the directions I proved correct? Any kind of help will be greatly appreciated.","['solution-verification', 'local-martingales', 'martingales', 'stopping-times', 'probability-theory']"
3701489,Signed measure: verification,"Let $f\colon X\to[-\infty,+\infty]$ a measurable function such that $$\int_Xf^+\;d\mu<\infty\quad\text{or}\quad \int_Xf^-\;d\mu<\infty,$$ then $$\nu(E)=\int_Ef\;d\mu$$ is a signed measure. 
I have to prove the countable additivity of $\nu$ . Let $\{E_k\}$ a sequence of disjoint measurable set and let $E=\cup_n E_k.$ By definition $$\nu(E)=\nu^+(E)-\nu^-(E)=\int_Ef^+d\mu-\int_Ef^-d\mu$$ since $\nu^+$ and $\nu^-$ are measures we have $$\nu(E)=\sum_{k}\nu^+(E_k)-\sum_{k}\nu^-(E_k)$$ I can conclude as $$\nu(E)=\sum_k[\nu^+(E_k)-\nu^-(E_k)]=\sum_k\nu(E_k)$$ Question. iIt's true or false? if it is fake how can i repair it?","['proof-explanation', 'measure-theory', 'proof-writing', 'solution-verification']"
3701514,Simplifying $\int\cos^2(x)\sin(2x)dx$ via the optimal substitution,"I was just tutoring and a student's question was: Make a trig substitution to make evaluating $\int \cos^2(x)\sin(2x)dx$ simpler. So yeah, the question is only asking for what trigonometric substitution do we use to simplify the integral, it's not asking to evaluate the integral. FIRST ATTEMPT: Using $\sin(2x)=2\cos(x)\sin(x)$ the integral becomes $$\begin{aligned}&\int\cos^2(x)\sin(2x)dx\\&=\int\cos^2(x)2\cos(x)\sin(x)dx\\&=2\int\cos^3(x)\sin(x)\end{aligned}$$ I thought this was a good answer because if we set $u =\cos^2(x)$ , then by the chain rule we get $$du = -2\cos(x)\sin(x)dx$$ and thus $$\frac{du}{-2\cos(x)\sin(x)}=dx$$ And so $$\begin{aligned}&\int\cos^2(x)2\cos(x)\sin(x)dx\\&=2\int\cos^3(x)\sin(x)dx\\&=\int\cos^2(x)(2\cos(x)\sin(x))dx\\&=\int\cos^2(x)(2\cos(x)\sin(x))\left(\frac{du}{-2\cos(x)\sin(x)}\right)\\&=\int\cos^2(x)\\&=\int udu\end{aligned}$$ And is thus quite solvable. However, the computer said that this substitution was not correct. SECOND ATTEMPT: I used $\cos^2(x) = \frac{1+\cos(2x)}{2}$ to get: $$\begin{aligned}\int\cos^2(x)\sin(2x)dx\\&=\int \left(\frac{1+\cos(2x)}2\right)\sin(2x)dx\\&=\int \left(\frac{\sin(2x)+\sin(2x)\cos(2x)}2\right)dx\\&=\int\left(\frac{sin(2x)}2+\frac{\sin(2x)\cos(2x)}2\right)dx\end{aligned}$$ which is quite a simplification, and we can even take this one further with realizing that since $\sin(2x)=2\sin(x)\cos(x)$ we have that $\sin(4x)=2\sin(2x)\cos(2x)$ . Thus our integral becomes: $$=\int\left(\frac{\sin(2x)}2+\frac{\sin(4x)}2\right)dx$$ which I think is quite simple. However, the homework program did not accept this substitution as the correct substitution to make either. Does anyone have any ideas?","['integration', 'indefinite-integrals', 'calculus', 'trigonometry']"
3701519,Evaluate $\int \cos^2(x)\tan^3(x) dx$ using trigonometric substitution,"How would I integrate to evaluate $\int \cos^2(x)\tan^3(x) dx$ using trigonometric substitution? I made an attempt by making substitutions such as $$\cos^2(x)=1-\sin^2(x)$$ $$\tan(x) = \frac{\sin(x)}{\cos(x)}$$ and $$\tan^2(x)=1+\sec^2(x)$$ But I couldn't find a way to make it look like an integral I could solve using a $u$ substitution or identity.
Could I get some help on this one?","['integration', 'indefinite-integrals', 'calculus', 'trigonometry']"
3701539,Find $( \dotsb ((2017 \diamond 2016) \diamond 2015) \diamond \dotsb \diamond 2) \diamond 1$ given ...,"For positive real numbers $a$ and $b,$ let $$a \diamond b = \frac{\sqrt{a^2 + 4ab + b^2 - 2a - 2b + 9}}{ab + 6}.$$ Find $$( \dotsb ((2017 \diamond 2016) \diamond 2015) \diamond \dotsb \diamond 2) \diamond 1.$$ I can't find any quick way to do this. Can anyone help? Thanks in advance!",['algebra-precalculus']
3701597,Is $H_m - H_n$ a surjection onto $\mathbb{Q}^+$?,"I was wondering whether, for each rational $q$ , we may always write $$q = \sum_{k=a}^b \frac 1k$$ For some positive integers $a \leq b$ . I get the feeling that this is not true (although an immediate consequence of $\mathbb{R}^+$ being Archimedean is that the set of such $q$ is dense). I'm sure there is some slick proof using Bertrand's postulate (as is typical with these problems) but I'm not seeing it. This post is partly a reference request, as I'm sure this has been touched on before in some article, and would like to see it.","['number-theory', 'rational-numbers', 'harmonic-numbers', 'reference-request']"
3701609,Bijective Pairing given one set,"****Disclaimer this is a homework help question not sure if that's a problem but I'll try to format my question in a way so I'm not just trying to get the answer but get some understanding of what it is I need to do to solve the question properly The Question How many ordered lists of four natural numbers, $(a,b,c,d) \in N^4$ , are there such that $a + b + c + d = 23$ Describe how to encode/decode each ordered list into a codeword. Why the encoding is a bijective pairing How to count the number of codewords to answer the question What I know Bijective pairing - what I know here is that bijective pairing between sets means for two sets X and Y a single value in X maps to a single value in Y and the inverse is also true If I am not mistaken the reason the encoding is a bijective pairing is because each one of the 4 numbers we will select will map to $\{a,b,c,d\}$ though I may be mistaken here Where my understanding fails me A) I am not sure exactly what they mean by encoding and decoding but again I sort of have the assumption in my head that this is mapping each of the 4 numbers to either a b c or d. B) I am not sure how understanding how to do this encoding will tie in to me being able to answer the last part of the question","['combinatorics', 'discrete-mathematics']"
3701642,Show that a function of $\lambda$ is monotone,"In my research I ran into the following problem Show that $$f(\lambda)=E\left[\exp\left(\frac{-X+\lambda Y}{\lambda+1}\right)\right]$$ is monotone in $\lambda$ . Where $X,Y$ are possibly unbounded but otherwise nice, fixed, random variables. Or at least, I hope this is true. I took the derivative to get $$f'(\lambda)=E\left[\exp\left(\frac{-X+\lambda Y}{\lambda+1}\right)\frac{X+Y}{(\lambda+1)^2}\right]$$ This looks like depending on the sign of $E[X+Y]$ , we either have $f'(\lambda)\geq 0$ or $f'(\lambda)\leq 0$ for all $\lambda$ . I've tried using various inequalities, but I can't quite show this. I would either like a proof or a counterexample.","['inequality', 'probability-theory', 'probability']"
3701670,"Finding all intersections of $f(x)= \sin(x)+1$ and $g(x)= \cos(x)$ on the interval $[0,4\pi]$","The question asks to find all the points where $f(x)= \sin(x)+1$ intersects with $g(x)= \cos(x)$ on the interval $[0,4\pi]$ . I started by setting both equations equal to each other resulting in the new equation: $$\sin(x)+1 = \cos(x)$$ I thought that if I was somehow able to use trigonometric identities in order to make $\sin(x)$ and $\cos(x)$ end up multiplying to each other so that I don't get rid of any solutions and can solve more easily. My process: sin(x)+1 = cos(x) (sin(x)-cos(x))^2= (-1)^2 sin^2(x)-2sin(x)cos(x)+cos^2(x)=1 sin^2(x)+cos^2(x)=1+2sin(x)cos(x)                 Pythagorean Identity 1= 1+2sin(x)cos(x)                                Subtract 1 from both sides 0= 2sin(x)cos(x) This states that the solution is anytime cos(x) or sin(x) equals zero. This would mean x= 0,π/2,π,3π/2,2π,5π/2,3π,7π/2, and 4π. But when I graphed this I got that the solutions are at: x=0,3π/2,2π,7π/2, and 4π. This is half of what I thought would be the solutions. I used logic to try to solve it now. I started again with setting the equations to each other again and then guessing and checking. sin(x)+1 = cos(x) I knew that for this to be true sin(x) would have to equal zero when cos(x) would have to equal one or sin(x) would have to equal negative one when cos(x) would have to equal zero. This in mind. I listed all the places: sin(x) equals zero: 0,π, and 2π cos(x) equals one: 0, 2π Where they coincided I knew there was a solution. Here two solution were 0 and 2π. Then I did the same for when sin(x) equals negative one and cos(x) equals zero
sin(x) equals negative one: 3π/2 cos(x) equals zero: π/2, 3π/2 Here another solution was 3π/2. Because sin and cos graphs oscillate I know that is I add 2π to every one of these solutions I would get the rest of the solutions from [2π,4π]. Although, when problems become more complicated I can't always rely on guess and check so I was wondering how I could algebraically solve it since I can't figure it out.","['algebra-precalculus', 'trigonometry']"
3701684,Sum of independent random variables is a martingale which converges almost surely,"Let $ \{X_n\}_{n \ge 1} $ be a sequence of independent random variables satisfying $$
    \mathbb{P}(X_n = -n^2) = 1 - \mathbb{P}(X_n = \frac{n^2}{n^2 - 1}) = \frac{1}{n^2}.
$$ The question is to show that $S_n = X_1 + ... + X_n$ is a martingale such that $S_n / n \rightarrow 1$ a.s. and $S_n \rightarrow \infty$ a.s. My attempt : $$
\mathbb{E}[X_m] = -m^2 \cdot \frac{1}{m^2} + (\frac{m^2}{m^2 - 1}) \cdot (1 - \frac{1}{m^2}) = -1 + 1=0,
$$ and $\mathbb{E}[S_n] = \sum_{i = 1}^n \mathbb{E}[X_i] = 0.$ For $\mathcal{F}_{n} = \sigma(X_1, ..., X_n)$ , we see that $$
\begin{align*}
    \mathbb{E}[S_{n} | \mathcal{F}_{n - 1}] &=  \mathbb{E}[S_{n - 1} + X_n |\mathcal{F}_{n - 1}] \\
    &= \mathbb{E}[S_{n - 1} |\mathcal{F}_{n - 1}] + \mathbb{E}[X_n] \\
    &= S_{n - 1} + 0 \\
    &= S_{n - 1}.
\end{align*} 
$$ Moreover, $\mathbb{E}|S_n| < +\infty$ since $$
\mathbb{E}|S_n| \le \mathbb{E}( \sum_{i = 1}^n |X_i|) = \sum_{i = 1}^n\mathbb{E}|X_i| = 2n.
$$ If we let $A_n$ be the event that $X_n = \frac{n^2}{n^2 - 1}$ , then $\sum_{n \ge 1} \mathbb{P}(A_n) = \sum_{n \ge 1} (1 - \frac{1}{n^2}) = +\infty $ and since $X_n$ independent for $n = 1, 2, ...$ we have by Borel-Cantelli lemma that $\mathbb{P}(A_n \text{ i.o}) = 1$ . And since $\lim_n X_n = 1$ , we can conclude that $S_n \rightarrow \infty$ almost surely. Is this reasoning correct? If it is, how do I apply the same reasoning using Borel-Cantelli for $S_n/n \rightarrow 1$ a.s. ?","['borel-cantelli-lemmas', 'martingales', 'probability-theory']"
3701758,Fermat's last theorem for entire functions,"Let $f,g,h$ be entire functions, i.e., holomorphic functions on $\mathbb{C}$ . Suppose $f^n+g^n=h^n$ for some integer $n\geq2$ . What can we say about $f,g,h$ ? Clearly this is Fermat's last theorem for entire functions. I did a little search on the internet but, somewhat surprisingly, I found nothing relevant. Where can I find the answer? Thanks in advance. :) Edit: In particular, I would like to know why there are no nontrivial solutions for $n\geq4$ . Here a trivial solution is a solution of the form $f=ap,g=bp,h=cp$ where $a,b,c\in\mathbb{C}$ satisfy $a^n+b^n=c^n$ and $p$ is entire.","['complex-analysis', 'number-theory', 'entire-functions']"
3701803,Differentiation of an integral depending on a parameter,"Let $f(t):=\int_0^{\pi/2} \arccos\frac{t-\tan^2x}{t+\tan^2x}\,dx$ , for $0\leq t\leq 1$ . I would like to differentiate $f$ with respect to $t$ by taking the partial of the integrand: $$
f'(t)
 = \int_0^{\pi/2}\frac{\partial}{\partial t}
   \left(\arccos\frac{t-\tan^2x}{t+\tan^2x}\right)\,dx
 = -\int_0^{\pi/2} \frac{1}{\sqrt{t}}
                   \frac{\tan x}{t+\tan^2x}\,dx.
$$ I am not sure to be able to fully justify this step, in particular because $x$ can approach $\frac{\pi}2$ (from the left), where $\tan x\rightarrow +\infty$ , and $t$ can approach $0$ (from the right), where $\frac 1{\sqrt{t}}\rightarrow +\infty$ . Am I allowed to do this differentiation under the integral sign? I also would like to be pointed to some reference about differentiation under the integral sign, for the Riemann integral. Any help would be very appreciated.","['definite-integrals', 'derivatives', 'real-analysis']"
3701807,Is this function lebesgue integrable or not?,"I'm trying to see if this function is lebesgue integrable. $$\int_0^1 \frac{(-1)^{\lfloor 1/x \rfloor}}{x^2} dx.$$ How can I prove it? I try the following:
Let $f(x)=\frac{(-1)^{\lfloor 1/x \rfloor}}{x^2}$ . \begin{align*}
\int_0^1 |f(x)| dx&=\sum_{n=1}^{\infty} \int_{1/(n+1)}^{1/n} |f(x)| dx\\
&=\sum_{n=1}^{\infty} \int_{1/(n+1)}^{1/n} \frac{1}{x^2} dx\\
&=\sum_{n=1}^{\infty} \left(\frac{-1}{n}+\frac{1}{n+1}\right)<\infty.
\end{align*} Thus $f(x)$ is L.I. I'm wrong?","['integration', 'solution-verification', 'lebesgue-integral', 'real-analysis']"
3701810,Number of ways of arranging 10 tiles in four colors such that any consecutive block of 5 tiles contain all four colors,"This problem is from Purple Comet High school contest, 2016. Ten square tiles are placed in a row, and each can be painted with one of the four colors red (R), yellow (Y), blue (B), and white (W). Find the number of ways this can be done so that each block of five adjacent
tiles contains at least one tile of each color. That is, count the patterns RWBWYRRBWY and
WWBYRWYBWR but not RWBYYBWWRY because the five adjacent tiles colored BYYBW does not
include the color red. It is easy to see that if a particular color to appear in any block of five tiles, there must be at least two tiles of that color and the two tiles must be at one of the following pairs of positions: \begin{align*}
	& 1,6   \\
	& 2,6 \quad 2,7  \\
&	3,6 \quad  3,7 \quad  3,8  \\
&	4,6 \quad  4,7 \quad  4,8 \quad  4,9  \\
&	5,6 \quad  5,7 \quad  5,8 \quad  5,9 \quad  5,10 \\
\end{align*} We need to choose 4 of the above pairs such that no two have the same first coordinate/second coordinate and assign the four colors one each to a pair. The remaining two tiles can be arbitrary color. If we choose four from $(1,6), (2,7), (3,8), (4,9), (5,10)$ , there are 24 ways to map the four colors and the number of colorings is $5 \cdot 24 \cdot\left(\frac{4}{2} + \binom{4}{2} \cdot 2\right) = 1680$ . When we choose four pairs other than the above five, there are 26 ways to choose the four pairs and there are multiple countings in subtle ways: For example, when we choose that pairs $(1,6), (3,7), (4,8), (5,9)$ , the coloring $WWBRYWBRYY$ is counted 4 times: the other three occur from the pairs $((2,6), (3,7), (4,8), (5,9))$ , $((2,6), (3,7), (4,8), (5,9))$ , $((1,6), (3,7), (4,8), (5,10))$ and $((2,6), (3,7), (4,8), (5,10))$ and the colorings $WWBRYWBRYW, WWBRYWBRYB, WWBRYWBRYR$ are counted twice each. I am not able to eliminate all the multiple countings. The answer is 7296.","['combinatorics', 'coloring']"
3701891,Limit Using squeeze theorem,"Find the limit of the following function as $x \rightarrow 0$ $$
\frac{|x|}{\sqrt{\left(x^{4}+4 x^{2}+7\right)}} \sin \left(\frac{1}{3 \sqrt{x}}\right)
$$ $\lim _{x \rightarrow 0} \frac{|x|}{\sqrt{\left(x^{4}+4 x^{2}+77\right)}} \sin \left(\frac{1}{3 \sqrt{x}}\right)$ My approach , applying squeeze theorem, $
-1 \leq \sin \left(\frac{1}{3 \sqrt{x}}\right) \leq 1
$ $-\frac{|x|}{\sqrt{x^{2}+4 x^{2}+7}} \leq \frac{|x|}{\sqrt{x^{4}+4 x^{2}+7}} \sin \left(\frac{1}{\sqrt{3x}}\right) \leq \frac{|x|}{\sqrt{x^{4}+4 x^{2}+7}}$ $\operatorname{Now,}_{\operatorname{limit}_{x \rightarrow 0} \frac{-x}{\sqrt{x^{4}+4 x^{2}+7}}}=\ _{x \rightarrow 0} \frac{x}{\sqrt{x^{4}+4 x^{2}+7}}=0$ Hence answer is zero. Am I correct?","['limits', 'solution-verification']"
3702051,Understanding the Proof of the Hyperplane Separation Theorem,"Am reading Wiki's proof of the Hyperplane Separation Theorem and am having trouble with the last part of the proof. Let me give you the structure of the argument and explain precisely where I have problem. Theorem. Let $A$ and $B$ be two disjoint nonempty convex subsets of $\mathbb{R}^n$ . Then there exist a nonzero vector $v$ and a real number $c$ such that $$ \langle x,v\rangle \geq c,{\text{ and }}\langle y,v\rangle \leq c $$ for all $x \in A$ and $y \in B$ . The proof begins with a Lemma, the proof of which I understand: Lemma. Let $K$ be a nonempty closed convex subset of $\mathbb{R}^n$ . Then there exists a unique vector in $K$ of minimum norm (length). Thus, given disjoint nonempty convex sets $A$ , $B$ we can let $$K=A-B$$ which is nonempty and convex. Hence so is its closure $\bar{K}$ . We can therefore apply the Lemma to obtain a vector $v \in \bar{K}$ of minimum norm. One can then show that (see Wiki's article) $$ \langle z,v\rangle \geq |v|^{2}$$ for all $z  \in K$ or equivalently $\langle x-y,v\rangle \geq |v|^{2}$ for all $x \in A$ and $y \in B$ . If $v$ is nonzero we are done because $$\inf _{x\in A}\langle x,v\rangle \geq |v|^{2}+\sup _{y\in B}\langle y,v\rangle $$ so taking $c=|v|^{2}+\sup _{y\in B}\langle y,v\rangle$ does what is wanted. Now, the last paragraph of the proof deals with the general case (where $v=0$ is possible) by dividing into two cases. Case 1. We assume that the interior of $K$ is nonempty. The article then reads “ The interior can be exhausted by a nested sequence of nonempty compact convex subsets $K_{1}\subset K_{2}\subset K_{3}\subset \cdots$ ”. I suppose it means we can find such a sequence with $K^\circ=\cup_{n \in \mathbb{N}} K_n$ . My first question is: How can I construct such a sequence explicitly? Since $K^\circ$ is nonempty my idea is to let $K_1=\bar{B}(z_0)$ be a closed ball centered at some $z_0\in K^\circ$ with $\bar{B}(z_0) \subset K$ . But I don't know how to define $K_2$ from there... Case 2. The interior of $K$ is empty. The article then reads “The affine set that $K$ spans has dimension less than that of the whole space. Consequently $K$ is contained in some hyperplane $\langle \cdot ,v\rangle =c$ ”. My second question is : How can I show that $\text{span}(K)$ has dimension less than $n$ ? I can show that any subspace of $\mathbb{R}^n$ of dimension less than $n$ is included in a hyperplane of the form $\{ x \in \mathbb{R}^n : \langle x ,v\rangle =0 \}$ for some nonzero vector $v$ . Hence in this second this case I believe we have $c=0$ . Am I correct? Thanks a lot for your help.","['normed-spaces', 'linear-algebra', 'functional-analysis', 'real-analysis']"
3702089,Use a reflexive and transitive closure to transform an antisymmetric and acyclic relation into a partially ordered set.,"The relation $R=\{(x,S_1),(S_1,S_2),(S_2,S_3),(S_3,S_4),(S_4,y)\}$ is antisymmetric and acyclic but not transitive or reflexive. We know that any antisymmetric and acyclic relation can be turned into a partial ordering through the usage of the transitive and reflexive closure. To make $R$ transitive we can utilize the concept the transitive cover: $$R^+=R \cup \{(x,y) : \exists k \in \mathbb{N}, S_1,...,S_k \in S, s.t. (x_1,S_1),..., (x_k,S_k) \in R\}$$ Essentially, we have to introduce all transitive pairs into $R$ thereby making $R$ transitive. After doing that we have: $$R=\{(x,S_1), ,(x,S_2),(x,S_3),(x,S_4),(x,y),\\(S_1,S_2),(S_1,S_3), (S_1,S_4), (S_1,y), \\(S_2,S_3), (S_2,S_4), (S_2,y)\\(S_3,S_4), (S_3,y), \\(S_4,y)\}$$ I can't introduce any more pairs without the relationship becoming symmetric. To make the relation reflexive, I use the idea of the reflexive closure and introduce $(x,x),(S_1,S_1),(S_2,S_2),(S_3,S_3),(S_4,S_4),(y,y)$ into $R$ . In the end I have: $$R=\{(x,x),(x,S_1), ,(x,S_2),(x,S_3),(x,S_4),(x,y),\\(S_1,S_1),(S_1,S_2),(S_1,S_3), (S_1,S_4), (S_1,y), \\(S_2,S_2), (S_2,S_3), (S_2,S_4), (S_2,y)\\(S_3,S_3)(S_3,S_4), (S_3,y), \\(S_4,S_4)(S_4,y) \\ (y,y)\}$$ This relation is reflexive, antisymmetric and transitive thus is a partially ordered set. Is this working out correct, or have I missed something?","['elementary-set-theory', 'order-theory', 'relations', 'discrete-mathematics']"
3702121,When is a line bundle the pullback of another line bundle?,"Let $X$ be a compact Riemann surface, $Y$ a smooth complex variety and $\pi : X \times Y \rightarrow Y$ the projection. Given a line bundle $L$ on $X \times Y$ which restricts to  the trivial bundle on the fibers of $\pi$ , can one say that $L$ is the pull-back of a line bundle on $Y$ ? If not, are there additional conditions that make this true? Thanks!","['complex-geometry', 'algebraic-geometry']"
3702138,"Prove that $\lim_{(x,y) \to (0,0)} \frac{\sin^2 xy}{x^2 + y^2}=0$ without using inequalities","I read a similar question that was solved by using the fact that $|\sin(x)| \leq |x|$ , but I tried a different approach, as I struggle with utilizing inequalities to solve limits of this kind. Please note that my textbook did not ask for the limit to be solved without using inequalities. I attempted to prove this result by first switching to polar coordinates, then applying Hopital's rule as follows: $$\lim_{(x,y) \to (0,0)} \frac{\sin^2 xy}{x^2 + y^2}=\lim_{\rho \to 0} \frac{\sin^2 (\rho^2\sin(\theta)\cos(\theta))}{\rho^2}$$ Now I use cosine duplication formula to rewrite $\sin^2(t)$ $$\lim_{\rho \to 0} \frac{\sin^2 (\rho^2\sin(\theta)\cos(\theta))}{\rho^2}=\lim_{\rho \to 0} \biggl(\frac{1}{2}\biggr)\frac{1-\cos(2\rho^2\sin(\theta)\cos(\theta)}{\rho^2}$$ and now I apply Hopital's rule $$\lim_{\rho \to 0} \biggl(\frac{1}{2}\biggr)\frac{4\rho\sin(\theta)\cos(\theta)\sin(2\rho^2\sin(\theta)\cos(\theta))}{2\rho}=\lim_{\rho \to 0} \sin(\theta)\cos(\theta)\sin(2\rho^2\sin(\theta)\cos(\theta))$$ Now if I'm understanding this correctly, because the argument of the second sine function goes to zero, the result is proven. Have I made any mistakes? Was there a faster or more intuitive approach to solving this problem without using inequalities?","['multivariable-calculus', 'limits', 'calculus']"
3702157,On the complex L'Hospital rule,"Let $f(z)$ and $g(z)$ be two complex functions (defined on a neighborhood of a point $z_0\in\mathbb{C}$ ) such that $f(z_0)=g(z_0)=0$ and $g'(z_0)\neq 0$ . Is it true that $\lim_{z\rightarrow z_0}\frac{f(z)^2}{g(z)^2}=\frac{[f'(z)]^2}{[g'(z)]^2}$ ? If so, can we generalize this result to any integer power $n$ of $\frac{f(z)}{g(z)}$ ? EDIT: Another related question would be as follows: Can we apply the L'Hospital rule consecutively ? That is, suppose that applying the L'Hospital rule each time the limit gives us $\frac{0}{0}$ , so in this case can we continue to apply the L'Hospital rule (in a finite step) ? Do we need any restrictions on the functions $f$ and $g$ ?",['complex-analysis']
3702192,Proving that we can chose 26 lines and 43 points so that every line contains eaxctly 7 points and every point belongs to exactly 4 lines,"The rpoblem consits in proving if we can define such 26 different lines and 43 different points, so that every line contains exactly 7 points and every point passes through 4 lines. The issue for me is trying to translate this problem into graph theory language. I do not exactly understand what am I looking for in terms of graphs.","['graph-theory', 'discrete-mathematics']"
3702223,problem on Cauchy problem,"$y u_x-xu_y=0,u=g $ on $ \Omega $ has a unique solution in neighborhood of $\Omega$ for every differentiable function g: $\Omega \rightarrow R$ if 1. $\Omega =\{(x,0):x>0\}$ 2. $\Omega =\{(x,y):x^2+y^2=1\}$ 3. $\Omega =\{(x,y):x+y=1,x>1\}$ 4. $\Omega =\{(x,y):y=x^2,x>0\}$ What i have tried
 I use  Lagrange's method $$\frac{dx}{y}=\frac{dy}{-x}=\frac{du}{0}$$ $\implies u=c_1,x^2+y^2=c_2$ Solution is of the form $u= \phi(x^2+y^2)$ where $\phi$ has to be match with condition  given . For  option 1 after apply condition $g= \phi (x^2)$ $\implies \phi(x)= g(√x)$ solution becomes $u = g(√x^2+y^2)$ So option 1 looks correct to me for option 2 After apply  condition $g= \phi(1)$ from this i got no solution option 2 looks wrong to me I am stuck at   3rd and 4th option please help me for these and also check my explanation for option 1and 2 . or is there other method to solve such problems","['ordinary-differential-equations', 'cauchy-problem', 'partial-differential-equations', 'partial-derivative', 'derivatives']"
3702259,Is $\int_E \frac{1}{(x^2+y^2)^2}dxdy$ convergent?,"I have to tell whether this integral is convergent: $$\int_E \frac{1}{(x^2+y^2)^2}dxdy$$ where $E=\{0\leq y \leq x^a\} \cap \{x^2+y^2\leq 1\} $ . I'm asked for which $a \geq 0$ the integral converges. How am I supposed to act when I find this kind of integrals? I mean, these domains determined by intersections of a curve with $[0,1]^2$ or with $B_n(0,0)$ . Thanks in advance. EDIT: I suppose I should do it for $x \geq 0$ even if not specified.","['integration', 'improper-integrals', 'real-analysis', 'multivariable-calculus', 'convergence-divergence']"
3702263,Estimate blow-up time.,"How am I supposed to find the blow-up time of this ODE solution? $$y'=e^x + y^2 \qquad y(0)=0$$ The fact that it blows up it's granted by the fact that $y' \geq y^2$ which solution explodes. But how to estimate the time of explosion?
I suppose I should use Gronwall or things like this, but don't actually know. Thanks in advance.","['integration', 'cauchy-problem', 'ordinary-differential-equations', 'real-analysis']"
3702284,"there do not exist intgers $a,b,c,d,$ with $k>1$ such that $(a+bw+cw^2+dw^3)^k=1+w$","let $w=e^{\frac{2\pi\cdot i}{5}}$ be a primitive fifth root of unity,Prove that there do not exist intgers $a,b,c,d,$ with $k>1$ such that $$(a+bw+cw^2+dw^3)^k=1+w$$ I try:let $x=a+bw+cw+dw^3(a,b,c,d\in Z)$ and note that $w+w^{-1}=\dfrac{\sqrt{5}-1}{2}$ and $w^2+w^{-2}=w^3+w^{-3}=-\dfrac{\sqrt{5}+1}{2}$ ,I deduce $$|x|^2=(a^2+b^2+c^2+d^2)+\dfrac{\sqrt{5}-1}{2}(ab+bc+cd)-\dfrac{\sqrt{5}+1}{2}(ac+bd+ad)$$ and $$|1+w|^2=\dfrac{3+\sqrt{5}}{2}$$ so  we need prove that:there not exist $a,b,c,d,k$ with $k>1$ such that $$\left((a^2+b^2+c^2+d^2)+\dfrac{\sqrt{5}-1}{2}(ab+bc+cd)-\dfrac{\sqrt{5}+1}{2}(ac+bd+ad)\right)^k=\dfrac{3+\sqrt{5}}{2}$$ then I can't it,Thank you for you help me!",['number-theory']
3702309,"Solving and interpreting $f(x+y)=f(x)+f(y)+x^2y$ for all $x,y \in \mathbb{R} $.","The question reads,
 Find all differentiable functions $f$ such that $$f(x+y)=f(x)+f(y)+x^2y$$ for all $x,y \in \mathbb{R} $ . The function $f$ also satisfies $$\lim_{x \rightarrow 0}\frac {f(x)}x = 0$$ To solve the problem I wrote the expression for $\frac{df}{dx}$ using first principle and found that $\frac{df}{dx} = x^2.$ (Due to the given conditions.) Using this and calculating $f(0)$ as zero I got the implication that $f(x)$ must be $\frac{x^3}{3}.$ But,
Clearly the calculated $f(x)$ does not satisfy the required condition for the problem. Thinking about where I had committed the mistake, I realized that $f(x+y)=f(x)+f(y)+x^2y$ cannot be true for all real $x,y$ . So how is it that these operations that implied $f(x)=\frac{x^3}{3}$ went wrong? And why is it that while doing these operations I could not 'see' that the conditions cannot be satisfied for all real $x$ ? EDIT:Reading the comments, I want to make the clarification that I realise the fact that there can not be any $ f(x) $ that satisfies these conditions using a different method. However I fail to understand why the method elaborated in the question does not reflect this fact to me??","['functional-equations', 'calculus', 'functions', 'intuition']"
3702380,Solve this differential equation $x^2y''-5xy'+6y=0$,"Solve this equation $$
\begin{cases}
x^2y''-5xy'+6y=0 \\
y(-1)=3 \\
y'(-1)=2
\end{cases}
$$ I got $$y=c_1x^{3+\sqrt3}+c_2x^{3-\sqrt3}$$ I have three little questions. Could I solve the problem by substituting $(-1)^{\sqrt3}=\cos((\sqrt 3) \pi)+i\sin((\sqrt 3)\pi)$ ? I need to substitute $t=-x$ ? If i have to use 2. , isn't the problem wrong because the problem itself contains $y(-1)=3$ ?",['ordinary-differential-equations']
3702411,Find the value of function with given conditions,"Let $f(x)$ be a fifth degree polynomial with leading coefficient unity. If $f(1)=5, f(2)=4, f(3)=3, f(4)=2 , f(5)=1$ find $f(6)$ I know I can solve this by assuming a polynomial equation and then finding the coefficients of every term and finding the value of $f(6)$ but I wanted to know if there is any other method of solving this problem. Any hints to solve this kind of problem is much appreciated.","['functions', 'polynomials']"
3702439,Is the Klein bottle a quotient of a $\mathbb{Z}\times\mathbb{Z}$-action on the plane?,"One of the basic examples of a group action on a topological space is the $\mathbb{Z}\times\mathbb{Z}-$ action on $\mathbb{R}^2$ whose quotient is a torus. There is also an example of a $G-$ action on $\mathbb{R}^2$ whose quotient is a Klein bottle, but $G\neq\mathbb{Z}\times\mathbb{Z}$ , being instead the fundamental group of the Klein bottle. My question is: is there a $\mathbb{Z}\times\mathbb{Z}-$ action on $\mathbb{R}^2$ whose quotient is a Klein bottle? I understand that, if there is such an action, it can't be properly discontinuous, otherwise the Klein bottle would have fundamental group $\mathbb{Z}\times\mathbb{Z}$ .","['general-topology', 'group-actions', 'klein-bottle', 'algebraic-topology']"
3702472,Unconditional convergence of a sum of elements in a complete Hausdorff topological ring.,"I'm not that familiar with theoretical math in general (I studied engineering), but I recently ended up down a theoretical rabbit hole that led me to the following question: Is there some type of well known property (e.g. locally compact, locally connected, regular) of a complete, Hausdorff topological ring $R$ that guarantees the following property: Let $\sum_{i=1}^{\infty} r_i$ unconditionally converge in $R$ , where $r_i \in R$ . Given any open set $S$ containing $0_R$ (the additive identity of the ring) there exists an open set $S'$ containing $0_R$ such that, given any finite subset $F$ of $S'$ and any sequence $f_i \in F$ , $\sum_{i=1}^{\infty} f_i r_i$ is in $S$ . This seems to be true if $R$ equals the real numbers with the usual topology, which I think I've proven: Let $r = \sum_{i=1}^{\infty} |r_i|$ (we know a series of real numbers converges absolutely if it converges unconditionally) and choose $S$ to be the open ball of radius $\epsilon > 0$ centered at the origin. If $r=0$ , any choice of an open set $S'$ will do, so we'll move on to the harder case. If $r\ne0$ , then let $S'$ be the open ball of radius $\frac{\epsilon}{r}$ . Thus for any elements $f_i \in S'$ , $|f_i| < \frac{\epsilon}{r}$ . This leads to the conclusion that $|\sum_{i=1}^{\infty} f_i r_i| \le \sum_{i=1}^{\infty} |f_i r_i| = \sum_{i=1}^{\infty} |f_i||r_i| < \sum_{i=1}^{\infty} \frac{\epsilon}{r}|r_i| =\frac{\epsilon}{r} \sum_{i=1}^{\infty} |r_i| = \frac{\epsilon}{r}r = \epsilon$ , assuming $|\sum_{i=1}^{\infty} f_i r_i|$ converges in the first place. In our case, we know the sum converges because, by assumption, the $f_i$ come from a finite set and $\sum_{i=1}^{\infty}r_i$ converges unconditionally. It seems like the same would apply to the ring of complex numbers as well. But when does this property apply to complete Hausdorff topological rings in general? (Just a note: it turns out that in a complete Hausdorff abelian topological group, for any unconditionally convergent series, the series' subseries also converge, as stated in the section ""Unconditionally convergent series"" at https://en.wikipedia.org/wiki/Series_(mathematics) . Thus as $F$ is finite, unless I am making a mistake, $\sum_{i=1}^{\infty} f_i r_i$ also converges. The question is just if it converges in $S$ .)","['topological-rings', 'topological-groups', 'sequences-and-series', 'general-topology', 'convergence-divergence']"
3702526,Why is electric potential function in free space infinitely differentiable?,"Electric potential function in free space of a continuous charge distribution $\rho'$ distributed over volume $V' \subset \mathbb{R}^3$ is denoted by: $\psi (x,y,z): \mathbb{R}^3 \setminus{V'} \to \mathbb{R}$ and is defined as: $$\psi (x,y,z)=\int_{V'} \dfrac{\rho'}{R}\ dV'$$ where $R$ is distance between point $(x,y,z)$ to a point $ P \in V'$ I know electric potential function in free space is differentiable once but I don't see why it is infinitely differentiable . Please explain why it is so. EDIT Theorem: PD of $\dfrac{1}{R}$ of all orders are differentiable in domain $\mathbb{R^3} \setminus (R=0)$ Proof: Let $P_k$ denote polynomials of degree $k$ in $x,y,z,x',y',z'$ $$\dfrac{\partial\frac{1}{R}}{\partial x}=-\dfrac{x-x'}{R^3};\
\dfrac{\partial\frac{1}{R}}{\partial y}=-\dfrac{y-y'}{R^3};\
\dfrac{\partial\frac{1}{R}}{\partial z}=-\dfrac{z-z'}{R^3}$$ Therefore: PD of $\dfrac{1}{R}$ of $1^{st}$ order = $\dfrac{P_1}{R^{(2 \times 1) + 1}}$ \begin{align}
\text{PD of $\dfrac{1}{R}$ of $k^{th}$ order} &= \dfrac{P_k}{R^{2k + 1}}\\
\implies \text{PD of $\dfrac{1}{R}$ of $(k+1)^{th}$ order} &= \dfrac{\partial}{\partial x} [\text{PD of $k^{th}$ order} ]\\
&= \dfrac{\partial \left[    \dfrac{P_k}{R^{2k + 1}}    \right]}{\partial x}\\
&= \dfrac{(P_k)'_x}{R^{2k+1}} - (2k+1) \dfrac{P_k}{R^{2k+2}} \dfrac{x-x'}{R}\\
&= \dfrac{(P_k)'_x\ [(x-x')^2+(y-y')^2+(z-z')^2]}{R^{2k+3}} - \dfrac{(2k+1)\ P_k\ (x-x')}{R^{2k+3}}\\
&=\dfrac{P_{k+1}}{R^{2(k+1)+1}}\\
\end{align} Thus by induction: PD of $\dfrac{1}{R}$ of $n^{th}$ order $=\dfrac{P_k}{R^{2n+1}}$ $P_k$ , being a polynomial function is continuous in $x,y,z$ in domain $\mathbb{R^3}$ $\dfrac{1}{R^{2n+1}}$ , being a radial function is continuous in $x,y,z$ in domain $\mathbb{R^3} \setminus (R=0)$ Thus: PD of $\dfrac{1}{R}$ of $n^{th}$ order is continuous in $x,y,z$ in domain $\mathbb{R^3} \setminus (R=0)$ PD of $\dfrac{1}{R}$ of all orders are continuous in $x,y,z$ in domain $\mathbb{R^3} \setminus (R=0)$ PD of $\dfrac{1}{R}$ of all orders are differentiable in $x,y,z$ in domain $\mathbb{R^3} \setminus (R=0)$ Now how shall we prove PD if $\psi$ of all orders are differentiable in $x,y,z$ in domain $\mathbb{R^3} \setminus {V'}$ ?","['electromagnetism', 'continuity', 'infinity', 'potential-theory', 'derivatives']"
3702572,Is my six sided dice weighted?,"I was playing a game with my son, and it seemed that we rolled two or five about half the time. He was wondering if the die was weighted. So I re-rolled it a bunch of times and jotted down the results: 1: 4 times
2: 12 times
3: 13 times
4: 4 times
5: 13 times
6: 8 times I realise that this is a small sample (only 54 datapoints), but to my very untrained eye, the 1 and 4 seem very low. I was wondering how I would go about determining the probability that the die is fair. I was expecting about 9 each. I did a ChiTest in excel, which I am not sure how to calculate manually and got 0.069 Does this mean that there's a 6.9% chance that the die is unweighted, and therefore a 93.1% chance it's weighted, or have I misinterpreted the results entirely?","['statistics', 'dice', 'probability', 'hypothesis-testing']"
3702599,Doubt about Q function,"Hi have a doubt about the Q function; I have this problem: $Z\sim N(20; 500)$ and I have to find $P(Z>0)$ , by Q function I have: $Q(\frac{0-20}{\sqrt{500}})=Q(-0.894)$ . Now I have to find $Q(-0.894)$ or $1-Q(0.894)$ on the table? Thank you","['calculus', 'statistics', 'probability']"
3702619,Complex derivative of Hadamard product inside Frobenius norm,"I'm trying to find the complex derivative of $$||R - P \circ \gamma \gamma ^H||_F ^2$$ . with respect to $\gamma$ . I saw the post regarding the real counterpart of the same question here . However, when I tried applying similar principles given there $-2(P\circ M+P^T\circ M^T)\gamma$ ,  (where $M=R - P \circ \gamma \gamma^T$ ), it didn't work. Here $||.||_F$ is the Frobenius norm and $\circ$ is the Hadamard product.","['matrices', 'matrix-calculus', 'derivatives', 'complex-numbers']"
3702680,What does the Kalman filter generally converge to? And why?,"So, i'm guessing whomever shows up here, knows what the Kalman filter is. It's quite an extensive model to type out, so here is an explanation from MIT (see ch. 11.5) We have a feeling that it converges to the observations, but we don't know how to show this. Can anyone help us out?","['statistics', 'kalman-filter', 'control-theory', 'numerical-methods', 'convergence-divergence']"
3702699,Why does this function ${f(x)} = {x^2}$ produce curved shape line on the graph?,"Guys, I'm learning algebra. And I'm very curious about this function's graph. Could you please tell me why the SQUARING FUNCTION ${f(x)} = {x^2}$ or ${g(x)} = {x^2}$ produce curved shape (Right side graph: Graph - Curved Line) line instead of straight line like left side graph (Graph - Straight Line) in the picture? On the left side I have connected all the points with small small straight lines. But, it is not correct according to book. There is no point discussed about the curved shape graph. Please enlighten me with your simple and expert opinion. Thanks in advance!","['functions', 'graphing-functions']"
3702756,Find the volume between the surface $x^2+y^2+z=1$ and $ z=x^2+(y-1)^2$,I'm trying to find the volume between the surface $x^2+y^2+z=1$ and $ z=x^2+(y-1)^2$ but nothing works for me. I made the plot and it looks like this: How could you start? Any recommendation?,"['integration', 'multivariable-calculus', 'definite-integrals', 'volume']"
3702776,"Does limit of $\tan(n !)-n!,n\to \infty$ exists ?And what is its upper bound?","I have tried many times to show if $\tan(n !)-n!$ exist or not but I can't , I have used this idea $n! = e(-1)^{n+1}/(n+1) + O(1/n^2) (\mod \mathbb Z)$ implies that $\tan( n!)-n!= e((-1)^{n+1}/(n+1) + O(1/n^2)) -1)(\mod \mathbb Z)$ to get such bounds of that sequence but it doesn' seems clear to me whethere it is converge or diverge , Then my question here is :Does limit of $\tan(n !)-n!$ exists ?And what is its upper bound? Wolfram alpha dosn't give any result only series asymptotic at infty as shown here using mathematica code  for $n=400$ , $\tan(n!)-n!$ I have got the below plot and this is the code , Block[{$MaxExtraPrecision = 800},
  lst = Table[Tan[n!] - n!, {n, 0, 400}];
  ListPlot[N[Accumulate[lst], 200], PlotRange -> All]
  ] Edit: Probabliy from density $n ! \bmod \mathbb{Z}$ the sequence would be diverge we may add this partial question :Does it will be diverge to $-\infty$ or just diverge ? Related question: https://mathoverflow.net/q/361945/51189","['trigonometry', 'upper-lower-bounds', 'sequences-and-series']"
3702811,Symmetric Matrix over a finite field of Characteristic 2,"Let $M$ be a $n$ by $n$ symmetric matrix over a finite field of Characteristic 2. Suppose that the entries in the diagonal of $M$ are all zero, and $n$ is an odd number. I found that the rank of $M$ is at most $n-1$ . Is my observation true? How do we prove it? Thanks","['matrices', 'finite-fields', 'linear-algebra', 'matrix-rank']"
3702812,How to solve this relatively simple non-linear ODE?,"I'm having troubles in simplifying a differential equation to find its solutions.  Consider this ODE: $$
    \frac{1}{r} \, \frac{d}{dr} \Bigl( \frac{r}{B} \, \frac{d B}{dr} \Bigr) = k \, B^2, \tag{1}
$$ where $k$ is just a real constant and $B(r)$ is the function to be found.  I already know one solution of this equation (it was found by guessing, trial and errors): $$
B(r) = \frac{\beta}{1 + \lambda r^2}, \tag{2}
$$ where $\beta$ and $\lambda = k \beta^2 / 4$ are arbitrary constants.  My goal is to transform (1) into an integral so I could find back the solution (2).  I'm yet unable to find a change of variable that makes that equation solvable analyticaly.  I tried $u = 1/B$ , and $B = e^{\phi(r)}$ (and few other trials).  Any idea how to solve (1)?","['functions', 'solution-verification', 'ordinary-differential-equations']"
3702841,Questions on the Kantorovich-Rubinstein duality,"Let $\mu,\nu$ be probability measures on a metric space $(E,d)$ endowed with the Borel $\sigma$ -algebra and $$\operatorname W_d(\mu,\nu):=\inf_{\gamma\in\mathcal C(\mu,\:\nu)}\int d\:{\rm d}\gamma,$$ where $\mathcal C(\mu,\nu)$ denotes the set of couplings of $\mu$ and $\nu$ . The Kantorovich-Rubinstein duality states that $$\operatorname W_d(\mu,\nu)=\sup_{\substack{f\::\:E\:\to\:\mathbb R\\|f|_{\operatorname{Lip}(d)}\:\le\:1}}\int f\:{\rm d}(\mu-\nu)\tag1,$$ where $$|f|_{\operatorname{Lip}(d)}:=\frac{|f(x)-f(y)|}{d(x,y)}\;\;\;\text{for }f:E\to\mathbb R.$$ The "" $\ge$ "" part is almost trivial. Is there an elegant way to prove the other inequality? In any case, I've got some questions on the statement. Does it matter whether we state it in the given form or if we replace the integral on the right-hand side by its absolute value? If $f:E\to\mathbb R$ satisfies $|f|_{\operatorname{Lip}(d)}<\infty$ , then $f$ is clearly continuous and hence Borel measurable. But in order for the integral on the right-hand side of $(1)$ to be well-defined, it needs to be integrable (or at least quasi-integrable) as well. Is this the case? Clearly, by the reverse triangle inequality, $$\int|f|\:{\rm d}(\mu-\nu)\le|f|_{\operatorname{Lip}(d)}\int d\:{\rm d}\gamma\tag2,$$ where $\gamma$ is any coupling of $\mu$ and $\nu$ . So, if we could show that there exists a coupling such that the integral on the right-hand side of $(2)$ is finite, we could conclude that $f$ is integrable. Is this the case? In any case, is $(1)$ equivalent to the same statement with requiring $f$ to be bounded as well?","['statistics', 'coupling', 'lipschitz-functions', 'markov-process', 'probability-theory']"
3702962,Integral Curves of Vector Fields with Zero Divergence or Zero Curl,"Say we've got some vector field which at every point indicates the instantaneous velocity of a particle moving through that point. I'm trying to gain some intuition for what the possible trajectories for particles would look like in the cases that this vector field has zero divergence, zero curl, or both... There's GOT to be something special about the trajectories in such vector fields... I'm still having trouble wrapping my head around divergence and curl...although, I think intuitively understanding possible trajectories will help. As for my background...I have not taken differential equations, and am just about done with an introductory course on multi-variable calculus. Thanks again! Edit: After receiving some answers and hints, I'd like to write out some of my thoughts... Say we have the vector-field $\vec{F} = (2x,-2y)$ . This vector-field has both zero divergence and zero curl. There are many possible ways to interpret such a vector-field: ie, an acceleration, a force...etc...but, lets focus on these two interpretations: First, lets consider it the gradient of a function. In this case, the function would be $f(x,y)=x^2-y^2$ , and thus $\nabla(f)=\vec{F}$ . As I understand it, the fact that $\vec{F}$ has no curl means that it can be the gradient of a function in the first place, because a line-integral in a closed circle is zero. As for what it means for the divergence to be zero everywhere...well, the divergence of the gradient is the Laplacian of the original function. It means that the function is harmonic, so that at each point, the ""bending"" is equal in all directions. If this function represented some stretched surface, no point would have any reason to bend, because the force on any point would cancel out from the points around it. Those are both beautiful and intuitive results...but, that wasn't what my question was driving it. I want to interpret $\vec{F}$ as a velocity-field . That is, at each point, $2x=\frac{dx}{dt}$ and $2y=\frac{dy}{dt}$ . In that case, integral curves (flow-lines) starting from some point $(x_0,y_0)$ would look like: $$(x_0e^{2t}, y_0e^{-2t})$$ And as for those flow-lines...I have absolutely no intuition what's special about them, coming from the fact that the divergence is zero, or that the curl is zero. These are what I wish to understand! Thanks!","['ordinary-differential-equations', 'vector-fields', 'multivariable-calculus', 'intuition', 'vector-analysis']"
3702983,Apply Pigeonhole Principle to pick numbers such that at least two of them have a digit in common,"How many integers from 100 through 999 must you pick in order to be
  sure that at least two of them have a digit in common? (For example,
  256 and 530 have the common digit 5.) In the worst case I can pick 111, 222, 333, 444, 555, 666, 777, 888, 999. Whatever next integer I choose will have a common digit with one of those above, therefore the answer is 10. But how to apply The Pigeonhole Principle? let $S=[100, 999]$ let $S'\subseteq S, |S'|>9$ (because I know that the answer is 10). $S'$ is the integers I pick from $S$ at least two of which have a digit in common. let $f: S' \rightarrow T$ where $T$ is some set, $|T|=9$ (again, because I know that the answer is 10). If I knew the definition of $f$ and $T$ I would proceed as follows: Let $k\in Z^+$ , by the generalised Pigeonhole Principle $k<\frac{|S'|}{|T|} \rightarrow \exists t\in T(|f^{-1}(t)|=k+1)$ , $f^{-1}(t)$ is the inverse image of $t$ The exercise says at least two numbers picked from $S$ to have a digit in common, therefore I want $k=1$ : $1<\frac{|S'|}{9}, 9<|S'|$ $\therefore |S'|\geq 10$ in order to guarantee that at least 2 integers in $S'$ have a digit in common. I'm struggling to find the set $T$ and the function $f$ . What could they be?","['pigeonhole-principle', 'functions', 'combinatorics', 'discrete-mathematics']"
3703033,"Grothendieck group ""commutes"" with direct sum","The Grothendieck completion group of a commutative monoid $M$ is the unique (up to isomorphism) pair $\langle \mathcal{G}(M), i_M\rangle$ , where $\mathcal{G}(M)$ is an abelian group and $i_M\colon M\to\mathcal{G}(M)$ is a monoid homomorphism, satisfying the universal property: for every abelian group $G$ and monoid homomorphism $f\colon M\to G$ there exists a unique $\varphi\colon\mathcal{G}(M)\to G$ such that $f = \varphi\circ i_M$ . Let $M$ and $N$ be commutative monoids. It's easily seen that $M\oplus N$ is a commutative monoid with component-wise operation. Question: Is it true that $\mathcal{G}(M\oplus N) \cong \mathcal{G}(M)\oplus\mathcal{G}(N)$ ? The universal property applied to the monoid homomorphism $i_{M}\oplus i_{N}\colon M\oplus N\to\mathcal{G}(M)\oplus\mathcal{G}(N)$ gives a group homomorphism $\varphi\colon\mathcal{G}(M\oplus N)\to\mathcal{G}(M)\oplus\mathcal{G}(N)$ such that $i_{M}\oplus i_{N} = \varphi\circ i_{M\oplus N}$ and I was trying to prove that $\varphi$ is the desired isomorphism, without success. Is the answer to the question affirmative? If so, is this the correct approach? Any hints would be appreciated. Thanks in advance. EDIT: Also, is it true if we replace $M\oplus N$ by $\bigoplus_{\alpha} M_{\alpha}$ ?","['group-isomorphism', 'monoid', 'abstract-algebra', 'group-theory', 'abelian-groups']"
3703039,Extracting a smaller Markov chain from a larger Markov chain,"I am not very familiar with Markov chains, hence the probably ill titled questions. If we have 5 random variables $X, Y, Z, W$ and they form a Markov chain such that $$X \rightarrow Y \rightarrow Z \rightarrow W \rightarrow P$$ Is also the case that $$X \rightarrow Y \rightarrow P$$ or $$X \rightarrow Y \rightarrow W $$ Intuitively I would assume it is true because no information about $X$ can be gained as we move along the chain, thus it is okay to remove a link. Secondly if i recall correctly then if $Z = f(Y)$ then $X \rightarrow Y \rightarrow Z$ is a Markov chain. So in my example $f$ is just a composite function. This is obviously a weak understanding at best, so any help is appreciated. Edit: My understanding is that 3 random variables $X, Y, Z$ form a markov chain if $X$ and $Z$ and conditionally independent given $Y$ . So $$X \rightarrow Y \rightarrow Z \iff p(x, y, z)=p(x) p(y | x) p(z | y)$$","['stochastic-processes', 'statistics', 'markov-chains', 'probability']"
3703041,Question on the use of the Markov Kernel for conditional probability,"We define a Markov kernel: Let $(\Omega_{1},\mathcal{A}_{1})$ and $(\Omega_{2},\mathcal{A}_{2})$ be some measurable spaces. A map $K$ where $K : \Omega_{1}\times \mathcal{A}_{2}\to [0,\infty]$ is called a Markov kernel if, $1.$ For all $A\in \mathcal{A}_{2}$ , the map $$K(\cdot,A):\Omega_{1}\to [0,\infty],\; \omega_{1}\mapsto K(\omega_{1},A)$$ is a $\mathcal{A}_{1}$ measurable. $2.$ For all $\omega_{1} \in \Omega_{1}$ , the map $$K(\omega,\cdot):  \mathcal{A}_{2} \to [0,\infty], \; A \mapsto K(\omega,A)$$ is a probability measure. In our lecture, the Markov kernel was introduced in order to find a ""satisfying"" expression for the conditional probability $P(A\lvert \mathcal{F})$ where $\mathcal{F}$ is some sub- $\sigma$ -field in a probability space $(\Omega,\mathcal{A},P)$ . I have to truly understand what ""satisfying"" means in this sense. The reason given in the lecture is that viewing the conditional probability operator given $\mathcal{F}$ as an operator on $\Omega\times \mathcal{A}$ , a continuous model can have uncountably many events $A \in \mathcal{A}$ and it is not clear whether the choice of null-sets remains plaubsible in order to obtain a probability measure in the event argument, since an uncountable union of null sets need not be a null set. My issue: I do not understand the problem here. Surely, we have the exact same issue in the unconditional case: the uncountable union of null sets need not be a null set. What am I misunderstanding?","['conditional-expectation', 'stochastic-processes', 'probability-theory', 'markov-chains']"
3703102,Find a solution to the congruences $y \equiv m_1x + b_1 \pmod p$ and $y \equiv m_2x + b_2 \pmod p$,"Problem Find a solution to the congruences: $$y \equiv m_1x + b_1 \pmod p$$ $$y \equiv m_2x + b_2 \pmod p$$ when $m_1 \not\equiv m_2 \pmod p$ . Solution attempt From the given congruences for $y$ , it follows that: $$m_1x + b_1 \equiv m_2x + b_2 \pmod p$$ Adding $-m_2x-b_1$ to both sides: $$m_1x - m_2x \equiv b_2 - b_1 \pmod p$$ $$(m_1 - m_2)x \equiv b_2 - b_1 \pmod p$$ Since $m_1 \not\equiv m_2 \pmod p$ , then $m_1 - m_2 \not\equiv 0 \pmod p$ . Since $p$ is a prime, this implies that $\mathrm{gcd}(m_1 - m_2, p) = 1$ . Therefore, the multiplicative inverse of $m_1 - m_2$ modulo $p$ exists. Call it $r$ . Multiplying both sides of the above congruence by $r$ : $$x \equiv (b_2 - b_1) r \pmod p$$ $y$ can then be found by substituting the above expression for $x$ in one of the original congruences. Substituting it in $y \equiv m_1x + b_1 \pmod p$ : $$y \equiv m_1((b_2 - b_1) r) + b_1 \pmod p$$ The value of $r$ can be found as follows: since $\mathrm{gcd}(m_1 - m_2, p) = 1$ , then, by Bézout's lemma, $a(m_1 - m_2) + bp = 1$ for some $a$ , $b$ (the values of $a$ and $b$ can be calculated using the extended Euclidean algorithm). Then, it follows that: $$a(m_1 - m_2) + bp \equiv 1 \pmod p$$ $$a(m_1 - m_2) \equiv 1 \pmod p$$ The above means that $a$ (or any other integer that is congruent to $a$ modulo $p$ ) is an inverse modulo $p$ of $m_1 - m_2$ . So, let $r = a$ , and the expressions for $x$ and $y$ become: $$x \equiv (b_2 - b_1) a \pmod p$$ $$y \equiv m_1(b_2 - b_1) a + b_1 \pmod p$$ Could someone verify if my attempt is correct? Thank you.","['elementary-number-theory', 'solution-verification', 'discrete-mathematics']"
3703196,Definition of Poisson Bracket,"Context : Let $f,g :T^*M\rightarrow \mathbb{R}$ , the Poisson Bracket was defined classically as $$\{f,g\}=\sum\limits_{i=1}^n\frac{\partial f}{\partial q^i}\frac{\partial g}{\partial p_i}-\frac{\partial f}{\partial p_i}\frac{\partial g}{\partial q^i}$$ But this definition depends of a choice of canonical coordinates $(q,p)$ and that is my problem: Question : How can I prove this definition is actually well-defined? Thanks in advance for any help or any recommendation to read about.","['classical-mechanics', 'smooth-manifolds', 'reference-request', 'poisson-geometry', 'differential-geometry']"
3703210,Can you have set theories with modal logical operators?,"It's fairly easy to conjure a set theory with a modal logic in it. I'm wondering whether the construction is incoherent or useless. I'm also curious what ways of extending set theory with a modal logic already exist. Let $\varepsilon$ denote the empty set. There are many questions on this site that ask about what ordered pairs are and the answer usually boils down to this is what a Kuratowski pair is, although there are alternatives . I think that the standard way to express the above statement is to use model theory. Suppose we are working in ZFC. My understanding of model theory is a bit weak, but I think this amounts to taking the signature of ZFC and its theory, extending the signature with an ordered pair function symbol, and extending the theory with the characteristic property of ordered pairs. We then show that original ZFC with an ordered pair defined as a Kuratowski pair is a model of our extended signature + theory. I'm not exactly sure how to deal with a model whose domain is a proper class rather than a set, but I think the above approach works. I'm wondering whether it makes sense to instead consider an extended set theory that uses modal logic and is thus capable of hosting non-primitive symbols itself . For the sake of this example, I'm considering a modal set theory that is like an ordinary set theory such as ZFC, but all of the usual set axioms and axiom schemas of set theory are necessary truths . The meta-statement a Kuratowski pair is a possible implementation of an ordered pair in some set theory has an obvious translation into modal logic, shown below. The particular modal logic I am using here is S5 , but I'm not sure what the consequences are of using different modal logics. Assuming we do some work off to the side to define the notation $(\cdot,\cdot)$ and assert that it is a legal term if its two arguments are terms, we can express the characteristic property of ordered pairs as follows (10). $$ \Box \bigg( (a, b) = (b, a) \iff a = b \bigg) \tag{10} $$ We can assert that we are choosing the Kuratowski pair in this world by not using a modal operator at all (11). $$ ( a, b ) = \{\{a\}, \{a, b\}\} \tag{11} $$ We can assert that a Wiener pair also works $$ \Diamond \bigg( (a, b) = \{ \{\{a\}, \varepsilon\} , \{\{b\}\}\} \bigg) \tag{12} $$ I think the main thing we've bought by adding modal operators to our logic is the ability to make things that would have been metatheorems into theorems. For instance if we wanted to express the fact that an ordered pair can't be associative, we can express it as follows $$ \lnot \Diamond \bigg( (a, (b, c)) = ((a, b), c) \bigg) $$","['elementary-set-theory', 'modal-logic']"
3703319,Should I be using normpdf to answer this question?,"If the mean of a sample is 30, and the standard deviation is 10, then how would I evaluate a question that asks me how likely it is that I would obtain a value of $34$ ? Also the size of the sample is 20. I'm confused about this: Would I calculate $P(X=34)=P(Z=\frac{34-30}{8})=P(Z=0.5)$ ? From this I'm confused because a cdf would give me $P(X\leq x )$ and I'm unclear on if I should use normpdf on a TI-84 calculator instead of normcdf. I'm an AP Statistics student and my teacher says never to use normpdf for this class. My second approach would be to see that $Z=\frac{34-30}{4} = 0.5$ so a value of 34 is only half a standard deviation above the mean. This would mean it's pretty likely. Also, does the sample size matter in this situation?","['statistics', 'normal-distribution']"
3703483,Calculate $\iiint_V dx dy dz$,"Problem : Calculate $$\iiint_V dx dy dz$$ where $V$ is the domain bounded by the surface $(x^2+y^2+z^2)^2=a^2xy$ . My Solution :
Make the following substitution: $$\begin{cases}
x = r\sin\varphi\cos\theta,\\
y = r\sin\varphi\sin\theta,\\
z = r\cos\varphi
\end{cases}$$ The limit of $V$ is equal to $r^2=\frac{a^2}{2}\sin^2 \varphi \sin 2\theta$ . So the integration is equal to $$\frac{2}{3}\int_0^{\frac{\pi}{2}}d \theta\int_{0}^{\pi}r^3\sin\varphi \,d\varphi =\frac{\sqrt{2}a^3}{6}\int_0^{\frac{\pi}{2}}d \theta\int_{0}^{\pi}\sin^4\varphi (\sin 2\theta)^{\frac{3}{2}}\,d\varphi $$ . But I can't figure out how to calculate $\int (\sin 2\theta)^{\frac{3}{2}}$ . I'm wondering if there's any convenient way to solve this question. I'll be grateful if there's any help. :)","['multivariable-calculus', 'multiple-integral', 'definite-integrals']"
3703510,Directional derivative along the intersection of two surfaces,"How can i find the intersection curve between these two surfaces $$
\left\{
\begin{array}{cc}
 2x^2 + 2y^2 − z^2 &= 50\\
 x^2 + y^2 -z^2 &= 0
\end{array}
\right.
$$ I need it to find the directional derivative of $f(x, y, z) = x^2 + y^2 − z^2$ , with this point $(3, 4, 5)$ and along the intersection curve mentioned above. I know how to get the gradient, I just don't know how to aproach finding that intersection.","['multivariable-calculus', 'derivatives']"
