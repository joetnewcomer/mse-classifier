question_id,title,body,tags
3717989,"Relating ""change of coordinates"" to change of basis - how to find change in representations of vectors","I've been studying about change of basis in $\mathbb{R}^2$ (could be $\mathbb{R}^n$ but sticking to $\mathbb{R}^2$ for simplicity) - how it affects representations of vectors, metrics and endomorphisms. Let's say I start with a basis $\mathcal{B}=\{\vec u_1, \vec u_2\}$ , and want to switch to a different basis $\mathcal{A}=\{\vec v_1,\vec v_2\}$ . That is, if earlier we were expressing the components of some vector $\vec w$ in the $\mathcal{B}$ basis, we now want to express its components in the $\mathcal{A}$ basis). For this I can use a change of basis matrix $M_{\mathcal{A}\leftarrow\mathcal{B}}$ whose columns are the representations of $\vec u_1,\vec u_2$ in the $\mathcal{A}$ basis . And then I can relate the representations of $\vec w$ in the two bases by: $$[\vec w]_{\mathcal{A}} = M_{\mathcal{A}\leftarrow\mathcal{B}}[\vec w]_{\mathcal{B}}$$ If I have a linear transformation $T$ of the vector space to itself (endomorphism), and if I know its representation in the old basis, then I can get its representation in the new basis like this (let's say $T$ maps $\vec w_1$ to $\vec w_2$ and the change of basis matrix is invertible ): $$[\vec w_2]_{\mathcal{A}}=[T]_{\mathcal{A}}[\vec w_1]_{\mathcal{A}}
\\\implies M_{\mathcal{B}\leftarrow\mathcal{A}}[\vec w_2]_{\mathcal{A}}=M_{\mathcal{B}\leftarrow\mathcal{A}}[T]_{\mathcal{A}}M_{\mathcal{A}\leftarrow\mathcal{B}}M_{\mathcal{B}\leftarrow\mathcal{A}}[\vec w_1]_{\mathcal{A}}
\\\implies [\vec w_2]_{\mathcal{B}}=(M_{\mathcal{B}\leftarrow\mathcal{A}}[T]_{\mathcal{A}}M_{\mathcal{A}\leftarrow\mathcal{B}})[\vec w_1]_{\mathcal{B}}
\\\implies [T]_{\mathcal{B}} = M_{\mathcal{B}\leftarrow\mathcal{A}}[T]_{\mathcal{A}}M_{\mathcal{A}\leftarrow\mathcal{B}}$$ Finally, if $\eta$ is the metric, then invariance of inner product gives us: $$[\vec w_1]^T_{\mathcal{A}}[\eta]_{\mathcal{A}}[\vec w_2]_{\mathcal{A}}=
[\vec w_1]^T_{\mathcal{B}}[\eta]_{\mathcal{B}}[\vec w_2]_{\mathcal{B}}
\\=[\vec w_1]^T_{\mathcal{A}}M^T_{\mathcal{B}\leftarrow\mathcal{A}}[\eta]_{\mathcal{B}}M_{\mathcal{B}\leftarrow\mathcal{A}}[\vec w_2]_{\mathcal{A}}
\\\implies [\eta]_{\mathcal{A}}=M^T_{\mathcal{B}\leftarrow\mathcal{A}}[\eta]_{\mathcal{B}}M_{\mathcal{B}\leftarrow\mathcal{A}}$$ So far so good. I can use the above to find representations in the new coordinate system in the case of some simple coordinate system changes - e.g. if I shift the coordinate system in some direction or if I rotate it by some angle $\phi$ . But I'm at a loss on how to extend this same formalism (of finding representations in the new coordinate system), if we change from Cartesian to polar coordinates. If I try to form a change of basis matrix (assuming that the new system is $(r,\phi)$ ), I get $[1,0]^T$ and $[1,\pi/2]^T$ as the columns of my CoB matrix, which gives wrong results when I try to use it to get components of a vector in the polar coordinate system. Next thing I thought was, am I fundamentally confusing a change of coordinates with a change of basis? For that, I tested the above procedure of finding vector component transformation in case of rescaling/rotating only one of the axes - even in that scenario, the above procedure works. This leads me to suspect that the above formulas for transformation of components between bases hold in general for any rectilinear coordinate systems - whether orthogonal or not. What do I do in case of a Cartesian to polar coordinate system change to find representations of vectors, metric and linear transformations?",['linear-algebra']
3717990,Do functions with composition form a ring?,"Functions with composition form a monoid, and injective functions with composition form a group. Is there in some sense a natural or useful definition for ""addition"" that would enable formation of a ring? If not, is there a sensible subset of functions where this is possible?","['universal-algebra', 'ring-theory', 'functions']"
3718040,Bound length of a curve in a ball,"Let $E$ be a $\mathbb R$ -Banach space, $v:E\to[1,\infty)$ be continuous and $v_i:[0,\infty)\to[1,\infty)$ be continuous and nondecreasing with $$v_1(\left\|x\right\|_E)\le v(x)\le v_2(\left\|x\right\|_E)\;\;\;\text{for all }x\in E,\tag1$$ $$v_1(a)\xrightarrow{a\to\infty}\infty\tag2$$ and $$av_2(a)\le C_1v_1^\theta(a)\;\;\;\text{for all }a>0\tag3$$ for some $C_1\ge0$ and $\theta\ge1$ . Now, let $r\in(0,1]$ and $$\rho(x,y):=\inf_{\substack{\gamma\:\in\:C^1([0,\:1],\:E)\\ \gamma(0)\:=\:x\\ \gamma(1)\:=\:y}}\int_0^1v^r\left(\gamma(t)\right)\left\|\gamma'(t)\right\|_E\:{\rm d}t\;\;\;\text{for }x,y\in E.$$ Let $k>0$ and $B_k$ denote the open ball around $0\in E$ with radius $k$ . Let $x,y\in E$ and $\varepsilon>0$ . By definition of the infimum, there is a $\gamma\in C^1([0,1],E)$ with $\gamma(0)=x$ , $\gamma(1)=y$ and $$\rho(x,y)\le\int_0^1v^r\left(\gamma(t)\right)\left\|\gamma'(t)\right\|_E\:{\rm d}t<\rho(x,y)+\varepsilon\tag4.$$ Question : Why can we conclude that $$\int_0^11_{B_k}(\gamma(t))\left\|\gamma'(t)\right\|_E\:{\rm d}t\le 2k\left(\frac{v_2(k)}{v_1(0)}\right)^r+\varepsilon?\tag5$$ The argument should be that we could otherwise replace the corresponding piece of curve by a straight line and obtain a value which differed from $\rho(x,y)$ by more than $\varepsilon$ , but how can we show this rigorously? EDIT : I mean, by $(1)$ , there is the trivial inequality $$1\le\frac{v_2(\left\|z\right\|_E)}{v_1(\left\|z\right\|_E)}\le\frac{v_2(k)}{v_1(0)}\;\;\;\text{for all }z\in B_k(0)\tag6$$ and I guess a variant of this needs to be used. EDIT 2 : The inequality is clearly trivial, when $\gamma$ never enters $B_k$ . Maybe it's useful to consider the entrance and exit times/points: Let $\sigma_0:=\tau_0:=0$ , \begin{align}\sigma_n&:=\inf\{t\in(\tau_{n-1},1):\gamma(t)\in B_k\},\\\tau_n&:=\inf\{t\in(\sigma_n,1):\gamma(t)\not\in B_k\}\wedge 1\end{align} for $n\in\mathbb N$ , $N:=\{n\in\mathbb N:\sigma_n<\infty\}$ and \begin{align}x_n&:=\gamma(\sigma_n),\\y_n&:=\gamma(\tau_n)\end{align} and $$c_n(t):=\frac{t(y_n-x_n)+\tau_nx_n-\sigma_ny_n}{\tau_n-\sigma_n}\;\;\;\text{for }t\in[\sigma_n,\tau_n]$$ be the straight line connecting $x_n$ and $y_n$ for $n\in N$ . The left-hand side of $(5)$ can then be rewritten as $$\int_0^11_{B_k}(\gamma(t))\left\|\gamma'(t)\right\|_E\:{\rm d}t=\sum_{n\in N}\int_{\sigma_n}^{\tau_n}\left\|\gamma'(t)\right\|_E\:{\rm d}t\tag7.$$ Maybe it can be shown that if the desired inequality doesn't hold, we could replace $\gamma$ on $[\sigma_n,\tau_n]$ with $c_n$ and obtain a value of the integral in $(4)$ which differs by more than $\varepsilon$ from $\rho(x,y)$ . Assume, for simplicity, that $N=\{1\}$ and let $$\tilde\gamma(t):=\left.\begin{cases}\gamma(t)&\text{, if }t\in[0,\sigma_1]\\ c_1(t)&\text{, if }t\in[\sigma_1,\tau_1]\\\gamma(t)&\text{, if }t\in[\tau_1,1]\end{cases}\right\}\;\;\;\text{for }t\in[0,1].$$ We may clearly note that, by construction, $$c_1((\sigma_1,\tau_1))\subseteq B_k\tag8$$ and hence $$\int_{\sigma_1}^{\tau_1}v^r(\tilde\gamma(t))\left\|\tilde\gamma'(t)\right\|_E\:{\rm d}t=\frac{\left\|x_1-y_1\right\|_E}{\tau_1-\sigma_1}\int_{\sigma_1}^{\tau_1}v^r(c_1(t))\le 2kv^r_2(k)\tag9$$ by $(1)$ . Now, maybe we need to use $(6)$ , $v_1\ge1$ and $r\le1$ to obtain $$v^r_2(k)\le\left(\frac{v_2(k)}{v_1(0)}\right)^r\le\left(\frac{v_2(\left\|z\right\|_E)}{v_1(\left\|z\right\|_E)}\right)^r\;\;\;\text{for all }z\in B_k\tag{10}.$$ I think I'm close but still can't complete the puzzle. EDIT 3 : I think we can argue in the following way: Assume $\sigma_1<\infty$ so that the curve enters the ball $B_k$ at time $\sigma_1$ . Replace $\gamma$ on $[\sigma_1,\tau_1]$ by $c_1$ , which yields the curve $\tilde\gamma$ (as defined above). If $(5)$ would not hold, then \begin{equation}\begin{split}\int_{\sigma_1}^{\tau_1}v^r(\tilde\gamma(t))\left\|\tilde\gamma'(t)\right\|_E\:{\rm d}t&\le 2kv_2^r(k)\le2ke\left(\frac{v_2(k)}{v_1(0)}\right)^r\\&<2ke\left(\frac{v_2(k)}{v_1(0)}\right)^r+\varepsilon<\int_{\sigma_1}^{\tau_1}1_{B_k}(\gamma(t))\left\|\gamma'(t)\right\|_E\:{\rm d}t\\&\le\int_{\sigma_1}^{\tau_1}\underbrace{v^r(\gamma(t))}_{\ge\:1}\left\|\gamma'(t)\right\|_E\:{\rm d}t\end{split}\tag{11}\end{equation} by $(9)$ and $(10)$ . Is this a contradiction to $(4)$ ?","['curves', 'analysis', 'functional-analysis', 'supremum-and-infimum', 'differential-geometry']"
3718048,Image of Borel functional calculus of a bounded normal operator,"Let $ H $ be a (not necessarily separable) Hilbert space and $ N $ be a bounded normal operator on $ H $ . For a bounded Borel function $ \phi\colon \sigma(N) \to \mathbb{C} $ on the spectrum of $ N $ , we consider Borel functional calculus $$
\phi(N) = \int_{\sigma(N)} \phi \,dE,
$$ where $ E $ is the spectral measure of $ N $ . I want to find the image of Borel functional calculus $$
X = \{\phi(N) \mid \text{$ \phi\colon \sigma(N) \to \mathbb{C} $ is a bounded Borel function}\}.
$$ To my understanding, $ X \subseteq W^*(N) $ , where $ W^*(N) $ is the von Neumann algebra generated by $ N $ (Proposition IX.8.1 of Conway’s A Course in Functional Analysis (2nd edition)), and $ X = W^*(N) $ if $ H $ is separable (Lemma IX.8.7 of Conway). I tried to generalize the proof of Conway’s Lemma IX.8.7 to non-separable case, but it seems that separability (or, more specifically, existence of a separating vector for $ W^*(N) $ ) is essential for Conway’s proof. So, my question is: Does $ X = W^*(N) $ hold if we don’t assume that $ H $ is separable? If not, how can we describe $ X $ ?","['functional-analysis', 'functional-calculus', 'operator-algebras']"
3718108,Does the derivative of the Fourier series $\sum_{k\geq2}\frac{1}{k^2\log k}\cos kt$ exist?,"Does the derivative of the Fourier series $\sum_{k\geq2}\frac{1}{k^2\log k}\cos kt$ exist? I wanted to use the following sufficient condition for this problem Theorem. Let $a_k(t)$ be differentiable. If a series of functions $\sum_{k}a_k(t)$ is such that $\sum_ka_k'(t)$ converges uniformly in $[a,b]$ , and $\sum_{k}a_k(t)$ converges at ont point in $(a,b)$ , then $\sum_ka(t)$ converges in $[a,b]$ and its derivative is $\sum_ka_k'(t)$ . But this theorem does not seem to be applicable to the series above, because I can't prove that $-\sum_k\frac{1}{k\log k}\sin kt$ is uniformly convergent. However, a book that I am reading says that it does have a derivative. How can I prove it?","['fourier-series', 'derivatives', 'sequences-and-series']"
3718157,When can I say that $A \otimes_{\mathbb{Z}_p} \mathbb{Q}_p \cong B \otimes_{\mathbb{Z}_p} \mathbb{Q}_p$ implies that $ A \cong B$?,I have to show that $ A \cong B$ and I know that $$A \otimes_{\mathbb{Z}_p} \mathbb{Q}_p \cong B \otimes_{\mathbb{Z}_p} \mathbb{Q}_p$$ with $A$ and $B$ commutative $\mathbb{Z}_p$ -algebras that are free as $\mathbb{Z}_p$ -module and of finite rank. Can I say this? Do i need other conditions on $A$ and $B$ ?,"['p-adic-number-theory', 'algebraic-geometry', 'tensor-products']"
3718212,Gaps between Bogotá numbers,"A Bogotá number is a positive integer equal to some smaller number, or itself, times its digital product, i.e. the product of its digits. For example, 138 is a Bogotá number because 138 = 23 x (2 x 3). Bogotá numbers are known to have natural density 0 ( On the density of a certain sequence of integers ). Also many instances of two consecutive integers being both Bogotá numbers (such as 24 and 25) are known ( https://puzzling.stackexchange.com/questions/98998/pairs-of-bogot%c3%a1-numbers?noredirect=1#comment281441_98998 ). Question: Can the gap between two consecutive Bogotá numbers be arbitrarily large? Bogotá numbers less than or equal to 1000 are as follows: 0, 1, 4, 9, 11, 16, 24, 25, 36, 39, 42, 49, 56, 64, 75, 81, 88, 93, 96, 111, 119, 138, 144, 164, 171, 192, 224, 242, 250, 255, 297, 312, 336, 339, 366, 378, 393, 408, 422, 448, 456, 488, 497, 516, 520, 522, 525, 564, 575, 648, 696, 704, 738, 744, 755, 777, 792, 795, 819, 848, 884, 900, 912, 933, 944, 966, 992. The initial sequence of gaps is: 1, 3, 5, 2, 5, 8, 1, 11, 3, 3, 7, 7, 8, 11, 6, 7, 5, 3, 15, 8, 19, 6, 20, 7, 21, 32, 18, 8, 5, 42, 15, 24, 3, 27, 12, 15, 15, 14, 26, 8, 32, 9, 19, 4, 2, 3, 39, 11, 73, 48, 8, 34, 6, 11, 22, 15, 3, 24, 29, 36, 16, 12, 21, 11, 22, 26, 16, 45, 18, 9, 24, 7, 23, 2, 61, 53, 28, 34, 4, 59, 11, 62, 64, 8, 13, 3, 72, 36, 12, 24, 32, 4, 3, 45, 12, 2, 94, 54, 2... Among the first 10,000 Bogota numbers, the largest gap Freddy Barrera found was one of size 5712.","['elementary-number-theory', 'sequences-and-series']"
3718241,Intermediate value theorem for $\mathbb{R}^2$,"Let's consider the continuous function $$ f:\mathbb{R}\times [a,b]\to\mathbb{R}$$ Such that $f(x,a)>0$ for all $x$ and there exists $x_b$ with $f(x_b,b)\leq 0$ . Then there exists $c\in [a,b]$ such that $f(x,c)\geq 0$ for all $x$ and a real value $x_c$ with $f(x_c,c)=0$ . Intuitively this seems true, but I woludn't know how to prove it. Any hint would be appreciated.","['multivariable-calculus', 'calculus', 'continuity', 'real-analysis']"
3718270,Calculating the P-value of a T-distribution.,"Learning some statistics here and in the chapter of Linear Regression I wanted to prove the values that I get on summary() from a created model. My summary() output is: Call:
lm(formula = Price ~ Taxes + Size, data = HousePrices)

Residuals:
    Min      1Q  Median      3Q     Max 
-188027  -26138     347   22944  200114 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -28608.744  13519.096  -2.116   0.0369 *  
Taxes           39.601      6.917   5.725 1.16e-07 ***
Size            66.512     12.817   5.189 1.16e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 48830 on 97 degrees of freedom
Multiple R-squared:  0.7722,    Adjusted R-squared:  0.7675 
F-statistic: 164.4 on 2 and 97 DF,  p-value: < 2.2e-16 For example to calculate the t-value for the intercept I do t-value = -28608.744 / 13519.096 = -2.116173 Now I found in other forums that to get the p-value from this H0 I have to find the probability of the tvalue in a lower tail, I do it with the next command. pvalue1 =  pt(-abs(tvalue), 97, lower.tail = T)*2 I get the right value but I got two questions I cant understand. Why do I have to calculate the probability always with a negative value of a t-value? What is the reason to make it with lower tail and then multiply the result by 2?","['linear-regression', 'statistics', 'p-value']"
3718421,Deriving Law of Cosines from Law of Sines,"How to eliminate $\alpha$ from the Law of Sines of plane trigonometry $$ \dfrac{a}{\sin \alpha}= \dfrac{c}{\sin \gamma} =\dfrac{b}{\sin (\gamma+\alpha)} =2R $$ in order to arrive at the Law of Cosines $$ c^2= a^2+b^2-2 a b \cos \gamma \;?$$ Starting to isolate $\alpha$ $$ \alpha =\sin^{-1}\big(\dfrac{b-c}{2R} +\sin  \gamma \big)-\gamma$$ $$ =\sin^{-1}( b \sin \gamma/c) -\gamma$$ involve $c$ that we are finding and so on, how best to simplify?",['trigonometry']
3718453,Prove there exists a $2$-coloring of the points of the projective plane of order $11$ such that every line has at least two points of each color,"To clarify, the projective plane of order $11$ has $133$ lines and $133$ points; any two lines intersect in one point, and any two points determine one line; there are exactly $12$ points on each line, and each point lies on exactly $12$ lines. I've been thinking about the above problem for a while now, and I believe that I need to use pigeonhole principle. However, I'm not sure how to use pigeonhole principle to prove the existence of a special coloring rather than a guaranteed property of any coloring. I've also looked at the smaller case of the projective plane of order $3$ **, and it seems that this plane has no $2$ -coloring such that each line has at least $1$ point of each color. If that's true, I'm not sure how to prove it, although I believe that the strategy to prove this case could help me solve the original problem. I would appreciate any help, especially a hint or approach that I can use to find the rest of the solution on my own! EDIT*: I sketched a potential solution in the comments below; please feel free to critique it! EDIT**: I meant order $2,$ with $7$ points and $7$ lines. Sorry about the confusion there!","['coloring', 'combinatorics', 'discrete-mathematics']"
3718462,"Why $\lim_{\varepsilon \to 0} \varepsilon \int_0^\infty \frac{z\,dz}{(z-1)^2 + \varepsilon^2z^3} = \pi$?","I need help evaluating the following limit: $$
\lim_{\varepsilon \to 0}\left[2\varepsilon\int_{0}^{\infty} \frac{x^{3}\,\mathrm{d}x}
{\left(x^{2} - \varepsilon^{2}\right)^{2} + x^{6}}\right]
$$ Making the substitutions $y = x^{2}$ and $z = y/\varepsilon^{2}$ I was able to put the integral in a form that seems more tractable: $$
\lim_{\varepsilon \to 0}\left[\varepsilon
\int_{0}^{\infty}\frac{z\,\mathrm{d}z}{\left(z - 1\right)^{2} + \varepsilon^{2}z^{3}}\right]
$$ I have two reasons to think that the limit evaluates to $\pi$ : The first one is that it's necessary for the result I'm trying to reach in a physics problem, which obviously isn't a very good justification. The second one ist that I made a numerical calculation that gave me a result very close to $\pi$ : I restricted the integral to the interval $[0,10]$ , because the integrand has a very sharp peak at $z=1$ . Then, I divided that interval in $2 \cdot 10^{6}$ subintervals and used Simpson's method to calculate the integral. With $\varepsilon = 10^{-4}$ I got the result $3.1417$ . I tried to calculate it using the residues method, but I couldn't find the roots of the third degree polynomial in the denominator. Does anyone have an idea on how to evaluate the limit analytically? Any help is appreciated.","['integration', 'limits', 'calculus']"
3718470,"All non abelian groups of order $56$, when $\mathbb Z_7\triangleleft G$","I am calculating all non abelian groups of order $56$ when $\mathbb Z_7$ is a normal subgroup ( Given in the exercise $7$ of §5.5, Dummit Foote). I have searched for related posts on this site but couldn't able to find something that discusses on this particular topic. It would be great if someone provide me link on this site discussing on this topic . However, here is my progress. Let $S$ be the Sylow $2$ subgroup and throughout the discussion I will call $\mathbb Z_7=\left<d\right>$ , where $d=1$ . My calculations are as follows : $\boxed{\text{case }(1) :  S=\mathbb{Z_2}\times\mathbb{Z_2}\times\mathbb{Z_2}=\left<a,b,c\right>}$ Since all elements of $\mathbb{Z_2}\times\mathbb{Z_2}\times\mathbb{Z_2}=\left<a,b,c\right>$ has order $2$ , so for any homomorphism $\phi\colon\left<a,b,c\right>\to Aut(\mathbb Z_7)$ , each of $\phi(a),\phi(b),\phi(c)$ has order either $1$ or $2$ . The element of $Aut(\mathbb Z_7)$ having order $1$ is the identity  automorphism $\alpha_1\colon1\mapsto1$ and that having order $2$ is the automorphism $\alpha_2\colon1\mapsto6$ because $1\mapsto6\mapsto6\cdot6=36=1$ in $\mathbb Z_7$ . So the possible homomorphisms are : $\begin{array}{c|c}\phi_1&\phi_2\\\hline
 a\mapsto\alpha_1 & a\mapsto  \alpha_1\\b\mapsto\alpha_1&
 b\mapsto\alpha_2\\c\mapsto \alpha_2&c\mapsto\alpha_2\end{array}\tag*{}$ In case of the homomorphism $\phi_1$ , $a\cdot d=d, b\cdot d=d, c\cdot d=d^{-1}$ , where the dot represents the action on $d$ . $\therefore ada^{-1}=d,bdb^{-1}=d,cdc^{-1}=d^{-1}\text{ with  }a^2=b^2=c^2=d^7=1$ Since $a$ and $b$ centralize both $c$ and $d$ , so in this case the group must be $\begin{align}G_{\phi_1}&=\left<a|a^2=1\right>\times\left<b|b^2=1\right>\times\left<c,  d|c^2=d^7=1,cdc^{-1}=d^{-1}\right>\\&=\mathbb Z_2\times\mathbb Z_2\times D_{14}\\&=\mathbb Z_2\times D_{28}\end{align}$ In case of the homomorphism $\phi_2$ , $a\cdot d=d, b\cdot d=d^{-1}, c\cdot d=d^{-1}$ . $\therefore
 ada^{-1}=d,bdb^{-1}=d^{-1},cdc^{-1}=d^{-1}\text{ with 
 }a^2=b^2=c^2=d^7=1$ . But the group $G_{\phi_2}$ formed by these relations is exactly same as the above group : if we invert all the elements of $G_{\phi_1}$ , we get $G_{\phi_2}$ . So $$G_{\phi_1}\cong G_{\phi_2}$$ $\boxed{\text{case }(2) : S=\mathbb{Z_4}\times\mathbb{Z_2}=\left<a,b\right>}$ By the same argument in case $1$ , the possible homomorphisms $\mathbb Z_4\times\mathbb Z_2\to Aut(\mathbb Z_7)$ are : $\begin{array}{c|c|c}\psi_1&\psi_2&\psi_3\\\hline a\mapsto\alpha_1& a\mapsto\alpha_2&a\mapsto \alpha_2\\b\mapsto\alpha_2& b\mapsto\alpha_2&b\mapsto \alpha_1\end{array}\tag*{}$ In case of the homomorphism $\psi_1$ , $G_{\psi_1}=\left<a,b,d|a^4=b^2=d^7=1, ab=ba ,ada^{-1}=d, bdb^{-1}=d^{-1}\right>$ Hence it  is easily seen to be $$G_{\psi_1}\cong\mathbb Z_4\times D_{14}$$ In case of the homomorphism $\psi_2$ , $G_{\psi_2}=\left<a,b,d|a^4=b^2=d^7=1,ab=ba ,ada^{-1}=d^{-1},bdb^{-1}=d^{-1}\right>$ Now, $(ab) \cdot (d)=(ab)d(ab)^{-1}=a(bdb^{-1})a^{-1}=ad^{-1}a^{-1}=d$ . And order of $ab$ is $4$ and $ab$ centralises both $b$ and $d$ . So the relations determined by $\psi_2$ are same as the relations determined by $\psi_1$ . So, $G_{\psi_2}=\left<ab\right>\times\left<b,d\right>=\mathbb Z_4\times D_{14}\cong G_{\psi_1}$ And the homomorphism $\psi_3$ produces the group $\begin{align}G_{\psi_3}&=\left<a,b,d|a^4=b^2=d^7=1, ab=ba ,ada^{-1}=d^{-1}, bdb^{-1}=d\right>\\&=\left<b|b^2=1\right>\times\left<a,d|a^4=d^7=1,ada^{-1}=d^{-1}\right>\\&=\mathbb Z_2\times\left<a,d|a^4=d^7=1,ada^{-1}=d^{-1}\right>\end{align}$ $\boxed{\text{case }(3) : S=\mathbb{Z_8}=\left<a\right>}$ The only possible homomorphism $\pi\colon\mathbb Z_8\to Aut(\mathbb Z_7)$ that gives rise to a non abelian group is : $\pi\colon a\mapsto\alpha_2$ . Here the group is $G_\pi=\mathbb Z_7\rtimes_{\pi}\mathbb Z_8$ . $\boxed{\text{case }(4) : S=\mathbb Q_8=\left<i ,j\right>}$ Since here $S$ is non abelian, we need to take the trivial homomorphism $S\to Aut(\mathbb Z_7)$ into account. The possible homomorphisms are : $\begin{array}{c|c|c|c}\theta_1&\theta_2&\theta_3&\theta_4(\text{ trivial })\\\hline
 i\mapsto\alpha_1& i\mapsto\alpha_2&i\mapsto
\alpha_2&i\mapsto\alpha_1\\j\mapsto\alpha_2& j\mapsto\alpha_1&j\mapsto
\alpha_2&j\mapsto\alpha_1\end{array}\tag*{}$ In case of the homomorphism $\theta_1$ , the relations between the elements are : $idi^{-1}=d, jdj^{-1}=d^{-1}, i^2=j^2=-1, d^7=1, ij=-ji$ I don't know the name of this  group $G_{\theta_1}$ . I would like to know if there is some name or explicit notation for this group. The group $G_{\theta_2}$ formed by the homomorphism $\theta_2$ is isomorphic to $G_{\theta_1}$ because we are just interchanging the roles of $i$ and $j$ . In case of the homomorphism $\theta_3$ , we have the relations : $idi^{-1}=d^{-1}, jdj^{-1}=d^{-1}, i^2=j^2=-1, d^7=1, ij=-ji$ . Now in the relation $j\cdot d=jdj^{-1}= d^{-1}$ , if we hit by $i$ , $(ij)d(ij)^{-1}=id^{-1}i^{-1}=d$ . So writing $ij=k$ the relations determined by $\theta_3$ are $idi^{-1}=d^{-1}, kdk^{-1}=d$ , which is exactly the same as the group determined by $\theta_1$ or $\theta_2$ . So $G_{\theta_1}\cong G_{\theta_2}\cong G_{\theta_3}$ . The trivial homomorphism $\theta_4\colon\mathbb Q_8\to Aut(\mathbb Z_7)$ corresponds to $G_{\theta_4}=\mathbb Q_8\times\mathbb Z_7$ $\boxed{\text{case }(5) : S=D_8=\left<r ,s\right>}$ Here the possible homomorphisms are : $\begin{array}{c|c|c|c}\eta_1&\eta_2&\eta_3&\eta_4(\text{ trivial })\\\hline r\mapsto\alpha_1& r\mapsto\alpha_2&r\mapsto \alpha_2&r\mapsto\alpha_1\\s\mapsto\alpha_2& 
 s\mapsto\alpha_1&s\mapsto \alpha_2&s\mapsto\alpha_1\end{array}\tag*{}$ The corresponding groups are as alex mentioned in the comment : $\begin{align}G_{\eta_1}&=\{r, s,d|r^4=s^2=d^7=1,srs=r^{-1},rdr^{-1}=d,sds=d^{-1}\}\\&=\{r,s,d|(rd) ^{28}=s^2=1,s(rd)\cdot s(rd)=s(dr)\cdot s(rd)=sd(rsr)d=sd(s)d=(sds)d=d^{-1}d=1\}\\&=D_{56}\end{align}$ $G_{\eta_2}=\{r, s,d|r^4=s^2=d^7=1,srs=r^{-1},rdr^{-1}=d^{-1},sds=d\}$ and $G_{\eta_3}=\{r, s, d|r^4=s^2=d^7=1,srs=r^{-1},rdr^{-1}=d^{-1},sds=d^{-1}\}$ In $G_{\eta_2}$ , if we hit the relation $s\cdot d=sds^{-1}=d$ by $r$ , we get, $(rs)\cdot d=(rs)d(rs)^{-1}=r(sds^{-1})r^{-1}=rdr^{-1}=d^{-1}$ So $G_{\eta_2}=\{r, s,d|r^4=s^2=d^7=1,srs=r^{-1},rdr^{-1}=d^{-1},(rs)d(rs)^{-1}=d^{-1}\}\cong G_{\eta_3}$ And here too I come up with the group $G_{\eta_2}$ for the first time. So it would be great if someone please help me to understand these groups. The trivial homomorphism $\eta_4\colon D_8\to Aut(\mathbb Z_7)$ gives rise to the group $G_{\eta_4}$ which is the direct product $D_8\times\mathbb Z_7$ Most importantly, I would like to know whether there are any flaws in my calculations. Thank you.","['finite-groups', 'semidirect-product', 'abstract-algebra', 'sylow-theory', 'solution-verification']"
3718534,"Prove the existence of a principal submatrix of order $r$ in $M\in\Bbb F^{n\times n}, M=-M^T,\ \operatorname{rank}(M)=r$","Let $M$ be a skew-symmetric matrix of $\operatorname{rank}(M)=r$ , prove that there exists a principal submatrix of order $r$ . I have a solution for the version which doesn't require the submatrix to be principal (this is not my solution)
take away all but $r$ linearly independent columns of $M$ , call the matrix $P$ since $\operatorname{rank}M=r$ this is possible
then if $P$ is $r \times r$ , done, invertible if $P$ is $n \times r$ where $n < r$ then $\operatorname{rank}(M)\leqslant n < r$ so this case can't happen so assume $P$ is $n \times r$ where $n > r$ ,
now we look at $P^T = -P$ , $\operatorname{rank}(P) = \operatorname{rank}(-P) = r$ then you can take away all but $r$ columns of $P^T$ obtaining $Q^T=$ taking all but $r$ rows of $P$ obtaining $Q$ then $Q$ is $r \times r$ and all columns are linearly independent So I am looking for a solution which proves the existence of a principal matrix.","['matrices', 'linear-algebra']"
3718570,"What is $\frac{\det(\hat{\Sigma}_0)}{\det(\hat{\Sigma})}$ in terms of $\hat{\mu}_1$, $\hat{\mu}_2$ and $\hat{\Sigma}$","Let $X_1,...,X_{n_1}$ be an i.i.d. sample from $N_p(\mu_1,\Sigma)$ and let $Y_1,...,Y_{n_2}$ be an independent sample from $N_p(\mu_2,\Sigma)$ , for some $\mu_1,\mu_2 \in \mathbb{R}^p$ and some invertible, $p\times p$ positive definite matrix $\Sigma$ . Let $\hat{\mu}_0 := \frac{\sum_{i=1}^{n_1}x_i + \sum_{i=1}^{n_2}y_i}{n_1 + n_2}$ , $\hat{\mu}_1 := \frac{1}{n_1}\sum_{i=1}^{n_1}x_i$ and $\hat{\mu}_2 := \frac{1}{n_2}\sum_{i=1}^{n_2}y_i$ Suppose $\hat{\Sigma}_0=\frac{1}{n_1+n_2}\biggl(\sum^{n_1}_{i=1}(x_i-\hat{\mu}_0)(x_i-\hat{\mu}_0)^T+\sum^{n_2}_{i=1}(y_i-\hat{\mu}_0)(y_i-\hat{\mu}_0)^T\biggr)$ and $\hat{\Sigma}=\frac{1}{n_1+n_2}\biggl(\sum^{n_1}_{i=1}(x_i-\hat{\mu}_1)(x_i-\hat{\mu}_1)^T+\sum^{n_2}_{i=1}(y_i-\hat{\mu}_2)(y_i-\hat{\mu}_2)^T\biggr)$ I would like to show that: $$\frac{\det(\hat{\Sigma}_0)}{\det(\hat{\Sigma})} = 1 + \frac{n_1n_2}{(n_1+n_2)^2}(\hat{\mu}_1 -\hat{\mu}_2)^T\hat\Sigma^{-1}(\hat{\mu}_1 -\hat{\mu}_2) $$ I know that $\frac{\det(\hat{\Sigma}_0)}{\det(\hat{\Sigma})}=\det(\hat{\Sigma}^{-1/2}\hat{\Sigma}_0\hat{\Sigma}^{-1/2})$ , but I'm not sure how to continue.","['statistics', 'covariance', 'determinant', 'matrices', 'maximum-likelihood']"
3718588,Special functions for understanding elemetary integrals,"In this earlier question I wrote: Sir Harold Jeffreys wrote: $\dagger$ Consider the integrals $$ I_n = \int_{-1}^1 (1-x^2)^n \cos\alpha x \,dx. $$ Two integrations by parts give the recurrence relation $$ \alpha^2 I_n = 2n(2n-1) I_{n-1} - 4n(n-1) I_{n-2}, \qquad n\ge 2. $$ So I did the two integrations by parts and got $$
\frac{2n}{\alpha^2} \int_{-1}^1 \cos(\alpha x) (1-x^2)^{n-2}(1 - (2n-1) x^2) \, dx,
$$ so I had to ascertain whether that was equal to the right side of the recurrence relation. That comes down to this: \begin{align}
& (1-x^2)^{n-2}(1 - (2n-1) x^2) \\[6pt]
= {} & (2n-1)\,\underbrace{(1-x^2)^{n-1}} {} - 2(n-1) \underbrace{(1-x^2)^{n-2}}
\end{align} As I said in that earlier question, here we use the set $\{ (1-x^2)^n : n=0,1,2,\ldots \}$ as a basis of the space of even polynomials. $$
\left\{\begin{array}{l}
\textbf{Note inspired by a comment below:} \\
\textbf{The QUESTION posed here is NOT} \\
\textbf{how to deal with this integral, and} \\
\textbf{appears BELOW, and can be understood} \\
\textbf{ONLY by reading what appears below.}
\\ {} \\
\textbf{AND this question is NOT about THIS integral.}
\end{array}\right.
$$ As I did not say in that earlier question, I attempted to ascertain whether the equality holds before it occurred to me to express the function I got as a linear combination of the functions in that particular sequence. Despite the triviality of it, seemingly being a matter for routine secondary-school algebra, it was hairy and icky until I realized that expressing everything as a linear combination of these functions is what was how it should be done. So now my somewhat vague question is whether, in the context of elementary sorts of integrals like this, there are OTHER instances of easily defined special functions whose employment instantly reveals a pattern without which the problem is hairy and with which it is straightforward and has a nice pattern? Just as there are tables of integrals, would it be worth making a table of such things? $\dagger$ Scientific Inference , third edition, Cambridge University Press, 1973. Appendix III. If I'm not mistaken, this appendix does not appear in other editions.","['integration', 'definite-integrals', 'special-functions']"
3718591,Sum of first K primes is triangle number,"I was reading something this morning and came across the fact that 28 is both the sum of the first five prime numbers and of the first seven natural numbers.  Naturally, I then tried to find other numbers U such that for some integers n and k $$U=\sum_{a=1}^{n}a=\sum_{a=1}^{k}p_a$$ I quickly noticed that 10 is both the sum of the first four natural numbers and of the first three prime numbers, but that I couldn't find any others off the top of my head.  After sitting at a computer, I found that the next such number is 133386, which is the sum of the first 516 natural numbers and of the first 217 prime numbers.  There were no other examples that for which $k\leq1000$ . Before sitting at the computer, I hypothesized that there were no other examples, and tried to go about proving it.  Based on the fact that the sum of the first n natural numbers is $\frac{n(n+1)}{2}$ , I was able to proceed: $$\frac{n(n+1)}{2}=U$$ $$n^2+n-2U=0$$ $$n=\frac{-1+\sqrt{1+8U}}{2}$$ Is there any way of proceeding past this point, either proving that there are infinitely many numbers k that $1+8\sum_{a=1}^{k}p_a$ is a perfect square or that there are only a finite number that fulfill this criterion?","['number-theory', 'recreational-mathematics']"
3718614,Functions $f: \mathbb{Z}^{+}\to \mathbb{R}$ satisfying $x f(y) + y f(x) = (x+y) f(x^2+y^2)$,"Let $\mathbb{Z}^{+}=\{1, 2, 3, ...\}$ denote the set of positive integers. Problem 1. Are there any non-constant functions $f\colon \mathbb{Z}^{+}\to\mathbb{R}$ such that $$
x f(y) + y f(x) = (x+y) f(x^2+y^2)
$$ for all $x, y\in\mathbb{Z}^{+}$ ? Clearly, the constant functions satisfy the functional equation above, and so it is natural to see if there are any non-constant examples. The motivation for this problem comes from a related (and easier problem) from Canadian Mathematical Olympiad (Year 2002): Problem 2. Find all functions $f\colon \mathbb{Z}^{+}\to\mathbb{Z}^{+}$ such that $$
x f(y) + y f(x) = (x+y) f(x^2+y^2)
$$ for all $x, y\in\mathbb{Z}^{+}$ . This second problem has a nice solution. I don't want to spoil it for others, so if you want to read it, you can hover over the following solution (I divided it into steps, in case you want to have hints one step at a time): Solution to Problem 2. We claim that only the constant functions $f:\mathbb{Z}^{+}\to\mathbb{Z}^{+}$ satisfy the functional equation above. Assume, to the contrary, there is a non-constant function $f$ with this property. Thus, there exist positive integers $a$ and $b$ such that $f(a)<f(b)$ . Then using the functional equation, one gets: $$ (a+b) f(a) < (a+b) f(a^2+b^2) < (a+b) f(b)$$ So, $f(a) < f(a^2+b^2) < f(b)$ . We have shown that between any two distinct points in the image of $f$ , there is a third point in between. And this process can be repeated forever. However, this is a contradiction since the target of $f$ is the natural numbers $\mathbb{Z}^{+}$ . As you can see, this solution does not work when the target is $\mathbb{R}$ , hence the reason for asking this question.","['contest-math', 'number-theory', 'functional-equations', 'examples-counterexamples']"
3718647,Relating the binomial probability distribution to the Poisson Distribution in an example,"Reading the textbook Mathematical Statistics and Data Analysis 3rd ed, by Rice. I've come up on an example that I'm trying to extend beyond the text: So I am trying to obtain one of the stated Poisson probabilities, but using the binomial distribution instead. I'm not sure if I am interpreting things right to get my stated goal. For instance let's take trying to get $\text{Number of Deaths} = 0$ . From the Poisson Probability this is given as $0.543$ . With the given information I am able to calculate a ""probability"" but I'm not sure what it means: $$np = \lambda \\ \Rightarrow p = \frac{\lambda}{n}$$ So we know that $n = 200$ and $\lambda = 0.61$ , meaning $$p = \frac{0.61}{200} = 0.00305$$ I took this as meaning the ""probability of dying from horse kick"". Here is where I get stuck trying to convert the problem into a binomial distribution problem. I could see framing things in terms of deaths -no deaths and that may possibly look like: $$\binom{200}{109}(0.00305)^{109}(0.99695)^{91}$$ But how would I go about things if I wanted to get  1 death, 2 deaths,...etc? How could I frame things to get the same (or close to) Poisson probabilities stated but with a binomial distribution instead ?","['probability-distributions', 'probability-theory', 'probability']"
3718715,"Prove that $\{f_n\} _{n=1}^{\infty}$ uniformly converges to $ f(x)=\int_{0}^{1}g(x,t)\mathrm{dt}$","Let $g:(0,\infty)\times [0,1]\to {\mathbb{R}}$ be continuous with respect to each variable separately  and $$f_n=\frac{1}{n}\sum_{i=1}^{n}g\left(x,\frac{i}{n}\right)$$ How can show that $\{f_n\} _{n=1}^{\infty}$ uniformly converges to $\displaystyle f(x)=\int_{0}^{1}g(x,t)\mathrm {dt}$ on $[m,M]$ , each subset of $(0,\infty)$ .","['multivariable-calculus', 'calculus', 'uniform-convergence', 'real-analysis']"
3718725,What is the expected cost of using LDA?,"Suppose that you observe $(X_1,Y_1),...,(X_{100}Y_{100})$ , which you assume to be i.i.d. copies of a random pair $(X,Y)$ taking values in $\mathbb{R}^2 \times \{1,2\}$ . I have that the cost of misclassification are equal, $c_1=c_2=1$ . The distributions $X|Y=1$ and $X|Y=2$ are each rotationally symmetric. I would like to perform LDA to classify the data points. I have that $a=\hat\Sigma^{-1}_p(\hat{\mu}_1-\hat{\mu}_2)=(0.132-0.0732)$ and $\frac{1}{2}a^T(\hat{\mu}_1+\hat{\mu}_2)\approx 0$ And now I would like to calculate the approximate expected cost of using LDA. So, in the textbook i'm using, the expected cost of misclassification is defined as: Suppose we use the classification rule $g:\mathbb{R}^p\rightarrow \{1,2\}$ , that assigns to group $1$ when $x \in R_1$ adnto group $2$ when $x\in R_2$ . The expected cost of misclassification associated to the rule $g$ is $$\mathbb{E}[\text{cost}(Y,g(X))]=c_2\mathbb{P}(x\in R_1 | Y=2)\pi_2+c_1\mathbb{P}(x\in R_2 | Y=1)\pi_1$$ Where $\pi_1=\mathbb{P}(Y=1|x)$ and $\pi_2=\mathbb{P}(Y=2|x)$ And so my attempt is: $$\mathbb{E}[\text{cost}(Y,g(X))]=c_2\mathbb{P}(x\in R_1 | Y=2)\pi_2+c_1\mathbb{P}(x\in R_2 | Y=1)\pi_1=\mathbb{P}(0.132x_1-0.0732x_2\gt 0|Y=2)\pi_2+\mathbb{P}(0.0132x_1-0.0722x_2 \lt 0|Y=1)\pi_1$$ And i'm stuck here. I'm not sure how to continue from here. In particular, I don't know what $\mathbb{P}(0.0132x_1-0.0722x_2 \lt 0|Y=1)$ and $\mathbb{P}(0.132x_1-0.0732x_2\gt 0|Y=2)$ are equal to, also $\pi_1,\pi_2$ .","['statistics', 'machine-learning', 'symmetry', 'probability-theory', 'probability']"
3718736,"Let $A\in M_n(\Bbb R)$ be such that the sum of the two largest numbers in each row is $a$, and in each column is $b$. How can I prove that $a=b$?","In every cell of a square table there is a real number. The sum of the largest two numbers in each row is $a$ and the sum of the largest two numbers in each column is $b$ . Prove that $a = b$ . Help! I don't know how to start the problem. I've considered the largest and smallest numbers of such a set, however, I don't know what good using the extremes will bring.","['contest-math', 'combinatorics']"
3718760,"For graph G and integer k, exist coloring $V\to [k]$ s.t. $(1-1/k)$ of every vertex get different color.","For any simple graph $G$ and positive integer $k$ , there exists a coloring $c: V(G) \rightarrow[k]$ such that for every vertex $v$ of $G,$ at least $(1-1/k)$ -fraction of its neighbors get different colors. I am studying extremal combinatorics, and this is a conclusion in the textbook. I cann't find its proof or figure it out by myself. Can someone help me?","['coloring', 'graph-theory', 'extremal-combinatorics', 'combinatorics', 'discrete-mathematics']"
3718836,Why does the infinitude of primes of a certain form matter? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question A result like Dirichlet's theorem makes sense to me as worthy of attention because arithmetic progressions are a natural mathematical phenomenon. But then there are results like the Friedlander-Iwaniec theorem which states the infinitude of primes of the form $a^2+b^4,$ and a theorem of Heath-Brown which states the infinitude of primes of the form $x^3 +2y^3.$ I don't understand why top-notch mathematicians pursue these questions, let alone receive prizes for them (""Iwaniec was awarded the 2001 Ostrowski Prize in part for his contributions to this work."" according to the linked Wikipedia article). It would be one thing if the primes were of a more natural form like in Dirichlet's theorem or applied to a broad class of forms, but these seem to be stand-alone results for very specific, unnatural forms. Why are these questions researched and and their solutions celebrated? I don't have the necessary sieve-theoretic background to understand the proofs, but is it the case that these theorems are just corollaries of much deeper and significant theories? Or is the motivation something else?","['sieve-theory', 'number-theory', 'analytic-number-theory', 'soft-question', 'prime-numbers']"
3718847,Goldbach twin and cousin primes,"Good day. My question is a counterexample for the following: Is every even number greater than 4 the sum of a number that belongs to set the cousin primes with another number that belongs to the set of twin primes? Cousin primes (p,q) in the sense that if p is prime, then p+4 is other prime number. I verify it up 1000. For example, and curiously, for 556=239+317 no there are much goldbach partitions that solve the question.","['twin-primes', 'number-theory', 'examples-counterexamples', 'computational-mathematics', 'prime-numbers']"
3718870,Volume Enclosed Between a Surface and a Plane,"This is a problem that I came up with that has been driving me crazy. I have not been able to find a solution nor a person who could direct me to one.
The problem is as follows;
Find the volume of the region enclosed by the surfaces on [ $-\pi..\pi, -\pi..\pi]$ (These are meant to describe the x and y value ranges, excuse my lack of knowledge on formal math notation) $$F(x,y)=cos(x)+cos(y)$$ $$G(x,y)=1/2$$ I need to specific, however, that I do not want to find the net volume of this region as 1-These are trigonometric functions with an infinite domain and therefore never reach a truly enclosed area and 2-Selecting a square region as I have will result in an answer of 0.
The volume I want to find in specific is the one enclosed by the plane G(x,y) and F(x,y) where F(x,y) lies above the plane. Below are some pictures to illustrate this. This problem is a bit above my current math knowledge, but I am really itching for a solution/walkthrough on the problem. The biggest obstacle for me is determining how to describe the boundary of the region I need to integrate over. Any help would be much appreciated and I can answer any questions as I know my explanation isn't perfectly clear/formalized.","['integration', 'multivariable-calculus', 'calculus', 'volume']"
3718895,Calculus: derivative of logarithm with respect to logarithm,"I have this expression: $$ \dfrac{d\ln\left(\dfrac{x_2}{x_1}\right)}{d\ln(\theta)} $$ That I’m hoping to get some help solving, Where $\ln\left(\dfrac{x_2}{x_1}\right)= \ln\left(\dfrac{1-a}{a}\right)+\ln(\theta)$ and $\theta= \dfrac{a}{1-a} \cdot \dfrac{x_2}{x_1}$ My confusion stems from having a derivative with ln in both the numerator and denominator and I’m not sure how to correctly proceed. I know the answer is $1$ , however, I’m more interested in knowing the technique to get there. Any help would be appreciated","['calculus', 'derivatives']"
3718905,Proving DeMorgan's law for arbitrary unions/intersections,"I am trying to prove DeMorgan's law for arbitrary unions and intersections using Munkres's notation. One of the laws takes the form $$B - \bigcup\limits_{A \in \mathcal{A}} A = \bigcap\limits_{A \in \mathcal{A}} (B - A).$$ This is the not the notation I am accustomed to, which would instead take the form $$\bigcup\limits_{A \in \mathcal{A}} A^c = \left(\bigcap\limits_{A \in \mathcal{A}} A^c\right)^c,$$ but I am trying to prove this fact using Munkres's notation, which uses set differences in place of complements. Here is what I have so far. \begin{align*}
x \in B - \bigcup\limits_{A \in \mathcal{A}} A & \iff x \in B \text{ and } x \not \in \bigcup\limits_{A \in \mathcal{A}} A \\
& \iff x \in B \text{ and } \forall A \in \mathcal{A}, \; x \not \in A
\end{align*} At this point, I am immediately stuck because I want to say something to the effect of: \begin{align*}
& \iff x \in (B - A_1) \text{ and } x \in (B - A_2) \ldots  
\end{align*} But the collection is arbitrary, so I cannot quite do that. In effect, I am using some sort of ""pairing"" and using the rule $p \wedge (q \wedge r)$ an arbitrary number of times. If I were to do that without writing it out in a misleading way, I would get something like: \begin{align*}
& \iff x \in \bigcap\limits_{A \in \mathcal{A}} (B - A).
\end{align*} But the problem is, I am essentially asserting the conclusion without showing any of the steps. The proof using the usual, complement notation I know to be far more involved in this. It seems that I am missing intermediary steps that are difficult to formalize with this notation. What am I missing?","['elementary-set-theory', 'proof-explanation']"
3718962,Question about proof of interchanging integral and derivative using uniform convergence.,"Theorem: Assume that $\varphi(x,t):[a,b]\times[c,d]\to \Bbb R$ $\varphi(x,t)\in R[a,b]$ ( $\varphi(x,t)$ is Riemann integrable on $[a,b]$ ) $\ \ \forall t\in [c,d]$ . i.e. $$\int_a^b\varphi(x,t)dx$$ exists $\ \forall t\in [c,d]$ . Let $c\lt s\lt d $ and $\varepsilon \gt 0$ , there exists $\delta \gt 0 $ s.t. $$\lvert \; \frac{\partial\varphi}{\partial t}(x,t) - \frac{\partial\varphi}{\partial t}(x,s)\;\rvert \lt \epsilon$$ for all $x\in [a,b]$ , $t\in (s-\delta,s+\delta)$ . Define $$f(t)=\int_a^b\varphi(x,t)dx$$ , $t\in[c,d]$ . Then $$\frac{\partial\varphi}{\partial t}(x,s)\in R[a,b]$$ and $$f'(s)=\int_a^b\frac{\partial\varphi}{\partial t}(x,s)dx$$ My attempt: Define $$\Psi(x,t)=\frac{\varphi(x,t)-\varphi(x,s)}{t-s}$$ for $0\lt\lvert t-s \rvert\lt\delta$ . By MVT, $\exists u$ between $s$ and $t$ s.t. $$\Psi(x,t)=\frac{\partial\varphi}{\partial t}(x,u)$$ So $$\lvert \Psi(x,t)-\frac{\partial\varphi}{\partial t}(x,s)  \rvert=\lvert\frac{\partial\varphi}{\partial t}(x,u)-\frac{\partial\varphi}{\partial t}(x,s)  \rvert\lt\varepsilon\ \forall x\in [a,b] \;\; \color{blue}{(\star)}$$ by assumption 3. $\color{darkred}{\textrm{My question}}$ : By $\color{blue}{(\star)}$ , can I conclude that $$\Psi(x,t)\to\frac{\partial\varphi}{\partial t}(x,s) \text{ uniformly on } [a,b] \text{ as } t\to s  \;\;\color{darkorange}{(\star)}\text{ ? }$$ be the limit function. I have learned uniform convergence for sequence of functions like $\{ f_n\}\to f$ uniformly means for any $\varepsilon \gt 0$ , there exist $N\in \Bbb N$ s.t.  for any $n\gt N$ $\lvert f_n(x)-f(x) \rvert\lt\varepsilon\ \forall x\in X$ ( if $f$ is defined on $X$ ). How can I find such $N$ in $\color{darkorange}{(\star)}$ ? Suppose $$\varepsilon=\frac1n$$ $(\forall n\in\Bbb N)\ \exists\delta_n$ in assumption 3 s.t. $$t\in (s-\delta_n,s+\delta_n)$$ which means $t$ getting closer and closer to $s$ as $n$ getting greater. i.e. $t\to s$ as $n\to\infty$ Can I let $$\Psi(x,t)=f_n(x)$$ in $\color{darkorange}{(\star)}$ ,where $n$ depends on $\delta_n$ related to $t$ . Let $$\frac{\partial\varphi}{\partial t}(x,s)=f(x)$$ Then $$f_n(x)\to f(x)\text{ uniformly on }[a,b]\text{ as }t\to s$$ Is my proof correct? Thanks for helping.","['multivariable-calculus', 'uniform-convergence', 'real-analysis']"
3719031,Is the minimum a continuous function?,"Let's consider a continuous function $$ f:\mathbb{R}\times [a,b]\to\mathbb{R}$$ Such that $g(y)=\min_{x\in\mathbb{R}} f(x,y)$ is well defined for every $y\in[a,b]$ . Is it true that $g(y)$ is continuous on [a,b]? I believe this statement to be true, but I don't know how to prove it. Any hint would be appreciated.","['real-analysis', 'maxima-minima', 'multivariable-calculus', 'calculus', 'continuity']"
3719032,How to find the distance along a sphere from an angle?,"Imagine there are two points on planet Earth and a light is shone from one to the other by reflecting off an object 500km up (think of this as a mirror oriented parallel to the surface right below it). Let us assume the Earth is a perfect sphere.  As the distance between the points increases, the angle that the light is received at increases with a limit of 90 degrees which corresponds to a tangent of the sphere.  I would like to know how far apart the two points along the sphere are as a function of this angle. To try to solve it I first notice that the angle of incidence equals the angle of reflection. So we can draw an  isosceles triangle with the reflector at the top and the two points as the other two vertices.  The height of the triangle is a function of how far apart the two points are. But now I am stuck. The radius of the Earth is 6371km.","['trigonometry', 'spheres', 'geometry']"
3719033,Prove that there exists $n\in \mathbb{N}$ s.t. $x_n=\frac12$,Let $(x_n)_n$ a sequence given by $2x_{n+1}=2x_n^2-5x_n+3$ with $x_1\in \mathbb{Q}$ . I know that the sequence is convergent. I know that the limit of the sequence should be $\dfrac{1}{2}$ or $3$ . I want to prove that there exists $n\in \mathbb{N}$ s.t. $x_n=\dfrac{1}{2}$ if the sequence goes to $\dfrac{1}{2}$ . Similar if the sequence goes to $3$ . I tried by definition with $\epsilon$ but I didn’t succeed.,"['limits', 'convergence-divergence', 'recurrence-relations', 'sequences-and-series']"
3719066,Extending the Dirac delta to $L^p$,"In this question the Dirac delta is extended from $\mathcal C^0([-1,1])$ to $L^\infty([-1,1])$ by the Hahn-Banach theorem. My question is: why can't it be extended to an arbitrary $L^p([-1,1])$ for $p \geq 1$ ?","['hahn-banach-theorem', 'functional-analysis', 'dirac-delta']"
3719127,Show that $\exp\left(\frac{1}{x}\log\frac{e^{x}-1}{x}\right)$ is increasing.,"I want to show that $f(x)= \exp\left(\frac{1}{x}\log\frac{e^{x}-1}{x}\right),x>0$ is increasing. I figure that it is enough to show that $\frac{1}{x}\log\frac{e^{x}-1}{x}$ is increasing. The derivative is $$
\frac{e^{x}(x-1)+1-(e^{x}-1)\log(e^{x}-1)+(e^{x}-1)\log x}{x^{2}(e^{x}-1)},
$$ so I think I need to show that the numerator is positive. However, I got stuck there. I am guessing that the inequality $e^x-1\ge x$ would be useful, but have no idea how to use it.
How can I show that $f$ is increasing?","['calculus', 'derivatives', 'inequality']"
3719134,"Szemerédi Regularity Lemma - finding regular pairs of ""large"" size","The Szemerédi Regularity Lemma states that for every $\epsilon>0$ , there exists a constant $M$ (dependent only on $\epsilon$ ) such that every graph $G$ has a $\epsilon$ -regular partition of its vertex set into at most $M$ parts. If one follows the proof (or other discussion therein) closely, $M$ is actually an astronomically large quantity - basically, $M$ is of the order of $2^{2^{2^{\dots}}}$ where the height is polynomial in $1/\epsilon$ . Thus, by the time one reaches an $\epsilon$ -regular partition guaranteed by the lemma, the part sizes might be some vanishingly small fraction each. Can I do better if I want to find just one $\epsilon$ -regular pair of
subsets (not necessarily disjoint or distinct)? Specifically, is it
possible to find some $C>0$ such that for every sufficiently small $\epsilon$ (say for all $\epsilon < 1/4$ ), every graph contains some $\epsilon$ -regular pair of
vertex subsets (not necessarily disjoint/distinct) such that each is of size at least $(\frac{1}{2})^{(1/\epsilon)^C}|V(G)|$ ? I tried the following approach (which is based on one of the common ways of proving the Szemerédi Regularity Lemma): Let the graph $G$ be given. Start off with $X_0=Y_0=V(G)$ . If $(X_0,Y_0)$ is $\epsilon$ -regular, we are good for this graph $G$ . Otherwise, find $A_0\subset X_0, B_0 \subset Y_0$ which causes the regularity to be violated. Let $X_1$ be the larger of $X_0, X_0-A_0$ and $Y_1$ be the larger of $Y_0, Y_0-B_0$ . Then each of $X_1, Y_1$ is of size $\ge \frac{1}{2}|V(G)|$ . Once again check if $(X_1, Y_1)$ is $\epsilon$ -regular and repeat the above argument. The key then is to show that this process always terminates after a number of steps that is bounded above by polynomial in $1/\epsilon$ . However, this is where I am unable to proceed. I tried to track the energy between the two partitions at each step but the increase in energy is getting smaller geometrically (specifically, the energy between the partitions is guaranteed to increase by $\epsilon^4 (1/4)^k$ at step $k$ ). Thus there is no reason why the process must terminate. Another idea I have : By considering $G$ or its complement, we can reduce the problem to a bipartite graph with $\ge n(n-1)/8$ edges between the ""left"" and ""right"" parts, and the goal is to find a subset on the left and a subset on the right so that these two form a regular pair.","['graph-theory', 'additive-combinatorics', 'combinatorics']"
3719142,Find the surface of a triangle between two slopes and x axis,"Find the surface of the triangle between this two slopes and x axis. $$f(x)=x+1$$ $$g(x)=(3-2\sqrt{2})x$$ So : $\text{k}_1= \arctan(1)=45$ ° and $\text{k}_2=\arctan(3-2\sqrt{2})=?$ It's very hard to get this angle without a calculator, which I must not use. Then I tried: $$\tan(\psi)=|\frac{\text{k}_1-\text{k}_2}{1+\text{k}_2\text{k}_1}| $$ I got: $\psi=45$ °
So the angles are: $\alpha=45$ °, $\psi=45$ °, $\beta=90$ ° But how to get surface of the triangle only from these data? EDIT: Also the $\arctan(3-2\sqrt2)$ is not 90 degrees. This frustrates me? What should I do? Actually mathematica says it is: $\,9,736$ °","['trigonometry', 'calculus', 'geometry', 'real-analysis']"
3719161,"If $a+b+c=0, ab+bc+ca=1$ and $abc=1,$ then find the value of $\frac ab+\frac bc+\frac ca.$","Clearly $a, b, c$ are the roots of the cubic equation: $x^3+x-1=0\tag{1}.$ We have to find: \begin{align}
\frac ab+\frac bc+\frac ca&=\frac{a^2c+b^2a+c^2b}{abc}\\\\
&=a^2c+b^2a+c^2b\\\\
&=p,\text{ say}.
\end{align} ( $p$ is not a symmetric function of the roots.) Now let: $q=ac^2+ba^2+cb^2.$ Then we have: $0=\left(\sum ab\right)\left(\sum a\right)=p+s+3abc.$ This gives $p+q=-3abc=-3.$ To find $p$ I multiplied $p$ and $q$ and obtained: $pq=\sum a^3b^3+abc\left(\sum a^3\right)+3a^2b^2c^2.$ Now since $a, b, c$ are the roots of the Eq. $(1),$ so we can write: $pq=\sum(1-a)(1-b)+abc\left[\sum(1-a)\right]+3(abc)^2=3-2\sum a+\sum ab+abc\left[3-\sum a\right]+3(abc)^2=3-0+1+1×(3-0)+3×1^2=10.$ This implies $p, q$ are the roots of the quadratic: $\color{green}{t^2+3t+10=0.}$ Which on solving gives $\color{green}{t=\frac{-3\pm i\sqrt{31}}2\tag*{}.}$ Now my actual question is: between these two values of $t$ which one is $p$ and which one is $q$ ? Please suggest. Thanks in advance.","['cubics', 'algebra-precalculus']"
3719165,Where is the Schatten norm differentiable?,"Let $M_n$ be the space of real $n \times n$ matrices, and let $|\cdot|_p$ be the $p$ - Schatten norm on $M_n$ , for $p \neq 2$ . For $A \in M_n$ , $|A|_p=\big(\sum \sigma_i^p(A)\big)^{1/p}$ , where $\sigma_i(A)$ are the singular values of $A$ . Is $| \cdot |_p$ differentiable at any non-zero point $A \in M_n$ ? Is it smooth there? If not, at which points is it differentiable? I think that $| \cdot |_p$ is $C^{\infty}$ when restricted to $GL_n(\mathbb R)$ , since $|A|_p^p=\text{tr}(|A|^p)$ : The map $A \to |A|$ is smooth on $GL_n(\mathbb R)$ , I guess that the map $A \to A^p$ is smooth on the domain of symmetric matrices. (Is it really? I am not sure).","['multivariable-calculus', 'matrix-calculus', 'matrix-decomposition', 'real-analysis']"
3719191,Problem involving maximum and minimum of a continuous function,"Let $f:\mathbb{R}\to\mathbb{R}$ be a continuous function. We denote, for every $x\in\mathbb{R}$ , with $m(x)$ and $M(x)$ the minimum and maximum of $f$ on the interval $[x-1,x]$ . Show that, if $m(x)+M(x)=0,\forall x\in\mathbb{R}$ , then the functions $m$ and $M$ are constant. I have tried to prove that $f$ is periodic, but I didn't managed to do it; I'm not sure it's even true...","['analysis', 'real-analysis']"
3719214,"Trying to understand example, determine fx and fy","I´m trying to learn 2nd order Taylor but i cant understand the example i have. This is an example i have from a book, $$y´=\frac{y}{2}+x$$ $$-1\le x \le  1 $$ $$y(-1)=1$$ How does fx = 1 and fy = 1/2 ? $$f´(x,y)= fx+fyf = 1+\frac{1}{2}\left(\frac{y}{2}+x\right) = 1+\frac{y}{4}+\frac{x}{2}$$",['ordinary-differential-equations']
3719220,"Surface of revolution, arc length approximates distance?","Consider an even function $z=f(x)$ and the surface of revolution $S$ by the graph around $z$ -axis. If $f$ is a $C^1$ ( $C^2$ ) function with $f'(0)=0$ , then $S$ is a $C^1$ ( $C^2$ ) manifold with the chart $\phi :R^2\to S$ : $$
\phi(v,u)=(v\cos u, v\sin u, f(v)).
$$ If $S$ is equipped with the induced metric from $R^3$ , then it's a Riemannian manifold, the metric $g$ is continuous ( $C^1$ ). The geodesic equation is $$
u''+\frac{2u'v'}{v}=0,
$$ $$
v''-\frac{v}{1+(f')^2}(u')^2+\frac{f'f''}{1+(f')^2}(v')^2=0.
$$ Consider two points $$
s_1=(v_0,0,f(v_0)), s_2=(v_0\cos u, v_0\sin u, f(v)) \in S. 
$$ The arc of the parallel $u=u(s), v \equiv v_0$ from $s_1$ to $s_2$ is not a geodesic in general. Denote the length of the arc by $L(s_1,s_2)$ . So How to compute the distance from $s_1$ to $s_2$ ?  Do we have $$
\lim_{u\to 0}\frac{d(s_1,s_2)}{L(s_1,s_2)}=1?
$$","['riemannian-geometry', 'differential-geometry']"
3719225,"Proof of $\tan{x}>x$ when $x\in(0,\frac{\pi}{2})$","I have read Why $x<\tan{x}$ while $0<x<\frac{\pi}{2}$? If I want to get $\tan{x}\gt x$ instead of weaker inequality $\tan{x} \ge x$ . Do I need only to show that $\tan{x} \gt x$ when $x\to 0$ ? Because from @David Mitra 's picture, it is obvious to see $\tan{x}\gt x$ when $x$ is not near $0$ . Since $$\lim_{x\to 0}\frac{\tan{x}}{x}=1 \text{}$$ ,for $$\varepsilon=\frac{1}{n} \;\;\text{ where }n\in\Bbb N$$ ,
we can find $\delta \gt 0 $ s.t. $$\forall x \in (0,0+\delta)$$ ,
we have $$\frac{\tan{x}}{x}\gt1-\frac{1}{n}$$ Let $n\to \infty$ , we get $$\frac{\tan{x}}{x}\gt1$$ So $$\tan{x}\gt x \text{ when }x\in(0,\frac{\pi}{2})$$ Or someone has more analytical proof instead of geometric proof for $x\in(0,\frac{\pi}{2})$ ,  since I only prove the case $x$ is near the origin. Thanks for helping.","['trigonometry', 'real-analysis']"
3719243,Residue fields at points on $\mathbb{A}^n$,"Let $k=\bar k$ be a field. I'm trying to ""write down"" the residue fields at various points on $\mathbb{A}^n=\operatorname{Spec} k[x_1,\cdots, x_n]$ , but am having some trouble with the non-closed points. The definition I'm using is that residue field at a point $x$ on an integral scheme $X$ is the residue field of the local ring $\mathcal{O}_x$ . Thus, if $\mathfrak{p}$ is a point on the affine scheme $X=\operatorname{Spec} A$ then the residue field at $\mathfrak{p}$ is $A_\mathfrak{p}/\mathfrak{p}A_\mathfrak{p}$ , which is isomorphic to the fraction field of $A/\mathfrak{p}$ . On $\mathbb{A}^1=\operatorname{Spec} k[x]$ these fields are not hard to determine. The only points are the generic point $(0)$ and the closed points $(x-a)$ for $a\in k$ . Clearly the residue field at the generic point (i.e., the function field) is $k(x)$ and the residue fields at closed points are all just $k$ . Already for $\mathbb{A}^2$ , though, I'm finding this a bit trickier. The points in this case are again $(0)$ (generic), $(x-a,y-b)$ for $a,b\in k$ (closed), and $(f)$ for $f\in k[x,y]$ irreducible (nonclosed). The function field at the generic point is clearly $k(x,y)$ , and it's also not hard to see that the function fields at closed points are all $k$ . But what do we get for the function field at a nonclosed point $(f)$ ? I think this should come out to be an algebraic extension of a transcendence degree 1 extension of $k$ , but would like some clarification on this. My thoughts are as follows. Given $f\in k[x,y]$ irreducible, the function field, which we denote $k(f)$ , will be the fraction field of $k[x,y]/(f)$ . Setting $R=k[x]$ and $g(y)=f(x,y)\in R[y]$ , we have $k[x,y]/(f)=R[y]/(g(y))$ , which I believe is isomorphic to $R(\alpha)$ , where $\alpha\in \overline{k(x)}$ satisfies $g(\alpha)=0$ , i.e., is a root of a polynomial equation with coefficients in $k[x]$ . Thus, the fraction field of $k[x,y]/(f)$ should be an algebraic extension of $k(x)$ . Morally, this feels right to me in that the various function fields one obtains for $\mathbb A^2$ include transcendence degree 0,1,2 extensions of $k$ . What makes me somewhat skeptical is the choice $R=k[x]$ was completely arbitrary. The same reasoning would also show that $k(f)$ is an algebraic extension of $k(y)$ . In either case, $k(f)$ seems to be a trans. degree 1 extension of $k$ , but the degrees $[k(f):k(x)]$ and $[k(f):k(y)]$ need not be equal, which I find a bit disturbing. Can someone tell me what's going on here? In the general case $\mathbb{A}^n$ , what I expect then is that the function fields are again $k$ at the generic point, $k(x_1,\cdots, x_n)$ at the closed points, and ... transcendence degree $n-1$ extensions of $k$ at the nonclosed other points?","['affine-schemes', 'function-fields', 'algebraic-geometry', 'schemes']"
3719262,Is there an alternative way to show that a finite dimensional vector space is separable?,"I am aware of the proofs of properties of finite-dimensional vector spaces in functional analysis. These use the properties of normed spaces $(\mathbb R^{d},\lvert\lvert\cdot\rvert\rvert)$ and establish an isometric isomorphism to more general $d-$ dimensional vector spaces. Properties such as completeness, closedness and separability immediately follow. Particularly on the issue of separability, is there any other way to show that a finite-dimensional normed space is indeed separable without using this isometry?","['separable-spaces', 'normed-spaces', 'functional-analysis', 'real-analysis']"
3719278,Existence of non-randomized most powerful test,"Let $\Omega = \mathbb{R}^n$ and probability measures $\mathbb{P}\small{1}, \mathbb{P}\small{2}$ are absolutely continuous with regard to the Lebesgue measure. Does a non-randomized most powerful test exist if we test a hypothesis $H\small1 = \{\mathbb{P} = \mathbb{P}\small{1}\}$ with an alternative hypothesis $H\small2 = \{\mathbb{P} = \mathbb{P}\small{2}\}$ for every significance level $\alpha$ ?","['statistics', 'lebesgue-measure', 'probability-theory']"
3719291,$\int_0^\infty \frac{1}{1+x^4}dx$ using the Residue Theorem,"I'm trying to evaluate the integral $$\int_0^\infty \frac{1}{1+x^4}dx $$ using the Residue Theorem. My approach: Let's consider $$\oint_\Gamma f$$ with $f(z)=\frac{1}{1+z^4}$ and $\Gamma = \Gamma_1 + \Gamma_2$ , where: $\Gamma_1:[-R,R]\rightarrow \mathbb{C}$ , with $\Gamma_1(t)=t$ $\Gamma_2:[0, \pi] \rightarrow \mathbb{C}$ , with $\Gamma_2(t)=Re^{it}$ So basically $\Gamma$ is the semicircle centers in the origin with imaginary part greater or equal to zero. First we need to find the isolated singularities $\alpha_i$ of the function $f$ . This singularities are the solution of the equation $1 + z^4 = 0$ : Let's call: $\alpha_1 = \frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2}$ $\alpha_2 = -\frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2}$ $\alpha_3 = -\frac{\sqrt{2}}{2} - i \frac{\sqrt{2}}{2}$ $\alpha_4 = \frac{\sqrt{2}}{2} - i \frac{\sqrt{2}}{2}$ So now we have: $$\oint_\Gamma f = 2 \pi i \sum_i \text{Res}(f,\alpha_i) \text{Ind}_\Gamma(\alpha_i)$$ All singularities are poles of order one, with: $$\text{Res}(f,\alpha_i)=\frac{1}{1+4\alpha_i^3}$$ So we end up with: $$\oint_\Gamma f = 2 \pi i \sum_i \frac{\text{Ind}_\Gamma(\alpha_i)}{1+4\alpha_i^3} $$ Because of the shape of our curve $\Gamma$ we have that $\text{Ind}_\Gamma(\alpha_3)=\text{Ind}_\Gamma(\alpha_4)=0$ So we end up with: $$\oint_\Gamma f = 2 \pi i \underbrace{\left( \frac{1}{1+4\alpha_1^3} + \frac{1}{1+4\alpha_2^3} \right)}_{:=\xi} $$ Now we can work on the left side of this expression: $$\int_{\Gamma_1} f + \int_{\Gamma_2} f = 2 \pi i \xi$$ We have that: $$\int_{\Gamma_1}f = \int_{-R}^R \frac{1}{1 + t^4} dt$$ And we also know that $$\begin{align}
\int_{\Gamma_2}f &\leq \int_0^\pi \left|\frac{Rie^{it}}{1 + R^4e^{4it}} \right| dt
\\
\\ &= \int_0^\pi \frac{R}{\left|1 + R^4e^{4it}\right|}  dt
\\
\\ &= \int_0^\pi \frac{1}{\left| \frac{1}{R} + R^3e^{4it}\right|}  dt
\end{align}$$ If we let $R \to \infty$ we have that $\int_{\Gamma_1} f = \int_{-\infty}^\infty \frac{dt}{1 + t^4}$ and $\int_{\Gamma_2} f = 0$ and because $\int_{-\infty}^\infty \frac{dt}{1 + t^4} = 2 \int_{0}^\infty \frac{dt}{1 + t^4}$ , we end up with: $$\int_{0}^\infty \frac{dt}{1 + t^4} = \pi i \xi$$ The thing is that $\pi i \xi$ is a complex number, so what did I do wrong?","['complex-analysis', 'contour-integration', 'singularity', 'residue-calculus']"
3719364,"What does this mathematical sentence mean? ""Let $f(x)$ be a function defined on an interval that contains $x=a$, except possibly at $x=a$.""","What does this mathematical sentence mean? ""Let $f(x)$ be a function defined on an interval that contains $x=a$ , except possibly at $x=a$ ."" How can a function contain $x=a$ ""except possibly at $x=a$ ""? That is so illogical to me. This is an excerpt out of the definition for $\lim$ . I know there are questions here that have discussed this already, however I think my question is a bit different as it focuses more on the definition as to what it says in relation to limits. My main question, again, is: How can a function contain $x=a$ ""except possibly at $x=a$ ""?","['real-analysis', 'calculus', 'functions', 'definition', 'limits']"
3719365,A noncomplete inner product space may have a nonempty closed convex subset which does not have a unique element of minimal norm,"It is well known that if $H$ is a Hilbert space and $E$ is a nonempty closed convex subset of $H$ , then there is a unique element in $E$ of minimal norm, i.e., a unique element $x_0\in E$ such that $\|x_0\|=\min _{x\in E} \|x\|$ . (cf. Rudin's Real and Complex Analysis, Theorem 4.10) Its proof crucially uses completeness of $H$ . I'm wondering if this fails if $H$ is not complete, but equipped with an inner product. A counterexample when $H$ is a Banach sapce, is given in Counterexamples to a theorem in Rudin's book on elements of smallest norm in a closed convex sets in a Hilbert space . But in this counterexample, $C[0,1]$ is not an inner product space. Is there a counterexample for a noncomplete innerproduct space?","['inner-products', 'real-analysis', 'hilbert-spaces', 'linear-algebra', 'functional-analysis']"
3719441,"How to prove that the inverse of a continuous strictly monotone increasing function is continuous? (Terence Tao Analysis 1, Proposition 9.8.3)","I'm having some problems proving the inverse is continuous. The hint in the book is to use the standard epsilon-delta definition of continuity. I believe the easiest route is a proof by contradiction, but with all of the quantifiers in the statement, I may be incorrectly negating the statement I am trying to prove. Also, I have at my disposal the intermediate value theorem, which most of my proof relies on. Below is the proposition: Let $a < b$ be real numbers, and let $ f:[a, b] \to \mathbb{R} $ be a function which is both continuous and strictly monotone increasing. Then $f$ is a bijection from $[a, b]$ to $[f(a), f(b)]$ , and the inverse $f^{-1}: [f(a), f(b)] \to [a, b]$ is also continuous and strictly monotone increasing. Below is my attempt at a proof: Let $x_1, x_2 \in [a, b]$ be real numbers such that $f(x_1) = f(x_2)$ . From the trichotomy of the real numbers, we have that exactly one of the following is true: $x_1 = x_2$ , $x_1 < x_2$ , or $x_1 > x_2$ . Suppose $x_1 \not = x_2$ . Then, by definition of strictly increasing monotone functions, we have that $f(x_1) \not = f(x_2)$ . Thus, $x_1 = x_2$ , and $f$ is injective.
Now let $y \in [f(a), f(b)]$ be a real number. Then, by the intermediate value theorem, there exists a real number $c \in [a, b]$ such that $f(c) = y$ . Thus, $f$ is a surjection from $[a, b]$ to $[f(a), f(b)]$ . Since $f$ is both injective and surjective, we can conclude that $f$ is a bijection from $[a, b]$ to $[f(a), f(b)]$ .
To show that $f^{-1}$ is strictly monotone increasing, let $y_1, y_2 \in [f(a), f(b)]$ be real numbers such that $y_1 < y_2$ . Then,by the intermediate value theorem, there exist $x_1, x_2 \in [a, b]$ such that $f(x_1) = y_1$ and $f(x_2) = y_2$ . Since $f$ is strictly monotone increasing, we have $x_1 < x_2$ . Using the definition of an inverse, we have \begin{align*}f^{-1}(y_1) &= f^{-1}(f(x_1)) \\&= x_1 \\&< x_2 \\&= f^{-1}(f(x_2)) \\&=f^{-1}(y_2) \text{,}\end{align*} showing that $f^{-1}$ is strictly monotone increasing.
Finally, we will show that $f^{-1}$ is continuous. Let $y_0 \in [f(a), f(b)]$ be a real number, and let $\epsilon > 0 $ be a real number. As before, there exists a real number $x_0 \in [a, b]$ such that $f(x_0) = y_0$ . Likewise, for any real number $y \in [f(a), f(b)]$ , the intermediate value theorem tells us that there exists a real number $x \in [a, b]$ such that $f(x) = y$ . We want to show that there exists a $\delta > 0 $ such that $ | f^{-1}(y) -f^{-1}( y_0) | < \epsilon$ for all $y \in [f(a), f(b)]$ such that $|y - y_0| < \delta$ . This is equivalent to showing that there exists a $\delta > 0 $ such that $ | x - x_0 | < \epsilon$ for all $f(x) \in [f(a), f(b)]$ such that $|f(x) - f(x_0)| < \delta$ . Written in the order we are more accustomed to, this is equivalent to showing that there exists a $\delta > 0 $ such that $|f(x) - f(x_0)| < \delta$ for all $x \in [a, b]$ such that $|x - x_0| < \epsilon$ .
Suppose, for the sake of contradiction, that $f^{-1}$ is not continuous. That is, suppose for all $\delta > 0$ , there exists an $\epsilon > 0$ such that $|f(x) - f(x_0)| \ge \delta$ for all $x \in [a, b]$ such that $|x - x_0| < \epsilon$ . I am not really sure where to go from here, and I'm not certain I correctly negated the statement that the inverse of $f$ is continuous. Any help is greatly appreciated. P.S. This is not for any homework, just self study. I've never taken a class in analysis, so please feel free to point out anything I am doing wrong (or that is less than rigorous).","['epsilon-delta', 'analysis', 'real-analysis', 'continuity', 'inverse']"
3719464,Show that this set is empty,"Let $E$ be a $\mathbb R$ -Banach space, $v:E\to[1,\infty)$ be continuous and $v_i:[0,\infty)\to[1,\infty)$ be continuous and nondecreasing with $$v_1(\left\|x\right\|_E)\le v(x)\le v_2(\left\|x\right\|_E)\;\;\;\text{for all }x\in E,\tag1$$ $$v_1(a)\xrightarrow{a\to\infty}\infty\tag2$$ and $$av_2(a)\le C_1v_1^\theta(a)\;\;\;\text{for all }a>0\tag3$$ for some $C_1\ge0$ and $\theta\ge1$ . Now, let $$\rho_r(x,y):=\inf_{\substack{\gamma\:\in\:C^1([0,\:1],\:E)\\ \gamma(0)\:=\:x\\ \gamma(1)\:=\:y}}\int_0^1v^r\left(\gamma(t)\right)\left\|\gamma'(t)\right\|_E\:{\rm d}t\;\;\;\text{for }x,y\in E$$ for $r\in(0,1]$ . Let $r\in(0,1]$ , $k,\delta>0$ and $$B:=\left\{(x,y)\in E^2:\rho_1(x,y)<k\text{ and }\rho_r(x,y)\ge\delta\right\}.$$ How can we show that if $v_1^{r-1}(0)k<\delta$ , then $B=\emptyset$ ? I'm unsure how we should approach this task. However, let me note the following: Let $(x,y)\in B$ and $\varepsilon>0$ . By definition of the infimum, there is a $\gamma\in C^1([0,1],E)$ with $\gamma(0)=x$ , $\gamma(1)=y$ and $$\rho_1(x,y)\le\int_0^1v\left(\gamma(t)\right)\left\|\gamma'(t)\right\|_E\:{\rm d}t<\rho_1(x,y)+\varepsilon<k+\varepsilon\tag4.$$ In particular, since $v\ge1$ , $$\left\|\gamma(t)-x\right\|_E\le\int_0^t\left\|\gamma'(s)\right\|_E\:{\rm d}s<k+\varepsilon\tag5$$ for all $t\in[0,1]$ . Now, \begin{equation}\begin{split}\rho_r(x,y)&\le\int_0^1v^r(\gamma(s))\left\|\gamma'(s)\right\|_E\:{\rm d}s\\&\le\sup_{B_{k+\varepsilon}(x)}v^{r-1}\int_0^1v(\gamma(s))\left\|\gamma'(s)\right\|_E\:{\rm d}s\\&\le\sup_{B_{k+\varepsilon}(x)}v^{r-1}(k+\varepsilon)\\&=\left(\inf_{B_{k+\varepsilon}(x)}v\right)^{r-1}(k+\varepsilon),\end{split}\tag6\end{equation} but I'm not able to derive a contradiction from these observations. (Can we somehow extend $(6)$ to $\varepsilon=0$ ?) EDIT : Another useful fact seems to be that, since $r-1\in(-1,0]$ , we obtain from $(1)$ that $$v^{r-1}(z)\le v_1^{r-1}(\left\|z\right\|_E)\le v_1^{r-1}(0)\;\;\;\text{for all }z\in E\tag7.$$ EDIT 2 : Please take note of my related question: Bound length of a curve in a ball .","['curves', 'metric-spaces', 'continuity', 'functional-analysis', 'differential-geometry']"
3719470,"Continuity of the length operator from $C^0([a,b],X)$ to $\mathbb{R}$","Given $(X,d)$ metric space we define the length of a curve as follows : $$l(\gamma, [a,b])=\sup\limits\limits_{P \in \mathbb{P}([a,b])}l(\gamma,P)$$ ( $\mathbb{P}[a,b]$ is the set of all possible partition of $[a,b]$ ) Where for every partition $P \in \mathbb{P}([a,b])$ , $l(\gamma, P)=\sum\limits_{k=1}^n d(\gamma(x_k),\gamma(x_{k+1}))$ I would prove that this last one is continuous as operator from $C^0([a,b],X)$ to $\mathbb{R}$ . Trying with the definition didn't see how to end : Let $\gamma_{1},\gamma_{2}$ be such that given $P = (x_{i})_{i=1,\cdots,n+1}$ with $d_{\infty}(\gamma_{1},\gamma_{2}) < \delta$ I'd like to state that $$|l(\gamma_{1},P)-l(\gamma_{2},P)| \leq \sum\limits_{k=1}^{n} |d(\gamma_{1}(x_{k}),\gamma_{1}(x_{k+1}))-d(\gamma_{2}(x_{k}),\gamma_{2}(x_{k+1}))| < \epsilon$$ but I got stuck since triangle's inequality didn't see to bring me somewhere. Any help, solution or hint would be appreciated.","['continuity', 'general-topology', 'metric-spaces', 'curves']"
3719492,Explanation of Cardinal Arithmetic Used in Proving that bases of Vector spaces have the same cardinality.,"Let $V$ be a vector space with bases $B_1$ , $B_2$ . For all $b\in B_1$ there exists $U_b\subset B_2$ such that $U_b$ is finite and $b\in span(U_b)$ . Hence, $V=span(B_1)=span(\cup_{b\in B_1}U_b)$ . Since $B_2$ is a minimal spanning set this implies that $B_2=\cup_{b\in B_1}U_b$ . At this point, I use an intuition-istic argument to show that $|B_1|\leq |B_2|$ . i.e $$|B_2|=|\cup_{b\in B_1}U_b|\leq_{(1)} \sum_{b\in B_1}|U_b|\leq_{(2)} \sum_{b\in B_1}|\aleph_0|=_{(3)}|B_1||\aleph_0|=_{(4)}|B_1|$$ Using the same argument we can show that $|B_2|\leq |B_1|$ . Hence by Schröder-Bernstein, $|B_1|=|B_2|$ . I did a course on set theory once and would have come across the operations involved in cardinal arithmetic. However, that was a long time ago. Can someone care to state or elucidate the actual cardinal operations or theorems involved in the argument above? Thanks.","['elementary-set-theory', 'cardinals', 'linear-algebra', 'vector-spaces']"
3719516,"$ \mathbb{P}( \xi_n > \frac{n}{2}) \geq \delta. $, where $\xi_n$ denotes the number of $X_i$s for which $ \sqrt{n} \leq i \leq n$ and $X_i \geq 1$","Suppose that $X_1, X_2, \ldots $ are mutually independent and $X_i$ has the following density function: $$
f_i(x)= 
\begin{cases}
\frac{|x|}{i^2} , \ \  0 \leq |x| \leq  i, \ i=1,2, \ldots \\
0, \ \ \text{sonst}
\end{cases}
$$ Then it is clear, that $$
\mathbb{P}(X_i \geq 1)= \frac{1}{2} - \frac{1}{(2i^2)},  \ \  i=1,2,\ldots
$$ Denote by $\xi_n$ the number of $X_i$ s for which $ \sqrt{n} \leq i \leq n$ and $X_i \geq 1$ . Why follows from this, by an application of the central limit theorem, that for some $ \delta \in (0,1/2)$ we have: $$
\mathbb{P}( \xi_n > \frac{n}{2})  \geq \delta.
$$ for $n$ sufficently large ?","['probability-theory', 'probability']"
3719529,Group of order 45 is abelian,"I am trying to prove that the inverse of Lagrange Theorem holds for a group $|G|$ of order $45$ and that it contains a subgroup of order $3$ . I think I proved that $G$ is abelian and therefore the inverse of Lagrange holds but I am not so sure about my proof.
So, since $45=5\times 3^{2}$ we can easily prove that there is a unique 5-Sylow subgroup of order 5 (let's call this $H$ ) and a unique 3-Sylow subgroup of order 9 (let's call this $K$ ), both of which are normal. (They are also abelian since $|H|=5$ , prime and thus cyclic and $|K|=9=3^{2}$ and we know that every group of order $p^{2}$ is abelian.) Now since they are normal $HK$ is a subgroup of $G$ and since $5$ , $9$ are coprime we have that $H\cap K= \{1_{G} \}$ . Thus, since $$|HK|=\frac{|H||K|}{|H\cap K|} $$ we have that $HK=G$ . Now we prove that $HK$ is abelian. Firstly, we have $hk=kh$ $\forall h\in H, k\in K$ . Indeed we have that $(h,k)=hkh^{1}k^{-1} \in H$ and $ (h,k)\in K$ beacause $H, K$ are normal and thus $(h,k)\in H\cap K =\{1_{G}\}$ . Now, if $g_{1}=h_{1}k_{1}, g_{2}=h_{2}k_{2} \in G$ then $$g_{1}g_{2}=h_{1}k_{1}h_{2}k_{2}=h_{2}k_{2}h_{1}k_{1}=g_{2}g_{1}$$ using the fact that $H,K $ are abelian and that $hk=kh$ . Therefore $G$ is abelian. Then to prove that there is a subgroup of order $3$ we find the non isomorphic abelian groups of order $45$ which are $G_{1}=\mathbb{Z_{5}}\times\mathbb{Z_{9}}\cong\mathbb{Z_{45}}$ and $G_{2}=\mathbb{Z_{5}}\times\mathbb{Z_{3}}\times\mathbb{Z_{3}}$ which both have $\mathbb{Z_{3}}$ of order $3$ as a subgroup. Is my proof correct?
Thank you in advance for your time.","['group-theory', 'sylow-theory', 'abelian-groups']"
3719620,"Proving $SL_2(\Bbb R)$ has no finite dimensional, non-trivial unitary representations using these hints","Show that $G=SL_2(\Bbb R)$ has no finite dimensional unitary representations except the trivial one. Let $A(t)=\begin{pmatrix}1 &t\\0 &1\end{pmatrix}, \forall t \in \Bbb R$ .
Steps to follow : (1) For $m \in \Bbb N$ show $$\begin{pmatrix}m &0\\0 &m^{-1}\end{pmatrix} A(t){\begin{pmatrix}m&0\\0 &m^{-1}\end{pmatrix}}^{-1}=A(m^2t)={A(t)}^{m^2}$$ (2) Let $\phi : G \to U(n)$ be a representation. Show that the eigenvalues of $\phi(A(t))$ are a permutation of their $m$ -th powers for every $m \in \Bbb N$ . Conclude that they all must be equal to 1. (3) Show that the normal subgroup of $G$ generated by $\{A(t):t \in \Bbb R\}$ is the whole group. I've verified the computation in Step(1) But am a bit confused about the statement made in Step (2). What does the Authors actually intend to say by ""the eigenvalues of $\phi(A(t))$ are a permutation of their $m$ -th powers for every $m \in \Bbb N$ "" ? EDIT : And for Step(3), According to Derek Holt's comment in a linked question : The group $PSL_2(𝐾)$ is simple for any field $𝐾$ with $|𝐾|>3$ , so in particular $PSL_2(ℝ)$ is simple. So the only normal subgroups of $SL_2(ℝ)$ are the trivial group, the whole group, and its centre $\{\pm I_2\}$ . So the normal subgroup generated by $𝐴(𝑡)$ is indeed the whole group. And for the conclusion, Exodd's comments resolve it completely. Thanks everyone for discussing and helping me solve this question :) Just a short comment: There are statements like ""An irreducible finite-dimensional representation of a noncompact simple Lie group of dimension greater than 1 is never unitary"" which would give the result immediately, but I want to prove the statement in the Question ONLY as in the instruction/hints given in the question!","['harmonic-analysis', 'representation-theory', 'linear-algebra', 'group-theory', 'locally-compact-groups']"
3719641,"About lemma 5.6.2 of Szamuely's ""Galois groups and fundamental groups"": descending etale morphisms.","I am working with Tamas Szamuely's book ""Galois groups and Fundamental groups"", and there is a point I am unsure in the proof of Lemma 5.6.2 The context is the following: $X$ is a quasi-compact and geometrically integral scheme (I think the second assumption might be irrelevant to the lemmma) over a field $k$ . Let's fix $\overline{k}$ an algebraic closure of $k$ and $k_s$ a separable closure of $k$ sitting inside $\bar{k}$ . Let $\overline{X}$ be the scheme $X \times_{\mathrm{Spec}(k)} \mathrm{Spec}(k_s)$ . Then lemma 5.6.2 states the following: Given a finite étale cover $\overline{Y} \to \overline{X}$ , there exists a finite subextension $L|k$ of $k_s$ , and an étale cover $Y_L$ of $X_L := X_k \times_{\mathrm{Spec}(L)}\mathrm{Spec}(k_s)$ , such that $\overline{Y} \cong Y_L \times_{\mathrm{Spec}(L)}\mathrm{Spec}(k_s)$ I interpret this lemma in the following way: since $k_s$ is the union of its finite subextensions, then $\mathrm{Spec}(k_s)$ can be viewed as the projective limit of the schemes $\mathrm{Spec}(L)$ where $L$ runs over the finite subextensions of $k_s$ . The lemma then says that any finite étale cover of $\overline{X}$ actually comes from an étale cover of a subextension. The proof goes this way: Since $X$ is quasi-compact, cover it by a finite number of affines $U_i = \mathrm{Spec}(A_i)$ . Pullback these affines to $k_s$ to get a cover $\overline{U_i} = \mathrm{Spec}(A_i \otimes_k k_s)$ of $\overline{X}$ . Now if $f : \overline{Y} \to \overline{X}$ is a finite etale morphism, then $f^{-1}(\overline{U}_i) = \mathrm{Spec}(B_i)$ where $B_i$ is some finite $A_i \otimes_{k} k_s$ algebra, so we can write $\mathrm{Spec}(B_i)$ as a quotient of $(A_i \otimes_k k_s)[x_1,\ldots,x_n]$ . Now the author claims that this quotient is generated by a finite number of polynomials. And that's where I am starting to have doubts. That would certainly be true if $A_i \otimes_k k_s$ were a noetherian ring, but with the given hypothesis, $A_i \otimes_k k_s$ is just an integral ring over $k_s$ , so it has no reason to be noetherian, that would also be true if $B_i$ was of finite presentation over $k_s$ . Going on with that, the author takes a finite number of polynomials generating all of these algebras, and then take the subextenstion of $k_s$ generated by their coefficient. The author then claims the same can be done on the overlaps $U_i \cap U_j$ and that the isomorphisms $\overline{Y}_{U_i} \times_{X_i} \overline{Y}_{U_j} \cong \overline{Y}_{U_i \cap U_j}$ is defined by a finite number of equations, and that by taking an extension generated by the coefficients, we are done. Once again, I have doubts, to me, it is not clear that the overlaps are defined by a finite number of equations. I have looked in EGA, and EGA $IV_4$ 17.7.8 (plus EGA $IV_3$ 8.10.5 (x) for finiteness) states basically this lemma (that one can descend an etale morphism of a projective limit to an etale morphism at some index of the limit), but under the assumption that the morphisms of the components of the limit to the base schemes are of finite presentation. I have the feeling that this is a crucial hypothesis that have been forgotten in Szamuely's lemma, since in that case then indeed at least the ideals giving the $B_i$ 's would be finitely generated. So, first question : am I right in assuming that this hypothesis have been forgotten or is there some point that I missed? Secondly: even in the case of finite presentation, the part concerning the overlaps of the $\overline{Y}_{U_i}$ is unclear to me. If the intersection $U_i \cap U_j$ is affine or just quasi-compact, then it is clear using the same method as above (writing it all in terms of a finite number of polynomial or covering by a finite number of things that can be written in terms of a finite number of polynomial, then taking the subextension generated by all the coefficients). But that would need some separation or quasi-separation hypothesis on $X$ . The morphism $f$ is affine since it's finite, so it is separated, so that much might be useful when dealing with the inverse image of the intersection $\overline{U_i} \times_{\overline{X_i}} \overline{U_j}$ . But without some separation hypothesis, I do not see how to phrase the fact the the $\overline{Y}_{U_i}$ are compatible on the overlaps $U_i \cap U_j$ only using a finite number of coefficients, though it is surely possible since the proposition in EGA do not need such hypothesis. Edit : I looked up in SGA I, there are no equivalent of lemma 5.6.2 in there. Szamuely's lemma 5.6.2 is used in the proof of the homotopy exact sequence for the etale fundamental group, which is SGA I IX 6.1. The hypotheses in SGA are the same as Szamuely's. So I might really be missing something here. The proof in SGA uses the fact that $\pi_1(\overline{X}, \overline{s}) = \varprojlim\pi_1(X_L, \overline{s_L})$ , claiming this is essentially the fact that an étale cover of $\overline{X}$ comes from an étale cover of some $\overline{X}_L$ for sufficiently large $L$ . Sadly for me, this fact is left to the reader in SGA I. Edit 2: After some reflexion, I think that $f$ being locally of finite presentation (since it is etale) is enough to at least claim that each of the affines $\mathrm{Spec}(B_i)$ can be covered by a finite number spectras of $A_i \otimes_k k_s$ -algebras of finite presentation, and so we can get away with ""finitary"" data as wanted. I still need to see if this work on the overlaps. Edit 3: Thanks to KReiser, the fact that the ideals defining $B_i$ is finitely generated is solved. The compatibility on overlaps remains open. On the confusing side, the homotopy exact sequence is stated in the Stacks Project ( https://stacks.math.columbia.edu/tag/0BTX ) with the additionnal assumption that $X$ is quasi-separated, which would solve the issue (see the comments in KReiser's answer), so there might be a forgotten hypothesis in Szamuely's book (but then also in SGA), and I don't know what to believe anymore.","['algebraic-geometry', 'schemes']"
3719652,The product of continuous function is continuous.,"Statement Let be $A$ , $B$ , $C$ and $D$ topological spaces and let be $\phi:A\rightarrow C$ and $\psi:B\rightarrow D$ two continuous function. So the product function $\Delta:A\times B\rightarrow C\times D$ defined through the condition $$
\Delta(a,b):=\big(\phi(a),\psi(b)\big)
$$ for any $(a,b)\in A\times B$ is continuous in the product topology. Clearly $\pi_A\big(\Delta(a,b)\big)=\phi(a)$ and $\pi_B\big(\Delta(a,b)\big)=\psi(b)$ but $\pi_A\circ\Delta: A\times B\rightarrow A$ and $\pi_B\circ\Delta:A\times B\rightarrow D$ whereas $\phi:A\rightarrow C$ and $\psi: B\rightarrow D$ so I think that I can't use the universal mapping theorem for products to claim that $\Delta$ is continuous. So could someone help me, please?","['continuity', 'general-topology', 'product-space']"
3719660,Extension of the Continuous Dependence Theorem (ODE),"Exercise: Let $(M, d_M)$ be a metric space and $F: \mathbb{R}^{1+d} \times M \rightarrow~\mathbb{R}^{d}$ a limited function, lipschitz on the second variable and uniformly continuous on the following distance: $$d((t, x, \lambda), (s, y, \mu)) = |t-s| + ||x-y|| + d_M(\lambda, \mu),$$ i.e, given $\epsilon > 0$ , there exists $\delta >0$ such that $$||F(t,x, \mu) - F(s,y,\lambda)|| < \epsilon, \text{whenever} \hspace{0.15cm} d((t,x,\mu), (s,y,\lambda)) < \delta.$$ Fixe $(t_0, x_0) \in \mathbb{R}^{1 + d}$ and let $t \mapsto \gamma_\lambda(t)$ be the maximal solution of $x'~=~F(t,x,\lambda)$ with initial condition $\gamma_\lambda(t_0) = x_0$ . Show that $\gamma_\lambda(t)$ is continuous on the parameter $\lambda$ : given $t \in \mathbb{R}$ and $\epsilon > 0$ , there exists $\delta > 0$ such that $$||\gamma_\lambda (t) - \gamma_\mu (t) || < \epsilon, \text{whenever} \hspace{0.15cm} d_M (\lambda, \mu) < \delta.$$ Attempt: Consider $(t_0, x_0) \in \mathbb{R}^{1+d}$ and let $t \mapsto \gamma_{\lambda}(t)$ be the maximal solution of the diferential equation $x' = F(t,x, \mu)$ , with initial condition $\gamma_{\lambda}(t_0) = x_0$ . Let $t \geq t_0$ and $\epsilon > 0$ . The following proof is completely analogous for $t \leq t_0$ . Considering $\lambda, \mu$ in the metric space $(M, d_M)$ , due to Picard's Theorem, we have $$\gamma_{\lambda} (t) = x_0 + \displaystyle\int_{t_0}^t F(s, \gamma_{\lambda}(s), \lambda) ds \hspace{0.15cm} \text{and} \hspace{0.15cm} \gamma_{\mu} (t) = x_0 + \displaystyle\int_{t_0}^t F(s, \gamma_{\mu}(s), \mu) ds,$$ with $\gamma_{\mu}(t)$ solution of $x' = F(t,x, \mu)$ , with initial condition $\gamma_{\mu} (t_0) = x_0$ . Therefore, $ \begin{array}{ccl} || \gamma_{\lambda}(t) - \gamma_{\mu}(t)|| & = & || \displaystyle\int_{t_0}^t \left[ F(s, \gamma_{\lambda}(s), \lambda) - F(s, \gamma_{\mu}(s), \mu) \right] ds || \\ & \leq & \displaystyle\int_{t_0}^t || F(s, \gamma_{\lambda}(s), \lambda) - F(s, \gamma_{\mu}(s), \mu) || ds \\ & = & \displaystyle\int_{t_0}^t ||F(s, \gamma_{\lambda}(s), \lambda) - F(s, \gamma_{\mu} (s), \lambda) +  F(s, \gamma_{\mu} (s), \lambda) - F(s, \gamma_{\mu}(s), \mu) || ds.          \end{array}$ It follows that $ \begin{array}{ccl} || \gamma_{\lambda}(t) - \gamma_{\mu}(t)|| & \leq & \displaystyle\int_{t_0}^t ||F(s, \gamma_{\lambda}(s), \lambda) - F(s, \gamma_{\mu} (s), \lambda) || ds + \displaystyle\int_{t_0}^t ||F(s, \gamma_{\mu} (s), \lambda) - F(s, \gamma_{\mu}(s), \mu) || ds.\end{array}$ Note that, since $F$ is lipschit on the second variable, there exists $C > 0$ such that $$ || F(t, x_1, \mu) - F(t, x_2, \mu)|| < C ||x_1 - x_2||, \hspace{0.1cm} \forall \hspace{0.1cm} (t, x_1, \mu), (t, x_2, \mu) \in \mathbb{R}^{1+d} \times M. $$ We also know that $F$ is uniformly continuous on the distance $d$ , so given $\epsilon'$ , there exists $\delta > 0$ such that $$||F(t,x, \mu) - F(s, y, \lambda)|| < \epsilon',$$ whenever $d((t,x,\mu), (s,y,\lambda)) < \delta$ . For $t=s$ e $x=y$ , by the definition of the distance $d$ , we get that $$d_M(\lambda, \mu) < \delta \Rightarrow ||F(t,x,\mu) - F(t,x,\lambda)|| < \epsilon'.$$ From the information above mentioned, whenever $d_M(\lambda, \mu) < \delta$ ,  we have $ \begin{array}{ccl} || \gamma_{\lambda}(t) - \gamma_{\mu}(t)|| & \leq & \displaystyle\int_{t_0}^t ||F(s, \gamma_{\lambda}(s), \lambda) - F(s, \gamma_{\mu} (s), \lambda) || ds +  \displaystyle\int_{t_0}^t ||F(s, \gamma_{\mu} (s), \lambda) - F(s, \gamma_{\mu}(s), \mu) || ds \\ & < & \displaystyle\int_{t_0}^t C || \gamma_{\lambda} (s) - \gamma_{\mu}(s) || ds + \displaystyle\int_{t_0}^t \epsilon' ds \\ & = & \displaystyle\int_{t_0}^t C ||\gamma_{\lambda}(s) - \gamma_{\mu}(s)|| ds + \epsilon' (t-t_0). \end{array}$ Since $t \geq t_0$ , the function $\epsilon' (t-t_0)$ is continuous and not decreasing. Therefore, we can apply Gronwall's Lemma for the function $||\gamma_{\lambda}(t) - \gamma_{\mu}(t)||$ . So, $$ || \gamma_{\lambda}(t) - \gamma_{\mu}(t)|| <  \epsilon' (t-t_0) e^{\displaystyle\int_{t_0}^t C ds}  =  \epsilon' (t-t_0)e^{C(t-t_0)}.$$ How do I take a proper $\epsilon'$ in order to make $||\gamma_{\lambda}(t) - \gamma_{\mu}(t)|| < \epsilon$ ? Does it somehow follow from the hypotesis that F is limited? I didn't use it so far. Any help would be appreciated!","['analysis', 'ordinary-differential-equations', 'dynamical-systems']"
3719661,Ways to write $n=p^k$ as a product of integers,"Let's say that $F(n)$ is the number of ways to write $n$ as a product of integers greater than $1$ . For example, $F(12)=4$ since $12=2\cdot 2 \cdot 3$ , $12=2\cdot 6$ , $12=3\cdot 4$ and $12=12$ . Given $n=p^k$ where $p$ is a prime number, what is the value of $F(n)$ ? I know how to manage this problem when $n=p_1\cdots p_k$ where $p_1,\ldots , p_k$ are different primes (the result is $B(k)$ , where $B(n)$ is the Bell-Number), but how can I do it in this case? Note : The order of the factors does not matter; that is, $a\cdot b$ and $b \cdot a$ do not count as different ways to write a number","['combinatorics', 'discrete-mathematics']"
3719780,On the proof of $\;(1+x)^p\equiv1+x^p \pmod p$,"I know the proof for $(1+x)^p\equiv 1+x^p\mod p$ using the binomial theorem. Moreover, I know that $x^p \equiv x \mod p$ due to Fermat's theorem. Hence, is $(1+x)^p\equiv(1+x)\equiv1+x^p \mod p$ a correct proof of this relation? After thinking about it for a bit, one of the proof of Fermat's theorem uses the binomial theorem so my comments might have been redundant (although Fermat's theorem can be deduced from Lagrange's theorem). I guess you can try to prove Fermat's by Pigeon hole: Assuming $a\not\equiv 0$ $$a^i,\;\;1\le i \le p$$ takes $p$ values but $\mod p$ can only take $p-1$ distinct values ( $a^p \not \equiv 0$ unless $a=0$ ) and so $a^i\equiv a^j$ and take inverses and the rest follows. If $a\equiv 0$ , then the statement follows. This can be extended to $(1+x)^{p^n}\equiv (1+x^{p^n})$ without using induction since $p |p^n$ , then $$(1+x)^{p^n}\equiv (1+x)^{p\cdot{p^{n-1}}}\equiv 1+x \equiv 1+x^{p^n}$$ I have a gut feeling that says I overlooked something important. If this is correct, what additional instructive value does the proof using the binomial theorem has that the Fermat's proof doesn't? PS: I don't know what to say on the title. Feel free to edit it.","['field-theory', 'number-theory', 'abstract-algebra']"
3719894,Limit $\lim _{x \to 0}\sqrt {x+\sqrt {x+\sqrt{x+\sqrt{x...}}}}=1$,"I've been investigating some interesting infinite square roots, and I've arrived at the hypothesis that $$\lim_{x\to 0}\sqrt {x+\sqrt {x+\sqrt{x+\sqrt{x...}}}}=1$$ However, I have tried to prove this but have found myself unable to do so. For example, I've tried re-writing this as $$1=\sqrt{x+1}$$ so $1=x+1$ , which leads us to $x=0$ , which doesn't exactly work- replacing $x$ with $0$ yields a value of $0$ . That's another side point: obviously the method I just used yields an incorrect result, but where is the maths flawed? Please could you either prove or disprove my hypothesis? Thank you in advance.","['limits', 'calculus', 'real-analysis']"
3719924,"If $T:X\to X$, $X$ is a Banach space, and $T$ linear, maps closed sets onto closed sets. Can I say that $T$ has a closed graph?","I know if $X$ were to incomplete space such as $c_{00}$ $X$ is a normed vector space and $T:X\to X$ is a function that has a closed graph, does $T$ map closed sets to closed sets? the hypothesis does not hold but what about if $X$ were to be a Banach space? My thought is $R(T)$ would be a Banach space too because it is a closed subset of a complete metric space. Therefore for $x_n\to x$ and $Tx_n\to y$ since the range is complete $y=Tx$ (but I think I need injectivity of $T$ , as well.)",['functional-analysis']
3719946,Coin Flip Problem,"So my friend gave me this question this other day, and I've tried to start it (I'll show my logic below), but I couldn't find any efficient way to do the problem. You start out with 1 coin. At the end of each minute, all coins are flipped simultaneously. For each heads that is flipped, you get another coin. But for every tails that is flipped, a coin is lost. (Note any new coins are not flipped until the next moment). Once there are no more coins remaining, the process stops. What is the probability that exactly after 5 minutes (that's 5 sets of flips), that the process will have stopped (so no earlier or no later)? I've taken a few approaches to this problem. What I've tried to do is to find the total amount of possibilities for each amount of coins by the 5th moment, and then multiply that by the probability that all coins will be vanished on the 5th moment. But I'm just not able to calculate how many possible ways exist to get to each amount of total coins by the end. Does anyone have any other ideas, or perhaps a formula to solve this problem?","['combinations', 'combinatorics', 'probability']"
3719947,"Show for some subsets of $G$ we have subgroups of $(G, \ast)$","Let $G$ be an abelian group. Show that for the following subsets $H_n$ , we have subgroups of $G$ . $H_1= \lbrace g \in G | g^n=e \rbrace $ , with $n$ being a certain fixed natural number. $H_2 = \lbrace g \in G | g^{-1}=g \rbrace$ $H_3 = \lbrace g \in G | g=x^2 $ for a $x \in G \rbrace$ For $H_1$ : $e \in H_1$ is obvious. Let be $k \in H_1$ , so $k^n=e\Longleftrightarrow k \ast(k)^{n-1}=e\Longleftrightarrow k^{-1}=(k)^{n-1}$ We need to show that $(k)^{n-1} \in H_1$ So we show: $((k)^{n-1})^n=e$ $((k)^{n-1})^n=\underbrace{k^{n-1}\ast k^{n-1} \ast...\ast k^{n-1}}_{n}=\overbrace{\underbrace{k^{n}\ast k^{n} \ast...\ast k^{n}}_{n-2}\ast \underbrace{k^{n-1}\ast k^{1}}_{=e}}^{\text{Since $\ast$ 
is associative}}=\underbrace{e\ast e \ast...\ast e}_{n-2}\ast e=e$ $\Longrightarrow \forall k \in H_1:k^{-1} \in H_1$ We show $\forall k,t \in H_1: k\ast t \in H_1$ : To show that we need to show: $(k \ast t)^n = e$ $(k \ast t)^n=\underbrace{(k \ast t) \ast (k \ast t) \ast ... \ast (k \ast t)}_{n}=\overbrace{\underbrace{(k \ast... \ast k \ast k)}_{n} \ast \underbrace{(t \ast ...\ast t \ast t)}_{n}}^{\text{since $(G,\ast)$ is associative and kommutative}}=k^n\ast t^n=e \ast e= e$ $\Longrightarrow \forall k,t \in H_1: k\ast t \in H_1$ $\Box$ For $H_2$ : $e \in H_2$ is obvious. Let $k \in H_2 \Longrightarrow k=k^{-1}\Longrightarrow \forall k \in H_2:k^{-1} \in H_2$ We now show that $\forall k,t \in H_2: k \ast t \in H_2$ : In order for $k \ast t \in H_2$ , $\,\,\,(k \ast t)=(k \ast t)^{-1}$ has to hold! Here again the kommutativity of $(G,\ast)$ plays a role! $k \ast t \ast k^{-1} \ast t^{-1}= k \ast t \ast t^{-1} \ast k^{-1}=k \ast e \ast k^{-1}= k \ast k^{-1}=e$ This tells us indeed: $(k\ast t)^{-1}=k^{-1}\ast t^{-1}=k \ast t= (k \ast t)$ $\Box$ For $H_3$ : Again $e=e^2 \Longrightarrow e \in H_3$ Let $k \in H_3 \Longrightarrow k = x^2$ for some $x \in G$ Then $k^{-1}=(x^2)^{-1}$ which is again since we have an abelian group $(x^2)^{-1}=(x^{-1})^2=k^{-1}$ $\Longrightarrow \forall k \in H_3:k^{-1} \in H_3$ We now show $\forall k,t \in H_3: k\ast t \in H_3$ : $k \ast t= x^2 \ast y^2$ with $x,y \in G$ $k \ast t= x^2 \ast y^2=x \ast x \ast y \ast y= x \ast y \ast x \ast y=(x\ast y)^2 \longleftarrow$ because its still an abelian group Since $x,y \in G \Longrightarrow x \ast y \in G$ Let $(x \ast y):= z$ $\Longrightarrow k \ast t=z^2$ $\Longrightarrow \forall k,t \in H_3: k\ast t \in H_3$ $\Box$ It would be great if someone could look over it and give me some feedback :)","['abelian-groups', 'group-theory', 'abstract-algebra', 'solution-verification']"
3720000,"How do I solve $ f(y) \int_0^1 \tfrac{\exp(-\frac{(x-y)^2}{2})}{\int_0^1 \exp(-\frac{(x-z)^2}{2}) f(z) dz}\,dx =1$?","I am trying to solve this integral equation for $f$ (can be assumed to be positive) $$ f(y) \int_0^1 \frac{e^{-\frac{(x-y)^2}{2}}}{\int_0^1 e^{-\frac{(x-z)^2}{2}} f(z) dz} dx =1, \quad y \in [0,1]$$ Any insight is welcome, I have no idea how this kind of equations is called and how to solve them. I thought about differentiating both side with regard to $y$ , we get $$f(y)\int_0^1 \frac{(x-y)e^{-\frac{(x-y)^2}{2}}}{\int_0^1 e^{-\frac{(x-z)^2}{2}} f(z) dz} dx + f'(y)\int_0^1 \frac{e^{-\frac{(x-y)^2}{2}}}{\int_0^1 e^{-\frac{(x-z)^2}{2}} f(z) dz} dx  =0$$ Plugging in the first equation, we get $$ f(y)\int_0^1 \frac{xe^{-\frac{(x-y)^2}{2}}}{\int_0^1 e^{-\frac{(x-z)^2}{2}} f(z) dz} dx -y + \frac{f'(y)}{f(y)} = 0$$ But it only seems to make the problem harder. EDIT: As this question seems to interest some people, here is some more info. We can rewrite the problem as a system of two integral equations: $$ f(y) \int_0^1 e^{-\frac{(x-y)^2}{2}} \hat f(x) dx =1, \quad y \in [0,1]$$ $$ \hat f(x) \int_0^1 e^{-\frac{(x-y)^2}{2}} f(y) dy =1, \quad x \in [0,1]$$ The existence of solutions $f,\hat f$ is a deep result in stochastic processes and probability theory. The trained eye recognized the heat kernel (Brownian transition density). The product $f(y)\hat f(x)$ is actually the density (not w.r.t Lebesgue, it's complicated) of a certain coupling of 2 given random variables. So $f,\hat f$ contain all the information about the dependence between those 2 random variables. They are unique up to multiplicative constant (when you multiply one by $c$ , you divide the other one by $c$ )","['integration', 'ordinary-differential-equations', 'analysis', 'real-analysis', 'functional-analysis']"
3720012,"Show that $E(|S_n-np|) = 2vq b(v; n, p) $.","(Feller Vol.1, P.241, Q.35) Let $S_n$ be the number of successes in $n$ Bernoulli trials. Prove $$E(|S_n-np|) = 2vq b(v; n, p) $$ where $v$ is the integer such that $np < v \le np+1$ and $b(v; n,p)$ is a binomial distribution with $v$ successes of $n$ trials. Hint: The left side $= \sum_{k=0}^{v-1} (np - k) \frac{n}{k} p^k q^{n-k}$ . My attempt: I found that $P(|S_n - np| = j)= b(np +j ; n, p)$ if $S_n \ge np$ , $b(np-j; n,p)$ if $S_n < np$ . Therefore, $$E(|S_n-np|)= \sum_{k=0}^{v-1} (np-k)b(k;n,p) + \sum_{k=v}^{n}(k-np)b(k; n,p).$$ I am stuck here, and don't know how to proceed. I would appreciate if you give some help.","['probability-distributions', 'binomial-distribution', 'probability']"
3720027,"Is the set $\{\langle \varnothing, a \rangle ,\langle \{ \varnothing \}, b \rangle \}$ considered as function?","The set defined as $$F=\{\langle\varnothing,a \rangle, \langle \{\varnothing\},b\rangle\}$$ a function?",['elementary-set-theory']
3720033,"If $a\frac {dy}{dx} + by = c$ has constant coeffcients, does that means that $a=b=c$?",I am trying to identify if a differential equation has constant coefficients. Let $A = a\dfrac {dy}{dx} + by = c$ The $A$ has constant coefficients only if $a=b=c$ correct?,"['definition', 'ordinary-differential-equations']"
3720038,Prove that if $A \subseteq B$ and $A \subseteq C$ then $A \subseteq B \cap C$.,"Is the proof of this statement correct? Currently in high school—so I'm kinda new to this—and working through ""How to Prove It: A Structured Approach""(3rd Edition) by Daniel J. Velleman. Prove that if $A \subseteq B$ and $A \subseteq C$ then $A \subseteq B \cap C$ . Scratch work. Quantified: $$(\forall x) [((x \in A \to x \in B) \wedge (x \in A \to x \in C)) \to (( x \in A \to x \in B) \wedge x \in C))]. $$ So, we assume: $(x \in A \to x \in B)$ , $ (x \in A \to x \in C))$ and $ x \in A$ , since they're the preceding statements in the conditionals. Hence we have to prove that $x \in B$ and $x \in C$ . Since we can suppose that $x \in A$ , then, by modus ponens, $x \in B $ and $x \in C$ . Theorem.
Suppose A, B, and C are set. If $A \subseteq B$ and $A \subseteq C$ then $A \subseteq B \cap C$ . Proof.
Let $x$ be arbitrary. Suppose $x \in A$ , $A \subseteq B$ , and $A \subseteq C$ . Because $x \in A$ , then by the definition of the subset, $x \in B$ , and $x \in C$ . Since $x$ was an arbitrary element of $A$ ; $x \in B$ and $x \in C$ , we can conclude that $A \subseteq B \cap C$ . Therefore if $A \subseteq B$ and $A \subseteq C$ then $A \subseteq B \cap C$ .","['elementary-set-theory', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
3720051,Neighborhood in orthogonal group,"Let $A\in O(n)$ . Assume that $|a_{i,i}|\neq 1$ for every $i$ . Prove that in every neighborhood of $A$ there exists $B\in O(n)$ such that $|b_{i,i}|>|a_{i,i}| \text{ for every } i \text{ and } |b_{i,j}|\leq |a_{i,j}| \text{ for every } i\neq j$ . I have thought about projecting $A+\epsilon I$ on $O(n)$ (wlog I assume $a_{ii}\geq 0$ here), but there doesn't seem to be a nice formula indicating whether this projection would work or not. Similarly I am not sure about Gram-Schmidt. Or maybe it's better to find a prove that doesn't use explicit constructions, but I don't know much about neighborhood in $O(n)$ . Any suggestions? Edit: the main difficulty I faced was that, if $a_{i,j}=0$ then we must force $b_{i,j}=0$ , which prevents methods that involve 'small perturbation of every entry'. Edit 2: As a counter-example is given below, I wonder whether the claim is true if $A$ is close to $I$ , say if $A$ is closest to $I$ among all signed permutation matrices. (In the counter-example, $A\neq I$ itself is a signed permutation matrix). Note that this claim is true is $A$ is close enough to $I$ , as we can form a path $B_t=\text{exp}(t\log(A))$ . Since the entries of $B_t$ is analytic on $t$ , if $A$ is sufficiently close to $I$ every $B_t$ would satisfy the conditions for $t\in[0,1]$ .","['matrices', 'orthogonal-matrices', 'linear-algebra', 'topological-groups']"
3720058,Calculating index of a nested loop,"preamble: I have used single letter variables as I am not sure what the ""correct"" way is, if it would be easier to understand with the full names of the variables, i can change this. Given the following loop and nested loop which will result in ""o"" being the value of 14640 (""o"" will at some point be any number from 0 to 14640 inclusive): o = 0
m = 2
w = 241
for i = 0; i < w; i += m
   for j = 0; j < w; j += m
      o = o + 1 If we slightly change the above loops we can calculate the the current value of ""o"" within the first loop with the following modified for loop and equation, we still need ""o"" in the future so I will calculate ""o"" and store as ""n"": $n=\lceil \frac{w}{m}\rceil \lceil \frac{i}{m}\rceil$ o = 0
m = 2
w = 241
for i = 0; i < w; i += m
   n = ceiling(w / m) * ceiling(i / m)
   for j = 0; j < w; j += m
      o = n + 1 My issue is when I add a third loop as below:
With the third loop, the value of ""n"" can be incorrect depending on the value of ""c"" as ""i"" could start on a value which should have been skipped while incrementing i by m.
for example with ""c"" being 5 at the end of the first loop, ""i"" will be 5 and subsequently ""j"" will equal 5, however, it should be 6. o = 0
m = 2
w = 241
c = 5
for s = 0; s < w; s += c
   for i = s; i < w and i < s + c; i += m
      n = ceiling(w / m) * ceiling(i / m)
      for j = 0; j < w; j += m
         o = n + 1 How would I calculate the starting value of ""i"" is given that ""s"" could be a value that would make ""i"" start at an incorrect value?","['logic', 'discrete-mathematics']"
3720091,Invariance of a bilinear (in generators) under a subgroup of a Lie group,"Let $L^a$ be generators of a Lie algebra of a compact connected Lie group $G$ in some irrep ( $a$ indexes the generators). Let $\phi_k^a$ be the standard exponential coordinates for a group element $k$ . Consider the following sum of group elements in any subgroup $K\subseteq G$ (sums over $a,b$ implied): $$
\sum_{k\in K} \exp{(\phi^a_k L^a)}
$$ This sum is proportional to the projection onto any trivial irreps of $K$ in the irrep of $G$ , so it is invariant under any conjugation by $r \in K$ . Let's expand it in the generators, obtaining the following quadratic leading-order term (the linear term cancels since for any $k\in K$ , the inverse is also in the sum): $$
\left(\sum_{k\in K}\phi_{k}^{a}\phi_{k}^{b}\right)L^{a}L^{b}\equiv f^{ab}L^{a}L^{b}
$$ I conjecture that the above quantity is also invariant under conjugation by $r \in K$ . Note that the matrix $f$ is a sum over outer products of the coordinates of the subgroup elements, acting on the space of the adjoint irrep of $G$ . Under conjugation by $r\in K$ , the generators transform as $L^a \to R^{ab} L^b$ , where $R=\text{ad}(r)$ . So what I think is true is that the matrix $f$ is invariant under conjugation by such rotations. I've shown this for all subgroups of $K\subset SO_3$ , discrete and continuous. If the adjoint irrep of $SO_3$ branches to only one irrep of $K$ , it's simple: $f^{ab}\propto\delta^{ab}$ . For $K=Z_N$ (rotations around the $z$ -axis by multiples of $2\pi/N$ ), $f \propto \text{diag}(0,0,1)$ , which makes sense since the $\phi^a$ are proportional to the axis of rotation. I have neither found a counter-example for other groups nor have I proven this more generally. I suspect the sum can also be over a class instead of a subgroup.","['lie-algebras', 'finite-groups', 'group-theory', 'lie-groups', 'differential-geometry']"
3720171,"In which sense is this an ""irreducibility"" condition on a Markov semigroup?","Let $E$ be a $\mathbb R$ -Banach space, $\rho$ be a metric on $E$ , $\delta_x$ denote the Dirac measure on $(E,\mathcal B(E))$ at $x$ for $x\in E$ and $(\kappa_t)_{t\ge0}$ be a Markov semigroup on $(E,\mathcal B(E))$ satisfying the following property: If $\delta>0$ , there is a $t_0\ge0$ so that for all $t\ge t_0$ there is a $a>0$ with $$\inf_{\substack{(x,\:y)\:\in\:E^2\\\left\|x\right\|_E,\:\left\|y\right\|_E\:\le\:c}}\sup_{\substack{\gamma\\\gamma\text{ is a coupling of }\delta_x\kappa_t\text{ and }\delta_y\kappa_t}}\gamma\left(\left\{\rho<\delta\right\}\right)\ge a\tag1.$$ In which sense is this an ""irreducibility"" condition on $(\kappa_t)_{t\ge0}$ ? If $(\Omega,\mathcal A,\operatorname P)$ is a probability space and $X:\Omega\times[0,\infty)\times E$ is a stochastic flow, $X^x_t(\omega):=X(\omega,t,x)$ for $(\omega,t,x)\in\Omega\times[0,\infty)\times E$ and $$\kappa_t(x,B)=\operatorname P\left[X^x_t\in B\right]\;\;\;\text{for all }(x,B)\in E\times\mathcal B(E)\text{ and }t\ge0\tag2,$$ how can we describe $(1)$ in plain English. I've got some problems to understand the intuitive meaning of $(1)$ for the flow.","['statistics', 'measure-theory', 'reference-request', 'markov-process', 'probability-theory']"
3720190,"Why is $\frac{a-ar^n}{1-r}$ always an integer when $a$, $r$ (except $1$), and (positive) $n$ are integers? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question If $a_1$ and $r$ are integers, explain why the value of $\dfrac{a_1-a_1r^n}{1-r}$ must also be an integer. Does anyone have any ideas to rigorously explain/prove it? I can't really think of anything. (Also this is besides when $r=1$ of course.) EDIT: $n$ is any positive integer.",['algebra-precalculus']
3720231,When are permutations and combinations interchangable?,"I was recently reading through a probability textbook and came across an example in the conditional probability section that went like this, ""An urn contains $10$ marbles; $8$ are red and $2$ are white. You choose two marbles at random. Let $\mathcal{R}_1$ be the event that the first marble is red, and let $\mathcal{R}_2$ be the event that the second marble is red. Suppose the first is red, i.e. that $\mathcal{R}_1$ is true. What is the probability that the second is red given this information? i.e what is $P(\mathcal{R}_2|\mathcal{R}_1)$ ? And they give the answer as $\frac{P(8,2)/P(10,2)}{8/10}$ and this bothered me because I could not for the life of me convince myself that the order of the chosen, supposedly identical, red marbles mattered, therreby warranting the use of permutations. So I tried calculating it with combinations, i.e $\frac{C(8,2)/C(10,2)}{8/10}$ ... and got the exact same result! Now I'm curious. Is there any literature on when one can use either $P$ or $C$ to count the same values? Does this only happen because I am using ratios of $P$ 's and/or $C$ 's? If I'm blowing this all out of proportion. I would very much welcome an explanation as to why order and thus permutations are required. Thanks!","['permutations', 'combinations', 'conditional-probability', 'combinatorics', 'discrete-mathematics']"
3720281,How to express this combination as a formula?,"Suppose that I have an infinite set $A(z)$ , where the elements of the set are: $$
A(z) = \{z^0,z^1,z^2,...\}
$$ I want to get the number of ways that I can combine its elements if I multiply the set with itself, where the multiplication is an operation that results in another set (call this set the product). The product has coefficients for each element that counts the number of ways it was produced from the multiplication. For example, $$
A(z)^2=A(z)A(z)=\{z^0z^0,z^0z^1,z^1z^0,z^1z^1,z^0z^2,z^2z^0,z^1z^2,z^2z^1,...\}=\{z^0,2z^1,3z^2,....\}
$$ So in $A(z)^2$ , the coefficient of $z^1$ is $2$ , since there are two ways to come up with $z^1$ from $A(z)^2$ , i.e. $\{z^0z^1,z^1z^0\}$ . The coefficient of $z^2$ is $3$ , since there are three ways to come up with $z^2$ from $A(z)^2$ , which are $\{z^0z^2,z^2z^0,z^1z^1\}$ ... Now I'd like to ask, is there a formula that can compute the coefficients of the elements of a $k$ -product, i.e. $A(z)^k$ ...","['combinations', 'abstract-algebra', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
3720295,Area of a Section of the Unit Sphere,"I am currently studying for the GRE. I came across the following question, and I can't seem to get the correct answer. The question reads: Compute the area of a unit sphere contained between the meridians $\phi =30^{\circ}$ and $\phi = 60^{\circ}$ and parallels $\theta =45^{\circ}$ and $\theta =60^{\circ}$ . First, I recalled that the area element of the unit sphere is: $dA=\sin(\phi)d\phi d\theta$ . From there, I made the following computations: $$\int_{\frac{\pi}{4}}^{\frac{\pi}{3}}\int_{\frac{\pi}{6}}^{\frac{\pi}{3}}\sin(\phi)d\phi d\theta  = \int_{\frac{\pi}{4}}^{\frac{\pi}{3}}(\frac{\sqrt{3}}{2}-\frac{1}{2})d\theta = \frac{\pi}{12}(\frac{\sqrt{3}}{2}-\frac{1}{2})$$ However, the correct answer is: $\frac{\pi}{12}(\sqrt{3}-\sqrt{2})$ . Any guidance on this problem would be greatly appreciated.","['integration', 'multivariable-calculus', 'surface-integrals']"
3720308,How to prove that the product of two $C^\infty$ functions is also a $C^\infty$ function rigorously?,"How to prove that the product of two $C^\infty$ functions is also a $C^\infty$ function? I guess it is easy to prove the above fact by induction, but I cannot prove that. Let $f, g$ be $C^\infty$ functions from an open set $U \subset \mathbb{R}^n \to \mathbb{R}$ . Prove that $f g$ is also a $C^\infty$ function from an open set $U \subset \mathbb{R}^n \to \mathbb{R}$ . My attemp is here: $D_i f$ is also a $C^\infty$ function for any $i \in \{1, 2, \cdots, n\}$ . $D_i g$ is also a $C^\infty$ function for any $i \in \{1, 2, \cdots, n\}$ . $D_i (f g) = D_i(f) g + f D_i(g)$ and $D_i f, D_i g$ are $C^\infty$ functions. It is enough to prove that $D_i(f) g$ and $f D_i(g)$ are $C^\infty$ functions. But to prove that $D_i(f) g$ and $f D_i(g)$ are $C^\infty$ functions, we need to prove the product of two $C^\infty$ functions is also a $C^\infty$ function. A circular argument?","['continuity', 'multivariable-calculus', 'derivatives']"
3720329,$T:\Bbb{R}^2\rightarrow\Bbb{R}^2$ has 2 distinct eigenvalues. Showing that $v$ or $T(v)− \lambda_1v$ are eigenvectors of $T$,"$T:\Bbb{R}^2\rightarrow\Bbb{R}^2$ which is diagonalizable with 2 distinct eigenvalues. Showing that either $v$ is an eigenvector for $\lambda_1$ or else $T(v)− \lambda_1v$ is an eigenvector for $\lambda_2$ . I tried to use the matrix representation of $T$ and the Cayley-Hamilton theorem, but I can't reach the conclusion. Is there a way to prove it without the matrix representation? I would prefer to get guidance rather than a full solution.","['linear-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
3720362,Values of c for which the given quotient ring is a field.,"I am stuck with the problem : Find all values of 'c' in $F_{5}=\frac{\mathbb{Z}}{5\mathbb{Z}}$ such
that the quotient ring $\frac{F_{5}}{⟨X^3 + 3X^2 + cX + 3⟩}$ is a
field. Justify your answer. My approach was, we've got a theorem for commutative ring R that if I is a maximal ideal in R then R/⟨I⟩ is a field. Now to prove $⟨X^3 + 3X^2 + cX + 3⟩$ is a maximal ideal in the given field we need to show that this is irreducible. So, I think for the set of values of 'c' for which this polynomial is irreducible, will be the set for which the above quotient ring is a field. But I don't know how to find all the values of 'c' for which $⟨X^3 + 3X^2 + cX + 3⟩$ is irreducible except to try each value of 'c' individually and then use some irreducibility test.
Is there a proper and simpler way to find such 'c'. Please help me in finding such values.","['field-theory', 'ring-theory', 'abstract-algebra', 'ideals']"
3720371,Deeper understand of $\cos$ and $\sin$,"I was hoping to understand $\sin$ and $\cos$ a bit more in detail regarding how they came about, not so much about the history but rather and the relationships of these functions with nature and other math topics. In school and college (depending on what your major is), we focus just on the mechanical aspects of $\sin$ and $\cos$ . But I'm still having a hard time wrapping my head around how these functions came about. On the unit circle, why does $\sin$ correspond to the $y$ coordinate on a point on the circle and $\cos$ correspond to the $x$ coordinate(was this just chosen by someone a long time ago)? Or why the vertical distance from the center of the circle to the tip of the line gives us the amplitude of the sine wave as shown on this site ? Or why is there a relationship between these two trig functions and a circle? Lastly, are $\sin$ and $\cos$ found in cyclic parts of nature, or are these functions used as good approximations regarding cyclic behaviors in nature? Sorry if the questions are open-ended, it's just that I've read some wiki articles and visited some other random websites, but I still wasn't able to find answers to these questions. Thanks for your time and help!","['trigonometry', 'soft-question']"
3720386,How to prove $|{^A}{(K \times L)}| =_c |{^A}{K} \times {^A}{L}|$?,"How to prove $|{^A}{(K \times L)}| =_c |{^A}{K} \times {^A}{L}|$ ? Definitions: $|X|=_c|Y|$ means that there is a function $f:X \rightarrow Y$ that is one-to-one and onto $Y$ . When $X$ and $Y$ are finite sets, then $|X|=|Y|$ if and only if $|X|=_c|Y|$ . $X$ has the same cardinality as $Y$ . Let $X$ and $Y$ be sets. The set of all functions from $X$ to $Y$ , denoted ${^X}{Y}$ , is defined by ${^X}{Y}$ ={ $F$ : $F$ is a function from $X$ to $Y$ }. Here is what I did: Let $f:A \rightarrow A \times A$ and $g:K \times L \rightarrow K \times L$ be bijections. Let $l:A \rightarrow K \times L$ and define $G:{^A}{(K \times L)} \rightarrow {^A}{K} \times {^A}{L}$ by $G(l)=g \circ l \circ f^{-1}$ , for each $l \in {^A}{(K \times L)}$ . We prove that $G$ is one-to-one. Let $l \in {^A}{(K \times L)}$ and $l^{\ast} \in {^A}{(K \times L)}$ . Assume that $G(l)=G(l^{\ast})$ , thus $(g \circ l \circ f^{-1})(x)=(g \circ l^{\ast} \circ f^{-1})(x)$ for all $x \in A \times A$ . Hence $g((l \circ f^{-1})(x))=g((l^{\ast} \circ f^{-1})(x))$ for all $x \in A \times A$ . Since $g$ is one-to-one, we conclude that $(l \circ f^{-1})(x)=(l^{\ast} \circ f^{-1})(x)$ for all $x \in A \times A$ . We now show that $l(a)=l^{\ast}(a)$ for all $a \in A$ , thus $f(a) \in A \times A$ . Letting $x=f(a)$ , we obtain $l(a)=l^{\ast}(a)$ since $f^{-1}(f(a))=a$ , so $l=l^{\ast}$ and $G$ is hence one-to-one. To prove that $G$ is onto ${^A}{K} \times {^A}{L}$ , let $h \in {^A}{K} \times {^A}{L}$ , then $g^{-1} \circ h \circ f \in {^A}{(K \times L)}$ and $G(g^{-1} \circ h \circ f)=h$ . Therefore, the function $G:{^A}{(K \times L)} \rightarrow {^A}{K} \times {^A}{L}$ is a bijection. I would appreciate if someone could help me with this one as I do not know what I did wrong. Thanks!","['elementary-set-theory', 'cardinals', 'functions', 'solution-verification']"
3720457,Find the range of $f:x \mapsto a+b\cos x$,"The function $f:x \mapsto a+b\cos x$ , is defined for $0 \le x\le 2\pi$ . Given that $f(0) = 10$ and $f\left(\frac{2}{3}\pi\right) = 1$ , find the values of $a$ and $b$ , the range of $f$ , and the exact value of $f\left(\frac{5}{6}\pi\right)$ . I was able to get the value of a and b given that $f(0) = 10$ and $f\left(\frac{2}{3}\pi\right) = 1$ which gives $a + b\cos (0) = 10$ and $a + b\cos\left(\frac{2}{3}\pi\right) = 1$ . Therefore $a = 4$ and $b = 6$ . For the exact value of $f\left(\frac{5}{6}\pi\right)$ ; Since $a = 4$ and $b = 6$ , $f(x) = a + b\cos x \Rightarrow  4 + 6\cos x$ , Therefore $f\left(\frac{5}{6}\pi\right) = 4 + 6\cos\left(\frac{5}{6}\pi\right) = 4 + 6(-\frac{\sqrt3}{2})$ = $4-3\sqrt{3}$ or $-1.1962$ .
Getting the range of f is what I don't know how to go about, can anyone here offer an explanation or answer? Thanks","['trigonometry', 'functions']"
3720484,"In triangle $ABC$, $\angle C = 48^\circ$. $D$ is any point on $BC$, such that $\angle CAD = 18^\circ$ and $AC = BD$. Find $\angle ABD.$","In  triangle $ABC$ , $\angle C = 48^\circ$ . $D$ is any point on $BC$ , such that $\angle CAD = 18^\circ$ and $AC = BD$ . Find $\angle ABD.$ I tried to make some constructions: draw a line through $D$ parallel to $AC$ ; draw a line through $C$ which makes $66$ degrees with $AC$ . None of them have been useful. It feels like I am trying to force the formation of congruent triangles, and that doesn't work. Please help.","['euclidean-geometry', 'triangles', 'geometry']"
3720492,Stability of a three-dimensional system,"when I consider the three-dimensional ODE system such as $$
\dot{x} = \frac{25}{(1+y^2)(1+z^2)} - x\\
\dot{y} = \frac{25}{(1+x^2)(1+z^2)} - y\\
\dot{z} = \frac{5}{1+(x+y)^2} - z
$$ There is an equilibrium state $$(2.78581, 2.78581, 0.15604).$$ When I substitute this equilibrium point into the corresponding Jacobian matrix. The eigenvalues at this equilibrium point are $$
[-2.82226, -0.949452, 0.771709]
$$ Since there is a positive eigenvalue, this equilibrium should be defined as an unstable state. However, when I simulated this system in MATLAB, the simulation results show that this equilibrium state seems like a stable state. I was wondering how this thing happens? Is there anything I misunderstood?","['stability-in-odes', 'jacobian', 'ordinary-differential-equations', 'dynamical-systems']"
3720572,Conjecture regarding the sum of prime factors,"$\text{Notations}$ Let $\pi(n)$ be the prime countiong function. Let denote $\alpha(n)$ the sum of the prime factors of $n$ . In other words, if $$n=p_1^{x_1}p_2^{x_2}...p_m^{x_m}$$ then $\alpha(n)=p_1+p_2+...+p_m$ (I changed the notation; It was pointed out in the comments that $\omega$ is another function and it was misleading) $\text{Statement}$ Prove or disprove that there exist infinitely many composite positive integers $n$ such that $\alpha(n)+1|n+1$ . $\text{Important}$ I made a new thread in which the question is posted with some new conditions. I am now interested in the squarefree solutions of the above equation. New problem link: Conjecture on the sum of prime factors","['number-theory', 'conjectures', 'elementary-number-theory']"
3720611,"For $W=\cup_{U\in\mathcal U} U$ show that there exists $U_1,\dots,U_n: \ \sum_{i=1}^n \lambda(U_i) > \frac{1 - \epsilon}{3^d}\lambda(W)$","I'm trying to solve the following, which is Exercise 13.15 in the book Probability Theory by A. Klenke. Let $C \subset \mathbb R^d $ be an open, bounded and convex set and assume that $$
\mathcal{U} \subset \left \{ x+rC: x \in \mathbb R^d, r>0 \right \}
$$ is such that $$
W:= \bigcup_{U \in \mathcal{U}}U 
$$ has finite Lebesgue measure $\lambda(W)$ . Show that for any $\epsilon > 0$ there exists finitely many pairwise disjoint sets $U_1, \dots, U_n$ such that $$
\sum_{i=1}^n \lambda(U_i) > \frac{1 - \epsilon}{3^d}\lambda(W). \tag 1
$$ Show by a counterexample that the condition of similarity of the open sets in $\mathcal{U} $ is essential. This is my approach: Given that the Lebesgue measure $\lambda$ is inner regular, pick a compact set $K \subset W$ such that $$
\lambda(W) - \epsilon < \lambda(K).
$$ Since the open sets\footnote{We take it as given that $C$ is open implies that $x + rC$ is open.} in $\mathcal{U}$ covers $K$ and $K$ is compact there exists a finite number $m$ of them such that $U_i, \dots, U_m$ covers $K$ . Order the $U_i$ :s such that, if $$
U_i = x_i + r_iC, \qquad i=1, \dots m
$$ then $r_1 \ge r_1 \ge \dots \ge r_m$ . Now, I have seen a similar Lemma in Rudin's Real and complex analysis (Lemma 7.3) where the sets $U_i$ are open balls $U_i = B(x_i,r_i)$ . In that case one may do as follows: to get a disjoint collection of sets we let $i_1=1$ , and then we discard every $U_j$ that intersects $U_{i_1}$ . Let $U_{i_2}$ be the first remaining $U_j$ (if any exists) and discard the remaining $U_j$ that intersects $U_{i_2}$ . Continuing this process gives a a collection of $n$ disjoint sets. Then one may claim that, $$
\bigcup_{i=1}^m x_i+ r_iC \subset \bigcup_{k=1}^n x_{i_k} + 3r_{i_k}C.
$$ The conclusion then follows (for that Lemma) from $$
\lambda \left(B(x, 3r)\right) =3^d \lambda \left(B(x, r)\right) 
$$ and subadditivity. I don't think the exact same argument works here but is there a similar approach to get at least pairwise disjoint sets in the case of this exercise? And further such that (1) holds? Secondly, what is the meaning of the last sentence in the exercise, ""Show by a counterexample that the condition of similarity of the open sets in $\mathcal{U} $ is essential.""? Much grateful for any help provided!","['measure-theory', 'lebesgue-measure', 'convex-geometry', 'combinatorial-geometry', 'convex-analysis']"
3720615,"Show that $f_{n}(x):=nx(1-x)^{n}$ is uniformly bounded on $[0,1]$ for all $n\geq 1$.","Consider $f_{n}(x):=nx(1-x)^{n}$ defined for $n=1,2,3,\cdots$ and $x\in [0,1]$ . The exercises have two parts: (a) Show that for each $n$ , $f_{n}(x)$ has a unique maximum $M_{n}$ at $x=x_{n}$ . Compute the limit of $M_{n}$ and $x_{n}$ as $n\rightarrow\infty.$ (b) Prove that $f_{n}(x)$ is uniformly bounded in $[0,1]$ . I have computed that for each $n$ , $f_{n}(x)$ has a unique maximum in $[0,1]$ at $$x_{n}=\dfrac{1}{1+n}$$ with the maximum value $$M_{n}=\Big(\dfrac{n}{n+1}\Big)^{n+1}.$$ Thus $$\lim_{n\rightarrow\infty}x_{n}=0\ \ \ \text{and}\ \ \ \lim_{n\rightarrow\infty}M_{n}=\lim_{n\rightarrow\infty}\Big(1-\dfrac{1}{1+n}\Big)^{n+1}=e^{-1}.$$ The solution says that since $|f_{n}(x)|\leq |M_{n}|$ for each $n=1,2,\cdots$ , the above shows that $|f_{n}(x)|\leq e^{-1}$ for all $x\in [0,1]$ and $n=1,2,\cdots$ . I don't understand this. To show the uniform boundedness, don't we need to show $$\sup_{n}|f_{n}(x)|\leq C,\ \ \text{for some constant}\  C\ \text{and for all}\  x\in [0,1]?$$ It is true that since $|f_{n}(x)|\leq M_{n}$ for each $n$ and for all $x\in [0,1]$ , we have $$\sup_{n}|f_{n}(x)|\leq\sup_{n}|M_{n}|,$$ but why does the limit of $M_{n}$ being $e^{-1}$ implies the sup is $e^{-1}$ ? Thank you!","['proof-explanation', 'analysis', 'real-analysis', 'sequences-and-series', 'limits']"
3720626,solve $x' = t^\alpha +x^\beta$,"I need to solve the following ode for some  non zero $\alpha \beta$ : $x' = t^\alpha + x^\beta$ . I don't have any initial conditions. I am not sure how to proceed with this ,I tried doing $ x=y^m$ to get $x'=my^(m-1) y'$ but I don know if it helps. Any help will be appreciated","['calculus', 'ordinary-differential-equations', 'real-analysis']"
3720695,Behaviour of sine sums,"I was considering the following function $$f_a(x)=\sum_{n=0}^{\lfloor x\rfloor}\sin^2(an)$$ and, as expected, $f_a(x)\approx x/2$ for every $a$ (except $2\pi$ and similar). This is because the function $\sin^2(ax)$ is ""on average"" equal to $1/2$ . That is: we are adding $x$ numbers all close to $1/2$ , and if one of them is bigger (than $1/2$ ) then not much later we are going to find another that is smaller (than $1/2$ ), cancelling the effect. At first I thought that the behaviour of $f_a$ would depend on how good of an approximation is $a$ to a rational multiple of $\pi$ (problems of convergence and similar always take this into consideration), but it is not the case. The problem begins when one considers (I found this before the $f_a$ ) the functions $$g_a(x)=\sum_{n=0}^{\lfloor x\rfloor}\sin(an)$$ I'm puzzled by these: they are (almost always) approximately equal to $A\sin^2\left(Bx\right)$ , where $A$ and $B$ are, I think, constants (or almost constant) which depend on $a$ . First of all, why does this happen? If $\sin^2(ax)$ is, on average equal to $1/2$ , then $\sin(an)$ is equal to $0$ on average, so we should oberve $g_a\approx0$ always. Instead, $g_a$ is either positive (and oscillating) or negative (also oscillating), except for very few values where it becomes negative (psitive) but very small. So they are, in a sense, ""very positive"" or ""very negative"". Either way, very not zero. Maybe it has to do with the fact that $$\frac{1}{x}\int_0^x\sin^2(at)\,dt$$ converges to $1/2$ but oscillating and $$\frac{1}{x}\int_0^x\sin(at)\,dt$$ converges to $0$ but is always postivie or negative so that, while it is $0$ on average, it is more positive somehow. Can you expalin this phenomenon? Also, this is not the whole story: there are some values of $a$ (for example $a=2.8$ ) for which $g_a$ is ""made"" of two sine waves (like a standing wave), but this time the ""very positive or very negative"" doesn't show up. For some other values ( $a=23$ ), $g_a$ is made up of three sine waves. I suspect this can be explained with the rational approximation thing. Note: (you may want to graph $g_a$ times a big constant like 10 and zoom out to see the various sine waves) Thanks!! Edit: We have the following identity: $$\sin(\varphi)+\sin(\varphi+\alpha)+\sin(\varphi+2\alpha)+\dots+\sin(\varphi+n\alpha)=$$ $$=\frac{\sin\left(\frac{(n+1)\alpha}{2}\right)\sin\left(\frac{n\alpha}{2}\right)}{\sin\left(\frac{\alpha}{2}\right)}$$ So making $\varphi=0$ and $\alpha=a$ we have a precise expression $$g_a(x)=\frac{\sin\left(\frac{(\lfloor x\rfloor+1) a}{2}\right)\sin\left(\frac{\lfloor x\rfloor a}{2}\right)}{\sin\left(\frac{a}{2}\right)}$$ Which looks similar enough to $A\sin^2(Bx)$ . This does not solve the "" $\sin$ 's average is $0$ so $g_a$ should be $0$ "". Also, and I find this very curious, if we substitute $\lfloor x\rfloor$ for $x$ in the formula we get a completely different function, and the ""made up of various sine waves for some choices of $a$ "" is far from clear from the formula. I'm guessing its a ""how synched"" the two waves in the numerator are: if they are very very similar then their product is very similar to $\sin^2$ . This explains the ""very positive"" or ""very negative"", but no more, because the periods are $a/2$ for both waves. Another observation: if we use $\cos$ instead, the opposite phenomenon occurs. For most values of $a$ , the sum is ""made up"" of various waves","['intuition', 'trigonometry', 'summation']"
3720699,Classifying Critical Point in 3D,"Question: $f(x, y, z) = px^2 +q(y^2 + z^2) +rxy + syz$ where $p,q,r,s \in \mathbb{R}$ has a critical point at $(0, 0, 0)$ . Classify this critical point. You can assume the product of $p$ and $q$ is positive. Also, $r$ and $s$ cannot be both equal to zero (either one is zero and the other is not, or neither are zero). Attempt: I've found the Hessian matrix evaluated at the critical point $H=\begin{bmatrix} 2p & r & 0 \\ r & 2q & s \\ 0 & s & 2q \\\end{bmatrix}$ . I've tried to find the eigenvalues ( $\lambda$ ) of $H$ to assess whether the point is a local minimum, maximum or saddle point, but ended up with a long messy equation that cannot be factorised easily to solve for $\lambda$ : $$(2p - \lambda)((2q-\lambda)^2-s^2)-r^2(2q-\lambda)=0$$ which expands to $$-2r^2q+\lambda r^2 -2ps^2 +8q^2p-8\lambda qp +2\lambda ^2p+\lambda s^2 -4\lambda q^2 +4\lambda ^2 q-\lambda^3=0$$ Using Wolfram Alpha to solve this and find the eigenvalues gives these three solutions , which pushes me to consider another strategy. So my next attempt was to see if I could classify the point via this method (see page 3) because I figured it would break it down into smaller more easier to manage equations with less unknowns, however it got pretty messy having to consider the two cases ( $p,q>0$ and $p,q<0$ ) and then the three subcases (both nonzero $r$ and $s$ , $r=0$ and nonzero $s$ , nonzero $r$ and $s=0$ ): $f_{xx}(0, 0, 0) = 2p$ $\det \begin{bmatrix} f_{xx} & f_{xy} \\ f_{yx} & f_{yy} \end{bmatrix}=\det \begin{bmatrix} 2p & r \\ r & 2q \end{bmatrix} = 4pq-r^2$ $\det H = \det \begin{bmatrix} 2p & r & 0 \\ r & 2q & s \\ 0 & s & 2q \\\end{bmatrix} = 2p(4q^2 - s^2)-2r^2q = 8pq^2 - 2ps^2 - 2r^2 q$ Dealing with the signs of the constants is really what's throwing me, as I am comfortable with the classification process. Any help would be greatly appreciated. Edit: I'm pretty sure the type of critical point will be different depending on the different cases of what $p, q, r, s$ are (i.e. $p,q \gt 0$ or $p, q \lt 0$ , and then subcases concerning $r$ and $s$ and whether they're zero or non-zero, remembering that they cannot be both zero).","['matrices', 'multivariable-calculus', 'calculus', 'functions', 'linear-algebra']"
3720724,Conjecture on the sum of prime factors,"$\text{Notations}$ Let $\pi(n)$ be the prime counting function. Let denote $\alpha(n)$ the sum of the prime factors of $n$ . (i.e. In other words, if $$n=p_1^{x_1}p_2^{x_2}...p_m^{x_m}$$ then $\alpha(n)=p_1+p_2+...+p_m$ .) (I changed the notation; It was pointed out in the comments that $\omega$ is another function and it was misleading) $\text{Statement}$ Find whether the equation $\alpha(n)+1|n+1$ has infinitely many squarefree solutions. Moreover, show that one can find an infinitude of composite, non-squarefree solutions. $\text{Progress}$ The original question was posted here and Peter found the following general solution for non-squarefree integers: Claim : $n=2\cdot 3\cdot 5^{5m+4}$ is a solution for all $m\ge 1$ Proof :  The sum of the prime factors is obviously $10$ . Because of $5^5\equiv 1\mod 11$ , we have $n\equiv 2\cdot 3\cdot 5^4\equiv -1\mod
> 11$ , hence $11\mid n+1$ Hence there are infinite many solutions. So it has been proven that there are in fact infinitely many non-squarefree solutions (and the prime numbers are trivial solutions). The question about composite squarefree solutions still holds.","['prime-factorization', 'conjectures', 'number-theory', 'elementary-number-theory', 'divisor-sum']"
3720781,"What are the odds of a triangle, if vertices are picked at random from an $m\times n$ square grid?","In an $m\times n $ square grid (assume $m,n >2$ ), three distinct points are picked randomly.  What are the odds they make a non-degenerate triangle?  In the limit the odds go to one. This is related to Sylvester's 4-point problem , but I'm interested in the same problem on a discrete grid.  The limit is 25/36 ~ 0.694444.  On a 21x21 grid the odds of a quadrilateral are 1053055398/1554599970 ~ 0.67738.  The odds of a triangle for a grid might solve this question. EDIT:  The square case is A000938 . A table of values has been made.","['geometry', 'combinatorics', 'triangles', 'discrete-mathematics', 'probability']"
3720874,Question related to continuity in Topology ( A proof i am unable to understand),I am self studying Topology from C.Wayne patty and I am unable to think about a step in proof of a theorem in Section 1.6 . Adding image -> Note that i have question in only (c) ->(d) part of the proof. In that part I am unable to understand how in 2-3rd line assuming x to be limit point of $f^{-1}(B)$ implies f(x) $\epsilon$ closure of $ f(f^{-1}(B)) $ . I tried using definationof a limit point but it's not clear to me. Please help.,"['general-topology', 'analysis']"
3720909,Proof to n-th order inhomogenous differential equation,"Let be $ I \subset \mathbb{R} $ an intervall and $ s \in C^{ ( \infty ) }( I) $ How can I show that every solution $ y \in C^{ (n)} (I) $ of $$  y^{ (n)} + \sum_{j=0}^{n-1} a_jy^{(j)} = s(x) $$ ( $ a_0,...,a_{n-1} \in \mathbb{R} $ constant ) is in $ C^{( \infty )} (I) $ ?",['ordinary-differential-equations']
3720915,"Gradient of $\mbox{dist}\left(x, D \right)^2:= \left\| x - P_{D}(x)\right\|_2^2$, where $P_{D}(x)$ is a projection operator","Let $D \subset \mathbb{R}^{n}$ be a non empty convex closed set and: $$f:\mathbb{R}^{n}\rightarrow \mathbb{R}_{+}, f(x)=(\operatorname{dist}(x,D))^{2}$$ Prove that f is differentiable in $\mathbb{R}^{n}$ and $$f'(x)=2(x-P_{D}(x)), \forall x \in \mathbb{R}^{n},$$ where $\mbox{dist}(x,D)$ is the distance between a point $x$ and the set $D$ and $P_{D}(x)$ is the projection of $x$ in $D$ , i.e., \begin{align}
\operatorname{dist}\left(x, D \right) := \left\| x -  P_{D}(x)\right\|_2.
\end{align}","['convex-optimization', 'derivatives', 'matrix-calculus', 'optimization', 'convex-analysis']"
3720917,Bourbaki's construction of generalized tensor product of modules,"Let $(G_\lambda)_{\lambda\in L}$ be a family of $\mathbf{Z}$ -modules. Let $\phi:\prod_{\lambda\in L}G_\lambda\rightarrow\mathbf{Z}^{(\prod_{\lambda\in L} G_\lambda)},\,x\mapsto e_x:=(\delta_x(x'))_{x'\in\prod_\lambda G_\lambda}$ , be the canonical injection. Let $C$ be the sub- $\mathbf{Z}$ -module of $\mathbf{Z}^{(\prod_{\lambda\in L} G_\lambda)}$ generated by elements of the form $$e_{x+y,(z_\lambda)_{\lambda\ne\mu}}-e_{x,(z_\lambda)_{\lambda\ne\mu}}-e_{y,(z_\lambda)_{\lambda\ne\mu}}$$ for $\mu\in L$ , $x,y\in G_\mu$ , and $z\in\prod_{\lambda\ne\mu}G_\lambda$ . Write $\bigotimes_{\lambda\in L}G_{\lambda}:=\mathbf{Z}^{(\prod_{\lambda\in L} G_\lambda)}/C$ and let $\pi:\mathbf{Z}^{(\prod_{\lambda\in L} G_\lambda)}\rightarrow\bigotimes_{\lambda\in L}G_{\lambda}$ be the canonical surjection. Then the mapping $$\pi\circ\phi:\prod_{\lambda\in L}G_\lambda\rightarrow\bigotimes_{\lambda\in L}G_\lambda$$ is $\mathbf{Z}$ -multilinear ( definition ). The $\mathbf{Z}$ -module is called the tensor product (over $\mathbf{Z}$ ) of the family $(G_\lambda)_{\lambda\in L}$ of $\mathbf{Z}$ -modules . For $x\in\prod_{\lambda\in L} G_\lambda$ , write $\bigotimes_{\lambda\in L}x_\lambda:=\pi(\phi(x))$ . Let $(H_\lambda)_{\lambda\in L}$ be another family of $\mathbf{Z}$ -modules and $(v_\lambda:G_\lambda\rightarrow H_\lambda)_{\lambda\in L}$ a family of $\mathbf{Z}$ -linear mappings. Then there exists a unique $\mathbf{Z}$ -linear mapping $$\bigotimes_{\lambda\in L}v_\lambda:\bigotimes_{\lambda\in L}G_\lambda\rightarrow\bigotimes_{\lambda\in L}H_\lambda$$ such that $\left(\bigotimes_{\lambda\in L}v_\lambda\right)\left(\bigotimes_{\lambda\in L}x_\lambda\right)=\bigotimes_{\lambda\in L}v_{\lambda}(x_{\lambda})$ for all $x\in\prod_{\lambda\in L}G_\lambda$ . In particular, let $\mu\in L$ and $\theta$ be an endomorphism of $G_\mu$ . We denote by $\tilde{\theta}$ the endomorphism of $\bigotimes_{\lambda\in L}G_\lambda$ equal to $\bigotimes_{\lambda\in L}v'_{\lambda}$ where $v'_\mu=\theta$ and $v'_\lambda=1_{G_\lambda}$ for $\lambda\ne\mu$ . Now, suppose we are given a set $\Omega$ , a mapping $c:\Omega\rightarrow L\times L,\,\omega\mapsto(\rho(\omega),\sigma(\omega))$ and, for all $\omega\in\Omega$ , an endomorphism $p_\omega$ of $G_{\rho(\omega)}$ and an endomorphism $q_\omega$ of $G_{\sigma(\omega)}$ ; there correspond to them two endomorphisms $\tilde{p}_\omega$ and $\tilde{q}_\omega$ of $\bigotimes_{\lambda\in L}G_\lambda$ . Set $$\bigotimes_{(c,p,q)}G_\lambda:=\left(\bigotimes_{\lambda\in L}G_\lambda\right)/\left(\sum_{\omega\in\Omega}\text{Im}(\tilde{p}_\omega-\tilde{q}_\omega)\right)$$ and let $\psi:\bigotimes_{\lambda\in L}G_\lambda\rightarrow\bigotimes_{(c,p,q)}G_\lambda$ be the canonical surjection. Then the mapping $$\varphi_{(c,p,q)}:=\psi\circ\pi\circ\phi:\prod_{\lambda\in L}G_\lambda\rightarrow\bigotimes_{(c,p,q)}G_\lambda$$ is $\mathbf{Z}$ -multilinear. Ok.–This construction seems rather involved, especially if you take into account that one still has to develop the notions of ""associativity"" and ""commutativity""..Is there a way to clean this up? (Perhaps using some category theory?) If not, can someone suggest alternative constructions that don't sacrifice generality (e.g. by restricting to finite cases, etc.)?","['category-theory', 'abstract-algebra', 'linear-algebra', 'tensor-products', 'multilinear-algebra']"
3720959,$W^2_0$ Poincaré inequality,"Let $\Omega \subset \mathbb R^n$ be a bounded set. Taking the Hilbert space $$W^2=\{v\in \mathcal S'(\Omega):\ v\in L^2,\ |\nabla v|\in L^2,\ \|D^2v\|\in L^2\ \}$$ in order to prove an analogue of the Poincaré inequality $$\exists C:\ \forall v\in ?\subset W^2(\Omega)\qquad \|v\|_{W^2}\le C\|\Delta v\|_{L^2}$$ we have to restrict to a subspace where: the functions take value zero at the boundary? the functions and their normal derivatives take value zero at the boundary? I would expect the second option, nevertheless, even for $\Omega=(-1,1)$ I cannot find an example of function $v\in W^2(\Omega)$ where the boundary value is zero and $$\|v\|_{W^2}>>\|v''\|_{L^2}\qquad v(-1)=v(1)=0$$ so I wonder if we can have a control of the norm even in case 1.","['sobolev-spaces', 'functional-analysis']"
3720981,Hilbert polynomial of the blow-up of a projection,"Let $p:\mathbb{P}^r\dashrightarrow\mathbb{P}^{r-k-1}$ with $0\le k<r$ be the projection $(a_0:\cdots:a_r)\longmapsto (a_{k+1}:\cdots:a_r)$ . Such a rational map has base $K:=V(X_{k+1},\cdots,X_r)\subsetneq\mathbb{P}^r$ , that is, the domain of $p$ is $\mathbb{P}^r\backslash K$ . The blow-up, $X:=Bl_{K}(\mathbb{P}^r)$ , of $\mathbb{P}^r$ along of $K$ is \begin{eqnarray}
  X &\overset{\pi}{\longrightarrow}& \mathbb{P}^r\\
  ((a_0:\cdots:a_r),(b_{k+1}:\cdots:b_r)) &\longmapsto& (a_0:\cdots:a_r),
\end{eqnarray} where $X=V(X_iY_j-X_jY_i\mid k+1\leq i,j,\le r)\subset \mathbb{P}^r\times\mathbb{P}^{r-k-1}$ , here we have given homogeneous coordinates $X_i$ to $\mathbb{P}^r$ and $Y_i$ to $\mathbb{P}^{r-k-1}$ .
The morphim \begin{eqnarray}
  X &\overset{P}{\longrightarrow}& \mathbb{P}^{r-k-1}\\
  ((a_0:\cdots:a_r),(b_{k+1}:\cdots:b_r)) &\longmapsto& (b_{k+1}:\cdots:b_r),
\end{eqnarray} resolves $p$ , i.e, $P\circ\pi^{-1}=p$ . The exceptional divisor is given by $E=\pi^{-1}(K)=V(X_{k+1},\cdots,X_r)\subsetneq X$ . We have a canonical immersion $(\pi,P): X \hookrightarrow\mathbb{P}^r\times\mathbb{P}^{r-k-1}$ which give us $P^*\mathcal{O}_{\mathbb{P}^{r-k-1}}(1)=\pi^*\mathcal{O}_{\mathbb{P}^r}(1)\otimes\mathcal{O}_{X}(-E)$ , this allow us to express the bivariate Hilbert polynomial of $X$ as \begin{eqnarray}
 Hilb_{X}(a,b)&:=&h⁰(\mathcal{O}_{\mathbb{P}^r}(a)|_{X}\otimes\mathcal{O}_{\mathbb{P}^{r-k-1}}(b)|_{X})\\
&=&h⁰(\pi^*\mathcal{O}_{\mathbb{P}^r}(a)\otimes P^*\mathcal{O}_{\mathbb{P}^{r-k-1}}(b))\\
&=&h⁰(\pi^*\mathcal{O}_{\mathbb{P}^r}(a+b)\otimes\mathcal{O}_{X}(-bE)), \mbox{ for } 
a,b >>0.
\end{eqnarray} Unfortunately, I have no idea how to calculate $h⁰(\pi^*\mathcal{O}_{\mathbb{P}^r}(a+b)\otimes \mathcal{O}_{X}(-bE))$ , or more generally, $Hilb_{X}(a,b)$ . I would be very happy if anyone could give me any idea how to calculate $h⁰(\pi^*\mathcal{O}_{\mathbb{P}^r}(a+b)\otimes \mathcal{O}_{X}(-bE))$ , or more generally, $Hilb_{X}(a,b)$ . References, a solution, absolutely anything which could help me is welcome!!","['projective-varieties', 'projective-schemes', 'algebraic-geometry', 'hilbert-polynomial', 'schemes']"
3720982,Group of order $1+2+3+ \cdots + n$ with class equation $1+2+3+ \cdots + n$,"It is known that the symmetric group $S_3$ of order $1+2+3$ has the class equation $1+2+3$ . But a non-abelian group of order $10 = 1+2+3+4$ (which is just $D_5$ ) cannot have the class equation $1+2+3+4$ . My question is the following: ""are there finite groups $G$ (other than $S_3$ ) of order $\frac{n(n+1)}{2}(n \in \Bbb N$ ) with class equation $1+2+3+\dots+n$ "" I've no idea how to find an example of this/disprove this claim. Kindly shed some light on this matter.","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
