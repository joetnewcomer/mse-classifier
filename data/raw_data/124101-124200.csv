question_id,title,body,tags
1873848,"Proving $x\in\text{SL}(n,\mathbb Q)$ given finite indices of $x^{-1}Gx$ in $G$ and $x^{-1}Gx$","Denote $G=\text{SL}(n,\mathbb Z)$ and let $x\in \text{SL}(n,\mathbb R)$ such that $$[G:x^{-1}Gx\cap G],[x^{-1}Gx:x^{-1}Gx\cap G]<\infty.$$
  Prove that $x\in\text{SL}(n,\mathbb Q)$. I know that $\text{SL}(n,\mathbb Z)$ is finitely generated but somehow I can't find how to use that to show that the entries of $x$ are all rational. The best I got is that for $n=2$, by some calculation, $x=\sqrt q M$ where $q\in\mathbb Q,M\in\text{GL}(2,\mathbb Q)$. From there I couldn't prove that $\sqrt q\in\mathbb Q$. Can I get a hint how to proceed? even for the case of $SL(2,\mathbb Z$)?","['matrices', 'abstract-algebra', 'group-theory', 'linear-groups']"
1873859,Interesting probability question - husband and wife committee variation,"Twenty husbands and wives (ten couples) are randomly divided into two groups. What is the probability that at exactly 4 wives are in the same group
as their husbands? Attempt: There are $\binom{40}{2}=780$ numbers of posible committees by dividing the couples into two groups. The way I thought about this problem was to have a bag filled with two colored balls both numbered 1-10 and drawing them out one by one. If there are exactly 4 couples together in a group that means there must be 1 male female pair in a committee with a different partner, or with the ball example two different colored balls with different numbers. So the number of ways of having a committee with exactly 4 couples is the number of pairs $$(1,2), \dots (1,10), (2,3), \dots (2,10), (3,4), \dots (3,10), \dots (9,10) = \sum_{i=1}^9 i = 45$$
therefore the probability is $45/780.$ Can anyone confirm this answer? I think it is wrong and I also think there is a much more elegant solution.","['permutations', 'combinatorics', 'probability-theory', 'probability']"
1873886,"surface to surface map, $f$ is closed but neither open nor continuous","I'm trying to teach my self topology. The book I'm using has the following problem: Give an example of two subsets $X,Y \subseteq \mathbb R ^2$, both considered as topological spaces with their Euclidean topologies, together with a map $f : X \rightarrow Y$ that has the property: * $f$ is closed but neither open nor continuous. I went a little overboard on this one, and made my own programs to visualize the function and it's inverse. I basically have 2 questions: (1)I have an example that I'm pretty sure is good. Is it a good example and are my justifications valid? (2) Can anyone please come up with another example of a surface to surface map? $g$ is a function that is used in the main function $f$. $
g(x,y) = \left\{
        \begin{array}{ll}
            x+y+10 & \quad max(|x|, |y|) \leq 2 \\
            x+y & \quad  \text{ else } 
        \end{array}
    \right.
$ $X=[-4,4]\times[-4,4]$ $Y=[0,32]\times[-14,14]$ $f: X \rightarrow Y$ $f(x,y) = (x^2+y^2, g(x,y) )$ The above figure, made by my computer program, shows the mapping of $f$. The function is not one-to-one, so if the entire domain was mapped, there would be 2 ""sheets"" (like a Riemann surface). I choose to visualize this by coloring the points below y=x and above y=x in such a way that their mapping would produce an identical image. I also included the equations of the boundaries of the range. (not open) Let $D = B_1(0,0)$ (the unit disk). Let $R$ be the region bounded by $x \geq \frac{1}{2}y^2-10y+50$  and $x < 1$. Then $f(D) = R$. $D$ is open, and $R$ is not open. ( see diagram below) The above figure, shows the mapping of the domain and range of the unit disk.  The image of the  boundary of the disk is a line segment on the line x=1, shown as rainbow colors. The Image of the line x=y, shown in magenta, is a close boundary. Some of the coordinates are also shown, to illustrate the scale. (not continuous) The diagram below shows an open ball,let's call it $U$, in the co-domain of $f$, it also shows how $f^{-1}$ would map the ball. The ball is connected on the left, but broken into two disjoint regions on the right. The blue edge(on the right) is ""closed""; $f^{-1}(U)$ is not open; The pre-image of $U$ is not open, and thus, $f$ is not continuous. (see diagram below) The above figure shows the inverse mapping. It does not perfectly map the range back to the domain due the the precision limitations of my program. I included a red dot, labeled with a 'p', to show that the pre-image of a point will be two points,(because the function is not one-to-one). The disk on the left is broken into two parts on the right. The blue edge is closed and the purpler edge is open. (closed) I'm not sure how to definitively prove the function is closed, but un-closed function seem to have something relate to a horizontal asymptote, and this function doesn't have anything like that.","['general-topology', 'metric-spaces', 'visualization', 'proof-verification']"
1873891,"Prove or disprove: $\bigcap_{n\in\mathbb{N}}\left[-\frac{1}{n!},1+\frac{1}{2^{n}}\right]=\left \{ 1,2 \right \}$","Prove or disprove:
  $\bigcap_{n\in\mathbb{N}}\left[-\frac{1}{n!},1+\frac{1}{2^{n}}\right]=\left
\{ 1,2 \right \}$ I have problems understanding the symbols. $\bigcap_{n\in\mathbb{N}}$ stands for intersection, right? If so, what actually is intersected here? What's meant by $\left[-\frac{1}{n!},1+\frac{1}{2^{n}}\right]$, especially by those brackets? For me it looks like this is an interval, starting from $-\frac{1}{n!}$ going till $1+\frac{1}{2^{n}}$. What is meant by $\left \{1,2 \right \}$? This seems to be a set, right? So the complete thing in words is saying: the intersection of the interval $\left[-\frac{1}{n!},1+\frac{1}{2^{n}}\right]$ equals the set $\left \{1,2 \right \}$, is that correct? I would solve it like that: We know that $n\in\mathbb{N}$ which is very important info. Starting from $1$, I would insert several values for $n$ in the interval: For $-\frac{1}{n!}$ we will always get negative rational numbers which is bad (bad in that case that this will most likely lead to a contradiction. For $1+\frac{1}{2^{n}}$ we will get positive rational numbers which is also bad. Since there is no way to even get a single positive natural number, we can never get to the set $\left \{1,2 \right \}$. So the statement is wrong. I hope I understood most things correctly?","['sequences-and-series', 'calculus', 'analysis']"
1873927,A hyperbolic set which is a unique center manifold,"Consider the first order ODE
\begin{equation}
\dot{x} = f(x),
\end{equation}
with $x \in \mathbb{R}^3$ and $f: \mathbb{R}^3 \rightarrow \mathbb{R}^3$ a smooth function. We assume that the ODE only has equilibria for $x=(0,0,x_3)$ for all $x_3 \in \mathbb{R}$. Furthermore, assume that the Jacobian of $f$ at $x=(0,0,x_3)$ has one positive, one negative and one zero eigenvalue. Does it then follow that the center manifold $W^{c}(0,0,x_3)$ is unique? It is not hard to see that $\{ (0,0,x_3) \; : \; x_3 \in \mathbb{R} \}$ is a center manifold. In the case that you have 2 positive or 2 negative eigenvalues it is easy to see that the center manifold is unique by making use that the unstable or stable manifold which foliates the whole space. This argument does not extend to the `saddle' case so I am not sure how to proceed. It also might be that it is not true so a counter example would also be highly appreciated.","['ordinary-differential-equations', 'dynamical-systems']"
1873936,Examples of smooth fractals,"A classic example of a fractal curve is the Koch Snowflake .  This is a topological manifold (as opposed to many other fractals which are not), but it also clearly not smooth. Question : Are there any curve-type fractals that are actually smooth?  Or does the infinite self-similarity eventually pose an insurmountable barrier to smoothness? Technically speaking, $\mathbb{R}$ is a smooth fractal too, so for the above question, I'd only introduce the caveat that the curve be 'interesting' as a fractal (or at least non-trivial). Intuitively, I see no reason for such objects to not exist, but this is far from any area of math I'm familiar with.","['real-analysis', 'plane-curves', 'fractals', 'geometry']"
1873972,Integrating $\displaystyle\int \frac{1+x^2}{1+x^4}dx$,"I am trying to integrate this function, which I got while solving $\int\frac{1}{\sin^4( x) + \cos^4 (x)}$ : $$\int \frac{1+x^2}{1+x^4}\mathrm dx$$ I think to factorise the denominator, and use partial fractions. But I cant seem to find roots of denominator. I also am unable to think substitution.","['integration', 'calculus']"
1873980,$H^1(\mathbb{R}^3)$ vs $H^1_0(\mathbb{R}^3\!\setminus\!\{0\})$,"I would like to understand whether the spaces $H^1(\mathbb{R}^3)$ and $H^1_0(\mathbb{R}^3\!\setminus\!\{0\})$ are the same or not. The first space is the standard Sobolev space, for which one also has $H^1(\mathbb{R}^3)=\overline{C^\infty_0(\mathbb{R}^3)}^{\|\,\|_{H^1}}$, that is, the closure in the $H^1$-norm of the smooth functions compactly supported away from the origin. The second space is, by definition, $H^1_0(\mathbb{R}^3\!\setminus\!\{0\})=\overline{C^\infty_0(\mathbb{R}^3\!\setminus\!\{0\})}^{\|\,\|_{H^1}}$. Clearly, $H^1_0(\mathbb{R}^3\!\setminus\!\{0\})$ is a closed subspace of $H^1(\mathbb{R}^3)$. Thus, an equivalent version of the question is: is the space $C^\infty_0(\mathbb{R}^3\!\setminus\!\{0\})$ dense in $H^1(\mathbb{R}^3)$ ?","['functional-analysis', 'sobolev-spaces']"
1873992,Are there any conditions of integration?,"When we differentiate a function $f(x)$, there are conditions under which the derivative would not exist and cannot become differentiable. However, I have tried looking online for any conditions for integration and I haven't found anything. Are there any cases where $F(x)$ does not exist from $\int f(x)dx$? In other words, what makes a function non-integrable?","['integration', 'calculus']"
1874029,The circle is not contractible,"I know that the circle is not contractible because I know that $\pi_1(S^1)\cong \mathbb Z$. But something is going wrong in my head. Choose a basepoint $*$ on the circle and chose an orientation (clockwise say) and for each point on the circle we take the path from that point to the base point $*$ going clockwise and making only one tour, meaning the first time we meet $*$ we stop. This seems to give us a continuous way to contract the circle onto $*$, making the circle contractible,  what is wrong with this reasoning ?","['algebraic-topology', 'general-topology', 'homotopy-theory']"
1874128,How to solve $y'''+2y''-y'-2y= e^x+x^2$?,The equation that needs to be solved is: $$y'''+2y''-y'-2y= e^x+x^2$$ Steps: homogeneous solution and then the particular part.Bbut how do i handle the particular part? Do i need to take them once at a time?,"['ordinary-differential-equations', 'calculus']"
1874130,Prove that $\frac{1}{x^{1+\epsilon}}<\frac{1}{x(\log x)^p}$,"Given $p>0$, $\epsilon>0$, prove that $\displaystyle \frac{1}{x^{1+\epsilon}}<\frac{1}{x(\log x)^p}$ for sufficiently large $x$. If $p\leq \epsilon$, then $(\log x)^p\leq x^p\leq x^\epsilon$. So the result is clear. But what if $p>\epsilon$? Any suggestion please.","['logarithms', 'real-analysis', 'inequality', 'functions']"
1874132,Comprehension Axiom and Intersections,"I'm reading Goldrei's very good self-study book, Classic Set Theory , and am confused by his remarks on the Comprehension (Separation) Axiom.  He says that one might naively think that the intersection of a and b exist if a and b do because one can form the set of all z, such that z is in a and z is in b.  But he says this won't work on the grounds that ""we...need the zs to be 'separated' out of some set x.""  I don't follow this reasoning.  Why isn't a itself such a set?",['elementary-set-theory']
1874159,How can I answer this Putnam question more rigorously?,"Given real numbers $a_0, a_1, ..., a_n$ such that $\dfrac {a_0}{1} + \dfrac {a_1}{2} + \cdots + \dfrac {a_n}{n+1}=0,$ prove that $a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n=0$ has at least one real solution. My solution: Let $$f(x) = a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n$$ $$\int f(x) = \dfrac {a_0}{1} x + \dfrac {a_1}{2}x^2 + \cdots + \dfrac {a_n}{n+1} x^{n+1} + C$$ $$\int_0^1 f(x) = \left[ \dfrac {a_0}{1} + \dfrac {a_1}{2} + \cdots + \dfrac {a_n}{n+1} \right]-0$$ $$\int_0^1 f(x) = 0$$ Since $f$ is continuous, by the area interpretation of integration, it must have at least one zero. My question is, is this rigorous enough? Do I need to prove the last statement, perhaps by contradiction using Riemann sums? Is this a theorem I can/should quote?","['contest-math', 'proof-writing', 'calculus']"
1874168,Automorphic forms and the Rankin Selberg method,"I was just solving an Exercise, where we looked at an analytic function $\phi : \mathbf{H} \to \mathbf{C}$, which is automorphic and $\phi (z) = \mathcal{O}(y^{-C})$ for all $C > 0$ as $z \to i \infty$ (we write $z = x + iy$). I think that this implies that $\phi$ is constant, since it is a modular form of weight zero. The solution to the Exercise however is three pages long and is about proving that $$\Lambda_\phi (s) := 2 \pi^{-s} \Gamma (s) \zeta(s) \mathcal{M}(\phi)(s - 1)$$ satisfies the functional equation $$\Lambda_\phi (s) = \Lambda_\phi(1 - s)$$
where $\mathcal{M}(\phi)(s)$ is the Mellin-transform $\int_0^\infty \phi(x + iy) y^{s - 1} dy$. This is referred to as ""the simplest case of the Rankin-Selberg-method"". The statement gets rather easy if $\phi$ is constant. So my question is: What was the actual point of the Exercise? I was hoping for someone to recognize a formulation of the Rankin-Selberg-method (which I have only seen stated differently in the sources I considered) or of a general tool that is used in the theory. Thanks! Added: Thinking about the problem again and looking at the specific example of the non-holomorphic Eisenstein series $$E(z, s) = \sum_{(m, n) \in \mathbf{Z}^2, \, (m, n ) \neq (0, 0)} \frac{y^s}{\vert m z + n \vert^{2s}}$$ I suppose that the only weakening on $\phi$ that is necessary is to make $\phi$ a smooth function in $x$ and $y$, instead of a holomorphic function. But my question is still: ""What is the context of this exercise?""","['number-theory', 'complex-analysis', 'analytic-number-theory', 'modular-forms']"
1874170,"Cox, Little, O'Shea exercise 2.3.11","Let $f_1,\dots, f_s\in k[x_1,\dots, x_n]$ and $LM(f_i)=x^{\alpha(i)}$ the leading monomial of $f_i$. Define \begin{align*}
&Δ_1 = α(1) + \mathbb{Z}^n_{≥0},\\
&Δ_2 = (α(2) + \mathbb{Z}^n_{≥0}) \setminus Δ_1,\\
&\;\vdots\\
&Δ_s = (α(s) + \mathbb{Z}^n_{≥0}) \setminus
\left(\bigcup^{s−1}_{i=1}
Δ_i
\right)
,\\
&\overline{Δ} = \mathbb{Z}^n_{≥0} \setminus
\left(\bigcup^{s}_{i=1}
Δ_i
\right)
.
\end{align*} I've been asked several questions about the division algorithm for multivariate polynomials described in Ideals, Varieties, and Algorithms using this construction. One of them, which I've solved: (c) Show that in the expression $f = q_1 f_1 + \dots + q_s f_s + r$
   computed by the division algorithm, for every $i$, every monomial
   $x^β$ in $q_i$ satisfies $β + α(i) ∈ Δ_i$, and every monomial $x^γ$ in
   $r$ satisfies $γ ∈ \overline{Δ}$. But then, there's the following: Show that there is exactly one expression $f = q_1 f_1 + \dots + q_s
 f_s + r$ satisfying the properties given in part (c). How can I show that uniqueness? So far I've thought that, since $LT(q_1f_1)=LT(f)=LT(q_1'f_1)$, it must be the case that $LT(q_1)=LT(q_1')$, but I don't know what to do with this.","['algorithms', 'polynomials']"
1874176,Evaluation of $\int^{\pi/2}_{0} \frac{x \tan(x)}{\sec(x)+\tan(x)}dx$,"Evaluate the given integral: $$\int^{\pi/2}_0 \frac{x \tan(x)}{\sec(x)+\tan(x)}dx$$ I multiplied and divided by $\sec(x)+\tan(x)$ to get denominator as $1$ but  In calculation of integral, $x$ is creating problem. Is there any way to eliminate $x$ here, like it would have been eliminated if upper limit was $\pi$?","['integration', 'definite-integrals', 'calculus']"
1874193,Find $2$ to the power $p^2-1$ modulo $p$,"Given a prime number $p>2$, find $2^{p^2-1}$ modulo $p$. I know Fermat's and Euler's theorem but I can't apply them here. Any help would be grateful.","['number-theory', 'prime-numbers', 'elementary-number-theory']"
1874198,Find the derivative of $f(x) = \frac{e^{x^{2}} (\arcsin{x})^{2}x\sqrt{\cos{x}}}{(\ln{x})^{6} \sin^{2}x}$,"Question: Find the derivative of: $$f(x) = \frac{e^{x^{2}} (\arcsin{x})^{2}x\sqrt{\cos{x}}}{(\ln{x})^{6} \sin^{2}x}$$ Attempted Solution The most productive approach seems to be logarithmic differentiation: $$\ln |f(x)| = \ln \left|\frac{e^{x^{2}} (\arcsin{x})^{2}x\sqrt{\cos{x}}}{(\ln{x})^{6} \sin^{2}x}\right|$$ Distributing the natural logarithm function gives addition instead of multiplication and subtraction instead of division: $$\ln \left|\frac{e^{x^{2}} (\arcsin{x})^{2}x\sqrt{\cos{x}}}{(\ln{x})^{6} \sin^{2}x}\right| = \ln |e^{x^2}| + \ln |(\arcsin x)^2| + \ln |x|$$
$$+ \ln |\sqrt{\cos x}| - \ln |(\ln x)^6| - \ln |\sin^2 x|$$ Taking the derivative of both sides gives us: $$f'(x) = f(x) \left( \frac{2 e^{x^2}}{e^{x^2}} + \frac{2 \arcsin x}{(\arcsin x)^2} \frac{1}{\sqrt{1-x^2}} + \frac{1}{x} + \frac{-\sin x}{2 \cos x} + \frac{6 (\ln x)^5}{(\ln x)^6} \frac{1}{x} - \frac{2 \sin x \cos x}{\sin x}\right) $$ Simplifying gives: $$f'(x) = f(x) \left( 2 + \frac{2}{\arcsin x \sqrt{1-x^2}} + \frac{1}{x} -\frac{1}{2} \tan x + \frac{6}{x \ln x} + 2\cos x \right)$$ However, this is not the correct answer. In particular, the first and last terms are wrong. Where and how did it go wrong?","['derivatives', 'calculus']"
1874224,Proving $\lim\limits_{x\rightarrow 1} \frac{x^2+3}{x+1}=2$ using the formal definition of the limit,"Prove $\lim\limits_{x\rightarrow 1} \frac{x^2+3}{x+1}=2$ using the formal definition of the limit. My question is, I've picked $\delta\lt1$, and I've found that $\delta \lt \min(1,\sqrt{\epsilon})$. Was picking $1$ problematic at all? and is my choice for $\delta$ correct? Rest of Proof: $$0\lt|x-1|\lt \delta \Rightarrow \left|\frac{(x-1)^2}{x+1}\right|\lt \epsilon$$ Picking $\delta \lt 1$: $$|x-1|\lt 1 \Rightarrow -1\lt x-1 \lt 1$$ And we get from that $\frac13 \lt \frac{1}{x+1} \lt 1$ which leads to $\left|\frac{1}{x+1}\right| \lt 1$ Let's go back: $$\left|\frac{(x-1)^2}{x+1}\right|\lt \left|1(x-1)^2\right|\lt \epsilon$$ Since $(x-1)^2\gt 0$ we can get rid of the absolute value
and we get $$(x-1)^2\lt \epsilon \rightarrow x-1 \lt \sqrt{\epsilon}$$ Also: What is the difference between picking $\delta=1$ and $\delta \lt 1$","['epsilon-delta', 'calculus', 'limits']"
1874236,There at least 4 divisors of $n-1$ which do not divide $\phi(n)$ if $n$ is a composite of the form $6k+1$.,"I observed that if $n$ is a composite number of the form $6k + 1$ then there are at least three divisors of $n - 1$ which do not divide $\phi(n)$ (Euler's totient function). Is this true in general? Edit 1: As pointed out by Gerry, the same has been posted in MO Edit 2: Changed the title after the proof of the claim.","['number-theory', 'prime-numbers', 'modular-arithmetic', 'elementary-number-theory']"
1874262,Infinite series with cos in numerator,"How do you evaluate this series? $$\sum_{i=1}^{\infty}\frac{\cos i}{2^i}$$ It's absolutely convergent by comparison to the geometric series. But the $\cos$ is tripping me up. I've tried differentiating in order to go through the $\cos$ -> $\sin$ -> $\cos$ route, but that gives me different powers of 2 in the denominator. Any ideas?",['sequences-and-series']
1874274,$x^4 - 4x^3 + 6x^2 - 4x + 1 = 0$,"Determine all the possibilities for rational roots of the polynomial $x^4 - 4x^3 + 6x^2 - 4x + 1 = 0$. Then determine how many of the real roots of the polynomial may be positive and how many may be negative. Factor the polynomial to confirm your results. The answer is possible rational roots: $+-1$; number of possible real roots - positive: four or two or zero, negative: zero; actual roots: $x = 1, 1, 1, 1$ (a quadruple root). Using the rational root theorem, you divide the factors of the constant, $1$, by the factors of the lead coefficient, also a 1. That step gives you only two different possibilities for rational roots: $1$ and $-1$. The signs change four times in the original polynomial, indicating $4$ or $2$ or $0$ positive real roots. Replacing each $x$ with $-x$, you get $x^4 + 4x^3 + 6x^2 + 4x + 1 = 0$. The signs never change. The polynomial is the fourth power of the binomial $(x - 1)$, so it factors into $(x - 1)^4 = 0$, and the roots are $1, 1, 1, 1$. There are four positive roots (all the same number, of course). Can someone explain, the factorization of the polynomial? I do not understand, how it factors into $(x - 1)^4$.",['algebra-precalculus']
1874282,Limit Involving a Product of a Sequence: $\lim _{x\to\infty }\left(1-\frac1{2^2}\right)\left(1-\frac1{3^2}\right)\dots\left(1-\frac1{x^2}\right)$ [duplicate],"This question already has answers here : Finding Value of the Infinite Product $\prod \Bigl(1-\frac{1}{n^{2}}\Bigr)$ (6 answers) Closed 7 years ago . I am having trouble figuring out how to solve this limit. $$\lim _{x\to \infty }\left(\left(1-\frac{1}{2^2}\right)\left(1-\frac{1}{3^2}\right)...\left(1-\frac{1}{x^2}\right)\right)$$ I understand that as '$x$' increases, the overall product becomes an even smaller number between $0$ and $1$  only because I tried plugging in numbers in hope to learn about the nature of the expression. But I can't seem to come to a pattern that will allow me to efficiently simplify it and solve the limit. Help, anyone?","['infinite-product', 'sequences-and-series', 'limits']"
1874299,Finding a differential equation orthogonal to a family of curves,"The question is: Consider the family $F$ of circles in the $xy$ plane, $(x-c)^2+y^2=c^2$ tangent to the $y$ axis at the origin. Find a differential equation that is satisfied by the family of curves orthogonal to $F$. My thinking: Since the implicit equation represents the level sets of the function $$
f(x,y)=c^2=(x-c)^2+y^2
$$
The gradient of the function $f$ will be perpendicular to its level sets, and therefore orthogonal to the family of curves $F$. This yields
$$
\nabla f(x,y)=(0,0)=(2x-2c,2y)\Rightarrow \left(x-\frac{x^2+y^2}{2x},y\right)=(0,0)\\
\Rightarrow \left(\frac{x^2-y^2}{2x},y\right)=(0,0)
$$
So we have in differential form
$$
\frac{x^2-y^2}{2x}dx+ydy=0\Rightarrow \frac{y^2-x^2}{2xy}=\frac{dy}{dx}
$$
But the answer is the negative reciprocal, or perpendicular vector to this one. Why? I assume my reasoning was flawed in the first step, when i took the gradient of $f$ to be perpindicular to the family $F$, but I don't see why.","['multivariable-calculus', 'ordinary-differential-equations', 'vector-analysis']"
1874340,Calculate the following integral,"$$\int_{[0,1]^n} \max(x_1,\ldots,x_n) \, dx_1\cdots dx_n$$ My work: I know that because all $x_k$ are symmetrical I can assume that $1\geq x_1 \geq \cdots \geq x_n\geq 0$ and multiply the answer by $n!$ so we get that $\max(x_1\ldots,x_n)=x_1$ and the integral that we want to calculate is
$n!\int_0^1 x_1 \, dx_1 \int_0^{x_1}dx_2\cdots\int_0^{x_{n-1}} \, dx_n$ and now it should be easier but I'm stuck.. Can anyone help?","['integration', 'analysis', 'riemann-integration']"
1874399,Power set notation,"Probably a really simple question: I'm currently studying automata theory and I have come across the notation 2^S. Wikipedia says it means the power set of S which is the set of all subsets of S including the empty set and S itself (S itself = all the elements in S). This makes pretty good sense regarding the automata theory I'm reading about. But I'm wondering whether the number, 2, is always the number to use, or if the number used depends on something. For instance, in my reading about automata theory, an alphabet like {0, 1} is being used and also on Wikipedia {0, 1} is being used. Also on Wikipedia it says the following: As ""2"" can be defined as {0,1}. So does the number being used depend on the number of elements in the set/alphabet, or is it correct to always use the number 2?","['elementary-set-theory', 'automata']"
1874462,Does not exist cover of $\mathbb{R}^n$ by disjoint closed balls,"Does not exist cover of $\mathbb{R}^n$ by disjoint closed balls with positive radius. My attempt: Suppose that exists, we can write: $\mathbb{R}^n=\displaystyle\bigcup_{i=1}^{\infty} B_{i}$. Let $C$ denote the set of center points of these balls. All points of $C$ are isolated so $C$ is countable. Associating each point of $C$ to the ball of wich this point is the center,it is easy see that this association is a bijection, concluding that set of balls is countable. The set of limit points of $C$, $C^{'}=\displaystyle\bigcup_{i=1}^{\infty} \partial B_{i}$. I thought it would be easy to find a contradiction there, I was wrong. Until now, I don't use hypothesis that $B_{i}$ is closed, and I think that is it that lack in my demostration. Is it true if the balls are open? Thank you for any help.","['general-topology', 'analysis']"
1874476,Infinitesimal generator of Brownian motion with additional jumps,"A compound Poisson process is a jump process with two parameters, the rate of the jumps $\lambda$ and the distribution of the jumps $\mu$ ($\mu$ is a probability measure on $\mathbb{R}$). The infinitesimal generator of this process is given by:
$$A_{\lambda,\mu}f(x) = \lambda\int_\mathbb{R} (f(x+z)-f(x))\mu(dz)$$
What happen if I take a brownian motion with generator $\frac{1}{2}f''$ and construct the process with generator $\frac{1}{2}f''+A_{\lambda,\mu}$.
Is this process the sum of a brownian motion with an a independent compound poisson process with parameters $\lambda, \mu$? If the answer is yes, How we can generalize this notion? for example, If we take a general process with generator $L$ and we construct the process with generator $L+A$ is this process the sum of a $L$-process and a independent $A$-process. I think that total generality it is not true because the $L$-process can have jumps with rate dependent on the state. Any help will be appreciated!","['probability-theory', 'markov-process', 'probability']"
1874504,Class Number of $\mathbb{Q}(\sqrt[3]{19})$ and Hilbert class field,"Finding the class number of $\mathbb{Q}(\sqrt[3]{19})$ is an exercise from Marcus 'Number Field'. This question was uploaded by some other user, but it was removed by now. I have worked on details and have some more questions. Following are the steps in the exercise: Let $K=\mathbb{Q}(\alpha)$, $R=\mathcal{O}_K$, and $3R=P^2Q$, where $\alpha=\sqrt[3]{19}$, and $P$, $Q$ are prime ideals in $R$. (a) Prove that the ideal class group is cyclic, generated by the class containing $P$. (b) Prove that the number of ideal classes is a multiple of $3$. (c) Prove that there are either three or six ideal classes. (d) Prove that there are three ideal classes. (Suggestion: Suppose there were six. Show that none of the ideals $J$ with $||J||\leq 9$ are in the same class with $P^3$. ) After solving this problem, it seems that the calculations from my solution to (a) are enough to conclude that the class number is $3$. To do (a), we find the Minkowski's bound:
$$
\frac{3!}{3^3}\frac 4{\pi} \sqrt{1083} \approx 9.3
$$
This shows that each ideal class in the ideal class group contains an ideal $J$ with $||J||\leq 9$. Also, each ideal class generating the class group contains a prime ideal lying above $2$, $3$, $5$, $7$. So, we find prime factorizations of $2R$, $3R$, $5R$, $7R$: 
$$
2R=P_1P_2,\ \ \ 3R=P^2 Q,$$
$$5R= P_3P_4, \ \ \ 7R = P_5,$$
with $P_1=(2, \alpha-1)$, $P=(3, \frac{\alpha^2+\alpha+1}3)$, $P_3=(5,\alpha+1)$. With a help of SAGE, I found that 
$$P_1= \frac{\alpha-1}3 P, \ \ \  P_3= \frac{-\alpha+4}3 P, \ \ \ P_5=\frac{7\alpha+14}9 P^3.$$ Then the prime ideals appear above (as factorizations of $2$, $3$, $5$, $7$) belong to one of the three ideal classes of $P$, $P^2$, $I$ (principal). My questions are Are these calculations enough to conclude that the ideal class group has order $3$? If the answer to 1 is no, then how are the rest of parts solved? How do we determine the Hilbert class field of $\mathbb{Q}(\sqrt[3]{19})$?","['number-theory', 'class-field-theory', 'algebraic-number-theory']"
1874517,"Proving that $\lim_{(x,y) \to (0,0)} (x^2 +y^2 -x^3 y^3)/(x^2 +y^2) =1$","How can I go about proving that $$\lim_{(x,y) \to (0,0)} \frac{x^2 +y^2 -x^3 y^3}{x^2 +y^2} = 1 ?$$ I checked some lines along $x, y$ and $x=y$ and it all gave $1$","['multivariable-calculus', 'calculus', 'limits']"
1874522,Solutions to Binary Equations,"Let $A \in \mathrm{Mat}(m,n,\{0,1\})$ (i.e. $m \times n$ matrices with entries in $\{0,1\}$ ) and $x,y\in \{0,1\}^n$. We will denote the $i$-th row of $A$ as $\mathrm{row}_i(A)\in \{0,1\}^n$. Define,
$$
 z_i := 
     \begin{cases}
       1~: & (x-y)\cdot \mathrm{row}_i(A) = \sum_{j=1}^n x_j\\
       0~: & \text{otherwise}\\
\end{cases}
$$ where $x_j$ is the $j$-th component of $x$ and $\cdot$ denotes the dot product. Is there an algorithm to determine all $x,y$ given a vector $z=(z_1,...,z_m)$? Example: Let $$A=
        \begin{bmatrix}
        0 & 0 & 1\\
        1 & 1 & 0\\
        1 & 0 & 1\\
        \end{bmatrix}
$$ and $z=(1, 0, 1)$. Then $x=(0,0,1)$ and $y=(0,1,0)$ would satisfy the conditions described.","['matrices', 'combinatorics']"
1874535,Is the singular locus of a variety (as a variety itself) a smooth variety?,"A general fact about the singular locus $Sing(X)$ of a variety $X$ (analytic or projective) is that they form a subvariety of the oringinal variety $X$. And we know that the boundary of a manifold have no boundary itself. My simple question is that Is $Sing(X)$ (as a variety itself) a smooth variety ? Intuitively, I can't imagine a picture such that the answer is no. If the answer is no, another question is that does the singular locus $Sing(X)$ necessarily have dimension less than that of $X$ ?","['analytic-geometry', 'differential-geometry', 'algebraic-geometry', 'geometry']"
1874542,"map $x+y \le 1, x,y >0$ to $R^2$? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Is there a bijective continuous function which can map $x+y \leq 1, x,y >0$ to $R^2$? I appreciate any idea and comment.","['real-analysis', 'elementary-set-theory']"
1874548,Finding the boundaries on a triple integral,"Solve:
$$\iiint yz \,dV$$
Over the tetrahedron with vertices on the points $$A(0,0,0), B(1,1,0), C(1,0,0), D(1,0,1)$$ 
Well, I proceeded to find a the equation of a plane which contained B, C and D. 
If I did it correctly which I think I did, the plane equation is x=1.
My problem arises when choosing the limits. I can't find a relation between x, y and z.So by looking at the graph I concluded that the upper limits would all be 1.
$$\int^1_0\int^1_0\int^1_0yz \,dx\,dy\,dz$$
Was I correct to make this assumption? Otherwise, where did I make a mistake?
Thanks.","['multivariable-calculus', 'integration']"
1874573,"A trivial combinatorics result I found, is my proof correct?","I have just finished highschool and have started learning on my own some combinatorics and how to do proofs, and while messing around with sums and Pascal's triangle I found an interesting yet trivial property that I tried to prove. I'm assuming that it has already been found, but I couldn't find anything mentioning it. So my questions are: Is my proof correct? Has this property been found already? What can this property be used for? Let $$f(x,n)= \sum_{i_1=1}^n \sum_{i_2=1}^{i_1} \sum_{i_3=1}^{i_2} \cdots \sum_{i_x=1}^{i_{x-1}}i_x \ $$
where $x$ is the number of sigma sums. My conjecture is that $$f(x,n)={n+x \choose x+1}$$ Proof by induction Basis step: $$\begin{align}
f(1,n) &=\sum_{i=1}^ni\\
&=\frac{n(n+1)}{2}\\
&={n+1 \choose 2}
\end{align}$$
The basis step works. This first result is already proven for all n. Inductive step: Assume that $f(x,n)= {n+x \choose x+1} $ Now, $$\begin{align}f(x+1,n) &=\sum_{m=1}^n \sum_{i_1=1}^{m} \sum_{i_2=1}^{i_1} \cdots \sum_{i_x=1}^{i_{x-1}}i_x\\
&=\sum_{m=1}^n f(x,m)\\
&=\sum_{m=1}^n {m+x \choose x+1}\\
&=\sum_{l=0}^{n-1}{l+1+x \choose x+1}\\
&={n+x+1 \choose x+2}\\ \end{align}$$
Therefore, if $f(x,n)$ holds, then $f(x+1,n)$ holds. What I am not sure about is whether I have to use induction to prove that this property holds for every integer $n$ as well,",['combinatorics']
1874581,Why use the Kronecker product?,I have found many references on Kronecker product but I did not see any reference talking about why this way of multiplication exist and whats the intuitive use of this particular product. Appreciate your suggestions!,"['matrices', 'kronecker-product', 'vectorization']"
1874598,Intermediate step in proving Cauchy's Integral Formula,"I'm trying to understand the proof of the Cauchy's Integral Formula from the J. Conway, Complex Integration book. He states that However, I don't know how to solve what he left as exercise 1, at the beginning of the proof. Can anyone give me a hint? Thanks",['complex-analysis']
1874662,Showing that $I+tA$ is invertible using $f(t)=\det(I+tA)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $A \in \mathbb{R}^{n\times n}$ a square matrix with $\text{trace}(A) \neq 0$. I would like to show that $f : \mathbb{R} \to \mathbb{R}$, $$f(t)=\det(I+tA)$$ local while $t=0$ is invertible.","['matrices', 'analysis']"
1874672,derivative of cosine similarity,"What is derivative of cosine similarity between two vectors? I found a paper that refers the derivative of cosine similarity  ($\cos=\frac{v_i\cdot{v_j}}{|v_i||v_j|}$) is as below. $$
\frac{\partial{\cos}}{\partial{v_i}}=\frac{\cos\cdot{v_i}}{\left|v_i\right|^2}+\frac{v_j}{\left|v_i\right|\left|v_j\right|}.
$$ There's no detailed explanation in the paper and I couldn't find any derivation of the derivative in internet. Is the derivation correct? 
If it's correct, how the derivative is found?","['multivariable-calculus', 'partial-derivative']"
1874711,"If Brauer characters are $\bar{\mathbb{Q}}$-linearly independent, why are they $\mathbb{C}$-linearly independent?","If Brauer characters are $\bar{\mathbb{Q}}$-linearly independent, why are they $\mathbb{C}$-linearly independent? I think this is a linear algebra fact showing up when proving the irreducible Brauer characters on a finite group are linearly independent over $\mathbb{C}$. The proof I've seen observes that the characters take values in the ring of algebraic integers, and then proves linear independence over $\bar{\mathbb{Q}}$. Why is it sufficient to only check linear independence over $\bar{\mathbb{Q}}$? It seems like something could go wrong when extending the field all the way up to $\mathbb{C}$. The proof I'm reading is Theorem 15.5 in Isaacs' Character Theory of Finite Groups .","['representation-theory', 'abstract-algebra', 'linear-algebra', 'characters']"
1874725,Solving $\cos 3x = \frac{1}{\sqrt2}$,"So I have this equation: $$\cos 3x = \frac{1}{\sqrt2}$$ I get two answers: 
$$x = \frac{1}{12}(\pi + 8 \pi n) \qquad x = \frac{1}{12}(7 \pi + 8 \pi n )$$ What is $n$ in these cases?",['trigonometry']
1874736,Any smart ideas on finding the area of this shaded region?,"Don't let the simplicity of this diagram fool you. I have been wondering about this for quite some time, but I can't think of an easy /smart way of finding it. Any ideas? For reference , the Area is: $$\bbox[10pt, border:2pt solid grey]{90−18.75\pi−25\cdot \arctan\left(\frac 12\right)}$$","['puzzle', 'recreational-mathematics', 'area', 'geometry']"
1874758,Distribution determined by its cgf,"It is well known, that if the domain of the mgf $M:=E[e^{uX}]$ of a random variable $X$ contains an interval around zero, then the distribution is completely determined by its moments. Consider the cumulant generating function $k:=\log E[e^{uX}]$ with domain $D_t$. Of course $0 \in D_t$. Assume moreover $D_t$ is an intervall. 
Can we already say, that the cumulant transform completely determines its distribution? According to a statement of Jacod, Shiryaev  Limit theorems for stochastic processes p. 612 mentoined in 2.3 Proposition, this should hold We may have a process with domain $[0,\infty)$, which doesn't contain an interval around zero. If not, with the assumptions of $D_t$ above, can we say, that if all moments of $X$ exists, then $k$ determines the distribution of $X$?","['probability-theory', 'probability', 'stochastic-calculus', 'probability-distributions']"
1874759,Find the eigenvalues of a symmetric matrix,"Find the eigenvalues of a $3 \times 3$ symmetric matrix with $1$ on the main diagonal and  $\frac{1}{\sqrt 3}$ off the main diagonal. Since each row on addition give the same value, one of the three eigenvalue is $1+\frac{2}{\sqrt 3}$. Is there an easy way to find the other two values without using the formula $\det(A-\lambda I_3) = 0$.","['matrices', 'eigenvalues-eigenvectors', 'symmetric-matrices', 'circulant-matrices']"
1874796,Extending section of principal open subvariety,"Let $X$ be a variety (not necessarily affine) over an algebraically closed field. Is it true, that for any global section $f \in \mathcal{O}_X(X)$ the natural morphism
  $\mathcal{O}_X(X)_f \to \mathcal{O}_X(D(f))$
  is an isomorphism? Equivalently, we may ask: For $g \in \mathcal{O}_X(D(f))$ arbitrary, is there a nonnegative integer $n$ such that $gf^n$ can be extended to a global section of $X$? If necessary, we may further assume that $D(f)$ is affine.","['abstract-algebra', 'algebraic-geometry']"
1874816,How to show $\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}=2^{n}$,"How does one show that $$\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}=2^{n}$$ for each nonnegative integer $n$ ? I tried using the Snake oil technique but I guess I am applying it incorrectly. With the snake oil technique we have $$F(x)= \sum_{n=0}^{\infty}\left\{\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}\right\}x^{n}.$$ I think I have to interchage the summation and do something. But I am not quite comfortable in interchanging the summation. Like after interchaging the summation will $$F(x)=\sum_{k=0}^{n}\sum_{n=0}^{\infty}\binom{n+k}{k}\frac{1}{2^k}x^{n}?$$ Even if I continue with this I am unable to get the correct answer. How does one prove this using the Snake oil technique? A combinatorial proof is also welcome, as are other kinds of proofs.","['generating-functions', 'combinatorics', 'binomial-coefficients', 'combinatorial-proofs']"
1874818,Analogy and connection between roots of unity and the solutions to $f^{(n)}(x)=f(x)$,"In the number theory we have roots of unity, i.e. the $n$ solutions of: $$x^n=1,~~~n=1,2,3,\dots$$ $$x_1=1$$ $$x_2=(-1,1)$$ $$x_3=\left( 1, e^{\dfrac{\pi i}{3}}, e^{\dfrac{2 \pi i}{3}} \right)$$ $$x_4=(1,-1,i,-i)$$ etc. If we consider a simple ODE: $$f^{(n)}(x)=f(x),~~~n=1,2,3,\dots$$ We obtain a something very similar (in my opinion): $$f_1(x)=C e^x$$ $$f_2(x)=C_1 e^x+C_2 e^{-x}$$ $$f_3(x)=C_1 e^x+C_2 e^{-x/2} \sin \left( \frac{\sqrt{3}}{2} x \right)+C_3 e^{-x/2} \cos \left( \frac{\sqrt{3}}{2} x \right)$$ $$f_4(x)=C_1 e^x+C_2 e^{-x}+C_3 e^{ix}+C_4 e^{-ix}$$ etc. We can always switch between the exponential and trigonometric forms of course. Do these functions play as important role in functional analysis or other fields, as the roots of unity play in number theory? What are they called? What are some examples of their use? (I mean the whole set of these functions, not just the exponent or trig functions). If possible, please offer an intuitive explanation of the connection/analogy between roots of unity and these functions.","['functional-analysis', 'number-theory', 'ordinary-differential-equations', 'roots-of-unity']"
1874864,Finding the first $n$ digits in a multiplication,"I'm not sure how to best approach this type of problem. It seems reasonable that
there's going to be use of exponents, scientific notation. But I'm not familiar
with doing this type of problem. I would be grateful to see worked solutions to these so that I could apply the
method in future. Here's the problem","['algebra-precalculus', 'arithmetic']"
1874869,Evaluation of series $\sum \limits_{n=1}^{\infty} \frac{\arctan n}{n^2}$,"Can we find a closed form for the series: $$\mathcal{S}=\sum_{n=1}^{\infty} \frac{\arctan n}{n^2}$$ Here is some basic manipulation I did: \begin{align*}
\sum_{n=1}^{\infty} \frac{\arctan n}{n^2} &=\sum_{n=1}^{\infty} \frac{1}{n^2} \sum_{k=0}^{\infty} (-1)^{k-1} \frac{n^{2k+1}}{2k+1} \\ 
 &= \sum_{k=0}^{\infty}\frac{(-1)^{k-1}}{2k+1} \sum_{n=1}^{\infty} \frac{n^{2k+1}}{n^2}\\ 
 &= \sum_{k=0}^{\infty} \frac{(-1)^{k-1} \zeta(1-2k)}{2k+1}
\end{align*} Now unfortunately I don't know how to proceed further. Maybe the sum does not admit a closed form and all that I have done so far be in vain. Another way would be : $$\sum_{n=1}^{\infty} \frac{\arctan n}{n^2} =\mathfrak{Im} \left ( \sum_{n=1}^{\infty} \frac{\ln (1+in)}{n^2} \right )$$ Now I don't know how to sum the second series! Any help?","['real-analysis', 'sequences-and-series', 'calculus', 'closed-form']"
1874894,Prove: If $\lim_{x \to \infty}g(x)=0$ $ \Rightarrow \lim_{x \to \infty} f(x)=0$,"$\forall x \in \mathbb R$ $g(x)\gt 0 $ and $\displaystyle \lim_{x \to \infty} \frac{f(x)}{g(x)}=L \gt0$ Prove that 1.) If $\displaystyle \lim_{x \to \infty}g(x)=0$ then $\displaystyle \lim_{x \to \infty} f(x)=0$ 2.) Conclude that $\displaystyle \lim_{x \to \infty}g(x)=0 \iff \lim_{x \to \infty} f(x)=0$ 1.) Using the definition of limits: $\forall \epsilon_1 \gt 0$ , $N_1 \gt 0$ $$ x\gt N_1  \Rightarrow |g(x)| \lt \epsilon_1$$ $\forall \epsilon_0 \gt 0$ , $N_0 \gt 0$ $$ x \gt N_0  \Rightarrow \left|\frac{f(x)}{g(x)}-L\right| \lt \epsilon_0$$ Now doing a little bit of algebra: $$g(x)(-\epsilon_0+L)\lt f(x) \lt g(x)(\epsilon_0+L)$$ And using the fact that $|g(x)| \lt \epsilon_1$ : $$-\epsilon_1(-\epsilon_0+L) \le g(x)(-\epsilon_0+L)\lt f(x) \lt g(x)(\epsilon_0+L)\le \epsilon_1(\epsilon_0+L)$$ This turns into: $$-\epsilon_1(-\epsilon_0+L) \lt f(x) \lt \epsilon_1(\epsilon_0+L)$$ Are my steps correct thus far? Leaving the only thing left is picking a value for $\epsilon_1$ so that I end up with $|f(x)|\lt \epsilon$ ?","['calculus', 'limits']"
1874920,Is a hyperplane defined by four points?,Any 3 points define a plane and therefore ALWAYS lie on the same plane. The same goes for two points and a straight line. Does this mean that a hyperplane in four dimensional space is defined by any four points? Can the concept be applied to higher dimensions and still make sense or be useful?,"['plane-geometry', 'dimensional-analysis', 'geometry']"
1874926,Projective subschemes and their coordinate rings,"I have questions related to Hartshorne's Exercise II.5.14, set up as follows: Let $X$ be a connected normal closed subscheme of $\mathbb{P}^r_k$, where $k$ is an algebraically closed field, and write $S$ for the homogeneous coordinate ring of $X$. Also take $S' = \oplus_{n \ge 0} \Gamma(X,\mathcal{O}_X(n))$ and view it as a graded ring. I'm trying to show $S$ is a domain and $S'$ is its integral closure. So far, I've proven $X$ is an integral scheme. My current questions: It follows from the text (namely Exercise 3.12(b) and Corollary 5.16(a)) that $X$ can be identified with Proj $S$. If $S$ is a domain, surely Proj $S$ is integral; is the converse true? Hartshorne's suggestion is to view $S'$ as $\Gamma(X,\mathcal{F})$ for a sheaf of rings $\mathcal{F} = \bigoplus_n \mathcal{O}_X(n)$, and in fact show $\mathcal{F}$ is a sheaf of integrally closed domains. Can anyone provide a hint on how this might be done?","['schemes', 'sheaf-theory', 'algebraic-geometry']"
1874935,How would you proof that this series is convergent (no solution needed)?,"Analyze if the series is convergent:$$\sum_{n=0}^{\infty}\frac{2n^{3}+3n^{2}+1}{2^{n}}$$ I have used ratio test and I got $\frac{1}{2}$ as result which seems pretty good, it's also smaller than $1$... But I'm not looking for a solution here. Problem with ratio test was, it took me half of a page and too much time. I didn't even have to think how to deform while I used the ratio test, I did it really fast (anyway was slow). There aren't easier and faster ways of solving this? In the exam I only got 120 minutes and a task like that is one of many tasks there. I can imagine there is a way which doesn't require you more than 2 lines, I have needed almost 7 lines (half DIN A4)...","['convergence-divergence', 'sequences-and-series', 'calculus', 'analysis']"
1874960,How does the induction axiom rule out numbers other than the naturals?,"The set-theoretic formulation of the axiom of induction is as follows: Suppose $A \subseteq \mathbf{N}$, such that $0 \in A$ and $k+1 \in A$ whenever $k \in A$. Then $A = \mathbf{N}$ This axiom is supposed to rule out possibilities like $A = \mathbf{Q}$ or $A= [0, \infty)$, which satisfy the other Peano Axioms, but not the axiom of induction. But I don't understand how it rules out the above cases. Firstly, how do we know that the set $A$ is a subset of $\mathbf{N}$ without first defining what $\mathbf{N}$ is? Something seems circular here, which means I've yet to understand the axiom. Suppose $B$ includes $0$, $S(0), S(S(0))$, and so on, but it also includes fractions such as $\frac{1}{2}$. Induction supposedly prevents $B$ from being $\mathbf{N}$. But this means that we must know beforehand that $B \nsubseteq \mathbf{N}$, which seems circular. Note: I've searched for similar questions on this site, and while there is one which pretty much asks the same question, I could not find a satisfactory answer.","['induction', 'elementary-set-theory']"
1874970,YX - XY = X for nilpotent matrix,"Let $X$ be a matrix over $\Bbb C$, I have to show that exists a matrix $Y$ s.t. $YX - XY = X$ iff $X$ is nilpotent. What have I done? Given $Y$ exists, I have already shown that $tr(X^i)=0$ $\forall  i$ so $X$ is nilpotent.
I miss the converse. Thank you","['matrices', 'linear-algebra']"
1875000,A very useful lemma for Henstock-Stieltjes integration,"I'd like to see a proof (or hints and outlines) for the following lemma, which is very useful to prove some interesting properties, including an Integration by Parts theorem for Henstock-Stieltjes integrals: Let $f$, $g$ and $\varphi$ be (normally real) functions defined on
  $[a,b]$ and $f$ is $\varphi$-Henstock-Stieltjes integrable with
  $F(x)=\int_a^x f d\varphi$. Then $fg$ is $\varphi$-Henstock-Stieltjes
  integrable if and only if $g$ is  $F$-Henstock-Stieltjes integrable
  and so we have $$\int_a^b fg d \varphi =\int_a^b g d F.$$ I think I'm able to show a simple version of this lemma where $\varphi(t)=t$ following the proof of 9.17 (image) given in The Integrals of Lebesgue, Denjoy, Perron and Henstock by Gordon A Russel, which is even more simple: he also takes $g(t)=1$. I'd like to know if it's possible to adapt this proof for what I want, or if I have to start from scratch. This definition may be required:","['real-analysis', 'gauge-integral', 'integration', 'stieltjes-integral', 'measure-theory']"
1875022,How to integrate surface area of the Mobius strip using 'density'?,"https://www.quora.com/Can-you-do-a-surface-integral-on-a-mobius-strip According to this link, it is possible to integrate surface area of the non-orientable Mobius strip by using density. However, I'm trying to understand explanations in the Wikipedia, I don't know from which equation I should start to calculate it. Please help me.","['manifolds', 'mobius-band', 'differential-geometry', 'differential-topology']"
1875037,"If a holomorphic bundle is smoothly trivial, is it holomorphically trivial?","Let $E\rightarrow X$ be a holomorphic vector bundle which is smoothly trivial (i.e. $E$ has a smooth global frame). Can we say that $E$ is holomorphically trivial? If yes, then what about the following generalization? If $E_{1}$ and $E_{2}$ are two holomorphic vector bundles over a complex manifold $X$ which are smoothly isomorphic, then they are holomorphically isomorphic. If no, then does there exist an easy counterexample?","['complex-geometry', 'differential-geometry', 'holomorphic-bundles']"
1875045,Is this lot drawing fair?,"Sorry for a stupid question, but it is bugging me a lot. Let's say there are $30$ classmates in my class and one of us has to clean the classroom. No one wants to do that. So we decided to draw a lot - thirty pieces of paper in a hat, one of which is with ""X"" on it. The one who draws ""X"" has to do the cleaning. Each one starts to draw... Is this kind of lot drawing fair or not fair? It looks to me like the first one's chances to get an ""X"" are equal to $1/29$, while the second one's chances would be equal either to  $1/28$ (in case the first one didn't draw an ""X"") or zero $0/29 = 0$ (in case the first one drew an ""X""). However, neither $1/28$, nor $0/29$ is equal to $1/29$.",['probability']
1875066,How many number of primes below n such that they are sum of consecutive primes,"Given a number n , how many number of primes are there such that each of them is equal to  $$\sum_{k=0}^z p_k $$ where z is some natural number and $p_k$ is nth prime number i.e, $p_0=2$? For example, if n=20 , there are 2 primes 5,17 , they satisfy the above rules as follows: 5 = 2+ 3 17 = 2 + 3 + 5 + 7 So , is there any formula or any efficient method to identify how many such primes are there below a huge number n ?","['number-theory', 'prime-numbers']"
1875113,Integration by means of partial fraction decomposition,"I'm trying to solve this indefinite integral by means of partial fraction decomposition: $\int\dfrac{x+1}{\left(x^2+4x+5\right)^2}\ dx$. The denominator has complex (but not real) roots because $\Delta<0$; so, according with my calculus book, i try to decompose the integrand function in this form: $\dfrac{x+1}{\left(x^2+4x+5\right)^2}=
\dfrac{Ax+B}{\left(x^2+4x+5\right)}+\dfrac{Cx+D}{\left(x^2+4x+5\right)^2}$. I get: $\dfrac{x+1}{\left(x^2+4x+5\right)^2}=
\dfrac{\left(Ax+B\right)\left(x^2+4x+5\right)+Cx+D}{\left(x^2+4x+5\right)^2}$. Multiplying the right term: $\dfrac{x+1}{\left(x^2+4x+5\right)^2}=
\dfrac{Ax^3+4Ax^2+5Ax+Bx^2+4Bx+5B+Cx+D}{\left(x^2+4x+5\right)^2}$. Now i collect the terms with the same pwer of $x$: $\dfrac{x+1}{\left(x^2+4x+5\right)^2}=
\dfrac{Ax^3+\left(4A+B\right)x^2+\left(5A+4B+C\right)x+D+ 5B}{\left(x^2+4x+5\right)^2}$. Now i equate the two numerators: $x+1=Ax^3+\left(4A+B\right)x^2+\left(5A+4B+C\right)x+D$ and equate term by term: i get: $A=0$, $B=0$, $C=1$, $D=1$. With these values i get a correct identity: $\dfrac{x+1}{\left(x^2+4x+5\right)^2}=
\dfrac{x+1}{\left(x^2+4x+5\right)^2}$ but this is unuseful in order to solve the integral. Where is my mistake ?","['partial-fractions', 'integration', 'calculus']"
1875122,"$ \int_{-\infty}^{\infty} \frac{e^{2x}}{ae^{3x}+b} dx,$ where $a,b \gt 0$","Evaluate $$ \int_{-\infty}^{\infty} \frac{e^{2x}}{ae^{3x}+b} dx,$$ where $a,b \gt 0$ I tried using $y=e^x$, but I still can't solve it. I get $\displaystyle\int_0^\infty \frac y{ay^3+b} \, dy.$ Is there any different method to solve it?",['ordinary-differential-equations']
1875134,"Let $n \in \mathbb N$ and $a,b \in \mathbb R$. Prove or disprove that $x^n+ax+b=0$ has no more than 3 solutions.","Let $n \in \mathbb N$ and $a,b \in \mathbb R$ . Prove or disprove that $x^n+ax+b=0$ has no more than 3 solutions. I believe this statement is true. Let's set $f(x)=x^n+ax+b$ and since it's a polynomial, it's continuous and differentiable. $$f'(x)=nx^{n-1}+a$$ $$f''(x)=n(n-1)x^{n-2}$$ My thoughts: I believe that if the polynomial has n solutions, then the first derivative has at most n-1 solutions, second has at most n-2 and so on. Since our second derivative has 1 solution, and our second derivative has 1 solution as well, then that means we have have at most 3 solutions. I feel that this train of thought isn't rigorous enough for a proof.","['derivatives', 'roots', 'polynomials', 'calculus']"
1875145,Standard Normal Distribution Findng A,"I have the following question and i am dumbfounded on how to find the a in my given question. $$\sigma= 10000$$
$$\mu= 50000 $$
Find the monthly income which is exceeded by 10 % of employees. I have 
$$ P(X=a) = 0.1$$
$$P(\frac{a-\mu/}{\sigma}) = 0.1$$ I am stuck at this part.","['statistics', 'standard-deviation', 'normal-distribution']"
1875146,Maximizing speed and fitness with fewest players,"There are $n$ football players, each of whom has a speed $s_i\in[0,1]$ and fitness $f_i\in[0,1]$. The sum of the speeds of all players is $1$, and the same is true for fitness. We want to choose a subset of players so that the sum of speeds and the sum of fitnesses are both at least $1/2$. Let $a$ be the size of the smallest such subset. Suppose we perform the following ""greedy"" algorithm: keep picking players with the maximum sum $s_i+f_i$, until either we have satisfied $\sum s_i\geq 1/2$ or $\sum f_i\geq 1/2$, and then pick the players with the maximum possible attribute that we haven't satisfied yet. Let $b$ be the size of the set we get. (Ties are broken arbitrarily.) Is it true that $b/a\leq 3/2$ always? It is possible that $b/a=3/2$, as shown by the example where $n=3$, $(s_i)=(0.4,0.6,0)$ and $(f_i)=(0.4,0,0.6)$. The minimum-size subset is $2$, by picking the 2nd and 3rd players, but the algorithm picks all three players. On the other hand, it is not hard to show that $b/a\leq 2$ must hold (e.g. following Alex Ravsky's argument)","['combinatorics', 'algorithms']"
1875159,Necessary and sufficient condition for the union of two intervals to be an interval,"I am trying to write down a proof of the following fact: Let $I$ and $J$ be non-empty intervals of $\mathbb{R}$ such that $\inf I \leqslant \inf J$. The union $I \cup J$ is an interval if and only if one of the following conditions holds: $I \cap J \neq \emptyset$; $\sup I = \inf J$, and $\sup I = \inf J \in I \cup J$. Sufficiency First, we show that, if $I \cap J \neq \emptyset$, then $I \cup J$ is an interval. Let $x, y \in I \cup J$ and $z \in \mathbb{R}$ such that $x \leqslant z \leqslant y$, and let $t$ be an arbitrary element of $I \cap J$. We consider three cases, in order to show that $z \in I \cup J$: If $z = t$, then $z \in I \cap J \subseteq I \cup J$. If $z > t$, then $t < z \leqslant y$. Therefore, if $y \in I$, then $z \in I$, because $t, y \in I$ and $I$ is an interval; if $y \in J$, then $z \in J$, because $t, y \in J$ and $J$ is an interval. Hence, $z \in I \cup J$. If $z < t$, then $x \leqslant z < t$. Therefore, if $x \in I$, then $z \in I$, because $t, x \in I$ and $I$ is an interval; if $x \in J$, then $z \in J$, because $t, x \in J$ and $J$ is an interval. Hence, $z \in I \cup J$. Next, we show that, if the second condition holds, then $I \cup J$ is an interval. Call $a$ the least upper bound of $I$, which is equal to the greatest lower bound of $J$ (by hypothesis). Let $x, y \in I \cup J$ and $z \in \mathbb{R}$ such that $x \leqslant z \leqslant y$. We consider three cases, in order to show that $z \in I \cup J$: If $z = a$, then $z \in I \cup J$ by hypothesis. If $z < a$, then $x \in I$, because $x \leqslant z < a$, while $n \geqslant a\ \forall \, n \in J$. By definition of least upper bound, there exists $u \in I$ such that $u > z$. Therefore, we have $x \leqslant z < u$, and $z \in I$ because $I$ is an interval. Hence, $z \in I \cup J$. If $z > a$, then $y \in J$, because $a < z \leqslant y$, while $m \leqslant a\ \forall \, m \in I$. By definition of greatest lower bound, there exists $v \in J$ such that $v < z$. Therefore, we have $v < z \leqslant y$, and $z \in J$ because $J$ is an interval. Hence, $z \in I \cup J$. Necessity Suppose $I \cap J = \emptyset$. We show by contradiction that the second condition holds. Suppose $\inf J < \sup I$. If $\inf J = \sup J$, then $J$ consists of only one point. It follows from the definition of interval that $I \supseteq\ ]\inf I, \sup I[$. So, it would be $J \subseteq I$, which is absurd (because $I \cap J = \emptyset$). Therefore, $\inf J < \sup J$. Call $m$ the minimum of $\sup I$ and $\sup J$. We have
\begin{equation*}
\inf I \leqslant \inf J < \frac{1}{2} (\inf J + m) < m.
\end{equation*}
Since $I \supseteq\ ]\inf I, \sup I[$ and $J \supseteq\ ]\inf J, \sup J[$ (this follows from the definition of interval), we have $\frac{1}{2} (\inf J + m) \in I \cap J$, which is absurd. Suppose $\sup I < \inf J$. Let $x$ be an arbitrary element of $I$, $y$ an arbitrary element of $J$ and $z := \frac{1}{2}(\sup I + \inf J)$. Then we have
\begin{equation*}
x \leqslant \sup I < z < \inf J \leqslant y.
\end{equation*}
$I \cup J$ is an interval, so $z \in I \cup J$, which is absurd because $z \notin I$ (since $z > \sup I$) and $z \notin J$ (since $z < \inf J$). Therefore, $\sup I = \inf J$. Call it $a$. We observe that $a \in \mathbb{R}$, otherwise it would be $a = +\infty$ and $J \subseteq I$, which is absurd. Finally, we show that $a \in I \cup J$. Let $x$ be an arbitrary element of $I$ and $y$ an arbitrary element of $J$. Then we have
\begin{equation*}
x \leqslant a \leqslant y.
\end{equation*}
Therefore, $a \in I \cup J$, because $I \cup J$ is an interval. Is this proof correct? If it is, can it be improved? Are there other proofs of this fact?","['real-analysis', 'alternative-proof', 'proof-verification', 'elementary-set-theory', 'general-topology']"
1875160,Show that $\min \{ |f(z)| : |z|=1 \} \leq |c_0| + |c_1|+ \dots + |c_m|$,"Suppose that $f$ is holomorphic inside and on $\gamma(0;1)$, the circle centered at $0$ of radius $1$, with Taylor expansion $\sum_{n=0}^{\infty} c_nz^n$. Given that $f$ has $m$ zeros inside $\gamma(0;1)$, prove that 
  $$\min \{ |f(z)| : |z|=1 \} \leq |c_0| + |c_1|+ \dots + |c_m|$$ I really don't know how to start. From the hypothesis we know that $$\frac{1}{2\pi i}\int_{\gamma(0;1)}\frac{f'(z)}{f(z)} dz =m$$
but I'm not sure if that fact is useful at all. Maybe I should exploit the series expansion of $f(z)$, but I haven't come up with anything. Any help will be highly appreciated, and thanks in advance!","['taylor-expansion', 'complex-analysis', 'integration']"
1875197,Does iterating the Union operator yield the empty set?,"Background In elementary set theory the union is taught as a binary operator on two sets, which contains all the elements of both those sets. $$
A = \{1,2,3\}\\
B = \{2,3,4\}\\
A\cup B = \{1,2,3,4\}
$$ In formal set theory this is generalized to a unary operator on one collection of sets, acting on each of the sets in that collection. $$
\bigcup \{A,B\} = \{1,2,3,4\}
$$ And now we can apply the union operator to a collection of not only two, but an arbitrary number of sets … $$
C = \{1,4,5\}\\
\bigcup \{A,B,C\} = \{1,2,3,4,5\}
$$ … even infinitely many. $$
N_1 = \{1\} \land N_2 = \{2\} \land N_3 = \{3\} \land \cdots\\
\bigcup \{N_1,N_2,N_3,\dots\} = \{1,2,3,\dots\}
$$ We can even take the union of a union of sets.
$$
D = \{A,B\}\\
E = \{B,C\}\\
\bigcup \bigcup \{D,E\} = \bigcup \{A,B,C\} = \{1,2,3,4,5\}
$$ Intermission Advanced axiomatic set theory teaches the idea that everything is a set, and that the first set guaranteed to exist is the empty set. Other sets must be built from that starting point. For example the natural number $0$ is the empty set $\emptyset$, the natural number $1$ is constructed as the singleton $\{0\}$, the natural number $2$ can be constructed as the pair $\{0,1\}$ (depending on the author), and so on. The Axiom of Existence is the only axiom that guarantees that a set—the empty set—exists without the input of other sets. Other sets like ordered pairs and unions can only exist given an input. The Axiom of Union states, “ given a collection of sets, there exists a set who owns any element of any set in that collection ” (as opposed to “all elements of all sets in the collection,” which would yield the intersection). The point is, a union set can exist, but the only way to create it is by giving, as an input, an existing set. That existing set could be a pair or a subset or even another union, which also require inputs; or it could be the empty set, which requires no previous set to exist. The bottom line is that the empty set is the foundation upon which all other sets are built. Question So finally here’s my question. If you take the union of any set $S$, and then take the union of that set, and keep going, will this process eventually yield the empty set? $$
\text{hypothesis: } \left(\forall S\right)\left(\bigcup\bigcup\cdots\bigcup S = \emptyset\right)
$$","['axioms', 'elementary-set-theory']"
1875230,Simplifying Ramanujan-type Nested Radicals,"Ramanujan found many awe-inspiring nested radicals, such as... $$\sqrt{\frac {1+\sqrt[5]{4}}{\sqrt[5]{5}}}=\frac {\sqrt[5]{16}+\sqrt[5]{8}+\sqrt[5]{2}-1}{\sqrt[5]{125}}\tag{1}$$$$\sqrt[4]{\frac {3+2\sqrt[4]{5}}{3-2\sqrt[4]{5}}}=\frac {\sqrt[4]{5}+1}{\sqrt[4]{5}-1}\tag{2}$$$$\sqrt[3]{\sqrt[5]{\frac {32}{5}}-\sqrt[5]{\frac {27}{5}}}=\frac {1+\sqrt[5]{3}+\sqrt[5]{9}}{\sqrt[5]{25}}\tag{3}$$$$\sqrt[3]{(\sqrt{2}+\sqrt{3})(5-\sqrt{6})+3(2\sqrt{3}+3\sqrt{2})}=\sqrt{10-\frac {13-5\sqrt{6}}{5+\sqrt{6}}}\tag{4}$$$$\sqrt[6]{4\sqrt[3]{\frac {2}{3}}-5\sqrt[3]{\frac {1}{3}}}=\sqrt[3]{\sqrt[3]{2}-1}=\frac {1-\sqrt[3]{2}+\sqrt[3]{4}}{\sqrt[3]{9}}\tag{5}$$ And there's more! Question: Is there a nice algebraic way to denest each radical such as above? For me, I've only been able to prove such identities by raising both sides to the appropriate exponents and use Algebra to simplify them. But sometimes, that can be very difficult for identities such as $(1)$.","['algebra-precalculus', 'radicals', 'nested-radicals']"
1875266,Prove that $\alpha^n+\beta^n+\gamma^n \equiv 4^n+5^n+(-6)^n \pmod{17}$,"Let $\alpha,\beta,\gamma$ be the roots of $x^3-3x^2+1 = 0$. Prove that $$\alpha^n+\beta^n+\gamma^n \equiv 4^n+5^n+(-6)^n \pmod{17}$$ where $n$ is an integer. It sort of makes sense why they are congruent since we can say $x^3-3x^2+1 \equiv (x-4)(x-5)(x+6) \pmod{17}$, but since $\alpha,\beta,\gamma$ aren't integers, how do we prove this?",['number-theory']
1875290,"Order of fibonacci modulo p, where p is a prime number","Order of fibinacci modulo p, where p is a prime number 1 < p < 10^18. What is most efficient way to find the Order of Fibonacci number modulo prime.
I have come up with an algorithm which can find the Order of Fibonacci modulo P in efficient way. My algorithm is based on below facts. The Fibonacci Sequence Modulo m •   The Fibonacci sequence mod m will always contain 1, 2, or 4 zeros, no matter what the modulus is. •   So first find the Pisano period of the given prime and check the below conditions Fib (pisano of p/1 ) mod P. Eq1 Fib (pisano of p/2 ) mod P. Eq2 Fib (pisano of p/4 ) mod P. Eq3 So the answer will be MAX of (1,2,4) for which Value of above Equations are 0. With above algorithm I can find the Order efficiently for 1 < P < 10^18, but is there any way we can find Order of Fibonacci for 1 < p < 10^100. This is the problem I am talking about, which I have solved Z124 - Zeros in Fibonacci period","['number-theory', 'fibonacci-numbers', 'modular-arithmetic', 'elementary-number-theory']"
1875291,Squeeze/Sandwich Theorem Involving $n^{th}$ root: $\lim _{ n\rightarrow \infty }{\left(3^n+1\right)}^{\frac 1n}$,Find $\lim _{ n\rightarrow \infty  }{ { \left( { 3 }^{ n }+1 \right)  }^{ \frac { 1 }{ n }  } } $ using the squeeze theorem I have come across ways to do this but none mention the squeeze (or sandwich) theorem. I know I need to find $2$ functions which squeeze the given function but can only think of using $(3^n)^{1/n}$ i.e. $3$ as the $\le $ function,"['sequences-and-series', 'calculus', 'limits']"
1875305,Absolute value in trigonometric substitutions,"In general, when we are trying to remove radicals from integrals, we perform a trigonometric substitution (either a circular or hyperbolic trig function), but often this results in a radical of the form $\sqrt{(f(x))^2}$, with $f$ being an arbitrary trigonometric function. What most texts tend to do is simply take $\sqrt{(f(x))^2} = f(x)$, without the absolute value of |f(x)|, and the texts do not offer any motivation as to why $\sqrt{(f(x))^2} = f(x) \neq |f(x)|$. I would have assumed the correct way to proceed would be $\sqrt{(f(x))^2} = |f(x)|$. Why is this the case? I'll give an example to show further explain what I'm trying to ask : $$\text{Integrate} \ \ \  \int{\frac{1}{\sqrt{x^2 + 16}}}\ dx$$ We let $\ x = 4\tan\theta \implies dx = 4\sec^2\theta \ d\theta$
\begin{equation} \label{eq1}
\begin{split}
\implies\int{\frac{1}{\sqrt{x^2 + 16}}}\ dx & = \int{\frac{4\sec^2\theta \ }{\sqrt{(4\tan\theta)^2 + 4^2}}}\ d\theta \\
 & = \int{\frac{4\sec^2\theta \ }{\sqrt{(4^2\sec^2\theta)}}}\ d\theta \\
&= \int{\frac{4\sec^2\theta \ }{4\cdot|\sec\theta \ |}}\ d\theta \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  \text{(*)}\\
\end{split}
\end{equation} What most texts do is omit the absolute value in the last starred step. Thus the denomitor of the integral becomes $\ 4\sec\theta \ $ instead of $4\cdot|\sec\theta \ |$ and there is no need to break the integral up into cases. Why is that so? We have not assumed $\sec\theta > 0$, so how can $|\sec\theta \ | = \sec\theta$?","['absolute-value', 'integration', 'trigonometry', 'calculus']"
1875331,Invertibility of $U+I$ where $U$ comes from a SVD $M=USV'$,"Assume that $U$ is a real $2 \times 2$ matrix arising from a singluar value decomposition
$$
M = USV'
$$ As a part of a bigger calculation, it suggested in this paper (see text right beneath equation (44)) that we can in this case use the properties of $U$ to create a so-called orthomorphic transformation, i.e. a matrix $X$ such that
$$
X = (I_2 + U)^{-1}(I_2-U)
$$
and
$$
U = (I+X)^{-1}(I-X)
$$
Now, here is my problem: It seems to me that the matrix $I_2 + U$ is almost never invertible. If $U$ is a real matrix, then by nature of the SVD it is typically a rotation matrix with $U_{11}=-U_{22}$. Then we have
$$
|I_2+U| = |U|+U_{11}+U_{22}+1
$$
with $|U| = \pm1$ since $U$ is orthogonal. So in that case, any time $|U|=-1$, the said matrix is singular. Am I right in that it is a somewhat exceptional case that $(I_2+U)$ is in fact invertible? Or am I missing something? I would be truly grateful if anyone could shed some light on this problem.","['matrices', 'matrix-decomposition', 'linear-algebra']"
1875336,Prove that $\lim_{n \to \infty}\dfrac{\alpha(n)}{n} = 0$,"Prove that $\displaystyle \lim_{n \to \infty}\dfrac{\alpha(n)}{n} = 0$ where $\alpha(n)$ is the number of primes which divide $n$. I think we should get an upper bound on $\alpha(n)$ by using the fact that each prime is greater than or equal to $2$, but I am not sure who to get the bound. Also, do they mean $\alpha(n)$ to be the number of distinct primes which divide $n$","['prime-factorization', 'calculus', 'limits']"
1875339,Axiom equivalent to the induction one,"I have been studying by myself set theory, natural numbers
 and properties of the real numbers, because i will enroll in a course of introduction to real analysis next semester in my university. I live in Brazil, and i am using a book written by a respected local author. I was capable of doing some exercises, but there are some that i cannot seem to have success. This one is an example that i have been struggling for more than a week. Here is the problem and my thoughts on how to solve it: Let $P1$ be the axiom that says "" $s: \mathbb N \rightarrow\ \mathbb N$ is injective , $s$ being the succesor function"" . Let $P2$ be the axiom that says "" $\mathbb N \setminus s(\mathbb N)$ consists of one element, the element ${1}$. "" Prove that in the presence of the first two axioms, the following statements are equivalent: $(i)$ Let $X \subset \mathbb N$ be a subset that ${1} \in X$ and $\forall {n} \in X, s({n}) \in X$. Then $X= \mathbb N$. $(ii)$For every $ A \subset \mathbb N$, $ A \neq \emptyset  ,$ it follows  that $  A \setminus s(A) \neq \emptyset $ I tried to use contradiction, letting $Y= \mathbb N \setminus X$ , and assuming $Y$ is not empty. If ,$Y$ is not empty, then $Y-s(Y) \neq \emptyset$. I was trying to somehow get to the conclusion that $Y-s(Y)$ was empty, and get to a contradiction, but i couldn't grasp what would the elements of $Y$ be. Yet another attempt, was to try to prove that $X=N$ by showing that $ X \subset \mathbb N $ and $ \mathbb N \subset X $. $X $ is defined to be a subset of $\mathbb N$ but i could not get to the other part using the $(ii)$ condition. I can't see why the $(ii)$ is needed or revelant. It seems to me that is a much weaker ""axiom"" than the first one. This is not part of any homework assigment, i just honestly really like math.",['elementary-set-theory']
1875389,Rates of convergence in expectation of a random variable (probability theory),"I'm reading a paper concerning probability theory. We have $X_i$ i.i.d random variables, such that $\mathbb{E}(|X_1|^t)<\infty$, where $t$ is some fixed number and $1\leq t< 2$, also $\mathbb{E}(X_1)=0$. Next we define a truncated random variable $$X_{kn}=X_k\mathbb{I}_{(|X_k|<n^{1/t})}, k=1,2,...,n=1,2,...$$ Now the author said that by integration by parts and the fact that $\mathbb{E}(X_1)=0$, we can conclude that $$n^{1-1/t}|\mathbb{E}(X_{1n})|\to 0,\quad \text{as  }n\to \infty$$ I do not get the key to prove this and I don't see how integration by parts is used in proving the above. Any comment is really appreciated.","['probability-limit-theorems', 'probability-theory', 'sequences-and-series']"
1875411,Real proofs with shorter equivalent proofs in Complex numbers?,"Are there any proofs about Real numbers that have shorter equivalent proofs going through Complex numbers? Are there proofs about Integers going through Reals, with longer equivalent proofs using pure Integers?",['number-theory']
1875413,Not a function despite passing vertical line test?,"I'm confused with something once again in my notes. The question is, $R$ on $\mathbb R$ , $R = \{ (x, y): y = \sqrt{x} \}$ is not a function how is the graph $y = \sqrt{x}$ not a function? $ y = \sqrt{x} $ $ x = y^2 $ Dom of $R = \{ x \in \mathbb R : x \ge 0 \} $ This is what the graph should be accordingly to the condition above Then i got another question that says R on $\mathbb R$ , $ R = \{ (x, y): x = y^2 \} $ is a function which isn't it the same as the above? Can anyone kindly explain?","['graphing-functions', 'functions', 'discrete-mathematics']"
1875429,Markov Chain and Forward and Backward Probabilities with Alice and Bob,"System Alice and Bob are moving independently from one city to another. There are $d$ cities, the probability of moving to another city (for each individual) is $m$ and each move is equiprobable (there is no preferred city). The choice of moving and choice of where to move to of Alice are independent of the choices of Bob. Terminology Let $X_t$ be the state of the system at time $t$. Let $S$ be the state in which Alice and Bob are in the same city, while $\bar S$ is the state in which Alice and Bob are in different cities. therefore, $P(X_{t-1}=S \space|\space X_{t}=\bar S)$ is the probability that at time $t-1$ Alice and Bob were in the same city given that they currently are in different cities. Previous post? FYI, we have shown in this post (no need to read it) that $P(X_t = S \space|\space X_{t-1} = \bar S) = \frac{m(2d-md-2)}{(d-1)^2}$. Question I am trying to understand the relationship between the following eight probabilities Forward Probabilities $P(X_t = S \space|\space X_{t-1} = \bar S)$ $P(X_t = \bar S \space|\space X_{t-1} = \bar S)$ $P(X_t = S \space|\space X_{t-1} = S)$ $P(X_t = \bar S \space|\space X_{t-1} = S)$ Backward Probabilities $P(X_{t-1} = S \space|\space X_t = \bar S)$ $P(X_{t-1} = \bar S \space|\space X_t = \bar S)$ $P(X_{t-1} = S \space|\space X_t = S)$ $P(X_{t-1} = \bar S \space|\space X_t = S)$ We will assume that the markov process started at $t=-\infty$. What relationships are there between these probabilities? How many probabilities do we need to know to infer all the others? My thoughts Let $A$ and $B$ be independent variables that can take either values $S$ or $\bar S$. It is clear for me that (forward probabilities) $$P(X_t = S \space|\space X_{t-1} = A) = 1 - P(X_t = \bar S \space|\space X_{t-1} = A) \space \forall \space A$$ and (backward probabilities) $$P(X_{t-1} = S \space|\space X = A) = 1 - P(X_{t-1} = \bar S \space|\space X = A) \space\forall \space A$$ Now it feels to me that $$P(X_t = A \space|\space X_{t-1} = B) = P(X_{t-1} = B \space|\space X = A) \space\forall\space A,B$$ Is it true? What characteristic of my system make it true? (Is it true for my system because $m$ is the same for all pair of cities?)","['markov-chains', 'problem-solving', 'markov-process', 'probability']"
1875436,"$R/(ab)\cong R/(a)\oplus R/(b)$, for $a$ and $b$ non-associate irreducible","Let $a,b$ be non-associate irreducible elements in UFD $R$. Then 
   $$R/(ab)\cong R/(a)\oplus R/(b)$$ What is the isomorphism function I have to define? Does $f(r+(ab))=(r+(a),r+(b))$ works here? If yes, how to show it is surjective? I also need to understand something, Why do we need UFD?","['abstract-algebra', 'ring-theory']"
1875439,Two tangent circles inscribed in a rectangle (Compute the area),"Consider two circles with a diameter equal to $a$, externally tangent to each other, and whose centers are at the same height. Those circles are inscribed inside a rectangle of length $2a$ and height $a$. This is a sketch I made for this problem (please, forgive my unsteady handwriting): I am asked to calculate the shaded area.
I can do it using: Symmetry. This is the easiest way in my opinion, since we know the area of each circle ($\pi a^2/4$) and the area of the rectangle ($2a^2$), which gives us: $\boxed{A_{\text{shaded}}=\dfrac{4-\pi}{4} a^2}$ Mathematical functions. We can set the origin at the bottom left corner, calculate each of the circles' analytical functions (as well as that of the line), compute the intersections, and make use of definite integrals to compute the final area. It will yield the exact same result as the above, yet the process to achieve it would be much longer. However, I'm not interested in any of these 2 methods (as they look pretty easy). I'm interested in finding a pure geometrical way to solve it. No functions. No symmetry as I used above. But pure geometric relationships. I thought about drawing some lines from the center of each circle to each intersection, like this: This would give us 4 areas hopefully easy to solve for ($S_1$, $S_1^{\prime\prime}$ and $S_2$, $S_2^{\prime\prime}$). Of course, $S_1=S_1^{\prime\prime}$ and $S_2=S_2^{\prime\prime}$ but as I said, I don't want to make use of symmetry (I'm a bit masochistic after all). So I thought about this solving scheme: $A_{\text{shaded}}=\frac12A_{\text{rectangle}}-S_2-(A_{\text{circle}}-S_2^{\prime\prime})$ $A_{\text{sector}}=S_1+S_2$ Since $S_1$ is a triangle, we could use some trigonometric relations in it to solve for $S_1$, and since the area of a circular sector is known, we could solve for $S_2$ (and $S_2^{\prime\prime}$, and very innocently find that actually $S_2=S_2^{\prime\prime}$) The main problem I have is that I don't know the inner angle of the circle sectors, because of the (seemingly randomly placed) intersection points near the borders of the rectangle. IF ONLY I were able to locate those intersection points using pure trigonometry and geometric relationships/theorems, the problem could be solved. Any hints or ideas? PD: Please, don't question my (foolish) decision of not making use of symmetry. I want to take this problem as a personal challenge. Obviously, if this were to be solved quickly I wouldn't scratch my head too much and go for the easy solution.","['circles', 'rectangles', 'trigonometry', 'geometry']"
1875441,Divergence of sum of reciprocals of square-free numbers,"I am aware that there is a similar question here , however I want to prove that $\sum \frac{1}{n}$ for $n$ square free diverges, without relying on the fact that $\sum \frac{1}{p}$ diverges for $p$ prime. This is equivalent to proving that $\sum \frac{|\mu(n)|}{n}$ converges, where $\mu(n)$ is the mobius function.  I would like verification that my proof is correct: My Proof: We begin by noting that $\sum_{n = 1}^{\infty} \frac{1}{n^2}$ converges, and so $$c * \sum_{n = 1}^{\infty} \frac{1}{n^2}$$ must also converge for any positive integer $c$. Therefore, if we look at the sum $\sum \frac{1}{n}$ where $n$ ranges only through the integers that are not squarefree, then this sum must converge because it is the composition of a series of convergent sums.  Since $\sum_{n = 1}^{\infty} \frac{1}{n}$ diverges, we must have the sum of the reciprocals of square-free integers also diverging. In particular, how can I be sure that the sum of the reciprocals of non square-free integers converges? It seems like we are taking an infinite number of convergent sums, which doesn't have to necessarily converge.","['number-theory', 'prime-numbers', 'convergence-divergence']"
1875460,Is there a closed form solution for $\frac {d^n}{dx^n} \frac {1}{1-ae^x}$?,"I am trying to find a closed form solution for $$\frac {d^n}{dx^n} \frac {1}{1-ae^x}$$
I have tried recognizing a pattern by computing specific cases but so far no luck. I do know that the function is a composition of $x^{-1}$ and $1-ae^x$. The $k$th derivative of the latter is the same for all $k\ge 1$ and there is a closed form of the $k$th derivative of the former. Yet I am still not finding any answer. However, when computing the derivatives manually I can see that in the numerator there is always a monic polynomial in $ae^x$ with constant term equal to one, all multiplied by $-ae^x$ and the denominator is always raised to the $n+1$ for the $n$th derivative. I tried arranging the coefficients of the polynomial in the numerator in a triangle like that of Pascal's but I only recognized a pattern for the coefficients of the first and last two terms. I tried Faa di Bruno's Formula but frankly it is over my head. Is there a clever solution or even a solution at all?","['derivatives', 'closed-form']"
1875492,Is a tubular neighborhood always diffeomorphic to the whole normal bundle?,"In Bott & Tu, a tubular neighborhood of a submanifold $S\subset M$ is defined as an open neighborhood $T$ of $S$ in $M$ such that $T$ is diffeomorphic to a vector bundle of rank $\mathrm{codim}\,S$ such that $S$ is diffeomorphic to the zero section. They then claim such tubular neighborhoods always exist and that the normal bundle $NS$ of $S$ in $M$ is the required bundle. However, the tubular neighborhood states that $T$ is diffeomorphic to a neighborhood of the zero section in $NS$, not to the whole thing. Is it possible to ""stretch"" the image of $T$ in $NS$ so that it is diffeomorphic to all of $NS$? Spivak seems to have a proof in the compact case, but how does one show this in general, using the tubular neighborhood quoted above?","['differential-geometry', 'differential-topology']"
1875521,Is $\sum_{d | n} f(d)$ completely multiplicative if $f$ is completely multiplicative?,"In these excellent notes by Pete L. Clark, it is claimed that if $f(n)$ is a multiplicative function, then $F(n) = \sum_{d|n} f(d)$ is multiplicative as well.  I understand the proof of this statement, however it is also said that this does not hold true for completely multiplicative functions. Why, in general, does the relation not preserve completely multiplicative functions?  I tried to begin by assuming that $(m,n) = d$ and to derive a contradiction for $F(m) * F(n)$ , but I was unable to. Thanks!","['number-theory', 'multiplicative-function']"
1875537,Taking the bidual of a non-reflexive space infinity times.,"This is just a curiosity and probably not well posed question but since several other colleagues also get curious about what would be the ""right"" question and its answer I decided to ask it here. Let $\Omega$ be a compact metric space and $C(\Omega)$ the space of all real continuous functions defined over $\Omega$ endowed with the supremum norm. Consider the sequence of successive biduals of $C(\Omega)$, i.e., $C(\Omega)^{**}, C(\Omega)^{****}$ and so on. Let us use the notation $C(\Omega)^{2n*}$ to denote the $n$-th element of this sequence of Banach spaces. Because of the Jordan mapping we can think that this sequence is nested, i.e.,  $C(\Omega)^{2n*}\hookrightarrow C(\Omega)^{2(n+1)*}$ so at least as sets taking limit would make some sense. The question is. Is there any reasonable sense for $\lim C(\Omega)^{2n*}$ (as being a Banach space) where one could expect $(\lim C(\Omega)^{2n*})^{**} \cong \lim C(\Omega)^{2n*}$ (reflexivity) ?","['functional-analysis', 'general-topology']"
1875613,If $\text{Area} (A) = \text{Area} (B)$ and $\text{Perimeter}(A) = \text{Perimeter}(B) \implies A \cong B$?,"If I have an $n$-gon $A$ and a convex $n$-gon $B$ with the same  perimeter and the same area, does $A\cong B$? Edit : What becomes the answer if I replace convex by regular?","['area', 'geometry']"
1875614,How many compact Hausdorff spaces are there of a given cardinality?,"This is a question I found myself wondering about recently.  I eventually figured out the answer myself, but as this doesn't seem to be written down anywhere easy to find on the Internet I decided to share it here. Let $\kappa$ be an uncountable cardinal.  How many compact Hausdorff spaces of cardinality $\kappa$ are there, up to homeomorphism? It is fairly well-known that if $\kappa$ is an infinite cardinal, then there are $2^{2^\kappa}$ different topological spaces of cardinality $\kappa$, up to homeomorphism (see What is the cardinality of the set of all topologies on $\mathbb{R}$? , for instance).  On the other hand, it is also fairly well-known that there are only $\aleph_1$ countable compact Hausdorff spaces up to homeomorphism (since they are all homeomorphic to countable ordinals; see Countable compact spaces as ordinals , for instance).  So it's not obvious what to expect the answer to the question above to be.","['set-theory', 'separation-axioms', 'compactness', 'general-topology', 'cardinals']"
1875625,"PDE $u_t+u^2u_x=0$ how do we deduce/know that the second shock line starts at the $(x=3,t=3)$ point","I am analyzing solution the below PDE. This is the example 1.14 from the textbook (p.19 http://people.uncw.edu/hermanr/pde1/PDEbook/PDE_Main.pdf ) My question how do we deduce/know that the second shock line starts at the point  $(x=3,t=3)$? $$u_t+u^2u_x=0, \ \ |x|< \infty , \ \ t>0 $$ with boundary condition 
$$u(x,0)= \left\{\begin{matrix}
0 &   x\leq 0,  \\ 
1 & 0<x<2,  \\ 
0 & x \geq 2
\end{matrix}\right.$$ There is a picture of the characteristic lines","['ordinary-differential-equations', 'partial-differential-equations']"
1875626,Another way to solve $y=-\frac1{x^2y'}-xy'$,"It is seen that this is a differential equation which can be written as $y=f(x,y')$, and so I solve the equation as follows: My solution: $1- $ Using the substitution $z=y'$ which leads to $y=-\frac1{x^2z}-xz\ \ \ \ (*)$. $2-$ deriving in terms of $x$ and then solving the new equation which is related to $x$ and $z$ with solutions $$(I)\ z=\pm \frac1{x^{3/2}}\ \text{and }\ (II)\ z=\frac c{x^2}. $$ $3-$ Replacing the obtained answers $(I)$ and $(II)$ to $(*)$ leading to $$ (I)\ y^2=\frac4x\ \ \text{and}\ \ \ (II)\ y=-\frac1c-\frac cx.$$ My question: Is there another technique to solve such a differential equation?",['ordinary-differential-equations']
1875630,$\sum_{n=1}^x\sin n$ is never greater than 2?,"I was playing around with Desmos, and I put in the following equation: $$y=\sum_{n=1}^{100x}\sin n$$ I'm not quite sure what I was expecting, but I noticed that the seemingly random dots it produced were never greater than y=2 (and never less than y=-0.25). I'm wondering if there is any proof and/or explanation that that is the case. Also, what branch of math would this problem fall under? It really interests me and I would like to know. Thanks.","['trigonometry', 'limits']"
1875684,How to evaluate the following integral: $\int_0^1\frac{\log(1+x)}{1+x^2}dx$ [duplicate],"This question already has answers here : Evaluate the integral: $\int_{0}^{1} \frac{\ln(x+1)}{x^2+1} \mathrm dx$ (8 answers) Closed 7 years ago . I would like to evaluate: $$\displaystyle\int_0^1 \frac{\log(1+x)}{1+x^2}\, dx$$ I have tried to evaluate this using integration by parts but failed. How can I evaluate it?","['integration', 'definite-integrals', 'calculus', 'closed-form']"
1875692,A Convergence Result Conjecture,"When I was doing my own research, I am tempted to prove the following statement. Suppose $\{a_n\}$ and $\{b_n\}$ are sequences of real numbers such that $\frac{1}{n}\sum_{i = 1}^n a_ib_i \to G \neq 0$ . $f$ is a continuous and bounded function on $\mathbb{R}^1$ . Fix $x_0 \in \mathbb{R}^1$ , then $$\frac{1}{n}\sum_{i = 1}^n a_ib_i\int_0^1\left[f(x_0) - f\left(x_0 + sn^{-1/2}b_i\right)\right]ds \to 0 \tag{1}$$ as $n \to \infty$ .
PS: If necessary, one may also assume $\max_{1 \leq i \leq n}|b_i| = O(n^{1/4})$ . I tend to believe this is true and spent some time to prove it. However, the difficulty comes from when I tried to bound the left side of $(1)$ by triangle
inequality, although the integral is controlled by arbitrarily small positive number, the absolute value was also imposed on $a_ib_i$ , which makes
it difficult to apply the non-absolute-value condition $\frac{1}{n}\sum_{i = 1}^n a_ib_i \to G$ (note we do not have any information about whether the summands are positive or negative.). Can someone give me a clear proof of $(1)$ if it is true? Or construct a counter example to overthrow it? Edit: I am happy to see this question gets much attention. In fact, the background of this problem comes from some theoretical proof under quantile regression settings. The above conjecture is my own abstraction. The thing I feel confusing are the proofs from some publications. The missing details seems
hard to fix. In the following, I will list the original statements from some papers: For example, in the proof of Gutenbrunnner, Jureckova (1992) , Lemma $1$ , the author claims
directly (I simplified the case to homoscedastic case so that $\sigma_{ni} \equiv 1$ ): \begin{align*}
\sup_{\|t\| \leq K, \varepsilon \leq \alpha \leq 1 - \varepsilon} & \left\|\frac{1}{n}\sum_{i = 1}^n x_{ni}x_{ni}'t\int_0^1\left[f\left(F^{-1}(\alpha) + n^{-1/2}x_{ni}'t\right) - f(F^{-1}(\alpha))\right]ds\right\| = o(1).
\tag{2}
\end{align*} Under the assumptions: $f$ is the continuous density of some distribution function $F$ , which is
positive and finite on $\{t: 0 < F(t) <1\}$ . $x_{ni}$ are rows of an $n \times p$ design matrix $X_n$ , where $p$ is fixed
and $n \to \infty$ . The first column of $X_n$ consists of ones and the other
columns are orthogonal to the first one. $\|X_n\|_\infty = o(n^{1/2})$ . $Q_n = \frac{1}{n}X_n^TX_n \to Q$ where $Q$ is a positive definite $p \times p$ matrix. I think $(2)$ and $(1)$ bear some resemblance, so if $(1)$ were not true, could $(2)$ be true? The problem $(2)$ may be even a little more challenging since for which we are actually dealing with the convergence
of a sequence of matrices. Another even more ambitious claim is Lemma A.2 of Koenker, Zhao (1996) , which states (both the statement and proof have many confusing typos, here I presented the version I corrected): If $\{g_t\}$ and $\{H_t\}$ are sequences of random $p$ -vectors such that $E\|g_t\|^{2 + \delta} \leq S < \infty$ , $E\|H_t\|^{2 + \delta} \leq S < \infty$ for some $\delta > 0$ . $\{u_t\}$ is a sequence of i.i.d. random variables with
continuous and bounded density $f$ . $g_t$ and $H_t$ are independent of $(u_t,
u_{t - 1}, \ldots)$ and $$n^{-1}\sum_{t = 1}^n g_tH_t' \to_P G$$ for a nonrandom, nonsingular matrix. Then, $$V(\Delta) = n^{-1/2}\sum_{t = 1}^n g_t\psi_\tau(u_t - F^{-1}(\tau) - n^{-1/2}H_t'\Delta)$$ satisfies $$\sup_{\|\Delta\| \leq M} \|V(\Delta) - V(0) + f(F^{-1}(\tau))G\Delta\| = o_P(1)$$ for fixed $M$ , $0 < M < \infty$ . Here $\psi_\tau(x) = \tau - I(x < 0)$ , $\tau \in (0, 1)$ , $I$ is indicator function. The last step to complete the proof of this lemma turns out to be a similar claim as $(1)$ and $(2)$ , that is $$\sup_{\|\Delta\| \leq M}\left\|n^{-1/2}\sum_{1}^n g_t(F(F^{-1}(\tau)) - F(F^{-1}(\tau) + n^{-1/2}H_t'\Delta)) + f(F^{-1}(\tau))G\Delta\right\| = o_P(1). \tag{3}$$ $(3)$ holds if the following form like $(1)$ $$\sup_{\|\Delta\| \leq M}\left\|n^{-1}\sum_{1}^n g_tH_t'\Delta\int_0^1\left[f(F^{-1}(\tau)) - f(F^{-1}(\tau) + sn^{-1/2}H_t'\Delta)\right]ds\right\| = o_P(1) \tag{4}$$ holds. But to prove $(4)$ , we probably encounter the same problem we must handle in proving $(1)$ , so if $(1)$ were wrong, would $(4)$ be true? Of course, it is also very welcome if someone can provide me with a direct proof of $(2)$ and $(3)$ (without linking them to $(1)$ ).","['real-analysis', 'probability', 'convergence-divergence', 'asymptotics']"
1875713,Is $545^4 + 4^{545}$ a prime number?,"The main question is :
Is $545^4 + 4^{545}$ a prime number? Explain your answer. My approach :
I tried writing the expression as, 
$$545^4 + 4*4^{544}$$
Thus we get,
$$545^4 + 4*{(4^{136})}^4$$ I can't proceed any further. Is there some obvious thing or concept I'm missing? This question is a base-level olympiad question, thus there must be some short solution to this. I will appreciate if you can give a detailed answer, along with a shortcut if you have one, so that I understand the concept thoroughly. Thanks!","['algebra-precalculus', 'contest-math', 'exponential-function']"
1875714,Simplifying $\sum_{r = 0}^{n} {{n}\choose{r}}r^k(-1)^r$,"Is there any way that I could simplify the following expression? $$\sum_{r = 0}^{n} {{n}\choose{r}}r^k(-1)^r$$ where $n,k$ are natural numbers (and in my particular problem, $k \gg n$, so maybe some sort of asymptotic behaviour?) I tried finding some sort of generating function (without any luck, though I haven't really learnt much about them yet), looking at differences between terms, but I haven't really been able to make any progress whatsoever.","['generating-functions', 'combinatorics', 'summation', 'binomial-coefficients']"
1875746,Let $A$ be a real $4\times 4$ matrix with characteristic polynomial $(x^2+1)^2$. Which of the following is true?,Let $A \in \mathbb R^{4\times 4}$ have characteristic polynomial $(x^2+1)^2$. Which of the following is true? $A$ is diagonalizable over $\mathbb C$ but not over $\mathbb R$ $A$ is nilpotent $A$ is invertible There is no such matrix $A$.,"['matrices', 'linear-algebra']"
1875766,Zeroes of $z^4+e^z$ in the unit disk,"How many zeroes does $f(z)=z^4+e^z$ have in the unit disc? ADDED: can you calculate them? Here the same question is asked about the disk of radius $2$. It can be solved easily by Rouché's theorem since when $|z|=2$, if $z=x+iy$ then $|e^z|=e^x\leq e^2$ so
$$|f(z)-z^4|=|e^z|\leq e^2\leq 9<16=|z^4|$$ therefore there are $4$ roots in that disc (up to multiplicity). Now when $|z|=1$ we don't have this inequality, nor can we use the same trick by subtracting $e^z$ instead, since when $|z|=1$, $1/e\leq |e^z|\leq e$, one side is less than $1$ and the other greater. This can be used to show that there are no roots in the right half of the disc, where by going around a curve approximating the boundary of the right half of the disc, so always $x>0$,  we get $e^x>1\geq |z|$. A direct calculation also shows no roots are on the $y$ axis. Any ideas on how to deal with the left half?",['complex-analysis']
1875769,Failure of geodesic uniqueness - what does it say about the manifold?,"I am more of a physicist than a mathematician, but this question is properly mathematical rather than physical, even though it is motivated by a physical application; please assume mathematical ignorance (and apologies for any abuse of notation and terminology ). Take a standard general relativist's spacetime manifold $M$ , i.e. a semi-Riemannian/Lorentzian paracompact Hausdorff manifold such that $\forall p\in M$ there is an unique (timelike) geodesic $\gamma_{p,\vec{v}}$ through $p$ with a given velocity $\vec{v}$ (i.e. for each $\vec{v}\in T_{p}M$ ). The specific question is this. If, after unspecified cut & join operations on $M$ , one finds that for some $p\in M, \vec{v}$ there are at least two (timelike) originally geodesic curves through $p$ : What properties of the manifold required for uniqueness theorems to apply (e.g Picard-Lindelöf/Cauchy-Lipschitz) are no longer satisfied (and specifically, why), and thus where do the uniqueness arguments break down? Are there some properties which necessarily have been violated, or are there one or more merely sufficient violations? I am most interested in the answers for excisions limited to the interiors of 4D regions within $M$ , but pedagogical examples of other cases are also welcome. 1 Aug 16 - Additional Illustrations & Commentary For clarification, as requested. For definiteness: initial manifold is Minkowksi space and $\gamma_{L}, \gamma_{R}$ are geodesics with $\vec{v}=0$ in the chosen frame, but the question remains for Lorentzian manifolds in general, as originally described; two spatial dimensions suppressed. Specify two tubes as sphere $\times$ the solid lines; excise the interiors (stippled regions) and identify the surfaces of the spheres as indicated at equal $t$ ; after the cut and glue*... Fig 1: The walls of the excised regions are not parallel; geodesics $\gamma_{L}, \gamma_{R}$ are initally distinct, but the identification of $p, q$ creates a Y and the geodesics can only continue on the LHS; there appear to be two geodesics through $p, q$ Fig 2: The walls of the excised regions are parallel; $\gamma_{L}, \gamma_{R}$ cross - or continue on the same side without any rationale for going one way or the other. Thoughts on what is wrong with the resulting manifold (Previously omitted to keep the question short and clean.) In excising the interiors of the 4D regions specified, a 3D boundary is created (time x 2D spatial). The indentification stated (which is traditional in physics literature) is purely spatial therefore the boundary does not seem to be completely removed. Whether, if true, this affects the differential structure and in such a way as to nullify the geodesic nature of one or more curves I don't know: in Minkowski space the metric is constant and it is hard for me to see how the cut & glue is problematic from this perspective, or in the more general case if derivatives are defined for closed intervals on $\mathbb{R}$ , which they can be, though I can see there might be a problem with the total derivative on $\mathbb{R}^{4}$ . In Fig 1 I do not think the solution is that the RHS line can be rotated to match the LHS because the implied homeomorphism does not, AFAICT, result in the neighbouhood $p,q$ becoming homemorphic to $\mathbb{R}^{4}$ because an extra gluing step is required. Is there a legitimate way to do this? That could be part of the answer; I don't know - hence the original question. Fig 2 is most illustrative because at $p,q$ the tangents are parallel, so upon identification there is no need for any ""rotation"", but is the neighbouhood of $p,q$ homeomorphic to $\mathbb{R}^{4}$ ? Conjecture I conjecture - and am trying to prove - that the excised regions have a unique geometry if local geodesic existence and uniqueness is to be preserved through the cut and glue operation, and that geometry is some (smooth, closed, etc.) surface $\times$ a geodesic congruence; my problem with proving it is that I think I can see something's wrong if the geometry is incorrect, but I can't identify the right mathematical concepts to pin down the issue. * I deliberately used ""join"" previously because I was aware of standard ""cut and glue"" methods and did not wish to imply any such that might have been incompatible with the motivation of the question.","['semi-riemannian-geometry', 'differential-geometry', 'geodesic']"
