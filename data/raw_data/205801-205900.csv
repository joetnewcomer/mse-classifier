question_id,title,body,tags
4097833,How does the Glivenko-Cantelli theorem improve the stochastic convergence of the empirical distribution $F_n(x)$?,"Let $X_i$ be iid random variables with empirical cumulative distribution function $F_n(x)$ and CDF $F(x)$ . From the central limit theorem and the strong law of large numbers, we know that $F_n\stackrel{d/a.s.}{\to}F$ . The Glivenko-Cantelli theorem states that $\sup\limits_{x\in\mathbb R}|F_n(x)-F(x)|\to 0$ almost  surely. How does it impact improvements for these two types of convergence (by itself or maybe by other theorems that are implied)?","['central-limit-theorem', 'weak-convergence', 'cumulative-distribution-functions', 'probability-theory', 'strong-convergence']"
4097844,"Is ""Let A be any set"", A universal or existential quantifier?","This is a very basic question but I can't find anything related on the internet. I know that Universal quantifiers are ""For all x"" while existential quantifiers are ""For some"" However, the statement for ""Let A be any set"" is confusing but from what I understand. It's a universal quantifier. However, if someone can clarify then Thank you!",['elementary-set-theory']
4097848,U-sub without changing the bounds of integration,"Let’s say for example you want to evaluate this integral: $$\int_0^{\pi/2}  \sin(x)\cos(x)\,dx$$ The best way to do that is to use a substitution, namely you will let $u=\sin(x) \implies du=\cos(x)dx$ , And you have to change the bounds of integration, so the integral will look like this : $$\int_0^1 u\,du=\frac{1}{2}$$ But there is a way to do this integral without changing the bounds of integration: $$\int_0^{\pi/2} u\,du=\frac{u^2}{2} \bigg\rvert_0^{\pi/2} $$ Now instead of calculating it directly you should go back to the original variable, namely $u=\sin(x)$ : $$\frac{u^2}{2}\bigg\rvert_0^{\pi/2} = \frac{\sin^2(x)}{2} \bigg\rvert_0^{\pi/2}=\frac{1}{2} $$ My question is which is better changing the bounds of integration first or doing this method? I think that this method is quite nice because if you have a hard substitution and you don’t know how to solve for $u$ To get the new bounds, you can just use this method. Is that correct?","['integration', 'calculus', 'substitution']"
4097866,"Let $a_1=\sqrt{6},a_{n+1}=\sqrt{6+a_n}$. Find $\lim\limits_{n \to \infty} (a_n-3)6^n$.","Let $a_1=\sqrt{6}$ , $a_{n+1}=\sqrt{6+a_n}$ . Find $\lim\limits_{n \to
 \infty} (a_n-3)6^n$ . First, we may obtain $\lim\limits_{n\to \infty}a_n=3$ . Hence, $\lim\limits_{n \to \infty}(a_n-3)b^n$ belongs to a type of limit with the form $0 \cdot \infty$ . Moreover, we obtained a similar result here , which is related to the form $\lim\limits_{n \to \infty} (a_n-3)9^n$ . How should I proceed?","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
4097920,"Isomorphism $\varphi_\star^e :H_n(\mathbb{D}_{\lambda}^n,\mathbb{S}_{\lambda}^{n-1})\longrightarrow H_n(X,X \setminus e)$","Let's suppose that $X$ is obtained from $A$ attaching $n$ -cells. We already have an isomorphism $\Phi : \oplus_\lambda H_n(\mathbb{D}_{\lambda}^n,\mathbb{S}_{\lambda}^{n-1})\longrightarrow H_n(X,A)$ . The problem is how to describe the inverse of $\Phi$ . Let $e = e_\lambda^n$ be an $n-$ cell and consider the homomorphism induced by the inclusion $p_\star^e : H_n(X,A) \longrightarrow H_n(X,X\setminus e)$ . I'd like to state that there's an isomorphism $$\varphi_\star^e :H_n(\mathbb{D}_{\lambda}^n,\mathbb{S}_{\lambda}^{n-1})\longrightarrow H_n(X,X \setminus e)$$ so that the composition $(\varphi_\star^e )^{-1} \circ p_\star^e$ is the inverse of the $\lambda$ component in $\Phi$ . Can this isomorphism $\varphi_\star^e$ be deduced by excision theorems ? If not, what's the way to approch it ? Any reference, help or solution would be appreciated.","['spheres', 'group-theory', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
4097953,Prove $\text{null}(A) \subseteq \text{null}(BA)$?,"The problem How does one show that $\text{null}(A) \subseteq \text{null}(BA)$ ? is it even true for all $A$ and $B$ ? My understandings Please correct me if I'm wrong. By definition, null space of any matrix $M$ , also $\text{null}(M)$ , is the set of all of the answers for $Ax=0$ . This equation has one obvious answer where $x=0$ , that's also the same thing in saying that linear transformations keep/do not move the origin . So, I can know that null space of matrices is at least zero. Now, for arbitrary $m \times n$ matrices $A$ and $B$ , we can say $\text{null}(A) > 0$ and $\text{null}(B) > 0$ , so $\text{null}(BA) > 0$ . Where I need help I suspect that I can say $BA$ is a linear transformation by $B$ on $A$ . Now, since $B$ might or might not nullify things that $A$ spanned, and since $A$ itself is can be thought of as a linear transformation on the identity matrix, and $A$ might or might not have nulled the space spanned by those unit vectors, $\text{null}(BA) \ge \text{null}(A)$ , because at least everything that $A$ has nullified is still nullified in $BA$ because of multiplication by zero, and $B$ might or might not have nulled more stuff.","['fake-proofs', 'matrices', 'solution-verification', 'linear-algebra', 'intuition']"
4097967,Why $\frac{DV}{dt}= \sum\limits_j \frac{dv^j}{dt}X_j +\sum\limits_{ij}\frac{dx_i}{dt} v^j \nabla_{X_i}X_j$ means the $\frac{DV}{dt}$ is unique?,"Picture below is from pages 50-51 of  do Carmo's Riemannian Geometry. I can't understand why the red line means that $\frac{DV}{dt}$ is unique when $V$ is fixed. In my view, there is not any  proof to show that the right part of red line  is independent to  the choice  of coordinate. What I try:  The red line can be written as $$
\frac{DV}{dt}=\left( \sum\limits_j \frac{dv^k}{dt} +\sum\limits_{ij}\frac{dx_i}{dt} v^j \Gamma_{ij}^k\right) X_k
$$ Then, I have $$
\left( \sum\limits_j \frac{dv^k}{dt} +\sum\limits_{ij}\frac{dx_i}{dt} v^j \Gamma_{ij}^k\right) = f^k(c(t))
$$ namely, the $\left( \sum\limits_j \frac{dv^k}{dt} +\sum\limits_{ij}\frac{dx_i}{dt} v^j \Gamma_{ij}^k\right)$ can be treated as a function of $c(t)$ or $t$ . So, I have $$
\frac{DV}{dt}(c(t)) =\sum_k f^k(c(t))X_k(c(t))   \tag{1}
$$ But,  if in another coordinate $Y_i=\frac{\partial}{\partial y_i}$ , similarly, I can get $$
\frac{DV}{dt}(c(t)) =\sum_k \hat f^k(c(t))Y_k(c(t))   \tag{2}
$$ how to show that the right parts of (1) and (2)  are same ?","['connections', 'riemannian-geometry', 'differential-geometry']"
4098024,"Almost first-order, almost-differential functional equations","The ODE $y'(x)+P(x)y(x)=Q(x)$ has solution $$I(x)y(x)=\int I(x)Q(x)\,dx$$ where $I(x)=\exp\int P(x)\,dx$ . Equivalently, $$Y(x)+P(x)\int_0^xY(t)\,dt=Q(x)\tag1$$ has solution $$Y(x)=\frac d{dx}\frac{\int I(x)Q^*(x)\,dx}{I(x)}=\frac{I(x)^2Q^*(x)-I'(x)\int I(x)Q^*(x)\,dx}{I(x)^2}$$ where $Y=y'$ and $Q^*(x)=Q(x)+P(x)y(0)$ . Equation $(1)$ gives the limiting case, where $$\int_0^xY(t)\,dt=\lim_{n\to\infty}\frac xn\sum_{k=0}^nY\left(\frac{kx}n\right).$$ Given $P(x),Q(x)$ , what could be said about the solutions of the functional equation $$Y(nx)+\frac{xP(x)}n\sum_{k=0}^nY(kx)=Q(x)\tag2,$$ where $n$ is no longer under the limit? That is, what is the behaviour of the families of solutions to $(2)$ as $n$ increases? (Cross-posted on MathOverflow .)","['riemann-sum', 'functional-analysis', 'ordinary-differential-equations', 'real-analysis']"
4098156,"Integrate $\int\frac{x}{(x^4-1)\cdot\sqrt{x^2+1}} \, dx$","Integrate $\int\frac{x}{(x^4-1)\cdot\sqrt{x^2+1}} \, dx$ I tried substituting $x=\tan(t)$ in order to get away with square root. ( $\:dx=\frac{1}{\cos^2(t)}dt\:$ ) $\sqrt{x^2+1}=\frac{1}{\cos(t)}\:\:$ and $\:\:x^4-1=\frac{\sin^4(t)-\cos^4(t)}{\cos^4(t)}$ Now after putting both into main Integral and by simplifying I have : $$
\int\frac{\sin(t)\cdot\cos^2(t)}{\sin^4(t)-\cos^4(t)} \, dt=\text{?}
$$ Now need a bit help if possible. Thank you in advance :)","['integration', 'indefinite-integrals', 'calculus']"
4098201,Show that $\lim_{x\to 0} \frac{g(x)}{\sqrt{x}}=2+\sqrt{2}$,"Let $g: (0,\infty)\rightarrow\mathbb{R}$ satisfies $\lim_{x\to 0}g(x)=0$ and $\lim_{x\to 0} \frac{g(x)-g(\frac{x}{2})}{\sqrt{x}}=1$ . Show that $$\lim_{x\to 0}\frac{g(x)}{\sqrt{x}}=2+\sqrt{2}$$ Here is what I think about. If I let $l= \lim_{x\to 0}\frac{g(x)}{\sqrt{x}}$ then I can find that $l=2+\sqrt{2}$ .
Because it is likely to calculate. It is not proving. For showing this, I use definition of limit Given $\epsilon>0,\exists \delta>0$ Such that $0<|x-0|<\delta$ And $$\left|\frac{g(x)-g(\frac{x}{2})}{\sqrt{x}}-1\right|<\epsilon$$ Then I don’t know how can I do more.Thank in advance!","['limits', 'calculus', 'epsilon-delta']"
4098274,Simple but tricky permutation question,"There are $72$ perspective home-buyers, and $300$ houses in a line. However, assume only sixty of the people purchase a house. Among the people are Oscar and Patricia, they were divorced recently, and refuse to ever be neighbors.  How many possible housing arrangements are there? Remember that neither Patricia nor Oscar are necessarily part of the $60$ . I reached the answer of: $_{72}C_{60} \cdot \mathbb{P}(300,60)-2\left(_{70}C_{58}\right)\cdot\mathbb{P}(299,59)$ , but I don't think I'm correct...",['combinatorics']
4098306,How does the tribonacci sequence have anything to do with hyperbolic functions?,"The Fibonacci sequence has always fascinated me because of its beauty. It was in high school that I was able to understand how the ratio between 2 consecutive terms of a purely integer sequence came to be a beautiful irrational number. So I wondered yesterday if instead of 2 terms, we kept 3 terms. So I wrote a python program to calculate the ratio. At the 10000th term it came to be close to 1.839... After some research on OEIS and Wikipedia, I found that the series is popular and is known as the tribonacci sequence. But what surprised me the most was the exact ratio given on this link . The tribonacci constant $$\frac{1+\sqrt[3]{19+3\sqrt{33}} + \sqrt[3]{19-3\sqrt{33}}}{3} = \frac{1+4\cosh\left(\frac{1}{3}\cosh^{-1}\frac{19}{8}\right)}{3} \approx 1.83928675$$ (sequence A058265 in the OEIS ) I wonder how a sequence with nothing but natural numbers leads us to non-Euclidean geometry. I wonder if someone could tell me how these two are related. Note: I don't actually want the exact solution which would be extremely difficult to understand for a high schooler like me, I just want to know if there is a way to connect number theory and non-Euclidian geometry.","['number-theory', 'recurrence-relations', 'hyperbolic-functions']"
4098345,"Prove that if locally compact group $G$ is discrete, then the group algebra $L^1(G)$ is unital.","I am trying to prove that if $G$ is discrete, then the group algebra $L^1(G)$ is unital. If $G$ is discrete, $\{1\}$ is an open set where 1 is the identity element of $G$ . I am trying to show that the indicator function at $\{1\}$ , $\chi_{\{1\}}$ is the unit element of $L^1(G)$ , but I run into a problem. The convolution operation is for $f\in L^1$ and $\chi_{1}$ is given by: $\int_G f(y)\chi_{\{1\}}(y^{-1}x)\,dy$ .
Replacing $y$ with $x$ in the above integral, we get: $\int_G f(x)\chi_{\{1\}}(x^{-1}x)\,dx=\int_G f(x)\,dx$ , because $\chi_{{\1\}}(x^{-1}x)=\chi_{\{1\}})=1$ . So now we have 'isolated' f, but how could we possibly get from $\int_G f(x)\,dx$ to $f$ , as needed? Clearly the integral of $f$ is not equal to $f$ in general. Do we have that somewhere along the line, the integral is no longer over $G$ but over only $\{1\}$ , because indicator function goes zero elsewhere? Then integrating over one element gives you the function itself back? Any help is greatly appreciated. Thanks!","['harmonic-analysis', 'measure-theory', 'functional-analysis']"
4098364,"Calculate $\lim_{n\to\infty}\sum_{\ \ \ \ i,j\ge0 \\ i^2+j^2\le n^2} \frac{1}{n^2+i^2+j^2}$","Calculate $$\lim_{n\to\infty}\sum_{\ \ \ \ i,j\ge0 \\ i^2+j^2\le n^2} \frac{1}{n^2+i^2+j^2}$$ It smells like a Riemann sum for a double integral. $$\lim_{n\to\infty}\sum_{\ \ \ \ i,j\ge0 \\ i^2+j^2\le n^2} \frac{1}{n^2+i^2+j^2} = \lim_{n\to\infty}\frac{1}{n^2}\sum_{\ \ \ \ i,j\ge0 \\ i^2+j^2\le n^2} \frac{1}{1+(i/n)^2+(j/n)^2} \overset{?}= \iint\limits_{[0,1]^2} \frac{1}{1+x^2+y^2}\mathrm dx\mathrm dy$$ I know how to calculate the last integral, but I'm not sure if the (?) part is correct. Doesn't $i^2+j^2\le n$ have any special job to do here?","['summation', 'multivariable-calculus', 'calculus', 'multiple-integral', 'limits']"
4098491,Angles determining a point interior to a triangle,"Given a triangle $ABC$ , a point $P$ interior to the triangle can be determined by two angles, for example the angle $\alpha = \angle PAC$ and the angle $\beta = \angle PBA$ (See diagram below). In this case, once $\alpha$ and $\beta$ are chosen, the third similarly defined angle $\gamma = \angle PCB$ is fixed. This question is about how $\gamma$ depends on (the known) $\alpha$ and $\beta$ . Applying the sine rule to the three triangles meeting at $P$ , I was able to find a formula $$
\cot \gamma = \cot C + \frac{\sin \alpha \, \sin \beta}{\sin (A-\alpha) \, \sin(B-\beta) \, \sin C}
\; \cdot$$ Blindly applying trig formulae in this way leads to what looks like a quite complex expression and it is not directly obvious how it relates to what appears to be a simple geometric relationship. Does anyone know of a simpler way to represent $\gamma$ and/or a basic geometric intuition to relate $\gamma$ to $\alpha$ and $\beta$ ?","['triangles', 'trigonometry', 'geometry']"
4098493,Summation by parts as a case of integration by parts,"I was wondering if the summation by parts formula $$
f_ng_n - f_mg_m = \sum_{k=m}^{n-1} f_k(g_{k+1}-g_k)  + \sum_{k=m}^{n-1}(f_{k+1}-f_k)g_{k+1}
$$ could be proven as a consequence of integration by parts over a suitable domain $$
\int_{[m,n]} d(fg) = \int_{[m,n]}  fdg + \int_{[m,n]} gdf
$$ and given some appropriate measure, for example the Dirac comb . I haven't done measure / distribution theory in a while, and I'm not even sure what $df$ is supposed to mean if I'm integrating something using a Dirac comb measure, or how the fundamental theorem of calculus looks in measure theory terms, so a bit more detailed explanation would be appreciated. I have found this similar post but the response does not quite answer my question.","['integration', 'measure-theory', 'summation-by-parts', 'dirac-delta']"
4098504,First integrals for topologically conjugate systems,"I have the two dynamical systems System 1: $(\dot{x},\dot{y})=(x(x+1),-y)$ System 2: $(\dot{x},\dot{y})=(x(x+1),-y+4x^3-12x+3)$ which are topologically conjugate, which we can show using the map $\vec{h}(x,y)=(x,y+p(x))$ where $p(x)=2x^2-6x+3$ . First I need to find the inverse of $\vec{h}$ . Then, given $V(x,y)$ is a first integral of System 2, I need to find a first integral of System 1 . I am not really familiar with inverses of vector fields but I think that $\vec{h}^{-1}(x,y)=(x,y-p(x))$ . I then tried to show that $V(x,y-p(x))$ was a first integral of system 2 but after taking the time derivative and expanding everything out I ended up with a mess, and not much simplified.","['ordinary-differential-equations', 'dynamical-systems']"
4098563,How to analyze the following ODE with 2 variables [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question THE ODEs has the following form: \begin{align*}
\frac{dy}{dt} &= - \lambda xy\\
\frac{dx}{dt} &= -\eta y^2,
\end{align*} where $\lambda$ and $\eta$ are constants. $y(0) = C_1 >0$ and $x(0) = C_2 >0$ . Is there any standard tool to analyze it? Thanks.",['ordinary-differential-equations']
4098591,Is $\mathbb{E}[X|X<Y]$ finite if $\mathbb{E}[Y]<\infty$?,"I'm afraid I may be overlooking an obvious answer to this question, but perhaps someone can provide some assistance, as probability is not my area of expertise. Suppose we have two independent random variables, $X$ and $Y$ , with $X$ finite almost surely, but $\mathbb{E}[X]=\infty$ and $\mathbb{E}[Y]<\infty$ . I'm trying to understand the quantity $\mathbb{E}[X\mid X<Y]$ . In particular, I would like to know if this conditional expectation is finite. I feel like I should be able to say $\mathbb{E}[X\mid X<Y] < \mathbb{E}[Y]$ , which gives the result, but then I got a bit caught up in the details. Any help, even just a nudge in the right direction, would be greatly appreciated. Edit: so sorry to have left this out, but $X$ and $Y$ are non-negative RV.","['conditional-expectation', 'probability', 'random-variables']"
4098597,Show that $H(x):=\frac{1}{|x|^{n-2}}u(\frac{x}{|x|^2})$ is harmonic if $u$ is harmonic [duplicate],"This question already has answers here : Show that the Kelvin-transform is harmonic (1 answer) $u$ is harmonic, prove that $v(x)=\frac{1}{|x|^{n-2}}\cdot u\left(\frac{x}{|x|^2}\right)$ is harmonic. [closed] (1 answer) Closed last year . (This is the $n$ -dimensional analogue of the 3D case: Show that $H(x) := |x|^{-1} u(x/|x|^2) $ is harmonic if $u$ is harmonic ) Suppose that $u$ is a harmonic function on $\mathbb{R}^n$ . Prove that the function $\displaystyle H(x):=\frac{1}{|x|^{n-2}}u\left(\frac{x}{|x|^2}\right)$ is harmonic on $\mathbb{R}^n\backslash\{0\}$ . I tried to compute $\Delta H$ directly by following the brute force method in the linked question, but it gets tedious very soon. Therefore, I am wondering if there is a more elegant way? I am thinking to use the converse of mean value property. So far I have worked out (probably) that Under the mapping $f: x\mapsto \frac{x}{|x|^2}$ , a circle with radius $r$ centered at $x_0$ would be mapped to a circle with radius $R=\frac{2r}{|x_0|^2-r^2}$ centered at $y_0=\frac{x_0}{|x_0|^2-r^2}$ . $f = f^{-1}$ Its Jacobian is $|Jf|=|x|^{2n}$ . I am stuck after doing change of variables in the integral $\displaystyle\frac{1}{|B_R(y_0)|}\int_{B_R(y_0)} H(y)dy$ , since the terms do not magically cancel out as wished, and expressing $|B_R(y_0)|$ in terms of the corresponding $|B_r(x_0)|$ also yields a mess. I really appreciate any help. Other methods (or more efficient brute force) are also greatly welcomed.","['integration', 'harmonic-functions', 'laplacian', 'multivariable-calculus', 'partial-differential-equations']"
4098617,Is there an explicit equivalence of categories between real and complex commutative unital C* algebras,Gelfand duality shows that the category of commutative unital C* algebras is dual to the category of compact Hausdorff spaces.  This holds for the real case (see Stone spaces of Johnstone) as well as the much better known case of complex C* algebras though the proofs are not the same.  Since these two categories are both dual to the same category they should be equivalent to each other.  Is this equivalence of categories explicitly described anywhere?,"['functional-analysis', 'category-theory']"
4098625,"Let $ G $ be a connected graph $ a \in E (G) $, they are equivalent","Let $ G $ be a connected graph $ a \in E (G) $ , they are equivalent: a) $ a $ is a bridge of $ G $ . b) $ a $ does not belong to a cycle c) There are $ u, \: v \in V (G) $ such that every $ uv- $ path contains $ a $ . d) There is a $ \{U, \: V \} $ partition of $ V (G) $ such that every $ UV $ -path contains $ a $ . Demonstration. We will show $ a) \Rightarrow b) \Rightarrow c) \Rightarrow d) \Rightarrow a) $ . $ a) \Rightarrow b) $ : Suppose $ a $ is a $ G $ bridge and is on a $ G $ cycle. By eliminating $ a $ , we know that there is a path between two vertices of $ a $ . But this is contradicted by the definition of a bridge. Therefore, $ a $ is not in a cycle. $ b) \Rightarrow c) $ : Since $ a $ is not in a cycle, $ a $ is a bridge, so $ G - \{a \} $ is disconnected. Thus there exist $ u, \: v \in V (G) $ such that there is no $ uv- $ path, since $ G $ is connected then every $ uv- $ path contains $ a $ . $ c) \Rightarrow d) $ : Suppose there exist $ u, \: v \in V (G) $ such that every $ uv- $ path contains $ a $ , then in $ G - \{a \} $ there is no $ uv- $ path. Therefore $ G - \{a \} $ is not connected. Let $ G_1, \: \ldots, \: G_l $ be the connected components of $ G - \{a \} $ , by choosing $ u $ and $ v $ , they must belong to different components, without losing generality Suppose $ u \in V (G_1) $ and $ v \in V (G_2) $ . Let's define $ U = V (G_1) $ and $ V = \cup_ {i = 2} ^ {l} V (G_i) $ . Assertion: $ \{U, \: V \} $ is a partition of $ V (G) $ . i) $ U \neq \emptyset $ then $ u \in U $ . ii) $ V \neq \emptyset $ since $ v \in V $ . iii) $ U \cap V = \emptyset $ by the definition of $ U $ and $ V $ . iv) $ U \cup V = V (G) $ by the definition of $ U $ and $ V $ . $ d) \Rightarrow a) $ : Let $ u $ and $ v $ be the extremes of $ a $ , with $ u \in U $ and $ v \in V $ , thus $ u \neq v $ , as by hypothesis every $ UV- $ path contains $ a $ and $ a \notin E (G - \{a \}) $ , then there is no $ uv- $ path in $ G - \{a \} $ , from where $ G - \{a \} $ is disconnected. Therefore, $ a $ is a bridge. it's okay?","['graph-theory', 'trees', 'discrete-mathematics']"
4098627,Second Bianchi identity on tangent bundle,"I'm having a hard time on proving the second Bianchi identity in the case of tangent bundle without choosing of metric .  I already know that on a general vector bundle, the second Bianchi identity reads: $$d^{\nabla}F=0$$ where $F$ is the curvature of $\nabla$ . I want to use this to prove the second Bianchi identity on tangent bundle: $$0=(\nabla_X R)(Y,Z)+(\nabla_Y R)(Z,X)+(\nabla_Z R)(X,Y)$$ My attempt is to use the formula of $d^{\nabla}$ , which will transfer the general result to: $$\nabla_X(R(Y,Z))+\nabla_Y(R(Z,X))+\nabla_Z(R(X,Y))-R([X,Y],Z)-R([Y,Z],X)-R([Z,X],Y)=0$$ But how can I show this implies the above? Note that in both cases, I'm identifying $R$ as a $End(TM)$ valued two form.","['connections', 'curvature', 'vector-bundles', 'tangent-bundle', 'differential-geometry']"
4098641,"Let $K$ be a nonempty closed, convex subset of $R^d$. Prove that if $x\notin K$, then there exists a unique point $y\in K$ that is closest to $x$.","Let $K$ be a nonempty closed, convex subset of $R^d$ . Prove that if $x\notin K$ , then there exists a unique point $y\in K$ that is closest to $x$ . My attempt: Suppose y and z are 2 different point that are both closest to x. Then, $||x-y||=\mbox{inf}\{||x-a||: a \in S\}$ and $||x-z||=\mbox{inf}\{||x-b||: b \in S\}$ . Consider the midpoint $w$ of the line that joins y to z. Then $w=\frac{||y-z||}{2}=\frac{||y-x+x-z||}{2}\le \frac{||x-y||+||x-z||}{2}\le \frac{||x-a||+||x-b||}{2}$ for any $a \in S$ . I don't know how to go from here; I thought the midpoint would be zero since we are trying to show that these 2 points are the same point, so is the midpoint formula I used incorrect? Also can you use $a$ for both infimums or do I have to use $a$ and $b$ distinctly for y and z as I did?","['supremum-and-infimum', 'analysis', 'real-analysis']"
4098731,When is this group compact?,"Let $K=\begin{pmatrix}
I_a & 0\\
0 & -I_b
\end{pmatrix}$ , where a+b=n, and $I_a$ is the $a\times a$ identity matrix and similar definition for $I_b$ . Let G be the group consisting of all complex $n\times n$ matrices such that $A^*KA=K$ . For what values of a and b is G compact? If $a=0$ or $b=0$ , this just reduces to the unitary group, which is compact. However, if $n=2$ and $a=b=1$ , then $A=\begin{pmatrix}
c & \sqrt{c^2-1}\\
\sqrt{c^2-1} & c
\end{pmatrix}$ is not bounded and in G. Is there a way to generalize this?","['matrices', 'group-theory', 'lie-groups', 'compactness']"
4098749,Hardy-Littlewood maximal function of $\log |x|$.,"Consider the function $f: \Bbb R^n \to \Bbb R$ defined by $f(x)=\log |x|$ for $x \neq 0$ and $f(0)=0$ . I'm trying to prove that the Hardy-Littlewood maximal function of $f$ , $Mf$ , equals $\infty$ . That is, for every $x \in \Bbb R^n$ , $$Mf(x) = \sup_{x \in B} \frac{1}{|B|} \int_B |f|  = \infty,$$ where the supremum is taken over all balls $B$ in $\Bbb R^n$ containing $x$ and $|B|$ is the Lebesgue measure of the ball. The reasoning I tried to use is that for any $x \in \Bbb R^n$ there is a ball $B$ containing $x$ and $0$ . Since it contains $0$ , $|f| \to \infty$ on $B$ , and then $\frac{1}{|B|} \int_B |f|  = \infty$ . But I don't know if that's true, do we need that $|f|$ is exactly $\infty$ on $B$ to say that the integral on $B$ is $\infty$ ? In that case, would we need to define $f(0)=\infty$ ?","['analysis', 'real-analysis']"
4098806,Identifying the finite symmetric groups,"Is there a single first-order sentence $\varphi$ in the language of groups such that for every finite $\mathfrak{A}$ we have $$\mathfrak{A}\models\varphi\quad\iff\quad\mathfrak{A}\cong S_n\mbox{ for some finite $n$}?$$ Clearly this can be done with a first-order theory in place of a single sentence: if for each $n$ we let $\varphi_n$ be the sentence asserting ""Either the structure is isomorphic to $S_m$ for some $m\le n$ , or the structure has $>n!$ elements,"" then the finite models of $\{\varphi_n:n\in\mathbb{N}\}$ are exactly the finite symmetric groups. Similarly, a single second-order sentence can do the job. However, I don't see how to do the job with a single first-order sentence.","['finite-groups', 'group-theory', 'logic', 'model-theory']"
4098825,Cardinality of a set of polynomial,"Given a set $A = \{x \in \mathbb{R}: \exists m \in \mathbb{N}, \exists b_0, \ldots, b_m \in \mathbb{Z} \text{ with } b_m \neq 0 \text{ and } b_mx^m + \cdots + b_0 = 0\}$ . Im trying to find cardinality of A. One of the hints given were to write the set as a set of unions to get rid of quantifiers. Although I have no idea what sets would you even take a union of. Another thing that I thought about is that if $m$ is fixed, the by rational root theorem there are $m$ roots of the equation so would that imply that its cardinality is at most $m$ ? What would I have to include in the proof to make it formal since my arguments are just informal observations? Also just to confirm, in the set A, the $m$ is fixed right? EDIT: would the unions would be the union of sets $A_i$ for $i \in \{0,1,\ldots, m\}$ where $A_i = \{x \in \mathbb{R}: i \in \mathbb{N}, b_0, \ldots, b_i \in \mathbb{Z} \text{ with } b_i \neq 0 \text{ and } b_ix^i + \cdots + b_0 = 0\}$ ? The idea being that the unions of $A_i$ will have overlaps so it is at most $m$ .",['elementary-set-theory']
4098856,Question regarding Basel Problem [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I have the following problem as quoted in a book: $$ S=\frac{1}{1^2}+\frac{1}{2^2}+\frac{1}{3^2}+\cdots $$ Prove that: $$ S < 3 $$ I know that $ S $ evaluates to $ \frac{\pi^2}{6} $ , so it is absolutely true. But I have no idea how to prove it. Also, the author of the book wants the proof without having the knowledge of the sum of the given infinite series. Any help would be appreciated.","['contest-math', 'solution-verification', 'education', 'sequences-and-series', 'algebra-precalculus']"
4098868,A BdMO 2021 Question,"Two toads named Gamakichi and Gamatatsu are sitting at the points $(0,0)$ and $(2,0)$ respectively. Their goal is to reach $(5,5)$ and $(7,5)$ respectively by making one unit jumps in positive $x$ or $y$ direction at a time. How many ways can they do this while ensuring that there is no point on the plane where both Gamakichi And Gamatatsu land on? It's a problem from BdMO 2021 . I have no idea about how to approach this kind of problems (Cause I'm a beginner). Please help me solve it. And sorry if it's too easy.","['contest-math', 'coordinate-systems', 'combinatorics']"
4098873,"Assume that $K$ is a compact subset of $\mathbb{R}$. Prove directly that $K′=\{(x,0) :x\in K\}$ is a compact subset of $\mathbb{R}^2$.","Assume that $K$ is a compact subset of $\mathbb{R}$ . Prove directly that $K′=\{(x,0) :x\in K\}$ is a compact subset of $\mathbb{R}^2$ . I have been given the following hint:
Suppose that $\{U_i\}_{i\in I}$ is a cover of $K′$ by open sets. These $U_i$ are subsets of the plane $\mathbb{R}^2$ . Find a collection $\{V_i\}_{i\in I}$ of open subsets of the real line $\mathbb{R}$ that cover $K$ . Be sure to prove that your sets $V_i$ are open—you can’t just say that they are open, you have to prove that. It really seems kind of like common sense that if all the values of $x$ form a compact set, then $(x,0)$ forms a compact set since $0$ is just $0$ . I don't even really understand the hint given.","['compactness', 'analysis', 'real-analysis']"
4099052,Furtwängler's family of irreducible polynomials: is there a perturbation criterion for irreducibility?,"In the Mathoverflow question Examples of nice families of irreducible polynomials over Z , user trew mentions a family of irreducible polynomials over the integers of the following form: $$ p(x) = x^4 \prod_{i=1}^{n-4} (x - b_i) - (-1)^n (2x + 4), \quad b_i \in \mathbb{Z}, \text{ pairwise distinct}, b_i \neq -2. $$ He attributes it to Philipp Furtwängler but provides no reference, and up to now I have not been able to locate it. Edit: as Sil rightly points out, these conditions are not sufficient to make $p$ irreducible. I do not know what other conditions (on the growth of the $b_i$ ?) are required (and if there is anything behind the claim. Here is Furtwängler's publication list on zbMathOpen: https://www.zbmath.org/?q=ai%3Afurtwangler.philipp I'd be very glad if anyone has an idea on how to dig this up! It might be an interesting question to the whole community as irreducibility arguments are frequently sought and notoriously difficult once one moves beyond the standard techniques. This family can be interpreted as a small perturbation of a reducible polynomial with real roots and Furtwängler's proof might add an additional technique to the irreducibility toolbox : empirically many more polynomials of this type seem to be irreducible.","['irreducible-polynomials', 'number-theory', 'reference-request']"
4099130,Roots of polynomial $\sum_{k = 0}^{n} \sqrt{\binom{n}{k}} x^k = 0$,"I'm interested in roots of the polynomial $$p(x) = \sum_{k = 0}^{n} \sqrt{\binom{n}{k}}  x^k = 0$$ I've looked around but can't find anything in the literature or forums. Since coefficients are all real, roots come in complex conjugate pairs. Having looks at some solutions for specific values of $n$ I also conjecture that for certain values of $n$ all roots lie on $|x| = 1$ , but have no idea how to approach this (eg for $n=11$ all but 2 roots lie on the unit circle). Any ideas would be appreciated.","['number-theory', 'roots', 'polynomials', 'complex-numbers']"
4099142,Number of distinct red and blue colored cycles,"Consider a cycle graph of length $n$ where $k$ nodes are colored blue and $n-k$ are colored red. I define two vectors $x,y$ each of length $l$ where $l$ is the number of connected components of red and blue colored subgraphs and the entries in the vectors are defined by the size of said subgraphs. $x$ and $y$ always have to be of the same length $l$ since the coloring alternates between blue and red colored sub-graphs. I want to find the number of distinct configurations and, hence, I have to get rid of those who I count twice due to symmetries implied by the symmetric group $S_l$ on the vectors $l$ . To rewrite this I consider two vectors of positive integers which I call obviously $x,y$ such that the length of $x$ is $l$ and the length of $y$ is likewise $l$ with $x_i\in\{1,...,k\}$ and $y_i\in\{1,...,n-k\}$ for $i=1,...,l$ and $\sum_{i=1}^l x_i = k$ and $\sum_{i=1}^l y_i = n-k$ for some positive integer $n>k$ . Then two configurations are identical under a rotation of $2\pi \dfrac{r}{n}$ iff $x_i = x_{(i+r)\mathrm{mod}\;l}$ and $y_i = y_{(i+r)\mathrm{mod}\;l}$ since both $x$ and $y$ have to be rotated. Note that if you find such an $r$ for a pair $x,y$ it is not true that the same $r$ is preserved under arbitrary actions of $S_l$ on $x$ and $y$ . Can these numbers be counted or is there no hope to even get a recursive formula for the number of ""identical"" $x$ ad $y$ which can be rotated in this way?","['graph-theory', 'combinatorics', 'discrete-mathematics']"
4099177,Integers $j>0$ with no prime among $2^j-2^k-1$ for $0\le k<j$,"Let $\mathcal S$ be the set of integers $j>0$ such that there exists no prime among the $j$ integers $2^j-2^k-1$ for $0\le k<j$ . The terms 1 to $2^{12}$ are: 1 7 15 23 27 31 37 39 43 55 58 63 71 79 82 91 95 111 123 127 133 135 139 143 148 151 159 167 169 172 173 175 179 183 191 195 199 207 211 223 239 255 286 295 313 316 319 335 337 351 367 373 383 406 415 417 433 435 447 455 461 463 479 483 487 493 495 497 505 511 517 523 527 543 551 559 571 575 578 583 587 591 599 603 607 615 623 635 639 643 651 655 671 673 679 682 687 703 711 715 735 739 742 745 751 767 771 783 787 799 803 805 807 811 815 823 827 831 839 847 863 867 871 887 895 911 915 923 927 943 959 963 967 975 991 999 1006 1007 1011 1015 1023 1027 1033 1039 1043 1047 1051 1055 1063 1071 1087 1095 1097 1103 1111 1115 1119 1123 1127 1135 1141 1151 1157 1167 1183 1191 1193 1199 1203 1213 1219 1229 1243 1247 1251 1263 1267 1279 1285 1287 1295 1299 1303 1311 1319 1327 1339 1343 1347 1351 1357 1359 1375 1383 1387 1407 1415 1423 1431 1438 1439 1455 1459 1471 1486 1487 1491 1495 1503 1519 1535 1543 1551 1555 1567 1575 1577 1583 1587 1591 1599 1607 1611 1615 1630 1631 1647 1651 1663 1666 1667 1671 1675 1685 1687 1695 1699 1703 1711 1713 1719 1723 1727 1741 1743 1755 1767 1773 1775 1791 1795 1803 1807 1815 1823 1827 1831 1847 1855 1877 1887 1911 1919 1939 1947 1951 1967 1979 1990 1999 2003 2007 2015 2026 2031 2047 2063 2075 2079 2091 2095 2099 2111 2127 2137 2143 2153 2159 2165 2175 2188 2191 2211 2223 2231 2239 2257 2263 2271 2295 2303 2311 2314 2319 2323 2335 2343 2351 2367 2375 2379 2383 2399 2407 2415 2422 2429 2431 2447 2463 2479 2487 2495 2503 2519 2527 2535 2543 2554 2557 2559 2575 2591 2607 2619 2623 2631 2647 2659 2663 2671 2687 2699 2703 2711 2719 2735 2751 2755 2767 2775 2783 2787 2791 2803 2815 2831 2847 2855 2859 2863 2867 2871 2873 2879 2895 2911 2927 2935 2942 2951 2967 2971 2975 2991 2995 2999 3007 3015 3019 3039 3063 3067 3071 3079 3095 3103 3107 3111 3115 3130 3135 3139 3142 3147 3151 3159 3163 3167 3171 3175 3179 3183 3199 3207 3215 3219 3231 3246 3251 3263 3271 3279 3283 3295 3303 3311 3316 3327 3335 3343 3351 3359 3375 3387 3391 3403 3407 3411 3423 3427 3431 3435 3447 3455 3457 3467 3471 3479 3487 3495 3497 3499 3503 3506 3507 3509 3515 3517 3519 3527 3535 3544 3551 3555 3567 3579 3583 3599 3627 3631 3639 3647 3651 3663 3667 3671 3675 3679 3683 3687 3695 3699 3701 3703 3711 3735 3737 3739 3751 3759 3773 3775 3787 3791 3795 3807 3817 3823 3831 3835 3839 3847 3855 3867 3871 3875 3887 3895 3898 3903 3907 3911 3913 3917 3919 3927 3935 3939 3943 3949 3951 3959 3963 3967 3975 3982 3983 3987 3993 3999 4011 4015 4019 4023 4027 4031 4047 4059 4063 4067 4087 4095 Can we prove that $\mathcal S$ is infinite? In the above first $532$ terms, only $30$ are even, only $6$ are multiple of $2^2$ , only $1$ is multiple of $2^3$ . With $j\le12000$ , only $j=3544$ , $6304$ , $10520$ , $11560$ are multiple of $2^3$ , with only $j=6304$ multiple of $2^4$ (and $2^5$ ). Why do terms multiple of $2^i$ dry out so fast ? More generally, can we explain the irregular distribution of $j\bmod2^i$ for $j\in\mathcal S$ ? Here it is for $i=3$ and the terms to $2^{12}$ : $$\begin{array}{l|rrrrrrr}
j\bmod2^3&0&1&2&3&4&5&6&7\\
\hline
\text{# with }j<2^{12}&1&24&11&121&5&27&13&330\\
\text{proportion}&0.002&0.045&0.021&0.227&0.009&0.051&0.024&0.620
\end{array}$$ Notes: For example, $7\in\mathcal S$ because $2^7-2^0-1=126\equiv0\pmod2$ , $2^7-2^1-1=125\equiv0\pmod5$ , $2^7-2^2-1=123\equiv0\pmod3$ , $2^7-2^3-1=119\equiv0\pmod7$ , $2^7-2^4-1=111\equiv0\pmod3$ , $2^7-2^5-1=95\equiv0\pmod5$ , $2^7-2^6-1=63\equiv0\pmod3$ . And $8\not\in\mathcal S$ because $2^8-2^2-1=251$ is prime. Primes of the form $2^j-2^k-1$ are among the simplest Solinas primes , and are commonly used for Elliptic Curve Cryptograpy in prime fields, for they allow efficient modular reduction: e.g. M-221, Curve1174, Curve41417, Ed448-Goldilocks, E-521; see SafeCurves . The sequence is not in OEIS at time of writing, which suggests it has not been extensively studied.","['number-theory', 'prime-numbers', 'sequences-and-series']"
4099212,Possible set of 4 integers,"$A = [a,b,c,d]$ is a set of four integers. We pick two integers out of $A$ and add them. The following six sums are obtained $- 0,2,4,8,10,12$ . Find the four integers in Set $A$ ? All that I could figure out from this problem is that there has to be two numbers which will be $x$ and $-x$ then only we can get a sum of $0$ . But I am still unable to solve this problem or devise a way to approach this problem. Please help ! Thanks in advance !!!","['elementary-set-theory', 'elementary-number-theory', 'arithmetic']"
4099247,How to smooth out 2 corners in a piecewise function?,"I have been experimenting with this a lot, but it eventually proves itself to be trickier than I expected. Let \begin{equation} f(z) =
      \begin{cases}
        1, &z<0  \\
        \frac{1}{2} + \frac{1}{10} \sqrt{25-20z + 20 \sin(\pi z)}, &0<z<1  \\
        \frac{1}{2} + \frac{1}{10} \sqrt5, &z>1
      \end{cases}
    \end{equation} be a piecewise smooth function, smooth everywhere, and differentiable everywhere but $z=0$ and $z=1$ . My idea is to smooth out the ""corners"" possibly by extracting a small domain around them, and replace this with a function g such that f and g can be glued together into a new function H that is everywhere smooth. I would extract a small stripe of width $2\delta$ , for $\delta$ small enough, left and right of $z=0$ , and do the same, left and right of $z=1$ . This would result in: \begin{equation} H(z) =
      \begin{cases}
        1, &z<-\delta  \\
         g_1 (z), &-\delta < z < \delta \\
        \frac{1}{2} + \frac{1}{10} \sqrt{25-20z + 20 \sin(\pi z)}, &\delta<z<1-\delta  \\
        g_2 (z), &1-\delta < z < 1+\delta \\
        \frac{1}{2} + \frac{1}{10} \sqrt5, &z>1+\delta
      \end{cases}
    \end{equation} so that -finally- $H(z)$ is everywhere smooth. My question is: can someone give me a suitable example for $g_1$ and $g_2$ and preferably explain to me the thinking process? Thanks in advance!","['smooth-functions', 'calculus', 'functions', 'derivatives', 'piecewise-continuity']"
4099267,Finding the maximum number of catchable Pokemon such that no two are enemies with each other,"Cynthia loves Pokemon and she wants to catch them all. In Victory Road, there are a total of $80$ Pokemon. Cynthia wants to catch as many of them as possible. However, she cannot catch any two Pokemon that are enemies with each other. After exploring around for a while, she makes the following two observations: 1.Every Pokemon in Victory Road is enemies with exactly two other Pokemon. 2.Due to her inability to catch Pokemon that are enemies with one another, the maximum number of the Pokemon she can catch is equal to $n$ . What is the sum of all possible values of $n$ ? This is a question from BdMO 2021 (Bangladesh National Mathematical Olympiad), which most of the students couldn't solve (including me). My attempt: Let's reconsider the problem with graph theory. We draw an edge between two Pokemons if they are enemies. So, each vertex has degree $2$ . If the whole graph is an $80$ cycle (or an $80$ -gon), Cynthia can catch $40$ Pokemons at max, which is just one case of the problem. There are some other cases when we change the edges of the graph, for which I am unable to find the maximum number of  catchable Pokemons (I am not good at graph theory). So, how do I approach the problem?","['graph-theory', 'recreational-mathematics', 'combinatorics', 'contest-math']"
4099306,"Show that $\sum_{k=1}^{n} a^{\gcd{(k,n)}} $ is divisible by $n$.","Let $a, n \in\mathbb{N}^*$ . Show that $$\sum_{k=1}^{n} a^{\gcd{(k,n)}} $$ is divisible by $n$ . My idea: That sum is $$\sum _{d\mid n} d\cdot \phi(d) \cdot a^{\frac{n}{d}}$$","['number-theory', 'abstract-algebra', 'elementary-number-theory']"
4099309,Is a Hölder continuous function differentiable almost everywhere?,As per the title. I know that a Lipschitz continuous function is differentiable almost everywhere (see the Rademacher Theorem ). I was wondering if something similar was true for Hölder continuous functions.,"['derivatives', 'analysis', 'holder-spaces']"
4099349,Solving differential equation for density in a gas sphere,"I'm trying to derive the equation for density as a function of height in a gas sphere due to gravitational force, and I have derived the following equation: $$\frac{\mathrm{d}\rho}{\mathrm{d}z}=\frac{4 \pi G}{z^2RT}\rho(z)\int_{0}^{z}z'^2\rho(z')\mathrm{d}z'$$ Is there a way to solve it, even if numerically, for $\rho(z)$ ?","['integration', 'calculus', 'derivatives', 'ordinary-differential-equations']"
4099455,An example of planar graph with maximal edges,"Let $G$ be a graph on vertices $v_1, v_2, . . . , v_n$ such that $v_iv_j$ is an edge iff $0 < |i − j| ≤ 3$ . Prove that $G$ is planar having $3n − 6$ edges. Please get me started. Any help will be appreciated. Thanks. I know there will be $3n - 6$ edges, but I couldn't do the planar part.","['graph-theory', 'combinatorics', 'planar-graphs']"
4099482,A problem when integrating $\int_{0}^{2\pi}\frac{d\theta}{(a+\cos \theta)^2}$.,"The exercise is computing $$\int_{0}^{2\pi}\frac{d\theta}{(a+\cos \theta)^2},a>1$$ I know that the exercise may be duplicated, but my problem is something strange when I am working with the residue of it. We know the idea of solving this exercise is that we can change the variable and integrate along the unit circle. And I directly use the formula that is obtained by this approach in class. $$
\int_{0}^{2\pi}R(\sin\theta ,\cos\theta)=2\pi\sum_{z_0\in\mathbb{D}}Res_{z_0}\frac{1}{z}R(\frac{z-\bar{z}}{2i},\frac{z+\bar{z}}{2})
$$ with $z=e^{i\theta}$ . Thus, our exercise becomes to compute the residue of $$\frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}.$$ I use two approach to compute the residue, both seems good to me but the result is different. The first method is my naive idea $$\frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}=\frac{1}{z}\frac{1}{(a+Re(z))^2}$$ Since $z$ is in the unit disc and $a>1$ , $\dfrac{1}{(a+Re(z))^2}\neq0$ , so the only pole is $z=0$ . The second method turns out to be correct. $$\frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}=\frac{4z}{az+\frac{z^2+1}{2}}=\frac{4z}{(z+a+\sqrt{a^2-1})^2(z+a-\sqrt{a^2-1})^2}$$ Thus, the pole in the unit disc is $z_0=\sqrt{a^2-1}-a$ . It is very very strange for me, please help me if you find it usual or easy to explain.",['complex-analysis']
4099490,Karhunen-Loeve expansion of non-centered processes,"The typical form of Karhunen-Loeve expansion is on a detrended stochastic process. E.g., let $Y(t)$ be a stochastic process on $[0,T]$ , and let $X(t) = Y(t)-\mathbb{E}Y(t)$ with a continuous covariance function $R_X(s,t)$ , then there exists a series of orthonormal functions $\phi_k(t)$ on $[0,T]$ and independent zero-mean and normalized random variables $Z_k$ such that $$
X(t) = \sum_{k=1}^{\infty} Z_k \sqrt{\lambda_k} \phi_k(t)
$$ where $\lambda_k$ and $\phi_k(t)$ are the solutions of the following eigensystems equation: $$
\int_0^T R_X(s,t)\phi_k(t)dt=\lambda_k\phi_k(s)
$$ My question is, if we do not subtract the mean from the process, and just focus on the raw autocorrelation function $R_Y(s,t)$ , as $R_Y(s,t)$ is also positive definite symmetric functions in $s,t$ , it has a spectral decomposition (Mercer's theorem) $$
R_Y(s,t) = \sum_k \mu_k \psi_k(s)\psi_k(t)
$$ Can we expand the original process $Y(t)$ in $\psi(t)$ ? And does this decomposition enjoy some similar properties of the original K-L decomposition, such as the optimal compaction of energies of the signal in the eigenfunctions? $$
Y(t)=\sum_k \tilde{Z}_k \sqrt{\mu_k} \psi_k(t)
$$ The empirical reason is that sometimes we are interested in the information contained in the mean as well, not only in the fluctuation around the mean. While the original K-L expansion optimally compacts the total variance into the first few eigenfunctions $\phi_k(t)$ , the direct decomposition of $Y(t)$ may optimally compact the total fluctuation around $0$ , i.e., the raw energy of the signal: $\mathbb{E}\int_0^T |Y(t)|^2dt$ into $\psi_k(t)$ . Has it been shown to be true? And if true, is the result trivial in the sense that $\psi_k(t)$ and $\phi_k(t)$ are connected in some simple way?","['stochastic-processes', 'spectral-theory', 'signal-processing', 'probability']"
4099536,Any chances to find the following sum analytically?,"Consider the following sum: \begin{equation}
S(x, k, N, \alpha_1, \alpha_2) = \sum\limits_{m=1}^{N} \dfrac{ e^{i \phi_m k}}{x - \Omega(m, \alpha_1, \alpha_2, N)},
\end{equation} where $x$ - complex valued parameter, $k, N$ - positive integers ( $k<N$ ), $\phi_m = \dfrac{2 \pi (m-1)}{N}$ , $\Omega (m, \alpha_1, \alpha_2, N) = i \alpha_1 \dfrac{\xi + \xi^{1/N} e^{-i \phi_m}}{1 + \xi^{1/N} e^{-i \phi_m}} - i \alpha_2$ , and $\alpha_1, \alpha_2$ - real-valued constants, and $0<\xi<1$ . I really doubt that for any $N$ this can be written as a simple formula in terms of several known functions, but may there be any possible way to simplify it in certain limits? Like $N \to \infty$ , or saying that $\alpha_2 \gg \alpha_1$ .","['calculus', 'summation', 'sequences-and-series']"
4099563,Find all entire function such that $|f(z)| \leq |ze^z|$,"What I did is: $f$ has zero at $0$ , so $f(z)=zg(z)$ . Using the data, we can say $\frac{g(z)}{e^z}$ is constant. So, $f(z)=Cze^z$ . Is that correct?","['complex-analysis', 'entire-functions']"
4099571,Why is the definite integral of $\int_{1}^{\infty} \frac {\ln (1+x^2)}{x^2}$ equal $\frac{\pi}{2} + \ln(2)$?,"I currently have a question on why when you partially integrate the definite integral. $$\int_{1}^{\infty} \frac {\ln (1+x^2)}{x^2} = \frac{\pi}{2} + \ln(2) $$ I obtained this result via plugging it into a WolframAlpha right after partially integrating the function by hand. Though what confuses me and makes me curious is why $\frac{\pi}{2}$ is one of the results of it, rather than anything that has nothing to do with trigonometrical equations on the surface. Is there any identity i was not aware of ? Anyone that can provide an answer is thanked in advance.","['integration', 'trigonometry', 'definite-integrals']"
4099579,"Coin weighing puzzle: one heavy coin, one light coin, which together weigh the same as two normal coins","My question was inspired by this previous question . There are $c = 3^k$ coins where $k \ge 2$ .  Among these coins: $c-2$ of them are good and weigh the same. The remaining $2$ coins are bad : one of them is heavier than a good coin, and the other is lighter than a good coin. The problem is to identify both bad coins (including which is heavy, which is light) using weighings on a balance. Importantly (and unlike the previous question): the two bad coins together weigh the same as two good coins. I.e., if the two bad coins are on one side of a weighing, and two good coins are on the other side, then the result would be balanced. There are $c(c-1)$ possible solutions. Since $3^{2k-1} = c(c/3) < c(c-1) < c^2 = 3^{2k}$ , we know that $2k$ weighings are necessary. My question: Are $2k$ weighings sufficient? I have a solution for $c = 9$ , where indeed $2k = 4$ weighings are sufficient.  I will post this in a few days, so that others can try their hands on it (both for fun, and also because I don't want to bias people one way or another initially).  My solution is pretty tedious, and I could not generalize it to higher $k$ . If, like me, you can solve the $c=9$ case but cannot generalize to higher $k$ , please feel free to post you (partial) solution so we can perhaps compare approaches.","['recreational-mathematics', 'puzzle', 'combinatorics']"
4099611,Prove that the Sierpiński space is a topology,"I need to prove that the Sierpiński space, $\mathcal{\tau} = \{\emptyset, \{1\}, \{0, 1\}\}$ , is a topology. I have only just started on toplogy, and so far just know the basic axioms. To prove that the union of any collection of subsets from T is in T, do I need to list every single possible union of subsets and check that it is in T? i.e. $\{1\} \cup \{0,1\} = \{0,1\} \in \mathcal{\tau}$ , $\emptyset ∪ \{0,1\} = \{0,1\} \in \mathcal{\tau}$ etc. Or is there a much shorter and more concise method?",['general-topology']
4099649,Two tough functions to integrate: $f(x)={\left({\frac{A}{x^\alpha}+\sqrt{B+\frac{C}{x^{2\alpha}}}}\right)}^{\frac{1}{3}}$ and $g(x)=\frac{1}{f(x)}$,"I’m trying to solve two (in my opinion, tough) integrals which appear in part of my problem. I tried different ways but in the end I failed. See them below, please. $${\rm{integral}}\,1 = \int {{{\left( {\frac{A}{{{x^\alpha }}}\, + \sqrt {B + \frac{C}{{{x^{2\alpha }}}}\,} } \right)}^{\frac{1}{3}}}} dx ,$$ and $${\rm{integral}}\,2 = \int {\frac{1}{{{{\left( {\frac{A}{{{x^\alpha }}}\, + \sqrt {B + \frac{{C\,}}{{{x^{2\alpha }}}}} } \right)}^{\frac{1}{3}}}}}} dx,$$ where $\alpha$ is a positive integer ( $\alpha \ge 2$ ). How can I solve them? I was wondering if someone could help me integrate these functions. Any help is appreciated. Much thanks. Edit : Don't you think that if we set $\alpha =2 $ , the integral might be easier to solve? Having this, I think I can solve the general case with $\alpha \ge 2$ .","['integration', 'indefinite-integrals', 'functions']"
4099678,Optimal strategy to maximize the expected gains of a probability based game,"The game: you start with nothing, and you choose to roll a fair dice as many times as you want. Each of the 6 outcomes is attached with a certain $ value, except for one, where you will lose all that you gained and the game ends. My question: Mathmaitcally speaking, is there an optimal stopping rule that maximizes the expected gains of a single game? There are two possible kinds of strategies: 1- Stop after n rounds 2- Stop as soon as your balance exceed $k The latter makes more sense to me, as the former feels like I'm indulging in some kind of gambler's fallacy.","['statistics', 'optimization', 'game-theory', 'probability-theory', 'probability']"
4099699,Complex analysis of $f(z) = 2 y^2 \sin x − i y^3 \cos x$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I want to find the domain of definition, the domain of derivability and the domain of analyticity of the function $f(z) = 2 y^2 \sin x − i y^3 \cos x$ The domain of definition is $\mathbb C$ but I don't know how to find the otres two in this function.","['complex-analysis', 'cauchy-riemann-equations', 'functions', 'analysis']"
4099731,Is there an integral for $\frac{\pi}{\mathrm{G}}$?,"I would like to find an integral of the form $$\int_a^bf(x)dx=\frac{\pi}{\mathrm G},$$ or at least an infinite series $$\sum_{n\ge k}a_n=\frac{\pi}{\mathrm G},$$ where $\mathrm G$ is Catalan's constant . These identities should be nontrivial (that is, $\int_0^1\pi/\mathrm G dx=\pi/\mathrm G$ and anything sufficiently similar does not count). Context: A while ago, I posted this question ( Relationship between Catalan's Constant and $\pi$ ), and in the answers there were many wonderful integrals and infinite series involving $\pi\mathrm G$ and $\mathrm G/\pi$ , but none for $\pi/\mathrm G$ . I got the idea to search for an integral for $\pi/\mathrm G$ , because it, along with the integrals $$\color{blue}{\int_0^1 \ln\left(\frac{1-x}{1+x}\right)\ln\left(\frac{1-x^2}{1+x^2}\right)\frac{dx}{x}=\pi G}$$ $$\color{red}{\int_0^\frac{\pi}{2} x\ln\left(\cot\left(\frac{x}{2}\right)\left(\frac{\sec x}{2}\right)^4\right)dx=\pi G}$$ (from @Zacky) and $$\frac {G}\pi=\int_0^1\frac{dx}{4\text{sech}^{-1}x}$$ (from @Quanto), would give a complete description of the multiplicative relationship between $\pi$ and $\mathrm G$ . Really, I guess we would only need an integral of the form $$\int_a^bg(x)dx=\frac1{\mathrm G},$$ because there are a plethora of sufficient integrals for $\pi$ ( see here ) such as $$\int_{-1}^{1}\frac{dx}{\sqrt{1-x^2}}=\pi,$$ and we could then write $$\int_a^b\int_{-1}^1\frac{g(y)}{\sqrt{1-x^2}}dxdy=\frac{\pi}{\mathrm G},$$ which would probably be pretty easy to convert from a double integral to a single integral. Of course there is the natural question ""is this even possible?"" I don't know. I have (clearly) never seen an integral for $1/\mathrm G$ . Do you have any ideas? Thanks :)","['integration', 'definite-integrals', 'pi', 'constants', 'catalans-constant']"
4099783,"Global Maximum of $f(x,y)$ on a set $M$.","I want to investigate the function $f(x,y) = 4x^2 + 9y - \frac{1}{3}y^3$ on the set $M:= \{(x,y) \in \mathbb{R}^2 : y \geq |x|\}$ . In particular, I want to a) proof the existence of a global maximum on the set $M$ , b) find all points in $M$ where this maximal value is reached. First of all I did draw a picture of the set $M$ . (Since $M$ is not very hard to illustrate I do not post it here.) I really struggle with a). The only real theorem I know is that every continuous function on a compact set has a Min/Max. Since $M$ is not compact, I don't see how I can proof a). I thought about quadratic expansion, but that did not work. Considering b), I first took a look at the gradient \begin{align}
\operatorname{grad} f(x,y) = \begin{pmatrix} 8x \\ 9 - y^2\end{pmatrix}
\end{align} which is zero for $(0,3)$ and $(0,-3) \notin M$ . Using the Hessian Matrix $\mathcal{H}_f$ and evaluating it at $(0,3)$ leads to the fact that $(0,3)$ seems to be a saddle point. Hence, there looks to be no inner point, which might be interesting for the question. Looking at the boundaries of $M$ , as Fra suggested in his answer, I looked at $$f|_{\partial M}(x,y) = \begin{cases} g(x) := 4x^2 +9x - \frac{x^3}{3}, & \mbox{if } x \geq 0\\
h(x) := 4x^2 -9x + \frac{x^3}{3}, & \mbox{if } x < 0
\end{cases}$$ and found that $g$ has a maximum, namely $\max\{4x^2+9x - \frac{x^3}{3}\} = 162$ for $x = 9$ . $h$ as well has a maximum, $\max\{4x^2-9x + \frac{x^3}{3}\} = 162$ for $x = -9$ . So my answer to b) is $\{(9,9), (-9,9)\}$ with value $162$ . Can someone provide a solution/explanation for a)? Furthermore I would be glad if my solution for b) can be verified.","['maxima-minima', 'multivariable-calculus', 'extreme-value-theorem', 'real-analysis']"
4099803,Solution for the following limit problem,"I want to solve the following limit problem $$\lim_{x \rightarrow \infty} \bigg[ (x + a)\log \big( \frac{x+a}{x+b} \big) \bigg] $$ A small simulation with a = 5 and b = 2 leads to a result of 3 which I think is correct and the right answer should be (a - b), somehow I am unable to prove it. Here is the code to reproduce the result def f(alpha):
    return (5 + alpha) * np.log((5 + alpha) / (2 + alpha))


alpha_list = np.linspace(10,1000)
plt.plot(alpha,[f(a) for a in alpha_list]) yields the following plot , Thanks in advance.",['limits']
4099807,Blowup extends a regular map to $\mathbb{P}^{N+1}$,"Let $(X_0,X_1,...,X_n)$ homogeneous coordinates of $\mathbb{P}^n$ and let assume that $X^r \subset \mathbb{P}^n$ is a complex variety where $x:= (1,0,...,0) \in X$ and $X$ isn't a cone with vertex $x$ . Consider the graded ring homomorphism $$ \phi: \mathbb{C}[X_0,...,X_n] \to \oplus_{k=0} O_{x, \mathbb{P}^n} \cdot X_0^k  $$ given by $\phi(f):= (f/X_0^k) \cdot X_0^k$ if $f$ is homogeneous of degree $k$ .
It induced the graded homomorphism $$ \psi:R_X= \mathbb{C}[X_0,...,X_n]/I(X) \to \oplus_{k=0} O_{x, X} \cdot X_0^k  $$ Define as $R^0_X := \psi^{-1}[\oplus_{k=0} m^k_{x, X} \cdot X_0^k]$ where $m_{x, X} $ is the unique maximal ideal of the local ring $\subset O_{x,X}$ . Let $f \in R^0_X$ be homogeneous of degree $l$ . Consider the embedding of $X-\{x\}$ into $\mathbb{P}^{N+1}$ defined by monomials in $X_1,..., X_n$ of degree $l$ and $f$ . Less formally the map is given by $$ y \mapsto (X_1^l(x): ... :X_0^{l_0} \cdot X_1^{l_1} ... \cdot X_n^{l_n}(y):
...: f(y)) $$ with $\sum_i l_i =l$ . Restricted to $X-\{x\}$ this map is regular. Now let $B_x(X)$ be the blowup of $X$ in $x$ . Geometrically $B_x(X)$ arise also as the Zariski closure of the graph $\Gamma_x^X
= \{(y, p_x(y)) \ \vert \ y \in X-\{x\} \} \subset \mathbb{P}^n 
\times \mathbb{P}^{n-1}$ where the graph $\Gamma_x^X$ is associated
to restriction of the projection from $x$ map $p_x: \mathbb{P}^{n} \to \mathbb{P}^{n-1}, (x_0:x_1:...:x_n) \mapsto
(x_1:...:x_n)$ to $X-\{x\}$ . Question: why the regular (regular means here well defined in projective sense)
embedding map $e: X-\{x\} \to \mathbb{P}^{N+1}$ from above extends
to a regular map from $B_x(X)$ to $\mathbb{P}^{N+1}$ ? Source: David Mumford's Algebraic Geometry 1: Complex projective varieties.
to avoid the clumsiness of having misread something below I attatched to
original source:","['complex-geometry', 'algebraic-geometry', 'blowup', 'schemes']"
4099826,"$1 = \phi(\phi(\cdots\phi(n)\cdots))$, where Euler's totient is applied $k$ times, then $n\leq 3^k$","Suppose that $n$ and $k$ are positive integers such that $1 = \phi(\phi(\cdots\phi(n)\cdots))$ , where the Euler's totient function is repeated $k$ times. Prove that $n \leq 3^k$ . My work so far: I'm thinking of doing induction. If $\phi$ is only done once, then $n$ must be $1$ or $2$ since those are the only values when $\phi (n) = 1$ . I'm not sure how to continue this induction proof, and should I also attempt a proof of contradiction?","['number-theory', 'induction', 'totient-function', 'elementary-number-theory']"
4099827,Some questions about $\operatorname{spec}( \mathbb{Z} )$,"Let consider the scheme $\operatorname{spec}(\mathbb{Z})$ I have some questions about this scheme : For a variety $X$ defined over a field $K$ , one can define the dualizing sheaf. Is there an analogue for $\operatorname{spec}(\mathbb{Z})$ ? Does $\operatorname{spec}(\mathbb{Z})$ have a ""dualizing sheaf"" ? I know that on affine schemes the cohomology groups $H^i(\operatorname{Spec}(\mathbb{Z}), \mathcal{F})$ are 0 for $i>0$ and for every quasicoherent sheaf $\mathcal{F}$ . And I know that invertible sheaf are quasi coherent. So let $D$ be a divisor on $\operatorname{spec}(\mathbb{Z})$ , if I denote $L_D$ the invertible sheaf associated with $D$ , we have $H^i( \operatorname{spec}(\mathbb{Z}), L_D)=0$ for all $i>0$ . But what is the forme of the $H^0$ ? How can I describe it ? Thanks for help","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'algebraic-geometry']"
4099830,What other tricks and techniques can I use in integration?,"So far, I know and can use a reasonable number of 'tricks' or techniques when I solve integrals. Below are the tricks/techniques that I know for indefinite and definite integrals separately. Indefinite integrals Standard integrals, such as those of polynomial, trigonometric, logarithmic and exponential functions, including usage of trig identies. Basic substitution. Weierstrass and Euler substitutions. Integration by parts. $$\int\frac{1}{x+x^n}dx=\int\frac{x^{-n}}{1+x^{1-n}}dx=\frac{1}{1-n}\ln\lvert 1+x^{1-n}\rvert+C$$ $$\int\frac{1}{x^{\frac{a+b}{a+b}}\cdot x^{\frac{a}{a+b}}+x^{\frac{b}{a+b}}}dx=\int \frac{x^{-\frac{b}{a+b}}}{\left(x^{\frac{a}{a+b}}\right)^2+1}dx=\arctan x^{\frac{a}{a+b}}+C$$ Substitution $u=\frac{1-x}{1+x}$ for integrals involving $\ln$ and/or the bounds $0$ and $1$ . Reduction formulae. $$\int e^x(f(x)+f'(x))dx=e^xf(x)+C$$ Writing $\sin$ 's and $\cos$ 's as complex exponentials. $$\int\frac{a\sin x+b\cos x}{c\sin x+d\cos x}dx=Ax+B\ln\lvert c\sin x+d\cos x\rvert+C$$ where $$A=\frac{ac+bd}{c^2+d^2}~~~B=\frac{bc-ad}{c^2+d^2}$$ which can be found using simultaneous equations. Definite integrals Differentiation under the integral sign ('Feynman's technique') $$\int_a^b f(x)dx=\int_a^bf(a+b-x)dx$$ Usage of power series to evaluate integrals such as $\int_0^1\frac{\ln(1-x)}{x}dx$ and the like. Making use of even or odd function properties. (My newest personal favourite) For even functions $f(x)$ and $g(x)$ , and an odd function $h(x)$ : $$\int_{-a}^a\frac{f(x)}{1\pm g(x)^{h(x)}}dx=\int_{0}^a f(x)~dx$$ which allows us to evaluate wonderful things like $$\int_{-\infty}^{\infty}\frac{e^{-x^2}}{1+\pi^{\sin x} }dx=\frac{\sqrt{\pi}}{2}$$ Question: Do you know any other integration techniques or tricks that I can use whose usage don't rely on anything beyond high school calculus * or perhaps the first year of a Mathematics degree course? I know that a similar question has been asked here and here but I've looked through them and nothing beyond what I have written above was mentioned, apart from some techniques I couldn't understand such as residue calculus and contour integrals. Many thanks for your help. * Roughly what I mean by high school level calculus: INCLUDED Integration of polynomials and the basic trigonometric functions, such as $\sin x$ , $\cos x$ , $\tan x$ , $\sec x$ , $\operatorname{cosec} x$ , $\cot x$ , $\sec^2 x$ , $\sec x\tan x$ , $\operatorname{cosec} x\cot x$ , $\operatorname{cosec}^2 x.$ Integration of all $x^n$ including $n=1$ . Integration of exponentials. Integration by parts. Integration using substitution, such as using trigonometric/hyperbolic substitutions, and Weierstrass and Euler substitutions (this also includes integration by 'inspection' which is really just substitution but when the individual doesn't need to substitute anything). Integration using partial fractions and logarithms, such as $\int\frac{f'(x)}{f(x)}dx$ . Reduction formulae. Ability to understand and use the concepts of even and odd functions in integration. Improper integrals. Integrating which results in elementary functions. NOT INCLUDED Fourier, Laplace and Mellin transforms. Indefinite integrals that include non-elementary functions in the solution. Contour integration. Residue calculus and similar methods.","['integration', 'big-list', 'calculus', 'indefinite-integrals', 'soft-question']"
4099894,The definition of Absolute Continuous function,"Absolute Continuous functions require a finite sequence of subintervals of the domain. Can we replace this finite sequence with a countably infinite one in this definition? Please note that an absolutely continuous function preserves null sets. To prove this result, I choose an open set G that contains a given null set N. Then eventually, I proved that the image of N has measure zero. In this proof, at some point, I chose a finite sequence from the countable sequence of intervals that covers G. Moreover, the converse is also true ie any continuous function with a bounded variation that preserves the null set is absolutely continuous. Based on my own shallow observation, I feel like we can replace this finite sequence criterion with a countably infinite one. Is this true? Could you give me an easy counter-example where my guess is false?  Thank you for your time.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'absolute-continuity']"
4099913,Example(s) of lift of Frobenius on Abelian Varieties,"This is a bit embarassing, but what are good examples of the lift of Frobenius of abelian varieties? In explicit terms? If I consider an ordinary abelian variety $A/k$ , then by Serre-Tate theory there exists a canonical lift of $A$ to $W(k)$ . However I find myself unable to write down a concrete example, or rather I'm stuck with the following computation:
Consider $y^2=x(x-1)(x+2)$ . This is ordinary for $p=5$ . Then we have a lift of the abelian variety to $W(\mathbb{F}_5)=\mathbb{Z}_5$ which affine locally is given by $\mathbb{Z}_5[x,y]/(y^2-x(x-1)(x+2))$ . Then to show that $$x\mapsto x^5, \quad y\mapsto y^5$$ is the Frobenius lift, I need to show that $$y^{10}-x^5(x^5-1)(x^5+2)\in (y^2-x(x-1)(x+2)).$$ However, that is not true by pluging-in $x=2,y=3$ , then $$2^{10}-3^5(3^5-1)(3^5+2)$$ is not divisible by $(2^2-3(3-1)(3+2))$ . So this can't be the lift of Frobenius. However, I don't know how to find it.....
Any other explicit examples of lift of Frobenius would also be appreciated. I'd just like to have some examples on hand to be able to ""play"" with them.","['algebraic-geometry', 'elliptic-curves']"
4099917,Arc Length Integral of $x^x$ from 0 to 1 in closed form.,"I was recently trying to compute the arc length of $x^x$ from $0$ to $1$ as follows: $$L=\int_0^1 \sqrt{1+\left(\frac{\text{d}}{\text{d}x}x^x\right)^2} \text{d}x=$$ $$\int_0^1\sqrt{1+x^{2x}(\ln x+1)^2} \text{d}x=$$ Using the infinite series expansion for the binomial theorem with |x|<1, we can rewrite the square root portion as $\sqrt x=x^{1/2}$ . We can assume a limit for x=1 in the integral bounds: $$\int_0^1 \sum_{n=0}^∞ \binom{\frac 12}{n} (x^{2x}(\ln x+1)^2)^n \text{d}x=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \int_0^1 e^{2nx\ln(x)}(\ln x+1)^{2n}\text{d}x=$$ It would be maybe easier to expand out the exponential as a series with a different index to have another series with an independent index so that no cauchy products are needed: $$\sum_{n=0}^∞ \binom{\frac 12}{n} \int_0^1 \sum_{m=0}^∞\frac{2^mn^mx^m\ln^m(x)}{m!}(\ln x+1)^{2n} \text{d}x=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \int_0^1 x^m\ln^m(x)(\ln x+1)^{2n}\text{d}x=$$ Then the exponentiated logarithmic part of this expression, if we only focus on it, can be expanded into another similar summation using a binomials expansion because the index of n is an integer by definition: $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \int_0^1 x^m\ln^m(x)\sum_{l=0}^{2n}\binom{2n}{l}\ln^l(x)\text{d}x=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} \int_0^1 x^m\ln^{l+m}(x)\text{d}x$$ This integral can be found in terms of the factorial and a “factorial coefficient” part. Using the substitution of u=-ln(x) gets us: $$\int_0^1 x^m\ln^{l+m}(x)\text{d}x=$$ $$(-1)^{l+m}\int_0^ ∞e^{-u(m+1)}u^{l+m}\text{d}u=$$ $$-(-1)^{l+m+1}m^{l+m+1}Γ(l+m+1,-(m+1)\ln(x))|_0^1=$$ $$(-1)^{l+m}m^{l+m+1}(l+m)!$$ The incomplete gamma function is here. This means our final possible answer is: $$L=^? \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} (-1)^{l+m}m^{l+m+1}(l+m)!=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mm^{m+1}n^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} (-1)^{l+m}m^l(l+m)!=^?1.2474...$$ This series diverges maybe because of a bad usage of the summations with the interval of convergence being too small. My main question is if all of these steps are correct as in my previous deleted question. Sorry for the undetailed question. Also, please correct and simplify the problem as much as possible using any widely used function. I.e. do not just do arclength(f(x),a,b). I tried a similar method which also diverges even though the surface area should not of the same figure but with $(y-x^x)(y-x^{-x})=0$ , $0\le x\le 1$ which got me to a similar answer. This one had $$S_y=\int_0^1 x^x \sqrt{1+\left(\frac{\text{d}}{\text{d}x}x^x\right)^2} \text{d}x$$ . This one experimentally had 5 summations with different indices by accident when I was trying to calculate the arc length. The area of this figure is simply the difference two sophomore dream integrals. This is $$A=\sum_{N=1}^ ∞\frac{1+(-1)^N}{N^N}=.507...$$ as n as an index was already defined. I was also trying to find the perimeter of the lamina and volume of this solid of revolution about both the x and y axes all or which are quite ambitious to figure out and very tricky as I most likely got this wrong except for the area of this figure. Please just figure out the arc length and all will be well: Here is the desmos demo of this arc length series: https://www.desmos.com/calculator/gt0hsg40ah If this is true, please expand the binomial coefficients and simplify the rest. Maybe keep the original form. Thanks, and please give me feedback!","['exponentiation', 'summation', 'arc-length', 'calculus', 'binomial-theorem']"
4099940,Find the Fisher Information of $X\sim{\rm Poisson}(\mu)$,"Suppose $X \sim Poisson(\mu)$ , so for $i \in \{0,1,2,\ldots\}$ , $P(X = i) = \exp(-\mu) \mu^i/i!.$ Find the Fisher Information of $X$ . This is  what I have  done so far $S_X(i) = \frac{\partial \ln (f_{X|\mu}(i))/\partial \mu}{f_{X|\mu}(i)} = -1 + \frac{i}{\mu}$ How do I find the probabilities to get the fisher score?","['statistics', 'poisson-distribution', 'probability-distributions', 'fisher-information', 'probability-theory']"
4100020,Heat Equation With Boundary Value Problem,"I have a heat equation $$
\frac{\partial u}{\partial t} = a^2 \frac {\partial^2 u}{\partial x^2} + b \frac{\partial u}{\partial x}  \
$$ with boundary conditions $$
u(0,x) = 300 \qquad u(t,0) = 100 \qquad  u_{x}(t, l) = 300e^{-t}
$$ I understand perfectly how to solve this equation with zero boundary conditions, but I can't figure out what to do with the boundary conditions. Can u help me please?","['heat-equation', 'boundary-value-problem', 'ordinary-differential-equations']"
4100036,Transversality in $\mathbb{R}^2$,"Define, for some $a\in\mathbb{R}, f_{a}:\mathbb{R}\to\mathbb{R}^{2}$ by $f_{a}(p)=(p,a)$ and consider $N\subset\mathbb{R}^{2}, \ N=\{(x,x^2); x\in\mathbb{R}\}.$ Analysis of the transversality of $f_{a}$ with $N.$ Could someone help me, please? Geometrically, we can see that for $a\leq 0,$ $f_{a}$ isn't transversality to $N$ . How to prove it? So, $d(f_{a})_{p}(v)=(v,0)$ and $T_{(p,p^2)}N=\{(v,2pv)| v \in \mathbb{R}\}.$ How and why does $ a $ influence this?","['differential-topology', 'transversality', 'differential-geometry']"
4100081,convergence of $\sum_{n=1}^\infty \frac{1}{(n!)^{(2/n)}}$,"Show that the following series converges or diverges. $\sum_{n=1}^\infty \frac{1}{(n!)^{(2/n)}}$ Hint: Note that $n! \geq p^{n-p+1}$ for all $i \leq p \leq n$ . I solved this by splitting into $3$ series $A,B,C$ where $A$ will be the series for those terms for which $3$ divides $n$ : i.e. $3, 6, 9...$ . $B$ will be the series for those terms for which $3$ divides $n+1$ , i.e. $4, 7, 10,...$ , and $C$ will be will be the series for those terms for which $3$ divides $n+2$ . Using the hint, for $A$ choose $p = (n/3 +1)$ , for $B$ choose $p = (n+1)/3 +1$ , for $C$ choose $p = (n+2)/3 +1$ . Each of these series $A, B, C$ converges; it should be like a $p$ -series with $p = 4/3$ (not to confuse this $p$ with the previous $p$ ). I believe this is correct. My question is does anyone see a cleaner/simpler way to do this? EDIT: Thanks for the answers so far, but is there a cleaner, simpler answer based on the Above Hint?","['convergence-divergence', 'analysis', 'real-analysis']"
4100105,"If a univariate function has directional derivatives on the whole domain, does this imply that it is differentiable except on a countable set?","Suppose we have a univariate function $f:\mathbb{R} \rightarrow \mathbb{R}$ .  It is well-known that if both directional derivatives of the function exist at a point then the function is differentiable at that point.  Of course, even if both directional derivatives exist, it is possible that they are different values at a point, in which case the function is not differentiable at that point. My Question: If both directional derivatives exist over the whole domain (i.e., all real numbers), does this imply that $f$ is differentiable except on a countable set (i.e., that the directional derivatives match except on a countable set)?  Intuitively that seems right to me, but I'm not sure how to prove it.","['derivatives', 'real-analysis']"
4100114,How to prove $\pi_1(\mathbb{A}_k^n) = 0$ when $k$ is an algebraic closed field of char 0?,"I know that to prove $\pi_1(\mathbb{P}_k^n) = 0$ , one can just use the curve case and proceed by induction. For example, if $n=2$ and there is any connected etale covering, one can choose any line in $\mathbb{P}_k^2$ . The inverse image of the line is the support of an ample divisor hence connected by Hartshorne III.7.9. Then one can conclude the covering is of degree 1 and finish the proof.
But I don’t know how to do this in the affine case and I don’t want to use comparison theorem to the topological fundamental group. Can someone tell me how to do this? Thank you very much! I’m not sure if the following argument works. One can prove that if $k$ is not required to be algebraic closed, then all connected finite etale coverings of $\mathbb{A}_k^n$ are $\mathbb{A}_{k’}^n$ where $k’/k$ is a finite separable extension. Now we can do induction as following. When $k$ is algebraic closed, If $f:X\rightarrow Spec(k[x,y])$ is a connected finite etale covering, then so is the base change $f’:X’\rightarrow Spec(k(x)[y])$ . By induction hypothesis, $X’=Spec(L[y])$ where $L$ is a finite separable extension of $k(x)$ . Hence the generic fiber of $y=0$ is $Spec(L)$ which is connected. Then one can use induction hypothesis to conclude $X=\mathbb{A}_k^n$ . When k is not algebraic closed, I guess it can be deduced from the precious case.","['fundamental-groups', 'algebraic-geometry']"
4100183,Which tosses should one choose to better estimate $p$?,"Puzzle $1$ : A coin $C_1$ has probability $p$ of turning up head, while a coin $C_2$ has probability $2p$ of
turning up head. All we know is that $0 < p < \frac12$ . Now, $20$ tosses are given. You can choose all tosses from $C_1$ , all tosses from $C_2$ , or some tosses from each (the total is $20$ ). If the objective is to estimate $p$ , what do you do? (Hint: Minimize mean-squared error of the estimator). If we choose all $n = 20$ tosses from $C_1$ , then we get $X_1,X_2,\ldots,X_n \sim \text{Ber}(p)$ . $\overline{X_n}$ is an estimate for $p$ which is unbiased, and hence $$\text{MSE}_{\overline X_n}(p) = \text{var}(\overline X_n) = \frac{np(1-p)}{n^2} = \frac{p(1-p)}{n}$$ since $\text{MSE}_{\overline X_n}(p) = \text{var}(\overline X_n) + (\text{bias}(\overline X_n))^2$ .
Similarly, if we choose all tosses from $C_2$ , we should get $$\text{MSE}_{\frac{\overline X_n}{2}}(p) = \text{var}\left(\frac{\overline X_n}{2}\right) = \frac{p(1-2p)}{2n}$$ right? The factor of two in the denominator is due to the fact that we're estimating $p$ , while drawing from $\text{Ber}(2p)$ . What happens if we choose some from $C_1$ and some from $C_2$ ? Answer: Choose all from $C_2$ . Here's another puzzle with a different answer: Puzzle $2$ : A factory produces light bulbs having an exponential distribution with mean $µ$ . Another factory produces light bulbs having an exponential distribution with a mean of $2µ$ . Your goal is to estimate $µ$ . You are allowed to choose a total of $50$ light bulbs (all from the first, all from the second, or some from each factory). What do you do? Answer: It does not matter what factory you choose from. In this case, I saw that the mean-squared error if we choose all bulbs from the first factory is $\mu^2/n$ , and it is the same if we choose all from the second factory as well. Due to the square of $\mu$ in the variance of this exponential distribution, it so happens that all choices make equivalently good estimators of $\mu$ . Follow-up question: Is there a way to probabilistically approach both these puzzles, i.e. without getting into actual MSE calculations to predict the MSE?","['statistics', 'probability-distributions', 'parameter-estimation']"
4100212,Weighted Twist of Vandermonde's Identity,"I've been stuck on the following expression, trying to determine a ""simple"" closed form for it: $$\sum_{i=0}^{m-1}\frac{1}{m-i}{x-a \choose i-a}{2m-x-b \choose m-1-i-b}.$$ I feel like there should be an obvious simplification based on where it is derived from, but who knows, maybe I'm crazy. As stated in the title, this can be viewed as a weighted twist of Vandermonde's identity, by setting $i\leftarrow i+a$ and adjusting the limits: $$\sum_{i=0}^{m-1-a-b}\frac{1}{m-i-a}{x-a \choose i}{2m-x-b \choose m-1-a-b-i}.$$ Now, without the leading weight term $\frac{1}{m-i-a}$ the sum would just be ${2m-a-b \choose m-1-a-b}$ by Vandermonde's identity. But with the weighted term, I'm pretty lost.","['binomial-coefficients', 'combinatorics', 'hypergeometric-function']"
4100214,Understanding the construction and structure of the Grassmannian manifold,"I have been reading Differential geometry of smooth manifolds from two different books: one by Jeffrey M Lee and the other by John M Lee. In the first chapter of both books, the authors construct what is called a Grassmannian manifold. Since the proof given in the book is almost complete, there are no ""doubts"" in the proof. However, here, I will be sharing a few concerns while constructing the manifold structure on the Grassmannian. For reference, we will be using the following result which tells us that a set can be given a smooth structure under certain conditions: Theorem: Let $M$ be a set and $\left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta}$ be a collection of subsets of $M$ together with injective maps $\phi_{\alpha}: U_{\alpha} \to \mathbb{R}^n$ . Assume the following: $\left\lbrace \left( U_{\alpha}, \phi_{\alpha} \right) \right\rbrace_{\alpha \in \Delta}$ is a smooth atlas for $M$ . There is a countable subcollection $\left\lbrace U_{\alpha_n} \right\rbrace_{n \in \mathbb{N}}$ of $\left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta}$ which covers $M$ . For distinct points $p, q \in M$ , either there is some $\alpha \in \Delta$ such that $p, q \in U_{\alpha}$ or there are $\alpha, \beta \in \Delta$ with $\alpha \neq \beta$ such that $p \in U_{\alpha}$ , $q \in U_{\beta}$ and $U_{\alpha} \cap U_{\beta} = \emptyset$ .
Then, $M$ is a smooth manifold with the topology induced by the atlas. Here, again, when we say a ""smooth atlas"", we mean independently (without assuming a topology on $M$ ). That definition is given as follows. Definition: Let $M$ be a set, $\left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta}$ be a collection of subsets of $M$ , and $\phi_{\alpha}: U_{\alpha} \rightarrow \mathbb{R}^n$ be injective maps onto open sets in $\mathbb{R}^n$ . Then, the collection $\left\lbrace \left( U_{\alpha}, \phi_{\alpha} \right) \right\rbrace_{\alpha \in \Delta}$ is a smooth chart on $M$ if $\bigcup\limits_{\alpha \in \Delta} U_{\alpha} = M$ . For each $\alpha, \beta \in \Delta$ , the set $\phi_{\alpha} \left( U_{\alpha} \cap U_{\beta} \right)$ is open in $\mathbb{R}^n$ . For each $\alpha, \beta \in \Delta$ with $U_{\alpha} \cap U_{\beta} \neq \emptyset$ , the map $\phi_{\beta} \circ \phi_{\alpha}^{-1} : \phi_{\alpha} \left( U_{\alpha} \cap U_{\beta} \right) \rightarrow \phi_{\beta} \left( U_{\alpha} \cap U_{\beta} \right)$ is a (smooth) diffeomorphism. Using this definition and the theorem, the authors try to construct a smooth structure on the Grassmannian. They start with a finite-dimensional real vector space $V$ , say of dimension $n$ , and consider the set of all $k$ -dimensional subspaces of $V$ . We call it $G_{k} \left( V \right)$ . This set will precisely become the Grassmannian manifold. To do so, we would need to construct a suitable atlas on $G_k \left( V \right)$ such that the conditions of the Theorem are satisfied. To achieve this end, we see that for any $k$ -dimensional subspace $P$ of $V$ , there is an $\left( n - k \right)$ -dimensional complementary subspace $Q$ such that $V = P \oplus Q$ . Then, for any linear map $T: P \rightarrow Q$ , if we consider its graph $\Gamma \left( T \right) = \left\lbrace \left( x, Tx \right) | x \in P \right\rbrace$ , then it can be considered as a subspace of $V$ , by identifying $\left( x, Tx \right)$ with $x + Tx$ . Moreover, it is also easy to see that $\Gamma \left( T \right) \cap Q = \left\lbrace 0 \right\rbrace$ . In fact, every $k$ -dimensional subspace of $V$ which intersects $Q$ trivially, can be seen as a graph of a linear map from $P$ to $Q$ . To see this, let $W \subseteq V$ be a $k$ -dimensional subspace such that $W \cap Q = \left\lbrace 0 \right\rbrace$ . Then, for each $w \in W$ , there is a unique $p \in P$ and $q \in Q$ such that $w = p + q$ . We define $T: P \rightarrow Q$ as $Tp = q$ . That is, if we consider $U_Q$ to be the set of all $k$ -dimensional subspaces which intersect $Q$ trivially, then we have a bijection $\psi_Q: L \left( P, Q \right) \rightarrow U_Q$ . Here, $L \left( P, Q \right)$ is the space of all linear transformations from $P$ to $Q$ , and can be identified with $R^{k \left( n - k \right)}$ . So, the collection $\left\lbrace \left( U_Q, \phi_Q \right) \right\rbrace$ , where $\phi_Q = \psi_Q^{-1}$ can be the required smooth atlas. Again, to see this, we have to prove point (2) and (3) of the definition. If $\left( P', Q' \right)$ is another pair of complementary subspaces of $V$ , where $P$ is $k$ -dimensional, we first want to prove that $\phi_Q \left( U_Q \cap U_{Q'} \right) = \left\lbrace T: P \rightarrow Q | \Gamma \left( T \right) \cap Q = \left\lbrace 0 \right\rbrace \text{ and } \Gamma \left( T \right) \cap Q' = \left\lbrace 0 \right\rbrace \right\rbrace$ is empty. However, because $\phi_Q$ is a bijection, we know that $\phi_Q \left( U_{Q} \cap U_{Q'} \right) = \left\lbrace T: P \rightarrow Q | \Gamma \left( T \right) \cap Q' = \emptyset \right\rbrace$ . What I don't understand is why should this be an open set in $L \left( P, Q \right)$ ?  To understand what is happening, I took a look at the three-dimensional case, when $\Gamma \left( T \right)$ could be $2$ -dimensional. Since there is a one-to-one correspondence between $T$ and $\Gamma \left( T \right)$ , we might as well work with a $2$ -dimensional subspace in $\mathbb{R}^3$ which intersects $Q$ and $Q'$ trivially. To get more of an idea, I have considered that $Q$ is the $X$ -axis, $Q'$ is the $Y$ -axis. Suppose that $T \in \phi_Q \left( U_Q \cap U_{Q'} \right)$ . Then, it corresponds to a plane which does not contain both $X$ - and $Y$ -axes. Now, this plane can be sort of ""rotated"" by a small amount so that the resulting plane(s) do not contain the $X$ - and the $Y$ -axes. See Figure for more intuitive understanding of my thoughts. What I have been stuck on is that how should we use these thoughts to construct open balls around each $T \in \phi_Q \left( U_Q \cap U_{Q'} \right)$ ?","['grassmannian', 'smooth-manifolds', 'differential-geometry']"
4100216,Is polynomially convex strictly weaker than convex?,"Define the polynomially convex hull of a compact set $K$ to be the set $K\hat{} = \{ z \in \mathbb{C}: |p(z)| \le \max_{x \in K} |p(x)| \text{ for every polynomial } p \}$ If $K\hat{} = K$ then $K$ is polynomially convex . I'm wondering to what extent does this agree with the ""normal"" sense of convexity in the Complex plane, that is containing all its line segments. I believe that for example the polynomially convex hull of two points is not the line segment between them, since a polynomial could obtain a max on the midpoint between them, thus be less than the maximum of the two points. Given that, is it correct to say we can recover the ""normal"" definition by considering only linear functions, which would make this a generalization and weakening of the concept (since it'd be harder to find points where this was true, thus the hull is smaller)?","['complex-analysis', 'geometry']"
4100221,Circle-to-circle contacts on a hexagonal grid.,"In OEIS sequences A047932 and A263135 , coins are placed in a ""spiral"" on the faces or vertices of a hexagonal grid respectively, and the number of coin-to-coin contacts are counted. The following images illustrate these two constructions respectively: Examples The following images illustrate $A047932(11) = 21$ and $A263135(22) = 27$ . That is, when $11$ coins are placed in a spiral on the faces of a hexagonal grid, there are 21 coin-to-coin connections. When $22$ coins are placed in a spiral on the vertices of a hexagonal grid, there are $27$ coin-to-coin connections. Asymptotically, $A047932(n) \sim \frac{6}{2}n$ and $A263135(n) \sim \frac{3}{2}n$ , because non-boundary coins have 6 and 3 neighbors respectively. Thus it's natural to ask how $A047932(n)$ compares with $A263135(2n)$ . An observation Numerically, it appears that $$A263135(2n) - A047932(n) = \left\lceil \sqrt{3n - \frac 34} - \frac 12 \right\rceil = A216256(n),$$ but I'm not sure how to prove it.
Obviously, A263135 and A047932 have combinatorial interpretations—the ones above! But what do I mean by a combinatorial interpretation of $A216256(n)$ ? One combinatorial pattern is the run-lengths, which are the positive integers with the odd numbers repeated. $$
\underbrace{1}_1, 
\underbrace{2}_1, 
\underbrace{3, 3}_2, 
\underbrace{4, 4, 4}_3, 
\underbrace{5, 5, 5}_3, 
\underbrace{6, 6, 6, 6}_4, 
\underbrace{7, 7, 7, 7, 7}_5, 
\underbrace{8, 8, 8, 8, 8}_5, 
\underbrace{9, 9, 9, 9, 9, 9}_6, \dots
$$ What is a combinatorial proof of the conjectured equation above? Or, if that's too hard, is there a way to derive a formula for $A263135(2n)$ and use the fact that we know that $A047932(n) = \lfloor 3n - \sqrt{12n-3}\rfloor$ ?","['integer-lattices', 'combinatorics', 'geometry']"
4100315,"How many rounds would it take to get each pair on the same team at least once, not using all possible teams?","I have a young group of kids ( $30$ ) playing soccer and they need to be put into $6$ teams of $5$ players for each round of matches. All $6$ teams play at the same time on adjoining fields. If I wanted each kid to play on a team with every other kid in the group (so they know each others names), how many team rounds would I need? Note: I'm not after the number of rounds to get through all of the combinations of unique teams.","['combinatorial-designs', 'combinatorics']"
4100485,Exercise about Schwarz derivative,"If $f$ is three times differentiable and $f'(x)\neq 0$ , the Schwarz derivative of $f$ at $x$ is defined by $$\mathscr{D}f(x)=\dfrac{f'''(x)}{f'(x)}-\dfrac32\left( \dfrac{f''(x)}{f'(x)}\right)^2.$$ (a) Demonstrate that $$\mathscr{D}(f\circ g)=[\mathscr{D}f\circ g]\cdot g'^2+\mathscr{D}g.$$ My solution: using the chain rule and the product rule and, we obtain $$(f\circ g)'(x)=f'(g(x))\cdot g'(x)$$ $$(f\circ g)''(x)=f''(g(x))\cdot (g'(x))^2+f'(g(x))\cdot g''(x)$$ $$(f\circ g)'''(x)=f'''(g(x))\cdot (g'(x))^3+2f''(g(x))\cdot g'(x)g''(x)+f''(g(x))\cdot g''(x)g'(x)+f'(g(x))\cdot g'''(x)=f'''(g(x))\cdot (g'(x))^3+3f''(g(x))\cdot g'(x)g''(x)+f'(g(x))\cdot g'''(x)$$ \begin{align*}
	\mathscr{D}(f\circ g) &= \dfrac{(f\circ g)'''(x)}{(f\circ g)'(x)}-\dfrac32\left( \dfrac{(f\circ g)''(x)}{(f\circ g)'(x)}\right)^2=\\
&= \dfrac{f'''(g(x))\cdot (g'(x))^3+3f''(g(x))\cdot g'(x)g''(x)+f'(g(x))\cdot g'''(x)}{f'(g(x))\cdot g'(x)}-\dfrac32 \left( \dfrac{f''(g(x))\cdot (g'(x))^2+f'(g(x))\cdot g''(x)}{f'(g(x))\cdot g'(x)}\right)^2 =\\
&= \dfrac{f'''(g(x))}{f'(g(x))}(g'(x))^2+3\dfrac{f''(g(x))}{f'(g(x))}g''(x)+\dfrac{g'''(x)}{g'(x)}-\dfrac32 \left( \left( \dfrac{f''(g(x))}{f'(g(x))}\right)^2(g'(x))^2+2\dfrac{f''(g(x))}{f'(g(x))}g''(x)+\left( \dfrac{g''(x)}{g'(x)}\right)^2\right)=\\
&= \left( \dfrac{f'''(g(x))}{f'(g(x))}-\dfrac32 \left( \dfrac{f''(g(x))}{f'(g(x))}\right) \right) (g'(x))^2+\left( \dfrac{g'''(x)}{g'(x)}-\dfrac32 \left( \dfrac{g''(x)}{g'(x)}\right)^2 \right) =[\mathscr{D}f\circ g]\cdot (g')^2+\mathscr{D}g
\end{align*} (b) Show that if $f(x)=\dfrac{ax+b}{cx+d}$ , with $ad-bc\neq 0$ , then $\mathscr{D}f=0$ . Therefore, $\mathscr{D}(f\circ g)=\mathscr{D}g$ . My solution: $f(x)=\dfrac{ax+b}{cx+d}$ , where $ad-bc\neq 0$ . We have $f(x)=\dfrac{a}{c}-\dfrac{ad-bc}{c(cx+d)}$ . We can find $f'$ , $f''$ , and $f'''$ : $$f'(x)=\dfrac{ad-bc}{(cx+d)^2}$$ $$f''(x)=-2c\cdot \dfrac{ad-bc}{(cx+d)^3}$$ $$f'''(x)=6c^2\cdot \dfrac{ad-bc}{(cx+d)^4}$$ Then we have $\dfrac{f'''(x)}{f'(x)}=\dfrac{6c^2}{(cx+d)^2}$ and $\dfrac{f''(x)}{f'(x)}=-\dfrac{2c}{cx+d}$ . $$\mathscr{D}f(x)=\dfrac{f'''(x)}{f'(x)}-\dfrac32\left( \dfrac{f''(x)}{f'(x)}\right)^2 =\dfrac{6c^2}{(cx+d)^2}-\dfrac32\dfrac{4c^2}{(cx+d)^2}=0$$ Therefore, $\mathscr{D}(f\circ g)=[\mathscr{D}f\circ g]\cdot (g')^2+\mathscr{D}g=0\cdot (g')^2+\mathscr{D}g=\mathscr{D}g$ . Is my solution correct? Anything to improve or comment on?","['differential', 'calculus', 'derivatives', 'real-analysis']"
4100516,Fuction whose gradient is of constant norm on its level sets,"I have a function $f:\mathbb{R}^N \to \mathbb{R}$ and I know that on its level sets $f^{-1}(z)$ the norm of its gradient is constant. What can I say about this function? $$
||\nabla_x f(x)|| = \text{const} \qquad \qquad \forall x \in f^{-1}(z) := \left\{x \in \mathbb{R}^N \, :\, f(x) = z\right\} \qquad \forall \in \mathbb{R}
$$ Related questions are this and this . However, they consider the norm of the gradient to be constant for every $x$ in the domain. I know that this is true only on each level set.","['riemannian-geometry', 'ordinary-differential-equations', 'real-analysis', 'multivariable-calculus', 'differential-geometry']"
4100599,Help with China TST 2011 geometry problem:,"(China TST 2011) Let $\Gamma$ be the circumcircle of a triangle $ABC$ . Assume $AA', BB',CC'$ are diameters of $\Gamma$ . Let $P$ be a point inside $\triangle ABC$ and let $D, E, F$ be the feet from $P$ to $BC, CA, AB$ . Let $X$ be the reflection of $A'$ across $D$ ; define $Y$ and $Z$ similarly. Prove that $\triangle XYZ\sim\triangle ABC$ . I found this problem and tried to use complex numbers to solve it, but every time it failed. Can someone please tell me what is wrong with my computations? First, I defined $\Gamma$ to be the unit circle. Then, its easy to notice that $a' = - a$ , $b' = -b$ and $c' = -c$ ( Since zero is the midpoint, and thus $\frac{1}{2} (a + a') = 0 \implies a' = -a$ ). As $D$ is the midpoint of $A'$ and $X$ , we have $d = \frac12(x + a') = \frac12(x - a) \implies x = 2d + a$ . Similarly, $y = 2e + b$ and $z = 2f + c$ . Now the only thing left is to express $d$ , $e$ and $f$ in therms of $p$ . As $A$ , $B$ and $C$ lie on the unit circle, we can use the formula: ""given $T$ and $S$ on the unit circle and a point $H$ , then the foot from $H$ to $TS$ is: $$\frac12( t + s + h - ts\bar{h})$$ where $\bar{h}$ is the conjugate of $h$ "" And thus \begin{align*}
x &= 2d + a = a + b + c + p - bc\bar{p},\\
y &= a + b + c + p - ca\bar{p}\\
z &= a + b + c + p - ab\bar{p}
\end{align*} For the triangles to similar, we must have $(c - a)/(b - a) = (z - x)/(y - x)$ , but $$
\frac{z - x}{y - x} = \frac{\bar{p}b( c - a)}{\bar{p}c(b - a)} = \frac{b(c - a)}{c (b - a)}
$$ This means: $(c - a)/(b - a) = (b(c - a))/(c(b - a)) \implies b = c$ , which is a lie.","['contest-math', 'geometry', 'complex-numbers']"
4100608,Converting polar unit vectors to Cartesian,"As far as I am aware, converting unit vectors from Cartesian to polar coordinates works as follows Express the transformation rules $$ x = r \cos \theta \\ y = r \sin \theta $$ Express the position vector in Cartesian coordinates $$ \vec{r} = x \vec{e}_x + y \vec{e}_y $$ Write the components of the position vector in polar coordinates $$ \vec{r} = r \cos \theta \vec{e}_x + r \sin \theta \vec{e}_y $$ The unit vectors in polar coordinates will be $$ \vec{e}_r = \frac{ \frac{\partial \vec{r}}{\partial r} }{\left| \frac{\partial \vec{r}}{\partial r} \right| } = \cos \theta \vec{e}_x + \sin \theta \vec{e}_y; \qquad \vec{e}_\theta = \frac{ \frac{\partial \vec{r}}{\partial \theta} }{\left| \frac{\partial \vec{r}}{\partial \theta} \right| } = -\sin \theta \vec{e}_x + \cos \theta \vec{e}_y $$ I'd say I'm quite confident about this transformation rule as it agrees with all the sources I can find on this topic. This makes me believe that the steps in the derivation are good and consistent. I am trying to do the same thing backwards, eg. start from polar coordinates and transform the unit vectors back to Cartesian. I've attempted the following steps, quite analogous to the ones above Express the transformation rules (with being aware of the limitation of $\tan^{-1}$ ) $$ r = \sqrt{x^2 + y^2} \\ \theta = \tan^{-1} (y/x) $$ Express the position vector in polar coordinates $$ \vec{r} = r \vec{e}_r $$ Write the components of the position vector in polar coordinates $$ \vec{r} = \sqrt{x^2+y^2} \vec{e}_r $$ The unit vectors in Cartesian coordinates will be $$ \vec{e}_x = \frac{ \frac{\partial \vec{r}}{\partial x} }{\left| \frac{\partial \vec{r}}{\partial x} \right| } =  \vec{e}_r ; \qquad \vec{e}_y = \frac{ \frac{\partial \vec{r}}{\partial y} }{\left| \frac{\partial \vec{r}}{\partial y} \right| } =  \vec{e}_r $$ Here I am pretty sure that my result is incorrect, seeing that I am getting the same exact vector for both $x$ and $y$ unit vectors, which makes no sense to me. However, I think I am faithfully following the necessary steps, and I don't think I've made a miscalculation anywhere. This makes me believe that there's a conceptual mistake somewhere. Could someone kindly point out to me what I did wrong, and how to do it correctly?","['multivariable-calculus', 'vector-spaces', 'real-analysis']"
4100666,Refinement of an infinite chain,"This might sound like a very trivial question.
Given an infinite chain of subsets indexed by ordinals $\lambda \leq \mu$ : $$X_\mu\subseteq ...\subseteq X_\lambda\subseteq...X_1\subseteq X_0$$ where $\mu$ is any ordinal. Is it possible to get a refinement where all the inclusions are strict (where only the repeated subsets are gone)? This is, is it possible to get a second chain $$X_{\mu'}\subsetneq ...\subsetneq X_{\lambda'}\subsetneq...X_1\subsetneq X_0$$ where for any $X_i$ in the first chain there exists a $X_{i'}$ in the second chain where $X_i=X_{i'}$ ? I know that $\mu'$ will be smaller than $\mu$ , and that even the cardinal of $\mu$ and $\mu'$ might be different. My way to do this is the following.
I start with $X_0$ if $X_0=X_1$ then I remove $X_1$ . If $X_0=X_2$ then I remove $X_2$ and so on. If $X_1\not= X_\lambda$ for some $\lambda$ then I move to $\lambda$ and start again the process. I believe that this works because all the indexes are ordinals and thus have a successor. But I am not very confident working with infinite chains and I might be doing something wrong.","['elementary-set-theory', 'order-theory', 'ordinals']"
4100669,Ask the detail of Neyman-Pearson Lemma (Necessity Part),"This is Theorem 8.3.12 (Neyman-Pearson Lemma) in George Casella stat inference. Consider testing $H_0: \theta=\theta_0$ versus $H_1: \theta=\theta_1$ , where the pdf pr pmf corresponding to $\theta_i$ is $f(\textbf{x}|\theta_i),i=0,1.$ , using a test with rejection region R that satisfies (8.3.1) \begin{align}
\begin{matrix}
x\in R & \text{if}& f(\textbf{x}|\theta_1)>kf(\textbf{x}|\theta_0)\\
x\in R^c & \text{if} & f(\textbf{x}|\theta_1)<kf(\textbf{x}|\theta_0)
\end{matrix}\tag{8.3.1}\label{8.3.1}
\end{align} for some $k \geq 0$ , and \begin{align}
\alpha=P_{\theta_0}(\textbf{x}\in R)\tag{8.3.2}\label{8.3.2}
\end{align} Then (Sufficiency): Any test that satisfies the above is a UMP level $\alpha$ test. (Necessity): If there exists a test satisfying (8.3.1) and (8.3.2) with k >0, then every UMP level $\alpha$ test is a size $\alpha$ test (satisfies (8.3.2)) and every UMP level $\alpha$ test satisfies (8.3.1) except perhaps on a set A satisfying $P_{\theta_0}(\textbf{x}\in A)=P_{\theta_1}(\textbf{x}\in A)=0.$ I feel difficulty to understand this Necessity. In the proof, it is clear that any test satisfying (8.3.2) is a  size $\alpha$ test. So I don't know why in the Necessity part, we say it again: If there exists a test satisfying (8.3.1) and (8.3.2) with k >0, then
every UMP level $\alpha$ test is a size $\alpha$ test (satisfies
(8.3.2)) . And the expressions are different. It says we need to satisfy (8.3.1) and (8.3.2). But don't the truth be we only need to satisfy (8.3.2)?","['statistical-inference', 'statistics', 'probability']"
4100710,$E[|X-\mu|^n] \le 2 E[|X-\mu|^{n+1}]$ for Integer Random Variables,"I would like to prove the following moment inequality for all integer random variables ( $X\in\mathbb Z$ ) for which the $n+1$ th moment is defined: $$\mathrm{E}[|X-\mu|^n] \le 2 \mathrm E[|X-\mu|^{n+1}].$$ ( $n\ge1$ , but probably doesn't have to be an integer.)
The constant, 2, can't be improved, since it is sharp for the Bernoulli distribution uniform over $\{0,1\}$ . We can assume $\mu=\mathrm E[X]\in[0,1/2]$ by shifting.
I know how to show that at least $\mathrm{E}[|X-\mu|^n] \le C \mathrm E[|X-\mu|^{n+1}]$ for some constant $C>0$ , but I wonder how I might get the exact value 2.",['probability']
4100753,Representing $\mathbb{C} P^3$ as $Sp(2) / (SU(2)U(1))$?,"I have a question regarding some representations of the three-dimensional complex projective space $\mathbb{C} P^3$ . I am reading the article 'Homogeneous Nearly Kähler manifolds' by Jean-Baptiste Butruille. In it, he claims that $\mathbb{C} P^3 = G/H$ , where $G = Sp(2)$ and $H = SU(2)U(1)$ . Question: I was wondering: what does $SU(2)U(1)$ mean? What group is it? It is clearly not the Cartesian product $SU(2) \times U(1)$ (for it is not a typo in the article). Also, he writes the homogeneous space $\mathbb{C} P^3 \cong Sp(2)/ U(1)Sp(1)$ . Again, I don't understand what the denominator means.","['homogeneous-spaces', 'differential-geometry']"
4100790,Do lower Riemann sums form a connected set?,"Let $f:[a, b] \rightarrow \mathbb{R}$ be a bounded function. The usual way of defining the Riemann integral is to take lower sums and upper sums of partitions of $[a, b]$ and going from there. However, I stumbled upon the following question: The lower sums form a bounded set, since it is bounded from above by any upper sum and bounded from below by $C(b-a)$ , where $C$ is a lower bound for $f$ on $[a, b]$ . Is this set connected? In other words, given any real number $c$ between the bounds of the lower sum, can you take a partition $P$ such that the lower sum of $f$ with respect to $P$ is $c$ ? My intuition tells me that this would hold for a continuous function, but I couldn't even prove it for the identity function on $[0, 1]$ . Is my intuition correct? If it is, can we relax any conditions on $f$ ? I would really like to work on this myself, so any hints would be appreciated.","['riemann-sum', 'connectedness', 'real-analysis']"
4100804,Cauchy-Riemann equations: Meromorphic Function,"A meromorphic function is a function that is holomorphic on all domain except for a set of isolated points. I know that a holomorphic function, by definition, satisfies the Cauchy-Riemann equations but I can't understand if the meromorphic function satisfies the Cauchy-Riemann equations. Can we restrict meromorphic function to the holomorphic part so it satisfies the Cauchy-Riemann equations? Or due to the set of isolated points the meromorphic function doesn't satisfies the Cauchy-Riemann equations? Thank you very much for your help!","['complex-analysis', 'meromorphic-functions']"
4100835,About the proof of Proposition 6.45 on Ziller's notes,"I'm currently going through W. Ziller's notes on symmetric spaces, and I've come across one argument he makes which I can't seem to wrap my head around. Suppose $(G,K)$ is a symmetric pair of the noncompact type with Cartan decomposition $\mathfrak{g}=\mathfrak{k}\oplus\mathfrak{p}$ (that is, the Killing form $B$ is negative definite in $\mathfrak{p}$ ). I wish to prove that $K$ is a maximal compact subgroup of $G$ . I'll briefly describe Ziller's proof as follows: given that $f\colon \mathfrak{p}\times K\to G$ , $f(X,g)=\operatorname{Exp}(X)g$ is a diffeomorphism, where $\operatorname{Exp}$ stands for the Lie exponential map, we suppose a compact subgroup $K\subseteq L\subseteq G$ . Since $L$ is compact, we can define an inner product over $\mathfrak{g}$ such that for every $X\in \mathfrak{l}=\operatorname{Lie}(L)$ , $\operatorname{ad}_{X}$ is skew-symmetric. This implies that $B|_{\mathfrak{l}}$ is negative semidefinite, and in reality it is negative definite, since its kernel is $\mathfrak{z}(\mathfrak{g})\cap\mathfrak{l}=0$ . Because of this, we must have $\mathfrak{k}=\mathfrak{l}$ , so that $K=L^{0}$ , the identity component of $L$ (hence, $K$ is normal in $L$ ). Therefore, $L/K$ is a $0$ -dimensional compact Lie group (that is, a finite group). Now the part that I don't understand Take a nontrivial element $gK\in L/K$ , which corresponds to some $g\in L\setminus K$ . Since $f$ is a diffeomorphism, we can write $g=\operatorname{Exp}(X)y$ for some uniquely determined $X\in \mathfrak{p}$ , $y\in K$ . Then, since $L/K$ is finite, we get that for some $n>0$ , $g^{n}=\operatorname{Exp}(nX)y'\in K$ , so that $\operatorname{Exp}(nX)y'=\operatorname{Exp}(0)z$ for $z\in K$ , contradicting that $f$ is injective. Here is my question: how can we be sure that $g^{n}$ admits an expression as above? Since elements of $G$ don't commute, it doesn't seem obvious to me that we can make such a claim. Thank you in advance!","['symmetric-spaces', 'differential-geometry']"
4100837,Minlos-Sazanov theorem on Banach Spaces,"Let $H$ be a separable Hilbert space and $\phi: H \rightarrow \mathbb{C}$ be a positive definite complex-valued continuous functional. Then the Minlos-Sazanov theorem asserts that the following are equivalent: $\phi$ is the Fourier transform of a finite Borel measure on $H$ there is a symmetric trace class linear operator s.t. $\phi$ is continuous w.r.t. the norm $\Vert x \Vert := \sqrt{\langle Sx, x \rangle}$ for every $x \in H$ . It is a generalization of the classical Bochner theorem for the Fourier transform of finite Borel measures on $\mathbb{R}^n$ . I am looking for some similar characterization in the case where $H$ is just Banach and not Hilbert, or even whether anything can be said in that case.","['measure-theory', 'fourier-analysis', 'reference-request']"
4100884,Complex $ \sqrt[n]{\cdot} $,"Define $ b^{z}:=e^{\log\left(b\right)\cdot z} $ , as a function of 2 complex variables $ (b,z) \in D(1,1)\times \mathbb{C} $ Where $log $ here is defined only on the disk $ D(1,1) $ and given by $$ \log\left(z\right)=\sum_{k=1}^{\infty}\frac{\left(-1\right)^{k+1}}{k}\left(z-1\right)^{k} $$ Now, given a positive integer $ n $ , I want to prove that there exist a unique function $ f=\sqrt[n]{\cdot}:D\left(1,1\right)\to D\left(1,1\right) $ such that $$ \left(f\left(z\right)\right)^{n}=z,\thinspace\thinspace\thinspace and\thinspace\thinspace\thinspace\thinspace\thinspace f\left(1\right)=1 $$ Here's what I have tried: Define $$ f\left(z\right)=e^{\frac{1}{n}\log\left(z\right)} $$ This will be our function. And indeed $ f\left(1\right)=e^{\frac{1}{n}\sum_{k=1}^{\infty}\frac{\left(-1\right)^{k}}{k}\left(1-1\right)^{k}}=e^0=1 $ Next, I want to prove that indeed $(f(z))^n=z$ . But Im not sure why would it even be true. Those are the steps Im not sure about: $ \left(f\left(z\right)\right)^{n}=\left(e^{\frac{1}{n}\log\left(z\right)}\right)^{n}\underset{?}{=}e^{\frac{n}{n}\log\left(z\right)}\underset{?}{=}z $ This power rule is true in this complex case? also, I know in general $ e^{\log\left(z\right)}\neq z $ , but in this particular case where we defined $ log $ as the power series over the disk $(1,1) $ , is it true? If indeed those steps are true, how can I show that this function is unique? Thanks in advance, any help would be appreciated.",['complex-analysis']
4100941,The logarithmic form of $\text{arcsin}(x)$ and its implications,"Background I recently set out to derive the exponential forms of the inverse trigonemtric functions using eulers identity and demoivres theorem, deciding to start with $arcsin(x)$ I first got that: $$e^{ix}=\cos(x)+i\sin(x) \implies e^{-ix}=\cos(x)- i\sin(x) $$ $$\therefore \sin(x)=\frac{e^{ix}-e^{-ix}}{2i}$$ Deriving arcsin(x) Letting $\sin(x)=y$ $$y=\frac{e^{ix}-e^{-ix}}{2i} \implies 2iye^{ix}=e^{2ix}-1$$ $$\implies e^{2ix}-2iye^{ix}-1=0$$ Completing the square; $$(e^{ix}-iy)^2=1-y^2 \implies e^{ix}=iy \space ± \space \sqrt{1-y^2}$$ Then by taking the natural log and noting that it exists only for positive non zero numbers; $$x=\frac{\ln(iy + \sqrt{1-y^2})}{i} $$ $$\therefore \text{arcsin}(x)= \frac{\ln(ix + \sqrt{1-x^2})}{i}$$ The more I studied this the more it became apparent that if I were to rewrite the complex number within the natural log in its exponential form then would it not be true that: $$\text{arcsin}(x)=\frac{(i)(\text{arg}(ix + \sqrt{1-x^2})}{i}$$ $$\therefore  \text{arcsin}(x)=\text{arg}(ix + \sqrt{1-x^2})$$ Deriving arctan(x) I am extremely fascinated by the fact that to find the $arcsin$ of some value, you merely have to find the argument of some arbitrary complex number, upon noting this I also derived the $\text{arctan}(x)$ logarithmic form in the same way: $$\text{arctan}(x)= \frac{\ln \left(\frac{2i}{x+i} -1 \right)}{2i}$$ So that I may plug in the value of $\frac{x}{\sqrt{1-x^2}}$ into the expression for $\text{arctan}(x)$ and find the argument. Upon making the same observation as with $arcsin(x)$ I noted that this expression was the same as $$\text{arctan}(x)= \frac{\text{arg} \left(\frac{2i}{x+i} -1 \right)}{2}$$ Questions and query about the implications Again, the fact that finding the $arctan$ or $arcsim$ of a value is the same as finding the argument of seemingly arbitrary complex numbers seems extremely interesting to me and I cant wait to find out more about this and what exactly these complex numbers in question represent. However I have not been able to find any satisfactory answers during my searching and so my question is, what do the complex numbers $ix + \sqrt{1-x^2}$ and $\frac{2i}{x+i} -1$ represent, and why do their respective arguments give values for the inverse trigonometric functions in question?","['trigonometry', 'inverse-function', 'complex-numbers']"
4100962,L2 boundness of Integral Operator,"If we have the kernel $k(x,y)=\frac{x}{(y-x)^2}$ for $(x,y)\in(0,\infty)\times(-\infty,0)$ , my question is: is this operator $$Tf(x)=\int_{-\infty}^{0}k(x,y)f(y)dy$$ bounded in $L^2(\mathbb{R}^{+})$ ? In other words: $$\int_{0}^{\infty}\left|Tf(x)\right|^2dx< C ||f||_{L^2(\mathbb{R}^{+})}$$ for some $C>0$ ? I tried to see if $k\in L^2(\mathbb{R}^2)$ , but it seems not to be true. Not all the singular integrals have integrable kernel, but I don't know how to follow at this point. Maybe it could be related to the derivative of the Hilbert transform, but I have an "" $x$ "" in the numerator anyways. Thank you in advance!","['functional-analysis', 'analysis']"
4100969,Question on compactification of a space.,"Let $X$ be a compact Hausdorff space and $A \subseteq X$ be closed. Then show that one point compactification of $X \setminus A$ is homeomorphic to $X / A.$ $\textbf {My attempt} :$ What we know is that one point compactification of $X \setminus A$ is nothing but the space $Y = (X \setminus A) \cup \{\infty\}$ equipped with the topology $\tau_Y = \tau_1 \cup \tau_2,$ where $\tau_1$ is the topology on $X \setminus A$ and $\tau_2$ is given by $$\tau_2 : = \{Y \setminus C\ |\ C \subseteq X \setminus A\ \text {is compact} \}.$$ It is clear that as a set $X / A$ and $Y$ are in a bijective correspondence. There are obvious natural embeddings of $X \setminus A$ into the spaces $X / A$ and $Y$ and it is clear that both the spaces can be obtained by adjoining one single point to $X \setminus A$ (when viewed in terms of the embeddings). So in order to prove $Y$ is homeomorphic to $X/A$ it is enough to show that $X/A$ is compact and Hausdorff. Compactness of $X/A$ is clear as it is the image of the compact set $X$ under the quotient map $p : X \longrightarrow X/A.$ Also since $X$ is compact and Hausdorff it is normal and hence regular in particular and since $A \subseteq X$ is closed it follows that $X / A$ is Hausdorff. This proves the result. Would anybody please have a look at my solution and check whether it holds good or not? Thanks for reading.","['quotient-spaces', 'general-topology', 'solution-verification', 'compactness']"
4101028,Are the convex open balls always a base?,"Let $(X, d)$ be a metric space. I define a set $\mathcal{U} \subseteq X$ to be convex if for all $x,z \in \mathcal{U}$ and $y \in X$ we have $$d(x,y) + d(y,z) = d(x,z) \implies y \in \mathcal{U}$$ An open ball in $(X, d)$ may not be convex and an example of this is a ball in $S^1$ (equipped with the ""shortest arc length"" metric) with a radius greater than $\frac{\pi}{2}$ . Nevertheless, the convex open balls in $S^1$ are a base for the topology induced by the metric. Are the convex open balls in $(X,d)$ always a base for the topology induced by $d$ ? These questions/answers may be relevant: Examples for geodesic balls which are not convex Are small $\varepsilon$ -balls convex in geodesic metric spaces But I am not sure whether the notion of convexity in use is equivalent.","['general-topology', 'metric-spaces']"
4101047,Evaluate $\int_{0}^{\infty} \frac{\tan^{-1}x^2}{x^2(x^4-1)}-\frac{\pi}{4(x^4-1)}\>dx$,"How to Integrate $$  I = \int_{0}^{\infty} \frac{\tan^{-1}x^2}{x^2(x^4-1)}-\frac{\pi}{4(x^4-1)} \>dx\approx -0.295512 $$ Mathematica returns a result that does not match numerically with the integral approximation : $$ \frac{i C}{4} -\frac{\pi}{4}\sqrt{4-3i} +\frac{3 \pi^2}{32} +\pi\left(\frac{1}{4}-\frac{i}{8}\right)\coth^{-1}(\sqrt{2}) \approx -0.048576 + 0.43823\,i $$ Where C denotes Catalan's Constant Motivation I was able to find a closed form for $$ \int_{0}^{1} \frac{\tan^{-1}(x^2)}{x^2(x^4-1)}-\frac{\pi}{4(x^4-1)}dx $$ using double infinite sums. Upon plotting the function within the integral i saw that it could be integrated from $0$ to ${\infty}$ . Attempts Number 1 I tried to Split the integral as $$ \int_{0}^{1} \frac{\tan^{-1}(x^2)}{x^2(x^4-1)}-\frac{\pi}{4(x^4-1)}dx + \int_{1}^{\infty} \frac{\tan^{-1}(x^2)}{x^2(x^4-1)}-\frac{\pi}{4(x^4-1)}dx $$ and use the Taylor Series for $\tan^{-1}(x^2) $ when $|x| >1$ Number 2 I tried using partial fractions as $$ \frac{1}{x^4-1} = \frac{1}{4(x-1)} - \frac{1}{4(x+1)} -\frac{1}{2(x^2+1)} $$ $$ \frac{1}{x^2(x^4-1)} = \frac{1}{2(x^2+1)}-\frac{1}{x^2}-\frac{1}{4(x+1)} + \frac{1}{4(x-1)} $$ from which I obtained $$\int_{0}^{\infty} \frac{\tan^{-1}(x^2)}{2(x^2+1)}dx = \frac{\pi^2}{16} $$ $$ \int_{0}^{\infty} \frac{\pi}{8(x^2+1)} dx= \frac{\pi^2}{8} $$ but was unable to proceed further. Number 3 A number of basic integration techniques such as U-Sub and Integration by parts. Number 4 Using the same technique i used to evaluate the same integral but from $0$ to $1$ I will continue to try , but for now I find myself to be stuck. Q - Is there a closed form for I? If the solution is easy and i am missing something , could you provide hints instead? Thank you for your help and time.","['integration', 'improper-integrals', 'sequences-and-series']"
4101068,Covariance Matrix of two random variables,Can two random variables $X$ and $Y$ have the covariance matrix $\begin{pmatrix} 0 & -1 \\ -1 & 0 \end{pmatrix}? $ The matrix is positive definite if $xy<0$ . Does this imply that it could be the convariance matrix for some $X$ and $Y$ ?,"['statistics', 'covariance', 'probability', 'random-variables']"
4101083,"$H^1(\text{Gal}(\bar{k}/k),B(\bar{k}))$ finite for linear algebraic groups $B$ and fields $k$ with Serre's property $(F)$.","New poster, apologies if the formatting/conventions are incorrect. I am reading Serre's book Galois Cohomology. My question is about exactly how Serre's inductive principle (chapter 1 prop. 39 cor. 3) is used in chapter 3, Section 4.3 Theorem 4 which says for fields $k$ with property $(F)$ and linear algebraic groups $B$ defined over $k$ , $H^1(k,B)$ is finite. Fixing notation and rewriting chapter 1 prop. 39 cor. 3: Let $k$ be a field and $\bar{k}$ be it's separable closure. By $H^1(k,G)$ I mean $H^1(\text{Gal}(\bar{k}/k),G(\bar{k}))$ where $G(\bar{k})$ are the $\bar{k}$ points of an algebraic group $G$ with an action of $\text{Gal}(\bar{k}/k)$ (this is usually the usual Galois action).  Let $$1 \to A \to B \to C \to 1$$ be an exact sequence of algebraic groups defined over $k$ each with an action of $\text{Gal}(\bar{k}/k)$ . This induces a long exact sequence in cohomology: $$1 \to A^{\text{Gal}(\bar{k}/k)} \to B^{\text{Gal}(\bar{k}/k)} \to C^{\text{Gal}(\bar{k}/k)} \to H^1(k,A) \to H^1(k,B) \to H^1(k,C)$$ Here is Corollary 3 to Proposition 39 in Chapter 1: In order that $H^1(k,B)$ be countable (resp. finite, resp. reduced to a single element), it is necessary and sufficient that the same be true for its image in $H^1(k,C)$ , and for all the quotients $H^1(k,bA)/(bC)^{\text{Gal}(\bar{k}/k)}$ ,for $b \in Z^1(k,B)$ . The proof of the finiteness of $H^1(k,B)$ for $k$ with property $(F)$ goes roughly as follows: The above corollary is used to reduce to the case where $B$ is connected. Then the corollary is again applied to a composition series for $B$ dealing with various terms in cases. I do not see how the reduction to the connected case takes place. Let $B_0$ be the connected component of $B$ . Then $B/B_0$ is finite. To reduce to the connected case, Serre applies the corollary to the short exact sequence $$1 \to B_0 \to B \to B/B_0 \to 1.$$ For $H^1(k,B)$ to be finite, it is sufficient that $H^1(k,B/B_0)$ be finite (This is true since $B/B_0$ is finite and $k$ has condition (F), see prop 8. ch 4.) and $H^1(k,bB_0)$ be finite for all $b \in Z^1(k,B)$ . Clearly, twisting by the trivial cocycle $b = e$ reduces to the connected case i.e. showing that $H^1(k, B_0)$ is finite. For nontrivial cocycles $b$ I see that $bB_0$ is still the same group as $B_0$ (and hence connected) but it is equipped with a different action of $\text{Gal}(\bar{k}/k)$ . I am confused because I think the text is implying that we can reduce to the case of showing that $H^1(k,B)$ is finite where $B$ is connected and $B$ has the usual (i.e. not twisted) Galois action of $\text{Gal}(\bar{k}/k)$ . I think that one way to possibly answer this is that $H^1(k, bB_0)$ is isomorphic as a pointed set to $H^1(k, bE)$ where $bE$ is a $k$ -form of $B_0$ associated to $b$ and where $H^1(k, bE)$ makes use of the usual Galois action of $\text{Gal}(\bar{k}/k)$ on $bE(\bar{k})$ . Should it be clear that $k$ -forms of a connected group $B_0$ need to be connected? Are the twists $bB_0$ of $B_0$ by $b \in Z^1(k,B)$ being considered as the connected group $B_0$ with a twisted action of $\text{Gal}(\bar{k}/k)$ or is there some way to see that $H^1(k, bB_0)$ is isomorphic as a pointed set to $H^1(k, bE)$ where $bE$ is some connected linear algebraic group over $k$ with the usual Galois action of $\text{Gal}(\bar{k}/k)$ ?","['algebraic-geometry', 'galois-cohomology']"
4101139,Volume bounded by the surface $x^n + y^n + z^n = a^n$,"Calculate the volume bounded by the surface $x^n + y^n + z^n = a^n$ $(x>0,y>0,z>0)$ . $$\iiint\limits_{x^n+y^n+z^n \le a^n \\ \ \ \ \ \ \ x,y,z > 0}\mathrm dx~ \mathrm dy ~\mathrm dz = \begin{bmatrix}x = r\cos\varphi\sin\psi \\ y = r\sin\varphi \sin\psi \\ z = r\cos\psi\end{bmatrix} = \iiint\limits_{r^n \le a^n} \underbrace{r^2 \sin \psi}_{J} ~\mathrm d\varphi ~\mathrm d\psi ~\mathrm dr =\\= \int_0^a r^2\mathrm dr \int_0^{\pi/2}\mathrm d\varphi \int_0^{\pi/2}\sin\psi~ \mathrm d\psi$$ Am I going right? I'm not sure about the bounds of the last three integrals. For even $n$ the graph looks like the following: For odd $n$ the first quadrant is alike.","['integration', 'volume', 'multivariable-calculus', 'calculus', 'multiple-integral']"
4101140,How do you go from an ODE to a Lagrangian?,"I know that given a Lagrangian, $L(t,x,v)$ you can write the Euler Lagrange equation $$L_x-\frac{d}{dt}L_v=0, \tag{1}$$ to minimize the functional $$\int_0^TL(t,x,v)dt.\tag{2}$$ I'm interested in the reverse direction - given an ODE say something like $$y''+f(t)y'+g(t)y+h(t)=0.\tag{3}$$ how can you find $L$ ?","['ordinary-differential-equations', 'euler-lagrange-equation']"
4101200,A $3\times3$ triangular matrix has a repeated eigenvalue if it is the square of a non-triangular matrix,"After pondering for an interesting answer to a recently asked question , I discovered the following phenomenon. Suppose $A$ is a $3\times3$ matrix whose elements are taken from some field. If $A$ is not upper triangular but $B:=A^2$ is upper triangular, then $B$ has a repeated eigenvalue. Here is a proof outline. Let $A=\pmatrix{a&b&c\\ p&q&r\\ x&y&z}$ . Since $A$ is not upper triangular, $(p,x,y)\ne(0,0,0)$ . The condition that $A^2$ is upper triangular is equivalent to the set of conditions \begin{align}
ap+pq+rx&=0,\tag{1}\\
ax+py+xz&=0,\tag{2}\\
bx+qy+yz&=0.\tag{3}
\end{align} Suppose both $p$ and $x$ are nonzero. Then $(1)$ and $(3)$ give \begin{equation}
\frac{(ap+pq+rx)(a+z)}{p} + \frac{(bx+qy+yz)p}{x} = 0.\tag{4}
\end{equation} Substitute $(2)$ into $(4)$ , we obtain $a^2+bp=yr+z^2$ . Hence $B_{11}=B_{33}$ in this case. The other cases where $(p,x,y)$ is $(=0,=0,\ne0),(=0,\ne0,\ne0),\ldots$ etc. can be handled by similar or simpler algebraic manipulations of $(1)-(3)$ , and other equalities between the diagonal elements of $B$ (i.e. $B_{11}=B_{22}$ or $B_{22}=B_{33}$ ) may occur in these cases. However, this proof feels ugly because it uses coordinates too heavily and it has to consider different corner cases separately. Admittedly, proofs of the statement in question probably cannot be entirely coordinate-free, because the assumption that "" $A$ is not triangular"" is already basis dependent, but I still want to see a more conceptual proof that isn't just a series of algebraic manipulations. Any idea? P.S. Since the analogous statement also holds when $A$ is $2\times2$ , I also wonder if it is true for all sizes of $A$ .","['matrices', 'linear-algebra']"
4101231,"Is there an abstract definition of a matrix being ""upper triangular""?","Another question brought this up.  The only definition I have ever seen for a matrix being upper triangular is, written in component forms, ""all the components below the main diagonal are zero.""  But of course that property is basis dependent.  It is not preserved under change of basis. Yet it doesn't seem as if it would be purely arbitrary because the product of upper triangular matrices is upper triangular, and so forth.  It has closure.  Is there some other sort of transformation besides a basis transformation that might be relevant here?  It seems as if a set of matrices having this property should have some sort of invariants. Is there some sort of isomorphism between the sets of upper triangular matrices in different bases?","['matrices', 'triangularization', 'change-of-basis', 'linear-algebra']"
4101273,Reductive group terminology questions [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question $\DeclareMathOperator{\Hom}{Hom}$ $\newcommand{\g}{\mathfrak{g}}$ I am a beginner in the subject of reductive groups and I am hoping someone might be able to walk me through some basic terminology. This is not homework so any and all remarks, even those not directly related to what I ask, are helpful. In some sense I am asking many questions, so if moderators wish that I ask separate questions, I will of course do so instead. But I view all of these as trivially tied together and I think it will be easy for someone knowledgeable to answer them all rapid-fire. Let $k$ be an algebraically closed field of arbitrary characteristic. Let $G$ be a connected reductive group over $k$ . Let $B=TU$ be a fixed Borel subgroup of $G$ , where $T$ is a torus and $U$ is the unipotent radical of $B$ . Let $X^*(T):=\Hom(T, GL_1)$ be the group of characters or the weight lattice and $X_*(T):=\Hom(GL_1, T)$ be the group of cocharacters or the coweight lattice . Now let $\g$ be the Lie algebra of $G$ . The adjoint representation of $G$ is given by conjugation on $\g$ . A root is a nontrivial weight of $G$ that occurs in the action of $T$ on $\g$ . The choice of $B$ determines a set of positive roots . A positive root that is not the sum of two positive roots is called a simple root .  If everything I have written so far makes sense, then I am pretty good up until here. My questions are the following: What is the meaning of a coroot ? I have been told that there is a pairing between the weight and coweight lattices, and those coweights corresponding to the roots are called coroots. What precisely is this pairing and what is the meaning of ""corresponding to?"" And what would the coroots for, say, $GL_n$ look like (with the standard choices of $B$ and $T$ )? Similar to #2, what is a positive coroot and a simple coroot ? I have some good guesses but I want to be sure. What is a dominant weight and a dominant coweight ? Why would we care about such weight/coweights? Are there only finitely many dominant weights/coweights? Finally, what are the fundamental weights and fundamental coweights ? It seems that these are necessarily dominant, but I am not sure what their precise definition is. Are there only finitely many of these? Any and all hints or remarks that you feel may clarify the situation are of course welcome.","['reductive-groups', 'algebraic-geometry', 'representation-theory', 'algebraic-groups']"
4101304,Identities similar to $\frac{a^3 + b^3 + c^3}{3} \cdot \frac{a^7 + b^7 + c^7}{7} = \left( \frac{a^5 + b^5 + c^5}{5} \right)^2$,"This question was inspired by the post here, which asks for a proof of the following fact: If $a+b+c = 0$ then show that $$\frac{a^3 + b^3 + c^3}{3} \cdot \frac{a^7 + b^7 + c^7}{7} = \left( \frac{a^5 + b^5 + c^5}{5} \right)^2$$ I was curious about finding all exponents for which this works, arriving at the following problem: For which distinct positive integers $m,n$ (with $m+n$ even) is it true that $$\frac{a^m + b^m + c^m}{m} \cdot \frac{a^n + b^n + c^n}{n} = \left( \frac{a^\frac{m+n}{2} + b^\frac{m+n}{2} + c^\frac{m+n}{2}}{(m+n)/2} \right)^2$$ for all $a,b,c$ with $a+b+c = 0$ ? I added the distinctness condition because $m=n$ always trivially works. So far, the only solution I know of is $(3,7)$ , as per the post quoted. A Mathematica search yielded that there are no other solutions with $a,b \leq 100$ . A solution for this problem would of course be really nice, but I don't really have high hopes for one! The shortest proof of the $(3,7)$ case uses Newton's formulas for power sums, which are defined recursively and don't have a nice closed form, as far as I know. So any kind of intuition/heuristic about why there should/shouldn't be any more solutions would also be very interesting. Some progress : I decided to run a much bare-bone simulation in Mathematica, by checking if the identity holds at least for $(a,b,c) = (1,-\frac{1}{2},-\frac{1}{2})$ , and indeed for $m,n \leq 2000$ it only holds for $(m,n) = (3,7)$ . Plugging in, we have $$\frac{1}{mn} \left(1 + \frac{(-1)^m}{2^{m-1}}\right)\left(1 + \frac{(-1)^n}{2^{n-1}}\right) = \frac{4}{(m+n)^2}\left( 1 + \frac{(-1)^\frac{m+n}{2}}{2^{\frac{m+n}{2} - 1}} \right)^2.$$ Thus we can turn the problem into a Diophantine equation, which might make things simpler?","['algebra-precalculus', 'symmetric-polynomials']"
