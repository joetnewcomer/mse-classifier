question_id,title,body,tags
540108,Example of a Non-Abelian Infinite Group,"I was hunting an example of a non-trivial infinite group in which 1) All non-trivial normal subgroup are non-abelian. 2) There exists a nontrivial subnormal abelian subgroup. Is there any hope to find this out? Note In the finite case such an example is not possible (see here ). Notation A subgroup H of a given group G is a subnormal subgroup of G if there is a finite chain of subgroups of the group, each one normal in the next, beginning at H and ending at G.","['group-theory', 'abstract-algebra']"
540125,How to find this integral $I=\int_{-\pi}^{+\pi}\frac{x\sin{x}\arctan{e^x}}{1+\cos^2{x}}dx$?,"Find the integral
$$I=\int_{-\pi}^{+\pi}\dfrac{x\sin{x}\arctan{e^x}}{1+\cos^2{x}}dx$$ My try: 
let
$$I=\int_{-\pi}^{0}\dfrac{x\sin{x}\arctan{e^x}}{1+\cos^2{x}}dx+\int_{0}^{+\pi}\dfrac{x\sin{x}\arctan{e^x}}{1+\cos^2{x}}dx=I_{1}+I_{2}$$ for $I_{2}$,we let $x=-t$",['integration']
540127,"Torsion-freeness of the group $\langle a, b \mid a b^m = ba^n\rangle$","For integers $m$ and $n$ let $K(m,n)$ be the group $\langle a, b \mid a b^m = ba^n\rangle$. Is there a special name for this group? Is there a complete characterization of those pairs $(m,n)$ for which the group is torsion-free? Or bi-orderable (in the sense of Rolfsen: http://www.math.ubc.ca/~rolfsen/papers/luminynotes/lum.pdf )?","['reference-request', 'group-theory']"
540132,Cup product mapping,"$
\newcommand{\OXD}{\mathcal{O}_X(D)}
\newcommand{\OXDD}{\mathcal{O}_X(D')}
$
Let $X$ be a smooth projective curve over $k=\bar{k}$ an effective $D$ a divisor on $X$. Associated to $D$ we have a line bundle $\OXD$, and it turns out that we have
$$ D\sim D' \iff \OXD \cong  \OXDD, $$
where $\sim$ denotes linear equivalence of divisors. For every $D$ we have the cup-product map on the cohomology groups
$$ \mu: H^0(X,\OXD)\otimes H^0(X,K(-D))\to H^0(K) $$
which, if $\OXD = L$, can also be rewritten equivalently as
$$ \mu: H^0(X,L)\otimes H^0(X,K\otimes L^{-1})\to H^0(K). $$
Now we come to my question: I'm reading this book about curves and Brill-Noether theory and, at page $190$, they say that Given a non zero section $s \in H^0(L) $ such that $(s)=D$, the image
  of  $$ s\otimes H^0(X,K\otimes L^{-1})\to H^0(K) $$ under $\mu $ is
  equal to $H^0(X,K(-D))$. Could you help me understanding this claim? I'm confused, especially because I was convinced that $H^0(X,K(-D))$ and $H^0(X,K\otimes L^{-1})$ were the same spaces... but from the above statement it looks like this is not the case.","['sheaf-theory', 'algebraic-geometry', 'algebraic-curves']"
540135,"Is $\mbox{lcm}(a,b,c)=\mbox{lcm}(\mbox{lcm}(a,b),c)$?","$\newcommand{\lcm}{\operatorname{lcm}}$Is $\lcm(a,b,c)=\lcm(\lcm(a,b),c)$? I managed to show thus far, that $a,b,c\mid\lcm(\lcm(a,b),c)$, yet I'm unable to prove, that $\lcm(\lcm(a,b),c)$ is the lowest such number...","['elementary-number-theory', 'divisibility', 'least-common-multiple', 'discrete-mathematics']"
540141,Trigonometry confusion,"I was doing a bit of trigonometry, as I have been for a couple of years and it suddenly dawned on me that I don't really understand the trigonometric functions, at all. You first learn the basic trig functions like this: $$\sin(x) = \dfrac{o}{h}$$ $$\cos(x) = \dfrac{a}{h}$$ $$\tan(x) = \dfrac{o}{a}$$ Where $x$ is an angle and $o,a,h$ are the opposite, adjacent and hypotenuse sides respectively. But I realized that I don't understand what the trig functions really , and especially why in god's name they work. This realization came when I had to sketch the functions $y=\sin^2(x)$ and I was dumbfounded; what exactly am I squaring? And why do the trig functions have a part below the x-axis? Why are they periodic? Is there a way I can easily understand these functions intuitively?","['trigonometry', 'intuition', 'definition']"
540147,preimages of simple functions form a partition,"Let $\varphi $ ba simple, then we know $A_i = \varphi^{-1} (a_i) $ . Claim is $A_i$ paritition $\mathbb{R}$ my try: Note that the sets $A_i = \varphi^{-1} ( \{ a_i \} ) $ form a partition of $\mathbb{R}$. To see this, we show $A_i$ are pairwise disjoint. Suppose that there exists $x \in A_i \cap A_j $ and $i \neq j$. Therefore, we have that $\varphi(x) = a_i = a_j \implies 1_{A_i} = 1_{A_j} $. Hence, by Definition of the indicator function, we must have that $A_i = A_j$. Therefore, $A_i$ are parwise disjoint. In particular $\mathbb{R} = \bigcup_{i=1}^{N} A_i $. Question; Is this correct?","['real-analysis', 'analysis']"
540169,Solve $\int_{0}^{\infty}\frac{\sin^{2}x}{x}\ dx$,"I have this problem $\displaystyle \int_{0}^{\infty}\frac{\sin^{2}x}{x}\ dx$ I think it diverges, but I cannot prove it. (I'm in my first calculus course, so I don't know of any more advanced methods than u-substitution (including trig subs) integration by parts","['calculus', 'integration']"
540186,Convergence of Rademacher's formula: Extending the partition numbers to complex index,"Consider the famous formula of Rademacher (actually Hardy, Ramanujan, and Rademacher): $$p(n) = \frac{1}{\pi \sqrt{2}} \sum_{k=1}^{\infty} \sqrt{k}\ A_k(n)\ F_k'(n)$$
$$A_k(n) = \sum_{0 \le m < k, \gcd(m, k) = 1} e^{i\pi\left(s(m, k) - 2nm/k\right)}$$
$$F_k(x) = \frac{1}{\sqrt{x - \frac{1}{24}}} \sinh\left(\frac{\pi}{k} \sqrt{\frac{2}{3}\left(x - \frac{1}{24}\right)}\right)$$ and $s(m, k)$ is the Dedekind sum given by $$s(m, k) = \sum_{n=1}^{k} \left(\left(\frac{n}{k}\right)\right)\left(\left(\frac{mn}{k}\right)\right)$$ where $((x))$ is the sawtooth function $$((x)) = \begin{cases}
x - \lfloor x \rfloor - \frac{1}{2}, &\mbox{if } x \in \mathbb{R} \setminus \mathbb{Z}\\
0, &\mbox{if }x \in \mathbb{Z}
\end{cases}$$. (see http://en.wikipedia.org/wiki/Partition_%28number_theory%29#Partition_function ) $p(n)$ is the $n$th partition number. But here's the interesting thing: this formula also actually seems to work not just for natural, but real and complex values of $n$ as well! So we could perhaps think of Rademacher's formula as giving an extension of the partition-number function to real and complex indices, much as how the gamma function extends the factorial. Albeit, however, it is complex-valued at real indices. But the question I have is, where does this converge , when the range of $n$ is expanded from $\mathbb{N}$ to $\mathbb{C}$? It seems to converge okay for real values of $n$, and also those for complex $n$ (perhaps should now be called $z$?) with negative imaginary part. But what about with positive imaginary part? The formula is slow, and numerical experiments with $n = 2i$ don't seem to help. It looks like it diverges, but I'm not totally sure. This is a very complicated series formula, and I'm not sure where one would even begin to analyze it to determine the region of convergence.","['complex-analysis', 'number-theory']"
540219,Invariant dimension property on a ring without zero divisors,"The following is exercise number 10 in Hungerford's Algebra, page 190: Let $R$ be a ring with no zero divisors such that for all $r, s \in R$ there exist $a, b \in R$, not both zero, such that $ar + bs = 0$. a) If $R = K \oplus L$ (module direct sum) then $K = 0$ or $L = 0$ b) If $R$ has an identity, then $R$ has the invariant dimension property. I have proved part a), but I'm having difficulty with b). I realize that it suffices to show that $R^m \cong R^n$ implies $m = n$, but I can't seem to use part a) to conclude this.","['ring-theory', 'dimension-theory-algebra', 'abstract-algebra']"
540220,Right adjoint of forgetful functor from Top,"How to prove this? The forgetful functor $U:\mathbf{Top}\to\mathbf{Set}$ has a right adjoint, namely the functor $\mathbf{Set}\to\mathbf{Top}$ which equips a set with the indiscrete topology and left adjoint which equips a set with the discrete topology.","['general-topology', 'category-theory']"
540230,Find all the values of $(1+i)^{(1-i)}$,"The question says to find all the values of $(1+i)^{(1-i)}$ I have trouble figuring out firstly, exactly what values are being looked for. I can toy around with the equation a bit to try to make it look ""acceptable"" (i.e $ax + byi$ format) but get stuck along the way. So I need help with: a) figuring out what values are needed. i.e. what does the question $mean$ and some brief background or diagram that explains, in a practical sense, what I'm supposed to be looking for. b) the algebra that can lead me to a reasonable solution. -- MY ATTEMPT: $$ (1+i)^{(1-i)} = (1+i)^{(1-i)}.\frac{(1+i)^{(1+i)}}{(1+i)^{(1+i)}} = \frac{(1+i)^2}{(1+i)^{(1+i)}} = *$$ *is where I get stuck.","['complex-numbers', 'algebra-precalculus', 'complex-analysis']"
540248,What are sufficient conditions for a matrix to have the same eigenvectors as its exponential?,"If $\boldsymbol{A}$ is a square matrix, then it is straightforward to show that each eigenvector to $\boldsymbol{A}$ is also an eigenvector to $e^\boldsymbol{A}$. On the other hand, an eigenvector to $e^\boldsymbol{A}$ is not necessarily an eigenvector to $\boldsymbol{A}$. For example, the eigenvectors to
$$
\boldsymbol{A}=
\begin{bmatrix}
2\pi i& 0 \\
0 & 4\pi i
\end{bmatrix}
$$
are the scalar multiples of $\begin{bmatrix}1 & 0\end{bmatrix}^T$ and $\begin{bmatrix}0 & 1\end{bmatrix}^T$, while any non-zero vector is an eigenvector to
$$
e^\boldsymbol{A}=
\begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}.
$$ Are there any interesting conditions which guarantee that $\boldsymbol{A}$ and $e^\boldsymbol{A}$ have exactly the same eigenvectors?","['matrices', 'eigenvalues-eigenvectors']"
540269,Proof of divergence of two complex series,"My task is to check, when the following series are convergent:
$$ $$ a) $\sum_{n=1}^{\infty} \frac{(2n)!}{(n!)^2} z^n$
$$ $$
B) $\sum_{n=1}^{\infty} \frac{n!}{n^n} z^n$
$$ $$ where $z$ is a complex number. Ok, in both cases I computed the radius of convegence. In a) I got $R=\frac{1}{4}$ and in b) I got $R=e$. Those answers are correct, as my book says. But I don't know what happens on the boundary, I mean in first case for $z=\frac{1}{4}$ and in the second for $z=e$. Wolfram says that in both cases it diverges, first one from the comparison test (but compare to what?) and the second one because $\lim \frac{n!}{n^n} e^n = \infty$ (Why?). How to prove it? I really tried, got so frustrated, because it should be easy, but I can't prove divergence of those series... Can you help? Edit: after hint with Stirling formula, I've got the second one (b) ). Help still needed in a). Thanks in advance.","['divergent-series', 'limits']"
540295,Integrate $e^{ax}\sin(bx)?$,Is there a general formula for finding the primitive of $$e^{ax}\sin(bx)?$$ I've done this manually with $a=9$ and $b=4$ using Euler's formulas. But it takes a bit of time. Is there a pattern here?,"['calculus', 'integration']"
540302,"The sup norm on $C[0,1]$ is not equivalent to another one, induced by some inner product","Let $\mathrm{C}[0,1]$ be the space of continuous functions $[0,1]\rightarrow \mathbb{R}$ endowed with the norm $||x||_{\infty}=\mathrm{max}_{t\in [0,1]}|x(t)|$. It is easy to verify that this norm is not induced by any inner product (really the parallelogram law fails for $x(t)=t$ and $y(t)=1$). Well, how to understand that this norm is not equivalent to anyone induced by an inner product? So, the norms induced by inner products should have some special properties...","['hilbert-spaces', 'functional-analysis', 'banach-spaces']"
540355,Is there a unique finitely-additive extension of the length function to all real subsets?,"It is known that the length function on closed, finite, real intervals cannot be extended to a $\sigma$-additive measure on $2^\mathbb{R}$ (hence the introduction of the Borel sets). But can it be extended to a finitely-additive measure on $2^\mathbb{R}$? If so, can it be extended uniquely, or at least in a ""natural"" way? EDIT: Thanks to André Nicolas's hint below, i have found the following useful links: A question on this forum An article",['measure-theory']
540358,$T_2$ spaces and isolated points,Is there a topological Hausdorff space with an infinite number of isolated points such that any infinite set of isolated points have an infinite number of limit points !? (Of course it would be impossible if a limit point is a limit of a sequence.),['general-topology']
540361,Derivative (or differential) of symmetric square root of a matrix,"Let A be a square, symmetric, positive-definite matrix.  Let S be its symmetric square root found by a singular value decomposition.  Let vech() be the half-vectorization operator. Is there a convenient expression for the derivative (or differential) of vech(S) with respect to vech(A)? I know the expression for an inverse, which is sort of like a matrix version of the power rule.  Would this approach work for a symmetric square root as well (i.e., (1/2)S^(-1/2))?","['matrices', 'linear-algebra', 'svd', 'derivatives']"
540379,"Does the sequence $1,-1,1,1,-1,1,1,1,-1,1,1,1,1,-1,1,1,1,1,1,-1,\ldots$ have a closed form?","Question : Can we represent the following sequence $\{a_n\}\ (n\ge 0)$ as a closed form?$$a_n : 1,-1,1,1,-1,1,1,1,-1,1,1,1,1,-1,1,1,1,1,1,-1,\ldots$$ Suppose that there exist ${(i+1)}$ $1_s$ between the $i_{th}$ $(-1)$ and ${(i+1)}_{th}$ $(-1)$ for $i=1,2,\cdots$. Though I've thought about this, I'm facing difficulty. Can anyone help? A simpler form is better if closed forms exist. Motivation : I've known that a periodic sequence can be represented as a closed form. For example, if a sequence $\{b_n\}\ (n\ge0)$ is defined as
$$b_n : 1,1,1,-1,1,1,1,1,1,-1,1,1,1,1,1,-1,\ldots,$$
(Suppose that $b_n=-1\ (n\equiv 4),b_n=1\ (n\not\equiv 4)\ ($mod$ 6$)) then we can represent $\{b_n\}$ as
$$b_n=\frac 13\left(2+(-1)^n+2\cos\frac{n\pi}{3}-2\cos\frac{2n\pi}{3}\right).$$
Then, I got interested in the above sequence $\{a_n\}$. I'm facing difficulty because $\{a_n\}$ is not periodic.","['closed-form', 'sequences-and-series']"
540415,What is the simplest proof of the pythagorean theorem you know? [duplicate],This question already has answers here : Different proofs of the Pythagorean theorem? (14 answers) Closed 10 years ago . Maybe enough so to explain it to children.,"['geometry', 'big-list', 'alternative-proof']"
540425,Simple circle geometry/ similarity question,"How would you prove that $a=b$ ?
Would it be possible to solve this using similarity or trigonometry? Thank you in advance for any help. Any theorems or links would be appreciated.","['geometry', 'trigonometry', 'circles']"
540439,Prove that $1/f$ is uniformly continuous on ...,"I need hints for this particular question: Prove that if a function $f$ is uniformly continuous on $A\subseteq \mathbb{R}$ and $|f(x)|\geq k>0$ for all $x\in A$, then the function $\frac{1}{f(x)}$ is also uniformly continuous on $A$. My attempt: From the rough work given that $f(x)$ is uniformly continuous on $A$ for all $\epsilon> 0$, there exists a $\delta$ such that $|f(x)-f(y)|<\epsilon k^2$ when $x\in A$ and $|x-y|< \delta$, which impiles $\frac{1}{k^2} |f(x)-f(y)|< \epsilon$ for all $\epsilon >0$ and $|x-y|<\delta$. Taking the hint from Ayman Hourieh into consideration we have using the same $\delta$ from rough work, $\left |\frac{1}{f(x)} - \frac{1}{f(y)}  \right | $ = $\left |\frac{1}{f(x)f(y)}  \right | \left | f(x) - f(y) \right |\leq \frac{1}{k^2} \left | f(x)-f(y)  \right |< \epsilon$ when $\left | x-y \right |<\delta$. Is this proof okay?","['proof-verification', 'real-analysis', 'uniform-continuity']"
540442,Help needed......Statistics probability and z table...stuck,"The question is: **An estimated 1.8 million students take on student loans to pay ever-rising tuition and room and board (New York Times, April 17, 2009). It is also known that the average cumulative debt of recent college graduates is about $22,500. The cumulative debt for college graduates is normally distributed with a standard deviation of $7,000. Approximately how many recent college graduates have accumulated a student loan of more than $30,000?** What I've done: 30,000-22500/7000=1.071428571
I then looked this up on the z table but that wouldn't give me the correct answer. What exactly am I doing wrong?","['statistics', 'descriptive-statistics', 'statistical-inference', 'order-statistics']"
540458,$\ell^1$ Schur property,"I want to show that $\ell^1( \mathbb N )$ enjoys the Schur property . More precisely, I have to prove the following Theorem. Let $X = \ell^1 (\mathbb N )$, $\{ x^{(n)} \} \subset X$, $x \in X$. The following statements are equivalent: $x^{(n)} \overset{n \to \infty}{\rightharpoonup} x$ ; $x^{(n)} \overset{n \to \infty}{\to} x$. Now, $(2) \implies (1)$ is trivial. For the $(1) \implies (2)$ side, I tried something like: let $f \in \ell^1(\mathbb N)^\prime$ be an arbitrary linear functional. Then, by definition, \begin{equation}
x^{(n)} \overset{n \to \infty}{\rightharpoonup} x \iff \langle f, x^{(n)} \rangle \to \langle f, x \rangle \implies \lvert \langle f, x^{(n)} - x \rangle \rvert \to 0 \quad (n \to \infty) .
\end{equation} Hence \begin{equation}
\lvert \langle f, x^{(n)} - x \rangle \rvert \leq \lVert f \rVert \lVert x^{(n)} - x \rVert.
\end{equation} (This reasoning is actually applied for the other side; I wonder if something useful could be extracted in a similar way.) Now, by the Hahn-Banach theorem, we can choose $f$ such that $\lVert f \rVert = 1$ and $\langle f, x^{(n)} - x \rangle = \lVert x^{(n)} - x \rVert$. Since the left hand side of the last equation tends to zero for every $f \in \ell^1(\mathbb N)^\prime$ by definition of weak convergence, and in particular for the $f$ given by H-B theorem, it seems that the result would hold for every Banach space. This is clearly absurd , but I can't understand where the error is. Notice that it is obvious that the proof relies on the particular norm of $\ell^1$ and my original idea was to exploit it in same manner from the point where I'm stucked. I suspect there is no way to complete the preceding attempt and achieve a correct solution of the problem. (as one should expect in most cases he tries to copy the other part in a proof like that.) Nevertheless, I wanna detect the mistakes for many reasons. (proving the theorem, understanding the usage of the Hahn-Banach theorem, better myself, avoid similar mistakes in different situations, etc...)
So I ask for a ""error-checking"" and for a proof of the theorem. (or references as well.) Thank you!","['weak-convergence', 'functional-analysis']"
540471,Asymptotics for sums involving factorials,"This question is rather general, but I have recently encountered the following situation in a variety of different settings. Let us suppose that we are given a complicated sum involving factorials and some other ""less problematic stuff"". For example,
$$\sum_{k=1}^n \frac{(3k)! \, n! \, n!}{k! \, (k-4)!} 3^{n-4k}$$
(This is just an example - it is possible that this sum may be solved by some ad hoc methods, but this is not the point of the question.) My question is, in general, how to derive asymptotic estimates of such sums. For me, the most obvious idea is to replace the factorials by their Stirling approximation and then to simplify the resulting expression in order to obtain a single series in the summand. But here comes the problem: the Stirling's approximation is not convergent and thus cannot be (at least as to my poor knowledge) summed term-by-term. So my question is: is there any sufficiently general method to overcome this problem? For instance some trick with the Stirling approximation, or some other approximation of factorial that is more useful.","['factorial', 'asymptotics', 'summation', 'combinatorics']"
540473,help find my error in a statistics transformation computation,"This is a low-priority question, but it has been bugging me so I thought I'd ask.  In my stats homework I have the following exercise: Exercise. Suppose $X_1$ and $X_2$ are iid observations from the pdf $f(x\mid\alpha)=\alpha x^{\alpha-1}e^{-x^\alpha}$, $x>0$, $\alpha>0$.  Show that $(\log X_1)/(\log X_2)$ is an ancillary statistic. This is easy to do by showing that if $X\sim X_i$ then $(\log X)$ is a scale family and then applying the Theorem which states that if $U$ is a scale family and $U_1,\cdots,U_n$ are iid observations from $U$ then each $U_i/U_j$, $i\neq j$, is ancillary.  However I attempted a different method which led to a curious problem.  Observe. Let $U=\frac{\log X_1}{\log X_2}$ and $V=\log X_2$, then consider the transformation $(X_1,X_2)\mapsto(U,V)$.  Then $x_1=e^{uv}$ and $x_2=e^v$, giving us the Jacobian \begin{equation*}J=\left|\begin{array}{cc}\frac{\partial x_1}{\partial u}&\frac{\partial x_1}{\partial v}\\\\\frac{\partial x_2}{\partial u}&\frac{\partial x_2}{\partial v}\end{array}\right|=e^{(u+1)v}.\end{equation*} Thus by independence of $X_1$ and $X_2$ we have \begin{multline*}f_{U,V}(u,v)=f_{X_1,X_2}(e^{uv},e^v)|J|\\\\=[\alpha (e^{uv})^{\alpha-1}e^{-(e^{uv})^\alpha}][\alpha (e^v)^{\alpha-1}e^{-(e^v)^\alpha}]e^{(u+1)v}\\\\=\alpha^2\exp[{(u+1)v\alpha}-e^{uv\alpha}-e^{v\alpha}].\end{multline*} Hence by changing variables $z=v\alpha$ we get $dv=dz/\alpha$, and then \begin{multline*}f_U(u)=\int_{-\infty}^\infty\alpha^2\exp[{(u+1)v\alpha}-e^{uv\alpha}-e^{v\alpha}]\;dv\\\\=\alpha\int_{-\infty}^\infty\exp[{(u+1)z}-e^{uz}-e^z]\;dz=:\alpha g(u),\end{multline*} where $g(u)$ is independent of $\alpha$.  However this is impossible! This leads to my question:  Where is my error?",['statistics']
540477,Smallest such $n \in \mathbb{N}$ that $2^{n} \equiv 1 \pmod{5\cdot 7\cdot 9\cdot 11\cdot 13}$,"Can anybody give me a hint about how to find smallest such $n \in \mathbb{N}$ that $2^{n} \equiv 1  \pmod{5\cdot 7\cdot 9\cdot 11\cdot 13}$? I thought that I will find it piece by piece with help from my friend Fermat's Little Theorem, so : $2^{n_{1}} \equiv 1 \mod 5$, so $n_{1}=4$. $2^{n_{2}} \equiv 1 \mod 7$, so $n_{2}=6$. $2^{n_{3}} \equiv 1 \mod 3$, so $n_{3}=2$. $2^{n_{4}} \equiv 1 \mod 11$, so $n_{4}=10$. $2^{n_{5}} \equiv 1 \mod 13$, so $n_{5}=12$. So, since I know that $x \equiv y \mod mz \Leftrightarrow x \equiv y \mod m$ when $z \neq 0$, so my lucky was to take the lowest common multiple of $4,6,2,10,12$, which is $60$ and lo and behold it fits the bill. But is it the smallest such $n$? If so, how to explain it?","['modular-arithmetic', 'discrete-mathematics', 'congruences']"
540509,Number Theory Contest Math,"Find the smallest positive integer $n$ such that $n^4 + (n + 1)^4$ is composite.
Find the sum of the first $5$ positive integers $n$ such that $n^2 - 1$ is the product of 3 distinct primes. Answer to the first is $5$, and answer to the second is 104. Can anyone show me the solution process?","['contest-math', 'number-theory']"
540536,A basic doubt over diagonalization of a matrix,"Suppose, we have a matrix $A$ which is diagonalizable i.e. there exist an invertible matrix $B$ such that $B^{-1}AB = D$ where $D$ is a diagonal matrix. Is $B$ unique ? I don't think so.","['matrices', 'linear-algebra']"
540568,"If $f(x)$ is 2x differentiable in $(a,b)$ & $f'(a)=f'(b)=0$, prove that, $\exists\xi $ in $(a,b)$ S.T. $|f''(\xi )|\leq\frac{4(f(b)-f(a))}{(b-a)^{2}}$","Here is my argument (it doesn't feel 100% correct for some reason): By the mean value theorem, there exists $\xi_{1}$ in $(a,b)$ such that, $$f'(\xi_{1}) =  \frac{f(b)-f(a)}{b-a}$$ Since, $f'(a)=f'(b)=0$, then by the mean value theorem again, there exists $\xi_{2}$ in $(\xi_{1},b)$ such that, $$f''(\xi_{2})=\frac{f'(b)-f'(\xi_{1})}{b-\xi_{1}}=\frac{-(f(b) -f(a))}{(b-a)(b-\xi_{1})}$$ Since $\xi_{1}$ can be no lower than $a$, $$f''(\xi_{2}) \geq \frac{-(f(b) -f(a))}{(b-a)^{2}} \, or\,  f''(\xi_{2}) \leq \frac{f(b) -f(a)}{(b-a)^{2}} \leq \frac{4(f(b) -f(a))}{(b-a)^{2}}$$ $$Assuming\, f(b)\geq f(a)$$ So it follows,
 $|f''(\xi_{2} )| \leq  \frac{4(f(b)-f(a))}{(b-a)^{2}}$?","['calculus', 'proof-verification', 'derivatives']"
540572,Definition of Vector Space,"What is the meaning of objects in a vector space? Definition: A vector space is a nonempty set V of objects , called vectors, on
  which are defined two operations, called addition and multiplication
  by scalars, subject to the ten axioms... Can entries of a vector be anything other than real or complex numbers?",['linear-algebra']
540591,"Find asymptotics of $x(n)$, if $n = x^{x!}$","Find the asymptotic for $x(n)$, if  $n = x^{x!}$. I've tried 1) to take a logarithm: $x! \log{x} = \log{n}$. 2) to find $n'(x)$, using gamma-function for factorial $\Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt$ I'm here now: $\frac{1}{n}n'(x) = \Gamma'(x+1)\log{x} + \Gamma(x) $ $n'(x) = x^{x!}(\Gamma'(x+1)\log{x} + \Gamma(x)) $ What should I do next? Should I use another way of solving this problem?
I'm new to this theme, I will be grateful for any help.","['asymptotics', 'roots', 'combinatorics']"
540592,"The Cantor Set length is zero, why? Limits","My question is after the construction of the Cantor set which you might want to skip over that part . This question is not philosophical at all it is pertinent to my understanding of measure and space. Please If you think this is absurd, don't bother replying. Construction of the Cantor Set: We will denote the cantor set as $\mathfrak{C}\subset\mathbb{I}$
 , $\mathbb{I}=[0,1]$
  as defined in section 1, as mentioned above we construct $\mathfrak{C}$
  by removing middle third of the set (not including its endpoints). We denote this first slice in $\mathbb{I}$
  as $$\mathfrak{c_{1}}=\left[0,\frac{1}{3}\right]\cup\left[\frac{2}{3},1\right]=\mathbb{I}\setminus\left(\frac{1}{3},\frac{2}{3}\right)$$
 Next we cut out the middle third of each interval in $\mathfrak{c_{1}}$
 , that is the intervals $\left[0,\frac{1}{3}\right]\text{ and }\left[\frac{2}{3},1\right]$
  so we get 
$$\left[0,\frac{1}{3}\right]\to\left[\frac{0}{9},\frac{1}{9}\right]\cup\left[\frac{2}{9},\frac{3}{9}\right]=\left[0,\frac{1}{9}\right]\cup\left[\frac{2}{9},\frac{1}{3}\right]$$
 $$\left[\frac{2}{3},1\right]\to\left[\frac{6}{9},\frac{7}{9}\right]\cup\left[\frac{8}{9},\frac{9}{9}\right]=\left[\frac{2}{3},\frac{7}{9}\right]\cup\left[\frac{8}{9},1\right]$$ So we write $$\mathfrak{c_{2}}=\left[0,\frac{1}{9}\right]\cup\left[\frac{2}{9},\frac{1}{3}\right]\cup\left[\frac{2}{3},\frac{7}{9}\right]\cup\left[\frac{8}{9},1\right]$$ Hence we have that $\mathfrak{c_{2}}$
  is the union of $2^{2}$
  intervals all of which are of the form $[k/3^{2},(k+1)/3^{2}]$
 , if we continue this process for all $n\in\mathbb{N}$
  we find that each $\mathfrak{c}_{n}$
  is constructed of $2^{n}$
  intervals all of the form $[k/3^{n},(k+1)/3^{n}]$
 , and $\mathfrak{c}_{n+1}$
  will be obtained by taking the middle third out of each interval in $\mathfrak{c}_{n}$
 . The cantor set is what remain after we continue this processv for all $n\in\mathbb{N}$
  and then take the intersection over every $\mathfrak{c}_{i}$
 , or we could write $$\lim_{n\to\infty}\bigcap_{i=1}^{n}\mathfrak{c}_{i}=\mathfrak{C}$$
  Where $\mathfrak{C}$
  is the Cantor set. My Question: Why do we say that the Cantor set has no length? I get that the length of $\mathfrak{c_1}=\left(\frac{2}{3}\right)^1$ and that the length of $\mathfrak{c}_n=\left(\frac{2}{3}\right)^n$ so 
$$\lim_{n\to \infty} \left(\frac{2}{3}\right)^n= 0$$ Since, $\mathfrak{C}\subseteq\mathfrak{c}_n$ if follows that $\mathfrak{C}$ has a length of zero. Or, even you could argue that 
$$\lim_{n\to\infty}\frac{k}{3^{n}}=\lim_{n\to\infty}\frac{k+1}{3^{n}}=0$$
Since, the endpoints of each interval in $\mathfrak{c}_n$ converge to the same point each interval will become a single point in interval $\mathbb{I}$, and a single point $x\in\mathbb{R}$ has a measure of zero, i.e. $d(x,x)=0$. So, summing up distances of each intervals (of which there must be $2^{\aleph_0}$ many) in $\mathfrak{C}$, you get that the distance is zero. It is the concept of the limit and space that is tripping me up . Even if $n\to \infty$ $\frac{k}{3^n}\neq 0$ unless $k=0$ (in which case $\frac{k+1}{3^n}\neq 0$). In my mind $\frac{k}{3^n}$ can never equal $\frac{k+1}{3^n}$ because $k\in\mathbb{N}$ and $k+1$ is $k$'s successor (thus they are clearly not equal), so in a world of only the natural numbers it is clear that $k$ and $k+1$ don't occupy the same space. However, in $\mathbb{R}$ if we take the limit $n \to \infty$ of both $\frac{k}{3^n}$ and $\frac{k+1}{3^n}$ they end up equaling the same point in space, even though there numerators are different. Clearly, a difference of $1$ is negligible  in respects to $\infty$. But in my mind the every point in $\mathbb{R}^n$ is distinct, if you changed the trillionth decimal place in $\sqrt{2}$ and left every other digit intact, this new number would not share the same space (point) as $\sqrt{2}$ in $\mathbb{R}$. And in this same vein I feel like $\frac{k}{3^n}$ and $\frac{k+1}{3^n}$ will never be equal, they will differ by some decimal. And ultimately that would mean that the Cantor set has a distance/measure. Can someone explain to me why we would think differently about this? I am taking a first course in Analysis but please feel free to go beyond this If it will give a more rigorous explanation for why the cantor set has no distance. (Also, point out any abuses in language that I might have made.) Thanks!","['general-topology', 'measure-theory', 'real-analysis']"
540593,Error in finding sum of $1\cdot 2+3\cdot 4+ \cdots \text{to}\space n\space \text{terms}$,"To find sum of the series $1\cdot 2+3\cdot 4+ \cdots \text{to}\space n\space \text{terms}$ My approach, Let S=$1^2+2^2+3^2 + \cdots +n^2$ If $n$ is even S=$(1-2)^2+(3-4)^2+ \cdots +[(n-1)-n]^2+2(1 \cdot 2+3 \cdot 4+5 \cdot 6+ \cdots \text{to}\space \dfrac{n}{2}\space \text{terms})$ =$\frac{n}2+2(1 \cdot 2+3 \cdot 4+5 \cdot 6+ \cdots \text{to}\space \dfrac{n}{2}\space \text{terms})$ And we know, $$S=\frac{n(n+1)(2n+1)}6$$ Therefore,$$2(1 \cdot 2+3 \cdot 4+5 \cdot 6+ \cdots \text{to}\space \frac{n}2\space \text{terms}) =\frac{n(n+1)(2n+1)}6-\frac{n}2$$ or $$2(1 \cdot 2+3 \cdot 4+5 \cdot 6+ \cdots \text{to}\space \frac{n}2\space \text{terms})=\frac{n}2.\frac{2n^2+3n-2}3$$ or $$(1 \cdot 2+3 \cdot 4+5 \cdot 6+ \cdots \text{to}\space \frac{n}2\space \text{terms})=\frac{n(n+2)(2n-1)}{24}$$ But, this is the sum of $\dfrac{n}{2}$ terms. To get sum of $n$ terms, we replace $n$ by $2n$ Thus, $$(1 \cdot 2+3 \cdot 4+5 \cdot 6+ \cdots \text{to}\space n\space \text{terms})=\frac{n(n+1)(4n-1)}6$$ So, if input of $n$ is even result should be correct, if $n=2$, sum (from formula) = $7$ However, actual sum is $14$ (=$1 \cdot 2+3 \cdot 4$). What is the error in the above approach? EDIT : I rechecked my calculations and also have written the steps but still the answer isn't coming right. Please tell in which step the problem lies. Thanks for your time and patience.","['sequences-and-series', 'algebra-precalculus', 'fake-proofs']"
540608,"What is meant by ""global smooth coordinates""?","On p. 65 of John M. Lee's book Introduction to Smooth Manifolds , we find the following as part of Exercise 3.17: Verify that $(\tilde{x}, \tilde{y})$ are smooth coordinates on $\mathbb{R}^2$ , where $$\tilde{x}=x; \;\;\tilde{y} = x^3+y.$$ What is meant by showing that these are global smooth coordinates? Are we just showing that $(x,y) \mapsto (x,x^3+y):\mathbb{R}^2\to \mathbb{R}^2$ is a diffeomorphism? Thanks folks","['differential-topology', 'calculus', 'differential-geometry']"
540611,showing existence and uniqueness of solution of $y'(t)=\frac1{1+|y(t)|}$,"Given \begin{align*}
y'(t)&=\frac1{1+|y(t)|},&y(0)=y_0&&\textrm{for }t\in[a,b] 
\end{align*} I want to show that this IVP has a unique solution My attempt: We get $f(t,x)=\frac1{1+|x|}$. If $f$ is continuous there exists a solution on $[a,b]$ by Peano. If $f$ is Lipschitz-continuous, the solution is unique. Since fractions and $|\cdot|$ are continous and $|\cdot|\geq0$, $f$ is continuous and so there exists a solution by Peano, right? Now showing Lipschitz-continuity: $$|f(t,x)-f(t,y)|=\left|\frac1{1+|x|}+\frac1{1+|y|}\right|=\left|\frac{1+|y|+1+|x|}{(1+|x|)(1+|y|)}\right|$$ but now I am stuck. How do you get $\leq L|x-y|$ ?","['ordinary-differential-equations', 'real-analysis']"
540645,Do adjoint functors really define monads?,"It is often claimed as ""obvious"" that a pair of adjoint functors: $L\colon{\cal V}\to {\cal M}$ and $R\colon{\cal M}\to {\cal V}$ defines a cotriple $(\bot, \epsilon, \delta)$ and a monad. What is wrong with the following counterexample? Let ${\cal V}$ be the category of vector spaces over $\mathbb R$ and ${\cal M}$ be the category of modules over a Lie algebra $\mathfrak g.$ Then (I believe) the forgetful functor $R:{\cal M}\to {\cal V}$ is right adjoint to $L\colon{\cal V}\to {\cal M},$ $L(V)=V\otimes \mathfrak g.$ The counit $\epsilon\colon M\otimes \mathfrak g\to M$ is given by the action of $\mathfrak g$ on $M.$ In Weibel's ""Intro to Homological Algebra"", the construction of a monad is based on the following identity: $\epsilon\circ (LR\epsilon)=\epsilon\circ(\epsilon LR)$. That means that $(m\cdot x)\cdot y=m\cdot (x\cdot y)$ for $x,y\in \mathfrak g.$ But for Lie algebra modules we have $(m\cdot x)\cdot y=m\cdot (x\cdot y)+(m\cdot y)\cdot x$!","['monads', 'category-theory', 'abstract-algebra']"
540646,"If a function is integrable, then it is bounded","Probably a simple question, but I wonder about the following.
I know that if a function $f : \mathbb{R} \rightarrow \mathbb{R} $ is (Riemann)integrable, then it is bounded. I wonder if I can generalize this to functions on $\mathbb{R}^3$ (now for an ingral over a volume). It seemed logical to me that, because this theorem is true on $\mathbb{R}$, that it should be true on $\mathbb{R}^n$. But apparently it isn't, because the integral in theorem 10.1 of the document http://people.maths.ox.ac.uk/kirchhei/section_1008.pdf converges according to the theorem. The function under the integral is not bounded however. So can't I generalize the theorem that a integrable function should be bounded?",['integration']
540651,Can I convert to polar coordinates when calculating multivariate limits with three variables,"When working on limits of functions with two variables, $f(x,y)$, I like to convert the problem to polar coordinates a lot of the time, by changing the question from $$\lim_{(x,y)\to (0,0)}f(x,y)$$ to $$\displaystyle\lim_{r\to 0}f(r\cos\theta,r\sin\theta).$$ I was just doing some problems in my book when I encountered a limit of a function with three variables, $f(x,y,z)$. I was just wondering if there was a way to calculate such a limit with polar coordinates. An example being: $$\lim_{(x,y,z)\to(0,0,0)}\frac{xy+yz^2+xz^2}{x^2+y^2+z^4}$$ Converting it into polar coordinates gives me: $\displaystyle\lim_{r\to 0}\dfrac{r^2\sin\theta\cos\theta+r\sin\theta \cdot z^2+r\cos\theta\cdot z^2}{r^2(\sin^2\theta+\cos^2\theta)+z^4}=\displaystyle\lim_{r\to 0}\dfrac{r(r\sin\theta\cos\theta+\sin\theta\cdot z^2+\cos\theta\cdot z^2)}{r^2+z^4}$ Can I proceed or is polar coordinates strictly for use with two variables only?","['multivariable-calculus', 'polar-coordinates', 'limits']"
540654,Elevated percentage of standard BMI associated with Carcinoma,"Percentage of Standard BMI$\hspace{30mm}$Male$\hspace{40mm}$Female $\hspace{70mm}$Case$\hspace{10mm}$Control$\hspace{20mm}$Case$\hspace{10mm}$Control <130$\hspace{61mm}$123$\hspace{12mm}$150$\hspace{27mm}$55$\hspace{15mm}$59 $\ge$130$\hspace{61mm}$85$\hspace{13mm}$45$\hspace{29mm}$51$\hspace{15mm}$46 *Standard BMI: male, 22.1; female, 20.6. Percentage of standard BMI=(observed BMI/standard BMI)x100 Is elevated percentage of standard BMI associated with renal cell carcinoma after controlling the effects of sex? Anyone know what kind of test to run on the data?",['statistics']
540678,How to prove if log is rational/irrational,"I'm an English major, now doubling in computer science. The first course I'm taking is Discrete Mathematics for Computer Science, using the MIT 6.042 textbook. Within the first chapter of the book's practice problems, they ask us multiple times to prove that some log function is either rational or irrational. Specific cases make more sense than others, but I would really appreciate any advice on how to approach these problems. Not how to carry them out algebraically, but what thought constructs are necessary to consider a log being (ir)rational. For example, in the case of $\sqrt{2}^{2\log_2 3}$, proving that $2\log_23$ is irrational (and therefore $a^b$, when $a=\sqrt{2}$ and $b=2\log_23$, is rational) is not an easily solvable problem. I understand the methods of proofs, but the rules of logs are not intuitive to me. A section from my TF's solution is not something I would know myself to construct: Since $2 < 3$, we know that $\log_23$ is positive
(specifically it is greater than $1$), and hence so is $2\log_23$. Therefore, we can assume that $a$ and $b$ are two positive integers.
Now $2\log_2 3=a/b$ implies $2^{2\log_2 3}=2^{a/b}$.
Thus $$2^{a/b}=2^{2\log_2 3} = 2^{\log_2 3^2} =3^2 =9\text{,}$$
and hence $2^a = 9^b$. Any advice on approaching thought construct to logs would be greatly appreciated!","['logarithms', 'discrete-mathematics']"
540685,the table at the end of Theoretical Computer Science Cheat Sheet,"Theoretical Computer Science Cheat Sheet , created by Steve Seiden , is a hodgepodge of well-known mathematical theorems and notions. I can understand (or guess at least) many of them, but I'm not sure about this 10-by-10 table at the end of the document. What is this matrix? The document has no explanation at all, and I'm wondering why the author put in a cheat sheet . Is there any special meaning in computer science or math that this matrix stands for?","['combinatorial-designs', 'matrices', 'pattern-recognition']"
540692,Finding a marginal PDF of a joint probability distribution,"I understand the idea of how to do it, but I'm currently getting a constant as my marginal PDF, which doesn't make sense. The overall distribution is as follows: 
$f(x,y) = 5ye^{-xy}$ for $0 < x, 0.2 < y < 0.4$ I'm trying to find the probability that $0 < x < 2$ given that $y = 0.25$, which should be $\frac{f(0<x<2,y=0.25)}{f_y(0.25)}$. As a minor double-check, should the top be a single integral evaluated with $y=0.25$? The bulk of my question is that I'm finding $f_y$ to be a constant, which doesn't make sense. What am I doing wrong? $f_y = \int_{0}^{\infty} 5ye^{-xy} dx = 5[-e^{-xy}]_{0}^{\infty} = 5[0-(-1)]=5$","['statistics', 'probability']"
540790,Wick polynomials - hard time following the basics...,"I am studying Peter Major's lecture notes on Multiple Wiener-Ito Integrals. I have hard time following the arguments of the proofs for the theorem 2.1, which is a first milestone to a Wick polynomial definition and all the other material there... I feel that this should be pretty straight forward for those who are familiar with this notion...any help would be very appreciated, thanks! Here is the content of the relevant pages (this is exact exert from pages 6 to 8 of Peter Major's lecture notes): ""
[...] In this section we consider the so-called Wick polynomials, a multi-dimentional generalization of Hermoite-polynomials. they are closely related to multiple Wiener-Ito integral. Let $X_t, t \in T$ be a set of jointly Gaussian random variables indexed by a parameter set $T$ . Let $EX_t = 0$ for all $t \in T$ . We define the real Hilbert space $\mathcal{H}_1$ and $\mathcal{H}$ in the following way: A square integrable random variable is in $\mathcal{H}$ if and only if it is measurable with respect to $\sigma$ -algebra $\mathcal{B}=\mathcal{B}(X_t, t \in T)$ and the scalar product in $\mathcal{H}$ is defined as $(\xi,\rho)=E\xi\rho,  $ for all $\xi,\rho \in \mathcal{H}$ . $\mathcal{H}_1 \subset \mathcal{H}$ is the subspace generated by the finite linear combinations $\sum c_j X_{t_j}$ , $t_j \in T$ . We consider only such sets $X_t, t \in T$ for which $\mathcal{H}_1$ is separable. $\{X_t, t \in T\}$ can be otherwise arbitrary. Let $Y_1,Y_2, \dots$ be an orthonormal basis in $\mathcal{H}_1$ . then the uncorrelated random variables $Y_1,Y_2, \dots$ are independent, because they are Gaussian. Moreover $\mathcal{B}(Y_1,Y_2, \dots)=\mathcal{B}(X_t, t \in T)$ . Let $H_n$ denote the $n$ -th Hermite polynomial with leading coefficient $1$ , i.e. let $
H_n(x) = (-1)^n \exp(\frac{x^2}{2})\frac{d^n}{dx^n}(\exp(\frac{x^2}{2})))
$ We recall the following result from analysis and measure theory: Theorem $2A$ - 
The Hermite polynomials $H_n(x), n=0,1,\dots$ form a complete orthogonal system in $L_2(\mathbb{R},\mathcal{B},\frac{dx}{\sqrt{2\pi}}\exp(-\frac{x^2}{2}))$ (Here $\mathcal{B}$ denotes a Borel $\sigma$ -algebra on the real line). Let $(X_j,\mathcal{X}_j, \mu_j), j=1,2,\dots$ be countably many copies of a probability space $(X,\mathcal{X}, \mu)$ (We denote the points of $X_j$ by $x_j$ ). Let $(X^\infty,\mathcal{X}^\infty, \mu^\infty)=\prod_{j=1}^{\infty}(X_j,\mathcal{X}_j, \mu_j)$ . Theorem $2B$ -
Let $\phi_0,\phi_1,\dots;\phi_0=1$ be a complete orthonormal system in $L_2(X,\mathcal{X}, \mu)$ . Then the functions $\prod_{j=1}^{\infty}\phi_{k_j}(X_j)$ where only finite many indices $k_j$ differ form zero, form a complete orthonormal basis in $(X^\infty,\mathcal{X}^\infty, \mu^\infty)$ . Theorem $2C$ - 
Let $(X, \mathcal{A})$ be a measurable space $Y_1,Y_2, \dots$ be $\mathcal{A}$ -measurable functions such that $\mathcal{B}(Y_1,Y_2, \dots)=\mathcal{A}$ . If $\xi$ is an $\mathcal{A}$ -measurable functions then there exists an $(\mathbb{R}^\infty, \mathcal{B}^\infty)$ -measurable functions $f$ such that $\xi=f(Y_1,Y_2, \dots)$ . Theorems $2A, 2B, 2C$ have the following important consequence: Theorem $2.1$ - 
Let $Y_1,Y_2, \dots$ be othonormal basis in $\mathcal{H}_1$ . Then the set of all possible finite products $H_{j_1}(Y_{l_1})\dots H_{j_k}(Y_{l_k})$ is a complete orthogonal system in $\mathcal{H}$ . Proof of Theorem $2.1$ By theorems $2A$ and $2B$ , the set of all possible products, $\prod_{j=1}^{\infty}H_{k_j}(x_j)$ , where only finite many indeces $k_j$ differ from $0$ , is a complete orthogonal system in $L_2(\mathbb{R}^\infty,\mathcal{B}^\infty,\prod_{j=1}^{\infty}\frac{dx_j}{\sqrt{2\pi}}\exp(-\frac{x_{j}^{2}}{2}))$ . Since $\mathcal{B}(X_t, t \in T)= \mathcal{B}(Y_1,Y_2, \dots)$ , theorem $2C$ implies that the mapping $f(x_1,x_2,\dots)\to f(Y_1,Y_2,\dots)$ is a unitary transform from $L_2(\mathbb{R}^\infty,\mathcal{B}^\infty,\prod_{j=1}^{\infty}\frac{dx_j}{\sqrt{2\pi}}\exp(-\frac{x_{j}^{2}}{2}))$ to $\mathcal{H}$ . Since the image of a complete orthogonal system under a unitary trasformation is again a complete orthonormal system, theorem $2.1$ is proved.
[...]"" [1] I don't really understand what is the connection between the first part int the proof that uses theorem $2A,2B$ and the second part, I only know that $ f $ in the second part can be expanded in the $\prod_{j=1}^{\infty}H_{k_j}(x_j)$ since those form an orthogonal systems. [2] Why is the mapping $f$ is unitary? [3] What is the intuition behind those claims? Thank you","['probability-theory', 'orthogonal-polynomials']"
540816,"The derivative of $e^x$ using the definition of derivative as a limit and the definition $e^x = \lim_{n\to\infty}(1+x/n)^n$, without L'Hôpital's rule","Let's define 
$$
e^x := \lim_{n\to\infty}\left(1+\frac{x} {n}\right)^n, \forall x\in\Bbb R
$$ and $$
\frac{d} {dx} f(x) := \lim_{\Delta x\to0} \frac{f(x+\Delta x) - f(x)} {\Delta x}
$$ Prove that $$
\frac{d} {dx} e^x = e^x
$$ using the definition of $e^x$ and derivation above, without using L'Hôpital's rule or the "" logarithm trick "" and/or the ""inverse function derivative trick"". $$
\left( \frac{d} {dx} f^{-1}(x)= \frac{1} {\left(\frac{d}{d(f^{-1}(x))}f(x)\right)(f^{-1}(x))}\right)
$$ Or equivalently prove that the following two definiton of $e$ are identical
$$
1)\space\space\space\space e =\lim_{n\to\infty}(1+\frac{1} {n})^n
$$ $$
2) \space\space\space\space e\in\Bbb R,\space\space(\frac{d} {dx} e^x)(x=0) = 1  
$$ What I've got is
$$
\frac{d}{dx}e^x=e^x \lim_{\Delta x\to0}\frac{e^{\Delta x} - 1} {\Delta x} =
e^x \lim_{\Delta x\to0}\lim_{n\to\infty}\frac{\left(1+\frac{\Delta x}{n}\right)^{n}-1}{\Delta x} = 
e^x \lim_{\Delta x\to0}\frac{e^{0+\Delta x}-e^0}{\Delta x} 
$$ If i assume that $n\in\Bbb N$ I could use binomial theorem but I didn't got much out of it. Wolframalpha just uses L'Hospital rule to solve it, but I am looking for an elementary solution. What I'm interested in is basically is the equivalence of the two definition of $e$ mentioned above. And I'd like to get a direct proof rather than an indirect(I mean which involves logarithms or the derivatives of invers functions). I look forward getting your aswers.","['calculus', 'derivatives', 'real-analysis', 'definition']"
540826,Using DeMorgan's Laws to complement a function,"Using DeMorgan's Law, write an expression for the complement of $F$ if: $F(x,y,z) = x(y' + z)$. $F=x'+(y'+x)'$ $F(x,y,z) = xy + x'z + yz'$ $F=(xy)'(x'z)'(yz')'$ $F(w,x,y,z) = xyz' (y'z + x)' + (w'yz + x' )$. $F=[(xyz')'+(y'z+x)](w'yz+x')'$ My answers are underneath the numbered questions. Is everything correct? I'm not 100% sure as to what I'm exactly supposed to do. I just took all the ANDs, negated them and made them ORs and vice-versa.","['logic', 'propositional-calculus', 'discrete-mathematics']"
540827,$\int_0^{\frac{\pi}{2}}x\cot(x)dx$ and $ \lim_{m \rightarrow \infty}\log\left( e^{2m}\left(\frac{(2m-1)!!}{(2m+1)^m}\right)^2\right)$.,"I'm trying to evaluate the integral, but in doing so have stumbled upon the limit, which I don't know whether it exists, and if so how to resolve it (and whether I've derived the relationship between the integral and limit correctly  [see below]). Derivation: First, use the cotangent formula: $$\cot(x)=\sum_{-\infty\le n\le\infty}\frac{1}{x+\pi n},$$
and apply it to the integral:
$$\int_0^{\frac{\pi}{2}}x\cot(x)dx=\sum_{-\infty\le n\le\infty}\int_0^{\frac{\pi}{2}}\frac{x}{x+\pi n}dx$$
$$=\sum_{-\infty\le n\le\infty}\int_{n \pi}^{\pi \left(n+\frac{1}{2}\right)}\frac{u- \pi n}{u}du$$
$$=\sum_{-\infty\le n\le\infty}[u-\pi n \log(u)]_{n \pi}^{\pi \left(n+\frac{1} {2}\right)},$$
and rearranging,
$$=\sum_{-\infty\le n\le\infty}\frac{\pi}{2}-\pi n \log\left(\frac{2n+1}{2n}\right)$$
$$=\frac{\pi}{2}\sum_{-\infty\le n\le\infty}  \log\left( e\left(\frac{2n}{2n+1}\right)^{2n}\right)$$
$$=\frac{\pi}{2}  \log\left( \prod_{-\infty\le n\le\infty} e\left(\frac{2n}{2n+1}\right)^{2n}\right).$$ Note that $$\prod_{-\infty\le n\le\infty} \left(\frac{2n}{2n+1}\right)^{2n}=  \prod_{1\le n\le\infty} \left(\frac{2n}{2n+1}\right)^{2n}\left(\frac{-2n}{-2n+1}\right)^{-2n} $$
$$=  \prod_{1\le n\le\infty} \left(\frac{2n-1}{2n+1}\right)^{2n} $$
$$=\left(\frac{1^1}{3^1}\cdot\frac{3^2}{5^2}\cdot\frac{5^3}{7^3}\cdots\right)^2=\lim_{m \rightarrow \infty}\left(\frac{(2m-1)!!}{(2m+1)^m}\right)^2.$$
Thus the original integral is equal to
$$\frac{\pi}{2}  \lim_{m \rightarrow \infty}\log\left( e^{2m+1}\left(\frac{(2m-1)!!}{(2m+1)^m}\right)^2\right).$$","['summation', 'integration']"
540842,"Reading, Writing, and Proving Math: Cartesian Product","The following is my attempt at one of my homework assignments. Let A, B, and C be sets. If the statement below is true, prove it. If false, give a counter example. A $\times$ (B $\cap$ C) = (A $\times$ B) $\cap$ (A $\times$ C). I want to say this is true so I went about it as follows.
To do this, I needed to show that they are subsets of each other. Claim 1: A $\times$ (B $\cap$ C) $\subseteq$ (A $\times$ B) $\cap$ (A $\times$ C) Let z $\in$ A $\times$ (B $\cap$ C) $\rightarrow$ z = (x,y) $\in$ A $\times$ (B $\cap$ C) $\rightarrow$ x $\in$ A $\wedge$ y $\in$ (B $\cap$ C) $\rightarrow$ x $\in$ A $\wedge$ (y $\in$ B $\wedge$ y $\in$ C) $\rightarrow$ (x $\in$ A $\wedge$ y $\in$ B) $\wedge$ (x $\in$ A $\wedge$ y $\in$ C) $\rightarrow$ (x,y) $\in$ A $\times$ B $\wedge$ (x,y) $\in$ A $\times$ C $\rightarrow$ (x,y) $\in$ (A $\times$ B) $\cap$ (A $\times$ C) Thus A $\times$ (B $\cap$ C) $\subseteq$ (A $\times$ B) $\cap$ (A $\times$ C) Claim 2: (A $\times$ B) $\cap$ (A $\times$ C) $\subseteq$ A $\times$ (B $\cap$ C) Let z $\in$ (A $\times$ B) $\cap$ (A $\times$ C) $\rightarrow$ z =(x,y) $\in$ (A $\times$ B) $\cap$ (A $\times$ C) $\rightarrow$ (x,y) $\in$ (A $\times$ B) $\wedge$ (x,y) $\in$ (A $\times$ C) Suppose (x,y) $\in$ (A $\times$ B) $\rightarrow$ x $\in$ A $\wedge$ y $\in$ B $\rightarrow$ x $\in$ A $\cap$ A $\wedge$ y $\in$ B $\cap$ C $\rightarrow$ x $\in$ A $\wedge$ y $\in$ B $\cap$ C $\rightarrow$ (x,y) $\in$ A $\times$ (B $\cap$ C) Suppose (x,y) $\in$ (A $\times$ C) $\rightarrow$ x $\in$ A $\wedge$ y $\in$ C $\rightarrow$ x $\in$ A $\cap$ A $\wedge$ y $\in$ B $\cap$ C $\rightarrow$ x $\in$ A $\wedge$ y $\in$ B $\cap$ C $\rightarrow$ (x,y) $\in$ A $\times$ (B $\cap$ C) Thus (A $\times$ B) $\cap$ (A $\times$ C) $\subseteq$ A $\times$ (B $\cap$ C) Hence A $\times$ (B $\cap$ C) = (A $\times$ B) $\cap$ (A $\times$ C). The only think I am not sure of is the second Claim. What makes me have doubts is the fact y can be in B but what if it is not in C. Then I thought, well doesn't y have to be in both to begin with. This is when I got confused. Thanks for taking the time to read the post. Thanks in advanced for your feedback.","['elementary-set-theory', 'proof-verification']"
540869,Is every rigid field perfect?,A field is rigid iff its automorphism group is trivial. A field $F$ is perfect iff all irreducibles in $F[x]$ are separable. Is every rigid field perfect?,"['galois-theory', 'commutative-algebra', 'algebraic-geometry', 'field-theory']"
540888,Complex integral of an exponent divided by a linear ($\int \frac{e^u}{u-1}$),"Here is the question I'm working on: Evaluate the following integral: $$ \oint_{|z+1|=1} \frac{\sin \frac{\pi z}{4}}{z^2-1}dz$$ I've tried along the following line. Substitute $sin(z) = \frac{e^z-e^{-z}}{2i}$: $$ \frac{1}{2i} \int \frac{e^{\pi z/4}-e^{-\pi z/4}}{z^2-1}dz$$ The contour is a circle of radius 1 around $-1$, so substitute $z=-1+e^{it}$, with $dz = ie^{it}dt$: $$ \frac{1}{2i} \int_0^{2\pi} \cfrac{e^{\pi/4(e^{it}-1)}-e^{-\pi/4(e^{it}-1)}}{(e^{it}-1)^2-1}ie^{it}dt = \frac{1}{2} \int \cfrac{e^{\pi/4(e^{it}-1)}-e^{-\pi/4(e^{it}-1)}}{e^{it}-2}dt$$ A repeat of the same substitution $u = e^{it} - 1$ with $du = ie^{it}dt$ gives: $$\frac{1}{2} \int \cfrac{e^{\pi u/4}-e^{-\pi u/4}}{u-1}du$$ At this point I've run out of ideas. Any hint or pointer would be appreciated.","['complex-numbers', 'integration', 'complex-analysis']"
540903,Why do all linear transformations have no restrictions on their natural domains?,"Some normal functions have restrictions on their natural domains, but linear functions don't. Why? Related: Is there a linear transformation who domain isn't all of $\mathbb{R}^n$? Why my question is not a duplicate of the above question : The above question asks if there asks if there is any function whose domain isn't $\mathbb{R}^n$. This function clearly exists by limiting the domain of any linear transformation. My question is asking about the natural domain of a linear transformation, which none of the answers from the question above address. Natural Domain: The largest domain where the transformation makes sense. In other words, the domain of a linear transformation, without any artificial ""restrictions"" put on it.","['vector-spaces', 'matrices', 'linear-algebra']"
540904,Derivative in interesting way,"I am supposed to give a 15-20 minutes math lecture, where I am expecting around 20-30 people. The lecture is about derivative. Since this would be my first ""class"", I would appreciate any suggestions to how to make it interesting. Students could be bored with definitions, theorems, mathematical concepts that are told in abstract way, therefore my question is: How to tell a story about derivative in simple, interesting but also, mathematically based way? :) Any suggestions about mathematical questions, examples, fun problems related to this topic (which should grab their attention) are also welcome.","['calculus', 'education', 'reference-request', 'soft-question', 'derivatives']"
540913,Examples of complex functions with infinitely many complex zeros,"What are some examples of complex functions with infinitely many complex zeros? There are no particular restrictions on the functions I am just curious and having a hard time finding examples. Also what can be said about a complex function with infinitely many complex zeros, must they have any special properties?","['roots', 'complex-analysis']"
540917,Involutive fourier transform,"The writer here states I am introducing a viewpoint  (the involutive convention)  which makes the Fourier transform its own inverse  (i.e., the Fourier transform so defined is an  involution). If I am reading the notation correctly, the definition given is: $$F(f)(s) = \int_{-\infty}^{\infty}\exp(2\pi is x)\overline{f(x)}dx.$$ Under this convention, $F$ fails to be a linear operator; but, I don't think this is too big of a deal, since $F$ ends up being conjugate-linear . In any event, I have never seen this definition before. My question is, firstly, does it have any subtle issues that make it a bad idea? If not, a thoughtful discussion of the benefits of this definition would be appreciated.","['fourier-analysis', 'calculus', 'integral-transforms', 'reference-request', 'functional-analysis']"
540925,sequences with cosines are they always divergent?,"I have to show if this sequence is converging or diverging :
$$a_n=\cos(n/2)$$
I know that $\lim_\infty n/2= \infty $ and I also know that the cosines function is alternating between $[-1,1]$. So by a theorem I can conclude that $a_n$ is diverging. But know I'm asking myself, if I have :
$$a_n=\cos(1/n)$$
I have $\lim_\infty 1/n= 0$ then by theorem $\lim_\infty a_n = 1$, so $a_n$ is converging, right ? but naively, I thought that sequences with cosines like both above, are always divergents because of alternating thx",['sequences-and-series']
540950,Rotation Matrix inverse using Gauss-Jordan elimination,"I'd like to calculate the inverse of a rotation matrix, let take the simplest case which is a $2$ x $2$ rotation matrix: $R =\begin{bmatrix} \cos \theta & -\sin \theta \\[0.3em] \sin \theta & \cos \theta \end{bmatrix}$ I know that the inverse is the following $R^{-1} =\begin{bmatrix} \cos \theta & \sin \theta \\[0.3em] -\sin \theta & \cos \theta \end{bmatrix}$ and I know that I can calculate it using the transpose method as such: $R^{-1}=R^T$ but I fail to calculate the inverse using $Gauss-Jordan$ elimination, that is I don't know how to substract $\cos \theta$ from $\sin \theta$ in the second row. It all gets a bit complicated; I've looked around and nobody has a full step method using $G.-J.$ only the solution or the transpose method. Could someone provide me a full-step solution using $G.-J.$?",['matrices']
540953,Probability convergence in distribution,"$Y_1, Y_2,..., Y_n$ are i.i.d and uniformly distributed on the set $\{1, 2,..., n\}$. Define $X_n = \min\{k: Y_k = Y_j\; \text {for some}\; j < k\}$, and prove that $\frac {X_n}{\sqrt n}$ converges in distribution to a limit with distribution function $F(x) = 1 - \exp\{-(x^2)/2\}$ for $x>0$. My working: $$P\left (\frac {X_n}{\sqrt n} \le  x\right) = P\left (X_n \le  x\sqrt n\right)
= 1 - P\left(X_n > x\sqrt n\right)$$
$$= 1 - (1 - 1/n)\cdot(1 - 2/n)\cdot...\cdot(1 - \lfloor {x\sqrt n}\rfloor/n)$$
where $\lfloor\; \rfloor$ is the floor function so I basically want to show $1 - (1 - 1/n)\cdot(1 - 2/n)\cdot...\cdot(1 - \lfloor {x\sqrt n}\rfloor/n)$ converges to
$\exp\{-(x^2)/2\}$ but i have no idea how to do this.",['probability-theory']
540955,Describing co-ordinate systems in 3D for which Laplace's equation is separable,"Laplace's Equation in 3 dimensions is given by $$\nabla^2f=\frac{ \partial^2f}{\partial x^2}+\frac{ \partial^2f}{\partial z^2}+\frac{ \partial^2f}{\partial y^2}=0$$ and  is a very important PDE in many areas of science. One of the usual ways to solve it is by seperation of variables . We let $f(x,y,z)=X(x)Y(y)Z(z)$ and then the PDE reduces to 3 independent ODE's of the form $X''(x)+k^2 x=0$ with $k$ a constant. This method works for a surprising number of coordinate systems. I can use cylindrical coordinates, spherical coordinates, bi-spherical coordinates and more. In fact in 2 dimensions, I can take $\mathbb{R}^2$ to be $\mathbb{C}$, and then any analytic function $f(z)$ maps the Cartesian coordinates of $\mathbb{R}^2$ onto a set of coordinates that is separable in Laplace's equation. This follows from analytic functions also being harmonic functions. For example $f(z)=z^2$ maps the cartesian coordinates to the parabolic coordinates . So how about in 3 dimensions? Is there a way to describe all coordinate systems such that the Laplacian separates in this way?I have no idea how to start. I think that Confocal Ellipsoidal Coordinates will work but I'm not sure how to verify it. I'm not familIar with differential geometry, so any help appreciated. Image source","['coordinate-systems', 'differential-geometry', 'partial-differential-equations', 'harmonic-functions', 'complex-analysis']"
540989,"Questions on ""painless conjugate gradient"": take gradient of a quadratic form","I am reading this paper: http://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf I have difficulties on the derivation of equation (6) on page 4.
It is to take gradient of a quadratic form. I searched around and found this: How to take the gradient of the quadratic form? I can understand most of the answer in above link, but: Why the $y$ in the second part of chain rule needs to be transposed? In neither original paper or above Q/A it tells me how to take derivative of a vector valued function($R^n \rightarrow R^n$). I think that was used implicitly in the derivation of
$\dfrac{\partial (x^TA^T)}{\partial x}$. And that may be not rigorous to apply 
$$\dfrac{\partial (b^Tx)}{\partial x} = \dfrac{\partial (x^Tb)}{\partial x} = b$$
directly on $\dfrac{\partial (x^TA^T)}{\partial x}$ to get $A^T$.","['linear-algebra', 'derivatives']"
540990,Real projective $n$ space,"We define $\sim$ on $\mathbf{R}^n - \{0\}$ by $x \sim y$ if $x = \lambda y$ for some $\lambda \in \mathbf{R}$. We define projective $n$ space by $X = (\mathbf{R}^n - \{0\})/{\sim}$. I am having trouble showing that $X$ is an $(n-1)$-dimensional topological manifold. The definition of a topological manifold that I'm working with is the following: $X$ is a topological $n$-manifold if, for all $x \in X$, there is an open nhood $U$ of $x$ such that $U$ is homeomorphic to an open subset of $\mathbf{R}^n$. I understand that one can take $U$ to be homeomorphic to any open ball in $\mathbf{R}^n$, or any open nhood ball in $\mathbf{R}^n$. I am also aware that the open nhoods of $\overline{x} \in X$ will look like a half-sphere (at least I think so; I think my work was OK here).","['manifolds', 'differential-geometry']"
541009,How prove $A=B=C$?,"in $\Delta ABC$,
such $$\sin{A}+\cos{B}+\tan{C}=\dfrac{3\sqrt{3}+1}{2}$$ prove that
$$A=B=C=\dfrac{\pi}{3}$$ My try: 
use $$\sin{x}+\sin{y}=2\sin{\dfrac{x+y}{2}}\cos{\dfrac{x-y}{2}}$$
  then 
  \begin{align*}&\sin{A}+\cos{B}\\
&=\sin{A}+\sin{(\dfrac{\pi}{2}-B)}=2\sin{\dfrac{\pi+2(A-B)}{4}}\cos{\dfrac{A+B-\dfrac{\pi}{2}}{2}}\\
&=2\sin{\dfrac{\pi+2(A-B)}{4}}\cos{\dfrac{\pi-2C}{4}}
\end{align*}
  my idea is take $\sin{A}+\cos{B}\le f(C)$?and if only if $A=B$,BUt I can't ,Thank you someone can help me",['trigonometry']
541021,Is this a correct way to prove uniqueness using limits?,"I have a question about the following proof: Claim: A sequence in $\mathbb{R}$ can have at most one limit. Proof: Assume a sequence $X = (x_n)$ has two limits. Call them $x$ and $x'$ . For any $\epsilon > 0$ , there exists $N$ such that $|x_n - x| < \epsilon/2$ for $n \geq N$ . There also exists $N'$ such that $|x_{n'}- x'| < \epsilon/2$ for $n' \geq N'$ . Let $M = $ max $(N, N')$ . Then for $m \geq M$ : $|x-x'| = |(x - x_m) + (x_m - x')| \leq |x_m - x| + |x_m - x'| < \epsilon/2 + \epsilon/2= \epsilon$ . Since $\epsilon$ is arbitrary, we conclude $x = x'$ . My question: is it necessary to split $\epsilon$ at all? Do we do this just because we want a clean looking proof? Here is the alternative proof which I had in mind, which may or may not be correct: Assume a sequence $X = (x_n)$ has two limits. Call them $x$ and $x'$ . For any $\epsilon > 0$ , there exists $N$ such that $|x_n - x| < \epsilon$ for $n \geq N$ . For $\epsilon_2 > 0$ , there exists $N'$ such that $|x_{n'}- x'| < \epsilon_2$ for $n' \geq N'$ . Let $M = $ max $(N, N')$ . Then for $m \geq M$ : $|x-x'| = |(x - x_m) + (x_m - x')| \leq |x_m - x| + |x_m -x'| < \epsilon + \epsilon_2= \epsilon_3$ . $\epsilon_3$ is just another positive real number. I can make $\epsilon_3$ as small as I like because I can make $\epsilon$ and $\epsilon_2$ as small as I like. So I draw the same conclusion. Is the last bit of reasoning valid? I've gotten the impression, from speaking with a professor, that I introduce a dependency on $\epsilon$ and $\epsilon_2$ , so I should be able to come up with some method of getting $\epsilon$ and $\epsilon_2$ . I'm confused. (the angle brackets from the blockquote seem to be screwing up the formatting.)","['real-analysis', 'limits']"
541046,Quotient of two smooth functions is smooth,"Let $f:\mathbb R\to \mathbb R$ be a $C^\infty$-smooth function. Suppose that   $f^{(k)}(0)=0$ for $k=0,\dots,n-1$. Prove that the function $g(x)=f(x)/x^n$ extends to a $C^\infty$-smooth function on $\mathbb R$. Comment: by l'Hôpital's rule, $g$ has a finite limit at $0$, namely $f^{(n)}(0)/n!$. So, it extends to a continuous function on $\mathbb R$. However, I do not see any elementary way to show that $g$ is $C^\infty$-smooth. (One could chop up the  Fourier transform of $g$ and thus reduce the problem to analytic functions, as one does in the proof of the Malgrange preparation theorem. But this looks like an overkill.) Related posts: The quotient of two functions How to show a function is a test function? Zeros of $C^\infty$ functions (which is the special case of the above, with accepted  answer that does not contain a   proof).","['derivatives', 'real-analysis']"
541054,"If $n$ is squarefree, $k\ge 2$, then $\exists f\in\Bbb Z[x_1,\dots,x_k] : f(\overline x)\equiv 0\pmod n\iff \overline x\equiv \overline 0\pmod n$","Starting from this question , we set $n=k=2$ and use the function $f\in\Bbb Z[x,y]$ where $f(x,y)=x\cdot y+x+y$, then the proofs applied to that question satisfy this case. Note that for $k=1$ the function $f(x)=x$ satisfies the title statement (except the $k$ condition) for all $n$, so this case is considered not to be part of this question. Note further that if $n$ is prime, the title statement is easy to prove: Let $n\ge 2$ and $k\ge 2$ and let $m$ be the multiplicative order$\mod n$.  The function $f\in\Bbb Z[x_1,\dots,x_k],f(\overline x)=\prod\limits_{i=1}^k(x^m-1)-(-1)^k$ will have value $f(\overline x)\equiv (-1)^k\pmod n$ whenever $\exists i:$GCD$(x_i, n)=1$ (since $x_i^m-1\equiv 0\pmod n$ in that case), so the important part to consider is $\forall i:$GCD$(x_i,n)\gt 1$.  For prime $n$, this will occur exactly when $\overline x\equiv \overline 0\pmod n$, so that case need not be considered further. What proof is there for the title statement for $n\ge 2,k\ge 2$ and $n$ is squarefree?  (Notation: $\overline x\in\Bbb Z^k$ is the ""vector $x$"" having dimension $k$; $\overline 0$ is the ""zero vector"" i.e., a vector of specified size having all entries be $0$.) To prove: For all $k\ge 1$ and squarefree $n$ there exists a function $f\in\Bbb Z[x_1,\dots,x_k] : f(\overline x)\equiv 0\pmod n\iff \overline x\equiv \overline 0\pmod n$ (proven, but feel free to offer an alternate proof, especially along the lines of the contrapositive) For all $k\ge 2$ and squareful $n$ no such function exists","['alternative-proof', 'discrete-mathematics']"
541082,Proving the inverse of a continuous function is also continuous,"Let $E, E'$ be metric spaces, $f: E\to E'$ a continuous function. Prove that if $E$ is compact and $f$ is bijective then $f^{-1}:E' \to E$ is continuous. I know one way to prove it is by showing that if $S\subset E$ and $S$ is closed then $f(s)\subset E'$ is also closed where $s\in S$. Since $S$ is closed then $p_n \in S$ and $p_n \to p_0$ in $E$ then $p_o\in S$. Since $E$ is compact there is a convergent subsequence. How can I do this proof?","['inverse', 'continuity', 'real-analysis', 'metric-spaces', 'compactness']"
541092,Why are the inverses of triangular matrices always triangular?,The inverse of an (invertible) upper triangular matrix is always upper triangular and the inverse of an (invertible) lower triangular matrix is always lower triangular. Why? I don't have any work to show and this isn't homework.,"['matrices', 'linear-algebra']"
541110,Show that $f(x)=x^2$ is continuous at $a=2$ using the $\delta-\epsilon$ definition of continuity.,"So we want to find a $\delta>0$
  such that for all $2-\delta<x<2+\delta$
 , we will have $4-\epsilon<x^{2}<4+\epsilon$ for all $\epsilon>0$
 . If we can find a way to express $\delta$  as a function $\delta (\epsilon)$,  $\delta:\mathbb{R}_+ \to \mathbb{R}_+ $ then we will have solved the problem. But I can't see how to relate $\epsilon$ to $\delta$ in this case. My initial reaction is write $(2-\delta)^2<x^2<(2+\delta)^2$, this makes the two inequalities look related, but I am not sure where to go from here.","['epsilon-delta', 'calculus', 'continuity']"
541118,Proving that sum of two measurable functions is measurable.,"Suppose $f$ and $g$ are Lebesgue measurable, we want to show $f+g$ is measurable. So, the hint is to consider the continuous functions $F : \mathbb{R}^2 \to \mathbb{R} $ given by $h(x) = F(f ,g ) $. If we can show $F$ Is measurable, then Taking $F = f +g $ would solve our problem. In other words, I want to show that the set $R = \{ (f,g) : F(f,g) > a $ } is lebesgue measurable.. But this set is just a rectangle in the plane. And since $F$ is continuous, then $R$ must be open, and hence a union of open rectangles which are measurable and hence $R$ must be measurable. Is this a correct approach to the problem? Can someone help me to make this formal? thanks","['real-analysis', 'analysis']"
541135,"Conjecture $\int_0^1\frac{\mathrm dx}{\sqrt{1-x}\ \sqrt[4]x\ \sqrt[4]{2-x\,\sqrt3}}\stackrel?=\frac{2\,\sqrt2}{3\,\sqrt[8]3}\pi$","$$\int_0^1\frac{\mathrm dx}{\sqrt{1-x}\ \sqrt[4]x\ \sqrt[4]{2-x\,\sqrt3}}\stackrel?=\frac{2\,\sqrt2}{3\,\sqrt[8]3}\pi\tag1$$
The equality numerically holds up to at least $10^4$ decimal digits. Can we prove that the equality is exact? An equivalent form of this conjecture is
$$I\left(\frac{\sqrt3}2;\ \frac14,\frac14\right)\stackrel?=\frac23,\tag2$$
where $I\left(z;\ a,b\right)$ is the regularized beta function . Even simpler case:
$$\int_0^1\frac{\mathrm dx}{\sqrt{1-x}\ \sqrt[6]{9-x}\ \sqrt[3]x}\stackrel?=\frac\pi{\sqrt3},\tag3$$
which is equivalent to
$$I\left(\frac19;\ \frac16,\frac13\right)\stackrel?=\frac12.\tag4$$ A related question .","['closed-form', 'calculus', 'integration', 'definite-integrals', 'conjectures']"
541139,Hard floor function problem,"Let $\left \lfloor{x}\right \rfloor $ denote the floor of $x$. Supose $m\in \mathbb{N}$, and that $t$ is a positive irrational number. Put $n=\left \lfloor{mt}\right \rfloor$. Prove that $$\sum_{k=1}^{m} \left \lfloor{kt}\right \rfloor +\sum_{k=1}^{n} \left \lfloor{\frac{k}{t}}\right \rfloor= mn$$","['ceiling-and-floor-functions', 'number-theory']"
541162,First order theory of abelian groups and first order theory of cyclic groups are coincide?,"Let $T$ be a first-order theory of cyclic groups. Even if an abelian group $(G,+)$ satisfy $(G,+)\models T$ there is no reason that $(G,+)$ is a cyclic. (For example, by Löwenheim–Skolem theorem there is uncountable abelian group $G$ that satisfy $T$.) I tried to find a first-order formula that is true for all cyclic groups, but is false for some abelian group. But I don't know how to find it. Thanks for any help.","['logic', 'group-theory', 'model-theory', 'abelian-groups']"
541175,Fast algebraic expansion,"Is there an algebraic trick to expand the following expression without multiplying each term with another, expanding the standard way it gives $6+6+6=18$ terms and then cancelling the same terms with opposite signs to get the final result, is there any shortcut? $(b+c-a)(y+z)+(c+a-b)(z+x)+(a+b-c)(x+y)$","['arithmetic', 'algebra-precalculus']"
541179,"If integral is zero and function is continuous and non negative, then what about the function? [duplicate]","This question already has answers here : Prove the integral of $f$ is positive if $f ≥ 0$, $f$ continuous at $x_0$ and $f(x_0)>0$ (2 answers) Closed 10 years ago . If $f$ is continuous on $[a,b]$, $f(x)≥0$ on $[a,b]$ and $$\int_{a}^{b} f(x) =0$$ then prove that $f(x)=0$ for all $x \in [a,b]$. I tried with Riemann's definite integral definition but couldn't proceed","['calculus', 'integration']"
541185,Minimum number of hemispheres covering a sphere,Here is a question which seems easy but seems to have many pitfalls. If I give you an arbitrary covering of the sphere by $N$ closed hemispheres. You can pick any of the hemispheres to keep. What is the minimum number you can keep while still covering the sphere? We suspect the answer is $4$ but we can't seem to prove it.,"['geometry', 'induction', 'combinatorial-geometry']"
541206,"How to show that $W^{2,\infty}(B_1)=C^{1,1}(\bar B_1)$?","Suppose that $B_1$ is the open unit ball in $\mathbb R^n$, denote $W^{2,\infty}(B_1)$ be the sobolev spaces and $C^{1,1}(\bar B_1)$ is the Holder spaces. It seems the equality $W^{2,\infty}(B_1)=C^{1,1}(\bar B_1)$ holds at  first glance, but how to move from intuition to a strictly argument? What's more, I don't know why closed $\bar B_1$ rather than $B_1$? Another thing: is this some kind of problem suitable for research or just a well known results?","['sobolev-spaces', 'partial-differential-equations', 'analysis']"
541210,What is the domain of $x^x$ as a real valued function?,"Consider the function $f(x) = x^x$. Wolfram alpha tells me that this function's domain is $x : x>0$, $x \in \mathbb{R}$. I can't see why it cannot be defined for a number like $(-2)$. I mean $(-2)^{-2}=0.25$, the same Wolfram Alpha told me. I realize that fractional powers for negative numbers may cause problems, but it could be defined for integers. Thanks for any help.","['calculus', 'functions']"
541221,Relations and Functions - Is my answer correct?,"Could someone please advise if my answer is correct or incorrect? Any help will be greatly appreciated. Given the sets $A = \{1, 2, 3\}$, $B = \{−1, 0, 1, 2\}$ and $C = \{3, 4, 5, 6\}$, indicate the members (pairs) in the following relations. Let $\Bbb N$ denote the natural numbers. (Note that in these definitions a comma ‘,’ is used as a less intrusive way of indicating predicate conjunction ‘$\land$’.) 1) $\{(x, n) \mid x \in A, n \in\Bbb N, n = 2 \cdot x\}$ Ans: $\{(1, 2), (2, 4), (3, 6)\}$ 2) $\{(x, z) \mid x \in A, z \in C, x = z − 1\}$ Ans: $\{(2,3),(3,4)\}$ 3) $\{(x, y, z) \mid x \in A, y \in B, z \in C, z = x + y\}$ Ans: $\{(1,2,3),(2,1,3),(2,2,4),(3,0,3),(3,1,4),(3,2,5)\}$ 4) $\{(x, y, z) \mid x \in A, y \in B, z \in C, z = x \cdot y\}$ Ans: $\{(2,2,4),(3,1,3),(3,2,6)\}$ 5) $\{(x, y, z) \mid x \in A, y \in B, z \in C, z = 100xy\}$ **Ans: NULL EDIT: I have edited this post and put in the answers I believe are correct. Thank you so much.","['relations', 'functions']"
541232,Evaluation of $\lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \ln \binom{2n}{n}$,"Evaluate $$\lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \ln \binom{2n}{n}.$$ $\underline{\bf{My\;\;Try}}::$ Let $\displaystyle y = \lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \ln \binom{2n}{n} = \lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \ln \left(\frac{(n+1)\cdot (n+2)\cdot (n+3)\cdots (n+n)}{(1)\cdot (2)\cdot (3)\cdots (n)}\right)$ $\displaystyle y = \lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \left\{\ln \left(\frac{n+1}{1}\right)+\ln \left(\frac{n+2}{2}\right)+\ln \left(\frac{n+3}{3}\right)+\cdots+\ln \left(\frac{n+n}{n}\right)\right\}$ $\displaystyle y = \lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \sum_{r=1}^{n}\ln \left(\frac{n+r}{r}\right) = \lim_{n\rightarrow \infty}\frac{1}{2n}\cdot \sum_{r=1}^{n}\ln \left(\frac{1+\frac{r}{n}}{\frac{r}{n}}\right)$ Now Using Reinman Sum $\displaystyle y = \frac{1}{2}\int_{0}^{1}\ln \left(\frac{x+1}{x}\right)dx = \frac{1}{2}\int_{0}^{1}\ln (x+1)dx-\frac{1}{2}\int_{0}^{1}\ln (x)dx =  \ln (2)$ My Question is , Is there is any method other then that like Striling Approximation OR Stolz–Cesàro theorem OR Ratio Test If yes then please explain here Thanks",['calculus']
541255,How does a left group action on the fiber of a principal bundle induce a right action on the total space?,"Suppose I define a ""principal $G$-bundle"" as follows: A principal $G$-bundle is a fiber bundle $F \to P \overset{\pi}{\to} X$ with a left group action of $G$ on $F$ that is free and transitive, together with a trivializing cover whose transition maps are $G$-valued. However, it seems that many references define ""principal $G$-bundle"" via a right action of $G$ on $P$ (not $F$). How does my definition induce a natural right action of $G$ on $P$?  Can this be done without saying the phrase ""identify $F$ with $G$""? The reason I would like to avoid this identification is two-fold.  First, I would like to keep the fiber $F$ and the group $G$ separate in my head -- at least for now -- in part because not all $G$-bundles are principal.  Second, and more importantly, I am concerned that any identification of $F$ with $G$ will involve an arbitrary choice of base-point of $F$, and I would rather not make such unnecessary choices if possible. Ultimately, I would like to say that the specified trivializations in my definition of ""principal $G$-bundle"" are $G$-equivariant with respect to the actions on $P$ and $F$.  I would like to deduce this as a consequence of the definition of the $G$-action on $P$, rather than taking this equivariance as the definition of the action. Aside: As usual, this question is a refinement of a previous, less focused question of mine.","['principal-bundles', 'geometric-topology', 'differential-geometry', 'fiber-bundles', 'differential-topology']"
541275,Why not $f(z)=z^2$ conformal at $z=0$?,$$f(z)=z^2$$ is not conformal at $z=0$ Why? Conformal definition: $f$ is conformal at z if f preserves angles there.,"['self-learning', 'conformal-geometry', 'complex-analysis', 'analysis']"
541305,The n-th root of a prime number is irrational [duplicate],"This question already has answers here : How to prove: if $a,b \in \mathbb N$, then $a^{1/b}$ is an integer or an irrational number? (14 answers) Closed 6 years ago . If $p$ is a prime number, how can I prove by contradiction that this equation  $x^{n}=p$ doesn't admit solutions in $\mathbb {Q}$ where $n\ge2$","['prime-numbers', 'irrational-numbers', 'real-analysis']"
541310,For what complex $z$ the series converges,"Can someone help me with this assignment? Find for what $z \in \mathbb{C}$ the series converges
  $\sum_{n=1}^{\infty} \frac{(2n)!}{(n!)^2}z^n$. I've just calculated (by using Cauchy-Hadamard theorem) that for all $z$ such that $|z|<\frac{1}{4}$ this series converges and for all $z$ such that $|z|>\frac{1}{4}$ it doesn't. I don't know how to check $|z|=\frac{1}{4}$.","['power-series', 'convergence-divergence', 'complex-analysis']"
541369,Torsion Subgroups and Periodicity,"I am trying to piece together elliptic curves in FLT and would greatly appreciate corrections to my summary (or attempts thereof). Mazur's paper ""Number Theory as Gadfly"" states, ""there is a natural way of identifying lattice with a with an orbit in the complex plane"" (and this would essentially be the hyperbolic uniformization?) He defines a hyperbolic uniformization to be a covering mapping from the half plane - {finite set of orbits} to an elliptic curve - {finite set of points}. Thus, he concludes that it is periodic. We can consider an elliptic curve E to be a torus over a lattice L, because E is doubly periodic (i.e., meromorphic). Viewing E as C/L gives information about the structure of the group of torsion points on E (according to Ribet). Now, a torsion subgroup of E(Q) would have elements P, such that P*n=0. It is also called periodic. So how is the torsion subgroup related to the periodicity found in elliptic curves and hyperbolic uniformizations? Thank you!","['algebraic-geometry', 'algebraic-groups', 'algebraic-curves']"
541383,why 64 is equal to 65 here? [duplicate],"This question already has answers here : How come $32.5 = 31.5$? (The ""Missing Square"" puzzle.) (8 answers) Closed 6 years ago . how is this possible? I know there is some trick, should someone please explain?!","['geometry', 'puzzle', 'fake-proofs']"
541386,"Two norms $\|\cdot\|_a$ and $\|\cdot\|_b$ on $X$, and a function $f:X\to Y$ Fréchet differentiable with one of the norms but not with the other one?","There is a theorem that if $f : (X,\|\cdot\|_{X1}) \to (Y,\|\cdot\|_{Y1}) $  is Fréchet differentiable, then replacing the norms with some equivalent norms $\|\cdot\|_{X2}$ and $\|\cdot\|_{Y2}$ preserves the differentiability. I was trying to construct an example where a function is not Fréchet differentiable anymore after replacing the norms with norms that aren't equivalent. The easiest example with not equivalent norms known to me is $\|x\|_\infty$ and $\|x\|_1$ on $C[0,1]$. Yet I can't think of any function, say, $f: C[0,1] \to \mathbb R$, that would be Fréchet differentiable with one of the norms but not with the other one. Any help with finding such an example (not necessarily with the above mentioned norms) is highly appreciated.","['normed-spaces', 'functional-analysis', 'real-analysis']"
541401,Symmetric relations,"Let $A=\{ 1, 2, 3, 4 \}$ is $ B = \{ (1, 2), (2, 1), (1, 3), (3, 1) \} $ Is $B$ a symmetric relation on $A$? I said no because not all $x, y \in A$ are in $B$ Is this correct?","['relations', 'elementary-set-theory']"
541416,Evaluating the limit $\lim_{n \rightarrow +\infty} \frac{e^n+e^{-n}}{e^{n+1}+e^{-n-1}}$,How would you solve the following limit? It's $\frac \infty \infty$ and L'Hospital doesn't seem to help: $$\lim_{n \rightarrow +\infty} \frac{e^n+e^{-n}}{e^{n+1}+e^{-n-1}}$$,"['calculus', 'limits']"
541451,Derivative Bilinear map,"I wanted to calculate the derivative of a continuous bilinear map $B: X_1 \times X_2 \rightarrow Y$. (Does anyhere know whether there is a generalisation of the notation $L(X,Y)$ that you use for the vector space of continuous linear maps to one for bilinear maps $B: X_1 \times X_2 \rightarrow Y$?)
Then we have $B(x_1 + h_1 , x_2 + h_2) = B(x_1,x_2) + B(h_1,x_2) + B(x_1,h_2) + B(h_1,h_2)$ Now I want to show that we have $\frac{B(h_1,h_2)}{|(h_1,h_2)|} \rightarrow 0$, but I do not know how.","['banach-spaces', 'functional-analysis', 'real-analysis', 'analysis']"
541461,How to find a conformal mapping of the first quadrant.,"Find a conformal mapping of the first quadrant onto the unit disc mapping the points $1+i$ and $0$ onto the points $0$ and $i$ respectively. I think that i need to use ""the change of variables $w=z^k$"" but how? And why do we apply this? Please can someone explain thisstep by step? 
Thanks alot:)","['self-learning', 'conformal-geometry', 'complex-analysis', 'analysis']"
541529,Power of a generator generates the group iff this power is coprime to the group order. [duplicate],"This question already has answers here : How to prove $\,{\rm order}(a^k) = n/\gcd(n,k)\,$ for $\,n={\rm order}(a)$? (4 answers) Closed 2 years ago . Let $\langle g\rangle$ be a cyclic group of order $n$. Suppose $1\leq q \leq n-1$, I want to show that $g^q$ generates $\langle g\rangle$ if and only if $\gcd(n,q)=1$. Suppose $g^q$ generates $\langle g\rangle$, then $$
1,g^q,g^{2q},...,g^{(n-1)q}
$$ are all distinct and $g^{nq}=1$, since $n$ is the order of the group. Note that this is the lowest multiple of $q$ for which this is the case. Therefore $\operatorname{lcm}(q,n)=qn$ and it follows that $q$ and $n$ are coprime. On the other hand, if $\gcd(q,n)=1$, then $\operatorname{lcm}(q,n)=qn$, we have $g^{nq}=1$ and hence all of $$
1,g^q,g^{2q},...,g^{(n-1)q}
$$ are distinct again and $g^q$ is a generator. Is my proof correct at all and is there maybe a more elegant argument?","['solution-verification', 'modular-arithmetic', 'cyclic-groups', 'finite-groups', 'group-theory']"
541532,Extending a connected open set,"Assume $\emptyset\neq V\subseteq U\subseteq\mathbb{R}^n$ are open and connected sets so that $U\setminus\overline{V}$ is connected as well. Given any point $x\in U$, is there always a connected open set $W\subseteq U$ so that $\{x\}\cup V\subseteq W$ and $U\setminus\overline{W}$ is connected? In other words, can $V$ be extended to a connected open set containing a given point so that the complement of the closure of the extended set is still connected?","['general-topology', 'connectedness', 'metric-spaces']"
541541,What is the kernel of the tensor product of two maps?,"Assume that $f_1\colon V_1\to W_1, f_2\colon V_2\to W_2$ are $k$-linear maps between $k$-vector spaces (over the same field $k$, but the dimension may be infinity). Then the tensor product $f_1\otimes f_2\colon V_1\otimes V_2\to W_1\otimes W_2$ is defined, and it's obvious that $\ker f_1\otimes V_2+ V_1\otimes \ker f_2 \subseteq \ker (f_1\otimes f_2)$. My question is whether the relation $\subseteq$ is in fact $=$. If this does not hold, how about assuming all these vector spaces are commutative associated $k$-algebras with identity and that all the maps are $k$-algebra homomorphisms? Or can you give a ""right"" form of the kernel $\ker (f_1\otimes f_2)$?","['vector-spaces', 'abstract-algebra', 'tensor-products', 'linear-algebra', 'multilinear-algebra']"
541545,Exercise II 2.8 on Hartshorne's Algebraic Geometry,"There are many people asking about exercises on this book. I've tried to check existing similar questions as many as I can, but I can't promise to have read everything. Sorry if this is duplicated. Let $X$ be a scheme. For any point $x \in X$, we define the Zariski tangent space $T_x$ to $X$ at $x$ to be the dual of the $k(x)$-vector space $\mathfrak m_x/\mathfrak m_x^2$. Now assume that $X$ is a scheme over a field $k$, and let $k[\varepsilon]/\varepsilon^2$ be the ring of dual numbers over $k$. Show that to give a $k$-morphism of $\text{Spec} k[\varepsilon]/\varepsilon^2$ to $X$ is equivalent to giving a point $x \in X$, rational over $k$ (i.e., such that $k(x) =k$), and an element of $T_x$. My Attempts: Suppose that $x \in X$ and $\alpha \in T_x$ is given. I think of determining the map of underlying topological spaces $f: \text{Spec} k[\varepsilon]/\varepsilon^2 \rightarrow X$. $k[\varepsilon]$ is a PID, so is $k[\varepsilon]/\varepsilon^2$. The nonzero ideals of $k[\varepsilon]/\varepsilon^2$ are of the form $(\varepsilon+a)$ for $a \in k$. (Right?) Some $(\varepsilon+a) = f^{-1}(x)$. Then $$f^{\sharp}: \mathcal O_x \rightarrow (k[\varepsilon]/\varepsilon^2)_{(\varepsilon+a)}.$$ Also $$\mathfrak m_x \rightarrow (\varepsilon+a)\text{ (in } k[\varepsilon]/\varepsilon^2 \text{)}$$ $$\mathfrak m_x/\mathfrak m_x^2 \rightarrow (\varepsilon+a)/(\varepsilon+a)^2 \text{ (in } k[\varepsilon]/\varepsilon^2 \text{)}.$$ Even if this map is given by $\alpha \in T_x$, how can we get the whole $f$? In the other direction, when the $k$-morphism $f: \text{Spec}k[\varepsilon]/\varepsilon^2 \rightarrow X$ is given, how can it determine $x \in X$ and some $\alpha \in T_x$?",['algebraic-geometry']
541565,"The MLE of a $N(\theta, 1)$ distribution","I am trying to find the Maximum Likelihood Estimator of an i.i.d. sample $X_1, \ldots, X_n$ arising from the model $N(\theta, 1)$, where $\theta \in [0,\infty)$. I have done this problem previously where the mean was not restricted to be non-negative, and found the MLE to be equal to the sample mean (as you would expect). Please could you explain why this situation is different and how it should be approached, as this is confusing me quite a bit! Many thanks.","['statistics', 'normal-distribution']"
541576,How to prove that the intersection of $L^1(\mathbb{R})$ and $L^2(\mathbb{R})$ is dense in $L^2(\mathbb{R})$ [duplicate],This question already has an answer here : Why is $L^1(\mathbb{R}^n) \cap L^2(\mathbb{R}^n)$ dense in $ L^2(\mathbb{R}^n)$? (1 answer) Closed 10 years ago . How to prove that the intersection of  $L^1(\mathbb{R})$ space and $L^2(\mathbb{R})$ space is dense in $L^2(\mathbb{R})$ space?,"['lp-spaces', 'functional-analysis', 'real-analysis']"
541619,"Proof that a sequence of continuous functions $(f_n)$ cannot converge pointwise to $1_\mathbb{Q}$ on $[0,1]$","As a homework question, we got asked the following: Construct a function $f:[0,1] \rightarrow \mathbb{R}$ which is not the pointwise limit of any sequence of continuous functions Thinking about it, a function which is nowhere continuous should be sufficient; thus I decided to try to use the indicator function on the rationals, $1_\mathbb{Q}$. Basically, I was just wondering if my proof was alright or not: Suppose $(f_n)$ is a sequence of continuous functions converging pointwise to $1_\mathbb{Q}$; thus for any $\epsilon > 0$ we have that for all $x$ we can find a $N$ such that if $n \geq N$ then $| f_n(x) - 1_\mathbb{Q} (x) | < \epsilon$. In particular, we have for some $x_1 \in \mathbb{Q}, x_2 \notin \mathbb{Q}$ a $N_1$ and $ N_2$ respectively such that if $ n \geq N_1$ then $ | f_n(x_1) - 1 | < \epsilon$ if $ n \geq N_2$ then $ | f_n(x_2) | < \epsilon$ Now, as $f_k$ is continuous, for any $\epsilon > 0$ we have that for all $x$ there exists a $\delta > 0$ such that if $ | x- y | < \delta$ then $|f_k(x) - f_k(y) | < \epsilon $. However, if we pick an arbitrary $x \in \mathbb{Q}$, for $n \geq \max\{N_1, N_2\}$, for any $\delta > 0$ we can pick a $ y \notin \mathbb{Q}$ such that $| x- y| < \delta$ yet $ | f_n(x) - f_n(y) - 1|  < 2\epsilon$ (by the triangle inequality and using the pointwise convergence properties); so if we choose $\epsilon = 1/10$, say, then we have by continuity that $|f_n(x) - f_n(y)| < 1/10$, yet $| f_n(x) - f_n(y) - 1|  < 1/5$, which (I believe) is absurd, so we have a contradiction. I'm a bit iffy about whether this is alright or not (I feel I may be subtly abusing the definitions here), so any feedback would be much appreciated.","['proof-verification', 'real-analysis']"
541630,Proving the cotangent function is uniformly bounded on the complex plane,"I'm trying to prove that the function $\cot\left(z\right)=i\frac{e^{iz}+e^{-iz}}{e^{iz}-e^{-iz}}$
  is uniformly bounded in the complex plane outside $\varepsilon$
  neighborhoods of the poles (with the bound depending on $\varepsilon$).
  The suggested method in my text is to first show that if $z=x+iy$
  and $y>0$
  then: $$\frac{e^{-2y}}{1+e^{-2y}}<\left|\cot\left(x+iy\right)+i\right|<\frac{e^{-2y}}{1-e^{-2y}}$$
 And if $y<0$
  then:$$\frac{e^{2y}}{1+e^{-2y}}<\left|\cot\left(x+iy\right)+i\right|<\frac{e^{2y}}{1-e^{-2y}}$$
 The calculations are a bit tedious and they aren't coming out right for me for some reason:
\begin{align*}
\left|\cot\left(x+i\cdot y\right)+i\right|
&=\left|i\cdot\frac{e^{iz}+e^{-iz}}{e^{iz}-e^{-iz}}+i\right| \\
&=\left|i\cdot\frac{e^{2iz}+1}{e^{2iz}-1}+i\right| \\
&=\left|\frac{i\cdot\left(e^{2iz}+1\right)+i\left(e^{2iz}-1\right)}{e^{2iz}-1}\right| \\
&=\left|\frac{2ie^{2i\left(x+i\cdot y\right)}}{e^{2i\left(x+i\cdot y\right)}-1}\right| \\
&=\left|2i\right|\cdot\left|e^{2iz}\right|\left|\frac{1}{e^{2iz}-1}\right|=2\cdot e^{-2y}\cdot\left|\frac{1}{e^{2iz}-1}\right| \\
&=2\cdot e^{-2y}\cdot\left|\frac{e^{2y}}{e^{2ix}-e^{2y}}\right| \\
&=2\left|\frac{1}{e^{2ix}-e^{2y}}\right| =2\frac{1}{\left|e^{2ix}-e^{2y}\right|} \\
&=2\cdot\frac{1}{\left|e^{ix}-e^{y}\right|\left|e^{ix}+e^{y}\right|} \\
&=\frac{2}{\sqrt{\left(e^{y}+\cos\left(x\right)\right)^{2}+\sin^{2}\left(x\right)}\cdot\sqrt{\left(e^{y}-\cos\left(x\right)\right)^{2}+\sin^{2}\left(x\right)}} \\
&=\frac{2}{\sqrt{e^{2y}+2e^{y}\cos\left(x\right)+1}\cdot\sqrt{e^{2y}-2e^{y}\cos\left(x\right)+1}} \\
&=\frac{2}{\sqrt{e^{4y}+2e^{2y}-4e^{2y}\cos^{2}\left(x\right)+1}} \\
&=\frac{2}{\sqrt{\left(1+e^{2y}\right)^{2}-4e^{2y}\cos^{2}\left(x\right)}}
\end{align*}
The denominator is maximal when $\cos^{2}\left(x\right)=1$
and minimal when $\cos^{2}\left(x\right)=0$
and thus:
$$\frac{2e^{-2y}}{1+e^{-2y}}=\frac{2}{1+e^{2y}}\leq\left|\cot\left(x+i\cdot y\right)+i\right|\leq\frac{2}{\sqrt{\left(e^{2y}-1\right)^{2}}}=\frac{2}{\left|1-e^{2y}\right|}=\frac{2e^{-2y}}{1-e^{-2y}}.$$
  I can't figure out whether I made an error in the calculations or whether there was an error in the suggested bound. I'm also not sure how to use these bounds in order to reach the required conclusion. Regardless of this method I'm also curious whether someone has an alternative and perhaps less technical method of proving the claim. Thanks in advance!",['complex-analysis']
541643,How to find the LCM of One Negative and one positive Integer,"The title pretty much explains my question. While studying theory of numbers I came across this problem. The way I did LCM in childhood gave me a negative result.Maybe the method I used is wrong. But according to the book,
LCM(-8,20)= 40 If I use the formula LCM(a,b)= |a.b|/GCD(a,b), Then I get the right answer. But this involves finding out gcd first. Is there a direct way to solve this problem? Thank you in advance.","['elementary-number-theory', 'gcd-and-lcm', 'discrete-mathematics']"
541644,Why $p \leftrightarrow q$ is equivalent to $(p \wedge q) \vee (\neg p \wedge \neg q)$? Without using the truth table [duplicate],This question already has answers here : proving logical equivalence $(P \leftrightarrow Q) \equiv (P \wedge Q) \vee (\neg P \wedge \neg Q)$ (4 answers) Closed 7 years ago . I want to know why $p \leftrightarrow q$ is equivalent to $(p \wedge q) \vee (\neg p \wedge \neg q)$? Without using the truth table. Thanks all,['discrete-mathematics']
