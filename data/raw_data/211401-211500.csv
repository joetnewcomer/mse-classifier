question_id,title,body,tags
4254306,Natural-Forced and Transient-SteadyState pairs of solutions,"We have the following circuit, where, $u(0)=V_{0}$ . The ode that describes this circuit that has $V_{s}$ as input and the voltage $u(t)$ of the capacitor as output is the following: $\dot{u} + \tau u = \tau V_{s}$ , where $\tau=\frac{1}{RC}$ . If I solve the ode, this way : for the homogeneous part, we have $u_{h}(t)=ce^{\lambda t}$ . After replacing it to the initial equation, we find that $\lambda=-\tau$ , and we get $u_{h}(t)=ce^{-\tau t}.$ To find the particular solution, we consider $u_{p}(t)=AV_{s}$ and after the replacement we get $A=1$ , which makes $u_{p}(t)=V_{s}$ Their sum is: $u(t)=ce^{-\tau t}+V_{s}$ , and by applying the initial condition, we get that $c=V_{0}-V_{s}$ Therefore, the total solution is: $u(t)=(V_{0}-V_{s})e^{-\tau t}+V_{s}$ the homogeneous solution coincides with the transient solution, while the particular
one coincides with the steady-state solution If I solve it, that way : The homogeneous part it's the same as before, so: $u_{h}(t)=ce^{-\tau t}$ . We find the particular solution by using directly the following equation: $u_{p}(t)=e^{-\int_{0}^{t}\tau  dt }\int_{0}^{t} (\tau V_{s} e^{\int_{0}^{t}\tau  dt })dt=e^{-\tau t}V_{s}(1-e^{\tau t})=V_{s}(1-e^{\tau t})$ Their sum is: $u(t)=ce^{-\tau t}+V_{s}(1-e^{\tau t})$ , and by applying the initial condition, we get that $c=V_{0}$ Therefore, the total solution is: $u(t)=V_{0}e^{-\tau t}+V_{s}(1-e^{\tau t})$ the homogeneous solution coincides with the natural solution, while the particular
one coincides with the forced solution Of course the total solutions are identical but I would be interested in knowing why the one way yields directly the $u_{natural}$ - $u_{forced}$ pair, while the other way yields directly the $u_{transient}$ - $u_{steady-state}$ pair.","['steady-state', 'ordinary-differential-equations']"
4254314,Solving a quadratic equation problem with two variables,"This is a post of two three problems regarding the method to solve bivariate quadratic equations. In brief, How does the elimination happen here . Or, how is the elimination used? ( Update, I know how this is done now. See update below ) Is the method below viable? If not, how to solve this problem in matrix format? (Update) Nope, this method below is not viable because rank 2 matrices cannot be factorized. And an alterative matrix method can be seen in chapter 11 of this book . (Update) I also post a method. Is it valid and complete? In order to be complete, some measurements should be done to avoid the case where there are no solutions (i.e., conics don't intersect) The very source of the problem is: $\begin{cases}
a_1x^2 + b_1y^2 + c_1xy + d_1x + e_1y + f_1 = 0 \\
a_2x^2 + b_2y^2 + c_2xy + d_2x + e_2y + f_2 = 0 
\end{cases}$ (Problem 1) I find a method here , but it does not tell me how the elimination work. How did the elimination work? (Backgrounds of problem 2) I heard that this problem also can be solved by matrices: Say we convert the equations into $\begin{cases}
X^TAX = 0 \\
X^TBX = 0 \\
X = \begin{bmatrix}x &y &1\end{bmatrix}^T
\end{cases}$ where $A$ and $B$ are symmetric and are obtained from the two equations respectively. And if $rank(A) = 3$ and $rank(B) =3$ (which happens most of the cases for randomly generated real symmetric matrices), to find the solution, one should find the eigenvalue of $A^{-1}B$ , i.e., $[V, D] = eigs(A^{-1}B)$ , where $V$ is the eigenvector matrix and $D$ is the eigenvalue matrix. Then we can always find $ X^T(\lambda{A} - B)X = 0$ , where $\lambda$ is the diagonal value of matrix $D$ . ( $\lambda{A} - B$ ) is guaranteed to have a rank of lower than 3 since its determinant is $0$ , and either it can be rank $1$ or rank $2$ . Let's call it $C$ . Then I do another diagonalization, such that $X^TCX = X^TP^{-1} D_C PX = X^TP^T D_C PX = (PX)^TD_C(PX) = PX \cdot D_CPX$ , where $D_C$ is the diagonal matrix for $C$ , and $P$ is its corresponding  eigenvector matrix. Assume $D_C = \begin{bmatrix} \lambda_{C1} & 0 & 0 \\ 0 & \lambda_{C2} & 0 \\ 0 & 0 & \lambda_{C3} \end{bmatrix}$ , $P= \begin{bmatrix} p_1 & p_4 & p_7 \\ p_2 & p_5 & p_8 \\ p_3 & p_6  & p_9 \end{bmatrix}$ , $\lambda_{C3} = 0$ Then the final result is something like: $\lambda_{C1} (p_1 x + p_2 y + p_3)^2 + \lambda_{C2} (p_4 x + p_5 y + p_6)^2 = 0$ (Problem 2) is the following true? If yes, prove it and express the equation in a factorized format (You can use any notation if you want). If not, how to solve in matrix format? The rank of matrix $C$ , as I tested with Matlab scripts, can be either $1$ or $2$ . In that post (I don't know where it is now), he says each eigenvalue corresponds to a $C$ , and $X^TCX=0$ corresponds to a factorized quadratic equation so that you can find $3$ equations that has the format of: $\begin{cases}
Eq_1 = (m_{11}x+m_{12}y+m_{13})(m_{14}x+m_{15}y+m_{16}) = 0 \\
Eq_2 = (m_{21}x+m_{22}y+m_{23})(m_{24}x+m_{25}y+m_{26}) = 0 \\
Eq_3 = (m_{31}x+m_{32}y+m_{33})(m_{34}x+m_{35}y+m_{36}) = 0 \\ 
\end{cases}$ And $Eq_3$ can be removed because ""it is not telling anything new"" and can be represented by $Eq_1$ and $Eq_2$ . There are $4$ solutions in total by solving the systems of equations below: Solve $(x_1, y_1)\begin{cases}
m_{11}x+m_{12}y+m_{13} = 0 \\
m_{21}x+m_{22}y+m_{23} = 0
\end{cases}$ Solve $(x_2, y_2)
\begin{cases}
m_{11}x+m_{12}y+m_{13} = 0 \\
m_{24}x+m_{25}y+m_{26} = 0
\end{cases}$ Solve $(x_3, y_3)
\begin{cases}
m_{14}x+m_{15}y+m_{16} = 0 \\
m_{21}x+m_{22}y+m_{23} = 0
\end{cases}$ Solve $(x_4, y_4)
\begin{cases}
m_{14}x+m_{15}y+m_{16} = 0 \\
m_{24}x+m_{25}y+m_{26} = 0
\end{cases}$ (Edited for some grammatical problem) Any $(m_{1}x+m_{2}y+m_{3})(m_{4}x+m_{5}y+m_{6})$ is not different from $ = 
\begin{bmatrix} x &y & 1\end{bmatrix}
\begin{bmatrix} m_1 \\ m_2 \\ m_3\end{bmatrix}
\begin{bmatrix} m_4 & m_5 & m_6\end{bmatrix}
\begin{bmatrix} x\\y\\1\end{bmatrix} = 
\begin{bmatrix} x &y & 1\end{bmatrix}
\begin{bmatrix} 
m_1 m_4 & m_1 m_5 & m_1 m_6 \\ 
m_2 m_4 & m_2 m_5 & m_2 m_6 \\ 
m_3 m_4 & m_3 m_5 & m_3 m_6 \\ 
\end{bmatrix}
\begin{bmatrix} x\\y\\1\end{bmatrix}
$ The method is proved to be invalid. But can someone solve it with matrix form? (Edited for proof) I find a solution in Perspectives on Projective Geometry by Jurgen Richter-Gebert. The process is seen in chapter 11 of this book . (Edited for finding one complete solution) Okay, I am still not satisfied. So I want to make a method as well. It seems like we can always do the following step because eigenvalues of symmetric matrices are always real. $C_{12} = \sqrt{\lambda_{C1}} (p_1 x + p_2 y + p_3) = \pm\sqrt{-\lambda_{C2}} (p_4 x + p_5 y + p_6)$ The $_{12}$ notation above means there are two equations ( $C1$ and $C2$ , plus and minus respectively) written into one. And with three eigenvalues we will have three groups of equations that look like this below (Shown two, but actually three). After some work, both equations can always be written as $\begin{bmatrix}c_1 & c_2 & c_3\end{bmatrix}$ $\begin{bmatrix}x \\ y \\ 1\end{bmatrix}$ = 0, which represents a line. $C_1$ and $C_2$ represent two branches of solution. Then, for a different eigenvalue, we will have $C_{34}$ ( $C_3$ and $C_4$ ). Similarly, $C_3$ and $C_4$ represent two branches of solution. A set of solution can be obtained from, similar to the last method, $\begin{cases}
C_1 = 0 \\
C_3 = 0
\end{cases}\rightarrow (x_1, y_1)$ $\begin{cases}
C_1 = 0 \\
C_4 = 0
\end{cases}\rightarrow (x_2, y_2)$ $\begin{cases}
C_2 = 0 \\
C_3 = 0
\end{cases}\rightarrow (x_3, y_3)$ $\begin{cases}
C_2 = 0 \\
C_4 = 0
\end{cases}\rightarrow (x_4, y_4)$ For combination of different ranks of matrices, the strategy is about finding two degenerate combinations ( $\det(\lambda_1 A + \mu B)$ ) such that we have two groups of lines. If both full rank (i.e., the combinations of $(\lambda , \mu)$ should not have a zero in it), we need to use two different eigenvalues of one matrix and establish two new degenerate cases. If one is full rank and one is singular (i.e., one of the combination of $(\lambda , \mu)$ has a zero in it), then we only need one more degenerate case. If both are singular, then we already have two degenerate cases. (In the combination, two of them should be $(something_1, 0)$ and $(0, something_2)$ ). Question 3: Why can we just use two of the three will be fine for both full rank cases? I did not prove this yet, because I am new to this question (saw it 3 days ago). But with some educated guess, just imagine the solutions are the lines that intersect on the intersection of conics (four points). You can draw three ""kinds"" of lines. Each two lines are parallel. The ""three"" here corresponds to three eigenvalues. The two parallel lines corresponds to the $\pm$ cases (two branches). If you pick any two combination of groups you can always find the four points and it is just up to you to use which two of them. (Edited for posting an alternative method) Allow me to make some stupid jokes, here's a not so detailed procedure on how to find the quartic equation. First, treat $x$ as a constant in the function, then we can find y as a function of $x$ , where there are two parts, one with square roots and one without. I'd like to write this as: $y = notsoshit_{1}(x) \pm shit(x)$ , And let's consider $notsoshit_{2}(x) = shit(x)^2$ because function without square roots are good elements in the bigger function. I want to avoid derive this myself and it is really... long. The $notsoshit$ functions contain elements that are not independent to what we have in the original functions, and then they can disappear (although it can be lengthy). Thus, substitute this into the original two equations, you will get something like $\begin{cases}
a_{3}x^2 + b_{3}shit(x)x  + c_{3}x + d_{3}shit(x) + e_{3} = 0 \\
a_{4}x^2 + b_{4}shit(x)x  + c_{4}x + d_{4}shit(x) + e_{4} = 0
\end{cases}$ Then we should eliminate the shit(x) element (Choose either one function to eliminate $d$ ). The next step is putting $shit(x)x$ to R.H.S., so that no square roots on L.H.S., and then make do a square for this function, so that no square roots on both sides. It is something like: $(a_{5}x^2+b_{5}x + c_{5})^2 = d_{5}(shit(x) x)^2 = d_{5}notsoshit_{2}(x)x^2$ After some work it will be in the beautiful format: $a_{6}x^4+b_{6}x^3 + c_{6}x^2 + d_{6}x + e = 0$ I am not sure how wolfram did this process (Link in the very front), but then the mission is to eliminate $shit(x)$ by adding the two equations with some ratios. (Edited for posting the method for elimination /Problem 1)","['systems-of-equations', 'conic-sections', 'matrices', 'quartics', 'quadratics']"
4254324,"Two equal parabolas with foci at S and S' touch each other at point P, such that PS'=PS. If the parabola with focus S is fixed, find the locus of S'","Two equal parabolas with foci at S and S' touch each other at point P,
such that PS'=PS. If the parabola with focus S is fixed, find the
locus of S' Hint given : Let the common tangent be L. PS and PS' are equally inclined to L which implies that P,S,S' are collinear or SS' is perpendicular to L. Thus the locus will be a parabola or directrix of a fixed parabola My attempt : I can't figure out how to prove that PS and PS' are equally inclined to L. I've assumed the fixed parabola to be a standard one, with vertex at the origin. If we join S and S' and construct a perpendicular from P to SS', we can prove the two triangles are congruent. Thus S,S',P have to be collinear, or SS' is perpendicular to L. Case 1 :S,S',P are collinear Assume P to be $(at^2,2at)$ and S to be (h,k) Then, $(h-a)^2+k^2=2a(t+1)^2$ , where t is the parameter. This looks like it will give a parabola upon plotting the locus, but I can't think of a proof. Case 2: SS' is perpendicular to L Then SS' will be the normal to the parabola, and the mirror image of the focus of the parabola about the tangent lies on the directrix. So the locus o S' in this case will be a straight line.","['conic-sections', 'soft-question', 'geometry']"
4254358,Question about calculating a series involving zeta functions,"On this page it had shown that the sum of $\frac{1}{n^3(n+1)^3}=10-\pi^2$ . I'm curious about, what is the value of $$\sum_{n=1}^\infty\frac1{n^3(n+k)^3}$$ For some positive integer $k$ . According to partial fraction expansion, we can show that $$\frac1{n^3(n+k)^3}= 6\bigg(\frac1{nk^5}-\frac1{(n+k)k^5}\bigg)-3\bigg(\frac1{k^4n^2}+\frac1{k^4(n+k)^2}\bigg)+\frac1{k^3n^3}-\frac1{k^3(n+k)^3}$$ It is obvious to show that the first part and the last part are telescoping series, and for the last part, we can see that $$\frac1{k^3n^3}-\frac1{k^3(n+k)^3}=\frac1{k^3}\bigg(\frac1{n^3}-\frac1{(n+k)^3}\bigg)=\frac1{k^3}\sum_{i=1}^{k}\frac1{i^3}=\zeta(6)+\sum_{i<j}\frac1{i^3j^3}=\sum_{n=1}^\infty\frac1{n^3(n+k)^3}$$ Which leads to the original question. The particular values of the sum are $k$ $$\sum_{n=1}^\infty\frac1{n^3(n+k)^3}$$ $1$ $10-\pi^2$ $2$ $\frac {21}{32}-\frac1{16}\pi^2$ $3$ $\frac {809}{5832}-\frac1{81}\pi^2$ We can easily know that the sum is in the form of $a+b\pi^2$ and $b=\frac1{k^4}$ . So what about the value of $a$ ? Edit: Some notes on $\zeta(3)$ : By squaring $\zeta(3)$ , $$(\zeta(3))^2=\zeta(6)+\sum_{i\ne j}\frac1{i^3j^3}$$ . Note that $i$ and $j$ are both integers and we can assume that $i$ is strictly larger than $j$ , or we could say that $i=n$ , $j=n+k$ for some positive integer $k$ . Hence $$(\zeta(3))^2=\zeta(6)+2\sum_{k=1}^{\infty}\sum_{n=1}^{\infty}\frac1{n^3(n+k)^3}$$ Assume $\sum_{n=1}^\infty\frac1{n^3(n+k)^3} = a_k-\frac{\pi^2}{k^4}$ . Thus we can know $$\begin{align}(\zeta(3))^2&=\zeta(6)+2\sum_{k=1}^{\infty}\bigg(a_k-\frac{\pi^2}{k^4}\bigg)\\&=\frac{\pi^6}{945}+2\sum_{k=1}^{\infty}a_k-2\pi^2\zeta(4)\\&=2\sum_{k=1}^{\infty}a_k-\frac{4\pi^6}{189}\end{align}$$ For $\sum_{k=1}^{10}a_k$ , we can calculate that $$\begin{align}(\zeta(3))^2&\approx 2\sum_{k=1}^{8}a_k-\frac{4\pi^6}{189}\\&\approx 1.42163941214...\end{align}$$ And $(\zeta(3))^2\approx1.44494079841...$","['riemann-zeta', 'summation', 'sequences-and-series']"
4254367,"Is the second, third, and nth standard deviation an established concept?","Of course the first standard deviation is a measure that shows the level of variation among a set of values, and is of course derived by taking the sqrt of mean squared differences of the values to their mean. But what if you needed to know the level of variation OF the variation of the set of values. This would be the second standard deviation, and would be derived by taking the sqrt of mean squared differences of the residuals to their standard deviation. And in the same way: the third, fourth, and nth standard deviation.","['statistics', 'standard-deviation']"
4254385,"If $A=[ij(i+j)]_{n \times n}$, why $\det(A)=0$, when $n>2$","My numerical experiments suggest that if $A=[ij(i+j)]_{n \times n}$ , then $\det(A)=0$ , $i,j \in[1,n] $ and $n>2.$ What could be an analytic proof for this observation? Can there be a general result? EDIT: Further, if $A=[(i+j)^k]_{n\times n}$ , then $\det(A)=0$ for $n\ge 2+k$ . The idea of degree of polynomial $k$ seems to work here according to the rank connection: $ rank(A+B+C+...) \le[ rank(A)+ rank(B)+rank(C)+...]$ or the matrices as pointed out by @orangeskid in his answer below. This is why for $A=[i^k+j^k]_{n\times n}, k=1,2,3,4,5,...$ we have $\det(A)=0$ for $n\ge 3$ (independent of $k$ ).","['matrices', 'determinant']"
4254407,Is there an open bijective map from $\mathbb{R}$ to $\mathbb{R}$ that is not continuous?,"I came upon this when trying to solve a similar problem first: Open maps which are not continuous (1), which is essentially my problem without requiring the map to be bijective. To my knowledge, there are a bunch constructions satisfying the weaker constraints: Conway base 13 function( https://en.wikipedia.org/wiki/Conway_base_13_function ), a cool one using Riemann Series Theorem (see (1)), and basically all strongly Darboux functions. The problem is that all these constructions are not bijective, and I'm looking for a bijective example. Immediately this disqualifies all strongly Darboux functions, as they are not bijective on any open set, and this is my progress so far.","['general-topology', 'open-map', 'examples-counterexamples', 'real-analysis']"
4254413,Permutations of a word if you can use both uppercase and lowercase,"I know how I would arrange letters of a word if only uppercase or lowercase was allowed, but how would I solve a problem when each letter can be either? For example, for the letters ANAGRAM using only uppercase, the number of arrangements would just be $7!/3!$ . However, what if something like AnaGraM or aNagRAM was allowed and they are considered different from each other? How many arrangements of these letters would there be if both uppercase and lowercase were allowed?","['permutations', 'combinatorics', 'discrete-mathematics']"
4254452,"How to prove that the matrix P has eigenvalues $1,-\frac{1}{2},\cdots,(-1)^{n-1}\frac{1}{n}$?","I came up with this when trying to solve a problem of a markov chain with the transition matrix $$P=\begin{bmatrix} 0,0,0,\cdots,1\\ 0,0,\cdots,\frac{1}{2},\frac{1}{2}\\ 0,\cdots,\frac{1}{3},\frac{1}{3},\frac{1}{3}\\ \cdots\cdots\\ \frac{1}{n},\cdots,\frac{1}{n},\frac{1}{n} \end{bmatrix}$$ and it asked me to find $$\lim\limits_{k \rightarrow +\infty}{P^k}\alpha$$ where $\alpha=(0,1,\cdots,n-1)^\top$ . So, I tried to diagonalize $P$ and surprisedly found that it has eigenvalues $1,-\frac{1}{2},\cdots,(-1)^{n-1}\frac{1}{n}$ when $n\leq 7$ .So I wonder if this is true for all $n$ from $N^+$ and then how to calculate $$\lim\limits_{k \rightarrow +\infty}{P^k}\alpha$$ Thanks!","['matrices', 'linear-algebra', 'markov-chains', 'eigenvalues-eigenvectors']"
4254469,How to prove that $4 \cot ^{-1}\left(\sqrt{\phi }\right)+\cot ^{-1}\left(\frac{1}{4} \sqrt{22+17 \sqrt{5}}\right)=\pi$,"Trying to answer this question (five years too late), I found to the surprising identity $$4 \cot ^{-1}\left(\sqrt{\phi }\right)+\cot ^{-1}\left(\frac{1}{4} \sqrt{22+17
   \sqrt{5}}\right)=\pi$$ How to prove it ?",['trigonometry']
4254480,Question about the encyclopedia of triangle centers,"The Encyclopedia of Triangle Centers has developed a neat approximate way to check whether an entry about a particular point already exists. It involves checking the first coordinate of the normalized trilinears of the ""new"" point against a list of all points. All entries in the ETC however also list interesting properties of points, e.g. "" X(44004) lies on these lines: {2, 35311}, {20, 10620}, {3448, 9033}, {5965, 43768}, {15319, 15801} "" My question is where do people get the data about tens of thousands of points to determine this, presumable in an automated way? I cannot imagine that this comes out of random checks, and also it is difficult to imagine that hundreds of contributors have typed all known points' barycentric coordinates in their own code to facilitate automatic checks.","['euclidean-geometry', 'triangles', 'geometry']"
4254512,"Let $A,B\in M_3(\mathbb{C})$ be invertible matrices such that $AB=BA=X$, $A^{T}+A=B^{T}+B=X^{T}+X$. Then, is $\det(X - I) = 0$?","Let $A,B\in M_3(\mathbb{C})$ be invertible matrices such that $AB=BA=X$ , $A^{T}+A=B^{T}+B=X^{T}+X$ , then: (A) $A=B$ (B) $\det(A-I)=0$ (C) $\det(B-I)=0$ (D) $\det(X-I)=0$ My working: $AB+(AB)^T=X+X^T\implies AB+B^TA^T=B+B^T\implies (A-I)B+B^T(A^T-I)=O_3$ $\implies (A-I)B+((A-I)B)^T=O_3\implies (A-I)B$ is skew symmetric matrix of order $3$ $\implies \det(A-I)=0$ . Similarly $\det (B-I)=0$ . How to check option D any counter example for D? Further progress: $A^T+A=B^T+B\iff A= \begin{pmatrix} \alpha & a_1 & a_2 \\ x-a_1 & \beta & a_3 \\ y-a_2 & z-a_3 & \gamma \end{pmatrix}$ and $B =\begin{pmatrix} \alpha & b_1 & b_2 \\ x-b_1 & \beta & b_3 \\ y-b_2 & z-b_3 & \gamma \end{pmatrix}$ . Counter example for (A): $A=I_3$ and $B= \begin{pmatrix} 1 & b_1 & b_2 \\ -b_1 & 1 & b_3 \\ -b_2 & -b_3 & 1 \end{pmatrix}\implies AB=BA=B\implies X=B$ . We can see that all conditions meet out and $A\ne B$ for at least one $b_i\ne0$ .","['matrices', 'skew-symmetric-matrices', 'linear-algebra']"
4254546,How can I derive $~\frac{d}{dx}\left(\exp\left(\int f\left(x\right)dx\right)\right)=\exp\left(\int f\left(x\right)dx\right)\cdot f\left(x\right)~$?,"$$  P:=\text{function which only contains } ~x~ \text{as variable}  $$ $$  I:= \exp\left(\int P dx\right) $$ I want to derive the below equation . $$  \frac{  d  }{ dx   } \left( \exp\left(\int P dx\right)  \right) = I \cdot P = \exp\left(\int P dx\right)  \cdot P $$ By the way I assumed that $~ P ~$ can be a constant function of $~ x ~$ . For instance $~ P= 1 ~$ is allowed . The following info are the things which I know (WIP). $$  a \in\mathbb{R}  $$ $$ \frac{  d  }{ dx   } \left( \exp\left(ax\right)  \right) = a \cdot \exp\left(a x\right)  $$ Resetted info of $~ a ~$ $$  \frac{  d  }{ dx   }  \left( \int_{a }^{x } f(t) \,dt   \right)  $$ $$ = \frac{  d  }{ dx   }  \left[ F(t) \right]_{a}^{x}  $$ $$ = \frac{  d  }{  dx  } \left\{ F(x)-F(a) \right\}  $$ $$ = \frac{  d  }{ dx   } F(x) -  \underbrace{\frac{  d  }{ dx   } F(a)}_\text{ constant}  $$ $$ = f(x) $$","['derivatives', 'exponential-function', 'ordinary-differential-equations']"
4254557,"I understand $Δy(x)$ as the difference between an output and another output of the same function, but i cant conceptualize $Δ^n y(x)$","I find $Δ^n y(x)$ to be quite confusing and i dont know if i have understood it correctly. Does it mean simply raising the $Δy(x)$ difference to a power, or something else entirely? I know the formula of finding $Δ^n y(x)$ but im having trouble conceptualizing what it actually means. The information about it on the internet is also very sparse, except for some advanced sources that my current math knowledge dont allow me to comprehend Edit more context: I saw it in a chapter which is about recursive functions. In short, it says that recursive equations and difference equations are equivalent. E.g. it says that $$\Delta^3 y(x)−2\Delta^2y(x)+5\Delta y(x)+7y(x)=3\cos x$$ can be expressed as $$y(x+3)−5y(x+2)+12y(x+1)−y(x)=3\cos x$$ But thats how the chapter starts and doesnt provide further context",['functions']
4254559,Is the Cauchy-Goursat theorem or even the homotopic invariance theorem valid for fields other than $\Bbb C$ which are similar to $\Bbb R^2$?,"Clearly, the Green's Theorem proof does not hold as that relies on the specific conditions of complex differentiability. However, Goursat's proof involving the triangle case and building up from there invokes the Cauchy-Riemann equations nowhere, and just requires a basic definition of differentiability that satisfies: $$f(x+h)-f(x)-f'(x)h=\psi_x(x+h)h$$ Where $\psi_x(x+h)h$ can be made as small as desired. It also requires some basic topology and geometric properties of triangles, so I believe any $\Bbb R^2$ -type space with the Euclidean topology would satisfy Goursat's lemma. Moreover, the use of this lemma to prove the Cauchy Integral Theorem again requires only some basic notion of contour (or line) integrability, and antiderivatives, which the space $\Bbb R^2$ also has. The homotopic invariance theorem relies on properties of compact sets, which exist in the Euclidean topology, and not really any much else. This leads to believe that if you have a space which is: Complete Has a notion of differentiability satisfying the above Has a notion of antiderivative, Riemann sum and line integral Is two-dimensional with the Euclidean topology Has compact sets and uniform continuity of continuous functions on them Then you have homotopic invariance of line integrals of differentiable functions. You can't quite have the Cauchy Integral Formula, as $2\pi i$ is not defined without letting $i$ be complex, however similar expressions to do with winding numbers could arise in other spaces. For example, by my reasoning, we have the above theorems valid in: $\Bbb R^2$ The split-complex numbers The dual numbers Yet these theorems are always touted as important results of complex analysis, implying that I'm missing something here. What about the proofs of any of these theorems is complex-specific?","['complex-analysis', 'split-complex-numbers', 'real-analysis']"
4254589,Understanding contour integral with branch cuts,"I was trying to understand contour integral which have or those involving branch cuts. Like $$I=\int_0^\infty\frac{dx}{x^3+1}$$ because the integrand is not even we cannot extend the integration to the whole real axis and then halve the result. However, suppose we look at the contour integral $$J=\oint_C\frac{\ln z \:dz}{x^3+1}$$ around the Keyhole contour . Everything seems nice until now. But then I get to know that ""There is a connection between $J$ and the original definite integral $I$ "" $$J=2\pi iI$$ I get the partial intuition from one of M.SE answer, but couldn't understand the logic. \begin{align}&\bbox[10px,#ffd]{\oint_C\frac{\ln z}{1+x^3}dz}=2\pi i\sum\text{Res}f(z)=\int_0^\infty\frac{\ln z}{1+z^3}dz+\int_\infty^0 \frac{\overbrace{\ln z+2\pi i}^\star}{1+z^3}dz=-2\pi i\int_0^\infty\frac{1}{1+z^3}dz\end{align} Here I don't understand the $\star$ . I think $\ln z=\ln r+i\theta+2\pi in$ used, but aren't we evaluate the integral on same branch? Then why to consider $2\pi i$ ? Some contour integral which have branch cuts use wedge-shaped contour. Where $\Gamma = \Gamma_1 + \Gamma_2 + \Gamma_3$ going in a straight line $\Gamma_1$ from $0$ to $R$ on the real axis, then a circular arc $\Gamma_2$ , then a straight line $\Gamma_3$ back to $0$ . But I couldn't understand which angle I should use for $\Gamma_3$ ? Like for $f(z) = \frac{z^n}{1+z^m}$ , it was suggested to use a wedge-shaped contour of angle $\frac{2\pi}{m}$ . Is there any trick or rule of thumb which help to decide the angle?","['complex-analysis', 'contour-integration', 'branch-cuts', 'residue-calculus']"
4254603,Does it make sense to integrate a function and a differential form at the same time?,"Let $(M,g)$ be an positively oriented $n$ -dimensional Riemannian manifold with or without boundary and $\text{dvol}_g$ its riemannian volume form. Let $f$ be a continuous real-valued function on $M$ and $\omega$ be an continuous $n$ -form on $M$ . If $(U\subseteq M, \phi)$ is a chart on $M$ such that $\omega$ can be written as $\omega = A \text{d}x^1\wedge \cdots \wedge \text{d}x^n$ where $A: U \longrightarrow \mathbb{R}$ is continuous function. I know that the integration of these objects are really well-defined: $$ \text{integral of $f$ on $U$} :=\int_U f \text{dvol}_g = \int_{\phi(U)}f(x) \sqrt{\text{det}(g_{ij})} \text{d}x^1 \cdots \text{d}x^n \tag1$$ and $$\text{integral of $\omega$ on $U$} := \int_U \omega = \int_{\phi(U)} A(x) \text{d}x^1 \cdots \text{d}x^n \tag2$$ My question: does it make sense integrate both $f$ and $\omega$ over $U$ ? In other words, does it make sense $$\int_U (f \text{dvol}_g + \omega) \stackrel{?}{=} \int_{\phi(U)} \left( f(x)\sqrt{\text{det}(g_{ij})} + A(x)\right)\text{d}x^1 \cdots \text{d}x^n $$","['integration', 'volume', 'riemannian-geometry', 'smooth-manifolds', 'differential-forms']"
4254604,Solving $\frac{(1+x)(1+2x)(1+3x)}{(4+x)(4+2x)(4+3x)}=4 $. Simply bringing it to a common denominator does not lead me to success,How can I solve this equation? $$\frac{(1+x)(1+2x)(1+3x)}{(4+x)(4+2x)(4+3x)}=4 $$ Simply bringing it to a common denominator does not lead me to success What I tried,['algebra-precalculus']
4254708,Limit of expression as x approaches 0,"I'm working with this limit, where I can't use any Maclaurin series, nor can I use L'Hopitals Rule. I'd be pleased if anyone could help me out with this one: $$\lim_{x\rightarrow 0}\frac{e^{x^{2}}-\cos(x)}{\sin^2x}$$ I'm trying to convert the problem into a limit where I can work with the standard limits, such as $cos(x)/x$ , but I'm not successful in doing so. Thanks for any potential tips!","['limits', 'limits-without-lhopital']"
4254720,Find a left transversal of a finite group which is a right transversal (without combinatorical theorems or assuming that $H$ is normal),"The Problem :
We have a finite group G, an arbitrary subgroup $H\leq G$ of index, say $r\in \mathbb{N}^+$ , and we want to find $\{g_1,...,g_r\}$ which is a left transversal and a right transversal. My Question : I am looking for a proof which does not use Hall's Marriage theorem (we did not cover this in my classes, so I would also have to prove that theorem itself in my proof if I used it, even then I probably would not get full credit). I really only have very basic set theory (including AC/Zorn's) and group theory that I am allowed to use here (up to for instance actions, class equation, and Sylow theory). What I have tried : Obviously we can take some left transversal $\{g_i\mid 1\leq i\leq r\}$ , then I know that $\{g_i^{-1}\mid 1\leq i\leq r\}$ is a right transversal, which does not seem to be particularly helpful. I have also tried throwing a combination of: existence of a Sylow p-subgroup P (where p is the smallest prime dividing $\rvert G\rvert$ ) and induction at this (something like: if $H$ is a proper subgroup of $HP$ (if $P$ is normal), then we can do some sort of induction on the index here I think, not really sure yet, but this need not happen, we could have $H$ strictly contain $P$ for instance, or $H = P$ ). The idea I was trying to get at was something like a composition series to apply induction to $[G:H]$ on, but even a finite group need not have a composition series which includes $H$ , so I am kind of stuck atm. Notes : Yes I am aware there are other MSE posts about this, but afaik they all either use some combinatorical theorems (namely Marriage theorem) that I can't use, or they assume H is normal (it is fairly trivial in that case anyway).","['group-theory', 'finite-groups']"
4254746,Which change of basis matrix makes a companion matrix similar to its transpose?,"I know that a companion matrix is similar to its transpose e.g by Smith normal form. When the characteristic polynomial splits, companion matrices become Jordan blocks. A Jordan block is similar to its transpose via the matrix comprised of 1's on the ""opposite diagonal"" and zeros elsewhere. This leads me to wonder: Is there a simple description of the matrix which exhibits a companion matrix as similar to its transpose?","['matrices', 'change-of-basis', 'linear-algebra', 'linear-transformations', 'transpose']"
4254748,Convergent stochastic process can't be iid?,"If we have a stochastic process $\{X_n , n\in\mathbb{N} \}$ for which we have $X_n \rightarrow{X}$ in probability does that imply that $X_n$ can't be iid unless the $X_n=C\in \mathbb{R}$ is a constant $\forall n \in \mathbb{N}$ ?","['stochastic-processes', 'probability-theory', 'probability']"
4254755,The Integral $\int\limits_0^1$ $\frac{e^x-\sum^{n-1}_{i=0} \frac{x^i}{i!}}{x^n}dx$,"$\def \ein{\operatorname{Ein}}$ $\def \ei{\operatorname{Ei}}$ Evaluate $$\int\limits_0^1 \frac{e^x-\sum^{n-1}_{i=0} \frac{x^i}{i!}}{x^n}dx,$$ for $n\in\mathbb N$ . Specific case: Case ( $n=1$ ): $$\int_0^1 \frac{e^x-1}{x}\,dx$$ Which is the exponential integral $\operatorname{ein}$ $$\ein(z)=-\int_0^z \frac{e^{-x}-1}{x}\,dx$$ Substituting $u=-x$ $$\ein(z)=-\int_0^{-z} \frac{e^{y}-1}{y}\,dy$$ $$-\ein(-1)=\ei(1)-\gamma-\ln(1)=\ei(1)-\gamma$$ But this doesn't seem to be generalizable as the $\ein$ and $\ei$ series seem to be uniquely similar enabling this. I've also tried using wolfram alpha, which gives: $$$$ \begin{array}{|c|c|} \hline
n & \text{The Intergral} \\ \hline
1 & \ei(1)-\gamma \\ \hline
2 & \ei(1)-\gamma +2-e \\ \hline
3 & \frac{1}{2}(\ei(1)-\gamma+\frac{9}{2}-2e) \\ \hline
4 & \frac{1}{6}(\ei(1)-\gamma+\frac{59}{6}-4e) \\ \hline
5 & \frac{1}{24}(\ei(1)-\gamma+\frac{626}{24}-10e) \\ \hline
6 & \frac{1}{120}(\ei(1)-\gamma+\frac{10954}{120}-34e) \\ \hline
\end{array} $$$$ the oies was helpful in identifiying the $e$ coefficient to be the left factorial (which is consistent with pax's answer)
And was unable to identify anything else.","['calculus', 'definite-integrals']"
4254761,What is the tangent to this equation at origin?,"$$x(x^2 + y^2) = a(x^2 - y^2)$$ I was trying to find the equation of the tangent as $$(Y-0) = \frac{dy}{dx}(X - 0)$$ where $$\frac{dy}{dx} = \frac{2ax-3x^2-y^2}{2(x+a)y}$$ So here putting the values of $(x,y)$ as $(0,0)$ makes the derivative non existent.
I am stuck at this point and unable to proceed further.","['tangent-line', 'calculus', 'implicit-differentiation', 'slope', 'derivatives']"
4254789,what is reconstruction of sets,"I am a high school student prepairing for IMO, and while studying I came accross a doubt. There is a question A is a set containing n elements. a subset P of A is selected. The set A is reconstructed by replacing the elements of P. A subset Q is again selected. Find number of ways to select P and Q such that P Intersection Q contains exactly R elements Here in this question, I was unable to understand the line The set A is reconstructed by replacing the elements of P What does reconstruction of set mean here? I tried to search on the web alot about my question, but was unable to fing anything useful thanks in advance :)",['elementary-set-theory']
4254805,How should logical quantifiers be understood if the domain of discourse is not specified?,"Let $P$ be a predicate. The expression $\forall x:P(x)$ seems to have two different meanings, depending on the context: If the domain of discourse $D$ is clear from context, then the statement "" $\forall x:P(x)$ "" should actually be read as an abbreviation of "" $\forall x\in D:P(x)$ "". For instance, in real analysis the statement $\forall x:x^2\ge0$ would be understood as an abbreviation of $\forall x\in\mathbb R:x^2\ge0$ . In set theory, it seems that $\forall x:P(x)$ means ""for any set $x$ , $P(x)$ is true"". For instance, the axiom of extensionality is written as $\forall x:\forall y:\forall z:(z\in x\iff z\in y)\implies x=y$ . I don't fully understand the meaning of $\forall x:P(x)$ in the context of set theory. Naïvely, the statement $\forall x:P(x)$ seems to be an abbreviation of $\forall x\in \mathbf{U}:P(x)$ , where $\mathbf{U}$ is the universal set. However, the ""universal set"" is not actually a meaningful concept in standard formulations of set theory, and so this interpretation is clearly wrong. So how should the statement $\forall x:P(x)$ actually be interpreted?","['elementary-set-theory', 'notation', 'logic', 'quantifiers']"
4254880,"Finding a pair $(a,b)\in \mathbb R^2$ such that $\inf_{m,n\in \mathbb Z}\left|(m+\sqrt{3}n+a)(\sqrt{2}m+n+b) \right|>0$","I am trying the find a pair $(a,b)\in \mathbb R^2$ such that $\inf_{m,n\in \mathbb Z}\left|(m+\sqrt{3}n+a)(\sqrt{2}m+n+b) \right|>0$ For $a=b=\frac{1}{2}$ , I speculate that the infimum is nonzero. By Dirichlet's theorem , we have $|\sqrt{2} m+n+\frac{1}{2}|\lesssim |\frac{1}{n}|$ for infinitely many $m,n$ and $\sqrt{2} m \asymp
 -n$ . So $|m+\sqrt{3}n+a|\sim |n|$ . But I don't see why $$\inf_{m,n\in \mathbb Z}\left|(m+\sqrt{3}n+\frac{1}{2})(\sqrt{2}m+n+\frac{1}{2}) \right|>0$$ My question is about finding such a pair explicitly , but if you have a non-constructive proof showing that such pairs exist, please also let me know.","['number-theory', 'diophantine-approximation']"
4254881,"For a triangle $ABC$, prove that for a point $P$ on the angle bisector of $\angle BAC$,$|PL|=|PK|$ where $L,K$ are intersections of circles with sides","In a triangle $ABC$ , the point $P$ lies on the angle bisector of $\angle BAC$ . We define a circle $\alpha$ with diameter $AP$ , circle $\beta$ which passes through $B$ and is tangent to $\alpha$ at the point $E$ , where it intersects $AB$ , and circle $\gamma$ which passes through $C$ and is tangent to $\alpha$ at the point $F$ , where it intersects $AC$ . Then the points $K,L$ are defined as the intersections of $BC$ with $\beta$ and $\gamma$ respectively. The task is to prove that $|PL|=|PK|$ . In the case when $ABC$ is isosceles with $CB$ as the base, we can see that since $\alpha$ passes through $A$ and $P$ which lies on the angle bisector, it passes through $AC$ and $AB$ symmetrically, i.e. the distances from $A$ to $D$ (intersection of $\alpha$ and $AB$ ) and from $A$ to $E$ (intersection of $\alpha$ and $AC$ ) are the same. Then from the fact that the trinagle is isosceles, $\beta$ and $\gamma$ intersect $CB$ symmetrically, i.e. $|CL| = |KB|$ . Hence, for $KLP$ , the angle bisector of $\angle BAC$ is also the angle bisector of $\angle KPL$ . $KLP$ is then similar to $ABC$ and therefore isosceles with $LK$ as base. I have not been successful with generalising this proof to all triangles, however. It certainly cannot make use of symmetry in a similar manner. How should I approach this? Thank you for your help.","['triangles', 'symmetry', 'geometry']"
4254887,Almost sure convergence of random variables with continuous densities implies $L^1$ convergence of densities?,Suppose we have a sequence of random variables $f_n:\Omega\rightarrow\mathbb{R}$ converging almost surely to some random variable $f:\Omega\rightarrow\mathbb{R}$ . Suppose we know that the law of each $f_n$ has a continuous density function $\phi_n:\mathbb{R}\rightarrow\mathbb{R}$ and $f$ has a continuous density $\phi:\mathbb{R}\rightarrow\mathbb{R}$ . I know that almost sure convergence of the random variables implies weak convergence of the laws. Can we use the extra assumptions here to conclude that we have a stronger form of convergence? For example it seems like we should have $\|\phi_n-\phi\|_{L^1}\rightarrow 0$ .,"['probability-theory', 'functional-analysis', 'probability', 'measure-theory']"
4254922,Why does this assumption give an under approximation for both the expected maximum and minimum,"The well known result, $\mathbb{E}[\text{min} \{X_i \}_{i=1}^n ] = \frac{1}{n+1}$ and $\mathbb{E}[\text{max} \{X_i \}_{i=1}^n ] = \frac{n}{n+1}$ where $X_i$ are I.I.D Uniform $(0,1)$ random variables is a lifesaver. It can be extrapolated to find the expected minimum and maximum of $n$ Uniform $(a,b)$ variables. I tried to use it in the discrete case. For example, consider the maximum of $10$ rolls of a $100$ sided die, the quick formula gives: $ \frac{10}{11}\cdot 100 = 90\frac{1}{11} \approx 90.91$ . The true answer however is $91.4007585757
$ (using tail sum formula : $100 - \sum\limits_{i=1}^{99}(\frac{i}{100})^{10}$ ) Notice the approximation gives an underestimate. Now consider using it to approximate the expected minimum. $\frac{1}{11}\cdot 100 = 9\frac{1}{11} \approx 9.09$ . The true answer however is $9.59924142434$ and again this formula under-approximates? Why does this happen in both cases? Is there a cheeky way to tweek it for the discrete case to get a bit more accurate? Thanks! A little thing I have noticed that might help is the following: The approximate min + approximate max is always $n$ . However, by symmetry the true min + true max is always $n+1$ . (because they are centred around the mean of $\frac{n+1}{2}$","['statistics', 'approximation', 'probability']"
4254923,Statistics for the number of empty vessels for large systems,"Consider randomly (iid) dropping $b$ balls into $n$ vessels. I am interested in the statistics of $e$ , the number of empty vessels. I've seen elsewhere on stackexchange that this can be written down in terms of Stirling numbers of the second kind, but I don't have a good sense of how to extract useful information from those expressions. I'm most interested in the following information: Can we find the probability distribution for $e$ in the large- $n$ limit, at least in some regimes for $k$ ? Can we say that the empty fraction $e/n$ is a function of the average number of balls per vessel $b/n$ in this limit? Can we find the mean and variance of $e$ , again in the large-system limit? I've tried a few things already. I started off by simply calculating the odds that no balls fell within $e$ specific vessels and then the odds that none fell within $e+1$ specific vessels. But of course it's wrong to say that the difference between these two numbers is proportional to the probability of exactly $e$ empty vessels. Next, I tried to write down a recursion relationship, in which $P(e,b+1)$ , the probability of $e$ empties given $b+1$ balls is (Edited to fix error) $$P(e,b+1) = P(e,b)(1-e/n) + P(e+1,b)((e+1)/n).$$ That one still seems to me to be correct, and I wanted to rewrite it in terms of $b/n$ and $e/n$ and then do a Taylor expansion. That gives me a PDE, but when I try to solve it I get nonsensical answers.","['combinatorics', 'variance', 'probability']"
4254933,Possible definition of the cotangent space,"This definition is inspired by the book mentioned in this question . As it turns out later it is identical to that in question mentioned in the comment by Paul Frost. The tangent space at $p \in M$ can be defined as the space of derivations on $C^\infty(M)$ . I thought that the space of functions $C^\infty(M)$ , which is a very large jungle of smooth functions, is actually redundant, to charaterise these special maps (derivations) by their action on them. So I wanted to reduce it bya quotient. First I have to prove that if the derivative of a smooth function at $p \in U \subset M$ vanishes in a some coordinates, it vanishes in all other compatible coordinates. Indeed, if $p \in U$ and $(U,\phi),(U,\psi)$ are any compatible charts, then for all $f \in C^\infty(M)$ we have, if $$
\hat f = f \circ \phi^{-1}:\phi(U) \to \mathbb R, \quad D\hat f_{\phi(p)} = 0
$$ then $$
\tilde f = f \circ \psi^{-1} = \hat f\circ \phi\circ\psi^{-1}:\psi(U) \to \mathbb R,\quad  D\tilde f_{\psi(p)} = (D\hat f_{\phi(p)})\circ (D (\phi\circ\psi^{-1})_{\psi(p)}) = 0
$$ The subset $W_p(M) \subset C^\infty(M)$ of functions with vanishing derivative is well defined and is a subspace, so one may take the quotient $$
T_p^*M := C^\infty(M)/W_p(M)
$$ The elements are equivalence classes of functions, each class is a set of functions with common (first) derivative. The derivative itself as a map $D(f\circ \phi^{-1})_{\phi(p)} \in \mathbb R^{m*}$ will depend on the coordinate map $\phi$ . Since these classes are distinguished from each other by the first derivative (in some coordinates) then $\dim T_p^*M = \dim \mathbb R^{m*} = m$ , as expected, since $\mathbb R^{m*}$ is the set of all such linear maps $D(f\circ \phi^{-1})_{\phi(p)}$ . One has still to prove that under coordinate change the classes are the preserved, which should be an easy part. Choosing some coordinate map, the coordinate function $x^i:U \to \mathbb R$ , or rather their classes $[x^i]$ , constitute a basis for $T_p^*M$ . Then a tangent vector $v_p$ is the map $$
v_p: [f] \mapsto  D(f\circ \phi^{-1})_{\phi(p)}(v^\phi), \quad v^\phi \in \mathbb R^m
$$ Could anyone check if every thing above is consistent ? Update The Leibniz property emerges from this definition of the tangent vector as a consequence of the old product rule and since $$
(fg)\circ \phi^{-1} = (f\circ \phi^{-1})(g\circ \phi^{-1}).
$$ Also the independence of the number $v_p([f])$ of the coordinate map $\phi$ gives the transformation rule $$
v^\phi \mapsto v^\psi = (D (\psi\circ\phi^{-1})_{\phi(p)})(v^\phi).
$$","['definition', 'co-tangent-space', 'smooth-manifolds', 'differential-geometry']"
4254935,Question about substitution in solving integrals,"In high school I learned that if I want to solve $$
\int_0^R f(x) dx 
$$ we can do $x = \psi (\theta)$ and $dx = \psi'(\theta) d \theta$ and the integral becomes $$
\int_0^R f(x) dx = \int_{a_1}^{a_2} f(\psi(\theta)) \psi'(\theta) d \theta, 
$$ say. Depending on $f$ and a suitable choice of $\psi$ , this second integral can be easier to solve. Here $\psi(a_1)= 0$ and $\psi(a_2) = R$ . My question. Does the end point matter as long as it the values of $\psi$ are $0$ and $R$ ?
In other words, can I pick any other two points $b_1$ $b_2$ such that $\psi(b_1) = 0$ and $\psi(b_2) = R$ and we have $$
\int_0^R f(x) dx = \int_{b_1}^{b_2} f(\psi(\theta)) \psi'(\theta) d \theta? 
$$","['integration', 'calculus', 'definite-integrals']"
4254961,Why the number of unlabeled graphs on $n$ vertices is not exactly $\frac{2^{n \choose 2}}{n!}$?,"OEIS A000088 sequence lists the number of unlabeled graphs on $n$ vertices. Very naively, I would have expected it to be exactly (well, it can't be, at the least because it's not an integer): $$\frac{2^{n \choose 2}}{n!}$$ thinking about the possible ${n \choose 2}$ edges present/not present, and then dividing by all the possible permutations of the vertices. Can someone explain simply why, even if tending asymptotically to that value, there are more than that?","['graph-theory', 'combinatorics']"
4254992,Trying to find a closed form for $\sum_{k=1}^nk^n$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Edited: Cosider the following summation $$A=\sum_{k=1}^nk^n.$$ I try to find an upper bound for $A$ as follow: I try to prove that $$\sum_{i=1}^ni^n\leq 2n^n$$ as follow, first I checked base cases that holds. then I suppose $$\sum_{i=1}^ki^k\leq 2k^k$$ now to prove for $n=k+1$ , $$\sum_{i=1}^{k+1}i^{k+1}=\sum_{i=1}^{k}i^{k+1}\;\;+ (k+1)^{k+1}$$ . At this step I get stuck, How I can relate $\sum_{i=1}^{k}i^{k+1}$ to our induction assumption?","['induction', 'discrete-mathematics']"
4255008,Can complex numbers be ordered in the way of Pythagorean triples?,"This post did not quite seem to answer my question. If we have $\quad a+bi\in\mathbb{C}\quad$ can ordering be done the way of Pythagorean triples $\quad A^2+B^2=C^2?\quad$ There are infinite triples for each of $\quad 
(C-B),\space
 (C-A),\space\text{and}\space
(B\pm A)\quad$ but these may be further ordered  as sets of sets $
(C-B)=(2n-1)^2\in\big\{1,3,5,\cdots\big\}
$ $
(C=A)=2k^2\in\big\{2,8,18,\cdots\big\}
$ \begin{align*}
&(B\pm A)=P:\\ 
&P=p_1,\cdots ,p_n),\space p_k\equiv \pm 1 \text{ (mod }8) \in\big\{1,7,17, \cdots\big\}
\end{align*} For each of $(A\text{ or } B\space\text{ or } \space C),\space$ there are $2^{n-1}\space$ primitive triples where $\space n\space $ is the number of unique prime factors of $\space(A\text{ or } B\space\text{ or } \space C)\space $ and these may be of vastly  different sizes. Perhaps these may be ordered by the pairs of natural numbers $\space(n,k)\space$ that generate them in this formula \begin{align*}
  A=(2n-1)^2+                     & 2(2n-1)k            \tag{a}  \\ 
  B=  \qquad\qquad\quad   & 2(2n-1)k+ ]]    2k^2        \tag{b}  \\ 
  C=(2n-1)^2+                    & 2(2n-1)k+       2k^2 \tag{c} 
\end{align*} where $\space n\space $ is a set number and $\space k\space$ is the ordinal triple  within each set.
For example, $C=65\space$ represents triples $\space f(4,1)=(63,16,65)\quad  f(5,4)=(33,56,65).\space$ where $\space(63,16,65)\space$ is the first member of $Set_4$ and $\space(33,56,65)\space$ is the fourth member of $Set_5.$ Can $\space (4+1i),\space (5+4i)\space$ be treated as natural ordering of these complex numbers or are their other considerations such as the size of the resulting squares or products to consider?","['elementary-set-theory', 'elementary-number-theory', 'complex-numbers']"
4255028,How to evaluate $\sum\limits_{x=0}^\infty \text{erfc}(x)= 1.1619990479471263635323…?$,"This will be the $5$ th in a series of an infinite series of a single function. Here are 2 related sums: A Kelvin-Bessel Sum: $$\mathrm{\sum\limits_{\Bbb N} ker(x)+i\ kei(x)= \sum\limits_1^\infty K_0\left(\sqrt ix\right)= 0.133691752… - 0.7256312077… i}$$ and On $$\mathrm{\sum\limits_{n=0}^\infty \left(C(n)-\frac{\sqrt\pi}{2\sqrt2}\right)+ \sum\limits_{n=0}^\infty \left(S(n)-\frac{\sqrt\pi}{2\sqrt2}\right)}$$ Our goal sum uses the Complementary Error function integrating term by term. Note the Fresnel Integrals . There are also Gamma type functions : $$\sum_{\Bbb N^0}\text{erfc}(x)=\sum_{x=0}^\infty \text{erfc}(x) =\lim_{n\to\infty} \left(n-\sum_0^n \text{erf}(x)\right)= \frac{2}{\sqrt \pi}\sum_{x\in \Bbb N^0}\int_x^\infty e^{-t^2} dt= \sum_{x\in \Bbb N^0}\left(1-\frac 2\pi \int_0^\infty \frac{\sin(2tx)}{te^{t^2}}dt\right)=\sum_{x\in\Bbb N^0}\left(1 - (1 + i) \left(\text C\left(\frac{((1 - i) z)}{\sqrt\pi}\right) - i\,\text S\left(\frac{((1 - i) z)}{\sqrt\pi}\right)\right)\right)=\sum_{\Bbb N^0}\text{erf}(x,\infty)= \frac{1}{\sqrt \pi}\sum_{\Bbb N^0}Γ\left(\frac12,x^2\right)= \sum_{\Bbb N^0}Q\left(\frac12,x^2\right) =\frac{1}{\sqrt \pi} \sum_{\Bbb N^0}x \text E_\frac12 \left(x^2\right)= \frac{1}{\sqrt \pi}\int_1^\infty t^{-\frac12}\sum_{x\in\Bbb N^0}xe^{-tx^2}dt =1.16199904794712636353230832245579717…$$ As @JohnBarber found: $$\sum_{\Bbb N^0}\text{erfc}(x) =1+\frac{2}{\sqrt\pi}\int_1^\infty \lfloor x\rfloor e^{-x^2} dx$$ The final integral-sum representation reminds me of a Differentiated Jacobi Theta function of the Third Kind . Here is a question about it although there are others. How can I evaluate the constant? Please correct me and give me feedback!","['special-functions', 'gamma-function', 'sequences-and-series', 'error-function', 'complex-numbers']"
4255038,Difficult limit proof,"Let $a_1 = 1$ and define a sequence recursively by $$a_{n+1} = \sqrt{a_1+a_2+\dots+a_n}.$$ Show that $\lim_{n \to \infty} \frac{a_n}{n} = \frac{1}{2}$ . So far, I've written $a_{n+1} = \sqrt{a_n^2 + a_n}$ , and have shown that if $a_n/n < 1/2$ , then so is $a_{n+1}/{(n+1)}$ . I'm really not sure how to relate the recurrence relation to the limit we want, though.","['limits', 'analysis']"
4255039,"For a Banach space $E$, is it sufficient to check differentiability of $F: U \to E$ on $\phi \circ F$ for all linear functionals $\phi$?","Let $E$ be a complex Banach space and and $U \subset \mathbb{C}$ an open set containing $0$ . Consider a function $F: U \to E$ . If for every linear functional $\phi \in E^*$ , the function $\phi \circ F: U \to \mathbb{C}$ is (complex) differentiable at $0$ , does this imply that $F$ is differentiable at $0$ ? related questions/generalizations: What about the case of real Banach spaces and real differentiability? Also, what happens if $U$ is also taken to be a subset of a complex Banach space and we consider Frechet derivatives? My ideas so far: We are assuming that for every $\phi \in E^*$ there exists a $g(\phi) \in E$ s.t. $$
\phi(F(h)) = \phi(F(0)) + h \cdot g(\phi) + o(h)
$$ It's easy to see that $\phi \to g(\phi)$ is linear so $g \in E^{**}$ . If we assume reflexivity of $E$ then we can say $g \in E$ and obtain that $\phi(F(h) - h\, g) = o(h)$ for any $\phi \in E^*$ . However, the $o(h)$ might not be uniform in $\phi$ , so I don't know how to continue from here.","['complex-analysis', 'frechet-derivative', 'banach-spaces', 'functional-analysis']"
4255045,"Show that $E[f(X_1,X_2)\mid \mathcal{F}_n]=\frac{2}{n(n-1)}\sum_{ 1 \leq p<q \leq n}f(X_p,X_q)$","Let $(X_k)_k$ be a sequence of i.i.d random variables and $f:\mathbb{R}^2 \to \mathbb{R}$ be a measurable function such that $f(X_1,X_2) \in L^1$ and for every $(x,y) \in \mathbb{R}^2,f(x,y)=f(y,x).$ Let for $n \geq 2,Y_n=\frac{2}{n(n-1)}\sum_{ 1 \leq p<q \leq n}f(X_p,X_q)$ and $\mathcal{F}_n=\sigma(Y_n,Y_{n+1},...)$ . Show that for $n \geq 2, Y_n=E[f(X_1,X_2)\mid \mathcal{F}_n].$ We have that \begin{align}
\sum_{1 \leq p<q \leq n}f(X_p,X_q)&=E\left[\sum_{1 \leq p<q \leq n}f(X_p,X_q)\mid Y_n \right]
\\&=\sum_{1 \leq p <q \leq n}E [f(X_p,X_q)\mid Y_n ]
\\&=\sum_{1 \leq p<q \leq n}E [f(X_1,X_2)\mid Y_n ]
\\&=\frac{n(n-1)}{2}E [f(X_1,X_2)\mid Y_n ]
\end{align} which is true since for $1 \leq p < q \leq n, P_{(X_p,X_q,U_n)}=P_{(X_1,X_2,U_n)}.$ How to verify that $Y_n=E[f(X_1,X_2)\mid \mathcal{F}_n ]$ ?","['conditional-expectation', 'stochastic-processes', 'probability-theory', 'martingales']"
4255072,"Let $f$ be a continuous function in $[0,5]$ and twice differentiable function in $(0,5)$ such that $f(4)=f(5)=0$. Prove the following","Let $f$ be a continuous function in $[0,5]$ and twice differentiable function in $(0,5)$ such that $f(4)=f(5)=0$ . Prove the following: There exists some $a$ in $[0,5]$ such that $nf(a)+af'(a)=0, n\in N$ There exists distinct $a_1,a_2 \in [0,5]$ such that $4f'(a_1)+f'(a_2)+f(0)=0$ There exists some $a \in [0,5]$ such that $nf(a)=af'(a), n \in N$ By Rolles theorem, there will be $a \in [4,5]$ such that $f'(a)=0$ . But $f(a)$ is not necessarily zero at that point, so it doesn't lead us anywhere. If we assume $f(0)=0,$ there will be $a_1 \in [0,4]$ and $a_2 \in [4,5]$ such that $f'(a_1)=f'(a_2)=0$ . Now I don't know how to prove this if $f(0) \neq 0$ Since $n,a>0$ either $f(a),f'(a)>0$ or $f(a),f'(a)<0$ . I haven't been able to find a single function which violates this rule in $[4,5]$ but I can't prove this rigorously. Please help, thanks :)","['rolles-theorem', 'functions', 'derivatives']"
4255094,A version of Hilbert Nullstellensatz for co-ordinate ring of a general irreducible affine variety,"Let $\mathbb{K}$ be an algebraically closed field. A version of Hilbert Nullstellensatz for polynomials rings says that, Every proper ideal $\mathfrak{a}$ in $\mathbb{K}[X_1,\dotsb,X_n]$ has a zero in $\mathbb{K}^n$ , i.e., there exists some $x\in\mathbb{K}^n$ , such that $x\in\mathcal{V}(\mathfrak{a})$ . I was wondering if such a statement is true for a general co-ordinate ring of an irreducible affine variety, i.e., Let $V$ be an irreducible affine variety. Then, every proper ideal $\mathfrak{a}$ in $\mathbb{K}[V]$ has a zero in $V$ , i.e., there exists some $x\in V$ , such that $x\in\mathcal{V}(\mathfrak{a})$ .","['algebraic-geometry', 'commutative-algebra']"
4255134,The largest possible number of inversions in a sequence of positive integers whose sum is $2014$,"In a sequence of positive integers an inversion is a pair of positions such that the element in the position to the left is greater than the element in the position to the right. For instance the sequence $2,5,3,1,3$ has five inversions - between the first and fourth positions, the second and all later positions, and between the third and fourth positions. What is the largest possible number of inversions in a sequence of positive integers whose sum is $2014$ ? I tried this question and I came under one construction. $62,61,\dots,3,2,1\dots 1(61~~1's)$ The sum is $62+\cdots +1+ 61=2014.$ And we get $122+121+\dots 62=61\times 61+(1+2+\dots +61)=3721+1891=5612$ inversions. Then I also got one more construction by expanding ""62."" So we get $61,60,\dots ,2,1( 123~1's)$ Now we get $182+181+\dots 123=122\times 60+60\times 61/2=9150$ inversions. Then we can again continue expanding the numbers to 1's. I don't think this is a nice way. Any solution?","['contest-math', 'number-theory', 'combinatorics', 'elementary-number-theory']"
4255147,inner product between homogenous harmonic polynomials,"Suppose $v_i$ and $v_j$ are homogenous harmonic polynomials of degrees $i$ and $j$ respectively in $B_1 \subset \mathbb{R}^n$ . I'm trying to show for all $i\neq j$ $$ \int_{B_1} \nabla v_j \cdot \nabla v_i dx = 0.$$ I know $$\nabla v_j(x) = r^{1-n}\nabla v_j(rx),$$ it then follows that for all $0<r<1$ $$\int_{B_1} \nabla v_j \cdot \nabla v_i \,dx = C \int_{B_{r}} \nabla v_j \cdot \nabla v_i \,dx$$ from a change of variables. By green's identity I get $$\int_{B_{r}} \nabla v_j \cdot \nabla v_i \,dx = \int_{\partial B_r} v_j d_n v_i \,d\mathcal{H}^{n-1}=\int_{\partial B_r} v_i d_n v_j \,d\mathcal{H}^{n-1}.$$ I don't know how to proceed from here (vector calc not my strong suit). I've tried brute forcing through the gradients of $v_i$ dot with the gradient of $v_j$ in hopes of applying a symmetry argument to show why the integral would be $0$ but it got too messy and confusing notation wise so this is what I've got so far. Would appreciate any hint!","['multivariable-calculus', 'partial-differential-equations']"
4255178,Find area of Pentagram : Regular Pentagon if $AP : PQ = m:1$,"While I was doing an Olympiad geometry sum in Sri Lanka I found this question A pentagram is a regular pentagon with its sides extended to their point of intersection. In the
pentagram ABCDE shown below PQRST is a regular pentagon. If AP:PQ = m:1 then what is the ratio ,the area of the pentagram : the area of the pentagon ? There are 5 answers:- The above is the image of the question My Attempt:- I drew SP, and SQ so I got congruent $\triangle PTS$ and $\triangle SQR$ And also I found that $\triangle ATP$ , $\triangle BPQ$ , $\triangle CQR$ , $\triangle DSR$ , $\triangle ETS$ , $\triangle SPQ$ are congruent And also I drew vertical heights h in $\triangle SRQ$ and H in $\triangle SPQ$ Then I took AP as $lm$ and PQ as $l$ I find the value of H and h from $l$ and $m$ but the simplifying of the answer is very hard to find the ratio So anyone could help me with this question Thank you","['contest-math', 'euclidean-geometry', 'geometry', 'ratio', 'triangles']"
4255187,"How to find the lower bound of $f(x, y) = -2xy+x^2y^2+x^2$?","$f(x, y) = -2xy+x^2y^2+x^2, x\in \mathbb{R}, y\in \mathbb{R}$ , how to find its lower bound? Here are my thoughts, I don't know if it is rigorous. $f(x, y) = -2xy+x^2y^2+x^2=(xy-1)^2+x^2-1$ , as $(xy-1)^2 \geq 0$ , $x^2\geq0$ , and they can not get to $0$ at the same time, therefore $f(x, y) > -1$ . Therefore, the lower bound of $f(x, y)$ is $-1$ .","['calculus', 'functions', 'analysis']"
4255209,Prove: $\det(I+A) = 2^{\text{rank}(A)}$ if $A$ is a square idempotent matrix. Find $(I+A)^{-1}$ such that the expression doesn't have inverses.,To prove: $\det(I+A)$ = $2^{\operatorname{rank}(A)}$ if $A \in$ $\mathbb{R}^{n\times n}$ and $A^{2}=A$ . Find an expression for $(I+A)^{-1}$ such that it does not involve inverses. Is there any way I could use Jordan Block? I am not sure where I need to start in order to solve it.,"['jordan-normal-form', 'determinant', 'idempotents', 'matrices', 'linear-algebra']"
4255211,Prove $\frac{S_{n}}{n} \overset{p}{\rightarrow} p$ where $S_n$ is a binomial random variable.,"I want to prove that $\frac{1}{n}S_{n} \overset{p}{\longrightarrow} p\:$ as $\:n \longrightarrow \infty$ from first principles, where $S_{n}$ denotes the number of successes in $n$ binomial trials with success probability $p$ . From the definition of convergence in probability. A random sequence $Y_{n}$ converges in probability to $c$ if: $$P(|Y_{n} - c| < \epsilon) \longrightarrow 1\text{ as } n \longrightarrow \infty$$ For every $\epsilon > 0$ . We can do the following: $$\begin{align}P\left(\left|\frac{S_{n}}{n} - p\right| < \epsilon\right) &= P\left(\frac{S_{n}}{n} - p < \epsilon\right) - P\left(\frac{S_{n}}{n} - p < -\epsilon\right) \\&= P(S_{n} < n(p + \epsilon)) - P(S_{n} < n(p - \epsilon))\end{align}$$ I assume that the result follows the binomial cdf. But im not sure how to proceed.","['binomial-distribution', 'statistics', 'convergence-divergence', 'probability-theory']"
4255229,"Find a bijection between $[1,2)$ and $(1,2)$ [duplicate]","This question already has answers here : How to define a bijection between $(0,1)$ and $(0,1]$? (9 answers) Closed 2 years ago . I want to find a bijection between $[1,2)$ and $(1,2)$ and prove it. My attempt: $[1,2) = \{x \in \mathbb R | 1 \leq x <2\}$ $(1,2) = \{x \in \mathbb R | 1 < x < 2\}$ $f(x) = x$ if $x \ne 1\frac{1}{n}$ for $n = 1,2,3,...$ and $f(x) = 1\frac{1}{x+1}$ , if $x =1\frac{1}{n}$ for $n = 1,2,3,...$ Proof - Injective - Prove $x_1 = x_2$ for $f(x) = x$ \begin{align*}
  f(x_1) = f(x_2) &\implies x_1 = x_2.\\
\end{align*} Proof - Injective - Prove $x_1 = x_2$ for $f(x) = 1\frac{1}{x+1}$ \begin{align*}
  f(x_1) = f(x_2) &\implies 1\frac{1}{x_1+1} = 1\frac{1}{x_2+1}\\
	&\implies \frac{1}{x_1+1} = \frac{1}{x_2+1}\\
	&\implies x_2+1 = x_1+1\\
	&\implies x_2 = x_1.\\
\end{align*} Therefore $f$ is injective. Any help will be appreciated. Thanks.",['functions']
4255260,Is there a connection between the sum of $\sum_{n=1}^\infty \frac{\ln(n+1)-\ln(n)}{n}$ and the Riemann zeta function?,"It can be shown that for every integer $p\geq 0$ , this integral identity holds: \begin{align}
\int_1^\infty\frac{1}{x^{p+2}\lfloor x\rfloor}\text{ }dx &= -1+\frac{1}{p+1}\sum_{m=2}^{p+2}\zeta(m)\\
&= -1+\frac{\zeta(2)+\zeta(3)+\zeta(4)+\cdots+\zeta(p+2)}{p+1}
\end{align} Pretty neat! I find it interesting that the quantity $$\frac{\zeta(2)+\zeta(3)+\zeta(4)+\cdots+\zeta(p+2)}{p+1}$$ is precisely the arithmetic mean of the numbers $\zeta(2),\zeta(3),\zeta(4),\dots,\zeta(p+2)$ . Anyway, notice that the integral $$\int_1^\infty\frac{1}{x^{p+2}\lfloor x\rfloor}\text{ }dx$$ also converges for $p=-1$ . This is intuitively plausible because $\lfloor x\rfloor$ grows roughly like $x$ , so $$\frac{1}{x^{-1+2}\lfloor x\rfloor}=\frac{1}{x\lfloor x\rfloor}$$ behaves like $1/x^2$ as $x\to\infty$ , yielding a convergent integral. To clear up any doubts, I've left a proof at the bottom of the post. Now, the equation $$\int_1^\infty\frac{1}{x^{p+2}\lfloor x\rfloor}\text{ }dx=-1+\frac{1}{p+1}\sum_{m=2}^{p+2}\zeta(m)$$ doesn't make sense for $p=-1$ because substituting $-1$ for $p$ involves division by zero. Nevertheless, given the obvious connection between $$\int_1^\infty\frac{1}{x^{p+2}\lfloor x\rfloor}\text{ }dx$$ and $\zeta(n)$ for $n\in\mathbb{N}$ , I can't help but wonder if there's a link between \begin{align}
\int_1^\infty\frac{1}{x\lfloor x\rfloor}\text{ }dx &= \lim_{k\to\infty}\left(\int_1^{k+1}\frac{1}{x\lfloor x\rfloor}\text{ }dx\right)\\
&= \lim_{k\to\infty}\left(\sum_{n=1}^k \frac{\ln(n+1)-\ln(n)}{n}\right)\\
&= \sum_{n=1}^\infty \frac{\ln(n+1)-\ln(n)}{n}
\end{align} and the zeta function. Maybe it’s the exact value of zeta evaluated at some other point in the complex plane? Seeing the pattern in the identity, my only ""reasonable"" idea was to try and find a link between the sum the series (I'll call it $S$ ) and $\zeta(1)$ . This expression is undefined ( $\zeta$ has a singularity at $1$ ), but its principal value exists and equals the Euler-Mascheroni constant: $$\lim_{h\to 0}\frac{\zeta(1-h)+\zeta(1+h)}{2}=\gamma$$ We can't have an exact equality; $\gamma\approx 0.57$ , but WolframAlpha says that $S\approx 1.25$ . It's unlikely, but could these numbers be related in some other way? If not, are there any other possible links between $S$ and the zeta function? Any answer is greatly appreciated. Proof : the sequence $$\left\lbrace\int_1^{k+1}\frac{1}{x\lfloor x\rfloor}\text{ }dx\right\rbrace_{k=0}^\infty$$ is strictly increasing because the integrand is strictly positive over $[1,k+1]$ . Now, \begin{align}
\int_1^{k+1}\frac{1}{x\lfloor x\rfloor}\text{ }dx &= \int_1^2\frac{1}{x\lfloor x\rfloor}\text{ }dx+\int_2^3\frac{1}{x\lfloor x\rfloor}\text{ }dx+\cdots+\int_k^{k+1}\frac{1}{x\lfloor x\rfloor}\text{ }dx\\
&= \sum_{n=1}^k \int_n^{n+1}\frac{1}{x\lfloor x\rfloor}\text{ }dx\\
&= \sum_{n=1}^k \int_n^{n+1}\frac{1}{x\cdot n}\text{ }dx\\
&= \sum_{n=1}^k \frac{1}{n}\int_n^{n+1}\frac{1}{x}\text{ }dx\\
&= \color{green}{\sum_{n=1}^k \frac{\ln(n+1)-\ln(n)}{n}}\\
&= \sum_{n=1}^k \frac{1}{n}\ln\left(\frac{n+1}{n}\right)\\
&= \sum_{n=1}^k \frac{1}{n}\ln\left(1+\frac{1}{n}\right)\\
&< \sum_{n=1}^k \frac{1}{n}\cdot\frac{1}{n}\\
&< \sum_{n=1}^\infty \frac{1}{n^2}
\end{align} so the terms of the sequence are bounded above. It follows that $$\left\lbrace\int_1^{k+1}\frac{1}{x\lfloor x\rfloor}\text{ }dx\right\rbrace_{k=0}^\infty$$ is a convergent sequence. $\blacksquare$","['riemann-zeta', 'calculus', 'closed-form', 'sequences-and-series']"
4255277,Why is the derivative of $y=\frac x y$ different from the derivative of $y^2=x$?,"I am trying to teach myself calculus but I can't overcome this question... Since, graphically, equations $y = \frac x y$ and $y^2=x$ are the same, how come $\frac {dy}{dx}$ of the former is $\frac{y}{y^2+x}$ while the derivative of the latter is $\frac{1}{2y}$ ? Shouldn't they be the same?","['calculus', 'implicit-differentiation', 'derivatives']"
4255315,Finding formula that solves $w^4+x^4=y^4+z^4$ over the integers.,"Several formulae that solve the diophantine equation $$w^4 + x^4 = y^4+z^4 \tag{1}$$ are presented in this collection . The simplest one bases on $$f_1 = a^7 + a^5 - 2 a^3 + 3 a^2 + a \tag{2}$$ and sets $\def\hf{{}^h\!f}$ $$ (w, x, y, z) = (\hf_1,\ \hf_1(b,-a),\ \hf_1(a,-b),\ \hf_1(b,a)) $$ where $\hf(a,b) = f(a/b)\cdot b^{\deg f}$ denotes the homogenized version of $f$ . Question: How does one find such formulae? The collection refers to Hardy & Wright, and MathWorld mentions that parametric solutions to (1) were already known to Euler in 1802, but without mentioning which one. Note: $f_1$ appears to be — in some sense — the simplest of such functions:  It produces (158, 59, 134, 133) from (1,2), the smallest solution of (1). All solutions that I checked using Sage were non-trivial except for the case $a=b=1$ , and with $\gcd(a,b)=1$ all solutions satisfied $\gcd(w,x,y,z)\in\{1,2\}$ .  The last two properties also showed up for the next 2 more complicted functions from the collection that I tried like $$f_2 = -a^{13} + a^{12} + a^{11} + 5 a^{10} + 6 a^{9} - 12 a^{8} - 4 a^{7} + 7 a^{6} - 3 a^{5} - 3 a^{4} + 4 a^{3} + 2 a^{2} - a + 1
$$","['number-theory', 'diophantine-equations', 'algebraic-geometry', 'problem-solving', 'arithmetic-geometry']"
4255331,"If $ \lim_{x\to \infty} (f(x+1)-f(x))=1$, then $ \lim_{x\to \infty} \frac{f(x)}{x}=1$?","Let $f:\mathbb{R} \to \mathbb{R}$ be a fuction such that $\displaystyle \lim_{x\to \infty} (f(x+1)-f(x))=1$ . Is it true then that $\displaystyle \lim_{x\to \infty} \frac{f(x)}{x}=1$ ? I think it is and here is how I went about it. Let $\varepsilon>0$ . Then there is some $\delta_\varepsilon>0$ such that $$1-\varepsilon < f(x)-f(x-1)<1+\varepsilon, \forall x>\delta_\varepsilon.$$ Thus, we may write the following inequalities for an $x> \delta_\epsilon$ : $$1-\varepsilon < f(x)-f(x-1)<1+\varepsilon\\
1-\varepsilon < f(x-1)-f(x-2)<1+\varepsilon\\    
\vdots\\
1-\varepsilon < f(\delta_\varepsilon+1)-f(\delta_\varepsilon)<1+\varepsilon$$ and after we sum these up we get that $$(x-\delta_\epsilon)(1-\epsilon)<f(x)-f(\delta_\varepsilon)<(x-\delta_\varepsilon)(1+\varepsilon), \forall x>\delta_\varepsilon.$$ This implies that $$\frac{f(\delta_\varepsilon)+(x-\delta_\varepsilon)(1-\varepsilon)}{x}<\frac{f(x)}{x}<\frac{f(\delta_\varepsilon)+(x-\delta_\varepsilon)(1+\varepsilon)}{x}, \forall x>\delta_\varepsilon.$$ If we take $\displaystyle\limsup_{x\to\infty}$ , we get that $1-\varepsilon < \displaystyle\limsup_{x\to\infty} \frac{f(x)}{x}< 1+\varepsilon$ , $\forall \varepsilon > 0$ , so $\displaystyle\limsup_{x\to\infty} \frac{f(x)}{x}=1$ . In the same way we get that $\displaystyle\liminf_{x\to\infty} \frac{f(x)}{x}=1$ , so $\displaystyle\lim_{x\to\infty} \frac{f(x)}{x}=1$ as desired. Is this proof correct? I am a bit unsure that I am taking that $\limsup$ correctly, even though I can't see why it could be wrong.","['epsilon-delta', 'limsup-and-liminf', 'real-analysis', 'solution-verification', 'limits']"
4255356,How to reach this sum from the following limit?,"I have come across this in a probability question, and couldn't reach it by myself, and in the solution it's done in one step and I'm unsure as of why it's correct: $$\sum^{m-1}_{i=0}\binom{\lfloor{nt}\rfloor}{i}(\frac{\lambda}{n})^i(1-\frac{\lambda}{n})^{-i}(1-\frac{\lambda}{n})^{\lfloor{nt}\rfloor}$$ When $n \to \infty$ , The answer is: $$\sum^{m-1}_{i=0}\frac{(\lambda t)^i}{i!}e^{-\lambda t}$$ I know that formally I need to use the squeeze theorem for $\lfloor{nt}\rfloor$ , but working with intuition something seems off for me: $(1-\frac{\lambda}{n})^{\lfloor{n t\rfloor}}\to e^{-\lambda t}$ . ( $1-\frac{\lambda}{n})^{-i}\to 1$ . What confuses me is how did they get rid of ( $\frac{\lambda}{n})$ which goes to $0$ when $n\to \infty$ , I'm trying to open the binomial, but I'm not sure how to deal with the $(nt)!$ . Any help is really appreciated, thanks in advance!","['limits', 'probability-distributions', 'probability']"
4255368,Exercise 1.3 in Harris' Algebraic Geometry,"I am a beginner in Algebraic Geometry and was recommended to read Harris' Book about the subject. I am, however, stuck on the first exercise: Show that if $\Gamma$ consists of $d$ points and is not contained in a
line, then $\Gamma$ may be described as the zero locus of polynomials
of degree $d-1$ and less. Upon further research, the only useful hint I have found is that I am supposed to use Lagrange Interpolation ( Any set of $d$ points in a projective space is the zero locus of polynomials of degree $d-1$? ). I have thus far been unable to apply it here. Could anyone please help me and explain it in an understandable manner? Thank you!","['algebraic-geometry', 'projective-geometry', 'projective-space']"
4255378,Does every Lie group have at most countably many connectected components?,"Some proofs in a lecture I took were motivated by this statement that ""some people don't assume second countability when they define a topological manifold, but for Lie groups we get this property for free"". They then proved the statement ""if a Lie group G has at most countably many connected components then G is second countable"" alongside some other related topological results. I see how if we assume second countability in our definition of a topological manifold that we must have at most countably many connected components. So I see the if and only if statement, but this isn't the same thing as saying every Lie group is second countable. So my question is if we don't include second countability in our definition of a topological manifold can we show every Lie group has at most countably many connected components? If not is there an example of a Lie group that this definition admits that is excluded when we assume topological manifolds are second countable?","['connectedness', 'second-countable', 'general-topology', 'lie-groups', 'differential-geometry']"
4255504,Radical expression for $\tan 14.4^\circ$,"Given that $\displaystyle\cos 20^\circ=\frac{\sqrt[3]{\frac{1-i\sqrt{3}}{2}}+\sqrt[3]{\frac{1+i\sqrt{3}}{2}}}{2}$ and $\displaystyle\sin 20^\circ=\frac{i\left(\sqrt[3]{\frac{1-i\sqrt{3}}{2}}-\sqrt[3]{\frac{1+i\sqrt{3}}{2}}\right)}{2}$ It turns out that there is a nice radical expression for $\tan 20^\circ$ : $\displaystyle\tan 20^\circ=\sqrt{11-\left(1-i\sqrt{3}\right)\sqrt[3]{148+4i\sqrt{3}}-\left(1+i\sqrt{3}\right)\sqrt[3]{148-4i\sqrt{3}}}$ . My question is, how did one get from the first two expressions to the third? It's pretty straightforward to find the minimal polynomial for $\cos 20^\circ$ from the triple-angle formulas, which is $8x^3-6x-1=0$ . In other words, where did the three ""new"" numbers ( $11$ and $37\pm i\sqrt{3}$ ) in the expression come from? Now a similar situation arises for $\tan 14.4^\circ$ : $\displaystyle\cos 14.4^\circ=\frac{\sqrt[5]{\frac{-1+\sqrt{5}-i\sqrt{10+2\sqrt{5}}}{4}}+\sqrt[5]{\frac{-1+\sqrt{5}+i\sqrt{10+2\sqrt{5}}}{4}}}{2}$ and likewise for $\sin 14.4^\circ$ . My gut instinct is that $\tan 14.4^\circ$ can be written as $\tan 14.4^\circ=\sqrt{a-\left(-1+\sqrt{5}-i\sqrt{10+2\sqrt{5}}\right)\sqrt[5]{b+ci}-\left(-1+\sqrt{5}+i\sqrt{10+2\sqrt{5}}\right)\sqrt[5]{b-ci}}$ for some algebraic $a, b,$ and $c.$ My question is, what are the values of a, b, and c? And I'm betting that my ""gut instinct"" on $\tan 14.4^\circ$ is wrong, so if anyone could help me derive the radical expression for $\tan 14.4^\circ$ , that would be great.","['trigonometry', 'roots-of-unity', 'complex-numbers']"
4255525,Problem on rank of a matrix-Mathematics Competition,"Hi, this problem is from a previous year question paper of a math competition which is held in our college annually. I hope it is  allowed to discuss these problems here, if not please let me know. Let $m,n\in \mathbb N$ .
Find the rank of the block matrix $C$ , where $C=\begin{pmatrix} (J-I)_{m\times m} & J_{m\times n}\\
J^T_{n\times m} & A_{n\times n}\end{pmatrix}$ .
Here $J$ is the matrix with all $1$ , and $A$ has rank $n$ with $A\neq J, I, J-I$ . My try :
The eigenvalues of $(J-I)_{m\times m} $ are $m-1$ with multiplicity $1$ and $-1$ with multiplicity $m-1$ . I am guessing that Rank( $C)=m+n$ , but I dont know any means to prove it.
Does there exist any particular result by which rank of block matrices can be determined. I have just started reading matrix theory, so I am not quite sure on how to proceed with these type of problems. Can someone please point me towards any text or provide me some hints on how to complete this problem? Apologies for giving the problem wrong. It has been edited now.","['matrices', 'matrix-rank', 'eigenvalues-eigenvectors']"
4255618,In infinite dimensional vector spaces the complementary of a compact is connected,"Let $X$ be an infinite dimensional normed vector space and $K$ a compact subset of $X$ . I want to show that $K^c$ is connected by path. I know that the unity sphere $\mathbb{S} := S(0,1)$ is connected by path and that up to an homeomorphism I can assume $K \subset \mathbb{B} := B(0,1)$ . So I only need to find a path from $x$ to a certain $u \in \mathbb{S}$ , for any $x \in K^c$ . I was suggested to look at the easiest paths, $t \mapsto (1-t)x+tu$ , but I fail to conclude. Any help would be appreciated.","['path-connected', 'normed-spaces', 'functional-analysis', 'general-topology', 'compactness']"
4255628,Proof of geometric series formula,"So for, the above formula, how did they get $(n+1)$ a for the geometric progression when $r = 1$ .  I also am confused where the negative a comes from in the following sequence of steps.","['geometric-series', 'discrete-mathematics']"
4255645,Contour integral along a straight line - why does this simple practice problem fail to be simple?,"Use the residue theorem to compute: $$I=\int_0^\infty\frac{1}{x^3+1}\,\mathrm{d}x$$ By using the contour that goes first from $0\to r$ along the real axis ( $\gamma_1$ ), then in an arc from $r\to r\exp(\frac{2}{3}\pi i)$ ( $\gamma_2$ ), then in a straight line from $r\exp(\frac{2}{3}\pi i)\to0$ ( $\gamma_3$ ), taking limits as $r\to\infty$ . Firstly we need to show that the integral along this contour is equivalent to the integral along the real axis, as $r\to\infty$ , so it first must be shown that: $$\lim_{r\to\infty}\int_{\gamma_2}\frac{1}{z^3+1}\,\mathrm{d}z=0$$ This part is straightforward: noticing that the arc, when cubed, is transformed to a circle of radius $r^3$ - missing the point $(r^3,0)$ - and adding $1$ to all values on this circle shifts the circle such that the smallest value of $|z^3+1|$ is $r^3-1$ : $$0\le\lim_{r\to\infty}\left|\int_{\gamma_2}\frac{1}{z^3+1}\,dz\right|\le\lim_{r\to\infty}\frac{2}{3}\pi r\cdot\sup_{\gamma_2}\frac{1}{|z^3+1|}\le\lim_{r\to\infty}\frac{2}{3}\pi r\cdot\frac{1}{r^3-1}=0$$ So the contour $\gamma_2$ is accounted for. Sadly, using the same estimation trick on the straight line segment $\gamma_3$ fails, since the maximum value of $(z^3+1)^{-1}$ on $\gamma_3$ is just $1$ , which fails to give a limit to zero. Deciding to crack the integral by hand, I proceeded: $$\begin{align}\int_{\gamma_3}\frac{1}{z^3+1}\,\mathrm{d}z&=\int_r^0\frac{\exp\frac{2}{3}\pi i}{(t\exp\frac{2}{3}\pi i)^3+1}\,\mathrm{d}t\\&=-\exp\frac{2}{3}\pi i\int_0^r\frac{1}{t^3+1}\,\mathrm{d}t\end{align}$$ And got immediately stuck. According to Wolfram Alpha, the antiderivative does exist but it is not at all clear that as $r\to\infty$ , the integral goes to $0$ . Besides, this is a practice problem; although university level, I doubt one has to crack a very tricky antiderivative and an unclear limit. What am I doing wrong? As far as I understand it, in order for the residue theorem to be of any use, the contour integral enclosing the singularity must first be shown to evaluate to the integral along the real axis.","['integration', 'complex-analysis', 'residue-calculus', 'improper-integrals']"
4255660,Why are soliton solutions interesting mathematically or physically?,"I've seen a great deal about classes of PDEs, particularly dispersive equations (e.g. KdV, NLS, Sine-Gordon) which permit soliton , or wave-packet solutions. My understanding of why these might be interesting is that they behave in a particle-like manner, experiencing things like elastic collisions and the like. Furthermore in cases like NLS, there is the soliton resolution conjecture which seems to roughly claim that the nonlinearity decomposes into a linear evolution plus soliton solutions. I have a rather vague question around this, being rather out of the loop, which is something like: why is the existence of soliton solutions mathematically or physically interesting in a broad sense? How come equations with these types of solutions are very popular to study these days? Secretly, I'm wondering: do soliton solutions help us characterize nonlinear equations in some broad sense the same way spectral theory does for linear equations?","['soliton-theory', 'functional-analysis', 'partial-differential-equations', 'nonlinear-system', 'mathematical-physics']"
4255699,Change of two normal coordinates based on two nearby points?,"Let $M$ be a manifold and $L(M)$ be the tangent frame bundle on $M$ . Let $\Gamma$ be a linear connection on $L(M)$ which induces a covariant derivative $\nabla$ on $TM$ . Let $p, q$ be two distinguished and sufficiently close points on $M$ , connected by a smooth curve $\gamma = \{\gamma_t\}_{t\in[0,\epsilon]}$ so that $\gamma(0)=p$ , $\gamma(\epsilon)=q$ . Suppose that there is an open set $U\subset M$ , such that $U$ contains $\gamma$ and is a normal neighborhood of both $p$ and $q$ . Fix a linear frame $u_p \in L_p(M): \mathbf R^d\to T_pM$ . Let $u_q = \Gamma(\gamma)_0^\epsilon (u_p) \in L_q(M)$ be the parallel displacement of $u_p$ along $\gamma$ , that is, $u_q$ can be joined to $u_p$ by a horizontal curve on $L(M)$ along $\gamma$ . Then we have two normal coordinate systems on $U$ : $$x=u_p^{-1}\circ \exp_p^{-1}: U \to \mathbf R^d,$$ $$y=u_q^{-1}\circ \exp_q^{-1}: U \to \mathbf R^d,$$ so that $(U,(x^i))$ and $(U,(y^j))$ are coordinate charts based on $p$ and $q$ respectively. Now my question is: how to do change of coordinates between these two normal coordinate charts? More precisely, let $m \in U$ , then what is the relation between $x(m)$ and $y(m)$ ? If necessary, you can endow more structures to $M$ . Say, $M$ is equipped with a Riemannian metric $g$ and $\nabla$ is the Levi-Civita connection , the frame bundle $L(M)$ is replaced by the orthonormal frame bundle $O(M)$ ... Some thinking: Clearly, $x(p) = y(q) = 0$ . If $\gamma$ is a geodesic , then it is easy to check $x(q) = -y(p)$ . Denote $\rho = x(q) \in\mathbf R^d$ . Then I believe that $x(m) = y(m) + \rho$ for all $m \in U$ . If $\gamma$ is not a geodesic , then I think that a curvature term should appear, since we may use the holonomy . But I do not know how to prove my conjectures... EDIT: I think there maybe no exact expressions for $x(m)$ and $y(m)$ , but there should be an asymptotic expression with infinitesimals $o(\epsilon)$ or $o(d(x,y))$ ...","['riemannian-geometry', 'principal-bundles', 'connections', 'tangent-bundle', 'differential-geometry']"
4255702,On the description of $\mathbb P^n_k$,"Vakil's Exercise 4.4.F is asking to show that if $k$ is algebraically closed, then the closed points of $\mathbb P^n_k$ may be interpreted in the traditional way, i.e., as points of the form $(a_,\dots, a_n)$ where not all $a_i$ are zero and $(a_0,\dots, a_n)$ is identified with $(\lambda a_0,\dots, \lambda a_n)$ for $\lambda \in k^\times$ . I'm not sure what exactly I need to do to prove this. The scheme $\mathbb P^n_k$ is glued from $U_i=\operatorname {Spec} k[x_0/x_i,\dots,\widehat{x_i/x_i}, \dots, x_n/x_i] $ , but I don't have a clear understanding of how they glue together (one just checks that certain conditions hold and hence they glue, but I don't understand the explicit construction) and what exactly the closed points are. Closed points should correspond to prime ideals of some ring, and some of them should be identified. Is the ring the polynomial ring in $n$ variables? Or one in $n+1$ variables? I also found the following solution, which I don't really understand: Are they mapping the point $[a_0:\dots :a_n]$ where $a_j\ne 0$ to the prime ideal $(x_0/x_j - a_0/a_j,\dots , \widehat{x_j/x_j-a_j/a_j}, \dots, x_n/x_j-a_n/a_j)\in U_j$ ? If so, why is this a closed point (or even any kind of point) of $\mathbb P^n_k$ ? From what I understand, $U_i s $ don't exactly have to be subsets of $\mathbb P^n_k$ , they are only used to construct $\mathbb P^n_k$ . Or does the part ""which is compatible under isomorphisms"" (I don't understand what it means) ensure that this is indeed a closed point of $\mathbb P^n_k$ ? Any further details would be helpful.","['proof-explanation', 'algebraic-geometry', 'schemes', 'projective-space']"
4255724,Find the maximum of the following function of summation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I ran into this problem: $$f(\sigma)= \sum_{i=\sigma-1}^{n-1} \Bigg (\frac{\sigma-1}{i} \Bigg)^2$$ Find the maximum of this function with $1<\sigma<n$ , $n>4$ . My conjecture is that it achieves max with $\sigma=\frac{n}{2}+1$ when $n$ is even and $\sigma=\frac{n-1}{2}+1$ when $n$ is odd (according to a simulation). However I cannot prove this. Any hint on what I can do?
Thanks a lot!","['number-theory', 'optimization', 'discrete-mathematics']"
4255749,"Could the notation $\{1, a \mid a\in A\}$ make sense?","Does having more than one variable before the vertical bar $|$ in the Set-builder notation make sense? For example, does the notation $\{a,b\mid a\in A, b \in B\}$ mean the set $A \cup B $ ? This form of writing, if acceptable to mathematicians, can provide us with some benefits. Let's say $A$ is a finite subset of $\mathbb{R}$ and we want to find the minimum value among the square of elements of $A$ and the number 1. That would be $\min\{\min\{a^2\mid a\in A\},\;1\}$ or $\min(\{a^2 \mid a\in A\}\cup\{1\})$ . But would it be mathematically correct or acceptable to simply write $\min\{1,a^2 \mid a\in A\}$ ? Would it be meaningful to use the notation $\{x_1,x_2,\cdots,x_n\,|\; P(x_1, x_2,\cdots, x_n)\}$ ? It is supposed to mean the set of all elements $x_1, \cdots, x_{n-1}$ , and $x_n$ such that a certain property is satisfied between the ordered elements of $(x_1, x_2,\cdots, x_n)$ . Actually, we want to define the following notation if appropriate: $$\{x,y\,|\; P(x, y)\}:= \left\{ x\,|\; \exists\,(x,y) \; \text{ s.t }\; P(x,y)\right\} \cup \left\{ y\,|\; \exists\,(x,y) \; \text{ s.t }\; P(x,y)\right\}$$ You could easily extend this to $n$ elements.",['elementary-set-theory']
4255764,"Number of $F_p$-points on standard quadric $\sum x_i^2=0$ (quadratic cone) is $p^{n-1}+ (-1)^{???}(p^{n/2} - p^{n/2-1}) $, n-even?","That should be very well-known. Consider $\sum_{i=1...n} x_i^2=0$ over finite field $F_p$ . (1) Seems number of solutions is $p^{n-1}$ for $n$ is odd i.e. $n=2k+1$ .
That seems to be not difficult to explain. (2) And can be given by polynomials  for $n=2k$ ,
where polynomial works for all except finite set of primes: $n = 4$ , $p^3+p^2-p	$ for p>2 ? (Checked for p=3,5,7,11,13,17,19,23, 29, 31) $n = 6$ , Here the answer seems to depend on p%4 $p^5+(p^3-p^2)$ for p>2 and $p\%4==1$ ? (Checked for p=5,13) $p^5-(p^3-p^2)$ for p>2 and $p\%4 == 3$ ? (Checked for p=3,7,11) $n = 8$ , $p^7+p^4-p^3$ for p>2 ? (Checked for p=3,5,7) So the general guess would be: $n=2k$ , Count equals to: $$p^{n-1}+ (-1)^{sign}(p^{n/2} - p^{n/2-1}) $$ where for n=4k, sign = +1, while for n=4k+2 sign depends on p%4 Question: I wonder is that correct ? The question has beed edited, in initial version hypothesis on ""sign"" was not correct. Simulation code can be found here: https://www.kaggle.com/alexandervc/count-f-q-points-on-quadric-cone-sum-x-i-2-0","['number-theory', 'finite-fields', 'algebraic-geometry']"
4255781,Proof that no set is equinumerous to its power set,"I am studying from Enderton's book ""Elements of set theory"" and I am struggling with the proof that "" No set is equinumerous to its power set "". Here is the proof: Let $g: A\rightarrow \mathcal{P}A$ ; we will construct a subset $B$ of $A$ that is not in ran $g$ . Specifically, let $B = \{x\in A\mid x\notin g(x)\}$ . Then $B\subseteq A$ , but for each $x\in A$ , $x\in B$ iff $x\notin g(x)$ . Hence $B\neq g(x)$ . I saw on the web another proof that is almost the same and seems a tiny bit clearer, but I am having the same trouble. The doubt is: what prevents us from thinking that $x\notin g(x)$ is actually a contradiction, just like $x\neq x$ , and that therefore $B=\emptyset$ ? This proof seems to assume that there must be an $x$ such that $x\notin g(x)$ , but I don't see where this is coming from. I am a just starting undergrad student, I am sorry if this question may be a bit naive. Thanks.",['elementary-set-theory']
4255812,Evaluating $\int_{-\infty }^{\infty }\cos x^3\sin x^2dx$ without the Airy function,"$$\int\limits_{-\infty }^{\infty }\cos x^3\sin x^2dx$$ I solved this problem using the special ""Airy function"". Question: is it possible to solve it in another way? $$\begin{align}
\int\limits_{-\infty }^{\infty }\cos x^3\sin x^2dx&=\frac{1}{3^{1/3}}\int\limits_{-\infty }^{\infty }\cos \frac{t^3}{3}\sin 3^{-2/3}t^2dt \\[1ex]
&=\frac{1}{3^{1/3}}\Im \int\limits_{-\infty }^{\infty }\exp \left \{ i\left [ \frac{t^3}{3}+3^{-2/3}t^2 \right ] \right \}dt \\[1ex]
&=\frac{1}{3^{1/3}}\Im \left \{ 2\pi \exp \left \{ 3^{-2/3}i\left [ \frac{2}{3}\left ( 3^{-2/3} \right )^2 \right ] \right \}\operatorname{Ai}\left ( 0-\left [ 3^{-2/3} \right ]^2 \right ) \right \} \\[1ex]
&=\frac{2\pi}{3^{1/3}}\sin \frac{2}{27}\cdot \operatorname{Ai}\left ( -3^{-4/3} \right )
\end{align}$$","['integration', 'calculus', 'real-analysis']"
4255825,Eigenvector matrix times diagonal matrix equals original matrix times eigenvector matrix?,"Suppose we have a $n\times n$ real symmetric matrix $A$ , and $V=[v_1\ v_2\cdots v_n]$ whose columns are the eigenvectors corresponding to the $n$ eigenvalues $\lambda_1,\ldots,\lambda_n$ .
Let $D$ be a diagonal matrix ${\rm diag}[\lambda_1\cdots\lambda_n]$ , where $\lambda_i$ are the eigenvalues of $A$ for $i=1,\ldots,n$ . How do we prove that $A𝑉 = 𝑉D$ ? edit: I realized what I said below is incorrect because multiplying $𝑉D$ does not give a diagonal matrix. But I am still confused as how I would know that $A𝑉 = 𝑉D$ when not given any numbers. I was trying to start this proof with expanding $𝑉D$ and I got another diagonal matrix with the diagonal entries being $v_1\lambda_1,\ldots,v_n\lambda_n$ and all other entries being $0$ .
I am unsure how this could be equivalent to A𝑉 because wouldn't this resultant matrix not be a diagonal matrix? Or how would we know without knowing what the entries of A are?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
4255828,Prove that $\eta (1/2) \gt \frac{\sqrt 2 \pi^2}{48}$,"Prove that $\eta (1/2) \gt \frac{\sqrt 2 \pi^2}{48}$ I am out of any good ideas, but the $\pi^2$ suggests some comparison with $\zeta(2)$ . Here is a bad try: $$\eta (1/2) \gt 1-\frac{1}{\sqrt 2} + \frac{1}{\sqrt 3}$$ Now it just remains to show that $\frac{\sqrt 2 \pi^2}{48} \lt 1-\frac{1}{\sqrt 2} + \frac{1}{\sqrt 3}$ . Any ideas?","['inequality', 'zeta-functions', 'analysis']"
4255857,"Let $G$ be a group of order $n$ where every non identity element is of order $2$. Then, ${\rm Aut}(G) $ is isomorphic to $S_{n-1}$","Let $G$ be a group of order $n$ where every non identity element is of order $2$ . Then, ${\rm Aut}(G) $ is isomorphic to $S_{n-1}$ . Is this true? I read that ${\rm Aut}(K_4)$ is isomorphic to $S_3$ . We can see this because of the permutations of the non identity elements, all of which have order $2$ . So for each non identity element, we have $3$ choices for it's image. Proceeding recursively, we get $3!$ and ${\rm Aut}(K_4)$ is isomorphic to $S_3$ . Can we further generalize this idea to groups in which all non identity elements are of order $2$ ? Thanks in advance!","['automorphism-group', 'abstract-algebra', 'symmetric-groups', 'group-theory', 'abelian-groups']"
4255909,"Defining operation $*$ as $x*y=\frac{x+y}{1+xy}$, what is the value of $1*(2*(3*(4*5)))$?","We are defining the operation $*$ in rational numbers set as $$x*y=\frac{x+y}{1+xy}$$ What is the value of $1*(2*(3*(4*5)))$ ? $1)1\qquad\qquad2)15\qquad\qquad3)\frac32\qquad\qquad4)\frac45\qquad\qquad5)4$ To solve this problem I just evaluated the expression, $$4*5=\frac37\qquad\qquad3*(4*5)=\frac32\qquad\qquad2*(3*(4*5))=\frac78$$ And finally $$1*(2*(3*(4*5)))=1$$ Although it is very easy to do these calculations I think there is some elegant method to obtain $1$ . Can you please solve it with other approaches?","['contest-math', 'algebra-precalculus']"
4255921,Prove vector area formula by stokes's theorem,"wiki says the following two formulas are equivalent. ${\mathbf {S}}=\int d{\mathbf {S}}$ ${\displaystyle \mathbf {S} ={\frac {1}{2}}\oint _{\partial S}{\vec {r}}\times d{\vec {r}}}$ I am learning exterior derivative and the generalized stokes' theorem ${\displaystyle \int _{\partial \Omega }\omega =\int _{\Omega }d\omega \,}$ , but when I applied $d(r \wedge dr) = dr \wedge dr - r \wedge ddr= dr \wedge dr + 0 = 0 \Rightarrow S = 0$ where did I do wrong? Any help is appreciated.","['stokes-theorem', 'exterior-algebra', 'vector-analysis', 'differential-geometry']"
4255937,Question about getting a formula for a recurrence relations,"https://www.youtube.com/watch?v=7mhvA5L7KqY&ab_channel=TrevTutor So basically, I was watching video above which is on recurrence relations and I had a question about this statement (which is at timestamp 5:21): $$a_n=a_{n-1}+6a_{n-2}\Longrightarrow a_n=\alpha(-2)^n+\beta(3)^n.$$ I understand how he got the $(-2)^n$ and $(3)^n$ , but not about how he is adding them and then multiplying them by the variables $\alpha$ and $\beta$ . He said that there is a proof online about why there is always going to be an $\alpha$ and a $\beta$ that will always make this statement true, but I wasn't able to find it and I was hoping that somebody could give me a step by step explanation about how this is. I was also wondering about the general case for getting a formula for recurrence relations in this form. Note:
I read somewhere that you can derive this from generating functions, but I don't have a strong background in them, so I was wondering if there is another way to derive the relation.","['recursion', 'recurrence-relations', 'discrete-mathematics', 'generating-functions']"
4256017,Problem in the derivation of the relation between $\sin^{-1}(x)$ & $\cos^{-1}(x)$,"My book's derivation : Let, $\sin^{-1}x=\theta\implies \sin\theta=x$ Now, $\cos\theta=\sqrt{1-\sin^2\theta}=\sqrt{1-x^2}\implies\theta=\cos^{-1}\sqrt{1-x^2}$ So, $$\fbox{$\theta=\sin^{-1}x=\cos^{-1}\sqrt{1-x^2}$}$$ My problem : My problem with this derivation is that $\sqrt{1-x^2}$ is always positive. So, the principal value of $\theta$ will always remain in the 1st quadrant. So, for negative values of $\cos\theta$ , we will not be able to determine $\theta$ accurately. So, how will I find the correct value of $\theta$ when $\cos\theta$ is negative? So, how will I find the correct value of $\theta$ when $\cos\theta$ is negative? Example of my problem: Let $\theta_1=\cos^{-1}(\frac{-4}{5})=\sin^{-1}(\frac{3}{5})$ is in the 2nd quadrant, so $\theta_1=143.1301^{\circ}$ , but according to the derived formula $\theta_2=\cos^{-1}(\sqrt{1-(\frac{3}{5})^2})=36.869^{\circ}$ , so we can see that $\theta_1\neq \theta_2$ when they should've been equal. This formula can't differentiate between when $\cos^{-1}(x)$ is in the 1st quadrant or when it is in the second quadrant. How do I find the value of $\theta$ correctly when $\cos\theta$ is negative or is the formula so that I just can't?",['trigonometry']
4256018,Average area of triangle formed ${1\over8}$ that of square,"Here's a question from my infamous probability textbook: A point is taken at random in each of the two adjacent sides of a square. Show that the average area of the triangle formed by joining them is one eighth of the area of the square. Intuitively, this makes sense since if I select the midpoints of two adjacent sides of the square, the triangle formed has ${1\over8}$ the area of the square. But I'm not sure how to go about averaging across all triangles i.e. what's the correct integral to setup. Any help would be well-appreciated. EDIT: Following Ninad Munshi's hint in the comments, I got the expression $${{\int_0^1 \int_0^1 {{xy}\over2}\,\text{d}x\,\text{d}y}\over{1^2}},$$ which indeed evaluates to ${1\over8}$ after a short calculation. But it feels like magic, can anyone explain in depth and conceptually why this integral gets us the desired probability? EDIT 2: Thanks to heropup for his answer. However, I am asking for an explanation that specifically addresses my concerns in my previous edit, which his answer unfortunately does not.","['integration', 'geometric-probability', 'multivariable-calculus', 'calculus', 'probability']"
4256025,Arranging books in bookshelves with the capacity of each shelf given,"I am struggling to solve the problem on Combinatorics: There are $k$ identical bookshelves in which each shelf cannot contain $m$ or more books. In how many ways can $n$ distinct books be arranged on these $k$ bookshelves? If there is no condition on the capacity of each shelf, the number of ways to arrange books equals $\sum_{i \in [k]} L(n, i)$ , where $L(n, i)$ denotes the Lah number. However, because of that constraint, I have trouble in solving the problem. I tried several ways to solve this problem by separating the cases via (1) the number of shelves which contains the full-number of books, or (2) the number of non-empty shelves. For the second trial, I observed that, if $j$ denotes the number of non-empty shelves, then the number of ways to arrange the books is zero if $j < \lfloor n/m \rfloor$ . However, these methods does not proceed quite well, since it looks like these methods result in the recurrence relation rather than the exact form of the number. For the related concepts, I have studied Catalan number, (both signed and unsigned) first and second Stirling number, Bell and Lah number, and the integer partition. Any insight or comment are welcomed.","['set-partition', 'combinatorics', 'discrete-mathematics']"
4256027,Entire function satisfying $f(f(z))=f'(z)$,"I met this problem preparing for my qualifying exam: Find all entire function $f$ such that $f(f(z))=f'(z)$ for all $z$ . My guess is that $f$ is a constant so I may need Liouville's theorem somewhere, but I don't see how. Any help is appreciated.","['complex-analysis', 'complex-numbers', 'analysis']"
4256062,Question about exact ODE. Why in $h'(y)$ contain $x$?,"Find the solution ODE $$\left(x^3e^xy+4x^2e^xy+2xe^xy\right)dx+(x^3e^x+x^2e^x)dy=0.$$ Let $M(x,y)=x^3e^xy+4x^2e^xy+2y$ and $N(x,y)=x^3e^x+x^2e^x$ . \begin{align*}
	\dfrac{\partial M}{\partial y}&=\dfrac{\partial}{\partial y}\left(x^3e^xy+4x^2e^xy+2xe^xy\right) \\
	&=x^3e^x+4x^2e^x+2xe^x.\\
	\dfrac{\partial N}{\partial x}&=\dfrac{\partial}{\partial x}\left(x^3e^x+x^2e^x\right) \\
	&=3x^2e^x+x^3e^x+2xe^x+x^2e^x\\
	&=x^3e^x+4x^2e^x+2xe^x.
\end{align*} This is exact ODE since $\dfrac{\partial M}{\partial y}= \dfrac{\partial N}{\partial x}$ . Now, \begin{alignat}{2}
	&&\dfrac{\partial F(x,y)}{\partial x}&=M(x,y)\nonumber\\
	\Longleftrightarrow\quad
	&&\dfrac{\partial F(x,y)}{\partial x}&=x^3e^xy+4x^2e^xy+2y\nonumber\\
	\Longleftrightarrow\quad
	&&\int\partial F(x,y)&=\int\left(x^3e^xy+4x^2e^xy+2y\right) \partial x\nonumber\\
	\Longleftrightarrow\quad
	&&\int\partial F(x,y)&=\int x^3e^xy\partial x+\int4x^2e^xy \partial x+\int2y \partial x.\label{ijoet}
\end{alignat} Consider that \begin{align}
	\int x^3e^xy\partial x&=x^3e^xy-\int e^xy 3x^2 \partial x\nonumber\\
	&=x^3e^xy-\int 3x^2 e^x y \partial x\nonumber\\
	&=x^3e^xy-\left(3x^2e^x y-\int e^x y 6x \partial x\right)\nonumber\\
	&=x^3e^xy-3x^2e^x y+\int  6x e^x y\partial x\nonumber\\
	&=x^3e^xy-3x^2e^x y+6x e^x y-\int e^x y 6\partial x\nonumber\\
	&=x^3e^xy-3x^2e^x y+6x e^x y- 6 e^x y+h_1(y).\label{meong}
\end{align} \begin{align}
	\int 4x^2e^xy\partial x&=4x^2e^xy-\int e^xy 8x \partial x\nonumber\\
	&=4x^2e^xy-\int 8x e^xy  \partial x\nonumber\\
	&=4x^2e^xy-\left(8x e^xy-\int e^xy 8 \partial x\right)\nonumber\\
	&=4x^2e^xy-8x e^xy+\int 8e^xy \partial x\nonumber\\
	&=4x^2e^xy-8x e^xy+ 8e^xy +h_2(y).\label{meong1}
\end{align} \begin{align}
	\int2y \partial x&= 2xy+h_3(y).\label{meong2}
\end{align} So, we have \begin{alignat}{2}
	&&\int\partial F(x,y)&=x^3e^xy-3x^2e^x y+6x e^x y- 6 e^x y+h_1(y)\nonumber\\
	&&&\quad +4x^2e^xy-8x e^xy+ 8e^xy +h_2(y)+2xy+h_3(y)\nonumber\\
	\Longleftrightarrow\quad
	&&F(x,y)&=x^3e^xy+x^2e^x y-2 x e^x y+2e^x y+2xy +h(y)\nonumber
\end{alignat} which $h(y)=h_1(y)+h_2(y)+h_3(y)$ . Next, consider that \begin{alignat*}{2}
	&&\dfrac{\partial F(x,y)}{\partial y}&=N(x,y)\\
	\Longleftrightarrow\quad
	&&\dfrac{\partial}{\partial y}\left(x^3e^xy+x^2e^x y-2 x e^x y+2e^x y+2xy +h(y)\right)&=x^3e^x+x^2e^x\\
	\Longleftrightarrow\quad
	&&x^3e^x+x^2e^x -2 x e^x +2e^x +2x +h'(y)&=x^3e^x+x^2e^x\\
	\Longleftrightarrow\quad
	&&h'(y)&=2 x e^x -2e^x -2x \\
\end{alignat*} When I want to find $h(y)$ , I have found $h'(y)=2 x e^x -2e^x -2x$ .
Why in $h'(y)$ contain $x$ ? What my mistake?",['ordinary-differential-equations']
4256063,Why is the Kaluza-Klein ansatz the natural choice?,"In Kaluza-Klein theory we can choose a parametrisation for the 5-dimensional metric: $$d\hat{s}^2 \equiv \hat{g}_{ab} dx^a dx^b = g_{\mu\nu}dx^\mu dx^\nu + \phi^2(dz + A_\mu dx^\mu)^2 $$ where $g_{\mu\nu}$ is the metric for the 4 ""large"" dimensions (the base manifold) and $z$ is the coordinate running along the fifth dimension (the fiber). Greek indices run from 0 to 3 while latin indices run from 0 to 4 ( $z\equiv x^4$ ). The scalar $\phi$ parametrises the size of the extra dimension. I have heard that this choice of metric is ""natural"" from the fiber bundle perspective, within which the 5D spacetime is considered as a $U(1)$ -principle bundle and $A_\mu$ are the components of a connection 1-form defined on that bundle. For example, here the author says that this choice of metric: Preserves the split between vertical and horizontal vectors Has metric on the horizontal subspace isomorphic to the metric on the base space Has metric on the vertical subspace isomorphic to some metric on the Lie algebra of the structure group ( $U(1)$ in this case) First question: I am not sure I understand these conditions properly so would appreciate any further explanation. I believe that the connection $A$ is defined to vanish on horizontal vectors so my best guess for the first point is that $\hat{g}_{a\nu} V^a = g_{\mu\nu}V^\mu$ and $\hat{g}_{a4} V^a = 0$ for a horizontal vector $V$ . And $\hat{g}_{ab}V^a = \hat{g}_{4b}V^4$ for a vertical vector $V$ . For the second and third points I don't know what the definition of an isomorphism between metrics is. I would guess $\phi^2 dz^2$ is the metric on the vertical subspace and $g_{\mu\nu}$ is the metric on the horizontal subspace, so can see that these are equivalent in some sense to what they're supposed to be equivalent to, though I am shaky on the formalities. Second question: My understanding is that there is a difference between a connection defined on the whole bundle, and the ""local connection"" defined on the base manifold (see e.g. ""Pull back via trivializing section"" here ). Which one of these is $A$ technically? Third question: The term $dz + A$ in the metric looks very similar to a gauge covariant derivative (but with $dz$ replacing a partial derivative). What's the explicit connection between the two? Final question: What are the differences between Kaluza-Klein theory and regular electromagnetism, considered from the fiber bundle perspective? (Have reposted from the physics stack exchange as the question could be more relevant here)","['fiber-bundles', 'electromagnetism', 'general-relativity', 'differential-geometry']"
4256079,"Can SIR models explain reduction in COVID case numbers in Florida and Texas, despite lack of restrictions?","This is a question about SIR or SEIR models and understanding the trajectory of the covid infections in Florida and Texas in September 2021. This is a genuinely academic question, and not meant to be political in any way. I am not sure this is the best SE site for this question, but it is definitely the best one to ask questions about SIR models, so let me give it a try. I have been watching the rapid rise in covid cases in Florida and Texas due to the Delta variant of Covid over the past 6 weeks or so. As we know, the governor in Florida and Texas were quite opposed to imposing any restrictions for masking or encouraging vaccinations, etc. That is just what I am seeing in the new coverage. Now SIR models are used to model epidemic disease spread. So if we have a mixing population with no additional restrictions, a vanilla SIR model would predict continued transmission of the illness until everyone is either recovered, infected, or dead. That is the very toy and simple result of what an SIR model would provide. Now, I am trying to understand what is causing the deceleration in cases in Florida and Texas, given that these states don't seem to be taking the actions that would diminish the transmission rate for the delta strain. That is the question? It could be that despite the governor's actions in both states, the local restrictions are having an impact. Though I have not heard of any locally imposed lockdown or such--I figured the governor would need to order that. Or is it that people are just changing their own behavior to increase distancing or not going to restaurants again,etc? Or are the governors doing more than is covered on the news? Again, I know that SIR models are far from predictive models, but I was just trying to understand how these real life waves of infection can end when restrictions are seemingly not imposed. Again, my question is simply academic. Thanks.","['biology', 'mathematical-modeling', 'ordinary-differential-equations']"
4256125,Syndeticity- and thickness-preserving bijections of $\mathbb N$,"Let me recall some definitions: a set $A \subseteq \mathbb N$ is: syndetic if it intersects every large enough interval, i.e. if $\exists \ell \in \mathbb N^* : \forall k \in \mathbb N, A \cap ⟦ k, k+\ell - 1 ⟧ \neq\varnothing$ ; thick if it contains arbitrarily long intervals, i.e. if $\forall \ell \in \mathbb N^*, \exists k \in \mathbb N : ⟦k, k+\ell-1⟧ \subseteq A$ . I'm interested in bijections $\mathbb N \to \mathbb N$ preserving these two notions. More precisely, I say that a bijection $f : \mathbb N \to \mathbb N$ preserves thickness if, for every set $A \subset \mathbb N$ , $A$ thick $\implies$ $f[A]$ thick ; strongly preserves thickness if, for every set $A \subset \mathbb N$ , $A$ thick $\iff$ $f[A]$ thick. I can define the same notions for syndeticity, but they are at least partly redundant. Indeed, a set $A$ is syndetic iff $\mathbb N \setminus A$ isn't thick. That shows that a bijection strongly preserves thickness iff it strongly preserves syndeticity. My first question is the following: Do you have an example of a bijection $f : \mathbb N \to \mathbb N$ which preserves thickness, but doesn't preserve it strongly? I'm not sure my second question has a satisfying answer, but here it is: What is a good description of (strongly) thickness-preserving bijections? Here's a (hopefully correct) very partial answer: if $W(\mathbb N)$ denote the group of bijections $\mathbb N \to \mathbb N$ satisfying $\exists d \in \mathbb N^* : \forall i \in \mathbb N, \left\lvert f(i) - i \right\rvert \leq d$ , every $f \in W(\mathbb N)$ strongly preserves thickness, but there are other examples. For instance, if $(a_n)$ is a rapidly growing sequence, I think that the bijection $f$ swapping each $a_{2n}$ with $a_{2n+1}$ strongly preserves thickness, even if $f \not\in W(\mathbb N)$ . Edit. I now believe that if $f : \mathbb N \to \mathbb N$ is a bijection, and there exists $d \in \mathbb N^*$ such that the ""d-approximate support"" $S_d(f) = \left\{ i \in \mathbb N \, \big| \, \left\lvert f(i) - i \right\rvert > d \right\}$ isn't piecewise syndetic, $f$ strongly preserves thickness. Could it be a necessary and sufficient condition? A set is piecewise syndetic iff it can be written as $S \cap T$ , where $S$ is syndetic and $T$ thick. It means that, for some $\ell$ , it contains arbitrarily long sequences $a_1 < \ldots < a_p$ s.t. $a_{i+1} - a_i \leq \ell$ .","['additive-combinatorics', 'semigroups', 'combinatorics', 'ramsey-theory']"
4256139,nth time differentiability at a point if limit of nth derivative exists at that point,"Exercise: Let the function $f$ be defined and continuous in an open interval $A$ . Suppose that $c$ is a point in $A$ and that $f$ has derivatives up to order $m$ on the set $A \backslash\{c\}$ . Suppose further that $\lim\limits _{x \rightarrow c} f^{(k)}(x)$ exists for $k=1, \ldots, m$ and the limits are finite numbers. Show that $f$ has derivatives up to order $m$ in all of $A$ . Moreover $f^{(k)}(c)=\lim\limits _{x \rightarrow c} f^{(k)}(x)$ , for $k=1, \ldots, m$ I know proof of the case when $k=1$ . It has a lot of answers in this site, for example here for complete induction step I was suggested the following expression: $$ f^{(k)}(c)=\lim _{x \rightarrow c} \frac{f^{(k-1)}(x)-f^{(k-1)}(c)}{x-c}=\lim _{x \rightarrow c} \frac{\int_{c}^{x} f^{(k)}(t) d t}{x-c}=\lim _{x \rightarrow c} f^{(k)}(x)$$ but we haven't studied integral yet. Is there any technique to replace integral with that one?? Thank you in advance.","['real-analysis', 'calculus', 'functions', 'limits', 'derivatives']"
4256269,Why $|P(\mathbb N)|>|\mathbb N|$,"Why $|\mathbb N|<|P(\mathbb N)|$ ? ( $P(\mathbb N)$ is the power set of \mathbb N). First of all i know that $|P(\mathbb N)|=|\mathbb R|.$ By using binary decimals injective function: $P(\mathbb N) \to (0,1) \in \mathbb R \implies  |P(\mathbb N)|\leq|\mathbb R|.$ But why i cant defined $f : P(\mathbb N) \to \mathbb N $ by mapping each number subset of $\mathbb N$ ? An example : define g: $P(\mathbb N) \to \mathbb N$ with mapping each number in a subset of $\mathbb N$ . $g({1,2,6}) = 110001.$ $g({12,15}) = 000000000001001.$ (g looks injective function to me). What i'm missing ?",['elementary-set-theory']
4256284,Does there exist an example of such a pathological continuous function?,"Suppose $\ f:[0,1]\to\mathbb{R}\ $ is continuous and let $\ \varepsilon>0.$ For each $\ x\in[0,1],\ $ find the supremum $\ \delta>0\ $ such that $\ f(\ B_{\delta}(x)\ \cap [0,1]\  )\ \subseteq B_{\varepsilon}(\ f(x)\ )\ \subset \mathbb{R}.\quad $ [The reason I say supremum $\ \delta\ $ rather than maximum $\ \delta\ $ for each $\ x\ $ is because I'm not sure a maximum $\ \delta\ $ is attained for each $\ x.$ ] Note that in finding $\ \delta\ $ for each $\ x,\ $ we can think of $\ \delta\ $ as a function of $\ x,\ $ $ \delta = \delta(x).$ Now my question is, can we have $(1)\quad \inf\{\ \delta(x): x\in [0,1]\ \} = 0,\ $ or is it always the case that $\ \inf\{\ \delta(x): x\in [0,1]\ \} > 0$ ? At first I thought that the following would be an example satisfying $\ (1)\ $ : $
f(x)=
\begin{cases}
 x\sin\left(\frac{1}{x}\right)&\text{if}\,\ 0<x\leq 1\\
 0&\text{if}\,\ x=0\\
\end{cases}
$ with $\ \varepsilon = 0.01,\ $ but now I realise this doesn't satisfy $\ (1).$ In trying to come up with a example satisfying $\ (1).\ $ Something like the Weierstrass function comes to mind, but I'm not sure the Weierstrass function is pathological enough, but maybe it is? If it is, how would we prove it is? Also, this may have something to do with uniform continuity because a standard example of a non-uniformly continuous function is $\ y = x^2,\ $ which would satisfy $\ (1)\ $ (even for any $\ \varepsilon>0\ )\ $ if our function's domain was $\ \mathbb{R}\ $ rather than $\ [0,1].$ The semi-circle $\ f(x) = \sqrt{\frac{1}{4} - \left(x-\frac12\right)^2}\ $ or other similar tries don't satisfy $\ (1)\ $ either for any value of $\ \varepsilon>0.$","['continuity', 'functions', 'uniform-continuity', 'real-analysis']"
4256325,Combinatorial Invariant Problem Solving Question,"Consider the following problem. Take an $nxn$ table $A$ with entries $\pm 1$ . A permitted move is multiplying any row or column by -1. How many $nxn$ tables exist that can be transformed to a table containing only $1$ s? I've done questions like this where I'm given an initial table and prove that the operation can't be done. Those proofs often rely on invariants. For instance, the product of any row or column is invariant after applying one of the permitted moves. Also, the product of any 2x2 squares within the table remains invariant. Using those two facts I've been able to prove some tables can never be transformed to only contain $1$ s. But not sure I can use invariants for this more general question. Intuition tells me that the only permitted $nxn$ tables of this form are the initial table containing all 1s or permutations of tables containing an entire row or column of $-1$ s which can be later transformed into a table of only $1$ s. I'm not sure how to prove this, I'm not sure if I can use invariants since this is for a general $n$ . Would anyone have any suggestions as to how to move forward with this question and how can I count the number of $nxn$ matrices in question?","['invariance', 'combinatorics', 'problem-solving', 'discrete-mathematics']"
4256337,Proving an identity relating to binomial coefficients,"This question is from the book Discrete mathematics and its applications, by K. Rosen, 6th chapter and 27th question. Show that if n is a positive
integers $2C(2n, n+1) + 2C(2n, n) = 
  C(2n+2,n+1)$ I know how to prove this algebraically, applying the formula and this is how it is also given in hints. Since I want to understand counting arguments I am thinking to give a proof of this using combinatorial arguments (double counting). The right side is the number of ways to select n+1 elements from 2n+2 elements. But I am not able to get an argument for the left side. I'm not getting how can I argue that I need to choose n or n+1 elements from 2n elements twice. Any other (counting) approaches are also fine. Thank you.","['combinatorial-proofs', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics', 'algebra-precalculus']"
4256356,How can we show $\sum_{n\in\mathbb N}\frac{1-\cos\frac xn}{2^{n+1}}=0$ iff $x=0$?,"Let $$g(x):=\sum_{n\in\mathbb N}\frac{1-\cos\frac xn}{2^{n+1}}\;\;\;\text{for }x\in\mathbb R.$$ How do we see that $g(x)=0$ if and only if $x=0$ ? Clearly, $g(x)\in[0,1]$ for all $x\in\mathbb R$ and $g$ is continuous. Now, if we want to find $x\in\mathbb R$ with $g(x)=0$ , we should want the cosine terms to be equal to $1$ ; but this should mean that for all $n\in\mathbb N$ there is a $k_n\in\mathbb Z$ with $\frac xn=2k_n\pi$ ... How do we see that this is impossible, unless $x=0$ (if this is the right approach at all)? And how do we see that there are no other zeros?","['trigonometry', 'analysis', 'real-analysis']"
4256429,Is it allowed to use the modulo operation in math?,"In computer programming, I use the mod operation to get the remainder from division, which can be used for many things, such as to check whether a number is even or odd. Is it allowed to use the mod operation in mathematics, or is it only in programming? If so, what is the proper way to write it (do I write something like 3 mod 2 or 3 % 2 )? If not, is there a mathematical formula that will get the remainder from division?","['notation', 'algebra-precalculus', 'computer-science']"
4256440,How do I understand $dz=dx+idy$?,"I am reading some lecture notes where it applies green's theorem on the holomorphic function $f(z)=u+iv$ .
The conclusion is that $\oint_{dD}f(z)dz=2i\iint_D \frac{df}{d\overline{z}}dxdy$ . The main step is to treat $dz=dx+idy$ and do the algebra as if $dx$ and $dy$ are variables, then separate real part and imaginary part, then apply the green's theorem.
For me at least in calculus class, $dx$ and $dy$ are just a ""code"" that we integrate with respect to that variable. How do I understand this case where I treat this as a variable? I learned somewhere about how to calculate wedge products, but I didn't really understand the underlying connection with calculus. What specific concepts do I need to learn in order to understand this one? My guess is the later chapter in baby Rudin's analysis book on the differential form. Could someone give me some insight?","['complex-analysis', 'differential-forms', 'complex-numbers', 'differential-geometry']"
4256446,Common subdivision of two simplicial subcomplexes (on the way to topological invariance of simplicial homology),"In Munkres' Elements of Algebraic Topology Chapter 18, he aims to show that given a continuous map $h:|K|\to |L|$ , there is a well-defined map $h_*:H_p(K)\to H_p(L)$ , given by $f_*\circ(g_*)^{-1}$ , where $f:K'\to L$ is a simplicial approximation of $h$ , and $g:K'\to K$ is a simplicial approximation to the identity. But to show this is independent of the subdivision $K'$ , he claims So I think he's saying that given two subdivisions $K'$ and $K''$ of a simpicial complex $K$ , there's a common subdivision $K'''$ . I see how it is enough to show for $K$ an n-simplex. But I haven't been able to show this fact. Would someone know a proof?","['general-topology', 'simplicial-complex', 'algebraic-topology', 'simplicial-stuff']"
4256486,Using connectedness to prove surjectivity...,"$\textbf{My problem:}$ Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a contraction and $\phi :\mathbb{R^2} \rightarrow \mathbb{R^2}$ defined by $\phi (x,y)=(x+f(y),y+f(x))$ . Prove that $\phi (\mathbb{R^2} )=\mathbb{R^2}.$ $\textbf{My attempt:}$ I though to prove that $\phi (\mathbb{R^2} )$ is an open and closed subset of $\mathbb{R^2} $ . Then, because $\mathbb{R^2} $ is connected, we can conclude the proof. However,
I don't achieved it... Could anyone help me please?...","['connectedness', 'lipschitz-functions', 'analysis', 'contraction-operator', 'general-topology']"
4256502,Neighbor of non measurable function still non measurable,"Does there exists a non-measurable function $f : \mathbb{R} \rightarrow \mathbb{R}$ such that for every function $g : \mathbb{R} \rightarrow \mathbb{R}$ with $$ |g(x)-f(x)|<1 $$ for all $x \in \mathbb{R}$ , then $g$ is also non-measurable? I am thinking about function $f$ such that $f(x)=|x|+100$ for $x$ in any non-measurable subset of $\mathbb{R}$ and $f(x)=|x|-100$ for $x$ in any measurable set of $\mathbb{R}$ . But I don't know whether this works or not since measurable set and non-measurable can intersect. Thanks. Note : the measure here is Lebesgue measure","['measure-theory', 'measurable-functions', 'real-analysis']"
4256538,Inverse functions and $f(x)=x$,"Is every solution of $f(x)=x$ a solution of $f^{-1}(x) = f(x)$ ? If not, why not? Can we not do the following ? \begin{eqnarray}
 f(x)&=&x\\
f(f(x))&=&f(x)=x\\
 f^{-1}(x)&=&f(x)\\
\end{eqnarray} Also, what about the converse of this statement? What if a function is invertible (bijective) only in a certain domain?","['functions', 'inverse-function']"
4256559,Is a random subset of $\mathbb{R}^2$ connected?,Create a set $S$ by adding each point of $\mathbb{R}^2$ with 50% probability (independently). What is the probability that $S$ is connected? (and is this even a valid thing to ask?),"['measure-theory', 'connectedness', 'independence', 'general-topology', 'probability']"
4256561,Proving the existence of a condition for reciprocal of derivatives of a given function,"Let f be any continuously differentiable function on [a,b] and twice differentiable on (a,b) such that f(a)=a and f(b)=b. Then prove that there exists some distinct $c,d$ such that $$1/f'(c)+1/f'(d)=2$$ I tried solving it using Rolle's theorem, Lagrange mean value theorem but got no way to reach any closer to the solution. It is the introduction of reciprocals of derivatives in the condition to be proved that stumps me. Any help would be greatly appreciated!","['proof-writing', 'functions', 'derivatives']"
4256562,Find the general expression for the n-th derivative,"I want to find the $n$ -th derivatives of the function $$f(x)=\frac{1}{(1-x^2)^b}$$ with respect to x. Here $b$ is a positive constant. By using the chain rule, I can get
the first derivative is $$f'(x)=(-b)(1-x^2)^{-b-1}(-2x).$$ By using the chain rule and product rule, I can get
the second derivative which is $$f''(x)=(-b)(-b-1)(1-x^2)^{-b-2}(-2x)^2+(-b)(1-x^2)^{-b-1}(-2).$$ Again, the third derivative is $$f'''(x)=(-b)(-b-1)(-b-2)(1-x^2)^{-b-3}(-2x)^3+(-b)(-b-1)(1-x^2)^{-b-2}2(-2x)(-2)+(-b)(-b-1)(1-x^2)^{-b-2}(-2x)(-2).$$ The fouth derivative is $$f^{(4)}(x)=(-b)(-b-1)(-b-2)(-b-3)(1-x^2)^{-b-4}(-2x)^4+(-b)(-b-1)(-b-2)(1-x^2)^{-b-3}3(-2x)^2(-2)+(-b)(-b-1)(-b-2)(1-x^2)^{-b-3}2(-2x)^2(-2)+(-b)(-b-1)(1-x^2)^{-b-2}2(-2x)(-2)+(-b)(-b-1)(-b-2)(1-x^2)^{-b-3}(-2x)^2(-2)+(-b)(-b-1)(1-x^2)^{-b-2}(-2)(-2).$$ My question is : Is there a general formula or a pattern for the $n$ th derivative of $f(x)$ ? Any suggestions or comments would be very welcome. Thanks in advance.","['calculus', 'derivatives']"
4256611,Homomorphism between $ S_n $ and the group of Automorphisms of a group of direct product,"here I am referring to the Problem 8 of the Exercise for Section 5.1 from Dummit Foote. The problem refers to the previous problem which reads: Let $ G_{1},\dots,G_{n} $ be groups and let $ \sigma\in S_{n} $ be fixed. Prove that the map $$ \varphi_{\sigma}:G_{1}\times \dots\times G_{n}\to G_{\sigma^{-1}(1)}\times \dots\times G_{\sigma^{-1}(n)} $$ defined by $$ \varphi_{\sigma}(g_1,\dots,g_n)=\big(g_{\sigma^{-1}(1)},\dots,g_{\sigma^{-1}(n)}\big) $$ is an isomorphism. Now problem 8 reads as the following: In the above exercise, let $ G_1=\dots=G_{n} $ , and call $ G=G_1\times \dots\times G_{n} $ . Then show that for every permutation $ \sigma\in S_{n} $ , the map $ \varphi_{\sigma} $ is an automorphism on $ G $ . Also show that the map $ \sigma\mapsto\varphi_{\sigma} $ is an injective homomorphism of $ S_{n} $ into $ \mathscr{A}(G) $ , where $ \mathscr{A}(G) $ is the group of automorphisms of $ G $ . I am having trouble with the homomorphism part. I know that I am making a very silly mistake, but cannot find the same. My argument is the following: For any arbitrary element $ (g_1,\dots,g_n)\in G $ and for arbitrary permutations $ \sigma,\tau\in S_n $ , we have $$\begin{align}
		\varphi_{\sigma\circ\tau}(g_1,\dots,g_n)	&=	\big(g_{(\sigma\circ\tau)^{-1}(1)}, \dots,g_{(\sigma\circ\tau)^{-1}(n)}\big)\\
		&=	\big(g_{(\tau^{-1}\circ\sigma^{-1})(1)},\dots,g_{(\tau^{-1}\circ\sigma^{-1})(n)}\big)\\
		&=	\big(g_{(\tau^{-1}(\sigma^{-1})(1))},\dots,g_{(\tau^{-1}(\sigma^{-1})(n))}\big)\\
		&=	\varphi_{\tau}\big(g_{\sigma^{-1}(1)},\dots,g_{\sigma^{-1}(n)}\big)\\
		&=	\varphi_{\tau}\big(\varphi_{\sigma}(g_1,\dots,g_n)\big)\\
		&=	(\varphi_{\tau}\circ\varphi_{\sigma})(g_1,\dots,g_n).
	\end{align}$$ Therefore, $ \varphi_{\sigma\circ\tau}=\varphi_{\tau}\circ\varphi_{\sigma} $ . So, the order of the maps has reversed. I cannot seem to find a mistake. Please help.","['group-homomorphism', 'direct-product', 'automorphism-group', 'symmetric-groups', 'group-theory']"
4256637,Struggle on a lemma in Cartan's proof of existence of Haar measure,"I am reading Cartan's original paper Sur les mesures de Haar , comptes rendus de l'Académie des Sciences de Paris, 1940 on the existence of Haar measure on a locally compact Hausdorff topological group. There is a lemma I'm stuck on : Translation : Given finitely many $f_i$ continuous nonnegative with compact support, $\rho > 0$ and $\Lambda > 0$ , there is a neighborhood $U$ of the identity in $G$ such that $$ I_{\phi}\bigg(\sum_i \lambda_i f_i\bigg) \le 
 \sum_i \lambda_iI_{\phi}(f_i) \le I_{\phi}\bigg(\sum_i \lambda_i f_i\bigg) + \rho ​$$ whenever $\phi \neq 0$ is continuous, nonnegative with compact support in $U$ , and $0 \le \lambda_i \le \Lambda$ . The functional $I_\phi$ is defined by $$ I_{\phi}(f) = \frac{(f:\phi)}{(f_0 : \phi)} $$ with usual notation for Haar covering numbers and $f_0$ is a fixed nontrivial nonnegative continuous function with compact support in $G$ . This result is well-known in the particular case $\lambda_i=1$ for all $i$ . For example, we can find a proof in Folland's Real analysis , or in André Weil's book L'intégration sur les groupes topologiques et ses applications (page 36) as mentionned by Cartan in the footnote. Later on in the proof of the Théorème d'approximation , Cartan defines some $\lambda_i$ depending on $\phi$ , so the $U$ given by  the lemma must be the same for all possible choices of $\lambda_i \le \Lambda$ (I thought at first that it was a quantifier misordering, but it would be a surprising mistake, coming from Cartan). However, I don't know, after many many attempts,  how to prove this lemma in its « $\lambda_i-$ uniform formulation ». Is it even possible to deduce it from the $\lambda_i = 1$ case ? Any hint will be appreciated. :)","['proof-explanation', 'general-topology', 'haar-measure', 'measure-theory']"
