question_id,title,body,tags
1268410,"$f(x)=(x^2,x^3)$ not an immersion but $Df$ one-to-one?","Let $f:\mathbb R\to\mathbb R^2$ with $f(x)=(x^2,x^3)$. Then $f$ is not an immersion since $rank Df\neq1$ for $x=0$. Our lecturer told us that this is equivalent that $Df$ is one-to-one. What is meant by that? Clearly $Df(x)=Df(y)\iff x=y$ so what is wrong?","['differential-geometry', 'real-analysis']"
1268419,Sum of elements of a finite field,"Let $F$ be a finite field and $i$ an integer. Calculate the sum of all the elements of $F$, each raised to the $i$th power. My approach so far: Let $F=(0,1,\alpha,\alpha^2,...,\alpha^{p^n-1})$, where $p$ is a prime number and let $\sigma=1+\sum_{k=1}^{p^n-1}(α^k)^i$ be the desired sum. Since $F$ is a ring, each element has an additive inverse.
Thus, the trivial case of $i=1$ results in $\sigma=1+[\alpha+(-\alpha)+\alpha^2+(-\alpha^2)+\cdots+\alpha^{p^n-1}+(-\alpha^{p^n-1})]=1$. We can also calculate the trivial case of $i=0$, where $\sigma=1+p^n-1=p^n$ In the general case, let $i=t (\text{mod } p^n)$. Then: $i=t+mp^n$, where $t,m$ are integers. We take into account the fact that the order of the multiplicative group of the finite field is $p^n$, so each element raised to the $p^n$ equals $1$.
Thus $σ=1+α^t+α^{2t}+\cdots+α^{t(p^n-1)}$. This is the sum of a geometric progression, plus $1$. Thus, $σ=1+α(α^{p^n-1})/α-1$ = $ 1$+($α^{p^n}-α$)/${\alpha-1}$. But according to Lagrange's theorem, for every $\alpha\in F$, the polynomial $x^{p^n}-x$ is zero. It follows that $\sigma=1$. An important question is raised: Is it true that the characteristic of the finite field is $p$ if its order is $p^n$? If so, the case for $i=0$ leads to $σ=0≠1$ and all cases have been considered?","['abstract-algebra', 'abelian-groups', 'modular-arithmetic', 'finite-fields']"
1268420,Find the limit of a $f(x)=\frac{\lfloor x^2\rfloor}{x^2}$ at an arbitrary point,"The function f is defined $f(x)=\frac{\lfloor x^2\rfloor}{x^2}$
I need to find the limit of the function at an arbitrary point. For the continuous parts it was fine, and also for right sided limit at positive points of discontinuity (and left sided for negatives, for all of which the lim is 1), and now I'm left with left sided limit of the function at positive points of discontinuity (and vice versa for the negative part). I know the answer from intuition: $\frac{(x^2-1)}{x^2}$, but I can't find the key to the proof. My attempt is as follows (letting the point of discontinuity be $x_0>0$) First, I restrict delta such that $f(x)=\frac{(x_0^2-1)}{x^2}$ Then, if $x_0=1$ then $f(x)-L=0< \varepsilon$ (restricting $x>0$) Otherwise, I restrict my neighborhood again to $1< x< x_0$, such that $x<x_0 \rightarrow ... \rightarrow 1/x^2 - 1/x_0^2$ and therefore $f(x)-L=...=(x_0^2-1)(1/x^2 - 1/x_0^2)< \varepsilon$ And now I'm stuck... I can't seem to find the right combo to make the delta-epsilon magic to work. Thanks for any help!","['ceiling-and-floor-functions', 'limits']"
1268441,Show that the set of all finite subsets of $\mathbb{N}$ whose size is exactly $n$ where $0<n\in\mathbb{N}$ is countable,"I got this problem: Show that the set of all finite subsets of $\mathbb{N}$ whose size is exactly $n$ where $0<n\in\mathbb{N}$ is countable. I.e. Show that $|\{P\in\mathbb{P}(\mathbb{N})| |P|=n\}|=\aleph_0$ where $0<n\in\mathbb{N}$ . My solution: I've defined a one to one map from $\{P\in\mathbb{P}(\mathbb{N})| |P|=n\}$ to the set $\mathbb{N}$ that is based on prime numbers in a similar manner to the first answer in Show that the set of all finite subsets of $\mathbb{N}$ is countable. but when I tried to define a one to one map from $\mathbb{N}$ to the set $\{P\in\mathbb{P}(\mathbb{N})| |P|=n\}$ , my map wasn't very elegant and very hard to understand. I am sure there is some elegant solution. Thanks for any solution.",['elementary-set-theory']
1268459,Let $\text{Rank}{(A - \lambda I)^k} = \text{Rank}{(B - \lambda I)^k}$. Why are $A$ and $B$ similar?,"Let $A$ and $B \in M_n$ be two matrices such that $$\forall k=1,2,\dots,n,\ \forall \lambda\  \text{eigenvalue of $A$},\ \text{Rank}{(A - \lambda I)^k} = \text{Rank}{(B - \lambda I)^k}.$$ Why are $A$ and $B$ similar?","['linear-algebra', 'matrices']"
1268510,"Variance $= 0$, show that $X=\mu$ with probability one","If the variance of $X$ is zero, show that $X=\mu$ with probability one. Using Chebychev's inequality that is, \begin{equation*}
P(|X-\mu|\geq k\sigma)\leq\frac{1}{k^2},
\end{equation*} I just let $\sigma=0$,thus, $P(|X-\mu|\geq 0)$, as our absolute value is always greater than or equal to one, this probability equals one.. Does this look correct?","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
1268588,"If $Ha\subseteq Kb$ for some $a,b\in G$, show that $H \subseteq K$.","Let $H$ and $K$ be subgroups of a group $G$ . If $Ha\subseteq Kb$ for some $a,b\in G$ , show that $H \subseteq K$ . I constructed a proof by contradiction and I am wondering whether or not it is free from flaws. I thank you in advance for taking your time to inspect my work! Let us assume to the contrary that $H \nsubseteq K$ . Then $\exists h \in H$ such that $h \notin K$ . As $Ha\subseteq Kb$ , then $H \subseteq Kba^{-1}$ . So for this $h \in H$ , it is of the form $h=kba^{-1}$ for some $k \in K$ . Hence, $h=kba^{-1} \notin K$ by hypothesis $\Rightarrow h=kba^{-1} \in Kc$ for some $c \in G$ , which then implies that $k \in Kcab^{-1}$ . This last implication only holds if $cab^{-1}=1$ $\Rightarrow c=ba^{-1}$ . As $h=kba^{-1} \in Kc$ , then $h=kc \in Kc \Rightarrow h \in K$ , which contradicts our assumption and thus concludes the proof.","['group-theory', 'proof-verification']"
1268598,"I thought the | symbol meant ""divides by"", but in set theory, does it mean something different?","I thought the | symbol meant ""divides by"", but in set theory it seems that it means ""such that.""  However, I thought we wrote ""such that"" as : . Can anybody elaborate?","['elementary-set-theory', 'notation', 'soft-question']"
1268599,"Find a non-trivial solution for the Diophantine Equation $17a^4 + 5b^4 = 35c^4$, or show that no non-trivial solutions exist","This is a problem on my practice exam for number theory, and we haven't had an example like this in class yet. The question is looking for a solution in $\mathbb{Z}$ for $a,b,c \in \mathbb{Z}$. I've tried reducing everything (mod 5), but I didn't really figure anything out from that, and I'm not seeing many options for quadratic reciprocity either...","['number-theory', 'diophantine-equations']"
1268625,Derivative of exponential maps in Lie group $G$ and the adjoint operator on its Lie algebra,"Let $G$ be a (not necessarily compact, probably even infinite dimensional) Lie group, and $g$  be its Lie algebra. Let $V,W\in g$. Consider $J(t):=(Dexp)_{tV}(tW)$ be the result of differential of the Lie group exponential map $exp:g\to G$ at $tV$ acting on $tW$. Can we express $J(t)$ in terms of the adjoint operator $ad$ on $g$, defined by $ad_X(Y)=[X,Y]$. I'd really appreciate a detailed answer if possible. In my case $G$ is a certain subgroup of diffeomorphism group of a manifold, and $g$ is a subspace of vector fields on that manifold. But I don't think this piece of information will be necessary. Also, how can we relate the derivative of the Lie group exponential map $exp:g\to G$ in terms of the above adjoint operator? Thank you!","['lie-groups', 'differential-geometry', 'lie-algebras', 'lie-derivative']"
1268631,Find the value of $x$ that satisfies the equation $\log_{10} \left(\frac{x^{\frac{1}{x}}}{x^{\frac{1}{x+1}}}\right) = 1/5050$ .,"I tried it many times and it went bit of lengthy , i reached until \begin{equation*}
\log_{10}(x^{1/(x^2+x)}) 
\end{equation*} then i multiplied $2$ both numerator and denominator and then it is consecutive terms in denominator I got my answer $100$. Just want to know if it is correct and a shorter way to solve it ?","['logarithms', 'functions']"
1268633,Tower Property for Expectations and Stopping Times,"Let $(\Omega,(\mathcal{F_t})_{t\geq0},P)$ be a filtered proability space with  $X\in L^1(P)$ and two stopping times $S$ and $T$. Show that \begin{equation*}
\mathbb{E}(\mathbb{E}(X|\mathcal{F}_T)|\mathcal{F}_S)=\mathbb{E}(X|\mathcal{F}_{S\wedge T}),~P-a.s.
\end{equation*} I am a bit stuck on this and tried spilting it into 2 cases, namely on $\{S\leq T\}$ and it's complement and usng the fact that $\mathcal{F}_s\cap\mathcal{F}_T=\mathcal{F}_{S\wedge T}$ but don't get far. So any help is most welcomed and needs.  Thanks in advance","['probability-theory', 'conditional-expectation', 'stochastic-analysis', 'stopping-times']"
1268652,"If $A = \{a,b,c,d\}$, what does $\{\{a\}\}$ mean?","I am trying to understand the significance of curly brackets in set theory. Let $A = \{a,b,c,d\}$. I understand $A$ is a set that includes the objects $a,b,c,d$.  However, what does $\{\{a\}\}$ mean?  Why use two curly brackets on either side instead of just $\{a\}$ ?",['elementary-set-theory']
1268678,"Laurent series , function representation","Write the Laurent series around zero for the entire function $f(z)=z^2e^{3z}$ I'm a little confused on how to represent the complex functions by series, as I did in the calculation of real functions, but do not know if it's right $$e^z=\sum_{n=0}^\infty \frac{z^n}{n!}\rightarrow e^{3z}=\sum_{n=0}^\infty \frac{3^nz^n}{n!}\rightarrow z^2e^{3z}=\sum_{n=0}^\infty \frac{3^nz^{n+2}}{n!}$$ ii) Find the Laurent series representation for $f(z)=z^2\sin(\frac{1}{z^2})$ where $0<|z|<\infty$","['power-series', 'complex-numbers', 'laurent-series', 'sequences-and-series', 'complex-analysis']"
1268682,What is a free group element that is not primitive?,"A primitive element of a free group is an element of some basis of the free group. I have seen some recent papers on algorithmic problems concerning primitive elements of free groups, for example, the papers on determining whether a subgroup of a free group contains a primitive element and determining whether a given element is primitive . However, I'm a little confused about the definition: it seems to me that every element of the free group on a finite set of generators is primitive. Suppose $\{x_1, \dotsc, x_n\}$ is the set of generators for a free group on $n$ generators. Let $u$ be a word of length $m$ in the free group, and suppose $u = u_1 \dotsb u_m$, where each $u_i$ is one of the generators. I claim that $u$ is primitive because $u (u_2 \dotsb u_m)^{-1} = u_1$, hence $\{(u_2 \dotsb u_m)^{-1}, x_2, \dotsc, x_n\}$ is a basis of the free group, assuming without loss of generality that $u_1 = x_1$. Where is the flaw in my argument?","['group-theory', 'free-groups']"
1268688,"If $B$ is a Brownian motion and $B'_t:=B_{T+t}-B_T$ for a fixed $T$, then $(B'_t,t\ge 0)$ and $(B_s,0\le s\le T)$ are independent","Let $B=(B_t,t\ge 0)$ be a Brownian motion and $$B'_t:=B_{T+t}-B_T\;\;\;\text{for }t\ge 0$$ for some $T\ge 0$. Especially, $B$ has independent increments , i.e. $$\left(B_{t_i}-B_{t_{i-1}}\right)_{i=1,\ldots,n}$$ is independent, for all $0\le t_0<\ldots<t_n$. I want to prove, that $B'$ and $(B_s)_{0\le s\le T}$ are independent, i.e. for all $0\le s_0<\ldots<s_m\le T$ and $0\le t_0<\ldots<t_n<\infty$ $$\left(B_{s_0},\ldots,B_{s_m}\right)\;\;\;\text{and}\;\;\;\left(B'_{t_0},\ldots,B'_{t_n}\right)\tag{1}$$ are independent. Since $$B'_{t_i}-B'_{t_{i-1}}=B_{T+t_i}-B_{T+t_{i-1}}$$ and $$0\le s_i<T+t_0<\ldots<T+t_n$$ it's easy to see (since $B$ has independent increments) that $$B_{T+t_n}-B_{T+t_{n-1}},\ldots,B_{T+t_1}-B_{T+t_0},B_{T+t_0}-B_{s_i},B_{s_i}-B_0=B_{s_i}$$ are independent. Thus, $$B_{s_i}\;\;\;\text{and}\;\;\;\left(B'_{t_j}-B'_{t_{j-1}}\right)_{j=1,\ldots,n}\tag{2}$$ are independent, for all $1\le i\le m$. Can we conclude $(1)$ from $(2)$?","['probability-theory', 'brownian-motion', 'stochastic-processes']"
1268729,What is $\lim_{n\to\infty}\sum_{r=1}^{n}\frac{1}{(r+2)r!}\:$?,"$$\lim_{n\to\infty}\displaystyle\sum_{r=1}^{n}\frac{1}{(r+2)r!}$$ if we can find sum of this series then we can evaluate limit \begin{equation*}
\frac{1}{(3)1!}+ \frac{1}{(4)2!}+\frac{1}{(5)3!}+ .... \frac{1}{(n+2)n!}
\end{equation*} How we can find sum of this series","['calculus', 'limits', 'definite-integrals', 'sequences-and-series', 'integration']"
1268736,Does $P(A) = 1$ imply that $P(A) = P(A \mid B) = P(A \mid \neg B) = 1$?,Suppose for proposition $A$ we have that $$P(A) = 1$$ Then does it follow that for all $B$ $$P(A) = P(A \mid B) = P(A \mid \neg B) = 1?$$,"['probability-theory', 'independence', 'probability']"
1268745,How exactly does $\frac{\partial f}{\partial \bar{z}}$ work?,"I'm currently learning about complex analysis, and I keep coming across expressions involving $\frac{\partial f}{\partial \bar{z}}$. But I don't understand what this means. For example people might write
$$\frac{\partial }{\partial \bar{z}}z\bar{z}=z$$
But how does that make any sense? Why can we regard $z$ and $\bar{z}$ as independent variable while they clearly aren't? In some material I've also read that  $\frac{\partial f}{\partial \bar{z}}=0$ can be interpreted as meaning that $f$ is 'independent' of $\bar{z}$. But $f$ depends on $z$, and $z$ can be thought of as 'depending' on $\bar{z}$, so clearly $f$ depends as much on $\bar{z}$ as it does on $z$. This  $\frac{\partial f}{\partial \bar{z}}=0$ condition, whatever it even means, seems to also be equivalent to $f$ being analytic, which then leads to people saying things like 'If $f$ can be expressed without involving $\bar{z}$ then it is analytic'. But this again seems very strange to me. For example
$$f(z)=\bar{z}=z-2\Im(z)$$
Can certainly 'be expressed' without explicitly involving $\bar{z}$, but is not analytic, so this also doesn't make any sense to me. Basically I'm asking for clarification on why in complex analysis people seem to be doing these dodgy things, and what they mean by them.",['complex-analysis']
1268765,Factor $z^4 +1$ into linear factors,"$z$ is a complex number, how do I factor $z^4 +1$ into linear factors?
Do I write z in terms of $x+yi$ so that $z^4+1=(x+yi)^4+1?$","['complex-analysis', 'complex-numbers']"
1268766,Proving $(A\times B) \cap (C\times D) = (A\cap C) \times (B\cap D)$,"So there is a similiar question in the archives which I looked at after I attempted my proof: Proving that for any sets $A,B,C$, and $D$, if $(A\times B)\cap (C\times D)=\emptyset $, then $A \cap C = \emptyset $ or $B \cap D = \emptyset $ But it is not exactly the same, so I wanted to write my proof out from start to finish to see if my thought process was correct. 1) First I just experimented with some sets to see if anything came about: let $A = \{1\}$, $B = \{2\}$, $C = \{3\}$, $D = \{4\}$: $(A\times B) \cap (C\times D)$ side: $$(1,2)\cap (3,4) = (\emptyset,\emptyset)$$ [not sure if i could state this, but it is what I said in my solution] $(A\cap C)\ \times (B\cap D)$ side:
$$\emptyset\ \times \emptyset = (\emptyset, \emptyset)$$ Ok so I established what appears to be equality, so now I have to prove it. let $(x,y) \in (A\ X\ B) \cap (C\ X\ D)$
--> $(x\in A \cap y\in B) \cap (x\in C \cap y\in D)$
--> $(x\in A \cap x\in C) \cap (y\in B \cap y\in D)$
--> $x\in (A\cap C)\ X\ y\in (B\cap D)$
--> $ (x,y)\in (A\cap C)\ X\ (B\cap D)$
 Done. Then I would have to do the other way as well but it would amount to a similar argument. P.S: How to get lines of my proof to line up with arrows?",['elementary-set-theory']
1268787,Statistics - Book Recommendation [duplicate],"This question already has answers here : Recommend a statistics fundamentals book (6 answers) Closed 3 years ago . I am taking a course in statistics. It covers: Parameter estimations: point and interval estimations, etc. Hypothesis testing: comparison of means, comparison of probabilities, Chi square tests, etc. Analysis of variance.. And the like. What are some books that you would recommend for such a course? Thanks.","['book-recommendation', 'statistics']"
1268813,Estimate of an exponential sum involving the Von Mangoldt function,"Let $f(x)$ be a polynomial in $\mathbb{Z}[x]$.
Define
$$
S(\alpha) = \sum_{1 \leq n \leq N} \Lambda(n) e^{2 \pi i f(n) \alpha}.
$$
I was wondering how does one obtain that
$$
\left( \int_0^1 S(\alpha) \ d \alpha \right)^2 \leq (\log N)^2 \ T(N),
$$
where $T(N)$ is the number of $(n,n') \in [1,N]^2$ such that $f(n) = f(n')$? Thank you!","['number-theory', 'elementary-number-theory']"
1268858,Can a metric subspace be completely covered by balls after a finite number of steps?,"Let $X$ me a metric space with distance $d$ and $A$ be a subspace of $X$ . Let $B_\varepsilon(x)$ be the open ball centered in $x$ with radius $\varepsilon$ , i.e. $\{y\in X\mid d(x,y) < \varepsilon\}$ . Let $B_\varepsilon(S) = \displaystyle\bigcup_{x\in S} B_\varepsilon(x)$ Let $S_0:=\{x_i\}_{i\in I_0}$ be a set of points such that: $x_i\in A\quad \forall i\in I_0$ . $B_\varepsilon(x_i)\cap B_\varepsilon(x_j) = \emptyset\quad \forall i\neq j$ If $x\in A\setminus S_0$ then $\exists i\in I_0$ such that $B_\varepsilon(x)\cap B_\varepsilon(x_i) \neq \emptyset$ (In other words, I'm taking a maximal set of points of $A$ so that any two are separated by $2\varepsilon$ or more) At this point if $A\setminus B_\varepsilon(S_0) \neq \emptyset$ then we create: $S_1:=\{x_i\}_{i\in I_1}$ such that: $x_i\in A\quad \forall i\in I_1$ . $B_\varepsilon(x_i)\cap B_\varepsilon(x_j) = \emptyset\quad \forall i\neq j$ If $x\in A\setminus(S_0\cup S_1)$ then $\exists i\in I_1$ such that $B_\varepsilon(x)\cap B_\varepsilon(x_i) \neq \emptyset$ (In other words, I'm taking a maximal set of points of $A\setminus B_\varepsilon(S_0)$ so that any two are separated by $2\varepsilon$ or more) At this point, if $A\setminus B_\varepsilon(S_0\cup S_1)\neq \emptyset$ then we create $S_2$ in a similar way. If $B_\varepsilon(S_0\cup S_1\cup S_2)$ does not cover $A$ we construct $S_3$ and so forth. The questions are: Given $\varepsilon > 0$ can we ensure that this process will finish after a finite amount of steps? If so, is there an upper bound of said ampunt of steps? A small example. Consider $X = A = \mathbb{R}$ with the euclidean distance. Consider any $\varepsilon > 0$ . Then let $k$ be the smallest integer such that $k\varepsilon \geq 1$ . This means that $S_0$ has a countable amount of points. We can order the points of $S_0$ acording to the usual total order $\leq$ of $\mathbb{R}$ . In this case, $2\varepsilon < d(x_n,x_{n+1}) < 4\varepsilon$ . In other words, the diameter of any conex subset of $\mathbb{R}\setminus B_\varepsilon (S_0)$ is less than $2\varepsilon$ (otherwise we could fit another ball in there) In the next iteration we create $S_1 = \{y_i\}$ where $x_n < y_n < x_{n+1}$ and $\varepsilon < d(x_n,y_n) < 3\varepsilon$ and $\varepsilon < d(y_n,x_{n+1}) < 3\varepsilon$ . In other words,  the diameter of any conex subset of $\mathbb{R}\setminus B_\varepsilon (S_0\cup S_1)$ is less than $\varepsilon$ . This means that when we put the points of $S_2$ in said connex subsets (one in each) then $\mathbb{R}\setminus B(S_0\cup S_1\cup S_2) = \emptyset$ . Thus three steps are sufficient to cover $\mathbb{R}$ with balls of any radius $\varepsilon$ .","['metric-spaces', 'general-topology']"
1268870,Brownian motion proof of Dirichlet problem,"I am reading the proof of the Dirichlet theorem stated in the following form: Theorem:
  Let $D$ be a bounded domain in $\mathbb{R}^d$ such that every boundary point satisfies the Poincare cone condition. Suppose that $\varphi$ is a continuous function on $\partial D$ . We let $\tau ( \partial D) = \inf \{ t \geq 0 : B_t \in \partial D \}$, which is an almost surely finite stopping time when starting in $D$. Then the function $u: \overline{D} \rightarrow \mathbb{R}$ given by $u(x) = \mathbb{E}_x [ \varphi( B_{\tau(\partial D)}) ]$, for $x \in \overline{D}$, is the unique continuous function satisfying 
  $$
\Delta  u =0 \, \, \text{ on } \, D, \quad u(x) = \varphi (x) \, \, \text{ for } x \in \partial D.
$$ The proof that $u$ is harmonic in $D$ goes as follows (using Markov property): Let $x \in D$ and $\delta >0$ be such that $\overline{B} (x, \delta) \subseteq D$. Also, let $\tau= \inf \{t > 0 : B_t \in \partial B (x, \delta) \}$. Then
  $$u(x) = \mathbb{E}_x [ \varphi(B_{\tau(\partial D)}) ]= \mathbb{E}_{x} [ \mathbb{E}_{B_{\tau}} [ \varphi(B_{\tau({\partial D})} ) ] \,] = \mathbb{E}_x [ u(B_{\tau}) ].$$
  Hence, $u$ satisfies the mean value property and is hence harmonic. However, I don't get the same expression in the second equality in the proof:
Let $\tilde{B}$ be a standard Brownian motion. Then, noting that $\tilde{B}_{\tau(\partial D)} - \tilde{B}_{\tau}$ is independent of $\mathcal{F}_{\tau}$, and $\tilde{B}_\tau$ is $\mathcal{F}_{\tau}$-measurable, \begin{eqnarray}
u(x) & = & \mathbb{E} \,[ \,\mathbb{E} [ \varphi(\tilde{B}_{\tau(\partial D)} +x)  \,| \,\mathcal{F}_\tau ] \,]\\
& = & \mathbb{E} \,[ \,\mathbb{E} [  \varphi(\tilde{B}_{\tau(\partial D)} - \tilde{B}_{\tau} +  \tilde{B}_{\tau} +x)  \,| \,\mathcal{F}_\tau ]\, ]\\
& = & \mathbb{E} \, [ \, \mathbb{E} [  \varphi(\tilde{B}_{\tau(\partial D)} - \tilde{B}_{\tau} + v) |_{v = \tilde{B}_{\tau} +x} \, ] \, ]\\
& = & \mathbb{E}_{x} [ \mathbb{E}_{B_{\tau}} [ \varphi(B_{\tau({\partial D})} - B_{\tau} ) ]].
\end{eqnarray} Why is there an extra term involving $B_{\tau}$ in my calculations? What have I done wrong?","['probability-theory', 'brownian-motion', 'stopping-times', 'stochastic-processes']"
1268881,Limit distribution of infinite sum of Bernoulli random variables,"I know that the finite sum of Bernoulli i.i.d. random variables is a binomial distribution, but what is the distribution of $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac{x_k}{2^k}$$ where $x_k$ is a Bernoulli random variable with parameter $\frac12$?","['probability-theory', 'probability', 'probability-distributions']"
1268887,What are the primary disadvantages of Dummit and Foote's abstract algebra text (3rd ed.)?,"I have done a fair amount of research concerning which abstract algebra book to ""settle down into""; that is, I wanted to pick an algebra text and really commit to it as my ""primary text,"" more or less, and I have chosen Dummit and Foote's 3rd edition of Abstract Algebra . My goal is to obtain a solid foundation in algebra at the beginning graduate level (I am self-learning). I have gone through a fair amount of John Durbin's Modern Algebra (6th ed.), but I know this is more of a ""warm-up text."" I have heard of algebra books by Herstein, Artin, etc., but I am no longer interested in a comparative analysis. What are the chief drawbacks of using Dummit and Foote's text as my primary algebra text? I know it has been criticized for being somewhat bland, but that it has a ton of excellent problems and examples and is fairly encyclopedic. I am more interested in mathematical drawbacks. Do they leave out any important topics in modern algebra? Does the book have extensive errata? Basically, what are the downsides of using this text? Preferably, I'd like to hear from people who have used this text before and have some background in abstract algebra who can look at my question from a more retrospective outlook.","['abstract-algebra', 'self-learning', 'education', 'soft-question']"
1268911,are connnected components of this scheme irreducible?,"So I have a normal surface (ie, all components are dimension 2) $X$ which is smooth and affine over a Dedekind domain $R$ (so $X$ is an affine scheme). Suppose $R'$ is integral (possibly not dedekind) and $Spec(R')\rightarrow Spec(R)$ is finite flat (but possibly ramified). Does $X_{R'}$ (the base change of $X$ to $Spec(R')$) have the property that connected components are irreducible? Note that $X$ has this property since it's normal. If $K,K'$ are the fraction fields of $R,R'$ respectively, then $X_K$ also has this property since it's also normal, and since $X_{K'}$ is smooth over $X_K$ and normality is smooth-local, $X_{K'}$ is also normal and has this property. The intuition is this: By There is a bijection between irreducible components of the generic fiber and irreducible components passing through it. together with the fact that $X_{R'}\rightarrow Spec(R')$ is smooth (hence open), we know that the irreducible components of $X_{R'}$ are in bijection with the irreducible components of $X_{K'}$, which are its connected components. Suppose two irreducible components $C_1,C_2\subset X_{R'}$ intersect. If they intersect in a curve, then there are two possibilities: The intersection is fibral (ie, lies in a fiber of the map $X_{R'}\rightarrow Spec(R')$). In this case, that fiber should be either singular (nonreduced?), probably(?) contradicting the smoothness assumption of $X\rightarrow Spec(R)$ (and hence $X_{R'}\rightarrow Spec(R')$), or higher dimension than the other fibers, contradicting flatness. If the intersection is not fibral, then the generic point of the intersection should map to the generic point of $Spec(R')$, and hence this should correspond to two irreducible components of $X_{K'}$ intersecting, which is impossible by normality. If $C_1,C_2$ intersect at a point, then that point should be a singular point in its fiber, which again probably(?) contradicts smoothness. Does this make sense? If it doesn't, does anyone have a counterexample? EDIT: Here are some really simple examples: $X = Spec k[x,y,z]/(xy)$, so $X$ is the union of two planes intersecting in the $z$-axis. Then over $R = Spec k[x]$, we see that the fiber above $x = 0$ is 2-dimensional, whereas the fiber above $x = a$ $(a\ne 0)$ is only 1-dimensional. This contradicts flatness. If $R = Spec k[x-y]$, then the fiber at $x-y = 0$ is Spec $k[x,z]/(x^2)$, which is nonreduced, contradicting smoothness.",['algebraic-geometry']
1268922,Find the maximum of a |cos(z)|,"How do you find the maximum of the complex function $|\cos{z}|$ on $[0,2\pi]\times[0,2\pi]$. I believe I'm to use the maximum modulus principle, since the function is entire. I'm just having problems starting. Any suggestions?",['complex-analysis']
1268957,Lens Conformal Map,"Please help me find a conformal map of the set $ A = \left \{\; z: \; |z-1| < \sqrt{2} \; and \;  |z+1| < \sqrt{2} \;  \right \}$ one-to-one onto the open first quadrant. First, I noticed that the circles meet at a right angle at $i$ and $-i$. So I know one of these need to be mapped to the origin. But I had know idea what to do next, so I tried shifting each circle so that they would be centered at the origin, then mapped one circle to the upper half plane and the other to the right half plane, each with an inverse Cayley Transform. For the left circle I got: $$-i\frac{z+2}{z},$$ and for the right circle I got: $$-\frac{z}{z-2}$$ Then I thought to myself, ""Great. Now I have two functions...how am I going to combine them?"" I peaked at the back of the book and they have: $$f(z)=e^{-\frac{3xi}{4}}\left ( \frac{z-i}{z+i} \right )$$ I'm pretty sure the ""x"" is a typo. I think they meant  ""$\pi$"" instead. After seeing the answer, I lost hope in my strategy. There is a good chance there is something very important that I don't understand. Please, enlighten me. :(","['complex-analysis', 'transformation']"
1268973,What does $d\log\left(\frac{y}{x}\right)$ mean mathematically?,"I am used to seeing derivatives written as $$\frac{df}{dx}.$$ But my economics professor keeps using notation like $$ d\log\left(\frac{y}{x}\right)$$ and I have no idea what this means. What does this notation signify? If it's a derivative, with respect to what? There is no denominator term. And I thought modern calculus used standard analysis with limits and not infinitesimals. my question: What does  $d\log\left(\frac{y}{x}\right)$ signify? How do I take this derivative and with respect to what?","['notation', 'calculus', 'logarithms', 'derivatives', 'differential']"
1268982,Does $\chi(g^{-1})=\overline{\chi (g)}$ hold for infinite groups,"Let $\chi$ be the character of some representation $\rho:G \to GL(M)$ over $\mathbb C$. Suppose $G$ is a group, then $\forall g \in G$ of finite order $n$, $ \chi(g^{-1})=\overline{\chi (g)}$ Proof: $\rho(g)^n=\rho(g^n)=\rho(e)=\textrm{id}$. Hence the characteristic polynomial of $\rho(g)$ divides $x^n-1$ and so the characteristic polynomial of $\rho(g)$ has distinct roots. Thus there is a basis $\mathcal B$ of $M$ composed of eigenvectors of $\rho(g)$ and so  $[\rho(g)]_\mathcal B$  is diagonal. Then $\chi(g)=\sum_i \lambda_i$ where the $\lambda_i$ are the eigenvalues of  $\rho(g)$. Now  $[\rho(g^{-1})]_\mathcal B=[\rho(g)]_\mathcal B ^{-1}$ which has the $\lambda_i  ^{-1}$ on the diagonal. So $\chi(g^{-1})=\sum_i \lambda_i^{-1}.$ But since $\rho(g)^n=\textrm{id}, \, [\rho(g)]_\mathcal B^n=I $ so for any eigenvector $v_i$ with eigenvalue $\lambda_i$, $\rho(g)^n(v_i)=\lambda_i^n v=v_i$. Hence $\lambda_i$ is an $n$-th root of unity and has $\lambda_i^{-1}=\overline{\lambda_i}$. Therefore $\chi(g^{-1})=\sum_i \lambda_i^{-1}=\sum_i \overline{ \lambda_i}=\overline{\sum_i \lambda _i}=\overline{\chi(g)}.$ You can see that my proof of this relies heavily on the existence of this finite $n$. I am therefore wondering: For an element $g\in G$ of infinite order, is it still true that $ \chi(g^{-1})=\overline{\chi (g)}$?","['group-theory', 'linear-algebra', 'representation-theory']"
1269008,Formula for $r+2r^2+3r^3+...+nr^n$ [duplicate],"This question already has answers here : How can I evaluate $\sum_{n=0}^\infty(n+1)x^n$? (24 answers) Closed 9 years ago . Is there a formula to get $r+2r^2+3r^3+\dots+nr^n$ provided that $|r|<1$?  This seems like the geometric ""sum"" $r+r^2+\dots+r^n$ so I guess that we have to use some kind of trick to get it, but I cannot think of a single one.  Can you please help me with this problem?","['power-series', 'summation', 'sequences-and-series', 'calculus']"
1269019,Roll one ellipse on another: Locus of center ever a circle?,"Let $E_1$ be an ellipse fixed in the plane.
Let $E_2$ be a second, possibly different ellipse, which rolls around
without slippage
outside $E_1$, touching perimeter-to-perimeter. Let $c_2(t)$ be the center of $E_2$
as a function of time $t$, where $t$ measures the progress of the rolling. Q . Is the locus $c_2(t)$ ever an exact circle when
  it is not the case that both $E_1$ and $E_2$ are circles? Image: Erik Mahieu Mathematica Demo . It seems likely the answer is No , but perhaps one can cleverly ""cancel out"" two
eccentricities...","['plane-curves', 'geometry', 'conic-sections']"
1269032,Wouldn't each addition take time $O(n)$?,"I am going over the asymptotic runtime of regular matrix multiplication. Here  is a lecture slide I am referencing(too much to type out, shown below), from Algorithms Everything makes sense up until the point that the author states that ""each addition takes $O(n^2)$ time"". Can anyone explain that? I have a counter example here. Say I have a 4 by 4 matrix. The product of $A$ and $E$ would result in something like (2 by 2 matrix) $$
        \begin{bmatrix}
        1 & 2 \\
        3 & 4  \\
        \end{bmatrix}
$$ and the product of $B$ and $G$ would result in something like $$
        \begin{bmatrix}
        5 & 6 \\
        7 & 8  \\
        \end{bmatrix}
$$
The author argues that one addition runs in $O(n^2)$ but I argue that one addition runs in $O(n)$. Here to add $AE$ and $BG$, you perform additions 1 + 5, 2 + 6, 3 + 7, and 4 + 8, or 4 additions. 4 was the original n, so the runtime of one addition would be $O(n)$ Do you guys agree with my counterexample/argument or did I miss something and runtime of one addition would be $O(n^2)$?","['computer-science', 'discrete-mathematics', 'matrices', 'computational-complexity', 'asymptotics']"
1269040,"Find the ""surface vertices"" of a collection of points.","I am currently doing some experiments in order to simulate liquids. I have a collection of 3D points that interact with each other to form a body of water. I would like to form a mesh from these points by adding faces between the points that represent the surface of the body of water, in order to make it look more like actual water. To do this, I need to figure out which points in this collection represent the surface of my body of water. The points that are inside this surface will be hidden by the mesh. The points move in real-time, so a fast technique would be preferable. (source: ayarger.com ) My initial idea was to calculate the mean of all the points and use it to discover which points are farthest away. I ran into a problem when I asked myself which points I would take...the top 10 farthest points? The top 20? What if the body of water is irregular and not spherical? Any help would be appreciated. Thank you!","['geometry', 'surfaces', 'algorithms']"
1269050,Finding the angle between two line equations,"I need to find the angle between two lines in $y = mx + b$ form and they are: \begin{equation*}
y = 4x + 2~\text{and}~y = -x + 3
\end{equation*} I have no idea how to solve this and if you could please consider that I'm in Grade 12 Calculus and Vectors. So my knowledge consist of adding vectors, derivatives, etc. Somehow the answer is suppose to be 59 degrees but I don't know how to get that",['calculus']
1269082,How to prove a Fibonacci inequality using Strong Induction?,"Using strong induction I am trying to prove that
$$F_n \geq \left(\frac{1+\sqrt{5}}{2}\right)^{n-2} \text{ for all } n \geq 2$$ for the Fibonacci Sequence defined by: $F_0 = 0$, $F_1 = 1$,  and $F_n = F_{n-1} + F_{n-2}$ for $n \geq 2$. I know how to do strong induction for normal sequences, but not for inequalities (I have never liked inequalities). If someone wouldn't mind pointing me in the right direction regarding what to do, I would be very grateful.","['number-theory', 'induction', 'discrete-mathematics']"
1269098,${a_n}$ for a sequence containing no zeroes,"Take the sequence of Natural numbers which do not contain the digit zero. So your sequence becomes: 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12 ... Can we find an expression for ${a_n}$ ?",['sequences-and-series']
1269115,Probability of particular subset of balls occurring in a larger set chosen from a total?,"If I have 3 balls chosen out of 6 (2 blue, 2 red, and 2 green) with replacement, what is the chance a chosen ball will be blue? How about two blue balls? I think I can reason this out, but I'm curious about the approach using permutations and combinations. So far, I'm thinking I have 6 balls in total, so all possible permutations would be 6! = 720, and then all permutations of 3 would be 6!/3! = 120, but this is where I'm stuck (and end up thinking in circles too hard, likely making an easy problem into something way more difficult). I'm thinking for one blue ball, we have a probability of 1/3 of choosing one each time, so for three choices this is still just 1/3...but it doesn't feel right. Any suggestions on how to tackle this?","['probability-theory', 'probability', 'statistics']"
1269135,Set of positive integers with unique sums,"What I'm looking for is the name of a type of number set. Given a number T (for total) and a set of positive integers S , I want to uniquely identify the subset of S that sums to T . All sets containing 1 or 2 positive integers will pass the test, since there is a unique combination of those numbers and the sum will therefore be the same. For example: {1, 7, 89} passes the test. Any combination of those numbers, when summed, will generate a unique T , and vice versa, any T that is a sum of a combination of those numbers will generate a unique subset of S . So, the set of all T s for the above set is {0, 1, 7, 8, 89, 90, 96, 97}. {2, 3, 7, 8} does not pass the test. There are multiple combinations that yield a total of 10 ({2, 8}, and {3, 7}). So if I specified a T of 10, you could not tell me with confidence the combination that produced that sum. With that out of the way. My question is this... Is there name for a set of positive integers like this? I'd like to learn more about them more a personal project of mine.","['elementary-number-theory', 'combinatorics']"
1269138,"What is the relationship between a complex manifold being Kähler, projective, nonprojective, and nonKähler?","I was wondering if this implication is true. I read a few places that
$$\text{nonprojective} \Longrightarrow \text{nonKähler}$$
but I think I maybe have misunderstood. Equivalently, this is of course asking if $$\text{Kähler} \Longrightarrow \text{projective ?}$$","['projective-geometry', 'complex-geometry', 'algebraic-geometry', 'differential-geometry', 'kahler-manifolds']"
1269141,What does a 3D periodic solution of a differential equation look like?,"The Pointcare-Bendixson Theorem implies that if a solution stays in a bounded region with no equilibrium points then it is either a periodic solution or it approaches a periodic orbit as t goes to infinity. But this is only in 2D. In higher order dimensions, are we able to find that solutions are periodic solution or approaching a periodic solution in that higher dimension space?","['stability-in-odes', 'dynamical-systems', 'ordinary-differential-equations']"
1269150,Initial Value problem and showing that $ x(t_n) - x_n = 1/2ht_ne^{tn} + O(h^2)$,"I have a question which I can't for the life of me figure out.  The questions starts by giving $$x'(t) = x(t), x(0) = 1, x(t) = e^t$$ So they give you the solution and basically ask you to apply the Euler method with step size $h$ to show $$x_n = (1+h)^{t_n/h} , t_n = nh , ~~ n = 0,1....$$ Now I have gotten this out quite simply however, the next part asks use the formula $$log(1+h) = h - 1/2h^2 + O(h^3)$$ to show that $$ x(t_n) - x_n = 1/2ht_ne^{tn} + O(h^2)$$ Now I have tried a couple of different options and i feel it should be easier than it is. The furthest I can sort of get is $$x_n =e^{t_n(1 - 1/2h+O(h^2))}$$ (but I have so many different types of solutions and maybe working with Taylor series) any help would be greatly appreciated",['ordinary-differential-equations']
1269174,Martingale converges to the boundary,"I asked an almost same question before and it is solved by considering adjacent $Z_n$ can not be far away and obtain a contradiction. However, if the setting is altered a bit, I wonder whether it is still true. Suppose $D$ is a bounded, connected, open subset of $\mathbb{R}^2$ with boundary $\partial D$. Consider a Markov chain $\{Z_n\}_{n\geq 0}$ on $D$ which evolves as follows: for each $n\geq 0$, conditional on $\sigma(Z_k)_{k\leq n}$, the random variable $Z_{n+1}$ is uniformly distributed on the disk of radius $R_n$ centered at $Z_n$, where $2R_n$ is the distance from $Z_n$ to $\partial D$. Prove that $$Z_n  \rightarrow  Z_{\infty} \;a.s., Z_{\infty}\in \partial D. $$ It is not too hard to see that coordinates of $Z_n$ are bounded (as $D$ is). It is also easy to see that the coordinates of $Z_n$ are martingale. Then by the boundedness of the coordinates and the martingale convergence theorem, we know that $Z_n$ indeed converges to some $Z_{\infty}$. But how to show $Z_\infty\in \partial D$? I am not able to produce a contradiction to $Z_\infty \in D$ with positive probability. I did some simulation on $\mathbb{R}^2$ with $D$ being a disk and it seems true that $Z_n$ will hit the boundary finally.","['probability-theory', 'martingales', 'markov-chains', 'markov-process']"
1269186,Two cards are drawn from a deck of 52. Let event A be that two cards have the same value and event B be the same suit. Are these independent?,"I'm not sure that I totally understand independent events. If the cards are the same suit or rank, then they have a 13/52 and 4/52 probability, respectively. However, I'm not totally sure how these two events relate to one another. I believe that they are independent.",['probability']
1269194,"Find solutions to $\cot(x)+\csc(x)=\sqrt3$ in range $[0,2\pi]$","What is the best way to do the above? Are there any tricks I should be aware of. I know how to simplify it to $\dfrac{\cos(x)}{\sin(x)} + \dfrac{1}{\sin(x)} = \sqrt{3}$ so multiplying both sides by $\sin(x)$, we get $\cos(x)+1=\sqrt{3}\sin(x)$. But I'm stuck from there.",['trigonometry']
1269201,Product of characters in representation theory,"Is it true that if $\phi_1$ and $\phi_2$ are characters then $\phi_1\phi_2$ is a character of a representation? I think this is true, say for instance if $R_1$ is a matrix representation with character $\phi_1$ of $G$ and $R_2$ is a matrix representation of $H$ with character $\phi_2$, then we can say $\phi_1\phi_2$ as the character of the matrix representation of $G\times H$ if we define $\phi_1\phi_2(g, h)=\phi_1(g)\phi_2(h)$. Will this suffice to prove our claim?","['representation-theory', 'characters', 'abstract-algebra', 'tensor-products', 'modules']"
1269221,Carmichael numbers of form $m^3+1$ and Ramanujan's $1729$,"While researching for a post on tetranacci pseudoprimes I came across a list of Carmichael numbers , $$C_n = 561,\, 1105,\, 1729,\, 2465,\, 2821,\dots$$ Of course, Ramanujan's taxicab number $1729 = 12^3+1$ stood out. So I looked at other near-cubes $C(m) = m^3+1$ and found that for $n<10000$, there were six, namely, $$m = 12,\, 36,\, 138,\, 270,\, 4800,\, 7560,\dots?$$ $C(m) = m^3+1 = (m+1)(m^2-m+1)$ have the factorizations, $$C(12) = 7 \cdot \color{brown}{13} \cdot 19$$ $$C(36) = 13 \cdot \color{brown}{37} \cdot 97$$ $$C(138) = 7 \cdot 37 \cdot 73 \cdot \color{brown}{139}$$ $$C(270) = 13 \cdot 37 \cdot 151 \cdot \color{brown}{271}$$ $$C(4800) = 7 \cdot 19 \cdot 31 \cdot 37 \cdot 151 \cdot \color{brown}{4801}$$ $$C(7560) = 271 \cdot 433 \cdot 487 \cdot \color{brown}{7561}$$ Note that $m+1$ is prime. Questions: Since there are an infinite number of Carmichael numbers, what others are of form $m^3+1$? Is it true that if it is of form $m^3+1$, then $m+1$ is prime? P.S. Richard Pinch's database with $C_n<10^{21}$ seem to have broken links. $\color{brown}{Update}$: Courtesy of R. Pinch's answer, the complete list with $C_n<10^{21}$ include three more, $$C(12840)$$ $$C(14700)$$ $$C(678480)$$ and only $14700+1$ is composite.","['prime-numbers', 'number-theory', 'computational-mathematics', 'modular-arithmetic', 'pseudoprimes']"
1269222,Is $\int_1^{\infty}\frac{x \cos(x)^2}{1+x^3}$ convergent or divergent?,"For the integral $$I= \int_1^{\infty}\frac{x \cos^2(x)}{1+x^3},$$ how do I test this for convergence or divergence? I know that this an improper integral- however it cannot be solved so would need to use a comparison test for this. Would the comparison test consist of: 
If $\cos(x)<1$ then we can use $1/(1+x^3)$ to show that it converges? However... How can i compare the equation where there is an $x$ on the numerator of the original equation? Would I need to use something else to compare it with instead? Thanks.","['improper-integrals', 'integration']"
1269224,Integral over a sequence of sets whose measures $\to 0.$,"If $ f \in L_p$ with $1 \leq p \leq \infty $ and ${A_n}$ is a sequence of measurable sets such that $ \mu (An) \rightarrow 0,$ then $ \int_{A_n} f \rightarrow 0$. Can someone give me a hint?","['analysis', 'real-analysis']"
1269285,Are symmetric matrices necessarily positive-definite / positive semi-definite?,"I am trying to prove this just to be clear about this but I don't have enough conditions to force this idea to be true, so I doubt it is. Are symmetric matrices always at least positive semi-definite? I know the other way around, by convention, positive-definite / positive semi-definite matrices are always symmetric. I currently have on my piece of paper a 1x1 block, after using the definition of positive-definiteness, that consists of a polynomial that is quadratic in the variables x, y, z, which are the components of my chosen vector.  But the coefficients attached are coming from the symmetric matrix, and there's no reason why a symmetric matrix needs to have all positive entries. Thanks,","['operator-theory', 'linear-algebra', 'symmetry']"
1269294,"Give an example of a singular matrix in $M_{3×3}(Q)$ the entries of which are distinct prime positive integers, or show that no such matrix can exist.","I know that the matrix exist because the entries are primes but I don´t know how to explain, i need some help.
Give an example of a singular matrix in $M_{3×3}(Q)$ the entries of which are distinct prime positive integers, or show that no such matrix can exist.","['linear-algebra', 'matrices']"
1269320,Central extension of the Discrete Heisenberg group $H_3(\Bbb Z)$,"I want to use the  Discrete Heisenberg group $(H_3(\Bbb Z),\times)$ as an example for a presentation on central extensions. $H_3(\Bbb Z) = \begin{bmatrix}1&x&z\\0&1&y\\0&0&1 \end{bmatrix}x,y,z\in \Bbb Z$ Now I have shown that the center of $H_3(\Bbb Z)$ is $Z = \begin{bmatrix}1&0&z\\0&1&0\\0&0&1 \end{bmatrix}$ I want a short exact sequence: $$I\hookrightarrow Z \hookrightarrow H_3(\Bbb Z) \twoheadrightarrow X\twoheadrightarrow I$$ Now for this to work, I need $X\cong H_3(\Bbb Z) / Z$ I believe, but I don't fully understand quotient groups apparently. Now I know that I can take this quotient group, since $Z$ is normal of course and I believe that we will get $$X= \begin{bmatrix}1&x&0\\0&1&y\\0&0&1 \end{bmatrix}$$ I can also see that $$Z^{-1}\begin{bmatrix}1&x&z\\0&1&y\\0&0&1 \end{bmatrix}=\begin{bmatrix}1&x&z\\0&1&y\\0&0&1 \end{bmatrix}Z^{-1}=X$$ Where $Z^{-1} = \begin{bmatrix}1&0&-z\\0&1&0\\0&0&1 \end{bmatrix}$ Does my guessed $X$ have $X\cong  H_3(\Bbb Z) / Z$ Can I let my maps be explicitly: $$I\overset{\phi_1}{\hookrightarrow} Z \overset{\phi_2}{\hookrightarrow} H_3(\Bbb Z) \overset{\phi_3}{\twoheadrightarrow} X\overset{\phi_4}{\twoheadrightarrow} I$$ $$\phi_1:A\mapsto A$$$$\phi_2:A\mapsto A$$$$\phi_3:A\mapsto Z^{-1}A$$$$\phi_4:A\mapsto I$$","['abstract-algebra', 'group-theory', 'matrices']"
1269324,Proving the uniqueness of the weak limit,"In ""A First Look at Rigorous Probability Theory"" by J. S. Rosenthal there is the following exercise: Prove that weak limits, if they exist are unique . That is, if $\mu, \nu, \mu_1, \mu_2, \ldots$ are probability measures [on $(\Bbb{R},\mathcal{B}(\Bbb{R})$] and $\mu_n \Rightarrow \mu$, and also $\mu_n \Rightarrow \nu$, then $\mu = \nu$ Now the official solution: Ok, I had instead the following idea: If $\int f \, d\mu_n \overset{n\rightarrow\infty}{\longrightarrow} \int f \, d\mu$ and $\int f \, d\mu_n \overset{n\rightarrow\infty}{\longrightarrow} \int f \, d\nu$ for any real continuous bounded function $f$, for any such function it must also hold (the limits are just limits of real numbers!) that
$$\int f \, d\mu = \int f \, d\nu\, .$$ Now using those ""trapezoid-like functions"" $f_n$ we have for an half-open interval $(a, b] \subset \Bbb{R}$ pointwise limit
$$\lim_{n\rightarrow \infty} f_n = \mathbf{1}_{(a, b]} \, . $$
Now using dominated convergence
$$
\mu((a, b]) = \int \mathbf{1}_{(a, b]} \, d\mu = \int \lim_{n\rightarrow \infty} f_n \, d\mu = \lim_{n\rightarrow \infty} \int f_n \, d\mu = \lim_{n\rightarrow \infty} \int f_n \, d\nu = \int \lim_{n\rightarrow \infty} f_n \, d\nu = \int \mathbf{1}_{(a, b]} \, d\nu = \nu((a, b])\,.
$$ The crucial step here was $\lim_{n\rightarrow \infty} \int f_n \, d\mu = \lim_{n\rightarrow \infty} \int f_n \, d\nu$. Contrary to the indicator function, the $f_n$ are continuous , so this follows, as we have seen, from $\mu$ and $\nu$ being weak limits of the same sequence of measures. Since the measures $\mu, \nu$ are probability measures and so $\sigma$-finite and have the same value on the semi-ring of half-open intervals, by Carathéodory's extension theorem we conclude that $\mu =\nu$. Would that solution be right, too?","['probability-theory', 'solution-verification', 'alternative-proof', 'weak-convergence']"
1269342,To Find Eigenvalues,"Find the eigenvalues of the $6\times 6$ matrix $$\left[\begin{matrix} 
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 \\
\end{matrix}\right]$$ The options  are $1, -1, i, -i$ It is a real symmetric matrix and the eigenvalues of a real symmetric matrix are real. Hence $i$ and $-i$ can't be its  eigenvalues. Then what else we can say? Is there any easy way to find it?","['eigenvalues-eigenvectors', 'linear-algebra']"
1269354,Elementary divisors theorem for Dedekind domains (Exercise in Lang's Algebra),"Exercise 13 (b) of Chapter III in Lang's Algebra is as follows. Let $M$ be a finitely generated projective module over the Dedekind ring $\mathfrak{o}$. Then there exists free modules $F$ and $F^\prime$ such that $F \supset M \supset F^\prime$ were $F$ and $F^\prime$ have the same rank $n$. Prove that there exists a basis $\{e_1, \cdots, e_n \}$ of $F$ and ideals $\mathfrak{a}_1, \cdots, \mathfrak{a}_n$ such that $M = \mathfrak{a_1} e_1 + \cdots + \mathfrak{a_n} e_n$, or in other words, $M \approx \oplus \; \mathfrak{a}_i$. I understand the proof of the structure theorem for finitely generated modules over Dedekind domains, but I do not see how to prove the existence of a basis of $F$ if we follow the same kind of arguments.","['abstract-algebra', 'modules', 'dedekind-domain']"
1269359,Prerequisite of Algebraic Geometry,"Algebraic geometry, as far as I know, is a very important branch of mathematics, which is also very difficult. I am going to take a try to taste that. Before really going into the field, I have two questions that could be a guide for me. Is it really necessary to know about algebraic geometry, even for a professional mathematician focus on other fields? I've learned from Wikipedia that commutative algebra is subsumed into algebraic geometry. So do I need to study commutative algebra or projective geometry before starting learning algebraic geometry?","['advice', 'algebraic-geometry', 'commutative-algebra']"
1269405,Prove that A(AB-BA) = (AB-BA)A implies AB-BA is nilpotent.,"Let A and B be $n \times n$ complex matrices such that 
$A(AB-BA) = (AB-BA)A$ a) Show that for every positive integer $k$, the matrix $(AB-BA)^k$ is of the form $AC-CA$, where $C$ is an $n \times n$ complex matrix. b) Prove that $AB-BA$ is nilpotent. I have tried the following.
$A^{-1}A(AB-BA) = A^{-1}(AB-BA)A \implies AB-BA = A^{-1}(AB-BA)A$ $A(AB-BA)A^{-1} = (AB-BA)AA^{-1} \implies AB-BA = A(AB-BA)A^{-1}$ Then $(AB-BA)^{k} = (A^{-1}(AB-BA)A)^k = A^{-1}(AB-BA)^kA$ and $(AB-BA)^{k} = A(AB-BA)^{k}A^{-1}$. I don't know where do I go from here, thanks for your help.",['linear-algebra']
1269425,The cantor set is uncountable,"I am reading a proof that the cantor set is uncountable and I don't understand it. Hopefully someone can help me. Let $C$ be the Cantor set and $x\in C$. Then there exists unique $x_k\in \{0,2\}$ such that $x=\sum_{k\in \mathbb N}\frac{x_k}{3^k}$. Conversely every $x$ with this representation lies in C. If $C$ would be countable then there would exists a injective map $f:C\rightarrow \mathbb N$. Let $f^{-1}(i)=\sum_{k\in \mathbb N}\frac{x_{ik}}{3^k}$ or $f^{-1}(i)=\emptyset$. Set $z_k=2-x_{i_k}$, then z=$\sum_{k\in \mathbb N}\frac{z_k}{3^k}$ Then $z$ is in the cantor set but z isn't in the pre-image of $f$. Questions: Shouldn't it be $z_k=2-x_k$? I understand that z lies in C but why it is not in the pre image of f? Thanks in advance","['elementary-set-theory', 'cantor-set']"
1269482,Confusion over common criterion for a line bundle on a scheme to be trivial?,Suppose you have a line bundle $L\to X$ on a scheme $X$. I'll denote by $\sigma\colon X\to L$ to be the zero section. Why is it that this bundle is trivial iff there is another section $s\colon X\to L$ such that $s(X)$ and $\sigma(X)$ are disjoint?,"['algebraic-geometry', 'schemes', 'vector-bundles']"
1269492,Compare determinants of matrices with different dimensions,"Reading about matrices and determinants I am wondering about the following concept: How valid is to compare the determinants of matrices with different dimensions?
e.g. compare a determinant $D1$ derived from a $N\times N$ matrix with the determinant $D2$ derived from a $M\times M$ matrix. I've read that the determinant represents the volume of the $N-$dimensional object that is defined by the elements of the matrix. If this is correct then comparing volumes of different ""objects"" doesn't sound as incorrect. But having in mind that these ""objects"" came from two different spaces (a $N-$dimensional and a $M-$dimensional) how valid is that?","['volume', 'determinant', 'matrices']"
1269497,"Conditional probability, Baye's rule, prisoner Ural / Siberia + coat exercise","I am currently statistics and probability course. One of the questions in the textbook is following: A prisoner will be sent to either Urals or Siberia , but he does not
  know where. He knows, that the probability is 0.8 that he will be sent
  to Siberia . He also knows the probabilities of prisoners wearing a coat - 0.5 in Siberia and 0.7 in Urals . When he arrives to the exile, the first person he sees is not wearing
  a coat. What is the probability he is in Siberia ? Given previous information, he sees another one, not wearing a coat . What is probability now, that he is in Siberia ? Would it change the probability if he saw both previous people at once? I believe the answer for the 1. is following: $$\mathcal P(S|\bar C)={\mathcal P(S)\times\mathcal P(\bar C|S) \over \mathcal P(\bar C)}={0.8\times0.5\over 1-(0.8\times0.5+0.2\times0.7)}=\frac{20}{23}\dot=\,0.8696$$ However, I have no idea how to move further on 2. or 3. Could you please help me? Thank You! EDIT The professor quickly responded with the solution for 2. : $$\frac{0.8696\times0.5}{0.8596\times0.5+0.1304\times0.3}=0.9174$$
From this, I've found out that the probabilities can be ""chained"", and decoded the underlining formula as: $$\mathcal P(S|\bar{C_2})=\frac{\mathcal P(S|\bar C)\times\mathcal P(\bar C|S)}{\mathcal P(S|\bar C)\times\mathcal P(\bar C|S)+\mathcal P(\bar S|\bar C)\times\mathcal P(\bar C|\bar S)}$$ However, since 0.5 is the probability for $\mathcal P(\bar C|S)$ and also for $\mathcal P(C|S)$, I need a clarification, if my decoded formula is right. Thank You.","['probability', 'bayes-theorem']"
1269512,subset of a compact set in $\mathbb{R}$ with nonempty interior has positive outer measure,"Let $A\subset I=[a,b] \subset \mathbb{R}$, $a < b$ such that Int$(A) \neq \emptyset$. Show that $A$ has positive outer measure. What I have so far: Since Int$(A) \subseteq A$, by the monotonicity property of the outer measure we have $m^*(\text{Int}(A)) \leq m^*(A)$. Since Int$(A)$ is a nonempty open set in $\mathbb{R}$, Int$(A)$ is uncountable, thus $m^*(\text{Int}(A)) > 0$.","['proof-verification', 'measure-theory']"
1269615,How many ways can $133$ be written as sum of only $1s$ and $2s$,"Since last week I have been working on a way, how to sum $1$ and $2$ to have $133$. So for instance we can have $133$ $1s$ or $61$ $s$2 and one and so on. Looking back to the example: if we sum: $1 + 1... + 1 = 133$ there is only one way. But for the second one there will be $131$ possible ways. And I have to do this for every possible combination. I am stuck with it and I have no idea whatsoever on how to begin. Any ideas or methods I could use guys?","['integer-partitions', 'number-theory', 'combinatorics']"
1269662,Numbers having in decimal representation no common digits with all their proper divisors,"Let us call a positive integer having in decimal representation no common digits with all its proper divisors "" a good number "". $54$ is a good number : $1,2,3,6,9,18,27$ . $48$ is not a good number : $1,2,3,\color{red}{4},6,\color{blue}{8},12,16,2\color{red}{4}$ Good numbers : $2,3,4,5,6,7,8,9,23,27,29,34,37,38,43,46,47,49,53,54,\cdots$ I've been interested in these numbers, and I noticed that OEIS has this sequence. One can easily see the followings : $1$ is not included in the digits of good numbers. The right-most digit of a good number $n\ge 6$ is neither $0,1,2$ nor $5$ . Let $d(n)$ be the number of divisors of $n$ . I noticed that $d(n)$ is relatively small for (smaller) good numbers $n$ . The following shows $d(n)$ for good numbers $n$ except prime numbers . $$\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline
    n&4&6&8&9&27&34&38&46&49&54&56&57&58&68&69\\  \hline
d(n)&3&4&4&3&4&4&4&4&3&8&8&4&4&6&4 \\\hline
\end{array}$$ $$\begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \hline
    n&76&78&86&87&247&249&259&267&289&323&329&334\\  \hline
d(n)&6&8&4&4&4&4&4&4&3&4&4&4 \\\hline
\end{array}$$ It seems that there exists the maximum of $d(n)$ for good numbers $n$ . Also, it seems that the number of sets of four consecutive good numbers, such as $\{56,57,58,59\}$ , is finite. However, though I've been trying to prove/disprove the two conjectures, I can neither prove nor disprove them. So, here are my questions. Question 1 : Does there exist the maximum of $d(n)$ for good numbers $n$ ? If yes , what is it? If no , how can we show that? Question 2 : Is the number of sets of four consecutive good numbers finite? If yes , what is the biggest such set? If no , how can we show that? Added : For Question 1, a user san showed that the answer is yes and that an upper bound for $d(n)$ is 16. However, the maximum of $d(n)$ has not been obtained yet. For Question 2, san showed that the answer is yes, and that the biggest such set is $\{56,57,58,59\}$ .","['number-theory', 'decimal-expansion', 'recreational-mathematics', 'divisor-counting-function']"
1269670,Equivalence of $\|x\|_1\|x\|_{\infty}$ and $\|x\|_2^2$,"Let $x$ be any complex $n$-vector and let $\|\cdot\|_p$ denote the usual $p$-norm .
It is easy to show that $\|x\|_2^2\leq\|x\|_1\|x\|_{\infty}$ ( Hölder's inequality ). What I am rather interested in is the reversed inequality: finding a $c$ ($c>1$) such that
$$\tag{1}
\|x\|_1\|x\|_\infty\leq c\|x\|_2^2\quad\text{for all $x$.}
$$
Obviously, $\|x\|_1\leq\sqrt{n}\|x\|_2$ and $\|x\|_\infty\leq\|x\|_2$, so an easy candidate is $c_\mathrm{naive}:=\sqrt{n}$. However, it seems that a better constant is about a half of the naive one: $c_\mathrm{better}:=(1+\sqrt{n})/2$. I was wondering about a proof for this better $c$, that is, how to prove that $$\tag{2}\|x\|_1\|x\|_\infty\leq\frac{1+\sqrt{n}}{2}\|x\|_2^2\quad\text{for all $x\in\mathbb{C}^n$.}$$ WLOG we can assume that $x:=[1,y^T]^T$, where $\|y\|_\infty\leq 1$, so the quest for the optimal $c$ in (1) is equivalent to finding (or bounding from above)
$$\tag{3}
c_\mathrm{optimal}:=\max_{\|y\|_\infty\leq 1}\frac{1+\|y\|_1}{1+\|y\|_2^2}\;.
$$
By some experimentation, it seems that actually (2) is sharp, that is, $c_\mathrm{optimal}=c_\mathrm{better}$, and the bound in (2) is attained by $x=[1,\alpha,\ldots,\alpha]^T$, where $\alpha=1/(\sqrt{n}+1)$. Since this is a problem in an early chapter of Matrix Computations by Golub and Van Loan, I suppose its prove might be not overly complicated and, since a hint is missing, it should actually be quite easy. Any input will be highly appretiated; a hint if possible :-)","['linear-algebra', 'normed-spaces']"
1269729,Finding this weird limit involving periodic functions with periods 5 and 10.,"If $f(x)$ and $g(x)$ are two periodic functions with periods 5 and 10 respectively, such that:
$$\lim_{x\to0}\frac{f(x)}x=\lim_{x\to0}\frac{g(x)}x=k;\quad k>0$$
then for $n\in\mathbb N$, the value of :
$$\lim_{n\to\infty}\frac{f(5(4+\sqrt{15})^n)}{g(10(4+\sqrt{14})^n)}$$. Note: Everything should be done by hand, any claculating/plotting, etc. device/software is not allowed. What I've thought is make up such a function:
$$f(x)\propto\sin\frac{2\pi x}{5}\qquad g(x)\propto\sin\frac{2\pi x}{10}$$
But the condition for the limit at zero cna not be satisfied in anyways from here. Also:
$$5(4+\sqrt{15})^n=5\times4^n(1+\sqrt{15}/4)^n\sim 5\times4^n+5\times4^n\times n\sqrt{15}/4+...$$
wheer $5\times4^n\in\mathbb Z$
So, by periodicity:
$$f(5\alpha+\beta)=f(\beta)\qquad \alpha\in\mathbb Z,\beta\in\mathbb R_{|\beta|<5}$$
And then:
$$L=\lim_{n\to\infty}\frac{f(5\times4^nn\sqrt{15}/4+\cdots)}{g(10\times4^nn\sqrt{14}/4+\cdots)}$$
But this proceeds nowhere, as I was wshing to apply L'Hospital or retain only the $(\beta, |\beta|<5)$ part, but :D.","['periodic-functions', 'calculus', 'limits', 'functions']"
1269747,Counterexamples to the Matrix norm AM-GM inequality?,"I am new here and this my first question, I hope I am being as clear as possible and apologize in advance for any misunderstandings. I am researching the Arithmetic-Geometric Mean (AM-GM) inequality for matrices. Which can be seen as an ""extension"" of the obvious AM-GM inequality for positive numbers $a,b$ : $ \sqrt{ab} \leq \frac{1}{2}(a+b) $. One of such possible extensions is the following: $|||A^{1/2}B^{1/2}|||\leq \frac{1}{2}|||A+B|||$   As shown in ""Positive Definite Matrices"" by R.Bhatia. Where A, B are positive, hermitian matrices, and $||| \cdot |||$ is a unitarily invariant norm. This is precisely my problem/question: all proofs and attempts to investigate the AM-GM matrix-norm-inequality use unitarily invariant norms. Does this mean that for non-unitarily invariant norms this inequality does not hold? Is there a counterexample for this? perhaps for p-norms such as 
$\|\cdot\|_\infty$ , $\|\cdot\|_1$? Or an explanation why a proof for non-unitarily invariant norms could not work? I am just lost since all the texts I read regarding the AM-GM inequality, immediately jump to using unitarily invariant norms. Thank you!!","['means', 'matrices', 'normed-spaces', 'examples-counterexamples', 'inequality']"
1269753,Proof on Riemann's Theorem that any conditionally convergent series can be rearranged to yield a series which converges to any given sum.,"I am looking at the proof of the following theorem from Apostol's Mathematical Analysis. I am having trouble showing the last part that the author left to the reader. I'm trying to show that $y$ is the limit superior of this rearrangement. To do so, I need to show two things based on the definition of limit superior from the text. First, for every $\epsilon \gt 0$ there is an integer $N$ such that $n \gt N$ implies $h_n \lt y + \epsilon$. Second, given $\epsilon \gt 0$ and $m \gt 0$, there is an integer $n \gt m$ such that $h_n \gt y-\epsilon$. Where I put $h_n$ as the rearrangement of the original series. The second condition is immediately satisfied since for every $y_n$ there is a rearrangement greater than it by construction. However, I'm having trouble showing the first part. How can I guarantee that for any $\epsilon$, all but finitely many $h_n$ is less than $y+ \epsilon$. I don't know how to show this part since our construction only guarantees that we have some rearrangement greater than every $y_n$. Finally, how does this theorem lead to the conclusion that any conditionally convergent series of real terms can be rearranged to yield a series which converges to any prescribed sum? I'd greatly appreciate it if anyone could rigorously establish the above facts for me.","['analysis', 'sequences-and-series', 'real-analysis']"
1269763,Let $A$ is nonsingular and each eigenvalue of $A$ is either $+1$ or $-1$.Why $A$ is similar to ${A^{ - 1}}$?,Let $A \in {M_n}$ is nonsingular and each eigenvalue of $A$ is either $+1$ or $-1$.Why $A$ is similar to ${A^{ - 1}}$?,"['linear-algebra', 'matrices']"
1269766,Evalutating $\lim_{x\to +\infty} \sqrt{x^2+4x+1} -x$ [duplicate],"This question already has answers here : Limits: How to evaluate $\lim\limits_{x\rightarrow \infty}\sqrt[n]{x^{n}+a_{n-1}x^{n-1}+\cdots+a_{0}}-x$ (6 answers) Closed 9 years ago . I'm looking to evaluate $$\lim_{x\to +\infty} \sqrt{x^2+4x+1} -x$$ The answer in the book is $2$. How do I simply evaluate this problem? I usually solve limits such as this with the short cut method, i.e (Numerator degree < Denominator degree) = 0 ; (Numerator degree = Denominator degree )= take ratio of leading coefficients; (Degree numerator > degree denominator )= take leading terms and use algebra to simplify and then plug in $-\infty$ or $+\infty$
Please keep in mind that I do not know L'Hopital's rule.","['radicals', 'calculus', 'limits', 'indeterminate-forms']"
1269782,Solving polynomial equations using more than radicals,"It is well known that one cannot solve every polynomial equation over $\Bbb Q$ using just radicals. In other words, let $A_n = \{x^n - a\mid a \in \Bbb Q\}$, $A = \cup_n A_n$ and $\bar{\Bbb Q}$ the algebraic closure of $\Bbb Q$. Then we know that the splitting field of $A$ over $\Bbb Q$ is not all of $\bar{\Bbb Q}$. Given this, is there a proper subset $S$ of all irreducible polynomials over $\Bbb Q$ whose splitting field is indeed all of $\bar{\Bbb Q}$? Can we say anything non trivial about such sets(like finding a minimum such one if it exists)? Can we define this set by induction on the degree of the polynomial? For instance, square roots are enough to solve quadratic equations and so on till fifth degree where radicals no longer suffice. There are a lot of questions here but I am only interested in understanding these sets in general and only suggest the questions as possibly interesting.","['number-theory', 'galois-theory', 'algebraic-number-theory']"
1269829,Inheritance of independence of random variables,"I want to show the following statement: let $(X_n)$ and $(Y_n)$ be sequences of random variables and $X_n\perp Y_n$ for each $n$. If $X_n\to X$ and $Y_n\to Y$ in probability respectively, then $X\perp Y$. How can I prove this without using characteristic function?","['probability-theory', 'random-variables']"
1269894,What is connection here between $x$ and interval: $\sin^{-1}(2x(\sqrt{1-x^2})=2\sin^{-1}x$ .,"For the expression \begin{equation*}
 \sin^{-1}(2x(\sqrt{1-x^2})=2 \sin^{-1}x,~x\in[\frac{-1}{\sqrt2}, \frac{1}{\sqrt2}],
\end{equation*} I know there is a connection between the interval and the value of $x$, what is that connection and why we are taking a specific value of $x$ in this interval, and why the value of $x$ is changed with interval.","['calculus', 'trigonometry']"
1269903,"Prob. 8, Sec. 3.5 in Erwin Kreyszig's Introductory Functoinal Anlaysis With Applications","Erwin Kreyszig's Introductory Functoinal Anlaysis With Applications Prob. 8, Sec. 3.5 $\DeclareMathOperator{\span}{span}$ Let $(e_k)$ be an orthonormal sequence in a Hilbert space $H$ , and let $M = \span (e_k)$ . Let $x \in H$ . If $$x = \sum_{k=1}^\infty \langle x, e_k \rangle e_k,$$ then $x \in \overline{\span(e_k)}$ because in this case the sequence $(s_n)$ in $\span(e_k)$ , where $s_n =  \sum_{k=1}^n \langle x, e_k \rangle e_k$ , converges to $x$ . How to show the converse? That is, how to show that if $x \in \overline{\span(e_k)}$ , then the series $\sum_{k=1}^\infty \langle x, e_k \rangle e_k$ converges (in the norm induced by the inner product on $H$ ) and has sum $x$ ? My effort: Suppose $x \in \overline{\span(e_k)}$ . Then there is a sequence $(x_n)$ in $\span(e_k)$ that converges to $x$ . Let $x_n = \sum_{k=1}^{m_n} \alpha_{nk} e_k$ for each $n= 1, 2, 3, \ldots$ , where $\alpha_{nk}$ are scalars and the $m_n$ are natural numbers. Then, using the orthonormality of the $e_k$ , we can conclude that $\alpha_{nk} = \langle x_n, e_k \rangle$ for each $n=1, 2, 3, \ldots$ and for each $k= 1, \ldots, m_n$ . So $$x_n = \sum_{k=1}^{m_n} \langle x_n, e_k \rangle e_k. $$ What next? Can we say the following? For each fixed $k$ , $$\langle x_n, e_k \rangle \to \langle x, e_k \rangle \  \mbox{ as } \ n \to \infty. $$ How to show that $$x = \sum_{k=1}^\infty \langle x, e_k \rangle e_k?$$ I also know that the series $\sum \langle x, e_k \rangle e_k$ does converge.","['inner-products', 'real-analysis', 'functional-analysis', 'hilbert-spaces', 'analysis']"
1269950,Solve differential equation $y' = |1.1 - y| + 1$,"How can the following differential equation be solved analytically? \begin{equation*}
y' = |1.1 - y| + 1, \\ 
y(0) = 1.
\end{equation*} I guess one must rewrite the differential equation piecewise and solve each piece independently. But how and how do I continue? Thanks in advance for your assistance.","['calculus', 'absolute-value', 'ordinary-differential-equations']"
1269970,Completely monotonic function intersect,"Is there any proof that two ""completely monotonic"" functions ($f,g: (0, \infty) \rightarrow \mathbb{R}$) would intersect at most at one point? Completely monotonic means: The $n$'th derivative of each function satisfies $(−1)^ n f^{(n)}(x) \geq 0$, $(−1)^ n g^{(n)}(x) \geq 0$, $x \in (0, \infty)$.",['functions']
1269990,is a number field by definition a subfield of $ \mathbb C $?,"I have seen that some authors are defining the number field as a subfield of $ \mathbb C$ which is a finite extension of the rational numbers $ \mathbb Q $ , while some others without referring to complex numbers $ \mathbb C$ .
I think we don't need $ K$ to be a subfield of $ \mathbb C$ in the definition.
So, my question is the follwing: Is it neceserily to define $K$ as a subfield of $ \mathbb C$ or not ?
And if no why ? Is it true that if we omit this in the definition, that then $K$ will turn out to be a subfield of $ \mathbb C$ ? I came up with this question, when I saw that in order to define infinite primes in a number field then these are determined by the embeddings $ K \to \mathbb C $ Any idea would be really appreciated. Thank you in advance.","['abstract-algebra', 'field-theory', 'algebraic-number-theory', 'commutative-algebra']"
1270003,Let $\mathfrak T_X = \{f^{-1} (U) : U \in \mathfrak T_Y\}$ then $\mathfrak T_X$ is a topology on X. False?,Let $f :X \rightarrow Y$ be a function and suppose that $\mathfrak T_Y$ is a topology on $Y$.  Let $\mathfrak T_X = \{f^{-1} (U) : U \in \mathfrak T_Y\}$ then $\mathfrak T_X$ is a topology on X. $f^{-1}(U)$ refers to the inverse image of a set I am supposed to determine if this is true or false and then prove or give a counterexample. I am leaning towards this being a false statement because this conjecture doesn't say anything about the function being continuous but I am not sure if this is necessary.  Can anyone help with where to go with my thinking?,"['elementary-set-theory', 'general-topology', 'proof-writing']"
1270022,"Extrema of quartic functions $f(x)=ax^4+bx^3+cx^2+dx$ with $a>0$, $c<0$","I am looking for some general statement how the extrema (or only the maximum) of a quartic function looks like. 
My quartic polynomial is bounded from below (fourth order coefficient is positive), the second order coefficient is negative (can look like a ""mexican hat"" potential), and $f(0)=0 $ (no constant term).
To summarize:
$f(x)=ax^4+bx^3+cx^2+dx$ with $a>0, c<0,(e=0)$
What I want to know: Is there any possibility that the function value at the local maximum is negative? If yes, can we say something about relations of the coefficients? What I have tried so far: If the maximum becomes negative, we are left with two real roots. There is a condition for this to happen, which I can use to derive some relations 
(see http://en.wikipedia.org/wiki/Quartic_function#Nature_of_the_roots , which becomes much simpler in my case since $e=0$). The problem is, that these conditions are necessary but not sufficient. It does not exclude the case where the function looks effectively quadratic or only has a saddle point. I still need the maximum. Unfortunately, I wasn't able to go on from here, since the equations become messy for me. Any hint on literature or general theorems are appreciated.","['maxima-minima', 'algebra-precalculus']"
1270072,Radius and interval of convergence of $\sum_{n=1}^{\infty}(-1)^n\frac{x^{2n}}{(2n)!}$ by root and ratio test are different?,$$\sum_{n=1}^{\infty}(-1)^n\frac{x^{2n}}{(2n)!}$$ By using ratio test $$\lim_{n\to\infty}\frac{x^{2(n+1)}}{(2(n+1))!}\frac{(2n)!}{x^{2n}}=\lim_{n\to\infty}\frac{x^2}{(2n+2)(2n+1)}=0$$ By using root test $$\lim_{n\to\infty}\sqrt[n]{\frac{x^{2n}}{(2n)!}}=\lim_{n\to\infty}\frac{x^2}{{(2n)!}^{\frac1n}} = x^2$$ By using root test then the series convergent only when $0<x<1$ while with ratio test x can be any real number. What is the mistake I made here. I assume that (I can't prove it's true) $\lim_{n\to\infty}{{(2n)!}^{\frac1n}}=1$. It is the part that I can't make sure as same as $\lim_{n\to\infty}\frac{n!}{n^n}=0$.,"['sequences-and-series', 'limits']"
1270082,To find jordan canonical form,"Which of the following matrices have Jordan canonical form of equal to the $3\times 3$ matrix $$
\begin{pmatrix}
0 & 1 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{pmatrix}$$ a)$
\begin{pmatrix}
0 & 0 & 1 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{pmatrix}$ b)$
\begin{pmatrix}
0 & 0 & 1 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{pmatrix}$ c)$
\begin{pmatrix}
0 & 1 & 1 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{pmatrix}$ d)$
\begin{pmatrix}
0 & 1 & 1 \\
0 & 0 & 1 \\
0 & 0 & 0
\end{pmatrix}$ Here characteristic equation of the matrix is $x^3$.Hence the 3 eigenvalues of the matrix are zero.
Do we want to find the eigenvalues of all the matrices in the options?Is there any other way?",['linear-algebra']
1270096,"Why is the ""wrong"" interpretation of confidence intervals still seemingly correct?","According to online sources, if you are operating at 95% confidence, it means if you repeated a sampling process many times and then looked at the 95% confidence intervals over all the results, 95% of the time the brackets would contain the true population mean. But then they say that it is NOT the same as saying ""you can be 95% confident that the intervals you computed contain the population mean."" Isn't it, though? For instance I do my first experiment and get a 95% confidence interval. Then a second. Third, fourth, ..., 100th. 95 of those intervals should contain the population mean. Is this correct so far? If so, then why isn't it the same as me saying, from the moment I did the very first test, ""this particular interval has a 95% chance at being one of the intervals that contain the true population mean""?",['statistics']
1270099,Proof of Reeb's theorem without using Morse Lemma,"I'm trying to prove Reeb's theorem as stated in Milnor's Morse Theory . That is, suppose we have an $n$-manifold $M$ together with a smooth function $f$ with exactly two critical points (both non-degenerate), then $M$ is homeomorphic to $S^n$. I understand the most crucial part. That is, let $f$ be normalized such that the critical points are mapped to $0$ and $1$ respectively. We can then prove that $f^{-1}[0,a]$ is diffeomorphic to $f^{-1}[0,b]$ for any $0<a,b<1$ by constructing a certain vector field out of the gradient of $f$ and then using the flow of this vector field as the required diffeomorphism. Then if $f^{-1}[0,\epsilon]$ and $f^{-1}[1-\epsilon,1]$ are homeomorphic to a disk, we have that $M$ must be the union of two disks glued along their boundary, making $M$ homeomorphic to $S^n$. Now my problem is the part where there is an $\epsilon>0$ such that $f^{-1}[0,\epsilon]$ is homeomorphic to an ($n$-dimensional) disk. Milnor uses a lemma (Morse Lemma) which constructs quadratic coordinates in some open neigborhood of $f^{-1}(0)$, but this seems to far too strong. So I was wondering if it's possible to prove this without resorting to that lemma. My idea is first of all to note that $f^{-1}[0,\epsilon]$ is contractible since we can simply consider the family $f^{-1}[0,t]$ for $t\in[0,\epsilon]$. So if we shrink $f^{-1}[0,\epsilon]$ such that it fits inside a single chart, we can consider it as an closed contractible subset of $\mathbb{R}^n$. However this is not enough to make it homeomorphic to a disk. Another approach would be to prove that $f^{-1}[\epsilon,a]$ is homeomorphic to $S^{n-1}\times [0,1]$, and then argue that since for any $0<t<\epsilon$, $f^{-1}[t,a]$is a deformation retract of $f^{-1}[\epsilon,a]$, so $f^{-1}[0,a]$ would be homeomorphic to $S^n\times [0,1]$ with $S^n\times\{0\}$ identified to a point. This space is then homeomorphic to a disk as well. Milnor also remarks that the non-degeneracy condition on $f$ is not essential. The way I would like to prove it doesn't use non-degeneracy either. He refers to two sources that supposedly give a proof that don't use the non-degeneracy condition, but I wasn't able to find a copy online and my university's library doesn't stock any copies. Any thoughts? Edit: In the end I was able to find a book after all. In Saaty's Lectures on Modern Mathematics vol. 2 Milnor has written a chapter on differential topology. In this section he gives a proof that doesn't require the non-degeneracy condition. He uses a lemma by Brown and Stalling that says that for a paracompact manifold $M$, if any compact subset is contained in an open set diffeomorphic to $\mathbb{R}^n$, then $M$ is itself diffeomorphic to $\mathbb{R}^n$. Let $x_0$, $x_1$ be the critical points, and let $U$ be a neigborhood of $x_0$ diffeomorphic to $\mathbb{R}^n$. Then using the gradient we can always stretch $U$ such that it covers any compact subset of $M-x_1$. Hence $M-x_1$ is diffeomorphic to $\mathbb{R}^n$. Now $M$ is homeomorphic to the one point compactification of $\mathbb{R}^n$ which is in turn homeomorphic to $S^n$, completing the proof.","['differential-topology', 'morse-theory', 'differential-geometry']"
1270105,What does it mean if the standard Hermitian form of complex two vectors is purely imaginary?,"If $v,w \in \mathbb{C}^n$, what does it mean geometrically for $\langle v , w \rangle$ to be purely imaginary?","['linear-algebra', 'complex-numbers']"
1270106,compute improper integrals using integration by parts,"Compute \begin{equation*}
\int_0^\infty \frac{\sin^4(x)}{x^2}~dx\text{ and }\int_0^\infty \frac{\sin (ax) \cos (bx)}{x}~dx.
\end{equation*} For the first integral I tried letting $u = \sin ^4 x$ and $dv= \frac{1}{x^2}~dx$, which simplified to $\int_0 ^\infty \frac{4 \sin^3(x) \cos(x)}{x}~dx$ and applying integration by parts again with $u = \sin^3(x) \cos (x)$ and $dv = \frac{1}{x}$, I got $$\left.\vphantom{\frac11}[\sin ^3 (x) \cos (x) \ln (x)] \right|_0^\infty - \int_0^\infty \ln (x) [3 \sin ^2 (2x) - \sin^4 (x)]~dx$$ The only problem is that it appears that the term $[\sin ^3 (x) \cos (x) \ln (x)] \big\vert_0^\infty$ evaluates to infinity and neither the $3\int_0^\infty \ln (x)  \sin ^2 (2x)~dx$ term nor the $3\int_0^\infty \ln (x)  \sin^4 (x)~dx$ converges.This looks like a dead end but the other choice of $u$ and $dv$ looks even worse, so I'm not sure how to proceed. For the second integral I tried $u = \sin (ax) \cos (bx)$ and $dv = \frac{1}{x}$, which gives me $[\sin (ax) \cos (bx) \ln (x)] \big\vert_0^\infty + \int_0^\infty \frac{b-a}{2} \ln (x) \cos ((a-b)x)~dx - \int_0 ^ \infty \frac{b+a}{2} \ln (x) \cos ((a+b)x)~dx$, which also looks like a dead end because all three of the terms go to infinity. Any help is appreciated.","['calculus', 'real-analysis', 'improper-integrals', 'integration']"
1270107,Finding the number of real roots of an unusual(!) equation [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How many real roots does the below equation have? \begin{equation*}
\frac{x^{2000}}{2001}+2\sqrt{3}x^2-2\sqrt{5}x+\sqrt{3}=0
\end{equation*} A) 0  B) 11 C) 12 D) 1 E) None of these I could not come up with anything. (Turkish Math Olympiads 2001)","['contest-math', 'algebra-precalculus']"
1270119,vector space of continuously differentiable functions is complete regarding a specific norm [duplicate],"This question already has an answer here : Prove that $C^1([a,b])$ with the $C^1$- norm is a Banach Space. (1 answer) Closed 4 years ago . Consider $C^1[a, b] = \{f: [a, b] \to \mathbb{C}\mid f\text{ continuously differentiable}\}$. Consider the following norm: $$\|f\|_{C^1} = \|f\|_\infty + \|f'\|_\infty$$ Now, it needs to be shown that $C^1[a, b]$ is complete with regard to the $\|\cdot\|_{C^1}$-Norm (using the definition for complete that a metric space $X$ is complete $\Longleftrightarrow$ every Cauchy-series in $X$ also converges in $X$). I know that $C^1[a, b]$ is not complete in respect to the $\infty$-norm. I guess these special Cauchy-sequences of functions that do not converge in $C^1[a, b]$ using the $\infty$-norm simply aren't Cauchy-sequences in respect to the $C^1$-norm. But how can this be proven? Thanks in advance. Edit: The linked thread only asks for why $||f||_{C^1}$ is a norm, and doesn't deal with whether or not $C^1[a, b]$ is complete regarding this norm at all, which is the specific topic of this thread.","['analysis', 'normed-spaces']"
1270126,"Calculating $\int_0^{\infty } \frac{\log (v+1)}{\sqrt{(v+1)^2+1} \sqrt{(v+1)^2+4 \sqrt{(v+1)^2+1} (v+1)+4}} \, dv$","What tools would you recommend me for this one? $$\int_0^{\infty } \frac{\log (v+1)}{\sqrt{(v+1)^2+1} \sqrt{(v+1)^2+4 \sqrt{(v+1)^2+1} (v+1)+4}} \, dv$$ It's related to Calculate in closed form $\int_0^1 \int_0^1 \frac{dx\,dy}{1-xy(1-x)(1-y)}$ if my so long calculations are correct, and it only represents a tiny bit of the whole story.","['calculus', 'real-analysis', 'definite-integrals', 'integration']"
1270169,Show $f(f^{-1}(B_0))\subset B_0$ and that equality holds if $f$ is surjective,"Let $f: A\to B$. Let $A_0\subset A$ and $B_0\subset B$. Show $f(f^{-1}(B_0))\subset B_0$ and that equality holds if $f$ is surjective. Attempt: I already did the first part. It is showing that equality holds for surjectivity that is troubling me. Assume $f$ is surjective but $f(f^{-1}(B_0))\subsetneq B_0$. $\implies$ there exists $f(a)\in B_0$ s.t $a\notin A_0$, but if $f$ is surjective this implies for all $f(x)\in B_0$ there exists $x\in A_0$ s.t. $f(x) = b\in B_0$ But this is a contradiction because we assumed $f$ was surjective. So $f(f^{-1}(B_0))\subset B_0$. So equality would hold??? I have a fealing this is completely bumbled up....","['elementary-set-theory', 'functions']"
1270210,Existence of the Brownian Motion using the Kolmogorov extension theorem,"Kolmogorov extension theorem: Let $T$ denote some interval (thought of as ""time""), and let $n \in \mathbb{N}.$ For each $k \in \mathbb{N}$ and finite sequence of times $t_{1}, \dots, t_{k} \in T$, let $\nu_{t_{1} \dots t_{k}}$ be a probability measure on $(\mathbb{R}^{n})^{k}.$ Suppose that these measures satisfy two consistency conditions: for all permutations $\pi$ of $\{ 1, \dots, k \}$ and measurable sets $F_{i} \subseteq \mathbb{R}^{n}$, $$\nu_{t_{\pi (1)} \dots t_{\pi (k)}} \left( F_{\pi (1)} \times \dots \times F_{ \pi(k)} \right) = \nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right);$$ for all measurable sets $F_{i} \subseteq \mathbb{R}^{n},m \in \mathbb{N}$ $$\nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right) = \nu_{t_{1} \dots t_{k} t_{k + 1}, \dots , t_{k+m}} \left( F_{1} \times \dots \times F_{k} \times \mathbb{R}^{n} \times \dots \times \mathbb{R}^{n} \right).$$ Then there exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and a stochastic process $X : T \times \Omega \to \mathbb{R}^{n}$ such that $$   \nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right) = \mathbb{P} \left( X_{t_{1}} \in F_{1}, \dots, X_{t_{k}} \in F_{k} \right)
$$
for all $t_{i} \in T, k \in \mathbb{N}$ and measurable sets $F_{i} \subseteq \mathbb{R}^{n},$ i.e. $X$ has $\nu_{t_{1} \dots t_{k}}$ as its finite-dimensional distributions relative to times $t_{1} \dots t_{k}.$ Brownian motion: The Brownian motion $B_t$ is characterised by four facts: $B_0=0$ $B_t$ is almost surely continuous $B_t$ has independent increments $B_t-B_s\sim \mathcal{N}(0,t-s)$ (for $0 \leq s \le t$) $\mathcal{N}(\mu,\sigma^2)$ denotes the normal distribution with expected value $\mu$ and variance $\sigma^2.$ The condition that it has independent increments means that if $0 \leq s_1 \leq t_1 \leq s_2 \leq t_2$ then $B_{t_1}-B_{s_1}$ and $B_{t_2}-B_{s_2}$ are independent random variables. MY QUESTION : How to proof the existence of the Brownian Motion using the Kolmogorov extension theorem?","['brownian-motion', 'probability', 'stochastic-processes', 'reference-request']"
1270218,Dice outcomes probability,"Two dice are rolled. What is the probability that the sum of the
  numbers on the dice is at least 10 Let $Z$ denote the set of successful outcomes: $Z=\{(4,6),(6,4),(5,5),(5,6),(6,5),(6,6)\}\\
\text{Sample space: }
S=6^2$ So the answer gives the probability as, $P=\frac{6}{36}$. My question is why are the pairs $(5,5),(6,6)$ only included once? The way I see it for two dice $D_1,D_2$ is it may appear as $D_1: 5,D_2: 5$ or $D_2: 5,D_1: 5$, so why don't we count for this as two outcomes?",['probability']
1270234,"If I know $AB$, how can I calculate $BA$?","Let $A∈\mathscr{M}_{3×2}(\mathbb{R})$ and $B∈\mathscr{M}_{2\times3}(\mathbb{R})$ be matrices satisfying
  $AB =\begin{bmatrix}
8 &2 &−2\\
2 &5 &4\\
−2 &4& 5
\end{bmatrix}$. Calculate $BA$. (Golan, The Linear Algebra a Beginning Graduate Student Ought to Know , Exercise 426.) Maybe it can be solved by solving a system of equations, but I think there is a shorter way since this problem was in my exam. Thanks.","['abstract-algebra', 'linear-algebra', 'matrices']"
1270256,Getting fiber bundles from short exact sequences,"Are there conditions that guarantee that a split short exact sequence of groups
$$
1 \rightarrow K \rightarrow G \rightarrow Q \rightarrow 1
$$
gives rise to a fiber bundle
$$
F \rightarrow E \rightarrow B
$$
on the level of $K(\pi,1)$'s? Any references relating fibrations to group extensions would be appreciated.","['exact-sequence', 'group-theory', 'algebraic-topology', 'fibration']"
1270275,Proofs of the Riesz–Markov–Kakutani representation theorem,"Let $X$ be a compact Hausdorff space, $C(X)$ the set of all real continuous functions on $X$, and $\mathcal{B}$ be the Baire $\sigma$-algebra of $X$, which is the $\sigma$-algebra generated by the functions in $C(X)$. Furthermore $M(X)$ is the set of all finite signed measures on $(X,\mathcal{B})$ with the norm $||\mu||=|\mu|(X)$, $|\mu|$ being the total variation of $\mu$. Finally, for all $\mu \in M(X)$ define $\phi_{\mu}:C(X)\rightarrow \mathbb{R}$ by $\phi_{\mu}(f)=\int f d\mu$. It is possible to formulate the Riesz-Markov-Kakutani theorem as follows: The application $\mu\mapsto \phi_{\mu}$ is a surjective isometry from $M(X),||.||$ onto $C(X)^{*},||.||_{*}$ the dual space of $C(X),||.||_{\infty}$. In other words the topological dual of the Banach space $(C(X),||.||_{\infty})$ (with as usual $||f||_{\infty}=\sup_{x\in X} f(x))$) can be identified with $M(X)$. My question is: since there is a functional analysis formulation of the theorem, is there a functional-analysis-flavoured proof of it ? Note that this version of the Riesz-Markov-Kakutani theorem is much stronger than the usually stated one, which is concerned positive functionals on $\mathbb{R}$. The fact that the dual norm is the total variation one is equivalent to the fact that Baire measures are necessarily regular, a not so trivial fact proved in Halmos's Measure Theory . I find proofs like the one in Rudin's Real and complex analysis disturbingly artificial and complex for such what seems such a natural and important result: an integral is nothing more or less than a bounded linear functional on continuous functions (when integrating over a compact space). I had a professor who used Daniell's integral with which the Riesz-Markov-Kakutani theorem follows almost instantly. That is a very good proof, the best I've seen so far, but I'm still under the impression that there might be other ways to look at the problem.","['compactness', 'measure-theory', 'functional-analysis', 'riesz-representation-theorem', 'reference-request']"
1270281,Proving a little tough trigonometric identity,Show that $$\frac{1+\sin A}{\cos A}+\frac{\cos B}{1-\sin B}=\frac{2\sin A-2\sin B}{\sin(A-B)+\cos A-\cos B}$$ How do I get the $A-B$ term in the denominator? Is RHS to LHS easier? Thanks.,"['proof-verification', 'trigonometry']"
1270286,Continued product in $\sin$ series,"Find the value of the product $$(\sin 1°)(\sin 3°)(\sin 5°)\ldots(\sin 89°)$$ I tried multiplying and dividing by $2$ and then combining and then converting into cosine, but doesn't work out.",['trigonometry']
1270298,Partition onto subsets at the same sum,"Positive integers $ a_1, a_2,\ldots, a_n $ such that $ a_k\leq k $ and the sum of all these numbers is even and equal to $ 2S $. Prove that the number can be divided into two groups, the amount of each of which is equal to $ S $. It's look like I have to use induction, but I can not figure out how...Please give me a hint.","['induction', 'combinatorics']"
1270301,Problem with black and white balls,"You are given $b+w$ boxes, $b,w$ of them contain a black or white ball inside, respectively. You want to find a pair of boxes with both balls black ($b\geq 2$). At each trial you make a guess of 2 boxes of your choice, and an Oracle tells you if both balls inside are black. If yes, you are done, if not, it just tells you ""No"", but does not reveal the contents of the boxes you chose. Question: what minimal number of trials $n(b,w)$ do you need to guarantee that you find such a pair? For $b>w$ there is a straightforward upperbound $n(b,w)\leq w+1$, which is achieved by dividing the collection into $\lceil (b+w)/2 \rceil$ pairs and trying them all one by one. The general upperbound is $n(b,w)\leq \binom{b+w}{2}-\binom{b}{2}+1$. I wonder if it can be improved by some clever box selection, and if there are some good lowerbounds.",['combinatorics']
