question_id,title,body,tags
1028294,Finding a tangent of an algebraic curve: $xy = 1$ [Well written explanation],"I want to find, using (easy) calculus, the slope of a tangent to the algebraic curve $xy = 1$. The tangent I want to find is the tangent that passes through the point $(x_i,y_i) = (0,f(t))$. $f$ is defined as $f(t) = 4\cdot2e^{-t/10}$. I know the general way of finding the slope of a tangent to a function that passes through a point $P$ outside of the function is to put: $$y-y_i = y'(x-x_i)$$ The problem for me is then to find $x_i$. I've tried the following: Implicit differentiation of $xy=1$ gives me: 
$$y' = -\frac{y}{x}$$ I then attempt to use the general method of finding tangents that pass through a point. $y-0 = -\dfrac{y}{x}\left(x-4\cdot2^{t/10}\right) \iff 1 = -1+\dfrac{1}{x}\cdot4\cdot2^{t/10} \iff x=2\cdot2^{t/10}$ I'm not sure if I even chose the right approach. Any help appreciated, thank you in advance.","['calculus', 'derivatives']"
1028296,"What's a concise word for ""the expression inside a limit""? Limitand?","In $\sqrt {f}$, $f$ is the radicand. In $\sum g_i$, $g_2$ is a  summand. In $x \times y \times z$, $y$ is a multiplicand. In: $$\displaystyle \lim_{n \to +\infty} h_n(x)$$ or: $$h(x) \to \ell \quad \text {as} \quad x \to c$$ What's ""$h$"" called? The limitand?","['terminology', 'limits']"
1028311,Stokes’ Theorem to find integration,"Use Stokes’ Theorem to evaluate integration $c (xy \,dx+ yz\, dy + zx\, dz)$ where and $C$ is the triangle with vertices $(1,0,0),(0,1,0),(0,0,1)$, oriented counter-clockwise rotation as viewed from above. can anyone please help me with this?","['multivariable-calculus', 'calculus', 'integration']"
1028341,Computing a Projection Valued Measure,"I've recently begun learning about Projection Valued Measure and I'm a little confused. I understand that a Projection Valued Measure is a family of orthogonal projections $P(\Lambda)$ indexed by the Borel measurable sets on a Hilbert Space with some caveats ($P(0)=0$, $P(\mathbb{R})=1$, etc.) I also understand that for a self-adjoint operator, we have $P(\Lambda)=\chi_{\Lambda}(H)$ where $\chi$ is the characteristic function on the Borel set $\Lambda$. In one of my questions, I was given a matrix that was just a linear combination of Pauli matrices and asked to find the projection valued measure of it. There was no mention of Borel sets or anything, so I became a little confused. I found that for Hermitian matrices, we can use functional calculus to find $$f(H)=\sum\limits_{i} f(E_i)P_i$$
Where $f$ is a Borel function, $E_i$ the eigenvalues of $H$ and $P_i$ the corresponding projections into the eigenspaces. Is this the same as the Projection Valued Measure for a $n\times n$ Hermitian matrix? EDIT: I think I might have figured it out. Wouldn't the projection valued measure just be $$P(\Lambda)=\sum\limits_{\{i|E_i\in\Lambda\}} P_i$$
Where $E_i$ are the eigenvalues and $P_i$ the projections into the eigenspaces? Again, no Borel sets are defined, but we are working in $\mathbb{C}^2$.","['operator-theory', 'measure-theory', 'quantum-mechanics', 'functional-analysis']"
1028350,quadratic variations of Brownian motion squared,"I'm trying to refresh my memories about stochastic processes.
We know that Brownian motion has as quadratic variation equals to t. What is the quadratic variation of the Brownian motion squared ? Usually for this I would just use Ito's formula and pick out whatever is in front of the dWt, except in that case it doesn't work. Is there a straightforward way to compute this ? thanks !","['quadratic-variation', 'stochastic-processes', 'probability', 'brownian-motion']"
1028371,Complex number isomorphic to certain $2\times 2$ matrices?,"I have been trying to prove this, but I am having trouble understanding how to prove the following mapping I found is injective and surjective. Just as a side note, I am trying to show the complex ring is isomorphic to special $2\times2$ matrices in regard to matrix multiplication and addition. Showing these hold is simple enough. $$\phi:a+bi \rightarrow \begin{pmatrix} a & -b \\ b & a \end{pmatrix}$$ This is what I have so far: Injective: I am also confused over the fact that there are two operations, and in turn two neutral elements (1 and 0). Showing that the kernel is trivial is usually the way I go about proving whether a mapping is injective, but I just can't grasp this. $$ \phi(z_1) = \phi(z_2) \implies \phi(z_1)\phi(z_2)^{-1} = I = \phi(z_1)\phi(z_2^{-1}) = \phi(z_2)\phi(z_2^{-1}).$$ So if we can just show that the kernel of $\phi$ is trivial, then it also shows that $z_1 = z_2$ . The only complex number that maps to the identity matrix is one where $a = 1$ and $b = 0$ , $a + bi = 1 + 0i = 1$ . Using a similar argument for addition we can just say that the only complex number $z$ such that $\phi(z) = 0\text{-matrix}$ , is one where $a=0$ and $b=0$ , $a+bi=0+0i=0$ . Surjective: I forgot to add this before I posted, but I honestly don't really understand how to prove this because it just seems so obvious. All possible $2\times2$ matrices of that form have a complex representation because the complex number can always be identified by its real parts and since the elements of the $2\times2$ matrix are real then the mapping is obviously onto. I have always had trouble understanding when I can say that I have ""rigorously"" proved something, so any help would be appreciated!","['matrices', 'complex-numbers', 'linear-algebra']"
1028374,Addition of two differentiable functions is differentiable,"I am stuck with proving the following statement. In fact, I am proving another assumption, and the proof of this would help me to proceed. Assume that $f_1$ and $f_2$ are differentiable on the interval $(a,b)$. Then define $f=f_1+f_2$. Show that $f$ is differentiable on any point in that interval. So I guess I need to prove that the sum of two differentiable functions on an interval is differentiable My attempt: I wanted to prove it from definition, writing $$\lim_{h\to0}\frac{f_1(a+h)-f_1(a)}{h}+\lim_{h\to 0}\frac{f_2(a+h)-f_2(a)}{h}$$ Then I can write them under the same limit, but then I cannot proceed. Would be thankful if anyone helped me with it.","['derivatives', 'real-analysis', 'limits']"
1028391,Prove this congruence,Let $p$ be a prime of the form $4k+3$ and $m$ an even positive integer less than $p-1$. Prove that $$1^m+2^m+\cdots+\left(\frac{p-1}{2}\right)^m \equiv \left(\frac{p+1}{4}\right)+\left(\frac{p+1}{4}\right)^2+\cdots+\left(\frac{p+1}{4}\right)^{\frac{p-1}{2}}\pmod p$$ WITHOUT doing it by showing that both sides are divisible by $p$. I couldn't solve this,"['proof-writing', 'number-theory']"
1028398,Formal adjoint of divergence,"We define the so-called conformal Killing operator $K$ mapping (1,0) vectors to (0,2) tensors by $$K(X)_{ab} = \frac{1}{2}\nabla_aX_b+ \nabla_bX_a -\frac{2}{3}(\text{div}X) g_{ab}.$$ Here $g$ is the metric and $\nabla$ is the induced covariant derivative. I am told that the formal adjoint of $K$ is $-\text{div}.$  This is supposed to be easy, but I am not getting anywhere near the answer and I presume I must be doing something basic incorrectly. Could anyone point me in the correct direction? Attempt (WRONG): Let $h_{ab}$ be a $(0,2)$ tensor. We integrate by parts over a closed manifold: $$\int -\nabla^a h_{ab} X^b = \int \nabla^a (h_{ab} X^b) + \int h_{ab} \nabla^a X^b= 0 + \int h_{ab}\nabla^aX^b.$$ This would appear to mean that -div is the adjoint of $\nabla,$ which is wrong. [Edit: see answer below for explanation. The computation is in fact correct, as pointed out by Jack Lee.]","['tensors', 'riemannian-geometry', 'differential-geometry']"
1028404,Why is every positive integer the sum of 3 triangular numbers?,Why is every positive integer the sum of at most 3 triangular numbers ?,['number-theory']
1028408,Groups of order 24.,"I supposed $n_3=4$ and $n_2=3$ , and then
I made $G$ act by conjugation on $\text{Syl}_3 (G)$ . I want to show that $G\cong S_4$ (looking at all order 24 groups here I saw the only one that has $n_3=|\text{Syl}_3(G)|=4$ and $n_2=|\text{Syl}_2(G)|=3$ is $S_4$ ) so I want to show that the kernel of this conjugation action is trivial.
So this action defines a representation $\varphi:G\rightarrow S_4$ . I was thinking of using the order of $G/\ker(\varphi)$ but this didn't solve anything. So I thought about this kernel as the set that normalizes all three Sylow $3-$ subgroups, the intersection of the normalizers. If we say $\text{Syl}_3 (G)=\left\{P_1,P_2,P_3\right\}$ ,then I had, by the Orbit-stabilizer theorem, that the order of the stabilizers is $6$ . 
I saw that in $S_4$ any two of these normalizers intersect in two elements, but when I intersect all of them the intersection is trivial. I want to prove that. So I was doing the following. By Lagrange, the intersection of all, has order $1, 2, 3$ or $6$ . It can't have order $3$ , it'd be a normal Sylow $3-$ subgroup and that's impossible. So it has order $1,2$ or $6$ , and I want to discard $2,6$ . How could I show that the normalizers are different (This would discard $6$ )? And how could I show that the intersection of all of them has more than two elements? I was thinking about saying that, if the intersection had order $2$ , then there would be a normal subgroup of order $2$ , and then a subgroup of order $6$ isomorphic to $\mathbb{Z}_2\rtimes_\phi \mathbb{Z}_3\cong \mathbb{Z}_6$ . Could I get somewhere this way? And how could I do the $2$ and $6$ parts?","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
1028413,"Proving if A and B are matrices such that A, B, and AB are normal, then BA is also normal.","If A and B are matrices such that A, B, and AB are normal, then BA is also normal. I've seen this statement around, although I've only seen the site/publication/etc... state that it was proven by Wiegmann, but nobody actually gives the proof. Could somebody help me wrap my head around why this is true? Thank you.","['matrices', 'linear-algebra', 'reference-request']"
1028434,Laplace transform with the Heaviside unit step function,"I want to find the laplace transform for the function: $$f(t) = \left\{\begin{array}tt,\quad t\lt 2 \\ t^2 , \quad t\geq 2 \end{array} \right.$$ So I thought that the proper setup was: $$\mathcal{L}(f(t)) = t - (t)u(t-2) + (t^2)u(t-2)$$ $$\mathcal{F}(s) = \frac{1}{s^2}- \frac{e^{-2s}}{s^2}  +\frac{2e^{-2s}}{s^3}$$ $$= \frac{s-se^{-2s} + 2e^{-2s}}{s^3}$$ But it would seem I don't know how to setup the heaviside unit step function properly. Why is the above wrong?","['ordinary-differential-equations', 'laplace-transform']"
1028436,Why is a Symmetric Relation also Transitive?,"A relation R on set A is as follows: R = {(1,1), (2,2), (3,3)} R is symmetric! But WHY is R Transitive?","['relations', 'discrete-mathematics', 'elementary-set-theory']"
1028439,Probability that a real number is bigger than another,"I am not a mathematician; I lack formal training in probability theory, but the following problem came to my mind. I take two random real numbers $a,b > 0$.
What is the probability that $a > b$ ?
I would say, due to the symmetry of the problem, $p=1/2$.
However, once I have $a$ (whatever it is), then $b$ has to fall either in $(0,a)$ or in $(a, + \infty)$, at random. But the measure of the former is finite, while the latter is infinite, therefore $b$ will almost surely $(p=1)$ be greater than $a$. But we saw before that the probability is $1/2$. How could the mere information that $a$ exist, only knowing it is finite, change the probability? The same reasonment would apply by considering $b$. The question may be stupid; if so, sorry in advance.",['probability-theory']
1028448,Orbits of General Linear Group,"I am working on a problem to find the orbits of the general linear group $\mathrm{GL}_n(\mathbb{R})$, acting on $\mathbb{R}^n$, with the invertible matrix $A$ acting on a column vector $x \in \mathbb{R}^n$ by taking it to the vector $Ax$. I have already verified that this is a group action, but I'm not sure how to show that there are only two orbits. Thanks for your help.",['abstract-algebra']
1028457,Smooth homotopy,"Let $M,N$ be manifolds. Suppose that $f_0, f_1:M\stackrel{C^\infty}\to N$ are homotopic, i.e. there exists a continuous mapping $f:M\times[0,1]\to N$ s.t. $f(x,0)=f_0(x)$, $f(x,1)=f_1(x)$. Then is there any smooth homotopy $F\in C^\infty(M\times[0,1],N)$ connecting $f_0$ to $f_1$?  How to construct it?","['differential-topology', 'geometry', 'manifolds', 'calculus']"
1028485,Bilinear functional to be elementary,"Let $V$ be a $n$ dimensional vector space over $\Bbb C$. We say a functional $f:V\times V\to \Bbb C$ is bilinear if $f$ is linear in each variable if the other variable is fixed. And $$f$$ is called elementary if there exists some $x,y\in V$ such that
$$f(u,v)=<x,u>\cdot <y,v>.$$
Here $<x,u>=x^*u$, $x^*$ is the conjugate transpose of $x$. Now my problem is as follows. Let $x,y,z$ be three linearly independent vectors in $V$. What conditions on $w$ should satisfy to ensure the following functional
$$f(u,v)=<x,u>\cdot <y,v>+<z,u>\cdot <w,v>$$
to be elementary. My first idea is as follows. If the above $f$ is elementary, then there exists some $a,b\in V$ such that 
$$f(u,v)=<a,u>\cdot <b,v>.$$
And thus
$$<x,u>\cdot <y,v>+<z,u>\cdot <w,v>=f(u,v)=<a,u>\cdot <b,v>$$
Since $f$ is bilinear, we need only to find conditions on $w$ such that there exists some $a,b\in\Bbb C^n$ such that 
$$\bar x_iy_j+\bar z_iw_j=\bar a_ib_j,\forall\ 1\leq i,j\leq n.$$
These are $n^2$ equations, but only with $2n$ variables, but I could not derive further.. I suspect that $w$ is a multiplier of $y$... This is exercise I.4.1 of Bhatia: Matrix Analysis.","['matrices', 'matrix-calculus', 'linear-algebra']"
1028545,"$\sum_{i=1}^{\infty}a_n*b_n $ converges for all $\lim_{n \rightarrow \infty}b_n = 1$, show that $a$ converges absolutely","So this is given:
$\sum_{n=1}^{\infty}a_n*b_n $ converges for all sequences $(b_n)$, such that $\lim_{n \rightarrow \infty}b_n = 1$. Somehow it should be showable that $(a_n)\,$converges absolutely, that is $\sum_{n=1}^{\infty}|a_n|$ converges. I have been pondering with this for hours, and I appreciate any help and ideas.","['absolute-convergence', 'convergence-divergence', 'sequences-and-series']"
1028560,Bijective function $f: \mathbb{Z} \to \mathbb{N}$,"Is it possible to have a bijective function between two sets if the domain is bigger than the co-domain, for instance, a function $f:\mathbb{Z} \to \mathbb{N}$?",['elementary-set-theory']
1028600,Smallest possible triangle to contain a square,"I was looking at this stack exchange question * and started thinking about the case of a polygon with 4 sides: a square. The question asks for a program that can take a polygon of N sides and return the smallest possible polygon of N-1 sides that contains the original polygon. Thinking about it, I wasn't sure what the optimal triangle encapsulating a square would look like. In KSab's answers, he returns a triangle that looks like this: This area is 2*(area of the square). With some easy guess-and-check work I found that this seems to be optimized. How do you prove that there is no better solution? EDIT: another consideration for the orientation of the triangle could be this:","['optimization', 'geometry']"
1028605,Prove or disprove that $G_1/H_1 \cong G_2/H_2$,"Let $\phi : G_1 \rightarrow G_2$ be a surjective group homomorphism. Let $H_1$ be a normal subgroup of $G_1$ and suppose that $\phi (H_1) = H_2$. Prove or disprove that $G_1/H_1 \cong G_2/H_2$. I say they are indeed isomorphic. Because: Let $f$ be the group homomorphism from $G_1$ to $G_2/H_2$ that sends $a$ to $\phi(a)$. Then the kernel of $f$ is everything that is sent to $H_2$. Well by assumption this is $H_1$. Since $\phi$ is surjective, so is $f$, so by the first isomorphism theorem, $G_1/H_1$ is isomorphic to $G_2/H_2$ Is this correct reasoning?","['group-isomorphism', 'group-theory', 'abstract-algebra']"
1028634,Derivative of ellipse,"Find $y'=\frac{dy}{dx}$
when: $$2x^2-xy+y^2=1$$ How do I solve this? Do I start with this?: $$y=\frac{2x^2+y^2-1}{x}$$ $$y'=\left(\frac{2x^2+y^2-1}{x}\right)'$$",['derivatives']
1028637,Using the Inverse Function Theorem prove that $(\sin^{-1}x)'$ = $\frac{1}{\sqrt{1-x^2}}$.,"Using the Inverse Function Theorem prove that $(\sin^{-1}x)'$ = $\frac{1}{\sqrt{1-x^2}}$. Proof: Let $f(x) = \sin x$, for $x$ in $(-1,1)$.  Then let $x_{0}$ be in (-1,1). Then $f'(x_{0})$ = $\cos(x_{0})\neq 0$, where $f'(x_{0})$ $> 0$. So $f$ is increasing thus one to one. Then using the Inverse Function Theorem,  $(f^{-1})'(y_{0})$ = $\frac{1}{\cos(\sin^{-1}y_{0})}$ = $sec(x_{0})$ = $\frac{1}{\sqrt{1-y_{0}^2}}$ . Is this a a correct way to prove it? Please any suggestion/feedback would be appreciated. And can someone please verify the intervals are correct since I am working with inverses.
Thank you very much.","['inverse', 'continuity', 'derivatives', 'real-analysis']"
1028642,Roll a fair die until a 6 appears for the third time. What is the chance that all six values have occurred?,"The question in the title is a homework question that I have been stumped on for some time. My approach thus far was to treat it as an occupancy problem. From class we derived the following formula for the probability of k faces being rolled on an r sided die after n rolls: $$ P(Y = k) = \binom{r}{k} \big (\frac{k}{r}\big )^n \sum_{i=0}^{r}(-1)^i\binom{k}{i}\big(1-\frac{i}{k}\big)^n$$ So what I have done is set k = r = 6 and arrived at: $$ P(Y = 6) = \sum_{i=0}^{6}(-1)^i\binom{6}{i}\big(1-\frac{i}{6}\big)^n$$ However, the problem now is that n is a random integer variable between $3$ and infinity. What I did next was attempt to model the number of rolls as a negative-binomial random variable and then compute the expectation value of the above expression inside of this distribution; however, it produces a very ugly expression which I am pretty sure is still wrong because it does not include the fact that a 6 is guaranteed to be rolled. I basically have run out of ideas and am somewhat stuck on how to proceed. My approach may be a total red herring, so feel free to discard it in any advice you give. Also, this is homework, so please don't list a full solution. Thanks for any help!","['statistics', 'dice', 'probability-theory', 'probability-distributions', 'probability']"
1028691,"show that Cov(X+ Y, X-Y)= Var(X) - Var(Y)","I have up until Cov(X+Y,X-Y) = E[((X-E(X))+(Y-E(Y)))((X-E(X))-(Y+E(Y)))] and now I am stuck and do not know how this turns into Var(X)-Var(Y)",['probability']
1028705,Computing derivative of parametric equation,"This is probably a silly question but I am just not sure if I understand what to do. So I have the parametric equations: $x=6\cos (t)-2\\   y=5\sin (t)+3$ I am asked to compute $\dfrac{dy}{dx}$ at the point $(3\sqrt{2}-2, 3-\frac{5}{\sqrt{2}})$ So 
$$\frac{dy}{dx}=\frac{\frac{dy}{dt}}{\frac{dx}{dt}}\implies\frac{dy}{dx}=-\frac{5\cos(t)}{6\sin(t)}$$ Now where do I plug the above numbers in to find $\dfrac{dy}{dx}$? Am I on the right track?","['parametric', 'derivatives']"
1028720,Example (?) of a Banach space containing an uncomplemented copy of itself,"I was wondering the following: Background Question: Does there exist a Banach space $X$ which contains a copy $X_0 \subset X$ of itself that is not complemented? By ""$X_0$ is a copy of $X$"", I mean $X_0 \cong X$ via an invertible, bounded, linear map.  Some googling turned up that the answer to the above question is ""yes"". This thread points to a paper containing an example of an uncomplemented copy of $\ell^1$ in $\ell^1$.  Since the proof seems to depend on some pretty fiddly analysis, and since answering the above question is only incidental to the aims of that paper, I was wondering whether there might be a simpler example of this phenomenon. In particular, I thought that the following example might work: Example(?): The most famous, and probably the most elementary, example of an uncomplemented subspace is the canonical copy of $c_0$ in $\ell_\infty$. With this in mind, I thought maybe one could use the following:
  \begin{align*}
X = c_0 \oplus \ell_\infty \oplus \ell_\infty \oplus \ell_\infty \oplus \ldots && X_0 = \{0\} \oplus c_0 \oplus \ell_\infty \oplus \ell_\infty \oplus \ell_\infty \oplus \ldots 
\end{align*}
  The hope is that, if $F \subset X$ was a complement for $X_0$, then this would imply $\pi_2(F) \subset \ell_\infty$ was a complement for $c_0 \subset \ell_\infty$ (a contradiction). Here, $\pi_2$ is projection onto the second factor $X \to \ell_\infty$. Towards completing the argument, I have already asked this question , but it hasn't attracted much attention. So, I am asking this (hopefully) better motivated question in addition. So, to reiterate, my question is: Question: Is $\{0\} \oplus c_0 \oplus \ell_\infty \oplus \ell_\infty \oplus \ell_\infty \oplus \ldots$ complemented in $c_0 \oplus \ell_\infty \oplus \ell_\infty \oplus \ell_\infty\oplus \ldots$?","['examples-counterexamples', 'functional-analysis', 'banach-spaces']"
1028725,Find the center of mass of soda can?,"Help finding center of mass of soda can?
If you represent the soda can as a right-circular cylinder radius=4 cm 
height =12 cm We are told to neglect the mass of the can itself. When the can is full the center of mass is at 6cm above the base, halfway along the axis of the can. As the can is drained and air replaces the soda, the center of mass descends towards the bottom. However when the can is completely empty the center of mass is still at 6cm. Assuming the density of soda is 1 gram per cubic cm and the density of air is 0.001 grams per cubic cm. Find the depth of soda in the can for which the center of mass is at it's lowest point. I am not sure where to begin, I was trying to think of this as a linear case where the fulcrum is at a point with masses on either end, but I am extremely lost. Thank you for the help",['multivariable-calculus']
1028733,How the derivative might fail to exist,Can a function have both a vertical tangent and cusp? Does The function $3x^{1/3}(x+2)$ have a vertical tangent and if so why? I believe that it has a cusp.,['derivatives']
1028781,"conformal mapping, regions of the complex plane marked +/-, find the function f,","The picture shows what the function f: $\mathbb{C}\to\mathbb{C}\cup\infty$ does to the plane. The values 0 at 0, 1 at $\pm$1, and $\infty$ at $\pm i$ are specified. To elaborate on the picture: there is a unit disk, with a plus sign on the part of the disk in the first quadrant, a minus sign on the part of the disk in the second quadrant, plus sign for the third quadrant and minus sign on the fourth quadrant. Outside this unit disk, there is a minus sign on the first quadrant, plus sign on the second quadrant, minus sign on third quadrant, and plus sign on the fourth quadrant. Now, back to the question: The signatures +/- indicate that the regions so marked are mapped 1 to 1 onto the upper / lower half-plane. What is f?  Explain why it cannot be otherwise. Edit: I'd like to post an old solution to this problem, as well as ask for help in the intermediate steps that were implicit in the solution itself: One solution offered by a student was this: Using the Reflection Principle, the function f is entirely determined by where it maps a single quarter-circle sector, say, the quarter-circle sector in the first quadrant. Question no. 1 : Why do we use the Reflection Principle?  Is it because, say, the first quarter-circle sector has a + sign, so f maps it to the upper half plane, and the Reflection Principle somehow tells us that f maps the rest of the first quadrant (outside of the quarter-circle sector), which has a minus sign, to the lower half plane?  If this is the case, how do we actually know the conditions are fulfilled to actually apply the Reflection Principle?  Do we think of the boundary of this quarter-circle sector to be the real line, where f takes real values and is continuous on this boundary?  How can we accept that?  Do we make some sort of intermediate transformation so that the image of the boundary is the real line?  (or perhaps just...real-valued, not necessarily the entire real line?) If we consider the mappings g(z)=z^2 and h(w)=−w−1/w, this quarter-circle is mapped to a semicircle and then to the upper half plane, both mappings invertible. Question no. 2 : How do we know to immediately consider these two specific mappings?  Why not consider other mappings of the quarter-circle sector in the first quadrant?  What makes these two choices of mappings so convenient? Thus our mapping must be of the form f(z)=T∘h∘g where T maps from the upper half plane onto the upper half plane. Such a map must be a linear fractional transformation, a consequence of Maximum Modulus Principle / Schwarz' Lemma. Question no. 3 : At which point did we use the Maximum Modulus Principle and Schwarz's Lemma? To determine which T it is, we consider the mappings now. $h(g(0))=\infty$,$h(g(i))=2$,$h(g(1))=−2$, so T must map $\infty$ to 0, 2 to $\infty$, and −2 to 1, so $$T(z)=−4/(z-2)$$ and putting the maps together
$$f(z)=4z^2/(1+z^2)^2$$ Question no. 4 : How do we know T will map the upper half plane to the upper half plane?  It seems that we only know what T does...to 3 specified pre-image points. Apparently, this final mapping is the mapping that describes the action indicated in the picture, which gives only + and - signs inside the unit disk and outside of it. Any help would be greatly appreciated. Thanks in advance,","['conformal-geometry', 'analyticity', 'complex-analysis']"
1028796,Are all symmetric and skew-symmetric matrices diagonalizable?,"I know from a theorem that every hermitian and skew-hermitian matrix is similar to a diagonal matrix. But, is this fact also true for symmetric and skew-symmetric matrices? And, symmetric matrices have real eigenvalues, what about symmetric matrices that have complex entries?","['matrices', 'linear-algebra']"
1028798,"Why do we retain exactness when tensoring by $\mathcal{O}_C$ in Hartshorne, Lemma V.1.3?","Hartshorne, Algebraic Geometry , Chapter V, Lemma 1.3, reads (in part): Throughout this chapter, a surface will mean a nonsingular projective surface over an algebraically closed field $k$.  [...] Let $X$ be a surface. [...] Lemma 1.3. Let $C$ be an irreducible nonsingular curve on $X$ , and let $D$ be any curve meeting $C$ transversally.  Then
  $$\#(C \cap D) = \deg_C(\mathscr{L}(D) \otimes \mathcal{O}_C).$$
  Proof.  [...] We use the fact that $\mathscr{L}(D)$ is the ideal sheaf of $D$ on $X$.  Therefore, tensoring with $\mathcal{O}_X$, we have an exact sequence
  $$0 \to \mathscr{L}(-D) \otimes \mathcal{O}_C \to \mathcal{O}_C \to \mathcal{O}_{C \cap D} \to 0$$
  where now $C \cap D$ denotes the scheme-theoretic intersection. [...] So apparently we've taken the exact sequence
$$0 \to \mathcal{O}_X(-D) \to \mathcal{O}_X \to \mathcal{O}_D \to 0$$
of coherent sheaves on $X$, tensored by the coherent sheaf $\mathcal{O}_C$, and the resulting sequence is still exact. Now, as I understand it, $\mathcal{O}_C$ is not flat: Proposition III.9.2(e) says that a coherent sheaf on a noetherian scheme is flat iff it is locally free, and $\mathcal{O}_C$ is clearly not locally free since it's supported on a curve.  (Of course I guess I don't actually need flatness here.)",['algebraic-geometry']
1028818,Proof of quotient set is a partition,"To prove a quotient set S/R is a partition of S, one of the requirements is that Union of S/R = S This is a proof that i dont quite understand (proving S is a subset of S/R)
∀x∈S:x∈[x]
=>¬(∃x∈S:x∉[x])
=>¬(∃x∈S:x∉⋃[x])
=>∀x∈S:x∈⋃S/R
=>S⊆⋃S/R Why can't we skip the De Morgan's Law steps and straightaway conclude that x∈⋃S/R?",['elementary-set-theory']
1028819,Prove that $\zeta(4)=\pi^4/90$,"I am asked to ""use the calculus of residues"" to prove that $$\displaystyle\sum\limits_{n=1}^{\infty} \frac{1}{n^4}=\frac{\pi^4}{90}$$ I think I can do this given the Laurent series for $\cot z$ centered at the origin, but I don't know how to find the first few terms of the Laurent series (I can use Cauchy's Integral Formula to find the first coefficient).","['residue-calculus', 'riemann-zeta', 'laurent-series', 'complex-analysis']"
1028828,Calculating Euclidean dissimilarity for a given cluster with itself,"Suppose I have clusters $$A= \{(1,1)^T, (1,2)^T\} $$
$$B=\{(2,3)^T, (3,4)^T\} $$
$$C= \{(4,5)^T, (5,6)^T, (1,2)^T\} $$ I wish to use the Euclidean dissimilarity and Average linkage to calculate a dissimilarity matrix for these clusters. So I use the formula $\frac{1}{|A||B|}\sum_{x\in A}\sum_{y\in B}\sqrt{\sum_{k=1}^{m}(x_{ik} - y_{jk})^2}$ But if I wish to calculate the dissimilarity using this measure between say $A$ and itself, I'm inclined to say from a rudimentary knowledge of metric spaces (and a basic intuition that $A$ should have $0$ dissimilarity with itself) that $d(A,A)=0$ for any $A$. However, using the formula given above I get $d(A,A)=0.5$; $$\frac{1}{4}\left[\sqrt{(1-2)^2 + 0} + \sqrt{(2-1)^2 + 0} \right] = 0.5$$ Can someone reason with me which of the two answers is correct? I feel the conclusion probably hinges on whether $A$ is interpreted as a single entity or as a collection of sets.","['clustering', 'statistics', 'matrices', 'euclidean-geometry', 'metric-spaces']"
1028860,Setting up the intergal but do not integrate,"I'm having a little trouble with this problem. Let D be the solid bounded by y=x, z=1-y^2, x=0, and z=0 1) Sketch the region of integration using 2 and  dimensional sketches to show the region clearly. 2). Setup 6 different integrals for calculating the volume of D, each with a different order of integration. I can do number 1 but for 2 I am having trouble I am thinking I need to setup intergals like this  dydxdz dxdydz dzdydx dzdxdy dydzdx dxdzdy If you could explain how to do go about doing this it will help a WHOLE bunch Of course I don't want you guys to do my work for me but if you could do one order of integration and walk me through that as well it will help because my teacher isn't all that great. Thank you much",['multivariable-calculus']
1028891,Compute: $\lim_{n \to \infty } \left ( 1-\frac{2}{3} \right ) ^{\frac{3}{n}}\cdots \left ( 1-\frac{2}{n+2} \right ) ^{\frac{n+2}{n}}$,"Help me please to compute the limit of: $
\lim_{n \to \infty }  \left ( 1-\frac{2}{3} \right ) ^{\frac{3}{n}}\cdot  \left ( 1-\frac{2}{4} \right ) ^{\frac{4}{n}}\cdot  \left ( 1-\frac{2}{5} \right ) ^{\frac{5}{n}}\cdots \left ( 1-\frac{2}{n+2} \right ) ^{\frac{n+2}{n}} 
$ What I did: $
L=\frac{a_{n+1}}{a_n} =   \frac{ \left ( 1-\frac{2}{n+3} \right ) ^{\frac{n+3}{n+1}}}{ \left ( 1-\frac{2}{n+2} \right ) ^{\frac{n+2}{n}}}=\frac{2/e}{2/e}=1
$ But it's not. Since $L=1$, I need use something else...","['calculus', 'limits']"
1028911,Looking for differentiable functions $f$ such that the set of points at which $|f|$ is not differentiable has some particular properties,"I know that $\sin x$ is differentiable at all points but $|\sin x|$ is not differentiable at countably many points namely at integer multiples of $\pi$ . So I am asking the following questions i) Give example of a differentiable function $f:\mathbb R \to \mathbb R$ such that the set of points at which $|f|$ is  not differentiable is countable and dense in $\mathbb R$ ii) Give example of a differentiable function $f:\mathbb R \to \mathbb R$ such that the set of points at which $|f|$ is  not differentiable is uncountable and not dense in $\mathbb R$ iii) Give example of a differentiable function $f:\mathbb R \to \mathbb R$ such that the set of points at which $|f|$ is  not differentiable is uncountable and  dense in $\mathbb R$ $ UPDATE$:- As mentioned in the comments if $f$ is differentiable and and at some point non-zero then since by continuity $f$ will have same sign in a  neighborhood of that point , $|f|$ will be differentiable ; thus $|f|$ is not differentiable $c$ only when $f(c)=0$ but then as  John pointed out , if such points are dense then this leads to a contradiction , resolving i) and iii) in the negative ; this leaves us with (ii) only","['derivatives', 'real-analysis']"
1028932,Generalized forms of Curl and Divergence,"The definitions I learned in my calculus courses for curl and divergence were rather, at least to me, unintuitive and seemed to work only for $\mathbb{R}^3$. I took a look on Wikipedia: ""The divergence of a vector field $F$ at a point $p$ is defined as the limit of the net flow of $F$ across the smooth boundary of a three-dimensional region $V$ divided by the volume of V as $V$ shrinks to $p$. Formally: $$\operatorname{div}\,\mathbf{F}(p) = 
\lim_{V \rightarrow \{p\}}
\iint_{S(V)} {\mathbf{F}\cdot\mathbf{n} \over |V| } \; dS$$ The curl of a vector field F, denoted by $\operatorname{curl} \, \mathbf{F}$, or $\nabla \times F$, at a point is defined in terms of its projection onto various lines through the point. If $\scriptstyle\mathbf{\hat{n}}$ is any unit vector, the projection of the curl of $F$ onto $\scriptstyle\mathbf{\hat{n}}$ is defined to be the limiting value of a closed line integral in a plane orthogonal to $\scriptstyle\mathbf{\hat{n}}$ as the path used in the integral becomes infinitesimally close to the point, divided by the area enclosed. As such, the curl operator maps continuously differentiable functions $f : \mathbb{R}^3 \to \mathbb{R}^3$ to continuous functions $g : \mathbb{R}^3 \to \mathbb{R}^3$. Implicitly, curl is defined by: $$(\nabla \times \mathbf{F}) \cdot \mathbf{\hat{n}} \ \overset{\underset{\mathrm{def}}{}}{=} \lim_{A \to 0}\left( \frac{1}{|A|}\oint_{C} \mathbf{F} \cdot d\mathbf{r}\right)$$
"" To me, ""intuitively"", it seems that divergence at a point involves making a closed surface around the point, measuring the total flux, and dividing that by the volume of the closed surface. Even more simply put, it is the net measure of how much ""flow"" is going in or out. For the curl at a point, we formulate a plane around the point, take an integral of the closed loop around the point and divide by the area enclosed by the loop. More simply, one could imagine a tiny sphere in $\mathbb{R}^3$. The curl tells us how that sphere is rotating by giving a vector. The vector tells us the direction and speed of rotation. Does anyone perhaps have a better or more intuitive way of viewing curl and divergence? I was also wondering if there is a general definition that works for any given vector space over any field, even finite fields. But then integration and dot products and even limits might not make sense.","['multivariable-calculus', 'calculus']"
1028943,Simple explanation for Hypergeometric distribution probability,"I am following through the Hypergeometric distribution: The probability that we select a sample of size $n$ containing $r$ defective items from a
population of $N$ items known to contain $M$ defective items is $P(X = r) = C(M,r) * C(N-M,n-r) / C(N,n)$ where C(P,Q) is the combination of P items taken Q at a time. Explanation on the above equation: (a) we may select $n$ items from a population of $N$ items in $C(N,n)$ ways - understood (b) we may select $r$ defective items from $M$ defective items in $C(M,r)$ ways - understood (c) we may select $n−r$ non-defective items from $N−M$ non-defective items in $C(N−M,n−r)$ ways -did not understand (d) hence we may select $n$ items containing $r$ defectives in $C(M,r) * C(N−M,n-r)$
ways -did not understand Why both (b) and (c) must be considered and those factors got multiplied in (d) Can anybody explain the hypergeometric distribution derivation in simple terms. The above material is taken from here : The Hypergeometric distribution","['probability', 'hypergeometric-function']"
1028952,prove convergence almost surely,"Let {$X_n$} be a sequence of i.i.d. random variables with $E[|X_1|]<\infty$, and $S_n=\sum_{j=1}^nX_j$. Show that if $E[X_1]\neq0$, then $$\frac{\max_{1\leq k\leq n} |X_k|}{|S_n|}\rightarrow 0 $$ almost surely. I'm thinking of using strong law of large numbers to prove this, but don't know how to start. Please help.","['statistics', 'probability']"
1028974,sum and product of Lipschitz functions,"I have the following question from my notes, where $f$ and $g$ are Lipschitz functions on $A ⊂ \Bbb R$. I'm able to show that the sum $f + g$ is also a Lipschitz function, however I'm stuck on trying to show that if $f,g$ are bounded on $A$, then the product $fg$ is Lipschitz
on $A$. Also, is there a valid example of a Lipschitz function $f$ on $[0,+∞)$ such that $f^2$ is
not Lipschitz on $[0,+∞)$?","['lipschitz-functions', 'real-analysis']"
1029025,"orthonormal sequence in $L^2[0,1]$ - how to prove these following equivalent terms?","I've been asked this following very interesting question and would like some help figuring out why it is true :) Let $u_n$ be an orthonormal sequence in $L^2[0,1]$ Prove that the following are equivalent: $u_n$ is complete (orthonormal basis) for every $x\in [0,1]$ : $x=\sum_{n=1}^{\infty} |\int_{0}^{x} u_n(t)dt|^2 $ $0.5=\sum_{n=1}^{\infty} \int_{0}^{1} |\int_{0}^{x} u_n(t)dt|^2 dx $ My thoughts so far: a. if $u_n$ is complete, I could use Parseval's identity with functions $f=1_{[0,x]}$ and get condition 2, and integrate it to get condition 3 ( p.s: why could I change the order of the inifite sum with that $\int_{0}^{1}$? ) b. The other way aronud is harder. I figured out that using the definition of orthonormal basis would be a little difficult, So probably I'm supposed to show the Parsevals' identity, or something like that. no luck there. I would like some guide if you could. Thanks! Edit: I tried this question for a couple more hours and couldn't solve. A more direct hint would be appreciated.","['lp-spaces', 'orthonormal', 'functional-analysis', 'real-analysis']"
1029034,"$A_1,A_2,A_3$ forms a partition of $\mathbb N_{>0}$ and $a,b,c \in A_i \implies a+b+c \in A_i$ then at-least one of $A_i$ is closed under addition?","If $A_1,A_2,A_3$ forms a partition of $\mathbb N_{>0}$ such that for any $i=1,2,3$ ; $a,b,c \in A_i \implies a+b+c \in A_i$ then is it true that at-least one of $A_i$ is closed under addition ? I can prove the result to be true  for general semigroups when the no. of partitioning set is 2 but in this case the method I applied for the 2 case is not working and I am unable to find a counterexample . Please help","['integers', 'semigroups', 'elementary-set-theory']"
1029045,Verifying $\sec^2x + \tan^2x = (1-\sin^4x)\sec^4x$,"Verify: $$\sec^2x + \tan^2x = (1-\sin^4x)\sec^4x$$ My solution: $$
\begin{align}\sec^2x+\tan^2x&=\frac{1}{\cos^2x}+\frac{\sin^2x}{\cos^2x}\\
&=\frac{1+\sin^2x}{\cos^2x}\\
&=\frac{1+\sin^2x}{\cos^2x}\cdot\frac{1-\sin^2x}{1-\sin^2x}\\
&=\frac{1-\sin^4x}{\cos^2x\cdot\cos^2x}\\
&=\frac{1-\sin^4x}{\cos^4x}\\
&=\frac{1}{\cos^4x}-\frac{\sin^4x}{\cos^4x}\\
&=\sec^4x-\sin^4x\sec^4x\\
&=\sec^4x(1-\sin^4x)\\
\end{align}$$ Is it incorrect to multiply in $1-\sin^2x$ like in the fourth equality?",['trigonometry']
1029063,How find this limit $\lim_{p\to 0^{+}}\left(\int_{a}^{m-p}f(x)dx+\int_{m+p}^{b}f(x)dx\right)$,"Give real numbers $a,b$ such that $0<a<b$ and $m=\dfrac{a+b}{2}<\dfrac{\pi}{4}$,Evaluate
  $$\lim_{p\to 0^{+}}\left(\int_{a}^{m-p}f(x)dx+\int_{m+p}^{b}f(x)dx\right)$$
  where
  $$f(x)=\dfrac{(1+\cos{(2m-2x)})\cos{(a-x)}\cos{(b-x)}}{(1-\sin{(a-x)})(1-\sin{(b-x)})\sin{(2m-2x)}}$$ Now I think follow idea is usefull Idea : since
$$\dfrac{1+\cos{(2m-2x)}}{\sin{(2m-2x)}}=\tan{(m-x)}$$
and
$$\dfrac{\cos{(a-x)}}{1-\sin{(a-x)}}=\tan{\left(\dfrac{\pi}{4}+\dfrac{a-x}{2}\right)}$$
$$\dfrac{\cos{(b-x)}}{1-\sin{(b-x)}}=\tan{\left(\dfrac{\pi}{4}+\dfrac{b-x}{2}\right)}$$.
so
$$f(x)=\tan{(m-x)}\cdot \tan{\left(\dfrac{\pi}{4}+\dfrac{a-x}{2}\right)}\cdot \tan{\left(\dfrac{\pi}{4}+\dfrac{b-x}{2}\right)}$$
since
$$m=\dfrac{a+b}{2}$$
so also have
$$\left(\dfrac{\pi}{4}+\dfrac{a-x}{2}\right)+\left(\dfrac{\pi}{4}+\dfrac{b-x}{2}\right)
=\dfrac{\pi}{2}+\dfrac{a+b}{2}-x=\dfrac{\pi}{2}+(m-x)$$ then I fell I will silve it,But can't it deal this integral. and this problem is interesting This problem is from The College Mathematics Joutnoal Vol.44.No.3 May 2013 problem,and I can't have this journal. can see joutnoal","['integration', 'limits']"
1029073,A cycle in an undirected graph,"A cycle is a simple path of length at least $1$ which begins and ends at the same vertex. In an undirected graph, a cycle must be of length at least $3$. Could you explain me why that stands??","['graph-theory', 'discrete-mathematics']"
1029091,Real affine variety of $d$ orthonormal vectors in $\mathbb R^n$,"I'm interested in the affine variety
$$
V = \left\{ \, A\in \mathbb R^{d\,\times\, n} \, \middle| \, A\,A^T = I \, \right\} \subseteq \mathbb R^{d\, \times\, n},
$$
where $n\ge d$ and $I$ is the $d\times d$ unit matrix. This is the set of real $d\times n$ matrices with orthonormal rows, so another way to look at this is the configuration space of $d$ orthonormal vectors in $\mathbb R^n$. For $n=d$ we have $V=\operatorname{O}(n,\mathbb R)$, so $V$ is not irreducible since it splits in two components where $\det(A)=1$ and $\det(A)=-1$, respectively. I'm guessing that this decomposition is already the decomposition of $V$ into irreducible components for $d=n$, but I'm not sure how to show that or where to look for a reference. For $n>d$ I would guess that $V$ is irreducible, but I don't know how to figure out whether that is true. I'd appreciate it, if anybody could provide insight or references on this problem.","['affine-schemes', 'orthonormal', 'algebraic-geometry', 'reference-request']"
1029094,Pure Point Spectrum implies Spanning Eigenfunctions,"If $H$ is a self-adjoint operator on a Hilbert space $\mathcal{H}$ , and the spectrum of $H$ is a pure point spectrum, i.e., the spectrum consists of discrete eigenvalues (perhaps with multiplicity $>1$ ), I wish to show that the eigenfunctions of $H$ span $\mathcal{H}$ . This seems like it should be simple, but I'm having a brain fart. I tried making some sort of degree argument, but this doesn't seem to work. Some of the books I've looked at even have this as the definition of an operator with pure point spectrum, so I must be missing something.","['operator-theory', 'spectral-theory', 'functional-analysis', 'mathematical-physics']"
1029099,One more question about mapping quaternionic matrices into real matrices,"Real matrices that lie in the image of the inclusion homomorphism $\rho_n: M_n(\mathbb C) \to M_{2n}(\mathbb R)$ are called complex linear real matrices. It is easy to see that a real matrix is complex linear if and only if it commutes with $I = \rho_n(iI)$. In analogy to this I am now studying the quaternionic inclusion $M_n(\mathbb H) \to M_{4n}(\mathbb R)$ using the inclusion $\psi_n: M_n(\mathbb H) \to M_{2n}(\mathbb C)$. If $i,j,k$ denote the unit quaternions then I want to find matrices $I$ and $J$ such that a real matrix is quaternionic linear if and only if it commutes with $I$ and $J$. In $1$ dimension I tried $I=\rho_{2n} \circ \psi_n (iI)$ and $J=\rho_{2n} \circ \psi_n (jI)$ but the problem then is that $I^2 \neq -1$ and $J^2 \neq -1$. Why does $I=\rho_{2n} \circ \psi_n (iI), J=\rho_{2n} \circ \psi_n (jI)$ not work in the quaternionic case? Is there an insightful geometric (or other) explanation? For the inclusion of complex matrices into real matrices setting $J=\rho_{2n} (iI)$ worked. Edit For a definition of $\rho_n$: define $\rho_n : M^n(\mathbb C) \to M^{2n}(\mathbb R)$ as $A_{ij}\mapsto \begin{array}{cc} a_{ij} & b_{ij} \\ -b_{ij} & a_{ij} \end{array}$ if $A_{ij}=(a_{ij} + i b_{ij})$ and $\color{blue}{\psi_n}: M^n(\mathbb H) \to M^{2n}(\mathbb C)$ as $A_{ij}\mapsto \begin{array}{cc} a_{ij} & b_{ij} \\ -\overline{b_{ij}} & \overline{a_{ij}} \end{array}$ if $A_{ij}=(a_{ij} +  b_{ij}j)$ Edit 2 (in response to the anwer) Let $$I = \rho(\color{blue}{\psi(i)})= \rho\left (
\begin{array}{cc} \color{blue}{i} & \color{blue}{0} \\ \color{blue}{0} & \color{blue}{-i} \end{array}\right)$$  Then 
$$ I = \left ( \begin{array}{cccc} 
0 & 1 & 0 & 0 \\ 
-1 & 0 & 0 & 0\\
0 & 0 & 0 & -1 \\
0 & 0 & 1 & 0 \end{array} \right )$$ so that $$  I^2 = -1$$ Edit 3 After the discussion with Incnis Mrsi I calculated $J^2=I^2 =-1$ for $J=\rho_{2}(\psi_1(j))$ and $I=\rho_{2}(\psi_1(i))$. I am confused that this seems to work. The reason why I asked this quetion is the following passage in Tapp's matrix groups for undergraduates : In particular, why is $I\neq\rho_{2n}(\psi_n(i))$ and $J\neq\rho_{2n}(\psi_n(j))$ for
  $n>1$? (for $n=1$, apparently it works as I just verified).","['matrices', 'quaternions', 'lie-groups']"
1029101,"Closed- form of $\int_0^1 \frac{{\text{Li}}_3^2(-x)}{x^2}\,dx$","Is there a possibility to find a closed-form for
 $$\int_0^1 \frac{{\text{Li}}_3^2(-x)}{x^2}\,dx$$","['closed-form', 'calculus', 'integration', 'definite-integrals', 'polylogarithm']"
1029110,Example of Hausdorff and Second Countable Space that is Not Metrizable,Does there exist topological space that is Hausdorff and second countable but not metrizable?,"['general-topology', 'examples-counterexamples']"
1029153,Deriving the normal distance from the origin to the decision surface,"While studying discriminant functions for linear classification, I encountered the following: .. if $\textbf{x}$ is a point on the decision surface, then $y(\textbf{x}) = 0$, and so the normal distance from the origin to the decision surface is given by: $$
\frac{\textbf{w}^T \textbf{x}}{\lvert\lvert \textbf{w} \lvert\lvert} = -\frac{w_0}{\lvert\lvert \textbf{w} \lvert\lvert} \tag 1
$$ Where $\textbf{w}$ is a weight vector, and $w_0$ is a bias. In an attempt to derive the above formula I tried the following: \begin{align*}
& \textbf{w}^T \textbf{x} + w_0 = 0 \tag 2\\
& \textbf{w}^T \textbf{x} = -w_0 \tag 3
\end{align*} After which I am basically stuck. I think that the author gets about from equation $(3)$ to equation $(1)$ by normalising. But isn't calculating the normal (perpendicular) distance quite separate from normalising a vector? Secondly, how does equation $(1)$ translate into the normal distance being $ - \frac{w_0}{\lvert\lvert \textbf{w} \lvert\lvert}$ i.e. How is the quantity $\frac{\textbf{w}^T \textbf{x}}{\lvert\lvert \textbf{w} \lvert\lvert}$ the normal distance ?","['linear-algebra', 'self-learning', 'machine-learning']"
1029170,First derivative of a multivariable function,"This question was featured on my calculus mid-term today : Find the first derivative of $g(x,y)$ where : $$ 
g(x,y) = f(x^2  + y^2 ,xy)
$$ This is the exact text of the problem. I just don't get it. How are we supposed to find the first derivative of a function that has no expression ? Secondly, how cand I find the derivative when we don't know in respect with which variable to differentiate ? Can somebody please explain and show a solution ?","['multivariable-calculus', 'derivatives']"
1029171,"Show that if $h$ is extendable to a continuous map of $\Bbb R^n$ into $Y$, then $h_*$ is the trivial homomorphism.","Let $A$ be a subspace of $\Bbb R^n$; let $h:(A,a_0) \to (Y,y_0)$. Show that if $h$ is extendable to a continuous map of $\Bbb R^n$ into $Y$, then $h_*$ is the trivial homomorphism. I can't get any clue how to deal with it...","['general-topology', 'algebraic-topology']"
1029179,Integration with respect to a signed measure,"Let $\mu$ be a singed measure, $f\in C_c(X)$, I want to show $$\int fd(c\mu) = c \int fd\mu, \forall c \in \mathbb{R}$$ Since $c\mu$ is also a singed measure, I think by definitionm I need to show  $$\int fd(c\mu)^+-\int fd(c\mu)^- = c \int fd\mu^+-c \int fd\mu^-$$ But I think here I can't directly say $d(c\mu)^+=cd\mu^+,d(c\mu)^-=cd\mu^-$, since the definition of $\mu^+,\mu^-$ involves $|\mu|$ and $|c\mu|=|c||\mu|$, hence I need to discuss wether $c<0$ or $c>0$ or $c=0$. For example, $c<0$, then $$(c\mu)^+=\frac{1}{2}(|c\mu|+c\mu)=-c\mu^-$$$$(c\mu)^-=\frac{1}{2}(|c\mu|-c\mu)=-c\mu^+$$
Hence the LHS equals to the RHS since $\int fd(c\lambda) = c \int fd\lambda, \forall c >0$ when $\lambda$ is a measure. Since I am new to this subject, could you help to confirm whether my understanding is correct?","['measure-theory', 'real-analysis']"
1029197,$(2x+y)\frac{dy}{dx} + x = 0$,"Solve:
  $(2x+y)\frac{dy}{dx} + x = 0$ . Only solving seperable equations and use of an integrating factor have been covered so far, and I can't see how to get it into a form such that it is solvable by these methods.",['ordinary-differential-equations']
1029199,How prove this $|z|>1$ with $1+z+\frac{z^2}{2!}+\cdots+\frac{z^n}{n!}=0$,"For give the  postive integer $n$ ,and $z\in C$ such this $$1+z+\dfrac{z^2}{2!}+\cdots+\dfrac{z^n}{n!}=0$$ show that $$|z|> 1$$ maybe we Assmue that exst $z$ such $$|z|\le 1$$ then we have $$z(1+\dfrac{z}{2}+\cdots+\dfrac{z^{n-1}}{n!})=-1$$ so $$|z|\cdot\left|1+\dfrac{z}{2}+\cdots+\dfrac{z^{n-1}}{n!}\right|=1$$ then we have $$\left|\dfrac{z}{2}+\cdots+\dfrac{z^{n-1}}{n!}\right|\ge 1$$ then I can't have idea","['inequality', 'complex-analysis']"
1029220,A Combinatorics question whose solution I can't understand.,"The question is ""For a natural number $n$, let $T(n)$ denote the number of ways we can place $n$ objects of weights $1,2,...,n$ on a balance such that the sum of the weights in each pan is the same. Prove that $T(100) > T(99)$."" Now while I have (one of the many possible) solutions thanks to the fact that the people conducting this test released it, though I do not understand one bit of it. Could someone explain me how to do this question? It's very difficult (for students) as it's part of the Stage I of selection of students from India for the International Mathematics Olympiad. I am so confused even looking at the question!!! The solution which was posted was: (scroll down to the last question) http://olympiads.hbcse.tifr.res.in/uploads/crmo-2013-solutions-2 I apologize in advance if this is too simple to search on the Internet.","['contest-math', 'combinatorics']"
1029228,Understanding connectedness argument in proof of Analytic Fredholm Theorem,"Let $X$ be a complex Banach space, and let $D \subset \mathbb{C}$ be a domain. Let $\mathcal{L}(X)$ denote the Banach space of bounded linear transformations $X \to X$. The Analytic Fredholm Theorem is given as follows: Let $A: D \to \mathcal{L}(X)$ be an operator-valued analytic function such that $A(z)$ is a compact operator for each $z \in D$. Then either: $(I - A(z))^{-1}$ does not exist for any $z \in D$, or $(I - A(z))^{-1}$ exists for all $z \in D \setminus S$, where $S$ is a discrete subset of $D$. This is Theorem 8.26 from Inverse Acoustic and Electromagnetic Scattering Theory by Colton and Kress. To prove this theorem, the authors first establish that, for each $z_0 \in D$, there exists a ball $B_{r_{z_0}}(z_0) \subset D$ within which either 1. or 2. holds. Then, the authors claim that the theorem itself follows by a simple connectedness argument. I am having trouble understanding how the connectedness argument should go. Here's what I have so far. To prove the full theorem, assuming we know the local version, let's assume that 1. does not hold. Then we want to show that $$ W =\{ z \in D | (I- A(z))^{-1} \text{ does not exist}\}$$ is discrete. If we fix $z_0 \in W$, then we know that in $B_{r_{z_0}}(z_0)$, either 1. or 2. holds. If we can rule out 1., we are done. But I'm not sure how to continue from here. I haven't really brought in the connectedness property of $D$, so I think I am missing a substantial step. Hints or solutions are greatly appreciated.","['compact-operators', 'functional-analysis', 'complex-analysis']"
1029248,Example 3.53 in Baby Rudin,"Here's Example 3.53 in the book Principles of Mathematical Analysis by Walter Rudin, third edition. Consider the convergent series $$1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \ldots$$ and one of its rearrangements $$1 + \frac{1}{3} - \frac{1}{2} + \frac{1}{5} + \frac{1}{7} - \frac{1}{4} + \frac{1}{9} + \frac{1}{11} - \frac{1}{6} + \ldots$$ in which two positive terms are always followed by one negative. If $s$ is the sum of the original series, then $$s < 1 - \frac{1}{2} + \frac{1}{3} = \frac{5}{6}.$$ Since $$\frac{1}{4k-3} + \frac{1}{4k-1} - \frac{1}{2k} = \frac{8k-4}{(4k-1)(4k-3)} - \frac{1}{2k} = \frac{2k(8k-4) - (4k-1)(4k-3)}{2k(4k-1)(4k-3)} = \frac{8k-3}{2k(4k-1)(4k-3)} > 0$$ for $k \geq 1$, we see that $$s^\prime_3 < s^\prime_6 < s^\prime_9 < \ldots,$$ where $s^\prime_n$ is the $n$th partial sum of the series after the rearrangement. Hence $$\lim_{n\to\infty}\sup s^\prime_n > s^\prime_3 = \frac{5}{6},$$ so that the rearranged series certainly does not converge to $s$. Now here's my question: How to determine, using the machinery developed by Rudin upto this point in the book, if the new (or rearranged) series converges at all? Rudin leaves it to the reader to check that the new series does converge. How to prove this convergence? I would like to have answers that use only the results that Rudin has discussed so far in the book.","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'analysis']"
1029310,Why is indefinite integral called so?,"Two questions that are greatly lingering on my mind: 1. Integral is all about area(as written in Wolfram). But what about indefinite integral ? What is the integral about it?? Is it measuring area?? Nope. It is the collection of functions the derivative of which give the original function and not measuring area. So, why ""integral""?? And what about the indefinite ??? It is not measuring an infinite area ; just telling about the original functions. So, what is the logic of this name?? Famous statement: Differentiation breaks apart the function infinitesimally to calculate the instantaneous rate of change, while, on the other hand, integration sums up or integrates the infinitesimal changes to measure the whole change or area . Yes, totally correct but in case of definite integrals,where small changes are summed up to give the area. But how is the statement related with indefinite integral ?? Do they sum up small changes??? What is the connection between them??? I am confused. Please help me explaining these two problems.",['calculus']
1029313,What is the limit of the rank of the power of a matrix?,"I am interested in $$\lim_{k \to \infty} \operatorname{rank} \left( \mathbf{A}^k \right)$$ for a $n \times n$ matrix $\mathbf{A}$ . I know that for a nilpotent matrix, $\mathbf{A}^k=0$ when $k$ is big enough, which means $\operatorname{rank} (\mathbf{A}^k) \to 0$ when $k \to \infty$ . for a nonsingular matrix, $\mathbf{A}^k$ is also nonsingular and $\operatorname{rank} \left( \mathbf{A}^k \right)$ is the number of the columns/rows. Is there any general theorem that tells us the result for a general square matrix?","['matrices', 'linear-algebra', 'matrix-rank']"
1029323,"Prove that the normed vector space $(S_F,\|\cdot\|_1)$ is not Banach.",$S_F$ is the space of real sequences $\mathbf a=(a_n)_{n=1}^{\infty}$ such that every sequence $\mathbf a\in S_F$ is eventually zero. $\|\cdot\|_1$ is the norm defined as $\|\mathbf a\|_1=\sum_{n=1}^{\infty}\lvert a_n\rvert$. I know that a Banach space is one where every Cauchy sequence in $S_F$ converges to an element of $S_F$ but I don't know how to prove that a normed vector space is not Banach. Can anyone help?,"['normed-spaces', 'banach-spaces', 'real-analysis', 'analysis']"
1029370,Rolle theorem proof via intermediate value theorem,"I'm wondering if we can use the Intermediate Value Theorem to prove Rolle's Theorem . The hypotheses of Rolle's Theorem are: The function should be continuous on a closed interval $[a,b]$ . The function should be differentiable on the open interval $(a,b)$ . $f(a)=f(b)$ The theorem then shows that there exist $c$ in $(a,b)$ such that $f'(c)=0$ . For I.V.T we need the function to be continuous and $f'(a).f'(b) \leq 0$ . If the conditions for Rolle's Theorem conditions are achieved, does it mean that $f'$ is continuous? For the second condition we have that $$ \frac{f(x)-f(a)}{x-a} .\frac{f(x)-f(b)}{x-b}<0$$ because $$ f(x)-f(a)=f(x)-f(b)$$ and $$ 0<x-a<b-a $$ $$ a-b<x-b<0 $$","['calculus', 'continuity', 'real-analysis', 'rolles-theorem', 'derivatives']"
1029390,"$ \int_0^\infty dx\, x^{-3/4} \ln(1+x) \operatorname{Li}_2 \left( -\frac 1 x \right)$","How to show the following identity from Wolfram ? $$
\int_0^\infty dx\, x^{-3/4} \ln(1+x) \operatorname{Li}_2 \left( -\frac 1 x \right) =-2\pi \sqrt 2\left[\frac{5 \pi^2}{3} + 16 \left(3 \ln 2 + G - 4 \right) \right].
$$
Here $G$ is Catalan's constant. I thought of using $\operatorname{Li}_2(-x) + \operatorname{Li}_2(-1/x) = -\zeta(2) - \frac 1 2 \ln(x)^ 2$, but the result is not much easier.","['definite-integrals', 'polylogarithm', 'integration', 'catalans-constant']"
1029420,explicit (holomorphic) map revealing blow-up as a connected sum with $\overline{\mathbb{CP}}^n$,"I am trying to understand the statement that a blow-up of a complex manifold $M$ at a point $p$ is equivalent to the connected sum of $M$ with $\overline{\mathbb{CP^n}}$ and, being a physicist, I need the explicit map between charts. I have looked at a number of sources, but found Broens' thesis particularly useful. Using this one may construct a transition function from the blow-up of $M$ , $\tilde{M}$ , to $\overline{\mathbb{CP^n}}$ . The problem I have is that it doesn't look very holomorphic. the set-up If $M$ has co-ordinates $z'$ with $z'(p)=0$ , then the blow-up $\tilde{M}$ is given by the set of points $\{ (z', [w]) \in \mathbb{C}^n \times \mathbb{CP^{n-1}} \;|\; z'_iw_j=z'_jw_i\}$ Now define a map $\psi:\overline{\mathbb{CP^n}}\to\tilde{M}$ by $\psi(\overline{Z}_0:Z_1:Z_2…:Z_n)=(Z_0Z/|Z|^2,\;[Z])$ where $Z=(Z_1,Z_2,…Z_n)\neq0$ . The inverse of this map is, I think, $\psi^{-1}(z',[z'])=(|z'|^2:z'_1:z'_2:…z'_n)$ A ball in $\mathbb{CP^n}$ about the point $q$ with co-ordinates $(1:0:0…:0)$ is defined by the set $B_\epsilon=\{ (\overline {Z}_0:Z)\;|\;\;|Z|/|Z_0|\;\leq\;1/\epsilon  \}$ which is then removed to give the set $V_\epsilon$ that will be glued on $V_\epsilon=\{ (\overline {Z}_0:Z)\;|\;\;|Z|/|Z_0|\;>\;1/\epsilon  \}$ the image of which is $\psi(V_\epsilon)=\{ (Z_0Z/|Z|^2,\;[Z])\;|\;\;|Z|/|Z_0|\;>\;1/\epsilon \}$ so if we define the co-ordinates on $M$ to be $z'=Z_0Z/|Z|^2$ we find the set of points $U_\epsilon=\psi(V_\epsilon)=\{  (z',[z'])\;|\;\;|z'|<\epsilon \}$ now make the annulus for the connected sum by constructing $U_\delta$ , $\delta<\epsilon$ , and the corresponding annulus on $V_\epsilon$ . So, given a point on the annulus in $M$ , $z'\in U_\epsilon-U_\delta$ , we get a point $(|z'|^2:z'_1:z'_2:…z'_n)=(1:z'_1/|z'|^2:z'_2/|z'|^2:…z'_n/|z'|^2)$ . on $\overline{\mathbb{CP^n}}$ with inhomogeneous co-ordinates $z'_i/|z|^2$ the problem There's a good chance that I have totally misunderstood something, but if we take $\zeta_i$ to be the inhomogeneous co-ordinates on $\overline{\mathbb{CP^n}}$ , then the above relates the charts of $M$ and $\overline{\mathbb{CP^n}}$ via $\zeta_i=z'_i/|z|^2$ which is not holomorphic. Given that, for example, the del Pezzo surfaces are blow-ups, and also complex manifolds, I would have expected a holomorphic map between charts.","['complex-geometry', 'algebraic-geometry', 'differential-geometry']"
1029429,Only one fixed point for $f:\bar{\mathbb{D}}\rightarrow\bar{\mathbb{D}}$ on the boundary.,"We know for Brouwer theorem that $f$ (continuous bijective function) have a fixed point. My questions are: 1) Is there a function with only one fixed point $x_0\in Int(\bar{\mathbb{D}}) $ (open disk)? 2) Is there a function with only one fixed point $x_0\in \partial(\bar{\mathbb{D}})$? For (1) is true since a rotation by any angle $\theta\not=2k\pi$. But for (2) I can't find $f$, I think that for any function with one fixed point on the boundary always have at least on fixed point in the open disk $\mathbb{D}$. Maybe for the continuity of $\partial f$ (the restricion of $f$ to $\partial \mathbb{D}$). Any ideas or suggestions or maybe a counterexample?","['general-topology', 'fixed-point-theorems', 'differential-topology']"
1029485,Show: $(x+y)^4 \leq 8(x^4 + y^4)$,"I wish to show the following statement: $
\forall x,y \in \mathbb{R}
$ $$
(x+y)^4 \leq 8(x^4 + y^4) 
$$ What is the scope for generalisaion? Edit: Apparently the above inequality can be shown using the Cauchy-Schwarz inequality. Could someone please elaborate,  stating the vectors you are using in the Cauchy-Schwarz inequality: $\ \ \forall \ \ v,w \in V, $ an inner product space, $$|\langle v,w\rangle|^2 \leq \langle v,v \rangle \cdot \langle w,w \rangle$$ where $\langle v,w\rangle$ is an inner product.","['inequality', 'inner-products', 'linear-algebra', 'algebra-precalculus']"
1029495,The measure generated by the Cantor staircase and the intersection of the Cantor set with its translate,"Suppose that $T$ is the shift $\bmod 1$ of the Cantor set by an irrational number $\alpha\in (0,1)$. Consider the measure $\mu$ on the interval $[0,1]$ generated by the Cantor staircase. I'd like to know whether (if it is known) $\mu(T(C)\cap C)=0$.","['ergodic-theory', 'fractals', 'number-theory', 'measure-theory', 'functional-analysis']"
1029506,Evaluating $\int_0^{\infty} \frac{\sqrt{x}}{x^2+2x+5} dx$ using complex analysis,"how do I compute $$\int_0^{\infty} \frac{\sqrt{x}}{x^2+2x+5} dx$$ with complex analysis? I feel like im calculating the residue wrong and I cant get to the answer correctly.
I tried to branch cut the real $0 \rightarrow \infty$ but I feel like im doing it wrong. any help is appriciated. additional information: thank you for the input everyone it is very helpful. i did come down to calculating the integral $$\int_0^{\infty} \frac{\sqrt{x}}{x^2+2x+5} dx = i\pi [Res(f,z_1=-1+2i)+Res(f,z_2=-1-2i)]$$ Then given answer to this question is $\frac{\pi}{2}\sqrt{\frac{\sqrt{5}-1}{2}}$ I was just simply calculating $i\pi [Res(f,z=-1+2i)+Res(f,z=-1-2i)] = i\pi \left(\frac{\sqrt{z_1}}{2z_1+2}+\frac{\sqrt{z_2}}{2z_2+2}\right)$ Solving for $\frac{\pi}{4} \left(\sqrt{-1+2i}-\sqrt{-1-2i}\right)$ I get $\frac{\pi}{2}\sqrt{\frac{-\sqrt{5}-1}{2}}$ and I still dont know what I am doing wrong for that one sign error.","['improper-integrals', 'calculus', 'integration', 'complex-analysis', 'contour-integration']"
1029617,Hard limit: $\lim_{n \to +\infty} \left(\sin\left(2\pi(k!)x\right)\right)^n$,"I've stumbled on a particularly hard limit problem: Evaluate the following limit:
  $$\lim_{n \to +\infty} \left(\sin\left(2\pi(k!)x\right)\right)^n\text{, with $n, k \in \mathbb{N}$ and $x \in \mathbb{R}$}$$
  You will find a sequence $a_k(x)$. Then evaluate the limit
  $$\lim_{k \to +\infty} a_k(x)$$
  finding a function $f(x)$. Side question: does something change if the $2$ inside the sine is dropped? Now, I've already seen something similar to this, but instead of the sine function it had the cosine. That is the Dirichlet function, giving $1$ for the rationals and $0$ otherwise. The problem is that here we have a sine, which is $0$ at multiples of $2\pi$. So my intuition is that the limit is $0$, but that does not make sense with respect to the problem statement!","['sequences-and-series', 'calculus', 'limits']"
1029634,Applying derangement principle to drunken postman problem.,"Two letters need to be delivered to each of n houses. How many ways can a postman deliver two letters to each house such that each house receives at least one incorrect letter? I got stuck and don't now how to progress. Can someone provide hint? 1) $(2n)!/2^n$ is the number of all possible onto functions from our domain of houses to the codomain of letters. 2) Let $A_i$ be property that two delivered letters are correct.
$ |A_1'  	\cup A_2'  	\cup... 	\cup A_n'|=(2n)!/2^n-|A_1  	\cap A_2  	\cap... 	\cap A_n|$
   I tried everything I could come up with but I cannot find $|A_1  	\cap A_2  	\cap... 	\cap A_n|$. I feel like I need to find union first but in order to do that I should find intersection. Really confused. Any hint would be appreciated. Edit: Corrected mistake in the equation.","['discrete-mathematics', 'combinatorics']"
1029640,$\sum_{p \in \mathcal P} \frac1{p\ln p}$ converges or diverges?,"We will denote the set of prime numbers with $\mathcal P$ . We know that the sum $$\sum_{n=1}^{\infty}\frac1n \hspace{3mm} \text{and} \hspace{3mm} \sum_{n=2}^{\infty}\frac1{n\ln n}$$ diverges. It is also known that $$\sum_{p \in \mathcal P} \frac1p$$ also diverges, where the sum runs over the $p$ primes. How could we decide whether $$\sum_{p \in \mathcal P} \frac1{p\ln p}$$ converges or not?","['prime-numbers', 'convergence-divergence', 'sequences-and-series', 'number-theory']"
1029646,Book recommendation for ordinary differential equations,"This question has been posted before, but I need book with specific qualifications. I do not need books for engineers, book that is centered around calculations and stuff. I need to find a book that is theoretical, proves the statements and has good presentation of the theoretical structure. I have had the book by Tenenbaum, I did not like it. I would be very very thankful if someone shared their knowledge with us about this matter.","['ordinary-differential-equations', 'book-recommendation', 'reference-request']"
1029651,How useful is the Weierstrass representation of minimal surfaces?,"Weierstrass representation  of minimal surfaces says that if I have a holomorphic function $f: U \rightarrow \mathbb{C}$ and a meromorphic function $g: U \rightarrow \mathbb{C}$ such that $f g^2$ is holomorphic with $U$ being simply connected, then we have an integral representation of the minimal surface. Now, this means that for $U = B (0,1)$ for example, we have a million possible pairs of homolomorphic functions $f,g$ defined on this set. So this should give us a million different minimal surfaces, is this correct? We cannot control the shape of our surface or the domain its range in $\mathbb{R}^3$, as it is totally arbitrary how $f,g$ can be chosen. The only thing we said is that for a given minimal surface, we can find such a pair $f,g$, but normally you would be interested in the other question: Given some boundary in $\mathbb{R}^3$: How can I find a minimal surface? - This seems to be unanswered. - So I see no point in this Weierstraß representation. Is it important that $U$ is simply connected? Let's consider the following ""stupid"" example $U = \mathbb{C}\backslash \{0\}$ $f=g=1$ . Can I still construct a minimal surface by the Weierstraß representation?","['differential-geometry', 'complex-analysis', 'real-analysis', 'minimal-surfaces']"
1029676,Minimum of $ay+az+bz+bx+cx+cy$ with $ab+bc+ca=xy+yz+zx=1$,"Let $a,b,c,x,y,z\in\mathbb{R}^+$, and $ab+bc+ca=xy+yz+zx=1$. What is the minimum value of $ay+az+bz+bx+cx+cy$? When $a=b=c=x=y=z=\dfrac{1}{\sqrt{3}}$, the desired value is $2$. When $a=b=x=y\rightarrow 1$ and $c=z\rightarrow 0$, the desired value also approaches $2$, so it seems likely that $2$ is the minimum.","['inequality', 'algebra-precalculus']"
1029681,Intuitive understanding of path integral formula,"I have learned a general formula for a path/line integral $$
\int_a^b f\left(\mathbf{r}(t)\right) \|\mathbf{r}'(t)\|\  dt \tag{1}
$$ and I'm trying to better understand it.  Specifically, I'm wondering what's not right about this: $$
\int_a^b f\left(\mathbf{r}(t)\right)\ dt \tag{2}
$$ If I try to work out what's happening in $(2)$, I reason that $f(\mathbf{r}(t))$ is the value of the field $f$ at the point $\mathbf{r}(t)$ for some $t$.  As you vary $t$ from $a$ to $b$, the sum of those values $f(\mathbf{r}(t))$ seems to me like the value of the whole path, i.e. the path integral.  Clearly, there's a gap in my understanding. I do feel that I understand the similar formula for the arc length $s$ for the same path $$
s = \int_a^b \|\mathbf{r}'(t)\|\ dt \tag{3}
$$ from geometry, so I understand extending $(3)$ to $(1)$ by simply including the scalar field $f$.  But, I think knowing what $(2)$ does mean might help me really take things to the next level .","['line-integrals', 'multivariable-calculus', 'intuition']"
1029724,Why is Implicit Differentiation needed for Derivative of $y = \arcsin (2x+1)$?,"my function is: $y = \arcsin (2x+1)$ and I want to find its derivative. My approach was to apply the chain rule: $$y' = \frac{dg}{du} \frac{du}{dx}$$ with $g = \arcsin(u)$ and $u = 2x+1$. $$g' = \frac{1}{\sqrt{1-u^2}}.$$ ${u}' = 2$. My solution therefore was
$$\frac{1}{\sqrt{1-u^2}} \cdot 2 = \frac{2}{\sqrt{1-(2x+1)^2}}.$$ This seems to be wrong and the correct solution is given by: 
$\frac{1}{\sqrt{-x^{2}-x}}$ I know that implicit differentiation should be used for this particular problem, but I do not really understand why. I appreciate any help!","['trigonometry', 'implicit-differentiation', 'derivatives']"
1029751,How can I construct a solution for this system of many inequalities?,"Let there be types $\omega\in\{0,1\}^n$ drawn according to some probability distribution. Suppose that these types are relayed through some imperfect message service. Specifically, any type $\omega$'s message, $m$, is always the product of some garbling so that $m\in\{0,1\}^n$, but $\sum_{i=1}^n m_i = k$. So there are $\binom{n}{k}$ different messages. A type $\omega$ will send message $m$ with probability $p_m^\omega$. I'd like to construct these distributions $p^\omega$ for each $\omega$ so that the message is ""believed"" according to a cost-weighted error. If $\omega_i=1$ and $m_i=0$, then the cost is 1. If $\omega_i=0$ and $m_i=1$, then the cost is $c$. Insofar as we want to minimize error, I think it's obvious that for any type $\omega$ it should send a message where $m_i=\omega_i$ when $\omega_i=1$, but for types where $\sum_{i=1}^n\omega_i>k$, then some ones must be turned off so to speak. Similarly, we have to turn on some false ones for types $\sum_{i=1}^n\omega_i<k$. Then, I think the problem is finding a distribution $p^\omega$ across messages for each $\omega$ so that for any $m$, $$\sum_{\omega\in \{\omega:\sum_i^n\omega_i<k\}} c(k-\sum_i\omega_i )\Pr(\omega)p_m^\omega + \sum_{\omega\in \{\omega:\sum_i^n\omega_i\geq k\}} (\sum_i\omega_i-k)\Pr(\omega)p_m^\omega$$ $$\leq \sum_{\Omega}\Pr(\omega)p_m^\omega(\sum_i\omega_i) .$$ This inequality says that the cost of errors made from believing $\omega_i=m_i$ when $\omega_i=0$ and $m_i=1$ is less than the number of errors made from disregarding the message and believing every $\omega_i=0$.
I think we can always find these $p^\omega$s whenever $\Pr(\sum_i^n\omega_i < k)\leq \frac{1}{c+1}$, but I don't believe this is necessary and I don't see how to actually construct the distributions to guarantee the inequality above. Any help would be appreciated, and let me know if anything is unclear. Example: Let $n=3$, $c=1$, and $\Pr(\omega_i=1)=.4$, i.i.d. Then for $k=2$, we can have $p^{(0,1,1)}_{(0,1,1)}=1$,$p^{(1,0,1)}_{(1,0,1)}=1$, and $p^{(1,1,0)}_{(1,1,0)}=1$. Then for the low types, set $p^{(1,0,0)}_{(1,1,0)}=p^{(1,0,0)}_{(1,0,1)}=1/2$. Similarly, set $p^{(0,1,0)}_{(1,1,0)}=p^{(0,1,0)}_{(0,1,1)}=1/2$ and set $p^{(0,0,1)}_{(0,1,1)}=p^{(0,0,1)}_{(1,0,1)}=1/2$. Finally, let the remaining types, $\omega=(1,1,1)$ and $(0,0,0)$ have $p^\omega_{(0,1,1)}=1$. I think all of the coniditions are met, yet $\Pr(\sum_{i=1}^n\omega<2)=0.648$ is not less than $1/2=\frac{1}{c+1}$.","['linear-algebra', 'coding-theory']"
1029813,Evaluate $\int_0^{\infty} \frac{\log x }{(x-1)\sqrt{x}}dx$ (solution verification),"I tried to find the integral $$I=\int_0^{\infty} \frac{\log x }{(x-1)\sqrt{x}}dx \tag1$$ I substituted $x=t^2, 2tdt=dx$ and chose $\log x$ and $\sqrt{x}$ to be principal values. We have $$\int_0^{\infty} \frac{\log x}{(x-1)\sqrt{x}}dx=2 \int_0^{\infty} \frac{\log t^2}{(t^2-1)}dt \tag2$$ Then because it is an even function $$2 \int_0^{\infty} \frac{\log t^2}{(t^2-1)}dt=2 \int_{-\infty}^{\infty} \frac{\log t}{(t^2-1)}dt \tag3$$ In the complex plane $z=1$ is a removable singularity of this function and $z=-1$ is a pole. So I chose the contour $$\oint_\gamma = \int_{-R}^{-1-r}+ \int_{C_1}+\int_{-1+r}^{R}+\int_{C_2}=0 \tag4$$ where $C_1$ is a semi-circle $z=-1+r e^{i\phi}, \pi \ge \phi \ge 0$ and $C_2$ a semi-circle $z=R e^{i\phi}, 0 \le \phi \le \pi$. In the limit $R\to\infty, r\to 0$ the integral on $C_2$ is $0$ and $\int_{-R}^{-1-r}+\int_{-1+r}^{R}=\int_{-\infty}^{\infty}$ so we need to find $$\lim_{r\to0} \int_{C_1} \frac{\log z}{(z^2-1)}dz = 0 \tag5$$ So $I$ should be zero. But if we compare with this question , we see it isn't. Where is my mistake? EDIT 2: For clarity, I will compile all my corrections as an answer. Thanks to everyone who helped in the comments (and the other answers, too, of course)!","['residue-calculus', 'integration', 'solution-verification', 'complex-analysis', 'contour-integration']"
1029836,Covariance of $Z'Vb$ given that the rows of V are i.i.d.,"Suppose that we have the following entities
$$
\underbrace{Z}_{n\times k},\quad\underbrace{V}_{n\times L},\quad \underbrace{b}_{L\times 1}.
$$
$Z$ and $b$ are nonstochastic whereas we assume that the rows of $V$ are i.i.d. with each having mean $0$ and covariance matrix $\Omega$ (dimension: $L\times L$). I'm trying to justify that the following $k\times 1$ vector
$$
S=Z'Vb
$$
has covariance matrix 
$$
Z'Zb'\Omega b
$$
which has dimension $k\times k$ because the 5 quantities above have dimensions
$$
Z': k\times n;\quad Z: n\times k;\quad b':1\times L;\quad \Omega:L\times L;\quad b:L\times 1.
$$
It's clear that $S$ has zero mean so the covariance matrix is just $E(SS')$. I tried expanding $SS'$ but I couldn't simplify things to produce the expression above. Can someone lend a hand please? Edit : The above result is claimed in passing on page 1030 in Moreira (2003) . Full article is accessible here .","['probability-theory', 'matrices', 'probability']"
1029840,Sampling theorem.,"Let us consider
\begin{equation}
\hat{f}(x)=\sum_{n\in \mathbb Z}\left\langle\hat{f},e^{i n x}\right\rangle_{L^2[-\pi,\pi]} e^{i n x} \ \ \ \ \ \ \ \ (1)
\end{equation}
where $\langle g, h\rangle_{L^2[-\pi,\pi]}=\int_{-\pi}^\pi g(x) \overline{h(x)} dx$. Taking the inverse Fourier transform in (1), we obtain the Whittaker-Kotelnikov-Shannon (WKS) sampling theorem,
\begin{equation}
f(x)=\sum_{n\in \mathbb Z}f(n) \operatorname{sinc}(x-n), \ \ \ x\in \mathbb R
\end{equation}
where $f$ is the inverse Fourier transform of the function $\hat{f}$. I would like to know if there is a version of this theorem for $x\in \mathbb C$.  Are there any good online resources for it? Thanks!","['reference-request', 'fourier-analysis', 'functional-analysis', 'signal-processing']"
1029851,understanding the meaning of formal linear combination and tensor product,"I have a question about understanding the meaning of formal linear combination. Let S be a set, the free vector space $\mathbb{R}\langle s\rangle$ on S is defined as the set of all formal linear combination of elements of S with real coefficients. The formal linear combination is a function F: S$\to$$\mathbb{R}$ such that F(s)=0 for all but finitely many s$\in$S. Identifying every element x$\in$S with the function that takes the value 1 on x and zero on other elements of S, any element F$\in$$\mathbb{R}\langle s\rangle$ can be written uniquely in the form F=$\sum_{i=1}^{m}a_ix_i$, where $x_i$ are the elements of S for which F($x_i$)$\neq$0 and $a_i$=F($x_i$). Here is first question: why we define things like this? why we just say the finite sum of elements in S? My second question is: Since the free vector space can be used to define tensor product of real vector spaces V and W. Then why we use $\mathbb{R}\langle V\times W\rangle$ modding out some equivalence class instead of use the finite sum of elements in the form $v_i\times w_i$ where $v_i\in V$ and $w_i\in W$ modding out that equivalence class? Thanks for any hint!",['differential-geometry']
1029873,Weird function or not,Is $f\colon\emptyset \to\mathbb{R}$ with $f(x) = (-1)^{\frac{1}{2}}$ a function where $\emptyset$ is the empty set and $\mathbb{R}$ is the set of real numbers?,"['elementary-set-theory', 'functions']"
1029958,Applying derangement principle to drunken postman problem.,"Two letters need to be delivered to each of n houses. How many ways can a postman deliver two letters to each house such that each house receives at least one incorrect letter? I got stuck and don't now how to progress. Can someone provide hint? 1) $(2n)!/2^n$ is the number of all possible onto functions from our domain of houses to the codomain of letters. 2) Let $A_i$ be property that two delivered letters are correct.
$ |A_1'  	\cup A_2'  	\cup... 	\cup A_n'|=(2n)!/2^n-|A_1  	\cap A_2  	\cap... 	\cap A_n|$
   I tried everything I could come up with but I cannot find $|A_1  	\cap A_2  	\cap... 	\cap A_n|$. I feel like I need to find union first but in order to do that I should find intersection. Really confused. Any hint would be appreciated. Edit: Corrected mistake in the equation.","['discrete-mathematics', 'combinatorics']"
1029976,Closed-form of prime zeta values,"The prime zeta function is defined as $$P(s)=\sum_{p\,\in\mathrm{\mathcal P}} \frac{1}{p^s},$$ where $\mathcal P$ is the set of prime numbers. It converges for all $\Re(s)>1$. There is a related function defined as $$\int_s^\infty P(t)\,dt = \sum_p \frac{1}{p^s\log p}.$$ Question. Are there any known closed-form value of $P(s)$ or $\int_s^\infty P(t)\,dt$?","['prime-numbers', 'sequences-and-series', 'closed-form', 'calculus']"
1030016,"Show that $A\in\mathbb{C}_n$ is normal $\iff$ $tr(A*A) = \sum_{i = 1}^n|\lambda_i|^2$, where $\lambda_1,...,\lambda_n$ are the eigenvalues of $A$.","Title restated: Show that $A\in\mathbb{C}_n$ is normal $\iff$ $tr(A^*A) = \sum_{i = 1}^n|\lambda_i|^2$, where $\lambda_1,...,\lambda_n$ are the eigenvalues of $A$. This question comes from ""Matrices and Linear Transformations"" by Charles Cullen. I'm studying for an exam and am trying to do some problems but I'm having trouble with this one. Any help would be appreciated. Thank you.","['matrices', 'linear-algebra']"
1030029,Prove $F(F^{-1}(B)) = B$ for onto function,"Suppose that $f:X \to Y$ is an onto function. Prove that for all subsets $B$ subset of $Y$, $f(f^{-1}(B)) = B$. I don't know how to do this if the function is not also one to one, which it is not. Any help proving this would be greatly appreciated.",['elementary-set-theory']
1030041,confidence inteverval $95\%$,"how do I go about finding the $95\%$ confidence interval when I have $n=12, s_x=0.66$ and $u=35.72$ and also how many more samples would I need to reduce the ""length"" of the interval by half? so I looked in the solution and it says: $\left(35.72-2.201\cdot 0.66/\sqrt{12},35.72+2.201\cdot 0.66/\sqrt{12}\right)$, so.. I got really confused about where $2.201$ comes from? is it something they calculated or do they look up stuff like that?",['statistics']
1030089,Finding number of relations on a set with 3 elements,"How do I find find out how many non reflexive relations X on the set P = {1, 2, 3}? I know $2^{n^2 - n}$ returns how many reflexive relations there on a set. Do I subtract that from something to get my result?","['relations', 'elementary-set-theory']"
1030113,Function with $f(x)f(y)=f(xy)$ satisfying intermediate value property,"Find all functions $f:\mathbb{R}\rightarrow\mathbb{R}$ such that $f(xy)=f(x)f(y)$ for all $x,y\in\mathbb{R}$, and $f$ satisfies the intermediate value property. Taking $x=0$, we have $f(0)=f(x)f(0)$. If $f(0)\neq 0$, then $f(x)=1$ for all $x$, which is a solution. Else, $f(0)=0$. Another solution is $f(x)=0$ for all $x$. We have $f(x^2)=f(x)^2$, which means that $f(x)\geq 0$ for $x\geq 0$. It's not clear how to use the intermediate value property.","['functions', 'real-analysis']"
1030122,"Bounded Measurable Functions on [0,1]^2","Suppose $f(x,y),g(x,y)$ are two functions on $[0,1]^2$ that are bounded and measurable, such that:
$$ \int_0^1 f(x,u)g(y,u) du \leq 1 $$
for almost every $(x,y) \in [0,1]^2$. Show that
$$\int_0^1 f(x,u)g(x,u) du \leq 1 $$
holds for almost every $x \in [0,1]$. Apparently there is a way to solve this question using martingales instead of conventional real analysis. But after trying for several hours I cannot seem to pick up on this question. If I can have some kind of general idea or hint to help me on the right track it would be most appreciated.","['probability-theory', 'real-analysis']"
1030145,Combinatorics question about choosing non consecutive integers [duplicate],"This question already has answers here : How many ways can $r$ nonconsecutive integers be chosen from the first $n$ integers? (4 answers) Closed 8 years ago . The problem is as follows: How many ways are there to pick $6$ of the first $20$ positive integers such that no $2$ of them are consecutive? At first glance, this seems like a fairly straightforward combinatorics problem, but after trying it (and failing) I decided it isn't as easy as it looks. My method was to find the number of ways you can choose $6$ integers such that there does exist consecutive integers, then subtract that from the total number of possibilities (${20 \choose  6}$ ) The first thing I did was to take all the possibilities for pairs of consecutive integers (there are $19$ of them, starting $(1,2),(2,3),(3,4),\dots,(19,20)$). There are $\binom{18}{4}$ ways to pick the remaining $4$ integers, hence there are a total of $$19\times \binom{18}{4}=58140$$
possibilites. However, this number is greater than the total number of possibilities (which is $38760$). What am I doing wrong?","['algebra-precalculus', 'combinatorics']"
1030166,An odd function $f$ is differentiable at zero. Prove $f'(0)=0$?,"I know that $f'$ of an even function is odd function, thus I have $f(x)=f(-x)$.
However I'd no idea how to prove that $f'(0)=0$?
Please answer my question...","['calculus', 'derivatives']"
1030171,Infinite direct sum of Hilbert spaces,"Let $\{H_i\}_{i \in I}$ be an infinite collection of Hilbert spaces. I am trying to understand their ""direct sum"" . $\bigoplus H_i$ (algebraic sum) is an inner product space in a straightforward way. It is not, however a Hilbert space .  Let $\overline{\,} : \mathbb{N} \to I$ be an injection, and $\{h_k\}_{k \in \mathbb{N}}$ such that $h_k \in H_{\overline{k}}$. Then the sequence $\sum\limits_{k=1}^n h_k$ is Cauchy, but not convergent when $\sum\limits_{k=1}^\infty \|h_k\|_{H_{\overline{k}}}^2 < \infty$. In fact, I would like to argue that these are the only obstructions to $\bigoplus H_i$ being a Hilbert space. Unfortunately, proving it is beyond me. Let $H \subseteq \prod H_i$ be the subset bounded with respect to the norm $$\|h\| := \sqrt{\sum \|\pi_i(h)\|_{H_i}^2}$$ (The sum is considered infinite if more than countably many $\pi_i(h)$ are non-zero.) I would like to prove that $H$ is an inner product space with the above norm $H$ is complete with respect to the above norm $\bigoplus H_i$ is a dense ""subspace"" of $H$ I'm looking for an accessible reference. I'm currently reading ""Linear Analysis"" by Bollobás, which I find very well-written. He even sets this as an exercise, but with a tone that strongly suggests that $H$ isn't complete:","['reference-request', 'hilbert-spaces', 'functional-analysis', 'direct-sum']"
1030183,One Question about the Fubini's Theorem,"The Fubini's Theorem says: If function $f:X \times Y \rightarrow R$ is integrable over $X \times Y$, then 
$$
\int_{X \times Y}f(x,y)dxdy = \int_{X}dx\int_{Y}f(x,y)dy = \int_{Y}dy\int_{X}f(x,y)dx.
$$ My question is:
If $\int_{X}dx\int_{Y}f(x,y)dy = \int_{Y}dy\int_{X}f(x,y)dx$, could we say $f:X \times Y \rightarrow R$ is integrable over $X \times Y$? If so, I can get: If $\int_{X}dx\int_{Y}f(x,y)dy = \int_{Y}dy\int_{X}f(x,y)dx$, then 
$$
\int_{X \times Y}f(x,y)dxdy = \int_{X}dx\int_{Y}f(x,y)dy = \int_{Y}dy\int_{X}f(x,y)dx.
$$","['multivariable-calculus', 'calculus', 'integration', 'real-analysis']"
1030191,Define $\phi:G/H \rightarrow G/K$ by $\phi(Ha)=Ka$. Prove: $\phi$ is a well defined function.,"Let $H$ and $K$ be normal subgroups of a group $G$ , with $H \subseteq K$ . Define $\phi:G/H \rightarrow G/K$ by $\phi(Ha)=Ka$ . Prove: $\phi$ is a well defined function. [That is, if $Ha=Hb$ , then $\phi(Ha)=\phi(Hb)$ .] Question: To show a function is well defined, do we show that if $x=y$ then $f(x)=f(y)$ ?  Isn't this the same as an injective function? Since $\phi(Ha)=Ka$ , if $Ha=Hb$ , then $Ka=Kb$ .  Is this what well defined is? I am not sure what this says.","['abstract-algebra', 'proof-writing', 'proof-verification', 'functions']"
1030200,Why is it hard to prove Jordan Curve Theorem in the case of Koch snowflake,Many books and papers mentioned that it is easier to prove Jordan Curve Theorem in the case of polygon and hard in the case of badly behaving curves. One example that most give is Koch snowflake. My question is specifically about Koch snowflake. Why is it hard to see and prove that the Koch snowflake divides the plane into 2 parts? Why can't we treat it as polygon and show Jordan Curve Theorem in a similar way?,['general-topology']
