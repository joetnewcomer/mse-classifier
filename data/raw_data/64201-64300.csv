question_id,title,body,tags
743442,Line integral with Stokes,"Let $C$ be curve $(x-1)^2 + (y-2)^2 =4$ and $z=4$ orientated counterclockwise when viewed from high on the z-axis. Let
$$\mathbf{F}(x,y,z)=(z^2 +y^2 +\sin x^2)\mathbf{i}+(2xy+xz)\mathbf{j}+(xz+2yz)\mathbf{k} $$
Evaluate $\oint_C \mathbf{F}\bullet d\mathbf{r}$ My work: Normal $\mathbf{\hat{N}}$ is $\mathbf{k}$, $dS=dA$ and the projection to $xy$-plane is a circle with area of $4\pi$ and curl $\mathbf{F}=(2z-x)\mathbf{i}+z\mathbf{j}+\mathbf{k} $. By Stokes theorem,
$$\begin{align} \oint_C \mathbf{F}\bullet d\mathbf{r}&=\iint_S ((2z-x)\mathbf{i}+z\mathbf{j}+z\mathbf{k})\bullet\mathbf{k}\; dA \\
&=\int_0^{2\pi}\int_0^2 z r \;drd\phi,\; \text{$z=4$ on $S$ } \\
&=4\times4\pi=16\pi\end{align}$$
Does my work seem correct? Im not that sure if the fact that the circle is not origo centered changes something.","['multivariable-calculus', 'vector-analysis']"
743471,Maximal Hamming distance,"Here is a combinatorial problem: let $\Sigma=\{\alpha_1,\ldots,\alpha_n\}$ be an alphabet and we consider any words over $\Sigma$ of length $n$. We also define over the set of such words the Hamming distance: $$d(\omega,\omega')=\#\{i\in \{1,\ldots,n\} \vert a_i\neq b_i\}$$ where $\omega=a_1\ldots a_{n}$ and $\omega'=b_1\ldots b_n$ are two words. The questions are the following: Let $\omega_0$ be the word built with only one letter: $$\omega_0=\underbrace{\alpha\ldots \alpha}_{n \text{ times}}$$ what is the cardinality of a biggest set $\Omega(\omega_0)$ of words of length $n$ containing $\omega_0$ and such that $\forall \omega,\omega'\in \Omega(\omega_0), \ d(\omega,\omega')=n-1$ ? What if we ask the same question for words of length $n+1$ where $\omega_0=\underbrace{\alpha\ldots \alpha}_{n+1 \text{ times}}$ and $\Omega(\omega_0)$ is a maximal set of words of length $n+1$ containing $\omega_0$ such that $\forall \omega,\omega'\in \Omega(\omega_0), \ d(\omega,\omega')=n-1$? It seems that the result is the same and depends only on the cardinality of the alphabet but I don't know how to prove it neatly. Any ideas?","['coding-theory', 'discrete-mathematics', 'combinatorics-on-words', 'combinatorics']"
743475,Do rational functions separate points?,"Let $X$ be an irreducible, normal variety over an algebraically closed field of characteristic zero. Let $x,y\in X$ be two points such that $f(x)=f(y)$ for every $f\in K(X)$ which is defined at $x$ and at $y$. Can I conclude that $x=y$? I feel the answer should be affirmative. In fact, the statement can be reduced to the following: Given two effective prime divisors $D_x$ and $D_y$ on $X$, there exists a rational function $f\in K(X)$ with $v_{D_x}(f)\ne 0$ and $v_{D_y}(f)=0$. If this is true, then assuming $x\ne y$ we could find a divisor $D_x$ containing $x$ but not $y$ and a divisor $D_y$ containing $y$ but not $x$, so a function $f$ as above would yield a contradiction. However, I just can't prove the statement, even though I also think it should be true.",['algebraic-geometry']
743477,Existence of $A^2B - BA^2 = 2A \textrm{ and } AB^2 - B^2A = 2B$. in $\mathcal{M}_n({\mathbb{C}}) $,"This question arose in this classical exercise : Do there exist two matrices such that $AB-BA=I_n$ in $\mathcal{M}_n({\mathbb{C}}) $. Wich is impossible (by using trace to prove this) But if $AB-BA=I_n$ then $A^2B - BA^2 = 2A \textrm{ and } AB^2 - B^2A = 2B$. So my question is : Do there exist  $A$ and $B$ (non-zero) in $\mathcal{M}_n({\mathbb{C}})$ such that : 
  $$
\textrm{(1) } A^2B - BA^2 = 2A 
$$
  $$
\textrm{(2) } AB^2 - B^2A = 2B
$$ For $n=2$ it's impossible (by putting $A^2$ for example).
By induction, we could conclude, if all matrices of rank one switch with matrices with zero trace. Unfortunately, this is not the case. Any ideas to prove it's impossible ? Thank you.","['matrices', 'linear-algebra']"
743504,Show that $c_1(L\otimes E) = rc_1(L) + c_1(E)$ if $E$ is a vector bundle of rank $r$ and $L$ is a line bundle,"Let $L$ be a line bundle and $E$ a vector bundle of rank $r$, then how can we prove that $$c_1(L\otimes E)=rc_1(L)+c_1(E)?$$ Here $c_1$ means the first Chern class.","['characteristic-classes', 'algebraic-geometry']"
743511,What is $\cos(k \pi)$?,I want to ask question for which I have been finding answer for. Please could anyone explain me why $\cos(k \pi) = (-1)^k$ and also explain me same for $\sin(k \pi)$?,['trigonometry']
743535,Formula for nth derivative of $\arcsin^k(x/2)$,"I need to find formula for $n$-th derivative of $\arcsin^k(\frac{x}{2})$. I have found formula for $$\left(\arcsin\frac{x}{2}\right)^{(n)}=\frac{(-i)^{n-1}(n-1)!}{\left(4-z^2\right)^{n/2}}P_{n-1}\left(\frac{i z}{\sqrt{4-z^2}}\right)$$ Where $P_n$ - Legendre polynomial. I have found on the net formula for $n$-th derivative of composite function, however it didn't help.
How can I find required formula?","['trigonometry', 'derivatives']"
743566,"Suppose $A=\langle a,b\mid ab^2a^{-1}b^{-3},ba^2b^{-1}a^{-3}\rangle.$ Show that $A \cong \{1\}$.","Suppose $A=\langle a,b\mid ab^2a^{-1}b^{-3},ba^2b^{-1}a^{-3}\rangle$, where $\langle a_1,\ldots, a_n \mid R\rangle$ is the group generated by $a_1,\ldots, a_n$ with relations in $R$. Show that $A \cong \{1\}$. After carrying out some algebras, I obtain $ab^2=b^3a$ and $ba^2=a^3b$. From here I don't know how to proceed. Can anyone give some hints?","['group-presentation', 'group-theory', 'abstract-algebra']"
743601,First 10-digit prime in consecutive digits of e,"Problem. What is the first $10$-digit prime in consecutive digits of $e$. For those of you who don't know, in 2004 the answer produced a URL to a Google employment page (sort of). I just found about this problem in a book I was reading, I quote from that book.
""The Prime Number Theorem says that among 10-digit numbers, about $1$ in $\ln10^{10}$ is a prime. This suggests that the problem isn't really so hard! Sure enough, the first 10-digit prime in consecutive digits of $e$ appears quite early."" I understand why among 10-digit numbers about $1$ in $\ln10^{10}$ is a prime. But I don't understand why this suggests that the problem is not so hard?","['prime-numbers', 'number-theory']"
743609,Upper Unitriangular Matrices,Let $U$ be the group of the upper unitriangular matrices $n$-$n$ over the field of rationals $\mathbb{Q}$. I know that $U$ is nilpotent and torsion-free. It is also radicable? How it can be proved in an elementary way? Deifnition A gorup $G$ is said to be a radicable group iff every element of $G$ has an $n$th root in $G$ for all positive numbers $n$.,"['matrices', 'group-theory', 'abstract-algebra']"
743627,Fixed points of the torus action on $\textrm{Hilb}_n(\mathbb C^2;d)$,"On the affine plane $\mathbb C^2$ we have the action of the torus $T=(\mathbb C^\times)^2$ given by rescaling: $$(t_1,t_2)\cdot (a,b)=(t_1a,t_2b)\in\mathbb C^2.$$
This action extends to the Hilbert scheme $\textrm{Hilb}_n(\mathbb C^2;d)$ consisting of ideals $I\subset \mathbb C[x,y]$ such that, for $k>>0$, one has $\textrm{codim}\,I_{k}=dk+n$. Here, the codimension of $I_k$ is the number of linearly independent polynomials in the vector space $I\cap \mathbb C[x,y]_k$. Just to be concrete: if $d=0$, we are dealing with $\textrm{Hilb}^n(\mathbb C^2)$. I would like to understand the statement asserting that $T$-fixed
  ideals are exactly monomial ideals (i.e. ideals spanned by monomials). A crucial step seems to be the following assertion: Monomials $x^iy^j$ are eigenvectors of the torus action with distinct
  eigenvalues. Could anyone please explain to me the latter sentence (which I cannot make sense of), and its relation with $T$-fixed ideals? Thank you very much.",['algebraic-geometry']
743694,"Any good, undergraduate level introductions to Functional Analysis?","In my lower division math classes, my instructors referenced functional analysis as essentially the extension of linear algebra to infinite dimensional vector spaces along with some real analysis. As an undergrad who feels like at times he knows more about math then the actual rigor and computation involved, are there any good recommendations to an introductory functional analysis book that give a reasonable treatment as well as show some connections it may have to other fields of math?","['reference-request', 'self-learning', 'functional-analysis', 'analysis']"
743713,"Prove that $\exists x_0 \in D$ such that $f(x_0) = (0,0)$","Here's the question (from last quarter's final): Define $D$ to be the closed unit disk, that is $D = \{(x_1,x_2):x_1^2 + x_2^2 \leq 1\}$. Let $f:D \to \mathbb{R}^2$ be a $C^1$ mapping.  If $f'(x)$ is invertible for all $x \in D$ and
  $$
|f(x) - x| \leq \frac 13, \quad x \in D
$$
  prove that there exists a point $x_0 \in D$ such that $f(x_0) = (0,0)$. Thoughts so far: clearly, the inverse function theorem applies, so that $f^{-1}$ can be defined in the neighborhood of any point.  Furthermore, the inequality applies so that
$$
|x - f^{-1}(x)| \leq \frac 13, \quad x \in f(D) 
$$
I'm not sure how any of this would allow me to show that $0 \in f(D)$, so I'm pretty much stuck for now. Any input, be it a gentle nudge or full solution, would be very much appreciated. EDIT: As copper.hat points out, the Brouwer fixed-point theorem makes quick work of this problem.  However, I am still looking for a solution ""in the spirit of the question"", hopefully one that uses the existence of an inverse in  the neighborhood of each point.","['multivariable-calculus', 'real-analysis']"
743719,Help in Measuring Error on Estimates of Differential Equations,"I am working on a project for class where I have to estimate the solutions to a damped harmonic oscillator ($x''+2 \gamma x'+ \omega^2 x=0$) and compare three methods for doing so (Third Order Runge-Kutta, Conformal Explicit Leap-Frog, Conformal Implicit Midpoint) Part of this is comparing what error looks like at each step (using the easily obtainable exact solution) but I am having trouble coming up with a way to measure error. Normally there is always the fallback on real error, but this is the first project I've done where the solution has a possibility of being 0 (such that real error would explode when the solution is near zero) so that is not a possibility. Absolute error doesn't help either since the solution is going to 0, the graph of error looks like the dampened harmonic graph itself. So I am wondering what might be a good way to calculate error? I am working in MATLAB and have been given the code for all 3 methods so I am confident they work. I know that Runge-Kutta should be better than the other two in shorter intervals, but the other two are better in the long run. Thanks for any help","['error-propagation', 'ordinary-differential-equations']"
743786,Examples of partial functions in which the domain is not known?,"I was reading this , it mentions about a kind of function in which the exact domain is not known. The only example given is this one - and I'm not really sure I understood it. I got curious about it: What are examples of these functions? (beyond the one I suggested as an example) What would be needed to know their exact domain ? I got curious about it because I'm an undergraduate student, every function I've seen had a known domain. The idea of not having a domain is completely alien to me. Notice that It's notvery clear what exact domain is, I have in mind only the discrepancy of domain/image.","['computability', 'computer-science', 'functions']"
743819,"Green balls and Red balls, probability problem","I'm studying for my exam and I came across the following draw without replacement  problem : $N$ boxes filled with red and green balls.
The box $r$ contains $r-1$ red balls and $N-r$ green balls.
We pick a box at random and we take $2$ random balls inside it, without putting them  back. 1) What is the probability that the second ball is green ? 2) What is a probability that the second ball is green, knowing the first one is green. I don't know where to start, all those dependance (to $r$ and $N$ ) are blowing my mind. I don't know if I should concider it as a Binomial law (with Bernoulli : ball = green, $n=2, p = ?$ ) or go with the formula $$p(X=k)=\frac{C_{m}^{k} C_{N-m}^{n-k}}{C_{N}^{n}}$$ or something else... Could someone advise me ?","['statistics', 'probability', 'combinatorics']"
743823,if $f(mn)+f(m+n-1)=f(m)f(n)$How find $f(n)$,"let $f:N^{+}\to Z$,and $f$ is  monotonic nondecreasing,and such
  $$f(m)f(n)=f(mn)+f(m+n-1),f(4)=5$$
  Find all $f(n)$ My try: let $$m=2,n=2\Longrightarrow f^2(2)=f(4)+f(3)$$
$$m=1.n=4,f(1)f(4)=f(4)+f(4)\Longrightarrow f(1)=2$$
$$m=2,n=1,f(2)f(1)=f(2)+f(2)\Longrightarrow f(1)=2$$
$$n=1,m=m\Longrightarrow f(m)f(1)=f(m)+f(m)\Longrightarrow f(1)=2$$
$$m=2,n=3,f(2)f(3)=f(6)+f(4)$$
I can't find $f(2)$, since $$2=f(1)\le f(2)\le f(3)\le f(4)=5$$,then we must
$$f(2)=3,f(3)=4$$.
but for $n\ge 6$,I can't find it. and I found  $$f(n)=n+1$$ is such it.because
$$f(m)f(n)=(m+1)(n+1)=(mn+1)+m+n=f(mn)+f(m+n-1)$$ But I can't  prove it. Thank you","['functions', 'functional-equations']"
743844,Generators of Special Linear Groups,"Linear algebra and special-linear group experts please help: I learn that in principle one can generate this $M$ matrix form the $B_1$ and $B_2$ matrix below. Here
$$
M=\begin{pmatrix} 0& 1& 0\\ -1& 1& 0\\ 0& 0& 1 \end{pmatrix}
$$
from:
$$
B_1=\begin{pmatrix} 0& 0& 1\\ 1& 0& 0\\ 0& 1& 0 \end{pmatrix},
\text{ 
and   }\;\; 
B_2=\begin{pmatrix} 1& 1& 0\\ 0& 1& 0\\ 0& 0& 1 \end{pmatrix}.
$$ Question: How to generate $M$ from $B_1$ and $B_2$? i.e. So what is the exact expression to make $M=\dots B_1 \dots B_2$ as a product of $B_1$ and $B_2$ matrices? I learned the basics about those generators and SL(N,Z) from the book Coxeter and Moser on "" Generators and relations for discrete groups "" (published by Springer, 1957). Thank you! :o)","['integer-lattices', 'discrete-mathematics', 'abstract-algebra', 'linear-algebra', 'group-theory']"
743851,"Are there differences between total functions, epimorphic functions and surjective functions?","I've read three definitions which seems to point to the same idea. I've read about epimorphic functions in Mazzola's Comprehensive Mathematics for Computer Scientists - in this book, he treats it as if they were surjective functions. I guess that this idea is employed in category theory (with more generality, I guess). In functions, it seems that the idea is about relations of sets, in category theory, these ideas seems to be employed in objects different of sets. Is that correct? Today I was reading Boolos' Logic and Computability , they mention the total functions, which by definition seems also to be the same of surjectivity. But I guess it may be used in some general way for the purposes of computer science, I'm still not sure about it. I've seen it on an exercise in the book (see below) and they use both terms: total function and surjectivity - This confuses me a little, presuming they are the same, why use both names Can you show me what are the differences of these three?","['category-theory', 'computer-science', 'functions']"
743857,If $B$ is a maximal linearly independent set in $V$ then $B$ is a basis for $V$,"How can you show that if $B$ is a maximal linearly independent set of $V$, then this implies that $B$ is a basis of $V$?",['linear-algebra']
743894,"Conjugation Quandles and... ""Quandle-Groups""? From quandles to Groups.","A quandle $(Q,*,/ )$ is a idempotent right-distributive and right invertible structure. 1) $a*a=a$ 2) $(a*b)*c=(a*c)*(b*c)$ 3) $(a*b) /b=(a/b)*b=a$ If we have a group $(G, \cdot, e,^{-1})$ and $*$ is the cojugation operation on $G$ $$a*b:=bab^{-1}$$ and $$a/b:=a*b^{-1}$$ then $(G,*,/)$ is denoted with $Conj(G)$ and is a quandle because it satisfies the quandles axioms 1) $a*a=a=aaa^{-1}$ 2) $(a*b)*c=(a*c)*(b*c)$ because $c(bab^{-1})c^{-1}=(cbc^{-1})cac^{-1}(cb^{-1}c^{-1})=cbab^{-1}c^{-1}$ 3) $(a*b) *b^{-1}=(a*b^{-1})*b=a$ because $b^{-1}(bab^{-1})b=b(b^{-1}ab)b^{-1}=a$ I read that we have too that a group homomorphism between two groups $G$ and $G'$ is a quandle homomorphism between theire cojugation quandles $Conj(G)$ and $Conj(G')$ and that makes $Conj$ a functor betwen the category of Groups and the category of quandles... I wanted to know more about this functor $Conj$ that ""maps"" Groups to Quandles and since I'm not expert of category theory I apologize if I use a wrong terminology $Q1a$ - I learnt that not every Quandle is a conjugation Quandle or in
  other words $conj$ is not """"surjective"""" on the ""set"" of all quandles
  (that is not a set but a class i think) so how can I prove that a
  Quandle is a Conjugation Quandle too? $Q1b$ -Wich extra ""axioms"" must hold in a Quandle that is a
  Conjugation Quandle? This has something to do with the inverse construction of $Conj$ so my next question is $Q2$ - There is a way to define a group operation starting with a
  quandle operation? Like an inverse $Conj$ construction that build a ""Quandle-Group"" $Conj^{-1}(Q)$ from a conjugation quandle $Q$. $Q3$ Is this process unique? With unique I mean is is possible to have two different groups $G=(G,\cdot,\phi)$ and $G'=(G,\circ,\varphi)$ and $$Conj (G)= Conj(G')$$ this should mean that is possible to have $$b\cdot a\cdot \phi(b)=b \circ a \circ \varphi(b)$$ where $\phi(b)$and $\varphi(b)$ are the inverse functions and $$a \cdot b \neq a \circ b$$ $Q4$ My last question is if possible to generalize the conjugation
  operation of groups for monoids and semigruops in a way that these
  ""Monoid-conjugations"" and ""Semigroup-conjugations"" are quandles. If is possible I would like to read more about. I've asked this question on MathOverflow here: From quandles to groups","['knot-theory', 'reference-request', 'group-theory', 'abstract-algebra']"
743905,Is $|x-y|^n\leq 2^n(|x|^n+|y|^n)$?,"Is $$|x-y|^n\leq 2^n(|x|^n+|y|^n)$$ for all $x,y\in\mathbb{R}$ and $n=1,2,3,\dots$ a standard inequality? If so, what's its name or how do you prove it?","['algebra-precalculus', 'real-analysis']"
743941,Bigger infinity than real number infinity [duplicate],This question already has answers here : What infinity is greater than the continuum? Show with an example (5 answers) Closed 10 years ago . Is there a bigger infinity than the infinity of cardinality of the real numbers $R$ ? i.e. is there a set to which real numbers can't be mapped one-one to ?,"['cardinals', 'elementary-set-theory']"
743947,How can I prove this trigonometric statement true?,"$$
{1+\sin^{2}\left(x\right) \over \cos^{2}\left(x\right)} = 1 + 2\tan^{2}\left(x\right)$$ This statement is part of a larger problem, but I need to prove that this is true before moving on. I'm assuming that I would first need to prove
$1 + \sin^{2}\left(x\right) = 2\sin^{2}\left(x\right) + \cos^{2}\left(x\right)$, but I'm not sure how to prove that. Any help would be greatly appreciated !.","['trigonometry', 'calculus', 'algebra-precalculus']"
743985,When does a field extension canonically determine a morphism of schemes?,"If I have an extension $L/K$ of number fields, then I can take the inclusion $\mathcal{O}_K \hookrightarrow \mathcal{O}_L$ and get a morphism of ""curves"" $\operatorname{Spec} \mathcal{O}_L \to \operatorname{Spec} \mathcal{O}_K$. Can I do something like this for an arbitrary field extension?  Or at least for a tower $F \subseteq K \subseteq L$ with $\operatorname{trdeg}_F K = \operatorname{trdeg}_F L$?",['algebraic-geometry']
743988,Why does exponentiating the derivative yield the shift operator?,"If we formally exponentiate the derivative operator $\frac{d}{dx}$ on $\mathbb{R}$, we get $$e^\frac{d}{dx} = I+\frac{d}{dx}+\frac{1}{2!}\frac{d^2}{dx^2}+\frac{1}{3!}\frac{d^3}{dx^3}+ \cdots$$ Applying this operator to a real analytic function, we have $$\begin{align*}e^\frac{d}{dx} f(x) &=  f(x)+f'(x)+\frac{1}{2!}f''(x)+\cdots\\
&=f(x)+f'(x)((x+1)-x)+\frac{1}{2!}f''(x)((x+1)-x)^2+\cdots\\
&=f(x+1)
\end{align*}$$ Does anyone have an explanation of why this should ""morally"" be true?  I do not have a very good intuition for the matrix exponential which is probably holding me back here...","['lie-algebras', 'calculus', 'operator-theory', 'operator-algebras', 'lie-groups']"
744022,Weird definition of Kodaira-Spencer map (What's a relative Kähler differential on a manifold?),"When I was reading ""Advances in Moduli Theory"" by Shimizu Yuji , I´ve found a weird way of writing the Kodaira-Spencer map $\rho$ . For a given analytic family of complex compact manifolds $\pi :\mathcal{V} \twoheadrightarrow \mathcal{W} $ , the author uses the notation $$\rho : \Theta_\mathcal{W} \longrightarrow R^1 \pi_* \Theta_{\mathcal{V/W}}$$ for the Kodaira-Spencer map given in each fiber by $\rho_w : \Theta_w \longrightarrow H^1(V_w,\Theta_{\mathcal{V_w}})$ , such that $\Theta$ is the sheaf of holomorphic tangent vector fields. However what´s $\Theta_\mathcal{V/W}$ in the context of manifolds????!!!! In scheme theory, $\Theta_{X/Y} = Hom_{\mathcal{O}_X} (\Omega^1_{X/Y}, \mathcal{O}_X)$ , however for manifolds what´s the correct definition of relative differentials? Is it possible to define $\Omega^1_{X/Y}$ for manifolds as people do for schemes?? Trying the analogous approach for some $f: X \rightarrow Y$ would lead in considering the map $\Delta_{X/Y}: X \longrightarrow X \times_Y X$ and, then pulling back the cotangent space $T^{*}(\Delta_{X/Y} (X))$ . Apparently the action of pulling back and picking the dual commutes (I think so, but maybe it's wrong), so it would be enough to test if $\Delta_{X/Y}^* (T(\Delta_{X/Y})) \cong TX /Ker(f_*)$ , however for a proper surjective submersion $f$ (as in the original case $\pi$ ) it looks like that $\Delta_{X/Y}^* (T(\Delta_{X/Y})) \cong TX$ (when drawing some ""sketches"", considering that $f$ is a locally trivial fibration). Thanks in advance.","['algebraic-geometry', 'complex-analysis', 'moduli-space']"
744029,A system of nonlinear differential equations,"We have the following system in $\mathbb{R}^{2}$ $$\dot{y}_1=2-y_1y_2-y_2^2$$ $$\dot{y}_2=2-y_1^2-y_1y_2$$ i) Calculate the equilibrium points en determine their stability. ii) Draw the Phase Plot. I know that I have to use the following to calculate the equilibrium points: $$\dot{y}_1=0 , \dot{y}_2=0$$ That's all I know. So my question is how do I solve these equations, how do I determine the stability of the equilibrium points and how do I draw the phase plot of this system. An other question I have is what kind of solution you will get, I'm not able to understand what this system represents. So I would like to know how I should interpret such a system like this. Are we looking for something like $f(y_1,y_2)$ or do you need to find $y_1$ and $y_2$. And if so what would the solution mean?","['dynamical-systems', 'ordinary-differential-equations', 'systems-of-equations']"
744037,Is a non-empty set a partition of itself?,"I have a homework assignment where, given some definitions, I need to prove that every set has a partition. There were some very elaborate ideas on how to prove this, but I realized that the definitions we were given allow a set to be a partition of itself. And if that is the case, then there clearly exists a partition of every set. I'm not sure if I'm taking advantage of the simplicity of the definitions we are given. I tried to search if a set is a partition of itself, and not much if anything came up. The claim ""every set is a partition of itself"" seems to violate our english definition of partition, but be consistent with the mathematical definitions I have found. For the sake of this discussion, I would think it be best to only consider non-empty sets because there seems to be some variety in how partitions are defined that prohibit the empty set from having partitions.",['elementary-set-theory']
744048,A Baire category question,"Let ${f_n}$ be a sequence of real valued continuous functions converging pointwise on $\Bbb R$. Show that there exists a number $M>0$ and an interval $I \subset \Bbb R$ such that $\sup\{ |f_n(x)|:x \in I \} \le M$ for all $n$. The idea here is to use the uniform boundedness principle or Baire category theorem, it's just a little unclear for me the best one to use, and the best way to apply it. I tried looking at the proof of the uniform boundedness principle, but for that, you need a Banach space $X$ and a normed linear space $Y$. I assume $Y$ is the real numbers, but what would I choose for $X$? Continuous functions on $\mathbb R$ under some norm making it complete?","['measure-theory', 'baire-category', 'real-analysis']"
744094,Why $\log xy=\log x+\log y$?,"It is of course well known and basic formula. I am just curious. Is there a proof for it?
How to prove that $\log xy=\log x+\log y$?","['calculus', 'real-analysis', 'analysis']"
744099,Proof of the Catalan number formula using Dyck walks,"In our notes we were given the formula $$C(n)=\frac{1}{n+1}\binom{2n}{n}$$ It was proved by counting the number of paths above the line $y=0$ from $(0,0)$ to $(2n,0)$ using $n(1,1)$ up arrows and $n(1,-1)$ down arrows. The notes are a bit unclear and I'm wondering if somebody could clarify for me. There is talk of reflections over the line $y=-1$ and how there are $\binom{2n}{n+1}$ paths from $(0,-2)$ to $(2n,0)$, but I can't see why this is. There is a similar proof on wikipedia but I'm more interested in this specific method.","['catalan-numbers', 'discrete-mathematics', 'combinatorics']"
744107,A Question about Non-Conservative Vector Fields,"In my multivariable calculus class, we spent some time discussing the vector field that was the gradient of arctan(y/x). This field was shown to be non-conservative in closed regions which enclosed the origin. Our instructor also hinted at the idea that any non-conservative vector field could be described as the sum of a conservative gradient field and a multiple of (-y,x)/(x^2+y^2), which is the gradient of the function mentioned above. This idea reminded me of algebra, where, in a linear map, the image of any set and the image of sums of members of the set and the kernel are identical. My question now is, is there any sort of relationship between these two notions of kernel in an algebraic structure and conservative vector fields? Furthermore, does it make sense to talk about the dimension of the gradient operator, as a sort of local linear map, in this context?","['multivariable-calculus', 'linear-algebra', 'vector-fields', 'complex-analysis']"
744158,Maclaurin Series for a natural logarithm,"Can anyone please help me with this question? Find the Maclaurin series and the interval of convergence for $f(x) = \ln(1-7x^9)$ I thought the answer was $$\sum_{n=1}^{\infty} (-1)^n \frac{7x^{9n}}{n} $$ but it seems that my homework assignment website will not accept that answer. I also am not sure how to find the interval of convergence. I know that $\ln|1-x|$ converges for $|x| < 1$, but I cannot figure out the interval of convergence for my current problem. Any help or insight is greatly appreciated! :)","['sequences-and-series', 'calculus', 'taylor-expansion']"
744162,Locate a point a given distance from another point on an ellipse,"Similar to Point on circumference a given distance from another point , but for an ellipse. Unfortunately, the difference is non-trivial. I have an ellipse and a point (C) that is somewhere on the ellipse. I would like to determine the location of some other point on the ellipse away from that point, in one direction (A) or the other (B) by a given straight-line distance (r). This is apparently equivalent to finding the intersections between the ellipse and a circle C with radius r. In the following, please consider a ""point"" to mean ""the Cartesian coordinates of a point"". Known: An ellipse defined in terms of center point C e and radius lengths r x , r y A point C on the ellipse (or, equivalently, the angle of the ray from C e through C) A distance r (r > 0) The direction of rotation, either clockwise or counterclockwise Unknown: A point on the ellipse in the given direction from C that is also a distance of r from C along a straight line (or, equivalently, the angle of the ray from C e to said point); specifically, A, if the direction of rotation is counterclockwise . Update: If there are multiple candidates for A, the candidate whose segment aligns most closely with the ellipse is selected. (If I'm not mistaken, an A candidate can be said to align more closely with the ellipse if the area between the segment and the counterclockwise arc it crosses, starting at C, is smaller than that of another candidate. There are probably other measures for this determination.) B, if the direction of rotation is clockwise Update: If there are multiple candidates for B, the candidate whose segment aligns most closely with the ellipse is selected. (If I'm not mistaken, a B candidate can be said to align more closely with the ellipse if the area between the segment and the clockwise arc it crosses, starting at C, is smaller than that of another candidate. There are probably other measures for this determination.) Intuitively, there is some r max for each set of other inputs such that, for r = r max , the result is the same in either direction (because the circle intersects with the ellipse in one point rather than two), and that for r > r max , there is no solution (because there is no intersection at all). I have failed to locate the formulae that implement this, but it's likely that I just didn't know what terminology to look for. Thoughts? Update: As MvG points out below, I missed the cases where up to four intersections are possible. (I'd considered them, actually, but given only a shallow examination thought that this didn't apply if the center of the circle was on the ellipse. Oops.) Therefore, the direction may not uniquely identify a segment. Additional requirements are given above.","['geometry', 'conic-sections', 'circles']"
744172,Indeterminate limit that is supposed to be solved with De L'Hospital's rule,"Last week my Maths teacher gave the class this exercise taken from our text book. We are working on De L'Hospital's rule at the moment and this exercise is from that part of the book so everybody assumed that was the right procedure to solve it. One week later and nobody has been able to get to the right solution (even using other procedures). This is the exercise: Solve
  $$
\lim_{x \to 0} \frac{1}{x^{2}} - \cot^{2}{x}
$$ According to the book and the mighty WolframAlpha the solution is $\frac{2}{3}$ but I can't get anywhere near it. The only solution I were able to get was a $-\infty$, which I got by transforming the $\cot^{2} x $ in $\frac{\cos^{2} x}{\sin^{2} x}$ and using De L'Hospital's. EDIT: I'm asking just out of curiosity, I don't have to turn in this exercise and I'm not asking to avoid doing my homework myself.","['indeterminate-forms', 'calculus', 'limits']"
744181,Leibniz's Derivative Rule for Integral in Measure Theory,"I saw the extension of Leibniz rule for integrals for measure theory on Wiki , although I am not sure if the proposition there is correct. Besides there is no proof for it. Can anybody please introduce a reference for the measure theoretic version of it? The statement on wiki is as follows: Let $X$ be an open subset of $\mathbb{R}$ , and $\Omega$ be
a measure space. Suppose $f: X \times \Omega \rightarrow \mathbb{R} $ satisfies the following conditions: ::(1) $f(x,\omega)$ is a Lebesgue-integrable function of $\omega$ for each $x \in X$ ::(2) For almost all $\omega \in \Omega$ , the derivative $f_x$ exists for all $x \in X$ ::(3) There is an integrable function $ \theta: \Omega \rightarrow \mathbb{R}$ such that $|f_x(x,\omega)| \leq \theta ( \omega)$ for all $x \in X$ Then for all $x \in X$
::$ \frac{\mathrm{d}}{\mathrm{d} x} \int_{\Omega} \, f(x, \omega) \mathrm{d} \omega = \int_{\Omega}  \, f_x ( x, \omega) \mathrm{d} \omega $","['measure-theory', 'calculus', 'integration', 'derivatives']"
744185,"Limits of series, proof of the convergence of two sequences","I have two sequences $x_i$ and $y_i$ defined by their expressions :
$$x_i-x_{i+1}=y_i-y_{i+1}=\sqrt{x_{i+1}y_{i+1}}$$
I have to prove that $xy(x-y)=0$. I tried this : I have
$$x_i=x^{2^{i-1}}\prod_{j=0}^{j=i-2} (x^{2^j}+y^{2^j})^{-1}$$
And
$$y_i=y^{2^{i-1}}\prod_{j=0}^{j=i-2} (x^{2^j}+y^{2^j})^{-1}$$
How to prove that $x=y$ ?
I tried this : I suppose $x\neq{y}$ and I define the series. I see that 
$$\sqrt{x_iy_i}=y_{i-1}-y_i=x_{i-1}-x_i$$
So
$$x_i-x_{i+1}=\sqrt{x_{i+1}y_{i+1}}$$
$$x_{i-1}-x_i=\sqrt{x_iy_i}$$
$$\vdots$$
$$x_1-x_2=x-x_2=\sqrt{x_2y_2}$$
Or
$$\sum_{j=2}^{j=i+1}{(\sqrt{x_jy_j})}=x-x_2+x_2-x_3+\cdots+x_i-x_{i+1}=x-x_{i+1}$$
Its limit is
$$\sum_{j=2}^{j=\infty}{(\sqrt{x_jy_j})}=\lim_{i\longrightarrow{\infty}}{(x-x_{i+1})}$$
If $x\geq{y}$
$$\sum_{j=2}^{j=\infty}{(\sqrt{x_jy_j})}=\lim_{i\longrightarrow{\infty}}{(x-x_{i+1})}=x-(x-y)=y$$
If $x\leq{y}$
$$\sum_{j=2}^{j=\infty}{(\sqrt{x_jy_j})}=\lim_{i\longrightarrow{\infty}}{(x-x_{i+1})}=x$$
I suppose $x\geq{y}$. Hence
$$\sum_{j=2}^{j=i}{((-1)^j\sqrt{x_jy_j})}=x-x_2-(x_2-x_3)+(x_3-x_4)-\cdots+(-1)^i(x_{i-1}-x_i)$$
  $$=x-2x_2+2x_3-\cdots+2(-1)^{i-1}x_{i-1}+(-1)^{i+1}x_i$$
  $$=2\sum_{j=2}^{j=i-1}{((-1)^{j+1}x_j)}+x+(-1)^{i+1}x_i$$
$$=2\sum_{j=1}^{j=i}{((-1)^{j+1}x_j)}-x-(-1)^{i+1}x_i$$
$$=\sum_{j=2}^{j=i-1}{((-1)^{j+1}x_j)}+\sum_{j=1}^{j=i}{((-1)^{j+1}x_j)}$$
$$=2\sum_{j=2}^{j=i-1}{((-1)^{j+1}y_j)}+y+(-1)^{i+1}y_i$$
$$=2\sum_{j=1}^{j=i}{((-1)^{j+1}y_j)}-y-(-1)^{i+1}y_i$$
$$=\sum_{j=2}^{j=i-1}{((-1)^{j+1}y_j)}+\sum_{j=1}^{j=i}{((-1)^{j+1}y_j)}$$
Or 
  $$2\sum_{j=1}^{j=i}{((-1)^{j+1}x_j)}=\sum_{j=2}^{j=i}{((-1)^j\sqrt{x_jy_j})}+x+(-1)^{i+1}x_i$$
And
$$2\sum_{j=1}^{j=i}{((-1)^{j+1}y_j)}=\sum_{j=2}^{j=i}{((-1)^j\sqrt{x_jy_j})}+y+(-1)^{i+1}y_i$$
I do not know the limit of $(-1)^{i+1}x_i$, 
  $$\sum_{j=1}^{j=\infty}{((-1)^{j}x_j)}$$ may diverge. But
  $$\sum_{j=2}^{j=\infty}{((-1)^j\sqrt{x_jy_j})}$$ is absolutely convergent. As $y_i$ tends to zero in the infinity, then
  $$\sum_{j=1}^{j=\infty}{((-1)^{j}y_j)}$$ converge. The limit of
  $$\sum_{j=2}^{j=i}{((-1)^j\sqrt{x_jy_j})}=2\sum_{j=1}^{j=i}{((-1)^{j+1}y_j)}-y-(-1)^{i+1}y_i$$
  $$=2\sum_{j=1}^{j=i}{((-1)^{j+1}x_j)}-x-(-1)^{i+1}x_i$$
exists and the series are convergent. I will try to prove
that
  $$\lim_{i\longrightarrow{\infty}}{(x_i)}=x-y=0$$
Let
 $$\sum_{k=1}^{k=2m}{((-1)^{k+1}x_{k}e^{-\frac{k}{\sqrt{2m}}})}$$
 $$=xe^{-\frac{1}{\sqrt{2m}}}-x_2e^{-\frac{2}{\sqrt{2m}}}+x_3e^{-\frac{3}{\sqrt{2m}}}-\cdots+(-1)^{2m+1}x_{2m}e^{-\frac{2m}{\sqrt{2m}}}$$
 $$=xe^{-\frac{2}{\sqrt{2m}}}+x(e^{-\frac{1}{\sqrt{2m}}}-e^{-\frac{2}{\sqrt{2m}}})-x_2e^{-\frac{2}{\sqrt{2m}}}+x_3e^{-\frac{4}{\sqrt{2m}}}+x_3(e^{-\frac{3}{\sqrt{2m}}}-e^{-\frac{4}{\sqrt{2m}}})-x_4e^{-\frac{4}{\sqrt{2m}}}+\cdots-x_{2m}e^{-\frac{2m}{\sqrt{2m}}}$$
 $$=xe^{-\frac{2}{\sqrt{2m}}}(e^{\frac{1}{\sqrt{2m}}}-1)+x_3e^{-\frac{4}{\sqrt{2m}}}(e^{\frac{1}{\sqrt{2m}}}-1)+\cdots+x_{2m-1}e^{-\frac{2m}{\sqrt{2m}}}(e^{\frac{1}{\sqrt{2m}}}-1)+$$
 $$+(x-x_2)e^{-\frac{2}{\sqrt{2m}}}+(x_3-x_4)e^{-\frac{4}{\sqrt{2m}}}+\cdots+(x_{2m-1}-x_{2m})e^{-\frac{2m}{\sqrt{2m}}}$$
 $$=(e^{\frac{1}{\sqrt{2m}}}-1)(xe^{-\frac{2}{\sqrt{2m}}}+x_3e^{-\frac{4}{\sqrt{2m}}}+\cdots+x_{2m-1}e^{-\sqrt{2m}})+(\sqrt{x_2y_2}e^{-\frac{2}{\sqrt{2m}}}+\sqrt{x_4y_4}e^{-\frac{4}{\sqrt{2m}}}+\cdots+\sqrt{x_{2m}y_{2m}}e^{-\frac{2m}{\sqrt{2m}}})$$
 $$=(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k}{\sqrt{2m}}})}+\sum_{k=1}^{k=m}{(\sqrt{x_{2k}y_{2k}}e^{-\frac{2k}{\sqrt{2m}}})}$$
Also
 $$\sum_{k=1}^{k=2m}{((-1)^{k+1}y_{k}e^{-\frac{k}{\sqrt{2m}}})}$$
 $$=ye^{-\frac{1}{\sqrt{2m}}}-y_2e^{-\frac{2}{\sqrt{2m}}}+y_3e^{-\frac{3}{\sqrt{2m}}}-\cdots+(-1)^{2m+1}y_{2m}e^{-\frac{2m}{\sqrt{2m}}}$$
 $$=(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k}{\sqrt{2m}}})}+\sum_{k=1}^{k=m}{(\sqrt{x_{2k}y_{2k}}e^{-\frac{2k}{\sqrt{2m}}})}$$
 But
 $$(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k}{\sqrt{2m}}})}=S$$
 And
 $$(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k+1}{\sqrt{2m}}})}<S<(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k-1}{\sqrt{2m}}})}$$
 $$(e^{\frac{1}{\sqrt{2m}}}-1)e^{-\frac{3}{\sqrt{2m}}}\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})}<S<(e^{\frac{1}{\sqrt{2m}}}-1)e^{-\frac{1}{\sqrt{2m}}}\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})}$$
 Thus
 $$\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)y+(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=2}^{k=m}{(y_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})})}$$
 $$=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=2}^{k=m}{(y_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{(S)}$$
 And
 $$(e^{\frac{1}{\sqrt2m}}-1)\sum_{k=p}^{k=m}{(y_{2k-1}e^{-\frac{2k-p}{\sqrt{2m}}})}=A$$
 Or
 $$(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(y_{2k-1}e^{-\frac{2k-p+1}{\sqrt{2m}}})}<A<(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(y_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})}$$
 Also
 $$(e^{\frac{1}{\sqrt{2m}}}-1)e^{-\frac{2}{\sqrt{2m}}}\sum_{k=p}^{k=m}{(y_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})}<A<(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(y_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})}$$
 Hence
 $$\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(y_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})})}$$
 $$=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)y_{2p-1}e^{-\frac{p-1}{\sqrt{2m}}}+(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p+1}^{k=m}{(y_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})})}$$
 $$=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p+1}^{k=m}{(y_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{(A)}=\lim_{m\longrightarrow{\infty}}{(S)}$$
 For
 $$p+1=m\Rightarrow{\lim_{m\longrightarrow{\infty}}{(A)}=\lim_{m\longrightarrow{\infty}}{(S)}=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)y_{2m-1}e^{-\frac{m}{\sqrt{2m}}})}=0}$$
 Consequently
 $$\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(y_{2k-1}e^{-\frac{2k}{\sqrt{2m}}})})}=0$$
 Also
  $$(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k}{\sqrt{2m}}})}=S$$
 Or
 $$(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k+1}{\sqrt{2m}}})}<S<(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k-1}{\sqrt{2m}}})}$$
 $$(e^{\frac{1}{\sqrt{2m}}}-1)e^{-\frac{3}{\sqrt{2m}}}\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})}<S<(e^{\frac{1}{\sqrt{2m}}}-1)e^{-\frac{1}{\sqrt{2m}}}\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})}$$
 And
 $$\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)x+(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=2}^{k=m}{(x_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})})}$$
 $$=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=2}^{k=m}{(x_{2k-1}e^{-\frac{2k-2}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{(S)}$$
 Or
 $$(e^{\frac{1}{\sqrt2m}}-1)\sum_{k=p}^{k=m}{(x_{2k-1}e^{-\frac{2k-p}{\sqrt{2m}}})}=A$$
 And
 $$(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(x_{2k-1}e^{-\frac{2k-p+1}{\sqrt{2m}}})}<A<(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(x_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})}$$
 Or
 $$(e^{\frac{1}{\sqrt{2m}}}-1)e^{-\frac{2}{\sqrt{2m}}}\sum_{k=p}^{k=m}{(x_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})}<A<(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(x_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})}$$
 Hence
 $$\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p}^{k=m}{(x_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})})}$$
 $$=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)x_{2p-1}e^{-\frac{p-1}{\sqrt{2m}}}+(e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p+1}^{k=m}{(x_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})})}$$
 $$=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=p+1}^{k=m}{(x_{2k-1}e^{-\frac{2k-p-1}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{(A)}=\lim_{m\longrightarrow{\infty}}{(S)}$$
 For
 $$p+1=m\Rightarrow{\lim_{m\longrightarrow{\infty}}{(A)}=\lim_{m\longrightarrow{\infty}}{(S)}=\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)x_{2m-1}e^{-\frac{m}{\sqrt{2m}}})}=0}$$
 Consequently
 $$\lim_{m\longrightarrow{\infty}}{((e^{\frac{1}{\sqrt{2m}}}-1)\sum_{k=1}^{k=m}{(x_{2k-1}e^{-\frac{2k}{\sqrt{2m}}})})}=0$$
I deduce
$$0<\lim_{m\longrightarrow{\infty}}{(\sum_{k=1}^{k=2m}{((-1)^{k+1}x_{k}e^{-\frac{k}{\sqrt{2m}}})})}$$
$$=\lim_{m\longrightarrow{\infty}}{(\sum_{k=1}^{k=2m}{((-1)^{k+1}y_{k}e^{-\frac{k}{\sqrt{2m}}})})}$$
$$=\lim_{m\longrightarrow{\infty}}{(\sum_{k=1}^{k=m}{(\sqrt{x_{2k}y_{2k}}e^{-\frac{2k}{\sqrt{2m}}})})}<\lim_{m\longrightarrow{\infty}}{(\sum_{k=1}^{k=m}{(\sqrt{x_{2k}y_{2k}})})}$$
$$<\lim_{m\longrightarrow{\infty}}{(\sum_{k=1}^{k=2m}{(\sqrt{x_{k}y_{k}})})}=y$$
Thus
$$\lim_{m\longrightarrow{\infty}}{(\sum_{k=1}^{k=2m}{((-1)^{k+1}(x_k-y_k)e^{-\frac{k}{\sqrt{2m}}})})}=0$$
$$=\lim_{m\longrightarrow{\infty}}{((x-y)\sum_{k=1}^{k=2m}{(e^{-\frac{k}{\sqrt{2m}}})})}=\lim_{m\longrightarrow{\infty}}{((x-y)e^{-\frac{1}{\sqrt{2m}}}\frac{1-e^{-\sqrt{2m}}}{1+e^{-\frac{1}{\sqrt{2m}}}})}=\frac{x-y}{2}=0$$
And
$$x-y=0$$
I recapitulate $$x_i>x_{i+1},\quad{y_i>y_{i+1}}\Rightarrow{x=y}$$ $$x_i=x_{i+1}=x_{i+1}+\sqrt{x_{i+1}y_{i+1}}\Rightarrow{xy=0}$$ $$y_i=y_{i+1}=y_{i+1}+\sqrt{x_{i+1}y_{i+1}}\Rightarrow{xy=0}$$
$$\Rightarrow{xy(x-y)=0}$$
Is this calculus correct ? Thank you.",['real-analysis']
744193,How many sequences of numbers $\{a_1...a_5\}$ where $a_i \in \{1...25\}$ satisfy $a_{i+1} \leq a_i + 2$,"Here's how it looks: 1 1 1 1 1 1 1 1 1 2 1 1 1 1 3 1 1 1 2 1 1 1 1 2 2 1 1 1 2 3 1 1 1 2 4 1 1 1 3 1 ......... 25 25 25 25 24 25 25 25 25 25 Counting sequences using a simple script gives an answer of 386958 I already know that if I had just $a_{i+1} \leq a_i$, it would be ${25+5-1 \choose 5}=118755$, but I don't know what to do with that extra ""+2"" in $a_{i+1} \leq a_i + 2$ What is the mathematical solution here? Do I have to use a generating function for this?",['combinatorics']
744285,Does $\mathrm{GL}_{n-2}(\mathbb{Z})$ has an element of order $m$?,"Let me introduce the context: A few week ago I have made the following contest as a ""homework"" : ENS contest (France) 2006 which is essentially about $SL_n(\mathbb{Z})$ group, finite subgroup of $SL_n(\mathbb{Z})$ and as a final question : Any surjective morphism group $SL_n(\mathbb{Z}) \rightarrow SL_n (\mathbb{Z})$ is bijective. Yesterday I had proved that $S_n$ is isomorphic to a subgroup of $\mathrm{GL}_{n-1}(\mathbb{Z})$. Which is mainly a consequence of the mentioned contest. So, here is my question : Assuming that $S_n$ has an element of order $m\in \mathbb{N}$. Does the following group  $\mathrm{GL}_{n-2}(\mathbb{Z})$ has an element of order $m$ ? For $n=\{1,2,3\}$ one can check the answers is no. Unfortunately, I had no idea to disprove (perhaps the result is true for $n \geq 4$) the claim for higher values of $n$. EDIT: It seems to be true for $n\ge 4$ and even. (Look at Greg's Martin answer).","['finite-groups', 'group-theory']"
744290,"Why is $\mathbb{Q}[X,Y]/(X^2+Y^2-1)$ a Dedekind domain?","What is the best way to understand that $D:=\mathbb{Q}[X,Y]/(X^2+Y^2-1)$ is a Dedekind domain? I first noticed that $X^2+Y^2-1$ is irreducible in $\mathbb{Q}[X,Y]$ since it is $Y-1$ Eisenstein in $\mathbb{Q}[Y][X]$. It follows that $\mathbb{Q}[X,Y]/(X^2+Y^2-1)$ is an integral domain. By Hilbert Basis theorem, $\mathbb{Q}[X,Y]$ is Noetherian, so this quotient is too. I know that a Dedekind domain is precisely a Noetherian integral domain which is integrally closed in its fraction field, and has Krull dimension $1$. However, computing the fraction field and showing $D$ is integrally closed in it seems quite difficult, and showing the Krull dimension is 1 also seems difficult. I'm aware of another result that a Noetherian integral domain is Dedekind domain if the localization at every prime is a discrete valuation ring. I think the prime ideals of $D$ are precisely the canonical images of the prime ideals containing $(X^2+Y^2-1)$ in $D$. But I'm stuck trying to get a general handle on $D_P$ and seeing it is a DVR. What is the best way to see this claim ( preferably algebraically, not geometrically )? Thanks.","['krull-dimension', 'commutative-algebra', 'abstract-algebra', 'dedekind-domain']"
744296,"differential equations, diagonalizable matrix","I have a question of differential equations of the form. $\textbf{x}'(t)=A*\textbf{x(t)}$, where x is an n-dimensional matrix, and A is an n*n real matrix. I have learned to solve this if a is diagonalizable, with n independent eigenvectors. Then I get that the solltion is: $\textbf{x(t)}=C_1\textbf{v}_1e^{\lambda_1t}+...+C_n\textbf{v}_ne^{\lambda_nt}$. This holds even if the eigenvectors and values are complex?, as long as the vectors are linearly independent and we have n of them? If the matrix is not diagonalizable is it possible to find an analytical sollution, or do you have to use numerical solutions then?","['linear-algebra', 'ordinary-differential-equations']"
744331,Area between two polar curves $r = 2 \sin\theta$ and $r =2\cos\theta$,"I am trying to find the area between the polar curves $r = 2 \sin θ$ and $r = 2 \cos θ$. I set up the area equation as follows: $$\frac12\int_0^{\pi/4}((2\sinθ)^2-(2\cosθ)^2)\,d\theta$$ I could not get the correct answer with this, which is $\frac\pi2-1$. Any help with this problem would be appreciated :D","['polar-coordinates', 'calculus', 'integration', 'area']"
744339,How to apply the Hölder's inequality in a clever way?,"Here is the problem: Let $f\in L^p(\mathbb R^n)\cap L^q(\mathbb R^n)$ and $s\in[p,q]$. Show that $f\in L^s(\mathbb R^n)$ I'm almost sure that this is a simple exercise on Hölder's inequality yet I can't find the right $a,b>1$ with $$\frac{1}{a}+\frac{1}{b}=1$$ to apply the inequality. Whether you'll give a hint or a full solution (which I expect to be very short), please explain your thought process. I guess it's like with the $\varepsilon/\delta$-proofs where things happen to appear out of the blue but we know that it's because of some scratch-work before.","['measure-theory', 'inequality', 'lp-spaces', 'real-analysis']"
744404,"How many surjective functions are there from $A=${$1,2,3,4,5$} to $B=${$1,2,3$}?","I want to find how many surjective functions there are from the set $A=${$1,2,3,4,5$} to the set $B=${$1,2,3$}? I think the best option is to count all the functions ($3^5$) and then to subtract the non-surjective functions. However, I'm not sure how can I count these functions. Thanks","['functions', 'combinatorics']"
744425,Separate the variables of the function $\frac{x^2}{\sqrt{x^2+y^2}}$,"Is there a way to express the function $\frac{x^2}{\sqrt{x^2+y^2}}$ as the product of two functions: $f(x)\cdot g(y)$, i.e. one in each variable? This is becasue I want to apply a convolution whose kernel is define that way, and I am willing to separate that kernel. For that I need to be able to express it as a product of two functions that are on each variable separatedly.","['convolution', 'multivariable-calculus', 'functions']"
744442,Transformation of ellipsoid to sphere,"So I need to find an volume-preserving mapping from an ellipsoid to a ball (solid sphere).  (Specifically: $\dfrac{x^2}9 + y^2 + z^2 \le 3$, but I'd rather understand the general case than just get how to transform this one ellipsoid.) I think I've got linear transformations (parallelotopes to parallelotopes) down, but apparently I missed something in class because I can't figure out how to approach these (seemingly) non-linear transformations.","['geometry', 'multivariable-calculus', 'linear-transformations', 'linear-algebra', 'transformation']"
744451,Is the categorical product for projective spaces essentially the tensor product?,"I wonder whether the categorical product of two projective spaces is essentially given by the tensor product of the underlying vector spaces. Is this at least true for projective Hilbert spaces? One problem I have with verifying this gut feeling is that I don't even know which morphisms are allowed between two projective spaces. Every non-zero linear map between the underlying vector spaces gives rise to a projective morphism between the projective spaces. But is every projective morphism of this form, or are there other possibilities? What about inversions, for example? (For the Hilbert space case, are the projective morphisms induced by the continuous linear maps?)","['category-theory', 'linear-algebra', 'projective-geometry']"
744488,Convergence in $L^2$ of difference quotients to derivative of function in $H^1$,"Is it true that if $u\in H^1({\mathbb R})$, then $(u(x+h)-u(x))/h$ converges to $u'(x)$ in $L^2({\mathbb R})$, as $h\to 0$?  It's hard for me to get a handle on this, since $u'$ doesn't have to be continuous (so there's no uniform convergence, even on compacts, since $u$ does have to be continuous), but I can't seem to construct a counterexample either.","['sobolev-spaces', 'derivatives']"
744495,Equivalent definitions of Lebesgue Measurability (Rudin and Royden),"I'm reading Royden's real analysis 4th edition, and he defines a real set $E$ to be lebesgue measurable if, for all real sets $A$, $m(A)=m(A∩E)+m(A∩E^c)$. Here, $m$ is the outer measure of a set. I believe this is called Caratheodory's criterion. Now, I'm also reading Baby Rudin (Principles of Analysis), and in chapter 11, Rudin defines a real set to be (lebesgue) measurable if it is the union of a countable collection of finitely measurable real sets, and he has another definition for ""finitely measurable"" which is a bit lengthy to type up. I'm having trouble proving that these two definitions are equivalent; that is, I want to show that the set of lebesgue measurable sets constructed under Royden's definition is the same as the set of lebesgue measurable sets constructed under Rudin's definition. Can someone who is familiar with both definitions (especially rudin's definition) help me out by suggesting a proof or a text that may help? So far, I managed to prove that a set measurable under rudin's definition satisfies the caratheodory criterion. I did this by using the following facts: $m(A)=m(A∩E)+m(A∩E^c)$ if and only if for every $\epsilon >0$, there exists an open set $O$ such that $m(O\setminus E) \le \epsilon$. Also: If a set $E$ is measurable under Rudin""s definition then there exists an open set $O$ such that $m(O\setminus E) \le \epsilon$. Can somebody help me out with the converse?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
744502,"Prove or find a counter example to the claim that for all sets A,B,C if A ∩ B = B ∩ C = A ∩ C = Ø then A∩B∩C ≠ Ø","This is a homework question of mine that Ive answered and I'd really like some feedback on my solution. Prove or find a counter example to the claim that for all sets $A,B,C$, $$\text{if  }A\cap B=B\cap C=A\cap C=\emptyset \text{ then } A\cap B\cap C\neq \emptyset$$. Since I can only either prove it is true, OR find a counter example I have gone with the latter because I think this statement is not true.
My counter example is as follows: Let $A = \{1,2,3 \}$ , $B = \{4,5,6 \}$ and $C = \{7,8,9 \}$.
It is then clear that $A ∩ B =  B ∩ C =  A ∩ C = \emptyset$ . If we let $x ∈ A\cap B\cap C$ then $x$ must be in $A$ and $B$ and $C$ . Since this cannot be possible because there are no common elements then this implies that $A∩B∩C$ has to be equal to a null set i.e $A∩B∩C = \emptyset$ and thereby showing that (at least for this scenario) if $A \cap  B =  B \cap  C =  A \cap  C = \emptyset$ then $A\cap B\cap C = \emptyset$. Is this okay? Any feedback will be greatly appreciated thank you!",['elementary-set-theory']
744527,How can I write an SDE in Matlab?,"My professor would like me to solve a system similar to the following:
 $$ dx_i=[f_i(x_1,x_2,...x_n)]dt + g_ix_idW_i$$ Where $g_i$ are positive constants that measure the amplitude of the random perturbations, and $W_i$ are random variables normally distributed. Im not sure how I can implement this in Matlab for ode45 to solve.  What is throwing me off is the $dt$ tacked on to $f_i(x_1,...)$ and $dW_i$. Is it as simple as coding function dxdt=money(t,x,a,b,c)

x1=x(1);
x2=x(2);
x3=x(3);

dx1=x1.*(x2-a)+x3 + 10*rand();
dx2=1-b*x2-x1.^2 + 10*rand;
dx3=-x1-c*x3 +10*rand();

dxdt=[dx1;dx2;dx3];

end","['ordinary-differential-equations', 'stochastic-calculus', 'probability', 'matlab', 'stochastic-differential-equations']"
744535,Verify integral over a surface,"Show $\int \int_{S} (x^2 +y^2) d\sigma = \frac{9\pi}{4}$ where $S = \left\{(x,y,z) : x>0, y>0, 3>z>0, z^2 =3(x^2+y^2)\right\}$. We have the formula $\int \int_{S} f(x,y,z) = \int \int_{D} f(x, y, g(x,y)) \sqrt{(\frac{\partial z }{\partial x})^2 + (\frac{\partial z }{\partial y})^2+1}dA$. I figured I could rewrite the constraint on $z$ as $z = \sqrt{3(x^2+y^2)}$ which gives $ \frac{\partial z }{\partial x}=\frac{\sqrt{3}x}{\sqrt{(x^2+y^2)}}$ and $ \frac{\partial z }{\partial y}=\frac{\sqrt{3}y}{\sqrt{(x^2+y^2)}}$. Plugging this in to the formula gives
$\int \int 2(x^2+y^2)$ after you simplify. I thought both integrals went from $0$ to $\sqrt{3}$, but this clearly doesn't give the correct answer. Where am I messing up?",['multivariable-calculus']
744562,Forcing function,"If the forcing function on the right-hand side of a linear $n^{th}$ order differential equation is nonconstant and periodic, can the solution of the equation be a nonperiodic function?",['ordinary-differential-equations']
744591,What's the intuition for the fact that $\mathscr{O}(-k)$ and $\mathscr{O}(k)$ are so different?,"maybe this question makes no sense and I just cannot accept the fact that dual the line bundle is different from the respective line bundle itself. Since it looks like that manifolds are more intuitive than algebraic varieties, let's consider smooth complex compact manifolds. Anyway, picking the most ordinary non-trivial line bundle over a complex manifold , namely the tautological line bundle, it's know that $0 = H^0(\mathbb{P}^n, \mathscr{O}(-k)) \not\cong H^0(\mathbb{P^n}, \mathscr{O}(k)) =$ ""homogeneous polynomials of degree $k$ "", because if both have non-trivial global sections then both must be trivial (because the manifold is compact). Another way of seeing this is by computing the cocyles of the respective bundles. Is there an intuitive way of seeing why the above one and the dual of the above one are so different (by drawing or seeing where the glueing fails when trying to create a global section)? Where does it fail when I try creating an isomorphism between some a line bundle and it's dual by picking fiberwise isomorphisms (as vector spaces of complex dimension $1$ )? If we just consider the smooth structure (without the holomorphic one),what happens to the global sections of both bundles in the above example? Where the fiberwise isomorphism fails to be a vector bundle (of rank $2$ ) isomorphism? Thanks in advance.","['algebraic-geometry', 'holomorphic-bundles', 'vector-bundles', 'complex-analysis']"
744622,Help with Convergence/Divergence,"So I am trying to prove whether the following problem converges or diverges? $$\sum_{n=1}^\infty \left({n\over n+18}\right)^n$$ So I decided to use the Root test. $$ L = \lim_{n\to \infty}\sqrt[n]{\left({n\over n+18}\right)^n} = \lim_{n\to \infty} {n\over n+18} = 1$$ But that answer is inconclusive, because according to the Root Test, if L $\lt 1$ than the function converges, and if L $\gt 1$, than the function diverges. But my answer is 1. Can someone please suggest some other methods through which I can determine whether the given problem converges or diverges? Thanks Alot","['divergent-series', 'convergence-divergence', 'sequences-and-series']"
744660,Mittag-Leffler Problem,"We have: $X$ a compact Riemann surface defined by $y^{2}=1-x^{6}$ and $P=(0,1) \in X$ a point given in local coordinates $(x,y)$. Furthermore, we have a meromorphic function $f(x,y)=y/x$ such that $f \in H^{0}(\mathcal{O}_{nP})$ for $n=3$. We know that our function is defined up to additive constant by its principal parts, i.e. $f(x)=a_{n}/x^{n}+\cdots+a_{1}/x+O(1)$ where the final term is something holomorphic. Given a holomorphic 1-form expressed near $P$ as $\omega(z)=(b_{0}+b_{1}z+\cdots+b_{n-1}z^{n-1}+O(z^{n}))dz$, we see that $\mathrm{Res}_{P}(f\omega)=b_{0}a_{1}+\cdots+b_{n-1}a_{n}$. That is, the vector $(b_{i})$ determines a linear constraint on the vector $(a_{i})$. Using our function $f(x,y)$ I want to explicitly compute the principal parts $f(x)$ given above, and then conclude $\mathrm{Res}_{P}(f\omega)=0$ for all $\omega \in \Omega(X)$. I'm not quite sure how to do this in practice. Can someone demonstrate this to me? There seems to be a dearth of explicit examples of such a problem in the literature. Thanks very much.","['riemann-surfaces', 'algebraic-geometry']"
744666,Uniformly Distributed Random Variables Minimum,"Let A,B,C,D,E be independent random variables, each of which is uniformly distributed in the interval [0,18]. 
Let X=min{A,B,C,D,E}. What is the expected value of X? Enter your answer as a decimal. I know that I need to be attempting some work,but any direction would be greatly appreciated!",['statistics']
744675,What is the difference between $\Bbb{R^n}\times\Bbb{R^m}$ and $\Bbb{R^{m+n}}$?,"My book specifies a function: $$\Bbb{R^n}\times\Bbb{R^m}\to\Bbb{R^m}$$ What is the difference between $\Bbb{R^n}\times\Bbb{R^m}$ and $\Bbb{R^{m+n}}$? And if there is none, what are the relative advantages of writing $\Bbb{R^n}\times\Bbb{R^m}$ over $\Bbb{R^{m+n}}$? Thanks.",['elementary-set-theory']
744713,Calculation of $\lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2}$,"Calculation of $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2}$ $\bf{My\; Try::}$ Given $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2} = \lim_{x\rightarrow 0}\frac{\sin (\pi (1-\sin^2 x))}{x^2}$ $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi \sin^2 x)}{\pi\sin^2 x} \times \pi \times \lim_{x\rightarrow 0} \frac{\sin^2 x}{x^2} = \pi$ Is there is any other method by which we can solve the above question. If yes, The please help me . Thanks",['calculus']
744785,The differential is NOT the Jacobi Matrix?,"In the book Analysis II by C.T. Michaels the differential is introduced as the Jacobi-Matrix. In class we had the following definition: Definition : Let $U \subset \mathbb{R}^m$ be open, $f: U \to \mathbb{R}^n$ , $x_0 \in U$ $f$ is at $x_0$ differentiable $ \iff \exists A: \mathbb{R}^m \to \mathbb{R}^n$ such that $ \displaystyle \lim_{x \to x_0}_{x \neq 0} \displaystyle \frac{f(x)-f(x_0)-A(x-x_0)}{||x-x_0||}=0$ Note : We call $A \in \hom(\mathbb{R}^m, \mathbb{R}^n)$ the differential of $f$ at point $x_0$ and we also write $A=df(x_0)$ My tutor said there are many books where the Jacobi-Matrix and the differential are said to be equal, but he mentioned they really are not. Oddly enough when I returned home after this Colloquium in Mathematics I did try to get some practice and just found the definition of the differential being equal to the Jacobi-Matrix as in C.T. Michaels. Now consider the following exercise (found in a paper by Salamon) Exercise : Show that $f$ is differentiable and compute the differential $df$ for all points in the domain: $$ f: \mathbb{R} \longrightarrow \mathbb{R}^2, \ f(x)= (ye^{ix}, xe^{iy}) $$ My approach : Showing that $f$ is differentiable is easy, I compute the Jacobi Matrix $$J_f= \begin{pmatrix}iye^{ix} \\ e^{iy} \end{pmatrix} \in \text{Mat}_{2,2}( \mathbb{C})  $$ And see that all the partial derivatives exists and are continuous $ \implies f$ is differentiable. Questions : How do I find the differential? If I plugin the Jacobi-Matrix into the definition above I can't seem to come up with the correct result Is it wrong to treat the Jacobi-Matrix and the differential as equal? (considering the definition as given in my class of course)","['multivariable-calculus', 'definition', 'self-learning', 'real-analysis', 'analysis']"
744791,let $A$ be an $n\times n$ matrix. Show that $\det(A^{-1}) = \frac{1}{\det(A)}$,"Let $A$ be a $n \times n$ matrix , and then show that $$\det(A^{-1}) = \frac{1}{\det(A)}.$$ Any tips on this one? basically I don't have a clue.","['matrices', 'linear-algebra', 'inverse', 'determinant']"
744812,One-one analytic functions on unit disc,"Is the following statement true? Suppose, $ f:D\to \mathbb C $ is an analytic function where $ D $ is the unit disc of radius $ 1 $ around $0 $. Suppose, $ f $ is analytic on the boundary of $ D $ as well. Then prove that, if $ f $ is one-one on the boundary of $ D $, then $ f $ is one-one on $ D $. P.S.
I think I got a solution. But I was wondering if this problem has a trivial solution. Here is my solution, since nobody has posted a solution yet:- Suppose, $ \gamma $ is the boundary of $ D $(assuming $ \gamma(t)=e^{2\pi it} $). Then $ f\circ \gamma $ is a simple continuously differentiable curve. So by Jordan curve theorem, $ f\circ \gamma $ divides $ \mathbb C $ into 2 path connected regions $ A_1, A_2 $ such that if $ a\in A_1 $, then $\int_{f\circ \gamma} \frac {1}{z-a} dz=2\pi i$ and if $ a\in A_2 $, then $\int_{f\circ \gamma} \frac {1}{z-a} dz=0$. So, $ f(z)=a $ for some $ a\in A_1,z\in D $ implies $ \int_{\gamma} \frac {f'(z)}{f(z)-a} dz=2\pi i $. So $ f(z)=a $ has only one solution in $ D $. Similarly if $ a\in A_2 $, then $\int_{\gamma} \frac {f'(z)}{f(z)-a}=0 $, so $ f(z)=a $ has no solution in $ D $. If $ f(z)=a $ for some $ z\in D, a\in f\circ \gamma $, then by open mapping theorem, $ f(z)=a' $ for some $ z\in D, a'\in A_2 $, which is not possible. So $ f $ is one-one in $ D $.",['complex-analysis']
744885,Integral of $e^{(a+ib)x}$,"Given the function $f:\mathbb{R}\rightarrow \mathbb{C}$, such that $f(x)=e^{(a+ib)x}$, how can I compute $f'(x)$ and $\int f(x)dx$ ?
Certanly, one can use the identity $e^{ibx}=\cos(bx)+i\sin(bx)$ and then compute the derivative and integral using the well known rules from real analysis. But is it true that $f'(x)=(a+ib)e^{(a+ib)x}$ (I've shown this but I want to be sure) and is there a similar rule for computing the integral?","['derivatives', 'calculus', 'integration', 'real-analysis']"
744896,Continuity of the sum of continuous functions,"Let $X$ be a topological space and $f:X\to \mathbb{R}$ and $g:X\to \mathbb{R}$ be continuous functions. How do I show that $h:X\to \mathbb{R}$ where $h:=f+g$ is continuous, would prefer to use the general definition so for and open $U$ in $\mathbb{R}$, $h^-(U)$ is open. Also if $Y$ is another top space and $k:Y\to \mathbb{R}$ is also a continuous function, how do I show $l:X\times Y\to \mathbb{R}$, defined by $l:=f+k$ is also continuous. Any help please. Thanks in advance.","['general-topology', 'continuity']"
744947,A problem with moments of a function,"How to show that there is no continuous function $f:[0,1] \to \mathbb{R}$, that satisfies $\displaystyle \int_0^1 x^nf(x)\,dx = 0$ for all $n = 0,2,3,\cdots$, but $\displaystyle \int_0^1 xf(x)\,dx \neq 0$ ? I will be grateful if the solution involves only theorems of Real-Analysis.","['functions', 'real-analysis']"
744955,Can the image of chains on a smooth manifold be thought of as a Borel $\sigma$-algebra?,"Volume forms on smooth manifolds have a nice interpretation as measures, but what takes the place of the Borel $\sigma$-algebra? In particular, if we let $\mathcal{M}$ be a smooth manifold and $\mathcal{B} ( \mathcal{M} )$ the Borel $\sigma$-algebra generated by the open neighborhoods of the manifold, then is $\mathcal{B} ( \mathcal{M} )$ equivalent to the image of top-rank chains on $\mathcal{M}$? Naively $\mathcal{B} (\mathcal{M} )$ is well-defined, in particular countable additivity should come from the local charts, but I'm struggling to find a more geometric interpretation and I haven't been able to find a readable reference on chains that gets into the details like countable additivity.  Pedagogical references welcome. Thanks!","['probability-theory', 'differential-geometry']"
744958,Homogeneous second-order differential equation with constant Wronskian,"Problem Prove that if the Wronskian of any two solutions of differential equation $y''+p(x)y'+q(x)y=0$ is constant, then $p(x)$ is zero. My attempt. : Let $y_1$ and $y_2$ be two solutions of given differential equation. Note that the Wronskian $W=W[y_1,y_2]$ satisfies $W'+p(x)W=0$ . Since $W$ is constant, we get $p(x)W=0$ . Question. How do I show that $W$ cannot be equal to zero? If there are two solutions $y_1$ , $y_2$ that are linearly independent, then $W[y_1,y_2]\neq 0$ . But I am not certain of the existence of such solutions. My question is : If a second-order ODE has a solution, do there exist two solutions that are linearly independent?","['ordinary-differential-equations', 'wronskian']"
744977,Hilbert Scheme and Chow variety in the case of Conics in $\mathbb{P}^{3}$,"My question concerns the relationship between chow varieties and hilbert schemes in the case of conics in $\mathbb{P}^{3}_{k}$. More precisely, consider the Hilbert scheme $\mathsf{hilb}^{2t+1}_{3}$, and the Chow variety $C^{2t+1}_{3}$. Let $f:\mathsf{hilb}^{2t+1}_{3} \longrightarrow C^{2t+1}_{3}$ be the rational map that maps every reduced element $X$ to the corresponding Chow variety $V_{X}$. I would like to show that this map is not an isomorphism on the reduced elements $X$ that correspond to double lines. My overall goal is to give a concrete example of family of curves, for which the correspinding Chow variety and Hilbert scheme behave differently.","['algebraic-geometry', 'schemes']"
744978,If $(x_n)$ is an unbounded increasing sequence then $\sum (1-x_n/x_{n+1})$ diverges [duplicate],"This question already has answers here : If the positive series $\sum a_n$ diverges and $s_n=\sum\limits_{k\leqslant n}a_k$ then $\sum \frac{a_n}{s_n}$ diverges as well (2 answers) Closed 8 years ago . Let {$x_n$} be monotone increasing sequence of positive real numbers. Show that if {$x_n$} is unbounded, then $\sum_{n=1}^{\infty}(1-\frac{x_n}{x_{n+1}})$ diverges.","['convergence-divergence', 'real-analysis', 'limits']"
744987,Show that $G$ ( subgroup of $\mathrm{GL}(E)$) is finite.,"I came across with, I think, a difficult problem : Let E a Hermitian space with a Hermitian norm $||\ ||$ . We provide $\mathcal{L}(E)$ with the norm $|||\ \  |||$ subordinated to $||\ ||$ . Let $r \in ]0,2[$ and $G$ a subgroup of $\mathrm{GL}(E)$ such that $G \subset B_o (\mathrm{Id}_ E , r)$ (open ball) . Show that $G$ is finite. I was able to show the following fact : if $\lambda \in \mathbb C$ is an eigenvalue of an element of $G$ , then $|\lambda -1| \leq r$ Proof. For $X$ a eigenvector associated with the eigenvalue $\lambda$ of $f\in G$ ,
then $||f(x)-X||\leq  N(f_{Id}) ||X||$ . The eigenvalues of elements of $G$ are the roots of unity, and there are finitely many eigenvalues. Proof. First, The eigenvalues of $f$ are $\vert\  \vert = 1$ Otherwise, $f^n$ element of $G$ (group) and we have $N(f^n)>\vert a\vert ^n$ Thus with $N (f^n) - N(Id) \le N( f^n{_Id}$ )
we get $\vert \lambda \vert^n \le r + 1$ winch is impossible when $n$ is big enough. Furthermore $f^-1$ is an element of $G$ (group) and its eigenvalues ​​are the inverse of those of $f$ . Therefore we deduce that all the eigenvalues ​​of $f$ are of modulus $1$ . EDIT : I forgot the rest of the proof,(I am not sure it's correct) Let $\lambda=\exp(i\theta)$ an eigenvalue of $f$ , fixed. If $\theta$ isn't of the form $\frac{2k \pi}n$ then all $\lambda^p$ with $p$ an integer will be dense on the points of the circle of radius 1 and we will find the eigenvalues of $f^p$ near $-1$ wich will contracdict the first inegality. How can I continue ? Thank you in advance NB: I made this bounty because lie theory it's beyon my reach.","['general-topology', 'eigenvalues-eigenvectors', 'finite-groups']"
744991,Squares of C*-algebras,"I'm reading a paper where it is claimed that every C*-algebra $A$ satisfies $A^2 = A$, ""for example, using Cohen's 1959 factorization theorem"". However, I don't see how to apply Cohen's factorization theorem to obtain this. Is there an easier proof that doesn't use Cohen's factorization theorem?","['c-star-algebras', 'operator-algebras', 'functional-analysis']"
745000,Green's first identity,"Good morning/evening to everybody. I'm interested in proving this proposition from the Green's first identity, which reads that, for any sufficiently differentiable vector field $\mathbf{\Gamma}$ and scalar field $\psi$ it holds: $$ \int_U \nabla \cdot \mathbf{\Gamma} \, \psi \, dU = \int_{\partial U} (\mathbf{\Gamma} \cdot \mathbf{n}) \, \psi \, dS - \int_U \mathbf{\Gamma} \cdot \nabla \psi \, dU.$$ I've been told that, for $\mathbf{u}, \vec{\omega} \in \mathbb{R}^2$ , it is true that (which I can prove quite easily using index notation): $$ \int_U \Delta u_j \omega_j \, dU = \int_{\partial U} \frac{\partial u_j}{\partial n} \, \omega_j \, dS - \int_U  \nabla u_j \cdot \nabla \omega_j \, dU,$$ which is equivalent to: $$\int_U (\nabla \cdot \nabla \mathbf{u}) \cdot \, \vec{\omega} \, dU = \int_{\partial U} \frac{\partial {\mathbf{u}}}{\partial n} \cdot \vec{\omega}\, dS - \int_U \nabla \mathbf{u} : \nabla \vec{\omega} \, dU, \quad j =1,2 . $$ In every one of the equations above, $U$ is a closed region and $\partial U$ its border, being $\mathbf{n}$ its outer normal unit vector and $:$ stands for tensor contraction. I would like to prove that, for any given tensor $\mathbf{T}$ , it holds: $$\int_U (\nabla \cdot \mathbf{T}) \cdot \, \vec{\omega} \, dU = \int_{\partial U}  (\mathbf{T} \cdot \mathbf{n}) \cdot \vec{\omega}\, dS - \int_U \mathbf{T} : \nabla \vec{\omega} \, dU , $$ but I'm not very proficient at dealing with index notation, yet. How could I proceed? Any help will be much appreciated. Cheers! Edit and hint: Maybe divergence theorem is useful here? Since the Green's first identity is derived from it.","['multivariable-calculus', 'tensors', 'integration']"
745003,How to prove series convergence: $\sum \limits_{n=1}^\infty \left(\frac1n+\sqrt{1+n^2}-\sqrt{2+n^2}\right)^2$,"I have this series:
$$\sum \limits_{n=1}^\infty \left(\frac1n+\sqrt{1+n^2}-\sqrt{2+n^2}\right)^2$$
I know that it's convergent (from WolframAlpha) but I need to prove it is convergent. How can I do it?","['sequences-and-series', 'limits']"
745023,Riemann's zeta as a continued fraction over prime numbers.,"Riemann's zeta function is a function with many faces, I mean representations. I recently derived this one, bellow, as a continued fraction over prime numbers. $$
\zeta(s)=1
+\cfrac{\frac{1}{2^{s}}}{1-\frac{1}{2^{s}}
-\cfrac{\frac{2^{s}-1}{3^{s}}}{1+\frac{2^{s}-1}{3^{s}}
-\cfrac{\frac{3^{s}-1}{5^{s}}}{1+\frac{3^{s}-1}{5^{s}}
-\cfrac{\frac{5^{s}-1}{7^{s}}}{1+\frac{5^{s}-1}{7^{s}}
-\cfrac{\frac{7^{s}-1}{11^{s}}}{1+\frac{7^{s}-1}{11^{s}}
-\ddots}}}}}
$$ ... and I'd like to know if this is known in the literature and if so I'd appreciate to have references about it. Thanks.","['riemann-zeta', 'continued-fractions', 'number-theory', 'reference-request', 'prime-numbers']"
745071,"If $A \in \mathbb{C}^{m\times n}$ is full-column rank matrix, then is rank($AB$) = rank ($BA$) = rank($B$)?","Let $A \in \mathbb{C}^{m\times n}$, and $B \in \mathbb{C}^{n\times k}$ complex matrices. If A is full-column rank matrix then can we say that rank($AB$) = rank ($BA$) = rank($B$)? What can we say about $N(AB)$? Under what condition $N(AB) = N(B)$? I need help to understand this. I would be very much helpful for any kind of help and suggestions.","['matrices', 'linear-algebra', 'matrix-rank']"
745081,Characters and conjugacy classes [duplicate],"This question already has answers here : Some irreducible character separates elements in different conjugacy classes (2 answers) Closed 10 years ago . This comes up in reading David Speyer's answer to this question. Given a finite group $G$ and two non-conjugate elements $x, y,$ how does one construct a unitary representation $\rho$ of $G$ such that $\rho(x)$ and $\rho(y)$ have different traces? (The same question makes sense for infinite groups, but it is far from clear that this is always possible in the infinite setting, even if you drop ""unitary"").","['representation-theory', 'group-theory']"
745158,Conceptual question: Critical Points,"This is my first question posted here, I hope to make it as easy-to-answer as possible. I'm currently studying Vector Calculus it is taught that to find critical points (over the entire surface, not over some domain), we do the following: Let $f_x=0$ and $f_y=0$. Solve the two resulting equations simultaneously if need be. We are taking the partials along the coordinate axes, but what is the guarantee that these are the only critical points? ie: If I take the partial derivatives along any two perpendicular vectors, could they yield critical points that would not be found by taking the partials along the coordinate axes? Below is my 'explanation' based on my current understanding (which may be completely incorrect!) Since we generally study 'friendly' surfaces, the partials (in any direction) will always tend to zero, so we take partials along the coordinate axes for the sake of convenience.",['multivariable-calculus']
745173,Möbius bundle as a tautological bundle,"I was trying to solve the exact same problem that was discussed in this question: Tautological vector bundle over $G_1(\mathbb{R^2})$ isomorphic to the Möbius bundle I came up with the step to identify one-dimensional projective space with the one-sphere by myself, but that didn't make it any clearer. Even when I draw a picture I cannot see how an element of the tautological bundle should ""twist around"" the one-sphere (I seem to end up with the trivial bundle), let alone can I write down an explicit bundle isomorphism. Can anyone make the identifications when one passes from projective space to the circle clear? It seems that my problem lies there.","['general-topology', 'smooth-manifolds']"
745220,Hessian equals zero.,"I'm currently just working through some maxima/minima problems, but came across one that was a bit different from the 'standard' ones. So they used the usual procedures and ended up finding that the Hessian is zero at the critical point (0,0). They set $x=y$, which resulted in $f(x,x)=-x^3$, which has an inflection point at the origin, which is the 2D version of the saddle point. I have a few questions about this. How did they 'know' to set x=y, or is this a standard technique for these problems? ie: Set $x=f(y)$ and choose some convenient $f(y)$? In a geometric sense, what does setting $x=y$ mean? I'm having trouble visualising this.",['multivariable-calculus']
745234,Calculate rotation/translation matrix to match measurement points to nominal points,"I have two matrices, one containing 3D coordinates that are nominal positions per a CAD model and the other containing 3D coordinates of actual measured positions using a CMM. Every nominal point has a corresponding measurement, or in other words the two matrices are of equal length and width. I'm not sure what the best way is to fit the measured points to the nominal points. I need a way of calculating the translation and rotation to apply to all of the measured points that produce the minimum distance between each nominal/measured pair of points while not exceeding allowed tolerances on maximum distance at any other point. This is similar to Registration of point clouds but different in that each pair of nominal/measured points has a unique tolerance/limit on how far apart they are allowed to be. That limit is higher for some pairs and lower for others. I'm programming in .Net and have looked into Point Cloud Library (PCL), OpenCV, Excel, and basic matrix operations as possible approaches.
This is a sample of the data X Nom    Y Nom  Z Nom   X Meas  Y Meas  Z Meas  Upper Tol   Lower Tol
118.81  2.24    -14.14  118.68  2.24    -14.14  1.00    -0.50
118.72  1.71    -17.19  118.52  1.70    -17.16  1.00    -0.50
115.36  1.53    -24.19  115.14  1.52    -23.98  0.50    -0.50
108.73  1.20    -27.75  108.66  1.20    -27.41  0.20    -0.20 Below is the type of matrix I need to calculate in order to best fit the measured points to the nominal points. I will multiply it by the measured point matrix to best fit to the nominal point matrix. Transformation  
0.999897324 -0.000587540    0.014317661
0.000632725 0.999994834 -0.003151567
-0.014315736    0.003160302 0.999892530
-0.000990993    0.001672040 0.001672040","['matrices', 'least-squares', 'rigid-transformation']"
745245,"How to read $\bigcap\limits_{r=1}^{\infty}\bigcup\limits_{k=1}^{\infty}\bigcap\limits_{n,m\ge k}^{\infty}\{x:|f_n-f_m|<\frac{1}{r}\}$","Can somebody explain me step by step why does this $\bigcap\limits_{r=1}^{\infty}\bigcup\limits_{k=1}^{\infty}\bigcap\limits_{n,m\ge k}^{\infty}\{x:|f_n-f_m|<\frac{1}{r}\}$ represents the set of points, where $f_n$ converges to $f$ (Assume $f_n\to f$ as $(n\to \infty)$) Since $f_n$ converges the sequence is Cauchy and therefore there exists a $k$, such that for $n,m\ge k$ their difference is smaller than $r$ and then why do we take the union of all $k$'s and then intersect with all $r$'s in which order do we have to increase the indices ?","['functions', 'convergence-divergence', 'real-analysis']"
745249,Stopping time question $\sigma$,"If $S$ and $T$ are stopping time, $S \vee T$ is $\max ({S,T})$, $F_S$ and $F_T$ are stopped sigma algebra, show that $F_{S \vee T} = \sigma(F_S,F_T)$. My thinking : I should take a set $A$ in $F_{S \vee T}$ and show it is in  $\sigma(F_S,F_T)$. I also notice that if $A$ is in $F_{S \vee T}$ then $A \cap\{S\le T\}$ is in $F_T$","['probability-theory', 'measure-theory', 'stopping-times']"
745282,Almost everywhere convergence of some series,Let $\{r_n\}$ be an arbitrary numerical sequence. Prove that $\sum_{n=1}^\infty\frac{1}{2^n\sqrt{|x-r_n|}}$. Prove that it converges almost everywhere on $\Bbb R$.,"['complex-analysis', 'real-analysis']"
745305,translation of open set problem,"Suppose U is an open set in an Euclidean space. Then any point in U is contained in all but finitely many open sets that is translated by vectors converging to zero. It is easily proved in one dimensional euclidean space, but i can't prove it generally...","['general-topology', 'analysis']"
745306,Mean time spent in transient states/Markov chain,"I dont get this in my book: For transient states $i$ and $j$ , let $s_{ij}$ denote the expected number of time periods that the markov chain is in state $j$ , given that it starts in state $i$. Let $\delta_{i,j} = 1$ when $i = j$ and let it be $0$ otherwise.Condition of the initial transition to obtain: $s_{ij} = \delta_{i,j} + \sum_k P_{ik}s_{kj} = \delta_{i,j} + \sum\limits^t P_{ik}s_{kj} $ can someone show me how , if i condition of the initial transition, obtain the above equation ?  or explain in how do interpret the equation?","['statistics', 'stochastic-processes', 'markov-chains', 'probability']"
745416,Volume integral help,"I have a volume integral to compute with the following bounded volume $V\in \mathbb{R}^3$ $$ \frac{x^2+y^2}{4}+z^2\leq 1 \;\;,\;\; \frac{1}{2} \sqrt{x^2+y^2}\leq z\;,\;\; z\geq 0$$
I hadn't a clue how to do it until my lecturer said to use spherical coordinates $$\widetilde{r}(r,\theta,\phi)=\begin{pmatrix} 2rsin{\phi}cos{\theta} \\ 2rsin{\phi}sin{\theta} \\ rcos{\phi} \end{pmatrix}\;\;\;\;\;\; \phi:\left[0,\frac{\pi}{4}\right], \theta:\left[0,2\pi\right], r:[0,1]$$ As the cone cuts out the ellipsoid at $\frac{\pi}{4}$. However I'm having a hard time trying to show that the cone cuts out the ellipsoid at $\frac{\pi}{4}$ mathematically though. Also I don't see why $r$ is only from $[0,1]$ rather than $[0,2]$ as the largest value of $r$ is $2$ and occurs when the ellipsoid and cone intersect. Any help or hints? I've shown that it cuts the ellipsoid at $z= \frac{1}{\sqrt{2}}$ and therefore $x^2+y^2=2$ on that plane, however I can't seem to find the angle. EDIT: Managed to find a way to compute the volume, answer is below.",['multivariable-calculus']
745455,What is the Taylor series of $\frac{1}{\sin(z)}$ about $z_0 = 1$?,This was a exam question so I know it cannot take too long to write out the proof. Only I cannot see an answer. I would imagine you write $\sin(z) = \sin(1+(z-1)) = \sin(1)\cos(z-1) + \sin(z-1)\cos(1)$ and then use the everywhere-defined Taylor series for $\sin$ and $\cos$ to write $\frac{1}{\sin(z)}$ as the reciprocal of a power series. Then you manipulate it into the form $\displaystyle \frac{1}{1-P(z)}$ where $P$ is a power series and then invert using the geometric series formula. Only my $P$ looks horrible and thus the condition for convergence $|P(z)|<1$ is impossible to compute. Another series which I cannot do but which I imagine could be done by similar methods is $\displaystyle \frac{1}{2\cos(z) -1}$ about $z_0 = 0$. Any tips?,"['laurent-series', 'power-series', 'complex-analysis', 'trigonometric-series']"
745488,Is the rhombic dodecahedron the only isohedral polyhedron that tiles 3-space (other than the cube)?,"Is the rhombic dodecahedron the only face-transitive (or isohedral , i.e. all faces are the same) polyhedron that seamlessly tiles 3-dimensional Euclidean space (other than the cube)? I'm looking for an answer to this question and although Wikipedia provides a lot of lists for 3-tesselations I cannot find a definite closure. In particular, if the above statement were true I'd expect it to be listed on the tesselation's Wiki page, but no such statement exists, which leaves some doubt in me whether it is actually the case.","['geometry', '3d', 'tiling', 'polyhedra', 'tessellations']"
745496,Simple algebra in a differential equation.,"I have the differential equation: $$\frac{dy}{dx}=\sin (x-y).$$ Substituting $v=x-y$ and $dy=dx-dv$, I got down to the equation:$$\frac{dv}{1-\sin(v)}=dx.$$
Multiplying the LHS by $\dfrac{1+\sin (v)}{1+\sin(v)}$, I got:$$(\sec^2(v)+\tan (v)\sec (v))dv=dx.$$
This is an easy integral, and I got that $x=\tan(v)+\sec(v)$, with some constant of integration.
Now, doing this in Maple gives the result: $$\frac{2}{1-\tan(\frac{v}{2})}=x,$$
where there should be some constant of integration. Now, I need to use ""simple"" algebra to show that the equation from Maple leads to: $$x=\frac{1+\tan(\frac{v}{2})}{1-\tan(\frac{v}{2})}+C.$$
How do I show that those two equations are equal? I cannot see the simple algebra that needs to be done.","['ordinary-differential-equations', 'calculus', 'integration', 'computer-algebra-systems']"
745534,Ham-sandwich cut of red points and blue points in the plane.,"For a finite set of points in the plane, each colored ""red"" or ""blue"", there is a line that simultaneously bisects the red points and bisects the blue points, that is, the number of red points on either side of the line is equal and the number of blue points on either side of the line is equal.
Can somebody tell me a proof of this result using the ham-sandwich theorem or Borsul-Ulam Theorem or some algebraic topology tool?
Wikipedia page of Ham Sandwich Theorem ( http://en.wikipedia.org/wiki/Ham_sandwich_theorem )
suggests there is such a prooof!
Thanks in advance!","['algebraic-topology', 'combinatorics']"
745560,Proof two solutions of a differential equation are linear independent,"Given two solutions for a second order diferential equation: $y(x)=e^{a x}$ and $y(x)=x e^{a x}$ How to show these are linear independent? I procede as follow applying the definition of linear independence: $A e^{a x} + B x e^{a x} = 0$ $ \forall x$ Then: $A  + B x  = 0$ Here i dont know exactly how to conclude in a ""formal"" way that $A=B=0$ are the only solutions and hence the two functions are linear independent.","['linear-algebra', 'differential-geometry']"
745583,Intuition behind Descartes' Rule of Signs,"I have read several places that Descartes' Rule of Signs was familiar to both Descartes and Newton, and that both considered it too ""obvious"" to merit a proof. I know how to prove it, but I would like to know how they intuitively sensed that it was true. Newton apparently used it in one of his books, so he must have had a good reason to believe it was true if he never bothered to attempt a proof. Just for clarification, I am referring to the theorem that the number of positive roots of the polynomial
$$p(x)=a_nx^n+⋯+a_1x+a_0$$
is equal to or less than by an even number the number of sign changes in p as written in the order above (descending powers of x).","['algebra-precalculus', 'intuition', 'polynomials']"
745597,How to find the value of $\sqrt{1\sqrt{2\sqrt{3 \cdots}}}$?,"I thought up this question recently, and I think I've figured out the partial sum:
$$
S_n := \left(n\prod_{k=2}^{n-1} k^{2^{n-k}}\right)^{2^{-k}}.
$$
But I don't even quite know if I'm on the right track. If I am, how do I find the limit of the above equation, and if not, how can I find it another way? Thanks.","['calculus', 'products']"
745642,Find the integral curves of the given vector field.,"The vector field is as follows: $X_{(x,y)} = x \dfrac{\partial}{\partial x} - y \dfrac{\partial}{\partial y} = \begin{bmatrix} x \\y \end{bmatrix}$. I know that to find integral curves, you need to solve a differential equation. So here, I would take a derivative of $X$, but I am not completely sure of what to do. With other integral curve computations, I'm usually given some initial conditions. Tips on how to get started would be very helpful. That's really all I'm asking for here. I can do the rest of the math myself. I'm just struggling setting it up.","['manifolds', 'differential-geometry']"
745647,Counting the dimension of a component of $\mathsf{hilb}^{2t+1}_{3}$,"Consider the Hilbert scheme $\mathsf{hilb}^{2t+1}_{3}$, parametrizing varieties of degree $2$ and genus $0$ in $\mathbb{P}^{3}_{k}$, with $k$ an algebraically closed field. Consider the component $
\quad \quad \mathsf{hilb}_{\text{conic}}=\{ p\in \mathsf{hilb}^{2t+1}_{3}\ |\ \text{the corresponding variety is a curve in $\mathbb{P}^{3}_{k}$}\}
$ My goal is to prove that such a component is irreducible of dimension $8$. I am not sure how to prove the irreducibility. To prove that $\dim (\mathsf{hilb}_{\text{conic}})=8$, one way would be to show that any conic can be obtained as the complete intersectio of a quartic and a hyperplane. However, in the context that I am working in, I would rather proceed in another way, and use the following $\mathbf{Lemma.}$ Any conic $C\in \mathbb{P}^{3}_{k}$ is a complete intersection of a plane $L$ and a quadric surface $S$. Does anyone know how to compute the dimension of $\mathsf{hilb}_{\text{conic}}$, using only the lemma above, and not other classical results concerning the nature of quadrics in projective space?","['algebraic-geometry', 'conic-sections', 'schemes']"
745661,How many functions defined on $n$ points are possible if each functional value is either $0$ or $1$?,"How many functions defined on $n$ points are possible if each functional value is either $0$ or $1$? This is from the text A First Course on Probability by Sheldon Ross. The solution he provides is: Let the points be $1,2,...,n$. Since $f(i)$ must be either $0$ or $1$ for each $i=1,2,...n,$ it follows that there are $2^n$ possible functions. I don't understand where he gets $2^n$ from...can you elaborate more on this? 
Is there a different way to solve this problem, a longer, more detailed, and clearer way? Thanks.","['probability', 'functions', 'combinatorics']"
745741,Differential Equation has a unique solution periodic,"Let $A(t)$ continuous and periodic of period $S$ in $\mathbb{R}$. Suppose $x' = Ax$ has $\varphi \equiv 0$ as the only periodic solution of period $S$. Show that there exists $\delta> 0$ such that for every continuous function $f:\mathbb{R} \times E \longrightarrow E $, $S$ period of periodic with variable the first $|D_2f(t,x)|<\delta$ to all $(t,x)$ so $x' = A(t)x + f(t,x)$ has a unique periodic solution $\varphi_f$ of period $S$ also prove that if $f\rightarrow0$ uniformly then $\varphi \rightarrow 0$ uniformly.","['ordinary-differential-equations', 'periodic-functions', 'analysis']"
745756,Geometrical Meaning of derivative of complex function,"What's the geometrical meaning of $f'(z)$ in complex analysis, as we know in real analysis $f'(x)$ has meaning ie. Slope of curve or gives max/ min. But what does derivative $f'(z)$ has geometrical meaning in complex analysis","['complex-analysis', 'analysis']"
745772,Fundamental matrix of OED.,"Let $\phi(t)$ be a $n \times n$ matrix whose elements are functions of class $C ^ 1$, no singular for all $t \in \mathbb{R}$. Show that there exists a unique matrix $A(t)$ continuous such that $\phi(t)$ is fundamental matrix of $x' = A(t)x$",['ordinary-differential-equations']
