question_id,title,body,tags
2970970,Find the probability that the pedestrian has to wait for exactly $4$ seconds before starting to cross.,"From Statistical Inference (2nd edition) by Casella Berger The flow of traffic at certain street corner can sometimes be modelled as a sequence of Bernoulli trails by assuming that the probability of a car passing during any given second is a constant $p$ and that there is no interaction between the passing of cars at different seconds. If we treat seconds as indivisible time units (trials), the Bernoulli model applies. Suppose a pedestrian can cross the street only if no car is to pass during the next $3$ seconds. Find the probability that the pedestrian has to wait for exactly $4$ seconds before starting to cross. The suggested answer is: $$(1-p(1-p)^3)(1-p)^3$$ And the reasoning is that: the last three seconds must have no car passing (explains the last $(1-p)^3$ ). In considering what happened to the first four seconds, we have to exclude the situation in which the first-second having car passing and the last three seconds having no car passing (explains the term $1-(1-p)^3$ ). Assuming independence between two parts, we multiply these two terms together to get the probability required. However, I find answer $(1-(1-p)^3)p(1-p)^3$ makes better sense. The reasoning is that if we want the pedestrian to wait for exactly $4$ seconds, the fourth second must have car passing, otherwise the pedestrian would cross the street one second earlier. Could someone please explain to me why the first answer is the correct one and what are the points that I have missed when I provides the alternative explanation?",['probability']
2971009,Is $\frac{x^2y^2}{\sqrt{x^2+y^2}}$ continuous?,"Let $f: \mathbb{R}^2 $ -> $\mathbb{R}$ I was wondering if this function is a continuous function. Can I just say that $\frac{x^2y^2}{\sqrt{x^2+y^2}}$ is continuous everywhere except perhaps at $x=0$ , because $\lim_{x\rightarrow \infty}$ $\frac{x^2y^2}{\sqrt{x^2+y^2}}$ = $\infty$ , and the definition is that if $\lim_{x\rightarrow c}$ $f(x)$ = $f(c)$ then $f(x)$ is continuous at $c$ .","['limits', 'multivariable-calculus', 'continuity']"
2971036,Shortest Algorithm That Generates a Harlequin* Pattern,What is the shortest possible length of an algorithm that generates on each side of the cube a pattern that has: 6 colors at most 2 facelets of the same color no adjacent facelets of the same color What is the algorithm (or algorithms)? * I don't know if that's how such a pattern is called but I had to keep the title as concise and as descriptive as possible.,"['group-theory', 'rubiks-cube']"
2971038,Intuitive understanding of the binomial theorem? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 months ago . Improve this question I'm trying to understand the thought process, of how I might come upon the binomial theorem intuitively by thinking about combinatorics, can someone help?","['binomial-theorem', 'combinatorics']"
2971070,Derivation of the bivariate normal distribution,"I am reading through a derivation of the bivariate normal distribution, (from the US Defence Department!) and came across an expression that I can't understand. The derivation starts off with the observation that the total area, $A$ , under the curve of the distribution is $1$ , since it is a probability distribution.  Also, the distribution can be expressed as a differential equation: $$dy=-k \ xy \ dx \tag{1}$$ $$y= Ce^{-k{x^2\over2}} \tag{2}$$ $$A= C\int_{-\infty}^{\infty}e^{-k{x^2\over2}}  \tag{3}$$ Using integration by parts, the text proceeds to evaluate $$A= C|e^{-k{x^2\over2}}|_{-\infty}^{\infty}+C\int_{-\infty}^{\infty}x^2e^{-k{x^2\over2}}  \tag{4}$$ (I skipped some steps for brevity. Please tell me if that creates confusion.) Then the text says the following line: Since the first expression takes an indeterminate form, new
  numerators and denominators are obtained by independent derivatives, and the
  limiting value of the expression then becomes zero. Since, by definition,
  the n-th moment of a frequency distribution is defined as $$\text {n-th moment} = \int_{b}^{a}x^n f(x)dx$$ and since from fundamental principles the standard deviation is the square
  root of the second moment about the mean, then it follows, considering $(3)$ ,
  that the second expression in $(4)$ becomes $$A=Ak\sigma_X^2 \tag{5}$$ I think I understand how we got rid of the first expression $C|e^{-k{x^2\over2}}|_{-\infty}^{\infty}$ in $(4)$ , but what I don't understand is, how does this last step, $(5)$ , follow from the previous steps? Also, where did the $C$ go?","['statistics', 'probability-distributions', 'probability-theory', 'probability']"
2971078,Proof that $\sum_{k=0}^{n}\frac{(-1)^k}{2k+1}{n\choose k}=\frac{4^n}{(2n+1){2n\choose n}}$ [duplicate],"This question already has answers here : How to apply induction to this formula? (4 answers) Closed 5 years ago . I saw in this paper the following identity: $$\sum_{k=0}^{n}\frac{(-1)^k}{2k+1}{n\choose k}=\frac{4^n}{(2n+1){2n\choose n}}$$ I have a pervious post on an integral quite closely related to this identity, but I still do not know how to derive/prove the identity. I'm really not that good at combinatorics or evaluating series, so I don't know how to start, which is why I don't have any attempts to show you. Please explain your steps thoroughly. Edit: I know there other posts on this series, but I did not get from them the proof I was satisfied by.","['proof-explanation', 'combinatorics', 'sequences-and-series']"
2971102,Is $|\frac{y}{x^2}|\exp(- |\frac{y}{x^2}|)$ continuous?,"Let $q: \mathbb{R}^2 \to\mathbb{R}$ such that $$
q(x,y):=\begin{cases}\left|\frac{y}{x^2}\right|\exp\left(-\left|\frac{y}{x^2}\right|\right),&\text{ for }x\neq 0\\0,&\text{ for }x=0\end{cases}
$$ Can I say that for all $x$ and $y$ and for all $\epsilon>0$ , there exists $\delta>0$ such that if $|q(x,y)−c|<δ$ , then $|q(x,y)−q(c)|<ϵ$ . So since $\exp$ is defined everywhere on $\Bbb R$ , let $c \in \Bbb R$ and let $\epsilon>0$ . But how do I find a corresponding $\delta>0$ ? Or is that already totally wrong?","['continuity', 'multivariable-calculus', 'functions', 'exponential-function']"
2971119,What is the maximum value of $n$ with average value must be an integer?,"Let $M$ be a positive integer greater than $1$ . All integers from $1$ to $M$ were written on a board. Each time we erase a positive integer on the board in a way that the average value of all numbers that have been erased must always be an integer. Assume that there are $n$ numbers that have been erased ( $1 \leq n \leq M$ , $n$ is not a constant number). The process will end with $n$ numbers if and only if it is impossible to erase the $(n+1)th$ number so that the average value of $n+1$ erased numbers can be an integer. For all possible ways to erase the numbers, what is the maximum and the minimum value that $n$ can reach? For example, with $M=3$ , we have the maximum of $n$ is $3$ (choose $a_1=1$ , $a_2=3$ , $a_3=2$ ) , the minimum value of $n$ is $1$ (choose $a_1=2$ , then it is impossible to choose $a_2=1$ or $a_2=3$ because $\frac{2+1}{2}, \frac{2+3}{2}$ are not integers). For larger $n$ , I thought that I can solve with Chinese Remainder Theorem, but I didn't know how to use it. Is it possible to find the minimum or maximum value of $n$ ?. If not, what are the conditions of $M$ so that the minimum or maximum value of $n$ can be found? (Sorry, English is my second language, so the questions may unclear for some readers)","['number-theory', 'average', 'combinatorics', 'elementary-number-theory']"
2971122,Extended limit laws for step by step evaluation of limits,"Most textbooks of calculus / real analysis present a version of limit laws which help us to infer about limit of sum or product of functions provided the limits of individual functions are known to exist. Such rules also go by the name algebra of limits . In this post and my answer to it I provide an extended version of these laws which are more helpful in step by step evaluation of a limit. Before I state those laws it is better to give some introductory remarks. If $f$ is a real valued function defined in certain deleted neighborhood of point $a$ then the limiting behavior of $f(x) $ as $x\to a$ can be of one of the following types: $\lim_{x\to a} f(x) $ exists. Although it is redundant to state, to avoid confusion / ambiguity this means that the limit exists as a finite real number. We also say that $f(x) $ converges to a real number as $x\to a$ . Example $\lim_{x\to 0}x$ . $f(x) \to \infty $ as $x\to a$ . We say that $f(x) $ diverges to $\infty $ as $x\to a$ and some prefer to write this in symbols as $\lim_{x\to a} f(x) =\infty$ . Example $\lim_{x\to 0} (1/x^2)$ . $f(x) \to - \infty $ as $x\to a$ . We say that $f(x) $ diverges to $-\infty $ as $x\to a $ and some prefer to write this in symbols as $\lim_{x\to a} f(x) =-\infty$ . Example $\lim_{x\to 0} (-1/x^2)$ . $f(x) $ oscillates finitely as $x\to a$ . More formally this means that $f$ is bounded in some deleted neighborhood of $a$ and there exist at least two distinct real numbers $A$ and $B$ and two sequences $\{a_n\}, \{b_n\} $ of numbers in the deleted neighborhood of $a$ such that $$\lim_{n\to\infty} a_n=a=\lim_{n\to\infty} b_n$$ and $$\lim_{n\to\infty} f(a_n) =A, \lim_{n\to\infty} f(b_n) =B$$ Example $\lim_{x\to 0}(1/x)-\lfloor 1/x\rfloor$ . $f(x) $ oscillates infinitely as $x\to a$ . This means that there is a sequence $\{a_n\} $ of numbers in deleted neighborhood of $a$ such that $$\lim_{n\to\infty} a_n=a, \lim_{n\to \infty} |f(a_n) |=\infty$$ and yet neither $f(x) \to\infty $ nor $f(x) \to-\infty $ as $x\to a$ . Example $\lim_{x\to 0}(1/x)\sin(1/x)$ . The above list is exhaustive and consists of mutually exclusive possibilities. Sometimes the second and third options are combined together and one says that $f(x) $ diverges as $x\to a$ . Similarly the fourth and fifth options can be combined to say that $f(x) $ oscillates as $x\to a$ . Now we come to extended limit laws. Theorem 1 : Let $f, g$ be functions defined in a certain deleted neighborhood of $a$ and let $\lim_{x\to a} f(x) $ exist and be equal to $L$ . Then the limiting behavior of $f(x) \pm g(x) $ as $x\to a$ is of exactly the same type  as that of $g(x) $ and we can write $$\lim_{x\to a} \{f(x) \pm g(x) \}=\lim_{x\to a} f(x) \pm\lim_{x\to a} g(x) =L\pm\lim_{x\to a} g(x) $$ The case of divergence can be same or opposite (as regards to sign of $\infty$ ) depending on the sign $\pm$ which combines $f, g$ . Theorem 2 : Let $f, g$ be defined in a certain deleted neighborhood of $a$ and let $\lim_{x\to a} f(x) =L\neq 0$ . Then the limiting behavior of $f(x) g(x) $ as $x\to a$ is of exactly the same type as that of $g(x) $ and we can write $$\lim_{x\to a} f(x) g(x) =\lim_{x\to a} f(x) \cdot \lim_{x\to a} g(x) =L\lim_{x\to a} g(x) $$ The case of divergence can be same or opposite according as $L>0$ or $L<0$ . Also the case of convergence holds when $L=0$ but other cases can't be guaranteed when $L=0$ . Both these theorems can be used to evaluate the limit of a complicated expression in a step by step manner by handling one term or one factor at a time whose limit is known thereby reducing the expression to a simpler form at each step. Each step is justified on the basis of the term/factor whose limit is known irrespective of the behavior of other terms/factors. Moreover the theorems indicate that each step is reversible and hence holds unconditionally. This is better than using the standard limit laws which basically say that the limit has to be applied simultaneously on each part of the expression on the condition that each part has a limit and parts occurring as denominator have non-zero limit. I will provide proof of one of the theorems as an answer (to be marked community wiki). I expect users to provide other point of views regarding these theorems and any improvements in my question and answer are also welcome. Note : The above is a more formal and detailed version of the rules presented in this answer and it is based on a request in a comment to another question.","['limits', 'calculus', 'real-analysis']"
2971133,Moment of Inertia of a Tetrahedron about the X-axis and its Centroid.,"My task is to compute the moment of inertia and the radius of gyration of a constant-density tetrahedron defined by $x,y,z\ge0$ and $\frac xa + \frac yb + \frac zc \leq 1$ about the x-axis. I know that the moment of inertia, $I$ , of an object is defined by: $I=\int_RdI$ over some region of integration R. Here, I'd let R be the volume of the tetrahedron. Then, $dI = r^2dM$ for mass element $dM=ρ(x,y,z)dV$ for some density constant density $ρ(x,y,z) = k$ . So, we should have: $I = \int_0^c \int_0^{b- \frac bcz} \int_0^{a- \frac aby - \frac acz} ρ(x,y,z)r^2dxdydz$ $r^2$ should represent the distance from any point in the tetrahedron to the x-axis, so we can (I think) let $r^2=y^2+z^2$ . Hence: $I = k\int_0^c \int_0^{b- \frac bcz} \int_0^{a- \frac aby - \frac acz}(y^2+z^2)dxdydz$ . From here, I would compute $I$ and then I would be able to calculate the radius of gyration, $r_g$ , where $r_g=\sqrt{\frac IM}$ . This integral looks unnecessarily complicated and I'm not sure if I set it up correctly. Any idea where I might have gone wrong?","['integration', 'classical-mechanics', 'multivariable-calculus', 'calculus', 'physics']"
2971204,Intuition behind the construction of a tail $\sigma$-field,"Before starting I should note that I've already read this , this , this and this , and none of them quite provide the intuition I seem to be missing. I've tried to provide as many details related to my own thought process to see if we can diagnose this misunderstanding more specifically. I just started learning about Kolmogorov's zero-one law, and (not unlike many people who first encounter it I suppose), I'm having trouble wrapping my head around the concept of a tail field . In particular, if we have a sequence of events $A_n\in\mathcal{F}$ , then the tail field $\tau$ is defined as $$
\tau = \bigcap_{n=1}^\infty\sigma(A_n, A_{n+1},\cdots)
$$ First, I'm slightly confused as to how $\tau$ is a $\sigma$ -algebra at all (though I think I can check this myself). What I'm really struggling with is simply how to interpret this definition. To me, it seems like $\tau$ should be empty, even though I know it's clearly not as $\limsup_n A_n\in\tau$ (and I understand the proof behind why). As far as I understand, if $A\in\tau$ , then $A\in\sigma(A_n,A_{n+1},\cdots)$ for every $n\in\mathbb{N}$ . So any $A\in\tau$ can't depend on the first $A_1,\cdots, A_n$ events for any $n$ . The problem is that I have no intuition for what kinds of sets behave this way. It seems to me like if you have any formula for $A$ involving the sets $A_n$ , then there has to be a minimum $n_0$ for which $A_{n_0}$ is involved in the formula for $A$ , but this means $A\not\in\sigma(A_{n_0+1},A_{n_0+2},\cdots)$ , meaning $A\in\tau$ . So, in my head, $\tau$ can't contain any set that can be written in terms of the $A_n$ 's. As I said above, I know this is false, as $\limsup_n A_n$ and $\liminf_n A_n$ are in $\tau$ . To be honest, the more I think about it the less sense the definitions of these two sets seem to make to me as well. I mean, what does $\limsup_n A_n$ even look like if it supposedly doesn't depend on any of the $A_n$ 's? If it doesn't depend on any of the $A_n$ 's, then $\limsup_n A_n = \limsup_n B_n$ for any two sequences of events $A_n$ and $B_n$ , no? I guess the flaw in my logic has to do with the idea of ""dependence"". I know there are events in $\limsup_n A_n$ , and the logical proposition giving the inclusion of an element in $\limsup_n A_n$ does depend on the $A_n$ 's, so what I said above makes no sense (obviously). But something is still wrong in my head, and I want to figure out how to right it. Can anyone see where the flaw in my logic is?",['probability-theory']
2971225,Breakdown of Analytical Solution to 4th order ODE,"The Problem: I have the 4th order Ordinary Differential Equation $$
\frac{\text{d}^4\theta}{\text{d}\eta^4}
+R(\theta-\theta_*)=0
$$ in the interval $0\le\eta\le1$ , subject to the boundary conditions $$
\eta=0: \frac{\text{d}\theta}{\text{d}\eta}=-1 ;
        \frac{\text{d}^2\theta}{\text{d}\eta^2}=0
$$ $$
\eta=1: \frac{\text{d}\theta}{\text{d}\eta}=0 ;
        \frac{\text{d}^2\theta}{\text{d}\eta^2}=0
$$ and where $\theta_*$ is to be determined such that the clamping constraint $$\theta(\eta=0)=0$$ is satisfied. Skipping details, it can be shown that the solution to the differential equation is $$
\theta=\theta_* + e^{P(\eta-1)}(A\cos P\eta+B\sin P\eta)
+e^{-P\eta}(C\cos P\eta+D\sin P\eta)
$$ where $P=\frac{R^\frac{1}{4}}{\sqrt{2}}$ and (skipping details again) the constants $A,B,C,D$ and $\theta_*$ can be determined from the boundary conditions and constraint. So far, so good. The issue: The solution works beautifully, until $R$ approaches $10^7$ whereupon it breaks down due to what I believe is the stiffness of the differential equation - the difference between the largest and smallest roots of the characteristic equation is of the order of $2P$ ~ $R^\frac{1}{4}$ . This is also apparent from the original differential equation itself, where as $R$ becomes very large $\theta \rightarrow \theta_*$ which tends to violate the Neumann boundary condition $\frac{\text{d}\theta}{\text{d}\eta}(\eta=0)=-1$ . What I find very odd however, is that the breakdown in the analytical solution is manifested not at $\eta=0$ , where the Neumann BC is actually satisfied very well, but by blowing up in the vicinity of $\eta=1$ . This is evident in the graphic below: My Question Given that the analytical solution tends to break down at large $R$ , how much confidence can I place in the computed values in the vicinity of $\eta=0$ . The Neumann condition at $\eta=0$ certainly seems to be honoured for $R=10^7$ , but I'm a bit circumspect about the correctness of the peak value in the second derivative (right plot in the graphic above). Any advice? Thanks in advance. Note that in practice, I clamp the value of $\eta$ used to compute $\theta$ and its derivatives at $\eta=1.1-0.1\log_{10}R$ , for $R\ge 10^6$",['ordinary-differential-equations']
2971279,"What changes in the sheaf theory of topological spaces with the ""étale topology""?","The customary site structure on the category of topological spaces has covering families given by open covers. What ""happens"" if we refine this topology and let any jointly surjective family of local homeomorphisms be covering? Refining the Zariski topology has lots of interesting consequences, so I wonder what kind of thing happens for topological spaces.","['general-topology', 'grothendieck-topologies', 'sheaf-theory']"
2971282,Way to solve $\int\limits _0^\limits\infty \frac{x^{-t}}{1+x}\ dx$,"Is there a direct way to prove that, for $t\in (0,1)$ $$\int\limits _0^\limits\infty \dfrac{x^{-t}}{1+x}\ dx=\dfrac{\pi}{\sin \pi t}$$ Without using Mellin transform?","['integration', 'improper-integrals', 'real-analysis']"
2971313,Prove that every even degree polynomial function has a maximum or minimum in $\mathbb{R}$,"Prove that every even degree polynomial function $f$ has maximum or minimum in $\mathbb{R}$ . (without direct using of derivative and making $f'$ ) The problem seems very easy and obvious but I don't know how to write it in a mathematical way. For example if the largest coefficient is positive, it seem obvious to me that from a point $x=a$ to $+\infty$ the function must be completely ascending. And from $-\infty$ to a point $x=b$ the function must be completely descending. If it is not like that, its limit will not be $+\infty$ at $\pm\infty$ . Now, because it is continuous, it will have a maximum and minimum in $[b,a]$ so it will have a minimum (because every other $f(x)$ where $x$ is outside $[b,a]$ is larger than $f(a)$ or $f(b)$ and we get the minimum that is less than or equal to both of them) . We can also the same for negative coefficient. But I can't write this in a formal mathematical way.","['maxima-minima', 'functions', 'polynomials', 'real-analysis']"
2971315,How do I combine standard deviations of two groups?,"I have 2 groups of people. I'm working with the data about their age. I know the means, the standard deviations and the number of people. I don't know the data of each person in the groups. Group 1 : Mean = 35 years old; SD = 14; n = 137 people Group 2 : Mean = 31 years old; SD = 11; n = 112 people I want to combine those 2 groups to obtain a new mean and SD. It's easy for the mean, but is it possible for the SD? I do not know the distribution of those samples, and I can't assume those are normal distributions. Is there a formula for distributions that aren't necessarily normal?","['statistics', 'standard-deviation']"
2971322,Convergence of (unbounded) self-adjoint operators,"I'm learning about the dynamical convergence (i.e, convergence of the unitary group associated with each operator) and resolvent convergence of (unbounded) self-adjoint densely defined operators. I can understand the proof of the initial results, but I can't notice what is the motivation for this. One motivation that I have seen was the following: if $(T_{n})_{n\in\mathbb{N}}$ and $T$ are (unbounded) self-adjoint densely defined operators in a Hilbert space $H$ , then the intersection of the domains could be only the null vector, thus the convergence $T_{n}v\to Tv$ will be true for all, possible, $v$ , since $v$ is just allowed to be $0$ , the convergence is gonna be true. I'm theoretically satisfied with this intuition, but I can't find an example to show that possibility, i.e, a sequence like that with $dom(T)\cap\biggl(\bigcap_{n\in\mathbb{N}}dom(T_{n})\biggr) = \left \{0\right \}$ Just to add some reference on my question, it can be found on ""César R. de Oliveira, Intermediate Spectral Theory and Quantum dynamics, Chapter 10"".","['self-adjoint-operators', 'hilbert-spaces', 'functional-analysis', 'unbounded-operators', 'spectral-theory']"
2971348,quant interview: (mathematical modelling) linear regression and statistical significance,"I am preparing a quantitative finance interview and I am struggling with this exercise: Consider two data series, X = (x1, x2, . . . , xn) and Y = (y1, y2, . . . , yn), both with mean zero. We use linear regression (ordinary least squares) to regress Y against X (without fitting any intercept), as in Y = aX + $\epsilon$ where $\epsilon$ denotes a series of error terms. Suppose that ρXY = 0.01. Is the resulting value of a statistically significantly different from 0 at the 95% level if: i. $n = 10^2$ \
ii. $n = 10^3$ \
iii. $n = 10^4$ \ I already know the relation between a and $\rho$ is given by $$a = \frac{\rho_{XY}}{\sigma_X}$$ But I am struggling with the confidence level part. Any help would be appreciated. Thank you!","['linear-regression', 'statistics', 'confidence-interval']"
2971375,From root and weight lattices of SU(N) to $\theta$-functions as sections of a line bundle and $CP$-space,"I have troubles to digest the following messages/discussions in the following work in p.10-12 ;
Which construct a map from the moduli space of flat connections $M_{\rm flat}=\mathbb{E} / {\mathfrak S}_N \to CP^{N-1}$ to the projective space explicitly. My questions: What are the purposes of using the root and weight lattices of SU(N) here? $\theta_k$ are usually theta fuctions. But they emphasize $\theta_k$ are not functions, but sections of a line bundle $L$ . Why is that? Their discussions are detailed below: We now make the map $M_{\rm flat}=\mathbb{E} / {\mathfrak S}_N \to CP^{N-1}$ more explicit. We denote the root lattice of $SU(N)$ by ${\mathbb L}$ $$
{\mathbb L}=\left\{ \vec{\ell} =(\ell_1, \cdots, \ell_N) \in \mathbb Z^N; \sum_i \ell_i=0 \right\}\;. 
$$ The weight lattice is spanned by the fundamental weights $$
\vec{e}_k=(\overset{1}{1},\cdots,\overset{k}{1},0,\cdots,0) - \frac{k}{N}(1,\cdots,1)\;. 
$$ We define theta functions as $$
\theta_k(\vec{\phi}) :=  \sum_{ \vec{\ell} \in {\mathbb L}} e^{ \pi i \tau (\vec{\ell}+\vec{e}_k)^2+ 2\pi i (\vec{\ell}+\vec{e}_k) \cdot \vec{\phi}  } ~~~~~(k=1,\cdots,N)\;,
$$ where $\vec{\phi}=(\phi_1,\cdots,\phi_N)$ and the inner product between vectors is defined as $\vec{\phi}\cdot \vec{\ell}=\sum_i \phi_i \ell_i$ . 
  These theta functions are invariant under the Weyl symmetry ${\mathfrak S}_N$ acting on $\vec{\phi}$ , because each set $$
\vec{e}_k+{\mathbb L}=\{ \vec{e}_k+\vec{\ell} ; \vec{\ell} \in {\mathbb L} \}
$$ is Weyl invariant, and the Weyl symmetry preserves the inner product. Furthermore, under the shift $$
\vec{\phi} \to \vec{\phi} +\tau \vec{m} - \vec{n}~~~~~(\vec{m}, \vec{n} \in {\mathbb L}) \;,
$$ they transform as $$
\theta_k(\vec{\phi} + \tau \vec{m} - \vec{n}) =e^{ -\pi i \tau \vec{m}^2-2\pi i \vec{m} \cdot \vec{\phi}}\theta_k(\vec{\phi}) \;.
$$ Note that the factor $e^{ -\pi i \tau \vec{m}^2-2\pi i \vec{m} \cdot \vec{\phi}}$ is independent of $k$ . We denote points of $CP^{N-1}$ by using homogeneous coordinates as $[Z_1,\cdots,Z_N]$ .
  Then, if we define $$
\varphi (\vec{\phi}):=[\theta_1(\vec{\phi}), \cdots, \theta_N(\vec{\phi})] \;,
$$ then the above properties imply that this is a well-defined map from $M_{\rm flat}$ to $CP^{N-1}$ . We claim that this is an isomorphism between $M_{\rm flat}$ and $CP^{N-1}$ .","['projective-module', 'representation-theory', 'algebraic-geometry', 'theta-functions', 'projective-space']"
2971379,Is there a locally compact space which is not a k-space,"Definitions : A locally compact space is a space where every point has a local base of compact neighborhoods. A $k$ -space $X$ has its topology generated by maps from compact Hausdorff spaces, i.e. $C$ is closed iff for every compact Hausdorff space $K$ and every continuous function $f: K \to X$ , $f^{-1}[C]$ is closed in $K$ . Strickland's notes call this compactly generated . By compact I mean not necessarily Hausdorff. The reason I ask is that standard constructions of non $k$ -spaces for example the square of the one-point compactification of $\mathbb{Q}$ and the product $\mathbb{R}\setminus \{1,\frac{1}{2},\frac{1}{3}\} \times \mathbb{R}/\mathbb{Z}$ where the second quotient means identifying $\mathbb{Z}$ to one point, are usually not locally compact. I'm looking for a locally compact space which is not a $k$ -space.","['general-topology', 'algebraic-topology']"
2971385,"Uniform Distribution: Broken Stick, Ratio of Parts [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question A stick of length 1 is broken at a uniformly random point, yielding two pieces.
Let X and Y be the lengths of the shorter and longer pieces, respectively, and let R = X/Y
be the ratio of the lengths X and Y .
(a) Find the CDF and PDF of R.
(b) Find the expected value of R (if it exists).
(c) Find the expected value of 1/R (if it exists) I'm stuck on finding a PMF and CDF of R - how would I set this up?","['statistics', 'probability']"
2971408,"Calculating the residue of $\frac{10z^4-10\sin(z)}{z^3}, z(0) = 0$","$$\frac{10z^4-10\sin(z)}{z^3}, \quad z(0) = 0.$$ I've gotten that $$\operatorname{Res} = 0$$ but I'm not quite  sure if that is correct, or if I have even used a correct pathway towards it. How should one work around sine (or cosine, for that matter) during residue calculations?","['complex-analysis', 'residue-calculus']"
2971422,"What is the minimun faces that you need to make a polyhedron with all the faces equilateral triangles, but one(base) square? (not a Pyramid)","I'm not a Mathematical person, but I know some things. I can't imagine a polyhedron with those characteristics. That polyhedron do exists? Is it possible to make something like that? (for that is why I ask for the minimum faces, I want to build it for my own)
I'm thinking something like a Icosahedron but with a square base.
I want to build something like that, but I can't find the form, or how I do that.
All right, I hope that this question wasn't in vain.
Thank you for reading, and thank you in advance if you can response","['polyhedra', 'geometry']"
2971462,Projective limit of spaces of probability measures is bijective to the space of probability measures on a projective limit.,"Consider an arbitrary directed set $I$ , and let $(K_i,\varphi_i)_{i\in I}$ be a collection of compact topological dynamical systems. I.e each $K_i$ is a compact Hausdorff space and each $\varphi_i:K_i\to K_i$ is continuous. For each $i\leq j\in I$ let $\pi_{ij}:K_j\to K_i$ be a continuous homomorphism of dynamical systems. That is $\pi_{ij}\circ\varphi_j=\varphi_i\circ\pi_{ij}$ . Furthermore suppose that $\pi_{ii}=\operatorname{id}$ and $\pi_{ij}\circ\pi_{jk}=\pi_{ik}$ for all $i\leq j\leq k$ . We know that the inverse (or projective I believe) limit of this system exists. Explicitly $\varprojlim_{i\in I}(K_i,\varphi_i)=(K,\varphi)$ where $$K:=\left\{(x_i)\in\prod_{i\in I}K_i:\pi_{ij}x_j=x_i~\text{for all}~ i\leq j\right\}$$ and $\varphi=(\varphi_i)_{i\in I}:K\to K$ is defined in the natural way. It is not too difficult to show that $(K,\varphi)$ is a topological dynamical system on a compact space (equipping $K$ with the subspace topology of the product topology.) For any compact Hausdorff space $X$ let us denote $M(X)$ to be the set of all finite valued complex Baire measures on $X$ , and we know that these measures are regular. In particular we can define $M^1(X)$ to be the space of all Baire probability measures on $X$ . We also know if $\phi:X\to X$ is continuous then the space of $\phi$ invariant Baire probability measures on $X$ , $M^1_\phi(X)$ is nonempty. By the Riesz Representation theorem we can identify $M(X)$ with the dual of $C(K)$ , and by Banach Alaoglu we can deduce that $M_\phi^1(X)$ is weak* compact. In particular that means that we can define $M^1_\varphi(K)$ and $M^1_{\varphi_i}(K_i)$ for all $i\in I$ to be compact topological spaces, and if we consider the pushforwards $\pi_{ij*}$ for $i\leq j$ we have another inverse system $(M_{\varphi_i}^1(K_i),\pi_{ij*})$ of compact spaces, so can construct $\varprojlim_{i\in I}M_{\varphi_i}^1(K_i)$ . A nice (but I think tricky) exercise in Operator Theoretic Aspects of Ergodic Theory by Eisner et al. is to show that $M^1_\varphi(K)$ is affinely homeomorphic to $\varprojlim_{i\in I}M_{\varphi_i}^1(K_i)$ by the map $\Phi:M^1_\varphi(K)\to\varprojlim_{i\in I}M_{\varphi_i}^1(K_i)$ given by $\mu\mapsto(\pi_{i*}\mu)$ where $\pi_i:K\to K_i$ is the standard projection. I am stuck trying to prove bijectivity. My idea is to use the Kolmogorov extension theorem to kill two birds with one stone, so to speak. Let $(\mu_i)_{i\in I}\in \varprojlim_{i\in I}M_{\varphi_i}^1(K_i)$ . As each measure is nice and regular we know there exists a unique measure on $\prod_{i\in I}K_i$ (equipped with the product $\sigma$ -algebra of the Baire $\sigma$ -algebras on each $K_i$ , which is actually just the Baire $\sigma$ -algebra on the product space) satisfying $\mu_i=P_{i*}\mu$ , where $P_i$ is the $i$ -th projection on the whole product space. As $K$ is compact it is Baire measurable, so this induces a measure $\mu_K$ on $K$ equipped with the trace $\sigma$ -algebra defined by $\mu_K(A)=\mu(A)/\mu(K)$ . There are two problems with this approach. Firstly I cannot see why $\mu(K)\neq 0$ , and secondly for $\pi_{i*}\mu_K=\mu_i$ we would need that $\mu_i(K_i\backslash P_i(K))=0$ for all $i\in I$ . This is my first time dealing with inverse limits, and I am struggling to see why this must be so. We could maybe use the fact that each $\pi_{ij*}$ is actually the adjoint of the Koopman operator $T_{\pi_{ji}}:C(K_i)\to C(K_j)$ and do some clever functional analysis argument, but I am unable to see it. In fact maybe the Kolmogorov Extension theorem is completely the wrong approach. Any pointers would be much appreciated. Eisner, Tanja; Farkas, Bálint; Haase, Markus; Nagel, Rainer , Operator theoretic aspects of ergodic theory , Graduate Texts in Mathematics 272. Cham: Springer (ISBN 978-3-319-16897-5/hbk; 978-3-319-16898-2/ebook). xviii, 628 p. (2015). ZBL1353.37002 . the book Operator Theoretic Aspects of Ergodic Theory","['general-topology', 'functional-analysis', 'analysis', 'measure-theory']"
2971477,Example of a Lebesgue measurable set that can't be constructed from Borel sets and projections?,"The Borel sigma algebra on $\mathbb{R}^n$ is obtained by starting with open sets and repeatedly applying the operations of complement, countable union, countable intersection.  Now Henri Lebesgue famously made the mistake of thinking that the projection of a Borel set is always a Borel set.  In reality, the projection of a Borel set need not be a Borel set, although it is still Lebesgue measurable.  So that is a way of constructing a Lebesgue measurable set that is not a Borel set. But my question is, what is an example of a Lebesgue measurable set that cannot be constructed in this way?  That is, what is a Lebesgue measurable set that cannot be constructed by starting with open sets in $\mathbb{R}^n$ and repeatedly applying the operations of complement, countable union, countable intersection, and projection?","['measure-theory', 'lebesgue-measure', 'examples-counterexamples', 'borel-sets', 'descriptive-set-theory']"
2971483,Verify divergence theorem (Integral Boundaries),"I am not sure how to get the boundaries for this problem. So far, I have worked out $\mathbf{n}=\nabla(1-r^2-z)=-(2r\mathbf{e}_r-\mathbf{e}_z)$ , normalize it so $$\hat{\mathbf{n}}=-\frac{1}{\sqrt{5}}(2r\mathbf{e}_r-\mathbf{e}_z).$$ I think the area element is $dA=rdrd\theta$ and volume element $dV=rdrd\theta dz$ and $$\nabla\cdot\mathbf{v}=\frac{z}{r}.$$ So, I have $$\int_V 1-r^2 drd\theta dz=\int_S -\frac{2}{\sqrt{5}}drd\theta.$$ But I don't know how to find the boundaries for this problem. I'd appreciate any help.","['multivariable-calculus', 'calculus', 'vector-analysis']"
2971501,Using the Residue Theorem to Prove that $\int^{2\pi}_{0} \frac{1}{(a+\cos\theta)^{2}} d \theta=\frac{2\pi a}{(a^{2}-1)^{3/{2}}}.$,"How do you evaluate the following integral? Here we take $a>1$ . $$\int^{2\pi}_{0} \frac{1}{(a+\cos\theta)^{2}} d \theta=\frac{2\pi a}{(a^{2}-1)^{\frac{3}{2}}}.$$ I know I have to use the Residue Theorem, however, I am stuck on which contour to use, and also how to find the pole of the function. Any hints are greatly appreciated.","['complex-analysis', 'residue-calculus']"
2971583,Does the pointwise limit of a sequence {$f_{n}$} of measurable functions imply that f is measurable? [Graduate studies],"I am using the H.L Royden 4th ed and the Folland Any definition of measurable functions or otherwise is as defined in the text above 1.Let { $f_{n}$ } be a sequence of measurable functions converging a.e(almost everywhere) to the function $f$ on $E$ . Prove that $f$ is measurable. 2.Let ( $\Omega$ , $\Sigma$ ) be a measurable space. If $f$ is a pointwise limit of a sequence { $f_{n}$ } of measurable functions on a common domain $D$ $\in$ $\Sigma$ . Then $f$ is measurable. My attempt For 1. I choose a set say $A_{0}$ such that this set is a subset of the entire set say $A$ . 
Next i proved that the measure of the first set is 0 and showed that $f_{n}$ converges pointwise to the compliment of the first set. Thereafter we know that f is measurable if and only if the restriction of the set is measurable. I then say that from this I assumed that the convergence to all possible sets A is pointwise. Then choose an element say b inside the entire real line and used the definition of pointwise convergence so show that f(x) is less than the element say b. And after some working with these sets I showed that the intersection of the entire set belongs to $M$ . After which the union of my entire set such that b is inside A is equal to my f(x) being less than b which shows that f is measurable since the countable union of measurable sets is again measurable so my LHS is measurable and my RHS is measurable so hence f is measurable. For 2. I have no idea how to even begin attempting the question. What my thought process?I have never done a question with ( $\Omega$ , $\Sigma$ ). Can anyone point me in the right direction how to begin such a question.","['general-topology', 'measurable-functions', 'measure-theory', 'real-analysis']"
2971586,Seeking methods to solve: $\int_{0}^{1} \frac{1}{1 + \arctan(x)} \:dx$,I've been playing with the following definite integral and was wondering if anyone knew of any methods to solve? $$I = \int_{0}^{1} \frac{1}{1 + \arctan(x)} \:dx$$,"['integration', 'definite-integrals']"
2971656,Open ball contains infinitely many disjoint open balls of equal radius,Let $X$ be an infinite dimensional Banach space. Show that the unit ball has contains infinitely many open balls all of equal radius. The hint is to use Riesz's lemma.,['functional-analysis']
2971675,How to solve a specific complex integral: $\int_M \frac{(6z+1)^5 \cos(3z+1)}{(3z+1)^2}dz$,"In a test today, we were given a specific integral to solve: for a curve $M$ oriented clockwise, being a rectangle with vertices $(1,2), (-1,2), (-1,-1), (1,-1)$ , $$\int_M \frac{(6z+1)^5 \cos(3z+1)}{(3z+1)^2}dz$$ We were not actually taught how to solve integrals of this form at this point - which was a bit eyebrow-raising for a bunch of us. The professor said it was more of a test of confidence ... or something. Either way a little weird to put on a test, but okay. So, my question is, how would one solve it? My Attempt: Post-script from a month after I posted this: this approach did touch on the correction but was wrong. The substitution was a big reason why. Very recently, we discussed expressing complex functions as a power series. If we try to express the function $f(z)$ as a power series about $z = 0$ , $$f(z) = \sum_{n=0}^{\infty} a_n z^n$$ then each coefficient $a_n$ is given by either of the below, $$a_n = \frac{-1}{2\pi i} \int_{M} \frac{f(\zeta)}{\zeta^{n+1}} d \zeta = \frac{1}{n!} f^{n}(0)$$ (The negative comes from $M$ being oriented clockwise.) Well, if we make the substitution $\zeta = 3z+1$ in our original integral (yielding $d\zeta = 3dz$ ), we have $$\int_M \frac{(6z+1)^5 \cos(3z+1)}{(3z+1)^2}dz= \frac{1}{3} \int_M \frac{(2\zeta-1)^5 \cos(\zeta)}{\zeta^2}d\zeta$$ If we let $f(\zeta)$ be given by $f(\zeta) = (2\zeta-1)^5 \cos(\zeta)$ , we then essentially match the form of the integral in the definition of the coefficients above if $n=1$ , i.e. $$a_2 = \frac{-1}{2\pi i}  \int_M \frac{f(\zeta)}{\zeta^2}d\zeta = \frac{-1}{2\pi i} \int_M \frac{(2\zeta-1)^5 \cos(\zeta)}{\zeta^2}d\zeta  = \frac{1}{1!} f^{1}(0)$$ or, essentially, $$\int_M \frac{f(\zeta)}{\zeta^2}d\zeta = \int_M \frac{(2\zeta-1)^5 \cos(\zeta)}{\zeta^2}d\zeta  = -2 \pi i \cdot f'(0)$$ Would this be right so far? From here, it's basically arithmetic: find the derivative of $f(\zeta)$ , evaluate it for $\zeta = 0$ , and multiply by $\frac{1}{3}$ to return to the integral we got by the substitution $\zeta = 3z+1$ = and $d\zeta = 3dz$ . I'm not going to bore you with that arithmetic, I'm more concerned with just the overarching idea of how to solve this integral, as opposed to the actual answer, since I'm not sure if I have the right idea. Actually I feel pretty sure I don't, but I couldn't think of anything else that would apply.","['complex-analysis', 'complex-integration']"
2971680,Coordinates on a parametric curve,"A curve is defined by the parametric equation $(x, y, z)$ $=$ $(-2 + 3t, 1 + 3t^2, 2t-3t^3)$ . There is a unique point $P$ on the curve with the property that the tangent line at $P$ passes through the point $(-8, 10, 8)$ . What are the coordinates of $P$ ? So I tried to find the equation of the tangent line first. So what I did was subtract the point $(-8, 10, 8)$ from the general equation of the line. This gave me $(-6-3t, 9-3t^2, 8-2t+3t^3)$ . The derivative for the general equation of the line is $(3 , 6t, 2-9t^2)$ . So I seem to understand that the tangent line is parallel, and therefore a scalar multiple, of the equation of the derivative. But I can't seem to see what the relationship is and how that can help me get the required coordinates. Any help?","['calculus', 'tangent-line', 'derivatives', 'parametric']"
2971682,Geometric intuition of flatness of completion,"Let $R$ be a ring and $I$ be an ideal of $R$ . Let $\widehat{R}$ be a $I$ -adic completion of $R$ . It is known that $\widehat{R}$ is a flat $R$ -module. Is there any geometric intuition for this fact? For example, let $R = k[X_{1}, \dots, X_{n}]$ and $I = (X_{1}, \dots, X_{n})$ , so that $\widehat{R} = k[[X_{1}, \dots, X_{n}]]$ . In this case, $\mathrm{Spec}(R) = \mathbb{A}_{k}^{n}$ . What is $\mathrm{Spec}(\widehat{R})$ , and is there any explanation for why $\mathrm{Spec}(\widehat{R})\to \mathbb{A}_{k}^{n}$ is flat?",['algebraic-geometry']
2971692,Is $\frac{\sin(xy)}{xy}$ continuous?,"Let $h: \mathbb{R}^2 $ -> $\mathbb{R}$ I can replace $h(x, 0) = x$ , so that $x=a≠0$ . Then the function essentially becomes $h(y) = \frac{\sin (ay)}{ay}$ . To figure out the limit for "" $h(0)$ "", we can substitute $z = ay$ : $$
\lim_{y \to 0}f(a, y) = \lim_{z \to 0}\frac{\sin z}{z} =  ?
$$ For $x = 0$ , we have that $h(0, y) = 0$ for non-zero $y$ , so $h(0, 0) = 0$ is a natural extension at the origin as well. Is that correct, or is that wrong? Can one do this differently?","['limits', 'functions', 'continuity']"
2971723,Stuck on a proof about rotating a matrix,"Given a matrix $A \in M^{n×n}(F)$ , let $A^{\rho}$ denote the matrix obtained from $A$ by ‘rotating’ it $90^{\circ}$ clockwise.
For example, $$\begin{bmatrix} 1&2\\ 3&4 \end{bmatrix}^\rho =\begin{bmatrix} 3&1\\ 4&2 \end{bmatrix}.$$ Find (with proof) an expression for $A^\rho$ in terms of $A$ . Through analyzing $2\times 2, 3\times 3, 4\times 4$ , and $5\times 5$ cases, it seems that the rotation is equivalent to transposing A and then swapping the first column with the $n^{th}$ column, the second column with the $(n-1)^{th}$ column, and so on. Performing these column operations is equivalent to right multiplication by a permutation matrix. So I've concluded that $A^\rho$ is equivalent to $A^TP$ where $P$ is the the ""mirror image"" of $I_n$ . For example in the $5 \times 5$ case, $P= \begin{bmatrix}
 0&0&0&0&1\\
 0&0&0&1&0\\
 0&0&1&0&0\\
 0&1&0&0&0\\
 1&0&0&0&0
\end{bmatrix}.$ I'm struggling with how to prove this in the general case, or how to express $P$ for any $n$ . Any help is appreciated!","['matrices', 'transpose', 'linear-algebra']"
2971743,The $2n$ th derivative of $\frac{1}{1+x^2y^2}$ with respect to $x$ in a way that does not require the imaginary unit.,"I wanted to know what is the $\frac{d^{2n}}{dx^{2n}}$ of \begin{align}
\frac{1}{1+x^2y^2}
\end{align} But the answer I got from another post was a function relaying on the imaginary unit $i^2=-1$ , and I wonder if we can find the $2n$ th derivative in a different way.","['calculus', 'derivatives', 'real-analysis']"
2971770,"How to calculate statistical ""difference"" of two samples in 0-100 range?","There are two groups of people, target and neutral There are two group of events X and others We're making assumption that people from target group react on event X very different to others. We have some sets of reaction numeric values on different type of events by those two groups. And after running Student's T-Test in excel I get 0.032 for target group and 0.55 for others so I can tell that target group react on X different but is it possible to measure how much different in 0-100 range? example of data set (not real data set) for both groups looks like 30, 20, 45, 15, 26 ... - reaction on X event
10, 14, 22, 8, 13 ... - reactions on other events What can I use to measure how much reaction X different (alike in T-Test) to reaction on other events in 0-100 range and is it possible in general?",['statistics']
2971798,"Find the derivative (a) $\frac{\partial w}{\partial s}$, where $w = \frac{x-z}{y+z}$, $x =s + t$, $y = st$ and $z = s - t$","Find the derivative (a) $\displaystyle\frac{\partial w}{\partial s}$ , where $\displaystyle w = \frac{x-z}{y+z}$ , $x =s + t$ , $y = st$ and $z = s - t$ Solution attempt: $$\frac{\partial w}{\partial s} = \frac{\partial w}{\partial x} \cdot \frac{\partial x}{\partial s} + \frac{\partial w}{\partial y} \cdot \frac{\partial y}{\partial s} + \frac{\partial w}{\partial z} \cdot \frac{\partial z}{\partial s} = \frac{1}{y+z} \cdot (1) + \frac{z-x}{(y+x)^2}t + \frac{-(x + y)}{(y + z)^{2}} (1) = (-x + z) \left(\frac{t}{(x + y)^2} + \frac{1}{(y + z)^2} \right)$$ (b) $\frac{\partial w}{\partial r}$ , where $w = \sqrt{x^2 + y^2 +z^2}, $ y = rs $, x = st, z = rt$ Solution attempt: $$\frac{\partial w}{\partial r} = \frac{\partial w}{\partial x} \cdot \frac{\partial x}{\partial r} + \frac{\partial w}{\partial y} \cdot \frac{\partial y}{\partial r} + \frac{\partial w}{\partial z} \cdot \frac{\partial z}{\partial r} = \frac{x}{\sqrt{x^2 + y^2 + z^2}} \cdot 0 + \frac{y}{\sqrt{x^2 + y^2 + z^2}} (1) + \frac{z}{\sqrt{x^2 + y^2 + z^2}}(1) = \frac{y+z}{\sqrt{x^2 + y^2 + z^2}}$$ (c) $\frac{\partial f}{\partial z}$ , where $u = f(v)$ , $v = g(w, x, y)$ , $w = h(z)$ , $x = p(t, z)$ and $y = q(t, z)$ Solution attempt: $$\frac{\partial f}{\partial z} = \frac{\partial f}{\partial u} \cdot \frac{\partial u}{\partial z} + \frac{\partial f}{\partial v} \cdot \frac{\partial v}{\partial z} + \frac{\partial f}{\partial w} \cdot \frac{\partial w}{\partial z} + \frac{\partial f}{\partial x} \cdot \frac{\partial x}{\partial z} + \frac{\partial f}{\partial y} \cdot \frac{\partial y}{\partial z} = ???$$ Would this be right. Also, how would I get the derivative of the functions?","['partial-derivative', 'multivariable-calculus']"
2971807,"Is there a continuous and injective function $f: [0,1] \to \mathbb R^2$ such that the image has positive two dimensional Lebesgue measure?","Is there a continuous and injective function $f: [0,1] \to \mathbb R^2$ such that the image has positive two dimensional Lebesgue measure? I am not sure how to approach here. I think ine way to approach this would be by contradiction. I think that we must use the fact that a contiuous bijective map from a campact set to a Hausdorff set is a homeomorphism. However, I am not sure what to do here. If only the property of being positive Lebesgue measure were a topological property...","['measure-theory', 'lebesgue-measure']"
2971824,Combinatorics - The Students and Grades Problem,"Suppose there are $20$ students in a classroom, $10$ males and 10 females. How many ways can a teacher distribute exactly $5$ As, $6$ Bs, $5$ Cs, $2$ Ds, and $2$ Fs to the students? My Logic: $(20 C 5)(15 C 6)(9 C 5)(4 C 2)(2 C 2)$ seems the like the most intuitive answer but then this answer ignores the number of males and females in the class. Rather, if we treat the whole classroom as our sample, then we avoid any extra casework. I may be missing something here though so feel free to enlighten me.",['combinatorics']
2971855,What is the difference between event of 0 probability and null event,"I can't understand the difference between Null event and an event that has 0 probability.
In the Null event the event which no way could happen?
and is the event of 0 probability the event that can happen but which would not happen in certain circumstances?
Is the event that has 0 probability a Null event? or can an event ot bu null but have 0 probability? I also want to discuss this example: I have a circle and I inscribe a triangle in it. There are 3 cases where it could be straight angle triangle(one angle is 90 degrees) but the probability of it is 0. Why is it like that? Please provide external links if available Thanks","['probability-theory', 'probability']"
2971863,Let $A_{n\times n}$ be a real matrix. Is it true that $I+A^TA$ is invertible?,Let $A_{n\times n}$ be a real matrix. Is it true that $I+A^TA$ is always invertible?,"['matrices', 'linear-algebra', 'inverse']"
2971892,Evaluating the Surface Integral on a Sphere for a scalar function (integral is involved in PDE),"I will begin by saying that I don't want to dissuade anyone who doesn't know PDE from helping, so if you're just here for the integral, you can skip down to ""Where I'm Stuck"" (For future reference: $\vec{x}=(x,y,z)$ , $\vec{x}_0=(x_0,y_0,z_0)$ , $\vec{x}+\vec{x}_0=(x+x_0,y+y_0,z+z_0)$ ) Integral set-up In my PDE class, we were asked to solve the homogeneous wave equation ( $U_{tt}-c^2\nabla^2 U=0$ ) for $U(\vec{x},t)$ on $\mathbb{R}^3$ where at $U(\vec{x},0)=xy^3z^2$ and $U_t(\vec{x},0)=z^2$ . The general way to solve the problem is to split the problem into 2 parts: a) Solve $V_{tt}-c^2\nabla^2 V=0$ where $V(\vec{x},0)=xy^3z^2$ and $V_t(\vec{x},0)=0$ b) Solve $W_{tt}-c^2\nabla^2 W=0$ where $W(\vec{x},0)=0$ and $W_t(\vec{x},0)=z^2$ So then $U=V+W$ . In class we derived a supposedly ""simple"" formula to solve part a ( $\psi(\vec{x})=V(\vec{x},0)=xy^3z^2$ ): $$V=\frac{\partial}{\partial t}\Bigg (\frac{1}{4\pi c^2t}\iint_{|\vec{x}_0|=ct}\psi(\vec{x}+\vec{x}_0)\,dS_{\vec{x}_0}\Bigg )$$ I'm going to ignore the partial derivative and the coefficient later on in the question because calculation of that is trivial to the problem I am having. Where I'm stuck I need to evaluate the following integral: $$\iint_{|\vec{x}_0|=ct}(x+x_0)(y+y_0)^3(z+z_0)^2\,dS_{\vec{x}_0}$$ The $|\vec{x}_0|=ct$ and $\,dS_{\vec{x}_0}$ mean that we're essentially treating $x$ , $y$ , and $z$ as numbers (instead of variables) and integrating only by the variables with 0 subscript ( $x_0$ , $y_0$ , and $z_0$ ) over a sphere of radius $ct$ (since theoretically this is for light waves). I'm not sure how I'm supposed to evaluate this, asI may have forgotten some of my calculus, but my confusion arises from the fact that typically when dealing with surface integrals, the integrand is a vector field (the result is the flux through an area). Although the integral now doesn't make physical sense to me, I can still try to work it out. Since I'm dealing with a sphere, I was thinking of doing the bounds of integration in spherical coordinates about a sphere of radius $\rho=ct$ : $$\int_0^\pi\int_0^{2\pi}(x+x_0)(y+y_0)^3(z+z_0)^2\rho^2\sin{\phi}\,d\theta\,d\phi$$ Since $\rho^2=c^2t^2$ has no relation to $\theta$ and $\phi$ , I can pull it out of the integral, leaving me with: $$c^2t^2\int_0^\pi\int_0^{2\pi}(x+x_0)(y+y_0)^3(z+z_0)^2\sin{\phi}\,d\theta\,d\phi$$ My thought from here is to expand my integrand, separate terms that don't involve any 0-subscripted variables, then use the rectangular to spherical coordinate conversions ( $x_0=\rho\sin{\phi}\cos{\theta}$ , $y_0=\rho\sin{\phi}\sin{\theta}$ , $z_0=\rho\cos{\phi}$ ), then integrate manually. Is there an easier way to do this since the expansion will have quite a few terms? Also, what will I do with the new $\rho$ 's that appear? Will they all simply be equal to $ct$ since I'm only looking at my integrand on the sphere itself? It is also worth noting that in class, it was pointed out that if I have terms of odd degree (with respect to $x_0$ , $y_0$ , and $z_0$ ) in my integrand, integrating those terms over a sphere will result in 0 due to symmetry, so that's why I'm leaning towards this path. Any other suggested methods would be helpful as I will most definitely have to be integrating similar integrals in the near future.","['surface-integrals', 'multivariable-calculus', 'definite-integrals', 'partial-differential-equations']"
2971905,What is this graph/matrix operation called in English ? ($ M_{2} = \frac{N^{2}}{|N^{2}b|} $),"I'm taking a Discrete mathematics course currently. At the moment we're working with different algorithms to manipulate graphs and the neighbor matrix of graphs. I'm trying to learn more about how to work with a specific algorithm but I'm not sure what it is called in English, would appreciate if someone could point me in the right direction, in Norwegish its called: Potensmetoden. A rough translation would be Power of method. The method looks like: $$ M_{2} = \frac{N^{2}}{|N^{2}b|} $$ If I have something like a $$ N =  \begin{bmatrix} 0 & 1 & 0 & 1 & 1 & 1   \\
 1 & 0 & 1 & 1 & 0 & 0 \\ 
0 & 1 & 0 & 1 & 0 & 0 \\
1 & 1 & 1 & 0 & 1 & 1\\
1 & 0 & 0 & 1 & 0 & 1 \\ 
1 & 0 & 0 & 1 & 1 & 0 \end{bmatrix}  $$ This would end up as $$ 
N^{2} = N * N = \begin{bmatrix} 0 & 1 & 0 & 1 & 1 & 1   \\
 1 & 0 & 1 & 1 & 0 & 0 \\ 
0 & 1 & 0 & 1 & 0 & 0 \\
1 & 1 & 1 & 0 & 1 & 1\\
1 & 0 & 0 & 1 & 0 & 1 \\ 
1 & 0 & 0 & 1 & 1 & 0 \end{bmatrix}  
 \begin{bmatrix} 0 & 1 & 0 & 1 & 1 & 1   \\
 1 & 0 & 1 & 1 & 0 & 0 \\ 
0 & 1 & 0 & 1 & 0 & 0 \\
1 & 1 & 1 & 0 & 1 & 1\\
1 & 0 & 0 & 1 & 0 & 1 \\ 
1 & 0 & 0 & 1 & 1 & 0 \end{bmatrix}  = \begin{bmatrix} 4 &1 & 2 & 3 & 2 & 2 \\
1 & 3 & 1 & 2 & 2 & 2 \\
2 & 1 & 2 & 1 & 1 & 1 \\
3 & 2 & 1 & 5 & 2 & 2 \\ 
2 & 2 & 1 & 2 & 3 & 2 \\ 
2 & 2 & 1 & 2 & 2 & 3 \end{bmatrix}
$$ $$ \underbrace{\begin{bmatrix} 
4 &1 & 2 & 3 & 2 & 2 \\
1 & 3 & 1 & 2 & 2 & 2 \\
2 & 1 & 2 & 1 & 1 & 1 \\
3 & 2 & 1 & 5 & 2 & 2 \\ 
2 & 2 & 1 & 2 & 3 & 2 \\ 
2 & 2 & 1 & 2 & 2 & 3 \end{bmatrix}}_{N_{2}} \underbrace{\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}}_{b}  = \begin{bmatrix} 14 \\ 11 \\ 8 \\ 15 \\ 12 \\ 12 \end{bmatrix}  $$ $$Norm |N_{2}b| =  \sqrt{14^{2} + 11^{2} + 8^{2} + 15^{2} + 12^{2} + 12^{2}}  \approx 29.9$$ $$ M_{2} = \frac{N^{2}}{|N^{2}b|} = \frac{1}{29.9} \begin{bmatrix} 
4 &1 & 2 & 3 & 2 & 2 \\
1 & 3 & 1 & 2 & 2 & 2 \\
2 & 1 & 2 & 1 & 1 & 1 \\
3 & 2 & 1 & 5 & 2 & 2 \\ 
2 & 2 & 1 & 2 & 3 & 2 \\ 
2 & 2 & 1 & 2 & 2 & 3 \end{bmatrix} \approx 
\begin{bmatrix} 
0,138 & 0,033 & 0,067 & 0,100 & 0,067 & 0,067 \\
0,033 & 0,100 & 0,033 & 0,067 & 0,067 & 0,067 \\
0,067 & 0,033 & 0,067 & 0,033 & 0,033 & 0,033 \\
0,100 & 0,067 & 0,033 & 0,167 & 0,067 & 0,067 \\ 
0,067 & 0,067 & 0,033 & 0,067 & 0,100 & 0,067 \\ 
0,067 & 0,067 & 0,033 & 0,067 & 0,067 & 0,100 \end{bmatrix} $$ An lastly, getting M_{2}b $$ M_{2}b = \begin{bmatrix} 
0,468 \\
0,368 \\
0,268 \\
0,502 \\ 
0,401 \\ 
0,401 \end{bmatrix} $$ I understand this relatively alright, however, in the next task I shall build upon this method by taking it up to a power of 4 and there im lost, i figured it would be the same steps basiclly i went back and took N^4 and started over. But I didn't manage to finish it. Method of the secound part of the task: $$ M_{4} = \frac{N^{4}}{|N^{4}b|} = \frac{M^{2}_{2}}{|M^{2}b|}, M_{4}b $$","['matrices', 'graph-theory', 'discrete-mathematics']"
2971913,Role of binomial coefficents in nested summations in layman terms,"I has this doubt from almost two years and not getting a simple solution in layman terms. In short, the doubt is the about relation between binomial coefficients and the nesting summation . Recently I started reading this pre print in which authors claimed a formula and it shows relation between nesting and binomial coefficients used. The formula given is as follows: $$\sum\limits_{}^{(m)} n^k = \sum\limits_{i=0}^{k} \binom{n+m-1}{m+i} \mu[k,i]$$ Let's kept aside $\mu[k,i]$ . The formula is showing relation between nesting ( $m$ ) and the corresponding binomial coefficients used $\binom{n+m-i}{m+i}$ . In simple terms, if the binomial coefficient is $\binom{x}{y}$ for nesting $m$ , then if we increase one more summation i.e., $(m+1)$ , the binomial coefficients become $\binom{x+1}{y+1}$ . The proving technique used is mathematical induction and hence can't able to get any clue from the pre print. Is there any intuitive explanation to understand this ?","['summation', 'elementary-number-theory', 'binomial-coefficients', 'intuition', 'sequences-and-series']"
2971948,The term to describe linear algebra's $\textrm{general solution }=\textrm{particular sol. + homogeneous sol.}$ in group theory,"I'm trying to relate the idea that in linear algebra any solution set $S$ of a given system of linear equation $Ax=b$ and $Ax_0=b$ then $S=\{x_0+k\mid k\in \ker A\}$ , to some corresponding idea in group theory. So far I only know that if the kernel is used to divide the domain of a given homomorphism then the same image corresponding to the same coset of kernel. Please help if this is not a wrong question...","['group-theory', 'linear-algebra']"
2972001,Count the number of shapes in a polyhedron.,"So this is a question that was asked in the International Kangaroo Math Contest 2017 . The question is: The faces of the following polyhedron are either triangles or squares. Each triangle is surrounded by $3$ squares and each square is surrounded by $4$ triangles. If there are $6$ square faces, how many triangular faces are there? What I did: Each square shares each of its four neighboring triangles with two more squares. So we can say that for 6 squares we have $6\times4\ -\ 2 \times 6 = 12$ triangles. However, I still know that this calculation of mine is quite wrong and based on an awkward thinking. So, what is the correct answer and how? Thanks for the attention.","['polyhedra', 'surfaces', '3d', 'geometry', 'combinatorics']"
2972044,How many ways could the guests arrange themselves on a four person couch [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question There are 33 guest at your home for a dinner party in how many ways could the guests arrange themselves on a four person couch I really not understand this question form where to start can someone explain please thanks ..","['permutations', 'combinations', 'combinatorics']"
2972085,3 circles internal tangent,"My friend show me the diagram above , and ask me ""What is the area of a BLACK circle with radius of 1 of BLUE circle?"" So, I solved it by algebraic method. $$$$ Let center of $\color{black}{BLACK}$ circle be $(0,0)$ . We can set, $x^2 + (y-R)^2 = R^2$ , where $R$ means radius of $\color{red}{RED}$ circle. $(x-p)^2 + (y-r)^2 = r^2 $ ,  where $(p,r)$ means center of $\color{blue}{BLUE}$ circle. $$$$ These can imply $    2R=r+ \sqrt{p^2 + r^2}$ $p^2 + (R-r)^2 = (R+r)^2 $ So, $ 2r=R$ $$$$ But he wants not algebraic but Geometrical Method. How can I show $ 2r=R$ with Geometrical Method ? Really thank you. $$$$ (Actually I constructed the diagram with algebraic methed, but I'd like to know how construct this whit Geometrical method.)",['geometry']
2972199,Let $f(z) = \frac{1+e^z}{1-e^z} $. Determine the image of $f(A)$,"On all the complex analysis-exams written by my professor, a question of this nature always pops up: Let $$f(z)=\frac{1+e^z}{1-e^z}$$ and $A=\{z:\Re(z)<0, \ -\pi<\Im(z)<\pi\}.$ Determine the image $f(A)$ .
  Hint: use the fact that $f(z)=M(e^z)$ where $M(z)=\frac{1+z}{1-z}.$ I'm wondering if anyone can somehow break down a solution for problems like these in steps. Like, step 1: check this, step 2: compute this and so on. I already have the profesors solutions but they are too cryptic for me. I need this problem simplified somehow so I can understand what needs to be done. My initial thought is simply that we have an area $A$ , which is an infinite rectangular area that is to the left of the complex halfplane but bounded by $-\pi$ and $\pi$ on the imaginary axis. So if every point inside of $A$ undergoes the transformation $f(z),$ they will form a different figure, i.e the image $f(A).$ However, I don't understand how I'm supposed to do the arithmetic here and use Möbius transforms. Any help is greatly appreciated, but please no usage of fancy math that is outside the scope of complex analysis.",['complex-analysis']
2972213,Find the remainder $R$ of $(1^2+1)(2^2+1)...(p^2+1)$ divided by $p$,"Find the remainder $R$ of $(1^2+1)(2^2+1)...(p^2+1)$ divided by $p$ , with $p$ being a prime number greater than $3$ . For $p \equiv 1 \mod 4$ , there exists an integer $j$ such that $p\mid j^2+1$ (since $-1$ is a quadratic residue of $p$ ), therefore $R=0$ . For $p \equiv 3 \mod 4$ , how can we find $R$ ? Does $R$ depend on the value of $p$ ?",['number-theory']
2972220,"Compute conditional expectations of X,Y iid given the generated sigma algebra of $Z=\mathbf{1}_{\{X+Y=0\}}$","Let X, Y be idependent, identically distributed random variables with $${P}(X=1) = {P}(Y=1) = p$$ $${P}(X=-1) = {P}(Y=-1) = 1-p$$ and set $$Z=\mathbf{1}_{\{X+Y=0\}}$$ $$\mathcal{G} = \sigma(Z)$$ Compute $\mathbb{E}[X|\mathcal{G}]$ and $\mathbb{E}[Y|\mathcal{G}]$ . Are these random variables still independent? I am confused because, I dont know on which space X and Y are on. Also because all examples I have seen just use a random variable as condition, now it is the generated sigma algebra of a RV and I dont know what $\mathbb{E}[-|\mathcal{G}]$ really means and how I can compute it.","['statistics', 'conditional-expectation', 'probability']"
2972235,Which function grows faster?,"Which function grows faster $𝑓(𝑛)= 2^{𝑛^2+3𝑛}$ and $𝑔(𝑛) = 2^{𝑛+1}$ by using the limit theorem I will first simplify then I will just get $$\lim_{n \to \infty} \dfrac{2^{n^2+3n}}{2^{n+1}}=\lim_{n \to \infty} 2^{n^2+3n-n-1}=\lim_{n \to \infty} 2^{n^2+2n-1}=\infty$$ Is this enough? 
I say it will go then to infinity so the $f(n)$ is growing faster? I am asking this question because I have to find it by using limit but I didn't need to use l'hopital rule!","['limits', 'asymptotics', 'logarithms']"
2972245,Is there a $\sigma$-complete homomorphism of $\sigma$-algebras that is not generated by a function on underlying sets?,"Let $\mathcal{A},\mathcal{B}\,$ be $\sigma$ -algebras on sets $X,Y$ , respectively. A mapping $h\colon\mathcal{A}\to\mathcal{B}\,$ is called a $\sigma$ -complete homomorphism if $h(\emptyset)=\emptyset$ , $h(X\setminus A)=Y\setminus h(A)$ for all $A\in\mathcal{A}$ , and $h\big(\bigcup A_n\big)=\bigcup h(A_n)$ for all sequences $\{A_n\}_{n\in\omega}$ in $\mathcal{A}$ . I am looking for an example of such $\mathcal{A}$ , $\mathcal{B}$ and $h$ for which there is no function $f\colon Y\to X$ satisfying $h(A)=f^{-1}[A]$ for all $A\in\mathcal{A}$ . If $\kappa$ is a measurable cardinal then one can take a $\sigma$ -complete non-principal ultrafilter $u$ on $\mathcal{P}(\kappa)$ and define $h\colon\mathcal{P}(\kappa)\to\mathcal{P}(\{\emptyset\})$ by taking $h(A)=\{\emptyset\}$ if and only if $A\in u$ . Question: Can one find an example of such $\mathcal{A}$ , $\mathcal{B}$ and $h$ in ZFC?","['boolean-algebra', 'measure-theory', 'set-theory']"
2972257,What is the maximum number of rational points that can lie on a circle in $\mathbb{R}^2$ whose center is not a rational point?,"This is a Putnam I found a few weeks ago, I believe I solved it, but something just seems off with my approach, can someone check wether my solution is right or not? So, since I'm searching for the maximum I can stablish ideal conditions, for example, a circumference of a radii such that $(0,1)$ lies on the circumference, then, if I choose any secant with rational slope that goes through $(0,1)$ , it has to cut through a rational point, since we would have a sistem of equations of degree $2$ , and we already know one of the solutions, mainly, $(0,1)$ , which is a rational point, and we know that if a cuadratic equation has a rational solution, the other solution must be rational as well. Then, we just need to take every secant with rational slope that goes through $(0,1)$ and we would cut in a rational point that lies on the circumference, hence, there are infinitely many rational points lying on that circumference. What just does't seem right to me, is that this isn't something new, I saw a very similar idea in my number theory class when we found all pythagorean triplets. But this is a Putnam, I wouldn't expect to find such an answer. Could someone please tell me if my procedure is correct or not?","['number-theory', 'algebraic-geometry', 'geometry']"
2972259,Positive function,"I am trying to prove the following result: Let $\mu$ be a Lebesgue measure. Suppose $f$ is a measurable positive application . Show that $\mu\Big(\left\{x\in[0,1]: f>3\right\}\Big)$ is zero Please help me do do so. Thanks","['measure-theory', 'functional-analysis', 'real-analysis']"
2972269,Complex analysis integral of the normal distribution,"I am looking at the expectation of a normal distribution with respect to a function of $x$ . To simplify the problem, I considered the following integral: \begin{equation}
\int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{-x}} \ dx.
\end{equation} To solve this, I considered the complex integral: \begin{equation}
\oint_C \frac{e^{-z^2}}{1+ae^{-z}} \ dz,
\end{equation} with the contour $C = C_1 + C_R$ where $C_1: z = x$ with $x \in [-R,R]$ and $C_R: z = R e^{i \theta}$ , with $\theta \in [0,\pi]$ . First I considered the $C_R$ part: \begin{align}
\int_0^\pi \frac{e^{-R^2 e^{2i \theta}}}{1 + a e^{-R e^{i \theta}}} i R e^{i \theta} d \theta
\end{align} The standard argument here is to consider $R \to \infty$ and show that this integral hopefully decays to 0. However, $e^{-R^2 e^{2i \theta}}$ changes to positive at $\pi/2$ and so this integral actually grows. If instead, I consider the rectangular contour with $C_1: z = x$ as before, $C_2: z = R + iy$ , with $y \in [0,2\pi]$ , $C_3: z = x + i(2\pi)$ and $C_4: z = -R + iy$ , we can show that the integrals $C_2$ and $C_4$ decay to zero \begin{align}
\int_0^{2\pi} \frac{e^{-(R+iy)^2}}{1+ae^{-(R+iy)}} i \ dy \stackrel{R \to \infty}{\to} 0.
\end{align} Hence we are left with the pole at $z_0 = \ln a + i\pi$ which can be computed from Cauchy's integral formula $$\oint \frac{f(z) \ dz}{g(z)(z-z_0)} = 2\pi i \frac{f(z_0)}{g'(z_0)} = 2\pi i e^{-z_0^2}$$ .
The $C_1$ integral is the original integral. However the third integral is slightly different. Is there anyway to proceed here, or does someone have another way to evaluate this integral analytically? $$\int_{C_3} = e^{4 \pi^2} \int_R^{-R} \frac{e^{-x^2}e^{-4 \pi i x}}{1 + a e^{-x}} \ dx = -e^{4 \pi^2} \int_{-R}^{R} \frac{e^{-x^2}e^{-4 \pi i x}}{1 + a e^{-x}} \ dx $$",['complex-analysis']
2972286,Verify the proof that $x_n = \ln^2(n+1) - \ln^2n$ is a bounded sequence.,"Let $n\ \in \mathbb N$ and: $$
x_n = \ln^2(n+1) - \ln^2n
$$ Prove that $x_n$ is a bounded sequence. I've taken the following steps. Consider $x_n$ $$
\begin{align}
x_n &= \ln^2(n+1) - \ln^2n = \\ 
&= (\ln(n+1) + \ln n)(\ln (n+1) - \ln n) = \\
&= \ln \frac{n + 1}{n}\cdot \ln (n(n+1)) = \\
&= \ln\left({1 + {1\over n}}\right)\cdot \ln(n(n+1))
\end{align}
$$ Now multiply and divide by $n$ : $$
\begin{align}
x_n &= {n \over n} \ln\left({1 + {1\over n}}\right)\cdot \ln(n(n+1)) = \\
&= \ln\left({1 + {1\over n}}\right)^n \cdot\ln \sqrt[^n]{(n(n+1))}
\end{align}
$$ Now consider $\left({1 + {1\over n}}\right)^n$ . There are plenty of proofs that it is bounded. In my case I've used expansion with binomial coefficients to prove that : $$
2< \left({1 + {1\over n}}\right)^n < 3 \implies \\
\ln2 < \ln \left({1 + {1\over n}}\right)^n < \ln3
$$ So now we want to prove that $\ln \sqrt[^n]{(n(n+1))}$ is bounded. Start with the following: $$
\ln \sqrt[^n]{n(n+1)} < \ln \sqrt[^n]{(n+1)^2}
$$ Consider the following equation: $$
\begin{align}
\sqrt[^n]{(n+1)^2} &= 1+a_n \iff \\
\iff (n+1)^2 &= (1+a_n)^n = \sum_{k=0}^{n}\binom{n}{k}a_n^k
\end{align}
$$ Now: $$
\sum_{k=0}^{n}\binom{n}{k}a_n^k \ge \frac{n(n+1)}{2}a_n^2 \implies \\
\implies (n+1)^2 \ge \frac{n(n+1)}{2}a_n^2 \implies \\
\implies a_n \le \sqrt{2 + {2\over n}}
$$ So $a_k$ is clearly bounded. Which means: $$
\sqrt[^n]{(n+1)^2} < 1 + \sup\{a_n\} = 3
$$ Also $\sqrt[^n]{(n+1)^2} > 1$ . So: $$
\ln1 < \ln \sqrt[^n]{(n(n+1))} < \ln3
$$ Now going back to initial expression: $$
\ln1 \cdot \ln2 < \ln\left({1 + {1\over n}}\right)^n \cdot\ln \sqrt[^n]{(n(n+1))} < \ln3 \cdot \ln3
$$ Meaning $x_n$ is bounded. Have I missed something?","['logarithms', 'proof-verification', 'upper-lower-bounds', 'sequences-and-series', 'algebra-precalculus']"
2972321,"What is the dimension of $\{X\in M_{n,n}(F); AX=XA=0\}$?","Let $A$ be a fixed $n\times n$ matrix over a field $F$ . We can look at the subspace $$W=\{X\in M_{n,n}(F); AX=XA=0\}$$ of the matrices which fulfill both $AX=0$ and $XA=0$ . Looking a these equations we get that all columns of $X$ have to fulfill the equation $A\vec c=\vec 0$ . (Let us say we're working with column vectors.) Similarly we get for the rows $\vec r^T A=\vec 0^T$ . This tells us that if we are looking at the possible choices for columns/rows of the matrix $X$ , they have to be in a subspace of dimension $n-\operatorname{rank}A$ (in the right/left null space of $A$ ). At least in some cases it is almost immediately possible to find $W$ or at least $\dim W$ . Obviously, if $A$ is invertible, then $W=\{0\}$ and $\dim W=0$ . Another trivial case is when $A=0$ , which gives us $W=M_{n,n}$ and $\dim W=n^2$ . Slightly less trivial but still simple case is when $\operatorname{rank} A=n-1$ . In this case the condition on rows/columns give us one-dimensional spaces, so there are non-zero vectors $\vec r$ , $\vec c$ such that each row has to be multiple of $\vec r^T$ and each column has to be a multiple of $\vec c$ . Up to a scalar multiple, there is only one way how to get such a matrix and we get that $W$ is generated by the matrix $\vec c\vec r^T$ and $\dim W=1$ . The general case seems to be a bit more complicated. If we denote $k=n-\operatorname{rank}A$ , we can use the same argument to see that there are $k$ linearly independent vectors $\vec c_1,\dots,\vec c_k$ such that the columns have to be linear combinations of these vectors. Similarly, row can be chosen only from the span of the linearly independent vectors $\vec r_1,\dots,\vec r_k$ . (This is again just a direct consequence of $A\vec c=\vec 0$ and $\vec r^TA=\vec 0^T$ .) Using these vectors we can get $k^2$ matrices $$A_{ij}=\vec c_i \vec r_j^T$$ for $i,j\in\{1,2,\dots,k\}$ . Unless I missed something, it seems that showing that these matrices are linearly independent is not too difficult. So we should get that $$\dim W \ge k^2 = (n-\operatorname{rank}A)^2.$$ It is not obvious to me whether these vectors actually generate $W$ . (And perhaps something can be said about the dimension of $W$ without exhibiting a basis.) You may notice that in the three trivial examples above (with $k=0,1,n$ ) we got the equality $\dim W=(n-\operatorname{rank}A)^2$ . Another possible way to look at this problem could be to use the linear function $$f\colon X\to(AX,XA)$$ $f\colon M_{n,n} \to M_{n,n}\oplus M_{n,n}$ , then we have $W=\operatorname{Ker} f$ , so we are basically asking for the dimension of the kernel of this map.
So to find $\dim W$ it would be sufficient to find $\dim\operatorname{Im} f$ . However, this does not seem to be easier than the original formulation of the problem. It is also possible to see this as a system of $n^2$ linear equations with $n^2$ unknowns $x_{11}, x_{12}, \dots, x_{nn}$ . If we try to use this line of thinking, the difficult part seems to be determining how many of those equations are linearly dependent. Question: What can be said about the dimension of the subspace $W$ ? Is it equal to $(n-\operatorname{rank}A)^2$ ? Is it determined just by the rank of $A$ ? If not, what are best possible bounds we can get, if we know only the rank of $A$ and have no further information about $A$ ? Motivation for this question was working on an exercise which asked for calculating dimensions of spaces $W_1$ , $W_2$ , $W_1\cap W_2$ and $W_1+W_2$ , where the spaces $W_1$ and $W_2$ were determined by the conditions $AX=0$ and $XA=0$ , respectively. Since the matrix $A$ was given, in this exercise it was possible to find a basis of $W_1\cap W_2$ explicitly. (And the exercise was probably intended just to make the students accustomed to some basic computations such as finding basis, using Grassmann's formula, etc.) Still, I was wondering how much we can say just from knowing the rank of $A$ , without going through all the computations.","['vector-spaces', 'matrices', 'linear-algebra', 'linear-transformations', 'matrix-equations']"
2972440,Solve differential equation $f''''(x)=f'''(x)f''(x)f'(x)f(x)$,"I met this DE recently, and I am utterly befuddled at how to solve it $$f''''(x)=f'''(x)f''(x)f'(x)f(x)$$ I tried this: $$\frac{f''''(x)}{f'''(x)}=f''(x)f'(x)f(x)$$ $$\ln|f'''(x)|=c_1+\int f(x)f'(x)f''(x)dx$$ I do not know how to solve the right side, though. Integration by parts? Plaese help.","['integration', 'calculus', 'ordinary-differential-equations']"
2972454,Rolling icosahedron Hamiltonian path,"A cube has 24 orientations. By rolling the cube on its edge within the perimeter of a $2\times4$ rectangle 3 times, all 24 orientations are reached and the next roll returns the cube to both the starting position and starting orientation. I've called the 24-node graph the ""rolling cube graph"".  It's the bipartite double graph of the cuboctahedral graph . A rolling icosahedron has 120 orientations. The top face can point up or down in each of 60 orientations.  What is the smallest triangular grid for which a rolling icosahedron can roll through a complete Hamiltonian cycle of all 120 orientations? What are the properties of the 120-vertex cubic graph? Similar question for the other 7 deltahedra . What is the smallest triangular grid allowing a complete cycle of all orientations? For other polyhedra that can be rolled through all possible orientations on a simple 2D grid of polygons, what is the smallest grid that supports a Hamiltonian cycle? For the 1x1x2 cuboid, here's a grid that allows a Hamiltonian path through all 24 orientations. Is there a grid with fewer cells?","['polyhedra', 'graph-theory', 'recreational-mathematics', 'group-theory', 'tiling']"
2972457,Simple Property of Determinant Functions,"Okay, so I am in a linear algebra course and we are going though the derivation of the determinant function for matrices. I am struggling with some of the properties of determinant functions i.e. functions which are n-linear, alternating, and give a 1 for the identity matrix. The question I am currently stuck on is as follows. Let $K$ be a commutative ring with identity and $D$ an $n$ -linear function on $n\times n$ matrices over $K$ . Show that $D(B)=D(A)$ , if $B$ is obtained from $A$ by adding a scalar multiple of one row of $A$ to another. What I have so far is as follows. Let $A$ be an $n\times n$ matrix. Let $A=(\alpha_1, \cdots,\alpha_i,\cdots,\alpha_j,\cdots, \alpha_n)$ where $a_k$ , $k=1,...,n$ denote the rows of $A$ . Let $B=(\alpha_1,\cdots,a\alpha_i+\alpha_j,\cdots,\alpha_n)$ for $a\in K$ . That is let $B$ be the matrix formed from $A$ where the $i^{th}$ row of $A$ is replaced by $a$ times the $i^{th}$ of $A$ row plus the $j^{th}$ row of $A$ . Then $D(B)=D(\alpha_1,\cdots,a\alpha_i+\alpha_j,\cdots,\alpha_n)=aD(\alpha_1,\cdots,\alpha_i,\cdots,\alpha_j,\cdots,\alpha_n)+D(\alpha_1,\cdots,\alpha_j,\cdots,\alpha_j,\cdots,\alpha_n)\text{($n$-linearity) }=aD(A)+0=aD(A).$ Therefore $D(B)=aD(A)$ I am clearly missing something obvious because the $a$ should not be there according to the question but for the life of me I can't see what is going on. I am assuming it is something obvious and easy but I have been stuck for far too long. Thanks.","['determinant', 'linear-algebra']"
2972484,Show that $\displaystyle (1-|z|)|f'(z)|\leq\sup_{z\in D}|f(z)|$ for all $z\in D$,"Suppose $f$ is a bounded analytic function on the open unit disk $D$ . Show that $$ (1-|z|)|f'(z)|\leq\sup_{z\in D}|f(z)|$$ for all $z\in D$ Fix $z_{0}\in\mathbb{D}$ . Let $r=1-|z_{0}|\in(0,1]$ if $|u-z_{0}|<r
$ , then $|u|\leq|u-z_{0}|+|z_{0}|<r+|z_{0}|=1$ . And hence $D_{z_{0}}(r)\subseteq\mathbb{D}$ . Can anyone help me proceed further?",['complex-analysis']
2972491,"Is $\int_{\sin x}^{\cos x}x\, dx$ not a well-defined integral?","Consider the integral $$\int_a^bx\, dx$$ where $a=\sin x$ , and $b=\cos x$ . How can we evaluate this particular integral, if $a$ and $b$ are both functions of $x$ , which is the variable with respect to which we are integrating?","['integration', 'calculus']"
2972505,find the sum to n term of $\frac{1}{1\cdot2\cdot3} + \frac{3}{2\cdot3\cdot4} + \frac{5}{3\cdot4\cdot5} + \frac{7}{4\cdot5\cdot6 } + ... $,$$\frac{1}{1\cdot2\cdot3} + \frac{3}{2\cdot3\cdot4} + \frac{5}{3\cdot4\cdot5} + \frac{7}{4\cdot5\cdot6 } + ... $$ $$=\sum \limits_{k=1}^{n} \frac{2k-1}{k\cdot(k+1)\cdot(k+2)}$$ $$= \sum \limits_{k=1}^{n} - \frac{1}{2}\cdot k + \sum \limits_{k=1}^{n} \frac{3}{k+1} - \sum \limits_{k=1}^{n}\frac{5}{2\cdot(k+2)} $$ I do not know how to get a telescoping series from here to cancel terms.,"['telescopic-series', 'sequences-and-series']"
2972527,Numerical differentiation with Binomial Theorem,"In George Shilov's Elementary Real and Complex Analysis, there is a problem which asks us prove If $f$ is twice differentiable on some open interval and the second derivative is continuous at $x$ , then prove that $$f''(x)=\lim_{h\rightarrow 0}\frac{f(x)-2f(x+h)+f(x+2h)}{h^2}\,.$$ This is a common fact in numerical differentiation to approximate derivatives at the left-hand point and is fairly immediate from two applications of Taylor's Theorem with Lagrange Remainder. However, this was not the end of Shilov's problem. He also states Find a similar expression for $f^{(n)}(x)$ (with appropriate hypotheses). In the back of his book, he asserts that $$f^{(n)}(x)=\lim_{h\rightarrow 0}\frac{1}{h^n}\sum_{k=0}^n (-1)^k\binom{n}{k}f(x+kh)$$ which I found interesting enough to at least remember, if not attempt. However, I recently came upon an application where this formula would be useful and attempted to prove it. However, it seems there was an error in Shilov's claim. He must have meant $$(-1)^nf^{(n)}(x)=\lim_{h\rightarrow 0}\frac{1}{h^n}\sum_{k=0}^n (-1)^k\binom{n}{k}f(x+kh)$$ because working out $n=3$ and applying Lagrange's Remainder three times results in $$\frac{f(x)-3f(x+h)+3f(x+2h)-f(x+3h)}{h^3}=\frac{1}{3!}\left(-3f'''(\xi_1)+24f'''(\xi_2)-27f'''(x_3)\right)$$ which gives the corrected limit (with continuity of $f^{(3)}$ at $x$ assumed). Is there an easy way to go about proving this result in general? We can attack this fairly directly, without induction. But this becomes equivalent to proving several interesting binomial identities: $$\sum_{k=0}^n(-1)^k\binom{n}{k} k^m=\begin{cases} (-1)^n n!&\text{ if }m=n\\0&\text{ if }0\leq m<n\end{cases}$$ The first of which was tackled here while the others seem to have gone largely unasked. The case $m=1$ is tackled here and here , and I can see that I could continue the approaches taken in these answers by differentiating several times. The book-keeping isn't too awful because all these identities are just sums of $0$ s. Thus $0\leq m<n$ isn't too bad, if we can do $m=1$ . However, proving the cases $m=1$ and $m=n$ aren't entirely trivial. Shilov seems to have hidden an interesting exercise in a terse sentence without any hint that it would be interesting. This makes me wonder if there's an easier way to go about proving this result.","['real-analysis', 'calculus', 'binomial-coefficients', 'binomial-theorem', 'derivatives']"
2972532,Die is rolled until 1 appears. What is the probability of rolling it odd number of times?,"Problem : Die is rolled until 1 appears. What is the probability of rolling it odd number of times? So, so far I have this: $\frac{1}{6}$ - this is a probability of rolling ""1"" on first try $\frac{5}{6} \cdot \frac{5}{6} \cdot \frac{1}{6}$ - three tries (two times something else than ""1"" and ""1"" on the 3rd try $\frac{5}{6} \cdot \frac{5}{6} \cdot \frac{5}{6} \cdot \frac{5}{6} \cdot
\frac{1}{6}$ - five tries and so on... By the looks of it, it seems I could come up with following formula $$ p = \left( \frac{5}{6}\right)^{n-1} \cdot \frac{1}{6}$$ where p would be a probability for nth try. However, I cannot think of any way to get probability of all odd number of tries and not sure if I am even on right track here.",['probability']
2972590,Explain these integer solutions,"$a+b=u^2, a^2+b^2=v^4$ I have found the solution: $a=4565486027761, \quad b=1061652293520, \quad u=2372159, \quad v=2165017$ . But I do not know a more theoretical way to get them.","['elliptic-curves', 'number-theory', 'integers', 'diophantine-equations', 'algebraic-geometry']"
2972597,"How to express $\max(x+y,0)$ in terms of $\max(\pm x, 0)$ and $\max(\pm y, 0)$","Suppose we define $X^+, X^-$ as $\max(X, 0)$ and $\max(-X, 0)$ respectively. Then, given $Z = X + Y$ , I've been trying to figure out how to express $Z^+$ and $Z^-$ in terms of $X^\pm$ and $Y^\pm$ , which is supposedly possible. I know that $\max(x, y) = \frac{x+y+|x-y|}2$ , and so $Z^+ = X^+ + Y^+ + \frac{|X+Y|-|X|-|Y|}{2}$ , but I'm unsure what to do with this remaining term, I can't seem to figure out how to express it in terms of the other quantities. I have considered breaking he domain $X, Y$ up into regions where $X+Y\ge 0$ , $X\ge 0$ and $Y\ge 0$ and flip-flopping the signs, but this seemed like too many cases to be the true solution. How exactly do you do this? I can't seem to see it.",['algebra-precalculus']
2972601,"Proof by induction: $\cup_{n=1}^\infty A_n$ is countable, for countable $A_n$","Here is Theorem 1.5.8 in ""Understanding Analysis"" by S. Abbott, 2nd edition. Theorem 1.5.8 (i) If $A_1, A_2, ..., A_n$ are each countable
  sets, then the union $A_1\cup A_2 \cup ... \cup A_n$ is countable. (ii) If $A_n$ is a countable set for each $n \in \mathbb{N}$ , then $\bigcup^\infty_{n=1}A_n$ is countable. Exercise 1.5.3 (b) asks: b) Explain why induction cannot be used to prove part (ii) of Theorem 1.5.8 from part (i). On Slader I find this solution . I have pasted it below: I don't quiet understand the reasoning above and why should it imply (does it?) that the infinite union would not be countable. Suppose I split $\mathbb{N}$ into an infinite number of sets corresponding to the rows below: $1 \;\;\;3 \;\;\;6 \;\;\;10\;\;...$ $2 \;\;\;5\;\;\; 9\;\;...$ $4\;\;\; 8\;\;...$ $7\;\;...$ The infinite union is clearly countable. However, if I am to replicate the argument given in the solution, given $N\in \mathbb{N}$ , we can always find infinitely many $x \in \bigcup_{n=1}^\infty A_n$ such that $x \not\in \bigcup_{n=1}^N A_n$ . What am I missing?",['elementary-set-theory']
2972643,Perfect understanding of Riemann Sums,"I am not sure  I have completely and properly understood Riemann sums. Given a sum like: $$S_n = \displaystyle\sum_{r=1}^n \dfrac{r^4+ r^3n +r^2n^2 +2n^4}{n^5}$$ After dividing by $n^4$ we will get several $r/n$ s, how is it that they represent $x$ when we take the $\lim_{n\to \infty}S_n$ ? What would be the width of the Riemann sum? Someone told me that the width is one but then when we take $\lim_{n \to \infty}$ , the width becomes $\frac{1}{n} = dx$ ? How is that? How do we actually graph them? I tried plotting them on Desmos but in vain. So I would like to receive a proper answer on Riemann sums, preferably with neat graphs covering the following aspects: Left and Right Riemann sums Limit of Riemann sum Graphing Riemann sums Intricacies like $r/n$ represents $x$ and $1/n$ represents $dx$ Other things that might be useful to future readers and me.","['integration', 'riemann-sum', 'calculus']"
2972696,How many non-diagonalizable $2\times 2$ matrices are there with all entries single-digit strictly positive integers?,"I'd like to know how many non-diagonalizable size 2 matrices there are with integer coefficient between 1 and 9 . I built a python program which counts the non-diagonalizable matrices with such coefficients: from sympy import *

count = 0
for a in range(1,10):
    for b in range(1,10):
        for c in range(1,10):
            for d in range(1,10):
                M = Matrix([[a,b],[c,d]])
                if not M.is_diagonalizable():
                    pprint(M)
                    count+=1
print(""Number of non-diagonalizable matrices :"", count) The output was : Number of non-diagonalizable matrices : 0 I wonder if there is a problem with my program or if it's true, that all the size 2 matrices with integer coefficient between 1 and 9 are diagonalizable . Please help me.","['matrices', 'diagonalization', 'python', 'linear-algebra']"
2972700,Torsions of Asymptotic Curves,"Let $p$ be a hyperbolic point of a surface $S$ . Let $\alpha_1$ and $\alpha_2$ be two asymptotic curves passing through $p$ (in two different asymptotic directions) and assume that they have nonzero curvatures at $p$ . Prove that if $\tau_1$ is the torsion of $\alpha_1$ at $p$ and $\tau_2$ is the torsion of $\alpha_2$ at $p$ , then $\tau_1$ = $-\tau_2$ . I'm thinking this has to do with the fact that a hyperbolic point has negative Gaussian curvature (per http://mathworld.wolfram.com/HyperbolicPoint.html ) and possibly relating the principal curvatures to the asymptotic curves, but I'm not quite sure where to go from there.",['differential-geometry']
2972714,Inequality of real numbers with exponent,"For $a,b>0$ are two real numbers and $p\geq 1$ . Is the following inequality true $$|a^p-b^p|\leq|a-b|^p\;\;?$$","['measure-theory', 'lp-spaces', 'inequality', 'real-analysis']"
2972721,Integration with respect to the product of a probability measure and a Markov kernel,"Let $(\Omega_i,\mathcal A_i)$ be a probability space $\mu$ be a probability measure on $(\Omega_1,\mathcal A_1)$ $\kappa$ be a Markov kernel with source $(\Omega_1,\mathcal A_1)$ and target $(\Omega_2,\mathcal A_2)$ Note that $$(\mu\kappa)(A_2):=\int\mu({ d}\omega_1)\kappa(\omega_1,A_2)\;\;\;\text{for }A_2\in\mathcal A_2$$ is a probability measure on $(\Omega,\mathcal A_2)$ . I've read that, by the Cauchy-Schwarz inequality, $$\int\mu({\rm d}\omega_1)\int\kappa(\omega_1,{\rm d}\omega_2)f(\omega_2)\le\int f\:{d}(\mu\kappa)\tag1$$ for all $\mathcal A_2$ -measurable $f:\Omega_2\to[0,\infty)$ . However, it's obvious that we've got equality in $(1)$ for any elementary $\mathcal A_2$ -measurable $f$ , so shouldn't we trivial obtain equality for all $\mathcal A_2$ -measurable $f$ ? What am I missing? I don't see how the Cauchy-Schwarz inequality is needed here.","['markov-process', 'measure-theory', 'probability-theory', 'real-analysis']"
2972748,Are all convex sets Borel sets?,"All convex subsets of $\mathbb{R}^n$ are Lebesgue measurable.  But not all Lebesgue measurable sets are Borel sets.  So my question is, are all convex subsets of $\mathbb{R}^n$ Borel sets?","['measure-theory', 'lebesgue-measure', 'examples-counterexamples', 'borel-sets', 'convex-analysis']"
2972761,Reflection of point in barycentric coordinates,"I have a triangle $ABC$ and a point $P$ with barycentric coordinates ( $\alpha, \beta, \gamma)$ that I want to reflect about the sides $a,b$ and $c$ . Calculating the general expression for a displacement vector perpendicular to $c$ and then using $|PB|=|P'B|$ , I got $$P'=\left(\alpha+x, \beta-\frac{S_A}{c^2}x, \gamma-\frac{S_B}{c^2}x\right)$$ for the reflection about $c$ , where $$x=\frac{-a^2\left((\beta-1)(-\frac{S_B}{c^2})+\gamma(-\frac{S_A}{c^2})\right)-b^2\left(\gamma+\alpha(-\frac{S_B}{c^2})\right)-c^2\left(\alpha(-\frac{S_A}{c^2})+(\beta-1)\right)}{\frac{S_A}{c^2}+\frac{S_B}{c^2}-\frac{S_A S_B}{c^4}}$$ and $$S_A=\frac{-a^2+b^2+c^2}{2}, S_B=\frac{a^2-b^2+c^2}{2}$$ is Conway's Notation. Can anyone confirm this or provide an easier formula? Any help is appreciated.","['triangles', 'geometry', 'barycentric-coordinates']"
2972817,Approximating Darboux integrals with continuous functions,"Let $f:[a,b]\rightarrow\mathbb{R}$ be a bounded function.  Show that the upper Darboux integral of $f$ is equal to the infimum of the Riemann integral of $g$ over all continuous functions $g\geq f$ . I'm not sure how to approximate an arbitrary bounded function with a continuous function.  One thought I had is that that upper Darboux integral is itself an infimum, namely the infimum of upper Darboux sums.  So we are basically trying to show that the infimum of two sets are equal to each other.  But I'm not sure what the conditions are under which two sets have the same infimum, though my question here is relevant to that.","['riemann-integration', 'measure-theory', 'lebesgue-integral', 'riemann-sum']"
2972845,Is a bouquet of circles always a CW complex?,"Let $X$ be a cell complex with one $0$ -cell and an arbitrary (possibly infinite of any degree) number of $1$ -cells which are self-loops to the only $0$ -cell. Clearly $X$ is closure-finite (property C in CW). Is the topology of $X$ necessarily coherent with the set of closed cells of $X$ (property W in CW)? That is, is $X$ a CW complex? Note: If $X$ is first countable, then I can show that being locally finite is equivalent to property W. This result can be used to show, for example, that the closed infinite (countable or uncountable) broom does not have property W. There is a question here which states that an infinite bouquet of circles is not first countable, which excludes using this result.","['general-topology', 'cw-complexes']"
2972851,How does one represent differential geometry on computers?,"So something that I've wondered is that how does one represent differential geometry concepts on a computer, since a lot of the concepts seem ""continuous"" and ""derivative"" (such as having $\frac{\partial}{\partial x^i}$ s as bases, rather than  unit vectors).","['discrete-mathematics', 'differential-geometry']"
2972872,"How to evaluate the integral: $\int_0^\frac{\pi}{2} \cos(x)\sqrt{\cos(x)} \,dx$","$$\int_0^\frac{\pi}{2} \cos(x)\sqrt{\cos(x)} \,dx$$ I've been trying to find a way to integrate this function for a while. From my research I think this should reduce to an elliptic integral but I can't seem to find a way to reduce it to one of the three canonical forms. I found this article which might be useful. I've tried to follow some of the steps but I think it's out of my sphere of knowledge at the moment. So contributions, even if very little, are much appreciated!","['integration', 'elliptic-integrals']"
2972891,Condition number bound using block LU factorization,"Let $A \in \mathbb{C}^{n \times n}$ be invertible and $P$ be a permutation matrix such that $$PA = \begin{pmatrix}A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix} $$ Where $A_{11} \in \mathbb{C}^{n \times n}$ , such that $1 \leq k < n$ , is also invertible. I want to show that if all the elements of $A_{21}A_{11}^{-1}$ have an absolute value that is less than or equal to one, then $K_{\infty}(A_{22}-A_{21}A_{11}^{-1}A_{12}) \leq n K_{\infty}(A)$ Where $K_{\infty}(X) = ||X||_{\infty}||X^{-1}||_{\infty} $ is the condition number of $X$ with respect to the infinity norm. $\textbf{Proof Attempt:}$ I believe that I need to write $PA$ in terms of its $LU$ factorization, such that $$\begin{pmatrix}A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix} = \begin{pmatrix}L_{11} & 0 \\ L_{21} & L_{22} \end{pmatrix}\begin{pmatrix}U_{11} & U_{12} \\ 0 & U_{22} \end{pmatrix}$$ This gives $$A_{11}=L_{11}U_{11} \\
  A_{12}=L_{11}U_{12} \\
  A_{21}=L_{21}U_{11} \\
  A_{22}=L_{21}U_{12} + L_{22}U_{22} $$ This implies $$K_{\infty}(A_{22}-A_{21}A_{11}^{-1}A_{12}) = K_{\infty}(L_{22}U_{12})$$ By the hypothesis, we can also say $||A_{21}A_{11}^{-1}||_{\infty} = ||L_{21}L_{11}^{-1}||_{\infty} < n$ , by our assumption and because the infinity norm is equivalent to the maximum absolute row sum. This is the point where I get stuck, since I don't see how I can get the inequality. I don't see how to to apply the property of the matrix A_{21}A_{11}^{-1} to the problem.","['normed-spaces', 'matrices', 'linear-algebra', 'numerical-linear-algebra', 'matrix-decomposition']"
2972901,First Order Differential equation - separable form,I am trying to evaluate the equation: $$y'=y\left(y^2-\frac12\right)$$ I multiplied the y over and tried to solve it in seperable form (M and N). The partial deritives did not work out to be equal to eachother so I am now stuck finding an integrating factor. Is this the right approach?,['ordinary-differential-equations']
2972950,"Clarification over Ahlfors page 116, 2.1 about winding numbers","Everything on this question is in complex plane. As the book describes a property of a winding number, it says that: Outside of the [line segment from $a$ to $b$ ] the function $(z-a) / (z-b)$ is never real and $\leq 0$ . Here, the above statement should be interpreted as ""never (real and $\leq 0$ )"". If anyone could explain why this is true that would be great. I do get why any point on the line segment (other than $b$ , in which case the denominator is $0$ ) has to satisfy the condition that $(z-a) / (z-b)$ is real and $\leq 0$ , but I am not sure how to prove why any point not on the line has to satisfy the condition also. Here, $a$ and $b$ are arbitrary complex number in a region determined by a closed curve in the complex plane; both points lie on the same region.","['complex-analysis', 'winding-number']"
2972979,$4$ females and $6$ males will be seated on $19$ chairs,"There are $4$ females and $6$ males students. They will be seated on $19$ chairs. How many ways can we do this, if no two females are seated in adjacent chairs? What makes me confused is there are only $10$ students but the chairs are $19$ . If the chairs are $10$ only (equal to the number of persons) I could do $C(7,4)\cdot 4!6!$","['permutations', 'combinatorics']"
2972992,Holder inequality is equality for $p =1$ and $q=\infty$,"Suppose $p=1$ and $q=\infty$ , and the right hand side of Holder inequality is finite. Then, Holder inequality is equality iff $|g| = ||g||_\infty$ a.e. on $\{x: f(x) \not=0\}$ . And here is the solution I found on the internet: I understand this part $\int_{A_\varepsilon} |fg| \le -\delta \varepsilon^2 + \int_{A_\varepsilon} |f |||g||_\infty$ . But, to hold the inequality, we have to show $\int_{X\sim A_\varepsilon} |fg| = \int_{X\sim A_\varepsilon} |f|||g||_\infty$ . I have $$X\setminus A_\varepsilon = \{x: |f(x)| < \varepsilon\} \cup \{x: |g(x)|> ||g||_\infty -\varepsilon\}.$$ Since we have the reverse inequality, $g(x) = ||g||_\infty$ on $x \in X\setminus A_\varepsilon$ . Is this correct? Also, the last equality does not make sense to me because $-\delta\varepsilon^2 + ||g||_\infty\int_X |f| \ge ||g||_\infty \int_X |f|$ . Lastly, suppose that this equation holds. Why is the condition $\{x: f(x) \not=0\}$ necessary? I appreciate if you give me some help.","['measure-theory', 'holder-inequality']"
2972997,Evaluate $\lim_{n \to \infty} (n!)^{\frac{1}{n^2}}$,"Let $a_n = (n!)^{\frac{1}{n^2}}$ . Now, $$n! \geq1 \implies (n!)^{\frac{1}{n^2}} \geq 1$$ and $$n! \leq n^n \implies (n!)^{\frac{1}{n^2}} \leq n^{\frac1n}$$ But $$\lim_{n \to \infty} n^{\frac1n} = 1 = \lim_{n \to \infty} 1$$ Thus by Sandwich Theorem $$\lim_{n \to \infty} (n!)^{\frac{1}{n^2}} =1$$ Is the solution correct?","['limits', 'proof-verification', 'sequences-and-series', 'real-analysis']"
2973012,question about semisimple ring.,"Wedderburn-Artin's theorem: A ring is left semisimple ring iff it is finite product of $M_{n_i}(D_i)$ for some division ring $D_i$ . Due to this theorem,we know that if a ring is left semisimple,then it is also right semisimple. I wonder how to prove this result without using the theorem.the result is equivalent to the following: if $l.gl.dim(R)=0$ ,then $r.gl.dim(R)=0$ . is there a direct proof? Thank you in advance!","['homological-algebra', 'ring-theory', 'abstract-algebra', 'noncommutative-algebra']"
2973019,Planar graph or not (Kuratowski's Theorem),"So the question is whether the graph given is planar or not. After some trial and error I think it is NOT planar, so I want to prove it using Kuratowski's Theorem but I couldn't break it down to $K_5$ or $K_{3,3}$ . Would appreciate any help on this! Also in general, is there any strategy that we can use when trying to apply Kuratowski's Theorem? Or any thing that can help to determine whether we should aim for $K_5$ or $K_{3,3}$ ? Or is it just purely trial and error? I got so frustrated when I could not figure it out.","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
2973038,Show that no group of order 48 is simple,"Show that no group of order 48 is simple I was wondering if I was allowed to do something along this line of thinking: Let $n_2$ be the number of $2$ -Sylow groups. $n_2$ is limited to $1$ and $3$ since these are the only divisors of 48 that are equivalent to $1 \mod 2$ . $n_2=3$ (since if $n_2=1$ the group is definitely not simple) Each $n_2$ subgroup contains 1 distinct element and there are 3 of these subgroups hence there are 3 distinct elements. We have $48-3=45$ elements to account for. At this point, can I assume that these 45 elements form a subgroup and then solve this proof by proving a group of 45 elements form a p-Sylow normal subgroup?","['simple-groups', 'group-theory', 'abstract-algebra', 'sylow-theory']"
2973041,"how to find a, b that satisfy $\displaystyle \lim_{x \to 0} \frac{e^{-2x} -\frac{1+ax}{1+bx}}{x^2}=0$","How can I find those $a$ and $b$ in $\displaystyle \lim_{x \to 0} \frac{e^{-2x} -\frac{1+ax}{1+bx}}{x^2}=0$ ? [my attempt] Since the denominator is $x^2$ , it will be $0$ . And $e^{-2x}$ is 1 so I get $1-\frac{1+ax}{1+bx} = 0$ . I get $a=b$ but Im not sure this is right. Am I taking a wrong way?","['real-analysis', 'calculus', 'limits', 'derivatives', 'exponential-function']"
2973059,"Clarification of Notion of a ""Good Approximation""","My textbook says the following: $$\lim_{x \to x_0} \dfrac{f(x) - f(x_0) - f'(x_0)(x - x_0)}{x - x_0} = 0$$ Thus, the tangent line $l$ through $(x_0, f(x_0))$ with slope $f'(x_0)$ is close to $f$ in the sense that the difference between $f(x)$ and $l(x) = f(x_0) + f'(x_0)(x - x_0)$ , the equation of the tangent line, goes to zero even when divided by $x - x_0$ as $x$ goes to $x_0$ . This is the notion of a ""good approximation that we will adapt to functions of several variables, with the tangent line replaced by the tangent plane. I'm finding it difficult to understand how this notion of ""good approximation"" makes logical sense, given logical reasoning and all of the other mathematics I've learned. For $\dfrac{f(x) - f(x_0) - f'(x_0)(x - x_0)}{x - x_0}$ , as $x \to x_0$ , we have that the numerator and denominator are approaching $0$ at the same rate -- after all, there are no exponents to indicate that one is approaching $0$ quicker than the other. Given this, we would usually say that $\lim_{x \to x_0} \dfrac{f(x) - f(x_0) - f'(x_0)(x - x_0)}{x - x_0} = \dfrac{0}{0}$ , which is an indeterminate form. In order to have that $\lim_{x \to x_0} \dfrac{f(x) - f(x_0) - f'(x_0)(x - x_0)}{x - x_0} = 0$ , we would require that the numerator approach $0$ quicker than the denominator, which, as I said, there is no indication of. So can someone please clarify this notion of ""good approximation"" and explain why it makes mathematical sense? I'm also wondering if this is just a crude/""hand-wavey"" way of explaining the notion of ""good approximation"", since, as I said, it doesn't seem very sensible, and a more sensible and rigorous way would use epsilon-delta notions? If anyone has a better mathematical explanation of the notion of ""good approximation"" feel free to share. I would greatly appreciate it if people could please take the time to clarify this.","['real-analysis', 'linear-approximation', 'calculus', 'limits', 'derivatives']"
2973061,Proof that the number of triangles is uncountably infinite,"Let a triangle be defined as a three-element tuple $(a, b, c)$ where $a$ , $b$ , $c$ are positive real numbers and subjected to triangle inequality. Let $T = \{(a, b, c) | a, b, c \in \mathbb{R}_{>0}, a + b > c\}$ . Prove that $T$ is uncountably infinite. My proof scratch is the following: Let $B = \{(a, b, c)| a, b, c \in \mathbb{R}_{>0}\}$ . Notice that $B = \mathbb{R}_{>0} \times \mathbb{R}_{>0} \times \mathbb{R}_{>0} $ . Since the Cartesian product of uncountable sets is uncountable, $B$ is uncountable. The subset of an uncountable set is uncountable. By definition, $T$ is a subset of $B$ . Therefore $T$ is uncountably infinite. $$\tag*{$\blacksquare$}$$ UPDATE: Based on the feedback from Anurag A, José Carlos Santos, and Patrick Stevens, the following is another attempt at the proof: Theorem: $T$ is uncountable. Proof: For an arbitrary but fixed triangle $(a, b, c)$ and an arbitrary positive real number $d$ , $(da, db, dc)$ is a triangle. Since there are uncountably infinite positive real number, the set of all $(da, db, dc)$ are uncountable. Since the set of all $(da, db, dc)$ is uncountable and it is a subset of all triangles, the set of all triangles is uncountable. $$\tag*{$\blacksquare$}$$ UPDATE: Based on the feedback from Patrick Stevens, the proof is simplified using injection. Theorem: $T$ is uncountable. Proof: Let $f(x) = (ax, bx, cx)$ . For a fixed $u, v \in \mathbb{R}_{>0}$ and $(a, b, c) \in T$ , suppose $f(u) = f(v)$ , then: $$\begin{equation}\begin{aligned}
(au, bu, cu) &= (av, bv, cv)\\
\end{aligned}\end{equation}\tag{1}\label{eq1}$$ If we abuse the notation and treat both sides of $\eqref{eq1}$ as vectors: $$\begin{equation}\begin{aligned}
\begin{bmatrix}
    au\\
    bu\\
    cu\\
\end{bmatrix} &= \begin{bmatrix}
    av\\
    bv\\
    cv\\
\end{bmatrix}
\\
\begin{bmatrix}
    \frac{1}{a}
    \frac{1}{b}
    \frac{1}{c}
\end{bmatrix}
\begin{bmatrix}
    au\\
    bu\\
    cu\\
\end{bmatrix} &= 
\begin{bmatrix}
    \frac{1}{a}
    \frac{1}{b}
    \frac{1}{c}
\end{bmatrix}
\begin{bmatrix}
    av\\
    bv\\
    cv\\
\end{bmatrix}\\
3u &= 3v\\
u &= v
\end{aligned}\end{equation}\tag{2}\label{eq2}$$ By definition, $f$ is an injection from $\mathbb{R}_{>0}$ to $T$ . Therefore, $T$ has at least as many elements as $\mathbb{R}_{>0}$ . Since $\mathbb{R}_{>0}$ is uncountable, $T$ is uncountable. $$\tag*{$\blacksquare$}$$","['elementary-set-theory', 'proof-verification', 'triangles']"
2973066,upper bound of an inequality,"Let $X_t = \theta_1\epsilon_{t-1} + ... + \theta_q\epsilon_{t-q} + \epsilon_t$ where $\epsilon_t$ is a white noise with zero mean variance $\sigma^2$ . $X_t$ is said to be invertible if $\epsilon_t = \sum_{j=0}^\infty \pi_j X_{t-j}$ where $\sum_{j=0}^\infty | \pi_{j}| < \infty$ I want to show \begin{equation}
\sigma^2 + E\left(\sum_{j > m} \pi_j X_{m+1-j}\right)^2 \leq \sigma^2 + \left(\sum_{j>m}|\pi_j|\right)^2\gamma(0)
\end{equation} where $\gamma(0) = E(X_{t}^2)$ for all $t$ . Also, \begin{equation}
\left(\sum_{j>m}|\pi_j|\right)^2\gamma(0) \leq Kc^m
\end{equation} where $K > 0$ and $c \in (0, 1)$ Any hints will be appreciated.","['time-series', 'statistics', 'inequality']"
2973071,On the commutativity of matrices and their exponentials,"It is fairly easy to see that if $A$ and $B $ , real square matrices, commute, then $A $ and $e^B $ commute. In fact, $$Ae^B = \sum_{n=0}^\infty A\frac{B^n}{n!} = \sum_{n=0}^\infty \frac{B^n}{n!}A = e^BA $$ But is the reverse true as well? If $A $ and $e^B $ commute, do $A $ and $B $ commute as well? If not, can you help me finding a counter-example? What if both $A $ and $B $ are not constant matrices but matricial functions of $t $ ?","['matrices', 'matrix-exponential', 'linear-algebra']"
2973082,Choosing columns in array,"In an array with four rows and $n\geq 1$ columns, some subset of cells are marked. Can we always choose some columns in such a way that for at least three rows, the number of chosen marked cells and the number of unchosen marked cells differ by at most $1$ ? An initial try is to pick some three fixed row (for example the first three rows) and see if it is possible to choose the columns in the required way. However, this is not always the case: it could be that there are three columns, in the first row the first and second columns are marked, in the second row the second and third column, and in the third row the third and first columns. But maybe there is some clever way to pick the three rows?",['combinatorics']
2973099,Why can't I find the value of $x$ using logarithms?,"This is concerning a question in stack exchange : Sum of real values of $x$ satisfying the equation $(x^2-5x+5)^{x^2+4x-60}=1$ . I was actually wondering why the correct result is not obtained when applying $\log$ on both sides,like how the second answer does.Why is this so? Is it possible to get this answer using logarithms?","['algebra-precalculus', 'proof-writing', 'exponential-function', 'logarithms']"
2973122,Find the area of the shaded region in the figure below:,Find the area of the shaded region in the figure below: I am completely stuck on how to start off this question. Please help on some guidance on how to start it off.,"['area', 'geometry']"
2973140,Approximation of $\log(x)$ for very small $x$,"To avoid the $\log()$ function, I am looking for a good approximation of $\log(x)$ for very small $x$ (e.g. order $10^{-5}$ ). I think Taylor series expansion is useless because around these small $x$ , the first order derivative approachs $+\infty$ . I did try this approximation $\log_{10}(x) \approx 1 - \frac{1}{\sqrt{x}}$ but still don't have satisfactory results. Could anyone suggest some better approximations?","['derivatives', 'approximation', 'logarithms']"
2973156,Evaluate $\lim_{n\to \infty}\left(\frac{1}{\sqrt{n(n+1)}}+\frac{1}{\sqrt{(n+1)(n+2)}}+\cdots+\frac{1}{\sqrt{(2n-1)2n}}\right)$,"I want to evaluate $$\lim_{n\to \infty}\left(\frac{1}{\sqrt{n(n+1)}}+\frac{1}{\sqrt{(n+1)(n+2)}}+\cdots+\frac{1}{\sqrt{(2n-1)2n}}\right).$$ I have computed \begin{align*}
a_{n+1}-a_n & = \frac{1}{\sqrt{(2n+1)(2n+2)}}-\frac{1}{\sqrt{n(n+1)}}\\
            & = \frac{1}{\sqrt{n+1}}\left( \frac{1}{\sqrt{2(2n+1)}}-\frac{1}{\sqrt{n}} \right).
\end{align*} Now I'm stuck.","['convergence-divergence', 'real-analysis']"
