question_id,title,body,tags
3634873,"If $f(x)$ is a polynomial with real coefficients such that $f(x)\geq f'(x)$ for all $x$, then $f(x)\geq 0$ for all $x$","Let $f(x)$ be a polynomial with real coefficients such that $ f(x)  \ge  f'(x) $ for all $ x \in \mathbb {R}$ , show that $ f(x) \ge 0 $ for all $x \in \mathbb{R}$","['calculus', 'functions', 'polynomials']"
3634996,Commuting vector fields with common first integrals,"Let $M$ be a $n-$ dimensional smooth manifold and $X\in\chi(M)$ be a smooth vector field defined on it. Let $f_1,...,f_{n-2}:M\rightarrow \mathbb{R}$ be functionally independent first integrals of $X$ , i.e. $$ L_{X}f_i=0,\quad \forall i=1,2,...,n-2. $$ Moreover, suppose there exists another vector field $Y\in\chi(M)$ , independent from $X$ , which is commuting with it, namely $$ \mathcal{L}_X Y = [X,Y]=0. $$ Is there some known general condition that $Y$ must satisfy in order to share the first integrals with $X$ ? I tried saying that for any $i=1,...,n-2$ since $XY=YX$ , then we have $$ 0=YX(f_i) = XY(f_i) $$ and hence the functions $g_i=Y(f_i)\in\mathcal{C}^{\infty}(M)$ are first integrals of $X$ . Namely, when is it true that then $\mathcal{L}_{Y}f_i=0$ for all the $i'$ s? But at this point, I am stuck because I can't think about some reasonable condition on $Y$ in order to be sure that $Y(f_i)=0$ . My ideas are to use the fact that we can have at most $(n-1)$ independent first integrals of both $X$ and $Y$ , and moreover at most $n$ linearly independent vectors on $T_mM$ for any $m\in M$ , but I don't actually know how to proceed.","['integrable-systems', 'classical-mechanics', 'vector-fields', 'lie-derivative', 'differential-geometry']"
3635003,"Advantage of the more general notion of ""neighborhoods"" in topology","The notion of ""open sets"" is a fundamental concept in topology. I have been puzzled by (the use of) another slightly more general but closely related one: neighborhoods . Given a topological space $(X,\tau)$ , and a point $p\in X$ , a neighbourhood of $p$ is a subset $V$ of $X$ that includes an open set $U$ containing $p$ , $$
p\in U\subset V.
$$ On the other hand, given a "" neighborhood system "" on a set $X$ , one can define a topology that is consistent with the notion of ""neighborhoods"". This Wikipedia article makes a remark that ""Some mathematicians require that neighbourhoods be open"". (For instance, in Munkres's Topology (c.f. page 96), the statement "" $U$ is an open set containing $x$ "" is considered as equivalent to "" $U$ is a neighborhood of $x$ "".) Question : What is the advantage of the more general notion of ""neighborhoods"" (that is not required to be open) in practice? Is it simply a matter of taste or does it make significant simplifications in some statement of theorems, proofs or definitions? Notes: Please note that this is question is not asking the definitions of ""neighborhoods"" and ""open sets"" as the suggested linked question did.","['general-topology', 'soft-question', 'terminology']"
3635060,Question on the differences in the definitions of what a tensor is,"Below are the common definitions of tensor. a. ""a tensor is a quantity which transforms according to a definite law under the change of the coordinate system"". b. ""a tensor is a multilinear function which takes vectors and duals and produces a scalar"" Questions: How are these two definitions related? That is, how can we start with one of definitions and arrive at the other? What is the significance of being ""multilinear""? If we have a function of vectors & duals producing a scalar which is not multilinear, what breaks down? The way I have so far understood a tensor is as follows. Multiple vectors might act on each point in space and produce a result. Tensor is a way of describing the whole phenomena. But again, I could not relate this to the definitions. Why ""invariance under coordinate change"" or ""mulitlinearity"" are required here?","['tensors', 'multilinear-algebra', 'linear-algebra', 'general-relativity', 'differential-geometry']"
3635099,Detail on Portmanteau theorem,"Let $(\mu_n)_n$ and $\mu$ be probability measures on $(\mathbb{R}^d,B(\mathbb{R}^d))$ . In Portmanteau theorem, one can prove that $(\mu_n)_n$ converges weakly to $\mu$ if and only if for all bounded, lower semicontinuous functions $f$ we have $$\int_{\mathbb{R}^d}f(x)d\mu(x) \leq \liminf_n\int_{\mathbb{R}^d}f(x)d\mu_n(x),$$ this is true because, without loss of generality, we can assume $f \geq 0$ (we can take, for the general case, $f=f^+-f^-$ ) and using Fatou's lemma, $\liminf_n \mu_n(O) \geq \mu(O)$ for every open $O$ and that $$\int_{\mathbb{R}^d}f(x)d\mu(x)=\int_{0}^{+\infty}\mu(f>x)dx$$ we will obtain the result. So, my question is, do we have the same result if we only suppose that $f$ is bounded and lower semi continuous $\mu$ a.e which means that $\mu(Q)=1$ where $Q$ is the set of points where $f$ is lower semicontinuous?","['measure-theory', 'probability-limit-theorems', 'probability-theory', 'weak-convergence']"
3635110,Does every smooth local frame of the tangent bundle correspond to a chart?,"Every smooth chart $(U,\phi)$ on a smooth manifold $M$ determines a smooth local frame $U \to TM$ on the tangent bundle, namely $(\partial/\partial x^i)$ , where $(x_i)$ are the coordinate functions of $\phi : U \to \mathbb{R}^n$ . But is the converse true? Namely, given any smooth local coordinate frame $(\sigma_i) : M \supset V \to TM$ , can we construct a chart such that the $\sigma_i$ are partial derivatives of the coordinate functions?","['vector-fields', 'tangent-bundle', 'smooth-manifolds', 'differential-geometry']"
3635132,Restrictions on a Function,"If $f(x) =$ \begin{cases}
x^2-4 &\quad \text{if } x \ge -4, \\
x + 3 &\quad \text{otherwise},
\end{cases} then for how many values of $x$ is $f(f(x)) = 5$ ? I'm not sure how to really start from this question other than bashing values. I need some help on a start, thanks!","['algebra-precalculus', 'functions']"
3635138,"If $\sec x + \csc x =p$ has four distinct solutions between $(0,2\pi)$, then which if the following is incorrect?","a) $p^2-8>0$ b) $p=\sqrt 2$ c) $p=-\sqrt 2$ d) $p=0$ My attempt $$\frac{\sec x +\csc x}{2} \ge \sqrt {\sec x \csc x}$$ $$\frac{\sin x +\cos x}{\sin x \cos x }\ge 2\sqrt {\frac{1}{\sin x \cos x}}$$ $$\sin x +\cos x \ge 2\sqrt {\sin x \cos x}$$ $$(\sqrt {\sin x}-\sqrt {\cos x})^2\ge 0$$ $$\sin x \ge \cos x$$ I realise that some of that squaring might have removed or added some roots, but I don’t know what else to do From this result, the interval for $x$ is $[\frac{\pi}{4}, \pi]\cup [\frac{5\pi}{4}, \frac{3\pi}{2}]$ Don’t know what do next. Can I get some insight? Another attempt $$\sin x +\cos x =p \sin x \cos x$$ $$1+2\sin x\cos x =\frac 14 p^2 4\sin^2x \cos ^2x$$ $$1+\sin 2x =\frac 14 p\sin^2 2x$$ $$p\sin^22x-4\sin 2x -4=0$$",['trigonometry']
3635266,Find a sequnce $\{a_n\}_{n=1}^{\infty}\in l_2$ such that $\sum_{n=1}^{\infty} a_n/\sqrt{n} = \infty$.,"As stated in title, I am curious how to construct a sequnce $\{a_n\}_{n=1}^{\infty}$ such that $\sum_{n=1}^{\infty} a_n^2 < +\infty$ but $\sum_{n=1}^{\infty}\frac{a_n}{\sqrt{n}} = \infty$ . This problem arises when I try to show that $f(x) = \sum_{i=1}^{\infty} \frac{x_n}{\sqrt{n}}$ defined on $l_2$ space is not bounded.","['functional-analysis', 'real-analysis']"
3635418,"Definite integration of trig functions: $\int_{0}^{\infty} \frac{\sin 2020x}{x} \prod_{k=1}^{n} \cos(kx) \, \mathrm d x$","Given $$\int_{0}^{\infty} \frac{\sin x}{x} \operatorname d x=\frac{\pi}{2}$$ Find the natural values of $n$ which satisfy , $$\int_{0}^{\infty} \cos x \cdot \cos 2 x\cdot  \cos 3 x\cdots\cos n x \cdot \frac{\sin 2020 x}{x} d x= \frac{\pi}{2}$$ My approach: Consider the given integral as $I(n)$ . Now if I find values of $I(n)$ corresponding to $n=1,2,3\dots$ I am getting value $\pi / 2$ . So I can see natural values of $n$ less than $2020 $ satisfy the equation. I don't know the answer to the problem. Is there some elegant approach to solve this question?","['integration', 'improper-integrals', 'definite-integrals']"
3635426,Does the ordering of a Schauder basis matter in Hilbert space?,"If $S=\{v_i\}_{i\in\mathbb N}$ is a (not necessarily orthogonal) Schauder basis for a Hilbert space $H$ , must $S$ be an unconditional Schauder basis? I define these terms below because not every source I have found agrees perfectly on the definitions. On general Banach spaces (where orthogonality is undefined), there exist conditional Schauder bases. But if the Schauder basis is on a Hilbert space and is orthogonal, then it is indeed unconditional. So my question is therefore whether this unconditional property remains if we stay in Hilbert space but orthogonality is removed. Definitions: An ordered countable subset $\{v_i\}_{i\in\mathbb N}$ of a Banach space $V$ is a Schauder basis if every $v\in V$ can be written uniquely as a series $v=\sum_{i=1}^\infty a_i v_i$ , where convergence is with respect to the norm-induced topology. A Schauder basis is unconditional if the terms of any convergent series can be rearranged without affecting the sum. A Hilbert basis is a maximal orthonormal subset of a Hilbert space $H$ , possibly uncountable. It is known that even for non-separable Hilbert spaces, there exists a Hilbert basis $B$ , and that every $v\in H$ can be expressed uniquely as a sum of a countable subset of $B$ , which is always independent of summation order.","['hilbert-spaces', 'conditional-convergence', 'schauder-basis', 'functional-analysis']"
3635451,Finding the point on $f(x)=\sqrt{2x+1}$ where the tangent line is perpendicular to $3x + y = 5$,"$$f(x)=\sqrt{2x+1}$$ Find the point on the radical function where the tangent line is perpendicular to $3x + y = 5$ . I worked out the $y= -3x+5$ , and therefore the slope was $-3$ . I then used the negative reciprocal to find the slope of a perpendicular line, $m= 1/3$ . I set the derivative equal to $1/3$ to find $x$ which I found to be $4$ , $x=4$ . I then put $x=4$ back into the original equation, and found the $y=3$ when $x$ is $4$ . Using the slope I had, and the point $(4,3)$ , I inserted these numbers in the equation $y=mx+b$ , to find that $b= 5/3$ . So my final equation was $y=\frac13x+\frac53$ . I put this and $y= -3x+5$ into my graphing calculator. The lines are not perpendicular to each other. I am not sure what I did wrong. If someone could assist me that would be awesome.","['calculus', 'derivatives']"
3635588,"Using that $1 + z + z^{2} + ... + z^{n} = \frac{1-z^{n+1}}{1-z}$ and taking the real parts, prove that:","$$ 1 + \cos \theta + \cos2\theta + ... + \cos n\theta = \frac12+\frac{\sin[(n + \frac{1}{2})\theta]}{2\sin(\frac{\theta}{2})} $$ for $0 < \theta < 2\pi$ . Alright. What I have done is this, using the De Moivre's Formula: $$ 1 + \cos \theta + \cos2\theta + ... + \cos n\theta = \operatorname{Re}(1 + (\cos\theta + i\sin\theta) + (\cos2\theta + i\sin2\theta) + ... + (\cos n\theta + i \sin n \theta))$$ That is equivalent to $$ \operatorname{Re}(1 + e^{i\theta} + e^{2i\theta} + ... e^{ni\theta}) = \operatorname{Re} \biggl(\frac{1 - e^{(n+1)i\theta}}{1 - e^{i\theta}}\biggr)$$ I've reached to this point, but now I don't know what to do. Any hint or idea?","['complex-analysis', 'problem-solving']"
3635686,Understanding etale cohomology versus ordinary sheaves,"I am a physicist trying to understand etale cohomology from Shafaverich, and I would like to check a misunderstanding, undoubtedly. When defining etale cohomology, it seems it is sheaf cohomology in the sense of right-derived functors, but with the etale site, as opposed to just concerning open subsets. For concreteness, we fix an etale sheaf $\mathcal F : U \mapsto \mathcal O_U(U)$ where $U$ is a scheme which comes equipped with an etale morphism $f:U\to X$ . We could then take an injective resolution, i.e. $$0\to \mathcal F \to \mathcal I^0 \to \mathcal I^1 \to \mathcal I^2 \to \cdots$$ We can then take sections, i.e. apply $\Gamma(X,-)$ : $$\Gamma(X,\mathcal I^0) \to \Gamma(X,\mathcal I^1) \to \Gamma(X,\mathcal I^2) \to \cdots$$ Taking the cohomology then yields $H^q(X,\mathcal F)$ . However, I do not see how this makes use of the ""new"" version of a sheaf, namely the etale sheaf. We are applying the etale sheaves to $X$ , which belongs to the site used in ordinary sheaf cohomology, so it seems like ordinary sheaf cohomology and etale cohomology should always agree? I don't see from the definition of etale cohomology, how we end up using anything extra, thanks to enlarging the site to etale maps.","['etale-cohomology', 'algebraic-geometry', 'sheaf-cohomology']"
3635757,Let $p$ be a prime number and let $G$ be a finite $p\text{-group}$. Let $M$ be a maximal subgroup of $G$.,"QUESTION: Let $p$ be a prime number and let $G$ be a finite $p\text{-group}$ . Let $M$ be a maximal subgroup of $G$ .   Show that $M$ is a normal subgroup of $G$ and that $| G: M | = p$ . THE HINT GIVEN IS: By strong induction on $n$ , where $| G | = p ^{n}$ . Let $ y \in Z(G) - \{1 \}$ , a convenient $x$ power belonging to $Z(G) - \{1\}$ has order $p$ . Consider $G / \langle x \rangle$ . ANSWER GIVEN: By induction on $n$ , where $| G | = p^ n$ . According to the tip, consider $x \in Z (G)$ of order $ p $ and let $N = \langle x \rangle$ . The group $ G / N $ has order $ p^{n-1} $ , so we can apply induction. If $ N $ is a subgroup of $ M $ then $ M / N $ is normal for the $ p $ index in $ G $ . Now suppose $ N $ is not a subgroup of $ M $ . Being $ M $ maximal we get $ NM = G $ . On the other hand being $ | N | = p $ prime we have $ N \cap M = \{1 \} $ logo $ p^{n-1} = | G / N | = | MN / N | = | M / M \cap N | = | M | $ e we deduct $| G: M | = p $ . In addition $ M $ is a subgroup of $ N_G (M) $ and $ N $ is a subgroup of $ N_G (M) $ because $ N \leq Z (G) $ . It follows that $ G = NM \leq N_G (M) $ so $ M $ is a normal subset of $ G $ . MY QUESTIONS: I didn't understand the following steps showed in this proof. The induction used in its solution. If $N$ is subgroup of $M$ then one is stated that $M/N$ is normal (why?) If $N$ is NOT a
subgroup of $M$ then one is stated that $NM=G$ (again, why?) Why $N \cap M=\{1\}?$ Why $N \leq N_G(M)$ ? Why $NM\leq N_G(M)$ ?","['maximal-subgroup', 'group-theory', 'finite-groups', 'p-groups']"
3635799,Most gentle introduction to undergraduate analysis,"I will be teaching a course which expects to have the following topics pulled from a now out-of-print book: Fundamental ideas of analysis, by Michael C. Reed, John Wiley&Sons,1998 As we can't use this book, I need something comparable. The expected topics include (again these are presumably pulled from the book mentioned above, and I'm supposed to teach these): Set of Natural Numbers Set of Rational Numbers Set of Real Numbers Completeness Axiom Sequences Limit Theorems for Sequences Monotone Sequences and Cauchy Sequences Series Alternating Series and Integral Tests Continuity Properties of Continuous Functions Sequences and Series Functions Uniform Convergence Differentiation and Integration of Power Series Mean Value Theorem L’Hopital Rule Taylor Theorem Part one of Integration Part two of Integration So can someone tell me the most gentle undergraduate analysis book which would deal with these (as gently as possible)?","['book-recommendation', 'analysis', 'real-analysis']"
3635807,Expected value of sin of brownian motion,"I am having trouble finding $E[X_t]$ , where $X_t = \sin(B_t)$ and $B_t$ is a Brownian motion. I have learned a little about Ito integrals but I don't think I really understand how to use them. Here is my approach at the moment: $$E[X_t] =E[\sin(B_t)] =\left(\frac{1}{\sqrt {2\pi t} } \int_{-\infty}^\infty e^\frac{-(x)^2}{2t} \sin(x) dx\right)\bigg\rvert_{x=B_t}$$ Is this the right approach? Any help would be appreciated, thank you!","['integration', 'statistics', 'stochastic-processes', 'brownian-motion', 'probability']"
3635875,Compute the kernel of the group hom $\Omega : \Bbb{Q}^{\times} \to \Bbb{Z}^+$.,"The $\Omega$ function is the counting function that returns precisely the number of primes $\Omega(n)$ (including multiplicity) that divide a natural number $n \in \Bbb{N}$ .  For example $\Omega(6) = 2, \Omega(8) = 3$ , etc.  It is known and easily seen to be completely multiplicative on $\Bbb{N}$ ie. $\Omega(ab) = \Omega(a) + \Omega(b)$ for all $a, b \in \Bbb{N}$ . Extend the definition to all of $\Bbb{Z}\setminus 0$ by defining $\Omega(-n) := \Omega(n)$ for all $n \gt  0$ .  Now extend the definition to all of $\Bbb{Q}^{\times} = \Bbb{Q}\setminus 0$ by defining $\Omega(a/b) = \Omega(a) - \Omega(b)$ .  Then what you have is a group homomorphism from the multiplicative rationals onto (surjective) $\Bbb{Z}^+$ : Let $$
a/b, c/d \in \Bbb{Q}
$$ Then $$\Omega(\dfrac{c}{d} \dfrac{a}{b}) = \Omega(\dfrac{ca}{db}) = \\\Omega(ca) - \Omega(db) = \\ \Omega(c) + \Omega(a) - (\Omega(d) + \Omega(b)) =\\ \Omega(c) - \Omega(d) + \Omega(a) - \Omega(b) = \\ \Omega(c/d) + \Omega(a/b)$$ It is well-defined since if $\dfrac{a}{b} = \dfrac{a'}{b'}$ , then $ab' = a' b$ so that $$\Omega(a) + \Omega(b') = \\ \Omega(ab') = \Omega(a'b) = \\ \Omega(a')  + \Omega(b) \implies \\ \Omega(a) - \Omega(b) = \Omega(a') - \Omega(b') \implies \\ \Omega(\dfrac{a}{b}) = \Omega(\dfrac{a'}{b'})$$ . Since we have a surjective group homomorphism $\Omega: \Bbb{Q}^{\times} \to \Bbb{Z}^+$ .  Was wondering how we could more explicitly compute the kernel which is : $$
\ker \Omega = \{ a/b \in \Bbb{Q}^{\times}: \Omega(a) = \Omega(b) \}
$$ For example $p/q \in \ker \Omega$ for all $\pm$ primes $p, q\in \Bbb{Z}$ . Thus isn't it a weird or ""exotic"" normal subgroup of $\Bbb{Q}^{\times}$ ?  Does it have a name? By the first isomorphism theorem for groups, $\Bbb{Q}^{\times}/\ker \Omega \simeq \Bbb{Z}^+$ . Question 2. Can we extend $\Omega$ to $\Bbb{Q}(i)$ easily?","['group-homomorphism', 'integers', 'group-theory', 'prime-numbers', 'rational-numbers']"
3635900,"A step in the proof of Characterization of $W^{1,\infty}$","In the book of PDE, evans, the proof of the characterization of $W^{1,\infty}$ uses the following argument: Suppose $u$ has compact support and Lipchitz continuous. Then $$
\Vert D_i^{-h}u\Vert_{L^\infty(\mathbb{R}^n)}\leq Lip(u),
$$ where $D_i^{-h}u$ the difference quotient defined by $$
D_i^hu=\frac{u(x+he_i)-u(x)}{h}.
$$ Then there exists a function $v_i\in L^\infty(\mathbb{R}^n)$ and a subsequence $h_k\rightarrow0$ such that $$
D_i^{-h_k}u\rightharpoonup v_i \quad\text{weakly in }L^2_{loc}(\mathbb{R}^n).
$$ Question: I don't know why such a subsequence exists. Since $u$ has some compact support $\Omega$ , then $u\in L^2(\Omega)$ . Then there exists a function $v_i\in L^2(\Omega)$ such that $$
D_i^{-h_k}u\rightharpoonup v_i \quad\text{weakly in }L^2(\Omega).
$$ But I don't know why this $v_i\in L^\infty$ .","['sobolev-spaces', 'functional-analysis', 'lipschitz-functions', 'partial-differential-equations']"
3635934,The number of binary strings of length $n$ with no three consecutive ones,"I am becoming more familiar with proving sequences that are given in a problem, though I am not familiar with how to actually define a sequence. More specifically, I am dealing mostly with binary numbers and tiling problems, though again, most of what I have deslt with have been proofs, not trying to define a sequence. The particular problem that has been frustrating me for the past few days is this: Define a sequence { $s_n$ } by recursion such that there are s_n different sequences of 0's and 1’s of length n that do not contain three consecutive 1's. I know the answer is $s_n = s_{n−1} + s_{n−2} + s_{n−3}$ but I don't understand why. I have tried listing the possible values for n: n = 1 has 2 posibilities (0, 1) n = 2 has 4 posibilities (00, 01, 10, 11) n = 3 has 7 posibilities (000, 001, 010, 011, 100, 101, 110, not including 111) etc. I know this problems also relates to Fibonacci's sequence in that each number in the sequence builds off of the previous one(s), though at this point, I don't know where to continue. Could someone please explain the steps to get to $s_n = s_{n−1} + s_{n−2} + s_{n−3}$ ?","['combinatorics', 'recurrence-relations', 'discrete-mathematics', 'sequences-and-series']"
3635978,Is there an analytic way to tell if a system of ordinary differential equations is conservative?,"I don’t know the exact definition of conservative, but we can assume that conservative means the sum of Lyapunov exponents is zero. Is there an analytic method to show that a given system is conservative?
I came to this question by reading Sprott’s Elegant Chaos. A system of interest could be e.g.: $$U''' + U' + \frac{1}{3}U^3 - Uc=0$$ where $c$ is constant, $U(t)$ is a function of time. It can be described as system of three equations: $$\begin{align}
U' &= X \\
X' &= Y  \\
Y' &= -X - \frac{1}{3} U^3 +Uc
\end{align}$$ Then I think (but cannot prove it) that the trace of the Jacobian $\operatorname{Tr}(J)$ shows the conservativeness. $$\operatorname{Tr}(J) = \frac{\partial U'}{\partial U} + \frac{\partial X'}{\partial X} + \frac{\partial Y'}{\partial Y} = 0 + 0 + 0 = 0$$ It also means that if $\operatorname{Tr}(J) < 0$ , the system is dissipative, and if $\operatorname{Tr}(J) > 0$ , the system diverges, i.e., it is not bounded. Can you say if I am right or wrong?","['jacobian', 'ordinary-differential-equations', 'dynamical-systems']"
3635993,Primes of the form $p=x^2+ny^2$ – Why are congruence given mod $4n$,"I’m currently reading Cox’s Primes of the Form $x^2+ny^2$ , and when giving congruences regarding forms of $x^2+ny^2$ , they are given $\pmod{4}$ . E. g., when stating the primes that satisfy $\left(\dfrac{-7}p\right)=1$ , it is stated $p \equiv 1,9,11,15,23,25 \pmod{28}$ . But this is equivalent to $p \equiv 1,2,4 \pmod 7$ , which is a much more natural answer as this is what quadratic reciprocity immediately reveals. I assume this was done for a reason, as when the solutions to $p=x^2+ny^2$ are discussed, they are always $\pmod{4n}$ . E. g., if $p=x^2+5y^2$ , $p \equiv 1,9 \pmod{20}$ . On page 13, it says that: The reciprocity step can be restated as the following question: is there a congruence $p \equiv a,b,\cdots \pmod{4n}$ which implies $\left(\dfrac{-n}p\right)=1$ when $p$ is prime? But I don’t understand why it is necessary to use $4n$ rather than $n$ . I’m sorry if this is a silly question but I feel that it’s essential to understand before continuing. Thanks for any help in advance.","['number-theory', 'quadratic-forms']"
3636009,Why can't Antoine's necklace fall apart?,"Antoine's necklace is an embedding of the Cantor set in $\mathbb{R}^3$ constructed by taking a torus, replacing it with a necklace of smaller interlinked tori lying inside it, replacing each smaller torus with a necklace of interlinked tori lying inside it, and continuing the process ad infinitum ; Antoine's necklace is the intersection of all iterations. A number of sources claim that this necklace ' cannot fall apart ' (e.g. here ). Given that the necklace is totally disconnected this obviously has to be taken somewhat loosely, but I tried to figure out exactly what is meant by this. Most sources seem to point to this paper (which it must be noted contains some truly remarkable images, e.g. Figure 12). There the authors make the same point that Antoine's necklace 'cannot fall apart'. Nevertheless, all they seem to show in the paper is that it cannot be separated by a sphere (every sphere with a point of the necklace inside it and a point of the necklace outside it has a point of the necklace on it). It seems to me to be a reasonably trivial exercise to construct a geometrical object in $\mathbb{R}^3$ which cannot be separated by a sphere, and yet can still 'fall apart'. In the spirit of the construction of Antoine's necklace, these two interlinked tori cannot be separated by a sphere (any sphere containing a point of one torus inside it will contain a point of that torus on its surface), but this seems to have no relation to the fact that they cannot fall apart - if we remove a segment of one of the tori the object still cannot be separated by a sphere, and yet can fall apart macroscopically. The fact mentioned here that the complement of the necklace is not simply connected, and the fact mentioned here that there are loops that cannot be unlinked from the necklace shouldn't impact whether it can be pulled apart either, as both are true of our broken rings My question is this: Is it possible to let me know either: How I have misunderstood separation by a sphere (so that it may still be relevant to an object being able to fall apart), What property Antoine's necklace does satisfy so that it cannot fall apart (if I have missed this), or What is actually meant when it is said to be unable to fall apart (if I have misunderstood this)","['general-topology', 'geometry', 'low-dimensional-topology', 'fractals']"
3636093,How can I solve $f(t^2+u)=tf(t)+f(u)$,"Solve $f(t^2+u)=tf(t)+f(u)$ on $\mathbb{R}$ . My solution is, if we take $u=t$ , then $f(t^2+t)=(t+1)f(t)$ and let $g(x)=\frac{f(x)}{x}$ , then $g(t^2+t)=g(t),(t\neq-1,0)$ . It means $g(x)=k,\quad k\in\mathbb{R}\tag{*}$ Therefore $\boxed{f(x)=kx\quad\forall k,x\in\mathbb{R}}$ . I'm not sure about $(*)$ is true.","['contest-math', 'functional-equations', 'functions', 'solution-verification']"
3636159,Mark a six-sided die with the results of six rolls of a previous die. How many iterations until all the faces match?,"This is FiveThirtyEight's ""Riddler Classic"" puzzle for 27 March, 2020: From Chris Nho comes a question of rolling (and re-rolling) a die: You start with a fair 6-sided die and roll it six times, recording the results of each roll. You then write these numbers on the six faces of another, unlabeled fair die. For example, if your six rolls were 3, 5, 3, 6, 1 and 2, then your second die wouldn’t have a 4 on it; instead, it would have two 3s. Next, you roll this second die six times. You take those six numbers and write them on the faces  of yet another fair die, and you continue this process of generating a new die from the previous one. Eventually, you’ll have a die with the same number on all six faces. What is the average number of rolls it will take to reach this state? Through numerical simulations, I know that the average number of rows to reach the final state is approximately 9.66 , and the PDF of the number of rows to reach this state looks like My question is: how do we calculate the average number of rows analytically? Is is possible to analytically calculate its PDF as well?","['dice', 'puzzle', 'combinatorics', 'probability']"
3636236,Gauss's Lemma Proof,"Theorem 2.39 (Gauss’s Lemma). A polynomial $f ∈ \mathbb{Z}[x] ⊆ \mathbb{Q}[x]$ of the form $$f(x) = x^n + a_{n−1}x+^{n−1}+ ...+ a_1x + a_0$$ is irreducible in $\mathbb{Q}[x]$ if and only if it is irreducible in $\mathbb{Z}[x]$ . More precisely, if $f(x) ∈ \mathbb{Z}[x]$ , then $f(x)$ factors into a product of two polynomials of lower degrees $r$ and $s$ in $\mathbb{Q}[x]$ if and only if it has such a factorisation with polynomials of the same degrees $r$ and $s$ in $\mathbb{Z}[x]$ . This is a theorem that we have gotten in our lecture notes, when I search the proof for Gauss's Theorem online I get different theorems to the one above and many different proofs that don't seem right for this theorem. Are there many different Gauss's Lemma? What would a proof for this version look like? Could someone send me a link to a website that has th eproof for this Lemma?","['abstract-algebra', 'polynomial-rings']"
3636277,Find the constant coefficient of $(x+\frac{2}{x})^{100}$,"How do I find the constant coefficient for the following binomial? $(x+ \frac{2}{x})^{100}$ I know a very similar question has been asked for $(x+ \frac{1}{x})^{100}$ , but how does it differ for $(x+ \frac{2}{x})^{100}$ ? Thank you so much in advance!","['binomial-coefficients', 'discrete-mathematics']"
3636301,Find $\int_{0}^{\sqrt{3}}f(x)\:dx$,$f:\mathbb{R} \to \mathbb{R}$ is a differentiable function satisfying: $$\left(f(x)\right)^{99}=x-f(x) \tag{1}$$ Then Find $$\int_{0}^{\sqrt{3}}f(x)\:dx$$ My try: Replacing $x$ with $-x$ in the functional equation we get: $$\left(f(-x)\right)^{99}=-x-f(-x)\tag{2}$$ Adding $(1)$ and $(2)$ we get: $$\left(f(x)\right)^{99}+\left(f(-x)\right)^{99}=-(f(x)+f(-x))$$ One solution is $$f(-x)=-f(x)$$ Any way from here?,"['calculus', 'definite-integrals', 'derivatives', 'algebra-precalculus']"
3636346,"Let $f$ be bounder linear functional on Hilbert space $H$ , then dimensional of orthogonal complement of null space is $1$",Let $f$ be bounded linear functional (non trivial) on Hilbert Space $H$ . Let $null(f)$ be null space of $f$ in $H$ . Then how to prove that dimension( $null(f)^⊥$ ) is $1$ .,"['hilbert-spaces', 'functional-analysis']"
3636438,Recommended books for reading the Euler characteristic class,"The book Differential Forms in Algebraic Topology of Bott & Tu gives a nice treatment with the Thom isomorphisms and the Euler classes of vector bundles rank $2$ . However, I think their approach to the Euler classes in higher dimensions is quite terrible for novices, at least for me because I do not want to be swamped in a bunch of Čech cohomology stuffs and bicomplexes-arguments. Therefore, I found another book, Differential Geometry: Connections, Curvature, and Characteristic Classes of Tu in which the author represents Pontryagin, Euler and Chern classes from differential geometry point of view unlike topological methods in Bott & Tu. In particular, he (Tu) constructs the Euler class by mean of curvature matrix and Plaffian but I do not know why he just stops at giving the definition without proving other important axioms characterizing the Euler class as other books do. So I ask for a book doing this job. Thank you in advance.","['algebraic-topology', 'book-recommendation', 'reference-request', 'characteristic-classes', 'differential-geometry']"
3636450,Showing linear isometry,"Define a norm on $\ell^1$ by $$\|x\|=(\|x\|_1^2+\|x\|_2^2)^{\frac{1}{2}},$$ where $\|.\|_p$ denotes the canonical norm on $\ell^p$ . Then $\|.\|$ is equivalent to $\|.\|_1$ . I want to show that a quotient space of $X=(\ell^1,\|.\|)$ is linearly isometric to $(\ell^1,\|.\|_1)$ . Let $D=\{x_n:n\in \mathbb{N}\}$ be a countable dense subset of $S_{\ell^1}$ . Let $M,m>0$ be such that $M\|x\|_1\leq \|x\|\leq m\|x\|_1$ for all $x\in \ell^1$ . Define $T:X\to (\ell^1,\|.\|_1)$ by $$T((\lambda_n))=\sum\limits_{n=1}^{\infty}M\lambda_n x_n \text{ for all }(\lambda_n)\in X.$$ Clearly, $T$ is linear. Also for all $(\lambda_n)\in X$ , $$\|T((\lambda_n))\|_1=\|\sum\limits_{n=1}^{\infty}M\lambda_n x_n\|\leq M\|(\lambda_n)\|_1\leq \|(\lambda_n)\|.$$ Thus $T$ is continuous. \ Let $x\in (\ell^1,\|.\|_1)$ . Choose $n_1\in \mathbb{N}$ such that $$\|x-\lambda_{n_1}x_{n_1}\|_1<\frac{\varepsilon}{2}, \text{ where }\lambda_{n_1}=\|x\|_1.$$ Choose $n_2\in \mathbb{N}$ with $n_2>n_1$ such that $$\|(x-\lambda_{n_1}x_{n_1})-\lambda_{n_2}x_{n_2}\|_1<\frac{\varepsilon}{2^2}, \text{ where }\lambda_{n_2}=\|x-\lambda_{n_1}x_{n_1}\|_1<\frac{\varepsilon}{2}.$$ Choose $n_3\in \mathbb{N}$ with $n_3>n_2>n_1$ such that $$\|(x-\lambda_{n_1}x_{n_1}-\lambda_{n_2}x_{n_2})-\lambda_{n_3}x_{n_3}\|_1<\frac{\varepsilon}{2^3}, \text{ where }\lambda_{n_3}=\|x-\lambda_{n_1}x_{n_1}-\lambda_{n_2}x_{n_2}\|_1<\frac{\varepsilon}{2^2}.$$ Proceeding in this way we get a sequence $(\lambda_{n_k})$ such that $$\lambda_{n_{k+1}}=\|x-(\lambda_{n_1}x_{n_1}+\ldots+\lambda_{n_k}x_{n_k})\|_1<\frac{\varepsilon}{2^k}.$$ It follows that $x=\sum\limits_{k=1}^{\infty}\lambda_{n_k}x_{n_k}$ . Let $\alpha_{n_k}=\frac{1}{M}\lambda_{n_k}$ for all $k\in \mathbb{N}$ and $\alpha_n=0$ for all $n\notin \{n_1,n_2,\ldots\}$ . Then $$\sum\limits_{n=1}^{\infty}|\alpha_n|\leq \frac{1}{M}(\|x\|+\sum\limits_{k=1}^{\infty}\frac{\varepsilon}{2^k})=\frac{1}{M}(\|x\|_1+\varepsilon)<\infty.$$ Consequently $(\alpha_n)\in X$ and $T((\alpha_n))=\sum\limits_{k=1}^{\infty}M\alpha_{n_k}x_{n_k}=\sum\limits_{k=1}^{\infty}\lambda_{n_k}x_{n_k}=x$ . Hence $T$ is onto. Since $T$ is continuous, $Y=\ker T$ is a closed subspace of $X$ and so $X/Y$ is a Banach space. Therefore by the first law of isomorphism of Banach spaces, $T$ induces a linear isomorphism $\tilde{T}$ from $X/Y$ onto $(\ell^1,\|.\|_1)$ given by $$\tilde{T}((\lambda_n)+Y)=T(\lambda_n)\text { for all }(\lambda_n)\in X.$$ We prove that $\tilde{T}$ is an isometry. For all $(y_n)\in Y$ , $$\|\tilde{T}((\lambda_n)+Y)\|_1=\|\tilde{T}((\lambda_n)+(y_n)+Y)\|_1=\|T((\lambda_n)+(y_n))\|_1 \leq \|(\lambda_n)+(y_n)\|.$$ Consequently $$\|\tilde{T}((\lambda_n)+Y)\|_1\leq \|(\lambda_n)+Y\|.$$ I got stuck here. How to show the reverse inequality? Any help will be appreciated.","['banach-spaces', 'isometry', 'functional-analysis', 'linear-transformations']"
3636491,Does $\lim |a_n-b_n|=0$ imply $\lim |f(a_n)-f(b_n)|=0$?,"Let $f:\mathbb{R}_{\geq 0}\to\mathbb{R}_{\geq 0}$ a continuous function and $(a_n)$ , $(b_n)$ two sequences with values in $\mathbb{R}_{\geq 0}$ and $\lim |a_n-b_n|=0$ . Does this imply $$\lim |f(a_n)-f(b_n)|=0?$$ Hint: the sequences $a,b$ needn't to be convergent. Althoug I know this statements holds for uniformly continuous functions, I think it is not true for continuous functions generally. But no counterexample comes into my mind. Has anyone an idea?","['examples-counterexamples', 'analysis', 'real-analysis', 'continuity', 'limits']"
3636500,Jacobian determinant equal to one?,"I would like to characterize the set of all continuous $G:[0,1]^n \rightarrow [0,1]^n$ such that the Jacobian determinant is one: $\mathcal{G}=\{G:[0,1]^n \rightarrow [0,1]^n: |DG(x)|=1\forall x \}$ . Is it true that $\mathcal{G}$ corresponds to the set of all linear transformations $G(x)=Ax+b$ with orthogonal matrices $A$ ?
Indeed we have $DG= A$ in this case. And taking a determinant equal to one should imply that $A$ is orthogonal.","['determinant', 'real-analysis', 'orthogonal-matrices', 'multivariable-calculus', 'linear-transformations']"
3636576,Evaluate $\lim\limits_{n \to \infty}\left(\sum\limits_{k=0}^{n}\left(\frac{\left(k-n\right)^k}{k!}\cdot e^{n-k}\right)-2n\right)$,"Evaluate $\lim\limits_{n \to \infty}\left(\sum\limits_{k=0}^{n}\left(\frac{\left(k-n\right)^k}{k!}\cdot e^{n-k}\right)-2n\right)$ . By plugging in large values for $n$ , I noticed that the limit is most likely $\frac{2}{3}$ , but I can't prove it. Update Over a year has passed since I asked this question, but recently it was closed out of the blue because it lacks additional context. So let me explain where this limit comes from. I was studying the following problem: Let's consider a sequence of random numbers. Each number is uniformly distributed between $0$ and $1$ . We add up the terms of this sequence one by one until their sum exceeds a certain number $x \in \mathbb{R}$ . Let $E_x$ be the expected number of terms needed for that. The original question asked for the value of $E_1$ , which turns out to be $e$ . After I solved this by using differential equations, I wanted to find a formula for all $E_x$ . Before I had found one, I thought: ""Well, each term of the sequence increases the sum by an expected value of $\frac{1}{2}$ , so the sum should exceed $x$ after roughly $2x$ "" terms. For large $x$ , this approximation should get better and $E_x$ will get closer and closer to $2x$ ."" In other words, I thought that $\lim\limits_{x \to \infty}\left(E_x-2x\right)=0$ . This turned out to be wrong later. Finding a nice formula for $E_x$ is not easy and the only explicit formula I could come up with was a piecewise-defined function with infinitely many pieces. The first piece ranges from $0$ to $1$ , the second from $1$ to $2$ , the third from $2$ to $3$ , and so on. This makes it really hard to evaluate the limit, so I decided to look at only integer values of $x$ . And indeed, you can find a nice for those, namely: $$E_n=\sum\limits_{k=0}^{n}\left(\frac{\left(k-n\right)^k}{k!}\cdot e^{n-k}\right)$$ Plugging this into $\lim\limits_{x \to \infty}\left(E_x-2x\right)$ , we get the limit in the title of this question. And apparently, this limit is equal to $\frac{2}{3}$ and not $0$ . So, there you go. Hopefully, this will be enough to open this question again.","['expected-value', 'limits', 'summation']"
3636604,"For an uncountable set $I$, is every Borel set of $2^I$ measurable?","Let $I$ be an uncountable set.
Consider $2^I$ to be a measure space with the usual coin-tossing measure. That is, we define a measure on $2^I$ as follows.
First we define $\mu(N_p) = 2^{-|p|}$ , where $N_p = \{ f \in 2^I : p \subset f \}$ for $p$ a finite partial function from $I$ to $2$ .
Secondly, we extend the $\mu$ to a measure on clopen sets of $2^I$ .
Thirdly, by the Carathéodory's extension theorem, we extend this measure to a measure on Baire sets of $2^I$ .
Here, a Baire set means a set belongs the $\sigma$ -algebra generated by the clopen sets.
Finally, we take the completion of this measure. We write this complete measure space as $(2^I, \mathcal{A}, \mu)$ . My question is whether every Borel set of $2^I$ belongs to $\mathcal{A}$ . If $I$ were countable, this question would be obviously true since every Borel set is Baire set.
But $I$ is uncountable.
So there is a Borel set which is not a Baire set. For instance, singletons of $2^I$ . If there were a counterexample, we could take such a set as a open set.
So we can paraphrase the question whether every open set of $2^I$ belongs to $\mathcal{A}$ .",['measure-theory']
3636623,Let $a_n>0$; $\sum a_n$ diverges; find $b_n$ s.t. $b_n>0$; $b_n/a_n\to0$; $\sum b_n$ diverges,"Let $(a_n)$ be a sequence of positive real numbers such that $\sum a_n$ diverges. Prove that there exists a sequence $(b_n)$ of positive real numbers such that $b_n/a_n \to 0$ , but $\sum b_n$ is divergent. I found a possible candidate solution for the sequence $(b_n)$ where $$
b_n = \frac{a_n}{\sum_{k=1}^n a_k}.$$ In fact, since $\sum a_k$ diverges, $b_n/a_n$ tends to 0. However I don't know how to show wether $\sum b_n$ actually diverges.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
3636627,Thermodynamic equation of differentials (and how to work with them),"Disclaimer: I am not a mathematician, I am a physicist. The thermodynamic identity is usually expressed in the following differential form $$
dU = TdS - PdV + \mu dN,
$$ where $U$ , $T$ , $S$ , $P$ , $V$ , $\mu$ and $N$ are the internal energy, temperature, entropy, pressure, volume, chemical potential and number of particles of the system respectively. If I am not mistaken, I can act with a vector, say $\frac{\partial}{\partial N}$ , to yield $$
 \frac{\partial U}{\partial N} = T \frac{\partial S}{\partial N} - P \frac{\partial V}{\partial N} + \mu \implies \mu = \frac{\partial U}{\partial N} - T \frac{\partial S}{\partial N} + P \frac{\partial V}{\partial N}.
$$ Consider the following question: Consider a monoatomic ideal gas that lives at height $z$ above sea level, so each molecule has potential energy $mgz$ in addition to its kinetic energy. Show that the chemical potential $\mu$ is the same as if the gas were at sea level, plus am additional term $mgz$ : $$
\mu(z) = -k_b T \text{ln}\left[\frac{V}{N}\left(\frac{2\pi m k_bT}{h^2}\right)^{3/2}\right] + mgz.
$$ My attempt was knowing that: The ""ideal monoatomic gas"" implies $U = \frac{3}{2}k_bT$ (by equipartition theorem) and the validity of Sackur-Tetrode equation: $$
S=k_bN\ln \left[{\frac {V}{N}}\left({\frac {4\pi m}{3h^{2}}}{\frac {U}{N}}\right)^{3/2}\right]+{\frac {5}{2}},
$$ together with the assumption that $V \neq V(N)$ . If one uses the above formula for $\mu$ and takes the partial derivatives I yield $$
\mu(z) = -k_b T \text{ln}\left[\frac{V}{N}\left(\frac{2\pi m k_bT}{h^2}\right)^{3/2}-\frac{3}{2}\right] + mgz,
$$ which is almost correct except for that $-\frac{3}{2}$ , although it still exhibits the problems described below. I came to the conclusion that I don't know how to manipulate these equations in differential form, am I allowed to do the above ""act with $\frac{\partial}{\partial N}$ "" business? The solution provided by the book is to say, hey hold $U$ and $V$ fixed so that the thermodynamic identity now reads $$
0 = TdS - 0 + \mu dN \implies \mu = T \left(\frac{\partial S}{\partial N}\right)_{V,U \text{ fixed}}
$$ but $U = U(N)$ , in particular $U = \frac{3}{2} k_b N T$ I could litterally make all the $N$ s in $S$ dissapear by substituting $N = \frac{2 U}{3 k_b T}$ and claim that $$
\mu = T \left(\frac{\partial S}{\partial N}\right)_{V,U \text{ fixed}} = 0,
$$ which is ridiculous. I'm really lost with the mathematics behind this type of calculations... Which would be the correct way to proceed?","['calculus', 'mathematical-physics', 'physics', 'differential-forms', 'differential-geometry']"
3636736,A summary and \or reference to the theory of REAL representation theory,"In fulton and harris there is a short discussion of real representations which is unsatisfactory to me. In $\mathbb{C}$ we have a great theory- We know how many irreducible representations there are We have a simple relation about their dimensions that in particular bounds the dimensions of irreducible nicely Most importantly, we have characters which are great tools to let us decompose a given representation to irreducible ones. I want to understand what the analogs of those are in $\mathbb{R}$ . Attempt My attempts give 'algorithms' to solve those questions, but I'd prefer formulas if that makes sense (like the number of conjugacy classes, etc). 1/2. We can use Artin Wedderburn and the Frobenius theorem to know the group algebra breaks up to a sum of $M_{n\times n}(D)$ for $D$ one of $\mathbb{R},\mathbb{C},\mathbb{H}$ . That gives us good bounds on the irreducible representations and I guess a 'formula' that instead of just their dimensions and amount, involves $Dim Hom_\mathbb{R}(V,V)$ 3. Suppose you found all complex representations.
The cheapest attempt is to say okay to understand a real representation $V$ I'll complexify it to $V'$ . Then if $V = \oplus V_i$ then $V' = \oplus V_i '$ , though the other direction is not true, so I have a technical way to decompose a representation assuming I know the complex ones, by going over all subsets of the summands of the decomposition of $V'$ and see if their sum comes from some $W \otimes \mathbb{C}$ for $W$ a subspace of $V$ .
Fulton-Harris gives a criterion to when a represenation is real (complexified of real), but that isn't the same as checking for me if the sum comes from some $W \otimes \mathbb{C}$ , so I don't even understand why this criterion is important. What are more accurate\systematic things one can say or good references?","['representation-theory', 'abstract-algebra', 'finite-groups']"
3636799,Bounds on expectation of Gaussian random vectors,"Let $X\in\mathbb{R}^n$ and $Y\in\mathbb{R}^m$ , $n\geq m$ , be independent standard Gaussian random vectors and define $D\in \mathbb{R}^{m\times m}$ , a positive-definite (symmetric) matrix. I want to prove that $$
-E\|X\|_2+E\|Y\|_2\leq -\sqrt{n}+\sqrt{m}\quad\quad (\text{1})
$$ and $$
\dfrac{E\|\sqrt{D}Y\|_2}{\sqrt{tr(D)}}\leq \dfrac{E\|Y\|_2}{\sqrt{m}}\quad\quad (\text{2})
$$ (Here $\|x\|_2=\sqrt{x^{T}x}$ , $tr(D)$ is the trace of $D$ and $\sqrt{D}$ is such that $(\sqrt{D})^2=D$ .) For (1) I know by Jensen's inequality that $E\|X\|_2\leq \sqrt{n}$ and $E\|Y\|_2\leq \sqrt{m}$ . But how this implies (1)? For (2) I know (again by Jensen) that $E\|\sqrt{D}Y\|_2\leq \sqrt{tr(D)}$ but that doesn't help me to obtain the bound since $E\|Y\|_2/\sqrt{m}\leq 1$ . Any help will be appreciated.","['normed-spaces', 'normal-distribution', 'expected-value', 'inequality', 'probability']"
3636820,cosets orders vs representatives orders,"Let $A$ be a finite abelian $p$ -group and $a_1\in A$ an element of maximal period. Let $A_1$ be the cyclic subgroup of $A$ generated by $a_1$ , say of order $p^{r_1}$ .Let $\bar{b}$ be an element of the factor group $A/A_1$ , of period $p^r$ . Then there exists a representative $a$ of $\bar{b}$ in $A$ which also has period $p^r$ . Proof. 
Let $b$ be any representative of $\bar{b}$ in $A$ .Then $p^rb$ lies in $A_1$ , say $p^r b=na_1$ , with some integer $n\geq 0$ . If $n=0$ let $a=b$ . Suppose $n\neq 0$ . We note that the period of $\bar{b}$ is $\leq$ the period of $b$ . Write $n=p^k t$ with $t$ prime to $p$ , then $ta_1$ is also a generator for $A_1$ , hence has period $p^{r_1}$ .We may assume $k\leq r_1$ . Then $p^kta_1$ has period $p^{r_1-k}$ . By our previous remark, the element $b$ has period $p^{r+r_1-k}$ , whence by hypothesis, $r+r_1-k\leq r_1$ and $r\leq k$ . This proves that there exists an element $c\in A_1$ such that $p^r c=p^r b$ . Let $a=b-c$ . Then $a$ is a representative of $\bar{b}$ in $A$ and $p^r a=0$ . Since the period of $a$ is $\geq p^r$ , we conclude that $a$ has period equal to $p^r$ . Can you help me understanding the bold sentence of the proof?","['proof-explanation', 'group-theory', 'abstract-algebra']"
3636853,"Find all values of $a$ that satisfy the inequality for all $(x,y)$","I need to determine all possible values for $a\in [0,2[$ such that the following holds for all $(x,y)\in\mathbb{R}^2$ : $$(2x+ay)(-x+6y)+(2y+ax)(-20y)\leq 0$$ or equivalent $$-2x^2-40y^2-21axy+12xy+a6y^2\leq 0$$ I've plotted the function and observed that it holds for all $a\in[0,\alpha[$ for some $\alpha$ between 1.3 and 1.4 and it doesn't hold for greater values. But I don't know how to prove it nor find such $\alpha$ .","['multivariable-calculus', 'polynomials', 'optimization', 'inequality', 'quadratics']"
3636941,"Power Series Solution of $y''+y=0$, and Summation Indices","I have a general question about this following problem \begin{equation} y''+y=0\end{equation} The required method to solve this problem is based on generating the power series solution, using the power series method. I began my problem by setting up the summations. \begin{align}\sum_{n=2}^\infty(n)(n-1)c_nx^{n-2}+\sum_{n=0}^\infty x^nc_n&=0\end{align} Then I did two substitutions, and then got to the following equation: \begin{equation}\sum_{k=0}^\infty[(k+2)(k+1)c_{k+2}+c_k]x^k=0\end{equation} Then I set the part that I know could zero out which was the inner portion of the sum: \begin{equation}(k+2)(k+1)c_{k+2}+c_k=0 \end{equation} Then I get the following equation: \begin{equation} c_{k+2}=-\frac{c_k}{(k+2)(k+1)}\end{equation} After that I decided to do the following and break it apart into a table: \begin{array}{|c|c|}k=0&k=1\\c_2=-\frac{c_0}{2\cdot1}&c_3=-\frac{c_1}{3\cdot2\cdot1}\\ \hline k=2 & k=3 \\ c_4 = \frac{c_o}{4\cdot 3\cdot 2 \cdot 1} & c_5 = \frac{c_1}{5\cdot 4\cdot 3\cdot 2\cdot 1}\end{array} Based off the pattern I that sgn changes, and that there is factorial in the denominator is my attempt right thus far, and how to collaborate them into a power series solution?","['power-series', 'solution-verification', 'ordinary-differential-equations']"
3636963,Intuition behind why is unit speed parametrization and arc length parametrization the same?,"I have found a bunch of simple and not so simple proofs about why a vector function ( $f(t)$ ) parametrized in such a way that it's derivative is always 1 ( $|f'(t)|=1$ ) is the same as parametrizing it by arc length ( $f(s) \iff |f'(s)|=1$ ). Just to provide one example of a proof found, I write down the definition for arclength with $t$ substituted with $s$ $$s=\int_0^s{|f(s)|}ds$$ apply derivative by both sides with respect to $s$ $$1=|f(s)|$$ BOOM!, proven.
(as long as the reparametrization is a biyective, smooth and has an inverse) The question is, How can i understand this as an intuitive thing? I think im missing the ""aha"" moment where is makes sense that an arc length function would have unit speed.","['multivariable-calculus', 'intuition', 'differential-geometry']"
3636980,A question regarding measurability,"The following is a problem from a text I (in portuguese) I am reading about Critical Point Theory: Let $\Omega \subset \Bbb{R}^N$ be an open set, $f: \overline \Omega \times \Bbb{R} \longrightarrow \Bbb{R}$ be a Carathéodory function and $F(x, t) = \int_0^t f(x, s) \ ds$ . Show that for every $u : \Omega \longrightarrow \Bbb{R}$ measurable the map $F(\cdot, u(\cdot))$ is measurable. Recall that $f$ is a Carathéodory function if (a) $x \mapsto f(x, s)$ is measurable for every $s$ and (b) $s \mapsto f(x, s)$ is continuous for almost every $x \in \Omega$ . I proceeded as follows: If $u$ is measurable there is a sequence of simple functions $(u_n)$ such that $u_n(x) \to u(x)$ for every $x \in \Omega$ . Write each $u_n$ as follows: $$
u_n = \sum_1^{k_n} z_{ni} \chi_{E_{ni}}.
$$ Then $$
F(x, u_n(x)) = \int_0^{\sum_1^{k_n} z_{ni} \chi_{E_{ni}}(x)} f(x, s) \ ds = \int_0^{z_{nj}} f(x, s) \ ds \\ = \sum_1^{k_n} \left( \int_0^{z_{ni}} f(x, s) \ ds \right) \chi_{E_{ni}}(x) = \sum_i^{k_n} F(x, z_{ni}) \chi_{E_{ni}}(x)
$$ Now, if each $F(x, z_{ni})$ is measurable then we have a sequence of measurable functions converging pointwise to $F(\cdot, u(\cdot))$ , and we are done. My question is: Is the above argument correct? If yes, how to show that $F(x, z_{ni})$ is measurable? If not, how does one solve this exercise? Thanks in advance and kind regards. EDIT I have made some progress with a hint by Gláucio Terra: By Tonelli's Theorem, we only have to show that $f$ is measurable with respect to the product $\sigma$ -algebra $\mathcal{L} \otimes \mathcal{B}$ , where $\mathcal{L}$ is the Lebesgue $\sigma$ -algebra in $\Bbb{R}^N$ and $\mathcal{B}$ is the Borel $\sigma$ -algebra in $\Bbb{R}$ . We also assume the Lebesgue $\sigma$ -algebra on the image $\Bbb{R}$ . Then $f^+$ and $f^-$ are measurable. By Tonelli's Theorem, the maps $\int_0^{z_{ni}}f^+(x, s) \ ds$ and $\int_0^{z_{ni}}f^-(x, s) \ ds$ are measurable and so also is $$
F(x, z_{ni}) =\int_0^{z_{ni}}f^+(x, s)- f^-(x, s) \ ds,
$$ To show that $f$ is measurable, Gláucio suggested addapting Exercise 2.11 in Folland's Real Analysis . I tried as follows: For $n \in \Bbb{N}$ , define $f_n$ as follows. Given $i \in \Bbb{Z}$ , let $a_i^n = i/n$ and define $$
f_n(x, s) =  \sum_{i = - \infty}^{\infty} \frac{f(x, a_{i+1}^n) (s - a_i^n) - f(x, a_i^n)(s - a_{i + 1}^n)}{a_{i+1}^n - a_i^n} \chi_{[a_i^n, a_{i + 1}^n]}(s).
$$ Note that, for all $i, n$ , $$
(x, s) \mapsto x \mapsto f(x, a_{i}^n)
$$ is a composition of $\mathcal{L} \times \mathcal{B}$ -measurable maps and hence is measurable, and the map $(x, s) \mapsto (s - a_i^n)$ is continuous and hence $\mathcal{L} \otimes \mathcal{B}$ -measurable. Hence $f_n$ is measurable, and $f_n \to f$ almost everywhere. Now, to say that $f$ is measurable we need conevrgence everywhere . How to overcome this difficulty?","['calculus-of-variations', 'measure-theory', 'measurable-functions', 'real-analysis']"
3636989,Homomorphic image of an alternating group,"I'm solving the following problem: If $f:S_n\rightarrow S_n$ is a group homomorphism, prove that $f(A_n)\subseteq A_n.$ (Here, $S_n$ is a symmetric group of degree $n$ , and $A_n$ is an alternating group of degree $n.$ ) For $n=2,$ it is trivial. Let $n\geq3.$ First we show that for any $3$ -cycle $(abc)\in S_n,$ its image $f((abc))$ is even . Suppose, on the contrary, that $f((abc))$ is odd . Since $(abc)^3=(1),$ $f((abc))^3=f((abc)^3)=f((1))=(1)$ . (Note that $f$ is a homomorphism). Thus, $f((abc))^3=(1).$ However, $(1)$ is $even$ and since we assumed that $f((abc))$ is odd , $f((abc))^3$ is odd . This is a contradiction! Thus $f((abc))$ is even . As every element $\sigma$ of $A_n$ (that is, all even permutations) is a product of $3$ -cycles ( Link ), we may write $\sigma = (a_1b_1c_1)\cdots(a_nb_nc_n).$ Then, $f(\sigma)=f((a_1b_1c_1)\cdots(a_nb_nc_n))=f((a_1b_1c_1))\cdots f((a_nb_nc_n)).$ As each $f((a_1b_1c_1)),\dots,f((a_nb_nc_n))$ is even , $f(\sigma)$ is also even . It follows that $f(A_n)\subseteq A_n$ ! Is my argument correct?","['group-homomorphism', 'abstract-algebra', 'solution-verification', 'symmetric-groups', 'group-theory']"
3637035,Derivative of generalized Taylor expansion of a function between Banach Spaces,"Let $E$ and $F$ be Banach spaces and let $f: E \to F$ be a $n+1$ times differentiable function. We define for a given $y\in E$ the Taylor expansion of $f$ as the following: $$
T_n(x,y)=\displaystyle\sum_{k=0}^{n}{\dfrac{d^kf_y(x-y)^k}{k!}}
$$ where in this case we use the abusive notation of $(x-y)^k$ as the $k$ -tuple with all entries being $x-y$ . We have that $T_n(x,y): E \to F$ with respect to $x$ (with $y$ and $n$ being constant). Question . What is the derivative of this series at the point $y$ ? 
( $d_yT_n(x,y)=?$ ) Here is what I've worked out so far. By linearity of the derivative the problem becomes one of finding the derivative of $d^kf_y(x-y)^k$ with respect to $x$ , if I am not mistaken. In this case we have that $d^kf_y(x-y)^k$ is a multilinear map which means it has derivative equal to the map that sends a point $(s_1,s_2,....,s_k)$ to : $\displaystyle\sum_{i=1}^{k}{d^kf_y(x-y,...,s_i,...,x-y)}$ . using the symmetry of higher derivatives we get that this derivative is equal to the map $k \cdot d^kf_y(x-y,....,x-y,s)$ .  I believe this leads to a form similar to the derivative of the Taylor polynomial for real functions. Is this the correct way to approach this problem? Am I taking the derivative on the wrong variable? Any help is appreciated.","['banach-spaces', 'normed-spaces', 'taylor-expansion', 'analysis']"
3637041,"How to show $G_{m}\cong G_n $ if and only if $n=m$, where $G_m:= \langle x,y \mid x(yx)^{m}=y(xy)^{m}\rangle$","I have this family of groups $G_{m}:= \langle x,y \mid x(yx)^{m}=y(xy)^{m}\rangle$ . I want to show that for different $m$ these two groups are either isomorphic or not. 
My guess is they are not and I tried to show that via abelization but of course you get a trivial group for all $m$ 's so that doesnt work. Any ideas how to show this?","['group-presentation', 'group-isomorphism', 'combinatorial-group-theory', 'abstract-algebra', 'group-theory']"
3637046,Proving the continuity of Fourier Transform between Schwartz spaces via sequences,"Prove that if $f_k \rightarrow f$ in the Schwartz space $\mathcal{S}(\mathbb{R}^n)$ , then $\hat{f_k} \rightarrow \hat{f}$ in $\mathcal{S}(\mathbb{R}^n)$ . This is the Exercise 2.2.2  in Loukas Grafakos's book named Classical Fourier Analysis (3º edition) and it's used to prove the Corollary 2.2.15 which says the Fourier transform is a homeomorphism between Schwartz spaces. The convergence in $\mathcal{S}(\mathbb{R}^n)$ is defined by: $f_k \rightarrow f$ in $\mathcal{S}(\mathbb{R}^n)$ if $\rho_{\alpha,\beta}(f_k-f) \rightarrow 0$ as $k \rightarrow \infty$ , $\forall\alpha, \beta$ multi-index, where $$\rho_{\alpha,\beta}(f) = \sup_{x \in \mathbb{R}^n} |x^\alpha \partial^\beta(f)(x)|.$$ My idea is to prove the convergence $\hat{f_k} \rightarrow \hat{f}$ by definition using the folowing identity: $$\xi^\alpha \partial^\beta \hat{g}(\xi) = \frac{(-2\pi i)^{|\beta|}}{(2\pi i)^{|\alpha|}} (\partial^\alpha(x^\beta g(x)))^\wedge(\xi), \;\; \forall g \in\mathcal{S}(\mathbb{R}^n),$$ but I'm can't get the convergence I want.","['fourier-analysis', 'fourier-transform', 'analysis', 'partial-differential-equations', 'schwartz-space']"
3637061,Value of $\sum_{n=1}^{\infty}\frac{1}{\sqrt{n!}}$?,"I was reading this old question and fascinated by the second infinite sum $$\sum_{n=1}^{\infty}\dfrac{1}{\sqrt{n!}}.$$ This is clearly convergent (by comparison or ratio test) and, we can obtain some crude approximations of this using inequalities like $n^4\le n!\le (n!)^2,$ here the first inequality holds for all $n\ge7.$ But, I wonder if we can find the exact value of this series using (familiar) special functions/constants. How would you attack to this series?","['special-functions', 'number-theory', 'analytic-number-theory', 'gamma-function', 'hypergeometric-function']"
3637085,"Is $\lim_{n\to\infty} \frac{4n}{a^2_n}=\pi e$ for $a_{n+2}=a_{n+1}+\frac{a_n}{2n}$, $a_1=0,a_2=1$?","I have found this limit in https://oeis.org/A019609 and I was wondering how to prove it (if it is actually correct): $$\lim_{n\to\infty} \frac{4n}{a^2_n}=\pi e$$ where $$a_1=0,a_2=1, a_{n+2}=a_{n+1}+\frac{a_n}{2n}.$$ By computer evaluation, it is correct for $2$ digits after decimal point at about $n\approx 24100$ , so if it is correct, it converges really slow. I've attempted to prove this by first considering generating function $f(x)=\sum_{n \geq 1}a_nx^n$ and then trying to get asymptotics of its coefficients. By using recurrence, we get $f(x)/x^2-1=f(x)/x+\sum \frac{a_n}{2n}x^n$ , and after differentiation we get differential equation which solves to $$f(x)=\frac{e^{-x/2}x^2}{(1-x)^{3/2}}.$$ Now I think this is a step away from getting asymptotics of $a_n$ , but I don't know how. Can anybody show how to finish this? Or maybe there is another way? Also, I don't think it is useful, but here is at least closed form obtained from the $f(x)$ using binomial series and exponential function series: $$
a_n=\sum_{i=0}^{n-2}\frac{(-1)^n}{2^i i!}\binom{-3/2}{n-i-2}.
$$ Closest to this question seems to be Mirror algorithm for computing $\pi$ and $e$ - does it hint on some connection between them? , where there are two sequences approaching $\pi$ and $e$ and solutions seem to use same approach using generating functions, so this seems to be on the right track.","['limits', 'generating-functions', 'sequences-and-series']"
3637105,Why is the blow-up of 9 points an elliptic surface?,"One example of elliptic fibration is obtained as follows: Let $Z(F),Z(G)\subset\Bbb{P}^2$ be two non-singular cubics intersecting in distinct points $P_1,...,P_9$ and take the rational map \begin{align*}
\varphi:\Bbb{P}^2&\to\Bbb{P}^1\\
P&\mapsto (F(P):G(P))
\end{align*} If $p:X\to \Bbb{P}^2$ is the blow-up of $\Bbb{P}^2$ in $P_1,...,P_9$ , then $\pi:=\varphi\circ p:X\to\Bbb{P}^1$ defines an elliptic fibration. I'm trying to understand why almost all fibers of $\pi$ are elliptic curves. Here's where I'm at: If $(a:b)\in\Bbb{P}^1$ , we see that $\varphi^{-1}(a:b)=C\setminus\{P_1,...,P_9\}$ where $C:=Z(bF-aG)$ . I'm not sure how to prove this, but intuitively I'm convinced that $C$ is irreducible for almost all $(a:b)$ . Now if $\widetilde{C}\subset X$ the strict transform of $C$ , we have $\pi^{-1}(a:b)=\widetilde{C}$ , and we should be able to prove that $g(\widetilde{C})=1$ . If $m_i$ is the multiplicity of $C$ in $P_i$ , then $m_i\cdot m_F(P_i)\leq I(P_i, C\cap F)=I(P_i, F\cap G)=1$ , so $m_i=1$ for all $i=1,...,9$ . Therefore: $$\widetilde{C}^2=C^2-(m_1^2+...+m_9^2)=9-(1+...+1)=0$$ This seems relevant, but I don't know how to conclude that $g(\widetilde{C})=1$ .","['algebraic-geometry', 'blowup', 'elliptic-curves', 'birational-geometry']"
3637134,On the matrix logarithm,"Let $A\in M_{n\times n}(\mathbb{C})$ . We define $\displaystyle\ln A=\sum_{k=1}^\infty(-1)^{k+1}\frac{(A-I)^k}{k}$ This series is convergent in particular when $A-I$ is nilpotent. Is it true (and how do you prove it) that if $A-I$ is nilpotent, then $e^{\ln A}=A$ ? (Also what about $\ln e^A=A$ ?)","['logarithms', 'matrices', 'linear-algebra', 'power-series', 'analytic-functions']"
3637273,"Is this true: $\operatorname{Cov}(X,Y)=\operatorname{Cov}(E[X|Y],Y)$? Covariance of variables versus conditional expectations?","Let $X$ and $Y$ be to correlated random variables. 
Is the following true? $\operatorname{Cov}[E[X|Y],Y]=\operatorname{Cov}[X,Y]$ I derived this for from the standard expression for covariance, and it holds if $E[E[X|Y]*Y]=E[XY]$ is correct, but somehow this seems wrong to me.","['statistics', 'covariance', 'conditional-probability', 'conditional-expectation', 'probability']"
3637337,Asymptotics of the quantum dilogarithm,"Fadeev and Kashaev define the quantum dilogarithm by $$
\Psi(x) = \prod_{n=1}^\infty (1 - x q^n)
$$ for $|q| < 1$ .
For $q = \exp(\epsilon)$ , $\Re \epsilon < 0$ , they say the asymptotic expansion $$
  \Psi(x) = \frac{1}{\sqrt{1 - x}} \exp( \operatorname{Li}_2(x) / \epsilon)(1 + O(\epsilon))
$$ as $\epsilon \to 0$ is ""easy to see,"" but I'm having trouble deriving it. Here $\operatorname{Li}_2$ is the dilogarithm $$
  \operatorname{Li}_2(x) = - \int_0^x \frac{\log( 1-t )}{t} \, dt = \sum_{n=1}^\infty \frac{x^n}{n^2}.
$$ I've tried expanding $$
    \log \left( \Psi(x) \sqrt{1-x} \exp(- \epsilon^{-1} \operatorname{Li}_2(x)) \right) = \log \Psi(x) + \frac{1}{2} \log(1 - x) - \frac{1}{\epsilon} \operatorname{Li}_2(x).
$$ but this doesn't seem like it can work: if you expand $\log \Psi(x)$ in $\epsilon$ there's only positive powers, so I don't see how you can get a cancellation with the $\epsilon^{-1} \operatorname{Li}_2(x)$ .","['complex-analysis', 'q-series', 'asymptotics']"
3637374,Very simple characterisation of $(-1)$-curves,"Let $X$ be a complex surface (i.e., complex dimension 2) and $C$ a $(-1)$ -curve in $X$ , i.e., a reduced, compact, connected curve $C$ with self-intersection $-1$ . I'm trying to understand the proof of the equivalent characterization of $(-1)$ -curves, namely, $$C^2 < 0 \ \ \text{and} \ \ (C, K_X) < 0.$$ Indeed, if $C$ is a $(-1)$ -curve, then $C^2 =-1$ by definition and by adjunction we have $$K_C = K_X \otimes \mathcal{O}_X(C) \vert_C.$$ Then $$(C, K_C) = (C, K_X) + (C, \mathcal{O}_X(C) \vert_C),$$ since the intersection product is bilinear with respect to the tensor product of line bundles. How do we deduce from this that $$(C,K_X) <0?$$","['complex-geometry', 'algebraic-geometry', 'surfaces', 'birational-geometry']"
3637404,Sensor matrix minimal wiring,"I was doing the wiring of the sensors on my pinball machine and that lead me to an interesting optimization problem. There are 35 on/off sensors on the playfield of the machine. Behind the playfield, all those sensors need to be connected to a multi-pin connector, which in turn is connected to a microcontroller. I want to minimize the amount (total length) of wiring. The sensors are connected to the connector using matrix wiring . This means that there are row-wires and column-wires. Every sensor is connected to one row-wire and one column-wire. Multiple sensors can use the same row-wire or the same column-wire, but each sensor needs a unique row-wire/column-wire pair. We have a set of sensors $S = \{S_1, S_2, \dots,S_N\}$ and a connector $C$ , which all lie in a metric space with distance function $d$ . We could also say that $S \cup \{C\}$ is the set of vertices of a positively weighted complete graph. (2D Euclidean space may be assumed if that makes it easier) We need to find two partitions of $S$ : a row partition $S_r$ and a column partition $S_c$ , under the condition $$\forall\ x \in S_r,\ y \in S_c:\ |x \cap y| \le 1.$$ The goal is to find partitions that minimize the total wiring length $$
T=\sum_{x \in S_r} W(x \cup \{C\}) + \sum_{y \in S_c} W(y \cup \{C\}).
$$ Here $W(z)$ is a function that gives the total weight of the minimum spanning tree that connects all elements of $z$ . What is a fast algorithm to find optimal or reasonable $S_r$ and $S_c$ to minimize $T$ ? Note: It is possible to use even less wiring if we allow a wire to split in different directions at a point that is not a sensor or connector, but to keep it simple let's not use that possibility. Example In the image, the black circles are the sensors, the red circle is the connector, the blue lines are the row wires and the green lines are the column wires. Here we have $S_r = \{\{S_1,S_2,S_4\},\{S_3,S_5,S_6\}\}$ and $S_c = \{\{S_1,S_3\},\{S_2\},\{S_4,S_5\},\{S_6\}\}$ . The wiring here is arbitrarily chosen by me, I don't know if it's optimal. Idea We don't have to consider combinations that have a minimum spanning tree with $C$ as an internal vertex. For example, in the example above we don't have to consider any partitions that contain $\{S_2, S_6\}$ , because $C$ is in the middle of $S_2$ and $S_6$ , and we might just as well take $\{S_2\}$ and $\{S_6\}$ separately. However, it is still necessary to look at supersets of $\{S_2, S_6\}$ . Data Here the $(x,y,z)$ locations of the controller (first in the list) and the 35 sensors: [[46,21,2],[20,38,0],[20,32,0],[20,27,0],[20,22,0],[20,16,0],[20,40,4],[21,34,3],[21,22,3],[23,12,4],[27,48,1],[33,28,3],[33,11,4],[57,48,4],[48,46,4],[40,42,4],[41,15,0],[46,28,4],[42,33.5],[44.7,34.5,15],[47.4,35.5,15],[50.1,36.5,15],[52.9,37.5,15],[55.6,38.5,15],[58.3,39.5,15],[61,40.5,15],[59,11,4],[76,17,4],[78,10,0],[78,6,0],[105,24,0],[97,18,3],[97,37,3],[76,39,4],[79,43,0],[79,47,0]] There are some obstacles below the playfield, so Euclidean distance is not entirely accurate, but for now that's good enough.","['graph-theory', 'optimization', 'combinatorics']"
3637410,Prove that $B \setminus (\bigcup_{i \in I} A_i) = \bigcap_{i \in I} B \setminus A_i$.,"This is an exercise from Velleman's ""How To Prove It"". I saw a similar question asked on here, but I am still confused. Also, those questions were closed for being off-topic for some reason. Suppose $B$ is a set, $\{A_i | i \in I\}$ is an indexed family of sets, and $I \neq \emptyset $ . b. Prove that $B \setminus (\bigcup_{i \in I} A_i) = \bigcap_{i \in I} B \setminus A_i$ . Here is my attempt at some of the proof. I have indicated the part where I get stuck: Proof: Let $x$ be arbitrary. Suppose $x \in B \setminus (\bigcup_{i \in I} A_i)$ . Then $x \in B$ , and for all $i \in I$ , $x \notin A_i$ . Let $j \in I$ be arbitrary. It follows that $x \notin A_j$ . Thus, $x \in B \setminus A_j$ . Since $j$ was arbitrary, $x \in \bigcap_{j \in I} B \setminus A_j$ . Now suppose $x \in \bigcap_{i \in I} B \setminus A_i$ . So $\forall i \in I (x \in B)$ and $\forall i \in I(x \notin A_i)$ . Suppose $x \in \bigcup_{i \in I} A_i $ . Then we can choose a $j \in I$ such that $x \in A_j$ . But since $j \in I$ , it follows that $x \notin A_j$ , which is a contradiction. Thus, $x \notin \bigcup_{i \in I} A_i$ . [How do we show that $x \in B$ to complete the proof?] $\square$ Proving the statement with a string of equivalences kind of makes sense: \begin{align}
x \in B \setminus (\bigcup_{i \in I} A_i) &\leftrightarrow x \in B \wedge x \notin \bigcup_{i \in I} A_i \\
& \leftrightarrow x \in B \wedge \neg (\exists i \in I (x \in A_i)) \\
& \leftrightarrow x \in B \wedge \forall i \in I(x \notin A_i) \\
& \leftrightarrow \forall i \in I(x \notin A_i \wedge x \in B ) & \text{since $x\in B$, of course $x \in B$ for all $i \in I$. But why the converse?}\\
& \leftrightarrow \forall i \in I(x \in B \setminus A_i)\\
& x\in \bigcap_{i \in I}B \setminus A_i \\
\end{align} I do not understand how we can go from $\forall i \in I(x \in B)$ to $x \in B$ , since if $x \in B$ is true, then that means $x \in B$ even for some $j \notin I$ . I think I am misunderstanding some fundamental rules. Thanks in advance!","['elementary-set-theory', 'proof-explanation', 'logic']"
3637424,Bohr Radius of an atom,"This is the question I am working on: The Bohr radius, $a_0$ , of the hydrogen atom is the value of $r$ that minimizes the energy $E(r)=\frac{h^2}{2mr^2} - \frac{e^2}{4\pi\epsilon_0r}$ where $h, m,e$ , and $\epsilon_0$ are physical constants. Show that $a_0=\frac{4\pi\epsilon_0h^2}{me^2}$ I have tried to plug in $a_0$ for the $r$ value and take the derivative of $E(r)$ but that didn't seem to be getting me any closer to the answer I needed. Any help with this question would be greatly appreciated. Thank you!","['physics', 'calculus', 'derivatives']"
3637452,"Prove that if $x_n \rightarrow x$ and $x_n + y_n \rightarrow z$, then $y_n \rightarrow z - x$","I've tried a proof of the above question, but it seems too simple to be right. If anyone has some pointers or tips that would be much appreciated as I am rather new to all this. We can deduce by $x_n + y_n \rightarrow z$ that $y_n$ must converge. So let $y_n \rightarrow y$ . $$x_n + y_n \rightarrow x +y $$ $$x_n + y_n \rightarrow z $$ $$z= x+y $$ $$y= z-x $$ $$y_n \rightarrow y $$ $$y_n \rightarrow z-x $$ Thanks for your time!","['limits', 'solution-verification', 'sequences-and-series', 'real-analysis']"
3637453,Maximize $\mathrm{tr}(Q^TCQ)$ subject to $Q^TQ=I$,"Let $C \in \mathbb{R}^{d \times d}$ be symmetric, and $$Q = \begin{bmatrix}
      \vert & \vert &    & \vert \\
      q_1   & q_2   & \dots & q_K  \\
      \vert & \vert &    & \vert
      \end{bmatrix} \in \mathbb{R}^{d\times K}$$ where $d \geq K$ . Using Lagrange multipliers, $$\begin{array}{ll} \text{maximize} & \mbox{tr} \left( Q^T C Q \right)\\ \text{subject to} & Q^T Q = I\end{array}$$ I am unfamiliar with these kind of constraints with this method, and after reading another post I believe the same specific and simple result given is also applicable, and therefore the lagrangian would be: $$\mathcal{L}(Q,\lambda)=\mathrm{tr}(Q^TCQ)-\left<\lambda,Q^TQ-I\right>$$ where $\lambda\in\mathbb{R}^{K\times K}$ , and $\left<\cdot,\cdot\right>$ is the element wise inner product (what kind of makes sense to me since we're actually adding as many constraints as there are elements in these matrices. In attempting to do that I start taking $\frac{\partial \mathcal{L}}{\partial Q}=O\in\mathbb{R}^{d\times K}$ , and compute that LHS element by element; for the $(l,m)$ one: \begin{equation}
0=\frac{\partial \mathcal{L}}{\partial Q_{lm}}=(CQ+C^TQ)_{lm}-\underbrace{\frac{\partial}{\partial Q_{lm}}\sum_{i,j}\lambda_{i,j}(Q^TQ-I)_{ij}}_{=\lambda_{lm}\frac{\partial (Q^TQ)_{lm}}{\partial Q_{lm}}}=2(CQ)_{lm}-\lambda_{lm}\frac{\partial (q_l^Tq_m)}{\partial q_m(l)}
\tag{1}\end{equation} where in the last step I've used the definition I made at the beginning for $Q$ , and $q_m(l)$ denotes the $l$ -th component of the column vector $q_m$ . In trying to compute the very last term: $$\frac{\partial (q_l^Tq_m)}{\partial q_m(l)}=\frac{\partial \left[q_l(1)q_m(1)+ \ldots + q_l(d)q_m(d)\right]}{\partial q_m(l)}=
\begin{cases}
    q_l(l)\equiv Q_{ll}    & \text{if } l\neq m\\
    2q_l(l)\equiv 2Q_{ll}  & \text{if} l=m
\end{cases}$$ The whole equality (1) then can be written: $$0=2(CQ)_{lm}-\lambda_{lm}Q_{ll}(1+\delta_{lm})$$ where $\delta_{lm}$ is the Kronecker delta. The equation for the other stationary point of the lagrangian, $\frac{\partial \mathcal{L}}{\partial \lambda}=O\in\mathbb{R}^{K\times K}$ , for the $(l,m)$ element as well: $$ 0=\frac{\partial \mathcal L}{\partial \lambda_{lm}}= \frac{\partial }{\partial \lambda_{lm}}\sum_{i,j}\lambda_{i,j}(Q^TQ-I)_{ij}=(Q^TQ-I)_{lm}\tag{2}$$ what obviously leads to $(Q^TQ)_{lm}=\delta_{lm}$ . All this should tell that the columns of $Q$ are eventually the $K$ first eigenvectors of $C$ , but I don't know how to continue from here to prove that, supposing I didn't make a mistake. Please I would sincerely appreciate any help. Edit: I have rewritten the inner product as a trace of a product of matrices (after seeing this question ): $$\left<\lambda,Q^TQ-I\right>=\sum_{i,j}\lambda_{i,j}(Q^TQ-I)_{ij}=\mathrm{tr}(\lambda^TQ^TQ) $$ and have thus managed to do the derivative without losing the matrix format (using formulas from the Matrix Cookbook ): \begin{align}
O=&\frac{\partial \mathcal{L}}{\partial Q}=\frac{\partial}{\partial Q}\mathrm{tr}(Q^TCQ)-\frac{\partial}{\partial Q}\underbrace{\mathrm{tr}(\lambda^T(Q^TQ-I))}_{\mathrm{tr}(\lambda^TQ^TQ)-\mathrm{tr}(\lambda^T)}\\=&(CQ+C^TQ)-(Q(\lambda^T)^T+Q\lambda^T)=2CQ+Q(\lambda+\lambda^T)
\end{align} And this leads to: $$CQ=Q\underbrace{\left(-\frac{\lambda+\lambda^T}{2}\right)}_{:=\widetilde{\lambda}};\quad CQ=Q$$ If the defined matrix $\widetilde{\lambda}=Q^TCQ$ were diagonal we would already have the result.","['qcqp', 'lagrange-multiplier', 'matrices', 'stiefel-manifolds', 'optimization']"
3637535,"Approximating multi-variate continuous functions that map to [0,1] by polynomials","The Stone-Weierstrass Theorem says that the polynomials are dense in C[X] under the sup norm, where X is any Hausdorff space. There have been several previous posts asking about approximations of $f \in C[X]$ with polynomials $P_n = \{p | p $ is a polynomial of degree less than or equal to $n\}$ for a fixed degree $n$ . It seems like this is a problem that has certain bounds for $\inf_{p \in P_n} ||f - p||_\infty < \epsilon(n)$ , where $\epsilon(n)$ is on the order $O(1/n)$ ( 1 , 2 ) I have two questions: If we restrict the output of $f: [-a, b] \rightarrow [0,1]$ , are there any tighter bounds that can be said? Clearly, $\inf_{p \in P_n} ||f - p||_\infty < 1/2$ for the trivial case $p=1/2$ . Can we prove the same bounds for $f: [-a, b]^n -> \mathbb{R}$ and a multi-variate polynomial $P(x_1, ... x_n)$ as we did in the one-dimensional case? What if we restrict the range to $f: [-a, b]^n -> [0,1]$ ? I am not sure how one would go about the first question, other than to note that $f$ is 1-Lipshitz and by the above posts there are potentially some tighter bounds there for Lipschitz functions. For the second question, I showed that the polynomials are still dense in $C[X]$ , which makes me think there might be an analgous way to prove the error bounds as well? This is probably all well-understood, but I'm not well-read on approximation theory. Any guidance would be wonderful.","['measure-theory', 'approximation-theory', 'reference-request', 'real-analysis', 'polynomials']"
3637583,Intersection of a closed subscheme with a point,"Let $X \subset \mathbb{P}^n$ be a quasiprojective scheme over a field $k$ and let $Z \subset \mathbb{P}^n$ be a closed subscheme. For a closed point $P$ in $X$ , let $Y = \operatorname{Spec}(\mathcal{O}_{X,P}/\mathfrak{m}^2_{X,P})$ . I want to prove that $Z \cap Y = \operatorname{Spec}(\mathcal{O}_{X,P}/(\mathfrak{m}^2_{X,P}, \mathcal{I}_{Z,P}))$ , where $\mathcal{I}_{Z}$ is the ideal sheaf of $Z$ . Is this actually true? Without loss of generality assume $P$ is only in one of the standard open affines, say $D_{+}(x_0)$ . Then $Z \times_{\mathbb{P}^n} Y = (Z \cap D_{+} (x_0)) \times_{D_+ (x_0)} Y$ . Now we can explicity compute the intersection as we are working with affine schemes and you get the result. Is this the right method?",['algebraic-geometry']
3637584,Analytic continuation of $\Phi(s)=\sum_{n \ge 1} e^{-n^s}$,"(After 3 bounties I've also posted on mathoverflow ). While discussing theta functions , I thought: $\zeta(s)=\sum n^{-s}=1+2^{-s}+3^{-s}+ \cdot\cdot\cdot$ and $\Phi(s)=\sum e^{-n^s}=e^{-1}+e^{-2^s}+e^{-3^s}+\cdot\cdot\cdot $ What is the analytic continuation of $\Phi(s)?$ User @reuns had an insightful point that maybe, $\sum_n (e^{-n^{-s}}-1)=\sum_{k\ge 1} \frac{(-1)^k}{k!} \zeta(sk).$ If the sum were instead a product, then the analytic continuation would coincide with the analytic continuation of $\zeta(s).$","['analytic-continuation', 'reference-request', 'complex-analysis', 'riemann-zeta', 'soft-question']"
3637626,Shortest path of a knight on a chessboard,"Given a knight on an infinite-size chessboard. Knight starts from $(0,0)$ and the destination is $(x,y)$ with $x\ge 0$ and $y\ge 0$ . I want to prove that among all the path with the minimum steps, there must be a path only containing points $(a,b)$ with $-1\le a\le x+2$ and $-1\le b\le y+2$ . I am not sure whether it is right or not, but after I tried many cases, it seems to be right. My first attempt is to use mathematical induction to prove that for any $c$ , all points within the square $0\le x\le c$ and $0\le y\le c$ satisfy that statement. I could prove my enumeration that $(c,c)$ with $0\le c\le 3$ satisfy the proposition. Then under the assumption that $(c,c)$ with $0\le c\le n$ satisfy the proposition, I want to prove $(c,c)$ with $0\le c\le n+1$ satisfy the proposition, too. I attempted to use the idea of Dijkstra's Algorithm, by stating that all points within the square $0\le c\le n+1$ can be accessed by one step from points within the square $0\le c\le n$ , but it seems not a correct proof. My second attempt is to use linear equation. If $3|x+y$ , then intuitively, the knight only needs to jump rightwards and upwards, and it will the fastest way to reach $(x,y)$ . Assume the knight go $u$ steps of $(2,1)$ and $v$ steps of $(1,2)$ , which leads to a equation $$\begin{cases}2u+v=a\\u+2v=b\end{cases}$$ So $u+v=\frac{a+b}{3}$ . I guess this must be the minimum steps, but I still have difficulty rigorously proving this statement. I thought by solving equations in this kind will lead me to the answer, but just don't know how to continue. Could anybody offer me some hint or help? Thank you very much!","['graph-theory', 'chessboard', 'discrete-mathematics', 'algorithms']"
3637763,"If $f: \mathbb{C} \to \mathbb{C}$ is analytic and not linear, then $z, f(z), f(f(z)), \dots$ are linearly independent functions over $\mathbb{C}.$","I wish to prove that if $f: \mathbb{C} \to \mathbb{C}$ is analytic and not of the form $az+b,$ then $z, f(z), f(f(z)), \dots$ are linearly independent functions over $\mathbb{C}.$ The cases $n=0, 1$ are trivial. To solve this problem, I'm starting on the first non-trivial scenario: assume $c_1 z + c_2 f(z) + c_3 f(f(z)) = 0$ for some $c_1, c_2, c_3.$ If I can solve this, I'll probably know how to solve the general case. But I'm getting nowhere. The equations $z-f(z)-f(f(z))+f^3(z)=g(z)-g(g(z)) = 0$ for $f(z) = z+1, g(z) = |z|$ suggest we should impose analycity and non-linearity. Any hints or ideas? Edit: I've obtained a major breakthrough, but one step is still missing. Define a function to be $n$ -independent if $z, f(z), f(f(z)), \dots, f^{(n)}(z)$ are linearly independent over $\mathbb{C}$ on some non-empty open subset of $\mathbb{C}.$ Unproven Lemma: The set of $n$ -dependent functions forms a vector space under addition. $f$ being $n$ -dependent easily implies $cf$ is $n$ -dependent, so additivity is the only thing that stands in the way of proving this lemma. We need to figure out some way to handle terms like $(f+g) \circ (f+g) = f(f(z)+g(z))+g(f(z)+g(z))$ without messing up the rest of the terms. First note that $h(z)=az+b$ is $2$ -dependent since $z, h(z), h(h(z))$ are $3$ vectors in the $2$ dimensional vector space of polynomials with degree $\le 1.$ Suppose $f$ is analytic and non-linear. Let $n$ be minimal such that $f$ is $n$ -dependent. Let $g(z) = f(z)-(f(1)-f(0))z-f(0).$ Since $f$ isn't linear, $n \ge 2,$ implying $g$ is $n$ -dependepnt. Suppose $c_0 z + c_1 g(z) + \dots + c_n g^n(z) = 0.$ Setting $z=1,$ we get $c_0 = 0,$ so $c_1 z + \dots + c_n g^{n-1}(z) = 0$ on $\mathcal{O} = g(\mathbb{C}),$ which is open by the open mapping theorem since $g$ is analytic and non-constant. Thus, $g$ is $n-1$ dependent. If $n \ge 3,$ this means $f$ is $n-1$ dependent, contradiction. If $n=2,$ then $g$ is $1$ -dependent, so $g(z)=cz$ for some $c,$ which means $f$ is linear, contradiction.","['complex-analysis', 'linear-algebra']"
3637796,Galois group of $x^5-x-1$ over $\Bbb Q$,"I am trying to compute the Galois group of $x^5-x-1$ over $
\Bbb Q$ . I've shown that this polynomial is irreducible over $\Bbb Q$ , by showing that it is irreducible over $\Bbb Z_5$ . Let $F$ be the splitting field of $x^5-x-1$ over $\Bbb Q$ . This polynomial has $1$ real root and $4$ complex (non-real) roots. If $\alpha \in F$ is the real root of $x^5-x-1$ , then $[\Bbb Q(\alpha):\Bbb Q]=5$ , and $\Bbb Q(\alpha)\subset \Bbb R$ . Since $F \not\subset \Bbb R$ , from this we conclude that $[F:\Bbb Q]$ is strictly bigger than $5$ , and that the Galois group $G$ has a subgroup of order $5$ , i.e., contains a $5$ -cycle. But I got stuck here. Any hints?","['field-theory', 'galois-theory', 'abstract-algebra', 'polynomials', 'galois-extensions']"
3637807,Finite rings $R$ in which $x^{25}=x$ holds,"I want to classify finite rings $R$ in which $x^{25}=x$ for all $x\in R$ . I know Jacobson's Theorem that if $x^n=x$ for all $x\in$ then $R$ is commutative. I don't know how to show the Theorem for the special case $n=25$ by elementary methods. Furthermore, after showing that $R$ is commutative, is there any Theorem similar to Wedderburn's Theorem to conclude that $R$ is a field?","['field-theory', 'ring-theory', 'abstract-algebra', 'noncommutative-algebra']"
3637870,$\alpha \in \mathfrak{a}$ implies $\alpha + \mathfrak{a} =\mathfrak{a}$,"I have an ordinal $\alpha$ and an infinite cardinal $\mathfrak{a}$ and I want to show that $\alpha \in \mathfrak{a}$ implies $\alpha + \mathfrak{a} =\mathfrak{a}$ using ordinal addition, as in $0+\omega=\omega=3+\omega\neq \omega+3$ , to make the notation clear. I'm still very bad with limit ordinals in the definition of ordinal addition, so I don't know how to approach this.","['elementary-set-theory', 'ordinals', 'cardinals']"
3637874,Why does the Jacobi accessory equation coincide with the Euler-Lagrange equation for the perturbation function?,"I'm studying the second variation in Calculus of Variation. For functional $\int_{a}^{b}f(t,y,y')$ ( $y(a), y(b)$ are fixed constants), the second variation $\delta^2J[\eta,y]$ is given by $$\int_{a}^{b}\frac{1}{2}f_{y'y'}\eta'^2 + \frac{1}{2}(f_{yy}-\frac{d}{dx}f_{yy'})\eta^2 dx$$ where $y$ is chosen to be an extremal curve, i.e. the one that satisfies the Euler-Lagrange equation. And the Jacobi accessory equation is given by $$\frac{d}{dx}(f_{y'y'}u') - (f_{yy}-\frac{d}{dx}f_{yy'})u=0$$ which coincides (in form) with the Euler lagrange equation for the functional $G[u]:=\delta^2J[u,y]$ . Namely, if we consider the fucntional $\delta^2[\eta,y]$ as a functional of $\eta$ , writing down the EL eqn. will give you the Jacobi accessory equation. So, why is that? Why do they coincide?","['ordinary-differential-equations', 'calculus-of-variations', 'euler-lagrange-equation', 'partial-differential-equations', 'hamilton-jacobi-equation']"
3637878,Question about Rene Schilling's construction of Brownian Motion using complete ONS: Taking a $L^2$ limit out of the exponential,"This is part of the proof of Lemma 3.1 from Rene Schilling's Brownian Motion.(The full proof is attached at the bottom of my question.) Consider the Hilbert space $L^2(dt)=L^2([0,1],dt)$ with scalar product $\langle f,g \rangle_{L^2} = \int_0^1 f(t)g(t)dt$ , and assume that $(\phi_n)_{n \ge 0}$ is any complete ONS and let $(G_n)_{n \ge 0}$ be a sequence of real-valued iid Gaussian $N(0,1)$ random variables on the probability space $(\Omega, \mathscr{A},P)$ . Set $$W_N(t) := \sum_{n=0}^{N-1} G_n \langle 1_{[0,t)}, \phi_n \rangle_{L^2} = \sum_{n=0}^{N-1} G_n \int_0^t \phi_n(s) ds.$$ Then the limit $W(t):= \lim_{N \to \infty} W_N(t) $ exists for every $t \in [0,1]$ in $L^2(P)$ and the process $W(t)$ satisfies the properties of Brownian Motion. Proof. The proof first shows that using the independence  of $G_n$ and Parseval's identity wee get for every $t \in [0,1]$ $E[W_N(t)]^2 = t$ and $W(t) = L^2-\lim_N W_N(t)$ exists. An analogous calculation yields for $s<t $ and $u<v$ $$E(W(t)-W(s))(W(v)-W(u)) = \sum_{n=0}^\infty \langle 1_{[0,t)} - 1_{[0,s)}, \phi_n \rangle_{L^2} \langle 1_{[0,v)} - 1_{[0,u)}, \phi_n \rangle_{L^2} = \langle 1_{[s,t)} , 1_{[u,v)}\rangle_{L^2},$$ and we see that $E(W(t)-W(s))(W(v)-W(u)) = (v \wedge t - u \vee s)^+$ , so $0$ if $[s,t) \cap [u,v) = \emptyset$ . Question. I have a question about the next line of the proof. It says in the text that: With this calculation we find for all $0 \le s < t \le u < v$ and $\xi , \eta \in \mathbb{R}$ $$E[\exp(i \xi ( W(t)-W(s)) + i \eta (W(v)-W(u)))] = \lim_N E[\exp(i \sum_{n=0}^{N-1} (\xi \langle 1_{[s,t)}, \phi_n \rangle + \eta 1_{[u,v)}, \phi_n \rangle ) G_n)].$$ I can't figure out how the above calculation is used to get this identity. What exactly allows us to take the limit outside of the exponent and the expectation when we have a $L^2$ limit? An argument I came up with is we can consider $g$ to be the bounded continuous function $g(x) = \exp(i ( \xi f(x) + \eta h(x)))$ , where $f_n \to f$ in $L^2$ and $h_n \to h$ in $L^2$ ( Take $f_n = W_n(t) - W_n(s)$ and $h_n = W_n(v)-W_n(u)$ . ) Then by Vitali's generalized dominated convergence theorem, we would get $\lim_n \exp(i(\xi f_n(x)+\eta h_n(x)))=g(x)$ , which gives the identity above. However, this argument does not use the calculation $E(W(t)-W(s))(W(v)-W(u)) = (v \wedge t - u \vee s)^+$ . So I don't think this is what the author intended. I would greatly appreciate a justification of this limiting argument. I attach below the full proof.","['measure-theory', 'analysis', 'real-analysis', 'brownian-motion', 'probability-theory']"
3637889,How to find first term in sequence for Lucas Lehmer Riesel test,"I'm trying to do the Lucas Lehmer Riesel primality test. It works on numbers of the form $k \cdot 2^n-1$ with $k<2^n$ . The test basically involves calculating a term in a sequence and checking if the number being tested divides it. The Wikipedia article seems to be missing a step and I'm hoping someone can fill it in: It says to find a $P$ that satisfies the Jacobi Symbols $(\frac{P-2}{N})=1$ and $(\frac{P+2}{N})=-1$ Then it states ""To find the starting value $u_o$ from the $P$ value we can use a Lucas( $P$ , $1$ ) sequence, as shown in 2 as well as page 124 of. 3 "" I think what it's saying is to do the Lucas sequence with parameters $P$ and $1$ but how do you know what term to go up to? I'm guessing some term is the value of $u_o$ ? Also is it the $U$ or $V$ sequence? Note that if $k=1$ or $k=3$ then there are other techniques for determining the starting value.","['number-theory', 'primality-test', 'discrete-mathematics', 'algorithms', 'sequences-and-series']"
3637967,Polarization of abelian variety made by the sum of two divisors,"Let $X$ be an abelian variety of dimension $n$ , and let $L$ be a polarization, that is, an ample line bundle on $X$ , with $\chi(L)=3$ .
In my specific case, I have that $L=\mathcal{O}_X(\Theta + D)$ , where $\Theta$ is an ample divisor with $\chi(\Theta)=1$ and $D$ is an effective Cartier divisor. I want to show that $(D^2)=0$ (self-intersection of $D$ ), or equivalently that $(\Theta^{n-2}.D^2)=0$ . For $n=2$ , $X$ is a surface, and using Riemann-Roch I have that $2\chi(L)=6=(\Theta^2)+2(\Theta.D)+(D^2)$ , where the first two intersection numbers are strictly positive because of ampleness of $\Theta$ (in particular $(\Theta^2)=2$ ). If I suppose $(D^2)\ne 0$ , then $(D^2)=2$ and so $(\Theta.D)$ must be 1. But this is impossible by the index theorem, because we have $4=(\Theta^2)(D^2)\le (\Theta.D)^2$ . But for dimension $n>2$ , I don't know how to procede, because in Riemann-Roch formula $n!$ increases too fast, so it seems impossible to make the same argument. Thanks for help! Edit: I posted the same question on MO, check here for the answer.","['divisors-algebraic-geometry', 'algebraic-geometry', 'abelian-varieties', 'line-bundles']"
3637969,Alternative methods of solving an angle in an equilateral triangle,"This question has already been answered here , but the OP said trigonometry was forbidden. I was thinking of different approaches that allow trigonometry, so I decided to post a new question. An equilateral triangle is given with edges of the length $a$ . Let $X\in\overline{AB}$ s.t. $|AX|=\frac{a}{3}$ and let $Y\in\overline{BC}$ s.t. $|BY|=\frac{a}{3}$ . Let $T$ be the intersection point of $AY$ and $CX$ . Find $\measuredangle{CTB}$ . First of all, $|BX|=2|BY|\;\&\;\measuredangle XBC=60^{\circ}\implies\Delta XBY$ is one half of an equilateral triangle $\implies\measuredangle BYX=90^{\circ}\implies\color{red}{\Delta XYC\;\text{is a right-triangle}}$ . Now, $|XY|^2=\left(\frac{2a}{3}\right)^2-\left(\frac{a}{3}\right)^2=\frac{3a^2}{9}$ $|CX|=\sqrt{|XY|^2+|YC|^2}=\frac{\sqrt{7}a}{3}$ According to the $SAS$ (Side-Angle-Side) theorem, $\Delta ABY\cong\Delta AXC\;\&\;\Delta XBC\cong\Delta AYC$ .
Then, $\measuredangle CXB=\measuredangle AYC\;\&\;\measuredangle YCT=\measuredangle BCX\implies\measuredangle CTY=\measuredangle XBC=60^{\circ}\implies\Delta TYC\sim\Delta BCX$ $$\implies\frac{|XC|}{|YC|}=\frac{|BC|}{|CT|}\implies|CT|=\frac{|BC|\cdot|YC|}{|XC|}=\frac{a\frac{2a}{3}}{\frac{\sqrt{7}a}{3}}=\frac{2a}{\sqrt{7}}$$ In $\Delta XYC$ , we have: $\cos(\measuredangle YCX)=\frac{|CY|}{|CX|}=\frac{\frac{2a}{3}}{\frac{\sqrt{7}a}{3}}=\frac{2}{\sqrt{7}}$ In $\Delta BCT$ , we have: $$|BT|=\sqrt{|BC|^2+|CT|^2-2|BC|\dot|CT|\cos(\measuredangle YCX)}=\sqrt{a^2+\frac{4a^2}{7}-2a\cdot\frac{2a}{\sqrt{7}}\cdot\frac{2}{\sqrt{7}}}=\frac{\sqrt{3}a}{\sqrt{7}}$$ In $\Delta YCT$ , we have: $\frac{|CY|}{\sin(\measuredangle CTY)}=\frac{|CT|}{\sin(\measuredangle TYC)}\implies \sin(\measuredangle TYC)=\frac{|CT|\sin(\measuredangle CTY)}{|CY|}=\frac{\frac{2a}{\sqrt{7}}\frac{\sqrt{3}}{2}}{\frac{2a}{3}}=\frac{3\sqrt{3}}{2\sqrt{7}}=\sin(\measuredangle BYT)$ In $\Delta BYT$ , we have $\frac{|BT|}{\sin(\measuredangle BYT)}=\frac{|BY|}{\sin(\measuredangle YTB)}\implies\measuredangle YTB=\arcsin\frac{|BY|\sin(\measuredangle BYT)}{|BT|}=\arcsin\frac{\frac{a}{3}\frac{3\sqrt{3}}{2\sqrt{7}}}{\frac{\sqrt{3}a}{\sqrt{7}}}=\arcsin\frac{1}{2}\implies\measuredangle YTB=30^{\circ}$ Finally, $\measuredangle CTB=\measuredangle TYB+\measuredangle CTY=90^{\circ}$ Picture: My question is : is there any shorter way I could solve this via trigonometry or vectors? Thank you in advance!","['euclidean-geometry', 'trigonometry', 'solution-verification', 'triangles']"
3638067,Is the number of nonzero digits always at least $m$?,"if $k,m$ is give  postive integers,for any postive integer $p$ , if we define $$p\cdot\dfrac{k^m-1}{k-1}=a_{i}k^{i}+a_{i-1}k^{i-1}+\cdots+a_{1}\cdot k+a_{0}$$ where $a_{i}\in\{0,1,2,\cdots,k-1\}$ ,and let set $A=\{i|a_{i}\neq 0\}$ ,show that $$|A|\ge m$$ this problem it see interesting,such  if $k=2,m=3$ I found $p=1,2,3,4,\cdots 10$ it is clear true,But How to prove this General for example: for $k=2,m=3$ ,it is clear $p=2^a,a\ge 1$ is right,and we only consider $p$ is prime, and (1) $p=3$ ,then $3(2^2+2^1+2^0)=21=2^4+2^2+2^0$ so $A|=3=m$ (2) $p=5$ ,then $5(2^2+2^1+2^0)=35=2^5+2^1+2^0$ ,so $A|=3$ (3): $p=7$ ,then $7(2^2+2^1+2^0)=49=2^5+2^4+2^0$ so $|A|=3$ (4): $p=11$ ,then $11(2^2+2^1+2^0)=77=2^6+2^3+2^2+2^0$ so $|A|=4\ge 3=m$ (5): $p=13$ ,then $13(2^2+2^2+2^0)=2^6+2^4+2^3+2^1+2^0$ ,so $|A|=5\ge m$ (5): $p=17$ ,then $13(2^2+2^2+2^0)=119=2^6+2^5+2^4+2^2+2^1+2^0$ ,so $|A|=6\ge m$ in general: let $p=2^{a_{1}}+2^{a_{2}}+\cdots+2^{a_{k}},0\le a_{1}<a_{2}<\cdots<a_{k},a_{i}\in N$","['number-theory', 'elementary-number-theory']"
3638084,Definition of Differentials through Surreal Numbers,"It is fairly well known that nowadays derivatives are defined primarily by use of a limit argument. I think I recall that when the idea of derivatives was first introduced (and limits had not yet been used) there was some criticism because the method of computing derivatives/justifying them required the notion of an absolutely small positive number (epsilon). I am wondering whether the concept of surreal numbers would allow for exactly this definition of derivatives/differentials to be mathematically valid as well. After all, surreal numbers would allow for an epsilon that fits the description above. It would also justify why higher-order terms can be neglected in a derivative (because higher order terms represent differentials raised to even higher powers, which must then belong to even smaller groups of surreal numbers. Thanks for any help on this.","['calculus', 'analysis', 'surreal-numbers']"
3638122,Motivation for Quasi Coherent Sheaf,"I have some background in vector bundles in the context of differential geometry and I have seen how vector fields form a module over smooth functions on a smooth manifold. Recently I came across quasi coherent sheaf in the context of $O_X$ -modules over a scheme $(X,O_X)$ . My teacher introduced it as sheaf of modules that locally look like associated sheaf wrt to some module M (although most online resources seem to define it using some exact sequence of modules which I do not quite get). Now coming to my questions : In many online resources I am seeing a recurrent comment ""Quasi coherent sheaves are generalizations of vector bundles in context of Algebraic Geometry"". What does this mean? How does that exact sequence definition come into play?","['quasicoherent-sheaves', 'definition', 'algebraic-geometry', 'vector-bundles', 'sheaf-theory']"
3638131,Reference Requiest: Representation Theory of Diffeomorphism Groups,"This wonderful and insightful Wikipedia page contains a lot of interesting facts about representations of diffeomorphism groups.  However, there are no references. In general, I'm curious if $Diff_k^p(\mathbb{R}^d)$ denotes the orientation-preserving $C^k$ -diffeomorphism group of $\mathbb{R}^d$ which stabilizes $0$ .  They claim that $Diff^{\infty}_x(\mathbb{R}^d)/Diff^{1}_x(\mathbb{R}^d)$ can be identified with $GL(\mathbb{R}^d)$ .  Where can I find this fact?  More interestingly, what can we say about $$
Diff^{\infty}_x(\mathbb{R}^d)/Diff^{k}_x(\mathbb{R}^d),
$$ for $k\geq 2$ (besides it being finite-dimensional) and where can I find a nice book about these wonderful things?","['diffeomorphism', 'topological-groups', 'reference-request', 'lie-groups', 'differential-geometry']"
3638204,The Maximum number of points of intersection of 4 distinct circles and 8 distinct straight lines is,The Maximum number of points of intersection of 4 distinct circles and 8 distinct straight lines is 1)66 2)64 3)104 4)40 Can anyone please help me to solve this problem? My attempt : I have seen this link-- Maximum number of points of intersection . But I can not understand how they are so sure that all intersection points are distinct.,"['combinatorial-geometry', 'combinatorics', 'geometry']"
3638229,"Show that the integral $ f(x,y)=1+\int_0^x\int_0^y f(u,v)dudv$ has at most one continuous solution","Show that the integral $$ f(x,y)=1+\int_0^x\int_0^y f(u,v)dudv$$ has at most one continuous solution for $0 \leq x \leq 1$ , $ 0\leq y <1$ . The integral can be written as $$I=1+\int_0^1\int_0^1 f(u,v)dudv.$$ Now if we take $f(u,v)$ to be an integrable function in the given region, certainly, we will get only one continuous solution or outcome. How to argue in general case? Suppose $f(u,v) = g(u,v)$ ,then $$\iint f(u,v)dudv = \iint g(u,v)dudv.$$ Therefore, $$1+\iint f(u,v)dudv = 1+\iint g(u,v)dudv.$$ This implies $$f(x,y)=g(x,y).$$ So only one continuous solution. Is it suitable argument??","['integration', 'multivariable-calculus']"
3638248,Vector bundle is Manifold,I want to show that the total space of a vector bundle $E \overset{\pi}{\rightarrow} M$ is itself a manifold. It is easy to construct charts by just composing the bundle maps $\pi^{-1}(U_{\alpha}) \rightarrow U_{\alpha} \times \mathbb{R}^k$ with the charts for $M$ . It now remains to show the Hausdorff property and that $E$ is second countable. Can someone help me with that?,"['vector-bundles', 'general-topology', 'smooth-manifolds', 'differential-geometry']"
3638251,Self-Study: Triangle Inequality Correct?,I am presented the following inequality for $f:D\rightarrow \Bbb{C}$ : $$|f(x)| \geq |f(\hat{x})| - |f(x) - f(\hat{x})|$$ My explanation is: $$|f(\hat{x})| = |f(\hat{x}) - f(x) + f(x)| = |(f(\hat{x}) - f(x)) + f(x)| \leq |(f(\hat{x}) - f(x))| + |f(x)|$$ Thus: $$|f(\hat{x})| - |(f(\hat{x}) - f(x)| \leq |f(x)|$$ Since $|x|= |-x|$ it follows: $$|f(\hat{x})| - |(f(\hat{x}) - f(x)| = |f(\hat{x})| - |(f(x) - f(\hat{x})| \leq |f(x)|$$ is my reasoning correct?,"['triangle-inequality', 'functions', 'analysis']"
3638270,Can we easily check whether a number is in this sequence?,"Here : https://oeis.org/A060650 the positive integers $\ n\ $ are shown for which there is exactly one non-abelian group of order $\ n\ $ . Is there an easy criterion to check whether a number is in this sequence ? It seems that a number in this sequence must be cubefree (Is this actually true ?) I am also aware of a formula for the number of groups of order $\ n\ $ when $\ n\ $ is squarefree, although this formula is quite complicated. If the number is even, it seems that it is in the list if and only if it is twice an odd prime.","['group-theory', 'finite-groups']"
3638306,Prove that $\lim_{n\to\infty}a_n=\frac{\sum_{i=1}^k2ia_i}{k(k+1)}$,"Given that a sequence $(a_n)$ satisfies $a_{n+k} = \dfrac{a_n + a_{n+1} + \cdots + a_{n+k-1}}{k}$ for $n\geq 1,$ where $k\in\mathbb{N},$ prove that $\lim\limits_{n\to\infty} a_n = \dfrac{2a_1}{k(k+1)}+\dfrac{4a_2}{k(k+1)}+\cdots +\dfrac{(2k)a_k}{k(k+1)}.$ I am not sure how to go about doing this. However, I understand why this might be the case. Informally, the $j$ th term, where $1\leq j\leq k$ eventually occurs $j$ times more often than the first term. Also, when the first $k$ terms are $1,$ all the terms in the sequence are one, as evidenced by the proof below. Proof: We proceed by strong induction. Suppose the first $k$ terms are $1.$ Then the $(k+1)$ th term is also $1$ (since it is the average of the first $k$ terms). Assume that the first $k+m$ terms are $1$ for some $m\in\mathbb{N}.$ Then we have $a_{m+1} = \cdots = a_{k+m} = 1$ and $a_{k+m+1} = \dfrac{a_{m+1} + \cdots + a_{k+m}}k = 1,$ so the first $k+m+1$ terms are $1.$ Hence by strong induction, all the terms of the sequence are $1$ if the first $k$ terms are $1.$ Since the $j$ th term, $1\leq j\leq k$ occurs $j$ times as often as the first term, we have that $\dfrac{1}a + \dfrac{2}a + \cdots + \dfrac{k}a = 1,$ where $\dfrac{1}a$ is the coefficient of $a_1$ in the limit of the sequence. Hence $\dfrac{k(k+1)}{2a} = 1\Rightarrow a = \dfrac{k(k+1)}2\Rightarrow \lim\limits_{n\to\infty} a_n = \dfrac{a_1}a + \dfrac{2a_2}a +\cdots + \dfrac{ka_k}a = \dfrac{2a_1}{k(k+1)} + \cdots + \dfrac{(2k)a_k}{k(k+1)}.$ Obviously the above reasoning is too informal to be considered a proof, so I am not sure how to prove this. If I could prove that the $j$ th term eventually occurs $j$ times as often as the first term in the limit, it would be enough to prove this.","['limits', 'calculus', 'sequences-and-series']"
3638337,Mean Value Theorem Integrals,"Let $f,g:[a,b]\to\mathbb{R}$ be smooth and integrable. Then , there exists an $x_0\in[a,b]$ with $$ \int_a^b f(x)g(x)dx=f(x_0)\cdot\int_a^b g(x)dx.$$ Is there any way of approximating $x_0$ , without evaluating $\int_a^b f(x)g(x)dx$ ? We may assume $g$ to be positive and monotone increasing and $\int_a^b g(x)dx$ to be known. Setting $g(x)\equiv1$ , we obtain $$ \int_a^b f(x)dx=f(x_0)\cdot(b-a),$$ so finding this $x_0$ numerically may be a strong tool in approximating any integral?","['integration', 'definite-integrals', 'approximation', 'real-analysis', 'numerical-methods']"
3638339,What is the best way to denote a set of solutions in a professional setting?,"I have the following Diophantine equation that I want to solve over the positive (real) integers: $$x^2+y^2=x+9y\tag1$$ Questions: I want to solve this equation for real positive integers bigger than or equal to 2. How do I write that mathematically? When I find the solutions I got: $(x,y)$ can be $(5,4)$ , $(5,5)$ and $(1,9)$ . How do I write that mathematically that those are the solutions? I think that the answer to question 1 is: $$\left(x\in\mathbb{N}\space\wedge\space x\ge2\right)\space\wedge\space\left(y\in\mathbb{N}\space\wedge\space y\ge2\right)\tag2$$ I think that the answer to question 2 is of these three notations: \begin{align}
(x,y)&=(5,4),(5,5),(1,9),\tag3 \\
(x,y)&=\{(5,4),(5,5),(1,9)\},\tag4 \\
(x,y)&\in\{(5,4),(5,5),(1,9)\}.\tag5
\end{align}","['real-numbers', 'number-theory', 'coordinate-systems', 'diophantine-equations', 'notation']"
3638344,Evaluate $\lim_{n \to \infty}\prod_{k=0}^{n} \left(1+\frac{2}{45^{2^k}+45^{-2^k}}\right)$,Evaluate $$P=\lim_{n \to \infty}\prod_{k=0}^{n} \left(1+\frac{2}{45^{2^k}+45^{-2^k}}\right)$$ My try: Let $a_k=45^{2^k}$ Then we have $45^{-2^k}=\frac{1}{a_k}$ So We get: $$1+\frac{2}{a_k+\frac{1}{a_k}}=\frac{(a_k+1)^2}{a_k^2+1}$$ So $$P=\lim_{n \to \infty}\prod_{k=0}^n\frac{(a_k+1)^2}{a_k^2+1}$$ Any way from here,"['infinite-product', 'telescopic-series', 'sequences-and-series']"
3638386,How does one solve $(x+1)y'+xy^2=0$ subject to $y(0) = 1$?,"I would like to solve the differential equation $$(x+1)y'+xy^2=0$$ and initial condition $$y(0)=1.$$ My result is $$y=\frac{1}{x-\ln|x+1|+c},$$ while the result from Wolfram is $$y=\frac{1}{x-\ln(x+1)+c}.$$ For initial condition $$y=\frac{1}{x-\ln|x+1|+1}$$ I do not know which interval as a domain to choose from $(-\infty,-W(1)-1)$ , $(-W(1)-1,-1)$ , $(-1,\infty)$ . It is my result for condition: $(x-\ln|x+1|+1\neq0) \wedge (x+1\neq0)$ . I wonder where did Wolfram get that result without absolute value, is there any trick for it? And also what solution would it be for initial condition $y(0)=0$ , will it be singular solution $y=0$ for $x\in R$ ?",['ordinary-differential-equations']
3638388,Prove that $1\cdot \frac{1}{2^2}\cdot ...\cdot \frac{1}{n^n}< \left(\frac{2}{n+1}\right)^\frac{n(n+1)}{2}$,"Prove that $$1\cdot \frac{1}{2^2}\cdot ...\cdot \frac{1}{n^n}< \left(\frac{2}{n+1}\right)^\frac{n(n+1)}{2}$$ where $n$ is a positive integer. My book suggests using AM-GM, but I couldn't do it. I just applied AM-GM to the numbers in the LHS, but it looks like I need some more upper bounds.","['algebra-precalculus', 'inequality']"
3638394,"Given $A \in \mathbb R^{m \times n}$, find upper bound for $\mathbb E\|Az\|_q$ for $z$ drawn uniformly at random on the sphere $\{\|z\|_p = 1\}$","Let $m$ and $n$ be positive integers and $p,q \in [1,\infty]$ . Consider the finite-dimensiaonal normed vector spaces $X = (\mathbb R^m,\|\cdot\|_p)$ and $Y = (\mathbb R^n,\|\cdot\|_q)$ , where $$
\|x\|_p := \begin{cases}(\sum_{i=1}^m|x_i|^p)^{1/p},&\mbox{ if }1 \le p < \infty,&\\\max_{i=1}^m|x_i|,&\mbox{ else.}\end{cases}
$$ Let $A:X \rightarrow Y$ be a linear operator, and $z$ be uniformly distributed on the unit sphere in $m$ -sphere of $X$ , and define $\Delta_{p,q}(A):= E[\|Az\|_q]$ . Question. What are good upper bounds for the quantity $\Delta_{p,q}(A)$ in terms of spectral properties of $A$ ( $m$ , $n$ , singular values, etc.) ? Note. I'm particularly interested in the cases where $p,q \in \{1,2,\infty\}$ . Solution for the euclidean case $p=q=2$ Suppose $p=q=2$ . Then $z$ is uniform on the euclidean unit $m$ -sphere, and so has mean $\mu = 0$ and covariance matrix $\Sigma = (1/m)I_m$ . By Jensen's inequality and standard formula for expectation of quadratic forms , one computes $$
\begin{split}
\Delta_{2,2}(A)^2 &:= (E\|Az\|_2)^2 \le E\|Az\|_2^2 = \text{Trace}(A^TA\Sigma) + \|A\mu\|_2^2 = (1/m)\text{Trace}(A^TA)\\
& = (1/m)\|A\|_{\text{Fro}}^2,
\end{split}
$$ from which we get $\Delta_{2,2}(A) \le m^{-1/2}\|A\|_{\text{Fro}}$ . Edit: Solution for the case $p \in \{2,\infty\}$ By symmetry, $z$ has mean 0 and covariance $$
\Sigma_p = \begin{cases}\frac{1}{m}I_m,&\mbox{ if }p = 2,\\\frac{1}{3}I_m + \mathcal O(m^2e^{-Cm}),&\mbox{ if }p=\infty.\end{cases}
$$ Thus, one computes $$
E\|Az\|_2^2 = \text{Trace}(A^TA\Sigma_p) = \begin{cases}\frac{1}{m}\text{Trace}(A^TA) = \|A\|_F^2,&\mbox{ if }p = 2,\\\frac{1}{3}\|A\|_F^2+ \mathcal O(m^2e^{-Cm}),&\mbox{ if }p=\infty.\end{cases}
\tag{1}
$$ On the other hand, we have by classical equaivalence bounds for norms on finite-dimensional spaces, one has $$
\|Az\|_q \le \begin{cases}n^{1/q-1/2}\|Az\|_2,&\mbox{ if }1 \le q < 2,\\\|Az\|_2, &\mbox{ if }2 \le q \le \infty.\end{cases}.
$$ Taking expectations on both sides and using (1), we then get $$
\begin{split}
\frac{\Delta_{p,q}(A)}{\|A\|_F} &\le \begin{cases}m^{-1/2}n^{1/q-1/2},&\mbox{ if }p=2,\;1 \le q < 2,\\m^{-1/2}, &\mbox{ if }p=2,\;2 \le q \le \infty,\\\dfrac{n^{1/q-1/2}}{3},&\mbox{ if }p=\infty,\; 1 \le q < 2,\\\frac{1}{3},&\mbox{ if }p=\infty,\; 2 \le p \le \infty.\end{cases}\\
\end{split}
$$ which can be written more compactly as $$
\frac{\Delta_{p,q}(A)}{\|A\|_F} \le  \begin{cases}m^{-1/2}n^{(1/q-1/2)_+},&\mbox{ if }p=2,\\\dfrac{n^{(1/q-1/2)_+}}{3},&\mbox{ if }p=\infty.\end{cases}
$$","['statistics', 'concentration-of-measure', 'geometric-probability', 'random-matrices', 'probability']"
3638437,Why must harmonic functions on compact Riemannian manifolds be constant?,"On a compact Riemannian manifold $(M,g)$ , a function $f$ is called harmonic if $\Delta_{g} f = 0$ , and it is known that the only harmonic function on a compact riemannian manifold is constant function. I wonder how one would prove this. So locally $\Delta_{g}$ is just a second order elliptic operator, thus has the weak maximum principle, which says that the max must appear on the boundary. However I do not think this is enough to prove that harmonic functions are constants. Instead, we need the strong maximum principle which I think holds when the operator is strongly elliptic. Is $\Delta_{g}$ strongly elliptic?","['partial-differential-equations', 'differential-geometry', 'riemannian-geometry', 'real-analysis']"
3638518,An invertible matrix minus the diagonal is nilpotent,"Let $A=(a_{ij})$ be an $n\times n$ invertible matrix over $\mathbb{C}$ and $D=diag(a_{11},a_{22},\dots,a_{nn})$ be the diagonal matrix whoes diagonal entries are same as $A$ . Suppose $A-D$ is nilpotent. Is it true that $D$ is invertible? For $n=2$ , since every nilpotent matrix with zero diagonal entries is either upper- or lower-triangular, I already know this is true for $n=2$ . Thank you! Thank you for user1551 for giving a counter example for $n\geq 3$ . I have modified the question a bit. I would like to assume the matrix $A$ having the property that $$a_{ij}\neq 0\Rightarrow a_{ji}=0.$$ Will it be true that $D$ is invertible under this assumption?","['matrices', 'linear-algebra']"
3638530,Bounded projector in Hilbert space,"I am facing the following exercise in functional analysis. Let $H$ be a Hilbert space and $P$ a bounded projector. We define the subspaces $M=\operatorname{im}P$ and $N=\operatorname{im}(I-P)^\perp$ . Show that $$\require{amsmath,mathtools} \alpha=\inf_{m\in M\setminus\{0\}}\sup_{n\in N\setminus\{0\}}\frac{|\langle m,n\rangle|}{||m|| ||n||}>0.$$ I know that $M$ and $N$ are closed since $P$ is bounded and that we can write $N=(\operatorname{ker} P)^\perp$ . Now let $m=Pu$ with $u\not\in \operatorname{ker} P$ and $n\in N$ , I don't see how to proceed. Any help is appreciated. (By the way, is there any general intuition to this ""inf-sup""-condition?)","['hilbert-spaces', 'functional-analysis']"
3638568,How to geometrically compute the group of deck transformations of a covering space?,"The following diagrams are covering spaces of the wedge sum of two circles $S^1 \vee S^1$ . In Hatcher's Algebraic Topology , Hatcher has this short remark on page 71. Note that in $(7)$ the group of deck transformations is $\mathbb{Z}_4$ while in $(8)$ it is $\mathbb{Z}_2 \times \mathbb{Z}_2$ . The definition for a deck transformation we use is that similar to Munkre's definition in Topology . Definition: Given a covering map $p:E \to B$ , a deck transformation is a homeomorphism $h: E \to E$ such that $p = p \circ h$ . For $(7)$ , each deck transformation can be view geometrically as a rotation of $0,\pi/2,\pi,$ or $3\pi/2$ . This explains why the group of deck transformations is $\mathbb{Z}_4$ . In $(8)$ , two of the deck transformations are a rotation of $0$ and a rotation of $\pi$ . However, it is unclear to me what the other two transformations are. In my lecture notes, my professor noted that the deck transformations for $(8)$ can be viewed as rotations and reflections. However, by reflecting $(8)$ at all, the orientation of each of the segments reverses. Doesn't this indicate that $p \neq p \circ h$ for a reflection homeomorphism $h$ ? My question: What are the deck transformations geometrically for $(8)$ and $(9)$ and how do you compute them? Furthermore, how do you argue that there are no other deck transformations?","['group-theory', 'algebraic-topology', 'covering-spaces']"
3638613,Orders of Elements in Symmetric Groups,"We define the symmetric group $S_n$ to be the set of all permutations of the first $n$ natural numbers. Moreover, we define the set $T_n$ as the set of all possible orders of elements in $S_n$ i.e. $$T_n=\{ \space|\sigma| \mid \sigma \in S_n \}$$ We are interested in studying the set $T_n$ . First, we can start by observing when $x \in T_n$ , given positive integers $x$ and $n$ . Clearly, $x=1$ is an element of $T_n$ for any $n \in \mathbb{N}$ since the identity permutation has order $1$ . For $x>1$ , let the prime factorization of $x$ be: $$x=\prod_{i=1}^k p_i^{a_i}$$ Assume that a permutation $\sigma \in S_n$ has order $x$ . Let the unique cycle decomposition (with cycles of length $1$ ignored) of $\sigma$ be: $$\sigma=\prod_{j=1}^t C_j$$ We have $x=|\sigma|=\text{lcm}(|C_1|,|C_2|,\ldots,|C_t|)$ . Using this equation, we can show that for every $1 \leqslant i \leqslant k$ , there exists some $1 \leqslant j \leqslant t$ such that $p_i^{a_i} \mid |C_j|$ . This implies that $p_i^{a_i} \leqslant |C_j|$ . Moreover, if we have multiple prime powers, say $p_1^{a_1}, p_2^{a_2}, \ldots ,p_i^{a_i}$ (WLOG a list of $i$ prime powers) all dividing $|C_j|$ , we can see that: $$p_1^{a_1}p_2^{a_2}\cdots p_i^{a_i} \mid |C_j| \implies p_1^{a_1}+p_2^{a_2}+\cdots+p_i^{a_i} < p_1^{a_1}p_2^{a_2}\cdots p_i^{a_i} \leqslant |C_j|$$ This tells us that: $$\sum_{i=1}^k p_i^{a_i} \leqslant \sum_{j=1}^t |C_j| \leqslant n \implies \sum_{i=1}^k p_i^{a_i} \leqslant n$$ However, one can see that this is a sufficient condition for the existence of a permutation $\sigma$ as we can set $k=t$ and $|C_i|=p_i^{a_i}$ for all $1 \leqslant i \leqslant k$ . Thus: $$x \in T_n \iff \sum_{i=1}^k p_i^{a_i} \leqslant n$$ We can see that the sum of the prime powers in the factorization of numbers is relevant in studying $T_n$ . Thus, we define: $$f \bigg( \prod_{i=1}^k p_i^{a_i} \bigg) = \sum_{i=1}^k p_i^{a_i}$$ One result we can deduce using this function is showing that the only exception to $|T_n|>|T_{n-1}|$ for $n>2$ is $n=6$ . Clearly, we can see from above that: $$|T_n|>|T_{n-1}| \iff \exists \space x \in \mathbb{N} \text{ such that } f(x)=n$$ We can check that $n=1,6$ are the only exceptions till $n<11$ . For $n \geqslant 11$ , we prove by induction hypothesis. We assume that $1$ and $6$ are the only exceptions until $n-1$ . As $11$ is the second Ramanujam prime, we have: $$\pi(n)-\pi \bigg(\frac{n}{2} \bigg) \geqslant 2$$ So, let two primes in the interval $\bigg(\frac{n}{2},n \bigg]$ be $p$ and $q$ . Clearly, $n-p$ and $n-q$ are not simultaneously $1$ and $6$ due to parity. WLOG, let $n-p \neq 1,6$ . We have: $$f(x)=n-p \implies f(px)=n$$ Note that $p \nmid x$ as $p>n-p$ . Thus, we have concluded that $|T_n|>|T_{n-1}|$ for $n>2, n\neq6$ . We can see that the observation of $f(x)$ gives us better insight on the set $T_n$ . I have the following questions: $1.$ What is the average order of $f(x)$ ? Can we write an asymptotic expression for the same? $2.$ Is there an asymptotic expression for $|T_n|$ ? Can we say anything about the same using the function $f(x)$ ?","['symmetric-groups', 'number-theory', 'group-theory']"
3638642,"Probability of getting 3 specific characters from a pool of 400, with 200 attempts, with repetitions","I'm playing a game where you can get characters from a pool of 400, if you get one character and dismiss it you can get that character again in another attempt, but if you take the character with you, you can't get it again. Also, you can only get one character per attempt. So, what is the probability of getting 3 specific characters after 200 attempts? Consider I would only get those 3 and dismiss all the rest. I came to a result, but I'm not sure if I'm right: Assuming they're all equally probable, and I already have 7 characters, the chances of getting the first one is $1 - (1 - 1/393)^{200} = 0.3992$ . The chances for the second are $1 - (1 - 1/392)^{199} = 0.3985$ , since I would take the first one, and I'd have to find it in the other 199 attempts. The chances for the third would be $1 - (1 - 1/391)^{198} = 0.3977$ . So, the chances of getting those 3 events in the same 200 attempts would be the multiplication of the probabilities of those 3 events alone: $0.3992 * 0.3985 * 0.3977 = 0.0632$ Is this correct? It's been some years since I last did something like this in university, so it's likely that I'm missing something.","['conditional-probability', 'probability']"
3638676,"Determine if $X=\{f\in C^1[0,1] | f(0)=f'(0)\}$ is complete WRT $||.||_{\infty}$ norm and show that $X$ is infinite dimensional.","I'm having trouble determining if $X$ is complete WRT $||.||_{\infty}$ norm. I know that in order to show that I need to take a Cauchy sequence and show that it has a limit in my space $X$ or find a Cauchy sequence of functions which satisfy $f(0)=f'(0)$ and which limit lies outside of $X$ . I tried but was unable to find a counter example, therefore I believe the statement to be true, however I am not sure exactly how to go about proving it. So far I was able to prove that any $g\in X$ is of the form $f(0)+\int_0^xf(y)dy$ where $f\in C[0,1]$ if it helps. would really appreciate it if somebody could show me how to prove of disprove this statement. Thanks","['banach-spaces', 'complete-spaces', 'normed-spaces', 'examples-counterexamples', 'functional-analysis']"
3638729,"1000 page book, without pages with odd digits","In a book of a thousand pages, we rip off those which have numbers with at least one odd digit, i.e. we rip off $768$ and $100$ but we don't rip off $248$ . a. Which page is in the position $100$ after the pages are ripped off? b. Which position holds the page with the number $888$ ? I started writing a generic number in decimal base: $a.10^3+b.10^2+c.10+d$ Then, I know that $a,b,c,d$ have to be even, and $a$ equals $0$ . I made a tree as follows: Then I counted until I found the page that holds the $100$ position, knowing that every green circle holds $25$ pages in it. When I found it I read the previous number because there is no page $0$ . That gives me the page with the number $686$ . Then with a similar reasoning the page with the number $888$ holds the $124$ position. So, I have two questions. First, is this right? Second, is there a better way to approach this problem? I feel there must be a more analytical way to do it.","['number-systems', 'divisibility', 'discrete-mathematics']"
3638770,Unbiased estimator of probability density function,"Given a random variable $X \sim f(x) = \frac{1}{x\log (\theta)}$ when $1 < x < \theta$ , I am trying to find an unbiased estimator of a simple random sample of size $n$ for $d(\theta) = \log (\theta)$ . The pdf of the simple random sample is $f(x_1, \dots, x_n) = \frac{\operatorname{I}_{(-\infty, \theta)}(X_{(n)})\operatorname{I}_{(1, \infty)}(X_{(1)})}{\log ^n(\theta)\prod_{i=0}^n x_i}$ I have tried every single candidate I can think of, but cannot find any suitable function. The candidates I have tried so far are: 1) The maximum, $T(X_1, \dots, X_n) = X_{(n)}$ , whose pdf is given by: \begin{equation}
P_T(X_{(n)} \leq Y) = P_X(X_i \leq Y\quad\forall i\in\{1,\dots,n\}) = (P_X(X\leq Y))^n \implies\\ f_T(x_1,\dots,x_n) = n(P_X(X\leq Y))^{n-1}f_X(x_1,\dots,x_n) = \frac{n\log ^{n-1}(x)}{x\log ^n(\theta)}
\end{equation} The expected value of $T$ is thus: \begin{equation}
E[X_{(n)}] =\int_1^\theta x\frac{n\log ^{n-1}(x)}{x\log ^n(\theta)} dx = \frac{n}{\log ^n(\theta)}\int_1^\theta \log ^{n-1}(x)
\end{equation} which is not $\log (\theta)$ . 2) $T(X_1, \dots, X_n) = \frac{1}{\prod_{i=0}^n X_i}$ . Since the random variables are independent: \begin{equation}
E\left[\frac{1}{\prod_{i=0}^n X_i}\right] = \left(E\left[\frac{1}{X}\right]\right)^n = \left(\int_1^\theta \frac{1}{x^2\log (\theta)} dx\right)^n = \frac{1}{\log ^n(\theta)}\left(1-\frac{1}{\theta}\right)^n \neq \log (\theta)
\end{equation} 3) The minimum, $T(X_1, \dots, X_n) = X_{(1)}$ , whose pdf is given by: \begin{equation}
P_T(X_{(1)} \leq Y) = 1 - P_T(X_{(1)} > Y) = 1 - P_X(X_i > Y\quad\forall i\in\{1,\dots,n\}) = 1 - (P_X(X> Y))^n = 1 - (1 - P_X(X \leq Y))^n \implies\\ f_T(x_1,\dots,x_n) = n(1 - P_X(X\leq Y))^{n-1}f_X(x_1,\dots,x_n) = n\left(1-\frac{\log (x)}{\log (\theta)}\right)^{n-1}\frac{1}{x\log (\theta)}
\end{equation} The expected value of $T$ is thus: \begin{equation}
E[X_{(1)}] =\int_1^\theta xn\left(1-\frac{\log (x)}{\log (\theta)}\right)^{n-1}\frac{1}{x\log (\theta)} dx = \frac{n}{\log ^n(\theta)}\int_1^\theta \log ^{n-1}(x) = \frac{n}{\log ^n(\theta)}\int_1^\theta (\log (\theta)-\log (x))^{n-1}
\end{equation} which, again, is not $\log (\theta)$ . Can anyone shine a light on how to calculate de MVUE? Thank you.","['statistics', 'variance']"
3638809,How can I find the number of different triangles in $n$-vertex graph?,"First of all, I reveal this problem stems from below statement. a graph $G = (V, E)$ with $n$ vertices is extremal for $K_3$ if it contains ""no triangles"" and has $\left\lfloor\frac{n^2}{4}\right\rfloor$ edges. Thm : For every $n$ , every extremal $n$ -vertex graph for $K_3$ is isomorphic to the graph $K_{a, b}$ with $a=\left\lfloor\frac{n}{2}\right\rfloor$ , $b = n -\left\lfloor\frac{n}{2}\right\rfloor$ . So, conversely saying, if the number of edges of any $n$ -vertex graph is greater than $\left\lfloor\frac{n^2}{4}\right\rfloor$ , We can find a triangle(or triangles), that is, can find at least ""one"" triangle. Likewise, if average degree of the n-vertex graph is greater than $\frac{n}{2}$ , so the number of edges is the graph is greater than $\frac{n^2}{4}$ , thus we can find at least one triangle. Back to main problem, I can't reach how can I find ""different $\frac{1}{10}$ ${n\choose 3}$ triangles"" if the average degree of the graph ( $n$ -vertex) is greater than $\frac{3n}{5}$ . I don't just want to find answers. If you're willing to help me, Give me hints, please. thanks for reading.","['graph-theory', 'extremal-combinatorics', 'combinatorics', 'discrete-mathematics', 'inequality']"
3638841,Proving these sets are well-ordered with the order inherited from $\mathbb{R}$.,"These questions arise in my Set Theory module but I don't understand how to go about deciding if the following sets, with order inherited from the reals, are well-ordered or not. $\textbf{I would only like a hint or some intuition to help me along.}$ $A=\{\frac{1}{m}- \frac{1}{n} : n,m \in\mathbb{N}\}$ $B=\{-2^{-m}-3^{-n} : n,m \in\mathbb{N}\}$ I argue that $A$ is not well-ordered. 
The generic element of $A$ , $\frac{1}{m}- \frac{1}{n}$ for some $n,m \in\mathbb{N}$ . We obtain that $-1 < \frac{1}{m}- \frac{1}{n} < 1$ . In particular, since the value of this element will ""converge"" to -1 as m tends to infinity, we cannot pick a smallest element of this set. Hence we cannot pick a smallest element for every subset of it, and so it cannot be well-ordered. For $B$ , I am stuck:
The whole set has a least element. However this does not tell us about the least element of any subset of it, so this does not help us. We could check if there is an infinite strictly decreasing sequence in this set. I tried taking the subsequence of the even or odd terms in this, but this leads to increasing sequences. I need some help with this one. Thanks","['elementary-set-theory', 'order-theory', 'well-orders']"
