question_id,title,body,tags
3332474,How to calculate probability of a cell containing mine in minesweeper?,In Minesweeper: If we just investigate 1 specific cell and 8 unrevealed cells surrounding it. I know that the chance of a cell is mine = number of mines (the center number) / number of hidden cells. But what if we have one more cell is revealed? Can someone please show me the way to calculate the probability of the rest of them containing mines? Thank you.,"['statistics', 'discrete-mathematics', 'probability']"
3332493,How can a constant point have a locus?,"My question is regarding this and similar problems like above. So the question is asking to find the locus of the centroid of the tetrahedron. But to my understanding, the centroid of the tetrahedron is a constant point (Because now the tetrahedron is also described according to constant coordinate points and sphere which too has constant radius). So how can a constant point like these can be represented as a equation?","['locus', 'geometry', '3d']"
3332502,Expected number of elements in intersection of two randomly sampled subsets from two different sets,"Let's say you have two sets $A$ with $5000$ elements and $B$ with $8000$ elements, $A ∩ B$ contains $500$ elements. Let's say we randomly sample $500$ elements from set $A$ , name it $A'$ and randomly sample $800$ elements for set $B$ , name it $B'$ . What is the expected number of elements in the set $A' ∩ B'$ ? Thinking in the naive way results in an answer of $50$ , which is wrong. I am unable to proceed in any particular direction. Any leads would be helpful ?","['expected-value', 'probability']"
3332599,Equivalence of power series,"Ok, this is probably a very silly question, and I'm probably overcomplicating the issue, but here it goes: I'm making questions on power series, and it asks me to find the convergence radius of the series $$\sum_{n=1}^\infty z^{n!}$$ Of course, usually a power series is given in the form $$\sum_{n=1}^\infty a_n z^n$$ and we see that we here have to take $$a_n = \begin{cases}1 \quad n = k! 
 \quad \mathrm{for \ some \ k}\\ 0 \quad \mathrm{else}\end{cases}$$ From this, it is easy to see that $\limsup_{n\to \infty} |a_n|^{1/n} = 1$ as we have a subsequence converging to $1$ and the limsup can't become greater than that, so $1$ is the largest limit of a subsequence. Hence, the convergence radius is $1$ . My concern : Shouldn't we formally show that $$\sum_{n=1}^\infty z^{n!}= \sum_{n=1}^\infty a_n z^n$$ for my choice of $(a_n)_n$ ? In the left sum, we sum over 'less' terms that the right one, while in the right sum we sum over 'more' terms, but these are zero so intuitively the terms are not affected. Write $(c_n)_n$ for the left partial sums and $(d_n)_n$ for the right partial sums. Then we see that $(d_n)_n$ has the form $(c_1,\underbrace{c_1, \dots, c_1}_{k_1 terms}, c_2, \underbrace{c_2, \dots, c_2}_{k_2 terms}, \dots)$ and it suffices to show that $(c_n)_n$ converges if and only if $(d_n)_n$ converges and in this
  case the limits coincide If $(d_n)_n$ converges, then $(c_n)_n$ converges to the same limit because it contains $(c_n)_n$ as a subsequence. Conversely, assume $(c_n)_n$ converges to $c$ . Let $\epsilon > 0$ and choose $n_0$ such that $d(c_n, c) < \epsilon$ whenever $n \geq n_0$ . If $n \geq n_0 + k_1 + \dots + k_{n_0}$ , then $d_n\in \{c_{n_0}, c_{n_0+1}, \dots\}$ and it follows that $d(d_n, c) < \epsilon$ . Hence $d_n \to c$ , proving the statement. $\quad \square$ . Any thoughts about it? Am I overthinking this?","['complex-analysis', 'convergence-divergence', 'power-series', 'real-analysis']"
3332606,Domain of definition of a hamiltonian with delta(contact) potential,"I am having a hard time making sense of the so-called ""delta function potential well"" in quantum theory. The Hamiltonian operator is defined as (with $\mathscr D_H\subset \mathscr H=L^2(\mathbb R)$ ) $$H:\mathscr D_H\rightarrow \mathscr H$$ $$\psi\mapsto H\psi$$ And $$(H\psi)(x):=-\frac{d^2}{dx^2}\psi(x)-\lambda\delta(x)\psi(x).$$ My job is to find the spectrum of this operator given a $\lambda>0$ . My problems are: How do I construct $\mathscr D_H$ ? What definition of the ""delta function"" is suitable for this kind of job?","['hilbert-spaces', 'functional-analysis', 'quantum-mechanics']"
3332620,"Maximize $\min(abh,cdg)k+\min(abj,fdg)l+\min(ebh,cdi)l+\min(ebj,fdi)m$ subject to $a+e=c+f=1$","Let $a,b,c,\ldots,m\ge0$ with $a,c,e,f\le1$ . I want to maximize $$\varphi(a,c,e,f):=\min(abh,cdg)k+\min(abj,fdg)l+\min(ebh,cdi)l+\min(ebj,fdi)m$$ over all choices of $a,c,e,f$ subject to $a+e=c+f=1$ . Unfortunately, I don't have much to contribute, since I'm not familiar with this kind of problems. I could imagine that the solution is simple, but I might be wrong. It might be useful to note that $2\min(x,y)=x+y-|x-y|$ for all $x,y\ge0$ .","['optimization', 'nonlinear-optimization', 'maxima-minima', 'analysis']"
3332625,Prove that the Bessel function $J_n(x)$ satisfied $\int x J_0^2(x) dx = \frac{x^2}{2}[J_0^2(x)+J_1^2(x)]$,Prove that the Bessel function $J_n(x)$ satisfied $\int x J_0^2(x) dx = \frac{x^2}{2}[J_0^2(x)+J_1^2(x)]$ I really don't know where to even begin. Any hints or ideas is greatly appreciated. Thank you!,"['ordinary-differential-equations', 'bessel-functions']"
3332667,What exactly does curl measure? What is rotating about what?,"This question is a bit long, the next two paragraphs give some context, but you can skip it. Thank you. I have seen many different explanations for the meaning of curl, or what exactly does it measures, but so far none of those gives a truly unambiguous, rigorous, definitive and clear explanation that clear all my doubts. Often it is mentioned that curl measures ""the tendency of the vector field to rotate"" or ""curl measures local rotation"", without mentioning what exactly does ""local"" mean, or what is ""tendency"". There is no mention of what exactly is rotating about what. And what exactly is the measurement of the rotation, is it ""angular speed""? In which case, is it measured in radians/unit time? But this seems very arbitrary, and does not feel right, as mathematical concept should not rely on a physical concept. So, I found this to give the most sense. But I still have lots of doubts regarding the explanation. Here is what I understood from reading it; along with some hypothesis I made (which may be wrong), which I believe is necessary to make the entire reasoning logically consistent. Please verify if my understanding is correct, help to correct any mistake in the assumptions/hypothesis I made. And most importantly, the following is written in natural language, which is not precise, but I lack all of the analysis machinery to spell all things out in precise mathematical terms. Please help to rephrase the story using fully rigorous analysis. Suppose we are dealing with 3 dimensional space. Given a vector field F, curl F is also a vector field, such that at each point (x, y, z), curl F measures this: draw a sphere centered at (x, y, z) with infinitely small radius, the sphere is infinitely small but not a singularity, so there are other points in the interior other than (x, y, z). F will give the direction and magnitude of the vector at each of the interior points. Then curl F gives 2x the total average instantaneous ""angular velocity"" of all the interior points about (x, y, z). It's not a real angular velocity as it does not carry the same physical units or meaning. It would be more precise to say it's 2x the total average instantaneous "" ratio between the length of tangential component of vector to the radius "" of all the interior points about (x, y, z) The rotation of the points as defined in 1 can be broken down into 3 orthogonal components, for example in 3-D euclidean coordinate system the x, y and z components. Hence it is valid to compute individual components of curl F separately in each of the three orthogonal planes. When computing one of the components (say z component in the x-y plane). Because we are only concerned with a sphere with infinitely small radius, we can regard the sphere as just a plane disc. As each of the level plane of the small sphere will have the same average ""angular velocity"". Similarly, when computing the average rotation of the disc, because we are letting the disc's radius tending to zero, so every ring on that disc will again have the same average ""angular velocity"". Thus, it is valid to just consider a single ring around the point (x, y, z). Hence the computation simply involves calculating the circulation of F around (x, y, z) with infinitely small radius. Hence the analogy of a small ""paddle wheel"" in the linked notes. But there is a problem here, if we apply the same argument in 3 and 4, we can say that the ring will shrink to a point, so that the value of the vector field F is the same at all points. But then this means that there will be no rotation, and the curl of any field is the zero vector. This is obviously wrong. But why is it valid to apply 3 and 4, but not 5? I need an analytic proof. Also, why should we be concerned with a small sphere, but not a small enclosed shape of any sort? A cube, a tetrahedron or some irregular shape? My hypothesis is that because for every closed shape one can come up with, there will be two spheres that bound the shape from inside and outside. If we can show that as the radii tend to zero the average ""angular velocity"" of all interior points in the two spheres are the same, then whatever shape one comes up with must also have the same average ""angular velocity"". with regard to 3-6, there seems to be a sense of when boundary shapes are ""topologically"" equivalent when considering limits. When or when not can someone ""simplify"" the shape to another form. Is there a formal branch of mathematics that deal with this, and gives the precise analysis tool to reason about this? the term ""instantaneous"" is important in ""total average instantaneous angular velocity of all the interior points about (x, y, z)"". Because, this way we will not be concerning ourselves with physics. Since, the outcome of filling the small sphere with a elastics/inelastic rigid-body/fluid will be different. If it was a rigid body, with perfect in-elasticity, then in general the object will disintegrate as F does not guarantee that all points will always have the same relative distance and orientation after some movement specified by the vector field. If it was a elastic rigid body, then some parts of the object could be compressed, and some parts will be stretched out. So, we are only concerned (on a more abstract level) about all the points enclosed by the sphere we draw, nothing to do with physics.","['analysis', 'real-analysis', 'multivariable-calculus', 'differential-topology', 'differential-geometry']"
3332669,Showing that the limit of non-eigenvector goes to infinity,"Let $A$ be a $3$ by $3$ real matrix with the triple eigenvalue $1$ . Also, further suppose its eigenspace corresponding to $1$ is only of dimension $1$ . Thus, we can find a basis of $\mathbb{R}^3$ , denoted by $v$ . $w_1$ . $w_2$ where $v$ is an eigenvector of $A$ . Then I have to show that $\lim_{n \to \infty} \|A^n w_1\|=\lim_{n \to \infty} \|A^n w_2\|=\infty$ . How is this possible? I do not have any idea how the norm goes to infinity...Could anyone please help me?","['matrices', 'linear-algebra']"
3332673,How wide is the Birkhoff Polytope?,"Now also posted on Math Overflow. Define the width of a polytope $P \subset \mathbb R^d$ as the minimum length of the interval $\{v \cdot p:p \in P\}$ for $v$ in the unit sphere. In other words the width is the smallest number $W$ such that you can sandwich $P$ between two hyperplanes distance $W$ apart. Here's a picture: Suppose the polytope $P \subset \mathbb R^d$ is contained in the affine subspace $A + x$ for $A \subset \mathbb R^d$ a hyerplane. Define the relative width as the smallest length of $\{v \cdot p:p \in P\}$ as $v$ ranges over the unit sphere in $A$ . In other words translate the affine subspace to contain the origin and then ignore the perpendicular directions. The Birkhoff polytope $\mathcal B$ is defined as the convex hull of the $n!$ permutation matrices. That means the $n \times n$ matrices with all zeros except for exactly one $1$ in each row and column. Equivalently $\mathcal B$ is the set of nonnegative matrices with all row and column sums equal to $1$ . In this case the affine subspace is defined as $$\left \{x \in \mathbb R^d: \sum_j x^i_j =1, \sum_i x^i_j =1\right \}.$$ This just says the row and column sums equal $1$ . Within that subspace the polytope is defined as the intersection with the first quadrant. I am having trouble computing or estimating the height of $\mathcal B$ . I would imagine the $v$ that minimises the projection is something like $$
   v =
  \left( {\begin{array}{cccc}
   1/4 & -1/4 & 1/4& -1/4\\
   -1/4 & 1/4 & -1/4 & 1/4\\
   1/4 & -1/4 & 1/4 & -1/4\\
  - 1/4 & 1/4 & - 1/4 & 1/4\\
  \end{array} } \right)
$$ or in general make half the diagonals equal to $1/n$ and the other equal to $-1/n$ . Then choosing the correct permutation matrices for the endpoints of the interval, we can force the interval to have length $2$ . The only reason I have to believe this is there are many choices of permutation matrices, and we want to minimise the interval length among all pairs. So $v$ should be symmetric in some sense. Does anyone have ideas?","['permutations', 'polytopes', 'discrete-geometry', 'linear-algebra', 'birkhoff-polytopes']"
3332676,"Exercise on stopping time, Doob decomposition and Martingale","Let X be a square integrable martingale with square variation process $\langle X\rangle$ . Let $\tau$ be a finite stopping time. Show the following: If $E(\langle X\rangle)<\infty$ , then $E((X_\tau-X_0)^2)=E(\langle X\rangle_\tau)$ and $E(X_\tau)=E(X_0)$ In my attempted solution I used the following definitions: Let's consider the probability space $\Omega,\mathbb{F},P$ , where $\mathscr{F}_k$ for $k=0,1,2,3...$ are the filtrations of $\mathbb{F}$ . $\langle X\rangle_n=\sum\limits_{k=1}^{n}E((X_k-X_{k-1})^2|\mathscr{F}_{k-1})$ Attempted proof : So $E(\langle X\rangle_\tau)=E(\sum\limits_{k=1}^{\tau}E((X_k-X_{k-1})^2|\mathscr{F}_{k-1}))=E(\mathbb{1}_\Omega\sum\limits_{k=1}^{\tau}E((X_k-X_{k-1})^2|\mathscr{F}_{k-1}))=\sum\limits_{k=1}^{\tau}E((X_k-X_{k-1})^2)=E(\sum\limits_{k=1}^{\tau}(X_k-X_{k-1})^2)=E((X_\tau-X_0)^2)$ Regarding $E(X_\tau)=E(X_0)$ , I have read in a similar question that I should use the martingale definition since $X_{\tau\wedge n}$ is a martingale by the optional sampling theorem. However I am not seeing how to solve it. Questions: Is my solution insofar right? How should I prove the second point $E(X_\tau)=E(X_0)$ ? Thanks in advance!","['martingales', 'probability-theory']"
3332691,Flipping k adjacent coins from n coins laid on a circle to make them all head-up,"Think of $n(\geq3)$ coins laid on a circle, each showing head-up or tail-up. The goal is to make every coin head-up by flipping $k$ adjacent coins several times. What is the necessary and sufficient condition of $n$ and $k$ for achieving this goal from any starting state? For example, I show an example below, where $n=4, k=3$ : ('O' means head) I figured out two conditions by invariant: $k$ should be odd $k \nmid n$ But I'm stuck showing whether this is an if and only if condition.",['number-theory']
3332702,"Proving $ \lim_{(x,y) \to (0,0)} \frac{x^2y}{x^2+|y|}=0$","I'm unable to prove that $$ \lim_{(x,y) \to (0,0)} \frac{x^2y}{x^2+|y|}=0$$ I tried with polar coordinates but I'm unable to reach a function that depends only on $\rho$ $$0\le\frac{\rho^3\cos^3(\theta)\sin(\theta)}{\rho^2\cos^2(\theta)+|\rho\sin(\theta)|}=\frac{\rho^2\cos^3(\theta)\sin(\theta)}{\rho\cos^2(\theta)+|\sin(\theta)|}\leq \dots ?$$","['multivariable-calculus', 'limits', 'calculus', 'proof-verification']"
3332740,"How do you find the coordinate points for $\pi/8$, then $3\pi/8$, $5\pi/8$ and $-7\pi/8$?","I am really struggling with this unit circle problem. How do you find the coordinate points for $\pi/8$ then $3\pi/8$ , $5\pi/8$ and $-7\pi/8$ ? I am familiar with other terminal points up to $\pi/6$ , and I guess $\pi/8$ must be below $\pi/6$ in the same quadrant, but how do you find the coordinates? Are there any steps or formula involved? In the lecture all we asked to do is to try to memorize the coordinates with the common terminal points and it didn't include $\pi/8$ . I have gone through the entire lecture notes but still don't know how to find it. I have attached a screenshot of the problem. Thank you.","['trigonometry', 'circles']"
3332832,"Properties of the sequential space $(X,\tau_{seq})$ generated by $\tau$.","Let $(X,\tau)$ be a Hausdorff space. Denote by $\tau_{seq}$ the topology on $X$ whose closed sets are the sequentially $\tau$ -closed subsets of $X$ . 
 From my understanding, the space $(X,\tau_{seq})$ is a sequential space . Is there a book/paper where I can read more about the topological properties of $\tau_{seq}$ or sequential spaces in general? The nlab page for sequential spaces mentions about their categorical properties which I am not interested in. I would like to know properties like metrizability or if such spaces are completely regular/normal . More specifically, I am interested in the space $(X,w_{seq})$ , where $X$ is a Banach space and $w$ its weak topology (generated by bounded linear functionals). This case is related to the sequential lower semicontinuity of some integral functional in calculus of variation that I am studying. Any account that covers only this case would suffice for my purpose. PS. This question is a follow-up question to another one I asked on Mathoverflow earlier here .","['calculus-of-variations', 'general-topology', 'functional-analysis', 'reference-request']"
3332849,Continuity at a Point (Local Property),"Can anyone please explain me the following paragraph regarding limits and continuity?: One thing to note about continuity is that it is a local property. What this means is that, for any $a \in \mathbb{R}$ , if two functions $f$ and $g$ are equal on an open interval containing $a$ , then either both $f$ and $g$ are continuous at $a$ or both are discontinuous at $a$ . This is because they have the same value at $a$ and the same limit at $a$ (if these exist). I don't clearly understand what 'local property' means. Moreover, I think that the statement ""if two functions $f$ and $g$ are equal on an open interval containing $a$ , then either both $f$ and $g$ are continuous at $a$ or both are discontinuous at $a$ "" is false. Here's a counterexample that I came up with: Let $a = 0$ , $f(x) = x^2 + 1$ , $g(x) = \left\{
\begin{array}{ll}
      x & \text{if } x\neq 0 \\
      1& \text{if } x = 0
\end{array} 
\right.$ Here, $f$ is continuous at $x = 0$ while $g$ is not. Yet both are equal at $x = 0$ . Edit: thank you for pointing out my error. I was wondering if there is any need for the interval to be open? Why can it not be a closed interval containing $a$ ?","['limits', 'continuity', 'real-analysis']"
3332927,analytic function that maps the entire complex plane into the real axis,"An analytic function that maps the entire complex plane into the real axis must map the imaginary axis onto: A) the entire real axis B) a point C) a ray D) an open finite interval E) the empty set I was thinking that it might be a constant function. 
Any help would be appreciated!",['complex-analysis']
3332999,Why are there $2^n-1$ terms in the inclusion-exclusion formula of $n$ sets?,"Why are there $2^n-1$ terms in the inclusion-exclusion formula of $n$ sets? An example of what I mean by inclusion-exclusion formula is this: There are three sets (i.e. $n$ $=$ $3$ ): $A, B,$ and $C$ . $A \cup B \cup C = |A| +|B|+|C|-|A\cap B| - |A\cap C| - |B \cap C| +|A \cap B \cap C| $ There are $2^3-1 =7$ terms in the right hand side of the equation. This seems to be true in general, but I'm not sure why. It's probably something obvious I'm missing, can anyone give me a hint?","['elementary-set-theory', 'inclusion-exclusion', 'discrete-mathematics']"
3333007,"If $x$ and $y$ are real numbers such that $4x^2 + y^2 = 4x - 2y + 7$, find the maximum value of $5x+6y$.","If $x$ and $y$ are real numbers such that $4x^2 + y^2 = 4x - 2y + 7$ , find the maximum value of $5x+6y$ . I did a little bit of manipulation and got $4(x+1)(x-2) + (y+1)^2=0$ . I then got $x=2$ and $y=-1$ which means the maximum must be $4$ , but the answer key says it's $16$ . How come?","['maxima-minima', 'cauchy-schwarz-inequality', 'optimization', 'algebra-precalculus', 'quadratics']"
3333037,"Showing $b^2 \notin \langle a \rangle$ for $V_{8n}=\langle a,b:a^{2n}=e, b^4 = e, ba=a^{-1}b^{-1},b^{-1}a=a^{-1}b\rangle.$","For $n \in \mathbb N$ , finite group $V_{8n}$ is $$ V_{8n} = \langle a, b  : a^{2n} = e, b^4 =e, ba = a^{-1}b^{-1}, b^{-1}a = a^{-1}b \rangle. $$ This group is defined in this paper for all $n \in  \mathbb N.$ I want to prove that $b^2 \notin \langle a \rangle$ . If possible,   let $b^2  \in \langle a \rangle$ . Then $b^2 = a^t$ for some $t$ . I observe that the possibility of $t$ is $n$ . Since $ba = a^{2n -1}b^3$ so that by mathematical induction on $i$ , we get $$ ba^i = \left\{ \begin{array}{ll}
a^{2n -i}b & \mbox{if $i$ is even };\\
a^{2n - i}b^3& \mbox{if $i$ is odd}\end{array} \right.$$ If $n$ is odd, then $b^3 = ba^n =  a^n b^3$ implies $a^n = e$ ; a contradiction. I am stuck here if $n$ is even.  I would be thankful for your kind help.","['group-presentation', 'finite-groups', 'combinatorial-group-theory', 'abstract-algebra', 'group-theory']"
3333045,Modular Arithmetic CRT: How do modulo with very big numbers,"I have always been intrigued as to how one would calculate the modulo of a very large number without a calculator. This is an example that I have come up with just now: 4239^4 mod 19043 The answer is 808, but that is only because I used a calculator. I read in books and online that you can break the modulo 19043 to its factors such that it is modulo 137 and 139 as (modulo (137*139)) is (modulo 19043). I tried something like this... 4239^4 mod 137
=129^4 mod 137
=123


4239^4 mod 139
=69^4 mod 139
=113 But now I am stuck as to what to do next in Chinese Remainder Theorem","['number-theory', 'chinese-remainder-theorem', 'modular-arithmetic', 'elementary-number-theory']"
3333061,"$7$ dwarfs $d_1, ... , d_7$ have $7$ jobs $j_1, ... , j_7$ to do every day","$7$ dwarfs $d_1, ... , d_7$ have $7$ jobs $j_1, ... , j_7$ to do every day. But: $$d_1 \text{ can't do } j_2, j_3$$ $$d_2 \text{ can't do } j_1, j_5$$ $$d_4 \text{ can't do } j_2, j_7$$ $$d_5 \text{ can't do } j_4$$ How many ways can they separate their work differently each day? In this task we know that every dwarf can only do $j_6$ . $j_1,j_3,j_4,j_5,j_7$ can be done by $6$ dwarfs. And $j_2$ can be done by $5$ dwarfs. However this observation is not enough to finish this task. I need an intelligent way to connect this fact with a sollution. Can you help me?","['graph-theory', 'combinatorics']"
3333080,Why $142857$ when multiplied by $1$ to $6$ gives the same digits?,"What made 142857 a special number?
Why it gives the same digits if it is multiplied by 1,2,3,4,5 & 6 ?
And gives all nines when it is multiplied by 7?","['algebra-precalculus', 'arithmetic', 'recreational-mathematics']"
3333115,"Help, A clearer picture of a messy proof on generated algebras.","I am trying to self learn from a MIT-OCW course  on measure theoretic probability: this resource . However, one of their homework problems turns out to be very messy even in the solution provided (which is probably why it is optional). In their homework assignment 2 , question 7 the following shows up in their proof: 
The very first part is where I have trouble, For a collection $C$ and a space $Ω$ let $α_Ω (C)$ denote the smallest algebra of sets in $Ω$ containing $C$ . Here $Ω_1 \subset Ω$ Claim: $α_{Ω_1} (C ∩ Ω_1) = α_Ω(C) ∩ Ω_1$ . I understand the intent to show the 2  are equal, by showing they are contained in one another but in doing so they arrive at the following step:  let $E∩Ω_1 ∈ α_Ω (C)∩Ω_1$ , then $$
(E ∩ Ω_1)^c=  Ω_1 -(E ∩ Ω_1 ) =  E^c ∩ Ω_1 ∈ α_Ω (C) ∩ Ω_1\text{, as } E ∈ α_Ω (C)
$$ and $ α_Ω(C)$ is an algebra. As I understand , $(E ∩ Ω_1)^c$ = $ Ω_1 -(E ∩ Ω_1 )$ can only happen when $E \subset Ω_1$ holds, but this is not the general case. I am stuck here and cannot process rest of the proof, now I have spent 2 days trying to convince myself that the steps are right. Can someone provide some clarity? The proof is actually very badly written, with an attempt to squeeze in some general theorem about algebras and their intersection.","['proof-explanation', 'measure-theory', 'algebras']"
3333153,"""sheaves of germs of differentiable functions are by no means coherent""?","This is related to a remark in Iitaka's algebraic geometry sec 1.12. ""...It should be noted that sheaves of germs of differentiable functions are by no means coherent. These facts seem to suggest coherence is linked with the property of being algebraic or analytic."" $\textbf{Q1:}$ What is the example of non-coherence for the differentiable case? First what is the sheaf of rings in the context? Is it ring of smooth functions? $\textbf{Q2:}$ If I recall correctly, there are analytic sheaves which are not coherent.(I do not think I will recall this correctly.) Coherence is related notion to algebraic for sure but I have to use GAGA to say it is analytic. However, in analytic setting, there are non-coherent sheaves as well. Should I naively interpret coherence is subcase of analytic or algebraic?(But not the reverse in general?)","['coherent-sheaves', 'algebraic-geometry', 'sheaf-theory', 'differential-geometry']"
3333184,How many subsets contain no 3 consecutive elements?,"How many subsets of $\{1,2,...,n\}$ have no $3$ consecutive numbers ? My solution: Inspired by How many subsets contain no consecutive elements? I decided to write recurrence: 
Let be set with numbers from $1$ to $n$ and let $A$ - subset of given set $$ a_n = \underbrace{a_{n-1}}_{n \notin A} + \underbrace{a_{n-2}}_{n \in A , n-1 \notin A} + \underbrace{a_{n-3}}_{n \in A, n-1 \in A, n-2 \notin A} $$ After examining corner cases I use iverson bracket to write full recurrence: $$ a_n = a_{n-1}+ a_{n-2} + a_{n-3} + [n=0] + [n=1] + [n=2]$$ After multiplying by $x^n$ and summing by all $n$ I got generating function: $$A(x) = x A(x) + x^2 A(x) + x^3 A(x) +1+ x + x^2 $$ $$A(x) = \frac{1+x+x^2}{1-x-x^2-x^3} $$ But how to solve this generating function to get coefficient with $x^n$ ?","['combinatorics', 'discrete-mathematics', 'generating-functions']"
3333205,$ \sum_{k=1}^{\infty}\frac{\log(k)}{k^2(k+1)}$ explicit value.,"I am trying to evaluate the following series explicitly, $$ \sum_{k=1}^{\infty}\frac{\log(k)}{k^2(k+1)}$$ I know this converges by the comparison test.
I have tried defining a function, $$f(t)=\sum_{k=1}^{\infty}\frac{\log(kt)}{k^2(k+1)}$$ Differentiating this with respect to t gives, $$f'(t)=\frac{1}{t}\sum_{k=1}^{\infty} \frac{1}{k^2(k+1)} = \frac{1}{t}(\zeta(2)-1)$$ Integrating this, $$\int_a^t f'(s)ds = f(t)-f(a) = (\zeta(2)-1)(\log(t) - \log(a))$$ for some constant a>0. However whichever constant I choose I get in a bit of a muddle when trying to evaluate at t=1. I was hoping for a hint in the right direction or maybe a suggestion of a different method that might be useful.","['power-series', 'sequences-and-series', 'real-analysis']"
3333209,$\mathbb{R}$ with the right topology is pseudocompact.,"I am studying for the math GRE, and I found this question on topology to be hard for me. Endow $\mathbb{R}$ with the right topology, generated by $\tau=\{(a,\infty):a\in\mathbb{R}\}$ , and call this space $X$ . Why is $X$ pseudocompact? By pseudocompact, I mean that every continuous function $f:X\mapsto\mathbb{R}$ is bounded.",['general-topology']
3333229,On Cayley representation of groups,"Suppose $G$ is a group. Let’s define Cayley representation of $G$ as the homomorphism $\operatorname{Cay}$ from $G$ to $\operatorname{Sym}(G)$ that maps every element $a$ to the permutation $\phi_a: g \mapsto ag$ . Is it always true, that $\frac{N_{\operatorname{Sym}(G)}(\operatorname{Cay}(G))}{C_{\operatorname{Sym}(G)}(\operatorname{Cay}(G))} \cong \operatorname{Aut}(G)$ ? Here $N$ stands for normalizer and $C$ for centralizer. For all finite groups of order up to $4$ this seems to be true, but what for other groups?","['symmetric-groups', 'group-theory', 'abstract-algebra', 'automorphism-group']"
3333252,differential geometry applied to Biology,"I'm looking for current areas of research which apply techniques from differential geometry to biological processes. I'm (scantly) aware of a handful of applications to cell science and microbiology, but I've heard almost nothing of differential geometric methods in say ecology or evolution. Any sort of reference (textbook, paper, researcher, etc) would be appreciated.","['biology', 'reference-request', 'applications', 'differential-geometry']"
3333268,Find an open set which has finite length and is super set of rational numbers,"We define the length of the open set as the difference between the ends. $l[(a,b)]=b-a$ and $l[(a,b)\cup(c,d)]\leq l[(a,b)]+l[(c,d)]$ We have to find one open set $U$ such that $l(U)<\infty$ and $Q\subset U$","['discrete-mathematics', 'real-analysis']"
3333290,Solution of a differential equation stays on the unit circle once it visits the unit circle,"Consider the equation (for $\lambda \in C([0,\infty))$ ) given by; $\partial_t g_t(z) = g_t(z) \frac{e^{i\lambda (t)} + g_t(z)}{e^{i \lambda (t)} - g_t(z)} $ ; $g_0(z) =z$ . Here $t \in [0,\infty)$ and $z \in \mathbb{C}$ . I want to prove that when $z$ is on the unit circle, $g_t(z)$ is also on the unit circle. So far, since $g_0(z) = z$ I have that $g_t(z)$ starts on the unit circle when $z$ is in the unit circle. I also see that $\partial_t \log|g_t(z)| = Re \Big( \frac{e^{i\lambda (t)} + g_t(z)}{e^{i \lambda (t)} - g_t(z)} \Big)$","['complex-analysis', 'ordinary-differential-equations', 'logarithms']"
3333293,Drawing causal relationship from an observational study?,"I am reading OpenIntro's Statistics and came across this problem: In part b) I don't believe one can establish causal relationships because the research is an observational study (I think). After reading through the study itself, it seems that its authors do draw a causal relationship. Any help explaining as to why this is would be greatly appreciated. Thank you.","['statistical-inference', 'statistics', 'definition']"
3333297,At what point of mathematical education can you start inventing new math?,"I am a 2nd year student doing an honors program in math and statistics. Everything that I have been learning has been formulas, theorems, and mathematical concepts that other people have discovered/invented/created. Some very simplistic formulas I am able to modify to meet the needs of what I am trying to accomplish, but still I am using someone else discoveries as a basis for what I am modifying. Friends and family say I am becoming a mathematician, but I dont feel that way as I do not have the ability to invent/create/discover new math, I am simply regurgitating what others have discovered. At what point in your mathematical education are you able to invent new math? For example, the linear regression formula. How did Francis Galton know that the formula he created would accomplish what he wanted to accomplish? Note: Sorry to the editors as I could not find a relevant tag for this question.",['calculus']
3333301,Question about branching process in Durrett,Q) Let $Z_n$ be a branching process with offspring distribution $p_k$ i.e. $Z_{n+1} = \xi_{1}^{n+1}+...+\xi_{Z_n}^{n+1}$ if $Z_n>0$ and $Z_{n+1} = 0$ if $Z_n = 0$ where $\xi_i^n$ are i.i.d and $p_k = P(\xi_i^n = k)$ is the offspring distribution. Let $\phi(\theta) = \sum p_k\theta^k$ . Suppose $\rho<1$ has $\phi(\rho)=\rho$ . Show that $\rho^{Z_n}$ is a martingale and conclude $P(Z_n = 0 \text{ for some } n\geq 1|Z_0 = x)=\rho^x$ . I've shown $\rho^{Z_n}$ is a martingale but am not sure how to conclude $P(Z_n = 0 \text{ for some } n\geq 1|Z_0 = x)=\rho^x$ because $E(\rho^{Z_n}|Z_0 = x) = \rho^x$ and the expectation is for a fixed $n$ where as the required probability is for some $n$ ? Thanks.,['probability-theory']
3333313,Ultraproducts and types!,"Let $\mathcal{C}=\{A_k\}_{k<\omega}$ be a class of finite $\mathcal{L}$ -structures. Let $p(x)=\{\varphi(x)\}_{i<\omega}$ be a consistent family of $\mathcal{L}$ -formulas (you can think about $p(x)$ as a type), and let $\mathcal{M}=\prod_{i\in I}A_i/\mathscr{U}$ be an infinite ultraproduct of members of $\mathcal{C}$ (where $I$ is an infinite subset of $\omega$ , and $\mathscr{U}$ is a non-principal ultrafilter on $I$ ).  By the Łoś Theorem we know that for every $\mathcal{L}$ -formula $\psi(x)$ and every $[(a_j)_{j\in I}]\in M$ : $$ \mathcal{M}\models \psi\big([(a_j)_{j\in I}]\big) \text{ iff }  \{i\in I: A_i\models \psi(a_i)\}\in \mathscr{U}.$$ Question (1): What can we say if $\mathcal{M}\models p(\bar{a})$ for some $\bar{a}=[(a_j)_{j\in I}]\in M$ ? Question (2): If for each $i<\omega $ , $\mathscr{U}_i:=\{j\in \omega: A_j\models \varphi_i(a_j) \text{  for some } a_j\in A_j \}\in \mathscr{U}$ , for some ultrafilter $\mathscr{U}$ on $\omega$ . Can we conclude that there is a ultraproduct of members of $\mathcal{C}$ that realizes $p(x)$ ? Question (3): In general, for a given type $p(x)=\{\varphi(x)\}_{i<\omega}$ ,  what are the sufficient conditions on members of $\mathcal{C}=\{A_k\}_{k<\omega}$ to conclude that ""there is an ultraproduct $\mathcal{M}$ of members of $\mathcal{C}$ that realizes $p(x)$ ""? (In general, it is not clear for me what happen when an ultraproduct satisfies a type. Any comment, idea or refrence would be appreciated)","['elementary-set-theory', 'model-theory', 'logic', 'first-order-logic']"
3333340,Statistical tests on correlation coefficients,"I ran an experiment with $n$ subjects. For each subject, I measured the correlation  ( $\rho$ ) between two variables. Thus, I ended up with $n$ correlation coefficients $\rho$ . I wanted to test whether the population correlation coefficient is different from zero. What statistical test should I perform? I had tried Fisher transformation on each subject's $\rho$ , but not sure how to proceed.","['statistical-inference', 'statistics', 'correlation', 'hypothesis-testing']"
3333356,Completion of local ring,"Suppose we have a variety $X$ over an algebraically closed char 0 field $K$ , and a point $p\in X$ . If the completion of the local ring of $X$ at $p$ is isomorphic to $K[[x_1,\ldots,x_n]]/(f)$ for some polynomial $f$ , what does this mean for the geometry of $X$ at $p$ ? Does there exist a nbhd $U$ of $p$ isomorphic to the affine variety defined by $f$ ?","['algebraic-geometry', 'commutative-algebra']"
3333357,"Intuitive reasons for why approximating arclength with lines is good, but approximating surface area with polygons fails?","One common definition of arclength is to just define it as a supremum of the set of lengths obtained by approximating your curve as a union of line segments (I was asked in the comments for a more precise definition; see https://en.wikipedia.org/wiki/Arc_length#Definition_for_a_smooth_curve ). The natural analogue of this to the surface area of a surface in 3 space fails quite spectacularly thanks to constructions such as the Schwarz lantern , which shows we can approximate a cylinder by polyhedra whose surface areas approach infinity! Is there an intuitive reason that polygonal approximation works so well for curves but fails so spectacularly for surfaces?",['geometry']
3333373,"$\int \log(x+e^x) \mathbb{d}x$, or When every CAS fails","No computer algebra system -- at least to my knowledge -- managed to either compute the integral $\int \log(x+e^x)\space \mathbb{d}x$ , in terms of any known functions, or even just prove that it is not elementary. Although it is pretty much obvious that no classical trick would help with getting the antiderivative, it is much less obvious -- to me at least --, as to why is this case so special that modern CASes either freeze (Wolfram), honestly report something like ""Implementation incomplete (constant residues)"" (Axiom), or a weird answer that is plain wrong if you try differentiating it (Mathcad). In fact, there is a big family of functions that all crash the modern CASes, in form of $\int f(x+g(x)) \mathbb{d}x$ , eg. $\sqrt{x+\cos(x)}$ , $\sqrt[3]{x+\sin(x)}$ . Mathcad even gives the wrong answer for the integrals of the latter two radicals. So, my two questions are: Are any of those inetegrals expressable in terms of any known functions? Why do the modern computer algebra systems fail to prove these are not elementary/...okay, liouvillian? If anyone reading this happen to know how Risch's algorithm works, I'd love to hear from him or her as to how Risch's algorithm is supposed to tackle this problem. I mean, proving the non-elementarity, what would be the right field extension tower for that, what would follow from it, and how would the algorithm show that this integral is not elementary/liouvillian/... -- or is it?","['integration', 'computer-algebra-systems']"
3333391,"Evaluate $\int_0^{\infty } \frac{\sinh (a x) \sinh (b x)}{(\cosh (a x)+\cos (t))^2} \, dx$","Gradshteyn&Ryzhik $3.514.4$ states that $$\int_0^{\infty } \frac{\sinh (a x) \sinh (b x)}{(\cosh (a x)+\cos (t))^2} \, dx=\frac{\pi  b \csc (t) \csc \left(\frac{\pi  b}{a}\right) \sin \left(\frac{b t}{a}\right)}{a^2}$$ Whenever $0<\left| b\right| <a,0<t<\pi$ . My bet is on Feynman's trick or contour integration but haven't figure out the exact way. Any help will be appreciated!","['integration', 'complex-analysis', 'definite-integrals']"
3333403,Does Every Subset of a Separable Topological Space have Countably Many Isolated Points?,"This is almost certainly a duplicate, but I keep seeing this result on metric spaces, not topological ones. Let $(X,\tau)$ be a topology. A set $A\subset X$ is dense if $A\cap B\neq\emptyset$ for all $B\in\tau$ . We say $(X,\tau)$ is separable if there exists a countable, dense $A\subseteq X$ . Given some $A\subseteq X$ , a point $p\in A$ is an isolated point in $A$ if there exists $O\in\tau$ such that $p\in O$ and $O\cap A=\{p\}$ . I am wondering: If $X$ is separable and $A\subseteq X$ , then must the set of isolated points in $A$ be at most countable? Perhaps if we add the condition that it is Hausdorff it is true. My attempt: If $A$ has $0$ or $1$ isolated points, we are done. Otherwise, let $p_{1},p_{2}\in A$ be isolated points of $A$ . Then there exist $O_{1},O_{2}\in\tau$ such that $O_{1}\cap A=\{p_{1}\}$ and $O_{2}\cap A=\{p_{2}\}$ . Furthermore, because $(X,\tau)$ is Hausdorff, there exist $T_{1},T_{2}\in\tau$ such that $p_{1}\in T_{1},p_{2}\in T_{2}$ , and $T_{1}\cap T_{2}=\emptyset$ . Now, because open sets are closed under finite intersection, we have that $O_{1}\cap T_{1}$ and $O_{2}\cap T_{2}$ are open, disjoint sets which have intersection $\{p_{1}\}$ and $\{p_{2}\}$ with $A$ , respectively. My idea from here is to well order some countable dense subset and use the well-ordering to choose one element from each open set around each isolated point (without using choice because we can just choose the least element). But I have yet to show that there exists a collection of disjoint open sets, one for each isolated point. I am not sure how to continue. For example, the result is true in the reals for closed sets by Cantor-Bendixon (I think). However the proof I saw was nothing like this and the fact that I've not seen a more general statement for any set of reals seems like an indicator that it is not true. Is it true if I add more restrictions? Maybe a stronger separation axiom?",['general-topology']
3333418,Difference between strictly increasing and increasing functions,"What is the precise difference between strictly increasing and increasing functions??
I see these terms being thrown around a lot
My guess is that strictly increasing mean that derivative is only greater than 0 and in case of just increasing derivative can be greater than or equal or 0?",['derivatives']
3333423,Tensor product of group algebras,"Let $G,G_1$ and $G_2$ are three abelian groups with group homomorphisms $\phi_i:G\to G_i$ . This gives $k$ -algebra homomorphisms $k[\phi_i]:k[G]\to k[G_i]$ . So we can consider $k[G_i]'s$ as $k[G]$ -module via the homomorphisms $k[\phi_i]$ . We can consider the tensor product $k[G_1]\otimes_{k[G]}k[G_2]$ and this will be again $k$ -algebras. My question is there a simpler way to describe the $k$ -algebra: $k[G_1]\otimes_{k[G]}k[G_2]$ ? For example take $G=\{e\}$ , the identity group; then $k[G]=k$ and hence $$k[G_1]\otimes_{k[G]}k[G_2]=k[G_1]\otimes_kk[G_2]\cong k[G_1\times G_2].$$ So I was wondering if there exists any simpler way to express $k[G_1]\otimes_{k[G]}k[G_2]$ like above. Note that here the groups are abelian and hence the group algebras are commutative rings. Therefore the tensor product makes sense. Thank you in advance.","['group-rings', 'group-theory', 'abelian-groups', 'commutative-algebra']"
3333430,Is my analysis of the series $\sum_{n=1}^\infty{\frac{\ln n}{n}}$ correct?,"I came across the following series and I'm supposed to analyse whether it converges or not. $$\sum_{n=1}^\infty{\frac{\ln n}{n}}$$ My attempt: At first sight, the thought of using the integral test came to my mind as each term of the series would be non-negative. But as I proceeded, I noticed that the function $f(x)=\frac{\ln x}{x}$ is not a monotonic function on the domain $x \in [1, \infty), \, \forall x \in \mathbb{R}$ as: $$f'(x)=\frac{1-\ln x}{x^2}$$ Since $f'(x)<0, \, \forall \,x>e$ , therefore I started analysing $\sum_{n=3}^\infty\frac{\ln x}{x}$ for which $f(x)$ is monotonic and decreasing . I solved it as follows: $$\sum_{n=1}^\infty\frac{\ln x}{x}=\frac{\ln1}{1}+\frac{\ln2}{2}+\sum_{n=3}^\infty\frac{\ln x}{x}$$ For $\sum_{n=1}^\infty\frac{\ln x}{x}$ to converge, $\int_3^\infty{f(x)}dx$ must also converge which would eventually lead to the convergence of $\sum_{n=1}^\infty\frac{\ln x}{x}$ as the initial two terms of the series are constants. $$\int_3^\infty{f(x)}dx=\int_3^\infty\frac{\ln x}{x}dx=\int_3^\infty{\ln{x}\,d(\ln x)}=\infty$$ Since the integral of $f(x)$ diverges, therefore the corresponding sum must also diverge, this implies that the series $\sum_{n=1}^{\infty}\frac{\ln n}{n}$ must also diverge . I am unsure if my analysis is correct or not. It would be helpful if some person suggests a better method or points out some mistakes in my attempt, if any.","['calculus', 'convergence-divergence', 'sequences-and-series']"
3333453,"Clarification: If $R$ is a ring, then $R^n\cong R^m$ as left $R$-modules if and only if they are also isomorphic as right $R$-modules.","I was working out the details of the following problem as I was preparing for a qualifying exam: Problem: Let $R$ be a unital ring (not necessarily commutative). Prove that if the left free $R$ -modules, $R^n$ and $R^m$ are isomorphic for some positive integers $n$ and $m$ , then $R^n$ and $R^m$ are isomorphic as right $R$ -modules. This question has been asked before , but the answer is very short and doesn't work out the details. While working out the details, I've encountered some confusion. Since the answer given by Lord Shark the Unknown is short, I'll reproduce it here before asking about the pieces I've found myself confused about. Lord Shark the Unknown's answer: If $\phi:R^m\to R^n$ is a left $R$ -module isomorphism,
  and $\psi:R^n\to R^m$ is its inverse, then they correspond
  to matrices $A$ and $B$ over $R$ with $AB=I_m$ and $BA=I_n$ .
  But then $A$ and $B$ correspond to right $R$ -module maps $R^n\to R^m$ and $R^m\to R^n$ which are inverse to each other. My work: Minor comment, it appears that $\phi$ is intended to correspond to $A$ and $\psi$ to $B$ , so I would think that $AB$ should correspond to $\phi \circ \psi= 1_{R^n}$ . Thus I'll assume that $\phi$ should be $\phi:R^n\to R^m$ and $\psi:R^m\to R^n$ . It's quite possible that something weird happens with noncommutative rings, and this was correct as is, and I'm missing something. 
( Later comment : It's also possible Lord Shark the Unknown was working with the transposes of the matrices that I'm thinking of, in which case these dimensions make sense). Then let $e_1,\ldots,e_n$ be the standard basis for $R^n$ , $f_1,\ldots,f_m$ the standard basis for $R^m$ . 
Let $A=[\phi]$ be defined by $$\phi(e_j)=\sum_i A_{ij}f_i,$$ and $B=[\psi]$ be defined by $$\psi(f_i)=\sum_j B_{ji}e_j.$$ Ignoring that $\phi\circ \psi = 1_{R^m}$ , $C:=[\phi\circ \psi]$ should be the 
matrix such that $$\phi(\psi(f_i))=\sum_k C_{ki}f_k,\newcommand\of[1]{\left({#1}\right)}$$ but $$\phi(\psi(f_i)) = \phi\of{\sum_j B_{ji}e_j} = \sum_j B_{ji}\phi(e_j) 
=\sum_j B_{ji} \sum_k A_{kj}f_k =\sum_k \of{\sum_j B_{ji}A_{kj}}f_k.$$ Thus $C_{ki} =\sum_j B_{ji}A_{kj}$ . Hence $B^TA^T = C^T$ . Alternatively,
if we regard $A$ and $B$ as being matrices over $R^{\text{op}}$ , we get $AB=C$ ,
as claimed. Now over $R^{\text{op}}$ we get $AB=I_m$ , $BA=I_n$ , or over $R$ , we get $B^TA^T=I_m$ , and $A^TB^T=I_n$ . This suggests that we should use the 
transposes to define the maps for the right modules, since right linear maps won't reverse the order of multiplication. (If $\phi(v)=ws$ , $\psi(w)=ur$ , then $\psi(\phi(v))=\psi(ws)=\psi(w)s=urs$ ). Then if we define $$\tilde{\phi}(e_j) =\sum_i f_i B_{ji}\text{, and }
\tilde{\psi}(f_i) =\sum_j e_j A_{ij},$$ we can check that $$\tilde{\phi}(\tilde{\psi}(f_i)) 
= \tilde{\phi}\of{\sum_j e_j A_{ij} }
= \sum_j \tilde{\phi}(e_j) A_{ij}
= \sum_j \sum_k f_kB_{jk}A_{ij} 
= \sum_k f_k \delta_{ik}
= f_i,
$$ and similarly, we get $\tilde{\psi}(\tilde{\phi}(e_j))=e_j$ , so $\tilde{\phi}$ and $\tilde{\psi}$ are inverse isomorphisms. Questions: Is this the standard way to handle matrices over noncommutative rings? I.e., for left modules do we usually take the entries to lie in $R^{\text{op}}$ ? For right modules it appears that the entries lie in $R$ . Then taking transposes 
gives an isomorphism between $\newcommand\op{\text{op}}\newcommand\Mat{\mathrm{Mat}}\Mat_{n\times m}(R^{\text{op}})$ and $\Mat_{m\times n}(R)$ ? Is this correct, and is it the standard way to think about these things? If anyone could let me know if I've understood the intent of Lord Shark the Unknown's answer, or if I'm misunderstanding, that would be very helpful. It feels like there should be a more conceptual way of thinking about what's going on here, by translating the matrix argument into an argument about $\operatorname{Hom}$ functors/dualization. Something like the following: Let $\phi: R^n\to R^m$ and $\psi: R^m \to R^n$ be inverse isomorphisms.
Let $*$ denote the functor $\newcommand\Hom{\operatorname{Hom}}\Hom(-,R)$ .
Then $\psi^*:R^{n*}\to R^{m*}$ and $\phi^*:R^{m*}\to R^{n*}$ are inverse 
isomorphisms. $R^{n*}$ has a natural right $R$ -module structure so that $R^{n*}\simeq R^n$ as right $R$ -modules. The natural right $R$ -module structure should be simply right multiplication by
elements of $R$ . I.e., if $\alpha \in \Hom(R^n,R)$ , and $s\in R$ ,
then define $(\alpha s)(x) = \alpha(x)s$ . As for the natural isomorphism with $R^n$ , it should be given by $\alpha \mapsto (\alpha(e_i))_i$ . Right linearity follows from the definition of the right action of $R$ on $\Hom(R^n,R)$ , injectivity follows from the fact that the $e_i$ generate $R^n$ , and surjectivity follows from the existence of $f_j$ such that $f_j(e_i)=\delta_{ij}$ , since $R^n$ is free. Is this idea correct?","['free-modules', 'modules', 'ring-theory', 'abstract-algebra', 'noncommutative-algebra']"
3333538,Hotel Key Card Recognition,"Another problem from  BadCamp Puzzles: http://www-scf.usc.edu/~mearnest/puzzles_by_genre.php Here is the question: A hotel key card has two ways it can inserted it into the lock. However, it is so poorly labeled that as far you can tell, either way is equally likely to be the correct one. Even worse, the card reader is finicky, so even when you insert it on the correct side, the lock only opens with a known probability, p. Trying the current side takes one seconds, and flipping takes half a second. What strategy minimizes the expected time it will take to open the lock? Personally, I think I should change the side after inserting side A or B specific times in a row. And I got the probability than side A is correct given $k_1$ times failure of A and $k_2$ times failure of B: $$P(side\ A\ is\ right | A\ failed\ k_1\ times\ and B\ failed\ k_2\ times)=\frac{(1-p)^{k_1}}{(1-p)^{k_1}+(1-p)^{k_2}}$$ But here flipping will always take half a second. So I got the equations intuitively: $$\frac{(1-p)^{k_2}}{(1-p)^{k_1}+(1-p)^{k_2}}*\frac{1}{p}+0.5=\frac{(1-p)^{k_1}}{(1-p)^{k_1}+(1-p)^{k_2}}*\frac{1}{p}$$ LHS means expectation time it will take to open if we flip, RHS means that of keeping flipping. If LHS side less than RHS, then we should flip from side A to side B. V.V. But I am not sure if this is right. Any suggestion or idea will be appreciated. Thanks a lot!","['statistics', 'probability']"
3333539,How to prove the transitivity of relation which is symmetric difference,"Given a non-empty set A, and define a power set of A as $S=P(A)$ . Proving R={ $(A_1,A_2)\in S^2| (A_1\setminus A_2 )\cup (A_2\setminus A_1 ) $ is finite } is a equivalence relation. I know how to prove reflexive and symmetric, need more lights on transitivity. Following is my attempt, and I realised it is wrong. suppose $(A_i,A_j) \in R$ and $(A_j,A_k) \in R$ , $(A_i \cup A_j) \setminus (A_i \cap A_j) $ is finite and $(A_j \cup A_k) \setminus (A_j \cap A_k) $ is finite. Then $(A_i \cup A_j\cup A_j \cup A_k) \setminus (A_i \cap A_j \cap A_j \cap A_k) $ is finite. Obviously $(A_i \cup A_k) \leqslant (A_i \cup A_j\cup A_j \cup A_k)$ and $(A_i \cap A_k) \leqslant (A_i \cap A_j \cap A_j \cap A_k)$ .  Then I conclude the transitivity which is inappropriate. I should not ensure the bigger set minus smaller set $(A_i \cup A_j\cup A_j \cup A_k) \setminus (A_i \cap A_j \cap A_j \cap A_k) $ will be finite as well. My gut is looking for a specific way involving cardinal and inequality to prove the transitivity. Anyone enlighten me, please. ""Already known the finite set is the union of each finite set and combined with complement approach""",['elementary-set-theory']
3333545,How to solve the system of such differential equations?,"Let $x_i=x_i(t)$ be a functions and let consider the system of differential equations $\left \{
\begin{align} 
&{\frac { d}{{ d}t}}x_{{0}}  =3\,x_{{1}} ,\\
&{\frac { d}{{ d}t}}x_{{1}}  =0,\\
&{\frac { d}{{ d}t}}x_{{2}}  =
{\frac {2\,x_{{1}}  x_{{2}}  +x_{{3}}
  }{x_{{0}}  }},\\
&{\frac { d}{{ d}
t}}x_{{3}}  ={\frac {3\,x_{{1}}  x_{{3
}}  -6\, x_{{2}}   ^{2}
}{x_{{0}}  }}. 
\end{align} \right.
$ My attempt. By brute forse I have found the first integral $$
{\frac {4\,{x_{{2}}}^{3}+{x_{{3}}}^{2}}{x_0^{2}}}=C,
$$ but I cant find $x_i$ as functions of $t.$ Is it possible?","['systems-of-equations', 'ordinary-differential-equations']"
3333562,"How to transform $(r,s)$ tensor fields?","Let $\mathcal M$ and $\mathcal N$ be smooth manifolds and let $f : \mathcal M \rightarrow \mathcal N$ be a diffeomorphism. How can we transform general $(r,s)$ tensor fields, with mixed convariant and contravariant indices,
along that mapping? A covariant tensor $\phi \in T_{r}^{0}\mathcal M$ is a section of the tensor product $\bigotimes_{i=1}^{r} T\mathcal M$ of the tangent bundle. We have a well-defined pushforward along $f$ of such tensors. For example, a vector field $\phi \in T_{1}^{0}\mathcal M$ gets transformed to a vector field along $f(\mathcal M)$ . A contravariant tensor $\psi \in T_{0}^{s}\mathcal N$ is a section of the tensor product $\bigotimes_{i=1}^{s} T^{\ast}\mathcal N$ of the cotangent bundle. We have a well-defined pullback along $f$ of such tensors. For example, a differential $s$ -form $\phi \in T_{0}^{s}\mathcal N$ gets transformed to an $s$ -form over $\mathcal M$ . It is not clear how those definitions extend to mixed tensor fields with covariant and contravariant components.","['pullback', 'pushforward', 'tensors', 'differential-geometry']"
3333583,"If $S(m)=20$ and $S(33m)=120$, what is the value of $S(3m)$?","Let $S(n)$ denotes the sum of the digits of a positive integer $n$ in base $10$ .
 If $S(m)=20$ and $S(33m)=120$ , what is the value of $S(3m)$ ? I do not even have a start, so a start would be appreciated or even a solution would be okay.","['number-theory', 'number-systems']"
3333586,"Determine whether elements of a set are bounded above, below, or to the side of another in 3 or more directions","I'm having a difficult time expressing an algorithm mathematically. Assuming a 2D matrix of $x$ and $y$ elements, I have a set of pairs for elements that have been found and definitely exist ( $A$ ), and a set of pairs for elements that may or may not exist ( $B$ ). From $B$ , the elements exist if and only if elements of $A$ lie in 3 or more directions vertically or horizontally. These can be located at infinite depth up, down, left, or right, but not diagonally. Example In Python, the function determining an element's existence may be written as such: def: exists(x, y, depth):
    found = 0

    # search rightward
    for i in range(depth):
        if x + i < ROWS and elements[x + i][y].found:
            found += 1
            break

    # search leftward
    for i in range(depth):
        if x - i >= 0 and elements[x - i][y].found:
            found += 1
            break

    # search upward
    for i in range(depth):
        if y + i < COLUMNS and elements[x][y + i].found:
            found += 1
            break

    # search downward
    for i in range(depth):
        if y - i >= 0 and elements[x][y - i].found:
            found += 1
            break

    if found >= 3:
        return True My Attempt Let $A$ and $B$ be sets of ordered pairs of natural numbers. Define for any $n = (n_x, n_y) \in B:$ $$A\subseteq \mathbb{N} \times \mathbb{N}$$ $$B\subseteq \mathbb{N} \times \mathbb{N}$$ $$f(n) : n \text{ exists}~.$$ $$\forall n \in B: f(n) \Leftrightarrow ~...$$ I get stuck around this point and would really appreciate it if anyone could help me understand how to best translate this. Thank you,","['matrices', 'logic', 'elementary-set-theory']"
3333597,A nice Combinatorial Identity,"I am trying to show that $\forall N\in\mathbb{N}$ , $$\sum\limits_{n=0}^{N}\sum\limits_{k=0}^{N}\frac{\left(-1\right)^{n+k}}{n+k+1}{N\choose n}{N\choose k}{N+n\choose n}{N+k\choose k}=\frac{1}{2N+1}$$ It's backed by numerical verifications, but I can't come up with a proof. So far, I tried using the generating function of $\left(\frac{1}{2N+1}\right)_{N\in\mathbb{N}}$ , which is $\frac{\arctan\left(\sqrt{x}\right)}{\sqrt{x}}$ , by showing that the LHS has the same generating function, but this calculation doesn't seem to lead me anywhere... Any suggestion ? Edit: the comment of bof (below this question) actually leads to a very simple proof. Indeed, from bof's comment we have that the LHS is equal to $$\int_{0}^{1}\left(\sum\limits_{k=0}^{N}(-1)^k{N\choose k}{N+k\choose k}x^k\right)^2dx$$ And we recognize here the shifted Legendre Polynomials $\widetilde{P_N}(x)=\displaystyle\sum\limits_{k=0}^{N}(-1)^k{N\choose k}{N+k\choose k}x^k$ . And we know that the shifted Legendre Polynomials form a family of orthogonal polynomials with respect to the inner product $\langle f|g\rangle=\displaystyle\int_{0}^{1}f(x)g(x)dx$ , and that their squared norm with respect to this product is $\langle\widetilde{P_n}|\widetilde{P_n}\rangle=\frac{1}{2n+1}$ ; so this basically provides the desired result immediately.","['summation', 'combinatorics', 'real-analysis']"
3333607,Airplane seats probability [duplicate],"This question already has an answer here : Disease probability with Bayes' Rule and airplane seats probability (1 answer) Closed 2 years ago . A company has small airplanes that fit $8$ people. Results show that 1 out of $10$ passengers does not show up when buying a ticket. Thus the company sells tickets to the first $10$ people who buy. The probability of k tickets sold is: \begin{align*}
P(k=6) & = 0.3\\
P(k=7) & = 0.3\\
P(k=8) & = 0.2\\
P(k=9) & = 0.15\\
P(k=10) & = 0.05
\end{align*} What is the probability of more people showing up than there are available places? Attempt: $X =$ people who show up I'm looking for $P(X \geq 9)$ . So I believe that becomes $$P(X = 9|k=9)P(k=9) + P(X = 9|k=10)P(k=10) + P(X=10|k=10)P(k=10)$$ But I only know the $P(k=...)$ , right? How can I find the other terms? How do I take the $1$ out of $10$ into account for 9 people? Please help me out here, this exercise really troubles me.","['statistics', 'probability']"
3333613,For polynomial $f$ : $\forall z \in \mathbb{C} : |zf(z)| \leq |z|^k \implies |f(z)| \leq |z|^{k-1}$?,"Suppose $f : \mathbb{C} \to \mathbb{C}$ is a polynomial such that $\forall z \in \mathbb{C}: |zf(z)| \leq |z|^k$ . Does it follow that $ \forall z \in \mathbb{C}: |f(z)| \leq |z|^{k-1}$ ? My thoughts: Certainly this holds $\forall z \neq 0$ . For $z = 0 $ , I believe this should also be true by continuity of $f$ . So I would say the assertion is valid. However I am unsure. I would be grateful if someone could either verify this for me or point out where I am mistaken!","['complex-analysis', 'complex-numbers', 'polynomials', 'analysis']"
3333617,Trace of matrix $A^{\ast}A$,"Given a $n \times n$ matrix $A$ with complex entries. And $A^{\ast}$ represents the  conjugate transpose of $A$ .Then If $\left | tr{\left ( A^{\ast}A \right )}\right | <n^2$ , then $\left |a_{ij} \right| < 1$ for some $i,j$ If $A$ is invertible ,then $ tr{\left ( A^{\ast}A \right )}$ $\neq0$ Solution i tried- The Matrix $A^{\ast}A$ is a Hermitian matrix  so all  of its eigenvalues will be real. but further i am not getting what to do ,while thinking about this question some other questions are also coming to my mind, like is $A^{\ast}A$ is a positive definite?  how eigenvalues of $A$ is related to eigenvalues of $A^{\ast}A$ ?. please help Thankyou?","['matrices', 'trace', 'linear-algebra', 'matrix-norms']"
3333626,"Eliminating parameter $\beta$ from $x=\cos 3 \beta + \sin 3 \beta$, $y = \cos \beta - \sin \beta$","Based on the given parametric equations: $$\begin{align}
x &=\cos 3 \beta + \sin 3 \beta \\
y &= \cos \beta \phantom{3}- \sin \beta
\end{align}$$ Eliminate the parameter $\beta$ to prove that $x-3y+2y^3=0$ . What I got so far: $$\cos 3 \beta + \sin 3 \beta = ( \cos \beta - \sin \beta)(1+4\sin\beta\cos\beta)$$ Which trigonometric identity should I use to proceed?","['trigonometry', 'systems-of-equations']"
3333757,Improper Fourier transform,"The most common way to verify if the Fourier transform of a function $f$ is integrable $(\hat f\in L^1(\mathbb{R}))$ is by proving that the function $f$ is integrable and $f'$ , $f''$ are also differentiable. Now, I came across a weaker condition for the Fourier tranform to be improper integrable. The statement was as follows: If $f:\mathbb{R} \to \mathbb{C}$ is a differentiable, integrable function and even, i.e. $f(x)=f(-x)$ , then the Fourier transform $\hat{f}: \mathbb{R} \to \mathbb{C}$ will be an improper integral, i.e. $\hat{f}\chi_{[c,d]}$ is integrable for all $c<d$ and the limit $$\lim_{c \to -\infty}\lim_{d\to +\infty} \int_c^d \hat{f}$$ will exist. Furthemore, would there be a formula for this improper integral in terms of $f$ ? Can anyone provide me with a hint for this problem? I have no idea how to start?","['integration', 'improper-integrals', 'fourier-analysis', 'fourier-transform', 'indefinite-integrals']"
3333766,Solution to variational problem,"I am struggling to see how to get to the solution of the equation below. The problem equation and solution come from here (see eqn 3 and eqn4) . They state that this is a variational problem, $$
p^{*}(a | w)=\underset{p(a | w)}{\arg \max } \sum_{a} \left[ p(a | w) U(w, a)-\frac{1}{\beta}  p(a | w) \log \frac{p(a | w)}{p_{0}(a)} \right]
$$ given that $0<p(a | w)<1$ and $\sum_{a} p(a | w) =1$ The answer is: $$
p^{*}(a | w)=\frac{1}{Z(w)} p_{0}(a) e^{\beta U(w, a)}
$$ where $Z$ is the normalisation constant $$
Z(w)=\Sigma_{a} p_{0}(a) e^{\beta U(w, a)}
$$ Edit: Added the constraint that p lies between 0 and 1 (as it's a probability)","['optimization', 'multivariable-calculus', 'lagrange-multiplier', 'karush-kuhn-tucker']"
3333775,Convex Set- Intuition,"I acknowledge that ""Convex Set"" has no hollow between any two points in the set as shown in Wikipedia ( https://en.wikipedia.org/wiki/Convex_set ). But I guess this intuition is based only on the three dimensional space. What if more than four? How the hollow is defined? Thanks in advance!","['convex-analysis', 'geometry']"
3333804,Convergence of $ \begin{equation} \sum\limits_{n = 1}^\infty{\frac{{{{\left( {2 +\sin n} \right)}^n}}}{{{3^n} \cdot n}}} \end{equation}$,"Determine whether the following series is convergent or not, with explanation. $$
\begin{equation}
\sum\limits_{n = 1}^\infty  {\frac{{{{\left( {2 + \sin n} \right)}^n}}}{{{3^n} \cdot n}}} 
\end{equation}
$$ I guess the above series is disvergent, but I cannot prove it. I have the following  assumptions: The function $\sin n$ has least upper bound one for counting number $n$ . In each 'cycle', there will be a positive number $n_k$ which lets $\sin n_k \to 1$ . Then I just consider all positive numbers $n_k \left(k=1,2,\cdots\right)$ $$
\begin{equation}
\sum\limits_{{n_k}} {\frac{{{{\left( {2 + \sin n} \right)}^n}}}{{{3^n} \cdot n}}} \to \sum\limits_{{n_k}} {\frac{1}{n}},
\end{equation}
$$ it looks like a harmonic series. PS. I used MATLAB to find the maximum of $\sin n$ within a certain range. n=1:1e4;[m,index]=max(sin(n)); Then, I got $\rm{m}=1.0000$ and $\rm{index}=9929$ .","['sequences-and-series', 'real-analysis']"
3333812,Why doesn't the graph of $x^2-\cos x$ look wiggly?,"When I use Desmos to draw the graph of the function $f$ defined by $f(x):=x^2-\cos x$ , the graph looks very similar to a quadratic function. Unlike the graph of, say, $x-\cos x$ , it does not have any wiggles/waves. I would expect the $\cos x$ term in $f(x)$ to cause there to be some wiggles, but this appears not to be the case. Why is this? I assume it has something to do with $x^2$ growing much faster than $\cos x$ ever does. Or perhaps it's because $f$ is everywhere convex, so always keeps growing steeply upwards when $x$ is positive. I have also notices that the graphs of $x^2-\cos(kx)$ are wiggly for $k\ge3$ , but not for $k=1,2$ . Can anyone shed any more light on why $x^2-\cos x$ doesn't have any wiggles?","['curves', 'calculus', 'algebra-precalculus']"
3333829,Calculating $e^{ar}+e^{ar^2}+...+e^{ar^n}$,"Calculate the sum, $$e^{ar}+e^{ar^2}+...+e^{ar^n}\ \text{where} \ a,r\in \mathbb{R}$$ It's easy to calculate the sum when the powers of $e$ are in an arithmetic progression. How do we proceed when the powers are in geometric progression?",['algebra-precalculus']
3333937,"If we know $\mathbb{Z}_{n}/ \mathbb{Z}_{m} \cong \mathbb{Z}_{k}$, can we conclude that $\mathbb{Z}_{n} \cong \mathbb{Z}_{m} \times \mathbb{Z}_{k} $?","If we know $\mathbb{Z}_{n}/ \mathbb{Z}_{m} \cong \mathbb{Z}_{k}$ , can we conclude that $\mathbb{Z}_{n} \cong \mathbb{Z}_{m} \times \mathbb{Z}_{k} $ ? I think not, but I can not find right counterexample. Any hint helps!",['group-theory']
3333949,Combinatorics generating functions of a series,Hi I found that the generating function of a series $a_n$ is: $$\frac{(1-x)(1+2x)}{(1+3x)(1-3x)}$$ I need to find a formula for $a_n$ . I tried some things and found that the generating function is equal to: $$\frac{1}{3}\cdot (1+2x)\cdot( \frac{2}{1+3x} + \frac{1}{1-3x})$$ but I cant get any further than that.,"['combinatorics', 'discrete-mathematics', 'generating-functions']"
3333990,Multivariable function Integrable for what values?,"For what values of $\alpha,\beta \in \mathbb{R}$ will the function $$f:(0,1]\times(0,1] \to \mathbb{R}: (x,y) \mapsto x^\alpha y^\alpha (x+y)^\beta$$ be integrable? Normally, I don't have problems solving these integrals using Fubini's theorem and by a change of variables. However, I don't seem to find the right change of variables? Any hints? Thank you!","['integration', 'functions', 'lebesgue-integral', 'fubini-tonelli-theorems']"
3334015,Approximating sin. Why absolute error gets bigger?,"So I wanted to aproximate $\sin(0.234,375^\circ)$ to 5 decimal places.
But the thing is, I wanted to do it the old school way(not using some power series). 
Also, I wanted to do the calculation on sheet of paper using basic calculator - hence, while calculating I wanted to keep least accurate approximations necessary to obtain my final result. I knew that: $
\cos(30^\circ) = \frac{\sqrt 3}{2}\\
\sin(\frac{\alpha}{2})=\sqrt{\frac{1-\cos(\alpha)}{2}}\\
\cos(\frac{\alpha}{2})=\sqrt{\frac{1+\cos(\alpha)}{2}}\\
$ And since $0.234,375=\frac{30}{2^7}$ it was all about doing some iterations Since, I wanted to obtain result with 5 decimal places accuracy, I decided to start with 6 decimal approximation of $\frac{\sqrt{3}}{2}$ , and to approximate I'm gonna use classic rounding. Iterations: $
\cos(30^\circ) = \frac{\sqrt{3}}{2} \approx 0.866,025\\
\cos(15^\circ) = \cos(\frac{30^\circ}{2})=\sqrt{\frac{1+\cos(30)}{2}} = \sqrt{\frac{1+0.866,025}{2}} \approx 0.965,926\\
\cos(7.5^\circ) = \cos(\frac{15^\circ}{2})=\sqrt{\frac{1+\cos(15)}{2}} = \sqrt{\frac{1+0.965,926}{2}} \approx 0.991,445\\
\cos(3.75^\circ) = \cos(\frac{7.5^\circ}{2})=\sqrt{\frac{1+\cos(7.5)}{2}} = \sqrt{\frac{1+0.991,445}{2}} \approx 0.997,859\\
\cos(1.875^\circ) = \cos(\frac{3.75^\circ}{2})=\sqrt{\frac{1+\cos(3.75)}{2}} = \sqrt{\frac{1+0.997,859}{2}} \approx 0.999,465\\
\cos(0.9375^\circ) = \cos(\frac{1.875^\circ}{2})=\sqrt{\frac{1+\cos(1.875)}{2}} = \sqrt{\frac{1+0.999,465}{2}} \approx 0.999,866\\
\cos(0.46875^\circ) = \cos(\frac{0.9375^\circ}{2})=\sqrt{\frac{1+\cos(0.9375)}{2}} = \sqrt{\frac{1+0.999,866}{2}} \approx 0.999,966\\
$ and finally: $\sin(0.234,375^\circ) = \sin(\frac{0.46875^\circ}{2})=\sqrt{\frac{1-\cos(0.46875)}{2}} = \sqrt{\frac{1-0.999,966}{2}} \approx 0.004,123$ My result rounded to 5 decimal places $\approx 0.00412$ Google calculator's result rounded to 5 decimal places $\approx 0.00409$ So, I have several questions: Why the results differ? What's the least neccessary aprroximation accuracy I have to keep in calculations to obtain 5 digits accurate result and why so? If I decide, instead of using classic rounding, to round every number to floor(just truncate unnecessary digits), how does this affect final result. I may have other questions, which I don't know yet. I just want to understand what's going on. I'm kinda newbie. I would likely read some easy explained article or book about numerical methods of approximation. If you have something that would help me understand things, let me know. As I was thinking about approximation I concluded that digits arent that ""important"" for example: $0.75000$ is a good aprroximation of $0.74999$ even though already second digit is different. So, alternatively to 5 digits accuracy, I may be looking to have a aproximation such as: $\lvert v-v_{approx}\rvert < 0.00001$","['trigonometry', 'number-systems', 'approximation', 'numerical-methods']"
3334019,Calculate in how many different ways can rotated square,"We put a square $3 \text{ x } 3$ from $9$ square tiles in two types: or which can be freely rotated (we allow also symmetries). Calculate in how many different ways you can do that if we identify such systems that one goes to the other with some rotation or symmetry of big square. My solution: I am going to use polya counting theory https://en.wikipedia.org/wiki/P%C3%B3lya_enumeration_theorem $$\begin{array}{|c|c|c|c||c|c|}
\hline
&G \in G &  \text{How many}& \text{Id x }\\ \hline
a) &\text{id} & 1 & x_{1}^{9} \\ \hline
b) &\text{90 degree rotation} & 2 & x_1 \cdot x_4^{2} \\ \hline
c) &\text{180 degree rotation }  &  1 & x_1 \cdot x_2^{4}\\ \hline
d) &\text{ diagonal symmetry}  &  2 & x_{1}^{3} \cdot x_2^{3}\\ \hline
e) &\text{centres symmetry }  &  2 & x_1^3 \cdot x_2^{3}\\ \hline
\end{array}$$ We must include our tiles: a) Here freely, so we have $6$ types: $6^9$ b) For each $4$ -element cycle we choose whether the first will be: The rest for him is clearly designated: The middle one can't be adjusted to fit all $4$ rotations, so: $0$ c) Middle: and the rest of the cycles as in b): $2\cdot 6^4$ d) In the middle in $6$ ways, the rest as in b): $6^3 \cdot 6^3=6^6$ e) $6^6$ as in d) Solution: $$\frac{1}{8} \cdot (2\cdot 6^6 + 2\cdot 6^6 +2\cdot 6^4+0+6^9)$$ Is my solution correct?","['polya-counting-theory', 'combinatorics']"
3334022,"How many closed paths with the operations $+1$, $-1$, and $\times 2$?","Consider a finite sequence of $n$ integers denoted $x_1,x_2,...,x_n$ where $x_1=x_n=0$ and $x_{n+1}$ is either equal to $x_n+1$ , $x_n-1$ or $2x_n$ . Is there a good way to count how many such sequences there are, with either an exact or asymptotic formula? Phrased differently, if you start with the number $0$ and are allowed to add one to your number, subtract one from your number, or double your number $n$ times, how many ways can you end up back at $0$ ? Is there a good approximate/asymptotic formula for this in terms of $n$ ? I have no idea how to start solving this. It would be nice to find some sort of generating function, but I’m not sure how to set one up.","['markov-chains', 'combinatorics', 'asymptotics', 'sequences-and-series']"
3334035,"I need a little help with probability, specifically involving 3 or more people.","This is my question that I am trying to conquer: A, B, and C draws a card in that order from a well-shuffled pack of 52 cards. The first to draw a diamond wins ₽740. If 'A' starts, find their mean and the variance. Now frankly, my probability-assessing skills are pretty weak, so I am unable to figure out a solution to this. I thought it'll require a binomial distribution, only to notice that the information isn't enough. What method should I employ and why? I did try searching for questions of a similar kind but to no avail. I understand that when A draws, he draws with a probability of $\frac{13}{52}$ . Do B and C also draw with the same probability? Or am I even starting out incorrectly?","['conditional-probability', 'probability-distributions', 'probability-theory', 'probability']"
3334067,Which vectors are stretched the most in a transform?,I thought that it would be obvious that in a transform the eigenvectors are the ones that are stretched the most as those are the directions in which the matrix acts. But according to this short video and what others have said: https://youtube.com/watch?v=vs2sRvSzA3o that does not seem to be the case. I thought so beacuse repeated application of a transform on any vectors makes that vector converge to its largest eigenvalue vector. I'm having a hard time digesting that there are other vectors stretched more. Can someone explain me why it makes sense? Consider the classic case of a 2D sphere being deformed to an ellipse by a transform. How would I find the vectors then which would become the major and minor axis? [Please dont use SVD but solve more fundamentally through calculus or basic linear algebra],"['matrices', 'abstract-algebra', 'linear-algebra']"
3334121,topological space satisfying the first axiom of countability,"If a topological space $(X,\tau)$ satisfies the first axiom of countability, then for every $x\in X$ , there exists a countable local base $\{B_k\}$ at $x$ . However, I find in many proofs the local base will be further assumed to satisfy $B_{k+1}\subset B_k$ for every $k\in N$ . Why is this assumption correct? Thanks!",['general-topology']
3334124,Is my understanding of matrices correct?,"Let $V = R^2$ be our vector space with the unit base vectors $J(1, 0), K(0, 1)$ . We have the linear map, $$T: V \to V$$ We can rewrite $\forall v \in V$ as a linear combination of the unit base vectors (by their very definition) and utilize the linearity of our map: $$v = xJ + yK = \begin{bmatrix}x \\ y\end{bmatrix}$$ $$T(v) = T(xJ + yK) = xT(J) +yT(K)$$ What does this mean? This means that all linear transformations can be uniquely described by the transformed unit base vectors $T_J, T_K$ . So we can notate our map in the matrix form (some kind of vector consisting of column vectors), $$T = \begin{bmatrix}T_J\\T_K\end{bmatrix}$$ And we can define matrix-vector multiplication as the dot product of them: $$\begin{bmatrix}T_J\\T_K\end{bmatrix} \cdot \begin{bmatrix}x\\y\end{bmatrix} = xT_J + yT_K = T(v).$$ But if we directly notate the $T_J, T_K$ as vectors rather than hiding them behind letters, it would be more convenient to write our matrix in row form: $$T = \begin{bmatrix}T_J \space T_K\end{bmatrix} = \begin{bmatrix} \begin{bmatrix}X_0 \\ X_1\end{bmatrix} \begin{bmatrix}Y_0 \\ Y_1\end{bmatrix}\end{bmatrix} \Rightarrow \begin{bmatrix}X_0 & Y_0 \\ X_1 & Y_1\end{bmatrix}$$ Also this form is more useful for representing our linear transformation / matrix as a set of linear equations. Is my understanding correct?","['matrices', 'intuition', 'linear-algebra', 'linear-transformations']"
3334130,What is exactly relationship between scheme $X$ and its global sections in comparison to $C^\star$ algebra,"This is just random thought based upon Iitaka's Algebraic Geometry Thm 1.15 proof. Let $X$ be a scheme and denote $A(X)$ ring of global sections of $X$ associated to the scheme. In the proof of $Spec,A(-)$ adjunction(to see adjunction, use $Sch^{op}$ category instead), $Hom_{Sch}(X,Spec B)\cong Hom_{Ring}(B,A(X))$ , the book constructed an arrow $X\to Spec(A(X))$ which enjoys universal arrow property. In other words, given $X\to Spec(B)$ , the map $X\to Spec(B)$ factors through $X\to Spec(A(X))\to Spec(B)$ . Recall Gelfand transform.(in accordance to Lang's Real and Functional Analysis book.) Let $A$ be a commutative Banach algebra. Let $M$ be the set of maximal ideals of $A$ . Now we have $A\to C(M,C)$ map where $M$ is really in bijection to characters of $A$ . So in effectives $A\to C(\hat{A},C)$ where $\hat{A}$ is the set of characters and this map is given by evaluation. $\textbf{Q:}$ It is clear that $A(X)$ is functions globally defined over $X$ . Both construction maps starting space into a function space. What is exactly analogy between them?(i.e. $X\to Spec(A(X))$ and $A\to C(\hat{A},C)$ ) Note that $X\to Spec(A(X))$ is an injection for topological space and for sheaves, there is no guarantee to be injection whereas $A\to C(\hat{A},C)$ is just a map which may not be bijection unless $A$ is commutative unital Banach algebra.","['c-star-algebras', 'analysis', 'algebraic-geometry', 'abstract-algebra', 'functional-analysis']"
3334155,Questions about different formulations of the Taylor expansion terms,"I'm reading Numerical Optimization from Nocedal/Wright, and was playing around the matrix notation of the Taylor expansion, regarding which I would have two questions. We have a 3-times differentiable function $f\,:\,\mathbb{R}^n\rightarrow \mathbb{R}$ , for which the Taylor expansion around the point $a$ , up to the quadratic term, is the following: where $x,\,\,a,\,\,p\,\in\,\mathbb{R}^n$ , and $p$ is the distance between $a$ and $x$ . ( $x = a + p$ ) $$
f\left( x \right) =f\left( a+p \right) \approx f\left( a \right) +\nabla f\left( a \right) ^Tp+\frac{1}{2}p^T\nabla ^2f\left( a \right) p
$$ My first question is: Can the quadratic term be expressed the following way? $$
\frac{1}{2}p^T\nabla ^2f\left( a \right) p\,\,\overset{?}{=}\,\,\frac{1}{2}\nabla \left( \nabla f\left( a \right) ^Tp \right) ^Tp
$$ (I tried to prove it with mapping matrix indices with each other, but always got lost somewhere.) My second question stands only if the answer to the first is yes. Is it possible to write the third-order term in this manner? $$
\frac{1}{6}\nabla \left( p^T\nabla ^2f\left( a \right) p \right) ^Tp
$$ I know that these forms would be of little practical use, I'm just asking out of curiosity. EDIT: I've made some calculations, and it worked out in the case I tried, but I still can't prove it: $$
f\left( a \right) =2a_{1}^{3}a_{2}^{4}+a_{1}^{2}
$$ $$
a=\left[ \begin{array}{c}
	a_1\\
	a_2\\
\end{array} \right] =\left[ \begin{array}{c}
	1\\
	2\\
\end{array} \right] \,\,\,\,\,\,\,\,\,\,\,\,p=\left[ \begin{array}{c}
	p_1\\
	p_2\\
\end{array} \right] =\left[ \begin{array}{c}
	2\\
	3\\
\end{array} \right] 
$$ $$
\nabla f\left( a \right) =\left[ \begin{array}{c}
	6a_{1}^{2}a_{2}^{4}+2a_1\\
	8a_{1}^{3}a_{2}^{3}\\
\end{array} \right] 
$$ $$
\nabla ^2f\left( a \right) =\left[ \begin{matrix}
	12a_1a_{2}^{4}+2&		24a_{1}^{2}a_{2}^{3}\\
	24a_{1}^{2}a_{2}^{3}&		24a_{1}^{3}a_{2}^{2}\\
\end{matrix} \right] 
$$ $$
p^T\nabla ^2f\left( a \right) p=\left[ \begin{matrix}
	2&		3\\
\end{matrix} \right] \left[ \begin{matrix}
	194&		192\\
	192&		96\\
\end{matrix} \right] \left[ \begin{array}{c}
	2\\
	3\\
\end{array} \right] =3944
$$ $$
\nabla \left( \nabla f\left( a \right) ^Tp \right) ^Tp=\nabla \left( \left[ \begin{matrix}
	6a_{1}^{2}a_{2}^{4}+2a_1&		8a_{1}^{3}a_{2}^{3}\\
\end{matrix} \right] \left[ \begin{array}{c}
	p_1\\
	p_2\\
\end{array} \right] \right) ^Tp=
\\
=\nabla \left( 6a_{1}^{2}a_{2}^{4}p_1+2a_1p_1+8a_{1}^{3}a_{2}^{3}p_2 \right) ^Tp=
\\
=\left[ \begin{array}{c}
	12a_1a_{2}^{4}p_1+2p_1+24a_{1}^{2}a_{2}^{3}p_2\\
	24a_{1}^{2}a_{2}^{3}p_1+24a_{1}^{3}a_{2}^{2}p_2\\
\end{array} \right] ^T\left[ \begin{array}{c}
	p_1\\
	p_2\\
\end{array} \right] =
\\
=\left[ \begin{matrix}
	964&		672\\
\end{matrix} \right] \left[ \begin{array}{c}
	2\\
	3\\
\end{array} \right] =1928+2016=3944
$$","['optimization', 'multivariable-calculus', 'linear-algebra']"
3334158,Find the formula for the convolution of the sequences (generating functions),"Find the formula for the convolution of the sequences: $a_n=\begin {cases} 1 & 0\leq n \leq 4 \\  0 &  n \geq 5  \end{cases} $ $b_n = 1$ $\forall n \in \mathbb{N}$ What I've been doing: In other words: $a_n = 1,1,1,1,1,0,0,...$ and $b_n=1,1,1,1,...$ So that means that their generating functions are: $a(x)=1+x+x^2+x^3+x^4=\sum _{i=0} ^{4} x^i$ $b(x)=1+x+x^2+x^3+...=\sum _{j=0} ^{\infty} x^i$ So using the convolution formula i.e: $b(x)a(x)=\sum _{j=0} ^{\infty}(\sum _{i=0} ^{4}a_ib_{j-i})x^4=\sum _{j=0} ^{\infty}(\sum _{i=0} ^{4}x^i(x^{i-j}))x^4=\sum _{j=0} ^{\infty}(\sum _{i=0} ^{4}x^{2i-j})x^4$ And I can't get past that nor do I know if what I did was correct... Can someone guide me?","['generating-functions', 'convolution', 'discrete-mathematics', 'sequences-and-series']"
3334202,"Why is $[0,1]\times [0,1] \cup [2,3]\times [2,3]$ not a product set","In proving that the product of two $\sigma-$ algebras, say $\mathcal{A}$ and $\mathcal{B}$ , is not necessarily a $\sigma-$ algebra, i.e. $\mathcal{A}\times \mathcal{B}$ is not a $\sigma-$ algebra. And we prove this by getting to a statement of the form: $[0,1]\times [0,1] \cup [2,3]\times [2,3]\notin \mathcal{A}\times \mathcal{B}$ Why is it so clear that the union of the product sets cannot lie in the product of the $\sigma-$ algebras? Is it because if $[0,1]\times [0,1] \cup [2,3]\times [2,3]\in \mathcal{A}\times \mathcal{B}$ , then by definition of the product $(0,2)\in[0,1]\times [0,1] \cup [2,3]\times [2,3]$ which obviously is not true? Or am I using the wrong reason?","['elementary-set-theory', 'general-topology', 'measure-theory']"
3334205,$\operatorname{rank} A = \operatorname{rank} A^2$ if and only if $\lim_{\lambda \to 0} (A+\lambda I)^{-1}A$ exists,"Let $A \in \mathbb C^{n \times n}$ . Prove that $\operatorname{rank} A = \operatorname{rank} A^2$ if and only if $\displaystyle\lim_{\lambda \to 0} (A+\lambda I)^{-1}A$ exists. I am stuck on this problem, I don't understand what the limit is supposed to mean. I would guess that if the limit exists, it should be $I$ since the invertible matrices are dense. But how can I relate this to the rank?","['matrix-rank', 'matrices', 'matrix-calculus', 'linear-algebra', 'limits']"
3334228,Gambler coin problem: fair coin and two-headed coin,"The following problem was posed to me: A gambler has in his pocket a fair coin and a two-headed coin. He selects one of the coins at random, i.e. the probability that the fair coin is selected is 0.5. When the gambler flips the chosen coin, it shows heads. (A) What is the probability that it is the fair coin? (B) Suppose that he flips the same coin a second time and again it shows heads. Now what is the probability that it is the fair coin? (C) Suppose that he flips the same coin a third time and it shows tails. Now what is the probability that it is the fair coin? I am concerned with (C). The following solution was provided: Let $F$ be the event that the coin is fair, $F^c$ is the complement of $F$ . Let also $H$ be the event that it shows a head. $$P(F|HHH) = \dfrac{P(HHH|F)P(F)}{P(HHH)} = \dfrac{P(HHH|F)P(F)}{P(HHH|F)P(F) + P(HHH|F^c)P(F^c)} = \dfrac{1/2 \cdot 1/2 \cdot 1/2 \cdot 1/2}{9/6} = 1/9$$ But isn't this a solution to the problem of probability that it is the fair coin when flipping the coin a third time and it showing heads ? Shouldn't we instead be calculating $P(F|HHT)$ ? But if we should be calculating $P(F|HHT)$ , since only one of the coins (the fair coin) has a tails side, wouldn't $P(F|HHT)$ (the probability that the coin is fair instead of the two-headed coin) equal to $1$ ? In that case, we wouldn't even need to calculate anything. I would greatly appreciate it if people could please take the time to clarify this.","['bayes-theorem', 'probability']"
3334240,Qual problem on the intersection of two surfaces,"This is a qual problem that has been giving me some difficulty: Let $$
 \begin{align*}
     f(x, y, z) &= x^2 + y^4 + z^6 - 3 \\
     g(x, y, z) &= x + y + z,
 \end{align*}
 $$ and $S = \{(x, y, z) \in \mathbb{R}^3\ \mid f(\vec{x}) = g(\vec{x}) = 0\}$ .
  Show that for every $\vec{v} \in S$ there exists a neighborhood $U$ of $\vec{v}$ such that: There exists a differentiable, injective map $\gamma \colon (-\epsilon, \epsilon) \to U$ . $\gamma'$ does not vanish on $(-\epsilon, \epsilon)$ . The image of $\gamma$ is $U \cap S$ . This seems like a good problem for the implicit function theorem. I am fairly certain that the problem is solved if the Jacobian matrix $$
J =
\begin{bmatrix}
   2x & 4y^3 & 6z^5 \\
    1 &  1   & 1
\end{bmatrix}
$$ has rank $2$ for all points in $S$ . (In this case, we could choose two variables to solve in terms of the remaining third with the implicit function theorem.) However, the rank of $J$ does not seem easy to compute in $S$ (or anywhere else). The rank of $J$ is $2$ precisely if a solution $(x, y, z) \in S$ cannot satisfy $2x = 4y^3 = 6z^5$ . For this to work, we would want the equations \begin{align*}
    2x = 4y^3 &= 6z^5 \\
    x^2 + y^4 + z^6 &= 3 \\
    x + y + z &= 0
\end{align*} to have no solutions. Eliminating a variable with $x + y + z = 0$ doesn't seem immensely helpful. For example, substituting $z = -x - y$ gives $x^2 + y^4 + (x + y)^6 = 3$ , which doesn't have any obviously nice properties. Is there a better way to solve this question? If not, how should I proceed with the implicit function theorem?","['multivariable-calculus', 'real-analysis']"
3334268,Quasifinite morphisms to a field are finite (Vakil),"With or without using Chevalley's theorem, show that if $X\to \text{Spec }k$ is a quasifinite morphism (according to Vakil, this means finite type morphism + finite fibers), then the morphism is actually finite. This question was asked before (in FOAG exercise 7.4.D. ), but I don't quite understand the solution: First, even if solve the case where $X$ is affine, how do we show that the claim holds in general for any scheme $X$ ? Moreover, the accepted solution suggests that $X=\text{Spec }A$ is integral (""consider the generic point of $X$ ""), that the morphism $\text{Spec }A \to\text{Spec }k[x]$ induced by the inclusion $k[x]\subset A$ is dominant, and that the condition on finite fibers implies that the generic point of $X$ is constructible, but none of these are particularly clear to me. Do we need some sort of requirement that the fiber is discrete (this would make, for instance, the last claim easy to verify)?","['algebraic-geometry', 'schemes']"
3334288,Application of the Collatz conjecture,"I'm very curious about the Collatz conjecture, also known as the $3n+1$ problem, mainly due to its rather simple formulation and beautiful visualizations. After all, Erdős himself said that ""mathematics may not be ready for such problems"", so there's a certain mystery about it that I find quite alluring. I would like to present the conjecture to high school students, since I believe such type of problems are illustrative of how simple ideas yield complex, yet amazing, mathematics, and that may kindle the love for maths and number theory in particular. However, I'd like to do so in an informal manner, if possible via a real life application of the Collatz conjecture, but so far I haven't been able to find or come up with any interesting examples that could potentially captivate a not so mathematically trained audience. Any ideas?","['education', 'number-theory', 'collatz-conjecture', 'elementary-number-theory']"
3334331,"Quant Trading interview probability question, what's wrong with my reasoning?","I roll a die up to three times. You can decide to stop and choose the number on the die (where the number is your payoff) during each roll. What's your strategy? I am confused about the strategy for the first roll. My reasoning is this: the chance of getting a 5 or 6 from rolls 2 and 3 is: $$1 - 4/6*4/6=1-4/9=5/9$$ So, you have a greater than $50\%$ chance to get a 5 or a 6 on either the 2nd or 3rd dice. Thus, you'd want to select the first dice only when it rolls a 6. However, this answer is incorrect. The solution says the Expected value during the first roll is \$4.25, which I can understand how they computed, and thus the strategy would be to settle with either a 5 or 6 on the first roll, but I can't figure out my logical fallacy.","['finance', 'probability']"
3334343,"Calculus for the Practical Man: Chapter 4, Problem 10 (Solve problem without trigonometry possible?)","My issue is that I am trying to avoid trigonometry as a means to solve this problem, because he goes into the calculus of trigonometric functions in the subsequent chapter, and, therefore, I think he intends the problem to be solved without trigonometry. Two automobiles are moving along straight level roads which cross at an angle of sixty degrees, one approaching the crossing at 25 miles an hour and the other leaving it at 30 miles an hour on the same side. How fast are they approaching or separating form each other at the moment when each is ten miles from the crossing. How do I relate the quantities given that I cannot use trigonometry and the right triangle relation $x^2 + y^2 = h^2$ ?""","['related-rates', 'calculus', 'derivatives']"
3334346,"Calculus for the Practical Man: Chapter 4, Problem 17 (Answer's differs from that of the book)","A tank is in the form of a cone with the point downward, and the height and diameter are each 10 feet. How fast is the water pouring in at the moment when it is 5 feet deep and the surface is rising at the rate of 4 feet per minute? The volume of a cone is $$V_c = \frac{1}{12} \pi D^2 H.$$ Given that the diameter of the cone is equal to its height, the volume of the cone may be written $$V_c = \frac{1}{12} \pi H^3.$$ So, $$\frac{dV}{dt} = \frac{1}{4} \pi H^2 \frac{dH}{dt} = \frac{1}{4} \pi (5)^2\times 4 = 25 \pi \textrm{ ft^3/min}$$ So, my answer: $25 \pi \textrm{ ft^3/min}.$ The book's answer: $\frac{25 \pi}{12} \textrm{ ft^3/min}.$","['related-rates', 'calculus', 'derivatives']"
3334376,"How to compare $\pi, e\cdot 2^{1/3}, \frac{1+\sqrt{2}}{\sqrt{3}-1}$","This is in the GRE exam where we are supposed to answer fast so I think there might be some trick behind this to allow us to do that. But so far the best I can do is to write $\frac{1+\sqrt{2}}{\sqrt{3}-1}=\frac{1+\sqrt{6}+\sqrt{2}+\sqrt{3}}{2}$ and compute the nominator with the value of square root 2 and 3 memorized. And as to $e\cdot 2^{1/3}$ , I just don't see how to compare it to other two items without take cubic and compute. This whole process is very time consuming. I have seen some tricks to compare say $2^\pi,\pi^2$ . But the technique does not seem to apply here.","['approximation', 'calculus', 'algebra-precalculus']"
3334389,Determining convergence of divergence with justification: $\sum\limits_{n=1}^\infty\left(\sqrt[n]{n}-1\right)$ [duplicate],This question already has answers here : Convergence of $\sum_{n=1}^\infty{\left(\sqrt[n]{n}-1\right)}$ (3 answers) Closed 4 years ago . So I was asked to determine and justify the convergence or divergence of $$\sum_{n=1}^\infty\left(\sqrt[n]{n}-1\right)$$ and I think it diverges and was trying to use the Comparison Test by finding a function less than it that diverges but I am not sure what the function would be... Thanks in advance for any help!,"['limits', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
3334391,"If every object in math can be reduced to sets, how are tuples explained via sets?",It seems to me that tuples are just as elementary as sets. Can tuples be reduced to sets?,['elementary-set-theory']
3334398,Is MLE of multinominal distribution almost surely convergence?,"I know MLE converges in probability to its parameters. However, I am not sure if MLE of multinominal distribution has stronger convergence, i.e., almost surely convergence.","['statistics', 'convergence-divergence', 'probability']"
3334411,Does $A\geq (\mathrm{tr}(A^{-1}))^{-1}I$ hold for symmetric positive-definite matrix $A$?,"Somewhere in my reading, it seems that the following inequality holds for  every symmetric positive definite matrix $A$ , $$A\geq \big(\mathrm{tr}(A^{-1})\big)^{-1}I,$$ where $I$ is the identity matrix. Is this true? Thank you!","['trace', 'matrices', 'symmetric-matrices', 'inequality', 'positive-definite']"
3334424,probability of infinite union of events,"Let $(U_i)_{i\in\mathbb N}$ be iid with $U_1\sim U[0,1]$ . Calculate $P(\,\bigcup_{i=1}^\infty \{U_i\in [0,x]\}\,)$ where $x\in (0,1]$ . I tried to apply $$P(\,\bigcup_{i=1}^\infty \{U_i\in [0,x]\}\,)=1-P(\,\bigcap_{i=1}^\infty \{U_i\notin [0,x]\}\,)=1-\prod_{i=1}^\infty P(U_i\notin [0,x])=1-\prod_{i=1}^\infty (1-x)=1$$ Right?","['probability-theory', 'probability']"
3334445,How many different ways to connect two triangles exist?,"Let's say you have two triangles with of side's lengths $a, b, c$ and $x, y, z$ respectively, such that all lengths  are different. Two triangles are connected if they have one common vertex and two sides lie on one straight line. Question How many different ways to connect two triangles exist? Edit. My answer is 54 . Let $A$ , $B$ , $C$ and $A_1$ , $B_1$ , $C_1$ be the vertex name of triangles $\Delta ABC$ and $\Delta A_1B_1C_1$ respectively. One can fix the first triangle $\Delta ABC$ and connect vertices $A$ and $A_1$ such that sides $AC$ and $A_1C_1$ will lie on one straight line. 
One put the second triangle in three ways: a) outside, b) inside, c) near: In three cases above one can rotate $3$ times the second triangle $\Delta A_1B_1C_1$ while the vertex $A$ is fixed. The triangle $\Delta ABC$ has the two vertices on each side, therefore, one can connect two triangles on one side by $3 \times 2$ ways. The fixed triangle has three sides, therefore, one can connect two triangles by $3 \times 2 \times 3 =18$ ways. One can have three cases above, finally, $18 \times 3 =54$ ways. Edit 2. After the @SheridanGrant's answer I added the case (d). 
And I thinking about the case (f). Should the case (f) give additional ways to the solution? Triangles have the same height.",['combinatorics']
3334464,How large can the entries of the matrix representation of an element of a number field be?,"Let $K$ be a finite extension of $\mathbb{Q}$ . For each $\alpha \in K$ , multiplication by $\alpha$ is a linear map from $K$ to $K$ . Fix an integral basis $\omega_1,\ldots,\omega_n$ for $K$ over $\mathbb{Q}$ . Let $M_{\alpha}$ be matrix for the ""multiplication by $\alpha$ "" map with respect to the given basis. If $\alpha = \sum_{i=1}^{n} a_i \omega_i$ , set $$\| \alpha \|_{1} = \max_{1 \leq i \leq n} \| a_i \|$$ and set $$
\| \alpha \|_{2} = \max_{1 \leq i,j \leq n} \| (M_{\alpha})_{ij} \|
$$ where $(M_{\alpha})_{ij}$ is the entry in the $i$ -th row and $j$ -th column of $M_{\alpha}$ . Both $\| \cdot \|_1$ and $\| \cdot \|_2$ are norms on $K$ , which is finite-dimensional, thus the norms are equivalent in the sense that there are constants $c,C > 0$ such that $$
c \|\alpha \|_1 \leq \| \alpha \|_2 \leq C \|\alpha \|_1
$$ for all $\alpha \in K$ . Update Since $K$ is over $\mathbb{Q}$ (as opposed to $\mathbb{R}$ or $\mathbb{C}$ ), it is not necessarily true that all norms on $K$ must be equivalent. So that gives a preliminary question: Are the two norms equivalent? Update 2 : I posted an answer that resolves the question in the first update. In summary, the norms are equivalent because they are equivalent when extended to the vector space given by the formal span $\text{span}_{\mathbb{R}}(\omega_1,\ldots,\omega_n)$ . The questions below still stand. Question How do the constants depend on $K$ ? Do they depend only on the degree $n$ of $K$ , if so how? For a given degree $n$ , can we always find a $K$ so that $c$ and $C$ are as small and large, respectively, as we desire? Side Question Is there any good reference for properties of matrix representations of algebraic numbers? Every book I've seen hardly goes beyond saying that the determinant of $M_{\alpha}$ is the norm of $\alpha$ .","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
3334470,"Is there a ""geometric reason"" for why the gradient of $f(x,y)=\frac{x}{\sqrt{x^2+y^2}}$ is tangent to the unit circle?","Consider $f(x,y)=\frac{x}{\sqrt{x^2+y^2}}$ defined on the unit $2$ -dimensional disk without the origin. A direct computation shows that $\nabla f(x,y)\perp (x,y)$ , so $\nabla f(x,y)$ is tangent to the circle of radius $\sqrt{{x^2+y^2}}$ at the point $(x,y)$ . Is this fact ""obvious"", when looking with the right glasses? I wonder it there is a way to ""see this"" with as little computation as possible. One intuition I do have is that taking an ""infinitesimal step"" on the circle keeps the denominator $\sqrt{{x^2+y^2}}$ constant while increasing the numerator. However, this does not seem to me a rigorous explanation, since it is not clear on advance why the maximal increase is obtained at this situation (there might be a better trade-off increasing the numerator and the denominator simultaneously). Is there a simple (rigorous) explanation? Here are two different explanations I have (I still wish for a justification which will make it seem more ""obvious""): The first is to use the formula for the gradient in polar coordinates. Since $f$ depends only on $\theta$ , the result follows. Edit: I now think that the fact $f$ depends only on $\theta$ provides sufficient intuition for the result, even without knowing the formula for the gradient. The point is that, since $f$ depends only on $\theta$ , it would be ""inefficient"" to change the radius as well; the best we can do is to choose the right angular direction-i.e. increasing or decreasing $\theta$ . The second is to recall that the gradient of $f$ at $(x_0,y_0)$ is normal to the level set of $f$ through $(x_0,y_0)$ , i.e. normal to $\{ (x,y) \, | \, f(x,y) =f(x_0,y_0) \}$ at $(x_0,y_0)$ . Geometrically, this level set corresponds to $\cos 
 \theta=\text{const}$ in polar coordinates, which is equivalent  (locally around $(x_0,y_0)$ ) to $\theta=\text{const}$ , i.e. the level set is just a ray passing through the origin, and it is visually clear that its tangent line at a point $(x_0,y_0)$ is itself- $\text{span}((x_0,y_0))$ .","['riemannian-geometry', 'alternative-proof', 'multivariable-calculus', 'soft-question', 'differential-geometry']"
3334483,Fermat-like polynomials are irreducible,"I am attempting to prove the following result. Let $K$ be a field, $n \ge 3$ , and $e_1,\ldots, e_n$ be positive integers which are not multiples of the characteristic. Then the polynomial $$
p(x) = \sum_{i=1}^n x_i^{e_i}
$$ is irreducible in $K[x_1,\ldots, x_n]$ . I am attempting to expand the outline given in this answer into a proof. My attempt to do so is below. Proof by induction. For the base case, $n = 3$ , we claim that irreducibility of $x^l + y^m + z^n$ in $k[x,y,z]$ is equivalent to irreducibility in $k(z)[x,y]$ . Since the coefficients of our polynomial are all $1$ , this follows from Gauss' Lemma; in particular, both are equivalent to irreducibility in $k(y,z)[x]$ . So we view our polynomial as $x^l + (y^m + z^n)$ in $k(z)[y][x]$ and want to satisfy Eisenstein's criterion. In particular, we can check by the derivative test that $a_0 \equiv (y^m + z^n)$ in $k(z)[y]$ is separable, since it is of the form $y^m + c$ for $c\neq 0$ and the characteristic does not divide $m$ . Since $a_0$ is separable, its prime factors in $k(z)[y]$ are all distinct. Let $\mathfrak{p}$ be the prime ideal generated by one of these prime factors. The conditions of Eisenstein are satisfied, so our polynomial is irreducible in $k(z)[y][x]$ and in $k[x,y,z]$ . Now for the inductive step, also by Eisenstein. We write $$
   p(x) = x_n^{e_n} + (x_1^{e_1} + \cdots + x_{n-1}^{e_{n-1}}) \in k[x_1, \ldots, x_{n-1}][x_n].
$$ Since by the inductive hypothesis the constant term is irreducible, it generates a prime ideal $(x_1^{e_1} + \cdots + x_{n-1}^{e_{n-1}})$ in the polynomial ring. We need to check that $$
    x_1^{e_1} + \cdots + x_{n-1}^{e_{n-1}} \not\in \langle x_1^{e_1} + \cdots + x_{n-1}^{e_{n-1}}\rangle^2 = \langle(x_1^{e_1} + \cdots + x_{n-1}^{e_{n-1}})^2\rangle.
$$ (Hagen von Eitzen) If it were, then setting $x_2,\ldots, x_{n-1}$ all to zero gives $$
   x_1^{e_1} = x_1^{2e_1} f(x_1)
$$ for some $f \in k[x_1]$ , which is absurd. Hence the inductive step holds by Eisenstein. (Edit: Answered by Hagen von Eitzen) This last fact seems like it should be true, at least in characteristic not 2, but I don't see how to prove it. Or do I need another technique to do the inductive step? This proof does not use the full strength of the assumptions, as far as I can see. I have so far only needed one of the $e_i$ to not be multiples of the characteristic. Am I making a mistake in the base case, or is the statement true that generally?","['field-theory', 'abstract-algebra', 'irreducible-polynomials', 'polynomials']"
3334488,"Calculus for the Practical Man: Chapter 4, Problem 16","A rope 28 feet long is attached to a block on level ground and runs over a pulley 12 feet above the ground. The rope is stretched taut and the free end is drawn directly away from the block and pulley at the rate of 13 ft. per sec. How fast will the block be moving when it is 5 feet away from the point directly below the pulley? My solution: I start with relating the three sides of the triangle, holding one side constant at 12 feet. My aim is to find the rate of movement of the rope, that is, the rate of change of the hypotenuse, h , which determines, and is therefore identical to, the rate of change of the position of the box. $$h^2 = x^2 + y^2$$ $$h = \sqrt{x^2 + 144},$$ and since the rate of movement of the rope dictates the rate of movement of the box, $$\frac{dh}{dt} = \frac{x}{\sqrt{x^2 + 144}} \cdot \frac{dx}{dt}$$ Given that $h = 28 - 5 = 23$ feet when the box is 5 feet from the pulley, and that $$ x = \sqrt{h^2 - y^2} = \sqrt{23^2 - 12^2} = \sqrt{385},$$ it follows that $$\frac{dh}{dt} = \frac{\sqrt{385}}{\sqrt{385 + 144}} \cdot 13 \approx 11.1 \textrm{ ft/s}.$$ The book's answer is $8 \textrm{ ft^2/s}.$ Did I do something wrong? My answer is so close to the book's.","['related-rates', 'calculus', 'derivatives']"
3334502,Conditions to exploit Polar coordinates in limits.,"Evaluate, $$\lim_{(x,y)\rightarrow(0,0)}f(x,y)=\lim_{(x,y)\rightarrow(0,0)}\dfrac{2x^2y}{x^4+y^2}$$ When I used polar coordinates with $x=r\cos\theta, y=r\sin\theta$ , $$\lim_{r\rightarrow0}\dfrac{r\cos\theta\sin2\theta}{r^2\cos^4\theta+\sin^2\theta}=0$$ But when I use path $y=x^2$ , $$\lim_{(x,y)\rightarrow(0,0)}\dfrac{2x^4}{2x^4}=1$$ Also from path $x=0$ or $y=0$ both gives, $$\lim_{(x,y)\rightarrow(0,0)}\dfrac{2x^2y}{x^4+y^2}=0$$ From path knowledge, I can say Limit does not exist. Why this occurred that I got two different values of limits from Polar and the path makes me put a question that when to employ polar coordinates method to compute limits? When can I ascertain that it gives the correct value? Why is it giving out the value $0$ even when limit DNE? Please help!","['limits', 'multivariable-calculus', 'polar-coordinates']"
3334525,Introduction to Rashee numbers,"Definition : A Rashee number is an integer that can form a palindrome through the iterative process of repeatedly reversing its digits and subtracting  the resulting numbers. To check if the number $3226$ is a Rashee number or not: $3226 \to (3226-6223) = -2997 \to (-2997+7992)=4995 \to (4995-5994)=-999$ So yes, $3226$ is a Rashee number. 1) give one example of non-Rashee number in base- $10$ ? 2) show that there are infinitely many Rashee numbers in base- $10$ ? 3) show that there are infinitely many non-Rashee numbers in base- $10$ ? Does the idea of this Rashee number already exist? Is it as hard as proving Lychrel number ?","['number-theory', 'palindrome', 'combinatorics', 'elementary-number-theory']"
3334539,Convergence of series of normally distributed random variables [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question $X_1, X_2,...$ are independent and each $X_n$ has normal distribution $N(0,a^n)$ for $a>0$ .
I need to find probability that the series $$\sum_{n=1}^\infty X_n$$ converges.
How do I approach this problem?","['probability-limit-theorems', 'probability-theory', 'normal-distribution']"
3334576,Bounds on the Christoffel symbols in normal coordinates,"Given a smooth closed Riemannian manifold $(M,g)$ with injectivity radius $i_M$ I can choose for every $x \in M$ an orthonormal basis of $T_x M$ and a normal coordinate system $ \phi$ in $x$ , such that the Christoffel symbols satisfy $$
(\Gamma^k_{ij})_x(0)=0.
$$ By differentiability we have for $p \in B_{i_M}(0)$ $$
|(\Gamma^k_{ij})_x(p)| \leq |p| \sup_{p \in B_{i_M}(0)} |D(\Gamma^k_{ij})(p)|
$$ How can I bound $\sup_{p \in B_{i_M}(0)}|D(\Gamma^k_{ij})(p)|$ in terms of the curvature tensor $R$ of $(M,g)$ ?
I found that the Christoffel symbols satisfy $$
\Gamma^k_{ij,l} = -\frac{1}{3} ( R^k_{jkl} + R^k_{kjl}).
$$ Does this imply that $$
\sup_{p \in B_{i_M}(0)} |D(\Gamma^k_{ij})(p)| \leq \sup_{p \in B_{i_M}(0)} \sup_{ijkl}  R^k_{jkl}(\phi^{-1}(p)).
$$",['differential-geometry']
