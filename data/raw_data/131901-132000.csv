question_id,title,body,tags
2064969,Evaluation of the following definite integral,"$$
\int_{-\infty}^\infty \frac{\sin\left(\sqrt{2-\sqrt{2}+\frac{k^2}{\sqrt{2}}}\,\,\right)}{\sqrt{2-\sqrt{2}+\frac{k^2}{\sqrt{2}}}} \cos(k) \,dk
$$ I arrived at this form of the integral while evaluating the causal propagator corresponding to a second order linear partial differential equation in position and time that resembles the Klein-Gordon equation of relativistic quantum mechanics in form. I'm having difficulty in solving this integral. I tried to do this using integration by parts and I may have to use the concept of branch points (which I'm not quite familiar with). A guidance on how to go about evaluating this further would be appreciated.","['quantum-mechanics', 'complex-analysis', 'definite-integrals']"
2064970,Evaluating a trigonometric integral.,"Show That $$\int_{0}^{\pi}\ln (\sin x) \cos(2nx) \, dx = -\dfrac{\pi}{2n}$$ I tried to use substitutions and taylor series of $\ln (\sin x)$ , but to no avail. Any help will be appreciated. Thanks.","['real-analysis', 'integration', 'trigonometry', 'definite-integrals']"
2064973,"If $N = \underbrace{8\ldots8}_{100 \text{ times} }$, what is the remainder when $N$ is divided by $625$?","If $N = \underbrace{8\ldots8}_{100 \text{ times} }$, what is the remainder when $N$ is divided by $625$ ? Is there a method or a particular approach for solving such questions ?","['permutations', 'combinatorics', 'discrete-mathematics']"
2064983,Solve non-linear differential equation with boundary conditions,"Consider this problem with a differential equation and border conditions. I have to find a differentiable function $f:[0,1]\rightarrow \mathbb{R}$ such that it will satisfy the following conditions: $$f(0)=a,f(1)=b,\ddot f=\dfrac{\dot f^2-c^2f^4}{f}$$
with $a,b,c\in \mathbb{R}$ given. Differential equations are really not my field and I really don't know how to find this function $f$ (in particular how to solve this differential equation), so I hope someone will point me out a way to proceed. As I said in the comments this problem arises from riemannian geometry: these are the conditions that a component of a geodesic must satisfy. I've tried to solve the differential equation imposing $v:=\dot f$. In this way I get $$\dfrac{\partial v}{\partial f}v=\dfrac{v^2-c^2f^4}{f}$$
but this isn't an ordinary separable differential equation and unfortunately I don't know how to proceed. Thank you. EDIT: user zwim found a solution $f=\frac{k}{c\cdot ch(kx+\phi)}$ which checks out. My question now is: how can I be sure that there aren't other solutions? If there are other solutions, which are they?","['ordinary-differential-equations', 'analysis', 'partial-differential-equations']"
2065004,Cosine function curve,Is this curve called cosine curve? Because I have a reference that says it is. I googled the cosine curve and found something different.,['trigonometry']
2065007,How do ring homomorphism R → ℤ correspond to prime ideals of R?,"In ""Category Theory"" (Oxford Logic Guides, 2010 by Steve Awodey), pg 35, Awodey makes an off-hand comment: ""Ring homomorphisms A → ℤ into the initial ring ℤ ... correspond to so-called prime ideals, which are the ring-theoretic generalizations of ultrafilters."" I can find other sources that claim this to be true, that ""clearly"" prime ideals of a ring correspond to its homomorphisms into ℤ. I understand both of these concepts individually and I'm trying to construct a proof connecting them using the homomorphism law alone, but I'm getting stuck. How do you get from ""homomorphism into ℤ"" to ""prime ideal""?","['ring-homomorphism', 'abstract-algebra', 'maximal-and-prime-ideals', 'ring-theory', 'category-theory']"
2065015,"If $a(n)=n^2+1$ then $\gcd(a_n,2^{d(a_n)})=1\text{ or }2$?","Let $n\in\mathbf{N}$. I write $a_n=n^2+1$ and let $d(a_n)$ count the number of divisors of $a_n$. Set $$\Phi_n=\gcd\left(a_n,2^{d\left(a_n\right)}\right)$$ I would like to show and I believe it to be true that $$\Phi_n =
\begin{cases}
1,  & \text{if $n$ is even} \\[2ex]
2, & \text{if $n$ is odd}
\end{cases}$$ My gut instinct is two beak it down by parity and then use Euclid's lemma. But I am not sure how to use Euclid's lemma. To see a working example consider $n=15$. Then $a_n=226$, $d(a_n)=4$ and $$\text{ }\Phi_n=\gcd(226,2^{4})=\gcd(226,16)=2$$","['algebra-precalculus', 'divisor-counting-function', 'gcd-and-lcm', 'elementary-number-theory']"
2065066,Formal notation of the sum of the first $n$ squares,"I've found the following summation to be true
$$\sum_{i=1}^3 i^2 = 3+(3+2)+(3+2+1)$$ 
and it works for the first $n$ numbers, I also know that there is already a summation for that: $\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$ but that's not what I'm looking to use, my question is how would I appropiately write that first summation, could it be the following? 
$$\sum_{i=1}^n i^2 = n+\big(n+(n-1)\big)+\big(n+(n−1)+(n−2)\big)+\dots$$
I think that looks kind of ugly. How would I write the previous summation with a correct notation?","['summation', 'sequences-and-series']"
2065067,"Solving two-dimensional recurrence relation $a_{i,\ j}\ =\ a_{i,\ j-1}\ +\ a_{i-1,\ j-1}$","How to approach the following two dimensional recurrence relation ? For $i,j\ge2$,
  $$a_{i,\ j}\ =\ a_{i,\ j-1}\ +\ a_{i-1,\ j-1}$$
  where $a_{p,\ 1}=1$ (for $p\ge1$) and $a_{1,\ q} = 1$ (for $q\ge1)$.","['recurrence-relations', 'sequences-and-series']"
2065082,The set of all real square roots of a real matrix cannot be countably infinite,Let $A \in End(\mathbb R^n)$ be any endomorphism. Prove that the set of solutions of equation $B^2 = A$ is finite or uncountable. Any help would be much appreciated.,"['matrices', 'abstract-algebra', 'linear-algebra']"
2065131,Defining a principal square root in the complex space : Wolfram case,"In Wikipedia( https://en.wikipedia.org/wiki/Square_root ), we define the square root as In mathematics, a square root of a number $a$ is a number y such that $y^2 = a$ ; in other words, a number $y$ whose square (the result of multiplying the number by itself, or $y × y$ ) is $a$ .[1] Every non-negative real number a has a unique non-negative square root, called the principal square root , which is denoted by $\sqrt{a}$ , where $\sqrt{}$ is called the radical sign or radix. For positive $a$ , the principal square root can also be written in exponent notation, as $a^{1/2}$ . If one would like to construct the concept of square root in $\mathbb{C}$ , we would just use Wikipedia definition with $a\in \mathbb{C}$ .
Since $P_a(x)=x^2-a$ is a polynomial of degree $2$ , it has two roots in $\mathbb{C}$ . How do we choose the principal square root ? Obviously, there is no solution !
However , when one goes to Wolfram , and type solve x^2=1+i Right away, and without any warning, it returns two solutions in terms of a square root of a complex number. Even worse, when one types solve sqrt(x)=1+i we get a solution : $2i$ How would one define the principal square root? For the sake of simplicity, we ignore $0$ . Let $\Phi_{\alpha} : \mathbb{C^*}\rightarrow]0,\infty[×]\alpha,\alpha+2\pi]$ denote a bijection from the Cartesian to Polar coordinates, with $]\alpha,\alpha+2\pi]$ supplied with the $2\pi$ -equivalence, and $\alpha \in \mathbb{R}$ We can say that $\forall z\in \mathbb{C^*} \exists!(\rho,\theta) \in]0,\infty[×]\alpha,\alpha+2\pi]$ such as $z=\rho(cos(\theta)+isin(\theta))$ or $z=\rho e^{i\theta}$ One natural definition would be to define the principal square root of $z$ as $\sqrt{z}=\sqrt{\rho}e^{i\frac{\theta}{2}}$ , however, because we introduced $\theta$ , the $\sqrt{}$ function depends on the defintion of $\Phi_{\alpha}$ . Indeed , if we pick $\alpha=0$ , $\sqrt{(\mathbb{C^*})}=\mathbb{C^*}\backslash\{\mathbb{R_{+}^*}\cup \{z \in \mathbb{C} | \Im(z)<0\}$ . This $\alpha$ is not appropriate as it violates what we build for the principal square root in $\mathbb{R}$ An interesting choice would be $\alpha=-\pi$ , indeed, the square root image will be in $\{z \in\mathbb{C*}| Re(z)\geq0\}$ It seems to be what Wolfram adopted... Now, this is where it gets messy for me : if we look back at the defintion of $\Phi_{\alpha}$ , nothing prevents us to define it as $\Phi_{\alpha} : \mathbb{C^*}\rightarrow]0,\infty[×[\alpha,\alpha+2\pi[$ , where we change the bracket of the interval. This change has a significant impact ! If we pick again $\alpha=-\pi$ ,
the equation $\sqrt{z}=i$ used to have a solution, but not anymore when changing the brackets. Similarly, Wolfram return ""no solution exists"" if we type solve sqrt(x)=-i I am trying to get a natural and intuitive definition of the square root in $\mathbb{C}$ : Wolfram seems to accept one ,  I would agree that the best bijection would be the one with $\alpha=-\pi$ , but I am not sure about the order of the brackets : why did Wolfram choose to reject $\{z \in \mathbb{C} | \Re(z)=0, \Im(z)<0\}$ ? Thanks.","['complex-analysis', 'real-analysis', 'complex-numbers', 'analysis']"
2065148,$\sin{x}\cdot\sin{2x}\cdot\sin{3x}=\frac{\sin{4x}}{4}$ - solving a trigonometric equation,"The question is to solve the following equation: $$ \sin{x}\cdot\sin{2x}\cdot\sin{3x}=\frac{\sin{4x}}{4} $$ There is a tedious and mistake-prone way to do this, that is using trigonometric identities to write the equation in terms of $\sin{x}$ exclusively. But what I'm concerned about, is if there's another , perhaps somewhat clever way to deal with such problems?",['trigonometry']
2065171,$\sin{x}+\sin{2x}+\sin{3x}=1+\cos{x}+\cos{2x}$ - solving a trigonometric equation,I'm looking for hints regarding such equation: $$ \sin{x}+\sin{2x}+\sin{3x}=1+\cos{x}+\cos{2x} $$ I'd be particularly interested in any clever method for dealing with such problem.,['trigonometry']
2065192,Connection between SVD and Discrete Fourier Transform for Denoising,"Denoising signals (in particular, 2D arrays, such as images) can be done by removing the high frequency components of the discrete Fourier transform (which is related to convolution with a Gaussian kernel) or by removing the smallest singular values.
I was wondering if there is a known, specific mathematical connection between  these two approaches. I've seen a little discussion on the topic here and here , but I didn't really glean much specifically except the mention of circulant matrices .","['fourier-analysis', 'matrices', 'signal-processing', 'matrix-decomposition', 'fourier-transform']"
2065254,Limits tricky problem,"Let $f: \mathbb{R} \to \mathbb{R}$ be a function that is twice differentiable. We know that:
$$\lim_{x\to-\infty}\ f(x) = 1$$ $$\lim_{x\to\infty}\ f(x) = 0$$ $$f(0) = \pi$$ We have to prove that there exist at least two points of the function in which $f''(x) = 0$. How could we do it in a rigorous way? It is pretty intuitive, but in a rigorous way it isn't that simple for me...","['calculus', 'limits']"
2065266,A question regarding the uniqueness of exponential distribution,"""It turns out that not only is the exponential distribution memoryless, but it is also the unique distribution possessing this property."" - Sheldon Ross, author of ""A First Course in Probability (eighth edition)"". The proof presented in the book isn't particularly rigorous (nor is it ment to be) so with some help from the the response of Michael Hardy in Uniqueness of memoryless property I believe I managed to arrive to the correct conclusion but I am uncertain and thus I seek some clarification regarding my result. Ultimately the problem boils down to solving the equation $f(s+t)=f(s)f(t)$ where $f$ is non-negative (since it's a cumulative distribution function) and is evaluated at real non-negative values. I believe I managed to show that only decaying exponential functions of the type $\alpha^{-\lambda x}$, $\lambda>0$ could serve as solutions to the problem but Sheldon Ross claims that $e^{-\lambda x}$ is the only unique solution. This leads to me believe that perhaps I have done something wrong. Is he correct or incorrect? I apologize for not providing you with the proof I came up with, I am bit too lazy to write it down. Edit: Book pdf , page $211$ if anyone is interested, perhaps I did not mention something important that might be in there.","['probability-theory', 'probability-distributions', 'probability', 'exponential-distribution', 'ordinary-differential-equations']"
2065284,Is this an ODE?,"A friend and I are discussing whether this is an ODE: $$y'(x)+y(-x)=e^x$$ My friend claims it is not because of the $-x$. IMHO, the differential equation can be written as $F(x,y,y')=0$ with: $$F=y' +  y\circ (-\mathrm{Id}) -\exp$$ and is an ODE, hence. Could you please confirm?","['terminology', 'ordinary-differential-equations', 'definition']"
2065291,Integral $ \int_{0}^{\infty} \ln x\left[\ln \left( \frac{x+1}{2} \right) - \frac{1}{x+1} - \psi \left( \frac{x+1}{2} \right) \right] \mathrm{d}x $,"Prove That : $$ \int_{0}^{\infty} \ln x\left[\ln \left( \dfrac{x+1}{2} \right) - \dfrac{1}{x+1} - \psi \left( \dfrac{x+1}{2} \right) \right] \mathrm{d}x = \dfrac{\ln^2 2}{2}+\ln2\cdot\ln\pi-1 $$ where $\psi(z)$ denotes the Digamma Function . This integral arose from my attempt to find an alternate solution to Problem 5 , i.e, $$ {\large\int}_0^\infty\frac{\ln\left(x^2+1\right)\,\arctan x}{e^{\pi x}-1}dx=\frac{\ln^22}2+\ln2\cdot\ln\pi-1 $$ Here's my try : We have the identity, $$ \displaystyle \int_0^\infty \frac{\ln y}{(y+a)^2 + b^2}\,\mathrm{d}y \; = \; \tfrac{1}{2b}\,\tan^{-1}\tfrac{b}{a}\,\ln(a^2+b^2) $$ Since substituting $y \mapsto \dfrac{a^2+b^2}{y}$ gives, $$\displaystyle \int_0^\infty \frac{\ln y}{(y+a)^2+b^2} \, \mathrm{d}y =\ln(a^2+b^2)\int_0^\infty \frac{dy}{y^2+2ay+a^2+b^2} - \int_0^\infty \frac{\ln y}{(y+a)^2+b^2} \, \mathrm{d}y $$ $$ \implies \displaystyle \int_0^\infty \frac{\ln y}{(y+a)^2 + b^2}\,\mathrm{d}y \; = \; \tfrac{1}{2b}\,\tan^{-1}\tfrac{b}{a}\,\ln(a^2+b^2)  $$ Putting $a=1$ and $b=x$, we have, $ \displaystyle \int_0^\infty \frac{2x \ln y}{(y+1)^2 + x^2}\,\mathrm{d}y \; = \; \,\,\ln(1+x^2) \ \tan^{-1}x \tag{1} $ Now, we have to prove, $$\displaystyle {\large\int}_0^\infty\frac{\ln\left(x^2+1\right)\,\tan^{-1}x}{e^{\pi x}-1} \mathrm{d}x=\frac{\ln^22}2+\ln2\cdot\ln\pi-1$$ Let, $$\displaystyle \text{I} = {\large\int}_0^\infty\frac{\ln\left(x^2+1\right)\,\tan^{-1}x}{e^{\pi x}-1} \mathrm{d}x $$ $$\displaystyle = \int_{0}^{\infty} \int_{0}^{\infty} \frac{2x \ln y}{[(y+1)^2 + x^2][e^{\pi x} - 1]} \mathrm{d}x \ \mathrm{d}y \quad (\text{From 1}) \tag{2}$$ The inner integral is of the form, $$ \displaystyle \text{J} = \int_{0}^{\infty} \dfrac{x}{(x^2+a^2)(e^{\pi x} - 1)}  \ \mathrm{d}x \ ; \ a = (y+1)$$ I have proved here that, $\displaystyle \int_{0}^{\infty} \dfrac{\log(1-e^{-2a\pi x})}{1+x^2} \mathrm{d}x = \pi \left[\dfrac{1}{2} \log (2a\pi ) + a(\log a - 1) - \log(\Gamma(a+1)) \right] \tag{3}$ Differentiating both sides w.r.t. $a$, substituting $ a \mapsto \frac{a}{2} $ and $ x \mapsto \frac{x}{a} $, we get, $\displaystyle \int_{0}^{\infty} \dfrac{x}{(x^2+a^2)(e^{\pi x} - 1)}  \ \mathrm{d}x = \dfrac{1}{2} \left[ \dfrac{1}{a} + \ln \left( \dfrac{a}{2} \right) - \psi \left( \dfrac{a}{2} + 1 \right) \right] \tag{4}$ Putting $(4)$ in $(2)$, we have, $$ \displaystyle \text{I} = \int_{0}^{\infty} \left[ \dfrac{\ln y}{y+1} + \ln y \ln \left( \dfrac{y+1}{2} \right) - \ln y \ \psi \left( \dfrac{y+1}{2} + 1 \right) \right]  \mathrm{d}y $$ $ = \displaystyle \int_{0}^{\infty} \ln x\left[\ln \left( \dfrac{x+1}{2} \right) - \dfrac{1}{x+1} - \psi \left( \dfrac{x+1}{2} \right) \right] \mathrm{d}x \tag{*}$ Since the original question has already been proved in the link, so $(*)$ must be equal to the stated closed form. It also matches numerically. I'm looking for  some method to evaluate $(*)$ independent of Problem 5. Any help will be greatly appreciated.","['special-functions', 'real-analysis', 'improper-integrals', 'definite-integrals']"
2065304,Is a cone in Banach space always a closed subset?,"Let $(\mathbb{X}, || \cdot||)$ be a real Banach space. We define a subset $P$ of $\mathbb{X}$ by $P := \{ x \in \mathbb{X} : x\geq 0\}$. In general, $P$ is termed a positive cone of $\mathbb{X}$. However, $\mathbb{X}$ is quite abstract and could be any real Banach space, so that I am wondering that whether $P$ always be a closed subset of $\mathbb{X}$ (as primitive)? If so, how to show that? In fact, there are many different definitions in textbooks for "" cone "". One is defined as ""A subset $C$ of $\mathbb{X}$ is called a cone iff (i) $C$ is nonempty and nontrival ($C \neq \{0\}$); (ii) $C$ is closed and convex; (iii) $\lambda C \subset C$ for any nonnegative real number $\lambda$; (iv) $C \cap (-C) = \{ 0\}$."" On the other hand, other textbook defines it as "" A subset $C$ of $\mathbb{X}$ is called a cone iff (iii) and (iv) are satisfied."" Therefore, it makes me confused about whether a positive cone $P := \{ x \in \mathbb{X} : x\geq 0\}$ is always a closed subset. I thought a positive cone $P$ is always closed. Because by the construction of $P$, for any convergent sequence $\{x_n \} \subset P$ such that $ x_n \rightarrow x \in \mathbb{X}$ (i.e., $||x_n - x|| \rightarrow 0$ as $n \rightarrow \infty$), we have $x_n \geq 0$ for all $n$. And, it is clear intuitively that the limit $x$ of this sequence should also be nonnegative. But how to prove it rigorously? Thanks for helping in advance!","['general-topology', 'real-analysis', 'functional-analysis', 'functional-equations']"
2065317,Find arc length of implicit function,"Result of integrating I've been trying to find the arc length of the following function: $e^y=\frac{e^x+1}{e^x-1}$ from $x = a$ to $x = b$. 
I've tried designating $y$, but it doesn't seem to work. I would really appreciate your help","['derivatives', 'integration', 'calculus', 'functions']"
2065325,"Compute the weights of a $(\mathbb C^*)^{m+1}$-action on $H^0(\mathbb P^m, \mathcal O_{\mathbb P^m}(1))$","Let $\mathbb T:=(\mathbb C^{*})^{m+1}$ be the complex torus and suppose $\mathbb T$ acts on $\mathbb C^{m+1}$ diagonally as follows $$ (t_0, \cdots, t_m) : (x_0, \cdots, x_m) \mapsto (t_0x_0, \cdots, t_mx_m)$$ This action can induces a natural $\mathbb T$-action on $\mathcal O_{\mathbb P^m}(1)$ and also on $X:=H^0(\mathbb P^m, \mathcal O_{\mathbb P^m}(1))$, so the vector space $X$ becomes a $\mathbb T$-representation. Question How to compute the weights of this $\mathbb T$-action explicitly? I will appreciate it if you can provide details. (PS:Someone told me that the weights are related to some Chern classes. Is this true? )","['complex-geometry', 'algebraic-geometry', 'characteristic-classes', 'group-actions', 'representation-theory']"
2065360,Do we have $\lim_{h\to 0^+}\int_0^\infty|f(t+h)-f(t)|dt=0$?,"Let $f:\mathbb{R^+}\to\mathbb{R}$ be an integrable function ($f\in L^1(\mathbb{R}^+,\mathbb{R})$). Do we have
$$\lim_{h\to 0^+}\int_0^\infty|f(t+h)-f(t)|dt=0$$
? How can we prove it ?","['lp-spaces', 'real-analysis', 'integration', 'limits']"
2065373,Find the last Digit of $237^{1002}$?,"I looked at alot of examples online and alot of videos on how to find the last digit  But the thing with their videos/examples was that the base wasn't a huge number. What I mean by that is you can actually do the calculations in your head. But let's say we are dealing with a $3$ digit base Number... then how would I find the last digit. Q: $237^{1002}$ EDIT: UNIVERSITY LEVEL QUESTION. It would be more appreciated if you can help answer in different ways. Since the Last digit is 7 --> $7^1 = 7$ $7^2 = 49 = 9$ $7^3 = 343 = 3$ $7^4 = 2401 = 1$ $.......$ $........$ $7^9 = 40353607 = 7$ $7^{10} = 282475249 = 9$ Notice the Pattern of the last digit. $7,9,3,1,7,9,3,1...$The last digit repeats in pattern that is 4 digits long. Remainder is 1 --> 7 Remainder is 2 --> 9 Remainder is 3 --> 3 Remainder is 0 --> 1 So, $237/4 = 59$ with the remainder of $1$ which refers to $7$. So the last digit has to be $7$.","['discrete-mathematics', 'exponentiation', 'decimal-expansion', 'elementary-number-theory']"
2065392,Why doesn't this property work on the following composite function?,"Given $f(x),g(x)$ find $(f \circ g)(x)$. $$f(x) = x + \frac 1x \\g(x) = \frac{x+1}{x+2}\\(fog)(x) = \frac{x+1}{x+2}+\frac{1}{\frac{x+1}{x+2}} = \frac{x+1}{x+2}+\frac{x+2}{x+1}$$ Using the property $\frac{a}{b}+\frac{c}{d}=\frac{ad+bc}{bd}$ I now get: $$\frac{(x+1)^2+(x+2)^2}{(x+2)(x+1)} =(x+1)(x+2)$$ But that is incorrect. The correct answer is: $$\frac{2x^2+6x+5}{(x+2)(x+1)}$$ I understand how this was reached, but I'd like to know what was wrong with the application of that property? Thank you for your help.","['algebra-precalculus', 'function-and-relation-composition', 'functions', 'rational-functions']"
2065413,What exponent law have I violated?,"Given the expression: $b^8(2b)^4$, simplify it. I multiply $b^8$ and $2b$, which gives $(2b^9)^4.$ $(2b^9)^4 = 16b^{36}$. However this is incorrect. The correct answer is to distribute the exponent first like so:
$b^8(2^4b^4) = 16b^{12}$. This makes sense, but I'd like to know why my original approach was incorrect.","['algebra-precalculus', 'exponentiation']"
2065419,How do you find the derivative of $\sqrt{x^2+9}$ using the definition of a derivative?,"I had this question on a not-so-recent math test. It asked to find the derivative of $\sqrt{x^2+9}$ with the definition of a derivative. Using the chain rule, I can figure out that the derivative is $\frac x{\sqrt{x^2+9}}$, but how can it be done with only the definition of a derivative? I tried multiplying both sides of the fraction by the square roots, but that just makes a mess of everything.","['derivatives', 'calculus']"
2065430,What is a non decreasing function of several variables?,"I came across the undefined terminology nondecreasing function in an appendix about ""useful remarks on probability"" in a textbook, ""Social and Economic Networks"" by Matthew Jackson. Precisely, it is for functions from ${\mathbb R}^n$ into $\mathbb R$ and the subsection was about ""domination of distributions"". Here is an example of statement using nondecreasing functions : Consider two probability distribution $\mu$ and $\nu$ on ${\mathbb R}^n$. We say that $\mu$ dominates $\nu$ if $$E_\mu[f] \geqslant E_\nu[f]$$ for every mondecreasing function $f:{\mathbb R}^n\to{\mathbb R}$. (with - I guess - $E_\mu[f]=\sum_{d\in{\mathbb R}^n}f(d)\mu(d)$) What is the usual definition of nondecreasing function $f:{\mathbb R}^n\to{\mathbb R}$ in the context of probability/random graphs?","['probability', 'monotone-functions', 'functions']"
2065449,Using Divergence theorem to calculate flux,"Let $W$ be the region bounded by the cylinder $x^2+y^2=4$ , the plane $z=x+1$ , and the $xy$ -plane. Use the Divergence Theorem to compute the flux of $F = \langle z,x,y+z^2 \rangle$ through the boundary of $W$ . So far I've gotten to the point of computing div $(F)$ and integrating from $0$ to $x+1$ to obtain $$\iint_{D}(x+1)^2 dA.$$ My problem is finding the bounds of the domain which is the circle of radius $2$ centered at the origin. I understand I must use polar coordinates but since the circle is cut off by the line $x=-1$ I'm having trouble figuring out what the bounds for the radius should be. I think $\theta$ goes from $2\pi/3$ to $4\pi/3$ (somewhat guessing the bound for theta when the radius is cut off by the line $x = -1$ )","['multivariable-calculus', 'integration', 'divergence-operator']"
2065463,Are injective continuous functions on open sets open? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $U$ be an open subset of $\mathbb{R}^n$ , is there a continuous injective function $f$ from $U$ to $\mathbb{R}^n$ whose image is not open?","['multivariable-calculus', 'general-topology', 'vector-analysis']"
2065465,What is the number of integer solutions of $2{x_{1}}+2{x_{2}}+{x_{3}}+{x_{4}}={12}$?,"What is the number of non negative integer solutions of $2{x_{1}}+2{x_{2}}+{x_{3}}+{x_{4}}={12}$ ? I tried it as : ${x_{3}}+{x_{4}}={12} - 2{x_{1}}-2{x_{2}}$ Now, finding the solutions of ${x_{1}}+{x_{2}}$ ${x_{1}}+{x_{2}} = 0 => 1$ Solution ${x_{1}}+{x_{2}} = 1 => 2$ Solutions ${x_{1}}+{x_{2}} = 2 => 3$ Solutions ${x_{1}}+{x_{2}} = 3 => 4$ Solutions ${x_{1}}+{x_{2}} = 4 => 5$ Solutions ${x_{1}}+{x_{2}} = 5 => 6$ Solutions ${x_{1}}+{x_{2}} = 6 => 7$ Solutions And, now respectively finding for ${x_{3}}+{x_{4}}$ ${x_{3}}+{x_{4}} = 12 => 13$ Solutions ${x_{3}}+{x_{4}} = 10 => 11$ Solutions ${x_{3}}+{x_{4}} = 8 => 9$ Solutions ${x_{3}}+{x_{4}} = 6 => 7$ Solutions ${x_{3}}+{x_{4}} = 4 => 5$ Solutions ${x_{3}}+{x_{4}} = 2 => 3$ Solutions ${x_{3}}+{x_{4}} = 0 => 1$ Solution Then, Multiplying respective numbers $1.13 +  2.11 + 3.9 + 4.7 + 5.5 + 6.3 + 7.1 = 140$ Solutions I don't have answer for it. Am i right here ?","['permutations', 'combinatorics', 'combinations']"
2065470,"Prove that $G=\langle a,b\; | \; abab^2=1\rangle$ is infinite cyclic.","Prove that $G=\langle a,b\; | \; abab^2=1\rangle$ is infinite cyclic. First I proved that $a=(ab)^3$ and also $b=(ab)^{-2}$. By using these, I proved that $G$ is abelian and $G=\langle ab\rangle$. However, since the order of $a$ and $b$ is not given, I have no idea on proving the order of $ab$ is infinite.","['abstract-algebra', 'group-theory']"
2065518,Showing that the union of the interiors of a closed sets making up a complete metric space is dense,"If $X$ is a complete metric space such that 
  $X =\bigcup\limits_{n {\in \mathbb{N}}}F_n$, 
  where each $F_n$ is closed, prove that $\bigcup\limits_{  n {\in \mathbb{N}}}$$F_n^o$
  is dense in $X$. ($F_n^o$ denotes the interior of $F_n$.) I've tried a few ways to prove it, and I'm pretty sure that it uses the Baire Category Theorem somehow, but I'm not sure.","['complete-spaces', 'general-topology', 'metric-spaces', 'baire-category']"
2065538,How to prove that trace$(ABA^{-1}B^{-1})$=$3$,"If $A,B$ are two $3 \times 3$ square matrices and trace(A) is defined as the sum of all diagonal elements. trace$(ABA^{-1}B^{-1})$=$3$ I could easily verify the above for the identity matrix.But I couldn't generalise it. Please help me in this regard.thanks.","['matrices', 'linear-algebra']"
2065540,Sato hyperfunction with non-isolated singluar support,"For some reason, I need to justify use of the ""function"" $f(x) = 0$ if $x < 0$ and $f(x) = \infty$ if $x > 0$.  Is there a theory which allows to use such a function? Specifically, I looked to Sato hyperfunctions.  However, all examples of Sato hyperfunctions I know (I read in the first two chapters of Urs Graf's ""Introduction to Hyperfunctions and Their Integral Transforms"", and skimmed several other books) only have isolated singular supports.  Yet, as far as I know, I cannot find the proof of the thesis that singular supports of Sato hyperfunctions are isolated points. I tried to construct an example myself, but it seems for me to be impossible. This is because, to do this, we need a homomorphic function with non-isolated singularity on the real axis,  but only examples I can come up with are branching points, which are only have finite(?) gap. I am not an expert in this area, so I should miss something very trivial.  But I would appreciate any comment or suggestion regarding this.",['complex-analysis']
2065548,Finite Extensions of $\mathbb{Q}_p$,"Could someone say exactly how many extensions of degree $n$ the field $\mathbb{Q}_p$ has? In Serre's ""Galois Cohomology"" he says it is computed precisely in a paper by Krasner, but I can't find a copy of that paper anywhere.","['number-theory', 'p-adic-number-theory']"
2065562,Roadmap for learning Topological Data Analysis?,"I'm a math major who has recently graduated and I will be starting full time work in 'data analysis'. Having finished with decent marks and still being incredibly interested in mathematics, I was thinking of pursuing graduate study/research at some point in the future. I was reading up about possible areas of study for this when I came across topological data analysis, which (as I understand it) is an application of algebraic topology to data analysis. Given my situation, I was intrigued by the concept and I would like to do some self study so I can have a working understanding of the subject. I have only done basic undergraduate abstract algebra, analysis and point set topology, and I am currently reading Munkres' Topology (Chapter 9 onwards). How do I get from where I am now to understanding the theory behind TDA and being able to apply it? My knowledge on further mathematics is far from extensive and I would appreciate any advice on links/texts which I could use to learn the relevant material.","['algebraic-topology', 'general-topology', 'data-analysis', 'topological-data-analysis']"
2065565,Is a product of integrals like distributing a product?,"Can I argue that: \begin{align}
\left(\int_a^b f(x) \,dx\right) \left(\int_c^d g(y) \,dy\right)
&= \int_a^b f(x) \int_c^d g(y) \,dy \,dx \\
&= \int_a^b \int_c^d f(x) g(y) \,dy \,dx
\end{align} since the same would be true for a product of finite sums?","['integration', 'calculus']"
2065576,Calculating number of equivalence classes where two points are equivalent if they can be joined by a continuous path.,"Q. Let $G$ be an open set in $\Bbb R^n$. Two points $x,y \in G$ are said to be equivalent if they can be joined by a continuous path completely lying inside $G$. Number of equivalence classes is Only one. At most finite. At most countable. Can be finite, countable or uncountable. This question was asked in the NET exam December 2016. We can discard the first option by taking $n=1$ and $G=(-\infty,0) \cup (0,\infty)$. We can reject the second option by taking $n=1$ and $G=\cup_{k \in \Bbb Z} (k,k+1).$ Now fun begins. Can we get an uncountable number of disjoint open path connected subsets of $\Bbb R^n$ for some $n$? If so, then we can take $G$ to be their union. For $n=1$, this method fails because that would give us the contradiction that the set of irrational numbers is countable.","['continuity', 'real-analysis', 'equivalence-relations', 'path-connected']"
2065577,Expectation of random variable. [duplicate],"This question already has an answer here : Expectation formula of an integrable random variable (1 answer) Closed 7 years ago . Somewhere I found the definition of expectation of random variable as $$E[X]=\int_{0}^{\infty}(1-F(x))\,dx-\int_{-\infty}^0F(x)\,dx$$ But the definition I know is $$E[X]=\int_{-\infty}^{\infty}xf(x)\,dx$$ My Question is  why $$\int_{-\infty}^{\infty}xf(x)\,dx=\int_{0}^{\infty}(1-F(x))\,dx-\int_{-\infty}^0F(x)\,dx$$","['normal-distribution', 'probability-theory', 'probability-distributions', 'probability', 'random-variables']"
2065595,Conventions for operation notation...,"When dealing with multiple sets it is common practice to use convenient notations $\displaystyle\bigcup_{k=1}^nA_k$ and $\displaystyle\bigcap_{k=1}^nA_k$ to mean the union and intersection respectively of sets $A_1, A_2,\dots,A_n$. I haven't ever seen similar notation applied to the membership (""element of"") symbol - i.e. something like $\displaystyle a_k\mathop\in_{k=1}^n A_k$ - though it seems that it would be as convenient and as implicitly understandable as the notation above. For example, this could allow us to define a Cartesian product very succinctly (and still very understandably) as: $$A_1\times A_2\times\cdots\times A_n = \left\{(a_1, a_2,\dots,a_n):a_k\mathop\in_{k=1}^n A_k \right\}$$ Or to stretch a point: $$\mathop\times_{k=1}^n A_k=\left\{(a_1, a_2,\dots,a_n):a_k\mathop\in_{k=1}^n A_k \right\}$$ Is there a reason or convention for the fact that this kind of notation is commonly used for some operators while not others? I can see, for example, that $\cup$ and $\cap$, unlike $\in$ but like $\sum$ and $\prod$, represent operations repeatedly performed on objects of the same kind. Does it have to do with this?","['convention', 'notation', 'elementary-set-theory']"
2065599,Is twice-differentiability at a point required for there to exist a point of inflection?,"I'm going off of a similar post and I don't quite understand what mathematicians believe - can $f(x)$ have a point of inflection at $c$ if $f''(c)$ does not exist? The post I linked seems to hint that this is not possible but does not address if there is a change in concavity. If the concavity changes, then shouldn't there exist a point of inflection at the point even if its second derivative does not exist?","['derivatives', 'calculus']"
2065609,Calabi-Yau manifold with fiber structure,"I'm reading the paper 'A bound on the Euler number for certain Calabi-Yau 3-folds' where the author made the following statement about fiberd Calabi-Yau manifold without proof. Let $X$ be a smooth projective threefold with trivial canonical bundle, $\pi:X\to Y$ be a surjective holomorphic map from $X$ to a lower dimensional manifold $Y$, if $F$ is the general fiber of $\pi$, then there are 3 possible types: a. $Y$= surface with kodaira dimension $-\infty$, $F$=elliptic curves; b. $Y= \mathbb{C}P^1$, $F$= abelian surface; c. $Y= \mathbb{C}P^1$, $F$= k3-surface. The author mentioned that $F$ should have trivial canonical bundle by ajunction formula, as far as I know, the ajunction formula says that
$$K_F=(K_X\otimes \mathcal{O}_X(F))\mid_F,$$
then $K_F=\mathcal{O}_X(F)\mid_F,$ so the problem is why $\mathcal{O}_X(F)\mid_F=\mathcal{O}_F$? And I can't see why the base manifold $Y$ should be either a surface with kodaira dimension $-\infty$ or $\mathbb{C}P^1$? The author also mentioned implicitly that if $\pi$ have no singular fibers, then $X$ is essentially a product. This is amazing since this is the main result of this paper in 2013.","['differential-geometry', 'algebraic-geometry']"
2065621,Wheter the given function is integrable or not?,"Let $H$ be a Hilbert space and $A:D(A)\subset H\to H$ be a densely defined  positive self adjoint unbounded operator. It can be prove that $\{e^{-tA}:t\geq 0\}$ is a $C_0$ or strongly continuous semigroup with $\|e^{-tA}\|\leq 1$, generated by $-A$, where $e^{-tA}x=\int_0^\infty e^{-t\nu }dE_\nu x$ and $\{E_\nu :\nu\geq0\}$ is the resolution of identity corresponding to the operator $A$. We know from semigroup theory that for $x\in D(A)$ (domain of $A$) $$\int_0^Te^{-(T-t)A} A x dt=(I-e^{-T A})x.$$ My question is that if we replace $x$ by a continuous function $g:[0,T]\to D(A)$, then $t\mapsto e^{-(T-t)A} Ag(t)$ is integrable or not. It is clear that if $t \mapsto Ag(t)$ is integrable, then $t\mapsto e^{-(T-t)A} Ag(t)$ is integrable.","['functional-analysis', 'semigroup-of-operators', 'measure-theory', 'operator-theory']"
2065639,"How to integrate $\int_a^b (x-a)(x-b)\,dx=-\frac{1}{6}(b-a)^3$ in a faster way?","$\displaystyle \int_a^b (x-a)(x-b)\,dx=-\frac{1}{6}(b-a)^3$ $\displaystyle \int_a^{(a+b)/2} (x-a)(x-\frac{a+b}{2})(x-b)\, dx=\frac{1}{64}(b-a)^4$ Instead of expanding the integrand, or doing integration by part, is there any faster way to compute this kind of integral?","['integration', 'calculus']"
2065643,"adjacency matrix, maximal eigenvalue","I'm given a $d$ regular graph $G$. Dentote by $A(G)$ the adjacency matrix of $G$. I have to show that $\lambda_{\max}=d$, where $\lambda_{\max}$ is the biggest eigenvalue of $A(G)$. I know that the vector $(1,1,\ldots,1)$ is an eigenvector of $A(G)$ with eigenvalue $d$ but I cannot show that that this eigenvalue is indeed the maximal one. Any help on this would be great.","['combinatorics', 'graph-theory', 'linear-algebra']"
2065652,Let $U_n$ be the subset of $2\times2$ matrices $M_2(\mathbb C)$ such that $T^n=I$,"Fixed $n>0$ let $U_n$ be the subset of $2\times2$ matrices $M_2(\mathbb C) \simeq \mathbb C^4 \simeq \mathbb A_{\mathbb C}^4$ such that $T^n=I$. a) Show that $U_n$ is a Zarisky closed subset of $M_2(\mathbb C)$. b) Describe the irriducible components of $U_n$ and show that there are $ \binom {n+1} {2}$ of them. Partial Solution: a) $U_n$ is given by an ideal $I \subset \mathbb C[a,b,c,d]$ generated by at most 4 polynomials. We are done. b) ??? I can diagonalize every matrix with eigenvalues $\alpha$, $\beta$ $n$-th roots of $1$. Can't tell more.","['matrices', 'linear-algebra', 'algebraic-geometry', 'geometry']"
2065672,Determine if a Point is inside a polygon without coordinates,"I have a polygon $ABCD$. I do not know the coordinates of the corners but I know the length of its sides (i.e. I know length of $AB$, $BC$, $CD$ & $DA$). I have a point $P$. I do not know the coordinates of this point either but I know the distances $AP$, $BP$, $CP$ & $DP$. How do I determine if point $P$ lies inside the polygon $ABCD$?",['geometry']
2065727,Minimum number of points needed to define a circle in 3d space,"Firstly I thought that it might be 2. 
Having point A as the center. The vector between A and another point B is perpendicular to the plane of the circle and its length determines the radius of the circle. 
But then I thought this might define a disk. Thoughts ?",['geometry']
2065776,Calculating probability density function,"I am having difficulty solving this problem. Given this distribution
  $$
\begin{align*}
	f_X(x) &= \begin{cases}e^{-x} &,& x\geq 0 \\
	 0 &,& x<0\end{cases} \\[1ex]
	f_Y(y) &= \begin{cases}2e^{-2y} &,& y\geq 0 \\
	 0 &,& y<0\end{cases}
\end{align*}
$$
  Calculate $\mathsf P(X<3Y)$ I have attempted the following, however I am unsure if my methodology is correct.
$$
 \mathsf P(X<3Y)= \int_0^\infty \left[\int_0^{3y} f_X(x)f_Y(y) dx\right] dy
$$","['statistics', 'probability']"
2065787,Dynamics of Triangle Iterates by angle bisector,"I'm attempting to prove what is demonstrated in this Wolfram demo Let $T_0$ be an arbitrary triangle with vertices $A_0,B_0$and $C_0$,and let $T_1$ be the triangle formed by the intersection points of the angle bisectors of $T_0$ on its three sides .Construct $T_2,T_3...$in the same manner. Prove that the sequence$\{T_n\}_{n\geq0}$converges (in shape) to an
  equilateral triangle! This question haved been solved by this paper:On Sequences of Nested Triangles .However ,this paper uses MAPLE to perform and check the calculation! So I'm curious that can we solve this question through only (mathematics) analysis?(May be ..it is difficult)
Thanks.","['angle', 'fractals', 'analysis', 'geometry']"
2065792,Is the inverse of the standard deviation Sub-Gaussian?,"A zero mean sub-Gaussian random variable Z satisfies $Eexp(tZ)≤exp(t^2k^2/2)$ for some constant k>0. Let's say we have random variables: $X_1,X_2,...,X_n$ with $EX_i=\mu$ and $Var(X_i)=\sigma^2$. We know that $\hat{\sigma}$ is consistent.
I am interested in obtaining tail bounds for the inverse of the estimator of the standard error: $1/\hat{\sigma}$, where $\hat{\sigma}=\sqrt{\frac{1}{n}\sum_{i=1}^n (X_i-\bar{X})^2}$ and $\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i$. I didn't find anything in the literature. If the $X_i$ are standard Gaussian random variables, then $\hat{\sigma}^2$ is distributed according to a chi-squared distribution.
Can we prove that if $X_i$ are sub-Gaussian, $\hat{\sigma}$ is sub-Gaussian or sub-exponential? And what about its inverse? Or more generally, can we prove that under some assumptions on
the $X_i$, it exists a $n$ such that $1/\hat{\sigma}$ is sub-Gaussian? Thanks you in advance","['statistics', 'probability', 'asymptotics']"
2065813,How to prove that the CDF of the standard normal distribution is log-concave?,"How can I prove $\log(\Phi(x))$ is concave, where $\Phi(x)$ is CDF of N(0, 1) ? Since
$\frac{d^2}{dx^2} \log \Phi(x) = \cfrac{\phi(x)[-x \Phi(x) - \phi(x)]}{(\Phi(x))^2}$, it is enough to show that $-x \Phi(x) - \phi(x) < 0$ for all $x \in \mathbb{R}$. Here's a plot of $\log \Phi$: P.S. This may be inaccurate but I consider like below: $-x \Phi(x) - \phi(x)$ is decreasing since \begin{align}
\frac{d}{dx}( -x \Phi(x) - \phi(x)) &= -\Phi(x) - x \phi(x) + x \phi(x) \\
&= -\Phi(x) < 0
\end{align} $\lim_{x \to -\infty} -x \Phi(x) - \phi(x) = 0$, since $\phi(-\infty)=0$ and by l'Hospital's rule \begin{align}
\lim_{x \to -\infty} -x \Phi(x) &= - \lim_{x \to -\infty} \cfrac{\Phi(x)}{\frac{1}{x}} \\
&= \lim_{x \to -\infty} x^2 \phi(x) \\
&= \frac{1}{\sqrt{2\pi}} \lim_{x \to -\infty} \frac{x^2}{\exp(\frac{x^2}{2})}\\
&= \frac{1}{\sqrt{2\pi}} \lim_{x \to -\infty} \frac{2}{\exp(\frac{x^2}{2})} \\
&= 0
\end{align} Therefore, $-x \Phi(x) - \phi(x) < 0$ for all $x \in \mathbb{R}$","['probability-theory', 'convex-analysis', 'statistics', 'normal-distribution']"
2065822,Trace of adjugate,"Let $A \in M(\mathbb{R}, n)$ and $C_A(\lambda)$ its characteristic polynomial. Let $$ \Gamma_A(\lambda) := (-1)^{n+1}\frac{C_A(\lambda) - C_A(0)}{\lambda} $$ Then, $\text{adj}(A) = \Gamma_A(A)$ which is a form of the Cramer's rule $\text{adj}(A)A = \det(A) I$ using the Cayley-Hamilton theorem. There is an identitiy that $$ \text{tr} ( \text{adj} (A) ) = (-1)^{n+1} \Gamma_A(0)$$ Question: how is this identity derived? Background: I was studying Lemma 1.4 of this book on page 86, claim 6.","['matrices', 'abstract-algebra', 'linear-algebra']"
2065837,Analysis of a function,"I'm analysing function $$y=x+\frac{\ln x}{x}$$ and I kinda don't get few  parts. I get an oblique asymptote $y=x$, that function is increasing throughout the domain and that it is convex on $(e^\frac{3}{2}, \infty)$ and concave on $(0, e^\frac{3}{2})$ what bugs me is when i try to sketch a graph. It doesn't seem to match one on wolframalpha, particularly, it seems their is not convex on any part. One more thing, it also doesn't say function has an oblique asymptote. Can anyone tell me how is wolfram getting those results?","['functions', 'asymptotics', 'calculus', 'limits']"
2065844,Derivative of the determinant of the right stretch tensor,"I have to evaluate the derivative
$$
\frac{\partial\det\mathcal{U}}{\partial F}
$$
where $\mathcal{U}=\sqrt{F^TF}$ and $F$ is a $m\times n$ real matrix. Any suggestion would be appreciated. Thank you all, guys!! You helped me a lot.","['derivatives', 'matrices', 'matrix-calculus', 'determinant', 'linear-algebra']"
2065845,Find the indefinite integral $\int \frac{25}{(3\cos(x)+4\sin(x))^2} dx$,Find the indefinite integral: $$ \int\frac{25}{(3\cos(x)+4\sin(x))^2} dx$$ Obviously the first thing to is to expand the denominator but that doesn't help us that much. I have also tried applying the Weierstrass substitution but that lead to a black hole of algebra. I also notice the denominator has a $3$ and $4$ and the numerator has $25$ which mean a $3-4-5$ triangle might be related to this integral but I'm not to sure. Any help is appreciated :),"['indefinite-integrals', 'integration', 'calculus']"
2065854,How to use group actions to prove Lagrange's theorem?,"I was browsing proof wiki and saw that is possible to use group actions to prove Lagrange's theorem as an immediate corollary of the orbit stabiliser theorem but I don't quite see how it follows. I have so far defined the group action (on the left coset space) as given on the page (except I used $gH$ for a left coset whereas they just use $H$ for a arbitrary left coset (presumably this doesn't matter then?)). I have proved using my action $\phi:G\times G/H \rightarrow G/H$ by $\phi:(g_1,g_2H) \mapsto (g_1g_2)H$ I have shown this is a group action. So from the orbit stabiliser theorem we have $|O_{gH}|=|G|/|\text{Stab}_G(gH)|$ I suspect that $|\text{Stab}_G(gH)|=|H|$ and $|O_{gH}|=[G:\text{Stab}_G(gH)]$ but I'm not fully sure of this and even then how can I finish this proof?","['group-actions', 'group-theory']"
2065859,Canonical Projections are Continuous,"I was wondering if one would be so kind as to critique my short proof that the canonical projections are continuous with respect to the product topology: Let $\pi_i : \prod X_k \rightarrow X_i$ be one of the canonical projections, and $V_i$ some open set in $X_i$. Then $\pi^{-1}_i(V_i) = \prod V_k$, where $V_k = X_k$ for all $k \neq i$, which is clearly basis element (and therefore open) in the product topology. Now we justify the set equality. Let $x \in \pi_i^{-1}(V_i)$. This happens if and only if $\pi_i(x) \in V_i$ or $x_i \in V_i$ and $x_k \in X_k$ for every $k \neq i$. Hence, $\pi^{-1}_i(V_i) = \prod V_k$. Moreover, I am wondering if I can conclude that the projections are also continuous with respect to the box topology, since it is finer than product topology.","['general-topology', 'proof-verification']"
2065868,"Proving that $\det(A) \ne 0$ if $a_{i,i} = 0$ and $a_{i,j} = \pm 1$ for $i \neq j$","Let $A$ be an $n\times n$ matrix ($n=2k$, $k \in \Bbb N^*$) such that. $$a_{ij} =
\begin{cases}
\pm 1,  & \text{if $i \ne j$} \\
0, & \text{if $i=j$}
\end{cases}$$ Show that $\det (A) \ne 0$. P.S. $a_{ij}=\pm 1$ means that it can be $+1$ or $-1$ not necessarily the same for all $a_{ij}$. My approach: I've started with the definition of $\det A$ writing like a permutation sum but it became messy. I also tried Laplace's method but also didn't work. I also tried induction but once $\pm 1$ is aleatory it became tough to deal with.","['matrices', 'linear-algebra', 'determinant']"
2065871,Proving $\ln \lambda = \int_0^\infty \frac{\mathrm dt}t e^{-\lambda t}$,"I am currently reading this paper . On page 5, it writes: For each positive eigenvalue $\lambda$ of the operator $D$ we may write an identity
  $$\ln \lambda = \int_0^\infty \frac{\mathrm dt}t e^{-\lambda t}.\tag{1.17}$$
  This identity is ""correct""  to an infinite constant, which does not depend on $\lambda$ and, therefore, may be ignored in what follows. Now we use $\ln \det(D)=\mathrm{Tr}\ln(D)$ and extend $(1.17)$ to the I can not prove this identity. I tried
$$\int_0^{\infty} \frac{\mathrm dt}{t}e^{-t\lambda}=\int_0^{\infty} \frac{\mathrm d(\lambda t)}{(\lambda t)}e^{-t\lambda}=\int_0^{\infty} x^{-1}e^{-x}\ \mathrm dx=\Gamma(0),$$
where fort the third equality, I used the definition of Gamma function .","['integration', 'definite-integrals', 'gamma-function']"
2065949,Operators and Tensor Products,"For clarity I've re-written this question. Let $V, \text{End} (V), V \otimes V, \text{End} (V\otimes V), \text{and } \text{End} (V) \otimes \text{End} (V)$ be a vector space, the space of linear operators on it, the tensor product of  $V$  with itself, the space of linear operators on $V \otimes V$, and the tensor product of the space of $\text{End}(V)$ with itself. There is no topology involved in  this question. Define a map $\phi: \text{End}(V) \times \text{End}(V) \to \text{End}(V \otimes V)$ by $\phi(S, T)(u \otimes v) = S(u) \otimes T(v)$. Then $\phi$ is bilinear: e.g. $\phi(S_1 + S_2, T)(u \otimes  v) = (S_1(u) + S_2(u)) \otimes T(v) = S_1(u) \otimes T(v) + S_2(u) \otimes T(v) = \phi(S_1 , T)(u \otimes v) + \phi(S_2, T)(u \otimes v)$ So by the universal property of the tensor product $\text{End}(V) \otimes \text{End}(V)$ there is a linear map $\overline \phi: \text{End}(V) \otimes \text{End}(V) \to \text{End}(V \otimes V)$ where for all $S, T \in \text{End}(V) $we have $\overline \phi (S \otimes T) (u \otimes v) = S(u) \otimes T(v)$ according to Operators on a Tensor Product Space and its answers, if $V$ is finite dimensional then $\overline \phi$ is a canonical isomorphism. Note that if $V$ has finite dimension $n$ then $Dim(\text{End}(V)) = n^2$; $Dim (\text{End}(V) \otimes \text{End}(V)) = n^ 4 = Dim(\text{End}(V \otimes V))$. So the spaces are isomorphic (but is $\overline \phi$ an isomorphism ?) If $\overline \phi$ is an isomorphism then it has an inverse, $\overline \phi^{-1}: \text{End}(V \otimes V) \to \text{End}(V) \otimes \text{End}(V)$ Consider the map $f: V \times V \to V \otimes V$ where $f(u, v) = v \otimes u$. This is also bilinear, e.g. $f(u, v_1 + v_2) = (v_1 + v_2) \otimes u = v_1 \otimes u + v_2 \otimes u = f(u, v_1) + f(u, v_2)$ By the universal property of $V \otimes V$ there is a linear map $\overline f \in \text{End}(V\otimes V)$ where for all $u, v \in V$ we have $\overline f(u \otimes v) = v \otimes u$. So, my question is if (V is finite dimensional and) $\overline \phi $ is an isomorphism, then what is $\overline \phi ^{-1}(\overline f)$ ? The answer has been provided below by @martini The original question wording is .... I may be mistaken in my understanding of what follows..... The answers to this question Operators on a Tensor Product Space say that  for finite dimensional spaces there is a canonical isomporphism between $\text{End}(V \otimes W)$ and $\text{End}(V) \otimes \text{End}(W)$ based on extending $\phi(S,T)(u\otimes v):=Su\otimes Tv.$ On the other hand I am reading http://www.physik.uni-leipzig.de/~schmidtm/qm/tepr.pdf which includes the following statement which appears to conflict with this Remark: There are many operators on V ⊗W which are not of the form A ⊗ B with A and B
being operators on V and W, respectively. For example, if W = V , the mapping V ×V → V ⊗V
defined by (v,w) 7→ (w, v) induces an operator on V ⊗V (check this) which is not of that form. This suggests (to me) that a mapping $\text{End}(V) \otimes \text{End}(W) \to \text{End}(V \otimes W)$ can't be surjective and so there can't be an isomorphism ? I would appreciate help with this.","['tensor-products', 'linear-algebra', 'linear-transformations', 'vector-spaces']"
2066004,"Big O Notation ""is element of"" or ""is equal""","People are always having trouble with ""big $O$"" notation when it comes to how to write it down in a mathematically correct way. Example: you have two functions $n\mapsto f(n) = n^3$ and $n\mapsto g(n) = n^2$ Obviously $f$ is asymptotically faster than $g$. Is it $f(n) = O (g(n))$ or is it $f(n) \in O(g(n))$? My prof says that the first one is wrong but is a very common practice, therefore it is used very offten in books. Although the second one is the right one. Why is that so?","['math-history', 'asymptotics', 'functions']"
2066034,Mistake in Apostol's Calculus Volume II regarding inner products?,"It looks like there is a completely miswritten formula in Apostol's Calculus, Volume II, regarding inner products. The formula states that: 
""If $x=(x_1,x_2)$ and $y=(y_1,y_2)$ are any two vectors in $V_2$, define $(x,y)$ by the formula $(x,y)=2x_1y_1+x_1y_2+x_2y_1+x_2y_2$. Through online research and consulting with a friend, it looks like $(x,y)=x_1y_1+x_2y_2$ is in fact the correct formula for inner products, but I wanted to make sure the book's version was not also correct, because this is more than a minute typo. Is there any validity to the book's definition?","['multivariable-calculus', 'real-analysis', 'inner-products']"
2066053,"Prove that the set of all functions from $A$ to $B$, where $|A| = \alpha$ is in a bijective correspondence with $B^{\alpha}$","Prove that the set of all functions from a set $A$ to $B$, where $|A| = \alpha$ (where $\alpha \in \mathbb{Z_+}$ if $A$ is finite, or $\alpha = \mathcal{w}$ is $A$ is countably infinie) is in a bijective correspondence with $B^{\alpha}$ My attempted proof: Put $\gamma = \{ f \ | \ f: A \to B \}$ to be the set of all functions $f$ from $A$ to $B$. Now the only condition that we need for $f$ to be a function from $A$ to $B$, is that every $a \in A$ must be mapped to any $b \in B$. In other words $f \in \gamma$ if for every $a \in A$, there exists a $b \in B$, such that $f(a) = b$. So we associate with each $a \in A$ an $f$ , since for each possible $a \in A$, there are $|B|$ many $b$'s that satisfy $f(a) = b$. And since there are $|A| = \alpha$ many $a$'s in $A$, there must be $$ \underbrace{|B| \cdot |B| \cdot \ ... \ \cdot |B|}_\text{$\alpha$ times}  = |B|^{\alpha}$$ possible functions from $A$ to $B$. Thus $|\gamma| = |B|^{\alpha}$, and since $|B^{\alpha}| = |B|^{\alpha}$, we have $|\gamma| = |B^{\alpha}|$, and by the definition of cardinality of sets, there must exist a bijection between $\gamma$ and $B^{\alpha}$. Is this proof correct? If so how rigorous is it? Any comments and criticism on my proof writing and proof style are greatly appreciated!","['elementary-set-theory', 'functions', 'proof-verification']"
2066089,The $n^{th}$ digits of $e+\pi$ and a periodic sequence,"Let $n$ be a positive integer greater than zero. I denote the $n^{th}$ digits of $e$ and $\pi$ by $e_n$ and $\pi_n$ respectively. Let $d(e_n+\pi_n)$ count the number of divisors of $e_n+\pi_n$ and set $$\alpha(n)=gcd\big(n,2^{d(e_n+\pi_n)}\big)$$ I want to prove and believe it to be true that $\alpha(n)$ is periodic with period $[1,2,1,4,1,2,1,8,1,2,1,4,1,2,1,16]$ I have verified the first 50 terms of $\alpha(n)$. A counter example would be nice.  This is pure curiosity.","['divisibility', 'gcd-and-lcm', 'algebra-precalculus', 'oeis', 'elementary-number-theory']"
2066097,Show that $e^n>\frac{(n+1)^n}{n!}$ without using induction.,"I have got an inequality problem which is as follow: Show that $e^n>\frac{(n+1)^n}{n!}$ I can do it by induction but I have been told to prove it without induction. My Work: $$e^n=1+n+\frac{n^2}{2!}+\frac{n^3}{3!}+........$$
$$e^n>1+n+\frac{n^2}{2!}+\frac{n^3}{3!}+........+\frac{n^n}{n!}$$
$$e^n>\frac{n^n}{n!}+\frac{n^{n-1}}{(n-1)!}.......+\frac{n^2}{2!}+n+1$$ From here I can't go further. I shall be thankful if you guys can provide me a complete solution/proof of this inequality. A hint will also work. Thanks in advance.","['inequality', 'proof-writing', 'exponential-function', 'alternative-proof']"
2066142,checking Inner product,"Consider the vector space of polynomials $\mathbb{R}[x]$. Let $p=\displaystyle \sum_{k=0}^{n} a_kx^k$ and $q= \displaystyle \sum_{j=0}^{n} b_jx^j$ be two polynomials each of degree $n$ in $\mathbb{R}[x]$. Assume that the sequence $\{s_n\}_{n=0}^\infty$ is positive definite and Let $L: \mathbb{R}[x] \rightarrow \mathbb{R}$ be a psoitive semi-definite linear functional suh that $L(x^n) =s_n , n\ge 0$. This implies that $L(p^2)> 0$ for all $p \in \mathbb{R}[x], p\neq 0$. Then $$\left<p,q \right>:= L(pq), \quad p,q \in \mathbb{R}[x]$$ defines an inner product $\left<.,.\right>$ on $\mathbb{R}[x]$ since $$ \left<p,q \right> =  \left< \sum_{k=0}^{n} a_kx^k, \sum_{j=0}^{n} b_jx^j\right> =L(pq) = \sum_{k,j=0}^{n}s_{k+j}a_kb_j.$$ I was checking that indeed $\left<.,.\right>$ is an inner product. First  $$\left<p,p \right> = L(p^2)\ge 0, \forall p \in \mathbb{R}[x].$$ Secondly  $$\left<p,q \right>= L(pq)=L(qp) =\left<q,p \right>$$ I checked other properties of an inner product but I am a bit confused if this last property is true $\left<p,p \right>=0$ if and only if $p=0$ since $\{s_n\}_{n=0}^{\infty}$ is positive definite by assumption. It is clear to me that if p=0 then $\left<p,p\right>=0$ but I am not convinced with the reverse direction. Thanks for helping me.","['real-analysis', 'abstract-algebra', 'functional-analysis', 'inner-products', 'linear-algebra']"
2066145,$f_x$ is Borel measurable and $f^y$ is continuous then $f$ is Borel measurable,"I have to prove the following: Let $f: \mathbb{R^2}\to \mathbb{R}$ such that $f_x:y\to f(x,y)$ is Borel measurable for all $x\in\mathbb{R}$ and that $f^y:x\to f(x,y)$ is continuous for all $y\in\mathbb{R}$. Prove that $f$ is Borel measurable. What I have tried to do is to find a sequence of functions $f_n(x,y)$ s.t for a fixed $y$ $f_n(.,y)$ is a linear approximation of $f(.,y)$..",['measure-theory']
2066147,"Choosing $a$ such that equation $f(x, a)=g(x)$ has only one solution with respect to $x$","Let $f(x, a)$ and $g(x)$ are given functions. We want to find all values of $a$ such that equation $f(x, a)-g(x)=0$ has only one solution with respect to $x$. For example: $a \cdot \log_{a}x=x$ or $ax^4 - e^x=0$","['multivariable-calculus', 'calculus']"
2066164,Does the form domain of the Friedrichs extension of an unbounded operator compactly embed?,"Say we have a Hilbert space $H$ and a positive symmetric operator $T$ with domain $D$. Define a norm $\|u\|_T = \langle Tu, u\rangle$ for $u\in D$ and take the completion of $D$ with respect to this norm to obtain a new Hilbert space $V$. Part of the construction of the Friedrichs extension of $T$ is that the inclusion map $D\hookrightarrow H$ extends to an injective bounded map $V\hookrightarrow H$. If $T$ is unbounded in $H$, is the inclusion $V\hookrightarrow H$ a compact embedding?",['functional-analysis']
2066170,Sums of quadratic residues with quadratic nonresidues,"For a given odd prime $p$ (with $p \mod 4 = 1$) I've being amusing myself to add any qr and any qnr. The result is sometimes a qr and sometimes a qnr, but what I found out is that exactly half of all the possible sums are qr and the other half are qnr. I've tried to write the qr as $a^{2i}$ (with $a$ a primitive root) and the qnr as $a^{2j+1}$, but $a^{2i} + a^{2j+1}$ leads nowhere, is it possible to prove this?","['number-theory', 'quadratic-residues']"
2066173,A $3\times3$ matrix with rank 2 must have a nonzero solution to $Ax=0$,I have recently come across the following statement: A $3\times3$ matrix A with rank $2$ must have a nonzero solution to $Ax=0.$ I am having trouble understanding why there must be a nonzero solution to $Ax = 0.$ Is it due to the fact that we will have a free variable?,['linear-algebra']
2066191,Basic Understanding of Linear Combinations Geometrically,"I am currently working through MIT's Introduction to Linear Algebra by Gilbert Strang, with no previous matrix experience.  In the first lecture, we are given the following linear equations: $$2x -  y = 0\\
-x + 2y = 3$$ The solution to the system of equations is $(1,2)$. Following this Professor Strang rewrites the system of linear equations in a column picture: x [ 2 ] + y [-1] = [ 0 ] [-1] +  [2] = [ 3 ] In the following steps, the vectors $[2, -1]$ and $[-1, 2]$ are plotted to show that the solution $(0, 3)$ can be found by geometrically by multiplying the ""$x$-vector"" by $1$ and the ""$y$-vector"" by $2$, and adding the two results. My confusion is as follows, looking at the column vectors: In the first vector from the $x$ coefficients we get $[2,-1]$.   What property allows the two $x$ coefficients to be drawn as a vector in $x$ and $y$ on an $xy$ plot?  The result of this is that both coefficients from equation $1$ give magnitude only in the $x$-axis and the coefficients from equation $2$ are on the $y$-axis? Which confuses me if this is an $xy$ plot I am new to this so I am not articulating this very well, so apologies and thanks in advance for your time. Diagrams and formal class notes on P1 & 2: https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/ax-b-and-the-four-subspaces/the-geometry-of-linear-equations/MIT18_06SCF11_Ses1.1sum.pdf",['linear-algebra']
2066198,What are the conditions that ensure that a linear operator on a separable Hilbert space has a discrete spectrum and its eigenvectors form a basis?,"I am particularly interesed in answers such as: symmetric, bounded, positive. self-adjoint and bounded essentialy self-adjoint and positive. (Those were invented) I'm interested in this question in the frame of Quantum mechanics. Thanks a lot!","['quantum-mechanics', 'linear-algebra', 'hilbert-spaces', 'linear-transformations']"
2066202,Is a norm in $\mathbb{R}^d$ increasing in every coordinate?,Consider any norm $\|\cdot\|$ in the $d$ dimensional Euclidean space and consider a fix point there $x$ such that all of its coordinates are positive. Let $e_k$ some vector in the standard basis of this space and consider the function $t \mapsto \|x +te_k\|$ for non negative $t$. Is this function increasing?,"['multivariable-calculus', 'vector-analysis', 'vector-spaces']"
2066207,How can one define parallel transport on lie groups?,"I want to transport a tangent vector $T_p$ at a point $p$ to some other point $q$ on a lie group. Do I have to use $log(p^{-1}q)$, which is also a tangent vector, to achieve the same?","['manifolds', 'differential-geometry', 'lie-algebras', 'lie-groups']"
2066277,Is there an alternative form/identity for $\prod_{k=1}^{m} \cos(2^kx)$? [duplicate],"This question already has answers here : Proving: $\cos A \cdot \cos 2A \cdot \cos 2^{2}A \cdot \cos 2^{3}A ... \cos 2^{n-1}A = \frac { \sin 2^n A}{ 2^n \sin A } $ (2 answers) Simplifying Trig Product in terms of a single expression and $n$ [duplicate] (2 answers) Closed 7 years ago . I am working with a family of integrals that involve a product of cosines of the form $\prod_{k=1}^{m} \cos(2^kx)$.  Is there a formula or identity for simplifying $\prod_{k=1}^{m} \cos(2^kx)$ to a polynomial number of terms in $x$?  Or $\cos x$, $\sin x$?","['trigonometric-integrals', 'trigonometry', 'trigonometric-series']"
2066297,"If $|f(z)|\le |g(z)|$, can we say $f$ is constant?","Let $f$ and $g$ be entire functions and $g(z)\neq 0$ for all $z\in \mathbb{C}$. If $|f(z)|\le |g(z)|$, can we say $f$ is constant? Liouville theorem says that an entire bounded function is constant, but g is not given bounded here. So I think it should be false. What else can we say about $f$?",['complex-analysis']
2066318,Is the following function a norm?,"Let $\| \|$ be any norm in $\mathbb{R}^d$. Consider now $d$ normed vector spaces $(V_i, \|\|_i)$ and let $V$ be the cartesian product vector space. Is the function $f$, given according to the rule $f(v) = \|(\|v_1\|_1, \ldots, \|v_d\|_d)\|$, a norm in $V$? (I can prove everything but the triangle inequality. As a matter of fact, any norm in $\mathbb{R}^d$ whose entries are non decreasing will make $f$ a norm; in particular, any $p$-norm make $f$ a norm -$p\in[1,\infty]$-).","['multivariable-calculus', 'normed-spaces', 'real-analysis']"
2066320,"Prob. 3, Chap. 3 in Baby Rudin: If $s_1 = \sqrt{2}$, and $s_{n+1} = \sqrt{2 + \sqrt{s_n}}$, what is the limit of this sequence?","Here's Prob. 3, Chap. 3 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: If $s_1 = \sqrt{2}$, and $$s_{n+1} = \sqrt{2 + \sqrt{s_n}} \ \ (n = 1, 2, 3, \ldots),$$ prove that $\left\{ s_n \right\}$ converges, and that $s_n < 2$ for $n = 1, 2, 3, \ldots$. My effort: We can show that $\sqrt{2} \leq s_n \leq 2$ for all $n = 1, 2, 3, \ldots$. [Am I right?] Then we can also show that $s_n < s_{n+1}$ for all $n = 1, 2, 3, \ldots$. [Am I right?] But how to calculate the exact value of the limit? Where does this sequence occur in applications?","['real-analysis', 'sequences-and-series', 'metric-spaces', 'convergence-divergence', 'analysis']"
2066330,cardinality of Y=$\{(x_n)\ : x_n=1\}$ for at most finitely many $n$,"Let $X$ be the set of all binary sequences i.e. $X=\{(x_n) : x_n \in \{0,1\}, n \in \mathbb{N}\}$ and Y be its subset such that  Y=$\{(x_n)\in X : x_n=1 \text{ for at most finitely many } n \}$. It is clear that $X$ is uncountable using Cantor's diagonalization argument. But Y must be countable right? As I think we can enumerate it and thus have a 1-1 function with $\mathbb{N}$. Am I right?",['elementary-set-theory']
2066366,Exhibit a non-principal ideal,"It is well-known that in a Noetherian UFD, every height one prime ideal is principal. I was wondering whether this statement holds if one replaces 'UFD' with 'locally factorial domain'. I am aware of the fact that 'locally factorial' in general does not imply 'factorial', i.e., 'unique factorization' (though have never come accross locally factorial domains that are not UFDs), so I believe that there is a counterexample to this. However I cannot come up with any.","['examples-counterexamples', 'abstract-algebra', 'maximal-and-prime-ideals', 'ring-theory', 'commutative-algebra']"
2066404,show that; strange sum yields triangular numbers $\sum_{k=1}^{n}\tan^2\left({k\pi\over 2n+1}\right)=T_{2n}$,"$1,3,6,10,15,...$ for $n=1,2,3,...$ it is the n-th Triangular numbers. I find it unsual that this sum yields even triangular numbers; $$\sum_{k=1}^{n}\tan^2\left({k\pi\over 2n+1}\right)=T_{2n}$$ How can I show that? Any hints into this strange sum? I can't figure it out where to start!","['number-theory', 'trigonometry', 'sequences-and-series']"
2066409,Words formed from NUMBER with N to the left of U,"In how many ways can the letters of the word NUMBER be arranged?
In how many ways is the letter N somewhere to the left of U? Why is the answer to the second question exactly half of the answer to the first?","['permutations', 'combinatorics']"
2066444,"Do Riemann-Stieltjes integrals ""iterate""?","Let's say we define: $$h(x) = \int_a^x f(t)dg(t),$$ then do we have for integrable functions $a$ that: $$\int_a^b a(u) dh(u) = \int_a^b a(u)f(u)dg(u) ?$$ I would like to know whether this holds for either the Riemann-Stieltjes or the Lebesgues-Stieltjes integral or any similar integral. Also for the sake of simplicity, feel free to assume that all relevant functions are as ""nice"" as you want, e.g. real-analytic. A yes/no answer would suffice, as would references which either prove or disprove such a result. Attempt: In ""nice"" cases, we hope that the behavior of the Riemann-Stieltjes sums will predict the behavior for the integrals, i.e. that the behavior will be respected/preserved by the appropriate limits. So let's write now instead: $$\int_a^b a(u) dh(u) \approx \sum_{i=0}^{n-1} a(x_i) (h(x_{i+1}) - h(x_i)) $$ Then by definition of $h$ we have that: $$h(x) \approx \sum_{j=0}^{m-1} f(t_j) (g(t_{j+1}) - g(t_j))$$ In particular for each $i$ we have that (setting $t_m = x_i, t_{m+1}=x_{i+1}$, etc.): $$h(x_{i+1}) - h(x_i)  \approx \sum_{j=0}^{m} f(t_j) (g(t_{j+1}) - g(t_j)) - \sum_{j=0}^{m-1} f(t_j) (g(t_{j+1}) - g(t_j)) = f(x_i)(g(x_{i+1})-g(x_i))$$ so that substituting into the above: $$\int_a^b a(u) dh(u) \approx \sum_{i=0}^{n-1} a(x_i) (h(x_{i+1}) - h(x_i)) \approx \sum_{i=0}^{n-1}a(x_i)f(x_i)(g(x_{i+1})-g(x_i)) \approx \int_a^b a(u)f(u)dg(u). $$ Of course, the above ""argument"" is extremely sloppy and would require considerable effort to be made rigorous, assuming that is even possible. But hopefully it suggests why I think the above result may be true -- I had hoped to find it or something similar on the Wikipedia page for the Riemann-Stieltjes integral , but it is not. Also one might expect the identity to be true by sloppily ""applying"" the fundamental theorem of calculus ($h(x)``=""\int_a^x f(t)g'(t)dt$ so $h'(u)``=""f(u)g'(u)$), i.e. when $$\int_a^b a(u)dh(u) ``="" \int_a^b a(u) h'(u) du ``="" \int_a^b  a(u) f(u) g'(u) du ``="" \int_a^b a(u) f(u) dg(u). $$","['real-analysis', 'reference-request', 'calculus', 'stieltjes-integral', 'integration']"
2066512,Closed immersion being an affine-local property on the target.,"Assume that $f : X \rightarrow Y$ is a morphism of schemes. Then prove that $f$ is a closed immersion if-f there is an affine cover of $Y$ say $\{ U_i \}$, such that the induced scheme morphisms $f^{-1}(U_i) \rightarrow U_i$, is a closed immersion $ \forall \thinspace i \in I$. (The above is an exercise from Vakil's notes)","['schemes', 'affine-schemes', 'algebraic-geometry']"
2066514,Convergence of complex sequence $z_{n}$,"A complex number is written in de form of $z=x+iy$, with $x,y \in \mathbb{R}$. We can call a sequence ($z_{n}$) of complex numbers convergent with limit $z^{*} \in \mathbb{C}$ if $\forall \varepsilon > 0: \exists n_{0} \in \mathbb{N} : \forall n \geq n_{0} : \vert z_{n} - z^{*} \vert < \varepsilon$. Let $z_{n} = x_{n} + iy_{n}$ and $z^{*} =x^{*}+iy^{*}$, then $\vert z_{n} - z^{*} \vert = \sqrt{(x_{n} - x^{*})^{2} + (y_{n} - y^{*})^{2}}$. $\textbf{Question:}$ Let $(z_{n})$ be a sequence of complex numbers. Take $x_{n}=$ Re $z_{n}$ and $y_{n} =$ Im $z_{n}$ for every $n \in \mathbb{N}$. Then $x_{n}$ and $y_{n}$ are both real sequences. Proof that $z_{n}$ is convergent if and only if the two sequences $x_{n}$ and $y_{n}$ are both convergent. I started by proving the reverse of the theorem:
Suppose $x_{n}$ is convergent, so that $\lim_{n\to\infty} x_{n} = x^{*}$. Then $\forall \varepsilon > 0: \exists n_{1} \in \mathbb{N} : \forall n \geq n_{1} : \vert x_{n} - x^{*} \vert < \frac{\varepsilon}{\sqrt{2}}$. Also, suppose that $y_{n}$ is convergent, so that $\lim_{n\to\infty} y_{n} = y^{*}$. Then $\forall \varepsilon > 0: \exists n_{2} \in \mathbb{N} : \forall n \geq n_{2} : \vert y_{n} - y^{*} \vert < \frac{\varepsilon}{\sqrt{2}}$. Then, $\vert x_{n}-x^{*}\vert^{2}<\frac{\varepsilon^{2}}{2}$ and also $\vert y_{n}-y^{*}\vert^{2}<\frac{\varepsilon^{2}}{2}$. If we add both inequalities together, we get after some calculations $\sqrt{(x_{n}-x^{*})^{2}+(y_{n}-y^{*})^{2}}<\varepsilon$. This holds $\forall \varepsilon > 0$ and $\forall n \geq max \lbrace n_{1},n_{2}\rbrace$, by which follows that $z_{n}$ is convergent and $\lim_{n\to\infty} z_{n} = z^{*}$. I'm not sure whether this proof is fully correct and I also have no idea how to proof the theorem the other way around.","['complex-analysis', 'sequences-and-series', 'convergence-divergence']"
2066523,Are there prime numbers not irreducible in $\mathcal{O}_{\mathbb{Q}(\sqrt{577})}$?,"All small (rational) primes I've looked at seem to be irreducible elements in the ring $\mathcal{O}_{\mathbb{Q}(\sqrt{577})}$. Often they're irreducible but not prime. And of course $577 = (\sqrt{577})^2$. Looking at ideals, it's clear that $$\langle 2 \rangle = \left\langle 2, \frac{1}{2} + \frac{\sqrt{577}}{2} \right\rangle^2,$$ $$\langle 3 \rangle = \left\langle 3, \frac{1}{2} - \frac{\sqrt{577}}{2} \right\rangle \left\langle 3, \frac{1}{2} + \frac{\sqrt{577}}{2} \right\rangle,$$ $\langle 5 \rangle$ and $\langle 7 \rangle$ are prime, etc. It's then not difficult to find failures of unique factorization such as $$12 = 2^2 \times 3 = (-1) \left(\frac{23}{2} - \frac{\sqrt{577}}{2} \right) \left(\frac{23}{2} + \frac{\sqrt{577}}{2} \right).$$ But I can't seem to find a case of principal ideals $\langle a \pm b \sqrt{577} \rangle$, with nonzero $a, b \in \mathbb{Q}$ (either integers or halves of integers, to be precise) having prime norm. For contrast, observe that in $\mathbb{Z}[\sqrt{15}]$ (not UFD either), we have $\langle 11 \rangle = \langle 2 - \sqrt{15} \rangle \langle 2 + \sqrt{15} \rangle$. Is this theoretically impossible in $\mathcal{O}_{\mathbb{Q}(\sqrt{577})}$, or have I just not looked far enough? EDIT: Thanks to quid for editing my question to be more precise in regards to terminology. I am editing the question now because in my non-UFD example I used $24$ when I should have used $12$. It seems no one would have caught that but it was bothering me.","['number-theory', 'quadratic-forms', 'prime-numbers', 'algebraic-number-theory']"
2066532,Perturbation by $\varepsilon\mathbf 1$ in a Banach Algebra.,"Let $A$ be a Banach algebra, $G(A)$ denotes the set of all invertible elements in $A$. Let $\mathbf 1$ be the identity element of $A$. Suppose that $x\in\partial G(A)$. Is it true that for any $r>0$, there exists $\varepsilon\in\Bbb C$ such that $|\varepsilon|<r$ and
  $
x+\varepsilon\mathbf 1\in G(A)
$? I know that this is true for $A=M_n(\Bbb C)$ and $G(A)=GL(n,\Bbb C)$. The proof follows from the discreteness of the roots of characteristic polynomials. I can't think of a proof or a counter example for infinite dimensional cases.","['functional-analysis', 'banach-algebras']"
2066533,Probability of choosing the correct missing digit > 0.5?,"The question goes as follows: A person has forgotten the last digit of a telephone number, so he dials
  the number with the last digit randomly chosen. How many times does he have to dial
  (not counting repetitions) in order that the probability of dialing the correct number
  is more than 0.5. The way I answered it was in the following format: Denote try 1 success as $T_1$, and subsequently follows: $ P(T_1 \cup (T_2 \cap T_1^c) \cup (T_3 \cap T_2^c \cap T_1^c)  ...) \gt 0.5 $ We know the union of these events can be expressed as additions because they're disjoint, so: $ P(T_1) + ... P(T_n \cap T_{n-1}^c ... T_1^c) \gt 0.5$ We also know that in each, the event of $T_x$ and $T_y$ such that $x \ne y$ is independent. Then we can say for $P(T_n \cap T_{n-1}^c ... T_1^c)$ for example it becomes: $P(T_n) P(T_{n-1}^c) ... P(T_1^c)$ So I just kept calculating the probabilities, which are 1/10, 1/9, 1/8, 1/7... 1 for the $T_n$'s and 9/10, 8/9, 7/8, 6/7... for the $T_n^c$'s. Iteratively doing this I found an answer. However, this is pretty tedious. I was wondering if there was a closed form solution, or if this is even correct?","['probability-theory', 'probability']"
2066553,Second derivative of the nuclear norm,"The nuclear norm is defined in the following way $$\| X \|_* := \mbox{tr} \left( \sqrt{X^T X} \right)$$ and, from Derivative of the nuclear norm with respect to its argument , $$\frac{d}{dX} \| X \|_*  = U\Sigma^{-1}\mid\Sigma \mid V^T$$ What is the second derivative of the nuclear norm? $$\frac{d^2}{dX^2} \| X \|_* = ?$$ I need it to compute Newton's method for my algorithm and I haven't had much success. Any help would greatly be appreciated. Thanks in advance!","['derivatives', 'optimization', 'nuclear-norm', 'matrix-calculus', 'linear-algebra']"
2066558,Directional Derivatives - Geometric intuition,"I just have a question about directional derivatives. I know that for a unit vector $v$, it is $\nabla f \cdot v$ (where $v$ is the direction we want to find the derivative of). The proof of this using limits makes sense, but how would you look at this geometrically? The gradient vector is the direction in which the function increases the most, but then having a dot product of this with a unit vector apparently gives the derivative going in that direction. I'm not quite sure how to interpret the dot product geometrically. Thank you!","['multivariable-calculus', 'inner-products', 'vectors', 'vector-spaces']"
2066574,Proofs involving sets and cross product,"So today I tried to solve two problems from a textbook involving sets again. I got stuck with the second one though I'm confident about my solution for the first problem. That's the task: Prove for any subsets $A,B,C,D$ of a finite set $M$:
$$
a.)\; (A\times B)\cap(C\times D)=(A\cap C)\times(B\cap D)
$$ $$
b.)\; (A\times B)\cup(C\times D)\subset(A\cup C)\times(B\cup D)
$$ $$
\begin{align}
(x,y)\in[(A\times B)\cap(C\times D)]&\Longleftrightarrow (x,y)\in(A\times B)\cap(x,y)\in(C\times D)\\
&\Longleftrightarrow(x\in A \land y\in B)\land(x\in C \land y \in D)\\
&\Longleftrightarrow(x\in A \land x\in C)\land(y\in B \land y\in D)\\
&\Longleftrightarrow[x\in(A\cap B)]\land[y\in(B\cap D)]\\
&\Longleftrightarrow(x,y)\in[(A\cap B)\times(B\cap D)].
\end{align}
$$ $$
\begin{align}
(x,y)\in[(A\times B)\cup(C\times D)]&\Longleftrightarrow(x,y)\in(A\times B)\lor(x,y)\in(C\times D)\\
&\Longleftrightarrow(x\in A\land y\in B)\lor(x\in C\land y\in D)\\
\end{align}
$$ After that I tried a bunch of things but none of them seem to work out. I suspect that $$
\begin{align}
(x\in A\land y\in B)\lor(x\in C\land y\in D)&\overset{(!)}{\implies}(x\in A \lor x\in C)\land(y\in B\lor y\in D)\\
&\Longleftrightarrow[x\in(A\cup C)]\land[y\in(B\cap D)]\\
&\Longleftrightarrow(x,y)\in[(A\cup C)\times(B\cap D)].
\end{align}
$$ but I couldn't explain why $(!)$ would imply my next step. One can easily see why equality wouldn't hold for $A=\{a\},\;B=\{b\},\;C=\{c\},\;D=\{d\}$ so my best bet for now is this implication.","['elementary-set-theory', 'proof-verification']"
2066584,Find an explicit surjection $f : \mathbb{Z_+} \to \mathbb{Z_+} \times \mathbb{Z_+}$,"Find an explicit surjection $f : \mathbb{Z_+} \to \mathbb{Z_+} \times \mathbb{Z_+}$ I was recently posed this question by a fellow Math.SE user on the main chat room, and I had two ideas. Idea 1 (Which I think is incorrect) Define $f$ such that $f(x) = ((x, i))_{i \in \mathbb{Z_+}}$ The idea here was to define a function for a specific $x \in \mathbb{Z_+}$ and have the function range over all $i \in \mathbb{Z_+}$, which as I thought would define a surjective function from $\mathbb{Z_+}$ to $\mathbb{Z_+} \times \mathbb{Z_+}$ Idea 2 Define $f$ such that $f(x) = ((x, y))_{y\ \leq \ x}$ and $y \in \mathbb{Z_+}$. The idea here, was to use a sort of diagonolisation argument to define a surjective function. In this case $f(3) = \{(3, 0), (3, 1), (3, 2), (3, 3)\}$ (or at least that's what I'm hoping the function would produce) Are either of the functions I defined surjective? Are they even correct? The notation I had used bugged me a bit, and I'm not even sure if I've defined (or even it's possible to define functions this way) correctly.","['elementary-set-theory', 'functions', 'proof-verification']"
2066609,Solve $f'(ax+by)=[f(y)-f(x)]/(y-x)$,"Let $a,b$ be two reals. Find all differentiable functions $f$ satisfying: $$f'(ax+by)= \frac{f(y)-f(x)}{y-x}$$ for all $y\neq x$. I have solved the problem but my solution is not as elegant as I would like it to be so I'm hoping someone can post their solution. The answer is: If $a=b=0.5$, the solution set is all quadratics; else, the solution set is all linear functions. A brief outline of my method, for which the key idea is l'Hopistal: First I show that $f$ is of class $C^2$ on $\mathbb{R}$. Then fix $x=x_0$ and take the limit of both sides of the given equation as $y \to x_0$, applying l'Hospital to the right side. We find that $f'(x_0)=f'[(a+b)x_0]$. Thus $f'(x)=f'[(a+b)x]$ for all $x$. Next, keeping $x=x_0$ fixed we differentiate both sides of the original equation w.r.t $y$ and take the limit again as $y \to x_0$, applying l'Hospital once more. You find $2bf''((a+b)x_0)=f''(x_0)$. But since $f''[(a+b)x_0](a+b)=f''(x_0)$, either $f''(x_0)=0$ for all $x_0$ or $a=b$. The first case implies that solutions are polynomials of degree at most $2$. The second case is easily dealt with by setting $a=b$ and $y=-x$ in the original equation.","['real-analysis', 'ordinary-differential-equations', 'functions']"
2066657,"On the integral $\int_0^\infty J_0(x)\,dx$","I'm not sure if the following result is correct, but I also have no clue where I could have possibly made a mistake. \begin{align}
\int_0^\infty J_0(x)\,dx &= \frac{1}{2}\int_{-\infty}^\infty J_0(x)\,dx \tag1\\
&=\frac{1}{4\pi}\int_{-\infty}^\infty \int_{-\pi}^\pi e^{ix\cos\phi} \, d\phi \, dx \tag2\\
&=\frac{1}{4\pi}\int_{-\pi}^\pi \int_{-\infty}^\infty e^{ix\cos\phi} \, dx \, d\phi \tag3\\
&=\frac{1}{2}\int_{-\pi}^\pi \delta(\cos\phi)\,d\phi \tag4\\
&=\frac{1}{2}\int_{-\pi}^\pi \left[\sum_{n=-\infty}^\infty \delta\left(\phi-\left(n+\frac{1}{2}\right)\pi\right)\right] \, d\phi \tag5\\
&=\frac{1}{2}\cdot 2 = 1 \tag6
\end{align} In $(1)$, I used the fact that $J_0(x)$ is even. In $(2)$, I used the integral representation of the Bessel Function of the First Kind. In $(3)$, I used Fubini's Theorem to interchange orders of integration. In $(4)$, I used the complex definition of the Delta Function. In $(5)$, I used the fact that $\delta(f(x)) = \sum\frac{\delta(x-x_i)}{|f'(x_i)|}$, where the $x_i$ are the roots of the function $f(x)$. In $(6)$, I used that only two delta functions contribute to the integral - the ones with singularities at $\pm\frac{\pi}{2}$, and the integral over each of these singularities is $1$. However, the reason that I am doubting my result is because the Bessel Function $J_0(x)$ looks somewhat like $\frac{\sin(x)}{\sqrt{x}}$ for large $x$ and actually encloses a larger area with the $x$-axis close to $0$ (as $J_0(0)= 1$, whereas $\lim\limits_{x\rightarrow 0}\frac{\sin(x)}{\sqrt{x}}=0$). Therefore, I would expect  that $$\int_0^\infty J_0(x) \, dx \geq \int_0^\infty \frac{\sin(x)}{\sqrt{x}} = \sqrt{\frac{\pi}{2}}\approx 1.25$$ would hold. Is my intuition wrong here, and if so, which part of my intuition is off? Or have I made a computational mistake somewhere?","['bessel-functions', 'integration', 'definite-integrals']"
2066678,Math inverse Matrix with variable,"So it's just a few days before my math exam and I came across this excercise and I just can't seem to find the right answer. Would really appreciate your help on this one. It's from a german textbook so please excuse any grammar mistakes: d 'is celebrating a party. a, b and c are doing a drinking game. They all drink the same from same size glasses:' I: a and b together drank as much as c.
II: a and c together drank 4 times as much as b
III: a drank n more glasses then b 1) I need to find out the Linear System of Equations. So I would assume: I: a + b = c
II: a + c = 4b
III: b + n = a To write the matrix it in the form of: A*X = B: => I: a + b - c = 0
=> II: a - 4b + c = 0
=> III: -a + b + n = 0 (please correct if I'm wrong) next: 2) Find the inverse Matrix with the Gauß-Jordan-Algorithm This is my solution for the inverse Matrix Is that correct? This is where I had a lot of problems with. Because of that extra variable n in the matrix. 3) From that inverse matrix i have to find universal solution where I just have to put in n to solve. Don't really know what to do here. If I take my inverse matrix and multiply it by B wich is (0 0 0) all my values for a,b,c would get 0... So don't really know how to proceed... 4) I just need to try different values for n and show the Equations for different n values. Would really really appreciate any kind of help. I've been working on this for more than 3 hours and I just can't seem to find the answer. Thank you in advance !","['matrices', 'matrix-equations', 'gaussian-elimination', 'linear-algebra']"
2066681,Find an injection from $\mathbb{Z_+}^n \to \mathbb{Z_+}$,"Find an injection from $\mathbb{Z_+}^n \to \mathbb{Z_+}$ This is what I did. Define $f : \mathbb{Z_+}^n \to \mathbb{Z_+}$ such that $$f\left(((x_i)_{i \in \mathbb{Z_+}}\right) = x_1$$ If I scrapped the notation, it would essentially be the following function  $f((x_1, x_2, \ldots)) = x_1$ Would this function define an injection? Furthermore, I'm not sure if I've made correct use of notation? Is there are better, cleaner way of finding an injective function mapping $\mathbb{Z_+}^n \to \mathbb{Z_+}$?","['elementary-set-theory', 'notation', 'functions', 'proof-verification']"
2066750,"Bezout in $\mathbb C [x,y]$ [duplicate]","This question already has an answer here : Irreducible polynomials and affine variety (1 answer) Closed 7 years ago . Let $f_1, f_2 \dots, f_r \in \mathbb C [x,y]$ and suppose $$\gcd(f_1, \dots , f_r)=1$$ Show that $V(f_1, \dots , f_r) \subset \mathbb A^2$ is finite. Partial Solution: suppose $(x_0,y_0) \in V(p(x,y),q(x,y))$, then for $(x,y_0)$ we can use Bezout and say that exist $a(x),b(x),h(x) \in \mathbb C [x]$ such that $$ a(x)p(x,y_0) + b(x)q(x,y_0)=h(x)$$ So there are finite $x_i \in \mathbb C$ such that $(x_i,y_0)\in V(p(x,y),q(x,y))$. The same holds for $(x_0,y)$.","['ring-theory', 'polynomials', 'algebraic-geometry', 'commutative-algebra']"
2066765,Subspaces of $\ell^{2}$ and $\ell^{\infty}$ which are not closed?,Are there any examples of subspaces  of $\ell^{2}$ and $\ell^{\infty}$ which are not closed?,"['functional-analysis', 'general-topology', 'examples-counterexamples', 'lp-spaces']"
