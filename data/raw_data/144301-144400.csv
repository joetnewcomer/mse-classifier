question_id,title,body,tags
2349374,Odds of guessing a sequence of cards in order,"For a deck of 52 cards, find the number m such that $P$(by random guessing we get more than m correct guesses) < $1/10000.$ I was thinking along the lines of - if there is m correct guesses, there are $(52-m)!$ possible arrangements with a correct guess. So the probability of m correct guesses is $(52-m)!/52!=k$ and the solution is given by $k<1/10000$. Is my reasoning correct? If not how to solve this problem?","['self-learning', 'probability']"
2349388,Find the minimum value of $P=\sum _{cyc}\frac{\left(x+1\right)^2\left(y+1\right)^2}{z^2+1}$,"For $x>0$, $y>0$, $z>0$ and $x+y+z=3$ find the minimize value of $$P=\frac{\left(x+1\right)^2\left(y+1\right)^2}{z^2+1}+\frac{\left(y+1\right)^2\left(z+1\right)^2}{x^2+1}+\frac{\left(z+1\right)^2\left(x+1\right)^2}{y^2+1}$$ We have: $P=\left(\left(x+1\right)\left(y+1\right)\left(z+1\right)\right)^2\left(\frac{1}{\left(z+1\right)^2\left(z^2+1\right)}+\frac{1}{\left(y+1\right)^2\left(y^2+1\right)}+\frac{1}{\left(x+1\right)^2\left(x^2+1\right)}\right)$ $\ge \left(\left(x+1\right)\left(y+1\right)\left(z+1\right)\right)^2\left(\frac{1}{2\left(z^2+1\right)^2}+\frac{1}{2\left(x^2+1\right)^2}+\frac{1}{2\left(y^2+1\right)^2}\right)$ $\ge \left(\left(x+1\right)\left(y+1\right)\left(z+1\right)\right)^2\left(\frac{9}{2\left(\left(z^2+1\right)^2+\left(y^2+1\right)^2+\left(x^2+1\right)^2\right)}\right)$ I can't continue. Help","['inequality', 'cauchy-schwarz-inequality', 'multivariable-calculus', 'maxima-minima', 'uvw']"
2349427,Help understand an inequality in a proof,"Assume standard inner product and 2-norm. $A$ is any symmetric real-valued $n\times n$ square matrix. $V_k$ is an $n\times k$ matrix whose columns are orthonormal. $T_k$ is a matrix such that it has the following relation with $A$ and $V_k$: $AV_k=V_kT_k+{\hat v}_{k+1}e_k^T$ where ${\hat v}_{k+1}$ is another vector orthogonal to every column of $V_k$, and $e_k^T = (0,...,0,1)$ is a vector with only the $k$th component being 1. I need to understand the following proof, but got stuck at an inequality. This is a proof about the error bound of Lanczos iteration. Above proof uses In order to apply Cauchy-Schwarz, which is $<x,y>\le \|x\|\|y\|$, we need to place absolute value operator on both the LHS and RHS of (10.26), but I have trouble understanding how the LHS of (10.26) becomes the LHS of (10.27). Many thanks! PS: the whole thing for those who are interested. the theorem in question is the last one.","['matrices', 'numerical-methods', 'linear-algebra']"
2349439,Topological groups on the circle $S^1$ [duplicate],"This question already has answers here : How many group structures make $S^1$ a topological group? (3 answers) Closed 6 years ago . On the circle $S^1$ there is the usual circle group , i.e. the group isomorphic to $\{e^{i\varphi}\mid \varphi\in[0,2\pi)\}$ with complex multiplication as group operation. This group is a topological group in the sense that $S^1$ is a topological space and the group operation and the inverse are continuous. Question: Are there other topological groups on $S^1$ essentially different from the circle group, assuming $S^1$ with the standard topology? What about other abelian topological groups? My question was motivated by this other post. The group described there turned out to be just the usual one. Two notes: I am looking for groups involving all of $S^1$, not only a subset. Especially no subgroups of the circle group. I am looking for groups not isomorphic to the circle group.","['circles', 'examples-counterexamples', 'topological-groups', 'general-topology', 'group-theory']"
2349446,A complex function integral,"I got a problem in an exam.
We need to caculate following limit: $$\lim_{x\rightarrow \infty} \int_{L_x}\frac{\cos z}{z^2+1} dz,$$ where $L_x$ is the line from $-x+2i$ to $x+2i$ . Of course we can calculate the integrals of the real part and imaginary part seperately. But it would be extremely complicated. I think it can't be the right solution since it wouldn't be done in the time of an exam.","['complex-analysis', 'calculus']"
2349462,Finding the mgf when moments are given,"Let $X$ be a random variable and it is known that the mgf of $X$ exists. If the $k$th moment is given by $m_k=\mathbb E[X^k]=\frac{(2k+1)!}{k!2^k}$ for $k=0, 1, ...$ Problem: Find the mgf of $X$. My attempt: The mgf of $X$ is $M_X (t)= \sum_{k=0}^\infty \frac{m_k}{k!}t^k=\sum_{k=0}^\infty \frac{(2k+1)!}{(k!)^22^k}t^k$. However, I have no idea how to proceed further. What should I do?","['statistics', 'probability', 'moment-generating-functions']"
2349467,Fundamental group of 2 copies of $\mathbb{R}P^2$ glued along a common $\mathbb{R}P^1$,"I was working on questions about computing fundamental groups from past qualifying exam papers and I wanted to know if I'm going about it correctly. The question reads Recall that the standard embedding of $\mathbb{R}P^1$ in $\mathbb{R}P^2$ is the image of the equator under the 2-fold cover $\pi : S^2 \to \mathbb{R}P^2$ given by $\pi (x) = \pi (-x)$. Let $X$ be the union of two projective planes glued via the identity map of the standardly embedded $\mathbb{R}P^1$s. Compute the fundamental group of $X$. My idea was to consider $\mathbb{R}P^2$ as an upper hemisphere with the boundary circle identified by the antipodal map. This boundary circle (when sent to the quotient) is $\mathbb{R}P^1$. Now instead of gluing after sending to the quotient, I thought of gluing before, so that effectively you take two hemispheres, glue them along the boundaries and apply the antipodal map to the boundary circle. Now, applying Seifert-van Kampen, I have one generator $x$ for one copy and another generator $y$ for the other copy, satisfying $x^2 = y^2 = e$. For the amalgamation, the inclusions of the generator of the intersection into either $\mathbb{R}P^2$ are $x^2$ and $y^2$ respectively, so the new relation is $x^2y^{-2} = e$ which is already true. So we get $\pi _1 (X) = \langle x, y | x^2 = y^2 = e \rangle$ which is just $\mathbb{Z}_2 * \mathbb{Z}_2$ Is this correct? Because this is also the fundamental group of $\mathbb{R}P^2 \vee \mathbb{R}P^2$, so I'm kind of unsure.","['algebraic-topology', 'general-topology', 'fundamental-groups']"
2349475,How do we take the Frechet derivative here? A question concernig a paper on the Kuramoto model,"In the paper ""DYNAMICAL ASPECTS OF MEAN FIELD PLANE ROTATORS
AND THE KURAMOTO MODEL"" by  L. Bertini, G. Giacomin, AND K. Pakdaman we read $$\partial_t q_t(\theta)=\frac12\frac{\partial^2q_t(\theta)}{\partial\theta^2}+K\frac{\partial}{\partial\theta}\left[\left(\int_{\mathbb{S}}\sin(\theta-\theta')q_t(\theta')\,\mathrm{d}\theta'\right)q_t(\theta)\right],\tag{1.9}$$ and further on, we see $1.3.$ The gradient flow viewpoint. For our purposes the following fact is of crucial importance: $(1.9)$ can be reqritten in the gradient form $$\partial_t q_t(\theta)=\nabla\left[q_t(\theta)\nabla\left(\dfrac{\delta\mathcal{F}(q_t)}{\delta q_t(\theta)}\right)\right],\tag{1.18}$$ where we use $\nabla$ for $\partial_\theta$ for visual impact, $\delta\mathcal{G}(q)/\delta q(\theta)$ is the standard $L^2$ Frechet derivative of the function $\mathcal{G}$ and $$\mathcal{F}(q):=\frac{1}{2}\int_{\mathbb{S}} q(\theta) \log q(\theta)\,\mathrm{d}\theta-\frac K2\int_{\mathbb{S}^2}\cos(\theta-\theta')q(\theta)q(\theta')\,\mathrm{d}\theta\,\mathrm{d}\theta'.\tag{1.19}$$ I am having trouble finding (1.18). I think the difficulty lies in computing the Frechet derivative. Attempt When computing a Frechet derivative we are looking for a transformation $A$ such that
$$\frac{\|f(x + v) - f(x) - Av\|}{\|h\|} \xrightarrow[h \to 0]{} 0 $$ The norms here are $L^2$ norms on the space of functions on $S = [0,2\pi)$ with the Lebesgue measure. So $h$ is a vector in $L^2(S)$. A first question is: What do we mean when we say $ \frac{\delta \mathcal{F(q_t)}}{\delta q_t(\theta)}$? Are we taking the derivative in the direction of the function $q_t$? More precisely  are we computing $$\lim_{h \to 0}\frac{\mathcal{F}(q_t + hq_t) - \mathcal{F}(q_t)}{h} ? \tag{*}$$ In this case we obtain: $$ \lim_{h\to 0} \frac{1}{2} \frac{1}{h}\int_S (q_t(\theta) + h q_t(\theta)) \log(q_t(\theta) + h q_t(\theta)) - q_t(\theta) \log (q_t(\theta)) d\theta\\
- \frac{K}{2}\frac{1}{h}\int_{S^2} \cos(\theta - \theta')\{ [q_t(\theta) + hq_t(\theta)][q_t(\theta') + hq_t(\theta')] - q_t(\theta) q_t(\theta')\} d\theta d\theta'  \\
= \frac{1}{2} \int_S q_t(\theta) +  q_t(\theta) \log(q_t(\theta))\, d\theta \\
- \frac{K}{2}\int_{S^2} \cos(\theta - \theta')\{ 2q_t(\theta) q_t(\theta')\} d\theta d\theta' 
$$ However, when computing the derivative $\partial_\theta  \frac{\delta \mathcal{F(q_t)}}{\delta q_t(\theta)}$ this is zero, once the value above does not depend on $\theta$ since we integrated on $\theta$. So this derivative makes no sense for our purposes. Maybe we should note that  the denominator of $ \frac{\delta \mathcal{F(q_t)}}{\delta q_t(\theta)}$ has a $\theta$. So this should mean that we are differentiating in a direction that depends on $\theta$. Maybe we should compute $$ \lim_{h\to 0} \frac{1}{2} \frac{1}{h}\int_S (q_t(u) + h q_t(\theta)) \log(q_t(u) + h q_t(\theta)) - q_t(u) \log (q_t(u)) du\\
- \frac{K}{2}\frac{1}{h}\int_{S^2} \cos(u - u')\{ [q_t(u) + hq_t(\theta)][q_t(u') + hq_t(\theta')] - q_t(u) q_t(u')\} du du'  \\
= \frac{1}{2} \int_S q_t(\theta) +  q_t(\theta) \log(q_t(u))\, du \\
- \frac{K}{2}\int_{S^2} \cos(u -u')\{ q_t(\theta)q_t(u) + q_t(u') q_t(\theta)\} du du' 
$$ Still I don't see how this could be compatible with (1.9) Any ideas?",['functional-analysis']
2349481,Find The Maximum Of $|z^2-3z+2|$ at $|z|\leq 1$,Find the maximum points of $|z^2-3z+2|$ at $|z|\leq 1$ Because $z^2-3z+2$ the function is analytic on the interior of $|z|\leq 1$ the maximum will be obtained on the boundary. Let $z=e^{it}$ where $0\leq t \leq 2\pi$ So the function is $e^{2it}-3e^{it}+2$ now I want to look at the boundry so I should take $|e^{2it}|-3|e^{it}|+2$?,"['inequality', 'complex-numbers', 'maxima-minima', 'complex-analysis', 'absolute-value']"
2349523,Conditional Probability: Bridge Hand given north and south has 8 spades,"I apologise as I'm pretty certain I could find the actual answer myself on these boards (as in the solution to the problem) but if possible I'd like it if someone can confirm whether my thinking is correct. In the card game bridge, the entire 52 cards are dealt out equally to
4 players, E/W/N/S if N and S have a total of 8 spades among them,
what is the probability E has 3 of the remaining 5 spades? This is example 2c on page 60 in ""A First Course in probability 8th edition"" and gives the solution as $$\frac{{{5}\choose{3}}{{21}\choose{10}}}{{26}\choose{13}}\approx .339$$ Later in the book, it asks to recalculate this using conditional probability (question 3.3 page 102): Compute the conditional probability that E has 3 spades given North
and South have a combined total of 8 spades. My answer is then as follows: Let E be the event that E has 3 spades. and F the event that N and S have 8 spades. Then $P(E)=\frac{{{5}\choose{3}}{{21}\choose{10}}}{{26}\choose{13}}$ as it is given that 26 cards have already been dealt to N and S, of which 8 of the 13 spades have also been dealt. This means for E to occur we have to choose 3 of the remaining 5 spades and any combination of 10 cards remaining from the 21 leftovers (that is 26 remaining cards minus the 5 spades). All are divided by the reduced sample space. (This is one of the parts in which I want to be certain) As we only care about E we can consider N and S to be one person which will be dealt 26 cards, 8 of which must be spades, giving $P(F)=\frac{{{13}\choose{8}}{{39}\choose{19}}}{{52}\choose{26}}$ this reasoning seems right to me as the two of them should receive any combination of 26 cards so long as 8 of them are spades. (We don't care if N has all 8 or if S has all 8.) Then our conditional Probability is $$P(E|F) = \frac{P(E\cap F)}{P(F)}.$$ My major issue is I'm not sure how I would go about calculating $P(E\cap F)$ in this instance. Logically I argue that the two events P and F are independent of each other, meaning $$P(E\cap F)=P(E)P(F)$$ and so making our final conditional probability $P(E|F)=P(E)$ which yes does give me the right answer, but unless the question specifically states that these are independent of each other, I would then have to prove that $P(E\cap F)=P(E)P(F)$ holds surely? Any clarification would be greatly appreciated. thank you.","['combinatorics', 'probability', 'card-games']"
2349544,Calculating the probability mathematically,"A football player's performance is recorded as 'well' or 'bad'. The probability of the football player performing well after the day he performed well is $3/4$. The probability of him performing bad after the day he performed bad is $1/2$. Given that this player has performed bad on Monday, what is the probability of him performing well on Friday ? $\left(~4\ \mbox{days later}~\right)$. I was able to solve this problem using a large tree diagram. But using a tree diagram for these type of question is not the best option as it is easy to make mistakes in the middle and it takes a lot of time. How to I set this situation mathematically ?.",['probability']
2349587,what is smallest possible value of range of $7$ values given that their mean is $12$ and their median is $9$,"what is smallest  possible  value  of range of $7$ values given that their mean is $12$ and their median is $9$ :- a) $3$ B) $6$ C) $7$ D) $8$ What is the proper approach to solve this problem , is there any relation or inquality that help ? What if we need the largest possible value? Thank you for your help","['statistics', 'probability']"
2349607,"If $f_{n}\to f$ in measure, then $f_{n} \cdot g \to f \cdot g$ in measure","This question has been asked in SE before, but my question asks to prove in a different way. Let $E$ be a set of finite lebesgue measure. $\{\ f_{n} \}\ \to f$ in measure on $E$, and $g$ be a measurable function which is finite a.e on $E$. Prove that $f_{n}.g \to f.g$ in measure. Deduce from that $\{\ f_{n}^{2} \}\ \to f^{2} $in measure. Infer from this that if $\{\ g_{n} \}\ \to g $ in measure on $E$, then $\{\ f_{n} \cdot g_{n} \}\ \to f \cdot g$ in measure on $E$. I have shown the first part. But I am struggling to show that $\{\ f_{n}^{2} \}\ \to f^{2}$ in measure. What I have is there exists a subsequence $f_{n_{k}}$ of $f$, such that $f_{n_{k}} \to f$ a.e on $E$. Now we have $f_{n_{k}}^{2} \to f^{2}$ a.e on $E$. Then since $E$ is of finite measure we have $f_{n_{k}}^{2} \to f^{2}$ in measure on $E$. But how to get $f_{n}^{2} \to f$ in measure on $E$. For the last part it seems that I have to prove that any linear combination of sequences converging in measure  also converge in measure. Then  I have to use that $$2f_{n} \cdot g_{n}=(f_{n}+g_{n})^{2}-f_{n}^{2}-g_{n}^{2}$$ Is that right? What to do about the second part and how to use the first part in the second part? Thanks in advance!!","['lebesgue-measure', 'measure-theory', 'convergence-divergence']"
2349622,Shifrin's Multivariable Mathematics,"I'm taking multivariable calc this fall. I began self-studying on my own a couple months ago, using Salas's calc text. Then I stumbled on Ted Shrifin's MTH3500/10 incredible lecture series on Youtube. His text, Multivariable Mathematics, arrived in the mail yesterday evening! It's a freakin' gorgeous book, and I'm super excited to start. I have three questions. (1) Question for anyone that's worked or taught from this book: In terms of coverage, how does this book compare with something like Munkres, Calculus on Manifolds? Is there significant overlap? Will I be prepared for Munkres after reading Shifrin? (2) I decided I had to have the book after bing-watching the lectures. The ideas there are just so lovely, and so nicely explained. The idea of linear maps is a beautiful one, and I'm amazed at how it generalizes the results of single-variable calc. Matrices, matrix multiplication, and the like can seem so unmotivated and pointless, until one sees that matrix multiplication is the algebra behind the composition of linear maps. Historically, was it the need to put multivariable calc on a sound footing that motivated the development of linear algebra? (3) I'll be taking linear algebra in the fall, too. I wonder: Why (or how!) would anyone successfully teach linear algebra without using multivariable calculus and the geometry of linear maps to reify matrices and their symbol-shunting? I mean, Shifrin strives to show the connection between linear algebra and multivariable calc, and this is an unusual approach, right? But then how else would linear algebra be taught?",['multivariable-calculus']
2349648,A question about Finite Element Method.,"Can we solve a matrix differential equation $\textbf{X}'(t)=\textbf{A}\textbf{X}(t)+\textbf{B}(t)$ by Finite Element Method? I will be very happy if you give some special example or suggest some books about the method for solving matrix differential eauations. In here, 
\begin{equation}
\begin{aligned}
&\textbf{X}(t)=\left( \begin{array}{cccc}
x_{1}(t) \\
x_{2}(t) \\
x_{3}(t)\\
x_{4}(t) \end{array} \right), \textbf{A}
=
\left( \begin{array}{cccc}
a_{11} & a_{12} &a_{13} & a_{14}\\
a_{21} & a_{22} & a_{23} & a_{24} \\
a_{31} & a_{32}& a_{33} & a_{34} \\
a_{41} & a_{42} & a_{43} & a_{44}
\end{array} \right),\\
&\textbf{B}(t)=\left( \begin{array}{cccc}
b_{1}(t)\\
b_{2}(t)\\
b_{3}(t)\\
b_{4}(t) \end{array} \right).
\end{aligned}
\end{equation}
initial conditions:
$$x_1(0)=m_1$$
$$x_2(0)=m_2$$
$$x_3(0)=m_3$$
$$x_4(0)=m_4.$$","['numerical-methods', 'ordinary-differential-equations', 'finite-element-method']"
2349660,"Universal differential identities, part 2","This is a follow-up of this question . Let $$F(f,f_{x_1},f_{x_2},\dots,f_{x_n},f_{x_1x_2},f_{x_1x_3}...)=0$$ be an identity relating some finite number of derivatives of a map $f:\mathbb{R}^n \to \mathbb{R}$. Suppose it is satisfied by all smooth maps. Must $F$ be the trivial identity, i.e the zero map? (Note we already take into account the equality of mixed derivatives, i.e for each pair $x_i,x_j$ we have as an argument only one of 
 the expressions $f_{x_ix_j} \,,\,f_{x_jx_i}$). The previous question was about the special case where $F$ was a polynomial identity. The point of the current generalization is to rule out the existence of non-trivial universal identities such as $\sin(f_x)=f_y$. (This particular identity is represented by $F(x_1,x_2,x_3)=\sin x_2-x_3$).","['multivariable-calculus', 'real-analysis', 'differential-operators']"
2349690,Problem on Triangles and Circles,"I was solving this question, and I'm hitting a wall. The circle $ω$ touches the circle $Ω$ internally at $E$. The centre $A$ of $Ω$ is outside $ω$. Let $BD$ be a diameter of $Ω$ which is also tangent to $ω$. Assume $ED >EB$. Let $ED$ intersect $ω$ at $F$. If $DF=2EF$, what is the magnitude of $EDB$ in degrees? This is the diagram I made: I know that $\angle{BED}=90°$, so $DE^2+BE^2=4AD^2$. I think that I could construct a line from $F$, cutting $BD$ at $G$, so that $BE||FH$, and then using similarity, but I'm unsure. Can anyone help?","['contest-math', 'geometry']"
2349701,"If $T^m$ is diagonalizable for a $m\in\mathbb N$, then $T$ is diagonalizable.","Suppose that $V$ is a finite dimensional $\mathbb C$-vector space, and suppose that $T:V\rightarrow V$ is injective. If there is a $m\in\mathbb N$ such $T^m$ is diagonalizable, then $T$ is diagonalizable. I've found the proof for the case that $T^m=Id$, but I can't adapt it to this case.","['linear-algebra', 'linear-transformations']"
2349715,How rigorous must my set theory proof be?,"I'm working on a problem from the book ""Introduction to Topology"" by Bert Mendelson: If $A_1\subset A_2, A_2\subset A_3, \ldots , A_{n-1}\subset A_n$, and $A_n \subset A_1$, prove that $A_1=A_2=\cdots=A_n$. I know how to prove this, but my question is how rigorous my proof should be. For example, to make my proof easier, I proved the following ""lemma"": If $H$ and $J$ are sets, $H \subset J$, and $J\subset H$, then $H=J$. My proof went like this: From the givens, we can determine that
  $$\alpha \in J, \forall \alpha \in H$$
  $$\beta \in H, \forall \beta \in J$$
  Which means that
  $$\alpha \in J, \forall \alpha \in H$$
  $$\neg \beta \notin H, \forall \beta \in J$$
  and so $H=J$. I then went on to prove that
$$A_k\subset A_{k+1}, A_{k+1}\subset A_k, \forall k \le n$$ Is my ""lemma"" proof enough of a proof? This is such a basic lemma that it seems like it should be obvious... but then again, when something seems obvious, it sometimes isn't. Is this rigorous enough? Is it too rigorous?","['proof-writing', 'elementary-set-theory']"
2349730,Is there a closed form formula for the recursive sequence: $x_n = x_{n-1} + \alpha\sqrt{x_{n-1}}$,"I saw this link for closed form formula for a recursive sequence ( How to derive a closed form of a simple recursion? ) However, what if my formula is:
$$x_n = x_{n-1} + \alpha\sqrt{x_{n-1}} \quad \text{ and } \quad x_0 = \beta \quad \text{ and }\quad\alpha,\beta> 0$$ Is there a closed form solution to determine the value of $x_n$ for a given $n$? Bonus: If there is a closed form solution, is there an inverse? That is, if one is given a value $y$, can one deduce the closest $n$ such that $x_n$ is the closest to $y$ compared to any other possible $x_n$ value? I couldn't figure out the mathemical formula for either question. Since we're CS engineers, we know that we could create a lookup table for the first 1 million values of $n$ and that should work for us. (It's arguably a reasonable solution, since we need to compute $x_n$ for 100 million values of $n$ (so obviously, $n$ will be the same thousands of times and so precomputing is not such a bad idea.) But still, it would ""cleaner"" if there were a closed form analytical solution to the above recursive sequence that we could use/consider.","['recursion', 'sequences-and-series', 'closed-form']"
2349761,If $f(0) = 0$ and $|f'(x)|\leq |f(x)|$ for all $x\in\mathbb{R}$ then $f\equiv 0$ [duplicate],"This question already has answers here : Prove $f(x) = 0$ for all $x \in [0, \infty)$ when $|f'(x)| \leq |f(x)|$ (3 answers) Closed 6 years ago . Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuous and differentiable function in all $\mathbb{R}$. If $f(0)=0$ and $|f'(x)|\leq |f(x)|$ for all  $x\in\mathbb{R}$, then $f\equiv 0$. I've been trying to prove this using the Mean Value Theorem, but I can't get to the result. Can someone help?","['derivatives', 'real-analysis', 'continuity', 'analysis']"
2349772,"If twice-differiantiable $f$ satisfies $f(x)f''(x)=0$ for all $x\in\mathbb R$, then $f$ is a polynomial of degree at most $1$","Let $f: \mathbb R \to \mathbb R$ be a twice differentiable function such that$$f(x)f''(x)=0.\quad \forall x \in \mathbb R$$Then is it true that $f$ is a polynomial of degree at most $1$? I could not find any other function satisfying the condition, but could not prove that there are no other functions. Please help.","['derivatives', 'real-analysis', 'continuity']"
2349800,Chain rule and implicit functions problem,"I'm trying to solve a problem involving the implicit function theorem. I've come to a point where I must derive this implicit function with respect to it's coordinates and don't know how to proceed. Here is the problem: Prove that exists an implicit function $\varphi$ around the point $0$ with $\varphi (0) = 0$ such that $F(\varphi(y),y)=0$ $F: \Bbb R^2 \rightarrow \Bbb R$ , $F(x,y)= x^3 - x(y+1)+y^2$ Express $\varphi ' (y)$ in terms of $y$ and $\varphi(y)$ Find the Taylor polynomial of second degree of $g$ around the point $p=(1,-1)$ with $g(x.y)=\varphi(y+x^2)+xe^{y+1}$ The hypothesis for the implicit function theorem are true for $F$ around the point. And $F_x(0,0)\neq0$ . So the function exists. I have $\varphi'(y)=\frac{\varphi(y)-2y}{3 \varphi(y)^2-y-1}$ I want to find the equation for $g$ 's taylor polynomial but I'm confused on how to derive with respect to what in $g$ . $g_x(x,y)=\varphi'(y+x^2)2x+e^{1+y}$ and $g_y(x,y)=\varphi'(y+x^2)+xe^{1+y}$ Could anyone help me with this? Thanks. Update: As I have $\varphi'$ I only need to understand how to get the second order partial derivatives of $g$ .","['multivariable-calculus', 'implicit-function-theorem', 'partial-derivative', 'derivatives']"
2349830,Why $\bigwedge^{d-1}A=\bigwedge^{d-1}B \Rightarrow A= \pm B$,"Let $V,W$ be $d$-dimensional vector spaces, and let $A,B \in \text{Hom}(V,W)$. Consider the induced maps on the exterior algebras: $\bigwedge^{d-1}A,\bigwedge^{d-1}B :\Lambda_{d-1}(V) \to \Lambda_{d-1}(W)$. Suppose that 
$\bigwedge^{d-1}A=\bigwedge^{d-1}B$, and that $A,B$ are invertible. I want to prove that $A=\pm B$. (Note that this implies $A=B$ in the case $d$ is even). The assumption implies $$\bigwedge^{d-1}(AB^{-1})=\text{Id}_{\Lambda_{d-1}(V)}.$$ Hence, the problem reduces to showing that for $S \in \text{GL}(V)$  ,$$\bigwedge^{d-1}S=\text{Id}_{\Lambda_{d-1}(V)} \Rightarrow S=\pm \text{Id}_V.$$ I can show this by introducing an inner product and orientation on $V$, but this seems ""unnatural"" to me. Is there a proof which avoids this?","['differential-geometry', 'linear-algebra', 'exterior-algebra']"
2349841,Evaluate $\int\limits_0^1\frac{\log(1-x+x^2)\log(1+x-x^2)}{x}dx$,"I was doing experiments with Wolfram Alpha online calculator, about similar integrals (simpler than the below one) and wondered about how get a closed-form for $$\int_0^1\frac{\log(1-x+x^2)\log(1+x-x^2)}{x}dx\tag{1}.$$ I've calculated the definite integral using the online calculator, but I believe that the output is an approximation, and since after of this, I've asked to Wolfram Alpha about the indefinite integral, I know that Wolfram Alpha can calculate it, but to me is impossible to evaluate the terms (are about two pages) int log(1-x+x^2)log(1+x-x^2)/x dx Question. Is there some way to evaluate this integral in $(1)$? This was just a curiosity, but I am asking here if you know such integral or do you know how get the evaluation of our integral. Thanks in advance. Since Wolfram Alpha's answer seems to me difficult, I didn't any attempt (change or variable, integration by parts...).","['integration', 'definite-integrals']"
2350060,When Does $\sigma(q^k)$ Have a Prime Factor Greater Than $q$,"Let $q$ be prime and $k$ be a natural number. When does $\sigma(q^k)$ have a prime factor greater than $q$ ? We can slightly reduce the problem by noting that $$\sigma(q^k)=\frac{q^{k+1}-1}{q-1}$$ Thus if $p\nmid q-1$ , then $p\mid \sigma(q^k)$ if and only if $p\mid q^{k+1}-1$ . Clearly a prime $p>q$ does not divide $q-1$ , so $\sigma(q^k)$ has a prime factor greater than $q$ if and only if $q^{k+1}-1$ does. Using this restatement, if one takes a look at one of my answers to this question we see this is the case when $k+1\ge q$ letting $a=q$ , $b=1$ , and $n=k+1$ (note the question requires $b>1$ , but the proof only uses Zsigmondy's Theorem in which $b>0$ suffices). However clearly this is true in more than just this case. Can we describe all cases in which this is true, or at least expand the set of $(q,k)$ for which we know that this holds? Edit Lets define $\kappa(n)$ to be the smallest prime congruent to $1\mod n$ . A modified argument of that in the linked question, where we restrict $b$ to $1$ , leads one to conclude that there exists a prime $\ge \kappa(n)$ that divides $q^n-1$ . Thus if $$\kappa(k+1)\ge q$$ (or really $\kappa(k+1)\ge q-1$ since $q\nmid q^n-1$ ), then $\sigma(q^k)$ satisfies the problem, slightly increasing the set of valid $(q,k)$ .","['number-theory', 'prime-factorization', 'elementary-number-theory']"
2350098,Proving a basic property of integration without using Monotone Convergence Theorem,"I'm trying to prove the exercise 4.F of Bartle's book: The Elements of Integration and Lebesgue Measure. 4.F Employ Exercise 4.E to establish that if $f,g\in M^{+}(X,\mathcal{F})$ then $f+g\in M^{+}(X,\mathcal{F})$ and $$\int(f+g)d\mu=\int fd\mu+\int gd\mu.$$ Exercise 4.E: Let $f,g\in M^{+},$ let $\omega\in M^{+}$ be a simple function such that $\omega\leq f+g$ and let $\phi_{n}(x)=\sup\{(m/n)\omega(x): 0\leq 
m\leq n, (m/n)\omega(x)\leq f(x)\}.$ Also let $\psi_{n}(x)=\sup\{(1-\frac{1}{n})\omega(x)-\phi_{n}(x),0\}.$ Show that $$(1-\frac{1}{n})\omega\leq\psi_{n}+\phi_{n},\quad\phi_{n}\leq f,\psi_{n}\leq g.$$ I've proved exercise 4.E but I have problems proving 4.F My attempt:because of the problem 4.E we can assure that $\sup\int\omega d\mu=\int f d\mu.$ In fact, we have the existence of $\int f d\mu$ and $\int g d\mu.$ I think the proof is divided in two parts: proving the inequialities to get the desired equality. I don't get how utilize the previous result to finish this exercise. Any kind of help is thanked in advanced.","['real-analysis', 'measure-theory']"
2350100,"""Totally transitive"" polytopes which are not regular","Is it possible to have an abstract polytope which is vertex-transitive, edge-transitive, face-transitive, etc. (individually transitive on faces of each particular dimension) and yet not flag-transitive?","['polytopes', 'geometry']"
2350114,P(At Least 1 Boy Born on Tuesday out of 2 Children),"A family has two children. Given that at least one of the children is a boy who was born on a Tuesday, what is the probability that both children are boys? Assume that the probability of a child being born on a particular day of the week is 1/7. I'm wondering if there's a better way to calculate P(At least 1 boy born on a Tuesday) than the explanation. [In the solution, this is P(B) in Bayes' Theorem. Here is how they calculate: To calculate  we note that there are  14^2 = 196 possible ways to select the gender and the day of the week the child was born on. Of these, there are 13^2 = 169 ways which do not have a boy born on Tuesday, and 196 - 169 = 27 which do, so P(B) = 27/196. I understand this intuitively, but my statistics classes shy away from this ""naive"" definition of probability (although we do assume equally likely boy vs girl and day of the week for this problem). So is there a way I can calculate this P(B) in a more stepwise fashion (for example: {1/7 chance of born on Tuesday • 1/2 chance boy} + {1/2 chance boy • 1/2 chance other was not a boy • 1/7 chance of Tuesday • 6/7 chance the other was not}. I know the example I just wrote isn't correct but can someone intuit for me a way I could go about getting P(B) in this problem in a similar method? Perhaps I just need it illustrated. Note: I found another thread with this question but wasn't sure I understood the explanation. Perhaps someone has an enlightening comment to help.","['statistics', 'probability', 'calculus']"
2350117,Definition of the value of a function in Enderton's Elements of Set-Theory,"In chapter 3 of his book Elements of Set Theory, Enderton defines the value of a funtion $F$ at a point $x$ in its domain $\text{dom} \, F$ to be the unique $y$ such that $\langle x,y \rangle \in F$, and denotes it by $F(x)$. Then, he explicitly resolves to use this notation only when $F$ is a function and $x \in \text{dom} \, F$. Now consider the following problem (exercise 12 of the same chapter): Assume that $f$ and $g$ are functions and show that $$ f \subseteq g \iff  \text{dom} \, f \subseteq \text{dom} \, g \ \& \ (\forall x \in \text{dom}\,f) f(x) = g(x)$$ I'm having trouble going from the right to the left-hand side. It is intuitively clear to me that the implication is true. However, when trying to formalize my intuition, I get stuck. In particular, when trying to translate the statement $$(\forall x \in \text{dom}\,f) f(x) = g(x)$$ to a well formed formula (wff) , I don't know how to handle the fact that if $x$ is not in $\text{dom}\,g$, then the expression $g(x)$ is meaningless (according to the notational convention stated above). I am aware that if the other right-hand side condition, $\text{dom} \, f \subseteq \text{dom} \, g$, is true, then $g(x)$ will always be meaningful. However, this doesn't seem to be of any help in obtaining a wff for  the previous expression, which should be meaningful independently of any conjuncts we might attach to it. I attempted a few different interpretations, which I later fully translated to wffs: $\forall x [x \in \text{dom}\,f \implies \forall y \forall z (\langle x,y \rangle \in f \& \langle x,z \rangle \in g \implies y=z)]$ $\forall x [x \in \text{dom}\,f \implies (\text{$f$ and $g$ are functions defined over x} \implies \forall y \forall z (\langle x,y \rangle \in f \& \langle x,z \rangle \in g \implies y=z))]$ $\forall x [x \in \text{dom}\,f \implies (\text{$f$ and $g$ are functions defined over x} \implies \exists y (\langle x,y \rangle \in f \& \langle x,y \rangle \in g))]$ They all seem to be sufficient conditions for $f \subseteq g$, because they guarantee, together with the other premises, the equality of $f(x)$ and $g(x)$ for every $x \in \text{dom} \, f$. However, they are clearly not equivalent. Is there a true or real ambiguity in the statement of the problem or am I missing something?","['first-order-logic', 'elementary-set-theory']"
2350148,Accumulation points of a holomorphic function.,"I am reviewing some complex analysis and I have just gotten to the portion on analytic continuation. My question is about the proof of the following theorem: Theorem. Suppose $f$ is a holomorphic function in a region $\Omega$ that vanishes on a sequence of distinct points with a limit point in $\Omega$. The $f$ is identically zero. Proof. Suppose $z_0 \in \Omega$ is a limit point for the sequence $\{w_k\}$ and $f(w_k) = 0$. Chose a disc $D \subset \Omega$ centered on $z_0$, and consider the power series expansion of $f$ in $D$ 
$$f(z) = \sum a_n(z-z_0)^n$$
If $f$ is not identically 0, there exists a smallest $m$ such that $a_m\neq 0$. Then, $f$ can be rewritten as 
$$f(z) = a_m(z-z_0)^m(1+g(z-z_0))$$ where $g(z-z_0) \to 0$ as $z \to z_0$. Taking $z = w_k$, we obtain a contradiction since $a_m(w_k-z_0)^m \neq 0$ and $g(w_k-z_0) \neq 0$, but $f(w_k) = 0$ ... $\blacksquare$ The proof concludes the argument by using the connectedness of $\Omega$. However, my question is why must $1+g(w_k-z_0) \neq 0$.","['complex-analysis', 'holomorphic-functions', 'analytic-continuation']"
2350191,Reasons for defining sheaves of holomorphic and meromorphic functions on complex manifolds,"I am hoping this question is sensible and non-trivial. I am learning algebraic geometry at the moment, and have taken a strong liking to it. Unfortunately my complex analysis is weaker and I only know it at an undergraduate level. I am trying to transfer some of what I know in algebraic geometry to the language of complex analysis, particularly complex manifolds. My main question is, what are the benefits and drawbacks of defining the sheaf on a complex manifold (for the time being say a Riemann surface, or even just the Riemann sphere) in terms of holomorphic functions as opposed to meromorphic functions? From what I have gathered, meromorphic functions align better with the theory of discrete valuation rings on algebraic curves, since this provides a framework for studying poles. However it seems that holomorphic functions are taken to be the standard structure sheaf. What difference does this make, and why do you choose one over the other in certain situations? Does it make any difference to the sheaf cohomology? Does it make a difference if the surface is compact or not? Again, forgive me if this question is either trivial or not particularly meaningful, but I feel like it would massively boost the speed I can learn complex geometry if I can frame it in the language of ringed spaces and algebraic geometry. Any help is appreciated, or even some introductory notes that you think would help someone coming from my perspective. Thanks","['riemann-surfaces', 'complex-geometry', 'algebraic-geometry', 'complex-analysis', 'algebraic-curves']"
2350223,Largest cube that fits between spheres.,"Two spheres, one of radius 2 and the other of radius 4, have the same centre. What is the edge size of the largest cube that fits between them? (AMC Senior, 2015) diagram: https://i.sstatic.net/bMuix.jpg I tried taking a cross-section of the shape, and used Pythagoras but kept getting the (same) wrong answer. The answer is $\frac {2}{3}(\sqrt 22 - 2)$.","['optimization', 'solid-geometry', 'spheres', 'geometry', 'contest-math']"
2350273,Finding the global minimum of $x^{n}+x^{n-1}+...+1$ for even $n.$,"Inspired by this question, I am curious if there is an asymptotic of the global minimum of the function: $$f_n(x) = x^{2n}+x^{2n-1}+...+x^2+x+1.$$ In the referred question, I showed that $$f_n(x) = x^{2n}+x^{2n-1}+...+x^2+x+1 =x^{2n-2}(x+\dfrac{1}{2})^2+\dfrac{3}{4}x^{2n-4}(x+\dfrac{2}{3})^2+\dfrac{4}{6}x^{2n-6}(x+\dfrac{3}{4})^2+\dots+ \dfrac{n+1}{2n}(x+\dfrac{n}{n+1})^2+\dfrac{n+2}{2n+2}> \dfrac{n+2}{2n+2}.$$ 
 Since the method was completely elementary, I figured this was a loose bound. However, it turned out to be surprisingly close to the actual values for when $n=2,3$ and sharp $n=1.$ When $n=2$, the minimum is $0.673753\approx\dfrac{2}{3}=0.66$ and  when $n=3$, the minimum is $0.635\approx \dfrac{5}{8} = 0.625.$ Thus, is it possible to obtain an asymptotic for $\min_{x\in\mathbb{R}}f_n(x)$, as $n\to\infty?$ 
A closed form solution would be even better, but that just seem hopeless.","['real-analysis', 'polynomials', 'optimization', 'calculus']"
2350278,Taylor approximation to a matrix logarithm of a product of matrix exponentials,"Let $\mu_i,\nu_i\in\mathbb{R}^{n\times n}$ for $i\in{\{1,\dots,I\}}$, and let $\sigma\in\mathbb{R}$. Assume that $\log{\prod_{i=1}^I{\exp{(\mu_i)}}}$ exists with real entries. It must be the case that for some matrix $M\in\mathbb{R}^{n\times n}$: $$\log{\prod_{i=1}^I{\exp{(\mu_i+\sigma\nu_i)}}}=\log{\prod_{i=1}^I{\exp{(\mu_i)}}}+M\sigma+O(\sigma ^2 )$$ as $\sigma\rightarrow 0$. What is $M$? The derivative of an exponential of an arbitrary matrix function seems to be rather messy, but I was hoping  there would be a simpler answer thanks to linearity, and only being interested in first order terms. Further, by vectorising and using the properties of Kronecker products and commutation matrices, can one express $M$ in the form: $$\operatorname{vec}{M}=\sum_{i=1}^I{f_i(\mu_1,\dots,\mu_I)\operatorname{vec}{\nu_i}}\space\space\space\space\space ?$$ P.S. I've tagged this with the Lie group and Lie algebra tags as it's abundantly clear that much of the relevant results are in the more general case. But my knowledge of Lie theory is minimal, so it would be appreciated if answers could keep things as specific to real matrices as possible.","['matrices', 'matrix-calculus', 'perturbation-theory', 'lie-algebras', 'lie-groups']"
2350298,If $(X_n)_n$ is i.i.d. and $\frac{S_n}{n} \to a$ almost surely then $a=\Bbb E[X_1]$ [duplicate],"This question already has an answer here : If $(X_n)$ is i.i.d. and $ \frac1n\sum\limits_{k=1}^{n} {X_k}\to Y$ almost surely then $X_1$ is integrable (converse of SLLN) (1 answer) Closed 6 years ago . $(X_n)_{n \in \Bbb N}$ independent and identical. $S_n = \sum_{i=1}^n X_i$
Now I want to show: $$\frac{S_n}{n} \xrightarrow{\text{almost surely}} a, \mathrm{with}\: a \in \Bbb R\Rightarrow a=\Bbb E[X_1]$$
In our lecture we showed:
$(X_n)_{n \in \Bbb N}$ independent and identical, with $\Bbb E[X_1] \lt \infty$ , then $\frac{S_n}{n} \xrightarrow{\text{almost surely}} \Bbb E[X_1]$ In other words, either there's a problem with the uniqueness of the limit or the fact that we don't know from the start if the expectation values are finite. I'm stuck on this problem. Does someone have any ideas or tipps on how to solve this? Thanks in advance!","['law-of-large-numbers', 'probability-theory', 'probability-distributions']"
2350325,Do bounded derivatives imply equi-continuity of function sequence?,"Let $f_n: [0, 1] \rightarrow \mathbb{R}$ $\forall n \in \mathbb{N}$ If $f_n \in C^1([0, 1])$ and $\vert\vert f_n'\vert\vert_\infty \le 3 \Longrightarrow \{f_n\}$ are equicontinuous I know that bounded derivative for $f \in C^1([a, b])$ implies $f$ is Lipschitz, which implies uniform continuity.
I'm sure that it isn't true for the $\{fn\}$ sequence, because the previous one is an answer between other three, and it can't be the correct one. But I can't find a counter-example. If $\vert\vert f_n'\vert\vert_\infty \le 3$, $\{fn\}$ should be equi-Lipschitz (Lipschitz $\forall$ $n$), because $\exists$ $L > 0: \vert\vert f_n(x_1) - f_n(x_2) \vert \vert \le L \vert \vert x_1 - x_2 \vert \vert$ because of Lagrange theorem (we can use the ""biggest"" $L$ that is good $\forall$ $n$). But in that case, $\{f_n\}$ are equicontinuous, so I can't understand where I am wrong. Maybe I can't take the ""biggest"" $L$ because I could have infinite $L$s ($n \in \mathbb{N})$? Any help is appreciated, thanks! EDIT: The answer I checked as correct is:
$f_n \in C^0([0, 1])$ $\Longrightarrow $ they are equibounded because of Weierstrass theorem.
Indeed, $\exists \max f_n, \exists \min f_n \Longrightarrow f_n$ are bounded $\forall$ $n$ EDIT: So, Weierstrass lost, and bounded derivatives imply equicontinuity in my case!","['real-analysis', 'analysis']"
2350337,Why we define topology on vector space in functional analysis,"It is said that functional analysis is just infinite dimensional version of linear algebra. However, I am quite puzzled by this statement since we are mainly doing analysis on it. Another question is that why we want to define topology on vector space, is it because we can let the function to be continuous so that we can gain some benefit from it, e.x. the continuous map of a compact set is bounded. In other words, what we really care is just mapping itself regardless of the topology",['functional-analysis']
2350339,"If a random variable $X$ is measurable with respect to the tail $\sigma$-algebra, then it is constant a.s.","Consider Kolmogorov's Zero-One law: Suppose that $(X_n)_{n \in \mathbb{N}}$ is a sequence of independent
  random variables. Then any event belonging to the tail
  $\sigma$-algebra $\bigcap_{n \in \mathbb{N}}\sigma(X_n,X_{n+1},\dots)$
  has probability $0$ or $1$. Now the book says: Every random variable $X$ which is measurable with respect to the tail
  $\sigma$-algebra is a.s. constant. I do not quite see this, but I think it should be easy. So since $X$ is measurable with respect to the tail $\sigma$-algebra, we have that $$\{X \leq t\} \in \bigcap_{n \in \mathbb{N}}\sigma(X_n,X_{n+1},\dots)$$ for all $t \in \mathbb{R}$. Similarly also $\{X \geq t\}$. So by $$\{X = t\} = \{X \leq t\} \cap \{X \geq t\}$$ we get that $P(X = t)$ is either $0$ or $1$. Why should it be $1$ for some $t$? Or how does one see this?","['probability', 'measure-theory']"
2350358,If $(X_n)$ is simple random walk and $M_n=\max\limits_{0\leq k \leq n}X_k$ then $\tau_N = \min\{ n\mid X_n = M_N\}$ is not a stopping time,"Let  $(X_n)_{n\in\mathbb N}$ denote a simple, symmetric, random walk, defined by $X_0=0$ and $X_n = \sum\limits_{j=1}^n\xi_j$ where $(\xi_i)_{i \in \mathbb N}$ is i.i.d. with $\mathbb{P}(\xi_i = 1)= \mathbb{P}(\xi_i = -1) = \frac{1}{2}$. The maximum process of $(X_n)_{n\in\mathbb N}$ is defined by $M_n=\max\limits_{0\leq k \leq n} X_k$. I want to show that $$\tau = \min\{ n \in \mathbb{N} :X_n = M_{100}\} $$ is not a stopping time with respect to the natural filtration $\mathcal{(F_n)}_{n\in \mathbb{N}}$ of $(X_n)_{n\in\mathbb N}$. I know why it isn't a stopping time, but I don't know how to write a formal proof. Why I think it isn't a stopping time, is that $$\{ \tau = t\} = \{ X_0 \neq \max\limits_{0\leq k \leq 100} X_k\} \cap \{X_1 \neq \max\limits_{0\leq k \leq 100} X_k \}\cap \dots \cap \{ X_t = \max\limits_{0\leq k \leq 100} X_k\}$$
If it was a stopping time, then $\{ \tau = t\}$ must be in $\mathcal{F_t}$. But if $t<100$ , then we still need the information on all $X_{t+1} \dots X_{100}$ which are not in $\mathcal{F_t}$. Is my idea correct? How to prove it mathematically?","['random-walk', 'probability-theory', 'stopping-times']"
2350374,"How does one show that when almost complex structure is integrable, it takes the canonical form in a local patch?","On an arbitrary almost complex manifold, $M$, it is said that one can always find coordinates for which the almost complex structure $J$ takes the canonical form 
$$
J_p=\left[\begin{array}{cc}
    0 & -1 \\
    1 & 0 	\\
    \end{array}\right]
$$
at any given point $p$. In general, however, it is not possible to find coordinates so that $J$ takes the canonical form on an entire neighborhood of $p$. Such coordinates, if they exist, are called 'local holomorphic coordinates for $J$'. If $M$ admits local holomorphic coordinates for $J$ around every point then these patch together to form a holomorphic atlas for $M$ giving it a complex structure, which moreover induces $J$. $J$ is then said to be 'integrable'. My question is, how does one show that when local holomorphic coordinates exist, $J$ takes the canonical form in a local patch?","['complex-geometry', 'almost-complex', 'differential-geometry']"
2350386,How to evaluate the improper integral $\int_{0}^{\pi/2} (\frac{\pi}{2} - x)\tan(x)\ dx$,"I'm trying to compute $$\int_{0}^{\pi/2} (\frac{\pi}{2} - x)\tan(x)\ dx.$$ This is an improper integral and according to Mathematica, its value is $\frac{\pi \log(2)}{2}$. I can't expand the product because $\int_{0}^{\pi/2} \tan(x)$ and $\int_{0}^{\pi/2} x\tan(x)$ both diverge. I also don't see any obvious substitutions. If possible, I'd like to see a solution using elementary methods (i.e. no contour integration). In case this is relevant, I came across this integral when trying to find an alternate solution for this question. I started with $$ \int_1^{\infty}\frac{\ln x}{x\sqrt{x^2-1}}\ dx. $$ By integration by parts, this is equal to $$ -\log(x) \arctan(\frac{1}{\sqrt{x^2-1}})\Big|_1^\infty + \int_1^\infty \frac{\arctan(\frac{1}{\sqrt{x^2-1}})}{x}\ dx $$ The left term is $0$. For the right term, I substituted $x = \sec(u)$ and got the integral 
$$\int_0^{\pi/2} \arctan(\frac{1}{\tan(u)}) \tan(u) \ du.$$
Then, since $\tan(u)\geq 0$ for $u \in [0,\pi/2]$, I used the identity $\arctan(y) + \arctan(1/y) = \pi/2$ for all $y > 0$ to get the integral I'm asking about.","['real-analysis', 'alternative-proof', 'trigonometry', 'improper-integrals', 'integration']"
2350389,Number of pairs of nontrivial relatively prime divisors,"Given a number, $n=p_1^{a_1}p_2^{a_2}\ldots p_k^{a_k}$, how many pairs of divisors (excluding 1) that are relatively prime are there? For example: $n=2^2\cdot 3=12$. There are 6 distinct factors:$\{1,2,3,4,6,12\}$, and the only pairs of factors that are relatively prime to each other (excluding 1 of course) are $\{2,3\}$ and $\{2^2,3$}. There was a similar question posted some years ago: Number of Relatively Prime Factors . My thoughts are that it is the $\frac{P-1}{2}$ mentioned before, but removing the $(\tau(n)-1)$ pairs with 1 in them (where $\tau$ is the number of divisors function), making for a total of $\frac{P-1}{2}-\tau(n)+1$.","['number-theory', 'combinatorics', 'elementary-number-theory']"
2350410,Prove $C_n=B_{n-1}-B_{n-2}+\dots +(-1)^nB_1$,"If $C_n$ is the number of the ways to partition set $\{1,2,\dots ,n \}$ into subsets that has at least two members and $B_n$ is the number of the ways to partition the same set into non empty subsets then prove that: $C_n=B_{n-1}-B_{n-2}+\dots +(-1)^nB_1$ It seems to we have to use inclusion-exclution principle But how can we connect $C_n$ to $B_{n-1}$?First I thought we should take a member and partition the others to some non-empty sets but it didn't work.Any hints?",['combinatorics']
2350421,"$\!\!\bmod 24\!:\ mn+1\equiv 0\Rightarrow m+n \equiv 0\,$ using group theory","I would like to prove that : 
if $m, n \in \mathbb{N}$ such that : $mn+1 \equiv 0 \pmod{24}$ then $m+n \equiv 0 \pmod{24}$. I know how to prove that but it's quite annoying : just look at every possible rest of $m$ and $n$ mod $24$. Yet it's annoying because they are $24^2$ cases to be treated. I think we can solve that more easily using group theory, that's why I am just asking : does any one have an idea of how to solve this problem using group theory ? 
Maybe by looking at : $\mathbb{F}_{3}$ and $\mathbb{F}_2$...","['number-theory', 'group-theory']"
2350438,What's the difference between the ring of Integers and the maximal order in a Number field?,"I have faced the concept of maximal order, while reading one of the books of Goro Shimura, Euler Products and Eisenstein Series. I am familiar with the concept of ring of integers of a number field. I have read something on the orders and lattices, but its confused me. So at first, I prefer to fix some definitions to reduce my confusion.
Let $\mathbf{F}$ be a number field, i.e. a finite extension of $\mathbb{Q}$. Let $n$ to be the degree of this extension, i.e. $n:=[\mathbf{F}:\mathbb{Q}]$, also we denote by $\mathfrak{O}_{\mathbf{F}}$ the ring of integers of $\mathbf{F}$. By an order $\mathfrak{O}$ in $\mathbf{F}$ we mean a subring of $\mathfrak{O}_{\mathbf{F}}$, which has the $\mathbb{Z}$-dimension equal to $n$. Are all of my definitions are right, Specially the definition of an order ?","['number-theory', 'abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
2350452,Prove that the two measures are the same,"Suppose $\mu$ and $\nu$ are positive measures on the Borel $\sigma$-algebra on $[0, 1]$ such that $\int fd\mu=\int fd\nu$ whenever $f$ is real-valued and continuous on $[0, 1]$. Prove that $\mu=\nu$. I have no idea how to deal with this question. How should I do?","['lebesgue-integral', 'measure-theory']"
2350456,BMO2 2006 - Optimal Arrangement,"An exam consisting of six questions is sat by $2006$ children. Each
question is marked either right or wrong. Any three children have
right answers to at least five of the six questions between them. Let $N$
be the total number of right answers achieved by all the children (i.e.
the total number of questions solved by child $1$ + the total solved by
child $2$ + · · · + the total solved by child $2006$). Find the least possible
value of $N$. So I've begun by trying to find an optimal arrangement and seeing if I can prove that this is the best I can do. $6 \choose 4$ $ = 15$, so we can have up to $30$ children getting fewer than $5$ questions right, since otherwise there will always be $3$ who have the same four questions. Hence, at least $2006-30 = 1976$ got five questions right. So, we can make a configuration so that the least of $N$ is at most $1976 \times 5 + 30 \times 4 = 10000$. Now I am struggling to prove that the least possible value of $N$ is indeed 10000. I would also be very grateful if anyone that has a rich collection of these kinds of problems involving finding the best arrangement and proving that it is the best could comment with a link to them.","['combinatorics', 'contest-math']"
2350481,Gradient of holomorphic function equals conjugate of complex derivative,"I'm using TensorFlow for some computations with complex variables (and derivatives of these computations). When I compute the derivative of (simple) holomorphic functions, the results obtained with TensorFlow are the conjugate of what I would expect. A simple example: Given $z = x + yi$, and $f(z) = zz = x^2 + i2xy - y^2$. We have
$\frac{df}{dz} = \frac12 \left(\frac{\partial f}{\partial x} - i\frac{\partial f}{\partial y}\right) = 2x + i2y$. Hence, for $z = \frac{1}{5}i$, $\frac{df}{dz} = \frac{2}{5}i$. However, using TensorFlow, I obtain  $\frac{df}{dz} = -\frac{2}{5}i$. While searching for this, I found the following statement: ""The gradient of a holomorphic function is the conjugate of its complex derivative."" in a Github Issue , however, I don't understand why. In other words: Why is the gradient of a holomorphic functions equal to the conjugate of the complex derivative, and, where is the mistake in this simple example?","['derivatives', 'holomorphic-functions', 'complex-numbers']"
2351481,Exact value of $\sin(\pi\sqrt 2)$?,"Using the multitude of formulas surrounding the trigonometric functions, mathematicians have been able to find exact values for many arguments of the trigonometric functions. For example,
$$\sin \frac{\pi}{12}=\frac{\sqrt 3-1}{2 \sqrt 2}$$
In fact, it is even the possible to find the value of the sine of one degree . However, my question is about how to calculate exact values for stranger values of the sine function involving ""irrational amounts of $\pi$"", such as
$$\sin(\pi \sqrt 2)$$
or
$$\sin(\pi e)$$
does anybody know how to calculate either of these, or how I should go about doing it? Many of the currently-used trigonometric identities will become useless if one attempts to use them for irrational numbers, since they involve sums and products, and there are no ""special values"" like this from which to start. Any ideas? Edit: What I mean by ""exact value"" is a value expressed not in terms of the trigonometric functions, or not as a Riemann Sum or Product; something closed-form that isn't circular.","['trigonometry', 'irrational-numbers']"
2351494,"let $f$ be a differentiable function. Compute $\frac{d}{dx}g(2)$, where $g(x) = \frac{f(2x)}{x}$.","let $f$ be a differentiable function and  $$\lim_{x\to 4}\dfrac{f(x)+7}{x-4}=\dfrac{-3}{2}.$$ Define $g(x)=\dfrac{f(2x)}{x}$. I want to know the derivative
$$\dfrac{d}{dx}g(2)=?$$ I know that : $$\dfrac{d}{dx}g(2)=\dfrac{4(\dfrac{d}{dx}f(4))-4f(4)}{4}$$ and : $$\lim_{x\to 4}\dfrac{f(x)-f(4)}{x-4}=a\in\mathbb{R}$$ so : $$\lim_{x\to 4}\dfrac{f(x)-f(4)+7+f(4)}{x-4}=\dfrac{-3}{2}$$ $$\lim_{x\to 4}\dfrac{f(x)-f(4)}{x-4}+\dfrac{f(4)+7}{x-4}=\dfrac{-3}{2}$$ now what ?","['calculus', 'limits']"
2351525,When are definite integrals undefined?,"We have $$\int_{-1}^{1} \dfrac{1}{x} \, dx$$ as undefined and then we have $$\int^1_{-1} f(x)\delta(x) = f(0)$$ assuming $f(x)$ is continuous everywhere and $$\delta(x) = \begin{cases} 0 & x\ne 0,
 \\ \infty & x = 0. \end{cases}$$ In both cases the integrand is infinite for $x = 0$, then why second integral is not undefined?","['dirac-delta', 'definite-integrals', 'calculus']"
2351529,Determinant of $5 \times 5$ Boolean matrix,"Consider the set of $5 \times 5$ matrices with $10$ entries equal to $1$ and the other $15$ entries equal to $0$. I would like to know how many such matrices have nonzero determinant. Is there a way to characterize them? I experimented a little with some examples, but could not make much progress.","['numerical-linear-algebra', 'matrices', 'determinant', 'combinatorics', 'linear-algebra']"
2351569,Expected value of strictly convex function is strictly convex?,"I have one question that I am confused about. 
X is random variable with finite mean, $\alpha$ $\in$ (0,1) and $\phi_{1}$,$\phi_{2}$ are strictly convex functions. Then I know that for each t the function $g(t,x) = \alpha \phi_{1}((t-x)_{+}) + (1-\alpha) \phi_{2}((t-x)_{-})$ is strictly convex in x. It should follow that $E[g(X,x)]$ is strictly convex in x. (Reason for this is that it implies that its minimizer is unique) I don't understand why it follows that $E[g(X,x)]$ is strictly convex in x ? Thanks for your time.","['statistics', 'probability']"
2351581,Convergence question about Lp norm when p tends to zero,"I'm reading the book Real and Complex Analysis recently. And I encountered a question in the exercises of Chapter 3 that I can not solve for a long time. This question is about what the $L^p$ norm(not a norm when $p<1$) will become if we send p to zero. Explicitly, Suppose $X$ is a measure space, $\mu$ is a probability measure on $X$. Define $$||f||_p = \left(\int_X|f|^pd\mu\right)^{1/p}$$for all $0<p<+\infty$ and complex measurable function $f$. Assume that $||f||_r < \infty$ for some $r > 0$, and prove that $$\lim_{p\rightarrow0}||f||_p = \exp\left\{\int_X\log|f|d\mu\right\}$$if $\exp\{-\infty\}$ is defined to be $0$. By using Jensen's Inequality and a conclusion that $|f|_r \leq |f|_s$ if $0<r<s<\infty$, I get half part of the conclusion:$$\lim_{p\rightarrow0}||f||_p \geq \exp\left\{\int_X\log|f|d\mu\right\}$$ Then it remains to prove $$\lim_{p\rightarrow0}||f||_p \leq \exp\left\{\int_X\log|f|d\mu\right\}$$ Or another form $$\lim_{p\rightarrow 0}\frac{1}{p}\left(\int_X\log|f|^pd\mu - \log\int_X|f|^pd\mu\right) \geq 0$$ Then by inequality $\log(1+x) < x$, I only need to prove 
$$\lim_{p\rightarrow 0}\frac{1}{p}\left(\int_X\log|f|^p-|f|^p + 1d\mu\right) \geq 0$$But the inequality seems to be wrong. Can this way work? Or are there any other solutions for this question?","['real-analysis', 'lp-spaces', 'measure-theory']"
2351588,Continuity of the optimal solution when the objective function is convex and separable,"I have a very simple class of optimization problems. The objective function is separable with each part being strictly (or even strongly) convex. Furthermore, there's a solitary linear constraint: the sum of the variables is $b$. The variables must all be non-negative. Can we say that the optimal solution, denoted $x(b)$, is a continuous function of the scalar $b$? minimize $\sum f_i(x_i)$ subject to: $\sum x_i = b$ with: $x_i \ge 0.$ If necessary, assume that there exists $m>0$ such that $f_i''(t) > m$ for all $i$ and for all $t \ge 0$.","['convex-optimization', 'optimization', 'analysis', 'convex-analysis']"
2351591,Physical System Producing Prime Numbers?,"Have you seen this wonderful movie ""Contact"" starring Jodie Foster ? She is basically looking for signals from outer space to discover intelligent life. She eventually finds a source that transmits the sequence of prime numbers and this is considered as an answer to her questions. Everyone is convinced that the signal came from conscious, intelligent beings. My question as a mathematician is, is this absolutely true ? Can we have a non-intelligent physical system producing prime numbers ? I understand that I haven't actually defined the word ""intelligent"" and that's because it is very hard (if not impossible) to define at this point. This is some form of Turing test, no? It could be a program on a computer that does this but then some intelligent life form must have manufactured the computer and coded up the program so are we back to square one ? Thanks a bunch!","['prime-numbers', 'mathematical-physics', 'analysis']"
2351604,"Approximation of Fermi-Dirac integral $\int \text{d}x \frac{f(x,\beta)}{1+e^{\beta x}}$","In physics is quite common to find integrals of the type
\begin{align}
I(\beta) = \int_{-\infty}^{\infty}\text{d}x \frac{f(x)}{1+e^{\beta x}} \tag{1}
\end{align}
where $f(x)$ is some quantity we want to average over the Fermi-Dirac distribution $n(x) = \left(1+e^{\beta x}\right)^{-1}$, and $\beta >0$ is a positive real parameter representing the the 'inverse of the temperature'. Since many times physicists are only interested in the 'low temperature' regime $\beta\gg 1$, it is common to consider the following Sommerfeld approximation :
\begin{align}
I(\beta)\underset{\beta \gg 1}{=} \int_{-\infty}^{0}\text{d} x~f(x)+\frac{\pi^2}{6\beta^2} f'(0)+O(\beta^{-4}). \tag{2}
\end{align}
Which sometimes appears in a mnemonic fashion as an expansion for $n(x,\beta)$ itself,
\begin{align}
\frac{1}{1+e^{\beta x}}\underset{\beta\gg1}{=} \theta(-x)-\frac{\pi^2} {6\beta^2}\delta'(x)+O(\beta^{-4}) \tag{3}
\end{align} My question is Can we understand Eq. (3) in a rigorous fashion? E.g. as the expansion of a distribution. If yes, can we understand the convergence of Eq.(2) as the condition for a series expansion under integral sign? E.g. dominated convergence. My motivation I need to study an integral similar to Eq. (1) but with the crucial difference that f(x) is also a function of the parameter $\beta$, and wanted to make a similar expansion as in Eq. (2). My idea was to understand Eq. (2) as a series expansion Eq.(3) under integrals sign, and also expand my $f$ in $\beta$. To check if this is safe, I wanted to use dominated convergence. But I am not confident this makes sense. References for rigorous discussions of Eq. (2) or Eq. (3) are welcome.","['distribution-theory', 'integration', 'convergence-divergence']"
2351617,"If $f(x+y) = f(x) + f(y)$, $f(1) = 1$ and for all $x,y$, $f(xy) = f(x)f(y)$ or $f(xy) = f(y)f(x)$, then $f$ is a homomorphism or an anti-homomorphism","Let $R$ and $R'$ be two rings and $f: R\to R'$ be a map satisfying the conditions: $f(1) = 1$ . For all $x,y \in R$ , $f(x+y) = f(x) + f(y)$ . For all $x,y \in R$ , either $f(xy) = f(x)f(y)$ or $f(xy) = f(y)f(x)$ . Prove that $f$ is either a homomorphism or an anti-homomorphism. Where $f$ is called an anti-homomorphism if the first two conditions above are satisfied and for all $x,y$ , $f(xy) = f(y)f(x)$ . Any hints? Reference: This is exercise $9$ , page $114$ in Jacobson's Basic Algebra $1$ . The author writes (Hua.) at the start of the exercise - so apparently this result is due to Hua Luogeng ?","['abstract-algebra', 'ring-theory', 'ring-homomorphism', 'functional-equations']"
2351631,Verification for the solution following differential equation!,"Consider the following second order homogeneous differential equation! $$a_0(x)\frac{d^2y}{dx^2}+a_1(x)\frac{dy}{dx}+a_2(x)y=0$$ Suppose that $a_0,a_1,a_2$ are continuous for all  values of $[a,b]$. Let $f_1$ and  $f_2$ be two distinct solutions to the above differential equation for all $x$ on $a \leq x \leq b$. Further suppose that $f_2(x)\neq 0$. Let $W[f_1(x),f_2(x)]$ be Wronskian of $f_1$ & $f_2$ at $x$. Show that 
$$\frac{\text{d}}{\text{d}x}\left[\frac{f_1(x)}{f_2(x)}\right]=-\frac{W[f_1(x),f_2(x)]}{[f_2(x)]^2}$$ My work is as follows $$y=\frac{f_1(x)}{f_2(x)}$$ Using product rule of differentiation we have $$\frac{\text{d}y}{\text{d}x}=\frac{f_2(x)f_1'(x)-f_2'(x)f_1(x)}{[f_2(x)]^2}$$ Know that $$W[f_1(x),f_2(x)]=|\begin{bmatrix}f_1(x) & f_2(x) \\f_1'(x) & f_2'(x) \end{bmatrix}|$$ $$W[f_1(x),f_2(x)]=f_1(x)f_2'(x)-f_1'(x)f_2(x)$$ $$-W[f_1(x),f_2(x)]=-[f_1'(x)f_2(x)-f_1(x)f_2'(x)]$$ $$\frac{\text{d}y}{\text{d}x}=-\frac{W[f_1(x),f_2(x)]}{[f_2(x)]^2}$$ for $x$ on $[a,b]$ Is is that simple? Use result in part 1 to show that if $W[f_1(x),f_2(x)]=0$ then, $f_1$ & $f_2$ are linearly dependent! My attempt Assume that $W[f_1(x),f_2(x)]=0$ $$\frac{\text{d}}{\text{d}x}[\frac{f_1(x)}{f_2(x)}]=-\frac{W[f_1(x),f_2(x)]}{[f_2(x)]^2}$$ $$\int{\text{d}}\left[\frac{f_1(x)}{f_2(x)}\right]=-\int\frac{W[f_1(x),f_2(x)]}{[f_2(x)]^2}{\text{d}x}$$ $$\int{\text{d}}\left[\frac{f_1(x)}{f_2(x)}\right]=-\int0{d}x$$ $$\frac{f_1(x)}{f_2(x)}=c$$ c is an arbitrary constant $${f_1(x)}=c{f_2(x)}$$ $f_1$ & $f_2$ just differ by a constant. Hence they are linearly dependent! Is this correct? Suppose that solution $f_1$ & $f_2$ are linearly independent on x on $a \leq x \leq b$ Hence, $f(x)=\frac{f_1(x)}{f_2(x)}$ and show that f is a monotonic function on $a \leq x \leq b$ I try to argue that The derivative of $f(x)$ is negative therefore monotonic! I am totally unsure for my work. I sincerely hope that someone will provide the rigorous and correct way of doing this question!",['ordinary-differential-equations']
2351632,Why do we need a Jordan normal form? [duplicate],"This question already has answers here : What is the purpose of Jordan Canonical Form? (2 answers) Closed 6 years ago . My professor said that the main idea of finding a Jordan normal form is to find the closest 'diagonal' matrix that is similar to a given matrix that does not have  a similar matrix that is diagonal.
I know that using a diagonal matrix is good for computations and simplifying powers of matrices. 
But what is the potential of finding a matrix with Jordan form? what is this 'almost diagonal' matrix gives me?
We learnt how to find it, without knowing what is the main idea behind it and what are the applications used with it, so I can't really understand it.","['matrices', 'jordan-normal-form', 'linear-algebra']"
2351659,Show this $\int_0^\infty \frac{t\ln(2\sinh t)}{\left(3t^2+\ln^2(2\sinh t)\right)^2}~dt=0$,"While evaluating the integral
$$
I_1=\int_{0}^\infty\frac{\sin\pi x~dx}{x\prod\limits_{k=1}^\infty\left(1-\frac{x^3}{k^3}\right)},\tag{1}
$$
I came to this integral of elementary function
$$
I_2=\int_0^\infty \frac{dt}{\left(i t\sqrt{3}+\ln(2\sinh t)\right)^2}.\tag{2}
$$
In fact $I_2$ is real and
$$
I_1=-2\pi I_2.
$$
These formulas imply the closed form
$$
\int_{0}^{\infty}\frac{t\ln\left(\,2\sinh\left(\,t\,\right)\,\right)}{\left[\,3t^{2} + \ln^{2}\left(\,2\sinh\left(\,t\,\right)\,\right)\right]^{\,2}}\,{d}t = 0,\tag{3}
$$
or alternatively
$$
\text{Im}\int_0^\infty \frac{dt}{\left(i t\sqrt{3}+\ln(2\sinh t)\right)^2}=0.
$$ Brief outline of proof is as follows. Write the infinite product in terms of Gamma functions, apply reflection formula for Gamma function to get rid of $\sin\pi x$, then use integral representation for Beta function and change the order of integration. Then one can integrate over $x$ to obtain the desired formula.
It seems that this should have a simple proof, but I don't see it. Q: Can anybody provide a direct proof ?. Such a direct proof may shed light on possible routes to calculation or simplification of $(2)$. Here is a numerical demonstration using Mathematica that the integral under consideration is $0$ up to at least $100$ digits: The integrand for $t>w$ has been replaced by $\frac{1}{16t^2}$, resulting in the term $\frac{1}{16w}$.","['calculus', 'closed-form', 'integration', 'definite-integrals', 'contour-integration']"
2351662,"Origin-Centred Elliptical ""Spotlight"" with Conical Light Source of Fixed Aperture","You have a light source with conical semi-aperture angle of $u$, and you want to create an ellipse-shaped spotlight with equation $\frac {x^2}{a^2}+\frac {y^2}{b^2}=1$ $(a>b)$ by shining it on the Cartesian $x$-$y$ plane from $(k,0,h)$ at a tilt angle $\alpha$ to the vertical on the $x$-$z$ plane. Express $k,h,\alpha$ in terms of $u,a,b$. In other words, using a light source with a fixed aperture, where should you place it on the $x$-$z$ plane and at what angle from the vertical should you tilt it from  in order to create an ellipse of given semi-major and semi-minor axes centred at the origin? (NB - this is a variation of this other question here posted earlier) Here's a nice video by ElicaTeam illustrating something similar. A screenshot is shown below. A screenshot from a desmos simulation is shown below. $\hspace{2cm}$ ] 2 Addendum The answer that I've worked out is 
$$\boxed{\begin{align}
&\sin\alpha&&=\sqrt{1-\frac{b^2}{a^2}} \cos u&&=e \cos u\\
&k&&=\sqrt{\left(1-\frac{b^2}{a^2}\right)(a^2+b^2\cot^2u)}&&=e\sqrt{a^2+b^2\cot^2u}\\
&h&&=\frac {b^2}{a\tan u}&&=a(1-e^2)\cot u\end{align}}$$
where $e=\sqrt{1-\frac{b^2}{a^2}}$ is the eccentricity of the ellipse. See desmos implementation here . Interestingly, there are similarities with the tilted martini glass problem posted here on MSE last year, and originally posted on $538$ Riddler. Further Addendum (27 Jul 2017) See improved desmos implementation here . The red curve is the locus of the light source position for constant $a$ and the blue curve is the locus for constant $b$.","['conic-sections', 'geometry']"
2351691,understanding statement of generalized CLT,"Durrett Theorem 3.7.2 Given a sum $S_n=\sum_1^nX_i$ of an iid sequence $X_1,X_2,\ldots,$ Durrett theorem 3.7.2 (image at link) gives necessary and sufficient conditions for the existence of constants $a_n,b_n$ such that $(S_n-b_n)/a_n$ converges weakly to a nondegenerate distribution. I am trying to see how the usual CLT, ie, when $var(X_1)<\infty$, relates to this theorem. Let the $X_i$ have the double exponential distribution, with pdf $f(x)=\exp(-|x|)/2$. The variance is 2 and the density is symmetric so the usual CLT says $S_n/\sqrt{2n}$ converges to a standard normal. Now to Durrett's theorem. Again since the pdf is symmetric condition $(i)$ is met with $\theta=1/2$ and also $b_n=0$. $P(|X_1|>x)=e^{-x}$ so $a_n=\inf\{x:P(|X_1|>x)\le 1/n)\}=\log n.$ So the theorem seems to be saying $S_n/\log n$ converges to a nondegenerate distribution, which cannot be, given the CLT result. So I must have miscalculated $a_n$ or I'm misunderstanding the statement of the theorem. I also do not see how condition $(ii)$ applies. For this example the dropoff of the tails is exponential. Is it possible to put $e^{-x}$ in the form $(ii)$ requires, $x^{-\alpha}L(x)$ for slowly varying $L$ and $\alpha<2$. Why is there a condition limiting how fast the tails drop off? That's the opposite of the usual CLT condition. But $(ii)$ must apply by the necessity direction and the CLT result.","['probability-theory', 'probability', 'statistics']"
2351694,$ \sin^2x_1+\dots \sin^2x_{10}=1$ implies $ 3(\sin x_1+\dots \sin x_{10})\leq \cos x_1 +\dots +\cos x_{10}. $ [duplicate],"This question already has answers here : Prove : $\frac{\cos(x_1) +\cos(x_2) +\cdots+\cos(x_{10})}{\sin(x_1) +\sin(x_2) +\cdots+\sin(x_{10})} \ge 3$ (3 answers) Closed 6 years ago . Suppose that $x_1,.\dots x_{10}\in[0,\frac{\pi}{2}]$ and that
  $$
\sin^2x_1+\dots \sin^2x_{10}=1.
$$
  Prove that
  $$
3(\sin x_1+\dots \sin x_{10})\leq \cos x_1 +\dots +\cos x_{10}.
$$","['radicals', 'inequality', 'trigonometry', 'tangent-line-method', 'contest-math']"
2351704,Z transform of a polynomial signal,"$$x(k)=\begin{cases} k^n \qquad k\ge 0 \\ 0 \ \  \qquad k<0 \end{cases}$$ I have this formula to calculate the Z transform:
$$\mathscr{Z} \{x(k) \}=\Big(-z \ \frac{d}{dz}\Big)^n \Big[ \frac{z}{z-1} \Big]$$ I have considered this particular case: $$x(k)=\begin{cases} k^2 \qquad k\ge 0 \\ 0 \ \  \qquad k<0 \end{cases}$$ $$f(z)=\frac{z}{z-1}$$
$$f'(z)=\frac{-1}{(z-1)^2}$$
$$-z f'(z)=\frac{z}{(z-1)^2}$$ $$g(z)=\frac{z}{(z-1)^2}$$
$$g'(z)=\frac{(z-1)^2-2z(z-1)}{(z-1)^4}=\frac{-z-1}{(z-1)^3}$$
$$-z g'(z)=\frac{z^2+z}{(z-1)^3}$$ So $$\mathscr{Z} \{ x(t) \}=\frac{z (z+1)}{(z-1)^3}$$ But, I have tried to calculate the inverse Z transform: $$\mathscr{Z}^{-1} \Big\{\frac{z (z+1)}{(z-1)^3} \Big\}=\mathscr{Z}^{-1} \Big\{H(z) \Big\}$$ Partial fraction decomposition of $\frac{H(z)}{z}$: $$\frac{z+1}{(z-1)^3}=\frac{1}{(z-1)^2}+\frac{2}{(z-1)^3}$$ $$\mathscr{Z}^{-1} \Big\{\frac{z}{(z-1)^2} \Big\}=k \ u(k)$$ $$\mathscr{Z}^{-1} \Big\{\frac{2z}{(z-1)^3} \Big\}=k^2 \ u(k)$$ $$\mathscr{Z}^{-1} \Big\{H(z) \Big\}=(k+k^2) \ u(k)$$ Where is the mistake? I know this formula to calculate the inverse Z transform: $$\mathscr{Z^{-1}}\Big[ \frac{C_{i,j} \ z}{(z-p_i)^j}\Big]=C_{i,j} \ \frac{k^{(j-1)}}{(j-1)!} \ p_i^{k-j+1} \ u(k)$$ Is it not applicable to $\frac{z(z+1)}{(z-1)^3}$? Thanks","['derivatives', 'z-transform', 'transformation']"
2351714,Show that a limit of the derivative of a complex function is $0$,"Question: For some $\alpha>0$, define $S=\{re^{i\theta}, r>0, 0<\theta<\alpha\}$. $f$ is bounded and holomorphic in $S$. Show that $\lim_{r\to\infty}f'(re^{i\theta})=0$ for each $0<\theta<\alpha$. Below $\Gamma$ is the counter-clockwise contour in S with only one loop around $z$ (here I choose $\Gamma$ to be a circle). My attempt is to represent $f'$ by Cauchy’s integral formula, i.e., I write
$$ f'(z)=\frac{1}{2\pi i}\int_{\Gamma}\frac{f(w)}{(w-z)^2}dw.$$
Then
$$ f'(re^{i\theta})=\frac{1}{2\pi i}\int_{\Gamma}\frac{f(w)}{(w-re^{i\theta})^2}dw.$$
Since $r\to\infty$, we can get $\frac{f(w)}{(w-re^{i\theta})^2}\to 0$, and then the integral goes to $0$ so that $f'(re^{i\theta})$ goes to $0$. But I begin to doubt myself since my attempt is too easy. So, is the method above correct? Is there any other ways to approch the problem.","['cauchy-integral-formula', 'complex-analysis', 'limits']"
2351726,Group Theory symmetry questions,"Is it possible to draw a figure that has exactly one reflection symmetry (flip) and one (or more) non-trivial rotational symmetry?  (Note:  The trivial symmetry is the 0 degrees or 360 degreesrotation). I am doing this problem for a homework assignment, and was assuming that it wasn't possible, but my proof may not be rigorous enough or even proof at all. This is what i think. if you assume that something has one reflectional symmetry and one non-trivial rotational symmetry you can rotate it and another reflectional symmetry will become present which contradicts the original assumption of a single reflective symmetry. furthermore any figure with a single reflective symmetry will have atleast 2 rotational non-trivial symmetries. can someone help me word this so it makes more sense? or steer me on the right path?","['proof-verification', 'proof-writing', 'proof-explanation', 'group-theory', 'symmetric-groups']"
2351742,Expected number of steps to walk through points by multiple walkers,"Suppose there are $m$ points.
A walker can visit the points in any order, but it will not visit a point twice.
There are $n$ walkers, and their starting points are randomly chosen. After $k$ steps, each point is visited at least once by any of the walkers.
What is the expected number of $k$? Some assumptions: a walker doesn't know the visited points of other walkers multiple walkers can be at the same position Additional question: What if walkers are capable of knowing the visited points of others after they have chosen their random starting points? (so the first assumption doesn't hold anymore)","['statistics', 'probability']"
2351768,Is every countable regular space zero-dimensional?,"Question is in the title. Zero-dimensional means ""has a basis of clopen sets"". Hausdorff is not enough to guarantee a countable space has dimension zero (in fact, a countable Hausdorff space can be connected). Is regular enough? Note 1: I assume that singletons are closed, so that regular is stronger than Hausdorff. I'm not sure what would happen here if we allow non-closed singletons... Note 2: (countable + regular) implies normal, if that helps (?)",['general-topology']
2351855,501 distinct coprime integers between 1 and 1000?,"This is exercise 1.6.1 of Guichard Suppose that 501 distinct integers are selected from 1 . . . 1000. Show that there are distinct selected integers $a$ and $b$ such that $a | b$. Show that this is not always true if 500 integers are selected. This seems like it should be simple but it's has been stumping me for a few days. Here's my idea for a proof: Let $S$ be a set of 500 distinct integers between 1 and 1000 that don't divide each other. Let $S_{1-500}$ and $S_{501-1000}$ partition $S$ into sets containing the elements ≤ and > than 500, respectively. Then consider $2 S_{1-500}$ and $\frac{1}{2}S_{501-1000}$, the result of multiplying the elements of these sets by 2 and 1/2, respectively. Because elements of S are coprime, $S_{1-500}$, $S_{501-1000}$, $2 S_{1-500}$, and $\frac{1}{2}S_{501-1000}$, are disjoint. Also note that each of these sets is a subset of the integers from 1 to 1000. One can deduce that the cardinality of the union of these sets is 1000, and therefore they form a partition of the integers from 1 to 1000. Now, I know this demonstrates that you can't add another number to $S$ that is coprime with all the elements in $S$, which means that a coprime subset of the integers from 1 to 1000 can have at most 500 elements. Can someone articulate why this is true for me? Also, this was in a section on the Pigeonhole principle, can someone rework the proof to utilize that, and possibly make it simpler? Thanks.","['combinatorics', 'pigeonhole-principle']"
2351861,Generalizations of Integrals,"I've been studying dimensional regularization recently and found that some people view the divergent integrals, which are replaced by certain finite expressions in the regularization procedure, as existent because ""the regularization process provides the correct understanding what the integral really is"". Thus they see those expressions no longer as Lebesgue integrals but as objects of a kind for which they don't have a rigorous mathematical definition. I'm looking for such definitions. This has parallels in the study of divergent series, which may be Cesàro-summable for example. On the other hand, if one views series as special cases of Lebesgue integrals with (counting measure), only absolutely convergent series exist in Lebesgue sense. We thus have a vast theory of generalizations to Lebesgue integrals with counting measure. An often quoted reference seems to be Hardy's book ""Divergent Series"" although I'd be interested in more modern sources, as well as for asymptotic analysis! Apart from looking for such references,the question is: Are there generalizations of integrals over, say, $\mathbb{R}^n $ that (for example) do not require the absolute value of the integrand to be integrable as well? Generalizations in the style of Cesàro? Do such generalizations have something to do with regularization schemes? Are there connections to topics like distribution theory?","['improper-integrals', 'integration', 'analysis']"
2351866,How to calculate $\lim_{x\to\infty}\frac{x}{x-\sin x}$?,"I tried to solve 
  $$
\lim_{x\to\infty}\frac{x}{x-\sin x}.
$$ After dividing by $x$ I got that it equals to: 
$$
\lim_{x\to\infty}\frac{1}{1-\frac{\sin x}{x}}.
$$ Now, using L'hopital (0/0) I get that 
$$
\lim_{x\to\infty}\frac{\sin x}{x} = \lim_{x\to\infty}\cos x
$$
 and the lim at infinity for $\cos x$ is not defined. So basically I get that the overall limit of 
$$
\lim_{x\to\infty}\frac{x}{x-\sin x}
$$ is $1$ or not defined?","['calculus', 'limits']"
2351875,Why is the fundamental group of the circle so non-trivial? [duplicate],This question already has answers here : intuition on the fundamental group of $S^1$ (2 answers) Closed 6 years ago . I've recently learned that the fundamental group of the circle is isomorphic to $\mathbb{Z}$. I'm having a hard time picturing loops in $S^1$; can you give some intuition for why that group has such a rich structure?,"['algebraic-topology', 'general-topology', 'fundamental-groups']"
2351911,How do I prove that the given function is continuous and monotonically increasing?,"How do I prove that the following function is continuous and monotonically increasing? $$f(x) = \begin{cases} \dfrac{e^x-1}{x}  & \text{if $x \neq0$ } \\ 1 & \text{if $x=0$ } \end{cases}$$ I tried to show that it's continuous by that it's always continuous, even when $x=0$ (because by definition it becomes $1$ and $1$ is in the upper functions definition) but it's not sufficient and I don't know how to write it mathematically, and without that I can not step forward to prove it being monotonously rising. Then to show it's monotonously rising, we can see that the derivative is $\frac{e^xx-e^x+1}{x^2}$ (it exists because the function is continuous (which I don't know how to prove yet)), and then to show that it is monotonically increasing i show that $f'(x)>0$. Please show me the right way to do so mathematically.","['derivatives', 'continuity', 'calculus']"
2351964,Sphere inside a pyramid,"A spherical ball of radius $1$ rests inside a holder in the shape of an inverted pyramid. The pyramid has a horizontal square top and its other faces are equilateral triangles. It is large enough to enclose the ball.
How far is the centre of the ball above the apex $X$ of the pyramid? diagram: https://i.sstatic.net/7c6js.jpg (Answer: $\sqrt 3$) So far, I tried making a triangle $OAX$, where $O$ is the centre of the circle and $A$ is the point where the sphere meets one of the triangular faces. I have said that ∠$OAX$ is a right angle and that ∠$OXA$ is $30$º but that gives the incorrect answer of $2$. Any suggestions?","['contest-math', 'geometry']"
2352023,Cardinality of a measure-zero set,"On real number line $\mathbb R$, does saying a set is of Lebesgue measure zero equivalent to saying that the set is of $\aleph_0$? Does saying a set is of Lebesgue measure $>0$ equivalent to saying that the set is of $\aleph_1$? I understand that countable sets are always of measure zero, but I am not sure if the inverse is also true.","['real-analysis', 'lebesgue-measure', 'measure-theory', 'elementary-set-theory']"
2352048,"Why is it more likely to be in the lead 0 or 40 times, rather than 20 in this example?","( https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/amsbook.mac.pdf ) (this question comes from here page 6) “Peter and Paul play a game called heads or tails. In this game, a fair coin is tossed a sequence of times—we choose 40. Each time a head comes up Peter wins 1 penny from Paul, and each time a tail comes up Peter loses 1 penny to Paul.
We adopt the convention that, when
Peter’s winnings are 0, he is in the lead if he was ahead at the previous toss and
not if he was behind at the previous toss. With this convention, Peter is in the lead
34 times in our example. Again, our intuition might suggest that the most likely
number of times to be in the lead is 1/2 of 40, or 20, and the least likely numbers
are the extreme cases of 40 or 0. Our intuition about Peter’s final winnings was quite correct, but our intuition about
the number of times Peter was in the lead was completely wrong. The simulation
suggests that the least likely number of times in the lead is 20 and the most likely
is 0 or 40. This is indeed correct, and the explanation for it is suggested by playing
the game of heads or tails with a large number of tosses and looking at a graph of
Peter’s winnings. In Figure 1.4 we show the results of a simulation of the game, for
1000 tosses and in Figure 1.5 for 10,000 tosses"" figure1.4","['statistics', 'probability', 'education']"
2352049,angle chasing in quadrilaterals,"Let $ABCD$ be a convex quadrilateral with 
  $\measuredangle{ABD} = 18^{\circ}$, $\measuredangle{ACB} = 54^{\circ}$,
  $\measuredangle{ACD} = 36^{\circ}$ and 
  $\measuredangle{ADB} = 27^{\circ}$. Let $\{P\}$
  be the intersection of the two diagonals $AC$ and $BD$. What is the degree value of $\measuredangle{APB}$?","['circles', 'quadrilateral', 'trigonometry', 'euclidean-geometry', 'geometry']"
2352060,"Definition of the ""natural reduction map"" $\tilde\phi$ for $\phi:E_1\to E_2$ an isogeny of elliptic curves","I'm looking at the following proposition (II.$4.4$) from Silverman's Advanced Topics in the Arithmetic of Elliptic Curves: Let $K$ be a number field, $\mathfrak P$ a maximal ideal of $K$, and let $E_1/K$ and $E_2/K$ be elliptic curves with good reduction at $\mathfrak P$. Then the natural reduction map $$\hom(E_1,E_2)\to\hom(\tilde E_1,\tilde E_2),\ \ \ \ \phi\mapsto\tilde\phi$$ is injective and preserves degrees. Silverman doesn't explicitly define this reduction map, I guess he just assumes it's obvious, but I don't quite see how we could always define this. To define the reduction $\tilde E$, we consider $E$ as an elliptic curve over the completion of $K$ with respect to $\mathfrak P$, call it $K_{\mathfrak P}$, then rewrite the equation defining $E$ as an equation over the ring of integers $R$ of $K_{\mathfrak P}$, then take the reduction of this equation modulo our maximal ideal $\mathscr M$ to get a curve $\tilde E$ defined over $k=R/\mathscr M$. In the case of a morphism $\phi:E_1\to E_2$, how would we define this $\tilde\phi$? If $\phi$ is defined over $\overline K$, we can't really guarantee that it'll be defined over $K_{\mathfrak P}$, can we? I suppose we could define $\tilde\phi$ by the equation $$\tilde\phi(\tilde P)=\widetilde{\phi(P)}.$$ How can we be sure this is well-defined? What we would need to check is that if $P\in E_1$ with $\tilde P=\tilde O$, then $\widetilde{\phi(P)}=\tilde O$. But also, don't we only define $\tilde P$ when $P\in E_1(K_{\mathfrak P})$? So how could we be sure that all elements of $\tilde E_1(\bar k)$ are of the form $\tilde P$ for some $P$? I know there's some correspondence between unramified extensions of $L$ and arbitrary extensions of $k$, so maybe to determine $\tilde\phi$ on all elements of $\tilde E_1(\bar k)$ we just need to be able to define $\phi$ over $K^{nr}$ where $K^{nr}$ is the maximal unramified extension of $K$?","['elliptic-curves', 'algebraic-number-theory', 'algebraic-geometry']"
2352118,Finding the Derivative of an Integral,"I am stuck trying to take the derivative of the following function: $$F(t) = \int_{-2t^2}^{t^{1/2}}f(xt^{-1},x)dx$$ I am aware the fundamental theorem of calculus is relevant, but I am not sure with how to deal with a generic function $f(xt^{-1},x)$ like this. Any help would be greatly appreciated!","['derivatives', 'calculus', 'multivariable-calculus', 'integration', 'ordinary-differential-equations']"
2352145,Proving the independence of the given statistics,"Let $(X_1, Y_1), ..., (X_n, Y_n)   (n>2)$ be random samples from the bivariate normal distribution $N_2 (\mu_1, \mu_2; \sigma_1^2, \sigma_2^2, \rho)$, where $\sigma_1>0, \sigma_2>0, -1<\rho<1$. Let $r$ be the sample correlation coefficient defined as $r= \frac{\sum_1^n (X_i - \bar X )(Y_i - \bar Y)}{\sqrt{\sum_1^n (X_i-\bar X)^2}\sqrt{\sum_1^n (Y_i -\bar Y)^2}}$ where $\bar X, \bar Y$ are sample means of $X_i$'s and $Y_i$'s, respectively. Also, let $Z_i = (X_i-\mu_1)/\sigma_1$, $W_i=\{(Y_i-\mu_2)/\sigma_2-\rho(X_i-\mu_1)/\sigma_1\}/\sqrt{1-\rho^2}$ for $i=1, ..., n$. Now prove the followings: (a) $S_{WW}-S_{ZW}^2/S_{ZZ} $ and $Z=(Z_1, ..., Z_n)$ are independent. (b) $S_{ZW}/\sqrt{S_{ZZ}} $ and $Z$ are independent. (c) $S_{WW}-S_{ZW}^2/S_{ZZ}, S_{ZW}/\sqrt{S_{ZZ}}, S_{ZZ}$ are indenepdent. Where $S_{ZZ} = \sum_1^n (Z_i-\bar Z)^2$, $S_{WW} = \sum_1^n (W_i-\bar W)^2$, $S_{ZW} = \sum_1^n (Z_i-\bar Z)(W_i-\bar W)$. What I know is that if $T=((Z_1-\bar Z)/\sqrt{S_{ZZ}}, ..., (Z_n-\bar Z)/\sqrt{S_{ZZ}}$), then $S_{WW}-S_{ZW}^2/S_{ZZ}=W^t(I-n^{-1} 11^t-TT^t)W$, where $1$ is the vector where all entries are 1. Also, it is known that $Z=(Z_1, ..., Z_n)$ and $W=(W_1, ..., W_n)$ are independent. How should I prove the independence this case? Using pdf or mgf to prove independence here seems ridiculous.","['independence', 'statistics', 'normal-distribution']"
2352152,"If $a_nb_n\to 1$ and $a_n+b_n\to2$, do $a_n,b_n\to1$?","Suppose that $a_n$ and $b_n$ are two real sequences satisfying $a_nb_n\to 1$ and $a_n+b_n\to 2$ . Does it follow that $a_n$ and $b_n$ both converge to $1$ ? I was working on this problem as one of the exercises from this online source of problems in analysis . I have not been able to find a counterexample, but I have deduced some necessary conditions on $a_n,b_n$ : Eventually $a_n$ and $b_n$ have the same sign, and this must be $>0$ : If they do not eventually share the same sign, then $a_nb_n$ can't converge to $1$ . If they are not both positive, their sum can't converge
to $2$ . There exists $t>0$ and $N$ such that $a_n>t$ for all $n\ge N$ . [Hence the same conclusion holds for $b_n$ .]: If not, there is some subsequence $a_{n_k}$ with $a_{n_k}\to 0$ . But then $b_{n_k}\to\infty$ as $a_{n_k}b_{n_k}\to1$ . Then $a_{n_k}+b_{n_k}\to\infty$ , absurd. $a_n$ and $b_n$ are both bounded above: Otherwise, there must be a subsequence of the other that tends to $0$ , which is impossible by 2. I imagine a counterexample would be very strange, but I feel like a proof is also not too far out of reach. Thanks for any suggestions. P.S. Does the conclusion change if we allow complex sequences $a_n,b_n$ ?","['real-analysis', 'sequences-and-series']"
2352193,Existence of bounded sequences for image of bounded linear operators,Let $X$ and $Y$ be Banach spaces and $A:X\to Y$ be a bounded linear operator. Assume that $y\in \overline {A(X)}$. Can we always choose a bounded sequence $(x_n)\subset X$ such that $\displaystyle \lim_{n\to \infty} Ax_n=y$?,"['functional-analysis', 'banach-spaces']"
2352236,How many odd three-digits numbers are there whose all three digits are different,"I faced this problem on one test. I wrote my solution but then I found out that my solution is wrong, I still cannot find where my mistake is. The problem says: How many three-digits numbers are there such that they are odd and their digits are all different. Here is my approach: We have three digits. Since the number should be odd, the last digit should be one of those numbers $1, 3, 5, 7, 9$. Now the second digits can be one of the digits: $0, 1, 2, 3, 4, 5, 6, 7, 8, 9$ There are 10 different digits for the second digits, but since the digits should be different we cannot place 10 digits, but we can place 9 digits. And for the first digits we can place digits in the range $1...9$ but we cannot place the digits that are used in the two other digits and we can place only 7 digits. So my result is $7\cdot9\cdot5 = 315$ However the result is not correct, because there are $320$ odd three-digits numbers with different digits. Can you point me where is my mistake, thanks in advance.","['number-theory', 'combinatorics']"
2352337,Are Dynkin's $\pi-\lambda$ Theorem and the Monotone Class Theorem equivalent?,"Let $X$ be a set. If $\mathcal{A}$ is a family of subsets of $X$ then let $\sigma(\mathcal{A})$ denote the $\sigma$-algebra generated by $\mathcal{A}$. Definition $1$ A $\pi$-system on $X$ to be a non-empty family $\mathcal{A}\subseteq \mathcal{P}(X)$ closed under finite intersections (I wonder why such a fancy name). Definition $2$ A $\lambda$-system on $X$ is a family $\mathcal{A}\subseteq \mathcal{P}(X)$ such that $X\in\mathcal{A}$ and that is closed under complements and unions of pairwise disjoint countable subfamilies. Definition $3$ A monotone class on $X$ is a family $\mathcal{A}\subseteq \mathcal{P}(X)$ that is closed unders unions and intersections of countable subfamilies of nested sets. Dynkin's $\pi-\lambda$ Theorem (source) Let $\mathcal{I}$ be a $\pi$-system on $X$ and $\mathcal{D}$ be a $\lambda$-system on $X$. If $\mathcal{I}\subseteq \mathcal{D}$ then $\sigma(\mathcal{I})\subseteq \mathcal{D}$. - The Monotone Class Theorem (source) Let $\mathcal{A}$ be an algebra of subsets of $X$ and suppose that $\mathcal{M}$ is the smallest monotone class on $X$ such that $\mathcal{A}\subseteq \mathcal{M}$, then $\sigma(\mathcal{A})=\mathcal{M}$. My question: I'd like to know if these two theorems are equivalent, in the sense of whether one can prove easily one from the other, in a way that makes it clear that for practical purposes they are to some extent interchangeable. More formally I would raise the question of whether they are equivalent given some ""basic"" set theory axioms (e.g. ZF). This question seems to be asking the same thing but it's actually considering a different statement for the Monotone Class Theorem.","['probability-theory', 'set-theory', 'measure-theory']"
2352352,Can every number $n$ be written as the sum of $n$ different prime numbers?,"Let $n\in \mathbb{N}\setminus\{1\}$, can every $n$ be written as:
   $ \ n=\pm p_{n}\pm p_{n-1}\cdots\pm p_{2}\pm p_{1} \,$ where $p_k$ is a prime number and :$\ \ p_{n}\neq p_{n-1}\neq\cdots \neq p_{2}\neq p_{1}$? Examples: $2=+7-5$ $3=+11-5-3$ $4=-17+11+7+3$ $5=+29-17-11+7-3$ $6=-29+17+13+7-5+3$ $7=+31-19-17+11-7+3+5$ $8=-31+29-21+17+13-11+7+5$ $9=+31-21-19+17+13-11+7-5-3$ $10=+37-31+21-19-17+13+11-7+5-3$","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2352374,"Find the number of permutations of $1,2,\dots ,n$ that $1$ is in the first position and the difference between two adjacent numbers is $\le 2$","Find the number of permutations of $1,2,\dots ,n$ that $1$ is in the first and the difference between two adjacent numbers is $\le 2$ My attempt :It can be easily proved that by deleting $n$ we get the same question for $n-1$ numbers, so consider the answer of the question $f_n$.  In any case of $n-1$ numbers, we can at least put $n$ in one place that the condition is true again.  But in some cases we can put $n$ in two places. I mean the case that $n-1$ is in the end and $n-2$ is before that I can calculate these case.  Anyway, the answer in the book is: $f_n=f_{n-1}+f_{n-3}+1$",['combinatorics']
2352474,What are the numerical methods for solving matrix differential equations?,Which numerical methods can be used to solve matrix differential equations of the following form? $$\textbf{X}'(t)=\textbf{A}\textbf{X}(t)+\textbf{B}(t)$$ Do you have book or article suggestions about it?,"['matrix-equations', 'numerical-methods', 'ordinary-differential-equations']"
2352479,A trigonometric sum (is it a Ramanujan sum?),"Let A be the following set: $A=\{x \in \mathbb{N}^+: x\lt3003 \text{ and } (x,3003)=1 \}$. I am asked to find the value of $$\sum_{n\in A}\sin^2\left( \frac{n\pi}{3003}\right).$$","['summation', 'trigonometry', 'elementary-number-theory']"
2352498,"Finding range and inverse of $f(x,y) := (x\sqrt{y},y\sqrt{x})$","Consider the function $f: (0,\infty)\times (0,\infty) \to \mathbb{R}^2$ defined by $$f(x,y) := (x\sqrt{y},y\sqrt{x})$$ I know that in general it is hard to tell if $f$ is injective or not and to determine the image of $f$. So I started calculating a possible inverse function, where the domain is to be determined later. If $f(x,y) = (u,v)$ I got $$(x,y) = (u^{4/3}v^{-2/3},v^{4/3}u^{-2/3})$$ How do I now find $f((0,\infty)\times(0,\infty))$ and where that $f$ is invertible?",['multivariable-calculus']
2352499,Show that The Hausdorff Measure is a Measure,"I am trying to prove that the Hausdorff measure is, in fact, a measure. Definition. $\mu$ is a measure on $\mathbb{R}^{m}$ if $\mu$ assigns a non-negative number (possibly $\infty$ ), to each subset of $\mathbb{R}^{m}$ such that $\mu(\emptyset)=0$ ; $\mu(S)\leq\mu(T)$ if $S\subseteq T$ ; if $S_{1},S_{2},\ldots$ is a countable or finite sequence of sets, then $\mu\left(\bigcup_{i=1}^{\infty}S_{i}\right)\leq\sum_{i=1}^{\infty}\mu(S_{i})$ with equality if $S_{i}$ are disjoint Borel sets. We call $\mu(S)$ the measure of $S$ . Definition. Suppose $F\subset\mathbb{R}^{n}$ and $s\in\mathbb{R}_{\geq0}$ . For $\delta>0$ , consider all $\delta$ -covers of $F$ and minimise the sum of the $s$ th powers of the diameters. As $\delta\to0$ , the class of permissible covers of $F$ is reduced. So $$\mathcal{H}_{\delta}^{s}(F)=\inf\left\{\sum_{i=1}^{\infty}|U_{i}|^{s}:\{U_{i}\} \text{ is a } \delta \text{-cover of } F\right\}$$ increases and so approaches a limit. The $s$ -dimensional Hausdorff measure $$\mathcal{H}^{s}(F)=\lim_{\delta\to0}\mathcal{H}_{\delta}^{s}(F)$$ exists for any $F\subset\mathbb{R}^{n}$ although it can be, and often is, either $0$ of $\infty$ . What I've done: Obviously $\mathcal{H}^{s}(\emptyset)=0$ , and it is intuitive that if $E\subseteq F$ , then $\mathcal{H}^{s}(E)\leqslant\mathcal{H}^{s}(F)$ . What I am not sure how to do it show that $$\mathcal{H}^{s}\left(\bigcup_{i=1}^{\infty}F_{i}\right)\leqslant\sum_{i=1}^{\infty}\mathcal{H}^{s}(F_{i})$$ with equality if $\{F{i}\}$ are disjoint Borel sets.",['measure-theory']
2352508,What is the value of the expression $[1 + \cos(\frac{\pi}{8})][1 + \cos(\frac{3\pi}{8})][1 + \cos(\frac{5\pi}{8})][1 + \cos(\frac{7\pi}{8})]$?,This is rather a simple problem that I'm posting ; looking forward not for the solution of it but the different ways it could be solved. What is the value of the following expression? $$\left( 1+\cos { \left( \frac { \pi  }{ 8 }  \right)  }  \right) \left( 1+\cos { \left( \frac { 3\pi  }{ 8 }  \right)  }  \right) \left( 1+\cos { \left( \frac { 5\pi  }{ 8 }  \right)  }  \right) \left( 1+\cos { \left( \frac { 7\pi  }{ 8 }  \right)  }  \right) $$ Edit: Do I manually put the values of $\cos\frac{\pi}{8}$ and all other cosine terms? Is there a better and shorter way?,['trigonometry']
2352513,Definition of closed subscheme,"Let $(X,\mathcal O_X)$ be a scheme. I'm using the following definition from Görtz-Wedhorn. A closed subscheme of $(X,\mathcal O_X)$ is a scheme $(Z,\mathcal O_Z)$, where $i\colon Z\hookrightarrow X$ is a closed subset of $X$, and for which there exists an ideal sheaf $\mathcal I\subset\mathcal O_X$ together with an isomorphism $\mathcal O_X/\mathcal I\cong i_*\mathcal O_Z$. Elsewhere I've seen the definition that a closed subscheme is a scheme of the form $(Z,i^{-1}(\mathcal O_X/\mathcal I))$, where $Z\subset X$ is a closed subset and $\mathcal I\subset\mathcal O_X$ is an ideal sheaf. It seems like these definitions are equivalent. Certainly the first implies the second, since $i^{-1}i_*\mathcal O_z=\mathcal O_Z$. How do I show the other implication?","['schemes', 'algebraic-geometry']"
2352527,What is the value of the expression $\sin\frac{2\pi}{7}\sin\frac{4\pi}{7}+\sin\frac{4\pi}{7}\sin\frac{8\pi}{7}+\sin\frac{8\pi}{7}\sin\frac{2\pi}{7}$?,This is rather a simple problem that I'm posting ; looking forward not for the solution of it but the different ways it could be solved. What is the value of $\sin\frac{2\pi}{7}\sin\frac{4\pi}{7}+\sin\frac{4\pi}{7}\sin\frac{8\pi}{7}+\sin\frac{8\pi}{7}\sin\frac{2\pi}{7}$ Do I just use $\cos(a-b)-\cos(a+b) = 2\sin(a)\sin(b)$,['trigonometry']
2352536,Weak convergence of a sequence,"Consider the sequence $(x_n)$ in $(c_0,\|.\|_{\infty})$, where $x_n=e_1+e_2+\ldots +e_n;  e_n=(0,0,\ldots,1,0,\ldots)$ for all $n\in \mathbb N$. I want to show that $(f(x_n))$ converges in $\mathbb K$ but $(x_n)$ does not converge weakly in $(c_0,\|.\|)$. Let $f\in c_0^*$. Since $c_0^*$ is $(c_0,\|.\|)$ isometrically isomorphic to $\ell^1$, therefore there exists $y\in \ell^1$ such that $f(x)=\sum\limits_{n=1}^{\infty}x(n)y(n)$ for all $x\in c_0$. Then $f(e_n)=\sum\limits_{m=1}^{\infty}e_n(m)y(m)=y(1)+\ldots+y(m)\to \sum\limits_{m=1}^{\infty}y(m)$. But how to show that $(x_n)$ does not converge weakly in $c_0$? Please suggest anything.","['functional-analysis', 'weak-convergence']"
2352541,Eigenvalues and eigenvectors of a tridiagonal block Toeplitz matrix,"Let $T$ be the $2 N \times 2 N$ matrix defined by
$$
T = 
\begin{pmatrix}
A && B\\
-B^* && -A^*
\end{pmatrix}
$$
where $*$ is entry wise complex conjugation, $A$ is a Hermitian $N \times N$ tridiagonal Toeplitz matrix
$$
A
=
\begin{pmatrix}
	a & \alpha& 0 & \dots & 0\\
	\alpha^* & a & \alpha & \vdots & \vdots\\
	0 & \alpha^* & \ddots  & \ddots & \vdots\\
	\vdots & \ddots & \ddots & a & \alpha\\
	0 & \dots & \dots & \alpha^* & a
	\end{pmatrix}
$$
with $a$ real and $\alpha$ in general complex and $B$ is the symmetric tridiagonal Toeplitz matrix
$$
B
=
\begin{pmatrix}
	b & \beta& 0 & \dots & 0\\
	\beta & b & \beta & \vdots & \vdots\\
	0 & \beta & \ddots  & \ddots & \vdots\\
	\vdots & \ddots & \ddots & b & \beta\\
	0 & \dots & \dots & \beta & b
	\end{pmatrix}
$$
where $b$ is real and $\beta$ is complex. I want to find the eigenvalues of eigenvectors of $T$. Here's what I have so far. If $\alpha$ is real, then the solution is quite simple since $A$ is symmetric. Thus, $T$ can be written as
$$
T = i \sigma_x \otimes Im(B)+i\sigma_y \otimes Re(B)+\sigma_z \otimes A
$$
where $\sigma_i$ are the usual Pauli matrices. It is well known that symmetric tridiagonal Toeplitz matrices all the same eigenvectors and their eigenvalues are particularly simple. We can simultaneously diagonalize $Re(B), Im(B),$ and $A$ and rewrite $T$ as a sum of $2 \times 2$ block matrices
$$
T = \sum_{n =1}^N 
\begin{pmatrix}
a+ 2 \alpha \cos(\frac{\pi n}{(N+1)}) && b+\beta \cos(\frac{\pi n}{(N+1)})\\
-(b+\beta^* \cos(\frac{\pi n}{(N+1)})) && -(a+ 2 \alpha \cos(\frac{\pi n}{(N+1)}))
\end{pmatrix}
$$
And finding the eigenvalues and eigenvectors becomes diagonalizing a $2 \times 2$ matrix. Now if $\alpha$ is complex, we encounter a problem. $T$ can now be written as
$$
T = Id \otimes Im(A) +i \sigma_x \otimes Im(B)+i\sigma_y \otimes Re(B)+\sigma_z \otimes Re(A)
$$
by hermicity of $A$, $Im(A)$ is an antisymmetric tridiagonal Toeplitz matrix which doesn't commute with $Re(A), Re(B), Im(B)$ (but it almost commutes in that the only non zero elements of the commutator are at the top left and bottom right of the matrix). So I tried something else. In a different basis (well really just swapping the tensor product) we get 
$$
T = Im(A) \otimes Id + Im(B) \otimes i \sigma_x + Re(B) \otimes i\sigma_y+ Re(A) \otimes \sigma_z
$$
Which we can write as a block tridiagonal Toeplitz matrix
$$
T 
=
\begin{pmatrix}
	C & D& 0 & \dots & 0\\
	E & C & D & \vdots & \vdots\\
	0 & E & \ddots  & \ddots & \vdots\\
	\vdots & \ddots & \ddots & C & D\\
	0 & \dots & \dots & E & C
	\end{pmatrix}
$$
with $C, D, E$ the $2 \times 2$ matrices.
$$
C = 
\begin{pmatrix}
a && b\\
-b && -a
\end{pmatrix}
\: \: \:
D =
\begin{pmatrix}
\alpha^* && \beta\\
-\beta^* && -\alpha
\end{pmatrix}
\: \: \:
E =
\begin{pmatrix}
\alpha && \beta\\
-\beta^* && -\alpha^*
\end{pmatrix}
$$
And so the eigenvalue problem becomes a three term difference equation 
$$
E\begin{pmatrix}x_{j-1} \\ y_{j-1}\end{pmatrix} + C\begin{pmatrix}x_{j} \\ y_{j}\end{pmatrix} + D\begin{pmatrix}x_{j+1} \\ y_{j+1}\end{pmatrix}
=
\lambda \begin{pmatrix} x_{j} \\ y_{j} \end{pmatrix}
$$
with boundary conditions $x_0 = x_{N+1} = y_0 = y_{N+1}$. Now, like in the regular tridiagonal Topeplitz matrix case, I make an ansatz of $x_j = x r^j$ and $y_j = y r^j$ the difference equation becomes
\begin{equation}
(rE+(C-\lambda)+r^{-1}D )
\begin{pmatrix}
x \\y
\end{pmatrix}
=
0
\end{equation}
For a non trivial solution to our equation we need the determinant to vanish, which is a polynomial of degree four in $r$ and we assume for the moment that there are four distinct roots $r_k$, $k = {1,2,3,4}$. Thus the general solution is of the form
$$
\begin{pmatrix}
x_j \\ y_j 
\end{pmatrix}
=
\sum_{k = 1}^4 c_k \lambda^j_k 
\begin{pmatrix}
x_k \\ y_k
\end{pmatrix}
$$
where $(x_k,y_k)$ is in the kernel of the difference equation above. We need to find the $c_k$ which satisfy the boundary conditions which equivalent to finding a non trivial solution to
$$
\begin{pmatrix}
x_1 & x_2 & x_3 & x_4 \\
y_1 & y_2 & y_3 & y_4 \\
\lambda_1^{N+1} x_1 & \lambda_2^{N+1} x_2 & \lambda_3^{N+1} x_3 & \lambda_4^{N+1} x_4 \\
\lambda_1^{N+1} y_1 & \lambda_2^{N+1} y_2 & \lambda_3^{N+1} y_3 & \lambda_4^{N+1} y_4
\end{pmatrix}
\begin{pmatrix}
c_1\\
c_2\\
c_3\\
c_4
\end{pmatrix}
=
\begin{pmatrix}
0\\
0\\
0\\
0
\end{pmatrix}
$$
For a nontrivial solution, we need the determinant to vanish, which imposes a conditions on the roots $\lambda_k$. It is at this point that I'm stuck and not sure what to do, because the determinant involves the eigenvectors $(x_k,y_k)$ which is involved and confusing. Any help would be greatly appreciated!","['eigenvalues-eigenvectors', 'tridiagonal-matrices', 'block-matrices', 'matrices', 'linear-algebra']"
2352545,Unsure of how to interpret the set $\mathbb{R}^X$ where $X$ is a real vector space?,"I recently came across the notation $\mathbb{R}^X$ and I'm not exactly sure what it means or how to 'visualize it'. The text it comes from is the following: Let $X$ be a real vector space and let $\mathcal{F} \subset
 \mathbb{R}^X$ be a set of real-valued functionals on $X$. How come the set of real functionals is a subset of $\mathbb{R}^X$? Is it possible to demonstrate why this is so with some simple example?","['functional-analysis', 'general-topology', 'notation', 'elementary-set-theory']"
2352560,Let $f$ be a continuous function satisfying $\lim \limits_{n \to \infty}f(x+n) = \infty$ for all $x$. Does $f$ satisfy $f(x) \to \infty$?,"Let $f: \Bbb R \to \Bbb R$ be a continuous function satisfying $f(x+n) \to \infty$ as a sequence in $n$, for all $x$. Does $f$ satisfy $f(x) \to \infty$ as $x\to \infty$? If we drop the continuity assumption then the claim is false, by considering a function tending more and more slowly to $\infty$ as we start at larger values in $(0,1)$. (Or many other examples) As for context: a variant of this claim (when $f$ is analytic and we replace $n$ by a general increasing sequence $a_n$) could be useful to me at some technical exercise, and this is a simplification which I still cannot tackle. Assuming by contradiction that $\exists M\forall x \exists x_0>x: f(x_0)\leqslant M$, we want to show that $\exists x \exists N>0 \forall n \exists n_0>n: f(x+n) \leqslant N$. No ""quantifiers-level"" logic seems to apply here. Any ideas?","['real-analysis', 'sequences-and-series', 'calculus', 'limits']"
2352622,How many isomorphisms are there between two cyclic groups of order $n > 0$?,"I'm stuck at this exercise. How can I approach this? I know that an isomorphism is a bijective homomorphism but we can't just count the number of bijections ($n!$), since we can't just assign every element to any other element. We need to work with the generators. A cyclic group of order n has $\phi (n) = |\mathbb Z  ^{*}_{n}|$ generators. And this is where I get stuck. How can I continue from here? Thank you","['abstract-algebra', 'group-isomorphism', 'cyclic-groups', 'group-theory', 'discrete-mathematics']"
