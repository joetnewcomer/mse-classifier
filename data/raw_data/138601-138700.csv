question_id,title,body,tags
2219891,Parital derivative of sigmoid function with respect to theta,"I am attempting to calculate the partial derivative of the sigmoid function with respect to theta: $ y = \frac{1}{1+ e^{-\theta x}}$ Let: $v = -\theta x $ $u = (1 + e^{-\theta x}) = (1 + e^v)$ Then: $ \frac{\partial y}{\partial u} = -u^{-2}$ $ \frac{\partial u}{\partial v} = e^v $ $ \frac{\partial v}{\partial \theta_i} = -x_i $ So, applying the chain rule: $ \frac{\partial y}{\partial \theta_i} $ $= \frac{\partial y}{\partial u} \frac{\partial u}{\partial v} \frac{\partial v}{\partial \theta_i}$ $= -u^{-2} e^v (-x_i)$ $= -(1 + e^v)^{-2} e^v (-x_i)$ $= -(1+e^{-\theta x})^{-2} e^{-\theta x} (-x_i)$ $=\frac{-x_ie^{-\theta x}}{-(1+e^{-\theta x})^2} $ At this point, I'm trying to figure out how to get it into this form: $ \frac{\partial y}{\partial \theta_i} = y(1 - y)$ How do I accomplish this? Also, it is alleged that: $1 - \frac{1}{1+ e^{-\theta x}} = \frac{e^{-\theta x}}{1 + e^{-\theta x}}$ How is this possible?","['calculus', 'algebra-precalculus', 'machine-learning', 'statistics', 'linear-algebra']"
2219907,Parametrization of the Möbius strip and orientation,"I'm supposed to prove that the Möbius strip is not orientable by using this lemma: Lemma: Let $S\subset\mathbb{R}^3$ be a surface such that $S=S_1\cup S_2$, where $S_1$, $S_2$ are connected, orientable surfaces, whose intersection $S_1\cap S_2$ has exactely two connected components $A$ and $B$. If there is an orientation $N_1$ for $S_1$ and $N_2$ for $S_2$ such that $N_1=N_2$ in $A$ and $N_1\neq N_2$ in $B$, then $S$ is not orientable. I'm using the following parametrization for the Möbius strip: $$X(u, v)=\left((2-v\sin\frac{u}{2})\sin u, (2-v\sin\frac{u}{2})\cos u,v\cos\frac{u}{2}\right)$$ for $u\in[0,2\pi]$ and $u\in(-1,1)$ I've defined $S_1:=X\left((\frac{\pi}{2}, \frac{3\pi}{2})\times(-1,1)\right)$ and $S_2:=X\left((0,\frac{3\pi}{4})\cup(\frac{5\pi}{4}, 2\pi)\times(-1,1)\right)$, so that $S_1\cap S_2=X\left((\frac{\pi}{2}, \frac{3\pi}{4})\times(-1,1)\right)\cup X\left((\frac{5\pi}{4}, \frac{3\pi}{2})\times(-1,1)\right)$ (one of the components is $A$, the other one $B$). My question is: how do I prove that the induced orientations are the same in $A$ and opposites in $B$, since for both $S_1$ and $S_2$ we are using the exact same formula $X(u,v)$? How does the minus sign actually appear?","['orientation', 'differential-geometry', 'geometry']"
2219919,Computing the expectation of $X^n e^{-\lambda X}$,"Is there an elegant (probabilistic) way to compute $E(X^n e^{-\lambda X})$, where $n \in \mathbb{N}$, $\lambda > 0$ and $X$ is a random variable with normal distribution $N(\mu,\sigma^2)$? Alternatively, my question is simply how to compute the integral
$$
\frac{1}{\sqrt{2\pi\sigma^2}} \int_{-\infty}^{\infty} x^n e^{-\lambda x} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx.
$$","['expectation', 'probability-theory', 'improper-integrals', 'integration', 'probability']"
2219929,Ideal class group of $\mathbb Q[\sqrt{-29}]$,"What is the ideal class group of $\mathbb Q[\sqrt{-29}]$? I think it could be the cyclic group of order 4 or order 6, but am not sure.","['number-theory', 'algebraic-number-theory']"
2219933,How to solve the limit for power tending to infinity,"How does one find
$$
\lim_{x \to 0} \left[1 + x\sin(\pi - x) \right]^{1/x}\ ?
$$ Does the limit exist? If yes, how is it found?","['calculus', 'limits']"
2220022,Question on lines of regression,I know how to find the line of regression when given the set of values of x and y. But in this question i don't have any idea what to do. I am a beginner . I will really appreciate the help.,"['regression', 'linear-regression', 'regression-analysis', 'statistics', 'probability']"
2220024,"Cup product of $H^{\bullet}(\mathbb{R}P^{2};\,\mathbb{Z}/2)$ in terms of cellular cohomology","Considering the CW complex structure on $\mathbb{R}P^{2}$ consisting of one $0$-cell, one $1$-cell and one $2$-cell. Then the cellular chain complex of $\mathbb{R}P^{2}$ in $\mathbb{Z}/2$-coefficient is given by
$$\mathbb{Z}/2\cdot e^{2} \longrightarrow \mathbb{Z}/2\cdot e^{1} \longrightarrow \mathbb{Z}/2\cdot e^{0}$$
where $e^{i}$ denotes the $i$-cell and all differentials are zero. Applying the functor $\mathrm{Hom}(-,\,\mathbb{Z}/2)$, we can get the cellular cochain complex of $\mathbb{R}P^{2}$ in $\mathbb{Z}/2$-coefficient:
$$\mathbb{Z}/2\cdot \epsilon ^{2} \longleftarrow \mathbb{Z}/2\cdot \epsilon ^{1} \longleftarrow \mathbb{Z}/2\cdot \epsilon ^{0}$$
where $\epsilon^{i}$ can be thought as the function sending $e^{i}$ to $1$. Since differentials are all zero, the cellular cohomology of $\mathbb{R}P^{2}$ in $\mathbb{Z}/2$-coefficient is also generated by $\epsilon^{i}$'s. My question is what is the cup product $\epsilon ^{1}\cup \epsilon ^{1}\in H^{2}(\mathbb{R}P^{2};\,\mathbb{Z}/2)$? It could be $0$ or $\epsilon ^{2}$. The cup product can be viewed as the composition of 
$$H^{1}(\mathbb{R}P^{2};\,\mathbb{Z}/2)\otimes H^{1}(\mathbb{R}P^{2};\,\mathbb{Z}/2) \longrightarrow H^{2}(\mathbb{R}P^{2}\times \mathbb{R}P^{2};\,\mathbb{Z}/2)\longrightarrow H^{2}(\mathbb{R}P^{2};\,\mathbb{Z}/2)$$ The first map sends $\epsilon^{1}\otimes\epsilon^{1}$ to the 2-cochain on $\mathbb{R}P^{2}\times \mathbb{R}P^{2}$ that takes value $1$ on $e^{1}\times e^{1}$ and $0$ on $e^{2}\times e^{0}$ and $e^{0}\times e^{2}$. The second map is dual to the cellular approximation of the diagonal map $$\Delta:\,\mathbb{R}P^{2}\longrightarrow\mathbb{R}P^{2}\times \mathbb{R}P^{2}$$
However, I don't understand this map. If it sends $e^{2}$ to $e^{1}\times e^{1}$, then we have $\epsilon ^{1}\cup \epsilon ^{1}=\epsilon^{2}$, otherwise we will have $\epsilon ^{1}\cup \epsilon ^{1}=0$. I really appreciate if someone can give me some explanations on this cup product via cellular cochains or some geometry behind this product.","['algebraic-topology', 'general-topology', 'homology-cohomology', 'cw-complexes']"
2220045,Changing signs of integration limits,"When we reverse the limits and then change the signs of the limits of the definite integral $$\int\limits_{-R}^{-\epsilon}\frac{e^{ix}}{x}dx $$ the integral becomes
$$-\int\limits_{\epsilon}^{R}\frac{e^{-ix}}{x}dx $$ This is how the process appears to go: (1) Changing the order of the limits of integration adds the minus sign before the integral. This is clear. (2) Changing the signs of the limits changes the signs of the $x$'s, but also the sign of $dx$ appears to have changed as well, for otherwise there wouldn't be the minus sign before the integral. Part (2) is not completely clear to me, because $dx$ arises from the Riemann sums, in which $\Delta x$ is always a positive quantity. So what exactly happens when we change the limits' signs?","['integration', 'definite-integrals', 'analysis']"
2220082,Why is the isometry group of a closed negatively curved manifold finite?,"Why is the isometry group of a closed negatively curved manifold finite? If the isometry group is infinite, then it must have a subgroup that is isomorphic to $S^1$, but how do I take advantage of this fact?","['differential-geometry', 'lie-groups']"
2220090,"Meaning of the Notation f ∈ F[0, 1]?","I would like to know what the notation F[0,1] represents. I tried searching ""F[0,1]"" on google but the symbols makes it hard for relevant results to come up. It appeared like this on my homework: Let V = {f ∈ F[0, 1]|f(0) = f(1) = 0} My guess is that the x in f(x) is on the closed interval [0,1]. Could someone confirm this for me? Thank you","['notation', 'functions']"
2220116,Sum of Sequence with Squares of Fibonacci Numbers in Denominator,"Find the sum of this sequence:
$$\frac{1}{1^2+1}-\frac{1}{2^2-1}+\frac{1}{3^2+1}-\frac{1}{5^2-1}+\frac{1}{8^2+1}-...$$ So, alternating series, but I've got nothing. I tried regrouping by pairs and got $$\frac{1}{6}+\frac{7}{120}+\frac{103}{10920}$$
which, helped me none.","['fibonacci-numbers', 'sequences-and-series']"
2220120,Dual space - bounded functionals?,"I'm taking a course on functional analysis at the moment and the lecturer has defined the dual space of a normed space $X$ to be the space of all bounded linear functionals and denoted it $X^*$. However if I look at other references (such as Wikipedia or Wolfram MathWorld) the definition of the dual space is given to be the space of all linear functionals (ie, they don't specify that they have to be bounded). Does this imply that any linear functional is necessarily bounded, or is my lecturer giving an unusual definition, or is the definition on Wikipedia wrong? I'm just a bit confused about this.",['functional-analysis']
2220210,Continuity of the derivative at a point given certain hypotheses [duplicate],"This question already has answers here : Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$. (6 answers) Closed 7 years ago . Suppose that $h$ is continuous on $[a,b]$ and differentiable on $(a,b)$, and that $c \in (a, b)$. Suppose also that $\lim\limits_{x \to c} h'(x)$ exists. Prove that $h'$ is continuous at $c$. I really have no idea how to think about this problem. I know if the limit exists then it's differentiable at the point, i was assuming differentiability implied continuity. Someone please give me advice.","['derivatives', 'limits', 'calculus', 'continuity', 'analysis']"
2220211,Sum of limit inferior: $\liminf s_n + \liminf t_n \le \liminf (s_n+t_n)$,"I'm seeking to prove the following statement: $$\lim \inf s_{n} + \lim \inf t_{n} \le \lim \inf (s_{n}+t_{n})$$
provided that $s_{n}$ and $t_{n}$ are bounded. My solution so far: Given that $s_{n}$ and $t_{n}$ are bounded, $\lim \inf s_{n}$ and $\lim \inf t_{n}$ both exist and are real numbers. Call them $s$ and $t$ respectively. Now since $\lim \inf s_{n} = s$, given some $\epsilon > 0$, the inequality $s_{n} > s + \epsilon$ fails for a finite amount of $n$'s. These $n$'s then have the property that $s_{n} + t_{n} \le s + t_{n} + \epsilon$... So here I was able to find an inequality relating $s_{n}$ and $t_{n}$ but I seem to have it in the reverse order. Nor do I understand how to preserve the inequality if I argue about applying $\lim \inf$ to $s_{n}$ and $t_{n}$ in the inequality. Any help would be appreciated.","['limsup-and-liminf', 'real-analysis', 'inequality', 'limits']"
2220253,Prove that $\lim_{x \to2 }x^{2}+4x=12$,"Please check my prove we begin by $$x^{2}+4x-12<\epsilon $$ $$|x+6||x-2|<\epsilon $$ I will prove by use property 
$\lim_{x->n}f(x)g(x)=\lim_{x->n}f(x)\lim_{x->n}g(x)$ then we divide into to case $|x+6|<\sqrt{\epsilon }$ and $ |x-2|<\sqrt{\epsilon }$ and let$\epsilon ,\delta _{1}\delta _{2}>0$ $$0<|x-2|<\delta _{1}\rightarrow |x+6|<\sqrt{\epsilon }$$ Choose $\delta _{1}=\sqrt{\epsilon }$ then $|x+6|<\sqrt{\epsilon }$ $$0<|x-2|<\delta _{2}\rightarrow |x-2|<\sqrt{\epsilon }$$ Choose $\delta _{1}=\sqrt{\epsilon }$ then $|x+6|<\sqrt{\epsilon }$ then use property $\lim_{x->n}f(x)g(x)=\lim_{x->n}f(x)\lim_{x->n}g(x)$ we get $$|x+6||x-2|<\sqrt{\epsilon }\sqrt{\epsilon }$$ then $\lim_{x->2}x^{2}+4x=12$","['real-analysis', 'proof-verification', 'limits']"
2220308,Does the function $x \mapsto \sqrt{1-x^2}$ have a name?,"Define a function $$[-1,1] \rightarrow \mathbb{R}$$ $$x \mapsto x^\perp$$ as follows: $$x^\perp = \sqrt{1-x^2}.$$ I find this function to be pedagogically useful, to help students grasp certain facts about the circular functions and relationships between circles and right-angled triangles. Question. Does $x^\perp$ have an accepted name and/or notation? I might as well tell you guys how I use it. I begin by drawing a right-angled triangle with hypotenuse $1$ . One side is labelled $x$ . I ask the student to write find the length of the other side, and to begin by labelling the other side $y$ . So they solve $x^2+y^2=1^2$ for $y$ , and obtain $y = \sqrt{1-x^2}$ . I tell them: lets call $\sqrt{1-x^2}$ the ""Pythagorean complement"" of $x$ , and denote it $x^\perp$ . I get them to compute a few examples until they've internalized the meaning of the formula. Then we graph the whole thing an it ends up looking like a half-circle. Hmmm, why is that? I get them to compute the length of the vector $(x,x^\perp),$ and sure enough it's $1$ . That makes sense; we obtained $x^\perp$ by solving the equation $|(x,y)| = 1$ subject to the constraint $y \geq 0$ , and then defining $y= x^\perp$ . So it stands to reason that $(x,x^\perp)$ is always a point on the upper half of the unit circle. Then we move to trigonometry. I complete the half-circle to a unit circle, and draw a vertical line at $x=\frac{1}{2}$ . What are the $y$ -values of the points of intersection? The student puzzles out that these are $\pm x^\perp$ . I get them to write those two points as $(x,x^\perp)$ and $(x,-x^\perp)$ . To see why this makes sense, we go back to the equation $x^2+y^2 = 1^2$ and solve it properly, with no assumptions on $y$ beyond being a real number and satisfying this equation. We get $$x^2+y^2 = 1^2 \iff y^2=1-x^2 \iff y \in \pm \sqrt{1-x^2} \iff y \in \pm x^\perp.$$ Seems to make sense. I get the student to compute a few examples: $$0^\perp = 1, \qquad \left(\frac{1}{2}\right)^\perp = \frac{\sqrt{3}}{2}, \qquad \left(\frac{1}{\sqrt{2}}\right)^\perp = \frac{1}{\sqrt{2}}, \qquad \mathrm{etc.} $$ I explain that this pairs off each point in $[0,1]$ with another point, such that the ordered pair $(x,x^\perp)$ is always on the unit circle in the first quadrant. We discuss whether or not $x \mapsto x^\perp$ is an involution. On the domain $[0,1]$ , it is. But on $[-1,1]$ , all we can say is that $(x^\perp)^\perp = |x|.$ Finally, we get to solving some trigonometric equations. In order to avoid complex numbers, I define $\mathrm{wrap} \,\theta = (\cos \theta, \sin \theta).$ The student computes $\|\mathrm{wrap}\,\theta\|$ and checks that this is always $1$ . So $\mathrm{wrap}$ lands us on the unit circle; it ""wraps"" the real line around the circle. Finally we try to solve some trigonometric equations. We proceed like so: TFAE $\cos \theta = \frac{1}{2}$ $\mathrm{wrap}\, \theta = \left(\frac{1}{2},\frac{\sqrt{3}}{2}\right) \vee \mathrm{wrap} \,\theta = \left(\frac{1}{2},-\frac{\sqrt{3}}{2}\right)$ $\left(\theta \in \frac{\pi}{3}+2\pi \mathbb{Z}\right) \vee \left(\theta \in \frac{5\pi}{3}+2\pi \mathbb{Z}\right)$ $\theta \in \left(\frac{\pi}{3}+2\pi \mathbb{Z}\right) \cup \left(\frac{5\pi}{3}+2\pi \mathbb{Z}\right)$ I think students appreciate this kind of reasoning, because it helps them understand why there's two families of solutions to each of these problems. For more advanced students, you can show them things like: $$(\cos\theta)^\perp = |\sin \theta|, \qquad (\sin\theta)^\perp = |\cos \theta|$$ $$\cos (\mathrm{arcsin}(x)) = \sin (\mathrm{arccos}(x)) = x^\perp$$ $$\frac{d}{dx} \mathrm{arcsin}(x) = \frac{1}{x^\perp}, \qquad \frac{d}{dx} \mathrm{arccos}(x) = -\frac{1}{x^\perp}, \quad \frac{d}{dx} \mathrm{arcsec} = \frac{1}{|x|x^\perp}$$ Etc. You can also give them some challenge problems related to the geometry of the circle. For instance, ask them to conjecture a value for $\int_{x=-1}^1 x^\perp$ . Addendum. I just learned that this function shows up when sums of inverse trigonometric functions are involved . In particular: $$\sin^{-1}(a) \pm \sin^{-1}(b) = \sin^{-1}(ab^\perp \pm a^\perp b)$$ $$\cos^{-1}(a) \pm cos^{-1}(b) = \cos^{-1}(ab \mp a^\perp b^\perp)$$","['calculus', 'terminology', 'triangles', 'geometry', 'education']"
2220337,$f(z)$ entire and $|f(z)| \le (1+|z|)^n$ implies $f(z)$ is polynomial,"Suppose that $f:\mathbb{C}\to \mathbb{C}$ is an entire function, $n\ge 1$ is an integer, and that $|f(z)|\le (1+|z|)^n$ for all $z\in\mathbb{C}$. Prove that $f$ is a polynomial. Proof : Since $f$ is entire, we can write it as $$f(z) = \sum\limits_{m=0}^\infty c_m z^m$$ By Cauchy Estimates, for any closed disk $\mathbb{D}$ of radius $r>0$ centred about $z=0$, $$|f^{(m)}(0)|\le \frac{M_r m!}{r^m}$$ where $M_r=\sup\{|f(z)|:z\in\mathbb{D}\}\le (1+r)^n$. Let $n<m$, then $$ |c_m|=\frac{|f^{(m)(0)}|}{m!}\le \frac{M_r m!}{m! r^m}=\frac{M_r}{r^m}\le \frac{(1+r)^n}{r^m} $$ Also, $|c_m|=\lim\limits_{r\to \infty}|c_m|\le 0$. Hence, $f(z)=c_0+c_1z+\dots+c_nz^n$ is a polynomial of at most degree $m$. My question is this : how does the above proof show that $f$ is a polynomial?","['complex-analysis', 'polynomials', 'entire-functions', 'proof-explanation']"
2220389,For which sets of parameters will this system of equations have no solution?,"If $S$ is the set of distinct values of '$b$' for which the following system of linear equations \begin{align} 
 x + y + z = 1\\
 x + ay + z = 1\\ 
 ax + by + z = 0
 \end{align}
  has no solution, then $S$ is: a singleton an empty set an infinite set a finite set containing two or more elements There's no information given about value of $a$.
You will be getting two cases: For $a=1, b$ has one value $b=1$ For $a$ not equal to $1 , b$ has no value.","['linear-algebra', 'systems-of-equations']"
2220399,Uniqueness of limit point of a Cauchy Sequence,"I'm trying to show that the closure of a Cauchy sequence is countable, and the hint for the question is to show that if $(x_n)$ is Cauchy, then it has at most one limit point. I'm a little bit confused between the idea between the idea of a limit point of a set and a limit of a sequence. I know that if $\{x_1,x_2,...\}$ is a set, then $x$ is a limit point if $\forall r >0, \exists x_k \neq x $ such that $x_k \in B_r(x)$. Now I also know what a limit of a sequence is, but since this isn't necessarily a complete metric space we don't know if $(x_n)$ converges. My first thought was to use the fact that Cauchy sequences are bounded, but I don't know where to go with that. Would appreciate any hints!","['cauchy-sequences', 'analysis']"
2220550,"A nice book on representation of groups (not too theoretical, for physisicts purposes)","I am looking for an easy to read book on representation theory. I learned some basics in group theory, differential geometry and lie algebra and I need to understand the representation of continous group. But I am more a physicist than a mathematician so I would like a not ""too theoretical"" book in math but something too understand the structure and the notions. To give you an idea I want to learn this to understand the usage of representations in quantum field theory (so it is really for physical purposes). I appreciated a lot all the answers but does it exist books with corrected exercises inside ? I am looking for exercices that check the comprehension of the chapter rather than ""hard"" ones. I forgot to ask it in the beginning. I know I am quite demanding but it would be really nice =)","['representation-theory', 'reference-request', 'book-recommendation', 'group-theory']"
2220578,"Reverse engineering ""nice"" matrices from the eigenvalues","Before beginning, I should note some similarities to the question: Building matrices from eigenvalues .  However, I have a different objective. The Setup When writing problems for an introductory linear algebra course, a generic question would be Find the eigenvalues of $A= \begin{bmatrix} \dots \end{bmatrix}$ . From an instructor perspective, it is generally desirable that the computation be reasonably straightforward (e.g., not tasking students with finding roots of an irreducible quintic). Furthermore, the goal of the question is whether students can correctly find the characteristic polynomial and solve for the roots, rather than the ability to carefully add numerous fractions. As such, matrices $A$ with integer entries are generally preferable, perhaps along with a bias towards positive entries that aren't too large. However, we don't want to make the problem too easy. For example, tasking students with finding the eigenvalues of a diagonal/triangular matrix doesn't make for a particularly good question (unless it is specifically a question of recognizing this property). As such, it is probably best to write such a question by starting with the eigenvalues and working backwards to generate a matrix $A$ with those eigenvalues. These thoughts lead me to an (admittedly vague) definition: A "" nifty matrix "" $A$ should Have a given set of eigenvalues $\{\lambda_1, \dots, \lambda_n\}$ . Contain only non-zero integers: $A = (a_{ij}) \in \{\mathbb{Z}\setminus\{0\}\}^{n \times n}$ Note that our conditions necessitate that the eigenvalues be algebraic integers and that the list of eigenvalues must contain all of the Galois conjugates. For example, $$ D= \begin{bmatrix} 3 & 0 \\ 0 & 2 \end{bmatrix}, \quad T= \begin{bmatrix} 3 & 7 \\ 0 & 2 \end{bmatrix}, \quad \text{ and } A=\begin{bmatrix} 1 & 1 \\ -2 & 4 \end{bmatrix} $$ all have the same eigenvalues, but only $A$ is ""nifty matrix"" for the eigenvalues $\{3,2\}$ . Similarly, $$A= \begin{bmatrix} 2 & 1 \\ 1 & 1 \end{bmatrix}$$ is a ""nifty matrix"" for the eigenvalues $\lambda_\pm = \frac{3 \pm \sqrt{5}}{2}$ . The Goal Imagine that you're stuck in a textbook factory and need to write hundreds of ""compute the eigenvalues"" problems. How would you set about your task? Since you are picking the eigenvalues at the start, you can also control the characteristic and minimal polynomials of $A$ , $\chi_A$ and $\mu_A$ . The way I envision this working is a function / algorithm that gives a (perhaps non-unique) mapping $$\{\text{eigenvalues & min. or char. poly} \} \longrightarrow \text{nifty matrix}. $$ A simple approach Start with a list of integer eigenvalues. Form a diagonal matrix (or Jordan block matrix or upper-triangular matrix) $M$ that has the desired eigenvalues. Build a matrix $P$ by doing some row operations on the identity matrix, without rescaling rows or adding non-integer copies of rows. By Cramer's rule, $P^{-1}$ will only have integer entries as well. Form $A= P M P^{-1}$ . See how we did. Keep trying different $P$ matrices until something works. A slightly more sophisticated approach. This approach has the benefit of starting with the characteristic polynomial, which allows you to generate nifty matrices for eigenvalues that aren't necessarily integers (unlike the above approach). Pick a suitable characteristic polynomial $\chi$ and minimal polynomial $\mu$ , each with integer coefficients. Build a matrix $C$ that will be the rational canonical form of $A$ using the characteristic polynomial and minimal polynomial. Note that $C$ will have integer entries. Use our trick from the previous algorithm: $A=P C P^{-1}$ where $\det(P)= \pm 1$ . See how we did. Keep trying different $P$ matrices until something works. The Question Is there a better way? Note that both of these algorithms are ill-defined--how do we find a $P$ that ensures $A$ has no zero entries? As an extension of this problem, suppose we defined a super nifty matrix to be a nifty matrix  that minimizes $f(A) = \max_{i,j} \{|a_{ij|} \}$ over all similar nifty matrices? How could we find a (probably non-unique) minimizer? What if we minimized with respect to $g(A) = \sum_{i,j} |a_{ij}|$ or any other suitable norm on the entries? What if we decided that negative numbers are too messy and wanted $A=(a_{ij}) \in \mathbb{N}^{n\times n}$ ? What conditions would this impose on the eigenvalues and our algorithms? Edited to Add: I should note that such ""nifty matrices"" truly aren't nice problems, outside of the $2 \times 2$ case. This is part of why I didn't call them ""nice matrices,"" but rather ""nifty"" as in ""Hey! This messy looking matrix of integers has my desired eigenvalues/ characteristic polynomial! Isn't that nifty?!"" I am primarily interested in this problem as a mathematical construct; generating a clever linear algebra problem is only a motivating idea. For another, perhaps more ""realistic"" motivation, you can recast the problem as: Given a list of $n$ suitable eigenvalues, is it possible to created a complete graph on $n$ vertices such that each edge has a non-zero (possibly negative) integer weight and the weighted transition matrix has the desired eigenvalues? What is the ""simplest"" such graph? How can you algorithmically construct this graph / weighted transition matrix?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2220613,"""Proper"" definition of a proper map?","What is the proper definition of a proper map? Here are a few definitions I've come across: A continuous map $f: X \to Y$ is proper if preimages of compact subsets are compact. A continuous map $f: X \to Y$ is proper if it is closed with compact fibres. Kashiwara and Schapira define a map $f: X \to Y$ to be proper if it is closed and its fibres are compact and relatively Hausdorff (two distinct points in the fibre have disjoint neighbourhoods in $Y$). Definitions 1. and 2. agree when $X$ is Hausdorff and $Y$ is locally compact Hausdorff. Kashiwara and Schapira state that definition 3. agrees with definition 1. when both $X$ and $Y$ are locally compact (and Hausdorff I assume?). There are also notions of proper morphisms of schemes and proper geometric morphisms of topoi , though I do not really understand these yet. However, I would assume that they should be attempting to capture the same sort of notion of ""properness"" as in topological category. It seems that a proper map in some category should satisfy some property, and I am wondering what that property should be. In other words, what is the correct ""abstract"" definition of properness? I have a feeling it should have something to do with a proper base change theorem in cohomology.","['algebraic-topology', 'general-topology', 'topos-theory', 'algebraic-geometry']"
2220622,Let $n$ be an integer such that if $d | n$ then $d + 1 | n + 1.$ Show that $n$ is a prime number,"Let $n$ be an integer such that for any integer $d$, if $d | n$ then $d + 1 | n + 1$. Show that $n$ is a
prime number or equal to $1$ My workout... Suppose $n = xy$ for some postive integers $x$ and $y. x|n$, and hence we assume without loss of generality $x + 1|n + 1.$ Then $x|xy + 1$. However, $xy + x$ is divisible by $x$. This implies $x − 1$ is divisible by $x$,
which is an impossibility if $x$ is not equal to $1$.
 Therefore whenever $n$ is decomposed
into two factors, one must turn out to be $1$. Hence $n$ must be a prime. I am looking for any other method which solves this quickly and more quickly...","['number-theory', 'prime-numbers']"
2220623,Geometric meaning of Archimedean property of real numbers.,"I was reading about real number system briefly as a part of my pre-calculus study and read about  Archimedean property of real numbers which says that If $ x \gt  0 $ and if  * y *  is  an arbitrary real number, there exists a positive integer * n * such  that $ nx \gt y $. They stated it as a consequence of least upper bound axiom for real numbers. Geometrically they said it means that * any  line segment, no matter how long, may be covered by a finite number of line segments of a given positive length, no matter how small. * I could well understand the statement but could not relate it with the Archimedean property . I thought that may be in this geometric intuition n may mean that finite number of small line segments and x and y be length of the small and large line segments respectively. But I'm not sure about this and need help in this matter. Any suggestions or help is appreciated. Thanks .","['algebra-precalculus', 'real-numbers']"
2220645,The dual of $L^p$ is $L^q$,"Let $1 \leq p < \infty$ and $1/p + 1/q = 1$. Then if $l$ is a bounded linear functional on $L^p(E, d\mu)$ where $\mu$ is a $\sigma$-finite measure, $l(f) = \int_Efgd\mu$ for some $g \in L^q(E,d\mu)$ with $\|g\|_q = \|l\|_{op}$. The statement follows from the Radon-Nikodym Theorem, which requires $\sigma$-finiteness. Is it true that if we let $p>1$ we can get rid of $\sigma$-finiteness in the proof? Is there a reference for this? What is the idea of the proof?","['real-analysis', 'dual-spaces', 'functional-analysis', 'lp-spaces', 'measure-theory']"
2220773,What are the Second Order Cauchy-Riemann equations in terms of polar co-ordinates?,"For a complex function $f(x + i y) = u(x,y) + i v(x,y)$, in Cartesian co-ordinates the Cauchy-Riemann equations are $u_x = v_y$ and $u_y = -v_x$, which can be used to find the second order Cauchy-Riemann equations: $u_{xx} = -u_{yy}$ and $v_{xx} = -v_{yy}$. In polar co-ordinates, the Cauchy-Riemann equations are $u_r = \frac{1}{r}v_{\theta}$ and $v_r = -\frac{1}{r}u_{\theta}$. In an attempt to find the second order Cauchy-Riemann equations for polar co-ordinates, I came out with two separate answers depending on whether I differentiated the polar Cauchy-Riemann equations with respect to $r$ or  $\theta$. With respect to $\theta$, I attained: $u_{rr} = -\frac{1}{r^2}u_{\theta \theta}$ and $v_{rr} = -\frac{1}{r^2}v_{\theta \theta}$, but when I differentiate with respect to $r$, I get $u_{rr} = -\frac{1}{r^2}v_{\theta} - \frac{1}{r^2}u_{\theta \theta}$ and $v_{rr} = \frac{1}{r^2}u_{\theta} -\frac{1}{r^2}v_{\theta \theta}$, due to using the product rule. Are either of these versions correct, and why does one, if not both, of them not give the correct answer?","['derivatives', 'complex-analysis', 'complex-numbers', 'polar-coordinates']"
2220778,Liouvilles theorem question - show $f$ is constant,"Let $f: \mathbb C \to \mathbb C$ be an analytic function, such that for all $z\in\mathbb C$, $$| \operatorname{Re}(f(z))\operatorname{Im}(f(z)) | \le 1.$$
  I have to show that $f$ is constant. I don't know how to apply Liouville's theorem to the question, but I can tell it is bounded, thus the theorem should apply.
Any help would be appreciated.",['complex-analysis']
2220815,Intersection of two $\sigma$-algebras is not an algebra,"I have the following task: Give an example of two $\sigma$-algebras such that their intersection is not an algebra There is a hint that such situation is possible only when their units differ, but I still can't come up to solution. Let $S_1,S_2$ be our $\sigma$-algebras and $X = S_1 \cap S_2$. 1) $A,B \in X \Rightarrow A \setminus B \in X$. This is obvious because $A,B \in S_i \Rightarrow A \setminus B \in S_i$ (for $i=1,2$). 2) Similarly, $A,B \in X \Rightarrow A \cup B \in X$. 3) Similarly, any countable union is in $X$ too (though we do not need $X$ be a $\sigma$-ring by condition of the task). So $X$ is at least a $\sigma$-ring and it must not contain a unit (or otherwise it will become an algebra). If $X$ is countable, then union of all its elements $A = \bigcup A_i$ is contained in $X$. This easily makes $A$ a unit. Thus our $X$ must be uncountable. And from here I can neither prove that $X$ contains a unit nor disapprove it.",['elementary-set-theory']
2220885,Prove that $f$ must have an inflection point at $0$,"Suppose $f$ is a function such that $f'(x)>0$ $\forall x\not=0$ and $f'(0)=0$. Also, $f''$ is a continuous $\text{one to one}$ function on some open interval containing $0$. Prove that $f$ must have an inflection point at $0$. Pf: Let a,b be arbitrary values in the open interval containing $0$ such that $a<0<b$ Since $f''$ is a continuous $1-1$ on [a,b], then either $f'''>0$ $\forall x \in [a,b]$ or $f'''<0$ $\forall x \in [a,b]$. So, -$f''
$ is continuous on $[a,b]$ and $f''$ is differentiable on $(a,b)$ By the mean value theorem, there exists $c$ with, $a<c<b$ such that $$f''(c)=\frac{f'(b)-f'(a)}{b-a}$$ Assuming I am even going the right direction with this, I do not know how to show that $f''(0)=0$ and that $f''$ changes sign at $0$. Most of what I am reading speaks in regards to a $\delta$ neighborhood of $0$ where I may be able to prove a sign change. Any helpful hints or guidance is greatly appreciated. Preferably more leaning towards hints and NOT full blown spoilers on this question. :) EDIT: $f''$ is not known to be differentiable, $f'$ is known to be differentiable and we are applying the mean value theorem to it.","['derivatives', 'real-analysis', 'calculus', 'proof-writing', 'proof-explanation']"
2220916,Proof that the incidence matrix of a laminar family is TU.,"A friend and I wrote a proof for this using the consecutive ones property that I haven't seen anywhere, so I thought I would share it here. $\textit{Def:}$ A matrix has the Total-Unimodularity (TU) property if the determinant of all of its square submatrices has determinant 1, -1, or 0. $\textit{Def:}$ A family of subsets $S$, is called laminar if for all $s,t \subset S$, if $s \cap t$ is not empty, then either $s \subset t$, or $s \supset t$. Let $S$ be a laminar family of a nonempty finite set $V$, and let $A_5$ denote its $M \times N$ incidence matrix. Prove that $A_S$ is TU.","['matrices', 'total-unimodularity', 'linear-algebra']"
2220918,What does this mean $\mu\{x:\bigcap_\limits{k\geqslant 1}^{}\bigcup_\limits{n}^{}\bigcap_\limits{l\geqslant n}^{}{|f_l-f|}\leqslant \frac{1}{k}\}$,"I am studying the following theorem: Consider $E\in\mathscr{F}$(sigma-algebra), and $E\in\Omega$ defined on a measure space $(\Omega,\mathscr{F},\mu)$. Suppose $\mu(E)<\infty$, and $\{f_n\}$ is a sequence of measurable functions on $E\to\mathbb{R}$ which are finite almost everywhere and converge almost everywhere to a function $f:E\to\mathbb{R}$ which is also finite almost everywhere. Then $f_n\to f$ almost uniformly in $E$.
The proof starts with the following: $\epsilon$>0 What does this mean? How do I read this intersection and union signs in this case? Thanks! $\mu\{x:\bigcap_\limits{k\geqslant 1}^{}\bigcup_\limits{n}^{}\bigcap_\limits{l\geqslant n}^{}{|f_l-f|}\leqslant \frac{1}{k}\}$","['functional-analysis', 'measure-theory', 'elementary-set-theory']"
2220988,Find a six-digit perfect square of a particular form – BMO 1993 P1,"1993 British Mathematical Olympiad, Round 1, Question 1 Find, showing your method, a six-digit integer $n$ with the following properties: $n$ is a perfect square, the number formed by the last three digits of $n$ is exactly one greater than the number formed by the first three digits of $n$ . (Thus $n$ might look like $123124$ , although this is not a square.) I gave it a try, albeit number theory not being a strong suit of mine. $$\text{n = }\overline{ABCABD}\text{, where } D = C +1$$ $$n = 10^5\times A + 10^4\times B + 10^3\times C + 10^2\times A + 10^1\times B + 10^0\times D \\=A(10^5+10^2) + B(10^4+10) + C(10^3+10^0)+1\qquad\qquad\,$$ $$\\n-1 = (10^3+1)\times(10^2\times A+10^1\times B + 10^0 \times C)\\\frac{n-1}{1001} = \overline{ABC}$$ $\text{The question then becomes:}\\\text{Find } r\in\mathbb{Z^+}\,(r = \overline{ABC})\text{ such that } $ $$n = 1001r + 1\\10^5\le n\le 10^6-1,\,n\in\mathbb{Z^+}$$ This, however, appears to have gotten me nowhere as I have no idea how to solve that linear equation. SIDE NOTE: Using Python, I found that $r\in\{{183,328,528,715}\}$ .
Therefore, $n\in\{{183184,328329,528529,715716}\}$ . However, I would like to see a mathematical solution.","['number-theory', 'contest-math', 'elementary-number-theory']"
2220993,What is the complement of empty set?,"We have learned that for universal set $U$ and  for set $A$ belonging to $U$,
$A^c=U-A$ but what about for the empty set?",['elementary-set-theory']
2221022,What angle does minute hand and hour hand clock inclined to each other at $2:25$,"What angle does minute hand and hour hand clock inclined to each other at $2:25$ My Attempt: The hour hand of a clock rotate throufh an angle of $30°$ in $1$ hour, So, At $2$o'clock, $2$ hrs$\equiv 60°$ Again, The minute hand of a clock rotate through an angle of $6°$ in $1$ minute. So, At $2:25$, i.e, $25$min$\equiv 150°$ What should I do further?","['algebra-precalculus', 'trigonometry']"
2221048,Contour integral of $e^z / (z-1)^n$.,"I am attempting to evaluate the following contour integral: 
\begin{equation*}
\oint_{C(i,2)} \frac{e^z}{(z-1)^n} \,\text{d}z
\end{equation*}
where $C(i,2)$ is the circle of radius 2 around $i$, $\forall\; n \in \mathbb{N}$. I attempted to use Cauchy's Integral formula, letting
\begin{equation*}
f_{n}(z) = \frac{e^z}{(z-1)^{n-1}}
\end{equation*}
$\forall\; n \in \mathbb{N}$, so then
\begin{align*}
f_n(z) = \frac{1}{2 \pi i} &\oint_{C(i,2)} \frac{f_n(z)}{z - 1} \,\text{d}z \\
\frac{2 \pi i e}{(1-1)^{n-1}} = &\oint_{C(i,2)} \frac{e^z}{(z-1)^n} \,\text{d}z
\end{align*}
But this is clearly undefined. Is there some key piece of understanding I'm missing with regards to this method or is there an entirely different tactic I am meant to take (or better yet, a result that simplifies this entirely)? Any help is appreciated. Thanks in advance.","['polynomials', 'cauchy-integral-formula', 'complex-analysis', 'integration', 'contour-integration']"
2221063,Finding the equation of electric field lines.,"Say we have a stationary particle located at $(0,0)$ with a positive unit charge, and a stationary particle located at $(a,0)$ with charge a negative unit charge. I want to find the field lines associated with the force field generated by the two charges. Suppose we have a charge with positive unit charge located at $(x_0,y_0)$ . The force acting on this charge can be described with the following (disgusting) vector: $$\left(\frac{x_0}{\left(x_0^2+y_0^2\right)^{3/2}}+\frac{a-x_0}{\left((x_0-a)^2+y_0^2\right)^{3/2}},\frac{y_0}{\left(x_0^2+y_0^2\right)^{3/2}}-\frac{y_0}{\left((x_0-a)^2+y_0^2\right)^{3/2}}\right)$$ This yields the following (disgusting) differetial-equation for the field lines associated with the force field: $$y'\left(\frac{x}{\left(x^2+y^2\right)^{3/2}}+\frac{a-x}{\left((x-a)^2+y^2\right)^{3/2}}\right)=\frac{y}{\left(x^2+y^2\right)^{3/2}}-\frac{y}{\left((x-a)^2+y^2\right)^{3/2}}$$ I can sort of simplify (but not really): $$y'\left(x\left((x-a)^2+y^2\right)^{3/2}+(a-x)\left(x^2+y^2\right)^{3/2}\right)=y\left(\left((x-a)^2+y^2\right)^{3/2}-\left(x^2+y^2\right)^{3/2}\right)$$ Unfortunately I have no idea how to solve this thing. Any help would be very much appreciated. I have posted the exact same question on physics.stackexchange Update: doing the same thing in polar coordinates yields the following differential equation (I think). $$\frac{\frac{dr}{d\theta}\sin\theta+r\cos\theta}{\frac{dr}{d\theta}\cos\theta-r\sin\theta}\left(\frac{\cos\theta}{r^2}+\frac{1}{\left(r^2\sin^2\theta+\left(a-r\cos\theta\right)^2\right)\sqrt{\left(\left(\frac{r\sin\theta}{a-r\cos\theta}\right)^2+1\right)}}\right)=\frac{\sin\theta}{r^2}-\frac{r\sin\theta}{\left(a-r\cos\theta\right)\left(r^2\sin^2\theta+\left(a-r\cos\theta\right)^2\right)\sqrt{\left(\left(\frac{r\sin\theta}{a-r\cos\theta}\right)^2+1\right)}}$$ I think the above only works for points whose $x$ -coordinate is less than $a$ .","['physics', 'ordinary-differential-equations']"
2221077,Find the probability that $Z_1$ is less than $Z_2$,"Let $Y=(Y_1,Y_2,Y_3)'\sim N_3(\mu,\sum)$ where $\mu=(1,-1,3)'$ and 
$$\sum= \begin{pmatrix} 
1 & 1 & 0\\
1 & 2 & 3\\
0 & 3 & 10\\
\end{pmatrix}
\quad $$ and define $Z=(Z_1,Z_2)'$,  where $Z_1=Y_1+Y_2+Y_3$, $Z_2=3Y_1+Y_2-2Y_3$. Find the probability that $Z_1$ is less than $Z_2$ What I have so far: 
We have to find $P(Z_1<Z_2)$ $Z$ has a normal distribution with mean $\begin{pmatrix} 3\\-4\\\end{pmatrix} \quad $ and variance $\begin{pmatrix} 21 & -14\\-14 & 45\\\end{pmatrix}. \quad $ Any comments are appreciated.","['statistics', 'probability', 'linear-algebra', 'normal-distribution']"
2221103,Asymptotically more $1324$-avoiding permutations than $1234$-avoiding permutations,"I'm reading Miklos Bona's ``Combinatorics of Permutations'', and struggling with the exercise that shows that there are (asymptotically, as $n$ grows) more permutations of $\{1,\ldots,n\}$ that avoid the pattern $1324$ than that avoid the pattern $1234$. [ Edit : a permutation $a_1a_2a_3\ldots a_n$ of $\{1,\ldots, n\}$ avoids the pattern $1324$ if there are no four indices $i < j < k <l$ (not necessarily consecutive) such that $a_l$ is the largest element in $\{a_i,a_j,a_k,a_l\}$, $a_j$ is the second largest, $a_k$ is the third largest, and $a_i$ is the smallest; and similarly for avoiding other patterns.] He defines an equivalence relation on permutations of $\{1,\ldots,n\}$ by declaring two permutations equivalent if they have the same set of left-to-right minima, in the same positions, and the same set of right-to-left maxima, in the same positions. Each class can be encoded by a string of length $n$ consisting of the l-to-r minima and the r-to-l maxima in their correct positions, and $\star$'s everywhere; from this it can be read off easily which of the entries are minima and which are maxima . He then shows that each class contains exactly one $1234$-avoiding permutation and at least one $1324$-avoiding permutation, and that the class
$$
n~n-1~n-2~\ldots~9~8~3~\star~1~\star~7~\star~5
$$ ($n, n-1, \ldots, 9, 8, 3, 1$ are the l-to-r minima; $7, 5$ are the r-to-l maxima) has two $1324$-avoiding permutation. This shows that there are more $1324$-avoiding permutations than $1234$-avoiding permutations. He then argues that there are lots of classes that have at least two $1324$-avoiding permutations, namely all those whose encodings end with $3~\star~1~\star~7~\star~5$. I'm fine with everything so far. But then he concludes with the statement ``[these] classes constitute at least a constant fraction of all ... classes''. If this is true, all is fine, but I can't seem to see how to argue this fact. I don't see it being helpful to try to enumerate classes whose encodings end with $3~\star~1~\star~7~\star~5$, since I don't know the total number of classes to compare my count with; and I can't see a way of grouping all classes on $\{1,\ldots, n\}$ into blocks of some fixed size such that each block is naturally associated with one classes whose encoding ends with $3~\star~1~\star~7~\star~5$. Any ideas on how I should proceed?",['combinatorics']
2221123,Show that there exists a smooth map $F: M \to M$ that is homotopic to the identity and has no fixed points.,"Question (Problem 9-5 of Lee's Introduction to Smooth Manifolds ): Suppose $M$ is a smooth, compact Manifold that admits a nowhere vanishing smooth vector field. Show that there exists a smooth map $F: M \to M$ that is homotopic to the identity and has no fixed points. My try: Let $V$ be the non-vanishing smooth vector field. Since $M$ is compact, $V$ is complete. Hence there is a global flow $\theta: \mathbb{R} \times M \to M$ such that for all $t,s \in \mathbb{R}$ and $p \in M ,\theta (t,\theta(s,p))=\theta(t+s,p)$ and $\theta(0,p)=p.$ Since $p\in M$ is a regular point of $V$ , there exists a neighbourhood $U_p$ in which $V$ has coordinate representation $\frac{\partial}{\partial s^1}$ . Choose a smaller neighbourhood $V_p$ such that $\theta(t,x)=x+(t,0,\ldots)$ for all $0 \le t \le t_p.$ Since $\{V_p\}_{p \in M}$ is a open cover for $M$ and $M$ is compact, there exists a smooth subcover say $\{V_{p_1},\ldots,V_{p_n}\}$ . Let $T=\min \{t_{p_1},\ldots,t_{p_n}\}.$ Then $\theta_T: M \to M$ is a smooth map which has no fixed points and $H:M \times I \to M$ given by $H(x,t)=\theta(tT,x)$ is the required homotopy to identity. I have a little issue here. I am uncertain as how can I choose the neighborhoods $V_p$ the way I did. Intuitively it seems to be true though. Thanks for the help!","['manifolds', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2221128,Why don't surjective functions form a group under composition?,Let's consider the functions $f$ from $X$ to $X$ that are surjective. It's easy to see that they have a right neutral element and a right inverse. Why they don't form a group? What am I missing? Is injectivity needed for the associativity of composition of functions?,"['abstract-algebra', 'group-theory', 'functions']"
2221152,Proving that a sequence of functions converge uniformly,"I have a sequence of functions: $$S_n(x) = x\frac{1-x^n}{1-x}, \text{ where } x \in (-1, 1)$$ It is known that: $$\lim_{n \to \infty}S_n(x) = \frac{x}{1-x}$$ thus $S_n(x)$ converges pointwise. I am to prove that is does not converge uniformly. I tried to estimate: $$\left|S_n(x) - \frac{x}{1-x}\right|$$ using an $x \in (-1, 1)$ but it didn't work. I would appreciate any help.","['real-analysis', 'sequences-and-series', 'uniform-convergence']"
2221158,Product Einstein Manifolds,In the book Einstein Manifolds by Besse it states the product of two Riemannian manifolds which are Einstein with the same constant $\lambda$ is an Einstein manifold with the same constant $\lambda$. Can someone provide a proof of this? Also what happens if the two manifolds are Einstein with different constants. Is the resulting product manifold still Einstein?,"['manifolds', 'differential-geometry']"
2221222,Let $G$ be a Lie group. How to prove that $G/H$ is a manifold?,"In my book on lie algebras, it is written the following stuff : Let $G$ be a Lie group, $H$ a Lie subgroup of G. $G/H$ is then a manifold. Is it hard to prove ? It is a little abstract for me : $G/H$ could not be ""smooth"" in my vision (we could have like a discrete set of elements, so we could'nt find open sets to define the charts). But it seems it's not the case. But I don't have any idea to how to prove this. (I'm a huge beginner in group theory and in Lie groups, I just started to learn this)","['differential-geometry', 'group-theory', 'lie-groups']"
2221248,"How to formalize notion of ""maximally dominated/dominating"" probability?","I want to choose a probability measure on the measurable space $(\Omega, \mathcal{F})$ that dominates, or is dominated by, ""as many probability measures as possible."" The question is how to formalize the phrase that I placed in scare quotes. I will give some simple examples to help show what I have in mind. ($P$ dominates $Q$ means $P(A)=0$ implies $Q(A)=0$, and we write $Q \ll P$.) ""Maximally dominating"" probabilities . Suppose $(\Omega, \mathcal{F})$ is countable and assume $\mathcal{F}$ is the powerset of $\Omega$. If $P$ is a probability that assigns the singletons in $\mathcal{F}$ positive measure, then $P$ dominates every probability $Q$ on $(\Omega, \mathcal{F})$. So probabilities that assign positive measure to singletons are ""maximally"" dominating, they dominate ""as many probabilities as possible."" Of course, for general $(\Omega, \mathcal{F})$ this won't work. Instead, I thought we could define a probability $P$ to be maximally dominating if there is no $Q$ such that 
$$\{\mu: \mu \ll Q \} \supset \{\mu: \mu \ll P \}.$$ 
This definition seems to pass some simple sanity checks. For example, point masses $\delta_\omega$ are not maximally dominating on this definition since $\{\mu: \mu \ll \delta_\omega \} = \{ \delta_\omega\}$, but any $Q$ with $Q(\{\omega \})>0$ dominates $\delta_\omega$ and many other probabilities as well. But I am unsure how to proceed from here; I don't have an example of a maximally dominating measure. ""Maximally dominated"" probabilities . In this case, I don't really have any ideas. Even for countable $(\Omega, \mathcal{F})$, we cannot hope to do what we did above: there's no probability that's dominated by every other probability (if we didn't require our measures to be probabilities, though, then the $0$ measure would be maximally dominated.) To sum up, Are there any known formalisms for the notions I'm trying to capture?","['reference-request', 'probability-theory', 'measure-theory']"
2221292,"I've got this Integral to evaluate , a really messy one [duplicate]","This question already has answers here : tough integral involving $\sin(x^2)$ and $\sinh^2 (x)$ (5 answers) Closed 7 years ago . $$ I=\displaystyle \int_{0}^{\infty} \dfrac{\sin (\pi x^{2})}{\sinh^{2} (\pi x)} ~\mathrm{d}x $$ Found this on the cover of a book called ""Integral Kokeboken"" written in some language that i've never seen and btw the ans is 
$$ I=\dfrac{2-\sqrt{2}}{4}$$","['definite-integrals', 'integration', 'trigonometry']"
2221300,Hahn-Banach and seminorms,"Let $V$ be a vector space, $\phi \in V'$, and let $p_1,\dots,p_n$ be seminorms on $V$ s.t. $|\phi (x) | \leq \sum_{k=1}^{n} p_k(x)$ for all $x \in V$. Prove that there are $\phi_1, \dots \phi_n \in V'$ s.t $$
\phi = \sum_{k=1}^{n} \phi_k, \\
|\phi_k (x) | \leq p_k (x) \ \forall x \in V.
$$ I thought about considering the product space $V^n = V \times \dots \times V$, but I'm stuck at trying to figure out a seminorm on $V^n$. If I can figure out a seminorm, I can then consider the subspace $\{(x,\dots,x): x \in V \}$ and the functional $\phi(x,\dots,x) = \psi(x)$ and apply Hahn-Banach theorem.",['functional-analysis']
2221338,Find limit of $x_n=\frac{n^{\frac{n}{2}}}{n!}$,"Find limit of $$x_n=\frac{n^{\frac{n}{2}}}{n!}$$
I know, that it goes to $0$ by WolframAlpha, but it's not clear for me why. Also I know, that $$x_n=\frac{n^n}{n!}=+\infty$$","['limits-without-lhopital', 'limits']"
2221367,Area of a right triangle if $a/b$ is $1.05$ and the difference between the radii of the circumscribed and inscribed circles is $17$?,"What's the area of a right triangle if the quotient of its legs is $1.05$ and the difference between the radii of the inscribed and circumscribed circles is $17$? I've been trying to solve this and I've got:
($R$ - radius of circumscribed circle, $r$ - radius of inscribed circle) $1.$ $ \frac{a}{b}=1.05$ $2.$ $c^2=a^2+b^2$ $3.$ $a + b - 2r = c$ $4.$ $c-2r=34$ $5.$ $ab=(a+b+c)r$ Using the first four equations, I can substitute for one of the legs from $1.$ and for $r$ through $4.$ which leaves me with $b(2.05)-2c=34$ $c=b\sqrt{1.05^2+1}$ However, solving this simply evades me, as I don't find myself getting rid of the square root which I don't know how to calculate. I do know my equations give the right answer so I'm probably missing a simpler way to solve the system of equations. Help much appreciated.","['systems-of-equations', 'geometry']"
2221371,"The equation $x^n+y^n+z^n=u^n+v^n+w^n=p$, where $p$ is prime.","I’m looking for positive integer solutions to $x^n+y^n+z^n=u^n+v^n+w^n=p$, where $p$ is prime. Background. I was looking at “Primes which are the sum of three nonzero 8th powers” https://oeis.org/A283019 and the like, and wondered if there are rules similar to those for a prime being the sum of two squares. My efforts. I’ve found primes of the form $x^n+y^n+z^n$ up to $n=19$. For $n=1$ solutions are trivial, for $n=2$ they are abundant. There are plenty of results for $n=3$ and they’re not uncommon for $n=4$. However, for $\color{blue}{n=5}$ I’ve found just two lonely solutions. $$(n,x,y,z=u,v,w,p)$$ $$(2,3,4,4=1,2,6,41)$$
$$(2,3,5,5=1,3,7,59)$$
$$(2,3,5,7=1,1,9,83)$$ $$(3,1,5,5=2,3,6,251)$$
$$(3,4,6,9=1,2,10,1009)$$
$$(3,1,9,9=4,4,11,1459)$$ $$(4,9,16,16=8,13,18,137633)$$
$$(4,4,18,19=1,6,22,235553)$$
$$(4,8,16,21=6,13,22,264113)$$ $$(\color{blue}5,11,183,209=19,168,216,604015282243)$$
$$(\color{blue}5,481,782,788=321,772,808,622015202536001)$$ My question. Can anyone find more solutions for $n=5$, or $n>5$, or give any insights, please.","['number-theory', 'prime-numbers', 'diophantine-equations']"
2221408,"If matrix is diagonalizable, eigenvalue?","Let $A$ be an $n \times n$ matrix and suppose $A$ is diagonalizable and the only eigenvalue is $\lambda = k$, what can you say about matrix $D$ where $A = P^{-1} D P$, for invertible matrix $P$. So if the only eigenvalue of $A$ is $\lambda = k$, what can I say about $D$? I know that $D$ is a diagonal matrix, but is it necessarily true that $D = \text{diag } (k, k, ... , k)$ ?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2221409,Prove that $R$ is commutative [duplicate],"This question already has answers here : If $x^{2}-x\in Z(R)$ for all $x\in R$, then $R$ is commutative. (2 answers) Closed 5 years ago . Let $R$ be a ring such that
  $$ x^2-x \in C(R) \quad \forall x \in R,$$
  where $C(R)$ is the center of $R$. Prove that $R$ is commutative. I cannot find any route to proceed. How can I start? Please give hints instead of full solution.","['abstract-algebra', 'ring-theory']"
2221423,How is position differentiable?,"Consider this graph of some point's position vector's endpoint - a function of time - on a Cartesian plane: This is a perfectly normal path - after all, in real world there is nothing keeping point from taking a sharp turn like this. However, in mathematical physics, we consider position vector as a differentiable function, where $\dfrac{df(t)}{dt}=(\dfrac{df_x(t)}{dt},\dfrac{df_y(t)}{dt},\dfrac{df_z(t)}{dt})$. In the graph I posted, the component $f_x$ seems to be undifferentiable at point $f_x(t)$, since there its goes through a cusp. Is there something I'm not seeing and there is a derivative of $f_x$ at $t$, or is this point really undifferentiable? And if it is, why do we define position vector as a differentiable function?","['derivatives', 'real-analysis', 'physics', 'calculus']"
2221449,Factorizing a rotation matrix into a product of stretch and shear matrices,"In a video which shows how to rotate a picture in Microsoft Paint by any given angle (usually you can only rotate by 90 degrees in Paint), it is shown how to do a rotation by $\alpha$ doing the following operations: Horziontal skew by $\alpha$ Vertical stretch by $\frac{1}{\cos^2(\alpha)}$ Vertical skew by $-\alpha$ Horizontal and vertical stretch by $\cos(\alpha)$ So in terms of matrices, we have $\begin{pmatrix}\cos(\alpha)&\sin(\alpha)\\-\sin(\alpha)&\cos(\alpha)\end{pmatrix}=\begin{pmatrix}\cos(\alpha)&0\\ 0&\cos(\alpha) \end{pmatrix}\begin{pmatrix}1&0\\ \tan(-\alpha)&1 \end{pmatrix}\begin{pmatrix}1&0\\0& \frac{1}{\cos^2(\alpha)} \end{pmatrix}\begin{pmatrix}1&\tan(\alpha)\\0&1 \end{pmatrix}.$ Are there general factorization results of this kind (e.g. for non-rotation matrices? In which sense is this factorization unique for a rotation matrix?","['trigonometry', 'linear-algebra']"
2221466,Help with showing equality of quadratic matrix equations,"For two symetric matrices $A$ and $B$ of same dimension with compatible column vectors $a$ and $b$ I verified numerically that $$(A^{-1}a + B^{-1}b) ^T (A - A(A+B)^{-1}A) (A^{-1}a + B^{-1}b) - a^TA^{-1}a -b^TB^{-1}b $$ simplifies to $$(a-b)^T(A+B)^{-1}(a-b)$$ I would welcome pointers what is a good approach to derive this. I factored out the first term, but I am stuck after some steps, specifically at $$ 2 b^TB^{-1}a + b^TB^{-1}AB^{-1}b - b^TB^{-1}b - a^T(A+B)^{-1}a  - 2 b^T B^{-1} A (A+B)^{-1}a -b^TB^{-1}A(A+B)^{-1}AB^{-1}b$$ The latter three terms are clearly related through $$(A B^{-1} b  + a) ^T (A+B)^{-1} (A B^{-1} b  + a)$$ But this does not really help.","['matrices', 'linear-algebra']"
2221506,Easier way of finding radius of circle inscribed in a scalene triangle given 2 sides and the included angle,"I have a scalene triangle with two sides given and the included angle.  I am solving for the radius of the inscribed circle.  See the image below. I know that I can use the law of Cosines to find the length of the missing side
$c^2=a^2+b^2-2ab cosC$ Then I could use area of a triangle formula $K=\frac12absin C$ Finally I could find and insert the perimeter and area into the formula below to solve for r. $r=\frac{2A}p$ My equation for r would be: $r=\frac{ab \sin{C}}{a+b+\sqrt{a^2+b^2-2ab \cos{C}}}$ Using the given data this would give me: $r=\frac{119*202*sin(43)}{119+202+\sqrt{119^2+202^2-2*119*202*cos(43)}}=35.5$ Is there a simpler way to do this?","['circles', 'triangles', 'geometry']"
2221510,Prove $\det[D f (x)] \neq 0$,"Let $U, V ⊆ \mathbb R^n$ be open sets and $f : U → V$ a differentiable bijection with a differentiable inverse. Show that $\det[D f (x)] \neq 0$ for any $x ∈ U$. This shows that the converse of the Inverse Function Theorem holds, but how should I prove it? Thank you.","['derivatives', 'inverse-function-theorem', 'real-analysis', 'implicit-differentiation']"
2221560,Understanding Proof of Chain Rule,"Reading through this proof of the chain rule, I'm fine up until the following step: $f[u(x+h)]-f[u(x)] = f[(ux)+h((v(h)+u'(x))]-f[u(x)]$ $= f[u(x)]+h(v(h)+u'(x))(w(k)+f'[u(x)])-f[u(x)]$ $= h(v(h)+u'(x))(w(k)+f'[u(x)])$ How does the proof go from the first line to the second?","['derivatives', 'chain-rule', 'calculus', 'functions', 'proof-explanation']"
2221574,Compact sets of direct limit topology,"We consider a direct limit of a tower $X_1\subset\cdots\subset X_n$ of spaces, where each $X_n$ is a subspace of $X_{n+1}$. The direct limit is $X_\infty:=\bigcup_n X_n$ endowed with the topology $\mathcal{T}_{\infty}$ defined as follows: $U\subset X_\infty$ is open if and only if $\forall n\in \Bbb{N},\quad U\cap X_n$ is open on $\mathcal{T_n}.$ We assume that $\mathcal{T}_n$ is the subspace topology on $X_n$ by $\mathcal{T_{n+1}}.$ If I denote $\mathcal{K}_n$ the family of compact sets of $X_n$ then the union of such sets are included in $K_\infty$ (which is the family of compact sets of $X_{\infty}$ If $K$ is compact of $X_n$ then it's a compact of $X_\infty.$ Do we have equality? In other words  the collection of all compact subsets of $X_{\infty}$ is the union of the corresponding collections for each $X_n.$ EDIT Thanks to Eric Wofsey the answer is no if $X_{\infty}$ is not Hausdorff. What if it's Hausdorff ? (we say $T_0$?)","['general-topology', 'compactness']"
2221578,Product of doubly stochastic matrix,"I have a question: Definitions A matrix $A$ is doubly stochastic if: a) $ 0\leq a_{ij}\leq1. $ b) $ \sum_{j=1}^{n}a_{ij}=1\;\forall i=1,2,\ldots, n. $ c) $ \sum_{i=1}^{n}a_{ij}=1\;\forall j=1,2,\ldots, n. $ Prove that the product of two doubly stochastic matrices is doubly stochastic. Part a) $$0\leq b_{kj}\leq 1,\forall k,j\in\{1,\ldots,n\}$$ $$\implies0\leq a_{ik}\cdot b_{kj}\leq a_{ik},\forall i\in\{1,\ldots,n\}$$ $$0\leq \sum_{k=1}^{n} a_{ik}b_{kj}\leq\sum_{k=1}^{n}a_{ik}$$ $$\implies0\leq c_{ij}\leq1.$$ Part b)
I use this property: $$\sum_{p=1}^{m}(\sum_{k=1}^{n}a_{ik}\cdot b_{kp})=\sum_{k=1}^{n}(\sum_{p=1}^{m}a_{ik}\cdot b_{kp})$$ $$\sum_{k=1}^{n} c_{ik}=\sum_{k=1}^{n}(\sum_{p=1}^{n}a_{ip}b_{pk})\mbox{, definition}$$ $$\implies \sum_{p=1}^{n}(\sum_{k=1}^{n}a_{ip}b_{pk}).$$ $$\implies\sum_{p=1}^{n} a_{ip}(\sum_{k=1}^{n}b_{pk}).$$ But $ \sum_{k=1}^{n}b_{pk} $ is the sum of  elements in one row of matrix $B$ and it is equal to 1 (doubly stochastic). $$ \implies\sum_{p=1}^{n}a_{ip}\cdot1=\sum_{p=1}^{n}a_{ip}$$ And $ \sum_{p=1}^{n}a_{ip} $ eis the sum of  elements in one row of matrix $A$ and it is equal to 1 (doubly stochastic). Please help me for the part c) or complete my proof.
Thank you so much Quote of today: ""Firstly, it is connected with technology. In order to do numerical analysis, you essentially need a machine."" Jacques-Louis Lions","['matrices', 'linear-algebra']"
2221585,magnetic field with a gradient?,"Usually it is said that the Maxwell equation $\vec \nabla \cdot \vec{B}=0$ is solved by introducing the vector potential according to $\vec B=\vec \nabla \times \vec A$. However, I supose that one could write the more general decomposition $\vec B=\vec \nabla \times \vec A+\vec \nabla f$ and require $\nabla^2 f=0$ to enforce $\vec \nabla \cdot \vec{B}=0$. Why is this never done? Why must magnetic fields be purely rotational?","['multivariable-calculus', 'linear-algebra']"
2221600,Counting Binary Strings (No block decompositions),The main question goes : How many binary strings of length $n$ are there that do not contain an odd string of $0$'s as a maximal substring? (So $1001$ is okay but $10001$ is not) A maximal substring is the substring of maximum length consisting of only $0$'s or only $1$'s. I encountered this problem on the second page of a introductory book on combinatorics. I know how to solve this using block decompositions but it would be nice to have a combinatorial proof involving some form of counting argument or maybe a recursive formula. I believe there should be such a solution since the book does not assume any block decompositions before this question.,"['combinations', 'combinatorics', 'bit-strings']"
2221614,Show that $\sum_{k=1}^{\infty} \sigma^2_k <\infty$ implies $|\sum_{k=1}^{\infty} X_k|<\infty $ almost surely.,"Suppose that $X_1, X_2, X_3,\ldots$ are sequence of independent random variables such that $\mu_k= 0$ and $ \sigma^2_k =\operatorname{Var}(X_k)< \infty$ for all $k$ . Then 
show that $\sum_{k=1}^{\infty} \sigma^2_k <\infty$ implies $|\sum_{k=1}^{\infty} X_k|<\infty $ almost surely. I was wondering how could  I use the facts: 1) if a martingale $M$ is bounded in $L^2 $ then $\lim M_n$ exists almost surely.
2) Orthogonality of increments of $M$ to prove the above statement. I would like to see the solution in explained way.","['probability-theory', 'variance', 'martingales', 'sequences-and-series', 'random-variables']"
2221617,C^1 function twice differentiable only at origin?,Is there a $C^1$ function $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f$ is twice differentiable only at origin? Can this phenomena occur in higher dimension? N.B I constructed a $C^1$ function that is twice differentiable nowhere but could not manipulate for one point. Any help is much appreciated.,"['real-analysis', 'functions']"
2221624,Proving existence of a matrix $X$ such that $A = BX$,"Let $A = [\overrightarrow{v_1}... \overrightarrow {v_k}]$
  and $B = [\overrightarrow{u_1}... \overrightarrow {u_k}]$
  be $n\times k $ matrices Prove that if Span{$\overrightarrow{v_1},..., \overrightarrow {v_k}$} $\subseteq$ Span{$\overrightarrow{u_1},..., \overrightarrow {u_k}$} then there exists a matrix $X$ such that $A = BX$ so we have $c_{i1} \overrightarrow{u_1} + ... + c_{ik} \overrightarrow{u_k} = v_i$ for $1\leq i\leq k$ substituting this into A gives us
$$ A = [(c_{11} \overrightarrow{u_1} + \space...\space + c_{1k} \overrightarrow{u_k}) \space...\space (c_{k1} \overrightarrow{u_1} + \space...\space + c_{kk} \overrightarrow{u_k})]$$ we see that we can write this in terms of coordinate vectors 
$$ A = [B[\overrightarrow{v_1}]_B\space...\space B[\overrightarrow{v_k}]_B]$$ that is $$ A = BX$$
where X is a $k \times k$ matrix with entries $[\overrightarrow{v_1}]_B ...[\overrightarrow{v_k}]_B$","['matrices', 'abstract-algebra', 'elementary-set-theory', 'linear-algebra', 'vector-spaces']"
2221662,Discrete math into plain English help $1$.,"Given Statement: $\forall x \in \Bbb N\left(x > 1 \to \exists k \in \Bbb N \exists m \in \Bbb N\left(m \equiv 1\pmod 2 \land x = 2^k \cdot m\right)\right)$ So far I have written it as: For all $x$ in the set Natural numbers where $x$ is larger than $1,$ there exists $k$ in Natural numbers existing $m$ in Natural numbers. That is how far I could go and not sure if it is correct. I need help for the $\left(m \equiv 1\pmod 2 \land x = 2^k \cdot m\right)$ part. Any edits of my existing statement and any help in converting to plain English is welcomed. Thank you in advance.",['discrete-mathematics']
2221672,Spectral Measures - Spectral Theorem,"I'm trying to understand the following lemma from Reed and Simon's text: Lemma 1: Let $A$ be a bounded self-adjoint operator with cyclic vector $\psi$. Then, there is a unitary operator $U : \mathscr{H} \to L^2(\sigma(A), d\mu_{\psi})$ with $$(UAU^{-1}f)(\lambda) = \lambda f(\lambda).$$ Proof: Define $U$ by $U \phi(f) \psi \equiv f$, where $f$ is continuous. To show that $U$ is well defined, we compute $$\| \phi(f)\psi \|^2 = \langle \psi, \phi^{\ast}(f)\phi(f) \psi \rangle = \langle \psi, \phi(f\overline{f})\psi \rangle = \int \left| f(\lambda) \right|^2 d\mu_{\psi}.$$ I'm not understanding the last two equalities. Thanks","['functional-analysis', 'spectral-theory', 'operator-theory', 'analysis']"
2221719,Working with functions,Suppose $f(3-x)=2x^2-5x+4$ and $f(x)=ax^2+bx+c$. What is $a+b+c$? I don't know how to approach this. I thought of maybe doing $a(3-x)^2+b(3-x)+c=2x^2-5x+4$ and solving for $a+b+c$ but it got messy.,['functions']
2221746,The motivating properites of beta distribution and how its density function is developed?,"The density of beta distribution is given by the following $$f(x\mid \alpha ,\beta ) = \frac 1 {\operatorname{B}(\alpha,\beta)} x^{\alpha  - 1} (1 - x)^{\beta  - 1}$$ where $$ \operatorname{B}(\alpha,\beta) = \int_0^1 x^{\alpha  - 1} (1 - x)^{\beta  - 1} \,dx $$ is the Beta function as the normalizing constant. I understand one use of Beta distribution is to draw random probabilities from it. I am interested in what gives rise to this distribution? In particular , why it is ""$x^{\alpha  - 1} (1 - x)^{\beta  - 1}$"", not something else? What kinds of desired properties uniquely determine this density? And how the density formula is derived? I have googled but could not find a good explanation. Many text books just throw this in front of you like it comes from nowhere.",['probability']
2221831,Find the Integral curves of: ${dx\over(-1)}= {dy\over(3y+4z)}= {dz\over(2y+5z)}$,"While going through the concept of simultaneous differential equation, I came across following problem: Find the Integral curves of:
$${dx\over(-1)}= {dy\over(3y+4z)}= {dz\over(2y+5z)}$$ The solution says: Each of these fractions of the given system of equations is equal to : $${(dx-dy)\over(y-z)}\; \text{and}\; {(dy+2dz)\over7(y+2z)}$$ How each of these fractions can be equal to these fractions?Is there the use of componendo-dividendo concept?if yes, how we deduced that?","['ordinary-differential-equations', 'calculus']"
2221838,Reference for computing sheaf cohomology of constructible sheaves by \v{C}ech cohomology?,"Let $X$ be a topological space. A stratification of $X$ is a decomposition into a collection of subsets $X = \amalg_i \ X_i$ (called strata) such that $X_i$'s are open in its closure, and $\partial X_i = \overline{X_i} \setminus X_i$ is again a disjiont union of strata. A sheaf $\mathcal{F}$ on $X$ is constructible with respect to a stratification $\amalg \ X_i$ if $\mathcal{F}\big|_{X_i}$ are locally constant sheaves for all $i$. I heard if the stratification satisfies some conditions, then we can calculate $H^i(X;\mathcal{F})$ by using the \v{C}ech complex of a certain open cover associated to the stratification. Does anyone know if there's reference about this? Or maybe the details are not hard? By the way, I know there's probably a page in Stack Project about this. But I concern more about manifold so I'm looking for one with more topological setting. Thanks.","['sheaf-theory', 'complex-geometry', 'reference-request', 'algebraic-topology', 'differential-geometry']"
2221846,"Finding the norm of the shift operator on $l^\infty$, $(x_1,x_2, \dots)\mapsto (x_2,x_3,\dots)$","Let $T:l^\infty\rightarrow l^\infty$ be defined by $(x_1,x_2, \dots)\mapsto (x_2,x_3,\dots)$. I have seen a claim without justification that $\|T\|=1$, but I am not convinced. I know that $\|T\| = \sup_{{\|x\|=1}}\|Tx\|$  . If $\|x\|=1$ then surely $\|Tx\|\le 1$. So $$\|T\| = \sup\limits_{\|x\|=1}\|Tx\|\le 1.$$ I don't see how it can be claimed that $\|T\| = 1$ Is it true or I am missing something?","['normed-spaces', 'supremum-and-infimum', 'functional-analysis', 'lp-spaces', 'linear-transformations']"
2221866,Given the PDF of $X$ find the PDF of $Y$ using CDF,"Suppose $X$ has PDF
  $$f_X(x) = \frac{x}{18}, \quad 0 \le x \le 6.$$
  Determine the probability distribution of the random variable $Y = 2X+10$ using the distribution function (CDF) method. Would you kindly tell me if my approach is correct? Approach: $$F_Y(y) = P(Y \leq y) = P(2X+10 \leq y) = P\left(X \leq \frac{y-10} {2}\right)$$ $$ \int^\frac{y-10} {2}_0 \frac{x}{18}\, dx= \frac{(y-10)^2} {144}.$$ I just started learning CDF's. Am I correct on this one?","['statistics', 'probability', 'random-variables', 'probability-distributions']"
2221872,If $(f(z))^2$ and $(f(z))^3$ are entire functions ; then is $f$ entire? [duplicate],"This question already has answers here : Proving that if $f: \mathbb{C} \to \mathbb{C} $ is a continuous function with $f^2, f^3$ analytic, then $f$ is also analytic (2 answers) Closed 7 years ago . Let $f:\mathbb C \to \mathbb C$ be a function such that $(f(z))^2$ and $(f(z))^3$ are entire   then is $f$ entire ? I can conclude $f$ is entire if given $f$ is continuous ; but without continuity of $f$ , is it true ?","['continuity', 'complex-analysis', 'holomorphic-functions', 'entire-functions']"
2221890,"How did people figure out that parabolas, hyperbolas, circles, and ellipses were conic sections?","Maybe it is not surprising if one thinks that parabolas, hyperbolas, circles, and ellipses are relatives because they all have kind of the same form of equations, i.e., $$
Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0,
$$ where different values of $A, B, C, D, E,$ and $F$, as well as their relations, give different kinds of curves. But how did people figure out they were all conic sections (how could one see a cone from that second-order equation)? Or was it the case that someone were playing with cones and somehow wondered how a cone could be cut in different ways and figured out that the edges from those cuts were all related through the above equation?","['conic-sections', 'math-history', 'geometry']"
2221897,Show that $\lim_{n \to \infty} \sum_{k=3}^n \frac{2k}{k^2+n^2+1} = \ln(2)$,"Show that $$\lim_{n \to \infty} \sum_{k=3}^n \frac{2k}{k^2+n^2+1} = \ln(2)$$ How many ways are there to prove it ? Is there a standard way ? I was thinking about making it a Riemann sum.
Or telescoping. What is the easiest way ?
What is the shortest way ?","['limits', 'logarithms', 'calculus', 'riemann-sum', 'summation']"
2221904,"Single random variable, multiple probability distributions?","If we have two separate probability distributions P(x) and Q(x) over the same random variable x, we can measure how diﬀerent these two distributions are using the Kullback-Leibler (KL) divergence... The above statement is from Deep Learning by Ian Goodfellow and Yoshua Bengio and Aaron Courville and I have the following question: As far as I have understood, a random variable is defined considering a specific probability distribution in mind, it takes the value of a random outcome in that distribution. Perhaps I'm wrong in my understanding. My question is: How can you have two separate probability distributions on the same random variable? Kindly help me resolve this confusion. Thanks!","['probability-theory', 'probability', 'random-variables', 'probability-distributions']"
2221942,Why aren't vectors curved?,"I don't understand why vectors can't be curved. For example when specifying the angle vector for an object in cylindrical/spherical coordinates, I think a curved vector would make more sense.","['intuition', 'linear-algebra', 'vectors', 'vector-spaces']"
2221977,"Prove that every converging limit $\lim_{n \to \infty} \sum_{k=1}^{a(n)} f(k,n)$ is essentially a riemann sum.","Let $a(n)$ be a strictly increasing function of $n$. Proof that every converging limit $$\lim_{n \to \infty} \sum_{k=1}^{a(n)} f(k,n)$$ is essentially a Riemann sum.","['limits', 'calculus', 'proof-writing', 'riemann-sum', 'summation']"
2221988,"How exactly do we explain ""distinct objects"" in the definition of set?","Wikipedia gives the following definition for sets: A set is a well-defined collection of distinct objects. But what does it mean by ""distinct objects"" here? For example, we can say $\{A,B\}=\{\{1,2\},\{1,3\}\}$ is a set. So essentially by ""distinct"" we wanted to say $A\neq B$. However, I think this is not enough. For example, can we say $\{\{a\},a\}$ is a set? I guess not. Just consider $\{$America, New York$\}$. It would be inconvenient to discuss problems when we put objects in different level of hierarchy together. So we should have $A\notin B$ and $B\notin A$ to say $A,B$ are distinct. But how about $\{\{\{a\},\emptyset\},a\}$?",['elementary-set-theory']
2221989,Where does boundedness feature in this argument?,"An assignment question asks: Let $\nu$ be a finite signed measure on $(X,\mathcal{A})$ and let $f:X\rightarrow \mathbb{R}$ be bounded and $\mathcal{A}$-measurable.  Show that $$\left|\int_X f d\nu\right| \leq \int_X|f|d|\nu|$$ My solution is simply: $$\left|\int_X f d\nu\right| = \left|\int_X f d(\nu^+-\nu^-)\right| = \left|\int_X f d\nu^+-\int_X f d\nu^-\right| \leq \left|\int_X f d\nu^+\right|+\left|\int_X f d\nu^-\right|$$ $$\leq \int_X |f| d\nu^++\int_X |f| d\nu^-= \int_X |f| d(\nu^++\nu^-) = \int_X|f| d|\nu|$$ But this seems too easy. We didn't use boundedness at all. Question. Where does boundedness feature in this argument?",['measure-theory']
2221994,Specific example of a certain claim in a paper,"In a paper of Heath-Brown, it is stated on page 24 that for any number field $K$, there exist ideals $\mathfrak{a_1, \dots, a_t}$ s.t. all fractional ideals can be written as the product of powers of the $\mathfrak{a_j}$ and a principal ideal uniquely (with some restrictions on the exponents). What would an example of $\mathfrak{a_1, \dots, a_t}$ be in the case $K = \mathbb{Q}(\sqrt{-5})$?","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
2222011,Find value of $k$ such that domain of $f(x)$ is $(-\infty \: 2] \cup [6 \:\infty)$,Find value of $k$ such that domain of $$f(x)=\log_{0.5}\left(\log_{4}\left(\log_3[(x-k)^2]\right)\right)$$ is $(-\infty \: 2] \cup [6 \:\infty)$ where $[.]$ is Greatest integer function. For outside $\log$ to take valid arguments we have $$ 0 \lt \log_{4}\left(\log_3[(x-k)^2]\right)\lt 1$$ which implies $$1 \lt \log_3[(x-k)^2] \lt 4$$ $\implies$ $$3 \lt [(x-k)^2] \lt 81$$ $\implies$ $$(x-k)^2 \ge 4$$ and $$(x-k)^2 \le 81$$ From here how can we find $k$,"['algebra-precalculus', 'logarithms', 'functions']"
2222023,$GL_n(F)$ acts on the flag variety,"I have the following 2-part question as a homework assignment... Let $F$ be a field and $n\in \mathbb{Z}_{\geq 1}$. A full flag in the vector space $F^n$ is a chain of subspaces 
  \begin{align} \{0\}\subset V_1\subset \cdots\subset V_{n-1}\subset V_n=F^n\end{align}
  such that $\dim V_i=i$ for all $i\in \{1,2,...,n\}$. The flag variety of $GL_n(F)$ is the set $\mathcal{B}$ of all full flags in $F^n$. (a) Show that $GL_n(F)$ acts on the flag variety $\mathcal{B}$. (b) Let $e_i$ be the coordinate basis vectors of $F^n$. Let $e_{*}$ be the full flag given by $V_i=\mathrm{span}\{e_1,...,e_i\}$. Show that $\mathrm{Stab}_{GL_n(F)}(e_*)=B$, where $B$ is the subgroup of upper-triangular matrices. I feel like once i understand how to tackle part (a), I will understand part (b), but at the moment I really don't understand what this flag variety really is. $\quad$-What does an element of the flag variety look like? $\quad$-How would $GL_n(F)$ act on such an element? These are the things I need some hints on. Thank you!","['abstract-algebra', 'schubert-calculus', 'linear-algebra']"
2222047,"Find all functions $f:\mathbb R \rightarrow \mathbb R$, such that: $(x^2 − y^2)\cdot f(xy) = x\cdot f(x^2y) − y\cdot f(xy^2)$","Find all functions $f:\mathbb R \rightarrow \mathbb R$, such that:
$$(x^2 − y^2)\cdot f(xy) = x\cdot f(x^2y) − y\cdot f(xy^2)$$
for all $x,y \in \mathbb R$ My work so far: 1) $f(0)=0$ 2) $y=1; y=\frac1x; y=-\frac1x; y=kx$","['functions', 'functional-equations']"
2222051,Spectral measure of 1-dimensional Ornstein-Uhlenbeck process,"I want to compute the spectral measure of the 1-dimensional Ornstein-Uhlenbeck process with covariance function 
\begin{align}
\rho(t) = e^{-|\beta|t}, \qquad t \in \mathbb{R}.
\end{align}
Since $\rho$ is a proper covariance function, Bochner's theorem says that $\rho$ is the covariance function of some stationary Gaussian random field if and only if
\begin{align}
\rho(t) = \int_\mathbb{R} e^{i\omega t}\ d\mu(\omega),
\end{align}
for some finite non-negative symmetric Borel measure on $\mathbb{R}$. Now, I know as well that if $\mu \ll \lambda$, when $\mu$ is absolutely continuous w.r.t. the Lebesgue-measure, $\rho$ could be written as
\begin{align}
\rho(t) = \int_\mathbb{R} e^{i\omega t}f(\omega)\ d \omega,
\end{align}
where $f$ is the spectral density, i.e. the Fourier transform of the covariance function $\rho$. Therefore,
\begin{align}
f(\omega)= \frac{1}{2\pi} \int_\mathbb{R} e^{-i\omega t} \rho(t)\ dt.
\end{align}
However, I do not know see how to compute the spectral measure explicitly. Any help is appreciated!","['probability-theory', 'statistics', 'measure-theory', 'spectral-theory', 'fourier-transform']"
2222122,Is there any quick way to derive the maximum likelihood estimator in the following example?,"Let's say we are given a sample: $Z_1,Z_2,\cdots,Z_n$. We know their joint distribution is
$$
\begin{bmatrix}
Z_1\\
Z_2\\
\vdots\\
Z_n
\end{bmatrix}
\sim
N\left(0,
\begin{bmatrix}
\sigma^2+2\omega^2 & -\omega^2 & 0 & 0 &\cdots & 0\\
-\omega^2 & \sigma^2+2\omega^2 & -\omega^2 & 0 &\cdots & 0\\
0 & -\omega^2 & \sigma^2+2\omega^2 & -\omega^2 & \cdots & 0\\
\cdots & \cdots & \cdots & \cdots & \cdots & \cdots\\
0 & \cdots &\cdots &\cdots & -\omega^2 & \sigma^2 + 2\omega^2 \\
\end{bmatrix}
\right)
$$
and want to derive the maximum likelihood estimator for both $\sigma^2$ and $\omega^2$. If we put $\Sigma$ as the covariance matrix of the sample, we may get a closed-form solution for $|\Sigma|$ and $\Sigma^{-1}$. Since it's a tridiagonal matrix, what I usually do is to use the formulas for determinants and inverse of block matrix inductively. Then we should be able to get the first order conditions and then solve for the MLE. However, I doubt if such method is too laboursome. At the very first glance, I guess that the MLE should be the same as moment estimator. That is,
$$
\begin{bmatrix}
\hat{\sigma}^2_{ML}\\
\hat{\omega}^2_{ML}\\
\end{bmatrix}
=
\begin{bmatrix}
\frac{1}{n} \sum_{j=1}^n Z_j^2 + \frac{2}{n-1} \sum_{j=2}^n Z_j Z_{j-1} \\
-\frac{2}{n-1} \sum_{j=2}^n Z_j Z_{j-1}
\end{bmatrix}
$$
Now my question is: if my guess is correct, is there any quick way to derive the maximum likelihood estimator than to do the tedious derivation? Or maybe I'm wrong, that is, $|\Sigma|$ and $\Sigma^{-1}$ can be easily solved? Any help will be greatly appreciated!","['statistics', 'probability', 'linear-algebra']"
2222171,Compute curvature tensor from constant sectional curvature,"Given sectional curvature as a constant, i.e. $\dfrac{R_m(X,Y,Y,X)}{|X|^2|Y|^2-<X,Y>^2} = C$, I want to compute the curvature tensors $R(X,Y)Z$ and $R_m(X,Y,Z,W)$. I believe I need to use the identity
$$-6R_m(X,Y,Z,W) = \partial_t\partial_s\{R_m(X+sZ, Y+tW, Y+tW, X+sZ) - R_m(X+sW, Y+tZ, Y+tZ, X+sW)\}$$ I can almost see what to do for $R_m(X,Y,Z,W)$ and how this identity and the defintion of sectional curvature are related but can't really see how to finish it off. I don't really even know where to begin with $R(X,Y)Z$.",['differential-geometry']
2222196,How are the Bell numbers related to this exponential series?,"I recently started studying about the exponential series, and came across this infinite series $
{S}_{k}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{k}}{n\mathrm{!}}}
$ A few results that were given in my textbook were: $$
\begin{array}{l}
{{S}_{0}\mathrm{{=}}{e}}\\
{{S}_{1}\mathrm{{=}}{e}}\\
{{S}_{2}\mathrm{{=}}{2}{e}}\\
{{S}_{3}\mathrm{{=}}{5}{e}}\\
{{S}_{4}\mathrm{{=}}{\mathrm{15}}{e}}
\end{array}
$$ The coefficients of $e$ piqued my interest, and so I used wolfram alpha to calculate $
{S}_{5}
$, which came out to be equal to 52$e$. I looked up the sequence of coefficients of e on OEIS and it showed me a sequence of numbers known as the Bell numbers. I learned on Wikipedia that these numbers are used in Combinatorics, and give the maximum possible partitions of a set with given number of elements. Anyhow, I attempted to solve the above series for $k$=2 and 3 to see if I could find a pattern linking bell numbers to the series. Here's what I did:
$$
\begin{array}{l}
{\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{2}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)}}\mathrm{{+}}{n}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\mathrm{(}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{2}{\mathrm{)!}}}}\mathrm{{+}}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)!}}}{\mathrm{)}}\mathrm{{=}}{e}\mathrm{{+}}{e}\mathrm{{=}}{2}{e}}\\
{\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}^{3}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\frac{{n}{\mathrm{(}}{n}\mathrm{{-}}{1}{\mathrm{)}}{\mathrm{(}}{n}\mathrm{{-}}{2}{\mathrm{)}}\mathrm{{+}}{3}{n}^{2}\mathrm{{-}}{2}{n}}{n\mathrm{!}}}\mathrm{{=}}\mathop{\sum}\limits_{{n}\mathrm{{=}}{0}}\limits^{\mathrm{\infty}}{\mathrm{(}\frac{1}{{\mathrm{(}}{n}\mathrm{{-}}{3}{\mathrm{)!}}}}\mathrm{{+}}{3}\frac{{n}^{2}}{n\mathrm{!}}\mathrm{{-}}{2}\frac{n}{n\mathrm{!}}{\mathrm{)}}\mathrm{{=}}{e}\mathrm{{+}}{3}{\mathrm{(}}{2}{e}{\mathrm{)}}\mathrm{{-}}{2}{\mathrm{(}}{e}{\mathrm{)}}\mathrm{{=}}{5}{e}}
\end{array}
$$ This method could be extended for any $k$, I believe, but will become tedious to calculate for larger $k$. Needless to say, this didn't clear up any confusion for me. So could anyone please explain to me what's going on here? Any help regarding this will be much appreciated. Thanks","['stirling-numbers', 'bell-numbers', 'combinatorics', 'summation', 'sequences-and-series']"
2222202,Finding sum $\frac{1}{2} x^2 + \frac{1}{2} \frac{1}{3} x^3 + \frac{1}{4} \frac{1}{3} x^4 + ... $,"I need to find following: for $0 < x < 1$ $$\frac{1}{2} x^2 + \frac{1}{2} \frac{1}{3} x^3 + \frac{1}{4} \frac{1}{3} x^4  + ... $$ My attempt: I can see that the sum is composed of two infinite sums, one is $\sum_{n=1}^{\infty} \frac{1}{n(n+1)} = \sum_{n=1}^{\infty} \left( \frac{1}{n} -
 \frac{1}{n+1} \right)$ (Telescoping ) and another is, $\sum_{n=2}^{\infty} x^n$ (it's a G.P.). How can I use these for solving the sum in question? Any hints will be appreciated...","['real-analysis', 'sequences-and-series', 'limits']"
2222276,Find all solutions of $(xy^2+x)dx+(y-x^2y)dy=0$,"Find all solutions of $$(xy^2+x)dx+(y-x^2y)dy=0$$ What I know is that:
Assuming $M=xy^2+x, N=y-x^2y$ then if $xN+yM\neq0$ then solution of above equation is unique for every point. In our case it is true when $x\neq0$ or $y\neq0$. However I do not know how to continue this one. Well, what I've written above is not true because $M,N$ are not homogeneous.",['ordinary-differential-equations']
2222284,Differentiating function times indicator function,"I have
$$C=\int\limits_{\lambda=0}^{\lambda=2\pi}\int\limits_{\mu=0}^{\mu=1}hq\chi_{q\geq Q}\mathrm{d}\lambda \mathrm{d}\mu$$
where $Q$ is some constant, and $h$ and $q$ are functions of $\lambda$ and $\mu$. I would like to evaluate $\partial_q C$. Am I correct in saying that it is
$$\int\limits_{\lambda=0}^{\lambda=2\pi}\int\limits_{\mu=0}^{\mu=1}h\chi_{q\geq Q}\mathrm{d}\lambda \mathrm{d}\mu - \int\limits_{\lambda=0}^{\lambda=2\pi}\int\limits_{\mu=0}^{\mu=1}hq\delta_{q- Q}\mathrm{d}\lambda \mathrm{d}\mu,$$
where $\delta$ is Dirac's delta?","['derivatives', 'dirac-delta', 'distribution-theory']"
2222314,Description of the order-5 square tiling of the hyperbolic plane as a graph,"What is a description of the graph representing the faces of the Order-5 square tiling . Alternatively, this can be seen as the graph of vertices of the its dual, the Order 4 pentagon tiling . Preferably, it should be a description useful for use with a computer (all that is needed is a way to find the neighbors of any node). The reason why is got interested in using hyperbolic geometry in games, so as a short cut to all the calculus needed I decided I'd make a bunch of rooms corresponding to a tessellation of the hyperbolic plane (and approximate each room as Euclidean). Also, these description should be discrete (i.e. not rely on real numbers (which would need to be approximated with floating numbers on a computer))?","['graph-theory', 'tessellations', 'algorithms', 'hyperbolic-geometry', 'discrete-mathematics']"
2222319,conformal maps between annulus,"The modulus of an annulus $\{ a < \vert z - z_0\vert < b\}$ with inner radius $a$ and outer radius $b$ is defined to be $$\frac1{2\pi} \log\left(\frac ba\right)$$ (a) Show that any conformal map from one annulus centred at the origin to another such
  annulus extends to a conformal self-map of the punctured plane. (b) Show that there is a conformal map of one annulus onto another if and only if the annuli have the same moduli. (c) Show that any automorphism of the annulus $ \{a < \vert z \vert < b\}$ is either a rotation $z \to e^{i\theta }z$ or a rotation followed by the inversion $z \to ab/z$ I'm totally stuck on this question","['complex-analysis', 'real-analysis', 'analysis']"
2222366,For which logarithm bases is this sum finite?,"Lets have a recursive sequence $a_0 = 1$, $a_{n+1}=\log_{b} (1+a_n)$ and corresponding sum $\sum_{n=0}^\infty  (a_n)$. For which logarithm bases $b>2$ ( possibly for $b>e$) is the sum finite, if for any? I did some calculations comparing this sequence to a harmonic sequence for b=e, and my result was, that for natural logarithm the sum is infinite. I used a trick expressing the harmonic sequence recursively and compared which transformation lowers the number more rapidly. For natural logarithm, harmonic sequence wins, so individual numbers in this sequence should be somewhat larger and therefore the sum should be bigger than sum of harmonic sequence (so they are both infinite). However, for larger bases, harmonic sequence loses, and therefore I can't tell, whether it is infinite or not and no other tricks are on my mind. Anybody can help?","['logarithms', 'sequences-and-series']"
2222371,convergence of $\sum\limits_{n=1}^\infty \frac{(-1)^{\lfloor \sqrt{n}\rfloor}}{\sqrt{n}}$,Does anybody know how to show analytically the convergence (divergence ?) of $\enspace\displaystyle \sum\limits_{n=1}^\infty \frac{(-1)^{\lfloor \sqrt{n}\rfloor}}{\sqrt{n}}\enspace$ or some literature for it ? (Thanks!) Note : Unfortunately I am still missing a useful approach. EDIT: I want to thank all here for the nice help. Result: The series is divergent (but limited) as it is written. It's possible to change to $\enspace\displaystyle\sum\limits_{n=1}^\infty (-1)^n (-2+\sum\limits_{k=n^2}^{(n+1)^2-1}\frac{1}{\sqrt{k}})\enspace$ to avoid the oscillation and to get convergence.,"['real-analysis', 'sequences-and-series']"
2222394,"Sample space in probability: Subsets of the sample space in ""different dimension""?","Recently in my class I have encountered the question as to whether the following statement is considered correct: Define $\Omega = \{ 0,1 \}^\mathbb{N} $,
are subsets of  $\{0,1\}^n$ for $ n = 1,2,3,...$ also subsets of $\Omega$? It seems strange if the answer is yes because if I consider $\{0,1\}^2$ = $\{(0,0), (0,1), (1,0),(1,1)\}$, and $\{0,1\}^1$= $\{(0),(1)\}$ then intuitively it feels very strange to compare $\{(0)\}$ with $\{(0,1)\}$ or $\{(1,0)\}$ because they seem to have different 'dimensions', if the use of such term is even appropriate here. However the question I have been given seems to suggest that the above is correct. Could somebody enlighten me on this question? Thanks! Furthermore, if the above holds true, would elements in the sigma algebra of, say $\{(0,1)^1\}$ be elements in the sigma algebra of $\{(0,1)^2\}$ as well? Thanks! Edit: Subject to the response that I have just received to the above question to be 'no'. Would it appear that my assignment question is making a contradiction? Is it perhaps defining this fact simply for purpose of this question? Source of wonder.image","['probability', 'measure-theory', 'elementary-set-theory']"
2222402,"Prob. 25(b), Chap. 4 in Baby Rudin: The set $C_1 + C_2$ need not be closed in $\mathbb{R}$ even for closed sets $C_1$ and $C_2$","Here is Prob. 25, Chap. 4 in Principles of Mathematical Analysis by Walter Rudin, 3rd edition: If $A \subset \mathbb{R}^k$ and $B \subset \mathbb{R}^k$, define $A + B$ to be the set of all sums $x+y$ with $x \in A$, $y \in B$. (a) If $K$ is compact and $C$ is closed in $\mathbb{R}^k$, prove that $K+C$ is closed. [This I think I've managed to prove.] Hint: . . . (b) Let $\alpha$ be an irrational real number. Let $C_1$ be the set of all integers, let $C_2$ be the set of all $n \alpha$ with $n \in C_1$. Show that $C_1$ and $C_2$ are closed subsets of $\mathbb{R}^1$ whose sum $C_1 + C_2$ is not closed, by by showing that $C_1 + C_2$ is a countable dense subset of $\mathbb{R}^1$. My effort: Let $p$ be a real number that is not an integer, and let $\delta$ be any real number such that $$0 < \delta < \min \left\{ \ p - \lfloor p \rfloor, \ \lceil p \rceil - p \ \right\}. $$ 
  Then the $\delta$-neighborhood of $p$ in $\mathbb{R}^1$ does not intersect the set of integers at all, showing that every point $p$ of $\mathbb{R}^1 - C_1$ is an interior point and hence that $C_1$ is closed in $\mathbb{R}^1$. Am I right? For any two distinct points $x$ and $y$ of $C_2$, we note that 
  $$\vert x-y \vert \geq \vert \alpha \vert > 0.$$ 
  So if $p$ is any real number that is not in $C_2$ and if $\delta$ is any real number such that 
  $$0 < \delta < \min \left\{ \ \left\vert p - \alpha \lfloor \frac{p}{\alpha} \rfloor \right\vert, \ \left\vert \alpha \lceil \frac{p}{\alpha} \rceil - p \right\vert \ \right\},$$ 
  then the $\delta$-neighborhood of $p$ in $\mathbb{$}^1$ --- which equals the segment $(p-\delta, p+\delta) --- does not intersect the set $C_2$ at all, for is $x \in \mathbb{R}$^1$ and $$ p-\delta < x < p+\delta, $$
  then we must have 
  $$ \alpha \lfloor \frac{p}{\alpha} \rfloor < x < \alpha \lceil \frac{p}{\alpha} \rceil,$$ 
  and $\lfloor \frac{p}{\alpha} \rfloor$ and $\lceil \frac{p}{\alpha} \rceil$ are two successive integers, which implies that $x$ lies strictly in between two successive elements of $C_2$. Thus every point $p$ of $\mathbb{R}^1- C_2$ is an interior point, from which it follows that $C_2$ is closed. Am I right? Moreover, we also note that if $n$ is non-zero, then $n \alpah$ is irrational, by Prob. 1, Chap. 1 in Baby Rudin, 3rd edition. So the sets $C_1$ and $C_2$ intersect in $0$ only. Am I right? Now the set $C_1 + C_2$ is given by 
  $$C_1 + C_2 = \left\{ \ m + n\alpha \ \colon \ m \mbox{ and } n \mbox{ are integers } \ \right\}.$$ Am I right? Now the map $m + n \alpha \ \mapsto \ (m, n)$ is an injective mapping of $C_1 + C_2$ into the Cartesian product $C_1 \times C_1$, and this Cartesian product is of course countable. So $C_1 + C_2$ is countable. Am I right? Now how to show that $C_1 + C_2$ is dense in $\mathbb{R}^1$? Once we have shown this then we know that $C_1 + C_2$ cannot be closed, because if $F$ is a closed set in a metric space $X$ and if $F$ is dense in $X$, then we have 
  $$X = \overline{F} = F,$$
  but $C_1 + C_2$, being a countable subset of $\mathbb{R}^1$, is of course a proper subset of $\mathbb{R}^1$, since $\mathbb{R}^1$ is uncountable. Am I right? So, if what I've established so far is correct, then my only question is how to (rigorously) show that $C_1 + C_2$ is dense in $\mathbb{R}^1$?","['real-analysis', 'metric-spaces', 'calculus', 'analysis']"
2222423,Lagrange: Show that there are two points where $f'$ equals zero,"Let $f: \mathbb R \to \Bbb R$ a differentiable function. Let $T>0 \in R$ such that $f(x+T)=f(x) \forall x \in \Bbb R$ Show that the interval $[0,T)$ has two points where the function $f'$ get equals to $0$(means that $f'(x) = 0$ What I've done : If I substitute $0$ I get $f(T) = f(0)$ and by Rolle Theorem - If a real-valued function f is continuous on a proper closed interval $[a, b]$, differentiable on the open interval $(a, b)$, and $f(a) = f(b)$, then there exists at least one $c$ in the open interval $(a, b)$ such that
$f'(c)=0$. Now I'm trying to find the second point I used Lagrange Theorem(Mean value theorem - https://en.wikipedia.org/wiki/Mean_value_theorem ) I get $f'(c) =$ $f(T) - f(0) \over T-0$ = $f(T) - f(T) \over T$ = $0$ but how can I confirm that it's a different point. Can someone help me please? Thanks in advance",['calculus']
2222429,Integrate: $\int (x^2+a^2)^{-3/2} \cdot dx$,Integrate: $\int (x^2+a^2)^{-3/2} \cdot dx$ My Approach: $\int (x^2+a^2)^{-3/2} \cdot dx$ $\int (x^2+a^2)^{-3/2} \cdot d(a^2+x^2)\cdot \frac{dx}{d(x^2+a^2)}$ But this doesn't give the right answer. I showed this to my friend and he said $d(x^2+a^2)$ is not possible which makes sense since you can't take a small element of the  form $(x^2+a^2)$. How can I then solve this integration without using trigonometry ?,"['integration', 'calculus']"
2222441,Minimum number of subsets of combinations so all combinations in a subset differ by one,"Consider all ${n \choose k}$ subsets of size $k$ from a larger set of size $n$.  I would like to split the set of subsets into parts so that in each part, the intersection of all the subsets is at least of size $k-1$. What is the minimum number of parts that you are guaranteed to be able
  to split the set of subsets into? The maximum number of subsets in a part is $n$ so this at least gives us a lower bound of $\frac{{n \choose k}}{n}$ for the number of parts. But this is not tight. When $k=1$ the minimum number of parts is $1$. When $k=2$ the minimum number of parts is $n-1$. I don't know how to solve the problem for $k=3$. Edit Smylic points out you can slightly raise the lower bound as each  part has at most $n  - (k-1)$ subsets. So this makes a new lower bound of $\frac{{n \choose k}}{n  - (k-1)}$.",['combinatorics']
