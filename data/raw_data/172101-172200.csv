question_id,title,body,tags
3056327,For which $a$ does the equation $a^x=x+2$ have two solutions?,"I need to find values of $a$ for the following equation to have two real solutions. $$a^x=x+2$$ $(1,\infty)$ $(0,1)$ $1/e,e$ $(1/(e^e), e^e)$ $(e^{1/e}, \infty)$ This is how I solved this exercise, but I don't understand some things. I would like to know if there's another way to solve this kind of exercise. I would be happy if I would get some ideas. Also, from my solution, I don't understand why from that table results just one solution and from the graphic results two solutions. Usually, to see the number of solutions I use this kind of table. For $a>1$ , $f$ decreases from infinity to -1, then increase from -1 to infinity. I'm really confused. Need some suggestions here. Thank you!","['algebra-precalculus', 'functions', 'exponential-function', 'transcendental-equations']"
3056394,Degrees of freedom of Riemann curvature tensor,"I know the argument that uses the symmetries $R_{a b c d} = -R_{b a c d} = R_{c d a b}$ $R_{a b c d} + R_{b c a d} + R_{c a b d} = 0$ of the Riemann curvature tensor $R$ of an $n$ -dimensional Riemannian manifold to show that it (the curvature tensor) has at most $\frac1{12} n^2 (n^2 - 1)$ degrees of freedom (see for example here, section 7 ) at a given point. As far as I know $\frac1{12} n^2 (n^2 - 1)$ is the actual number of degrees of freedom, so my question is how does one get the lower bound? EDIT : To clarify: The argument I linked to shows that using the mentioned symmetries $\frac1{12}n^2 (n^2 - 1)$ of the $n^4$ entries of $R$ already determine it. However there could be other constraints like symmetries or inequalities that make the actual number of degrees of freedom even lower. As far as I know, this is not the case and my but I would like a proof of this. (The only wat to prove this I can think of would be constructing a family of manifolds parametrized by $\mathbb{R}^{n^2 (n^2 - 1)/12}$ such that for a given $p \in \mathbb{R}^{n^2 (n^2 - 1)/12}$ the corresponding manifold has the curvature tensor corresponding to $p$ at some point.)","['riemannian-geometry', 'tensors', 'curvature', 'general-relativity', 'differential-geometry']"
3056419,How to prove $\frac{\tan (A)}{\tan (A)}+\frac{\cot (A)}{\cot (A)}=\frac{1}{1-2\cos(A)^2}$,"I am unable to prove this trigonometric identity $$\frac{\tan (A)}{\tan (A)}+\frac{\cot (A)}{\cot (A)}=\frac{1}{1-2\cos^2(A)}$$ I have tried to transform the left-hand side and stuck with this $$\frac{2\sin(A)\cos(A)}{\sin(A)\cos(A)}$$ And I have tried to transform the right-hand side by changing the $$2\cos^2(A)$$ to $$\frac{2}{\sec^2(A)}$$ , and used the trigonometric identity $$1+\tan^2(A)=\sec^2(A)$$ and got this instead $$\frac{1+\tan^2(A)}{\tan^2(A)-1}$$ which I can transform to $$\frac{\cot(A)+\tan(A)}{\tan(A)-\cot(A)}$$ . I cannot get both sides equal, help please?",['trigonometry']
3056433,Question related to Darboux's theorem,"Darboux's theorem says that $f'$ has intermediate value property. More precisely, ( Darboux's theorem) If $f$ is differentiable on $[a,b]$ , and if r is any number for which $f'(a)<r<f'(b)$ then $\exists$ c in (a,b) such that $f'(r)=c$ . Thus Darboux's theorem implies that $f'$ cannot have any simple discontinuities on $[a,b].$ I have a question as follows: Is there a function $f$ satisfying $\displaystyle \lim_{x\to d} f'(x)=\infty$ for some $d \in (a,b)$ under the assumptions in Darboux's theorem? If so, I can conclude that for each $x \in (a,b),$ either $(i)$ $f'$ is continuous at $x$ or $(ii)$ $f'$ oscillates near $x.$ It seems that there is no differentiable function $f$ on $[a,b]$ satisfying function $\displaystyle \lim_{x\to d} f'(x)=\infty$ and $\exists f'(d)$ for some $d \in (a,b)$ . Please let me know if you have any idea or comment for my question. Thanks in advance!","['calculus', 'analysis', 'real-analysis']"
3056448,Shape of $\{a>0:\int |f|^a \text{d}\mu<\infty\}$,"Given a measure space $\mathcal{M}=(X,\mathcal{A},\mu)$ and a measurable function $f:X\to\mathbf{R}$ , what shapes can the following set take? $$\{a>0:\int |f|^a \text{d}\mu<\infty\}$$ Is it always a half-open intervall, can it contain isolated points, etc.?","['measure-theory', 'analysis']"
3056466,What is the best way to factor $25x^2-121$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question What is the best way to factor $25x^2-121$ ? The methods I have been taught doesn't work for this problem. Is there an another way to solve this problem? If so, how?","['algebra-precalculus', 'factoring']"
3056471,"Expected value of $k$th ordered statistic in Uniform(0, r) for r<1","Suppose that we draw $X_1, \ldots, X_n$ independently and uniformly from $(0,r)$ and let $X_{(k)}$ denote the $k$ th smallest number drawn. Denoting the pdf of $X_{(k)}$ by function $f_k$ , I know that $$
f_{k}(x) = n \frac{1}{r} \binom{n-1}{k-1}(x/r)^{k-1}(1-x/r)^{n-k}.
$$ Questions How can I find the expected value of $X_{(k)}$ ? I know that $\mathbb{E}[X_{(k)}] = \int_0^rf_k(x)xdx$ ; but I don't know how to solve it. Intuitively, I believe the answer should be $\mathbb{E}[X_{(k)}]=\frac{k}{n+1}r$ but I don't have any proofs for it. How concentrated is $X_{(k)}$ around its expectation? More precisely, I would like to know an upper bound on $\Pr[|X_{(k)}-\mathbb{E}[X_{(k)}]| > \epsilon]$ for given $\epsilon$ .","['statistics', 'probability']"
3056491,Inverse of strictly diagonally dominant matrix,I have a matrix whose diagonal entries are positive whereas non-diagonal entries are negative.This matrix is also Strictly diagonally dominant. Can we say that all elements of the inverse of this matrix is strictly positive i.e $a_{ij}$ >0 .,"['matrices', 'linear-algebra']"
3056493,Prove that $X/A \cong (\Bbb{R^*};.)$.,"Let $$\begin{align}
X &=\left\{r\left(\cos \dfrac{k\pi}{3}+i \sin \dfrac{k\pi}{3}\right): r \in \Bbb{R^*},k \in \Bbb{Z}\right\}, \\
A &=\{z \in \Bbb{C}|z^3=1\}.
\end{align}$$ We can show that $(X;.) ,(A;.)$ is a group. Moreover, we got $(A;.)$ is a subgroup of $(X;.)$ . The problem is: Prove that $X/A \cong (\Bbb{R^*};.)$ . I tried my best to find an isomorphism but I can't find an isomorphism which has kernel $A$ even though I used the lemma $(\Bbb{R^+};+) \cong (\Bbb{R^*};.)$ , so I am stuck here. Any help is appreciated.","['group-theory', 'abstract-algebra', 'group-isomorphism']"
3056515,Mutually disjoint triangles in certain planar graph,"Let G be a connected, planar graph for which every vertex has degree 3, except that one vertex has degree 2. Is it possible to construct an example of such G whose only odd faces are triangles, and for which no two such triangles share a common vertex? (For my purposes I may assume there are no faces of length 1 or 2, in which case there must be an odd face of length at least 3. By the handshake lemma, there are an even number of, hence at least 2, such odd faces.)","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3056521,Problem of three circles,"This geometrical problem was proposed in a Mathematics Contest for high school students of my country. It is truly hard to find its solution. Let $ABC$ be an acute triangle inscribed in the circle with its center $O$ . The line which is perpendicular to $AO$ at $O$ intersects $AB$ and $AC$ at $E$ and $F$ respectively. Let $D$ be the intersection point of $BF$ and $CE$ . The circumscribed circle of triangle $BDC$ intersects $AB$ and $AC$ at $M$ and $N$ respectively and the circumscribed circle of triangle $DEF$ intersects $AB$ and $AC$ at $P$ and $Q$ respectively. Let $S$ be the intersection point of $BC$ and $EF$ , and $K$ be the intersection point of $PN$ and $MQ$ . Prove that $AK\perp SD$ . I am happy if someone could propose some fresh ideas to attack this problem.","['contest-math', 'euclidean-geometry', 'geometry', 'triangles', 'plane-geometry']"
3056556,Inequality involving Monotone likelihood ratio and CDF ratio,"This problem has really been bothering me and I have no idea whether the statement is true or not. So any help is appreciated. Suppose $f(x)/g(x)$ satisfies monotone likelihood ratio property and have CDF $F$ and $G$ , respectively. Assume $f$ and $g$ have support in $[0,1]$ . Let $C \leq 1$ be a constant, and some $1 \geq x_1 \geq x_2\geq 0 $ , such that the following condition holds: $$ C\cdot \frac{f(x_1)}{g(x_1)} = \frac{f(x_2)}{g(x_2)}.$$ Prove or give a counterexample $$ C\cdot \frac{1-F(x_1)}{1-G(x_1)} \leq \frac{1-F(x_2)}{1-G(x_2)}$$ If false, is there a simple condition that could be added to $f$ and $g$ such that the statement is true? Attempt to showing proof : A natural place to start was using the inequality $$\frac{f}{g}(x) \leq \frac{1-F(x)}{1-G(x)}$$ but that ended up going nowhere. Attempt to construct counterexample If there is a counterexample, it could be that $1-F(x_2)$ is extremely close to $0$ . But that means $1-F(x_1)$ is also close to $0$ since $x_1 > x_2$ . It's also not immediately clear that the construction is valid. I also attempted a simple case of $F = x^2$ and $G = x$ but it was not a counterexample.","['statistics', 'ratio', 'density-function']"
3056560,Proving inequality $\int_a^{\pi/2}\cos^nxdx\le e^{-na^2/2}\int_0^{\pi/2}\cos^nxdx$,"How to prove $$\int_a^{\pi/2}\cos^nxdx\le e^{-na^2/2}\int_0^{\pi/2}\cos^nxdx,$$ where $n\in\mathbb N$ and $a\in[0,\pi/2]$ ? I noticed that if we can prove $$\cos^na\le nae^{-na^2/2}\int_0^{\pi/2}\cos^nxdx,$$ apply $\displaystyle\int_a^{\pi/2}$ to both side, the conclusion will follow. But unfortunately, this inequality above is not true. When $a=0$ , $LHS=1>0=RHS$ . Also, Wallis' formula can help us find $\displaystyle\int_0^{\pi/2}\cos^nxdx$ . I'm not sure if it helps.","['integration', 'calculus', 'definite-integrals', 'inequality']"
3056578,$\sum_{n=-\infty}^{\infty}\frac{1}{(u +n)^2}=\frac{\pi^2}{(\sin \pi u)^2}$,"I've already see a proof by Marko Riedel which I list it follows: The standard way to treat these sums is to integrate $$ f(z) = \frac{1}{(z+\alpha)^2} \pi \cot(\pi z)$$ along a contour consisting of a circle of radius $R$ and with $R$ going to infinity and hence being larger than $\alpha$ , where the circle does not pass through the poles on the real axis.
  Now along the semicircle in the upper half plane we have $$|f(z)| \le \frac{1}{(R-|\alpha|)^2}\pi
\left|\frac{e^{i\pi R\exp(i\theta)} + e^{-i\pi R\exp(i\theta)}}
{e^{i\pi R\exp(i\theta)} - e^{-i\pi R\exp(i\theta)}}\right|=
\frac{1}{(R-|\alpha|)^2} \pi 
\left|\frac{e^{2i\pi R\exp(i\theta)}+1}{e^{2i\pi R\exp(i\theta)}-1}\right| <
\frac{1}{(R-|\alpha|)^2} \pi  
\frac{1+e^{-2\pi R\sin(\theta)}e^{2i\pi R\cos(\theta)}}
{1-e^{-2\pi R\sin(\theta)}e^{2i\pi R\cos(\theta)}}$$ This last term is clearly $O(1/R^2)$ as $R$ goes to infinity as the quotient of the two exponentials goes to one since $\exp(-R)$ vanishes and there is no singularity when $\theta = 0$ or $\theta = \pi$ as $R\cos\theta = \pm R$ , which is not an integer by the assumption that the circle avoids the poles and hence cannot be one. My question: It is clear that for each $z=Re^{i \theta}$ , $f(z)=O(1/R^2)$ ，but can this guarantee that the last term on RHS is uniform bounded ? Since $\theta$ varies on a compact interval $[0, \pi]$ , I want to show that for each $ \theta \in [0, \pi]$ , and a fixed positive number $M \gt 1 $ there exist an open ball contains $\theta$ and a fixed $R_{\theta}\gt 0$ , for every $R \ge R_{\theta}$ and $x \in $ the open ball $$\frac{1+e^{-2\pi R\sin(x)}e^{2i\pi R\cos(x)}}
{1-e^{-2\pi R\sin(x)}e^{2i\pi R\cos(x)}} \le M$$ For $\theta \neq 0,\pi$ , it is easy to find the desired $R_{\theta}$ and the open ball , but if $\theta = 0$ or $ \theta = \pi$ , for every open ball containing $\theta$ , it behave erratically near $\theta$ , I have no idea how to deal with this .",['complex-analysis']
3056623,$\int_0^{\pi/2}\log^2(\cos^2x)\mathrm{d}x=\frac{\pi^3}6+2\pi\log^2(2)$???,I saw in a paper by @Jack D'aurizio the following integral $$I=\int_0^{\pi/2}\log^2(\cos^2x)\mathrm{d}x=\frac{\pi^3}6+2\pi\log^2(2)$$ Below is my attempt. $$I=4\int_0^{\pi/2}\log^2(\cos x)\mathrm{d}x$$ Then we define $$F(a)=\int_0^{\pi/2}\log^2(a\cos x)\mathrm{d}x$$ So we have $$F'(a)=\frac2a\int_0^{\pi/2}\log(a\cos x)\mathrm{d}x$$ Which I do not know how to compute. How do I proceed? Thanks.,['integration']
3056648,Exit poll in elections,"We want to run an exit poll for the government referendum, by asking the voters in one vote center whether they voted for option A or B.
  We have an urn with 5 red, 3 green and 2 blue marbles. Each voter randomly picks one marble from the urn, sees its color and then places it back in the urn. If it is red, he tells the truth (we assume that he must have voted either A or B – there is no other option). If it is green, he replies “B”, regardless of what he has actually voted and if it is blue, he replies “A”, again regardless of what he has actually voted. 
  At the end of the exit poll, we got 40% A’s. What is the actual percentage of the A’s voters in this vote center? Probabilities is not my strong area of knowledge :( I was told that this is an easy example of Bayes theorem - I went through it but really can't find how to apply it! \begin{align}
\mathsf P(R\mid G, B) & = \frac{\mathsf P(R,G,B)}{\mathsf P(G, B)}
\end{align} OK of course the probability of R is 0.5, of G 0.333 and for B 0.2. 
But I don't know what to do then.",['probability']
3056689,"Given $\left(x + \sqrt{1+y^2}\right)\left(y + \sqrt{1+x^2}\right) = 1$, prove $\left(x + \sqrt{1+x^2}\right)\left(y + \sqrt{1+y^2}\right) = 1$. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $x$ and $y$ be real numbers such that $$\left(x + \sqrt{1+y^2}\right)\left(y + \sqrt{1+x^2}\right) = 1$$ Prove that $$\left(x + \sqrt{1+x^2}\right)\left(y + \sqrt{1+y^2}\right) = 1$$","['contest-math', 'algebra-precalculus', 'radicals', 'trigonometry']"
3056692,Converting ODE to Variational Problem (for numerical solution),"This might be a stupid question, but I cannot find the answer anywhere and as an engineer I don't have the mathematical foundation to investigate this properly myself. So, If I have a simple ODE, say for example a harmonic oscillator like $u''+u=0$ , I know that I can try to convert it into a variational problem by finding a Lagrange function $F$ , so that if I plug it into to the Euler-Lagrange differential equation $$\frac{\partial F}{\partial u}-\frac{\mathrm{d}}{\mathrm{d}x}\frac{\partial F}{\partial u'}+\frac{\mathrm{d^{2}}}{\mathrm{d}x^{2}}\frac{\partial F}{\partial u''}=0$$ I get my ODE back. In this case one easily finds that e.g. $$F=\left(u'\right)^2-u^2$$ fulfills this condition. However now I considered the naive idea of simply just taking the following integral $$\int_{x_{1}}^{x_{2}}(u''+u)^{2}\mathrm{d}x\rightarrow\text{min.}$$ So basically to take $F:=(\text{some ODE})^2$ . Naively this seems to me like in its minimum the ODE is satisfied. To test this, I implemented a numerical solver that takes a polynomial ansatz and solves the coefficients to find an approximation of the solution (here a sine) of the ODE between $0$ and $\pi/2$ . And it seems to actually work but the solution isn't exactly the same as for $F=\left(u'\right)^2-u^2$ - it is a little bit less accurate (so clearly not the optimal solution yielded by the ansatz)! However, if I take piece-wise linear functions, this native functional completely fails to provide an approximate solution, while $F=\left(u'\right)^2-u^2$ works perfectly. To investigate a little further I plugged in $F=(u''+u)^{2}$ into the Euler-Lagrange eq. and realize that I get $$2(u''+u)+2\left(u''+u\right)''=0$$ which seems to satisfy the same solution as my original problem. So my two questions that arise from all this: 1) Why is it that the naive idea of doing $F=(\text{some ODE})^2$ seems to be working somewhat but not always, if I want to numerically solve an ODE via variational method? 2) Consequently: If I have an ODE of the form $f(u, u', u'', ..., x)=0$ , all ODEs of the form $f(u, u', u'', ..., x) + \left(f(u, u', u'', ..., x)\right)' + \left(f(u, u', u'', ..., x)\right)'' + ... =0$ seem to have the same solution as the original ODE, but they are in fact of higher order. What is the significance of these ODEs and their solutions? Apologies of the lengthy post but I would really appreciate any input on this. As I said, I am an engineer and quite out of my depth here. Thank you in advance!","['differential', 'numerical-methods', 'ordinary-differential-equations', 'calculus-of-variations']"
3056696,Has this topology been studied?,"I came up with a certain topology and played around with it a little. I was wondering if it has been looked at. I wouldn't know where to begin looking. Given a real vector space $V$ , define a topology on $V$ as such: A set $U\subset V$ is open if and only if for all $x\in U$ and all $y\in V$ , there exists $\epsilon>0$ such that for all $t\in (-\epsilon,\epsilon)$ , we have $x+ty\in U$ . This topology is typically strictly finer than that induced by a norm on $V$ . I've deduced several properties of this topology myself, but I wanted to read more on it. This can also be generalized to vector spaces over any field which is a metric space.","['general-topology', 'reference-request']"
3056699,Two sides of a triangle are $\sqrt{3}+1$ and $\sqrt{3}-1$ and the included angle is $60^{\circ}$. Find other angles,"Two sides of a triangle are $\sqrt{3}+1$ and $\sqrt{3}-1$ and the included angle is $60^{\circ}$ . Then find the other angles My Attempt Let $a=\sqrt{3}+1$ , $b=\sqrt{3}-1$ and $C=60$ $$
c^2=a^2+b^2-2.a.b\cos C\\=(\sqrt{3}+1)^2
+(\sqrt{3}-1)^2-2(\sqrt{3}+1)(\sqrt{3}-1).\frac{1}{2}
=8-2=6\\
\implies c=\sqrt{6}=\sqrt{2}\sqrt{3}\\
\frac{a}{\sin A}=\frac{c}{\sin C}\implies\sin A=\frac{\sqrt{3}+1}{\sqrt{2}\sqrt{3}}\frac{\sqrt{3}}{2}=\frac{\sqrt{3}+1}{2\sqrt{2}}\\
A=75^\circ\quad\&\quad B=45^\circ
$$ But the solution given in my reference is $105^\circ$ and $15^\circ$ , what is going wrong with my attempt ?","['triangles', 'trigonometry', 'geometry']"
3056715,Evaluate $\frac{2}{\sqrt{2}}\cdot \frac{2}{\sqrt{2+\sqrt{2}}}\cdot \frac{2}{\sqrt{2+\sqrt{2+\sqrt{2}}}}\cdots$,"Problem Evaluate the infinite product $$\frac{2}{\sqrt{2}}\cdot \frac{2}{\sqrt{2+\sqrt{2}}}\cdot
\frac{2}{\sqrt{2+\sqrt{2+\sqrt{2}}}}\cdots$$ Attempt For convenience，let's rewrite the limit. Denote $$x_1=\sqrt{2},~~~x_{n+1}=\sqrt{2+x_n}(n=1,2,\cdots),$$ then $$\lim_{n \to \infty}\left(\frac{2}{x_1}\cdot \frac{2}{x_2}\cdots \frac{2}{x_n}\right)$$ is what we want. It's easy to obtain that， $\{x_n\}$ is increasing with a greater $n$ ，and convergent to $2$ . Hence $$x_1<x_2<\cdots x_n<2.$$ Therefore $$\frac{2}{x_1}>\frac{2}{x_2}>\cdots>\frac{2}{x_n}>1.$$ Can we go on from here?","['infinite-product', 'limits']"
3056717,Isn't the construction of successors of numbers up to infinity the same as what the axiom of infinity says?,"In the book of ""Näive Set Theory"", the author writes first 3 numbers as a set of previous numbers building by this successors of previous numbers and then writes ""etc."" which he clarifies that from what has been said it doesn't follow the construction of successors continues ad infinitum. Then, he introduces the axiom of infinity which says there exists a set that contains $0$ and successor of each of its elements. Isn't it the same thing as building successors up to infinity? What am I missing and why I can't I see the difference between two concepts?",['elementary-set-theory']
3056729,Why is $\mathscr{A}_{\infty}=\bigcup_{n\in\mathbb{N}} \mathscr{A}_n$ never a $\sigma$-algebra?,"Problem: Let $(X, \mathscr{A})$ be a measurable space and $(\mathscr{A}_n)_{n\in\mathbb{N}}$ be a strictly increasing sequence of $\sigma$ -algebras. Show that $$ \mathscr{A}_{\infty} := \bigcup_{n\in\mathbb{N}} \mathscr{A}_n $$ is never a $\sigma$ -algebra. This is a problem of a book of Rene Schilling . He shows an answer of this problem on his homepage. However I don't understand the last part, Step 5. I don't know there always exists the smallest set $B_n$ . Here is his solutions . This problem is Problem 3.8. [pp.24-26]","['elementary-set-theory', 'measure-theory']"
3056732,How to find a specific curve if the initial value is not given?,"Question: Let $y(x)$ be the solution of the differential equation $x\cdot ln(x)\dfrac{dy}{dx}+y=2x\cdot ln(x)$ , $x\ge1$ . Find $y(e)$ . Answer : $y(e) = 2$ Problem: So I understand that this can be converted into a simple linear differential equation and found that the solution is: $y\cdot ln(x)=2(x\cdot ln(x) - x) + C$ This is a family of curves. However for solving the question, I need a specific curve out of all these.
What I don't understand is how how do I find that particular curve  as the initial value of the function is not given.","['calculus', 'ordinary-differential-equations']"
3056775,Finding the number of subgroups of $\mathbb{Z}_{p^3} \oplus \mathbb{Z}_{p^2} $.,What is the number of subgroups of order $p^2$ of $\mathbb{Z}_{p^3} \oplus \mathbb{Z}_{p^2} $ ? I'm not really sure how to figure it out. I tried seeing subgroups of each $\Bbb Z_{p^n}$ but I'm not sure I'm going to get them all.,"['group-theory', 'abstract-algebra', 'finite-groups', 'p-groups']"
3056821,"$L(V,\mathbb{R})$ with $\|\cdot\|_1$ complete?","Let $(V,\|\cdot\|_V)$ and $(W,\|\cdot\|_W)$ be normed vector spaces. By $L(V,W)$ we denote the space of bounded linear operators from $V$ to $W.$ If $W$ is complete, then $L(V,W)$ with the operator norm $\|T\| := \sup \left\{\|Tu\|_W : \|u\|_V \leq 1\right\}$ is a Banach space. Now assume in addition that $\gamma$ is probability measure on $V$ with $\mathrm{supp}\, \gamma = V$ and with existing first moment. My Question: Is $L(V,\mathbb{R})$ closed subspace in $(\mathrm{L}_1(V),\|\cdot\|_1)$ ? In this case $L(V,\mathbb{R})$ with $\|\cdot\|_1$ would also be a Banach space.","['general-topology', 'lp-spaces', 'functional-analysis']"
3056834,Prove that $T$ is a bounded operator on a disk algebra and prove the existence of a Borel measure on a boundary of an open unit disk.,"Let $A(D)$ be the space of holomorphic functions on the open unit disk $D$ and continuous on the closed disk $\bar{D}$ . Then $A(D)$ is a Banach space if we set $\|f\|=\sup\{|f(z)|:z\in\bar{D}\}$ . For $f\in A(D)$ write $$
f(z)=\sum_{n=0}^{\infty}a_nz^n.
$$ a) Let $\{c_n\}_{n=0}^{\infty}$ be a sequence of complex numbers with the property that if $f\in A(D)$ represented as above, and $$
f^*(z)=\sum_{n=0}^{\infty}c_na_nz^n,
$$ then $f^*\in A(D)$ . Prove that there exists $C>0$ such that $\|f^*\|\leq C\|f\|$ for all $f\in A(D)$ . I am thinking that I need to prove $T:A(D)\to A(D)$ with $T(f)=f^*$ is bounded (or continuous). Do you have any other ideas? b) Let $\omega\in D$ . Prove that there exists a Borel measure $\mu_{\omega}$ on $\partial D=\{z:|z|=1\}$ such that $$
f(\omega)=\int_{\partial D}f(t)d\mu_{\omega}(t),\;f\in A.
$$ I am thinking that we can use the Maximum Modulus principle, but is the measure $\mu_{\omega}$ unique? Could you please give me some ideas? Thank you so much.","['banach-spaces', 'analysis', 'holomorphic-functions', 'maximum-principle', 'functional-analysis']"
3056845,Conditions on face length in planar graph,"I have a planar, connected graph with vertices of degree 3 except for one with degree 2. There is an odd, outer face of length at least 5, containing the degree 2 vertex. The inside faces consist of 3 mutually disjoint triangles,disjoint from the outer face, and the rest even. EDIT: further suppose that no triangle and square share an edge. (Adjacent squares are permitted.) Is such a graph possible? Below is a non-example. It only has 1 triangle, and this is not disjoint from the outer, length 5, face (which contains the degree 2 vertex). Plus there is a square sharing an edge with a triangle.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3056875,Solving an DE involving a logarithm,"I've the following DE, describing a physical phenomenon. And the prupose is to solve that DE: $$x(t)\cdot r+x'(t)\cdot l+a\cdot\ln\left(1+\frac{x(t)}{b}\right)=0\space\Longleftrightarrow\space x(t)=\dots$$ The intial conditon is equal to $x(0)=x_0$ . For the constants (because that is maybe important for an approximation): $r$ can be very large; $l$ can be very large; $a$ is round about $0.02526$ ; $b$ is very small, round about $300\cdot10^{-6}$ ; $x_0$ can be very large I've no idea where to start what so ever. Thanks for any help or ideas","['ordinary-differential-equations', 'logarithms', 'functions', 'physics', 'mathematical-physics']"
3056882,Can an indefinite integral be expressed as a definite integral with variable bounds?,"If I have a function $f(t)$ , and an indefinite integral of this function, $g(x) = \int f(t)\, dt$ , is there any way I can express $g(x)$ as a definite integral whose bounds depend on $x$ ? I thought I saw somewhere that I could express it as $$g(x) = \int_a^x f(t)\, dt$$ but I don't know what $a$ is. Is this representation correct? Or is there a better way to express $g$ ?","['indefinite-integrals', 'calculus', 'definite-integrals']"
3056887,What is $\int\delta(x-y)\delta(y-z)f(y)\:{\rm d}y$?,"Let $(\Omega,\mathcal A,\mu)$ be a measurable space and $\delta$ denote the Dirac delta function. If $f\in\mathcal L^1(\mu)$ and $x,z\in\Omega$ , what is $$\int\delta(x-y)\delta(y-z)f(y)\:\mu({\rm d}y)?$$ I've found that in a paper, but isn't that undefined?","['dirac-delta', 'functional-analysis', 'real-analysis']"
3056890,A Series For the Golden Ratio,Question: Can we show that $$\phi=\frac{1}{2}+\frac{11}{2}\sum_{n=0}^\infty\frac{(2n)!}{5^{3n+1}(n!)^2} $$ ; where $\phi={1+\sqrt{5} \above 1.5pt 2}$ is the golden ratio ? Some background and motivation: Wikipedia only provides one series for the golden ratio - see also the link in the comment by @Zacky. I became curious if I could construct another series for the Golden Ratio based on a slight modification to a known series representation of the $\sqrt{2}.$ At first I considered $$\sqrt{2}=\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n+1)!!}{(2n)!!}$$ ; which series can be accelerated via an Euler transform to yield $$\sqrt{2}=\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n+1)!!}{2^{3n+1}(n!)^2}$$ This last series became the impetus to try and and get to the Golden ratio. Through trial and error I stumbled upon $$\frac{\sqrt{5}}{11}=\sum_{n=0}^\infty\frac{(2n)!}{5^{3n+1}(n!)^2}$$,"['golden-ratio', 'calculus', 'sequences-and-series']"
3056919,What is the relationship between the orbit-stabilizer theorem and Lagrange's theorem?,"Is Lagrange's theorem used to prove that the length of the orbit times the order of the stabilizer is the order of the group, or is Lagrange's theorem a corollary of the orbit-stabilizer theorem?","['group-theory', 'group-actions', 'finite-groups']"
3056924,"if $A \in C^{2015,2015}$ and $rank(A) < 1000$ proof that $\dim(\ker(A+A^T)) > 15$","I want to solve that thesis: if $A \in C^{2015,2015}$ and $rank(A) < 1000$ proof that $\dim(\ker(A+A^T)) > 15 $ from the fact that $$\dim(im(A)) = \dim(im(A^T))$$ and $$ \dim(\ker(A))+\dim(im(A))=n $$ it follows that $$\dim(\ker(A)) = \dim(\ker(A^T))$$ We know that $rank(A) < 1000$ . Hence $\dim(\ker(A))>1015$ But there I have stuck...
thanks for your time","['matrices', 'matrix-rank', 'linear-algebra']"
3056953,How did Einstein integrate $\frac{\partial \tau}{\partial x'}+\frac{v}{c^2-v^2}\frac{\partial \tau}{\partial t}=0$?,"In his paper ""On the Electrodynamics of Moving Bodies"", Einstein writes the equation $$\dfrac{\partial \tau}{\partial x'}+\dfrac{v}{c^2-v^2}\dfrac{\partial \tau}{\partial t}=0$$ where $\tau=\tau(x',y,z,t)$ is a linear function (i.e. $\tau=Ax'+By+Cz+Dt$ ) $x'=x-vt$ $\dfrac{\partial \tau}{\partial y}=0$ (i.e. $B=0$ ) $\dfrac{\partial \tau}{\partial z}=0$ (i.e. $C=0$ ) $c$ is a constant $x,x',y,z,t,v$ are variables and he derives that $$\tau=a\left(t-\dfrac{v}{c^2-v^2}x'\right)$$ where $a=a(v)$ Could someone please walk me through step-by-step how he derived this? I am not very familiar with integrals invovling partial derivatives, so I would be appreciative if any answers are quite explicit. Additionally, if I modified the question to say that $\tau$ was an affine function (i.e. $\tau=Ax'+By+Cz+Dt+E$ ), would it make any difference to the result (I suspect it wouldn't)?","['partial-derivative', 'linear-algebra', 'linear-transformations', 'partial-differential-equations']"
3056961,New Year Maths $2019$,"$$\;\;\;\color{red}{\binom {20}{19}}\\
\color{orange}{+\binom {19}{a}
+{\binom  ab}}\\
\color{green}{+\binom bc
+\binom cd}\\
\color{blue}{+\binom de+
\binom ef}\\
\color{purple}{+\binom fg+\binom gh}\\
\color{magenta}{+\binom hk}\\[15pt]
\color{orange}=\\[10pt]
\color{red}{2019}\\[15pt]
\color{orange}{a,b,}
\color{green}{c,d,}
\color{blue}{e,f,}
\color{purple}{g,h,}
\color{magenta}k\color{orange}{=?}\\[20pt]$$ $$\color{red}{\text{Happy New Year!}}$$ Note - Please feel free to post any other interesting identities based on the same theme!","['summation', 'binomial-coefficients', 'combinatorics', 'recreational-mathematics']"
3056971,Number of primes between $n$ and $2n$,What is a good lower bound on $\pi(2n)-\pi(n)$ ? Bertrand's postulate gives $1$ . It is expected to be as I understand of form $\frac{c\cdot n}{\log n}$ from Prime Number Theorem. Does the ratio always hold for all large enough $n$ with some $c$ always between $0$ and $c_0$ for some absolute constant $c_0$ ? How often does it fail as far as we know?,"['analytic-number-theory', 'number-theory', 'prime-gaps', 'prime-numbers']"
3056984,Strict convexity and equivalent conditions,"Let $f \colon \mathbb R^n \to [0,+\infty)$ be a convex, positively 1-homogeneous function, i.e. it holds $$\tag{1}
f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda) f(y), \qquad \forall \lambda \in [0,1], \, \forall x,y \in \mathbb R^n
$$ and $$\tag{2}
f(\lambda x) = \lambda f(x), \qquad \forall \lambda >0, \, x \in \mathbb R^n. 
$$ Let me denote by $E_c := \{ f \le c\}$ the sub-level set at height $c$ . I have been asked to show that Assumption (2) implies that the sub-level sets are homothetic. Indeed I have proved that $E_c = cE_1$ for every $c>0$ . Now, assuming that $f$ is also of class $C^2(\mathbb R^n)$ ,  I have to investigate the validity of the following equivalence: (A) The set $E_1$ is strictly convex; (B) There exists $s>0$ such that $$
\nabla^2 f[x] (z,z) \ge s \vert z - (z\cdot x)x \vert^2 
$$ for every $x,z \in \mathbb R^n$ , being $\nabla^2 f[x](z,z) = \langle (\nabla^2 f)(x) \cdot z, z \rangle$ the quadratic form associated to the Hessian matrix of $f$ (evaluated at $x$ ). Q. Is it true that (A) iff (B)? I have no idea on how to face the question, and I am looking for some intuition behind condition (B). What is it actually saying? How could it be related to sub-level sets? ADDENDUM : I think I got some intuition behind condition (B). If I am not wrong that should be a uniform bound (from below) on the Gaussian curvature of the level set $\{f=1\}$ (assuming that all points are regular, i.e. $\vert \nabla f(x) \vert \ne 0$ for every $x \in \{f=1\}$ : is this assumption necessary?). This is an easy consequence of the formula contained in this page. Do you agree on this consideration? Now the question becomes: how is it possible to relate a (uniform) bound on the Gaussian curvature of the level set $\{f=1\}$ with the (strict) convexity of the set $\{f \le 1\}$ ? To me this makes sense, because the strict convexity of $\{f \le 1\}$ roughly means that its boundary has no flat parts, and its boundary should be related to the level set - which has curvature bounded from below, i.e. it is well-round...","['functions', 'convex-analysis', 'real-analysis']"
3056994,Galois Groups are isomorphic to subgroups of symmetric groups.,"I am currently working through Joseph Rotman's book ""Galois Theory"" and am trying to prove the following theorem. If $f(x) \in F[x]$ has $n$ distinct roots in its splitting field $E$ , then $\operatorname{Gal}(E/F)$ is isomorphic to a subgroup of the symmetric group $S_n$ , thus its order is a divisor of $n!$ . I have struggled to understand the proof in the book and have therefore tried to write my own proof of this fact, I have found some questions close to this on this site, but haven't been able to find exactly what I'm looking for. My proof (so far) is as follows: Proof: Let $X = \{\alpha_1, ... , \alpha_n \}$ be the set of roots of $f(x)$ , as $E$ is the splitting field of $f$ , it may be written as $E = F(\alpha_1, ... , \alpha_n)$ and noting that $\alpha_i \neq \alpha_j$ for $i\neq j$ . Let $\sigma \in \operatorname{Gal}(E/F)$ then $\sigma(X) = X$ (a result from an earlier lemma). Now I would like to construct an injective homomorphism from $\operatorname{Gal}(E/F)$ to $S_n$ , my guess is the map which sends $\sigma$ to its restriction in $X$ , which I shall denote by $\sigma_X$ . Let $g$ be this map, then it is clear that $g$ is a homomorphism. Now I try to show that $g$ is injective, consider $\sigma, \phi \in \operatorname{Gal}(E/F)$ where $\sigma \neq \phi$ , both of these functions are F-automorphisms of $E/F$ , so they ""fix"" $F$ , then we can conclude that $\sigma$ and $\phi$ can be different if and only if they act differently on $X$ , which in the language of mathematics is precisely $\sigma \neq \phi \Leftrightarrow \sigma_X \neq \phi_X$ . This is the definition of an injective function. This means that $\left|\operatorname{Gal}(E/F)\right| \leq |S_n| = n!$ , however due to having constructed a homomorphism, we have mapped a group  to another group, hence we have mapped $\operatorname{Gal}(E/F)$ to a subgroup of $S_n$ , whose order divides $|S_n|$ and therefore $\left|\operatorname{Gal}(E/F)\right|$ divides $n!$ , completing the proof. Question I am wondering whether my proof for this is correct, I think that it is mostly there, with the statement we can conclude that $\sigma$ and $\phi$ can be different if and only if they act differently on X perhaps being the only issue.","['galois-theory', 'group-theory', 'solution-verification']"
3057013,Intuition of definition of divergence,"Intution : 
The divergence of a three-dimensional vector field is the extent to which the vector field flow behaves like a source at a given point. But if my vector field is $F=\langle P,Q,R\rangle$ then formula is for divergence is given as $P_x+Q_y+R_z$ . I want to know how this formula capute that intutitve idea. I studied using MIT OCW. But professor didn't talk about how we get formula from the idea. 
So,I see videos from Khan academy, if we consider $i$ component i.e. $P$ , the divergence is positive ( Intution) if $P_x>0$ and vice versa.similarly for $j,k$ component. But a vector field need not be oriented along axis .he tells something like for an arbitrary vector field we can decompose vectors into components.but I didn't get that thing Could someone please explain how we get this formula from intution of divergence. Thanks!","['divergence-operator', 'multivariable-calculus', 'vector-analysis', 'fluid-dynamics']"
3057029,$\lim_{n \to \infty} \frac{\int_{\epsilon}^{1}(f(x))^{\frac{n-1}{2}}dx}{\int_{0}^{1}(f(x))^{\frac{n-1}{2}}dx} = 0$,"I wish to show that $\lim_{n \to \infty} \frac{\int_{\epsilon}^{1}(1-t^2)^{\frac{n-1}{2}}dt}{\int_{0}^{1}(1-t^2)^{\frac{n-1}{2}}dt} = 0$ where $0 < \epsilon < 1$ . I've failed to see a simple proof and would appreciate any help. This isn't the original question, but my efforts led me to this.","['integration', 'limits', 'calculus']"
3057030,Evaluate $\int_0^1 \frac{\operatorname{arctanh}^3(x)}{x}dx$,"I'm trying to evaluate the following integral: $$\int_0^1 \frac{\operatorname{arctanh}^3(x)}{x}dx$$ I was playing around trying to numerically approximate the answer with known constants and found that the integral is almost exactly $\frac{\pi^4}{64}$ . The integral seems to break down after about $11$ decimal places. I have a suspicion that this stems from the integral: $$\int_0^1 \frac{\operatorname{arctanh}(x)}{x}dx$$ since this is exactly equal to $\frac{\pi^2}{8}$ . Also for the integral: $$\int_0^1 \frac{\operatorname{arctanh}^5(x)}{x}dx$$ This is suspicously close to $\frac{\pi^6}{128}$ but not exactly.
For some reason the above integrals diverges slightly from the some from of $\frac{\pi^n}{2^m}$ for some $n$ and $m$ . My question is: Why does this happen? And what are the true values of those integrals?","['integration', 'definite-integrals', 'hyperbolic-functions', 'calculus', 'closed-form']"
3057061,Does invertability and closure imply identity?,"Sorry if this is a basic question or I'm overthinking it, but if an algebraic structure has inverse elements (or at least for a member $a$ ), that means $a^{-1}a=e$ , and if there's closure then e is an element of the set. So in the case of defining a group, for instance, why do we need to include identity? Is it already implied?","['binary-operations', 'abstract-algebra']"
3057078,When associated prime ideals are comaximal,"Let $R $ be a commutative ring with identity. Recall that a prime ideal is called associated prime ideal whenever it is the annihilator of a nonzero element. I want to know is there any equivalent conditions under which any two distinct associated prime ideals are comaximal, that is, their sum is $R $ ?","['maximal-and-prime-ideals', 'algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3057088,Does this velocity field have a potential?,"Let $\Psi=x-\frac{x^3y}{2}$ be the stream function . Then, by definition: $$
v_x=-\frac{\partial \Psi}{\partial y}, \, v_y=-\frac{\partial \Psi}{\partial x}
$$ To determine whether this field have a velocity potential : $$
-\frac{\partial \Phi}{\partial x}=v_x, \, -\frac{\partial \Phi}{\partial y}=v_y
$$ Solution: \begin{align*}
&\Phi (x,y)= -\frac{x^4}{8}+f(y) \\
 &\Phi (x,y)=\frac{3x^2y^2}{4}-y+g(x)
\end{align*} Does the fact that $x,y$ are not separated ensures that $\Phi(x,y)$ does not exist and the fluid is viscid ?","['ordinary-differential-equations', 'fluid-dynamics']"
3057129,Maximum estimator in upper Chernoff bound,"I have the following exercise about Chernoff bounds: Let $X_{1}, X_{2}, \dots, X_{n}$ be independent, identically distributed (i.i.d) random variables with distribution $N(0,\sigma^{2})$ . Show that for every $\varepsilon > 0$ : $$P(\overline{X_{n}} > \varepsilon) \le e^{\frac{-n\varepsilon^{2}}{2\sigma^{2}}}$$ A random variable $X$ with $E(X) = 0$ is said to be Subgaussian for the parameter $\sigma > 0$ if its moment generating function $M_{x}(t)$ is such that $M_{x}(t) \le e^{\frac{t^{2}\sigma^{2}}{2}}$ for all $t \in \mathbb{R} $ . Show that the inequality in the previous point holds if $X_{1}, X_{2}, \dots, X_{n}$ are i.i.d random variables, and Subgaussian for the parameter $\sigma > 0$ In the first point I know I am working with Chernoff bounds since the exercise already gives its upper tail, with $\mu = 0$ , so I have something like: $$P(\overline{X_{n}} > \varepsilon +  0) \le e^{-ng(t)}$$ Where $$g(t) = \varepsilon t - \log M_{X_{1}}(t)$$ Recalling that, in this case, $$M_{X_{1}}(t) = e^{\frac{t^{2}\sigma^{2}}{2}}$$ We have $$g(t) = \varepsilon t - \frac{t^{2}\sigma^{2}}{2}$$ Now here comes the problem. In order to discover my upper tail, I have to find a maximum estimator $t^{\star}$ so I can compute $g(t^{*})$ . The solution of the exercise says $t^{\star} = \frac{\varepsilon}{\sigma^{2}}$ , but I don't know why. So, what I ask is how I can find maximum estimators when it comes to this type of exercises. About the second point, since I already have $g(t^{\star})$ , how can this result will be useful to prove the inequality for all the Subgaussian. Wasn't this implicitly proved in the previous point?","['statistics', 'parameter-estimation', 'inequality', 'probability', 'random-variables']"
3057144,Largest coefficient in the power of a polynomial,"How do I find the largest coefficient of any power of $x$ in an expansion such as $(1 + 2x + 2x^2)^n$ , as a function of $n$ ? In the case $(1+x)^n$ , we know that the central coefficients are the largest, and for $(1+ax)^n$ I can take ratios of consecutive terms to find the largest one, but these methods fail in the case mentioned above. Also, can we find the degree of the term for which this largest coefficient occurs, again as a function of $n$ ?","['power-series', 'algebra-precalculus', 'combinatorics']"
3057155,"Is $\int\limits_0^\infty\frac{\sin y}{y^{s+1}}dy=-\Gamma(-s)\sin(\frac{\pi s}{2})$ for $\operatorname{Re}(s)\in (-1,0)$ obvious?","This is a part of computation in Titchmash, Theories of Zeta Functions which I do not find obvious but there is no explanation. I did figure out the computation. $$\int_0^\infty\frac{\sin(y)}{y^{s+1}}dy=-\Gamma(-s)\sin\left(\frac{\pi s}{2}\right)$$ Q: There is no explanation in the book for this step. Why is this obvious without explanation? My recipe goes as the following. It suffices to restrict to real axis part with $s\in (-1,0)$ region. Now integral is real valued in this region. Here I need $\Gamma(-s)=\frac{\Gamma(-s+1)}{s}$ extension to obtain real valuedness. Consider the integral as the imaginary part of $\int_0^{i\infty} \frac{e^{z}}{i^s z^{s+1}}dz$ where I have already rotated axis by $i$ multiplication. Now to obtain $\Gamma$ function, close contour from $(+\infty,0)$ axis portion and connect to $(0,i\infty)$ portion. Then close the contour by arc. The arc contour contribution is $0$ via exponential suppresion. Then apply residue theorem easily as the whole thing is holomorphic by $s\in (-1,0)$ region. Hence equality follows. This is not $1-2$ line naive computation though not hard. However, it did take me a while to figure out.","['complex-analysis', 'number-theory', 'analysis', 'real-analysis']"
3057167,"If $x^3 = y^2$, why is $y/x$ transcendental?","Let the ring $A=\mathbb{k}[x,y]/(x^3-y^2)$ , and set $t = \frac{y}{x}$ . We can form the subring $\mathbb{k}[t]\subset \operatorname{Frac}(A)$ , the smallest ring containing $t$ . We have identities like $t^2=x$ and $t^3 = y$ . Now - why is $\mathbb{k}[t]$ isomorphic to $\mathbb{k}[X]$ - the ring of polynomials in one variable? In other words, how we know that for any non-zero polynomial $p\in \mathbb{k}[X]$ , $p(t)\neq 0$ , i.e. $t$ is transcendental? Motivation: The question is motivated by another question, about the normalization of A , in which was determined that the normalization of $\widetilde{A}$ is indeed equal to $\mathbb{k}[t]$ . In there, the author of the question explicitly states in the comments that $t$ is not algebraic over $\mathbb{k}$ , but with no proof. So the proof should trivial, but still I don't see it. I think I have a proof of this fact, but it is unnecessarily complicated. I'm looking for a one-sentence proof. Nevertheless, I would be really thankful for a proof verification.
Let $w\in \mathbb{k}[T]$ be a polynomial such that $w(t) = 0$ in $\mathbb{k}[t]$ . It is of the form $$ w(T) = a_n T^n + \cdots+ a_1 T + a_0 $$ Using the definition of $t$ , I make a polynomial $w' \in \mathbb{k}[X,Y]$ $$ w'(X,Y) = a_n Y^n + a_{n-1} Y^{n-1} X + \cdots +a_1 Y X^{n-1} + a_0 X^n $$ so that $w'(x,y) = x^n w(t) $ in $A$ . Therefore $w'(x,y) = 0$ . It means that $w' \in \ker p$ , where $p$ is a natural projection $p: \mathbb{k}[X,Y] \to \mathbb{k}[x,y]/(x^3-y^2)$ , so we have $w'(X,Y) = (X^3-Y^2)v(X,Y)$ for $v \in \mathbb{k}[X,Y]$ . So we have a factorization $$ a_n Y^n + a_{n-1} Y^{n-1} X + \cdots + a_1 Y X^{n-1} + a_0 X^n = (X^3 - Y^2)v(X,Y)$$ Assuming $a_n \neq 0$ we see that $-a_0 Y^{n-2}$ should be among addends of $v$ (by comparing coefficients). Then we would have $-a_0 Y^{n-2} X^3$ in the product $(X^3-Y^2)v(X,Y)$ . But the coefficient in $w'$ before the $Y^{n-2} X^3$ term is $0$ , so to cancel it, we need either $$-a_0 Y^{n-4} X^3$$ or $$a_0 Y^{n-2}$$ term in $v(X,Y)$ . 
But it cannot be the latter - we already determined the coefficient before $Y^{n-2}$ to be $-a_0$ . So it must be $-a_0 Y^{n-4} X^3$ . But then, analogously, we get $-a_0 Y^{n-4} X^6$ that need to be canceled in the product.  Continuing like this, after $\lceil{\frac{n}{2}}\rceil$ steps we no longer could form the term for canceling, because the exponent would need to be negative. That leads to contradiction.","['alternative-proof', 'abstract-algebra', 'proof-verification', 'commutative-algebra']"
3057171,Average of a function that comes out of a complicated DE,"I've to find (the average of a function over a particular interval, where $t_1>0$ , $t_2>0$ and $t_2>t_1$ ): $$\frac{1}{t_2-t_1}\int_{t_1}^{t_2}x(t)dt\tag1$$ Where $x(t)$ is the solution to the following DE (with intial condition $x(0)=x_0)$ : $$x(t)\cdot r+x'(t)\cdot l+a\cdot\ln\left(1+\frac{x(t)}{b}\right)=0\space\Longleftrightarrow\space x(t)=\dots\tag2$$ Now, according to the answer of @JJacquelin on my previuous question , I could write $x(t)$ as follows: $$t=-l\int_{x_0}^{x(t)}\frac{d\xi}{r\xi+a\ln\left(1+\frac{\xi}{b}\right)}\tag3$$ But I do not see how that can help me find $(1)$ ?!","['integration', 'definite-integrals', 'ordinary-differential-equations', 'physics', 'average']"
3057193,"For a Schwartz function $f$, if $\int_{\mathbb{R}} f(x) x^n dx = 0$ for all nonnegative integers $n$, is $f$ identically 0?","This is an old exam question I'm practicing with. The associated hint is to use the Fourier transform. I'm pretty lost, but here are my thoughts so far. First, in this old stack exchange question a user referenced Classical Fourier Analysis by Loukas Grafakos, which in Prop 2.3.25 defines $S_\infty (\mathbb{R}^n)$ to be a subspace of $S(\mathbb{R}^n)$ such that for $f \in S(\mathbb{R}^n)$ $$\int_{\mathbb{R}^n} x^\alpha f(x) = 0$$ which leads me to think there are non-trivial $f$ in this space. Moreover, as user Jonas Teuwen wrote in the question linked above, the Fourier transform maps the Schwartz function to itself, so the question is equivalently asking whether the Fourier tranform evaluated at $0$ of $\hat{x^\alpha} f(x) = 0$ implies that $f$ is identically $0$ . Since $x^\alpha \mapsto i^\alpha d/dx^\alpha$ , we want $f$ so that $$\frac{d}{dx^{\alpha}} \hat{f(x)} = 0$$ when evaluated at $x = 0$ . But I'm at a loss as to how to construct such a function. Any help or hints would be very much appreciated!","['fourier-transform', 'schwartz-space', 'fourier-analysis', 'functional-analysis']"
3057197,"Prove that $x=0,122112122122...$ is irrational","The Kolakoski sequence $1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, ... $ is an example of what people call a self-reading sequence: ${a_n}$ is defined to be the sequence of $1's$ and $2's$ whose first term is $1$ , and each subsequent term an is the length of the nth run (of ones or twos). In more detail, sequence $1,~~~~~~	2,2,~~~~~~1,1,~~~~~~	2,~~~~~~1,~~~~~~	2,2,~~~~~~	1,~~~~~~	2,2,	...$ run length $1	 ~~~~~~2~~~~~~~~~~~~   2	~~~~~~~~~~~~    1~~~~~~~~ 1~~~~~~~~~~	  2 ~~~~~~~~~	1~~~~~~~~~~~	2$ Start with $a_1 = 1$ . The rule says that the first run (which is a single $1$ ) has length $1$ . Thus $a_2$ must be different, so that $a_2 = 2$ . The second run therefore has length $2$ , which forces the third term, $a_3$ , to be a two also. This completes the second run, so the third run begins with $1$ ; since its length is $2$ we have $a_4 = 1$ and $a_5 = 1$ . The fourth and fifth runs are consequently the singletons $2$ then $1$ . And so on. Prove that $x=0,122112122122...$ is irrational I have the solution but I didn't understand it. The problem reduces itself to prove that Kolakoski sequence isn't periodic. Let's assume for the sake of contradiction that the sequence is periodic , and let $u_n$ be the n-th term of the sequence. That the sequence is periodic means that there exist a period $t$ such that $u_{n+t}=u_n$ , let t be the smallest number that satisfies this property. Let $a$ (resp b) be the number of $i$ ( $0\le i \le t)$ suhthat $u_i=1$ (resp $u_i=2$ ), it is obvious that we have $a+b=t$ . By the definition of the sequence , $a+2b$ is also a period of the sequence , hence $a+b$ divides $a+2b$ because $a+b$ is the smallest period , so $a=0$ or $b=0$ which is impossible . so $x$ is irrational what I didn't understand is why $a+2b$ is also a period of the sequence.","['number-theory', 'sequences-and-series']"
3057214,Euclidean division exercise,"I faced the following problem in a previous abstract algebra session in my university:
Let $\omega$ be a non-zero real number and n be a non-zero natural integer both supposed to be fixed. Calculate the remainder of the Euclidean division of the polynomial $(\cos{\omega}+X\sin{\omega}) ^n$ by $X^2 +1$ . I tried to expand $(\cos{\omega}+X\sin{\omega}) ^n$ but it didn't look helpful for me. Can anyone help?","['abstract-algebra', 'polynomials']"
3057234,Finding parametric equations of the tangent line to a curve of intersection,"The question asks to find the parametric equations of the tangent line to the curve of intersection of the surface $z=2\sqrt{9-\frac{x^2}{2}-y^2}$ and the plane $x=2$ at the point $(2,\sqrt{3},4)$ I've seen solutions to questions similar to this one but they use the gradient notation (the triangle) which I am unfamiliar with. How do you do this question? I was thinking of starting with the partial derivatives w.r.t $x$ and $y$ but I'm not sure where to go from there. Then I thought of ignoring the partial derivative of $x$ since the intersection involves $x=2$ so $x$ is unchanging, so there's that. Thanks!","['multivariable-calculus', 'calculus', 'parametric', 'curves']"
3057245,On the algebraic formulation of the Clifford algebra,"I apologize in advance for a rather wordy question. As a physicist trying to learn new mathematics, I figured this was the place to ask. I am having trouble understanding the algebraic formulation of Clifford algebras and I am (hopefully) looking for some clarity. I will say from the get-go, that my understanding of quotient spaces and ideals are elementary . By this I mean, that I understand the basic definitions at  face-value and some of the simpler examples, though both subjects has always been somewhat confusing to me. So forgive my ignorance in advance. What I understand: Up until now, my understanding of Clifford algebras is the following (I'll be brief and omit details): If $(V,g)$ is a vector space, equipped with a symmetric, bilinear form $g : V \times V \rightarrow \mathbb{F}$ , then the Clifford algebra $\text{C}\ell (V,g)$ of $V$ is the algebra spanned by the elements of $V$ , subject to the condition that $v^2=g(v,v)$ . From this, I can deduce and understand that $\text{C}\ell^{\pm} (\mathbb{R}^n)$ is the algebra generated by the vectors subject to $v_i v_j +v_j v_i = \pm 2 \delta_{ij}$ . I understand also that the Clifford product of any two vectors $u,v$ may be written as $uv=u \cdot v + u \wedge v$ , where $u \cdot v$ is the inner product and $u \wedge v$ is the wedge product. From this, the representations of the various Clifford algebras follows (both in the real and complex cases) and I'm pretty happy. What I don't understand: Now, if  I move on to more advanced texts, I often come across the following: If $T(V)$ is the tensor algebra $T(V) := \bigoplus_{k=0}^{\infty} V^{k \otimes}$ , with $T^0(V) = \mathbb{F}$ , then the Clifford algebra $\text{C}\ell(V,g)$ is the quotient $\text{C}\ell (V,g)=T(V)/I(V)$ of $T(V)$ by the ideal $I(V)$ , generated by the elements of the form $v \otimes u + u \otimes v -2g(u,v)$ . Though I know what all the ingredients are, I simply do not see the correlation between this definition and the more ""geometric"" notion of a Clifford algebra! All my intuitions about the subject are gone. From my (again, very basic) understanding of quotient spaces, $\text{C}\ell (V,g)$ should be the space of equivalence classes, where $u \sim v$ iff $u = v+w$ for some $w \in I(V)$ . Working from the definition of the ideal, I can deduce that $u \otimes v \sim \frac{1}{2}(u\otimes v-v \otimes u)+g(u,v) = u \wedge v + g(u,v)$ , but I cannot get much further and it does not do any wonders for my understanding. I will try to be concrete: Questions: 1) How is the ""algebraic"" definition of the Clifford algebra $\text{C}\ell(V,g)$ (above) related to the concept of the Clifford algebra as the algebra generated by elements in $V$ , subject to the condition that $v^2=g(v,v)$ (in the most general sense)? 2) How does one obtain the Clifford product, now that the Clifford algebra is a space of equivalence classes? 3) Why is this definition of the Clifford algebra ""useful"", as opposed to the geometric formulation?","['algebraic-geometry', 'clifford-algebras']"
3057268,Different ways of proving that $|\sum^{\infty}_{k=1}(1-\cos(1/k))|\leq 2 $,"I've found two ways of proving that \begin{align} \left|\sum^{\infty}_{k=1}\left[1-\cos\left(\dfrac{1}{k}\right)\right]\right|&\leq 2   \end{align} Are there any other ways out there, for proving this? METHOD 1 Let $k\in \Bbb{N}$ , then \begin{align} f:[ 0&,1]\longrightarrow \Bbb{R}\\&x \mapsto 
\cos\left(\dfrac{x}{k}\right)   \end{align} is continuous. Then, by Mean Value Theorem, there exists $c\in [ 0,x]$ such that \begin{align} \cos\left(\dfrac{x}{k}\right)-\cos\left(0\right) =-\dfrac{1}{k}\sin\left(\dfrac{c}{k}\right)\,(x-0), \end{align} which implies \begin{align} \left|\sum^{\infty}_{k=1}\left[1-\cos\left(\dfrac{1}{k}\right)\right]\right| &=\left|\sum^{\infty}_{k=1}\dfrac{x}{k}\sin\left(\dfrac{c}{k}\right)\right| \leq \sum^{\infty}_{k=1}\dfrac{\left|x\right|}{k}\left|\sin\left(\dfrac{c}{k}\right)\right|\leq \sum^{\infty}_{k=1}\dfrac{\left|x\right|}{k}\dfrac{\left|c\right|}{k}\\&\leq \sum^{\infty}_{k=1}\left(\dfrac{\left|x\right|}{k}\right)^2\leq \sum^{\infty}_{k=1}\dfrac{1}{k^2}=1+ \sum^{\infty}_{k=2}\dfrac{1}{k^2}\\&\leq 1+ \sum^{\infty}_{k=2}\dfrac{1}{k(k-1)}\\&= 1+ \lim\limits_{n\to\infty}\sum^{n}_{k=2}\left(\dfrac{1}{k-1}-\dfrac{1}{k}\right)\\&=1+ \lim\limits_{n\to\infty}\left(1-\dfrac{1}{n}\right)\\&=2, \end{align} METHOD 2 Let $x\in [0,1]$ be fixed, then \begin{align} \sum^{\infty}_{k=1}\left[1-\cos\left(\dfrac{1}{k}\right)\right]&=\sum^{\infty}_{k=1}\dfrac{1}{k}\left[-k\cos\left(\dfrac{x}{k}\right)\right]^{1}_{0}=\sum^{\infty}_{k=1}\dfrac{1}{k}\int^{1}_{0}\sin\left(\dfrac{x}{k}\right)dx \\&=\sum^{\infty}_{k=1}\int^{1}_{0}\dfrac{1}{k}\sin\left(\dfrac{x}{k}\right)dx  \end{align} The series $\sum^{\infty}_{k=1}\dfrac{1}{k}\sin\left(\dfrac{x}{k}\right)$ converges uniformly on $[0,1]$ , by Weierstrass-M test, since \begin{align} \left|\sum^{\infty}_{k=1}\dfrac{1}{k}\sin\left(\dfrac{x}{k}\right) \right|\leq \sum^{\infty}_{k=1}\dfrac{1}{k}\left|\sin\left(\dfrac{x}{k}\right) \right|\leq \sum^{\infty}_{k=1}\dfrac{1}{k^2}. \end{align} Hence, \begin{align} \sum^{\infty}_{k=1}\left[1-\cos\left(\dfrac{1}{k}\right)\right]&=\sum^{\infty}_{k=1}\int^{1}_{0}\dfrac{1}{k}\sin\left(\dfrac{x}{k}\right)dx=\int^{1}_{0}\sum^{\infty}_{k=1}\dfrac{1}{k}\sin\left(\dfrac{x}{k}\right)dx,  \end{align} and \begin{align} \left|\sum^{\infty}_{k=1}\left[1-\cos\left(\dfrac{1}{k}\right)\right]\right|&=\left|\int^{1}_{0}\sum^{\infty}_{k=1}\dfrac{1}{k}\sin\left(\dfrac{x}{k}\right)dx\right|\leq\int^{1}_{0}\sum^{\infty}_{k=1}\dfrac{1}{k}\left|\sin\left(\dfrac{x}{k}\right)\right|dx \\&\leq\int^{1}_{0}\sum^{\infty}_{k=1}\dfrac{1}{k^2}dx \\&\leq 2 \end{align}","['convergence-divergence', 'uniform-convergence', 'analysis', 'real-analysis']"
3057278,A Series for $\pi$,"Question: Can we show that $$\sum_{n=0}^\infty(-1)^{n+1}\frac{(2n-3)!!}{(2n+3)!!}=\frac{\pi}{8} $$ ? According to wolfram alpha this result is true . Just amateur curiosity, not sure of a starting point to show if this true.","['calculus', 'pi', 'sequences-and-series']"
3057297,Evaluating $\int_{-\infty}^{\infty}\frac{e^{ax}}{\cosh{x}}dx $ using contour integration,"Let $a \in \mathbb{C}$ with $-1 <$ Re $a < 1$ . By considering a rectangular contour with corners at $R, R + i\pi, -R+ i\pi, -R,$ show that $$\int_{-\infty}^{\infty}\frac{e^{ax}}{\cosh{x}}dx = \pi\sec\left( \frac{\pi a}{2}\right)$$ and hence evaluate, for real $n$ , $$\int_{-\infty}^{\infty}\frac{\cos nx}{\cosh{x}}dx$$ I can do everything in the question except showing that the integrals along the two sides of the rectangle vanish as $R$ tends to infinity. I have these two paths as $\gamma_1(t) = R +it$ for $t\in[0,\pi]$ and $\gamma_2(t) = -R + (\pi-t)i$ for $t\in[0,\pi]$ . I'm pretty sure these are right, but I really can't see how the integral of $\frac{e^{az}}{\cosh{z}}$ goes to zero when you integrate along these. I'd really appreciate whatever help you could offer.","['integration', 'analysis', 'complex-analysis', 'contour-integration', 'residue-calculus']"
3057298,Solving used Real Based Methods: $\int_0^x \frac{t^k}{\left(t^n + a\right)^m}\:dt$,"In working on integrals for the past couple of months, I've come across different cases of the following integral: \begin{equation}
I\left(x,a,k,n,m\right) = \int_0^x \frac{t^k}{\left(t^n + a\right)^m}\:dt
\end{equation} Where $x,a\in \mathbb{R}^{+}$ . Here the method that I've taken is rather simple and I was curious as to other 'Real' Based methods could be employed with this integral? I also believe that with the conditions I've set on the parameters that it is convergent. If I'm able to expand those conditions, could you please advise. Interested in special cases too! The method I took: First I wanted to bring the 'a' out the front: \begin{equation}
I(x,a,k,n,m) =  \int_0^x \frac{t^k}{\left(a\left[\left(a^{-\frac{1}{n}}t\right)^n + 1\right]\right)^m}\:dt = \frac{1}{a^m} \int_0^x \frac{t^k}{\left(\left(a^{-\frac{1}{n}}t\right)^n + 1\right)^m}\:dt
\end{equation} Here let $u = a^{-\frac{1}{n}}t$ Thus, \begin{equation}
 I(x,a,k,n,m) = \frac{1}{a^m} \int_0^{a^{-\frac{1}{n}}x} \frac{\left(a^{\frac{1}{n}}u\right)^k}{\left(u^n + 1\right)^m}a^{\frac{1}{n}}\:du = a^{\frac{k + 1}{n} - m}\int_0^{a^{-\frac{1}{n}}x} \frac{u^k}{\left(u^n + 1\right)^m}\:du = a^{\frac{k + 1}{n} - m}I(a^{-\frac{1}{n}}x,1,k,n,m)
\end{equation} From here I will use $I$ in place of $I(x,a,k,n,m)$ for ease of typing. The next step is to make the substitution $w = u^n$ to yield: \begin{equation}
 I = a^{\frac{k + 1}{n} - m}\int_0^{ax^n} \frac{w^\frac{k}{n}}{\left(w + 1\right)^m}\frac{\:dw}{nw^{\frac{n - 1}{n}}} = \frac{1}{n}a^{\frac{k + 1}{n} - m}\int_0^{ax^n} \frac{w^{\frac{k + 1}{n} - 1}}{\left(w + 1\right)^m}\:dw
\end{equation} Here make the substitution $z = \frac{1}{1 + w}$ to yield: \begin{align}
I &= \frac{1}{n}a^{\frac{k + 1}{n} - m}\int_1^{\frac{1}{1 + ax^n}} z^m \left(\frac{1 - z}{z}\right)^{\frac{k + 1}{n} - 1}\left(-\frac{1}{z^2}\right) \:dz = \frac{1}{n}a^{\frac{k + 1}{n} - m}\int_{\frac{1}{1 + ax^n}}^1 z^{m - \frac{k + 1}{n} - 1}\left(1 - z\right)^{\frac{k + 1}{n} - 1}\:dz \\
&= \frac{1}{n}a^{\frac{k + 1}{n} - m} \left[\int_0^1 z^{m - \frac{k + 1}{n} - 1}\left(1 - z\right)^{\frac{k + 1}{n} - 1}\:dz - \int_0^{\frac{1}{1 + ax^n}} z^{m - \frac{k + 1}{n} - 1}\left(1 - z\right)^{\frac{k + 1}{n} - 1}\:dz \ \right] \\
&= \frac{1}{n}a^{\frac{k + 1}{n} - m} \left[B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n}\right) -  B\left( \frac{1}{1 + ax^n}; m - \frac{k + 1}{n}, \frac{k + 1}{n}  \right)\right]
\end{align} Where $B(a,b)$ is the Beta Function and $B(x; a,b)$ is the Incomplete Beta Function . And so, we arrive at: \begin{equation}
 \int_0^x \frac{t^k}{\left(t^n + a\right)^m}\:dt = \frac{1}{n}a^{\frac{k + 1}{n} - m} \left[B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n}\right) -  B\left(\frac{1}{1 + ax^n}; m - \frac{k + 1}{n}, \frac{k + 1}{n}  \right)\right]
\end{equation} Here we observe that for convergence: \begin{equation}
 m - \frac{k + 1}{n} \gt 0,\quad  \frac{k + 1}{n} \gt 0,\quad n \neq 0
\end{equation} Note: when $x \rightarrow \infty$ we have: \begin{equation}
 \int_0^\infty \frac{t^k}{\left(t^n + a\right)^m}\:dt = \frac{1}{n}a^{\frac{k + 1}{n} - m} B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n}\right) 
\end{equation} Update: Today I realised that we can use this result for another integral: \begin{equation}
 \int_0^\infty \frac{\ln(t)}{\left(t^n + 1\right)^m}\:dt
\end{equation} This is achieved through a simple use of Feynman's Trick. Here we  consider the case when $x \rightarrow \infty$ and $a = 1$ . We see that \begin{align}
\frac{d}{dk}\left[ \int_0^\infty \frac{t^k}{\left(t^n + 1\right)^m}\:dt \right]&= \frac{d}{dk}\left[\frac{1}{n}B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n} \right)\right] \\
 \int_0^\infty \frac{t^k \ln(t)}{\left(t^n + 1\right)^m}\:dt &= \frac{1}{n^2}B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n} \right)\left[\psi^{(0)}\left(\frac{k + 1}{n}\right) - \psi^{(0)}\left(m - \frac{k + 1}{n}\right) \right]
\end{align} Thus, \begin{equation}
\lim_{k \rightarrow 0} \int_0^\infty \frac{t^k \ln(t)}{\left(t^n + 1\right)^m}\:dt = \lim_{k \rightarrow 0}\frac{1}{n^2}B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n} \right)\left[\psi^{(0)}\left(\frac{k + 1}{n}\right) - \psi^{(0)}\left(m - \frac{k + 1}{n}\right) \right]
\end{equation} And finally: \begin{equation}
 \int_0^\infty \frac{ \ln(t)}{\left(t^n + 1\right)^m}\:dt = \frac{1}{n^2}B\left(m - \frac{1}{n}, \frac{1}{n} \right)\left[\psi^{(0)}\left(\frac{1}{n}\right) - \psi^{(0)}\left(m - \frac{1}{n}\right) \right]
\end{equation} Note: In the case where $m = 1$ we arrive: \begin{align}
 \int_0^\infty \frac{ \ln(t)}{\left(t^n + 1\right)^1}\:dt &= \frac{1}{n^2}B\left(1 - \frac{1}{n}, \frac{1}{n} \right)\left[\psi^{(0)}\left(\frac{1}{n}\right) - \psi^{(0)}\left(1 - \frac{1}{n}\right) \right] \\
&= \frac{1}{n^2} \Gamma\left(\frac{1}{n} \right)\Gamma\left(1 - \frac{1}{n} \right) \cdot -\pi\cot\left(\frac{\pi}{n}\right) \\
&= \frac{1}{n^2} \frac{\pi}{\sin\left(\frac{\pi}{n}\right)}\cdot -\pi\cot\left(\frac{\pi}{n}\right)
\end{align} Thus: \begin{equation}
 \int_0^\infty \frac{ \ln(t)}{t^n + 1}\:dt = -\frac{\pi^2}{n^2} \operatorname{cosec}\left(\frac{\pi}{n} \right)\cot\left(\frac{\pi}{n}\right)
\end{equation}","['integration', 'beta-function', 'definite-integrals', 'real-analysis']"
3057312,Definition of conjugate momentum on a manifold,"I have trouble understanding this definition: Let $Q$ be some manifold and $L: TQ \to \mathbb{R}$ a smooth function. Then for some local coordinates $(q, \dot{q})$ on $TQ$ the conjugated momentum is defined as $\frac{\partial L}{\partial \dot{q}}$ , which is an element of the co-tangential bundle $T^{*}Q$ . How is the expression $\frac{\partial L}{\partial \dot{q}}$ to be interpreted? If one simply expresses $L$ in local coordinates by $$L \circ(q^{-1}, \dot{q}^{-1}): \mathbb{R}^{2n} \to \mathbb{R}$$ and differentiates it with respect to the second variable one gets a function $\mathbb{R}^n \to \mathbb{R}$ and not an element of the co-tangential bundle $T^{*}Q$ . Is the correct expression $$\partial_2 ( L \circ(q^{-1}, \dot{q}^{-1}))\circ (q, \dot{q}) \in T^{*}Q\ ?$$","['classical-mechanics', 'manifolds', 'differential-topology', 'mathematical-physics', 'differential-geometry']"
3057320,Set-theoretic difficulties concerning normality,"In her ""Lectures on Set Theoretic Topology"" Mary Ellen Rudin states at the end of page 5 that ""In the case on nomality this is made doubly difficult by the fact that normality is such a second order property that it can often not be decided whether a given topological space is normal or not within the usual axioms for set theory."" What does it means ""nomality is such a second order property""? And why this is a particularity of normality? The regularity isn't a second order property? Is it possible to define a topological space in ZFC such that it is undecidable wheter this space is normal or not?","['general-topology', 'logic']"
3057339,Every perfect set has cardinality $2^{\aleph_0}$?,"It is well known that perfect sets in $\mathbb{R}^n$ are uncountable (e.g., baby Rudin states this). Recently I heard of this stronger result: Every perfect set in $\mathbb{R}^n$ has cardinality $2^{\aleph_0}$ . This is easily proved if we assume the continuum hypothesis. However, this result does not rely on that. Is there a proof of this fact? And does this result hold for more general spaces (e.g., complete metric spaces)? I understand that it's customary to show my effort here at math.SE, but honestly I have no idea how I should attempt at it...","['general-topology', 'descriptive-set-theory']"
3057355,Sequential compactness $\rightarrow$ limit point compactness and axiom of choice,"A space $S$ is sequentially compact if every sequence has a convergent subsequence. A space $S$ is limit point compact is every infinite subset has a limit point in $S$ . Proving sequential compactness implies limit point compactness more or less involves letting $E \subset S$ be infinite and extracting a countably infinite subset from $E$ , which we can then view as a sequence. What the convergent subsequence converges to will be the limit point. However, the claim that an arbitrary infinite set has a countably infinite subset is dependent on the axiom of choice. Does sequentially compact $\to $ limit point compact still hold without choice? Can my proof above be modified so that choice isn't needed?","['axiom-of-choice', 'general-topology', 'compactness']"
3057357,Infinite Noetherian ring of dimension $1$ in which distinct non-zero ideals have distinct and finite index,"Let $R$ be an infinite commutative ring with unity such that every non-zero ideal has finite index. Then $R$ is Noetherian, every non-zero prime ideal is maximal , and I can also show that $R$ is an integral domain.  Now also assume that  distinct ideals have distinct index; then is it true that $R$ is a UFD, or at least normal (integrally closed in its fraction field) ? (note: $\dim R \le 1$ , now if $\dim R=0$ , then $R$ is an Artinian domain, so a field. So w.l.o.g., assume $R$ has dimension $1$ )","['dimension-theory-algebra', 'ring-theory', 'algebraic-geometry', 'integral-extensions', 'commutative-algebra']"
3057367,$F:M\to N$ is surjective if $\int_M F^* \eta \ne 0$ for some $\eta \in \Omega^n(N)$,"Let $M$ and $N$ be compact orientable and connected smooth $n$ -manifolds and $F:M \to N$ a smooth map. Suppose $$\int_M F^* \eta \ne 0$$ for some $\eta \in \Omega^n(N)$ . Then $F$ is surjective. Give an example that shows the converse is not true. A non-surjective map has degree $0$ so the first part is clear. I could not think of an example for the converse, however. I want to find two compact oriented connected manifolds such that $F$ is surjective but $\int_M F^* \eta = 0$ for all $\eta \in \Omega^n(N)$ .","['de-rham-cohomology', 'smooth-manifolds', 'differential-geometry']"
3057382,Equivalence of two definitions of simple connectedness.,"I am an undergraduate in mathematics, self-studying complex analysis. In Bak, Newman - Complex Analysis , there is the following definition: An open connected set $D \subset \mathbb{C}$ is simply connected if its complement is ""connected within $\epsilon$ to $\infty$ "". That is, for any $z_0 \in \mathbb{C}-D$ and $\epsilon>0$ , there exists a continuous curve $\gamma :[0,\infty) \rightarrow \mathbb{C}$ such that (a) $d(\gamma(t), \mathbb{C}-D) <\epsilon $ for all $t \geq 0$ , (b) $\gamma(0)= z_0$ , (c) $\lim _{t\rightarrow \infty} \gamma(t) = \infty$ . I blowed up my mind, since in my topology class I learned the following definition: A simply connected space is a path-connected space whose fundamental group vanish. How can I prove that these two seemingly very different definitions are actually equivalent(if it is indeed equivalent)?","['complex-analysis', 'general-topology', 'algebraic-topology']"
3057402,Can different topological spaces have the same square?,"For topological spaces $X$ and $Y$ , is it possible that $X \times X$ and $Y \times Y$ are homeomorphic, but $X$ and $Y$ are not homeomorphic? (I poked around with finite spaces, and manifolds, and the Cantor set, without seeing any examples.) This was inspired by Existence of topological space which has no “square-root” but whose “cube” has a “square-root” . Cartesian product makes the proper class of topological spaces (up to homeomorphism) into a large abelian monoid, so here's a bonus question: what is known about the structure of this monoid? For example, the dogbone space shows that it is not cancellative. Does it have torsion in the sense that sometimes $X^n \not\cong X$ but $X^{n + 1} \cong X$ ?",['general-topology']
3057441,Proof of an inequality for a function $f$ in the Hilbert space,"Prove that for any $ f \in H^1(0,\pi)$ : \begin{equation}
\int_0^\pi f^2 dx \leq \int_0^\pi \left(f'\right)^2 dx + \left(\int_0^\pi f dx\right)^2
\end{equation} $H$ is the Hilbert space. 1 means that the 1st (weak) derivative exists. I am thinking of applying some inequalities involving $L^2$ norms, such as Hoelder, but right now I can't think of a way to make it work.
A further hint would be greatly appreciated!","['real-analysis', 'hilbert-spaces', 'functional-analysis', 'partial-differential-equations', 'inequality']"
3057446,"$L^1$ norm equivalent to weak topology of $W^{1,1}$?","Let's consider a weakly compact set $S\subset W^{1,1}(\Omega)$ , where $\Omega$ is a domain in $\Bbb R^m$ with smooth boundary. It turns out that $(S,w)$ is metrizable. Is the topology induced by the metric $d(u,v):=\int_{\Omega} |u(x)-v(x)|\, dx$ on $S$ equivalent to the weak topology $(S,w)$ that $S$ inherits from $W^{1,1}$ ? We know that the map $T:(S,w)\to L^1(\Omega)$ defined by $$
Tu:=u
$$ is a bijection from a compact space into a Hausdorff space, hence if we manage to show continuity of $T$ then $T$ is a homeomorphism onto its image. An element $u\in S$ can be identified with $(u,\nabla u)\in L^1(\Omega;\Bbb R\times \Bbb R^m)$ so we can view $T$ as a projection of the first coordinate. It is clearly continuous but I don't know if it is weakly continuous or not. Am I missing something obvious or is the statement simply not true?","['real-analysis', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations', 'general-topology']"
3057450,Does the constant $C$ in this solution to a differential equation equal infinity?,"The problem is $y' = -\frac{1}{t^2} - \frac{1}{t}y + y^2;\ y_p = \frac{1}{t}$ .  My solution is $$\begin{align}
y = \frac{1}{t} + B &\implies y' = -\frac{1}{t^2} + B' \\
&\implies -\frac{1}{t^2} - \frac{1}{t}y + y^2 = -\frac{1}{t^2} + B' \\
&\implies -\frac{1}{t^2} - \frac{1}{t} \left(\frac{1}{t} + B \right) + \left(\frac{1}{t} + B\right)^2 = -\frac{1}{t^2} + B' \\
&\implies B' - \frac{1}{t}B = B^2 \\
&\implies L = B^{-1} \\
&\implies L' = -B^{-2} \left(B^2 + \frac{1}{t}B \right) \\
&\implies L' + \frac{1}{tB} = -1 \\
&\implies L' + \frac{1}{t}L = -1 \\
&\implies L_h = \frac{1}{t} \\
&\implies L = \frac{1}{t}\int\frac{-1}{\frac{1}{t}}dt \\
&\implies L = \frac{1}{t} \left(-\frac{1}{2}t^2 + C_{tentative} \right) \\
&\implies L = \frac{C - t^2}{2t} \\
&\implies B = \frac{2t}{C - t^2} \\
&\implies y = \frac{1}{t} + \frac{2t}{C - t^2}
\end{align}$$ Although this solution does not appear equivalent to the answer given in my book, one or two people in chat reviewed this work and could not see anything incorrect.  The issue is that the given particular solution, $y_p = \frac{1}{t}$ , cannot be obtained by plugging any finite value into the $C$ in my general solution.  We could say that the general solution yields the given particular solution when $C =$ infinity, more specifically, when $C =$ some $\aleph$ expression which makes the term $\frac{2t}{C - t^2}$ disappear regardless of $t$ , but this feels a bit outside the box for a textbook problem.  Is my general solution correct, and if so, how if at all can we derive the given particular solution from it?","['ordinary-differential-equations', 'proof-verification', 'substitution', 'infinity', 'constants']"
3057451,a.c.c. and d.c.c. on radical ideals in commutative ring of dimension zero,"Let $R$ be a commutative ring with unity of dimension zero (i.e. every prime ideal is maximal). Does any of the following two conditions imply the other : 1) $R$ satisfies a.c.c. on radical ideals 2) $R$ satisfies d.c.c. on radical ideals ?? Motivation: For a zero dimensional ring, Artinian is equivalent to Noetherian ... now a.c.c. (resp. d.c.c. ) on radical ideals is same as saying the prime spectrum with Zariski topology is Noetherian (resp. Artinian) , where we mean a topological space to be Noetherian (resp. Artinian) iff a.c.c. (resp. d.c.c.) holds on open sets ... hence the question","['commutative-algebra', 'ring-theory', 'algebraic-geometry', 'ideals', 'dimension-theory-algebra']"
3057465,"If $p$ is prime, then $x^2 +5y^2 = p \iff p\equiv 1,9 $ mod $(20)$.","Let $p\neq 2,5$ be prime. I wish to show that: $x^2 +5y^2 = p \Leftrightarrow p\equiv 1,9 $ mod $(20)$ . I proved to $\Rightarrow$ part, means $x^2 +5y^2=p \Rightarrow p\equiv 1,9 $ mod $(20)$ . For $\Leftarrow$ , $p\equiv 1,9(20) \Rightarrow p\equiv 1(4)$ , $p\equiv1 ,4 (5)$ thus $(\frac{4}{p})=1,(\frac{-1}{p}) =1$ (using legendre symbols) , also $(\frac{5}{p})=_{p\equiv1(4)}(\frac{p}{5})$ and $p\equiv1(5)$ so $(\frac{5}{p})=1$ , so $(\frac{-20}{p})=(\frac{5}{p})(\frac{4}{p})(\frac{-1}{p}) = 1$ . So $-20$ is a quadratic residue mod $p$ . Yet I don't succeed to go on from this point (I don't know even if its possible to do so).","['algebraic-number-theory', 'number-theory', 'elementary-number-theory', 'quadratic-residues', 'quadratic-forms']"
3057471,Rotation of axes by 45 degrees,"I was reading a book in which it is mentioned that: Rotate coordinate axes by $45$ degrees so that a point $(x,y)$ becomes $(x+y,y-x)$ . Here is image 1 Here is image 2 I can't understand how the new coordinates became $(x+y,y-x)$ .
If I apply the formula for rotation of axes I'll get $\sqrt{2}$ $(x-y, x+y) $ .","['geometry', 'rotations']"
3057481,Solution of Diophantine Equation $1+a^6=x^2$,"Does the equation $1+a^6=x^2$ have any other integer solutions except the trivial one $a=0,x=1$ ?","['number-theory', 'diophantine-equations']"
3057503,The meaning of **homomorphic preimage **,"We are working on commutative Ring Theory and their modules. While studying a paper, we saw the concept ""homomorphic preimage of an $R$ -module"". I want to know the meaning of this.","['abstract-algebra', 'modules']"
3057514,Second Order Matrix ODE,"Given the equation $\frac{d^2X}{dt^2} = MX$ and the appropriate initial values, how would one go about solving this equation? 
I've looked at Qualitative dependence of solution to second-order matrix differential equation on eigenvalues , which was very useful but I don't really understand how the change of basis was performed nor how the eigenvalues could be found. Are there any resources that explain how to tackle second order matrix equations out there?","['matrices', 'ordinary-differential-equations']"
3057541,Regarding $|\textrm{G}| = 65$ $\Rightarrow$ $\textrm{G}$ is cyclic.,"I am proving that a group of order $\textrm {G}$ being 65 would imply that $\textrm {G}$ is cyclic, using Lagrange's Theorem and $N \textrm{by} C$ Theorem. Clearly, one can show that not all non-identity elements in $\textrm{G}$ would have order 13. But I have difficulty in proving that not all non-identity elements in $\textrm{G}$ would have order 5 either. Assuming that  all non-identity elements in $\textrm{G}$ have order 5, the following statement can be concluded: 1) Every non-trivial, proper subgroup of $\textrm{G}$ is a cyclic group of order 5. 2) None of those groups will be normal subgroups of $\textrm{G}$ ; otherwise it will imply that $\textrm{G}$ will have a subgroup of order 25 which is not possible since $|\textrm{G}| = 65$ . 3) Index of every non-trivial, proper subgroup of $\textrm{G}$ will be 13. My hunch is that point (3) would possibly show that $\textrm{G}$ doesn't have every non-identity element of order 5. But I have difficulty in showing that given any non-trivial, proper subgroup, I can  construct more than 13 coset of that subgroup. Or is their any other fact that I'm missing.","['group-theory', 'abstract-algebra', 'finite-groups', 'cyclic-groups']"
3057551,Understanding Variance-Covariance Matrix,Suppose data set is expressed by the matrix $X \in\mathbb R^{n \times d}$ where $n =$ Number of samples and $d =$ dimension/features of each sample Then what does $\operatorname{Cov}(X) \in\mathbb R^{d \times d}$ (Variance-Covariance matrix of $X$ ) represent. Does below interpretation would be right Variance-Covariance matrix of $X$ represents covariance between every pair of dimension/feature for all samples.,"['matrices', 'covariance', 'linear-algebra']"
3057601,What does the Stieltjes integral represent? Can it be seen as an area?,"The Stieltjes integral of $f$ w.r.t. $g$ is $$\int_0^T f(t)\,\mathrm dg(t)=\lim_{n\to \infty }\sum_{i=0}^{n-1} f(t_i)(g(x_{i+1})-g(x_i)),$$ where $t_i\in [x_i,x_{i+1}]$ and $\{x_0,...,x_n\}$ is a partition of $[0,T]$ . What does it represent concretely ? Can it be seen as an area ? I see it often, but I don't see in what this integral is worth. For example, what could represent $$\int_0^1 x\,\mathrm d x^2 \ \ ?$$ (despite the fact that it's equal to $\int_0^1 2x^2\,\mathrm d x$ )","['integration', 'real-analysis']"
3057630,Calculation of Christoffel symbol for unit sphere,"We use the following parameterisation for the unit sphere: $\sigma(\theta,\phi)=(\cos\theta\cos\phi,\cos\theta\sin\phi,\sin\theta)$ .
I have calculated the Christoffel symbols to be $\Gamma^1_{11}=\Gamma^2_{11}=\Gamma^1_{12}=0, \Gamma^1_{22}=\sin\theta\cos\theta,\Gamma^2_{22}=0$ , which match the answers I am given in my notes. But when I calculate $\Gamma^2_{12}$ I get $-\sin\theta\cos\theta$ , which apparently is incorrect and should be $-\tan\theta$ . My reasoning was that $\Gamma^2_{12}=\sigma_\phi \cdot \sigma_{\theta\phi}=(-\cos\theta\sin\phi,\cos\theta\cos\phi,0)\cdot(\sin\theta\sin\phi,-\sin\theta\cos\phi,0)=-\sin\theta\cos\theta$ . I am not sure what I am doing wrong - the same method worked for the other five symbols and I have no idea where a $\tan\theta$ term would come from. Any help would be appreciated.","['parametrization', 'differential-geometry']"
3057644,Why SVD is not unique but the Moore-Penrose pseudo inverse is unique?,"I feel confused about the uniqueness of the Moore-Penrose inverse generated from SVD.
For any matrix $A$ , if $X$ satisfied $$AXA=A, XAX=X, (AX)^\mathrm{T}=AX, (XA)^\mathrm{T}=XA $$ then $X$ is called the Moore-Penrose inverse of $A$ . If $A$ has the SVD(singular value decomposition) $$A=P\left[\begin{matrix}\Lambda_r&0\\0&0\end{matrix}\right]Q^\mathrm{T}$$ then it is easy to prove that $$A^+ = Q\left[\begin{matrix}\Lambda_r^{-1}&0\\0&0\end{matrix}\right]P^\mathrm{T}$$ is a Moore-Penrose inverse. If $X$ and $Y$ are both Moore-Penrose inverse of $A$ , from the equation $$X=XAX=X(AX)^\mathrm{T}=XX^\mathrm{T}A^\mathrm{T}=XX^\mathrm{T}(AYA)^\mathrm{T}=X(AX)^\mathrm{T}(AY)^\mathrm{T}=(XAX)AY=XAY=(XA)^\mathrm{T}YAY=A^\mathrm{T}X^\mathrm{T}A^\mathrm{T}Y^\mathrm{T}Y=A^\mathrm{T}Y^\mathrm{T}Y=(YA)^\mathrm{T}Y=YAY=Y$$ we can see that the Moore-Penrose inverse is unique. However, the Moore-Penrose inverse depends on the SVD and SVD is not unique. How to explain it?","['svd', 'matrices', 'pseudoinverse', 'linear-algebra', 'matrix-decomposition']"
3057656,derivative of logarithm of determinant,"I am trying to read ""pattern recognition and machine learning"" and in the appendix there is a forumla with no proof. The author suggest to solve the following formula using the given four formulas given below. $\lambda_i$ and $u_i$ are eigen values and eigen vectors respectively. Any hint as to how to tackle this proof. Most proof on the internet use Jacobi's formula. The book is available online: http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf Trying to prove C.22. $$\frac { \partial } { \partial x } \ln | \mathbf { A } | = \operatorname { Tr } \left( \mathbf { A } ^ { - 1 } \frac { \partial \mathbf { A } } { \partial x } \right)$$ $\mathbf { u } _ { i } ^ { \mathrm { T } } \mathbf { u } _ { j } = I _ { i j }$ $ \mathbf { A } = \sum _ { i = 1 } ^ { M } \lambda _ { i } \mathbf { u } _ { i } \mathbf { u } _ { i } ^ { \mathrm { T } } $ $ \mathbf { A } ^ { - 1 } = \sum _ { i = 1 } ^ { M } \frac { 1 } { \lambda _ { i } } \mathbf { u } _ { i } \mathbf { u } _ { i } ^ { \mathrm { T } } $ $ | \mathbf { A } | = \prod _ { i = 1 } ^ { M } \lambda _ { i } $","['multivariable-calculus', 'matrix-calculus', 'linear-algebra']"
3057659,using Poincaré-Bendixon to prove periodic solution existence,"I got the system: $$\dot{x} = x-y-y^3-2x(x^2+y^2)$$ $$\dot{y}= x+y-2y(x^2+y^2)$$ And it's given that the origin is the only fixed point. 
I've converted it to Polar using $\dot{r}r=\dot{x}x+\dot{y}y$ and ended up with: $$r\dot{r}=r^2-2r^3-r^4\cos\theta \sin^3\theta $$ Which I have simplified to the following but I do not trust my trig within this. $$\dot{r}=r-2r^2-\frac{r^3}{4}(\sin2\theta-\frac{1}{2}\sin4\theta)$$ I'm not very sure if this was the right way to go because when it comes to classifying $\dot{r}$ now I have to deal with $\sin2\theta$ and $\sin4\theta$ . So I guess my question right now is did I end up with the correct $\dot{r}$ ? If yes how do I end up trapping the region in this situation? I know that I have to check for when $\dot{r}>0$ for the outward flow and $\dot{r}<0$ for the inward flow. But I do not know how to inspect that with both $\sin{2\theta}$ and $\sin{4\theta}$ present at the same time. My brain right now is a scattered mess and I do not trust anything that comes out of it so I have resorted to share this with you and hopefully someone can put my mind to rest and let me know where I am going wrong because I have tried to solve this question 4 times now and every time I get a different $\dot{r}$ .","['systems-of-equations', 'ordinary-differential-equations']"
3057692,Show monotonicity of solution of Delayed Differential Equation with respect to a parameter,"Short Description of the General Question Suppose we have some Delayed Differential Equation (DDE) which depends on a parameter $a$ , $x_a'(t)=f(a,x_a(t),x_a(t-s))$ for some fixed $a$ and $s$ . I would like to prove that $x_a(t)$ is increasing in $a$ . I.e. if we have $a<b$ and $x_a'(t) = f(a,x_a(t),x_a(t-s))$ and $x_b'(t)=f(b,x_b(t),x_b(t-s))$ then $x_a(t) \leq x_b(t)$ for all $t$ . Specific Scenario Consider the following Delayed Differential Equation: \begin{align*}
x_a(0) &= a\\
x_a'(t) &= - a (1 - x_a(t)^2) & t \leq 1\\
x_a'(t) &= -a(x_a(t-1)^2 - x_a(t)^2) & t > 1.
\end{align*} I have found numerically that for all $a \in (0,1)$ we have: $$
a \leq b \Rightarrow x_a(t) \leq x_b(t),
$$ but I am unable to prove this statement. I can solve the ODE in $[0,1]$ exactly, thus on this interval it is easily verified that $x_a(t) \leq x_b(t)$ . I then use that solution to find a solution on $[1,2]$ and so on. But as $t$ grows large we can't find an exact solution anymore.","['calculus', 'delay-differential-equations', 'ordinary-differential-equations', 'real-analysis']"
3057710,Calculate $\lim\limits_{ x\to + \infty}x\cdot \sin(\sqrt{x^{2}+3}-\sqrt{x^{2}+2})$,"I know that $$\lim\limits_{  x\to + \infty}x\cdot \sin(\sqrt{x^{2}+3}-\sqrt{x^{2}+2})\\=\lim\limits_{  x\to + \infty}x\cdot \sin\left(\frac{1}{\sqrt{x^{2}+3}+\sqrt{x^{2}+2}}\right).$$ If $x \rightarrow + \infty$ , then $\sin\left(\frac{1}{\sqrt{x^{2}+3}+\sqrt{x^{2}+2}}\right)\rightarrow \sin0 $ . However I have also $x$ before $\sin x$ and I don't know how to calculate it.","['limits', 'real-analysis']"
3057745,Probability distribution vs. probability mass function (PMF): what is the difference between the terms? [duplicate],"This question already has answers here : Concept of Probability distribution (3 answers) Closed 2 years ago . Consider a discrete case. PMF is the probability each value of random variable gets. So, for example, X ~ Poisson(2). I plot these probabilities (below), so I can say that I show the PMF of X. But on the other hand I show the distribution of X. For example, I can say whether the distribution I have is symmetrical or not. So, what is the difference between probability distribution and PMF terms (in discrete case)? Below I also bring the definitions from Wikipedia, but it is not helpful either. Many thanks! A probability mass function (pmf) is a function that gives the probability that a discrete random variable is exactly equal to some value. A probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment.","['probability-distributions', 'probability', 'terminology']"
3057802,Deck transformation group in algebraic geometry,"Let $f:X\to Y$ be a finite morphism between (irreducible) varieties. We can define $\operatorname{Aut}(X/Y)$ to be the automorphism of $X$ commutes with $f$ . For the case over $\mathbb C$ , we can also define the monodromy group $G$ to be the image of the monodromy action. My question is Is it true that $G\cong \operatorname{Aut}(X/Y)$ ? I know this is true in the topological setting (edit: should be ""in the birational setting"" or ""on the unramified part"") and also the case of dimension one. So the question is, if the monodromy data, say the monodromy action of some loop, determines a morphism $X \to X$ in general? Edit: I tend to believe this is not true. Assume it is, then for any finite morphism of degree $d>1$ , there exists some nontrivial automorphism $g:X\to X$ which preserves the fiber. This might be a way to construct counter-examples.","['automorphism-group', 'algebraic-geometry', 'covering-spaces', 'reference-request']"
3057838,How to classify $\mathbb N^2$-orbits?,"I'm sure the answer to this question is well-known, but I don't know how to search for it. Neither do I know how to tag the question. Feel free to retag it! Or to mark it as a duplicate! Say that an $\mathbb N$ -set is a set $X$ together with an endomap $s:X\to X$ . The notion of isomorphism of $\mathbb N$ -sets is the obvious one. Given a point $x$ of an $\mathbb N$ -set $X$ , say that the orbit of $x$ is $$
\{s^n(x)\ |\ n\in\mathbb N\}.
$$ This is a sub- $\mathbb N$ -set of $X$ . Say that the orbits of $x\in X$ and of $y\in Y$ are isomorphic if there is an isomorphism from the first to the second mapping $x$ to $y$ . The $\mathbb N$ -orbits are easily classified up to isomorphism, and there is an obvious analog of the above definitions with $\mathbb N^2$ instead of $\mathbb N$ . My question is How to classify $\mathbb N^2$ -orbits? Edit An $\mathbb N^2$ -set is a set equipped with two commuting endomaps. Here is the classification of $\mathbb N$ -orbits up to isomorphism I'd like to generalize to $\mathbb N^2$ -orbits: I'll give examples of $\mathbb N$ -orbits, and claim that any $\mathbb N$ -orbit is isomorphic to exactly one of the examples. The first example is $\mathbb N$ itself viewed as the orbit of $0$ under the standard successor map $n\mapsto n+1$ . The other examples are finite, and come as a two parameter family. Set $X:=\{x_0,\dots,x_n\}$ with $n\ge0$ , let $k$ be an integer such that $0\le k\le n$ , and define $s:X\to X$ by $s(x_0)=x_1,\dots,s(x_{n-1})=x_n,s(x_n)=x_k$ . (Such an orbit resembles the letter P - or the letter O if $k=0$ .) Let $Y$ be an orbit starting with $y\in Y$ . If $Y$ is infinite, $(Y,y)$ is isomorphic to $(\mathbb N,0)$ with the usual successor map. If $Y$ is finite, there is a unique $(k,n)\in\mathbb N^2$ such that $(Y,y)$ is isomorphic to the orbit $(X,x_0)$ described above. The verification is left to the reader.","['monoid', 'category-theory', 'reference-request', 'combinatorics', 'elementary-set-theory']"
3057853,Evaluate $\sum\limits_{n=0}^{\infty}(-1)^n\sum\limits_{j=0}^{k}{k \choose j}\frac{(-1)^j}{2n+2j+1}$,"Evaluate $g(k)$ if $\sum\limits_{n=0}^{\infty}(-1)^n\sum\limits_{j=0}^{k}{k \choose j}\frac{(-1)^j}{2n+2j+1}=\frac{\pi}{2^{2-k}}+g(k)$ . The well-known Gregory Series , $$\sum_{n=0}^{\infty}\frac{(-1)^n}{2n+1}=\frac{\pi}{4}\tag1$$ Let us generalize $(1)$ in terms of binomial coefficients ${k \choose j}$ , Where $k\ge0$ $$\sum_{n=0}^{\infty}(-1)^n\sum_{j=0}^{k}{k \choose j}\frac{(-1)^j}{2n+2j+1}=\frac{\pi}{2^{2-k}}+g(k)\tag2$$ Expand $(2)$ for $k=1,2$ and $3$ , $$\sum_{n=0}^{\infty}(-1)^n\left(\frac{1}{2n+1}-\frac{1}{2n+3}\right)=\frac{\pi}{2}-1\tag3$$ $$\sum_{n=0}^{\infty}(-1)^n\left(\frac{1}{2n+1}-2\frac{1}{2n+3}+\frac{1}{2n+5}\right)=\pi-\frac{8}{3}\tag4$$ $$\sum_{n=0}^{\infty}(-1)^n\left(\frac{1}{2n+1}-\frac{3}{2n+3}+\frac{3}{2n+5}-\frac{1}{2n+5}\right)=2\pi-\frac{88}{15}\tag5$$ The pattern for $g(k)$ is not so obvious, I was not able to determine the closed form $g(k)$ Q: How can we find the closed form for $(2)?$",['sequences-and-series']
3057860,Arbitrary close and norm-bounded approximations to an element in a Banach space from a dense subset,"I have an element $e \in E$ , where $E$ is a Banach space, and $\lVert e\rVert=l$ . I also have a subset $Y$ which is dense in $E$ . Does this mean that we can find element $y\in Y$ s.t. $\lVert y - e\rVert \le \frac{l}{2}$ and $\lVert y\rVert \le l$ ? If so, why? I have the feeling that a Banach space is like the Euclidean space $\mathbf R^n$ so to speak continuous and we can find elements arbitrary close to an element. Thanks in advance!","['banach-spaces', 'normed-spaces', 'functional-analysis']"
3057878,Proving that a solution to a differential equation is monotonic,"The answer that ws given on a previous question of mine, stated that the solution to this DE: $$x(t)\cdot r+x'(t)\cdot l+a\cdot\ln\left(1+\frac{x(t)}{b}\right)=0\space\Longleftrightarrow\space x(t)=\dots\tag1$$ Must be monotonic. Is there a way to proof that that is the case, that the function $x(t)$ is monotonic?! Background: I've to find (the average of a function over a particular interval, where $t_1>0$ , $t_2>0$ and $t_2>t_1$ ): $$\frac{1}{t_2-t_1}\int_{t_1}^{t_2}x(t)dt\tag2$$ Where $x(t)$ in equation $(2)$ is the solution to the DE in equation $(1)$ .","['definite-integrals', 'ordinary-differential-equations', 'logarithms', 'average', 'mathematical-physics']"
3057908,Using $\bar{A}$ ($A$ modulo $2$) to prove that $A$ is invertible,"Following this website, https://yutsumura.com/how-to-prove-a-matrix-is-nonsingular-in-10-seconds/ : Let $\bar{A}$ be the matrix whose $(i,j)$ -entry is the $(i,j)$ -entry of $A$ modulo $2$ . That is $\bar{A}=\begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
\end{bmatrix}$ Since $\det(A)$ is a polynomial of entries of $A$ , we have $$\det(A)=\det(\bar{A}) (\text{mod} \ 2)= 1$$ I cannot see how we get the equality $\det(A)=\det(\bar{A}) (\text{mod} \ 2)$ just because $\det(A)$ is a polynomial of entries of $A$ .","['determinant', 'modular-arithmetic', 'matrices', 'linear-algebra', 'polynomials']"
3057921,Find all integer solutions for $2(x^2+y^2)+x+y=5xy$,"Find all integer solutions for $2(x^2+y^2)+x+y=5xy$ I have been attempting to solve this question for a long period of time but have never achieved anything. I tried to go back to WolframAlpha and it gave me that the integer solutions were $x=y=2, x=y=0$ . I tried to make to factor it and have a number left on the RHS so I can find out its factors but could not factor it. I also tried making it into the form of: $(x-a_1)^2+(y-a_2)^2+(\text{ })(\text{ })$ but was unable to determine what would be located inside the empty brackets and the values of $a_1,a_2$ . I also tried to multiply the equation by $2$ to get $4x^2=(2x)^2$ Another attempt was assuming that WLOG $x\ge y \iff x=y+a$ which would give me that $a=0$ and from there I could get that $x=y$ and therefore $x=y=0,2$ from basic math. I hope I could get help on this question and thank you anyways.",['algebra-precalculus']
3057932,"Is $\sum_{n,m \in \mathbb Z^2} e^{-\Vert n-m \Vert} \frac{1}{1+\Vert n \Vert^{1+\varepsilon}} \frac{1}{1+\Vert m \Vert^{1+\varepsilon}}$ summable?","I would like to ask whether the expression $$\sum_{n,m \in \mathbb Z^2} e^{-\Vert n-m \Vert} \frac{1}{1+\Vert n \Vert^{1+\varepsilon}} \frac{1}{1+\Vert m \Vert^{1+\varepsilon}}$$ is finite? Intuitively, this should be the case as away from the diagonal $n=m$ the exponential is rapidly decaying and on the diagonal, this expression is summable, but I cannot make it rigorous. EDIT: The sum is over $n$ and $m$ both in $\mathbb Z^2.$","['calculus', 'sequences-and-series', 'analysis', 'real-analysis']"
3057935,Recurring Decimal Expansion,"For any natural number $n>1$ , we write the infinite decimal expansion of $\frac 1n$ (for example, $\frac 14$ is written as $0.24999$ ... instead of $0.25$ ). We need to determine the length of the non-periodic part of the infinite decimal expansion of $\frac 1n$ . I tried many methods, a somewhat promising one was to assume $\frac 1n$ to be some $0.abbbbb$ ..., where ‘ $a$ ’ denotes the non-recurring part which has $r$ digits including zero, while ‘ $b$ ’ is the recurring part. But I get stuck at deciding the lower and upper bounds for $r$ . Please help. (Please note: this is my first post on this website. So if I have to improve the way I should post the question in, please let me know how to correct the errors in my post. Thanks.)","['number-theory', 'elementary-number-theory', 'rational-numbers']"
3057942,monotone subsequences of permutation,"Prove that the number of permutations of $\{1, ..., n\}$ containing a monotone increasing or decreasing subsequence of length at least $3\sqrt{n}$ is $o(n!)$ .
(Hint: pick a random permutation, and show that with probability tending to 1 it does not contain a monotone subsequence of length $3\sqrt{n}$ .) SOLUTION: Let $k = 3\sqrt{n}$ . Let $π$ be a random permutation of $\{1, ..., n\}$ and for a $k$ -element subset $A ⊂ \{1, ..., n\}$ , let $I(A)$ be the indicator random variable that $π$ is either monotone decreasing or increasing on $A$ . Let $X = \sum_{|A| = k} I(A)$ . We have $E(I(A)) = 2/k!$ , so $$
E(X) = \binom{n}{k} 2/k! \leq 2(en/k)^k(e/k)^k = 2(e^2n/k^2)^k < 2 (0.9)^k
 $$ But then, $P(X \geq 1) \leq E(X) < 2 (0.9)^k$ , so as $n$ goes to infinity $P(X \geq 1) = 0$ , which means that the
number of permutations containing a monotone increasing or decreasing subsequence of length $k$ is $o(n!)$ . In the above solution, I understand everything perfectly except in the end how we decide the little-o. I see that for large $n$ , a random permutation does not contain the subsequence we are looking for. However, how do we conclude that $\lim_{n \rightarrow \infty} f(n)/n! = 0$ , $f(n)$ being the number of permutations with the property?","['permutations', 'proof-explanation', 'probabilistic-method', 'asymptotics', 'combinatorics']"
3057946,Lagrange's Theorem: Injectivity.,"Let $U$ be a subgroup of the finite group $G$ and $a\in G$ . To show Lagrange's Theorem we defined a map $U \rightarrow aU$ , $u\mapsto au$ and said that it was bijective. Now for the injectivity we used the trivial case that for $au_1 = au_2\Leftrightarrow u_1=u_2 $ but this uses that we add $a^{-1}$ from the left side in both cases. Now my question is that of course there exists a $a^{-1}\in G$ but don't we need to have $a^{-1}\in aU$ to add it from the left? And if so, how can we show $a^{-1}\in aU$ ? Best,
KingDingeling","['group-theory', 'abstract-algebra', 'finite-groups']"
3057956,"Prove: $\lim_{n\to\infty}{\sum_{m=0}^{n}{\sum_{k=0}^{n-m}{\frac{2^{n-m-k}}{n-m+1}\,\frac{{{2k}\choose{k}}{{2m}\choose{m}}}{{{2n}\choose{n}}}}}}=\pi$","Consider the following limit: $$\lim_{n\to\infty}{\sum_{m=0}^{n}{\sum_{k=0}^{n-m}{\left[\frac{2^{n-m-k}}{n-m+1}\,\frac{{{2k}\choose{k}}{{2m}\choose{m}}}{{{2n}\choose{n}}}\right]}}}=\pi$$ I cooked this up while playing around with power series (details below). Is there a more direct way to prove this limit? Consider the functions $f(x)=\frac{\tan^{-1}(\sqrt{1-x})}{\sqrt{1-x}}$ , $g(x)=\frac{\pi/2-\tan^{-1}(\sqrt{1-x})}{\sqrt{1-x}}$ . We write the power series: $$f(x)=\sum_{n=0}^{\infty}{(s_n\pi-r_n)x^n},\qquad{g}(x)=\sum_{n=0}^{\infty}{(s_n\pi+r_n)x^n}$$ where computing the first few terms suggests that $r_n$ , $s_n$ are rational. Indeed, we have $\frac{\pi/4-\tan^{-1}(\sqrt{1-x})}{\sqrt{1-x}}=\frac{g(x)-f(x)}{2}=\sum{r_nx^n}$ , and $\frac{1/4}{\sqrt{1-x}}=\frac{g(x)+f(x)}{2\pi}=\sum{s_nx^n}$ . Using $\frac{d}{dx}[\tan^{-1}(\sqrt{1-x})]=-\frac{1}{2(2-x)\sqrt{1-x}}$ , we can use the power series for $\frac{1}{2-x}$ and $\frac{1}{\sqrt{1-x}}$ to calculate the power series for $(\pi/4-\tan^{-1}(\sqrt{1-x}))$ , which consists of only rational coefficients. Combining this with the power series for $\frac{1}{\sqrt{1-x}}$ gives: $$r_n=\frac{1}{2}\sum_{m=0}^{n-1}{\sum_{k=0}^{n-m-1}{\frac{{{2k}\choose{k}}{{2m}\choose{m}}}{(n-m)\cdot2^{k+m+n}}}}$$ We easily get $s_n=\frac{1}{2^{2n+2}}{2n\choose{n}}$ . Now, because no branch of $f(z)$ has singularities anywhere (the apparent singularity at $z=1$ is removable), the coefficients of the power series of $f$ must tend to zero. Hence $\lim_{n\to\infty}{\frac{r_{n+1}}{s_{n+1}}}=\pi$ , and the desired limit follows after simplifying. Notes: 1) It is easily shown that: $$s_n\pi-r_n=\int_{0}^{\pi/4}{\sin^{2n}{\theta}\,d\theta},\qquad{s}_n\pi+r_n=\int_{\pi/4}^{\pi/2}{\sin^{2n}{\theta}\,d\theta}$$ 2) The above proof actually shows: $$\lim_{n\to\infty}{\left(1+\frac{1}{2n+1}\right)\sum_{m=0}^{n}{\sum_{k=0}^{n-m}{\left[\frac{2^{n-m-k}}{n-m+1}\,\frac{{{2k}\choose{k}}{{2m}\choose{m}}}{{{2n}\choose{n}}}\right]}}}=\pi$$ which converges much faster than the given limit.","['summation', 'proof-verification', 'alternative-proof', 'binomial-coefficients', 'limits']"
3057962,Surjectivity and Invertibility of the exponential map,"Let $(\mathcal{M},g)$ be a geodesically complete Riemannian manifold.  So $\forall x \in \mathcal{M}$ , the exponential map $\exp_x$ is defined on all of $T_x \mathcal{M}$ .  I have two related questions: (1) Is $\exp_x : T_x \mathcal{M} \rightarrow \mathcal{M}$ surjective for all $x \in \mathcal{M}$ ?  If not, under what conditions on $\mathcal{M}$ is $\exp_x$ surjective (e.g., assuming $\mathcal{M}$ is compact)? (2) If $\exp_x : T_x \mathcal{M} \rightarrow \mathcal{M}$ is surjective, is there a subset of $S_x \subset T_x \mathcal{M}$ such that $\exp_x$ is invertible on $S_x$ and the image of $S_x$ is almost all of $\mathcal{M}$ ?  I.e., $\exp_x(S_x) = \mathcal{M} \setminus U_x$ for some small (e.g., 'measure zero') set $U_x$ .  For example, consider the unit 2-sphere: $\mathcal{M} = S^2 \subset \mathbb{R}^3$ .  Then $exp_x : B_{\pi} \rightarrow S^2 \setminus \{-x\}$ is invertible.","['riemannian-geometry', 'differential-geometry']"
3057994,Convergence of the distribution of the Langevin diffusion to its invariant measure,"Let $(X_t)_{t\ge0}$ be a solution of $${\rm d}X_t=-h'(X_t){\rm d}t+\sqrt 2W_t,\tag1$$ where $(W_t)_{t\ge0}$ is a Brownian motion and $h$ is such that $X$ is the unique strong solution of $(1)$ . Assume $c:=\int e^{-h}\:{\rm d}\lambda\in(0,\infty)$ , where $\lambda$ denotes the Lebesgue measure, and let $g:=c^{-1}e^{-h}$ . $X$ is a time-homogeneous Markov process whose transition semigroup is stationary with respect to the measure $\mu:=g\lambda$ with density $g$ with respect to $\lambda$ . Are we able to show that the distribution $\mathcal L(X_t)$ converges to $\mu$ as $t\to\infty$ ? If so, for which mode of convergence? Weak convergence? Convergence in total variation distance? EDIT :
Let me precise the question: Let $\kappa_t$ denote a regular version of $X_t$ given $X_0$ , $$\kappa_t(x,B)=\operatorname P\left[X_t\in B\mid X_0=x\right]\;\;\;\text{for }\operatorname P\circ\:X_0^{-1}\text{-almost all }x\in\mathbb R\text{ and }B\in\mathcal B(\mathbb R)\tag2.$$ Assume $\nu:=\operatorname P\circ\:X_0^{-1}$ has a density $f$ with respect to $\lambda$ and let $\left|\mu-\nu\kappa_t\right|$ denote the total variation distance of $\mu$ and $$(\nu\kappa_t)(B):=\int\nu({\rm d}x)\kappa_t(x,B)\;\;\;\text{for }B\in\mathcal B(\mathbb R).$$ If we could show that $\mathcal L(X_t)=\nu\kappa_t$ has a density $h_t$ with respect to $\lambda$ , it's well-known that $$\left|\mu-\nu\kappa_t\right|=\frac12\left\|g-h_t\right\|_{L^1(\lambda)}\tag3$$ and we could conclude if we would been able to show that this converges to $0$ as $t\to\infty$ . EDIT 2 :
Some thoughts: Let $L\varphi:=-h'\varphi'+\varphi''$ and $L^\ast\varphi:=(h'\varphi)'+\varphi''$ for $\varphi\in C^2(\mathbb R)$ . Note that $$L^\ast g=0\tag4$$ and $$\mu(L\varphi):=\int L\varphi\:{\rm d}\mu=0\;\;\;\text{for all }\varphi\in C_c^\infty(\mathbb R).\tag4$$ Moreover, $${\rm d}\varphi(X_t)=(L\varphi)(X_t){\rm d}t+\varphi'(X_t){\rm d}W_t\tag5$$ for all $\varphi\in C^2(\mathbb R)$ . In particular, $$\mathcal L(X_t)\varphi=(\nu\kappa_t)\varphi=\underbrace{\lambda(f\varphi)}_{=\:\nu\varphi}+\int_0^t\operatorname E\left[(L\varphi)(X_s)\right]\:{\rm d}s\tag6$$ for all $\varphi\in C_c^2(\mathbb R)$ . EDIT 3 :
Let $(\mathcal D(A),A)$ denote the generator of $(\kappa_t)_{t\ge0}$ . We know that $C_c^\infty(\mathbb R)$ is a core of $(\mathcal D(A),A)$ , $$\mathcal D(A)=\left\{\varphi\in C_0(\mathbb R)\cap C^2(\mathbb R):L\varphi\in C_0(\mathbb R)\right\}\tag7$$ and $$A=\left.L\right|_{\mathcal D(A)}.\tag8$$ Now, let $$\mathcal E(\varphi,\psi):=-\langle\varphi,A\psi\rangle_{L^2(\mu)}\;\;\;\text{for }\varphi,\psi\in\mathcal D(A).$$ $\mathcal E$ is called the Dirichlet form associated to $(\mathcal D(A),A)$ on $L^2(\mu)$ . It's easily seen that if $\rho>0$ and the Poincaré inequality $$\operatorname{Var}_\mu\left[\varphi\right]\le\frac1\rho\mathcal E(\varphi,\varphi)\;\;\;\text{for all }\varphi\in\mathcal D(A)\tag9$$ holds, then $$\left|\nu\kappa_t-\mu\right|^2\le\frac14e^{-2\rho t}\chi^2(\nu,\mu)\tag{10}$$ for all probability measures $\nu$ (not only the special one above) on $(\mathbb R,\mathcal B(\mathbb R))$ , where $$\chi^2(\operatorname P,\operatorname Q):=\begin{cases}\operatorname P\left|\frac{{\rm d}\operatorname P}{{\rm d}\operatorname Q}-1\right|^2&\text{, if }\operatorname P\ll\operatorname Q\\\infty&\text{, otherwise}\end{cases}$$ is the $\chi^2$ -distance of probability measures $\operatorname P$ and $\operatorname Q$ on any common measurable space. Note that in our special choice for $\nu=f\lambda$ , we have $\mu\ll\lambda$ and $\nu\ll\lambda\ll\mu$ (and hence $\nu\ll\mu$ ). As a last note $$\mathcal E(\varphi,\psi)=\frac12\left(\langle\varphi',\psi'\rangle_{L^2(\mu)}+\langle\varphi,h'\psi'\rangle_{L^2(\mu)}\right)\;\;\;\text{for all }\varphi,\psi\in C_c^\infty(\mathbb R)\tag{11}$$ (as can be seen by partial integration). Oh, and note that since $C_c^\infty(\mathbb R)$ is dense in $L^2(\mu)$ , $(\kappa_t)_{t\ge0}$ is a strongly continuous contraction semigroup on $L^2(\mu)$ and the corresponding generator coincides with $A$ on $\mathcal D(A)$ . So, one approach could be to show $(9)$ and somehow use $(10)$ to conclude. If it is of any use, it would be fine for me to assume $h=-\ln f$ for some positive $f\in C^2(\mathbb R)$ .","['stochastic-analysis', 'stochastic-processes', 'markov-process', 'stochastic-differential-equations', 'probability-theory']"
