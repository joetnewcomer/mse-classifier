question_id,title,body,tags
3753060,If $\int f(x)dx =g(x)$ then $\int f^{-1}(x)dx $ is equal to,"If $\int f(x)dx =g(x)$ then $\int f^{-1}(x)dx $ is equal to (1) $g^{-1}(x)$ (2) $xf^{-1}(x)-g(f^{-1}(x))$ (3) $xf^{-1}(x)-g^{-1}(x)$ (4) $f^{-1}(x)$ My approach is as follows:
Let $f(x)=y$ , therefore $f^{-1}(y)=x$ , $\int f^{-1}(f(x))dx =g(f(x))$ On differentiating we get $x=g'(f(x))f'(x)$ After this step, I am not able to proceed.","['integration', 'indefinite-integrals', 'calculus', 'inverse-function']"
3753076,How to calculate $ \left| \sin x \right| $ derivative in a more elegant way?,"I am trying to calculate the derivative of $\left| \sin x \right| $ Given the graphs, we notice that the derivative of $\left| \sin x \right|$ does not exist for $x= k\pi$ . Graph for $\left|\sin x\right|$ : We can rewrite the function as $\left| \sin(x) \right| =  \left\{
\begin{array}{ll}
      \sin(x),& 2k\pi < x < (2k+1)\pi \\
      -\sin(x), & \text{elsewhere} \\
\end{array} 
\right.  $ Therefore calculate its derivative as: $(\left| \sin(x) \right|)^{'} =  \left\{
\begin{array}{ll}
      \cos(x),& 2k\pi < x < (2k+1)\pi \\
      -\cos(x), & \text{elsewhere} \\
\end{array} 
\right.  $ Is there a way to rewrite this derivative, in a more elegant way (as a non-branch function) $(\left| \sin(x) \right|)^{'} = g(x)$ ?","['calculus', 'derivatives', 'absolute-value', 'real-analysis']"
3753139,volume of tilted ellipsoid,"I'm supposed to calculate the volume of $$(2 x+y+z)^2 + (x+2 y+z)^2 + (x+y+2 z)^2 \leq 1$$ simplifying it gives $$6 (x^2 + y^2  + z^2) + 10 (x y + y z + x z) \leq 1$$ After drawing it using GeoGebra, I saw that it's a tilted ellipsoid inside the unit sphere, but I'm unable to think of how to solve this.
I tried replacing the coordinates and I tried using spherical coordinates but I was unable to go anywhere with them. The final answer is $\frac{\pi}{3}$ meaning it's $\frac{1}{4}$ of a unit sphere's volume, and still, I wasn't able to conclude anything useful from it. Any hints would be greatly appreciated.","['volume', 'multivariable-calculus', 'multiple-integral', 'vector-analysis']"
3753143,Mathematical problems which prompts the creation of new theories,"We spend a lot of time learning different theories (for instance, theory of differential forms, sobolev spaces, homology groups, distributions). Although (at least most parts of) these theories are very natural and understandable when we read them from books, they are very difficult to create at the first place: it could take tens of years of effort of a large number of excellent mathematicians. After learning those theories, we do exercises or solve problems, but most of the time, we are just using the tools stated in the book. Even the chance that we come up with a ""new"" definition ourselves is rare. (By ""new"", I mean ""have not learnt"", even if someone else have created it before.) So here is my question: What are some problems which prompts the creation of a new theory? EDIT: Just to clarify, I am looking for some problems which give everybody a chance to experience the process of creating new mathematics; so the problem need not be as difficult as Riemann conjecture. By ""new theory"", I just mean something that help us formulate the problem in a different way. For example, this video on a chess board puzzle has the idea of creating new theories, because unlike other less interesting puzzles about chess board which can be solved by just carefully counting the squares, this video mentions a new way of looking at the problem, namely the vertices of a hypercube. I have also seen other similar puzzles like this. Apparently, almost all of them are on discrete mathematics, so it would be really interesting if anyone could provide such a ""theory creating"" problem in other areas of mathematics (e.g. analysis). Of course, not all theories are created to tackle specific problems, so other ways of experiencing inventing new maths could also be suggested.","['soft-question', 'discrete-mathematics', 'problem-solving', 'analysis']"
3753212,Is there any geometric intuition for the factorials in Taylor expansions?,"Given a smooth real function $f$ , we can approximate it as a sum of polynomials as $$f(x+h)=f(x)+h f'(x) + \frac{h^2}{2!} f''(x)+ \dotsb = \sum_{k=0}^n \frac{h^k}{k!} f^{(k)}(x) + h^n R_n(h),$$ where $\lim_{h\to0} R_n(h)=0$ . There are multiple ways to derive this result. Some are already discussed in the answers to the question "" Where do the factorials come from in the taylor series? "". An easy way to see why the $1/k!$ factors must be there is to observe that computing $\partial_h^k f(x+h)\rvert_{h=0}$ , we need the $1/k!$ factors to balance the $k!$ factors arising from $\partial_h^k h^k=k!$ in order to get a consistent result on the left- and right-hand sides. However, even though algebraically it is very clear why we need these factorials, I don't have any intuition as to why they should be there. Is there any geometrical (or similarly intuitive) argument to see where they come from?","['real-analysis', 'calculus', 'taylor-expansion', 'polynomials', 'derivatives']"
3753236,What number follows immediately after a rational number?,"I recently came across a confusing question on limits and was having trouble solving it. $$f(x) =
\begin{cases}
x^2  & \text{if $x$ is rational} \\[1ex]
0 & \text{if $x$ is irrational}
\end{cases}$$ What would be the limit of this function as it approaches any Rational number?","['limits', 'irrational-numbers', 'rational-numbers']"
3753251,An inequality involving real numbers,"Let $x,y,z$ be real numbers such that $xyz=-1$ . Prove that $$\sqrt[3/2]{\frac{3}{2}}\geq E:=\frac{4(x^3+y^3+z^3)}{(x^2+y^2+z^2)^2}$$ I tried to imitate an idea by River Li but it does not work. The idea is to find a function $f$ such that for all $x,y>0$ , $$E\leq f(x+y)$$ and then use calculus to show $\displaystyle f_{\max}=\sqrt[3/2]{\frac{3}{2}}$ . For instance, $$x^2+y^2\geq\frac{(x+y)^2}{2},\qquad z^2=\frac{1}{x^2y^2}\geq\frac{16}{(x+y)^4},\qquad z^3=-\frac{1}{x^3y^3}\leq-\frac{64}{(x+y)^6}$$ Unfortunately, there does not exist any function $g$ such that $x^3+y^3\leq g(x+y)$ .","['uvw', 'multivariable-calculus', 'symmetric-polynomials', 'inequality', 'quadratics']"
3753266,Double integral of a shifted circle,"Task: find a double integral $$\iint_D (x+y)dxdy,$$ where D is bound by $x^2 + y^2 = x + y$ . What I have done so far: turns out it's a circle $$(x-1)^2 + (y-1)^2 = 2$$ Calculating it as a common double integral is hard because I get something like this: $$\int_{1-\sqrt{2}}^{1+\sqrt{2}} dx \int_{1 - \sqrt{2 - (x-1)^2}}^{1 + \sqrt{2 - (x-1)^2}} (x + y) dy.$$ So, I decided to give up on this. My next idea is to transform it into Polar coordinates. And that's where I got stuck. $$dxdy = rdrd\theta \\ x = r \cos{\theta} \\ y = r \sin{\theta}.$$ What to do next? For me, it looks like $$0 \leq\theta \leq 2\pi \\ 0 \leq r \leq 2\sqrt{2},$$ but this seems like a case when the origin of a circle is $(0, 0)$ . I have my circle shifted and there should be some tricks. Any help would be appreciated.","['integration', 'volume', 'multivariable-calculus', 'polar-coordinates', 'multiple-integral']"
3753293,"Prove that $\bigcup\Bigr\{A\setminus B\;\Bigr|\,A\in\mathcal F\Bigr\}\subseteq\bigcup\Bigr(\mathcal F\setminus\mathscr P(B)\Bigr)$.","Not a duplicate of Suppose $B$ is a set and $F$ is a family of sets. Prove that $\bigcup\{A \setminus B | A \in F\} \subseteq \bigcup(F \setminus P(B))$. This is exercise $3.4.14$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $B$ is a set and $\mathcal F$ is a family of sets. Prove that $\bigcup\Bigr\{A\setminus B\:\Bigr|\,A\in\mathcal F\Bigr\}\subseteq\bigcup\Bigr(\mathcal F\setminus\mathscr P(B)\Bigr)$ . Here is my proof: Let $x$ be an arbitrary element of $\bigcup\Bigr\{A\setminus B\;\Bigr|\,A\in\mathcal F\Bigr\}$ . So we  can choose some $A_0$ such that $A_0\in \mathcal F$ and $x\in A_0\setminus B$ . This means $x\in A_0$ and $x\notin B$ . Since $x\in A_0$ but $x\notin B$ , $\require{cancel}A_0\cancel{\subseteq} B$ . Ergo $A_0\notin \mathscr P(B)$ . From $A_0\in \mathcal F$ and $A_0\notin \mathscr P(B)$ , $A_0\in\mathcal F\setminus\mathscr P(B)$ . From $x\in A_0$ and $A_0\in\mathcal F\setminus \mathscr P(B)$ , $x\in\bigcup\Bigr(\mathcal F\setminus \mathscr P(B)\Bigr)$ . Therefore if $x\in \bigcup\Bigr\{A\setminus B\:\Bigr|\,A\in\mathcal F\Bigr\}$ then $x\in\bigcup\Bigr(\mathcal F\setminus \mathscr P(B)\Bigr)$ . Since $x$ is arbitrary, $\forall x\Biggr(x\in\bigcup\Bigr\{A\setminus B\;\Bigr|\,A\in\mathcal F\Bigr\}\rightarrow x\in\bigcup\Bigr(\mathcal F\setminus \mathscr P(B)\Bigr)\Biggr)$ and so $\bigcup\Bigr\{A\setminus B\;\Bigr|\,A\in\mathcal F\Bigr\}\subseteq\bigcup\Bigr(\mathcal F\setminus\mathscr P(B)\Bigr)$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3753365,Show $\frac{f'(x)}{f(x)}\ge\frac{g'(x)}{g(x)}-\left|\frac{f'(1)}{f(1)}-\frac{g'(1)}{g(1)} \right|$ if $\frac{f''(x)}{f(x)}\ge\frac{g''(x)}{g(x)}$.,"Suppose $f$ and $g$ are positive increasing functions on $\left[ 1,+\infty \right)$ such that $$\frac{f''\left( x \right)}{f\left( x \right)}\ge \frac{g''\left( x \right)}{g\left( x \right)}\,.$$ Prove that $$\frac{f'\left( x \right)}{f\left( x \right)}\ge \frac{g'\left( x \right)}{g\left( x \right)}-\left| \frac{f'\left( 1 \right)}{f\left( 1 \right)}-\frac{g'\left( 1 \right)}{g\left( 1 \right)} \right|
\,.$$ The problem is  taken from： Mitrinovic, D.S. Pecaric, j. E, Fink, A. M., Classical and new inequalities in analysis, Kluwer Acad tools. Publ, Dordrecht, 1993.
But I couldn't find the book, and I didn't come up with a good solution. $$\varphi \left( x \right) =f'\left( x \right) g\left( x \right) -f\left( x \right) g'\left( x \right) \,\,$$ $$\varphi '\left( x \right) =f''\left( x \right) g\left( x \right) -f\left( x \right) g''\left( x \right) \ge 0$$ $$\varphi \left( x \right) \ge \varphi \left( 1 \right) \Rightarrow \frac{f'\left( x \right)}{f\left( x \right)}-\frac{g'\left( x \right)}{g\left( x \right)}\ge \frac{f\left( 1 \right) g\left( 1 \right)}{f\left( x \right) g\left( x \right)}\left[ \frac{f'\left( 1 \right)}{f\left( 1 \right)}-\frac{g\left( 1 \right)}{g\left( 1 \right)} \right] $$ The rest of the work is just to take the absolute value out of the case.","['calculus', 'derivatives', 'analysis', 'inequality']"
3753368,Show this identity for the surface measure on the boundary of a submanifold,"Let $M$ be a $k$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ with boundary $^1$ and $(\Omega,\phi)$ be a $k$ -dimensional boundary $C^1$ -chart $^2$ of $M$ . We know that $^3$ $(\tilde\Omega,\tilde\phi):=(\Omega\cap\partial M,\pi\circ\left.\phi\right|_{\tilde\Omega})$ is a $(k-1)$ -dimensional $C^1$ -chart of $\partial M$ . Let $(U,\psi):=(\phi(\Omega),\phi^{-1})$ and $(\tilde U,\tilde\psi):=(\tilde\phi(\tilde\Omega),\tilde\phi^{-1})$ . Then $${\rm D}\tilde\psi(u)={\rm D}\psi(\iota u)\circ\iota\;\;\;\text{for all }u\in\tilde U=\{u\in\mathbb R^{k-1}:(u,0)\in U\}\tag1.$$ By definition, the surface measure on $\mathcal B(\tilde\Omega)$ is given by $$\sigma_{\tilde\Omega}:=\sqrt{g_{\tilde\psi}}\left.\lambda^{\otimes(k-1)}\right|_{\tilde U}\circ\tilde\psi^{-1},$$ where $g_{\tilde\psi}:=\det G_{\tilde\psi}$ , $G_{\tilde\psi}(u):={\rm D}\tilde\psi(u)^\ast{\rm D}\tilde\psi(u)$ for $u\in\tilde U$ and $\lambda$ denotes the Lebesgue measure on $\mathcal B(\mathbb R)$ . If $k=d$ , I would like to show that $$\int f\:{\rm d}\sigma_{\tilde\Omega}=\int_{B_0}f(\psi(u))|\det{\rm D}\phi(u)|\left\|{\rm D}\phi(u)^\ast e_k\right\|\:\lambda^{\otimes k}({\rm d}u)\tag2$$ for all $\sigma_{\tilde\Omega}$ -integrable $f:\tilde\Omega\to\mathbb R$ , where $B_0:=\{u\in\mathbb R^k:\left\|u\right\|\le1\text{ and }u_k=0\}$ and $(e_1,\ldots,e_k)$ denotes the standard basis of $\mathbb R^k$ . How can we do that? It's easy to see that $\pi$ is the adjoint $\iota^\ast$ of $\iota$ , i.e. $\iota^\ast=\pi$ . So, if $A\in\mathbb R^{d\times k}$ and $\tilde A:=A\circ\iota$ , then $$(\tilde A^\ast\tilde A)_{ij}=\langle Ae_i,Ae_j\rangle=B_{ij}\;\;\;\text{for all }i,j\in\{1,\ldots,k-1\},\tag3$$ where $B:=A^\ast A$ . If we denote by $B^{kk}$ the submatrix of $B$ formed by deleting the $k$ th row and $k$ th column, we have shown that $\tilde A^\ast\tilde A=B^{kk}$ . If $\operatorname{cof}(M)$ denotes the cofactor matrix of a square-matrix $M$ and $k=d$ , then $$\operatorname{cof}(B)=\operatorname{cof}(A)^\ast\operatorname{cof}(A)\tag4$$ and hence $$\det\tilde A^\ast\tilde A=\operatorname{cof}(B)_{kk}=\left\|\operatorname{cof}(A)e_k\right\|^2\tag5.$$ If $A$ is regular, then $$\operatorname{cof}(A)=\det A(A^{-1})^\ast\tag6$$ and hence $$\sqrt{\det\tilde A^\ast\tilde A}=|\det A|\left\|(A^{-1})^\ast e_k\right\|\tag7.$$ If we apply this to $A={\rm D}\psi(u)$ , $u\in\phi(\Omega)$ , we obtain $$\sqrt{g_{\tilde\psi}(u)}=|\det{\rm D}\psi(\iota u)|\left\|({\rm D}\psi(\iota u)^{-1})^\ast e_k\right\|\;\;\;\text{for all }u\in\tilde U\tag8.$$ Now, by definition, $$\int f\:{\rm d}\sigma_{\tilde\Omega}=\int\sqrt{g_{\tilde\psi}}(f\circ\tilde\psi)\:{\rm d}\left.\lambda^{\otimes(k-1)}\right|_{\tilde U}.\tag9$$ How do we need to proceed? If $B$ denotes the closed unit ball in $\mathbb R^k$ , $B_+:=B\cap(\mathbb H^k)^\circ$ and $B_0=B\cap\partial\mathbb H^k$ , I've read that we can assume without loss of generality that $\Omega^\circ=\phi^{-1}(B_+)$ and $\partial\Omega=\phi^{-1}(B_0)$ , but I don't get why this is possible. EDIT : What I could imagine is that we can replace $\phi$ by $$x\mapsto\begin{cases}\frac{\phi(x)}{\max(1,\left\|\phi(x)\right\|)}&\text{, if }\phi(x)\ne0\\0&\text{, otherwise}\end{cases}\tag{10}.$$ This should (am I missing something?) still be a $C^1$ -diffeomorphism and it clearly takes values in $B$ . Is this the right approach? $^1$ i.e. each point of $M$ is locally $C^1$ -diffeomorphic to $\mathbb H^k$ . If $E_i$ is a $\mathbb R$ -Banach space and $B_i\subseteq E_i$ , then $f:B_1\to E_2$ is called $C^1$ -differentiable if $f=\left.\tilde f\right|_{B_1}$ for some $E_1$ -open neighborhood $\Omega_1$ of $B_1$ and some $\tilde f\in C^1(\Omega_1,E_2)$ and $g:B_1\to B_2$ is called $C^1$ -diffeomorphism if $g$ is a homeomorphism from $B_1$ onto $B_2$ and $g$ and $g^{-1}$ are $C^1$ -differentiable. $^2$ A $k$ -dimensional $C^1$ -chart of $M$ is a $C^1$ -diffeomorphism from an open subset of $M$ onto an open subset of $\mathbb H^k$ . $^3$ Let $\iota$ denote the canonical embedding of $\mathbb R^{k-1}$ into $\mathbb R^k$ with $\iota\mathbb R^{k-1}=\mathbb R^{k-1}\times\{0\}$ and $\pi$ denote the canonical projection of $\mathbb R^k$ onto $\mathbb R^{k-1}$ with $\pi(\mathbb R^{k-1}\times\{0\})=\mathbb R^{k-1}$ .","['submanifold', 'manifolds-with-boundary', 'geometric-measure-theory', 'smooth-manifolds', 'differential-geometry']"
3753372,Equivalent definitions of Fredholm operators on infinite dimensional Banach spaces,"This question is similar to other questions on MSE, but none of them has an answer which satisfies me. Given an infinite dimensional complex Banach space $X$ , $T \in B(H)$ is Fredholm iff the cokernel and the kernel are finite dimensional (if the dimension of the cokernel is finite dimensional, the range is closed, so I have not written this last condition because it is redundant). Now, for Hilbert spaces it can be shown, using decompositions in direct orthogonal sums, that $\dim \operatorname{coker} T < \infty$ is equivalent to $\dim \ker T^* < \infty$ ., where $T^*$ is the adjoint of $T$ . The adjoint can be defined even for general Banach spaces. Moreover, we can define a notion of orthogonal complement in Banach spaces using the dual space $X^*$ . When $X$ is reflexive, we can obtain properties of orthogonality which are similar to Hilbert spaces (when $X$ is not reflexive, some analoguous facts which hold for Hilbert spaces are not anymore valid). So, I would expect that $\dim \operatorname{coker} T < \infty \Leftrightarrow \dim \ker T^* < \infty$ could be true for $X$ reflexive. But what happens for general Banach spaces? A proof as in the case of Hilbert spaces seem to be not anymore possible, but maybe something else could work. So my question is: does this equivalence still hold in general? If the answer is yes, could you please provide some reference with a proof of this fact? EDIT: @s.harp Even though your proof seems correct to me, consider the Toeplitz operator with symbol $(z-1)$ on $H^2$ . The kernel of this operator and the kernel of its adjoint are both trivial, so they have dimension $0$ . This would imply that the dimension of the cokernel is finite, which implies that the range of the operator is closed. However, this Toeplitz operator has a dense - but not closed - range. Maybe this fact depends on the logical axioms used (as, for instance, in the case of Whitehead problem)?","['banach-spaces', 'operator-theory', 'functional-analysis']"
3753413,Finding a class $C$ of bipartite PPT states such that entanglement of $\rho \in C$ implies entanglement of $\rho + \rho^{\Gamma}$.,"Consider an entangled bipartite quantum state $\rho \in \mathcal{M}_d(\mathbb{C}) \otimes \mathcal{M}_{d'}(\mathbb{C})$ which is positive under partial transposition, i.e., $\rho^\Gamma \geq 0$ . As separability of $\rho$ is equivalent to separability of its partial transpose $\rho^\Gamma$ , we know that $\rho^\Gamma$ is entangled. What are the conditions on $\rho$ which will guarantee that the sum $\rho + \rho^\Gamma$ (ignoring trace normalization) is also entangled? It turns out that the above proposition does not hold for arbitrary PPT entangled states. Easiest counterexamples can be found in $\mathcal{M}_2(\mathbb{C}) \otimes \mathcal{M}_{d}(\mathbb{C})$ , where $\rho + \rho^\Gamma$ is separable for all quantum states $\rho \in \mathcal{M}_2(\mathbb{C}) \otimes \mathcal{M}_d(\mathbb{C})$ (see separability in 2xN systems ). In the language of entanglement witnesses, the problem reduces to finding a common witness that detects both $\rho$ and $\rho^\Gamma$ . Let $W$ be the entanglement witness detecting $\rho$ , i.e., $\text{Tr} (W\rho) < 0$ . Then $W$ is non-decomposable (as $\rho$ is PPT) and is of the canonical form $P+Q^\Gamma - \epsilon \mathbb{I}$ , where $P, Q \geq 0$ are such that $\text{range}(P) \subseteq\text{ker}(\delta)$ and $\text{range}(Q) \subseteq \text{ker}(\delta^\Gamma)$ for some bipartite edge state $\delta$ (these are special states that violate the range criterion for separability in an extreme manner, see edge states ) and $0 < \epsilon \leq \text{inf}_{|e,f\rangle} \langle e,f | P+Q^\Gamma | e,f \rangle$ . If $\delta$ is such that $\text{ker}(\delta) \cap \text{ker}(\delta^\Gamma)$ is not empty, then we can choose $P=Q$ to be the orthogonal projector on $\text{ker}(\delta) \cap \text{ker}(\delta^\Gamma)$ , in which case $W=W^\Gamma$ is the common witness. Can we find a class of PPT entangled states for which the previous statement holds? Can optimization of entanglement witnesses be somehow used to ensure this condition? Cross-posted on physics.SE Cross-posted on quantumcomputing.SE","['positive-semidefinite', 'matrices', 'linear-algebra', 'quantum-information', 'mathematical-physics']"
3753451,I have trouble finding limits at infinity .,"When I'm asked to find limits at infinity for a given rational function, what do I do?
I'm aware of the result we obtain by comparing the degrees of the numerator and the denominator of a given rational function. I'm listing the questions below which I don't understand. $$\lim _{x\to\infty}\left(\frac{x^2+1}{x+1}-ax-b\right)=0 $$ $$\lim _{x\to\infty}\left(\frac{x^2-1}{x+1}-ax-b\right)=2 $$ $$\lim _{x\to\infty}\left(\frac{x^2+1}{x+1}-ax-b\right)=\infty $$ Here, a and b are some Real constants. Answer to question 1: $a = 1$ ; $b = -1$ .
Answer to question 2: $a = 1$ ; $b = -3$ .
Answer to question 3: $a ≠ 1$ ; $b ∈ ℝ$ . In Q.1 since the value of limit is equal to 0, degree of the numerator must be less than that of the denominator. By using this I am able to get the value of a and b as 1 and -1 respectively. But for question 2 and 3 I'm unable to understand what happens. If possible please tell me a good source to learn limits.","['limits', 'calculus', 'limits-without-lhopital']"
3753473,Surjective homomorphisms between braid groups,"There cannot be a surjective homomorphism $B_2 \to B_n$ for any $n > 2$ because $B_2$ is commutative and $B_n$ is not. It seems plausible that if $m < n$ , there cannot be a surjective homomorphism $B_m \to B_n$ . If $m>n$ , there are surjective maps $B_m \to B_n$ obtained by forgetting a certain number of strands, but these are not homomorphisms: e.g., if $f: B_3 \to B_2$ is the map forgetting the third strand, then $f(\sigma_1 \sigma_2 \sigma_1) = \sigma_1$ , but $f(\sigma_1) \cdot f(\sigma_2) \cdot f(\sigma_1) = \sigma_1^2$ . Here, $\sigma_i$ is the braid swapping the $i$ -th and the $(i+1)$ -st strand using a single positive crossing. How do these observations generalize? I.e., under what conditions on $m,n \geq 2$ does there exist a surjective homomorphism $B_m \to B_n$ ? My suspicion is that this requires $m = n$ or, similar to the case of symmetric groups, $(m,n) = (4,3)$ , is this true? Edit : I also posted this on MO since this may be harder than it looks. In the comments there, a solution for the case $m > n$ has turned up in the literature (Theorem 3.1 in Lin ). Any thoughts on the case $m < n$ are very much appreciated.","['group-theory', 'abstract-algebra', 'low-dimensional-topology', 'braid-groups']"
3753477,"$\frac{1}{2r}\int_{x-r}^{x+r}f(t)dt \to g(x)$ uniformly when $r\rightarrow \infty$, then $g(x)=ax+b$","Suppose $f$ is a Continuous function on $\Bbb R$ and $g: \Bbb R \to \Bbb R$ a function such that $$ \frac{1}{2r}\int_{x-r}^{x+r}f(t)dt \to g(x) \text{ uniformly }$$ when $r\rightarrow \infty$ , then show that $g(x)=ax+b$ for some $a,b \in \Bbb R$ . I really have no idea on how to approach the problem. Thanks in advance for help!","['integration', 'functional-analysis', 'uniform-convergence', 'real-analysis']"
3753490,How to evaluate $\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{n+1}$ directly?,"The rational zeta series $$
\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{n+1}=\frac{3}{2}-\ln \pi \tag1
$$ can be derived from other well known rational zeta series. $$
\sum_{n=2}^{\infty}\frac{\left ( -1 \right )^{n}\left ( \zeta (n)-1 \right )}{n+1}=\frac{3}{2}+\frac{\gamma }{2}-\frac{\ln 8\pi}{2} \tag2
$$ $$
\sum_{n=2}^{\infty}\frac{\zeta (n)-1}{n+1}=\frac{3}{2}-\frac{\gamma }{2}-\frac{\ln 2\pi}{2} \tag3
$$ Zeta series (2) and (3) can be derived by integrating the Taylor series of logarithm of gamma function. Zeta series (2)+(3) gives $$
\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{2n+1}=\frac{3}{2}-\frac{\ln 4\pi}{2} \tag4
$$ The zeta series below can be derived directly with the integral definition of $\zeta(2n)$ . $$
\sum_{n=1}^{\infty}\frac{\zeta (2n)}{(n+1)(2n+1)}=\frac{1}{2} \tag5
$$ From zeta series (5) we get $$
\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{(2n+1)(2n+2)}=\frac{3}{4}-\ln 2 \tag6
$$ Zeta series (6) can be rewritten as $$
\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{2n+1}-\frac{1}{2}\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{n+1}=\frac{3}{4}-\ln 2 \tag7
$$ Tegether with zeta series (4), we get the result of zeta series (1). Other than using known results of rational zeta series, how to evaluate zeta series (1) directly with elementary sum of series and integral? I have tried several ways without success. One of my attempts: $$
\sum_{n=1}^{\infty}\frac{\zeta (2n)-1}{n+1}x^{n+1}=\sum_{n=1}^{\infty}\sum_{k=2}^{\infty}\frac{1}{k^{2n}}\int_{0}^{x}t^{n}dt=\sum_{k=2}^{\infty}\int_{0}^{x}\sum_{n=1}^{\infty}\left ( \frac{t}{k^{2}} \right )^{n}dt \\
=\sum_{k=2}^{\infty}\int_{0}^{x}\frac{t}{k^{2}-t}dt=\sum_{k=2}^{\infty}\left ( k^{2}\ln\frac{k^{2}}{k^{2}-x}-x\right )
$$ It seems this attempt won't give any useful result for a closed form, although the sum of this series does converge to $(3/2-\ln\pi)$ slowly when setting $x=1$ .","['zeta-functions', 'sequences-and-series']"
3753495,Derivative of argmin in a constrained problem,"Let $f(x,y)$ be a continuously differentiable function from $\mathbb{R}^2$ to $\mathbb{R}$ . Suppose that for every $y$ the function $g_y(x)=f(x,y)$ is strictly convex.  Define $$
h(y) = \arg\min_{x\leq b} f(x,y)
$$ where $b\in \mathbb{R}$ is a parameter that constraint the set of possible $x$ . My question is: Can we say anything about the derivative of the argmin $h'(y)$ ? I know from this question that $h(y)$ is continuous. In addition, the answer to this question shows that when the problem is unconstrained ( $b=\infty$ ) we can differentiate the optimality condition $$
\frac{ \partial f(h(y),y)}{\partial x} = 0
$$ with respect to $y$ to obtain an expression for $h'(y)$ . But when the problem is constrained ( $b<\infty$ ) that expression becomes $$
\frac{ \partial f(h(y),y)}{\partial x} = \lambda(y)
$$ where $\lambda(y)$ is the Lagrange multiplier on the constraint $x\leq b$ and its hard to say anything about $h'(y)$ without knowing $\lambda'(y)$ .","['convex-optimization', 'real-analysis', 'partial-derivative', 'optimization', 'derivatives']"
3753514,Is $(A+B)$ necessarily singular?,"Let $A, B$ be two orthogonal matrices over a field $F$ of characteristic $2$ such that $$\det (A) + \det (B) = 0.$$ Is $(A+B)$ necessarily a singular matrix? I have proved the result to be true for real matrices anf the result also holds for complex matrices. I even proved the result over any field of characteristic $\neq 2.$ Can it hold for matrices over a field of characteristic $2$ ? I am asking this question because at the fag end of the proof of this result for real matrices I got a relation $2 \det (A + B) = 0,$ since $2 \neq 0$ over $\Bbb R$ we have the required result. But for any field $F$ of characteristic $2$ we have $2 = 0$ and hence we can't say whether or not $\det (A+B) = 0$ so that $(A+B)$ is a singular matrix. Any help or suggestion in this regard will be highly appreciated. Thanks in advance.","['matrices', 'finite-fields', 'examples-counterexamples']"
3753519,"$\lim_{(x,y)\to(0,0)} \frac{x^2y^3}{x^4+2y^6}$ limit calculation",I have tried to write the limit using polar coordination. but I remain with a $cos(\theta)$ in the denominator. thanks for the help,"['multivariable-calculus', 'limits', 'calculus']"
3753591,Help understanding the Weak Law of Large Numbers?,"In the book I'm currently reading, this law is stated as: The Weak Law of Large Numbers provides proof of the notion that if $n$ independent and identically distributed random variables, $X_1,X_2,...,X_n$ , from a distribution with ﬁnite variance are observed, then the sample mean, $\bar{X}$ , should be very close to $\mu$ provided $n$ is large. The problem is, the book hasn't formally defined $\bar{X}$ , so I'm unclear as the the relationship between $X$ and the $X_i's$ . From the context I assuming that: $$\bar{X} = \frac{X_1+X_2+\cdots+X_n}{n}$$ But this makes no sense to me since the $X_i's$ may not necessarily all even be the same unit, so this would be like adding apples and oranges. In other words, I can say, in an experiment of three coin tosses, let $X_1$ be the number of tails that appear and $X_2$ be the number of heads that appear, thus the units for $X_1$ and $X_2$ are tails and heads, respectively. Understanding the relationship between the $X_i's$ and $X$ is important to me to make sense of the expression: $$\lim_{n \rightarrow \infty} \mathbb P \left( \left| \frac{X_1+X_2+\cdots+X_n}{n}-\mu \right| \ge \epsilon \right) = 0$$ which, upon replacing $\mu$ with its definition, I obtain: $$\lim_{n \rightarrow \infty} \mathbb P \left( \left| \frac{X_1+X_2+\cdots+X_n}{n}-E[X] \right| \ge \epsilon \right) = 0$$ Perhaps this is totally wrong but my interpretation of this law is essentially if $\mu_i=E[X_i]$ , then, as $n \rightarrow \infty$ , $\mu_1=\mu_2=\cdots=\mu_n=\mu$ , which I feel is intuitively obvious as all the $X$ 's are identically distributed (again, ignoring units). So my questions boil down to: What is the definition of $\bar{X}$ ? What is the conceptual meaning of $\frac{X_1+X_2+\cdots+X_n}{n}$ ? How do I reconcile the unit differences of the expression in question 2? What is the relationship between the $X_i$ 's and $X$ ?","['statistics', 'probability-limit-theorems', 'law-of-large-numbers', 'probability']"
3753628,Interchanging supremum with infimum,"Let $f:(0,a) \times (0,b) \to \mathbb{R}$ be a given function. Under what conditions is it true that $$\sup_{x\in(0,a)} \inf_{y \in (0,b)} f(x,y) = \inf_{y \in (0,b)} \sup_{x\in(0,a)} f(x,y) \tag{1}$$ There is a related question saying that the inequality $""\leq""$ in $(1)$ holds true, however in general one cannot expect the converse inequality $""\geq""$ . I'm interested in some additional assumptions that will make $(1)$ true. Any references will be much appreciated. For example if we assume that $f$ is increasing in $y$ and decreasing in $x$ , then $\sup_{x \in (0,a)}$ and $\inf_{y \in (0,b)}$ in $(1)$ can be replaced with $\lim_{x\to 0}$ and $\lim_{y\to 0}$ respectively. Then $(1)$ would hold for example if the double limit at $(0,0)$ exists. But these are very restrictive assumptions, anything more general?","['supremum-and-infimum', 'sequences-and-series', 'real-analysis']"
3753629,Is the point of the Gelfand triple/Hilbert triple that we don't need to write as many symbols?,"Let $V \subset H$ be a continuous embedding of Hilbert spaces. Let $I\colon V \to H$ be the inclusion map. Let $R\colon H \to H^*$ be the Riesz map. Then we have for $h \in H$ and all $v \in V$ $$\langle I^*Rf, v \rangle_{V^*,V} = (f,v)_H$$ where $I^*\colon H^* \to V^*$ is the adjoint map of $I$ . Now let us identify $H$ with its dual and make $V \subset H \subset V^*$ a Gelfand triple. In this case, we would write for any $h \in H$ and $w \in V$ the formula $$\langle h, w \rangle_{V^*,V} = (h,w)_H.$$ So is the whole point of the Gelfand triple that it means we don't need to write $I^*R$ in the first displayed equation? It is just a notation?","['hilbert-spaces', 'banach-spaces', 'functional-analysis']"
3753694,"Prob. 3 (d), Sec. 1, in G.F. Simmon's INTRO TO TOPOLOGY & MODERN ANALYSIS","Here is Prob. 3, Sec. 1, in the book Introduction To Topology And Modern Analysis by George F. Simmons. (a) Let $U$ be the single-element set $\{ 1 \}$ . There are two subsets, the empty set $\emptyset$ and $\{ 1 \}$ itself. If $A$ and $B$ are arbitrary subsets of $U$ , there are four possible relations of the form $A \subseteq B$ . Count the number of true relations among these. (b) Let $U$ be the set $\{ 1, 2 \}$ . There are four subsets. List them. If $A$ and $B$ are arbitrary subsets of $U$ , there are $16$ possible relations of the form $A \subseteq B$ . Count the number of true ones. (c) Let $U$ be the set $\{ 1, 2, 3 \}$ . There are $8$ subsets. What are they? There are $64$ possible relations of the form $A \subseteq B$ . Count the number of true ones. (d) Let $U$ be the set $\{ 1, 2, \ldots, n \}$ for an arbitrary positive integer $n$ . How many subsets are there? How many possible relations of the form $A \subseteq B$ are there? Can you make an informed guess as to how many of these are true? I know that there are a total of $2^n$ subsets of the set $U \colon= \{ 1, \ldots, n \}$ for any positive  integer $n$ . So, given any arbitrary subsets $A$ and $B$ of set $U$ , there are $2^n \times 2^n = 2^{2n}$ relations of the form $A \subseteq B$ , of which $3^n$ are true relations. This much we can conclude from the parts (a) through (c) above. Am I right? Now my question is, how to prove rigorously (i.e. using induction or otherwise) that there are a total of $3^n$ true relations? My Attempt: Our desired assertion of course holds for $n = 1$ . Suppose it holds for an arbitrary positive integer $n$ . Now let us consider the set $U$ given by $$
U \colon= \{ 1, \ldots, n, n+1 \}.
$$ Let us form the set $U^\prime$ as $$
U^\prime \colon= \{ 1, \ldots, n \}.
$$ Then of course $$ U^\prime \subset U, $$ and also $$ U \setminus U^\prime = \{ n+1 \}. $$ Let $A$ and $B$ be arbitrary subsets of $U$ . We want to count the total number of tru relations $A \subseteq B$ . The following four cases arise: Case 1. Suppose both $A$ and $B$ are subsets of $U^\prime$ . Then there are a total of $3^n$ true relations of the form $A \subseteq B$ , by our inductive hypothesis. Case 2. Suppose that $A \subseteq U^\prime$ and $B \not\subseteq U^\prime$ . Then $n + 1 \in B$ but $n + 1 \not\in A$ . Let us form the set $B^\prime$ as $$
B^\prime \colon= B \setminus \{ n+1 \}.
$$ Then both $A$ and $B^\prime$ are subsets of $U^\prime$ , and so by our inductive hypothesis there are a total of $3^n$ true relations of the form $A \subseteq B^\prime$ , and since $B^\prime \subset B$ , we can conclude that corresponding to each of the $3^n$ true relations of the form $A \subseteq B^\prime$ , we have the true relation $A \subseteq B$ . Thus there are at least a total of $3^n$ true relations of the form $A \subseteq B$ . On the other hand, as $n+1 \in B$ but $n+1 \not\in A$ , so if $A \subseteq B$ , then we also have $A \subseteq B^\prime$ , and since there are a total of $3^n$ true relations of the form $A \subseteq B^\prime$ , we can conclude that there are at most a total of $3^n$ true relations of the form $A \subseteq B$ . From the preceding two paragraphs we can conclude that there are exactly $3^n$ true relations of the form $A \subseteq B$ . Case 3. Suppose that $A \not\subseteq U^\prime$ and $B \subseteq U^\prime$ . Then $n + 1 \in A$ but $n+1 \not\in B$ . Thus $A \not\subseteq B$ . There are a total of $0$ true relations of the form $A \subseteq B$ . Case 4. Suppose that $A \not\subseteq U^\prime$ and $B \not\subseteq U^\prime$ . Then $n+1 \in A$ and $n+1 \in B$ . Let us form the sets $A^\prime$ and $B^\prime$ as follows: $$
A^\prime \colon= A \setminus \{ n+1 \} \qquad \mbox{ and } \qquad B^\prime \colon= B \setminus \{ n+1 \}. 
$$ Then of course $$ A^\prime \subseteq U^\prime \qquad \mbox{ and } \qquad B^\prime \subseteq U^\prime. $$ So by our inductive hypothesis there are a total of $3^n$ true relations of the form $A^\prime \subseteq B^\prime$ .
But whenever $A^\prime \subseteq B^\prime$ holds, we also have $$
A^\prime \cup \{ n+1 \} \subseteq B^\prime \cup \{ n+1 \},
$$ that is, $$
A \subseteq B.
$$ Thus there are at least $3^n$ true relations of the form $A \subseteq B$ . On the other hand, suppose that $A \subseteq B$ . Let $x \in A^\prime$ . Then $x \neq n+1$ and as $A^\prime \subset A$ , so we also have $x \in A$ , which from the supposition of $A \subseteq B$ implies that $x \in B$ ; thus $x \in B$ and $x \neq n+1$ , which implies that $x \in B^\prime$ . So it follows that $A^\prime \subseteq B^\prime$ . Therefore whenever $A \subseteq B$ holds, we also have $A^\prime \subseteq B^\prime$ . Thus there are at most $3^n$ true relations of the form $A \subseteq B$ . Combining the conclusions of the preceding two paragraphs we can conclude that there are exactly $3^n$ true relations of the form $A \subseteq B$ . Since the above four cases are mutually exclusive and collectively exhaust all the possibilities for subsets $A$ and $B$ of our set $U$ , therefore we can conclude that there are a total of $$
3^n + 3^n + 0 + 3^n = 3 \times 3^n = 3^{n+1}
$$ true relations of the form $A \subseteq B$ , where $A$ and $B$ are arbitrary subsets of the set $U$ given by $$
U = \{ 1, \ldots, n, n+1 \}.
$$ Thus by the principle of mathematical induction our assertion holds for all positive integers $n$ . Is my proof correct in each and every detail of its logic and presentation? If so, is my presentation clear enough? Or have I made any errors or mistakes?","['relations', 'solution-verification', 'combinatorics', 'elementary-set-theory', 'induction']"
3753714,Derivative of $y = \log_{\sqrt[3]{x}}(7)$.,"Never dealt with a derivative of these type. My approach was $$y = \log_{\sqrt[3]{x}}(7) \iff 7 = (\sqrt[3]{x})^y.$$ Then, $$\frac{d}{dx}(7) = \frac{d}{dx}\left(\sqrt[3]{x}\right)^y \Rightarrow (\sqrt[3]{x})^y = e^{\frac{y\ln(x)}{3}} $$ From here, $0 = e^u\dfrac{du}{dx}$ and $u = \dfrac{y\ln(x)}{3}.$ Thus, $$0 = \frac{du}{dx} = \frac{y}{3x} +\frac{\ln(x)}{3}\frac{dy}{dx}.$$ Which implies that $$\frac{dy}{dx}= \frac{-\log_{\sqrt[3]{x}}(7)}{x\ln(x)}.$$ Is this the correct derivative? Can I alternatively use $\log_{b}(a) = \dfrac{\ln(a)}{\ln(b)}$ , with $b = \sqrt[3]{x}$ and $a=7$ ? In that case, I arrive at $$\frac{dy}{dx}= \dfrac{-3\ln(7)}{x(\ln(x))^2}.$$","['calculus', 'derivatives', 'logarithms']"
3753715,Show that $\lim_{x\to 0^+} xf'(x)=0$.,"Suppose $f$ is a continuous function on $[0,1]$ . Suppose $f$ is differentiable on $(0,1)$ and its derivative is continuous on $(0,1)$ . Then is it true that $$\lim_{x\to 0^{+}} xf'(x)=0 \ ?$$ I only thought about functions like $x^{a}$ for $a>0$ . It seems to be true. Indeed, in fact if we assume $f'$ is monotonically decreasing and non negative then $$0\le xf'(x) \le \int_0^x f'(t) \, dt = f(x)-f(0)$$ But I am not sure how to do it generally. Any help suggestions?","['integration', 'limits', 'derivatives', 'real-analysis']"
3753755,Suppose $\forall A\in\mathcal F\:\exists B\in\mathcal G(A\cap B=\emptyset)$. Prove that $\bigcup\mathcal F$ and $\bigcap\mathcal G$ are disjoint.,"This is exercise $3.4.15$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $\mathcal F$ and $\mathcal G$ are nonempty families of sets and every element of $\mathcal F$ is disjoint from some element of $\mathcal G$ . Prove that $\bigcup\mathcal F$ and $\bigcap\mathcal G$ are disjoint. The author gives a proof by contradiction but I attempted to give a direct proof as follows: Suppose $\forall A\in\mathcal F\exists B\in\mathcal G(A\cap B=\emptyset)$ . Let $x$ be an arbitrary element of $\bigcup\mathcal F$ . So we can choose some $A_0$ such that $A_0\in\mathcal F$ and $x\in A_0$ . Since $\forall A\in\mathcal F\exists B\in\mathcal G(A\cap B=\emptyset)$ and $A_0\in \mathcal F$ , we can choose some $B_0$ such that $B_0\in\mathcal G$ and $A_0\cap B_0=\emptyset$ . From $A_0\cap B_0=\emptyset$ and $x\in A_0$ , $x\notin B_0$ . From $B_0\in\mathcal G$ and $x\notin B_0$ , $x\notin\bigcap\mathcal G$ . Thus if $x\in\bigcup\mathcal F$ then $x\notin\bigcap\mathcal G$ . Since $x$ is arbitrary, $\forall x(x\in\bigcup\mathcal F\rightarrow x\notin\bigcap\mathcal G)$ and so $\bigcup\mathcal F\cap\bigcap\mathcal G=\emptyset$ . Therefore if $\forall A\in\mathcal F\exists B\in\mathcal G(A\cap B=\emptyset)$ then $\bigcup\mathcal F\cap\bigcap\mathcal G=\emptyset$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3753760,Covering of a compact set,"Let $K$ be a compact subset of $\mathbb{R}^n$ . Fix a constant $r>0$ , I'm wondering whether there exists a finite collection of points $x_1,\dots,x_k \in K$ such that the collection of open balls $\{B(x_i,2r)\}_{i=1}^{k}$ forms an open cover of $K$ while $B(x_i,r)$ are mutually disjoint. I am looking for some variations of covering lemmas in $\mathbb{R}^n$ but failed to find any. Any insight or familiarity with would be appreciated.",['real-analysis']
3753772,Showing a series of functions converges to a periodic function.,"Let $z = x+iy$ and let $k \in \mathbb{C}$ be a constant. I am reading a paper from Perelman where he considers the function, \begin{align*}
\mathrm{f}&:\mathbb{C}\backslash\ D \longrightarrow \mathbb{R}\\[3mm]
&:z \longmapsto \mathfrak{R}[\ln\left(1+\frac{4k^{3}}{(z + k)^{2} (z - 2k)}\right)]
\end{align*} where $k \in \mathbb{C}$ is a constant and $D$ is a discrete subset of $\mathbb{C}$ Perelma says that that the series converges $$
\sum_{a,b\ \in\ \mathbb{Z}}\mathrm{f}\left(z + a + \mathrm{i}b\right)
$$ converges to a function, $\mathrm{g}\left(z\right)$ , which $\textbf{is}$ $1$ -periodic. It is not clear to me whether I have to find this function $\mathrm{g}\left(z\right)$ explicitly in order to show this $1$ -periodicity ?. In any case, I am quite at a loss as how to move forward to show the $1$ -periodicity and convergence of this series. By "" $1$ -periodic"", I mean with respect to $x$ and $y$ . $\textbf{EDIT/UPDATE}$ : I am now clear on the $1$ -periodicity of the series, however it is still unclear to me why this series converges? $\textbf{EDIT/UPDATE}$ : I realised I copied Perelman's function incorrectly, I have since changed this in the text above, also you can see the relevant part of his paper here .","['complex-analysis', 'periodic-functions', 'analysis', 'sequences-and-series']"
3753785,Prove that the serie $\sum_{n=1}^\infty \frac{1}{n(n + a)}$ converges,"I was trying to solve this problem but i got stucked. I use the Radio Test to compute the convergence interval, but it doesnt works in this case, i need help... Prove that the serie $\sum_{n=1}^\infty \frac{1}{n(n + a)}$ converges Calculate the sum of the serie","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3753802,A property of the function $\frac{\sin x}{x}$,"How can one prove, that $0$ is the only value of $\frac{\sin x}{x}$ taken infinitely often? What I tried: To see how the graph looks like https://www.wolframalpha.com/input/?i=%28sin+x%29%2Fx The function is continuous and has infinitely many positive and negative values, so by Darboux it has infinitely many zeroes. Also, the line $y=0$ is an asymptote both in $\pm\infty$ , but this thing only, doesn't imply the result. What else should I use?","['limits', 'functions', 'real-analysis']"
3753806,Determine the $\lambda \in \mathbb{R}$ for which this integral converges,"Consider the cuspoidal cubic given by $x^2 - y^3 =0$ in $\mathbb{C}^2$ . The log-canonical threshold of the cuspoidal cubic is determined by finding the largest value of $\lambda \in \mathbb{R}$ for which the integral $$\int \frac{1}{| x^2 - y^3|^{2\lambda}}$$ converges in a neighborhood of $0$ . There is an algebraic way of showing that $\lambda = \frac{5}{6}$ , but I'm curious as to whether we can deduce this from the convergence of the above integral. Does anyone know how to show that the above integral converges in a neighborhood of $0$ only if $\lambda =\frac{5}{6}$ ? Additional Remark: From what I understand, to compute the lct, the integral needs to converge in a neighborhood of $0$ in $\mathbb{C}^2$ . Regardless, I do not know how to integrate the function if $x$ and $y$ are real variables. Both settings may be of interest. Thank you for your interest in this problem","['integration', 'calculus', 'algebraic-geometry', 'convergence-divergence']"
3753813,"Help to solve $y'=y$, building exp function","I come to ask for help building the exponential function as the solution to $y'=y$ . This question is different from  : Prove that $C\exp(x)$ is the only set of functions for which $f(x) = f'(x)$ Since I would like help to prove it using the following arguments : show that the solution should verify : $f(a+b)=f(a)f(b)$ show that $f(x)$ for any $x$ in $\Bbb R$ , will write $f(x)=c a^x$ . show that if the function value is $1$ at $0$ , using a numerical tool we will be able to find the Euler constant value and not it e. For the moment here are my ideas : no idea – this is here that I need the more help prove it for naturals, rationals then all real numbers using density arguments. using Euler method,I can show that $a$ is the limit of $f(1) = \lim_{n\to\infty} (1+1/n)^n$ As you can see here, the computation will tend to $e$ : https://www.freecodecamp.org/news/eulers-method-explained-with-examples/ Many thanks, I'll appreciate your help G","['alternative-proof', 'proof-writing', 'exponential-function', 'ordinary-differential-equations']"
3753816,"Expected number of fair coin tosses until 2 consequitive heads, a non-recurseive solution","Trying to find the expected number of fair coin tosses until 2 consequitive heads fall, I didn't come up with the recursive solution initially and used a more 'iterative' or 'brute-force' approach, which lead me to a different answer, without any hints where I might be wrong. I couldn't find a similar solution on the Internet, to which I could compare mine, so I'd love if someone could point me to the flaw in my logic. Here is my attempt: Let $X$ be the random variable for which I'm searching the expected value $\text{E}X$ . I'm building a series $\sum_0^\infty n \cdot P(X=n)$ , and my goal is to find the probabiity that a game lasts $n$ tosses - $P(X = n)$ , for all $n \in \mathbb N$ . The general form of a single play is as follows: $$ \underbrace{\dots 0\,1\,0 \dots 0\,1\,0\dots0}_{n \,\text{tosses}}\;1\,1 $$ i.e. a bunch of heads, surrounded by tails, and two heads at the end. Denote the number of tosses before the final two heads with $n$ . It is clear there are at least 2 tosses in a single (successful) run, and $n \ge 0$ . For convenience I use $n$ for the tosses before the final two heads, and not for the length of the whole run. Now I need to count the possible plays for any given length (starting from 2), and the answer is then: $$\text{E}X := \sum_{t=0}^\infty t \cdot P(X=t) = \sum_{n=0}^\infty (n+2) \cdot \frac{\text{No. of valid non-final parts of length } n}{2^{n+2}}$$ (The second sum in fact skips runs of length 0 and 1 as they contribute nothing to the expected value.) The number of valid plays of length $n$ I find by looking at all possible cases for the number of heads in the non-final part of the string - let's call that $k$ . For a given $n$ , the number of non-final heads can be at most half of $n$ , since each head must be followed by a tail. Let's fix an $n \in \mathbb N$ and a number of heads $k \in [0,\lfloor \frac{n}{2}\rfloor]$ . The picture in my head is like this: $$ \|\,(10)\,\|\,(10)\,\|\,\dots\,\|\,(10)\,\| \; 1\, 1 $$ where "" $\|$ ""s represent the $k + 1$ placeholders for the $n-2k$ tails I must arrange around the $k$ head-tail pairs in a $(n + 2)$ -toss-long play. The total number of positions to ""put stuff"" (tails and head-tails pairs) is $(k + 1) + (n-2k) = n - k + 1$ . Moreover, every configuration is uniquely described by the positions of the $k$ head-tail pairs, and all possible positions of $k$ head-tail pairs make up a valid toss sequence. Therefore, given $n$ and $k$ , the number of valid runs with $k$ non-final tails of length $n+2$ is $\binom{n-k+1}{k}$ . (These 2-3 lines were a part I suspected for some time that it could be wrong, but I cannot see any mistakes here.) Letting $k$ range over $[0, \lfloor \frac{n}{2} \rfloor]$ , the probability that a play lasts $n + 2$ tosses is: $$P(X = n+2) = \frac{\sum_{k=0}^{ \lfloor n / 2 \rfloor} \binom{n-k+1}{k}}{2^{n+2}}$$ And finally, the series for the expected value: $$\text{E}X = \sum_{n=0}^\infty n \cdot P(X=n) = \sum_{n=0}^\infty \left(\frac{n+2}{2^{n+2}}\cdot\sum_{k=0}^{ \lfloor n / 2 \rfloor} \binom{n-k+1}{k}\right)$$ Giving this to Wolfram Mathematica, I see that it quickly converges to $8.888...$ .
After 2 or 3 random attempts to ""make it work"" I found that removing the ""+ 1"" part in the binomial coefficient produces the correct answer (6), so I thought this part could be wrong. There should definitely be a $+1$ in it, though (for the reasons I explained above), and I think it's just a coincidence that I get the correct answer this way. As much as I hope that is not the case, it's possible that only my code is wrong, here's it for reference: https://pastebin.com/iuPW7f8H (I couldn't make it compute the actual limit so I checked the result for some sample points). (I use the words 'run' and 'play' interchangably for a single sequence of tosses in a valid experiment as said in the problem, please let me know if there's a more standard term for this.)","['combinatorics', 'probability']"
3753819,Problem 7.V Bartle Elements of Integration,"$\textbf{Question:}$ Let $(X,\mathcal{F},\mu)$ be an arbitrary measure space. Let $\varphi: \mathbb{R} \rightarrow \mathbb{R}$ be continuous and satisfy for some $K>0$ : $$ \vert \varphi(t) \vert \leq K \vert t \vert, \forall t\in \mathbb{R} \tag{$*$}$$ If $f \in L^p$ , then $\varphi \circ f$ belongs to $L^p$ . Conversely, if $\varphi$ does not satisfy (*), there exists a measure space $(X,\mathcal{F},\mu)$ and a function $f \in L^p$ such that $\varphi \circ f$ does not belong to $L^p$ . $\textbf{My attempt:}$ If $\varphi$ satisfy $(*)$ we have for each $(X,\mathcal{F},\mu)$ and $x\in X$ $$ \vert (\varphi \circ f)(x) \vert = \vert \varphi(f(x)) \vert \leq K \vert f(x) \vert $$ $$ \implies \vert \varphi \circ f \vert^p \leq K^p \vert f \vert^p $$ So $\varphi \circ f \in L^p$ . I can't solve the other statement, help please.","['measure-theory', 'functional-analysis', 'real-analysis']"
3753849,A good way to proceed to Hartshorne. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 3 years ago . Improve this question I am going to take a course in Algebraic Geometry covering chapter II and III of Hartshorne next year. Before this, I have the option to take either Commutative Algebra (Mainly use Atiyah) or Riemann Surface & Algebraic Curves (Mainly Rick Miranda) next semester. As I know, commutative algebra provides the necessary algebraic tools to handle algebraic geometry. Some said it can be learnt along Hartshorne while some said it is better to learn commutative algebra before learning Hartshorne. Also, some mentioned Riemann Surface & Algebraic Curves (over $\mathbb{C}$ ) provides geometrical intuition as they are the prototype to modern algebraic geometry which helps in understanding the concept in Hartshorne. Which is more important for me to move into Chapter II and III of Hartshorne? I wish to pick both but unfortunately, I am overload next semester so I can only pick one. By the way, I had taken a course in algebraic curves where lecture note by William Fulton was used. Thus, I know a bit commutative algebra from there but not as much as in Atiyahs'","['algebraic-curves', 'riemann-surfaces', 'algebraic-geometry', 'commutative-algebra']"
3753883,How can I integrate $\int \frac{u^3}{(u^2+1)^3}du?$,"How to integrate following $$\int\frac{u^3}{(u^2+1)^3}du\,?$$ What I did is here: Used partial fractions $$\dfrac{u^3}{(u^2+1)^3}=\dfrac{Au+B}{(u^2+1)}+\dfrac{Cu+D}{(u^2+1)^2}+\dfrac{Au+B}{(u^2+1)^3}$$ After solving I got $A=0, B=0, C=1, D=0, E=-1, F=0$ $$\dfrac{u^3}{(u^2+1)^3}=\dfrac{u}{(u^2+1)^2}-\dfrac{u}{(u^2+1)^3}$$ Substitute $u^2+1=t$ , $2u\ du=dt$ , $u\ du=dt/2$ $$\int\frac{u^3}{(u^2+1)^3}du=\int \frac{dt/2}{t^2}-\int \frac{dt/2}{t^3}$$ $$=\frac12\dfrac{-1}{t}-\frac{1}{2}\dfrac{-1}{2t^2}$$ $$=-\dfrac{1}{2t}+\dfrac{1}{4t^2}$$ $$=-\dfrac{1}{2(u^2+1)}+\dfrac{1}{4(u^2+1)^2}+c$$ My question: Can I integrate this with suitable substitution?  Thank you","['integration', 'indefinite-integrals', 'calculus', 'substitution']"
3753884,Motivation commutative algebra [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 years ago . Improve this question I'm starting to learn commutative algebra. I heard before that a reason to learn it is because it unifies the language of algebraic geometry and algebraic number theory. Are there any examples of problems in algebraic geometry and algebraic number theory, that share the same notions in commutative algebra? It just seems to me. bit disconnected. I've been reading Atiyah and Eisenbud. I know a little bit of the language of AG, but don't know how the DVR and Dedekind domains relate to any AG. Any help or references would be appreciated.","['algebraic-geometry', 'abstract-algebra', 'algebraic-number-theory', 'commutative-algebra']"
3753915,Expected value of sum of a random variable where the upper limit is a random variable.,"Consider $X_i$ to denote the numerical value for the i-th event. Assume it is IID. Say we want to compute $$
c = E\left[\sum_{i=1}^NX_i\right]
$$ $N$ is a random variable. You can think of it as represent the number of events needed to get some constant sum $c$ . My question is, can the above be simplified in the following manner? $$
c = \sum_{i=1}^NE[X_i] \\
= NE[X_i]
$$","['expected-value', 'probability', 'random-variables']"
3754019,Is every contractible subspace of the unit ball a retract of the unit ball?,"I have a subspace of a unit ball, and I want to prove that this subspace is a retract of the ball. I know that homology groups and homotopy groups of this subspace vanish, and I strongly believe that this subspace is a CW complex, which would then imply that my subspace is contractible. I also believe that the said subspace has finitely many cells. I am thus left with the question: Is every contractible subspace of the unit ball a retract of the unit ball? If not, what about every contractible finite CW subcomplex? Thanks, Maithreya","['general-topology', 'algebraic-topology']"
3754033,$\zeta(4)$ in terms of a series of $\zeta(3)$ and harmonic numbers,"The other day I believe I found a proof that: $$\sum_{k=1}^\infty \frac{\zeta(2)-H_k^{(2)}}{k} = \zeta(3)$$ I was wondering if a general recursion like this was well known, but I couldn't find anything.
I tried the following result which seems to hold. $$\sum_{k=1}^\infty \frac{\zeta(3)-H_k^{(3)}}{k} = \frac{\zeta(4)}{4}$$ Can anyone prove that this last result is correct or incorrect? Thanks.","['riemann-zeta', 'harmonic-numbers', 'sequences-and-series']"
3754053,"Prove that if $G$ is a finite group in which every proper subgroup is nilpotent, then $G$ is solvable.","Prove that if $G$ is a finite group in which every proper subgroup is nilpotent, then $G$ is solvable. (Hint: Show that a minimal counterexample is simple. Let $M$ and $N$ be distinct maximal subgroups chose with $|M\cap N|$ as large as possible and apply Part 2 of Theorem 3. Now apply the methods of Exercise 53 in Section 4.5.) This is Exercise 6.1.35 in Dummit and Foote. Using the idea from the hint, I tried the following proof. But I couldn't prove that $M\cap N=1$ . Does anyone know how to prove this? Thanks. Here is what I have done so far: We proceed by induction. If $|G|=2$ , then $G$ is clearly solvable. Let $|G|\geq6$ . Assume that the statement is true for all groups of order $<|G|$ . If $G$ is of prime order, then clearly $G$ is solvable. So we assume that $G$ is not of prime order. Since $G$ is finite, $G$ contains nontrivial maximal subgroups. Claim: There exists a maximal subgroup of $G$ which is normal. Suppose not. Since conjugates of a maximal subgroup are maximal subgroups, $G$ has more than one maximal subgroups. Let $M$ and $N$ be the distinct maximal subgroups such that $|M\cap N|$ is maximal. Since $M$ and $N$ are nilpotent, $M\cap N<N_M(M\cap N)$ and $M\cap N<N_N(M\cap N)$ . (Here I want to show that $M\cap N=1$ following the hint.) Now since $G\neq\bigcup_{g\in G}gMg^{-1}$ , there exists $H\leq G$ maximal such that $H$ is not a conjugate of $M$ . So $G$ has at least the following number of nonidentity elements: \begin{equation*}
\begin{split}
(|M|-1)|G:N_G(M)|+(|H|-1)|G:N_G(H)|=&(|M|-1)|G:M|+(|H|-1)|G:H|\\=&2|G|-|G:M|-|G:H|\\\geq&2|G|-\frac{1}{2}|G|-\frac{1}{2}|G|=|G|
\end{split}
\end{equation*} which is a contradiction. Hence there exists a maximal subgroup of $G$ which is normal. Now let $M\unlhd G$ be a maximal subgroup. Then $M$ is nilpotent and hence solvable. Now $|G/M|<|G|$ . Since every subgroup of $G$ is nilpotent, by the correspondence theorem, every subgroup of $G/M$ is nilpotent. So $G/M$ is solvable. Hence $G$ is solvable.","['nilpotent-groups', 'group-theory', 'abstract-algebra', 'solvable-groups']"
3754083,"A question about $f:(0,1]\times[0,1]\rightarrow N_{l^1(\mathbb{R}^\omega)}(0,2)$","Let $L$ be the $l^1$ topology on the subset of $\mathbb{R}^\omega$ with finite $l^1$ norm. ( $\left\|x\right\|_{l^1(\mathbb{R}^\omega)}:=\sum_i|x_i|$ . $l^1$ topology is the metric topology induced by this norm.) Say $f:(0,1]\times[0,1]\rightarrow N_L(0,2)$ is any continuous function s.t. $f(t,0)\equiv 0$ and $f(t,1)\equiv(1,0,0...)$ . Then, would there always exist $\{t_n\},\{x_n\}$ s.t. $t_n\rightarrow 0$ and $f(t_n,x_n)$ converges pointwisely to a point in $N_L(0,\frac{1}{2})\setminus\{0\}$ ? ( $N_L(0,r)$ : the open ball of radius $r$ centered at 0, with respect to the metric of $L$ )","['general-topology', 'analysis']"
3754137,limit of the mollifying sequence,"Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ be an $L^1(\mathbb{R}^2; \mathbb{R})$ function. Let $A \subset \mathbb{R}$ be a measurable set.
Let $\eta: \mathbb{R}\rightarrow \mathbb{R} \in C_c^{\infty}(\mathbb{R}),$ with support in $[-1,1]$ such that $\int\limits_{\mathbb{R}}\eta(x)dx=1.$ Then consider the following limit \begin{eqnarray}
\lim\limits_{\epsilon \rightarrow 0}\frac{1}{\epsilon}\int\limits_{\mathbb{R}}
\int\limits_{A} f(x,y)\eta\left(\frac{x-y}{\epsilon}\right)dy dx.
\end{eqnarray} What is the value of the limit? How to prove it. P.S: Define $\eta_{\epsilon}(x):=\frac{1}{\epsilon}\eta(\frac{x}{\epsilon}).$ Then $\eta_{\epsilon} \rightarrow \delta_0.$ So, I think the limit is, \begin{eqnarray}
\int\limits_{A} f(x,x)dx.
\end{eqnarray} is it correct? How to prove it?","['integration', 'measure-theory', 'real-analysis']"
3754143,"Can $\int_0^\infty f (x) \, dx$ exist if $\lim_{x \to \infty} f(x)$ does not exist?","Is is possible to have a function for which $\lim_{x \to \infty} f(x)$ does not exist, but $\int_0^\infty f(x) \, dx$ exists and is finite? I think I've found an example actually, but I'm not sure it works. Let $H_n$ be the $n$ th harmonic number. Consider $f$ such that $f(x) = 1$ for $x \in [0,1)$ and $f(x) = (-1)^{n}$ for $x \in [H_n , H_{n + 1})$ . It seems that $$
\int_0^\infty f(x) \, dx = \sum_{n = 1}^\infty \frac{(-1)^{n + 1}}{n} = \log 2
$$ even though $\lim_{x \to \infty} f(x)$ doesn't exist. Does this work?","['limits', 'improper-integrals', 'harmonic-numbers', 'sequences-and-series']"
3754159,Categorical definition of Spectrum of a ring as a colimit?,"I've been watching AGITTOC: Algebraic geometry in the time of Covid; Pseudolecture 3 , where a user describes an alternative definition of the spectrum of a ring: (Name hidden for privacy): I like the definition of $\operatorname{Spec}(A)$ that doesn't include the word
prime ideal, by a colimit of $\operatorname{Hom}(A, k)$ where $k$ run over all fields and the
maps are morphisms that make the diagrams commute. I've been trying to find a reference to this, to no avail.  The closest thing  could find is this reference in the Stacks project which talks about how if the ring $A$ is built up as a colimit of $A_i$ , then the spectrum $\operatorname{Spec}(A)$ is built up as the limit of $\operatorname{Spec}(A_i)$ .  This does not seem to be what I am looking for. Can someone please provide a reference and/or quickly exposit this definition of $\operatorname{Spec}(A)$ which I have not seen before?","['algebraic-geometry', 'category-theory']"
3754166,$k$ regular graph with $(k+1)^2 -1$ vertices and matching saturates $n-k$ vertices,"We have a $k$ regular graph $G$ with $n=(k+1)^2-1$ vertices and $k \geq 1$ is even. Prove that the graph has a matching saturates at least $n-k$ vertices. My first intuition is to use the defect version of Tutte's Theorem. However, I am stuck on where to start. Can anyone help me with that?","['graph-theory', 'matching-theory', 'combinatorics', 'discrete-mathematics']"
3754177,"Brezis section 7.2, theorem 7.3","This is from Brezis' Functional Analysis, Sobolev Spaces, and PDEs book. Theorem 7.3 reads: Let $E$ be a Banach space, $F: E \rightarrow E$ a Lipschitz map. If $u_0 \in E$ then there exists a unique solution $u \in C^1([0,\infty); E)$ of the problem $$\begin{cases} \frac{du}{dt}=Fu(t) &\mbox{on } [0, \infty), \\ u(0) = u_0. & \\ \end{cases}$$ The proof defines a Banach space: let $k > 0$ , and set $$ X = \{u \in C([0, \infty); E) \mid \sup_{t \geq 0} e^{-kt} \lVert u(t) \rVert < \infty\}. $$ Then if $u \in X$ , we claim $$ (\Phi u)(t) = u_0 + \int_0^t F(u(s))ds $$ is also an element of $X$ . My question is why? If $F = \mbox{id}_E$ and $u(t) = f(t)u_0$ with $\lVert u_0 \rVert = 1$ and $f(t) \in \mathbb R_{>0}$ , then membership $u \in X$ says $\sup_{t \geq 0} e^{-kt}f(t) < \infty$ while membership $\Phi u \in X$ says $\sup_{t \geq 0} e^{-kt}(1 + \int_0^t f(s)ds) < \infty$ . It seems to me that although $e^{-kt}f(t)$ might be bounded, $e^{-kt}\int_0^t f(s)ds$ might not, since there are functions whose integral grows quicker than itself. On the other hand, I can somewhat reason that this growth is ""polynomial"", in the sense $\int_0^t sds = \frac{t^2}{2}$ grows faster than $t$ but polynomially so, and therefore continues to be controlled by $e^{-kt}$ . Is there any direct proof or intuition for why $u \in X$ implies $\Phi u \in X$ ?","['functional-analysis', 'analysis', 'real-analysis']"
3754228,Understanding exact tests for clinical trial data,"A clinical trial is done with 400 persons suffering from a particular disease, to find out whether a treatment is better than placebo. They are randomised to receive treatment or placebo (200 participants each). The outcome studied is how many get cured. The results are shown in the following 2x2 table: \begin{array} {|r|r|}
\hline
\text{ } & \text{Treatment group} & \text{Placebo group}\\
\hline
\text{Cured} & 172 & 151 \\
\hline
\text{Not cured} & 28 & 49
\\
\hline
\text{Total} & 200 & 200
\\
\hline
\end{array} The odds ratio calculated from this table is $1.99$ . The objective now is to test the null hypothesis (odds ratio = 1) against the alternate hypothesis (odds ratio is not 1). Ludbrook's 2008 article describes an exact test for this scenario: The formula for executing a two-sided randomization test, adapted to a
2x2 table with the constraint that the column totals are fixed ( single
conditioning ), is: P=(All tables for which the summary statistic is at least as extreme
as that observed, in either direction)/All possible tables with the
same column totals I am a bit confused about what exactly it means. Does it mean I should form all possible tables with 200 treatment and 200 control participants, with each participant having a 50% chance of getting cured? Then there would be $2^{200} \times 2^{200}=2^{400}$ possible tables, each being equally likely. I would then calculate what fraction of these tables give an odds ratio equally or more extreme than the one I got experimentally, i.e. $1.99$ . This would give me the p-value. Is this the correct interpretation? If not, why? If so, why the assumption of 50% cure rate? Why not 20%, 70%, 90%, or any other number? (I would have contacted the author directly, but it turns out he is deceased. That is why I asked this question here.) Reference John Ludbrook, Analysis of 2 × 2 tables of frequencies: matching test to experimental design, International Journal of Epidemiology, Volume 37, Issue 6, December 2008, Pages 1430–1435, https://doi.org/10.1093/ije/dyn162","['p-value', 'statistical-inference', 'statistics', 'hypothesis-testing']"
3754263,Did I do something wrong in solving the functional equation $2f(x+y)+6y^3=f(x+2y)+x^3$ or does it have no solutions?,"I was trying to solve this functional equation that I found in some papers. $$f:\mathbb{R} \to \mathbb{R}$$ $$2f(x+y)+6y^3=f(x+2y)+x^3$$ for every $x,y \in \mathbb{R}$ First, I made $x=y=0$ . Then: $$2f(0)+0=f(0)+0$$ $$f(0)=0$$ I then made $x=-y$ . I get: $$2f(-y+y)+6y^3=f(-y+2y)+(-y)^3$$ $$2f(0)+7y^3=f(y)$$ Because we know that $f(0)=0$ , we can say that: $$f(x)=7x^3$$ But when I try to use $f(x)=7x^3$ in the original functional equation I don't get something that is equal for every $x,y$ . Does that mean there are no solutions to this functional equation or did I do something wrong?","['functional-equations', 'functions', 'solution-verification']"
3754270,Prove inequality $\tan(x) \arctan(x) \geqslant x^2$,"Prove that for $x\in \left( - \frac{\pi} {2},\,\frac{\pi}{2}\right)$ the following inequality holds $$\tan(x) \arctan(x) \geqslant x^2.$$ I have tried proving that function $f(x) := \tan(x) \arctan(x) - x^2 \geqslant 0$ by using derivatives but it gets really messy and I couldn't make it to the end. I also tried by using inequality $\tan(x) \geqslant x$ on the positive part of the interval but this is too weak estimation and gives opposite result i.e. $x\arctan(x) \leqslant x^2$ .","['inequality', 'inverse-function', 'a.m.-g.m.-inequality', 'real-analysis', 'trigonometry']"
3754304,verifying $\lim\limits_{x \to \infty} (1+\frac{1}{\sqrt{x}})^x$,"What is the limit of $\lim\limits_{x \to \infty} (1+\frac{1}{\sqrt{x}})^x$ ? I tried to solve it but I am not sure if it is appropriate to solve it this way. $(1+\frac{1}{\sqrt{x}})^x =\exp\Bigl({x\times\ln\bigl(1+\frac{1}{\sqrt{x}}\bigr)\Bigr)}\tag{*}$ Let $\,t=\frac {1}{\sqrt{x}} $ $\,t=\frac {1}{\sqrt{x}} \Rightarrow t^2=\frac {1}{x}\Rightarrow \frac {1}{t^2}=x $ By substituting in $(*) $ we have $\exp\Bigl(x\ln\bigl(1+\frac{1}{\sqrt{x}}\bigr)\Bigr)=\exp\Bigl(\frac{1}{t^2}\ln(1+t)\Bigr) $ as $\quad x\rightarrow \infty ,\quad \frac{1}{\sqrt{x}}\rightarrow 0,\quad$ so $t\rightarrow 0 $ $\lim\limits_{x \to \infty} (1+\frac{1}{\sqrt{x}})^x = \lim\limits_{t \to 0} \exp\bigl(\frac{1}{t^2}\ln(1+t)\bigr)$ as $t\neq 0 \,$ we can divide and multiply by $t$ : \begin{align}
\lim_{t \to 0} 
\exp\Bigl(\frac{1}{t^2}\times \ln(1+t)\Bigr)&=\lim_{t \to 0} \exp\Bigl(\frac{1}{t^2}\times \ln(1+t)\times \frac{t}{t}\Bigr)\\
&=\lim_{t \to 0} \exp\Bigl(\frac{1}{t}\times \frac {\ln(1+t)}{t}\Bigr)
\end{align} using L’Hospital’s rule, $\,\,\lim\limits_{t \to 0} \frac{\ln(1+t)}{t}=1$ $\lim\limits_{t \to 0}\exp\Bigl(\frac{1}{t}\times \frac {\ln(1+t)}{t}\Bigr)=\infty$","['indeterminate-forms', 'limits', 'calculus', 'real-analysis']"
3754308,"Let $f(x)$ be a polynomial of degree $8$ such that $f(r)=\frac1r$, for $r=1,2,3,\ldots,9$. Find $\frac1{f(10)}$.","Question: Let $f(x)$ be a polynomial of degree $8$ such that $f(r)=\frac1r$ , for $r=1,2,3,\ldots,9$ . Find $\frac1{f(10)}$ . My Approach: We know that $f(r)=\frac1r$ , which implies that $$rf(r)-1=0$$ Using the information that $f(r)=\frac1r$ , for $r=1,2,3,4...8,9$ , we get that $1,2,3,4,5...,8,9$ are roots of the equation $rf(r)-1=0$ . Which implies that $$rf(r)-1=(r-1)(r-2)(r-3)(r-4)(r-5)(r-6)(r-7)(r-8)(r-9)$$ .
Putting $r=10$ in the above equation, we get, $$f(10)=\frac{1+9!}{10}$$ and $\frac{1}{f(10)}$ as $$\frac{1}{f(10)}=\frac{10}{1+9!}$$ . But the answer is 5. Please help.","['algebra-precalculus', 'functions', 'solution-verification', 'polynomials']"
3754332,First prolongation formula,"My question is about the derivation of the prolongation formula from Olver's book:""Applications of Lie groups to differential equations"" Page 109. Considering a differential equation with independent variable(x) and one dependent variable(u):
(x,u) $\subset$ $X \times U$ The coordinate in first jet space $M^{(1)}$ is (x, $u^{(1)}$ ) = (x,u, $u_j$ ). Let u = f(x) is any function with $u_j = \frac{\partial u}{\partial x_j} $ First prolongation of a group action on M is given as: $pr^{1} g_\epsilon . (x,u^{(1)}) = (\tilde{x},\tilde{u}^{(1)})$ The dependent variable is unchanged here; I mean $\tilde{u} = \tilde{f}_\epsilon(\tilde{x}) = f[\Xi^{-1}_\epsilon(\tilde{x})] = f[\Xi_{-\epsilon} (\tilde{x})] $ To find the infinitesimal generator of pr(1) go we must differentiate the
formulas for the prolonged transformations with respect to e and set e = O.
Thus $pr ^{1} v= \xi ^{i}(x)\frac{\partial}{\partial x^i}+ \phi ^{j}(x,u^{1})\frac{\partial}{\partial u^j},$ where $ \phi ^{j}(x,u^{1})= \frac{d}{ d\epsilon}_{\epsilon|=0} [\frac{\partial \Xi^k_{-\epsilon}}{\partial\tilde{x}^j} ] (\Xi_{\epsilon}(x)). u_{k}= - \frac{\partial \xi^k}{\partial x^j}(x).  $ It seems simple, but I don't know how to calculate $ \phi ^{j}(x,u^{1}) $ . Can anybody help me to find the answer?
What kind of derivative is it? Olver obtained two types of terms multiplying $u_{k}$ , first: $\frac{\partial}{\partial\tilde{x}^j} [\frac{d\Xi^k_{-\epsilon}}{d\epsilon} ] (\Xi_{\epsilon}(x)) |_{\epsilon = 0} = \frac{\partial}{\partial x^j} [\frac{d\Xi^k_{\epsilon}}{d\epsilon} ] |_{\epsilon = 0} = - \frac{\partial \xi^k}{\partial x^j}(x)$ and second, $ \frac{\partial^{2} [\Xi^k_{-\epsilon} ]}{\partial\tilde{x}^j \partial\tilde{x}^l}  ((\Xi_{-\epsilon}(x))  [\frac{d\Xi^k_{\epsilon}}{d\epsilon} ](x) |_{\epsilon = 0} =0.$ Shoud I add this two term? How can I obtained them?
Thank you in advance!","['linear-algebra', 'lie-groups', 'ordinary-differential-equations', 'differential-geometry']"
3754397,Convergence of a sequence of uniformly integrable functions.,"Let $(\Omega,\mathscr{A},P)$ be a probability space, $(\mathscr{F}_n)$ a filtration on $\mathscr{A}$ , and $\nu$ be a finite measure dominated by $P$ . Let $(X_n)$ be a sequence of real random variables  with values in $[0,1]$ , adapted to $\mathscr{F}$ , i.e. for each $n$ , $X_n$ is $\mathscr{F}_n$ -measurable. Suppose that $$
\int_A X_n \mathrm{d}P = \nu(A) \quad\text{
for each $A \in \mathscr{F}_n$.}
$$ How can I prove that $(X_n)$ converges almost surely (i.e. almost everywhere), or in $L^1$ , to an integrable random variable $Z$ ? My attempt. I have tried to prove that $(X_n)$ is a Cauchy sequence in $L^1(P)$ . To this end, I  did $$
\begin{split}
\int |X_n - X_m|\mathrm{d}P &= \int_{\{X_n \ge X_m\}} (X_n - X_m)\mathrm{d}P + \int_{\{X_n < X_m\}} (X_m - X_n)\mathrm{d}P \cr
&=\int_{\{X_n \ge X_m\}} X_n \mathrm{d}P - \int_{\{X_n \ge X_m\}} X_m \mathrm{d}P 
 +\int_{\{X_n < X_m\}} X_m \mathrm{d}P - \int_{\{X_n < X_m\}} X_n \mathrm{d}P 
\end{split}
$$ Now, I could prove this if the following statement was true: For every $A \in \mathscr{F}_m$ there exist $B_n,C_n \in \mathscr{F}_n$ such that $$ B_n \subseteq A \subseteq C_n \qquad\text{and}\qquad P(C_n\setminus B_n) \to 0$$ Using this result, in fact, I would find that $$
\begin{split}
\int |X_n - X_m|\mathrm{d}P & \le 
  \int_{C_n} X_n\mathrm{d}P - \int_{B_n} X_m\mathrm{d}P
  + \int_{B_n^c} X_m\mathrm{d}P - \int_{C_n^c} X_n\mathrm{d}P \cr
&= \nu(C_n) - \nu(B_n) + \nu(B_n^c) - \nu(C_n^c) \cr
&= \nu(C_n) - \nu(B_n) + 1- \nu(B_n) - 1 + \nu(C_n) \cr
&= 2[\nu(C_n) - \nu(B_n)] \cr
&= 2\nu(C_n\setminus B_n).
\end{split}
$$ Note. I have little hope that the previous argument may be fixed. However, I might add the property that each $\mathscr{F}_n$ is generated by a finite partition $\mathscr{P}_n$ of $\Omega$ and that the partition $\mathscr{P}_m$ is finer than $\mathscr{P}_n$ if $m \ge n$ .","['measure-theory', 'convergence-divergence', 'probability-theory']"
3754405,The projection $G\rightarrow G/H$ is a fibre bundle with structure group $N(H)/H$?,"Suppose that $G$ is a Lie group and $H$ is a closed subgroup of $G$ . Then it is well known that the projection $$\pi:G\to G/H$$ has the structure of a locally trivial fibre bundle with fibre $H$ . As pointed out in the comments, it is usually understood to be a principal $H$ -bundle. However, in Bredon's book, Topology and Geometry , chapter $2$ , section $13$ , the author's first exercise is to show that $\pi$ is a fibre bundle with structure group $N(H)/H$ , where $N(H)$ is the normalizer of $H$ in $G$ ? The question is why the structure group here is $N(H)/H$ ? In particular this seems to be in contradiction to some of the discussion in the comments. The following is a copy of the relevant page from Bredon's book which contains all related informations (before this exercise, there is a detailed discussion of the construction of local trivializations):","['algebraic-topology', 'fiber-bundles', 'differential-topology', 'lie-groups', 'differential-geometry']"
3754417,How do I finish solving $f(x)f(2y)=f(x+4y)$?,"I'm trying to solve this functional equation: $$f(x)f(2y)=f(x+4y)$$ The first thing I tried was to set $x=y=0$ ; then I get: $$f(0)f(0)=f(0)$$ which means that either $f(0)=0$ or we can divide the equation by $f(0)$ and then $f(0)=1$ . Case 1: If $f(0)=0$ then we can try to set $x=0$ . Then; $$f(0)f(2y)=f(4y)$$ $$0=f(4y)$$ Which means that one of the solutions is a constant function $f(x)=0$ Case 2: If $f(0)=1$ . This is where I'm stuck. I tried to set $x=0$ , then I get: $$f(2y)=f(4y)$$ I also tried to set $x=-4y$ . Then I get: $$f(-4y)f(2y)=f(0)=1$$ I think that these two observations could be useful, but I don't know how to continue from here. I have guessed that another solution is $f(x)=1$ but I don't know how to show that there aren't any others as well.","['functional-equations', 'functions']"
3754445,How can one point determine a unique straight line in differentiation?,"I found a similar question and a beautiful answer here . However I'm not able to fully understand the answer and have a question on the selected answer at: Consider all the lines going through point $(x_0,f(x_0))$ . For every line, the relative error should approach $0$ as $x$ approaches $0$ because all these lines go through point $(x_0,f(x_0))$ , the linear approximation equals the function at $x=x_0$ . What is special about the tangent line in relation to the relative error ? Why does Arturo say only the tangent line makes the relative error zero ?","['calculus', 'derivatives', 'slope', 'tangent-line']"
3754447,Is The Set Of Subsequential Limits Always Closed/Compact? [duplicate],"This question already has answers here : Proof that the set of subsequential limits is closed (2 answers) Closed 3 years ago . I've been working my way through Rudin's PoMA, and I was thinking about subsequential limits. If you take a sequence with finitely many subsequential limits, then the set of subsequential limits is clearly closed and compact. Theorem 3.17 in Rudin states that the upper limit of a sequence is the limit of some subsequence. This gives me the feeling that perhaps the set of subsequential limits for a divergent sequence with infinitely many subsequnetial limits is also closed or compact. Admittedly, however, I don't think this follows directly from theorem 3.17. I've toyed with this idea for a bit, but I haven't been able to come up with a proof or a counter-example. Is this true or false, and what's the proof? Does this have any other interesting extensions/implications?","['limits', 'sequences-and-series', 'compactness', 'real-analysis']"
3754476,implication of the Abel–Ruffini theorem,"I am taking a course in abstract algebra, and we proved the following theorem: I want to prove something more specific. Let's look at polynomials of degree 5 over C.
Someone is claiming he has a magic formula, which receives the coefficients of a polynomial of degree 5, and returns its roots using only basic operations and radicals.
I want to understand, how I can prove this person wrong using the theorem above.
In this case, the theorem talks about the field of rational functions with 5 variables over C. It shows that I can't express $t_1, ..., t_5$ (the roots of f) in terms of $s_1,...,s_5$ , in this abstract field.
I understand the proof in this context, but I want to understand how I can use it concretely in order to prove this person wrong.
In the sources that I have seen, they say that Abel–Ruffini theorem implies what I want to prove, but they don't show how. Can someone help me understand how you can show this?
I am adding the proof we saw in the course:","['radicals', 'abstract-algebra', 'polynomials']"
3754492,Solving a third order Euler-Cauchy ODE,"I have been given the following ODE: $$(2x+3)^3 y''' + 3 (2x+3) y' - 6 y=0$$ and I have to solve it using Euler's method, which I am fairly familiar with. Now, I let $ 2x+3 = e^t$ and $y=e^{λt}$ After differentiating $y$ , I get that $$y''' = \frac{y_t'''-3y_t''+2y_t'}{e^{3t}}$$ and $y'$ is $$\frac{y_t'}{e^t}$$ Now after substituting in the given equation I get $$e^{3t} \frac{y_t'''-3y_t''+2y_t'}{e^{3t}} + 3e^t \frac{y_t'}{e^t} -6y=0 $$ After which I am left with the following homogeneous equation: $$y''' - 3y'' + 5y' -6y =0$$ Which can be easily solved and the solutions are (I checked in wolframalpha): $$C_1 e^{2t} + e^{\frac{t}{2}}(C_2 \cos(\frac{\sqrt {11}}{2} t) + C_3 \sin(\frac{\sqrt {11}}{2} t))$$ When I plug $2x+3=e^t$ back in, I get: $$y(x) = C_1(2x+3)^2 + C_2 \sqrt{2x+3}   \cos(\frac{\sqrt {11}}{2}\ln(2x+3)) +  C_3 \sqrt{2x+3}   \sin(\frac{\sqrt {11}}{2}\ln(2x+3))$$ But the wolframalpha solution for the whole eqauation is $$C_2(2x+3)^{\frac{3}{2}} + C_3(2x+3) + C_1\sqrt{2x+3}$$ Now, I am new to ODES so I can't rule out that I made a silly mistake. What I did when substituting back is essentially $e^t = 2x+3$ and $t=\ln(2x+3)$ Can anyone point out my mistakes?",['ordinary-differential-equations']
3754498,"Let $|G|=p^n, p$ a prime, and let $|G:C_G(x)|\leq p$ for all $x \in G$. Then $|G'|\leq p$.","Hi: I could solve (a) and (b). As for (c): Let $\phi:G\to G', \phi(x)=[x,y]$ for $y$ fixed. Then $\phi(gh)=[gh,y]=[g,y]^h[h,y]$ . By (b) $[g,y]^h=[g,y]$ and then $\phi(gh)=[g,y][h,y]=\phi(g)\phi(h)$ and $\phi$ is homomorphism. Also $ker(\phi)= C_G(y)$ (easy). Now if $\phi$ were onto, then $G/C_G(y)$ isomorphic to $G'$ and then $|G'|\leq p$ . Is $\phi$ onto? If it is I can't prove it. The two preceding problems in this book are these: I think they can help in the solution.",['group-theory']
3754506,"Prove that for any set $A$, $A = \bigcup \mathscr P (A)$.","Not a duplicate of Prove that $ (\forall A)\bigcup\mathcal P(A) = A$ Prove that for any set A, A = $\cup$ $\mathscr{P}$(A) This is exercise $3.4.16$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Prove that for any set $A$ , $A = \bigcup \mathscr P (A)$ . Here is my proof: Suppose $A$ is arbitrary. $(\rightarrow)$ Let $x$ be an arbitrary element of $A$ . Since $A\subseteq A$ then $A\in\mathscr P(A)$ . From $A\in\mathscr P(A)$ and $x\in A$ , $x\in\bigcup \mathscr P(A)$ . Therefore if $x\in A$ then $x\in\bigcup \mathscr P(A)$ . Since $x$ is arbitrary, $\forall x\Bigr(x\in A\rightarrow x\in\bigcup\mathscr P(A)\Bigr)$ and so $A\subseteq \bigcup\mathscr P(A)$ . $(\leftarrow)$ Let $x$ be an arbitrary element of $\bigcup\mathscr P(A)$ . So we can choose some $A_0$ such that $A_0\in\mathscr P(A)$ and $x\in A_0$ . $A_0\in\mathscr P(A)$ is equivalent to $A_0\subseteq A$ and since $x\in A_0$ , $x\in A$ . Therefore if $x\in\bigcup \mathscr P(A)$ then $x\in A$ . Since $x$ is arbitrary, $\forall x\Bigr(x\in\bigcup\mathscr P(A)\rightarrow x\in A\Bigr)$ and so $\bigcup\mathscr P(A)\subseteq A$ . From $A\subseteq \bigcup\mathscr P(A)$ and $\bigcup\mathscr P(A)\subseteq A$ we obtain $A= \bigcup\mathscr P(A)$ . Since $A$ is arbitrary, $\forall A\Bigr(A=\bigcup\mathscr P(A)\Bigr)$ . $Q.E.D.$ Is my proof valid $?$ Thanks for your attention.","['elementary-set-theory', 'proof-writing', 'solution-verification']"
3754510,"Rolling a dice twice, (1,1) = 1/36 not 2/36? (Generalized Counting Principle confusion)","So I am confused over why the sample space of rolling a red die and green die results in (1,4) being different from (4,1), but there can only be one (1,1). Why can't there be (1 -red, 1-green) and (1-green, 1-red), if order matters? In addition, does the generalized counting principle always account for all outcomes possible? I am not sure if the generalized counting principle is counting total number of outcomes where order matters, or order does not matter. It seems that it changes depending on the problem, so I am confused on how to properly apply the generalized counting principle. For example, my textbook says:
Let E 1 , E 2 , . . . , E k be sets
with n 1 , n 2 , . . . , n k elements, respectively. Then there are n 1 × n 2 × n 3 × · · · × n k ways
in which we can, first, choose an element of E 1 , then an element of E 2 , then an element
of E 3 , . . . , and finally an element of E k . So it seems to me that order matters for the generalized counting principle? Why don't we multiply by k!, because there are also k! ways to order these Ek sets? Thank you in advance!","['dice', 'combinatorics', 'probability', 'factorial']"
3754548,How to prove that supremum of strictly convex function is infinity?,"Suppose there is a strictly convex continuous function $f$ : $R^n$ $\rightarrow$ $R$ . Is the supremum of $f$ always infinity? How can we prove it? I am trying to come up with proof. If $x$ and $y$ are two points in $R^n$ , strictly convex implies $f(\alpha x_1 + (1-\alpha) x_2) $ < $\alpha f(x_1) + (1-\alpha)f(x_2)$ . Suppose $f$ is bounded. Case 1:
The bound is attained at a point, say $x_0$ . Then for some $\alpha$ , some $x_1$ and $x_2$ s.t. $ (\alpha x_1 + (1-\alpha) x_2) = x_0$ : $f(x_0)$ < $\alpha f(x_1) + (1-\alpha)f(x_2)$ Therefore a contradiction. Case 2: The bound is not attained. Since the function is strictly convex, we know $f(x)$ approaches this bound as $x$ approaches $ \infty $ I don't know how to proceed after this step. Where can I find a contradiction in this case?","['proof-explanation', 'multivariable-calculus', 'supremum-and-infimum', 'convex-analysis']"
3754556,Show that: $f(\theta)=\sin\theta\cos(\theta\ -k)$ is max when $\theta = \frac{k+90^{\circ}}{2}$ without using calculus.,"Given $$f(\theta)=\sin\theta\cos(\theta\ -k)$$ Show that $f(\theta)$ is maximum when: $\theta = \frac{k+90^{\circ}}{2}$ I can do this easily using calculus, but I'm looking for a way of doing it without calculus. Context: A particle is projected up an inclined slope. The incline is fixed at an angle $k$ to the horizontal. The particle is projected at an angle $\theta$ to the incline. This problem resulted from trying to find the angle of maximum range.",['trigonometry']
3754599,Difference in bounds of convolution integral,"In my ODE class, I was taught that the convolution of two functions is calculated by: $$\left(f*g\right)\left(t\right)=\int_0^t{f\left(u\right)g\left(t-u\right)du}$$ According to Wikipedia , the convolution is defined as: $$\left(f*g\right)\left(t\right)=\int_{-\infty}^\infty{f\left(u\right)g\left(t-u\right)du}$$ and can be simplified to the definition I was taught if the functions $f\left(t\right)$ and $g\left(t\right)$ are only defined for $t\in\left[0, \infty\right)$ . $$$$ It makes sense why the lower bound would become $0$ when the functions are only defined for $t\in\left[0, \infty\right)$ , but I am confused why the upper bound becomes $t$ instead of remaining at $\infty$ . Wouldn't this change the value of the convolution? If so, do both definitions have the property that $\mathcal{L}^{-1}\left\{F\left(s\right)G\left(s\right)\right\} = \left(f*g\right)\left(t\right)$ ?","['convolution', 'laplace-transform', 'ordinary-differential-equations']"
3754631,Proving that $0 \rightarrow \Bbb Z \rightarrow \Bbb Q \rightarrow \Bbb Q / \Bbb Z \rightarrow 0$ does not split.,"Can I prove that the $\Bbb Z$ -module exact sequence $0 \rightarrow \Bbb Z \rightarrow \Bbb Q \rightarrow \Bbb Q / \Bbb Z \rightarrow 0$ is non-split exact by proving that $\Bbb{Z} \bigoplus \Bbb{Q} / \Bbb{Z}$ is not isomorphic to $\Bbb{Q}$ ? The way I prove this is by noticing that in $\Bbb{Z} \bigoplus \Bbb{Q} / \Bbb{Z}$ , there exist elements of order $a$ in which $a$ is the smallest natural number that satisfy $ar \in \Bbb Z$ , where $r \in \Bbb Q$ (e.g. order of $(0, \frac{1}{2} + \Bbb Z)$ is $2$ ), whereas the order of elements in $\Bbb Q$ is either $1$ or $\infty$ , showing that they are not isomorphic to each other. Is this correct?","['module-isomorphism', 'modules', 'exact-sequence', 'abstract-algebra', 'abelian-categories']"
3754648,Solve $x^5\equiv 4\pmod 7$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question We know about calculating $x^2\equiv 2\pmod 7$ using quadratic residue properties in order to find out whether a solution exists or not. I wonder is there any way to determine that $x^n\equiv k\pmod v$ , where $v\ge 2$ , $k\in\Bbb Z$ , and $n\ge 3$ ?  As I asked in title: Solve $x^5\equiv 4\pmod 7$","['elementary-number-theory', 'problem-solving', 'discrete-mathematics']"
3754652,The number of real solutions of the equation $\cos(\cos(\cos(\cos(x)))) = \sin(\sin(\sin(\sin(x))))$ [duplicate],This question already has answers here : Solving $ \cos (\cos (\cos (\cos(x))))=\sin (\sin (\sin (\sin (x)))) $ (3 answers) Closed 3 years ago . The number of real solutions of the equation $$\cos(\cos(\cos(\cos(x)))) = \sin(\sin(\sin(\sin(x))))$$ (I have no clue to solve this problem),['trigonometry']
3754676,"Let $S=\{a,b\}$. Which binary operation $*$ on $\wp(S)$ makes $(\wp(S),*)$ a cyclic group?","Let $S=\{a,b\}$ be a set, and $\wp(S)$ the power set of $S$ . It is well known that $$(\wp(S),\triangle,\emptyset)\cong \mathbb{Z}_2\times \mathbb{Z}_2\,,$$ where $\triangle$ is the symmetric difference of two sets. Now, there are $24$ bijections $f\colon \mathbb{Z}_4 \to \wp(S)$ , and hence as many operations "" $*$ "" in $\wp(S)$ such that $$(\wp(S),*,f(0))\cong \mathbb{Z}_4.$$ I tried by trial and error several times, but I couldn't succeed in finding any of such operations as a symmetric (being the group abelian), closed formula in terms of the basic set operations $\cup, \cap,\setminus$ , just like the symmetric difference formula.","['boolean-algebra', 'finite-groups', 'abstract-algebra', 'elementary-set-theory', 'group-theory']"
3754685,Does this differential equation have a solution that has certain properties?,"Conjecture: Suppose we have a function $f(x)$ and some real number $\alpha$ such that $f(\alpha)=\alpha$ and $f'(\alpha)<1$ . Then there exists a solution $y(t)$ to the differential equation $f(y)-y=y'$ such that $\lim_{t\to\infty}y(t)=\alpha$ . I've tested some functions and the conjecture always seems to hold: For $f(x)=x^2, \alpha=0$ and the corresponding solution is $\dfrac{1}{ce^t+1}$ , which goes to $\alpha=0$ . If $f(x)=\sin(x)+x, \alpha = (2k+1)\pi$ , then $y(t)=2\cot^{-1}(ce^{-t})+2k\pi\to(2k+1)\pi$ and so on... I would appreciate any kind of help, discussion or source for further reading. Thanks!","['fixed-point-theorems', 'limits', 'ordinary-differential-equations']"
3754688,Show that $K$ has measure zero,"This is a problem from my measure theory book: Let $K$ be a compact subset of $\mathbb{R}^d$ such that the intersection $H_r(K)\cap H_{r'}(K)$ of two homothetic images ( $H_r(x)=rx$ for $x\in \mathbb{R}^d$ and $r\in\mathbb{R}$ ) of $K$ has Lebesgue-Borel measure zero whenever $0<r<r'<1$ . Prove that $\lambda^d(K)=0$ . Hint : $H_r(K) \subset \tilde{K}=\{tx:0\leq t\leq 1, x\in K \}$ which is a compact set. Hence $\lambda^d(\tilde{K})<\infty$ . I know that $\lambda^d(H_r(K))=|r|^d \lambda^d(K)$ approaches $\lambda^d(K)$ as $r$ approaches $1$ , but not sure where I can go from there. Any help is greatly appreciated.","['measure-theory', 'lebesgue-measure']"
3754725,Mild Error on Page 32 Spivak's Calculus of Manifolds that I couldn't find online.,"I'm just asking if this is actually an error, as I could not find it in any errata online, math stackexchange questions etc. In Spivak's Calculus on Manifolds, page 32, I believe there is a mild error in the statement of Theorem 2-9. The theorem states: ""Let $g_{1} ,..., g_{m}$ : $\Bbb{R}^{n} \rightarrow \Bbb{R}$ be continuously differentiable at $a$ and let $f:\Bbb{R}^{m} \rightarrow \Bbb{R}$ be differentiable at $(g_{1}(a), ... , g_{m}(a)) $ . Define the function $F:\Bbb{R}^{n} \rightarrow \Bbb{R}$ by $F(x) = f(g_{1}(x), ... , g_{m}(x)). $ Then $D_{i}F(a) = \sum_{j=1}^m D_{j}f(g_{1}(a), ... ,g_{m}(a))\cdot D_{i}g_{j}(a).$ "" I believe it is an error that the $g_{i}$ must be assumed to be continuously differentiable (as opposed to just differentiable), as he proves in Theorem 2-3 on page 20 that the function $g:\Bbb{R}^{n} \rightarrow \Bbb{R}^{m}, x\rightarrow(g_{1}(x), ... , g_{m}(x))$ is differentiable iff the $g_{i}$ are just differentiable, with no continuity requirement. Normally I would just ignore this and assume it is an error, but he explicitly states after the proof that this theorem is weaker than the chain rule because the $g_{i}$ must be continuously differentiable. Am I correct in assuming that by Theorem 2-3 they need not be?",['multivariable-calculus']
3754726,"If $\phi\circ f$ and $f$ is analytic, then $\phi$ is analytic.","A question from a past qualifying exam at my university reads: Let $f$ be a nonconstant analytic function on the unit disk $D$ and
let $U = f(D)$ . Show that if $\phi$ is a function on $U$ (not necessarily even
continuous) and $\phi \circ f$ is analytic on $D$ , then $\phi$ is analytic on $U$ . My approach so far is as follows. Because differentiable functions are continuous, then $\phi\circ f$ is  continuous. One can go on to show that $\phi$ must be continuous on $U$ . I now want to use Morea's theorem to show that $\phi$ is analytic, i.e. show that $\int_{\partial T}\phi(z)dz=0$ for any triangle $T\subset U$ . For $z\in U$ , $\phi(z)=\phi(f(w))$ where $f(w)=z$ . So I want to rewrite the previous integral in terms of $\phi(f(w))$ and apply Cauchy's theorem to conclude the integral vanishes. However, I don't know how to control the preimage of $T$ under $f$ .  Will it even be connected? If I can show that $f^{-1}(T)$ is a domain with peicewise-smooth boundary, then I should be down. How should I proceed?",['complex-analysis']
3754768,Can we equip the power set $P$ of any set $S$ with a binary operation such that $P$ becomes a group (with some restrictions)?,"This question is inspired by this one .  Please read my answer there to get better context. Settings. Let $S$ be a (not necessarily finite) set, and $P$ the power set of $S$ (i.e., $P$ is the set of all subsets of $S$ ).  A binary operator $*:P\times P\to P$ is said to be elementary if it can be given in terms of the standard set operations: the union operator $\cup$ , the intersection operator $\cap$ , the set difference operator $\setminus$ , the symmetric difference operator $\triangle$ , and the complement operator $(\_)^\complement$ . Some Examples. This operator $\star$ is considered an elementary binary operator: $$A \star B:= \big((M\setminus A)\cup (B\cap N)\big)^{\complement}\triangle \Big(A\cup B^\complement\Big)\text{ for all }A,B\subseteq S\,,$$ where $M$ and $N$ are fixed subsets of $S$ .  On the other hand, if $|S|=2$ , then this operator $\bullet$ is not an elementary binary operator: $$A\bullet B:=\left\{
\begin{array}{ll}
S&\text{if }A\subseteq B\,,\\
\emptyset&\text{otherwise}\,,
\end{array}\right.$$ where $A,B\subseteq S$ (a proof can be done by imitating this answer ). Question. For which groups $G$ of order $2^{|S|}$ does there exist an elementary binary operator $*:P\times P\to P$ such that $(P,*)$ is a group isomorphic to $G$ ?  If the case where $S$ is an infinite set is too troublesome, then an answer in the case where $S$ is a finite set is very welcome. Let $n:=|S|$ .  Write $Z_k$ for the cyclic group of order $k$ . Trivial Answer. When $G\cong Z_2^n$ , then the binary operator $\triangle$ does the work.  My conjecture is that there are no other groups. Known Result. When $|S|=2$ and $G\cong Z_4$ , then there does not exist such an elementary binary operator.","['boolean-algebra', 'binary-operations', 'abstract-algebra', 'elementary-set-theory', 'group-theory']"
3754803,Conditional convergence for improper Riemann double integrals,"I'm reading Buck's advanced calculus. It says for improper integral of higher dimensions, conditional convergence is impossible, i.e., $\int\int_D f$ cannot exist without $\int\int_D|f|$ existing too. Then book only gives a sketch of proof as follow. Let $f_1=(|f|+f)/2$ and $f_2=(|f|-f)/2$ . We may assume that the integrals $\int\int_Df_i$ are each divergent. Since $f_1f_2=0$ , so that the sets where $f_1$ and $f_2$ are positive are disjoint. It is then possible to choose an expanding sequence of closed rectangles $\{D_n\}$ which favour $f_1$ over $f_2$ , so that $\int\int_{D_n} f_1$ diverges faster than $\int\int_{D_n} f_2$ , with the result that $\int\int_{D_n} f$ , which is their different, also diverge. But it feels like a almost exactly same proof can be used to show that single improper integral can not be conditional convergent too, but single integral can be convergent without being absolute convergent. For example, $\int^\infty_1 x^{-1}\sin x$ is conditional convergent but not absolutely convergent. So what is the essential difference between single integral and double integral which makes the conditional convergence for double integral impossible? Thanks.","['integration', 'conditional-convergence', 'multivariable-calculus', 'improper-integrals']"
3754819,"Evaluate $\int_{1}^{\sqrt{2}} \frac{x^4}{(x^2-1)^2+1}\,dx$","Evaluate the integral: $$\int_{1}^{\sqrt{2}} \frac{x^4}{(x^2-1)^2+1}\,dx$$ The denominator is irreducible, if I want to factorize and use partial fractions, it has to be in complex numbers and then as an indefinite integral, we get $$x + \frac{\tan^{-1}\left(\displaystyle\frac{x}{\sqrt{-1 - i}}\right)}{\sqrt{-1 - i}} + \frac{\tan^{-1}\left(\displaystyle\frac{x}{\sqrt{-1 + i}}\right)}{\sqrt{-1 + i}}+C$$ But evaluating this from $1$ to $\sqrt{2}$ is another mess, keeping in mind the principal values. I also tried the substitution $x \mapsto \sqrt{x+1}$ , which then becomes $$\frac{1}{2}\int_{0}^1 \frac{(x+1)^{3/2}}{x^2+1}\,dx$$ I don't see where I can go from here. Another substitution of $x\mapsto \tan x$ also leads me nowhere. Should I approach the problem in some other way?","['integration', 'definite-integrals']"
3754839,Distribution of highest numbered occupied box and number of balls therein?,"Say we have $N$ boxes, numbered $1,2,...,N$ . We select $K$ numbers uniformly from $1,2,...,N$ , and for each result we place one ball into the correspondingly numbered box. We then select $L$ numbers uniformly from the same $1,2,...,N$ and for each result we remove one ball (if any are left) from the corresponding box. In both iterations, the numbers are selected with replacement.
The boxes have no capacity limit, that is, more than one ball can be placed into any given box. To clarify the mechanic, say we had 4 boxes, and we'd tossed some number $K$ balls into them as specified. Now, say $L$ was 4, and the resulting samples of numbers were ${1,3,4,4}$ . We'd remove one ball from box 1 (if any were there), one ball from box 3 (if any...), and two balls from box 4 (if any were there, so if box 4 had 2 or fewer balls it will be left empty). I'm interested in the probability distribution of the highest numbered occupied box (if any) and the associated number of remaining balls in that box. I've written a couple of methods in my CAS to arrive at the result, one simply enumerating the multinomial possibilities and doing the corresponding machinations, the other using a generating function and pulling the coefficients with corresponding machinations. As requested in comments, an example for the results for the case of $N=6$ boxes, $K=3$ tosses, and $L=2$ removals is as follows (left column is box number, followed left-to-right with probabilities that box is the highest numbered occupied box, with number of remaining balls $1,2,3$ seen there): Both work fine up to $K$ and $L$ of 15 with $N$ up to ~6, but the complexity of the methods means it gets slow pretty quickly. Is there a more efficient means to arrive at the desired results?","['balls-in-bins', 'probability']"
3754858,a question on composite values of integer polynomials,"Here is a problem stated by myself and I don't have idea how to attack it: Let $P$ be a nonconstant polynomial of integer coefficients.
Is it true that for any $n\in\mathbb{N}$ there is $a\in\mathbb{Z}$ such that all numbers $|P(a+1)|,\dots,|P(a+n)|$ are composite? It seems hard even for degree 1 polynomials. I know Dirichlet's famous theorem on primes in arithmetic progressions, but it doesn't seem to work here. I don't have any idea how to look for composite values when the polynomial satisfies $P(0)=\pm 1$ .","['number-theory', 'polynomials']"
3754909,How can I prove that these definitions of curl are equivalent?,"I am reading the book ""Div, Grad, Curl, and All that"" and I got to the section about curl. In this section, the author defines the curl to be $$ (\nabla \times \mathbf{F})\cdot \mathbf{\hat{n}} \ \overset{\underset{\mathrm{def}}{}}{=} \lim_{S \to 0}\left( \frac{1}{|S|}\oint_C \mathbf{F} \cdot d\mathbf{r}\right) \tag{1}$$ The author gives a ""physicist's rough-and-ready proof"" of how this expression reduces to each of the $x,y$ and $z$ components of $$
\nabla \times \mathbf{F} =
\left(\frac{\partial F_z}{\partial y} - \frac{\partial F_y}{\partial z}\right) \boldsymbol{\hat\imath} + \left(\frac{\partial F_x}{\partial z} - \frac{\partial F_z}{\partial x} \right) \boldsymbol{\hat\jmath} + \left(\frac{\partial F_y}{\partial x} - \frac{\partial F_x}{\partial y} \right) \boldsymbol{\hat k} \tag{2}
$$ when analyzing a closed path $C$ which is parallel to the $yz, xz$ , and $xy$ planes respectively. After this, I started wondering if there's a more rigorous way to show that, in cartesian coordinates, equation $(2)$ satisfies the definition in equation $(1)$ . I'm specifically interested in a proof where you assume any arbitrary closed path $C$ . If someone could tell me how this is can be done, or could point me in a direction where this proof is already given I would greatly appreciate it. Thank you!","['vector-fields', 'curl', 'multivariable-calculus', 'vector-analysis', 'line-integrals']"
3754940,$f^2$ and $f^3$ are holomorphic implies $f$ is holomorphic. Without continuity assumption.,"The answer is here: $f^2$ and $f^3$ are holomorphic implies $f$ is holomorphic. However, they assume continuity of $f$ . I just wanted to make sure that that is not necessary. Since $f^2$ is holomorphic, it is bounded around its zeroes. Thus $f$ is bounded around its zero. Hence now we can conclude that that all of the singularities are removable as $f^3/f^2$ is bounded around $f$ 's zeroes. Thus it follows $f$ is holomorphic",['complex-analysis']
3754972,Why is the well-ordering theorem so important in the set theory?,"Why is the well-ordering theorem so important in the set theory? Every set can be well-ordered. Mathematicians think the above theorem is very important but the below theorem is not so important. Of course I know that the above theorem is stronger than the below theorem.
But why is the above theorem so important? Every set can be totally-ordered.","['elementary-set-theory', 'order-theory', 'well-orders']"
3754985,Want to study Graduate Measure Theory with heavy Emphasis on Topology and/or Geometry.,"I did one course in Measure Theory and want to study it again. But this time I want to do this in a way that emphasizes Measure Theoretic structure on Geometric or Topological Spaces. I don't know, if it is at all possible. But I have heard there are some Differential forms and Measure theoretic relations on manifolds. So, my question is,- Do you know a graduate level literature (book,notes,lectures anything) on Measure Theory that you think is topologically or Geometrically heavy (in your judgement) ? Showing an interplay between Measure theory and topology/geometry is desired but any other reasons that you have is good too. More specifically, Is there anything for measure theory on manifolds? Is reading Geometric Measure Theory a good idea for this? I asked this on Reddit too. But I need more opinions.Thank You.","['measure-theory', 'book-recommendation', 'geometric-measure-theory', 'general-topology', 'differential-geometry']"
3755001,Find $\int_{0}^{\infty} \frac{\sqrt{x}}{x^2+5x+6}$ using residues.,"Find $$ \int_0^\infty \frac{\sqrt{x}\ dx}{x^2+5x+6}$$ This problem is slightly unusual as the poles are on the real axis, + it has the square root so we will need to deal with a log branch. Here a terrible sketch of my contour. I know that the integral over $z_2$ and $z_4$ goes to $0$ regardless of how much of an arch we make. $z_1$ gives us the desired integral letting $\epsilon \to 0$ . Now $z_3$ is parameterized so that it is a straight line a little bit below the real axis $z_3(t)=t+i\delta, t\in [-\sqrt{R^2-\delta^2},-\sqrt{\epsilon^2-\delta^2}]$ . Now by definition of contour integral over $z_3$ we get $$\int_{-\sqrt{R^2-\delta^2}}^{-\sqrt{\epsilon^2-\delta^2}}\frac{\sqrt{t+i\delta}}{(t+i\delta)^2+5(t+i\delta)+6}$$ letting $\delta \to 0$ ( I am having trouble justifying moving the limit inside) we get $\int_{-R}^{-\epsilon}\frac{\sqrt{t}}{t^2+5t+6}$ which is imaginary, so we just have to take the real part of the residue and we are done. Is this correct? It gives me the right answer but i am not sure if all i did was valid.","['improper-integrals', 'complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
3755017,How to integrate $ \int\frac{x-2}{(7x^2-36x+48)\sqrt{x^2-2x-1}}dx$?,How to integrate $$ I=\int\frac{x-2}{\left(7x^2-36x+48\right)\sqrt{x^2-2x-1}}dx$$ The given answer is $$ I=-\dfrac{1}{\sqrt{33}}\cdot \tan^{-1}\left(\frac{\sqrt{3x^2-6x-3}}{\sqrt{11}\cdot (x-3)}\right)+\mathcal{C}$$ I tried by different substitutions i.e $$\dfrac{x^2 - 2x -1}{x-3} = t$$ but I am not getting my desired answer.,"['integration', 'indefinite-integrals', 'calculus']"
3755018,"Defining a general structure of ""Calculus"" [closed]","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 3 years ago . Improve this question I've been thinking lately, is there a way to generalize the fundamental concepts of Calculus such as convergence, differentiability and integrability to it's ""maximum potential""? That is, defining a really long $n$ - uple in the algebraic sense (like in group theory, $(G,\,\cdot\,)$ ) that would include all the other ""cases of Calculus"" (in the real line, in $\mathbb{R}^n$ , in Banach Spaces, in a manifold, etc).
I know we could generalize the notion of differentiability to normed spaces and manifolds, and the notion of integrability to any measurable space, including, again, manifolds, so I think that the most likely structure to harbor the strongest definition of what ""Calculus"" comes to be are the manifolds. That put, I've came across the notion of Difeological Space, in which the manifolds (even the infinite-dimensional ones) are replaced by stronger counterparts; similarly, I've encountered some sources claiming that the language of Category Theory could make such a powerful generalization of Calculus, creating it's own ""algebraic structure"", in some sort of manner. What do you guys think? Such a thing would be possible? Thanks in advance!","['integration', 'manifolds', 'derivatives', 'global-analysis', 'differential-geometry']"
3755031,A finite abelian group is isomorphic to the direct product of its Sylow subgroups,"I've seen this question here before, but I want to know if the following is sufficient: Attempt: First note that the product of two normal subgroups $H_1$ and $H_2$ is itself a normal subgroup, and that if $H_1 \cap H_2 = \{e\}$ then $|H_1 H_2| = |H_1||H_2|$ . Now suppose we have subgroups $H_1, H_2, \ldots, H_n$ , each of which is normal, and such that $\displaystyle \bigcap_{H_j} = \{e\}$ . By taking the products one at a time, we obtain that the product $H_1 H_2$ is a normal subgroup of order $|H_1||H_2|$ , the product $(H_1 H_2)H_3$ is a normal subgroup of order $|H_1||H_2||H_3| \ldots$ , and the product of all the $H_i$ , ( $i = 1, 2, \ldots, n$ ) is a normal subgroup whose order is $|H_1||H_2| \cdots |H_n|$ . Now if $G$ is a finite abelian group of order $p_1^{a_1} \cdots p_k^{a_k}$ for distinct primes $p_j$ , then the Sylow $p_j$ -subgroups $P_1, \ldots, P_k$ have orders $p_1^{a_1} \cdots p_k^{a_k}$ , respectively. Note that they are all normal, and that any two distinct Sylow $p_j$ -subgroups intersect in the identity. By the argument above, the product $P_1 \cdots P_n$ is a subgroup of of $G$ that has order $p_1^{a_1} \cdots p_k^{a_k} = |G|$ , and by the recognition theorem $^\spadesuit$ , this product is the same as the direct product, i.e. $G \cong P_1 \times P_2 \times \cdots \times P_k$ . Hence $G$ is isomorphic to the direct product of its Sylow subgroups. EDIT: Suppose that $x \in P_1 P_2 \cap P_3$ . Since $|P_1 P_2|$ and $|P_3|$ are relatively prime, we can write $1 = a|P_1 P_2| + b|P_3|$ . Then $$x = x^1 = x^{a|P_1 P_2| + b|P_3|} = x^{a|P_1 P_2|}x^{b|P_3|} = {x^{|P_1 P_2|}}^a{x^{|P_3|}}^b = e.$$ Hence $|x|$ divides 1, so $x = e$ . Thus for each $j$ , $(P_1 P_2 \cdots P_j) \cap P_{j + 1} = \{e\}$ . $\spadesuit$ Dummit and Foote call the following a ""recognition theorem"": If $H$ and $K$ are normal subgroups of $G$ and $H \cap K = \{e\}$ , then $HK \cong H \times K$ .","['group-theory', 'solution-verification', 'abelian-groups', 'sylow-theory']"
3755033,Serre FAC book by McLennan,"I am planning to read Serre's FAC paper. I came to know that there is a book/notes by Andy McLennan, containing the commutative algebra background as well as an english translation of the FAC (Ravi Vakil's blog mentions it: https://math216.wordpress.com/2014/12/30/2014-version/ ) But the link to the book seems to be broken. I could not find it elsewhere. Does someone know of a working link?","['algebraic-geometry', 'coherent-sheaves', 'reference-request']"
3755060,Edited: Let $I=\int_{0}^{\pi/2}(\sin 2x)^{1/3}\sin x dx$ $J=\int_{0}^{\pi/2}(\cos 2x)^{1/3}\cos x dx$. Find $I/J$,"Edit:Sorry guys I made an error in question, I have edited it now. I found $$I=\int_{0}^{\pi/2}(\sin 2x)^{1/3}\sin x dx = 2^{1/2}\int_{0}^{\pi/4}(\cos 2x)^{1/3}\cos x dx$$ $$J=\int_{0}^{\pi/2}(\cos 2x)^{1/3}\cos xdx=2^{1/2}\int_{0}^{\pi/4}(\sin 2x)^{1/3}\sin x dx$$ So I got them in each other's integral form but the limits have changed and I don't know what to do next.","['integration', 'trigonometry', 'definite-integrals']"
3755067,Find squares in recurrence relation,"Find all squares in $\{a_n\}$ which obeys the following recurrence relation: $a_0=a_1=1, a_{n+2}=6a_{n+1}-a_n$ I've tried to solve the equation $n^2+(n+1)^2=m^4$ and got this recurrence relation. (If and only if $m^2\in\{a_i\}_{i=2,3,\dots}$ , $m$ satisfies this equation, I suppose.) I'd be happy if you could share your ideas on how to find the all square numbers in $\{a_i\}_{i=2,3,\dots}=\{5,29,169,985,5741,\dots\}$ with me. There seems to be only one square in the first 30 terms, according to my computer. Interestingly, each term has very few divisors. I've read one of the proofs of square Fibonacci numbers, but failed to apply it to this problem. Please give me some hints. EDIT Here is the page of this sequence. Solution Thanks to your help, I found the elementary solution here .","['number-theory', 'recurrence-relations', 'recursion']"
3755088,Why don't we need to count the two pre-assigned people in this committee forming probability question?,"The following question comes from MITx 6.431x. Out of five men and five women, we form a committee consisting of four
different people. Assume that 1) each committee of size four is
equally likely, 2) Alice and Bob are among the ten people being
considered. Calculate the probability that both Alice and Bob are members of the
committee. I know the correct solution to this problem; what I do not understand is why isn't $(1/5)^2*\binom{8}{2}/\binom{10}{4}$ the correct way to calculate. $(1/5)^2$ because both Alice and Bob have a 1 out of 5 chances of being picked $\binom{8}{2}$ because after Alice and Bob have been picked, there are two spots left to fill out of 4 men and 4 women $\binom{10}{4}$ because that's the total amount of combinations possible Could anyone help please? In particular, $(1/5)^2$ is not necessary - why?","['solution-verification', 'probability-theory']"
3755224,How to calculate the length $AH$?,"We have a triangle $ABC$ and the heights $AD$ and $BE$ that intersect in $H$ . The following length are given: $$AB=12, \ BD=4, EC=  8, \ AE=6$$ How can we calculate $AH$ ? Does the orthocenter divide a length by a specific ratio?","['triangles', 'geometry']"
3755235,Find range of $f(x)=\frac{5}{\sin^2x-6\sin x\cos x+3\cos^2x}$,"Find range of $f(x)=\frac{5}{\sin^2x-6\sin x\cos x+3\cos^2x}$ My attempt : \begin{align*}
f(x)&=\dfrac{5}{9\cos^2x-6\sin x\cos x+\sin^2x-6\cos^2x}\\
&= \dfrac{5}{(3\cos x+\sin x)^2-6\cos^2x}
\end{align*} The problem is if I'm going to use $$-1\leqslant\sin x\leqslant1\;\text{and}-1\leqslant\cos x\leqslant1$$ I think I need to have only one term. Edit : I have made some more progress $$-3\leqslant 3\cos x\leqslant 3$$ $$\therefore -4\leqslant 3\cos x+\sin x\leqslant 4$$ $$ 0\leqslant (3\cos x+\sin x)^2\leqslant 16$$","['trigonometry', 'functions']"
3755249,Applications of Tits' alternative in number theory,"I have recently studying Tits' alternative. The theorem statement goes like the following: Tits' alternative: Let $G$ be any finitely generated linear group over a field. Then one of the following is true, $(1)$ $G$ contains a solvable normal subgroup of finite index, $(2)$ $G$ contains a non-abelian free subgroup (of rank at least $2$ ). I am in search of applications of this wonderful theorem in number theory. Any help, resources or reference will be appreciated. Thanks in advance. The same question was asked by me in Mathoverflow. But due to lack of proper response, I posted it here.","['geometric-group-theory', 'number-theory', 'free-groups', 'solvable-groups']"
3755258,Distribute $n$ distinguishable balls into $k$ distinguishable baskets,"Given a number $n$ and $k$ numbers $n_1,n_2,n_3\ldots, n_k \in \mathbb{N}$ such that $n_1+n_2+n_3+\ldots+ n_k=n$ How many ways are there to distribute 𝑛 distinguishable balls into $k$ distinguishable baskets so that exactly $n_i$ balls are placed in each basket $i$ , $i =1,2,\ldots, k$ ? Also, how many ways are there to distribute $n$ distinguishable balls into $k$ distinguishable baskets? Let's say if there is no restriction to the number of balls in each basket. I can't really understand the logic of that. I mean, there are $n$ balls by the given forumla $n_1+n_2+\ldots+n_k=n$ and there are $k$ baskets? So what's the deal with "" $n_1, n_2,\dots$ etc.""? Why isn't it $x_1,x_2,\dots$ etc.?
How do you think should I do it? I mean if they were identical balls I would use the $k+n-1\choose{n-1}$ formula.
But here they are different. I can't really figure out what should I do in both of those questions.
Thanks. For the second answer it's gonna be $k^n$ ? ( $k$ : number of baskets; $n$ : number of balls) Edit: The bins are not identical. I thought about it, and if $n_1,n_2,n_3,\dots,n_k$ are simply numbers which represent the amount of balls in each bin (for example $n_1$ balls in bin number $1$ , $n_2$ balls in bin number $2$ and so on), then there is only one option, right? Because we already have the exact amount of balls in each basket. But maybe it's something fishy because we can find a lot of options for $n_1+n_2+...+n_k=n$ ...
I mean, $n_1$ can be different in each option...","['combinatorics', 'discrete-mathematics']"
3755260,Can you win the monochromatic urn game?,"In the (monochromatic) urn depletion game , you are given $n$ vases, each containing some number of balls $a_1,\ldots, a_n \geq 0$ . You win the game if you can remove all of the balls from the vases; you must draw them one at a time, and the only rule is that you cannot draw from the same vase twice in a row. The problem is to decide, given the occupancy numbers $a_1, \ldots, a_n$ , whether the game is winnable. Example: The game [AAA, A] (three in one vase; one in another) is unwinnable. I've already got an efficient algorithm for winning the game: at each step, draw from the vase with the largest number of balls $a_i$ (among vases you can legally choose). If the game is winnable at all, this algorithm will win it. So instead of an algorithm, I am looking for a property of the numbers $a_1,\ldots, a_n$ which would enable someone to calculate whether the game is winnable. Evidently there's a formula implicit in the algorithm above, but I wonder if it's possible to find an explicit and simple one. I've tried establishing the result for small $n$ : if $n=1$ , $a_1$ must be 0 or 1. If $n=2$ , then $|a_1-a_2|$ must be 0 or 1. If $n=3$ , the condition is slightly more complicated but might be expressible in terms of the differences $|a_i-a_j|$ . It also seems to me that a game instance is solvable just if you can find a perfect or near-perfect matching in a particular graph—the graph has one node for every ball in every vase, and each ball is connected to all the balls in the other vases. Rationale: Given such a matching, you can win the game as follows: iterate over the edges in an arbitrary order; for each edge, at least one of the two endpoints will belong to a legal urn; draw that one, then the other.  Conversely, a winnable game has at least one winning sequence of draws. Form a [near]-perfect matching by pairing consecutively drawn balls, starting with the first and second, third and fourth, etc. The graph matching approach seems like a potentially fruitful avenue, but I don't know much about matching or matching polynomials to do much more. (I previously asked a related question about the multicolor version of this game)","['graph-theory', 'matching-theory', 'combinatorics', 'combinatorial-game-theory', 'computational-complexity']"
3755284,Law of Cosines: Proof Without Words,"I am trying to prove the Law of Cosines using the following diagram taken from Thomas' Calculus 11th edition. I have an answer, but I think there must be a simpler or better way to do it.  Here is my answer: Construct a coordinate system such that $(0,0)$ is located at the bottom right corner of the pictured triangle.  Then the red line intersects the hypotenuse at $(-a,0)$ and a leg at $(-b\cos\theta,b\sin\theta)$ .  Thus the squared distance $c$ from $(-a,0)$ to $(-b\cos\theta,b\sin\theta)$ is \begin{align}
c^2&=(-b\cos\theta-(-a))^2 + (b\sin\theta)^2\\
&=a^2-2ab\cos\theta+b^2\cos^2\theta+b^2\sin^2\theta\\
&=a^2+b^2-2ab\cos\theta.
\end{align} I feel like there has to be a simpler way, since my proof is basically ignoring the right triangle, the circle, etc.  If somebody can show me another proof, that would be great.  Thanks. UPDATE: It looks like I needed the Intersecting Chords Theorem from Geometry to write $(a+c)(a-c)=(2a\cos\theta-b)(b)$ .","['trigonometry', 'geometry']"
3755288,Estimating $\int_{0}^{1}\sqrt {1 + \frac{1}{3x}} \ dx$.,"I'm trying to solve this: Which of the following is the closest to the value of this integral? $$\int_{0}^{1}\sqrt {1 + \frac{1}{3x}} \ dx$$ (A) 1 (B) 1.2 (C) 1.6 (D) 2 (E) The integral doesn't converge. I've found a lower bound by manually calculating $\int_{0}^{1} \sqrt{1+\frac{1}{3}} \ dx \approx 1.1547$ . This eliminates option (A). I also see no reason why the integral shouldn't converge. However, to pick an option out of (B), (C) and (D) I need to find an upper bound too. Ideas? Please note that I'm not supposed to use a calculator to solve this. From GRE problem sets by UChicago","['integration', 'definite-integrals', 'estimation']"
3755296,Does $x^n$ belong to $O(e^x)$ for all $n\geq 1$?,"My question is essentially two-fold. I've been asked to prove that $x^5 \in$ $O(e^x)$ as $x\to \infty$ , and trying to do that I decided to plot some functions of the form $x^n$ next to $e^x$ , and noted that after some (possibly very large) point $e^x$ tends to outgrow $x^n$ . Now, I only tested this up to about $n=7$ as the numbers get extremely large, but I wonder if the pattern holds up for all $n$ ? I tried thinking about this inductively, i.e. supposing that $x^n\in$ $O(e^x)$ up to some $n$ , then for $x^{n+1}$ we have that its rate of growth is $(n+1)x^n$ , which is in $O(e^x)$ by the inductive hypothesis, hence $e^x$ must outgrow $x^{n+1}$ eventually.I am not sure, however, if that is correct. Either way, I lack the intuition as to why that happens (if it does), so any explanation would be appreciated.","['calculus', 'functions']"
