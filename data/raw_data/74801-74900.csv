question_id,title,body,tags
927875,If $X$ is inductive then the set $\{ x \in X \mid x $ is transitive and $ x \notin x \}$ is inductive.,"Definition. We say that $A$ is an inductive set if $\varnothing\in A$, and whenever $x\in A$ then $x\cup\{x\}\in A$ as well. I am trying to prove the following exercise: If $X$ is inductive then the set $U = \{ x \in X \mid x $ is transitive and $ x \notin x \}$ is inductive. Proof: Let $\alpha \in U$, we have to show that $\alpha \cup \{ \alpha \} \in U$. But $\alpha \cup \{ \alpha \}$ is transitive since $(\beta \in \alpha \Rightarrow \beta \subseteq \alpha)$ and $(\alpha \subseteq \alpha \cup \{ \alpha \})$. Left to show: $\alpha \cup \{ \alpha \} \notin \alpha \cup \{ \alpha \}$. Suppose in contradiction that $\alpha \cup \{ \alpha \} \in \alpha \cup \{ \alpha \}$. This would imply $\alpha \cup \{ \alpha \} \in \alpha$ which implies $\alpha \in \alpha$ ($\alpha$ transitive). contradiction. Is my proof correct?",['elementary-set-theory']
927879,Generating the special linear group of 2 by 2 matrices over the integers.,"Our Number Theory professor claimed that the special linear group $\text{SL}_2(\mathbb{Z})$ is generated by just two matrices: $$
M_1=\begin{pmatrix} 0& -1\\ 1& 0 \\\end{pmatrix} 
$$ $$
M_2=\begin{pmatrix} 1& 1\\ 1& 0 \\\end{pmatrix}
$$ He commented that the proof is outside the scope of the syllabus. When I pressed him to give a hint, he made the following cryptic comment: Consider the action of the group $\text{SL}_2(\mathbb{Z})$ on the complex upper half plane $\mathbb{H}$ by the action:
  $$\begin{pmatrix} a& b\\ c& d \\\end{pmatrix}: z \to \frac{az+b}{cz+d}$$
  Show that 'some region' in $\mathbb{H}$ is a 'fundamental domain' and that finishes the proof. I don't follow the argument at all. He drew a region that looked like a semicircle with a rectangular patch in between. This is the 'some region' in the block quote. I don't know how the complex plane helps. I don't know what a 'fundamental domain' means in this problem. And most of all, I don't see how this approaches the proof at all :( Would someone explain this argument to me? I will be happy with references, papers or a general hand waving argument as well. Thank you.","['matrices', 'complex-numbers', 'number-theory']"
927901,Is there a closed form solution for this differential equation?,"I was trying to solve the following ODE, but I cannot find an easy way anywhere. I also tried using Mathematica, but it also does not provide me with a solution. $\frac{dx}{dt}=-k_1 x+(1-x)k_2 e^{-k_3 t}$, $x(0)=0$ However on simulating I find a smooth curve increasing till a threshold time and later on, decreasing. Can someone help me solve this ODE?","['dynamical-systems', 'ordinary-differential-equations']"
927902,Does a positive semidefinite matrix always have a non-negative trace?,"If $A$ is a positive semidefinite matrix ( $A\succeq 0)$ , does it imply that $\mbox{Tr}(A)\geq 0$ , where the $\mbox{Tr}(\cdot)$ denotes the trace. If not, any counter-example? Thanks.","['trace', 'matrices', 'positive-semidefinite']"
927913,$yy''=y^2y'+(y')^2$ method of reduction (differential equation),I have a question about using reduction to solve $$yy''=y^2y'+(y')^2$$ This is how I have been thinking: put $y'=p$ and $p''=(dp)/(dy)*p$ $yp*dp/dy-y^2p-p^2=0$ ... $dp/dy-y=p/y$ but now I don't know how I can solve it? perhaps with integrating factor? Thanks for help,['ordinary-differential-equations']
927921,length of an interval as a limit,"Let $I$ be an interval and $A_{n}$ be the set of $k/n$ where $k$ is an integer. Prove that the length of $I$ (the positive difference between the end points) is the limit as $n$ tends to infinity of $\frac{1}{n}|(I \cap A_{n})|$ . My plan was to split it up into cases for the different type of intervals and come up with formulas for $|(I \cap A_{n})|$ , but I'm finding that very tricky. Thanks","['measure-theory', 'real-analysis']"
927982,Calculus Question: $\int\frac{\sqrt{x^2-1}+x}{\sqrt{x^2-1}+x-1}dx$,"How to evaluate integral $$\int\frac{\sqrt{x^2-1}+x}{\sqrt{x^2-1}+x-1}dx?$$
I tried substitution $u^2=x^2-1$ and $u=\sqrt{x^2-1}+x$ but it turns out too complicated. Could anyone here help me to evaluate the integral? Thanks in advance.","['radicals', 'calculus', 'integration', 'indefinite-integrals']"
927989,Periodicity with irrational numbers,"Recently, I composed the following math problem and found a solution,
it seems strange since it is very counter-intuitive to me.
Is there a place or a branch of math where I can read about it? Or at least a key word?
Any explanation is definitely welcome!
Sorry for my terminology - I am not a mathematician. Suppose we are given a set $S = \{i\} \cup \{j \cdot x\},$ where $i, j \in \mathbb{N}^{+}$ and $x$ is a positive irrational number. Prove that there exist two real numbers $\alpha$ and positive $T$ such that, for any $k\in\mathbb{N}^+$, the interval $(\alpha + k \cdot T, \alpha + k \cdot T + T),$ contains exactly one number from $S$.","['calculus', 'irrational-numbers', 'number-theory']"
928008,Find the area where dog can roam [duplicate],"This question already has answers here : Area of the field that the cow can graze. (4 answers) Closed 9 years ago . A dog is tied to circular pillar by a rope. Radius of this pillar is $1m$ and length of rope is $\pi m$. What is an area where dog can roam? I tried to find the area of all semicircles and then to find its sum. It is easy to find an area at front side of the pillar. It is $\displaystyle\frac12\pi^2\pi=\frac{\pi^3}{2}$. Problem is how to find remaining area. I tried to write this area using compass and straightedge, but I couldn't. Then I wrote this in AutoCAD and it looks like this: Is it possible to find the exact value of this area?","['geometry', 'area']"
928040,How to solve the integral $\int \frac {(x^2 +1)}{x^4- x^2 +1} dx$,"I have started this problem but I'm not completely sure I'm going down the right path with it. So far I have completed the square in the denominator. $x^4-x^2+1= (x^2-1/2)^2+\frac{3}{4}$ Then, let $u=x^2-\frac{1}{2}$   so $x=\sqrt(u+\frac{1}{2})$ $\int\frac{x^2+1}{x^4-x^2+1}dx = \int\frac{u+\frac{1}{2}+1}{u^2+\frac{3}{4}}du
                             =\int\frac{u}{u^2+\frac{3}{4}} +\frac{\frac{3}{2}}{u^2+\frac{3}{4}}du$",['integration']
928074,Why is Euler's formula defined for non-integer values?,"Say that for some complex number $w$ $$e^{wi} = a$$ Now raise both sides to $1/4$. $$e^{wi/4} = a^{1/4}$$ Now $e^{wi/4}$ has a single defined  value. Yet $a^{1/4}$ can have multiple values. So why is Euler's formula well defined for non-integer powers, since non-integer powers can yield multiple values?","['complex-numbers', 'complex-analysis']"
928088,Determining the number of colourings of regions of a pentagon by Burnside's Lemma,"I have the question: The symmetry of a regular pentagon has 10 elements. Use 4 colours to colour the 5 regions of the pentagon below. Determine what the total number of distinct colourings of the pentagon using Burnside's lemma/counting theorem. (Two colourings are considered to be the same if there is a symmetry of the regular pentagon that maps one colouring to the other) Is this how I would go about a question like this? My solution. I'll refer to each $|\operatorname{fix}(g)|$ by a particular letter.
First, I have ' $A$ ', any one of the 4 colours could be chosen for each of the 5 regions.
This gives $4^5$ . Then I have the rotations around the centre point, ' $B$ '. There are 4 rotations ( $\frac {1}{5}, \frac 25, \frac 35, \frac 45$ ), with each being able to one of the 4 colours. Therefore I have $4 \times 4$ possible choices. Finally ' $C$ ', I have the rotations in regards to 'cutting' through the edge. There are 5 edges. Each when 'cut' causes 2 'pairs' of opposite regions to swap/transpose. When transposed, these regions must be the colour which they were transposed with. So I have the axis (the cutting edge) which can be one of 4 colours and the each of the pairs which can also be one of the 4 colours. Therefore $C = 5 \times 4^3$ To find the number of colourings, the equation is: $$
\begin{align}
\text{#Colourings} 
&= \tfrac {1}{10}[A + B + C] \\
&= \tfrac {1}{10}[4^5 + (4 \times 4) + (5\times 4^3)] \\
&= \tfrac {1}{10}[1360] \\
&= 136.
\end{align}
$$ Is this the correct method to go about a problem like this/have I missed anything?","['polya-counting-theory', 'combinatorics']"
928093,"If $f \circ g$ is surjective, $g$ is surjective","If $f \circ g$ is surjective, $f$ is surjective. If $f \circ g$ is surjective, $g$ is surjective. $\textbf{Part 1:}$ Let $f:B \to A$ and $g:C \to B$. Assume $f \circ g$ is surjective. Since $f(g(x))$ is surjective, for all $a \in A$ there is a $c \in C$ such that $f(g(c))=a$. But since $g(c) \in C$ (by definition of g), that means for all $a \in A$, there is a $b \in B$ (namely g(c) such that f(b)=a). So f is surjective. $\textbf{Part 2:}$ How would I amend the proof for Part 1 for Part 2?",['functions']
928105,Uniqueness of a continuous extension of a continuous map from a set to its closure,"Suppose $f$ is a continuous map from a space $A$ to a Hausdorff space Y. Then I know that $f$ can be extended uniquely to a continuous map from closure of $A$ to Y. What is a counterexample to the fact that this need not be true if Y is not Hausdorff? I think two point sets will work (and this has been hinted here Uniqueness of continuous extension from $A$ to $\overline{A}$ for maps into a Hausdorff space ), but how?",['general-topology']
928117,Closed form of $\int_0^{\frac{\pi}{3}} \log^2(\sin x) \mathrm{d}x$,"Inspired by the popularity of these kind of integrals appearing on MSE lately, I actually learned new methods to attack weird integrals by studying the beautiful answers on the similar past questions, so I conjecture $$\int_0^{\frac{\pi}{3}} \log^2(\sin x) \mathrm{d}x$$ has a closed form. How would someone approach this? PS; To be honest, I'm more interested in the methodology, as on the previous questions I lacked the mathematical background to understand them completely anyway. Which implies I don't want Cleo-like answers.","['calculus', 'integration', 'real-analysis']"
928129,Binomial distribution (working included),"I've been working on this question but I'm not too sure if I am correct... Any feedback or advice would be much appreciated. Question: 
Suppose an aircraft has a capacity of 500 passengers. The airline that operates it 'overbooks' the plane by accepting reservations for up to 575 passengers, because it knows from experience that 5% of passengers do not check in for the flight. a) Assuming that X, the number of passengers who check in for the flight, can be modelled by a binomial distribution, calculate the probability that one or more passengers will be denied the chance to board. My working: We can safely use the normal approximation to the binomial with such large numbers. mean = np = 575*0.95 = 546.25 sd = √(npq) = √(575*0.95*0.05) = 5.226 with continuity correction, > 500 becomes > 500.5 z-score = (500.5-546.25)/5.226 = -8.75 P(z> -8.75) ≈ 1 This means that for all practical persons, it is certain that one or more persons will be denied the chance to board.","['statistics', 'binomial-theorem', 'probability']"
928146,Integration by parts for multidimensional Lebesgue-Stieltjes Integrals,"I am concerned with the following problem: I am wondering if there exists any sort of integration by parts formula for a multidimensional Lebesgue-Stieltjes integral. In my case the integral is given by (1) and its domain is a multidimensional subset of $\mathbb{R}^n$. I suspect that this would involve the function $f$ instead of the corresponding measure $\mu$ according to Theorem 2 below. I am looking for a result similar to the well known result in the case of $n=1$, i.e.:
$$\int\limits_a^b g(t) \, df(t) = g(b)f(b)-g(a)f(a)-\int\limits_a^b f(t) dg(t)$$ I'd be greatful for any hint on literature that contains relevant information on such multidimensional scenarios. So far I found plenty of literature on the one-dimensional case, i.e. $\Omega \subset \mathbb{R}$, but nothing definitive on $\Omega \subset \mathbb{R}^n$ for $n>1$. Let's consider the following well known result from duality theory in Analysis: Theorem 1 (cf. Aliprantis Border, Infinite-Dimensional Analysis Theorem 14.14) Let $\Omega \subset \mathbb{R}^n$ and $\Phi: C_c(\Omega) \rightarrow \mathbb{R}$ be a continuous linear functional, where $C_c(\Omega)$ is the set of all real valued continous functions on $\Omega$ with compact support. Then $\Phi$ can be expressed the follwing way:
$$\Phi(g) = \int\limits_{\Omega} g(x) \, d\mu(x) \mspace{1in} \forall g \in C_c(\Omega)\tag{1}$$
where $\mu$ is a regular signed Borel measures of bounded variation, which is uniquely determined. To further work with this measure $\mu$ I found the following interesting fact: Let's define
$$\Delta_h f(x) := \sum\limits_\delta (-1)^{\sum_{i=1}^n \delta_i} f(x-h(\delta)) \tag{2}$$
with $\delta_i$ being either $0$ or $1$, $h = (h_1,\dots,h_n)$ and $h(\delta) = (h_1 \delta_1, \dots, h_n \delta_n)$ and the sum over $delta$ meaning the sum over all possible binary vectors with length $n$. Then the following theorem holds Theorem 2 (cf. Aliprantis Border, Infinite-Dimensional Analysis Theorem 10.50) If $f : \mathbb{R}^n \rightarrow \mathbb{R}$ is continuous from above and satisfies $\Delta_h f(x) \geq 0$ for all $x \in \mathbb{R}^n$ and all $h \in \mathbb{R}_+^n$, then there exists a unique Borel measure $\mu$ on $\mathbb{R}^n$ satisfying (2). Conversely, if $\mu$ is Borel measure on $\mathbb{R}^n$, then there exists a function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ (unique up to translation) that is continuous from above, satisfies $\Delta_h f(x) \geq 0$ for all $x \in \mathbb{R}^n$ and all $h \in \mathbb{R}_+^n$, and satisfies (2).","['measure-theory', 'lebesgue-measure', 'integration']"
928172,Why were affine spaces defined so?,"My geometry textbook gives this definition of affine space: A set $A$ is called ""affine space"" iff, given a $K$-vector space $V$, there exist a function $f$ from $A \times A$ to $ V $ such that the following conditions are satisfied: 1)for every $P \in A $ and $v \in V $ there exist one and only one $Q \in A $ such that $f((P,Q))=v$ 2)for every $P, Q, R \in A $, $f((P,Q))+f((Q,R))=f((P,R))$ What I could understand is that we are making a generalization of ordinary space. With this definition, the geometrical space built upon Hilbert axioms becomes a special case of affine space, because 1) and 2) hold. My question is: why were those two properties chosen to make such a generalization? Moreover, why was it necessary? why using linear algebra instead of the axiomatic or analytic (as in high school) approach?","['geometry', 'linear-algebra']"
928177,What is the probability that I roll a 2 before I roll two odd numbers?,"Assuming that I use a standard die, what is the probability that I roll a 2 before I roll  two odd numbers? The odd numbers do not have to be distinct. For example, 1,6,4,2 wins and 3,3 loses.",['probability']
928217,Definition of neighborhood,"I am starting to work through Rudin's Principles of Mathematical Analysis .  For $(X, d)$ a metric space and $x \in X$, Rudin defines the neighborhood $N_r(x)$ of $x$ to be the set consisting of all points $y$ such that $d(x,y) < r$.  My question is this: if $A \subset X$ and $a \in A$, then does $N_r(a)$ refer to the same set in both $A$ and $X$ the ambient space?  For example, if $X = \mathbb{R}$ and $A = \mathbb{Q}$, then is it the case that $N_{1/2}(a)$ is always the set $N = \{p \in \mathbb{R} : a - 1/2 < p < a + 1/2\}$, or can $N_{1/2}(a)$ be interpreted as the set $N' = \{q \in \mathbb{Q} : a - 1/2 < q < a + 1/2\}$?  Essentially I am asking if the notion of neighborhood is relative.  This would affect things like the interiority of points in a set.  For instance, $N$ is always contained in $\mathbb{R}$ so that $a$ is always an interior point of $\mathbb{R}$, but $N \not \subset \mathbb{Q}$ so that $a$ is never an interior point of $\mathbb{Q}$.  On the other hand, $N'$ is always contained in both $\mathbb{R}$ and $\mathbb{Q}$ so that $a$ is always an interior point of both of them.  (I guess $N$ is basically a neighborhood formed with respect to the whole space while $N'$ is a neighborhood formed with respect to a specific subspace of the metric.)  Thanks in advance.","['general-topology', 'definition', 'metric-spaces', 'analysis']"
928227,Powerset of $A\times B$,"$A = \{0,1\}$ and $B = \{1,2\}$, find $P(A\times B).$ And I found $A\times B = \{(0,1),(0,2),(1,1),(1,2)\}$ So if I wanted $P(A\times B),\text{would I do this:} \\
P(A\times B) = \{\emptyset,\{(0,1)\},\{(0,2)\},\{(1,1)\},\{(1,2)\},\{(0,1),(0,2)\},\{(0,1),(1,1)\}...,\{(0,1),(0,2),(1,1),(1,2)\}\}$ Or am I doing this wrong? $A\times B$ has $4$ elements, so $P(A\times B)$ should have $2^{n}$ elements, right?","['elementary-set-theory', 'proof-verification']"
928230,"After $10$ minutes, what is the probability that the fly is back on $A$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A fly is walking on a hexagon, at random. The fly starts at vertex $A$. After a minute, it moves to one of the two adjacent vertices. After $10$ minutes, what is the probability that the fly in back on $A$?",['probability']
928251,How to find the limit of $\lim_{x\to -\infty}\frac{3x^3+6x^2+45}{5|x|^3+25|x|+12}$,Evaluate $$\lim_{x\to -\infty}\dfrac{3x^3+6x^2+45}{5|x|^3+25|x|+12}$$ Is just a matter dividing all variables by $x^3$ and getting $\frac{3}{5}$? I tried looking it up and saw the graph doesn't just stop at $0$.,['limits']
928260,Modulus of continuity properties and uniform continuity.,"Let  $f:[a,b]\rightarrow \mathbb{R}$ bounded and $\omega(f,r)=\sup\{|f(x)-f(y)| \colon x,y \in [a,b], \ |x-y|<r\}$ (called modulus of continuity of $f$ EDIT note: the original question is in spanish, I'm not sure if the ""modulus of continuity"" is a proper translation from ""módulo de continuidad"") Show that the following properties of $\omega(f,r)$ are satisfied: if  $0<r_1 < r_2$  then $\omega(f,r_1)<\omega(f,r_2)$ $\omega(f,r_1+ r_2) \leq \omega(f,r_1) + \omega(f,r_2)$ $f$  is uniformly continuous if and only if $\lim_{r \searrow 0}\omega(f,r)=0$ If $\lambda>0$ then $\omega(f,\lambda r)< (1+\lambda)\omega(f,r)$ So far I have proved only the first one: Let $\gamma(r)=\{|f(x)-f(y)|\colon x,y \in [a,b], \ |x-y|<r\}$ Then $\gamma(r_1)\subseteq \gamma(r_2)$ Then $\sup\gamma(r_1) \leq \sup \gamma(r_2)$ (*) $\therefore \omega(f,r_1)\leq \omega(f,r_2)$ (*) Let $A,B \subseteq \mathbb{R}$ bounded above, such that $A \subseteq B$, we know that $\sup B$ is an upper bound of $A$ and by definition, $\sup A$ is the smallest upper bound of $A$ $\therefore \sup A \leq \sup B$. For the second I am trying to use a triangle inequality but I'm having a hard time incorporating it inside $\omega(f,r)$ if that makes any sense. I'm not exactly sure how I should start. For this one I tried using the definition of uniform continuity using sequences, but I'm not sure I'm writing it properly: $\forall \varepsilon >0$ $\exists \ (X_n)_{n=1}^\infty ,(Y_n)_{n=1}^\infty $ sequences in $[a,b]$, such that $|X_n-Y_n|<\frac{1}{n} \Rightarrow$  $|f(X_n)-f(Y_n)|<\varepsilon$ I don't know how to start with this one Any corrections, comments, suggestions are highly appreciated.","['functional-analysis', 'real-analysis', 'uniform-continuity']"
928271,Show that $ \sum_{k=0}^{r} \binom{r-k}{m} \binom{s+k}{n} = \binom{r+s+1}{m+n+1} $?,I can't resolve this exercise and I need a tip. $$ \sum_{k=0}^{r} \binom{r-k}{m} \binom{s+k}{n} = \binom{r+s+1}{m+n+1} $$ where $ n \geq s $.,"['summation', 'binomial-coefficients', 'combinatorics']"
928275,"Problem on the number of generators of some ideals in $k[x,y,z]$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I have got stuck with two generator problems: The ideal $(zx,xy,yz)$ can't be generated by $2$ elements. The ideal $(xz-y^2,yz-x^3,z^2-xy)$ can't be generated by $2$ elements. Here the ring is $k[x,y,z]$. Thanks in advance for any help.","['commutative-algebra', 'ideals', 'abstract-algebra']"
928276,Elementary Set Theory,"My question is $A\!\setminus \!B = A\cap B^C$ always true? Given that the definition for $A\!\setminus \!B := \lbrace{x \in A \mid x \notin B\rbrace}$ and that  $A\cap B^C:=\lbrace{x\mid x \in A \text{ and } x \in B^C\rbrace}$ I can't see why they would be different. If they are equal, when does one choose one notation over the other?",['elementary-set-theory']
928302,What is the difference between a field and a sigma field? [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Can someone explain what is the smallest sigma field? I need to know this Thanks,['probability']
928304,"If a subgroup acts transitively on a set, then the index of the subgroup equals the index of the stabilizer?","I am trying to prove the following: If a subgroup $H < G$ acts transitively on a set $X$, then $[G:H] = [G_x:H_x]$ for any $x \in X$ ($H_x$ denotes the point stabilizer of $x$ in $H$.) Any hints would be appreciated. (EDIT: I am mostly interested in the case where G and H are infinite. What if $X$ is infinite?)",['group-theory']
928306,"Show that if $X$ is a Hilbert space, then so is $Y$","Given that $X$ and $Y$ are normed linear spaces and that $T:X\to Y$ is a linear map, such that $T(\alpha x_1 + \beta x_2) = \alpha T(x_1)+ \beta T(x_2)$ for all vectors $x_1,x_2\in X$ and scalars $\alpha , \beta$. Suppose $T$ maps $X$ onto $Y$ and is isometric, $\|Tx\|=\|x\|$ for all $x\in X$. 1) Show that if $X$ is a Hilbert space then so is $Y$ if we define: $$\langle y_1,y_2\rangle_Y=\langle x_1,x_2\rangle_X$$ Where $x_1,x_2$ are the unique points in $X$ satisfying $Tx_1=y_1$ and $Tx_2=y_2$ What I have done so far I have previously proved that if $X$ is a Banach space then so is $Y$. So I am thinking that since $X$ is a Hilbert space, $$||y_1-y_2|| = ||T(x_1)-T(x_2)|| = ||T(x_1-x_2)||=||x_1-x_2|| \implies$$ $$||y_1-y_2||^2 = ||y_1||^2 - 2Re\langle y_1,y_2 \rangle + ||y_2||^2$$ $$||x_1-x_2||^2 = ||x_1||^2 - 2Re\langle x_1,x_2 \rangle + ||x_2||^2$$ and $$||y_1+y_2|| = ||T(x_1)+T(x_2)|| = ||T(x_1+x_2)||=||x_1+x_2|| \implies$$ $$||y_1+y_2||^2 = ||y_1||^2 + 2Re\langle y_1,y_2 \rangle + ||y_2||^2$$ $$||x_1+x_2||^2 = ||x_1||^2 + 2Re\langle x_1,x_2 \rangle + ||x_2||^2$$ Therefore $$||y_1+y_2||^2+||y_1-y_2||^2=2||y_1||^2+2||y_2||^2$$ Therefore the parallelogram equality holds for $Y$, and therefore there is an inner product that gives the norm, and so $||y_1 - y_2||=\sqrt{\langle y_1-y_2,y_1-y_2 \rangle}$ and therefore $Y$ is a Hilbert space.",['functional-analysis']
928319,"How to prove that $\int_0^b\Big(\int_0^xf(x,y)\;dy\Big)\;dx=\int_0^b\Big(\int_y^bf(x,y)\;dx\Big)\;dy$?","Problem. Let $f:[0,b]\times[0,b]\to\mathbb{R}$ be continuous. Prove that
  $$\int_0^b\left(\int_0^xf(x,y)\;dy\right)\;dx=\int_0^b\left(\int_y^bf(x,y)\;dx\right)\;dy.\tag{1}$$ My first thought was to use Fubini's theorem: the left hand side of $(1)$ equals the double integral
$$\iint_{D_1} f(x,y)\;dA\tag{2}$$
and the right-hand side equals
$$\iint_{D_2} f(x,y)\;dA,\tag{3}$$
where $D_1=\{(x,y);\;0\leq x\leq b,\;0\leq y\leq x\}$ and $D_2=\{(x,y);\;0\leq y\leq b,\;y\leq x\leq b\}$. Since $D_1=D_2$, the integrals $(2)$ and $(3)$ are the same and thus $(1)$ holds. However, the problem  is proposed before multiple integrals be defined. So my question is: how to solve the problem using single variable integrals? Remark. In the section that proposes the problem, we have the following theorem: if $f:[a,b]\times[c,d]\to\mathbb{R}$ is continuous, then
$$\int_a^b\left(\int_c^df(s,t)\;ds\right)\;ds=\int_c^d\left(\int_a^bf(s,t)\;ds\right)\;dt.$$ Proof: Let $\varphi:[a,b]\to\mathbb{R}$ be given by
$$\varphi(x)=\int_c^d\left(\int_a^xf(s,t)\;ds\right)\;dt.$$
Then,
$$\int_a^b\left(\int_c^df(s,t)\;ds\right)\;ds=\varphi(a)+\int_a^b\varphi'(s)\;ds=\varphi(b)=\int_c^d\left(\int_a^bf(s,t)\;ds\right)\;dt.$$ I tried to apply a similar argument to the problem, but I couldn't do it. Thanks.","['multivariable-calculus', 'calculus', 'real-analysis']"
928336,Is $\mathcal P(A) \times \mathcal P(B)=\mathcal P(A\times B)$?,"Let $A=\lbrace 1,2 \rbrace$ and $B=\lbrace 2,3,4 \rbrace$. Is  $\mathcal P(A)\times \mathcal P(B)=\mathcal P(A\times B)$? My attempt and reasoning, from the first one, I compute the powerset of both and get $\mathcal P(A)=\bigg\lbrace \lbrace 1 \rbrace, \lbrace 2 \rbrace, \lbrace 1,2 \rbrace,\emptyset \bigg\rbrace$ and $\mathcal P(B)=\bigg\lbrace \lbrace 2 \rbrace, \lbrace 3 \rbrace, \lbrace 4 \rbrace, \lbrace 2,3 \rbrace,\lbrace 2,4 \rbrace, \lbrace 3,4 \rbrace, \lbrace 2,3,4 \rbrace, \emptyset\bigg\rbrace$ and  $|\mathcal P(A) \times \mathcal P(B)|=32 \quad .$ The right hand side I compute $A \times B$ to get $\lbrace (1,2),(1,3),(1,4),(2,2),(2,3),(2,4),\emptyset \rbrace$ It is easy to see that $|\mathcal P(A \times B)|=36$ so they shouldn't be equal by this reasoning right?,","['discrete-mathematics', 'real-analysis']"
928344,Uncountable $\sigma$-algebra,"I'm stuck on the following problem (Source: Real Analysis for Graduate Students; Exercise 2.6; Bass ): Suppose $\mathcal A$ is a $\sigma$-algebra with the property that whenever $A \in \mathcal A$, there exists $B, C \in \mathcal A$ with $B \cap C = \emptyset$, $B \cup C = A$, and neither $B$ nor $C$ is empty. Prove that $\mathcal A$ is uncountable. I think there is the added assumption that this is only true for $A \in \mathcal A$ having at least two elements, so it doesn't hold for singletons and the emptyset? I tried to show this by way of contradiction and say that $\mathcal A = \{A_k\}$ is countable, but I didn't see how this could get me to a contradiction. The other approach I tried was to look at $X = B_1 \cup C_1$ where $B_1 \cap C_1 = \emptyset$, then look at $B_1 = B_2 \cup C_2$ where $B_2 \cap C_2 = \emptyset$ and so on. If I look at the $C_k$'s they are pairwise disjoint and I either have a finite number of them or an infinite number of them in which case I've created a countable sequence of pairwise disjoint nonempty elements of $\mathcal A$. This path looked promising, but I couldn't see what to do next. Any ideas? As a secondary question: I think this result is supposed to be used to show that if $\mathcal A$ is a $\sigma$-algebra with infinitely many elements, then it's uncountable, but I wasn't able to show that the property mentioned above (the one I'm trying to show) was satisfied in this case.",['measure-theory']
928345,I have two symmetric relations on a set. How can I prove that the symmetric difference is irreflexive?,"I have this problem. Let R and S be symmetric relations on a set A. Prove or disprove: $R \oplus S$ is irreflexive. Now I'm assuming it's not true, because $(x,x)$ can be an element of $R$ without being an element of $S$, but I'm not sure how to prove it. Any tips?","['relations', 'discrete-mathematics']"
928383,What in Mathematics cannot be described within set theory? [duplicate],"This question already has an answer here : Are there areas of mathematics (current or future) that cannot be formalized in set theory? (1 answer) Closed 9 years ago . I have begun reading Patrick Suppes' book Axiomatic Set Theory . The first sentence in chapter 1 reads: ""Among the many branches of modern mathematics set theory occupies a unique place: with a few rare exceptions the entities which are studied and analyzed in mathematics may be regarded as certain particular sets or classes of objects."" What are these rare exceptions? What in mathematics cannot be described within set theory?","['foundations', 'elementary-set-theory', 'soft-question']"
928408,How to show that every nonempty $X \subset \mathbb N$ has an $\in$-minimal element [duplicate],"This question already has answers here : Proving the so-called ""Well Ordering Principle"" (5 answers) Closed 9 years ago . I am trying to prove the following: Every nonempty $X \subset \mathbb N$ has an $\in$-minimal element. Proof: Take some $n \in X$. Then $\min \{ n \cap X \} = \min \{ X \}$. Is this ok or should it be more detailed?",['elementary-set-theory']
928415,A question on a proof that every sequence has a monotone subsequence,"Consider the following proof that every sequence $\{x_n\}_n$ in $\mathbb R$ has a monotone subsequence. Proof: Let us call a positive integer $n$ a peak of the sequence if $m > n  \implies x_n > x_m$ i.e., if $x_n$ is greater than every subsequent term in the sequence. Suppose first that the sequence has infinitely many peaks, $n_1 < n_2 < n_3 < … < n_j < …$ . Then the subsequence $\{x_{n_j}\}_j$ corresponding to these peaks is monotonically decreasing, and we are done. So suppose now that there are only finitely many peaks, let $N$ be the last peak and set $n_1 = N + 1$ . Then $n_1$ is not a peak, since $n_1 > N$ , which implies the existence of an $n_2 > n_1$ with $x_{n_2} \geq x_{n_1}.$ Again, as $n_2 > N$ it is not a peak, hence there is $n_3 > n_2$ with $x_{n_3} \geq x_{n_2}.$ Repeating this process leads to an infinite non-decreasing subsequence $x_{n_1} \leq x_{n_2} \leq x_{n_3} \leq \ldots$ as desired. In the second case, if $n_1$ is not a peak, how does this imply the existence of an $n_2 > n_1$ with $x_{n_2} \geq x_{n_1}$ ? Can't it be possible that there does not exist any $n_2 > n_1$ such that $x_{n_2} \geq x_{n_1}$ ? A possible example can be the sequence $\{\sin n\}_n$ , taking $N$ to be the closest integer to $\pi/2$","['sequences-and-series', 'real-analysis']"
928445,find the slope of the tangent line,"Sorry I couldn't figure out how to use the editor right now and I really need help with this question. 
Let $f(x)=\frac{1}{\sqrt[3]{x}}$. find the slope of the tangent line at $(8,\frac{1}{2})$
So far this is what I have I just don't know what to do from here $$
\begin{array}{lll}
m&=&\lim_{h \to 0}\frac{f(8+h)-f(8)}{h}\\
&=&\lim_{h \to 0} \frac{\frac{1}{\sqrt[3]{8+h}}-1/2}h \\
&=&\lim_{h \to 0} \ 2-\frac{\sqrt[3]{8+h}}{2\sqrt[3]{8+h}}\\
&=&\lim_{h \to 0} \frac{2-\sqrt[3]{8+h}}{2h\sqrt[3]{8+h}}\\
\end{array}
$$ Can someone please help me out please","['calculus', 'algebra-precalculus']"
928452,$\int\frac{dx}{x-3y}$ when $y(x-y)^2=x$?,"If y is a function of x such that $y(x-y)^2=x$ Statement-I: $$\int\frac{dx}{x-3y}=\frac12\log[(x-y)^2-1]$$ Because Statement-II: $$\int\frac{dx}{x-3y}=\log(x-3y)+c$$ Question: Is Statement-I true? Is Statement-II true? Is Statement-II a correct explanation for Statement-I ? I can say that II is false because y is not a constant but indeeed a function, I don't know answers to other two questions.I am thinking that probably we have to eleiminate y from the given functional equation or do a clever substitution?",['integration']
928455,The Uniqueness Part of the Smooth-Manifold-Chart-Lemma in John M. Lee's Introduction to Smooth Manifolds.,"I am trying to understand the proof of Lemma 1.35 (Smooth Manifold Chart Lemma) of John. M. Lee's Introduction to Smooth Manifolds , 2nd Edition. The Lemma is an existence-and-uniqueness-lemma. I understand the existence part of it but not the uniqueness part. Here I state the Lemma and the proof of the existence part (the proof is essentially just a detailed version of the proof given in Lee's book.) LEMMA. Let $M$ be a set and $\{U_\alpha\}_{\alpha\in J}$ be a collection of subsets of $M$ , along with maps $\varphi_\alpha:U_\alpha\to\mathbf R^n$ , such that the following properties are satisfied: (i) $\forall \alpha\in J$ : $\varphi_\alpha$ is an injective map and $\varphi_\alpha(U_\alpha)$ is open in $\mathbf R^n$ . (ii) $\forall \alpha,\beta\in J$ : the sets $\varphi_\alpha(U_\alpha\cap U_\beta)$ and $\varphi_\beta(U_\alpha\cap U_\beta)$ are open in $\mathbf R^n$ . (iii) $\forall\alpha,\beta\in J$ : $U_\alpha\cap U_\beta\neq \emptyset
			\quad
			\Rightarrow
			\quad \varphi_\beta\circ\varphi_\alpha^{-1}:\varphi_\alpha(U_\alpha\cap U_\beta)\to \varphi_\beta(U_\alpha\cap U_\beta)$ is smooth. (iv) Countably many of the sets $U_\alpha$ cover $M$ . (v) $
\left.
\begin{array}{c}
p,q\in M\\
p\neq q
\end{array}
\right\}
\quad
\Rightarrow
\quad
\left\{
\begin{array}{c}
\exists \alpha\in J\text{ such that } p,q\in U_\alpha,\quad\text{ or}\\
\exists \alpha,\beta\in J\text{ such that } p\in U_\alpha, q\in U_\beta \text{ and } U_\alpha\cap U_\beta=\emptyset
\end{array}
\right.
$ Then $M$ has a unique manifold structure such that each pair $(U_\alpha,\varphi_\alpha)$ is a smooth chart. PROOF. Let $\mathcal B=\{\varphi_\alpha^{-1}(V):\alpha\in J, V\text{ open in } \mathbf R^n\}$ . Claim 1: $\mathcal B$ forms a basis for $M$ . Proof: We use $(i)$ --- $(iv)$ in this proof. 
From $(iv)$ we see that the elements of $\mathcal B$ cover $M$ .
Now let $\varphi_\alpha^{-1}(V)$ and $\varphi_\beta^{-1}(W)$ be two elements of $\mathcal B$ , where $V$ and $W$ are open in $\mathbf R^n$ .
To show that $\mathcal B$ forms a basis, it is enough to show that $ \varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ itself lies in $\mathcal B$ .
Note that \begin{equation*}
\varphi_\alpha^{-1}(V)\cap \varphi_\beta^{-1}(W)=\varphi_\alpha^{-1}\Big(V\cap(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)\Big)
\tag{1}
\end{equation*} But by (iii), $\varphi_\beta\circ\varphi_\alpha^{-1}$ is continuous, and therefore $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\varphi_\alpha(U_\alpha\cap U_\beta)$ .
By (ii), $\varphi_\alpha(U_\alpha\cap U_\beta)$ is open in $\mathbf R^n$ and therefore $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\mathbf R^n$ .
Using this in $(1)$ , we immediately see that $\varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ is in $\mathcal B$ .
This settles the claim. Let $\tau$ be the topology generated on $M$ by $\mathcal B$ .
By definition of $\mathcal B$ , each function $\varphi_\alpha$ is a homeomorphism onto its image.
Thus $(M,\tau)$ is locally Euclidean of dimension $n$ . Claim 2: $(M,\tau)$ is Hausdorff. Proof: This uses $(v)$ . Let $p,q\in M$ with $p\neq q$ . If $\exists \alpha,\beta\in J$ such that $p\in U_\alpha, q\in U_\beta$ and $U_\alpha\cap U_\beta=\emptyset$ , then we have nothing to prove. The other possibility if that $\exists \alpha\in J$ such that $p,q\in U_\alpha$ .
            Now since $\varphi_\alpha(U_\alpha)$ is open in $\mathbf R^n$ , there exist disjoint open sets $V$ and $W$ open in $\varphi_\alpha(U_\alpha)$ containing $p$ and $q$ respectively. The neighborhoods $\varphi_\alpha^{-1}(V)$ and $\varphi_\alpha^{-1}(W)$ separate $p$ and $q$ in $M$ . Thus the claim is settled. Claim 3: $(M,\tau)$ is second countable. Proof: Note that since $\varphi_\alpha(U_\alpha)$ is second countable, and since $\varphi_\alpha:U_\alpha\to\varphi_\alpha(U_\alpha)$ is a homeomorphism, we must have $U_\alpha$ is second countable. The proof is now immediate from $(iv)$ and Lemma given at the bottom. The above working shows that $(M,\tau)$ is a topological $n$ -manifold. Now from $(iii)$ it is clear that $\{(U_\alpha,\varphi_\alpha)\}_{\alpha\in J}$ is a smooth atlas on $M$ , giving $M$ a smooth structure. Now we need to establish that this is the only smooth structure on $M$ such that each $\varphi_\alpha:U_\alpha\to\varphi_\alpha(U_\alpha)$ is a smooth chart on $M$ and here I am stuck.
In fact what Lee writes is that ""It is clear that this topology and smooth structure are the unique ones satisfying the conclusions (conditions?) of the lemma.""
Can somebody please explain this to me. LEMMA. Let $X$ be a topological space and $\{U_n\}_{n\in\mathbf N}$ be a countable open cover of $X$ such that each $U_i$ is second countable in the subspace topology. Then $X$ is second countable.","['smooth-manifolds', 'differential-geometry']"
928463,"If $y=f(x)$ is a linear function satisfying the relation $f(xy)=f(x)f(y)$, then the curve $P(x,y)=\alpha$ cuts $y=f^{-1}x$ at?","If $y=f(x)$ is  a linear function satisfying the relation $f(xy)=f(x)f(y)\forall x,y\in\mathbb R$, then the curve $$y^2+\int_0^x(\sin t+a^2t^3+bt)dt=\alpha,\alpha\in\mathbb R^+$$
  cuts $y=f^{-1}x$ at? My try: $f(x)=x$ and $f^{-1}(x)=x$ $y^2-\cos x+\frac14a^2x^4+\frac12bx^2=\alpha-C=C'$ So $x^2+C'=\cos x-\frac14a^2x^4-\frac12bx^2$ Edit: Options are: No point. exactly one point. at least two points.( Correct Option ) infinite points.","['integration', 'functions']"
928524,Difference between external and internal direct product?,What is the difference between external and internal direct product ?? I think both of them boil down to the same thing.,['abstract-algebra']
928531,"Runge-Kutta 8(5,3)","This is actually three small very related questions about Runge-Kutta methods. I have programmed a RK 7(8) method also RK 4(5). At the beginning I was assuming that the RK 7(8) uses two approximations of different order, one of order 7 an another of order 8. The difference between the two approximations is used to estimate the error of integration, and the algorithm returns the approximation of order 8. But by using an system of ODE's for which I know the exact answer (as a test method), I have seen that the approximation of order 7 gives a smaller error. As when we write RK 7(8) we write first the 7, is it supposed that the method is of order 7 or 8? When we say order $k$ , do we mean that the approximation is up to order $k$ or that the error is of order $k$ ? Python programming language provides a routine called dop853 that performs a Runge Kutta 8(5,3). What does it mean exactly when the method is specified by three numbers. Thank you very much.","['ordinary-differential-equations', 'runge-kutta-methods', 'soft-question', 'math-software', 'numerical-methods']"
928536,"Analysis of $f(x,y,z)=\frac{\sin(xyz)} {x^2+y^2+z^2}$","$f(x,y,z)=\frac {\sin(xyz)} {x^2+y^2+z^2}$ or $0$ if $(x,y,z)=(0,0,0)$ The problem says the following: a) Where is this function continuous, and b) Where is it differentiable? At a quick glance, the only point which might give problems is the origin point. For (a), I did the following: To prove that the limit of the first part of the function is 0 I used an $\epsilon-\delta$ proof of said limit. If $0<|(x^2+y^2+z^2)|<\delta$ then $|\frac {\sin(xyz)} {x^2+y^2+z^2}|<\epsilon$ The inequalities I used are: $|\frac {\sin(xyz)} {x^2+y^2+z^2}|<|\frac {xyz} {x^2+y^2+z^2}|<|\frac {(x^2+y^2+z^2)^{3/2}}
{x^2+y^2+z^2}|<|\sqrt{x^2+y^2+z^2}|<\epsilon$, so that if $\epsilon=\delta$, the limit is proven to exist and equal 0, so f is continuous in $R^3$ And for (b) I used spherical coordinates: $x=r\cos\theta \sin\varphi , y=r\cos\theta \sin\varphi , z=r\cos\varphi$ so the function is now $f(x,y,z)= \frac {\sin (r^3 \cos\theta \sin\theta \cos\varphi \sin^2\varphi)} {r^2}$ The differentiability condition is that, if f is to be differentiable
  in a given point, f must tend to the limit faster than the distance
  between the test point and the point where the function is being
  evaluated. In this case, $\lim_{(x,y,z)\rightarrow (0,0,0)}\frac
 {f(x,y,z)} {r} = 0$ must be true for f to be differentiable
  everywhere. Substituting the function, this translates into $\lim_{(x,y,z)\rightarrow (0,0,0)}\frac {\sin (r^3 \cos\theta \sin\theta \cos\varphi \sin^2\varphi)} {r^3}$, but since r goes to 0, we can ""take
  out"" the sine, and then the distances cancel out. What is left is
  $\cos\theta \sin\theta \cos\varphi \sin^2\varphi$, which does not equal 0
  unless you chose a path contained within one of the planes generated
  by two cartesian axes (and so the limit does not exist at all), so f is differentiable everywhere but the origin. The question is, simply: What or where did I go wrong? Many, many thanks in advance.","['multivariable-calculus', 'real-analysis']"
928540,Expected run in a run test.,"The run test is used to know whether the given data is random or not. 
How can we derive the formula for the expected run with $n_1$ ups and $n_2$ downs.","['statistics', 'probability']"
928545,Stability analysis for a system of two differential equations,"I have this system of differential equations:
\begin{equation}
\frac{dx}{dt}=\alpha x-\beta xy\\
\frac{dy}{dt}=\beta xy-\gamma y
\end{equation} I need to find the critical points and then do a stability analysis. After this I need to find the solutions curves for this system. I have started like this:
The critical points are $(0,0), (0,\frac{\alpha} {\beta}), (\frac{γ}{β},0)$. Is this correct? As I understand it I need to create a Jacobian matrix: $g(X)$= $\begin{pmatrix}
\alpha & -\beta x  \\
\beta y & -\gamma 
\end{pmatrix}$, where $X=(x,y)^T$ Then form: (also matrices) $A_1=g(0,0)$= $\begin{pmatrix}
\alpha & 0  \\
 0 & -\gamma 
\end{pmatrix}$,
$A_2=g\bigl(0,\frac{\alpha} {\beta}\bigr)$= $\begin{pmatrix}
\alpha & 0  \\
 \alpha & -\gamma 
\end{pmatrix}$,
$A_3=g\bigl(\frac{γ}{β},0\bigr)$= $\begin{pmatrix}
\alpha & -\gamma  \\
 0 & -\gamma 
\end{pmatrix}$ My question is how do I know which one is stable? and then how do I form the solution curves.","['ordinary-differential-equations', 'stability-in-odes', 'systems-of-equations']"
928638,Log likelihood function for logistic regression,"If the training set S represents are an independent and identically distributed (i.i.d.) sample of a Bernoulli distribution and in logistic regression log likelihood function is given as, $$L(y_i,f)=-\sum_{i=1}^m {{y_i} \text{log } \pi(x_i)+ (1-y_i)\text{log }(1-\pi(x_i)}$$ but in paper's log likelihood function is also written as $$L(y_i,f)=\sum_{i=1}^n \log(1+e^{-y_if(x_i)})$$ I am confused are these two expression same or they are different. If same how to derive the second equation from first.","['statistics', 'regression-analysis']"
928642,Calculating $\sum_{k=1}^nk(k!)$ combinatorially [duplicate],This question already has answers here : Combinatorial proof of $\sum_{k=1}^n k k!=(n+1)!-1$ (9 answers) Closed 7 years ago . The sum $\sum_{k=1}^nk(k!)$ can be easily calculated by noting $k(k!)=(k+1)!-k!$. Is there a way to calculate the sum nicely using a combinatorial argument. Is it possible to notice it is $(n+1)!-1$ combinatorially?,"['factorial', 'summation', 'combinatorial-proofs', 'combinatorics']"
928644,"Let $f,g$ be $\mathcal E$-$\mathcal B(\mathbb R)$-measurable functions. I want to show piecewise function $h$ of $f$ and $g$ is also measurable.","Let $f,g$ be $\mathcal E$-$\mathcal B(\mathbb R)$-measurable functions. I want to show piecewise function $h$ of $f$ and $g$ is also measurable. Suppose $(X, \mathcal E)$ is a measure space, let $f,g$ be $\mathcal E$-$\mathcal B(\mathbb R)$-measurable functions and let $A \in \mathcal E$. I want to show $h: X \rightarrow \mathbb R$ given by $ h(x) = \left\{
     \begin{array}{lr}
       f(x)  : x \in A\\
       g(x) : x \in A^C
     \end{array}
   \right.\\$ is again a $\mathcal E$-$\mathcal B(\mathbb R)$-measurable function. I've tried writing $(-\infty, a]$ as two disjoint sets $A_1, A_2$ such that $A_1 \cup A_2 = (-\infty, a]$, but then $f^{-1}(-\infty, a]) = f^{-1}(A_1 \cup A_2) = f^{-1}(A_1) \cup f^{-1}(A_2)$ and I can't say whether this is an element of $\mathcal E$. Also I don't use that $A \in \mathcal E$. Can anyone help ?","['measure-theory', 'real-analysis']"
928651,Show that $\max(\mathrm{Re} (\exp(it)\cdot z) = |z| $,"I need to show that $\max(\mathrm{Re} (\exp(it)z) = |z| $, with $t\in \mathbb{R}$ and $z\in \mathbb{C}$. Therefore I have calculated $\exp(it) = \cos(t) + i \sin(t)$. If we write $z=  a+bi$, then
$$
\mathrm{Re}(\exp(it)z) = \mathrm{Re}(\exp(it)(a+bi) = a\cdot \mathrm{Re}(\cos t + i\sin t) + b\cdot \mathrm{Re}(i\cos t - \sin t) = 
$$
$$
a\cdot \cos t - b \cdot \sin t
$$ To calculate the maximum, I figured to set the derivative equal to zero, so
$$
-a \cdot \sin t - b\cdot \cos(t) = 0
$$ From here, I do not know how to proceed.","['trigonometry', 'complex-analysis']"
928674,Solving $y^3=x^3+8x^2-6x+8$,"Solve for the equation $y^3=x^3+8x^2-6x+8$ for positive integers x and y. My attempt- $$y^3=x^3+8x^2-6x+8$$
            $$\implies y^3-x^3=8x^2-6x+8$$
            $$\implies (y-x)(y^2+x^2+xy)=8x^2-6x+8$$ Now if we are able to factorise $8x^2-6x+8$ then we can compare LHS with RHS.Am I on the right track?Please help.","['algebra-precalculus', 'diophantine-equations', 'number-theory']"
928707,Solving a tough integral,"I am studying telecommunications theory and I was doing an exercise where it's required to find the (infinite) taps of a zero forcing equalizer. Here's the point where I am stuck at: $$
p_\ell=T\int_{-\frac{1}{2T}}^{\frac{1}{2T}}\frac{e^{j2\pi f\ell T}}{1+\alpha e^{-j2\pi fT}}df
$$
Where: $\ell\in \mathbb{Z}$ $0<\alpha<\frac{1}{2}$ $T>0$ $T,\alpha\in\mathbb{R}$ That comes out because the channel time domain response is:
$$
g(t)=\delta(t)+\alpha\delta(t-T)
$$
And its fourier transform of course is:
$$
G(f)=1+\alpha e^{-j2\pi fT}
$$
In a ZF equalizer it is required that the total f-response of the channel and equalizer is unity, i.e. $ P(f)\cdot G(f)=1 $, so to find the $p_\ell$ sequence one has to anti-transform $\frac{1}{G(f)}$. It doesn't look to me I've done any errors before the integral but I don't have a clue on how to solve it, if possible. Some help/hints would be very appreciated. Thanks to PhoemueX answer : $$
\frac{1}{1 + \alpha e^{-2\pi i f T}} = \frac{1}{1 - (- \alpha e^{-2\pi i f T})} = \sum_{n=0}^{\infty} (-\alpha \cdot e^{-2\pi i f T})^n,
$$ So let's start rocking: $$
p_\ell=T\int_{-\frac{1}{2T}}^{\frac{1}{2T}}e^{j2\pi f\ell T}\sum_{n=0}^{\infty} (-\alpha \cdot e^{-2\pi i f T})^ndf=\\
=T\sum_{n=0}^{\infty}\int_{-\frac{1}{2T}}^{\frac{1}{2T}}(-\alpha)^ne^{j2\pi f T(\ell-n)}df=\\
=\frac{T}{j2\pi T}\sum_{n=0}^{\infty}\frac{(-\alpha)^n}{\ell-n}
\left(e^{j\pi(\ell-n)}-e^{-j\pi(\ell-n)}\right)=\\
=\frac{2j}{2j\pi}\sum_{n=0}^{\infty}(-\alpha)^n\frac{\sin[\pi(\ell-n)]}{\ell-n}=\\
=\sum_{n=0}^{\infty}(-\alpha)^n\text{sinc}(\ell-n)
$$ That last line equals zero whenever $\ell\neq n$, while when $\ell=n$ the sinc is not defined. We can not compute the limit because that is nonsense in $\mathbb{Z}$ but looking at the second equation we can see that when $\ell=n$ the integral becomes trivial and that sum equals $(-\alpha)^\ell$ To sum up:
$$
p_\ell=(-\alpha)^\ell
$$ Math is awesome.","['fourier-analysis', 'integration']"
928712,Solve the equation: $1+2^x+4^x+8^x+16^x+32^x=3(1+2^x+4^x)$,"I am doing some math repetition and am a bit stuck on this exercise: Solve the equation: $1+2^x+4^x+8^x+16^x+32^x=3(1+2^x+4^x)$. Now, this is a geometric sum on both the $LHS$ and $RHS$, which I guess is something that I should use to solve the equation... Another way is to simply start to eliminate terms: $$1+2^x+4^x+8^x+16^x+32^x=3+3 \times 2^x+3\times4^x$$ $$-2 -2\times 2^x -2\times4^x+8^x+16^x+32^x = 0$$ $$8^x+16^x+32^x = 2 +2\times 2^x +2\times4^x$$ $$8^x+16^x+32^x = 2(1 + 2^x + 4^x)$$ But I am stuck here...","['exponentiation', 'algebra-precalculus']"
928715,"Find $\lim_{x \to 0^+}x\int_x^1 \frac{\cos t}{t^2}\,dt$","Find
$$\lim_{x \to 0^+}x\int_x^1 \dfrac{\cos t}{t^2}\,dt$$ This looks like an interesting problem,but i cannot figure out where to start, can anyone explain","['calculus', 'integration', 'limits']"
928735,Find solution of equation $(z+1)^5=z^5$ [duplicate],"This question already has answers here : Solving $(z+1)^5 = z^5$ (6 answers) Closed 9 years ago . I attempt to solve the equation $(z+1)^5=z^5$. My first approach is to expand the left hand side but ı get more complicated equation. So I couldn't go further. Secondly, I write equation as, since $z\neq0$, $(\frac{z+1}{z})^5=1$, put $\xi=\frac{z+1}{z}$ and attempt to solve equivalent equation $\xi^5=1$. But this time it requires more computation to find solutions $z$. Can anyone suggest a simple way to solve this equation?
Thanks in advance..","['complex-numbers', 'complex-analysis']"
928739,Expected number of subtree removal in a tree.,"I was solving this problem. In a gist the problem is as follows: You are given a rooted tree. On each step you choose a node randomly and remove the subtree rooted by that node and the node itself, until all of them have been removed (that is root has been chosen). Find the expected number of steps in this process. In the editorial it is written that the direct removal of the node $i$ (that node $i$ has been chosen, not its ancestors) is $\frac{1}{\text{Depth[i]}}$. Intuitively I realise that if some node has more ancestors then the probability that its ancestor is chosen (hence the node $i$ got removed) is more than the node itself. Hence, more ancestors implies lesser the probability of direct removal. But how the probability is exactly equal to $\frac{1}{\text{Depth[i]}}$, that I couldn't understand. Please help.","['trees', 'probability', 'expectation']"
928746,How to prove $\exp(\ln M)=M$,Given a $n\times n$ real (complex) matrix $A$. Let me define: $$\exp A=\sum_{n=0}^\infty \frac{A^n}{n!}$$ and $$\ln A=\sum_{n=1}^\infty (-1)^{n+1}\frac{(A-I)^n}{n}$$ Let assume that the $2$ above series converge for $A=M$. How can I prove that: $$\exp(\ln M)=M$$,['linear-algebra']
928772,"If$(ab)^n=a^nb^n$ & $(|G|, n(n-1))=1$ then $G$ is abelian [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $G$ be a group. If $(ab)^n=a^nb^n$ $\forall a,b \in G$ and $(|G|, n(n-1))=1$ then prove that $G$ is abelian. What I have proven is that: If $G$ is a group such that $(ab)^i = a^ib^i$ for three consecutive integers $i$ for all $a, b\in G$ , then $G$ is abelian. A proof of this can be found in the answers to this old question.","['group-theory', 'abelian-groups']"
928795,Solving an integral (using Cauchy contour integral?),"I need to solve this integral: 
\begin{equation}
f(t)=\int_0^\infty x^2 \sqrt x \left( e^{a x} -1\right)^{-1/2} \frac{e^{i(b-x)t}-1}{b-x} dx
\end{equation}
where $a$ and $b$ are real, positive constants. I was thinking Cauchy contour integral might help.. Any help/advice is welcome!","['calculus', 'integration', 'contour-integration']"
928809,Algebra problem involving Q functions,"I have the following algebra problem, which is actually the end-part of my bigger research problem. Let $a$, $b$ and $m$ be reals with $a<b$. Also, let $Q(\cdot)$ denote the Gaussian Q-function, i.e., $Q(x) = \frac{1}{\sqrt{2\pi}}\int_{x}^{\infty} e^{-t^2/2} dt$. I have the quantities $b_{\infty} = e^{-\frac{m^2}{2}} \left[ Q(a) - Q(b) \right]$ $b_0 = \sqrt{[Q(a+m) - Q(b+m)][Q(a-m) - Q(b-m)]}$ $b_1 = \sqrt{[Q(a+m) - Q(t+m)][Q(a-m) - Q(t-m)]} + \sqrt{[Q(t+m) - Q(b+m)][Q(t-m) - Q(b-m)]}$ and I am trying to prove that, for any $a<b$, and for any $m$, there is a $a<t<b$ such that $b_1^2 \leq b_0 b_{\infty}$. I am certain that such $t$ exists, having done thourough simulations on the matter, but I cant show it anallytically. If you have a good eye in algebra, I would appreciate your input.","['statistics', 'calculus', 'analysis']"
928811,"Differentiation of the Law of Cosines, where a, b, c, A, B, and C are functions of time t","Is the differentiation of the law of cosines ($c^2= a^2 + b^2 - 2ab\cos C$) this? a, b, c, A, B, and C are functions of time t. $$2c \frac{dc}{dt} = 2a \frac{da}{dt} + 2b\frac{db}{dt} - 2b \cos C \frac{da}{dt} - 2 a \cos C \frac{db}{dt} + 2ab \sin C \frac{dC}{dt}$$",['derivatives']
928815,"If all mappings $f: A\to B$ are many-to-one, does there exist surjective $g: A\to B$?","Suppose sets $A$ and $B$ [edit: for $B\ne \emptyset$] are such that all mappings $f: A\to B$ are many-to-one (i.e. not injective). Can we prove that there must exist a surjective $g: A\to B$? Ideally, I am hoping to be able to construct $g$.","['proof-writing', 'elementary-set-theory']"
928816,Find the integral $\int_{0}^{\frac{\pi}{4}}\frac{\sin{x}\cos{x}}{\sin{x}+\cos{x}}dx$,"find the integeral 
$$\int_{0}^{\frac{\pi}{4}}\dfrac{\sin{x}\cos{x}}{\sin{x}+\cos{x}}dx$$ I know 
$$\dfrac{2\sin{x}\cos{x}}{\sin{x}+\cos{x}}=\dfrac{(\sin{x}+\cos{x})^2-1}{\sin{x}+\cos{x}}=\sin{x}+\cos{x}-\dfrac{1}{\sin{x}+\cos{x}}$$ and
$$\int(\sin{x}+\cos{x})dx=\sin{x}-\cos{x}+C$$
and
$$\int\dfrac{1}{\sin{x}+\cos{x}}dx=\int\dfrac{1}{\sqrt{2}}\csc{(x+\dfrac{\pi}{4})}dx=\dfrac{1}{\sqrt{2}}\cdot(-\ln{(\cot{x}-\csc{x})})+C$$ I think this intgral have other methods.because this is simple form, so My Question:
can you have other methods?",['integration']
928848,A function with zero gradient is locally constant,"A mapping $f:X\to Y$ is defined to be locally constant if $\forall x\in X$, there exists a neighbourhood $V(x)$ containing $x$ such that $a\in V(x)\implies f(a)=x_0$ for some constant $x_0$. In other words, every point in that neighbourhood maps to the same image . My book says that if $\text{grad }f=0$ for all $x \in X$, then $f$ is locally constant. Could someone give a proof of this fact? It has been confusing me for some time now!",['general-topology']
928857,Minimizing $\tan^2 x+\frac{\tan^2 y}{4}+\frac{\tan^2 z}{9}$,"Given that $\tan x+2\tan y+3\tan z=40 , \ \ \ x,y,z \in \left(\dfrac{\pi}{2},\dfrac{3\pi}{2}\right),$ We need to find the minimum value of $ \tan^2 x+\dfrac{\tan^2 y}{4}+\dfrac{\tan^2 z}{9}$ One way would be to consider the vectors 
$$\begin{align}
&\vec{v_1}=\tan x \ \hat{i}+\dfrac{\tan y}{2} \ \hat{j}+\dfrac{\tan z}{3} \ \hat{k} \ \ \ \ \ \ \ \ \text{and}\\ &\vec{v_2}=\hat{i}+4 \ \hat{j}+9 \ \hat{k}
\end{align}$$ And then apply to them the inequality $\left(\vec{v_1} \cdot \vec{v_2}\right)^2 \leq \left|\vec{v_1}\right|^2 \left|\vec{v_2}\right|^2$. Using this we get $\tan^2 x+\dfrac{\tan^2 y}{4}+\dfrac{\tan^2 z}{9} \geq \dfrac{1600}{98}$ Is this method fine? What are other methods to solve this problem, which do not involve vectors or complex numbers? Can this result be obtained by using elementary calculus? Thank you.","['optimization', 'trigonometry', 'calculus']"
928873,Prove by induction that $n < 2^n$ for all $n \ge 1$ [duplicate],"This question already has answers here : Prove that $ n < 2^{n}$ for all natural numbers $n$. [duplicate] (12 answers) Closed 6 years ago . I'm trying to do homework problems and for the most part I've been getting the results. For this one though, I am having some trouble since its $2^n$ and I can't relate it properly: Prove using simple induction that $n < 2^n$ for all $n \ge 1$. So obviously, the basis step holds as $1 < 3$. Now, I assume that $n = k$ holds as well and have to prove for $n=k+1$. This is the step I am having trouble with as I cannot relate the induction hypothesis with what I want to end up with. Can anybody show me a model solution for this one? I think my trouble comes because of the $2^n $","['induction', 'discrete-mathematics', 'proof-writing']"
928924,Proof of Gauss theorem (divergence theorem) in $\mathbb R^2$,"I am trying to solve an exercise in where it is asked to show the divergence theorem, or also known as Gauss theorem, in $\mathbb R^2$ using Green's theorem. I suppose that the divergence theorem in $\mathbb R^2$ is that for a $C^1$ vector field $F:\mathbb R^2 \to \mathbb R^2$ defined on a $3$ type region $D$ such that $\partial D$ is a closed curve, we have $$\iint_D div(F)dA=\int_{\partial D} Fds$$ I've tried to prove this theorem applying Green's theorem but I coudn't, I would appreciate if someone could provide a solution using Green's theorem (or at least the steps I should follow to prove the equality).","['multivariable-calculus', 'integration']"
928930,Obtaining Wirtinger presentation using van Kampen theorem,"Hatcher's Algebraic Topology , section 1.2, problem #22 describes an algorithm for computing the Wirtinger presentation of the complement of a smooth or piecewise linear knot K in $\mathbb{R}^3$: Position the knot to lie almost flat on a table, so that K consists of finitely many disjoint arcs $\alpha_i$ where it intersects the table top together with finitely many disjoint arcs $\beta_l$ where K crosses over itself...We build a 2-dimensional complex X that is a deformation retract of $\mathbb{R}^3-K$ by the following three steps. First, start with the rectangle T formed by the table top. Next, just above each arc $\alpha_i$ place a long, thin rectangular strip $R_i$, curved to run parallel to $\alpha_i$ along the full length of $\alpha_i$ and arched so that the two long edges of $R_i$ are identified with points of T...Any arcs $B_l$ that cross over $\alpha_i$ are positioned to lie in $R_i$. Finally, over each arc $B_l$ put a square $S_l$ bent downward along its four edges so that these edges are identified with points of three strips $R_i$, $R_j$, and $R_k$...namely, two opposite edges of $S_l$ are identified with two arcs crossing the interior of $R_i$. The knot K is now a subspace of X, but after we lift K up slightly into the complement of X, it becomes evident that X is a deformation retract of $\mathbb{R}^3-K$. The actual problem is to assume this geometry is valid, and then ""apply van Kampen's theorem at each step"" to get the Wirtinger presentation. My main trouble with the problem is trying to actually make sense of this geometry. First, if the knot is ""almost flat"" on the table, does that mean that it is entirely on top of the table, in such a way that if I think of the string as a road, cars going across it will have to take some kind of almost-u-turn in the transition from one of the $\alpha_i$ arcs to another? I'm struggling to describe what I'm talking about, but it's the only way I can make physical sense of the entire knot being on the table, but also divided into multiple different pieces (""arcs""). Next, the squares. The best I can tell from the diagram is that the square ""$S_l$"" is really just a piece cut out of $R_i$ with the two bottom (i.e., table-intersecting) edges that touch $R_j$ and $R_k$ identified with the bottom pieces of those strips at the ends where they meet it. Is that right, or way off base? Finally, the last sentence. I can't imagine how just picking K up off of X shows that it is a deformation retract of the entire knot complement. I don't think a more detailed explanation of this is actually necessary for proving the Wirtinger presentation of the fundamental group, since the problem basically allows me to assume this is true and it isn't actually one of the steps for ""constructing"" X, but I'd still like to have some understanding of it. Any help with seeing what this retraction looks like would be appreciated.","['general-topology', 'algebraic-topology', 'knot-theory']"
928944,A question about the convergence of partial products of zeta of one.,"Recently I've been toying around with the Totient function and the Prime Number Theorem and came up with the odd result that the following limit $$\lim_{n\to\infty}\frac{\pi(n)m_n}{\phi(m_n)n}$$ where $$m_n\equiv\prod_{i=1}^{n}p_i$$ where $p_i$ is the $i$th prime converges to approximately $e$ (somewhat verified computationally). This is, by the prime number theorem, equivalent to the statement that $$\lim_{n\to\infty}\prod_{i=1}^{n}\left(\frac{p_i}{p_i-1}\right)/\log n\approx e$$. Or, taking the logarithm, $$\lim_{n\to\infty}\left[\sum_{i=1}^{n}\log\left(\frac{p_i}{p_i-1}\right)-\log\log n\right]\approx 1$$ Furthermore, by a relation involving the Euler-Mascheroni constant, this implies $$\lim_{n\to\infty}\sum_{n<p\leq p_n}\log\left(\frac{p}{p-1}\right)\approx 1-\gamma$$ My question is whether or not anyone knows how to prove any of these statements, either with equality (perhaps computation is leading me astray) or with a different value as the limit.","['riemann-zeta', 'number-theory', 'totient-function', 'euler-product', 'analytic-number-theory']"
928946,Prove that the the variance estimator $\widehat{\sigma}^2=MSE/(n-2)$ is biased is the simple linear regression model,"This is in scope of the simple linear model. Im trying to prove that $\mathbb{E}\left(\widehat{\sigma}^2\right) = \sigma^2$ for $$\widehat{\sigma}^2 = \frac{1}{n-2}\sum^n_{i=1} \left(y_i-\widehat{y}_i\right)^2$$ where $$Y_i\sim N(\beta_0+\beta_1x_i,\sigma^2)$$ and $\widehat{y_i},i=1,2,3,...,n$ are pedricted values and $y_1,y_2,...,y_n$ is a sample from $Y_i$","['statistics', 'regression', 'regression-analysis', 'statistical-inference']"
928948,Equality of ideals and their vareties.,"Let $I_1 $,$I_2 $ $\in \mathbb{C}[x_1,x_2,...,x_n] $ be two polynomial ideals. If their affine varieties, $\mathbb{V}(I_1)=\mathbb{V}(I_2)$ are equal then is $I_1=I_2$ always?","['ideals', 'algebraic-geometry']"
928957,How many automorphisms does $S_3\times S_3$ have?,"I've shown that $|\text{Aut}(S_3\times S_3)|\ge 72$, how can I show that $|\text{Aut}(S_3\times S_3)|\le 72$ ?","['permutations', 'group-theory', 'abstract-algebra']"
928968,Summation of series $\sum_{k=0}^\infty 2^k/\binom{2k+1}{k}$,"How to find the sum of this series? 
$$\sum_{k=0}^{\infty}\cfrac{{2}^{k}}{\binom{2k+1}{k}}$$ It seems very easy. But I still can not work it out, can anyone help?","['summation', 'sequences-and-series', 'combinations']"
928969,determine distribution by finding the moment generating function,"Mathematical Statistics and Data Analysis, Rice, Chapter 4, Problem 92 $\theta$ is Gamma($\lambda,\alpha$) distributed, $X|\theta$ follows a Poisson($\theta$) distribution. Wanted: the unconditional distribution of $\alpha + X$. Attempt:
$M_{\alpha+X}(t) = e^{\alpha t}E(E(e^{tX}|\theta)) = e^{\alpha t}E(M_{X|\theta}(t)) = e^{\alpha t}E(e^{\theta(e^t-1)}) = e^{\alpha t}M_{\theta}(e^t-1) = \left(\frac{\lambda e^t}{(\lambda-e^t+1)}\right)^\alpha$ Can someone help me along? How to identify to which distribution the mgf belongs?","['probability-theory', 'moment-generating-functions']"
929016,Möbius band parameterizaton: Showing injective,"So, I'm trying to show that the parameteization function from $\mathbb R^2$ to $\mathbb R^3$ given in the wikipedia page http://en.wikipedia.org/wiki/Mobius_band#Geometry_and_topology is injective on the interior of the domain.   (this is part of a larger exercise I'm doing in a general topology class showing it is homeomorphic to an identification space of the unit square).  Trying to do it by brute force gets me 3 equations with 4 unknowns.  Is there a multivariable analysis way to do this?  I know the implicit function theorem/inverse function theorem can give locally 1-1,  but I need 1-1 on the entire open unit square.","['general-topology', 'multivariable-calculus']"
929023,$1^2+2^2+\cdots+24^2=70^2$ and squarily squaring the torus,"The unique nontrivial solution to $1^2+2^2+\cdots+n^2=m^2$ is $(n,m)=(24,70)$. (This fact has connections to modular forms, special functions, lattices and string theory.) Martin Gardner, in the September 1966 issue of Scientific American, attributed the following question to someone named Richard Britton: can we tile a $70\times70$ square with $1\times1$, $2\times2$, $\cdots$, $24\times24$ squares? The answer, after some computer analysis, has turned out to be negative. (If I understand correctly it wasn't quite brute force but it was something of an exhaustive search. I am also curious about the potential for a paper-and-pen combinatorial disproof.) So I will relax the question a bit: is it possible to tile the $70\times70\,$ torus with these squares? Equivalently, can we tile the $70\times70$ square with them if we allow wrapping across both pairs of opposite sides?","['discrete-mathematics', 'combinatorics']"
929030,Integral with rational functions of powers and exponentials,"Any ideas how to solve: 
\begin{equation}
\int_0^\infty x^{n+\frac{1}{2}} (e^{a x }-1)^{-\frac{1}{2}} e^{i x t} dx
\end{equation}
where $a$ and $t$ are real, positive constants; $n$ is a positive integer. I think the problem comes from having rational functions in both powers and exponential functions. I tried to get ride of the rational power, but it didn't really help
\begin{equation}
\frac{\partial}{\partial q } \int_0^\infty x^{n} (e^{a x }-1)^{-\frac{1}{2}} e^{i x t+ q x^{1/2}} dx
\end{equation} Having an hint how to solve this for $t=0$ would already be useful. Thanks!","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'complex-integration']"
929032,$\nabla \cdot f + w \cdot f = 0$,"Let $w(x,y,z)$ be a fixed vector field on $\mathbb{R}^3$. What are the solutions of the equation
$$
\nabla \cdot f + w \cdot f = 0 \, ?
$$
Note that if  $w = \nabla \phi $, then the above equation is equivalent to
$$
\nabla \cdot (e^\phi f) = 0,
$$
for which the solutions are of the form $f = e^{-\phi} \nabla \times g$ for some arbitrary $g$.","['ordinary-differential-equations', 'partial-differential-equations']"
929038,Operator norm and Hilbert Schmidt norm,"I'm looking for a proof of \begin{equation}
||T||\leq ||T||_{HS},
\end{equation}
for which it is sufficient to show
\begin{equation}
||Tx|| \leq ||x|| \cdot ||T||_{HS} \forall x\in H, x\not=0
\end{equation}
can someone help?","['operator-theory', 'normed-spaces', 'hilbert-spaces', 'functional-analysis']"
929053,Solving an equation over the reals: $ x^3 + 1 = 2\sqrt[3]{{2x - 1}}$,"Solve the following equation over the reals:$$
x^3  + 1 = 2\sqrt[3]{{2x - 1}}
$$
I noticed that 1 is a trivial solution, then I tried raising the equation to the 3rd, then dividing the polynomial by $(x-1)$.. But I can't see the solution, how do I go from here?",['algebra-precalculus']
929057,Find the median of a function of a normal random variable.,"If $X\sim N(\mu,\sigma^2)$ and $Y=e^X$, then what is the median of $Y$? I am pretty sure that $Y$ is also distributed normal.  To try to prove it, I attempted both the method of moment generating functions and the method of cdfs.  I just can't get it.  Thanks for your help.   Once I show that, getting the median is the same as getting the mean.","['statistics', 'moment-generating-functions', 'probability']"
929081,Prove that the vector sum of the vertices of an n-sided regular polytope whose center is at the orgin is zero,"I need to prove this (assuming it's true): The vector sum of the vectors pointing to the vertices of an n-sided regular polytope whose center is at the origin of a Euclidean space is zero. If it has an even number of vertices, it's clearly zero by symmetry (at least where my imagination works).  I can't think of a way to prove this in the general case, though.","['geometry', 'vectors', 'euclidean-geometry']"
929100,Why is differential geometry called differential geometry?,Why is differential geometry called differential geometry? Why it is not called differential and integral geometry? Isn't integration and finding areas as important as differentiation? Is it the case that  differential equations are more common and natural in mechanics than integral equations so as a result differential geometry as the language of mechanics is more concerned with differentiation?,"['soft-question', 'big-picture', 'differential-geometry']"
929113,When is there a vector $D$ with positive coordinates such that $e^{Ct}D$ has a negative coordinate?,"Let $C$ be a $2 \times 2$ asymmetric matrix with real entries. Assume that $C$ has strictly negative, real eigenvalues. Fix $D\in\mathbb{R}^2$, where $D > 0$ (i.e., both coordinates are strictly positive). Let $t \geq 0$ be a scalar and define the vector valued function using the matrix exponential,
$$
H(t) = e^{C t} D\in\mathbb{R}^2
$$
Denote $\min(H(t))<0$ if at least one of the elements is less than $0$. Fixing $D > 0$, under what conditions on $C$ and $D$ does a $t^{*}> 0$ exist such that $\min(H(t^*)) < 0$?  Or conversely, given a numerical $C$ and $D$, how can I test whether the $H(t) > 0$ for all $t$? Ideal conditions are checking signs of eigenvectors or diagonal elements of $C$, etc.  If they can be done without a particular $D$ matrix, so much the better. A few notes: If possible, you can use the assumption that $-C^{-1} D \cdot \begin{bmatrix} 1 &1\end{bmatrix} = 1$.  i.e. the sum of $-C^{-1}D = 1$  This comes out of necessary equilibrium condition to ensure that $H(t)$ is a valid PDF, and may pin down requirements to make the answer only requirements on $C$. $C$ negative definite should be enough to ensure that $\lim\limits_{t\to\infty}H(t) = 0$ If you wish, assume that C is diagonalizable and denote $C \equiv Q S Q^{-1}$, where $S$ the matrix of eigenvalues (both $< 0$).  In that case, 
$$
H(t)= Q e^{S t} Q^{-1} D
$$ Solution Approach?: Clearly, having negative eigenvalues of $C$ ensures convergence of $H(t) \to 0$, but what do the eigenvectors of $C$ tell us? Can they tell us from which direction it approaches $0$ (given the sign of $D$)? I notice that in examples which break, one of the eigenvectors has the same signs for both coordinates, while the other has different signs?  Could $Q \leq 0$ be the answer? Example where it goes below 0 with negative definite C: See the following matlab code: C = [- 2.2959 -1.5; -.1 -1.6918];
min(eig(-C)) %Can check the eigenvalues to ensure negative definite
D = [2.0; 0.6918];
F_p = @(z) expm(C * z) * D;
%Evaluate at a few z's
F_p(1) %Both > 0
F_p(3) %One of them < 0!!!
F_p(100) %They both converge to 0
%Could diagonalize C
[Q,B] = eig(C)
% Then define F''(z)
F_pp = @(z) Q * diag(exp(diag(B) * z))* inv(Q) * C * D Added from Idea Given in Solution: The following may be a sketch of a proof that $D$ as the eigenvector of $C$ fulfills the requirement, Preliminaries: $A$ and $A^{n}$ have the same eigenvectors and if $\lambda $ is a root
of $A,\ \lambda ^{n\text{ }}\ $is a root of $A^{n}.\ $And $-A$ has roots $
-\lambda $ $If$ $A$ is non-negative (with some positive elements) it has a
non-negative eigenvector $v\geq 0$ associated to a dominant root $\hat{
\lambda}>0,$  which is real, simple and larger in modulus than its other
roots. $A$ and $-A\ $\ have the same eigenvectors. Now consider $e^{C t}D=\left[ I+C t+\frac{1}{2!}\left( C t\right) ^{2}+\frac{1}{
3!}\left( C t\right) ^{3}+\frac{1}{4!}\left( C t\right) ^{4}+\frac{1}{5!}
\left( C t\right) ^{5}+\frac{1}{6!}\left( C t\right) ^{6}+..\right] D$ where $
C\leq 0.$ Take $v$ to be the dominant eigenvector of $-C.$ So if $\lambda $
is the dominant root of $-C,$ then the minimum eigenvalue of $-C$ is $
-\lambda .$ Take $D=v.$ Then
\begin{eqnarray*}
C t v &=&\left( -\lambda t\right) v \\
\left( C t\right) ^{2}v &=&\left( -\lambda t\right) ^{2}v \\
\left( C t\right) ^{3}v &=&\left( -\lambda t\right) ^{3}v
\end{eqnarray*}
\begin{eqnarray*}
e^{C t}v &=&\left[ I+C t+\frac{1}{2!}\left( C t\right) ^{2}+\frac{1}{3!}\left(
C t\right) ^{3}+\frac{1}{4!}\left( C t\right) ^{4}+\frac{1}{5!}\left(
C t\right) ^{5}+\frac{1}{6!}\left( C t\right) ^{6}+..\right] v \\
&=&\left[ 1+\left( -\lambda t\right) +\frac{1}{2!}\left( -\lambda t\right)
^{2}+\frac{1}{3!}\left( -\lambda t\right) ^{3}+\frac{1}{4!}\left( -\lambda
t\right) ^{4}+\frac{1}{5!}\left( -\lambda t\right) ^{5}+\frac{1}{6!}\left(
-\lambda t\right) ^{6}+..\right] v
\end{eqnarray*}
But by definition $$
e^{-\lambda t}=\left[ 1+\left( -\lambda t\right) +\frac{1}{2!}\left(
-\lambda t\right) ^{2}+\frac{1}{3!}\left( -\lambda t\right) ^{3}+\frac{1}{4!}
\left( -\lambda t\right) ^{4}+\frac{1}{5!}\left( -\lambda t\right) ^{5}+
\frac{1}{6!}\left( -\lambda t\right) ^{6}+..\right] 
$$
So
$$
e^{C t}v=\left[ I+C t+\frac{1}{2!}\left( C t\right) ^{2}+\frac{1}{3!}\left(
C t\right) ^{3}+\frac{1}{4!}\left( C t\right) ^{4}+\frac{1}{5!}\left(
C t\right) ^{5}+\frac{1}{6!}\left( C t\right) ^{6}+..\right] v=e^{-\lambda
t}v\geq 0
$$
since $v$ is the non-negative eigenvector. Choose $D=H\left(
0\right) =v$ and $H\left( t\right) =e^{Ct}D\geq 0.$","['matrices', 'linear-algebra', 'exponential-function']"
929149,"Intuitively, how do you explain the concept of Flux?","Lately in my physics and mathematics classes, I've come across the concept of Flux . And although I've been able to define them mathematically and figure out how to use them. I'm still not entirely sure what flux is. My question is: So is there any intuitive way I can understand the concept of flux?","['calculus', 'intuition', 'physics']"
929208,Square integrable stochastic process,"Suppose that for a stochastic process we have \begin{align}
\mathbb{E}\left[\int_{0}^{T}X^{2}(t)dt \right]<\infty
\end{align} where $T<\infty$. Does it  holds that $|X(t)|<M$, where $M$ constant? I am a little confused.","['stochastic-processes', 'probability']"
929243,Need help with $(¬p \vee ¬(p\wedge¬q)) \wedge ¬(p \wedge q) ≡¬p$,"Hey guys I just need help solving this solution here. Sorry if I didn't type the symbols correctly. My solution so far:
$$
(¬p \vee ¬(p\wedge¬q)) \wedge (¬p \vee ¬q)≡
(¬p \vee (¬p \vee q)) \wedge (¬p \vee ¬q)≡
$$
at this point I'm stuck. Is there any way I can take care of the not-$p$ $\vee$ not-$p$? Thanks","['logic', 'discrete-mathematics']"
929249,How to show this integral equals $\pi^2$?,"I was trying to evaluate an integral related to the product of two cauchy distributions and in one of the steps got stuck in the integral $$\int_0^{\infty} \frac{\ln(x)}{\sqrt{x}(x-1)} dx. $$ I tried to evaluate the integral using Mathematica, and it seems that the answer is $\pi^2$. Furthermore, if I restrict the integral to $(0,1)$, the answer is just $\pi^2/2$, i.e. the integral over $(0,1)$ and the integral over $(1,\infty)$ are equal. 
I was wondering if anyone could help me verify/disprove this identity? I apologize in advance if this seems an ill-posed question.","['definite-integrals', 'probability-distributions', 'integration']"
929255,Quibble with Dawkins's reasoning on the watch-stopping probability on a psychic audience,"In Unweaving the Rainbow (page 150) Richard Dawkins mentions the following (famous) reasoning on why it's almost certain that a psychic with a big audience will accurately predict/command rare events like watch-stopping: We can do a similar calculation for the television guru whose psychic miasma seemed to stop people's watches, but we'll have to use estimates rather than exact figures. Any given watch has a certain low probability of stopping at any moment. I don't know what this probability is, but here's the kind of way in which we could come to an estimate. If we take just digital watches, their battery typically runs out within a year. Approximately, then, a digital watch stops once per year. Presumably clockwork watches stop more often because people forget to wind them and presumably digital watches stop less often because people sometimes remember to renew the battery ahead of time. But both kinds of watches probably stop as often again because they develop faults of one kind or another. So, let our estimate be that any given watch is likely to stop about once a year. It doesn't matter too much how accurate our estimate is. The principle will remain. If somebody's watch stopped three weeks after the spell was cast, even the most credulous would prefer to put it down to chance. We need to decide how large a delay would have been judged by the audience as sufficiently simultaneous with the psychic's announcement to impress. About five minutes is certainly safe, especially since he can keep talking to each caller for a few minutes before the next call ceases to seem roughly simultaneous. There are about 100,000 five-minute periods in a year. The probability that any given watch, say mine, will stop in a designated five-minute period is about 1 in 100,000. Low odds, but there are 10 million people watching the show. If only half of them are wearing watches, we could expect about 25 of those watches to stop in any given minute. If only a quarter of these ring in to the studio, that is 6 calls, more than enough to dumbfound a naive audience. Especially when you add in the calls from people whose watches stopped the day before, people whose watches didn't stop but whose grandfather clocks did, people who died of heart attacks and their bereaved relatives phoned in to say that their ‘ticker’ gave out, and so on. I agree with the general reasoning but I'm confused as to how he gets to 25 there in the middle, I think it should be 50. This would NOT change at all the general point he's making but it seems big enough to point out. Can someone please help me see how he got to 25? Is it just a simple mistake on his part or mine? Here's my reasoning: The minutes in a year are 365 days * 24 hours * 60 min = 525,600 minutes. And that divided by 5, gives 105,120 five-minute periods in a year. So far, consistent with Dawkins account. He then asks us to consider a 10,000,000 audience, only half of whom are wearing watches, so 5,000,000 watch-wearing viewers. If we now multiply these by the probability of stopping in a five-minute period we get, 5,000,000 * (1/104,120) = 47.56. So, in a 5,000,000 watch-wearing audience ABOUT 50 watches are expected to stop in a 5-minute-period, not 25 as he claims. (Note that his statement is rather ambiguous, if we interpret ""in any given minute"" as being literally how many watches we expect to stop in ONE minute then the answer is 9.5, so about 10... still not 25.) Thanks.","['statistics', 'probability']"
929262,The projection of a vector value function onto the xz-plane.,"Okay, so I missed CalcIII today and I'm struggling a bit here. $r(t) = (\sin t,\cos t,7\sin t + 4\cos 2t)$ Find the projection of $r(t)$ onto the xz-plane for $−1 \leq x \leq 1$ Answer as an equation using the variables $x$, $y$, and $z$. P.S. I clepped CalcI and II.... in 2010. Haven't done much since then so I'm just a little out of practice, need to kick my brain back into gear.",['multivariable-calculus']
929295,"Is $d(x,y) = (x-y)^2$ a metric on $\Bbb R$?","For $x,y,z \in \Bbb R$, define $d(x,y):= (x-y)^2$ Is this a metric on $\Bbb R$? It's clear that $d(x,x)=0$ and $d(x,y)=d(y,x)$ for all $x,y \in \Bbb R$. The triangle inequality seems to have a contradiction [$d(x,z) \leq d(x,y) +d(y,z)$]
If I let $x=1$, $y=0$ and $z=-1$, then I will have $(1+1)^2 = 4 > (1-0)^2 + (0+1)^2 = 2$. So is this $d$ a metric? If it's, how can I prove it?","['general-topology', 'real-analysis', 'analysis']"
929299,How to find the equation of the graph reflected about a line?,"Consider the graph of $y = e^x$ (a) Find the equation of the graph that results from reflecting about the line $y = 4$ . (b) Find the equation of the graph that results from reflecting about the line $x = 5$ . I get that in order for the equation to reflect about the $y$ -axis, the function would have to be $y= - e^x$ , and also for it to reflect about the $x$ -axis the function should be something like $y= e^{-x}$ . But what to do when a line is not one of the coordinate axes?","['transformation', 'graphing-functions', 'algebra-precalculus', 'functions']"
929312,System of Equations and Pumpkins? I Think Not.,"Here is a challenge problem my math teacher gave to his pre-calculus class. I saw it. I attempted it. And I failed. It's sort of bothering me because my teacher said, ""It's simpler than you're making it out to be."" That sort of bothered me even though I know he's right. Anyways, time for the problem. It is as follows: ""A pumpkin growing contest occurs every year in Half Moon Bay. The pumpkins are weighed to see who grew the heaviest one. One individual decided to weigh his 5 pumpkins two at a time. He recorded the following waits: 110, 112, 113, 114, 115, 116, 117, 118, 120, and 121. How much did each pumpkin weigh?"" This is my attempt. Let $a_1, a_2, a_3, a_4, a_5$ be the weights of the pumpkins in increasing order, i.e. such that $a_1 \le a_2 \le a_3 \le a_4 \le a_5.$ If we take the sum of the 10 distinct weighings  then we will have four times the sum of the weights of the pumpkins. In other words, $$110 + 112 + 113 + 114 + 115 + 116 + 117 + 118 + 120 + 121 = 1156$$ which is equivalent to, $$(a_1+a_2)+(a_1+a_3)+(a_1+a_4)+(a_1+a_5)+(a_2+a_3)+(a_2+a_4)+(a_2+a_5)+(a_3+a_4)+(a_3+a_5)+(a_4+a_5).$$ So we have $$ 4(a_1+a_2+a_3+a_4+a_5) = 1156$$ $$a_1+a_2+a_3+a_4+a_5 = 289.$$ Since $a_1, a_2$ weigh the least their sum must weigh the least, so $a_1+a_2 = 110.$ By similar reasoning we can see that $a_4+a_5 =121.$ Now we can see that $a_3=58.$ This ends my attempt. I tried to go further but I couldn't. One person told me that it could be solved by system of equations but I thought that systems of equations might be troublesome because the problem does not specify which pairs of pumpkins correspond to which weights. But I don't doubt that it can be solved with systems of equations. Any solutions would be much appreciated! Many thanks to all!","['algebra-precalculus', 'systems-of-equations']"
929319,Does bounded in probability imply convergence in probability?,"A random variable, $X_n$, is defined to be bounded in probability if there exists an $M$ and $N$ for which
\begin{align*}
\mathbb{P}\big(|X_n| < M\big) > 1 - \epsilon,\ \forall n > N,\ \forall \epsilon > 0,
\end{align*}
and it is defined to converge in probability to another random variable $X$ if
\begin{align*}
\mathbb{P}\big(|X_n - X| < \epsilon\big) \to 1, \text{ as } n \to \infty,\ \forall \epsilon > 0.
\end{align*} My question is as follows:
Is saying that ""$X_n$ is bounded in probability"" equivalent to saying that ""$X_n$ converges in probability to 0""? Choose an $N$ such that $M = \epsilon$. $X_n$ can be then re-expressed as
\begin{align*}
\mathbb{P}\big(|X_n| < \epsilon\big) > 1 - \epsilon,\ \forall n > N_{\epsilon},\ \forall \epsilon > 0.
\end{align*}
This leads to
\begin{align*}
1 - \epsilon < \mathbb{P}\big(|X_n| < \epsilon\big) \leq 1
\end{align*}
for all $\epsilon > 0$. Since the set $\{|X_n| < \epsilon_1\} \subset \{|X_n| < \epsilon_2\}$ for all $\epsilon_1 < \epsilon_2$, by continuity of probability,
\begin{align*}
\lim_{\epsilon \to 0} \mathbb{P}\big(|X_n| < \epsilon\big) = \mathbb{P}\!\left(\lim_{\epsilon \to 0} |X_n| < \epsilon\right) = \mathbb{P}\big(|X_n| \leq 0\big),
\end{align*}
so
\begin{align*}
\lim_{\epsilon \to 0} 1 - \epsilon \leq \lim_{\epsilon \to 0} \mathbb{P}\big(|X_n| < \epsilon\big) \leq 1, \text{ or }\ \ 1 \leq \mathbb{P}\big(|X_n| \leq 0\big) \leq 1,
\end{align*}
which, by the Sandwich Theorem, gives $\mathbb{P}\big(|X_n| \leq 0\big) = 1$ for all $n \geq N_{\epsilon}$. Then $\mathbb{P}\big(|X_n| < 0\big) \to 1$ as $n \to \infty$, since $N_{\epsilon} < \infty$. Since for all $\epsilon > 0$,
\begin{align*}
\mathbb{P}\big(|X_n| < \epsilon\big) \geq \mathbb{P}\big(|X_n| \leq 0\big) = 1,
\end{align*}
$\mathbb{P}\big(|X_n| < \epsilon\big) \to 1$ and $X_n$ converges to 0 in probability. Remark: The ""$<$"" inequalities are converted into ""$\leq$"" as the limit $\epsilon \to 0$ is approached from the right. As I am new to the topic, can I check with the seasoned professionals here on whether the above argument is flawed? Thanks in advance.",['probability-theory']
929336,show a cartesian product in function is injective or surjective?,"I had previously figured out injectivity/surjectivity on basic functions but I am stumpted when it comes to showing functions which are cartesian products are injective/surjective. The first one:
$$f: \Bbb{Z} \to \Bbb{Z}\times\Bbb{Z},$$ where $\Bbb{Z}$ is integers set. $$f(n) = (2n, n+3)$$ I had shown that f was injective by contrapositive: suppose $f(x) = f(y)$ then $(2x, x+3) = (2y, y+3)$ but I am unsure if this proof is complete.. When showing onto, I could not think of any counter examples. When dealing with basic functions I would just show that $f(x) = y$ but I am unsure how to show that with cartesian products.",['functions']
929344,How to solve $-20=15 \sin \theta- 30.98 \cos \theta$?,"How can I solve the following equation? $$-20=15 \sin \theta- 30.98 \cos \theta$$ I can't think of any way to solve it.  You can't factor out cosine because of the annoying little negative twenty, and if you divide by cosine you also get nowhere.",['algebra-precalculus']
929354,Can anybody help me solve this combinatorial identity?,"While trying to derive some physical equation, I noticed that the following identity was needed: $\sum^{4a \leq 2k}_{a=0}{2k \choose 4a} + \sum^{4a+1 \leq 2k}_{a=0} {2k \choose 4a+1} = \left\{ \begin{array}{ll} \frac{2^k(2^k +1)}{2} & (k=4l+1, 4l+4)\\
                          \frac{2^k(2^k -1)}{2} & (k=4l+2, 4l+3) \end{array} \right.$ (where $l,a$ are positive integers) My strategy was to change  the $2^k$'s of RHS into $\sum_{a=0}^{a=k}{k \choose a}$ and use ${n \choose k}={n-1 \choose k} +{n-1 \choose k-1}$, but obtained only incomplete and partial relations. Can anybody solve this identity explicitly, or at least suggest another strategy that might work better?",['combinatorics']
929373,"How many integers in the range [1,999] are divisible by exactly 1 of 7 and 11?","This is a question in Kenneth Rosen's Discrete Mathematics textbook 6th edition.  I haven't had trouble with any other counting problems regarding ""how many numbers in range [x,y] have divisibility property Z?""  My issue is I have no idea what Rosen is asking for, i.e. I don't understand the question because I don't know what he wants me to compute. Therefore this is not a duplicate of this question (1) https://math.stackexchange.com/questions/588160/how-many-positive-integers-less-than-1000-are-divisible , since while the answer is given, it doesn't explain the language of the question and what is being computed.  I have no idea why the number of integers divisible by 7 or 11 minus the number of integer divisible by 77 (11 and 7) is the answer to this question.  Both of these values I've already computed correctly (in separate questions). In context:
20.  How many positive integers less than 1000
e) are divisible by exactly one of 7 and 11? Thus my question is: what/which numbers am I supposed to count/compute?","['inclusion-exclusion', 'discrete-mathematics', 'divisibility']"
929378,Left ideals of $M_n(K)$ [duplicate],"This question already has answers here : What are the left and right ideals of matrix ring? How about the two sided ideals? (2 answers) Closed 9 years ago . Let $K$ be a field and $n \in \mathbb N$ . Show the following: (i) Let $V \subset K^n$ be a subspace and $I_V$ the subset of $M_n(K)$ consisting of all the matrices whose rows belong to $V$ . Prove that $I_V$ is a left ideal of $M_n(K)$ . (ii) Show that every left ideal of $M_n(K)$ is of the form defined in (i). I think I could show (i). I am having problems with (ii) For (i), take $M \in M_n(K)$ and $N \in I_V$ . Let $P=MN$ , I want to show that $P \in I_V$ .
Let $P_i=(P_{i1} ... P_{in})$ be the i-th row of $P$ . Then, by definition of matrix multiplication, $$P_i=(\sum_{k=1}^n M_{ik}N_{k1} ... \sum_{k=1}^n M_{ik}N_{kn})$$ $$=\sum_{k=1}^n M_{ik} (N_{k1} ... N_{kn})$$ $$=M_{i1}(N_{11} ... N_{1n})+...+M_{in}(N_{n1} ... N_{nn})$$ This means that the $i-th$ row  of $P$ is a linear combination of the rows of $N$ . From here it follows $P=MN \in I_V$ . This proves $I_V$ is a left ideal of $M_n(K)$ . I don't know how to show (ii), I would appreciate some help with that part.","['ring-theory', 'ideals', 'abstract-algebra']"
929380,What is wrong with the following u-substitution?,"We will calculate $\displaystyle\int^{2 \pi}_0 x \, dx$.  Let $u=\sin (x)$, and observe that $\sin(2 \pi)=0$ and $\sin(0)=0$.  We also have that $\frac{du}{dx}=\cos(x)=\sqrt{1-u^2}$. Hence,
$$
\int^{2 \pi}_0 x \, dx=\int^0_0 \frac{\sin^{-1}(u)}{\sqrt{1-u^2}} \, du = 0.
$$
This is very obviously wrong, but I am not sure how to explain the error formally. Edit: Thanks for the responses and in particular the link below to the related problem!  The error is indeed caused by the substitution $x=\sin^{-1}(u)$.  The integration is performed over $[0,2 \pi]$ which is outside the range of the $\sin^{-1}$ function. Remark The error is slightly better disguised when calculating $\displaystyle\int^1_{-1}\frac{2x}{1+x^2} \, dx.$ Let $u(x)=1+x^2$, and observe that $u(1)=u(-1)=2$.  Then since $dx=\frac{1}{2x} du$, we have that
$$
\int^1_{-1} \frac{2x}{1+x^2} \, dx =  \int^2_2 \frac{1}{u} \, du=0.
$$
This time, no trigonometric substitution is used, but it is still an incorrect proof for the same reason as above.  A correct proof can be obtained by using the fact that $x \mapsto \displaystyle\frac{2x}{1+x^2}$ is odd. This example is more disturbing because the procedures above are entirely intuitive and yield the correct result. It seems to me that students when taught integration by substitution of definite integrals should also be taught that great care be exercised in checking the range of integration, particularly when the (apparent) substituting function is not invertible in that range.","['calculus', 'integration', 'analysis']"
