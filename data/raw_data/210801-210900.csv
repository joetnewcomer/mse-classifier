question_id,title,body,tags
4238520,Real part of Riemann Zeta function inequality,"In the book ‘Riemann’s Zeta Function’ by H.M Edwards, the following is a line in a proof (within section 6.7) that I can’t follow. The variable $T$ is just a positive real number. $$|\Re [\zeta(2+iT)]|\geq 1 - 2^{-2}-3^{-2}-4^{-2}-… = 1 - (\zeta(2)-1)$$ Where does this result come from?","['complex-analysis', 'riemann-zeta', 'zeta-functions']"
4238526,"What's wrong with the naive ""take successive smallest"" procedure in proving well-ordered subsets of $\mathbb R$ are countable?","For context, I have no set theory background and my understanding of sets is naive. I had a discussion with a friend that I thought for any well-ordered subset of the reals, I could simply take the least element, second least, etc. to show it is countable. It is the same procedure described in Is a well-ordered subset of $(\mathbb{R},<)$ countable? . However he told me I had to make use of ordinals (which I don't know about) to index into the set. Is there an intuitive (or at least relatively elementary) reason why I can't count up using my naive procedure to conclude the subset is countable? The main concern I see is about if I ever ""finish counting"" which I don't know how to reason about and seems subtle.","['elementary-set-theory', 'real-numbers', 'well-orders']"
4238554,Conjugate in Symmetry Group,"I have found the following question in one of my old assignments. I think it is wrong! Question. Let $\psi = (i_1 i_2 \dots i_k)$ a $k$ -cycle in $S_n$ .Prove that: $$|N_{S_n}(\langle \psi \rangle):C_{S_n}(\psi)|=\varphi(n)$$ My problem is here! Shouldn't it be $\varphi(k)$ instead of $\varphi(n)$ ? My attempt: If $\beta \in N_{S_n}(\langle \psi \rangle)$ this means that: $$\beta \psi {\beta}^{-1} = {\psi}^m \;\text{and}\; (m,k)=1$$ Am I wrong here? So know we can count the number of $N_{S_n}(\langle \psi \rangle)$ . $$\beta \psi {\beta}^{-1}=(\beta(i_1) \beta(i_2) \dots \beta(i_k))=\psi^m$$ This means that with knowing only $\beta(i_1)=i_t$ , then we have the value of $\beta(i)$ for all $i$ . Thus, we can have only $k.(n-k)!$ elements that $\beta \psi {\beta}^{-1}=\psi^m$ . We use the fact that the $\psi^m$ are $k-$ cycles with different arrangement of $i_1, \dots, i_k$ .
As a result: $$|N_{S_n}(\langle \psi \rangle)|=\varphi(k).k.(n-k)!$$ We can conclude similarly as above that: $$|C_{S_n}( \psi )|=k.(n-k)!$$ Am I missing something? or is there a misspelling in the question?","['symmetric-groups', 'group-theory', 'abstract-algebra', 'solution-verification']"
4238559,Why is $\Re \zeta$ non-zero on the line $\Re(s)=\frac32$,"I am trying to understand why $\Re \zeta (s)$ is non-zero on the line $\Re (s)=\frac32$ . This in stated without explanation in section 6.6 of the book ‘Riemann’s Zeta Function’ by H.M. Edwards, and it is a key part in Backlund’s proof for the evaluation of $N(T)$ (number of complex zeta roots below $t=T$ ). Using the zeta formula, I have deduced for $s=3/2 +iT$ , we have $$ \Re \zeta (s)= \sum_{n=1}^{\infty} \frac{\cos(T \log n)}{n^{3/2}}.$$ How can one show this summation must be non-zero?","['complex-analysis', 'convergence-divergence', 'riemann-zeta', 'sequences-and-series']"
4239747,USAMO 1973 (Simultaneous Equations),"Determine all the roots, real or complex, of the system of simultaneous equations (USAMO 1973/4) $$x+y+z=3$$ $$x^2+y^2+z^2=3$$ $$x^3+y^3+z^3=3$$ Multiply equation I by 2 and subtract it from Equation II: $$x^2-2x+y^2-2y+z^2-2z=-3$$ Complete the square for all three variables: $$(x-1)^2+(y-1)^2+(z-1)^2=0$$ Since the RHS is zero, and the LHS has only perfect squares, by the trivial inequality, we must have: $$(x-1)^2=0\Rightarrow x=1$$ $$(y-1)^2\Rightarrow y=1$$ $$(z-1)^2=0\Rightarrow z=1$$ Hence, the only solution for Equations I and II is $$x=y=z=1$$ This satisfies Equation III as well. And hence, this is also the only solution to the overall system of equations. 1.
Would this be enough to get full marks?
Anything missing, or needed to be added? 2.
The complex roots is neither needed nor used anywhere. This was just used to (artificially?)  increase the ""complexity"" of the problem. Is this correct.","['contest-math', 'algebra-precalculus', 'systems-of-equations', 'complex-numbers']"
4239763,Factorial-like product where the factors are offset,"Does this ""factorial-like"" product have a name? $ (1 + t) \cdot (2 + t) \cdot (3 + t) \cdot \ldots \cdot (n + t) $ where $n \in \mathbb{N}$ and $0 < t < 1$ ? So it's like a factorial in the sense that the factors differ by 1, but the factors are integers offset by a fixed real number $t$ . And is there a known way to numerically approximate the logarithm of such a product for large $n$ where an iterative approach would be too slow? (just like the logarithm of the Gamma function can be approximated well)","['factorial', 'approximation', 'gamma-function', 'sequences-and-series', 'numerical-methods']"
4239776,what situation is right,"I have two categories of people, the reliable and the liars.The reliable telling always the truth,the liars always telling lies. One visitor meets both of them: A declares: ""I and B are the same."" B declares : ""From us no one is reliable."" What situation is true? a)both are liars
b) the A is liar and the B reliable
c)both reliable
d)A is reliable and B is liar I beleive is the b) A is liar and the B reliable
Am I right?","['logic', 'discrete-mathematics']"
4239814,"Are two events independent, if occurrence of one event alters possible outcomes of the other's, but still maintains the same probability?","Let's assume a group of $80$ friends where $40$ of them plays baseball, $20$ of them plays football and $10$ of them plays both the game. Without any further information, if a random person is chosen, the probability of him playing football is $20/80 = 1/4$ Now let's say, we introduce one more information that the chosen person plays baseball. Now the sample space is halved (currently having only $40$ people) but so is the event space (currently $10$ ). So probability stays the same ( $1/4$ ) This example was shown to me by one of my friends and he claimed, here One person playing baseball and One person playing football is independent of each other. Because the occurrence of one event is not changing other's probability. But I thought, if one event reduces other's possible outcomes (Here $10$ friends leaves the equation when I apply condition), how can they be considered independent. If these events are indeed independent, the same example with different numbers, would surely change the probability. Will the same example then be considered having dependent events? The Wikipedia article on Conditional Probability says, If P(A|B) = P(A), then events A and B are said to be independent: in
such a case, knowledge about either event does not alter the
likelihood of each other Then should I always calculate the answer of any probability question to determine what formula to use? Then how will I get to the answer in the first place? Edit Fine tuned terminologies to match with what I wanted to say","['conditional-probability', 'probability']"
4239865,Exchanging the order of integration in improper double integrals,"My question arise from Improper Riemann Integrals by Ioannis M. Roussos Why the improper double integral is absolutely convergent,then we can exchange order of integration in improper Riemann sense? I really don't understand that it said $\textbf{Condition II}\ \Longleftrightarrow \textbf{Condition III} \Longleftrightarrow \textbf{Condition IV}$ and each one of them can ensure the equalities $$ \iint_{\mathbf{R}^2} f(x,y) \, \mathrm{d}x \, \mathrm{d}y
= \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty f(x,y) \, \mathrm{d}x \right] \, \mathrm{d}y
= \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty f(x,y) \, \mathrm{d}y \right] \, \mathrm{d}x $$ hold. This has been bothering me for a long time！Any help you can provide would be greatly appreciated! I got a counterexample function $f(x,y)$ as following which is discontinuous on $[0,1]\times[0,1].$ $f(x,y)$ is defined on $\left [0,1  \right ] \times\left [ 0,1 \right ] $ $$f(x,y)=\begin{cases}
  2^n,\quad x=\frac{2m-1}{2^n}\text{ and }0<y\le\frac{1}{2^n}\\
\quad \left ( n=1,2,\ldots;m=1,2,\ldots,2^{n-1} \right ) ,\\
  0,  \text{ otherwise}.
\end{cases}$$ $\textbf(1).$ For any $\varepsilon>0,$ $$\iint_{[0,1]\times[\varepsilon ,1]} f(x,y)\,dx\,dy=0 \Rightarrow $$ $$\iint_{[0,1]\times[0 ,1]} f(x,y) \, dx\, dy = \lim_{\varepsilon \to 0} \iint_{[0,1]\times[\varepsilon ,1]} f(x,y) \, dx \, dy = 0.$$ $\textbf(2).$ For any fixed $y\in\left [ 0,1 \right ],$ $$ \int_0^1 f(x,y) \, dx=0\Rightarrow \int_0^1 dy \int_0^1 f(x,y) \, dx = 0.$$ $\textbf(3).$ When $x\in[0,1]$ but $x\ne\frac{2m-1}{2^n}\left ( n=1,2,\ldots;m=1,2,\ldots,2^{n-1} \right ) ,$ we get $\int_0^1 f(x,y) \, dy = 0;$ When $x\in[0,1]$ and $x=\frac{2m-1}{2^n}\left ( n=1,2,\ldots;m=1,2,\ldots,2^{n-1} \right ) ,$ we get $$\int_0^1 f(x,y) \, dy = \int_0^{\frac{1}{2^n}}f(x,y) \, dy=1.$$ So $$ \int_0^1 dx\int_0^1 f(x,y) \, dy$$ does not exist in Riemann sense! I am definitely not disagreeing with Fubini's Theorem. Actually,I want find a counterexample/example $f(x,y)$ is bounded or unbounded,continuous  on some region $\mathcal{R}$ which is bounde or unbounded and not necessarily closed or open and the function $f(x,y)$ satisfies the $\textbf{Condition IV}$ , but $$ \text{ the improper double integral } \iint_{\mathbf{R}^2}  \lvert f(x,y) \rvert \, \mathrm{d}x \, \mathrm{d}y < \infty \nRightarrow \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty \lvert f(x,y) \rvert \, \mathrm{d}x \right] \mathrm{d}y < \infty ;$$ and $$\text{ the improper double integral } \iint_{\mathbf{R}^2}  \lvert f(x,y) \rvert \, \mathrm{d}x \, \mathrm{d}y < \infty \nRightarrow \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty \lvert f(x,y) \rvert \, \mathrm{d}y \right] \, \mathrm{d}x < \infty.$$ further,the the equalities $$ \iint_{\mathbf{R}^2} f(x,y) \, \mathrm{d}x \, \mathrm{d}y
= \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty f(x,y) \, \mathrm{d}x \right] \, \mathrm{d}y
= \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty f(x,y) \, \mathrm{d}y \right] \, \mathrm{d}x $$ can not hold.","['multivariable-calculus', 'multiple-integral', 'improper-integrals', 'real-analysis']"
4239872,Difference between cardinal and ordinal [duplicate],"This question already has an answer here : Simple definition of Ordinal and Cardinal numbering (1 answer) Closed 2 years ago . I think this question has already been asked, but I do not find any precise trace of it. I do not get the difference between cardinal and ordinal numbers: why aren't they both matching the equivalence classes under the relation ""being in bijection with""?",['elementary-set-theory']
4239877,Polynomial that forces a polynomial to be $0$,"Suppose that $f(x_0,x_1,\dots,x_n)\in \mathbb C[x_0,\dots,x_n]$ is a polynomial. Then what are the conditions that $f$ must satisfy (preferably necessary and sufficient) such that there exists a $g\in \mathbb C[x_1,\dots,x_n]$ for which $f(g(x_1,\dots,x_n),x_1,\dots,x_n)$ is a polynomial identical to $0$ ? I am sure that there is a theory based on this question, if someone could point me to the right direction I would appreciate it.","['algebraic-geometry', 'polynomials']"
4239900,How to calculate the residue of this function quickly (or by mathematica)?,"While looking at this post (The second answer) , I find that it is to tedious to calculate the  Residue of $$ f(z)=-\left(\frac{z-1}{z+1}\right)^2\frac{2n/z}{z^{2n}-1} $$ at $-1$ .
I do know that we can do this: $$\operatorname*{Res}_{z=-1}f(z)=\frac{1}{2!}\frac{d^2}{dz^2}(f(z)\cdot(z+1)^3).$$ But I am not satisfied with this method. I have the following questions: 1 . How many methods do we have to calculate this, can you provide me with an ingenious one? 2 . I tried to calculate this via Mathematica like this:[ ] If I let $n$ take concrete integers, say, $n=5$ , we do get the right answer $-34$ . However, it seems that we cann't get the right answer if we let $n$ be a variable.  What's wrong here, how can we use mathematica to get a general answer (instead of concrete examples by letting n be some integers). I faced with this sort of problems in similar situations. Can you tell me what shoud I do, or just let me know that mathematica cannot do this! Thank you ! Addition As for Sangchul Lee's answer for my second question, I have another quesion. Why does the following code does not work, what's the difference between ""Element[n, Integers]"" and ""Assumptions -> n \in Integers"":","['complex-analysis', 'residue-calculus', 'complex-numbers']"
4239908,Definition of variety in Huybrechts's Fourier-Mukai transforms in algebraic geometry,"Given a variety $X$ over a field $k$ , Huybrechts's book ""Fourier-Mukai transforms in algebraic geometry"" deals mainly with the bounded derived category $\mathcal{D}^b(X)$ of $X$ , which is defined as the bounded derived category of the abelian category $\text{Coh}(X)$ of coherent sheaves on $X$ . Q.: Which definition of variety is Huybrechts using? Neither did I find a definition in his book, nor here on mathstacksexchange or other online sources that I came across. Since I am reading chapter 4 at the moment, I also checked the original publications of Bondal and Orlov (the primary content of chapter 4), but they do also not define varieties. In chapter 4, Huybrechts mostly assumes that $X$ is smooth and projective to have Serre duality. By projectiveness, we certainly have a dualizing sheaf $\omega_X$ and that having the actual isomorphisms of Serre duality is equivalent to being locally Cohen-Macaulay (all local rings are Cohen-Macaulay) and being equidimensional. Smoothness gives us Cohen-Macaulay-ness, which means that we should definitely assume the notion of a variety to contain being equidimensional (as per usual, of course). So he is not just talking about general schemes and just avoiding the word ""scheme"" as some authors do. I guess that Huybrechts actually uses one of the more standard definitions like integral separated scheme of finite type or just reduced separated scheme of finite type but which assumptions does one actually need?","['definition', 'algebraic-geometry', 'schemes']"
4239954,Complex manifold and Hadamard theorem,The Hadamard theorem states that： any complete and simply connected manifold M with nonpositive sectional curvature is diffeomorphic to the euclidean space. Is it also true if we assume that $M$ is a Hermitian manifold and replace sectional curvature with holomorphic sectional curvature？ If it’s not enough，how about changing nonpositive sectional curvature to semi-negative curvature form？ Thank you for your answer！,"['complex-geometry', 'riemannian-geometry', 'differential-geometry']"
4239956,Why are the general solutions for $x$ of $ \sin(\pi-x)=0$ and $ \sin(x-\pi)=0$ different?,"If, $$ \sin(π-x)=0$$ Then, $ \sin(x-π)=0 $ [multiplying by $(-1)$ on both sides] But since general solution of $ \sin x=0 $ is $ x=n\pi $ Above equations yield $$ x=\pi - n\pi $$ And $$ x = \pi +n\pi $$ Is it okay to use either of equations $ \sin(π-x)=0 $ and $ \sin(x-π)=0 $ when finding general solution? Or am I free to multiply the equation with $(-1)$ ?",['trigonometry']
4239989,Dilemma regarding first fundamental theorem of Calculus,"In the book Principles of mathematical analysis by Walter Rudin these are the statements which I came across Corollary 5.12 $\space\space\space$ If $f$ is differentiable on $[a,b]$ then $f'$ cannot have any simple discontinuities on $[a,b]$ . But $f'$ may have discontinuties of the second kind. Theorem 6.20 $\space\space\space$ Let $f$ $\in$ $\mathscr{R}$ on $[a,b].$ For $a\le x \le b,$ put $$F(x)=\int_a^xf(t)dt.$$ Then $F$ is continuous on $[a,b]$ ; furthermore, if $f$ is continuous at a point $x_0$ of $[a,b]$ , then $F$ is differentiable at $x_0$ , and $$F'(x_0)=f(x_0).$$ Theorem 6.21 $\space\space\space$ If $f$ $\in$ $\mathscr{R}$ on $[a,b]$ and if there is a differentiable function $F$ on $[a,b]$ such that $F'=f$ , then $$\int_a^b{f(x)dx}=F(b)-F(a).$$ Now the problem is, we can have a differentiable function $F$ on $[a,b]$ such that $F'= f$ and $f$ is discontinuous, although the discontinuity will be of second kind according to the statement $1$ . If these discontinuities are finite then $f\in\mathscr{R}.$ Let's assume a point $c\in[a,b]$ where $f$ is discontinuous (discontinuity of the second kind). Since, $f\in\mathscr{R}$ let's define a function $$G=\int_a^xf(t)dt\tag{1}$$ for $x\in[a,b]$ . Then according to the statement $2$ , $G(x)$ is clearly not differentiable at $c$ since $f$ is discontinuous at $c$ .
Now, from statement $3$ we can also say that $$\int_a^xf(t)dt=F(x)-F(a)\tag{2}$$ if $x\in[a,b]$ .
Thus from equations $(1)$ and $(2)$ we have $$F(x)-F(a)=G(x)$$ which would make $G(x)$ differentiable for all $x\in[a,b]$ but we know that $G(x)$ is not differentiable at $c$ . So, this is a paradox which means I am wrong somewhere but try as I might I am not able to find it. It'd be a great help if someone can point out the error. Edit: $\mathscr{R}$ here denotes the set of Riemann-integrable functions","['riemann-integration', 'calculus', 'derivatives', 'real-analysis']"
4240011,Conceptual doubt in Definite Integration regarding limits of $\int_{0}^{2}x\cdot\sqrt{x+2}\ dx$,"Question: Evaluate $I=\int_{0}^{2}x\cdot\sqrt{x+2}\ dx$ . My Approach: Put $x+2=t^{2}$ .
Now changing limits: Lower Limit $\left(x=0\right)\ :\ t^{2}=0+2=2$ $\to$ $t=\pm\sqrt{2}$ How do I know if i have to take the t with + or - sign? Same confusion is with the upper limit. Sorry if this might be too bad of a question to ask but I have only began with definite integration. I know This doubt is really specific because taking some other substitution would not have landed me in this situation. But how do I proceed this way? Edit: I think everyone is right, It is just a matter of preference.
What alex is saying is: Let me take $-\sqrt{2}$ as the lower limit and $-2$ as the upper limit, since I have substituted $t^{2}=x+2$ We have, $dx=2tdt$ and the integral becomes: $I=2\int_{-\sqrt{2}}^{-2}\left|t\right|\cdot t\cdot\left(t^{2}-2\right)dt$ which gives the same answer. Here we will open |t| with - sign because we know it is varying in negative number. We can even take lower limit as $-\sqrt{2}$ and upper limit as $+2$ and evaluate the integral which gives the same thing but this time I have to split the integral because of the mod, specifically: $$I=2\int_{-\sqrt{2}}^{2}\left|t\right|\cdot t\cdot\left(t^{2}-2\right)dt$$ $$I=2\int_{-\sqrt{2}}^{0}\left(-t\right)\cdot t\cdot\left(t^{2}-2\right)dt+2\int_{0}^{2}\left(+t\right)\cdot t\cdot\left(t^{2}-2\right)dt$$ . Both give the same answer. Obviously integrating from $+\sqrt{2}\to2$ is easy but it's nice to get the concepts right.","['integration', 'calculus', 'solution-verification', 'definite-integrals']"
4240042,General form third degree multi variable Taylor polynomial,"Using a second-degree multivariable Taylor polynomial for $x=(x_{1},...,x_{n})$ it follows that $$f(x+\Delta x)\approx f(x)+\nabla f(x)\Delta x+\frac{1}{2}\Delta x^{T}H(x)\Delta x$$ with $\nabla f$ the gradient and $H(x)$ the Hessian of $f$ . What is the general form of the third degree polynomial? My attempt would be something like $\frac{1}{6}\Delta x^{T}I(x)\Delta x^{2}$ , such that (e.g., for $n=2$ ) $$I(x)\Delta x^{2}=\begin{bmatrix}\frac{\partial^{3}f(x)}{\partial x_{1}^{3}}&3\frac{\partial f}{\partial x_{1}}\frac{\partial^{2}f}{\partial x_{2}^{2}}\\3\frac{\partial f}{\partial x_{2}}\frac{\partial^{2}f}{\partial x_{1}^{2}}&\frac{\partial^{3}f(x)}{\partial x_{2}^{3}}\end{bmatrix}\begin{bmatrix}\Delta x^{2}_{1}\\\Delta x^{2}_{2}\end{bmatrix}$$ and $$\frac{1}{6}\Delta xI(x)\Delta x^{2}=\frac{1}{6}\frac{\partial^{3}f(x)}{\partial x_{1}^{3}}\Delta x_{1}^{3}+\frac{1}{6}\frac{\partial^{3}f(x)}{\partial x_{2}^{3}}\Delta x_{2}^{3}+\frac{1}{2}\frac{\partial f}{\partial x_{1}}\frac{\partial^{2}f}{\partial x_{2}^{2}}\Delta x_{1}\Delta x_{2}^{2}+\frac{1}{2}\frac{\partial f}{\partial x_{2}}\frac{\partial^{1}f}{\partial x_{1}^{2}}\Delta x_{2}\Delta x_{1}^{2}$$ ; however, I know this to be wrong unfortunately.","['multivariable-calculus', 'taylor-expansion']"
4240045,Finding the limit as $x$ tends to $0^{+}$,Question: $$\lim_{x\rightarrow 0^{+}} x \ \tan(\frac{\pi }{2}-x)$$ My Work: To begin with I re-arranged the the question to the $\frac{\infty}{\infty}$ form: $$\lim_{x\rightarrow 0^{+}} \frac{\tan(\frac{\pi }{2}-x)}{\frac{1}{x}}$$ Then applying L'Hospital's rule I got the following: $$\lim_{x\rightarrow 0^{+}}\frac{\sec ^{2}(\frac{\pi }{2}-x)}{\frac{1}{x^{2}}}$$ which I rearranged to $$\lim_{x\rightarrow 0^{+}} \frac{x^{2}}{\cos ^{2}(\frac{\pi}{2}-x)}$$ Applying L'Hospital's rule again I got the following: $$\lim_{x\rightarrow 0^{+}} \frac{2x}{(-2)(-1))\cos(\frac{\pi }{2}-x)\sin(\frac{\pi }{2}-x) )} \ = \lim_{x\rightarrow 0^{+}} \frac{2x}{\sin(\pi-2x) )}$$ Above I used the property $\sin(2x) = 2\sin(x) \ \cos(x) $ And then applying L'Hospital's rule for the final time I got the following: $$ \lim_{x\rightarrow 0^{+}} \frac{-1}{\cos(\pi-2x) )} = 1$$ Is my answer and method correct?,"['limits', 'self-learning', 'derivatives']"
4240065,Possible number of passwords combinations,"We have been given the following question for our mock exam: Each student has a password, which is 6 characters long and each character
is either a digit or a lower case letter. Each password must contain at least
ONE letter. How many possible passwords are there? 26 lower case letters
10 digits
6 characters long
At least one letter The way I understood, is that it would be easier using inclusion-exclusion, therefore: $36^6 - 10^6 $ = 2175782336 However another student mentioned it would be: $36^6 - 10^5 $ = 2176682336 And I also heard: $36*36*36*36*36*26$ = 1572120576 I think the word ""at least ONE letter"" is throwing me off a bit. Would anyone mind explaining this to me, please?","['permutations', 'combinatorics']"
4240097,Limit of the ratio of the areas of complex surfaces.,"Let $D$ be the disc in the complex plane centred at the point $\frac{\pi}{4}$ and of radius $r$ . Let $D'$ be the
image of this disk under the map $z\to \sin z$ . Evaluate the following limit $$\lim_{r\to 0}\frac{\text{Area}(D')}{\text{Area}(D)}.$$ My attempt: The given disc is $|z-\frac{\pi}{4}|\leq r$ , i.e., $z=\frac{\pi}{4}+re^{i\theta}$ for $0\leq \theta\leq 2\pi$ . We note that when $r\to 0$ , $\sin z\to \sin \frac{\pi}{4}=\frac{1}{\sqrt{2}}.$ How to think forward?","['complex-analysis', 'limits', 'area']"
4240101,Convergence in Probability via Test Functions,"A sequence $X_n$ of random variables is said to converge weakly (i.e. in distribution) to $X$ if for every $f \in C_b$ we have $$
Ef(X_n) \to Ef(X).
$$ Now, I was wondering if there was a class of test functions such that for every $g \in Class$ , we would have an equivalent definition for convergence in probability. That is $X_n$ converges in probability to $X$ if for every $g \in Class$ , we have $$
Eg(X_n) \to E g(X).
$$","['measure-theory', 'convergence-divergence', 'probability-theory', 'weak-convergence']"
4240108,Multiple Lagrange Interpolation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I have a data table looking similar to the one below. There I have for given x- and y-values respective z-values ( $z(x,y)$ ). How can I interpolate the matrix that I find a function that describes $f(x)=z=f(x,y)$ ? Do I need a Multiple Lagrange Interpolation (as described in this document ) for this non-linear function? What kind of (free) software can I use to achieve this? y x1 x2 x3 x4 x5 x6 x7 y1 z (x1,y1) z (x2,y1) z (x3,y1) z (x4,y1) z (x5,y1) z (x6,y1) z (x7,y1) y2 z (x1,y2) z (x2,y2) z (x3,y2) z (x4,y2) z (x5,y2) z (x6,y2) z (x7,y2) y3 z (x1,y3) z (x2,y3) z (x3,y3) z (x4,y3) z (x5,y3) z (x6,y3) z (x7,y3) y4 z (x1,y4) z (x2,y4) z (x3,y4) z (x4,y4) z (x5,y4) z (x6,y4) z (x7,y4) y5 z (x1,y5) z (x2,y5) z (x3,y5) z (x4,y5) z (x5,y5) z (x6,y5) z (x7,y5) y6 z (x1,y6) z (x2,y6) z (x3,y6) z (x4,y6) z (x5,y6) z (x6,y6) z (x7,y6) y7 z (x1,y7) z (x2,y7) z (x3,y7) z (x4,y7) z (x5,y7) z (x6,y7) z (x7,y7) y8 z (x1,y8) z (x2,y8) z (x3,y8) z (x4,y8) z (x5,y8) z (x6,y8) z (x7,y8) y9 z (x1,y9) z (x2,y9) z (x3,y9) z (x4,y9) z (x5,y9) z (x6,y9) z (x7,y9) Given Numbers: f(x,y)=z 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 32 4 -16 -32 -48 -63 -76 -90 -103 -116 -124 -128 -132 -136 -139 -136 -128 -118 -100 -75 -40 2 50 16 0 -18 -32 -48 -63 -78 -90 -100 -111 -118 -123 -125 -128 -125 -121 -112 -96 -70 -37 4 75 44 26 8 -10 -27 -44 -57 -70 -84 -96 -104 -110 -116 -118 -116 -113 -100 -83 -60 -30 12 100 66 51 32 13 -7 -22 -38 -53 -68 -79 -88 -95 -100 -106 -103 -98 -90 -72 -48 -16 21 125 96 76 57 36 18 -2 -20 -36 -49 -60 -72 -80 -86 -92 -90 -86 -75 -60 -38 -11 27 150 120 96 77 56 36 17 -4 -18 -33 -44 -55 -64 -70 -74 -74 -71 -63 -46 -26 5 39 175 144 124 102 79 57 36 19 1 -17 -28 -40 -50 -56 -63 -64 -60 -50 -33 -18 16 44 200 164 146 123 100 80 60 40 23 5 -9 -21 -32 -41 -48 -50 -47 -40 -28 -7 20 58 225 180 160 138 116 95 77 58 38 20 5 -10 -20 -28 -35 -38 -36 -29 -16 6 30 64 250 180 160 138 116 95 77 58 41 29 18 4 -10 -17 -24 -28 -24 -16 -5 18 44 73 300 180 160 138 116 95 77 58 41 29 18 4 1 1 8 0 2 9 20 36 60 92","['lagrange-interpolation', 'interpolation', 'functions']"
4240112,Maximization of complex quadratic function with quadratic and cubic equality constraints,"I am trying to solve $$\max_{g_0,...,g_{M-1}} \left|\sum_{m=0}^{M-1} g_m\right|^2\ \text{s.t.}\ \sum_{m=0}^{M-1} |g_m|^2=M,\ \sum_{m=0}^{M-1} g_m |g_m|^2=0.$$ where $g_m$ can be complex. The problem does not seem easy to solve for me. Intuitively, I would conjecture that an optimal $g_m$ should be purely real up to a constant phasor ( $g_me^{\jmath \phi}$ achieves the same cost function as $g_m$ and also meets the constraints if $g_m$ does). If this phasor is set to one, the problem is converted to an all real problem $$\max_{g_0,...,g_{M-1}} \left(\sum_{m=0}^{M-1} g_m\right)^2\ \text{s.t.}\ \sum_{m=0}^{M-1} g_m^2=M,\ \sum_{m=0}^{M-1} g_m^3=0.$$ I can find the globally optimal solution of this problem using the Lagrangian, setting its derivative to zero, and finding the global optimum among the different critical points. The optimal solution is then ""simply"" to set all $g_m$ to the same value except for one with an opposite sign to meet the second constraint. For instance, using first element as the opposite one \begin{align*}
	g_m&=\frac{\sqrt{M}}{\sqrt{M-1+(M-1)^{2/3}}}\begin{cases}
	- \left(M-1\right)^{1/3}\ &\text{if}\ m=0\\
	1\ &\text{otherwise}
	\end{cases}.
\end{align*} Of course all of that relies on the conjecture, which I find hard to prove... Any idea? Thank you for your help!","['complex-analysis', 'optimization', 'non-convex-optimization']"
4240156,Functorial properties of the degree in vector bundles,"Let $X$ be a Riemann surface $^\dagger$ and consider a complex vector bundle $E$ over it. I know that the definition of the degree of the bundle $E$ is given by $$\text{deg} E = \frac{i}{2\pi} \int_X \text{trace}F_A$$ where $F_A$ is the curvature induced by an arbitrary connection $A$ on $E$ . I know that the degree depends solely on the topology of the bundle and not on the arbitrary connection $A$ used in the definition. I would like to know what are the degrees of related vector bundles such as: The tensor product, $\text{deg} (E_1\otimes E_2)$ . The direct sum, $\text{deg} (E_1\oplus E_2)$ . Quotients, $\text{deg}(E/F)$ where $F\subset E$ is a subbundle. I think I can prove that for direct sums and tensor products the degree is additive by using direct-sum and tensor-product connections, but I am at a loss at computing degree in the quotient bundle. $^\dagger$ : I restrict the question to Riemann surfaces in order for the degree to also be independent of the volume form of the base space $X$ , although I know that the degree can be defined with respect to a given metric/volume/Kähler form in higher dimensions.","['complex-geometry', 'vector-bundles', 'algebraic-geometry', 'differential-geometry']"
4240174,Why $E[X] = \sum_{i=1}^{\infty}(i\times Pr\{X=i\})$ is equal to $E[X] = \sum_{i=1}^{\infty}( Pr\{X \ge i \}))$ [duplicate],"This question already has an answer here : Proof of expectation of discrete random variable (1 answer) Closed 2 years ago . If we have expectation $E[X] = \sum_{i=1}^{\infty}(i\times Pr\{X=i\})$ , where $i \in \mathbb{N}$ . Can you please explain how is it equal to $E[X] = \sum_{i=1}^{\infty}( Pr\{X \ge i \}))$ ? I see that $$
Pr\left[ X\ge i \right] =1-Pr\left[ X<i \right] 
$$ $$
Pr\left[ X<i \right] =\frac{1}{N}\times \frac{2}{N}\cdots \frac{i-1}{N}
$$ $$
Pr\left[ X\ge i \right] =1-\frac{1}{N}\times \frac{2}{N}\cdots \frac{i-1}{N}
$$ $$
=1-\frac{\left( i-1 \right) !}{N}
$$ $$
=\frac{N-\left( i-1 \right) !}{N}
$$ $$
\sum_{i=1}^{\infty}{\left( i\times Pr\{X=i\} \right)}=i\times \frac{i}{N}\ne \sum_{i=1}^{\infty}{\left( Pr\{X\ge i\} \right)}=\frac{N-\left( i-1 \right) !}{N}
$$ So, can you please correct if I am wrong? I am not able to get to formula that $E[X] = \sum_{i=1}^{\infty}(i\times Pr\{X=i\})$ , where $i \in \mathbb{N}$ is equal to $E[X] = \sum_{i=1}^{\infty}( Pr\{X \ge i \}))$ ?.","['statistics', 'probability']"
4240175,Uniform convergence and exchanging limit and integral,"I have to perform the following operation $$\lim_{n\to\infty} \int_{-\infty}^{+\infty} \Phi(x+n) \phi(x) dx$$ where $\Phi$ and $\phi$ are the standard normal CDF and PDF respectively. From what I understand, a sufficient condition to exchange limit and integral is that the integrand converges uniformly to its limit, which we know to be $\lim_{n\to\infty} \Phi(x+n) \phi(x) = \phi(x)$ . Here, I don't think we have uniform convergence (but corrections are welcome as my understanding is still lacking), and one way to check it is to see that $\sup_x |\Phi(x+n)\phi(x)-\phi(x)| \not\rightarrow_{n\to\infty}0$ . However, solving the integral (using properties of standard normal integrals) yields $$
\int_{-\infty}^{+\infty} \Phi(x+n) \phi(x) dx = \Phi(n)
$$ and so it turns out that $$
\lim_{n\to\infty} \int_{-\infty}^{+\infty} \Phi(x+n) \phi(x) dx =  \int_{-\infty}^{+\infty} \lim_{n\to\infty} \Phi(x+n) \phi(x) dx = 1,
$$ so we can exchange limit and integral. What am I missing? I am trying to understand the theory behind, because I will have to deal with more general functions than $\Phi(x+n)$ , all of which have limits in this sort of additive way.","['integration', 'limits', 'normal-distribution', 'uniform-convergence']"
4240203,What is the limit of the following problem?,"I need to find the limit of the following function : $$\lim_{x\rightarrow 0} \  \frac{a^{\ x} \ b^{ \ x} - b^{ \ x} - a^{\ x} +1}{x^{ \ 2}}$$ I know that it is in $\frac{0}{0}$ form so I have applied L'Hospital rule as seen below: $$\lim_{x\rightarrow 0}\frac{(ab)^{x} \ log(b) + (ab)^{x} \ log(a) - b^x \ log(b) - a^x \ log(a)}{2x} $$ Applying the L'Hospital rule again I ended up with: $$\lim_{x\rightarrow 0}\frac{(ab)^{x}\log(ab) \left [ log(a) + log(b) \right ]\ - \ b^{x} \ (log \ b)^{2} \ - a^{x}\ (log \ a)^{2}}{2} \  $$ $$ =\frac{(log \ a)^{2} + (log \ b)^{2} + 2log(a)log(b) \ - (log \ a)^{2} - (log \ b)^{2}}{2}\ $$ $$=log(a)log(b)$$ Is the answer and method correct? Also if correct, is there a shorter way of solving it?","['limits', 'self-learning', 'derivatives', 'exponential-function']"
4240216,Suppose we have $N$ people. A random selection of $k$ of these people meet each day. What is the expected number of days until everyone has met?,"I thought of this problem today and I'm not quite sure how it's solved. My idea is simply to use the definition of expectation: $$E[\text{# of days until everyone has met}] = \sum_{x=1} x \cdot p(x)$$ Where $p(x)$ is the probability that everyone has met in $x$ days. After that, I'm not quite sure how to compute $p(x)$ . Is this the correct approach? If so, any ideas for how to compute $p(x)$ ? Also, does anyone have ideas for how to solve the case for the expected number of days until $X \%$ of people have met?","['graph-theory', 'expected-value', 'combinatorics', 'coupon-collector', 'probability']"
4240218,Limit in a topology.,"Let $\mathbb{Z}$ denote the set of integers. For $c$ and $r$ in $\mathbb{Z}$ , define: $$B(c, r):=\{c+kr\ |\ k\in \mathbb{Z}\}.$$ As $c$ varies over all integers and $r$ over all positive integers, the sets $B(c, r)$ form a basis for a topology on $\mathbb{Z}$ . Does the following limit exist with respect to this topology? $$\lim_{n\to\infty}(n!-2)^2.$$ I have no idea how to think about this problem. Any hint or help.","['limits', 'general-topology']"
4240228,Tensor product of rings: well-definedness of multiplication,"Let $R$ and $S$ be rings, and let $T$ be a ring with ring homomorphisms $\alpha: T \to R$ , $\beta: T \to S$ . (None of these rings are assumed to be commutative.) Since $R$ and $S$ contain subrings that are isomorphic to quotients of $T$ , we may view them as $T$ -bimodules. Let $\varphi : R \times S \to R \otimes_T S$ be the $T$ -balanced map $\varphi(r, s) = r\otimes s$ . We want to turn the tensor product into a ring. The ring multiplication behaves exactly how you would expect on elementary tensors: $(r\otimes s) \cdot (r^\prime\otimes s^\prime) = (rr^\prime)\otimes(ss^\prime)$ . We then extend it to sums of elementary tensors by distribution. Unfortunately, I can't seem to convince myself that this is well defined. My first idea was to invoke the universal property of the tensor product to show that if $r^\prime \otimes s^\prime = r^{\prime\prime}\otimes s^{\prime\prime}$ , then $(rr^\prime)\otimes (ss^\prime) = (rr^{\prime\prime}) \otimes (ss^{\prime\prime})$ . To this end I defined $f: R \times S \to R \otimes_T S$ by $f(x, y) = (rx) \otimes (sy)$ , where $r \in R$ and $s \in S$ are fixed. However, this does not seem to be $T$ -balanced in general, so the universal property is of little help. Another option is to instead define $f(x, y) = (rx) \otimes (ys)$ . This map is $T$ -balanced, but the induced map $R \otimes_T S \to R \otimes_T S$ only seems to show that $x \otimes y = x^\prime \otimes y^\prime \implies (rx)\otimes (ys) = (rx^\prime) \otimes (y^\prime s)$ , which isn't quite what we want. How can I prove that the multiplication is well defined (for elementary tensors and for arbitrary tensors)? Do I need to make any additional assumptions? (I'm willing to assume that $R$ , $S$ , and $T$ are finite-dimensional algebras over a field $k$ , and that $\alpha$ and $\beta$ are $k$ -linear. If absolutely necessary I might also be willing to assume that $T$ is commutative. However, I would prefer not to assume that $R$ and $S$ are $T$ -algebras, i.e. I don't want to assume that $\operatorname{Im}\alpha \subseteq Z(R)$ or $\operatorname{Im}\beta \subseteq Z(S)$ .)","['ring-theory', 'abstract-algebra', 'tensor-products', 'algebras']"
4240251,Is a figure eight a manifold,"Let $S$ be image of function of $f : (-\pi,\pi) \rightarrow \mathbb{R}^2$ defined $f(t) = (\sin 2t, \sin t)$ . Which is figure-eight. Now it is not manifold because there is self-intersection. But it is immersed submanifold of dimension 1. Which implies that it is a smooth manifold. Isn't this contradiction. where am I going wrong ?","['manifolds', 'submanifold', 'differential-geometry']"
4240268,multiplication principle and permutation rule; when to use what,"Problem: You have CDs of which n1= # of classical, n2= # of rocks, n3= # of pop. How many ways can we place the CDs on a rack but keep the genres together? The Answer is: Because there are n1 ways to order classical, n1i (n1 factorial), similarly we have n2i, n3i. And because there are 3 different ways to order classical, rock and pop, we want to multiply by 3 factorial. The answer is (3!) (n1!) (n2!)*(n3!) MY QUESTION: In this problem, the order matters, but it doesn't specify which genre should come first or second, or third. But since the order matters , can we still apply the permutation rule?
For instance, r = 3 since there are 3 ways to order 3 genres. We can say the total # of ways to place the CDs and keeping the genres together are: Permutation(n1 and r=3*Permutation(n2 and r=2)*Permutation(n3=r=1) Since the problem didn't specify which genre will come first or second, we don't know which of n1,n2, or n3 will get r=3 or 2 or 1, so I understand this way isn't correct, but I'm struggling to understand when to use Permutation rule and when to use simply just multiplication principle. Experiment: I assigned random numbers to n1,n2,n3 (n1=5,n2=6, n3=7) and tried both ways and the correct way ( 3! (n1!) (n2!) (n3!)) shows a lot more ways then using the permutation rule.
3!(5!)(6!)(7!) vs. (5!/2!) (6!/4!)*(7!/6!) Can someone help me understand what I'm missing?","['permutations', 'statistics', 'probability']"
4240304,How does one find such a number?,"Not really one of those who usually ask for help here, but this case seems to be too much for me. I have been going over Courant’s “Differential and Integral Calculus”, and I have finally reached the problems section of the chapter 1.5 (i.e. “The limit of a sequence”). I would not have come here if it hasn’t been for the problem 9, namely the (e) part of it. The problem is generally about the sequence $a_n = \frac{10^n}{n!}$ . I have, as all the parts (a)-(d) asked me to, found the limit of the mentioned sequence (=0), concluded whether it is monotonic or not, found the value of n such that the sequence is monotonic onwards and estimated the difference between the sequence and its limit respectively. Now, the (e) part demands that I calculate the exact value of n such that the difference mentioned is less than $\frac{1}{100}$ . I have attempted to expand the factorial and try to deduce some helpful corollaries, but that does not seem to work. I am genuinely confused by this problem and not certain how I should approach it. It is of utmost importance that I note the following: I do not require the solution, I only need a HINT. Not a very crucial one, which virtually solves it (the problem), but one sufficient enough to proceed. I should be grateful for any help provided. P.S. Please excuse me for some fairly probable mistakes in my writing (happens for I am not a native).","['limits', 'calculus', 'analysis', 'sequences-and-series']"
4240332,Group is indecomposible but homomorphic image is not,"A nontrivial homomorphic image of an indecomposable group need not be indecomposable. A group $G$ is indecomposable if $G \neq \{ e\}$ and G is not the (internal) direct product of two of its proper subgroups. Let $f$ be a homomorphism such that it is non trivial an $G$ be an indecomposible group. I have to find a homomorphism after finding a indecomposible group. Every Simple group  is indecomposible, $\mathbb{Z}$ , $\mathbb{Z}_{p^n}$ and $S_n$ are indecomposible. But I am unable to find a example  of homomorphism to prove that $f(P)$ is  not indecomposible.","['group-homomorphism', 'group-theory', 'abstract-algebra']"
4240349,How to construct for rotating a point around a given point with an angle $\alpha$,"Explain the construction steps of rotating a point around a given point for a given angle $\alpha$ . I know that we have to translate the point of rotation to origin and then $$x' = x\cos{\alpha} - y \sin{\alpha}$$ $$y' = y\cos{\alpha} + x \sin{\alpha}$$ Then we have to add the given point of rotation to $x'$ and $y'$ .
But I have a confusion that it may not be the construction step of rotating.
Can you please tell me that if construction is based on drawing figures using rulers and protractors?
And if that is true, what will be the construction steps?
Thanks in advance.",['geometry']
4240372,Is topology intrinsic or is it a construction?,"Given a set $M$ , we can construct a topology $\tau$ to this set, which is nothing but a collection of open sets, making it a topological space $(M,\tau)$ . There are many ways to do so. Continuity is defined based on the concept of open sets, i.e., a function $f:(M,\tau) \rightarrow (N,\tau')$ from one topological space to another is said to be continuous if and only if the preimage of each open set of $N$ is open. There is here something which is pretty awkward to me: the notion of continuity is not a property of the function itself, but depends on the topologies you choose for $M$ and $N$ . Since topologies change the continuous character of functions, this makes homeomorphisms from two different sets/manifolds not to be a intrinsic property between the two sets/manifolds, i.e., it depends on the topology you choose. For instance, pick $\mathbb{R}^{n}$ with euclidian metric $|x| = \sqrt{\sum\limits_{i=1}^{n} x_{i}^{2}}$ . We can construct a topology by choosing a basis with the n-balls $B(p;r) = \{x \in \mathbb{R}^{n}; \, |x-p|<r\}$ . Let's call this topology $\tau$ . Now, let $\tau_{0}$ be the trivial topology for $\mathbb{R}^{n}$ , i.e., $\tau_{0} = \{\mathbb{R}^{n}, \varnothing \}$ . Let $f:(\mathbb{R}^{n},\tau_{0}) \rightarrow (\mathbb{R}^{n}, \tau)$ be given by $f(x)=x, \forall x \in \mathbb{R}^{n}$ . One can see that $f$ is not a homeomorphism since it is not continuous. Nonetheless, we know that surfaces in $\mathbb{R}^{3}$ can be topologicaly identified in terms of its genus. I.e., We have a list of surfaces (sphere, torus, 2-torus, ..., n-torus,...) that make any other surface homeomorphic to one of them according to its genus. And genus is something intrinsic of the surface. Therefore the topology is intrinsic to the surface. Thus we have here a contradiction with the construction made above. So, my question is: Is topology a intrinsic property of manifolds or is it an arbitrary construction with respect to nothing but the definition of open set? And, if it is indeed intrinsic, what is the meaning of saying a topology when there is only one topology for a manifold? Thank you!!",['general-topology']
4240400,"Finding $\bigcap\limits_{n=1}^{\infty} \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ [duplicate]","This question already has answers here : Finding and proving $\bigcap\limits_{n=1}^{\infty} \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ (2 answers) Closed 2 years ago . Upon defining $A_n = \left(- \frac{1}{n}, \frac{n}{2n+1}\right)$ , I am trying to find and prove $\bigcap\limits_{n=1}^{\infty} A_n$ . Since $- \frac{1}{n}, \frac{n}{2n+1}$ converge to $0$ as sequences, I am fairly sure that the answer is $0$ (though I don't have any other intuition other than thinking of them sequences). Here is my attempt at proving it. I claim that $\bigcap\limits_{n-1}^{\infty} A_n = \{0\}$ . For any $n \in \mathbb{N}$ , we have $- \frac{1}{n} < 0 < \frac{n}{2n+1}$ , so $0 \in A_n$ for all $n$ , hence $0 \in \bigcap\limits_{n=1}^{\infty} A_n$ . Furthermore, given $x < 0$ , we can find a sufficiently large $N$ such that $- \frac{1}{N} > x$ . so $x \not \in A_n$ and hence $x \not \in \bigcap\limits_{n=1}^{\infty} A_n$ . Furthermore, given $x > 0$ , we can find an $N \in \mathbb{N}$ for which $N > x$ . Then, since $N \geq 1$ , $2N + 1 \geq 1$ , so $x(2N + 1) \geq x > N$ , so $x > \frac{N}{2N+1}$ , so $x \not \in A_N$ , and hence $x \not \in \bigcap\limits_{n=1}^{\infty} A_n$ . Therefore, if $x \neq 0$ , $x \not \in \bigcap\limits_{n=1}^{\infty}$ , so $\bigcap\limits_{n=1}^{\infty} A_n = \{0\}$ . How does this look? Is there a better way to either intuitively come up with this or to prove this? I'm not particularly comfortable with how I proved that $x > 0$ was not in the intersection.","['elementary-set-theory', 'solution-verification']"
4240437,"If $d$ is a gcd of $a$ and $b$, is $dx$ a gcd of $ax$ and $bx$?","Let $D$ be an integral domain and $a,b,x \in D$ . If $d$ is a greatest common divisor ( gcd ) of $a$ and $b$ , is it true that $dx$ is a gcd of $ax$ and $bx$ ? Note that $D$ is an integer domain, not a GCD domain. So this question is not the same as any of the following questions： 1 2 3 etc. More specifically, the existence of gcd of $ax$ and $bx$ is not guaranteed. Any insights are much appreciated. BTW: To avoid ambiguity , I haven't used notations such as $(a,b)$ or $(ax,bx)$ , which makes me verbose. You may use it at will.","['ring-theory', 'gcd-and-lcm', 'abstract-algebra', 'integral-domain']"
4240470,The definition of simple eigenvalue,"There seem to be two accepted definitions for simple eigenvalues. The definitions involve algebraic multiplicity and geometric multiplicity. When space has a finite dimension, the most used is algebraic multiplicity. As I am interested in the general case (where the dimension of space can be infinite) I will not speak of the characteristic polynomial. Let $E$ be a Banach space (possible infinite) and $A:E\to E$ a linear operator, then the eigenvalue $\lambda$ is simple if The dimension of $\mathcal{N}_{\lambda}=\cup_{k\in\mathbb{N}}\mathcal{N}((\lambda I-A)^k)$ is $1$ -- algebraic multiplicity $m_a(\lambda)=1$ ; or The dimension of $\mathcal{N}(\lambda I - A)$ is $1$ -- geometric multiplicity $m_g(\lambda)=1$ . Note that the definitions are not equivalent as we have $m_a \ge m_g$ . We have that, if an eigenvalue is simple in definition 1, it will be simple in definition 2, but the opposite is not true. As mentioned in this answer , in ergodic theory definition 2 is used. In this case, why is this definition used? Is there a range of useful operators they want to include using this definition? More precisely, I am interested in the difference when we characterize ergodicity . A system is ergodic iff 1 is a simple eigenvalue of the Koopman operator . See question 4 or this post . Another moment where the simplicity of the eigenvalue appears is in the Perron-Frobenius theorem ( finite version ). In this context of ergodic theory (mainly, speaking of the Koopman operator), I was told that the definitions are equivalent, but I was not convinced by the explanation. $\mathcal{N}(X)$ is the kernel or nullpace of $X$ .","['ergodic-theory', 'linear-algebra', 'functional-analysis', 'spectral-theory', 'dynamical-systems']"
4240471,"Uniqueness of a local certain homomorphism (Etale Cohomology and the Weil Conjecture by Freitag, Kiehl)","(All rings in the context are presumed to be commutative, unital and noetherian. ) Let $(A,n), (B_1, m_1),$ and $(B_2, m_2)$ be local rings with their maximal ideals, $k$ a field. For $i=1,2$ there are local-etale maps $a_i: A \to B_i$ and local maps $p_i: B_i \to k$ . Recall that a map $\varphi: (R, n) \to (S,m)$ between local ring is called local if $\varphi(n) \subset n$ ; it is local-etale if it is local, flat, unramified (meaning $\varphi(n) = m$ and $R/n \to S/m$ are finite separable) and $S$ arises as a localization of a finitely generated $R$ -algebra. Assume there exist two local maps $\phi_1, \phi_2: B_1 \to B_2$ compatible with $a_i$ and $p_i$ , i.e. $\phi_j \circ a_1 = a_2$ and $p_2 \circ \phi_j = p_1$ for $j=1,2$ . Question: Why does this imply $\phi_1= \phi_2$ ? Clearly, since $p_i$ factorizes as $B_i \to B_i/m_i \to k$ and field extensions $B_i/m_i \to k$ are always injective and so mono,
the induced maps $\overline{\phi_1}, \overline{\phi_2}: B_1/m_1 \to B_2/m_2$ between residue fields coincide due to compatibility with $p_i$ . Why does this suffice to show that $\phi_1 $ and $ \phi_2$ already coincide? Since $a_i$ unramified, we have equality $m_i = n \cdot B_i$ of maximal ideals, but note(!) that we cannot apply Nakayama lemma here to deduce from $B_1= \ker(\phi_1-\phi_2) + m_1 = \ker(\phi_1-\phi_2) + n \cdot B_1$ that $B_1= \ker(\phi_1-\phi_2)$ , since $B_1$ is not a finite $A$ -module. Source: Etale Cohomology and the Weil Conjecture by Freitag, Kiehl, page 16, Construction of Henselian rings.","['etale-cohomology', 'ring-theory', 'algebraic-geometry', 'commutative-algebra']"
4240491,"Suppose that $G$ is a finite group with $\gcd(|G|,3)=1$. Show that $G=\{x^3:x\in G\}$","Suppose that $G$ is a finite group with $\gcd(|G|,3)=1$ . If $\theta:G\longrightarrow G$ , $x\longmapsto x^3$ is a homomorphism of groups, we want to prove that $$G=\{x^3:x\in G\}.$$ To this end, we claim that $\ker \theta =1$ . Indeed, if $a\in \ker \theta$ , then $g^3=1_G$ . So $|g| \mid 3$ . On the other hand, $|g|\mid |G|$ . So, $|g|\mid \gcd(|G|,3)$ and therefore $g=1_G$ .
Hence $\theta$ is injective which maps the finite group $G$ into itself. Therefore, $\theta$ is surjective (and hence $\theta\in \mathrm{Aut}(G)$ ). Then, $$G=\mathrm{im}\theta=\{x^3:x\in G\}$$ and the result follows. My question is whether we could work as follows: Take an $g\in G$ . Then, using Bezout's identity, $$g=g^1=g^{|G|a+3b}=(g^b)^3\in \mathrm{im}(\theta)$$ where $a,b$ are integers and $g^b\in G$ . So, could we omit using that way the whole premise about the homomorphism $\theta$ ? Thanks. Update: Many apologies, I forgot to define $\theta$ !","['finite-groups', 'alternative-proof', 'abstract-algebra', 'solution-verification', 'group-theory']"
4240518,Generalized $\texttt{ABRACADABRA}$ Problem,"Consider the classic problem of a monkey hitting random keys on a keyboard, each with equal probability, and calculating the expected time for the monkey to type $\texttt{ABRACADABRA}$ (if unfamiliar with the martingale solution see, e.g., this question ). Is there a straightforward way to extend the solution to an arbitrary alphabet, arbitrary distribution of hitting the keys on the alphabet, and arbitrary string? Edit Based on Misha Lavrov's and user6247850's answers and comments. Let $A$ be an alphabet, $p$ be a probability distribution over the characters of this alphabet and $S$ be a string, with $s_i$ the $i$ -th character. Let $p(s_i)$ be the probability of hitting this character. I define $L_n(S)$ the left substring of $S$ of length $n$ by the first $n$ characters of $S$ , and analogously $R_n(S)$ the right substring of $S$ of length $n$ by the last $n$ characters of $S$ . The expectation of the stopping time $T_S$ will be: $$\mathbb{E}(T_S) = \sum_{i=1}^{\#S}\left(\prod_{j=1}^i p(s_j)^{-1}\right)\mathbf{1}(R_i(S) = L_i(S)),$$ where $\mathbf{1}$ denotes the indicator function. Is this correct?","['permutations', 'measure-theory', 'game-theory', 'probability-theory', 'martingales']"
4240520,Solving non-linear first order differential equation,"I have the following differential equation problem but I couldn't proceed any further - $$\frac{dy}{dx}= \frac{\frac{-a~y}{x}}{1- ~b~\left(\frac{1}{x}\right)^n\left(\frac{y}{1-y}\right)^m}$$ where, $x \in [0,1] ~\text{and} ~ y \in [0,1]$ But I can't solve it down. I have tried $y= uy_1 ~~~
\text{where}, ~ y_1 = x^{\frac{n}{m}}~$ , but it didn't help. Wolfram gives the solution as - $$y(x) = c_1 \exp( \int  \frac{a}{x - b \frac{x^{m - n + 1}}{(-x + 1)^m}} \, dx) $$ How to simplify the integral? I just wanted a hint that whether it can be solved? If yes, please just tell me what am I doing wrong.","['nonlinear-system', 'substitution', 'ordinary-differential-equations']"
4240535,Is almost-naive set theory in fuzzy logic with comprehension limited to continuous connectives consistent?,"I've heard the result before that naive set theory is consistent in infinite-valued Łukasiewicz logic. This answer contains a citation. In this logic, every connective is continuous (w.r.t the product topology when necessary). Additionally, $[0, 1]$ equipped with the standard topology has the property that any continuous unary function has a fixed point. I'm curious whether this last property is enough to make naive set-theory consistent. I'm also curious whether almost-naive set theories that restrict comprehension to formulas with continuous connectives only are consistent. What follows is an explanation and my attempt to understand the material. I'm interested in the following first-order fuzzy logic. Let $r : \mathbb{R} \to [0, 1]$ be defined in the following way: $$ r(x) = 1 \;\;\text{iff}\;\; x \ge 1 \\ r(x) = 0 \;\; \text{iff}\;\; x \le 0 \\ r(x) = x \;\; \text{otherwise} $$ Let $[a]$ be the truth value associated with the well-formed formula $a$ in the given context. The set of all truth values is $[0, 1]$ and $1$ is the designated truth value. I'm taking the following connectives from infinite-valued Łukasiewicz logic , $\to, \lnot, \leftrightarrow$ . $$ [a\to b] = r(1-[a]+[b]) \\
   [a \leftrightarrow b] = 1-\mathrm{abs}([a]-[b]) \\
   [\lnot a] = 1-[a] $$ Additionally, I add the following connective called strong negation, written $!a$ . Strong negation exchanges designated and undesignated truth values. $$ [!a] = 0 \;\;\text{iff}\;\; [a] = 1 \\ [!a] = 0 \;\; \text{otherwise} $$ Next, I will extend this logic to a first-order setting by adding a notion of relations and a notion of constants. Let $M$ be a metric space $(M_0, d)$ with the additional constraint that the maximum distance between any two elements is $1$ . Let $M$ additionally be equipped with an interpretation of each constant symbol, and let $M$ be equipped with a function of type $M^n \to [0, 1]$ for each relation symbol. Let $a_1, \cdots, a_n$ be terms, the truth value of $R(a_1, \cdots, a_n)$ is the truth value returned by the interpretation of $R$ in $M$ when applied to the tuple $(a_1, \cdots, a_n)$ . The truth value of $a_1 = a_2$ is $1-d(a_1, a_2)$ where $d$ is the distance  function. Additionally, the truth value of $\forall x \mathop. \varphi(x)$ is the greatest lower bound of $\varphi(w)$ for all $w$ in M. The truth value of $\exists x \mathop. \varphi(x)$ is the least upper bound of $\varphi(w)$ for all $w$ in $M$ . I will define equality $=$ as an ordinary predicate that is constrained to be a congruence with respect to all other predicates, i.e. $$ \forall \vec{x} \vec{y} \mathop. (\vec{x} = \vec{y} \to (R(\vec{x}) \leftrightarrow R(\vec{y}))) $$ The above statement includes an abuse of notation ; it cannot be expressed in our logic without a $\land$ -like connective representing the minimum of two truth values. $\vec{x} = \vec{y}$ is defined as $1 - [\text{the maximum distance in any component between $\vec{x}$ and $\vec{y}$}]$ . The connectives $\to$ and $\leftrightarrow$ are the Łukasiewicz connectives. So, here is our axiomatization of almost-naive set theory. We have the axiom of extensionality. Extensionality is sort of bizarre because of the presence of intermediate truth values, it constrains the value of $=$ even when the sets in question are not equal (more specifically, $[a=b]$ must be greater than or equal to $[\forall x \mathop. x \in a \leftrightarrow x \in b]$ .) $$ \forall a \mathop. \forall b \mathop. ((\forall x \mathop. x \in a \leftrightarrow x \in b) \to a = b) $$ We have the axiom schema of continuous comprehension. Let $\varphi$ be constrained not to include any mention of the connective $!$ . The double strong negation $!!$ is there to stop a sequence that approximates $\{x : \varphi(x)\}$ more and more closely from satisfying the axiom. $$ \exists x \mathop. !!(\forall u \mathop. u \in x \leftrightarrow \varphi(x)) $$ In this setting, the Russell set $\{x : \lnot (x \in x)\}$ simply assigns a truth value of $\frac{1}{2}$ to the statement expressing self-membership. $\{x : !(x \in x)\}$ produces a genuine contradiction, but comprehension does not promise us this particular set. This got me thinking, continuous functions from $[0,1]$ to $[0,1]$ must always have a fixed point, and the presence of these fixed points seems to defuse a broad range of possible paradoxes. Are almost-naive set theories in fuzzy FOL with the continuous-only restriction given above consistent? Is the particular theory given above consistent?","['elementary-set-theory', 'fuzzy-logic', 'fuzzy-set', 'logic']"
4240542,Iterated diagonal maps and normal bundle,"Let $X$ be a smooth projective variety. Let $X \times X \xrightarrow{id \times \Delta} X \times X \times X$ be the identity map on the first factor and the diagonal morphism on the second. Is it true that the pull-back of the normal bundle along $\Delta:X \rightarrow X \times X$ , $\Delta^*N_{X \times X / X \times X \times X},$ is just isomorphic to the tangent bundle on $X$ , $TX$ ? Can you see this from the (co)normal exact sequence?","['vector-bundles', 'algebraic-geometry']"
4240546,Can this combinatorics proof be finished using the Compactness Theorem in Logic?,"In Alon and Spencer's book The Probabilistic Method , they prove the following theorem: Theorem: Let $m$ and $k$ be two positive integers satisfying $$e(m(m-1)+1)k\left(1-\frac{1}{k}\right)^m \leq 1$$ Then, for any set $S$ of $m$ real numbers there is a $k$ -colouring of $\mathbb{R}$ so that each translation $x+S$ (for $x \in\mathbb{R}$ ) is multicoloured (i.e. contains at least one real of each colour). Their proof proceeds by proving the statement holds for every finite set of translations $X$ (i.e. there is a $k$ -colouring so that each translation $x+S$ is multicoloured when $x \in X$ ) and then they apply an argument which they refer to as ""a standard compactness argument"", invoking Tychonoff's Theorem to prove the compactness of the space of all functions from $\mathbb{R}$ to $\{1,2,...,k\}$ etc. I'm slightly less familiar with analysis than you might hope (/expect?) when reading this book and while I understand their argument formally, it definitely doesn't come across as ""standard"". I therefore wonder whether it is possible to finish the proof instead using the Compactness Theorem in first-order logic (a piece of machinery I'm a little more comfortable with!). It seems to me that we could formalise the notion of a k-colouring of a set of real numbers in first-order logic and then similarly formalise every sentence of the form "" $x+S$ is multicoloured"" (for each individual $x \in\mathbb{R}$ ). We then know from their earlier argumentation that for every finite subset of these sentences, there is a colouring (i.e. a model for these sentences) and therefore there is a model for all the sentences and the theorem is proven. Question: Is the above reasoning correct? Are there any barriers I have missed to formalising this in first-order logic and using the Compactness Theorem?","['logic', 'combinatorics', 'first-order-logic', 'solution-verification']"
4240564,"Given a simple closed plane curve, find a relationship between the area of the original curve and the area of its parallel curve","For context, I have been introduced to simple plane curves from the perspective of single-variable calculus through the use of parameterization. Furthermore, my textbook only deals with plane curves that don't intersect themselves. The question from my textbook is stated as follows: Let $x = x(t)$ , $y = y(t)$ be a closed curve. A constant length $d$ is measured off along the normal to the curve. The extremity of this segment describes a curve which is called a parallel curve to the original curve. Find the area, the length of arc, and the radius of curvature of the parallel curve Now, after much rumination, I have found expressions for the length of arc and radius of curvature of the parallel curve. The only one I have been having a lot of trouble with is the area of the parallel curve. The first approach that came to mind was a simple algebraic approach: Since the question did not specify, I just assumed that the curve is arc-length parameterized to make life a little easier. Then, the parallel curve can be represented by the following parametric equations: $$x_p=\dot x - R\ddot y, \\ y_p = \dot y + R\ddot x$$ Now, the area of a parametric curve is normally given by the equation: $$A = \int^{t_1}_{t_0}y\dot xdt$$ We can obtain an alternative expression for the area using integration by parts: $$\begin{align}A &= y(t_1)x(t_1)-y(t_0)x(t_0)-\int^{t_1}_{t_0}x\dot ydt \\ &= -\int^{t_1}_{t_0}x\dot ydt, \text{since the curve is closed } x(t_1) = x(t_0),y(t_1) = y(t_0) \end{align}$$ Combining both expressions above, we obtain a nice symmetrical form for the equation for area: $$A=\frac{1}{2}\int^{t_1}_{t_0}y\dot x - x\dot y dt$$ Now, if we denote the total length of the original curve by $l$ , the area of the parallel curve is: $$\begin{align} A_p &= \frac{1}{2}\int^{l}_{0}(y-R\dot x)(\dot x + R\ddot y)-(x+R\dot y)(\dot y - R\ddot x)dt \\ &= \frac{1}{2}\int^{l}_{0} (y\dot x - x\dot y) + R(y\ddot y + x\ddot x) - R(\dot x^2 + \dot y^2) - R^2(\dot x \ddot y - \dot y \ddot x)dt \\ &= \frac{1}{2}\int^{l}_{0} (y\dot x - x\dot y) + R(y(k\dot x) + R(-k\dot y)) - R - R^2k dt, \text{ where } k \text{ refers to the curvature of the original curve} \\ &= \frac{1}{2}\int^{l}_{0} (y\dot x - x\dot y)(1+Rk)-R-R^2k dt \end{align}$$ I didn't really know how to continue simplifying this integral any further from this point, so I tried to get a better intuitive grasp of the problem by considering the simplest case of a plane curve - the circle: If you have a circle of radius $r$ and offset this circle by a distance $d$ , the relationship between the area of the offset circle and the original circle can be stated as: $$\begin{align} \pi (r+d)^2 &= \pi r^2 + 2\pi rd + \pi d^2 \\ A_p &= A + Cd + \pi d^2, \text{ where } C \text{ refers to the circumference of original circle} \end{align}$$ The equation above was interesting because it is similar in form to the integrand I obtained before. The only way I could think of to make use of this simpler case was to consider the osculating circles of the original curve and the parallel curve; however, I wasn't successful in fleshing out this idea further. I would appreciate any input on how I could either flesh out my idea of using osculating circles or any hints on simplifying the integral I got. Any other ideas on how to approach this problem are welcome as well.","['calculus', 'differential-geometry']"
4240599,Solving $f'(x)=f^{-1}(x)$,This is a problem that a friend of mine gave to me a while back. I somewhat solved it and paid no attention to it afterwards until I though about it now. Forgive the errors and laziness this was a long time ago and not everything has to be perfect. I assumed $f$ to be a polynomial function of the kind $f(x)=ax^b$ where $f^{-1}(x)= \big(\frac x a\big)^{1/b} $ and found $$f(x)= \varphi^{-\frac{1}{\varphi}-1}(-x)^{\phi} $$ where $\varphi=\frac{1+\sqrt{5}}{2}$ and $\phi=\frac{1-\sqrt{5}}{2}$ my working is in the following images : (I did this in word) I was curious if there were more solutions to just this polynomial? Perhaps a different function ? Don't bother commenting trying to correct my work I am just curious about the above questions. Thank you for your time,"['functions', 'ordinary-differential-equations', 'real-analysis']"
4240644,Sequence of unit disk automorphisms converge l.u. to an automorphism,"Given $\{f_n\}$ sequence of automorphisms on the (open) unit disk converging locally uniformly to some nonconstant function $f$ . Show that $f$ is an automorphism of the open unit disk. For injectivity we may use Hurwitz theorem (and identity theorem). For surjectivity I wanted to use maximum modulus principle on $\frac{1}{f(z)-w}$ for some $w \notin f(D)$ , but $f$ is not defined on the unit circle...?","['complex-analysis', 'convergence-divergence']"
4240652,"The points M and N are the midpoints of the sides BC and AC of the acute triangle ABC, respectively. There is a point P on AM ...","The points M and N are the midpoints of the sides BC and AC of the acute triangle ABC, respectively. There is a point P on AM so that the angles MPC and NPC are equal. Draw a transient line from point B parallel to CP to intersect the NP at point D. Prove that AB = AD. my try :
at the first Stretching AM from point M to intersect the extend of BD (from D) and I called this point Q after that I tried to use cyclic quadrilateral Properties but I got nowhere
I think this is not hard problem but I stuck on it",['geometry']
4240656,Expressing Sequence as a set,"Let $X$ be a set and let $(x_n)$ be a sequence in $X$ . Then obviously $\{x_n:~n\in \mathbb{N}\}$ is a subset of $X$ . Is that set necessarily infinite? For example if the sequence is an eventually constant sequence, i.e., $x_n=a$ for all $n\geq n_0$ for some $n_0\in \mathbb{N}$ , then is not the set $\{x_n:~n\in \mathbb{N}\}$ a finite subset of $X$ . On the other hand, if $\{x_n:~n\in \mathbb{N}\}$ is a finite subset of $X$ , then is it always true that the sequence is eventually constant? In particular, what can we say about the sequence $(x_n)$ , if $\{x_n:~n\in \mathbb{N}\}$ is a finite subset of $X$ ? Edit: Let $(x_n)$ be a sequence such that $ \{x_n:~n\in \mathbb{N}\}$ is a finite subset of $X$ , then $(x_n)$ contains an eventually contant subsequence. Let $\{x_n:~n\in \mathbb{N}\}=\{y_1,y_2, \dots, y_k\}$ . Consider an Equivalence relation on $\mathbb{N}$ by $$p\sim q \iff x_p = x_q.$$ Then $\sim$ creates a partition on $\mathbb{N}$ , say $A_\alpha$ , where $\alpha$ runs over all disjoint equivalence classes. Obviously, $$\mathbb{N}=\bigcup_{\alpha} A_\alpha.$$ We note that $\frac{N}{\sim}$ is finite. Otherwise, by choice axiom choosing exactly one member from each disjoint equivalence classes, we have $\{x_n:~n\in \mathbb{N}\}$ is infinite, a contradiction. Now index the disjoint equivalence classes by $J_1, J_2, \dots , J_k$ where $\{x_n:~n\in J_m\}=\{y_m\}$ ; $1\leq m \leq k$ . It is straightforward to see that at least one of $J_m$ is infinite, call it $\widetilde{J}$ . Thereafter $\{x_n:~n\in \widetilde{J}\}$ is a constant subsequence of $(x_n)$ .","['elementary-set-theory', 'sequences-and-series']"
4240679,Problem on Mean Value Theorem,"The Question: Let $f$ be a function defined on an interval $[a,b]$ . What conditions could you place on $f$ to guarantee that $$
\min f'\leq \frac{f(b)-f(a)}{b-a} \leq \max f'
$$ My Answer We must require a $\min f'$ and a $\max f'$ before we can proceed further. That means $f'$ must be defined in $[a,b]$ , that is, $f$ should be differentiable in $[a,b]$ . So that's one condition. Now, if $f$ is continuous in $[a,b]$ and differentiable in $(a,b)$ then, per the mean value theorem $$
\exists \text{ } c\in(a,b) \text{ | } f'(c)=\frac{f(b)-f(a)}{b-a}
$$ and obviously $$
\min f'\leq f'(c) \leq \max f'
$$ So the only condition would be for $f$ to be differentiable in $[a,b]$ . Now, I'll tell what's bothering me.
The textbook I'm reading currently has the following definition for absolute extrema. Let $f$ be a function with domain $D$ . Then $f$ has an absolute
maximum value on $D$ at a point $c$ if $$ f(x) \leq f(c) \text{ }
 \forall \text{ } x \in D $$ and an absolute minimum value on $D$ at $c$ if $$ f(x) \geq f(c) \text{ }
 \forall \text{ } x \in D  $$ The reason, I've considered $f$ to be differentiable in $[a,b]$ and not just $(a,b)$ is because of the definition of absolute extrema. Did I miss anything?",['derivatives']
4240686,Conceptual Issues in the Measure Theoretic Proof of Conditional Expectations (via Radon-Nikodym),"I have been looking into measure theory (from a probabilist's perspective), and I have found the proof of the existence  of the conditional expectation to feel a little ""glossed over"" in literature. As such I've tried to very, very slowly break down the steps -- and as a result I have three questions pertaining to what feels like ""conceptual issues"". I will first show how I would slowly develop the proof (please correct me if I'm wrong), which will then lead to the questions at the end: Step 1: Establish probability space: $(\Omega, \Sigma, \mathbb{P})$ . Consider a $\Sigma$ -measurable random variable (RV), over this space as $X$ (which would work for example as: $X: \Omega \rightarrow \mathbb{R}$ ) Step 2: Define sub $\sigma$ -algebra: $\mathcal{G}\subset \Sigma$ , resulting in measurable space: $(\Omega, \mathcal{G})$ . Step 3: Define a measure, $\nu$ , on $(\Omega, \mathcal{G})$ . This measure is to behave as: \begin{align*}
\nu(G) = \int_G X d\mathbb{P} = \int_{\Omega}X\mathbf{1}_{G} d\mathbb{P}=\mathbb{E}[X\mathbf{1}_{G}], \quad \forall G\in\mathcal{G}.
\end{align*} Step 4: Consider now the restricted probability measure, $\mathbb{P}^{\mathcal{G}}$ , restricted to measurable space, $(\Omega, \mathcal{G})$ , such that $\mathbb{P}(G) = \mathbb{P}^{\mathcal{G}}(G)$ , $\forall G\in\mathcal{G}$ . Thus, we are now considering to work probability space: $(\Omega, \mathcal{G},\mathbb{P}^{\mathcal{G}})$ . Step 5: By construction $\nu \ll \mathbb{P}^{\mathcal{G}}$ . We can thus invoke Radon-Nikodym, meaning that there is a unique (a.s.), $\mathcal{G}$ -measurable function, $Z$ , s.t. \begin{align*}
\nu(G) = \int_G Z d\mathbb{P}^{\mathcal{G}} = \int_{\Omega} Z \mathbf{1}_{G} d\mathbb{P}^{\mathcal{G}} = \mathbb{E}[Z\mathbf{1}_{G}], \quad \forall G\in\mathcal{G}.
\end{align*} Step 6: We can thus conclude the following relationships: \begin{align*}
E[X\mathbf{1}_G] = \nu(G) = \int_{\Omega} Z\mathbf{1}_G  d\mathbb{P}^{\mathcal{G}} = \mathbb{E}[Z\mathbf{1}_{G}]
\end{align*} The significance of this is that the LHS is a $\Sigma$ -measurable RV, and in the RHS it is a $\mathcal{G}$ -measurable RV. Moreover, $X=Z$ (a.s.) as by Radon-Nikodym $Z$ is unique (a.s.). Questions: Q1: As far as I can tell, this is the proof of existence for the conditional expectation. However, for me it is not immediately obvious why this should be the conditional expectation. It seems that authors simply make a claim at the end: Therefore, $Z=\mathbb{E}[X\mid \mathcal{G}]$ ... However, I don't get why that is? Especially because $\mathbb{E}[\cdot]$ seems for me to not just be a ""matter of notation"", because $\mathbb{E}[X] = \int Xd\mathbb{P}$ has a very precise definition! So if we declare, $Z=\mathbb{E}[X\mid \mathcal{G}]$ , it seems like the definition of $\nu(G)$ should consist of an iterated integral. Q2: In the long list of equalities in Step 6, whereby we conclude $\mathbb{E}[X\mathbf{1}_G]=\mathbb{E}[Z\mathbf{1}_G]$ , is the expectation wrt the same probability measure? i.e. is it $\mathbb{P}$ on both sides? Or $\mathbb{P}$ in the case of $\mathbb{E}[X\mathbf{1}_G]$ , and $\mathbb{P}^{\mathcal{G}}$ in the case of $\mathbb{E}[Z\mathbf{1}_{G}]$ ... or does it simply not matter? On this case, I have seen different authors have conflicting views, and I am not sure if it is an important issue, or simply transcription error. Q3: What is the significance that $X$ is $\Sigma$ -measurable, and $Z$ is $\mathcal{G}$ -measurable? I wrote down before that ""it is a significant conclusion"", but I don't have an intuition why this is such an important concept.","['measure-theory', 'conditional-expectation', 'measurable-functions', 'probability-theory', 'radon-nikodym']"
4240752,Generalised form of $|HK|=\frac{|H||K|}{|H\cap K|}$ [SOLVED],"So for groups, we know that the cardinality of the product of two subgroups is given by the formula $|HK|=\frac{|H||K|}{|H\cap K|}$ , where $H$ and $K$ are subgroups of the group $G$ . However, after scouring the internet I cannot seem to find a formula for the cardinality of the product of three or more subgroups. Failed attempt: I conjectured that the cardinality of the product of three subgroups is given by the formula $$|XYZ|=\frac{|X||Y||Z||X \cap Y \cap Z|}{|X \cap Y||X \cap Z||Y \cap Z|},$$ where $X$ , $Y$ and $Z$ are subgroups of the group $G$ . Similarly, the cardinality of the product of four subgroups should be given by the formula $$|WXYZ|=\frac{|W||X||Y||Z| |W \cap X \cap Y| |W \cap X \cap Z| |W \cap Y \cap Z| |X \cap Y \cap Z|}{|W \cap X| |W \cap Y| |W \cap Z| |X \cap Y||X \cap Z||Y \cap Z||W\cap X \cap Y \cap Z|},$$ where $W$ , $X$ , $Y$ and $Z$ are subgroups of the group $G$ . I conjectured these formulas because the formula for the cardinality of two subgroups seems to have a similar structure to the principle of inclusion and exclusion $(|A \cup B|=|A|+|B|-|A \cap B|)$ and also the formula $\operatorname{lcm}(x,y)=\frac{xy}{\gcd(x,y)}$ . Therefore, the formula for the cardinality of the product of three subgroups should somewhat follow the pattern for $|A \cup B \cup C|$ and $\operatorname{lcm}(x,y,z)$ in my humble opinion. (although if it doesn’t, I wouldn’t be very surprised either because my argument isn’t very rigorous). I have checked that the formula $$|XYZ|=\frac{|X||Y||Z||X \cap Y \cap Z|}{|X \cap Y||X \cap Z||Y \cap Z|},$$ holds for the example $G=\mathbb{Z}/120\mathbb{Z}$ , $X= \mathbb{Z}/2\mathbb{Z}$ , $Y= \mathbb{Z}/3\mathbb{Z}$ and $Z=\mathbb{Z}/5\mathbb{Z}$ . Also, the formula holds when you let the subgroup $Z$ be the subgroup $X\cap Y$ . Sadly, reality is often times disappointing because I managed to find a counter example to the above formula. By letting the group $G$ be $S_3$ , $X=\{(1),(12)\}$ , $Y=\{(1),(13)\}$ and $Z=\{(1),(123),(132)\}$ . In this example, it isn’t hard to see that the right hand side of the formula would give us $\frac{2\cdot 2\cdot 3 \cdot 1}{1 \cdot 1 \cdot 1}=12$ . However, on the left hand side of the formula, $XYZ$ is a subset of $S_3$ and hence its cardinality has to be less than the order of $S_3$ which is 6, a contradiction. Since my formula failed to hold water, the only natural question to have is what is the formula for $|XYZ|$ ? And perhaps what is the formula of the cardinality of the product of $n$ many subgroups of $G$ be? Will somebody who is rather experienced in this field be able to satisfy my curiousity? Current progress: We can derive a formula for $|XYZ|$ if we were to assume that one of the subgroups is normal
If we were to assume that one of these three subgroups are normal, then either $(XY)$ or $(YZ)$ is a subgroup of $G$ . In the case that $(XY)$ is the subgroup, we can deduce that $$|XYZ|=\frac{|XY|\cdot|Z|}{|XY\cap Z|}=\frac{|X|\cdot |Y|}{|X\cap Y|}\cdot \frac{|Z|}{|XY\cap Z|}=\frac{|X|\cdot|Y|\cdot|Z|}{|X\cap Y|\cdot|XY\cap Z|}$$ We can derive a similar formula if $(YZ)$ is a subgroup. Many of the comments seem to suggest that such a formula probably do not exists. One of the reason cited is due to the fact that there isn’t a clear cut way for us to use induction because $XY$ is usually not a group. Somebody (in an already deleted post) suggested the formula $$|H_1H_2H_3|=\frac{|H_1||H_2||H_3|}{|H_1\cap H_2||H_2\cap H_3| |H_3\cap H_1|},$$ where $H_1,H_2,H_3$ are subgroups for $n=3$ . And in general, $$|\displaystyle \prod_{i=l}^n(H_i)|=\frac{\displaystyle \prod_{i=l}^n(|H_i|)}{\displaystyle \prod_{i=l}^{n}(|H_i\cap H_{i+1}|)}$$ (Note that $H_{n+1}=H_1$ ) where the ${H_i}’s$ are subgroups of $G$ It seemed plausible at first sight. Sadly, it too was quickly disproven using the same counter example for my conjectured formula. For the case of $n=3$ , let the group $G$ be $S_3$ , $H_1=\{(1),(12)\}$ , $H_2=\{(1),(13)\}$ and $H_3=\{(1),(123),(132)\}$ . In this example, it isn’t hard to see that the right hand side of the formula would give us $\frac{2\cdot 2\cdot 3}{1 \cdot 1 \cdot 1}=12$ . However, on the left hand side of the formula, $XYZ$ is a subset of $S_3$ and hence its order has to be less than the cardinality of $S_3$ which is 6, a contradiction. My thoughts on this problem: I still think that there is a chance of there being such a formula. Clearly, one cannot simply work by induction on the number of factors because $XY$ is usually not a subgroup (as mentioned by Brauer Suzuki in the comments below). One approach that I can think of in solving this problem is to look at the proof for $|HK|=\frac{|H||K|}{|H\cap K|}$ and try to somehow replicate it for the case of $n=3$ . (I have tried this but to no success. But feel free to try it because I am kind of new to algebra and hence might have missed something crucial) At the same time, perhaps there is indeed no such formula. For arguments against such a formula do read the comments of ΑΘΩ below which I felt to be rather insightful. Conclusion: Pretty convinced that there isn’t such a formula. Do read the solution by David A. Craven.","['group-theory', 'abstract-algebra']"
4240766,Exponential convergence to equilibrium for finite continuous-time Markov chains,"Setting: Consider a continuous-time Markov chain on a finite state space $\mathcal Z$ with irreducible (constant) generator matrix $L\in\mathbb R^{|\mathcal Z| \times |\mathcal Z|}$ . Let $\rho_t\in\mathcal P(\mathbb R^{|\mathcal Z|})$ be the probability law of $X_t$ (here subscript denotes dependence on time and $\mathcal P(\cdot)$ is the space of probability measures). This time- $t$ distribution evolves according to \begin{equation}
\partial_t\rho_t = L^T \rho_t,
\end{equation} with some initial distribution. Since $L$ is irreducible there exists a stationary measure $\mu\in \mathcal P(\mathbb R^{|\mathcal Z|})$ , i.e. $L^T\mu = 0$ . Question: Are there some results in this setting which state that the time- $t$ distribution $\rho_t$ converges exponentially fast to $\mu$ , i.e. \begin{equation}
\|\rho_t - \mu\|_{TV} \leq Ce^{-D t},
\end{equation} for some positive constants $C,D$ . Here $\|\cdot\|_{TV}$ is the total-variation norm. Remarks: When I search online, typical results require that the Markov chain is reversible and then they provide estimates on convergence, however I do not want to make any such assumption. Also, there is often discussion about spectral gap, but I don't yet understand what I need to assume for $L$ so as to get a spectral gap.","['probability-theory', 'markov-chains', 'mixing']"
4240799,Doubt with Chain rule differentiation in multivariate calculus.,"Suppose $E\subseteq\mathbb R^n$ and $f$ maps $E$ into $\mathbb R^m$ . Let $g$ map
a subset of $\mathbb R^m$ into $\mathbb R^p$ . If $f$ is differentiable at $x\in E$ and $g$ is differentiable at $f(x) \in f(E)$ , then the composition $g \circ f$ is differentiable at $x$ and $$(g\circ f)'(x) = g'(f(x)) f'(x).$$ where the indicated product is matrix multiplication. Although this version of the chain rule may look a bit strange, it is really
just the familiar chain rule of calculus in a new guise. You can convince
yourself of this fact by writing the formula out in terms of partial derivatives. This is something I don't understand. I don't find this definition of chain rule intuitive.Can someone explain this?","['multivariable-calculus', 'chain-rule']"
4240826,Integer solutions for $\frac{1}{a} + \frac{1}{b}=\frac{p}{q}$,"I found a description of the way to solve $$\frac{1}{a} + \frac{1}{b}=\frac{p}{q}$$ , for relatively prime $p,q$ in integers that goes as follows: Write the LHS as $\frac{a+b}{ab}$ . Let $a=\frac{m+q}{p}, b=\frac{n+q}{p}$ . Hence, $$\frac{a+b}{ab}=p\cdot \frac{m+n+2q}{q^2+(m+n)q+mn}=\frac{p}{q}$$ . Thus, we see that the big fraction must be equal $\frac{1}{q}$ . Thus, $q(m+n+2q)=q^2+(m+n)q+mn$ , so $mn=q^2$ . The solutions are generated as follows: list all ways to write $q^2$ as a product $mn$ of integers, keep only those for which $p$ divides $q+m$ and $q+n$ (since $a$ and $b$ are integers), and the solutions are $a=(m+q)/p$ , $b=(n+q)/p$ . The only thing I don't understand is why we assume that $a=\frac{m+q}{p}, b=\frac{n+q}{p}$ .  This step seems completely arbitrary to me. Why do all solutions to the equation have this form? What is the motivation to make this substituiton?","['proof-explanation', 'algebra-precalculus', 'diophantine-equations']"
4240889,Exact sequence of abelian groups - Corolary 11.7 - Neukirch,"The Proposition $(11.6)$ of Neukirch's Algebraic Number Theory states that if $\mathcal O$ is a dedekind domain with field of fractions $K$ and $X$ is a set of nonzero prime ideals of $\mathcal O$ with finite complement, there is a canonical exact sequence: $\begin{eqnarray*}
1 \rightarrow U(\mathcal O) \rightarrow U(\mathcal O(X)) \rightarrow \bigoplus_{\mathfrak p\not\in X}K^*/U(\mathcal O_{\mathfrak p}) \rightarrow \mathscr C\ell(\mathcal O) \rightarrow \mathscr C\ell(\mathcal O(X)) \rightarrow 1,
\end{eqnarray*}$ and that $K^*/U(\mathcal O_{\mathfrak p})\cong \mathbb Z$ , for all prime $\mathfrak p\not\in X$ . Now let $\mathcal O_K$ be the ring of integers of $K$ , let $S$ denote a finite set of prime ideals of $\mathcal O_K$ , and let $X$ be the set of all prime ideals that do not belong to $S$ . We put $\mathcal O_K^S = \mathcal O_K (X)$ . The units of this ring are called the $S$ -units. (11.7) Corollary. For the group $K^S = (\mathcal O_K^S)*$ of $S$ -units of $K$ there is an isomorphism $K^S\cong \mu(K) \times \mathbb Z^{\# S+r+s-1}$ where $r$ and $s$ are the number of real imersions and pairs of complex imersions of $K$ . The proof of Neukirch is as follows: Proof: The torsion subgroup of $K^S$ is the group $\mu(K)$ of roots of unity
in $K$ . Since $\mathscr C\ell(\mathcal O)$ is finite, we obtain the following identities from the exact
sequence above and from Dirichlet Units Theorem: $rank(K^S)=rank(\mathcal O_K^*)+rank(\bigoplus_{\mathfrak p\in S}\mathbb Z)=\#S+r+s-1$ . I suppose the proof uses that result that relates exact sequences of $\mathbb Z$ -modules and the ranks of these modules. But I only find: $rank~U(\mathcal O)-rank~U(\mathcal O(X))+rank~\mathbb Z^{\# S}-rank~\mathscr C\ell(\mathcal O)+rank~\mathscr C\ell(\mathcal O(X))=0$ . Dirichlet Unit Theorem gives $rank~U(\mathcal O)=r+s-1$ , but do I have some information about the ranks of the class groups?","['algebraic-number-theory', 'group-theory', 'abelian-groups', 'exact-sequence']"
4240894,Get radius of circle given arc length and chord length,"I have to program a software to get radius of a circle with arc and chord Let's say arc = $9.27$ and chord = $8$ , here is what I tried so far: from the arc formula, I know that: $$\pi r * \frac{\theta}{180} = 9.27$$ And base on the cosine law: $$2r^2 - 2r^2\cos\theta = 8^2$$ Currently I'm stuck at how to get the value of r from this two equation, I'm not really sure how to deal with the $\cos()$ here Or there's easier way to calculate the radius from arc length and chord length?","['trigonometry', 'circles']"
4240904,matrix isomorphism apparent contradiction - where is the bug?,"Let $M_2(\mathbb R)$ be the algebra of 2x2 matrices over $\mathbb R$ .
Let $M^{op}_2$ be the same algebra, but with product reverted (that is, $A\cdot B \ \hbox{(in $M^{op}$)}= B\cdot A \ \hbox{(in $M$)}$ . By the Skolem-Noether theorem (if I'm not wrong), every isomorphism of $M$ into $M^{op}$ is
of the form $f(M) = U^{-1}MU$ , where $U$ is an invertible matrix of $M_2$ (depending only on $f$ ). Now, matrix transposition is such an isomorphism. But I think that if there were exist a matrix $U$ such that $M^T= U^{-1}MU$ for all $M$ , this would be known (a joke, this is impossible of course). So, the theorem of Skolem-Noether is false!
where is the bug in my thinking ? Edit : the Skolem-Noether theorem:
Let $R$ , $S$ be finite dimensional algebras, $R$ simple and $S$ central simple. If $f, g :\ R → S$ are homomorphisms then there is an element $s ∈ S$ such that, for all $r ∈ R$ , $g(r) = s^{−1} f (r)s$ .","['matrices', 'linear-algebra']"
4240923,Calculate the volume of the set $M$,"We have the set $M=\{(x,y,z)\in \mathbb{R}^3 : x^2+y^2-z^2\leq 1, \ 0 \leq z\leq 3\}$ . Draw $M$ and calculate the volume of $M$ . $$$$ I have done the following : \begin{equation*}\int_M\, dV=\int\int\int\, dx\, dy\, dy\end{equation*} Which are the boundaries of the integrals? Do we have to use spherical coordinates? Or do we set $x=r\cos\theta$ and $y=r\sin\theta$ and $z$ remains $z$ with $0\leq z\leq 3$ ?","['integration', 'multivariable-calculus', 'definite-integrals', 'volume']"
4240956,"What happens to $w=\frac{x^2y^3}{z^4}$ , if $x,y,z$ increase by $\%1$ , $\%2$ , $\%3$ respectively?","If $x,y,z$ increase by $\%1$ , $\%2$ , $\%3$ respectively , then $w=\dfrac{x^2y^3}{z^4}$ ............. approximately. $1)\ \%\ 3\text{ decrease}$ $2)\  \%\ 4\text{ decrease}$ $3)\ \%\ 3\text{ increase}$ $4)\ \%\ 4\text{ increase}$ I denote the new $w$ by $w'$ , $$w'-w=\left( \frac{1.01^2.1.02^3}{1.03^4}-1\right)\times w=\left(\frac{101^2\times102^3}{103^4\times100}-1\right)\times w$$ From here should I evaluate $\dfrac{101^2\times102^3}{103^4\times100}-1$ by hand (calculator is not allowed) or there is a quicker method to get to the correct answer?","['calculus', 'algebra-precalculus', 'percentages']"
4240957,Fixed points of permutation groups,"I was studying permutation groups and I founs this question- Let $S_n$ be the group of all permutations of the set $X=\{1,2,\dots,n\}$ . Given a permutation $\sigma\in S_n$ , let $f(\sigma)$ denote the number of fixed points of $\sigma$ . a. Show that the average number of fixed points is $1$ , i.e., $$\frac 1{|S_n|}\sum_{\sigma\in S_n}f(\sigma)=1$$ b. Find the average value of $f(\sigma)^2$ . All that comes to my mind is to use Inclusion Exclusion Principle to calculate the number of combinations for a given value of $f(\sigma)$ . That is, explicitly calculate the number of permutations of $X$ with exactly $r$ fixed points, denoted by $S_n(r)$ . But, that is not a very easy task since we are doing it for a general $n$ which means $S_n(r)$ will be in the form of a summation, all of which needs to be summed again over all $r$ . Also, this approach is not quite elegant. It becomes a real headache however in b since there you need to take a square as well. Also, we are never really using any property of permutation groups while solving this problem. Is there any other approach that can make life easier? While it is suggested in the comments and in an answer to use expectations of random variables, I don't think that is what the question asks of me considering the fact that the course in which I got the problem (it's a group theory course by the way) is far away from that. Is there any other ways to go about it?","['permutations', 'combinations', 'fixed-points', 'combinatorics', 'group-theory']"
4240992,Evaluate $\int \frac{(x^2-1)(x^2+3)}{x^4-2x^3-6x-1}dx$ using elementary methods,"I found this problem while doing some integration from my problem practice book (unkown name). It said to evaluate it using elementary methods.
Please help me evaluating the following integral using elementary methods $$\int \frac{(x^2-1)(x^2+3)}{x^4-2x^3-6x-1} \, dx.$$ I tried to factorize the denominator but it failed. I can't think of any substitution too. I tried to input this at wolfram alpha, and it showed the answer as a summation of a complex function formed using complex cube roots of unity.
Substitution of $x=\sec\theta$ also failed. I am continuously thinking of this but I'm not getting how to start it. If I succeed I will post it. It will be great if someone could give a beautiful solution to this problem preferably using elementary methods. I am a high school student in India. I know how to evaluate elementary integrals .","['integration', 'indefinite-integrals']"
4241055,Transitivity of the action of a normalizer on the set of fixed points,"Let $G$ be a finite group acting transitively on a set $X$ (from the left). Let $H$ be a subgroup. Denote by $S$ the set of fixed points of $H$ . That is $$S=\{x\in X\mid \text{$h\cdot x=x$ for all $h\in H$}\}.$$ Let $N=N_G(H)$ be the normalizer. If $x\in S$ and $n\in N$ , then $H\le Stab_G(x)$ . Hence $H=nHn^{-1}\le Stab_G(n\cdot x)$ , allowing us to conclude that $n\cdot x$ is also a fixed point of $H$ . Therefore $N$ acts on the set $S$ , and we have reached
my question: Is the action of $N$ on $S$ necessarily transitive? Testing with small groups suggests this to be the case, but I am nowhere near seeing why this should always happen. It might also be false! This question is my translation of a natural question from Galois theory into the language of group actions. Incarnations: 1 , 2 . An answer by Derek Holt shows that the answer is affirmative, if $H$ happens to be a Sylow subgroup of $G$ . What happens in general?","['group-theory', 'group-actions']"
4241130,$S_n$ cannot be generated by less than $n-1$ transpositions.,"Question. Assume that $\tau_i$ are transpositions in $S_n$ . Prove that if $\langle \tau_1, \dots \tau_k  \rangle = S_n $ , then $k \geq n-1$ . My attempt. I know that $\langle (1 \; 2), \dots (1 \; n)  \rangle = S_n $ , and I want to substitute $\tau_i$ by these elements. We now that $(1 \; m) \in \langle \tau_1, \dots \tau_k  \rangle$ for each $ 1 \leq m \leq n $ . Assume that $m$ is the smallest integer between $2$ and $n$ that $(1 \; m) \notin \{\tau_1, \dots, \tau_k\}$ . $$(1 \; m) = \tau_{i_1} \dots \tau_{i_s} $$ That $\tau_{i_a} \in \{\tau_1, \dots, \tau_k\} $ for all $ 1 \leq a \leq s$ . These transpositions should send $1 $ to $m$ , so there is the following series between them: $$(1 \; a_0), (a_0 \; a_1), \dots ,(a_t \; m)$$ In the way that it is the smallest series in the $\{\tau_{i_1}, \dots, \tau_{i_s} \}$ . I mean that $a_j \neq m$ for all $1 \le j \le t$ . Moreover, these transpositions in the $\{\tau_{1}, \dots, \tau_{k}\}$ are enough to generate $(1 \; m)$ too. $$
\begin{equation}
(1 \; m) = (1 \; a_0)(a_0 \; a_1) \dots (a_{t-1} \; a_t)(m \; a_t)(a_t \; a_{t-1}) \dots (a_0 \; 1) 
\end{equation}\tag{1}\label{eq1}
$$ By the use of \ref{eq1}, we can substitute $(m \; a_t)$ by $(1 \; m)$ . We can continue this method, and substitute some elements of $\tau_i$ by $(1 \; m)$ . This means that we should have more than equally $n-1$ elements in $\{\tau_1, \dots, \tau_k\}$ . $$
\begin{equation}
(m \; a_t) = (a_{t-1} \; a_t) \dots (a_0 \; a_1)(1 \; a_0)(1 \; m)(a_0 \; 1) \dots (a_t \; a_{t-1})   
\end{equation}\tag{2}\label{eq2}
$$","['alternative-proof', 'group-theory', 'abstract-algebra', 'solution-verification']"
4241134,Why is $\sum\limits_{k=1}^{\left\lfloor\frac n2\right\rfloor}\sin^2\left((2k-1)\frac\pi n\right)=\frac n4$?,"I found the relation for $n\geq3$ $$\sum\limits_{k=1}^{\left\lfloor\frac n2\right\rfloor}\sin^2\left((2k-1)\frac\pi n\right)=\frac n4$$ But despite my best efforts, I still have no idea as to how to prove it. Things I've tried: Adding $\cos^2$ terms. Of course, $\sin^2x+\cos^2x$ and $\cos^2x-\sin^2x$ are both simplifiable, so I thought about adding $\cos^2$ terms to make the sum into $\frac n2$ and hope that the $\sin^2$ and $\cos^2$ terms sum to equal amounts. They don't in the $n$ odd case, so I didn't know what to do with this approach. Adding more $\sin^2$ terms: Since $\sin^2 x=\sin^2(\pi-x)$ , we can add terms to this sum, but honestly, it didn't make the sum any easier to evaluate. Any help here? Edit: Based on the comments, here are my attempts. $$\sum\limits_{k=1}^{\left\lfloor\frac n2\right\rfloor}\sin^2\left((2k-1)\frac\pi n\right)=\frac12\cdot\left\lfloor\frac n2\right\rfloor-\frac12\sum\limits_{k=1}^{\left\lfloor\frac n2\right\rfloor}\cos\left((2k-1)\frac{2\pi}n\right)$$ $$=\frac12\cdot\left\lfloor\frac n2\right\rfloor-\frac12\mathfrak{Re}\left(\sum\limits_{k=1}^{\left\lfloor\frac n2\right\rfloor}\exp\left((2k-1)\frac{2i\pi}n\right)\right)$$ How do I finish?","['trigonometry', 'sequences-and-series']"
4241140,Need to prove with empty set?,"So I've been working on set theory lately, and I have been asking myself: Do I need to do every proof for the empty set?
For example; I need to prove that if $A\cap B=A$ then $A\subseteq B$ . You can do that by saying that if $a\in A$ then $a\in A\cap B$ , so $a\in B$ . Thus, $A\subseteq B$ . Does the assumption that $a\in A$ break the proof for the empty set? (As the empty set has no elements) Also, when I say $a\in B$ I'm assuming B has elements. I know that the proof for $A=\emptyset$ or $B=\emptyset$ is trivial (if $A=\emptyset$ , for every set B $A\cap B=A$ and $A\subseteq B$ ; if $B=\emptyset$ then A must be $\emptyset$ so that $A\cap B=A$ , and obviously $\emptyset \subseteq \emptyset$ ), but I don't know if I should show it in an exam.","['elementary-set-theory', 'proof-writing']"
4241195,"How can I solve this integral $\int_{-1}^1 \int_0^{π}\sin(x)e^{\cos y} \,dy\,dx$","I have trouble solving this integral $$\int_{-1}^1 \int_0^{π} \sin(x)e^{\cos y} \,dy\,dx$$ Any advice on this would be really helpful.","['integration', 'multivariable-calculus', 'definite-integrals']"
4241198,Let ${f}$ be a differentiable function in $x=6$ so that $\lim_{x\to6}{\frac{x^{3}f(x)-1512}{x-6}}=262.144$. Find the values of $f(6)$ and $f(6)'$.,"Let ${f}$ be a differentiable function in $x=6$ so that $$\lim_{x\to6}{\frac{x^{3}f(x)-1512}{x-6}}=262.144$$ Find the values of $f(6)$ and $f(6)'$ . The right answers are, respectively 7 and 1.21. This was a problem presented in a quiz I had this week in Calculus I. By my understanding it would suffice to do $x^{3}f(x)-1512 = 0$ since the upper part should be $0$ just as $x-6$ for the function to exist in $x=6$ . This would return $f(6)=7$ . Doing l'Hôpital's rule and deriving the function makes $f(6)'=-2.28$ ... My other problem is that using $7$ in the place of $f(x)$ does NOT give a limit of $262.144$ as it's intended. Any enlightnment would be appreciated! UPDATE:
You can really find $f(6)$ by just isolating it. To get $f(6)'$ it's necessary to use the definition of derivatives when ${x\to6}$ . That is: $\lim_{x\to6}\frac{f(x)-f(6)}{x-6}$ . Multiplying both sides by $\frac{1}{x^{3}}$ back in the original limit and using $x=6$ we get to: $$\lim_{x\to6}\frac{f(x)-7}{x-6} = \frac{262.144}{6^{3}}$$ It looks exactly like f(6)'... Since $\frac{262.144}{6^{3}}=1.21$ , that's the derivative wanted.
A huge thanks to the people that helped me understand it here.","['limits', 'calculus', 'derivatives']"
4241227,"Meaning of ""holes"" counted by homology groups","In a lot of more or less informal introductions to simplicial homology
often the groups $H_k(X)$ of a topological space or CW space
are introduced as groups which ""counting $k$ -dimensional holes"". I know that
is of course motivated by rather elementary examples but nevertheless
even if we discuss simple examples like sphere or torus it is
not clear to me what is preciesely meant by a "" $k$ -dimensional hole"". Can it be clarified? Note, that it's only about intuition, I know that all this 'hole counting approach' of homology groups cannot be formally approached, but even from 'informal' point of view I see several problems which I would like to clarify. The two most common examples, the $2$ -sphere $S^2$ and
the torus $T= S^1 \times S^1$ are discussed here in Wikipedia :  these two examples carry exactly the two properties of this 'hole terminology' which I find rather misleading or maybe just misunderstand. The terminology of ""holes"" in case of $S^2$ looks to me intuitively rather acceptable up to the dimension choice, see further.
We call the $0$ -holes the connected components. Since the sphere
is hollow, it is reasonable to say that is has a ""hole"". But why this ""hole"" of $S^2$ is called $2$ -dimensional hole?
Intuitively the hollow space inside of $S^2$ is $3$ -dimensional,
therefore I not understand what is the logic behind the name
"" $2$ -hole"" here. Similary it is said that the circle $S^1$ has a $1$ -dimensional hole.
But isn't this hole regarded from common sense $2$ -dimensional?
Essentially this ""hole"" is the removed inner of a $2$ -disc $D$ where $S^1 = \partial D$ . Can somebody clarify the 'logic' behind the
""dimension"" of the holes in this setting. Even more confusing is the notation of a hole for a torus $T$ . According to
the 'logic' above a $k$ -dimensional hole of a $k$ -simensional
""surface"" is the 'removed inner mass' which as observed in examples
before seemingly should be always contractible to a point. But in case of torus the $1$ -hole is not even contractible, since
it is homotopic to $S^1$ . That's confusing. Is it possible at least just for these two quite simple examples to precisely define what a $k$ -hole is?","['general-topology', 'homology-cohomology', 'algebraic-topology']"
4241253,"Cutting a polygon into 2 or 3 smaller, rationally-scaled copies of itself?","I've noticed that many 2D geometric figures can be tiled using four smaller copies of themselves. For example, here's how to subdivide a rectangle, equilateral triangle, and right triomino into four smaller copies: Each smaller figure here is scaled down by a factor of $\frac{1}{2}$ in width and height, dropping its area by a factor of four, which is why there are four smaller figures in each. You can also tile some 2D figures with nine smaller copies, each $\frac{1}{3}$ of the original size, or sixteen smaller copies, each $\frac{1}{4}$ of the original size, as shown here: By mixing and matching sizes, we can get other numbers of figures in the subdivisions. For example, here's a $2 \times 1$ rectangle subdivided into five rectangles of the same aspect ratio, an equilateral triangle subdivided into eleven equilateral triangles, and a right triomino tiled by thirty-eight right triominoes: $2 \times 1$ rectangle subdivided into five rectangles of the same aspect ratio, an equilateral triangle subdivided into eleven equilateral triangles, and a right triomino tiled by thirty-eight right triominoes"" /> I've been looking for a shape that can tile itself with exactly two or three smaller copies. I know this is possible if we allow the smaller copies to be scaled down by arbitrary amounts, but I haven't been able to find a shape that can tile itself with two or three copies of itself when those smaller copies are scaled down by rational amounts (e.g. by a factor of $\frac{1}{2}$ or $\frac{3}{5}$ ). My Question My question is the following: Is there a 2D polygon that can be tiled with two or three smaller copies of itself such that each smaller copy's dimensions are a rational multiple of the original size? If we drop the restriction about the smaller figures having their dimensions scaled by a rational multiple, we can do this pretty easily. For example, a rectangle of aspect ratio $\sqrt{2} : 1$ can tile itself with two smaller copies, and a rectangle of aspect ratio $\sqrt{3} : 1$ can tile itself with three smaller copies: $\sqrt{2}:1$ rectangle cut into two self-similar copies, and a $\sqrt{3}:1$ rectangle cut into three self-similar copies"" /> However, in these figures, the two smaller copies are scaled down by a factor of $\frac{\sqrt{2}}{2}$ and $\frac{\sqrt{3}}{3}$ , respectively, which aren't rational numbers. If we move away from classical polygons and allow for fractals, then we can do this with a Sierpinski triangle, which can be tiled by three smaller copies of itself. However, it's a fractal, not a polygon. What I've Tried If we scale down a 2D figure by a factor of $\frac{a}{b}$ , then its area drops to a $\frac{a^2}{b^2}$ fraction of its original area. This led me to explore writing $1$ as a sum of squares of rational numbers, such as $1 = \frac{4}{9} + \frac{4}{9} + \frac{1}{9}$ or $1 = \frac{9}{25} + \frac{16}{25}$ . This gives several possible values for how to scale down the smaller copies of the polygon, but doesn't give a strategy for choosing the shapes of the reduced-size polygon to get the smaller pieces to perfectly tile it. I've looked into other problems like squaring the square and other similar tiling problems. However, none of the figures I've found so far allow for a figure to be tiled with two or three copies of itself. I've also tried drawing a bunch of figures on paper and seeing what happens, but none of them are panning out. Is this even possible in the first place? Thanks!","['recreational-mathematics', 'geometry', 'tiling', 'rational-numbers']"
4241257,"Let $G$ be a finite solvable group, all of whose Sylow subgroups are abelian. Prove that $Z(G) \cap G' = 1$.","Let $G$ be a finite solvable group, all of whose Sylow subgroups are abelian. Prove that $Z(G) \cap G' = 1$ . Attempt: From the second isomorphism theorem $\frac{G'}{Z(G)\cap G'} \simeq \frac{G'Z(G)}{Z(G)}$ so it suffices to show that $\frac{G'Z(G)}{Z(G)} \simeq G'$ . I couldn't proceed any further though and I can't figure out how to use the fact that every Sylow subgroup is abelian. Any hint is appreciated. Thanks.","['finite-groups', 'abstract-algebra', 'sylow-theory', 'group-theory', 'solvable-groups']"
4241267,Soluition of Riccati equation,"Solution of Riccati equation: $y' -y + y^2 e^x + 5e^{-x} = 0 , y(0) = \pi $ My work: A Riccati equation of the form $y' + py + q y^2 = r $ can be transformed to second order ODE as follows. $u''+\left ( p - \dfrac{q'}{q} \right ) u' -rq u =0 $ Therefore, $p = -1 $ , $q = e^x $ , $r = -5 e^{-x}$ $u''+\left ( -1 - \dfrac{(e^{x})'}{e^x} \right ) u' + 5u =0 $ $u''+\left ( -1 -1 \right ) u' + 5u =0 $ $u''- 2u' + 5u =0 $ The auxillary equation is $ k^2 -2k +5  = 0 $ $k = \dfrac{2 \pm \sqrt{4-20}}{2}$ $k = 1 \pm 2 i$ Therefore, the solution is, $u(x) = e^{x} (C_1 \cos (2x) + C_2 \sin (2x))$ How to find the solution for y? Kindly advise.",['ordinary-differential-equations']
4241283,What is the value of the angle x in the given figure? (by geometry),"For reference: In the figure, AOB is a quadrant and the quadrilaterals OMNL and LTQK are square. My progress..I would like a solution by geometry...by trigonometry it is solved: $\triangle QOL: \frac{r}{\sin45}=\frac{r\sqrt2}{2\sin 2\theta} \implies \sin2\theta =\frac{1}{2} \therefore \theta = 15^\circ$",['geometry']
4241285,Does every reflection generating set of a RA Coxeter group contain a conjugate of every standard generator?,"I am interested in understanding generating sets of right-angle Coxeter groups (RACGs) consisting of reflections. More precisely, let $(W,S)$ be a finite rank RACG, and write $R=\{wsw^{-1}\mid s\in S\;\textrm{and}\;w\in W\}$ for the set of reflections in $W$ . Question: Suppose $X\subset R$ generates $W$ , then for each $s\in S$ is there $w\in W$ such that $wsw^{-1}\in X$ ? (Or indeed when is this the case for arbitrary Coxeter systems?) This property doesn't hold for all Coxeter systems, for example for $W\cong\textrm{Dih}_5$ , $\{s_1,s_2s_1s_2\}$ is a generating set, but in RACGs (or Even Coxeter groups more generally), distinct elements of $S$ are never conjugate so this kind of counter-example can't exist. I tried searching the literature but couldn't find anything about this, however it could be relevant to note that RACGs are rigid, meaning that all Coxeter systems for a fixed RACG $W$ have isomorphic Coxeter-Dynkin diagrams. I did try to use the method of Pallavi Dani and Ivan Levcovitz , constructing folding sequences of cube complexes to prove the answer the question is yes, but couldn't quite make it work. Maybe there's some simple argument to answer the question?","['reflection', 'group-theory', 'coxeter-groups']"
4241305,Proving the induced derivation of endomorphism equals trace on top exterior power,"Let $V$ be a finite-dimensional vector space over a field $K$ of dimension $r:= \dim_K(V)$ (let's say $K$ equals the real or complex numbers). If $\varphi: V\to V$ is an endomorphism, we know that $\varphi$ can be naturally extended to act as a derivation on $\bigwedge^k V $ for each $1\leq k\leq r$ by $\widetilde\varphi_k\colon \bigwedge^k V \to \bigwedge^k V  $ defined as $$ \widetilde\varphi_k(v_1\wedge\cdots\wedge v_k):=\sum_{j=1}^k v_1\wedge\cdots\wedge \varphi (v_j)\wedge\cdots\wedge v_k. $$ Now, I want a formal explanation/proof of why does this extension acts as just the scalar multiplication by the trace of $\varphi$ on the top exterior power $\bigwedge^r V \cong  K$ . Namely, I want to prove that $$(*)\qquad\qquad\widetilde\varphi_r(v_1\wedge\cdots\wedge v_r)=\mathrm{tr}(\varphi)v_1\wedge\cdots\wedge v_r  .$$ This has appeared in my path in the context of differential geometry. Namely, if $E$ is a vector bundle of rank $r$ with connection $\nabla$ and curvature form $\Omega$ , then it is asserted or implicitely used in several places that the curvature form of the determinant line bundle $\det E:=\bigwedge^r E$ is given by $\widetilde\Omega=\mathrm{tr}(\Omega)$ with respect to the natural connection $\widetilde\nabla$ on $\bigwedge^r E$ , namely, the extension of $\nabla$ as a derivation: $\widetilde\nabla(\xi_1\wedge\cdots\wedge \xi_r):=\sum\limits_{j=1}^r \xi_1\wedge\cdots\wedge \nabla \xi_j\wedge\cdots\wedge \xi_r$ .
By what we said above, this just amounts to a multilinear algebra problem, that is, $(*)$ . It is also worth noting that the identity $(*)$ is a sister identity of the more well-known identity $$\bigwedge\nolimits^r \varphi(v_1\wedge\cdots\wedge v_r):= \varphi(v_1)\wedge\cdots\wedge\varphi(v_r)=\det(\varphi)v_1\wedge\cdots\wedge v_r,$$ and that give us a nice overpowered definition of both the determinant and the trace. Any hint or proof is appreciated.","['connections', 'trace', 'reference-request', 'multilinear-algebra', 'differential-geometry']"
4241311,Solving the recurrence $a_{k+2} = \frac {k - 4}{(k+1)(k+2)}a_k$?,"I am solving the ODE $y'' - xy' + 4y = 0$ via power series, which leads me to the following recurrence: $$a_{k+2} = \frac {k - 4}{(k+1)(k+2)}a_k \tag{1}$$ where $k \ge 1$ and $a_0, a_1$ are given. I would like to ask a question about one of the steps in my solution ( $\color{red}{\text{in red below}}$ ), and whether there is a better solution. My Solution: With $k = 2$ we see that $a_4 = 0$ , and as a result $a_n = 0$ for all even $n \ge 4$ . So we concentrate on $a_n$ with $n$ odd. Define $b_k = a_{2k + 1}$ for $k \ge 0$ . Letting $k = 2k-1$ in $(1)$ , $$b_k = \frac {2k - 5}{2k(2k+1)}b_{k-1}.$$ Now $$
\begin{align*}
b_k &=  \frac {2k - 5}{2k(2k+1)}b_{k-1} \\
&= \frac {2k - 5}{2k(2k+1)} \cdot \frac {2k - 7}{2(k-1)(2k-1)}b_{k-2}\\
 & \ \ \vdots\\
&= \frac {2k - 5}{2k(2k+1)} \cdot \frac {2k - 7}{2(k-1)(2k-1)} \cdots \frac {-3}{2(1)(1)}b_0
\end{align*}.
$$ $\color{red}{\text{(trouble above)}}$ After cancelling, we have $$b_k = \frac {3}{2^k \cdot k! \cdot (2k+1)(2k-1)(2k-3)}b_0$$ and we are essentially done. Trouble: I am worried about the part where I used the vertical dots. I always have difficulty with figuring out what the final coefficient is once we get to $b_0$ . This is how I currently think about it: Consider $b_k =  \frac {2k - 5}{2k(2k+1)}b_{k-1}$ . To get to $b_0$ on the RHS, we must subtract $1$ a total number of $k-1$ times. Every time we subtract a $1$ , we subtract a $2$ from the $(2k-5)$ term, so the (numerator of the) final term should be $2k-5 - 2(k-1) = -3$ . Similarly for the $(2k)$ and $(2k+1)$ terms in the denominator. In which way do you figure out the last term? (I think my way is not the best)","['discrete-mathematics', 'recurrence-relations', 'ordinary-differential-equations']"
4241319,Can all mathematical proof be represented visually? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question Can all mathematical proof and all mathematical be represented visually? When defining visually I mean ""could potentially be expressed visually"", such as graphically or geometrically so the layman could still potentially understand the proof. I arrived at this idea when this video on topology which was understandable to me: a high school student that has not studied topology. Obviously there could be some problems when extending to higher dimensions but nonetheless we can represent higher dimensional objects on a piece of paper. As I research higher problems and topics in calculus and analysis I feel detached from visual proofs as there seems to be no visual intuition grounding my problems, such as one I was working on  yesterday. $$\int \arcsin(x) \ln(x) dx$$ However this problem can still be grounded in visual intuition if you graph it and understand Riemann sums visually. I feel as if most students, when studying maths, rely on ""seeing the problem"". Does this way of problem solving fade when studying higher maths? So could all problems and proofs be represented visually or can some proofs only be expressed and understood through definitions? Is there a universal visualisation?","['proof-explanation', 'geometry', 'proof-without-words', 'calculus', 'general-topology']"
4241332,Triangle angle bisector problem: Finding area,"I need help on a geometry challenge from Instagram user gercekboss that really stumps me. I know some relevant theorems, such as the angle bisector theorem, but I just can't for the life of me figure out how to apply them. Can anyone give any help?
Thank you",['geometry']
4241341,Visualize why the group of isometries of the sphere $S^2$ is $S^3/(\mathbf{Z}/2) ?$,"How to visualize
why the group of rotational symmetries (orientation preserving isometries) of the sphere $S^2$ is $$S^3/(\mathbf{Z}/2) ?$$ I meant that because that the rotational symmetry group is $SO(3)=RP^3=S^3/(\mathbf{Z}/2) $ . I know this fact, but how to convince ourselves that by visualization that there is a $\mathbf{Z}/2$ mod out? It may be useful to use the fibration fact that the $S^3/(\mathbf{Z}/2)$ can be a lens space obtained by $S^1$ fiber over $S^2$ ? But how is that relevant to the isometry group of the sphere $S^2$ ? p.s. I certainly know $𝑆𝑂(3)=𝑅𝑃^3=𝑆^3/(𝐙/2)$ . My point here is how to visualize the rotational group has a quotient out $(𝐙/2)$ part in $𝑆^3/(𝐙/2)$ for the rotational group? Which path of the loop of the rotational group element gives that $\pi_1(𝑆^3/(𝐙/2))=(𝐙/2)$ ?","['differential-topology', 'group-theory', 'isometry', 'lie-groups', 'differential-geometry']"
4241343,Solving an analytic geometry problem with euclidean geometry,"$\mathrm{OABC}$ is a tetrahedron with $\overline{\mathrm{OA}}=1$ . There is a point $P$ on $\triangle \mathrm{ABC}$ such that $\cos^2 \alpha+\cos^2 \beta + \cos^2 \gamma = \frac{11}{6}$ where $\alpha=\angle\mathrm{AOP}$ , $\beta=\angle\mathrm{BOP}$ and $\gamma=\angle\mathrm{COP}$ . Describe the trace of such $P$ . We can solve this problem by using the following lemma: Let's imagine the tetrahedron with four vertices $O(0,0,0)$ , $A(a,b,c)$ , $B(b,c,a)$ and $C(c,a,b)$ . Since $\overline{\mathrm{OA}}=\overline{\mathrm{OB}}=\overline{\mathrm{OC}}=\overline{\mathrm{AB}}=\overline{\mathrm{BC}}=\overline{\mathrm{CA}}$ , we have $a^2+b^2+c^2=(a-b)^2+(b-c)^2+(c-a)^2\Rightarrow a^2+b^2+c^2=2(ab+bc+ca)$ . And since $\vec{\mathrm{OA}}=(a,b,c)$ , $\vec{\mathrm{OP}}=(x,y,z)$ , we have $\cos^2 \alpha=\left(\frac{\vec{\mathrm{OA}} \cdot \vec{\mathrm{OP}}}{\vert \vec{\mathrm{OA}} \vert \vert\vec{\mathrm{OP}}\vert}\right)^2=\frac{(ax+by+cz)^2}{(a^2+b^2+c^2)(x^2+y^2+z^2)}$ . WLOG $\cos^2 \beta=\frac{(bx+cy+az)^2}{(a^2+b^2+c^2)(x^2+y^2+z^2)}$ , $\cos^2 \gamma=\frac{(cx+ay+bz)^2}{(a^2+b^2+c^2)(x^2+y^2+z^2)}$ . Then by the given equation, $\frac{(ax+by+cz)^2+(bx+cy+az)^2+(cx+ay+bz)^2}{(a^2+b^2+c^2)(x^2+y^2+z^2)}=1+\frac{2(ab+bc+ca)(xy+yz+zx)}{(a^2+b^2+c^2)(x^2+y^2+z^2)}=\frac{11}{6}$ . By substituting $a^2+b^2+c^2=2(ab+bc+ca)$ , we obtain $5(x^2+y^2+z^2)=6(xy+yz+zx)$ . Now, observe that $P$ is on the plane $x+y+z=a+b+c$ . So $2(xy+yz+zx)=(x+y+z)^2-(x^2+y^2+z^2)=(a+b+c)^2-(x^2+y^2+z^2)$ and $8(x^2+y^2+z^2)=3(a+b+c)^2$ . As a conclusion, the trace of $P$ is a circle which is an intersection between the sphere $x^2+y^2+z^2=\frac{3}{8}(a+b+c)^2$ and the plane $x+y+z=a+b+c$ . I think it is a quite simple and nice solution, but I do not want to use such analytic methods. I tried many times to solve this only with euclidean geometry, but I could not find a better strategy. Would you help me?","['euclidean-geometry', 'analytic-geometry', 'geometry']"
4241346,Spivak Chapter $2$ Problem $22$ Clarification,"From Spivak's calculus 3rd edition: The result in Problem 1-7 has an important generalization: If $a_1,...,a_n \geq 0$ , then the ""arithmetic mean"" $$A_n = \frac{a_1+...+a_n}{n}$$ and ""geometric mean"" $$G_n = \sqrt[n]{a_1...a_n}$$ satisy $$G_n \leq A_n$$ (a) Suppose that $a_1 < A_n$ Then some $a_i$ satisfies $a_i>A_n$ ; for convenience, say $a_2>A_n$ . Let $\bar{a_1} = A_n$ and let $\bar{a_2} = a_1 + a_2 - \bar{a_1}$ . Show that $$\bar{a_1}\bar{a_2} \geq a_1a_2$$ Why does repeating this process enough times eventually prove that $G_n \leq A_n$ ? I've got the first part but I'm struggling to understand the ""repeating process"" aspect of the proof. From what i understand it comes from each iteration of the process increasing $G_n$ but keeping $A_n$ constant but i don't get how exactly the process is repeated. For example,
Given a set of values $\{a_1, a_2\}$ , if $$a_1 < A_2 < a_2$$ $$\bar{a_1}=A_2\\ \bar{a_2}=a_1+a_2-\bar{a_1}$$ then a new set $\{\bar{a_1}, \bar{a_2}\}$ can be created where $\bar{A_2} = A_2$ and $\bar{G_n} \geq G_n$ How would you repeat the process for $\{\bar{a_1}, \bar{a_2}\}$ ?","['calculus', 'a.m.-g.m.-inequality', 'inequality']"
4241353,Ricci flow that expands the negative curvature part of the manifold and contracts the positive curvature part?,"Hamilton's program for proving the Poincaré conjecture involves first putting a Riemannian metric on the unknown simply connected closed 3-manifold. The basic idea is to try to ""improve"" this metric; for example, if the metric can be improved enough so that it has constant positive curvature, then according to classical results in Riemannian geometry, it must be the 3-sphere. Hamilton prescribed the ""Ricci flow equations"" for improving the metric; $$\partial {t}g_{ij}=-2R_{ij} $$ where g is the metric and R its Ricci curvature, and one hopes that as the time t increases the manifold becomes easier to understand. Then I read from Wikipedia said: Ricci flow expands the negative curvature part of the manifold and contracts the positive curvature part. Why contracts the positive curvature part? If we want to flow to 3-sphere, should not we consider to use the Ricci flow that contracts the negative curvature part and expands the positive curvature part? here is the link of the quoted text https://en.wikipedia.org/wiki/Poincaré_conjecture#Ricci_flow_with_surgery","['riemannian-geometry', 'curvature', 'geometric-topology', 'differential-topology', 'differential-geometry']"
4241354,Find limit $\lim_{n \to \infty} \sum_{k=1}^{n} \frac{k^4}{k^5+n^5}$.,"Find the following limit: $$\lim_{n \to \infty} \sum_{k=1}^{n} \frac{k^4}{k^5+n^5}$$ I had an idea of using upper Riemann sum for function $x^4$ on interval $[0,1]$ but I don't know how to deal with $k^5$ in denominator which ruins my approach. Kindly asking for some help.","['integration', 'summation', 'riemann-sum', 'calculus', 'limits']"
4241357,An example of high dimension (financial) integrals?,"Introduction This question mainly arises out of the context of [Quasi Monte Carlo integration][1]. Which uses ""quasi-random"" numbers, (i.e. deterministic) with low discrepancy to reduce the variance in Monte Carlo integration. This reduction in variance is more prevalent in higher dimensions. And has thus found use in financial mathematics where they require numerical solutions to very high dimension integrals (>10^2). Question I have been unable to find any explicit examples of these very high dimension integrals anywhere online. Many articles reference these to arise from financial mathematics but are quite vague about its precise origins. I would like to know how I could construct a integral of this manner and what its implications would be? Unfortunately I am very clueless on what goes on in financial mathematics. Even better would be if anyone knows of an explicitly stated example of such a higher dimensional integral, but that seems unlikely. My main purpose is really more of a showcase of Quasi Monte Carlo, but at the same time I want to avoid simply constructing an elementary integral like: $$\int_{\Omega^d} \cos(x)^d\,dx$$ Thanks for any and all help!","['integration', 'numerical-methods', 'monte-carlo', 'finance']"
4241366,Validating a Character Table for a Given Finite Group,"Suppose we have some finite group $G$ , and we have computed the first few rows and columns of the table. I was wondering how one would verify that one have computed the correct character table of a given group (up to some permutation of the rows and columns of the entries). Presumably even after all the orthogonality conditions, a priori there might be multiple ways to complete the character table, at least without looking at the group/representations themselves. From my understanding, it seems that in textbooks, one would exhibit the representation to a given character. In general how does one 'check' if one has the correct character table of a given group? Are there any way to avoid exhibiting these irreducible representations? Daniel Robert-Nicoud gave an answer here mentioning Burnside's Algorithm, so in principle one could execute the algorithm on the given group $G$ and check if it matches your table but I don't think people would do this in real life, using pen and paper. I've looked around for answer and it seems that most question are either about constructing a group from a given character table, or questions about how to compute a character table of a particular group. This is my first question on the site so I apologize if this question was asked previously.","['representation-theory', 'group-theory', 'finite-groups', 'characters']"
4241382,How slowly can a series grow to be convergent?,"This may be a poorly worded question, but I hope to flesh out my ideas well. The takeaway here is this: some series diverge to infinity while others converge to a fixed value. Take the two classical examples: the harmonic series and the Basel Problem $$\displaystyle\sum_{n=1}^\infty \frac{1}{n}= \infty \, , \hspace{0.6cm} \displaystyle\sum_{n=1}^\infty\frac{1}{n^2} = \frac{\pi^2}{6}$$ On one end, we have a divergent series, whereas on the other end, we have a convergent series, both series of which seem eerily similar, except for the square in the latter. A question I might raise would be: at what ""rate of growth"" (loosely speaking) does a series have to grow to tip over from the point of convergence to sudden, chaotic divergence? Yes, in Calculus, you learn about various convergence tests that allow one to test whether a given series is convergent, but I am wondering if there is a famous ""rate of growth"" that a series must ""exceed"" in order to indisputably diverge.","['convergence-divergence', 'sequences-and-series']"
4241404,If $f_n \rightrightarrows f$ and every $f_n$ has antiderivative is that true that $f$ has antiderivative?,"There is a sequence of functions $f_n$ and each of these functions has antiderivative. If they are uniformly convergent to $f$ is that true that $f$ has antiderivative? I know that is true in case of continuity and that every continuous function has antiderivative but on the other hand, I know that there are functions that are not continuous but have antiderivatives.","['integration', 'uniform-convergence', 'analysis', 'real-analysis']"
4241419,Laplace's equation in the first quadrant,"I am trying to find a non-constant harmonic function $\phi$ on $Q = \{z \mid \mathfrak{R}(z), \mathfrak{I}(z) > 0\}$ , (i.e. the first quadrant) such that $\phi$ extends continuously to $\overline{Q} \setminus \{0\}$ with constant values on each the components of $\partial Q - \{0\}$ ( $\phi$ need not be continuous at the origin). My method for doing this is to solve Laplace's equation in the strip $S = \{0 < \mathfrak{I}(z) < 1\}$ subject to appropriate boundary conditions, then carrying the solution forward under the conformal map $f(z) = e^{\pi z/2}$ which is a conformal equivalence between $S$ and $Q$ (I'm doing it this way because in an earlier part of the problem they ask us to find $f$ ). Solving $\Delta u = 0$ on $S$ in general seems straightforward enough. Assume $u(x,y) = \alpha(x)\beta(y)$ then we get $\alpha''(x) = \lambda \alpha(x)$ and $\beta''(y) = -\lambda \beta(y)$ by simple algebra. This gives $\alpha(x) = Ae^{\sqrt \lambda x} + Be^{-\sqrt \lambda x}$ and $\beta(y) = Ce^{-\sqrt \lambda y} + De^{-i\sqrt \lambda y}$ . Then we allow $u$ in general to be any linear combination of these solutions. My issue here is that I'm not sure how to carry the boundary conditions in $Q$ to boundary conditions on $S$ . Intuitively it seems that it should just that $u$ must be constant on $\mathfrak{I}(z) = 0$ and $\mathfrak{I}(z) = 1$ , but this forces $\alpha(x) = 0$ which gives $u = 0$ , clearly not the desired result.My question is, how can I carry the boundary conditions over carefully (in general or in this case - I can probably figure out the general case if someone can work out this example)?","['complex-analysis', 'laplacian', 'harmonic-functions']"
4241484,"Let $f(x)=ax^3+bx^2+cx+5$. If $|f(x)|\le|e^x-e^2|$ for all $x\ge0$ and if the maximum value of $|12a+4b+c|$ is $m$, then find $[m]$","Let $f(x)=ax^3+bx^2+cx+5$ . If $|f(x)|\le|e^x-e^2|$ for all $x\ge0$ and if the maximum value of $|12a+4b+c|$ is $m$ , then find $[m]$ (where $[.]$ represents the greatest integer function.) I first thought $|f(x)|\le|e^x-e^2|$ represents the boundedness of $f(x)$ but then realized a cubic function is unbounded. Also, the RHS of the inequality is not constant. On observing $|12a+4b+c|$ , I figured it is $f'(2)$ . I don't think we can find its maximum value by finding the critical points of $f''(x)=0$ because that would give the extremum of $f'(x)$ , not $f'(2)$ . If $|f(x)|\le|e^x-e^2|$ , can we say anything about $f'(x)$ ?","['calculus', 'functional-inequalities', 'derivatives']"
4241535,Can you define and elementary $f(x)$ such that $2^{x}<f(f(f(x)))<2^{2^x}$?,Can you define a elementary real-valued function $f$ such that $2^{x} < f(f(f(x))) < 2^{2^x}$ for sufficiently large $x\in \mathbb{R}$ ? I know that there is no elementary function $f$ such that. $f(f(x))=2^{x}$ but is it possible to find an elementary function such that $2^{x}<f(f(f(x)))<2^{2^x}$ for sufficiently large $x\in \mathbb{R}$ ?,"['elementary-functions', 'functions', 'exponential-function', 'problem-solving']"
4241539,min $k$ s.t. $|z_1+z_2+\cdots+z_n|\geq \frac{1}{k}(|z_1|+|z_2|+\cdots+|z_n|).$,"Find the smallest positive real number $k$ such that, given any finite set $z_1,\cdots, z_n$ of complex numbers, all with strictly positive real and imaginary parts, the following inequality holds: $$|z_1+z_2+\cdots+z_n|\geq \frac{1}{k}(|z_1|+|z_2|+\cdots+|z_n|).$$ Answer- $\sqrt{2}$ My Attempt: First, we take $n=2$ . Let $z_i=r_ie^{i\theta_i}$ for $i=1, 2$ . Then $$|z_1+z_2|^2=|r_1e^{i\theta_1}+r_2e^{i\theta_2}|^2=
r_1^2+r_2^2+r_1r_2e^{i(\theta_1-\theta_2)}+r_1r_2e^{i(\theta_2-\theta_1)}.$$ Also $|z_1|+|z_2|=r_1+r_2.$ Therefore, the given inequality holds if $$r_1^2+r_2^2+r_1r_2e^{i(\theta_1-\theta_2)}+r_1r_2e^{i(\theta_2-\theta_1)}\geq \frac{1}{k^2}(r_1+r_2)^2$$ $$\implies (k^2-1)(r_1^2+r_2^2)+r_1r_2(k^2 e^{i(\theta_1-\theta_2)}+k^2e^{i(\theta_2-\theta_1)}-2)\geq 0.$$ which holds if $$k^2(e^{i(\theta_1-\theta_2)}+e^{i(\theta_2-\theta_1)})\geq 2$$ I struck at this point. Please help.","['complex-analysis', 'inequality']"
4241553,Generalisation of Thales's Theorem,"Show that, for a circle $\bigcirc$ with given dimensions, any arc subtends the same angle at every point on $\bigcirc$ . I arrived at this problem while working on projective transformations in $\mathbb{CP}^1$ . Being unfamiliar with the Inscribed Angle theorem, I was trying to generalise Thales's theorem. Posting here for verification. The diagram below shows Thales's theorem $$\tag{1} 2\color{red}{\phi}+2\color{green}{\gamma}=\pi \implies \angle BDC=\frac{\pi}{2}.$$ In order to generalise Thales, consider any segment $FG \parallel BC$ on $\bigcirc$ . Since $\triangle FAD$ is isosceles $$ \tag{2} 2(\color{red}{\phi} + \color{purple}{\delta})+2\color{green}{\gamma} - \color{purple}{\psi}=\pi.$$ Appealing to $(1)$ $$\tag{3} 2\color{purple}{\delta} =\color{purple}{\psi}.$$ The same argument, applied to $\triangle ADG$ shows $$\tag{4} \angle CDG = \color{purple}\delta.$$ In general, any arc $FG$ on $\bigcirc$ subtends the same angle $\theta$ , where $$\tag{5}\theta = \frac{\pi}{2} \pm\color{purple}\psi$$ depending on whether $D$ lies above or below the segment $FG$ in the above diagram. Note : Some care has to be taken when considering points $D$ between $BC$ and $FG$ , as in the following: In this case, inspection of $\triangle FAD$ shows $(3)$ still holds and inspection of $\triangle ADG$ shows $$\tag{6} 2(\color{red}{\phi}+\color{purple}\delta+\angle FDG ) +\color{purple}\psi-2\color{red}{\phi}=\pi$$ from which the result follows.","['alternative-proof', 'euclidean-geometry', 'solution-verification', 'geometry']"
4241557,Non-abelian simple groups of odd order less than $10000$.,"I am trying to solve problem 6.2.16 from Dummit and Foote, namely Prove there are no non-abelian simple groups of odd order $< 10000$ . I did something similar for order $<100$ , where I showed the only non-abelian simple group of order $< 100$ is $A_5$ , but this was done by looking at many different forms of order in terms of prime arrangements and picking a few special cases aside to rule everything out but order $60$ . The order is too big to do this here. The only thought I have is that $10000=100^2$ and so taking $G$ to be a minimal counterexample with $|G|>100$ we can write $|G|=ab$ with $a<100, b\geq 100$ . Apart from that not much that I feel could be constructive. Any help would be appreciated for getting to an elegant proof that doesn't grind through every prime arrangement.","['simple-groups', 'group-theory', 'abstract-algebra', 'finite-groups']"
4241577,Show that $4(u^2+v^2)\left(\left(\frac{\partial z}{\partial x} \right)^2+\left(\frac{\partial z}{\partial y} \right)^2\right)$,"Let $x = u^2-v^2$ and $y = 2uv$ , and suppose that $z = f(x,y)$ is differentiable. Show that: $$ \left(\frac{\partial z}{\partial u}\right) ^2+\left(\frac{\partial z}{\partial v}
\right)^2 =  4(u^2+v^2)\left(\left(\frac{\partial z}{\partial x} \right)^2+\left(\frac{\partial z}{\partial y} \right)^2\right)$$ By taking the derivative in respect to $u$ and $v$ then taking their composite values: $\frac{d}{dx}=2u-2v; \frac{d}{dy} = 2v+2u$ Which are equivalent to: $2(u-v)2(u+v)=4(u^2-v^2)$ However the signs are different as I'm expected to get a positive between $u$ and $v$ .",['multivariable-calculus']
4241606,Find the values $a>0$ for which this improper integral converges,"Find the values of $a > 0$ for which the improper integral $$\int_{0}^{\infty} \frac{\sin x} {x^a} dx$$ converges. This question is from my analysis quiz (now over). I have studied improper integrals but Dirichlet test, Comparison tests and other results can't be used in this case as Dirichlet test is used if $\sin x$ used to tend to $\infty$ , also 2 comparison tests are not suited for two functions inside the integral. If I use Abel test and write $$\int_{0}^{\infty} \frac{\sin x} {x^a} dx = \int_{0}^{a} \frac{\sin x} {x^a} dx + \int_{a}^{\infty} \frac{\sin x} {x^a} dx$$ then $\int_{a}^{\infty} \frac{\sin x} {x^a} dx$ converges at infinity for $a<1$ but $\sin x$ is not bounded and monotonic in $(a, \infty)$ . So, it can't be used as well. So, what result should I use. (I have done a course on real analysis.)","['integration', 'improper-integrals', 'real-analysis']"
4241607,Does the area under the graph being lebesgue measurable imply the function is measurable?,"The opposite implication is true, but i don't know about this side. I've considered intersecting the area under the graph of the function with subsets of the form $\mathbb{R} \times (a,\infty)$ . This intersection has to be measurable, but it doesn't seem to follow that the x-coordinates of this set are also measurable (in $\mathbb{R}$ ). For example, the set $\mathcal{V} \times \{ 0 \}$ , where $\mathcal{V}$ is a vitali set, is measurable on $\mathbb{R}^2$ , but it's x-coordinates are not measurable on $\mathbb{R}$ .","['measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
4241617,Clarification on convergence in distribution $\implies$ convergence in probability requiring a constant probability space,"Let $X_n,n\geq1$ be a sequence of random variables defined on the same probability
space. Show that if $X_n \to c$ in distribution, where $c$ is a constant, then also $X_n \to c$ in probability. I am attempting to formulate an efficient proof for this claim, which I have done as follows: Letting $F_n$ denote the distribution function for $X_n$ , and $F$ is that of $c$ , i.e. $$F(x)=\begin{cases}
0\;\;x\lt c\\
1\;\;x\geq c
\end{cases}$$ we have that $F_n(x)\to F(x)$ for all $x\in\mathbb{R}\setminus\{c\}$ . Choose $\epsilon\gt 0$ . Then $$\begin{align}\mathbb{P}(\lvert X_n-c\rvert\lt\epsilon)=\mathbb{P}(\{X_n\lt c+\epsilon\}\setminus\{X_n\leq c-\epsilon\})\\
=\mathbb{P}(X_n\lt c+\epsilon)-\mathbb{P}(X_n\leq c-\epsilon)\\
=F_n(c+\epsilon)-F_n(c-\epsilon)\\
\to1-0=1.
\end{align}$$ Note $\epsilon$ arbitrary so the result follows. My question is what is what is the precise reason / justification for the variables to be on the same probability space? At which step would this need to be used?","['proof-writing', 'probability-distributions', 'convergence-divergence', 'probability-theory', 'probability']"
