question_id,title,body,tags
4262700,A comprehensive book on graduate real analysis,"I'm looking for a comprehensive book/a comprehensive list of books on graduate analysis that covers/cover these topics: Lebesgue measure and integration on $\mathbb{R}^d$ , the relationships between integrability and differentiability (it must also cover the theory of functions of bounded variation), complex analysis and fourier analysis.","['integration', 'real-numbers', 'fourier-analysis', 'real-analysis', 'complex-analysis']"
4262726,Reference Request: Full mathematical treatment of Schrödinger evolution of hydrogen atom,"This is to request a reference on the above problem. I have checked various references in the mathematical physics literature and could not really find a clear, satisfactory answer to some questions, or at least I was unable to extract them myself. In particular, I would like to know the following: It is known among mathematical physicists that most problems in quantum mechanics cannot be fully dealt with by just looking at a particular (separable) Hilbert space and are more appropriately dealt with in terms of a Gelfand triple (one reason being that $L^2$ functions are not differentiable). I suspect that in the above problem a ""natural choice"" for that triple is $$\mathcal{S}(\mathbb{R}^3,\mathbb{C}) \subset L^2(\mathbb{R}^3,\mathbb{C}) \hookrightarrow \left( \mathcal{S}(\mathbb{R}^3,\mathbb{C}) \right)^* \, ,$$ where on the left we have the space of complex-valued Schwartz functions in $\mathbb{R}^3$ , in the center we have the respective space of square-integrable functions, and on the right the respective tempered distributions. I base that suspicion on the fact that the common stationary states $\Psi_{n l m}$ are elements of $\mathcal{S}(\mathbb{R}^3,\mathbb{C})$ . Is what is usually assumed in most physics textbooks mathematically correct, namely that any $\Phi \in L^2(\mathbb{R}^3,\mathbb{C}) $ admits a series representation of the form $$\Phi = \sum_{n, l, m} a_{n l m} \, \Psi_{n l m} \, ?$$ If so, then the time evolution is well-defined in that problem for any such $\Phi$ . This concerns the so-called scattering states: If one solves the time-independent Schrödinger equation for the above problem one may ask for stationary states of positive energy. Formal solutions can be found, for instance, in Takhtajan's book ""Quantum Mechanics for Mathematicians"". After reflecting on this question a bit, I guess the fact that those are not square-integrable means that there are no such states --- which makes physical sense, since the only way one should get a stationary state here is if the particle is somehow ""trapped"" by the nucleus. However, for the free particle we can solve that equation and treat the resulting states as generalized eigenfunctions in the sense that we may define $$\Psi(x) = \frac{1}{\sqrt{2 \pi \hbar}^3} \int_{R^3} \operatorname{d}^3 p \, 
e^{\mathfrak{i}  p \cdot x / \hbar} \, \Phi(p) \, ,$$ which is, of course, just a Fourier transform. Since we can obtain $\Phi$ for given $\Psi \in L^2(\mathbb{R}^3,\mathbb{C})$ via inverse Fourier transform, the time evolution of $\Psi$ is just given by $$\Psi(t,x) = \frac{1}{\sqrt{2 \pi \hbar}^3} \int_{R^3} \operatorname{d}^3 p \, 
e^{\mathfrak{i}  \left( p \cdot x- \omega(p) t \right) / \hbar} \, \Phi(p) \, ,$$ where $\omega(p)=p^2/2m \hbar$ . Does a similar procedure work for the hydrogen atom? EDIT: The above framing of the problem is a slight bit off. As can be found it any textbook, the ground state wave function is proportional to $e^{-|x|/a_0}$ with $a_0$ denoting the Bohr radius. Due to lack of differentiability at the origin, this function is not an element of $\mathcal{S}(\mathbb{R}^3,\mathbb{C})$ . The problem seems to be fixable, however, by using $\mathcal{S}(\mathbb{R}^3 \setminus \lbrace 0 \rbrace,\mathbb{C})$ instead.","['hilbert-spaces', 'functional-analysis', 'quantum-mechanics', 'partial-differential-equations']"
4262789,"Reading Rovelli's ""General Relativity"" - how to calculate a ""diad""?","So I'm reading Carlo Rovelli's ""General Relativity"" and there is this notion of ""diad field"" or ""frame field"" that I do not really get. According to Rovelli, given a differentiable manifold $\Sigma$ and a point $p$ on it, one can consider the tangent plane $T_p\Sigma$ and Cartesian coordinates $X^i$ on that plane.
Than one can define ""local Cartesian coordinates"" $X^i_p$ by orthogonally projecting the $X^i$ onto the manifold. Let also $x^j$ be general coordinates on $\Sigma$ (here I guess Rovelli means that the $x^j$ are coordinates in an open set of the same dimension of the manifold that are mapped to $\Sigma$ via some diffeomorphism $\varphi$ ). Then the frame field, or ""diad field"" is defined as follows: \begin{equation}
e^i_j :=\frac{\partial X^i_p(x^j_p)}{\partial x^j}
\end{equation} where $X^i_p$ maps the general coordinates to the local Cartesian coordinates and $x^j_p$ are the coordinates for the point $p$ . I have some problems understanding this definition, and also calculating the actual diad field in some easy cases- i.e. for the paraboloid $z=x^2+y^2$ at a specific point $p$ . Can somebody please explain this concept to me?","['general-relativity', 'tangent-spaces', 'differential-geometry']"
4262797,$C^{\infty}$ reconciliation of two functions,"Let $\Omega$ be an open subset of $\mathbb{R}^d$ , $K$ a compact subset of $\Omega$ and $\phi \in C^\infty(\Omega)$ . Given $\epsilon > 0$ and denoting $K_\epsilon = \{ x \in K : d(x,K^c) \geq \epsilon \}$ , is it possible to find $\psi \in C^\infty(\Omega)$ such that $\psi = \phi$ on $K_\epsilon$ and $\psi = 0$ on $K^c$ ? I feel like there is some space between $K_\epsilon$ and $K^c$ so this is reasonable but I cannot see why it should be true.","['functions', 'distribution-theory', 'smooth-functions', 'real-analysis']"
4262816,Does $\int_{0}^{\infty} \sin^x(x) dx$ converge?,"From what I have found the indefinite integral does not have a closed form solution. Also, the function takes complex values except for in the intervals $[0,\pi],[2\pi,3\pi],$ (and for whole x between those intervals). But if we only considered those intervals where the function takes on real values, i.e. $$\int_{0}^{\pi}\sin^x(x)dx+\int_{2\pi}^{3\pi}\sin^x(x)dx+\int_{4\pi}^{5\pi}\sin^x(x)dx+{...}$$ Does this infinite sum converge? For the record I have no idea how to go about proving this, but I am curious if anyone does.","['limits', 'calculus', 'convergence-divergence', 'trigonometry']"
4262844,Nowhere vanishing harmonic 1-forms on 3-manifolds,"Consider $(S^1 \times \Sigma^2, g)$ , where $g$ is any Riemannian metric on the compact and closed $3$ -manifold $S^1 \times \Sigma^2$ . Question:
Does there always exist a nowhere vanishing harmonic $1$ -form on $S^1 \times \Sigma^2$ ?
If the answer to this question is No, how about the generalisation to $k$ -parameter families of metrics? So far I tried to find an example of a harmonic $1$ -form on $T^3=S^1 \times S^1 \times S^1$ that does have a zero but did not succeed. I have cross-posted this question to: https://mathoverflow.net/questions/407340/nowhere-vanishing-harmonic-1-forms-on-3-manifolds .","['hodge-theory', 'differential-geometry']"
4262862,Two equivalent definitions of the Cantor function,"I know two definitions of the Cantor function $c: [0,1] \to [0,1]$ . $$
c(x) = 
\begin{cases}
\sum_{n=1}^{\infty} \frac{a_{n}}{2^{n}}, \; x \in C\\
\sup_{y \leq x, \; y \in C} c(y), \; x \notin C
\end{cases}
$$ where $\{a_{n}\}$ is the ternary expansion of $x$ . I also know the recursive definition: $$
c(x) = \lim_{n \to \infty} c_{n}(x)
$$ where $$
c_{n+1}(x) = 
\begin{cases}
\frac{1}{2} c_{n}(3x), & x\in [0, \frac{1}{3}); \\
\frac{1}{2}, & x\in[\frac{1}{3}, \frac{2}{3}];\\
\frac{1}{2}(1 + c_{n}(3x-2)), & x\in (\frac{2}{3}, 1]. 
\end{cases}
$$ and $$
c_{0}(x) = x
$$ I have seen and understood the proof that the recursive definition converges uniformly to some continuous function. This function is the Cantor function of course, but I cannot see how this is. Is there some easy way to demonstrate that this recursive definition of the function is the equivalent the function above it?","['measure-theory', 'cantor-set', 'real-analysis']"
4262888,Set of atoms must be countable,"My task is to prove that if an atomic measure space is $\sigma$ -finite, then the set of atoms must be countable. This is my given definition of an atomic measure space: Assume $(X,\mathcal{M},\mu)$ is a measure space with all single points being measurable. An atom is a point $x$ with $\mu(\{x\}) > 0$ . Letting $\mathcal{A}$ be the set of atoms, $(X,\mathcal{M},\mu)$ is called atomic if $\mathcal{A}\in\mathcal{M}$ and $\mu(\mathcal{A^c}) = 0$ . I didn't know how to prove this at first, so I looked it up on stack exchange and found this answer : (I do not have enough reputation to comment on the original post) Here's how to prove your claim, with the appropriate assumption. Let $S\subset X$ be the set of atoms for some measure $\mu$ on $X$ . Let $\{U_i\}$ be a countable measurable partition of $X$ . Then if $S$ is
uncountable, some $U_i$ contains an uncountable subset $S'$ of $S$ ,
and $\mu(U_i)\geq \sum_{x\in S'}\mu(x)=\infty$ since any uncountable
sum of positive numbers diverges. Thus $\mu$ is not $\sigma$ -finite. My question is why do we have that $\mu(U_i) \geq \sum_{x\in S'} \mu(x)$ ? I am assuming that this inequality comes from subadditivity of $\mu$ but as I have understood it subadditivity is defined for countable unions, not for uncountable unions so I am confused as to how we arrive at an uncountable sum in this step.",['measure-theory']
4262892,Sectional curvature of a compact Lie Group,"I've been trying to proof this: In a compact lie group with bi-invariant metric $g$ , the sectional curvature holds the next equality. $K(\sigma)=\frac{1}{4}\|[X,Y]\|^2$ When I tried, I needed to use that $g([[X,Y],X],Y)=g([X,Y],[X,Y])$ but I couldn't prove it. Thank you","['lie-groups', 'riemannian-geometry', 'differential-geometry']"
4262999,"Determine the tangent planes of $x^2+z^2=1$ at the points $(x, 0, z)$ and show that they are all parallel to the $y-$axis.","Determine the tangent planes of $x^2+z^2=1$ at the points $(x, 0, z)$ and show that they are all parallel to the $y-$ axis. Attempt: Let $f(x, y, z)=x^2+z^2-1$ . Then we have that $$\nabla f(x, y, z)=(2x, 0, 2z)$$ Now, the normal vector of the tangential plane at point $(x, 0, z)$ is $$\nabla f(x, 0, z)=(2x, 0, 2z)=2(x, 0, z)$$ Since $$(x, 0, z)\cdot (0,1,0)=0$$ it follows that the vector $2(x, 0, y)$ is perpendicular to the plane $y-$ axis, which implies that the tangential plane is parallel to it.","['multivariable-calculus', 'tangent-spaces', 'differential-geometry']"
4263016,Taylor series for a complex function $f(z) = \frac{1}{z^2 - 1}$ center at z=2,"I was trying to find the taylor serie for $f(z) = \frac{1}{z^2 - 1}$ center at z=2 using $$f(x)=\sum_{k=0}^\infty f^{(k)}(a)\frac{(x-a)^k}{k!}$$ However, it seems really hard. I didn't find the ""series"" for $f,f',f'',f'''...$ I found that I can use the geometric series. I read that $$f(z) = \frac{1}{1-x} = \sum_{k=0}^\infty x^k$$ I know that $$f(z) = \frac{1}{z^2 - 1} = f(z) = \frac{1}{(z - 1)(z + 1)}$$ Thus, is it correct to say that $$\frac{1}{(z - 1)(z + 1)}  = \frac{1}{(z+1)} \cdot \sum_{k=0}^\infty z^k = \sum_{k=0}^\infty z^k \cdot\frac{1}{(z+1)}$$ Any help for for the rest will be appreciate. Edit: I just saw that my function is $\frac{1}{z-1}$ and not $\frac{1}{-z + 1}$ , so probably all I did is wrong.","['complex-analysis', 'taylor-expansion']"
4263032,"How to Prove $\lim_{(x, y) \rightarrow (0, 0)}\frac{x^3-y^3}{x^2+y^2}=0$ [duplicate]","This question already has answers here : Evaluating $\lim\limits_{(x,y) \rightarrow (0,0)} \frac{x^3 - y^3}{x^2 + y^2}$ (2 answers) Closed 2 years ago . I wanted to prove how $$
\lim_{(x, y) \to (0, 0)} \frac{x^3-y^3}{x^2+y^2} = 0.
$$ Specifically, I want to use the Squeeze Theorem for multivariable calculus. Then I know that I should pick an arbitrary function $g(x, y)$ where $|f(x, y)-L| \leq g(x, y)$ and the limit of $g(x, y)$ is $0$ . Since the limit of $f(x, y) =0$ , I just have to make $$
\Biggl\lvert \frac{x^3-y^3}{x^2+y^2} \Biggr\rvert \leq g(x, y),
$$ where the limit of $g(x,y)=0$ . I was given a hint that $|x^3-y^3| \leq |x|^3+|y|^3$ . So I divided both sides by $|x^2+y^2|$ , $$
\frac{\bigl\lvert x^3-y^3 \bigr\rvert}{\bigl\lvert x^2+y^2 \bigr\rvert} 
\leq \frac{\lvert x\rvert^3+ \lvert y\rvert^3}{\bigl\lvert x^2+y^2 \bigr\rvert},
$$ meaning that $$
\frac{\bigl\lvert x^3-y^3 \bigr\rvert}{\bigl\lvert x^2+y^2 \bigr\rvert}  
\leq \lvert x\rvert + \lvert y\rvert. 
$$ What do I do next?","['multivariable-calculus', 'limits', 'calculus', 'triangle-inequality']"
4263038,Is a multivariable function with coplanar tangent lines always differentiable?,"It's easy to find a function $f(x,y)$ whose directional derivatives are all zero at a point but which is not differentiable at that point.  But my question is, is it true that a function $f(x,y)$ is differentiable at a point if and only if the tangent line of every differentiable curve lying on the surface and passing through the point lies on the same plane? If not, does anyone know of a counterexample?  For instance, is it possible for $$
\frac{d}{dt} f\bigl( x(t), y(t) \bigr)\Big|_{t=t_0}
$$ to equal $0$ for every differentiable curve $\langle x, y \rangle = \langle x(t), y(t) \rangle$ passing through $\langle x(t_0), y(t_0) \rangle$ at $t=t_0$ without $f$ being differentiable at that point?","['tangent-spaces', 'examples-counterexamples', 'real-analysis', 'multivariable-calculus', 'derivatives']"
4263040,How can we apply this simple eigenvector expression 'repeatedly'?,"Let $A,B$ be linear operators on a complex vector space $V$ and suppose $$ABu = (\alpha + 2)Bu$$ where $u \in V$ is an eigenvector of $A$ with eigenvalue $\alpha$ and $\alpha \in \mathbb{C}$ . We can interpret this as either $Bu = 0$ or $Bu$ is an eigenvector of $A$ with eigenvalue $\alpha+2$ . I'm reading a proof which proves this equation above about the operators $A,B$ as a lemma and then claims that 'by applying the lemma repeatedly' we get the formula $$AB^ku = (\alpha+2k)B^ku$$ I have tried many things but cannot see how to apply it repeatedly. The lemma seems to a statement about $ABu$ , sticking many more $B$ 's seems like it would prevent us from using it. The context: $\pi$ is a representation of the Lie algebra $sl(2,\mathbb{C})$ acting on $V$ . Above I was letting $A = \pi(H)$ and $B = \pi(X)$ where $$H = \begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix} \quad \quad X = \begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix}$$ Calculation shows $[X,H] = HX - XH = 2X$ , and because $\pi$ is a Lie algebra homomorphism, we have $\pi([H,X]) = [\pi(H),\pi(X)] = 2\pi(X)$ . Playing with this equation is what proves the lemma above. Maybe playing with this repeatedly is what is needed.","['lie-algebras', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'lie-groups']"
4263078,Munkres 23.5 - empty set in relation to total disconnectedness?,"Munkres 23.5 is stated as ""A space X is called totally disconnected if
its only connected subspaces are one-point sets. Show that if X is discrete, then X is
totally disconnected. Does the converse hold?"" I'm confused about the definition of totally disconnected. I thought the empty set was trivially a connected subspace of any space X. Wouldn't this violate that X's only connected subspaces are one-point sets? In other words, should this definition also include the empty set?","['general-topology', 'connectedness']"
4263094,Does it make sense to talk about sub-topologies?,"Upon examining the real line with the finite complement topology $\tau_{c}$ , an open set $O$ is a union of certain open intervals in $\mathbb{R}$ . Since $\mathbb{R}$ itself is the single interval $(-\infty,\infty)$ , the empty set is the empty union of intervals, and any other set is of the form $O=(-\infty,p_1)\cup (p_1,p_2)\cup\dots\cup (p_{n-1},p_n)\cup (p_n,\infty)$ where $p_1<p_2<\dots <p_n$ . Well, the usual topology on the real line $\tau$ , is made up of all union of open intervals. So it seems like (and forgive me if this isn't the proper notation) that we could say $\tau_c\subset\tau$ . I can't seem to find anything about ""sub topologies"" online though. Does this idea make sense/ is it any useful? Is there a name for this situation? This is my first semester in topology, so I'm not sure what to look up to find anything about it (but I've tried!).",['general-topology']
4263095,Counting Number of Distributions (Constraint: No adjacent objects are identical),"The question from the book is Five persons A,B,C,D,E are seated in a circular arrangement. If each of them is given a hat of one of the three colors- red, blue, and green; then the number of ways of distributing hats such that the persons seated in adjacent seats get different colored hats is ___. So, I tried using the multiplication theorem to get to an answer, Assuming ABCDE are seated along a line in the given order, A can get any of the three colors,
following which B gets one of the two remaining colors, following C gets one of the two colors other than the one that B gets, and so on. So, the number of distributions would be $$ \text{No. of distributions for a line} = 3 \times 2 \times 2 \times 2 \times 2 = 48 $$ Now this includes distributions in which A and E have the same colored hats, If A and E have the same colors, then there are 6 possible distributions which satisfy the conditions, 2 for each color that A gets. Using the inclusion-exclusion principle, $$ \text{No. of distributions for a circle} = 48 - 6 = 42 $$ But the answer is supposed to be 30. I'm not sure where I am wrong, so if someone could figure it out and help me solve this question, I'd be really grateful. This is my first time on this forum so excuse me if my question is not very clear. Thanks!","['permutations', 'combinatorics']"
4263098,"Probability that a string has a rotation that is ""similar"" to a target string","I came up with the following problem: Suppose that you have a string s1 of length N with an alphabet with 4 letters. That is, each character in a string has only 4 possible choices. A string s2 is considered similar to s1 if there exists a rotation of s2 such that the hamming distance between the rotation of s2 and s1 is 3 or less. A rotation is defined as a cyclic shuffling of words. For example, rotations of ABCD are BCDA. CDAB, DABC, ABCD. Note that ABCD isa considered a rotation of itself. What's the probability that a random string s2 is similar to s1? My initial thought process was to enumerate the number of strings that had valid rotations as so: for each allowed number of differences $i \in$ [0 to 3], you can choose $i$ characters to be different in a string of size $N$ . Each of those characters has 3 different possible characters that they can take on, since they are differing from s1. Each of those strings has $N$ valid rotations, so we multiply each by $N$ . There are 4^N possible strings of length $N$ . This yields: $$\frac{N\sum_{i=0}^{3} \binom{N}{i} 3^i}{4^N} $$ However, it's clear to see that this over-counts by quite a bit. Removing the $N$ from the numerator gives much better results but doesn't match up to what I see experimentally. Does anybody have any hints as to what I'm doing wrong? I also attached my brute-force tester: import random
from math import comb

def similarDNA(reference, candidates):
    N = len(reference)

    reference += reference

    num_similar = 0

    for candidate in candidates:
        if len(candidate) != N:
            continue
        for i in range(N):
            num_diffs = 0
            for j in range(N):
                if reference[i+j] != candidate[j]:
                    num_diffs += 1
                if num_diffs > 3:
                    break
            if num_diffs <= 3:
                num_similar += 1
                break

    return num_similar

def random_string(N = 1000):
    return ''.join(random.choices(""ATGC"", k = N))

def calc_probability(N):
    denom = 4**N
    numer = 0
    for i in range(4):
        numer += comb(N, i) * 3**i
    return numer / denom

num_candidates = 100000
num_trials = 1000

for num_digits in range(1, 20):
    num_similar = 0
    candidates = set([random_string(num_digits) for i in range(num_candidates)])
    for _ in range(num_trials):
        reference = random_string(num_digits)
        num_similar += similarDNA(reference, candidates)

    print(num_digits, num_similar/(num_trials*len(candidates)), calc_probability(num_digits))","['permutations', 'combinatorics', 'probability']"
4263125,"Inverse function theorem, Tao, Analysis II","In Analysis II by Tao, he wrote: Theorem 6.7.2 (Inverse function theorem). Let $E$ be an open subset of $\mathbf{R}^n$ , and let $f : E \to \mathbf{R}^n$ be a function which is continuously differentiable on $E$ . Suppose $x_0 \in E$ is such that linear transformation $f'(x_0) : \mathbf{R}^n \to \mathbf{R}^n$ is invertible. Then there exists an open set $U$ in $E$ containing $x_0$ , and an open set $V$ in $\mathbf{R}^n$ containing $f(x_0)$ , such that $f$ is a bijection from $U$ to $V$ . In particular, there is an inverse map $f^{-1} : V \to U$ . Furthermore, this inverse map is differentiable at $f(x_0)$ , and $$
(f^{-1})'(f(x_0)) = (f'(x_0))^{-1}.
$$ From errta of this book on his blog, he wrote: Exercise 6.7.4. Let the notation and hypotheses be as in Theorem 6.7.2. Show that, after shrinking the open sets U, V if necessary (while still having $x_0 \in U$ , $f(x_0) \in V$ of course), the derivative map $f'(x)$ is invertible for all $x \in U$ , and that the inverse map $f^{-1}$ is differentiable at every point of $V$ with $(f^{-1})'(f(x)) = (f'(x))^{-1}$ for all $x \in U$ . Finally, show that $f^{-1}$ is continuously differentiable on $V$ . I try to solve this exercise by looking for the relation between $f'(x)$ and $f'(x_0)$ for $x$ near $x_0$ , but so far I got nothing.
I also try to google proofs, turn out the exercise I'm tring to proof is given as a part of the hypothesis . To conclude, I am looking for the answers of the following questions: How to proof the exercise for functions $f : \mathbf{R}^n \to \mathbf{R}^n$ ? (Tao already explained the case $f : \mathbf{R} \to \mathbf{R}$ .) More specifically, proof the exercise without using some prior knowledge in linear algebra just like the way Tao proof the inverse function theorem (like determinants, etc. I did not learn linear algebra before). How to interpret the result of the exercises (with graph) ? Which parts of the given hypotheses are necessary ?","['inverse-function-theorem', 'derivatives', 'differential-geometry', 'real-analysis']"
4263177,Submanifolds on 2x2 matrices with trace=0.,"Let $S=\{X\in\text{Mat}_2(\mathbb{R}) : \text{tr}(X)=0\}$ . The group $\text{SL}_2(\mathbb{R})$ acts on $S$ by conjugation, that is $g \cdot X = gXg^{-1}$ . Describe the orbits of this action. When are the orbits submanifolds of S and what is their dimension? My attempt thus far: For 1, the orbits are given by matrices with the same Jordan Form, but I'm not sure how to approach 2. My idea is that for any $A \in \text{Orb}(X)$ , $\text{det}(A) = \text{det}(X)$ , so the orbit is given by the submanifold defined by $f^{-1}(0)$ , $f:S \rightarrow \mathbb{R}$ , $f(A) = \text{det}(A)-\text{det}(X)$ . Then in order for the orbit to be a submanifold, $Df_A$ must be of constant rank on $\text{Orb}(X)$ , but I am unsure of how to show this.","['derivatives', 'multivariable-calculus', 'linear-algebra', 'smooth-manifolds']"
4263187,Convergence in the resolvent-sense and spectral properties,"I'm reading the chapter about unbounded operators in [Reed,Simon,""Methods in modern mathematical physics"", vol. 1] Let $\{T_k\}_k, T$ be unbounded selfadjoint operators on a Hilbert space $H$ . If $T_k\to T$ in the norm-resolvent sense, then for any $(a,b)\subset \mathbb R$ with $\{a,b\}\cap \sigma(T)=\emptyset$ , the spectral projections $P_{(a,b)}(T_k)\to P_{(a,b)}(T)$ converge in norm. This in particular means that the spectrum of the limiting operator cannot suddenly contract. While working on a specific case, I constructed a sequence of selfadjoint operators satisfying, for some purely imaginary number $\lambda$ $$\|\Pi_FR(\lambda, T_k)\Pi_F-\Pi_FR(\lambda,T)\Pi_F\|\to 0.$$ $\Pi$ is the orthogonal projection and $F$ is a subspace of $H$ . What does this convergence say about the spectrum of $T_k,T$ ? Maybe about $\Pi_F T\Pi_F$ ? Is there a weaker version of the previous statement?","['spectral-theory', 'functional-analysis', 'unbounded-operators']"
4263207,Does speed of convergence of Lebesgue Differentiation Theorem imply Holder Continuity?,"Given a function $f \in L^1(\mathbb R)$ , suppose that $$
\Big|\frac{1}{\text{vol}(B(x,r))}\int_{B(x,r)} f(z)dz -f(x) \Big| \le C r^\alpha
$$ uniformly over $x \in K$ some bounded domain of $\mathbb R^d$ for some $C>0,\alpha \in (0,1) $ . Do we have that $f \in C^\alpha(K)$ ? The converse is simple to get, but I could not prove whether this is true.","['harmonic-analysis', 'measure-theory', 'real-analysis']"
4263224,"$n$ points at random on line segment, average distance between two consecutive points","I had previously asked the following question from my probability textbook: If two points be taken at random on a finite straight line their average distance apart will be one third of the line. See here: Integrating $\int_0^1 \int_0^1 |x-y|\,\text{d}x\,\text{d}y$ by hand Basically, it boils down to calculating ${\int_0^1 \int_0^1 |x-y|\,\text{d}x\,\text{d}y} = {1\over3}$ . It turns out this question had been asked before a long time ago, see here: Average Distance Between Random Points on a Line Segment Now, my probability textbook also asks the following generalization: If $n$ points be taken at random on a finite line the average distance between any two consecutive points will be one $(n+1)$ th of the line. My question is, how do I go about showing this? How should go about generalizing my previous integral of ${\int_0^1 \int_0^1 |x-y|\,\text{d}x\,\text{d}y}$ ? Any help would be well-appreciated.","['contest-math', 'multivariable-calculus', 'multiple-integral', 'probability']"
4263247,Integrability of Symplectic structures,"A symplectic structure on even dimensional manifold is a non-degenerate closed two form and I understood integrability of symplectic structure is closedness as a differential 2-form which comes from involutivity of symplectic vector fields by Frobenius theorem. However, in my calculation of Lie derivative of semi symplectic form $ \omega$ which means merely non-degenerate 2-form with Lie bracket $[X, Y]$ of two symplectic vector fields $X$ and $Y$ is zero without d closed condition.
My question is that did I misunderstand of the notion of integrability of symplectic structures in the sense of Frobenius, or mistake in the following calculation? Assume that $0=\mathcal{L}_X\omega, \ 0= \mathcal{L}_Y\omega$ , since $X$ and $Y$ are symplectic.
We now compute $\mathcal{L}_{[X, Y]}\omega$ using a formula $\mathcal{L}_{[X, Y]}=\mathcal{L}_X \mathcal{L}_Y -\mathcal{L}_Y\mathcal{L}_X$ . \begin{align}
\mathcal{L}_{[X, Y]}\omega & = (\mathcal{L}_X \mathcal{L}_Y -\mathcal{L}_Y\mathcal{L}_X)\omega \\
& = 0. \\
\end{align} Now $\mathcal{L}_{[X, Y]}\omega$ vanished, it implies that $[X, Y]$ is also symplectic without using d-closed condition. How should I use d-closed condition to confirm integrability of symplectic structures?","['symplectic-geometry', 'differential-geometry']"
4263281,"Existence of a unique function $f:\Bbb R^2\setminus\{(0,0)\}\to\Bbb R, f(x,y)^3=xy\cos(xyf(x,y))-x^2y^2f(x,y), (x,y)\in\Bbb R^2\setminus\{(0,0)\}.$","Does there exist a unique continuous function $f:\Bbb R^2\setminus\{(0,0)\}\to\Bbb R$ such that $$f(x,y)^3=xy\cos(xyf(x,y))-x^2y^2f(x,y),\quad (x,y)\in\Bbb R^2\setminus\{(0,0)\}.$$ Is it of the class $C^1$ ? My attempt: Let $F(x,y,z)=z^3-xy\cos(xyz)+x^2y^2z$ and let $t=xy.$ Then, $F(x,y,1)=1-xy\cos(xy)+x^2y^2=1-t\cos(t)+t^2\ge1-|t|+t^2>0,\forall t\in\Bbb R,$ that is, $\forall (x,y)\in\Bbb R^2$ . Also, $F(x,y,-1)=-1-xy\cos(xy)-x^2y^2=-1-t\cos(t)-t^2\le-1+|t|-t^2<0,\forall t\in\Bbb R,$ that is, $\forall (x,y)\in\Bbb R^2.$ Fix $(x_0,y_0)\in\Bbb R^2$ and define $G:[-1,1]\to\Bbb R,\quad G(z)=F(x_0,y_0,z).$ Since $G$ is continuous and $\lim\limits_{z\to -1^+} G(z)=G(-1)=\ell_1<0$ and $\lim\limits_{z\to 1^-} G(z)=G(1)=\ell_2>0,$ by the mean value theorem,there is $z_0\in(-1,1)$ such that $G(z_0)=F(x_0,y_0,z_0)=0.$ Now, let's look at $G'(z)=\frac{\partial F(x_0,y_0,z)}{\partial z}=3z^2+x^2y^2\sin(xyz)+x^2+y^2=3z^2+x^2y^2(\sin(xyz)+1)\ge 0.$ I think $G'(z)=0\iff z=0$ and $x=0$ or $y=0$ . I would like to apply the implicit function theorem, but, if $x=0$ or $y=0$ and $z=0,$ then I found an example of $F(x_0,y_0,z_0)=0$ and $\frac{\partial F(x_0,y_0,z)}{\partial z}=0$ so I don't know if $f\in C^1(\Bbb R^2\setminus\{(0,0)\})$ . (1) Should, therefore, the domain of the function $f$ be $\Bbb R^2\setminus\{(x,y)\in\Bbb R^2\mid x=0\text{ or } y=0\}?$ In that case, $G'(z)>0\implies G$ is strictly increasing and hence, has a unique root $z_0\in[-1,1]$ and we could define $f(x_0,y_0)=z_0$ for each fixed $(x_0,y_0)\in\Bbb R^2$ and, then, apply the implicit function theorem that guarantees the existence of some open intervals $I,J,K\subseteq\Bbb R$ containing $x_0,y_0,z_0$ respectively and a unique function $g:I\times J\to K$ of the class $C^1$ such that $F(x,y,g(x,y))=0,\forall (x,y)\in I\times J.$ Since $F(x,y,z)=0\iff z=f(x,y),$ we conclude that $f_{\mid I\times J}=g\in C^1$ . As being of the class $C^1$ is a local notion, we conclude $f\in C^1.$ Could anybody verify my answer?","['real-analysis', 'multivariable-calculus', 'functions', 'solution-verification', 'implicit-function-theorem']"
4263298,"Arrangements of ""1234123567"" such that no two identical numbers are adjacent to each other","Find the number of ways to rearrange the sequence “1234123567”, such that no two identical numbers are adjacent to each other (there are two 1’s, two 2’s, and two 3’s). For example, “1123234567” is invalid because the two 1’s are adjacent. I first tried to use the Inclusion-exclusion principle: Let $A$ be ""there is ""11"" in the arrangement""
let $B$ be ""there is ""22"" in the arrangement""
let $C$ be ""there is ""33"" in the arrangement"" Then the number of invalid cases should be: $|A\cup B\cup C|=|A|+|B|+|C|-|A\cap B|-|A\cap C|-|B\cap C|+|A\cap B\cap C|$ , which means $|A\cup B\cup C|=3\times 9!-3\times (7!\times 2)+6\times 5!=1059120$ . However, when I use the brute-force approach using Python: from itertools import permutations

perm = [''.join(i) for i in permutations(""1234123567"")]

valid = [n for n in perm if not (""11"" in n or ""22"" in n or ""33"" in n)]

print(len(valid)) # 1895040 it gives $1895040$ as the result. I wonder why these results don't seem to match? Is any of these results, in fact, true?",['combinatorics']
4263323,"$10$ circles ($2$ large of radius $R$, $6$ small of radius $r$ and 2 small of radius $t$) are enclosed in a square. How we find $r$ in terms of $t$?","Let us embed $2$ large intersecting circles of radius $R$ into a square as depicted by the figure below. These two circles are highlighted green. Into these $2$ circles we embedd $6$ smaller ones of equal radius $r$ (highlighted orange). Finally we have $2$ circles of the same radius $t$ , which both touch the large (green) circles and the square. How we can find a formula that calculates the radius $r$ of the $6$ small circles when inputting the radius $t$ ? One idea to proceed might be to define a distance $d$ from the center of one of the large (green) circles to the point at which the large radius $R$ is touching one of the small (orange) circles. Then at least we would get the Pythagorean triangle equation $r^2+d^2=(R − r)^2$ as a possibly useful starting point:","['puzzle', 'circles', 'geometry', 'sangaku', 'trigonometry']"
4263373,Conjecture: $\lim\limits_{x\to\infty}\operatorname{Re}\text W_x(x)\mathop=\limits^?-\ln(2\pi)$,"The inspiration for the question is Closed form of $$\frac{d}{dk}\text W_k(z)$$ Derivative of W-Lambert function with respect to its branch cuts experiment. I also like making functions central to my work. So I though about “centralizing” the Generalized W-Lambert function so that the branch cut is the same as the argument: $$\text W_k(z)=\text W_x(x)$$ I then considered what the value of $$\text W_{\pm \infty}(\pm \infty)$$ would be. Assume that the signs can be chosen in any order. I found a conjectured closed form. For simplicity, let’s consider the convergent real part of the expression. Let’s also further constrain our problem by choosing signs to be $$\text{Re}(\text W_{ \infty}( \infty))$$ $$\lim_{x\to\pm \infty}\text {Re}(\text W_x(x))\mathop=^{\large ?} -\ln(2\pi)$$ The imaginary part turn out to be asymptotic to $$\pm 2\pi i \infty=\pm\infty i$$ so it is just an infinite complex number. I found the possible result after using a discrete limit . For example, the value at $x=10^{10}$ is the following. I used the the real an imaginary part as well as different signs for completion. $$\text W_x(x)= \text W_x(-x)= \text W_{x}(\pm ix) =-1.8378770663843454835603092354803385245074740939... +
6.2831853070225068442428720324366974719089270342... × 10^{10} i, \text W_{-x}(-x)= \text W_{-x}(x)=\text W_{-x}(\pm ix)=-1.8378770663343454835578092354801887222706941730... -
6.2831853067083475788838927085903664574425628653... × 10^{10} i $$ Note the $2\pi$ approximation in the scientific notation if the imaginary part. As said before, the real part is approximately: $$-\ln(2\pi)= -1.8378770663843454835603092354803385245074740939... $$ Here are the Inverse Symbolic Calculator results . How can you formally evaluate $$\text{Re}\lim_{x\to \infty} \text W_x(x)$$ using a discrete limit? Please correct me and give me feedback! Just for fun, the Wright Omega function can also have the interesting identity that: $$ω(z)\mathop=^\text{def} \text W_{\left \lceil\frac{\text{Im}(z)}{2\pi}-\frac12\right\rceil}\left(e^z\right)\implies -\ln(2\pi)=\lim_{x\to\infty} ω(\ln(x)+2i\pi  x)$$ Where $$\left\lceil\frac{\text{Im}(z)}{2\pi}-\frac12\right\rceil =\frac{i\left(\ln\left(e^z\right)-z\right)}{2\pi}=\text{unwindK(z)}=\text K(z)$$ is called the Unwinding Number","['lambert-w', 'solution-verification', 'discrete-calculus', 'branch-cuts', 'limits']"
4263423,Reference request to have a deep understanding of solutions to PDE,"I come from an engineering background that heavily involves modelling in many fields especially data science and control theory. I have dealt with PDEs many times while modelling data features such as in control systems in analyzing natural phenomena around the system. Many of these PDEs I have encountered are elliptical by class (such as the Laplacian) and while it all ends by just finding the solution to this PDE, I am looking to learn more on how to apply ""hardcore analysis"" on the solution obtained in solving PDEs to have a better understanding of what I have and what special properties this solution belonging to this type of class has. I have specifically highlighted the word solution because a quick search on this topic gave me a whole different meaning about this term which appears to be generalized to spaces that allows non-smooth solutions. In fact I have yet to see a natural phenomena modelled to have solution that is ""smooth"". I wish to know ""what key ideas need to be known"" to have a rigorous understanding in this topic as I am not looking on functional analysis on one side and PDEs on the other side. I am tending to look for the intersection between these two. Furthermore, what references are recommended? I have a good knowledge in advanced calculus and measure theory. I firmly believe that performing analysis on solutions to PDEs using advanced mathematical concepts can improve my perspective on modelling.","['reference-request', 'mathematical-modeling', 'functional-analysis', 'partial-differential-equations']"
4263438,Irreducible mapping between compact Hausdorff spaces with no singleton fibers,"A continuous surjection $f\colon X \to Y$ is called irreducible if for every proper closed subset $A \subset X$ , $f(A) \neq Y$ . I have to construct an irreducible mapping between compact Hausdorff spaces, which has no singleton fibers. Here is my observation. Let $f\colon X \to Y$ be such a mapping. Since it is a mapping from a compact space into a Hausdorff space, it is closed. Thus $f$ is a quotient mapping. The irreducibility of $f$ can be rephrased to this: For every nonempty open set $U$ (here we may fix a basis to pick from), there exists $y \in Y$ s.t. $f^{-1}(y) \subset U$ i.e. $U$ contains a fiber. $Y$ being Hausdorff is equivalent to saying that two distinct fibers can be separated by saturated open sets. To sum up, we should find a partition of a compact Hausdorff space containing no singletons such that every nonempty open set contains a cell(an element of the partition) and every cell can be separated by saturated open sets. Starting from $X = [0, 1]$ , let $x \sim y$ when $x, y$ are triadic rationals different than $0, 1$ and $x$ can be transformed to $y$ with changing the rightmost digit in ternary representation from $1$ to $2$ or $2$ to $1$ . With this I was able to tuck two point cells in every nonempty open set and find saturated open sets separating them. The problem is that $\sim$ has too many singleton cells. And further identifying singleton cells modulo $1/3$ breaks the Hausdorff condition. I'm stuck here. How can one construct such mapping?","['quotient-spaces', 'general-topology', 'examples-counterexamples', 'compactness']"
4263464,functional derivative and dualspace,"Consider the function space $F=\{ f : \mathbb{R}^m \rightarrow \mathbb{R}^n\}$ and the empirical scalarproduct: $$
\langle f,g\rangle:=1/n\sum^n_{i=1}f(x_i)^Tg(x_i),
$$ for a a finite dataset $x_1, \ldots, x_n \in \mathbb{R}^m$ . The Dualspace is defined as $F^*=\{\langle d,\cdot\rangle:d\in F\}$ .
The cost functional $C$ (for example: $$C(f)=1/n\sum_{i=1}^n\|f(x_i)-f*(x_i)\|^2$$ )
only depends on the values of $f \in F$ at the data points. As a result it was said that, the (functional) derivative of the $\operatorname{cost} C$ at point $f_0 \in F$ can be viewed as an element of $F^{*}$ , which we write $\left.\partial_{f} C\right|_{f_0}$ , such that $\left.\partial_f C\right|_{f_0}=\langle d|_{f_0}, \cdot\rangle$ for some $d|_{f_0} \in F$ . Can someone explain why the last equation holds? Also im not familiar with the functional derivative, but according to the definition of wiki: https://en.wikipedia.org/wiki/Functional_derivative shouldn't the derivative at $f_0$ also be a function from $\mathbb{R}^m$ to $\mathbb{R}^n$ ?","['frechet-derivative', 'statistics', 'functional-analysis', 'dual-spaces']"
4263502,Inverse of $A-I$,"I am trying to understand one detail of one solution of below question Let $A$ be n-by-n matrix ( $n \geq 2$ ), and $$ A=
\begin{pmatrix}
0 & 1 & 1 & \cdots & 1 \\
1 & 0 & 1 & \cdots & 1 \\
\vdots & \vdots & \vdots &  & \vdots \\
1 & 1 & 1 & \cdots & 0
\end{pmatrix}
$$ calculate $A^{-1}$ . The solution: Let $A = B - I$ , $B$ is matrix that every element is $1$ . Then let $A^{-1} = aB + bI$ , we  can construct the equation $$
\begin{array}{ll}
I &= (B-I)(aB + bI) \\
  &= aB^2+(b-a)B -bI \\
  &= anB + (b-a)B - bI \\
  &= (an+b-a)B - bI
\end{array}
$$ so $b = -1, a = \frac{1}{n-1}$ . But why it can let $A^{-1} = aB + bI$ directly at the beginning of the solution? Is there some tricks for calculate inverse of such matrix?","['matrices', 'linear-algebra', 'inverse']"
4263520,The image of a smooth submanifold is not always a smooth submanifold.,"Let $M, N$ be smooth manifolds, $F:M\to N$ be a smooth map, and $A\subset$ M be a smooth submanifold of $M$ . What conditions do I need to impose if I want to have that $f(A)$ is a smooth submanifold of $N$ ? Some counterexample that I have in mind is $M=\mathbb{R}^3$ , $N=\mathbb{R}^2$ , $F$ is given by $F(x,y,z)=(x,y)$ , and $A=\{(\sin(t),\sin(t)\cos(t),\cos(t))|t\in[0,2\pi]\}$ . So, figure $8$ in space which is projected to a figure $8$ in the plane with a selfintersection.","['submanifold', 'smooth-manifolds', 'differential-geometry']"
4263542,Understanding the concept of infinitely often,"My book in stochastic processes has this section about i.o which I don’t really understand. Is there any example of any other to explain this? How can I understand this? It states the following:
Let $A_{1}, A_{2}, \ldots$ be a sequence of subsets of $\Omega$ . We define $$
\left(A_{n} \text { i.o. }\right)=\bigcap_{n=1}^{\infty} \bigcup_{m=n}^{\infty} A_{m}
$$ The abbreviation i.o. stands for infinitely often.","['measure-theory', 'statistics', 'stochastic-processes', 'borel-cantelli-lemmas', 'probability']"
4263560,Probabilistic interpretation linear regression implication step,"I am reading Andrew Ng's notes on linear regression, and in this section, he attempts to derive the formula for the least squares using a probability approach: http://cs229.stanford.edu/summer2020/cs229-notes1.pdf We assume: $$y^{(i)}=\theta ^{T}x^{(i)}+e^{(i)}$$ where where $\epsilon$ is distributed according to the normal distrubtion: $N(0, \sigma^2)$ Thus, we can find the probability of $e^{(i)}$ as $$p(e^{(i)})=\frac{1}{\sqrt{2π}σ}exp(-\frac{(e^{(i)})^2}{2σ^2})$$ However, in the next step, he says that this implies $$p(y^{(i)}|x^{(i)}; \theta)=\frac{1}{\sqrt{2π}σ}exp(-\frac{(y^{(i)} - \theta^Tx^{(i)})^2}{2σ^2})$$ and I am not sure how. We see that $e$ is a RV and is distributed according the normal, so then how can we calculate the probability on something that isn't $e$ ?","['machine-learning', 'statistics', 'linear-regression']"
4263567,Let $k$ be a field. The generic point of $\operatorname{Spec}k[x]$ does not form a constructible set of $\operatorname{Spec}k[x]$?,"Let $\zeta=[(0)]$ be the generic point of $\operatorname{Spec}k[x]$ . If $\{\zeta\}$ were constructible, then we could write $\{\zeta\}$ as a finite disjoint union of locally closed subsets. But then $\zeta$ must be in just one of these locally closed subsets. Say, $\zeta \in U \cap V$ where $U$ is open and $V$ is closed. Since $\zeta \in V$ , then $V=\operatorname{Spec}k[x]$ and so $\{\zeta\} = U$ is open. Therefore, $\operatorname{Spec}k[x]-\{\zeta\}$ is closed. Where should we go from here?","['general-topology', 'algebraic-geometry', 'commutative-algebra']"
4263628,Turning an informal proof about palindromes into a formal proof,"No. of dots: $k$ No. of slots: $n$ If the dots are placed in every combination within the slots, how many palindromes will there be? The dots cannot be superimposed on each other, which means $k \lt n$ . $$n,k,x,y \in \Bbb N$$ $$\text{No. palindromes} =
\begin{cases}
\displaystyle {n \div 2 \choose \ k \div 2}, & n = 2x, \ k = 2y \\[2ex]
\displaystyle{\lfloor n \div 2 \rfloor\choose k \div 2}, & n = 2x +1, \ k = 2y \\[2ex]
\displaystyle{\lfloor n \div 2 \rfloor \choose \lfloor k \div 2\rfloor}, & n = 2x +1, \ k = 2y + 1 \\[2ex]
0, & n =2x, \ k = 2y +1 
\end{cases}$$ This is what I've got. I'm pretty sure it's correct, but I have no formal proof. I think I have an informal proof: For a combination of dots in the slots to make a palindrome, the two halves of the string of slots must be mirror images. That means we're dealing with the halves of $n$ and $k$ , as for every arrangement of dots there is on one half of the string, there is only one possible arrangement on the other half (that arrangement being the mirror image). As such, if both $n$ and $k$ are even, the number of palindromes will be equal $n/2 \choose k/2$ . If $n$ is odd, but $k$ is even, then none of the dots may take the central slot. This is because it would then mean an uneven number of dots $2y -1$ would be distributed over an even number of slots $2x +1 -1$ . In such a case, there will always be one more or one less on one of the halves. As such, no dot can be placed in the central slot. This reduced the amount of available slots from $n/2$ to $(n-1)/2$ or just $\lfloor n/2 \rfloor$ . That means the number of palindromes in this case is $\lfloor n/2 \rfloor \choose k/2$ . If both $n$ and $k$ are odd, then a dot must occupy the central slot. That removes both a slot and a dot from the previously odd number of slots and dots (respectively), meaning we're left with an even number of dots distributed onto an even number of slots. Thus, the number of palindromes is $\lfloor n/2 \rfloor \choose \lfloor k/2 \rfloor$ . If $n$ is even but $k$ is odd, then there is no central slot to remove a dot, meaning there are no palindromes. If this is correct, how can I make it into a formal proof? If it is incorrect, where did I go wrong? EDIT: Forgot to add the rule that the dots cannot overlap. There can never be $3$ dots distributed over $2$ slots.","['word-problem', 'palindrome', 'proof-writing', 'combinatorics']"
4263640,Proving that the Sample Mean is BLUE (Best Linear Unbiased Estimator),"For a pupil, i, selected at random from a school, the number of years of education of their parents, $X_i$ , is given by: $$
X_{i}=\mu+\varepsilon_{i}
$$ $\varepsilon_{i} \sim i i d\left(0, \sigma^{2}\right)$ . Here $\mu$ is the mean number of years of education completed by parents. For a sample of N students selected independently from the population: (e) Is the sample mean BLUE? Either way, prove it. Answer:
First part of proof proves conditions for linear estimator to be unbiased. The second part proves that if the estimator is unbiased, the variance of a linear estimator cannot better it. Define linear estimator $\tilde{X}=\frac{1}{N} \sum_{i=1}^{N} w_{i} X_{i}$ with weights made up: $w_{i}=1+\delta_{i}$ . The 1 here is what the sample mean weight are, so we are saying our new estimator weights differ from that of the sample mean by the amount $\delta_{i}$ . $$
\mathbb{E}(\tilde{X})=\mathbb{E}\left(\frac{1}{N} \sum_{i=1}^{N}\left(1+\delta_{i}\right) X_{i}\right)=\mu+\frac{\mu}{N} \sum_{i=1}^{N} \delta_{i}
$$ Hence we must have $\sum_{i=1}^{N} \delta_{i}=0$ for our new linear estimator to be unbiased. Now we derive variance: $$
\operatorname{Var}(\tilde{X})=\frac{1}{N^{2}} \sum_{i=1}^{N}\left(1+\delta_{i}\right)^{2} \sigma^{2}=\frac{\sigma^{2}}{N}+\frac{\sigma^{2}}{N^{2}} \sum_{i=1}^{N}\left(2 \delta_{i}+\delta_{i}^{2}\right)=\operatorname{Var}(\bar{X})+\frac{\sigma^{2}}{N^{2}} \sum_{i=1}^{N} \delta_{i}^{2}
$$ Finally, note that for non-zero weights the expression $\sum_{i=1}^{N} \delta_{i}^{2}=\eta>0$ , hence we have that the variance of the new estimator is greater than that of the sample mean. Hence this has proved that any other linear estimator apart from the sample mean has a greater sampling variance. $$
\operatorname{Var}(\tilde{X})=\operatorname{Var}(\bar{X})+\eta
$$ Q: The expected value expression makes sense, but where does the variance expression come from and how does he get that?","['regression', 'statistics']"
4263642,Does the Green's Function for an IVP always converge while integrating?,"I'm having some trouble solving an ODE using the Green's function method. The problem I'm working in is the simple harmonic oscillator equation $$ L[y(t)]=f(t)$$ $$ L = \frac{d^2}{dt^2}+\omega^2$$ $$y(0)=1,y'(0)=0$$ Now I'll construct my Green's function. I have two linear independent solutions for the homogeneous version ( $f(t)=0$ ) of my problem: $y_1(t)=\cos(\omega t)$ and $y_2(t)=\sin(\omega t)$ . I know that the Green's function satisfies $L[G(t,\xi)]=\delta(t-\xi)$ . For $t\neq\xi$ we have that $L[G(t,\xi)]=0$ . My function should be $$ G(t,\xi)=\left\{\begin{matrix}
 A\cos(\omega t) + B \sin(\omega t),& t<\xi \\ 
 C\cos(\omega t) + D \sin(\omega t),& \xi<t
\end{matrix}\right. $$ Applying the initial conditions $G(0,\xi)=1,G'(0,\xi)=0$ we find that $A=1$ and $B=0$ . $$ G(t,\xi)=\left\{\begin{matrix}
 \cos(\omega t),& t<\xi \\ 
 C\cos(\omega t) + D \sin(\omega t),& \xi<t
\end{matrix}\right. $$ Using the continuity of the function at $t=\xi$ and the discontinuity of the derivative at $t=\xi$ we should have $$C \cos(\omega \xi)+D \sin(\omega \xi)-\cos(\omega \xi)=0 \\ -C\sin(\omega \xi)+D\cos(\omega \xi)+\sin(\omega\xi)=\frac{1}{\omega}$$ Solving this system we find that $C=1-\dfrac{\sin(\omega\xi)}{\omega}, \;D=\dfrac{\cos(\omega\xi)}{\omega}$ . Finally, the Green's function should be $$ G(t,\xi)=\left\{\begin{matrix}
 \cos(\omega t),& t<\xi \\ 
 \dfrac{1}{\omega}\left[\omega-\sin(\omega\xi)\right]\cos(\omega t) + \dfrac{1}{\omega}\cos(\omega\xi)\sin(\omega t),& \xi<t
\end{matrix}\right. $$ Now I should be able to find a solution for the ODE using the Green's function because $y(t)=\int_0^\infty f(\xi)\,G(t,\xi)\,d\xi$ I'm having trouble with this last step. Some of the functions I should try are $f(t)=e^{-t}$ and $f(t)=\cos(t)$ . For the case where the ""forcing function"" is a cosine, the integral does not converge. I tried the following \begin{align*}
y(t)
&=\int_0^\infty f(\xi)\,G(t,\xi)\,d\xi\\
&=\int_0^t \cos(\xi)\left[ \frac{1}{\omega}\left[\omega-\sin(\omega\xi)\right]\cos(\omega t) + \frac{1}{\omega}\cos(\omega\xi)\sin(\omega t)\right]d\xi\\
&\quad+\int_t^\infty \cos(\xi)\,\cos(\omega t)\,d\xi
\end{align*} The first integral is not hard to compute and it give us an answer. But the second integral does not converge. I thought that the Green's function should give us a solution for this problem because this ODE has a solution that we can easily get with other methods. So, my question is: what is going wrong with my construction? Is my Green's function wrong or am I taking the integral in the wrong way with the wrong limits?
Thanks in advance!","['differential-operators', 'initial-value-problems', 'greens-function', 'ordinary-differential-equations']"
4263685,"Proof of $\frac{1}{N}\sum_{j=1}^{N}{\sin(jx)}<\frac{2}{Nx}, \forall x \in (-2\pi,2\pi)$?","I've come across this beautiful expression, I would like to share how nicely the function $\displaystyle\frac{1}{N}\displaystyle\sum_{j=1}^{N}{\sin(jx)}$ fits into $\displaystyle\frac{2}{Nx}$ , for all x in ( $-2\pi,2\pi$ ). But how can I prove it? I tried taking the derivative of the function to get its maximum value but got nowhere. I'm still a student who hasn't yet formally encountered the topics I may need to reach the solution: Since this place is full of experts I thought it was a good idea to post this problem here. Thanks in advance for your time.","['trigonometry', 'summation', 'sequences-and-series']"
4263723,finding roots of $a \sin \theta + b \cos \theta +c \sin \theta \cos \theta + d \sin^2 \theta + e \cos^2 \theta$,"I've encountered the following function while working on a project: $$
f(\theta) = a \sin \theta + b \cos \theta +c \sin \theta \cos \theta + d \sin^2 \theta + e \cos^2 \theta
$$ where a through e are all real non-zero numbers and $0 \leq \theta < 2 \pi$ . I know this function has at least two roots. For reasons I won't bore you with, finding the roots numerically isn't ideal for the project I'm working on. Applying the tangent half-angle substitution described in this answer results in a fourth order polynomial, which is troublesome to find the roots of without numerical methods. $$
0 = (e-b)t^4 + (2a-2c) t^3 - 2et^2 + (2a+2c+4d)t + (b+e)
$$ Is there a better non-numerical option for finding the roots?","['trigonometry', 'roots']"
4263746,Bhatia—Davis inequality: first recorded occurrence?,"The Bhatia–Davis inequality states that, for any random variable $X$ such that $m \leq X \leq M$ a.s., $$
\operatorname{Var}[X] \leq (M-\mathbb{E}[X])(\mathbb{E}[X]-m)
$$ This is a strenghtening of another inequality , attributed to Popovicius (1935). However, Bhatia and Davis only published their paper in 2000. Was there no earlier recorded occurrence of this inequality? It seems a little strange for it to have waited 65 years...","['inequality', 'math-history', 'probability']"
4263772,Let $|G|=2^n3$. Show that there's a normal subgroup of order $2^n$ or $2^{n-1}$.,"Let $|G|=2^n3$ . Show that there's a normal subgroup of order $2^n$ or $2^{n-1}$ . What I did so far: I used the third Sylow theorem, which says that if $|G|=p^nb$ with $\operatorname{GCD}\{p,b\} = 1$ then the number of $p$ -Sylow subgroups, $n_p$ , divides $b$ and $n_p \equiv 1 \operatorname{mod}p$ . From here, we have that $n_2 = 1$ or $n_2 = 3$ . If $n_2 = 1$ , then the $2$ -Sylow subgroup of $G$ is normal and the order is $2^n$ . If $n_2 = 3$ then I need to show somehow that there's a normal subgroup of order $2^{n-1}$ . Any hints on how to continue?","['finite-groups', 'normal-subgroups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
4263774,Trouble finding the area [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question This question appears in a kid's math book.  Am I missing some obvious answer? I can't find a way to draw a line that divides the area evenly.",['geometry']
4263816,Injectivity of map between tensor products with $\mathbb{Q}$ and $\mathbb{R}$,"Let $G$ be an abelian group. We have a natural map $i\colon G\otimes\mathbb{Q}\to G\otimes\mathbb{R}$ given on simple tensors by $$i(g\otimes a)=g\otimes a.$$ Question: Is $i$ injective? Comment: I understand that for example that the analogous map $G\otimes\mathbb{Z}\to G\otimes\mathbb{Q}$ is not injective in general, since $G\otimes\mathbb{Q}$ is torsion-free. But can there be any other reason that the map $i$ above is not injective?","['modules', 'abstract-algebra', 'tensor-products', 'group-theory', 'abelian-groups']"
4263831,How many subgraphs of $(K_n)^-$ are isomorphic to $(K_5)^-$?,"my question says How many subgraphs of $(K_n)^-$ are isomorphic to $(K_5)^-$ ? Let $(K_n)^-$ be a graph obtained from $K_n$ by deleting any one of its edges. I thought about using Cayley’s Formula but do not know whether to apply it here. I am having a hard time visualizing and understanding the logic behind this question, any help is appreciated.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
4263844,Properties of First Order Linear ODE as it relates to the solution,"I am given the following image, and asked which of the following forms of ODE's could this solution match to (vertical asymptote at $t = 8$ ). $(1) \ y' + p(t)y=g(t)$ or $ (2) \ y' = f(y)$ or $ (3) \ y' = f(y)g(t)$ . From the graph, I can see that the slope varies with $t$ hence it can not be autonomous like in $(2)$ . However, what justifications can I make to decide whether this can be a solution to $(1)$ or $(3)$ ?",['ordinary-differential-equations']
4263870,"""Mod"" out symmetry in ideal for a Groebner basis calculation (using a quotient ring?)","Consider a set of polynomials $P$ in the polynomial ring $R$ of $n$ variables ( $R = \mathbb{C}[x_1,...,x_n]$ ), and let $I$ be the ideal generated by the polynomials in $P$ . I have an ideal which is invariant to some permutations in the variables. These permutations are a non-trivial proper subgroup of $S_n$ (the full group of permutations of the n variables). I will denote this subgroup as $G$ . Furthermore, in my case of interest, not all of the polynomials in the generating set $P$ are invariant to the permutations in $G$ , yet the full set is invariant (some permutations permute the polynomials with-in P, while the set itself remains invariant). I would like to, in essence, calculate the ""symmetry unique"" pieces of the Groebner basis of this ideal. My real over-arching question is: What are some options to ""remove"" the symmetry to simplify the calculation? And narrowing in a bit: Is this what a ""quotient ring"" is for? Or is that for modding out a different structure? Because here, the generating polynomials do not have a particular symmetry (so it's not like I'm restricting to ""the ring of symmetric polynomials""), it is instead the ideal which has a particular symmetry. If I could use a quotient ring, I imagine it would go something like this: somehow construct an ideal $J$ capturing the 'symmetry' in $G$ form a quotient ring $R_2$ = $R/J$ get $I_2$ , the ideal $I$ ""transferred"" from the ring $R$ to the quotient ring $R_2$ now calculate the Groebner basis of $I_2$ in the quotient ring $R_2$ The above worries that a ""quotient ring"" is not the right object to use here, make me unsure how to even go about the first step there. So this leads me to ask: Is this outline correct? If so, how do I construct $J$ to correctly capture the symmetry from the permutations in $G$ ?","['groebner-basis', 'algebraic-geometry', 'polynomial-rings', 'ideals']"
4263880,Is $f(x)=\frac{x}{x^{4}+x^{3}+x^{2}+x}$ a polynomial function?,"My book mentions that in a polynomial function, there cannot be any x-terms in the denominator; however, they didn't give any explanation as to why. My hunch is that if there are any x-related terms in the denominator, the denominator could become 0 for some value of x, and the function would become undefined. For example, $$f(x)=\frac{x}{x^{4}+x^{3}+x^{2}+x}$$ Is that why the book tells me to do so?","['functions', 'polynomials']"
4263896,Show that $3$ lines must concur,"I was recently posed with the following problem: Let $\Omega$ be a circle passing through vertices $B$ and $C$ in triangle $\Delta ABC$ and let $\omega$ be a circle tangent to segments $AB$ and $AC$ at the points $P$ and $Q$ respectively, and externally tangent to $\Omega$ at point $T$ . Let $M$ be the midpoint of arc $BTC$ of $\Omega$ . Show that lines $BC$ , $PQ$ , and $MT$ concur. Naturally, I first made a quick sketch of the problem: I then quickly realised that in order for $\Omega$ to pass through both $B$ and $C$ , its centre must lie on their perpendicular bisector. This also quickly leads to finding $M$ , as it is simply the point where $\Omega$ intersects this perpendicular bisector. I then managed to loosely show that $T$ has to be on the angular bisector of $\angle BAC$ , i.e. the point where $\Omega$ intersects with this angular bisector. This also very simply shows that $P$ and $Q$ must be the same distance away from $A$ , or in other words, that the triangle $\Delta PQA$ is isosceles. With this information, I made a new, more accurate diagram: I then started trying to prove the statement in the original problem. Since we know $M$ and $T$ , and we know $BC$ , we can now find the point where the three lines must concur. Then, since we know that $\Delta PQA$ is isosceles, my idea was that we could find the point of concurrence, and draw a line from it to $\Delta ABC$ , such that it would make an isosceles triangle at the points where it intersects with the triangle, and check if those points are $P$ and $Q$ (the points of tangency with the circle). If they are, then we have proved it to be true, since $P$ and $Q$ make a line to the point of concurrence, otherwise, it is false. This is where I got stuck, I don't know how I would go about finding this line from the point of concurrence to $\Delta ABC$ , or how I would then go about showing that it intersects at $P$ and $Q$ specifically. I pondered this for a few days but couldn't think of anything, so I decided to ask it here. All help is greatly appreciated! EDIT: it turns out a claim I made earlier was wrong, $T$ does not have to lie on the angular bisector as @user10354138 pointed out EDIT: I also had another finding I forgot to include in my original question. Since $\omega$ is tangent to line $AB$ at the point $P$ , it follows that the centre of $\omega$ must lie on the line perpendicular to $AB$ at point $P$ , and similarly for $AC$ and point $P$ , like so: And since the lines $OP$ and $OQ$ (where $O$ is the centre of $\omega$ ) must be the same length, $O$ must lie on the angular bisector of $\angle BAC$ .","['contest-math', 'euclidean-geometry', 'recreational-mathematics', 'geometry']"
4263899,Is that possible for a system to have an equilibrium point at infinity?,"I know for some system of ODEs, there is no  equilibrium at all, but I am wording that is valid to say a system has equilibrium at $\infty$ ? Consider the following system as an example. $$x' = \frac{y}{x}$$ $$y' = y - 4$$ So for this system, if we want to solve the equilibrium point, we need to solve the system of equation $$\frac{y}{x} = 0$$ $$y - 4 = 0$$ which give us $y = 4$ and $ 4/x = 0$ . So the only way for the first equation to be zero is as $x$ approaching $\infty$ $$ \lim_{x \to \infty}\frac{4}{x} = 0$$ but can we say $(\infty, 4)$ is an equilibrium point?","['limits', 'infinity', 'systems-of-equations', 'ordinary-differential-equations']"
4263917,Partial Derivatives of Sigmoid Function,"I am confused about the partial derivatives that I'm using in my deep learning model. The formula of the sigmoid is: $i_t = \sigma(W_{ii}*x_t+b_{ii} + W_{hi}*h_{t-1}+b_{hi})$ Notation meaning: $\sigma$ = Sigmoid Function $W_{ii}$ = Weight Input $x_t$ = Input data $b_{ii}$ = Bias Input $W_{hi}$ = Weight Hidden $h_{t-1}$ = Hidden State previous Time Step $b_{ii}$ = Bias Hidden I've been searched that the regular sigmoid function partial derivatives is: $\frac{d}{d_x} =  \sigma(x) . (1-\sigma(x))$ Then, I'm trying to do a partial derivative of the $i_t$ formula w.r.t $W_{ii}$ , my current answer is: $\frac{d}{dw_{ii}} = \sigma(x_t) . (1-\sigma(x_t))$ Am I do wrong? If I do wrong, can someone help me to correct my answer? UPDATE:
I've been try again and this is my step right now: Assume that $z = W_{ii}*x_t+b_{ii} + W_{hi}*h_{t-1}+b_{hi}$ Then the $i_t$ formula will be: $i_t = \sigma(z)$ Partial derivative will be: $\frac{d}{d_z}i_t =  \sigma(z) . (1-\sigma(z))$ On the other hand, the partial derivative of the $z$ is: $\frac{d}{dw_{ii}}z = x_t $ Finally, the final partial derivative formula is: $\frac{d}{dw_{ii}}i_t = \sigma(z) . (1-\sigma(z)) . x_t$ But, I don't know whether it's correct or wrong. Can someone correct my updated answer? Thank you in advance","['partial-derivative', 'machine-learning', 'derivatives', 'partial-differential-equations']"
4263996,What is an open subset of $X$?,"From Walter Rudin's Principles of Mathematical Analysis Ed. 3. 2.29 Remark Suppose $E \subset Y \subset X$ where $X$ is a metric space. To say that $E$ is an open subset of $X$ means that to each point $p \in E$ there is associated a positive number $r$ such that the conditions $d(p,q) < r$ , $q \in X$ imply that $q \in E$ . My understanding is that $E$ is an open subset of $X$ if for all $p \in E$ , there exists $r > 0$ such that all $q \in X$ with $d(p, q) < r$ is in $E$ . That is to say, every $p \in E$ has a neighborhood containing only elements of $X$ that's also in $E$ . Is this equivalent to remark 2.29? Why state "" $q \in X$ imply that $q \in E$ "" instead of just "" $q \in E$ ""? "" $q \in X$ imply that $q \in E$ "" is true if $q \notin X$ and $q \notin E$ , so the conditions are satisfied if $d(p, q) < r \wedge q \notin X \wedge q \notin E$ , but this seems irrelevant when mentioning subsets of $X$ .","['general-topology', 'analysis']"
4263997,Convergence of the image of the derivative map,"Let $g\colon \Bbb R^2\to \Bbb R^2$ be a smooth map and $x_n\to x$ in $\Bbb R^2$ with $r_n:=|g(x_n)|\to 1$ . Write $S_r:=\{z\in \Bbb
 R^2:|z|=r\}$ and assume $\text{im}(dg_{x_n})=T_{g(x_n)}(S_{r_n})$ for
all $n$ . Then $\text{im}(dg_x)\subseteq T_{g(x)}(S_1)$ . My attempt: Without loss of generality, assume $dg_x\neq 0$ . So, we need to show, $\text{im}(dg_x)= T_{g(x)}(S_1)$ . Since $x_n\to x$ we have $g(x_n)\to g(x)$ . So, we can write, $g(x)=(\cos\theta,\sin\theta)$ and $g(x_n)=(r_n\cos\theta_n, r_n\sin \theta_n)$ so that $\theta_n\to \theta$ . Let $v_n=(-\sin\theta_n,\cos\theta_n)$ be a generator of $T_{g(x_n)}(S_{r_n})$ and $v=(-\sin\theta,\cos\theta)$ be a generator of $T_{g(x)}(S_1)$ . The derivative map $dg\colon \Bbb R^2\to L(\Bbb R^2,\Bbb R^2)$ is continuous implies $dg_{x_n}\to dg_x$ , and this convergence an be thought as convergence of $2\times 2$ -matrices. As $\text{rank}(dg_{x_n})=1$ , we have $\text{rank}(dg_x)$ is either $0$ or $1$ . From the assumption, $\text{rank}(dg_x)=1$ . Let $\widehat i,\widehat j\in \Bbb R^2\cong T_{x_n}\Bbb R^2$ be two perpendicular unit vectors. So, $dg_{x_n}(\widehat i)\to dg_x(\widehat i)$ and $dg_{x_n}(\widehat j)\to dg_x(\widehat j)$ . Since, $dg_{x_n}(\bullet)\parallel v_n$ we have $\big\langle dg_{x_n}(\widehat i), g(x_n)\big\rangle=0=\big\langle dg_{x_n}(\widehat j), g(x_n)\big\rangle$ , hence convergence of inner-product gives $$\big\langle dg_{x}(\widehat i), g(x)\big\rangle=0=\big\langle dg_{x}(\widehat j), g(x)\big\rangle,$$ i.e., $\text{im}(dg_x)=T_{g(x)}(S_1)$ . Is my attempt correct? Is there any other way of doing this?","['differential-topology', 'solution-verification', 'smooth-manifolds', 'differential-geometry']"
4264054,Does there exist an invertible nonlinear function in $GF(p)$?,"Given $GF(p)$ , does there exist a nonlinear function $y=f_a(x)$ such that every element $x\in GF(p)$ uniquely maps to an element $y\in GF(p)$ ? Of course, $y=x$ is a trivial linear example. However, when I plot $f_a(x_a), \cdots, f_a(x_p)$ , I want the result to appear random, similar like the scatter plot in https://upload.wikimedia.org/wikipedia/commons/c/c3/Polynomial_over_a_finite_field_as_per_SSSS.png but no two values of $x$ must generate the same $y$ (in other words, the output space must include all elements). If possible, the parameter $a$ should parameterize the function such that a different, randomly looking behavior is obtained.","['number-theory', 'finite-fields', 'discrete-mathematics']"
4264155,"Given a triangle $ABC$ with angle $ABC=120^\circ$, side $AB =10$ cm and median $BM =2$ cm, what is the length of $BC$?","Given a triangle $ABC$ with angle $ABC=120^\circ$ , side $AB =10$ cm and median $BM =2$ cm, what is the length of $BC$ ? Above I have attached a picture of what my approach to it was. I extedended the median $BM$ by $2$ times and obtained parallelogram $ABCD$ . We then have $\angle BAD=60^\circ$ . Letting $\angle ADB=\theta$ and using the Sine Rule, I get $$\frac{\sin(60^\circ)}{4}=\frac{\sin(\theta)}{10}$$ However, this does not seem to yield any real value for $\theta$ . I was going to continue by then finding $\angle ABD$ and again applying the sine rule to find $AD$ . Where did I go wrong in order to not obtain a real value for $\theta$ ?","['euclidean-geometry', 'triangles', 'geometry']"
4264185,Probability of having exactly $v$ different letters in password,"Consider a password with $t$ characters, with a character set of length $n^2$ . What is the probability there are $v$ distinct letters in the password. So if the password was ""abccdadde"" $v$ would be $5$ and $t=9$ . So far I have deduced if $t=n=v$ the probability is given by: $$\frac{n^{2}!}{\left(n^{2}-n\right)!n^{2n}}$$ And when $t=v+1=n+1$ the probability is given by: $$\frac{n\left(n+1\right)!n^{2}!}{2n!\left(n^{2}-n\right)!n^{2\left(n+1\right)}}$$","['summation', 'functions', 'combinatorics', 'probability']"
4264207,Binomial Expansion related problem,If ${}^n{C_0} - {}^n{C_1} + {}^n{C_2} - {}^n{C_3} + .. + {\left( { - 1} \right)^r}{}^n{C_r} = 28$ . Then find the value of $n$ . My approach is as follow ${}^n{C_0} - {}^n{C_1} + {}^n{C_2} - {}^n{C_3} + .. + {\left( { - 1} \right)^r}{}^n{C_r} = 28 = {}^8{C_2} = {}^8{C_6}$ ${\left( {1 - x} \right)^n} = {}^n{C_0} - {}^n{C_1}x + {}^n{C_2}{x^2} - {}^n{C_3}{x^3} + .. + {\left( { - 1} \right)^n}{}^n{C_n}.{x^n}$ Putting x=1 ${}^n{C_0} - {}^n{C_1} + {}^n{C_2} - {}^n{C_3} + .. + {\left( { - 1} \right)^n}{}^n{C_n} = 0$ $ \Rightarrow 28 + {\left( { - 1} \right)^{r + 1}}{}^n{C_{r + 1}} + .. + {\left( { - 1} \right)^n}{}^n{C_n} = 0$ How do I approach from here,['combinatorics']
4264227,Find the range of function $f(x) = \frac{4-x}{x-4}$,"We have to find the range of the function, $y = \dfrac{4-x}{x-4}$ My approach:- I know the first method to find the range of a function by finding  the domain of inverse function. $y = \dfrac{4-x}{x-4}$ $\implies y(x-4) = 4-x$ $\implies xy - 4y = 4-x$ $\implies xy +x = 4+4y$ $\implies x(y+1) = 4(y+1)$ $\implies x = \dfrac{4(y+1)}{(y+1)}$ Now, here $y$ cannot be equal to $-1$ . Therefore the range of the function is $\mathbb{R} - \{-1\}$ The second method is :- $y= \dfrac{4-x}{x-4}$ $y = \dfrac{-(x-4)}{(x-4)}$ $y  = -1$ Therefore the range of the function is $\{-1\}$ I checked my answer on wolfram alpha, $\{-1\}$ is the correct answer. But what's the mistake in the first method? Which step is incorrect? Further more, I tried to check my solution step by step on desmos by plotting the graph. What I found is that the graphs from 1st to 6th step are same but the graph changed at the step when I got $x = \dfrac{4(1+y)}{(1+y)}$ . I need help here. Thanks in advance!",['functions']
4264239,Directly showing $\lim_{n\to\infty}n\sum_{k=0}^n \binom{n}{k}(-1)^k\zeta (k+2) =1$,"In this question it is shown, up to a small detail or two, that $$\lim_{n\to\infty}n\cdot \sum_{m=1}^{\infty}\Big(1-\frac{1}{m}\Big)^n\cdot \frac{1}{m^2}=1$$ The proof essentially involves Taylor series and reimagining the sum as a Riemann integral to show a lower bound and an upper bound each converge to $1$ . However, I believe the problem can be solved a different way. If we use the binomial theorem to expand $(1-1/m)^n$ and swap the resulting double sum, we have $$
\lim_{n\to\infty}n\sum_{k=0}^n \binom{n}{k}(-1)^k\zeta (k+2)
$$ Intuitively, this limit should converge because $\zeta(n+2)\to 1$ as $n\to\infty$ , and then the series looks like $\sum_{0\le k\le n}\binom{n}{k}(-1)^k=0$ , but the asymptotics evade me. Previously I was interested in so-called 'alternating binomial zeta series,' (my own clunky descriptor of this object) and found that convergence was quite delicate and subtle. I tried using Stolz-Cesaro, the discrete version of L'Hopital's Rule, but was unsusccessful, though maybe it's possible through this or other means.","['complex-analysis', 'sequences-and-series', 'riemann-zeta', 'limits', 'convergence-divergence']"
4264245,Expected closest distance to a point,"Consider $X_1, X_2, \dots X_n $ all I.I.D Uniform $[0,1]$ . What is the expected distance from a uniformly selected point to its closest neighbour? I know that the expected point closest greater than it is $\frac{1}{n+1}$ . And the same result for expect point closest less than it is $\frac{1}{n+1}$ . This is clearly an upper bound on our answer. Notice the problem has a lack of symmetry. That is the expected closest point to $0$ is $\frac{1}{n+1}$ But the expected closest point to $\frac{1}{2}$ is $\frac{1}{2(n+1)}$ We do however have symmetry around one half. I wanted to condition the expectation on the selected point and integrate. I was thinking of using the law of total expectation. The sigma-algebra being generated by the number of points in $[0,2x]$ and using linearity rescale the expected closest point to $\frac{1}{2}$ . However when using the Tower Rule we have a Binomial RV on the denominator and this is tricky. Reforming the problem as this: Let $X \sim $ Uniform $[0,1]$ Then $Y_1 , Y_2 , \dots Y_{n-1}$ be IID Uniform $[0,1]$ and we are after $\mathbb{E}$ [Min $_{i \in [1,n-1]}$$\{ |X - Y_i| \}$ ] We could then find the CDF, differentiate for PDF and integrate for expectation, due to symmetry around $\frac{1}{2}$ consider only $x \in[0,\frac{1}{2}]$ Which of my methods seems most fruitful ? Is there much simpler way of doing this? If it helps here is a plot with values $n=2$ to $n=20$","['statistics', 'probability']"
4264261,Doubt about Probability Question,"There is a box containing $20$ green marbles, $20$ blue marbles, and $20$ purple marbles. You draw $10$ marbles at random without replacement. What is the probability that you do not get all the colors? The solution in the book: $\Large 3\frac{\binom{20}{10} \binom{40}{0}}{\binom{60}{10}} + 3\frac{\binom{40}{10} \binom{20}{0}}{\binom{60}{10}} $ I believe the book seperated into cases. Case 1: All the marbles are exactly $1$ color. Case 2: All the marbles are exactly $2$ colors. I feel like the solution is wrong because there is overcounting in the second case. If we lump together $2$ colors , such as green and blue marbles, that gives us $40$ marbles and choose $10$ . However this also includes cases such as all green, since we could draw all $10$ green.",['probability']
4264307,When is the orbit of a vector spanning the whole space?,"Let $\rho:G\to\mathrm{GL}(V)$ be a linear representation of a finite group $G$ over a complex vector space $V$ . One may ask whether there is a point $v\in V$ so that the orbit $\rho(G)v$ spans all of $V$ . Apprently there is an answer in terms of characters: If $\chi$ is the character of $\rho$ and $\psi_1,...,\psi_m$ is an enumeration of the irreducible characters of $G$ , then such a point exists if and only if $\langle \chi,\psi_i\rangle \le \psi_i(1)$ for all $i\in\{1,...,m\}$ . I thought about this and found an involved topological argument. But this seems like a basic and well-known fact. So I wonder, what is the easiest proof that you know of? And do we need to assume some machinery or does it quickly follow from first principles?","['characters', 'representation-theory', 'vector-spaces', 'linear-algebra', 'linear-transformations']"
4264317,differential volume form under two parameterizations,"I am trying to solidify my understanding of differential volume form by integrating the same section of the unit sphere using two separate parameterizations.  With the parameterization $\varphi^{-1}_1(\phi, \theta)=(\sin\phi\sin\theta, \sin\phi\cos\theta, \cos\phi)'$ , $A_1 := \{ (\phi, \theta): \phi\in (0, \pi/4), \theta \in (0,\pi)\}$ , I calculate the integral according to Amann (2009) : $$\text{Vol}_{g, U}(A) := \int_{\varphi(A)} \sqrt{\det(D {\varphi^{-1}}'D \varphi^{-1})} da$$ which here is just $$\text{Vol}_{g, U}(A_1) := \int_{0}^\pi \int_0^{\pi/4} |\sin \phi| ~d\phi~ d\theta \approx 0.920151.$$ Next, I use the parameterization $\varphi^{-1}_2(x,y)=(x, y, \sqrt{1-x^2-y^2})'$ , $A_1 := \{ (x,y): x\in \left(-\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right), y \in (0,\sqrt{\frac{1}{\sqrt{2}} - x^2})\}$ (which I think should be the same section of the sphere) to get $$\text{Vol}_{g, U}(A_2) := \int_{-\frac{1}{\sqrt{2}}}^\frac{1}{\sqrt{2}} \int_0^{\sqrt{\frac{1}{\sqrt{2}} - x^2}} \left|\frac{1}{\sqrt{1-x^2-y^2}}\right| ~dy~ dx \approx 1.30593.$$ So, two questions: Where am I going wrong here?  I think that the spherical coordinates one is okay.  I would really like an example where it matches the direct parameterization. I believe that $|\sin \phi|d\phi\theta$ in its entirety is the Riemannian volume form -- is this correct? Thanks! Edit Oct1: I've added a photo of the region.","['multivariable-calculus', 'geometry', 'riemannian-geometry', 'differential-geometry']"
4264390,Prove that: $F(F(n)) \equiv F(F(n) \mathbin{\%} \pi(m)) \bmod m$,"If $F(n)$ is the $n$ -th number in a Fibonacci sequence and $\pi(m)$ is a Pisano period of $m$ . Proposition: $$F(F(n)) \equiv F(F(n) \mathbin{\%} \pi(m)) \bmod m$$ This is a proposition I encountered while solving a competitive programming problem and I really want to understand/prove it. Since I just started my freshman year in university, I really need a detailed explanation for this one.","['number-theory', 'fibonacci-numbers', 'problem-solving']"
4264475,"Prove that if a subgroup $H$ generated by $x$ is of infinity order, then $H=\langle x^a\rangle$ iff $a = ±1$","I am trying to prove a proposition in Dummit and Foote book which says: Let $H = \langle x \rangle$ . Assume $|x| = \infty$ .Then $H = \langle x^a \rangle$ if and only if $𝑎=±1$ . My attempt was:
If $𝑎=±1$ , then obviously $H = \langle x^{-1} \rangle = \langle x \rangle$ , since for $H$ to be a group it must also contain inverses of $x$ . Conversely, if $H = \langle x^a \rangle$ , we have $|x| = \infty$ hence $|H| = \infty$ , which implies $|x^a| = \infty$ , from here I don't know how to prove that $𝑎=±1$ . I know that $x^a \neq 1$ for all non zero $a$","['group-theory', 'cyclic-groups', 'infinite-groups']"
4264496,Any bound on the Jensen's inequality with absolute value?,So we have the jensen's inequality: $$|EX| \leq E|X|$$ Any bound on the Jensen gap (upper bound or lower bound)? $$\text{gap}=E|X| - |EX|$$,"['jensen-inequality', 'probability-theory', 'probability', 'random-variables']"
4264501,Does $ \mathbb{E}\Big(\min_{1\leq j\leq J} |\epsilon_j|\Big)=\infty $ imply heavy tails?,"Consider $J$ continuous random variables $$
\epsilon_1,\dots, \epsilon_J
$$ Suppose $$
\mathbb{E}\Big(\min_{1\leq j\leq J} |\epsilon_j|\Big)=\infty
$$ Could you help me to ""graphically"" interpret this condition? In particular, does it mean that there is an issue of heavy tails? If not, is there any other intuitive interpretation?","['integration', 'expected-value', 'probability-theory', 'probability']"
4264508,Identifying $\mathcal{O}_X(-1)$ with the blow-up of the cone of $X$ at the origin,"Let $X$ be a projective variety in $\mathbb{P}^n.$ I'm trying to prove the following fact that the total space of the line bundle $\mathcal{O}_X(-1)$ is isomorphic to the blow-up of the affine cone $\widehat{X}$ at the origin in $\mathbb{A}^{n+1}$ . The statement is quite obvious to me visually, but I'm getting stuck proving it in the language of schemes. I can prove that $X\simeq \text{Proj}(\bigoplus _{n\geq 0} H^0(X,\mathcal{O}_X(n)))$ , so $\widehat{X}\simeq \text{Spec}(\bigoplus _{n\geq 0} H^0(X,\mathcal{O}_X(n)))$ , and hence $Bl_0{\widehat{X}}=\text{Proj}(\bigoplus I^n)$ , where $I$ should be the ideal generated by the images of $x_0,\cdots,x_n$ in $H^0(X,\mathcal{O}_X(1))$ .
On the other hand, the underlying space of $\mathcal{O}_X(-1)$ is given by $|\mathcal{O}_X(-1)| = \text{Spec}(Sym^{\cdot}\mathcal{O}_X(1))$ , where $Sym^{\cdot}$ denotes the symmetric algebra. But at this point, I'm stuck. Any help would be appreciated.","['algebraic-geometry', 'projective-geometry', 'line-bundles']"
4264555,"if $\mathrm{ord}_p(b)\mid \mathrm{ord}_p(a)$ for all sufficiently large prime p, is $b$ necessarily a power of $a$?","Let $a$ and $b$ be integers, and denote by ${\rm ord}_p(a)$ the $\textbf{multiplicative order}$ of $a$ modulo $p$ . Assume that there exists a constant $K$ such that for all prime $p>K$ , ${\rm ord}_p(b)$ divides ${\rm ord}_p(a)$ .
Is it that $b$ is a power of $a$ ? I came up with this question, but I don't know if it's true or false, and I have no idea how to deal with it. Could you help me? Thanks.","['modular-arithmetic', 'number-theory', 'arithmetic', 'group-theory', 'prime-numbers']"
4264557,Why is this limit $\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)$ not $0$?,"I have this limit: $$
\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)
$$ For me my initial answer would be zero as: $$
\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)=\lim_{x\to \infty}x^2-\lim_{x\to \infty}x^2\cdot\lim_{x\to \infty}\cos\left(\frac{1}{x}\right)
$$ Which is: $$
\infty-\infty\cdot1=0
$$ But after looking at wolfram alpha and doing a series expansion of $\cos(x)$ i see that the answer is in fact $1/2.$ Why is my original thinking incorrect?",['limits']
4264569,Designing a general function that describes pharmacodynamic data,"I am interested in coming up with a function describing the dose-dependent action of a drug over time. In this specific case, the image attached below shows the glucose infusion rate (GIR) of the insulin ""Lyumjev"", where the GIR represents the amount of glucose that needs to be infused into a patient to keep that patient's blood glucose level constant. It's therefore a sort of surrogate marker for insulin action. If you look at the image, you can see that that there's an extremely steep, linear climb during the first hour, followed by a broad peak or plateau before the required GIR slowly drops back to zero. Depicted are the GIRs for three doses (7, 15 or 30 units of insulin), and if you look closely you can see that the plateaus become higher and broader, and the duration of insulin action becomes longer in dependence of the dose. I could use simple software like Excel to describe each of the three curves using, e.g., simple polynomial fits, but this won't let me predict the likely curve for, say, 5 U or 10 U of this insulin. To really solve this issue, I will have to come up with a general function that takes the insulin dose as an argument, but I have no idea how to do this and where to start. What I know The dose (I would like to plot curves for whichever dose I enter) Area under the curve (put simply, the AUC more or less scales linearly with the dose such that 2 U of insulin will have double the AUC of 1 U, but the distribution will be slightly shifted towards later hours as shown in the image) I am not sure if my question is naive, but is there a way to ""design"" an equation like this? I did check pharmacokinetic equations that I found on the web, but the issue is that these normally describe serum drug levels over time, and those I have tried did not alter the distribution of the drug over time, but instead only altered the height of the peak. I appreciate any hint you may have on where to start, or where to look... thanks a lot in advance! Glucose infusion rate over time, plotted for three insulin doses: The picture is taken from the EMA's assessment report for the drug Lyumjev. ( https://www.ema.europa.eu/en/documents/assessment-report/liumjev-epar-public-assessment-report_en.pdf page 69)","['functions', 'mathematical-modeling']"
4264605,Orthogonality in Sobolev $H^1$.,"Consider $H^1(-1,1)$ Sobolev space with natural dot product: $\langle f, g\rangle_{H^1} = \langle f, g\rangle_{L^2} + \langle f', g'\rangle_{L^2}$ . Let $U$ be the space of functions: $f(x) = 0$ $\forall x \le 0$ . We want to know $U^\perp$ . The first thing is $U^\perp = \{f: f(x) = 0, x > 0\}$ . But I guess the same trick (consider a neighborhood of zero) as for $C[-1,1]$ with $\langle f, g\rangle = \int_{-1}^1 f(x) g(x) dx$ doesn't work. But I guess the latter family of functions obviously orthogonal to the $U$ . But maybe there is something else? I've tried so: $$
\int_{0}^{t} f g + \int_{0}^{t} f'g' = \int_{0}^t f g + f(t)g'(t) - \int_0^t f(x) g''(x) dx=0 \iff$$ $$f(t) g(t) + f'(t) g'(t) + f(t) g''(t) - f(t)g''(t) + f(0)g''(0) = 0
$$ Hence we obtain something like: $f(t) = \bar{C}\exp\left(-\displaystyle\int \dfrac{g + c}{g'} dt\right)$ . But here we assume that there is exists $g''$ (which might be not true). Any ideas?","['sobolev-spaces', 'functional-analysis']"
4264607,Relation between polynomial division and derivative,"$P(x)$ is a polynomial and it is equal to $2x^3 + 2ax^2 +bx +c$ . It is given that $P(x)$ can be divided by $(x-1)^3$ with zero remainder. Then , what is $c$ ? This is a basic polynomials question, to reach the solution we use derivative for shortcut. For example, we find $P(1) ,P'(1),P''(1)$ respectively. Then answer is $2$ .. My question is why we use derivative, I could not conceive the reason behind the usage of derivative. In first thought, I thought that if $(x-1)^3$ divides $P(x)$ , then $(x-1)^2$ and $(x-1)$ divides $P(x)$ , as well. However, I could not see any relation with derivative. Can you enlighten me?","['algebra-precalculus', 'derivatives', 'polynomials', 'real-analysis']"
4264655,Is there a closed form for this mean of conditional expected order statistics?,"$X_1, X_2, X_3, ..., X_n$ are iid distributed according to $U[0,1]$ .
Computing the mean of the expected order statistics is easy: $$\frac{1}{n}\sum_{i=1}^n\mathbb{E}[X_{(i)}] = \sum_{i=1}^n \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX = \frac{1}{2}.$$ Instead I would like to multiply each order statistic by the probability that it lies below some value $z$ . $$\sum_{i=1}^n F_i(z) \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX = \sum_{i=1}^n \sum_{j=i}^n {n \choose j}z^j(1-z)^{n-j} \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX $$ Suddenly the computation is not so easy anymore. Is there a closed form?","['statistics', 'order-statistics', 'conditional-expectation', 'probability']"
4264714,Tail bound implies sub-Gaussian,"A random variable $X$ is sub-gaussian with parameter $\sigma^2$ if for all $ \lambda \in \mathbb{R}$ , we have that $$\mathbb{E} e^{\lambda(X - \mathbb{E} X)} \leq e^{\lambda^2\sigma^2/2}$$ I want to show that if a r.v. $X$ satisfies the tail bound: for all $t \geq 0$ , we have $$P(X - \mathbb{E} X \geq t) \leq e^{-t^2/2\sigma^2} \text{ and } P(X - \mathbb{E} X \leq -t) \leq e^{-t^2/2\sigma^2}$$ then $X$ is sub-gaussian with parameter $c \cdot \sigma^2$ for some constant $c$ . My idea was to use that for a nonnegative random variable $Z$ we have that $\mathbb{E} Z = \int_0^{\infty} P(Z \geq t) \,dt$ and apply this to $Z = e^{\lambda(X - \mathbb{E} X)}$ , but this gave a messy integral that I couldn't easily bound with what I wanted, and also only used the first half of the tail bound.","['moment-generating-functions', 'probability-theory']"
4264723,"Selection rules: Why is $\frac1m\sum_g\sum_{\lambda}^{\oplus} \underline{\underline{I}}_{\,\lambda}\otimes\underline{\underline{D}}^{(\lambda)}(g)=0$?","Here is the derivation from some notes given to me. I uploaded these handwritten notes for 2 reasons: To show you that this is the only source of information I have available to me (and it's incredibly difficult to learn from it). In the hopes that you can make more sense of them than I can. There are two expressions in these notes for which I would like to understand, which I have marked with red question marks above the relevant expressions. For the first expression, $$\frac1m\sum_g\underline{\underline{D}}^{(\lambda)}(g)=\begin{cases}
0,  & \text{for rest of $\lambda$'s} \\
1, & \text{$\lambda$ for fully symmetric IRREP}
\end{cases}$$ The $\underline{\underline{D}}^{(\lambda)}(g)$ in this expression (I think) is supposed to represent the triple direct product at the top of the page, namely, $$\underline{\underline{D}}^{(\lambda)}(g)\equiv\Big[{\underline{\underline{D}}^{(1)}}^*\otimes {\underline{\underline{D}}}^{\prime} \otimes {\underline{\underline{D}}^{(2)}}\Big]_{n,\,\beta,\,p,\, i,\,\alpha,\,j}$$ This $\frac1m\sum_g\underline{\underline{D}}^{(\lambda)}(g)$ as I understand it is not an orthogonality expression (but it should be), else how can it possibly be equal to zero or $1$ ? While in the middle of constructing this question I was able to find a PDF version of a book $^{\large\zeta}$ that has a specific chapter that derives selection rules in a remarkably similar way to the notes I have above: I would like to know why ""We note that the sum of matrices of any irreducible representation, other than the identity representation, over the group, is equal to the zero matrix (see Exercise 3.7)"". Which is written in the paragraph underneath equation $(21.7)$ above. This exercise 3.7 has been asked about and answered here which I found earlier and put a comment below the question to indicate the source. User @ Gerry Myerson answered that question, but I am unable to understand his proof. So in summary, I would like to know why $\sum_g\sum_{\lambda}^{\oplus} \underline{\underline{D}}^{(\lambda)}(g)=0?$ Or, if you prefer, could someone please prove why the sum over a group of the matrix elements of any irreducible representation other than the identity/fully symmetric/trivial representation is equal to zero? Update: Although this update possibly should be asked as a separate question and if I am told to do this then I will comply, the reason I ask it here is that it is simply regarding applications of the expression given in the title to this post. I have a few small questions regarding the final page of the authors' written lecture notes (page 74), embedded as an image: As ever, I have scribbled red question marks over the parts I don't understand. I know that for a direct product of two matrices, say $\underline{\underline{A}}=\begin{pmatrix}a_{11}& a_{12}\\a_{21}& a_{22}\\ \end{pmatrix} \,\, \text{and} \,\,\,\underline{\underline{B}}=\begin{pmatrix}b_{11}& b_{12} & b_{13}\\b_{21}& b_{22}& b_{23}\\b_{31}& b_{32}& b_{33} \end{pmatrix}\implies\underline{\underline{A}}\otimes \underline{\underline{B}}=\begin{pmatrix}a_{11}\,\underline{\underline{B}}& a_{12}\,\underline{\underline{B}}\\a_{21}\,\underline{\underline{B}}& a_{22}\,\underline{\underline{B}}\\ \end{pmatrix}$ But that was the direct product for matrices, how does this direct product work for characters? So looking at the character table for $C_{3v}$ the author of these notes written that for $z$ - polarised light $\langle\psi_{A_1}|\hat z | \psi_E\rangle$ for which the decomposition, ${\color{red}{\chi_{A_1}\otimes\chi_{A_1}}}\otimes\chi_E=\chi_E\ne\chi_{A_1}$ . Although I know that for a transition to be allowed, its matrix element must be non-zero, as shown to me in the proofs by @ Gerry Myerson and @ lEm . Therefore, to be non-zero the decomposition must contain the trivial representation, which in this case (from the $C_{3v}$ character table) is the IRREP $A_1$ , but why is $\chi_{A_1}\otimes\chi_{A_1}\otimes\chi_E=\chi_E$ ? Is the red part equal to 1? I know this information is coming from the character table somehow, but I don't understand how. The author then determines whether the matrix element, $\langle\psi_{A_1}|\hat x | \psi_E\rangle$ for the same transition ( $A_1 \to E$ ) for $x$ -polarised light is non-zero by the decomposition, $\chi_{A_1}\otimes\chi_{E}\otimes\chi_E=\chi_E=(4,1,0)$ . But, where does this $(4,1,0)$ come from and how does this 'contain $A_1$ '? I looked at the $C_{3v}$ character table and naively note that summing together the totals for the 3 columns gives $(4,1,0)$ , but this could just be a coincidence. I won't ask about the last 2 red question marks for now, since I may be able to answer them once I've understood the first two. Edit: @lEm Okay, I think I see it now, the $(4,1,0)$ is the whole row of $E$ multiplied by itself, not sure why though. Need to think more, any hints please anyone? $^{\large\zeta}$ The textbook page 265 embedded in this post as an image is from ""Applications of group theory in quantum mechanics"" by Petrashen & Trifonov.","['direct-product', 'representation-theory', 'direct-sum', 'matrices', 'group-theory']"
4264772,Taking second derivative of multivariate normal density wrt covariance matrix,"In attempting to compute the second derivative of the density of a $d$ -dimensional $\mathrm{MVN}(\pmb0,\Sigma)$ random variable with respect to $\Sigma$ , I am running into an issue. In particular, I am having trouble figuring out the order of multiplication from element-wise notation. I am also having difficulties figuring out how to translate an expression from element-wise notation to matrix notation. I am looking for an answer to the order of multiplication and at least some tips on how to move forward with the final expression below. For $\Sigma=(\sigma_{ij})$ , set $\nabla_\Sigma=(\partial_{\sigma_{ij}})$ . For the pdf, write $$p(x)=(2\pi)^{-d/2}|\Sigma|^{-1/2}\exp\left(-\frac{1}{2}x^\top\Sigma^{-1}x\right).$$ Then we have $$\nabla_\Sigma p(x)=(2\pi)^{-d/2}\left[|\Sigma|^{-1/2}\nabla_\Sigma\exp\left(-\frac{1}{2}x^\top\Sigma^{-1}x\right)\\
+\exp\left(-\frac{1}{2}x^\top\Sigma^{-1}x\right)\nabla_\Sigma|\Sigma|^{-1/2}\right]$$ $$=-\frac{1}{2}(2\pi)^{-1/2}\exp\left(-\frac{1}{2}x^\top\Sigma^{-1}x\right)\left[|\Sigma|^{-1/2}\Sigma^{-1}xx^\top\Sigma^{-1}-|\Sigma|^{-3/2}|\Sigma|\Sigma^{-1}\right]$$ $$=\frac{p(x)}{2}\left[\Sigma^{-1}-\Sigma^{-1}xx^\top\Sigma^{-1}\right].$$ Hence, $\nabla_\Sigma\nabla_\Sigma p(x)=[\nabla_\Sigma(p(x)\Sigma^{-1})-\nabla_\Sigma(p(x)\Sigma^{-1}xx^\top\Sigma^{-1})]/2$ . Beginning with $\nabla_\Sigma(p(x)\Sigma^{-1})$ , I go component-wise to get $$\partial_{\sigma_{ij}}p(x)(\Sigma^{-1})_{kl}=p(x)\partial_{\sigma_{ij}}(\Sigma^{-1})_{kl}+(\Sigma^{-1})_{kl}\partial_{\sigma_{ij}}p(x)$$ $$=-p(x)(\Sigma^{-1})_{ik}(\Sigma^{-1})_{lj}+(\Sigma^{-1})_{kl}\partial_{\sigma_{ij}}p(x).$$ Here I come to my first question. Should $(\Sigma^{-1})_{kl}\partial_{\sigma_{ij}}p(x)$ correspond to $\Sigma^{-1}\otimes\nabla_\Sigma p(x)$ or $\nabla_\Sigma p(x)\otimes\Sigma^{-1}$ ? How can I tell? Assuming the former provides $$\nabla_\Sigma(p(x)\Sigma^{-1})=-p(x)\Sigma^{-1}\otimes\Sigma^{-1}+\Sigma^{-1}\otimes\nabla_\Sigma p(x)$$ $$=\frac{p(x)}{2}\Sigma^{-1}\otimes\left[\Sigma^{-1}-\Sigma^{-1}xx^\top\Sigma^{-1}\right].$$ For $\nabla_\Sigma[p(x)\Sigma^{-1}xx^\top\Sigma^{-1}]$ , I also proceed component-wise: $$\partial_{\sigma_{ij}}\left[p(x)\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k(\Sigma^{-1})_{kj}\right]=p(x)\partial_{\sigma_{ij}}\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k(\Sigma^{-1})_{kj}+\left[\partial_{\sigma_{ij}}p(x)\right]\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k(\Sigma^{-1})_{kj}.$$ Since the right-most component corresponds to either $\nabla_\Sigma p(x)\otimes\Sigma^{-1}xx^\top\Sigma^{-1}$ or $\Sigma^{-1}xx^\top\Sigma^{-1}\otimes\nabla_\Sigma p(x)$ , I focus on the left component, dropping the $p(x)$ for brevity $$\partial_{\sigma_{ij}}\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k(\Sigma^{-1})_{kj}=\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k\partial_{\sigma_{ij}}(\Sigma^{-1})_{kj}+(\Sigma^{-1})_{kj}x_lx_k\partial_{\sigma_{ij}}(\Sigma^{-1})_{il}$$ $$=-\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k(\Sigma^{-1})_{ki}(\Sigma^{-1})_{jj}+(\Sigma^{-1})_{kj}x_lx_k(\Sigma^{-1})_{ii}(\Sigma^{-1})_{jl}$$ $$=-(\Sigma^{-1})_{jj}\sum_{k,l}(\Sigma^{-1})_{il}x_lx_k(\Sigma^{-1})_{ki}-(\Sigma^{-1})_{ii}\sum_{k,l}(\Sigma^{-1})_{kj}x_lx_k(\Sigma^{-1})_{jl}.$$ Since I am not sure how to write this last expression in terms of matrices and Kronecker products, this is where my journey has ended so far. Any ideas for finishing this calculation would be greatly appreciated.","['tensor-products', 'multivariable-calculus', 'normal-distribution']"
4264785,Evaluating $\arccos\left(\cos \left(-\frac{7\pi}{10}\right)\right)$,"I have the problem $$\arccos\left(\cos \left(-\frac{7\pi}{10}\right)\right)$$ But I am confused on it. What I did: find reference angle, which is $\frac{3\pi}{10}$ , and locate its quadrant, which is the first quadrant. I am confused on what to do from here.",['trigonometry']
4264836,"Is it ""safe"" to evaluate $\lim_{x \to \infty} \frac{1}{\frac{1}{x} +x}$ as follows?","If I want to evaluate the following limit: $$\lim_{x \to \infty} \frac{1}{\frac{1}{x} +x},$$ is it valid to use regular arithemtic rules to come to $$\frac{\lim_{x \to \infty} 1}{\lim_{x \to \infty} \frac{1}{x} +\lim_{x \to \infty} x}?$$ Evaluating existing limits gives $$\frac{1}{0 +\lim_{x \to \infty} x},$$ but writing something such as $$\frac{1}{\infty}=0$$ does not seem legal, although it feels intuitive that the limit is $0$ from the first expression. Is there a more sound way of stating this? Perhaps with different laws of limits which I seem to be lacking knowledge of? Thanks in advance for your help!","['limits', 'limits-without-lhopital']"
4264892,Prove that an arc segment of an ellipse cannot be similar to an arc segment of an ellipse with different eccentricity.,"I would like to know if there is any proof to this: Prove that an arc segment of an ellipse cannot be similar to an arc segment of an ellipse with different eccentricity. I specifically exclude circles, which can be considered ellipses with coincident focal points. Motivation: this seems obvious to me, and maybe to many others, I'm curious if there's any formal proof of it mathematically. I should add: I may be wrong and this may not actually be the case. I would like a formal proof of the *negation, if that's the case.",['geometry']
4264911,Complementary Trigonometric relationship for sine and cosine,"To begin, let's start with the first quadrant in the unit circle: It's easy to see why(due to complementary angles): $$\cos\left(\frac{\pi}{2}-\theta\right) = \sin(\theta)$$ $$\sin\left(\frac{\pi}{2}-\theta\right) = \cos(\theta)$$ But what about Quadrant 2, 3 and 4, how do I visualise and prove these using the unit circle? Q2: $$\sin\left(\frac{\pi}{2}+\theta\right) = ???$$ $$\cos\left(\frac{\pi}{2}+\theta\right) = ???$$ Q3: $$\sin\left(\frac{3\pi}{2}-\theta\right) = ???$$ $$\cos\left(\frac{3\pi}{2}-\theta\right) = ???$$ Q4: $$\sin\left(\frac{3\pi}{2}+\theta\right) = ???$$ $$\cos\left(\frac{3\pi}{2}+\theta\right) = ???$$","['trigonometry', 'functions', 'circles', 'triangles']"
4265033,Structure on $\mathbb{R}$ such that homomorphisms $\mathbb{R} \to \mathbb{R}$ are exactly polynomials?,"If we consider $\mathbb{R}$ as a vector space over the field $\mathbb{R}$ , then the maps $\mathbb{R} \to \mathbb{R}$ preserving this structure are exactly the linear maps $x \mapsto ax$ . In contrast, if we think of $\mathbb{R}$ as an affine space instead, the maps preserving this structure are exactly the affine maps $x \mapsto ax + b$ . Is it possible to ""forget"" even more structure, and have a structure on $\mathbb{R}$ such that the maps $\mathbb{R} \to \mathbb{R}$ preserving this structure are exactly the polynomials? I'll leave it up to you what ring to take coefficients of polynomials from. If anyone could do it for $\mathbb{N}$ , $\mathbb{Z}$ , $\mathbb{Q}$ , $\mathbb{C}$ instead, I'll be equally happy.","['model-theory', 'linear-algebra', 'polynomials']"
4265080,Gradient of a multi-dimensional multi-variable function,"(First of all, feel free to suggest a better title for the question, I might just be totally missing the naming, hence not finding my answer because of that :) ) I understand how to compute the partial derivative of some function $f(x, y)$ , with respect its different variables, and how to get the gradient of the function from that. Now, if I have a function $f$ that takes, let say, two 2D vectors $p1$ and $p2$ as inputs and I want to find the gradient of this function with respect to each point $\nabla_{p1}f(p1, p2)$ and $\nabla_{p2}f(p1, p2)$ . This is where I'm totally lost. How is this computed ? For example, if $f(p1,p2) = |p1 - p2| - d$ , $|p1 - p2|$ being the distance between the two points (or the norm of the vector defined by those points) and $d$ being a constant, how does one compute $\nabla_{p1}f(p1, p2)$ and $\nabla_{p2}f(p1, p2)$ ? In that case, the results I need to find are $$\nabla_{p1}f(p1, p2) = \frac{p1-p2}{|p1 - p2|}$$ and $$\nabla_{p2}f(p1, p2) = -\frac{p1-p2}{|p1 - p2|}$$ but I do not understand how to find this result. Edit:
To add a bit more context, I want to understand how to compute those formulas to be able to put them in a computer graphics physics simulation loop (namely using Position-Based Dynamics ).
The function $f$ is in fact a constraint between the inputs (in that case, we want the two points to keep a certain distance from each other).","['multivariable-calculus', 'calculus']"
4265149,canonical divisor and different ideal,"Let $X=\operatorname{Spec } O_K$ where $K$ is a number field. On one side we have the notion of canonical class $\mathcal K_X$ that is the divisor class associated to the sheaf $\Omega^1_{X|\mathbb Z}=\mathcal O^\vee_X$ . But on the other hand one can define the different divisor $\mathfrak D_K$ associated to the different ideal $\delta_K$ . What is the relationship between the divisors $\mathfrak D_K$ and $\mathcal K_X$ ? Are they the same? As far as I know $\mathfrak D_K$ should be the ""right"" arithmetic generalisation of the canonical divisor if one looks at the arithmetic Riemann-Roch theorem.","['algebraic-number-theory', 'algebraic-geometry', 'divisors-algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
4265157,Statement of Well-ordering principle,"The statement of well ordering principle appears in different mode - on subsets of natural numbers, or well-ordering of every (non-empty) set. For the question below, I am considering it w.r.t. non-empty subsets of natural numbers. The question below appeared in my mind, and I was unable to justify myself by referring various articles/books. It started from proof of Division Algorithm. Let $a>b>0$ be integers. Then there are (unique) integers $q$ and $r$ such that $a=bq+r$ where $0\le r<q$ . Proof: Consider $S=\{ a-bn \,\,| \,\, n\in \mathbb{Z}_{\ge 0}, \,\, a-bn\ge 0\}.$ Then $S$ is non-empty (since $a\in S$ ) subset of $\mathbb{Z}_{\ge 0}$ ; by well-ordering principle, it contains least element, say $r=a-bq$ . ..... [the rest of the proof goes for  proving that $r$ satisfy above conditions.] Question. Since $S$ is finite set,  do we really need well-ordering principle in proof of Division Algorithm? To make more precise, let us make two statements. i) A non-empty finite subset of $\mathbb{Z}_{\ge 0}$ contains least element. ii) A non-empty infinite subset of $\mathbb{Z}_{\ge 0}$ contains least element. So, in statement of well-ordering principle, do we need to include both i) and ii)? (The inclusion of i) and ii) in well-ordering principle is done simply by ignoring the words finite/infinite in these statements.) I was feeling that only ii) is the main part of Well-ordering principle, whereas i) also holds if $\mathbb{Z}_{\ge 0}$ is replaced by $\mathbb{Z}$ or $\mathbb{Q}$ or by $\mathbb{R}$ . But, I am unable to clarify my doubts. Can  anyone clarify my doubts?","['elementary-set-theory', 'well-orders', 'natural-numbers']"
4265173,A “general definition” of Riemann sum,"Suppose $f$ is Riemann integerable in $[0,1]$ .Prove that $$\lim_{n\rightarrow \infty}\frac{1}{\phi(n)}\sum_{1\leq k\leq n,(k,n)=1}f\left(\frac{k}{n}\right)=\int_0^1f(x)dx$$ Here $\phi(n)$ is Euler's function My attempt: Let $\mu$ be the Möbius function. $$\begin{align}
LHS-RHS&=\frac{\sum_{k=1}^{n}\sum_{d|(k,n)}\mu(d)f(\frac{k}{n})}{n\sum_{d|n}\frac{\mu(d)}{d}}-\frac{1}{n}\sum_{k=1}^{n}f(\frac{k}{n})\\
&=\frac{1}{n}\frac{\sum_{k=1}^{n}(\sum_{d|(k,n)}\mu(d)-\sum_{d|n}\frac{\mu(d)}{d})f(\frac{k}{n})}{\sum_{d|n}\frac{\mu(d)}{d}}
\end{align}
$$ But it seems not to work.Does anyone know how to prove it?Thank you",['calculus']
4265182,How do you find Pythagorean triples that approximately correspond to a right triangle with a given angle?,"Given an angle $\theta$ , can I find a Pythagorean triple $(A,B,C)$ such that the corresponding right triangle contains an angle that is as close to $\theta$ as I want? And if so, how? For example suppose $\theta = 56.25^\circ$ . How do I find Pythagorean triples $(A,B,C)$ such that $\tan(56.25^\circ) \approx B/A$ ? Looking at Euclid's formula this is the same as asking for coprime not-both-odd integers $m$ and $n$ such that $$\tan(56.25^\circ) \approx \frac{2mn}{m^2-n^2}\,$$ but this only makes a brute-force search easier. Is there a procedural way to generate such arbitrarily precise triples?","['triangles', 'algebra-precalculus', 'pythagorean-triples', 'trigonometry']"
4265184,How to solve $\lim _{x\to \infty}\dfrac{x^5}{2^x} $ without L'Hospital's Rule [duplicate],"This question already has answers here : How to prove that exponential grows faster than polynomial? (15 answers) Closed 2 years ago . Considering that asymptotically, $2^x$ grows faster than $x^5$ (in the beginning, $x^5$ grows faster than $2^x$ , but there will be a point where $2^x$ outgrows $x^5$ ) then $\dfrac{x^5}{2^x} \rightarrow 0$ as $x \rightarrow \infty$ . Therefore, $$\lim _{x\to \infty}\dfrac{x^5}{2^x}  = 0$$ But in order to solve the limit, I applied  L'Hospital's Rule five times \begin{align}
\lim _{x\to \infty}\dfrac{x^5}{2^x}  & =\lim _{x\to \infty}\dfrac{5x^4}{2^x\ln 2}\\
& = \lim _{x\to \infty}\frac{20x^3}{\ln^2(2)\cdot 2^x} \\
& = \lim _{x\to \infty}\frac{60x^2}{\ln^3(2)\cdot 2^x} \\
& = \lim _{x\to \infty}\frac{120x}{\ln^4(2)\cdot 2^x}  \\
& = \lim _{x\to \infty}\frac{120}{\ln^5(2)\cdot 2^x}   \\
& = \frac{120}{\ln^5(2)}\cdot\lim _{x\to \infty}\frac{1}{2^x} \\
& = 0
\end{align} What would be a more elegant way solve it without using L'Hospital's Rule? Edit Even though, the Limit: $\lim_{n\to \infty} \frac{n^5}{3^n}$ is similar, I found the link provided by Axion004, How to prove that exponential grows faster than polynomial? more interesting. Also, the answer provided by user trancelocation was very interesting and is what I was expecting.","['limits', 'calculus', 'limits-without-lhopital']"
4265230,Find the $x^n$ coefficient of $(1+x+x^2)^n$,"I've tried a bunch of different groupings of the three terms so that I could use the binomial expansion forumula, but I haven't been able to go much further than that. This is an example of what I've tried so far: $$(1+x+x^2)^n=\sum_{n=0}^{\infty} {n \choose k}(1+x)^{n-k}x^{2k}
=\sum_{k=0}^{\infty}\sum_{i=0}^{\infty}{n \choose k}{{n-k} \choose i}x^{2k+i}$$ I decided to show this as it has the closest looking coefficient to the expected answer, which states that the coefficient of $x^n$ is $$\sum_{k=0}^{n}{n \choose k}{{n-k} \choose k}$$ .
I'm assuming I'm taking the wrong approach so I'd appreciate some input.","['multinomial-theorem', 'binomial-coefficients', 'combinatorics', 'multinomial-coefficients', 'generating-functions']"
4265284,"An $m\times n$ table has $0$ or $1$ in each cell. ($m$, $n$ even; at least one $1$.) Show that there exists a ""cross"" of cells whose sum is odd.","A (hard) combinatorics problem: There is a $m \times n$ table, and you write $0$ or $1$ in every cell of the table. Show that there exists a ""cross"" such that the sum of integers written in the cross is odd. (There is at least one cell that has $1$ written on it. $n$ and $m$ are even.) A ""cross"" is the ""+""-like shape that is made when a row and a column intersects. My try: I assumed that all the crosses are even and tried to show a contradiction, but I could not progress further.",['combinatorics']
4265285,Geometric Riemann-Roch for Hyperelliptic curves,"I'm studying Riemann surfaces and I just met the geometric interpretation of Riemann-Roch according to which $$
dim(span(D))=deg D- l(D)
$$ where $D$ is a positive divisor and $span(D)$ is the intersection of every hyperplane intersecting the image of $supp(D)$ via the canonincal map $\phi$ with proper multiplicity.
I see that it is always assumed that the Riemann surface $X$ is not hyperellip^tic so that $\phi$ is an embedding. It is possible to generalize this to the hyperelliptic case? I tried to repeat the argument for an explicit example: the hyperelliptic curve of genus 3 arising by considering $y^2 = x^8+1$ .
Take the points $p_1 = (1,0),\ p_2=(-1,0),\ p_3=(i,0),\ p_4=(-i,0) $ and consider the positive divisor $D = p_1+p_2+p_3+p_4$ . Consider now the canonical map $\phi:(x,y)\rightarrow (1:x:x^2)\in\Bbb{P}^1$ , so that the images of the $p_i$ are $$
\phi(p_1) = (1:1:1)\\
\phi(p_2) = (1:-1:1)\\
\phi(p_3) = (1:i:-1)\\
\phi(p_4) = (1:-i:-1)
$$ It seems to me that the only linear combination annihilating them is $-x_0+x_1-ix_2+ix_3$ , so I would say that the smallest linear subspace of $\Bbb{P}^3$ containing the images is $$
H: -x_0+x_1-ix_2+ix_3=0
$$ whose dimension is 2.
By algebraic Riemann-Roch I know that $l(D)=1+4-3=2$ and so, in fact, I get $2 = 4-2$ .
First question: is this argument right?
Second question: if previous answer is ""yes"", how does it differ from non-hyperelliptic case? Now I consider a divisor whose support is made of point where tha canonical map fails to be an embedding. Consider $D'=q_1+q_2+q_3+q_4$ where $q_1=(0,1),\ q_2=(0,-1),\ q_3=(1,\sqrt{2}),\ q_4=(1,-\sqrt{2})$ .
Now we get $$
\phi(q_1)=\phi(q_2) = (1:0:0)\\
\phi(q_3)=\phi(q_4) = (1:1:1)
$$ And we have two hyperplanes $H_1,\ H_2$ annihilating them, namely $$
H_1 = x_0-x_1\\
H_2 = x_2-x_3
$$ $H_1\cap H_2$ should be the projective line given by $(x:x:y:y)$ , so it has dimension 1, but again $degD' = 4$ and $l(D')=2$ and $1\neq 4-2$ Am I missing something?
Thank you for any hint!","['riemannian-geometry', 'complex-geometry', 'divisors-algebraic-geometry', 'algebraic-geometry', 'line-bundles']"
4265307,Tree: number of children of each node given total number of nodes and number of sublevels,"Imagine a full n-tree: every node has a single parent (or is the root and has 0 parents) and exactly n children (or is a leaf node and has 0 children). We can describe this tree with three variables: A = total number of nodes in the tree. B = number of sublevels in the tree. C = number of children per node. The fundamental formula to relate these three variables is most intuitively: $$ A =  \sum_{n=0}^{B}{C^n} $$ For example, if there are 4 sublevels of hierarchy (under the top node) and each node has 3 children, then B = 4 and C = 3. The top layer's count is 1, then the second layer's count is 3, then 3^2 = 9, then 3^3 and 3^4. The sum equals 121. From some Googling, I discovered that this sum can be expressed as: $$ A = \frac{{C^{B+1}-1}}{{C-1}} $$ If given A and C, you can work it out to solve for B and end up with: $$ B=log_C(AC-A+1)-1 $$ However, I am looking for a way to solve for C given A and B. Is there a way to do this?","['graph-theory', 'trees', 'algebra-precalculus', 'discrete-mathematics']"
4265319,Hartshorne theorem II.8.19,"There is a step in this proof I don't understand and maybe someone who does can help clarify it to me. The theorem is the following: Let $X$ and $X'$ be birationally equivalent non-singular projective varieties over a field $k$ . Then $p_g(X)=p_g(X')$ The proof has two steps, first show there is an open set $V\subset X$ and an injective map $\Gamma(X',\omega_{X'})\to \Gamma(V,\omega_V)$ and then show that $\Gamma(X,\omega_X)\to \Gamma(V,\omega_V)$ is bijective. As our open set $V$ we pick the largest open set on which some given rational equivalence $X\to X'$ is defined. Then to prove the second part Hartshorne begins by showing that the complement of $V$ has codimension $\geq 2$ . This is what I understand from his argument. If $P\in X$ has codimension $1$ we get a commutative diagram as below $$\text{Spec}(\mathcal{O}_{\xi,X})\longrightarrow X'\\
\downarrow \ \ \quad\quad\quad\quad \downarrow\\\text{Spec}(\mathcal{O}_{P,X})\longrightarrow \text{Spec}(k)$$ where $\xi$ is the generic point of $X$ . Then since $X'\to \text{Spec}(k)$ is proper and $\mathcal{O}_{P,X}$ is a DVR we get a unique map $\text{Spec}(\mathcal{O}_{P,X})\to X'$ . But I don't understand what comes next. Hartshorne says this unique map is compatible with the birational map and that it extends to some neighborhood of $P$ . I don't know why either of these claims are true. Any help would be appreciated!","['algebraic-geometry', 'schemes']"
4265331,Complex differentiation - Quotient Rule,"I've been given the following statement for the Quotient Rule:
Suppose $U \subseteq \mathbb{C} $ is open, $c \in U$ and both $f:U \rightarrow \mathbb{C}$ and $g:U \rightarrow \mathbb{C}$ are differentiable at $c$ . Provided $g(c) \neq 0$ , $\frac{f}{g}$ is differentiable at $c$ and $(\frac{f}{g})'(c) = \frac{g(c)f'(c)-f(c)g'(c)}{(g(c))^2}$ I am unsure why it is specified that $g$ is nonzero at only $c$ . Surely it should be required that $g$ is nonzero everywhere on $U$ , or else the function $\frac{f}{g}:U \rightarrow \mathbb{C}$ wouldn't be well defined. Is this not stated because it's obvious, or is not stated because it's not required? And if it is not required, then why is this the case? I've checked several different sources and it's only every specified that $g$ is nonzero at $c$ and never anywhere else. Edit: Thank you both for your answers! I understand now why only $g$ being nonzero at $c$ is required.","['complex-analysis', 'derivatives', 'complex-numbers']"
4265377,Derivative with respect to $y$ and $x$ are equal?,"Consider the wave equation $\frac{\partial^2u}{\partial x^2} = a^2\frac{\partial^2 u}{\partial y^2}$ .  Show that $u(x,y) = \sin(y-ax)$ is a solution of the wave equation.  More generally, show that $u(x,y) = f(x-ay) + g(x+ay)$ satisfies the wave equation. Hi, so in this problem for the second part, I got $f_{xx}(x-ay)+g_{xx}(x-ay)$ for the left hand side and $a^2( f_{yy}(x-ay)+g_{yy}(x-ay))$ for the right hand side and I don't get why the derivatives with respect to $x$ and $y$ have to be equal or am I confusing and the $x$ and $y$ don't matter when taking the derivative of the whole thing?","['partial-derivative', 'multivariable-calculus', 'wave-equation', 'partial-differential-equations']"
4265379,Bijection and spanning trees,"Given two spanning trees $T_1$ and $T_2$ , prove that there exists a bijection $h$ from $T_2 \setminus T_1$ to $T_1 \setminus T_2$ such that for every $a \in T_2 \setminus T_1$ , $T_1 - h(a) + a$ is a spanning tree. So far I have proved that if $u \in T_1\setminus T_2$ , there exists $v$ in $T_2 \setminus T_1$ such that $T_2 - v + u$ and $T_1 - u + v$ are spanning trees at the same time. What else could I do?","['trees', 'graph-theory', 'computational-mathematics', 'discrete-mathematics', 'algorithms']"
4265383,Universal property of gluing of schemes (or locally ringed spaces),"Given a gluing datum of locally ringed spaces, i.e. a family $X_i, i \in I$ of locally ringed spaces, for all $i,j \in I$ an open subset $X_{ij} \subseteq X_i$ , for all $i,j$ , an isomorphism of locally ringed spaces $\phi_{ij}\colon X_{ij}\to X_{ji}$ , such that $U_{ii} = U_i, \phi_{ii} = 1_{U_i}$ and $\phi_{ik} = \phi_{jk}\circ \phi_{ij}$ on $X_{ij}\cap X_{ik}$ , one can glue $X_i$ along $\phi_{ij}$ to obtain a new locally ringed space $X$ (together with canonical open immersions $\psi_i\colon X_i\to X$ ) satisfying a certain universal property. I'm trying to find out what this property is exactly. Gortz and Wedhorn (the book Algebraic Geometry I: Schemes: With Examples and Exercises ) state it as follows: if $Y$ is a locally ringed space and for all $i \in I \ \ \psi_i\colon X_i\to T$ a morphism of locally ringed spaces which induce an isomorphism of $X_i$ with with an open subspace of $T$ , such that $\xi_j\circ \phi_{ij} = \xi_i$ on $U_{ij}$ for all $i,j \in I$ , then there exists a unique morphism $\xi\colon X\to T$ with $\xi\circ \psi_i = \xi_i$ for all $i \in I$ . According to the book, the claim follows from the existence of the gluing of locally ringed spaces and the gluing lemma for morphisms (which states that we can glue morphisms $f_i\colon U_i\to X$ of locally ringed spaces where $U_i \subseteq Y$ to a unique morphism $f\colon Y\to X$ ). What I don't see is why it's necessary that $\xi_i$ are open immersions ( $\psi_i$ necessarily are though). Unless I'm mistaken (which is very possible), the deduction of the universal property of the gluing from the gluing lemma for morphisms can be done without this extra assumption. Stacks doesn't seem to include this line as well.","['algebraic-geometry', 'sheaf-theory']"
4265406,"how to determine the number of moved points of a commutator [g,h] from the shared moved points of g and h","I know that if two permutations share only 1 point that is moved by both of them, then the commutator of those permutations is a 3-cycle [1] . This is helpful for puzzles like Rubik's cube, where if two moves overlap by just 1 piece, the commutator will result in a 3-cycle with the remaining pieces fixed. Can anything be said about the number of moved points of the commutator if the permutations overlap by more than 1 point? I think the max number of moved points would be 3n, where n is the number of shared moved points. But it could be fewer if the shared points move to other shared points. In other words, is there an easy way to tell how many points will be moved by the commutator [g,h] given the points that are moved by both g and h (and other information about shared points moving to shared points)?","['group-theory', 'puzzle', 'permutation-cycles']"
4265618,Range of the function $f(x) = |x-3|+|x+5|$,"As the title suggests, we have to find the range of $f(x) = |x-3|+|x+5|$ I know how to find the range when we have a function in which only one modulus function is involved like $|x\pm a|$ or $k\pm |x\pm a|$ , but I don't know how to solve this given question. Being a newcomer to modulus functions, I asked my teacher this question. He suggested me to find the range by plotting graph of the function. I solved it using the method suggested by my teacher but I am wondering if there's any more feasiable method to find the range of this function. Any hint would be enough, thanks a ton in advance!","['algebra-precalculus', 'functions', 'absolute-value']"
