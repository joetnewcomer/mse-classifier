question_id,title,body,tags
1312677,Determining angle for rotation of conics,"I am working on rotation of conic sections and I'm having trouble determining the angle of rotation from the coefficients of the general conic equation. I'm given $$11x^2-24xy+4y^2+20=0$$ From this equation I know that $$cot(2\theta)= \frac{A-C}B=\frac{11-4}{-24}=\frac{7}{-24}$$ But when I draw a triangle with angle $2\theta$ to find $cos(2\theta)$, I end up with $$cos(2\theta)=\frac{7}{25}$$ Using this value for $cos(2\theta)$ with the half-angle formulas results in an incorrect solution, which does not eliminate the original $xy$-term. However, if I rewrite $$cot(2\theta)=\frac{-7}{24}$$ and draw a new triangle with angle $2\theta$, I end up with $$cos(2\theta)=\frac{-7}{25}$$ which yields the solution given in the back of the book after substitution and simplification. I keep encountering problems of this sort and am having trouble understanding why changing the sign of $$cot(2\theta)=\frac{7}{-24}$$ is allowed. I'm sure I am missing something with respect to the trig functions. I would be grateful for any clarification.","['conic-sections', 'algebra-precalculus', 'trigonometry']"
1312683,Prove path-lifting property using Lebesgue covering lemma,"For every map $\gamma:[0,1]\to S^1$, show that there is a map $\hat\gamma:[0,1]\to\mathbb{R}$ with $\gamma(t)=P(\hat\gamma(t)),$ where $P(s)=(\cos 2\pi s,\sin 2\pi s)\in S^1$. I want to prove this proposition using Lebesgue covering lemma, which states that for a compact metric space with open cover $\cup V_\lambda$, there is an $\epsilon>0$ such that for every $x$, its $\epsilon$-ball is completely contained in some sets in the cover. In order to use this theorem, I suppose we first need to find an open cover for $[0,1]$. So I considered a finite cover of $S^1$ (which is possible, since $S^1$ is compact0, then the preimage of these sets under $\gamma^{-1}$ form an open cover for $[0,1]$. But then I don't know how to proceed. Any thought would be helpful. Thank you very much.",['general-topology']
1312693,"show that the equation $r_1+r_2= \text{constant}$ implies the relation $\mathbf{T}\cdot \nabla(r_1+r_2)=0,$","This is a problem from Apostol's Calculus, which I have difficulty solving. If $r_1$ and $r_2$ denote the distances from a point $(x,y)$ on an ellipse to its foci, show that the equation $r_1+r_2= \text{constant}$ (satisfied by these distances) implies the relation $$\mathbf{T}\cdot \nabla(r_1+r_2)=0,$$ where $\mathbf{T}$ is the unit tangent to the curve. Interpret this result geometrically, thereby showing that the tangent makes equal angles with the lines joining $(x,y)$ to the foci. I would greatly appreciate any solutions or suggestions.","['vector-analysis', 'multivariable-calculus']"
1312720,Find sum of series [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I need to find the sum of the following series: $$\sum_{n=2}^\infty \ln\left(1-\frac 1{n^2}\right)$$ How to proceed with this?","['sequences-and-series', 'logarithms']"
1312722,Optimizing screening sample size,"Consider a machine like so: Every time I activate it, the machine generates a ""sufficiently large"" pool of plastic balls for me. Each ball is made out of colored plastic and painted over with white paint. I do not see the balls being created, and the white coat makes it impossible to tell what color the balls are inside. The machine chooses red, green or blue plastic for each ball randomly and with equal probability of each. I can only activate the machine once per day. The only way to determine the true color of a ball is to use a chemical stripping process that takes a whole day. Luckily, you can do more than one ball in parallel, but there is still an extra cost per-ball (although doing $2$ balls in one strip is still much better than doing $1$ ball each in $2$ strips). My objective is to obtain $1$ ball of every color. To do this, I am using the following strategy: Activate the machine, getting a large pool of balls. Pick a small number of balls to ""screen"" (for instance, $5$). Take this ""screening set"", strip them all in one go, take one ball of each color and discard the rest. At the end of this, I will probably get one of each ball, but there is a chance that I might not get every kind. If that happens, I will have to go back and screen some more balls, which will cost me an extra day - but time is money and I am very impatient. Therefore, I don't want to screen too few balls at once (the extreme case is screening 1 ball at a time, which will take forever). On the other hand, stripping balls costs money, so I don't want to strip more balls than I have to. For example, screening a whole pool of $1000$ balls when there are only $3$ colors will almost guarantee success, but I'm not really getting much more assurance than a smaller screen (e.g. $10$ balls) while it costs me $100$ times more. Obviously, if I want $100\%$ probability to catch all my balls in the first screen, I need to screen an infinite number of them. However, if I can accept a $95\%$ probability of needing more than one screen, then there is a finite and small number that will accomplish this. For $3$ colors with equal probability, the chances of needing a second screen after screening $n$ balls are: $$ 3\cdot\left(\frac{1}{3}\right)^n + 3\cdot\left(\frac{2}{3}\right)^n  $$ If I want $95\%$ or more confidence, I set this to: $$ 3\cdot\left(\frac{1}{3}\right)^n + 3\cdot\left(\frac{2}{3}\right)^n \le 0.05 $$ Then solve for $n$. (in this case it comes out $2.68$, so I would screen $3$ balls at a time) Is it possible to generalize this for any desired minimum confidence $p$ of getting all colors on each try, $q$ colors of equal probability, and derive a function of $q$ and $p$ that gives $n$? If you are curious, I am trying to figure out how many colonies to screen after a single transformation with a pooled sample. The machine producing a number of balls represents colonies you get from one transformation, the balls themselves are strains of bacteria, the color represents the plasmid carried by each strain, and the paint stripping process represents extracting and sequencing the plasmid.","['probability', 'binomial-distribution']"
1312729,Need a closed formula for the generating function $x/(1+x+x^2)$.,"I used partial fractions but the obtained formula is only correct for the first two elements. $\dfrac{x}{(1+x+x^2)}=\dfrac{x}{(1+a_1x)(1+a_2x)}=\dfrac{A_1}{(1+a_1x)+A_2(1+a_2x)}$ $x=\dfrac{-1 \pm\sqrt3i}{2}$ Then let $a_1=\dfrac{-1+\sqrt3i}{2}$ and $a_2=\dfrac{-1-\sqrt3i}{2}$ and then calculated $A_1$ and $A_2$ to obtain the formula $a_n=\dfrac{(-1)^n}{\sqrt3i} \cdot \left(\left(\dfrac{-1-\sqrt3i}{2}\right)^n-\left(\dfrac{-1+\sqrt3i}{2}\right)^n\right)$ The first three elements become $0$, $1$, $1$, but the answer from the Taylor series is $0$, $1$, $-1$.",['discrete-mathematics']
1312732,How do I calculate the odds of a given set of dice results occurring before another given set?,"Dice odds seem simple at first glance, but I've never taken a Calculus based statistics course or game theory, and I think I may need to in order to solve some of the things I'm trying to solve. I can hammer out the odds in some of the more straight-forward scenarios, but when it comes to calculating the odds of a series of dice events with variable conditions... I get lost in the numbers. I've tried different, seemingly legit methods... only to return vastly different figures each time.
Casino craps tables have a great variety of bets and hedge bets you can make. Some of the bets you make can sit on the table for half an hour or more, through dozens and dozens of dice throws, waiting on a resolution. It's technically possible (in theory not fact) that some of these bets could go on forever without being resolved. I would really like a decent approach to calculating these odds myself... hopefully by presenting a particular scenario, I can pick up enough tid-bits from your answers to piece together the methodology: We're throwing two six-sided dice at a time. Each side of each dice has equal probability on any given throw. There exists a tracking list with the numbers: 2, 3, 4, 5, 6, 8, 9, 10, 11, 12. ( Note : 7 is not in this list.) When the dice are thrown and their total is a number other than 7, the number is crossed off the tracking list and the dice are rolled again. When the dice are thrown and their total is a number that's already been crossed off the tracking list, the dice are rolled again. At any point if the dice are thrown and their total is 7, the series is resolved as a loss. At any point if all ten numbers are crossed off the tracking list, the series is resolved as a win. What's the probability of crossing all ten numbers off the list (winning) before throwing a 7 (losing)? This is the""All or Nothing at All"" bonus bet newly popular at many casinos. It pays 175 to 1. There are also ""All Small"" and ""All Tall"" bonus bets that pay 34 to 1 for throwing 2 thru 6 or 8 thru 12 respectively before throwing the 7. There's also a ""Fire Bet"" I'd like to break apart, but the rules are quite different. It will require a new post if I can't cull some new insights from the answers here... Please bear in mind, I'm wanting to know how to calculate conditional dice probability (where instantaneous probability shifts depending on your progression from throw to throw), not just know the odds in this particular case. I've taken mathematics courses up through CalcIII, so I can understand discussions involving limits and summation. Again, I've never takes statistics, probability, or game theory. Sorry for the long post, I know I talk too much....","['probability-theory', 'statistics', 'dice', 'probability', 'game-theory']"
1312754,Equality with dilogarithms,"During some calculations with definite integrals I happened to get the equality 
\begin{eqnarray}
2\, \textrm{Li}_2(-\frac{1}{2}) - 2 \, \textrm{Li}_2(\frac{1}{4})+ 2\, \textrm{Li}_2(\frac{2}{3})= 
3 \log^2 2 - \log^2 3
\end{eqnarray}
Does this follow from some well known equalities for dilogarithms ?","['analysis', 'special-functions', 'polylogarithm']"
1312801,Dimension of vector space of real numbers over rational number field,I know that dimension  of $\mathbb{R} $ over $ \mathbb{Q} $ is infinite. What can i say about the cardinality of its basis mean whether  it is countable or uncountable. Can we find exact basis for that.,['linear-algebra']
1312810,Equivalence of line bundles and $\mathbb{G}_m$-torsors,"This appears to be a duplicate of (half of) this question , but it received no attention so I'll try again. Given a line bundle $L\to X$ on a scheme $X$ over a field $k$, I am to show that $L'=L\setminus z(X)$ the complement of the zero section is a torsor for the multiplicative group. Our definition of a $G$-torsor $T$ is, I think, somewhat special: one simply requires $T$ to be faithfully flat over $X$ and equipped with an action $G\times_X T\to T\times_X T$ which is an isomorphism. I'm working in functor-of-points style. As I understand it, for $R$ a finitely generated $k$-algebra, $\mathbb{G}_m(R)=\coprod_{x\in X(R)} R^\times$. I can't quite get this to be the value of $L'(R)$. The most naive guess is that the fiber of $L'(R)$ over $x\in X(R)$ is simply the complement of zero in the projective $R$-module $x^*(R)$. But this is bad, and it seems the reason is that $L'$ has to be a subfunctor, so for instance elements of $L'(R)$ have to map to units under maps from $R$ to fields. I think this means elements of $L'(R)$ have to be generators, although I haven't written it out. So it seems it would suffice to show that The set of generators of a rank 1 projective $R$-module $P$ is a torsor for $R^\times$. But if $a$ and $ra=r'a$ generate $P$, then all I seem to get from $r-r'$ annihilating $a$ is that $r-r'$ is nilpotent-since otherwise $P$ would be $0$-dimensional modulo some prime and not of constant rank $1$. What am I missing here? Did I run off the tracks entirely with the rank-1 projectives lemma?","['algebraic-geometry', 'group-schemes', 'commutative-algebra']"
1312812,Arrange Relatively Prime Numbers in a Circle,"The question: In how many ways can you arrange the numbers $1$ to $8$ in a circle so that neighboring numbers are relatively prime? Can you generalize for $1$ to $n$? It's fairly easy to list all possible arrangements for the numbers $1$ to $n$ when $n \leq 7$; however, beyond this it is hard to do it by hand. I've tried approaching the problem in three ways, but none of them have got me any success (for either the general case or the special one). Consider the graph with vertices numbered $1, 2, \dotsc, n$. In this graph, there is an edge between two distinct vertices iff their numbers are relatively prime. For example, $1$ will be connected to all other vertices, $2$ to all odd numbers, etc. Then, the number of Hamiltonian cycles in this graph is our answer. Another way to look at the problem is by recursion. Given an arrangement of $n-1$ vertices, the $n^{\text{th}}$ vertex (with the number $n$) can be inserted on an edge where both neighbors are relatively prime to it. Thus the edge will be split into two. To solve the problem, we have to solve the recurrence. But note that the initial arrangement of $n-1$ vertices does not have to have all neighbors relatively prime; the condition is that either all neighbors are relatively prime, or there is exactly one relatively non-prime pair such that both numbers are relatively prime to the inserted number $n$. A third way is by making 'trees' for the choices of each next vertex. We start at $1$: there are $n-1$ branches for each of the $n-1$ remaining numbers. For each of the branches, there are further branches for each of the remaining numbers relatively prime to that branch, and so on. Counting the number of ways to get to the bottom of this tree will give us an answer. Edit: As in @Mark Main's answer, this approach is equivalent to making 'option sets' for a given number: starting from 1, choose any number in its option set, then choose any number from that number's option set, and so on. This is a good way to deal with the problem programmatically , but I can see no other advantage for the solution. Sorry for making it so long, but I thought it's better if I put up all my attempts. Please add more specific tags if you can, I couldn't find any.","['elementary-number-theory', 'combinatorics']"
1312820,Symmetric permutation matrix,"I am trying to prove that an $ n \times n $ permutation matrix $ P $  that is formed by switching two rows of an $ n \times n $ identity matrix will always be symmetric. This is what I am trying to use thus far but I can't quite figure out how to piece it all together: A matrix is symmetric if it is its own transpose. The transpose of the identity matrix is still the identity matrix. Any permutation $ P$  of the identity matrix satisfies $ P(P^T)=I$ (where $ P^T $ is the transpose of $ P$ ). A permutation matrix is always nonsingular and has a determinant of $ \pm 1$ . Basic transpose property: For matrices $ A $ and $ B$ , $   
   (AB)^T=(B^T)(A^T)$ Any help/advice would be greatly appreciated!","['linear-algebra', 'permutation-matrices', 'matrices']"
1312839,Function where 1 goes to 100 and 25 to 0,"It's times like these I wish I had paid more attention during calculus class... I'm trying to write a function for a computer program to calculate the ""heard volume"" a sound makes. Whereupon if something is standing 1 hypothetical unit away from me and made a sound, heard volume at my position would equate to 100 (Which would be the upper limit for volume), and if the same something where to be standing 25 units away from me, heard volume would then equate to 0. (It's too far away to be heard)",['algebra-precalculus']
1312849,Matrix with zeros on diagonal and ones in other places is invertible,"Hi guys I am working with this and I am trying to prove to myself that n by n matrices of the type zero on the diagonal and 1 everywhere else are invertible. I ran some cases and looked at the determinant and came to the conclusion that we can easily find the determinant by using the following $\det(A)=(-1)^{n+1}(n-1)$. To prove this I do induction n=2 we have the $A=\begin{bmatrix}
0 & 1\\ 
1 & 0
\end{bmatrix}$ $\det(A)=-1$ and my formula gives me the same thing (-1)(2-1)=-1 Now assume if for $n \times n$ and $\det(A)=(-1)^{n+1}(n-1)$ Now to show for  a matrix B of size $n+1 \times n+1$. I am not sure I was thinking to take the determinant of the $n \times n$ minors but I am maybe someone can help me. Also is there an easier way to see this is invertible other than the determinant? I am curious.","['linear-algebra', 'matrices']"
1312867,"A set having the same mean, median, mode, and range","Is it possible to have a set with the same mean, median, mode, and range? If not, how can the following question be solved: Set $H$ contains five positive integers such that the mean, median,
mode, and range are all equal. The sum of the data is $25$ . Using the above information, indicate which one will be greater: a) the smallest possible number in set $H$ . b) 6. If I assume that all the elements in set $H$ are equal to $5$ , it doesn't satisfy the conditions for range, as the range will become zero then.","['means', 'median', 'statistics']"
1312880,Show an intersection of Galois groups is trivial,"Let $L/K$ be a finite abelian extension of number fields, and for an extension of places $w/v$ consider the local Artin map $\Phi: K_v^{\ast} \rightarrow Gal(L_w/K_v)$, defined via the global Artin map on the ideles.  Let $\pi$ be a uniformizer for $K_v$, $E$ the maximal unramified extension of $K_v$ in $L_w$, and $F$ the fixed field of the subgroup of $Gal(L_w/K_v)$ generated by $\Phi(\pi)$.  Note that the restriction of $\Phi(\pi)$ to $E$ generates the Galois group of $E/K_v$. It's not difficult to show that $$K_v = E \cap F$$ but I would really like to show that also $$L_w = EF$$ or in other words the intersection of $Gal(L_w/E)$ and $Gal(L_w/F)$ is $1$.  I'm interested in this because this is the last step I need to do in a proof that the local Artin map is defined independently of the global fields inducing it. This proposition should be true (it is an analogue of a similar argument for infinite abelian extensions I saw in Caessels and Frohlich). I'm having trouble using the fact that $E$ is maximal .  Any ideas?","['p-adic-number-theory', 'number-theory', 'class-field-theory', 'algebraic-number-theory']"
1312894,Finding $\lim\limits_{x\to 0}(\frac{\sin(x)}{x})^{\frac{\sin(x)}{x-\sin(x)}}$ with and without L'Hopital's Rule.,"So, we have to find $\lim\limits_{x\to 0}(\frac{\sin(x)}{x})^{\frac{\sin(x)}{x-\sin(x)}}$ with and without L'Hopital's Rule. My Work : Let $\lim\limits_{x\to 0}(\frac{\sin(x)}{x})^{\frac{\sin(x)}{x-\sin(x)}}=L$ Taking $\ln$ of both sides and bringing the exponent down. $\lim\limits_{x\to 0}{\frac{\sin(x)}{x-\sin(x)}\ln(\frac{\sin(x)}{x})}=\ln(L)$ But it changes to undefined form? The answer (in my textbook) is $$\boxed{L=\frac1{e}}$$","['limits-without-lhopital', 'calculus', 'limits']"
1312896,Can we count odd and even derangements nicely without taking a determinant?,"It's not hard to see that 
$$\det \begin{pmatrix}
0 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0 \end{pmatrix}$$
is equal to #(even derangements on 3 elements) - #(odd derangements on 3 elements) and similarly for larger n .  It's not hard to calculate this determinant by various methods, and together with the known expression for the total number of derangements on n elements this results in explicit expressions for the number of odd and even derangements on n elements. Question: Is there any nice and fundamentally different way of getting at the numbers of odd an even derangements? My motivation is that this would then provide an alternate method of calculating the determinant.  See: Matrix with zeros on diagonal and ones in other places is invertible which is the original motivation, goes over a few simple ways to calculate the determinant, and includes a full explanation of the identity I claim above.","['combinatorics', 'permutations']"
1312913,How can vector field simultaneously be a function and also an operator that acts on a function?,"In elementary calculus we have definition: A vector field is a function that assigns a vector to each point in $\mathbb{R}^2$ or $\mathbb{R}^3$ i.e. F(x,y) = P(x,y) $\hat i$ +
Q(x,y,) $\hat j$ In differential geometry we have notation: $vf$ where $v$ = $v_k \partial^k$ so $vf$ = $v_k \partial^k f$ more precisely $v : C^\infty(M) \to C^\infty(M) $ In the former case, a vector field is defined as $F(x,y)$ , in the latter case, vector field is an operator $v = v_k \partial^k$ I am very new to differential geometry. Is there any reconciliation between the two concepts?","['vector-fields', 'differential-geometry', 'multivariable-calculus']"
1312930,Roots of a power series in an interval,"Let $ a_0 + \frac{a_1}{2} + \frac{a_2}{3} + \cdots + \frac{a_n}{n+1} = 0 $ Prove that $ a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n = 0 $ has real roots into the interval $ (0,1) $ I found this problem in a real analysis course notes, but I don't even know how to attack the problem. I tried to affirm that all coefficients are zero, but that is cleary not true, we have many cases when the result is 0 but $ a_i \ne 0$ for some $i$. I have tried derive/integrate, isolate and substitute some coefficients ($ a_0 $ and $a_n $ where my favorite candidates). Work with factorials (and derivatives and factorials) but could not find a way to prove. I have many pages of useless scratches. Any tips are welcome.",['real-analysis']
1312960,Matrix multiplication: What is $\mathbf A^3$ and $\mathbf A^n$?,Suppose there is matrix A . I know that A 2 = A $\cdot $A But what if it is A 3 ? Is it A $\cdot $A $\cdot$A OR A 2 $\cdot$ A OR A  $\cdot$ A 2 ? So basically my question is what is A n ?,"['exponentiation', 'matrices']"
1312991,Alternating series involving zeta function,Can anyone help me attain the result for the following series? $$\sum_{n=2}^{\infty} \frac{(-1)^n \zeta(n)}{n(n+1)}= \frac{1}{2} \left( \log 2 + \log \pi +\gamma -2 \right)$$ I don't know how to start. I am seriously thinking that this can be done using residues or contour integration since with real analysis I cannot see a pattern.,"['sequences-and-series', 'riemann-zeta', 'calculus']"
1313011,Prove that $f=(x+i)^{10}+(x-i)^{10}$ have all real roots,"We have $f=(x+i)^{10}+(x-i)^{10}$ and we need to prove that $f$ have all the roots in $\mathbb{R}$. Here is all my steps: Suppose that $z\in\mathbb{R}$ is a root of $f\Rightarrow (z+i)^{10}+(z-i)^{10}=0$ Therefore: $f(z)=\sum_{k=0}^{10}\left[\left(\dbinom{10}{k}\cdot z^{10-k}\cdot i^k\right)\left(1+(-1)^k\right)\right]=0$ I don't have ideea how can I prove that $f$ have all real roots Suppose that $z=a+bi$ and we need to prove that $b=0$: $$\Rightarrow f(z)=\sum_{k=0}^{10}\left(\dbinom{10}{k}\cdot a^{10-k}\cdot i^k\right) \left[(b+1)^k+(b-1)^k \right]=0$$ $$\Rightarrow \left[(b+1)^k+(b-1)^k \right]=0$$ $$\Rightarrow b+1=-b+1$$
$$\Rightarrow b=0$$ Therefore $f$ have all the roots in $\mathbb{R}$ Here is a photo with the proof of real axis, I don't know if is correct:","['polynomials', 'calculus', 'complex-numbers', 'algebra-precalculus']"
1313013,Determinant of matrix with trigonometric functions,"Find the determinant of the following matrix:
  $$\begin{pmatrix}\cos\left(a_{1}-b_{1}\right) & \cos\left(a_{1}-b_{2}\right) & \cos\left(a_{1}-b_{3}\right)\\
\cos\left(a_{2}-b_{1}\right) & \cos\left(a_{2}-b_{2}\right) & \cos\left(a_{2}-b_{3}\right)\\
\cos\left(a_{3}-b_{1}\right) & \cos\left(a_{3}-b_{2}\right) & \cos\left(a_{3}-b_{3}\right)
\end{pmatrix}$$For $a_1,\dots ,a_3,b_1,\dots, b_3\in\mathbb{R}$ I'm completely stumped honestly. I tried using the cosine addition identity to open the cosine, but I wasn't able to find how it helps me, and even for a $2\times2$ version of the matrix I wasn't really sure what to do. Any help?","['determinant', 'linear-algebra', 'matrices']"
1313021,How to use Hoeffding Inequality?,"I am new to Hoeffding Inequality and can someone kindly explain to me how to use it? I need to solve the following problem. If $\mu = 0.9$, use Hoeffding Inequality to bound the probability that a sample of 10 marbles will have $k \leq 0.1$. $\mu$ refers to the probability of red marbles in a bin of red and green marbles and $k$ refers to the fraction of red marbles within the sample Hoeffding Inequality is given as $P(|k - \mu| > \epsilon) \leq 2e^{-2\epsilon^2 N}$ for any $\epsilon > 0$. I can't relate binomial distribution to Hoeffding Inequality.","['statistics', 'machine-learning']"
1313059,Show that a matrix has positive determinant,"For a natural number $i>0$, let $p_i$ be the $i$th prime number, that is, $p_1=2, p_2=3, p_3=5,...$. Show that for all $n$, the following matrix has positive determinant $$
\begin{pmatrix}
1^{p_1} & 2^{p_1} & \cdots & (n-1)^{p_1} & n^{p_1} \\
1^{p_2} & 2^{p_2} & \cdots & (n-1)^{p_2} & n^{p_2} \\
\vdots  & \vdots  & \vdots  & \vdots  & \vdots  \\
1^{p_n} & 2^{p_n} & \cdots & (n-1)^{p_n} & n^{p_n}\\
\end{pmatrix}
$$ The hint provided is to use the fact that the polynomial $P(x)=a_nx^{p_n}+a_{n-1}x^{p_{n-1}} + \cdots + a_1x^{p_1}+a_0x^{p_1}$ has at most $n-1$ positive roots for all real constants. But I don't know how to use the fact to prove the question. Can anyone help me? The source of the problem is here , question $2.5$.","['contest-math', 'determinant', 'matrices']"
1313079,Moduli space of algebraic surfaces Vs moduli space of curves,"Define the surface $S$ as the complete intersection of four quadrics $Q_i$ with $i=1,2,3,4$ in $\mathbb{P}^6$ (complex six dimensional projective space) i.e. $$S=Q_1 \cap Q_2 \cap Q_3 \cap Q_4$$. Put $C=H \cap S$ where $H$ is an hyperplane of $\mathbb{P}^6$. So $C$ is a smooth curve on $S$ with genus $g=g(C)$. Set $\eta_{C/S}$ the normal bundle. So you can show that $\eta_{C/S}$ satisfy $\omega_C=(\eta_{C/S})^{\otimes2}$ where $\omega_C$ is the canonical bundle on the curve $C$. So the normal bundle is a theta characteristic on $S$. My questions: 1) what kind of theta-characteristic? odd or even? 2) suppose that $\mathscr{M}_S$ is the moduli space of the surface $S$ and $\mathscr{L}_C$ is the moduli space of the set $S_g=\{C, \theta_C \}$ where $\theta_C$ is a theta-characteristic on $C$. What are the dimensions of $\mathscr{M}_S$ and $\mathscr{L}_C$? is there a relations between these moduli spaces? any suggestions are welcome.","['projective-geometry', 'algebraic-geometry', 'projective-module']"
1313099,An asymptotic formula for the bounded sum of primes.,"How to prove the following asymptotic formula?: $$
\sum\limits_{p\leq x} p \sim \frac{x^2}{2 \log x}
$$ I'm stuck and I don't know where to start. I've been suggested the use of $\pi (x) = \frac{x}{\log x} + O\left( \frac{x}{\log ^2 x} \right) $. But I'm unsure about how to procede.","['number-theory', 'analytic-number-theory']"
1313115,Explicit calculation of eigenvalues of banded Toeplitz matrix,"I recently found a paper which detailed a method of finding the eigenvalues of the $n\times n$ banded Toeplitz matrix
$$ \left[ \begin{array}{ccccccc} 
a_0 & a_1 & a_2 & \dots & a_s & 0 & \dots & 0 \\
a_{-1} & a_0 & \dots & & & & & 0 \\
a_{-2} & \dots & & & & & & 0 \\
\vdots &&&&&& & \vdots \\
a_{-s} &\dots &&&& && \vdots \\
0 & \dots &&&&& & \vdots \\
\vdots &&&&&& a_0 & a_1\\
0 & \dots & & & & & a_{-1} & a_0
\end{array} \right]_.$$
The problem was reduced to finding the zeros of a much smaller determinant, of dimension $(2s) \times (2s)$.  As an example the authors compute the well-known formula for eigenvalues of a tridiagonal Toeplitz matrix, and the associated determinant had a form along the lines of $$ \left[ \begin{array}{cc}
a & b \\ a^{n+1} & b^{n+1}
\end{array} \right] $$ That's just about all I can recall from the reading - I managed to misplace the paper/pdf and am having trouble finding any references that might point to it in the literature. I'm hoping a MSE reader recognizes this and can point me in the direction of the source.  Any leads would be much appreciated.","['toeplitz-matrices', 'matrices', 'eigenvalues-eigenvectors', 'reference-request', 'linear-algebra']"
1313177,Laplace equation in a circle - where is my mistake,"We want to solve $r^2u''_{rr}+ru'_r+u''_{\theta \theta}=0$ where $0\leq \theta <2\pi$ and $0\leq r \leq 2$, given that $u(2,\theta)=\cos(2\theta)$. I managed to work out a simple solution, but when I checked it, I saw that it does not agree with $r^2u''_{rr}+ru'_r+u''_{\theta \theta}=0$ and I'd like to know where is the mistake. My solution Let $u(r,\theta)=R(r)T(\theta)$. Then from $r^2u''_{rr}+ru'_r+u''_{\theta \theta}=0$ we have $\frac{r^2R''(r)+rR'(r)}{R(r)}=-\frac{T''(\theta)}{T(\theta)}$ On the left hand side we have a function of just $r$, on the right hand just $\theta$, so they must both be scalar $\frac{r^2R''(r)+rR'(r)}{R(r)}=-\frac{T''(\theta)}{T(\theta)}=\lambda$ From this we have $T''(\theta)+\lambda T(\theta)=0$, but since $u$ is periodic with respect to $\theta$ with period of $2\pi$, we must have $T(0)=T(2\pi)$ and $T'(0)=T'(2\pi)$. This is a sturm-liouville problem whos solution is given by: $\lambda_k=k^2$ and $T_k(\theta)=A_k\cos(k\theta)+B_k\sin(k\theta)$. where $k=1,2,...$ and $T_0=1$. But we also had $\frac{r^2R''(r)+rR'(r)}{R(r)}=\lambda=k^2$, so $r^2R''_k(r)+rR'_k(r)-k^2R_k(r)=0$ If we guess a solution $R(r)=r^\alpha$ then we have $\alpha(\alpha-1)\alpha-k^2=\alpha^2-k^2=0$ so $\alpha=\pm k$ and so $R_k(r)=C_kr^k+D_kr^{-k}$ when $k\neq 0$, and $R_0=C_0+D_0\ln(r)$. So overall our solution will be of the form $u(r,\theta)=T_0(\theta)R_0(r)+\sum_{k=1}^{\infty}T_k(\theta)R_k(r)$ which equals to $u(r,\theta)=C_0+D_0\ln(r)+\sum_{k=1}^{\infty}[A_k\cos(k\theta)+B_k\sin(k\theta)](C_kr^k+D_kr^{-k})$ We impose another restriction that $\lim_{r\to 0}u(r,\theta)$ will be bounded. it will diverge to infinity or negative infinity. This can only happen when $D_0=0$ and $D_k=0$, so we have: $u(r,\theta)=C_0+\sum_{k=1}^{\infty}[A_k\cos(k\theta)+B_k\sin(k\theta)]C_kr^k$ To make things simple, since we don't know either $A_k,B_k,C_k$ let's just say $C_k=1$ and find $A_k,B_k$ that all the conditions are met. So overall: $u(r,\theta)=C_0+\sum_{k=1}^{\infty}[A_k\cos(k\theta)+B_k\sin(k\theta)]r^k$. but we also had a condition that $u(2,\theta)=\cos(2\theta)$. so $u(2,\theta)=C_0+\sum_{k=1}^{\infty}[A_k\cos(k\theta)+B_k\sin(k\theta)]2^k=\cos(2\theta)$. This can only hold if $C_0=0$, $B_k=0$ for all $k$. In addition we must have $A_k=0$ when $k\neq 2$, and we must also have $2^2A_2=1$, so $A_2=\frac{1}{4}$ so my answer is: $u(r,\theta)=\frac{1}{4}r^2\cos(2\theta)$. That's the solution I got. Indeed it is true that $\lim_{r \to 0}u(r,\theta)=0$ is bounded. And it is also true that $u(2,\theta)=\frac{1}{4}4\cos(2\theta)=\cos(2\theta)$. So these conditions are met. However, we have $u'_r=\frac{1}{2}r\cos(2\theta)$, $u''_{rr}=\cos(2\theta)$ and $u''_{\theta \theta}=-r^2\cos(2\theta)$. so: $r^2u''_{rr}+ru'_{r}+u''_{\theta \theta}=\frac{1}{2}r^2\cos(2\theta)$. And it should be zero. So I'm really not sure what's going on.","['partial-derivative', 'calculus', 'ordinary-differential-equations', 'partial-differential-equations']"
1313180,How does Morse theory on non-compact manifolds differ from compact manifolds?,"What is the Morse homology of a non-compact manifold? When is it, as in the compact case, isomorphic to singular homology of the underlying manifold? What other constructions can be identified with the Morse homology of a non-compact manifold? Links to places where these questions are discussed would be appreciated.","['differential-topology', 'morse-theory', 'differential-geometry']"
1313245,Can any commutative ring of characteristic $p\in\mathbb P$ be written as the form $R/(p)$ with $R$ being a ring of characteristic $0$?,"Let $S$ be a commutative ring with identity with $\operatorname{char}S=p$, where $p$ is a prime number. I wonder if we can always find a ring $R$ such that $\operatorname{char}R=0$ and $R/(p)\cong S$. I think above question is equivalent to if for every $\mathbb Z_{p}$-polynomial algebra $A$ and ideal $I$ of $A$ containing $p$, there exists an ideal $J$ not containing nonzero constants such that $I=(p)+J$. But I'm not sure if the latter simplifies the former. Moreover, it'll be more preferable if such a $R$ admits a canonical projection $\varphi:R\twoheadrightarrow S$ in the sense that every ring homomorphism from a ring of characteristic $0$ to $S$ can be factored through $\varphi$.","['abstract-algebra', 'commutative-algebra', 'ring-theory']"
1313247,Finding the limit without L'Hospital's rule.,"Find the value of $n$ for the given limit. $$\lim\limits_{x \to 1}\frac{π/4-\tan^{-1}x}{e^{\sin(\ln x)}-x^n} =\frac 18.$$ ATTEMPT: I tried expanding the denominator by Maclaurin's series, but the term $e^{\sin(\ln x)}$ has a very complicated expansion. Is there any other way to solve this without L'Hospital's rule?","['limits-without-lhopital', 'limits', 'algebra-precalculus']"
1313285,Show determinant of $\left[\begin{matrix} A & 0 \\ C & D\end{matrix}\right] = \det{A}\cdot \det{D}$ [duplicate],"This question already has answers here : The determinant of block triangular matrix as product of determinants of diagonal blocks (2 answers) Closed 6 years ago . Let $A \in \mathbb{R}^{n, n}$ , $B \in \mathbb{R}^{n, m}$ , $C \in \mathbb{R}^{m, n}$ and $D \in \mathbb{R}^{m, m}$ be matrices. Now, I have seen on Wikipedia the explanation of why determinant of $\left[\begin{matrix} A & 0 \\ C & D\end{matrix}\right] = \det{A}\cdot \det{D}$ , but I still did not get it. Specifically, the explanation is: This can be seen ... from a decomposition like: $\left[\begin{matrix} A & 0 \\ C & D\end{matrix}\right] = \left[\begin{matrix} A & 0 \\ C & I_{m}\end{matrix}\right]\left[\begin{matrix} I_n & 0 \\ 0 & D\end{matrix}\right]$ I understood that the equation is true from the standard rules of matrix-matrix multiplication, but it is still not too clear why this should prove what we want to prove or show. If $A$ , $B$ , $C$ and $D$ were regular reals (and $I_{i}$ was $1$ ), then the equation and the explanation would be obvious, because of the standard rules of calculating determinants... But in this case, I cannot understand why the equation shows that the final determinant is $$\det{A} \cdot \det{D}$$ Those 2 matrices $\left[\begin{matrix} A & 0 \\ C & I_{m}\end{matrix}\right]$ and $\left[\begin{matrix} I_n & 0 \\ 0 & D\end{matrix}\right]$ basically could not be triangular or diagonal matrices, from my understanding...","['solution-verification', 'determinant', 'block-matrices', 'matrices']"
1313292,$n$ points in the plane: show there are at least $\lceil \frac{n}{3} \rceil $ different distances between pairs of points,"How can I prove that in each group of $n$ points in the plane, such that there are not $3$ points on the same line, there are at least $\left\lceil \frac{n}{3} \right\rceil $ different distances between pairs of points?","['pigeonhole-principle', 'graph-theory', 'induction', 'discrete-mathematics']"
1313304,Calculating the convex conjugate of the function $f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right)$.,"The convex conjugate also known as Legendre–Fenchel transformation of a convex function $f:\mathbb{R}\to\mathbb{R}\cup\{+\infty\}$ is function $f^\ast:\mathbb{R}\to\mathbb{R}\cup\{+\infty\}$ definite by 
$$
f^{\ast}(x^\ast)=\sup_{x\in\mathbb{R}}\{ x\cdot x^\ast -f(x)\}
$$
Let $\{a_k\}_{n\in\mathbb{N}}$ and $\{b_k\}_{n\in\mathbb{N}}$ numerical sequences such that $\sum_{k=1}^\infty e^{a_k\cdot x+b_k}<\infty$. Let the function
$
f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right).
$
By a simple calculations and by Holder's inequality we prove that $f(x)$ is convex. Then Legendre-Fenchel transformation is well defined. Question. What is the convex conjugate of the function $f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right)$? A more explicit way, I would calculate the supremum below
\begin{align}
f^{\ast}(x^\ast)
=
&
\sup_{x\in\mathbb{R}}
\left\{
x\cdot x^\ast
+
\lim_{n\to \infty}\left(\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right)
\right\}.
\\
\end{align}","['sequences-and-series', 'convex-analysis', 'real-analysis', 'supremum-and-infimum']"
1313312,On construction of Mittag Leffler Theorem meromorphic functions.,I'm reading in my notes the proof of Mittag Leffler theorem but when I look at the exercises I don't know how to construct these functions. From the proof it's clear that if $\{z_n\}$ is the sequence of desired poles. One should construct the meromorphic function $f(z)= \Sigma (R_k - T_k)$ where $R_k$ are the desired principal  parts and $T_k$ are rational functions given by Runge's theorem so the sum converges on compact subsets of $\mathbb{C}$ How can i give in a simple case these functions in an explicit form? For example: A meromorphic function $f(z)$ with simple poles $\forall n \in \mathbb{N}$ with residue equal to $n$,['complex-analysis']
1313313,"If I assign a random number $r_x \in (0,1)$ to every $x \in (0,1)$ what are the odds that one of them will be a specific number?","I'll start by motivating by question with a simpler scenario to ensure I've at least understood that scenario properly. Scenario 1 : Imagine an infinite sequence of numbers where $i$ is the $i^{th}$ element of that sequence. If I assign a random number $r_i \in (0,1)$ to each $i$, and then ask ""What are the odds that for at least one $i$ we have $r_i = a$ ?"" where $a$ is some specific pre-chosen number in $(0,1)$ (say $0.5$), I believe I am correct in assuming that such an $i$ will almost never exist because $\aleph_0 = |\mathbb{N}| < |(0,1)| = \mathfrak{c}$. Is this reasoning accurate ? Scenario 2 : So now I would like to consider another infinite set of random numbers, but this time I'd like to replace my discrete infinite sequence with a sort of continuous equivalent, which I suppose is somewhat similar to a random function. Namely, for every real number in $x \in (0,1)$ I associate a random number $r_x \in (0,1)$. Now I again ask the question ""What are the odds that for some $x$ we have $r_x = a$ ?"". Here I'm really not sure what to think. It's certainly possible that the very scenario I'm describing cannot be rigorously defined and no such set of $r_x$ can exist, in which case I'd appreciate an explanation as to why this is so and what the closest possible scenario is. Conversely, feel free to more rigorously define my problem. Michael provided a solution to a seemingly related problem that's somewhere in between scenario 1 and 2 and so I'll post it here to see if anyone can extend this type of thinking to the reals : 1) Choose some natural number $n$ 2) List the naturals from $1$ to $n$ (let's call this set $\mathbb{N}_n$) 3) For each number in $\mathbb{N}_n$ randomly assign another number in $\mathbb{N}_n$ We can then see that the probability that some randomly chosen number $a \in \mathbb{N}$ never appears is $(1-1/n)^n$, which approaches $1/e$ as $n\to\infty$.  The chance that it does appear therefore approaches $1-1/e=0.632$. Is there any way to extend this to all reals between $0$ and $1$ ? After a little digging, I've come to think that perhaps there can't be an answer to my question, or if there is I'm probably in way over my head trying to find one. Let's define the problem a little more rigorously first : 1) Consider the family of sets $S_x$ where $S_x = (0,1) \forall x \in (0,1)$ (yes these are all the same set, why I'm considering this family will become apparent in step 2). 2) Using the axiom of choice, construct a set $R$ which contains one randomly chosen element from each $S_x$. This set $R$ is non-measurable. 3) Pick some number $a \in (0,1)$, and ask what are the odds that $a \in R$ is true ? And now I'm simply not sure what to make of the fact that $R$ is non-measurable. Does it make my question unanswerable ? Or does it actually provide a great test case for understanding non-measurable sets ?","['random-functions', 'probability', 'axiom-of-choice']"
1313315,What does an apostrophe mean in a function?,"In a workbook, I saw the function $f(x)=x^2$. Then, there was the same function with an apostrophe $f'(x)$. It was stated that $f'(x)=2x$. What is the apostrophe, and why does it change the function?","['notation', 'calculus', 'derivatives']"
1313320,An upper bound for Summative Fission numbers,"I recently found OEIS entry A256504 and have been playing around with this sequence a bit. Its definition is: For a positive integer $n$, find the greatest number of consecutive positive integers (at least 2) which add to $n$. For each of these do the same ... iterate to completion. $F(n)$ is then the total number of integers (including $n$ itself) defined. And here is an example, $F(24) = 13$: 24
       /|\
      / | \
     /  |  \
    7   8   9
   / \     /|\
  3   4   / | \
 / \     /  |  \
1   2   2   3   4
           / \
          1   2 Looking at the graph on OEIS these numbers seem to be growing roughly linearly, but I'm not sure how to establish a rigorous bound for it. A few interesting things I've noticed while checking numbers up to $n = 6\cdot10^6$ (and a few around $10^7$): There only seems to be one number where $F(n) > n$: $F(11) = 12$ There only seem to be five numbers where $F(n) = n$: $1$, $3$, $5$, $6$, $23$. It appears that the sequence is growing slightly sublinearly. After $10^6$, the largest ratio $F(n)/n$ I can find is $0.713924$ for $1110609$. After $2\cdot10^6$, it's $0.712693$ for $2097749$. After $5\cdot10^6$, it's $0.710524$ for $5570687$. After $10^7$, it's $0.709625$ for $10240519$. So my question is: can an upper bound for the sequence's growth be established rigorously and how tight can we make it? If the maximum ratio $\max_{n>n_0}F(n)/n$ is actually decreasing as $n_0$ grows, does it approach a finite constant? I suppose it might be helpful to have an upper bound on A109814 .","['asymptotics', 'sequences-and-series', 'integers', 'elementary-number-theory']"
1313327,Closest packing of equal balls in $\Bbb{R}^4$,"I know how to find the closest packing of equal spheres in $\Bbb{R}^3$ .  I'd like to know how to find the closest packing of equal balls in $\Bbb{R}^4$ with the standard Euclidian metric.  I suspect it's going to be something like the $\Bbb{R}^3$ FCC or HCP packing layered in hyperplane 'slices', but I'm having a hard time formulating an equation that I can use to compute the central points for the balls.","['metric-spaces', 'geometry']"
1313343,Finding $\lim_{x\to0} \frac{(4^x-1)^3}{\sin\left(\frac{x}{a}\right)\log\left(1+\frac{x^2}{3}\right)}$,"Find $$\lim_{x\rightarrow 0}\frac{(4^x-1)^3}{\sin\left(\frac{x}{a}\right)\log\left(1+\frac{x^2}{3}\right)}$$ I initially changed $4^x$ to $e^{x \ln(x)}$ and later tried to manipulate the function using L'Hopital's rule.
But then I concluded that that was not enough for evaluation; more simplification is required.","['calculus', 'limits']"
1313365,On the variation of a Kähler metric on a surface by pullback of the complex structure,"Let $\Sigma$ be a compact, connected, oriented surface, and let $\rho\in\Omega^2(\Sigma)$ be a fixed volume form. Then any (almost) complex structure $J\in\Omega^0(M;\operatorname{End}TM)$ compatible with the orientation gives us a Riemannian metric via
$$g(-,-) = \rho(-,J-).$$
Now let $\psi:\Sigma\to\Sigma$ be a diffeomorphism. Then $\tilde{J} = \psi^*J$ induces a possibly different metric $\tilde{g}$. We have
$$\begin{align}
\tilde{g}(-,-) = & \rho(-,\tilde{J}-)\\
= & \rho(-,d\psi^{-1}(J\circ\psi)d\psi-)\\
= & ((\psi^{-1})^*\rho)(d\psi-,(J\circ\psi)d\psi-)
\end{align}$$
and as $(\psi^{-1})^*\rho$ at $\psi(m)$ is given by $f(\psi(m))\rho_{\psi(m)}$, where $f:\Sigma\to\mathbb{R}_{>0}$ is some function, we obtain
$$\tilde{g} = \psi^*(fg).$$
I need to find $f$ in function of $\psi$ (as this would allow me, for example, to understand how the curvature changes when we change $J$ by the pullback via a diffeomorphism). Are there known results for this? Any help or hint on how to proceed would be appreciated. Notes: The following things are true in the case I need, but I don't know whether they are useful: The genus of $\Sigma$ is at least $2$. The diffeomorphism $\psi$ can be taken to be homotopic to the identity. As $\rho$ can be thought of as a symplectic form, we are in fact working with Kähler metrics. My progress: Write $\phi=\psi^{-1}$, $x=\psi(m)$. Let $v_1,v_2\in T_x\Sigma$, $w_1,w_2\in T_{\phi(x)}\Sigma$ be bases and write
$$d\phi_x\cdot(a^iv_i) = d\phi_i^jw_j.$$
Then (using Einstein summation convention):
$$\begin{align}
(\phi^*\rho)_x(a^iv_i,b^jv_j) = & \rho_{\phi(x)}(d\phi_i^ka^iw_k,d\phi_j^lb^jw_l)\\
= & d\phi_i^ka^id\phi_j^lb^j\rho_{\phi(x)}(w_k,w_l)
\end{align}$$
and using the fact that $\rho_{\phi(x)}(w_k,w_l)$ is zero if $k=l$ and writing down explicitly all the summands:
$$\begin{align}
= & \rho_{\phi(x)}(w_1,w_2)\big(d\phi_i^1a^id\phi_j^2b^j - d\phi_i^2a^id\phi_j^1b^j\big)\\
= & \rho_{\phi(x)}(w_1,w_2)\big(d\phi_i^1a^id\phi_j^2b^j - d\phi_i^2a^id\phi_j^1b^j\big)\\
= & \det\pmatrix{b^1&a^1\\b^2&a^2}\det(d\phi_x)\rho_{\phi(x)}(w_1,w_2).
\end{align}$$
At the same time, we have:
$$\rho_x(a^iv_i,b^jv_j) = \det\pmatrix{b^1&a^1\\b^2&a^2}\rho_x(w_1,w_2),$$
so that we conclude:
$$(\phi^*\rho)_x = \frac{\rho_{\phi(x)}(w_1,w_2)}{\rho_x(v_1,v_2)}\det(d\phi_x)\rho_x.$$
The first term compensates for the changes in the determinant coming from a change of basis, so that this expression is independent of choice. Is there a nicer way to write down this formula (without having to write terms a priori dependent from the choice of basis)?","['complex-geometry', 'differential-geometry', 'riemannian-geometry', 'surfaces']"
1313373,Connectedness of a linear continuum,"From Munkres pg 153: Theorem 24.1. If $L$ is a linear continuum in the order topology, then $L$ is connected, and so are intervals and rays in $L$ . Proof. Recall that a subspace $Y$ of $L$ is said to be convex if for every pair of points $a,b$ of $Y$ with $a < b$ , the entire interval $[a,b]$ of points of $L$ lies in $Y$ . We prove that if $Y$ is a convex subspace of $L$ , then $Y$ is connected. So suppose that $Y$ is the union of the disjoint nonempty sets $A$ and $B$ , each of which is open in $Y$ . Choose $a \in A$ and $b \in B$ ; suppose for convenience that $a < b$ . The interval $[a,b]$ of points of $L$ is contained in $Y$ . Hence $[a,b]$ is the union of the disjoint sets $$ A_0 = A \cap [a,b]\ \  \textrm{and}\ \  B_0 = B \cap [a,b]\textrm{,}$$ each of which is open in $[a,b]$ in the subspace topology, which is the same as the order topology. The sets $A_0$ and $B_0$ are nonempty because $a \in A_0$ and $b \in B_0$ . Thus, $A_0$ and $B_0$ constitute a separation of $[a,b]$ . Let $c = \sup A_0$ . We show that $c$ belongs neither to $A_0$ nor $B_0$ , which contradicts the fact that $[a,b]$ is the union of $A_0$ and $B_0$ . I do not understand the last sentence, ""which contradicts the fact that $[a,b]$ is the union of $A_0$ and $B_0$ . Why does the fact that $c$ belongs neither to $A_0$ nor to $B_0$ give a contradiction?",['general-topology']
1313378,Moving circular disk between two parallel sinusoidal curves,"Find the largest radius of the circle that can be ""rolled"" between the curves $y = sin(x)$ and $y = sin(x)+1$. After two weeks of research, I finally give up.","['euclidean-geometry', 'analysis', 'metric-geometry']"
1313454,Is this a valid partial fraction decomposition?,"Write $\dfrac{4x+1}{x^2 - x - 2}$ using partial fractions. $$ \frac{4x+1}{x^2 - x - 2} = \frac{4x+1}{(x+1)(x+2)} = \frac{A}{x+1} + \frac{B}{x-2} = \frac{A(x-2)+B(x+1)}{(x+1)(x-2)}$$ $$4x+1 = A(x-2)+B(x+1)$$ $$x=2 \Rightarrow 4 \cdot2 + 1 = A(0) + B(3) \Rightarrow B = 3$$ $$x = -1 \Rightarrow 4(-1) +1 = A(-3)+ B(0) \Rightarrow A = 1$$ Thus, $$\frac{4x+1}{x^2-x-2} = \frac{1}{x+1} + \frac{3}{x-2}\textrm{.}$$ The substitution of $x$ ( $x = 2, -1$ ) is a common method to find out the coefficient of the partial fractions. However, the equation on the third line is obtained by multiplying $(x+1)(x-2)$ , which is assumed to be nonzero. Here we have a contradiction. Furthermore, the original function is not defined at $x=-1,2$ . How can we substitute these value for $x$ ? So is this method valid and rigorous? How to modify it so that it is rigorous?","['partial-fractions', 'algebra-precalculus']"
1313461,Functions proof.,"Find all functions $$f: \mathbb{Z} \rightarrow \mathbb{Z}$$ such that
$$f(a)^2+f(b)^2+f(c)^2=2f(a)f(b)+2f(b)f(c)+2f(c)f(a)$$
for all integers $$a, b, c$$ satisfying $$a+b+c=0$$ I have no idea how to even begin this one? Any comments?","['contest-math', 'functional-equations', 'functions']"
1313522,What does it mean when two groups commute?,"This is probably an easy question, but I can't find the definition in my book. Let $G$ be a group, and let $H$ and $N$ be subgroups. What does it mean for $H$ and $N$ to commute? I have two possibilities that come to mind: $(\forall h \in H)(\forall n \in N)[hn=nh]$ $HN=NH$ , that is, if we have $hn$ , then there exists $h_2,n_2$ such that $hn=n_2h_2$ . What is the correct definition? I have this problem because of this exercise: Let $A$ and $B$ be subgroups of $G$ . a) Show that if either $A$ or $B$ is normal, then $AB=\{ab \mid a\in A, b \in B\}$ is a subgroup. Show by an example that the assumption $A$ or $B$ be normal can not be dropped. Show that if $A$ and $B$ commute , then $N =\{(x,x^{-1}) \mid x \in A \cap B\}$ is a normal subgroup of the direct product $A \times B$ and that AB is isomorphic to $A\times B /N$ .","['abstract-algebra', 'group-theory', 'definition']"
1313532,How to apply fundamental theorem of calculus to multiple integrals,"I have the following problem at hand: $$\lim_{\epsilon \to 0}\dfrac{1}{4\epsilon^2}\int_{z-\epsilon}^{z+\epsilon}f(e_1,y) \int_{\frac{z+y}{2}-\epsilon}^{\frac{z+y}{2}+\epsilon}g(e_2,x) dx dy$$ $f$ and $g$ are well behaving, continuous functions. I have the following intuitive thought but I can't show it rigorously: I shift $1/2\epsilon$ inside the first integral. Then we have: $$\lim_{\epsilon \to 0}\dfrac{1}{2\epsilon}\int_{z-\epsilon}^{z+\epsilon}f(e_1,y) \dfrac{1}{2\epsilon}\int_{\frac{z+y}{2}-\epsilon}^{\frac{z+y}{2}+\epsilon}g(e_2,x) dx dy$$
If it would be valid to apply Fundamental theorem of calculus both for inner and outer integrals, we would have obtain $f(e_1,z)g(e_2,z)$ as the result. But I have no idea how to show to in a proper way. What should be done in this case?","['derivatives', 'calculus', 'limits', 'integration']"
1313543,How to solve this multiple summation?,"How to solve this summation ? $$\sum_{0\le x_1\le x_2...\le x_n \le n}^{}\binom{k+x_1-1}{x_1}\binom{k+x_2-1}{x_2}...\binom{k+x_n-1}{x_n}$$
where $k$ , $n$ are known. Due to hockey-stick identity ,
$$\sum_{i=0}^n\binom{i+k-1}{i}=\binom{n+k}{k}$$","['summation', 'sequences-and-series', 'combinatorics']"
1313548,"Do ""domain"" and ""set"" mean the same thing in set theory?","My professor is asking me a question on my homework assignment in set theory.  First he asks me ""how many equivalence relations are on a set $X$ with one element?""  Then he asks ""how many equivalence relations are on a domain with two elements?"" My understanding is the word ""domain"" and ""set"" should be interchangeable.  Am I correct?",['elementary-set-theory']
1313575,Is there a closed form for $\sum_{n=0}^{+\infty} \frac{1}{\sqrt {n!}}$?,"This is a curiosity question. Let's consider the following sum:
$$S=\sum_{n=0}^{+\infty} \frac{1}{\sqrt{ n !}}$$ The question asked to prove its convergence, which I did using the ratio test. So I tried to find a closed form for the this sum but without luck. My question 1) Is there a closed form for $S$? (very likely no).
  2) If the answer is no can we prove that there is no closed form for $S$ rigorously? Thanks,","['summation', 'sequences-and-series']"
1313585,Question regarding example of toric variety and generators of cone,"Consider the canonical example taking n=2, and taking the cone $\sigma$ generated by the vectors $e_{2}$ and $2e_{1} - e_{2}$. The dual cone $\sigma^{v}$ is defined as the set of vectors in the dual lattice $M$ s.t. they give a non-negative inner product on the cone $\sigma$. Now, referring to Fulton Introduction to Toric Varieties page 5, he states that the semigroup $S_{\sigma}$ is generated by the dual vectors $e_{1}^{*}, e_{1}^{*} + e_{2}^{*}$, and $e_{1}^{*} + 2e_{2}^{*}$. My question is why isn't it sufficient for $S_{\sigma}$ to be generated by the dual vectors $e_{1}^{*}$ and $e_{1}^{*}+2e_{2}^{*}$ which are normal to the generators for $\sigma$? Why do we need the extra dual vector $e_{1}^{*} +e_{2}^{*}$ which is needed in order to show that this toric variety is isomorphic to the variety $V(xz-y^{2})$? Additionally, is there an easy/intuitive way to see that the spectrum Spec($\mathbb{C}[X,Y,Z]/[XZ-Y^{2}]$) gives a quadric cone? Thanks!","['vector-spaces', 'algebraic-geometry', 'geometry', 'toric-geometry', 'linear-algebra']"
1313630,Integer partitioning,"Suppose we have an integer $n$. I we want to partition the integer in the form of $2$ and $3$ only; i.e., $10$ can be partitioned in the form $2+2+2+2+2$ and $2+2+3+3$. So, given an integer, how to calculate the total number of ways of doing such partitions and how many $2$'s and $3$'s are there in each of the partitions?","['combinations', 'discrete-mathematics', 'integer-partitions', 'combinatorics']"
1313635,Quick way to solve $yy''-(y')^2=y^4$.,"This is a simple yet ugly ODE (arising from Euler-Lagrange equations):
$$yy''-(y')^2=y^4$$ What method could I use to quickly solve it? I began to notice that by dividing by $y^2$ I can write it as 
$$ (y'/y)'=y^2 $$
which implies that $y'=y^3t+cy$ for some constant $c$. But even there I don't know how to proceed.",['ordinary-differential-equations']
1313664,Riesz's Lemma for finite-dimensional spaces [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Let $Z$ be any linear normed space and $Y$ a closed subspace of $Z$ , then by Riesz's Lemma there exist an element $z_\theta \in Z$ such that $||z_\theta||=1$ and $dist(z_\theta,Y)<\theta$ where $\theta\in (0,1)$ , i.e we can get away from the closed subspace arbitrarily close to $1$ and still be on the unit ball. When however, $Z$ is a finite dimensional linear normed space, one can find an element $z\in Z$ such that $\operatorname{dist}(z,Y)=1$ with $\|z\|=1$ . Could someone give me an idea of ​​what happens in finite dimensional case?","['functional-analysis', 'normed-spaces']"
1313679,Dual space of $L^{\infty}$ - Where is the mistake?,"Today I thought about this for the first time and I really cannot see what is going on. I think it is a very stupid question but I really cannot see it. Consider the space $L^{\infty}(\mathbb{R})$ with the Lebesgue measure. According to this: The Duals of $l^\infty$ and $L^{\infty}$ , an element in the dual of this space is a finite signed measure $v$ which is absolutely continuous with respect to the Lebesgue measure. By Radon - Nikodym theorem we obtain: $dv = fd\mu$ and then the bounded total variation property is equivalent to $f \in L^1$. Thus we may thus construct an isometry between $(L^{\infty})^*$ and $L^1$ in an obvious way to get reflexivity of $L^1$ which is absurd. So my question is: where is the mistake?","['lp-spaces', 'lebesgue-measure', 'functional-analysis', 'measure-theory']"
1313688,Show that a locally compact Hausdorff space is regular.,"Show that a locally compact Hausdorff space $(X,\tau)$ is regular. I have already shown that a compact Hausdorff space is regular. My textbook proposes 2 methodes, but I get stuck at both. The first method looks the most elegant, but how can I continue? Compactification method. Consider the compactification $(X_\infty, \tau_\infty)$ where $X_\infty = X\sqcup \infty$ and $\tau_\infty = \tau \cup \{ X_\infty \setminus K: K \text{ is a compact subset of } X\}$ Then $(X_\infty, \tau_\infty)$ is regular. Let $x\in X\setminus F, F\subseteq X$ closed in $\tau$. Then $x\in X_\infty$ and $F\sqcup \{ \infty\}$ is closed in $\tau_\infty$. By regularity: $$(\exists U_\infty, V_\infty \in \tau_\infty)(x\in U_\infty, (F\sqcup \{ \infty\} ) \subseteq V_\infty, U_\infty\cap V\infty = \varnothing)$$ Since $\infty \in V_\infty$ then $U_\infty \in \tau$. How can I prove $V_\infty \setminus \{ \infty\} \in \tau?$ Any pointers? Direct method: Consider $x\in X\setminus F, F\subseteq X$ closed in $\tau$. We are on the lookout for $(U, V\in \tau)$ such that $U\cap V = \varnothing, x\in U, F\subseteq V$. Since $x\in X$ there (exists $K\subseteq X$ compact)($K$ is a neighbourhood of $x$) Consider the compact subspace $(K, \tau_K)$ of $(X,\tau)$ which is Hausdorff. Then $K\cap F$ is closed in $\tau_K$ which makes $(K,\tau_K)$ regular. And then $(\exists U_K, V_K \in \tau_K)(x\in U_K, (K\cap F)\subseteq V_K, U_K\cap V_K =  \varnothing)$. But how can I expand this $V_K$, such that $F\subseteq V$?","['separation-axioms', 'proof-verification', 'general-topology', 'compactness']"
1313740,How to solve $4^x+\sin(x)=10$,$$4^x+\sin(x)=10$$ I would use a log function to solve it but I don't know what to do with $\sin(x)$. What is the $x$ value of the exponent?,"['transcendental-equations', 'trigonometry']"
1313755,"Why is $\lim\limits_{x\to\infty} e^{\ln(y)} = e^{\,\lim\limits_{x\to\infty} \ln(y)}$?",In the above limit $y = x ^{\frac 1x}$. Is the above a limit or an exponent property? Thanks in advance. Context (Last paragraph): http://tutorial.math.lamar.edu/Classes/CalcI/LHospitalsRule.aspx,"['limits', 'exponentiation']"
1313764,Changing variable in a second derivative,"I want to convert the differentiation variable in a second derivative, but it's a bit more complicated than the case of the first derivative. For context, the variable $\eta$ is a dimensionless density and $V$ a volume. I have the expression for $d\eta/dV$ and $\frac{d^2}{dV^2}$. The first derivative conversion is the following: $\frac{da}{dV}=\frac{da}{d\eta}\cdot \frac{d\eta}{dV}$ Then what are the functions to convert the following second derivatives in terms of $\eta$ to volume $V$? $$\frac{d^2a}{dV^2}=\frac{d^2a}{d\eta^2}$$
then
$$\frac{d^2a}{dxdV}=\frac{d^2a}{dxd\eta}$$","['partial-derivative', 'calculus', 'multivariable-calculus', 'ordinary-differential-equations']"
1313801,A slightly stranger Hensel's Lemma,"I'm trying to understand the solution to this problem. It came up when doing some revision. It is essentially to show that the conclusion of Hensel's Lemma holds if we have take a valuation ring $R$ attached to a field $K$ complete with respect to a non-Archimedian valuation $|.|$, an $a_0 \in R$ and $f(t) \in R[t]$ such that $|f(a_0)|=|f'(a_0)^2|$ $0<|f'(a_0)|<1$ $|\dfrac{1}{2} f''(b)|<1$ for all $ b \in R$ Has anyone got an suggestions for this? I'm trying to modify the usual proof for hensel's lemma, but it isn't working out so well for me. Update: I think I might have a solution to this, but it may be completely wrong. Taking a Taylor series expansion of $f$ about $a_0$, we write: $$
f(a_0+h)= f(a_0)+hf'(a_0)+\frac{h^2}{2!}f''(a_0)+...
$$ Setting $h = -\frac{f(a_0)}{f'(a_0)}$, then note that $|h|=|f'(a_0)|<1$ so that $a_1:=a_0+h \in R$ and $h \ne 0$ or else we have a solution. Then $$ f(a_1)=\frac{h^2}{2!}f''(a_0)+\frac{h^3}{3!}f'''(a_0)+...$$ Under condition 2. then $$|\frac{h^3}{3!}f'''(a_0)+...| \leq \max(|f(a_1)|,|\frac{h^2}{2!}f''(a_0)|)<\max(|f(a_1)|,|h^2|)$$ So then $$|\frac{h}{3!}f'''(a_0)+...| <\max(\frac{|f(a_1)|}{|h^2|},1)$$ Therefore as, $$ \frac{|f(a_1)|}{|h^2|} \leq \max( |\frac{1}{2}f''(a_0)|,|\frac{h}{3!}f'''(a_0)+...|)< \max(1,\frac{|f(a_1)|}{|h^2|})  $$ so that $$|f(a_1)|<|h^2|=|f(a_0)|$$. Also, then we have that $$|f'(a_1)-f'(a_0)| = |hf''(a_0)+\frac{h^2}{2}f'''(a_0)+...|=|f'(a_0)||f''(a_0)+...|$$ So then $$ |f'(a_1)-f'(a_0)|< |f'(a_0)||2|\leq |f'(a_0)|$$ and $|f'(a_1)|=|f'(a_0)|$. So we have found an $a_1 \in R$ such that $|f(a_1)|< |f(a_0)|=|f'(a_0)|^2=|f'(a_1)|^2$ and we can use Hensel's Lemma with $a_1$. So we find a unique $a \in R$ such that $f(a)=0$ and $|a-a_1| \leq \dfrac{|f(a_1)|}{|f'(a_1)|}$. Then $|a-a_0|=|a-a_1+a_1-a_0|\leq \max( \dfrac{|f(a_1)|}{|f'(a_1)|}, \dfrac{|f(a_0)|}{|f'(a_0)|})= \dfrac{|f(a_0)|}{|f'(a_0)|}$. Am I on the right track with this or way off course?","['p-adic-number-theory', 'number-theory', 'valuation-theory']"
1313847,Prove $\lim_{x\to 0^+}{\frac{x^3}{|x|}} = 0$,"Prove $\lim_{x\to 0^+}{\frac{x^3}{|x|}} = 0$ My work: Because we are approaching $0$ from the right side, we can drop the absolute value since $x > 0$ $\forall x \in (0,+\infty)$ so we get: $f(x) = x^2$. Obviously, if we just plugged in $0$ we would see the $\lim_{x\to 0^+} {x^2} = 0$ but I want to prove this using the following definition: Let $f$ be a function defined on a subset $S$ of $\mathbb{R}$, let $a$ be a real number that is the limit of some sequence in $S$, and let $L$ be a real number. then $\lim_{x\to a^S}{f(x)} = L$ if and only if for each $\epsilon > 0$ there exists $\delta >0$ such that $x \in S$ and $|x-a| < \delta$ imply $|f(x) - L| < \epsilon$ Using this definition, we find that in order for this limit to exist, we must have that $x_0 \in S$  and $|x-0| < \delta \implies \left|\frac{x^3}{|x|} - L\right| < \epsilon$ However, I have no idea how to continue!","['limits', 'real-analysis']"
1313866,"Can we always construct a ""$p$th root"" of a $p$-element in a finite group?","Let $p$ be a prime, $G$ a finite group, and $g\in G$ a $p$-element.
Can one always embed $G$ in a finite group $H$ that contains a $p$-element $h$ such that $h^p=g$?","['abstract-algebra', 'group-theory', 'finite-groups']"
1313880,Limit as $n\to\infty$ of $\frac{\frac{n}{1}+\frac{n-1}{2}+\frac{n-3}{3}+...+\frac{2}{n-1}+\frac{1}{n}}{\ln(n!)}$,The task is to get the limit below: $$\lim_{n\rightarrow \infty}\frac{\frac{n}{1}+\frac{n-1}{2}+\frac{n-3}{3}+\cdots+\frac{2}{n-1}+\frac{1}{n}}{\ln(n!)}$$ I used Stolz but I don't know how to subtract the sequence.,"['limits', 'real-analysis']"
1313897,Minimal Polynomial of $\sqrt{2}+\sqrt{3}+\sqrt{5}$,"To find the above minimal polynomial, let 
$$x=\sqrt{2}+\sqrt{3}+\sqrt{5}$$
$$x^2=10+2\sqrt{6}+2\sqrt{10}+2\sqrt{15}$$
Subtracting 10 and squaring gives
$$x^4-20x^2+100=4(31+2\sqrt{60}+2\sqrt{90}+2\sqrt{150})$$
$$x^4-20x^2+100=4(31+4\sqrt{15}+6\sqrt{10}+10\sqrt{6})$$
$$x^4-20x^2-24=40\sqrt{6}+24\sqrt{10}+16\sqrt{15}$$
$$x^4-20x^2-24=8(2\sqrt{6}+2\sqrt{10}+2\sqrt{15})+24\sqrt{6}+8\sqrt{10}$$
$$x^4-20x^2-24=8(x^2-10)+24\sqrt{6}+8\sqrt{10}$$
$$x^4-28x^2-104=24\sqrt{6}+8\sqrt{10}$$
Again, squaring both sides
$$x^8-56x^6+576x^4+5428x^2+10816=4096+765\sqrt{6}$$
But if I square again, I will get a degree 16 polynomial.  Mathematica says the minimal polynomial is degree 8, which would make sense since elements of $\mathbb{Q}[\sqrt{2},\sqrt{3},\sqrt{5}]$ look like
$$a+b\sqrt{2}+c\sqrt{3}+d\sqrt{5}+e\sqrt{6}+f\sqrt{10}+g\sqrt{15}+h\sqrt{30}$$
Where am I making mistakes?","['ring-theory', 'field-theory', 'abstract-algebra', 'polynomials', 'minimal-polynomials']"
1313956,First mean value theorem for integration and Lebesgue measureability,"According to first mean value theorem for integration, if $G \ : \ [a,b] \to \mathbb{R}$ is a continuous function, there exists $x \in (a,b)$ such that
$$\int_a^b G(t) dt = G(x)(b-a)$$ Assume $G$ is a continuous function defined on $[a,b]$. For $0 < h < \frac{b-a}{2}$
$$\overline{G} \ : \ y \mapsto \int_{y-h}^{y+h} G(t) dt$$ is defined for $y \in [a+h,b-h]$. Applying the first mean value theorem for integration, for all $y \in [a+h,b-h]$, there exists $c_y \in (y-h,y+h)$ with
$$\overline{G}(y)=\int_{y-h}^{y+h} G(t) dt = 2 h G(c_y)$$ Taking for $G$ a constant function, $c_y$ can by any point in $(y-h,y+h)$. Hence we can pick up it in a way for which $y \mapsto c_y$ is not a Lebesgue measureable function. Question: can one find a continuous function $G$ for which $c_y$ is uniquely defined for all $y \in (a+h,b-h)$ and such that $y \mapsto c_y$ is not Lebesgue measureable? Jean-Pierre ( http://www.mathcounterexamples.net )","['calculus', 'measure-theory', 'integration']"
1313958,Some questions about the cartesian product,"I understand that the cartesian product of $A \times B$ is a set with elements of the form $(a,b)$ where $a\in A$, $b\in B$. My question arise from the fact that I was described $\Bbb{R}^3$ as $\Bbb{R} \times \Bbb{R} \times \Bbb{R}$, but elements of $\Bbb{R}^3$ have the form $(x,y,z)$, while elements of $\Bbb{R} \times \Bbb{R} \times \Bbb{R}$ should have the form $((x,y),z)$ where $(x,y)\in \Bbb{R}^2,z\in\Bbb{R}$. If this sets are different, how do we construct $\Bbb{R}^n$ with elements of the form $(x_1,x_2,...,x_n)$?",['elementary-set-theory']
1314006,Drawing an arrow,"Given values $L_1, L_2, x_1,y_1, x_2, y_2$ and $\theta$ , calculate $x_3, y_3, x_4, y_4$ . Basically, given a line, find the points of the tip of the arrow head. I have asked many people for help on this with no luck. I have tried making a right triangle, and this would work if only the arrow was facing upright. But the angle of the arrow is unknown so that is my problem.","['geometry', 'trigonometry']"
1314013,Components of the set of rational numbers,"From Munkres'(pg 160): Example 1:If $\mathbb{Q}$ is the subspace of $\mathbb{R}$ consisting of the rational numbers, then each component of $\mathbb{Q}$ is a single point. How do I see that each component of the rational numbers is a singleton?",['general-topology']
1314090,Intuition behind Fisher information and expected value,"I am learning stats. On page 128 of my book, All of Statistics 1e , it explains that the Fisher information is the variance of the score function. It then goes on to say that when $n = 1$ $$I(\theta) = -E_{\theta}\left(\frac{\partial^2 \log\space f(X;\theta)}{\partial{\theta}^2}\right)$$ where $f(x;\theta)$ is, I think, the pdf with parameters $\theta$. I am trying to get an intuition for what that definition is saying. Why would the variance of the score function be equal to the opposite of the expected value of the partial derivative of the pdf with respect to theta? In googling around I've found some videos for the Cramer-Rao lower bound and that seems related. I'm way over my head mathematically (in part to build up my skills), so it would be great if someone could really break down what is going on.",['statistics']
1314125,Applications of propositional logic,"I'm working on this propositional logic question and I did not understand the book answer at all. The book says the hostess knows to bring back two drinks for the first two professors. When three professors are seated in a restaurant, the hostess ask them, "" Does everyone want coffee? "" The first professor says, "" I do not know. ""  The second professor then says, "" I do not know. "" Finally, the third professor says, "" No, not everyone wants coffee. "" The hostess comes back and gives coffee to the professors who want it.  How did she figure out who wanted coffee?",['discrete-mathematics']
1314138,"How to prove $\lim\limits_{x\to\infty}\int_a^bf(t)\sin(xt)\,dt=0$","I need help to prove: Suppose $f\in C$. Prove that
  $$
\lim\limits_{x\to\infty}\int_a^bf(t)\sin(xt)\,dt=0
$$ My idea is to use substitute of $xt=u$ and prove
$$
\lim\limits_{x\to\infty}\dfrac1{x}\int_{ax}^{bx}f\left(\dfrac{y}{x}\right)\sin(y)\,dy=0
$$
But I am not sure how to do it. Thanks.","['calculus', 'limits', 'real-analysis', 'definite-integrals', 'integration']"
1314142,Trace of AB = Trace of BA [duplicate],"This question already has answers here : How to prove $\operatorname{Tr}(AB) = \operatorname{Tr}(BA)$? (4 answers) Closed 7 years ago . We can define trace if $A =\sum_{i} \langle e_i, Ae_i\rangle$ where $e_i$'s are standard column vectors, and $\langle x, y\rangle =x^t y$ for suitable column vectors $x, y$. With this set up, I want to prove trace of AB and BA are same, so it's enough to prove that $$\sum_{i} \langle e_i, ABe_i\rangle =\sum_{i} \langle e_i, BAe_i\rangle$$ but how to conclude that?",['linear-algebra']
1314159,Intuition for gradient when you only have one variable?,"I am learning about gradient. I understand how gradient is a vector that represents the sum of the rates of change for each component variable of a function. I am able to follow the Khan Academy video showing the gradient of f(x,y). I am also able to imagine (if not visualize) what gradient would be if you had more variables. But what if you only have one variable? Like for the function $f(x) = x^2$ Do you just have a one dimensional vector? What would it look like in the case of $f(x) = x^2$?",['calculus']
1314181,Are there concepts in nonstandard analysis that are useful for an introductory calculus student to know?,"Studying calculus I became aware that nonstandard analysis had some methods that that made the concept of infinitesimal concrete, so that $dx$ actually made sense. Can someone elaborate on this concept and whether there are any other things that are useful to know for a student in introductory calculus?","['infinity', 'nonstandard-analysis', 'calculus', 'soft-question', 'infinitesimals']"
1314183,Evaluating $\int_0 ^{\infty}\frac{dx}{x^{1/3}(1+x)}$ using Complex Analysis,"I am trying to use the residue theorem to evaluate $$I=\int_0 ^{\infty}\frac{dx}{x^{1/3}(1+x)}$$ I'll explain my difficulty in finding a contour, then I explain my difficulty in finding a new contour after a substitution. Consider the complexification $$f(z)=\frac{1}{z^{1/3}(1+z)}$$ where we choose the branch of the radical given by $$z^{1/3}=r^{1/3}e^{i\theta}, -\pi /2<\theta < 3\pi /2$$ (I'm open to using a different branch if convenient). The poles of $f$ are at $0,-1$, and I am not sure what contour I should use. I'm convinced that I am going to use a wedge, but I am not sure at which angle to make the wedge (that is, I am unsure of the angle of the line $\gamma_3$ lies on - see the pic below). In a different example that involved a square root, I was told ""the angle should be twice the argument of the pole,"" but I have two poles; I don't know the argument of $0$ and if I double or triple the argument of $-1$, I land back on the real axis and my contour will have two overlapping sides or will intersect itself. On the other hand, if we apply the $u$-substitution $u=x^{1/3}$, then $I$ becomes $$3\int_0^{\infty}\frac{u}{1+u^3}du$$, and the (complexification of the) integrand has poles at $-1,e^{\pi i /3}, e^{-\pi i /3}$. In this case, I am also unsure of how to determine the angle at which $\gamma_2$ should be (see pic below). I beleive the modified integral can be solved using partial fractions (and no complex analysis), but I prefer to use complex for now. Question: How can I choose the right contour in each case, and should one always consider using a $u$-substitution when the integrand has rational powers of $x$?","['contour-integration', 'complex-analysis', 'residue-calculus']"
1314202,When is an ordered space scattered?,"There is a concept of scattered in both order theory and topology. A topological space $X$ is scattered if every nonempty subspace has an isolated point. A linearly ordered set $( X , < )$ is scattered if it has no densely ordered subsets of size at least $2$ (that is, for each $A \subseteq X$ containing at least two elements there are $a < b$ in $A$ such that there is no $x \in A$ with $a < x < b$). Recall that given a linearly ordered set $( X , < )$, the order topology on $X$ induced by $<$ is generated by the subbasis consisting of all set of the form $$\begin{align}
( \leftarrow , a ) &:= \{ x \in X : x < a \} \\
( a , \rightarrow ) &:= \{ x \in X : x > a \}
\end{align}$$
for $a \in X$. Now, given a scattered linear order $(X , < )$, the order topology on $X$ is scattered, however the converse does not hold. Wikipedia gives the example of the lexicographic order on $\mathbb{Q} \times \mathbb{Z}$. Clearly $\mathbb{Q} \times \{ 0 \}$ is a densely ordered subset, so it is not a scattered order. However the order topology on $\mathbb{Q} \times \mathbb{Z}$ is discrete: for each $(q,n) \in \mathbb{Q} \times \mathbb{Z}$ we have that $(\,(q,n-1),(q,n+1)\,) = \{ (q,n) \}$ is open. Question. Is there a ""nice"" order-theoretic characterisation of when the order topology of a linearly ordered set is scattered?","['order-theory', 'general-topology']"
1314245,Physical meaning of linear ODE $xy''+2y' + \lambda^2 x y = 0$,"As reported by Wikipedia - Sinc function , $y(x)=\lambda \operatorname{sinc}(\lambda x)$ is a solution of the linear ordinary differential equation
$$x \frac{d^2 y}{d x^2} + 2 \frac{d y}{d x} + \lambda^2 x y = 0.\,\!$$ Has equation above physical meaning? That is, is it used to model some physical phenomena?","['applications', 'ordinary-differential-equations']"
1314257,Shortest irreducible polynomials over $\Bbb F_p$ of degree $n$,"For any prime $p$ , one can realize any finite field $\Bbb F_{p^n}$ as the quotient of the ring $\Bbb F_p[X]$ by the maximal ideal generated by an irreducible polynomial $f$ of degree $n$ . By dividing by the leading coefficient, we may as well assume $f$ is monic, in which case we can write it as $$f(X) = X^n + a_{n - 1} X^n + \cdots + a_1 X + a_0.
\def\co{\color{#00bf00}{1}}
\def\ct{\color{#0000ff}{2}}
\def\ch{\color{#bf00bf}{3}}
\def\cf{\color{#ff0000}{4}}
\def\ci{\color{#ff7f00}{5}}
$$ If we let $\zeta$ denote a root of $f$ , then $\Bbb F_{p^n} \cong \Bbb F_p[X] / \langle f \rangle \cong \Bbb F_p[\zeta]$ , and so when computing multiplication in this field and write elements as polynomials in $\zeta$ of degree $< n$ , one way or another we use iteratively the identity $$\zeta^n = -a_{n - 1} \zeta^{n - 1} - \cdots - a_1 \zeta - a_0.$$ Manually multiplying elements in this field is naively more efficient, then, when one chooses a polynomial $f$ with fewer nonzero coefficients. So, naturally, we can ask just how efficient we can be: For any prime $p$ and any positive integer $n > 1$ , what is the least number $\lambda(p, n)$ of nonzero coefficients an irreducible polynomial of degree $n$ over $\Bbb F_p$ can have? Some general observations: The only polynomial of degree $n$ with exactly one nonzero coefficient is $X^n$ , $\lambda(p, n) > 1$ . Jim Belk's answer shows that there is an irreducible polynomial of the form $X^n + a$ , that is, $\lambda(p, n) = 2$ , if $p \not\mid n$ and $p$ has order $n$ modulo $n (p - 1)$ . Thus, if these criteria do not hold for $(p, n)$ , we have $\lambda(p, n) \geq 3$ . Case $p = 2$ . Several behaviors are peculiar to the case $p = 2$ . First, if $f(X) \in \Bbb F_p[X]$ has an even number of terms with coefficient $1$ , then $f(1) = 0$ and so $f$ is divisible by $x - 1$ , hence (if $\deg f > 1$ ) not irreducible. Thus, for $n > 1$ , $\lambda(p, n)$ must be odd. Some additional facts about this case: Swan has given several sufficient conditions for the reducibility of a trinomial $x^n + x^k + 1$ in $\Bbb F_2[x]$ (see citation below). One of these conditions in particular implies that all such trinomials are reducible when $n \equiv 0 \bmod 8$ , and hence $\lambda(2, 8m) > 3$ . More details can be found in $\S$ 40.9 of Jörg Arndt's Matters Computational (pdf warning, $>5$ MB). Ciet, Quiscater, and Siet showed similarly that $\lambda(2, n) > 3$ if $n \equiv 13 \bmod 24$ or $n \equiv 19 \bmod 24$ . Case $p \neq 2$ . If $n = 2$ and we write $p = 2 q + 1$ , then $p^2 = (2 q + 1)^2 = 4q(q + 1) + 1 \equiv 1 \pmod {4 q} = 1 \pmod {2(p - 1)}$ , so by Jim Belk's characterization, $\lambda(p, 2)$ = 2. Harry Altman gives a proof (generalizing an observation) below that for $p > 3$ we have $\lambda(p, 3) = 2$ for $p \equiv 1 \bmod 3$ and $\lambda(p, 3) = 3$ for $p \equiv 2 \bmod 3$ . These facts together give us: A characterization of $(p, n)$ such that $\lambda(p, n) = 2$ . Knowledge of all $\lambda(p, n)$ , $n \leq 3$ . It thus remains to determine which $(p, n)$ have $\lambda(p, n) > 3$ and $\lambda(p, n)$ for those values. Some naive experimentation suggests that it is rare for $\lambda(2, n) > 5$ and for $\lambda(p, n) > 3$ for $p > 2$ . A naive Maple script gives that the only values of $\lambda(n, p)$ that occur for $p < 2^5, n \leq 2^8$ are $2, 3, 4, 5$ . Apparently minimal examples are: \begin{array}{crrr}
\hline
\lambda(p, n) & p & n & f(X) \\
\hline
2 & 3 &  2 & X^2 + 1 \\
3 & 2 &  2 & X^2 + X + 1 \\
4 & 5 & 35 & X^{35} + X^4 + 4 X + 1 \\
5 & 2 &  5 & X^8 + X^4 + X^3 + X + 1 \\
\hline
\end{array} For $p = 2$ , Table of Low-Weight Binary Irreducible Polynomials gives minimal polynomials (and hence values $\lambda(2, n)$ ) for all $n \leq 10^5$ . In all cases, $\lambda(2, n) \in \{3, 5\}$ . See also OEIS A057486 , ""Degrees of absolutely reducible trinomials, i.e. numbers $n$ such that $x^n + x^m + 1$ is factorable [modulo $2$ ] for all $m$ between $1$ and $n$ ."" What is the smallest degree $n$ , if any, such that $\lambda(2, n) > 5$ , i.e., for which there are no irreducible trinomials or pentanomials over $\Bbb F_2$ ? If there is such a degree, what is the maximum value of $\lambda(2, n)$ , if any? Among $2 < p < 2^5$ and $n \leq 2^8$ , the only values $\lambda(p, n) > 3$ are the following, and in each case $\lambda(p, n) = 4$ : \begin{array}{rl}
\hline
p & n \\
\hline
3 & 49, 57, 65, 68, 75, 98, 105, 123, 129, 130, 132, 149, 161, 175, 189, \\ & \quad 197, 207, 212, 213, 221, 223, 231, 233 \\
5 & 35, 70, 123, 125, 140, 181, 191, 209, 213, 219, 237, 249, 250, 253 \\
7 & 124, 163 \\
11 & 219 \\
17 & 231 \\
\hline
\end{array} Searching $2 < p \leq 8161$ (the $2^{10}$ th prime) and $n \leq 2^4$ yields no cases where $\lambda(p, n) > 3$ . What is the smallest $n$ such that $\lambda(p, n) \leq 3$ for all $p > 2$ ? (We know from the above that $4 \leq n \leq 35$ .) Is $\lambda(p, n) > 4$ for some $n$ and $p > 2$ ? If so, what is a minimal example, and what is the maximum value of $\lambda(p, n)$ , $p > 2$ ? References Jörg Arndt, Matters Computational (pdf warning, $>5$ MB) Mathieu Ciet, Jean-Jacques Quisquater, Francesco Sica, ""A Short Note on Irreducible Trinomials in Binary Fields"", (2002). Gadiel Seroussi, ""Table of Low-Weight Binary Irreducible Polynomials,"" Computer Systems Laboratory HPL-98-135. Richard G. Swan, ""Factorization of polynomials over finite fields"", Pacific Journal of Mathematics , (12) 3, pp. 1099-1106, (1962).","['abstract-algebra', 'polynomials', 'field-theory', 'finite-fields']"
1314270,"Prob. 10, Sec. 3.10 in Kreyszig's functional analysis book: Every isometric linear operator on a finite-dimensional inner product space is unitary? [duplicate]","This question already has answers here : Is linear surjective isometry always unitary? (2 answers) Closed 9 years ago . Let $X$ be an inner product space such that $\dim X < \infty$, and let $T \colon X \to X$ be an isometric linear operator. Since $\dim X < \infty$, $X$ is complete and thus a Hilbert space; since $T$ is isometric, $T$ is also injective and hence also surjective and thus bijective, because $\dim X < \infty$. So $T^{-1}$ exists. How to show that $T$ is unitary. That is, how to show that the Hilbert adjoint operator $T^*$ of $T$ equals $T^{-1}$? Since $X$ is finite-dimensional, we can choose an orthonormal basis for $X$; let $n \colon= \dim X$, and let $\{e_1, \ldots, e_n \}$ be an orthonormal basis for $X$. Then, for each $i, j = 1, \ldots, n$, we have 
$$\langle Te_i , e_j \rangle = \langle e_i, T^* e_j \rangle,$$
and, 
$$\langle T^* T e_i, e_j \rangle =  \langle T e_i , T e_j \rangle = \langle e_i , e_j \rangle = \begin{cases} 1 \ & \mbox{ if  } \ i = j \\ 0 \ & \mbox{ if } \ i \neq j. \end{cases} $$ What next?","['real-analysis', 'functional-analysis', 'hilbert-spaces', 'analysis', 'operator-theory']"
1314288,"Let $\mathbf{r}=(x,y,z)$,$r=||\mathbf{r}||$. Show the following equation on $B\cdot \nabla (A\cdot \nabla (\frac{1}{r}))$","Let $\mathbf{r}=(x,y,z)$ and let $r=||\mathbf{r}||$. If $A$ and $B$ are constant vectors show that: $$B\cdot \left(\nabla \left (A\cdot \nabla \left(\frac{1}{r}\right)\right)\right)=\frac{3A\cdot \mathbf{r}B\cdot \mathbf{r}}{r^5}-\frac{A\cdot B}{r^3}$$ I've found so far that $A\cdot \nabla\left(\frac{1}{r}\right)=-\frac{A\cdot \mathbf{r}}{r^3}$. However, I have not been able to show the equation above. 
I would greatly appreciate any solutions, suggestions, or hints.","['vector-analysis', 'multivariable-calculus']"
1314299,Problems on orthogonality and tangency in 3-space.,"Find the set of all points $(a,b,c)$ in 3-space for which the two spheres $(x-a)^2+(y-b)^2+(z-c)^2=1$ and $x^2+y^2+z^2=1$ intersect orthogonally. A cylinder whose equation is $y=f(x)$ is tangent to the surface $z^2+2xz+y=0$. For the first one, at the set of points, $\nabla f \cdot \nabla g$ should be $0$, where $f$ and $g$ each correspond to the first two spheres. Doing this, I get $4x(x-a)+4y(y-b)+4z(z-c)=0$, which gives the function of a sphere centered at $(a/2,b/2,c/2)$. However, the answer of this problem is a sphere with center at the origin and radius $\sqrt{2}$. For the second one, I tried solving it by setting the first equation as $F(x,y,z)=f(x)-y$ and the second one as $G(x,y,z)=z^2+2xz+y$. But I do not know how to progress further from here. I guess I'm not good at solving these kind of geometric problems yet. I would greatly appreciate any help.","['vector-analysis', 'multivariable-calculus']"
1314306,Inverse of a matrix having zeroes in diagonal and one elsewhere,"Could any one help me to find inverse of such matrix? I observed that $A=  J-I$, where J is a matrix having all entries 1.
Thanks for helping.",['linear-algebra']
1314350,Can we show that the decimal expansion of $\pi$ doesn't occur in the decimal expansion of the Champernowne constant?,"This question was inspired by an answer and some comments to this question . Recall that the Champernowne constant is obtained by concatenating all natural numbers written in base 10 and then put $0.$ in front, that is,
$$C_{10}=0.123456789101112131415161718192021222324\cdots$$ The question is does the decimal expansion of $\pi$ occur as a tail of this number? By which I mean is there some $n$ such that $$\pi=C_{10}\cdot10^{n+1}-10\cdot\lfloor C_{10}\cdot10^n\rfloor$$ Now it is obvious that any finite initial string of $\pi$ occurs in $C_{10}$. Not only that, it also occurs infinitely often (that's just because any finite string of numbers occurs infinitely often in $C_{10}$). Hagen von Eitzen (who's answer inspired this question) also notes that proving that $\pi$ does occur as the tail of $C_{10}$ would imply that $\pi$ is base-$10$-normal which is an open question see e.g. here , so it is very unlikely we can prove that. He also notes ""that if such a position exists [one where $C_{10}$ starts giving the digits of $\pi$] (somewhere in the middle of an $n$-digit integer, say) then the first $10^{n/2}n$ or so digits of $\pi$ turn out nearly regular and this should give rise to an unusually good rational approximation."" I tried to consider if there might be some relationship with relative algebraicity, but even in that direction little seems to be known since it is unknown even whether $\pi$ is algebraic over $e$. In conclusion it seems intuitively extremely unlikely that $\pi$ would occur in $C_{10}$, but I can't think of a proof that it doesn't. A good answer would also be a reduction of this problem to some known open problem (note that we need to reduce that $\pi$ is not the tail of $C_{10}$). PS If someone can come up with better tags please have a go at it.","['number-theory', 'pi']"
1314382,Step in the construction of the global spec of a sheaf of algebras,"I'm working my way through the construction of the global spec of a sheaf of algebras. Here is the setup. Let $ Y $ be a scheme. Let $ \mathscr{A } $ be a quasi coherent sheaf of $ \mathcal{O}_Y$algebras. For open affine subsets $V \subset U \subset Y$ we define $ X_{V}=\text{Spec}(\mathscr{A}(V)) $ and $ X_{U}=\text{Spec}(\mathscr{A}(U)) $ with the map $ {X}_{V}\to{X}_{U}$ induced by the restriction $\mathscr{A}(U)\to\mathscr{A}(V)$. My question is, why is $X_{V}\to{X}_{U}$ an open immersion? I tried to use basic affines but I'm losing it with the multi-level application of functors in this construction.","['algebraic-geometry', 'sheaf-theory']"
1314405,Intuitive/geometric way of thinking about effective divisors?,What is the motivation/intuition/geometric way of thinking about an effective divisor? I know that a divisor is effective if all its coefficients are non-negative. We write $D \ge 0$ for effective divisors. We can extend this in the obvious manner to get a partial ordering of divisors. I would consider any explanation that introduces the concepts of Weil and/or Cartier divisors to be obfuscating the underlying intuition of the definition in more formalism...,"['commutative-algebra', 'algebraic-curves', 'abstract-algebra', 'algebraic-geometry', 'geometry']"
1314411,Proof that determinant is continuous using $\epsilon-\delta $ definition,"I need to prove that the determinant $\det: M(n, \mathbb{R}) \rightarrow \mathbb{R}$ is a continuous function given the euclidean metric on the vector space of all $n \times n$ matrices over $\mathbb{R}$, i.e. $\Vert M \Vert = \sqrt{\sum_{i,j=1}^n M_{i,j}^2}$. So what I need to prove, I think, is that there exists a $\delta > 0$ such that if $\Vert M - M' \Vert < \delta$, for any $M' \in M(n,\mathbb{R})$ then it follows that for all $\epsilon > 0: |\det(M) - \det(M')|< \epsilon$. Unfortunately I have no idea how to derive the correct inequalities between the given euclidean metric and a determinant, since I'm kind of struggling with the permutation part in the definition of a determinant. Can anybody help, please?","['matrices', 'determinant', 'continuity', 'real-analysis', 'linear-algebra']"
1314460,How to generate a random number between 1 and 10 with a six-sided die?,"Just for fun, I am trying to find a good method to generate a random number between 1 and 10 (uniformly) with an unbiased six-sided die. I found a way, but it may requires a lot of steps before getting the number, so I was wondering if there are more efficient methods. My method: Throw the die and call the result $n$. If $1\leq n\leq 3$ your number will be between $1$ and $5$ and if $4\leq n\leq 6$ your number will be between $6$ and $10$. Hence, we reduced to the problem of generating a random number between $1$ and $5$. Now, to get a number between $1$ and $5$, throw the die five times. If the $i$th throw got the largest result, take your number to be $i$. If there is no largest result, start again until there is. The problem is that although the probability that there will eventually be a largest result is $1$, it might take a while before getting it. Is there a more efficient way that requires only some fixed number of steps? Edit: Or if not possible, a method with a smaller expected number of rolls?",['probability']
1314463,Find all possible Jordan Canonical forms of $A^2$,"Finding Jordan Canonical forms seems pretty straightforward mostly, but this one threw me off: Let $A\in M_n(\Bbb{F}) $ be a matrix with a minimal polynomial $m_A(t)=(t-\lambda)^n$. Find all the possible Jordan Canonical forms of $A^2$. I've looked through all my notes and material and didn't find a single example of finding a Jordan Canonical form for a matrix by any power. I know how to find it well enough for $A$ alone, but wouldn't know how raising it by the power of 2 (or any power) would affect that. Any tips?
Thanks!","['jordan-normal-form', 'linear-algebra']"
1314532,Self-adjoint extension of the Laplacian,"Let $M$ be a complete Riemannian manifold and $-\Delta$ denote the Laplace-Beltrami operator on $M$. We can prove that $(-\Delta f, g) = (\nabla f, \nabla g) = (f, -\Delta g)$, when $f, g \in C^\infty_0(M)$. My question is, when one extends the Laplace-Beltrami operator as a self-adjoint operator, what is the domain of the extension? Edit: As Jack Lee points out, here we are thinking of $-\Delta$ as an unbounded operator on $L^2(M)$.","['sobolev-spaces', 'differential-geometry', 'functional-analysis', 'reference-request']"
1314543,"$(e^x \cos y,e^x \sin y)$ is local diffeomorphism not global","Let $f:\mathbb{R^2} \to \mathbb{R^2}$ defined by $f(x,y)=(e^x \cos y,e^x \sin y)$ I have showed that $f$ is a local diffeomorphism by using inverse function theorem, that is $\det(Df)=e^x \gt 0$ for all $x$, so $Df$ is invertible, hence local diffeomorphism. But how do I see this is not a global diffeomorphism?",['differential-geometry']
1314578,Compass-and-Straightedge Construction [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I stumbled upon this question in math class, and I got stuck.
The Question: 
You're are given a circle, and two points.
How do you construct a circle that goes through the two points and is tangent to the the given circle?
Thank you, please reply.","['puzzle', 'geometric-construction', 'circles', 'discrete-mathematics']"
1314582,Exercise $1.8$ of chapter one in Hartshorne.,"In exercise 1.8 of chap I in Hartshorne algebraic geometry, Let $Y$ be an affine variety of dimension $r$ in $\mathbf A^n$. Let $H$ be a hypersurface in $\mathbf A^n$, and assume that $Y \nsubseteq H$. Then every irreducible component of $Y \cap H$ has dimension $r-1$. I refered to a solution .
In this solution, why $f$ is not a unit in $B$?","['algebraic-geometry', 'commutative-algebra']"
1314628,How to find the generating function,"What is the generating function for ${a_k}$, where $a_k$ is the number of solutions of $x_1 + x_2 + x_3 = k$ when $x_1,x_2,x_3$ are integers with $x_1 \geq 2$, $0 \leq x_2 \leq 3$, and $2 \leq x_3 \leq 5$? I know that the answer of this problem is $x^4(1+x+x^2+x^3)^2/(1-x)$. I want to know how to find the generating function in detail. Please help me!","['generating-functions', 'discrete-mathematics']"
1314630,Differentiability implies continuity - A question about the proof,"I have a question, to aid my understanding, about the proof that differentiability implies continutity . $\mathstrut$ Differentiability Definition When we say a function is differentiable at $x_0$ , we mean that the limit: $$‎f^{\prime} ‎(x) = \lim_{x\to x_0} \frac{f(x) - f(x_0)}{x-x_0}$$ exists. Continuity Definition When we say a function is continuous at $x_0$ , we mean that: $$\lim_{x\to x_0} f(x) - f(x_0) = 0$$ Theorem: Differentiability implies Continuity: If $f$ is a differentiable function at $x_0$ , then it is continuous at $x_0$ . Proof: Let us suppose that $f$ is differentiable at $x_0$ . Then $$ \lim_{x\to x_0} \frac{f(x) - f(x_0)}{x-x_0} =  ‎f^{\prime} ‎(x) $$ and hence $$ \lim_{x\to x_0} f(x) - f(x_0) = \lim_{x\to x_0} \left[ \frac{f(x) - f(x_0)}{x-x_0} \right] \cdot \lim_{x\to x_0} (x-x_0) = 0$$ We have therefore shown that, using the definition of continuous, if the function is differentiable at $x_0$ , it must also be continuous. My Question The proof seems to execute the following steps: Assume the function is continuous at $x_0$ Show that, with little algebra, we can change this into an equivalent question about differentiability at $x_0$ . With this little bit of algebra, we can show that if a function is differentiable at $x_0$ it is also continuous. What I am slightly unsure about is the apparent circularity. In my mind it seems to say, if a function is continuous, we can show that if it is also differentiable , then it is continuous. Rather than what I was expecting, namely, if a function is differentiable, we can show it must be continuous. Hopefully my confusion is clear. Any help will be greatly appreciated.","['continuity', 'real-analysis', 'proof-writing', 'derivatives']"
1314638,confusion in using Lebiniz integral rule,"I was trying this question - Let $$f: (0,\infty )\rightarrow \mathbb{R}$$ and $$F(x) =
 \int_{0}^{x}tf(t)dt$$ If $F(x^2)= x^{4} + x^{5} $, then the value of $\sum_{r=1}^{12}f(r^{2})$ is I applied chain rule for differentiation in $F(x^2)$ to get $$2xF'(x^2)=4x^3+5x^4$$ then used Leibniz rule in $F(x^2)$ to get 
$$F'(x^2)=2x(x^2)f(x^2)$$
 and substituted it in above equation to get $f(r^2)$ then trying to sum it up but in the solution the correct equation is $ 2x(x^2)f(x^2)= 4x^3 + 5x^4 $ but according to my method the equation for $f(r^2)$ is $2x(2x)(x^2)f(x^2)= 4x^3 + 5x^4$, what am I doing wrong?","['derivatives', 'calculus', 'definite-integrals', 'integration']"
1314640,"Examine the convergence of a sequence $\{a_{n}\}$ which is given by $a_{1}=a>0,a_{2}=b>0, a_{n+2}=\sqrt{a_{n+1}a_{n}},n\ge 1$","I used inequality between arithmetic and geometric means to show that a sequence $\{a_{n}\}$ is bounded:
$$a_{n+2}=\sqrt{a_{n+1}a_{n}}\le \frac{a_{n+1}+a_{n}}{2}$$ Solving this, I get quadratic inequality
$$a^2_{n+1}-2a_{n+1}a_{n}+a^2_{n}\ge 0$$ which gets me to $$0\le a_{n}\le 1$$
thus, sequence is bounded. I get that sequence is not monotonic, because
$$a_{n}\le a_{n+2} \le {a_{n+1}}$$
or
$$a_{n+1}\le a_{n+2} \le {a_{n}}$$ Is this right?","['calculus', 'recurrence-relations', 'sequences-and-series', 'analysis', 'convergence-divergence']"
1314660,Find the parametric equation of the curve to be the intersection of the paraboloid $z=x^{2}+y^{2}$ and the plane $y=z$,"A space-curve $C$ is defined to be the intersection of the paraboloid $z=x^{2}+y^{2}$ and the plane $y=z$. How should one try to find the parametric equation of the curve? It seems natural to let $x=(t-t^{2})^{\frac{1}{2}}$, $y=t$, z=$t$. However, rearranging the equations I got $\frac{1}{4}=x^{2}+\left ( y-\frac{1}{2} \right )^{2}$, which calls for the substitution $x=\cos(t)$, $y=\frac{1}{2}+\sin(t)$, $z=\frac{1}{2}+\sin(t)$. Which one do you suggest? Any tips on generalizing parametrization?","['differential-geometry', 'curves']"
1314672,"Two sets $X,Y \subset [0,1]$ such that $X+Y=[0,2]$","A set $X\subset \mathbb{R}$ is called nice if, for every $\epsilon > 0$, there are a 
  positive integer $k$ and some bounded intervals $I_1,I_2,...,I_k$ such that 
  $X \subset I_1 \cup I_2 \cup \cdots \cup I_k$ and $\sum\limits_{j=1}^k |I_j|^{\epsilon} < \epsilon$. Prove that there exist sets $X,Y \subset [0,1]$, both of them nice , such that $X+Y = [0,2]$, where $X+Y:=\{x+y\mid x\in X,y\in Y\}.$ This question is from an iberoamerican exam for undergraduate students (ciim 2010). An attempt to solve this problem can be found at aops but it doesn't seem to be complete or correct. Any help is welcome.","['sumset', 'real-analysis', 'measure-theory']"
