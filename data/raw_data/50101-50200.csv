question_id,title,body,tags
512377,Proving that a metric space is a group,"I'm stuck on this relatively hard problem. Let $G$ be a non-empty set, $d$ a distance on $G$ and $\cdot$ an associative operation on $G$ $\cdot$ is such that $$\forall a \in G , \forall x \in G ,\forall y \in G,( a\cdot x =a \cdot y) \Rightarrow x=y $$ and $$\forall a \in G , \forall x \in G ,\forall y \in G, (x\cdot a =y \cdot a) \Rightarrow x=y $$ $ \cdot$ is continuous $(G,d)$ is compact Prove that $(G,\cdot)$ is a group, and that the inverse function ($x \rightarrow x^{-1}$) is continuous What I need to find first is an identity element. My guess is that I should consider the minimum $m$ of the function  $f_x:y \rightarrow d(x\cdot y,x) $ (which exists since $f_x$ has a compact domain, and its codomain is $\mathbb R$). I don't know how to prove that $m=0$ though...","['topological-groups', 'general-topology', 'compactness', 'metric-spaces', 'group-theory']"
512382,Proving $\sqrt{\tan(\alpha)\tan(\beta)+5}+\sqrt{\tan(\alpha)\tan(\gamma)+5}+\sqrt{\tan(\beta)\tan(\gamma)+5}\le4\sqrt{3}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Prove that if $\alpha+\beta+\gamma=90^{\circ}$, then we have following inequality:
$$\sqrt{\tan(\alpha)\tan(\beta)+5}+\sqrt{\tan(\alpha)\tan(\gamma)+5}+\sqrt{\tan(\beta)\tan(\gamma)+5}\le4\sqrt{3}$$",['trigonometry']
512393,"Why is the set $ \mathbb{Z}_{+} \times \{a, b \}$ limit point compact?","I'm having trouble with an example from Munkres dealing with limit point compactness. The example is as follows: Let $Y$ consist of two points; give $Y$ the topology consisting of $Y$ and the empty set. Then the space $X = \mathbb{Z}_{+} \times Y$ is limit point compact, for every nonempty subset of $X$ has a limit point. It is not compact, for the covering of $X$ by the open set $U_n = \{n\} \times Y$ has not finite collection covering $X.$ So what I don't understand is how is $X$ limit point compact. The way I picture this is by taking the real line, picking the positive integers, and having two point above it. Now if we give each point an epsilon neighbourhood, then it would either contain both points or none. How would this imply that it is limit has a limit point?","['general-topology', 'compactness']"
512395,Homogenization of an irreducible polynomial is irreducible,"This is the last detail in an exercise that I'm working on in Hartshorne and I can't seem to figure it out. If $f$ is an irreducible polynomial in $k[x_{0},\dots,x_{n}]$ (where $x_{i}$ does not appear) and $\beta(f)$ is the homogenization of $f$ with respect to $x_{i}$, i.e., $\beta(f)=x_{i}^{d}f(\tfrac{x_{0}}{x_{i}},\dots ,\tfrac{x_{n}}{x_{i}})$, where $d$ is the maximal total degree of $f$, why is $\beta(f)$ irreducible? $$\text{My plan}$$ Assume otherwise then $\beta(f)=gh$ where $g$ and $h$ are homogeneous. (A proof of this fact would be nice or a link. I wasn't able to straighten this out.) Then $f=\alpha(g)\alpha(h)$ where $\alpha$ is defined by $\alpha(f)=f(x_{0},\dots ,1,\dots,x_{n})$ where the $1$ appears in the $i^{th}$ spot. $f$ is irreducible so either $\alpha(g)$ or $\alpha(h)$ is a unit. But I don't know how to relate this back to $g$ or $h$.","['irreducible-polynomials', 'abstract-algebra', 'polynomials']"
512397,"Is there a simple, constructive, 1-1 mapping between the reals and the irrationals?","Is there a simple, constructive, 1-1 mapping between the reals and the irrationals? I know that the Cantor–Bernstein–Schroeder theorem
implies the existence
of a 1-1 mapping between the reals and the irrationals,
but the proofs of this theorem
are nonconstructive. I wondered if a simple
(not involving an infinite set of mappings)
constructive
(so the mapping is straightforwardly specified)
mapping existed. I have considered
things like
mapping the rationals
to the rationals plus a fixed irrational,
but then I could not figure out
how to prevent an infinite
(possible uncountably infinite)
regression.","['elementary-set-theory', 'real-analysis']"
512407,Interchanging probability and limits,"I am trying to prove that $\mathbb{P}(\cup A_n)=1$ if $\mathbb{P}(\limsup A_n)=1$ when $A_1...A_n$ are independent events and $\mathbb{P}(A_n)<1$. My question is, while trying to prove this, can I interchange the limit and probability and can I do that always or are there conditions when I can't ? $\mathbb{P}(\limsup A_n)=\lim_{n \to \infty}(\mathbb{P}(\cup_{m\geq n} A_m))$ . Also if $\mathbb{P}(A_n)<1$ then why is $\sum \mathbb{P}(A_n) = \infty$ ?","['probability-theory', 'probability']"
512434,Tricks for calculating absolute third moment?,"Are there any useful tricks for calculating third absoute moments, similar to MGFs for raw and central moments? In particular, I'd like the third absolute moment of the Lognormal, normal, weibull, and binomial (discrete version). I can't seem to find much on the web or in my textbooks about the $\textit{absolute}$ third moment $\gamma$. Where $\gamma = \int |X|^3 dF $ Thanks for any help :)",['probability-theory']
512444,How find this$\frac{1}{{{p}_{1}}}+\frac{1}{{{p}_{2}}}+...+\frac{1}{{{p}_{n}}}<10$,"Let ${{p}_{1}},{{p}_{2}},...,{{p}_{n}}$ be the prime numbers less than ${{2}^{100}}$. Prove that
$$\frac{1}{{{p}_{1}}}+\frac{1}{{{p}_{2}}}+...+\frac{1}{{{p}_{n}}}<10$$ This problem is from this Romania National Olympiad 2013,grade 10 -P4 http://www.artofproblemsolving.com/Forum/viewtopic.php?p=3000224&sid=70162fff5664ceb6c25410e6fe0a42f6#p3000224 So  I think this problem have nice methods,it must have  without anlaysis numbers methods This following is ugly methods By mathlinks Lemma 1, We have that $$\prod_{p\ prime \leq x}p\leq 4^x$$ for any positive integer $x$. Proof : We use induction. The base cases are trivial. Passing from an odd integer to an even one is very easy (as LHS remains the same while the RHS increases). So we only show how to pass from an even integer to an odd one (i.e. prove the inequality for $x=2k+1$). We will use the binomial coefficient $\dbinom{2k+1}{k+1}$. It is easy to see that it is divisible by $\displaystyle \prod_{k+1<p\leq 2k+1}p$ (the product is taken over primes). Therefore $\prod_{p\leq 2k+1}p\leq \left(\prod_{p\leq k+1}p\right)\left(\prod_{k+1<p\leq 2k+1}p\right)\leq 4^{k+1}\dbinom{2k+1}{k+1}\leq 4^{2k+1}$ (we used the induction hypothesis and the fact that $\dbinom{2k+1}{k+1}\leq 2^{2k}$, which is an easy exercise). The lemma is proved. Lemma 2:(Partial summation) Let $a_n$ ($n\in\mathbb{N}$) be a sequence, so that $a_n=0$ for $n<x_0$, and $S(x)=\displaystyle\sum_{n\leq x} a_n$. Let $f$ be a function with continuous derivative. Then $\sum_{n\leq x} a_nf(n)=S(x)f(x)-\int_{x_0}^{x}S(t)f'(t)\mathrm{d} t$ Proof:Let us note that $$\sum_{n\leq x} a_nf(n)=\sum_{n\leq x} (S(n)-S(n-1))f(n)=S(x)f(x)-$$
 $$\sum_{n\leq x} S(n-1)(f(n)-f(n-1))=S(x)f(x)-\sum_{n\leq x-1} S(n)\int_{n}^{n+1}f'(t)\mathrm{d}t$$.
 As $S$ behaves like a step function constant on $[n,n+1)$, we get that $\sum_{n\leq x}a_nf(n)=S(x)f(x)-\int_{0}^xS(t)f'(t)\ \mathrm{d}t=S(x)f(x)-\int_{x_0}^xS(t)f'(t)\mathrm{d}t$, as $a_n=0$ for $n<x_0$. With these two lemmas we are ready to prove the problem. From the first lemma we have (by taking logarithms) that $\sum_{p\leq n}\log(p)\leq n\log(4)$, for any integer $n$ so the relation actually holds even if $n$ is any positive real number. We use lemma 2 with $a_n=\log(n)$ if $n$ is prime and $a_n=0$ otherwise. We take $f(x)=\frac{1}{x\log(x)}$. We can take in the lemma $x_0=2$. We have that $$\sum_{p\leq x}\frac{1}{p}=\sum_{n\leq x} a_nf(n)=S(x)f(x)-\int_{2}^{x}S(t)f'(t)\mathrm{d} t=\frac{S(x)}{x\log(x)}+\int_{2}^x\frac{S(t)(1+\log(t))}{t^2\log^2(t)}\mathrm{d}t$$ Using that $S(x)
\leq x\log(4)$ we get that $$\sum_{p\leq x}\frac{1}{p}\leq \frac{\log(4)}{\log(x)}+\int_{2}^x\frac{\log(4)}{t\log^2(t)}\mathrm{d}t+\int_{2}^x\frac{\log(4)}{t\log(t)}\mathrm{d}t$$. The antiderivative of the function in the first integral is $\frac{1}{\log(t)}$, so the first integral is at most $\frac{\log(4)}{\log(2)}=2$, and the antiderivative of the function in the second integral is $\log(\log(x))$. We therefore have that $$\sum_{p\leq x}\frac{1}{p}\leq \frac{\log(4)}{\log(x)}+2+\log(4)(\log(\log(x))-\log(\log(2)))$. For $x=2^{100}$$ we have that $$\sum_{p\leq 2^{100}}\frac{1}{p}\leq \frac{1}{50}+2+\log(4)\log(100)$$, and the last expression is less than $8.405$ (in an olympiad one might use that $e$ is greater than $2.7$ and use this to estimate $\log(2)$ and $\log(10)$)","['inequality', 'number-theory', 'analysis']"
512455,Expected max load with $n$ balls in $n$ bins?,"If you throw $n$ balls into $n$ bins uniformly and independently at random, let $X$ be the number of balls in the bin with the largest number of balls in it. Is there an elementary way to compute $\mathbb{E}(X)$? This problem comes up when considering hashing in computer science, for example, or randomized load balancing. EDIT.  Having seen the current answer, if there is a simpler way to prove that $\mathbb{E}(X) =\Theta(\log{n}/\log{\log{n}})$ instead of an exact formula I would be happy with that.","['balls-in-bins', 'probability']"
512456,"Injection from $\{f: \mathbb{N} \to \{0,1\} \} \to [0,1]$.","For a proof that $\mathfrak{c} = 2^{\aleph_0}$ I have created the following function.
\begin{align*}
\varphi: \{f: \mathbb{N}\to \{0,1\}  \} &\to [0,1]\\
f &\mapsto 0,f(1)f(2)f(3)....
\end{align*}
I think it is injective, for suppose $\varphi(f)=\varphi(g)$. Then $\forall n \in \mathbb{N}, f(n)=g(n)$, so $f=g$. My question is, am I missing something? Because I often encounter more involved injections for this proof. Maybe the funtion $\varphi$ is not welldefined because of non-unique decimal representation in [0,1] (but I fail to see how this could be a problem with only 0's and 1's as decimals)? Thanks in advance.",['elementary-set-theory']
512457,Closed form of $\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]$,"While working on a question , I wanted to find a limit in closed form as known numbers but I could not find a way to express it. $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]$$ $$\ln (x+1)=\frac{x}{1} -\frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4}+ ....=\sum \limits_{k=1}^{\infty} (-1)^{k+1} \frac{x^k}{k}$$
$$\frac{1}{n\ln(1+\frac{x^2}{n^2})}=\frac{1}{n(\frac{x^2}{n^2} - \frac{x^4}{2n^4} + \frac{x^6}{3n^6}+ \cdots)}=\frac{1}{\frac{x^2}{n}- \frac{x^4}{2n^3} + \frac{x^6}{3n^5}+ \cdots}=\frac{n}{x^2}(\frac{1}{1 - \frac{x^2}{2n^2} + \frac{x^4}{3n^4}+ \cdots)}=\frac{n}{x^2}.({1 + \frac{x^2}{2n^2} - \frac{x^4}{12n^4}+ \cdots)}$$ $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]=\lim_{n\to\infty}[(\sum_{k=1}^n \frac{n}{k^2}.(1 + \frac{k^2}{2n^2} - \frac{k^4}{12n^4}+ \cdots) )-\frac{{n \pi}^2}{6}]=\lim_{n\to\infty}[(n\sum_{k=1}^n \frac{1}{k^2} + \frac{1}{2n}\sum_{k=1}^n1 - \frac{1}{12n^3}\sum_{k=1}^n k^2+ \cdots) -\frac{{n \pi}^2}{6}]= \frac{1}{2} - \frac{1}{36}+ \cdots$$ The results from above we can express the requested number as $$\alpha=\sum_{k=1}^{\infty} \frac{1}{2k-1} \frac{1}{k!}\frac{d^k}{{dx}^k}(\frac{x}{\ln(1+x)})|_{x=0}$$ maybe that way can help to see the number in closed form Thanks for answers EDIT: @user8268 noticed good point.Maybe we can find the result via integral variable change. I want to share the transform from sum into integral representation. We know that
$$\frac{{\pi}^2}{6}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}$$ Thus we can write that
$$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-n\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}]$$ $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n \frac{1}{n}(\frac{1}{\ln(1+\frac{k^2}{n^2})})-\lim_{n\to\infty}\sum_{k=1}^n \frac{1}{n}(\frac{1}{\frac{k^2}{n^2}})]$$ $$\alpha=\lim_{n\to\infty}[\sum_{k=1}^n \frac{1}{n}(\frac{1}{\ln(1+\frac{k^2}{n^2})}-\frac{1}{\frac{k^2}{n^2}})]$$ We can write a  sum as integral because we know a formula that 
$$\int _0^x {f(t) dt}=\lim_{n\to\infty} \frac{x}{n}\sum \limits_{k=1}^n f(\frac{kx}{n})$$ Thus
$$\alpha=\int _0^1 {(\frac{1}{\ln(1+t^2)}-\frac{1}{t^2}) dt}$$
Now I can focus on the variable change and try to evaluate the integral as known closed form numbers such as $\ln2, e,\gamma$,  $\pi$ , $\Gamma(\frac{1}{4})$ etc (or their combinations if it is possible )","['sequences-and-series', 'limits']"
512473,Interview Puzzle,"Suppose $5$ blue points and $5$ red points are selected in the interval $[0,1]$. What is the probability that the points will interleave each other? Interleave as in one blue point followed by one red point and so on or one red point followed by a blue point and so on. Any tips for solving such problems is highly appreciated.
Thanks in advance.",['probability']
512521,How many $n$-disk legal configurations are there for the Tower of Hanoi?,"This question comes from this homework assignment from ECS20 at UC Davis. How many $n$-disk legal configurations are there for the Tower of Hanoi? A ""legal configuration"" means that no disk is larger than a disk beneath it on the same peg. All $n$ disks have different diameters. I am able to prove that the minimum number of required moves for $n$-disks is $2^n - 1$, however is that the maximum number of legal configurations for $n$-disks? I have been thinking about this for a while now and can't come to a conclusion. Any help or pointing in the right direction would be appreciated.","['arithmetic', 'algebra-precalculus', 'recreational-mathematics', 'discrete-mathematics']"
512534,Is the inverse operation on matrices distributive with respect to addition?,"For example, is the following true:
$$(A + B)^{-1} = A^{-1} + B^{-1}$$
If $\det(A) \ne 0$, $\det(B) \ne 0$, and $\det(A + B) \ne 0$.","['matrices', 'linear-algebra', 'inverse']"
512540,A question regarding the axioms of Separation and Replacement in ZFC,"It is well known that the axioms of Separation and Replacement are axiom schema, that is, they subsume an infinite number of first-order axioms for ZFC.  My question is, how large an infinity is this, or, perhaps better, how large an infinity should this be.  One can naively imagine this infinity to be as large as Ord, the proper class of all ordinals. If it were, could ZFC then be considered 'complete' contrary to the Godel incompleteness theorems?  Could one argue that ZFC could not have Ord many instances of Separation and Replacement?",['elementary-set-theory']
512548,Probability - exactly one of A and B occurs,"$A$ and $B$ are events that are subsets of the sample space. $C$ is the event that exactly one of $A$ and $B$ occurs. 1) Write an expression for $C$ in terms of unions, intersections and complements involving the events $A$ and $B$ 2) Let $P$ be a probability defined on the events of the sample space. Write an expression for $P(C)$ in terms of $P(A)$, $P(B)$ and $P(A \cap B)$. Give proof of your result. Would I be right in saying that 1) is just $C=(A \cup B)-(A \cap B)$ Or would it be? $(A \cap B^c) \cup (A^c \cap B)$",['probability']
512621,Finding all solutions of the Pell-type equation $x^2-5y^2 = -4$,"I wanted to solve the equation $x^2-5y^2 = -4$ with $x$ and $y$ integers. Let $\omega=\frac{1+\sqrt5}{2}$ and $A = \mathbb{Z}[\omega]$.
One can reduce the Pell equation to finding the elements of $A$ that have a norm equal to $-4$. I know that $N(2) = 4$, $N(\omega) = -1$, so that 
for all integer $n$, $N(\pm2\omega^{2n+1}) = -4$. How can I prove that there are no other solution? I am familiar with Dirichlet's unit theorem, and I have managed (using ad hoc inequalities) to show that $\omega$ is a fundamental unit.","['pell-type-equations', 'diophantine-equations', 'algebraic-number-theory', 'number-theory']"
512625,Damped Harmonic Oscillator and Response Function,"This is another one of those questions that I feel like I am almost there, but not quite, and it's the math that gets me. But here goes: For a driven damped harmonic oscillator, show that the full width at half maximum of the response function $| R(\omega)|^2$ is $\gamma$. Where $\gamma $ is the damping factor. So we start off with: $$\ddot x + \gamma \dot x + \omega_0x = \frac{F_{ext}(t)}{m} = f(t)$$ And I move to solve this. I know that the solution will be $x_0 e^{i\omega t}$ and that I should get the following: 
$$-\omega^2 x_0 e^{i\omega t} + (i\omega)x_0 e^{i\omega t}\gamma+ \omega_0^2x_0e^{i\omega t} = \frac{F_0 e^{i\omega t}}{m}$$ 
which turns into $$x_0 (\omega_0^2 -\omega^2 + (i\omega) \gamma ) = \frac{F_0}{m}= f_0$$ which then becomes $$x_0 = \frac{f_0}{\omega_0^2 -\omega^2 + (i\omega) \gamma }$$
The denominator should give me the response function $R(\omega)$. So I take the absolute value and square it and I get: $$|R(\omega^2)| = \frac{f_0}{\omega_0^2 -\omega^2 t + (i\omega) \gamma } \frac{f_0}{\omega_0^2 -\omega^2 t - (i\omega) \gamma } = \frac{f_0}{(\omega_0^2 -\omega^2)^2 + \gamma^2 \omega^2 }$$ So far so good. I want to find the maximum of this function and that means I want to know where the derivative of the denominator is zero. Taking that derivative: $$\frac{d}{d\omega}(\omega_0^2 -\omega^2)^2 + \gamma^2 \omega^2) = 2((\omega_0^2 -\omega^2)(2\omega) + 2\gamma^2 \omega = 0$$ and since it = 0 we can divide thru by $2\omega$ and we are left with $$-2(\omega_0^2 - \omega^2) + \gamma^2 = 0$$ and solving for $\omega$: $\omega = \sqrt{\omega_0^2 - \frac{\gamma^2}{2}} $. We will replace $\gamma$ with $2\beta$, leaving us $\omega = \sqrt{\omega_0^2 - 2 \beta^2} $ we know where the maximum is, but now we want to find the half-maximum. Plugging my $\omega$ back into my $|R(\omega)|^2$ expression, I have $$\frac{1}{(\omega_0^2 - \omega_0^2 + 2 \beta^2)^2 + 4\beta^4 (\omega_0^2 - 2\beta^2)}=\frac{1}{(2 \beta^2)^2 + 4\beta^4 (\omega_0^2 - 2\beta^2)}=\frac{1}{4 \beta^4 + 4\beta^2 \omega_0^2 - 8\beta^6}$$ which shows me the maximum of $|R(\omega)|^2$. At 1/2 that is the half maximum and I want to know what $\omega$ is at that point. So going back to my original equation I posit: $$|R(\omega^2)| = \frac{1}{(\omega_0^2 -\omega^2)^2 + 4\beta^2 \omega^2 }=\frac{1}{8 \beta^4 + 8\beta^2 \omega_0^2 - 16\beta^6}$$ But at this point I feel I have lost the plot. Going through this the whole thing struck me as more complicated than it needs to be. My text says showing this should be ""an easy exercise."" So I am turning to people here to see where I messed up. Best to you all, and thanks.","['ordinary-differential-equations', 'physics']"
512634,Express the statements using quantifiers example,"I'm having a little trouble understanding quantifiers and therefore doubting all my homework answers. Since there is no where to check if the answers are correct, I'm very very worried I am just practicing incorrectly. So I've set up two examples with what I think the answers are. It would be brilliant if you could confirm if I am correct or not so I could use these answers as a base to check my other answers. If I am incorrect, it would be awesome if you could point me the right direction! Express the statements using quantifiers. 
*note: ~ = negation. a) Everybody knows everybody. my answer: ∀xE(x), E(x) = knows everybody. b) Somebody knows everybody. my answer: ∃xE(x) c) There is somebody whom no one knows. my answer: ~∃xE(x)","['predicate-logic', 'quantifiers', 'discrete-mathematics']"
512647,Surprising limit (probability of no two coinciding pairs),"I stumbled upon this question by random chance. The motivation is kind of long, the question is pretty short; if you're just here for the limits, feel free to skip to the break. I'm taking five courses this semester, all of which meet on two days, and I happened to notice that all of my days seemed a little bit different. So I took a closer look at my schedule, and sure enough, none of my classes share the same two days. This struck me as very unlikely, so I decided to work out the probability of this occurring. Of course, in reality, there are all sorts of complicating factors that make certain distributions more favorable than others, but I decided to ignore that and just assume that the schedules were independent identically distributed variables. It was sort of convenient that there are also five days in a week, so the motivating question was this: In an $n$ day week, what is the probability that $n$ classes meeting twice each, do not have any pair that meets on the same two days? So I looked at the combinatorics, and I'm pretty sure the answer is the obnoxiously vertical formula
$$\frac{ \displaystyle  { {n \choose 2} \choose n} n!}{ {n \choose 2}^n}$$
The idea here is that there are ${n \choose 2}$ possible schedules, so the list of all possible outcomes includes $n$ choices with repetition from this pool, considering the classes distinguishable. The list of desired outcomes chooses $n$ choices without repetition from this pool, and then assigns the schedules to the classes. [ Perhaps this is not right; if not I'd be interested in that, too, but my question for you all is really about this expression, not my class situation :) ] Now I knew by working out by hand that $n=3$ gives about 22% and $n=4$ gives about 28%, and I computed my actual situation at about 30%. Monotone increasing is what I expected. After all, you have dramatically more ability to separate the classes during longer weeks. I also expected that this effect would quickly dominate the complication that more classes are being added in. But the picture that arises for (larger) small $n$ made it pretty clear that I was wrong . When I was playing around in WolframAlpha, I found the limit $$\lim_{n\to\infty}\frac{ \displaystyle  { {n \choose 2} \choose n} n!}{ {n \choose 2}^n} = \frac{1}{e}$$ That caught me off guard. I immediately thought of Stirling's approximation, but I can't make it fit, since in Stirling $e$ is raised to the $n^\text{th}$. Admittedly I don't know a lot of special limits, but writing it out in terms of factorials seems to get nowhere near the definition of $e$. Is there an elementary explanation for this limit? Bonus question: ""choose $2$"" seems to be a pretty special circumstance: if the twos are replaced by ones, the limit becomes $0$, and if the twos are replaced by threes or fours, the limit becomes $1$. My guess is that with the right explanation of the interesting case, the reason for these will become pretty obvious.","['limits', 'recreational-mathematics', 'probability', 'combinatorics']"
512688,"Show that $x^2+5y^2=2z^2$ has only trivial solution $(x,y,z)=(0,0,0)$","I have no way to start with this problem. Can anyone give me a hint? Show that $x^2+5y^2=2z^2$ has only trivial solution $(x,y,z)=(0,0,0)$","['diophantine-equations', 'congruences', 'number-theory']"
512706,prove that there are infinitely many integers n so that 3 does not divide $\phi(n)$,prove that there are infinitely many integers n so that 3 does not divide $\phi(n)$ I began to look at the problem with the residue classes of 3. I am not sure if this is correct.,['number-theory']
512721,Existence and Uniqueness of complex ODE's,"I'm wondering if there is a theorem for the existence and uniqueness of complex ODE's. If there is, would someone mind explaining the general breadth of the theorem and/or directions to an online source detailing this theorem? That would be great.","['ordinary-differential-equations', 'complex-analysis']"
512728,Intersection of int(cl) of open sets,"$\newcommand{\cl}{\operatorname{cl}}$ $\newcommand{\i}{\operatorname{int}}$ Prove that if $A$ and $B$ are open, then $\i(\cl(A\cap B))=\i(\cl A) \cap \i(\cl B)$. One way implication is easy as we have $$\cl(A\cap B)\subseteq \cl A \cap \cl B \Rightarrow \i(\cl(A\cap B))\subseteq \i(\cl(A)\cap \cl(B))= \i \cl A \cap \i\cl B.
$$ I had difficulties in proving the other way. Let $x \in \i\cl(A) \cap \i\cl(B).$ Then there are open neighborhoods $U$, $V$ of $x$ such that $x\in U\subseteq \cl A$ and $x\in V\subseteq \cl B.$ I want to show that$ U\cap V \subseteq \cl(A \cap B)$ hence implies that this way implication is true. let $y\in U\cap V$ and $R$ to be any open neighborhood of $y$. Then $R\cap A$ and$ R\cap B$ are non-empty. But I am stuck here when I try to prove that $R \cap A \cap B$ is non-empty. (Because if $R \cap A\cap B$ is non-empty were to be true, then I am done). Can anyone give me some hints to proceed in this proof?Or actually I am heading in the wrong direction?","['general-topology', 'elementary-set-theory']"
512743,Showing continuity of partially defined map,"There is a theorem in Note on Cofibrations by Arne Strøm. It says Let $A$ be a closed subspace of a topological space $X$. Then $(X,A)$ has the HEP if and only if there are (i) a neighborhood $U$ of $A$ which is deformable in $X$ to $A$ rel$A$, i.e. there is an $H:U\times I\to X$ s.t. $H(x,0)=x,\ H(x,1)\in A,\ H(a,t)=a$ for all $a\in A,x\in X,t\in I.$ (ii) a map $\phi:X\to I$ s.t. $A=\phi^{-1}(0)$ and $\phi(x)=1$ for all $x\notin U$ To show that $(X,A)$ has the HEP, one constructs a retraction $X\times I\to A\times I\cup X\times\{0\}$. Such a one is given in the proof, namely: $$r(x,t)=\begin{cases}
(x,\ 0), &\text{ if }\phi(x)=1\\
(H(x,2(1-\phi(x))t),\ 0), &\text{ if }1/2\le\phi(x)<1\\
(H(x,t/(2\phi(x))),\ 0), &\text{ if }0<\phi(x)\le1/2,\ t\le2\phi(x)\\
(H(x,1),\ t-2\phi(x)), &\text{ if }0\le\phi(x)\le1/2,\ t\ge2\phi(x)
\end{cases}$$ Now, these partial functions could easily be glued to a single continuous function if the domains were closed, but they are not. So, in order to show continuity, especially on the union of the first two domains, that is on
$\phi^{-1}\left[\left[\frac12,1\right]\right]$, one takes an element $(x,t)$ and shows that the function is continuous at that point. Since
$\phi^{-1}[[0,1)]$ is an open subset of $U$ and the homotopy $H$ is only used for $\phi(x)<1$ in the construction of $r$, we can assume that $U=\phi^{-1}[[0,1)]$ and is open. Let us define the map
$$s:\{x\in X\mid\phi(x)\ge1/2\}\times I\to X\times I\\
(x,t)\mapsto(x,2(1-\phi(x))t)$$
The image of $s$ is the set $S=\{(x,t)\mid t\le2(1-\phi(x))\le1\}$. Now, $r(x,t)$ can written as $(\tilde Hs(x,t),0)$ where $\tilde H:S\to X$ is defined by
$$\tilde H(x,t)=\begin{cases}
H(x,t)  &\text{ if }x\in U\\
x,  &\text{ if }t=0
\end{cases}$$ The map $s$ is continuous, so it would be enough to show continuity of $\tilde H$. This is only nontrivial for $x\in\partial U.$ Then $x\notin U$ and $\phi(x)=1$, so $t=0$. I take an open neighborhood $V$ about $x=\tilde H(x,0)$ and try to find a neighborhood $W$ of $x$ such that $H[W\times I\cap S]\subseteq V$. But how can I find this $W$? Clearly, it must be a subset of $V$.","['general-topology', 'homotopy-theory', 'continuity']"
512751,What is the purpose of implication in discrete mathematics?,"I would be obliged if you can show me an example of a truth table for implication where there is a also a real life aspect to it. (i.e., where would someone use the scenario to make F->F = T and also the same for the remaining 3 cases). However, this one scenario should be able to be adjusted to fit all three. Hopefully that makes sense. I am just trying to understand the concept of implication.","['logic', 'discrete-mathematics']"
512752,Injectivity of the dual map,"Suppose V and W are vector spaces of  possibly finite and infinite dimension over a field K. Show that if a linear map $L : V → W$ is surjective the its dual is injective.
Also prove the converse of the last implication. Well when V,W are finite spaces i can prove it and i understand that dimension is not necessary if i want prove surjective implies injective. Other way injective implies surjective when is finite i take a basis ${e_1,….,e_n}$ of V then ${Le_1,….,Le_n}$ is l.i. in W so we can extend a basis ${Le_1,….,Le_n,w_1,…,w_k}$ of W and define:$f: W → K$ by $f(Le_i) = g(w_i)$ and $f(w_i)=0$ then $L^*: V → K$ and$L^*(f)(e_i) = (fL)(e_i) = f(Le_i)=g(e_i)$ then $L^*(f)=g$ But what happen if V and W is infinite dimension?.","['vector-spaces', 'linear-algebra', 'category-theory']"
512755,Independence of a random variable $X$ from itself,"In our lecture on probability, my professor made the comment that ""a random variable X is not independent from itself."" (Here he was specifically talking about discrete random variables.) I asked him why that was true. (My intuition for two counterexamples are $X \equiv 0$ and $X$ s.t. $$m_X(x) = \begin{cases}1, &\text{ if } x = x_0\\ 0, &\text{ if }x \neq x_0.)\end{cases}$$ In these cases, it seems that $\mathbb{P}(X \leq x_1 , X \leq x_2) = \mathbb{P}(X \leq x_1) \cdot \mathbb{P}(X \leq x_2)$. My professor's response was, ""The independence from or dependence of $X$ on itself depends on the definition of the joint distribution function $m_{X,X}$, which is essentially arbitrary."" Can someone help me to understand this?","['probability', 'random-variables']"
512768,Explanation for $\lim_{x\to\infty}\sqrt{x^2-4x}-x=-2$ and not $0$,"I am trying to intuitively understand why the solution to the following problem is $-2$. $$\lim_{x\to\infty}\sqrt{x^2-4x}-x$$
$$\lim_{x\to\infty}(\sqrt{x^2-4x}-x)\frac{\sqrt{x^2-4x}+x}{\sqrt{x^2-4x}+x}$$
$$\lim_{x\to\infty}\frac{x^2-4x-x^2}{\sqrt{x^2-4x}+x}$$
$$\lim_{x\to\infty}\frac{-4x}{\sqrt{x^2-4x}+x}$$
$$\lim_{x\to\infty}\frac{-4}{\sqrt{1-\frac{4}{x}}+1}$$
$$\frac{-4}{\sqrt{1-0}+1}$$
$$\frac{-4}{2}$$
$$-2$$
I can understand the process that results in the answer being $-2$. However, I expected the result to be $0$. I have learned that when dealing with a limit approaching $\infty$, only the highest degree term matters because the others will not be as significant. For this reason, I thought that the $4x$ would be ignored, resulting in:
$$\lim_{x\to\infty}\sqrt{x^2-4x}-x$$
$$\lim_{x\to\infty}\sqrt{x^2}-x$$
$$\lim_{x\to\infty}x-x$$
$$\lim_{x\to\infty}0$$
$$0$$
Why is the above process incorrect?","['calculus', 'radicals', 'arithmetic', 'intuition', 'limits']"
512769,Help in proof of Compactness implies limit point compactness.,"Munkres' Topology says Theorem 28.1.  Compactness implies limit point compactness, but not conversely. Proof .  Let $X$ be a compact space.  Given a subset $A$ of $X$, we wish to prove that if $A$ is infinite, then $A$ has a limit point.  We prove the contrapositive - if $A$ has no limit point, then $A$ must be finite.
      Suppose $A$ has no limit point. Then $A$ contains all its limit points, so that $A$ is closed. .... That's confusing.  Do they mean vacuously $A$ must be closed since it has no limit points even to contain?",['general-topology']
512807,Generating Pythagorean Triples S.T. $b = a+1$,"I am looking for a method to generate Pythagorean Triples $(a,b,c)$. There are many methods listed on Wikipedia but I have a unique constraint that I can't seem to integrate into any of the listed methods. I need to generate Pythagorean Triples $(a,b,c)$ such that: $$a^2 + b^2 = c^2$$
$$a\lt b\lt c \,; \quad a,b,c \in \Bbb Z^+$$
$$and $$
$$b=a+1$$ Is there a way to modify one of the listed methods to include this constraint?","['elementary-number-theory', 'triangles', 'algebra-precalculus']"
512808,locally isometric is not a symmetric relation.,The relation of being locally isometric for Riemannian manifolds is reflexive and transitive. Is it symmetric? Can you give me an example?,"['riemannian-geometry', 'differential-geometry']"
512810,"Definition about ""infinitely often""","As we know, ""$A_n \text{ i.o.}$"" means $A_n$ happens infinitely often, where $A_n$ is an event. I'm not sure whether ""the complement of $A_n$ happens for large $n$"" is the complement of the preceding event. Can anyone help me?","['probability-theory', 'logic']"
512834,Frobenius twist commutes with fiber product,"Let $k$ be a field, and let $X$ be a scheme over $k$.  Let $f:k\to k$ be the embedding of fields defined by $f(\lambda)=\lambda^p$.  Define the first Frobenius twist of $X$ to be the scheme $X\times_f k$, where we consider $\operatorname{spec}k$ as a scheme over itself via $f$.  The first Frobenius twist can be viewed as a functor from the category of schemes over $k$ to itself. I'd like to show that the bifunctors $(-\times_k-)^{(1)}$ and $(-)^{(1)}\times_k(-)^{(1)}$ are naturally isomorphic.  To do so, for any schemes $X$ and $Y$, I need to define an isomorphism $$\varphi_{X,Y}:(X\times_kY)\times_fk\to(X\times_fk)\times_k(Y\times_fk)$$ I don't know how to think about schemes very well, so I've resorted to using the universal property of the fiber product many different times to arrive at some fairly large and complicated commutative diagrams in order to define $\varphi_{X,Y}$.  Even though this method gives me the existence of such a morphism, it is not clear to me how to show this is an isomorphism (perhaps larger commutative diagrams, which would be horrible). I would like to know if there is a better way to think about the above canonical identification, or in other words, how would someone well-versed in algebraic geometry solve my exercise (if at all!). In the affine case, I can think of the isomorphism of commutative $k$-algebras $$(k[X]\otimes_fk)\otimes_k(k[Y]\otimes_fk)\cong(k[X]\otimes_kk[Y])\otimes_fk$$ but I'd like to be able to think in the language of general schemes (I'm always more comfortable in the affine case, because all of the information is contained in a nice, concrete $k$-algebra).","['algebraic-geometry', 'schemes']"
512839,Solving ODE $\frac{(1-2y)y'}{y-y^2}=(x+4)^3$,"Consider the ODE
$$\frac{(1-2y)y'}{y-y^2}=(x+4)^3.$$ The answer is supposed to be $$\ln\Bigl(y(1-y)\Bigr)=\frac{(x+4)^4}{4}+C.$$ However, I'm not sure how to get to that answer. I can easily see how to get the right side of the answer, I know that's the integral of $(x+4)^3$.  I expanded the left side to get $$\frac{y'-2yy'}{y-y^2}.$$ I'm assuming I have to do the integral of that somewhere to get $\ln$, but this is where I got stuck.  How do I do the rest of the problem?  Thanks.",['ordinary-differential-equations']
512863,How to calculate this series?,"$$\sum^{\infty}_{n=0} (-1)^n\frac{n+1}{n!}$$ I've been working on it for one WHOLE day, still have no clue. I think it's time to seek for help....>< Any hint to compute this series? Thanks!!","['sequences-and-series', 'calculus']"
512877,Math Joke about Differentiation,"So I recently read a joke that goes like this: A constant function and $e^x$ are walking on Broadway. Then suddenly the constant function sees a differential operator approaching and runs away. So $e^x$ follows him and asks why the hurry. ""Well, you see, there's this differential operator coming this way, and when we meet, he'll differentiate me and nothing will be left of me...!"" ""Ah,"" says $e^x$ , ""he won't bother ME, I'm e to the x!"" and he walks on. Of course he meets the differential operator after a short distance. ex: ""Hi, I'm $e^x$ "" diff.op.: ""Hi, I'm $d\over dy$ "" What I dont understand is, Isn't ${d\over dy}\left(e^x\right)$ supposed to be $e^x {dx\over dy}$ because of the Chain rule? So what does the joke mean?","['derivatives', 'soft-question']"
512879,Integral of the square of the normal distribution.,"Does someone know what the integral of the square of the normal distribution with standard deviation sigma over the range $-\infty$ to $+\infty$ is? 
Thanks!","['calculus', 'integration']"
512891,Euler character of etale finite cover,"Let $\pi: \tilde{X} \to X$ be an etale finite cover, then why the Euler character has relation:
$$\chi(\tilde{X},\mathcal{O}_{\tilde{X}})=\deg(\pi)\chi({X},\mathcal{O}_{{X}}).$$ I try to use  Riemann-Roch, but do not know how to relate Chern characters and Todd class of them. Besides, I found a similar question on topological setting .",['algebraic-geometry']
512906,Why does there exist a unique quotient topology that makes a given surjective map a quotient map?,"I'm reading Munkres on the quotient topology, pg. 138 It says that: If $X$ is a topological space and $A$ is a set and if $p: X \to A$ is a surjective map, then there exists exactly one topology on $A$ relative to which $p$ is a quotient map. It then goes on to say that this topology is defined by letting the open sets be those subsets $U$ of $A$ such that $p^{-1}(U)$ is open in $X$. I understand why this is a topology, and I understand why this makes the $p$ map a quotient map. I just don't understand why this is the only topology to make $p$ a quotient map. I understand that it may be a minimal topology to make $p$ a quotient map. It was my understanding that being a quotient map is a rather weak condition compared to others such as being an open map (when surjectivity is assumed). So couldn't we have defined a topology on $A$ that makes $p$ into an open map, whereby it would then be a quotient map? This topology would be finer than the one given above and could be defined by having the open sets $U$ be those where there exists an open set $V$ in $X$ such that $p(V) = U$. Is there any substantive difference here or would they essentially be the same topologies?","['general-topology', 'quotient-spaces']"
512912,Is this a function and injective/surjective question,"Consider the set $A={(x^2, x):x \in R}$. Is this a function from $R$ to $R$? I know it will be a function if there is a unique output per input, but I've never seen a function formatted like this. Is the $x^2$ the independent value and $x$ the dependent? A function $f:Z \rightarrow Z x Z$ is defined as $f(n) = (2n, n+3)$. Verify whether this function is injective and whether it is surjective. Here I'm confused how to prove either injective and surjective. I can't see an $n$ such that I get the same output making it not injective, thus I think it's injective...but not sure how to show it. I don't think it's surjective because $f(n)$ does not map to $(1, 0)$ for example. But if something were surjective how would I prove it? Thanks for any help!",['functions']
512936,Equilibrium points of the ODE $y'=\sin y−\frac{y}{2}$.,"Find the equilibrium points of the ODE, and investigate their stability: $$y'=\sin y−\frac{y}{2}.$$ I know the equilibrium points are about $1.9$, $-1.9$, and $0$.  Not sure how to get to that point though. I went ahead and tried to create a graph to find the stability of the problem.  I got this (forgive my poor artwork): https://i.sstatic.net/nG2Cd.png From this I'm inferring that at $+1.9$ and $-1.9$ the solution is stable, and at $0$ it's unstable because of the split.  Would be great if someone confirmed this. Thanks for the help.",['ordinary-differential-equations']
512948,Corollary to Preissman's theorem,"Preismann's theorem states (ref. Petersen's ""Riemannian Geometry"", chapter 6): On a compact manifold with negative sectional curvature, any abelian subgroup of the fundamental group is cyclic. A corollary is stated: No compact product manifold admits a metric with negative curvature. I don't understand how the corollary follows from the thoerem. Of course it would if, on a product manifold, there are always non-cyclic abelian subgroups of the fundamental group. Is this true? (It seems like it shouldn't be, taking for example the product of simply connected manifolds.)","['riemannian-geometry', 'differential-geometry']"
512989,Equation of Earth's Orbit around Sun (ellipse),"The preihelion is the smallest distance from a planet to the sun, and aphelion is the greatest distance. The sun is one of the two foci. For the Earth, the perihelion is 147.1 million km and the aphelion is 152.1 million km. These two distances help identify the location of the sun on the major axis of Earth's elliptical orbit. Assume that the major axis of Earth is on the x-axis. a. Find an equation of the Earth's orbit about the sun. b. With the given information,  estimate Earth's speed around the sun in milers per hour. So I'm thinking half the total distance of the aphelion and perihelion would give half the major axis. ($\frac{147.1+152.1}{2}=149.6$) My problem is how would I find the length of the minor axis?
$$\frac{x^2}{149.6^2}+\frac{y^2}{?}=1$$ Thanks for any help!","['geometry', 'euclidean-geometry']"
512994,Guessing a number between 1 and 100 in 7 guesses or less.,"This question was asked before but I have a lot of trouble understanding the answers given. Why is it that a number selected at random between 1 and 100 can be determined in 7 or less guesses by always guessing the number in the middle of the remaining values, given that you're told whether your previous guess was too high or low? Here's a link to the earlier thread: Guessing number between 1-100 always can always be guessed in 7 guess. Why? I wonder if someone could explain this in greater detail?","['statistics', 'probability']"
513010,Either $a^{2}\neq b^{2}$ or $a^3\neq b^3.$,"If a and b are distinct group elements, prove that either $a^{2}\neq b^{2}$ or $a^3\neq b^3.$ I tried doing the operation by inverses to get the identity, but that does nothing.",['group-theory']
513018,Are continued fractions a mere curiosity?,"Does algebraic geometry have a good understanding of continued fractions? What kind of geometric or arithmetic information does a continued fraction expansion contain, if any? Are there rings of formal continued fractions?","['algebraic-geometry', 'continued-fractions']"
513023,About the fact that every natural number which is coprime to $10$ has a multiple in the form that each digit is $1$.,"It is known that every natural number which is coprime to $10$ has a multiple in the form that each digit is $1$. For example, we can see
$$111=3\times 37, 111111=7\times 15873, 111111111=9\times 12345679, $$$$11=11\times 1, 111111=13\times 8547,\cdots$$ To prove the above fact is easy if we use Pigeonhole principle. Then, here is my question. Question : How can we get the minimum digit (let this be $N(m)$) of multiples of $m$ in the above form for any $m\in\mathbb N$ which is coprime to $10$? (I think the best answer would be to represent $N(m)$ by $m$ if it is possible.) For example, though we get $111111111111=13\times 8547008547$, we know that $N(13)=6.$ Motivation : The above fact got me interested in this question.",['number-theory']
513045,"Need to prove that $(S,\cdot)$ defined by the binary operation $a\cdot b = a+b+ab$ is an abelian group on $S = \Bbb R \setminus \{-1\}$.","So basically this proof centers around proving that (S,*) is a group, as it's quite easy to see that it's abelian as both addition and multiplication are commutative. My issue is finding an identity element, other than 0. Because if 0 is the identity element, then this group won't have inverses. The set explicitly excludes -1, which I found to be its identity element, which makes going about proving that this is a group mighty difficult.","['group-theory', 'abelian-groups']"
513053,Is $\prod \limits_{n=2}^{\infty}(1-\frac{1}{n^2})=1$ [duplicate],"This question already has answers here : Finding Value of the Infinite Product $\prod \Bigl(1-\frac{1}{n^{2}}\Bigr)$ (6 answers) Closed 9 years ago . Question is to check if  $\prod \limits_{n=2}^{\infty}(1-\frac{1}{n^2})=1$ we have $\prod \limits_{n=2}^{\infty}(1-\frac{1}{n^2})=\prod \limits_{n=2}^{\infty}(\frac{n^2-1}{n^2})=\prod \limits_{n=2}^{\infty}\frac{n+1}{n}\frac{n-1}{n}=(\frac{3}{2}.\frac{1}{2})(\frac{4}{3}.\frac{2}{3})(\frac{5}{4}.\frac{3}{4})...$ In above product we have for each term $\frac{a}{b}$ a term $\frac{b}{a}$ except for $\frac{1}{2}$.. So, all  other terms gets cancelled and we left with $\frac{1}{2}$. So, $\prod \limits_{n=2}^{\infty}(1-\frac{1}{n^2})=\frac{1}{2}$. I would be thankful if some one can assure that this explanation is correct/wrong?? I am solving this kind of problems for the first time so, it would be helpful if some one can tell if there are any other ways to do this.. Thank you","['sequences-and-series', 'infinite-product', 'real-analysis']"
513059,Prove that an automorphism group is a normal subgroup,"Let $G$ be a group, let $T$ be an automorphism of $G$, and let $N$ be a normal subgroup of $G$. Prove that $T(N)=\{T(x) \mid x\in N\}$ is a normal subgroup of $G$. I would prefer a hint to get started, rather than a full solution.",['group-theory']
513071,Tetrahedron inequality,"Do we have an analogue to triangle inequality in 3-D say tetrahedron inequality(or any other relation), which once satisfied by any  six real numbers; implies an existence of a tetrahedron with those side lengths?",['geometry']
513091,A little rusty on my contour integration..,"I've been asked to compute $\displaystyle\int_{0}^{\infty}\frac{x^2}{(x^2+1)^2(x^2+2x+2)}dx$ via finding the poles of the integrand and then construncting a contour to take advantage of cauchy's residue theorem. I have already computed the residues, but I keep coming up with something like $\frac{5 \pi}{3}$. However it is now to my realization that the integral is not symmetric about 0, so we have to find a different approach... Thanks!
EDIT: this isn't homework, I've been doing some integration problems on my own to brush up on it.","['integration', 'complex-analysis', 'contour-integration']"
513097,Infinite Inclusion and Exclusion in Probability,"Is there some way of generalizing the principle of inclusion and exclusion for infinite unions in the context of probability? In particular, I would like to say that $$P\left(\bigcup_nA_n\right) = \sum_nP(A_n) - \sum_{n \neq m}P(A_n \cap A_m) + \ldots$$ Does the above hold when all the infinite sums converge (and the sum of the infinite sums converges)? Also, is there a generalization to avoid the problem of the sums diverging?","['probability-theory', 'inclusion-exclusion']"
513102,"What does ""$.05$ irrespective of the value of $\hat p$"" mean?","I have a statistics question that says ""What sample size would be required for the width of a $99$% confidence interval to be at most $.05$ irrespective of the value of $\hat p$?"". But I'm not sure what irrespective is refering to. I tried to figure it out in my book but I can't find where exactly it explains it.",['statistics']
513125,There is a subspace $W$ of $V$ such that $V = U \oplus W$,"I have a question about the following proof of the statement that for every subspace $U$ of a finite dimensional vector space $V$ there is a subspace $W$ of $V$ such that $V = U \oplus W$. Proof: Because $V$ is finite-dimensional, so is $U$. Thus there is a basis $(u_1,\ldots,u_m)$ of U. Of course $(u_1,\ldots,u_m)$ is a linearly independent list of vectors in $V$, and thus it can be extended to a basis $(u_1,\ldots,u_m, w_1, \ldots,w_n)$ of $V$. Let $W = \text{span}(w_1,\ldots,w_n).$ To prove that $V = U \oplus W$, we need to show that $$V = U + W \text{ and } U \cap W = \{0\}.$$ To prove the first equation, suppose that $v \in V$. Then, because the list $(u_1,\ldots,u_m, w_1, \ldots,w_n)$ spans $V$, there exist scalars $a_1,\ldots,a_m,b_1,\ldots,b_n \in \mathbb{F}$ such that $$v = \underbrace{a_1u_1 + \dotsb + a_mu_m} + \underbrace{b_1w_1 + \dotsb + b_nw_n}.$$ In other words, we have $v = u + w$, where $u \in U$ and $w \in W$ are defined as above. Thus $v \in U + W$. I understand everything up until this point, the next part of the proof is the portion that I wish to clarify. To show that $U \cap W = \{0\}$, suppose $v \in U \cap W$. Then there exist scalars $a_1,\ldots,a_m,b_1,...,b_n \in \mathbb{F}$ such that $$v = a_1u_1 + \dotsb+a_mu_m = b_1w_1 + \dotsb + b_nw_n. $$ Halt! See the above. How does the notion that $v \in U\cap W$ lead to the equality $v = a_1u_1 + \dotsb+a_mu_m = b_1w_1 + \dotsb + b_nw_n$? Or how does the containment of $v$ in  $U$ and $W$ yield the equality $v = a_1u_1 + \dotsb+a_mu_m = b_1w_1 + \dotsb + b_nw_n$?",['linear-algebra']
513126,Find an example about the connectedness.,"Let $I=[0,1]$ and $I\times I$ be a subspace of $\Bbb R^2$. Find an example satisfying the following conditions: $A$ and $B$ are subsets of $I\times I$. $A$ and $B$ are connected. $(0,0), (1,1)\in A$ and $(0,1), (1,0)\in B$. $A \cap B=\varnothing$.","['general-topology', 'connectedness']"
513141,Infinite Series $\sum_{k=1}^{\infty}\frac{1}{(mk^2-n)^2}$,"How can we prove the following formula? $$\sum_{k=1}^{\infty}\frac{1}{(mk^2-n)^2}=\frac{-2m+\sqrt{mn}\pi\cot\left(\sqrt{\frac{n}{m}}\pi\right)+n\pi^2\csc^2\left(\sqrt{\frac{n}{m}}\pi\right)}{4mn^2}$$ What is the general method for finding sums of the form $\sum\limits_{k=1}^{\infty}\frac{1}{(mk^2-n)^\ell}, \ell\in\mathbb{N}$ ?","['complex-analysis', 'closed-form', 'sequences-and-series', 'real-analysis']"
513143,Gambler's Ruin Problem,"Two gamblers, A and B, initially have capital 7 and  13 respectively. At each round of the 
game, player A wins 1 from B with probability p, or loses 1 to B with probability q = 1 - p. 
Assume that 0 < p < 1 and that different rounds of game are independent. A and B play until one of them is ruined. Find the probability of each of the following events: (a) the event that there is at least one gambler whose capital has ever been 4 (b) the event that the capital of gambler A has ever been 4 (c) the event that the capital of each gambler has ever been 4. I have thought of using the following formula for gambler A : As for gambler B , after replacing k by a - k , p by q , q by p, we have : I somehow tried to change a = 20 to a = 16 but somehow the numbers just don't add up. What do you guys think ?","['probability-theory', 'probability']"
513147,Visualizing a projective variety,"What does the variety $V(x_0^2+x_1^2+x_2^2)\subset \mathbb{P}^2$ look like? It seems to me like a single point... In general, are there any good ways/tips/tricks to visualize projective varieties?","['algebraic-geometry', 'visualization', 'projective-geometry']"
513174,Find coefficient of $x^{50}$ in $(\sum_{i=1}^{\infty}x^n)^3$,How do you find the coefficient of $x^{50}$ in $(\sum_{i=1}^{\infty}x^n)^3$?,['sequences-and-series']
513180,automorphisms of rigidified line bundles,"Let $\mathcal{L}$ be a line bundle over a proper variety $X/k$. Choose a $k$-rational point $P$ in some fibre of $\mathcal{L}$. Why are there no non-trivial automorphisms of $\mathcal{L}$ fixing $P$? Does this have something to do with $\Gamma(X,\mathcal{O}_X) = k$? ($\mathrm{Hom}(\mathcal{L},\mathcal{L}) = \mathrm{Hom}(\mathcal{O}_X,\mathcal{O}_X) = \Gamma(X,\mathcal{O}_X) = k$)",['algebraic-geometry']
513204,Does this sequence always give a square number?,"Question : Supposing that  a sequence $\{a_n\}$ is defined as 
$${a_{n+3}}^2=-{a_{n+2}}^2+2{a_{n+1}}^2+48a_{n+1}a_{n}+32{a_n}^2\ (n\ge 1)$$
$$a_1=a_2=a_3=1$$
then, is $a_n$ a square number for any $n$? For example, we can see
$$\sqrt{a_n} : 1,1,1,3,1,5,7,3,17,11,23,45,1,91,89,93,271,85,457,627,287,1541,967,2115,\cdots$$ Motivation : I found the following question in a book without any proof. Supposing that a sequence $\{b_n\}$ is defined as 
$$b_{n+3}=-b_{n+2}+2b_{n+1}+8b_n\ (n\ge 1)$$
$$b_1=b_2=b_3=1,$$
then, prove that $b_n$ is a square number for any $n$. This is obvious by the following relational expression : 
$$(b_{n+3}-b_{n+2})^2=64b_{n+1}b_n,$$
which can be shown by induction on $n$. After solving this question, I've tried to find a similar sequence by using computer. Then, I reached the above expectation. The expectation seems true, but I can neither find any counterexample nor prove that the sequence always gives a square number. Can anyone help?",['sequences-and-series']
513223,"Example of ""ring"" without the distributive property?","Can anyone give an example of an ""non-artificial"" algebraic structure that fails to be a ring only because of a lack of one- and two-sided distributive property?","['ring-theory', 'abstract-algebra']"
513237,Hochschild homology - motivation and examples,"I'm currently trying to learn about Hochschild homology of differential graded algebras. After reading the definition, the notion of Hochschild homology is somewhat unmotivated and myterious to me. What is the motivation to define Hochschild homology and what are some nice examples? I'm particularly interested in the Hochschild homology of truncated polynomial algebras $$k[x]/(x^{n+1})$$ where $k$ is a field of characteristic zero and $x$ is of some degree $d$. Are there any nice references for Hochschild homology?","['homological-algebra', 'hochschild-cohomology', 'abstract-algebra']"
513248,The degree of every smooth map $\mathbb{R}^n \to \mathbb{R}^n$ is one...,"Let $\varphi : M^n \to N^n$ be a proper smooth map between two connected smooth manifolds. Then $\varphi$ induces a linear map $\varphi^* : H_c^n(N) \simeq \mathbb{R} \to H_c^n(M) \simeq \mathbb{R}$ (where $H_c^n$ is the $n$-th de Rham cohomology group with compact support), so there exists $d \in \mathbb{R}$ so that $\varphi^* : x \mapsto d \cdot x$; $d$ is called the degree of $\varphi$. Moreover, it can be shown that if $\varphi : M \to N$ and $\phi : M\to N$ are smoothly homotopic, then $\varphi^*= \phi^*$ hence $\deg(\varphi)= \deg(\phi)$. However, every proper smooth map $f : \mathbb{R}^n \to \mathbb{R}^n$ and $g : \mathbb{R}^n \to \mathbb{R}^n$ are smoothly homotopic (thanks to $H(t,x)= tf(x)+(1-t)g(x)$), so every proper smooth map $\mathbb{R}^n \to \mathbb{R}^n$ should have the same degree... It is probably a silly question, but where does my argument fail? Edit: Sean Eberhard found a first problem; in fact, to conclude that $\varphi^*=\phi^*$ it is needed the homotopy be proper at any $t$. However, here is another contradiction: If $P(z)=z^n$ (where $\mathbb{R}^2$ and $\mathbb{C}$ are not distinguised), $\deg(P)=n$ and $P$ is proper if $n \geq 1$. Taking $H(t,z)=tz^m+(1-t)z^n$ with $m>n>1$, $m= \deg(H(1, \cdot))= \deg(H(0,\cdot))=n$, a contradiction.","['differential-topology', 'homology-cohomology', 'differential-geometry']"
513250,Conditional probability question with cards where the other side color is to be guessed,"A box contains three cards. One card is red on both
sides, one card is green on both sides, and one card is red
on one side and green on the other. One card is selected
from the box at random, and the color on one side is
observed. If this side is green, what is the probability that
the other side of the card is also green? I think the answer should be $\frac{1}{2}$ as once the card is selected with one side green, there remain only two possibilities  for the other side: either red or green. But the answer to this question is $\frac{2}{3}$. So,where am I wrong?Why the answer $\frac{2}{3}$ is the $\frac{1}{2}$ wrong? Please explain! Thank you.","['probability', 'conditional-probability']"
513258,Definition of Linear Differential Equation,"I am a 13 year old self teaching myself Differential Equations from a website and a book, I came across the definition of a Linear Differential Equation but I didn't understand the definition, I looked on other websites and even found a Chinese book from the library about differential equations (I'm Chinese just saying) but I still didn't understand the definition of it, I think its just the Notation messing me up. Can someone explain to me what exactly a Linear Differential Equation is in simple words? I've seen a definition that looks like this:
$$a_n(t)y^{(n)}(t)+a_{n-1}(t)y^{(n-1)}(t)+......+a_1(t)y^{(1)}(t)+a_0(t)y(t)=g(t)$$ Thanks in Advance, Yan Yau","['ordinary-differential-equations', 'definition']"
513260,Probabilistic riddle [duplicate],"This question already has answers here : Multiple-choice question about the probability of a random answer to itself being correct (6 answers) Closed 6 years ago . If you choose an answer to this question at random, then what is the
chance you will be correct? A) 25% B) 50% C) 60% D) 25% On internet you can find the problem here .","['puzzle', 'probability']"
513269,Semigroups defined by the subsets of groups,"In a group $G$, the non empty subsets form a semigroup (with identity) under the usual multiplication $ST=\{st \mid s\in S, t \in T\}$. This semigroup seems to be very rich of information, for instance if $G$ is finite the idempotents in this semigroup are exactly the subgroups of $G$.  Also for any (non empty) subset $S$, there is a power $S^n$ of $S$ which is an idempotent, and so a subgroup of $G$. if $S$ contains the identity, this would be the subgroup generated by $S$ (I don't know what happen if $S$ does not contain the identity). 1) Is there any attempts to studying such a semigroup, and its relations to the underlying group? 2) If $G$ is finite, our subsets can be identified to the elements of the group algebra $\mathbb{Z}_2[G]$, the multiplication in this algebra is somewhat different from the above one; can one covers the information about the semigroup of subsets of $G$ by only studying the group algebra $\mathbb{Z}_2[G]$?. Thanks in advance.",['group-theory']
513277,Is there a closed form expression for the Taylor series of exp((f(z))?,"Given a holomorphic function $f(z) = \sum_{k=0}^\infty f_k z^k/k!$, is there a readable formula for the Taylor series of $\exp(f(z))$? Using the chain and product rules, one can obtain
$$\partial_z e^f = f' e^f, \partial_z^2 e^f = (f''+f'^2)e^f, \partial_z^3 e^f = (f'''+2f''f'+(f''+f'^2)f')e^f,...$$
to obtain
$$\exp(f(z)-f_0) = 1 + f_1z + (f_2+f_1^2)z^2/ + (f_3+3f_2f_2+f_1^3)z^3/3! + \mathcal O(z^4)$$
but that's tedious and only yields the first view terms. Is the a more general formula to directly obtain all coefficients of this series?","['complex-analysis', 'taylor-expansion']"
513288,Test for acyclic graph property based on adjacency matrix,"I am trying to solve a problem that I have but I lack the theoretical knowledge that might be necessary to solve it. I have a directed graph encoded as an adjacency matrix. Is it possible to test whether a graph is acyclic just by using algebra (operations/transformations/properties of that adjacency matrix)?
Any help greatly appreciated. Thank you.","['matrices', 'graph-theory']"
513342,Expected squared prediction error,"I'm reading about statistical decision theory and on one point in my book the author defines the expected squared prediction error by: $$EPE = E(Y-g(X))^2 = \int(y -g(x))^2Pr(dx, dy)$$ I like to write this with the density function so that it stays more precise: $$EPE = \int\int(y-g(x))^2f(x,y)\;dx\;dy$$ Now on the other part the author says that by conditioning on $X$, $EPE$ can be written as: $$EPE = E_XE_{Y|X}([Y-g(X)]^2\;|\;X)$$ For some reason this notation confuses me...could someone write this conditional notation of $EPE$ more precisely, i.e. so that it would include the joint density function of random variables $X$ and $Y$ etc.? Just to be sure: $X$ is the variable we use to predict $Y$ and $g(X)$ is the function we are trying to solve, which minimizes $EPE$. Thank you for any help :)","['statistics', 'probability', 'conditional-probability']"
513347,Can a matrix have a null space that is equal to its column space?,"I had a question in a recent assignment that asked if a $3\times 3$ matrix could have a null space equal to its column space... clearly no, by the rank+nullity theorem... but I have a hard time wrapping my head around the concept of such a matrix, no matter what size, even existing. How could this be possible, and does anybody have an example of such a $m\times n$ matrix?",['linear-algebra']
513353,"If $u$ and $v$ have weak derivatives,what about $uv$?","$\Omega$ is a domain in $R^n$, Let $u\in L^1_{\text{loc}}(\Omega)$. If there exists $g_i \in  L^1_{\text{loc}}(\Omega)$ such that 
$$\int_\Omega g_i \phi \, dx=-\int_\Omega u \frac{\partial \phi_i}{\partial x},\phi \in C_0^\infty(\Omega)$$
Then we say $u$ has weak partial derivatives $g_i$. If $u$ and $v$ have weak partial derivatives, does $uv$ have 
weak partial derivatives? Or what conditions should we add to $u$ and $v$?","['sobolev-spaces', 'distribution-theory', 'functional-analysis', 'partial-differential-equations']"
513401,For every $\epsilon>0$ there exists $\delta>0$ such that $\int_A|f(x)|\mu(dx) < \epsilon$ whenever $\mu(A) < \delta$,"Hello all mathematicians!! Again, I am struggling with solving the exercises in Lebesgue Integral for preparing the quiz. At this moment, I and my friend are handling this problem, but both of us agreed this problem is a bit tricky.
The problem is following. Let ($X,\mathcal{A},\mu$) be a measure space and suppose $\mu$ is $\sigma$-finite. Suppose $f$ is integrable. Prove that given $\epsilon$ there exist $\delta$ such that $$
\int_A |f(x)|\mu(dx) \;\;<\;\;\epsilon
$$ whenever $\mu(A) < \delta$. Could anybody give some good idea for us? Think you very much for your suggestion in advance.","['lebesgue-integral', 'measure-theory']"
513429,Maps with every point being periodic,"Does there exists a characterization of continuous maps $f:[0,1]\rightarrow [0,1]$ with every point $x\in [0,1]$ being periodic (i.e. if for every $x\in [0,1]$ there exists $n\in\mathbb{N}$ such that $f^{n}(x)=x$)? What about those continuous maps $f:[0,1]\rightarrow [0,1]$ with every point being periodic and for which the set of all periods $\{Per(x):\ x\in [0,1]\}$ is bounded?","['dynamical-systems', 'continuity', 'functions']"
513439,Elegant or elementary evaluation of $\lim\limits_{x\to 0} \left( \frac{1}{x}-\frac{1}{\sin(x)} \right) $ [duplicate],"This question already has answers here : What is the result of $\lim_{x \rightarrow 0}\left(\frac1x - \frac1{\sin x}\right)$? (11 answers) Closed 10 years ago . I give math tutoring and was wondering about the following limit. I found the answer but I was wondering if someone has a nicer explanation than the one I am giving where I use L'Hôpital's rule twice. The limit I am evaluating is:
$$\lim\limits_{x\to 0}    \left( \frac{1}{x}-\frac{1}{\sin(x)}   \right)  = \lim\limits_{x\to 0} \frac{\sin(x)-x}{x\sin(x)}  $$
Both numerator and denomitor go to zero here so we may use l'Hôpital's rule here. The limit is thus equal to:
$$\lim\limits_{x\to 0}   \frac{\cos(x)-1}{\sin(x)+x\cos(x)}   $$
Again numerator and denominator go to zero and thus by l'Hôpital the limit is equal to:
$$\lim\limits_{x\to 0}  \frac{-\sin(x)}{\cos(x) + \cos(x) + x\sin(x)}$$
Now we are looking at the limit of the quotient of two everywhere continuous functions where the denominator is not zero. Thus the function itself is continuous and so the limits is:
$$\lim\limits_{x\to 0}  \frac{-\sin(x)}{2 \cos(x) + x\sin(x)} = \frac{0}{2}=0$$ Does anyone know a more nicer, more elementary way of solving this?
Thanks! EDIT: Also, if anyone knows a fast, yet less elementary way to solve I would enjoy seeing it so feel free to post :)","['alternative-proof', 'calculus', 'limits']"
513444,A question on Regular Conditional Probability,"Let $X$ & $Y$ be random vectors. Let $Z$=$f(X,Y)$ be a random variable. Then if $X$ & $Y$ are independent, the following is a well known result: $P(f(X,Y)\in B\mid Y=y)$  = $P(f(X,y)\in B)$ I need some help to 'formalize' what appears to be an intuitive generalization when $X$ & $Y$ are not assumed to be independent, namely that $P(f(X,Y)\in B\mid Y=y)$  = $P(f(X,y)\in B\mid Y=y)$ without assuming $Y$ is discrete. One 'immediate' problem for example is that, I am not sure that the RHS of the above equation is well defined. For in Breiman's text 'Probability' , by Definition 4.7 ,  the conditional probability $P(C\mid Y=y)$ is defined as a measurable function in $y$ satisfying $P(C, Y\in A )$=$\int_{A} P( C\mid Y=y) \, P_{Y}(dy)$ where $C$ is a measurable subset of the sample space and $A$ is an arbitrary Borel subset in the state space of $Y$. Notice that $C$ is held fixed in the definition, as $y$ is allowed to vary. Identifying $C$ with$[f(X,Y)\in B]$ in the LHS of our conjecture , allows us to make sense of $P(f(X,Y)\in B\mid Y=y)$. But the subset $[f(X,y)\in B]$ changes with changes in $y$, hence at least by the above definition $P(f(X,y)\in B\mid Y=y)$ is not well defined. As an aside, for similar reasons, $E(f(X,y)\in B\mid Y=y)$ is also problematic. Using the concept of Regular Conditional Probability, I think the statement above can be formalized as follows. Let $X$ & $Y$ be random vectors. Let $Z$=$f(X,Y)$ be a random variable, and $P_{Y}$ be the marginal distribution of $Y$. Let $Q_{X\mid Y}(\cdot\mid y)$ be a regular conditional distribution for $X$ given $Y=y$. Then $P(f(X,Y)\in B\mid Y=y)$  = $P(f(X,y)\in B\mid Y=y)$, is I believe an intuitive interpretation of the following 'unproven' statement $Q_{Z\mid Y}( B\mid y)$= $Q_{X\mid Y}(B_y \mid y)$ where $B$ is any arbitrary Borel subset of $R$, and  $B_y$ = $[x \mid f(x,y) \in B]$ and $Q_{Z\mid Y}(\cdot\mid y)$ the regular conditional distribution for $Z=f(X,Y)$ given $Y=y$. Written alternatively we need to prove that $P(Z\in B, Y\in A )$=$\int_{A} Q_{Z\mid Y}( B\mid y) \, P_{Y}(dy)$=$\int_{A} Q_{X\mid Y}( B_y\mid y) \, P_{Y}(dy)$ A related problem is to prove the following: Let $P_{(X,Y)}$ be the joint distribution of $(X,Y)$, $Q_{X\mid Y}(\cdot\mid y)$ be a regular conditional distribution for $X$ given $Y=y$, $P_{Y}$ be the marginal distribution of $Y$, and
let $D$ be a given Borel subset in the state space of $(X,Y)$. Then
$P_{(X,Y)}(D )$=$\int Q_{X\mid Y}( D_y\mid y) \, P_{Y}(dy)$ where $D_y$ = $[x \mid (x,y) \in D]$","['probability-theory', 'probability', 'conditional-probability']"
513470,"How to find real root of a function with $ \sin x, \cos x $?","Is there any way to find real root of the following equation by hand?
Only need to count the number of zeros~ $$x^2-x \sin x- \cos x=0 $$ I know there's a rule for finding real roots for polynomial by counting the number of times that the sign of the coefficients changes. But how do we find real root for some function like this, without using graphing calculator? Thanks in advance!!",['algebra-precalculus']
513484,Getting the PDE using Laplace equations,"Hey guys I need help on one of the past midterm question that I came across. I am pretty sure I got (a) right. But if it is wrong could you please let me know. But its (b) and (c) that I got in trouble with. Any help or solution to those would be really helpful. I have a midterm in 2 days I just want to get confident in all this. Question: Let D be the inﬁnite vertical strip $D = (0 \leq  x \leq  1, -\infty < y < \infty)$: (a) show that the function $u(x, y) = sin(\alphax)sinh(\alphay)$ satisﬁes the (two-dimensional version of the) Laplace equation in D for any real value of the constant . For which value(s) of $\alpha$  does the above proposed solution satisfy the Dirichlet boundary conditions $u = 0$ on the boundary of D? b) consider the following PDE problem: $\bigtriangleup u = g(x, y)$ on D $u = h$      on the boundary of D where $\bigtriangleup$ denotes the two-dimensional Laplace operator $\frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} $
Is the problem well-posed? Justify your answer using the results of item (a). (c) Taking inspiration for item (a), guess a solution of the Laplace equation in D which satisﬁes the Neumann boundary conditions $\frac{\partial u}{\partial n} = 0$ on the boundary of D. What can you conclude about the well-posedness ofthe following PDE problem? $\bigtriangleup u = g(x, y)$   on D $\frac{\partial u}{\partial n} = h$ on the boundary of D: My attempt: (a) So I know the laplace equation is $u_{xx} + u_{yy} = 0$ So I found $u_{xx} = - \alpha^2 sin(\alpha x)sinh(\alpha y)$ and $u_{yy} = \alpha^2 sin(\alpha x)sinh(\alpha y)$ So therefore $u_{xx} + u_{yy} = 0$ if I plug it into the equation. Now to find the values of $\alpha$ we know $u(0, y) = sin(0)sin(\alpha y) = 0$ and $u(1,y) = sin(\alpha)sinh(\alpha y)$ Therefore $sin(\alpha) = 0 \Rightarrow $ only when $\alpha = k \pi$ where $k \in \mathbb{R}$ now b and c I get confused. Please help out I would be really greatful thank you.","['ordinary-differential-equations', 'partial-differential-equations']"
513487,How to show that $ \succ acyclic \implies \succ asymmetric $,"For a preference relation defined as $$ \succ := \{ (x,y) \in X\times X : x\ is\ better\ than\ y \}$$ one has to show that $$ \succ acyclic \implies \succ asymmetric $$ whereas $$ acyclic := \forall\ n \ge 2,\ x_1 \succ x_2,\ x_2 \succ x_3,\ ... \ x_{n-1} \succ x_n \implies x_1 \ne x_n$$ and $$ asymmetric := x \succ y \implies y \nsucc x$$ Now as much as I believe the solution should be obvious, unfortunately for me it's not. My approach whould be to show that this is true for $n =2$ first of all, and then proof via induction. However, even for $n = 2$, I do not manage to establish that the proposition holds, because the acyclic property is only $$ x_1 \succ x_2 \implies x_1 \ne x_2 \implies x_1 \succ x_2 \lor x_2 \succ x_1$$ which is far from implying that $\succ$ is also asymmetric, i.e., $$ x_1\succ x_2 \implies x_2 \nsucc x_1$$ Which key point do I miss here? Is it even smart to go for proof by induction here, or is there a better approach? Thanks for all hints!","['relations', 'elementary-set-theory', 'order-theory']"
513490,Sets $Q$ such that outer measure $\mu^*$ equals inner measure $\mu_*$ form an $\sigma$-algebra.,"Suppose $\mathcal{A}$ is a $\sigma$-algebra and $\mu$ is a finite measure on $\mathcal{A}$. For all $Q \subseteq \Omega$, let: $\mu^*(Q) = \inf \{\sum_{n=1}^{\infty} \mu(A_n): \forall n, A_n \in \mathcal{A} $ and $Q \subseteq \bigcup_n A_n \}$ and $\mu_*(Q) = \sup \{\mu(A): A \subset Q, A \in \mathcal{A} \}$. Let $\overline{\mathcal{A}}$ be the collection of all sets $Q \subseteq \Omega$ such that $\mu_*(Q) = \mu^*(Q)$. I want to show that $\overline{\mathcal{A}}$ is a $\sigma$-algebra, but I'm having trouble proving that $\overline{\mathcal{A}}$ is closed under taking countable unions. I can show $\overline{\mathcal{A}}$  is a Dynkin system, but I couldn't prove it was closed under taking intersections. Any ideas? Thanks.",['measure-theory']
513565,Is a cylinder a Lipschitz domain?,"I'm wondering if the domain $(0,T)\times \Omega$ is a Lipschitz domain ($T$ is a positive real number), provided that $\Omega$ is an open bounded subset of $\mathbb{R}^n$ with Lipschitz boundary, and how to prove or disprove this fact. Thank you",['differential-geometry']
513567,The constant in the Sobolev trace theorem inequality,"The trace theorem for nice enough domains states that there is a operator $T:H^1(\Omega) \to L^2(\partial \Omega)$ such that
$$|Tu|_{L^2(\partial \Omega)} \leq C|u|_{H^1}.$$ My question, is there an expression for the constant $C$? I want to see exactly how it depends on the domain $\Omega.$ This is because I want to see how the constant varies (eg. continuously) if I vary the domain.","['trace', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
513570,Is there any standard N-sphere that has non-trivial first Pontryagin class?,"I am wondering if there is a standard $N$-sphere that has non-trivial first Pontryagin class on its tangent bundle $TS^n$and frame bundle $FS^n$? I know that only $S^4$ has non-trivial $H^4(S^n, R)$ cohomology class, while locally I write the first Pontryagin class on $TS^n$ as $Tr(R^2)$, where $R$ is curvature of $S^n$, is trivially zero. Does it mean all sphere have trivial first Pontryagin class?","['differential-topology', 'characteristic-classes', 'algebraic-topology', 'differential-geometry']"
513621,"Solving $a(x+2)=\pi-cy$ for $x$, arrived at an answer different from the one in the book","In an algebra review book, one exercise asked to solve for $x$:
$$a(x+2)=\pi-cy$$
I arrived at the following:
$$x=\frac{\pi-cy}{a}-2$$
The book stated the correct answer is:
$$x=\frac{\pi-cy-2a}{a}$$
I see that technically I ignored the PEMDAS guideline in my answer, however, my solution doesn't seem very far from the book's answer. I'm rusty on my algebra and am curious as to whether or not my answer is acceptable or incorrect.",['algebra-precalculus']
513627,"Baseball, batting average, and probability","A baseball player's batting average is equivalent to the probability he will get a hit for any given at-bat (at-bats don't include Errors, Walks, or HBP and a few other exceptions).  So for a specific player with a specific batting average, the probability that he will get a hit against an unknown pitcher is exactly equivalent to his batting average. Similar to the AVG statistic for hitters, pitchers have a statistic called Batting Average Against (BAA).  This statistic is calculated in the exact same way as hitters except it's done for a pitcher.  It's equivalent to Hits divided by At-Bats of opposing batmen (na na na na).  So for a specific pitcher with a specific BAA, the probability that he will allow a hit against an unknown batter is exactly equivalent to his batting average against. Intuitively, it seems obvious to me that a batter, no matter his personal batting average, is more likely to get a hit against a pitcher with a high BAA, and less likely to get a hit against a pitcher with a low BAA.  Additionally, a pitcher, no matter his own BAA, is more likely to allow a hit when facing a batter with a high AVG than when facing a batter with a low AVG. So the question is, given a specific batter with a specific AVG and a specific pitcher with a specific BAA, how do we calculate the probability that that specific batter will earn a Hit against that specific pitcher? EDIT: It's fair to assume we're talking about MLB, and we have an overwhelming wealth of extra information.  Assume we're talking about a batter with thousands of at-bats recorded, a pitcher with thousands of batters faced, and we know all the information about the average league AVG, average league BAA, etc., but this specific batter and this specific pitcher have never faced each other.  How would we calculate the probability of a Hit? EDIT2: Let's not get bogged down with vsLHP, vsRHP, RISP, and other statistics.  These are merely statistics that can be used to give a more accurate probability.  The method for calculating the probability should remain basically the same.  Let's just suppose we have Batter A who has an AVG of .300, and the average BAA of the pitchers he's faced (weighted to account for facing some pitchers more frequently etc) is .250.  And we have Pitcher B who has a BAA of .225, and the average AVG of the batters he's faced (again, weighted) is .250.  Batter A has never faced Pitcher B before, but both have thousands of At-Bats/Batters-Faced.  How do we calculate the probability of a Hit versus an Out?","['statistics', 'probability']"
513651,Puzzle about voting,"I came across about this puzzle which I'm not sure how to go about. Suppose there are $L$ leaders and $F$ followers, with $1 < L<<F$. A leader makes a binary decision, $0$ or $1$ with same probability. Each follower copies the decision of one of the leaders, for simplicity, choosing one of them with uniform distribution. The experiment is repeated many times, as many as you like. Every follower copies the vote of a leader for a random number of times $k\in {1, 2, ..., K}$, with $K$ equal to some positive integer. After that, the follower chooses another leader or the same, again, uniformly at random. Is there anything in the literature that can be used to solve this problem, that is, to identify or guess who the leaders are?","['machine-learning', 'probability', 'algorithms', 'combinatorics']"
513686,Central moments of the wrapped normal distribution?,"The wikipedia page defines the raw moments of the wrapped normal fairly succinctly: http://en.wikipedia.org/wiki/Wrapped_normal_distribution#Moments However, I'm struggling to find any literature on the equivalent of central moments for the wrapped normal (and circular distributions in general). Does the binomial transform still apply? If so, then I can derive the central moments using the raw moments.","['statistics', 'probability', 'complex-analysis']"
513691,Proving energy conservation for wave equation,"Hi guys I have a midterm tommorow and I was doing this practice problem that I need help on. So any hints or solutions would be appreciated. Thank you for your time Problem The head of timpani is constituted by some kind of elastic membrane which is stretched over a circular bowl; in a mathematical language, we are studying the displacement $u$ of the membrane as a function $u(x, y, t)$ deﬁned in $D = \{(x,y,t) \ |\ x^2 + y^2 \leq R, \ -\infty < t < \infty\}$, where $R$ is the radius of the bowl. The function u satisﬁes the two-dimensional Wave Equation $u_{tt} = c^2(u_{xx} + u_{yy})$ with Dirichlet boundary conditions $u = 0$ on the boundary. Prove conservation of energy E(t), which is deﬁned as $E(t) = \frac{1}{2} \iint\limits_D u_{t}^2 + c^2 (u_{x}^2 + u_{y}^2) dxdy$ [Hint: Proceed as we did for the one-dimensional case and use the divergence theorem to “integrate by parts” ] which I don't understand Assume now that we take into account friction between air and the membrane; the displacement of the membrane now satisﬁes the damped Wave Equation, which reads: $u_{tt} - c^2 (u_{xx} + u_{yy}) = -vu_{t}$ with the same boundary conditions. Show that, in this case, energy is always a strictly decreasing function except if $u(x, y, t) = 0$, for which it is constant equal to $0$.
[Hint: What condition must $u_t$ satisfy in order for E to be non-decreasing?
What PDE will u satisfy? Conclude using the maximum principle. My attempt: So first I found the derivative of E(t) and if the derivative of E(t) = 0 then I know the energy is conserved and I used integral by parts in 3 dimension to solve that to get $\iint 2u_{t}u_{tt} = 0$ because it is decreasing. Since the derivative is 0 E is constant over time therefore the energy is concerved. But I do not understand the last part please any help or hints would be greatly appreciated. Thank you","['ordinary-differential-equations', 'partial-differential-equations', 'analysis']"
513717,Prove that limit goes to infinity if a convex function's derivative > 0,"I do understand what a convex function is and I can see geometrically that following statement is true: $(1)$ If for a given convex function $f$ which is differentiable over $\mathbb{R}$, if $f'(x_0)>0$ for some $x_0$ then $\lim_{x \to \infty}{f(x)} = \infty$. I see it like this: if the derivative $f'(x_0)>0$ then the slope is increasing all the time as long as you approach infinity from $x_0$ due to the definition of convex function: $$f(tx_0 + (1-t)x_1 \leq tf(x_0) + (1-t)f(x_1)$$ In other words, the secant is above the curve all the time. But how do I prove the statement $(1)$?","['calculus', 'functions']"
513758,"can we construct a countable set $A$, such that the cardinality of $A'$ is $c$, and $A\cap A'=\emptyset$?","I came up with a problem when learning real analysis. We have known that since $Q$ is a countable set and $Q'=R$,  the cardinality of $Q'$ is $c$. Then, can we construct a countable set $A$, such that the cardinality of $A'$ is $c$, and  $A\cap A'=\emptyset$ ? Some textbook on real analysis provides this conclusion, but I wonder how to construct it. Your help will be appreciated. Note: $c$ denotes the cardinality of $\mathbb{R}$; $A^\prime$ denotes the derived set of $A$.","['elementary-set-theory', 'real-analysis']"
513765,What irrational numbers repeat under a different base?,The comments section of this post says that $\pi$ does repeat itself if done under base 11... and that it somehow defines the universe. Can anyone expand on the idea that irrational numbers may repeat if a different base is used? Does $\pi$ in fact repeat under base 11? Is there any known value in numbers that have this property? (or conversely the ones that don't have this property?),"['pi', 'algebra-precalculus']"
513822,Can the limit of a product exist if neither of its factors exist?,"Show an example where neither $\lim\limits_{x\to c} f(x)$ or $\lim\limits_{x\to c} g(x)$ exists but $\lim\limits_{x\to c} f(x)g(x)$ exists. Sorry if this seems elementary, I have just started my degree... Thanks in advance.","['calculus', 'products', 'limits']"
513851,Why does completing the square give you the minimum point?,"Say we have an equation:$y=$ ${x^2} + 2x + 1$ Completing the square we get: $\eqalign{
  & y={x^2} + 2x + 1  \cr 
  &  = {(x + 1)^2} - {(1)^2} + 1  \cr 
  &  = {(x + 1)^2} \cr} $ The minimum point of this parabola is (-1,0) What I would like to know is how/why does putting a quadratic equation in completing the square form give you the minimum point of a parabola? What is it about this form that corresponds to give you the minimum point? I hope i've made myself clear, if not please ask me to make myself clearer. Thank you!","['factoring', 'algebra-precalculus', 'quadratics']"
513865,A closed form for $\int_0^1\frac{\ln(-\ln x)\ \operatorname{li}^2x}{x}dx$,"Let $\operatorname{li}x$ denote the logarithmic integral $^{[1]}$ $^{[2]}$ $^{[3]}$ :
$$\operatorname{li}x=\int_0^x\frac{dt}{\ln t}$$
and
$$I=\int_0^1\frac{\ln(-\ln x)\ \operatorname{li}^2x}{x}dx\approx-4.311872263...$$
Is it possible to express the integral $I$ in a closed form (using algebraic numbers, known mathematical constants, elementary and known special functions)?","['closed-form', 'special-functions', 'calculus', 'integration', 'logarithms']"
513877,Hodge-Star-Operator on arbitrary oriented basis,"Assume that $V$  is oriented finite dimensional vectorspace with dimension $n$, 
$g \in T^0_2(V)$ a given symmetric and nondegenerate tensor. Let 
$\mu$ be the corresponding volume element of $V$. Assume that $\{e_1, \dotsc,e_n\}$ is a oriented arbitrary (not necessarily $g$-orthonormal) basis of $V$ and 
$\{e^1, \dotsc,e^n\}$ its dual basis. 
Let $\ast \colon \Lambda^k(V) \to \Lambda^{n-k}(V)$ be the unique isomorphism
satisfying
$$\alpha \wedge \ast \beta = \langle\!\langle \alpha, \beta \rangle\!\rangle \mu \quad \text{for } \alpha, \beta \in \Lambda^k(V),$$
where it is known that $\langle\!\langle,\rangle\!\rangle$ fulfills the following
$$\langle\!\langle e^{i_1} \wedge \dotsb \wedge e^{i_k}, e^{j_1} \wedge \dotsb \wedge e^{j_k} \rangle\!\rangle 
= \det (g^{i_l j_{l^\prime}})_{l,l^\prime \in \{1,\dotsc,k\}} = 
\det \left(g\left((e^{i_l})^\sharp,(e^{j_{l^\prime}})^\sharp\right)\right)_{l,l^\prime \in \{1,\dotsc,k\}}$$
and $\mu$ is given by
$$\mu = \sqrt{|\det [g(e_i,e_j)]|} e^1 \wedge \dotsb \wedge e^n.$$ Then
  $$\ast (e^{i_1} \wedge \dots \wedge e^{i_k}) = \sum_{j_{k+1} < \dotsb < j_n}c^{i_1 \dotsm i_k}_{j_{k+1} \dotsm j_n} e^{j_{k+1}} \wedge \dotsb \wedge e^{j_n},$$
  where
  $$c^{i_1 \dotsm i_k}_{j_{k+1} \dotsm j_n} = \sqrt{|\det [g(e_i,e_j)]|} 
	 \mathrm{sign} \binom{1 \dotsm n}{j_1 \dotsm j_n}g^{i_1j_1} \dotsm g^{i_kj_k} .$$ Result has been stated in Abraham, R. and Marsden, J.E. and Ratiu, T.""Manifolds, Tensor Analysis, and Applications (3rd Ed)"" 7.2.14 Examples (2 ) Proof : Set $\alpha = e^{j_1} \wedge \dotsb \wedge e^{j_k}$ with $j_1 < \dotsb < j_k$ and $\beta = e^{i_1} \wedge \dotsb \wedge e^{i_k}$
One can compute
\begin{align}
	\alpha \wedge \ast \beta &= e^{j_1} \wedge \dotsb \wedge e^{j_k }\wedge \sum_{l_{k+1} < \dotsb < l_n} c^{i_1 \dotsm i_k}_{l_{k+1} \dotsm l_n} e^{l_{k+1}} \wedge \dotsb \wedge e^{l_n} \\
	       &=  c^{i_1 \dotsm i_k}_{j_{k+1} \dotsm j_n} 
	       	   e^{j_1} \wedge \dotsb \wedge e^{j_k } \wedge e^{j_{k+1}} \wedge \dotsb \wedge e^{j_n} \\
		   &= c^{i_1 \dotsm i_k}_{j_{k+1} \dotsm j_n} \mathrm{sign} \binom{1 \dotsm n}{j_1 \dotsm j_n}
		   e^1 \wedge \dotsb \wedge e^n.
	\end{align}
On the other hand it holds that
\begin{align}
	\langle\!\langle \alpha, \beta \rangle\!\rangle \mu &=
	\det (g^{j_l i_{l^\prime}})_{l,l^\prime \in \{1,\dotsc,k\}} \sqrt{|\det [g(e_i,e_j)]|} e^1 \wedge \dotsb \wedge e^n.
\end{align} Since $\alpha \wedge \ast \beta = \langle\!\langle \alpha, \beta \rangle\!\rangle \mu$, I get 
$$c^{i_1 \dotsm i_k}_{j_{k+1} \dotsm j_n} = \sqrt{|\det [g(e_i,e_j)]|}  \mathrm{sign} \binom{1 \dotsm n}{j_1 \dotsm j_n}
	 \det (g^{j_l i_{l^\prime}})_{l,l^\prime \in \{1,\dotsc,k\}}.$$ But this is obviously not the full truth, what am I missing, to get the desired formula? What are my mistakes in argumentation so far? I appreciate your help.","['exterior-algebra', 'riemannian-geometry', 'multilinear-algebra', 'differential-geometry']"
513882,"How do you prove that vectors are linearly independent in $ \mathcal{C}[0,1]$?","I'm presented with the question: Show that the given vectors are linearly independent in $\mathcal{C}[0,1]$ : $x^{3/2}, x^{5/2}$ I'm having a terrible time understanding linearly algebra in general. I think my part of my problem with this question is understanding what the $\mathcal{C}[0,1]$ notation means. Beyond that, I'm still not exactly sure how to show this. Any help would be greatly appreciated.",['linear-algebra']
513887,Second derivative positive $\implies$ convex,"In proof of the following theorem; If $f$ has a second derivative that is non-negative (positive) over an interval then $f$ is convex (strictly convex). $f$ is in real number space., the book I refer, uses Taylor series expansion but disregards terms of order 3 and above. So I'm not convinced of the correctness of the proof, which I paste below. Is there a way to bound the terms of order 3 and above in the follow proof? I think bounding the error of higher order terms is important in many cases. So would really appreciate a clear answer. Thanks a lot.","['convex-analysis', 'convex-optimization', 'real-analysis', 'analysis']"
