question_id,title,body,tags
4812830,"Let $f: [0,1]\to\mathbb{R}$ be injective. Does $\sum_{n=1}^{\infty} c_n\left( f(x)\right)^n=0\forall x\in [0,1] \implies c_n=0\forall n\in\mathbb{N}?$","Let $f: [0,1] \to \mathbb{R}$ be injective. Does $ \displaystyle\sum_{n=1}^{\infty} c_n \left( f(x) \right) ^n
 = 0\ \forall x\in [0,1] \implies c_n = 0\ \forall n\in\mathbb{N}\ ? $ Maybe something related to (i.e. a more general version of) Stone-Weierstrass could be helpful?","['linear-independence', 'sequences-and-series', 'real-analysis']"
4812868,How to slightly modify my ODE system in order to capture bump in the data?,"I have the following two sets of data, which show the dependencies of two quantities, namely, $S$ and $B$ , on time ( $0$ h, $3$ h, $6$ h, $9$ h, $15$ h, $18$ h, $21$ h, and $24$ h): Sdata = {{0, 9.74},{3, 4.92},{6, 8.29},{9, 5.54},{15, 2.08},{18, 1.38},{21, 1.99},{24, 0.893}};

Bdata = {{0, 0.915094},{3, 0.736097},{6, 0.793694},{9, 0.833664},{15, 1},{18, 0.99578},{21, 0.897964},{24, 0.214499}}; I have modeled the dynamics of the above system by a coupled ODE system: $$\frac{dS(t)}{dt} = - \frac{a}{1 + B(t)} S(t),$$ $$\frac{dB(t)}{dt} = \frac{c}{1 + S(t)} B(t) - d B^2(t) \Big( \frac{1 - B(t)}{B(t)} \Big)^n,$$ where $a$ , $c$ , $d$ , and $n$ are constants to be determined from the data. Using Mathematica for fitting, we obtain: Sdata = {{0, 9.74}, {3, 4.92}, {6, 8.29}, {9, 5.54}, {15, 2.08}, {18, 
1.38}, {21, 1.99}, {24, 0.893}};
Bdata = {{0, 0.915094}, {3, 0.736097}, {6, 0.793694}, {9, 
0.833664}, {15, 1}, {18, 0.99578}, {21, 0.897964}, {24, 0.214499}};
order = 1;
interpolatedData = {intS, 
intB} = {Interpolation[Sdata, InterpolationOrder -> order], 
Interpolation[Bdata, InterpolationOrder -> order]};
sys = {S'[t] == -a/(1 + B[t]) S[t], 
B'[t] == c B[t]/(1 + S[t]) - d B[t]^2 ((1 - B[t])/B[t])^n};
squareDiffs = MapApply[(#1 - #2)^2 &, sys];
withInt[t_] = squareDiffs /. {S -> intS, B -> intB};
totalSquaredError = Total@Flatten[withInt /@ (Range[0, 24, 3])];
forMin = Join[{totalSquaredError}, restrictions];
restrictions = Thread[{a, c, d, n} > 0];
{resid, bestFitParams} = 
NMinimize[forMin, {a, c, d, n}, Method -> ""RandomSearch""]
init = {S[0] == Sdata[[1, 2]], B[0] == Bdata[[1, 2]]};
new = Join[sys /. bestFitParams, init];
{sSol[t_], bSol[t_]} = NDSolveValue[new, {S[t], B[t]}, {t, 0, 24}];

lp = ListPlot[Bdata];
p = Plot[bSol[t], {t, 0, 24}, PlotRange -> All];
Show[lp, p]
lpp = ListPlot[Sdata];
pp = Plot[sSol[t], {t, 0, 24}, PlotRange -> All];
Show[lpp, pp] See here the fitted curves. (Blue points show $S(t)$ data and red points show $B(t)$ data.) The fitted curve to the red points, i.e., $B(t)$ , cannot capture the bump in the data around $t = 15$ . I appreciate any insight or hint for how changing my ODE system slightly in order to capture this bump before falling down of the values. EDIT The datasets with standard deviations: SdatawithSD = {{0, Around[9.74, 2.89]}, {3, Around[4.92, 1.65]}, {6, 
Around[8.29, 4.04]}, {9, Around[5.54, 2.45]}, {15, 
Around[2.08, 1.91]}, {18, Around[1.38, 0.962]}, {21, 
Around[1.99, 2.41]}, {24, Around[0.893, 0.359]}};


BdatawithSD = {{0, Around[0.915094, 0.1]}, {3, 
Around[0.736097, 0.091668]}, {6, Around[0.793694, 0.082575]}, {9, 
Around[0.833664, 0.070242]}, {15, Around[1, 0.002851]}, {18, 
Around[0.99578, 0.015591]}, {21, Around[0.897964, 0.04783]}, {24, 
Around[0.214499, 0.01231]}};","['mathematical-biology', 'mathematical-modeling', 'ordinary-differential-equations']"
4812962,What is wrong with my argument that every group of order $pq$ is abelian?,"Question: Prove that a group $G$ of order 143 is abelian. Solution: $G$ contains subgroups $H$ and $K$ of orders 11 and 13, respectively.
The subgroups $G/H$ and $G/K$ have orders 13 and 11, respectively, and hence are cyclic,
and a fortiori, abelian.
This means $G' \subset H \cap K = \{e\}.$ So, $gh = ghg^{-1}h^{-1}hg = ehg = hg.$ I have used the Lemma: If $G'$ is the subgroup generated by the set $$U = \{ ghg^{-1}h^{-1} \colon g,h \in G\},$$ then $G/G'$ is abelian and any normal subgroup $N$ which satisfies $G/N$ is abelian also satisfies $N \supseteq G'.$ $G'$ is called the commutator subgroup of $G.$ It is the smallest subgroup containing $U,$ and any subgroup containing $U$ contains $G'.$ Proof: For $g,h$ in $G,$ we have $gh N= hg N = ghh^{-1}g^{-1}hg N$ implying that $h^{-1}g^{-1}hgN = N.$ So, $h^{-1}g^{-1} hg \in N.$ As $g,h$ were arbitrarily chosen in $G,$ we get $U \subset N.$ Problem: This would also apply to all groups of order $pq$ where $p$ and $q$ are distinct primes. This is known to be false.","['finite-groups', 'fake-proofs', 'group-theory', 'abstract-algebra', 'abelian-groups']"
4812983,Why is this the general solution of this DE?,"I am reading a device physics text (Sze Physics of Semiconductor Devices , 3e, Chapter 2.4.3) and the author makes the claim that the solution $y(x)$ to a simple linear DE of the form $$y' +P(x)y = Q(x)$$ along with the boundary condition at $x = 0$ which I will just call $y(0)$ is $$y(x) = \frac{\int_0^{x}Q\exp \left(\int_0^{x''} P \,dx' \right) \,dx'' + y(0)}{\exp \left(\int_0^x P \,dx' \right)}.$$ My differential equations knowledge is weak as it's been a long time. I have some hazy sense that I should be looking for an integrating factor or something of the sort, but I would greatly appreciate if someone could step through the argument leading to this solution. Thank you!","['integration', 'integrating-factor', 'ordinary-differential-equations']"
4813032,Uniform law of large numbers in an infinite dimensional set,"Most properties on the uniform law of large numbers impose that parameter lies in a compact set. Let $X_1, \dots, X_n$ be ergodic variables such that, for any $\theta \in \Theta$ , $S_n(\theta) = (1/n)\sum_{i = 1}^n f(X_i, \theta)$ converges in probability to $S_0(\theta) = \lim_{n \to \infty}(1/n)\sum_{i = 1}^n \mathbb{E}(f(X_i, \theta))$ , for some measurable function $f$ continuous in $\theta$ . To generalize the convergence to the uniform convergence, we typically need $\Theta$ to be compact and $\mathbb{E}(\sup_{\theta}f(X_i, \theta)) < \infty$ . Under these conditions, we can say that $sup_{\theta}\lVert S_n(\theta) - S_0(\theta)\rVert = o_p(1)$ . What if $\Theta$ is not compact (an infinite dimensional set)?  For example, Let $u_1, \dots, u_n$ be a nonstochastic sequence, such that $u_i \in \mathcal{N}_i$ , where $\mathcal{N}_i$ is a neighborhood subset in $\Theta$ . Assume that $T_n (u_1, \dots, u_n) = (1/n)\sum_{i = 1}^n f(X_i, u_i)$ converges in probability to $\lim \mathbb {E}(T_n (u_1, \dots, u_n))$ . Intuitively, it is as if I replace $\theta$ with a function. Which conditions should I impose to show that $$\sup_{u_1\in\mathcal{N}_1,\dots,u_n\in\mathcal{N}_n}\lVert T_n (u_1, \dots, u_n) - {E}(T_n (u_1, \dots, u_n))\rVert = o_p(1)?$$","['measure-theory', 'probability-limit-theorems', 'uniform-convergence', 'probability-theory', 'probability']"
4813034,Derivative of $X^{-1}AX^{-1}$ w.r.t. X,"I want to calculate the derivative of $X^{-1}AX^{-1}$ w.r.t. X in a simple form Let \begin{align}
AX^{-1}&=Y\\
X^{-1}A&=Z\\
dX^{-1} &= -X^{-1}dXX^{-1}\\
\text{vec}(dX^{-1}) &= -(X^{-T} \otimes X^{-1})\text{vec}(dX),
\end{align} were $\text{vec}$ is the vectorization operator. We have \begin{align}
F &= X^{-1}AX^{-1}\\
\implies dF & = d(X^{-1})AX^{-1} + X^{-1}Ad(X^{-1})\\
\implies dF & = d(X^{-1})Y + Zd(X^{-1})\\
\implies \text{vec}(dF) & = (Y^T \otimes I)\text{vec}(dX^{-1}) + (I \otimes Z) \text{vec} (dX^{-1})\\
\implies \text{vec}(dF) & = (Y^T \otimes I)\text{vec}(dX^{-1}) + (I \otimes Z) \text{vec}(dX^{-1})\\
& = -[(Y^T \otimes I) + (I \otimes Z)](X^{-T} \otimes X^{-1}) \text{vec}(dX)\\
& = -[((AX^{-1})^T \otimes I) + (I \otimes X^{-1}A)](X^{-T} \otimes X^{-1}) \text{vec}(dX)\\
\end{align} Can we obtain a simple formula of this result?
Thank you.","['matrices', 'calculus', 'derivatives', 'algebra-precalculus']"
4813076,How Many Ways Could My Stackoverflow Question have been Upvoted?,"Jokingly, this is a question I have always wondered about: Suppose I post a question on Math Stackexchange: my current score is $0$ If someone wants to vote on my question, they can either vote to give a score of $+ 10$ or a score of $-2$ Suppose there are $N$ members in the Math Stackexchange community (for the sake of this problem, lets assume it stays constant throughout this problem, i.e. no new members can join and no existing members can leave) Suppose each member can only vote once. Members also have the ability not to vote (i.e. $+0$ ) After some time, I check back on my question and my question now has a score of $Z$ : $Z$ is a whole number ( $Z$ can be positive or negative) that is divisible by $2$ My Question: How many ways could my question have been upvoted? For example, suppose my friend checks my Math Stackexchange account and only tells me that my question resulted in a net vote of +10 (without telling me more details as to how many people upvoted  and downvoted). Scenario 1: Perhaps one person voted +10. Scenario 2: Perhaps five people each voted - 2 and two people each voted + 10. Scenario 3: Perhaps ten people each voted -2 and three people each voted + 10. etc, etc. At first glance, there seems that there can be so many combinations which resulted in a net vote of +10 ! Here is what I tried so far: Part 1: I thought I could use the idea of the Power Set. That is, I could break all $N$ members into different combinations (i.e. subsets) of ""voting"" and ""non-voting"" members. For example, given $2^N$ , for $i$ = 1 to $N$ : Subset 1 ( $W_1$ ): When $i$ = 1, Voting Members = 1 and Non Voting Members = $2^N$ - $1$ Subset 2 ( $W_2$ ): When $i$ = 2, Voting Members = 2 and Non Voting Members = $2^N$ - $2$ Subset 3 ( $W_3$ ): When $i$ = 3, Voting Members = 3 and Non Voting Members = $2^N$ - $3$ etc. Part 2: Then, for each subset of Voting Members, we have to identify if each Subset of Voting Members can sum to $Z$ . It is possible that some of the Voting Members subsets can not sum to $Z$ - these subsets have to removed. To check if a subset can add to $Z$ , I think the following set of equations has to be solved for each subset: In a given Voting Members subset $W_i$ , let $x_i$ be the number of times $-2$ is picked and $y_i$ be the number of times $10$ is picked. Suppose we take some subset of Voting Members $W_i$ and there are $W_j$ members in this subset. Then: $$W_j = x_i + y_i$$ $$ x_i * (-2) + y_i * (10) = Z $$ For a given subset of voting members $W_i$ , I suppose the above equations could be solved to determine if it can sum to $Z$ or not. In the case where it can not sum to $Z$ , this subset will have to be removed. Part 3: Then, based on my very limited knowledge of combinatorics, I think some generating function ( Number of ways to write n as a sum of k nonnegative integers , The number of ways to get N as the sum of R elements with constraints , In how many different from a set of numbers can a fixed sum be achieved? ) would need to defined to see that within each ""admissible"" (i.e. not deleted in Part 2) voting members subset, how many ways can the members pick combinations of $+10$ and $-2$ such that they add to $W$ . Thus, for a subset of voting members $w_i$ with $w_j$ member, I think the generating function for this problem might be: $$ f(a) = (a^{-2} + a^{10})^{w_j} $$ And now for each subset, I would have to evaluate this expression and find out the coefficients of the terms where the exponents sums to $w_j$ . But I am not sure if this is correct. I am afraid that I have overcomplicated the question - could someone please help me understand an easier way to answer this question? Also the approach I am thinking about would require solving the equations in Part 2 for each subset, making it impossible to answer this question in general. Thanks!",['combinatorics']
4813110,Non injectively path-connected space,"Do you have an example of a path-connected non-hausdorff space on which two points can't be injectively path-connected? (that is, any path between them is not injective). I tried to figure out what such a space should look like, and what its topological properties should be, but I failed. Thank you very much,
AF","['general-topology', 'path-connected', 'examples-counterexamples']"
4813130,Can $n$ squares each be dissected into identical polygons and then re-assembled into a a single larger square,"Suppose you have $n$ unit squares. Can you dissect each square into polygons such that all the polygons are identical , and then re-arrange the polygons into a single big square of area $n$ ? Rotations, reflections, translations are allowed, but there can be no gaps or overlaps. All of the polygons across each of the $n$ squares must be identical. So for example, if $n$ is a square $n=r^2$ , the polygons can simply be the squares themselves which you can arrange in an $r\times r$ grid. For a slightly non-trivial example, for $n=2$ , you can cut the two squares along a diagonal to get 4 isosceles right triangles each of area $1/2$ , and then arrange these into a square of area $2$ by having each edge of the square be a hypotenuse of one of the triangles. Below I generalize this to integers $n$ that can be written as the sum of two squares. Using the Sum of two squares theorem we can characterize such $n$ . But what about other $n$ ? In particular, is there a solution for $n=3$ ? Or are there some $n$ for which it is impossible to perform such an operation? Solution for $n=a^2+b^2$ : Suppose $a,b$ are both non-zero; otherwise $n$ itself is a square in which case we are already done. We can then consider the right triangle of sides $a,b,\sqrt{n}$ where $\sqrt{n}$ is the length of the hypotenuse; call the edges of this triangle $A,B,C$ , respectively. If we had $4$ copies of this triangle, we can arrange them inside a square of area $n$ (called the ""big square"") by putting the $C$ edge of each copy as one of the edges of the square. The result is that there will be a square hole of side-length $|b-a|$ in the middle of the big square (rotated relative to the big square of area $n$ ). Since the inside square had integer side lengths, it can be made of $(b-a)^2$ of our unit squares. So for this inside square, it doesn't matter how we divide the unit squares, since for $(b-a)^2$ of the unit squares we can just re-assemble them back into the original unit squares and then build our inside square of side-length $|b-a|$ . So it remains to divide up the unit squares into identical polygons such that we can build our triangle of side-length $a,b,\sqrt{n}$ . This triangle be built from $(ab)^2$ triangles of side-length $\frac{1}{b},\frac{1}{a},\frac{\sqrt{n}}{ab}$ . To obtain such triangles, we divide all of our unit squares by first cutting them into $ab$ rectangles of side-lengths $a$ and $b$ , and then cutting each rectangle along a diagonal into two right triangles. You can do the calculation to see that we'll have exactly enough triangles to build the big square after cutting up the unit squares. Or you can just observe that the area of the big square equals the sum of the areas of the original unit squares, so we must have exactly the right number of triangles.","['dissection', 'geometry']"
4813131,Need Help Understanding a Differential Equation Problem,"I hope you're doing well. I'm a first-year mathematics student in a French preparatory program, and I'm currently working on a challenging exercise involving differential equations. I've made some progress, but I'm stuck. The exercise is as follows: Consider finding all functions $f: (1, +\infty) \rightarrow (1, +\infty)$ , differentiable, such that for every $x$ belonging to $(1, +\infty)$ , the following equation holds: $
(x-1)f'(x) = (x-1)f(x)^2 + (2-x^2)f(x) + x^2 - x - 1
$ Next, find a constant solution $K$ . Then, define $h(x) = f(x) - K$ . Determine the differential equation satisfied by $h$ . Let $g(x) = \frac{1}{h(x)}$ . Find the differential equation satisfied by $g$ . Finally, draw conclusions based on the analysis. I managed to find one constant solution $ K = 1 $ , but I'm struggling to understand how to proceed further. The next steps involve defining a new function $ h(x) = f(x) - K $ and determining the differential equation satisfied by $ h $ . After that, I'm supposed to define $ g(x) = \frac{1}{h(x)} $ and find the differential equation satisfied by $ g $ . If anyone could offer some guidance or insight into how to approach this problem, I would greatly appreciate it. I'm eager to learn and understand the steps involved in solving this type of problem. Thank you in advance for your help!","['calculus', 'derivatives', 'ordinary-differential-equations']"
4813138,Integrals involving $\operatorname{artanh}$ and $\log$,"1. APOLOGY I had previously asked a similar question, but that question was closed due to negligence on my part (too little information, lack of respect for the respondent, etc.). I am very sorry about this. I felt that in the future I must take care to ensure that this does not happen to me when I ask questions. $ $ 2. BACKGROUND A few months ago, I posted a question about the following integral $$ \int_0^1 \! \frac{x}{\operatorname{artanh}x} \, dx = \int_0^1 \! \frac{\sinh x}{x\cosh^3 x} \, dx = \frac{7\,\zeta(3)}{\pi^2} $$ where $\operatorname{artanh}x$ is the inverse hyperbolic tangent function. Furthermore, I computed the following integrals $$ \int_0^1 \!\!\! \int_0^1 \! \frac{\ln\frac1x - \ln\frac1y}{\ln\ln\frac1x - \ln\ln\frac1y} \, dx \, dy = \frac{7\,\zeta(3)}{\pi^2} $$ and obtained exactly the same results as the integrals above. Since the values of both integrals are equal, we get the conclusion that $$ \int_0^1 \! \frac{x}{\operatorname{artanh} x} \, dx = \int_0^1 \!\!\! \int_0^1 \! \frac{\ln\frac1x - \ln\frac1y}{\ln\ln\frac1x - \ln\ln\frac1y} \, dx \, dy, $$ but according to my friend, $$ \int_0^1 \!\!\! \int_0^1 \Biggl( \frac{\ln\frac1x - \ln\frac1y}{\ln\ln\frac1x - \ln\ln\frac1y} \Biggr)^{\!n} \, dx \, dy = \frac{\varGamma(n+2)}{2^n} \int_0^1 \biggl( \frac{x}{\operatorname{artanh} x} \biggr)^{\!n} \, dx $$ holds more generally for all positive integers $n$ where $\varGamma$ is the gamma function. My friend and I have not yet obtained the closed-form of the above integral. Therefore, I believe he has shown this only by deformation of the integral. So, I too would like to show this result only by the transformation of the integrals, without comparing the values of the integrals, but I cannot show it even for a case $n=1$ . $ $ 3. MAIN QUESTION Can you show that $$ \int_0^1 \!\!\! \int_0^1 \Biggl( \frac{\ln\frac1x - \ln\frac1y}{\ln\ln\frac1x - \ln\ln\frac1y} \Biggr)^{\!n} \, dx \, dy = \frac{\varGamma(n+2)}{2^n} \int_0^1 \biggl( \frac{x}{\operatorname{artanh} x} \biggr)^{\!n} \, dx $$ only with transformation of the integral, without comparing by the value of the integral? $ $ 4. FINALLY I have been very disrespectful to you all respondents. I am very sorry.",['integration']
4813167,Is there a sequence of polynomials $p_n $such that $p_n(0)=1$ for all $n$ but $\lim_{n \rightarrow \infty} p_n(z)=0$?,"I want to solve the following problem: Is there a sequence of polynomials $p_n$ , such that $p_n(0)=1$ , $n \in \mathbb{N}$ , but $\lim_{n \rightarrow \infty} p_n(z)=0$ for all $z \neq 0$ . As a hint I got:
“Consider $K_n:=(\{ z \in \mathbb{C}:|z|\leq n \} \setminus \{ z \in \mathbb{C}: d(z,[0,n]) <\frac{1}{n}\}) \cup \{0\} \cup [\frac{1}{n},n]$ , then show that $K_n $ is compact and $\mathbb{C}\setminus K$ is connected. Then use Runge theorem to find a polynomial.” My approach:
Obviously $\{ \ z \in \mathbb{C}:|z|\leq n \}$ is compact, and $\{ z \in \mathbb{C}: d(z,[0,n]) <\frac{1}{n}\}$ is open.
Now subtracting an open set from a compact set yields a compact set. Further $\{0\}$ and $\{[\frac{1}{n},n]\}$ are both compact. Thus $K_n$ is compact. Now I am struggling to show that $\mathbb{C}\setminus K$ is connected. The only thing that comes to mind is to use the definition of connected sets.
(A set $E$ is called connected, if it can not be writen as the union of two disjoint nonempty sets $A$ and $B$ which statisfy $A \cap E \neq \emptyset$ and $B \cap E \neq \emptyset$ ). Further I am not sure on how to use Runge’s theorem to “find a polynomial”. The version of Runge’s theorem that I know (and think may be useful) is:
Let $\Omega$ be an open subset of $\mathbb{C}$ . Then $\mathbb{\hat{C}}\setminus \Omega$ is connected $\iff$ all $f \in H(\Omega)$ can be approximated uniformly on compact sets in $\Omega$ by polynomials.",['complex-analysis']
4813211,Does this function grow slower than $e^{x}$ but faster than $e^{kx}$ for all $0<k<1$,"$f\left(x\right)=\lim_{a\to\infty}\sum_{n=1}^{a}\frac{x^{n}}{n\cdot n!}$ I spontaneously thought of this function while messing with the power series for exp(x). It's fairly obvious that this function grows slower than exp(x) and evaluating further derivatives at x=0 seems to indicate that it grows faster than all $e^{kx}$ functions (for 0<k<1), as their derivatives follow $k$ , $k^2$ , $k^3$ , etc, while derivatives of f(x) are 1, 1/2, 1/3 etc. The former derivatives shrink faster than the latter. I think this is not really a valid argument (since it's all at zero), but my guess seems to be true from my observations. Is it, and how would you prove it in that case? edit: by ""grows faster"" I guess I mean as x→∞, the ratio of f(x) / $e^{kx}$ approaches infinity. P.S. I apologise if this is a well-known function or if I screwed up the latex formatting.","['limits', 'calculus', 'exponential-function', 'real-analysis']"
4813235,Please help me determine the boundedness of a function.,"Assumption Suppose the function $K: \mathbb R \to \mathbb R_{\geq 0}$ is symmetric about $0$ and the following holds \begin{align}
\int_{-\infty}^\infty K(z)dz &= 1,\\
\int_{-\infty}^\infty K^2(z)dz &< \infty,\\
\int_{-\infty}^\infty z^2 K(z)dz &< \infty,\\
\int_{-\infty}^\infty |z|^3 K(z)dz &< \infty.
\end{align} Problem Can we show that the following is true in this case? \begin{align}
\int_{-\infty}^\infty z^2 K^2(z)dz < \infty
\end{align} Intuitively it seems correct, but I have no idea how to show it mathematically.","['statistics', 'analysis', 'real-analysis']"
4813325,Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$,"I'm supposed to calculate: $$\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!}$$ By using WolframAlpha, I might guess that the limit is $\frac{1}{2}$ , which is a pretty interesting and nice result. I wonder in which ways we may approach it.","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
4813357,The preimage of a single point is not compact,"Let $f:\mathbb{R}^2\to\mathbb{R}$ be a continuous surjection under the ordinary topology. Show that the preimage of a single point, i.e. $f^{-1}(\{t\})$ is not compact. The set is obviously closed, and thus is should be unbounded. I guess we need to use contradiction here and probably it should be some kind of a 'one-line' proof.",['general-topology']
4813358,How to prove the tautology for the inference rule of hypothetical syllogism using a chain of logical identities?,"Let $p$ , $q$ , and $r$ be any propositions. Then, using a chain of logical equivalences, how to establish the following logical identity? $$
\big( (p \rightarrow q) \land (q \rightarrow r) \big) \rightarrow \big( p \rightarrow r \big) \ \equiv \ T.
$$ My Attempt: In the following chain of equivalences, I will be using the same nomenclature as that used in Table 6, Sec. 1.3, of the book Discrete Mathematics and Its Applications by Kenneth H. Rosen, 8th edition. We note that $$
\begin{align}
&\qquad \big( (p \rightarrow q) \land (q \rightarrow r) \big) \rightarrow \big( p \rightarrow r \big) \\ 
&\equiv \left( \overline{ \left( \overline{p} \lor q \right) \land \left( \overline{q} \lor r \right) } \right) \lor \left( \overline{p} \lor r \right) 
\\ 
& \qquad \mbox{[ using the conditional-disjunction equivalence ]} \\
&\equiv \left( \left( \overline{ \overline{p} \lor q } \right) \lor \left( \overline{ \overline{q} \lor r } \right) \right) \lor \left( \overline{p} \lor r \right) \\
&\qquad \mbox{[ using a DeMorgan's law ]} \\ 
&\equiv \left( \left( \overline{ \overline{p}} \land  \overline{q}  \right) \lor \left( \overline{ \overline{q}} \land \overline{r} \right) \right) \lor \left( \overline{p} \lor r \right) \\
&\qquad \mbox{[ using a DeMorgan's law ]} \\ 
&\equiv \left( \left( p \land  \overline{q}  \right) \lor \left( q \land \overline{r} \right) \right) \lor \left( \overline{p} \lor r \right) \\ 
&\qquad \mbox{[ using the double-negation law ]} \\
&\equiv \left( \left( p \land  \overline{q}  \right) \lor \overline{p} \right) \ \lor \  \left( \left( q \land \overline{r} \right) \lor r \right) \\ 
&\qquad \mbox{[ using the associativity and commutativity of $\lor$ ]} \\ 
&\equiv \left( \left( p \lor \overline{p} \right) \land \left( \overline{q} \lor \overline{p} \right) \right) \ \lor \ \left( \left( q \lor r \right) \land \left( \overline{r} \lor r \right) \right) \\ 
&\qquad \mbox{[ using the distributivity of $\lor$ over $\land$ ]} \\
&\equiv \left( T \land \left( \overline{q} \lor \overline{p} \right) \right) \ \lor \ \left( \left( q \lor r \right) \land T \right) \\ 
&\qquad \mbox{[ using a negation law ]} \\
&\equiv \left(  \overline{q} \lor \overline{p}  \right) \ \lor \ \left( q \lor r \right) \\ 
&\qquad \mbox{[ using an identity  law ]} \\
&\equiv \left( \overline{q} \lor q \right)\  \lor \ \left( \overline{p} \lor r \right) \\  
&\qquad \mbox{[ using the associativity and commutativity of $\lor$ ]} \\
&\equiv T \  \lor \ \left( \overline{p} \lor r \right) \\  
&\qquad \mbox{[ using a negation law ]} \\
&\equiv T. \\ 
&\qquad \mbox{[ using a domination law ]}
\end{align}
$$ Is the above calculation correct and clear enough? If so, is this the shortest possible chain of logical equivalences necessary for establishing the tautology in question, using the same machinary as developed by Rosen up to Sec. 1.3? Or, are there any issues?","['propositional-calculus', 'solution-verification', 'logic', 'discrete-mathematics']"
4813364,Probability that two random lines intersect inside a square,"Consider the square with vertices $(0,0),(1,0),(1,1),(0,1)$ . Choose two independent uniformly random points $P$ and $Q$ inside the square. Draw a line $l_P$ connecting $(0,0)$ and $P$ . Draw another line $l_Q$ connecting $(1,0)$ and $Q$ . What is the probability that $l_P$ and $l_Q$ intersect inside the square? I will post my answer. Alternative solutions are welcome. This question and answer serve to flesh out a comment I made at a similar question .","['intuition', 'geometric-probability', 'geometry', 'probability']"
4813379,Calculate $\sum\limits_{n = - \infty }^\infty {\frac{{\log \left( {{{\left( {n + \frac{1}{3}} \right)}^2}} \right)}}{{n + \frac{1}{3}}}} $,question: how do we find that: $$ S = \sum\limits_{n =  - \infty }^\infty  {\frac{{\log \left( {{{\left( {n + \frac{1}{3}} \right)}^2}} \right)}}{{n + \frac{1}{3}}}} $$ I modified the sum $$\sum\limits_{n =  - \infty }^\infty  {\frac{{\log \left( {{{\left( {n + \frac{1}{3}} \right)}^2}} \right)}}{{n + \frac{1}{3}}}}  = \frac{{\log \left( {{{\left( {\frac{1}{3}} \right)}^2}} \right)}}{{\frac{1}{3}}} + \sum\limits_{n = 1}^\infty  {\left( {\frac{{\log \left( {{{\left( {n + \frac{1}{3}} \right)}^2}} \right)}}{{n + \frac{1}{3}}} + \frac{{\log \left( {{{\left( { - n + \frac{1}{3}} \right)}^2}} \right)}}{{ - n + \frac{1}{3}}}} \right)} $$ $${ =  - 3\log \left( 9 \right) + \sum\limits_{n = 1}^\infty  {\left( {\frac{{\log \left( {{{\left( {n + \frac{1}{3}} \right)}^2}} \right)}}{{n + \frac{1}{3}}} - \frac{{\log \left( {{{\left( {n - \frac{1}{3}} \right)}^2}} \right)}}{{n - \frac{1}{3}}}} \right)}  =  - 3\log \left( 9 \right) + 6\sum\limits_{n = 1}^\infty  {\left( {\frac{{\log \left( {\frac{{3n + 1}}{3}} \right)}}{{3n + 1}} - \frac{{\log \left( {\frac{{3n - 1}}{3}} \right)}}{{3n - 1}}} \right)}  = }$$ $${ =  - 6\log \left( 3 \right) + 6\sum\limits_{n = 1}^\infty  {\left( {\frac{{\log \left( {3n + 1} \right) - \log 3}}{{3n + 1}} - \frac{{\log \left( {3n - 1} \right) - \log 3}}{{3n - 1}}} \right)}  = }$$ $${ =  - 6\log \left( 3 \right) + 6\sum\limits_{n = 1}^\infty  {\left( {\frac{{\log 3}}{{3n - 1}} - \frac{{\log 3}}{{3n + 1}}} \right)}  + 6\sum\limits_{n = 1}^\infty  {\left( {\frac{{\log \left( {3n + 1} \right)}}{{3n + 1}} - \frac{{\log \left( {3n - 1} \right)}}{{3n - 1}}} \right)} }$$,"['calculus', 'closed-form', 'summation', 'sequences-and-series']"
4813386,A very complicated icebreaking game,"9 strangers play an ice-breaking game at a party for several rounds. For each round, they will sit around a round table and introduce themselves to their neighbors. The rule is that no one is seated next to his/her acquaintance in a new round. Suppose the game has been played for 3 rounds. Is it always possible to find a seating plan for the 4th round? I'm tempted to say that it's possible based on pigeonhole principle: For a given person, there are at most 3 rounds that have already taken place (rounds 1,2, and 3). In these rounds, the person has had a total of 2 × 3 = 6 neighbors (two
neighbors in each round, 3 rounds). In the 4th round, there are 9 - 6 = 3 people left that this person has not been acquainted with. Since there are 3 people left that each person hasn't been acquainted with, and each person needs 2 new neighbors, it is always possible to find a seating plan for the 4th round. This is because there are enough unacquainted people to fill the neighbor slots for each person. However, I think it needs to relate using concepts of graph theory as well. Any help is appreciated.","['graph-theory', 'pigeonhole-principle', 'combinatorics']"
4813410,Expected value - No consecutive heads sequence,"Problem: Suppose that you flip a coin $n$ times and it turns out that
no consecutive heads appear in the sequence. Let $E(n)$ be the
expected number of heads that appear given this information. Find $
 \lim_{n\to\infty} \frac{E(n)}{n}$ . The answer is in the form of $\frac{a}{b+\sqrt{c}}$ for integers a,b,c with minimal c. My approach:
Any sequence of n coins having exactly k heads (none consecutive) will be of the form T...THT...THT...THT...T
Let $x_1$ be the number of T's before the first H. Similarly define $x_i$ for i = $2,3,...,k+1$ Here, $\quad x_1$ and $x_{k+1}$ can be $0,1,... $ $\quad$ but $\quad$ $\forall$ i = $2,..,k\quad$ $ x_i = 1,2,...\quad$ (since we want no consecutive heads) In order to use the multinomial approach, define new variables $y_i = x_i-1 $ for these $k-1$ variables. Now, the number of ways to get such a sequence with k heads (no consecutive) = number of sol of the equation: $x_1 + y_2+y_3+...+y_k+x_{k+1} = n - k,$ where all variables $\in 0, 1,..$ After getting the general term for the above, taking the summation over k and dividing by total number of possible outcomes and taking the limit of n. $$\lim_{n\to\infty}\frac{E(n)}n = \frac1n \left( \frac{\sum_{k=0}^{k=(n+1)/2} k\cdot {{n-k+1} \choose {k}}}{\sum_{k=0}^{k=(n+1)/2} {{n-k+1} \choose {k}}} \right) $$ I can't seem to simplify the numerator. I've tried everything. Is this the correct approach? Is there a better one? Either way how do I find the above limit?","['expected-value', 'conditional-expectation', 'probability-theory', 'probability']"
4813450,How to define this function so that it is continuous?,I have a function $$f(x)=\frac{\arctan(2 \tan (x))}{x}$$ or in general for some $c\in \mathbb{R}$ $$f(x)=\frac{\arctan(c \tan (x))}{x}$$ Is there a way to define it so that it is continuous on interval $0\le x \le 2\pi$ avoiding piecewise definition? Here is the plot of it: But if I plot all instances of multivalued function $\tan ^{-1}(x)=\{\arctan(x)+\pi k\mid k\in \mathbb {Z} \}$ I get this: I want the definition of the middle orange-green-blue-red-violet curve.,"['trigonometry', 'functions', 'analytic-continuation']"
4813499,A fair six-sided die is rolled repeatedly until the product of the rolls is square.,"I'm stuck on this problem. A fair six-sided die is rolled repeatedly. On average how long does it take until the first
time that the product of the numbers rolled is a square? (For example, if the first roll is
1 or 4, it takes just one roll; if the sequence begins 3, 2, 6, then it takes three rolls.) I'm trying to use prime factors to get a solution, for instance if we don't roll a 1 or 4 first, rolling it again will not affect the chance of the next throw giving our product as a square, and we need an even number of 5s, the number of 2s + number of 6s to be even, and the number of 3s + number of 6s to be even. I know I need to relate this to Markov chains somehow, but I'm stuck as to how.","['statistics', 'markov-chains', 'probability', 'dice']"
4813576,"$f^2=g^3+1$ only when $f,g\in\Bbb C$","Trying to learn some algebraic geometry I found the following exercise, where the author claims I will get some insight in the field: Prove that if $f$ and $g$ are polynomials (with complex coefficients) such that $$f^2=g^3+1\tag{1}$$ then $f$ and $g$ are both constant. I want to know if my proof is correct, and if there is a faster way to get the result. Here we go: Write $g^3=f^2-1=(f+1)(f-1)$ . If a polynomial $d$ divides either $f,g$ then $d\mid 1$ , so $f,g$ have no common factor. Also, there is no non-constant polynomial that divides both $f+1,f-1$ , as that polynomial ought to divide $2$ . Therefore there are polynomials $u,v$ such that $$f+1=u^3$$ $$f-1=v^3$$ This gives $2=u^3-v^3=(u-v)(u^2+uv+v^2)$ . Therefore $u-v=c$ for some constant $c\in\Bbb C$ . This gives $$(v+c)^3-1=v^3+1$$ $$3cv^2+3c^2v+c^3-2=0$$ The last equation is only possible if $v$ is a constant, this forces $f,g$ to be constants as well.","['number-theory', 'algebraic-geometry', 'solution-verification']"
4813615,When is $x^2+9y^2 \pm y$ a perfect square,"I have come across a problem in which it is to be determined for what values of $x$ the expression $x^2+9y^2 \pm y$ is a perfect square, i.e. $x^2+9y^2 \pm y=z^2$ , for $x,y,z \in \mathbb N$ There are obvious trivial solutions, when $y=0$ and $y=x^2$ , so I am interested in solutions where $0<y<x^2$ . Looking at small numbers by trial and error calculation, there are some values of $x$ that give rise to no solutions, such as $x=5,10,12$ . But many other values of $x$ give rise to one or more solutions, including $(x,y,z)=(4,3,10),(8,9,28),(20,23,72),(20,36,110),(20,57,172)$ , etc. I have included the tag Pythagorean triples because when $9y^2$ is viewed as $(3y)^2$ the equation resembles a variation of the Pythagorean equation, and some students of that relationship may have insights. I am unaware of any tools to analyze the equation of interest, $x^2+9y^2 \pm y=z^2$ with regard to what values of $x$ do or do not give rise to solutions. My questions are: Are there methods to decide what values of $x$ will give rise to solutions? And, more specifically, is there a value of $x$ , call it $x_m$ , such that for all $x>x_m$ , solutions can be found? I am extremely embarrassed to have posted essentially the same question twice (see link in comments). The reason I find this question to be so important (and I arrived at it twice in my pursuits) is because the statement ""There are infinitely many values of $x$ for which the expression $x^2+9y^2 \pm y$ cannot be a perfect square"" (for $y$ within the range specified) is equivalent to the statement ""The twin prime conjecture is true."" The demonstration of that claim is lengthy and goes far afield beyond the specific question posed, but if proof thereof is demanded, I can append it in a further addition to this question.","['number-theory', 'square-numbers', 'pythagorean-triples']"
4813645,Maximum variance of a discrete probability distribution over a set of N fixed numbers,"Suppose $P_i$ is a probability distribution over a set $\\{a_i\\}$ i.e. $\\{a_1,a_2,...a_N\\}$ where the $a_i$ 's are fixed and $N$ is finite. If the mean is defined by $$
\langle a \rangle = \sum_{i=1}^{N} P_i a_i
$$ Then what will be the maximum value of the variance $\langle a^2 \rangle - (\langle a \rangle)^2 $ ? Note: this is a variation of the post Maximum variance of a discrete probability distribution over the non-negative integers. Here the set $\\{a_i\\}$ was simply the set of first $N$ non-negative integers, but my question is for a more general finite set. Any guidance on how to approach this would be helpful!","['statistics', 'probability-distributions', 'probability']"
4813653,"Asymptotically, how many rolls of an $n$-sided die will multiply to a perfect square for the first time?","This is a generalization of this question , which I found amusing. My generalization is as follows: You have an $n$ -sided die. You roll at least once, and keep rolling until the product of all the rolls equals a perfect square. For instance, the following roll sequences are complete and don't contain any complete proper prefixes: $2$ - $1$ - $6$ - $3$ , yielding $36 = 6^2$ the single roll $4 = 2^2$ $5$ - $2$ - $2$ - $4$ - $5$ , yielding $400 = 20^2$ Let $r(n)$ be the expected number of rolls needed to multiply to a perfect square for the first time. The quoted question asks for $r(6)$ . I'd like to find the asymptotic behavior of $r(n)$ as $n \to \infty$ , as closely as possible. I don't see a duplicate, but I'm not $100$ percent sure there isn't one. I have a simple approach (which I haven't completed working on yet) based on a continuous approximation to $\pi(n)$ , the prime-counting function, but I have a vague suspicion that there's something better out there. Any thoughts?","['probability', 'prime-numbers']"
4813703,What are general Theorems / Conjectures for Graph Characterization other than of Forbidden subgraphs?,"Recently, I have been interested in graph characterization problems. One such problem deals with forbidden subgraphs or minors. Robert and Seymour long back in a series of papers (Graph Minors Series) proved theorem related to graph minors now called 'Robert-Seymour' theorem. There are conjectures I found related to $K_6$ and $K_7$ minors (Topics in Chromatic Graph Theory) and more general ones like Hadwiger conjecture. So are there in literature - theorems/conjectures or similar to aforementioned some undertaking that deal with graph characterization other than forbidden subgraphs? Wherein the characterization simply does not deal with ""subgraph related"" problems. In short, I am looking for more characterization problems that are as general as or more general than Robertson–Seymour theorem in graph theory literature but not about forbidden subgraphs.","['graph-theory', 'discrete-mathematics']"
4813710,Is an immersively path-connected space arc-connected?,"Edit : I've asked a followup question . Suppose $X$ is a topological space such that any two points $x_0,x_1\in X$ are connected by an immersive path, i.e. there is a locally homeomorphic embedding $\gamma\colon [0,1]\to X$ such that $\gamma(0)=x_0$ and $\gamma(1)=x_1$ . Does it follow that $X$ is arc-connected, i.e. that we can choose $\gamma$ to be an actual homeomorphic embedding? Note that we can assume without loss of generality that $X$ is the image if an immersive path, in particular that it is a compact space which is covered by (finitely many, by compactness) arcs. Further, the conclusion is true if $X$ is Hausdorff (in fact, just being path-connected is sufficient in this case). (This is sort of motivated by my ruminations related to this question .)","['general-topology', 'path-connected', 'examples-counterexamples']"
4813731,Closed form expression for an integral with a cosine function,"I am attempting to solve a first-order ODE of the form: $$y'(x) = {\rm sech}^2(x){\rm sech}'(x) \times(a + b\cos(cx))$$ The part with the constant was easy to solve and I get $$y(x) = a\int {\rm sech}^2(x){\rm sech}'(x) dx = a\frac{{\rm sech}^3(x)}{3} + C,$$ where $C$ is a constant. However, the part with the cosine term is harder to integrate. I tried simple integration-by-parts since I know the integral of ${\rm sech}^2(x){\rm sech}'(x)$ , but I didn't see it leading me anywhere. Wolfram Alpha gave me a hypergeometric function, but I wonder if there is a cleaner closed-form expression for the integral.","['indefinite-integrals', 'ordinary-differential-equations']"
4813755,How to solve the differential equation given below,"How to solve the following differential equation: $$ y' = \frac{\sqrt[3]{x-2y}}{\sin(x)} $$ We can rewrite it as $$ y= \frac{1}{2} (x- y'^3 \sin^3(x))$$ I tried to substitute $y'=p$ and then proceed, but I did not conclude anything. $\textbf{Edit:}$ I tried to rewrite it as: $$ dy - \frac{\sqrt[3]{x-2y}}{\sin x} dx=0 $$ And then find the integrating factor: $$ \mu = \mu (x) = e^{- \int \frac{\sqrt[3]{x-2y}}{\sin x}dx} $$ However there is no elementary way to solve the integral on the exponent. $\textbf{Edit 2}$ I saw this Calculate Laurent series for $1/ \sin(z)$ So one way is perhaps to decompose the function: $$ f(x) = \frac{1}{\sin(x)} $$ However I'm not familiar with solutions of DE with series and I don't know under what conditions we can do that.",['ordinary-differential-equations']
4813799,Have roots of $z^3+|a|z^2+|b|z+|c|$ module $1$ if roots of $z^3+az^2+bz+c$ have module $1$?,"Let $a,b,c\in\mathbb{C}$ and for any root $\alpha$ of polynomial $z^3+az^2+bz+c$ , $|\alpha |=1$ . Prove that for any root $\beta$ of polynomial $z^3+|a|z^2+|b|z+|c|$ , $|\beta |=1$ . My try so far: Let's suppose $z_1, z_2, z_3$ are roots of $z^3+az^2+bz+c$ , by Vieta's formula I know that $$a=-(z_1+z_2+z_3)$$ $$b=z_1z_2+z_2z_3+z_1z_3$$ $$c=-z_1z_2z_3$$ and substituing in $z^3+|a|z^2+|b|z+|c|$ I have that $$z^3+|z_1+z_2+z_3|z^2+|z_1z_2+z_2z_3+z_1z_3|+|z_1z_2z_3|\le z^3+3z^2+3z+1=(z+1)^3$$ I guess it's a good thing getting to a polynomial as $(z+1)^3$ because its roots have module $1$ , but I don't see a clear way to go. Any idea? Edit: Assuming $\beta =e^{i\theta}\alpha$ and substituing in the polynomial then I get $$e^{3i\theta}\alpha^3+|a|e^{2i\theta}\alpha^2+|b|e^{i\theta}\alpha+|c|$$ and have to prove this is $0$ , but don't know how to follow","['complex-analysis', 'polynomials']"
4813810,Frobenius norm of a product of Gaussian matrices,"Suppose $$C_n=X_1 X_2\cdots X_n$$ where $X_i$ is $d\times d$ matrix with IID entries sampled with normal centered at 0 and variance $1/d$ . The following appears to be true for large $d$ , why? $$\|C_n C_n^T\|_F^2\approx d(n+1)$$ Here are some numbers from a 4 samples with $d=1000$ $$
\begin{array}{c|ccccc}
  & \text{n} & \text{sample1} & \text{sample2} & \text{sample3} & \text{sample4} \\
\hline
  & 1 & 2003.99 & 1998.66 & 1999.51 & 1998.14 \\
  & 2 & 3029.97 & 2990.12 & 3008.21 & 2999.13 \\
  & 3 & 3967.81 & 3995.46 & 4022.33 & 4005.2 \\
  & 4 & 5027.41 & 5075.39 & 4941.94 & 5057.4 \\
  & 5 & 6143.21 & 5964.35 & 5844.76 & 6015.08 \\
\end{array}
$$ Notebook It also appears to hold if I use the same matrix for all $X_i$ , ie, $$\|X^n (X^T)^n\|^2_F \approx d(n+1)$$ Dividing entries of table by $d$ below we get near perfect agreement in table below with $d=4000$ using either $X^n$ (fixed) or $C_n$ (resampled) ( crossposted on stats.SE)","['statistics', 'linear-algebra', 'random-matrices', 'probability-theory', 'probability']"
4813818,Proving a math problem is only solvable numerically?,"This is a question I have always wondered about: Classical theorems in calculus (e.g. Extreme Value Theorem) tells us that for some function over a given interval, a set of inputs must exist such that the function reaches a maximum and a minimum. The aim of the game is now to determine if these inputs can be determined analytically or numerically Now, consider a system of Maximum Likelihood Equations In some cases, a given system of Maximum Likelihood Equations has an ""analytical"" solution : we can find a general relationship between the parameters of the probability distribution with respect to the random variables. This makes things very convenient - if this can be done, in the future, no matter what dataset we encounter, we can very quickly calculate the parameters for any dataset because we have found a closed form solution However, many times, this is not possible and we are required to solve numerically Thus, it makes me wonder, perhaps in the future, a ""cool mathematical trick"" would be discovered that would allow for this same problem to be solved analytically Yet, in most references I read (e.g. textbooks in probability/statistics) - I have never encountered a mathematical proof which shows that certain systems of Maximum Likelihood Equations fundamentally do not have closed form solutions. There is always this tone being implied that perhaps a closed form solution exists, perhaps it doesn't - but currently, we solve numerically. I was always curious to know if we can conclusively prove that a closed form solution is guaranteed to not exist. I have asked similar questions in the past (see references below) and have never been able to find an exact answer on this topic. I am now trying to reformulate my question in a more concise way: For a given system of maximum likelihood equations, is it possible to mathematically prove that an ""elementary solution"" will never exist ... no matter how much the field of mathematics ever progresses? Thanks! References Prove that an equation has no elementary solution How do we know that some System of Equations doesn't have an ""Analytical Solution""? Is it Possible that some Non-Analytically Integrable Functions might actually have Analytical Integrals? https://en.wikipedia.org/wiki/Liouville%27s_theorem_(differential_algebra)","['optimization', 'probability']"
4813828,Why do we define things in terms of differential equations instead of directly in functions?,"Consider the 1 dimensional heat equation (which is a differential equation) - this tells you the rate at which temperature changes across the rod at different times (relative to some initial conditions): $$\frac{\partial u}{\partial t} = \alpha \frac{\partial^2 u}{\partial x^2}$$ The solution this equation is the following: $$u(x,t) = \sum_{n=1}^{\infty} B_n \sin\left(\frac{n\pi x}{L}\right) \exp\left(-\alpha \left(\frac{n\pi}{L}\right)^2 t\right)$$ Although the solution looks more complicated, (for me at least) its easier to understand. The solution tells us directly the temperature of the rod at any position at any time (given some initial conditions). My Question: In our math lectures/classes, we always start with the differential equation and then learn how to solve this. That is, we first define the differential equation and then derive its solution. The solution to this differential equation always seem to be of prime importance as the solution can be directly applied in many real world situations. Thus, the obvious question: If we are so interested in the solution of the differential equation - why don't we start by directly defining an equation that we believe directly describes the temperature of the rod at some point/time (relative to the initial conditions)? Why go through all the trouble of defining the differential equation only to then figure out how to solve it ... and eventually end up with the solution? Why not directly define the solution, instead of defining a differential equation and then solving it .... when we are primarily interested only in the solution? Thanks!",['ordinary-differential-equations']
4813916,Prove that $ \int^t_0X_s dA_s$ is progressively measurable.,"Let $(\Omega, \mathcal F_\infty, \mathcal F= (\mathcal F_t)_{t\geq 0})$ be a filtered probability space, let $X = (X_t)_{t\geq 0}$ be a progressively measurable process and $A= (A_t)_{t\geq 0}$ be a pathwise increasing, right-continuous, $\mathcal F$ -adapted process and $A_0=0$ identically. Suppose we have $$ \quad \int_0^\infty |X_s(\omega)| dA_s(\omega) < \infty, \forall \omega$$ Prove that the process $$ Y_t(\omega) := \int_{0}^t X_s(\omega)dA_s(\omega), \forall \omega $$ is progressively measurable. Here $ \int^t_0 = \int_{[0,t]}$ is the Lebesgue-Stieljes integral with the $\sigma$ -finite measure $\mu_{A(\omega)} (a,b] = A_b(\omega) - A_a(\omega)$ on $[0,\infty)$ . What I have tried: I know that Lebesgue integrals are right-continuous so $Y$ is right-continuous, hence what is left is to prove $Y_t \in \mathcal F_t$ . If $X$ is continuous, this is again doable for me since now I can write the integral as a Riemann limit. But for general progressively measurable process, I don't know what to do. My first thought is try (but fail) to approximate $X_t(\omega)$ by simple progressive processes, which are of the form $$ Z_t = Z_0 + \sum_{i=1}^{n-1} Z_i \mathbb 1_{[t_i,t_{i+1})}, \quad Z_i \in F_{t_i} $$ Any hints are highly appreciated!","['stochastic-processes', 'lebesgue-measure', 'probability-theory']"
4813945,When and why is the sum of infinite zeroes exactly zero? [duplicate],"This question already has answers here : How do you calculate this limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2}$? (3 answers) Closed 7 months ago . I was solving the following limit problem : $$L=\lim_{n\to\infty}\sum_{r=1}^{n}\frac{r}{n^2+r^2}$$ Upon opening sum, we have : $$L= \frac{1}{n^2+1}+\frac{2}{n^2+4}...+\frac{n}{n^2+n}$$ Clearly, each term approaches to zero as $n\to\infty$ . But , my teacher said we cannot add all zeroes and say that answer is zero. This is because there are infinitely many zeroes and $(0\times\infty$ ) is indeterminate. However, in various limits problems where we had to use series expansions ( like of $\lim_{x\to0}\frac{e^x-1}{x} , \frac{\sin(x)}{x}$ , etc.) , we did put zeroes and ignored the sum of infinite zeroes. For example : $$\frac{\sin(x)}{x} = 1- \frac{x^2}{6}+\frac{x^4}{120}...$$ As $x\to0$ , $$\lim_{x\to0}\frac{\sin(x)}{x}=1+0 +0+0+0...$$ Similarly, for any $n≤r≤1$ , $$\lim_{n\to\infty}\frac{r}{n^2+r^2}=0 $$ So that ; $$\lim_{n\to\infty}\sum\frac{r}{n^2+r^2}=0 + 0 + 0... $$ We get the correct answer in first case but it's wrong in second. Question: When and why can the sum of infinite zeroes be exact zero or indeterminate ? Edit: I am not interested in finding the answer to this limit problem. My question is about when and when not can we add infinitely many terms approaching zero. The limit used above in my question was just an example to illustrate my main question.","['limits', 'algebra-precalculus', 'functions']"
4813973,"Equation of plane $\mathbf{x} = (1, 0, 1) + s(1, 3, -1) + t(2, 2, 1)$","I'm given that the plane $W$ in $\mathbb R^3$ can be written as $$W: \mathbf{x} = (1, 0, 1) + s(1, 3, -1) + t(2, 2, 1)$$ where $s$ and $t$ are real numbers. My task is to write $W$ as a general equation. I can't seem to figure out how to do this. I've tried to find similar threads and working out a normal of two vectors in the plane, using the cross product. Can't get it to work. When I plot certain points for random values of s and t, the points don't actually lie on the plane. Any help would be appreciated...","['algebra-precalculus', 'linear-algebra', 'vectors']"
4813992,Problem with understanding Morse's Lemma / Function.,"https://math.stackexchange.com/a/398282/1257548 In this answer it is said that $f:S→\mathbb{R}, (x,y,z)↦y$ is Morse function but I don't see why. As far as I understand, because function is defined on manifold $S = \{(x,y,z):z^4+(x^2+y^2-1)(2x^2+3y^2-1)=0\}$ then using implicit function theorem we have that $$\frac{dy}{dz} = -\frac{4z^3}{12y^3+10x^2y-8y}$$ and $$\frac{dy}{dx} = -\frac{8x^3+10xy^2-6x}{12y^3+10x^2y-8y}$$ so $$\frac{d^2y}{dz^2}(x,y,0)=0, \frac{d^2y}{dx^2}(0,y,0)=a,\frac{d^2y}{dxdz}(x,y,0)=0.$$ So Hessian of $f$ is degenerated in $(0,−1,0),(0,−\frac{1}{\sqrt{3}},0),(0,\frac{1}{\sqrt{3}},0),(0,1,0)$ thus it can't be Morse function. Even differentiating $f$ like $\frac{df}{dy}=1$ and $\frac{d^2f}{dy^2}=0$ shows that it's also degenerated. I don't know if I don't understand something or if the answer is wrong. I know that taking the height function as Morse function works on torus and I see that taking $f(x,y,z)=y$ on S should work the same but I don't know why it doesn't work (or if I'm just doing something wrong). And if the function is wrong is it possible to correct it to proper Morse function?","['morse-theory', 'algebraic-geometry', 'surfaces', 'differential-geometry']"
4814006,BMO1 number theory question on fibonacci sequence and divisibility,"This is question 2 from the 1983 British Maths Olympaid The fibonacci sequence $f_{n}$ is defined by $f_{1} = 1, f_{2} = 1,$ and $f_{n} = f_{n-1} + f_{n-2}, n > 2$ prove that there are integers a, b and m such that $0 < a < m$ , $0 < b < m$ and $f_{n}-anb^{n}$ is divisible by $m$ for all positive integers $n$ . I'm pretty sure I've solved the question, but this is my first time solving a question like this with divisibility in sequences, so please could someone look at my solution and tell me places where there are better routes or improvements. I also think my solution is quite long for a question 2 problem, which makes me think there is an easier, quicker way that I have overlooked. My solution:
By the inequality condition, we see $m = 1$ is impossible, then let $T_{n} = f_{n} - anb^{n}$ , so, $m|T_{1}$ and $m|T_{2}$ . $m|1-ab$ -----> (A) from this we can also see m must not divide a or b, or else $m|1$ which means for $m>0$ we get $m = 1$ which is impossible $m|1-2ab^{2}$ -----> (B) multiply (A) by $2b$ $m|2b-2ab^{2}$ -----> (C) $m|(C) - (A)$ so, $m|2b-1$ $m|T_{1} + T_{2}$ and $m|T_{3}$ , since these two parts have the same constant I thought to subtract one from the other and get an expression only in terms of $a$ and $b$ which I then factorised to get $m|ab(b-1)(3b+1)$ since m doesn't divide a or b, $ab$ can be removed. Also, $m|2b-1$ but m doesn't divide $b$ , so $m$ doesn't divide the difference between $2b-1$ and $b$ . So, $m|b-1$ is impossible, meaning (b-1) can be removed too, leaving us with $m|3b+1$ and $m|2b-1$ so $m|6b+2$ and $m|6b-3$ so $m|(6b+2) - (6b-3)$ so $m|5$ . Under current restrictions for $m$ only $m=5$ is possible, so $m = 5$ . $a<5, b<5$ for $T_{1} \equiv 0\pmod{5}$ it must be that $ab \equiv 1\pmod{5}$ . The only possible pairs $(a,b)$ are $(1,1)$ , $(4,4)$ and $(2,3)$ or $(3,2)$ . I just tested each pair for $T_{n}$ divisibility by $5$ , where they all failed quite quickly except for $(a,b) = (2,3)$ .
Now we just have to prove that this pair works. I decided to do this by having $S_{n} = 2(n)(3^{n})$ and showing that $S_{n} \equiv f_{n}\pmod{5}$ for all $n$ . This I found I could do by showing $S_{n}$ follows the same relation as $f_{n}$ in $\mod{5}$ and has the same start terms (1 and 1). We could have done this by calculating $f_{n}\pmod{5}$ for some time and eventually see that it becomes a repeating sequence, so we could just calculate $S_{n}\pmod{5}$ upto that point and show that $S_{n}\pmod{5}$ is also repeating with the same period as $f_{n}\pmod{5}$ and that all the terms are equal, but I wanted to avoid much computation and instead tried the following. Now to show $S_{n} \equiv f_{n}\pmod{5}$ for all n: We follow the route of showing that $S_{n} \pmod{5}$ follows the same relation as $f_{n}\pmod{5}$ . we know by applying $\pmod{5}$ to the fibonacci sequence definition, $f_{n} \equiv f_{n-1} + f_{n-2} \pmod{5}$ . So, since we already have $S_{1} \equiv f_{1} \pmod{5} $ and $S_{2} \equiv f_{2} \pmod{5}$ by some calculations, we just need to show that $S_{n} \equiv S_{n-1} + S_{n-2} \pmod{5}$ . base case: $S_{3} \equiv S_{1} + S_{2}\pmod{5}$ which is true. By definition, $S_{k+1} = 2(k+1)(3^{k+1})$ $S_{k+1} = (2k+2)(3^{k+1})$ $S_{k+1} = (2k)(3^{k+1}) + 2(3^{k+1})$ $S_{k+1} = (2k)(3^{k})(3) + 2(3^{k+1})$ $S_{k+1} = (2k)(3^{k}) + 2((2k)(3^{k})) + 2(3^{k+1})$ $S_{k+1} = 2k(3^{k}) + (6)(2k)(3^{k-1}) + 2(9)(3^{k-1})$ Now since we are considering $S_{n} \pmod{5}$ , I applied $\pmod{5}$ to the above equation. $S_{k+1} \equiv 2k(3^{k}) + 2k(3^{k-1}) - 2(3^{k-1})\pmod{5}$ $S_{k+1} \equiv 2k(3^{k}) + 2(k-1)(3^{k-1})\pmod{5}$ $S_{k+1} \equiv S_{k} + S_{k-1}\pmod{5}$ This is the same recurrence relation as $f_{n}\pmod{5}$ and since they have the same starting two values, 1 and 1, $S_{n} \equiv f_{n} \pmod{5}$ for all $n$ , meaning that $f_{n} - S_{n} \equiv 0\pmod{5}$ for all $n$ ie: $5|f_{n} - 2n(3^{n}) $ for all $n$ , which means that $m =5$ , $a = 2$ and $b = 3$ are the only positive integers with $a<m$ and $b<m$ that allow $m$ to divide every term of the sequence $T_{n}$ .","['contest-math', 'fibonacci-numbers', 'divisibility', 'elementary-number-theory', 'sequences-and-series']"
4814029,Are biconnected spaces $T_0$?,"This question was motivated by recent posts about biconnected spaces, see here . A space is called biconnected , if it is connected and the intersection of any two connected subsets $A,B$ with $|A|, |B| \ge 2$ is non-empty.
(This is not the original definition, but an equivalent one, which turned out to be more relevant.) Let $X$ be a biconnected topological space with $|X| \ge 4.$ Is $X$ $T_0$ ? Notes. If $X$ has the indiscrete topology and $2 \le |X| \le 3$ , then $X$ is biconnected, but not $T_0$ . If $X$ is finite (or, more generally, Alexandroff), the answer is yes, see the post linked above. Every connected space with a dispersion point (i.e., the subspace without that point is totally disconnected) is biconnected. While the converse is false, both properties seem to be quite close together. For instance, no counterexample in the plane without additional set-theoretic assumptions is known. In fact, 3. was my motiviation for this question, since, as it is easy to see, a connected space with a dispersion point is $T_0$ . As an answer to the question of the above link, M W proved that there is an $x_0 \in X$ , such that $X \setminus \{x_0\}$ is $T_1$ . Does this help? Most often, biconnectness is considered in the realm of $T_2$ , or even (separable) metric spaces. Hence, this question is somewhat unusual. Or is there any relevant, already known result? Of course, biconnected spaces need not be $T_1$ : there are even finite, bicconected spaces of arbitrary size.","['general-topology', 'connectedness']"
4814031,"If $\pi(x) = Li(x) + O(\ln^3(x) \sqrt x) $ is true, what does that say about the Riemann zeta zeros?","Let $\pi(x)$ be the prime counting function.
The statement $\pi(x) = Li(x) + O(\ln^3(x) \sqrt x) $ is in ""essence"" weaker than what we can conclude from the RH if the RH is true. I assume it is correct to say that this statement does not imply the ""stronger"" statement $|\pi(x) - Li(x)| < \ln(x) \sqrt x$ for $x>2656$ that follows from the RH ?
If that is incorrect, let me know. If $\pi(x) = Li(x) + O(\ln^3(x) \sqrt x) $ is true, and it is indeed weaker than the RH, then what does that say about the nontrivial Riemann zeta zero's ?
Do they change in real part or distance or multiplicity ?
And how does that work ? edit : I used big O notation : see https://en.wikipedia.org/wiki/Big_O_notation edit 2 : To clarify (or avoid confusion) I mentioned $|\pi(x) - Li(x)| < \ln(x) \sqrt x$ and this follows from the truth of the Riemann Hypothesis, But the Riemann Hypothesis implies a stronger statement : and I am not sure if there is a stronger implication from RH or if it would be possible to find a stronger implication from RH , but anyways RH implies this : $|\pi(x) - Li(x)| < \frac{\ln(x) \sqrt x}{8 \pi}$ for $x>2656$ . Also I am uncertain what is the sharpest bound that is still consistant with the RH. For instance is $|\pi(x) - Li(x)| < \frac{\sqrt{\ln(x) x}}{8 \pi}$ for $x>q$ . for some fixed $q$ still potentially consistant with RH ? The following question and answers were clarifying : Riemann Hypothesis and the prime counting function copy answer : Any bound $|\pi(x)-\rm {li}(x)|\le f(x)$ with $f(x)=O(x^{1/2 + \epsilon})$ implies the Riemann hypothesis, and RH is equivalent to the existence of a bound of that type. The point of this particular $f(x)$ is that it is known to be provable from the Riemann hypothesis, and the parameters in the proof have been worked out explicitly (and might be some of the best ones currently available), so that the end result is not "" $f(x) = A\sqrt{x}(\log x)^B$ for $x > C$ for some $A,B$ and $C$ "", but $A = \frac{1}{8 \pi}$ , $B=1$ , $C = 2657$ .  The $O()$ notation signifies that the limit of $\frac{\log f(x)}{\log x}$ is $1/2$ ; if the limit had been $\rho \in [\frac{1}{2},1]$ the (non-trivial) zeros of the Riemann zeta would have real parts in the interval $[1 - \rho, \rho]$ .  The same bound with any other values of $A,B,C$ would also have been equivalent to RH. $C$ can be eliminated by inflating $A$ to cover the first $2656$ cases and then one would get a bound valid for all $x \geq 1$ .  This would be less informative, because the important thing is to minimize the exponent $B$ of the logarithm (which is related to the vertical distribution of the zeros), then the constant $A$ (which measures some finer aspect of the zero distribution, but I don't know if it has been articulated what that is). The cutoff $C$ is much less significant, because it is not an asymptotic, large- $x$ , quantity, and can be affected by moving a single zero along the critical line.
(end copy) But this still does not completely answer my question.
It does show that the real parts are still $1/2$ though. See also the related question : Is $|\pi(x) - Li(x)| < \frac{\sqrt{\ln(x) x}}{8 \pi}$ for $x>q$. for some fixed $q$ still potentially consistant with RH? where I ask for the case, Is $|\pi(x) - Li(x)| < \frac{\sqrt{\ln(x) x}}{8 \pi}$ for $x>q$ . for some fixed $q$ still potentially consistant with RH ?","['number-theory', 'analytic-number-theory', 'upper-lower-bounds', 'riemann-zeta', 'prime-numbers']"
4814068,Prove $A_{ij} = \frac{1}{\sqrt{i+j}}$ is positive definite,"I'm currently working through an exercise in an undergraduate functional analysis textbook and encountered the following problem: Prove that the $n\times n$ matrix $A$ with entries defined as $A_{ij} = \frac{1}{\sqrt{i+j}}$ is positive definite. In our lectures, we've just been introduced to the concept of inner products, and this problem was presented soon after. I suspect that the solution may not require advanced theorems. I have checked the result with numeric methods. And it turns out that at least for $n\le13$ it's true. For $n=14$ somehow the determinant becomes $−2.26×10^{−111}$ . Is it really negative or a numeric error?","['linear-algebra', 'functional-analysis']"
4814074,Problem of drawing poker,"Randomly shuffle a deck of poker cards (52) and continually draw the card without replacement. On average how many cards you need to draw in order to get a card which has a same value as the cards you've drawn?
That is to say, if the card you've drawn is 1->2->3->4, then you would stop at the next step if you draw one of the 1,2,3 or 4. This is a problem I came upwith when I was playing desk card games... I thought ""on average"" it could be seen as $E(\sum_{i=1}^{52}I_i)$ of which $I_i$ means the i-th card has already been seen (0) or not (1). Then $E(\sum_{i=1}^{52}I_i) = \sum_{i=1}^{52}P_i$ of which $P_i$ is the prob that the i-th card is a new card (not seen before). But apparently the $P_i$ depends on $i$ ....so what can I do next? ===============
The original post is ""stop when you draw a card with a same face value as the first card"". I think that's just splitting the remaining deck (52-1=51 cards) by 3 cards, i.e. we have (51-3)/4 cards per subdeck. Then the answer could be (51-3)/4 + 1 + 1. But not so sure... The background comes from a Chinese desk card game. The game aims to kill other characters (lower down the life points). One special hero has a special skill, i.e. when he is almost dying (life point goes from 1 to 0 due to the attack) he could draw a card from the deck and collect it, if the card has a same face value compared to the cards he collected by this method (i.e. draw a card when life point goes from 1 to 0) then he dies. I am just wondering on average how many cards he could collect (or how many times you need to ""attack"" him).","['statistics', 'card-games', 'probability']"
4814076,Seeking guidance on calculating the volume of a four-dimensional cone,"I'm working on a problem involving a four-dimensional cone defined as follows: $C = \left\{\left(x,y,z,t\right)| (x,y,z) \in (1 - \frac{t}{12})B,0 \leq t \leq 12\right\}$ where the base $B$ is described by $x^2 + (y - 1)^2 + z^2 \leq 1$ . I'm tasked with finding the volume (measure) of $\mu(C)$ .
I understand that the base $B$ is a three-dimensional ball centered at $(0,1,0)$ with a radius of 1. However, I'm unsure how to approach calculating the volume of this four-dimensional cone based on this information. Could someone please provide guidance on how to compute the volume of this four-dimensional cone? Any step-by-step approach or insights into higher-dimensional geometry would be greatly appreciated!","['measure-theory', 'volume', 'geometry', 'solid-geometry', 'multivariable-calculus']"
4814081,Ramanujan-Type Harmonic Series $\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{1/6+r}{2^{8r}}\right)H_{r-1/2}=-\frac{8\ln2}{9\pi}$,"We will be considering series such as this : $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{1/6+r}{2^{8r}}\right)H_{r-1/2}=-\frac{8\ln2}{9\pi}$$ Consider $K(k)$ and $E(k)$ to be the Complete Elliptical Integrals of the First and Second Kind Respectively with $K'(k)=K(k')$ and $E'(k)=E(k')$ , where $k^2+k'^2=1$ . First let us consider the following Generating Functions: $$\sum_{r=0}^{\infty}\binom{2r}{r}^2\frac{H_r}{2^{4r}}k^{2r}=K'(k)+\frac{2K(k)}{\pi}\ln\left(\frac{k}{4k'}\right)$$ $$\sum_{r=0}^{\infty}\binom{2r}{r}^2\frac{H_{2r}}{2^{4r}}k^{2r}=\frac{K'(k)}{2}+\frac{2K(k)}{\pi}\ln\left(\frac{\sqrt{k}}{2k'}\right)$$ Now one may let $k\to k\sin t$ and Integrate from $0$ to $\pi/2$ with respect to $t$ . $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{H_r}{2^{6r}}\right)(2kk')^{2r}=\frac{4K(k)K'(k)}{3\pi}+\frac{8K^2(k)}{3\pi^2}\ln(kk'/4)-\frac{2v(2kk')}{\pi^2}$$ $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{H_{2r}}{2^{6r}}\right)(2kk')^{2r}=\frac{2K(k)K'(k)}{3\pi}+\frac{4K^2(k)}{3\pi^2}\ln(kk'/4)-\frac{2v(2kk')}{\pi^2}$$ where, $$v(k)=\int_{0}^{\pi/2}K(k\sin t)\ln(1-k^{2}\sin^{2}t)dt$$ What's troublesome here is the function $v(k)$ , I am not able reduce it further. At the very least we can find the Generating Function for $H_{n}-H_{2n}=\overline{H}_{2n}$ which is the Skew Harmonic Number (As the Function $v(k)$ cancels out). $$\pi\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\overline{H}_{2r}}{2^{6r}}\right)(2kk')^{2r}=\frac{2}{3}K(k)K'(k)+\frac{4}{3\pi}\ln(kk'/4)K^2(k)$$ Now we differentiate here and write everything in Terms of $k_n$ , $\alpha_n,\beta_n$ . Where $k_n$ is the Elliptic Integral Singular Value such that $K'/K=\sqrt{n}$ . $\alpha_n$ is the Elliptic Alpha Function. and $\beta_n$ is defined by us as $$\beta_n=\ln(k_nk'_n/4)$$ Now, $$\pi\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\overline{H}_{2r}}{2^{6r}}\right)(2k_nk'_n)^{2r}=\frac{2}{3}K_n^2\left(\sqrt{n}+\frac{2\beta_n}{\pi}\right)$$ and, $$\pi\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\overline{H}_{2r}}{2^{6r}}\right)r(2k_nk'_n)^{2r}=\frac{2}{3}K_n^2\left(\frac{1}{\pi}+\left(\frac{\alpha_n-k_n^2\sqrt{n}}{2k_n^2-1}\right)\left(1+\frac{2\beta_n}{\pi\sqrt{n}}\right)\right)-\frac{\beta_n}{3(2k_n^2-1)\sqrt{n}}$$ Although we cannot Eliminate $K_n$ by taking a Linear Combination, we can remove the Algebraic Term attached with $K_n$ . This gives us: $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\overline{H}_{2r}}{2^{6r}}\right)(2k_nk'_n)^{2r}\left(\frac{k_n^{2}-\alpha_n/\sqrt{n}}{k_n^2-k'^2_n}+r\right)=\frac{1}{\pi}\left(\frac{2K^2_n}{3\pi}-\frac{\beta_n}{3\sqrt{n}(k_n^2-k_n'^2)}\right)$$ Some Particular Evaluations of these using $k_3k'_3=1/4$ , $k_7k'_7=1/16$ are: $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\color{blue}{1/6}+r}{2^{8r}}\right)\overline{H}_{2r}=\frac{2}{3\pi}\left(\frac{K^2(k_{3})}{\pi}\ -\frac{4\ln2}{3}\right)$$ $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\color{blue}{5/42}+r}{2^{12r}}\right)\overline{H}_{2r}=\frac{8}{21\pi}\left(\frac{7K^2(k_{7})}{4\pi}-2\ln2\right)$$ And recall Ramanujan's Famous Series for $\pi$ : $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\color{blue}{1/6}+r}{2^{8r}}\right)=\frac{2}{3\pi}$$ $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{\color{blue}{5/42}+r}{2^{12r}}\right)=\frac{8}{21\pi}$$ Which is Interesting, I am guessing the Algebraic Term along with $r$ also appears in the Derivation of these Series. This got me thinking that although we do not have the closed form of Generating Functions for $H_r$ and $H_{2r}$ (due to function $v(x)$ ) so instead I set up to use Integer Relation Algorithms which surprisingly gives. $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{1/6+r}{2^{8r}}\right)H_{r}=\frac{4}{3\pi}\left(\frac{K^2(k_{3})}{\pi}\ -\ln2\right)$$ $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{1/6+r}{2^{8r}}\right)H_{2r}=\frac{2}{9\pi}\left(\frac{3K^2(k_{3})}{\pi}\ -2\ln2\right)$$ Nothing for the case of $k_7$ . (If it involves roots then I don't know how to use Integer Relations). This means we have a certain Hope of Evaluating $v(k)$ .
Both of the above equations are analogous to: $$2v\left(\frac{1}{2}\right)+3v'\left(\frac{1}{2}\right)=-\frac{8\pi \ln2}{3}\tag{1}$$ In fact now we can take a Linear Combination to Eliminate $K^2(k_3)$ as follows: $$\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{1/6+r}{2^{8r}}\right)(2H_{2r}-H_r)=\frac{4\ln2}{9\pi}$$ Which is a good start. If one wants something fancier then use $H_{n-1/2}=2H_{2n}-H_{n}-2\ln2$ to get: $$\boxed{\sum_{r=0}^{\infty}\binom{2r}{r}^3\left(\frac{1/6+r}{2^{8r}}\right)H_{r-1/2}=-\frac{8\ln2}{9\pi}}$$ Questions: Do we know anything about the Function $v(k)$ ?
The question about Generating Functions for Cubed Binomial $H_{r}$ and $H_{2r}$ has been considered in this post Generating function of the sequence $\binom{2n}{n}^3H_n$ but no response so far. Can we prove $(1)$ ? Like the Higher Order Variations of the $1/\pi^m$ Series, are higher order variations of the Binomial Harmonic Sums been considered anywhere in Literature?","['integration', 'summation', 'harmonic-numbers', 'generating-functions', 'elliptic-integrals']"
4814109,Regarding Egorychev integrals for binomial coefficients,"I've been searching for references that deals with the Egorychev methods and particularly with the integral representations for binomial coefficients. $$\binom{n}{k}=\frac{1}{2\pi i} \oint_{|z|<\infty}\frac{(1+z)^n}{z^{k+1}}dz$$ and $$\binom{n}{k}=\frac{1}{2\pi i} \oint_{|z|<1}\frac{dz}{(1-z)^{k+1}z^{n-k+1}}$$ My doubt here is, when to use each one? I've seen problems here on MSE where both are used but couldn't figure out when to choose over another.
Also I managed to get (?) a sketch of a proof but i would like to see this in the depth it deserves, and there's where I haven't had luck finding references. I am aware of Marko Riedel pdf about the Egorychev method and the Egorychev book itself. But there's no more besides these? And why isn't this more popular and used? I don't remember seeing these results in complex analysis books (not that I can remember at least). Anyway, thanks in advance if anyone can answer the question about when to use each case and/or conditions to consider to choose.","['book-recommendation', 'reference-request', 'complex-analysis', 'binomial-coefficients', 'combinatorics']"
4814111,how to obtain the value of $\frac{dy}{dx}$ at $x=1$ here...,Consider the following values of X and Y I know here we are required to find the value of $\frac{dy}{dx}$ using numerical methods.. But I am not getting how to use here... Actaully I am not getting the question also...what $x$ and $y$ values are given here.. Please hint me how to deal with this problem.. Thanks in advance...,"['numerical-methods', 'ordinary-differential-equations']"
4814129,Bregman divergence from Wasserstein distance,"I was wondering whether one has studied the Bregman divergence arising from a squared Wasserstein distance. More precisely, let $\Omega\subset \mathbb{R}^d$ be a compact set and $c\in \Omega\times \Omega $ be continuous. Let $\nu\in P(\Omega)$ be a fixed probability measure,
and define the map $P(\Omega) \ni \mu\mapsto T(\mu,\nu)\in \mathbb {R}$ such that $$
T(\mu,\nu)=\min_{\gamma \in \Pi(\mu,\nu)}\int_\Omega c(x,y)d \gamma,
$$ where $\Pi(\mu,\nu)$ is the set of probability measures with $\mu$ and $\nu$ as their first and second marginals, respectively. As shown in Proposition 7.17 of the book , $\mu\mapsto T(\mu,\nu)$ is convex and under suitable conditions on $\nu$ and $c$ , for all $\mu,\mu'\in P(\Omega)$ , $$
\lim_{\epsilon \to 0} \frac{T(\mu+\epsilon (\mu'-\mu),\nu)}{\epsilon}=\int_\Omega \varphi_\mu (x) (\mu'-\mu)(dx),
$$ where $\varphi_\mu$ is the unique Kantorovich potential from $\mu$ to $\nu$ .  This allows us to define the following Bregman divergence $D(\cdot|\cdot):P(\Omega)\times P(\Omega)\to \mathbb{R}$ by $$
D(\mu'|\mu)=T(\mu',\nu)-T(\mu,\nu)-\int_\Omega \varphi_\mu (x) (\mu'-\mu)(dx),
$$ where $\varphi_\mu (x)$ is the first variation of $  T(\cdot,\nu)$ at $\mu$ . Has the above Bregman divergence been studied in the literature? For instance, with specific choices of $c$ , say $c(x,y)=|x-y|^2$ , can we simplify the expression of $D(\mu'|\mu)$ ? Can we obtain its relation with commonly used metrics of probability measures?","['statistics', 'optimal-transport', 'information-theory', 'wasserstein', 'probability-theory']"
4814147,Property of signed measure and total variation,"Let $\nu$ be a signed measure on $(X,\mathcal{M})$ . The total variation of $\nu$ is defined as $$
|\nu|= \nu^+ + \nu^-,
$$ where $\nu = \nu^+ - \nu^-$ is the Jordan decomposition of $\nu$ . For every $B \in \mathcal{M}$ , one can show that if $\nu$ is $\sigma$ -finite, then $$
|\nu(B)| = \sup \left(\int_Bfd|\nu|:f \text{ is measurable, } |f| \leq 1 \right).
$$ Question: How can I show that $$
|\nu(B)| = \sup \left(\int_Bfd\nu:f \text{ is measurable, } |f| \leq 1 \right).
$$ That is, the equality still holds with $\nu$ instead of $|\nu|$ in the integral?","['measure-theory', 'total-variation', 'real-analysis']"
4814149,Sum of integers =sum of their reciprocals special case,"Problem :- Are there infinitely many integers $x_1, x_2, x_3,..., x_5$ such that $\sum_{i=1}^{5} \frac{1}{x_i}=\sum_{i=1}^{5} x_i$ and sum of no two terms in $x_i$ is $0$ and $x_i$ is never $1$ or $-1$ . and $(x_1, x_2,. .., x_5)=1$ The original problem was posted here Sum of integers=sum of their reciprocals . However that problem after the pattern was countered by some people in comments, seemed to have reached a dead end, however I was still wondering whether there are infinitely many solutions , and possibly generalize to more than 5 terms . I just  tried to make cases on the number of negative terms as in the previous problem . Edit: As for the generalization part using n=6 solution mentioned in the linked post[comment section] note and $n=5$ we can compose other solutions for example $\frac{1}{-40k}+\frac{1}{-3k}+\frac{1}{5k}+\frac{1}{8k}+\frac{1}{30k}+\frac{1}{2}+\frac{1}{-4}+\frac{1}{-9}+\frac{1}{-10}+\frac{1}{-15}+\frac{1}{36}$ would be a valid construction for $n=11$ under certain infinitely many values of $k$ to make sure no two terms sum to 0. and as we paste another $\frac{1}{-40a}+\frac{1}{-3a}+\frac{1}{5a}+\frac{1}{8a}+\frac{1}{30a}$ and so $\frac{1}{-40a}+\frac{1}{-3a}+\frac{1}{5a}+\frac{1}{8a}+\frac{1}{30a}+\frac{1}{-40k}+\frac{1}{-3k}+\frac{1}{5k}+\frac{1}{8k}+\frac{1}{30k}+\frac{1}{2}+\frac{1}{-4}+\frac{1}{-9}+\frac{1}{-10}+\frac{1}{-15}+\frac{1}{36}$ would become valid example for $n=16$ and in general we have construction for $n=5k+1$ we can similarly paste the 6 term solution again and again along with the 5 term solution and get a solution for $n=5a+6b$ by Mc Chicken nugget theorom https://artofproblemsolving.com/wiki/index.php/Chicken_McNugget_Theorem . All $n \geq 20$ can be written in that form so we now have infinite solutions for them [note again we have restrictions on constants we are multiplying with to make sure no two sum to $0$ [gcd is always obeyed as we can have two coprime terms in the sequence always],but even with that we have infinite]. there are some other ways to compose solutions for $n=31$ using only $n=5$ manually without writing code by which we have examples for $n \geq 120$ using same method. This is the method we know $1+\frac{1}{30}+\frac{1}{8}+\frac{1}{5}+\frac{1}{-3}+\frac{1}{-40}=1+30+8+5-3-40=1$ Square both sides without grouping that is for example dont write $a+a=2a$ and keep it as $a$ and $a$ and separetely in the new sequence we have $6^2=36$ terms only two terms that will cancel[sum to 0] will be those in pairs of [observe in the expansion we again have sum of integers=sum of reciprocals] of $8*5$ and $-40*1$ , as we didnt group total 4 terms got removed , and no two other terms sum to 0 , also remove the $1^2$ from both sides , u are left with $36-4-1=31$ terms and gcd is 1 as one as $5^2$ and $8^2$ were in expansion and they are coprime. Hope i was clear coz this part was a bit tough for me to write ask on comments for any quiries. Imma also share a list of solutions that got produced when i coded for $n=5$ [the sum of terms being 0 is not a coincidence but forced to make the search program faster] some solutions are permutations of others. Update:
Have a proof for  n=9 . Take any tuple $(x, y, z)$ sum of no two terms is 0 of integers none is $1$ or $-1$ . And $x+y+z=0$ . Take another such tuple $(a, b, c)$ We show infinite solutions for when the sum is $0$ . hence it suffices to find infinite rational solutions[which are not just created by multipltying one solution with a constant ] as the equation is homogenous . Now consider $(\frac{1}{x}+\frac{1}{y}+\frac{1}{z})(a+b+c)=(x+y+z)(\frac{1}{a}+\frac{1}{b}+\frac{1}{c})=0$ When u expand left side u get some sum of rational numbers  u have exactly $3^2=9$ terms take the lcm we have something like [rational numbers produced on expansion of RHS are reciprocals of LHS] $q(\frac{1}{a1}+.... +\frac{1}{a_9})=(a_1+a_2+.... +a_9)\frac{1}{q}=0$ That implies $\frac{1}{a_1}+... +\frac{1}{a_9}=a_1+a_2+.... +a_9$ We can add further conditions on $(x, y, z)$ and $(a, b, c)$ To ensure no two sum to 0 and gcd=1 and no term is 1 or -1 but those are easy to ensure maintaining infinite solutions . Previously had posted this as an answer,if i wasent clear enough in it
as it got one downvote . Then here is a example to illustrate better take $(x,y,z)=(3,4,-7)$ and $(a,b,c)=(3,5,-8)$ $0=(3+4-7)(\frac{1}{3}+\frac{1}{5}-\frac{1}{8})=1+3/5-3/8+4/3+4/5-4/8-7/3-7/5+7/8$ and $0=(\frac{1}{3}+\frac{1}{4}-\frac{1}{7})(3+5-8)=1+\frac{5}{3}-\frac{8}{3}+\frac{3}{4}+\frac{5}{4}-\frac{8}{4}-\frac{3}{7}-\frac{5}{7}+\frac{8}{7}$ as $1=120/120$ , $3/5=(24*3)/120$ similarly simplify other terms U get $\frac{120+24*3-15*3+4*8*5+4*8*3-40*7-4*15-7*24+7*15}{120}=120(1/(120)+1/(24*3)-1/(15*3)+1/(4*8*5)+1/(4*8*3)-1/(40*7)-1/(4*15)-1/(7*24)+1/(7*15))=0$ Automatically giving solution $[120,24*3,-15*3,4*8*5,4*8*3,-40*7,-4*15,-7*24,7*15]$ U can verify no two sum to 0. More update:- After some work i showed infinite solutions for $n=7$ and infinite soluitions to the orginal problem but rather the condition that $(\sum_{i=1}^{5} x_i)/(\sum_{i=1}^{5} \frac{1}{x_i})$ is a non zero perfect square","['number-theory', 'elementary-number-theory', 'diophantine-equations']"
4814156,Regression coefficient on a triangle using geometry [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 7 months ago . Improve this question I also post this question in CrossValidate . Consider the following problem: Let $X, Y$ be two independent uniform random variable on $(0,1)$ . We
consider the regression model $Y = \beta_1 X + \beta_0$ , given the
restriction that $X + Y > 1$ . Find $\beta_1$ . Let us call $U = X|X + Y > 1$ , $V = Y|X+Y > 1$ . Then we could compute the density of $U$ and $V$ by doing conditional probability, and $\beta_1 = \frac{Cov(U,V)}{Var(U)}$ , $\beta_0$ could be found by plugging in the mean of $U$ and $V$ . The final answer should be $\beta_1 = -\frac{1}{2}$ . My question is: how to compute $\beta_1$ based on geometry? If we draw the graph, we could see that we are doing a right-top triangle within the unit square $[0,1] \times [0,1]$ . We could also know the center of the triangle is $(\frac{2}{3}, \frac{2}{3}) = (E[U], E[V])$ . Is there a way that we could visualize the $\beta_1$ should be $-\frac{1}{2}$ ?","['linear-regression', 'statistics']"
4814265,The unit circle of a field has an injective homomorphism to the group of units.,"Let $K$ be a field with characteristic more than 2, and containing an element $i\in K$ such that $i^2=-1$ . Define the unit circle of $K$ to be the set $U.C. = \{(x,y)\in K^2:x^2+y^2=1\}$ .  Define $\varphi: U.C.\to K^\times$ by $$ \varphi(x,y) = x+iy $$ . Show that $\varphi$ is injective. My work so far: I've already shown that $\varphi$ is a homomorphism.  In order to prove injectivity we let $w,x,y,z\in K$ such that $w^2+x^2=1=y^2+z^2$ , and need to show that $\varphi(w,x) = \varphi(y,z)$ implies that $(w,x)=(y,z)$ .  Of course the assumption is the same as $$ w+ix = y+iz $$ but we can't use the usual manipulation of complex numbers.  We can obtain $$ w-y = i(z-x) $$ which implies $$ w^2-2wy + y^2 = -(z^2-2xz+x^2) $$ which implies $$ 2-2wy = 2xz $$ and then $$ 1 = wy+xz $$ This looks like Bezout's identity and therefore implies a few statements about GCDs.  However, none of them implies the equality $w=y$ as far as I can tell. Here are the things I know about fields, which seem even possibly relevant: Every ideal in $K[x]$ is principal. A commutative ring with identity is a field if and only if it has only two ideals. An injective homomorphism from an integral domain to a field always extends to an injective homomorphism from its ring of fractions to the same field.","['group-homomorphism', 'ring-theory', 'abstract-algebra']"
4814268,Relationship between crystalline cohomology and crystalline representation,"I know some basics about crystalline cohomology and very little about crystalline representation. The two names suggest there should be some natural connections between them, but I was unable to find any in the literature. So is there any significant connection between crystalline cohomology and crystalline representations? For example, do the crystalline cohomology groups of a smooth projective variety give crystalline representations?","['number-theory', 'algebraic-geometry', 'representation-theory']"
4814316,Solving exercise 2.3.5 in Vershynin's HDP book with the best choice of c,"I am starting to work my way through Vershynin's High-Dimensional Probability and have become stuck on Exercise 2.3.5.  The problem is as follows: Let $X_i \sim \text{Bern}(p_i)$ ( $i\in\{1,\dots,N\}$ ) be independent.  Denote $S_N := \sum_i X_i$ and $\mu := ES_N$ .  Then show that there is some absolute constant $c>0$ such that for all $\delta\in (0,1]$ , we have $$P(|S_N-\mu|\geq \delta\mu)\leq 2\exp(-c\mu\delta^2).$$ I have applied Chernoff's inequality to transform the problem into showing the following inequality: $$\left(\frac{e}{1+\delta}\right)^{1+\delta} + \left(\frac{e}{1-\delta}\right)^{1-\delta} \leq 2\exp(1-c\delta^2).$$ Following a process similar to the hint given by the answer to this Math.SE question , I've shown the inequality for some $c<\frac{1}{2}$ .  However, the approach given there requires one to bound each term on the lefthand side by half the righthand side; I think that this loses some efficiency, since one needs to choose one choice of $c$ to bound each term separately even though they are unequal.  Indeed, when I try to bound each term separately I can't use $c=1/2$ , but from plotting the functions I see that $c=1/2$ should work (and it seems that the bound does not hold for $c>1/2$ , so this is the best choice of $c$ ).  Does anyone have a hint (or several) for solving the problem with $c=1/2$ ?","['inequality', 'probability']"
4814345,"if $F(x,y)>0$ is convex and $1/F$ is convex show that up to a rotation $F(x,y) = F(x)$","Let $$F \; : \; \mathbb{R}^2 \to \mathbb{R}$$ be a strictly positive function such that $F, \frac{1}{F}$ are both convex.
Show that there is a function $$g \; : \; \mathbb{R} \to \mathbb{R}$$ and a vector $$v \in \mathbb{R}^2$$ such that $$F(x) = g(v\cdot x) \;\; \text{ for all } x \in \mathbb{R}^2$$ I have found a solution to this exercise but I'm not satisfied because it uses the extra assumption that $F \in C^2$ and $\nabla F$ is never $\underline{0}$ , I would like to find an easier solution that doesn't rely on these extra assumptions. This is my solution : I will assume $F \in C^2$ and $\nabla F$ is always non-zero. First a bit of notation : I use the euclidean metric on $\mathbb{R}^2$ thus I identify matrices with biliniear forms, if $A$ is a ( $2 \times 2$ ) matrix by $A \geq 0$ I mean $$(Ax,x) \geq 0 \;\; \forall x \in \mathbb{R}^2$$ by $A \leq B$ I mean $B - A \geq 0$ , or equivalently $$(Ax,x) \leq (Bx,x) \;\; \forall x \in \mathbb{R}^2$$ I claim that if $A$ is a symmetric matrix and $B$ is any matrix such that $0 \leq A \leq B$ then $\ker(B) \subset \ker(A)$ To show it observe that, since $A$ is symmetric, up to a rotation I can assume it is diagonal,so there are $\lambda,\mu \geq 0$ so that $$
		A=
		\left( {\begin{array}{cc}
				\lambda & 0 \\
				0 & \mu \\
		\end{array} } \right)
		$$ then if $B v = 0$ and $v = (v_1,v_2)$ I find $0 \leq \lambda (v_1)^2 + \mu(v_2)^2 \leq 0$ which clearly implies $\lambda v_1 = \mu v_2 = 0$ so $A v = 0$ which shows the claim Now back to the exercise I assume $F \in C^2$ , thus $1/F \in C^2$ and so convexity implies $\nabla^2 F \geq 0$ , $\nabla^2 1/F \geq 0$ . I calculate $\nabla^2 \frac{1}{F}$ \begin{equation}\nabla^2 \frac{1}{F} = \frac{2}{F^3}\nabla F \otimes \nabla F - \frac{1}{F^2}\nabla^2 F \geq 0\end{equation} from this I easily find \begin{equation} 0 \leq \nabla^2 F \leq \frac{2}{F} (\nabla F \otimes \nabla F) \end{equation} so using the previous claim $\ker(\nabla F \otimes \nabla F) \subset \ker(\nabla^2 F)$ but clearly $\ker(\nabla F) \subset \ker(\nabla F \otimes \nabla F)$ . Now let $$\mathcal{N}(x,y,\underline{v}) = 
\left( {\begin{array}{cc}
		\nabla F(x,y)\cdot \underline{v}  \\
		\underline{v} \cdot \underline{v} - 1 \\
\end{array} } \right) $$ I want to use implicit differentiation theorem to find $v = v(x,y)$ , so I differentiate $\mathcal{N}$ with respect to $v$ $$\nabla_{\underline{v}}{\mathcal{N}} = 
\left( {\begin{array}{cc}
		\nabla F(x,y)  \\
		2\underline{v} \\
\end{array} } \right) $$ by definition if $\mathcal{N}(x,y,\underline{v}) = 0$ then the two vectors are orthogonal and they are both non-zero thus $\nabla_{\underline{v}}{\mathcal{N}}$ is invertible and $$\nabla_{x,y}{\underline{v}} = (\nabla_{\underline{v}}{\mathcal{N}})^{-1}( \nabla_{x,y}{\mathcal{N}})$$ but I have that $$\nabla_{x,y}{\mathcal{N}} = 	\left( {\begin{array}{cc}
		\nabla^2F(x,y) \cdot v  \\
		\underline{0} \\
\end{array} }  \right) = \left( {\begin{array}{cc}
		\underline{0}  \\
		\underline{0} \\
\end{array} }  \right) $$ and here I'm using $\underline{v} \in \ker{\nabla F} \subset \ker{\nabla^2 F}$ thus $\nabla_{x,y}{\underline{v}} = 0$ . Now fix $\underline{w}$ so that it has norm $1$ and $\nabla F(0,0) \cdot \underline{w} = 0$ , Let $U := \{ (x,y) \in \mathbb{R}^2 \; : \; \mathcal{N}(x,y,w) = 0\}$ .\ The set is nonempty since $(0,0) \in U$ , and by what we have shown the set is open, therefore it's $U =\mathbb{R}^2$ , but this shows that $\nabla F(x,y) \cdot w = 0$ for all $(x,y)$ and this concludes the proof.","['convex-analysis', 'solution-verification', 'linear-algebra', 'analysis']"
4814410,Is a vector field irrotational iff its Jacobian is symmetric?,"Let $F: \mathbb R^n \to \mathbb R^n$ be a smooth vector field.  I conjecture that $F$ is irrotational iff its Jacobian is a symmetric matrix. In two and three dimensions, this seems clear from Green and Stokes theorem.  I conjecture this is true for any $n$ dimensions. Is this true? If so, it raises a few additional questions: We normally use curl to describe a vector field.  Can we use curl, or at least its magnitude, to describe matrices? That is, can we use the magnitude of curl to measure how much a matrix rotates, or how non symmetric it is? Can we use the components of curl to tell us the nature of this asymmetry / rotation? Would it be correct to say that for any two distinct dimensions $i, j$ , that the measure of asymmetry $A_{ij} - A_{ji}$ is a measure of how much the matrix rotates a vector in the $i,j$ plane? There are many well known types of matrices with interesting properties (e.g. orthogonal).  If the Jacobian of $F$ is an ""interesting"" matrix, what does it tell us about $F$ ? For example, if $J(F)$ is orthogonal?","['geometry', 'multivariable-calculus', 'calculus', 'linear-algebra', 'vector-analysis']"
4814446,How to evaluate $ \displaystyle \int_0^\infty \frac {\sin x}{1+x^3}dx. $?,"I was wondering if we can use complex contour integration to evaluate the integral $$
\int_0^\infty \frac {\sin x}{1+x^3}dx.
$$ Since the integrand is not even, we cannot extend the integration domain to $\mathbb R$ and use the upper semicircular contour $Re^{it}$ , $0\le t\le \pi$ . We cannot use the keyhole contour either, since the integral of $\frac{e^{iz}}{1+z^3}$ over the lower semicircle $Re^{it}$ , $\pi\le t\le 2\pi$ does not converge to $0$ as $R\to \infty$ . Using Wolframalpha to evaluate the above improper integral, it does not give a closed form answer. Therefore I was wondering if complex integration is not applicable in this case.","['complex-analysis', 'calculus', 'improper-integrals', 'complex-integration']"
4814500,Can you multiply 3 matrices simultaneouly?,"I know that the algorithm for multiplying 2 matrices is defined as: $$(AB)_{ij} = (\text{row }i\text{ of matrix }A) ⋅ (\text{column }j\text{ of matrix }B)$$ And I know that matrix multiplication is associative. So in the case of 3 matrices: $$(A ⋅ B) ⋅ C = A ⋅ (B ⋅ C)$$ Is there an algorithm for matrix multiplication that can multiply 3 matrices simultaneously? For example, could one evaluate the expression $ABC$ without first evaluating either of: $(AB) ⋅ C$ $A ⋅ (BC)$ Additional questions I am in high school, so I am not sure if this is the correct terminology, but I read somewhere about binary operations, where for instance, an operation such as normal multiplication takes 2 elements (such as 2 real numbers) and produces an output, and you can't multiply 3 numbers together simultaneously. Is matrix multiplication a binary operation, where you can't multiply 3 matrices simultaneously? Is $A ⋅ B ⋅ C$ defined as $(A⋅ B)⋅ C$ or $A⋅ (B⋅ C)$ ? Is the omission of the parentheses in $A⋅ B⋅ C$ (matrices) just a form of notation? What is the most precise way to interpret expressions of multiplication or addition (associative operations) with more than 3 variables - where there are no brackets, such as $A⋅B⋅C⋅D$ ?","['matrices', 'binary-operations']"
4814564,What's wrong with this picture? Impossible circles.,"The planar diagram shows points $A,B,C,D$ (they don't have to be the vertices of any particular kind of quadrilateral) and four circles: $\text{C}_{AB}$ with diameter $AB$ , $\text{C}_{BC}$ with diameter $BC$ , $\text{C}_{CD}$ with diameter $CD$ and $\text{C}_{DA}$ with diameter $DA$ . $\text{C}_{AB}$ and $\text{C}_{CD}$ are disjoint (no points in common; neither is inside the other). $\text{C}_{BC}$ and $\text{C}_{DA}$ are disjoint. Is this possible? I don't think it's possible. The diagram actually shows four ellipses. When I draw four circles, I am unable to make the pairs of circles disjoint. But I don't know how to prove that this is impossible. I've been trying proof by contradiction, but contradiction eludes me. Context: I've been trying to crack another question , and my effort led to this question.","['circles', 'geometry']"
4814604,A natural topology on a field,"I can endow any field with a natural topology in the following way. Given a polynomial $f\in K[X]$ , I denote by $\mathcal{O}(f)=\{x\in K\mid\exists y\in K^{\times}\ f(x)=y^2\}$ , i.e. the set of elements $x\in K$ such that $f(x)$ is a non-zero square in $K$ . I then consider the topology generated by the sets $\mathcal{O}(f)$ . This gives a unified description for a priori completely different topologies. If $K$ is algebraically closed, one recovers the Zariski topology. If $K=\mathbb{R}$ , one recovers the Euclidean topology. If $K=\mathbb{Q}_p$ , one recovers the $p$ -adic topology. If $K$ is finite, one recovers the discrete topology. The field $K$ together with this topology is in general not a topological field. What I can prove so far is that this topology is always T1 and finer than the Zariski topology. I should also mention that this gives a way to topologize the affine space $K^n$ by considering polynomials $f\in K[X_1,\dots,X_n]$ . I am wondering if people studied this topology. When is this topology Hausdorff? Do you know other fields where one recovers an interesting topology?","['field-theory', 'general-topology', 'algebraic-geometry', 'topological-rings']"
4814621,Proof of $ran(E(\lambda)) = ker(\lambda-A)^\alpha$,"Let $A: H \to H$ be a compact operator on the complex Hilbert space $H$ . Let $\lambda \neq 0$ be an Eigenvalue of $A$ . Since A is compact, it's Eigenvalues can only accumulate at $0$ , so we can find a smooth curve $\Gamma \subset \mathbb{C}$ enclosing no other Eigenvalue than $\lambda$ . Then the Risz-Projector $E(\lambda)$ (see also https://en.wikipedia.org/wiki/Riesz_projector ) is defined as $$
E(\lambda):= \frac{1}{2\pi i}\int_\Gamma (z-A)^{-1} dz
$$ Question: How to prove $ran(E(\lambda)) = ker(\lambda-A)^\alpha$ , where $\alpha$ is the ascent multiplicity of $\lambda - A$ , i. e. the smallest integer such that $ker(\lambda - A)^\alpha = ker(\lambda - A)^{\alpha + 1}$ . $ker(\lambda-A)^\alpha$ is sometimes called the generalized Eigenspace. Background : This property of Riesz-Projectors is key to the Babuska-Osborn-Theory for approximating non-symmetric Eigenvalue problems. Babuska and Osborn state this property in their paper 'Eigenvalue Problems, 1991' but give no proof (they seem to refer to Dunford and Schwartz but I can't find a proof there either). I found a proof for the special case when $A$ is self-adjoint (in this case $\alpha = 1$ ) in this book https://link.springer.com/book/10.1007/978-1-4612-0741-2 . In the proof of "" $\supset$ "" (self-adj. case) they show that for $f \in ker(\lambda - A)$ we have $E(\lambda)f = f$ . I could generalize this to the non self-adjoint case by looking at Jordan-chains and using that $(\lambda - A)$ and $E(\lambda)$ commute. However, I don't see how to generalize "" $\subset$ "". Here is how the proof in the self-adjoint case works: They show $$
(\lambda - A) E(\lambda) = \frac{1}{2\pi i}\int_\Gamma (\lambda - A)(z-A)^{-1} dz = \frac{1}{2\pi i}\int_\Gamma (\lambda - z)(z-A)^{-1} dz = 0\\
$$ For the last equality the argument is as follows: We have $||(\lambda - A)^{-1}|| \leq d(\lambda, \sigma(A))^{-1}$ (which is true for self-adjoint operators). Therefore $ |(\lambda - z)| ||(z-A)^{-1}||$ is uniformly bounded on $interior(\Gamma) \backslash \{ \lambda \} $ . The equality then follows from Riemann's theorem on removable singularities and Cauchy's theorem. Any references or ideas are greatly appreciated. Thanks!","['spectral-theory', 'compact-operators', 'functional-analysis']"
4814631,"Geometric interpretation of $\frac {\partial^2} {\partial x \partial y} f(x,y)$","Is there any geometric interpretation for the following second partial derivative? $$f_{xy} = \frac {\partial^2 f} {\partial x \partial y}$$ In particular, I'm trying to understand the determinant from second partial derivative test for determining whether a critical point is a minima/maxima/saddle points: $$D(a, b) = f_{xx}(a,b) f_{yy}(a,b) - f_{xy}(a,b)^2$$ I have no trouble understanding $f_{xx}(x,y)$ and $f_{yy}(x,y)$ as the of measure of concavity/convexity of $f$ in the direction of $x$ and $y$ axis. But what does $f_{xy}(x,y)$ mean?","['scalar-fields', 'multivariable-calculus', 'hessian-matrix', 'partial-derivative', 'geometric-interpretation']"
4814651,Topology induced by generalised absolute values,"In a number of texts (including Cassels' ""Local Fields"" and Artin's ""Algebraic Numbers and Algebraic Functions"") I've met the definition of an absolute value on a field that's almost the same as the usual, except that instead of the triangle inequality it satisfies $$|x+y|\leq C\max(|x|,|y|)$$ for some real $C$ (which is then necessarily $\geq1$ ). According to these texts such values induce a topology on the field with the open balls $U_r(x)=\{y:|x-y|<r\}$ as basis sets. Now in order for this family of sets to be a basis for the topology they generate the intersection of any two should contain a third (around any point of the intersection) and this can be reduced to showing $|x|<r\implies\exists s$ such that $|x-y|<s\implies|y|<r$ . How do I show this? I tried playing with stuff like $s=\min(\frac1Cr,|x|)$ , but it's not working. I am aware that any such function is a power of a regular absolute value, so one could just decree the topology of this to be the topology of any so associated absolute value (since powers don't affect the topology), however I'm looking for an elementary proof of this proposition.","['field-theory', 'number-theory', 'general-topology', 'abstract-algebra']"
4814653,Norm is multiplicative?,"Let $L/K$ be a finite extension of number fields . Let $I$ be an ideal in $L$ , we define the norm $N(I)$ of $I$ to be the ideal in $K$ generated by elements of the type $N_{L|K}(a)$ where $a \in I.$ I want to show that $N$ is multiplicative. I am able to show that $N(I)N(J) \subseteq N(IJ)$ because, elements in $N(I)$ looks like $\sum r_i N(a_i)$ where $a_i \in I,$ So if $x=\sum_i r_iN(a_i), a_i \in I$ and $y= \sum_j s_j N(b_j), b_j \in J$ then $$xy = \sum \sum r_i s_j N(a_i b_j) \in N(IJ).$$ So $$N(I)N(J) \subseteq N(IJ).$$ What is not clear to me is the other direction. Since, norm is not additive in general, it is not clear to me how to prove this. Note : Ideals in $L$ means ideals in the ring of integers of $L.$","['number-theory', 'algebraic-number-theory', 'ideals']"
4814712,Show that $\sum_{k=1}^{\infty} \frac{(-1)^{k+1}}{k^2} \sum_{n=1}^k \frac{1}{n}=\frac{5\zeta(3)}{8}$,"$$\sum_{k=1}^{\infty} \dfrac{(-1)^{k+1}}{k^2} \sum_{n=1}^k \dfrac{1}{n}=\frac{5\zeta(3)}{8}$$ I tried to create a proof from some lemmas some are suggested by my Senior friends Lemma 1 $$
{H_n} = \sum\limits_{k = 1}^\infty  {\left( {\frac{1}{k} - \frac{1}{{n + k}}} \right)}   = \sum\limits_{k = 1}^\infty  {\frac{n}{{k \cdot \left( {n + k} \right)}}} $$ Lemma 2 $$
\begin{split}
\sum\limits_{n = 1}^\infty  {\frac{{{x^{2n - 1}}}}{{2n - 1}}}  &= \sum\limits_{n = 1}^\infty  {\frac{{{x^n}}}{n}}  - \sum\limits_{n = 1}^\infty  {\frac{{{x^{2n}}}}{{2n}}}  - \log \left( {1 - x} \right) - \frac{1}{2}\sum\limits_{n = 1}^\infty  {\frac{{{x^{2n}}}}{n}}  \\
&= \frac{1}{2} \cdot \log \left( {1 - {x^2}} \right) - \log \left( {1 - x} \right) \\
&= \frac{1}{2} \cdot \log \frac{{1 + x}}{{1 - x}}
\end{split}
$$ Lemma 3 $$
\begin{split}
\int\limits_0^1 {\frac{{\log }^2 x}{1 - x}dx}   & = \int\limits_0^1 {{{\log }^2}x \cdot \sum\limits_{n = 0}^\infty  {{x^n}}   dx} 
\\
&= \sum\limits_{n = 0}^\infty  {\int\limits_0^1 {{{\log }^2}x \cdot {x^n}  dx} }  \\
&= 2 \cdot \sum\limits_{n = 0}^\infty  {\frac{1}{{{{\left( {n + 1} \right)}^3}}}}  = 2 \cdot \zeta \left( 3 \right) 
\end{split}$$ Lemma 4 $$
\begin{split}
\int\limits_0^1 {\frac{{{{\log }^2}x}}{{1 + x}} dx} & = \int\limits_0^1 {{{\log }^2}x \cdot \sum\limits_{n = 0}^\infty  {{{\left( { - 1} \right)}^n} \cdot {x^n}} dx}  \\
& = \sum\limits_{n = 0}^\infty  {{{\left( { - 1} \right)}^n} \cdot \int\limits_0^1 {{{\log }^2}x \cdot {x^n} dx} }  \\
& = 2 \cdot \sum\limits_{n = 0}^\infty  {\frac{{{{\left( { - 1} \right)}^n} \cdot }}{{{{\left( {n + 1} \right)}^3}}}}  = \frac{3}{2} \cdot \zeta \left( 3 \right)
\end{split}$$","['calculus', 'closed-form', 'summation', 'sequences-and-series']"
4814715,Are all GCD-Sequences Divisor Product sequences too?,"I attended a math camp few years ago, where I studied two types of sequences called GCD-Sequences and Divisor Product sequences. They are defined as follows; GCD-Sequences: Define an integer sequence $A=\left(a_n\right)_{n\geq 1}$ to be a GCD Sequence if $$\gcd(a_m, a_n) = a_{\gcd(m, n)}.$$ Divisor Product Sequences: Define an integer sequence $A=\left(a_n\right)_{n\geq 1}$ to be a Divisor-Product Sequence if there exists an integer sequence $B=\left(b_n\right)_{n\geq 1}$ such that for every index $n$ : $$a_n = \prod_{d \mid n} b_d.$$ Recently, I revisited these sequences, and found many results. I remember my friend from the program told me, that; all GCD-Sequences might be divisor product sequences . I can't find a way to prove this. Here are two examples of GCD-Sequences. As it turns out, they are also divisor products sequences; \begin{align*}
&a_n=n^k\text{ for some }k\in\mathbb{Z}^+\\
&a_n=\alpha^n-\beta^n\text{ for }\alpha,\beta\in\mathbb{Z}^+
\end{align*} This seems like a good research problem. If anyone has an idea or possibly a proof, you can share. Here's a formal problem statement; Let $(a_n)_{n\geq 1}$ be a sequence of positive integers such that for all $m,n\in \mathbb{Z}^+,$ we have $a_{\gcd(m,n)}=\gcd(a_m,a_n),$ then there exists a sequence $(b_n)_{n\geq 1}$ such that for all positive integers $n,$ we have; $$a_n=\prod_{d\mid n}{b_d}.$$","['integer-sequences', 'number-theory', 'sequences-and-series']"
4814717,"If a number $7^n$ has 40 digits, show that this number contains a digit which repeats at least 5 times.","I tried solving this problem using the contradiction method: if I can't write a number with 40 digits using each of the digits from 0 to 9 less than 5 times => one of the digits must repeat at least 5 times. The problem is that you can, 4 times the 10 available digits = 40 digits. Then I thought that one of the digits from 0 to 9 probably does not appear in a number of the form $7^n$ but all of them do appear as seen in the sequence $$7,49,343,2401,16807,117649,823543$$ I don't think the rule of divisibility with 7 or the ending digits of a power of 7 will help me either so I want some ideas. Thank you in advance!",['combinatorics']
4814723,"Show that, given four points, we can always draw two intersecting circles whose diameter endpoints are the four points.","Show that, given four coplanar points, we can always draw two intersecting circles coplanar with the points, such that two of the given points are diameter endpoints of one circle, and the other two given points are diameter endpoints of the other circle. In this question, ""intersecting"" means that the circles share at least one common point. Example: I will post my answer. Alternative solutions are welcome. This question and answer serve to provide ideas that might help answer a harder question about five points and two non -intersecting circles.","['circles', 'geometry', 'discrete-mathematics']"
4814725,Intersection multiplicity of projective curves,"Let $Y=Z(g)$ and $H=Z(f)$ be projective plane curves in $\mathbb{P}^2$ given by irreducible homogeneous polynomials $f,g\in K[T_0,T_1,T_2]$ of degrees deg $(f)=d$ and deg $(g)=1$ . $Y$ is a projective line and we assume $Y\neq H$ .
I have showed that there exists the parametrization of $Y$ , i.e. the isomorphism $\varphi:\mathbb{P}^1\rightarrow Y$ . To show: (i) $p:=f\circ \varphi$ is a non zero polynomial $p\in K[S_0,S_1]$ . Explain why you can view $p$ as a polynomial of the same degree in one variable. (ii) For $P\in Y\cap Z$ and $Q:=\varphi^{-1}(P)$ prove that the intersection multiplicity $i(Y,H,P)$ is the multiplicity of the zero $Q$ of the polynomial $p$ . Then I have to prove Bézout's theorem in this special case using the statements above. I'm very stack and any suggestion would be helpful","['algebraic-geometry', 'projective-space']"
4814740,Dividing $18$ students into $3$ groups of $6$,How many ways are there of dividing $18$ students into $3$ groups of $6$ ? The person who marked my assignment said that it was $$\frac{18!}{(6!)^3}$$ but I thought it was $$\frac{18!}{(6!)^3(3!)}$$ because you could switch all $3$ partitions around and still have the same way of dividing them.,['combinatorics']
4814818,"Prove that $\{ f \in \mathbb{R}^{[0,1]} : \sup_{t \in [0,1]} f(t) < 1 \}$ is not measurable?","Let $\mathbb{R}^{[0,1]}$ be the set of all functions $f : [0,1] \to \mathbb{R}$ . The infinite dimensisonal product $\sigma$ -algebra $\mathcal{T}([0,1], \mathbb{R})$ is generated by the cylindrical sets: $$
\{f \in \mathbb{R}^{[0,1]} : f(t_1) \in I_1, \ldots, f(t_n) \in I_n\}
$$ with $I_i$ being subintervals of $\mathbb{R}$ . How may I go about proving that the following set is not measurable with respect to $\mathcal{T}([0,1], \mathbb{R})$ : $$
\{f \in \mathbb{R}^{[0,1]} : \sup_{t \in [0,1]} f(t) < 1\}.
$$ This is an exercise from the textbook ""Diffusion Processes and Stochastic Calculus"" by Fabrice Baudoin.","['stochastic-processes', 'measure-theory']"
4814829,Confusion about definition Petersson product,"I'm taking a course on modular forms, but my background in analysis is not that strong (I have taken complex analysis and measure theory before however). Therefore I'm a bit confused about the definition of the Petersson inner product. Let $F$ be the usual fundamental domain for the SL $_2(\mathbb Z)$ -action on the upper-half plane, then for cusp forms $f, g$ of weight $k$ we defined (with $z = x + iy$ ) $$
\langle f, g \rangle = \int_F f(z) \overline{g(z)} y^k \frac{dx dy}{y^2}.
$$ One of the things I am confused by is putting the factor $1/y^2$ seperately. Why is this? If I instead write $\int_F f(z) \overline{g(z)} y^{k-2} dx dy,$ does this mean something else, or is this not a well-defined expression? We also spoke about the ""hyperbolic form"", which as I understand it is the measure $\nu$ defined by $$
\nu(S) = \int_S \frac{1}{y^2} dx dy.
$$ So, maybe what is meant is that we are integrating with respect to this measure, so $\langle f, g \rangle = \int_F f(z) \overline{g(z)} y^k d\nu(z)$ . Is this something different from just integrating with respect to the Lebesgue measure and adding a factor $y^{-2}$ ? Thanks in advance for any help and explainations.","['integration', 'measure-theory', 'number-theory', 'analytic-number-theory', 'modular-forms']"
4814844,Are subgroup enumeration algorithms probabilistic?,"Let $G$ be a finite group, given as either a permutation group as a finite set or a subgroup of a matrix group over a finite field. There are a number of impressively implemented algorithms for finding conjugacy classes of subgroups of $G$ , some are discussed in papers mentioned in this answer: https://math.stackexchange.com/a/2775758/1038520 My question is: Are the best algorithms for subgroup enumeration inherently probabilistic? Looking at Cannon-Cox-Holt, there is at least one point where one step in the algorithm (discussed in section 3) calls for making random choices of elements of conjugacy classes, but I have not tried to precisely follow through to see either how this is done or whether it can be done deterministically (let alone other steps of the process). The background motivation for my question is as follows. I use some of these enumeration algorithms in $\texttt{magma}$ . However, it can (and does) happen that if you run the same code twice on the same group $G$ , the output may differ. That is, the precise ordering of the subgroups (up to conjugation) may differ, and the output may even permute two (non-conjugate) subgroups $H$ and $H'$ of $G$ which are isomorphic. (For example, $G=S_6$ and $H \simeq H' \simeq S_5$ ). This is a little frustrating as a user (for writing code that can be replicated), but I would feel much better if I knew there was a fundamentally good reason it had to be this way. So this question is really just about making me feel better. Note that in practice in $\texttt{magma}$ I can always $\texttt{SetSeed(1);}$ to avoid this particular issue.","['group-theory', 'finite-groups']"
4814846,Extension of a measure from $\mathbb{R}$ to $\bar{\mathbb{R}}$,"Let $\mathbb{R}$ be equipped with the standard Borel $\sigma$ -algebra $\mathbb{B}(\mathbb{R})$ , that is the $\sigma$ -algebra generated by the open sets of $\mathbb{R}$ . Suppose $\mu$ is a measure on $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ . I want to understand how to extend $\mu$ to the set $\bar{\mathbb{R}} = \mathbb{R}\cup \{+\infty\}$ . By $\bar{\mathbb{R}} = \mathbb{R}\cup \{+\infty\}$ I mean the one-point compactification of $\mathbb{R}$ , which is a compact topological space. It is not clear to me how to make such extension. Some of my thoughts: first, I need to equip $\bar{\mathbb{R}}$ with a suitable $\sigma$ -algebra, say, $\mathcal{F}$ . My guess would be to consider the $\sigma$ -algebra $\mathcal{F} = \mathbb{B}(\bar{\mathbb{R}})$ generated by the open sets of $\bar{\mathbb{R}}$ , that is, the $\sigma$ -algebra generated by the set: $$\tau_{\bar{\mathbb{R}}} = \tau_{\mathbb{R}} \cup \{U \cup \{+\infty\}: \text{$U \in \tau_{\mathbb{R}}$ and $U^{c} = \mathbb{R}\setminus U$ is compact}\}.$$ However, if this is the correct $\sigma$ -algebra to equip $\bar{\mathbb{R}}$ , how to exten $\mu$ to $\bar{\mathbb{R}}$ ? What I would like to do is, roughly speaking, set the ""measure of infinity to zero"". Something like: $\mu(E \cup \{+\infty\}) = \mu(E)$ , for $E \in \mathbb{B}(\mathbb{R})$ . However, it is not clear to me if all the sets $E$ of the $\sigma$ -algebra $\mathbb{B}(\bar{\mathbb{R}})$ either elements of $\mathbb{B}(\mathbb{R})$ or elements of the form $E\cup \{+\infty\}$ , so I can define the measure $\mu$ as I want. Any help is really apreciated!","['general-topology', 'functional-analysis', 'analysis', 'measure-theory']"
4814852,How to show that $\sum_{k} (-1)^k{{a+b}\choose{a+k}}{{b+c}\choose{b+k}}{{c+a}\choose{c+k}} = \frac{(a+b+c)!}{a!b!c!}$,How to show that $$\sum_{k} (-1)^k{{a+b}\choose{a+k}}{{b+c}\choose{b+k}}{{c+a}\choose{c+k}} = \frac{(a+b+c)!}{a!b!c!}$$,"['summation', 'factorial', 'binomial-coefficients', 'combinatorics', 'multinomial-coefficients']"
4814920,What is the change in angle of of a symmetric matrix when summed over a plane?,"A symmetric matrix has orthogonal eigenvectors with real eigenvalues, and hence can be thought of as scaling along a particular orthogonal set of axes. Of course, not all vectors are (usually) eigenvectors, and therefore many individual vectors will have their direction changed under a symmetric matrix. It seems to me, however, that these direction changes will somehow ""cancel out"" in the sense that there is no net rotation by a symmetric matrix.  I don't know how to state this more precisely, other than to observe that $A_{ij} - A_{ji}$ is a measure of the rotation in the $i,j$ plane (see here ). That is, if $A$ is a symmetric matrix, for any plane $P$ , the net direction change of $Av$ over all vectors $v \in P$ is zero.  Again, I'm not sure how state this more precisely, but perhaps it could be formulated as an integral. Is my intuition correct? And how can it be stated more precisely?","['conjectures', 'matrices', 'multivariable-calculus', 'linear-algebra', 'intuition']"
4815008,"If $a+b+c+abc=4,$ prove $\frac{1}{\sqrt{a^2+4bc}}+\frac{1}{\sqrt{b^2+4ac}}+\frac{1}{\sqrt{c^2+4ba}}\ge \frac{5}{4}.$","Let $a,b,c\ge 0: ab+bc+ca>0$ and $a+b+c+abc=4.$ Prove that $$\color{black}{\frac{1}{\sqrt{a^2+4bc}}+\frac{1}{\sqrt{b^2+4ca}}+\frac{1}{\sqrt{c^2+4ba}}\ge \frac{5}{4}. }$$ Remark. My teacher asasigned this problem to our class as a homework. I post it here to look for help and share some thoughts. Any ideas and comments are welcome. Please feel free to discuss about this inequality. Here is my attempts. Since equality holds at $a=b=2;c=0$ we can't use normal approach. For example, by using Cauchy-Schwarz inequality $$\color{black}{\frac{1}{\sqrt{a^2+4bc}}+\frac{1}{\sqrt{b^2+4ac}}+\frac{1}{\sqrt{c^2+4ba}}\ge \frac{9}{\sqrt{a^2+4bc}+\sqrt{b^2+4ba}+\sqrt{c^2+4ba}}. }$$ But $$\frac{9}{\sqrt{a^2+4bc}+\sqrt{b^2+4ba}+\sqrt{c^2+4ba}}- \frac{5}{4}=-\frac{1}{8}$$ is already wrong when $a=b=2;c=0.$ I'll post more ideas which are not good enough. Now, I hope you consider carefully before voting to close my topic. I try to use Jichen lemma which seems not good enough. Indeed, we can rewrite the original inequality as $$\color{black}{\frac{1}{\sqrt{a^2+4bc}}+\frac{1}{\sqrt{b^2+4ac}}+\frac{1}{\sqrt{c^2+4ba}}\ge \frac{1}{\sqrt{16}}+\frac{1}{\sqrt{4}}+\frac{1}{\sqrt{4}}. }$$ I checked that $$\frac{1}{a^2+4bc}+\frac{1}{b^2+4ca}+\frac{1}{c^2+4ab}\ge \frac{9}{16}$$ is not true when $a=b=0.5;c=2.4$ . Also, in comment section, Michael Rozenberg said that the Holder using with $(3a+b+c)^3$ is not good. I hope you can optimize your idea soon. I'll update more approach when I found it. Thanks for your interest.","['contest-math', 'algebra-precalculus', 'inequality']"
4815054,Independence is preserved by joint weak convergence,"Suppose a sequence of random vectors $(X_n,Y_n)$ converges jointly to some $(X,Y)$ in the weak topology. Question: If $X_n$ and $Y_n$ are independent for all $n$ , are also $X$ and $Y$ independent? This question has been answered in 1 under some hypothesis on the state space. However, since weak convergence only concerns the laws, and since independence can be inferred from the joint law, I feel like it should hold without any hypothesis on the state space. The following seems to establish the answer if the random variables take values in separable metric spaces with their Borel $\sigma$ -algebra, which we denote $(\mathcal{S}_1,\mathcal{B}_1)$ and $(\mathcal{S}_2,\mathcal{B}_2)$ .
We remark that the Borel $\sigma$ -algebra of $\mathcal{S}_1 \times \mathcal{S}_2$ is generated by the Cartesian product of Borel sets, by separability. Let $\mu_n$ be the law of $(X_n,Y_n)$ and let $\mu_n^1$ , $\mu_n^2$ be the marginals. Denote their weak limits by $\mu$ and $\mu^1$ , $\mu^2$ .
Consider $$
\mathcal{C} = \{ A \times B \colon A \in \mathcal{B}_1 , B \in \mathcal{B}_2, \mu^1(\partial A) = 0 = \mu^2(\partial B) \}.
$$ Note that $$
\mu(\partial (A \times B)) \leq \mu(\partial A \times B) + \mu(A \times \partial B) \leq \mu^1(\partial A) + \mu^2(\partial B)  = 0
$$ for $A \times B \in \mathcal{C}$ .
Thus, sets in $\mathcal{C}$ are sets of continuity for the measures $\mu^1$ , $\mu^2$ and $\mu$ , so by the Portmanteau theorem \begin{equation}
\begin{split}
\mathbb{P}( X \in A, Y \in B )
&= \mathbb{P}( (X,Y) \in A \times B )
= \lim_n \mathbb{P}( (X_n,Y_n) \in A \times B )
\\
&= \lim_n \mathbb{P}( X_n \in A ) \mathbb{P}( Y_n \in B )
= \mathbb{P}( X \in A ) \mathbb{P}( Y \in B ).
\end{split}
\end{equation} Thus, the probability measure $\mu$ and $\mu_1 \otimes \mu_2$ coincide on $\mathcal{C}$ and, hence, on the $\sigma$ -algebra generated by $\mathcal{C}$ since $\mathcal{C}$ is closed under finite intersections. Finally, it was shown in 2 that the $\sigma$ -algebra generated by all sets of continuity is the entire Borel $\sigma$ -algebra for separable metric spaces. Is this proof correct? Can it be extended to more general settings or is there another proof that covers more general settings? Cheers","['probability-theory', 'probability']"
4815056,IF $f(x)= \frac{1}{\mu} e^{-\frac{x}{\mu}} $ Write the likelihood function to find those observations.,"Suppose a measurement process is applied to something whose actual value $\mu$ is given by the probability density function $f(x)= \frac{1}{\mu} e^{-\frac{x}{\mu}} $ Suppose we have observations $x_1, x_2 \ldots, x_n$ were taken with precision $\Delta$ . This means that each measurement can have a value of $x \pm \Delta$ . Write the likelihood function to find those observations.
Find the value that maximizes the likelihood function I do $L(\mu)= \frac{1}{\mu} e^{-\frac{x_1}{\mu}} \cdots \frac{1}{\mu} e^{-\frac{x_n}{\mu}}=\frac{1}{\mu^n}e^{\frac{-x_1-x_2- \ldots -x_n}{\mu}}=\frac{1}{\mu^n}e^{\frac{-n\bar{x}}{\mu}}$ but i dont know if im right or  i have to consider the $ \pm \Delta$ and for the second i do $\frac{\partial ln(L(\mu))}{\partial \mu}=\frac{n(\bar{x}-\mu)}{\mu^2}=0$ then $\mu=\bar{x}$",['statistics']
4815078,Verify (or critique) this informal proof of Green's theorem,"In order to better understand Green's Theorem, I developed this informal proof, which I request verification and critique of (both the proof and its writing).  Of course, any textbook has a proof: my goal here is to improve my intuition by developing a proof from a simple argument I could visualize, and then passing to the limit. Consider a linear function $\mathbf F: \mathbb R^2 \to \mathbb R^2$ .   Write $\mathbf{F}(x,y) = P(x,y) \mathbf i + Q(x,y) \mathbf j$ , and let $p = P(0,0)$ and $q = Q(0,0)$ . Then, for any rectangle $C$ parallel to the $x$ and $y$ axes with width $w$ and height $h$ , $$ \frac 1 {hw} \oint_C \mathbf F \cdot d\mathbf l$$ is the circulation of $\mathbf F$ around $C$ divided by the area of $C$ . Define the 2D curl of $\bf F$ at $(x,y)$ as $$\lim_{h,w \to 0} \frac 1 {hw} \oint_C \mathbf F \cdot d\mathbf l$$ for any rectangle $C$ parallel to the $x$ and $y$ axes with width $w$ and height $h$ , provided that this quantity exists and is identical for any sequence of such rectangles each containing $(x,y)$ . We claim that the 2D curl of $\mathbf F$ is $\frac {\partial Q}{\partial x} - \frac {\partial P}{\partial y}$ .  For consider any rectangle $C$ with corners $(-u, -v), (u, -v), (u,v), (-u,v)$ .   Then, $hw = 4uv$ and, since $\mathbf F$ is linear, \begin{align}
\oint_C \mathbf F \cdot d \mathbf l &= 2u\left(p - \frac {\partial P}{\partial y}v\right) + 2v\left(q + \frac {\partial Q}{\partial x}u\right) - 2u\left(p + \frac {\partial P}{\partial y}v\right) - 2v\left(q - \frac {\partial Q}{\partial u}v\right) \\
&= 4uv\left(\frac {\partial Q}{\partial x} - \frac {\partial P}{\partial y}\right).
\end{align} (This is the crux of the argument.  The rest is simply set up or justification of using the linear approximation to find the limit.) If we relax the assumption that $\mathbf F$ is linear, but still assume it to be smooth then over a sufficiently small rectangle, the linear approximation holds to arbitrary accuracy, and the limit still holds.  So the 2D curl of $\mathbf F$ at $(x,y)$ is $\frac {\partial Q}{\partial x}(x,y) - \frac {\partial P}{\partial y}(x,y)$ . Now consider an arbitrary smooth region $R$ .  It can be shown via a simple geometric argument that the circulation around $R$ is equal to the sum of the circulations around any decomposition of $R$ .  Then for any grain size $G > 0$ , we can decompose $R$ into rectangles parallel to $x$ and $y$ axes of height and width $G$ , plus a peripheral region.  As $G \to 0$ , the area of this periphery shrinks faster than $G$ , and since $F$ is assumed smooth, the circulation of the periphery goes to zero as well.  Thus, as $G \to 0$ ,  the sum of the circulation around all of the rectangles goes to the circulation around the entire region.  But the sum of the circulation around all of the rectangles is simply $\iint_R \frac {\partial Q}{\partial x}(x,y) - \frac {\partial P}{\partial y}(x,y) \, dx \, dy$ , giving as desired $$\oint_{\partial R} \mathbf F \cdot d\mathbf l = \iint_R \frac {\partial Q}{\partial x}(x,y) - \frac {\partial P}{\partial y}(x,y) \, dx \, dy.$$","['intuition', 'multivariable-calculus', 'solution-verification', 'vector-analysis']"
4815088,A combinatorial model for multi-sexual reproduction,"I was thinking about the following question: why do most creatures on earth reproduce asexually or bisexually, but not trisexually? Looking on the internet, I read an interesting perspective https://www.zhihu.com/question/303528094 that attempts to answer this question via the following mathematical model, which I call the reproduction model . A species has $m$ sexes, and $n$ different types of sexual chromosome, which we call $\{1,2,\cdots, n\}$ . Each individual of the species has a genotype of $m$ sexual chromosomes, which can be described as an $m$ -element multiset with each element in $\{1,2,\cdots, n\}$ . There are disjoint families $F_1, F_2, \cdots, F_m$ of genotypes, such that an individual exhibit sex $i$ iff their sexual chromosome lies in family $F_i$ . There is a distribution $\mu$ on $F_1 \sqcup \cdots \sqcup F_m$ that describes the distribution of each possible genotype across the entire species. We require equal number of individual of each sex : we must have $\mu(F_1) = \mu(F_2) = \cdots = \mu(F_m) = 1/m$ . The main point of the argument is that the distribution $\mu$ must be stable . Specifically, consider the following reproduction process: for each $i$ , we sample a random individual from sex $i$ according to $\mu$ . We then form an offspring by selecting a uniformly random chromosome from each individual. Then the genotype of this offspring must also be distributed according to $\mu$ . Let me give two stable examples. Asexual reproduction: $m = n = 1$ , and $F_1 = \{(1)\}$ . This is clearly stable. Bisexual reproduction: $m = 2, n = 2$ , $F_1 = \{(1, 1)\}$ , $F_2 = \{(1, 2)\}$ , and $\mu$ is uniform. This is also stable, since during reproduction there is an equal chance that an offspring of type $(1,1)$ or $(1,2)$ are born. The author of this models argue that trisexual reproduction is not stable, by considering the following model: $m = 3, n = 2$ , $F_1 = \{(1,1,1)\}, F_2 = \{(1,1,2)\}, F_3 = \{(1,2,2)\}$ , $\mu$ is uniform. Then the probability that the offspring is of sex $1,2,3$ is $2/9,5/9,2/9$ respectively. For example, the offspring is of sex $1$ only if all three parents donate type $1$ chromosome, which happens w.p. $1 \cdot 2/3 \cdot 1/3 = 2/9$ . So this model is unstable. However, the author said that they cannot rule out models with more than $2$ chromosome types i.e. $n \geq 3$ . So my question is Does there exist a stable reproduction model with more than $2$ sexes?","['mathematical-biology', 'probability-distributions', 'combinatorics']"
4815092,"Why did the author write ""Why?""? Any deep reason? (""Calculus Fourth Edition"" by Michael Spivak)","THEOREM 6 If $f$ is integrable on $[a,b]$ , then for any number $c$ , the function $cf$ is integrable on $[a,b]$ and $$\int_a^b cf=c\cdot\int_a^b f.$$ PROOF The proof (which is much easier than that of Theorem 5) is left to you. It is a good idea to treat separately the cases $c\geq 0$ and $c\leq 0$ . Why? I wonder why the author Michael Spivak wrote ""Why?"". Is there any deep reason? My Proof : I think it is very natural to treat separately the cases $c=0$ and $c>0$ and $c<0$ because it is obvious that $\int_a^b cf=0=c\cdot\int_a^b f$ if $c=0$ and $L(cf,P)=cL(f,P)$ and $U(cf,P)=cU(f,P)$ holds if $c>0$ and $L(cf,P)=cU(f,P)$ and $U(cf,P)=cL(f,P)$ holds if $c<0$ .","['riemann-integration', 'calculus', 'soft-question', 'definite-integrals']"
4815107,"Is there any way to solve for $k$, given $\beta \sin (k-k N)-\sin (k N+k)=0$?","Consider $$\beta \sin (k-k N)-\sin (k N+k)=0$$ Are there any ways to find $k$ ’s that satisfy this equation given $\beta \in \mathbb{R}$ and $N\in \mathbb{Z}^+$ . My attempt was to write it as imaginary part of exponent as $\beta \Im(e^{i(k-kN)})=\Im e^{i(kN+k+2\pi)}$ and find the $k$ ’s but I am not sure how to handle the imaginary part carefully. Since $\beta$ is real, I thought putting it inside the $\Im$ and solving for the $k$ ’s that satisfy the equation without $\Im$ would solve it. But it turns out that’s not the case.","['trigonometry', 'problem-solving']"
4815114,Converse of existence of minimizers.,"Given $(V, \|\cdot\|)$ a real normed linear space, suppose it has the property that given any closed convex set $K$ , there exists a $u_0 \in K$ such that $\|u_0\| \leq \|u\|$ for any $u \in K$ . Does it imply the space is complete? What if we have a real inner product space instead? Does it imply our space is actually a Hilbert Space? The proof in establishing the existence of the minimizers in Hilbert space uses completeness at a crucial step but what I would like to know if that is actually necessary in general. Edit .
I think the following argument can show that if $(V,\langle \cdot , \cdot \rangle)$ is an inner product space, then existence of these minimizers implies that the space is complete: Given any closed subspace $M \subset V$ , We can still define the orthogonal projection operator $P: V \rightarrow M$ such that $P(x)$ is the closest point to $x$ in that subspace. This will tell us that the decomposition of $V$ into $M \bigoplus M^{\perp}$ still goes through, and thus Riesz Representation Theorem still holds for any such space. Thus as $V^* \cong V$ , the space is complete. Does there exist anything for general Banach Spaces?
(Perhaps it is necessary to add the existence of a unique minimizer)","['functional-analysis', 'real-analysis']"
4815134,Evaluating $\csc\left(\frac{\pi}{18}\right) + \csc\left(\frac{5\pi}{18}\right) - \csc\left(\frac{7\pi}{18}\right)$,"I need to evaluate $$\csc\left(\frac{\pi}{18}\right) + \csc\left(\frac{5\pi}{18}\right) - \csc\left(\frac{7\pi}{18}\right)$$ My work : Taking $t = \frac{\pi}{18}$ , the expression becomes: $$\frac{2\cos 6t-\cos 12t + \cos 2u - \cos 4u - \cos 8u}{2\sin u\cdot \sin 5u\cdot \sin 7u}$$ According to WolframAlpha, this evaluates to $6$ . But I am having trouble showing the same. Then I tried complex exponentials: Taking $u=e^{\frac{i\pi}{18}}$ , the expression becomes: $$2i\cdot \left(\frac{u}{u^2-1} + \frac{u^5}{u^{10}-1} + \frac{u^7}{1-u^{14}}\right)$$ but that too seems to be in vain. Any help will be appreciated. I think the first approach might work out. If you write an answer, I would appreciate if you could provide a general approach to deal with such problems. Thanks!","['algebra-precalculus', 'trigonometry']"
4815194,Can the formation of Kähler differentials be seen as a functor into the category of modules (without specifying the ring of scalars)?,"In an Algebraic Geometry course, I've seen the definition of the $A$ -module of Kähler differentials $\Omega_A^1$ given a $k$ -algebra $A$ ( $k$ is a field).
Then if $X$ is a variety, we defined the sheaf of 1-forms $\Omega_X^1$ on $X$ as the sheafification of the presheaf $\Omega^{1,p}_X$ that maps an open set $U \subseteq X$ to the $\mathcal{O}_X(X)$ -module $\Omega^1_{\mathcal{O}_X(U)}$ and that maps an inclusion $V \subseteq U$ to the map $\Omega^1_{\mathcal{O}_X(U)} \to \Omega^1_{\mathcal{O}_X(V)}$ induced by the $k$ -algebra map that is restriction from $\mathcal{O}_X(U)$ to $\mathcal{O}_X(V)$ .
This prehseaf seems to me like a composition of the two functors $\mathcal{O}_X$ and $\Omega^1$ , but in order to show this I need to precisely define $\Omega^1$ as a functor. We have that $\Omega^1$ takes a $k$ -algebra $A$ and sends it to an $A$ -module $\Omega^1_A$ .
Since the ring of scalars over which this is a module depends on the $k$ -algebra itself, we can't define $\Omega^1$ as a functor $k\text{-alg} \to \text{R-Mod}$ for a fixed ring $R$ .
Instead it seems it goes into a general category of modules, without fixing the ring of scalars. (Update from the future: I later realised that we can just say that the codomain is the category of $k$ -modules, i.e. $k$ -vector spaces, but I'm still interested in the question below.) Can we see $\Omega^1$ as a functor from $k\text{-alg} \to \text{Mod}$ where $\text{Mod}$ is the category described below? I made my own candidate definition of $\text{Mod}$ which turned out to be the same as the one mentioned here . Define $\mathrm{Mod}$ to be a category whose objects are modules over any ring, i.e. tuples of the form $(M, A, \cdot)$ where $M$ is an abelian group (the operation is implicit), $A$ is a ring, and $\cdot \colon A \times M \to M $ is a scalar multiplication satisfying the axioms of a module.
The morphisms of $\mathrm{Mod}$ from $(M, A, \cdot)$ to $(N, B, \star)$ consist of pairs $(\phi, \sigma)$ where $\sigma\colon A \to B$ is a ring homomorphism and $\phi \colon M \to N$ is an $A$ -module homomorphism if we view $N$ as an $A$ -module $(N, A, \cdot_N)$ by setting $a \cdot_N n := \sigma(a) \star n$ for all $a \in A$ and $n \in N$ .
Composition of morphisms are componentwise compositions on such pairs.","['commutative-algebra', 'category-theory', 'algebraic-geometry', 'solution-verification', 'differential-algebra']"
4815199,"If $ A $ and $ A^T $ commute, do they share the same eigenvectors when they are not diagonalizable?","I saw this on Strong's book Introduction to Linear Algebra , but it didn't prove it: If $ A $ and $ A^T $ commute, then they share the same eigenvectors. And now I am wondering whether it is still true even if they may not be diagonalizable. There are many similar questions like "" $A$ and $B$ are both diagonalizable and commute if and only if they share the same eigenvectors"", but I am still wondering whether it is still true when $B=A^T$ and $A$ is not diagonalizable.","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'transpose', 'diagonalization']"
4815204,Why write codomain instead of image when defining a function.,"$X \xrightarrow{\quad f \quad } Y $ Given some function like the one above, why must the function have as the object on the left the domain which it must cover but have as the right hand object the codomain which $f$ need not be onto? I have looked online and don't understand why we don't restrict $Y$ to be the image of which $f$ is onto. I would assume that much like the distinction between partial functions and relations and functions, there is some edifice of theorems and axioms that may fall apart if we don't allow $Y$ to be an overset of the image of $f$ . However, I would like some concrete motivating examples of why we have chosen this as our criteria and or notation. Thank you in advance for your help, I really appreciate this!","['elementary-set-theory', 'functions', 'set-theory']"
4815213,Algebraic manipulation of trigonometric Taylor series,"There are a number of standard identities that are simple to understand for trigonometric functions (like $\sin(x+2π) = \sin(x)$ or $\sin^2(x)+\cos^2(x) = 1$ ), but when these same identities are stated in terms of the function's Taylor expansion they are anything but obvious. I am wondering how you could prove the above (or other) identities true if you were only working with the Taylor series expansions algebraically. That is, are there methods for proving such identities of the functions ? $$\sin x=x - \frac{x^3}{3!} + \frac{x^5}{5!}  ...$$ $$\cos x =1 - \frac{x^2}{2!} + \frac{x^4}{4!} ...$$ without relying on their equivalence to cos and sin. While any identity proofs are appreciated I am primarily interested in those relating to pi. Thanks in advance for any help.","['calculus', 'trigonometry', 'sequences-and-series']"
4815216,"A question about prime numbers, totient function $ \phi(n) $ and sum of divisors function $ \sigma(n) $","I noticed something interesting with  the totient function $ \phi(n) $ and sum of divisors function $ \sigma(n) $ when $n > 1$ . It seems than : $ \sigma(4n^2-1) \equiv 0  \pmod{\phi(2n^2)}$ only if $ 2n - 1 $ is a prime number. for example : $ \sigma(4 \cdot 6^2-1) \equiv 0 \pmod{\phi(2 \cdot 6^2)} $ and $ 2 \cdot 6 - 1 = 11$ and $11$ is a prime number. $ \sigma(4 \cdot 7^2-1) \equiv 0 \pmod{\phi(2 \cdot 7^2)} $ and $ 2 \cdot 7 - 1 = 13$ and $13$ is a prime number. I found this sequences of primes : $``3,5,11,13,19,29,31,53,67,83,103,113,131,139,193,233,251,271,313,383,389 ...""$ I've checked until $n = 1000000$ and I didn't find any counterexamples. This sequence is not on OEIS. I would like to know why some primes are here and some primes are not here. This is only an coincidence or not ? And if not, is there a way to prove it ?","['number-theory', 'divisor-sum', 'totient-function', 'prime-numbers']"
4815263,Finding determinant and rank of matrix $A$,"Finding rank of this matrix : $$A_{n\times n}=
\begin{bmatrix}
a+1&a&\cdots&a\\
a&a+1&\cdots&a\\
\vdots&\vdots&\ddots&\vdots\\
a&a&\cdots&a+1
\end{bmatrix}
$$ $(a\geq 2, a\in \mathbb{N})$ I'm trying to prove $det(A) \ne 0$ so that $rank(A)=n$ but I don't know how to prove it quickly. Can anyone help me ?","['matrices', 'matrix-rank', 'linear-algebra']"
4815265,Girsanov-type Theorem that alters the variance of a Wiener process,"Consider a general probability space $(\Omega, \mathcal{F}, \mathbb{S})$ , on which two or more other probability measures, $\mathbb{P}_1$ , $\mathbb{P}_2$ ,..., $\mathbb{P}_j$ ,..., $\mathbb{P}_n$ are defined that are absolutely continuous with respect to one another. Consider a normally distributed random variable $X\sim N(0, \sigma)$ with its density function denoted $f_{X}$ . Consider a probability measure $\mathbb{P_1}$ defined by the cumulative density function (CDF) of $X$ : \begin{equation}
\label{eq1}
\mathbb{P}_1(A):=\int_{-\infty}^{h=a}\frac{1}{\sigma \sqrt{ 2\pi}}e^{\frac{-(h)^2}{2\sigma^2}}dh
\tag{1}
\end{equation} (to be clear, $X$ is defined on Borel-measuruable sets on $\mathbb{R}$ , above $a \in \mathbb{R}$ and $A$ is defined as the event: $\{A \in \mathcal{F} : X \leq a\}$ ). Next consider the following function of $X$ : \begin{equation}
\label{eq2}
g(X):=\frac{1}{k}e^{\frac{(k^2-1)X^2}{2k^2\sigma^2}}
\tag{2}
\end{equation} Using the ""law of the unconscious statistician"", we have that: \begin{equation}
\label{eq3}
\mathbb{E}^{\mathbb{P_1}}\left[g(X)\right]=\int_{-\infty}^{\infty}g(h)f_{X}(h)dh=\int_{-\infty}^{\infty}\frac{1}{k\sigma\sqrt{ 2\pi}}e^{\frac{-(h)^2}{2\sigma^2 k^2}}dh
\tag{3}
\end{equation} Since in the last expression in \ref{eq3} we recognize a PDF of a normally distributed random variable with mean zero and variance $\sigma^2k^2$ , we have that $\mathbb{E}^{\mathbb{P_1}}\left[g(X)\right]=1$ . Furthermore, restricting $k>0$ results in $g(X)>0$ , and under this restriction, $g(X)$ is a valid Radon-Nikodym derivative. We can define a new measure $\mathbb{P}_2$ as follows (below $\mathbb{I}_{\{.\}}$ is an indicator function): \begin{equation}
\label{eq4}
\mathbb{P}_2(A):=\mathbb{E}^{\mathbb{P}_1}\left[g(X)\mathbb{I}_{\{A\}}\right]
\tag{4}
\end{equation} We can say that under the measure $\mathbb{P}_2$ : $X^{\mathbb{P}_2}\sim N(0, k^2\sigma^2)$ . Consider now a different probability space $(\Omega, \mathcal{F_t}, \mathbb{S})$ and assume that $\mathbb{S}$ is a probability measure induced by the standard Wiener process $W_t$ . Define $\mathbb{P}_1$ as: \begin{equation}
\label{eq5}
\mathbb{P_1}(A):=\mathbb{P_1}(W_t\leq a: a \in\mathbb{R})=\int_{-\infty}^{h=a}\frac{1}{\sqrt{ 2\pi t}}e^{\frac{-(h)^2}{2t}}dh=\int_{-\infty}^{h=a}f_{W_t}(h)dh
\tag{5}
\end{equation} Consider the following function of $W_t$ : \begin{equation}
\label{eq6}
g(W_t):=\frac{1}{k}\exp{\left(\frac{W_t^2\left(k^2-1\right)}{2tk^2}\right)}
\tag{6}
\end{equation} Above, $k>0$ is some constant. Repeating the same argument, we can conclude that $g(W_t)$ is a valid Radon-Nikodym derivative (i.e. integrates to 1 and is positive). We can write $\mathbb{P}_2(A):=\mathbb{E}^{\mathbb{P}_1}\left[g(W_t)\mathbb{I}_{\{A\}}\right]$ and conclude that: \begin{equation}
\label{eq7}
W(t)^{\mathbb{P}_2}\sim N(0,k^2t)
\tag{7}
\end{equation} Question : in the text-book "" Stochastic Calculus and Financial Application "" by J.M. Steele, in the first paragraph on page 221, the author states (without proof) that given two processes $\sigma_1 W_t$ and $\sigma_2 W_t$ , the measures $\mathbb{P}_{\sigma_1}$ and $\mathbb{P}_{\sigma_2}$ are singular whenever $\sigma_1 \neq \sigma_2$ . Setting $\sigma_1=1$ and $\sigma_2=k$ , I am unable to prove / explain why the construction above wouldn't produce two equivalent probability measures.","['measure-theory', 'stochastic-analysis', 'girsanov-theorem', 'stochastic-processes', 'stochastic-calculus']"
4815271,How is P(GB) equal to the P(G)P(B)?,"I have read the Probability and Statistics for Engineering
and the Sciences by Jay Devore, and then I got stuck at the example 3.12 (ch3 Discrete Random Variables and Probability Distributions) as following Starting at a fixed time, we observe the gender of each newborn child at a certain hospital until a boy (B) is born. Let p=P(B), assume that successive births are independent, and define the rv X by x=number of births observed. Then p(1) = P(X=1) = P(B) = p p(2) = P(X=2) = P(GB) = P(G)P(B) = (1-p)p … I am little curious and can not figure out that how(why) is P(GB) equal to P(G)P(B) ?","['statistical-inference', 'statistics', 'probability']"
4815275,"How to show that given two acute angles, the sine ratio of the greater angle is greater than the sine ratio of lesser angle?","How do I show that for angles $\theta ,\psi \in [0^°,90^°$ ], if $\theta > \psi$ , then $\sin \theta > \sin \psi$ ? I thought of proving this by creating two right triangles with the same hypotenuse length $h$ , one having an acute angle of $\theta$ and another right triangle having one of its acute angle as $\psi$ . I denote the side opposite to $\theta$ and $\psi$ as $p$ and $q$ , respectively. $\theta$ and another triangle with its acute angle being $\psi$ "" /> Then by the greater side is opposite to greater angle in a triangle theorem: $$p>q$$ $$\frac{p}{h}> \frac{q}{h}$$ Therefore, $\sin \theta = \frac{p}{h}> \frac{q}{h} = \sin \psi$ . However, I then realize that the 'greater side is opposite the greater angle' should be applied within a triangle. I also think that maybe I shouldn't assume that both right triangles have the same hypotenuse length. How would I modify this proof so that it is correct? Or is it that I'll have to find a completely different approach of proving this? I'm still new to trigonometry so I hope that the proofs given won't use any complicated theorems. Thank you.","['triangles', 'trigonometry', 'proof-writing', 'geometry']"
4815325,Distribution of an estimator,"Let $X_1,\ldots,X_n$ be indenpendent identically distributed random variables with density $$f_X(x)=\theta(1+x)^{-1-\theta}$$ for some $\theta>0$ and $x>0$ . I would like to know how to compute the distribution of the estimator $$T=\sum_{i=1}^n\log(1+X_i).$$ I have computed the distribution of $\log(1+X)$ but I don't know what to do then. Thanks in advance.","['statistics', 'probability-distributions', 'probability-theory', 'probability', 'random-variables']"
4815336,"Proving the existence of integers $a, b, c$ such that $\left\lvert a + b\sqrt{2} + c\sqrt{3}\right\rvert < 10^{-5}$ [duplicate]","This question already has an answer here : Prove: $\exists a,b,c\in\mathbb{Z}$ not all zero, $|a|,|b|,|c|<10^6$ s.t. $|a+\sqrt2 b+\sqrt 3 c|\leq\frac{1+\sqrt2 +\sqrt3}{1+10^6+10^{12}}$ (1 answer) Closed 7 months ago . Prove that there exist integers $a, b, c$ such that $|a|, |b|, |c| \leq 1000$ where not all of them are zero and $\left\lvert a + b\sqrt{2} + c\sqrt{3}\right\rvert < 10^{-5}$ I am stuck on this problem. My Attempt : I've tried the Pigeonhole Principle. I tried making the decimal values of $\left\lvert b\sqrt{2} + c\sqrt{3}\right\rvert$ as pigeons in $\left[0, 10^{-5}\right), \left[10^{-5}, 2 \cdot 10^{-5}\right), ... , \left[\left(10^5 - 1\right) \cdot 10 ^ {-5}, 1\right)$ . Since there are $10^3 \cdot 10^3 = 10^6$ pigeons in $10^5$ holes, there must be a hole such that it has at least two pigeons. If we add/subtract them, then $x = \left\lvert(b_1 \pm b_2)\sqrt{2} + (c_1 \pm c_2)\sqrt{3}\right\rvert$ will have decimal point less than $10^{-5}$ . So, we need to make the integer value of $x$ to be zero which we can subtract as $a$ . One Problem is that $x$ may have an integer value on the orders of $1000\cdot \sqrt{2} + 1000 \cdot \sqrt{3} = 3146$ which highly exceeds the maximum for $a$ . Second Problem is that the part about adding/subtracting seems complicated in terms of ensuring that $\left\lvert b_1 \pm b_2\right\rvert \leq 1000$ and $\left\lvert c_1 \pm c_2\right\rvert \leq 1000$ . So, I am stuck! Any help is appreciated. Thanks!","['contest-math', 'pigeonhole-principle', 'discrete-mathematics']"
4815377,Decrease list difference via swaps,"There are four lists, each with $100$ numbers in $[0,1]$ . You want to perform as few swaps between pairs of numbers as possible, so that the difference between the sums of numbers in any two lists becomes at most $1$ . What is the largest number of swaps that you may have to perform? A worst case seems to be when two lists are all $1$ and the other two lists are all $0$ , which needs $100$ swaps. A method for achieving the goal (difference $\le 1$ ) is that, as long as the goal is not met, we swap a largest number in a largest-sum list with a smallest number in a smallest-sum list. This always terminates because after the swap, both lists have a larger sum than the previous sum of the smaller-sum list. But does it always terminate after at most $100$ swaps?","['combinatorics', 'extremal-combinatorics', 'algorithms']"
4815402,Justifying steps in Riesz Representation theorem (local compact hausdorff space case),"I am reading the proof of  Riesz Representation theorem(1.5.14) on Leon Simon's book:Geometric Measure Theory And I got stuck at the following higlighted part. I completely understand the note he made befor the highlight part but I just cant reach his conclusion using that note.
For your information: $$L(g)=\int_{X} g\cdot\nu d\mu$$ is proved .And $f \in C_c(X,[0,\infty))$ , $X$ is locally compact and Hausdorff Any help will be appreciated.","['integration', 'riesz-representation-theorem', 'geometry', 'real-analysis', 'functional-analysis']"
4815414,"Proving $_4F_3\left(\frac{1}{2},\frac{3}{4},\frac{3}{4},1;\frac{5}{4},\frac{5}{4}, \frac{3}{2};1\right)=\frac{\Gamma^8(1/4)}{768\pi^3}$","I have been trying to Prove the following Sum. $$\frac{\Gamma^2(5/4)}{\Gamma^2(3/4)}\sum_{r=0}^{\infty}\left(\frac{1}{2r+1}\right)\frac{\Gamma^2(r+3/4)}{\Gamma^2(r+5/4)}=\frac{\Gamma^8(1/4)}{768\pi^3}$$ Or in terms of Pochhammer Symbol: $$\sum_{r=0}^{\infty}\left(\frac{1}{2r+1}\right)\frac{(3/4)_r^2}{(5/4)_r^2}=\frac{\Gamma^8(1/4)}{768\pi^3}$$ One may convert it into a Hypergeometric Representation which gives: $$_4F_3\left(\frac{1}{2},\frac{3}{4},\frac{3}{4},1;\frac{5}{4},\frac{5}{4},
\frac{3}{2};1\right)=\frac{1}{768\pi^3}\Gamma^8\left(\frac{1}{4}\right)$$ Also note that, $$\sum_{i=1}^3b_i-\sum_{i=1}^{4}a_i=1$$ I just mentioned the above because I heard it's a kind of Property of such Functions. I don't see how a $8$ th Power Gamma Term appears. The following List at Functions.Wolfram doesn't have any similar ones nor am I able to use any formulas either. One may use the following to Numerically Test it. N[HypergeometricPFQ[{1/2,3/4,3/4,1},{5/4,5/4,3/2},1],300]-Gamma[1/4]^8/Pi^3*1/768 EDIT: I was able to Convert it to an Integral: $$\int_{0}^{1}\int_{0}^{1}\frac{\ln(1+xy)-\ln(1-xy)}{\sqrt{xy(1-x^2)(1-y^2)}}dxdy=\frac{\Gamma^4(1/4)}{48}$$","['calculus', 'hypergeometric-function', 'sequences-and-series']"
