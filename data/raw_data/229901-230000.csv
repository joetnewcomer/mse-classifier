question_id,title,body,tags
4764351,Seeking for shortcut for evaluating $\cos\left(\frac{\pi}{11}\right)\cos\left(\frac{2\pi}{11}\right)\cdots\cos\left(\frac{10\pi}{11}\right)$,"I hope this message finds you well. I am currently working on a challenging trigonometric problem and am seeking the collective wisdom and expertise of this community to help me find an efficient and elegant solution. The problem at hand involves evaluating the following intricate trigonometric expression: $$\cos\left(\frac{\pi}{11}\right)\cos\left(\frac{2\pi}{11}\right)\cos\left(\frac{3\pi}{11}\right)\cdots\cos\left(\frac{10\pi}{11}\right) = -2^n $$ Find the value of $n$ Approach: Allow me to share my current approach, which involves the method of the product of cosines and subsequent algebraic manipulation. However, I am keen to explore whether there exists a more concise or elegant approach or a shortcut method to arrive at the value of $n.$ Here is my current approach: Let's   consider $ \theta = \frac{\pi}{11} $ , then $ 11\theta = \pi $ $ \Rightarrow \cos\left(\frac{\pi}{11}\right)\cos\left(\frac{2\pi}{11}\right)\cos\left(\frac{3\pi}{11}\right)\cos\left(\frac{4\pi}{11}\right)\cos\left(\frac{5\pi}{11}\right)\cos\left(\frac{6\pi}{11}\right)\cos\left(\frac{7\pi}{11}\right)\cos\left(\frac{8\pi}{11}\right)\cos\left(\frac{9\pi}{11}\right)\cos\left(\frac{10\pi}{11}\right) = -2^n $ $\Rightarrow \cos\theta \cos(2\theta) \cos(3\theta) \cos(4\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(8\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $\Rightarrow \frac{1}{2\sin(\theta)} \cdot 2 \sin(\theta) \cos(\theta)\cos(2\theta) \cos(3\theta) \cos(4\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(8\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $\Rightarrow \frac{1}{2\sin(\theta)} \cdot \sin(2\theta) \cos(2\theta) \cos(3\theta) \cos(4\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(8\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{1}{2\sin(\theta)}\frac{1}{2} \cdot 2 \sin(2\theta) \cos(2\theta) \cos(3\theta) \cos(4\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(8\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{1}{2^2\sin(\theta)} \cdot \sin(4\theta)\cos(4\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(8\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $\Rightarrow \frac{1}{2^2\sin(\theta)} \cdot \frac{1}{2} \cdot 2 \sin(4\theta)\cos(4\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(8\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{1}{2^3\sin(\theta)} \cdot \sin(8\theta)\cos(8\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{1}{2^3\sin(\theta)} \cdot \frac{1}{2} \cdot 2 \sin(8\theta)\cos(8\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{1}{2^4\sin(\theta)} \cdot \sin(16\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{1}{2^4\sin(\theta)} \cdot \sin(11\theta+ 5\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $\Rightarrow \frac{1}{2^4\sin(\theta)} \cdot \sin(\pi + 5\theta) \cos(3\theta) \cos(5\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $\Rightarrow \frac{1}{2^4\sin(\theta)} -\sin( 5\theta)\cos(5\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $\Rightarrow \frac{-1}{2^4\sin(\theta)}\cdot \frac{1}{2} \cdot 2 \sin( 5\theta)\cos(5\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) \cos(10\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^5 \sin(\theta)}\cdot \sin(10\theta)\cos(10\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^5 \sin(\theta)}\cdot \frac{1}{2} \cdot 2 \sin(10\theta)\cos(10\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^6 \sin(\theta)}\cdot \sin(20\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^6 \sin(\theta)}\cdot\sin(11\theta+9\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^6 \sin(\theta)}\cdot\sin(\pi +9\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) \cos(9\theta) = -2^n $ $\Rightarrow\frac{-1}{2^6 \sin(\theta)}\cdot\ -sin(9\theta) \cos(9\theta) \cos(3\theta) \ cos(6\theta) \cos(7\theta) = -2^n $ $ \Rightarrow\frac{1}{2^6 \sin(\theta)}\cdot \frac{1}{2} \cdot 2 \sin(9\theta) \cos(9\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) = -2^n $ $ \Rightarrow\frac{1}{2^7 \sin(\theta)} \cdot \sin(18\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) = -2^n $ $ \Rightarrow\frac{1}{2^7 \sin(\theta)} \cdot \sin(11\theta+7\theta) \cos(3\theta) \cos(6\theta) \cos(7\theta) = -2^n $ $\Rightarrow \frac{1}{2^7 \sin(\theta)} \cdot -sin(7\theta) \cos(7\theta) \cos(3\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^7 \sin(\theta)}\cdot \frac{1}{2} \cdot 2 sin(7\theta) \cos(7\theta) \cos(3\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^8 \sin(\theta)} \cdot sin(14\theta) \cos(3\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^8 \sin(\theta)} \cdot sin(11\theta+3\theta) \cos(3\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^8 \sin(\theta)} \cdot -sin(3\theta) \cos(3\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{1}{2^8 \sin(\theta)} \cdot \frac{1}{2} \cdot 2 sin(3\theta) \cos(3\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{1}{2^9 \sin(\theta)} \cdot sin(6\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{1}{2^9 \sin(\theta)} \cdot sin(6\theta) \cos(6\theta) = -2^n $ $\Rightarrow \frac{1}{2^9 \sin(\theta)}\cdot\frac{1}{2} \cdot 2 \cdot sin(6\theta) \cos(6\theta) = -2^n $ $ \Rightarrow\frac{1}{2^{10} \sin(\theta)}\cdot 2 \cdot sin(12\theta) = -2^n $ $ \Rightarrow\frac{1}{2^{10} \sin(\theta)}\cdot sin(11\theta+\theta) = -2^n $ $ \Rightarrow\frac{1}{2^{10} \sin(\theta)}\cdot -sin(\theta) = -2^n $ $ \Rightarrow\frac{-1}{2^{10} }\cdot 1 = -2^n $ $\Rightarrow-2^{-10} = -2^n $ $\Rightarrow n = -10 $ While my current method is functional but too long, I believe that leveraging the collective expertise of this community might uncover a more efficient solution or a clever mathematical technique. Your insights, shortcuts , or alternative approaches to simplify this expression would benefit me and assist others who encounter similar trigonometric challenges. Thank you in advance for your time and expertise in helping me tackle this trigonometric conundrum. Your contributions are greatly appreciated.",['trigonometry']
4764358,Limit of a particular trace norm.,"I have the following problem. Let $\mathbf{\hat{\rho}}(t)$ and $\mathbf{\hat{\sigma}}(t)$ be two trace class positive operators acting on a Hilbert space of infinite dimension for all $t > 0$ . More precisely assume that $$
\mathbf{\hat{\rho}}(t):= \int p_{i}(x)e^{-ixt\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ixt\mathbf{\hat{B}}}dx
$$ $$
\mathbf{\hat{\sigma}}(t):= \int p_{j}(x)e^{-ixt\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ixt\mathbf{\hat{B}}}dx
$$ where $\mathbf{\hat{B}} $ is a self-adjoint operator with purely absolutely continuous spectrum and $\big|\psi\big\rangle$ is any vector in the Hilbert space in question, and $p_{i}$ and $p_{j}$ are probability distributions with compact support which is nonoverlapping.
I am trying to prove that $$\lim_{t\rightarrow \infty}\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1}= 0  \;\; (quantum\; fidelity)$$ However, this has proven to be quite a challenge since there are no good upper bounds for the quantum fidelity in the general case were both of the operators in question are not pure. I have tried using the following celebrated bound. $$
\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1}\leq\sqrt{1-\big\|\mathbf{\hat{\rho}}(t)-\mathbf{\hat{\sigma}}(t)\big\|_{1}^{2}}
$$ but this just replaces a very difficult problem with one of equal complexity. For the simpler version of this problem where $$\mathbf{\hat{\rho}}(t):=e^{-ix_{i}t\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ix_{i}t\mathbf{\hat{B}}}
$$ and $$
\mathbf{\hat{\sigma}}(t):=e^{-ix_{j}t\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ix_{j}t\mathbf{\hat{B}}}
$$ with $x_{i}\neq x_{j}$ and all of the other assumptions preserved I can easily show the analogous hypothesis. Here $$
 \lim_{t\rightarrow \infty}\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1} = \big|\langle \psi\big|e^{-t(x_{i}-x_{j})\mathbf{\hat{B}}}\big|\psi\big\rangle\big| = \int e^{-t(x_{i}-x_{j})\lambda}d\mu_{\psi}(\lambda)
$$ where $d\mu_{\psi}(\lambda)$ is the absolutely continnuous spectral measure afforded by $\big|\psi\rangle$ . Owing to the Riemann Lebegues lemma indeed $\lim_{t\rightarrow \infty}\int e^{-t(x_{i}-x_{j})\lambda}d\mu_{\psi}(\lambda) = 0$ . Due to this result, I am led to believe that the more general case where $\mathbf{\hat{\rho}}(t)$ and $\mathbf{\hat{\sigma}}(t)$ are uncountable mixtures as presented above, we should have the same sort of behavior as $t\rightarrow \infty$ . However, the quantum fidelity is unwieldy. Any help tackling this problem would be greatly appreciated.","['measure-theory', 'operator-theory', 'trace', 'functional-analysis', 'quantum-mechanics']"
4764359,Equivalent definitions of residual finite groups,"Let $G$ be a group. In the literature, I have encountered the following two definitions of residually finite group $G$ : Definition 1: $G$ is called residually finite if for all $x\ne 1$ , there exists a normal subgroup $N\lhd G$ of finite index such that $x\notin N$ . This is e.g. the definition on Wikipedia , where equivalent characterisations are given. On the other hand, I have also encountered the following definition in e.g. Brown-Ozawa's book "" $C^*$ -algebras and finite-dimensional approximations"" or other $C^*$ -literature: Definition 2: $G$ is called residually finite if there exists a descreasing sequence of normal subgroups $$G \supseteq G_1 \supseteq G_2 \supseteq G_3 \supseteq \dots$$ such that $G_i$ is of finite index in $G$ for all $i\ge 1$ and such that $\bigcap_{i=1}^\infty G_i = \{1\}$ . My question: Are these definitions equivalent? It is clear to me that Definition 2 implies Definition 1, so concretely, I want to know why Definition 1 implies Definition 2. I don't see how to construct the desired decreasing sequence of normal subgroups. Maybe, we need to assume that the group $G$ is countable? Any help will be highly appreciated!","['group-theory', 'abstract-algebra']"
4764362,"Automorphism group of the Klein quartic over field of characteristic 2,3,7(Hartshorne exercise IV.5.7)","Let $k$ be an algebraically closed field of characteristic $p$ , and $X$ be the plane quartic curve defined by $$x^3y+y^3z+z^3x=0,$$ which is the so-called Klein quartic . Hartshorne claims in exercise IV.5.7(b) of his book < Algebraic Geometry > that Assume $p\ne3$ , then the group $\mathrm{Aut}\, X$ is the simple group of order $168$ , whose order is the maximum $84(g-1)$ allowed by (Ex. 2.5). For the case $p\ne2,3,7$ , I found a proof in e.g. Perng.pdf . A sketch: we can find $3$ special automorphisms represented by matrices $$S=\begin{pmatrix}
\zeta&0&0\\
0&\zeta^4&0\\
0&0&\zeta^2
\end{pmatrix},\ T=\begin{pmatrix}
0&1&0\\
0&0&1\\
1&0&0
\end{pmatrix},\ 
U=\frac{1}{\sqrt{-7}}\begin{pmatrix}
\zeta-\zeta^6&\zeta^2-\zeta^5&\zeta^4-\zeta^3\\
\zeta^2-\zeta^5&\zeta^4-\zeta^3&\zeta-\zeta^6\\
\zeta^4-\zeta^3&\zeta-\zeta^6&\zeta^2-\zeta^5
\end{pmatrix},$$ where $\zeta$ is a primitive $7$ -th root of unity (in $k$ ), and the group $G$ generated by $S,T,U$ is a simple group of order $168$ , achieving the Hurwitz's bound, so $G=\mathrm{Aut}\,X$ . However, this proof fails for $p=2,3,7$ . For $p=2,3$ , the Hurwitz's bound $84(g-1)$ can fail. For $p=7$ , $X$ has a double point $[1,2,4]$ (and no other singularities), and there is no $7$ -th root of unity. I want to solve this exercise for $p=2,7$ . Also, I am curious about the case $p=3$ , in which the Hurwitz's bound can fail and $\mathrm{Aut}\,X$ is probably of order $>168$ . Any hint or reference? Edit: I have recently found a paper On Certain Curves of Genus Three with Many Automorphisms , which solved the case $p=2,3$ . For $p=3$ the group $\mathrm{Aut}\,X$ is just $PSU(3,3^2)$ , the simple group of order $6048$ . However, the singular case $p=7$ is still unsolved.","['algebraic-curves', 'algebraic-geometry']"
4764393,Integral $I=\int_{0}^{\pi/2}\frac{ \{ \tan x \} }{\tan x}dx$,"Motivated by Calculate $\int_0^\infty \frac{\{\tan x\}}{\tan x}dx$ I want to evaluate the following integral, $$I=\int_{0}^{\pi/2}\frac{  \{ \tan x \} }{\tan x}dx$$ Here is the value from Wolfram, $$I=0.919900494885649087058609882333342085980315192991199436742670023056103944536683559170770204$$ First step would be to write, $$\{ \tan x \} =\tan x-\lfloor\tan x\rfloor$$ $$I=\frac{\pi}{2}-\int_{0}^{\frac{\pi}{2}}\frac{\lfloor\tan x\rfloor}{\tan x}dx$$ $$x\to \pi/2-x$$ $$I=\frac{\pi}{2}-\int_{0}^{\frac{\pi}{2}}\frac{\lfloor\cot x\rfloor}{\cot x}dx$$ $$x\to \cot x$$ $$I=\frac{\pi}{2}-\int_{0}^{\infty}\frac{\operatorname{floor}\left(x\right)}{x\csc^{2}\left(\operatorname{arccot}x\right)}dx$$ $$I=\frac{\pi}{2}-\int_{0}^{\infty}\frac{\operatorname{floor}\left(x\right)}{x\left(1+x^{2}\right)}dx$$ $$I=\frac{\pi}{2}-\sum_{j=1}^{\infty}j\left(\int_{j}^{1+j}\frac{1}{x\left(1+x^{2}\right)}dx\right)$$ Also, $$\int_{j}^{1+j}\frac{1}{x\left(1+x^{2}\right)}dx=\ln\left(\frac{1+j}{j}\right)-\frac{1}{2}\ln\left(\frac{\left(j+1\right)^{2}+1}{j^{2}+1}\right)$$ or, $$=\ln\left(\frac{1+j}{j}\left(\frac{j^{2}+1}{\left(j+1\right)^{2}+1}\right)^{\frac{1}{2}}\right)$$ Therefore, $$I=\frac{\pi}{2}-\sum_{j=1}^{\infty}j\ln\left(\frac{1+j}{j}\left(\frac{j^{2}+1}{\left(j+1\right)^{2}+1}\right)^{\frac{1}{2}}\right)$$ or, $$I=\frac{\pi}{2}-\ln\left(\prod_{j=1}^{\infty}\left(\frac{1+j}{j}\right)^{j}\left(\frac{j^{2}+1}{\left(j+1\right)^{2}+1}\right)^{\frac{j}{2}}\right)$$ Note that, $$\prod_{j=1}^{n}\left(\frac{1+j}{j}\right)^{j}=\frac{\left(n+1\right)^{n}}{n!}$$ $$\prod_{j=1}^{n}\left(\frac{j^{2}+1}{\left(j+1\right)^{2}+1}\right)^{\frac{j}{2}}=\frac{1}{\left(\left(n+1\right)^{2}+1\right)^{\frac{n}{2}}}\prod_{j=1}^{n}\sqrt{1+j^{2}}$$ $$\prod_{j=1}^{\infty}\left(\frac{1+j}{j}\right)^{j}\left(\frac{j^{2}+1}{\left(j+1\right)^{2}+1}\right)^{\frac{j}{2}}=\lim_{n\to \infty}\left(\frac{\left(n+1\right)^{n}}{n!}\cdot\frac{1}{\left(\left(n+1\right)^{2}+1\right)^{\frac{n}{2}}}\prod_{j=1}^{n}\sqrt{1+j^{2}}\right)$$ $$=\lim_{n\to \infty}\left(\frac{\left(n+1\right)^{n}}{\left(\left(n+1\right)^{2}+1\right)^{\frac{n}{2}}}\right)\cdot\lim_{n\to \infty}\left(\frac{\prod_{j=1}^{n}\sqrt{1+j^{2}}}{n!}\right)$$ Although I am not aware of the proof but it seems that, $$\lim_{n\to \infty}\left(\frac{\prod_{j=1}^{n}\sqrt{1+j^{2}}}{n!}\right)=\sqrt{\frac{\sinh\pi}{\pi}}$$ whereas, $$\lim_{n\to \infty}\left(\frac{\left(n+1\right)^{n}}{\left(\left(n+1\right)^{2}+1\right)^{\frac{n}{2}}}\right)=1$$ This would imply, $$\boxed{I=\frac{\pi}{2}-\frac{1}{2}\ln\left(\frac{\sinh\pi}{\pi}\right)}$$ But this does not work numerically. Although I have not done this rigorously, I can't seem to find where the mistake is.","['integration', 'calculus', 'definite-integrals']"
4764430,On the infinite series $\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)$,"Let $F_n$ the $n-$ th Fibonacci number, i.e. $F_n=F_{n-1}+F_{n-2}$ with $F_0=0$ and $F_1=1$ . We know that ( here ): $$\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n+1}}\right)=\frac{\pi}{4}$$ but how about the following series: $$\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)$$ We can use Catalan's identity with $r=2$ and $m=2n$ , leading us to: $$F_{2n}^2-F_{2n-2}\cdot F_{2n+2}=(-1)^{2n-2}\cdot F_2^2\implies F_{2n}^2=1+F_{2n-2}\cdot F_{2n+2}$$ So: $$\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{F_{2n}}\right)=\sum_{n=1}^{+\infty}\arctan\left(\frac{1}{\sqrt{1+F_{2n-2}\cdot F_{2n+2}}}\right)$$ How can we go on? Also, I've calculated the result with the following C++ code and it appears to be $\mathcal{S}=1.30850 28221 75405 19611 19578 86489...$ #include<stdlib.h>
#include<iostream>
#include<math.h>
#include<iomanip>
int main(){

long double fn2, fn1, fn, sum;

fn2 = 0;
fn1 = 1;
sum = 0;

for(int i = 0; i < 5000; i++){
    fn = fn1 + fn2;
    fn2 = fn1;
    fn1 = fn;
     if(i%2==0){
        sum = sum + atan(1/fn);
    }
}

std::cout << setprecision(50);
std::cout << ""Result: "" << sum << std::endl;
system(""pause"");
} With Inverse Symbolic Calculator (via wayback), no result has been found. Possible linked post here .","['calculus', 'fibonacci-numbers', 'sequences-and-series']"
4764451,"What are all the elements of $\mathrm{Fun}(\mathbb{Z},\mathbb{Z})$ that satisfy the following property?","I'm very certain that this is nothing new under the sun but this is something I wondered yesterday and couldn't find resources online. Let $R$ be a (commutative, unital) ring and let $I$ be an ideal in $R$ . I say that a function $f:R\rightarrow R$ is $I$ -differentiable if for all $x\in R$ we have $f(x+I)-f(x)\subset I$ . The set $D(I)$ of all such functions is easily seen to be a subring of the ring $\mathrm{Fun}(R,R)$ of all $R$ -valued functions on $R$ that contains all polynomial functions, all $I$ -invariant functions and is stable und composition. On the other hand, in many cases such as $R=\mathbb{Z}$ and $I=n\mathbb{Z}$ , $D(I)$ is easily seen to be not the whole ring (e.g. no nontrivial function with finite support is $n\mathbb{Z}$ -differentiable). So my question is: What precisely are all the $n\mathbb{Z}$ -differentiable $\mathbb{Z}$ -valued functions on $\mathbb{Z}$ ? I'm suspecting $D(n\mathbb{Z})$ to actually be the smallest subring that contains all polynomial functions, all $I$ -invariant functions and is stable under composition, but would be delighted if it was actually larger. Thank you so much for your help and for providing further literature!","['ring-theory', 'abstract-algebra', 'commutative-algebra']"
4764499,Is the image of the regular representation of a finite field extension an algebraic variey?,"Let $L/K$ be a field extension of finite dimension $d$ . Choosing a $K$ -basis for $L$ gives rise to a map $\rho\colon L\to M_d(K)$ representing the map $x \mapsto (y\mapsto xy)$ . Is the image $\rho(L)$ cut from $M_d(K)$ by a set of polynomials with coefficients in $K$ ? If so, is there a nice way to say what these polynomials are? By trying out examples, I think the answer is Yes. I also feel like I'm missing something simple. I am only interested in the case where $K$ and $L$ are number fields, but I feel this assumption is probably not needed.","['extension-field', 'algebraic-geometry', 'commutative-algebra']"
4764517,Solving the equation $8\Delta = \left( {b + c} \right)\left( {bc + 1} \right)$,"In $\Delta ABC$ , $8\Delta  = \left( {b + c} \right)\left( {bc + 1} \right)$ then circumradius of   is $\Delta ABC$ is     ( where $\Delta$ denotes area of triangle and b, c are length of sides AC and AB respectively) (1) $\sqrt \Delta  $ (2) $\frac{1}{{\sqrt {2\Delta } }}$ (3) $\sqrt {2\Delta } $ (4) $\frac{1}{{\sqrt \Delta  }}$ My approach is as follow $R = \frac{{abc}}{{4\Delta }}$ where R is the circumradius of the $\Delta ABC$ $\Delta  = \frac{1}{2}bc\sin A$ , $8\Delta  = 4bc\sin A = \left( {b + c} \right)\left( {bc + 1} \right) \Rightarrow 4bc\sin A - bc\left( {b + c} \right) = \left( {b + c} \right)$ Nor able to proceed further.",['trigonometry']
4764535,Smooth manifold with finite atlas,"There is already quite a bit of discussion about this online, but I feel like a lot of this discussion is very confused so please help me understand the following questions: Does every connected manifold have a finite atlas with connected charts? There is a book by Werner Greub called ""Connections, Curvature and Cohomology - Volume 1"" which, on page 20 contains the corollary that every topological manifold has a finite atlas of at most $n+1$ charts, where $n$ is the dimension of the manifold. Of course, these charts could well be disconnected, so I wonder if we can also find a finite atlas consisting of charts whose domains are each connected. How does this change if we are working with smooth manifolds? I assume the proof by Werner Greub still works if we impose the additional requirement that charts be compatible in the sense that the transition maps are $C^{\infty}$ , leading to the implication that every smooth manifold has a finite atlas consisting of at most $n+1$ charts. Finally, I came across the dubious paper A. Solecki. ""Finite atlases on manifolds"", Annales Societatis Mathematicae Polonae. Series I: Commentationes Mathematicae XVII (1974), which I call dubious because it doesn't have a single citation as far as I can tell. Without having fully verified the proof myself, the paper claims that for every smooth connected manifold $M$ of dimension $n$ there exists a finite atlas consisting of at most $2\cdot3^{2n}$ full charts, where a full chart is one that maps onto $\mathbb{R}^n$ . Since each chart is a homeomorphism and $\mathbb{R}^n$ is connected, this would mean that the domains of each of these charts is also connected. Any clarification is much appreciated.","['smooth-manifolds', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
4764549,Weak convergence does not imply joint weak convergence?,"Suppose that $X_n\Rightarrow X$ and $Y_n\Rightarrow Y$ as $n\to\infty$ where "" $\Rightarrow$ "" means convergence in distribution. We know that it does NOT imply that $(X_n,Y_n)\Rightarrow (X,Y)$ as $n\to\infty$ . In the following proof, which step is incorrect? Proof. Let $g_n(c_n)=E[f(X_n,Y_n)|Y_n=c_n]$ and $g(c)=E[f(X,Y)|Y=c]$ , where $f$ is any given bounded and continuous function and $c_n\to c$ as $n\to\infty$ . Because $(X_n,c_n)\Rightarrow (X,c)$ as $n\to\infty$ , we have $$
g_n(c_n)\to g(c) \quad \mbox{as $n\to\infty$}. 
$$ Then, by continuous-mapping theorem, we have $g_n(Y_n)\to g(Y)$ as $n\to\infty$ , i.e., $$
\lim_{n\to\infty} E[f(X_n,Y_n)|Y_n]=E[f(X,c)|c=Y]. 
$$ By dominated convergence theorem, we have $$
\lim_{n\to\infty}E[f(X_n,Y_n)]=\lim_{n\to\infty}E[E[f(X_n,Y_n)|Y_n]]=E\left[\lim_{n\to\infty}E[f(X_n,Y_n)|Y_n]\right]=E[E[f(X,c)|c=Y]]=E[f(X,Y)],
$$ which shows that $(X_n,Y_n)\Rightarrow (X,Y)$ as $n\to\infty$ . $~~~~~~~~~~$ QED. Note: I use the ""extended"" continuous-mapping theorem in the proof where there are a sequence of functions $g_n$ instead of a function $g$ , see http://www.bios.unc.edu/~kosorok/lecture09.pdf (Page 23) This proof leads us to an incorrect conclusion. So, I am wondering which step in the proof is incorrect? Thank you!","['probability-limit-theorems', 'weak-convergence', 'probability-theory', 'uniform-convergence', 'pointwise-convergence']"
4764560,Evaluation or simplification of $\displaystyle{\int_0^{\frac{\pi}{4}}}\dfrac{dx}{\sqrt{A-\cos x-Bx}}$,"The period for an inverted pendulum on which some external forces act is expressed in terms of its initial angle, $\Phi_o\in[0º,70º]$ (higher angles are unstable), as $$\mathcal{T}(\Phi_o)=2\sqrt 2\sqrt{\dfrac{\ell}{g}}\int_0^{\Phi_o}\dfrac{d\Phi}{\sqrt{(\cos\Phi_o-\cos\Phi)+\zeta(\Phi_o-\Phi)}},$$ where $g$ is gravity, and $\ell$ and $\zeta$ are pendulum-related constants. In brief, we're interested in $$\int_0^{\Phi_o}\dfrac{d\Phi}{\sqrt{A-\cos\Phi-B\Phi}}.$$ Is there any series expansion for this integral or any elliptical type function describing it maybe? Using Desmos to visualize the period in terms of the initial angle, looks like there shouldn't be any problem with convergence of this integral within the initial angle's interval and zeta's interval, $\zeta\in[0,2]$ . If it were too hard to find an expression in terms of $\Phi_o$ , at least it'd want to try it for $\Phi_o=\frac{\pi}{4}$ , which is the default inital value I use the most.","['integration', 'definite-integrals', 'multivariable-calculus', 'power-series', 'elliptic-integrals']"
4764574,How do I find an ellipse that is tangent to two non-orthogonal lines?,"I am trying to connect two lines (depicted below in red and blue) by an elliptical arc, such that the arc of ellipse runs seamlessly into those two lines. 1-3 below are the easy cases, but they should give a good idea of what I am trying to do. 1 and 3 are easy because they can be accomplished with an arc of a circle. Case 2 is easy because a circle can be scaled along one axis to create the desired ellipse. Case 4 is where I am stuck. Simply scaling a circular arc doesn't work. If I took the arc from case 3 and scaled it to fit the space, it would no longer be tangent with the top line. Is there a mathematical way to solve this problem? Is the solution significantly different when the depicted angle is acute vs. obtuse?",['geometry']
4764577,Order of study (books) modular forms/elliptic curves/Iwasawa theory,"can you please tell me a order to study these books? Algebraic number theory [edit] (Neukirch) Cohomology of number fields (Neukirch) A first course in modular forms (Diamond) The Arithmetic of elliptic curves (Silverman) Advanced topics on the arithmetic of elliptic curve (Silverman) P.S.
May I ask if these books cover the path to understand this book of papers? —-> Elliptic curves, modular forms and Iwasawa theory (Loeffler)","['self-learning', 'elliptic-curves', 'book-recommendation', 'algebraic-geometry', 'modular-forms']"
4764580,Integration of Products of Cosine,"Is there any elegant way of showing $$\int_{0}^{2\pi} \cos(x)\cos(2x)\cos(3x)\cos(4x)\cos(5x)\cos(6x) = 0$$ More generally, how could one approach to show that $$\int_{0}^{2\pi} \prod_{k=1}^{N} \cos(k x) = 0$$ if any only if $N$ is congruent to $1$ or $2$ mod $4$ ? Thank you for any help!","['integration', 'trigonometry']"
4764581,Show that $M$ is the midpoint of $JI$,"* $H$ is the orthocenter of $\triangle ABC$ I don't even know where to start, it appears that point $E$ has nothing too special about it, line $LI$ is too mysterious to me, I couldn't turn it into a radical axis or any convenient polar w.r.t some circle. Projective geometry also doesn't seem to help except if we could use Pascal's theorem in a tricky way, perhaps with the symedian of $\triangle ABC$ but I'm not sure how to do it. EDIT: well, here is a transcription of the problem since people asked me: $\triangle JIK$ is the orthic triangle of $\triangle ABC$ and $L$ is the reflection of $H$ with respect to $BC$ . Show that line $BE$ bisects $JI$ ( $E = (ABC) \cap LI \neq L$ ).","['euclidean-geometry', 'geometry']"
4764643,Proof request: Extending vector valued function of unit outer normals to the whole space $\Bbb R^n$.,"I was wondering if anyone could provide a proof or a reference of the following proposition: Let $C$ be an open subset of $\mathbb{R}^n$ with $C^2$ boundary so that the unit outer normal vector $v(x)$ will be a $C^1$ function i.e $v: \partial C \to \mathbb{S}^{n-1}$ , then it can be extended to a $C^1$ function $N: \mathbb{R}^n \to \mathbb{R}^n $ such that $|N(x)| \leq 1$ . Unfortunalety I don't know much differential geometry so it is not obvious to me. For the context, this is used when proving that the characteristic function of a $C^2$ open bounded set $C$ is of bounded variation and its total variation equals $\mathcal{H}^{n-1}(\partial C)$ . Thanks in advanced","['geometry', 'geometric-measure-theory', 'bounded-variation', 'calculus', 'differential-geometry']"
4764692,Is there an exact solution to $x \sinh\Big(\frac{1}{x}\Big) = a$?,"Is there an exact formula for solutions to the equation $x \sinh\Big(\frac{1}{x}\Big) = a$ where $a,x \in \mathbb{R}^+$ ? And if not, why? I tried to rearrange to apply Lambert W somewhere to no avail. If it does exist, does it also exist for $x \sinh\Big(\frac{k}{x}\Big) = a$ where $k\in \mathbb{R}^+$ and is a known constant. Wolfram only gives approximant solutions and no explanation, which is unfortunate. https://www.wolframalpha.com/input?i2d=true&i=x+sinh%5C%2840%29Divide%5B1%2Cx%5D%5C%2841%29%3D2","['hyperbolic-functions', 'inverse-function', 'lambert-w', 'functions', 'hyperbolic-equations']"
4764814,Applying the limit definition of a derivative on a radical function $x^{2/3}$,"I'm trying to find the derivative of the following using the limit definition of a derivative: $$f(x)=x^{2/3}.$$ I know that the derivative of $f(x)$ is $\frac23x^{-1/3}$ by the power rule, but I can't figure out how to do it with the limit definition. I've tried multiplying by a conjugate and can't get it that way. The professor said to use the difference of cubes formula to solve it, but I can't figure out how that plays into this question. The question is due 9/6/23, so any answers before that are greatly welcomed.","['limits-without-lhopital', 'calculus', 'limits', 'radicals', 'derivatives']"
4764847,u-substitution shows 0=1,"This question/observation is inspired by the integral: $$\int_0^{\sqrt{\pi}}x\sin(x^2)\cos(x^2)dx$$ The $u$ -substitution $u=\sin(x^2)$ yields $du=2x\cos(x^2)dx$ and $$\int_0^{\sqrt{\pi}}x\sin(x^2)\cos(x^2)dx=\frac{1}{2}\int_0^0 u du=0,$$ right? Wolframalpha certainly agrees. Great, now consider the much harder integral $$\int_0^1 dx.$$ After banging our heads against the wall for hours we take $u=x^2-x$ so $du=(2x-1)dx=\pm\sqrt{1+4u}*dx$ by the quadratic formula, so $$\int_0^1 dx=\int_0^0\frac{du}{\pm\sqrt{1+4u}}=0$$ The problem is wolframalpha says this integral should be $1$ . Well, I guess it is a unit square. Since $0\neq 1$ there is something fishy going on - I'm just trying to fully nail down the issue here. I think it boils down to hidden division by $0$ like most false proofs. In particular we can't solve the equation $du=(2x-1)dx$ for $dx$ if $x=\frac{1}{2}$ , which happens inside the domain of integration. This isn't a problem for the original integral because even though there is a place where $\frac{du}{dx}=0$ inside the domain of integration $(x=\sqrt{\frac{\pi}{2}})$ there is no issue because we don't have to divide by this expression to make all the $x$ s cancel. Anyway, I'm curious for further explanation and to know if there are any references which carefully explain subtleties such as this for integration by substitution.","['integration', 'fake-proofs', 'real-analysis', 'calculus', 'differential-forms']"
4764864,Showing that a set similar to Cantor set has complement with measure one,"Consider the Cantor set $C$ . Define a new ""Cantor"" set which we will call $C_\alpha$ for $\alpha \in (0,1)$ . We construct $C_\alpha$ by letting $C_0 = [0,1]$ , $C_1 = C_0$ but with an open interval of length $\alpha$ taken out of the center. Define $C_2$ by taking $C_1$ and taking out of each remaining half an interval of length $b \cdot \alpha$ where $b$ is the length of one of the remaining halves in $C_2$ . Continue in this manner for all sets $C_k$ with $k \in \mathbb{N}$ . Then we create our new ""Cantor"" set $C_\alpha$ by taking $C_\alpha = \displaystyle\bigcap_{i=0}^\infty C_i$ . I seek to show that the complement of $C_\alpha$ in the unit interval $[0,1]$ has measure $1$ (Notation: when I write $C_i^c$ , I mean with respect to $[0,1]$ , not all of $\mathbb{R}$ ). First, note that $|C_0^c| = 0, |C_1^c| = \alpha, |C_2^c| = 2\alpha^2$ . In general, we will see that $|C_k^c| = 2^{k-1}\alpha^k$ . Then I obtain $$\displaystyle\sum_{i=0}^\infty |C_i^c| = \displaystyle\sum_{i=0}^\infty 2^{k-1}\alpha^k = \frac{1}{2} \displaystyle\sum_{i=0}^\infty (2\alpha)^k = \dots ?$$ At this point, I get stuck because I want to eventually use $\displaystyle\sum_{k=0}^\infty x^k = \frac{1}{1-x}$ for $|x| < 1$ since I suspect that is the way to do this, but I cannot be sure that $|2\alpha| < 1$ . In fact, this won't be true for all $\alpha \in (0,1)$ whenever $\alpha \geq \frac{1}{2}$ . Any suggestions on where I should go? I'm trying to show that $\displaystyle\sum_{i=0}^\infty |C_i^c|  =1$ .","['measure-theory', 'cantor-set', 'real-analysis']"
4764895,Integral inequality involving $e^{i\theta}$,"I believe the below inequality is true; $$\int_0^{2\pi}|a+e^{i\theta}\alpha b|^pd\theta\leq (1+\alpha)^p \int_0^{2\pi}|a+e^{i\theta} b|^pd\theta,$$ for any nonnegative reals $a, b, \alpha$ and $p>0.$ When $a=0$ or $b=0$ or $\alpha=1,$ the inequality is true.  May I know how to  verify if my claim is true or not. When $\alpha=1,$ the bound $(1+\alpha)^p$ appears relatively large, and therefore, is there any scope for sharpening this bound in my claim if the inequality is true in its current form?","['integration', 'complex-analysis', 'inequality', 'definite-integrals']"
4764952,Is Every Closed Algebraic Set of Dimension $n$ Contained in a Closed Variety of Dimension $n+1$,"Let $V$ be an algebraic variety of dimension $m$ over an algebraically-closed field of characteristic $0$ , and let $n<m$ and $U\subset V$ be a closed subset of $V$ . Must there exist a subvariety $U\subset U'\subseteq V$ with $U'$ of dimension $n+1$ ? In the affine case, this is just asking if the solutions to a system of $m-n$ or more polynomial equations are all solutions to a system of $m-n-1$ equations giving a variety. It is foundational to algebraic geometry that a potentially reducible $U'$ exists. I can show the result using Lagrange interpolation for the projective case when $n=1$ , but beyond that I am lost. I am not particularly learned in algebraic geometry.","['irreducible-polynomials', 'algebraic-geometry', 'affine-varieties', 'projective-varieties']"
4765010,There exists a region bounded by a Jordan curve on the plane.,"For me, a region is a set bounded by a Jordan curve (homeomorphic image of a circle) on the plane $\mathbb R^2$ together with the boundary (it follows from Jordan curve theorem that the complement of a Jordan curve consists of two connected sets, exactly one of which is bounded). Here $\partial R$ denotes the boundary of a region $R$ (that is a Jordan curve). I need help  proving the following. Given two regions $P,Q$ and a point $x\in \mathrm{int}(P\cap Q)$ , there exists a region $R$ such that $\partial R\subseteq \partial P \cup\partial Q$ and $x\in\mathrm{int} R\subseteq \mathrm{int}(P\cap Q)$ . My idea is to define $R$ as the closure of the connected component of the point $x$ in the set $\mathrm{int}(P\cap Q)$ , but I don't know how to prove that the boundary of $R$ is a Jordan curve. Edit (inspired by dsh's answer) Let $P,Q$ be regions and $x\in \mathrm{int}(P\cap Q)$ , Consider the set $Q_1= \partial Q\cap\mathrm{int}\,P$ . The set $Q_1$ is open in $\partial Q$ and if $\partial Q\not\subseteq\mathrm{int}P$ , then $Q_1$ is a finite or countable union of arcs, each one having the endpoints on $\partial P$ . First assume $L_1,\ldots, L_n$ are all such arcs. Then one can prove by induction that there exist (unique) $n+1$ pairwise disjoint regions $J_1,\ldots,J_{n+1}$ such that $$\partial J_i\subseteq \partial P \cup (L_1\cup\ldots\cup L_n)\text{ and}$$ $$\mathrm{int}\,P=(\mathrm{int}\, J_1\cup\ldots\cup\mathrm{int}\,  J_{n+1})\cup (L_1^*\cup\ldots\cup L_n^*),$$ where $L_i^*$ is the arc without its endpoints. Then $x\in \mathrm{int}\,J_i$ for some $i$ and since $x\in\mathrm{int}\, Q$ and $\mathrm{int}\,J_i\cap \partial Q=\emptyset$ , we get $\mathrm{int}\,J_i\subseteq\mathrm{int}\,Q$ . Now assume that there are infinitely many such arcs $L_1,L_2,L_3,\ldots$ For each $n\in\mathbb N$ consider the regions $J_1^n,\ldots,J_{n+1}^n$ that exist for arcs $L_1,\ldots, L_n$ as in the finite case, while $J_1^0=P$ . For each $n$ the point $x$ belongs to the interior of exactly one of the regions $J_1^n,\ldots,J_{n+1}^n$ , call it $C_n$ . Then $C_{n+1}\subseteq C_n$ and for each $n$ there are arcs $K$ and $M$ both with endpoints $a,b$ on $\partial C_n$ such that $K^*\subseteq \mathrm{int}\,C_n$ and $K\cup M=\partial C_{n+1}$ . Choose a sequence of parametrizations $\gamma_n\colon S^1\rightarrow\partial C_n$ such that $\gamma_{n+1}|I=\gamma_n|I$ , where $\gamma_n[I]=M$ and $M$ is as above. I want to show that for any $s\in S^1$ , $\gamma_n(s)$ is eventually stable with respect to $n$ and hence the pointwise limit $\gamma=\lim_{n\to\infty}\gamma_n$ exists and is a parametrization of the required Jordan curve.
Any help appreciated. EDIT Let me share my other idea based on dsh's answers (which I don't fully understand). Let $P,Q$ be regions and $x\in \mathrm{int}(P\cap Q)$ , I define $R$ to be a connected component of $x$ in $\mathrm{cl}\,\mathrm{int}\,(P\cap Q)$ . Then $\partial R\subseteq \partial P\cup\partial Q$ . Next, one can inductively define a sequence $(P_n)$ of regions and a sequence $(\gamma_n)$ of homeomorphisms $\gamma_n\colon S^1\rightarrow \partial P_n$ , while $P_0=P$ and $\gamma_0$ is arbitrary, such that we have the following. $P_{n}\subseteq P_{n-1}$ for $n\in\mathbb N$ . $R\subseteq \bigcap_{n}P_n$ . For each $n\in\mathbb N$ there exists a finite family of arcs $\mathcal I_n$ such that each $I\in\mathcal I_n$ is contained in $\partial R\cap \mathrm{int}\,P$ , endpoints of $I$ lie on $P$ and divide $P$ into two arcs $J_I,K_I$ , where the Jordan curve $I\cup J_I$ encloses $x$ , arcs $K_I$ are disjoint (except possibly for the endpoints) for different $I\in\mathcal I_n$ , there exist homeomorphisms $f_I\colon K_I\rightarrow I$ , and $$\gamma_n(t)=\begin{cases}f_I(\gamma_0(t)) &, \text{ if }\gamma_0(t)\in K_I\\\gamma_0(t) &,\text{ otherwise}\end{cases},$$ and moreover $\mathcal{I}_{n}\supseteq \mathcal I_{n-1}$ for all $n\in\mathbb N$ , while functions $f_I$ are the same for different $n$ . If $y\in \partial R$ , then $\mathrm{dist}(y,\partial P_n)<\frac1{2^n}$ for $n>0$ . It is clear that the sequence $(\gamma_n)$ is pointwise convergent. I can't see however why the limit function $\gamma$ is continuous and why $\partial R$ is the image of $\gamma$ .","['geometric-topology', 'general-topology']"
4765053,Find maximum and minimum of $\frac{\sin(A) + \sin(B) + \sin(C)}{\cos(A) + \cos(B) + \cos(C)}$ in acute triangles,"One day I had a question. In an acute angled triangle,what is maximum and minimum of $I$ ? $$ I=\frac{\sin(A) + \sin(B) + \sin(C)}{\cos(A) + \cos(B) + \cos(C)}$$ Attempt As law of cosines, $$\cos(A) + \cos(B) + \cos(C) = \frac{r}{R} + 1$$ $R$ is radius of the circumcircle $r$ is radius of the incircle so $ I=\frac{a+b+c}{2(r+R)}$ But I can't evaluate this, could not solve further. Would you mind solving my question?","['calculus', 'trigonometry', 'inequality']"
4765065,"For which natural numbers $a, b, c$ is the number $\dfrac{a^2+b^2+c^2-1}{(1+a)(1+b)(1+c)}$ an integer?","For which natural numbers $a, b, c$ is the number $\dfrac{a^2+b^2+c^2-1}{(1+a)(1+b)(1+c)}$ an integer? Please give me some tips on how to move it what can be applied what methods to use. I used symmetric polynomials. I multiplied the bottom to the end and then substituted: $$x=a+b+c \\
y=ab+ac+bc \\
z=abc$$ and top: $$a^2+b^2+c^2=(a+b+c)^2-2(ab+ac+bc)$$ I got such an expression- $$\frac{x^2-2y}{x+y+z}$$ But what do I do next?",['number-theory']
4765083,Vector space of functions on an empty domain?,"I know that these sorts of pathological cases are irrelevant, but I want to ""practice"" as it were and so want to understand the following. Hoffman and Kunze give the following example of a vector space: The space of functions from a set to a field. Let $F$ be any field and let $S$ be any non-empty set. Let $V$ be the set of all functions from the set $S$ into $F$ . They give the usual definitions of addition and scalar multiplication. At any rate, my question is about why they give the nonempty requirement. If $S$ is empty, then $V$ itself is not empty but rather contains the empty set (the empty set can be defined as a function on an empty set), $V = \{ \emptyset \}$ . If I define $\emptyset$ as my neutral element, then why on earth can't this be a vector space?","['functions', 'vector-spaces']"
4765088,What are the counter examples books for Abstract algebra?,"In mathematics field which book best for counter examples of group theory, linear algebra?","['book-recommendation', 'examples-counterexamples', 'abstract-algebra', 'linear-algebra', 'group-theory']"
4765127,"Show that if $x^2+x+1=0$, then $x^{26}+\dfrac{1}{x^{26}}=-1$","I am trying to answer the following precalculus question: Show that if $x^2+x+1=0$ , then $A=x^{26}+\dfrac{1}{x^{26}}=-1$ . Let's multiply the first equality (that we know is true) by $(x-1)$ . We can do that as $x$ is obviously $\ne1$ , $x=1$ isn't a solution of the first equation. (We need the second equality to hold for all of the solutions of the equation). We arrive at \begin{align}
(x-1)(x^2+x+1)=0&\iff x^3-1=0\\
&\iff x^3=1\\&\iff x=1\ (x\in\mathbb{R})
\end{align} in real numbers (I am not familiar with complex numbers), but we said $x\ne 1$ . So $x=1$ isn't a solution, so maybe for the left both complex roots the second equality holds. How can we use that to show that $A=-1$ ?",['algebra-precalculus']
4765130,Criteria for irrationality of Euler's constant,"Define for $n\in\mathbb{N}$ , $$I_n=\int_0^1\int_0^1 -\frac{(x(1-x)y(1-y))^n}{(1-xy)\log xy}dx dy$$ In this article it is proved that $$I_n=\binom{2n}{n}\gamma+L_n-A_n$$ where $L_n=d^{-1}_{2n}\log S_n$ , $A_n=\sum_{i=0}^{n}\binom{n}{i}^2 H_{n+i}$ and $$S_n=\prod_{k=1}^{n}\prod_{i=0}^{\min(k-1,n-k)}\prod_{j=i+1}^{n-i}(n+k)^{\frac{2d_{2n}}{j}\binom{n}{i}^2}$$ where $d_n=\text{lcm}(1,2,...,n)$ and $H_n$ is the $n$ th Harmonic number. In Theorem $4$ it is proved using the above representation of $I_n$ that for $n$ fixed, $\{\log S_n\}=d_{2n}I_n$ if and only if $\gamma=p/q$ for some $p,q\in\mathbb{Z}$ , where $q|d_{2n}\binom{2n}{n}$ and $\{x\}$ denotes the fractional part of $x$ . Question: Can we conclude that for $n$ fixed, $\log S_n-d_{2n} I_n\in\mathbb{Z}$ if and only if $\gamma$ is rational? We have by multiplication by $d_{2n}$ $$d_{2n}I_n=d_{2n}\binom{2n}{n}\gamma+d_{2n}L_n-d_{2n}A_n$$ which can be rewritten as $$\log S_n-d_{2n}I_n=d_{2n}A_n- d_{2n}\binom{2n}{n}\gamma$$ where $d_{2n}A_n\in\mathbb{Z}$ . So we have, $\log S_n-d_{2n} I_n\in\mathbb{Z}$ if and only if $\gamma=a/b$ for some $a,b\in\mathbb{Z}$ , where $b|d_{2n}\binom{2n}{n}$ . Can we conclude that for $n$ fixed, $\log S_n-d_{2n} I_n\in\mathbb{Z}$ if and only if $\gamma$ is rational? Any help will be highly appreciated. Thank you. Edit I am looking for an answer which I can accept. Thank you.","['number-theory', 'irrational-numbers', 'real-analysis', 'euler-mascheroni-constant', 'transcendental-numbers']"
4765182,"Confused about ""k-form""","Lee's Riemannian Manifolds: An Introduction to Curvature states the following on page 14: We let $\Lambda ^k (V)$ denote the space of covariant alternating $k$ -tensors on $V$ , also called $k$ - covectors or (exterior) $k$ - forms . This confused me because, for me, a $k$ -form is an alternating covariant tensor field of degree $k$ , not just a tensor. Later, Lee defines the following: the bundle of $k$ - forms is $\Lambda^k M := \coprod_{p\in M}\Lambda^k(T_p M).$ a differential $k$ - form is a smooth section of $\Lambda^k M$ . According to this, am I correct in assuming the following? A $k$ -form without ""differential"" is just an alternating multilinear map from a vector space to the space of scalars. A differential $k$ -form is what I have been thinking a $k$ -form is, that is, an alternating covariant tensor field of degree $k$ . Some people omit ""differential"" for some reason when they actually mean differential $k$ -form. If I am correct, is it a common naming method?","['differential-forms', 'differential-geometry']"
4765224,"Prove that the matrix $(I-xx^\top)(I-3 \mathrm{Diag}(xx^\top))(I-xx^\top)$ has at most one negative eigenvalue, for $x$ a unit vector","Let $x \in \mathbb{R}^n$ be a unit vector, i.e., $\|x\|=1$ .  Show that the following matrix $A$ has at most one negative eigenvalue: $$A:=(I-xx^\top)(I-3 \mathrm{Diag}(xx^\top))(I-xx^\top).$$ $\mathrm{Diag}(xx^\top)$ is the diagonal matrix whose $i$ -th diagonal entry is $x_i^2$ .  ( $\mathrm{Diag}$ extracts the diagonal of a matrix.) Some of my thoughts/attempts: The inner matrix $I-3 \mathrm{Diag}(xx^\top)$ clearly has at most 2 negative eigenvalues, as $\|x\|^2=1$ . The matrix $(I-xx^\top)$ is of course the orthogonal projector to the orthogonal complement of $x$ .  So we can add anything of the form $z x^\top + x z^\top$ to the inner matrix without changing $A$ . I believe it suffices to show that there is some $y \in \mathbb{R}^n$ such that $A + y y^\top \succeq 0$ -- see this MSE post .  So it suffices to show that there exists a $y$ such that $$z^\top (I-3 \mathrm{Diag}(xx^\top) + y y^\top) z \geq 0$$ for all $z$ orthogonal to $x$ . Maybe we can somehow appeal to Sylvester's law of inertia -- also not clear though.","['matrices', 'linear-algebra', 'positive-semidefinite', 'eigenvalues-eigenvectors']"
4765231,"Number of sequences $A_1, A_2, ..., A_k$ such that: $A_1 \subseteq A_2 \subseteq ... \subseteq A_k = [n]$.","For given numbers $n, k \in \mathbb{N} \setminus \{ 0 \}$ find the number of sequences $A_1, A_2, ..., A_k$ such that: $A_1 \subseteq A_2 \subseteq ... \subseteq A_k = [n]$ $[n] = \{1,2,3 ... n \}$ I know that A_k needs to contain all [n]. Then every other set must be a subset of that one. So we van choose $A_{k-1}$ in one of $\sum_{i=0}^n {{n}\choose{i}}$ ways. But then, for each of those we are faced with the same problem and I don't see how it can be described as dependent on n since some of those subsets in the sequence can be equal to one another.","['discrete-mathematics', 'sequences-and-series']"
4765238,"Can we express the value of $b^a$ in terms of $c$ , where $c=a^b$?","We know that ; If $a+b = c$ , then $b+a = c$ If $a-b = c$ , then $b-a=-c$ If $ab = c$ then $ba = c$ If $\dfrac{a}{b} = c$ then $\dfrac{b}{a} = \dfrac{1}{c}$ Now, I am curious to know that If $a^{b} = c$ , then what is $b^a$ in terms of $c$ ? I tried using logarithms but failed to get the desired answer in terms of $c$ . EDIT : It has been made clear from the answers that $b^a$ is not unique because $a^b$ can also be expressed as $x^y$ where $x,y$ can take infinite values. However, what happens if $a$ and $b$ are not changed? I want to emphasize more on the numerical value of $b^a$ rather than preserving numerical value of $a^b$ and then changing it to for some other forms of $x,y$ such that $x^y=c$ . For example, $2^6 = 64$ and $6^2=36$ which is unique. It is clear that $64 = 4^3$ ; but we do not wish to change $a$ and $b$ by other possible values which also happen to be some solutions of the $c$ . Or in more mathematical terms, I am intrested in ; If for some $a,b$ we have : $a^b = c$ then find $y^x$ given that : 1) $x^y = c$ as well as 2) $x=a$ , $y=b$ If it is impossible to find, then please also provide a proof . Thanks!","['exponentiation', 'algebra-precalculus', 'exponential-function', 'logarithms']"
4765307,"Volume of the graded linear series $\Gamma_\bullet(\mathbf{P}^n, \mathcal{O}(1) \otimes \mathfrak{m}^c)$. Is it $1 - c$ or $1 - c^n$?","I am working out example 2.4.13 in Lazarsfeld's ""Positivity in Algebraic Goemetry I"" and I got a conflicting answer with his. I am wondering if I made a mistake or if it's a typo in the book. Let $\mathfrak{m} \subset \mathcal{O}$ be the ideal sheaf of a point in some projective space $\mathbf{P} = \mathbf{P}^n$ , and $0 < c < 1$ a real number. We denote $\Gamma_\bullet(\mathbf{P}, \mathcal{O}(1) \otimes \mathfrak{m}^c )$ to be the graded linear series $$(\Gamma_\bullet(\mathbf{P}^b, \mathcal{O}(1) \otimes \mathfrak{m}^c ))_m := H^0(\mathbf{P}, \mathcal{O}(m) \otimes \mathfrak{m}^{\lceil cm\rceil }).$$ For a greaded linear series $|V_\bullet|$ we define its volume to be $\limsup_{m \to \infty} (n!\dim(V_m))/m^n$ . It is claimed in the book that the volume of $\Gamma_\bullet(\mathbf{P}, \mathcal{O}(1) \otimes \mathfrak{m}^c)$ is $1 - c$ but my calculation yielded $1 - c^n$ . I am wondering where/if I went wrong. Thanks! I'll write my calculation below. We note that $\mathcal{O}(m) \otimes \mathfrak{m}^{\lceil cm\rceil }$ fits into the short exact sequence below, which remains exact when we take global sections. $$0 \to \mathcal{O}(m) \otimes \mathfrak{m}^{\lceil cm\rceil } \to \mathcal{O}(m) \to \mathbf{C}[x_1, \dots, x_n]/((x_1, \dots, x_n)^{\lceil mc \rceil}) \to0$$ The sheaf on the right is a skyskraper sheaf at $x$ , with local coordinates $x_1, \dots, x_n$ . Now homogenizing polynomials allows us to identify $\mathbf{C}[x_1, \dots, x_n]/((x_1, \dots, x_n)^{\lceil mc \rceil}) $ with homogeneous polynomials in $\mathbf{C}[x_0, \dots, x_n]$ of degree exactly $\lceil mc \rceil - 1$ . Hence, we get that $$h^0(\mathcal{O}(m) \otimes \mathfrak{m}^{\lceil mc \rceil}) = P(m) - P(\lceil mc \rceil - 1)$$ where $P$ is the hilbert polynomial of $\mathbf{P}^n$ . Now, the growth of this with respect to $m$ is determined by the highest order terms, so $$\text{vol}(\Gamma_\bullet(\mathbf{P}^b, \mathcal{O}(1) \otimes \mathfrak{m}^c )) = 
\limsup_{m \to \infty} \frac{n!}{m^n} (m^n/n! - (\lceil mc \rceil - 1)^n/n!) = \limsup (1 - (\lceil mc \rceil - 1)^n/m^n).$$ But now, the last expression is a limit, and equal to $$1 - (\lim_{m \to \infty} \frac{\lceil mc \rceil - 1}{m})^n = 1 - c^n.$$ Edit: I wanted to clean up what was written above, and to include an additional simple explanation that confirms what we already know. For rational $c$ , global sections considerations allows us to identify the volume of $\Gamma_\bullet(\mathbf{P}, \mathcal{O}(1) \otimes \mathfrak{m}^c)$ with the volume of $H - cE$ in $N^1(\operatorname{Bl}_x\mathbf{P})_{\mathbf{R}}$ , where $H$ is the pullback of a hyperplane. Since this is an ample $\mathbf{Q}$ -divisor, its volume is $(H - cE)^n = 1 - c^n$ . The continuity of volume and the intersection product allows us to extend this to any real $0 < c < 1$ , which proves the result.","['algebraic-geometry', 'commutative-algebra']"
4765336,Showing that the centers of two semicircles and a circle inscribed in a quarter circle form a right triangle,"The challenge in this image is to determine the radii of the two semicircles and the full circle. Determining the radii of the two semicircles is straightforward; if the radius of the quarter circle is $6$ , the radius of the larger semicircle is $3$ , and of the smaller semicircle is $2$ . Solving for the radius of the full circle is also easy if you assume the angle in the red triangle is a right angle - the radius is $1$ . My question is how do we know that the marked angle is actually a right angle?","['circles', 'geometry', 'triangles', 'trigonometry', 'algebra-precalculus']"
4765339,Solving $\int_0^\pi \frac{\cos(kn)}{1+k^2}dk$,"I want to solve the integral $\int_0^\pi \frac{\cos(kn)}{1+k^2}dk$ . In my attempt, I tried do Integration by Parts twice, but this didn't get me anywhere. Then, I thought about using the Residue theorem, but to do that I needed the limits of integration to be $-\infty$ to $\infty$ . What else can I do to analytically solve this? $$\int\limits_{0}^{\pi}\frac{\cos(kn)}{1+k^2}dk$$ \begin{align}
\int\limits_{0}^{\pi}\frac{\cos(kn)}{1+k^2}dk &= \int\limits_{0}^{\pi}\frac{\cos(kn)}{(k+i)(k-i)}dk\\
&=\int\limits_{0}^{\pi}\frac i 2\left(\frac{\cos (k n)}{k+i}-\frac{\cos (k n)}{k-i}\right)dk\\
&=\frac{i}{2}\int\limits_{0}^{\pi}\frac{\cos(kn)}{k+i}dk-\frac{i}{2}\int\limits_{0}^{\pi}\frac{\cos(kn)}{k-i}dk
\end{align} Consider the first integral term and perform the change of variables $k = x - i$ . \begin{align}
\frac{i}{2}\int\limits_{0}^{\pi}\frac{\cos (k n)}{k+i} &= \frac{i}{2}\int\limits_{i}^{\pi+i} \frac{\cos (n (x-i))}{x} dx\\
&= \frac{i}{2}\int\limits_i^{\pi+i} \cosh (n) \frac {\cos (n x)}{x}+i\sinh (n) \frac{\sin (n x)} {x} dx\\
&=n\frac{i}{2}\cosh(n)\int\limits_{i}^{\pi+i}\frac{\cos(nx)}{nx}dx - n\frac{1}{2}\sinh(n)\int\limits_{i}^{\pi+i} \frac{\sin(nx)}{nx}dx 
\end{align} Change of variables: $t = nx$ : \begin{align}
&=n\frac{i}{2}\cosh(n)\int\limits_{n i}^{n(\pi + i)} \frac{\cos(t)}{t}dt - n\frac{1}{2}\sinh(n)\int\limits_{ni}^{n(\pi+i)}\frac{\sinh(t)}{t}dt\\
&= n\frac{i}{2}\cosh(n) \left ( Ci(n(\pi+i) - Ci(ni)) \right ) - n\frac{1}{2}\sinh(n)\left( Si(n(\pi+i)) - Si(ni)\right )
\end{align} Likewise, the second integral term of $(3)$ becomes: \begin{equation}
\begin{split}
&\frac{i}{2}\int\limits_{0}^{\pi}\frac{\cos(kn)}{k-i}dk \\ &=n\frac{i}{2}\cosh(n) \left ( Ci(n(\pi-i) - Ci(-ni)) \right ) + n\frac{1}{2}\sinh(n)\left( Si(n(\pi-i)) - Si(-ni)\right )
\end{split}
\end{equation} Therefore, $(3) = (8) - (9)$ .","['integration', 'definite-integrals', 'complex-analysis', 'calculus', 'trigonometric-integrals']"
4765348,How can I determine this polynomial of degree 3?,"I want to find a polynomial of degree 3 which passes through $(2,0) ,(-2,4),(-4,8)$ and has a minimum on the y-axis. I wrote $f(x)=ax^3+bx^2+cx+d$ , then we need to satisfy $f(2)=0$ $f(-2)=4$ $f(-4)=8$ $f'(0)=0$ However, solving this system of equations gives me $$f(x)=-\frac{1}{4}x^3-\frac{5}{6}x^2+\frac{16}{3}$$ I know this is wrong because $$f
''(0)=2(-5/6)<0$$ means we don‘t have a minimum on the y axis. Where is my mistake?","['maxima-minima', 'calculus', 'solution-verification']"
4765351,Is this group isomorphic to the real numbers?,"I have a locally compact abelian group $G$ with the following properties: It is connected (therefore divisible) and non-compact; It admits a $\mathbb{Q}$ -vector space structure and for any $g \neq 0$ , the group $\mathbb{Q}\cdot g$ is dense in $G$ ; All its non-trivial closed subgroups are of the form $\mathbb{Z} \cdot x = \langle x \rangle \cong \mathbb{Z}$ for any $x \in G\setminus\{0\}$ and for any such x, the quotient $G/\langle x \rangle$ is isomorphic to the unit circle; It admits a natural order by fixing some $x_0 \neq 0$ and saying that $\frac{a_1}{b_1}x_0 \le \frac{a_2}{b_2}x_0$ if and only if $\frac{a_1}{b_1} \le \frac{a_2}{b_2}$ . This can be extended through density of $\mathbb{Q}\cdot x_0$ by saying that the limit of a Cauchy net $(x_{\alpha})_{\alpha} \subset \mathbb{Q}\cdot x_0$ is positive iff only a finite number of its terms are non-negative; The rays of the form $]a, b[ = \{x \in G: \ a < x < b\}$ are open (it's easy to see that their complements have to be closed by the definition of the order); $G$ admits fractional parts in the sense that if $g \in G$ , there exists unique $n \in \mathbb{Z}$ and $y \in [0, x_0[$ such that $g = y + nx_0$ ; Any continuous non-trivial homomorphism $\psi: G \to \mathbb{R}$ is necessarily a bijection and any continuous non-trivial homomorphism $\mathbb{R} \to G$ is injective and has dense image. Note that the first and third properties imply the second one, which in turn implies all the other properties besides the last one (that one can be assumed regardless though). I'm naturally quite convinced that a group with all these properties will have to be isomorphic to $\mathbb{R}$ , since they share way too many things in common (and property 3 itself is probably restrictive enough anyway), but I'm struggling really hard to deal with topological issues. In particular, the topology on G clearly contains the order topology induced by the rays $]a, b[$ but it doesn't seem at all obvious that they would have to be equal. I thought of trying to turn $G$ into a vector space over the real numbers through density of the rationals, but the problem is that if a sequence of rational numbers $y_n$ converges to a real number $y$ , the sequence $y_n \cdot x$ doesn't seem to have any reason to converge in $G$ , atleast in general. I'd appreciate any help on handling this.","['real-numbers', 'group-isomorphism', 'topological-groups', 'general-topology', 'rational-numbers']"
4765386,Basic Combinatorics Question from Article 1 of Lawvere's Conceptual Mathematics,"the question I am referring to is: ""Can you find a pair of maps $B \stackrel{f}{\longrightarrow} A \stackrel{g}{\longrightarrow} B$ for which $g \circ f = 1_B$ ?"" Where $A$ is a set of 3 distinct elements and $B$ is a set of 2 distinct elements. We are then asked to count the number of pairs of maps satisfying the above condition. This seems like a very basic question to me as there are 6 valid maps for $g$ , each of which may pair up with 2 options for $f$ giving 12 total pairs. However, online I have seen a number of sources give 6 as the answer to this question. Am I missing something obvious or are those other answers incorrect?","['elementary-set-theory', 'combinatorics', 'category-theory']"
4765392,Ill-Conditioned Model Error,"Problem : Consider a linear regression problem where we observe noisy observations, $$y=Xw^* + \epsilon,$$ where $X \in \mathbb{R}^{n\times d}$ represents the data matrix ( $n$ points and $d$ features), $w^*\in\mathbb{R}^n$ represents the ground truth, and $\epsilon \in \mathbb{R}^n$ represents some noise. Suppose $X$ is ill-conditioned (i.e. $\kappa(X)\gg 1$ ) and we take $\hat{w}=X^{-1}y$ as an estimate for $w^*$ . What can I say about this quantity? $$ \lVert \hat{w}-w^*\rVert_2$$ Thoughts : Well, following our nose we see $$ \lVert \hat{w}  - w^*\rVert_{2} = \lVert X^{-1}y - w^* \rVert_{2} = \lVert X^{-1}(Xw^* + \varepsilon) - w^*\rVert_{2}=\lVert X^{-1}\varepsilon \rVert_{2}.$$ With Cauchy-Schwarz, I can see (letting $\lambda_{\min}$ denote the smallest characteristic value of $X$ ) $$ \lVert \hat{w}  - w^*\rVert_{2}\leq \frac{1}{\lambda_{\min}}\lVert \varepsilon\rVert_2.$$ Question : I guess I'm lamenting the lameness of this upper bound. If $\lambda_{\min}\geq 1$ , then this actually isn't a bad estimate for $w^*$ right? Just because the condition number is high doesn't mean $\lambda_{\min}$ has to be tiny - it's just that it's tiny in comparison to $\lambda_{\max}$ . I guess the idea here is that this error could be large provided $\varepsilon$ is large in norm and/or $\lambda_{\min}$ is tiny? Is there a lower bound for this that's more interesting?","['statistics', 'linear-algebra', 'inequality']"
4765430,"If $m(E)=m_*(E_1)+m_*(E_2)$ , then $E_1$ and $E_2$ are measurable","Suppose $E$ is measurable with $m(E) \lt \infty$ , and $$E=E_1 \cup E_2 , E_1 \cap E_2 \text{is  empty}$$ Show that if $m(E)=m_*(E_1)+m_*(E_2)$ , then $E_1$ and $E_2$ are measurable. My attempt: Since $E_2=E-E_1$ , it suffice to prove $E_1$ is measurable . And for $E_1$ , since $m_*(E_1)\le m(E) \lt \infty$ , for any $\epsilon$ , we can find an open set $O$ such taht $E_1 \subset O$ and $m(O)-m_*(E_1) \lt \epsilon$ , but how to show that $m_*(O-E_1)\lt \epsilon$ ?","['lebesgue-measure', 'real-analysis']"
4765438,Can a well-defined function have a smaller codomain than range?,"If I define a function with a domain such that its range is bigger than its codomain, is it necessarily ill-defined? For example, consider $f: \mathbb{R} \rightarrow \mathbb{Z}\\ f(x) = x.$ Clearly, some values of $f(x)$ are not in the codomain; can I ignore/forbid these values by restricting the codomain to the integers, that is, can I allow the function to return outputs only when they are integers? Or would this function not be well-defined or, indeed, a function at all?",['functions']
4765444,Methods for Finding A Representative of Each Element in a Quotient Set $S/G$,"Question : Let $G$ be a group and $S$ be a $G$ -set. I am interested in finding a representative for each orbit in the quotient set $S/G$ , especially in cases with an infinite number of orbits, i.e., the size of $S/G$ is infinite. Are there any general techniques that can deal with this task? Thoughts : For a finite number of orbits, I can enumerate all orbits one by one and canonically select one representative for each orbit. A simple case is that $S$ forms a homogeneous space of $G$ possessing only a single orbit, e.g., I can choose the zero point for the $n$ -dimensional translation group $\mathbb{R}^n$ . I am stuck for an infinite number of orbits. The trivial idea is to find the invariants so elements in each orbit share one invariant, e.g., eigenvalues of symmetric matrices w.r.t. orthogonal group. However, that invariant might not belong to the orbit, so a representative cannot be selected. I am new to group theory :). Any insights, references, or suggestions for further reading would be greatly appreciated.","['general-topology', 'representation-theory', 'reference-request', 'group-theory']"
4765445,How does one show that the operator whose kernel is properly supported is a smoothing operator?,"Proposition 1.7 (Properly supported smoothing operators). $L^{-\infty}=$ smoothing operators. Given $A \in L^{-\infty}$ with properly supported amplitude $a \in S^{-\infty}\left(\Omega \times \Omega \times \mathbb{R}^n\right)$ $$
A u(x)=\int_{\mathbb{R}^n} \int_{\Omega} e^{i\langle x-y, \xi\rangle} a(x, y, \xi) u(y) d y d \xi=\int_{\Omega}(\underbrace{\int_{\mathbb{R}^n} e^{i\langle x-y, \xi\rangle} a(x, y, \xi) d \xi}_{k(x, y)}) u(y) d y
$$ Thus $$
A u(x)=\int_{\Omega} k(x, y) d y \quad \text { with } k \in C_{\text {proper }}^{\infty}(\Omega \times \Omega)
$$ What about the converse?
Given $k \in C_{\text {proper }}^{\infty}(\Omega \times \Omega)$ Is $A$ as above in $L^{-\infty}(\Omega)$ (1) Fix $\chi \in C_c^{\infty}\left(\mathbb{R}^n\right), \int_{\mathbb{R}^n} \chi=1, u \in \mathcal{E}(\Omega), x \in B \subset \subset \Omega$ (compact neighbourhood) $$
\begin{gathered}
L:=\pi_2\left(\pi_1^{-1}(B) \cap \operatorname{supp} k\right) \quad \text { compact! }\\
\end{gathered}
$$ $$
Au(x)=\int_L k(x, y) u(y) \int_{\mathbb{R}^n} \chi(\xi) e^{i\langle x-y, \xi\rangle} e^{-i\langle x-y, \xi\rangle} d \xi d y\\
=\int_{\mathbb{R}^n} \int_L e^{i\langle x-y, \xi\rangle} \underbrace{\left\{k(x, y) e^{-i\langle x-y, \xi\rangle} \chi(\xi)\right\}}_{a(x, y, \xi) \in S^{-\infty}\left(\Omega \times \Omega \times \mathbb{R}^n\right)} u(y) d y d \xi
$$ Im going through this proof of that an operator whose kernel is properly supported is a smoothing operator. Here properly supported means that the projections to each component are proper maps. Im not quite sure why we can restrict the area of integration to L, where a priori it should be over all of omega.","['microlocal-analysis', 'pseudo-differential-operators', 'analysis']"
4765466,Coefficients of a symmetric product of polynomials with root of unity,"For number $n\ge2$ , let $\xi$ be a primitive $n$ -th root of unity. The determinant of circulant matrix is a symmetric polynomial in $x_0,\dots,x_{n-1}$ $$f_n=\prod_{j=0}^{n-1}\sum_{i=0}^{n-1}ξ^{ij}x_i$$ so after expansion, all coefficients are integer. Is the following true? For prime number $n$ , all coefficients of $$f_n-\sum_{i=0}^{n-1}x_i^n$$ are divisible by $n$ . Using SageMath I verified it for $n=2,3,5,7$ . For $n=5$ : from sympy import symbols
x = symbols('x_:5')

f5 = prod(sum(exp(I*2*pi/5*j*i) * x[i] for i in (0..4)) for j in (0..4))
poly = expand(f5- sum(x[i]**5 for i in (0..4))).maxima_methods().rootscontract() output:
$-5x_{0} x_{1}^{3} x_{2} + 5x_{0}^{2} x_{1} x_{2}^{2} + 5x_{0}^{2} x_{1}^{2} x_{3} - 5x_{0}^{3} x_{2} x_{3} - 5x_{1} x_{2}^{3} x_{3} + 5x_{1}^{2} x_{2} x_{3}^{2} + 5x_{0} x_{2}^{2} x_{3}^{2} - 5x_{0} x_{1} x_{3}^{3} - 5x_{0}^{3} x_{1} x_{4} + 5x_{1}^{2} x_{2}^{2} x_{4} - 5x_{0} x_{2}^{3} x_{4} - 5x_{1}^{3} x_{3} x_{4} - 5x_{0} x_{1} x_{2} x_{3} x_{4} + 5x_{0}^{2} x_{3}^{2} x_{4} - 5x_{2} x_{3}^{3} x_{4} + 5x_{0} x_{1}^{2} x_{4}^{2} + 5x_{0}^{2} x_{2} x_{4}^{2} + 5x_{2}^{2} x_{3} x_{4}^{2} + 5x_{1} x_{3}^{2} x_{4}^{2} - 5x_{1} x_{2} x_{4}^{3} - 5x_{0} x_{3} x_{4}^{3}$ poly/5 in ZZ[x] output: True","['circulant-matrices', 'linear-algebra', 'roots-of-unity', 'symmetric-polynomials']"
4765475,"How to characterize the tangent space $T_f C^\infty(K, \mathbb{R}^n)$ and paths in $C^\infty(K, \mathbb{R}^n)$","Let $K \subset \mathbb{R}$ be compact. For any function $f \in C^\infty(K, \mathbb{R}^n)$ how would one characterize the tangent space $T_f C^\infty(K, \mathbb{R}^n)$ ? I am following a set of notes that says for any $f$ , $T_f C^\infty(K, \mathbb{R}^n)$ can be identified with the space of smooth sections of some pullback bundle. If this is true, how would one arrive to this conclusion? Why do sections of the pullback bundle appear? Secondly how would one define smooth paths in such a space?","['manifolds', 'tangent-spaces', 'smooth-manifolds', 'differential-geometry']"
4765544,$\alpha>0;\ a(n+1)\ $ is the least integer $>a(n)$ such that $\sum_{i=1}^{n+1} a(i) < \alpha.$,"Let $\alpha>0$ be any positive real number and let $k\ $ be any positive integer satisfying $k > \frac{1}{\alpha}\ $ Consider the integer sequence define by: $a(1)=k;\ $ and for $n\geq 1,\ a(n+1)\ $ is the least integer $>a(n)$ such that $\displaystyle\sum_{i=1}^{n+1} \frac{1}{a(i)} < \alpha.$ What is the (asymptotic) growth rate of $a(n)$ ? I would imagine exponential or maybe even along the lines of factorial, but I do not know how to study such sequences, although obviously I am interested in them. It's possible that this has to do with continued fractions, although I have never really understood continued fractions all that well, so I'm not really sure. Thanks in advance.","['convergence-divergence', 'diophantine-approximation', 'sequences-and-series']"
4765553,Integration of connected variable,"In my research, I am trying to Model an Ebby Current Braking system based on W. R. Smythe work ( On Eddy Currents in a Rotating Disk ) In this paper the Eddy Currents Torque can be estimated using the following integration: $$
T = \frac{\omega c b \gamma \Phi^2}{\pi^2 a^4} \times \int_{c-a}^{c+a} 
\left( r^2 \sin{\theta_1} - \frac{a^2 A^2 r^2 \sin{\theta_1}}{c^2 r^2 + A^4 - 2 A^2 r c \cos{\theta_1}} \right) dr
$$ where $\theta_1$ and $r$ are connected by the relation: $$
r^2 + c^2 — 2 r c \cos{\theta_1} = a^2
$$ Note that all parameters are constants with the exception of $\theta_1$ and $r$ So, I need some help in at least how the first term ( $r^2 \sin(\theta_1)$ ) is integrated.
My field is Mechanical Engineering and I think that I do not have enough mathematical background when it comes to integration of connected variables.","['integration', 'multivariable-calculus', 'calculus']"
4765593,"We take k-element sequences with values from the set $[n]$. For each, we find the smallest value, and then sum these. Why the sum $=1^k+...+ n^k$?","We consider all k-element sequences with values from the set $[n] = \{1,2 ,..., n \}$ . For each such list, we determine the smallest value, and then sum these values. Show that the sum is equal to: $$1^k + 2^k + 3^k + ... + n^k$$ Example, for $k = 2$ and $n = \{ 1,2 \}$ : In that case, get $4$ seqences. Those are: $11$ , $22$ , $12$ , $21$ . Therefore, we take smallest values from each of those $4$ sequences. These will be: $1,2,1,1$ . We sum them up and get $5$ . Why would that be the case? I know that there are $n^k$ k-element sequences with values from the set $[n]$ . From each of those we need to take the smallest value. It will be $1$ for $n^k - (n-1)^{k}$ of those sqeuences (we take all possible sequences and subtract those without any $1$ ). Therefore we have $(n^k - (n-1)^{k}) \cdot 1$ . For $2$ we have: $(n-1)^k - (n-2)^{k}$ sequences because we can take all possible sequences without $1$ and subtract those without any $1$ and $2$ And so on... Therefore we get: $$\big(n^k - (n-1)^{k} \big) \cdot 1 + \big( (n-1)^k - (n-2)^{k} \big) \cdot 2 + ... + \big( 1^k - 0^{k} \big) \cdot n$$ But that doesn't look like: $1^k + 2^k + 3^k + ... + n^k$ , so I don't know what to do...","['discrete-mathematics', 'sequences-and-series']"
4765603,Relation between topological and measurable subspaces,"Let $(X, \tau)$ be a topological subspace and let $\Sigma(\mathcal{C})$ denote the $\sigma$ -algebra generated by $\mathcal{C}$ . Suppose $E \in \Sigma(\tau)$ , and consider the topological structure: $$
\tau' = \{F \in P(E): \exists U \in \tau: F=U \cap E\}
$$ and the measurable structure: $$
M' = \{F \in P(E): \exists U \in \Sigma(\tau): F=U \cap E\}
$$ inherited by $E$ from $X$ . I would like to know what is the relation between $M'$ and $\Sigma(\tau')$ . It is clear that $\Sigma(\tau') \subseteq M'$ because if $F \in \tau'$ then $F=U \cap E$ for some $U \in \tau \subseteq \Sigma(\tau)$ so that $F \in M'$ , but what about the converse inclusion? As always, any comment or answer is much appreciated and let me know if I can explain myself clearer!","['general-topology', 'proof-writing', 'examples-counterexamples', 'measure-theory']"
4765614,Approximating a function of bounded variation function by a stepfunction obtained by averaging over measurable sets,"Inspired by this question, suppose that we have a function $f\in\mathrm{BV}([0,1])\cap L^1([0,1])$ , take a measurable partition $\mathcal P^N$ of $[0,1]=\bigcup_{i=1}^NI_i$ , and obtain a new function $f^N$ obtained by averaging over the sets $I_i$ : when $x\in I_i$ , $$f^N(x)=\frac1{|I_i|}\int_{I_i}f(y)\ \mathrm dy.$$ As in the linked question, we have $f^N\in L^1[0,1]$ , and if the mesh of the partition tends to $0$ when $N\to\infty$ , we can argue that $f^N\to f$ a.e. as $N\to\infty$ . I was wondering whether it is possible in this case to prove that $$\|f^N-f\|_{L^1[0,1]}\leq\|f\|_{TV}\mathrm{mesh}(\mathcal P^N),$$ though the approach of the linked question didn't seem to work here directly. I hope someone can help. EDIT: as Alex Ravsky's counterexample shows, we cannot just take $\mathcal P^N$ to be any measurable partition. Instead, let's assume that we have partitions of the form $0=t_0<t_1<\cdots<t_{n-1}<t_n=1$ of the unit interval in disjoint, consecutive intervals $[t_{k-1}, t_k)$ . In this case, I'm still wondering if the result holds. A similar bound is not hard to prove if we assume that the size of the smallest and largest set in the $N$ th partition do not differ by more than a factor $C$ , independent of $N$ . However, I'm particularly interested in not making that assumption.","['bounded-variation', 'measure-theory', 'analysis', 'real-analysis']"
4765635,"What is the difference between ""for all"" and ""there exists"" in set builder notation?","I'm having trouble with a specific example of set builder notation, and I'm hoping someone can help. Here's an example of what I am having trouble with: $$A = \{n \in \mathbb{N} : \exists x \in \mathbb{N} \text{ and } n=2^x\}$$ $$B = \{n \in \mathbb{N} : \forall x \in \mathbb{N} \text{ and } n=2^x\}$$ Both of these sets are supposed to be equivalent to set $S$ where $$S = \{...,\frac{1}{4},\frac{1}{2},1,2,4,...\}$$ My question is what is the difference between set $A$ and set $B$ ? Is one of the notations more accurate than the other?","['elementary-set-theory', 'quantifiers', 'notation']"
4765649,Is a full specification of a family of subsets also a full specification of the sigma-algebra it generates?,"Let $C$ be a family of subsets of $\Omega$ , and $G(C)$ the $\sigma$ -algebra generated by $C$ . Assume that $f \in C$ is a ""full specification"" for $C$ , meaning that for all $s \in C$ either $f \subseteq s$ or $f \subseteq \Omega \backslash s$ . Can we prove that is also a full specification for $G(C)$ (meaning that for all $s \in G(C)$ either $f \subseteq s$ or $f \subseteq \Omega \backslash s$ )? If so, how? Some extra background: it seems intuitively clear to me that this should be true. But I'm struggling to prove it rigorously. My issue is that I don't really understand what explicit recipe we use to calculate $G(C)$ . I know that it's something like $C$ together with everything obtained from $C$ via complements and countable unions"". But this definition still seems a bit vague. For example, is it enough to first take the closure of $C$ under countable unions, and then the closure of that larger family under complements? Or do I have to keep on going iteratively, taking unions, then complements, then unions, then complements? And then if so, is it enough to iterate a finite number of times, or a countable number of times, or might I need an uncountable number of these steps?",['measure-theory']
4765722,prove (or disprove) $\left|x^\top\left(\frac{x}{|x|^\frac{1}{2}}-\frac{y+x}{|y+x|^\frac{1}{2}}\right)\right|\le 3|x||y|^\frac{1}{2}$,"As stated in the title, I need help showing (or disproving) $$\left|x^\top\left(\frac{x}{|x|^\frac{1}{2}}-\frac{y+x}{|y+x|^\frac{1}{2}}\right)\right|\le 3|x||y|^\frac{1}{2}$$ for $x, y\in\mathbb{R}^N$ . Here, we take $|\cdot|$ to be the Euclidean norm and we interpret $\frac{x}{|x|^\frac{1}{2}}$ to be $0$ at $x=0$ . I have already shown it to be true for scalar x, y but I am having trouble proving (or disproving) it for the vector valued case. I tried several approaches including inducting on the dimension, finding scalars $\tilde{x}, \tilde{y}$ corresponding to $x$ and $y$ (with $|\tilde{x}|<|x|$ and $|\tilde{y}|<|y|$ ) and upper bounding the vector valued expression by the scalar one, but none of these approaches have really panned out for me. I even wrote a MATLAB script to look for a counter example but cannot find one so far. This problem is relevant to a research problem I am working on so any help would be appreciated. Thanks! (EDIT: it should be noted that it may possible one could improve the 3 with a smaller constant, but at the moment I can't find an optimal value. However, for my purposes showing the statement with any constant in place of the 3 will suffice)","['multivariable-calculus', 'linear-algebra', 'upper-lower-bounds', 'inequality']"
4765723,Need help evaluating double integral,"I need help calculating $I$ where: $$I = \iint_R\frac{dxdy}{\sqrt{1-x^2-y^2}} 
,\qquad R = \left\{ (x,y) \in \Bbb R^2 : x^2 + y^2 -x \le 0 , y \ge 0  \right\}$$ The possible answers are $\:\pi$ $\:2\pi-1$ $\:2\pi+2$ $\:\pi +1$ I have converted it to polar where I ended up with the integral: $$I = \int_0^\pi\int_0^{cos{\theta}}\frac{r}{\sqrt{1-r^2}}\:dr\:d\theta$$ I have tried evauluating it but the answer I get is: $\:\pi -2$ I took the following steps: $\int_0^{\cos\theta}\frac{r}{\sqrt{1-r^2}} ,\:u = 1-r^2,\: dr = \frac{-1}{2r}du$ $\int_0^{\cos\theta}\frac{r}{\sqrt{1-r^2}} =\int \frac{r}{\sqrt{u}}\frac{-1}{2r}du = \frac{-1}{2}\int\frac{1}{\sqrt{u}}du  = \frac{-1}{2}\left[2\sqrt{1-r^2} \right]_0^{\cos\theta} = -\sqrt{1-\cos^2\theta} \:\:+ 1 $ $-\sqrt{1-\cos^2\theta} \:\:+ 1  = 1 - \sin\theta$ $\int_0^\pi 1- \sin\theta \:d\theta = \int_0^\pi1\:d\theta + \int_0^\pi -\sin\theta \:d\theta$ $\int_0^\pi1\:d\theta = \pi$ $\int_0^\pi -\sin\theta \:d\theta = \left[ \cos\theta\right]_0^\pi = \cos(\pi) - \cos(0) = -2$ From steps 4, 5 and 6 we get $\:I = \pi -2$ Somewhere along these steps I have made a mistake and I can't find it.","['integration', 'multivariable-calculus', 'definite-integrals']"
4765774,"Conjugacy classes in $SL(2,q)$: where to find them in a particular book.","NB: This question is tagged with reference-request . It does not require the usual type of context. I am interested in what the conjugacy classes of $SL_2(q)$ are. They can be found in Remark 3 of Harris et al. 's, ""On Conjugacy Classes of $SL_2(q)$ ."" Here is said remark (letting $\mathcal{F}=\Bbb F_q$ ): We can describe the matrix representatives of conjugacy classes in $\mathcal{S}=SL(2,\mathcal{F})$ by four families of types ([6]): $\begin{pmatrix} r & 0 \\ 0 & r\end{pmatrix}$ , where $r\in\mathcal{F}$ and $r^2=1$ . $\begin{pmatrix} r & 0 \\ 0 & s\end{pmatrix}$ , where $r,s\in\mathcal{F}$ and $rs=1$ . $\begin{pmatrix} s & u \\ 0 & s\end{pmatrix}$ , where $s\in\mathcal{F}, s^2=1$ and $u$ is either $1$ or a non-square element of $\mathcal{F}$ , i.e. $u\in \mathcal{F}\setminus\{ x^2: x\in \mathcal{F}\}$ . $\begin{pmatrix} 0 & 1 \\ -1 & w\end{pmatrix}$ , where $w=r+r^q$ and $1=r^{1+q}$ for some $r\in \mathcal{E}\setminus\mathcal{F}$ , where $\mathcal{E}$ is a quadratic extension of $\mathcal{F}$ . That is, any conjugacy class $A^\mathcal{S}$ of $\mathcal S$ must contain one of the above matrices. Here [6] is G. James and M. Liebeck's, Representations and Characters of Groups , Cambridge mathematical textbooks, Cambridge University Press, 2001. My university library can lend me a physical copy of that book within a week (borrowing from a different library, which I believe might cost me a couple of quid); however, I only need this bit; further: it can get me a pdf of any given chapter of the second edition, that doesn't expire. Therefore, my question is: In which chapter of the second edition of said book can I find a proof of the conjugacy classes of $SL(2,q)$ ? This will save me time and money. Of course, you could provide the proof here, but it wouldn't be right asking for that without more context. The closest I could find is this MO post . EDIT: Now that I think about it, some alternatives of where to find a proof would be welcome too!","['matrices', 'group-theory', 'reference-request']"
4765827,"Suppose $v^T(A^{-1} - B^{-1})v\geq 0$ for any vector $v$, show that $u^T(B - A)u \geq 0$ for any vector $u$","Suppose $A$ and $B$ are $p\times p$ invertible, symmetric matrices with positive eigenvalues (i.e., positive definite) and that $$v^T(A^{-1} - B^{-1})v\geq 0$$ for any vector $v \in \mathbb{R}^p$ . How can I show that $$u^T(B - A)u \geq 0$$ for any vector $u \in \mathbb{R}^p$ ? Since $u^TBu$ and $u^TAu$ are scalars, I was hoping to take the inverse, i.e., $\frac{1}{u^TBu}$ and $\frac{1}{u^TAu}$ and relate them to $A^{-1}$ and $B^{-1}$ somehow. But I'm not sure how to go about this.","['matrices', 'inequality', 'linear-algebra']"
4765885,Diagonal submatrices of the inverse of a $p \times p$ block matrix,"Let $X$ be a square, symmetric, positive definite matrix that can be decomposed into $p\times p$ block matrices: $$X = \begin{bmatrix} X_{11} & X_{12} & \ldots & X_{1p}\\
X_{21} & X_{22} & \ldots & X_{2p}\\
\vdots & \vdots & \ddots & \vdots \\
X_{p1} & X_{p2} & \ldots & X_{pp}
\end{bmatrix}$$ Let $Y$ denote the inverse of $X$ that consists of $p \times p$ submatrices: $$Y = X^{-1} = \begin{bmatrix} Y_{11} & Y_{12} & \ldots & Y_{1p}\\
Y_{21} & Y_{22} & \ldots & Y_{2p}\\
\vdots & \vdots & \ddots & \vdots \\
Y_{p1} & Y_{p2} & \ldots & Y_{pp}
\end{bmatrix}$$ I would like to write the diagonal submatrices $Y_{ii}$ for $1 \leq i \leq p$ as a function of the submatrices in $X$ . $\bf{p =2}$ case: Since $X_{11}, X_{22}$ are positive definite (and invertible), then $$Y = \begin{bmatrix} (X_{11} - X_{12}X_{22}^{-1}X_{21})^{-1} & -(X_{11}-X_{12}X_{22}^{-1} X_{21})^{-1}X_{12}X_{22}^{-1} \\
-(X_{22} - X_{21} X_{11}^{-1} X_{12})^{-1} X_{21}X_{11}^{-1} & (X_{22}-X_{21} X_{11}^{-1} X_{12})^{-1} \end{bmatrix}$$ so $Y_{11} = (X_{11} - X_{12}X_{22}^{-1}X_{21})^{-1}$ $Y_{22} = (X_{22}-X_{21} X_{11}^{-1} X_{12})^{-1}$ $\bf{p =3}$ case: Since $X_{11}, X_{22}, X_{33}$ are positive definite (and invertible), then (if my math is right) we have the following $Y_{11} = ((X_{11} - X_{13}X^{-1}_{11}X_{31}) - (X_{12}-X_{13}X^{-1}_{33}X_{32})(X_{22}-X_{23}X^{-1}_{33}X_{32})^{-1}(X_{21}-X_{23}X^{-1}_{33}X_{31}))^{-1}$ $Y_{22} = ((X_{22} - X_{21}X^{-1}_{11}X_{12}) - (X_{23}-X_{21}X^{-1}_{11}X_{13})(X_{33}-X_{31}X^{-1}_{11}X_{13})^{-1}(X_{32} - X_{31}X^{-1}_{11}X_{12}))^{-1}$ $Y_{33} = ((X_{33}-X_{31}X^{-1}_{11}X_{13}) - (X_{32}-X_{31}X^{-1}_{11}X_{12})(X_{22}-X_{21}X^{-1}_{11}X_{12})^{-1}(X_{23}-X_{21}X^{-1}_{11}X_{13}))^{-1}$ For the general $p \times p$ case, is it possible to write $$Y_{ii} = (Z_{ii})^{-1}$$ where $Z_{ii}$ can be written as a function of the submatrices in $X$ ? Would $Z_{ii}$ be a Schur complement of some sort?","['matrices', 'linear-algebra', 'positive-definite', 'block-matrices']"
4765917,"Generalized notion of perpendicularity, (not orthogonal)","In 3 dimensions, we might call 2 planes perpendicular iff their normals are orthogonal. But this does not coincide with the definition of orthogonal subspaces - the dot product of any pair of vectors is $0$ . Is there a notion of perpendicularity any text introduces, generalising in $\mathbb R^n$ the perpendicular planes in $\mathbb R^3$ ? For example - I was thinking if we had two subspaces be ""perpendicular"" iff they are not parallel and are the sides of some $n$ -cube.","['orthogonality', 'linear-algebra', 'affine-geometry']"
4765923,Finding solution without solving differential equation,"I was trying to solve a physics problem and the equation I came up with was: $$F-2kx(t)=mx''(t)$$ It is given that $x(0)=0$ and $x'(0)=0$ , and my target is to find the extrema values of $x(t)$ Solving the differential equation: $$x(t)=c_2\sin{\left(\sqrt{\frac{2k}{m}}t\right)}+c_1\cos{\left(\sqrt{\frac{2k}{m}}t\right)}+\frac{F}{2k}$$ Putting in the given conditions, $c_2=0$ and $c_1=-\frac{F}{2k}$ , so: $$x(t)=\frac{F}{2k}\left(1-\cos{\left(\sqrt{\frac{2k}{m}}t\right)}\right)$$ Finding the extrema values: $$x_{min}=0$$ $$x_{max}=\frac{F}{k}$$ Now my question is: Is it possible to find the extrema values of $x(t)$ using only the given differential equation and the 2 conditions, but without actually solving the differential equation? NOTE:
The actual question that I simplified down to come up with the equation: I used the relative acceleration of the right block with respect to the left one to create the equation.","['physics', 'ordinary-differential-equations']"
4765969,"Let $c_k\ge0$ be a sequence which is bounded above and bounded away from $0$. Prove that $\lim 1/n\sum\limits_{k=1}^n c_kz^k=0$ for $|z|\le1,z\ne1$","Let $m,M>0$ be such that $m\le c_k\le M$ for all $k$ . If $|z|<1$ , then $|c_kz^k|\le M|z|^k\to 0$ . Then we have $$\lim\limits_{n\to\infty}\frac{1}{n}\sum\limits_{k=1}^n c_k z^k=0$$ But I cannot show for $|z|=1$ . If $c_k=c$ is a constant sequence. Then $\frac{1}{n}\sum\limits_{k=1}^n c_k z^k=c\frac{z(z^n-1)}{n(z-1)}\to0$ as $z\ne1$ and $|z|=1$ . Can anyone help with any idea or hint for the problem? Thanks for your help in advance.","['limits', 'sequences-and-series', 'analysis', 'real-analysis']"
4765979,"Conjecture: If matrix $M$ has entries (left to right, then top to botom) $\sin 1,\sin 2,\sin 3,\dots,\sin (n^2)$, where $n\ge 3$, then $\det M = 0$.","According to my calculator, $\det\begin{bmatrix}\sin 1 & \sin 2 & \sin 3 \\ \sin 4 & \sin 5 & \sin 6 \\ \sin 7 & \sin 8 & \sin 9\end{bmatrix}=0$ $\det\begin{bmatrix}\sin 1 & \sin 2 & \sin 3 & \sin 4 \\ \sin 5 & \sin 6 & \sin 7  & \sin 8 \\ \sin 9 & \sin 10 & \sin 11 & \sin 12 \\ \sin 13 & \sin 14 & \sin 15 & \sin 16 \end{bmatrix}=0$ $\det\begin{bmatrix}\sin 1 & \sin 2 & \sin 3 & \sin 4 & \sin 5 \\ \sin 6 & \sin 7 & \sin 8  & \sin 9 & \sin 10 \\ \sin 11 & \sin 12 & \sin 13 & \sin 14  & \sin 15 \\ \sin 16 & \sin 17 & \sin 18 & \sin 19  & \sin 20 \\ \sin 21 & \sin 22 & \sin 23 & \sin 24 & \sin 25\end{bmatrix}=0$ I conjecture that, for $n\ge 3$ , $\det \begin{bmatrix} \sin 1 & \sin 2 & \sin 3 & \dots & \sin n \\ \sin (n+1) & \sin (n+2) & \sin (n+3) & \dots & \sin (2n) \\ \sin (2n+1) & \sin (2n+2) & \sin (2n+3) & \dots & \sin(3n) \\ \vdots & \vdots & \vdots & \vdots & \vdots \\ \sin ((n-1)n+1) & \sin ((n-1)n+2) & \sin ((n-1)n+3) & \dots & \sin (n^2) \end{bmatrix}=0$ Is my conjecture true? I have only been able to prove the case with $n=3$ . $\sin 5 + \sin 7 + [\sin 1 + \sin (-1)] + [\sin 3 + \sin (-3)]$ $=\sin 5 + \sin 7 + [\sin 1 + \sin (-1)] + [\sin 3 + \sin (-3)]$ Rearrange each side: $[\sin (-3) + \sin 5] + [\sin 1 + \sin 3] + [\sin (-1) + \sin 7]$ $=[\sin (-1) + \sin 3] + [\sin (-3) + \sin 7] + [\sin 1 + \sin 5]$ Use the product-to-sum formulas : $(\sin 1)(\cos 4) + (\sin 2)(\cos 1) + (\sin 3)(\cos 4)$ $=(\sin 1)(\cos 2) + (\sin 2)(\cos 5) + (\sin 3)(\cos 2)$ Subtract $(\sin 1)(\cos 14)+(\sin 2)(\cos 13)+(\sin 3)(\cos 12)$ from both sides: $(\sin 1)(\cos 4 - \cos 14) + (\sin 2)(\cos 1 - \cos 13) + (\sin 3)(\cos 4 - \cos 12)$ $=(\sin 1)(\cos 2 - \cos 14) + (\sin 2)(\cos 5 - \cos 13) + (\sin 3)(\cos 2 - \cos 12)$ Use the product-to-sum formulas again: $(\sin 1)(\sin 5)(\sin 9)+(\sin 2)(\sin 6)(\sin 7)+(\sin 3)(\sin 4)(\sin 8)$ $=(\sin 1)(\sin 6)(\sin 8)+(\sin 2)(\sin 4)(\sin 9)+(\sin 3)(\sin 5)(\sin 7)$ which is equivalent to $\det\begin{bmatrix}\sin 1 & \sin 2 & \sin 3 \\ \sin 4 & \sin 5 & \sin 6 \\ \sin 7 & \sin 8 & \sin 9\end{bmatrix}=0$","['conjectures', 'determinant', 'matrices', 'linear-algebra', 'trigonometry']"
4766063,Leibniz integral rule for an arbitrary number of dimensions,"Suppose we have $N$ particles whose coordinates are given by $\mathbf{r}_{i}$ . These coordinates are confined to be within a three-dimensional unit cell defined by $$\mathcal{V}=\left[0,L_{x}\right]\times\left[0,L_{y}\right]\times\left[0,L_{z}\right]$$ (For simplicity, we may assume $L_{x}=L_{y}=L_{z}\equiv L$ ). We shall also assume periodic boundary conditions, i.e., for example, $f\left(x_i=0\right)=f\left(x_i=L_{x}\right)$ (and same for the other Cartesian components and particles). Consider the integral $$
I = \int_{\Omega}dR\;f\left(R,t\right)
$$ where $R$ represents the collection of coordinates $\mathbf{r}_1,\dots,\mathbf{r}_N$ and $dR=d\mathbf{r}_{1}\dots d\mathbf{r}_{N}$ . The volume of integration $\Omega$ is essentially the hyper-volume $\mathcal{V}^{N}$ formed by the unit cell $\mathcal{\mathcal{V}}$ . Now, suppose we perform the change of coordinates $\bar{\mathbf{r}}_{i}=c\left(t\right)\mathbf{r}_{i}$ , where $c\left(t\right)$ is some function of $t$ . For example, $\bar{\mathbf{r}}_{i}=t^{\alpha}\mathbf{r}_{i}$ , where $\alpha$ is some constant. I would like to calculate the derivative of the transformed $I$ with respect to $t$ , i.e., $$\frac{d}{dt}\int_{\bar{\Omega}\left(t\right)}d\bar{R}\;f\left(\bar{R},t\right) J(t)$$ where the transformed quantities are marked with a bar, and $J(t)$ is the Jacobian term that results from the change of coordinates. Note that after this substitution, the volume of integration depends on $t$ , because $\bar{\mathcal{V}}=\left[0,c(t) L_{x}\right]\times\left[0,c(t) L_{y}\right]\times\left[0, c(t) L_{z}\right]$ . According to Leibniz integral rule, $$\frac{d}{dt}\int_{\bar{\Omega}\left(t\right)}d\bar{R}\;f\left(\bar{R},t\right)J(t)=\int_{\bar{\Omega}\left(t\right)}d\bar{R}\;\frac{\partial}{\partial t}\left[f\left(\bar{R},t\right)J(t)\right]+\underbrace{\int_{\partial\bar{\Omega}\left(t\right)}f\left(\bar{R},t\right)J(t)\;U\cdot d\mathbf{\Sigma}}_{\text{boundary term}}$$ where $\partial\bar{\Omega}\left(t\right)$ is the boundary of the integration hyper-volume, $U$ is the velocity of the boundary (rate of change with $t$ ) and $d\mathbf{\Sigma}$ is a surface element. However, I have trouble evaluating $U\cdot d\mathbf{\Sigma}$ even for the simple cubic geometry provided here. For example, I am unsure how to calculate $U$ , or how to properly account for the orientation of the surface element.","['integration', 'multivariable-calculus', 'leibniz-integral-rule']"
4766168,Does problem 2-9 of Spivak's Calculus on Manifolds contain an error?,"In Michael Spivak's Calculus on Manifolds , problem 2-9, part (a) on page 18 reads as follows: Two functions $f,g:\mathbb R\to\mathbb R$ are equal up to $\mathbf n$ th order at $a$ if $$
\lim_{h\to 0}\frac{f(a+h)-g(a+h)}{h^n}=0
$$ a) Show that $f$ is differentiable at $a$ if and only if there is a function $g$ of the form $g(x)=a_0+a_1(x-a)$ such that $f$ and $g$ are equal up to first order at $a$ . As written, I think the ""if"" direction is false. For instance, take $a=0$ , and define $f(x)$ as $x$ for $x\neq0$ , and as $1$ for $x=0$ . Then, $f$ is obviously not differentiable at $0$ , but $f$ and the identity function are equal up to first order at $0$ . Question: is my objection correct? If so, I think the problem can be repaired by requiring continuity. If $a\in\mathbb R$ , $f:\mathbb R\to\mathbb R$ is continuous at $a$ , and there is an affine map $g$ such that $f$ and $g$ are equal up to first order, then I believe it follows that $f$ is differentiable at $a$ .","['multivariable-calculus', 'real-analysis']"
4766171,"Suppose $f:[0,\infty) \to \mathbb R$ is continuous and differentiable with $f(0)=0$ and $f'$ is increasing. Show that $g(x)$ is increasing.","First Question: Show that $\displaystyle \frac{f(x)}{x} < f'(x)$ for $\forall 0<x$ My attempt: Clearly, $f$ is satifying conditions of mean value theorem. So, apply MVT to $f$ on $[0,x]$ . We get $$\frac {f(x)-f(0)}{x-0} =\frac {f(x)}{x} = f'(c)$$ for some $c \in (0,x)$ .
And we know that $f'$ is increasing so for some $d$ such that $c<d$ we have $f'(c)<f'(d)$ . Hence we obtain $$\frac {f(x)}{x} < f'(d) $$ My FIRST question is how can I move into $f'(x)$ instead of having $f'(d)$ . Second Question: Suppose $f:[0,\infty) \to \mathbb R$ is continuous and differentiable  with $f(0)=0$ and derivative of $f$ is increasing. Show that $g(x)$ is increasing. $$
g(x):=\begin{cases}
 \frac {f(x)}{x}& \text{ if } x>0\\ 
 f'(0)& \text{ if } x= 0
\end{cases}$$ First I am really sorry that I couldn't write $g(x)$ as piecewise function. My attemp for second question: I need to show that if $x_1 < x_2 $ then $g(x_1)<g(x_2)$ . If $x_1=0$ then obviously $g(0)=f'(0)$ and since $0<x_2$ then $f'(0) < f'(x_2)$ so it is increasing. Now, I know that I have to show $\displaystyle \frac {f(x_1)}{x_1} <\frac {f(x_2)}{x_2}$ Pick $x_1 > 0$ then $g(x_1)=\displaystyle \frac {f(x_1)}{x_1} < f'(x_1) $ That is where I stuck. Could you help?","['calculus', 'derivatives']"
4766197,Extension of functions with bounded derivatives,"Consider an analytic function $f:\mathbb{R}^n\to\mathbb{R}$ . Let $A\subset\mathbb{R}^n$ be a closed set and let $L$ be a positive constant such that $\|\nabla f(x)\|\le L$ for all $x\in A$ , where $\nabla f$ is the gradient of $f$ and $\|{\cdot}\|$ is a norm. I wonder whether there exists a function $F:\mathbb{R}^n\to\mathbb{R}$ such that $(1)$ $F\in C^1(\mathbb{R}^n)$ ; $(2)$ $F(x)=f(x)$ for all $x\in A$ ; $(3)$ $\|\nabla F(x)\|\le L$ for all $x\in\mathbb{R}^n$ . In other words, $F$ extends condition $(3)$ from $A$ to $\mathbb{R}^n$ with or without analyticity.","['multivariable-calculus', 'derivatives', 'real-analysis']"
4766207,In which conditions the limit of an infinite sum is equal to the infinite sum of the limits?,"Let $X \neq \varnothing$ be a set, $\{x_k\}_{k\in \Bbb{N}} \subset X$ and $\{f_n : X \hookrightarrow[0,\infty]\}_{n\in \Bbb{N}}$ such that $\forall n \in \Bbb{N} \, \forall x \in X : f_n(x) \leq f_{n+1}(x)$ . I want to know in which conditions $$\sum_{k\in \Bbb{N}} \lim_{m \rightarrow \infty} f_m(x_k) = \lim_{m \rightarrow \infty} \sum_{k\in \Bbb{N}} f_m(x_k)$$ My attempt guides me to the following by knowing that the limit of a increasing sequence is greater than all the elements of the sequence: $$\forall n \in \Bbb{N} \, \forall x \in X : f_n(x) \leq f_{n+1}(x) \Rightarrow \forall n,k \in \Bbb{N} : f_n(x_k) \leq f_{n+1}(x_k) \Rightarrow \forall n,k \in \Bbb{N}:f_n(x_k) \leq \lim_{m \rightarrow \infty} f_m(x_k) \Rightarrow \forall n \in \Bbb{N}:\sum_{k\in \Bbb{N}} f_n(x_k) \leq \sum_{k\in \Bbb{N}} \lim_{m \rightarrow \infty} f_m(x_k) \Rightarrow \lim_{m \rightarrow \infty} \sum_{k\in \Bbb{N}} f_m(x_k) \leq \sum_{k\in \Bbb{N}} \lim_{m \rightarrow \infty} f_m(x_k) $$ I don't know if the other inequality is true, neither which conditions should make it true. Any possible answers would be appreciated.","['convergence-divergence', 'measure-theory', 'sequences-and-series', 'real-analysis']"
4766226,Spinors in Spin Geometry,"First of all I am a physicist with a decent knowledge of graduate-level geometry.
I'm studying Spin Geometry from Bär Lecture Notes and I have some trouble understanding what spinors are from his definition. I'll recap some information here to avoid the needing of reading the lecture notes. Given a vector space $V$ and a symmetric bilinear form $\beta$ we build the Clifford algebra $Cl(V,\beta)$ with Clifford product $\cdot_C$ Given an algebra homomorphism $\phi: Cl(V,\beta) \rightarrow Cl(V,\beta)$ This splits the algebra as: $Cl(V,\beta) = Cl^0(V,\beta) \oplus Cl^1(V,\beta)$ With $Cl^0(V,\beta)$ the +1 eigenspace of $\phi$ and $Cl^1(V,\beta)$ the -1 eigenspace of $\phi$ Now i will choose $V = \mathbb{R}^n$ because it's the most straight forward vector space to work with. Then he defines the Pin and Spin groups as: $$Pin(n) = \{v_1 \cdot_C ... \cdot_C \; v_m \in Cl(\mathbb{R}^n) | v_i \in S^{n-1} \; , \; m\in \mathbb{N}_0 \}$$ And $$Spin(n) = Pin(n)\cap Cl^0(\mathbb{R}^n,\beta) $$ So to my understanding, $Pin(n)$ is the group built multiplying a number $m$ of unitary elements of $\mathbb{R}^n$ while $Spin(n)$ is built only with an even amount of multiplications. For $n=2m$ he defines 2 quantities: $$z_j = (e_{2j-1}-ie_{2j})/2 $$ $$\bar{z}_j = (e_{2j-1}+ie_{2j})/2 $$ To me this seems the basis, split into right-handed and left-handed, for the complexified version of $\mathbb{R}^n$ but I'm not sure if it is the case. Now the questions. Question 1 He defines: $$z(j_1, ..., j_k) = z_{j_1} \cdot_C \; ... \cdot_C\; z_{j_k} \cdot_C\; \bar{z}_1 \cdot_C\;...\cdot_C\;\bar{z}_m$$ What does this quantity represent?
What is it? An explanation in geometrical terms would be awesome Question 2 He defines: $$\Sigma_n^\pm = span\{z(j_1, ..., j_k) | k=0, ..., m \; j_i \; ordered\}$$ With $+$ for even $m$ and $-$ for odd $m$ He calls elements of such a space spinors, left and right-handed. How do these elements relate to the ""complex vector-type"" of spinors usually encountered in physics and to the $Spin(n)$ group above? Those should be the mathematical counterpart of the physics Weyl spinors, but I can't see how it is possible to recover them.","['abstract-algebra', 'spin-geometry', 'mathematical-physics', 'clifford-algebras']"
4766235,Convention - remove parentheses of n-tuple in function evaluation,"Let $f \colon X^2 \to Y$ where $X, Y$ are two sets. For $x_1, x_2 \in X$ I can write $f((x_1, x_2))$ .
But can I remove the parentheses, i.e. $f(x_1, x_2)$ ? If yes, can I generalise on the cartesian product?
My question is a little bit tricky because the cartesian product on sets is not associative.
For example, if $g \colon X^2 \times Y \to Z$ , for $x_1, x_2 \in X, y \in Y$ can I write $g(x_1, x_2, y)$ or because of the non-associativity of the cartesian product on sets must I write $g((x_1, x_2), y)$ ? Any advice on mathematical writing conventions for this text is appreciated!","['elementary-set-theory', 'functions']"
4766237,Parametric Equation of an $(n-2)$-Sphere in n-Dimensional Space on the Hyperplane $x_1 + x_2 + ... + x_n = 0$,"Given a circle in a 3D space centered on the plane $x+y+z=0$ , its parametric equation can be represented as: $$
\left( \sqrt{\frac{1}{2}}\cos(t) + \sqrt{\frac{1}{6}}\sin(t), -\sqrt{\frac{1}{2}}\cos(t) + \sqrt{\frac{1}{6}}\sin(t), -\sqrt{\frac{2}{3}}\sin(t) \right)
$$ where $t \in [0, 2\pi]$ . This equation is derived using two orthogonal unit vectors, $v_1$ and $v_2$ , lying in the plane $x+y+z=0$ . However, I am finding difficulties in generalizing this to higher dimensions. Specifically: How can one describe a parametric equation for an (n-2) dimensional
sphere in an n-dimensional space if that sphere is centered on the
hyperplane defined by $x_1 + x_2 + ... + x_n = 0$ ? Any insights or pointers would be greatly appreciated! p.s. Visualization for better understanding of the circle talked about above:","['euclidean-geometry', 'spheres', 'geometry', 'metric-spaces']"
4766245,Understanding the proof of the Brezis-Lieb lemma,"I am trying to understand the proof of the Brezis-Lieb lemma from the Wikipedia page: https://en.wikipedia.org/wiki/Brezis%E2%80%93Lieb_lemma Here is the statement of said lemma: Let $(X, \mu)$ be a measure space and let $(f_n)_n$ be a sequence of measurable complex-valued functions on $X$ which converge almost everywhere to a function $f$ . The limiting function $f$ is automatically measurable. The Brezis–Lieb lemma asserts that if $p$ is a positive number, then $$\lim _{n\to \infty }\int _{X}{\Big |}|f|^{p}-|f_{n}|^{p}+|f-f_{n}|^{p}{\Big |}\,d\mu =0$$ provided that the sequence $(f_n)_n$ is uniformly bounded in $L^p(X, \mu)$ . So I am uncertain about this last line of this proof. Specifically, why is the supremum finite? This is essentially saying that for all $n$ , the integral is finite correct? But that would imply that $f-f_n$ is in $L^p$ which would imply $f$ is in $L^p$ which is not true in general since all we know is that $f_n$ converges pointwise to $f$ .","['proof-explanation', 'measure-theory', 'analysis', 'real-analysis']"
4766259,Exercise 2 Stanley combinatorics volume 1: Bijective proof of a sum equality,"Let $S$ be a finite set of objects and let $\mathscr{P}$ be a finite set of properties that the elements of $S$ may or may not satisfy. Given a subset of properties $X$ , I define $f_=(X)$ as the number of elements of $S$ that satisfy exactly the properties $X$ and $f_\geq  (X)$ as the number of element of $S$ satisfying at least the properties $X$ . I have to give a bijective proof of the following equality $$\sum_{X\subseteq \mathscr{P}} f_=(X)x^{\# X}= \sum_{X\subseteq \mathscr{P}} f_\geq (X)(x-1)^{\# X} $$ but I’m a bit lost. I’m trying to interpret the monomial $x^{\# X}$ as the number of functions $X\to [x]$ . Is this the right idea?","['inclusion-exclusion', 'combinatorics', 'combinatorial-proofs', 'discrete-mathematics']"
4766351,Conjugation Functor from a Groupoid to $\mathbf{Grp}$,"Take a groupoid $\mathcal{C} \in \mathbf{Grpd}$ . It's possible to construct a conjugation functor $F_{\mathcal{C} } : \mathcal{C} \to \mathbf{Grp}$ as follows: For every object $x \in \text{ob}(\mathcal{C})$ , $F_{\mathcal{C} }(x) = \text{Hom}_{\mathcal{C} }(x, x)$ considered as a group. This is the standard way to think of groups as one-object groupoids. For every morphism $f : x \to y$ , the corresponding group homomorphism $F_{\mathcal{C} }(f) : \text{Hom}_{\mathcal{C} }(x, x) \to \text{Hom}_{\mathcal{C} }(y, y)$ is constructed by conjugation . Specifically, $F_{\mathcal{C} }(f)(g) = f \circ g \circ f^{-1}$ for $g \in \text{Hom}_{\mathcal{C} }(x, x)$ . Here it's important that $\mathcal{C}$ is a groupoid so that $f^{-1} : y \to x$ exists (and is unique). This can be verified to be a functor. But there's more. Take a groupoid morphism $G : \mathcal{C}_1 \to \mathcal{C}_2$ between two groupoids in $\mathbf{Grpd}$ . It turns out that there always exists a natural transformation $\eta^G : F_{\mathcal{C}_1} \to F_{\mathcal{C}_2} \circ G$ . This is constructed by seeing that $G$ turns $\text{Hom}_{\mathcal{C}_1}(x, x)$ into a subset of $\text{Hom}_{\mathcal{C}_2} (G(x), G(x))$ , and $G$ being a groupoid morphism (so a functor between $\mathcal{C}_1$ and $\mathcal{C}_2$ ) means that this is a group homomorphism. And it turns out this group homomorphism makes the appropriate diagrams for a natural transformation commute. Furthermore, these natural transformations ""play nicely with each other"", in the sense that if $G : \mathcal{C}_1 \to \mathcal{C}_2$ and $H : \mathcal{C}_2 \to \mathcal{C}_3$ are groupoid morphisms, then $\eta^{H \circ G} = (\eta^H G) \circ \eta^G$ , the composition of the natural transformations (using whiskering). This kind of looks like the chain rule. My question is - what sort of object is $F$ ? Is there some category-theoretic name for it? I tried looking into 2-categories. $\mathbf{Cat}$ is the prototypical example - here, objects are categories, morphisms are functors, and 2-morphisms are natural transformations. $\mathbf{Grpd}$ works naturally as a subcategory of this. But in a sense, I want something ""1 level down"" - the objects here aren't really the groupoids, but the objects of the groupoids . The morphisms are just the morphisms within the groupoids, and the 2-morphisms would be the functors between groupoids. The natural transformations between functors don't really show up here. So I'm not sure if this is related to 2-categories or not. EDIT: As suggested by @ZachGoldthorpe, I'll put some details of why I wanted to use $F$ . The fundamental groupoid can be shown to work as a functor $\pi_1 : \mathbf{Top} \to \mathbf{Grpd}$ , which sends a topological space $X$ to the groupoid $\pi_1(X)$ , where: The objects of $\pi_1(X)$ are pairs $(X, x_0)$ for a point $x_0 \in X$ The morphisms of $\pi_1(X)$ are homotopy classes of paths $[\gamma] : (X, x_0) \to (X, x_1)$ for $\gamma$ a path connecting $x_0$ and $x_1$ . Morphism composition is given by path concatenation, identity morphisms are constant paths, and inverse morphisms are given by ""following the path backwards"". Additionally, it sends a continuous map $f : X \to Y$ to a functor $\pi_1(f) : \pi_1(X) \to \pi_1(Y)$ that: Takes in an object $(X, x_0) \in \text{ob}(\pi_1(X))$ and sends it to $(Y, f(x_0)) \in \text{ob}(\pi_1(Y))$ . Takes in a morphism $[\gamma] : (X, x_0) \to (X, x_1)$ and sends it to $[f \circ \gamma] : (Y, f(x_0)) \to (Y, f(x_1))$ . The usefulness of $F$ comes from applying $\pi_1$ and then $F$ : The objects $(X, x_0)$ of $\pi_1(X)$ , under $F_{\pi_1(X)}$ , become the fundamental groups $\pi_1(X, x_0)$ of $X$ with basepoint $x_0$ The morphisms $[\gamma] : (X, x_0) \to (X, x_1)$ of $\pi_1(X)$ under $F_{\pi_1(X)}$ become the isomorphisms between fundamental groups $[\gamma]_{\#} : \pi_1(X, x_0) \to \pi_1(X, x_1)$ which sends a loop $[u] \in \pi_1(X, x_0)$ to the loop $[\gamma^{-1} . u . \gamma ] \in \pi_1(X, x_1)$ . Note that path concatenation notation here means you follow $\gamma^{-1}$ first. The functors between groupoids $\pi_1(f) : \pi_1(X) \to \pi_1(Y)$ (from a continuous map $f : X \to Y$ ) become natural transformations $\eta^f$ which make the following diagrams commute: Here $u$ is a (homotopy class of) path(s) connecting $x_0$ to $x_1$ , with $f \circ u$ the corresponding path(s) connecting $f(x_0)$ and $f(x_1)$ . And $f_*$ is the usual homomorphism from $\pi_1(X, x_0)$ to $\pi_1(Y, f(x_0))$ sending a homotopy class of loops $[\gamma]$ to $[f \circ \gamma]$ . This is recognised as the diagram that relates how the group homomorphism $f_*$ between the fundamental groups of $X$ and $Y$ play with the isomorphisms between fundamental groups at different basepoints via paths connecting the basepoints. The properties of $F$ ensure that commutative squares of this type can be composed: Vertically, via composition of morphisms in $\pi_1(X), \pi_1(Y)$ combined with the fact that $F_{\pi_1(X)}, F_{\pi_1(Y)}$ are functors to $\mathbf{Grp}$ Horizontally, by the consistency condition $\eta^{H \circ G} = (\eta^H G) \circ \eta^G$ . Indeed, the ""horizontal"" composition of such commutative squares expresses the fact that the fundamental group functor $\pi_1 : \mathbf{Top}^* \to \mathbf{Grp}$ sending a pointed topological space $(X, x_0)$ to $\pi_1(X, x_0)$ works as a functor - the morphisms of $\mathbf{Top}^*$ become precisely these natural transformation morphisms. In a sense, the fundamental group functor only cares about the ""top edge"" of the commutative square, and doesn't a priori know about the compatibility with paths.","['groupoids', 'higher-category-theory', 'category-theory', 'group-theory', 'natural-transformations']"
4766371,How should I find the nontrivial solution to this differential equation using the method of undetermined coefficients?,"Find the nontrivial solution of this differential equation $x^2\frac{d^2y}{dx^2}+3x\frac{dy}{dx}+5y=8x, y(1)=2, y(exp(\pi/4))=2sinh(\pi/4).$ Here's my work: Consider the differential equation $x^2\frac{d^2y}{dx^2}+3x\frac{dy}{dx}+5y=8x, y(1)=2, y(exp(\pi/4))=2sinh(\pi/4).$ The corresponding homogeneous equation is $x^2\frac{d^2y}{dx^2}+3x\frac{dy}{dx}+5y=0.$ Its characteristic equation is $r(r-1)+3r+5=0,$ so $r=-1\pm 2i.$ Now we have $y_{h}(x)=e^{-x}(c_{1}cos(2x)+c_{2}sin(2x)).$ Note that $y_{p}=Ax+B, y_{p}'=A, y_{p}''=0.$ Observe that $x^{2}y_{p}''+3xy_{p}'+5y_{p}=8x$ $x^2(0)+3x(A)+5(Ax+B)=8x$ $3Ax+5Ax+5B=8x$ $8Ax+5B=8x.$ Since $A=1, B=0,$ it follows that $y_{p}=x.$ Thus $y(x)=y_{h}(x)+y_{p}=e^{-x}(c_{1}cos(2x)+c_{2}sin(2x))+x.$ By our boundary conditions, we have that $y(1)=2\implies 2=e^{-1}(c_{1}cos(2)+c_{2}sin(2))+1,$ so $c_{1}cos(2)+c_{2}sin(2)=e.$ Then, $y(e^{\pi/4})=2sinh(\pi/4)\implies 2sinh(\pi/4)=e^{-e^{\pi/4}}(c_{1}cos(2e^{\pi/4})+c_{2}sin(2e^{\pi/4}))+e^{\pi/4}.$ Now I'm stuck. How should I proceed from here and find $c_{1}, c_{2}?$ What's the correct answer?","['solution-verification', 'ordinary-differential-equations']"
4766378,Are these 2 different definitions of a derivative?,"I've recently started learning calculus, and I'm trying to grasp the concept of derivatives. In my textbook, two seemingly different definitions of the derivative are presented: The first definition states: $$
\frac{d\ f(x)}{dx} = \lim_{h \to 0} \frac {f(x+h) - f(x)}{h}, \text{ provided limit exists}
\implies
f'(c) = \lim_{h \to 0} \frac {f(c+h) - f(c)}{h}, \text{ provided limit exists}
$$ Later in the book, another expression is used: $$
f'(c) = \lim_{x \to c} \frac {f(x) - f(c)}{x-c}, \text{ provided limit exists}
$$ I'm struggling to see how these two definitions represent the same concept. Could someone help clarify this for me? Thank you in advance, and I apologize if this question has been asked before or if there are any formatting errors.","['calculus', 'definition', 'derivatives']"
4766404,Area between $\frac{\sin(x)}{x}$ and its derivative,"I want to find the area of the space between $\frac{\sin{x}}{x}$ and its derivative, $\frac{x\cos(x)-\sin(x)}{x^2}$ , that includes the origin. More specifically, between the sinc function and its derivative, so that the function is defined at $x = 0$ as $1$ . The difficulty seemed to arise in finding the intersection points of the two functions. Even if the area or the intersection points can't be defined in terms of algebraic numbers, can they be defined as some output of the sinc function or another trigonometric function?","['calculus', 'improper-integrals', 'trigonometry', 'trigonometric-integrals']"
4766412,Integral Calculus Question: $ g\left(x\right)=\int\frac{x^2-12}{\left(x^2-6x+k^2\right)^2}dx $ where $k \in \Bbb N$,"Assume that $$
g\left(x\right)=\int\frac{x^2-12}{\left(x^2-6x+k\right)^2}dx,
$$ where $k \in \Bbb N$ , is a rational function.
Find sum of all possible values of k. My attempt: \begin{align*}
g\left(x\right)
&=\int\frac{x^2-12}{\left(x^2-6x+k\right)^2}dx \\
&=\int\frac{1}{x^2-6x+k}dx + 3\int\frac{\left(2x-6\right)}{\left(x^2-6k+k\right)^2}dx + \left(6-k\right)\int\frac{1}{\left(x^2-6k+k\right)^2}dx \\
&=\int\frac{1}{\left(x-3\right)^2+k-9}dx + 3\int\frac{\left(2x-6\right)}{\left(x^2-6k+k\right)^2}dx + \left(6-k\right)\int\frac{1}{\left(x^2-6k+k\right)^2}dx
\end{align*} I know $k=9$ is a solution as it makes the quadratic in the denominator a perfect square but how am I supposed to go about finding the other solutions? Is there a better approach than using partial fractions? I also don't know how to integrate the last term (dx/biquadratic)...","['integration', 'calculus', 'polynomials', 'indefinite-integrals', 'problem-solving']"
4766449,Definition of the $\hat{A}$-genus,"From page $50$ of Heat Kernels and Dirac Operators : If $E$ is a real vector bundle with covariant derivative $\nabla$ and curvature $F$ , we associate to it its $\hat{A}$ -genus form \begin{equation}
    \hat{A}(\nabla):=\mathrm{det}^{1/2}\bigg(\frac{F/2}{\sinh{F/2}}\bigg)\in\Gamma(M,\Lambda(TM^*)).
\end{equation} I feel a bit betrayed, because the $\hat{A}$ -genus form seems to be defined in terms of another undefined expression. Am I right in assuming that the definition is meant as follows: Fix $x\in M$ and choose a basis $e_1,\ldots,e_n$ of $E_x$ , consider the matrix $\Omega\in \Lambda(T_pM^*)^{n\times n}$ with $\Omega^{i}{}_{j}\in \Lambda^2(T_pM^*)\subset\Lambda(T_pM^*)$ given by $$\Omega^{i}{}_{j}(X,Y)=e^iF(X,Y)e_j$$ and set $$\hat{A}(\nabla)_x:=\mathrm{det}^{1/2}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)$$ (of course we have to check that the definition is independent of the basis). But even the definition of the last expression is not entirely clear: First of all, note that the entries of $\Omega$ are in the even subalgebra of $\Lambda(T_pM^*)$ , i.e. the determinant makes sense. I would have expected that $$\mathrm{det}^{1/2}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg):=\bigg(\mathrm{det}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)\bigg)^{1/2}$$ but the determinant is an element of $\Lambda(T_pM^*)$ and defining the square root is a subtle issue. Setting $$\hat{A}(\nabla)_x:=\mathrm{det}\bigg(\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)^{1/2}\bigg)$$ seems much more reasonable, as this solves the issue: On the one hand, the function \begin{align}
\mathbb R&\to\mathbb R\\
x&\mapsto\sqrt{\frac{x}{\sinh{x}}}
\end{align} has a nice taylor series and the other hand we dont even have to worry about convergence as $\Omega$ is nilpotent. (To do: Check consistency with $(1.36)$ for $8$ -dim. manifolds.)",['differential-geometry']
4766463,"Sequences of length $n$ made of digits $2, 3, 5, 6$ that no element of sequence divides the next one and that the first element is $5$.","Determine the number of such sequences of length $n$ formed from the digits $2, 3, 5, 6$ that no element of sequence divides the next one and that the first element is $5$ . Form a suitable equation or system of recursive equations and determine the general formula. MY SOLUTION: So, we have that: after $2$ there can be: $3, 5$ after $3$ there can be: $2, 5$ after $5$ there can be: $2, 3, 6$ after $6$ there can be: $2, 3, 5$ Therefore we can distinguish $2$ groups of digits: group $C = 2$ and $3$ group $B = 5$ and $6$ There are 2 possible movements between those: form a digit from group $C$ we go to a digit group $C$ and a digit group $B$ from a digit from group $B$ we go to $2$ digits from group $C$ and one digit from group $B$ Therefore I came up with an equations ( $c =$ number of sequences with digit from the group $C$ at the end, $b =$ number of sequences with digit from the group $B$ at the end): $c_n = 2b_{n-1} + c_{n-1}$ , $b_n = b_{n-1} + c_{n-1}$ Now I try to solve those to get $B$ : $c_n = 2b_{n-1} + c_{n-1} \implies c_n = b_{n-1} + b_n$ And from that: $b_n = b_{n-1} + b_{n-2} + b_{n-1} = 2b_{n-1} + b_{n-2}$ So, for $B$ : $$b_n = 2b_{n-1} + b_{n-2}$$ For $C$ : $c_n = 2b_{n-1} + c_{n-1} \implies b_{n-1} = \frac{1}{2}c_n - \frac{1}{2}c_{n-1}$ And from that: $b_n = b_{n-1} + c_{n-1} \implies b_n = \frac{1}{2}c_n - \frac{1}{2}c_{n-1} + c_{n-1} \implies b_n = \frac{1}{2}c_n + \frac{1}{2}c_{n-1}$ And from that: $c_n = 2(\frac{1}{2}c_{n-1} + \frac{1}{2}c_{n-2}) + c_{n-1} \implies c_n = c_{n-1} + c_{n-2} + c_{n-1} \implies c_n = 2c_{n-1} + c_{n-2}$ So, for $C$ : $$c_n = 2c_{n-1} + c_{n-2}$$ From that I get: $b_n = 2b_{n-1} + b_{n-2}$ $c_n = 2c_{n-1} + c_{n-2}$ By solving one of them I will effectively solve both. Then I will just plug different values of first two elements of sequences to get specific equations without parametres ( $b_1$ and $b_2$ for $b_n$ , $c_1$ and $c_2$ for $c_n$ ). $\lambda^2 - 2\lambda - 1 = 0 \implies \left( \lambda - (1 - \sqrt{2}) \right) \left( \lambda - (1 + \sqrt{2}) \right) = 0 $ So I get: $x(1 - \sqrt{2})^n + y(1 + \sqrt{2})^n$ I calculated manually the numbers of sequences for some of the initial values of $n$ : $a_1 = 1$ (because we can take only $5$ ) $a_2 = 3$ (because we can take $52$ , $53$ or $56$ ) $a_3 = 7$ (because we can take $523$ , $525$ , $532$ , $535$ , $562$ , $563$ or $565$ ) $a_4 = 17$ (because we can take $5232$ , $5235$ , $5252$ , $5253$ , $5256$ , $5323$ , $5325$ , $5352$ , $5353$ , $5356$ , $5623$ , $5625$ , $5632$ , $5635$ , $5652$ , $5653$ or $5656$ ) I distinguished between $B$ and $C$ values: $b_1 = 1$ and $c_1 = 0$ $b_2 = 1$ and $c_2 = 2$ $b_3 = 3$ and $c_3 = 4$ $b_4 = 7$ and $c_4 = 10$ Pluging in the first two terms for $b_n$ : $b_1 = 1 = x(1 - \sqrt{2}) + y(1 + \sqrt{2}) \iff x = \frac{1 - y(1 + \sqrt{2})}{1 - \sqrt{2}}$ $b_2 = 1 = x(1 - \sqrt{2})^2 + y(1 + \sqrt{2})^2 \iff 1 = x(3 - 2\sqrt{2}) + y(3 + 2\sqrt{2})$ And I plug the value of $x$ : $$1 = \frac{1 - y(1 + \sqrt{2})}{1 - \sqrt{2}}(3 - 2\sqrt{2}) + y(3 + 2\sqrt{2})$$ $$1 - \sqrt{2} = (1 - y - y\sqrt{2}))(3 - 2\sqrt{2}) + (3y + 2y\sqrt{2})(1 - \sqrt{2}) $$ $$1 - \sqrt{2} = 3 - 2\sqrt{2} - 3y + 2\sqrt{2}y - 3y\sqrt{2} + 4y + 3y + 2y\sqrt{2} - 3\sqrt{2}y - 4y$$ $$0 = 2 - \sqrt{2} - 2y\sqrt{2} $$ $$y = \frac{2 - \sqrt{2}}{2\sqrt{2}}  = \frac{\sqrt{2}}{2} - \frac{1}{2}$$ From that we get $x = \frac{1 - (\frac{\sqrt{2}}{2} - \frac{1}{2})(1 + \sqrt{2})}{1 - \sqrt{2}} = \frac{1 - \frac{\sqrt{2}}{2} - 1  + \frac{1}{2} + \frac{\sqrt{2}}{2}}{1 - \sqrt{2}} = \frac{\frac{1}{2}}{1 - \sqrt{2}} = \frac{1}{2 - 2\sqrt{2}}$ I get: $$b_n = \frac{1}{2 - 2\sqrt{2}}(1 - \sqrt{2})^n + \left( \frac{\sqrt{2}}{2} - \frac{1}{2} \right)(1 + \sqrt{2})^n$$ Pluging in the first two terms for $c_n$ : $c_1 = 0 = x(1 - \sqrt{2}) + y(1 + \sqrt{2}) \iff x = \frac{-y - y\sqrt{2}}{1 - \sqrt{2}}$ $c_2 = 2 = x(1 - \sqrt{2})^2 + y(1 + \sqrt{2})^2 \iff 2 = x(3 - 2\sqrt{2}) + y(3 + 2\sqrt{2})$ And I plug the value of $x$ : $$2 = \frac{-y - y\sqrt{2}}{1 - \sqrt{2}} (3 - 2\sqrt{2}) + y(3 + 2\sqrt{2})$$ $$2 - 2\sqrt{2} = (-y - y\sqrt{2})(3 - 2\sqrt{2}) + (3y + 2\sqrt{2}y)(1 - \sqrt{2})$$ $$2 - 2\sqrt{2} = -3y + 2y\sqrt{2} -3y\sqrt{2} + 4y + 3y - 3y\sqrt{2} + 2\sqrt{2}y - 4y$$ $$1 - \sqrt{2} = -y\sqrt{2}$$ $$y = \frac{\sqrt{2} - 1 }{\sqrt{2}} = \frac{2 - \sqrt{2}}{2} = 1 - \frac{\sqrt{2}}{2}$$ From that we get $x = \frac{-y - y\sqrt{2}}{1 - \sqrt{2}} = \frac{-(1 - \frac{\sqrt{2}}{2}) - (1 - \frac{\sqrt{2}}{2})\sqrt{2}}{1 - \sqrt{2}} = \frac{-1 + \frac{\sqrt{2}}{2} - \sqrt{2} + 1}{1 - \sqrt{2}} = \frac{\frac{\sqrt{2}}{2} - \sqrt{2}}{1 - \sqrt{2}} = \frac{-1}{\sqrt{2} - 2}$ I get: $$c_n = \frac{-1}{\sqrt{2} - 2}(1 - \sqrt{2})^n + \left( 1 - \frac{\sqrt{2}}{2} \right)(1 + \sqrt{2})^n$$ We know that the final equation needs to be a sum of $c_n$ and $b_n$ . Therefore we get: $$a_n = \frac{1}{2 - 2\sqrt{2}}(1 - \sqrt{2})^n + \left( \frac{\sqrt{2}}{2} - \frac{1}{2} \right)(1 + \sqrt{2})^n + \frac{-1}{\sqrt{2} - 2}(1 - \sqrt{2})^n + \left( 1 - \frac{\sqrt{2}}{2} \right)(1 + \sqrt{2})^n$$ $$a_n = \left( \frac{-1}{\sqrt{2} - 2} + \frac{1}{2 - 2\sqrt{2}} \right) (1 - \sqrt{2})^n
+ \left( 1 - \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2} - \frac{1}{2} \right)(1 + \sqrt{2})^n$$ $$a_n = \left(\frac{-2 + 2\sqrt{2} + \sqrt{2} - 2}{(\sqrt{2} - 2)(2 - 2\sqrt{2})} \right) (1 - \sqrt{2})^n + \frac{1}{2} (1 + \sqrt{2})^n$$ $$a_n = \left( \frac{3\sqrt{2} - 4}{- 8 + 6\sqrt{2}} \right) (1 - \sqrt{2})^n + \frac{1}{2} (1 + \sqrt{2})^n$$ The formula seems to work fine since: $a_1 = \left( \frac{3\sqrt{2} - 4}{- 8 + 6\sqrt{2}} \right) (1 - \sqrt{2}) + \frac{1}{2} (1 + \sqrt{2}) = 1$ $a_2 = \left( \frac{3\sqrt{2} - 4}{- 8 + 6\sqrt{2}} \right) (1 - \sqrt{2})^2 + \frac{1}{2} (1 + \sqrt{2})^2 = 3$ $a_3 = \left( \frac{3\sqrt{2} - 4}{- 8 + 6\sqrt{2}} \right) (1 - \sqrt{2})^3 + \frac{1}{2} (1 + \sqrt{2})^3 = 7$ $a_4 = \left( \frac{3\sqrt{2} - 4}{- 8 + 6\sqrt{2}} \right) (1 - \sqrt{2})^4 + \frac{1}{2} (1 + \sqrt{2})^4 = 17$ Is that correct? Is there any 'easier' way to do that, than: partitioning into $2$ difference equations, solving both of them separatly, pluging first values for both of them separatly, adding together. ?","['combinatorics', 'discrete-mathematics', 'sequences-and-series']"
4766474,Analytic solution for number of paths with length $k$ on an $n \times n$ Chessboard allowing Self-Intersecting?,"Consider an $n \times n$ chessboard where the journey begins at the bottom-left corner $(1, 1)$ and concludes at the top-right corner $(n, n)$ . How many distinct paths are available that necessitate exactly $k$ steps? The permissible movements are restricted to up, down, left, and right, and paths that self-intersect are allowed. While I am aware that a dynamic programming solution exists with a time complexity of $O(k n^2)$ , I am intrigued to know if there is an analytical solution. Let $a(i, j, s) $ denote the number of ways to travel from $(1, 1)$ to $(i, j)$ , allowing for self-intersections. The recurrence relation for this problem is given by: $$
a(i, j, s) = a(i - 1, j, s - 1) + a(i + 1, j, s - 1) + a(i, j - 1, s - 1) + a(i, j + 1, s - 1)
$$ assuming no boundary violations. The initial condition is set as follows: $$
a(1, 1, 0) = 1, \quad a(i, j, 0) = 0 \quad \text{for} \quad (i, j) \neq (1, 1)
$$ The objective is to compute $a(n, n, k)$ . Is there an analytical solution or an algorithmic approach that is faster than $O(n^2 k)$ ? Any references covering this topic would be appreciated.","['graph-theory', 'recurrence-relations', 'combinatorics', 'discrete-mathematics', 'algorithms']"
4766492,Prove this wonderful trigonometric limit $\lim_{n \rightarrow \infty} (\cot(\frac{x}{n+1})-\cot(\frac{x}{n-1}))=\frac{2}{x}$,Show that $$\lim_{n \rightarrow \infty} (\cot(\frac{x}{n+1})-\cot(\frac{x}{n-1}))=\frac{2}{x}$$ One way to prove is using series but I am wondering is there any other way to prove it . Can anyone suggest me any ideas on how to solve it without series . Any help would be appreciated .,"['limits', 'calculus', 'trigonometry', 'infinity']"
4766516,Alexander-Whitney map gives a coalgebra?,"Let $R$ be a unital ring with multiplication $\mu\colon R\otimes R \rightarrow R$ . Consider the category $\mathcal{Ch}(R-\text{mod})$ of chain complexes of $R$ -modules.
This category becomes a monoidal category with the tensor product of chain complexes as monoidal product and the chain complex $R[0]$ (concentrated in degree $0$ on $R$ ) as the monoidal unit. This monoidal category is braided via $x\otimes y\mapsto(-1)^{\vert x\vert \vert y \vert}y\otimes x$ . Let $X$ be a topological space. Consider $S_\ast(X):=S_\ast(X,R)$ , its singular chain complex with coefficients in $R$ . This is an object in $\mathcal{Ch}(R-\text{mod})$ . There is a special morphism in $\mathcal{Ch}(R-\text{mod})$ , aka a chain map $$AW(X)\colon S_\ast(X)\rightarrow S_\ast(X)\otimes S_\ast(X).$$ This map is sometimes called Alexander-Whitney diagonal map and defined on a chain $c\in S_n(X)$ as $AW(X)_n(c):=\sum_{p+q=n}F^p(c)\otimes R^q(c)$ , where $F^p(c)=c\circ \iota$ and $R^q(c)=c\circ \tilde{\iota}$ for the inclusions $\iota\colon \Delta^p\rightarrow \Delta^n, (t_0,\ldots, t_p)\mapsto (t_0,t_1,\ldots,t_p,0,\ldots,0)$ and $\tilde{\iota}\colon \Delta^q\rightarrow \Delta^n, (t_0,\ldots, t_q)\mapsto (0,\ldots,0,t_0,t_1,\ldots,t_q)$ . Define the chain map $\epsilon(X)\colon S_\ast(X)\rightarrow R[0]$ by letting $\epsilon(X)_{i}=0$ for all $i \neq 0$ and $\epsilon(X)_{0}$ be the $R$ -module map that sends each singular $0$ -simplex in $X$ to $1_R$ . This makes the triple $(S_{\ast}(X),AW(X), \epsilon(X))$ into a coassociative, and counital coalgebra in $\mathcal{Ch}(R-\text{mod})$ , I think. This coalgebra is not cocommutative. Is what I have said so far correct? (When) can $(S_{\ast}(X),AW(X), \epsilon(X))$ be made into a bialgebra or even a Hopf algebra? Additionally, the cup product $\cup \colon S^p(X)\otimes S^q(X)\rightarrow S^{p+q}(X)$ is defined as $\alpha\otimes \beta \mapsto \mu \circ (\alpha \otimes \beta) \circ \pi_{p,q} \circ AW(X)_{p+q}$ , where $\pi_{p,q}\colon \oplus_{k+l=p+q}S_k(X)\otimes S_l(X)\rightarrow S_{p}(X)\otimes S_q(X)$ is the projection map. This definition somehow looks like a convolution product in a bialgebra. Can this be made precise?","['homological-algebra', 'coalgebras', 'abstract-algebra', 'homology-cohomology', 'algebraic-topology']"
4766519,Expected Length of Maximum Decreasing Subsequences in Random Sequences,"Given $ n $ distinct numbers that are randomly shuffled to form a sequence $ A = [a_1, a_2, \ldots, a_n] $ , we select the largest number $ x_1 $ from the sequence. Subsequently, we pick the largest remaining number $ x_2 $ that appears after $ x_1 $ , and continue this process. This results in a decreasing sequence $ X = [x_1, x_2, \ldots, x_k] $ of length $ k $ . What is the expected value of $ k $ ? For example: If the sequence $ A $ is $ [1, 5, 4, 2, 3] $ , then $ X = [5, 4, 3] $ . If $ A = [4, 3, 2, 1, 5] $ , then $ X = [5] $ . If $ A = [5, 1, 3, 2, 4] $ , then $ X = [5, 4] $ . If $ A = [3, 2, 4, 5, 1] $ , then $ X = [5, 1] $ . Note: it's different from longest decreasing subsequence. For longest decreasing subsequence, the expected length is approximately $2\sqrt{n}$ here Let $ k $ be the length of $ X $ , and let $ b_i = n - \text{index}(x_{k-i}) $ , where $\text{index}(x_{k-i})$ denotes the position of the element $ x_{k-i} $ in $ A $ . For example, if $ A = [1, 5, 4, 2, 3] $ , then $ X = [5, 4, 3] $ , and: $ b_0 = n - \text{index}(x_3) = n - \text{index}(3) = 5 - 5 = 0 $ $ b_1 = n - \text{index}(x_2) = n - \text{index}(4) = 5 - 3 = 2 $ $ b_2 = n - \text{index}(x_1) = n - \text{index}(5) = 5 - 2 = 3 $ The probability of the length $ k $ can be represented as $$
P(\text{length} = k) = \frac{1}{n} \sum_{{1 \le b_1 < b_2 < \cdots < b_{k-1} \le n-1}} \frac{1}{b_1 \cdot b_2 \cdots b_{k-1}}.
$$ The expected length is then $$
E[\text{length}] = \sum_{k=1}^{n} k \cdot P(\text{length} = k).
$$ How can we simplify the above formulas and determine their asymptotic behavior as $ n \to \infty $ ? This question arises in the context of analyzing the average space complexity of the sliding window maximum with window size $n$ for a random infinite data stream. A monotonic deque is used to track the above structure within a window of size $ n $ . For example, data stream  4, 3, 5, 3, 2, 4, 1, 10, and window size n = 4 [4, 3, 5, 3] 2, 4, 1, 10 deque=[5, 3] 4, [3, 5, 3, 2], 4, 1, 10 deque=[5, 3, 2] 4, 3, [5, 3, 2, 4], 1, 10 deque=[5, 4] 4, 3, 5, [3, 2, 4, 1], 10 deque=[4, 1] 4, 3, 5, 3, [2, 4, 1, 10] deque=[10]","['asymptotics', 'combinatorics', 'discrete-mathematics', 'algorithms', 'probability']"
4766522,Generalized formula for $\sin((2n-1)x)$?,"Does there exist a generalized formula for $\sin((2n-1)x)$ ? I noticed that if, $\sin(1x)=t^1$ Then $\sin(3x)=3t^1-4t^3$ $\sin(5x)=5t^1-20t^3+16t^5$ $\sin(7x)=7t^1-56t^3+112t^5-64t^7$ $\cdots$ They do appear to follow some relation but can we deduce and generalize the relation using Taylor polynomials? Assuming, $\sin((2n-1)x)=a_1\sin^1(x)+a_2\sin^3(x)+a_3\sin^5(x)+a_4\sin^7(x)+\cdots?$","['trigonometric-series', 'trigonometry', 'sequences-and-series']"
4766552,"Why are there not $3^3 \over 3!$ ways to select $3$ elements from different sets, not caring about order?","Say there are three sets of cardinality 3 where each set has no element in common with the other 2. When I think of the number of combinations of 3 items where each item is from a different one of these three sets, I am seeing that this is $3^3 \over 3!$ , but this isn't an integer. I am seeing this because if I think of the number of permutations, this is $3^3$ as there are $3$ choices for each element we select, and each combination is represented $3!$ times in the set of all permutations, as there are $3!$ ways to order it, so we divide the number of permutations by $3!$ to get the number of combinations. Conceptually, what have I done wrong?","['solution-verification', 'combinatorics', 'discrete-mathematics']"
4766558,The pre-image of a curve under a surjective morphism,"The following lemma and proof come from the paper Toward a numerical theory of ampleness , Chapter I, Section 4, Lemma 1 by Kleiman: Let $f: V'\rightarrow V$ be a surjective morphism from a proper irreducible variety $V'$ to a integral curve $V$ . Then there is a integral curve $X'$ on $V'$ such that $f(X')=V$ . Proof. By Chow's lemma we can assume that $V'$ is projective. Let $r'=\dim V'$ and let $X'$ be the section of $V'$ by a suitably general linear space of codimension $r'-1$ . Then $X'$ is a variety of dimension 1. Let $F'$ be the generic fibre of $f$ . We have $\dim X'\cap F'=(r'-1)-(r'-1)=0$ . Therefore $f(X')=V$ . My questions about the proof are: Where is the projectivity hypothesis used in the proof? What is ""suitably general linear space"" exactly? And what is a section of it? Why $\dim X'\cap F'=(r'-1)-(r'-1)$ ? Why does the final conclusion follows from the equation in question 3? Thanks in advance.",['algebraic-geometry']
4766583,"Let $f:A\to B$ be an onto function where $A=\{1,2,3,4\}, B=\{x,y,z\}$. Also, $f(1)=x$. Find the total number of such functions.","Let $f:A\to B$ be an onto function where $A=\{1,2,3,4\}, B=\{x,y,z\}$ . Also, $f(1)=x$ . Find the total number of such functions. My Attempt: I listed all the cases separately and got only $12$ unique cases. But with the following approach, I am getting $18$ cases. If three input values are going to $x,y,z$ then the fourth value will go to either of $x,y,z$ . i.e. for fourth value, we have $3$ mapping choices. Also, this fourth input value can be either of $2,3,4$ . So, $3$ choices. Also, first input value is going to $x$ . It's fixed. Fourth value I have discussed above. The remaining two input values have $2$ mapping choices. So, $3*3*2=18$ . What's wrong here? Edit: Reattempting my second attempt here. $f(1)=x$ . Let $f(2)=y$ , $f(3)=z$ To map $f(4)$ , I have $3$ choices. Also, it output of $f(2)$ and $f(3)$ can also be permuted in $2!$ ways. Also, when I chose $f(4)$ , I could as well have chosen $f(2)$ or $f(3)$ . So, $3$ choices. So, $3*2*3=18$ . I must be counting something extra. What's the proper way to count here without listing all the cases?","['contest-math', 'functions', 'combinatorics', 'solution-verification']"
4766588,Using Histograms for Discrete Data?,"Consider the following From my previous understanding, Histograms were used only to model continuous data. However, here the histogram is used to model the number of incorrect notes, which is clearly discrete. Hence, I suspect that Histograms can be used to model discrete data. Let's say we can model discrete data with a Histogram. I see many immediate problems. To ensure, the bars are touching we must extend the classes such that $1-5$ becomes $0.5-5.5$ . Hence it seems that when we do model discrete data, we more or less treat the data as being continuous in nature. It obviously doesn't make sense to have half a note. So what is going on here?","['statistics', 'probability']"
4766605,Using rotation matrix vs sin & cos,"I am trying to understand when/why you would use the 2D rotation matrix vs just using $\cos$ and $\sin$ in order to change a point's position in 2D space. For example, I have a straight line from point A and point B. I want to change the location of point B but keep it the same distance ( $length$ ) away from point A so that the line would draw to point B's new position. What would be the benefit of using the matrix below: $$\begin{bmatrix}\cos \theta &-\sin \theta \\\sin \theta &\cos \theta \end{bmatrix}$$ ...instead of just using: $Bx = Ax + \cos(\theta) * length$ $By = Ay + \sin(\theta) * length$","['matrices', 'trigonometry']"
4766628,Terminology: measures that are absolutely continuous wrt each other,"One says that measure $\nu$ is absolutely continuous w.r.t $\mu$ , $\nu \ll \mu$ , if every $\mu$ -negligible set is also $\nu$ -negligible. Is there any standard name for the equivalence relation defined by $$\nu \equiv \mu \iff \nu\ll\mu \mbox{ and } \mu\ll\nu? $$ And is there a standard terminology for the equivalence classes thus defined?",['measure-theory']
4766712,Evaluating $\lim_{x\to0}\frac{\sqrt{\frac{1}{\cos x}}-1}{\sin^2 {\frac{x}{16}}}$ without L'Hopital's Rule,"I was solving the limit $$\lim_{x\to0}\frac{\sqrt{\frac{1}{\cos x}}-1}{\sin^2 {\frac{x}{16}}}$$ I simplified the numerator by multiplying both the numerator and denominator by $\sqrt{\frac{1}{\cos x}}+1$ getting to $$\frac{1-\cos x}{\sin^2 \left(\frac x {16}\right) \left(\sqrt{\frac{1}{\cos x}}+1 \right)\cos x}$$ After this step, Wolfram suggests to use the product rule and calculate separately: $$\lim_{x\to0}\frac{1-\cos x}{\sin^2\left(\frac{x}{16}\right)}\;\cdot\;\lim_{x\to0}\frac 1 {\left(\sqrt{\frac{1}{\cos x}}+1\right)\cos x}$$ which eventually gets to the final result of $64$ using De l'Hopital. I was wondering if there was a better/simpler solution  that doesn't require De l'Hopital as my professor suggests to avoid using that as much as possible. Thanks in advance.","['limits', 'limits-without-lhopital']"
4766719,Unknown distribution for birthday problem,"Coming from Blitzstein's book: In the birthday problem, we assumed that all 365 days of the year are
equally likely (and excluded February 29). In reality, some days are
slightly more likely as birthdays than others. For example, scientists
have long struggled to understand why more babies are born 9 months
after a holiday. Let $\textbf{p}= (p_1, p_2, ..., p_{365})$ be the
vector of birthday probabilities, with $p_j$ the probability of being
born on the $j$ th day of the year (February 29 is still excluded, with
no offense intended to Leap Dayers). The $k$ th elementary symmetric
polynomial in the variables $x_1,..., x_n$ is defined by $e_k(x_1, ..., x_n) = \sum_{1 \leq j_1 < j_n < ... < j_k \leq n}{x_{j_i} ... x_{j_k}}$ . This just says to add up all of the $n \choose k$ terms we can get by
choosing and multiplying $k$ of the variables. For example, $e_1(x_1, x_2, x_3) = x_1 + x_2 + x_3$ and $e_2(x_1, x_2, x_3) = x_1x_2 + x_1x_3 + x_2x_3$ . Now let $k \geq 2$ be the number of people. a) Find a simple expression for the probability there is at least one
birthday match, in terms of $\textbf{p}$ and an elementary symmetric
polynomial. I am confused how to do this problem; I've tried a couple approaches. Let $x_j$ be the the day of the year ( $x_1$ = January 1, $x_{364}$ = December 30th, etc..). PIE $P$ (at least one match) = $P$ (match on $x_1 \cup$ match on $x_2 \cup  ... \cup $ match on $x_{365}$ . Now if we look at this with two people, is is a simple: $\textbf{p} \cdot \textbf{p}$ because person 1 can have each birthday $x_i$ with $P(x_i) = p_i$ and for there to be a match person 2 must also have the birthday on $x_i$ . Each event is disjoint, so we have $\textbf{p} \cdot \textbf{p}$ . With 3 people, it becomes a little more confusing with $P$ (match on $x_i$ ) = ${3 \choose 2} p_i^2(1-p_i)^1  + {3\choose3} (p_i)^3$ , which I arrived to by saying a birthday on $x_i$ is a success with $P(x_i) = p_i$ and continued as a binomial distribution for 2 or 3 successes. Note: This can easily be extended that given n $n$ people, the probability 2 or more share a birthday on $x_i$ is the sum from $j=2$ to $n$ successes in a binomial distribution: $\sum_{j=2}^{n} {n \choose j}p_i^j(1-p_i)^{n-j}$ So for 3 people, we still have disjoint events and we have $\textbf{p}_{k=3} = {{3 \choose 2} p_i^2(1-p_i)^1  + {3\choose3} (p_i)^3}_{1 \leq i \leq 365}$ and the probability of intersecting birthdays is $\textbf{p}_{k=3} \cdot \textbf{p}_{k=3}$ . Once we get to four people, the work becomes really messy as PIE has to start getting used, and honestly my math is probably either A) wrong or B) messy. So, I decided to not take PIE approach. Counting compliment Again, with 2 people it is the trivial $1 - (\textbf{p} \cdot (\textbf{1 - p}))$ Immediately, with 3 people and more I realized there is a brutal tree structure where we effectively turn everything into cases, which definitely seemed like the wrong approach. Could someone help me with what the approach might be for this question? The other post related to this did not help me very much. Thank you in advance!","['birthday', 'probability']"
4766820,n students standing in line are to be divided into teams and in each team appointed a captain. How many ways to do that? (I need last transformation),"There are $n$ students in the class. They stand in a line in front of the teacher, who is to divide them into any number of non-empty teams (in particular, the sets can be of size $1$ or $n$ ) and in each set appoint a captain. A team can only consist of students standing consecutively in the line. In how many different ways can the teacher do this? Arrange a suitable equation or system of recursive equations and determine the general formula. I belive that the same question was asked right here: Counting the number of ways to divide into teams - complicated There's no concrete solution provided so I tried to get my own. I calculated manually the numbers of sequences for some of the initial values of $n$ : $a_1 = 1$ (because we can have just $1$ team and $1$ captain of that team) $a_2 = 1 + 2 = 3$ (because we can have $2$ teams in which case the captains are obvious or $1$ team in which case we need to choose the captain in one of $2$ ways) $a_3 = 1 + 2 \cdot 2 + 3 = 8$ (because we can have $3$ teams in which case the captains are obvious or we can have in $2$ ways $2$ teams of $1 + 2$ students in which case we need to choose the captain in one of $2$ ways or we can have one big team of $3$ students for which we need to choose the captain in one of $3$ ways) $a_4 = 1 + 2 \cdot 3 + 2 \cdot 2 + 3 \cdot 2 + 4 = 21$ (because we can have $4$ teams in which case the captain are obvious or we can have in $2$ ways $2$ teams of $1 + 3$ students in which case we need to choose the captain in one of $3$ ways or we can have in one way $2$ teams of $2+2$ students in which case we can choose $2$ captains in $2$ ways each or we can have in $3$ ways $3$ teams of $1 + 1 + 2$ students in which case we can choose captain in $2$ ways or we can have one big team of $4$ students for which we need to choose the captain in one of $4$ ways) When we add one student in the line at the plece n, we have: one big team with n students (so we can choose the captain of that team in one of n ways) and... as many teams with captains as in the line of lenght n-1, but we have that one 'new student' alone in his own team and... as many teams with captains as in the line of lenght n-2, but we have that one 'new student' in a team of 2 (so we can choose the captain of that team in one of 2 ways) and... as many teams with captains as in the line of lenght n-3, but we have that one 'new student' in a team of 3 (so we can choose the captain of that team in one of 3 ways) and so on Therefore, I thought that the recurrence equation would look like this: $a_n = n + a_{n-1} + 2a_{n-2} + 3a_{n-3} +...$ As you can see while comparing with the numbers of sequences for some of the initial values of $n$ (those that I calculated manually above), the formula does work. Now, from the comments below I know that the general formula needs to be of form: $a_n = 3a_{n-1} - a_{n-2}$ Could somebody explain to me how to get from: $$a_n = n + a_{n-1} + 2a_{n-2} + 3a_{n-3} +...$$ to: $$a_n = 3a_{n-1} - a_{n-2}$$ ? I would like to see an algebraic way of transformation, not a proof by induction.","['recurrence-relations', 'discrete-mathematics']"
4766842,If an operation can be represented with other associative operations can we assume it is associative?,"From what I can find it seems that to show an operation operation $\oplus$ is associative, you must show that $(A\oplus B) \oplus C \equiv A \oplus (B \oplus C)$ . If $\oplus$ can be represented with purely associative operations does it follow that $\oplus$ is also associative? For example, take $\oplus$ to be a symmetric difference set operator. Since $$
A \oplus B = A \cup B - A\cap B = (A\cup B) \cap \overline{(A\cap B)}
$$ can we say that $\oplus$ is associative as it can be represented by known associative operations?","['logic', 'discrete-mathematics']"
4766888,Complements of subobjects and algebraic geometry,"This is an idle question, I don't really have any particular application in mind. In any category $C$ , for any object $c \in C$ we can consider its subobjects, namely monomorphisms $d \hookrightarrow c$ . If the objects of $C$ are ""sufficiently spacelike"" we might hope that subobjects have complements , in the following sense. Say that two subobjects are disjoint if their intersection (pullback) is trivial (the initial object). Definition: The complement of a subobject $d \hookrightarrow c$ , if it exists, is the terminal subobject $\neg d \hookrightarrow c$ which is disjoint from $d$ . This recovers the usual notion of the complement of a subset of a set, for example. The definition makes sense more generally in any preorder and if applied to a Heyting algebra , such as the open subsets of a topological space, recovers the Heyting complement. Here is the example which motivates this question. Take $C$ to be the category of functors $\text{CRing} \to \text{Set}$ and consider first the usual forgetful functor $U$ which sends a commutative ring $R$ to its underlying set. This functor has a subfunctor $\{ 0 \}$ sending a commutative ring $R$ to the set consisting of its additive identity $ \{ 0 \}$ . Now we can ask: what is the complement of this subfunctor, if any? There is a ""naive complement"" given by $R \mapsto R \setminus \{ 0 \}$ , but this is not a functor, because elements that are nonzero in some commutative ring may become zero after applying a homomorphism. So we have to ""functorialize"" this construction: we need to know what elements $r$ of a commutative ring $R$ are not only nonzero but remain nonzero after the application of any nonzero homomorphism. (Something goes wrong here with the zero ring; I am just going to ignore this for now.) This is equivalent to requiring that $r$ is not in any proper ideal, which means that the ideal $(r)$ generated by $r$ must be the unit ideal; hence this condition is equivalent to requiring that $r$ be invertible. We conclude that the complement of the zero subfunctor is the group $R^{\times}$ of units. In terms of functors of points, this lets us describe abstractly the sense in which the punctured affine line $\mathbb{A}^1 \setminus \{ 0 \} = \text{Spec } \mathbb{Z}[x, x^{-1}]$ is the complement of the origin in $\mathbb{A}^1$ ! Now we can take complements again , and ask: what is the complement of $R^{\times}$ in $R$ ? (Something again goes wrong here with the zero ring, which I am again going to ignore.) There is a ""naive complement"" $R \mapsto R \setminus R^{\times}$ sending a ring to its non-units, it is not a functor because a non-unit may become a unit after applying a homomorphism, so we need to ""functorialize"" and understand what elements $r \in R$ are not only non-units but remain non-units after the application of any nonzero homomorphism. If $r$ is not contained in some prime ideal $P$ then it becomes a unit in the fraction field $\text{Frac}(R/P)$ ; therefore $r$ must be contained in every prime ideal, and hence in their intersection, which is the nilradical. So $r$ must be nilpotent. Conversely nilpotents clearly satisfy the desired property, and so the complement of $R^{\times}$ is $\text{Nil}(R)$ . $\text{Nil}(R)$ is not representable but it is close: it is ""pro-representable"" by the rings $\mathbb{Z}[x]/x^n$ which organize into a cofiltered limit $\mathbb{Z}[[x]]$ (equipped with the $x$ -adic topology). Geometrically this says that the complement of the punctured affine line in $\mathbb{A}^1$ is not the origin again but its formal neighborhood, which is quite nice and seems to have something to do with the Beauville-Laszlo theorem . If only I knew what was going on with the zero ring! The problem is that all of these functors assign the zero ring its unique element $\{ 0 \}$ (since it is both invertible and nilpotent), so none of them are technically disjoint! So, now my actual Question: Has anyone seen this notion of the complement of a subobject applied to functors of points in algebraic geometry in particular? Also, what's going on with the zero ring above and how do we fix it? I have not thought about whether we should really be working in the category of Zariski sheaves or whatever else; if someone can explain how that might fix the zero ring issue I'd be grateful. Edit: Okay, I have a guess. Everything would be fixed if we worked in Zariski sheaves and the initial sheaf was not the initial presheaf, but was instead the sheaf that assigns the empty set to every nonzero ring but assigns $1$ to the zero ring. That alters the definition of disjointness in exactly the right way to allow all of the above functors to be disjoint. Is that right? Then we'd just need to check that $\text{Nil}(R)$ is a Zariski sheaf, which I think is true?","['heyting-algebra', 'algebraic-geometry', 'category-theory']"
4766899,How do I know what assumptions I can make in a proof?,I'm given this proof and am told to prove by deduction: $(p∨(q∧r))→(((q∧r)→p)→p)$ I have the following rules that I can use: ∧ introductions and eliminations ∨ introductions ∨ eliminations (a case analysis where I prove each case) → introductions Modus Ponens Modus Tollens My issue is that I do not know what I can assume as true/where to begin assuming which parts of the proof are true. How do I know what assumptions I can make in a given proof? Is there a procedural way to determine what is safe to assume?,"['natural-deduction', 'logic', 'discrete-mathematics']"
4767012,Number of ways to write integers in balanced binary,"Imagine a method of writing integers which is similar to balanced ternary , except as you write more digits, their value increases by a factor of 2, not 3. For the remainder of the post, I will call this system  ""balanced binary"". For example: (with T representing -1) 1T11 $= 1*2^0 + 1*2^1 - 1*2^2 + 1*2^3 = 7$ 10T $= -1*2^0 + 0*2^1 + 1*2^2 = 3$ Obviously, there is more than one way to represent each integer in this system, as an n-digit number can range from $-2^{n+1}+1$ to $2^{n+1}-1$ , which contains roughly $2^{n+2}$ numbers, and the n-digit balanced binary string has n ternary digits, which can represent $3^{n}$ numbers, clearly more as n grows. If given a string in balanced binary, you can apply 2 transformations to the string which do not change its value. These are: 1T <=> 01 T1 <=> 0T For example: 1T11 $= 7$ 10T1 $= 1*2^0 - 1*2^1 +0*2^2 + 1*2^3 = 7$ These represent the fact that $2-1=0+1$ , and $1-2=0-1$ , respectively. By applying these transformations to eliminate all T's, all positive numbers written in balanced binary can be converted to their standard binary representations. For negative numbers, the same can be done by eliminating all 1's, then swapping every T with a 1 and adding a negative sign. What I would like to know is: how can I compute a function which, given an integer and a string length, outputs the number of ways the integer can be written in a balanced binary string of the given length, and, optionally, a list of the representations.","['binary', 'combinatorics']"
4767052,Positive integral of $fg$ everywhere for all $g \in C_C^0(\mathbb R^n )$ implies positive function a.e,"Let $f$ be an locally integrable function on the measure space $(\mathbb R^n,S,\mu)$ , with $\mu$ be a radon measure proof that \begin{align}
\text{If }\int_{\mathbb R^n} f g\, d\mu \geq 0\text{ for all }g\in C_C^0(\mathbb R^n)\text{ s.t } g \geq 0 \text{ then }f \geq 0\text{ a.e.}
\end{align} I see clear that the reasoning of these problem is by contradiction, then i suppose that $\mu(f^{-1}(- \infty ,0)) >0$ is easy to see that $$f^{-1}(- \infty ,0)=\bigcup_{n} f^{-1}(-\infty, -1/n)$$ then i take $n_0$ s.t $\mu(f^{-1}(-\infty, -1/n_0))>0$ now my problem is how i can construct a continuous compact supported function $g$ s.t. $spt(g) \subset f^{-1}(-\infty, -1/n)$ $g \geq0$ for find the contradiction
Another aproach to i think is using something like the density of $C_C^0(\mathbb R^n)$ but i not sure EDIT I think in a new approach: By contradiction, sup. exists $A$ st. $ \mu(A)>0$ and $f<0$ in A, then like $\mu$ is Radon there exists $K$ compact such that $K \subset A$ and $\infty> \mu(K)>\frac{\mu(A)}{2}>0$ now like $\infty >\mu(K)$ then exists a sequence of compact supported continuous functions $( \psi _n )_n$ such that $0 \leq \psi_n \leq 1$ and $\psi_n \to 1_K$ then by dominated convergence theorem (I have doubts in these step) $$\int f \psi_n d \mu \to \int f 1_K d\mu = \int_K f d \mu <0$$ But by hypothesis $0 \leq \int f\psi_n d \mu$ , $\forall n \in \mathbb N$ then $$0 \leq \int f \psi_n d \mu <0$$ And hence these is a contradiction.\ These proof is correct? Any hint or help I will be very grateful.","['integration', 'measure-theory', 'real-analysis']"
4767053,A line perpendicular to a tangent curved at both ends,"I made a guess two years ago. I have a strong feeling that there is a proof using the fixed point theorem with geometric visualization, but I couldn't do the proof. If you have a simple closed convex curve, thr line Perpendicular to the tangent on the curve at both ends must be present If this feature is already known, please point to a reference that mentions it If you can prove it would be appreciated, thanks","['curves', 'geometry', 'reference-request', 'combinatorial-geometry', 'differential-geometry']"
