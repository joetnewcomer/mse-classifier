question_id,title,body,tags
2368998,More general lattices on the complex plane,"I have learned that lattices defined on the complex plane can be defined by $\mathbb Z\tau_1\oplus\mathbb Z\tau_2$, where $\tau_1,\tau_2\in\mathbb C$ are linearly independent over $\mathbb R$. I have also learned that $(\tau_1,\tau_2)$ and $(\tau_1',\tau_2')$ define the same lattice when: 
$$(\tau_1',\tau_2')=(a\tau_1+b\tau_2,c\tau_1+d\tau_2)$$ For $\begin{pmatrix}a&b\\c&d\end{pmatrix}\in\mathrm{SL}_2(\mathbb Z)$. I'm wondering what the more general form of this is. I don't know what the technical term is, but let's call $\mathrm{SL}_2(\mathbb Z)$ the ""Lattice Transition Group"" of $\mathbb C$, in that it defines all isomorphisms between lattices in $\mathbb C$. If we fix the lattice transition group of some group $G$ as $\mathrm{SL}_n(\mathbb Z)$, what can be said of $G$? Is there even a group for every $n$ (or even any $n>2$?) that would satisfy this property? If so, what are the properties of this group?","['abstract-algebra', 'lattices-in-lie-groups', 'modular-forms', 'integer-lattices', 'group-theory']"
2369010,Transforming from a simplex in 4 dimensions to a 3D tetrahedron,"I have a collection of points that lie in the unit simplex in 4 dimensions. That is, each point is a vector of four non-negative real numbers that sum to 1. (They are probability distributions.) This simplex in 4 dimensions is equivalent to a three dimensional tetrahedron. I would like to make a 3D plot of my points, each one plotted inside a regular tetrahedron, but I can't seem to work out the formula to transform my four-dimensional points into three-dimensional space in the correct way. That is, I'm looking for a set of (presumably linear) equations that map the vectors $(1,0,0,0)$, $(0,1,0,0)$, $(0,0,1,0)$ and $(0,0,0,1)$ to the four corners of a regular tetrahedron, and the vector $(\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4})$ to its centre. (The position, scale and rotation of the tetrahedron don't matter.) Any insights into how to construct this mapping would be most appreciated.","['simplex', 'probability-theory', 'geometry']"
2369041,Proving a closed form of $\sum_{j=0}^m\binom{m}{j}(-1)^{m-j}j^k$ (for $0\leq k\le m$).,"I'm attempting to show that, given a positive integer $m$ and a non-zero constant $\lambda,$ the sequence $n\mapsto\lambda^nn^k$ satisfies the recurrence relation $$\sum_{j=0}^m\binom{m}{j}(-\lambda)^{m-j}a_{n+j}=0$$ for any integer $0\le k<m.$ I have reduced the problem to showing that $$\sum_{j=0}^m\binom{m}{j}(-1)^{m-j}j^k=0$$ for such $k.$ To prove the $k=0$ case, one need only apply the binomial theorem to $(1-1)^m,$ but I'm stymied trying to prove it for other such $k.$ I checked several examples specifically to make sure I hadn't erred along the way, and it seems that it's true. I also determined (quite by accident) the apparent identity $$\sum_{j=0}^m\binom{m}{j}(-1)^{m-j}j^m=m!,$$ which I have no idea how to prove, either. This leads me to wonder how one could possibly go about determining a closed form for $f(k,m):=\sum_{j=0}^m\binom{m}{j}(-1)^{m-j}j^k.$ Any suggestions/hints (for finding a closed form, proving the identities, or proving the recurrence relation is satisfied) would be appreciated.","['algebra-precalculus', 'combinatorics', 'recurrence-relations', 'closed-form']"
2369044,$f$ Holder continuous with Holder exponent $p>1\implies f \text{ is constant}$,"Say I have a function on a an interval $I$ in $\mathbb{R}$ $f: I \to Y  $ where $Y$ is any metric space.Say $f$ satisfies $d_{Y}(f(y), f(x)) \leq  C\cdot|y-x|^p$, for all $y,x \in I$ where $p \in (1,\infty)$ , i.e. $p$ is bigger than $1$ (so this is much stronger than mere Holder Continuity). I want to show that $f$ is constant on $I$. Here is what I got so far. $f$ is obviously continuous. Also, it makes intuitive sense for $f$ to be constant, since $p >1$ will make $|y-x|^p$ very small for for $|y-x| \ll 1$. I also feel like I have to look at the expression 
$$\frac{d_{Y}(f(y), f(x))}{|y-x|} \leq  C\cdot|y-x|^{p-1}$$ (Note: There is no notion of differentiability here). I'm also thinking that splitting up the interval $[x,y]$ (assuming $x<y$) will help me like so: $$d_{Y}(f(y), f(x))\leq\sum_{k=1}^{k=n}d_{Y}(f(x_k), f(x_{k-1})) \leq C\cdot\sum_{k=1}^{n}  |x_k-x_{k-1}|^p = \sum_{k=1}^{n}  (\frac{1}{n})^p = n^{1-p} $$ $ (y = x_n, x = x_0)$. Is this the answer, that last equality chain? Edit: 
That last chain of equations, as suggested in the comments below should be
$$d_{Y}(f(y), f(x))\leq\sum_{k=1}^{k=n}d_{Y}(f(x_k), f(x_{k-1})) \leq C\cdot\sum_{k=1}^{n}  |x_k-x_{k-1}|^p $$ $$= C\sum_{k=1}^{n} (\frac{|y-x|}{n})^p =|y-x|^p n^{1-p} $$","['continuity', 'real-analysis', 'holder-spaces']"
2369059,One distinct eigenvalue $\iff A-\lambda E_n$ is nilpotent,"Let $A\in \mathbb{C}^{n\times n}$ and $\lambda \in \mathbb{C}.$ $\lambda$ only eigenvalue of $A \iff A-\lambda E_n$ is nilpotent. So the first direction: let $\lambda$ be the only eigenvalue of $A$ then the characteristic polynomial of $A$ has the form $\chi_A(\lambda)=\left(x-\lambda\right)^n$ and so does the minimal polynomial $\mu_A(\lambda)=\left(x-\lambda\right)^m, m\le n$ then by Cayley Hamilton theorem, the matrix satisfies $(A-\lambda E_n)^n=0$ and also $(A-\lambda E_n)^m=0$ so $A$ is nilpotent of degree $m.$
Any help with the other implication would be appreciated.",['linear-algebra']
2369111,"Could we have a by hand proof that $H^{0,q}_{\bar{\partial}}(\mathbb{C}P^n)=0$ for $q>0$?","It is well known that $H^{0,q}_{\bar{\partial}}(\mathbb{C}P^n)=0$ for $q>0$ and the usual proof is through Hodge decomposition. See Page 118 of Principles of Algebraic Geometry by Griffiths and Harris. Could we have a direct, by hand proof that $H^{0,q}_{\bar{\partial}}(\mathbb{C}P^n)=0$ for $q>0$ without involving Hodge decomposition?","['complex-geometry', 'algebraic-geometry']"
2369142,Two values for one trigonometric function [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question We know that trigonometric function like $\mathsf{sin}$, $\mathsf{cos}$ etc. Give one value for one angle. However there may be different (in fact infinite ) angles which give same value of trigonometric functions. But consider $\mathsf{sin}(270)$, or alike problems. Here if we make $270$ as 
$270= 3 \times 90 +0$. 
Then where to take it- in third or fourth quadrant, 
$\mathsf{cos}$ is negative on third and positive in fourth quadrant. (here $\mathsf{sin}$ transforms into $\mathsf{cos}$) (In certain books writer takes both positive and negative values but they have chosen all such questions which give zero as answer) . How to solve this confusion ?",['trigonometry']
2369198,"If $A + I$, $A^2 + I$ and $A^3 + I$ are all unitary, show that $A$ is the zero matrix","Let $A$ be an $n \times n$ complex matrix such that the three
matrices $A + I$, $A^2 + I$, $A^3 + I$ are all unitary. Prove that $A$ is the zero matrix. I know eigenvalues of a unitary matrix has modulus 1, so if $\lambda$ is an eigenvalue of A, then the eigenvalues of $A + I$, $A^2 + I$, $A^3 + I$ are $ \lambda + 1, \lambda^2 + 1, \lambda^3 + 1$ all on the circle $|z+1|<1$. Where to go from here though?","['matrices', 'linear-algebra']"
2369199,Horizontal line(s) that intersect $f(x)=x-2+\frac{5}{x}$ in two points.,"Compute exactly the value(s) of $q$ for which the horizontal line $y = q$
intersects the graph of $f(x)$ in two points that are located on a distance $4$ from each other. While I found the two lines as $y = 4$ and $y = -8$
, I do not know how to find it by any mathematical means.","['algebra-precalculus', 'calculus']"
2369237,Existence of Haar Measure,"I am trying to understand the proof of existence of Haar Measure from Folland's A course in abstract Harmonic analysis. Theorem : Every locally compact group $G$ possesses a left Haar Measure. He used following proposition : Let $\mu$ be a Radon Measure on the locally compact group $G$. Then $\mu$ is a left Haar measure if and only if $\int L_yf \,d\mu=\int f\,d\mu$ for every $f\in C_c^+(G)$ and for every $y\in G$. So, it boils down to look for existence of radon measure with property defined above. We have Riesz representation theorem that gives a radon measure for a given positive linear functional on $C_c(G)$. Riesz Representation theorem : Let $G$ be a locally compact hausdorff space and $\Lambda$ be a positive linear functional on $C_c(G)$. Then there exists a radon measure $\mu$ on $G$ such that $\Lambda(f)=\int f \,d\mu$ for every $f\in C_c(G)$. So, it boils down to looking for existence of a suitable linear functional on $C_c(G)$. How do I look for this linear functional. Proof in that books is  confusing and unclear to me. Any suggestion on how to do this by approximation argument is most welcome. Added : We have one one correspondence
$$\{\text{Arbitrary functions }C_c^+(G)\rightarrow \mathbb{R}\}\rightarrow\prod_{f\in C_c^+(G)} \mathbb{R}.$$ Define the interval $X_f=[(f_0:f)^{-1},(f:f_0)]$ and we have seen that $I_{\varphi}(C_c^+(G))\subseteq X_f$. So, we have correspondence
$$\{C_c^+(G)\xrightarrow{I_{\varphi}}\mathbb{R}\}\rightarrow \prod_{f\in C_c^+(G)} X_f\subseteq \prod_{f\in C_c^+(G)} \mathbb{R}.$$ We set $X=\prod_{f\in C_c^+(G)}X_f$. So, we identify maps $I_{\varphi}:C_c^+(G)\rightarrow \mathbb{R}$ by elements of $X$. For a neighbourhood $V$ of $e$ we define $$K_V=\overline{\{I_{\varphi}\in X: \text{Supp}(\varphi)\subseteq V, \varphi\in C_c^+(G)\}}\subseteq X.$$
Here $I_{\varphi}$ has to be seen as an element of $X$ and as a linear functional by one one correspondence mentioned above. As $X_f$ is compact for each $f$, $X$ is compact by Tychonoff's theorem. So, he some how proves that these collection $\{K_V\}$ has finite intersection property. A space $X$ is compact iff any collection of closed subsets having finite intersection property have non empty intersection. So, we see that $\bigcap K_V\neq \emptyset$. Let $I\in \bigcap K_V$. This is the linear functional that we are looking for. As $I\in K_V=\overline{\{I_{\varphi}\in X: \text{Supp}(\varphi)\subseteq V, \varphi\in C_c^+(G)\}}$,  given $\epsilon>0$ there is an element $I_{\varphi}$ with $\text{Supp}(\varphi)\subseteq V$ such that $|I-I_{\varphi}|<\epsilon$. It is not clear to me what $|I-I_{\varphi}|<\epsilon$ means when we see $I,I_{\varphi}$ as linear functionals. He says $I\in K_V$ means that given any $\epsilon>0$ and any $f_1,\cdots,f_n\in C_c^+(G)$ there exists $\varphi\in C_c^+(G)$ such that $|I(f_j)-I_{\varphi}(f_j)|<\epsilon$ for all $1\leq j\leq n$. Help me to understand why it is the case.","['locally-compact-groups', 'measure-theory', 'haar-measure']"
2369252,Finding solutions for expression to be a perfect square,"Determine all integers such that $$ n^4- n^2 +64$$ is the square of an integer. The first two lines of the solution given in the textbook is as below: Since $n^4-n^2+64>(n^2-1)^2. $ For some non negative integer $k$, 
  $n^4-n^2+64=(n^2+k)^2$. I fail to understand what the author tries to say here. Can't this problem be done in another manner?","['number-theory', 'elementary-number-theory']"
2369264,Torus and Elliptic curves,"In a conference on elliptic curves (an introduction to the subject), the speaker said that an elliptic curve (I.e. an equation of the form $y^2=x^3+ax+b $ where the RHS has distinct roots) is, in the complex space, a torus/Riemann surface of genus 1. What is meant by that? Are we talking about a 2-dimensional manifold the 4D space?","['complex-analysis', 'elliptic-curves', 'elliptic-functions']"
2369276,Question about left exactness of the section functor for sheaves,"Suppose we have an exact sequence of sheaves of abelian groups, 
$$ 0 \longrightarrow \mathcal{F}' \stackrel{\phi'}{\longrightarrow} \mathcal{F} \stackrel{\phi}{\longrightarrow} \mathcal{F}''. $$ I want to show that the sequence of abelian groups
$$0 \longrightarrow \mathcal{F}'(U) \stackrel{\phi'_{U}}{\longrightarrow} \mathcal{F}(U) \stackrel{\phi_{U}}{\longrightarrow} \mathcal{F}''(U) $$
is exact for all open sets $U$. So far I have that exactness at $\mathcal{F}'(U)$ is immediate since injectivity for morphisms of sheaves can be checked on injectivity of morphisms of sections. However I am stuck at exactness at $\mathcal{F}(U)$. I feel as though I am very close. I have determined that exactness at $\mathcal{F}(U)$ is equivalent to the presheaf image of $\phi '$ being equal to the kernel sheaf of $\phi$. From exactness of the original sequence, I have that $\text{im} \phi ' = \ker \phi  $, but how do I then show that this is equal to the image presheaf of $\phi '$? In other words, the image presheaf of $\phi'$ was already a sheaf? This is related to another question asked here Functor of section over U is left-exact , where user Future suggests that we can use the fact that the image sheaf can be identified with a subsheaf of the target sheaf, but I am still not sure how to do it. I realize there are other ways to prove left exactness of the section functor, but I am very curious how to make this particular approach work. Any help is appreciated.","['exact-sequence', 'sheaf-theory', 'sheaf-cohomology', 'algebraic-geometry']"
2369296,Conjecture about distribution of certain primes,"Conjecture: Let $f(x,y,z)=xy+xz+yz\:$ and 
$\: S_m=\{n\in\mathbb N|n<m\wedge f(p_n,p_{n+1},p_{n+2})\in\mathbb P\}$. Then $|S_m|\sim \frac{m}{\ln m}$. Computationally tested only, but I would like to see a proof. It seems like I made a mistake with the inequality in the comment, but here are some data: m    m/ln m     |Sm|   pi(m)           li m     |Tm|
     10      4.34        5       4      6.1655995        6
    100     21.71       26      25     30.1261416       41
   1000    144.76      171     168    177.6096580      295
  10000   1085.74     1292    1229   1246.1372159     2234
 100000   8685.89    10102    9592   9629.8090011    12024
1000000  72382.41    82114   78794  78627.5491595
5000000 324150.19   366716  348513 348638.1150413 For comparision: 
$T_m=\{n\in\mathbb N|n<m\wedge f(a_n,a_{n+1},a_{n+2})\in\mathbb P\}$, 
where $a_n=2n+1$","['number-theory', 'conjectures', 'prime-numbers']"
2369307,Proving that a continuous $\frac{1}{\sqrt{n}}-$periodic function is constant,"Let $f: \mathbb{R} \rightarrow \mathbb{R}$ a continuous function with the property $f(x)=f(x+\frac{1}{\sqrt{n}}),\forall x \in \mathbb{R},\forall n \in \mathbb{N}$.Prove that
   $f$ is constant. Here is my attempt: Let $x \in \mathbb{R}$. Firstly we notice that $\forall n \in \mathbb{N}$ we have   $f(-\frac{1}{\sqrt{n}})=f(0)=f(\frac{1}{\sqrt{n}})$ From this we can deduce that $$f(\frac{m}{\sqrt{n}})=f(0),\forall n \in \mathbb{N},\forall m \in \mathbb{Z}$$ Now $x=\frac{x \sqrt{n}}{\sqrt{n}}$ and $x-\frac{1}{\sqrt{n}}=\frac{x \sqrt{n}-1}{\sqrt{n}} \leqslant \frac{[x \sqrt{n}]}{\sqrt{n}} \leqslant x$ The sequence $x_n=\frac{m_n}{\sqrt{n}} \rightarrow x$ where $m_n=[x\sqrt{n}]$ and $f(x_n)=f(0), \forall n \in \mathbb{N}$ From continuity by taking limits we have that $f(x)=f(0)$ Thus $f(x)=f(0),\forall x \in \mathbb{R}$ proving that $f$ is constant. Is my argument correct? If not can someone provide me a hint? Thank you in advance!","['continuity', 'real-analysis', 'proof-verification']"
2369309,How to transform $y = 2 \sin(x) - \cos(x)$ into the format $y = z \sin(x - b)$,"How can I transform $y = 2 \sin(x) - \cos(x)$ into the format $y = z \sin(x - b)$ for some $z,b\in\Bbb R$? I have been playing with various trig identities and looking through various trigonometry references but cannot so much as find a starting point. Any hints or pushes in the right direction would be much appreciated. Helping a struggling high school study and find myself greatly out of practice.",['trigonometry']
2369325,Codimension of intersection,"Suppose $E$ is a vector space over a field of characteristic $0$ . Let $E_1, F_1$ be subspaces of finite codimension and let $E_2, F_2$ be their respective complements, i.e., $E = E_1 \oplus E_2 = F_1 \oplus F_2$ . $\DeclareMathOperator{\codim}{codim}$ I know that $\dim E_2 = \codim E_1$ and $\dim  F_2 = \codim F_1$ because $E_2 \cong E/E_1$ and $F_2 \cong E/F_1$ . But I don't know how to prove that $\codim (E_1 \cap F_1) \le \dim E_2 + \dim F_2$ . I saw a proof that $\codim (E_1 \cap F_1)$ is finite but it used some fancy isomorphism theorem, so I think a more bare hands approach would be helpful. Thanks.",['linear-algebra']
2369328,Easy way to determine matrix positive / negative definiteness,"So I have this math final coming up on Wednesday, and recently we have been finding critical points for two variable function using the Hessian matrix, and we didn't really explicitly learn how to find out the definiteness of the Hessian matrix in order to determine whether the point is a min/max etc. I was wondering if there is a good way to be able to find this out, something quick and simple that I could apply in the exam. So far in the couple of example we had, the prof. said that if the value of the top left element of the matrix is greater than 0, as well as the determinant, then it's positive semi-definite. But I think this only works for positive matrices. We're more than likely only going to be dealing with real numbers, rather than complex numbers, so I'm looking for something applicable for real matrices. Thank you!","['matrices', 'hessian-matrix', 'positive-definite', 'multivariable-calculus']"
2369368,Different ways to state the motivation of the definition of the product topology,"Suppose for every $i\in\mathscr I,$ $X_i$ is a topological space. The product space has as its underlying set the product set $X =\prod \limits_{i\,\in\,\mathscr I} X_i$ and as its open sets product sets of the form $\prod\limits_{i\,\in\,\mathscr I} G_i$ where for every $i\in\mathscr I,$ $G_i$ is open and for all except finitely many $i\in\mathscr I,$ $G_i=X_i.$ Now suppose one is asked why the definition is that rather than something else ‒ for example, omitting the restriction to finitely many factors. The answer that I know instantly is this: This is the same as the topology of pointwise convergence. That is, a net of points in $X$ converges to a point in $X$ if and only if for every $i\in\mathscr I,$ the projection of the net onto the $i$th factor space is a net that converges to the projection of the limit point onto that factor space. However, there may be other and maybe even better ways of stating the motivation. What are they?","['product-space', 'general-topology', 'motivation']"
2369391,Is this limit dependent on x. Derivative natural log.,"$$ \begin{align}
 \frac{d}{dx}\ln x &= \lim_{h \to 0} \, \frac{\ln{(x+h)} - \ln x}{h} \\ \\
&= \lim_{h \to 0} \, \frac{1}{h} \, {\ln{\bigg(\frac{x+h}{x}\bigg)}} \\ \\
&= \lim_{h \to 0} \, {\ln{\bigg(1+\frac{h}{x}\bigg)}}^{1/h} \\ \\
&=  {\ln{\lim_{h \to 0} \, \bigg(1+\frac{h}{x}\bigg)}}^{1/h}, \text{ let } \frac{h}{x} = \frac{1}{n}  \tag{*}\\ \\ 
&= {\ln{\lim_{n \to \infty} \, \bigg [\bigg(1+\frac{1}{n}\bigg)}}^{n} \,  \bigg]^{1/x} \tag{A} \\ \\
&= \frac{1}{x} \ln \lim_{n \to \infty} \, \bigg(1+\frac{1}{n}\bigg)^{n} \tag{B} \\ \\
&=  \frac{1}{x} \ln e = \frac{1}{x} 
\end{align}$$ So my question is: is this a legal step from (A) to (B)? I removed $x$ from the limit, but in step (*) I sort of created $ x = h\cdot n$ which is the part that's confusing me. Does this indicate $x$ depends on $n$? Any other tips on the clarity of the proof would be great, thanks!","['derivatives', 'limits', 'logarithms', 'exponential-function', 'calculus']"
2369403,"Which area is larger, the blue area, or the white area?","In the square below, two semicircles are overlapping in a symmetrical pattern. Which is greater: the area shaded blue or the area shaded white? My Solution Let the length of each side of the square be $2r$ . The area of the square is $4r^2$ . The two semi-circles have equal area. Area of one semi-circle = $\frac{{\pi}r^2}{2}$ . ${\times}2 = {\pi}r^2$ White area = ${\pi}r^2 - $ area of the intersection of the two circles. Let the area of the intersection of the two circles be $t$ . White area = ${\pi}r^2 - t$ . The segments that make up $t$ are identical. $t$ = area of segment ${\times}2$ . Area of segment = Area of sector - Area of triangle. Angle of sector = $90^{\circ}$ (The circles both have radius $r$ , and the outer shape is a square. Angle of sector $ = \frac{1}{4} * {\pi}r^2$ . Area of triangle $ = \frac{1}{2} * r^2$ . Area of segment $ = \frac{{\pi}r^2 - 2r^2}{4}$ . $t = 2 {\times} \frac{{\pi}r^2 - 2r^2}{4}$ . $t = \frac{{\pi}r^2 - 2r^2}{2}$ . White area $ = {\pi}r^2 - \frac{{\pi}r^2 - 2r^2}{2}$ . White area $ = \frac{2{\pi}r^2 - {\pi}r^2 + 2r^2}{2}$ . White area $ = \frac{{\pi}r^2 + 2r^2}{2}$ . Blue area = $r^2\left(4 - \frac{{\pi} + 2}{2}\right)$ . Blue area = $r^2\left(\frac{8 - ({\pi} + 2)}{2}\right)$ . Blue area = $r^2\left(\frac{6 - {\pi}}{2}\right)$ . If White area $-$ Blue area $ \gt 0$ , then the White area is larger. $$r^2\left(\frac{{\pi}+2 - (6 - {\pi}}{2}\right)$$ $$r^2\left(\frac{2{\pi} - 4}{2}\right)$$ $$r^2(\pi - 2)$$ $\therefore$ the white area is larger. My answer was wrong. What is the error in my solution? The provided solution:","['euclidean-geometry', 'area', 'geometry']"
2369405,Testing $q$-binomial theorem at $z=1/a$,"The $q$-binomial theorem states that when $|q|<1$
$$ \frac{(az;q)_\infty}{(z;q)_\infty}={}_1 \phi_0 (a;\;;q;z)\equiv \sum_{n=0}^\infty \frac{(a;q)_n}{(q;q)_n}z^n \quad \text{for } |z|<1$$
with no restriction on $a$.
The proof can be found in Gasper & Rahman - Basic hypergeometric series or in Andrews, Askey, Roy - Special functions . 
Since there is no restriction on $a \in \mathbb{C}$, we can choose $a$ such that $|a|>1$. My question is the following: the left-hand side of this equation has a zero at $z=a^{-1}$ since $(1,q)_\infty=(1-1)(1-q)\dots=0$, while the right-hand side is not obviously zero at $z=a^{-1}$. How are these two facts reconciled?","['number-theory', 'binomial-theorem', 'q-analogs', 'binomial-coefficients']"
2369439,Moments about the mean of a uniform distribution,"I really don't know what needs to be completed here, because I don't understand the parameters of alpha and beta: Show that if a random variable has a uniform density with the parameters alpha and beta, the $r$th moment about the mean is $\frac{1}{r+1}\left(\frac{\beta-\alpha}{2}\right)^r$ and zero otherwise.","['expectation', 'probability-distributions', 'statistics', 'probability', 'uniform-distribution']"
2369443,Find the maximum value of $a-b$ where $4a+5b=61$ and where $a$ and $b$ are positive whole numbers.,"I am at a beginners level at maths. I have tried to work out the question myself, but I have seen a more simpler way of getting to the answer in which I haven't understood. Here's the simpler approach to this question: $4a+5b=61$ When $b=1$,  $a=14$ When $b=5$,  $a=9$ When $b=9$,  $a=4$ From the pattern we add $4$ to the value given to b each time and we subtract $5$ from the value given to a each time. That is the shortcut to get all the possible values. Why is this so? The solution goes on to say 
when $a=14$ and $b=1$ ; $a-b=13$ which is the maximum value of $a-b$.","['integer-programming', 'optimization', 'linear-diophantine-equations', 'discrete-optimization', 'linear-algebra']"
2369489,Roots of $z^{11}-2z^6+z^4+10i$ in upper half plane.,"I have this problem: How many times the polynomial $P(z)=z^{11}-2z^6+z^4+10i$ goes to zero in the upper half plane? Obviously I need the zeros of $P(z)$, and I thought it would be useful the Rouché theorem. For that I thought it was a good idea to get a disc to bound the problem, and it was considering $\vert z\vert =2$ and $g(z)=z^{11}$. Now, with it I obtained that the zeros were inside that disc. My problem is how to count the number of zeros in $B_2(0)\cap R$ with $R=\{z\colon \Im(z)\geq 0\}$. Can anyone help me how to do that?","['complex-analysis', 'complex-numbers']"
2369531,A $\lambda$-system $\mathcal{L}$ that is a $\pi$-system is automatically a $\sigma$-field.,"Let $\Omega$ be a set.  Let $\mathcal{L}$ be a $\lambda$-system, that is: $\Omega \in \mathcal{L}$. $A \in \mathcal{L} \implies A^c \in \mathcal{L}$. $A_n \in \mathcal{L}, n\geq 1$ and $A_m \cap A_n = \varnothing$ when $n \neq m \ \implies \cup_{n} A_n \in \mathcal{L}$. A $\pi$-system just means $\mathcal{L}$ is also closed under finite intersection. A $\sigma$-field is a set of subsets of $\Omega$ that contains $\varnothing$ and is closed under complement and countable union. Clearly, I only have to show the last property (countable union) as the first two are immediate from the definitions. Let $A_n \in \mathcal{L}, n \geq 1$ be a countable collection of sets in $\mathcal{L}$.  I've tried this out: $B_n = A_n \setminus (\cup_{n \neq m} A_m)$ satisfies property (3) but doesn't lead to a proof, nor does $\cup A_n = \cup B_n$. Yeah... sort of stuck here.","['probability-theory', 'proof-writing', 'measure-theory', 'elementary-set-theory']"
2369537,The Hahn-Mazurkiewicz Theorem for non-metric spaces,"I am looking for a yes or no answer to the following question, though if there is a simple explanation I'd like that as well: If $X$ is any continuous image (not necessarily metrizable) of $[0,1]$, then is $X$ necessarily locally connected? Just need a clarification here because a lot of times metrizability is implicitly assumed in the classical theorems.","['examples-counterexamples', 'general-topology', 'metric-spaces', 'locally-connected']"
2369550,"Find all sets $a_1,...,a_k$ of positive integers such that the sum of any triplet is divisible by each member of the triplet.","Let $k\geq3$ be a fixed integer. Find all sets $a_1,...,a_k$ of positive integers such that the sum of any triplet is divisible by each member of the triplet. I have no idea of how to start attacking this problem. Could someone give me a hint? Thank you.","['number-theory', 'elementary-number-theory']"
2369552,Third axiom proof,"I feel stuck proving the third axiom for the topology. I proved the first two. The intersection does not seem obvious to me, and I have spent some time trying to prove it but have ran out of luck, and would really appreciate some help. Prove Theorem 5.11: Let X be a non-empty set and let there be assigned to each point p $\in$ X a class $\mathcal A_p$ of subsets of X satisfying the following axioms: [$\mathbf A_1$] $\mathcal A_p$ is not empty and p belongs to each member of $\mathcal A_p$ [$\mathbf A_2$] The intersection of any two members of $\mathcal A_p$ belongs to $\mathcal A_p$ [$\mathbf A_3$] Every superset of a member of $\mathcal A_p$ belongs to $\mathcal A_p$ [$\mathbf A_4$] Each member $\mathcal N $$\in$ $\mathcal A_p$ is a superset of a member $\mathsf G$ $\in$ $\mathcal A_p$ such that $\mathsf G$ $\in$ $\mathcal A_g$ for every g $\in$ $\mathsf G$. Then there exists one and only one topology $\tau$ on X such that $\mathcal A_p$ is the $\tau$-neighborhood system of the point p $\in$ X. My candidate topology consists of the class $\mathcal A_p$ of subsets of X satisfying the four given axioms and the empty set.
If there is another topology I should be using, please let me know.",['general-topology']
2369557,Exercise with a dice with 14 faces,"I'm having trouble solving this problem: There's a dice with 14 faces, of which 6 are squared, and 8 are triangular. If the probability of getting a squared face is twice the probability of getting a triangular one, then what is the probability of getting two squared sides when throwing the dice twice? My answer is $\frac49$ (but it's not even in the alternatives), since the probability of getting a squared side is $P(S)=2P(T)$, and I can either get a squared or a triangular one, then the probability of getting a squared side is: $$\frac{2\cdot P(T)}{3\cdot P(T)}=\frac23$$ The solution that is proved to me is $\frac9{25}$, but it doesn't even make sense to me, because that implies that the probability of getting a squared size is $\frac35$. So I want to know if either I'm wrong, or if the solution is correct. Thanks for your help.",['probability']
2369582,How to classify the the critical points of this nonlinear system?,"Consider the nonlinear system:
\begin{align}
 \dot x &= -x - \frac{y}{\log \sqrt{x^2 + y^2}} \\
 \dot y &= -y + \frac{x}{\log \sqrt{x^2 + y^2}}
\end{align}
a) Show that the origin is a stable node for linearized system: Attempt at the solution: The Jacobian is 
$$ J(x, y) =
\begin{bmatrix}
\frac{x y}{(x^2 + y^2) \log^2{\sqrt{x^2 + y^2}}} - 1 & \frac{y^2}{(x^2 + y^2) \log^2{\sqrt{x^2 + y^2}}}- \frac{1}{\log\sqrt{x^2 + y^2}} \\
\frac{1}{\log\sqrt{x^2 + y^2}} - \frac{x^2}{(x^2 + y^2) \log^2\sqrt{x^2 + y^2}} &  -\frac{x y}{(x^2 + y^2) \log^2\sqrt{x^2 + y^2}} - 1 \\
\end{bmatrix}.
$$
As we approach $(0, 0)$ it appears that $J$ approaches 
$$
\begin{bmatrix}
-1 & 0 \\
 0  & -1 \\
\end{bmatrix},
$$
if this is true then it shows $(0, 0)$ is a stable node. However, I'm unsure how to show this rigorously. b) Show that the origin of the nonlinear system is not a stable node but rather a stable spiral. Attempt at the solution:
I am unsure how to proceed for this part. Thanks for your help.","['stability-in-odes', 'ordinary-differential-equations', 'nonlinear-system', 'stability-theory']"
2369598,Tower of Hanoi confusion from Concrete Mathematics,"so I just started reading Concrete Mathematics as a precursor to The Art of Computer Programming vol. 1. I'm on page 3 and I'm already struggling. Anyway, the recurrence is stated to be: $2T_{n-1} +1$ But I don't understand how this works. If $n$ is 3, then we would have: $2T_{3-1}+1$ or $2(2) + 1 = 4$ correct? But that's not right. The answer here is 7. They go on to compute it saying: $T_3 = 2 * 3 + 1 = 7; T_4 = 2*7+1=15$ Now the $T_4$ one makes a little bit of sense if you calculate $2*4 - 1$ instead of $2*(4-1)$, but that logic doesn't seem to apply to that one. I'm trying to figure out of it's a range of $n$ to $1$, but $2*(3*2*1) + 1 = 13$ so obviously that's not right... Oh, maybe I've got it. I'm substituting $2T_{n-1}$ with $2(n-3)$ when I'm actually supposed to use the result of $T_{n-1}$ instead and multiply that by 2 and add 1. Thanks in advance.",['discrete-mathematics']
2369613,Deduce Geodesics equation from Euler equations,"I am using from the following Euler equations : $$\dfrac{\partial f}{\partial u^{i}}-\dfrac{\text{d}}{\text{d}s}\bigg(\dfrac{\partial f}{\partial u'^{i}}\bigg) =0$$ with function $f$ is equal to : $$f=g_{ij}\dfrac{\text{d}u^{i}}{\text{d}s}\dfrac{\text{d}u^{j}}{\text{d}s}$$ Firstly, I don't understand the following relation : $$f=g_{ij} u'^{i}u'^{j}=1$$ (with $u'^{i}=\dfrac{\text{d}u^{i}}{\text{d}s}$) I know that sum of cosinus directors implies : $$u'^{1}u'^{1}+u'^{2}u'^{2}+u'^{3}u'^{3}=1$$ without $g_{ij}$ factors. How to prove that $f=g_{ij} u'^{i}u'^{j}=1$ with $g_{ij}$ factors ? Secondly, starting from the expression of function $f$ and Euler equations, I would like to get : $$\dfrac{\text{d}}{\text{d}s}(g_{ij}u'^{j})-\dfrac{1}{2}\partial_{i}g_{jk}u'^{j}u'^{k}=g_{ij}\dfrac{\text{d}u'^{j}}{\text{d}s}+(\partial_{k}g_{ij}-\dfrac{1}{2}\partial_{i}g_{jk})u'^{j}u'^{k}=0$$ but I can't obtain it. Finally, I should get the general form of geodesics equation, i.e : $$g_{ij}\dfrac{\text{d}u'^{j}}{\text{d}s}+\Gamma_{ijk}u'^{j}u'^{k}$$ if someone coul explain the different steps to get this final result. Thanks for your help UPDATE 1 : For the first issue, I think that function $f$ can be represented as the curvilinear abscissa $ds^2$ which is equal to : $$ds^{2}=g_{ij}\text{d}u^{i}\text{d}u^{j}$$ So I got : $$\text{d}s^{2}/\text{d}s^2=1=f=g_{ij}\dfrac{\text{d}u^{i}}{\text{d}s}\dfrac{\text{d}u^{j}}{\text{d}s}$$ Concerning the second issue, I can write : $$\dfrac{\partial f}{\partial u^{i}}=\partial_{i}g_{jk}u'^{j}u'^{k}$$ But I can't make appear the factor $\dfrac{1}{2}$ on the right term of above equation. How to fix this factor $\dfrac{1}{2}$ to get the general form of geodesic equations ??? i.e : $$g_{ij}\dfrac{\text{d}u'^{j}}{\text{d}s}+\Gamma_{ijk}u'^{j}u'^{k}$$ UPDATE 2 : Concerning the second problem, the issue came from : $$\dfrac{\partial f}{\partial u'^{i}}=\dfrac{\partial g_{jk}u'^{j}u'^{k}}{\partial u'^{i}}$$ and the following expression is wrong : $$\dfrac{\partial f}{\partial u'^{i}}=g_{ij}u'^{j}$$ because of inversion between $j$ and $k$ index, we count double. So we have : $$\dfrac{\partial f}{\partial u'^{i}}=\dfrac{\partial g_{jk}u'^{j}u'^{k}}{\partial u'^{i}}$$ $$=g_{jk}\bigg(\dfrac{\partial u'^{j}}{\partial u'^{i}}u'^{k}+u'^{j}\dfrac{\partial u'^{k}}{\partial u'^{i}}\bigg)$$ $$=g_{jk}(\delta^{j}_{i}u'^{k}+\delta_{i}^{k}u'^{j})=2\,g_{ik}\,u'^{k}$$","['tensors', 'euler-lagrange-equation', 'differential-geometry']"
2369684,3 interior points in a grid based polygon,Given a polygon with vertices on a grid with 3 interior grid points and no 3 vertices lying on the same line. Is it true that all vertices are on the same circle? EDITED There is also another counter example with convex points:,"['number-theory', 'discrete-geometry', 'polygons', 'geometry']"
2369739,Find the differential equation of $\sqrt{1-x^2}+\sqrt{1-y^2}=c(x-y)$. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I tried to find the differential equation of the following 
$$\sqrt{1-x^2}+\sqrt{1-y^2}=c(x-y)$$
where $c$ is arbitrary constant. I would like to show what progress I have made so far. Let $x=\cos \theta$ and $y=\sin \theta$. Then the given equation becomes 
$\sin \theta +\cos \theta = c(\sin \theta -\cos \theta)$ $\Rightarrow c=\tan(\frac{\pi}{4}+\theta)$. Differentiating both sides we get 
$$0=\sec^2 (\frac{\pi}{4}+\theta)d\theta \,.$$ Now what ? Please show me the path. I don't know if this problem has been solved earlier or not. If solved before, kindly provide me the link. P.S. Many many thanks to you all. Finally the solution I have found. This question is now solved completely.",['ordinary-differential-equations']
2369746,Use tools from complex analysis to show $\int_0^{2\pi} \frac{d\theta}{A + B \sin \theta} = \frac{2\pi}{\sqrt{A^2 - B^2}}$,Assume $A^2 > B^2$ and that $A > 0$. Show that: $$\int_0^{2\pi} \frac{d\theta}{A + B \sin \theta} = \frac{2\pi}{\sqrt{A^2 - B^2}}$$ This problem appears in the context of complex analysis. That implies the use of things such as contour integration. I have not seen a problem of this nature before so I'm not sure where to start.,"['complex-integration', 'complex-analysis', 'integration', 'contour-integration', 'trigonometric-integrals']"
2369753,About nowhere meager and relative closed sets.,"Definition: A subset $A$ of a space $X$. Then $A$ is meager in $X$ if $A=\displaystyle\bigcup_{n\in N}A_n,$ where ${\rm int}(\overline{A_n})=\emptyset$, for all $n\in N.$ And $A$ is nowhere meager in $X$, if every non-empty relatively open subset of $A$ is not meager in $X$. Problem: Suppose that $X$ is a topological space and $A\subseteq X$ nowhere meager. Thus $\overline{A}$ is a regular closed, that is, ${\rm int}(\overline{A})$ is dense in $\overline{A}$. For to prove this, I try to see ${\rm int}\left(\overline{A}\right)$ intersects every non empty relatively open subset of $\overline{A}.$ In efect, Let be $V$ an open of $X$ such that $V\cap\overline{A}\neq\emptyset.$ Since $A$ is nowhere meager then $V\cap A$ is not meager in particular ${\rm int}\left(\overline{V\cap A}\right)\neq\emptyset.$ But I can not finish the proof. How do I conclude that ${\rm int}\left(\overline{A}\right)\cap V\cap\overline{A}\neq\emptyset$?",['general-topology']
2369765,A question concerning pointwise convergence,"Let $\{f_k\}_{k\ge 0}$ be a sequence of continuous and bounded functions $f_k\colon \mathbb{R}\to \mathbb{R},\ x\mapsto f_k(x)$, converging pointwise to $f$. Suppose that there exists a sequence of increasing integers $k_1,k_2,\dots$ and a corresponding convergent sequence $x_1,x_2,\dots$ such that $\displaystyle\lim_{\ell\to\infty}x_\ell = x$ and $\displaystyle\lim_{\ell\to\infty} f_{k_\ell}(x_\ell)$ exists. My question: Is it true that
  $$
\lim_{\ell\to\infty} f_{k_\ell}(x_\ell) = f(x)\ \ \ ?
$$ I apologize if this is a silly question. Any help is very appreciated.","['functional-analysis', 'convergence-divergence']"
2369776,Representation theory: An origin story.,"I read that: Dedekind made the observation: taking the multiplication table of a finite group $G$ and turning it into a matrix $X_G$ by replacing each entry $g$ of the table by a variable $x_g$. The determinant of $X_G$ factors into a product of irreducible polynomials, each of which occurs with multiplicity equal to its degree. For a second I couldn't think of what 'multiplicity equal to its degree meant' and then I realised that they must mean I have $f_1^{a_1}f_2^{a_2}f_3^{a_3}$ where $f_i$ are irreducible, and each have degree $a_i$. So I went to check this in an easy case, to make sure I understood, and I see that for $\Bbb Z_3$:
$$\begin{matrix}&0&1&2\\0&0&1&2\\1&1&2&0\\2&2&0&1\end{matrix} \mapsto \begin{bmatrix}x_0&x_1&x_2\\x_1&x_2&x_0\\x_2&x_0&x_1\end{bmatrix}$$
Where the determinant of this is $$-x_0^3-x_1^3-x_2^3+3x_0x_1x_2=-(x_0+x_1+x_2)(x_0^2+x_1^2+x_2^2-x_0x_1-x_0x_2-x_1x_2)$$
which I believe are irreducible. But the latter term has degree $2$ and multiplicity $1$. What has gone wrong?","['matrices', 'abstract-algebra', 'representation-theory']"
2369781,Understanding pullback of pushforward,"Sorry if this is sort of a soft question. I added an example at the end to mitigate. So I hope you can bear with me here. Let $\phi : X \rightarrow Y$ be a morphism of noetherian schemes, $\mathscr F$ a coherent sheaf on $X$. I am looking to better understand $\phi^*\phi_*\mathscr F$, or the natural map $\phi^*\phi_*\mathscr F \rightarrow \mathscr F$. I want to collect interesting or useful facts, that one ought to be aware of. No matter if trivial(-ish) or rather specific, I want to collect 'em all. Provide either proofs or references, both are fine. Assumptions might, among others, include: $\phi_*O_X = O_Y$ $\phi$ is birational $\mathscr F$ is generated by global sections (gbgs) ... Answers might, among others, concern any of the following: the morphism being injective / surjective / an isomorphism the $\phi$-movable part of a divisor $D$, which is defined by $M=$ Im$\{\phi^*\phi_*\mathscr L(D) \rightarrow \mathscr L(D)\}$ (e.g. the motivation behind the definition) ... One example statement: [Hartshorne III.8.8]: $f:X\rightarrow Y$ a projective morphism of noetherin schemes, with $O_X(1)$ very ample, and $\mathscr F$ coherent on $X$. Then $\forall n>>0, f^*f_*\mathscr F (n) \rightarrow \mathscr F(n)$ is surjective. (Because $\mathscr F(n)$ is gbgs.) Now the promised concrete example question: consider two birational morphisms $f:X\rightarrow Y$, $f': X'\rightarrow Y$ of normal projective varieties. Let $V$ be a common resolution of $X$ and $X'$, with morphisms $s$ and $s'$ respectively. Suppose we have an $l$ such that $\mathscr L(lK_{X'})$ is very ample, and $\mathscr L (lK_X)$ is Cartier. (E.g. take $f'$ to be the flip of $f$, in which case we assume both morphisms to be small, $-K_X$ and $K_{X'}$ to be $f$- and $f'$-ample, respectively, and $\rho(X/Y)=\rho(X'/Y)=1$.) Then we write $s^*\mathscr L (lK_X) = \mathscr L (M) \otimes \mathscr L (F)$, where $$\mathscr L (M) = Im\{(f\circ s)^*(f\circ s)_*s^*\mathscr L (lK_X)\rightarrow s^* \mathscr L (lK_X)\}$$
is the $(f\circ s)$-movable part. We have $$ \mathscr L (M) = Im\{(f'\circ s')^* f'_* \mathscr L (lK_{X'}) \rightarrow s^*\mathscr L (lK_X)\}, \tag{1}$$ where I would want to show:
$$= Im\{(f'\circ s')^* f'_* \mathscr L (lK_{X'}) \rightarrow s'^*\mathscr L (lK_{X'})\} ( = s'^*\mathscr L (lK_{X'}) \subset s^*\mathscr L (lK_{X})), \tag{2}$$
but I am not certain why the images of the two maps are the same. Related questions: [1] https://mathoverflow.net/questions/110866/interpreting-ff [2] Pullback and Pushforward Isomorphism of Sheaves","['algebraic-geometry', 'birational-geometry']"
2369785,Sine of infinity?,"While considering limiting problems there are some situations when we have argument tending to infinity of sine or cosine function . My book writes it as an ""OSCILLATING number between $-1$ & $1$"" . How is this possible?","['trigonometry', 'limits']"
2369805,Why is the inverse matrix of $A^TA$ is guaranteed to exists?,"For a matrix $A$ of an arbitrary size $n{\times}m$ where $n>m$ and $rank\left(A\right)=m$, there is no guarantee that the inverse matrix $A^{-1}$ will exist. But for the multiplication of the matrix with its transpose $A^T{\cdot}A$ the inverse $\left(A^T{\cdot}A\right)^{-1}$ is guaranteed to exist. Why is it so?",['matrices']
2369837,The functional equation $f\bigl(x+yf(x)\bigr)+f\bigl(xf(y)-y\bigr) = f(x)-f(y)+2xy^2$,"Let $f:\mathbb{R} \to \mathbb{R}$ such that: $$f\bigl(x+yf(x)\bigr)+f\bigl(xf(y)-y\bigr) = f(x)-f(y)+2xy^2$$ I don't know how to solve this functional equation. Yet here is what I've noticed so far: $f(0) = 0$ after the substitution: $(x,y) = (0,0)$ $f(-x) = -f(x)$ after the substitution: $(x,y) = (0,x)$ $f\bigl(x+xf(x)\bigr)+f\bigl(xf(x)-x\bigr) = 2x^3$ after the substitution: $(x,y) = (x,x)$ $f\bigl(-x-xf(x)\bigr) = -f(x)-x^3$ after the substitution: $(x,y) = (-x, x)$ Moreover I don't think this equation has any solutions...","['functions', 'functional-equations']"
2369849,Is a harmonic function in $L^p(\mathbb{R}^2)$ equal to zero?,"Let $u :\mathbb{R}^2 \to \mathbb{R}$ be a smooth harmonic function ($\Delta u = 0$). Furthermore, suppose that $u \in L^p(\mathbb{R}^2)$, with $1 < p < \infty$. Does it follow that $u = 0$ everywhere? By the theorem of Liouville, this follows immediately if $u \in L^\infty(\mathbb{R}^2)$. For $u \in L^p(\mathbb{R}^2)$, this would also follow if we knew that $u$, for example, is uniformly continuous ($u$ is necessarily unbounded, find a sequence of points $x_k$ such that $u(x_k) \to \infty$, and apply the definition of uniform continuity in a neighbourhood of those points to get a contradiction with $u \in L^p(\mathbb{R}^2)$). The enemy seems therefore higher and narrower ``spikes'' going off to infinity. Any help would be much appreciated!","['functional-analysis', 'harmonic-functions', 'partial-differential-equations']"
2369855,Are greedy methods such as orthogonal matching pursuit considered obsolete for finding sparse solutions?,"When researchers first began seeking sparse solutions to $Ax = b$ , they used greedy methods such as orthogonal matching pursuit (OMP).  In OMP, we activate components of $x$ one by one, and at each stage we select the component $i$ such that the $i$ th column of $A$ is most correlated with the residual $Ax - b$ . Researchers then developed methods such as Basis Pursuit and Lasso, which are based on solving optimization problems with sparsity-inducing regularizers. The Basis Pursuit problem is \begin{align}
\underset{x}{\text{minimize}} & \quad \| x \|_1 \\
\text{subject to} & \quad Ax = b.
\end{align} The Lasso problem is $$
\underset{x}{\text{minimize}} \quad \frac12 \| Ax - b \|_2^2 + \lambda \| x \|_1.
$$ This new strategy was made possible by new optimization algorithms (interior point methods) which were able to solve these large scale optimization problems efficiently. Question: Are greedy methods such as orthogonal matching pursuit and its variants now considered to be obsolete?  Is there a consensus that they do not work as well as the approaches based on optimization with sparsity-inducing regularizers? Has OMP been abandoned? Here is a 1994 paper by Chen and Donoho that gives a brief overview of early attempts to find sparse solutions to $Ax = b$ , leading up to Basis Pursuit and Lasso: Atomic Decomposition by Basis Pursuit","['convex-optimization', 'linear-algebra', 'sparsity']"
2369903,Confusion regarding the domain of a function,"Let $f(x)=x^2$ and $g(x)=x$. What is the domain of $\frac{f(x)}{g(x)}$? Evaluating $\frac{f(x)}{g(x)}$ gives us $x$. Does that mean that its domain is all real numbers? If we evaluate the function at $x=0$, $\frac{f(0)}{g(0)}$, then $g(0)$ will gives us zero. Does that mean zero is not in the domain of $\frac{f(x)}{g(x)}$? From what I understand, the domain of $x$ is the set of all real numbers, but the domain of $\frac{f(x)}{g(x)}$ is the set of all real numbers except zero. Am I right? Edit: $f(x)=2x^2$. Sorry. I forgot to add the two. To make it less confusing, I'm just gonna remove the ""2"" in $2x$","['algebra-precalculus', 'functions']"
2369916,Should I use the indefinite or the definite integral when working with differential equations?,"I'm working through Pollard & Tenenbaum's ""Ordinary Differential Equations"". In their treatment of first-order differential equations they write that for an equation of form $$P(x)dx + Q(y)dy = 0$$ its solution is given by $$\int P(x)dx + \int Q(y)dy = c $$ In other words, they take indefinite integrals to obtain the solution. Later in the part on first-order equations, they arrive at exact differential equations, and use definite integrals in their proof of the exact differential equation's solution, to arrive at $$\int_{x_0}^x P(x, y)dx + \int_{y_0}^{y} Q(x_0, y)dy = c$$ as a solution of $$P(x, y)dx + Q(x, y)dy = 0$$ Where $P$ and $Q$ are partial derivatives of a multivariable function $f$. When do I use the definite integral $\int_{x_0}^x f(x)dx$ and when can I use $\int f(x)dx$, taking just the antiderivative and being done with it?","['ordinary-differential-equations', 'calculus']"
2369940,Parametric representation of orthogonal matrices,"It is a known fact that if $X$ is a skew-symmetric matrix, then $e^X$ is an orthogonal matrix. Is it also true the opposite, ie that any orthogonal matrix admits a representation like $e^X$ for some $X$ skew-symmetric? If not, is there a way to parametrize the space of the orthogonal matrices? With this I mean, a function $f$ that takes some parameters $\Theta$ and returns a matrix $O$ such that: $f(\Theta)=O$ is orthogonal If $O$ is orthogonal, there exists a set of parameters $\Theta$ s.t. $f(\Theta)=O$? Does the topic get easier if we focus on orthonormal matrices?","['matrices', 'orthogonal-matrices', 'matrix-exponential', 'linear-algebra']"
2369950,"My teacher describes absolute value confusingly: $|x|=\pm x,\quad \text{if}\enspace x>0 $.","He says (direct quote): ""In higher mathematics the absolute value of a number, $|x|$, is equal to positive and negative $x$, if $x$ is a positive number."" Then he wrote: 
$|x|=\pm x,\quad \text{if}\enspace x>0 $. I think he misunderstood the definition of absolute value, or did I? From what I understand, absolute value of a number is the distance of a number from zero, so it is always positive. Am I wrong?","['algebra-precalculus', 'proof-writing', 'absolute-value']"
2369969,Logarithmic series as $\sum_{n=3}^{\infty}(-1)^n\ln\!\left(1+\frac1{2n}\right) \!\ln \!\left(\frac{2n^2+n-6}{2n^2+n-10}\!\right)$,"Inspired by this question , I've designed the following series. $$
\begin{align}
S&=\sum_{n=3}^{\infty}\ln\!\left(1+\frac1{2n}\right) \!\ln \!\left(\frac{2n^2+n-6}{2n^2+n-10}\!\right) \tag1
\\\\
T&=\sum_{n=3}^{\infty}(-1)^n\ln\!\left(1+\frac1{2n}\right) \!\ln \!\left(\frac{2n^2+n-6}{2n^2+n-10}\!\right) \tag2
\end{align}
$$ Each one admits a nice closed form. Q1. What are their closed forms? Q2. To which family would you tell these series belong to ?","['definite-integrals', 'sequences-and-series', 'calculus', 'closed-form']"
2369972,Solving $\sqrt{8+2x-x^2} > 6-3x$.,"So I was solving this inequality.
  $$\sqrt{8+2x-x^2} > 6-3x$$ First things first, I obtained that the common domain of definition is actually $[-2,4]$. Next we would square and solve the quadratic that follows. But the ""solution"" seems to have a part, where they took $6-3x \geq 0$, which gave another restriction for $x$ as $(-\infty,2]$. I did not understand this. Why was this necessary?","['algebra-precalculus', 'radicals', 'inequality', 'functions']"
2370027,Using unit circle to explain $\cos(0) = 1$ and $\sin(90) = 1$,"We have been taught $\cos(0) = 1$  and $\sin(90) = 1$. But, how do I visualize these angles on the unit circle?","['algebra-precalculus', 'trigonometry']"
2370082,"Maximum of $E[|X+Z|^m]$ for $Z$ standard normal and $X$ independent of $Z$, two-valued, with $E[|X|^k]=c$","Let $Z$ be a standard normal distribution. I am trying to find a solution to the following problem:
\begin{align}
&\max_{ x_1,x_2 \in \mathbb{R}, t\in[0,1]} (1-t) E[|x_1+Z|^m]+t E[|x_2+Z|^m]\\
&\text{ s.t. }  (1-t) |x_1|^k+t|x_2|^k=c
\end{align}
where $0\le m\le k$. This problem can also be cast as the following problem:
\begin{align}
&\max_{X}  E[|X+Z|^m] \quad (*)\\
&\text{ s.t. }  X \text{ has two mass points}, E[|X|^k]=c, X \text{ is indpendent of } Z
\end{align} My conjecture is that the above problem is maximized by a deterministic random variable $X= c^{\frac{1}{k}}$ and
\begin{align}
\max_{X} E[|X+Z|^m]= E[|c^{\frac{1}{k}}+Z|^m].
\end{align} While we are restrict $Z$ to be standard normal it would be nice to have a proof that works for all symmetric and absolutely continuous distributions. I feel like the proof should be using Jensen's inequality but not sure how to use it.   The reason is the following. Suppose we remove $Z$ and seek to optimize \begin{align}
&\max_{X}  E[|X|^m]\\
&\text{ s.t. }  X \text{ has two mass points}, E[|X|^k]=c, X \text{ is indpendent of } Z
\end{align}
Since, $m \le k$ by Jensen's inequality
\begin{align}
E[|X|^m] \le (  E[|X|^k]  )^{\frac{m}{k}}.
\end{align}
Note, that Jensen's inequality is equality iff $X$ is a constant.  So, the optimization problem $\max_{X}  E[|X|^m]$ is solve by deterministic random variable. Edit 1: It appears that my conjecture is only true in some cases. See a very nice approach of kimchilover. Edit 2 :  It also appears that in $(*)$ the $\max$ should be replaced with $\sup$. This was also pointed out by kimchilover.","['expectation', 'probability-theory', 'optimization']"
2370090,Segment condition: Approximation of sobolev functions by functions which are smooth up to the boundary,"The idea behind domains fulfilling the segment seems to exclude the situation that ""the domain does not lie on both sides of the boundary"". But what about the set 
$$
S := \{x \subset \mathbb R^2 \colon 0 < |x| < 1\}?
$$ I have two questions regarding the segment condition (see bottom for the definition as in Adams) : Does the above set fulfill the segment condition? Where exacly can I observe that the fact that $\Omega$ does not fulfill the segment condition leads to a contradiction in the following example? From what I see is that the problem should be the approximation of the weak derivative of $u$ as it is no problem to approximate the ""step"" function $u(x,y)$ by a $C_0^\infty(\mathbb R^2)$ function in $L^p$-norm.* (addendum to 2.) Strictly speaking,  $\Omega$  does not fulfill the segment condition because it is no domain. Why do we restrict the definition of ""segment condition"" to domains anyway? The following example in Adams -- Sobolev Spaces (3.20, p.68) tries to motivate the segment condition: Where does this example go wrong? Apparently $\partial\Omega$ only has $2$ points, namely $(0,1)$ and $(0,0)$ failing the segment condition:","['functional-analysis', 'proof-explanation', 'sobolev-spaces', 'partial-differential-equations']"
2370091,Find the biggest point where $G$ is invertible.,"Let $G(x, y) = ((x - 1)^2, y^4)$ , (i) let $t = (7, -3)$ . Find the greatest real num $L$ such that $G$ is invertible in the neighborhood $\sqrt{(x - 7)^2 + (y + 3)^2} < L$ . I am aware of the inverse function theorem and I see that $G$ is invertible everything except where if $t = (x, y)$ , we cannot have either $x = 0$ or $y = 1$ , but how can I further proceed with this constraint?","['algebra-precalculus', 'functions']"
2370097,When are all subsets intersections of countably many open sets?,"(Motivated by a comment by Jeppe Stig Nelson to this question ) In what topological spaces $X$ can every subset $A$ be written as the intersection of countably many open sets, i.e., $A=\bigcap_{n=1}^\infty U_n$ with $U_n$ open? Without demanding countability, $T_1$ is enough. If we even demanded finite intersections, we end up with discrete spaces, of course. What property would guarantee countable intersections? For example, does it hold for metric spaces, even though a ""straightforward"" approach like $A\stackrel?=\bigcap_{n=1}^\infty\bigcup_{a\in A}B(a;\frac1n)$ does not work?",['general-topology']
2370144,Peculiar Sum regarding the Reciprocal Binomial Coefficients,"Whilst playing around on Wolfram Alpha, I typed in the sum
$$\sum_{x=0}^\infty \frac{1}{\binom{2x}{x}}=\frac{2}{27}(18+\pi\sqrt 3)$$
I'm not sure how to derive the answer. My first instinct was to expand the binomial coefficient to get
$$\sum_{x=0}^\infty \frac{x!^2}{(2x)!}$$
and then to try using a Taylor Series to get the answer. I thought that if I could find a function $f(n)$ with
$$f(n)=\sum_{x=0}^\infty \frac{x!^2n^x}{(2x)!}$$
Then my sum would be equal to $f(1)$. How do I find such a function? EDIT: I continued on this path and realized that I can use this to set up a recurrence relation for $f^{(x)}(0)$: $$f^{(0)}(0)=1$$
$$f^{(x)}(0)=\frac{x^2}{2x(2x-1)}f^{(x-1)}(0)$$ However, I'm not sure how this helps me find $f(1)$... Am I on the right track? Can somebody help me finish what I started, or point me towards a better method of calculating this sum? Thanks!","['binomial-coefficients', 'closed-form', 'definite-integrals', 'summation', 'sequences-and-series']"
2370169,Finding the number of elements of a set,"Let $S$ be the set of all integers from $100$ to $999$ which are neither divisible by $3$ nor divisible by $5$ . The number of elements in $S$ is $480$ $420$ $360$ $240$ My answer is coming out as $420$ , but in the actual answer-sheet the answer is given as $480$ . Why is my answer not correct? Please, someone help.",['number-theory']
2370229,Finding a closed form for $\int_0^{\infty} \frac{\sin(x/\epsilon)}{1+x^2}dx$ in terms of $\epsilon$?,$$\int_0^{\infty} \frac{\sin(x/\epsilon)}{1+x^2}dx$$ We can use complex analysis to show that $\int_0^{\infty} \frac{\cos(x/\epsilon)}{1+x^2}dx = \frac{\pi}{2}e^{-1/\epsilon}$ but this sin version is causing trouble. Does anyone know a closed form solution like this for it or is it a wasted effort? Thanks.,"['complex-analysis', 'improper-integrals', 'calculus', 'closed-form']"
2370244,"If every open set of a metric space $(X, \rho)$ is $\mu^*$-measurable, then $\mu^*$ is a metric outer measure.","Let $(X, \rho)$ be a metric space and $\mu^*$ and outer measure on $X$. Then, if every open subset of $X$ is $\mu^*$-measurable, $\mu^*$ is a metric outer measure. I'm stuck with this problem. I'm supposed to prove that for every $A$, $B$ subsets of $X$ with $d(A, B) = \inf\{d(a,b) \mid a \in A, b \in B \} > 0$, 
$$\mu^*(A \cup B) = \mu^*(A) + \mu^*(B)$$
and the hypothesis says that if $U \subset X$ is open, then 
$$\mu^*(E) = \mu^*(E\cap U) + \mu^*(E\cap U^c)$$
for every set $E$
but I don't know how to do it. I thought of letting $E = A \cup B$ and then try to find some choice of $U$. With that choice of $E$, we have that 
$$
\begin{align*}
\mu^*(A\cup B) &= \mu^*((A\cup B) \cap U)+\mu^*((A\cup B)\cap A^c)\\
& =\mu^*((A\cap U) \cup (B \cap U))+ \mu^*((a \cap U^c)\cap (B\cap U^c))
\end{align*}$$ 
So at first sight, it looks like the open set $U$ we seek for has to be of one of the following two forms, $U \subset A$ and $B \subset U^c$ or the inverse, $U \subset B$ and $A \subset U^c$. The problem is that, even though the existence of an open set $U \subset A$ is always guaranteed, I don't know why it should also satisfy the property that $B \subset  U^c$ as well. My guess is that there is some property of metric spaces that I'm not aware off (or maybe I am really off the track here). Any help would be appreciated. Thank you!","['outer-measure', 'metric-spaces', 'measure-theory']"
2370263,How many different ways can you distribute $5$ apples and $8$ oranges among six children if every child must receive at least one piece of fruit?,"How many different ways can you distribute $5$ apples and $8$ oranges among six children if every child must receive at least one piece of fruit? If there is a way to solve this using Pólya-Redfield that would be great, but I cannot figure out the group elements. I know this is a duplicate of: How many different ways can you distribute 5 apples and 8 oranges among six children? . But I can not comment on this or contact the member who explained the task. Could someone explain in more detail how to apply this, especially how to evaluate the sums? Maybe someone has more examples?  Or even a book with solved exercises? 
The main Problem is i dont know what i need to know in order to apply it. Application 1: How many distinct circular necklace patterns are possible with n beads, these being available in k colors. It could be solved by Burnside's lemma but I also have no clue to to apply it.","['combinatorics', 'discrete-mathematics']"
2370265,For which value of k is a matrix diagonalizable?,"I have attempted to solve this problem and I reach a certain point (finding eigenvalues) before getting stuck. Let  $$ 
   A=
  \left[ {\begin{array}{cc}
   2 & 0 & k \\
   0 & 3 & 0\\
0 & 0 & k \\
  \end{array} } \right]
 $$ To find the values for which this matrix is diagonalizable, I first found the characteristic polynomial, which I calculated to be:
$(2- \lambda)(3- \lambda)(k - \lambda)$ I calculated this by solving for the determinant of $A - \lambda I$. The answer is apparently for all $k \neq 2$, but I am unsure of how to prove this.  Could someone provide any insight on this?  Thanks! For self-study.","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'determinant']"
2370277,Differentiating a matrix function [duplicate],"This question already has an answer here : Taking derivatives with respect to a matrix (1 answer) Closed 6 years ago . In the book ""Elements of Statistical Learning"", early on the author is discussing linear regression, and naturally discusses the residual sum of squares (RSS) based on the parameter space $\boldsymbol{\beta}$. In the general formulation, $\text{RSS}(\beta) = (\boldsymbol{y} - \boldsymbol{X}\beta)^T(\boldsymbol{y} - \boldsymbol{X}\beta)$ where $\boldsymbol{X}$ is an $N \times p$ matrix and $\beta$ is a $p \times K$ matrix. The author then says to minimize RSS, you differentiate with respect to $\beta$ and get $\boldsymbol{X}^T(\boldsymbol{y} - \boldsymbol{X}\beta) = 0$ My question is, what are the mechanics of differentiating with respect to the matrix $\beta$? I have a B.S. in physics, so I have a reasonably sophisticated math background, but I never covered this in my undergraduate education. I tried looking a bit into ""Matrix calculus"", but it wasn't much help. Is that the correct term? If this is the language used in the remainder of the textbook, what are some good resources somewhat familiar with vector calc and linear algebra to learn ""matrix calc""?","['multivariable-calculus', 'matrix-calculus', 'linear-algebra', 'calculus']"
2370289,Triangularization of matrix over PID,Let $R$ be a PID and let  $A \in Mat_n(R)$ with all of its eigenvalues in R. Is it true that I can always find $P \in GL_n(R)$ such that $P^{-1}AP$ is uppertriangular?  If so can I have a reference for this. Otherwise what additional hypotheses on $A$ do I need in order for it to be true. If it helps the case I am interested in is when $R$ is the ring of integers of some extension of $\mathbb{Q}_p$ or even just $\mathcal{O}_{\mathbb{C}_p}$. Thank you.,"['p-adic-number-theory', 'matrices', 'matrix-decomposition', 'principal-ideal-domains', 'triangularization']"
2370300,derivative of generating function for calculating expected value intuition,"I'm currently studying discrete random variables and I am on using generating functions for calculating the expected value. Given that a generating function is a polynomial of the following kind $g_x(s)=\sum_{k=0}^n P(X=k)s^k$, where the coefficient in front the kth power of s is the probability that the random variable X equals k, we can calculate the expected value for the discrete random variable using the derivative of the generating function at 1. $
EX = g_x'(1)
$ I understand the proof for this, but I can't seem to get the intuition behind it. My questions are : What is the intuitive understanding of this? How was this result achieved? Is there a visual way to interpret the statement? The generating function is a polynomial, so how come the first derivative is EX and for the variance is $g''_x(1)+g'_x(1)−g'_x(1)^2$? If getting intuition for this statement requires more work, what prerequisite theory would you advice me to get to in order to understand it? Thanks in advance!","['intuition', 'statistics', 'generating-functions', 'random-variables']"
2370376,Comparison of Runge-Kutta and Predictor-Corrector-methods,"I just have a short question about something: Which method calculates the more exact result for a differential equation?
The Runge-Kutta-method with a constant step-size h or the predictor-corrector-method with the Adams-Bashford- and Adams-Moulton-method? I use the $P(EC)^mE$ method. Does this calculate a better result than the Runge-Kutta-method, even if $m=0$? I need no proof for that, just the information for a better understanding. I didn't find a comparison, yet.","['numerical-methods', 'ordinary-differential-equations']"
2370391,Show that the minimum of (particular) program is differentiable w.r.t. constraint size,"Question Define the function $f: (0, \infty) \to \mathbb{R}$ by $$f(c) = \min_{x \in \mathbb{R}^n \, : \, \|x\| = c} \|b - A x\|_2^2,$$ for $A \in \mathbb{R}^{m \times n}$ with full rank, $b \in \mathbb{R}^m$, and $\|\cdot\|$ some norm. How do I show that $f(c)$ is differentiable? Is it possible to show that $f''(c) \ge 0$ for $c$ less than $\|\hat{x}\|$, to be defined later? Thoughts toward solution Plug into derivative Plugging this function into the definition of the derivative isn't illuminating. ""Geometric"" interpretation There is a clear geometric interpretation of this problem, since, $$f(c) = \|b - A \hat{x} \|_2^2 + \min_{\|x\| = c} (x - \hat{x})^T (A^T A) (x - \hat{x}),$$ for $\hat{x} = (A^TA)^{+}A^T b \in \arg\min_{x \in \mathbb{R}^n} \|b - A x\|_2^2$ and $\left( \cdot \right)^+$ the pseudo-inverse. Thus, we need only to consider the function 
\begin{align*}
 g(c)
 & =  \min_{\|x\| = c} (x - \hat{x})^T (A^T A) (x - \hat{x}) \\
 & = c^2 \min_{\|x\| = 1} (x - c^{-1} \hat{x})^T (A^T A) (x - c^{-1} \hat{x}) \\
 & = c^2 \left( \mathbf{d}(c^{-1} \hat{x}, \Omega) \right)^2,
\end{align*} 
where $\mathbf{d}(x,y) = \|A(x-y)\|_2^2$ is a pseudo-metric (and a metric if $A$ is ""skinny"") and $\Omega = \{x \in \mathbb{R}^n \, : \, \|x\|=1 \}$. Notice that $g$ is differentiable if and only if the function $$c \mapsto  \mathbf{d}^2(c \hat{x}, \Omega) \tag{*}$$ is differentiable for $c \in (0, \infty)$ and a fixed point $\hat{x}$. A very special case as an example: note that if $A^T A = I$, $\|\cdot\| = \|\cdot\|_1,$ and $|\hat{x}_j| = |\hat{x}_k|$ for all $j,k$, then the projection $\Pi_\Omega(\hat{x}) = \mathrm{sgn}(\hat{x})$, and $\mathbf{d}^2(c\hat{x}, \Omega) = \left( \sqrt{2} \left| \frac{c}{\|\hat{x}\|}-1 \right| \right)^2$, which is differentiable and has positive second derivative. Later, I add this more general example: We will reexpress $\hat{x}$ in a basis where each basis vector is orthogonal to a face of the $\ell_1$ norm level set. Assume that $\|c \hat{x} \|_1 > 1$ so that the point $c \hat{x}$ is outside of the unit ball. Assume without loss of generality that $\hat{x}_j > 0$. Then, since now each component of $c\hat{x}$ measures it's distance from a face, we have that $d(c \hat{x}, \Omega) = \left[ \sum_{j=1}^n (c \hat{x}_j - 1)^2 \mathbf{1}_{c > d_j} \right]^{1/2},$ where $\{d_j\}$ is the set of knots of $\mathbf{proj}_\Omega c\hat{x}$. Therefore, the distance $d$ is has a derivative which increases across each knot, so that it's convex. Perhaps this is a convex program on part of its domain? I also think that it could be true that $f(c)$ is decreasing on $(0, \|\hat{x}\|)$ so that $$f(c) \stackrel{?}{=} \min_{x \in \mathbb{R}^n \, : \, \|x\| \leq c} \|b - A x\|_2^2,$$ for $c \in (0, \|\hat{x}\|)$. This would make this a convex program and hence more amenable to analysis. I think this could be true since as $C$ increases within $(0, \|\hat{x}\|)$, the value $f(c)$ will get ""closer"" to the unconstrained minimum $\|b - A \hat{x}\|_2^2$. Further comments on question If possible, it would be interesting to know how general the norm $\|\cdot\|$ could be while still having the result being provable. If it helps to simplify the problem, I'm particular interested in the case $\|x\| = \|x\|_1$. As Rodrigo kindly pointed out, the case of $\|x\| = \|x\|_2$ follows from noticing that ""ridge regression"" estimator $f(c)$ has a closed form.","['derivatives', 'optimization', 'non-convex-optimization', 'duality-theorems']"
2370433,Bayes classification with a simple example of mail classification,"Every mail is described by a bag of words: $x = (x_1, . . . , x_l)$, where $x_i \in \{0, 1\}$ indicates whether the $i$th word is present or not. We have $n$ training samples ${(x^1,y^1),....(x^n,y^n)}$, where ""$y$"" indicates if the mail is relevant or not relevant, and we want to classify mails accordingly as either relevant or not relevant. Task 1: Determine joint distribution, prior and the class conditional distributions $P(x_i|y)$? Task 2: Consider the class posterior distribution $P(y | x)$ and assume that the cost $c_{1 \to 0}$ for classifying a relevant message as irrelevant is larger than the cost $c_{0 \to 1}$ of classifying an irrelevant message as relevant. The cost of classifying correctly is assumed to be zero. How does the classication
rule change? Edit of my answers --- Task 1: We can think of this as a Bernoulli trial, where a word $w_i$ is either in the document or it is not. Hence we get $\operatorname{argmax}_y \prod_{i=1}^n P(x_i|y) = \prod_{i=1}^n P(w_i|k)^{x_i}
 \cdot (1-P(x_i|y))^{1-x_i}$ $x_i$ is the binary variable indicating if the word $w_i$ is present or not. With Maximum Likelihood, we can estimate $P(y)$ as the fraction of the documents belonging to the corresponding class. 
The class-conditional distribution can be calculated similarly: For instance $P(x=x1|y)$, are the fraction of ""$x1$"" datasamples in class $y$. Questions: Is $P(w_i|k)^{x_i} \cdot (1-P(x_i|y))^{1-x_i}$ the joint distribution (it looks like a conditional distribution)? Any hints for task2?","['bayesian', 'naive-bayes', 'statistics', 'probability']"
2370437,Practical applications of non-standard probability,"Recently I read a paper by Benci et al. describing an alternative to Kolmogorov's construction of probability where the probability measure $P$ takes values in a non-Archimedian field and we have $P(A) = 1 \iff A = \Omega$. One consequence of this is that now the definition $$P(A|B) := \frac{P(A \cap B)}{P(B)}$$ is valid for any $A, B \in 2^{\Omega}$, so we can avoid all of the rigamarole with conditional expectations that arises in the standard formulation, just like how in non-standard analysis we have that derivatives are actually quotients. We also can measure every element of $2^\Omega$ so we don't even need to bother with $\sigma$-algebras. What I like so much about this is that it removes many of the initial hurdles to dealing with measure-theoretic framework, such how if $X \sim \mathcal N(0,1)$ then $P(X = 0)=P(X = \textrm{""blue""}) = 0$, i.e. we can't distinguish impossible outcomes from ""almost never"" outcomes. My question: are there ever practical uses of non-Kolmogrovian probability, and if not, what's so special about Kolmogrov's framework that it's the only one that we can or do use to compute actual quantities of interest? By practical uses I mean real-life probability computations, like coin tosses and die rolls or like machine learning predictions such as estimating the conditional probability of defaulting on a loan. My guess would be that it comes down to how all of these models agree on the finite cases (like the probability of getting 3 heads in a row for a coin toss) and it's only on the infinite and not-so-practical cases that we see disagreement (like the probability of tossing a coin and getting heads forever, and cases where $\sigma$-additivity can lead to counterintuitive results), but I'm not sure about this. Update : @pash has pointed out that with hyperreal-valued extensions we have the transfer principle . Does this completely settle the issue? The Kolmogorov formulation has different axioms though so can't I expect that there are true statements in one formulation that are false in the other? And regardless, this still doesn't seem to answer my question of what is so special about Kolmogorov's formulation that it is the root of all of these non-Archimedian extensions.","['nonstandard-analysis', 'probability-theory', 'measure-theory']"
2370438,Splitting real coins into half,"There are $n$ coins, some are real and others fake. Real coins all have equal positive weight, and fake coins have zero weight. The number of real coins is $2k$ for some $k\geq 1$, but you don't know $k$. Your task is to split the coins into two halves so that each half contains $k$ real coins. You are given a scale that, between two sets of coins, tells you which set is heavier (or if they are equal). What is the optimal number of weighings, in terms of $n$, after which you can do the task? Note that we need at most $n$ weighings: We can start with an empty scale and add one coin at a time to the side that is lighter (if the two sides are equal, then it doesn't matter.) If $k=1$, then we only need $\Theta(\log n)$ weighings. We can divide the coins in half and weigh the two halves. If the two halves are equal, we are done. Else, we recurse on the heavier half, which must contain both real coins. But in the question we don't know $k$.","['puzzle', 'combinatorics']"
2370451,How to define a delta function on complex plane?,"I understand that it makes perfect sense to define a 2-dimensional delta function on the complex plane by $$\int dz\wedge d\bar{z}\delta(z)\delta(\bar{z})=1.$$ However, is there any chance to define a 1-dimensional holomorphic delta function $\delta(z)$, which equals to 1 under certain kind of integration, other than $\frac{1}{2\pi i}\frac{1}{z}$?","['complex-analysis', 'dirac-delta']"
2370462,Find $k$ such that $(\alpha-1)^3+(\beta-2)^3+(\gamma-3)^3=0$ holds for the roots of $x^3-6x^2+kx+k=0$,"If $\alpha$, $\beta$ and $\gamma$ are the three roots of the equation $x^3-6x^2+kx+k=0$, find the values of $k$ such that $(\alpha-1)^3+(\beta-2)^3+(\gamma-3)^3=0$. For each of the possible values of $k$ solve the equation. I conclude from the equation that $\alpha+\beta+\gamma=6$, $\alpha\beta+\beta\gamma+\gamma\alpha=k$ and $\alpha\beta\gamma=-k$ and with the condition that $(\alpha-1)^3+(\beta-2)^3+(\gamma-3)^3=0$. I found the solution from wolfram: http://www.wolframalpha.com/input/?i=Solve%5Ba%2Bb%2Bc%3D6,ab%2Bbc%2Bca%3Dk,abc%3D-k,(a-1)%5E3%2B(b-2)%5E3%2B(c-3)%5E3%3D0%5D From the solution I can see that either $\alpha=1$ or $\beta=2$ or $\gamma=3$. I guess to calculate the term $(\alpha-1)(\beta-2)(\gamma-3)$ and prove it to be zero. Should I continue with this or are there another other method?","['polynomials', 'systems-of-equations', 'roots', 'algebra-precalculus', 'quadratics']"
2370486,Integral over exponential involving reciprocial,"I want to show $$I := \int_{-\infty}^\infty \exp \left(-\left(x-\frac p x \right)^2\right) \, dx = \sqrt{\pi}$$ for any non-negative $p\geq 0$. I tried to prove $I^2=\pi$ using Fubini's theorem, but had no success.","['real-analysis', 'integration', 'calculus']"
2370511,Sequence of continuous functions over a compact set that converges pointwise and monotonically also converges uniformly,"I have the following problem: Let $\{f_n\}_{n = 1}^\infty$ be a sequence of functions such that, for all $n \in \mathbb{N}$,  $f_n:[0,1]  \to [0,1]$ is continuous, and for all $x\in [0,1]$, we have that $f_n(x) \to 0$ and $f_{n+1}(x) \le f_n(x)$. Show that $f_n \to 0$ uniformly. My idea so far is to get for every $n \in \mathbb{N}$ a $c_n \in [0,1]$ such that $f_n(c_n) = \sup_{x \in [0,1]} f_n(c_n)$ and to show that $f_n(c_n) \to 0$. I know that passing to a subsequence I can assume that the $c_n$ converge to some $c \in [0,1]$, and I know that sequence $\{f_n(c_n)\}$ is monotonically decreasing, so it has a limit. My instinct tells me to show that $\lim_{n \to \infty}f_n(c_n) = \lim_{n \to \infty}f_n(c)$, but I haven't been able to do this last step. I feel like I'm close to a solution, but am I really? Does anyone have any idea how to close this proof or of how to do a different proof?","['pointwise-convergence', 'uniform-convergence', 'analysis']"
2370521,Definition of topology using separation as primitive notion,"In ""General Topology"", chapter 1, exercise b, Kelley wrote in a note that it is possible to use the notion of separation ($A$ and $B$ are separated iff $A^k\cap B=A\cap B^k=\emptyset$) as primitive to define topological spaces and he put these three bibliographical references: Wallace: ""Separation Spaces"" Krishna Murti: ""A set of axioms for topological algebra"" Szyrmanski: ""La notion des ensembles separé comme terme primitif de la topologie"" I read the Wallace's article, but his definitions of separation as primitive only work for defining $T_1$-spaces (i.e., in that singletons are closed).
Moreover, I was not able to find on internet the other two articles. How can I adjust the Wallace's definition so that it works for defining any topological space? $\textbf{Note:}$ Here is Wallace's definition: Given a set $X$, a separation relation is a relation $s\subseteq\mathcal{P}(X)\times\mathcal{P}(X)$ such that: 1) $\emptyset\,s\,A$. 2) If $A\,s\,B$, then $B\,s\,A$. 3) If $A\,s\,B$, then $A\cap B=\emptyset$. 4) If $A\,s\,B$ and $C\subseteq A$, then $C\,s\,B$. 5) If $A\,s\,C$ and $B\,s\,C$, then $A\cup B\,s\,C$. 6) If $\{x\}\,s\,A$, then $\{x\}\,s\,\{y\in X:\neg\{y\}\,s\,A\}$. 7) If $x\neq y$, then $\{x\}\,s\,\{y\}$. 8) If for all $x\in A$ and all $y\in B$ we have $\{x\}\,s\,B$ and $\{y\}\,s\,A$, then $A\,s\,B$. Then taking $A^k=\{x\in X:\neg\{x\}\,s\,A\}$, it would be a closure operator, but the resulting topological space would be $T_1$.",['general-topology']
2370587,Are there any functions that can't be expressed in terms of binary operations?,"Does there exist a function $\mathbb R^n \to \mathbb R$ $$f(x_1, x_2, x_3, \dots, x_n)$$ such that it is not possible to write $f$ in terms of a finite number of arbitrary binary operations $\mathbb R^2 \to \mathbb R$? Let's term a binary operation which takes only real numbers as inputs and outputs a single real number (as opposed to a tuple of real numbers) to be a real-valued binary operation . If all real-valued functions can be written in terms of arbitrary real-valued binary operations, is there a lower-bound to the minimum number of real-valued binary operations needed to write a real-valued function that takes $n$ inputs?","['set-theory', 'functions']"
2370591,What is the best way to sample from joint distributions with independent marginals?,"Suppose we have an $n$ -dimensional joint distribution where all its marginals are independent. That is, if the joint density function is $p(x_1,\ldots,x_n)$ , then $p(x_1,\ldots,x_n)=p_1(x_1)\cdots p_n(x_n)$ , where $p_1,\ldots,p_n$ are marginal densities, and all these marginals are known and quite simple. Now we want to get samples ${\bf x}_k=(x_{k,1},\ldots,x_{k,n}),k=1,\ldots,m$ from $p$ where each sample is an $n$ -dimensional vector, and the objective is to use these samples to estimate the expectation of $E(h(X))$ where $h$ is a real-valued function, X is a random variable distributed according to $p$ , by computing the mean of $h({\bf x}_1),\ldots,h({\bf x}_m)$ . For this purpose $m$ is better to be a very large number. Anyone knows what is the most efficient way to do so besides MCMC ? The brutal naive way is to sample $x_{k,i}$ from $p_i$ for every $i=1,\ldots,n$ for every $k$ . This is not desirable when $m$ is large. We exclude MCMC because the cost is too high for our application. All marginals are independent, known, and simple. We don't want to involve this heavy machinery. A possible alternative may be that, after we sample ${\bf x}$ from $p$ , we then take turns to re-sample each dimension of ${\bf x}$ from corresponding marginal, but we are not sure if this is correct ( i.e. if the estimate is unbiased, will the convergence will be much slower ). Anyone can help prove or show counterexample of this?","['numerical-methods', 'statistics', 'probability']"
2370592,polar and rectangular coordinates [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question The point $(r,\theta)$ in polar coordinates is $(7,5)$ in rectangular coordinates. What is the point $\left( 2r, \theta + \frac{\pi}{2} \right)$ in rectangular coordinates? Am I supposed to find (7,5) in polar coordinates? If yes, then how should I solve?","['algebra-precalculus', 'polar-coordinates']"
2370632,Are subanalytic sets measurable?,"Definition. Let $M$ be a real analytic manifold and $X\subset M$ be a subset. $X$ is called semianalytic if it can be described by analytic equalities and inequalities (ie $X=\bigcup_{i=1}^p\bigcap_{j=1}^q X_{ij}$ where $X_{ij}=\{x\in X \mid f_{ij}>0\}$ or $X_{ij}=\{x\in X \mid f_{ij}=0\}$ for real-analytic functions $f_{ij}$ on $M$. Definition. Let $M$ be a real analytic manifold and $E\subset M$ be a subset. $E$ is said to be subanalytic if there exists for each $e\in E$ an open neighborhood $U\subset M$ such that $E\cap U$ is the projection of a relatively compact semianalytic set (ie there exists a real analytic manifold $N$ and relatively compact semianalytic subset $A\subset M\times N$ such that $E\cap U =\pi(A)$ where $\pi:M\times N\to M$ is the projection). Question: Suppose $M$ is a real-analytic manifold and $E\subset M$ is a subanalytic set. Is $E$ measurable? I suspect the answer is yes, but I'm far removed from my measure-theory classes and I'm getting tripped up in dealing with the interaction between the projection involved in the definition of $E$ and how measurability works with projections. Most of the references I've been reading about subanalytic sets (Bierstone/Milman, Denkowska, etc) don't talk about whether they are measurable, so I'm not sure whether this is easy and I should be kicking myself or whether it's moderately difficult and I found an interesting question to ask. Non-question: If someone knows a good MSE tag to deal with subanalytic sets, please suggest it in the comments or edit this post to add it. subanalytic-sets doesn't exist, definable-sets doesn't exist, o-minimal-sets doesn't exist, etc.","['lebesgue-measure', 'logic', 'measure-theory']"
2370652,Frechet differentiability of ODE functional,"Setup: Suppose that $q(x)$ is a strictly positive $C^{2}$ function and consider the initial value problem:
\begin{equation}
\begin{aligned}
y''+q(x)y=&0\\
y(0)=&k\\
y'(0)=&c
\end{aligned}
\end{equation}
We know that such an initial value problem has a unique solution which we will denote by $f^q(x)$. Define the functional $F_{x}$ by \begin{equation}
\begin{aligned}
F_{x}:C^{2}(\mathbb{R};\mathbb{R})&\rightarrow \mathbb{R}\\
%C^{1,2}(\mathbb{R}^2;\mathbb{R})\\
F_{x}(q)&\mapsto f^{q}(x).
\end{aligned}
\end{equation} Question: Is the functional $F_{x}$ Frechet differentiable?  How can we determine if it is?","['functional-calculus', 'functional-analysis', 'ordinary-differential-equations', 'analysis', 'frechet-derivative']"
2370682,Geometric significance of completion of a ring,"I am reading about completions in Eisenbud's commutative algebra book. He mentions that the completion $\hat{R}_m$ can represent the properties of a variety, I imagine with coordinate ring $R$,  in a much smaller neighborhood of $\frak{m}$ than what we can see via localizing at $\frak{m}$. This is an interesting observation I would like to know more about. Could somebody give me a simple example of how one would use completion in algebraic geometry? How is it employed and what makes it useful?","['algebraic-geometry', 'commutative-algebra']"
2370686,"if $f:[0,1] \to \mathbb{R}$ is increasing, show that $f$ is the pointwise limit of a sequence of continuous functions over $[0,1]$ [duplicate]","This question already has an answer here : Increasing functions are Baire one (1 answer) Closed 6 years ago . if $f:[0,1] \to \mathbb{R}$ is increasing, show that $f$ is the pointwise limit of a sequence of continuous  functions over $[0,1]$ Intuitively this makes sense but I am having trouble with showing why there would be a sequence of continuous functions converging pointwise to $f$. Clearly there is a sequence converging pointwise to $f$, I can set:
$\forall n \in \mathbb{N}, f_n = f$. How to prove there is at least one which is made up of continuous functions $f_n, \forall n \in \mathbb{N}$ over $[0,1]$ I can't quite figure out the argument.",['real-analysis']
2370691,$F(u) = F(u^2)$ if $u$ is algebraic of odd degree,"This has been asked before, but I have a different solution and I would like to check it. Let $F$ be a field and $u$ be algebraic over $F$ of odd degree. Prove that $F(u) = F(u^2)$. Of course $F(u^2) \subset F(u)$. If we can show that $u \in F(u^2)$, we are through. Let $$f(x) = x^{2n+1} + a_{2n}x^{2n} + \cdots + a_1 x + a_0$$ be the minimum polynomial of $u$ over $F$. Then: $$u g(u) + h(u) = 0$$ where $$g(x) = x^{2n} + a_{2n-1}bx^{2n-2} + a_{2n-3} x^{n-2} + \cdots + a_3 x^2 + a_1$$ and $$h(x) = a_{2n}x^{2n} + a_{2n-2} x^{2n-2} + \cdots + a_2 x^2 + a_0$$ We can't have $g(u) = 0$ because the degree of $u$ is $2n+1$. So $g(u)$ is a unit in $F(u^2)$. Hence $u = - h(u)g(u)^{-1} \in F(u^2)$. Does this look good?","['abstract-algebra', 'polynomials', 'field-theory', 'proof-verification']"
2370707,Is there any short method to solve the integral $I=\int {{\sin3x}\cdot\sin{5x\over2}\over\sin {x\over2}}dx$,"Given integral:$$I=\int\,\,{{\sin3x}\cdot\sin{5x\over2}\over\sin {x\over2}}\,dx$$ I have solved the given integral but it's too lengthy and tiresome to write here. Also is there any method to solve the integral with help of Complex Integration (I'm new here on math.SE and can't type frequently so for me it'll take too much time to type the complete solution here since I'm using iPad) In case anyone wants to see my solution, I'll attach the image of paper-solution here Sorry for not being supportive, need your help!","['real-analysis', 'trigonometry', 'calculus', 'indefinite-integrals', 'integration']"
2370719,"Is there a function which is ""midpoint linear"" but not linear?","Let a function $f:\mathbb{R}\rightarrow\mathbb{R}$ be midpoint linear if for all $x,y\in\mathbb{R}$, $f(\frac{x+y}{2})=\frac{f(x)+f(y)}{2}$. If a midpoint linear function $f$ is continuous, then I believe you can show through a density argument that $f$ is also linear. However, if we drop the assumption of continuity, I wonder if we can construct (or at least describe) a counterexample that is midpoint linear function but is not in fact linear. Because midpoint convexity does not imply convexity without the additional assumption of continuity, I believe that such a counterexample should exist, and that it will likely be through a Vitali set sort of argument that involves taking a basis for $\mathbb{R}$ over $\mathbb{Q}$. I am not sure of the details though.","['continuity', 'real-analysis', 'examples-counterexamples', 'linear-transformations']"
2370728,"Symbolic Notation for $\theta ""="" \arcsin(-.5)$?","I'm teaching PreCalculus and the following issue has always bugged me. Problem: Solve $\sin\theta = -.5$ for $0 \le \theta \le 2\pi$. Solution:
\begin{align*}
\sin\theta &= -.5\\
\theta &= \arcsin(-.5) = -\frac\pi6
\end{align*} But to get this into our desired domain, our solutions are $\boxed{\theta = \frac{7\pi}6 \text{ or }\frac{11\pi}6}$. So my objection is the line $\theta = \arcsin(-.5)$, because that's really not true. $\theta$ can be a whole lot of things! So does there exist some symbol or notation that expresses this? Something a-la ""If $x^2=9$, then $x = \pm 3$."" Like
$$\theta \stackrel{\text{is related to}}{\sim} \arcsin(-.5) = -\frac\pi6 ?$$","['algebra-precalculus', 'trigonometry', 'notation']"
2370740,A dice is rolled until a $6$ occurs. What is the probability that the sum including the $6$ is even?,"A game is played where a standard six sided dice is rolled until a $6$ is rolled, and the sum of all of the rolls up to and including the $6$ is taken. What is the probability that this sum is even? I know that this is a geometric distribution and the expected number of rolls is $\frac1{1/6} = 6$ rolls until a $6$ occurs, along with the expected value being $21$ ($6$ rolls times expected value of $3.5$ per roll), but I'm not certain how to proceed from there. Would the expected range (if it is even relevant) be from $11 = 1·5+6$ to $31 = 5·5+6$? The answer is supposedly $\frac47$. I'm also curious about how this question would change if the stopping number was anything else, say a $3$ stopping the sequence rather than a $6$. Thank you in advance!","['probability', 'dice']"
2370782,"Finding $\lim_{a\to \infty} \left(\int\limits_0^\infty\frac {\ln ax}{\cosh x}\, dx-\frac {\pi\ln a}2 \right)$","Define the function$$F(a)=\int\limits_0^\infty\frac {\ln ax}{\cosh x}\, dx$$ Question: How do you calculate the limit$$\lim\limits_{a\to\infty}\left(F(a)-\frac {\pi\ln a}2\right)\tag1$$ I was trying to integrate $F(a)$ using Feynman's trick . Differentiating with respect to $a$, we get$$\begin{align*}F'(a) & =\int\limits_{0}^\infty\frac {\text{sech } x}a\\ & =\frac {\pi}{2a}\end{align*}$$Integrating that again, we see that$$F(a)=\frac {\pi\ln a}2+C$$However, in order to find the constant $C$, I need to solve $(1)$. I tried plugging it into Mathematica , and it started running for a long time before I gave up. I'm wondering if you have any ideas...","['integration', 'definite-integrals', 'limits']"
2370827,How to show that $f(x)=|x|/x$ does not have any limit as $x\to0$?,"$f(x)$ does not converge to any $L$ as $x\to a$ if for every $L$ there is $\epsilon>0$ such that for all $\delta>0$ there is $x$ such that $0<|x-a|<\delta$ and $|f(x)-L|\geq\epsilon$. I wish to prove that $$
f(x)=\frac{|x|}{x}=\begin{cases}
1,&x>0\\
-1,&x<0
\end{cases}
$$
does not converge to any $L$ as $x\to0$ using the above definition. This is what I did: Fix $L$ and take $\epsilon=\frac{1}{2}$. For any $\delta>0$ there is $x$ such that $0<|x-0|<\delta$ and $$
|f(x)-L|=\begin{cases}
|1-L|,&x>0\\
|-1-L|,&x<0
\end{cases}=
\begin{cases}
|1-L|,&x>0\\
|1+L|,&x<0
\end{cases}
$$ but I am not sure how I should show that $|f(x)-L|\geq\frac{1}{2}=\epsilon$.","['real-analysis', 'proof-writing', 'limits']"
2370843,Are these two sets of density functions equivalent?,"Consider the set of density functions $$\mathscr{G}=\{ g=(1-\epsilon)f + \epsilon h\mid \mbox{h is a density function on $\Omega$}\}$$ where $f$ is a known (fixed) density function on $\Omega$ , $h$ is a density function, which is a member of the set of all density functions on $\Omega$ and $\epsilon$ is also a fixed known number with $0<\epsilon<1$ . Claim: For the set $$\mathscr{G}'=\{g'=(1+\epsilon')f'-\epsilon' h\mid \mbox{h is a density function on $\Omega$}\}$$ $\mathscr{G}=\mathscr{G}'$ with a suitable choice of $f'$ , which may only be dependent on $f$ but not on $h$ . Is this claim true? if yes, what is $f'$ ? The idea is the following: one can get the same set either by first choosing $(1-\epsilon)f$ and adding $\epsilon h$ or by first choosing $(1+\epsilon')f'$ and then subtracting $\epsilon' h$ .","['elementary-set-theory', 'general-topology', 'functions', 'probability-distributions']"
2370844,Proving this following elementary set theory relation,"For all sets $A,B,C$ if $A\cap C \subseteq B\cap C$ and $A \cup C \subseteq B\cup C$, then $A\subseteq B$. I'm not sure what the second condition is used for because I think I only used the first one: Let $x \in A\cap C$. Then $x \in A$ and $x \in C$. Since $A\cap B \subseteq B\cap C$, $ x \in A$ and $x\in C \implies x\in B$ and $x\in C$. Doesn't this automatically show that $x\in A \implies x \in B$?",['elementary-set-theory']
2370881,Find the leading behavior of $\int_0^\infty \cos \left(x \left(\frac{t^3}{3} - t\right)\right)dt$,"Find the leading behavior of $$\int_0^\infty \cos \left(x \left(\frac{t^3}{3} - t\right)\right)dt$$ for large $x$. The problem also asks for outlining the method for finding more terms in the asymptotic expansion. The following hint is provided: $\int_{-\infty}^{\infty} \cos (ax^2) dx = \int_{-\infty}^{\infty} \sin (ax^2) dx = \sqrt{\frac{\pi}{2a}}$. I have not seen a question like this before. Most questions for leading-order behavior involve the exponential function in some way (which isn't immediately apparent here). I suppose that $\cos x$ is related to the exponential in the sense that $e^{ix} = \cos x + i \sin x$, but this does not look helpful here. A Taylor expansion does not necessarily look promising to me either.","['asymptotics', 'integration', 'trigonometry']"
2370884,What exactly is an improper subset?,"I've been studying elementary set theory from my textbook. I'm confused about what exactly is an improper subset. I know that if we say $A \subset B$, that means all the elements of $A$ are also the elements of $B$ but $A \neq B$.  So $A$ is a proper subset of $B$. But if I say that $A \subseteq B$ does that mean (i) $A$ must be equal to $B$ or (ii) $A$ may be equal to $B$ I tried looking up on google but some websites agree to (i) some agree to (ii) so it didn't clear up my question. I also found this somewhat related question which was somewhat helpful but didn't exactly cleared by doubt.",['elementary-set-theory']
2370930,Conjecture about arcsin and $\sqrt{\quad}$,"Let $r(a,b)$ be a rational number depending on $a,b$ and nonnegative. For every $b$ there is an $a$ such that $r(a,b)$ is not $0$. Let $C(a,b)$ be a squarefree positive integer depending on $b$ and different for every $b$. Consider for positive integers $I,J$ : $$ S_J = \sum_{j=1}^J \sum_{i=1}^I \arcsin\left( r(i,j) \sqrt {C(i,j)} \right) $$ Where $ r(i,j) \sqrt C(i,j) $ is always smaller than $1$. Conjecture G For $J>2$ $$ S_J \neq 2 \pi $$ Is this true ??","['radicals', 'trigonometry', 'inverse-function', 'pi']"
2370932,Proof of a matrix exponential identity,"Let $A,B \in M_n(\mathbb{R})$, and suppose $[A,[A,B]] = [B,[A,B]] = 0$, where $[A,B] = BA-AB$. We want to show
$$
e^{At}e^{Bt}=e^{(A+B)t}e^{[A,B]t^2/2}, \quad \forall t\in \mathbb{R}.
$$
I'm given a hint to show that $x(t) =e^{-(A+B)t}e^{Bt}e^{At}x_0$ is a solution to the ODE $x'= t[A,B]x$ for each $x_0\in \mathbb{R}$. I haven't been able to prove the hint, let alone see why being a solution helps prove the identity. Taking the derivative of $x(t)$ didn't lead to much, and moreover there's no $t$ outside of the exponent, and substituting it into the RHS of the ODE also didn't help. The RHS of the identity to be shown solves $x' = (A+B+t[A,B])x$, which maybe gives some intuition about the ODE in the hint, but I'm not really sure where to go.","['matrices', 'matrix-exponential', 'ordinary-differential-equations']"
2370985,Example of $(b_n)$ such that $\lim_{n\to\infty} {\frac1n}\sum_{i=1}^{n-1}b_i$ does not exists and $0\le b_n\le 1$,"Find a ${{b_n}}$ $n\in\Bbb N$ and $0\le b_n\le 1$ such as  the limit
$$\lim_{n\to\infty} {\frac1n}\sum_{i=1}^{n-1}b_i$$
does not exist. I don't know how to deal with this problem, it seems to me that this limit can not be undetermined because the terms of the sum are all positive, so how is it possbile to obtain an ""oscillation"" of the limit?
Maybe it can be  undetermined because of $1/n$ but  I can't find any ${b_n}$, I tried whit absolute value of sine and cosine but I think that I should consider a  ${b_n}$ defined for recurrence or defined by intervals Thanks for your help","['examples-counterexamples', 'limits', 'calculus', 'cesaro-summable', 'summation']"
2371019,Using Jacobi Elliptic Functions for the solution of an ODE,"I need to solve the following ODE:
$$
Ay''-By^3+Cy=0
$$
where $A,B,C \in \mathbb{R}_{+}$ (i.e.- positive constants). After reading a little bit about the properties of the Jacobi sn function, I think the solution should contain sn in it, but have no idea how to arrive to it. Will you please help me understand how to formally obtain the solution for this ode? In addition, is there any book that contains solved examples for odes with Jacobi functions as solutions? Thanks !",['ordinary-differential-equations']
2371022,Cross product in higher dimensions,"Suppose we have a vector $(a,b)$ in $2$ -space. Then the vector $(-b,a)$ is orthogonal to the one we started with. Furthermore, the function $$(a,b) \mapsto (-b,a)$$ is linear. Suppose instead we have two vectors $x$ and $y$ in $3$ -space. Then the cross product gives us a new vector $x \times y$ that's orthogonal to the first two. Furthermore, cross products are bilinear. Question. Can we do this in higher dimensions? For example, is there a way of turning three vectors in $4$ -space into a fourth vector, orthogonal to the others, in a trilinear way?","['multilinear-algebra', 'cross-product', 'orthogonality', 'linear-algebra', 'vectors']"
2371060,What can be said if $f^*\omega_Y = \omega_X$?,"Let $f : X \to Y$ be a finite morphism of connected, reduced, pure-dimensional projective schemes of equal dimension satisfying $f^*\omega_Y \cong \omega_X$. What can be said about $f$ in this case? Is $f$ surjective? Etale? I am failing to come up with examples showing otherwise. One can assume that $\omega_Y$ is an invertible sheaf. To clarify, I'm interested in the geometric consequences the condition $f^*\omega_Y \cong \omega_X$ imposes.",['algebraic-geometry']
2371083,Reps of $Lie(G)$ lift to universal cover of $G$. Reps of $G$ descend to highest weight reps of $Lie(G)$?,"Let us work over an algebraically closed field of characteristic $0$. Let $G$ be a semisimple, or perhaps reductive algebraic group, so we are working with the Zariski topology. Let $\mathfrak{g}$ be the Lie algebra associated to $G$. If possible, could we not appeal to Lie groups and/or exponentiation, unless we explain how this relates to the algebraic group setting, with the Zariski topology. How does one lift a representation from $\mathfrak{g}$ to $G$? It lifts to a representation of the universal cover of $G$? In the setting of Algebraic groups, I can't use the exponential to lift representations, since it isn't algebraic? How does one descend a representation from $G$ to $\mathfrak{g}$? These descend to highest weight representations? Essentially I would like to understand the functors:
$$d:Rep(G)\to Rep(\mathfrak{g}),\qquad \int: Rep(\mathfrak{g})\to Rep(G)$$ An example on $\text{SL}(2,\Bbb C)$ would be nice, since the rep theory is simple.","['algebraic-groups', 'representation-theory', 'algebraic-geometry']"
