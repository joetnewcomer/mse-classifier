question_id,title,body,tags
1228731,Understanding the definition of a set with $C^k$ boundary and of the outward pointing normal vector field,"Consider the following excerpt from Evans book. I don't understand these definitions. Can some please illustrate them on an example , so that I can figure out how to work with them. A negative example may be more illustrative, i.e. a set $U$ such that $\partial U$ isn't $ C^1$. Especially the second definition is unclear to me, since $\nu^i$ is nowhere actually defined.","['analysis', 'calculus']"
1228740,A comment in the Disquisitiones Arithmeticae,"Gauss proves that if $t\equiv\pm 3\mod 8$, then $2$ is a non-(quadratic)-residue modulo $t$ as follows: Assume $t\equiv\pm 3\mod 8$ is the smallest counter-example, and say $a^2\equiv 2\mod t$, that is $a^2=2+tu$, where $a<t$. By taking $t-a$ instead of $a$ if necessary, we can assume $a$ is odd (since $t$ is odd, so $a$ and $t-a$ can't both be even). Since $a$ is odd, $a^2\equiv 1\mod 8$. So modulo $8$, we have $1\equiv 2\pm3u$ which implies $u\equiv\mp3$. But from $a^2=2+tu$ we conclude that $2$ is a residue modulo $u$, and recalling that $a<t$ we conclude that $u<t$, so $u$ is a smaller counterexample than $t$, which was assumed minimal. He then says that even if we assumed $a$ even, we could do the same proof, we would just have to distinguish between the cases $a\equiv0$ and $a\equiv2$ modulo $4$. I don't see it. If say we assume $a$ is a multiple of $4$, then $a^2\equiv 0$ modulo $8$, which, imitating the above, gives us $u\equiv\pm 2$ modulo $8$, and so we don't get a contradiction.",['number-theory']
1228748,Inductive limit of sheaves over noetherian topological space,"Let $X$ be a topological space. Let $I$ be a poset and let $\mathcal F_i$ for $i\in I$ be sheaves on $X$, and $\{\pi_{ij}\colon \mathcal F_i \rightarrow \mathcal F_j\}_{i,j\in I}$ be an inductive system of maps for $i \le j$ and $i,j \in I$ that are compatible with the restriction maps of the $\mathcal F_i$. One may form a sheaf $\varinjlim \mathcal F_i$ by sheafifying the presheaf $U\mapsto \varinjlim \mathcal{F}_i(U)$ for $U$ open in $X$. Claim : If $X$ is Noetherian then the presheaf $U\mapsto \varinjlim \mathcal{F}_i(U)$ is already a sheaf. The above is an exercise in Hartshorne. It seems to me that this is true more generally, indeed all one needs is the space to be quasi-compact. But being Noetherian is stronger, indeed one can prove that a space is Noetherian iff it is locally Noetherian and quasi-compact. So I am left wondering why Mr. Hartshorne wrote Noetherian instead of quasi-compact here? Perhaps I am missing something?","['algebraic-geometry', 'sheaf-theory']"
1228809,Inverse of the sum of the inverse of two matrices,"I need to compute $ (A^{-1} + B^{-1})^{-1} $. Both $A$ and $B$ are symmetric and $A$ is invertible and PSD. I already know $B^{-1}$ and $A$, but I don't have $A^{-1}$ and $B$. Is there a formula to compute that avoids two inversions? EDIT: Another related question is if there are situations (e.g. $A$ and $B$ have additional properties) where it is possible to avoid both the inversions and under which conditions. As additional properties consider that I know also $B$ together with $A$ and $B^{-1}$ and that $B$ is invertible and PSD as $A$. Furthermore, both $A$ and $B$ are square matrices. With these properties, is there a formual (or even an approximation) to avoid both the inversions?","['inverse', 'matrices']"
1228823,Question from a topology textbook regarding the uniform topology,I am able to prove that T maps continuous functions to continuous functions but I am lost when it comes to proving T is linear. I am also unsure how to solve b) and c). Thanks for any help you can offer!,"['functional-analysis', 'general-topology']"
1228884,$x$ is a left zero-divisor $\iff$ $x$ is a right zero-divisor.,"Let $R$ be a ring with unity. Show that $x$ is a left zero-divisor if and only if $x$ is a right zero-divisor. Suppose, $x$ is a left zero divisor. Then, $\exists y \in R$ such that $xy = 0 \Rightarrow (xy)\cdot 1_R = 0 \Rightarrow (xy)(x^{-1}x)= 0 \Rightarrow (xyx^{-1})x = 0$. Hence, $x$ is a right zero divisor. Now, suppose, $x$ is a right zero divisor. Then,$\exists y \in R$ such that $yx = 0 \Rightarrow 1_R\cdot(yx) = 0 \Rightarrow (xx^{-1})(yx)= 0 \Rightarrow x(x^{-1}yx) = 0$. Thus, $x$ is a left zero divisor. But, this isn't correct. So, please tell me what's wrong with my proof.","['abstract-algebra', 'ring-theory']"
1228954,Prove that this vector space is not finite dimensional. [duplicate],"This question already has answers here : Is there a quick proof as to why the vector space of $\mathbb{R}$ over $\mathbb{Q}$ is infinite-dimensional? (7 answers) Closed 9 years ago . Let $V$ be the set of real numbers. Regard V as a vector space over the field of rational numbers $F$ with the usual operations. Prove that this vector space is not finite dimensional. My attempt:
Let $\beta$ be the basis of $V$ such that $\beta =\{\alpha_1, \alpha_2, ..., \alpha_n\}$. $\quad\therefore\;\forall\;\alpha\in span(\beta),\;\alpha = c_1\alpha_1 + c_2\alpha_2 + ..... c_n\alpha_n$ where $c_1, c_2, ...., c_n \in F$. Now I have to show there exists $\alpha \in V$ such that $\alpha \notin span(\beta)$ but I cant figure out which $\alpha$ will not belong in $span(\beta)$.","['vector-spaces', 'linear-algebra']"
1228964,Area of Spherical Polygon,"It appears to me that after repeated applications of Girard's theorem on the area of spherical triangles that we can obtain the surface area of a spherical polygon with interior angles $\theta_{1},...,\theta_{n}$ on a sphere of radius $R$ is
$$\text{area}(\text{spolygon}(\theta_{1},...,\theta_{n}))=R^2 \left(\sum_{i=1}^{n} \theta_{i} - (n-2)\pi\right).$$
Does this make sense to anyone else? I wanted to check before I used the result in a paper I am writing. Even if this just holds for spherical squares, it is all I need.","['spheres', 'spherical-geometry', 'geometry', 'polygons']"
1228997,What is the general solution to $\sin\theta=\frac12$?,"What is the general solution to $\sin\theta=\frac12$? I have an incorrect solution but I don't know why.
\begin{align*}
\sin\theta & =\frac12\\
\sin\theta & =\sin\alpha\\
\alpha & =\arcsin\left(\frac12\right)=\frac{\pi}{6}\\
\theta & =n\pi+\alpha(-1)^n\\
\theta & =n\pi+\frac{\pi(-1)^n}6\\
\end{align*}
I then found the two general solutions for when $n$ is even and odd. $$\theta=\pi(n+\frac16)$$
and
$$\theta=\pi(n-\frac16)$$ What am I doing wrong here? Thanks",['trigonometry']
1229019,Clarification about second order Linear ODE with constant coefficients,"I'm studying the steps to obtain the general solution of a second order Linear ODE with constant coefficients, but I haven't understood a justification. $$y''+ay'+by=f$$
Let's look for a solution $y=\gamma_1 y_1 +\gamma_2  y_2$ where: $\gamma_1, \gamma_2 \in C^1(R)$ and $y_1, y_2$ solutions of the associated homogeneous equation. We arrive at 
$$\begin {cases} \gamma_1 ' y_1+ \gamma_2 ' y_2=0\\ \gamma_1'y_1'+\gamma_2'y_2'=f(x)\end{cases} $$ The system has only one solution if $$ Det\begin{pmatrix}
y_1(x) & y_2(x)\\
y_1(x)' & y_2'(x)\end {pmatrix} \ne 0$$ And (this is the step that I haven't understood)
it is $\ne0$ for all $ x\in R$, because of $y_1$ and $ y_2$ are linearly independent. But I know that if $y_1$ and $y_2$ are linearly independent, $\exists$ $x_0 \in R$ such as the Wronskian $\det W(x_0)\ne0$. I deduce that $\exists x_0$ such as I can have only one solution of the system. But why the book says that $\forall x \in R \; \det W(x) \ne 0$? Many thanks","['calculus', 'ordinary-differential-equations']"
1229031,Are Mersenne numbers $M_p$ deficient?,"A positive integer $n$ is called deficient if $\sigma(n)<2n$, i.e., the sum of divisors is less than $2n$. What is known about Mersenne numbers $n=2^p-1$ with $p$ prime in this respect ? Is there a counterexample to
$$
\sigma(2^p-1)<2^{p+1}-2 \; 
$$
for a prime $p$ ?",['number-theory']
1229059,Seeking Recommendation on Theoretical Multivariable Calculus textbooks,"I am a college sophomore with double majors in mathematics and microbiology. I wrote this email to seek your advice on selecting a theoretical, proof-based textbook on the multivariable calculus. I will be taking a multivariable calculus on this Summer but it unfortunately is a computational one with little theories. I would like one that comprehensively covers the theories of multivariable calculus and perhaps including sections on the applications too (but not necessary). Couple of textbooks I have in my mind are ones written by Serge Lang, Apostol, Marsden, Hubbard, and Fleming. Which one is good for self-learning? Sincerely, PK","['calculus', 'reference-request', 'self-learning', 'book-recommendation', 'multivariable-calculus']"
1229071,$\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is ring isomorphic to $\mathbb{Z}_n$.,"what would be an $n$ such that $\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is ring isomorphic to $\mathbb{Z}_n$? This problem was on a qualification test. Here's how I solved it, but I'm not satisfied with my answer since it is too intuitive. Let $I=(3-\sqrt{2})$.
Since $3+I=\sqrt{2}+I$, $9+I=2+I$ hence $7+I=I$. Hence the characteristic of the quotient ring $\mathbb{Z}[\sqrt{2}]/(3-\sqrt{2})$ is not greater than $7$. For this reason, I expected $n$ would be $7$. Define $\phi(1)=\bar{1}$ and $\phi(\sqrt{2})=\bar{3}$. Since $2$ is square-free the function $\phi:\mathbb{Z}[\sqrt{2}]\rightarrow \mathbb{Z}_7$ is well defined. Then, it can be directly checked that $\phi$ is a ring epimorphism. Let $a+b\sqrt{2}\in \ker(\phi)$. Then, $a+3b \equiv 0 \pmod 7$ Thus for some $k$, $a+3b=7k$. Note that every element in $(3-\sqrt{2})$ is of the form $3c-2d+\sqrt{2}(3d-c)$. Define $A=3-2k, B= 3k-1$. Note that $a+3b=7k=A+3B$. Thus, $a=A+3l$ and $b=B-l$ for some $l$. Thus. $a=(3+3l) - 2k , b=3k - (1+l)$. Thus, $a+b\sqrt{2}\in I$. This shows that $\ker(\phi)=I$. This proves the problem. Q.E.D. Is there another way to prove this?","['abstract-algebra', 'alternative-proof']"
1229117,How to calculate $\lim_{n \to \infty}\sqrt[n]{\frac{2^n+3^n}{3^n+4^n}}$,"I came across this strange limit whilst showing convergence of a series:
$$\lim_{n \to \infty}\sqrt[n]{\frac{2^n+3^n}{3^n+4^n}}$$
How can I calculate this limit?","['limits-without-lhopital', 'limits']"
1229131,Convergence of $\sum \frac{a_n}{1+a_n}$ when $\sum a_n$ and $\sum a_n^2$ converges.,"Suppose $a_n$ are real numbers and $\sum a_n$ and $\sum a_n^2$ converges. How would one go about showing that $\sum \frac{a_n}{1+a_n}$ converges?
($a_n \neq -1$ for every $n$)",['sequences-and-series']
1229134,What is the limit as k approaches infinity of $(k!)^{\frac{1}{k}}$ [duplicate],"This question already has answers here : $\lim\limits_{n \to{+}\infty}{\sqrt[n]{n!}}$ is infinite (12 answers) Closed 9 years ago . What is the value of
$$\lim_{k\to\infty}(k!)^{\frac{1}{k}}?$$ One of my students concluded the limit was infinity – which I tend to agree with, but was unable to show that was the limit.  We knew  $k!$ was tough to beat, but $k^k$ does – so this situation was unclear.","['factorial', 'radicals', 'sequences-and-series', 'limits']"
1229168,Therem of Residue application,"I want to determinate the following integral: $$\int_{\gamma} \frac{e^z}{\cos{(z)}} dz$$ Where $\gamma (t)=\frac{\pi \cos t}{1 +\sin^2 t}(1+i\sin t)$ , $0\leq t \leq 2\pi$ So I see that $\gamma$ is too much complicated to simplify. I have a feeling that I just need to play with the parametrization and substitute $dz$ by $z'dt$ to make a legitim simplification. But after of some hard work I did get to no where. So I'm asking for tips and another ways to solve this problem :)","['complex-analysis', 'residue-calculus', 'integration']"
1229184,$3 \times 3$ matrices are similar if and only if they have the same characteristic and minimal polynomial,"I want to prove: $B$ is similar to $A \Leftrightarrow m_A(x) = m_B(x)$ and $P_A(x) = P_B(x)$, where $m,P$ are the minimal and characteristic polynomial, respectively. ""$\Rightarrow$"" Let $A$ to be similar to $B$, then they have the same rational canonical form. On the other hand, the characteristic polynomial is the product of the invariant factors, but the invariant factors of an $n \times n$ matrix over a field $F$ are the invariant factors of its canonical form. Since $A,B$ have the same rational canonical form, then the characteristic polynomials are the same, hence: $P_A(x) = P_B(x)$, but the minimal polynomial is the largest invariant factor, so the minimal polynomials are the same and every other invariant factor divides the minimal polynomial, hence: $m_A(x) = m_B(x)$. (This comes from the fact that similar matrices have the same determinant) ""$\Leftarrow$""
Let $A, B \in M_3(F)$ with the property that they have the same characteristic and minimal polynomial, that is:
$P_A(x) = P_B(x) = f(x),$
$m_A(x) = m_B(x) = g(x).$
we want to prove that $A$ and $B$ are similar. First, recall that since we have a $3 \times 3$ matrix, this implies that the characteristic polynomial will have degree $3$, $g | f$ and every irreducible factor of $f(x)$ appears in $g(x)$. Moreover the degree of $g(x)$ is at most $3$. To prove similarity, it is enough to prove that they have the same set of invariant factors, which implies that the companion matrices will be the same. $\deg(g(x)) = 3$
If the degree of $g(x)$ is $3$, basically we cannot do a lot, so, we have that: $f(x) = g(x)$, so in this case the minimal polynomial is just $f(x)$ which implies that they are similar. $\deg(g(x)) = 2$
Notice that $f(x) = (x-a)g(x)$ for some $a \in F$ and $(x-a)$ is irreducible. On the other hand, every irreducible factor of the characteristic polynomial must appear in $g(x)$, which implies that: $g(x) = (x-a)(x-b)$ for some $b \in F$ and $f(x) = (x-a)^2 (x-b)$. Again, in this case the set of invariant factors is given by
$\{(x-a),(x-a)(x-b)\}$
Then, they share the same invariant factors, so the companion matrices are the same, hence there are similar. $\deg(g(x)) = 1$
clearly, we have that: $g(x) = (x-a)$ for some $a \in F$. Then, the only possibility is that the invariant factors have the following form:
$$\{(x-a),(x-a),(x-a)\}$$
Then, the matrices, $A,B$ have the same set of invariant factors and the same companion matrix, which implies that they are similar","['abstract-algebra', 'linear-algebra', 'proof-verification']"
1229203,Let $G$ be a finite group and let $P$ be a Sylow p-subgroup with $N_G(P)=P$. Prove that $P$ is not contained in any proper normal subgroup of $G$.,"Let $G$ be a finite group and let $P$ be a Sylow p-subgroup with $N_G(P)=P$. Prove that $P$ is not contained in any proper normal subgroup of $G$. We can suppose $P \subseteq K\lhd G$. Since $P$ is a p-group, it is contained in some Sylow p-subgroup $K ⊂ G$. 
Since $K$ is a solvable group. and we have $\forall g \in G, gPg^{-1} \subseteq gKg^{-1}$ which then is K since it is normal. There is theorem that says, If P is a Sylow p-subgroup of a finite group G, then $N_G(N_G(P))=N_G(P)$ Now, I am supposing that I must then find a contradiction to this???","['abstract-algebra', 'group-theory', 'normal-subgroups']"
1229228,In an abelian category is it true that $\ker f \cong \ker (\operatorname{coker} (\ker f))$?,"In an abelian category is it true that $\ker f \cong \ker (\operatorname{coker} (\ker f))$? I am teaching myself category and was playing with the definitions of kernel and cokernel and think I established this result (and of course dually that 
$\operatorname{coker} f \cong \operatorname{coker} (\ker (\operatorname{coker} f))$ ). The trouble is, that I haven't seen it in any of the texts and lecture notes I have been reading so perhaps I am wrong. Here is my reasoning (which would look simpler if I could work out how to draw the commutative diagram in LaTeX): Let $f:A\to B$.  Then there exists $i: \ker f \to A$ with $f\circ i = 0$.  Hence there exists $q: A \to \operatorname{coker} (\ker f)$ with $ q\circ i = 0$.
Hence there exists $j: \ker (\operatorname{coker}(\ker f)) \to A$ such that $q\circ j = 0$. We thus have two maps: $0 = q\circ i : \ker f \to A \to \operatorname{coker} (\ker f)$ and $0 = q\circ j : \ker (\operatorname{coker} (\ker f)) \to A \to \operatorname{coker} (\ker f)$
and so by the universal property of kernels we must have that $\ker f \cong \ker (\operatorname{coker} (\ker f))$.","['abstract-algebra', 'category-theory']"
1229233,$\operatorname{tr}(A)=\operatorname{tr}(A^{2})= \ldots = \operatorname{tr}(A^{n})=0$ implies $A$ is nilpotent,"$\DeclareMathOperator{\tr}{tr}$ Let's consider a $n \times n$ matrix and the sequence of traces $\tr(A)=\tr(A^{2})= \ldots = \tr(A^{n})=0$ . How to prove that $A$ is a nilpotent matrix (a matrix so that $A^{k} \times u = 0$ for all $u \in V$ and for some $k$ )? Maybe it would be reasonable to consider $A$ 's Jordan form (we assume that the action occurs over an algebraically closed field, such as $\mathbb{C}$ ). For example, suppose that we have found it and $A'$ consists of $m$ blocks of sizes $r_{1}, \ldots r_{m}$ ( $r_{1}+r_{2}+\ldots+r_{m}=m, r_{i} \in \mathbb{Z}_{+}$ ) with $\alpha_{1}, \ldots \alpha_{m}$ as corresponding eigenvalues to each of the blocks. Then, according to the problem will get the system $$\begin{align}
r_{1}\alpha_{1}+&\ldots+r_{m}\alpha_{m}=0 \\
r_{1}{\alpha_{1}}^{2}+&\ldots+r_{m} {\alpha_{m}} ^{2}=0\\
&\ ~\,\vdots \\
r_{1}{\alpha_{1}}^{n}+&\ldots +r_{m}{\alpha_{m}}^{n}=0 
\end{align}$$ But the system's analysis over $\mathbb{C}$ seems to be too much complicated. Actually, the problem must have more or less simple solution. Any piece of advice would be much appreciated.","['polynomials', 'linear-algebra', 'trace', 'matrices']"
1229234,"How can I prove if $A\subseteq B$, then $A\cup B=B$?","I need to prove that  $$A\subseteq B \implies A\cup B=B$$ I defined the subset relation as the statement $x\in A\Rightarrow x\in B$. I tried to convert the claim into a logic statement, then proceeded to simplify the statement $$(x\in A\Rightarrow x\in B)\Rightarrow(x\in A\vee x\in B),$$ and I simplified it to $x\in A\vee x\in B$. Only after I did this did I realize that this didn't really prove anything. This fact seems to be taken axiomatically—I haven't been able to find any proofs for it. I found that it is proposed under Wikipedia's Proposition 8 under ‘Algebra of Sets’ that this is true, and equivalent to the subset relation. A proof of this, however, escapes me. I also realize that it would be sufficient to be able to convert the antecedent to the consequent or vice versa (which would result in the tautology $p\Rightarrow p$ and thus prove the statement), though I do not know how to do this.",['elementary-set-theory']
1229251,Can anyone clarify why this is?,"The question is to prove: $$I=\int_{-\infty}^{\infty}e^{-x^2}\,\Bbb dx=\sqrt{\pi}.$$ Let \begin{align} I_r&=\int_{-r}^{r}e^{-x^2}\,\Bbb dx \\ \implies I_r^2&=\int_{-r}^{r}e^{-x^2}\,\Bbb dx\int_{-r}^{r}e^{-y^2}\,\Bbb dy \\ &=\iint_{[-r,r]^2} e^{-x^2-y^2}\,\Bbb dx\,\Bbb dy. \end{align} $x^2+y^2\leq r^2=D_r$ $$K_r=\iint_{D_r}{e^{-x^2-y^2}}\,\Bbb dx\,\Bbb dy$$ $$0\leq I_r-K_r=\int_{Q_r \setminus D_r}e^{-x^2-y^2}\,\Bbb dx\,\Bbb dy\leq e^{-r^2}\mu(Q_r)=e^{-r^2}4r^2\rightarrow0; r\rightarrow \infty.$$ The rest is clear to me just this last inequality: $\leq e^{-r^2}\mu(Q_r)$ , where $\mu(A)$ is a measure of $A$ . I’ll type out the rest of the proof if need be, for educational purposes $\ldots$","['calculus', 'measure-theory', 'integration']"
1229255,Proving that $n$ and $m$ divides $1^{n}+2^{n}+3^{n}+\cdots+m^{n}$,"For which positive integers $m, n$ is true that the number $$1^{n}+2^{n}+3^{n}+\cdots+m^{n}$$ is divisible by $n$ and $m$?",['number-theory']
1229261,Constructive Expectation Question,"Six balls numbered $1$ through $6$ are in a bin. You randomly draw them out one at a time, without replacement, and put them into boxes numbered $1$ through $6$ (one ball in each box). For each ball whose number matches the number of the box you put it in, you win that number of dollars. (For example, if ball $\#2$ ends up in box $2$, you win $\$2$ for that ball.) What are your expected total winnings (in dollars)? Would the answer be $(6)(21/6)=21$? Because the expected winning for each roll is $(1/6)(1+2+3+4+5+6)$ and there are $6$ rolls Thanks!",['combinatorics']
1229283,Learning modern differential geometry before curves and surfaces,"What might one miss by learning modern differential geometry without first learning about curves and surfaces? I'm currently reading this book on differential geometry which starts with manifolds and builds from there. I'm already deep inside it and it's a perfect fit for me. Still, I wonder what i might have missed by skipping on learning the ""classical"" differential geometry. The book has a chapter about hypersurfaces but i'm still a bit worried that i might miss something important. What are some important notions from classical differential geometry i better know?","['differential-geometry', 'learning']"
1229289,Solving Eikonal Equation $u_x^2+u_y^2=u^2$,"The problem is the following: I have the bidimensional eikonal equation with non-constant propagation: $u_x^2+u_y^2=u^2$ The goal is: i) To find the characteristic strips for the parametrization $x=f(s)$ , $y=g(s)$ and $z=u(f(s),g(s))=h(s)$ ; ii)To find the integral surfaces passing through the circle $x=cos(s)$ , $y=sin(s)$ , $z=1$ ; iii)To find the integral surfaces through the line $x=s$ , $y=0$ , $z=1$ . Writing the equation in general form, $F(x(s),y(s),u,p(s),q(s))=0$ , i.e., $p^2+q^2-u^2=0$ , where $p=u_x, q=u_y$ ,we have, for the item i), the following system of EDO's: $\frac{dx}{ds}=F_p=2p$ $\frac{dy}{ds}=F_p=2q$ $\frac{dz}{ds}=pF_p+qF_q=2(p^2+q^2)$ $\frac{dp}{ds}=-F_x-pF_u=2(u_xu+pu)$ $\frac{dq}{ds}=-F_y=2(u_yu+qu)$ For item ii), I know the answer is $z=\exp[\pm (1-\sqrt{x^2+y^2})]$ , but I don't know how to find it; For item iii), I know the answer is $u=\exp(\pm y)$ , but I don't know how to find it. Suggestions to solve the problem?","['applications', 'ordinary-differential-equations', 'partial-differential-equations']"
1229325,3D Dodecahedron model: Construction question.,"The image below is a 2D construction that, when cut-out and folded appropriately (hopefully it is intuitively clear how to cut and fold), forms a 3D dodecahedron. It works great: I've successfully used it to build a very nice dodecahedron. The problem I'm trying to solve is, given a rectangular piece of paper (mine happens to be 32"" X 40"", but any rectangle reasonable for the construction could be substituted), what is the largest such pattern that can be drawn? As one aid to this, I am basing my construction on Steiner's Porism (using concentric circles with the radii in a given ratio to fill in the annular region with a chain of sequentially tangent circles, each of which is also tangent to the inner and outer circle). This specific part of the construction is significant only in that it makes the problem of constructing the largest possible dodecahedron cut-out within the given rectangular region somewhat simpler (to my mind at least), because one can now draw two circles with the same diameter to fill the page. The problem is that the relationship between these two circles is not something simple like tangency. They overlap (as the diagram shows), but by how much? In the diagram, one can imagine the line 'm' as dividing the sheet of paper in half by cutting the longer dimension. I'm taking it as given by the phrase 'reasonable rectangle for this construction' that one of the circles can be centered along the similarly defined dividing line for the shorter dimension. My problem, really, is to place the points A, B, and C, where the midpoint of A and B is on the dividing line for the shorter dimension, and making the circles as large as possible while still fitting on the page. Purely empirically, I measured $\angle BAC = 8$ and the angle between dividing line m and and edge of the right hand ""outer"" pentagon, as 16 degrees (as labeled on the diagram).","['polyhedra', 'geometry']"
1229345,Question about Dominated Convergence Theorem.,"How to compute $$\lim_{n \to \infty}\int_0^{\infty}\Big(1+\frac{x}{n}\Big)^{-n}\sin\Big(\frac{x}{n}\Big) dx$$ I want to use the Dominated Convergence Theorem. so it becomes $$\int_0^{\infty}\lim_{n\to \infty}\Big(1+\frac{x}{n}\Big)^{\frac{n}{x}(-x)}\sin\Big(\frac{x}{n}\Big) dx=\int_0^{\infty}e^{-x}\times 0 dx=0$$ I have trouble finding the dominating term, which is essential for me to apply dominated convergence theorem. Could anyone help me with this? Thanks!","['real-analysis', 'lebesgue-integral']"
1229364,"If every element of G/H has finite order and every element of H has finite order, then every element of G has finite order","Let $G$ a group with normal subgroup $H$. If every element of $G/H$ has
  finite order and  every element of $H$ has finite order, then every
  element of $G$ has finite order Proof: Let G be a group with normal subgroup H. Suppose that every element of G/H has finite order and that every element of H has finite order. We want to show $G$ has finite order. Let $x \in G$ then by coset and quotient group definition, $Hx \in G/H$ has $Hx$ has finite order $n$ or in other words $(Hx)^n=e$. Also for some $h \in H$, it also has a finite order where $h^m=e$ I'm stuck on how to link it together. Any input?",['abstract-algebra']
1229374,Deriving the value of $\pi$ from a dart board,"I saw this on a website and it was pretty interesting: The circle inscribed in the square has a radius of $1$ and the square has a side length of $2$. This means that the area of the circle is: $$\pi \times r^{2} = \pi \times (1^2) = \pi$$ Moreover, the area of the square is: $$(2^2) = 4$$ Then, we can randomly select points within the square and get a good approximation of pi by doing this thousands to millions of times, maybe by a computer sequence. Once we've repeated this process enough, we can plug our values into this equation: $$ \frac{\pi}{4} = \frac{\text{Number of points within the circle}}{\text{Total number of points}}$$ Is this a viable approach to approximate the value of $\pi$?","['geometry', 'probability', 'pi']"
1229443,Power set of a subset,"Proof that if $A \subseteq B$, then ${\mathscr P}(A) \subseteq {\mathscr P}(B)$. I tried using the definition of a subset: $A \subseteq B = \forall x(x \in A \to x \in B)$, but get stuck as to how to use it to write the power sets of A and B.","['elementary-set-theory', 'discrete-mathematics']"
1229548,Reduction modulo p of a linear group over the rational numbers,"A paper ( http://arxiv.org/pdf/1407.3158v2.pdf ) contains the following theorem: Suppose $\mathbb{G}$ is a connected, simply connected, semisimple algebraic group defined over $\mathbb{Q}$, and let $\Gamma \leq \mathbb{G}(\mathbb{Q})$ be a finitely generated Zariski-dense subgroup. Denote by $\mathbb{G}_p$ the smooth reduction of $\mathbb{G}$ over $\mathbb{F}_p$. Then for all sufficiently large prime numbers $p$, the reduction $\Gamma_p$ of $\Gamma$ is equal to $\mathbb{G}_p (\mathbb{F}_p)$. What confuses me is the so-called smooth reduction happening. I would understand this if $\mathbb{G}$ were defined over $\mathbb{Z}$ because then we can just take all the matrix entries modulo $p$, but what can it mean for a rational number to be reduced in this way, if that is indeed what is happening? EDIT It would help to have also an example of how this reduction would apply to an element of $\operatorname{GL}_n(\mathbb{Q})$. EDIT 2 I received the following answer to this question in a chatroom, but it is far too complicated for me to understand. In particular, I know little to no algebraic geometry, and I am only beginning to learn category theory. $\mathbb{G}$ is defined over $\operatorname{Spec} \mathbb{Q}$, so it's of finite type (over $\operatorname{Spec} \mathbb{Q}$), and so you can take the ideal sheaf locally and restrict it to $\mathbb{Z}$. -- hodgeclass","['modular-arithmetic', 'algebraic-groups', 'abstract-algebra', 'algebraic-geometry', 'finite-fields']"
1229575,Characterisation of limit points of subsets of Hausdorff spaces,"The theorem which I want to show is the following: For a Hausdorff space $X$ and a subset $A$ of $X$, $x$ is a limit point of $A$ if and only if every neighborhood of $x$ contains infinitely many points of $A$. And this is my answer; (⇒) Suppose not. Then there is a neighborhood of $x$, say $M$, which has finitely many points $a_1, \ldots, a_n$ of $A$. Since $M$ is an open set containing $x$, $M$ must contain a point of $A$ distinct from $x$. 
Then, there exist open sets $U_1 ,U_2, \ldots, U_n$ and $V$ in $X$ such that each $U_i$ contains in $a_i$ for $i=1,\ldots,n$ and $V$ contains $x$, and all of $U_1,\ldots,U_n$ and $V$ are disjoint, since $X$ is Hausdorff space.
Then, since $V$ is an open set containing $x$, $V$ contains another point $a_{n+1}$ of $A$ distinct from $x$. Thus, $M$ has $n+1$ points of $A$; contradiction! (⇐) Suppose not. Then $x$ is not a limit point of $A$; there is an open set $O$ containing $x$ and contains no point of $A$ but $x$. Then $O$ is a neighborhood of $x$. Thus $O$ has infinitely many points of $A$. This is contradiction. Is it correct? And if $A$ is a neighborhood of $x$ means interior of $A$ contains $x$; $A$ is an open set containing $x$?",['general-topology']
1229580,Differentiating exponential functions - is base e the only situation?,My maths book gives the example of; Where $$ f = e^x $$ $$ f` = e^x $$ It only uses the example of base e in all of the questions so does that mean this is the only situation where the differential of an exponential function is the same as the original?,"['calculus', 'ordinary-differential-equations', 'exponential-function']"
1229674,Explicit construction of retraction for Brouwer's fixed point theorem (disk),"So I'm trying to prove the Brouwer fixed-point theorem for the disk, arguing by contradiction and using the theorem that states that there is no retraction from the unit disk $D^2$ to the unit circle $S^1$.  Assuming that for all $x\in D^2$, $f(x)\neq x$, we see that the line connecting $f(x)$ and $x$ is not degenerate, i.e. not a point.  I'm attempting to define the retraction $r:D^2\to S^1$ as the map that sends $x$ to an intersection of the line connecting $x$ and $f(x)$ and the circle, particularly the one with closer distance to $x$, so that if $x\in S^1$, then $r(x)=x$.  However, I'm having a bit of an issue explicitly defining this function; I used the equations given here as a guide: http://mathworld.wolfram.com/Circle-LineIntersection.html but to show which one of the intersections is closest to $x$ seems like a very algebraically messy process.  Is there an easier way to construct this retraction?  If I've left anything out, I apologize, of course.  Thanks.","['algebraic-topology', 'general-topology']"
1229688,Evaluating $\lim\limits_{x \to 0}\left(\frac{\sin x}{x}\right)^{\frac{1}{1-\cos x}}$,"How do I evaluate
$$\lim_{x \to 0}\left(\frac{\sin x}{x}\right)^{\dfrac{1}{1-\cos x}}\ ?$$ I tried using the fact that $\left(\frac{\sin x}{x}\right)^{\frac{1}{1-\cos x}} = \exp\left(\ln\bigg(\frac{\sin x}{x}\right)\frac{1}{1-\cos x}\bigg)$ and then I am already stuck.","['calculus', 'limits']"
1229692,When is $G\cong\operatorname{End}(G)$?,"$\newcommand\End{\operatorname{End}}$Let $G$ be an Abelian group. Are there sufficient conditions for the existence of an isomorphism $G\cong\End(G)$, where $\End(G)$ is considered a group under addition?
This is true for $\mathbb Z$ and $\mathbb Q$, but not (as far as I know) for $\mathbb R$, where you can construct monstrous additive functions from the Axiom of Choice. Side questions for people to consider: If $R$ is a ring, when will it be isomorphic (as a ring) to the ring $\End_{\text{group}}(R)$ of group endomorphisms? When will it be isomorphic to the ring $\End_{\text{ring}}(R)$ of ring endomorphisms?","['ring-theory', 'group-theory']"
1229704,"Request For An Example Of A Continuous Map Relative To The Box Topology On $\mathbb{R}^J$, When $J$ Is Infinite","Let $J$ denote an infinite --- countable or uncountable --- index set. Let $\mathbb{R}^J$ denote the set of all $J$-tuples of real numbers (i.e. the set of all real-valued functions with domain $J$) under the box topology having as basis all Cartesian products of the form 
$$B \colon= \Pi_{\alpha \in J} \left(a_{\alpha}, b_{\alpha} \right) = \left\{ \ (x_{\alpha})_{\alpha \in J} \ \colon \ x_{\alpha} \in (a_\alpha, b_\alpha ) \ \right\},$$ 
where 
$$ \left(a_{\alpha}, b_{\alpha} \right) \colon= \left\{x_{\alpha} \in \mathbb{R} \ \colon \ a_{\alpha} < x_{\alpha} < b_{\alpha} \ \right\}.$$ Then is there an example of a ""non-constant"" continuous function $f$ from $\mathbb{R}$ to $\mathbb{R}^J$, especially when $J$ is uncountable? Even the function $f \colon \mathbb{R} \to \mathbb{R}^{\mathbb{N}}$ defined by 
$$ t \mapsto (t, t, t, \ldots )$$ 
fails to be continuous! What would be the form of such continuous functions, I wonder? An afterthought: Is it true that such functions necessarily have to consist of constant functions except in only finitely many coordinates? That is, is it true that if 
$f \colon \mathbb{R} \to \mathbb{R}^J$ is to be given by 
$$f(t) \colon = \left( f_\alpha (t) \right)_{\alpha \in J} \ \ \ \forall \ t \in \mathbb{R},$$
where $f_\alpha \colon \mathbb{R} \to \mathbb{R}$ for each $\alpha \in J$, then in order for $f$ to be continuous, all the functions $f_\alpha$ are constant functions except possibly for only finitely many indices $\alpha$?",['general-topology']
1229732,Differential Form Pullback Definition,"I'm having some difficulty following how Spivak (Calculus on Manifolds) has induced the pullback on page 89. From reading elsewhere online it seems convention is to define the induced map of the pushforward of a differentiable function $f: \mathbb R^n \to \mathbb R^m$ with the corresponding linear transformation $Df(p): \mathbb R^n \to \mathbb R^m$ as $$f_*: \mathbb R^n_p \to\mathbb R^m_{f(p)}$$$$f_*(v_p) = (Df(p)(v))_{f(p)}$$ and to then use this definition for the pullback, defined as $$f^*:\Lambda(\mathbb R^m_{f(p)})\to \Lambda(\mathbb R^n_p)$$$$f^*\omega(p)(v_1, .., v_k) = \omega(f(p))(f_*(v_1),..., f_*(v_k)),$$where $\omega$ is a k-form on $\mathbb R^m.$ However Spivak has offered the induced definition for the pullback as $$(f^*\omega)(p) = f^*(\omega(f(p))).$$ which then leads to the above definition. I'd be grateful for any help explaining the intuition behind this.","['differential-geometry', 'multivariable-calculus', 'differential-forms']"
1229764,Bounds on Maclaurin series of $e^{-x^2}$,"This is a problem from a textbook: By taking the 4th degree Maclaurin polynomial for $e^{-x^2}$ find an approximation to $\int^1_0 e^{-x^2} \,dx$ . Place bounds on the error in this approximation. The first part is done by substituting $-x^2$ in series $$ e^{x}  =  1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots $$ yielding $$e^{-x^2} = 1 - x^2 + \frac{x^4}{2!} + \cdots $$ Integrating gives $$ \int^1_0 e^{-x^2}\,dx \approx x - \frac{x^3}{3} + \frac{x^5}{10} \bigg|^1_0 = \frac{23}{30}$$ Which is correct according the answer. However, I do not know how they have computed the bound, error < $2.38 \times 10$ May someone explain? Thank you so much!","['power-series', 'approximation', 'integration']"
1229767,Every local property for $\mathbb{R}$ (any Connected Separable Space) holds globally?,"I'm given this problem : Prove that ""being polynomial"" is a local property , meaning if $f: ℝ → ℝ$ is a polynomial in a neighborhood of each real point, then $f$ is a polynomial. I think I have proved a more general proposition, but I need verification of my proof ! Conjecture : For any Separable Connected Topological space $(X,\tau)$, every local property $\phi(f)$ for some function $f:X\rightarrow Y$, holds entirely over $X$. my proof : For each $x\in X$ define $U_x$ as follows : $\displaystyle U_x:=\bigcup_{\substack{x\in U'_x\in\tau \\ \; U'_x\text{has property}\phi}}U'_x \quad$ $\bigg($*It's the Maximal Open Set Containing $x$ $\underline{\text{with property $\phi$}}$(??)*$\bigg)$ Lemma . $\forall x,y\in X :\;U_x=U_y\;\vee\;U_x\cap U_y=\emptyset$. proof . If there's $z\in X$ that $z\in U_x\cap U_y$, then since $z\in U_x\in\tau$, so $U_x\subseteq U_z$. Since $U_z$ is a suitable open set containing $x$ and $U_x$ is maximal, therefore $U_z\subseteq U_x$. $\quad\triangledown$ Corollary. $\{U_x\}_{x\in X}$ is a partition for $X$. Let $A$ be the countable dense subset of $X$. Then by Axiom of Choice , there exists the sequence $\{q_n\}_{n\in\mathbb{N}}\subseteq A$, such that 
$\{U_{q_n}\}_{n\in\mathbb{N}}$ is a disjoint partition for $X$. Claim. $\forall n:\; U_{q_n}=X$. proof. Suppose $U_{q_n}\subsetneqq X$. Since $X$ is connected , $U_{q_n}\subsetneqq\overline{U_{q_n}}$. Let $y\in\overline{U_{q_n}}\setminus U_{q_n}$. Then there exists $m$ such that $y\in U_{q_m}$. Now as $y$ is an interior point of $U_{q_m}$, so there is an open subset of $U_{q_m}$ around $y$. BUT each neighborhood of $y$ has nonempty intersection with $U_{q_n}$. Hence $U_{q_n}\bigcap U_{q_m}\neq\emptyset.\quad$($\bot$) Theorem. Above conjecture is TRUE !????","['proof-verification', 'connectedness', 'general-topology']"
1229783,Solve the limit $\lim\limits _{x\to 0}\frac{\sqrt{1-\cos\left(x^2\right)}}{1-\cos\left(x\right)}$,$$\lim _{x\to \:0}\frac{\sqrt{1-\cos\left(x^2\right)}}{1-\cos\left(x\right)}=\left|\frac{0}{0}\right|$$ I think you have to multiply by the conjugate. And then make the change equivalent small. Right?,['limits']
1229803,"Prove $\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,$ [duplicate]","This question already has answers here : Proof of $\int_{[0,\infty)}pt^{p-1}\mu(\{x:|f(x)|\geq t\})d\mu(t)=\int_{[0,\infty)}\mu(\{x:|f(x)|^p\geq s\})d\mu(s)$ (4 answers) Closed 6 years ago . Let $(X,\mathcal{M},\mu)$ be a measure space and $f$ be a nonnegative measurable function on $X$. Let $1\le p<\infty$. Show that, the function $|f|^p$ is integrable with respect to $\mu$ precisely when the function $$t\mapsto t^{p-1}\mu({x:|f(x)>t})$$ is integrable on $[0,\infty)$ with respect to Lebesgue measure. In addition prove that 
  $$\int_X |f|^p=p\int^{\infty}_{0} t^{p-1}\mu({x: |f(x)>t}) dt\,$$ I solved this problem for the case when space is sigma finite but don't know how to solve for general case.",['measure-theory']
1229804,Under what conditions is a linear automorphism an isometry of some inner product?,"Assume $V$ is a finite-dimensional vector space over $\mathbb{R}$, and that $T: V \to V$ is a (linear) isomorphism. When is it possible to construct an inner product on $V$ 
  making $T$ an isometry? (Hopefully, I am looking for necessary & sufficient conditions $T$ should satisfy, i.e. a full characterization of the situation). What I have so far: A necessary condition: all the real eigenvalues of $T$ are of absolute value $1$. (Since $ T(v)=\lambda v \Rightarrow  \langle v,v\rangle=\langle Tv,Tv\rangle = \langle \lambda v, \lambda v\rangle = \lambda^2\langle v, v\rangle$ and an eigenvector $v$ must be nonzero.) This condition is certainly not sufficient: For example look at $A$ = $\begin{pmatrix} 1 & 1 \\\ 0 & 1 \end{pmatrix}: \mathbb{R}^2 \to \mathbb{R}^2$. It is an automorphism which has only one eigenvalue ($\lambda = 1$). However, $A\begin{pmatrix} x \\ y \end{pmatrix}= \begin{pmatrix} x+y \\ y \end{pmatrix}$, hence $A^n\begin{pmatrix} x \\ y \end{pmatrix}= \begin{pmatrix} x+ny \\ y \end{pmatrix}$ and the requirement $A:(\mathbb{R}^2,\langle \rangle) \to (\mathbb{R}^2,\langle \rangle) $ to be an isometry for some inner product $\langle \rangle$ implies: $\lVert \begin{pmatrix} x \\ y \end{pmatrix}\rVert^2=\lVert A^n\begin{pmatrix} x \\ y \end{pmatrix}\rVert^2\Rightarrow x^2 \lVert e_1\rVert^2+y^2 \lVert e_2\rVert^2+2xy\langle e_1,e_2\rangle = (x+ny)^2 \lVert e_1\rVert^2+y^2 \lVert e_2\rVert^2+2y(x+ny) \langle e_1,e_2\rangle \Rightarrow 0=(2nxy+n^2y^2)\lVert e_1\rVert^2+2ny^2 \langle e_1,e_2\rangle$. So we get that $0=(2xy+ny^2)\lVert e_1\rVert^2+2y^2 \langle e_1,e_2\rangle$ for any $x,y\in \mathbb{R}, n\in \mathbb{N}$ which is a contradiction since $\lVert e_1 \rVert > 0$. Some sufficient conditions: 1)  If $T$ is diagonalizable over $\mathbb {R}$ (with all eigenvalues $1$ or $-1$, by our necessary condition), then let ${V_1,...,V_n}$ be a basis of eigenvectors of $T$ , and define $\langle v_i,v_j\rangle = \delta_{ij}$. $T$ will be an isometry. This condition is certainly not necessary: just take a rotation (say by $90^{\circ}$) in the plane. note that it is diagonalizable over $\mathbb{C}$. My guess is that if our transformation is diagonalizable over $\mathbb{C}$ (with all eigenvalues with absolute value 1) a similar construction like the above will work. One problem I see with this approach is that an odd-dimensional $\mathbb{R}$-vector space cannot even be considered as a $\mathbb{C}$-vector space. (Though we can always complexify...). 2) $T$ is of finite order. (Then we just start with any inner product on $V$ and construct a new one via summing over iterates of $T$, i.e: $\langle v,w \rangle ' = \sum_{i=0}^{n-1} \langle T^iv,T^iw \rangle $). Note that (as explained for instance here ) this implies $T$ is diagonalizable over $\mathbb{C}$, but of course not necessarily over $\mathbb{R}$. (Think about our rotation again.) Actually, I have now understood that condition (1) implies $T$ is of order 2, (I think the reverse implication also holds, i.e $T^2=Id\Rightarrow T$ is diagonalizable). So condition (1) is a particular case of (2). However, (2) is  not necessary, since any rotation of irrational multiple of 2$\pi$ is an isometry w.r.t the standard product, but of infinite order. I somehow think the right way to handle this question is to think over $\mathbb{C}$, but I am not sure how to do this.","['isometry', 'linear-algebra', 'inner-products', 'linear-transformations']"
1229810,"Prove $\{ (x,y) \in [0,1]^2: x-y\in \mathbb{Q}\}$ is measurable.","Let $T:=\{ (x,y) \in [0,1]^2\ :\ x-y\in \mathbb{Q} \}$. Show that $T$ has measure zero, but it meets every set of the form $A \times B$ , where $A$ and $B$ are measurable sets of positive measure in $[0,1]$. T is measurable since it will be countable union of lines in $[0,1]^2$ and thus will be of measure zero, but why does it intersect every $A \times B$ ?",['measure-theory']
1229815,How do I prove that $\alpha/\lVert\alpha\rVert$ is differentiable?,Let $\alpha\colon I\rightarrow \mathbb{R}^3$ be a $C^2$-curve such that $\alpha(t)\neq 0$. How do I prove that $\alpha/\lVert\alpha\lVert$ is differentiable?,"['analysis', 'multivariable-calculus']"
1229849,Paired and unpaired data-Statistics/Hypothesis testing,"I'm getting a bit confused about paired and unpaired data, for example in this question I don't understand how this data is paired. If it was the same steel pipes that were left uncoated first in the soil to see the effects of corrosion and then taken out and were coated this time and then left in the soil to see the effects of corrosion then I understand the data would have been paired  because  the definition of paired data that I know is when there is one sample which has been tested twice (repeated measures) but here clearly it is different steel pipes that are left uncoated and coated so how is this data paired. So when deciding that data is paired or not what exactly are we supposed to look at? Also can I quickly check:
null hypothesis would be: mean1-mean2=0,
alternative hypothesis would be mean1-mean2>0,
where mean 1 is for uncoated pipes and mean 2 is for coated pipes
and our rejection region would be (using a t-statistic) t>t(alpha) , where alpha is 5%","['statistics', 'statistical-inference']"
1229870,If $A+B=\pi/3$ then what will maximum value of $\tan(A).\tan(B)$?,"Suppose I am given that $$A+B=\frac{\pi}{3}$$ then what will be maximum value of $$\tan(A).\tan(B)=?$$ $$\tan(A+B)=\frac{\tan(A)+\tan(B)}{1-\tan(A).\tan(B)}=\sqrt{3}$$
then 
$$\tan(A).\tan(B)=\frac{\sqrt(3)-[\tan(A)+\tan(B)]}{\sqrt{3}}=\lambda$$ now for $\lambda$ to be maximum $\tan(A)+\tan(B)$ should be minimum , how to minimise it? I can make guesses but that's not a good approach.","['calculus', 'derivatives']"
1229888,Is the algebraic closure of $\mathbb Q$ in the field $\mathbb Q_5$ a number field?,"Is the algebraic closure of $\mathbb Q$ in the field $\mathbb Q_5$ of $5$-adic numbers a number field, if yes what is the degree ? To be honest I don't understand the question, what does it mean to be the algebraic closure of $\mathbb Q$ in the field $\mathbb Q_5$? Maybe $\bar{\mathbb Q}\cap\mathbb Q_5$ ? on Wikipedia I saw also; ''The algebraic closure of a field $K$ has the same cardinality as $K$ if $K$ is infinite, and is countably infinite if $K$ is finite.'' Therefore If $\mathbb Q$ is not entirely contained in $\mathbb Q_5$, $\bar{\mathbb Q}\cap\mathbb Q_5$ cannot be a finite extension of $\mathbb Q$, is that correct ?","['p-adic-number-theory', 'field-theory', 'number-theory', 'algebraic-number-theory']"
1229897,Sum the infinite series,"How to solve this: \begin{equation*}
\sum_{n=1}^{\infty }\left[ \frac{1\cdot 3\cdot 5\cdots \left( 2n-1\right) }{
2\cdot 4\cdot 6\cdots 2n}\right] ^{3}
\end{equation*} I can make the bracket thing, $\left[ C(2n,n)/4^{n}\right] ^{3}$, but how to proceed now.","['sequences-and-series', 'calculus']"
1229923,How to find a definite integral over a symmetric interval without finding the antiderivative?,"How do I find the following without finding the anti derivative
$$
\int_{-\pi}^\pi \ln(x^2+1)e^{\sin \lvert x\rvert}\sin x dx 
$$","['calculus', 'functions', 'integration']"
1229929,When is it allowed to take a constant out of a series?,"When is it allowed to take a constant out of a series? Suppose we have a series $\sum ca_n$, when can we write it as $c\sum a_n$? It's pretty obvious when we know beforehand the series converges but what if we're asked to check if the series converges? Can we take it out and then if it does converge then the operation was legal (like with LHR)? Lastly, does it matter for diverging series?","['sequences-and-series', 'calculus', 'definition']"
1229936,"Calculate $\int_{C(0,2)^+} \frac{z^3}{z^5 - 1} dz$","How do I calculate this integral $\int_{C(0,2)^+} \frac{z^3}{z^5 - 1} dz$? What I have done so far is the following: set $z(t) = 2e^{it}$ with $t \in [0,2\pi]$ so we get. $$
\int_{C(0,2)^+} \frac{z^3}{z^5 - 1} dz = \int_{0}^{2\pi} \frac{(2e^{it})^3}{(2e^{it})^5 - 1}2ie^{it} dt = i\int_0^{2\pi} \frac{16e^{4it}}{32e^{5it} - 1}dt.
$$ Now setting $u(t) = 32e^{5it} + 1$ we get $du = 160ie^{5it}dt$. How should I continue?","['analysis', 'integration']"
1229942,Understanding the isomorphism of Picard group with the first cohomology group,"I am learning the subject for the first time, and the material has not yet settled inside me. I would like to get some intuitive understanding of the following: Let $X$ be a complex manifold. The Picard group $Pic(X)$ of $X$ is an abelian group of isomorphism classes of holomorphic line bundles on $X$. I want to first get a rough idea on why $Pic(X)$ is naturally isomorphic to the first cohomology group $H^1(X,\mathcal{O}^*_X)$ where $\mathcal{O}^*_X$ is the multiplicative sheaf of no-where vanishing holomorphic functions on $X$. How should I think of this isomorphism? I want to get some understanding, without going into the technical proof. Is it possible to understand the above result without getting into Cech cohomology?","['complex-geometry', 'algebraic-geometry']"
1230021,Can some one help me parametrize $\frac{x^4}{a^4}+\frac{y^4}{b^4}+\frac{z^4}{c^4}=1$,"Given a surface $$\frac{x^4}{a^4}+\frac{y^4}{b^4}+\frac{z^4}{c^4}=1$$how can I parametrize the surface using $X(u,v).$ I tried to use $$x=a\sqrt{\cos(\theta)\sin(\phi)}$$ $$y=b\sqrt{\cos(\theta)\sin(\phi)}$$ $$z=c\sqrt{\sin(\phi)}$$ but turns out it couldn't include all the points of the surface. Can some help me solve it? (The problem is that maybe we need to think about how to parametrize $x^4+y^4=1?$)","['calculus', 'real-analysis', 'geometry', 'analysis', 'differential-geometry']"
1230049,"Sum of every row, column and diagonal is equal to 0. Is it possible that none of the numbers is eqaul to zero?","A square with 2015 rows and 2015 columns is filled with integers. The sum of every row is equal to zero, the sum of every column is equal to zero, and sum of the two main diagonals is equal to zero. Is it possible that none of the numbers in square is equal to zero? How can I prove it?",['combinatorics']
1230051,Inverse Square Root Of Matrix,So let's say a matrix is A. Then how do you find A^-1/2 ? It seems to be different from finding the inverse of A. Could someone provide a simple example as explanation? Thanks a lot!!,"['statistics', 'matrices']"
1230164,Evaluate $\int \frac{dx}{1+\sin x+\cos x}$,Evaluate $$\int \frac{1}{1+\sin x+\cos x}\:dx$$ I tried several ways but all of them didn't work I tried to use Integration-By-Parts method but it's going to give me a more complicated integral I also tried u-substitution but all of my choices of u didn't work Any suggestions?,"['calculus', 'integration']"
1230173,"Elementary proof for $\sqrt{p_{n+1}} \notin \mathbb{Q}(\sqrt{p_1}, \sqrt{p_2}, \ldots, \sqrt{p_n})$ where $p_i$ are different prime numbers. [duplicate]","This question already has answers here : Proving that $\left(\mathbb Q[\sqrt p_1,\dots,\sqrt p_n]:\mathbb Q\right)=2^n$ for distinct primes $p_i$. (6 answers) Closed 9 years ago . Take $p_1, p_2, \ldots, p_n, p_{n+1}$ be $n+1$ prime numbers in $\mathbb{P} \subseteq \mathbb{N}$. $\sqrt{p_{n+1}} \notin \mathbb{Q}(\sqrt{p_1}, \sqrt{p_2}, \ldots, \sqrt{p_n})$ seems to be quite clear, but still need a proof. I know some proofs are involved with Galois theory, which is not I want.","['extension-field', 'abstract-algebra', 'prime-numbers']"
1230209,Generalization of Dirichlet convolution,"The Wikipedia page on the Mobius inversion formula gives the following formula in passing: if $$G(x)=\sum_{k=1}^x \alpha(x)F(x/k)$$ for some arithmetic function $\alpha(n)$ possessing a Dirichlet inverse $\alpha^{-1}(n)$, then $$F(x)=\sum_{k=1}^x \alpha^{-1}(k)G(x/k).$$ My question is the following: can we define an operator $*'$ analogous to Dirichlet convolution $*$ defined by the formula $$(f*'g)(x)=\sum_{k=1}^x f(k)g(x/k)$$ and if so what can we do with it? In particular, the formula from Wikipedia states that $(f*'g)*'f^{-1}=g$ where $f^{-1}$ is the Dirichlet inverse of $f$. For what function $f^{-1*}$ do we have $(g*'f)*'f^{-1*}=g$? (Clearly $f*'g \neq g*'f$.) In general, what else can we say about this convolution? Does there exist a transform analogous to Dirichlet convolution for which $*'$ is the convolution? If so, can we define it and is it useful? In addition, does anyone know the source of the Wikipedia theorem, and if so does the author discuss these or similar questions? My attempt to derive a formula to the above question about modified Dirichlet inverses ends up ""proving"" a false result; if anyone can spot the error, or even suggest how to fix it, that would be greatly appreciated. Define the function $$G(x)=\sum_{k=1}^x \alpha(k)F(\frac xk).$$ We now consider the sum $$\sum_{k=1}^x \alpha^{-1}(k)G(\frac xk)=\sum_{k=1}^x \alpha^{-1}(k) \sum_{j=1}^{x/k}\alpha(j)F(\frac x{kj})$$ by the definition of $G(x)$. Using Iverson bracket notation, we rewrite $$=\sum_{k=1}^x\alpha^{-1}(k)\sum_{j=1}^{x/k} \alpha(j) \sum_{r=1}^x [r=kj] F(x/r)=\sum_{r=1}^x F(x/r) \sum_{k=1}^x \alpha^{-1}(k)\sum_{j=1}^{x/k} \alpha(j)[j=r/k]\\=\sum_{r=1}^x F(x/r)\sum_{d|r}\alpha(d)\alpha^{-1}(r/d)=\sum_{k=1}^x F(x/k)\epsilon(k)=F(x)$$ which proves the Wikipedia identity. (A similar proof is in fact given on the Wikipedia page.) Proceeding analogously, we define $$G(x)=\sum_{k=1}^x F(k) \alpha(x/k)$$ and consider the sum $$\sum_{k=1}^x G(k) \alpha^{-1}(x/k)=\sum_{k=1}^x \alpha^{-1}(x/k)\sum_{j=1}^k F(j)\alpha(k/j)$$ by the definition of $G(x)$ and rewrite as above $$=\sum_{k=1}^x \alpha^{-1}(x/k)\sum_{j=1}^k\sum_{r=1}^x F(j)\alpha(r)[r=k/j]=\sum_{r=1}^x \alpha(r)\sum_{k=1}^x \alpha^{-1}(x/k) \sum_{j=1}^k F(j)[j=k/r]=\sum_{k=1}^x \alpha^{-1}(x/k)\sum_{r=1}^x \alpha(r) \sum_{j=1}^k F(j)[j=k/r]=\sum_{k=1}^x\alpha^{-1}(x/k)\sum_{d|k}F(k/d)\alpha(d)$$ which by our definition of $*'$ can be written $$(F*'\alpha)*'\alpha^{-1}=(F*\alpha)*'\alpha^{-1}$$ which seems to imply $$F*'\alpha=F*\alpha$$ which is clearly false. What am I doing wrong?","['number-theory', 'proof-verification', 'dirichlet-convolution', 'analytic-number-theory']"
1230211,Lagrange's multiplier not working,"Given the function $f(x,y):=xy+x-y$. Let $D:=\{(x,y)\in\mathbb{R}^2:x^2+y^2\leq25\wedge x \geq 0\}$. Find the absolute maximum and minimum of $f$ on $D$. My working is as follows: $\begin{array}
& f_x(x,y)=y+1=0 & \qquad \qquad f_y(x,y)=x-1=0 \\
\Rightarrow y=-1 & \qquad \qquad \Rightarrow x=1
\end{array}$ $D(x,y)=\begin{vmatrix}
f_{xx}(x,y) & f_{xy}(x,y) \\
f_{xy}(x,y) & f_{yy}(x,y) 
\end{vmatrix} = \begin{vmatrix}
0 & 1 \\
1 & 0 
\end{vmatrix} = -1$ $D(x,y) = D(1,-1) < 0 \Rightarrow (1,-1)$ is a saddle point. Also, just for interest, $f(1,-1)=1$ To find the maximum and minimum of $f$ subject to $x^2+y^2=25$ I will use a Lagrange multiplier. $\nabla f(x,y) = \lambda \nabla g(x,y)$ where $g(x,y)=x^2+y^2-25$ $\langle y+1, x-1 \rangle = \lambda \langle 2x, 2y \rangle$ $\left\{\begin{array}{llll}
y+1=2\lambda x & \Rightarrow & y=2\lambda x -1 & (1) \\
x-1=2\lambda y & \Rightarrow & x=2\lambda y +1 & (2) \\
x^2+y^2=25 & & & (3)
\end{array}\right.$ Putting (1) into (2) and (2) into (1) gives $$x=\frac{1}{1+2\lambda} \qquad \text{and} \qquad y=-\frac{1}{1+2\lambda}\tag{4}$$ Where $\lambda \neq \pm \frac12$ Putting (4) into (3) gives $$\lambda = \frac{-5\pm \sqrt2}{10} \approx -0.64 \quad \text{or} \quad -0.36$$ Subsequently, $$x \approx \pm 3.54 \quad \text{and} \quad y \approx \mp 3.54$$ Note that $x=-y$. So, $$f(3.54,-3.54) \approx -5.43 \quad \text{and} \quad f(-3.54,3.54) \approx -19.57$$ By this calculation, (-3.54, 3.54, -19.57) would be a point of absolute minimum on the circle $x^2+y^2=25$. But $x\geq 0$. Hmm. Let me try evaluating $f(0,5)$. $$f(0,5)=-5 \nless f(3.54,-3.54) \approx -5.43$$ Nope. What should I do now to find the minimum in a procedurally correct way? I also cannot find the absolute maximum. $(1,-1,1)$ is not the absolute maximum because I have found that $(3.54, 3.54, 12.5)$ exists on $D$. Why did my calculation using Lagrange's multiplier not give me this point?","['optimization', 'lagrange-multiplier', 'multivariable-calculus']"
1230269,"If $g$ is continuous and $g(1)=0$, then $x^ng(x)$ converges on $[0,1)$","Suppose $g:[0,1]\to\mathbb R$ is a continuous function satisfying $g(1)=0$. Prove that the functions $f_n(x)=x^ng(x)$ converge uniformly on $[0,1]$. Hence or using Mean Value Theorem, prove that if $\int_0^1x^ng(x)dx=0$ for every $n\in\mathbb N$ then $g$ is identically $0$. First of all, I don't think the convergence is uniform. The pointwise limit is $0$. Now consider $\sup_{x\in[0,1)}x^n|g(x)|=c_n^n|g(c_n)|$ for some $c_n$ which depends on $n$. The supremum is attained as the function $x^n|g(x)|$ is continuous. Now, as I vary $n$, $c_n$ varies and thus, we cannot conclude anything I think. Secondly, I don't understand how the first part can imply the second part of the question. I obtained the second part using Bernstein Polynomials (Weierstrauss Approximation Theorem) using the fact that these polynomials are uniformly convergent to $g$. I tried using Mean Value Theorem but could not proceed further. But this lands in a new question: Suppose $f$ is a continuous non-zero function on a closed bounded interval $[a,b]$. Then is it true that $f$ cannot have infinitely many roots in $[a,b]$? If I know the answer to this question, I can answer the second part of the original question. The reasoning being that for every $n$, using Mean Value Theorem, there exists $c_n\in[0,1]$ such that $f(c_n)\int_0^1x^ndx=0$ giving $f(c_n)=0$ for all $n$. I want to show this is a contradiction if $f$ is non-zero.","['limits', 'continuity', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
1230358,Arveson spectrum for a unitary representation of a group on a Hilbert space,"Let $G = \mathbb{R}$. By Stone's theorem, $U(t)\in\mathcal{B}(\mathcal{H})$ is generated by a self-adjoint operator $H$ (for which there is a resolution of the identity P(p), by the spectral theorem)
 $$ U(t) = e^{i t H} = \int_{\mathbb{R}} e^{i pt} d P(p)$$
One can thus define a spectral subspace, e.g. of eigenvectors of $H$ with eigenvalues in $[p_1,p_2]$, given by $(P(p_2)-P(p_1))\mathcal{H}$. Let's denote it $\mathcal{H}^U([p_1,p_2])$. More generally, for a uniformly bounded action $\alpha$ of a locally compact group $G$ on a Banach space $X$, one can define the $\alpha$-spectrum $\mathrm{Sp}_{\alpha}(a)$ of $ x\in X$ as the set of maximal ideals of $L^1(G)$ containing $\mathcal{I}(a):=\{f\in L^1(G),\ \alpha_f(a) := \int_{G} f(x)\alpha_x(b) \operatorname{d}\! x \stackrel{!}{=}0\}$ By [8.2 p.218][1], maximal ideals are the kernels of the ""characters"" of $L^1(G)$ which are themselves in bijection with characters of the group via Fourier transform:
 $$  \forall\ \Phi: L^1(G) \rightarrow \mathbb{C}\ \text{ algebra morphism},\ \exists !\ \gamma\in\hat{G} \ \text{ s.t. }\
  \Phi(f)= \int_G \overline{\gamma(x)} f(x)\operatorname{d}\!\mu (x)=: \hat{f}(\gamma)
 $$
The $\alpha$-spectrum can thus also be defined as a subset of the dual group $\hat{G}$
 $$
  \mathrm{Sp}_{\alpha}(a) := \{\gamma\in \hat{G},\ \hat{f}(\gamma) = 0,\ \forall\ f\in \mathcal{I}(a)\} $$ Now for a given subset $S\subset \hat{G}$ one can associate the following spectral subspaces 
 $$  X^{\alpha}(S) := \overline{\{a\in X,\ \mathrm{Sp}_{\alpha}(a)\subseteq S\}} $$ $$  X^{\alpha}_0(S) := \overline{\mathrm{Span}\{\alpha_f(a),\ \forall\ a\in X,\ f\in L^1(G),\ \mathrm{supp}(\hat{f})\subseteq S\}}   
 $$
(Relation between them: [Lemma 3.2.39 p.253][2]) [Bratteli, Robinson][2] say p.251 that it is ""easy to derive""/ p.258 that it is ""easily verified"" that
$$ \mathcal{H}([p_1,p_2]) = \mathcal{H}^U ([p_1,p_2])$$
where l.h.s. is given by the projections of the spectral theorem for the generator $H$ and r.h.s. is the abstract definition with $X:=\mathcal{H}$ and $\alpha:= U$ Question: how do we see this? I have also seen, for $G= \mathbb{R}$ the following definition
  $$
 \mathrm{Sp}_{\alpha}(a):=\{p\in\mathbb{R},\ \forall\ U\ni p\ \text{neighborhood},\ \exists\ f\in L^1(\mathbb{R}),\ \mathrm{supp}(\hat{f})\subset U \ , \enspace \alpha_f(a)\neq 0 \}
 $$
Which I find more accessible, and I guess it does agree with the one above by [3.2.40 (2) p.254][2] [1]: ""A course in functional analysis"", Conway, (actually works even if $L^1(G)$ is not unital) ; or Thm. 34B p.136-137 for some algebra of measure containing $L^1(G)$,  ""Introduction to abstract harmonic analysis"", Loomis [2]: ""Operator algebras and Quantum statistical mechanics vol. 1"", Bratelli, Robinson","['operator-algebras', 'functional-analysis', 'c-star-algebras', 'harmonic-analysis', 'von-neumann-algebras']"
1230369,Show that $\sum r^n \cos(nx)=r\cos(x)-r^2/(1-2r\cos(x)+r^2)$,"I'm a little unsure about how to approach this.  I've been told that we have to use the relationship that $\sum r^n=1/1-r$. However, I'm not too sure what to do with the $\cos(nx)$.  Can someone give me some help?","['taylor-expansion', 'complex-analysis']"
1230374,How to find the area of the following triangle,"I am stuck on the following problem: Let ABC be an isosceles triangle having two equal sides of length $20$ cm. and the angle between the 
  two equal sides is $45^{\circ}$. Then I have to find the area of $\triangle ABC$ . But I can not use any trigonometric formulae using $\sin$, $\cos$ etc. It is a ninth grade problem . Can someone please help? Thanks in advance for your time. ADDENDUM : Though my problem has been solved , but I have got a similar problem which is identical with the one posted above apart from the fact that the angle between the two equal sides( each of length $20$ cm.) is given by $30^{\circ}$. In that case how can I solve the problem ?",['geometry']
1230449,Power set functors preserve monicness,"This link discusses power set functors. Proposition 5.7 If $f$ is a epimorphism then so is $\exists_f$. Proposition 5.8 If $f$ is an monomorphism then so is $\forall_f$. A little confused...doesn't proposition 5.8 apply to $\exists_f$ also? Certainly if $f$ is injective then $f^* \circ \exists_f = \text{Id}$, so $\exists_f$ must be injective. Am I missing that they're talking about a richer category than just $\mathsf{Set}$? Maybe because of additional structure monic means more than just being injective here?","['elementary-set-theory', 'category-theory']"
1230459,Integration of Fundamental Solution of Laplace's equation.,"I am currently reading Evan's PDE and am getting hung up on many of the more ""technical details"". This question may be very basic (multivariable calculus). I am given that the fundamental solution of Laplace's equation is $$ \Phi(x) := \begin{cases} -\frac{1}{2 \pi}  \log |x|  & (n=2) \\ 
\frac{1}{n(n-2) \alpha(n)} \frac{1}{|x|^{n-2}} & (n \ge 3) \end{cases}$$ How would I evaluate $$ \int_{B(0, \epsilon)} |\Phi(y) | dy ? $$","['calculus', 'partial-differential-equations']"
1230482,A little doubt about set notation.,"Is $ A \setminus B = A \setminus (A \cap {B})$. I am learning sets and it is given that A minus B is {x $\in$ A such that x $\notin$ B}. Is it the same as A minus A intersection B. One word answer will do if ""yes""; explain if ""no"".",['elementary-set-theory']
1230488,Explicit bijection between $\mathbb Q$ and $\mathbb Z \times \mathbb Z$?,"Any idea of an explicit bijection between $\mathbb Q$ and $\mathbb Z \times \mathbb Z$? Even if I think of rational elements as $\frac {m}{n}$, sending them to $(m,n)$ won't work, because all pairs $(m,0)$ don't have a source... Any hints would be much appreciated!",['elementary-set-theory']
1230517,Constant torsion-expression of unit speed curves,I am currently studying for an exam in differential geometry. There's a problem which I am not able to solve and do not even know where to start (although I think it has to do with the Frenet equations) :Let $\alpha(s)$ be a curve parametrised by arc length of non zero constant torsion $\frac{1}{a}$. Show that there exists a (vector valued) function $f$ satisfying : $\alpha(s) = a \int (f(s) \times f'(s)) ds$ $\vert f(s) \vert =1$ and $(f(s) \times f'(s)) \cdot f''(s) \not =0$ Any help/hints?,['differential-geometry']
1230522,Finding the CDF of a piecewise PDF,"So for my statistics class I am taking this semester we've been working on continuous random variables and we have one question that the teacher did not cover at all nor his notes, and it has to deal with piecewise functions. I'm given the piecewise PDF f(x) = x + 1 for -1 < x < 0 and -x + 1 for 0 < x < 1. I do know that to get from a PDF to a CDF you need to integrate the function which I did for both of these giving me x^2/2 + x and -x^2/2 + x. This question given in the book has the answer given in the back of the book and it has a + 1/2 on the end of both CDF functions. My question is so I understand what is going here, where does that 1/2 come from in this question because the teacher never went over problems involving piecewise functions just single functions, and also the book doesn't ever mention piecewise functions either.","['statistics', 'integration']"
1230581,"If a function maps $A$ to its PowerSet, is it Surjective?","Given an arbitrary set $A$ , let $F : A \rightarrow 2^A$ be the function defined for
all $a \in A$ by $f(a) = \{a\}$ If $A$ maps to its power set, does this make $F$ surjective? If somebody could help to prove this that would be very helpful","['elementary-set-theory', 'discrete-mathematics', 'functions']"
1230614,Proof of Fermat's last theorem for $n=5$ using primitive roots of unity?,"I've been reading ""An introduction to the theory of numbers"" by Hardy and Wright and they gave a nice proof of Fermat's last theorem for $n=3$ by proving that there are no solutions to $$x^3+y^3+z^3=0$$ where $x$,$y$, and $z$ are numbers of the form $a+bp$ where $a$ and $b$ are integers and $$p=e^{2/3\pi i}=\frac 12\Big(-1+\sqrt{3}i\Big)$$ which is a primitive third root of unity. The general approach of the proof is to factor $x^3+y^3$ into $$(x+y)(x+py)(x+p^2y)$$ They also then state that the proof of FLT for n=5 is very similar but uses $p=e^{2/5\pi i}$ which is a primitive fifth root of unity. My question is, does anyone know where I can find this proof? I'm looking for a proof of FLT for $n=5$ that uses properties of integers of the form $a+bp$, and specifically the fact that $x^5+y^5$ factors into $$(x+y)(x+py)(x+p^2y)(x+p^3y)(x+p^4y)$$ I don't expect anyone to type up the full proof but a link or reference would be nice.","['number-theory', 'reference-request']"
1230627,Confusion about Lusin's Theorem.,"I saw a proof which heavily relied on Lusin's Theorem recently, and I was hoping someone might be able to help me fill in the detail as to why this theorem allows for a particular creation. (Lusin's Theorem) If $f : [a, b] \rightarrow \mathbb{C}$ is Lebesgue measurable and $\epsilon > 0$, there is a compact set $E \subset [a,b]$ such that $\mu(E^c) < \epsilon$ and $ f $ is continuous on $E$. The line in the proof I read was as follows, ""Suppose $f \in L^\infty$ is given, we can apply Lusin's theorem infinitely many times to construct a sequence $(f_n)$ in $C[0,1]$ uniformly bounded by $\|f\|_\infty$ such that the measure of the set where $f$ and $f_n$ are unequal less than $\frac{1}{n}$."" The requirement for this theorem is the existence of a compact set for continuity, but the set may only be a single point. Let's just say we had the measurable function
\begin{equation}
f(x) = \begin{cases} 1 &\mbox{if } x\in \mathbb{Q} \\ 
0 & \mbox{if } x \not \in Q. \end{cases}
\end{equation} What would this creation $(f_n)$ look like, and how does it follow that this sequence will be continuous on $[0,1]$.","['continuity', 'real-analysis', 'functional-analysis', 'measure-theory']"
1230637,"Demand $z=x+y$ and $x^2/4 + y^2/5 + z^2/25 = 1$. What is the maximum value of $f(x,y,z) = x^2+y^2+z^2$?","Demand $z=x+y$ and $x^2/4 + y^2/5 + z^2/25 = 1$. What is the maximum value of $f(x,y,z) = x^2+y^2+z^2$? I've been attempting this with Lagrange multipliers in a few different ways. However, the resulting system of equations with two lagrangians has so many variables that it becomes very complicated. Can someone show how this is to be done manually? I also attempted turning it into two unknowns by replacing $z$ with $x+y$. However, this also led nowhere.","['maxima-minima', 'multivariable-calculus', 'optimization', 'lagrange-multiplier', 'qcqp']"
1230666,Moment generating function of Random Sums,"I am unsure of a particular step in the supplied solution of this problem. Problem: We are given $X_{i}$, for i = 1,..., n, is a sequence of iid Geometric Random Variables. N ~ Geometric(p), and N is independent of all the $X_{i}$'s $S_{N} = \sum^{N}_{i=1}Xi$. What is the MGF of $S_{N}$? My working: Let $Y = S_{N}$ Know that $M_{X}(t) = \frac{pe^{t}}{1-qe^{t}}$ (from an earlier part of this problem).
So the conditional MGF of the random sum is $M_{Y|N}(t|N) = [M_{X}(t)]^{N} = [\frac{pe^{t}}{1-qe^{t}}]^{N}$ Next, MGF of Y, $M_{Y}(t) = E[M_{Y|N}(t|N)] = E[(\frac{pe^{t}}{1-qe^{t}})^{N}]$ I am able to show up till this part, so everything above is fine. The next step is to perform this: $E[(\frac{pe^{t}}{1-qe^{t}})^{N}] = \frac{p.\frac{pe^{t}}{1-qe^{t}}}{1-q.\frac{pe^{t}}{1-qe^{t}}} $ I don't understand  why the expression for the denominator takes that form if we are bringing it up by power of N. Can someone kindly explain the reasoning for it please?","['statistics', 'random-variables', 'moment-generating-functions']"
1230667,Nonlinear second-order ODE $yy'' - (y')^{2} = y^4$,"I have the following ODE to solve.
$$
yy'' - (y')^{2} = y^4
$$
I tried to substitute $y'$ by $v$, and then I get the following: $$
yv' - v^{2} = y^4.
$$ I can't go further. I can't see what I'm supposed to do in order to solve it. I saw a solution involving Bessel function. But, is it possible to transform the first ODE into an exact, linear, or Bernoulli equation? Any hint, please. Thanks.",['ordinary-differential-equations']
1230673,Laplace transforms for a pharmacokinetics multi-compartmental model,"I am an anaesthetist trying to write some pharmacokinetics software as a pet project. Unfortunately the maths I need is a bit too much for my rusty high school calculus, and I am out of my depth. I am working with the following system of equations: $\frac{dC_{1}}{dt}=k_{21}C_{2}(t)-k_{12}C_{1}(t)+k_{31}C_{3}(t)-k_{13}C_{1}(t)-k_{10}C_{1}(t)+C_{inf}$ $\frac{dC_{2}}{dt}=k_{12}C_{1}(t)-k_{21}C_{2}(t)$ $\frac{dC_{3}}{dt}=k_{13}C_{1}(t)-k_{31}C_{3}(t)$ $\frac{dC_{e}}{dt}=k_{e0}C_{1}(t)-k_{e0}C_{e}(t)$ These equations model the distribution of a drug in the human body according to a multi-compartmental model where: $C_{1}$: concentration in compartment 1 (bloodstream). $C_{2}$: concentration in compartment 2 (richly perfused, mostly muscle). $C_{3}$: concentration in compartment 3 (poorly perfused, mostly fat). $C_{e}$: concentration at effector site (brain). $C_{inf}$: concentration of infusion (for a drug given intravenously at a constant rate, the rate divided by the volume of distribution of compartment 1). $k_{10}$: constant of elimination from compartment 1. $k_{12}$, $k_{13}$, etc.: constants of equilibration between compartments. $k_{e0}$: constant of equilibration to effector site (it is assumed to be the same in both directions). t: time. All the above are known except for $C_{1}$, $C_{2}$, $C_{3}$ and $C_{e}$. We also know what the 4 concentrations are at t = 0. I have done Laplace transforms of these equations (with the aid of the computer program Maxima) and solved the system for the Laplace transforms. I have not been able to calculate the inverse of the transforms, so I have used Zakian's method to obtain a numerical approximation to the inverse of the Laplace transforms. This approach works reasonably well and provides quite accurate results, but it is computationally intensive, and therefore too slow to draw graphics on the fly. Also it bugs me to use a numerical approximation when there may be an exact solution. This link seems to indicate that for a simpler two compartment model it is possible to find an exact solution by doing Laplace transforms, solving the system of equations, and then inverting the transforms. Is my system of equations solvable? If so, I would be very grateful for some pointers.","['laplace-transform', 'ordinary-differential-equations', 'integration']"
1230709,Minimum distance between two rectangles with known size and orientation,"I have faced a problem, that I need to calculate a shortest distance between two rectangles, which are on a different angles. Known parameters : length, width, angle and coordinate of center point of each
rectangular.","['optimization', 'geometry', 'rectangles']"
1230742,Working out the area of Australia through Calculus? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question I was wondering if it would be possible, and if so how, to calculate the area of an abstract shape on a sphere using surface integrals and Parametric surfaces and such. I am looking in to this as part of my assignment and I am not sure how to approach this problem.","['surface-integrals', 'parametric', 'calculus', 'multivariable-calculus']"
1230747,Using the residue theorem to evaluate $\sum_\limits{n=-\infty}^{\infty} \frac{e^{in \alpha}}{(n-\beta)^{2}+\gamma^{2}}$,"I would like to know how to sum up to following series (from the Gradshteyn-Ryzhik tables): $$\sum_{n=-\infty}^\infty\frac{e^{in\alpha}}{(n-\beta)^2+\gamma^2}=\frac{\pi}{\gamma}\frac{e^{i\beta(\alpha-2\pi)}\sinh(\gamma\alpha)+e^{i\beta\alpha}\sinh[\gamma(2\pi-\alpha)]}{\cosh(2\pi\gamma)-\cos(2\pi\beta)}$$ with $0\leq\alpha\leq2\pi$. In the special case of $\alpha=0$, we have $$\sum_{n=-\infty}^\infty\frac1{(n-\beta)^2+\gamma^2}=\frac{\pi}{\gamma}\frac{\sinh[ 2\pi\gamma]}{\cosh(2\pi\gamma)-\cos(2\pi\beta)}$$ and I now that I can use the function $$ \frac{\cot(\pi z)}{(z-\beta)^2+\gamma^2}$$ to sum up this series via the residue theorem. 
In more detail, the singularities are $\beta\pm {\rm i}\gamma$ and $z_n=n$, $n\in\mathbb{N}$.
If I sum the corresponding residues, I get what the above result (for $\alpha=0$). I am not sure, however: 1) How to choose the contour in order to have a correct argumentation? 2) What to do with the general case $\alpha\neq 0$?","['sequences-and-series', 'complex-analysis', 'residue-calculus', 'contour-integration']"
1230784,What are some good books on vector analysis in higher dimenesion,What is some good books specifically on vector analysis in higher dimension? Standard vector calculus book usually only introduced double and triple integral method,"['vector-analysis', 'real-analysis', 'reference-request', 'book-recommendation', 'multivariable-calculus']"
1230787,Can a series of polynomials converge non-uniformly?,"Is there an example of a series of polynomials, say, the degree equals the index and converges non-uniformly? In other words, does point-wise convergence of a polynomial series imply uniform convergence?","['sequences-and-series', 'uniform-convergence']"
1230800,Ricci curvature of the Grassmannian?,"Let $G(k, \mathbb{C}^n)$ be the Grassmannian of $k-$dimensional complex linear subspaces of $\mathbb{C}^n.$  We know that the Grassmannian can be embedded to the projective space $(\mathbb{P}^N,\omega_{FS})$ for some $N,$ via the Plucker embedding. What can we say about the Ricci curvature of the Grassmannian? or even the scalar curvature? (any bounds?)","['complex-geometry', 'riemannian-geometry', 'algebraic-geometry', 'grassmannian', 'differential-geometry']"
1230801,Where surjectivity goes in?,"Let $X$ be an infinite set with the cofinite topology, and $f: X \to X$ a surjective function. Prove that $f$ is continuous if and only if $f^{-1}(\{x\})$ is finite for all $x\in X$. I know that $f$ being onto is essential, otherwise $f$ constant is continuous, but the inverse image of the constant is the whole infinite space. $\implies :$ Suppose that $f$ is continuous. Given $x\in X$, $X\setminus \{x\}$ is open because $\{x\}$ is finite. By continuity, $f^{-1}(X\setminus \{x\}) = X\setminus f^{-1}(\{x\})$ is open, hence the complement $f^{-1}(\{x\})$ is finite. $\impliedby :$ Suppose that $f^{-1}(\{x\})$ is finite for all $x\in X$. Let $\Omega$ be open. If $\Omega = \varnothing$ there is nothing to do. Otherwise $X\setminus \Omega$ is finite: $$X\setminus \Omega = \bigcup_{i=1}^n \{x_i\} \implies X\setminus f^{-1}(\Omega) = f^{-1}(X\setminus \Omega) = \bigcup_{i=1}^n f^{-1}(\{x_i\})$$ is a finite union of finite sets, hence finite. So $f^{-1}(\Omega)$ is open and $f$ is continuous. Question: Where did I use that $f$ is onto? If I didn't, where is the flaw in the proof?","['continuity', 'general-topology']"
1230828,Characterization of the $x$ such that $\sin(x)$ is rational?,"For $x \in [0,\pi/2]$, $\sin(x)$ ranges over $[0,1]$. 
So every rational number in $[0,1]$ is the sine of some $x \in [0,\pi/2]$. Q . Is there any characterization of the $x$ for which $\sin(x)$ is rational? I am not quite sure what shape such a characterization might take.
Something like: If $x$ satisfies such-and-such conditions, then $\sin(x)$ is rational. Perhaps there is at least a partial characterization?","['rational-numbers', 'trigonometry']"
1230856,"Let $G$ be a finite simple group. Suppose that $A, B < G$, $G = AB$ and $A$ is an Abelian group. Is it true that $A \cap B=1 $?","Let $G$ be a finite simple group. Suppose that $A$ and $B$ are proper subgroups of $G$, $ G = AB$ and $A$ is an Abelian group. Is it true that $A \cap B=1 $ ? I checked it with some examples and it seems to be true; but I have no proof for it.","['abstract-algebra', 'group-theory', 'finite-groups']"
1230906,What's the theoretical basis for integration using partial fractions?,"Exercises involving integration using partial fractions depend on expressing a rational function $\frac{P(x)}{Q(x)}$ (where the degree of $P$ is less than the degree of $Q$) as a sum of $$\frac{A}{(x+a)^k}$$ and $$ \frac{Bx+C}{(x^2+bx+c)^m}$$ I didn't see a reasonable explanation for why this is possible (especially for why it's necessary to put a linear polynomial $Bx+c$ in the numerator when there are ""repeated"" quadratical terms in the denominator). OBS.: I'm just a calculus student, so the theory which explains this might not be accessible to me. I asked this however because maybe someone could show me a way to look to it.","['ring-theory', 'field-theory', 'calculus', 'commutative-algebra', 'integration']"
1230908,How to calculate a reduced volume?,"Let's say we have an irregular 3D shape with volume=V ( we know V but we don't know its equation= F).  Now I want to calculate another 3D shape which is exactly the same shape but one size smaller, such that at any point of space, the smaller one has a vertical distance=a from the outer one.","['volume', 'algebraic-geometry', 'geometry', 'analytic-geometry']"
1230921,Remainder Taylor series two+ variables,"Hard to find an article /  tutorial specifically about this subject online....
Can anyone explain / send link to explanation or tutorial regarding how to calculate remainder for multi-variable taylor series? Thanks much!","['taylor-expansion', 'error-function', 'multivariable-calculus']"
1230925,"If |f| is constant, f is constant.",I am confused as to how they got from the two equations being equal to 0 to the derivative being 0. I could be really tired right now but this isn't really making sense to me. I was thinking of doing cases where u isn't 0 and v isn't 0 separately and they assume both aren't 0 and then just solve it out. I feel like I could brute force this but is there a shorter way of doing this without these cases.,['complex-analysis']
1230928,Classification of line bundles by Griffiths and Harris,"I am reading pages $132$ and $133$ of Principles of Algebraic Geometry by Griffiths and Harris. They consider a holomorphic line bundle $L \to M$ over a manifold $M$ and an open cover $\left\{ U_{a}\right\}$ associated to the holomorphic trivializations of $L$: $\phi_{a} : L|_{U_{a}}\to U_{a}\times \mathbb{C}$. Then they explain how the corresponding transition functions $g_{ab} = \phi_{a}\circ\phi^{-1}_{b}$ represent a Čech cocycle in $M$ and that two sets of transition functions are equivalent if they differ by a Čech coboundary. Thus, the set of holomorphic line bundles on $M$ is classified by $H^{1}(M,\mathcal{O}^{\ast})$. What I don't understand is: at what point the classification of the line bundles stopped depending on the open cover $\left\{ U_{a}\right\}$? As I understand it, what they have shown is that the set of line bundles with trivializations given in terms of the open cover $\left\{ U_{a}\right\}$ is classified by $H^{1}(\left\{ U_{a}\right\},\mathcal{O}^{\ast})$. Only if $\left\{ U_{a}\right\}$ is the finest open cover then I get the classification as elements of $H^{1}(M,\mathcal{O}^{\ast})$. What am I missing? Edit: How the discussion of Griffiths and Harris can be extended to complex line bundles not necessarily holomorphic? Thanks.","['complex-geometry', 'algebraic-geometry', 'differential-geometry']"
1230999,Definite integral of an odd function is 0 (symmetric interval),"For an odd function, I know that f(x) = - f(x). I'm trying to show that $\int^{a}_{-a} f(x) dx$ = 0. I've seen the proof where it splits the integral up into: $$\int^{a}_{0} f(x) dx + \int^{0}_{-a} f(x) dx $$ However, I still don't understand how to evaluate the second part, which is the 'gold' of the proof. For example in https://proofwiki.org/wiki/Definite_Integral_of_Odd_Function , why do we define a function from $x \mapsto -x$? (hence leading onto du = - dx and so on). I've been to different sites/videos and they all show me 'how', but not 'why' certain steps are carried out. Additionally, why can't I evaluate the original integral right away? $$\int^{a}_{-a} f(x) dx = [F(x)]^{a}_{-a} = F(a) - F(-a) = F(a) - F(a) = 0 $$? Is it because we're limited by the need to prove that the integral of that (odd) function is even?","['functions', 'integration']"
1231034,Isn't this a non-surjective epimorphism on the category of sets?,"I am trying to prove that a morphism in the category of sets is epic iff it is a surjective function. Recall that for objects $A,B,C$, $f \in \hom(A,B)$ is epic when $g_1 \circ f = g_2 \circ f \Rightarrow g_1 = g_2, \forall g_1, g_2 \in \hom(B,C)$. Consider $A= \{0\}, B= \{1,2\}, C=\{3\}$. Since there is only one element in $\hom(B,C)$, $g_1 \circ f = g_2 \circ f \Rightarrow g_1 = g_2, \forall g_1, g_2 \in \hom(B,C)$ is trivially satisfied $\forall f \in \hom(A,B)$ In particular, $f : A \rightarrow B $ $f(0) \mapsto 1$ is an epimorphism, but $f$ is non-surjective. Am I missing something about how categories are defined? Or is it simply false that the original implication is two-sided?","['category-theory', 'functions']"
1231055,How to solve $\int_0^{\frac{\pi}{2}}\frac{x^2\cdot\log\sin x}{\sin^2 x}dx$ using a very cute way? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Few days ago my friend gave me this integral and i cant get how to solve this. The integral is:$$\int_0^{\large \frac{\pi}{2}}\frac{x^2\cdot\log{{\sin{x}}}}{\sin^2{x}}dx$$","['closed-form', 'calculus', 'definite-integrals', 'integration']"
1231075,Show that $2^{105} + 3^{105}$ is divisible by $7$,"I know that $$\frac{(ak \pm 1)^n}{a}$$ gives remainder $a - 1$ is n is odd or $1$ is n is even. So, I wrote $ 2^{105} + 3^{105}$ as $8^{35} + 27^{35}$ and then as $(7\cdot 1+1)^{35} + (7\cdot 4-1)^{35}$ , which on division should give remainder of $6$ for each term and total remainder of 5 (12/7). But, as per question, it should be divisible by 7, so remainder should be zero not 5. Where did I go wrong? [note: i don't know binomial theorem or number theory.]","['arithmetic', 'linear-algebra']"
1231078,The Poincaré dual of a space-time curve,"We have a smooth space-time curve defined by $f:C{\mapsto}M$, where $M$ is a typical curved space-time manifold. ${\eta}^{(4)}$ is the volume 4-form defined on $M$ and ${\varepsilon}^{(1)}$ is the (non-degenerate) volume 1-form induced on $C$. As usual, both forms are defined by the space-time metric. Making  reasonable assumptions about the curve, how does one find its Poincaré dual, denoted by the closed 3-form ${\beta}$.","['differential-geometry', 'algebraic-topology', 'mathematical-physics']"
1231095,Inverse Laplace Transform of $\ln[\frac{s^2+a^2}{s^2+b^2}]$,"How does one find $\mathcal{L}^{-1}\{\ln[\frac{s^2+a^2}{s^2+b^2}]\}$? I've tried splitting it up into $\mathcal{L}^{-1}\{\ln(s^2+a^2)\}-\mathcal{L}^{-1}\{\ln(s^2+b^2)\}$. However, I can't think of any way to actually take the inverse transform of $\mathcal{L}^{-1}\{\ln(s^2+a^2)\}$.","['laplace-transform', 'ordinary-differential-equations']"
1231158,Compute $\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^{2}} dy]^2}{\int^x_0 e^{2y^{2}}dy}$,"I've tried to apply L'hopitals rule on this one, as this get's $\frac{\infty}{\infty}$ $$\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^2}\mathrm{d}y]^2}{\int^x_0 e^{2y^2}\mathrm{d}y}$$ $\frac{\mathrm{d} }{\mathrm{d} x}[\int^x_0 e^{y^2}\mathrm{d}y]^2 = 2[\int^x_0 e^{y^2}\mathrm{d}y] * [\frac{\mathrm{d} }{\mathrm{d} x}\int^x_0 e^{y^2}\mathrm{d}y]=2(e^{x^2}-1)(e^{x^2})$ and $\frac{\mathrm{d} }{\mathrm{d} x}[\int^x_0 e^{2y^2}\mathrm{d}y]=e^{2x^2}$ so $\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^2}\mathrm{d}y]^2}{\int^x_0 e^{2y^2}\mathrm{d}y} = \lim_{x \rightarrow +\infty} \frac{2(e^{x^2}-1)(e^{x^2})}{e^{2x^2}} = 2\lim_{x \rightarrow +\infty} \frac{(e^{x^2}-1)}{e^{x^2}}=2\lim_{x \rightarrow +\infty} (1-\frac{1}{e^{x^2}})=2$ But the answer is $0$, so I think I've done a mistake somewhere I can't figure out where.","['limits', 'definite-integrals', 'derivatives']"
