question_id,title,body,tags
1553919,Gumbel distribution convergence,"$X_1,X_2,\ldots$ IID, so that $X_i\sim E(\lambda)$. Therefore $\mathbf{P}(X_i>t)=\exp(-\lambda t)$ if $t\geqslant 0$. We denote $M_n=\max\{X_1,\ldots ,X_n\}$ and I want to prove that
$$M_n-\frac{\ln n}\lambda \overset{D}\to Y,$$
where $Y\sim G_\lambda$, $G_\lambda (t)=\exp(-e^{-\lambda t}), \ t\in \mathbb{R}, \ \lambda >0$. I don't know how to deal with $M_n$. Advice would be appreciated.","['statistics', 'probability']"
1553933,Why can I add the same number on both sides of an equation? [duplicate],"This question already has answers here : Is there a law that you can add or multiply to both sides of an equation? [duplicate] (9 answers) Closed 8 months ago . I know it is an elementary algebra question. But, is there a good reason for it being valid. Let's say we have $x+5=7$. We obviously know $x=2$, but if I can add any number on both sides and it still is valid. Ex: $x+5+3=7+3$. Simplifying to $x+8=10$. This is also valid and $x$ still equals $2$",['algebra-precalculus']
1553948,Prove that $\lim_{x \to \infty}\big(\frac{x}{x-1}\big)^x$ is also $e$.,"Trying to make sense out of the idea that $100\%$ continuous decay is $\frac{1}{e}$, I thought about this: You can express $1+\frac{1}{x}$ as $\frac{x+1}{x}$, such that $\big(1+\frac{1}{x}\big)^x = \big(\frac{x+1}{x}\big)^x$ And you can express $1-\frac{1}{x}$ as $\frac{x-1}{x}$, such that $\big(1-\frac{1}{x}\big)^x = \big(\frac{x-1}{x}\big)^x =\frac{1}{\big(\frac{x}{x-1}\big)^x}$ Now $\big(\frac{x}{x-1}\big)^x$ and $\big(\frac{x+1}{x}\big)^x$ look very similar, and I can imagine (and see on Mathematica) that $\lim_{x \to \infty} \big(\frac{x}{x-1}\big)^x$ also approaches $e$. However I'm clueless about limit proofs, how do you prove that? EDIT : Just had a last second insight.  Can you say that $$\lim_{x \to \infty} \big(\frac{x}{x-1}\big)^x = \lim_{x \to \infty} \big(\frac{x}{x-1}\big)^{x-1} \cdot \lim_{x \to \infty} \big(\frac{x}{x-1}\big)$$ $$= \lim_{x \to \infty} \big(\frac{x}{x-1}\big)^{x-1} \cdot 1$$ $$=\lim_{x \to \infty} \big(\frac{x+1}{x}\big)^x = e ?$$ (not sure about that last limit transition...I mean I'm pretty sure it's true, just not sure how to write it; I would appreciate feedback on that , thank you)","['proof-writing', 'exponential-function', 'proof-verification', 'limits']"
1553966,Converging to $\infty$?,"For example, does the following summation ""converge"" to $\infty$? $$\sum_{n=1}^{\infty}\frac 1 n$$ If so, give me some other examples and explain what it means to converge to infinity. Also, is there anything special about a series converging to infinity?",['sequences-and-series']
1553990,"Easy way of memorizing values of sine, cosine, and tangent","My math professor recently told us that she wanted us to be able to answer $\sin\left(\frac{\pi }{2}\right)$ in our head on the snap. I know I can simply memorize the table for the test by this Friday, but I may likely forget them after the test. So is there a trick or pattern you guys usually use to remember it? For example, SOHCAHTOA tells us what sine, cosine, and tangent really mean. If not, I will just memorize the table. But just wanted to know what memorization techniques you guys use. I feel this is the perfect place to ask, because I bet a bunch of people in the math stackexchange, also had to go through the same thing freshman year of college. Oh here is a picture of the unit circle:","['mnemonic', 'trigonometry']"
1554001,Find a vector field $G$ with curl ($G$) = $F$,"Let $F(x, y, z) = (y, z, x^2)$ on $\mathbb{R}^3$.
We know that
$$y = \frac{\partial G_3}{ \partial y} - \frac{\partial G_2 }{\partial z}, \\ z = \frac{\partial G_1}{ \partial z} - \frac{\partial G_3 }{\partial x}, \\ 
x^2 = \frac{\partial G_2}{ \partial x} - \frac{\partial G_1 }{\partial y}.$$ How do I go further?","['multivariable-calculus', 'vector-fields']"
1554018,"Check answer, How to find Cov(x,y) and Var(2x-y)?","I have the following tableau x:   -1          0         1       total

y:  1    0         1/8        3/8      1/2
    2    3/8       1/8        0        1/2
total:   3/8       2/8        3/8       1 *)Find Cov(x,y) and Var(2x-y) My work:
 I use Cov(x,y)= E(XY)-E(X)E(Y) I have E(x)= 0
 E(Y)= 3/2
 E(X^2)= 3/4
 E(Y^2)= 5/2 After plug the values I have: Cov(xy)=-15/8 And, var(2x-y)= 4 var(x) + var(y) - 2*2 cov(xy)
   Var(2x-y)= 10.75 Question: I solve the exercise ok, or I have some problem. I want to check. Thanks!",['statistics']
1554033,Proving that restrictions of partial orders are partial orders,"Prove: A set has a partial-order relation $R$ on it. $P$ is a subset of this set. Prove that the restriction of $R$ to $P$ is itself a partial-order relation. Assume that this relation, $T$, resulting from the restriction of $R$ on $P$ is defined as such: $T = \{(x,y) \mid x \in P, y \in P, (x, y) \in R\}$. It seems to be obvious that if $R$ works on a set $S$, and $P$ contains some subset of $S$, then $T(R\text{ on }P)$ is also a partial-order relation; that, or $P$ is the non-orderable units of $S$. Anyhow, I have no examples of how to do this proof with a very general description of a relation/the sets it acts upon. How do I prove that that $T$ is a partial-order relation?","['order-theory', 'relations', 'discrete-mathematics']"
1554038,"Integral $\int_0^\infty\operatorname{arccot}(x)\,\operatorname{arccot}(2x)\,\operatorname{arccot}(5x)\,dx$","I have to evaluate this definite integral:
$$Z=\int_0^\infty\operatorname{arccot}(x)\,\operatorname{arccot}(2x)\,\operatorname{arccot}(5x)\,dx$$
My CAS was only able to find its approximate numeric value:
$$Z\approx0.796300956669079523165601562454031588576893734085453548868394...$$
Is there an approach that would allow to evaluate it in a closed form? I looked up this integral in Gradshteyn-Ryzhyk, but the closest one I found was formula 4.511:
$$\int_0^\infty\operatorname{arccot}(px)\,\operatorname{arccot}(qx)\,dx=\frac\pi2\left[\frac1p\,\ln\left(1+\frac p q\right)+\frac1q\,\ln\left(1+\frac q p\right)\right]$$
Is there a way to generalize it to a product of 3 arccotangents? Any help is appreciated.","['trigonometry', 'calculus', 'closed-form', 'integration', 'definite-integrals']"
1554062,Integral representation for Fibonacci's numbers,"We know that, for example, the Gamma function is a perfect integral representation for the factorial $n!$ for a natural number $n$. $$\Gamma[n] = \int_0^{+\infty} t^{n-1}e^{-t}\text{d}t = (n-1)!$$ Is there a similar integral representation through which I might find Fibonacci's numbers? Something like $$F_n = \int_0^{+\infty} F(x, n)\ \text{d}x$$ to obtain the $n-$th Fibonacci's number? P.s. Not necessarily an integration from zero to infinity.","['special-functions', 'integration', 'fibonacci-numbers']"
1554070,Prove $3+ 5 \sqrt {2}$ is irrational,"Prove $3+ 5 \sqrt{2}$ is irrational. I have some ideas about this proof, but I am not quite finished. I understand being irrational means the number would not be in the form of $\frac pq$. I have proved root $2$ is irrational before, but am a bit confused with this one, any ideas. Thank you in advance.","['proof-writing', 'discrete-mathematics']"
1554130,Does there exist a subgroup $G$ of $\mathbb{R}$ such that $\mathbb{R}/G \cong \mathbb{Z}$?,"My question is whether or not it's possible to find an additive subgroup $G$ of the real numbers such that the quotient group $\mathbb{R}/G$ is isomorphic to the infinite cyclic group. I'm not familiar with how to find the cardinality of infinite quotient groups, but my guess is that $G$ would have to have the same cardinality as the reals, in order for $\mathbb{R}/G$ to have cardinality $\aleph_0$. If I were to decide either way, I would guess that such a subgroup doesn't exist, but I haven't able to prove this, so I don't know. My idea for a proof of the negation of the statement is that given any isomorphism $\varphi: \mathbb{Z} \to \mathbb{R}/G=<r>$, $\varphi$ sends $1$ to the generator $r$, and to show that if $G$ is dense in the reals, there must exist elements of $G$ that add up to $r$, thus showing $r \in G$ by closure, which is a contradiction. Then again, the rationals are dense in $\mathbb{R}$ and no finite sum of rationals will ever give us an irrational number, so this proof may fall apart. Any thoughts?","['normal-subgroups', 'real-numbers', 'group-theory']"
1554168,What is a Killing Vector Field?,"What is the definition of Killing vector field?. The one my professor told me is : a smooth vector field $V$ on $M$ is called a Killing vector field for $g$ if the flow of $V$ acts by isometries of $g$. So what does it mean by the flow of $V$ acts by isometries? I suspect this definition is equivalent to saying the lie derivative of $g$ along a vector field is 0, then the vector field is a Killing field. But first I need to figure out the meaning of the first definition. $g$ is just the Riemannian Metric.",['differential-geometry']
1554174,When does $\log(\lim_{x\to c} f(x)) = \lim_{x\to c} \log(f(x))$?,"When does $$\log(\lim_{x\to c} f(x)) = \lim_{x\to c} \log(f(x))$$ I have seen different things from different sources. For example, this and this . Does $f(x)$ have to be continuous at c, does $\log (f(x))$ have to be continuous at c, or something else?","['continuity', 'real-analysis', 'logarithms', 'limits']"
1554203,Triangle inequality and the square root of a metric space,for (i) I know that the square root part is true but I don't know how to put it into words to prove it. For (ii) I just don't know how top apply the requirements for a metric space to the square root of another metric space. Just kind of confusing me,['real-analysis']
1554214,When can we restrict/condition a probability measure to a subset of zero measure?,"If $\mu(C)>0$, $$\mu_C(A)=\frac{\mu(A\cap C)}{\mu(C)}$$ is well-defined. If $\mu(C)=0$ things get hairy. If $C=\{x\}$ (single point) then $\mu_C=\delta_x$. If $C=\bigcup_{i=1}^nx_i$ (a finite collection of points) and $\mu$ has density $f$ w.r.t. Lebesgue measure then $$\mu_C\propto \sum_{i=1}^n f(x_i)\delta_{x_i}$$ (as long as not all $f(x_i)$ are zero). What about general case of $\mu(C)=0$? Any conditions on $\mu$ that would allow such a restriction? Would non-singularity be sufficient? Is the following limit well-defined: $$\mu_C(A)=\lim_{\epsilon\to 0}\mu_{C_\epsilon}(A)$$
where $C_\epsilon=\bigcup_{x\in C}B_x(\epsilon)$?","['probability', 'measure-theory']"
1554225,Calculus (Limits) Doubt: $\theta - \cfrac{\theta^3}{3!} < \sin \theta < \theta$ use to solve limit.,"Following is the question I've been trying to work on but can't get enough of it: $$\lim_{n\rightarrow \infty} \sin\left(\cfrac{n}{n^2+1^2}\right) + \sin\left(\cfrac{n}{n^2+2^2}\right) + \cdots + \sin\left({\cfrac{n}{n^2+n^2}}\right) $$ I'm required to find the value of the above limit. All I could think about is to take $n^2$ common from numerator and denominator of each term. $$\lim_{n\rightarrow \infty} \sin\left(\cfrac{1/n}{1+1^2/n^2}\right) + \sin\left(\cfrac{1/n}{1+2^2/n^2}\right) + \cdots + \sin\left({\cfrac{1/n}{1+n^2/n^2}}\right) $$ Now since $n \to \infty$ then shouldn't each term inside the sine function be zero and thus value of limit be zero? Where am I going wrong in this approach? Also, I found a trick for this question specified in my book as: To use the following inequality : $$\color{blue}{\theta - \cfrac{\theta^3}{3!} < \sin \theta < \theta }$$ And then to replace $\theta$ with $\cfrac{n}{n^2+k^2}$. I've never seen this inequality before, can anyone refer to the proof of this inequality? (or give the proof). EDIT : After working with the suggestions posted in the comments and answers: (and the link of the duplicate post) I do get the following equation: $$ \lim_{n \to \infty} \sum_{k=1}^{n} \cfrac{1}{n} \left(\cfrac{1}{1+(k/n)^2}\right)$$ How can I convert this into Integral now?","['calculus', 'limits']"
1554228,Three people each flip two fair coins.Find the probability that exactly two of the people flipped one head and one tail.,"Three people each flip two fair coins.Find the probability that exactly two of the people flipped one head and one tail. Out of three persons,two persons can be chosen in $\binom{3}{2}$ ways.Each person flips two fair coins.So each persons gets $HH,HT,TH,TT$.Probability of a person getting one head and one tail is $\frac{1}{2}$. So the probability that exactly two of the people flipped one head and one tail is $\binom{3}{2}\times\frac{1}{2}\times\frac{1}{2}=\frac{3}{4}$ But my answer is wrong.What is wrong in my approach.Please help me.","['combinatorics', 'probability']"
1554248,How to deal with an indefinite L'Hôpital operation,"Today in our AP Calculus class, we learned what is called L'Hôpital's rule for finding the limit of indefinite limits $\infty/\infty$ or $0/0$. The operation works by continuing to take the derivative of the limit until the answer is not indeterminate. How would one ""identify ahead of time"" and if possible, solve for a limit that would be continuously deriving without achieving an indeterminate answer? For example something along the lines of $\lim_{x \to \infty} \dfrac{e^{x}}{e^{x}}$ Wouldn't this example be indefinitely deriving to achieve the answer?","['calculus', 'limits']"
1554262,Does Globally Lipchitz prove a solution exists for all time?,"From ODE I learned if $g$ is Lipchitz on $\mathbb{R}^n$ there exists a unique solution $y:\mathbb{R} \Rightarrow \mathbb{R}^n$ to the IVP 
\begin{eqnarray}
y' &=& g(y)\\
y(t_0) &=& y_0
\end{eqnarray}
where $t_0=0$ From what I understand, since $g$ is globally Lipchitz, then it is locally Lipchitz. From the fact it is locally Lipchitz, I can prove there exist a $c>0$ such that our IVP has a unique solution $y(t)$ on a small interval $[-c,c]$. What I don't understand is, how does a Globally Lipchitz function implies there exist a unique solution on $\mathbb{R}$? The only thing that comes to mind is this, (continuing from what we previously established) since $g$ is Globally Lipchitz and we have proven there exist a unique solution $y(t)$ on $[-c,c]$, I can pick a $t_1>0\in [-c,c]$ such that we have a new IVP 
\begin{eqnarray}
y' &=& g(y)\\
y(t_1) &=& y_1
\end{eqnarray}
Afterwards, it can be proven that this new IVP has a unique solution on some interval $[-c_1+t_1,c_1+t_1]$. Then you would continue iterating this procedure (making sure to pick $t_i>t_{i-1}$) until you construct $[c,\infty]$. You would apply a similar argument to construct the other half of our interval to get the complete $\mathbb{R}$. My only issue is, what if (let's say) after some large $n$, $[-c_n+t_n,c_n+t_n]$ becomes so small that the maximal interval converges to a fixed point and doesn't reach $\infty$?  How would you prevent that issue from happening? I'm new to the forum so I hope my question wasn't to vague. If you need me to clarify, please let me know. Thanks for the help.","['real-analysis', 'lipschitz-functions', 'ordinary-differential-equations']"
1554268,What's the probability that Erica has one boy and one girl?,"During a flight on an airplane, Eric strikes up a chat with Erica, the person sitting next to him. It turns out that Erica has two kids, and at least one of them is a girl born on a Tuesday. Being a mathematician, Eric decides to find the probability that Erica has a boy and a girl before asking her. What is the probability that Erica has one boy, and one girl? Assume an equal chance of giving birth to either gender and an equal chance to giving birth on any day. I was looking at the solution to this question and for some reason they were looking at the number of pairs of $bg$ in a two week time period. Why not a week period?",['probability']
1554278,Evaluating $\int_0^2 x(8-x^3)^{\frac{1}{3}}\ dx$,"What substitution would you use to get from
$$\int\limits_0^2 x(8-x^3)^{\frac{1}{3}}\ dx$$
to $$\int\limits_0^1 (1-t)^{a-1}t^{-a}\ dt, \ a\in(0,1)\ ?$$ I know how to evaluate the second integral and I thought that if I substitute $t={x^3\over8}$ I would reduce this to the form above, but what I get is $$\frac{8}{3}\int\limits_0^1 (1-y)^{\frac{1}{3}}y^{-\frac{1}{3}}\ dy$$","['substitution', 'complex-analysis', 'integration', 'definite-integrals']"
1554316,"If $P \in Syl_p(G)$ and $P$ is cyclic, then $N_G(P)=C_G(P)$","Let $G$ be a group such that $|G|=p^a m$ where $p$ is the smallest prime divisor of $|G|$.
        If $P \in Syl_p(G)$ and $P$ is cyclic, then $N_G(P)=C_G(P)$ Proof First, note that $C_G(P) \leq N_G(P) \leq G$. Thus, we are done if $|N_G(P)|/|C_G(P)|=1$.
        Since $P \leq G$, by Corollary 15, $N_G(P)/C_G(P)$ is isomorphic to a subgroup of $Aut(P)$.
        Since $P$ is cyclic of order $p^a$, we have $P \cong \mathbb{Z}/p^a \mathbb{Z}$.
        Thus, $|Aut(P)| = |Aut(\mathbb{Z}/ p^a \mathbb{Z})| = |(\mathbb{Z}/p^a \mathbb{Z})^{\times}|$ since
        $Aut(\mathbb{Z}/ p^a \mathbb{Z})| \cong (\mathbb{Z}/p^a \mathbb{Z})^{\times}$. 
        Then, $|Aut(P)| = \phi(p^a) = p^{a-1}(p-1)$ where $\phi$ is Euler's totient function.
        Thus, $N_G(P)/C_G(P)$ divides $p^{a-1}(p-1)$. Since $P$ is cyclic, $P$ in particular is abelian, and it follows that $P \leq C_G(P) \leq N_G(P)$. Since $P \leq N_G(P)$, there exists a positive integer $k_1, k_2$ such that $|N_G(P)|=k_1 p^a$ and $|C_G(P)|=k_2 p^a$.
Since $k_1 p^a$ divides $p^a m$, $k_1$ must divide $m$.
Since $|N_G(P)|/|C_G(P)|=k_1/k_2$, $|N_G(P)/C_G(P)|$ divides $m$. Since the prime divisors of $m$ are greater than $p$, it must be that $|N_G(P)/C_G(P)|=1$. This completes the proof. I don't really like the way argued the division of $m$. Is there a more succinct and better way to argue this? Thank you in advance!","['finite-groups', 'abstract-algebra', 'proof-verification', 'sylow-theory', 'group-theory']"
1554319,A conceptual problem in group theory,"As we all know that in group $S_n$ every pair of distinct  disjoint cycles commute .my doubt is is it reverse all true,mean if a pair of distinct cycles commute ,then they have to be disjoint??.i tried to find examples where distinct cycles commute but not disjoint,but fail to do so","['finite-groups', 'permutations', 'group-theory', 'symmetric-groups']"
1554392,Connection of Fourier's work with Fredholm's,"Im trying to formulate for myself in what sense Fredholms work on the Dirichlet problem is connected to Fouriers work on the heat equation. Fourier idea seems to have fundamental problems with convergence, while Fredholm concerns himself with existence of solutions via the integral equation $I \lambda - K$. There doesn't seem to be any series or convergence in the work of Fredholm, also anyone writing about the work of Fredholms have an abstract kernel $K$ and do not say anything about how this looked in his specific problems which makes it even harder to see the connection. Is there simple explanation why these problems seem so far apart? Own idea ; Fourier suggest solution in term of series. No one knows what this expression represent. Fredholm doesn't investigate the solution itself but rather tries showing that some solution exists. If it doesn't then fourier expression might not even be well defined. It turns out that this has solutions, and then people carry on investigating the convergence. Am I on the right track?","['math-history', 'fourier-analysis', 'partial-differential-equations', 'operator-theory', 'functional-analysis']"
1554412,Show that $P$ is symmetric.,"Let $P$ = $A(A^TA)^{-1}A^T$, where A is an m x n matrix with rank $n$. I feel like this is wrong, but here is my attempt:
$A(A^TA)^{-1}A^T$ = $AA^{-1}(A^T)^{-1}A^T$ = $I$
And $I^T$ = $I$, so the matrix is symmetric.","['matrices', 'transpose', 'symmetry', 'inverse', 'linear-algebra']"
1554414,"If a separately continuous function $f : [0,1]^2 \to \mathbb{R}$ vanishes on a dense set, must it vanish on the whole set?","Assume $f(x,y)$ is defined on $D=[0,1]\times[0,1]$, and $f(x,y)$ is continuous of each separate variables(i.e. if we fix $y$ to $y_0$, then $f(x,y_0)$ is continuous and vice versa). If $f(x,y)$ vanishes on a dense subset of $D$. Does $f$ vanishes on $D$?","['multivariable-calculus', 'real-analysis', 'continuity', 'analysis']"
1554418,How do you prove the injective nature of an isomorphism from $\mathbb{R}[x]/\langle x^2+1\rangle$ and $\mathbb{C}$,"I've been reviewing my notes for a course I'm taking and I am confused about my professor shows that $\mathbb{F}=\mathbb{R}[x]/\langle x^2+1\rangle$ is isomorphic to $\mathbb{C}$. I understand most of it but when it comes time to prove that the homomorphism is a bijection I get confused. Essentially, what he does is he shows that $f:\mathbb{F} \to \mathbb{C}: f(g)=g(i),g\in \mathbb{F}$ is a homomorphism and then shows the injective nature by showing that $\ker(f)={1_\mathbb{F} }$ and then he shows the bijective nature. I dont understand why this is a valid way of showing the injective nature of $f$. Could someone please explain it to me? Also, if you dont mind, would you be able to walk me through the logic of this proof? Thanks","['abstract-algebra', 'ring-theory']"
1554421,Name for the module corresponding to a square matrix,"I recently learned that for each $n \times n$ matrix $A$ with entries in some field $F$, there is a corresponding $F[x]$-module $M_A$. Namely, $M_A$ is the set $F^n$ with vector addition defined as usual, but with scalar multiplication defined by $f(x) \cdot v = f(A) \, v$ for each $f(x) \in F[x]$. My question is whether there is a name for the module $M_A$, and if so, what is it? I'm sorry that this is a bit of a trivial question, but I've looked around and have been unable to find an answer. If this question is inappropriate for this site please don't hesitate to let me know. Thanks.","['abstract-algebra', 'functional-analysis', 'terminology', 'representation-theory', 'linear-algebra']"
1554424,How do you solve $\frac{|x^2+5x+6|}{|x|-3} = 1$,"How do you solve $ \frac{|x^2+5x+6|}{|x|-3} = 1 $   ? I have tried rearranging, polynomial division, multiplying both sides by a a fraction to simplify to no avail for the last hour.","['algebra-precalculus', 'polynomials']"
1554431,"The order of $ab$ when $a,b$ commute","Let $a,b$ be two group elements of finite order that commute. What can be said about the order of $ab$? I thought that $|ab| = \text{lcm}(|a|,|b|)$. My proof was that $(ab)^n = a^n b^n =e$ if and only if $a^n = b^n = e$ if and only if $|a|,|b|$ both divide $n$. The smallest $n$ such that both orders divide it is the least common multiple of $|a|$ and $|b|$. By chance I came across this answer . It has an upvote so it's clearly correct. (?) But it contradicts what I think: It's clear that $$ (ab)^{\text{lcm}(|a|,|b|)} = e$$ hence $|ab| \mid \text{lcm}(|a|,|b|)$. It seems to me that this is saying more than $|ab| \mid |a| |b|$. Is it not? Now my question is: what is the precisest statement that can be made about $|ab|$?  Is there anything more than $|ab| \mid \text{lcm}(|a|,|b|)$ that can be said about $|ab|$?","['group-theory', 'proof-verification']"
1554436,De Moivre Theorem. Find the exact values of the solutions of the equations.,"By considering $z=cos\theta +i \sin \theta$ and using de Moivre's theorem, show that $$\sin5 \theta=\sin \theta (16 \sin^4 \theta-20 \sin^2 \theta +5)$$ Find the exact values of the solutions of the equation $16x^4-20x^2+5=0$ I've no problem with the first part. Then i found the x is equal to 0, $\sin36, \sin108$ and $\sin144$. But the given answer 0 is not included. Why?","['algebra-precalculus', 'trigonometry', 'complex-numbers']"
1554437,Blowing up an affine scheme at a regular point,"I am reading Liu's Algebraic Geometry and Arithmetic Curves and get stuck at Lemma 8.1.2: Let $A$ be a Noetherian ring an define for an ideal $I \subset A$ the $A$-algebra
$$\tilde{A}:=\bigoplus_{d\geqslant 0} I^d, \qquad I^0:=A.$$
Let $f_1, \ldots, f_r$ be a system of generators of $I$ and let $t_i \in I = \tilde{A}_1$ denote the element $f_i$ considered as a homogeneous element of degree 1. We have a surjective homomorphism of graded $A$-algebras
$$\phi: A[T_1, \ldots, T_n] \longrightarrow \tilde{A}, \qquad T_i \mapsto t_i.$$
Let $\tilde{X}:= \operatorname{Proj} \tilde{A}$. My questions are the following: He says: If $P$ is a polynomial with coefficients in $A$, then $P(t_1, \ldots, t_n)=0$ if and only if $P(f_1, \ldots, f_n)=0$.
Why is this worth a remark, if $f_i=t_i$? If $I$ is generated by a regular element, then $\tilde{A} \cong A[T]$.
In the proof he says the homomorphism $\phi: A[T] \longrightarrow \tilde{A}$ from above is an isomorphism. But why? Is see, that the elements in $A[T]$ and in $\tilde{A}$ look very similar, but I cannot see, why the fact ""regular"" gives the claim. I hope anybody can help me! Thanks for helping me!","['blowup', 'algebraic-geometry', 'commutative-algebra']"
1554446,Abstract appoach to multivariable calculus,"(I have posted a similar question hours ago, but I deleted that and slightly modified the question and reposting it here.) So far, I have studied all undergraduate courses only except Green's theorem and Stoke's theorem. As far as I know, to prove the most general form of Stoke's theorem, one must know some sophisticated algebras. (Tensor algebra, Exterior algebra and etc) I like this approach but it seems like I have to learn so many things to achieve this. Anyway, what are the rigorous texts introducing this general form of Stoke's theorem ? Moreover, while the general form of Stoke's theorem requires lots of prerequisites, Green's theorem seems much easier to prove than Stoke's theorem in abstract context. I'm not asking for a very top generalized setting of Green's theorem. Just like one learns Cauchy's Integral formula with relation of homotopy theory in graduate school while one learns it for a simple closed curve (without knowledge of homotopy theory), I'm curious whether there is a text treating Green's theorem and related multivariable calculus in graduate-level abstract setting . Say $\alpha$ is a differentiable simple closed curve one is applying Green's theorem on. And consider a rectifiable simple closed curve $\beta$ which is homotopic to $\alpha$ rel $\{0,1\}$. Such $\beta$ can be chosen very close to $\alpha$ so I think the area difference of interiors of $\alpha$ and $\beta$ can be made arbitrarily small or zero. I think to make this assertion precise, one needs lebesgue measure to control areas. Even though a text does not cover what I just described, what is an abstract text treating multivariable calculus that you know? Thank you in advance.","['multivariable-calculus', 'reference-request', 'real-analysis', 'book-recommendation']"
1554448,How to integrate $xe^x$ without using antiderivatives or integration by parts.,"Yesterday, I sat for my Real Analysis II paper. There I found a question asking to integrate $\displaystyle\int_0^1 xe^x \, dx$ without using antiderivatives and integrating by parts. I tried it by choosing a partition $$P_n=(0,\frac{1}{n},\frac{2}{n},\ldots,\frac{n-1}{n},1),$$ but I was not able to show that $\displaystyle \lim_{n \to \infty} U(f,P_n)=\lim_{n \to \infty} L(f,P_n)=1$","['riemann-integration', 'calculus', 'integration', 'definite-integrals', 'riemann-sum']"
1554466,Calculating $Log(-e i)$,$$Log(-e i)$$ My try: $$=\ln|0+(-e)i|+i[\arg (0+(-e i))+2\pi k]$$ $$=\ln|e i|+i(-\frac{\pi}{2}+2\pi k)$$ My attempt is correct?,"['complex-analysis', 'proof-verification']"
1554494,Reference Request for Topics in Group Theory,"I'm taking an honors-level algebra class and we're getting into group actions, Sylow subgroups and semidirect products. These topics are fairly intimidating, but the lengthier discussions in the book (Dummit and Foote) have been very helpful in bringing these topics down to earth - for example, investigating the structure of groups of order $pq$, $p^2q$, classifying all groups of order 30, etc. Seeing these ideas put to use ""in the wild"" makes them a lot more tractable. Therefore I'm looking for further reading material in this vein, i.e. substantial discussions that use many of the techniques and ideas that one would find in a solid undergraduate group theory course. Ideas I had: research papers in group theory which would be accessible to someone at my level, materials used in graduate courses, miscellaneous articles and expository writings. D&F has plenty of exercises but even more couldn't hurt. And I'm open to sources that go a little beyond what might be expected of an undergraduate.","['reference-request', 'abstract-algebra', 'group-theory', 'soft-question']"
1554506,Computing cohomology over projective curve in $\mathbf{P}^3$,"Let be $k$ an algebraically closed field and Let be $X\subseteq \mathbf{P}^3:=\mathbf{P}_k^3$ a smooth, irreducible curve that is not contained in any hyperplane. Let's call $d=\deg(X)$. A well known theorem of Gruson, Lazarsfeld and Peskine states that such a curve is $d-(3-1)+1=d-1$-regular, that is 
$$H^p(\mathbf{P}^3,\mathscr{I}_X(d-1-p))=0$$
for all $p>0$. Now, some simple computations on this definition show us that this reduces to the following conditions:
$$H^1(\mathbf{P}^3,\mathscr{I}_X(d-2))=0,\,\,\,H^1(\mathbf{P}^3,\mathscr{O}_X(d-3))=0$$ Now the actual question. I would like to show that the theorem holds without using it, but I'm a bit struck. I need in particular the cases of a complete intersection curve and a rational curve of degree $3$. For example, if you write $X=F_1\cap F_2$ as complete intersection of hypersurfaces $F_1,F_2$ of degree $d_1,d_2$ respectively, then the Koszul complex (aka Hilbert-Burch complex) resolves the ideal of $X$:
$$0\to \mathscr O_{\mathbf{P}^3}(-d_1-d_2)\to \mathscr O_{\mathbf{R}^3}(-d_1)\oplus \mathscr O_{\mathbf{R}^3}(-d_1)\to \mathscr{I}_X\to 0$$
Switching to cohomology sequence, this should imply $H^1(\mathbf{P}^3,\mathscr{I}_X(s))=0$ for all $s$; I'm not so sure this is completely correct. As for the other condition, we may compute the canonical bundle $$\omega_X=\omega_{\mathbb{P}^3}(+d_1+d_2)=\omega_{\mathbb{P}^3}(d_1+d_2-4)$$ so when $s\geq d_1+d_2-3$ we have $H^1(\mathscr{O}_X(s))=0$ for sure. Then the inequality $d=d_1d_2\geq d_1+d_2-1$ shows the second condition. Can somebody help me understand better these computations? How should I proceed to yeld a similar result in the case of a rational curve of degree $3$?","['algebraic-curves', 'sheaf-cohomology', 'algebraic-geometry']"
1554543,$x \propto y^2$ Vs $x \propto y$,"$$x \propto y^2$$ How is it different from saying: $$x \propto y$$ That is; when we say that Two variables are proportional then it means that two variables are related such that when one is zero other is too. And change in one variable is accompanied by change in other. This is a general definition for proportionality. Then if we write $x \propto y^2$, by definition, we implicitly mean that $x \propto y$. So, why write $x \propto y^2$ instead of a simple one $x \propto y$? Is it due to the calculation of constant of variation? Viz., the constant of proportionality onliy lies between $x$ and $y^2$ relation and not between $x$ and $y$ relation? Is it for that purpose that we specify them?",['algebra-precalculus']
1554573,"How do I prove that among any $5$ integers, you are able to find $3$ such that their sum is divisible by $3$?","How do I prove that among any $5$ integers, you are able to find $3$ such that their sum is divisible by $3?$
I realize that this is a number theory question and we use modular arithmetic, but I'm unsure of where to begin with this specific situation.",['number-theory']
1554604,Calculate point A from given point E and angle and afterwards calculate Point A from E and angle,"I read some related questions, but I am not sure how to adopt them to my problem. ( Example: Calculate point, given x, y, angle, and distance ) Let's say I have point E(600|581) and an angle of 64 degrees .
To calculate A I use the following. (distance = 133) radian measure = (2 * PI / 360 ) * (360 - 64)
A.x =  E.x + distance *  cos(radian measure)
A.y =  E.y + distance *  sin(radian measure)

A = (658 | 460) Now how can I get from A back to E? ( Assuming that I dont know the coordinates for A) 
I thougt it would be radian measure = (2 * PI / 360 ) * 64
E.x =  A.x + distance *  cos(radian measure)
E.y =  A.y + distance *  sin(radian measure) But this results in E = (716|581) Changing the + to - gives the right result. radian measure = (2 * PI / 360 ) * 64
E.x =  A.x - distance *  cos(radian measure)
E.y =  A.y + distance *  sin(radian measure)

E = 600 | 581 I just found this by guessing so I am not sure why it is like that and when it has to be like this.","['trigonometry', 'geometry']"
1554615,Are all sets in sigma-algebra measurable?,"In the Wikipedia article it says: the collection of those subsets for which a given measure is defined
  is necessarily a $\sigma$-algebra. Fine, but is the opposite true? Do we know for sure that all sets of sigma algebra are measurable? If the answer is no , then is it the reason why Borel sigma algebra is so widely used in probability theory?","['measure-theory', 'elementary-set-theory']"
1554623,Subalgebra of $C(X)$ where $X$ is a compact Hausdorff space,"Proposition Let $X$ be a compact Hausdorff space and $C(X)$ be the set of all continuous real-valued functions on $X$. Let $\mathcal{A}$ be a subalgebra of $C(X)$ that separates points of $X$. Show that either $\overline{\mathcal{A}}= C(X)$ or there is a point $x_{0}$ such that $\overline{\mathcal{A}}= \{\ f\in C(X): f(x_{0})=0 \}\ $. My attempt: If constant function $1$ belongs to $\mathcal{A}$, then subalgebra $\mathcal{A}$ contains all constant functions and $\mathcal{A}$ is dense in $C(X)$ by Stone-Weierstrass theorem. Otherwise, $1\notin \mathcal{A}$. Suppose that for each $x\in X$ there is an $f\in \mathcal{A}$ with $f(x)\neq 0$, then by the continuity of each $f$ and compactness of $X$ I can prove that there is a $g\in \mathcal{A}$ that is positive on $X$. But how can I use this fact to conclude a contradiction i.e. $1\in \mathcal{A}$ so that we prove the exsitence of such $x_{0}$? And I was also wondering how to prove $\{\ f\in C(X): f(x_{0})=0 \}\ \subset \overline{\mathcal{A}}$? Thanks!","['general-topology', 'real-analysis']"
1554690,Cardinality of $\sigma$-algebra generated by an infinite family of sets,"Let $\mathcal{F}$ be an infinite family of subset of $X$ of cardinality $\kappa$ (thus $\kappa$ is an infinite cardinal). From the recursive description of generated $\sigma$-algebra, I know that the $\sigma$-algebra $\langle \mathcal{F}\rangle$ which is generated by $\mathcal{F}$ has cardinality at most $\kappa^{\aleph_0}$. On the other hand, since $\langle \mathcal{F}\rangle $ contains $\mathcal{F}$,  $\langle \mathcal{F}\rangle$ has cardinality at least $\kappa$. Thus we have $\kappa\leq |\langle \mathcal{F}\rangle |\leq \kappa^{\aleph_0}$. Is is true that $|\langle \mathcal{F}\rangle |=\kappa^{\aleph_0}$? I'm not very familiar with cardinal arithmetic, thanks for any help.","['real-analysis', 'set-theory']"
1554699,Proving that the circumcenters are concyclic.,"I was completely lost when handed this at a math competition a couple of weeks ago. In triangle $ABC$ , medians $AA_0$ , $BB_0$ and $CC_0$ intersect at a point $M$ .  Prove that the circumcenters of triangles $MA_0B_0$ , $MCB_0$ , $MA_0C_0$ , $MBC_0$ and point $M$ are concyclic. I drew the diagram and was able to make sense of the question. My diagram also seemed to show that the circumcenters were concyclic however, because of my lack of any major exposure to circle geometry I was not able to make much progress beyond this.  Please help. I am trying to practice for the next competition. I really appreciate your support. Thank you.","['contest-math', 'geometry']"
1554740,Is a continuous function locally uniformly continuous?,"Assume a function, $f : X \to Y$, mapping between two metric spaces, $X,Y$, is pointwise continuous, i.e. for every $\varepsilon >0$ and $x \in X$ there exists a $\delta>0$ such that 
$$
\|x-x'\|_X < \delta
\implies
\|f(x) - f(x')\|_Y < \varepsilon
, \qquad
\forall x' \in X.
$$ Does this imply $f$ is locally uniformly continuous , i.e. for every $x \in X$ there exists a neighbourhood $U \subset X$ such that for every $\varepsilon > 0$ there exists a $\delta > 0$ such that 
$$
\|x_1-x_2\|_X < \delta
\implies
\|f(x_1) - f(x_2)\|_Y < \varepsilon
, \qquad
\forall x_1,x_2 \in U?
$$ A positive answer without proof, under the condition that $X$ and/or $Y$ are locally compact, is implied here .","['continuity', 'general-topology', 'examples-counterexamples', 'uniform-continuity']"
1554756,How do I explain the Königsberg Bridge problem to a child?,"I am going to demonstrate the Königsberg seven bridge problem in a science exhibition. I am also going to use a model for a more visual representation of the problem. Now, how do I explain this (the solution) simply to a child who is not too much familiar with high school mathematics. How do I approach the demonstration to make it appear more attractive?","['graph-theory', 'big-list', 'eulerian-path', 'soft-question', 'general-topology']"
1554765,Differentiability of $f(x+y) = f(x)f(y)$ [duplicate],"This question already has answers here : Prove that $f'$ exists for all $x$ in $R$ if $f(x+y)=f(x)f(y)$ and $f'(0)$ exists (2 answers) Closed 8 years ago . Let $f$: $\mathbb R$ $\to$ $\mathbb R$ be a function such that $f(x+y)$ = $f(x)f(y)$ for all $x,y$ $\in$ $\mathbb R$. Suppose that $f'(0)$ exists. Prove that $f$ is a differentiable function. This is what I've tried:
Using the definition of differentiability and taking arbitrary $x_0$ $\in$ $\mathbb R$. $\lim_{h\to 0}$ ${f(x_0 + h)-f(x_0)\over h}$ $=$ $\cdots$ $=$  $f(x_0)$$\lim_{h\to 0}$ ${f(h) - 1\over h}$. Then since $x_0$ arbitrary, using $f(x_0+0) = f(x_0) = f(x_0)f(0)$ for $y = 0$, can I finish the proof?","['derivatives', 'real-analysis', 'functional-equations']"
1554766,Root system of an abelian lie subalgebra.,"Let $L$ be a lie algebra and $H$ an abelian subalgebra of $L$ such that each element of $h \in H$ is diagonalizable under the adjoint representation. So there exists a basis of common eigenvectors for $ad(h)$ for all $h \in H$ and non zero functionals $\lambda_1 \ldots \lambda_n \in H^*$
\begin{gather}
L=C_L(H) \oplus \bigoplus_{i=1}^n L_{\lambda_i} 
\end{gather}
With $C_L(H)$ is the centralizer of $H$ and $L_\lambda =\{x \in L: [h,x]=\lambda(h)x, \forall h\in H\} $.
Now if $H$ is maximal among the abelian lie sub-algebras that act diagonalizable on $L$ via the adjoint representation, the functionals $\lambda_i$ are a root system for $H^*$ and $H$ is self-centralizing.
What can we say if $H$ is not maximal? For examble, if we don´t know that $H$ is maximal but we find out that the $\lambda_i$ are a root system for $H^*$, can we say that the decomposition of $L$ above is a root decomposition and $H$ self-centralizing?
In general, are there some ways to obtain information about how $H$ is embedded in $L$ from the eigenvalues $\lambda_i$?","['abstract-algebra', 'root-systems', 'lie-algebras']"
1554777,Infinite series equality $¥frac{1}{1+x}+¥frac{2x}{1+x^2}+¥frac{3x^2}{1+x^3}+¥frac{4x^3}{1+x^4}+¥cdots$,"Prove the following equality ($|x|<1$). $$¥frac{1}{1+x}+¥frac{2x}{1+x^2}+¥frac{3x^2}{1+x^3}+¥frac{4x^3}{1+x^4}+¥cdots¥¥
=¥frac{1}{1-x}+¥frac{3x^2}{1-x^3}+¥frac{5x^4}{1-x^5}+¥frac{7x^6}{1-x^7}+¥cdots¥¥$$","['sequences-and-series', 'calculus']"
1554787,What are the mean and variance of the log of a random variable?,"Here's the problem. We have a random variable X that follows a Poisson law. If we take the log of this variable, what are the first two moments (mean and variance) of the law it follows? This looks like a simple question, but I can't find anything about it. Any idea? EDIT: In order to prevent the X=0 case, we bias the Poisson law. Our random variable becomes log(X+epsilon) with X~Poisson(λ).","['poisson-distribution', 'probability', 'random-variables', 'probability-distributions']"
1554790,How to prove that $\lim_{n \to\infty} \frac{(2n-1)!!}{(2n)!!}=0$,"So guys, how can I evaluate and prove that $$\lim_{n \to\infty} \frac{(2n-1)!!}{(2n)!!}=0.$$ Any ideas are welcomed. $n!!$ is the double factorial, as explained in this wolfram post.","['factorial', 'calculus', 'limits']"
1554819,A solution of a second order homogenous ODE has infinite zeros on a closed interval is $y=0$,"We have the ODE $y''+p(x)y'+q(x)y=0$, the functions $p(x)$ and $q(x)$
  continuous on a closed interval $[a,b]$. Prove that if the solution
  $y(x)$ has an infinite number of roots ($x$s such that $y(x)=0$) on
  the interval $[a,b]$, then $y(x)=0$. I tried negating the claim, saying there is an $x_0$ such that $y(x_0)\neq 0$, but got nowhere. A hint or a direction of thought would be appreciated.",['ordinary-differential-equations']
1554822,Relation between coefficients of a matrix and its eigenvalues,"Let $A \in \mathbb{R}^{nxn}$ be a matrix and $\rho(A)$ its largest eigenvalue (or largest module of its eigenvalues). Let $a_{ij}$ be a typical entry of the matrix $A$ at the $i$-th row and $j$-th column such that $a_{ij} \in \{0,1\}$ and $a_{ii} \equiv 0$. If the following condition is satisfied for some constant $\alpha > 0$ $$ \alpha \rho(A) < 1 $$ can we deduce that $$\alpha a_{ij} < 1 $$ for all $i$ and $j$ in $\{1, \ldots n \}$ ? For example call the following matrix A, \begin{pmatrix} 
   0 & 0 & 1 \\
   1 & 0 & 1 \\
1 & 1 & 0 
\end{pmatrix} has eigenvalues  $-0.6180$ and $1.6180$ and $-1.0000$. Since $\rho(A)= 1.618$ it seems to be true for this special case. Can anyone see an obvious counter example? We know from Gershgorin circle theorem that every eigen value of the square matrix $A$ lies in at least one of Gershgorin's disc $D(a_{ii} , R_i)$, where $D(a_{ii} , R_i)$ is a closed disc centered at $a_{ii}$ with radius $R_i = \sum_{ j \neq i } |a_{ij} |$. So we have an estimate of the range of the eigenvalues but it doesn't directly answer my question.","['matrices', 'eigenvalues-eigenvectors']"
1554870,Real Analysis - Uniform Convergence of $f_n$,"I am given that: For $n \in \mathbb{N}$, define $f_n: \mathbb{R} \to \mathbb{R}$ by $$f_n(x)=\frac{x^{4n}}{4+x^{4n}}.$$ I need to determine whether the sequence $(f_n)$ converges uniformly on $\mathbb{R}$. This is what I have done: \begin{align}
\lim_{n \to \infty}f_n(x)&=\lim_{n \to \infty}\frac{x^{4n}}{4+x^{4n}}=
    \begin{cases}
       0, & \text{if}\ x \in (-1,1) \\
      \frac15, & \text{if}\ x \in \{-1,1\} \\
      1, & \text{if}\ x \in \mathbb{R}\setminus[-1,1]
    \end{cases} = f(x)
\end{align} Now I am struggling to show whether or not $f_n$ converges uniformly to $f$ over $\mathbb{R}$.","['uniform-convergence', 'real-analysis', 'convergence-divergence', 'analysis']"
1554884,"In a Completely regular $T_1$ space, two disjoint sets, one compact, the other closed, can be separated by a continuous function?","Let $X$ be a completely regular $T_1$ space and let $A,B$ be disjoint closed subsets of $X$, where $A$ is compact also. Then is it true that there exist a continuous function $f\colon X \to [0,1]$ such that $f(A)=\{0\}$, $f(B)=\{1\}$?","['continuity', 'general-topology', 'separation-axioms']"
1554955,Show that $\int_{\mathbb{R}} |f'(t)|^2+(9t^6+18t^4)|f(t)|^2 dt\ge 3$ for functions with unit $L^2$ norm,"I want to show that $$g(f):=\int_{\mathbb{R}} |f'(t)|^2+(9t^6+18t^4)|f(t)|^2 dt$$ is bounded from below by $3$ for $f \in C_c^{\infty}(\mathbb{R})$ and $||f||_{L^2}=1.$ What is obvious is that $g$ is bounded below by $0,$ but I don't see how the $3$ comes into the game. Does anybody have an idea? My ideas so far: Throw away any of the terms, as they are all positive (does not sound that good to me, as it is a very bold approximation). Use Sobolev's inequality to eliminate the derivative. In particular, I think we have to do something about this polynomial there. Use the Fourier transform (Plancherel) to turn derivatives into polynomials and vice versa. If anything is unclear, please let me know.","['functional-analysis', 'real-analysis', 'fourier-analysis']"
1554956,"if $f: (0,\infty) \to (0,\infty)$ is a strictly decreasing then $f \circ f$ is decreasing?","I need to find the truth value of the statement ""for each strictly decreasing function $f :(0,\infty)\to(0,\infty)$,the composition function function $f\circ f$ is decreasing"".
Can I find a function to disprove this statement? Can I use the function $f :(0,\infty)\to(0,\infty)$, where $f(x)=\dfrac1x$?","['elementary-set-theory', 'logic', 'functions']"
1554971,Branch of $\sqrt{1-z^2}$,"Show that a branch of $\sqrt{1-z^2}$ can be defined in any region $\Omega$ where the points $1,-1$ are in the same component of its complement. This is a question in Ahlfors' Complex Analysis (P.148 Q5) that I came across while trying to self-study the book. I tried to tackle the problem by considering $\Omega=\mathbb{C} \backslash [-1,1]$ first, and tried the approach as in Section 4.4 Corollary 2, namely find a branch of the corresponding log first. For this $\Omega$, the image of $1-z^2$ is $\mathbb{C} \backslash [0,1]$, so a branch of $log(1-z^2)$ cannot be defined; evidently one needs to construct the branch of $\sqrt{1-z^2}$ directly. Here is where I ran out of ideas... Any help is appreciated!",['complex-analysis']
1554993,integer solution of $\frac{x^3+y^3+z^3-xy(x+y)-yz(y+z)-xz(x+z)-2xyz}{(x+y+z)(x+y-z)(x-y+z)(x-y-z)}=\frac{1}{2016}$,"Let $x,y,z$ be positive integers such that $\frac{x^3+y^3+z^3-xy(x+y)-yz(y+z)-xz(x+z)-2xyz}{(x+y+z)(x+y-z)(x-y+z)(x-y-z)}=\frac{1}{2016}$. How to find all solutions ? I have no any idea. Thanks in advance.","['number-theory', 'integers', 'diophantine-equations']"
1554995,substituting spherical coordinates to evaluate an integral.,"I have to evaluate $$\int^1_{-1} \int^{ \sqrt {1-x^2}}_{-\sqrt {1-x^2}} \int^1_{-\sqrt{x^2+y^2}} \, dz \, dy \, dx$$ using spherical coordinates. This is what I have come up with \begin{align}
& \int^1_0 \int^{2\pi}_0 \int^{3\pi/4}_0 r^2\sin\theta \, d\theta \, d\phi \, dr \\[10pt]
= {} & \int^1_0 r^2 \, dr \int^{2\pi}_0 d \phi \int^{3\pi/4}_0 r^2\sin\theta \, d\theta \\[10pt]
= {} & \frac 1 3 \times 2\pi \times \left[-\cos\theta\vphantom{\frac 1 1}\right]^{3\pi/4}_0
\end{align} by a combination of sketching and substituting spherical coordinates. After evaluating I obtain this integral to equal 3.57. where as the first one evaluates to 5.236. EDIT:
A bit of thought shows me that the above integral gives a spherical volume. We need to restrict $r$ As $x^2 + y^2 = 1 \implies \rho = \csc \theta$ $$\int^{3\pi/4}_{\pi/4} \int^{2\pi}_0 \int^{\csc \theta}_1 r^2\sin\theta \, dr d\phi \, d\theta $$ However This, yet again, does not give me what I want.","['multivariable-calculus', 'spherical-coordinates']"
1555039,"What is the agreed upon definition of a ""positive definite matrix""?","In here: http://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/positive-definite-matrices-and-applications/symmetric-matrices-and-positive-definiteness/MIT18_06SCF11_Ses3.1sum.pdf A positive definite matrix is a symmetric matrix A for which all
  eigenvalues are positive. - Gilbert Strang I have heard of positive definite quadratic forms, but never heard of definiteness for a matrix. Because definiteness is higher dimensional analogy for whether if
something is convex (opening up) or concave (opening down). It does
not make sense to me to say a matrix is opening up, or matrix is
opening down. Therefore it does not make sense to say that a matrix has definiteness. In addition, when we say $M \in \mathbb{R}^{n \times n}$ positive
definite, what is the first thing we do? We plug $M$ into a function(al)
$x^T (\cdot) x$ and check whether the function is positive for all $x
   \in \mathbb{R}^n$. Clearly, that means we are defining this
definiteness with respect to $x^T (\cdot) x$ and NOT $M$ itself. Furthermore, when matrix have complex eigenvalues, then we ditch the
notion of definiteness property all together. Clearly, definiteness
is a flimsy property for matrices if we can just throw it away when it becomes inconvenient. I will grant you that if we were to define positive definite matrices, we should only define with respect to symmetric matrices. This is the definition on Wikipedia, the definition used by numerous linear algebra books and many applied math books. But then when confronted with a matrix of the form $$\begin{bmatrix} 1 & -1 \\ 0  & 1 \end{bmatrix}$$ I still firmly believe that this matrix is not positive definite because it is not symmetric. Because to me positive definiteness implies symmetry. To what degree is it widely agreed upon in the math community that a positive definite matrix is defined strictly with respect to symmetric matrices and why only with respect to symmetric matrices?","['matrices', 'vector-spaces', 'positive-definite', 'linear-algebra', 'definition']"
1555045,Show that rank of skew-symetric is even number,$$A = -A^T$$ I assume that $A$ is not singular. So $$\det{A} \neq 0$$ Then $$ \det(A) = \det(-A^T) = \det(-I_{n} A^T) = (-1)^n\det(A^T) = (-1)^n\det(A)$$ So I get that $n$ must be even. But what about odd $n$ ? I know it has to be singular matrix. Hints?,"['matrices', 'matrix-rank']"
1555068,Simplify the expression $(a+1)(a^2+1)(a^4+1)\cdots(a^{32}+1)$,How do I simplify this expression? $$\left( a+1 \right) \left( a^{2}+1 \right) \left( a^{4}+1 \right) \left( a^{8}+1 \right) \left( a^{16}+1 \right) \left( a^{32}+1 \right)$$,"['algebra-precalculus', 'exponentiation']"
1555071,Rotation of a regular tetrahedron,"The tetrahedron can be written with its apex at the north pole of a sphere
with the four vertices:
\begin{eqnarray}
a(0,0,\sqrt{6}/4) \; , \;  a(\sqrt{3}/3, 0, -\sqrt{6}/12) 
\; , \; a(-\sqrt{3}/6, 1/2, -\sqrt{6}/12) \; , \;
a(-\sqrt{3}/6, -1/2, -\sqrt{6}/12)
\end{eqnarray}
where $a$ is the side of length of the  tetrahedron.
This can be shown using Pythagoras theorem but the reader can verify these equations in the wolfram website It is also known that the tetrahedron can be found by using the alternating cube. That is choosing every other vertex (that is no two-consecutive vertices) of a cube. In this case the vertices are simple: \begin{eqnarray}
 (1,1,1) \; , \; (1,−1,−1)  \; , \; (−1,1,−1) \; , \; (−1,−1,1)
\end{eqnarray} For this you can check the Wikipedia website. Up to a normalization factor (so that we can plot both tetrahedra in the same sphere of radius $R$) we should be able to map one into the other
with a simple (or two) rotations. We could set up a system of equations with unknowns such that three of the vertices on one tetrahedron are mapped into three of the vertices of another tetrahedron and find a rotation matrix, or after normalizing, find the 
director cosines (dot product of normal vectors between each pair of vectors,
where pair means one from one tetrahedron and another from the other). The question is: Is there a product of 1, 2 or even 3 elementary rotation matrices that will take me from one tetrahedron to the other?
By elementary rotation matrix I mean any of these three:
\begin{equation}
\left (
\begin{array}{ccc}
 1 & 0 & 0 \\
 0 & \cos \theta & - \sin \theta \\
0 &  \sin \theta & \cos \theta
\end{array}
\right )
\end{equation} \begin{equation}
\left (
\begin{array}{ccc}
\cos \alpha & -\sin \alpha & 0 \\
\sin \alpha & \cos \alpha & 0 \\
0 & 0 & 1
\end{array}
\right )
\end{equation} or \begin{equation}
\left (
\begin{array}{ccc}
\cos \gamma & 0 & -\sin \gamma \\
0 & 1 & 0  \\
\sin \gamma & 0 & \cos \gamma 
\end{array}
\right )
\end{equation} Thanks.","['platonic-solids', 'euclidean-geometry', 'linear-transformations', 'geometry', 'linear-algebra']"
1555108,Stabilizer Conjugation,"This may be a straightforward question, but if I have a group $G$ acting on a set $A$, and two elements $a,b\in A$ belong to the same orbit, how do I show that their stabilizers are conjugate. So far I know that  $a=gb$ for some $g\in G$. Do I just need to show that $g$ times some element of the stabilizer of $b$ is equal to a stabilizer of $a$?","['group-actions', 'group-theory']"
1555128,How can I explain my logic? - Related to Herfindahl index,"I've tried to measure something that I have in mind. My problem is as following: Let's assume that there is a group with 8 members. There are two cases:
First, A group consists of 4 subgroups each with 1,1,2, and 4 members.(1+1+2+4=8)
Second, A group consists of 4 subgroups each with 2 members (2+2+2+2=8) I want to calculate the relative size of a subgroup with 2 members.
If I calculated it as 2/8, it does not reflect the size of the other subgroups.
In the first case, a subgroup with 2 members is likely to be a minor subgroups because of a major subgroup with 4 members.
But in the latter case, a subgroup with 2 members is not either minor or major subgroup because other subgroups have 2 members. To reflect this concern, I try to adopt Herfindahl index.
First of all, divide the number of members of subgroups by total members(=8).
For example, in the group with 1,1,2,4 members, the value is 0.125, 0.125, 0.25, 0.5.
Then, I calculate the square value (0.0156,0.0156,0.0625,0.25). The sum of it is Herfindahl index as you know. The important things, here, is that I divide the square value by sum of square value. 
In the end, the 2-member subgroup in the group with 1,1,2,4 members have the value-0.181818.
Contrary to it, the 2-member subgroup in the group with 2,2,2,2 members have the value-0.25 I think it can adequately reflect my thought because the 2 member subgroup in the former case (=0.1818) has relatively smaller size than in the latter group (=0.25).
I can understand it intuitively but I cannot explain it logically. Maybe one reason might be I cannot find the reference.
Calculating Herfindahl index is common, but dividing the fraction by the index is unusual to me. Does anyone know the similar situation? Does it make sense?
If you know any reference or have any recommendation to my logic, please let me know. Thanks a lot!","['statistics', 'probability', 'calculus', 'probability-distributions']"
1555143,Independent random variables: Sum,"Suppose that for $n\in\mathbb{N}$, $(Y_1,\ldots ,Y_{n+1})$ is a finite collection of independent random variables, does that imply that $Y_{n+1}$ is independent of $Y_{1} +\cdots+Y_{n}$? And if so, how does one prove this RIGOROUSLY. Thanks in advance!","['probability-theory', 'random']"
1555158,How do I find a bounded linear functional under the assumptions of the following theorem?,"Theorem: Let $X$ be a normed space and $0 \not= x_0 \in X$ be a arbitrary. Then there exists a bounded linear functional $\bar f$ on $X$ such that $$\|\bar f \|=1, \quad \bar f(x_0) =\|x_0\|.$$ Problem: Find $\bar f$ when $X$ is the Euclidean plane $\mathbb{R}^2$. My interpretation of the task is that I have to explicitly specify a functional that satisfies the conditions and works for arbitrary non-zero points in the plane. I've been told however that such a functional need not be unique and may depend on each $x_0$. I'm confused now about how to go about solving this problem. I'd also appreciate if someone can comment on if the following solution to finding some $f \in X'$ such that $\|f\|=\|x_0\|^{-1}$ and $f(x)=1$ under the assumptions is correct? I've defined $f(x)=\frac{1}{\|x_0\|} \bar f(x).$ Then $f$ is a bounded linear functional on $X$ because of $\bar f$ of the theorem. $$f(x_0)=\frac{1}{\|x_0\|}\bar f(x_0)=\frac{1}{\|x_0\|} \|x_0\|=1.$$ and since $f(x)=\frac{1}{\|x_0\|} \bar f(x)$, $\|f\|=\frac{1}{\|x_0\|} \|\bar f\|$ (Does this equality require any further justification? Intuitively I can see it has to hold, but I'm unable to find a good reason for why and would like someone to explain this to me.) $=\frac{1}{\|x_0\|}$.",['functional-analysis']
1555195,"Show that $\lim_{\epsilon\to0^{+}}\frac{1}{2\pi i}\int_{\gamma_\epsilon}\frac{f(z)}{z-a} \, dz=f(a)$","Let $a\in\Bbb C$ and $r>0$ and denote by $B(a,r)\subseteq \Bbb C$ the open ball of center $a$ and radius $r$. Assume that $f:B(a,r)\to\Bbb C$ is a continuous function and for each $\epsilon>0$ let $\gamma_\epsilon:[0,2\pi]\to \Bbb C$ be given by $\gamma_\epsilon(t)=a+\epsilon e^{it}$. Show that 
  $$\lim_{\epsilon\to0^{+}}\frac{1}{2\pi i}\int_{\gamma_\epsilon}\frac{f(z)}{z-a} \, dz = f(a).$$ I tried the following
$$\lim_{\epsilon\to0^{+}}\frac{1}{2\pi i}\int_{\gamma_\epsilon}\frac{f(z)}{z-a}dz=\lim_{\epsilon\to0^{+}}\frac{1}{2\pi i}\int_0^{2\pi}\frac{f(a+\epsilon e^{it})}{a+\epsilon e^{it}-a}i\epsilon e^{it} \, dt = \lim_{\epsilon\to0^{+}} \frac{1}{2\pi} \int_0^{2\pi}f(a+\epsilon e^{it}) \, dt$$ If I can change the limit and the integral, then it is obvious. I tried to use the Lebesgue bounded convergence theorem to argue that, since $f:B(a,r)\to\Bbb C$ thus on $B(a,r)$ we have $|f(a+\epsilon e^{it})|\le M$, where M is the maximum of $|f(x)|$ on $B(a,r)$. Is that valid?","['complex-analysis', 'real-analysis']"
1555271,Does every finite digit-sequence appear in some factorial?,"Suppose, some finite digit-sequence is given. Can we prove or disprove, that there is always some number $n$, such that the digit-sequence appears in the decimal-expansion of the number $n!$ ? If there is no specific pattern in the decimal-expansions of the factorials, this should be the case, but I have no idea how we can check it.","['number-theory', 'decimal-expansion']"
1555297,How to show that $f(x) = \frac{\sqrt{\cos x}}{1-x^2}$ is convex and has a minimum value,"I want to show that  $f(x) = \frac{\sqrt{\cos x}}{1-x^2}$ is convex on the interval $]-1,1[$. How do I have to proceed? I did take the derivative of the function which is 
$f'(x) = \frac{2x\sqrt{\cos x }}{(1-x^2)^2}-\frac{\sin x}{2\sqrt{\cos x}(1-x^2)}$ For a function to be convex I need to show that it is increasing on the interval? I'm a little stuck to proof that rigorously. Thanks for your help!","['convex-analysis', 'functions']"
1555340,Prove congruence rule,"Say you have integers $a$ and $b$ If $a \equiv b \pmod 5$, we know that $a \pmod 5 = b \pmod 5$. Let $a \pmod 5 = c$ and $x,y$ be some whole numbers satisfying
$$a = 5x + c \quad \text{and} \quad b = 5y + c$$ Then, $a-b = 5x + c -(5y + c) = 5(x-y)$, so $5$ is a factor in $a-b$. Now my question is, if we start with only knowing that $5$ is a factor in $a-b$, how can we show that $a \pmod 5 = b \pmod 5$?","['proof-explanation', 'modular-arithmetic', 'discrete-mathematics']"
1555379,Why is this a senseful notion of stability? Whyt is the intuition behind this idea of stability?,"Let $\xi=x-ct$. Moreover, let $U(\xi)$ be a travelling wave solution of a PDE. Suppose that $U(\xi,t)$ is a solution of a PDE. The travelling wave $U(\xi)$ is called stable (with respect to the PDE) if there is a neighborhood $N$ of it, such that for a solution $U(\xi,t)$ whose initial value $U(\xi,0)$ is within $N$,  there exists some $k\in\mathbb{R}$ such that
$$
\lVert U(\xi,t)-U(\xi+k)\rVert\to 0~\text{ as }t\to+\infty.
$$ In other words, a travelling wave $U(\xi)$ is stable, if each solution whose initial values are sufficiently close to it (in some norm), converges to a translate travelling wave $U(\cdot +k)$ as $t\to +\infty$. I am wondering a bit why this reflects a stable behaviour of $U(\xi)$ since the translate travelling wave $U(\cdot +k)$ can be very far away from $U(\xi)$, or not? Maybe this is not possible because of the wave structure, that is, after some time there is the next ""maximum"" (when the wave is starting again) and so maybe the definition tells us that, indeed, this means that the solution will be close to $U(\xi)$ as $t\to\infty$ if it is close to some translate of it. Is this the reason why it is a stable behaviour? In other words: If I think of a typical wave form, then, when a solution starts near a wave and then, as $t\to\infty$, it is near some translate of the wave, this implies that it is somewhere between to ""maxima"" of the wave, so it is quite near to the original wave again? But what if two maxima of the wave are far away from each other? Then being close to some translate of the wave does not need to mean being near the original wave? Maybe my intuition is wrong.","['stability-theory', 'ordinary-differential-equations', 'partial-differential-equations']"
1555388,"If $C_G(x) \leq H$ for every $p$-element $x \in H$, then $p$ cannot divide both $|H|$ and $|G:H|$","This is problem 1.D.2 in Isaacs, Finite Group Theory . I am self-studying, so would appreciate a proof verification. Note: in this book, all groups are assumed finite unless otherwise stated. Fix a prime $p$, and suppose that a subgroup $H \leq G$ has the property that $C_G(x) \leq H$ for every element $x \in H$ having order $p$. Show that $p$ cannot divide both $|H|$ and $|G:H|$. My proof: Suppose that $p$ divides both $|H|$ and $|G:H|$. Let $P \in Syl_p(H)$. Since $p$ divides $|G:H|$, we see that $P$ cannot be in $Syl_p(G)$ (its order is too small), but it must be contained in some $Q \in Syl_p(G)$. Let $N = N_Q(P)$. Since $P < Q$ and $Q$ is a $p$-subgroup, we have $P < N \leq Q$ since ""normalizers grow"" in finite $p$-groups (because they are nilpotent). Let $N$ act on $P$ by conjugation. Suppose that $y \in P$ is a nonidentity element which is fixed by this action, i.e., $\{y\}$ is a one-point orbit. Then every element of $\langle y \rangle$ is also fixed, since, for example, $gy^2g^{-1} = (gyg^{-1})(gyg^{-1}) = y^2$. Since $\langle y \rangle$ is a $p$-subgroup, it contains some $x$ of order $p$. Since $x$ is fixed by the action, it is centralized by $N$. This means that $N \leq C_G(x)$. Since $C_G(x) \leq H$ by hypothesis, we have $P < N \leq H$. But this is impossible because $P \in Syl_p(H)$ and $N$ is a $p$-subgroup which properly contains $N$. We conclude that $1$ is the only fixed point in this action. Now by the orbit-stabilizer theorem, we have $|P| = 1 + \text{stuff divisible by }p$. Taking this equation modulo $p$, we obtain the contradiction $0 \equiv 1 \mod p$.","['finite-groups', 'sylow-theory', 'group-theory', 'proof-verification']"
1555449,Decomposing a surface $S$ with a simple closed curve $\Gamma$,"In class we learned about how the Euler characteristic changes when we take a connected sum of surfaces $M_1$ and $M_2$: $$\chi(M_1 \# M_2) = \chi(M_1) + \chi(M_2) - 2,$$ and it made me wonder how the Euler characteristic would change if we decomposed $S$ by cutting along a simple closed curve (a non-intersecting curve that ends where it begins). I have two questions: Suppose we have a surface $S$ with Euler characteristic $\chi(S)$ and a simple closed curve $\Gamma$ on $S$. If we decompose $S$ into two surfaces $S_1$ and $S_2$ by cutting along $\Gamma$, how do the Euler characteristics, $\chi(S_1), \chi(S_2)$ relate to $\chi(S)$? What if $\Gamma$ decomposes $S$ into one surface $S_0$ with Euler characteristic $\chi(S_0)$? How does $\chi(S_0)$ relate to $\chi(S)$?","['general-topology', 'surfaces']"
1555450,Sigma algebra - motivation in measure theory,"Taken from the Motivation section of sigma-algebra article: A measure on $X$ is a function that assigns a non-negative real number
  to subsets of $X$; this can be thought of as making precise a notion of
  ""size"" or ""volume"" for sets. We want the size of the union of disjoint
  sets to be the sum of their individual sizes, even for an infinite
  sequence of disjoint sets. One would like to assign a size to every subset of $X$, but in many
  natural settings, this is not possible. For example the axiom of
  choice implies that when the size under consideration is the ordinary
  notion of length for subsets of the real line, then there exist sets
  for which no size exists, for example, the Vitali sets. For this
  reason, one considers instead a smaller collection of privileged
  subsets of $X$. These subsets will be called the measurable sets. They
  are closed under operations that one would expect for measurable sets,
  that is, the complement of a measurable set is a measurable set and
  the countable union of measurable sets is a measurable set. Non-empty
  collections of sets with these properties are called $\sigma$-algebras. source Does it explain the need for sigma-algebra in mathematics or measure theory? I just don't see how this description explains the motivation for sigma-algebra. First, the article states that there are sets that are not Lebesgue-measurable, i.e. it's impossible to assign a Lebesgue measure to them (one satisfying the property that measure of a set is its length, which is very natural). Ok, fine. However, next it says: For this
  reason, one considers instead a smaller collection of privileged
  subsets of $X$. These subsets will be called the measurable sets. They
  are closed under operations that one would expect for measurable sets,
  that is, the complement of a measurable set is a measurable set and
  the countable union of measurable sets is a measurable set. What are the 'privileged subsets of X'? Borel sets for instance? Is it that because all Borel sets form the smallest sigma algebra (smallest meaning it has the least elements among all sigma algebras containing all Borel sets), and Borel sets have the nice property that they are made of open intervals, which means we can assign size to those sets that is equal to the length of that interval. That's obviously one of many possible measures we can use. AFAIK, I can have a sigma-algebra that contains Vitali set. Everything can be a sigma-algebra, as long as it satisfies its 3 simple axioms. So if there is something you could add to clarify the quoted explanation, I'd be very grateful. I've seen some amazing answers here om Math SE to related questions, like this one .","['measure-theory', 'elementary-set-theory']"
1555457,"Referral of a Textbook or Book that teaches Intuition, focusing on Calculus.","I was wondering if there is a book out there that doesn't teach you how to do calculus, but teaches you how to apply it in the physical or social sciences. I know calculus, integration and differentiation and the applications for each, but I struggle to find a book that teaches me how to use calculus to derive my own mathematical models. I think it will be easier to give an example: Imagine a spinning rod with uniform mass with length, $L$. To find the kinetic energy of the rod I know that each part of the rod moves at a different speed, and therefore the entire kinetic energy of the rod is the sum of all the infinitesimals of little sections on the rod. I am not going to solve this problem, because this isn't the question on hand, but the point is is that I am looking for a book that teaches you, and challenges you to use your already knowledge of calculus to solve problems like this? Hope I am making myself clear, and any input would greatly be appreciated.","['ordinary-differential-equations', 'education', 'calculus']"
1555468,Minimum of an Order Statistic with probability,"Let $X_1,\ldots,X_n$ constitute a random sample of size $n$ from a normal distribution with $\mu = 0$ and var= 2. Find the smallest value of n such that $P(\min(X^2_1,\ldots,X^2_n)\leq .002) \geq .8$ Essentially we want the smallest value of n that would make the min of an order statistic less than .002 with 80% certainty.","['statistics', 'probability', 'order-statistics']"
1555492,A set $A$ which satisfies $A\approx A\cup\left\{x\right\}$,"Let $A$ be a set such that $A\approx A\cup\left\{x\right\}$ for all $x$, ($\approx \leftrightarrow$ of the same cardinality). I need to prove that this set has a countable subset, not assuming the axiom of choice. I am actually clueless on how to do this, the connection seems very abstract for me, and would like a hint on this one.",['elementary-set-theory']
1555502,Prove that bounded $p$-norms and convergence a.e implies convergence in $L^1$,"Suppose $\mu\left(X\right) < \infty$, $f_n \rightarrow f$ a.e and $p > 1$ is such that for some constant $C>0$, we have 
$$
\|f_n\|_p \leq C,\ \ \text{for each} \ n
$$
Prove that $f_n \rightarrow f$ in $L^1$. My attempt: I am trying to prove that $f_n \rightarrow f$ in $L^p$. Then the result is obvious from Holder's inequality. I am unable to use the given condition that $p$-norms are bounded. I need to apply Dominated convergence theorem, but I'm unable to see it.",['measure-theory']
1555547,Prove the generating function for the Catalan number sequence is $f(x) = \frac{1 -\sqrt{1-4x}}{2x}$,"I know that generating function for the Catalan number sequence is $$f(x) = \frac{1 -\sqrt{1-4x}}{2x}$$ but I want to prove it. The sequence for the Catalan numbers is $$1,1,2,5,14, \dots$$ as we all know. Now I have to find a generating function that generates this sequence. I read that we can prove it this way: Assume that $f(x)$ is the generating function for the Catalan sequence then by the Cauchy product rule it can be shown that $xf(x)^2 = f(x) − 1$ . And so this implies that $$xf(x)^2 - f(x) + 1 = 0$$ and so we can get that $$f(x) = \frac{1-\sqrt{1-4x}}{2x}$$ But I don't understand how this is possible. How to apply the Cauchy product rule to obtain $xf(x)^2 = f(x) − 1$ ? I know that if we multiply the sequence $$1,1,2,5,14, \dots$$ by itself we would get in the resulting sequence $$1,1,5,14,...$$ Because we have that $c_k = a_0b_k + a_1b_{k-1}+ ........ + a_kb_0$ using the cauchy product formula. But still, how do we have that $xf(x)^2 = f(x) − 1$ and how did we get that $$f(x) = \frac{1-\sqrt{1-4x}}{2x}$$ from $xf(x)^2 = f(x) − 1$ ? Did we use the quadratic formula somehow?","['generating-functions', 'combinatorics', 'catalan-numbers', 'discrete-mathematics']"
1555605,Can anyone help me understand Lagrange Multipliers?,"I'm currently trying to understand the method of Lagrange Multipliers. The explanation I'm currently looking at says something along the lines of ""Suppose we wish to minimise the function $f(x,y)$ subject to the constraint $g(x,y)=0$, and that this minimum is the point $(x_{0}, y_{0})$. Then $\nabla f(x_{0}, y_{0})$ is the normal to the function $f$ at this point. Furthermore, the normal vectors of $f$ and $g$ are are parallel.
Thus, $\nabla f(x_{0}, y_{0})=\lambda \nabla g(x_{0}, y_{0})$."" (Source: http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html ) I really don't understand why the normal vectors of $f$ and $g$ are are parallel, or how this gives rise to the equation $\nabla f(x_{0}, y_{0})=\lambda \nabla g(x_{0}, y_{0})$. Could someone please explain this to me? Many thanks.","['multivariable-calculus', 'lagrange-multiplier', 'optimization', 'calculus']"
1555636,When is a quasiprojective variety Kobayashi hyperbolic?,"I am looking for some (simple and well-known) sufficient conditions on a quasiprojective variety to be Kobayashi hyperbolic. I realize that in this generality it may be a complicated (maybe even hopelessly naive) question, so less generality is perfectly OK. A bit more specifically, I have read in some paper a comment like ""this is the complement in a (complex) projective space of a certain number of hyperplanes, so it is Kobayashi hyperbolic"". Why is that? What is the statement that seems to be so classical that the author did not include it?","['reference-request', 'several-complex-variables', 'complex-geometry', 'algebraic-geometry']"
1555641,"Probability Density Function Equation, Multivariable Calculus","I have the following problem: The formula for the normal distribution has a π in it. In this simplified version of the normal probability density function, solve for C. The correct answer has π in it. $$
1 = C\int_{-\infty}^\infty\int_{-\infty}^\infty e^{-(x^2+y^2)}dydx
$$ Can anybody tell me how to solve this problem? Any help is appreciated!","['density-function', 'multivariable-calculus', 'improper-integrals', 'integration', 'probability']"
1555670,Infinite product equality $\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right) = \prod_{n=1}^{\infty} \frac1{1+x^{2n-1}+x^{4n-2}}$,"Prove the following equation ($|x|<1$)
$$\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right) = \prod_{n=1}^{\infty} \frac1{1+x^{2n-1}+x^{4n-2}}$$ I made this question and I have the following answer but I think it may be incomplete.
If anyone can point out a flaw in my proof or give a better proof then it would be appreciated. My solution: $$\begin{align}
&f(x)=\prod_{n=1}^{\infty} \left(1-x^n+x^{2n}\right)\\
&N(p,q)=\{n\in\mathbb N \mid n\ne (2m-1)2^{k-1};m,k\in\mathbb N,2m-1\leq p,k\leq q\}\\
&f(x)(1+x+x^2)=(1+x+x^2)(1-x+x^2)\prod_{n\in N(1,1)}^{\infty} \left(1-x^n+x^{2n}\right)\\
&=(1+x^2+x^4)\prod_{n\in N(1,1)}^{\infty} \left(1-x^n+x^{2n}\right)=(1+x^2+x^4)(1-x^2+x^4)\prod_{n\in N(1,2)}^{\infty} \left(1-x^n+x^{2n}\right)\\
&=(1+x^4+x^8)\prod_{n\in N(1,2)}^{\infty} \left(1-x^n+x^{2n}\right)=(1+x^4+x^8)(1-x^4+x^8)\prod_{n\in N(1,3)}^{\infty} \left(1-x^n+x^{2n}\right)\\
&=(1+x^8+x^{16})\prod_{n\in N(1,3)}^{\infty} \left(1-x^n+x^{2n}\right)=\cdots\\
&=\lim_{k\to\infty}(1+x^{2^k}+x^{2^{k+1}})\prod_{n\in N(1,k)}^{} \left(1-x^n+x^{2n}\right)=\prod_{n\in N(1,\infty)}^{} \left(1-x^n+x^{2n}\right)\\
&\text{Similarly,}\\
&f(x)(1+x+x^2)(1+x^3+x^6)=\prod_{n\in N(3,\infty)}^{} \left(1-x^n+x^{2n}\right)\\
&f(x)(1+x+x^2)(1+x^3+x^6)(1+x^5+x^{10})=\prod_{n\in N(5,\infty)}^{} \left(1-x^n+x^{2n}\right)\\
&\cdots\\
&f(x)\prod_{m=1}^{\infty} \left(1+x^{2m-1}+x^{2(2m-1)}\right)=\lim_{p\to\infty} \prod_{n\in N(p,\infty)}^{} \left(1-x^n+x^{2n}\right)=1
\end{align}$$ (*) Is it obvious that $\{(2m-1)\cdot2^{k-1}\mid m,k\in \mathbb N\}$ is equivalent to $\mathbb N$, or should I also prove it? Thanks.","['infinite-product', 'sequences-and-series', 'calculus']"
1555671,Integral of $\frac{1}{x^2+4}$ Different approach,"underneath is a brief method of partial fractions integration on the problem given in the title Using a standard trigonometric result it is known that:
$$ \int \frac{1}{x^2+4}dx=\frac{1}{2}\tan^{-1}(\frac{x}{2})+C$$
But also:
$$\frac{1}{x^2+4}=\frac{A}{x+2i}+\frac{B}{x-2i}$$
Hence using partial fractions,
$$1=A(x-2i)+B(x+2i)$$
Let $x=2i$ 
$$\therefore 1=4Bi$$
$$\text{Hence } B=\frac{-i}{4}$$
Let $x=-2i$ 
$$\therefore 1=-4Ai$$
$$\text{Hence } A=\frac{i}{4}$$
Hence,
$$\frac{1}{x^2+4}=\frac{i}{4(x+2i)}-\frac{i}{4(x-2i)}$$
Or,
$$\frac{1}{x^2+4}=\frac{i}{4}(\frac{1}{x+2i}-\frac{i}{x-2i})$$
Hence, it is quite easy to see that:
\begin{align*}
\int \frac{1}{x^2+4}dx &=\int \frac{i}{4}(\frac{1}{x+2i}-\frac{1}{x-2i}) dx\\
&=\frac{i}{4}\int \frac{1}{x+2i}-\frac{1}{x-2i} dx\\
&=\frac{i}{4}(\log(x+2i)-\log(x-2i))+C\\
\end{align*}
We know that the principal value of log of a complex number can be calculated by the following formula:
$$\log(x+yi)=\log(x^2+y^2)+arg(x+yi)$$
Hence,
\begin{align*}
\int \frac{1}{x^2+4}dx &=\frac{i}{4}(\log(x+2i)-\log(x-2i))+C\\
&=\frac{i}{4}(\log(x^2+4)+\arg(x+2i)-\log(x^2+4)-\arg(x-2i)+C\\
&=\frac{i}{4}(\arg(x+2i)-\arg(x-2i))+C\\
\end{align*}
Now, consider cases. If x is bigger than 0, the argument of a complex number is always defined as $\arg(x+yi)=\tan^{-1}(\frac{y}{x})$
So our integral becomes
$$\int \frac{1}{x^2+4}dx=\frac{i}{4}(\tan^{-1}(\frac{2}{x})-\tan^{-1}(\frac{-2}{x}))+C$$
And since arctan is an odd function
\begin{align*}
\int \frac{1}{x^2+4}dx&=\frac{i}{4}(2\tan^{-1}(\frac{2}{x}))+C\\&=\frac{i}{2}\tan^{-1}(\frac{2}{x})+C\\
\end{align*}
Now, if $x$ is less than $0$ and $y$ is less than $0$ then argument of a complex number becomes $\tan^{-1}(\frac{y}{x})-\pi$ and if $x$ is less than $0$ and $y$ is more than $0$ the argument becomes $\tan^{-1}(\frac{y}{x})+\pi$ Also as in a previous case becasue arctan is an odd function, the integral becomes
\begin{align*}
\int \frac{1}{x^2+4}dx&=\frac{i}{4}(\tan^{-1}(\frac{2}{x})-\tan^{-1}(\frac{-2}{x})+2\pi)+C\\
&=\frac{i}{4}(2\tan^{-1}(\frac{2}{x})+2\pi)+C\\
&=\frac{i}{2}\tan^{-1}(\frac{2}{x})+D
\end{align*}
Hence
$$\int \frac{1}{x^2+4}dx=\frac{i}{2}(\tan^{-1}\frac{2}{x}), x\in\mathbb R\ \land x\neq0$$ Now, obviously, it is not the same, as the trig identity, it has a pole at x=0 while the original integral doesn't and most importantly it is not a real number. This was done by me purely for recreational purposes but now it frustrates me. Can it be done this way? Did I basically did a mistake or maybe I missed something crucial?. thanks in advance. EDIT After using the correct definition of principal value of log and nice property about arctan (both given to me by you guys) we know that $$\log(x+yi)=\frac{1}{2}\log(x^2+y^2)+i\arg(x+yi)$$
and hence
*** becomes 
$$\frac{i}{4}(i(\arg(x+2i)-\arg(x-2i)))$$
=$$\frac{-1}{4}((\arg(x+2i)-\arg(x-2i)))$$ So the answe becomes 
$$\int \frac{1}{x^2+4}dx=\frac{-1}{2}\tan^{-1}(\frac{2}{x})+D$$ And since $$\tan^{-1}(\frac{2}{x})=\frac{\pi}{2}-\tan^{-1}(\frac{x}{2})$$
the result is $$\int \frac{1}{x^2+4}dx=\frac{-1}{2}(\frac{\pi}{2}-\tan^{-1}(\frac{x}{2}))+D$$
OR$$\int \frac{1}{x^2+4}dx=\frac{1}{2}\tan^{-1}(\frac{x}{2})+E$$ as required Thanks :)","['complex-numbers', 'substitution', 'calculus', 'functions', 'integration']"
1555695,Fibonacci-Like Sequence: Breeding Rabbits,"I came across the following question on a math test: Suppose Fibonacci's research in the breeding habits of rabbits has been adjusted. They are now believed to be fertile after $2$ months of life, and they consistently give birth $6$ pairs of rabbits at the end of every month; the gestation period is still one month (it takes $1$ month for them to give birth after they are fertile). Also, these particular rabbits only live $6$ months. Find a recurrence relation for $s_n$ For this problem I first started to list the total number of rabbits after $n$ number of months: $$s_0 = 1$$
$$s_1 = 1$$
$$s_2 = 1$$
$$s_3 = 1 + 6 = 7$$
$$s_4 = 7 + 6 = 13$$
$$s_5 = 19$$
$$s_6 = 61$$
$$s_7 = 133$$
$$\vdots$$ After using this recurrence pattern, I got the following sequence: $$s_n = s_{n-1} + 6s_{n-3} - 6s_{n-7}$$ However, my teacher told me the answer was incorrect. I have no idea where my math went wrong. Any help would be appreciated.","['recurrence-relations', 'pattern-recognition', 'discrete-mathematics']"
1555710,Setting up a recurrence relation of ternary strings of length n that does not have three consecutive 1s,"Let $a_n$ denote "" the number of ternary strings of length n that do not contain three consecutive 1s"" Ternary string contains only 0, 1, 2 and has length n. The way I approached it was to make a tree of length n: Besides from my obvious lack of artistic skills, I find it very hard to believe that the recurrence relation is $  a_n = 26(a_{n-3}) $ . If anybody could tell me what I did wrong and help me out, that would be greatly appreciated. Note: I realized that there are some possible duplicates on the site, which I have went through and either 1) do not apply to three consecutive (insert digit here)s or 2) I don't fully understand.","['recurrence-relations', 'discrete-mathematics']"
1555743,How do you solve 5th degree polynomials?,"I looked on Wikipedia for a formula for roots of a 5th degree polynomial, but it said that by Abel's theorem it isn't possible. The Abel's theorem states that you can't solve specific polynomials of the 5th degree using basic operations and root extractions. Can you find the roots of a specific quintic with only real irrational roots (e.g. $f(x)=x^5+x+2$ ) using other methods (such as logarithms, trigonometry, or convergent sums of infinite series, etc.)? Basically, how can the exact values of the roots of such functions be expressed other than a radical (since we know that for some functions it is not a radical)? If no, is numerical solving/graphing the only way to solve such polynomials? Edit: I found a link here that explains all the ways that the above mentioned functions could be solved.","['radicals', 'roots', 'polynomials', 'functions']"
1555753,Two term free resolution of an abelian group.,"This is probably a very easy question but I think I am missing some background regarding free abelian groups to answer it for myself. In Hatcher's Algebraic Topology , the idea of a free resolution is introduced in the section on cohomology. A $\textbf{free resolution}$ of an abelian group is an exact sequence $$ \cdots \to F_2 \to F_1 \to F_0 \to H \to 0$$ such that each $F_i$ is free. Let $f_0:F_0 \to H$ and choose a set of generators of $H$ . Let $F_0$ be the free abelian group with basis in one-to-one correspondence with this set of generators. Then we can easily form the two term free resolution $$\cdots \to 0 \to Ker(f_0) \to F_0 \to H \to 0$$ Why is $H$ an abelian group a necessary condition so that there necessarily exists resolution of the form $0 \to F_1 \to F_0 \to H \to 0$ ? For what non-abelian group does such a free resolution not exist?","['abelian-groups', 'homological-algebra', 'free-groups', 'algebraic-topology', 'group-theory']"
1555764,Smooth cubic surface in $\mathbb{CP}^4$ is covered by lines,"How to prove that smooth cubic surface $X$ in $\mathbb{CP}^4$ is covered by lines and the normal bundle of the generic line $l$ is $N_{l/X}=\mathcal{O}_{\mathbb{P}^1}\oplus\mathcal{O}_{\mathbb{P}^1}$? $\textbf{Edit}$ Let me give some explanations. Basically, this question should follow from Proposition 2.13 on page 48 in Debarre's book ""Higher-Dimensional Algebraic Geometry"", which states that if $X$ is a subvariety in $\mathbb{P}^N$ defined by equations of degrees $d_1$,...,$d_k$ and $d:=d_1+...+d_k\leq N-1$ then through any point of $X$, there is a line contained in $X$. Moreover, if the equations defining $X$ are general and $l$ is a general line contained in $X$ then 
$$N_{l/X}=\mathcal{O}_l(1)^{N-1-d}\oplus\mathcal{O}_l^{d-k}.$$ But is it true that a smooth cubic surface in $\mathbb{CP}^4$ is a complete intersection? If it is not, is there a possibility to apply this result from Debarre's book? $\textbf{Edit 2}$ It seems, however, that I can not apply this result from Debarre's book. If my cubic surface is given by two homogeneous equations, the first one of degree 1 and the second one of degree 3, then $d=4$ and the conditions of the Proposition are not satisfied. Could anyone suggest me how to think about this problem?",['algebraic-geometry']
1555798,""" only prime number that can only be divided by itself and one"" logic","How do I write ""only prime number that can only be divided by itself and one"" and I can only use these predicates : H(x, y) is x/y=integer(x mod y=0), S(x, y) is x=y, and P(x) is x is prime number?
My guess is : ∀x∀y(~S(x, 1)^(~S(x, y)^~S(y,1)→~H(x, y))→P(x))
But I can't check if it's true or false",['discrete-mathematics']
1555833,"Uniqueness of elements in Klein Four and ""Klein Five"" group","I had a question about the uniqueness of group elements. Let the Klein Four group be defined as the group generated by the elements ${1,a,b,c}$ such that $a^2=b^2=c^2=1$ and $ab=c$, $bc=a$, $ca=b$, and $1$ is the identity element. Let the ""Klein Five"" group be defined as the group generated by the elements ${1,a,b,c,d}$ such that $a^2=b^2=c^2=d^2=1$ and $ab=c$, $bc=d$, $cd=a$, $da=b$, and $1$ is the identity element. If I manipulate the symbols of the ""Klein Five"" group I defined above, I can show every element is equivalent to the identity. From $ab=c=ad$ I can see $a$ is the identity, from $bc=d=ba$ I can see $b$ is the identity, and so on. This gives that $a=b=c=d=1$. In some sense, this group doesn't seem to exist. I can't make a group such that $a \neq b \neq c \neq d \neq 1$ with the constraints above. How do I know that the same isn't true of the Klein Four group? How do I know there isn't some set of constraints that makes the group ""non-existent"" for unique elements in the same way as the ""Klein Five"" group? Any help would be appreciated!","['abstract-algebra', 'group-theory']"
1555836,"Let $A\subset R^{n}$ . Then $A$ is disconnected iff there exists a continuous and surjective functon $f:A\to${0,1}","Let $A\subset R^{n}$ . Then $A$ is disconnected iff there exists a continuous and surjective function $f:A\to${0,1} How can I prove this?
To prove $\rightarrow$, I know that if $A$ is disconnected, then there are two open, non empty and disjoint sets $U,V\subset R^n$ such that $A=U\cup V$ , $A\cap U \ne \emptyset $, $A\cap V \ne \emptyset$ and $A \cap U \cap V=\emptyset$ . Then we define a function $f(x)=\begin{cases} 0, & x \in U \\ 1, & x \in V\\
\end{cases}$ We can see that this function is surjective because both sets are non empty and there is not an $x$ such that $f(x)=0$  and  $f(x)=1$ (the sets are disjoint). Is this correct? Then I don't know how to prove the continuity of $f$, I've tried using the fact that $f$ is continuous iff the inverse image of an open(closed) set is open(closed) in $A$, but I still struggle using the concepts of relative open and closed sets(my professor didn't explain them very well) so I don't know how to finish the proof. Any help will be apprecciated, thanks.","['general-topology', 'real-analysis', 'metric-spaces', 'calculus']"
1555847,Differentiability of an homogeneous and continuous function $f$ ($f(\alpha x)=\alpha^\beta f(x)$),"Suppose $f$ is continuous on $\mathbb{R}$. Let $\beta$ be a positive real number, and assume that for every real number $x$ and $\alpha$>0 $f(x\alpha)=\alpha^\beta f(x)$ 1) if $\beta >1$ show that $f$ is differentiable at $0$ 2) if $0<\beta<1$ show that $f$ is not differentiable at $0$ Here's where I am. let $x=0$ Then $f(0)=\alpha^\beta f(0)$ Hence either $f(0)=0 $ or $\alpha^\beta=1$ $\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}=\frac{f(h)}{h}$ Then, I don't know how to continue..
Any Hint?","['derivatives', 'functions', 'proof-verification']"
1555855,Prove that the boy cannot escape the teacher,"I'm struggling with the following problem from Terence Tao's ""Solving Mathematical Problems"": Suppose the teacher can run six times as fast as the
  boy can swim. Now show that the boy cannot escape. (Hint: Draw an
  imaginary square of sidelength 1/6 unit centred at $O$. Once the boy leaves
  that square, the teacher gains the upper hand.) Here $O$ is the center of the swimming pool. This question is a follow up on the previous one, which is solved in the affirmative in the text (Taylor 1989, p. 34, Q2). In the centre of a square swimming
  pool is a boy, while his teacher (who cannot swim) is at one corner
  of the pool. The teacher can run three times faster than the boy can swim,
  but the boy can run faster than the teacher can. Can the boy escape from
  the teacher? (Assume both persons are infinitely manoeuvrable.) My attempt: Since the boy can always swim back into the small square of sidelength 1/6 centered at $O$, I can't see how to apply the hint properly. Also, since the student's path need not even be smooth (it was taken as a polygonal chain in the previous question) I'm having difficulties writing data down clearly. Any help would be appreciated. Thanks.","['analytic-geometry', 'curves', 'geometry']"
1555907,Show that $\hat x$ is a least squares solution of the system $Ax=b$,"Show that if $$\begin{bmatrix}A & I \\ O & A^T\end{bmatrix} \begin{bmatrix}\hat x \\ r\end{bmatrix} = \begin{bmatrix}b \\ 0\end{bmatrix}$$ then $\hat x$ is a least squares solution of the system $Ax = b$ and $r$ is the residual vector. The wording of the problem is confusing to me, because I can usually find the least squares solution by finding the solution of $\hat x$ to $A^TA\hat x = A^Tb$. Except, this wants me to prove the least squares solution is $\hat x$, which doesn't make much sense to me.","['matrices', 'transpose', 'least-squares', 'linear-algebra']"
1555934,Probability distribution on finite group,"I'm preparing for finals and this is a practice question. I'm not really sure how to start, so any solutions/hints/starting points are appreciated. Suppose $P = \sum a_gg$ were a probability distribution on a finite group $G$. If $a_1 > 0$, then $\lim_{k\rightarrow \infty} P^k$ exists and is equal to ${1\over|H|}\sum_{h\in H}a_hh$, where $H$ is the subgroup of $G$ generated by elements with $a_g > 0$.","['finite-groups', 'abstract-algebra', 'probability-theory', 'representation-theory', 'group-theory']"
1555954,$\alpha (1+\alpha/2)^{-1} < \log(1+\alpha) $ for $\alpha > 0$,How does one prove that $\alpha (1+\alpha/2)^{-1} < \log(1+\alpha) $ for $\alpha > 0$?,"['algebra-precalculus', 'inequality']"
