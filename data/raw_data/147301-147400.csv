question_id,title,body,tags
2418032,Cycle Property over Matroids,"The cycle property on graphs states, that For any cycle $C$ in a graph, if the weight of an edge $e$ of $C$ is
  larger than the individual weights of all other edges of $C$, then this
  edge cannot belong to a minimum spanning tree. Now I'm interested in generalizing this statement to matroids, but I cannot find a way of proving or disproving it. Does the following hold? For any cycle $C$ in a matroid, if the weight of an element $e\in C$ is larger
  than the individual weights of all other elements in $C$, then $e$ cannot
  belong to a minimal basis of the matroid.","['graph-theory', 'matroids', 'discrete-mathematics']"
2418040,"How many cheaters in a gaming community would be required to ""ruin"" the game?","Recently I was playing an online game. I was frequently beaten by someone who was performing suspiciously well. I told a friend why I didn't really like playing this game, and his response was ""It happens, but I think that only 2% of these players cheat. That's not much right?"" So I got to thinking; ""If only X percent of a community reliably use hacks, what is my probability on a per-game basis of encountering such a cheater on either team?"" Lets say we have a pool of 100 players, and match sizes are 10 people. Answers are rounded at the hundredths place. In each instance, I calculate the number of ways I can choose 10 people 
    from the fair players and divide it by the total number of ways I could 
    have selected my players.

If 1 of them is a cheater, representing 1%
C(99,10) / C(100,10) = 0.9
90% Chance of a fair game, 10% chance the game contains a cheater

If 2 of them are cheaters
C(98,10) / C(100, 10) = 0.81
81% chance of a fair game, 19% chance the game contains a cheater

And if 3 of them are cheaters
C(97,10) / C(100,10) = 0.73
73% chance of a fair game, 27% chance the game contains a cheater Is this math correct? Are percentages this small really all that's required to reliably encounter cheaters in an online game? Note: I know ""ruin"" is subjective. Given the competitive nature of online games nowadays, lets say that one could consider their game experience ""ruined"" if they encounter a hacker on either team in > 10% of matches played.",['discrete-mathematics']
2418096,Is it possible to determine if you were on a Möbius strip?,"I understand that if you were to walk on the surface of a Möbius strip you would have the same perspective as if you walked on the outer surface of a cylinder. However, would it be possible for someone to determine whether they were on a Möbius strip or cylinder.","['general-topology', 'mobius-band']"
2418161,To show that $\sum_{a=1}^{p-2}(a(a+1)/p)=-1$,"Let $p$ be an odd prime and for any integer $a$ , relatively prime to $p$ , let $(a/p)$ denote the Legendre symbol . Then how to show that $\sum_{a=1}^{p-2}(a(a+1)/p)=-1$ ? I know that $\sum_{a=1}^{p-1}(a/p)=0$ , so it is enough to show that modulo $p$ , the integers $a(a+1) ; a=1,...,p-2$ runs through a complete set of non-zero residues modulo $p$ except exactly one quadratic residue mod $p$ . But I am unable to show this . Please help . Thanks in advance","['number-theory', 'legendre-symbol', 'quadratic-residues']"
2418207,"What is the general solution to equations of form $f(k\cdot x)-lf(x)=1, k,l \in \Bbb N$ ? Prove that $\log_{10} x$ is the solution when $k = 10,l =1$.","I have a function $f:\mathbb{R}^{>0}\rightarrow \mathbb{R}$ that satisfies the following equation:
$$f(10\cdot x)-f(x)=1 \quad\quad (1)$$ From looking at this equation I can easily see that $f(x)=\log_{10}(x)$ works out nicely. However, if the equation would have been 
$$f(10\cdot x)-5f(x)=1 \quad\quad (2)$$
then the logarithm would not have worked out. Two questions: How can I prove that the logarithm is the only solution to equation (1)? Is there a general way to solve these kind of equations, for example, how would one solve equation (2)?","['logarithms', 'functions']"
2418217,Regarding the nilpotency class of finite p-groups,"I'm aware that for a $p$ -group $G$ of order $p^{n}$ , say, that $G$ must have a nilpotency class between 1 and $n - 1$ for $n\geq 2$ . My question is why can $G$ not have nilpotency class $n$ ? Take for example a group of order $p^{3}$ . Why is it not possible to make a lower central series with orders $p^{3} \rightarrow p^{2} \rightarrow p \rightarrow 1$ ? I know all the 5 possible groups in this case have nilpotency class 1 or 2. But since there's theoretically 'room' for there to be a chain of length 4, how do we know this is never the case in general?","['abstract-algebra', 'p-groups', 'group-theory']"
2418256,Property of skew-symmetric matrices of vectors multiplied by rotation matrices,"Let $v \in \mathbb{R}^3$ and $R$ be a rotation matrix (probably orthogonal is enough). I think the following property is true: $$ [R\cdot v] = R \cdot [v] \cdot R^T$$ where $[v]$ is the skew symmetric form of the vector $v$. I should verify this by direct calculation, but I am not in the mood right now, hence I want to know if the following proof is true: proof: let $u \in \mathbb{R}^3$ hence $$ [R\cdot v] \cdot \left( R \cdot u\right) = \left(R\cdot v\right) \times \left( R\cdot u\right) = R \cdot \left( v\times u\right) = R \cdot [v] \cdot R^T \cdot \left( R \cdot u\right)$$ therefore 
$$ [R\cdot v] \cdot \left( R \cdot u\right) = R \cdot [v] \cdot R^T \cdot \left( R \cdot u\right) $$ hence $\left([R\cdot v] - R \cdot [v] \cdot R^T \right) \cdot w = 0$ for all $w = R \cdot u$ with $u \in \mathbb{R}^3$. It follows that $\left([R\cdot v] - R \cdot [v] \cdot R^T \right) = O_{3 \times 3}$ Edit: Suppose $v = \begin{bmatrix} a\\b\\c\end{bmatrix}$ then $[v] = \begin{bmatrix}0 &-c &b\\ c &0 &-a\\ -b &a &0 \end{bmatrix}$","['matrices', 'linear-algebra']"
2418259,Either $f$ is a polynomial or $|f(z_j)| > e^{n|z_j|}. $,"Me and a friend of mine didn't manage to solve the following problem. Let $f: \mathbb{C} \to \mathbb{C}$ be an intere holomorphic function having a finite number of zeroes. Then either $f$ is a polynomial or there is a succession $\{z_j\}$ such that $z_j \to \infty$ and there exist $r$ such that eventually $$|f(z_j)| > e^{r|z_j|}. $$ Attempts Let's call $h = \frac{f}{g}$, where $g$ is the polynomial that vanishes on zeroes of $f$ with the same multiplicity of $f$. We tried to look at $\frac{h'}{h}$, the logarithmic derivative of $h$ , but without good ideas. One can observe that $h$, when it's not constant, must have an essential singularity at infty.","['complex-analysis', 'holomorphic-functions']"
2418286,Can $Ax = b$ have infinitely many solutions for every $b$ in $ℝ^m$?,"I've been learning about linear independence/dependence and this question was asked: Suppose an m × n matrix A has n pivot columns. Explain why for each b in $ℝ^m$ the equation Ax=b has at most one solution? Hint: Explain why Ax=b cannot have infinitely many solutions. For reference: Let A be an m × n matrix.  Then the following statements are logically equivalent: For each b in $\Bbb R^m$, the equation Ax = b has a solution. Each b in $\Bbb R^m$ is a linear combination of the columns of A . The columns of A span $\Bbb R^m$. A has a pivot position in every row. I understand that each b in $ℝ^m$ has one solution, because, in the question, every column is a pivot column.  Therefore, there are no free variables, and Ax = b cannot have infinitely many solutions.  However, all this led to my question: Is there a circumstance where Ax = b has infinitely many solutions for every b in $ℝ^m$ , or, if there's a solution for every b in $ℝ^m$ , is it always unique (only one)? Edit: Would this matrix A have infinitely many solutions for every b ?
\begin{array}{l}1&0&0&*\\0&1&0&*\\0&0&1&*\end{array} Asterisk = any number. If you added vector b to the right hand side of this matrix A , to make it an augmented matrix, there would still be a pivot position in every row, but there would also be a free variable $x_4$.  Would this be a circumstance where Ax = b has infinitely many solutions for every b in $ℝ^m$ ?","['matrices', 'matrix-equations', 'linear-algebra']"
2418323,How many functions have an n-bit input and m-bit output?,"How many functions have an n-bit input and m-bit output? The first question was how many functions have an n-bit input and a 1 bit (yes/no) output. I thought the answer was $2^{2^n}$, because there were $2^n$ possible inputs, and for each input half the functions would print $1$ on it and half the functions would print $0$. So the answer to the second question was maybe  $(2^{2^n})^m=2^{{2^n}m}$ because it was constructed of m 1-bit functions. Is this correct? Thanks.","['combinatorics', 'functions']"
2418389,Homomorphism between $\mathbb C^*$ and $S_n$,"I want to know that if there is any nontrivial homomorphism between $\mathbb C^*$ , the group of all non zero complex numbers and $S_n$ , the group of all permutations on the set   $\{1,2, \dots , n\}$   $(n \ge 2) $ or  $A_n$ , the set of all even permutations on the same set. Any insight . Thank you.","['abstract-algebra', 'group-theory', 'group-homomorphism']"
2418392,$X$ is normal if and only if $A\subseteq U$ implies there exists $V$ such that $A\subseteq V\subseteq\overline{V}\subseteq U$,"I want to prove this: $X$ is normal if and only if for every closed $A$ and open $U$ such that $A\subseteq U$, there exists $V$ such that $A\subseteq V\subseteq\overline{V}\subseteq U$. Suppose $X$ is normal. Let $A\subseteq U$ where $A$ is closed and $U$ is open. Then $X\setminus U$ is closed and $(X\setminus U)\cap A=\emptyset$. But since $X$ is normal, there exist open sets $V$ and $V'$ such that $A\subseteq V$, $X\setminus U\subseteq V'$, and $V\cap V'=\emptyset$. Clearly $V\subseteq \overline{V}$, and also $V\subseteq U$ because $V\cap V'=\emptyset$. But how does that guarantee the closure of $V$ is also contained in $U$? Conversely, suppose for each $A\subseteq U$ with $A$ closed and $U$ open, there exists an open set $V$ such that $A\subseteq V\subseteq\overline{V}\subseteq U$. Let $C_1, C_2$ be closed and $C_1\cap C_2=\emptyset$. Then $X\setminus C_2$ is open and $C_1\subseteq X\setminus C_2$. By assumption, there exists an open $V$ such that $C_1\subseteq V\subseteq\overline{V}\subseteq U$, hence $V\cap C_2=\emptyset$. Similarly there exists open $V'$ such that $C_2\subseteq V'\subseteq\overline{V'}\subseteq U$ with $V'\cap C_1=\emptyset$. But how do we get that $V\cap V'=\emptyset$?","['general-topology', 'separation-axioms']"
2418396,"Finding domain, codomain and range of $h(x)= \cos\big(\pi\frac{7x}{6}\big)$","I mainly need help with deciding the range of this function, I don't really understand it when I read my book. The only thing I know which I think I should use is that the value of a cos function is between -1 and 1. $f: \mathbb{Q} \to \mathbb{R}$,  $ f(x)$= cos(π$x$) $g: \mathbb{Z} \to \mathbb{Q}$,  $ g(x)= \frac{7x}{6}$ $h(x) = f(g(x)) $ $h(x) $ = cos$( π \frac{7x}{6} )   $ $h: \mathbb{Z} \to \mathbb{R}$ The domain for $h$ is $\mathbb{Z}$, and the codomain for $h$ is $\mathbb{R}$, is this correct$?$ But how do I find the range for $h?$ And also, is $h$ a surjective or injective function$?$ Many thanks in advance!","['trigonometry', 'functions']"
2418401,Upper bound for $\sum\limits_{i=2}^{N}{{{x}_{i}}({{x}_{i-1}}+{{x}_{i}})}$,"Let $x_1, ..., x_N$ be $N$ arbitrary positive integers, and their sum is a constant number $C$, that is, $x_1+x_2+...+x_N=C$. Is it possible to find an upper bound for the following sum in term of $C$ (the tighter the better): $\sum\limits_{i=2}^{N}{{{x}_{i}}({{x}_{i-1}}+{{x}_{i}})}$","['real-analysis', 'inequality', 'sequences-and-series', 'functions']"
2418402,Tensor product of two quotient modules,"I have a question from ""Exercise 1.3, Chapter 1, Qing Liu, Algebraic Geometry and Arithmetic Curves "": Let $A$ be a commutative ring with unit. Let $M,N$ be two $A-$modules,
  and $i:M' \to M, j:N' \to N$ submodules of $M$ and $N$, respectively.
  Then there exists a canonical isomorphism  $$\left( M/M' \right)
 \otimes_A \left( N/N' \right) \simeq \left( M \otimes_A N
 \right)/\left( \text{Im } i_N + \text{Im } j_M\right).$$ Notation : Let $f:N' \to N$ be a linear map of $A-$modules. For any $A-$module $M$, we denote the linear map $f \otimes_A \text{Id}_M : N' \otimes_A M \to N \otimes_A M$ by $f_M$. My attempt : Using the result Let $A$ be a commutative ring with unit. Let $M,N$ be two $A-$modules,
  and $i:M' \to M$ submodules of $M$.
  Then there exists a canonical isomorphism $$\left( M \otimes_A N \right)/\left( \text{Im } i_N \right) \simeq \left( M/M' \right)\otimes_A N,$$ we obtain that
\begin{align*}
\left( M/M' \right) \otimes_A \left( N/N' \right) &\simeq \left(N\otimes_A \left(M/M'\right)\right)/\left(\text{Im } j_{M/M'}\right)\\
&\simeq \left(\left(N\otimes_A M\right)/\text{Im } i_N\right)/\left(\text{Im } j_{M/M'}\right).
\end{align*}
However, I have a trouble when I try to prove 
$$\left(\left(N\otimes_A M\right)/\text{Im } i_N\right)/\left(\text{Im } j_{M/M'}\right) \simeq \left( M \otimes_A N
 \right)/\left( \text{Im } i_N + \text{Im } j_M\right).$$
Can you help me for this problem? Thank you very much.","['tensor-products', 'homological-algebra', 'algebraic-geometry', 'commutative-algebra']"
2418445,Infinite 'hex': is a win always achievable?,"In the game hex , at least one player always wins because they can form a chain of hexagons across the board. This led me to wonder, what happens if we generalise to infinitely many points? Specifically, if every point in a unit square (including boundaries) is coloured red or blue, does there necessarily exist a continuous function $f: [0,1] \to [0,1]\times [0,1]$ such that $f(x)$ is either a) Always red$\space\space$ and $f(0)=(0,a), f(1)=(1,b)$ for some a,b b) Always blue and $f(0)=(a,0), f(1)=(b,1)$ for some a,b Furthermore, if there exists a function such that (a) is true, then does that necessarily mean there does not exist a function such that (b) is true? (In the example, red wins with the path shown an blue loses) My intuition tells me that this is true, but I have no idea how to begin proving it. My best idea was to colour the regions to the left and right of the square red. Then anything connected to this red region is marked green. If the other side is connected to this then we are done. Otherwise, take the points along the boundary of this green region. They must be blue otherwise there exists a point closer to the region that is blue (by definition of the green region). Hence this boundary reaches all the way down to the bottom and we are done. But I'm not sure if this green region is well-defined or anything and have no idea how to show that it is. (Also, I've got no idea what tag(s) to put on this, sorry)","['game-theory', 'real-analysis']"
2418506,Lottery and win with less numbers - Hypergeometric Distribution,"I got a problem in showing this proof in paper.
One of my coworkers insists that using a sequential number in a Brazilian lottery increases the chances of winning the prizes with less odds I pretty certain it's not true but I can't come up with an adequate proof. Here we have a special lottery that works as the following. One must choose 15 numbers from 25. With this ticket, you'll be able to win the biggest prize (hitting the 15 numbers from 25) but you can also win the smaller prize with 14. This continues until 11, where you get the smallest. His theory is that betting with a sequential ticket from 1-15, 2-16 and 3-17 he'll have more chances to win instead of just picking 3 random sequences. The problem gets worse when others coworkers go gambling together. They insist that combining sequences like that in different tickets also increases their chances. I'm thinking about using Hypergeometric distribution with conditional probability but this is not working since they don't have this mathematical background. Thanks!","['statistics', 'hypergeometric-function', 'proof-explanation']"
2418524,5-color Theorem proof,"I have been studying planar graphs for a while now and found it useful for my learning to formulate a few proofs myself, based on the study material I worked through. This proof is about the 5-color Theorem. I was wondering if proof by induction or contradiction is better, but I decided for proof by induction, as this is easier to translate in actual code then. Have a look at my proof, any feedback appreciated: Lemma 1 : Every planar graph contains a vertex with $\operatorname{deg}(v) \leq 5$. Theorem : Every planar graph with $n$ vertices can be colored using at most 5 colors. Proof by induction, we induct on $n$, the number of vertices in a planar graph $G$. Base case, $P(n \leq 5)$: Since there exist $\leq 5$ nodes in $G$, the graph can be colored using 5 colors. Inductive step, $P(n+1)$: Assuming $P(n)$ is true, that is, every planar graph with $n$ vertices, we need to show $P(n)$ is true. By Lemma 1, we know every planar graph has one vertex with $\operatorname{deg}(v) \leq 5$. We call this vertex $v$ in our graph $G$. Remove $v$ and for the remaining subgraph $G'$ we can assume $P(n)$. If $\operatorname{deg}(v) \leq 4$, we can color all vertices adjacent to $v$ using 4 colors and use color 5 to color $v$ itself to reach a valid coloring. If $\operatorname{deg}(v) = 5$, we assume that all vertices adjacent to $v$ are colored in different colors. Assume there exists no path from $A$ to $C$. 
We can change the color of $A$ from red to blue, the color of $C$. Since no neighbor of $v$ now has the color red, we can color $v$ in red. We also need to change all vertices adjacent to $A$ from blue to red. Since no path exists from $A$ to $C$, the color of $C$ remains unchanged. Assume there exists a path from $A$ to $C$, alernating in color from red to blue. Note that this path bounds a planar embedding with $B$ on the inside and $D$ on the outside. 
We can change the color of $B$ from green to yellow, the color of $D$. Since no neighbor of $v$ now has the color green, we can color $v$ in green. We also need to change all vertices adjacent to $B$ from yellow to green. Since no path can exist from $B$ to $D$ (without crossing the path from $A$ to $C$), the color of $D$ remains unchanged.","['graph-theory', 'planar-graphs', 'proof-verification', 'coloring', 'discrete-mathematics']"
2418554,Why is log-of-sum-of-exponentials $f(x)=\log\left(\sum_{i=1}^n e^ {x_i}\right)$ a convex function for $x \in\mathbb R^n$?,"How to prove $f(x)=\log\left(\displaystyle\sum_{i=1}^n e^{x_i}\right)$ is a convex function? EDIT1: for above function $f(x)$ , following inequalities hold: $$\max\{x_1,x_2,\ldots,x_n\}\leqslant f(x)\leqslant\max\{x_1,x_2,\ldots,x_n\}+\log n$$ and I have tried proving its convexity via definition of a convex function with above inequalities, but that didn't work. EDIT2 : I have posted my answers below.","['real-analysis', 'convex-analysis']"
2418568,$\cos(\theta_n) \to \cos(\theta)$ and $\sin(\theta_n) \to \sin(\theta)$. How to show that $\theta_n \to \theta$?,"$\cos(\theta_n) \to \cos(\theta)$ and $\sin(\theta_n) \to \sin(\theta)$ where $\theta_n$ , $\theta \in (-\pi, \pi)$. How to show that $\theta_n \to \theta$ ? Can I use the continuity of $\cos^{-1}$ or $\sin^{-1}$ (only one of them) to get the result? If not, then how to proceed? Edit: As we know, range of $\arcsin $ is $[-\pi/2, \pi/2]$, we can use continuity of $\arcsin $ to get $\theta_n \to \theta$ when they belongs to  $[-\pi/2, \pi/2]$, in other cases use continuity of $\arccos$. Is this argument correct?","['continuity', 'real-analysis', 'sequences-and-series']"
2418584,"If $x^y y^x z^z=c$, then find $\frac {\partial^2z}{\partial x \,\partial y}$ at $x=y=z$.","If $x^y y^x z^z=c$, then find $\dfrac {\partial^2z}{\partial x \,\partial y}$ at $x=y=z$. I tried taking $\log$ but that doesn't help. Any hints will be appreciated. Thanks. This is what I have tried:","['multivariable-calculus', 'partial-derivative']"
2418587,What does the notation $f : \mathbb R \rightarrow \mathbb R$ mean?,"Alright, I've done research regarding this question have attained answers that identify $f$ as the function (which is obvious) and identify $\mathbb R \rightarrow \mathbb R$ as meaning ""the domain is the set of all real numbers and the codomain is the set of all real numbers"", I've also read that, say $f :  x \rightarrow x^2$ can be used as the notation for a function, and can otherwise be written as $f(x) = x^2$, which makes sense, but say for example, $f : 2\sqrt x \rightarrow \displaystyle \frac{x}{4}$, would this be equivalent to $f(x) = \displaystyle \frac{x^2}{64}$? Furthermore, can the use of symbols indicating the sets of, for example, all real or rational numbers always be used to distinguish between when this notation is referring to a function and when it is referring to the domain and codomain of a function? All I would like is confirmation to these ideas so that I am aware of how to use them in the future. Thank you.","['notation', 'functions']"
2418681,A probability distribution problem,"Is this a negative binomial distribution? How to solve this particular problem? Two ball players, denoted A and B , are practicing their scoring skill in their respective sports. The probability that A will score in any attempt is $p$, and A tries until they have scored $r$ times. The probability that B will score in any attempt is $mp$, where $m$ is a given integer $(m = 2, 3, . . .)$ such that $mp < 1$, and B tries until they have scored $mr$ times. (a) For which player ( A or B ) is the expected number of failed attempts smaller? Solved. (b) For which player is the variance of the total number of attempts smaller?","['statistics', 'probability-distributions', 'probability', 'discrete-mathematics']"
2418708,Permanent generating function identity for $\exp{\mathbf{x^{T}}A\mathbf{y}}$,"In this paper , there's an identity that I can't prove to my satisfaction, (there's a similar statement in here )
which is that, given a permanent of a $(\mathbf{k,l})$-replicated matrix $A$, (written $A^{(\mathbf{k,l})}$), 
$$\sum_{\mathbf{k,l}\geq 0}\mathrm{per}(A^{(\mathbf{k,l})})\frac{\mathbf{x}^{\mathbf{k}}\mathbf{y}^{\mathbf{l}}}{\mathbf{k}!\mathbf{l}!}=\exp{\mathbf{x^{T}}A\mathbf{y}}$$ Notation: $\mathbf{x^{k}}=\prod_{i=1}^{n}x_{i}^{k_{i}}$, $\mathbf{k}!=\prod_{i=1}^{n}k_{i}!$, and $A^{(\mathbf{k,l})}$ is the block matrix with the entry $a_{i,j}$ repeated $k_{i}\times l_{j}$ times. This is related to MacMahon's Master Theorem where 
$$
\sum_{\mathbf{k}\geq 0}\mathrm{per}(A^{(\mathbf{k,k})})\frac{\mathbf{x}^{\mathbf{k}}}{\mathbf{k}!}=\det (1-XA)^{-1}
$$
with $X_{ij}=x_{i}\delta_{ij}$ and $A=A^{(\mathbf{1,1})}$","['generating-functions', 'combinatorics', 'permanent', 'determinant']"
2418722,The corresponding Lie subalgebra of the isotropy subgroup,"Consider the Lie group action $G$ on the manifold $M$. How to find the Lie subalgebra of the isotropy subgroup $ G_m:=\{g\in G\,|\,g.m=m\}$?","['differential-geometry', 'lie-algebras', 'lie-groups']"
2418725,1000 elves and their hat (by induction),"Each of $1000$ elves has a hat, red on the inside and blue on the outside or vice-versa. An elf with a hat that is red outside can only lie, and an elf with a hat that is blue outside can only tell the truth. One day every elf tells every other elf, “Your hat is red on the outside.” During that day, some of the elves turn their hats inside out at any time during the day. (An elf can do that more than once per day.)Find the smallest possible number of times any hat is turned inside out (please use induction) I calculate the smallest possible number times all of the hats are turned inside out but I wasn't able to find the smallest possible number of times any hat is turned inside out my solution :(find all of the changes) Lemma: If we have $n$ elves, each with the same color hat, it will take at least $n-1$ switches for each of them to tell each other ""Your hat is red"". We will use induction: The base case is pretty obvious.
Now, assume that this statement is true for $n$. If we have $n+1$ elves of the same color, none of them can tell each other ""Your hat is red"", so we must first switch at least one hat. Once this is done, the elf who switched colors can tell everyone and everyone can tell him that his hat is red, so we may remove this elf from the picture entirely. The remaining $n$ elves all have the same color, and by the inductive hypothesis, they can only finish in a minimum of $n-1$ moves, so we have at least $n-1+1=n$ moves, as desired. Now, assume that among the 1000 elves, there are $x$ with blue hats and $1000-x$ with red hats. Every elf can tell the opposite colored elves that their hat is red, so we only need to consider the blue hat and red hat elves separately. By our lemma, it will take the blue elves at least $x-1$ switches and the red elves at least $1000-x-1$ switches to tell each other in their separate groups that their hats are red, so we must have at least $x-1+1000-x-1=998$ switches, as desired.
this question is from (Russian MO,2010,G9)","['combinatorics', 'induction', 'proof-verification']"
2418729,A function is analytic if and only if it is holomorphic,"I am studying some complex analysis and I have found this result. In fact it isn't a single theorem (I am reading Cartan's ""Elementary theory of analytic functions"" and I haven't found such a theorem, but maybe I just didn't find it), but there are many results that should give us this equivalence. However, I was wondering about two things. The first is: is this equivalence ""perfect""? I mean, could I exchange the terms ""holomorphic"" and ""analytic"" in theorems and various results without changing anything, or are there some hypothesis I should satisfy first? I am asking this because even though they should be equivalent, I always find theorems about (for instance) analytic prolongation that always talk about analytic functions, and there is no ""holomorphic prolongation"", if you understand what I mean. So I was not sure if this was simply a matter of tradition or if analytic functions are more general/poweerful than holomorphic ones. The second one is: if I have a function from $\mathbb{R}^2$ to $\mathbb{R}^2$ that is differentiable in an open connected set $U$ and in that open set it satisfies Cauchy-Riemann conditions, then it should be holomorphic and analytic, if viewed as a complex function. So, for the prolongation theorem, there should be only one function like that (that is, differentiable and that satisfes Cauchy-Riemann)on $U$. So, are you telling me that if I have a differentiable function satisfying Cauchy-Riemann in an open connected set, not only it is the only function (unless you add/subtract constants obviously) that does that, but (being analytic in $\mathbb{C}$) it is also $C^{\infty}$. It would be so incredible I can't believe it!","['analyticity', 'complex-analysis', 'analytic-functions', 'holomorphic-functions']"
2418741,"If $ \Omega $ is a bounded domain, is a $ BV(\Omega) $ function also $ L^\infty(\Omega) $?","Let $ \Omega $ be a (non-empty) bounded domain. The space of functions of bounded variation is defined by 
$$ BV(\Omega) = \{ u\in L^1(\Omega) \mid \|u\|_{TV} < \infty \} $$
where 
$$ |u|_{TV} = \sup\left\{ \int_\Omega u\operatorname{div}\phi\,dx \mid \phi \in C_c^1(\Omega), |\phi|\leq 1 \right\}. $$
Does $ u \in BV(\Omega) $ imply that $ u \in L^\infty(\Omega) $, i.e. is it the case that $ BV(\Omega) \subset L^\infty(\Omega) $? In case it isn't true, then $ \operatorname{ess}\sup_{x\in\Omega} |u(x)| = \infty $. $ u $ being infinite everywhere whould make the TV-norm infinite, which is a contradiction, so $ u $ must be finite somewhere, say at $ y $. I feel like this jump from finiteness at $ y $ to whereever the essential supremum is attained should make the TV-norm infinite again, thus contradicting my initial assumption. However, I have no clue so far about how to go about it technically. Maybe my gut feeling is just plain wrong?","['functional-analysis', 'total-variation', 'bounded-variation']"
2418761,"How many flags, with 3 horizontal stripes, can be made if two stripes are one color and the third is a different color?","For example, take the Austrian flag (red, white, red). I thought that the answer would be three from $\frac{3!}{1!2!}$, but the instructor said twelve, because from the product rule: $3\cdot2\cdot2$. Can anyone give me an explanation? Thanks.","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2418765,On an operator norm inequality for two triangular matrices,"Let $n\ge3$. Create two copies $A$ and $B$ of the $n\times n$ lower triangular matrices of ones. Then set $A(2,1)=A(n,n-1)=B(n,n-1)=B(n,n-2)=0$ (with all other entries in the lower triangular parts still equal to $1$). I want to show that the largest eigenvalue of $AA^T$ is greater than or equal to that of $BB^T$. Any hint to prove it?","['matrices', 'linear-algebra']"
2418785,"Showing that $f$ is linear function if $\forall z \in \mathbb{C}$, $|f(z)| \leq 1 + |z|$.","Let $f$ be an entire function that satisfies $|f(z)| \leq 1 + |z|$ for all $z\in \mathbb{C}$. Show that $f(z) = az +b$ for fixed complex numbers $a,b$. The hint tells us to try and use Cauchy's Integral Formula on an arbitrary circle. This is my attempt: Consider an arbitrary large circle with centre $0$ and let $\Upsilon$ be the contour around this circle. Then $$\int_{\Upsilon} \frac{f(z)}{z^{n+1}} \mathrm{d}z = \frac{2\pi i}{n!}f^{(n)}(0).$$ Note that $$\int_{\Upsilon}\frac{f(z)}{z^{n+1}} \leq \int_{\Upsilon}\left|\frac{f(z)}{z^{n+1}} \right|\leq \int_{\Upsilon} \frac{1}{|z^{n+1}|} + \frac{1}{|z|^n}$$ and the right hand side is $0$ by Cauchy's Integral Formula. I'm not sure if the first equality is valid, and not sure where to go from here.",['complex-analysis']
2418808,Could the orbit of $0$ through a polynomial be dense in $\mathbb R$?,"Could we construct a polynomial $P(x)\in\mathbb R[x]$ such that the sequence $(x_n)$ which is given by $x_0=P(0)$ and $x_{n+1}=P(x_n)$ for any $n\ge0$, is dense in $\mathbb R$ ?. I guess the answer is no, but I could not prove it.","['real-analysis', 'calculus']"
2418810,Show that ${\sum^{n}_{k=1}} \frac{1}{n+k} \le \frac{3}{4}$,"Prove that $\displaystyle{\sum^{n}_{k=1}} \frac{1}{n+k} \le \frac{3}{4}$ for each positive integer $n$. My work . I think that i have to use induction, but i can't see how... What i did:
$$f(n)=\displaystyle{\sum^{n}_{k=1}} \frac{1}{n+k} \implies k(n)=f(n+1)-f(n)=\frac{1}{2n+1}-\frac{1}{2n+2}.$$
Now we have 
$$f(n+1)=\displaystyle{\sum^{n}_{k=1}} \left ( \frac{1}{2k+1} \right )- \displaystyle{\sum^{n}_{k=1}} \left ( \frac{1}{2k+2} \right )$$
But now I have no more ideas.","['summation', 'sequences-and-series']"
2418837,Confusion in direction of differentiation,"We are given a coordinate $x$ and a function $f(x)$ at each point on $x$. We need to compute the derivative at a point $x$. For this, we usually choose two points $x+dx$ and $x$ (first principles). Can we also choose the points $x-dx$ and $x$ and get the same derivative? If not, why? If yes, why do we get opposite values for directional derivatives in two opposite directions?","['derivatives', 'calculus', 'functions']"
2418850,"Is there a notion of ""schemeification"" analogous to that of sheafification of a presheaf?","So this may seem like an odd question, but hear me out. In the Stacks Project, tag 01I4, we find that not only does the category of affine schemes live inside the category of locally ringed spaces, but that limits of affine schemes can be computed as limits in the ambient category of locally ringed spaces. In other words, the inclusion functor commutes with these limits. I am also aware that the reason we have sheafification of a presheaf is similar. The inclusion of the category of sheaves on a space is a full subcategory of the category of presheaves on that space. Moreover, it commutes with limits and a certain smallness condition is satisfied that allows us to deduce that the adjoint functor theory is satisfied and hence the inclusion functor has a left adjoint, which we call the sheafification functor. Is it true that the inclusion of affine schemes into the category of locally ringed spaces also admits a left adjoint which we might call schemeification? If so, what does it look like? How does it turn a locally ringed space into an (affine?) scheme? If not, what fails that we can't apply the adjoint functor theorem?","['algebraic-geometry', 'adjoint-functors', 'affine-schemes', 'category-theory', 'ringed-spaces']"
2418857,What kind of convergence is in Gateaux derivative?,"Let $F$ map $X$ to another Banach space $Y$. The usual (one sided) directional derivative of $F$ at $x$ in the direction $v$ is 
$$F'(x;v)=\lim_{t\downarrow0}\frac{F(x+tv)-F(x)}{t}\qquad(1)$$
when this limit exists. If $F'(x;\cdot)\in\mathcal{L}(X,Y)$ then (denoting $DF(x)=F'(x;\cdot)$) $DF(x)$ is Gâteaux derivative. My question is: what kind of convergence is in (1)? Is it pointwise convergence? If we consider convergence with respect to the norm $\|\cdot\|_{Y}$, i.e.,
$$\lim_{t\downarrow0}\|F'(x;v)-\frac{F(x+tv)-F(x)}{t}\|_{Y}=0$$ 
and once again $F'(x;\cdot)\in\mathcal{L}(X,Y)$, I think we obtain Fréchet derivative. Am I correct?","['derivatives', 'real-analysis']"
2418859,How to evaluate $\int_0^1\ln (\sqrt{1-x}+\sqrt{x}+\sqrt{1+x})dx$,"Evaluate $$I=\int_0^1\ln (\sqrt{1-x}+\sqrt{x}+\sqrt{1+x})dx$$ First, I tried like this $$I=\int_0^1\ln (\sqrt{x}+\sqrt{1+x})dx+\int_0^1\ln (\sqrt{1-x^2}-\sqrt{x-x^2}+1)dx$$ and I got a stuck. Then I tried using wolframalpha. But, the result is too complicated. How to we evaluate this integral. I don't know how to do it. Any help is welcome . Thank you very much for your answer","['logarithms', 'integration', 'definite-integrals', 'calculus']"
2418872,Why are Airy like Integrals zero when the start and endpoints of integration are in the same $\frac{1}{3}$ slice of convergence?,"Background : This is Bence et al. Mathematical methods: The version of the equation being solved is $$\frac{d^2y}{ dz^2}=zy\tag{1}$$ If z is a parameter, a solution as a contour integral is $$y(z)=\int_a^bf(t)e^{zt}dt\tag{2}$$ which yields when plugged into (1)
$$\int_a^bt^2f(t)e^{zt}dt=\int_a^bzf(t)e^{zt}dt$$
$$=f(t)e^{zt}\mid_a^b-\int_a^b\frac{df(t)}{dt}e^{zt}dt$$
If a and b are chosen so that the middle term is zero the equation can be solved as $$\frac{df(t)}{dt}+t^2f(t)=0$$
$$f(t)=Ae^{-t^3/3}\tag{3}$$
This occurs when $arg(t)=\pm\pi/6+\frac{2n\pi}{3}$ because the real part of t is positive and the exponent goes to zero. 
Plugging (3) into (1) and normalizing yields the $$Ai(z)=\frac{1}{2\pi i}\int_{C1} e^{-t^3/3+zt}dt$$
As long as the endpoints are in the shaded regions, the equation is valid: Question According to the text, the contour integral will be zero if the start and endpoints are in the same shaded region. Why would the integral be zero when the path is completely in one shaded region but not when the path is in two different shaded regions? Hypothesis/uneducated guess: Equation (1) has a singular point at infinity. Perhaps this means that the contour which crosses a branch cut encompasses points at infinity? Could this be used to solve the integral by using the residue at infinity? References : Bence, Hobson, Riley, Mathematical methods pg 891","['special-functions', 'complex-analysis']"
2418938,$\exp(A)$ is orthogonal iff $A$ is skew symmetric,"Let $A \in M_n(\mathbb R)$ and $\exp(A)=\sum_{i=0}^{\infty}\frac{A^i}{i!}$.
How to prove $\exp(A)$ is an orthogonal matrix iff $A^t=-A$? I can get that $\exp(A)$ is an orthogonal matrix iff $\exp(A^t)=\exp(-A)$, but how to get $A^t=-A$ from it? What's more, is $\exp(A)$ injective or not?","['matrices', 'matrix-exponential', 'linear-algebra']"
2418954,Find $\frac{1}{x_1^3} + \frac{1}{x_2^3} + \frac{1}{x_3^3}$ for $ax^3 + bx^2 + cx + d$,"Using Vieta's formulas, I can get $$\begin{align} \frac{1}{x_1^3} + \frac{1}{x_2^3} + \frac{1}{x_3^3} &= \frac{x_1^3x_2^3 + x_1^3x_3^3 + x_2^3x_3^3}{x_1^3x_2^3x_3^3} \\&= \frac{x_1^3x_2^3 + x_1^3x_3^3 + x_2^3x_3^3}{x_1^3x_2^3x_3^3} \\ &= \frac{x_1^3x_2^3 + x_1^3x_3^3 + x_2^3x_3^3}{\left (-\frac{d}{a} \right)^3}\end{align}$$
But then I don't know how to substitute the numerator.","['algebra-precalculus', 'cubics', 'roots']"
2418961,"Minimizing the multivariable function $f(x,y) = \frac{1}{xy} + x^2y$","I need to locate the optimal point(s) of the function $$f(x,y) = \frac{1}{xy} + x^2y$$ subject to the conditions $x \gt 0, y \gt 0$. I have tried the following approach
$$\frac{\partial f}{\partial x} = \frac{-1}{x^2y} + 2xy = 0 \rightarrow 1$$
$$\frac{\partial f}{\partial y} = \frac{-1}{xy^2} + x^2 = 0 \rightarrow 2$$
Now, $x \ne 0, y \ne 0,$ hence, we solve the two equations to get the optimal point, $(x^*, y^*)$. But the above system of equations has no solution. Physically, when $x \rightarrow 0$ or $y \rightarrow 0$, the function blows up. Also, when either $x \rightarrow \infty$ or $y \rightarrow \infty$, the function also blows up. Since it takes finite values in between and is continuous and differentiable, it should have some minimum value(s), and hence an optimal point. Where am I going wrong ? SOLVED Thanks to Arthur, I have realised the error in the above statements. I have assumed that whenever x or y becomes large, the function will blow up. But if I were to go along the path $y = \sqrt{\frac{1}{x^3}}$, and take $x$ smaller and smaller, $f = 2\sqrt x$ will go to 0. Hence, the infimum is $0$","['multivariable-calculus', 'a.m.-g.m.-inequality', 'optimization', 'calculus']"
2418977,Help needed in understanding Heron's Formula,"So i just started learning Trigonometry seriously and something doesn't feel right to me, either I'm missing something or not but. Lets assume we have a triangle and there are two ways to find the area.
1 is using the standard $$A = \frac{1}{2}bh$$ and by using the example image above we get $A = 10625$ but if I use the other formula, in this case, Heron's Formula 
\begin{align*}
s & = \frac{a+b+c}{2}\\
A & = \sqrt{s(s-a)(s-b)(s-c)}
\end{align*}
the area becomes $A = 10620.09$. They're both gravely close to each other, which has me thinking maybe I missed something. So my question is, why are the areas different?","['area', 'trigonometry']"
2419003,Every Pseudo-Differential Operator is Pseudo-Local operator.,"This is the theorem 8.9 of the book Introduction to PDE, Folland, G. B. I'm trying to complete the proof details. I would like to know how to justify the ""Afirmation"", with more rigor. Every pseudo-differential operator is pseudo-local, that is, if $P\in \Psi^m(\Omega)$, then, for all $u\in \mathcal{E}'(\Omega)$, $\hbox{ sing  supp }  Pu \subset \hbox{ sing supp } u $. Proof:  Let $P\in \Psi^m(\Omega)$ and $u\in \mathcal{E}'(\Omega)$.  Given $y_0 \notin \hbox{ sing supp } u$, choose a neighborhood $V$ of $\hbox{sing supp} u$ in $\Omega$ which do not meets the set $\{y_0\}$. Choose $\varphi \in C_0^\infty(\Omega)$ verifying $\hbox{supp }  \varphi \subset V$, such that $\varphi =1$ in a  neighborhood $U \subset V$ of $\hbox{ sing supp } u$ and define $u_1=\varphi u$ and $u_2 = (1-\varphi)u$. Then $u = u_1+u_2$, $\hbox{ supp } u_1 \subset V$ and $u_2= (1-\varphi)u\in C_0^\infty(\Omega)$. Indeed, $\hbox{  supp } u_1 = \hbox{ supp }(\varphi u) \subset \hbox{ supp } (\varphi)\cap \hbox{  supp } u\subset V$ and, in addition, $\hbox{ supp }(u_2) \subset \hbox{ supp }((1-\varphi))\cap \hbox{  supp } u\subset \hbox{  supp } u$ and $\hbox{ supp } u$ is a compact set because $u\in \mathcal{E}'(\Omega)$. To show that $u_2 \in C^\infty(\Omega)$, observe that if $x \in \Omega \setminus \hbox{ sing supp } u$, then $u_2$ is $C^\infty$ in $x$. Thus, it is sufficient to prove that $u_2$ is $C^\infty$ in $U$. Let $\psi \in \mathcal{D}(U)$, then $\langle u_2|_{U}, \psi \rangle = \langle u, (1- \varphi)|_{U} \widetilde{\psi}|_{U} \rangle =0$, since $(1-\varphi)|_{U}=0$, where $\widetilde{\psi}$ denotes the extension of $\psi$ zero outside of $U$. Thus, $u_2|_{U}=0$ and consequently $u_2 \in C^\infty(\Omega)$. Hence, $Pu=Pu_1 + Pu_2$, and $P u_2$ is a $C^\infty(\Omega)$ function since $u_2\in C_0^\infty(\Omega)$. If $k_p$ is the distributional kernel of $P$, the Theorem 8.8 gives that
        $k_p(x, y)$ is a $C^\infty$ function in $(\Omega\times \Omega) \backslash \Delta_{\Omega \times \Omega}$. In particular, $k_p(x,y)$ is a $C^\infty$ function for $x \notin V$ and $y \in V$, that is, if $Z$ is a neighborhood of $x$ which do not meets the set $V$, then $k_p \in C^\infty(Z \times V)$. Thus, for $x \notin V$  we have
        \begin{eqnarray*}
			P u_1(x) = \left<k_p(x,\cdot),u_1 \right>_{\mathcal{E}(V),\mathcal{E}'(V)}.
		\end{eqnarray*} In fact, let $u \in  \mathcal{E}'(V)$.  Since $C_0^\infty(V)$ is dense in $ \mathcal{E}'(V)$, there exists $(u_n) \subset C_0^\infty(V)$ such that $u_n \rightarrow u$ in $ \mathcal{E}'(V)$.  Then,
        \begin{eqnarray*}
			Pu_{n}(x)& = &  \int_{\mathbb{R}^{n}} e^{2 \pi i x \cdot \xi} p(x, \xi) \hat{u}_{n}(\xi) d \xi\\
			& = & \int_{\mathbb{R}^{n}} \int_{\mathbb{R}^{n}} e^{2 \pi i (x - y) \cdot\xi}
			p(x, \xi) u_{n}(y) dy d \xi \\
			& = & \int_{\mathbb{R}^{n}} \left[\int_{\mathbb{R}^{n}} e^{2 \pi i (x - y)\cdot \xi}p(x, \xi) d \xi \right]  u_{n}(y) dy \\
			& = &  \int_{\mathbb{R}^{n}}{k_p (x, y)u_{n}(y)}dy \\
			& = &  \left< k_p (x,\cdot),u_n \right>_{\mathcal{E}(V),\mathcal{E}'(V)}.
		\end{eqnarray*}
        Passing to the limit when $n$ goes to infinity, we obtain the desired equality. Afirmation: This implies that $D^\alpha P u_1(x) = \left<D_x^\alpha k_p(x,\cdot), u_1\right>_{\mathcal{E}(V), \mathcal{E}'(V)}$, and hence we deduce that the aplication $u_1 \mapsto Pu_1|_Z$ is linear and continous from $\mathcal{E}'(V)$ into $C^\infty(Z)$. I do not know if it is possible to identify a distribution with compact support defined in $\mathcal{E}'(\Omega)$ with a distribution defined in $\mathcal{E}'(V)$, even if $\hbox{ supp } u_1 \subset V \subset \Omega$. Justify this it's important to the next step ""$Pu_1$ is $C^\infty$ in $W$ "". Next, we shall prove that $\hbox{ sing supp } Pu_1 \subset V$.  To this end, let $U_{Pu_1}$ be the largest open set on which $Pu_1\in C^\infty(U_{P u_1})$. So, we have to prove that $\Omega \backslash U_{Pu_1} \subset V$, i.e., $\Omega\backslash V \subset U_{Pu_1}$. We will argue by absurd.  Let's assume that $x_0\in \Omega\backslash V $ and that $x_0 \notin U_{Pu_1}$. If $x_0 \in \Omega$ and $x_0\notin V$, then there exists a neighbourhood $W$ of $x_0$ such that $W\cap V=\emptyset$. Then, $P u_1$ is also a $C^\infty$ function in $W$. Note that $W \subset \Omega\setminus V$ and by the above comments we have the desired. Thus, $x_0 \in U_{Pu_1}$, which is a absurd.  Then,  $\hbox{ sing supp } Pu_1 \subset V$ as we desired to prove. Since $y_0 \notin V$, then $y_0 \notin \hbox{ sing supp } Pu_1$. Hence, $y_0 \in U_{Pu_1}$. From this, we deduce that there exists a open set $\omega \subset \Omega$ such that $Pu_1|_{\omega} \in C^\infty(\Omega)$. So, $Pu|_\omega=Pu_1|_{\omega}+Pu_2|_{\omega} \in C^\infty(\omega)$, since $Pu_2 \in C^\infty(\omega)$. Hence, $y_0 \notin\hbox{ sing supp } Pu$.
        $\blacksquare$","['functional-analysis', 'pseudo-differential-operators', 'topological-vector-spaces']"
2419029,Completeness of $L^p$ space,"In proving completeness of $L^p$ space, I got stuck at a step where this situation occurs.      Let $\langle\,f_n\,\rangle$ be sequence of measurable functions on $[0,1].$ Can we say that in $L^p$ space, integration of summation of modulus of functions is equal to the summation of integration of modulus of functions. Here we know that each function $f_n$ is measurable. This is generally true in uniform convergence of series . What can we say about this in $L^p$ space.
Thanks in advance","['functional-analysis', 'complete-spaces', 'lp-spaces', 'banach-spaces']"
2419071,"Probability measures, Integral","I had a test and was asked to prove that, with $\Omega = (0,1)$,
$$
\mathbb{P}(B)= \frac32 \int_B \sqrt{x} \,dx,
$$
is a probability measure, meaning it has to satisfy that $\mathbb{P}(\Omega)=1$, but had the condition $0 < x < 1$ (i.e. $B \subseteq \Omega$). I agree that
$$\mathbb{P}(\Omega) = \left. x^{3/2}\right|_0^1 = 1,$$
but $x$ can’t take those values, so $\mathbb{P}(\Omega)$ cannot be equal to 1, which means that $\mathbb{P}(B)$ is not a probability measure. But my teacher insists that it is an integral, so taking away those points doesn’t affects the area, I don’t know which is the right answer because I don’t understand that argument, because an area is a group of “dots” joined together.","['definite-integrals', 'integration', 'probability', 'calculus']"
2419078,Coin flipping probability?,"Q: flip a coin - how many times should it be flipped until the prob of all tails is $< 0.005$? Intuitively, I want to just do $0.5\times 0.5\times 0.5...$ until I get an answer $< 0.005$. Would this be the best way to do it to find out how many times I should flip it?","['statistics', 'probability']"
2419116,evaluate limit of a sequence,"The problem is: Prove the convergence of the sequence $\sqrt7,\; \sqrt{7-\sqrt7}, \; \sqrt{7-\sqrt{7+\sqrt7}},\; \sqrt{7-\sqrt{7+\sqrt{7-\sqrt7}}}$, .... AND evaluate its limit. If the convergen is proved, I can evaluate the limit by the recurrence relation $a_{n+2} = \sqrt{7-\sqrt{7+a_n}}$. A quickly find solution to this quartic equation is 2; and other roots (if I find them all) can be disposed (since they are either too large or negative). But this method presupposes that I can find all roots of a quartic equation. Can I have other method that bypasses this? For example can I find another recurrence relation such that I dont have to solve a quartic (or cubic) equation? or at least a quintic equation that involvs only quadratic terms (thus can be reduced to quadratic equation)? If these attempts are futile, I shall happily take my above mathod as an answer.","['sequences-and-series', 'analysis']"
2419134,Sum of powers of Harmonic Numbers,"This is a natural extension of the question Sum of Squares of Harmonic Numbers . I became interested in this question while studying the problem A closed form of $\sum_{n=1}^\infty\left[ H_n^2-\left(\ln n+\gamma+\frac1{2n} \right)^2\right]$ , especially the variation with a general integer power $q$, of which the present question is a part. Let the sum in question be $$s(q,n) = \sum _{k=1}^n H_k^{q} \tag{1}$$ where $q = 1, 2, 3, ...$ and $H_k = 1 + 1/2 + ... + 1/k$ is the harmonic number. Problems Derive a recursion relation for $s(q,n)$ Calculate $s(q,n)$ for $q=1 .. 4$ Discuss similarities with and possible deviation from the corresponding integrals $i(q,n)=\int_1^n ln(k)^q \, dk$ Discuss the possible meaning of the term ""closed form"" in the present context of finite sums. I have given an answer to 1. and 2. up to q = 4, and 3. correspondingly. Question 4. is perhaps the most interesting, and I have started to answer it.","['summation', 'harmonic-numbers', 'sequences-and-series']"
2419197,Reference: Derivatives of Riemannian Exponential Map,"Is there a known formula expressing the (first two) derivatives of the Riemannian exponential map on a Riemmannian manifold $(M,g)$?  I keep seeing references about some type of Jacobi-field thing but I can't seem to find anything expressing both the first and the second one...could someone please provide a reference :))","['riemannian-geometry', 'differential-geometry']"
2419209,How does $d\phi =d\lambda+wd\mu$ define a measure $\phi$?,"In Rudin's proof of the Lebesgue-Radon-Nikodym theorem, he states if $\lambda$ is a positive bounded measure and $\mu$ is a $\sigma$-finite measure, then $$d\phi =d\lambda+wd\mu$$ defines a measure, where $w\in L^1(\mu)$ and $0<w<1$. My question is: how does that define a measure? I am aware that $d\bar \mu=wd\mu$ implies that for all measurable, nonnegative functions $g$, $\int gd\bar\mu=\int gwd\mu$. So my first guess was to think that maybe $$d\phi =d\lambda+wd\mu$$ 
implies that for all measurable, nonnegative functions $g$
$$\int gd\phi =\int g(d\lambda+wd\mu)$$ 
But I have no idea what to do with the integral on the right. Do we distribute the integrand over the measures and integrate the sum? Do we replace $wd\mu$ with $d\bar\mu$ and suppose $d\lambda+d\bar\mu=d(\lambda+\bar\mu)$ so that at least for a characteristic function $g=\chi _E$ we get
$$\int gd\phi =\int gd(\lambda+\bar\mu)=(\lambda+\bar\mu)(E)=\lambda(E)+\bar\mu(E)=\int g d\lambda+\int gwd\mu$$ 
I do not know what is the convention or the definition of an integral with respect to $\phi$.","['real-analysis', 'lebesgue-integral', 'measure-theory']"
2419212,Intervals as infinite unions,"While studying σ-algebras for probability, at some point I needed some knowledge from topology, dealing with unions of intervals. I haven't studied topology so far but I do know that, for example, to write an open interval as unions of closed intervals we use: $$(x,y) = \bigcup_{n=1}^{\infty}[x+\frac{1}{n},y-\frac{1}{n}]$$ So my question is, if on the right-hand side we replaced the closed interval with an open one, like so: $ \bigcup_{n=1}^{\infty}(x+\frac{1}{n},y-\frac{1}{n})$, are we still capturing every element in $(x,y)$ this way too? If not then what is the meaning of this, if it has any?","['general-topology', 'elementary-set-theory']"
2419216,Determinant of a specific $n\times n$ matrix [duplicate],"This question already has answers here : If $a_{ij}=\max(i,j)$, calculate the determinant of $A$ (7 answers) Closed 6 years ago . Let $M_n=
  \begin{bmatrix}
    1 & 2 & 3 & ... & n\\
    2 & 2 & 3 & ... & n\\
    3 & 3 & 3 & ... & n\\
    \vdots & \vdots & \vdots & \ddots & n\\
    n & n & n & n & n
  \end{bmatrix}$ What's $\det(M_n)$ ? Seems like it is one of these exercises virtually impossible to do without the one trick, which is why I ask this question. Computing the first few determinants yields: $\det(M_1)=1$ $\det(M_2)=-2$ $\det(M_3)=3$ so if I were to make a wild guess, I would say $\det(M_n)=n(-1)^{n+1}$ The induction process didn't work too well for me because I can't find the determinant once a row and a column have been added to pad the matrix to dimension $n+1$. I tried to use the well-known formula for the determinant by cutting the inside in four parts ($M_n$ in the upper-left, $(n+1)$ in the lower-right, and the $(n+1)$ row and column, but at the end I must compute the determinant of a sum of matrices which didn't help... I don't know the name of this specific matrix, so maybe this is a repost, but if this is the case, I can't find the original one I'd be grateful if someone could provide some hints.","['matrices', 'determinant']"
2419226,Constructive Burnside's lemma,"Burnside's lemma is a clever tool to calculate the number of distinct configurations up to a given symmetry group. Wikipedia's example shows that the number of rotationally distinct colourings of the faces of a cube using three colours is 57. This introduction similarly shows that there are 6 distinct squares whose vertices have one of two colours. But what if we actually want to construct the 57 distinct-coloured cubes, or the 6 distinct-coloured squares, instead of just counting them? Is there a non-brute-force way of doing this?","['combinatorics', 'group-theory']"
2419249,Why is it inappropriate to describe a set in this way?,"I'm perfectly aware of one way of describing the set of squared natural natural numbers as such: $\{x|x=n^2,n\in N\}$ but what is wrong with the more compact $\{n^2|n\in N\}$?  A similar notion could be used to make any number of sets written in a more compact form.  I guess my question is: ""Is it ever APPROPRIATE to start a set description of this type with anything other than a generic variable representing a member of the set?""  If not, then why not condense the notation down to just something like $\{x=n^2, n\in N\}$?  Excuse my blissful ignorance.  Even though I have a degree in math, my study of set theory and and underlying foundations was extraordinarily weak at best.",['elementary-set-theory']
2419255,Why can't the ratio test be used for geometric series?,"The ratio test says that, for $a_k\neq 0$, if
$$\lim_{k\to\infty}\left|\frac{a_{k+1}}{a_k}\right|=L$$
exists, then if $0\leq L <1$, then $\sum_k a_k$ converges. If $L>1$, it diverges. The notes I'm reading say that it's inadmissible to use the ratio test to test for convergence of a geometric series. I can't see why this should be the case. Say we have some geometric series $\sum_kar^k$. Then
$$\lim_{k\to\infty}\left|\frac{a_{k+1}}{a_k}\right|=\lim_{k\to\infty}\frac{\left|ar^{k+1}\right|}{\left|ar^k\right|}=|r|.$$
So the ratio test tells us that the geometric series converges for $|r|<1$, and diverges for $|r|>1$, which is exactly what we get by using the formula
$$\sum_{k=1}^n ar^k=a\left(\frac{1-r^{n+1}}{1-r}\right).$$ What is an example that demonstrates why the ratio test is inadmissible for a geometric series?","['real-analysis', 'sequences-and-series', 'geometric-series', 'power-series', 'analysis']"
2419256,Is there a relation between the cohomology ring of a blowup with the base scheme and blowup locus?,"Let
$$
Y \subset X
$$
be a codimension 2 or greater smooth subvariety of a smooth projective variety $X$. Is there a relation between the cohomology of the blowup $Bl_Y(X)$ and the cohomology rings of $X,Y$?","['homology-cohomology', 'hodge-theory', 'algebraic-geometry', 'blowup']"
2419330,Using bump function in coordinate chart to construct a vector field $V$ along a curve $\gamma$ with particular properties.,"I get a little confused by the details of the following theorem from John Lee's book Riemannian Manifold page 100. It basically about construction of vector field along a piecewise smooth curve using smooth bump function. Let $\gamma : [a,b] \rightarrow M$ be piecewise smooth curve (i.e there are subdivision $a_0=a<a_1<...<a_{n-1}<a_n=b$ s.t $\gamma_{[a_i,a_{i+1}]}$ is smooth). Now we want a vector field $V : [a,b] \rightarrow M$ along $\gamma$ such that at a point in the ""corner"", say at $\gamma(a_i)$ for $0<i<n$, $V$ having a particular value, say $V(a_i)=V_i$, but at any other corner $a_j (j\neq i)$, $V(a_j)=0$. This particular construction arise from the following proof. $\textbf{Theorem 6.6.}$ Every minimizing curve is a geodesic when it is given a unit speed parametrization
  The idea is to use First Variation Formula 
  \begin{equation}
\frac{d}{ds}\Bigg|_{s=0} L(\Gamma_s) = -\int_a^b \langle V,D_t\dot{\gamma} \rangle dt - \sum_{i=1}^{k-1} \langle V(a_i), \Delta_i\dot{\gamma} \rangle
\end{equation}
  to show that the initial piecewise curve $\gamma$ satisfying the hypothesis (minimizing and unit speed) is a broken geodesic, that is $D_t \dot{\gamma} \equiv 0$ on each subdivision where its smooth, and to show that it has no corners, that is $\Delta_i \dot{\gamma} = 0$ for all $i$. My trouble is to follow the second step. It is says that to show $\Delta_i \dot{\gamma} = 0$, we can use a smooth bump function in a coordinate chart to construct a vector field $V$ along $\gamma$ such that $V(a_i)=\Delta_i \dot{\gamma}$ and $V(a_j)=0$ for all $j\neq i$. After a lot of thinking i already did such construction but not sure it is right. I worried because the similar proof for the above theorem in another text like do Carmo (Riemannian Geometry, Ch.9 prop 2.5 p.196) does not show either how to construct such vector field. Here is my ideas : Choose a small neighbourhood $U$ of $\gamma (a_i)$ such that it does not contain any other points $\gamma(a_j)$ except for $j=i$. Build a local vector field $V$ such that $V$ is constant with the constant coefficient equal to $\Delta_i \dot{\gamma}$. Choose a bump function $\varphi$ supported in $U$ such that $\varphi(\gamma(a_i)) = 1$. Restrict $\varphi$ to $U$ and multiplied it by $V$. Therefore we have a vector field $\varphi V$ defined in $U$. By Gluing lemma for smooth map we can extend $\varphi V$ to the whole $M$ such that $\varphi V$ vanish outside $U$ (details for extending $\varphi V$ is in here : Using Gluing Lemma for Smooth Functions ). Finally defined vector field along $\gamma$ by restrict the global vector field above to the image of $\gamma$ in $M$. I've been thinking some easier way (i'm not sure its correct or not). First we choose a appropriate small neighbourhood of $a_i$ in the domain of $\gamma : I \rightarrow M$, say $U \subset I$ such that $U$ does not contain $a_j$ for $j \neq i$. Choose a bump function $\varphi$ supported in $U$. Parallel translate the vector $\Delta_i \dot{\gamma}$ at $\gamma(a_i)$ along all portion of $\gamma(I)$, called this vector field $V$. Multiplied the resulting vector field by $\varphi$. The result is the vector field along $\gamma$, $\varphi V$, with the property that we needed, which is vanish for all $\gamma(a_j)$ for $j\neq i$ Any one can suggest another way (or correct way) to construct such vector field ? Thank you.","['smooth-manifolds', 'vector-fields', 'riemannian-geometry', 'differential-geometry']"
2419335,Finding the limit as $x$ approaches $0$,"I was shown the above problem in my calculus class today.  It seems that one can solve the limit in white by realizing that it mirrors the limit in yellow. However, I don't understand what the exact relationship between those two limits is. My TA went over it rather quickly. Can someone explain what point he was trying to make?","['calculus', 'limits']"
2419357,A Contact Form with Zeros,"I'm interested in 1-forms $\alpha$ on a 3-dimensional manifold $M$ with the following properties: 1) $\alpha \wedge d \alpha \leq 0$ 2) The set $Z(\alpha)$ for which $\alpha \wedge d \alpha = 0$ is controlled in some sense. Initially I would like to consider $Z(\alpha)$ to consist of finitely many points, perhaps to be extended to a situation where $Z(\alpha)$ is compact. When $Z(\alpha)$ is empty such a 1-form determines (at least locally) a contact structure on $M$. When $Z(\alpha)$ it (locally) determines a contact structure on the manifold minus these 'bad' points. My knowledge of contact geometry is limited and a cursory reading of the literature suggests that what I'm interested in is not covered. I have come across 'almost contact structures', but I do not think these cover my situation either. My question: is there anything in the literature about contact forms with isolated zeros (by which I mean, there is an $x$ such that $\alpha(x) = 0$ and an open neighbourhood around $x$ on which $\alpha$ is not zero)? Has any work been done on the local breakdown of the non-integrability condition $\alpha \wedge d \alpha \neq 0$ for a contact form $\alpha$? Motivation: I'm studying structures that arise in chiral nematic liquid crystals. The alignment of the liquid crystal molecules is given by a vector field $v$ (or equivalently 1-form) that describes the orientation at each point. The structures that arise are chiral in the sense that they have a well-defined handedness at each point. The chirality is defined by $v \cdot \nabla \times v$, which is equivalent to the condition I gave for the corresponding 1-form. One problem with using contact structures in this situation is that the liquid crystal will have defects, line or points where the orientational order is not defined. The vector field $v$ will be zero at these points, and thus $v \cdot \nabla \times v$ will also be zero there. Hence my interest in the kinds of structures I have described. I have a few ideas and have made some progress on local properties of point defects by looking at the singularity theory of Arnold, I was just wondering if there was any work already out there that might be applicable. I can't find anything, but maybe I don't know the right terms to search for.","['reference-request', 'contact-topology', 'differential-geometry']"
2419371,A limit involving $\frac{\pi^2}{6}$,"Let $a_n=1+\frac{1}{2^2}+\dots+\frac{1}{n^2}$. Considering known that $\lim_{n\to\infty}a_n=\frac{\pi^2}{6}$, evaluate $$\lim_{n\to\infty}n\left( a_n-\frac{\pi^2}{6}\right)$$
My attempt: I first proved that $b_n=n\left( a_n-\frac{\pi^2}{6}\right)$ is decreasing , i.e. $b_{n+1}-b_n=a_n+\frac{1}{n+1}-\frac{\pi^2}{6} \leq 0$, which is true since $$\lim_{n\to\infty}\left(a_n+\frac{1}{n+1}\right)=\frac{\pi^2}{6}$$ and $a_n+\frac{1}{n+1}$ is an increasing sequence. Then I proved that $b_n$ is bounded by $0$ (obviously) and $-1$, the latter being true since it is equivalent to $a_n+\frac{1}{n}\geq \frac{\pi^2}{6}$, which can be proven as above. So $b_n$ is both decreasing and bounded, which means that it has a limit $l$ and I ended with Stolz-Cesaro:
$$l=\lim_{n\to\infty}n\left( a_n-\frac{\pi^2}{6}\right)=\lim_{n\to\infty}\frac{n^2\left( a_n-\frac{\pi^2}{6}\right)}{n}=\lim_{n\to\infty}\left( (n+1)^2\left( a_{n+1}-\frac{\pi^2}{6}\right) -n^2\left( a_n-\frac{\pi^2}{6}\right)\right)=\lim_{n\to\infty}\left( \frac{n^2}{(n+1)^2}+a_{n+1}-\frac{\pi^2}{6}+2n\left( a_{n+1}-\frac{\pi^2}{6}\right)\right)=1+0+2l$$ so $l=-1$. Can anyone provide a shorter solution, if there is one, please?","['real-analysis', 'calculus', 'limits']"
2419384,Is there any example of a non-measurable set whose proof of existence doesn't appeal to the Axiom of choice?,"Is there any example of a non-measurable set whose proof of existence doesn't appeal to the Axiom of choice? What would it imply if there was such an example? EDIT: For instance, maybe this will help understand the kind of example I had in mind, it is known that an important feature to determine that the AC is needed in the Banach-Tarski case is the non-transitivity of rotations on Euclidean space, one might find an example of a transitive group for some given space keeping the rest equal and make the AC unnecessary? I guess then it might be said that this transitivity will be in this particular case equivalent to the AC or some amount of it, but I guess that it would be important to show this if it hadn't been realized before.","['lebesgue-measure', 'measure-theory', 'axiom-of-choice', 'foundations']"
2419391,Lebesgue Spaces and Integration by parts,"Suppose there exists a Lebesgue Space, $L_1$ and functions functions $\phi$ , $\phi'$ , $f$ , and $f'$ functions where $$\phi, \phi' \in L_1$$ By rule of integration by parts, $$uv|_a^b = \int_a^b udv + \int_a^b vdu$$ Let $$ u = \phi, du= \phi'$$ $$ v = f, dv = f'$$ Are there any properties of Lebesgue functions that allow $$ uv|_a^b = 0$$ Are $\phi$ and $\phi'$ convergent as integrals?
Do the unbounded limits of $\phi$ and $\phi'$ converge?","['real-analysis', 'integration', 'lebesgue-integral', 'analysis']"
2419420,Integer with largest number of divisors,"Prove that the number $83160=  2 ^{3} \cdot  3
^{3}\cdot  5 \cdot 7 \cdot 11
 $  has the  largest number of divisors among all integers $≤10^5$. My Attempt.  The number $83160$ is so-called highly composite numbers and there are algorithms, for example here , for calculating such a numbers. So, I can make a computer program to calculate it. It is possible to prove it without any  computer calculation?","['number-theory', 'prime-factorization', 'prime-numbers', 'elementary-number-theory']"
2419431,Infinite expected return time implies return probabilities tend to zero,"For a Markov chain $X_n$ I want to prove that if
$$ \mathbb{E} (\min\{n \geq 1:X_n = i\}\mid X_0 = i) = \infty$$
(that is, if $i$ is transient or null recurrent), then
$$ p_{ii}^{(n)} \equiv \mathbb{P}(X_n = i \mid X_0 = i) \to 0 \quad \mathrm{as} \quad n \to \infty .$$
My intuition is that if the above expected value is infinite, then the probability that the first return to $i$ occurs at $n$ must decay relatively slowly with $n$, which means it's 'fairly likely' that the chain won't have returned to $i$ in the first $n$ steps. Hence the return probabilities are small. However, I can't turn this into a proof that they decay to zero. Please be as elementary as possible! If $i$ is transient then the theorem is easy to prove. Transience is equivalent to the sum of the $p_{ii}^{(n)}$ being finite, which means they must tend to zero. The null recurrent case is proving more stubborn.","['stochastic-processes', 'markov-chains', 'probability-theory']"
2419476,"Largest set in which $(x, y)\mapsto \sqrt{xe^y - ye^x}$ is defined","I have to find the biggest $\mathbb{R}^2$ subset in which the function $g(x,y) = \sqrt{xe^y - ye^x}$ is defined. In order to do it I have to study $xe^y - ye^x \ge 0$ but I can't find out a solution. Can someone help me?","['multivariable-calculus', 'exponential-function', 'functions']"
2419515,Genus and Faltings Theorem,"This is probably a silly question, but I still can't figure it out: Acording to Faltings Theorem, a non-singular algebraic curve in $\mathbb{Q}[x,y]$ with genus $g>1$ has a finite number of rational points. But the curve $y=x^4-1$, for example, is non-singular and, from the genus-degree formula, $g=\frac{(4-1)(4-2)}{2}=3>1$, but of course all $(r, r^4-1)$ with $r\in\mathbb{Q}$ are rational points. What am I getting wrong?","['diophantine-approximation', 'elliptic-curves', 'algebraic-number-theory', 'algebraic-geometry']"
2419549,What is the probability that a random ordering of the $7$ integers results in one run up followed by one run down?,"Suppose that the integers from $1$ to $7$ are randomly ordered from left to right. If the ordering consists of an initial increasing sequence followed by a decreasing sequence, then we say that we have one run up followed by one run down. What is the probability that a random ordering of the $7$ integers results in one run up followed by one run down. My attempt: I think I did this right, but I am looking for verification or other interesting methods to approach this. I noted that $7$ must not be in position $1$ or $7$. When considering $7$ to be in position $2$, you have $6\choose1$ different possibilities for position $1$, and positions $3$-$7$ would only have one possibility (the remaining digits in decreasing order). Similarly, we $6\choose2$, $6\choose3$. $6\choose4$, and $6\choose5$ possibilities when $7$ is in the $3^{rd}$, $4^{th}$, $5^{th}$, and $6^{th}$ spot, respectively. This gives $p$ = 
${{6\choose1}+{6\choose2}+{6\choose3}+{6\choose4}+{6\choose5}\over 7!}$ $=$ $.0123$","['permutations', 'combinatorics', 'statistics', 'probability']"
2419581,"Discrete math $A\,\triangle\, B = C$ implies that $A\,\triangle\, C = B$","$A\,\triangle\, B = C$ implies that $A\,\triangle\, C = B$ I understand that the delta is the symmetric difference and that the symmetric difference of $A$ and $B$ is the set of elements that belong to exactly one of $A$ and $B$. How do I prove the above statement?",['discrete-mathematics']
2419583,Does a topological space contain the closed sets?,"I am confused concerning the relation between closed sets and a topological space.
I know that a topological space is mostly defined in terms of open sets via the underlying topology and ist requiered properties. The sets defining the topology are then called open sets. Given the de Morgan laws one could restate this in terms of closed sets. But this will then necessarily imply that the closed sets define the topology and thus the topological space which contains them. That the topological space will contain both open and closed sets makes me totally confused. I know that one of the differences between a sigma algebra and a topological space is precisely this: through the complementation the sigma algebra contains also the closed sets whereas the topological space does not. Can somebody help me clarify this confusion ?
Thanks.","['general-topology', 'measure-theory']"
2419619,Probability of selecting elements with replacement,"If I'm selecting $N$ elements uniformly at random (with replacement) from $\{1, \dots, N\}$, what is the chance that a given value is selected at least once? What is the name for the distribution for the more general case where I'm selecting $N$ elements from a domain with $M$ elements?","['combinatorics', 'probability']"
2419629,Show that the cosine of $\theta$ is $\frac{1 - t^2}{1 + t^2}$. Where am I going wrong?,"I've recently picked up the book Mathematics and it's History by John Stillwell due to a recent curiosity in the history of math. I started doing one of the exercises in the book and got a little stumped (I'll admit, I'm quite rusty at math). I'm asked to use this figure ... ... to show that $\cos \theta = \dfrac{1 - t^2}{1 + t^2}$. I labeled the bottom side of the smaller triangle $a$, and the right side of the smaller triangle as $b$, which makes the bottom side of the bigger triangle $1 + a$. In these terms, $\cos \theta = a$, since the hypotenuse of the smaller triangle is $1$. I also came up with the following equations: $$
a^2 + b^2 = 1
$$
$$
(a + 1)^2 + b^2 = t^2
$$ Solving the first equation for $b$ gives:
$$
b = \sqrt{1 - a^2}
$$ Substituting this equation into the second equation above gives:
$$
(a + 1)^2 + (\sqrt{1 - a^2})^2 = t^2
$$
$$
a^2 + 2a + 1 + 1 - a^2 = t^2
$$
$$
2a + 2 = t^2
$$
$$
a = \frac{t^2 - 2}{2}
$$ As you can tell, $\frac{t^2 - 2}{2}$ is not equal to the given $\frac{1 - t^2}{1 + t^2}$. Where am I going wrong in my logic? Thanks!",['trigonometry']
2419639,Number of tangent lines to an algebraic curve passing through a given point,"Let $C=V(f)\subset \mathbb{P}^2$ be a smooth plane algebraic curve of degree $d$ . For all $x\in \mathbb{P}^2\setminus C$ there are at most $d(d-1)$ tangent lines to $C$ passing through $x$ . There exists an $x$ such that we have an equality in the statement above. For the first part I have tried to do this: After a translation we can assume that $x=(0:0:1)$ , then as an arbitrary line passing through $x$ has exactly one intersection with the line at infinity we have an unique parametric representation in the form $l_{(a:b)}=\{(a\mu:b\mu:\lambda); \lambda,\mu \in k\}$ for some $(a:b)\in \mathbb{P}^1$ . Now, $l_{(a:b)}$ is tangent to $C$ $\iff$ one of the equations $f(ax,bx,1)=0$ or $f(a,b,x)=0$ has a multiple root $\iff$ one of the associated discriminants $\Delta_{(a:b)}$ or $\hat{\Delta}_{(a:b)}$ vanished. If $(a:b)\neq (1:0)$ we can take $b=1$ and studying $P(a)=\Delta_{(a:1)}$ and $Q(a)=\hat{\Delta}_{(a:1)}$ as polynomials in $a$ so it would be enough to prove the following $\deg(P)+\deg(Q)+\#(\{\Delta_{(1:0)}\}\cap \{0\})+\#(\{\hat{\Delta}_{(1:0)}\}\cap \{0\})\leq d(d-1)$ But I don't know how to compute $\deg(P)$ or $\deg(Q)$ so I don't know hot to continue. For the second part perhaps I could take $x=(c:0:1)$ and make computations similar to those above to obtain expressions of the form $\Delta_{c,(a:b)}$ and $\hat{\Delta}_{c,(a:b)}$ . Then if we define $P^c(a)=\Delta_{c,(a:1)}$ and $Q^c(a)=\hat{\Delta}_{c,(a:1)}$ maybe we can choose $c\in k$ such that $P^c$ and $Q^c$ have different roots and $\Delta_{c,(1:0)},\hat{\Delta}_{c,(1:0)}\neq 0$ . Then $\deg(P^c)+\deg(Q^c)$ would be equal to the number of tangent lines, and a good understanding of the first part should give us a way to compute this. As noticed here assuming Hurwitz's formula this problem is equivalent to Plücker's Formula and that's where my interest comes from.","['algebraic-curves', 'algebraic-geometry']"
2419682,Triangle Inequality proof with three variables [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How do I prove $$|x + y+ z| \le |x|+|y|+|z|$$ without using the triangle inequality itself? Are cases the best way to go? Or using properties of absolute? very stuck","['algebra-precalculus', 'inequality', 'triangles', 'absolute-value']"
2419697,Trapezoid geometry problem involving areas,"ABCD is a trapezoid with $AD$ parallel to $BC$ . The area of $ABCD$ is $225$ . The area of $\triangle BPC$ is $49$ . What is the area of $\triangle APD?$ I can see that the triangles $BPC$ and $APD$ are congruent, though I do not know how to apply this to a solution. The formula for the area of a trapezium doesn't seem to be applicable here. Could someone provide an explained solution which doesn't involve trigonometric functions?","['contest-math', 'geometry']"
2419736,Is there a significance to the asymptotic probability of at least one occurrence of an event in n attempts?,"Let's look at the set of the probabilities of having at least one occurrence of an event if we make $n$ attempts, where the probability of the event occurring is $1/n$. For example, if we are looking at the probability of the occurrence of rolling a $4$ on a die ($1/6$ chance), we will actually make $6$ attempts. The probability of success in that case (at least one occurrence of a $4$ in the $6$ attempts) is $1-(5/6)^{6} = 0.6651$ (I have rounded the results.) If we make $15$ attempts at something with a probability of its happening (on each separate occasion) being $1/15$, then the probability of its occurring at least once in those $15$ attempts is $1-(14/15)^{15} = 0.6447$.  If we use $n=1,000,000$ then we get $0.63212$. So, we see that we have an asymptotic situation. I have always wondered if there was any other known mathematical significance to this specific approximate number/asymptote. Thanks in advance for reading and for all responses!",['probability']
2419737,probability of combinations for numbers 1-7 [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question In Japan, there is a Chimpanzee named Ai who can evidently understand numbers better than many college students. The numbers 1 - 7 appear on a computer screen for Ai. Ai then touches the screen to select the numbers in the correct order. Each time Ai selects a number, it disappears from the screen of choices. What is the probability of getting the entire sequence correct (1,2,3,4,5,6,7) if the chimp, Ai, is just guessing?","['statistics', 'probability', 'sequences-and-series']"
2419759,$\sin(\cos(\sin(\cos(\sin(\cos \cdots \sin(\cos x)))))))\cdots))))$,I was wondering if there was some easy way to evaluate a repeating pattern of $$\sin(\cos(\sin(\cos x)))$$  for an arbitrary number of $\sin(\cos(\cdots $'s.  I typed it into desmos and notice if I typed in enough it hovered around a value near $.7$ -  Does anyone know the actual value of this number or a finite representation of an arbitrary length string of sines and cosines?,"['trigonometry', 'calculus']"
2419920,A net converges to a point iff every subsequence of the net converges to the same point in first countable topological spaces,"I'm having trouble proving the fact that in first countable topological spaces, a net converges to a point iff every subsequence of the net converges to the same point. I first encountered this problem when I was learning dominated convergence theorem. I often tried to pass the limit under the integral sign, especially when dealing with partial derivative of an integral and using Leibniz's rule. The statement of DCT involves a sequence of functions and the convergence of a sequence of integrals. $$\lim_{n \rightarrow \infty} \int f_n = \int \lim_{n \rightarrow \infty} f_n$$ But when I was dealing with partial derivative of an integral, it's a net of functions which gives the convergence of a net of integrals. For example, $$\lim_{h\rightarrow0} \int_0^t \frac{H(t+h,s)-H(t,s)}{h}ds = \int_0^t \lim_{h\rightarrow 0} \frac{H(t+h,s)-H(t,s)}{h}ds = \int_0^t \frac{\partial H(t,s)}{\partial t} ds$$ This is often proved by DCT. I don't know why exactly we can do this. I was told it is because of the result that a net converges to a point iff every subsequence of the net converges to the same point in first countable topological spaces. I tried to prove this result by myself but couldn't get anywhere. Thanks in advance for any help!","['general-topology', 'nets', 'measure-theory', 'convergence-divergence']"
2420033,$n$ numbers with their sum and product equal to each other.,"I was trying to do this: For any integer $n\ge2$, find $n$ numbers $a_1,\ a_2,\ a_3,\dots,a_n$ such that 
$$a_1+a_2+a_3+\dots+a_n=a_1a_2a_3\dots a_n$$ For $n=2$, we have $a_1=a_2=2$. (As $2+2=2\times2)$ For $n=3$, we have $a_1=1,\ a_2=2,\ a_3=3.$ ($1+2+3=1\times2\times3$) Do there exist any such numbers for higher values of $n$ (i.e $n\ge4$). If there are give such examples. If there don't exist such numbers for $n\ge4$, there must be a proof from elementary number theory for this. What is that proof?","['number-theory', 'products', 'elementary-number-theory']"
2420054,Is one-to-one correspondence the same as bijection?,Or is it a bijection that is everywhere defined ?,"['elementary-set-theory', 'relations', 'terminology', 'functions']"
2420068,$\lim_{n \to \infty}\left(\frac{\sqrt[n]a}{n+1}+\frac{\sqrt[n]{a^2}}{n+\frac12}+\cdots+\frac{\sqrt[n]{a^n}}{n+\frac1n}\right)=?$,"What is the value of limit $$\lim_{n \to \infty}\left(\frac{\sqrt[n]a}{n+1}+\frac{\sqrt[n]{a^2}}{n+\frac12}+\frac{\sqrt[n]{a^3}}{n+\frac13}+\cdots+\frac{\sqrt[n]{a^n}}{n+\frac1n}\right)$$ If we know that $a>0$? I get stuck on this, it seems to be Riemann sum but I can't find relation. I am thankful if someone could guide me.","['riemann-sum', 'summation', 'calculus', 'limits']"
2420091,"Find expectation of $\frac{X_1 + \cdots + X_m}{X_1 + \cdots + X_n}$ when $X_1,\ldots,X_n$ are i.i.d","Let $X_1, \ldots, X_n$ be i.i.d. random variables with expectation $a$ and variance $\sigma^2$ , taking only positive values. Let $m < n$ . Find the expectiation of $\displaystyle\frac{X_1 + \cdots + X_m}{X_1 + \cdots + X_n}$ . My attemps to solve this probles are rather straightforward. Denote $X = X_1 + \cdots + X_m$ and $Y = X_{m+1} + \dots + X_n$ . So, $X$ has the expectation $ma$ and the variance $m\sigma^2$ . And $Y$ has the expectation $(n-m)a$ and variance $(n-m)\sigma^2$ . And also $X$ and $Y$ are independent. So we can compute the expectation by the definition $\mathbb{E}\displaystyle\frac{X}{X+Y} = \int\limits_{\Omega^2}\frac{X(\omega_1)}{X(\omega_1) + Y(\omega_2)}\mathbb{P}(d\omega_1)\mathbb{P}(d\omega_2)$ . But we do not know the distribution, so we do not have chance to calculate it. I would be glad to any help or ideas!","['expected-value', 'probability-theory', 'statistics']"
2420100,Difference between covariance matrix and covariance operator,"We that gaussian measures are characterized by their mean and covariance.In $\mathbb{R^{n}}$ we know that mean would be a vector of 1xn dimensions and covariance would be a nxn matrix.Now when we use a banach space or a hilbert space , mean will be an infinite vector and covariance will change to covariance operator.Can someone give me the notion of the difference between covariance matrix and covariance operator ?? I mean covariance operator is going to be an infinite dimensions matrix ?? What do we change from matrix to operator ??","['functional-analysis', 'measure-theory', 'operator-theory']"
2420133,What is the relation between $\varepsilon$-$\delta$ and $dy$-$dx$ notations?,"For what I know, $dy$-$dx$ aren't real numbers, exist as convenient notations to capture our intuitions about infinitesimal increments, while $\varepsilon$-$\delta$ are real distances, saying that $f$ can be as close as we want to $L$ if $x$ is sufficiently close to $c$. The latter has a formal statement: $$ \lim_{x \to c} f(x) = L  \iff  (\forall \varepsilon > 0)(\exists \ \delta > 0) (\forall x \in D)(0 < |x - c | < \delta \ \Rightarrow \ |f(x) - L| < \varepsilon)$$ While the former denote for $\Delta f$ and $\Delta x$ respectively when we arrive at $\Delta f=A\Delta x+o(\Delta x)$, which comes from the definition of derivative $f'=\lim_{\Delta x\to0}\frac{\Delta f}{\Delta x}$, and a chain of denotations $\varepsilon(\Delta x)=\frac{\Delta f}{\Delta x}-f'$, $o(\Delta x)=\varepsilon(\Delta x)\Delta x$ and $A=f'(x)$, with a note that $\lim_{\Delta x\to0}\varepsilon(\Delta x)=0$. As I understand here $\varepsilon(\Delta x)$ is simply a random unimportant convenient notation and has nothing relates to the infinitesimal above. Yet looking at the graph on Wikipedia: (ε, δ)-definition of limit , I can't help but thinking that they are just one thing: So what is the difference, and more generally, the relation between these two notations? Can I use $\varepsilon$-$\delta$ in a integral? And if $df=A\Delta x,dx=\Delta x$, then they should be real, right?","['derivatives', 'differential', 'nonstandard-analysis', 'calculus', 'infinitesimals']"
2420161,Convergence of $\sum_{n=0}^{\infty}\sin(x\pi n!)$,"Since this question is closed, I'm asking it myself. Let $M=\{x\in \mathbb R|\sum_{n=0}^{\infty}\sin(x\pi n!)\text{ converges}\}$ Prove that there is no $a,b\in \mathbb R$ such that $(a,b)\subset M$ (ie $M$ has empty interior). It has been proved that $e\in M$ , and it's easy to prove that $\mathbb Q \subset M$ (essentially because if $n\in \mathbb N$ , then $\sin(n\pi)=0$ ). I haven't managed to prove $M$ has empty interior. The idea would be to point out a dense subset of $M^c$ . Noting that $\sin(x\pi n!)\approx 0 \iff \exists k_n\in \mathbb Z, x\approx \frac{k_n}{n!}$ , we're looking for $x$ 's that are badly approximated by rationals. A result by Liouville states that if $x$ is an irrational algebraic number of degree $m$ , there exists some $c_x$ such that for all $p,q\in \mathbb Z$ , $\left|x-\frac pq \right|> \frac{c_x}{q^m}$ . In our case, if $x$ is an irrational algebraic number of degree $m$ , then for each $n$ and any $p\in \mathbb Z$ , $$\left|xn!\pi -p\pi \right|>\frac{c_x\pi}{(n!)^{m-1}}$$ Hence $|\sin(xn!\pi)|>\left|\sin\left(\frac{c_x\pi}{(n!)^{m-1}}\right) \right|$ . However, nothing may be derived from this lower bound (the RHS goes to $0$ too fast).","['real-analysis', 'diophantine-approximation', 'sequences-and-series']"
2420176,"What is general term of the sequence : $1, 2, 4, 4, 8, 8, 8, 8, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32 ...$?","I have a sequence as follows: $$1, 2, 4, 4, 8, 8, 8, 8, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32 ...$$ What will be the closed form of the above sequence for the nth term? I clearly see the pattern of $2^x$ getting repeated $2^{x-1}$ times. But I am getting confused in finding the closed form of this sequence. EDIT: Thanks @Arthur for providing the closed form. Now to extend the questiona bit further, what would be the sum upto nth term given the closed form? . Looking at the closed form, it seems like that the sum would be of the order of $N^2$, but not able to find the exact value. I would like to see how much difference would it make because of the ""ceiling"" function.",['sequences-and-series']
2420241,Tangent bundle of a manifold as more than a vector bundle,"Let $M$ be a smooth manifold.  The tangent bundle is naturally a smooth vector bundle, but it obviously has more structure than that.  Specifically, there is a natural action of the the diffeomorphism group of $M$ on $TM$.  Unless I am mistaken, this action is what distinguishes $TM$ it from an isomorphic vector bundle (e.g., the cotangent bundle of $M$).  A similar question could be asked for the bundle of $n$-forms and the bundle of densities on an orientable $n$-manifold. Both should be trivial line bundles, but the action should be different. My question is what are good ways to think about this additional structure and does it have a name?  The less category theory the better.",['differential-geometry']
2420258,Does the proof of Yamabe problem gives a method for finding metric of constant scalar curvature?,"Yamabe problem states that: Given a smooth, compact manifold $M$ of dimension $n \geq 3$ with a Riemannian metric $g$, does there exist a metric $h$ conformal to $g$ for which the scalar curvature of $h$ is constant? The answer is now known to be yes and I want to know Question: Does the proof of Yamabe problem give a method for finding metric of constant scalar curvature? If the answer is positive, then what is its method? Thanks.","['riemannian-geometry', 'differential-geometry']"
2420290,Show that $a_n (X_n-c) \stackrel{d}{\to} F$ implies $X_n \stackrel{\mathbb{P}}{\to} c$ for any sequence $a_n \to \infty$,"I am given that $a_n\to\infty$, and $a_n(X_n-c)\xrightarrow{d}F(x)$ for some distribution $F$ and constant $c$. I am to show that $X_n\xrightarrow p c$. What I've tried: first I thought maybe some version of Slutsky's applied here, but it seems not. Then I tried using the definitions and the fact that for any $\epsilon>0$ and $x\in\mathbb R$, we have $\frac x {a_n}<\epsilon$ for high enough $n$. But I couldn't find a way to use this. Finally I've tried working backwards from the desired conclusion via a reductio, but that doesn't seem to go anywhere either. Any tips would be appreciated.","['weak-convergence', 'probability-theory', 'convergence-divergence']"
2420320,In a square with unit side lengths there are two identical circles that are tangent to each other and two faces of the square. Find the radius?,"In a square with side lengths $1$ there are two identical circles that are tangent to each other and two faces of the square. What is the radius of the circles? I've spent a bit of time trying to solve this, as part of a larger problem.","['circles', 'geometry']"
2420364,faithful state on commutative AW$^*$-algebras,"Any commutative AW$^*$-algebra has the form $C(X)$ where $X$ is a Stonean space. In Takesaki's book Theory of Operator Algebra's, he shows that any Stonean space can be decomposed into three parts: a hyperstonean part, a part with a dense meagre set and a part where every regular positive measure has a nowhere dense support. Let's call these Type A,B and C. Type A is a von Neumann algebra, while type B and C allow no normal states, so they are in a certain sense maximally non-von Neumann. A Type C Stonean space doesn't allow a faithful state, since all states/measures have nowhere dense support. My question is: Is there a Type B commutative AW$^*$-algebra that has a faithful state? Or in other words: Does there exist a Stonean space with a dense meagre set that has a measure on it that is nonzero on every open set. edit: Just want to add that the question can be reframed in another way: Is there a commutative AW$^*$-algebra with a faithful state that isn't a von Neumann algebra? There is a result that says that any AW$^*$ II-factor with a faithful state is a von Neumann algebra, while there are III-factor AW$^*$-algebra's that aren't von Neumann,  so I wouldn't be surprised if there was some result about the commutative case in either direction.","['operator-algebras', 'measure-theory', 'von-neumann-algebras']"
2420387,Please explain how the following derivative graphically makes sense.,"I have two vectors $\vec{A}$ and $\vec{B}$ as shown below: The point at the origin of vector $\vec{B}$ has coordinates $(x,y)$. The angle between the two vectors is $\theta$. Now in my physics book there is an expression $\dfrac{\partial(\cos\theta)}{\partial x}$. How does this expression makes sense? At point $(x,y)$, there is a vector $\vec{B}$. But at point $(x+dx,y)$, there should be no vector. By changing $dx$ (i.e. by moving the point from $(x,y)$ to $(x+dx,y)$) we only change the point, not the whole vector. If someone says that the whole vector needs to be moved, how can we prove it mathematically? Edit: Simplified version of a part of the treatise","['derivatives', 'coordinate-systems', 'angle', 'calculus', 'vectors']"
2420402,Show that $f$ is bounded if $f(x)+f''(x)=-xg(x)f'(x)$ where $g\ge0$,"Let $f$ be a twice differentiable real valued function such that 
$f(x)+f''(x)=-xg(x)f'(x)$
Where $g(x)\geq 0$ for all real $x$
Show that $|f(x) |$ is a bounded function.","['real-analysis', 'calculus']"
2420465,Product of a shifted Log-Normal and a Log-Normal distribution,"Let $X$ and $Y$ follow Log-Normal distributions, with $\ln X \sim \mathcal{N}(\mu_x, \sigma_x^2)$ and $\ln Y \sim \mathcal{N}(\mu_y, \sigma_y^2)$. $X$ and $Y$ are independent. Let $W = X (Y + c)$, where $c$ is a constant. Is $W$ still Log-Normally distributed? If not, can $W$ be approximated by a Log-Normal distribution? I know that the product of Log-Normal distributions is Log-Normal. Unfortunately, $Y+c$ is no longer a Log-Normal, since its support is $[c, \infty)$. On the contrary, the support of $W$ is again $[0, \infty)$, which does not exclude the possibility that $W$ follows a Log-Normal distribution. Moreover, the numerical approximation of $W$ seems indeed to be Log-Normal - see the superposition of the histograms below, with $\mu_x = 2$, $\mu_y = 4$, $\sigma^2_x = \sigma^2_y = 1$, and $c = 5$.","['probability', 'normal-distribution', 'probability-distributions']"
2420474,Is the proof of the derivative of $\sin(x)$ circular?,"The proof of $\frac{d}{dx}\sin(x)$ goes something like this: $$\begin{aligned}
\lim_{h\to0}\frac{\sin(x+h)-\sin(x)}{h}=\lim_{h\to0}\frac{\sin(x)\cos(h)+\cos(x)\sin(h)-\sin(x)}{h}\\
=\lim_{h\to0}\frac{\sin(x)(\cos(h)-1)+\cos(x)\sin(h)}{h}\\
=\lim_{h\to0}\frac{\sin(x)(\cos(h)-1)}{h}+\cos(x)\lim_{h\to0}\frac{\sin(h)}{h}\\
=0+\cos(x)\times1\\
=\cos(x)
\end{aligned}$$ My doubt about this is that it uses the limit of $\frac{\sin(h)}h$ and $\frac{\cos(h)-1}{h}$ in the proof. However, proving these two limits uses L'Hopital's rule, which uses the derivative of $\sin(x)$ and $\cos(x)$ to prove the limits. This causes a circular argument because we're using the derivative of $\sin(x)$ to prove the derivative of $\sin(x)$. Is there a way to prove these two limits without using L'Hopital's rule or just looking at the graph, or is there a way to find $\frac{d}{dx}\sin(x)$ without using these two limits? There is a nice way to prove the limits using geometry here , but I'm wondering if there's a way to do it without using this, either. Edit: The way I'm defining sine is by the unit circle definition, not the Taylor series one.","['derivatives', 'trigonometry', 'calculus']"
2420527,"Let $A, B$ a $3\times\,3$ matrices that sets $\ A^3+5AB=I, A^3-5BA=2I$, find $\det(A) $","Need help with this question: Let $A, B$ a $3\times\,3$ matrices that sets $\ A^3+5AB=I, A^3-5BA=2I$, find the determinate of $A$. So I know since $\ A(A^2+5B) = I$, $A$ is invertible and $\ A^{-1} = A^2+5B $, but what next? Thanks in advance","['matrices', 'linear-algebra', 'determinant']"
2420547,Series of functions $f_n (x)$ which are Differentiable and $\sum_{n=0}^\infty f_n (x) $ uniform convergence to non-differentiable function,"I got the following question on my Home work: show an example of Series of functions $f_n (x)$ which are differentiable and $\sum_{n=0}^\infty f_n (x)  $ uniform convergence to non-differentiable  function. (translated from Hebrew) My main problem is that even if i have $f_n (x)$ which i think is an example, I do not know to calculate $\sum_{n=0}^\infty f_n (x)$","['derivatives', 'sequences-and-series', 'calculus']"
2420616,"Show that, for each rational function $h(x)$, the function $f(x)=e^{x^2}$ doesn't admit a primitive in the form $G(x)=e^{x^2}h(x)$.","I'm trying this exercise: Show that, for each rational function $h(x)$, the function $f(x)=e^{x^2}$ doesn't admit ( on any interval in $\mathbb{R}$ ) a primitive in the form $G(x)=e^{x^2}h(x)$. I suppose that $G'(x)=f(x) \ \ \ \rm \forall x \in I \subset \mathbb{R}$ for a interval, so $G'(x)=e^{x^2}h'(x) + h(x)e^{x^2}2x$.
But $h(x)=\dfrac{p(x)}{q(x)}$ where $p(x)$ and $q(x)$ are polynomials, so $G'(x)=e^{x^2}\dfrac{p'(x)q(x)-q'(x)p(x)}{(q(x))^2}+\dfrac{2xe^{x^2}p(x)}{q(x)}=e^{x^2}$.
Simplifying the equation I get $p'(x)q(x)-q'(x)p(x)+2xp(x)q(x)=(q(x))^2$. Now, I would like to find a contradiction, but I can't. Perhaps the I interpreted wrongly the text and the polynomials $p(x)$ and $q(x)$ are integer polynomials?","['derivatives', 'polynomials', 'calculus']"
2420683,How to find the closed form of $\sum_{k=2}^{\infty}{\lambda(k)-1\over k}?$,Given that: $$\sum_{k=2}^{\infty}{\lambda(k)-1\over k}\tag1$$ Where $\lambda(k)$ is Dirichlet Lambda Function We are seeking to determine the closed form $(1)$ and came close to estimates it to $1-{\frac12}\left(\gamma+\ln{\pi}\right)$. where $\gamma=0.5772156...$ is Euler-Mascheroni Constant How can we evalauate the exact closed form for $(1)$?,"['real-analysis', 'sequences-and-series']"
2420691,Doubt about double limit definition.,"Let $(a_n)_{n \in \mathbb{N}}$ a sequence. We say that the $\lim_{n \rightarrow \infty} a_n = L$, if for every $\varepsilon >0$ given, there exists $n_0 (\varepsilon) \in \mathbb{N}$, such that $$n > n_{0}(\varepsilon) \Rightarrow |a_n - L| < \varepsilon $$ Consider $g: \mathbb{N}\times \mathbb{N} \rightarrow \mathbb{R}$, I would like to know how I would write $$\lim_{n \rightarrow \infty}\left( \lim_{k \rightarrow \infty} g(n,k)\right) = L $$ in terms of the $\varepsilon$-$\delta$ language. My progress First, I defined $\bar{g}(n)$ as $ \bar{g}(n) := \lim_{k\rightarrow \infty} g(n,k) $ . So fixing $n \in \mathbb{N}$, for every $\varepsilon/2 >0$ exists $k(n,\varepsilon) \in \mathbb{N}$, satisfying $$k > k(n,\varepsilon) \Rightarrow |g(n,k) - \bar{g}(n)| < \varepsilon/2.$$ On the other hand $\lim_{n \rightarrow \infty} \bar{g}(n) = L$. Consequently for every $\varepsilon/2 >0,$ exists $n_0(\varepsilon) \in \mathbb{N},$ satisfying $$n > n_0(\varepsilon) \Rightarrow |\bar{g}(n) - L| < \varepsilon/2 $$ Therefore, joining the two results above we have that the definition of the double limit would be: For every $\varepsilon>0,$ exists $n_0(\varepsilon)$ $\in$ $\mathbb{N}$, and for every $n> n_0(\varepsilon)$, exists $k(n,\varepsilon)$ $\in$ $\mathbb{N}$, such that $$n> n_0(\varepsilon),\hspace{0.1cm} k>k(n,\varepsilon) \Rightarrow |g(n,k) - L| < \varepsilon.  $$ Is this  correct? I'm not confident with my result. Thanks in advance","['definition', 'real-analysis', 'analysis', 'proof-verification']"
