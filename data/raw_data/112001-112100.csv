question_id,title,body,tags
1619742,What is an upper bound for number of semiprimes less than $n$?,"A semiprime is a number that is the product of two prime numbers. What is an upper bound for the number of numbers of the form $pq$ less than $n$ ? $p,q$ are prime numbers smaller than $n$ .","['analytic-number-theory', 'semiprimes', 'prime-factorization', 'number-theory', 'prime-numbers']"
1619772,A continuous random variable is memoryless if and only if it is an exponential random variable,"I'm reviewing some probability, and I remembered this quite interesting claim. A continuous random variable is memoryless if and only if it is an exponential random variable. Obviously, ""$\Longleftarrow$"" is easy to prove. But how does one prove ""$\Longrightarrow$""? I suppose, suppose we have an absolutely continuous CDF $F_{X}$ for a random variable $X$ which is memoryless, and define $S_{X} = 1 - F_{X}$. Then we have for $s > t$,
$$\mathbb{P}\left(X > s \mid X > t\right) = \dfrac{S_{X}(s)}{S_{X}(t)} = S_{X}(s-t)\text{.}$$
What to do from here, though, I'm not sure.","['probability-theory', 'probability', 'probability-distributions']"
1619809,Linear Algebraic Group acting on the co-ordinate ring,"Let $G$ be a linear algebraic group and let $C[G] = C[x_1,...,x_n] / I(G)$ denote the coordinate ring of $G$. (Note that $I(G)$ is the ideal containing all those polynomials in $C[x_1,...,x_n]$ of which elements of $G$ are the common zeroes.) Now, we the action of $C$- points of $G$ on $C[G]$ is defined by : 
          $$ G_C \times C[G] \to C[G]$$
          $$(x,f(y)) \mapsto f(x^{-1}y) $$ I am not able to see the condition $x_1.(x_2.f) = (x_1.x_2).f$ being satisfied by this. Please help me in realising that this indeed is a group action. Thank you !","['algebraic-groups', 'algebraic-geometry']"
1619826,Find polynomial in equation,"Find polynomial $f(x)$ with real coefficients that satisfied: $$x^2f(x) + 2 = f(x^2) + 2x^3$$ I find that $\deg f$ can be $1$ and $2$. $$\deg f = n $$ $$2+n=\max(2n,3)$$ First case $2=n$ Second case $n=1$ But what next?","['algebra-precalculus', 'polynomials', 'functions']"
1619838,"The limit of a uniform convergent sequence of isometries is an isometry (problem 6-3 of Lee's ""Riemannian manifolds"")","I'm trying to prove the following theorem: let $f_n : M \to N $ a sequence of isometries of Riemannian manifolds that converges uniformly to a function $f:M \to N$: prove that $f$ is an isometry too. What I did already: It is enough to prove the theorem for $M,N$ connected, so we can use the fact that $f$ is a Riemannian isometry if and only if it is a metric isometry, with respect to Riemannian distance. Now, $f$ is continuous because it is the limit of a uniformly convergent sequence of continuous maps, and preserves the distance because the distance function is continuous. So, $f$ is also injective, and then it is open by the invariance of domain theorem. Now, it suffices to show that $f$ is closed or surjective. Any help?","['smooth-manifolds', 'riemannian-geometry', 'differential-geometry', 'uniform-convergence']"
1619920,Prove f is not measurable,"Let $E$ be a non-measurable set contained in $(0,1)$. we will define $f(x) =x\textbf{1}_{E}(x) + x^3\textbf{1}_{E^C}(x)$ where $\textbf{1}_{E}(x)$ is the indicator function for the set $E$. Does $f$ is a measurable function? Answer: So I'm pretty sure the answer should be no, the function is not measurable. But I didn't succeed prove it formally, could anyone please help me prove it formally. Thanks.","['real-analysis', 'measure-theory']"
1619971,Find all $p$'s such that $p^4 + p^3 + p^2 + p +1$ is a perfect square.,Let $p$ be a prime number. Find all $p$'s such that $p^4 + p^3 + p^2 + p +1$ is a perfect square. I tried rewriting the expression as  $p^4 + p^3 + p^2 + p +1 = x^2 \iff (p^2 + p)(p^2 + 1)=(x - 1)(x + 1)$. Then I think I need to bound this using $x$ but am not sure how to.,['number-theory']
1619990,Behavior of derivative near the zero of a function.,"Suppose the function $f:[0,\delta) \to \mathbb{R}$ is continuous, differentiable in $(0,\delta)$ and $f(0)=0$. If the limit $\displaystyle \lim_{x \to 0+}\frac{f(x)}{f'(x)}= L$ exists, then is it always the case that $L = 0$. This seems to be true both for functions with well-behaved derivatives such as $f(x) = x,$ $$\lim_{x \to 0+} \frac{f(x)}{f'(x)}=\lim_{x \to 0+} \frac{x}{1}=0,$$ as well as functions with ""bad"" derivatives such as $$f(x) = \begin{cases}x \ln x &\mbox{if }x>0 ,\\0  &\mbox{if } x=0,  \end{cases},$$ where $$\lim_{x \to 0+} \frac{f(x)}{f'(x)}=\lim_{x \to 0+} \frac{x \ln x }{1+ \ln x}=0.$$ Is there a simple proof or counterexample?","['real-analysis', 'calculus', 'limits']"
1620059,More 'conceptual' reason of why $\int_{-\infty}^{+\infty}\text{sin}(x^2) = \int_{-\infty}^{+\infty}\text{cos}(x^2)$,"In our complex analysis course, as an application of the residue theorem and some clever contour integration, we computed the following integrals: $$\int_{-\infty}^{\infty}\text{sin}(x^2)\,\mathrm{d}x = \sqrt{\frac{\pi}{2}}$$ 
  And 
  $$\int_{-\infty}^{\infty}\text{cos}(x^2)\,\mathrm{d}x = \sqrt{\frac{\pi}{2}}$$ I noted that these two values are equal (not a very unusual observation). However, I was wondering if we could deduce just this result (i.e. the fact that they are equal) without actually computing them. The computation we made did not make this clear at all. It just happened to be a consequence of our calculations. So does anyone know a more conceptual reason? I'm not sure wheter this exists or should exist, but I had the following (more trivial) example in mind:
$$ \int_{0}^{\pi/2} \sin{x} \,\mathrm{d}x = \int_{0}^{\pi/2} \cos{x} \,\mathrm{d}x $$
Which can be proven by using a substitution $u = \pi/2-x$ and the fact that $\text{sin}(\pi/2-x) = \cos{x}$ Many thanks in advance.","['complex-analysis', 'integration', 'definite-integrals', 'residue-calculus']"
1620073,Why Brauer-Severi varieties over number fields satisfy the Hasse principle?,"If I understand correctly, a Brauer-Severi variety is supposed to be a variety $X/k$ such that it becomes isomorphic over $\overline{k}$ to some projective space $\mathbb{P}_{k}^{n}$. When $k$ is a number field, and if we suppose that $X(k_{v})\neq{\emptyset}$ for every place $v$ of $k$, then $X(k)\neq{\emptyset}$. I can't find the reference where this statement is proved, so I would appreciate it if you could tell me where exactly I can read the proof. Otherwise, I tried to prove it by using three facts: 1) the set of $k$-isomorphic Brauer-Severi varieties of dimension $n-1$ is parametrized by $H^{1}(k,\mathrm{PGL}_{n}(k))$, 2) The set of equivalence classes of central simple algebras $A$ over $k$ of dimension $n^{2}$ is parametrized again by $H^{1}(k,\mathrm{PGL}_{n}(k))$, 3) If $A$ is a central simple $k$-algebra of dimension $n$ such that $A\otimes_{k}k_{v}\cong{\mathrm{Mat}_{n}(k_{v})}$ as $k$-algebras and for every place $v$ of $k$, then $A\cong{A\otimes_{k}k}\cong{\mathrm{Mat}_{n}(k)}$ (this is supposed to be another example of the Hasse principle and it's called Albert-Brauer-Hasse-Noether theorem according to wikipedia...). I have the feeling that somehow I need to use these 3 results, but I can't figure out the way to do it. Thanks for your help!",['algebraic-geometry']
1620083,An identity involving binomial coefficients,"Prove the following identity
$$\displaystyle \sum_{i+j=m}\frac{(n-1) \binom{ai+n-1}{i} \binom{aj+1}{j}}{(ai+n-1)(aj+1)} =  \frac{n\binom{am+n}{m}}{am+n}$$
where $i = 0,1,\cdots,m$ and $m, n$ are positive integers and $a$ is a positive integer or even a fraction. One complete proof can be found in that famous book ""Concrete Mathematics"" by
Ronald L. Graham, Donald E. Knuth, and Oren Patashnik  which is widely used as a textbook in many computer science departments. Another complete proof can be found in the book written by Egorychev which is directly using the inversion rule of residue, see page 49 in the book ""Integral representation and the computation of combinatorial sums"". If you are reading that book, keep in mind that the index under $\sum$ can be extended to infinity because the contour integral has no pole when $k>n$.",['combinatorics']
1620148,Lie groups where $x \mapsto x^2$ is a diffeomorphism?,"In every Lie group $G$ the function $x \mapsto x^2$ is a local diffeomorphism in a neighbourhood of the identiy. (This is because its differential is: $v \mapsto 2v$ when considered as a map from $T_eG$ to itself). In some Lie groups it is a global diffeomorphism, for instance in $\mathbb{R}^n$. I would like to find more examples for Lie groups where the square is a global diffeomorphism. Are there any non-abelian groups where this holds?","['smooth-manifolds', 'differential-geometry', 'differential-topology', 'lie-groups']"
1620239,Find the minimum value of $\sin^{2} \theta +\cos^{2} \theta+\sec^{2} \theta+\csc^{2} \theta+\tan^{2} \theta+\cot^{2} \theta$,"Find the minimum value of $\sin^{2} \theta +\cos^{2} \theta+\sec^{2} \theta+\csc^{2} \theta+\tan^{2} \theta+\cot^{2} \theta$ $a.)\ 1 \ \ \ \ \ \ \ \ \ \ \ \ b.)\ 3 \\
c.)\ 5 \ \ \ \ \ \ \ \ \ \ \ \ d.)\ 7 $ $\sin^{2} \theta +\cos^{2} \theta+\sec^{2} \theta+\csc^{2} \theta+\tan^{2} \theta+\cot^{2} \theta \\ 
=\sin^{2} \theta +\dfrac{1}{\sin^{2} \theta }+\cos^{2} \theta+\dfrac{1}{\cos^{2} \theta }+\tan^{2} \theta+\dfrac{1}{\tan^{2} \theta } \\
\color{blue}{\text{By using the AM-GM inequlity}} \\
\color{blue}{x+\dfrac{1}{x} \geq 2} \\ 
=2+2+2=6 $ Which is not in options. But I am not sure if I can use that $ AM-GM$ inequality in this case. I look for a short and simple way . I have studied maths upnto $12$th grade .",['trigonometry']
1620240,Is $z+\overline{z}$ an Analytic function? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How can I immediately demonstrate that $z+\overline z$ is not an analytic function?","['complex-analysis', 'functions']"
1620250,Every open set in $\mathbb{R}^n$ is the increasing union of compact sets. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question $X= \bigcup K_m$, where $K_m$ is a increasing sequence of compact sets and $X$ is the open set.","['compact-manifolds', 'general-topology', 'compactness']"
1620314,Induced ring homomorphism by map on spectra,"I know that when we have a ring homomorphism $$ \phi: A\rightarrow B$$ this induces continuous map between the spectra $$ \phi': \operatorname{Spec} B\rightarrow \operatorname{Spec}A$$ which maps $p$ to $\phi^{-1}(p)$. What I am wondering about is the other direction. Suppose we have a map between the spectra, is it possible to determine (explicitly) the induced map on the ring? Is it absolutely necessary to consider a morphism affine schemes to do this? My particular question concerns showing that $A$ is finitely generated as a $\mathbb C$-algebra, i.e. there exists a surjective morphism of rings $\mathbb C[x_1,..., x_n]\rightarrow A$, knowing that $A\otimes_{\mathbb C} B$ is finitely generated (i.e. there exists a surjective morphism of rings  $\mathbb C[x_1,..., x_n]\rightarrow A\otimes_{\mathbb C} B $) using the fact that $\operatorname{Spec}(A\otimes_\mathbb C B)=\operatorname{Spec} A\times \operatorname{Spec} B$. Or is this equality only true in the reduced and finitely generated case to begin with?","['algebraic-geometry', 'commutative-algebra']"
1620326,Characteristic function and moment generating function: differentiating under the integral,"In order to justify the interchange of the derivative and integral when differentiating a characteristic function, one can use the dominated convergence theorem: $$\frac{d}{dt} \int e^{itx} P(dx) = \lim_{h \to 0} \frac{1}{h} \int (e^{ihx}-1) e^{itx} P(dx).$$ Since $|e^{ihx}-1| \le |hx|$, we have $$\frac{1}{h} \int |e^{ihx}-1| P(dx) \le \int |x| P(dx),$$
  so if we assume the random variable is in $L^1$, we may push the derivative under the integral. Similarly, if the random variable is in $L^k$, then we can push the $k$th derivative under the integral. I am trying to find an analogous statement for moment generating functions, but I am having trouble generalizing the above argument. Under what conditions can we do this for MGFs? Any hints would be appreciated, but I would prefer an argument that uses dominated convergence rather than Leibniz's integral rule.","['characteristic-functions', 'real-analysis', 'moment-generating-functions', 'probability-theory']"
1620341,"What is an example of a non-zero ""ring pseudo-homomorphism""? [duplicate]","This question already has answers here : Ring homomorphism with $\phi(1_R) \neq1_S$ (2 answers) Closed 8 years ago . By ""pseudo ring homomorphism"", I mean a map $f: R \to S$ satisfying all ring homomorphism axioms except for $f(1_R)=f(1_S)$. Even if we let this last condition drop, there are only two ring pseudo-homomorphisms from $\Bbb Z$ to $\Bbb Z[\omega]$ where $\omega$ is any root of unity, for example. They are the identity homomorphism and the ""$0$ pseudo-homomorphism"". I couldn't find a non-zero example. It is easy to conclude that $0=f(a)(1_S-f(1_R))$, so I know that the counterexample will have to be some $S$ with zero-divisors.","['abstract-algebra', 'ring-theory']"
1620351,"If $f$ is twice differentiable, $\big(f(y) - f(x)\big)/(y-x)$ is differentiable","Suppose $f: \mathbb{R} \to \mathbb{R}$ is a $C^{1}$ function. Then, define a new function $F: \mathbb{R}^{2} \to \mathbb{R}$ by:
$$
F(x,y) = \begin{cases}
  \displaystyle \frac{f(y) - f(x)}{y - x} &\text{ if } x \neq y \\
  \displaystyle f'(x) &\text{ otherwise.}
\end{cases}
$$
Then, if $f''(x)$ exists, $F$ is differentiable. I can prove that $F$ is differentiable if $x \neq y$, since under these conditions $F_{x}$ and $F_{y}$ are $C^{1}$. So it's left to prove $F$ is also differentiable if $x = y$. At first, I conjectured that, for example, $F_{x} (a,a)$ would be $f''(a)/2$, but I'm having a hard time proving it. I started using the definition $\lim_{h \to 0} (F(a+h, a) - F(a,a)) / h$ and applying the MVT found $\bar{a}$ between $a$ and $a + h$ s.t. this difference quotient is:
$$
\frac{1}{h}(f'(\bar{a}) - f'(a))
$$
so I tried dividing and multiplying by $\bar{a} - a$, thinking it would be possible to prove that $\lim_{h \to 0} (\bar{a} - a)/h = 1$, but so far I've only been able to bound it above by $1$. Is it true? Does this conjecture even makes sense? I'm lost in thinking about any other candidates for the differential in these points. Any help would be appreciated!","['multivariable-calculus', 'partial-derivative', 'derivatives']"
1620366,How to keep aspect ratio and position of rectangle inside another rectangle?,"This problem has plagued me for many years. Given two rectangles how do I resize the first to fit into the second while preserving the aspect ratio? The second rectangle could be bigger or smaller than the first. Here are the variables I have to work with where the first rectangle is represented as an image: // these variables contain the image and container sizes
imageWidth
imageHeight
targetWidth
targetHeight
adjustedImageWidth
adjustedImageHeight

imageAspectRatio = imageWidth/imageHeight;
targetAspectRatio = targetWidth/targetHeight; What I have found so far as the next step (from open source code): if (imageAspectRatio > targetAspectRatio) {
    adjustedHeight = targetWidth / imageAspectRatio;
else
    adjustedWidth = targetHeight * imageAspectRatio;
}

// define size and position of image
// to fit inside second rectangle I do not know what to do next.","['algebra-precalculus', 'rectangles', 'ratio']"
1620371,Solving a differential equation with Bernoulli's Method,"What approach do you take to solve the differential equation $ y' + (6y/x) = (y^3)/ x^5\ $ through the use of Bernoulli's method? I've assumed u = y^(-2) for substitution, but I don't know where to go from there. The answer is  y $ ((C\x^2\) + (1/8x^4))^(-.5) \ $","['bernoulli-numbers', 'ordinary-differential-equations', 'linear-algebra']"
1620373,Can I extend mathematical induction to real numbers? [duplicate],"This question already has answers here : Induction on Real Numbers (7 answers) Closed 8 years ago . Here is my rather simple idea. I will treat the set of real numbers as a set of discrete continuities, each separated by an Epsilon ball that tends to 0. So, let's say P(b) is true.
We then assume P(k) is true, and prove that P(k+e) is true, where e goes to zero. I just want to know if this is a valid technique or not because our teacher said that mathematical induction can only be applied to discrete structures, but I see no difficulty in treating a continuous system as a set of infinitesimal discrete quantities. Mak","['induction', 'real-numbers', 'discrete-mathematics']"
1620424,"Prove that if $(a^2+b^2+c^2+d^2)^2 > 3(a^4+b^4+c^4+d^4)$, then, using any three of them we can construct a triangle.","Prove that if $a,b,c,$ and $d$ are positive numbers and satisfy $(a^2+b^2+c^2+d^2)^2 > 3(a^4+b^4+c^4+d^4)$, then, using any three of them we can construct a triangle. I find it hard to go from the given inequality to the triangle inequality for $3$ of $a,b,c,d$. Expanding it may help but that would get ugly. I did it and got $d^2 (2 a^2+2 b^2+2 c^2-2 d^2)+b^2 (2 a^2-2 b^2+2 c^2)+a^2 (2 c^2-2 a^2)-2 c^4$. Also doing a ravi substitution here seems almost impossible to do with $4$ variables.","['contest-math', 'inequality', 'cauchy-schwarz-inequality', 'geometry']"
1620425,Estimate Grade Distribution Based on Performance of Each Question,"As the title states, I would like to be able to estimate the grade distribution of an exam based on the mark distribution of each individual question. To give a quick example of what I mean, suppose an exam has 2 questions worth 2 and 3 marks respectively: Question 1: 20% receive 0 marks, 50% receive 1 mark, 30% receive 2
  marks. Question 2: 10% receive 0 marks, 30% receive 1 mark, 40% receive 2
  marks,  20% receive 3 marks Based on these individual distributions, I would like to find the overall distribution of marks (from 0 to 5). My initial thoughts were: I could assume the performance on each question is independent of the other questions. However, I thought this unrealistic as a stronger student will likely get both Q1 and Q2 correct whereas a weaker student will likely get both wrong I could initially assign each student a 'strength' based on a normal (or other) distribution. Those at the right tail would be more likely to gain full marks and those at the left tail would be more likely to receive zero marks. However, such a model would not account for 'silly mistakes' or 'flukes'; i.e. even though a student's 'strength' is very large, there is still a probability of making a careless error or the probability a student guesses a question correct even though their 'strength' is very low. I also considered using models from my CT4 (actuarial stats) course, but I struggled with applying assumptions made for mortality investigations to my current problem. Finally, I am familiar with the saying ""all models are wrong but some are useful"", but I would like to try get an accurate model if possible! Note: I do have actual numbers to verify any potential solution presented here and I will be happy to share them if need be :)","['statistics', 'probability-distributions']"
1620434,Exterior derivative of a coordinate function,"I'm starting to learn about differential forms.  From what I understand the coordinate differential forms $dx^1, \dots, dx^n$ are actually the exterior derivatives of the coordinate functions $x^1, \dots, x^n$ (not necessarily Cartesian coordinates).  How is this shown? The only way I know how to take the exterior derivative of a function ($0$-form) $f$ is to use the formula $df = \frac {\partial f}{\partial x^1}dx^1 + \cdots + \frac {\partial f}{\partial x^n}dx^n$, but applying this to a coordinate function $x^1$ would give $$d(x^1) = \frac{\partial x^1}{\partial x^1}dx^1 + \cdots + \frac{\partial x^1}{\partial x^n}dx^n = dx^1$$ which is wholly unconvincing to me.  If someone showed me this proof I'd think that they'd come up with the method just because they knew what the answer should be. I think the problem is that I need a definition of the exterior derivative that doesn't already contain the coordinate functions and then I can confirm that for any arbitrary smooth $f$ the exterior derivative $df$ does in fact equal $\frac {\partial f}{\partial x^1}dx^1 + \cdots + \frac {\partial f}{\partial x^n}dx^n$ where $dx^i$ is the exterior derivative of the coordinate function $x^i$. So what is the rigorous way to show that the things that we expand the $1$-form $df$ in ($dx^1, \dots, dx^n$ in the usual notation) are the same things that we get be taking the exterior derivative of each coordinate function ($x^1, \dots, x^n$)?","['differential-forms', 'differential-geometry']"
1620450,Runge Approximation Theorem in Hormanders text,"NOTE : This excerpt comes form Hormander's text, An Introduction to COmplex Analysis of Several Variables . STATEMENT: (Runge approximation theorem)Let $\Omega$ be an open set in $\mathbb{C}$ and $K$ a compact subset of $\Omega$. The following conditions on $\Omega$ and $K$ are equivalent: (a) Every function which is analytic in a neighborhood of $K$ can be approximated uniformly on $K$ by functions in $A(\Omega)$. (b)The open set $\Omega\backslash K=\Omega \cap K^c$ has no components which is relatively compact in $\Omega$. (c)For every $z\in\Omega\backslash K$ there is a function $f\in A(\Omega)$ such that $$|f(z)|>\sup_k |f|$$ Proof :To prove that $(b)\rightarrow (a)$ it suffices to show that every measure which is orthogonal to $A(\Omega)$ is also orthogonal to every function which is analytic in a neighborhood of $K$, for the theorem is then a consequence of the Hahn-Banach theorem. Set $$\varphi(\zeta)=\int(z-\zeta)^{-1}d\mu(z),\;\;\;\;\; z\in K^c$$ By theorem 1.2.2, $\varphi$ is analytic in $K^c$, and when $\zeta\in \Omega^c$ we have $$\varphi^{(k)}(\zeta)=k!\int(z-\zeta)^{-k-1}d\mu(z)=0\;\;\;\;\;\;\text{for every}\;k$$ QUESTION : So I have two questions regarding Hormander's proof. The first one is how does the problem reduce to just using Hahn-Banach theorem. Secondly, why does $\varphi^{(k)}$ vanish for all $k$ when $\zeta\in\Omega^c$.","['complex-analysis', 'analysis']"
1620457,relations between homology and cohomology,"Let $p$ be a prime number and $X$ a topological space. Are the following  equivalent? (1) In the homology module $H_*(X;\mathbb{Z})$ there does not exist any element of order $p$. (2) In the cohomology module $H^*(X;\mathbb{Z})$ there does not exist any element of order $p$. Could you explain it? I want to use the Universal Coefficient Theorem but do not know how to use. We can impose extra conditions, such as finite $CW$-complexes, or manifolds, on $X$. But we may not assume $X$ to be a closed and orientable manifold. Thanks!","['homology-cohomology', 'modules', 'abstract-algebra', 'homological-algebra', 'algebraic-topology']"
1620460,"$(\mathbb{R}^n,\|\cdot\|_{p})$ is isometrically isomorphic to $(\mathbb{R}^n,\|\cdot\|_{q})$ iff $p=q,$","I want to prove, that $(\mathbb{R}^n,\|\cdot\|_{p})$ is isometrically isomorphic to $(\mathbb{R}^n,\|\cdot\|_{q})$ iff $p=q,$ I have tried looking the unitary balls, and I have been proved that $(\mathbb{R}^n,\|\cdot\|_{1})$ is not isometrically isometric to any other $p$-norm.","['functional-analysis', 'real-analysis', 'analysis']"
1620487,How to show a straight line homotopy is continuous?,"Given $f$ and $g$ continuous maps from $X$ into $\mathbb{R}^{2}$, how to show that the straight line homotopy map $F(x,t)=(1-t)f(x)+tg(x)$ is continuous?","['algebraic-topology', 'general-topology', 'continuity', 'homotopy-theory']"
1620540,First countable + separable imply second countable? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . The community reviewed whether to reopen this question 1 year ago and left it closed: Original close reason(s) were not resolved Improve this question In topological space, does first countable+ separable imply second countable? If not, any counterexample?","['examples-counterexamples', 'second-countable', 'separable-spaces', 'first-countable', 'general-topology']"
1620610,Product of perfect maps is perfect,"Suppose $X=\prod_{s\in S}X_s$ and $Y=\prod_{s\in S}Y_s$ have the product topology and $f_s:X_s\to Y_s$ are functions. If each $f_s$ is perfect then $f=\prod_{s\in S}f_s$ is perfect. I already proved $f$ is continuous and the fibers $f^{-1}(y)$ are compact. But I haven't proved $f$ is closed yet. In this answer Finite Product of Closed Maps Need Not Be Closed , it is shown the product of closed maps need not be closed, so the compactness of the fibers must be important, but how? Say $A\subseteq X$ is closed. Which way do I need to follow to prove $f(A)$ is closed? I don't know how to start.",['general-topology']
1620619,"Do there exist an infinite number of integer-solutions $(x,y,z)$ of $x^x\cdot y^y=z^z$ where $1\lt x\le y$?","Question : Do there exist an infinite number of integer-solutions $(x,y,z)$ of $x^x\cdot y^y=z^z$ where $1\lt x\le y$ ? Motivation : After struggling to find a solution, I've just got one solution, which is 
$$(x,y,z)=(1679616, 2985984, 4478976).$$ In the following, I'm going to write how I got this solution. Letting $d$ be the greatest common divisor of $x,y,z$, we can represent
$$x=ad, y=bd, z=cd$$
where $a,b,c$ are coprimes with each other. Then, we get
$$d^{a+b-c}\cdot a^a\cdot b^b=c^c.$$ In the following, let's consider without the condition $x\le y$. Here, I suppose $$a=2^m, b=3^n, a+b-c=1.$$ (As a result, this supposition works.) Then, we get
$$d=\frac{c^c}{2^{ma}\cdot 3^{nb}}.$$ Hence, letting $c=2^k\cdot 3^l$, if 
$$kc\ge ma=m\cdot 2^m, lc\ge nb=n\cdot 3^n,$$
then $d$ is an integer. Since $(m,n)=(4,2)$ satisfies the above conditions, then we get $d=2^8\cdot 3^6=186624.$ Hence we can get 
$$x=9d=2^8\cdot 3^8=1679616, y=16d=2^{12}\cdot 3^6=2985984, z=24d=2^{11}\cdot 3^7=4478976.$$
Note that here I interchanged $x$ and $y$. P.S : I was surprised to get this solution because I got this almost by chance. So, I don't know the other solutions. If you have any helpful information, please teach me.","['number-theory', 'diophantine-equations']"
1620627,Prove that there exists a sequence of continuous functions $f_n(x)$ such that $f_n \rightarrow f$ pointwise on this interval.,"Suppose that the real-valued function $f(x)$ is nondecreasing on the interval $[0,1]$. Prove that there exists a sequence of continuous functions $f_n(x)$ such that $f_n \rightarrow f$ pointwise on this interval. I've been considering problem for a while. The main results that I know of are all about converging almost everywhere. I want to construct $f_n$ but don't know where to start.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1620646,Where am I wrong at deriving the formula of volume of cone?,"I was deriving the formula of cone volume yesterday but I was stuck at a place.My reason for asking help in Math SE is because I was not doing it by looking at any book or the internet.So,I want your help to know where my thinking went wrong. My attempt: In a right circular cone with base radius $r$ and height $h$,both keep changing as we move upward.So,my integral must take into account the change of height (from $0$ to complete length $h$) and change of radius (from base radius $r$ to $0$ at the apex.) So $$\begin{align}
V_{cone} & =\int_r^0\int_0^h\pi r^2 dr \space dh \\
   & =\int_r^0\pi r^2 dr \cdot \int_0^h\pi r^2  dh
\end{align}$$ In the first integral I'm treating $r$ as a variable but in the second integral I'm treating it as a constant. Solving this does not yield the formula $V_{cone}=\frac13\pi r^2h$. Where I made a mistake?","['volume', 'calculus', 'geometry']"
1620689,Complement of the Solid Torus in $S^3$ is Again a Solid Torus,"On pg. 48 of Hatcher's Algebraic Topology , the author writes that the $3$-sphere $S^3$ can be thought of as the union of two solid torus. First a formal reasoning is given which is $S^3=\partial D^4 = \partial(D^2\times D^2) = (\partial D^2\times D^2)\cup (D^2\times \partial D^2)$ This is clear. But then the author gives a geometric interpretation which is as follows. Think of $S^3$ as the one point compactification of $\mathbf R^3$. Let $T=S^1\times D^2$ be the first solid torus. The second solid torus is the closure of the complement of $T$ in $\mathbf R^3$ along with the compatification point at infinity. The statement in italics is not clear to me. How do we see this as a solid torus?","['algebraic-topology', 'general-topology']"
1620712,Good text to start studying topological games?,"Topological games and some similar infinite games seem to be often used used as a tool in some areas of general topology , but also some other areas, such as Ramsey
theory , filters , etc.
Probably the best known are Banach-Mazur and Choquet game , but many other games of similar nature have been studied. Various questions about topological
games and their winning strategies have also been asked on this site. (And there were also posts specifically about Banach-Mazur
game and Choquet game .) Apart from being a useful tool in some areas of research, they seem to be rather fascinating topic by itself, since there are some results which seem, at the first glance, rather counter-intuitive. (Especially when compared with finite games.) For example, it is possible that topological games is not determined, i.e., it is possible that neither of the two players has a winning strategy. (As far as I know, this is related to Axiom of Choice and Axiom of determinacy.)
Another seemingly counter-intuitive fact is that for some games there might be difference between winning strategy and winning tactic (a.k.a. stationary strategy, which is a strategy where the move depends only on the position and not on the sequence of moves which lead to the position). Is there some good text (book, thesis, lecture notes) suitable to start studying topological games and other similar infinite games? Of course, I could start backwards by taking some paper using topological games in connection with some topic I am interested in or some survey article and whenever I stumble upon some unfamiliar result or notion, I could try to track down some references and learn about this particular thing. But if there is some reference which develops infinites game in a somewhat more systematic way, it might be more suitable way to start studying this topic. (It is also possible that what I am asking is not a reasonable question in this sense: Maybe if somebody understands the basic idea of the topological games and winning strategies, then the next logical step to gain enough practice in adapting this technique to various specific situations rather than studying some systematic development of the topic.) I suppose that for such specific topic there will not be too many suggestions. So I will be grateful for any suggestion . But since in the book recommendation and reference request it is advised to be specific , I will also add the following: What would I mostly expect from the text? I would hope that after studying this text I would have better understanding of the seemingly counter-intuitive statements mentioned before. And I would also hope to be able to follow better proofs using topological games and maybe even to be able to come up with my own proofs in situations where topological games can be used. If it is relevant to the question, I will also describe my background in this area. (Although I guess that if this post is supposed to be useful for other people as well, there should not be that much stress on this.) I understand the basic results about Banach-Mazur game and Choquet game given in Chapter 8 of Kechris: Classical Descriptive Set Theory. (I think I understand them well enough that probably I would be able to reproduce the proofs given enough time. I have not read Chapters 20 and 21, which also deal with topological games. I suppose that studying some material from the preceding parts of the book before starting these two chapters will be needed.) I have also been at some talks on topological games (in connection with Baire spaces ), which I was more-or-less able to follow.","['reference-request', 'infinite-games', 'descriptive-set-theory', 'book-recommendation', 'general-topology']"
1620724,When is LIATE simply wrong?,"I'm currently teaching Calculus II, and yesterday I covered integration by parts and mentioned the LIATE rule. I also gave the usual ""it works 99% of the time"", but started wondering whether there are any cases where LIATE simply gets the choice of $u$ and $v'$ wrong. (For those of you who don't know what LIATE is, check out https://en.wikipedia.org/wiki/Integration_by_parts#LIATE_rule ) I don't consider the example listed at the link above to be what I'm looking for, because I don't consider $e^{x^2}$ to be an exponential function here (only $a^{bx}$). (I don't consider $\tan x$ to be a ""trig"" function, either, in this context.) Does anyone have a ""pet"" example that they show?","['integration', 'calculus']"
1620737,Probabilistic method proof,"Let $v_1, v_2,...,v_n \in \mathbb{R}^n$ be unit vectors. Use probabilistic method to show that there exist constants $a_1, a_2,..., a_n \in \{-1,1\}$ such that
$||a_1 v_1 + a_2 v_2 + ... + a_n v_n ||_2 \leq \sqrt{n}$. I think I should make a n random variable $X_i$ that take values in $\{-1,1\}$ each with probability ½, and somehow show that the probability that the squared $2-$norm of the linear combination with coefficients $X_i$ is greater than n, is less than 1. But I am not sure how I should go about that.
Any hint would be appreciated.","['probability', 'probabilistic-method']"
1620831,Derivative of a real function (the magnitude of a variable) w.r.t a complex variable,"Let $z=x+iy$ and let $f(z) = |z| = \sqrt{x^2+y^2}$. Is it possible to get a derivative of $f(z)$ w.r.t the complex variable, $z$? I know the Cauchy-Riemann equations are not satisfied, since $f(z)=u(x,y)+iv(x,y)\Rightarrow v(x,y)=0$ in my case, but I'm wondering if there's any approach I can take to go in a certain direction to minimize $f(z)$ in this case. Thanks.","['complex-analysis', 'calculus']"
1620833,Solution of $ (dy/dx)^2 = (x^2+y^2) $,"How do I find the solution of:
$$ (dy/dx)^2 = (x^2+y^2). $$ 
I tried $ y=tx$ and $x=r\cos(t) ,y=r\sin(t)$ substitutions but they did not help. I am not  able to change it into any variable separable form and the only meaning I can make out is that the slope at any point is equal to the distance of it from origin.",['ordinary-differential-equations']
1620838,"Is it always possible to find the roots of $P(z)=az^4+bz^3+cz^2+bz+a$, where $a,b,c \in \mathbb{R}^*$, by first dividing both sides by $z^2$?","A classic way to solve quartics in the form $P(z)=az^4+bz^3+cz^2+bz+a$, if we know that the roots lie on the unit circle, is to divide both sides by $z^2$ and then use the fact that if $$z=\cos \theta + i \sin \theta$$ then $$z^n + z^{-n}=2 \cos n\theta \qquad (*)$$ When the roots lie on the unit circle, this method will most certainly yield all of the roots of $P(z)$ because we then have the equation $$a \left ( z^2+z^{-2} \right )+b \left ( z+z^{-1} \right )+c=0$$ which by ($*$) then becomes $$2a \cos (2\theta) + 2b \cos \theta + c=0$$ This is a quadratic that can be solved explicitly for $\cos \theta$. One can then discover $\sin \theta$ and hence obtain all of the roots, as they must all be in the form $z=\cos \theta + i \sin \theta$. My question is concerning the case when the roots do not lie on the unit circle. We must then let the roots be $z=R \left ( \cos \theta + i \sin \theta \right )$. However, proceeding with the above steps, we end up with the quadratic $$2aR \cos (2\theta) + 2bR \cos \theta + c=0$$ This is different from the previous case because now we have another unknown $R$ to deal with. Will the above method still work despite this problem? How can we go about finding $R$?","['polynomials', 'trigonometry', 'complex-numbers']"
1620852,How to proof that $f^{-1}(\sigma(\mathcal C))\subseteq\sigma(f^{-1}(\mathcal C))$?,"Let $f:X\to Y$ be a function, $\mathcal C$ be a family of subsets of $Y$. I am convinced that $f^{-1}(\sigma(\mathcal C))=\sigma(f^{-1}(\mathcal C))$, where $\sigma(\mathcal A)$ is the $\sigma$-algebra generated by $\mathcal A$. The part $\sigma(f^{-1}(\mathcal C))\subseteq f^{-1}(\sigma(\mathcal C))$ is quite straight forward since $f^{-1}$ behave nicely with set-theoretic operations but I cannot see how to prove its converse. I tried to characterize $\sigma(\mathcal A)$ by seeing how it can be constructively define but my effort was not very fruitful. (From this post by Mr.Asaf, it seems that I must use higher cardinal.) So how should I prove $f^{-1}(\sigma(\mathcal C))\subseteq\sigma(f^{-1}(\mathcal C))$ ? It is really hard or perhaps I missed something silly? Any hint would be appreciate. Thank you in advance.","['real-analysis', 'measure-theory', 'elementary-set-theory']"
1620855,Basic understanding of a metric.,"What is a metric ? Do a metric depend on the system of coordinates I use ? Does it depend on surfaces (or higher dimensional manifolds. Correct me if I'm wrong using the word) the coordinate frames are chosen on ? Is there any general form for a metric? In this course it's mentioned Gauss pointed it out as restriction for an infinitesimal metric or distance function on surfaces to be
$$(dS)^2 = g_{xx} (x,y)(dx)^2 + g_{xy} (x,y)dxdy + g_{yy} (x,y)(dy)^2.$$ And is it that mentioned quadratic form restricted for a metric to look like a Euclidean metric $(ds)^2 = (dx)^2 + (dy)^2$ , is just a belief working in this comment of Gauss or is there any proper logical explanation to this ?","['coordinate-systems', 'differential-geometry', 'geometry']"
1620888,Are $\frac{\pi}{e}$ or $\frac{e}{\pi}$ irrational?,"Is it clear whether $\displaystyle \frac{\pi}{e}$ or $\displaystyle \frac{e}{\pi}$ are irrational or not? If not, then there would exist $q,p\in \mathbb{Z}$ such that $$p\cdot \pi = q\cdot e$$","['number-theory', 'irrational-numbers']"
1620905,What is the gradient of a distribution?,"Let $\Omega\subseteq\mathbb R^d$ be open and $\mathcal D(\Omega)$ be the set of $C^\infty(\Omega)$-functions with compact support equipped with a locally convex topology. Let $\mathcal D(\Omega)'$ be the dual space of $\mathcal D(\Omega)$ and $p\in\mathcal D(\Omega)'$, i.e. $$p:\mathcal D(\Omega)\to\mathbb R$$ is linear and continuous. What is meant by the gradient $\nabla p$ of $p$ as it is been used in the paper A Remark on the Characterization of the Gradient of a Distribution ?","['functional-analysis', 'distribution-theory']"
1620929,Compound Distribution --- Normal Distribution with Normally Distributed Mean,"Could someone please point me to a source or suggest ways in which we can obtain the Distribution, Density Functions, Expected Value, etc. of a Normal Distribution whose mean is distributed Normally. Given, $$X \sim N[Y,\sigma^2_{X}]$$ $$Y \sim N[\mu_{Y},\sigma^2_{Y}]$$ To Determine, $$f_{X}(x), F_{X}(x), E(X), E(X^{2})$$ Related Question when Variance is Log Normal Compound Distribution — Normal Distribution with Log Normally Distributed Variance Wikipedia Link: This is listed as example at this link without proof. https://en.wikipedia.org/wiki/Compound_probability_distribution#Examples Related General Question Starting with the above special case, it quickly becomes apparent there are many combinations possible. Hence was wondering if there were general techniques to derive the density, distribution function, expected value, higher moments, conditional expectations etc. of compound distributions and some source where certain combinations and results therein were given with detailed steps and complete proofs: https://math.stackexchange.com/questions/1614212/compound-distributions-basic-techniques-and-key-general-results-from-first-p","['probability-theory', 'normal-distribution', 'probability-distributions']"
1620945,Variance of Negative Binomial Distribution (without Moment Generating Series),"Given the discrete probability distribution for the negative binomial distribution in the form $$P(X = r) = \sum_{n\geq r} {n-1\choose r-1} (1-p)^{n-r}p^r$$ It appears there are no derivations on the entire www of the variance formula $V(X) = \frac{r(1-p)}{p^2}$ that do not make use of the moment generating function. I have successfully managed to compute the mean without this as follows; \begin{align*}
\mu = \sum_{n\geq r} n{n-1\choose r-1} (1-p)^{n-r}p^r 
&= \sum_{n\geq r} \frac{n(n-1)!}{(r-1)!(n-r)!}(1-p)^{n-r}p^r \\
&= \frac{r}{p} \sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1}\\
\end{align*}
Having already factored our claimed mean of $r/p$, it remains to show that $\sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1} = 1$ which is done by reindexing (both $r$ and $n$) and realizing this as the sum of a probability mass function for a negative binomial distribution. Indeed, letting $k = r+1$ followed by $m = n+1$, we find \begin{align*}
\sum_{n\geq r} \frac{n!}{r!(n-r)!}(1-p)^{n-r} p^{r+1} &= \sum_{n\geq k-1}\frac{n!}{(k-1)!(n-k+1)!}(1-p)^{n-k+1}p^k\\
&=  \sum_{m\geq k}\frac{(m-1)!}{(k-1)!(m-k)!}(1-p)^{m-k}p^k\\
&=  \sum_{m\geq k}{m-1\choose k-1}(1-p)^{m-k}p^k  = 1
\end{align*} Does anyone know of a way to demonstrate that $\sigma^2 = V(X) = \frac{r(1-p)}{p^2}$ in this fashion?","['variance', 'probability', 'negative-binomial', 'probability-distributions']"
1620961,Can the cohomology of the Grassmannian identified with the cohomology of a specific dense open subvariety?,"Let $(\mathbb{C}^{2p},Q)$ be a $2p$-dimensional complex vector space equipped with a nondegenerate symmetric bilinear form $Q$ where $p\geq 3$. Let $l\leq p-2$. You may assume that $l$ is odd if this helpful. Consider the Grassmannian $\bar{Y}=\mathbb{G}(2(l-1),2p)$ parametrizing $2(l-1)$-dimensional linear subspaces of $\mathbb{C}^{2p}$. Let $W$ be a nondegenerated $2(l-1)$-dimensional subspace. Let $G=\mathrm{SO}_{2p}$. The group $G$ acts on $\bar{Y}$ and we can consider the orbit of $W$ under the action of $G$, this is
$$
Y:=GW=\{V\in\bar{Y}\mid V\text{ nondegenerated}\}=G/Q
$$
where $Q$ is the stabilizer of $W$ in $G$ ($Q=\mathrm{Stab}_G(W)=\{g\in G\mid gW=W\}$). The homogeneous space $Y$ is a dense open subset of $\bar{Y}$ with respect to the Zariski topology. My question is now the following: do we have an isomorphism in cohomology $H^*(Y,\mathbb{Z})\cong H^*(\bar{Y},\mathbb{Z})$ where the isomorphism is as rings, i.e. is supposed to preserve the cupproduct? Is there maybe a general satement which implies this isomorphism? Or a specific argument to prove the isomorphism in this situation? There might be an obvious reason for this which I don't know. I see that we cannot always hope to identify the cohomology of a space with a the cohomology of a dense open subspace, eg. $H^*(\mathbb{R},\mathbb{Z})\not\cong H^*(\mathbb{R}\setminus\{\text{pt}\},\mathbb{Z})$, but I hope that it is true at least in the situation described above. Any help is appreciated! Thanks!","['homology-cohomology', 'algebraic-geometry', 'grassmannian', 'homogeneous-spaces', 'algebraic-groups']"
1620969,"Prob. 6, Chap. 1, in Rudin's PMA [duplicate]","This question already has answers here : Prob. 6 (d), Chap. 1, in Baby Rudin, 3rd ed: How to complete this proof? (5 answers) Closed 8 years ago . Here's problem $6$ in Chapter $1$ in the book Principles of Mathematical Analysis by Walter Rudin, $3$rd edition: Fix a real number $b$, such that $b > 1$. $(a)$ If $m, n, p, q$ are integers, $n > 0$, $q > 0$, and $r = m/n = p/q$, then (I've managed to show that) $$\left( b^m \right)^{1/n} = \left( b^p \right)^{1/q}.$$ Hence it makes sense to define $$b^r \colon= \left(b^m\right)^{1/n}.$$ $(b)$ (I've also managed to show that) for any rational numbers $r, s$, we have 
$$b^{r+s} = b^r b^s.$$ $(c)$ For any real number $x$, define the set $B(x)$ as follows: $$B(x) \colon= \left\{ \ b^t \ \colon \ t \ \mbox{ is rational}, \ t \leq x \ \right\}.$$ We can then prove that $$b^r = \sup B(r)$$ when $r$ is a rational number. Hence it makes sense to define $$b^x \colon= \sup B(x) = \sup \left\{ \ b^t \ \colon \ t \ \mbox{ is rational}, \ t \leq x \ \right\}$$
for every real number $x$. $(d)$ How to prove (USING THE MACHINERY DEVELOPED HERE) that $$b^{x+y} = b^x b^y$$
for all real numbers $x$ and $y$? I've already posted this question. Here's the link . However, none of the answers there seems to work for me. My Work Let  $X, Y$ be any two non-empty subsets of $\mathbb{R}$. Then we have the following facts: $(1)$ If $X \subset Y$ and if $Y$ is bounded above in $\mathbb{R}$, then so is $X$ and we have the inequality
$$\sup X \leq \sup Y.$$ $(2)$ If $X, Y$ are non-empty subsets of the set of non-negative real numbers and if both $X$ and $Y$ are bounded above, then so is the set $$\{ \ xy \ \colon \ x \in X, \ y \in Y \ \};$$
moreover, we have the identity $$\sup \{ \ xy \ \colon \ x \in X, \ y \in Y \ \} = \sup X \cdot \sup Y.$$ Thus, $$\begin{align}
b^x b^y &= \sup B(x) \sup B(y) \\
&= \sup \{ \ b^r \ \colon \ r \in \mathbb{Q}, r \leq x \ \} \sup \{ \ b^s \ \colon \ s \in \mathbb{Q}, s \leq y \ \} \\
&= \sup \{ \ b^{r+s} \ \colon \ r \in \mathbb{Q}, \ s \in \mathbb{Q}, \  r \leq x, \ s \leq y \ \}.
\end{align}$$ But if $r \in \mathbb{Q}$, $s \in \mathbb{Q}$, $r \leq x$, and $s \leq y$, then the sum $r+s \in \mathbb{Q}$ and $r + s \leq x + y$ also. So $$ \{ \ b^{r+s} \ \colon \ r \in \mathbb{Q}, \ s \in \mathbb{Q}, \  r \leq x, \ s \leq y \ \} \subseteq \{ \ b^t \ \colon \ t \in \mathbb{Q}, \ t \leq x+y \ \}.$$
Therefore, $$\begin{align}
b^x  b^y &= \sup \{ \ b^{r+s} \ \colon \ r \in \mathbb{Q}, \ s \in \mathbb{Q}, \  r \leq x, \ s \leq y \ \} \\
&\leq \sup \{ \ b^t \ \colon \ t \in \mathbb{Q}, \ t \leq x+y \ \} \\
&= \sup B(x+y) = b^{x+y}.
\end{align}$$ Now we have to show that $$b^x  b^y \geq b^{x+y}.$$ Case I. When $x+y$ is irrational: If $t$ is a rational number such that $t \leq x+y$, then since $x+y$ is irrational, we can also conclude that $t < x+y$. So we can find a rational number $r$ such that $$ t-y < r < x.$$ Then $$t-r < y < x+y -r.$$ Let's take $s \colon = t-r$. Then $s \in \mathbb{Q}$. And $s < y$. Thus, we have written $t$ as $t = r + s$, where $r, s \in \mathbb{Q}$, with $r < x$, $s < y$. So, when $x + y \in \mathbb{R} - \mathbb{Q}$, then we have $$\begin{align}
b^{x+y} &= \sup B(x+y) = \sup \{ \ b^t \ \colon \ t \in \mathbb{Q}, \ t \leq x+y \ \} \\
&= \sup \{ \ b^t \ \colon \ t \in \mathbb{Q}, \ t < x+y  \} \\
&= \sup \{ \ b^{r+s} \ \colon \ r \in \mathbb{Q}, \ s \in \mathbb{Q}, \ r< x, \ s < y  \}  \\
&= \sup \{ \ b^r b^s  \ \colon \ r \in \mathbb{Q}, \ s \in \mathbb{Q}, \ r< x, \ s < y  \}  \\
&= \sup \{ \ b^r \ \colon \ r \in \mathbb{Q}, \ r < x \ \} \sup  \{ \ b^s \ \colon \ s \in \mathbb{Q}, \ s < y  \} \\ 
&\leq \sup \{ \ b^r \ \colon \ r \in \mathbb{Q}, \ r \leq x \ \} \sup  \{ \ b^s \ \colon \ s \in \mathbb{Q}, \ s \leq y  \} \\ 
&= \sup B(x) \sup B(y) \\ 
&= b^x b^y.
\end{align}$$ Case II. What if $x + y \in \mathbb{Q}$? In this case, we can conclude that both $x$ and $y$ are irrational. How do we proceed with showing the remaining reverse inequality in this particular case?","['real-analysis', 'foundations', 'analysis', 'exponentiation']"
1620979,Prove that if $n^2 -2n +2$ is odd then $n$ is odd,"Prove that if $n^2 -2n +2$ is odd then $n$ is odd I was wondering if you would prove this by using proof by contrapostive. I tried using proof by contrapostive, but I end up with the wrong answer.","['discrete-mathematics', 'elementary-number-theory']"
1620982,"Bounding the Jacobian determinant for ""sublipschitz"" function","I'm practicing for my upcoming exam in calculus 3. I came across the following question in a practice paper: $ f:\mathbb R^3 \rightarrow \mathbb R^3 $, f is $C^1$. Also, $K|p-p'| \le |f(p)-f(p')|$ for all $p, p' \in \mathbb R^3$ (where $|\cdot|$ is the Euclidean norm and $K>0$ is a real constant). Prove that $K^3 v(\Omega) \le v(f(\Omega))$ for every Jordan measurable $\Omega\subset\mathbb R^3$ ($v$ is the Jordan measure on $\mathbb R^3$) I approached the question as follows. First, I noticed I can prove $f$ is a diffeomorphism $\mathbb R^3 \rightarrow f(\mathbb R^3)$ such that $D_f (x)$ is an invertible matrix for every $x\in\mathbb R^3$. Provided this is true, using variable substitution theorem, I can obtain the equality $v(f(\Omega))=\int_{f(\Omega))} 1 = \int_{\Omega} |J_f(x)|dx$, where $J_f (x) = det(D_f(x))$ is the Jacobian determinant. Now, I wanted to prove $(*)$ $|J_f (x)| \ge K^3$. From this I'll get $\int_{\Omega} |J_f(x)|dx \ge K^3 \int_{\Omega} 1 = K^3 v(\Omega)$, thus completing the proof. However, though $(*)$ seems intuitively true to me, I couldn't manage to prove it. In particular, I tried primarily to rely on the equality $det(D_f(x)) = lim_{Q\downarrow x} \frac{v(f(Q))}{v(Q)}$, where $Q$ is a cube centered around $x$ and $Q\downarrow x$ means $Q$'s area approaches zero. Regardless, nothing I tried worked. Any help in proving $(*)$ will be much appreciated, particularly if it was done with the equality I mentioned above. Thanks!","['multivariable-calculus', 'multiple-integral', 'integration', 'calculus']"
1621001,remove the interior points of two intersected closed-curves,"The problem is as follows I have two intersected closed curves and each curve was represented by two arrays respectively, which means we know the coordinates of every points $(x_i,y_i)$ but no analytic formula was given. For example, an example was given in the plot: two intersected ellipse I want to remove those points overlapped or inside the exterior boundary. The two intersected points (blue dots) were given in $(x_1,y_1),(x_2,y_2)$. What I did was to remove points with coordinates between x1 and x2, y1 and y2, and get a plot like: some interior points were removed Apparently, this was not enough for removing all interior points. So does anyone have idea of how to identify those inside points? Bear in mind that the boundary was not yet known until the inside and outside points were distinguished. So this is not a same problem as posted in Find grid points interior to a closed curve Thank you all!","['analytic-geometry', 'general-topology', 'algebraic-geometry', 'geometry']"
1621007,finding the integral solutions,"Prove that the equation $\sum\limits_{i=1}^n x_i^{-2} = 1$ has integral solutions for $n > 6$. I have no idea how to proceed, can someone give me a hint. Sorry for the mistakes in the text above.",['algebra-precalculus']
1621008,How many non-negative integer solutions does the equation $3x + y + z = 24$ have?,If the equation is $x + y + z = 24$ then it is solvable with stars and bars theorem.  But what to do if it is $3x + y + z = 24$?,"['number-theory', 'combinatorics']"
1621018,"How can I solve this PDE: $u_{tt}(\mathbf{x},t)+ku_t(\mathbf{x},t)-c^2 \Delta u(\mathbf{x},t)=0$","Consider the wave equation: $$u_{tt}(\mathbf{x},t)+ku_t(\mathbf{x},t)-c^2 \Delta u(\mathbf{x},t)=0$$ $\mathbf{x}\in\Bbb R^2, t>0 \\ \space \\ u(\mathbf{x},0)=0 \\ u_t(\mathbf{x},0)=\psi(\mathbf{x})$ a) Determine $\alpha \in \Bbb R$ such that $v(\mathbf{x},t):=e^{\alpha t}u(\mathbf{x},t)$ satisfies a first order PDE without first order derivatives on $\Bbb R^2$ b) Determine a $\beta \in \Bbb R$ such that $w(x_1,x_2,x_3,t)=w(\mathbf{x},x_3,t):=e^{\beta x_3}v(\mathbf{x},t)$ satisfies a PDE on $\Bbb R^2$ with second order derivatives only c) Show that the solution of the PDE is: $$u(\mathbf{x},t)=\frac{e^{-kt/2}}{2 \pi c} \int_{\lvert y \rvert >ct}d^2y \frac{\cosh(\frac{k}{2c}\sqrt{c^2t^2-\lvert y \rvert^2})}{\sqrt{c^2t^2-\lvert y \rvert^2}}\psi(x+y)$$ I don't even know how to start solving this problem. a) and b) doesn't make any sense to me. Can anyone explain why I am trying to find $\alpha$ and $\beta$ and what these constants mean? c) Looks a bit like the 2-D Poisson-Formula but as far as I understand the Poisson-Formula only applies to PDE's without a dissipation term. I also don't understand how a) and b) will lead me to figuring out c). Any ideas?","['ordinary-differential-equations', 'partial-differential-equations']"
1621062,What about $\lim_{x\to 1}\left(\zeta(x)-\frac{1}{x^x-1}\right)=1+\gamma$?,"When I type 1 in the box lim x to , and zeta(x)-1/(x^x-1) in the box Function , of this online calculator ( Wolfram Alpha ) one has as output $$\lim_{x\to 1}\left(\zeta(x)-\frac{1}{x^x-1}\right)=1+\gamma,$$ where $\zeta(x)$ is the Riemann zeta function , and $\gamma$ is the Euler- Mascheroni constant . I know that $$\lim_{x\to 1^{+}}\left(\zeta(x)-\frac{1}{x-1}\right)=\gamma,$$ and understand the proof. Question. What about $$\lim_{x\to 1}\left(\zeta(x)-\frac{1}{x^x-1}\right)=1+\gamma?$$ Canyou give a proof of previous limit when $x\to 1^{+}$ ? Thanks in advance.","['riemann-zeta', 'convergence-divergence', 'online-resources', 'limits']"
1621065,Sudoku grid guaranteed to be solvable?,"I want to generate random sudoku grids. My approach is to fill the three 3x3 groups on a diagonal of the grid, each with the numbers 1-9 randomly shuffled. That looks e.g. like the grid below: +-------+-------+-------+
| 5 6 4 | · · · | · · · |
| 1 7 2 | · · · | · · · |
| 9 8 3 | · · · | · · · |
+-------+-------+-------+
| · · · | 3 2 5 | · · · |
| · · · | 7 9 6 | · · · |
| · · · | 8 1 4 | · · · |
+-------+-------+-------+
| · · · | · · · | 1 5 9 |
| · · · | · · · | 3 2 7 |
| · · · | · · · | 6 4 8 |
+-------+-------+-------+ Then I let my sudoku solver process it until it finds a solution to fill all remaining gaps. The example above resulted in the filled grid below: +-------+-------+-------+
| 5 6 4 | 9 3 7 | 2 8 1 |
| 1 7 2 | 5 4 8 | 9 6 3 |
| 9 8 3 | 1 6 2 | 4 7 5 |
+-------+-------+-------+
| 7 4 9 | 3 2 5 | 8 1 6 |
| 2 1 8 | 7 9 6 | 5 3 4 |
| 6 3 5 | 8 1 4 | 7 9 2 |
+-------+-------+-------+
| 8 2 6 | 4 7 3 | 1 5 9 |
| 4 5 1 | 6 8 9 | 3 2 7 |
| 3 9 7 | 2 5 1 | 6 4 8 |
+-------+-------+-------+ My question is if this approach is mathematically safe, i.e. can you prove me that when I fill my grid using the described approach (randomly assigning the first 27 numbers to fields in the groups on a diagonal line), there will be always at least one possible way to complete the grid from there on? Or are there chances that the randomly placed numbers can interfere with each other and result in an impossible grid?","['matrices', 'puzzle']"
1621074,Prove that $3 \le a+b+c \le 2\sqrt{3}$ in a triangle,"Let $a,b,$ and $c$ be the lengths of the sides of a triangle satisfying $ab+bc+ca = 3.$ Prove that $3 \le a+b+c \le 2\sqrt{3}$. The idea I had was $(a+b+c)^2 = a^2+b^2+c^2+2(ab+bc+ca) = a^2+b^2+c^2+6 \geq 9$ by rearrangement. That takes care of the first inequality. How do I show the other inequality?","['inequality', 'geometry']"
1621108,Notation: Rows and Columns of Matrix,"A purely notational question: It is possible to denote the rows of a matrix $\mathbf{A}\in\mathbb{R}^{n\times m}$ by $\mathbf{w_1},\ldots,\mathbf{w_n}\in\mathbb{R}^{1\times m}$ and the columns by $\mathbf{v_1},\ldots,\mathbf{v_m}\in\mathbb{R}^{1\times n}$, such that
\begin{equation}
\mathbf{A}=\left(\begin{matrix}\mathbf{w_1}\\\vdots\\\mathbf{w_n}\end{matrix}\right)=\left(\begin{matrix}\mathbf{v_1}&\cdots&\mathbf{v_m}\end{matrix}\right).
\end{equation} Now, I write a paper containing a lot of matrices and in which I have to talk a lot about their rows. Thus instead of $\mathbf{w_k}$, I conveniently used the notation $\mathbf{A_k}$ to denote the $k^{th}$ row of $\mathbf{A}$, which has the big advantage that it is immediately clear of which matrix $\mathbf{A_k}$ is the $k^{th}$ row. However, I also sometimes have to talk about the columns of $\mathbf{A}$, which were denoted by $\mathbf{v_l}$ above. Denoting them by $\mathbf{A}_l$ is not an option, since this already denotes the $l^{th}$ row. Giving them a completely different name neither, since this makes the paper ugly and hard to read. What I would like is a clean notation to denote either rows or columns which still associates the rows/columns with $\mathbf{A}$. I thought of $\mathbf{A}_{*,l}$ and $\mathbf{A_{k,*}}$, but some matrix names already contain sub- and super-scripts themselves, making this notation ugly, too. In short, I need a notation for the rows respectively columns which would look also nice for e.g. $\mathbf{A_\beta^i}(t)\in\mathbb{R}^{n\times m}$. It would be OK if the notation would be nicer for the rows than for the columns, since I talk about the latter less often.","['matrices', 'notation']"
1621162,A probability question that I failed to answer in a job interview,"There are $N$ different sized targets, numbered $1, 2,\dots, N$.  A blindfolded shooter shoots towards random directions. Because target sizes are different, the hit probabilities of each target are different, say $p_1, p_2,\dots ,p_N$. A bullet hole is left on the target each time a target is hit. The shooter does not know whether a shot hit a target or not. Note that a shoot could be ""void"", i.e., $p_1+p_2+\cdots+p_N\le1$. One shot at most hits one target. The shooter keeps shooting until $X$ out of the $N$, $X<N$, targets have bullet holes. ( each of the $X$ targets is hit at least once). Then the shooter is told to stop. The question is: at the end of the game, what is the probability that target $k$ has NOT been hit, $1\leq k\leq N$.",['probability']
1621165,Textbook Accompanying Naive Set Theory,"I'm in the process of self-studying from the very popular Halmos book ""Naive Set Theory"" and I must say I can say only the best about the book. However, although the book has some excercises I would like if someone would suggest another resource that contains excercises about the substance of the before mentioned book. It doesn't really need to be a textbook, anything would work really. Thank you.","['reference-request', 'self-learning', 'elementary-set-theory']"
1621173,Prove that $\left | \frac{a-b}{a+b}+\frac{b-c}{b+c}+\frac{c-a}{c+a} \right | < \frac{1}{8}.$,"Let $a,b,$ and $c$ be the lengths of the sides of a triangle. Prove that $$\left | \dfrac{a-b}{a+b}+\dfrac{b-c}{b+c}+\dfrac{c-a}{c+a} \right | < \dfrac{1}{8}.$$ The best idea I had was to expand the fractions to get something nicer. So we get $\dfrac{a-b}{a+b}+\dfrac{b-c}{b+c}+\dfrac{c-a}{c+a} = \dfrac{a^2 b-a^2 c-a b^2+a c^2+b^2 c-b c^2}{(a+b) (a+c) (b+c)}.$ Then I would try to relate this to side lengths of a triangle to prove the desired inequality but that is the step where I am unsure.","['inequality', 'a.m.-g.m.-inequality', 'absolute-value', 'geometry', 'buffalo-way']"
1621187,How Angle AOP' is equal to (90° - θ) in the second figure?,"I'm learning Trigonometry right now with myself and at current I'm understanding how to find the trigonometric ratio of the angle (90°- θ) in those of θ. I'm little bit confused right now in second Figure, I didn't get how angle AOP'= (90°- θ). First figure is understandable to me because the angle BOP' is less than 90°but the second on is a little bit confusing because of the angle BOP' > 90°. Please help. Sorry If I'm asking foolish question. Thankyou in advance.",['trigonometry']
1621198,What is the definition of a presheaf in EGA?,"In EGA I, Grothendieck says he is not going to bother recalling the definition of a presheaf (on a given topological space $X$ with values in some category $\textbf{K}$).  I was just wondering what that definition was.  I know a presheaf should be a contravariant functor $\mathcal F$ from the category of open sets of $X$ to $\mathbf{K}$, but I was wondering if there is anything else to the definition?  For example, do we require that $\mathcal F(\emptyset)$ be a terminal object in $\mathbf{K}$?  (thereby assuming something about $\mathbf{K}$)","['category-theory', 'reference-request', 'algebraic-geometry']"
1621216,Prove $G$ is a group (unusual star operation).,"I've come across another rather simple question, but I'm having trouble with $G$'s defined operation. Let $(G,\circ)$ be a group and $x_0 \in G$. Consider the operation $*$ defined in $G$ by $a * b = a \circ x_0 \circ b, a,b\in G$. a) Knowing $*$ is associative, show $(G,*)$ is a group. Well, so far I've got this: Since $x_0 \in G$, G is non-empty. Closed under multiplication: Let $a,b \in G$. $a * b = a \circ x_0 \circ b$. Since all $a, b,$ and $x_0$ are in $G$, then its product is in $G$ as well. Identity: $a * 1_G = a$ (I don't think I've got this one quite right, because I'm messing with inverses, and that's probably not required) $a * 1_G = a == a \circ x_0 \circ 1_G = a == a^-1 \circ a \circ x_0^-1 \circ 1_G = a^-1 \circ a == x_0 \circ 1_G = 1_G == x_0 = 1_G$ I'm left with proving the inverse element, which should probably be done before the identity. Or maybe I should re-think my identity strategy. I'm a bit lost here. Any help? Thanks. EDIT: What I mean is: Clearly, we need the concept of inverses to work out the group's identity element. Thing is, I proved it before proving the very existence of the inverse element. Is this not a problem?","['abstract-algebra', 'group-theory']"
1621299,How many ordered pairs (with limitations)?,"having hard time with the following question:
$$A = \{1,2,.....,n\}$$
How many ordered pairs $(B,C)$ which are members of $P(A) \times P(A)$ are there where $B\cap \overline{C}$ is the empty set?",['discrete-mathematics']
1621316,Show that A contains two numbers $s$ and $t$ such that $s-t=9$.,"Let $A \subset K$ where $K=\{1,...,100\}$ with #$A=55$. Show that A contains two numbers $s$
  and $t$ such that $s-t=9$. Hint: Use Rule of Double Counting From my notes, the rule of Double Counting is: Let $(X,Y,I)$ be the incidence system and for $a\in X$ let $r(a)$ denote the number of elements of $T$ incident to $a$, and let $r(b)$ for $b\in Y$ is the number of elements incident to $b$. Then the following relation holds: $$\sum_{a\in X} r(a)= \sum_{b\in Y} r(b) $$ $\mathbf{Attempt}$ I think that we take $X=K$ and $Y=A$ and the incident is that $s-t=9$ ,so hence that would mean $$\sum_{a\in S} r(a)=55$$ However, I'm confused at what to do with the right hand side of the rule, how do we choose the elements of this set where $s-t=9$ is satisfied? Any Hints would be a great help, thanks.",['combinatorics']
1621324,Infinitely many primes of the form $3k+2$,"Prove that there are infinitely many primes of theform $3k+2$
I tried so:
Let $$A= \left\{ p \in \mathbb{P} : \; p=3k+2 \right\}$$ Suppose, that the set  $A$ is finite, i.e.  $$A= \left\{ p_1 , p_2, \ldots , p_k \right\}$$ Let $$M=3 p_1 p_2, \ldots  p_k+2$$ Then $M$ is of the form $3k+2$ Since $M>1$, then there exists prime $q$ such that  $q\mid M$. We show that $M$ has prime divisor of the form $3k+2$. Suppose that every prime divisor of $M$ is of the form $3k+1$. Fundamental theorem of arithmetic we have that $M= q_1 q_2 \ldots q_s$ where for each $i$ $q_i$ is of the form $3k+1$. Since for each $i$ $q_i$ is of the form $3k+1$, then $$M= q_1 q_2 \ldots q_s$$ is of the form $3k+1$, contradiction because  $M$ is of the form $3k+2$. Thus there exists prime $q$ of the form $$3k+2$$ and $q\mid M$. Thus there exists $i \in \left\{ 1, \ldots ,k\right\}$ such that $q=p_i$ but $q\mid M$, i.e. $p_i \mid M$, but $p_i \mid M=3 p_1 p_2, \ldots  p_k+2$ and $p_i \mid 3 p_1 p_2, \ldots p_k$, contradiction. Thus $A$ is infinite. I have problem, because don't get a contradiction when $p_i=2$, but this proof is correct for primes of the form $4k-1$ and $6k-1$. Please help me.","['number-theory', 'prime-numbers']"
1621326,$A_r$-singularities and effectiveness of some divisor.,"Let $X=\text{Spec}(\mathbb{C}[x,y,t]\big/(xy-t^n))$ for some $n$. Let $Y\subset X$ be defined by the prime ideal $(y,t)$. If we know that $$K_X-mY$$
is effective, can we say something about the relation between $n$ and $m$?","['algebraic-geometry', 'commutative-algebra']"
1621363,"Integrate: $\int \frac{\sin(x)}{9+16\sin(2x)}\,\text{d}x$.","Integrate: $$\int \frac{\sin(x)}{9+16\sin(2x)}\,\text{d}x.$$ I tried the substitution method ($\sin(x) = t$) and ended up getting $\int \frac{t}{9+32t-32t^3}\,\text{d}t$. Don't know how to proceed further. Also tried adding and substracting $\cos(x)$ in the numerator which led me to get $$\sin(2x) = t^2-1$$ by taking $\sin(x)+\cos(x) = t$. Can't figure out any other method now. Any suggestions or tips?","['indefinite-integrals', 'integration']"
1621372,Why Cohomology Groups?,"Why do we need cohomology groups? Homology groups are easier to compute and given two topological spaces, there is an isomorphism in homology groups if and only if there is an isomorphism in cohomology groups. So why do I need them?","['algebraic-topology', 'homology-cohomology', 'algebraic-geometry', 'geometry']"
1621401,Unit Normal vs Principal Normal,"Here is the problem I am working on:
Deduce the equation of the main normal and binormal to the curve: $x=t, y=t^2, z=t^3,   t=1.$ I remember from Calc-3 that the binormal is unit tangent $\times$ unit normal, and that unit normal is tangent prime /magnitude of tangent prime. However, my text book has the binormal as unit tangent $\times$ principle normal, with principal normal listed as a very long formula. Is unit normal different from principal normal? I have worked my way through the unit tangent but am not sure about the normal.",['differential-geometry']
1621418,Set Theory: Proof of existence of surjection,"As part of a larger proof, I have to show that there does not exist a surjection $\pi: A \rightarrow P(A)$, where $P(A)$ is the power set of the set $A$. I am having a problem with the proof given in the book. It is given as follows: Assume towards a contradiction that there exists a surjection $\pi: A \rightarrow P(A)$ and define $$ B = \{x \in A | x \notin \pi (x)\}.$$
Then $x \in B$ $\iff$  $x\notin \pi(x)$.  $B$ is a subset of $A$, and since $\pi$ is a surjection, there exists $b \in A$ such that $B = \pi(b)$. Then we have that $b \in B$ $\iff$ $b \notin \pi(b) = B$.  Contradiction. My question is: how can it be fine to define B in the first place?  I feel like saying there exists such a set is based on the assumption that $\pi$ is not a surjection.  If there was a surjection, then B would be empty.  Am I missing something here? Thanks in advance for any help.","['elementary-set-theory', 'proof-explanation']"
1621430,Can the Recursion Theorem be proved in Peano Arithmetic?,"A recursive function on $\mathbb{N}$ can be defined as follows: Given an element $a \in \mathbb{N}$ and a function $f:\mathbb{N}\rightarrow\mathbb{N}$, we can define a function $g:\mathbb{N}\rightarrow\mathbb{N}$ as follows: $g(0) = a$ $g(n+1) = f(g(n))$ The fact that $g$ exists and is unique can be proved using the Recursion Theorem in set theory. My understanding is that in Peano Arithmetic, it is possible prove the existence of exponentiation using just addition and multiplication, but is it true for any recursively defined function? In other words, is the existence of addition and multiplication strong enough to prove the existence of any recursive function? i.e can the Recursion Theorem be proved using the Peano Axioms (including addition and multiplication)? Update: Since the answers below indicate that this is true, I am looking for an outline of a  proof or a reference that shows that addition and multiplication are powerful enough to define any recursive function.","['induction', 'recursion', 'foundations', 'elementary-set-theory', 'peano-axioms']"
1621438,Proving whether the series $\frac{\cos(n)}{n}$ is absolutely convergent,"I have the infinite sum $$\sum_{n=1}^\infty \frac{\cos(n)}{n}$$ and I am able to show that it is conditionally convergent by using the Dirichlet Test (and the Lagrange Trig Identity to show the partial sums of $\cos(n)$ are bounded). However I want to try and prove whether or not it is absolutely convergent. It seems like it isn't, but I have no idea how to prove it either way. How could I go about doing this?","['trigonometry', 'sequences-and-series']"
1621446,The sum of infinitely many $c$s is $c$ implies $c = 0$.,"This seems like an obvious claim, but I would like to be able to prove this rigorously. Suppose I have $c \in \mathbb{R}$ satisfying
$$\lim_{n \to \infty}\sum_{i=1}^{n}c = c\text{.}$$
How does it follow that $c = 0$? What I think I shouldn't do : $$c\lim_{n \to \infty}n = c$$
because this gives $0 \cdot \infty = 0$ (is this true?). To understand the context of this question, I am working with a probability measure $\mathbb{P}$ and am trying to show that $\mathbb{P}\left(\emptyset\right) = 0$ using the definition (and in this case, $\mathbb{P}\left(\emptyset\right) = c$). Maybe infinite sums are defined differently in measure theory? I don't know.","['algebra-precalculus', 'real-analysis', 'measure-theory', 'probability-theory']"
1622673,"Is ""non-random parameter estimation"" the same thing as maximum likelihood estimation?","In one book and a few papers, mostly on navigational tracking, I have found reference to the method of ""non-random parameter estimation"" but this term is not on the Wikipedia and not in a lot of standard texts. It seems to be similar, however, to maximum likelihood estimation which is a standard method found in every tracking and navigation text. Are these two terms referring to the same thing? For example, in ""Estimation with Applications to Tracking and Navigation"" by Bar-Shalom, he writes ""A common method of estimating nonrandom parameters is the maximum likelihood method that maximizes the likelihood function (2.2.2-2). This yields the maximum likelihood estimator (MLE) ...."" So, from this language I am guessing when other authors speak of ""non-random parameter estimation"" they are talking about the MLE. Is that right?","['statistics', 'estimation', 'parameter-estimation']"
1622679,Limit $\lim_{x \to 1} \frac{\log{x}}{x-1}$ without L'Hôpital [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I was wondering if it's possible to identify this limit without using L'Hôpital's Rule:
$$\lim_{x \to 1} \frac{\log{x}}{x-1}$$","['limits', 'limits-without-lhopital', 'calculus', 'analysis']"
1622725,Determinant of non-square Jacobian,"Suppose I have a 3d solid in ${\bf R}^4$ which can be parametrized by the function $F:W\subset{\bf R}^3\rightarrow{\bf R}^4$.  Now suppose I want to calculate the volume of this solid.  Then naively I would compute the Jacobian of this map and then compute the following integral $$\int_VdV=\int_W|\det{\bf J}_F(x,y,z)|dxdydz$$ But of course I can't do this since the Jacobian is not square.  My understanding is that the way to do this is to actually compute $\sqrt{\det{\bf J}_F^{\mathrm{T}}{\bf J}_F}$.  This of course reduces to $|\det{\bf J}_F|$ when the Jacobian is square, and also agrees with the definition of arc length found here , and the definition of surface integral found here . And when I tested it for a parametrization ${\bf R}^2\rightarrow{\bf R}^3$ it was equivalent to taking the 2-norm of the vector containing the three square sub-determinants of its associated $3\times 2$ Jacobian.  Furthermore it agrees with the way the Riemannian metric changes when you perform the pull-back, since the length of a tangent vector under the pull-back is given by
$$\sqrt{\langle{\bf J}v, {\bf J}v\rangle}=\sqrt{v^{\mathrm{T}}{\bf J}^{\mathrm{T}}{\bf J}v}$$
Is all of this correct?  Am I missing something?  It was maddening to figure this out on my own as it's literally proposed no where in the introductory literature on vector calculus and differential geometry. I don't know much about differential topology, but I believe this is somehow all connected with the way differential forms operate, and I would conjecture that for a Jacobian, say $m\times n$ with $m\geq n$, we have that $\sqrt{\det{\bf J}^{\mathrm{T}}{\bf J}}$ is equal to the Euclidean norm of the $\binom{m}{n}$ square sub-determinants of $\bf J$.","['differential-geometry', 'vector-analysis', 'determinant']"
1622740,Symmetric difference and indicator function,Associativity of symmetric difference of sets In that post it said the symmetric difference is $$1_{A\mathbin{\Delta} B} = 1_A + 1_B - 1_{A\cap B}$$ Why is it not $$1_{A\mathbin{\Delta} B}=1_A+1_B-2(1_{A\cap B})$$ I can't really see why.,['elementary-set-theory']
1622747,Are the eigenvalues of the sum of two positive definite matrices increased?,"Let $A$ and $B$ be two $n \times n$ (symmetric) positive definite matrices, and denote the $k$ th smallest eigenvalue of a general $n \times n$ matrix by $\lambda_k(X)$ , $k = 1, 2, \ldots, n$ so that $$\lambda_1(X) \leq \lambda_2(X) \leq \cdots \leq \lambda_n(X).$$ I guess the following relation holds: $$\lambda_k(A + B) > \max\{\lambda_k(A), \lambda_k(B)\}, \; k = 1, 2, \ldots, n.$$ This looks intuitive but I have difficulty to prove it, any hints?","['eigenvalues-eigenvectors', 'linear-algebra']"
1622781,Discontinuous solution to first order ODE with delta function coefficients,"Consider the following first-order ODE: $$y'(x) = f'(x) y(x);$$ this has solution $y(x) = C e^{f(x)}$.  Now, consider taking $$f_\lambda(x) = \frac{\alpha}{2}\left(1+\tanh(\lambda x)\right);$$ in the limit $\lambda \to \infty$, $f_\lambda(x) \to \alpha\Theta(x)$ (where $\Theta(x)$ is the Heaviside step function), and the solution becomes $y(x) = C e^{\alpha \Theta(x)}$, which is discontinuous at $x = 0$.  Presumably, there is a sense in which one can think of this as some kind of solution to the ODE with delta-function coefficient $$y'(x) = \alpha \delta(x) y(x).$$ Now, the discontinuity in $y$ at $x=0$ is $$\Delta y \equiv y(0^+) - y(0^-) = C(e^\alpha - 1).$$ My question is the following: is there a way to extract $\Delta y$ from the singular ODE directly without first finding a solution with smooth $f(x)$ and then taking an appropriate limit?  For instance, in analogy with what one does with second-order ODEs with delta function coefficients, one could try to integrate it: $$\Delta y = \lim_{\epsilon \to 0} \int^\epsilon_{-\epsilon} y' dx = \lim_{\epsilon \to 0} \int^\epsilon_{-\epsilon} \alpha \delta(x) y(x) dx = \alpha y(0),$$ but this has the problem that $y(0)$ is not defined due to the discontinuity in $y(x)$.","['dirac-delta', 'ordinary-differential-equations']"
1622868,Limit problem $\ln(x)$ and $1^\infty$,Can anyone help me with this limit problem without L'Hopital rule and Taylor series? $$\lim_{x\rightarrow\ 1}\left(\frac{2^x+2}{3^x+1}\right)^{1/\ln(x)}$$,"['limits-without-lhopital', 'calculus', 'limits']"
1622873,Connection between weak topology in probability and weak* topology in functional analysis,"In functional analysis, Definition A: for any normed linear space $(X, \| \cdot \| )$ , the weak star topology $\sigma (X^*, X)$ on $X^*$ is generated by the collection of seminorms $\{ p_x \, | \, x \in X\}$ , defined by $$p_x (f) = |f(x)|.$$ In probability theory (more specifically from the book ""Probability measures on Metric Spaces"" written by Parthasarathy), Definition B: for any metric space $X$ , let $\mathcal{M} (X)$ denote the space of measures defined on $\mathcal{B} (X)$ and let $C(X)$ be the space of all bounded real valued continuous functions on $X$ , equipped with the sup norm. Then the weak topology on the space $\mathcal{M} (X)$ is generated by the base of open neighbourhoods at a point $\mu$ defined by $$ \bigg\{ \nu \in \mathcal{M} (X) \, \Bigg| \, \,  \bigg| \int_X f_i \, d \nu - \int_X f_i \, d \mu \bigg| < \epsilon_i, \, \, i= 1,2,\ldots, k \bigg\},$$ where $f_1, \ldots, f_k \in C(X)$ and $\epsilon_1 , \ldots, \epsilon_k >0$ . Here is what I don't understand: If $X$ is a compact metric space, then by the representation theorem of bounded linear functionals on $C(X)^*$ , then for any $\Lambda \in C(X)^*$ , there exists a unique Borel measure $\mu \in \mathcal{M}(X)$ such that $$ \Lambda_\mu (f) := \Lambda (f) = \int_X f \,d \mu, \quad \forall f \in C(X),$$ and that $$\| \Lambda_\mu \| = \mu (X).$$ Thus, if we identify each element $\mu \in \mathcal{M} (X)$ by $\Lambda_\mu \in C(X)^*$ , Definitions A and B are the same. However, for any general metric space $X$ that is NOT necessarily compact, $\mathcal{M} (X)$ and $C(X)^*$ are not necessarily in isometric isomorphism. (Or is there a representation result in greater generality?) Is Definition B slightly more general than Definition A to cater for the needs in probability theory? If this is the case, then some functional analytic results might not be applicable to weak convergence theory in probability..... Any ideas?","['probability-theory', 'functional-analysis', 'weak-convergence', 'metric-spaces', 'analysis']"
1622878,"If $G$ is a finite group s.t. $|G|=4$, is it abelian ? [duplicate]","This question already has answers here : Prove that every group of order $4$ is abelian (8 answers) Closed 7 years ago . If $G$ is a finite group s.t. $|G|=4$, is it abelian ? To me it's isomorphic to $\mathbb Z/2\mathbb Z\times \mathbb Z/2\mathbb Z$ or $\mathbb Z/4\mathbb Z$, but a friend of me said that they are not the only group of order 4, and there exist some non-abelian. Do you have such example ?",['group-theory']
1622897,"If $G$ is a direct product of simple groups, then is every simple subgroup of $G$ isomorphic to a subgroup of some factor?","Let $G=N_1\times N_2\dots \times N_n$. Suppose that $H$ is a simple subgroup of $G$. Is $H$ isomorphic to a subgroup of $N_i$, for some $N_i$? This is a weaker version of this question, which turned out to be false: If $G$ is direct product of simple normal subgroups, then is every simple subgroup isomorphic to some factor","['abstract-algebra', 'normal-subgroups', 'group-theory', 'simple-groups']"
1622904,QR(pivot) vs SVD for low rank approximation,"Define the low rank problem as finding the approximation of matrix A, B: where we want to minimize rank(B) and we want the 2 norm of the residu of A-B to be less than epsilon. Could someone help me understand what the benefits of both methods are when you use them for low rank approximation? I did some research and found some points: QR is supposed to be faster than SVD (especially for low rank probs) When matrices have 'gaps' in singular values -> QR better than SVD When there are no gaps in singular values, SVD is preferred. I have no idea why 1) holds. 
I also have only a guess of why 2) works: the gap in singular values could make our estimation of the new matrix off because if epsilon should fall between a huge gap of singular values, the matrix we would obtain would be too rough of an approximation (we lose data we did not anticipate) ? Another point I'd like to understand better is that I found somewhere that SVD would work better than QR when lower k was required.
The example that was given was as follows: A matrix with rank only 1: \begin{bmatrix}1&1\\2&2\end{bmatrix} A matrix with theoretical rank of 2: \begin{bmatrix}1.000&0.9999\\2&2\end{bmatrix} And a matrix $\sum$ was given from $ A = U * \sum * V^T$ (SVD of A).
With its singular values on the diagonal: \begin{bmatrix}2&0\\0&10^-8\end{bmatrix} In this case, SVD would actually tell us that the rank of the second matrix was only 1, and not really 2. Which I guess aids in a low rank approximation? I cannot explain how this helps.","['matrix-decomposition', 'svd', 'linear-algebra', 'approximation']"
1622906,"Mapping $\Delta(2,2,2)\mapsto \Delta(4,4,2)$... [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 7 years ago . Improve this question Looking at the images below, you recognize that the adajency matrix of the graph $A_G$ splits up into three different color submatrices, with $A_G=A_r+A_b+A_d$ (where $d$ is dark, damn...). 
It's obvious that $A_k^2=1$. Now have a look a the right coloring: You'll see that $(A_dA_r)^2=(A_rA_b)^2=(A_bA_d)^2=1$ as well. Let's use $a,b,c$ instead. We summarize this as:
$$
\langle a,b,c|a^2=b^2=c^2=(ab)^2=(bc)^2=(ca)^2=1\rangle =\Delta(2,2,2)
$$
This is a presentation of a triangle group $\Delta(2,2,2)$, a special kind of Coxeter group . The left image resembles the situation: $\hskip0.5in$ Now the right images deviates from the left at the inner square, where blue and dark are flipped; still a valid 3-edge coloring.
 It  has hamiltonian cycles (follow dark-red or red-blue edges), therefore its presentation is:
$$
\langle a,b,c|a^2=b^2=c^2=(ab)^4=(bc)^4=(ca)^2=1 \rangle =\Delta(4,4,2)
$$ So by flipping the inner cycle, we map $\Delta(2,2,2)\mapsto \Delta(4,4,2)$. EDIT : This means that we change the classification from $\frac12+\frac12+\frac12=\frac32>1$, i.e. spherical, to $\frac14+\frac14+\frac12=1$, i.e. euclidean. Which branch of math deals with this mapping? What are good introductionals to it? Let's restrict to planar, bicubic graphs...","['graph-theory', 'group-theory', 'group-presentation', 'coxeter-groups']"
1622929,"How to calculate the shortest interval, for $P ( X ≤ 1 . 645) = 0 . 95$?","The problem statement said: Based on the fact that $\Phi(1 . 645) = 0 . 95$ ﬁnd an interval in which $X$
  will fall with $95\%$ probability. Therefore: Since $P ( X ≤ 1 . 645) = 0 . 95, ( -∞ , 1 . 645)$ is a $95\%$ conﬁdence interval for $X$ The question I have problem to understand is: Among all possible intervals into which $X$ falls with $95\%$ probability,
  ﬁnd the shortest one. How can I compute or see which is the shortest interval? Thanks!","['probability-theory', 'probability', 'statistics']"
1622934,How to express logical equivalence arrow using Pierce's arrow?,"I am really confused about this and not sure how to show $P\iff Q$ with the ↓ arrow and only the ↓ arrow. I understand that $P \iff Q$ is $P\implies Q$ and $Q\implies P$. I also know that $P\implies Q$ is also $\neg P$ or $Q$. If anyone can help me represent $P\iff Q$ with only the ↓ arrow, I would really appreciate it.",['discrete-mathematics']
1622963,"Find the equation of parabola passing through $(-1, 6), (1, 4), (2, 9)$","A(the?) equation of parabola is $y = ax^2 + bx + c$. That gives the equations below: \begin{align*}
6 & = a - b + c\\
4 & = a + b + c\\
9 & = 4a + 2b + c
\end{align*} Then I simply solve for $(a, b, c)$ and substitute it into $y = ax^2 + bx + c$, correct? I guess it can be considered a quick question :)",['algebra-precalculus']
1622971,Some clarification on this textbook's definition of linear ODEs?,"The textbook I am reading (Zill's ""A First Course in Differential Equations with Modeling Applications) describes classifying ODEs as linear vs. nonlinear with the following statement: An nth-order ordinary differential equation $$F(x,y,y',...,y^n) = 0$$ is said to be linear if F is linear in $$y,y',...,y^n$$ This means that an nth-order ODE is linear when it is $$a_n(x)y^{(n)}+a_{n-1}(x)y^{n-1}+...+a_1(x)y'+a_0(x)y - g(x) = 0$$ I understand that the intuitive definition of linearity is that an ODE is linear if: 1) the highest degree of the dependent variable (y) and all of its derivatives is 1 2) the coefficient of the dependent variable and its derivatives is either a constant, or some term with at most the independent variable (x) 3) the dependent variable and its derivatives aren't inside of other functions like sin(y) However, the mathematical general definition is almost incomprehensible to me. I don't understand what the word ""in"" means when the author says that the function F is ""linear in"" followed by y and its derivatives separated by commas. And it does not say what g(x) means, what the collection of a(x) functions mean, etc.","['ordinary-differential-equations', 'definition']"
1622986,Law of the Iterated Logarithm Bound (Finite Number of Crossings),"Let $(X_1,X_2,...)$ be i.i.d random variables with mean  $0$ and variance $1$. By the Law of the Iterated Logarithm, for all $\epsilon >0$, \begin{equation}
P\left[ \frac{1}{t}\sum_{i=1}^{t}X_i \geq (1+\epsilon)\sqrt{\frac{2\log \log t}{t}}\text{ i.o.}\right] =0
\end{equation} I want to show that 
\begin{equation}
P\left(\frac{1}{t}\sum_{i=1}^{t}X_i<(1+\epsilon)\sqrt{\frac{2\log \log t}{t}}\text{ for all }t \geq 3 , \;\epsilon >0\right) >0
\end{equation}
i.e. with positive probability, $\frac{1}{t}\sum_{i=1}^{t-1}X_i$ never exceeds the LIL bound.","['probability-theory', 'borel-cantelli-lemmas']"
1623002,Find a (simple?) counterexample to this statement about topological manifolds.,"Let us assume by a topological manifold $M$ of dimension $n$ I mean a Hausdorff topological space that is locally homeomorphic to $\mathbf{R}^n$, where $n$ is fixed. I know that if $M$ is assumed separable and paracompact, then $M$ admits an exhaustion by compact sets. Is this still true if $M$ is only assumed separable, and not necessarily paracompact? Thanks.","['manifolds', 'general-topology']"
1623027,Exists a uniformly convex norm on Banach space satisfying certain condition?,"Let $E$ be a Banach space with norm $\|\cdot\|$. Assume that there exists on $E$ an equivalent norm, denoted by $|\cdot|$, that is uniformly convex. Given any $k > 1$, does there exist a uniformly convex norm $\|\cdot\|'$ on $E$ such that$$\|x\| \le \|x\|' \le k\|x\| \text{ for all }x \in E?$$ Progress. Maybe we could set$$\|x\|'^2 = \|x\|^2 + \alpha|x|^2$$with $\alpha > 0$ small enough? I am not sure what to do from there on out though.","['real-analysis', 'banach-spaces', 'normed-spaces', 'calculus', 'functional-analysis']"
1623038,"Will the conditional expectation always have this ""property""?(understanding/explanation of conditional expectation)","Lets say you have a probability space $(\Omega, \mathcal{A},P)$, and a random variable $X: \Omega \rightarrow \mathbb{R}$ on this space. Assume that we have a sub-sigma algebra $\mathcal{G}\subset \mathcal{A}$. We can then show that $\mu_X(G)=\int_GXdP$, is a measure on $(\Omega, \mathcal{G})$, it is also easy to see that this measure is absolutely continuous with respect to P. The Radon-Nikodym theorem tells us that we have a unique $P$-a.e $\mathcal{G}$-measurable function $\mathcal{E}(X|\mathcal{G})$ on $\Omega$, s.t. $\mu_X(G)=\int_G\mathcal{E}(X|\mathcal{G})dP, G \in \mathcal{G}$. My problem is that I have a hard time describing $\mathcal{E}(X|\mathcal{G})$ in general. If I make a specific example like this: $\Omega=\{1,2,3,4\}$ $\mathcal{A}=\{\emptyset,\{1\},\{2,3\},\{4\},\{1,4\},\{1,2,3\},\{2,3,4\},\Omega\}$
$ P(\{1\})=0.5,P(\{2,3\})=0.25, P(\{4\})=0.25$ $ X(1)=1, X(2)=3,X(3)=3,X(4)=4$ $\mathcal{G}=\{\emptyset, \{1,4\},\{2,3\},\Omega\}$ Then a calculation, and using the uniqueness of the radon nikodym derivative, gives us that: $\mathcal{E}(X|\mathcal{G})(\omega)=2\mathcal{X}_{\{1,4\}}(\omega)+3\mathcal{X}_{\{2,3\}}(\omega)$. Now comes my question: From elementary courses in probability and statistics, we can show that $E(X|\{1,4\})=2$ and $E(X|\{2,3\})=3$. So in this case, we see that the conditional expectation can be described this way: If you can only differentiate between the sets in $\mathcal{G}$ then the value of the conditional expectation for a given omega, is the value of the conditional expectation of the set in $\mathcal{G}$ containing $\Omega$ which is ""smallest"", or where we have eliminated most of the possibilities that did not happen, and that the sigma algebra $\mathcal{G}$ allows us to remove. But this was an easy example. And in general you may not have smallest sets like this? But is there an intuitive or good explanation of the value of the conditional expectation when we work with larger sets like countable or uncountable? Is there an equivalent way of saying in these cases for associating the value of the conditional expectation with the conditional expectation of a set as given in elementary statistics?
Or is there some theorem or explanation that generalises what I did above for ""small"" sets. And gives a good intuitive justification for conditional expectation here? If you have other intuitive ""explanations"" of the conditional expectation, I would like to hear them as well.","['real-analysis', 'probability-theory', 'probability', 'measure-theory', 'conditional-expectation']"
1623074,Prove that every $\mathbb{Z}/6\mathbb{Z}$-module is projective and injective. Find a $\mathbb{Z}/4\mathbb{Z}$-module that is neither.,"I want to show that every $\mathbb{Z}/6\mathbb{Z}$ -module is a direct sum of projective modules. As abelian group, $\mathbb{Z}/6\mathbb{Z}\cong\mathbb{Z}/2\mathbb{Z}\oplus \mathbb{Z}/3\mathbb{Z}$ , but is it the direct sum of $\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{Z}/3\mathbb{Z}$ as a $\mathbb{Z}/6\mathbb{Z}$ -module? Also, I know that free modules are projective, but does a module free over $\mathbb{Z}/2\mathbb{Z}$ implies that it is a free module over $\mathbb{Z}/6\mathbb{Z}$ ? And is it really true that every $\mathbb{Z}/6\mathbb{Z}$ -module is a direct sum of free modules? Also, I don't know how to prove the statement for $\mathbb{Z}/4\mathbb{Z}$ .","['injective-module', 'modules', 'abstract-algebra', 'projective-module', 'free-modules']"
1623086,Use of directed sets in the definition of nets in topology,"In topology, we use nets instead of sequences. The motivation is quite natural since the sequence is not ""long"" enough if the neighborhoods of some point ""separate"" too much. What I am confused about is the concept of directed set, is the only reason why we need the set to be directed because we want the definition of convergence of net to be uniform with that of sequence? Or there is another reason, thanks","['general-topology', 'nets', 'convergence-divergence', 'limits']"
1623094,First derivative meaning in this case,"If we have a function:
$$f(x)=\frac{x}{2}+\arcsin{\frac{2x}{1+x^2}}$$
And it's first derivative is calculated as:
$$f'(x)=\frac{1}{2}+\frac{1}{\sqrt{1-\big(\frac{2x}{1+x^2}\big)^2}}\frac{2+2x^2-4x^2}{(1+x^2)^2}=$$
$$\frac{1}{2}+\frac{2(1-x^2)}{\sqrt{\frac{(1-x^2)^2}{(1+x^2)^2}}\cdot(1+x^2)^2}=$$
$$\frac{1}{2}+\frac{2(1-x^2)}{|1-x^2|\cdot(1+x^2)}=$$
$$\frac{1}{2}+\frac{2\cdot sgn(1-x^2)}{1+x^2}$$
Why did my teacher say the critical points are at $x=\pm1$? Then she wrote:
$$f_+'(1)=-\frac{1}{2}$$
$$f_-'(1)=\frac{3}{2}$$
and I'm not sure what she meant by that eather, nor by the following:
$$f'(x)=
\begin{cases}
\frac{x^2-3}{2(x^2+1)}, & |x|>1 \\
\frac{x^2+5}{2(x^2+1)}, & |x|<1
\end{cases}$$
Thank you for your time.","['derivatives', 'calculus']"
1623097,Two nondecreasing sequences that bound each other,"Question: Let ($a_n$) and ($b_n$) be two nondecreasing sequences with the property that, for each positive integer $n$, there are integers $p$ and $q$ such that $a_n \leq b_p$ and $b_n \leq a_q$. 
Show that ($a_n$) and ($b_n$) either both converge or both diverge to $\infty$ and that, moreover, if they both converge they have the same limit. Given: ($a_n$) and ($b_n$) are non-decreasing, and $a_n \leq b_p$ and $b_n \leq a_q$ My proof is like: Suppose ($a_n$) is convergent, then for every $\epsilon$ greater than $0$, we have $|an - L| < ε$  , then the limit for ($a_n$) is $L$. we know that $a_n ≤ bp$ and  $bn ≤ aq$, 
so $a_n - b_p ≤ 0$   and   $b_n-a_q ≤ 0$ Let $|a_n-b_p|= ε/2$       $|b_p-a_m| = ε /2$ $|a_n - a_m| = |a_n - b_p + b_p -a_m| ≤ |a_n-b_p|+|b_p-a_m| < ε$ So an is a cauchy sequence Then I want to prove bn is a Cauchy sequence because there is a theorem says that the sequence converges if and only if the sequence is cauchy. Let $ε > 0$ and let      $|b_n-a_q|> ε/2$    &   $|a_q-b-m| > ε/2$ $|b_n - b_m| = |b_n-a_q + a_q-b_m| ≤  |b_n-a_q|+|a_q-b_m| ≤ ε$ So that ($b_n$) is a Cauchy sequence, and ($b_n$) converges. Since it converges, it has a limit, and according to the definition of limit, we have $|b_n - L| < ε$
So the limit of ($b_n$) is also $L$. I conclude that an and bn both converge and both of them converge to the same limit. I don't konw if it is helpful to use Cauchy to prove this question, I talk to the TA of this course and he suggests me to use Cauchy to solve. Maybe I misunderstand his hint, any help will be super appreciated:) Thanks a lot! Joy","['real-analysis', 'convergence-divergence', 'limits']"
