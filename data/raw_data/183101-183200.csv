question_id,title,body,tags
3346973,Reasoning gone wrong?,"While I was going through the previous year question paper of a college entrance examination conducted in our country, I came across this particular problem. The probability of men getting a certain disease is $\frac{1}{2}$ and that of women getting the same disease is $\frac{1}{5}$ . The blood test that identifies the disease gives the correct result with probability $4/5$ . Suppose a person is chosen at random from a group of $30$ males and $20$ females, the blood test of the person is found to be positive. What is the probablity that the chosen person is a man? Now at that time I wasn't aware of using conditional probability so I went a quite different way. The test could have been correct or maybe wrong. If we consider the case where the test is correct. Number of diseased men $= 30(\frac{1}{2})=15$ . Number of diseased women $ = 20(\frac{1}{5})=4$ .
Given that the test is positive the probability is $(\frac{4}{5})(\frac{15}{15+4})$ If the test is incorrect then that particular person do not have the disease.
Total men and women without the disease $15+16=31$ Probabilty for this case : $(\frac{1}{5})(\frac{15}{15+16})$ Adding both cases gives $\approx0.72$ However the real ansewer is around $0.70$ which is obatined by using conditional probabilty. After this I did dug into conditional probabilities but I am still curious about why my method didn't worked.
If you could point it out, I will be very grateful. Thanks","['conditional-probability', 'probability']"
3347007,"Maximizing the line integral $\int \mathbf{F}\cdot d\mathbf{r}$ for the vector field $\mathbf{F}=\langle x^2 y+y^3-y,3x+2y^2 x+e^y\rangle$.","Consider the vector field $\mathbf{F}=\langle x^2 y+y^3-y,3x+2y^2 x+e^y\rangle$ . For which closed non-self-intersecting curve in the plane does the line integral over this vector field have the maximal value? What is this value? Let $\mathbf{F}=\langle xy,y^2\rangle$ , let $C$ be the unit circle centered at the origin, and consider $\int_C \mathbf{F}\cdot d\mathbf{r}$ . Which portions of $C$ contribute positively to this integral? Calculate the integral two ways, first directly and then by using Green's theorem. For the first question. I need to maximize the line integral  how do I do that?
How can I apply Maxima minima concept to this?","['integration', 'multivariable-calculus', 'calculus']"
3347022,How to solve $x(3x+3)(x+5)(2x+12)+576 = 0$?,"How to solve $$x(3x+3)(x+5)(2x+12)+576 = 0?$$ This was a question on a test i recently took, And i wasn't able to solve it. I later tried to solve it using online calculators and it turns out this doesn't have any real solutions. I know there's a general formula for quartic polynomials that can work but we were only taught two methods, modifying the equation to a quadratic one using substitution or guessing some of the solutions. Both of these didn't work for me. Are there any ways to prove that this doesn't have real solutions without the quartic formula?","['algebra-precalculus', 'quartics', 'roots', 'polynomials']"
3347093,Doubt regarding definition of integral for positive measurable functions.,"I am starting to study some Measurement Theory following the book Measures, Integrals and Martingales and I have a doubt regarding the definition of integral that the author provides. First he defines the integral for simple functions as $$I_{\mu}(f):=\sum_{j=0}^M y_j \mu(A_j)$$ (where $f$ is a simple function, ${A_j}\in \sigma$ -algebra and $\mu$ is a measure). Then using the previous one he defines (Definition $9.4$ ) the $\mu$ -integral of a positive measurable function as: $$\int u \, d\mu:=\sup\{I_{\mu}(g):g\leq u, g \text{ is simple}\}$$ I am not really familiar with this definition, but this looks pretty much as the ""lower integral"" on Riemann's definition. Actually I was expecting to see also a sort of ""upper integral"" too, but nothing else was stated. Does this have to do with the fact that the function $u$ is measurable (by assumption)?
If not, why don't we require both the upper and the lower integral to coincide? 
Maybe this is a straightforward application of some well-known result that I am not aware of, but as I said this is my first approach to measure theory. 
Thanks in advance EDIT: Could this be because we know that any measurable function is
  the point-wise limit of simple functions, so we don't actually need to
  calculate the upper integral. We can ‘inscribe’ simple functions 
  below the graph of $u$ and exhaust the area?","['integration', 'measure-theory', 'lebesgue-integral']"
3347141,Does every bistochastic matrix $A$ have a unitary matrix $U$ s.t. $a_{ij} = |u_{ij}|^2$?,"Bistochastic matrix is a square matrix made of non-negative reals s.t. the sum of elements of any row or column equal 1. Unitary matrix is a square matrix with complex entries s.t. $UU^*=E$ It's known that if you take a Unitary matrix and take the squared modulus of every entry then you get a bistochastic one. Is the converse true? Does every bistochastic matrix $A$ have a unitary matrix $U$ s.t. $a_{ij} = |u_{ij}|^2$ ? If yes, what is the answer if we restrict the set of matrices to orthogonal real ones? I tried to write all the equations $U$ should satisfy in two-dimensional case. We have $6$ orthogonality relations and $4$ squared-modulus relations. Note that just two orthogonality relation don't hold automatically since we have squared-modulus relations. I tried to find such matrix for the matrix $\begin{pmatrix} \frac{1}{2} & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{2} \end{pmatrix} $ , it lead me to $\frac{1}{\sqrt{2}}(\cos2\pi n / 4 + i \sin 2 \pi n /4)$ . We can take any four complex numbers forming a square. The modified construction works for any matrix $\begin{pmatrix} a & 1-a \\ 1-a & a \end{pmatrix} $ Furthermore, we can rotate all the complex numbers and the relations still hold.","['matrices', 'unitary-matrices', 'linear-algebra']"
3347147,"Connected, totally geodesic and geodesically complete submanifolds","We have the following theorem in my lecture: Let $M,N \subset P$ be Connected, totally geodesic and geodesically complete submanifolds, s.t. $\exists p \in M \cap N$ and $T_pM=T_pN$ . Then it holds $M=N$ . I understand this and also the proof for this. But then we have a corollary, that each connected, totally geodesic and geodesically complete submanifold of $\mathbb{R}^n_{\nu}$ is of the form $p + V$ where $V$ is a non degenerate subspace. I see that the $p+V$ are connected, totally geodesic and geodesically complete submanifolds. But I don't see how it follows from the thm., that all .... submanifolds are of the form because we would have to show that for each other connected, totally geodesic and geodesically complete submanifold $M$ with $q \in M \cap (p+V)$ it holds $T_qN = T_q (p+V)$ and I don't see how this works.. can somebody give a hint? Also, in my lecture it says that eacb connected totally geodesic submanifold of $\mathbb{R}^n_{\nu}$ is an open subset of a non degenerated affine subspace.. why  should this be clear?","['semi-riemannian-geometry', 'geodesic', 'tangent-spaces', 'differential-geometry']"
3347149,Formal definition of a function VS. highschool,"In highschool, functions are often defined like this (example): $$f(x)=x^3-x+3$$ But on the wikipedia page of a mathematical function I read that this is not a formal way of defining a function, but rather just the function $f$ applied to $x$ , or something along those lines. Now I was wondering whether the above mentioned way is a valid way of defining a function as some kind of short form or shorter way or whether it is actually wrong to say that this is a function definition. And why is this way of defining functions used in highscool if it's wrong? And is there maybe a compromise between the completely formal and this kind of informal definition?","['notation', 'functions']"
3347150,Newton Raphson method issues with differentiation,"I am trying to solve for the roots of the follwing equation using the newton raphson method $$f\left(x\right)\ =-I+I_{ph}-I_s\times\left(e^\frac{q\times(V_c+I\times R_c)}{n\times k\times T}-1\right)$$ The solution that I am trying to find is: $$I_{n+1}=\ I_n-\frac{I_n-I_{ph}+I_s\times\left(e^\frac{q\times(V_c+I_n\times R_c)}{n\times k\times T}-1\right)}{\frac{{q\times I}_s\times{R_c\times\left(e^\frac{q\times(V_c+I_n\ timesR_c)}{n\times k\times T}-1\right)}_\ }{n\times k\times T}+1}$$ However when i reproduce the method myself I arrive to: $$I_{n+1}=\ I_n-\frac{I_n-I_{ph}+I_s\times\left(e^\frac{q\times(V_c+I_n\times R_c)}{n\times k\times T}-1\right)}{\frac{{q\times I}_s\times{R_c\times\left(e^\frac{q\times(V_c+I_n\times R_c)}{n\times k\times T}\right)}_\ }{n\times k\times T}+1}$$ I have used matlab to find the derivative and do the calculations, I dont know where the -1 term in the denominator has gone. The Method does not work without it.","['newton-raphson', 'derivatives']"
3347175,Techniques for set operation proofs?,"Techniques for set operation proofs? Particularly, Consider e.g. $$E \cup F = (E \setminus F)\cup(F \setminus E) \cup (E \cap F)$$ I can see this true from Venn diagrams, but I struggle as to how to write it algebraically. So how to approach it and other kinds? Show that $A \cup B = (A$ \ $B ) \cup (A \cap B) \cup (B$ \ $A)$",['elementary-set-theory']
3347177,How to list all possible topologies,"I am begginer and have no more idea about listing all the topologies on a given set. Precisely, given a finite set $X=\{a,b,c\}$ kindly guide me to list all its possible topologies.",['general-topology']
3347182,Powers of two are not sums of squares of different integers greater than zero,"It seems that non-trivial sums of squares of different non-zero integers aren't powers of two. Tested for sums of $2,3,4$ terms. Is there something known about this topic? Are there counter-examples?","['computational-mathematics', 'number-theory', 'sums-of-squares', 'reference-request']"
3347187,Probability of hitting a four in cricket,"Based on historical data, I calculated the probability of hitting a four (a type of shot) in cricket in one ball to be 0.114 (11.4%) [total number of fours / total number of balls]. In this case, how would I calculate the probability of a certain player hitting F fours in B balls? I tried simply multiplying the probability per ball by the number of balls, but this at times gives results far greater than 1 (when the number of fours is more than expected). Thanks for the help.","['data-analysis', 'statistics', 'probability']"
3347192,How to find effective partition of $n$ into $k$?,"Here is a type of question that I find quite often on MO sites, that I couldn't quite solve: How many ways can I put $n$ identical balls into $k$ identical boxes, with $n>>k$ , such that each box has at least one ball? For me, this question had $n=600$ , and $k = 3$ . At first, I thought this was a combinations problem, as we could have 3 balls put in each box first, and then the other $600-3=597$ balls can be placed in any boxes. The answer I first thought of was $3^{597}$ . I then realised this was wrong, because I was considering each as a separate ball, in which case it wasn't. Afterwards, I did a little research, and I thought this question might have something to do with compositions of numbers . However, the equation provided, which is $\binom{n-1}{k-1}$ was not the correct answer, when I plugged in $n$ and $k$ respectively, which got me $179101$ .   I realised that in my question, the $k$ boxes were not distinguishable, however in the equation, the $k$ boxes are. I believe the way I need to solve this problem is using partitions, instead of compositions, of the numbers, but I am not yet sure. I don't know how I can solve this problem with partitions of numbers. P.S the answer is $30,000$","['integer-partitions', 'combinatorics', 'balls-in-bins', 'discrete-mathematics']"
3347205,A curve with constant curvature and torsion [duplicate],"This question already has answers here : Given the curvature and torsion, find the curve (3 answers) Closed 4 years ago . I'm trying to come up with an example of a curve that has constant curvature and torsion, both exactly 1. Let $\vec{r(t)}$ be a parametrization for the curve $\gamma$ . By calculating with formulas for curvature $\kappa$ and torsion $\tau$ I got that the length of the second derivative $\dot{\vec{r}} $ must be the square of the length of the first derivative. Similarly, I got that the length of the third derivative must be a cube of the first derivative. But I couldn't get this any further. I'm guessing it could be something like a spiral... that would give us a constant curvature. And this spiral should bend... What would be such an example? (For definition of the curvature and torsion: https://en.m.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas )","['curves', 'vector-analysis', 'differential-geometry']"
3347226,"Are $\{\{a\},\{b,c\},\{d\},\{e\}\}$ and $\{a,b,c,d,e\} $ the same set?","Are $A = \{\{a\},\{b,c\},\{d\},\{e\}\}$ and $B = \{a,b,c,d,e\} $ the same set? Justify your answer. I think I get that set $A$ has elements in the form of sets: $\{a\}, \{b,c\}, \{d\}$ and $\{e\}$ . Is that the same as the elements in $B$ ? Could someone explain if these two sets are the same or not? Thank you!","['elementary-set-theory', 'discrete-mathematics']"
3347236,Source for MODERN combinatorial topology,"I have basic background in algebraic topology (Up to and including homology chapters of hatcher). I recently saw a couple of papers that seem very interesting- https://arxiv.org/pdf/math/0312482.pdf http://www2.math.technion.ac.il/~meshulam/eprints/exp_final.pdf http://www2.math.technion.ac.il/~meshulam/eprints/torsion.pdf These all seem to be giving combinatorical conditions for bounds on dimensions of homologies, I'm descrinbing this super vaugly and probably incorrectly because I haven't read the details of the proofs. I tried searching for an introductory book but searching combinatorial topology or homology gives me classical intro books for alg. topology. Is there a good reference? Added as a commentor recommanded- I am like a child asking ""I know group theory, why is there no quintic formula?"", and the answer I want is read about field theory (see this book), then galois theory (see this book). My point is I feel like this is a whole well known subject and I just don't know what the name is so I can't find good surveys.","['combinatorics', 'algebraic-topology', 'reference-request']"
3347245,Inequality : $\Big(\frac{x^n+1+(\frac{x+1}{2})^n}{x^{n-1}+1+(\frac{x+1}{2})^{n-1}}\Big)^n+\Big(\frac{x+1}{2}\Big)^n\leq x^n+1$,"I have the following problem to solve : Let $x,y>0$ and $n>1$ a natural number then we have : $$\Big(\frac{x^n+y^n+(\frac{x+y}{2})^n}{x^{n-1}+y^{n-1}+(\frac{x+y}{2})^{n-1}}\Big)^n+\Big(\frac{x+y}{2}\Big)^n\leq x^n+y^n$$ The problem is equivalent to : $$\Big(\frac{x^n+1+(\frac{x+1}{2})^n}{x^{n-1}+1+(\frac{x+1}{2})^{n-1}}\Big)^n+\Big(\frac{x+1}{2}\Big)^n\leq x^n+1$$ Or ( $y^2=x$ ): $$\Big(\frac{y^{2n}+1+(\frac{y^2+1}{2})^n}{y^{2(n-1)}+1+(\frac{y^2+1}{2})^{n-1}}\Big)^n+\Big(\frac{y^2+1}{2}\Big)^n\leq y^{2n}+1$$ I try the following identity : $$ch^2(x)-sh^2(x)=1$$ So we put $y=sh(x)$ we get : $$\Big(\frac{sh^{2n}(x)+1+(\frac{ch^2(x)}{2})^n}{sh^{2(n-1)}(x)+1+(\frac{ch^2(x)}{2})^{n-1}}\Big)^n+\Big(\frac{ch^2(x)}{2}\Big)^n\leq sh^{2n}(x)+1$$ And after I'm stuck... Update case $n=3$ : Due to homogeneity we can assume : $$x^{2}+y^{2}+\Big(\frac{x+y}{2}\Big)^{2}=1$$ Remains to show : $$\Big(x^3+y^3+\Big(\frac{x+y}{2}\Big)^3\Big)^3+\Big(\frac{x+y}{2}\Big)^{3}-x^3-y^3\leq 0$$ Or : $$\frac{1}{512} (x + y) (729 x^8 + 972 x^6 y^2 + 1728 x^5 y^3 + 54 x^4 y^4 + 1728 x^3 y^5 + 972 x^2 y^6 - 448 x^2 + 640 x y + 729 y^8 - 448 y^2)\quad(1)$$ Or : $$\frac{1}{512} (x + y)(27 (x + y)^2 (3 x^2 - 2 x y + 3 y^2)^3-448y^2-448z^2+640xy)$$ Or : $$\frac{1}{512} (x + y)(27 (x + y)^2 (3 x^2 - 2 x y + 3 y^2)^3-64 (7 x^2 - 10 x y + 7 y^2))$$ But with the constraint : $$\frac{5x^2}{4}+\frac{xy}{2}+\frac{5y^2}{4}=1$$ Or : $$x^2+y^2=\Big(1-\frac{xy}{2}\Big)\frac{4}{5}$$ It gives : $$\frac{1}{512} (x + y)\Big(27 (x + y)^2 \Big(\Big(1-\frac{xy}{2}\Big)\frac{12}{5}-2xy\Big)^3-64 \Big(\Big(1-\frac{xy}{2}\Big)\frac{28}{5}-10xy\Big)\Big )$$ Or : $$\frac{1}{512} (x + y)\Big(27 \Big(\Big(1-\frac{xy}{2}\Big)\Big)\frac{4}{5}+2xy) \Big(\Big(1-\frac{xy}{2}\Big)\frac{12}{5}-2xy\Big)^3-64 \Big(\Big(1-\frac{xy}{2}\Big)\frac{28}{5}-10xy\Big)\Big)$$ We put the substitution $a=xy$ .There is a root at $a=\frac{1}{3}$ it gives : $$\frac{1}{512} (x + y)\Big(-\frac{512}{625} (3 a - 1) (576 a^3 - 816 a^2 + 52 a - 73)\Big)$$ Now with the constraint it's not hard to see that $a\leq \frac{1}{3}$ And $$f(a)=(576 a^3 - 816 a^2 + 52 a - 73)\leq 0$$ on $[0,\frac{1}{3}]$ So the quantity $(1)$ is negative . We are done for this case . If you have a hint it would be cool . Thanks a lot !","['inequality', 'jensen-inequality', 'real-analysis']"
3347302,Convergence of an infinite series containing the sine function,"Does the following infinite series converge? $\displaystyle \sum _{k=1}^{\infty } \frac{\sin (k)}{\sqrt[3]{k^2+1}}$ In case it converges, does it have a closed-form value or solution? Or just a numerical solution?","['convergence-divergence', 'analysis', 'sequences-and-series']"
3347311,Time complexity of simple recursive procedure with random variable,"Considering this function: function F1(n);
begin
  if n > 0 then
    for i := 0 to n do
      print(i);
      print(n - i);
    end for
    m := random(0, n - 1);   // tricky part
    F1(m);
  else
    print(n);
  end if
end function I need to compute average time complexity of $F1$ procedure. Dominant operations are print calls. $random(d, g)$ returns random integer value from range $d, \cdots, g$ . So far I got this relation: $$\begin{cases}T(0) = 1 \\ T(n) = T(m) + 2(n+1) \end{cases}$$ I believe it is correct so far. But I need to get rid of the $T(m)$ thing and make it dependant on something like $\underbrace{T(n-1)}_{\text{well, that'd be worst case}}$ or $T(\frac{n}{2})$ etc. I was thinking in order to get rid of $m$ parameter perhaps I need to compute some sum, like: $$m = \sum_{i=0}^{n-1}\frac{i}{n} = \sum_{i=1}^{n}\frac{i}{n+1} = \frac{n}{2}$$ But I think the second sum is not really equivalent to the first sum, is it? Regardless, my question is how to get rid of the $m$ parameter from my relation above.","['recursive-algorithms', 'recursion', 'recurrence-relations', 'discrete-mathematics', 'algorithms']"
3347325,Distribute $13$ identical balls in $6$ cells. Find the number of distributions such that at least $10$ balls will be in the first 3 cells together,"Let $13$ identical balls be distributed in $6$ cells. Find the number of distributions in which there are at least $10$ balls in the first $3$ cells together. My attempt: First I'll divide into cases: $A_{0},A_{1},A_{2},A_{3}$ $\sum_{i=0}^{3}A_{i}=$ all distributions possible.
This is a question where the order matters and reparations
is allowed. Given $n$ balls and $k$ cells, there are: $\binom{n+k-1}{n}$ ways to distribute $n$ balls to $k$ cells. $A_{0}$ - there are $13$ balls in the first $3$ cells, and $0$ balls in the $3$ other cells thus $k_{1}=3,n_{1}=13\Longrightarrow$$\binom{n+k-1}{n}=\binom{15}{13}=105$ ways to distribute $13$ balls between $3$ cells. The distribution of balls in the first $3$ cells is disjointed to the distribution of balls in the other $3$ cells, therefore we'd apply the multiplication principle:
number of ways to distribute $0$ balls in $3$ cells: $\binom{2}{0}=1\Longrightarrow A_{0}=\binom{15}{13}=105$ $A_{1}$ - there are $12$ balls in the first $3$ cells,
and $1$ ball in the $3$ other cells: $k_{1}=3,n_{1}=12,k_{2}=3,n_{2}=1 \Longrightarrow\binom{n_{1}+k_{1}-1}{n_{1}}\cdot\binom{n_{2}+k_{2}-1}{n_{2}}=\binom{15}{12}\cdot\binom{3}{1}=455\cdot3=1365$ $A_{2}$ - there are $11$ balls in the first $3$ cells,
and $2$ ball in the $3$ other cells: $k_{1}=3,n_{1}=11,k_{2}=3,n_{2}=2$ } $\Longrightarrow\binom{n_{1}+k_{1}-1}{n_{1}}\cdot\binom{n_{2}+k_{2}-1}{n_{2}}=\binom{15}{11}\cdot\binom{4}{2}=1365\cdot6=8190$ } $A_{3}$ - there are $10$ balls in the first $3$ cells,
and $3$ ball in the $3$ other cells: $k_{1}=3,n_{1}=11,k_{2}=3,n_{2}=3 \Longrightarrow\binom{n_{1}+k_{1}-1}{n_{1}}\cdot\binom{n_{2}+k_{2}-1}{n_{2}}=\binom{15}{10}\cdot\binom{5}{3}=3003\cdot10=30030$ } $\sum_{i=0}^{3}A_{i}=105+1365+8190+30030=39690$ I'm not sure that my answer is correct, it seems to me that my result is to big.","['proof-verification', 'combinatorics', 'discrete-mathematics']"
3347360,"Convolution of $f(x)={1 \over 2} \chi_{[-1,1]}*\chi_{[-5,5]}$","Convolution of $f(x)={1 \over 2} \chi_{[-1,1]}*\chi_{[-5,5]}$ . This is my first exercise, it's basically an interpolation between the two functions. So here my results: Calling $u={1 \over 2} \chi_{[-1,1]}$ and $v=\chi_{[-5,5]}$ I can calculate the different values: $u*v(0)={ 3 \over 2}$ $u*v({1 \over 2})={ 3 \over 2}$ $u*v(-{1 \over 2})={ 3 \over 2}$ So for the borders, we have: $0$ for $x<-5,x>5$ $1$ for $x \geq -5,x \leq -{ 3\over 4}$ $-x+{ 3 \over 4}$ for $-{ 3\over 4} \leq x \leq -{ 1 \over 4}$ ${ 3 \over 2}$ for $-{ 1 \over 4} \leq x \leq { 1 \over 4}$ $x-{ 3 \over 4}$ for ${ 1 \over 4} \leq x \leq { 3 \over 4}$ $1$ for $x \geq { 3 \over 4},x\leq5$ I hope it's right (I can't draw the graphic here); if there is some error or not rigorous passage, please let me know I want to be capable to solve this at the best of possibilities","['integration', 'convolution', 'real-analysis']"
3347377,Erdos-Turan theorem for normal subgroups?,"Suppose $G$ is a finite group and $N \triangleleft G$ . Let’s define the relative commuting fraction as $$cf(G, N) := \frac{|\{(g, h) \in G \times H| [g, h] = e\}|}{|G||H|}$$ Does there exist such $\epsilon > 0$ , that for all $G$ and $H$ if $cf(G, N) > 1 - \epsilon$ , then $N \leq Z(G)$ ? For the particular case when $N = G$ we have the following fact: Erdos-Turan theorem If $cf(G, G) > \frac{5}{8}$ , then $G$ is abelian. However, the method that is used to prove it can not be extended onto this general case… It may still be useful to get this inequality: $$cf(G, N) \leq \frac{|Z(G) \cap N|}{|N|} + \frac{1}{2}$$ $$cf(G, N) = \frac{1}{|G||H|}(|G||Z(G)\cap N| + \Sigma_{g \in N} C_G(g)) \leq \frac{1}{|G||H|}(|G||Z(G)\cap N| + \frac{|N||G|}{2}) = \frac{|Z(G) \cap N|}{|N|} + \frac{1}{2}$$ But I do not know how to proceed further...","['inequality', 'finite-groups', 'normal-subgroups', 'combinatorics', 'group-theory']"
3347378,Finding Injectivity in function,"I have a doubt with the following problem. I have to find if the function is injective, surjective and if bijective find the inverse function $$f : \mathbb{Z} \longrightarrow \mathbb{N},\qquad
f(a) = 
     \begin{cases}
       2a  & \text{if } a >0, \\
       1 - 2a & \text{if } a \le 0. \\
     \end{cases}$$ The solution to the problem: Injectivity: $f(a)=f(b) \Rightarrow a=b$ . Taking a $x_{1}$ , $x_{2} \in \mathbb{Z}$ , I separate into the following cases: 1) $x_ {1} > 0$ , $x_{2} > 0:\; 2x_{1} = 2x_{2} \Rightarrow x_{1} = x_{2}$ 2) $x_ {1} \le 0$ , $x_{2} \le 0:\; 1-2x_{1} = 1-2x_{2} \Rightarrow x_{1} = x_{2}$ 3) $x_{1} > 0, x_{2} \le 0:\;2x_{1} = 1-2x_{2} \Rightarrow 2x_{1} + 2x_{2} = 1 \Rightarrow (x_{1} + x_{2}) = 1/2$ The case $x_{2} > 0$ , $x_{1} \le 0$ , gives the same answer as the third case. My question is that if this conclusion makes the function not injective, or it simply is telling me that this is a case that cannot happen since $x_{1}$ , $x_{2} \in \mathbb{Z}$ . Putting aside this, the function also is surjective and I could find the inverse function, that is $$f^{-1} : \mathbb{N} \longrightarrow \mathbb{Z},\qquad f^{-1}(a) = 
     \begin{cases}
       \text{a/2} &\text{if $a$ is even,} \\
       \text{(1 - a)/2} &\text{if $a$ is odd.} \\
     \end{cases}
$$ Is this correct? PD: First time writing LATEX, feedback is very welcomed!","['functions', 'inverse-function']"
3347436,"An fpqc morphism is a ""quotient"" morphism (as a continuous map between topological spaces)","Let $f: X \to Y$ be a faithfully flat quasi-compact morphism.
Then for a subset $V \subseteq Y$ , $V$ is open in $Y$ iff $f^{-1}(V)$ is open in $X$ ? I know this is EGA IV2 2.3.12.
But its proof is very complicated for me.
(I'm not familiar with pro-constructibility.)
So are there other good proofs of it or its references? Thank you very much!",['algebraic-geometry']
3347444,In how many ways can $14$ people be seated in a row if there are $8$ men and they must sit next to one another?,"In how many ways can 14 people be seated in a row if: a.) there are 7 men and 7 women and no two men or two women sit next to each other? My attempt: Since no two men or women can sit next to each other I calculated $(7-1)! \cdot (7-1)! = 518400$ b.) there are 8 men and they must sit next to one another? My attempt: If 8 men must sit next to one another, then there are 6 women left. What I did was calculate $(6 + 1)! = 5040$ Is this the correct approach?","['permutations', 'combinatorics', 'discrete-mathematics']"
3347447,Proof for integral representation of Lambert W function,"The Lambert W function satisfies the identity $$W(z)e^{W(z)}=z.$$ How do you prove that $$
W(z)
= \frac{z}{2\pi} \int_{-\pi}^{\pi} \frac{(1-\nu \cot(\nu))^2+\nu^2}{z+\nu \csc(\nu)e^{-\nu\cot(\nu)}} \, \mathrm{d}\nu
$$ where $z$ is a real number and $z\geq-\frac{1}{e}$ ?","['complex-analysis', 'definite-integrals', 'lambert-w']"
3347448,Geometric intuition of isolated and embedded prime of a module,"In this wikipedia page https://en.wikipedia.org/wiki/Associated_prime In a commutative ring R, minimal elements in $\text{Ass}(M)$ (with respect to the set-theoretic inclusion) are called isolated primes while the rest of the associated primes (i.e., those properly containing associated primes) are called embedded primes . Is there any geometric way of thinking about this ""isolated and embedded prime""? To which concept do they relate in algebraic geometry?","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3347475,"Let $G$ be non-abelian, $|G|=p^3$, where $p$ is an odd prime. Show $\exists N\unlhd G$ with $Z(G)<N<G$ and $N\cong\Bbb Z_p \times\Bbb Z_p$.","Let $G$ be a non-abelian group of order $p^3$ , where $p$ is an odd prime.  Show that $G$ has normal subgroup $N$ such that $$Z(G)<N<G$$ and $N \cong\Bbb Z_p \times\Bbb Z_p$ . I know the following facts about a non-abelian group $G$ of order $p^3$ : $$|Z(G)| = p \mbox{ and } G/Z(G) \mbox{ is elementary abelian. }$$ Thanks!","['group-theory', 'abstract-algebra', 'finite-groups', 'p-groups']"
3347476,Find the largest positive integer which can divide the sum of any five such numbers.,"Five different positive integers are such that if we take any two of them, possibly the same number twice, exactly nine different sums may be obtained. Find the largest positive integer which can divide the sum of any five such numbers. I have no idea how to approach this problem hints, suggestions, and solutions would all be appreciated. Taken from the 2015 CIMC","['contest-math', 'number-theory', 'problem-solving']"
3347485,Calculate the integral value using residues,"Hello I'm trying to solve this integral : $\\$ $$\int_{0}^{2\pi} \frac {\cos^2(x)}{4+3\cos(x)} dx.$$ I want to solve this integral using the theorem: $$\int_{0}^{2\pi} R\bigl(\cos(\alpha),\sin(\alpha)\bigr) d\alpha =2\pi i \sum_{|z_{k}|<1} \operatorname*{Res}_{z=z_k}f(z)$$ where $\displaystyle\;f(z)=\frac {1}{iz}R\biggl(\frac{1}{2}\Bigl(z+\frac {1}{z}\Bigr),\frac {1}{2i}\Bigl(z-\frac {1}{z}\Bigr)\biggr).$ Let $R(x,y)=\frac {x^2}{4+3x}$ , then i used the theorem to find $f(z)$ . So $f(z)=\frac{1}{i} \frac {(z+\frac {1}{z})^2}{16z+6z^{2}+6}$ then i find the zeros of ${16z+6z^{2}+6}$ which is $z_{1}=\frac{-8+\sqrt{28}}{6}$ and $z_{2}=\frac{-8-\sqrt{28}}{6}$ . Then i don't know but i should use only $z_{1}$ to answer the question? $$I=\int_{0}^{2\pi} \frac {\cos^2(x)}{4+3\cos(x)} dx=2\pi i {Res}_{z=z_1}f(z)$$ I found ${Res}_{z=z_1}f(z)=\frac{64-8\sqrt{28}}{i(-8\sqrt{28}+28)}$ Using the theorem I mentioned, I found the singular points ( $z_1=0$ essential point, $z_2=\frac{−8+sqrt(28)}{6}$ and $z_3=\frac{−8-sqrt(28)}{6}$ such as simple poles). But $z_3$ isn't in the disk $D(0,1)$ . So the integral $=2\pi i(Res_{z=z1}f(z)+Res_{z=z2}f(z))$ . I found the $Res_{z=z2} f(z)$ but i can't find $Res_{z=z1}f(z)$ . Can someone help me with that?
Thank you :)",['complex-analysis']
3347486,"Group law on $\{ f \in L^1[0,1], f>0,\int f=1\}$","Let $$G = \left\{ f : [0,1] \to (0,\infty)\text{ Lebesgue measurable and }\int_{[0,1]} fd\mu=1\right\}$$ Question: is $$f \odot g = f\left(\int_0^x g(y)dy\right) g(x)$$ a group law on $G$ with identity $1$ and inverse $\frac1{f(F^{-1}(x))}, F(x)=\int_0^x f(y)dy$ ? ie. when integrating the elements of $G$ we'd obtain a subgroup of the group $C$ of bijective strictly increasing continuous functions $[0,1] \to [0,1]$ with group law given by composition. The map $G \to C$ is not surjective because of those kind of things constructed from the Cantor function . Both $f\left(\int_0^x g(y)dy\right) g(x)$ and $\frac1{f(F^{-1}(x))}$ are measurable so the problem is to find if they integrate to $1$ and trying to produce a counter-example if they don't.","['measure-theory', 'real-analysis']"
3347519,Is $\infty^\infty$ indeterminate?,"What can be said about the value of $\infty^\infty$ ? Some of the main arguments regarding indeterminations like $0^0$ and $1^\infty$ involve the fact that different limit directions yield different results, in some cases only noticable via the complex plane. Are there similar arguments that can be used for this case, or is it simply $\infty$ ?","['limits', 'calculus', 'infinity']"
3347528,A Problem from Past Entrance Exams into Math Master's Program in Taiwan,"Let $f$ and $g$ be $\mathbb{R}$ -valued $C^{\infty}$ functions on $\mathbb{R}^2$ and let $S=\{(x,y)\in\mathbb{R}^2|f(x,y)=0\}$ . Suppose that at some point $p=(a,b)\in S$ we have $\frac{\partial f}{\partial x}(p)=-1$ , $\frac{\partial f}{\partial y}(p)=2$ , $\frac{\partial g}{\partial x}(p)=3$ , $\frac{\partial g}{\partial y}(p)=-6$ , $\begin{bmatrix} \frac{\partial^2 f}{\partial x^2}(p) & \frac{\partial^2 f}{\partial x\partial y}(p) \\ \frac{\partial^2 f}{\partial y\partial x}(p) & \frac{\partial^2 f}{\partial y^2}(p)
\end{bmatrix} = \begin{bmatrix} 1 & 3 \\ 3 & 0 \end{bmatrix}$ , and $\begin{bmatrix} \frac{\partial^2 g}{\partial x^2}(p) & \frac{\partial^2 g}{\partial x\partial y}(p) \\ \frac{\partial^2 g}{\partial y\partial x}(p) & \frac{\partial^2 g}{\partial y^2}(p)
\end{bmatrix} = \begin{bmatrix} 3 & -1 \\ -1 & 2 \end{bmatrix}$ . Show that there exists $R>0$ such that $g(p)<g(q)$ for $q\in S\cap\{(x,y)\in\mathbb{R}^2|(x-a)^2+(y-b)^2<R^2\}$ . I am very very sorry that I keep haven't figured out it is because what concepts/topics/applications/skills that I am unfamiliar with so that I fail to have an idea how to solve this problem from entrance exams into math Master's program in Taiwan. I really need someone can guess what I lack of and point out the direction for me to solve this problem. Thanks eveyone in advance for every possible help!!! P.S. This problem already had appeared in the past exams in year 2017. It is already a past/old problem now. An past/old exam file can be downloaded from: http://www.math.ntu.edu.tw/sites/default/files/imce/documents/exams/M_aca_107.pdf","['self-learning', 'analysis', 'maxima-minima', 'calculus', 'hessian-matrix']"
3347531,Proving $\sqrt{2}$ is irrational,"I had my first lecture the University of Toronto, MAT157 with professor Meinrenken. I am struggling with proof #3 which he briefly walked us through. I do not understand the method of thinking and there are a lot of missing lines. Can someone guide me through how this proof works? I have understood the other two proofs. If it is any help, I am also reading through Calculus 4e, by Michael Spivak. Any input on this proof is helpful. I understand mostly everything until the last three to four lines. Mainly, how do those statements relate to each other? There are some missing steps? Proof. Let $$S = \{x\in\mathbb R \mid x=a + \sqrt{2} b\}$$ where both $a,b\in \mathbb Z$ . S is closed under multiplication. If $x_1 , x_2 \in S$ then $x_1 x_2 \in S$ $(a_1 + \sqrt{2} b_1)(a_2 + \sqrt{2} b_2) = (a_1 a_2 + 2b_1 b_2) + \sqrt{2} (b_1 a_2 + b_2 a_1)$ Hence, if $x\in S$ , then $x^n= x ... x \in S$ for all $n\in\mathbb N$ If $\sqrt{2} = {p \over q}$ then if $x\in S$ , then $qx\in S$ . $x = a + {p \over q} b$ and $qx = qa + qb$ Note $x = \sqrt{2} -1 \in S, 0 < x < 1$ . So $1 \over x$ > 1 Choose $n\in \mathbb N$ with $\left({1 \over x}\right)^n> q, $ so $1 > qx^n > 0 $ . End of proof. I am struggling specifically with the last three lines of the proof. The rest of the proof is simple for me to understand.","['calculus', 'proof-writing', 'irrational-numbers', 'real-analysis']"
3347553,"Why is infinite intersection ""towards infinity"" an empty set?","Why is the infinite intersection ""towards infinity"" an empty set? Or i.e. Why is: $$\cap_{i=1}^{\infty} F_i = \emptyset$$ $$F_n=[n, \infty)$$ There's intuition, the intersection is always the ""smallest of the sets"" so eventually it will be $(\infty,\infty)$ or something like that.",['elementary-set-theory']
3347575,"When calculating averages, why can we treat exploding die as if they're independent?","I'm certain that I'm forgetting something basic, but here goes. The exploding dice is a (house) rule for some games that says when you roll the maximum result on a given die (e.g. 6 on a six-sided die) you roll that die again and add the result. If you roll the maximum value again, you roll again and add that. This will carry on until you stop rolling the maximum value. From here, a natural question arises: ""what's the average of an exploding die?"". With the example of a six-sided die, the following answer comes naturally: $3.5*+3.5*\frac{1}{6}+3.5*\frac{1}{6^2}\dots=4.2$ This does indeed seem to be correct, and holds to any empirical test that I can think of, but why does this work? I want to use some excuse to the effect of ""expected value is linear and we've got identical distributions"", but I find that unsatisfactory. In particular, I don't understand why we can use the average values of 3.5 when every term to the right of that 3.5 assumes that we've beat the average. I have no doubt that this is why we need the $6^{-n}$ terms, but my intuition insists that this is insufficient. Note: What I really want here is to see the rigor. An ideal answer will attack this from the ground up, possibly even axiomatically. I'd hope that we don't have to go as deep as using probability measures on sets, but at the very least I want some answer that focuses on what property of averages allows us to factor the dice like this.","['average', 'dice', 'probability']"
3347591,Nonhomogeneous random walk with increasing probability of staying still,"Let $\alpha \geq 1$ and $X_n$ be independent random variables such that $P(X_n=2)=P(X_n=-2)=\frac 1{2n^\alpha}$ and $P(X_n=0)=1-\frac 1{n^\alpha}$ . Let $S_n=\sum_{k=1}^n X_k$ . Depending on the value of $\alpha$ , what are the properties of $S_n$ (convergence, asymptotic behaviour)? $S_n$ is clearly a Markov chain on the even integers. Note that it is not time-homogeneous or stationary . Since $E(X_n)=0$ and $V(X_n)=\frac 4{n^\alpha}$ , we have $V(S_n)=4\sum_{k=1}^n \frac{1}{k^\alpha}$ . Whether $\alpha=1$ or $\alpha >1$ , we have respectively $V(S_n)=O(\log n)$ and $V(S_n)=O(1)$ .
In both cases, by Markov's bound, for any $\epsilon >0$ and $\delta >0$ , $$P(\frac{|S_n|}{ n^{1/2+\epsilon}}\geq\delta) = P(|S_n|\geq n^{1/2+\epsilon}\delta)=O\left( \frac{\log n}{n^{1+2\epsilon}}\right)$$ and since $\sum_n \frac{\log n}{n^{1+2\epsilon}} < \infty$ , we get $S_n = o\left(n^{1/2+\epsilon} \right)$ a.s. As noticed by Olivier in the comments, if $\alpha>1$ , $\sum_n P(X_n\neq 0) = \sum_n \frac{1}{n^\alpha}<\infty$ thus by Borel-Cantelli lemma, $P(\limsup_n (X_n\neq 0)) = 0$ , i.e. $$P(\liminf_n (X_n= 0)) = 1$$ Hence almost surely, $S_n$ becomes constant. Olivier also noticed that $S_n$ is a martingale, and for $\alpha>1$ , $E(S_n^2) = V(S_n)=O(1)$ . A result from the theory of martingales implies that $S_n$ converges almost surely and also converges in $L^2$ . The characteristic function of $S_n$ is $$\prod_{k=1}^n \frac 1{2k^\alpha} e^{2it} + \frac 1{2k^\alpha} e^{-2it} + 1-\frac 1{k^\alpha} = \prod_{k=1}^n \left(1-\frac{1-\cos(2t)}{k^\alpha}\right)$$ When $\alpha=1$ , this converges pointwise to $$t\mapsto 1_{\pi \mathbb Z}(t) $$ This limit is not a continuous function, so Lévy's continuity theorem does not apply. This rather indicates that $S_n$ does not converge in distribution when $\alpha=1$ .","['stochastic-processes', 'random-walk', 'probability-theory', 'markov-chains']"
3347684,"If I draw three cards, what is the probability that one of them is higher than 10.","Exercise: Suppose I have 100 cards marked 1 to 100. Let's say that I draw three cards. What is the probability that at least one of them is marked with number 10 or lower? My approach: If I name the cards $A, B$ , and $C$ , then at least one of them is marked with number 10 or lower in the following cases: A is 10 or lower, B is higher than 10, C is higher than 10 A is 10 or lower, B is 10 or lower, C is higher than 10 A is 10 or lower, B is 10 or lower, C is 10 or lower A is higher than 10, B is 10 or lower, C is higher than 10 A is higher than 10, B is 10 or lower, C is 10 or lower A is higher than 10, B is higher than 10, C is 10 or lower I first thought I could just sum the probabilities of these events. That is $$
P(\text{at least one of $A,B,C$ is marked with number 10 or lower})= (0.1 * 0.9 * 0.9) + (0.1 * 0.1 * 0.9) + ... + (0.9 * 0.9 * 0.1)
$$ Unfortunately, I don't think this is correct, because some of the events are overlapping. Furthermore, I don't think this is the smartest way to do this. Question: How should I approach this exercise? What is the best way to look at these type of problems?","['probability-theory', 'probability']"
3347754,is ergodicity just the law of large numbers?,"There are various laws of large numbers. They have the form LLN. If [ conditions on $X_i$ ] then $\lim_{n\to\infty}\frac 1 n \sum_{i=1}^n X_i=\mathbb E [X_i]$ Is it correct to say that $X_i$ satisfies ergodicity if $\lim_{n\to\infty}\frac 1 n \sum_{i=1}^n X_i=\mathbb E [X_i]$ ? In other words, that ergodicity is just the conclusion you get if you apply the law of large numbers? I know that ergodicity is formalized differently, but I am trying to connect it to something I know.","['law-of-large-numbers', 'ergodic-theory', 'probability-theory']"
3347837,Word metric on a finitely generated subgroup versus the word metric of its finitely generated parent,"Let $G$ be a finitely generated group and $H\subseteq G$ a finitely generated subgroup. For every finite set of a generators $F$ for $H$ , we can extend to a finite generating set $\hat{F}$ for $G$ . Denoting the word metrics on $H$ and $G$ with respect to these generating sets by $d_{1}(x,y)$ and $d_{2}(x,y)$ , what relationships exist between $d_{1}$ and $d_{2}$ . Presumably for all $x,y\in H$ we have that $d_{1}(x,y)\geq d_{2}(x,y)$ , but can we say something more specific? Edit: The word metric on a group $G$ with respect to a finite generating set $F=\{a_{1},\ldots,a_{n}\}$ is defined in the following way. For an element $x\in G$ the natural number $|x|$ is the length of the shortest word in $F$ and inverses of elements thereof that is equal to $x$ . The word metric on $G$ with respect to $F$ is defined by setting $d(x,y):=|xy^{-1}|$ .","['metric-spaces', 'combinatorial-group-theory', 'finitely-generated', 'geometric-group-theory', 'group-theory']"
3347840,Probability that the orthographic projection of a randomly oriented regular tetrahedron is a triangle,"I wanted to find the probability that, given a uniformly sampled rotation matrix , when applied to a regular tetrahedron, its orthographic projection is a triangle (instead of a quadrilateral) when viewed from a predetermined ""camera angle"". Here is my approach. First, some definitions and convenient choices: The regular tetrahedron has side length $a$ be centered at the origin. We are looking at it from the positive $z$ axis. Thus we are projecting the tetrahedron onto the $xy$ -plane. Given a triangular projection, let the triangle's vertices be $A, B, C$ . The fourth vertex of the tetrahedron is $D$ . Assume for now WLOG that $D$ is obscured by the face $\triangle ABC$ . I want to calculate how much area on the tetrahedron's circumsphere can be reached by $D$ through rotation without $D$ 's projection ever exiting the projection of $\triangle ABC$ . Dividing that by the total surface area would give the probability. To start, let us start with the tetrahedron being oriented such that $\triangle ABC$ is parallel to the $xy$ -plane, and $AB$ (the edge) is parallel to the $x$ -axis. Let $\theta = \phi = 0$ (spherical coordinates) at this orientation, as this describes the position of $D$ . What I want to do, is for each value of $\theta$ , where $0 \leq \theta \leq \pi/3$ (I chose this range since I believe the math to be symmetric enough to do on 1/6 of a full rotation), rotate the tetrahedron about the $z$ -axis by $\theta$ , then determine how much I can rotate the tetrahedron clockwise (as seen from positive $x$ ) about the $x$ axis without having vertex $D$ exit $\triangle ABC$ . To help explain the next step, I will use the figures below. Figures 1 through 4 are viewed from the positive $z$ -axis, Figure 5 is viewed from the positive $x$ -axis. See Figure 4 for what the rotation by $\theta$ mentioned earlier looks like, and Figures 1-3 for concrete examples. In Figure 4, there is a point $P$ on the edge $AB$ , and line segment $PD$ . See Figure 5 for a partial view of Figure 4 from the positive $x$ -axis. If we are rotating clockwise about the $x$ -axis, then we cannot rotate further once $PD$ becomes parallel to the $z$ -axis. That is, when the projections of $P$ and $D$ would coincide. Thus, the value $\alpha$ in Figure 5 is the most we can rotate about the $x$ -axis for this particular value of $\alpha$ . In particular, the value of $\phi$ ranges from $0$ to $\alpha$ . To get $\alpha$ as a function of $\theta$ , note that $|EF| = \sqrt{3}a/6$ is the inradius of $\triangle ABC$ , and so $|PF| = |EF| \sec \theta = (\sqrt{3}a \sec \theta)/6$ . As $|DF| = \sqrt{6}a/3$ is the height of the tetrahedron and $\tan \alpha = |PF|/|DF|$ , we have $$\alpha(\theta) = \tan^{-1}\left(\frac{|PF|}{|DF|}\right) = \tan^{-1}\left(\frac{\frac{\sqrt{3}}{6}a \sec \theta}{\frac{\sqrt{6}}{3}a}\right) = \tan^{-1}\left(\frac{\sec \theta}{2 \sqrt{2}}\right).$$ We now prepare to integrate in spherical coordinates. The differential for the surface area of the sphere is $dA = R^2 \cos \theta \; d\phi \; d\theta$ where $R$ is the circumradius of the tetrahedron. Using this information, the area that $D$ can reach when $\theta \in [0, \pi/3]$ is $$A_{\pi/3} = \int_0^{\pi/3}\int_0^{\tan^{-1}\left(\frac{\sec \theta}{2 \sqrt{2}}\right)} R^2 \cos \theta \; d \phi \; d \theta.$$ The total area reachable for $\theta \in [0, 2 \pi)$ is $6$ times this value due to symmetry. But, we need to multiply by an additional factor of $2$ to account for the case when $D$ is in front of $\triangle ABC$ (the math should be the same). As the surface area of the circumsphere is $4 \pi R^2$ , the final probability is $$P = \frac{12A_{\pi/3}}{4 \pi R^2} = \frac{3}{\pi} \int_0^{\pi/3}\int_0^{\tan^{-1}\left(\frac{\sec \theta}{2 \sqrt{2}}\right)} \cos \theta \; d \phi \; d \theta \approx 0.33222.$$ The only problem is, from numerical results, I am getting a probability of about $0.35$ , so there is a mistake here somewhere, probably with the procedure itself. But that is the approach I came up with, so what I would like to ask is whether this approach solves the problem at all, and if you have a better idea, whether it be a correction/improvement to mine or something else entirely.","['geometry', 'probability', 'platonic-solids']"
3347857,"Asymptotic behavior of number of triples $i,j,k\le n$ with pairwise bounded least common multiples each $\le n$.","I want to know a tighter bound for the growth rate of $f(n)$ when $n\to\infty $ , where $$
f(n)=\sum_{i=1}^n\sum_{j=i}^n\sum_{k=j}^n [\mathrm{lcm}(i,j)\le n][\mathrm{lcm}(j,k)\le n][\mathrm{lcm}(i,k)\le n]
$$ A trivial upper bound is $O(n\sqrt{n}\log^3 n)$ ，for that the numbers of pair $[\mathrm{lcm}(i,j)\le n]$ is $\Theta(n\ln^2n)$ ，and the number of triple rings of undirected simple graphs is $O(|E|^{1.5})$ 。 A trivial lower bound is $\Omega(n\sqrt{n})$ ，because the triples $i\le j\le k\le \sqrt{n}$ all satisfies the given equation. However, due to the analysis of the function when $n\leq 10^6$ , I guess that the upper bound is not tight, and the real growth rate might be around $\Theta(n\sqrt n)$ . A better upper bound would be $O(n\sqrt{n}\log^{2.25}n)$ 。 Assume $1\le B\le \sqrt{n}$ ，then the number of triples that satisfy $k\le \dfrac{n}{B}$ is $O\left (\left (\dfrac{n}{B}\right )^3\right )$ 。 For $k> \dfrac{n}{B}$ , we have： $$
\begin{eqnarray}
g(n) & = & \sum_{k=\left\lceil\frac{n}{B}\right\rceil}^n\sum_{j=1}^k\sum_{i=1}^j [\mathrm{lcm}(i,j)\le n][\mathrm{lcm}(j,k)\le n][\mathrm{lcm}(i,k)\le n] \\
& \le & \sum_{k=\left\lceil\frac{n}{B}\right\rceil}^n\left (\sum_{j=1}^k [\mathrm{lcm}(j,k)\le n]\right ) \left (\sum_{i=1}^k [\mathrm{lcm}(i,k)\le n]\right ) \\
& \le & \sum_{k=\left\lceil\frac{n}{B}\right \rceil}^n\left (\sum_{j=1}^n [\mathrm{lcm}(j,k)\le n]\right )^2 \\
& \le & \sum_{k=\left\lceil\frac{n}{B}\right \rceil}^n\left (\sum_{d|k} \sum_{j=1}^{\lfloor\frac{n}{d}\rfloor} \left [dj\frac{k}{d}\le n\right ] \right )^2 \\
& \le & \sum_{k=\left\lceil\frac{n}{B}\right \rceil}^n\left (\sigma_0(k)\left \lfloor\frac{n}{k}\right \rfloor \right )^2 \\
& = & O\left (\sum_{k=\left \lceil\frac{n}{B}\right \rceil}^n\left (\sigma_0(k)\frac{n}{k}\right )^2\right ) \\
& = & O\left (\sum_{i=1}^B\sum_{k=\left \lfloor\frac{n}{i+1}\right \rfloor+1}^{\left \lfloor\frac{n}{i}\right \rfloor}\left (\sigma_0(k)i\right )^2\right ) \\
& = & O\left (\sum_{i=1}^B\sum_{k=1}^{\left \lfloor\frac{n}{i}\right \rfloor}\sigma_0^2(k)i\right ) \\
& = & O\left (\sum_{i=1}^Bi\frac{n}{i}\log^3\frac{n}{i}\right ) \\
& = & O(nB\log^3n) \\
\end{eqnarray}
$$ And we can see that when $B=\Theta\left (\dfrac{\sqrt{n}}{\log^{0.75}n}\right )$ , the minimum of two sums is $O(n\sqrt{n}\log^{2.25}n)$ . So my question is, is there a tighter upper/lower bound? UPD: It has been solved by @Eric Naslund with an elegant transformation(I appreciate it very much). I am now curious about how to solve it with Dirichlet series , as @reuns said in the comments.","['number-theory', 'gcd-and-lcm', 'asymptotics', 'analytic-number-theory', 'upper-lower-bounds']"
3347894,Do differential forms and ordinary differential equations have identical solutions?,"Consider the 1-form $$
M(x,y)dx + N(x,y)dy = 0
$$ and the ODE $$
M(x,y) + N(x,y)y'=0.
$$ These functions seem to be identical, and if one were to abuse notation, the first equation, multiplied by $\frac{1}{dx}$ (whatever that means) is equivalent to the second. I believe that they have identical solutions, but my professor said that their solutions are not identical; namely that the solutions to the first are level curves of some function, can be implicit, and are expressed in the form $f(x,y) = c$ , where c is constant, while the second has solutions that are functions, explicit, and are expressed in the form $y(x) = g(x,c)$ , where c is constant.","['differential-forms', 'ordinary-differential-equations', 'differential-geometry']"
3347895,Probability Proof. $P(A | B) = P(A | B^c)$,"Be A,B are independent envents, if and only if $P(A|B) = P(A|B^c)$ I know that $P(A) = P(A∩B) + P(A∩B^c)$ and $P(B)= 1- P(B^c)$ So... $\frac {P(A∩B)}{P(B)} = \frac {P(A∩B^c)}{P(B^c)}$ hence $(1-P(B)) P(A∩B) = P(B)P(A∩B^c)$ $P(A∩B)=P(B)P(A|B^c)$ (this change is not very clear to me) But i can't see how continue... Thanks for the time :)","['elementary-set-theory', 'independence', 'probability']"
3347939,"If $f(x) = e^{x^a}$, what is $f^{(n)}(x)$, the $n$-th derivative of $f$ and what is $\lim_{x \to 0^+} f^{(n)}(x)/x^{a-n}$.","This is inspired by Finding the $18th$ Derivative of a Particular Product at $x = 0$ If $f(x) = e^{x^a}$ ,
what is $f^{(n)}(x)$ ,
the $n$ -th derivative of $f$ and what is $\lim_{x \to 0^+} f^{(n)}(x)/x^{a-n}$ . I'm sure that this is a duplicate,
but I haven't been able to find it. My conjecture is that $f^{(n)}(x)
=f(x)ax^{a-n}g_n(x, a)
$ where $g_n(x, a)
=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-1}c(a, n, k)x^{ka}
$ ,
the $c(a, n, k)
$ are
polynomials in $a$ of degree $n-1$ ,
and $g_n(0,a)
=c(a, n, 0)
=\prod_{k=1}^{n-1} (a-k)
=\dfrac{(a-1)!}{(a-n)!}
$ . Note: 
I just added my derivation of
the recurrence for the $c(a, n, k)$ .
It's messy,
so there is a fair chance of error(s). Here is what I've done. The following was done
with Wolfy and https://www.derivative-calculator.net $\begin{array}\\
f'(x)
&=ax^{a-1}f(x)\\
f''(x)
&=a x^{a - 2} (a x^a + a - 1)f(x)\\
f'''(x)
&=f(x) (a^3 x^{3 a - 3} + (a - 1) a^2 x^{2 a - 3} + a^2 (2 a - 2) x^{2 a - 3} + (a - 2) (a - 1) a x^{a - 3})\\
&=f(x)x^{a-3} (a^3 x^{2 a} + (a - 1) a^2 x^{ a} + a^2 (2 a - 2) x^{ a} + (a - 2) (a - 1)a)\\
&=f(x)ax^{a-3} (a^2 x^{2 a} + ((a - 1) a+a (2 a - 2) ) x^{ a} + (a - 2) (a - 1))\\
&=f(x)ax^{a-3} (a^2 x^{2 a} + 3(a - 1) a x^{ a} + (a - 2) (a - 1))\\
f''''(x)
&=ax^{a-4}f(x)\left(a^3x^{3a}+\left(6a^3-6a^2\right)x^{2a}+\left(7a^3-18a^2+11a\right)x^a+a^3-6a^2+11a-6\right)\\
&=ax^{a-4}f(x)\left(a^3x^{3a}+6a^2(a-1)x^{2a}+a (a - 1) (7 a - 11)x^a+(a - 1) (a - 2) (a - 3)\right)\\
...\\
f^{(n)}(x)
&=f(x)ax^{a-n}g_n(x, a)\\
g_1(x, a)
&= 1\\
g_2(x, a)
&= ax^a+a-1\\
g_3(x, a)
&= a^2 x^{2 a} + 3(a - 1) a x^{ a} + (a - 2) (a - 1)\\
g_4(x)
&=a^3x^{3a}+6a^2(a-1)x^{2a}+a (a - 1) (7 a - 11)x^a+(a - 1) (a - 2) (a - 3)\\
...\\
g_n(x, a)
&=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-1}c(a, n, k)x^{ka}\\ 
\end{array}
$ It looks like $g_n(0, a)
=c(a, n, 0)
=\prod_{k=1}^{n-1} (a-k)
=\dfrac{(a-1)!}{(a-n)!}
$ (the last for integer $a$ ). I'm quite sure that
the existence of the $g_n(x, a)$ can be confirmed by induction,
but finding the form of the recurrence,
though probably straightforward,
would take more work
than I am willing to do right now. Maybe later. And here it is. If $f(x)
=\prod_{k=1}^m f_k(x)
$ ,
then,
removing the "" $(x)$ "", $\ln f
=\sum_{k=1}^m f_k
$ so, differentiating, $\dfrac{f'}{f}
=\sum_{k=1}^m \dfrac{f_k'}{f_k}
$ so that $f'
=\sum_{k=1}^m f_k'\prod_{j=1, j\ne k}^m f_j
$ . Since $\begin{array}\\
f^{(n)}(x)
&=f(x)ax^{a-n}g_n(x, a),\\
f^{(n+1)}(x)
&=(f(x)ax^{a-n}g_n(x, a))'\\
&=f'(x)ax^{a-n}g_n(x, a)+f(x)a(x^{a-n})'g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\
&=ax^{a-1}f(x)ax^{a-n}g_n(x, a)+f(x)a(a-n)x^{a-n-1}g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\
&=a^2x^{2a-n-1}f(x)g_n(x, a)+f(x)a(a-n)x^{a-n-1}g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\
&=f(x)ax^{a-n-1}(ax^{a}g_n(x, a)+(a-n)g_n(x, a)+xg_n'(x, a))\\
&=f(x)ax^{a-n-1}((ax^{a}+a-n)g_n(x, a)+xg_n'(x, a))\\
\text{so}\\
g_{n+1}(x, a)
&=(ax^{a}+a-n)g_n(x, a)+xg_n'(x, a)\\
\text{Since}\\
g_n(x, a)
&=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ 
g_n'(x, a)
&=a^{n-1}a(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1}\\ 
&=a^{n}(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1}\\ 
\text{so}\\
g_{n+1}(x, a)
&=(ax^{a}+a-n)(a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-2}c(a, n, k)x^{ka})\\
&+x(a^{n}(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1})\\
&=(ax^{a}+a-n)a^{n-1}x^{a(n-1)}+(ax^{a}+a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka})\\
&+a^{n}(n-1)x^{a(n-1)}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+(a-n)a^{n-1}x^{a(n-2)}+ax^{a}\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+a^{n}(n-1)x^{a(n-2)}+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+(a-n)a^{n-1}x^{a(n-2)}
+a\sum_{k=0}^{n-2}c(a, n, k)x^{(k+1)a}\\
&+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+a^{n}(n-1)x^{a(n-2)}+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+((a-n)a^{n-1}+a^{n}(n-1))x^{a(n-2)}\\
&+\sum_{k=1}^{n-1}ac(a, n, k-1)x^{ka}\\
&+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+(a^n-na^{n-1}+na^{n}-a^n)x^{a(n-2)}\\
&+\sum_{k=1}^{n-2}ac(a, n, k-1)x^{ka}
+ac(a, n, n-2)x^{(n-1)a}\\
&+(a-n)c(a, n, 0)+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=a^{n}x^{an}+ac(a, n, n-2)x^{(n-1)a}+na^{n-1}(a-1)x^{a(n-2)}\\
&+(a-n)c(a, n, 0)\\
&+\sum_{k=1}^{n-2}(ac(a, n, k-1)+(a-n)+kac(a, n, k))x^{ka}\\
\text{Matching}\\
g_{n+1}(x, a)
&=a^{n}x^{an}+\sum_{k=0}^{n-1}c(a, n+1, k)x^{ka}\\
c(a, n+1, n-1) 
&=ac(a, n, n-2)\\
c(a, n+1, n-2) 
&=na^{n-1}(a-1)+ac(a, n, n-3)+(a-n)+(n-2)ac(a, n, n-2)\\
c(a, n+1, 0) 
&=(a-n)c(a, n, 0)\\
c(a, n+1, k)
&=ac(a, n, k-1)+(a-n)+kac(a, n, k)
\quad\text{for }k=1..n-3\\
\end{array}
$","['induction', 'derivatives', 'exponential-function', 'recurrence-relations']"
3347944,"Construct a compact set with countably infinite limit points using $1/n + 1/m$ (Rudin, Cooke) [duplicate]","This question already has answers here : Find the limit points of the set $\{ \frac{1}{n} +\frac{1}{m} \mid n , m = 1,2,3,\dots \}$ (5 answers) Closed 4 years ago . So I am having trouble proving that if $$
K= \{0\} \cup \left\{\frac1n: n = 1,2,\ldots\right\} \cup \left\{\frac1n + \frac1m : n=m,m+1,\ldots; m=1,2,\ldots \right\}
$$ then 0 and the points $\frac1m$ are the only limit points of $K$ . Cooke proves this by saying that: Since $x\geq0$ for all $x \in K$ and for any positive number $\epsilon$ there is only a finite set of number s in $K$ larger than $1+\epsilon$ , it is clear that no negative number and no number larger than 1 can be a limit point of K. Hence we need only consider positive numbers $x$ satisfying $0\lt x \lt 1 $ . If $x$ is such a number and $x$ is not one of the points $\frac1m$ , let $p$ be such that $\frac1{1+p} \lt x \lt \frac1\epsilon$ , and let $\epsilon=\frac12\min(x-\frac1{p+1},\frac1p - x)$ . The intersection of the set $K$ with the interval $(x-\epsilon,x+\epsilon)$ is contained in the set of points $$
\left\{\frac1{p+1}+\frac1k:p+1\le k \lt \frac1\epsilon\right\} \cup \left\{\frac1m+\frac1n:m\le n \lt \frac1{p+1} - \frac1{p+2}; m=p+2, \ldots,2p+2\right\},
$$ which is a finite set. Therefore $x$ cannot be a limit point of $K$ . I understand why you take $\epsilon$ to be half of $\min$ , and the using that every neighborhood around a limit point contains infinitely many points, but I don't understand why the intersection of $K$ with the interval $(x-\epsilon,x+\epsilon)$ is contained in the set mentioned above, and why it is finite. Is it a typo? $$
\left\{\frac1m+\frac1n:m\le n \lt \frac1{p+1} - \frac1{p+2}; m=p+2, \ldots,2p+2\right\},
$$ here I think n is meant to be an integer in order for the finite argument to work, but how can be $$
n \lt \frac1{p+1} - \frac1{p+2}\:\:?
$$ Here is how I fixed the typo to work: if $$
\left\{\frac1m+\frac1n:m\le n \lt \frac1{p+1} - \frac1{p+2}; m=p+2, \ldots,2p+2\right\}
$$ is changed to $$
\left\{\frac1m+\frac1n: m\le n, \frac1n \ge \frac1{p+1} - \frac1{p+2}; m=p+2, \ldots,2p+2, n \in N\right\},
$$ then $m\le n \le (p+1)(p+2)$ which would be finite. Am  I understanding this argument correctly? I think there is a typo or error in Cooke's solution, as the original version can't seem to work. I know there are other constructions that can be understood easily, but I would like to understand Cooke's proof of $\frac1n + \frac1m$ and see if there are are any typos or errors in the original solution. Thanks a lot.","['limits', 'proof-explanation', 'real-analysis']"
3347948,Classify all groups of order $375$,"According to A000001 , the number of groups of order $375$ is $7$ . How to figure them out? $5$ groups can be found in this way: Because the number of $125$ -order groups is $5$ , we can make the direct product of those groups of order $125$ with $Z_3$ and then we get $5$ $375$ -order groups. But how to find the another two groups? UPD: one of the rest of groups is $C_5^3\rtimes C_3$ , and now the task is to find the last missing group. UPD2: Now I think that a more profound comprehension (to Jyrki Lahtonen's answer) would be appreciated...","['group-theory', 'abstract-algebra', 'groups-enumeration', 'discrete-mathematics']"
3348055,Condition for $ \text{rank}(A) = \text{rank}(A^2) $,"Let $ A $ be an $ n \times n $ complex matrix. Prove that $ \text{rank}(A) = \text{rank}(A^2) $ if and only if $ \lim_{\lambda \to 0} (A + \lambda I)^{-1}A $ exists. I'm not exactly sure how to approach this sort of question. I've thought about putting $ A $ in Jordan form and working with Jordan blocks, but it seems messy.","['limits', 'linear-algebra']"
3348059,"If a trigonometric series converges to a function $f$, is the Fourier series of $f$ the original series?","If a trigonometric series $\frac{1}{2}a_0+\sum_{n=1}^\infty (a_n\cos(nx)+b_n\sin(nx))$ converges pointwise to a function $f$ , then is the Fourier series of $f$ the original trigonometric series? I know that if we have uniform convergence, then we can integrate term by term and the conclusion is true. But what if we only have pointwise convergence? I appreciate any help!","['trigonometric-series', 'fourier-series', 'fourier-analysis', 'analysis']"
3348075,Proving a result by making discriminant zero,"If the roots of given Quadratic equation $$a(b-c)x^2 +b(c-a)x + c(a-b)=0$$ are equal, prove the following: $$\frac{2}{b}=\frac{1}{a}+\frac{1}{c}$$ . MY approach : Method 1: put Discriminant=0 and get stuck. Method2:add $acx$ on both sides and get $(x-1)$ as factor ,so other root is also 1 and hence the result. But if someone can prove the result by making discriminant zero (method 1), that would be more rigorous.
Thank you.","['algebra-precalculus', 'quadratics']"
3348089,How to find eigenvalues of the matrix,"This is a question from our end-semester exam: How to find the eigenvalues of the given matrix: M= \begin{bmatrix}
5,1,1,1,1,1\\
1,5,1,1,1,1\\
1,1,5,1,1,1\\
1,1,1,5,1,1\\
1,1,1,1,4,0\\
1,1,1,1,0,4\\
\end{bmatrix} I know that $4$ is an eigenvalue of $M$ with multiplicity atleast $3$ since $M-4I$ has $4$ identical rows. Is there any way to find all eigenvalues of this matrix? I could find only $3$ out of $6$ .","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3348116,Mathematical reason behind exponential distribution in random shuffling of balls in boxes,"Let's take a very simple problem where 1000 identical boxes initially each have 10 balls. Then we select at random one box, take out a ball from it and put it into another box chosen again randomly. This algorithm repeated large number of times always give exponential distribution with most boxes being empty and only few with large number of balls. Sample code for problem illustration: import numpy as np  
import matplotlib.pyplot as plt  

box = np.ones(1000)  
box = box*10  
for i in range(100000):  
    rand = np.random.randint(low=0, high=1000, size=2)  
    if box[rand[0]] > 0:  
        box[rand[0]] = box[rand[0]] - 1  
        box[rand[1]] = box[rand[1]] + 1  
#     print(box)  
plt.hist(box,bins=50)  
plt.show() Question: Probability of choosing a box is equal for any box, then can't we assume that in large number of trials, each box is chosen equal number of times for removal of ball and similarly each box is chosen equal number of times to add a ball to it?
Why after a large repeated trials, the number of balls in each box does not reach equilibrium value 10. Why most of the boxes are emptied and only handful are filled with huge number of balls. This seems counter-intuitive. Is it something to do with the way random number generators are designed so we indeed get binomial distribution to imitate some physical behavior? Or there is a purely mathematical intuition behind?","['statistics', 'probability']"
3348126,"Two approaches to duality in TVS: dual pairing versus ""canonical"" dual. Are they equivalent?","I have been reading about the basics of duality in Topological Vector Spaces and I have met two different approaches. Treves starts from a TVS $(E,\iota)$ , which determines the set of continuous
linear forms on $E$ : $E'_\iota$ . Then he describes a technique to
topologize $E'_\iota$ through polar topologies on $E'_\iota$ . He then describes an analogous way to topologise the set of
continuous linear maps $\phi:(E,\tau)\rightarrow (F,\sigma)$ where $(E,\tau)$ and $(F,\sigma)$ are two TVS, let us call this set $L(E,F)$ . This is
evidently a generalization of the previous case, if one considers $\mathbb{R}$ or $\mathbb{C}$ with the usual topology. Characherizes which topologies $\tau$ on $E$ are such that $E'_\iota=E'_\tau$ . Hence, which way of retopologizing a TVS $E$ preserve its topological dual. He calls these topologies compatible with a duality and proves that any topology on a locally convex TVS $E$ can be seen as such: it is the topology of uniform conergence on equicontinuous subsets of $E'$ . Moreover he shows that $\sigma(E,E')$ , the topology of convergence on finite sets of $E'$ is the coarsest to achieve the result and moreover he shows we can always embed $E$ in $(E'_\sigma)'$ . Proves the Mackey theorem stating that topologies compatible with a duality share the same bounded sets, and treat reflexivity. Schechter Start from an abstract dual pair $\langle E,F\rangle$ : this is a completely algebraic construction. $E$ and $F$ are two vector spaces and $\langle,\rangle$ is a (separating) dual form. Describe polar topologies on $E$ or on $F$ in an analogous way as Treves. Now, however this is done through $\langle,\rangle$ and not the canonical evaluation of elements of the dual $E'$ . Describe how the topology $\sigma(F,G)$ is the weakest making all the evaluations of elements of $G$ aigainst element of $F$ continuous, and gives both the result about the topology of equicontinuous convergence and the embedding in the double dual. Now I ask: Are these two approaches completely equivalent? It seems that, obviously, the Schechter's approach includes Treves by considering the canonical evaluation of a functional of $E'$ angainst an element of $E$ .  Anyhow, I personally find Treves' discussion neater, and moreover all examples I encountered so far are of the type $<E,E'>$ . But can this appproach be shown equivalent to the former? If we start from a dual pair $\langle F,G\rangle$ can we always
recover all informations about it by considering some topology on $F$ and $\langle F,F'\rangle$ ? If not which are the differences between the two? What I can notice, at the algebraic level is the following rather straghtforwad fact A vector space $E$ and its algebraic dual $E^*$ form a dual pair $\langle E,E^*\rangle$ where the pairing bilinear map is given by the
evaluation of linear functionals: $(x\in E, y\in E^*)\mapsto y(x)\in
   \mathbb{R}$ . Conversely, given an arbitrary separating dual pair $\langle
   E,F\rangle$ , we can notice that the bilinear form $\langle,\rangle$ ,
a fixed $y\in F$ induces a linear map $x\mapsto <x,y>$ which is
linear and injective. Hence it is an element of $E^*$ then $F$ can
always  be indentified with a subspace of $E^*$ . Or viceversa, with $E$ and $F^*$","['proof-explanation', 'topological-vector-spaces', 'functional-analysis', 'general-topology', 'duality-theorems']"
3348160,"f is a differentiable function with $f(0)>0$. f has only one fixed point on [0,1] Prove that $f′(x_0)<1$","Question: Let $f:[0,1]\rightarrow [0,1]$ be a differentiable function with $f(0) > 0$ . Asuming $x_0\in(0,1)$ is the only fixed point of $f$ , prove that $f'(x_0) < 1$ My Attempt: Let $g(x) := f(x)-x$ for $x\in[0,1]$ By given condition $g(0) = f(0)-0 > 0$ As $f$ has unique fixed point on [0,1] so $g$ will have only one solution on [0,1].
So if $g(0)>0$ then $\forall x<x_0,\; g(x)>0\; and \; \forall x>x_0,\; g(x)<0$ Now $g'(x)=f'(x)-1$ $f$ is differentiable on [0,1] so is $g$ . Consider Right-hand derivative of $g$ at $x_0$ $A=\lim_{h \rightarrow 0}\frac{g(x_0+h)-g(x_0)}{h}$ for $h>0$ Using fact that $g(x_0)=0\;and\;\forall x>x_0,\; g(x)<0$ we have $A<0$ So we can say that $g'(x_0)<0$ Therefore $f'(x_0)<1$ I want to know if my proof is correct or not. Is there any simple proof for this question.","['proof-verification', 'derivatives', 'analysis', 'real-analysis']"
3348202,Deriving polar substitution formula for double integrals,"I'm studying double integrals (the theory part, not the problem solving). We're  trying to derive the formula for the polar substitution in a double integral: $$\iint_{D}f(x, y)dxdy = \iint_{D_1}f(r\cos\theta, r\sin\theta)rdrd\theta$$ where $x = r\cos\theta, y = r\sin\theta$ maps $D_1 \to D$ First I want to say that it is explicitly stated in the textbook that we're not going to prove the general formula for substitutions in the integral (the one that uses the Jacobian) but rather, just for now, the formula for the polar substitution. It starts by defining a set $S := \big\{(r, \theta)|\bar{r_1} \leq r\leq \bar{r_2}, \bar{\theta_1} \leq \theta \leq \bar{\theta_2}\big\}$ and dividing this set using lines/curves $r = r_j$ and $\theta = \theta_j$ where: $$r_j := \bar{r_1} + j\triangle r, \text{where } \triangle r := \frac{\bar{r_2} - \bar{r_1}}{n}
\\\theta_j:= \bar{\theta_1}+j\triangle \theta, \text{where } \triangle\theta := \frac{\bar{\theta_2} - \bar{\theta_1}}{n}
$$ and $j=0, 1, ..., n$ This part is clear, it's pretty similar to dividing a rectangular region when defining a double integral itself. So an illustration would look something like this (sorry for the bad picture, couldn't find a way to do it in Desmos): The following sentence really confuses me because it's stated as a given (without any explanation whatsoever): If we look at the region $\big\{ (r, \theta)| r_0 \leq r \leq r_0 + \triangle r, \theta_0 \leq \theta \leq \theta_0 + \triangle \theta  \big\}$ we notice that the area of that region is $$\frac{1}{2}\triangle \theta ((r_0 + \triangle r)^2 - r_0^2) = (r_0 + \frac{\triangle r}{2})\triangle r \triangle \theta$$ The region that we're talking about is, as far as I can see, the 'bottom-right' sub-region of the set $S$ , since $r_0 = \bar{r_1}, \theta_0 = \bar{\theta_1}$ . What I don't see is how what they said is the area of that region? Speaking in polar terms the region defined should actually be a rectangle, so I guess the area should be just $\triangle r \triangle \theta$ , but apparently I'm missing something. After this statement it goes on to show the formula I've mention above and it's all clear from here on, it's just this one part that I can't understand. Any ideas? Thanks.","['integration', 'multivariable-calculus', 'polar-coordinates']"
3348206,A reverse Azuma's inequality for martingale,"I thought finding a reverse Azuma's inequality. Are there any inequality or lower bound looks like the following. Suppose $\{X_k:k=0,1,2,3...\}$ is a martingale and $$P(|X_N-X_0|\ge t)\ge f(t)$$ . I saw a similar lower bound for binomial distribution, which is as the following. Suppose $X$ follows Binomial(n,p), $$P(X\ge k) \ge \frac{1}{\sqrt{2n}}\exp(-nD(\frac{k}{n}||p))$$ . Can I find a similar inequality in martingale? Thanks !","['martingales', 'inequality', 'probability', 'upper-lower-bounds']"
3348209,Walking on an infinite grid,"I am sure someone has asked a similar question already, but I wasn't able to find it. So lets get started: We have an infinite grid with coordinates out of $ \mathbb{Z} $ . Lets say the first coordinate is the X and the second is the Y. We start at some position on the grid (lets say $ (2, 2) $ ) and now want to go to an other position (lets say $ (42, 2) $ ). To do that we could go the following steps (for example): $$A=(+1, 0)$$ $$B=(+1, +1)$$ $$C=(+1, -1)$$ Now I want to know the number of possible ways using the steps from above. I already had some ideas - I'll list them here too for inspiration: The step A has a weight of one and the step B and C has a combined weight of 2. So my mission is to find the number of their combinations to reach 40 (see example from above). BUT this doesn't work because combinations like 'BAC' are also valid. I count the possible ways to perform the steps B and C: If n equals the number of steps into the right direction, so i can go B on $n-1$ steps (the last one is impossible, because for now I start with up only) and it corresponding down step can be on $n-2$ steps and so on... This doesn't work, because I could go on $n-1$ steps up and on the n-th all down. Additionally things like 'BCCAB' are with this model also not possible. Well, I can see a pattern there (n equals steps to the right): 40xA; 0xB+C -> 1 possible way 38xA; 1xB+C -> $ n * (n-1) $ possible ways 36xA; 2xB+C -> $ n * (n-1) * (n-2) * (n-3) $ possible ways 34xA; 3xB+C -> $ n * (n-1) * (n-2) * (n-3) * (n-4) * (n-5) $ possible ways ...so maybe something like this: $ \prod\limits_{i=0}\limits^{n/2-1} ( (n-i*2) * (n-i*2-1) ) $ So, anyone has an idea or hint for me? EDIT: Added third idea.","['combinatorics', 'discrete-mathematics']"
3348226,"Given $G,H_1,H_2$ finite abelian groups and $G\times H_1 \cong G\times H_2$ then $H_1 \cong H_2$ [duplicate]","This question already has an answer here : Direct sum of Abelian groups and Isomorphism (1 answer) Closed 4 years ago . Given $G,H_1,H_2$ finite abelian groups and $G\times H_1 \cong G\times H_2$ Show $H_1 \cong H_2$ I think the proof would go something like this: $H_1\cong(G\times H_1)/(G\times\{e_{H_1}\})\cong(G\times H_2)/(G\times\{e_{H_2}\})\cong H_2$ Though the first and third isomorphisms are somewhat obvious, I'm doubtful about the second isomorphism because Given $\Phi:G_1 \to G_2$ is an isomorphism, I only know that (this is a guess) $G_1/H\cong G_2/\Phi(H)$ (is this true? I have not verified) But $\Phi((G,e_{H_1}))$ may not be equal to $(G, e_{H_2})$ So how do I show this?","['group-theory', 'group-isomorphism', 'finite-groups']"
3348258,Need help to understand the integral rules used solving the convolution of two functions,"I am teaching myself how convolution works, there's a question which looks like this - find the convolution of the following two functions $f$ and $g$ . I understand the problem intuitively that the resulting function should be essentially the product of $f$ sweeping over $g$ , and since the functions are quite simple, I can find key points like when $x = 0, 1, 2, 3$ and interpolate the graph of the resulting function easily. While reading through the ""solution"" of this problem in my textbook, for the intersection of $0 \le x \lt 1$ , the author wrote this: for $0\leq x<1$ , $$\int_{-\infty}^{\infty} g(t)\cdot f(x-t)dt=\int_{0}^x 2t\cdot  dt=\frac{x^2}{2}\cdot 2.$$ which I'm having trouble to understand. How exactly did he replace the $\infty$ and $-\infty$ with $0$ and $x$ , and how exactly did he turn the whole $g(t) \cdot f(x-t)$ into $2t$ ?","['integration', 'convolution']"
3348283,Induced map on $T(X)$ the Tangent bundle,"If $ f:X\to Y$ is an Immersion\ Submersion\ Diffeomorphism then what can we say about the induced map $ df: T(X)\to T(Y) $ defined as $df(x,v)= (f(x),df_x(v))$ .
 Will it also have the same properties? I don't know how to start, kindly help. Thanks & regards","['differential-topology', 'differential-geometry']"
3348284,Cotangent complex of dual numbers,"Let $k$ be a ring, put $k[\epsilon] := k[t]/(t^2)$ . What is the cotangent complex of $k[\epsilon] \to k$ ? I know $\Omega^1_{k/k[\epsilon]]}$ is going to be zero. But I don't see any way around explicitly writing down a cofibrant replacement to get the whole complex. I tried to do something like a bar construction for this, but I can't get it to work. If it helps, I'm happy to assume $k$ is a field. edit: I've gotten an idea, would still appreciate a confirmation. Look at $k[T] \to k[\epsilon] \to k$ . Then the fundamental triangle gives \begin{align*}
\mathcal{L}_{k[\epsilon]/k[T]} \otimes_{k[\epsilon]} k \to \mathcal{L}_{k / k[T]} \to \mathcal{L}_{k/k[\epsilon]}
\end{align*} We know that $f:k[T] \to k[\epsilon]$ is regular since $T^2$ is not a zero-divisor in $k[T]$ . Let $I$ be the kernel of $f$ , i.e. $I=(T^2)$ . Then we know that the cotangent complex of $f$ is the conormal sheaf of $\mathrm{Spec} k[\epsilon] \to \mathrm{Spec}k[T]$ concentrated in degree 1. We can thus compute the first term in the above triangle as \begin{align*}
\mathcal{L}_{k[\epsilon]/k[T]} \otimes_{k[\epsilon]} k \simeq (I/I^2)[1] \otimes_{k[\epsilon]} k
\end{align*} which I think comes out to be $k[1]$ . Since we also know that $\mathcal{L}_{k / k[t]}$ is zero, this gives us $\mathcal{L}_{k/k[\epsilon]} = k[2]$ . Is this answer believable?","['algebraic-geometry', 'proof-verification', 'deformation-theory', 'commutative-algebra']"
3348290,Lemma 4.1. Do Carmo's Riemannian Geometry,"A question about the lemma in the title: Lemma 4.1. For any $p \in M$ there exists a number $c > 0$ such that any geodesic in $M$ that is tangent at $q \in M$ to the geodesic sphere $S_r(p)$ of radius $r < c$ stays out of the geodesic ball $B_r(p)$ for some neighborhood of $q$ . I'll write down the proof and write the question after Proof. Let $W$ be a totally normal neighborhood of $p$ . Using the lemma of homogeneity, we can suppose, by conveniently restricting the the interval of definition, that all of the geodesics of $W$ have velocity one. We can, therefore, restrict ourselves to the unit tangent bundle $T_1 W$ given by $$
T_1 W = \left\{(q,v) : q \in W, v \in T_q M, |v| = 1 \right\}
$$ Let $\gamma : I \times T_1 W \to M$ , $I = (-\epsilon,\epsilon)$ , be the differentiable mapping such that $t \to \gamma(t,q,v)$ is the geodesic that at the instant $t=0$ passes through $q$ with velocity $v, |v| = 1$ . Define $u(t,q,v) = \exp_p^{-1}(\gamma(t,q,v))$ and $$
F:I\times T_qW \to \mathbb{R}, \;\;\;\; F(t,q,v) = |u(t,q,v)|^2.
$$ $F$ measures the square of the ""distance"" from $p$ to a point that is moving along the geodesic $\gamma$ . It is clear that $u$ and $F$ are differentiable, and that $$
\begin{array}{l}
\frac{\partial F}{\partial t} = 2 \left\langle \frac{\partial u}{\partial t}, u\right\rangle \\
\frac{\partial^2 F}{\partial t^2} = 2 \left\langle \frac{\partial^2 u}{\partial t^2}, u\right\rangle + 2 \left| \frac{\partial u}{\partial t} \right|^2
\end{array}
$$ Now let $r > 0$ be chosen so that $$
\exp_p B_r(0) = B_r(p) \subset W
$$ If a geodesic $\gamma$ is tangent to the geodesic sphere $S_r(p)$ at the point $q = \gamma(0,q,v)$ , then, from the Gauss lemma $$
\left\langle \frac{\partial u}{\partial t}(0,q,v), u(0,q,v) \right\rangle = 0
$$ Question : How is the Gauss lemma exactly applied here?","['proof-explanation', 'manifolds', 'riemannian-geometry', 'differential-geometry']"
3348292,"Finding $1$, $2$, $3$, $\ldots$, $n$ in a random string of $x$ digits","A weird but an interesting question I thought of ... Consider this random 100-digit integer that I generated using random.org $$9771602964370316251552537368279107346523948777589513994616004391156991741564023185294939440725424639$$ This number will most likely have $1,2,3..$ upto $9$ in them. But when we further look into we can also find $10$ , (i.e $1$ then $0$ right after) and also $11$ . But there's no $12$ in them (i.e no $1$ then a $2$ right after). So what I want to find out is what will be the approximation of $n$ , such that there will be $1,2,3,...,(n-2),(n-1),n$ integers that can be seen inside a random x-digit. Also note that $(n+1)$ can never be found in a random x-digit. If you say that the 'n' value will change randomly and there cannot be any asymptotic or approximations of that. You're kind of wrong. See, I did this with 9 other random 100-digit numbers and also the 100 decimal places of the famous constants $\pi,e$ and $\phi$ . The results are pretty close to $11$ . Here are them; (scroll right to see the corresponding $n-values$ ) $$\begin{array} {|r|r|}\hline Sl. No. & 100-Digit Integer & n-value \\ \hline 1 & 9771602964370316251552537368279107346523948777589513994616004391156991741564023185294939440725424639 & 11 \\ \hline 2 & 5933798531736924945959336111487355483181228762319970946972332473586986158448822614193445434946714049 & 9 \\ \hline 3 & 0748006010018385701305255708540275105163777493821503992289412752198434315022707697359036044788900096 & 10 \\ \hline 4 & 8895177092192596874320826762636449513223106780359367744719402357085023730983517329137267473940940810 & 10 \\ \hline 5 & 4921918080733246056200145588743524919616898465382373461652822273753544023393089458416653653351525383 & 9 \\ \hline 6 & 6386614054105909456194325500596228770058096441918965347422338768650600045406879715848359336828536144 & 10 \\ \hline 7 & 8599263737601951772329677396723688342052445287633091648167742178784189581850841772769226465303321562 & 9 \\ \hline 8 & 0660623044515625611084768937485195387862394776640249639087054616789402273433078233077669093361145164 & 11 \\ \hline 9 & 8747230800762985911116404157733707704590034002122077023051291424897238915375434573976156208269944527 & 9 \\ \hline 10 & 1177720655605689615530670722522895831819411456667323162088720568188745848931083487687853204730731860 & 11 \\ \hline π & 1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 & 11 \\ \hline e & 7182818284590452353602874713526624977572470936999595749669676277240766303535475945713821785251664274 & 9 \\ \hline φ & 6180339887498948482045868343656381177203091798057628621354486227052604628189024497072072041893911374 & 9 \\ \hline  \end{array}$$ Now take the average of all the n-values and you'll get $n ≈ 9.8$ , for $x=100$ I'm starting to work on $x=1000$ and for a hint $n ≈ 99$ or $100$ and this is just like approximate value of an approximate value, I'll find a good approximate value soon. So what are your thoughts on this? What will be a good expression that could take in the $x$ value and give a good approximate? I'm got a formula, a crude, anecdotal that could give a value close to what is got. I'll post it soon after a few modifications. EDIT Some observations that I did. $$n ≈ \frac{x}{10}\tag{1}\label{1}$$ Or I can say that for a $x$ , the $n$ value is; (Big thanks to @glowstonetrees for an inspiration.) $$n≈9*10^{m−3}\tag{2}\label{2}$$ Where $m$ is the no. of digits of $x$ . But we know $x$ is the no. of digits of the given $x$ -digit value. So $m$ is like no. of digits of the no. of digits of $x$ -digit integer Now for my own anecdotal estimate of this; $$n≈\pi^{2\left(\log\left(x\right)-1\right)}\tag{3}\label{3}$$ The reason I chose log is that it is a ""slow-moving"" function so it doesn't change rapidly. And don't ask me why $\pi$ is there, I don't know I kinda like it. But I also edited it and made it more efficient; so it is; $$n≈\pi^{2\left(\log\left(x\right)-\sin\left(79.4\right)\right)}\tag{4}\label{4}$$ The reason I chose $\sin(79.4)$ is that $$\sin(79.4)=0.9829353491$$ So I didn't want an exact $1$ as in Eq.3 but a rather a number close to 0.98. And I believe this is an irrational number and $sin(79.8)$ is just an estimate for this. ** Now to test all these expressions with $x=10000$ , from data I got that $n≈999$ $$n≈\frac{10000}{10}=1000\tag{By Eq.1}\label{5}$$ $$n≈9*10^{5−3}\tag{By Eq.2}\label{6}=900$$ $$n≈\pi^{2\left(\log\left(10000\right)-1\right)}≈961.38\tag{By Eq.3}\label{7}$$ $$n≈\pi^{2\left(\log\left(10000\right)-\sin\left(79.4\right)\right)}≈999.6\tag{By Eq.4}\label{8}$$ So yeah even know my equation, i.e Eq 4 did well; I have to say Eq 1 of $n≈\frac{x}{10}$ is really the best bet for simplicity and accuracy.","['random', 'decimal-expansion', 'sequences-and-series']"
3348338,The proof of lemma 1 in Dempster's 1977 EM algorithm paper,"I am learning the proofs about general properties for the EM algorithm in Dempster's 1977 EM algorithm paper 1 . In it I found that the proof of Lemma 1, which is attached below, is referred to a conclusion in Rao's statistical inference book 2 . But when I checked the (1e5.6) formulae, I found it is just the Jensen's equation. While (1e6.6), which is attached below, has an extra application condition that $\int_S(f-g)\geq0$ , I suppose there shall be a corresponding  relationship between $\phi$ and $\phi'$ . In contrast, Dempster's lemma 1 says that $\phi$ and $\phi'$ could be any pairs, which makes me confused. Could you please tell me which part of my thinking is wrong or an entire proof for this lemma? I also found a related question on this topic: Jensen's inequality in derivation of EM algorithm .
However, it is not totally the same. 1 Dempster, Arthur P., Nan M. Laird, and Donald B. Rubin. ""Maximum likelihood from incomplete data via the EM algorithm."" Journal of the Royal Statistical Society: Series B (Methodological) 39, no. 1 (1977): 1-22. 2 Rao, C.R., 1973. Linear statistical inference and its applications. New York: Wiley.","['expected-value', 'statistics', 'probability']"
3348349,Evaluating $ \lim_{x\to \infty} x \left({{\left(\frac{x}{x+1}\right)}^{x}-\frac{1}{e}}\right)$ [duplicate],"This question already has answers here : Computing $\lim_{x \to \infty} x \biggl[ \frac{1}{e} - \left( \frac{x}{x+1} \right)^x \biggr]$ (3 answers) Closed 3 years ago . Evaluate the following: $$
\lim_{x\to \infty}
 x \left({{\left(\frac{x}{x+1}\right)}^{x}-\frac{1}{e}}\right)$$ I tried to first solve the interior portion as $1^\infty$ indeterminate form but ended up getting a different indeterminate form of $\infty\cdot 0$ .","['limits', 'limits-without-lhopital']"
3348389,Prove that $f(x) = x^3 -x $ is surjective,"Problem: Prove that the mapping $ f: \mathbb R \rightarrow \mathbb R , f(x) = x^3-x$ is surjective. Let $y\in \mathbb R$ such that $f(x)=y$ for some $x\in  \mathbb R$ . Then $x^3-x=y$ . If we can express $x$ in terms of $y$ , then we can say something about surjectiveness. But I stuck at that point. What is the way to solve this problem?","['calculus', 'functions', 'real-analysis']"
3348412,"A property between ""separable"" and ""second countable""","Let $(X, \tau)$ be a topological space. It is second countable if it has a countable basis $B \subseteq \tau$ . It is separable if there exists a countable $S \subseteq X$ such that $O \cap S \neq \emptyset$ for every nonempty $O \in \tau$ . It is well known that second countability is strictly stronger than separability. I'm working on something hinges on an intermediate property: ""there exists a countable subset $C \subseteq \tau$ [edit: with each $C$ -member nonempty !] that is dense in $\tau$ , in the sense that for all $O \in \tau$ , there exists $P \in C$ such that $P \subseteq O$ ."" Is there a common name for this property? I will call it ""property C"" for now. Second countability implies property C (since a countable basis for $\tau$ is dense in $\tau$ ), which implies separability (choose one member from each $P \in C$ and the set of all the choices serves as the $S$ in the definition of separability). The Moore plane is an example of a topology that has property C but is not second countable. Are there examples of topological spaces that are separable but do not have property C?",['general-topology']
3348422,"If you draw two cards in consecutively in a standard deck of 52 cards, what is the probability of getting black on the second draw?",This is my thought process: $P(2^{nd}\ \text{black}) = P(2^{nd}\ \text{black} \mid 1^{st}\ \text{red}) P(1^{st}\ \text{red}) + P(2^{nd}\ \text{black} \mid 1^{st}\ \text{black}) P(1^{st} \ \text{black}) $ $\frac{26}{51}*\frac{26}{52} + \frac{25}{51}*\frac{26}{52} = \frac{1}{2} $ Is this correct?,['probability']
3348443,Prove that $a^2+u^2+d^2-b^2-c^2-v^2>-4w^2$,"Let $ABCD$ be cyclic quadrilateral of the circle $O$ with: $$R=w\text{ is radius };AB=a;BC=b;CD=c;DA=d;AC=u;BD=v$$ . Prove that $$a^2+u^2+d^2-b^2-c^2-v^2>-4w^2$$ We have $$u=\sqrt{\frac{\left(ac+bd\right)\left(ad+bc\right)}{ab+cd}};v=\sqrt{\frac{\left(ac+bd\right)\left(ab+cd\right)}{ad+bc}}$$ and $$R=\frac{1}{4}\sqrt{\frac{\left(ab+cd\right)\left(ac+bd\right)\left(ad+bc\right)}{\left(s-a\right)\left(s-b\right)\left(s-c\right)\left(s-d\right)}} \text{for 
 } s=\frac{a+b+c+d}{2}$$ Then by BW and computer we're done. But it's very ugly.I have no idea to solve it without computer. Help me.","['inequality', 'geometry']"
3348463,Prove $\int_0^1\frac{\ln x\ln(1+x)}{1-x}\ dx=\zeta(3)-\frac32\ln2\zeta(2)$,"How to prove without using Euler sums that $$I=\int_0^1\frac{\ln x\ln(1+x)}{1-x}\ dx=\zeta(3)-\frac32\ln2\zeta(2)$$ where $\zeta$ is the Riemann zeta function. We can relate this integral to some Euler sum as follows: \begin{align}
I&=-\sum_{n=1}^\infty\frac{(-1)^n}{n}\int_0^1\frac{x^n\ln x}{1-x}\ dx\\
&=-\sum_{n=1}^\infty\frac{(-1)^n}{n}(H_n^{(2)}-\zeta(2))\\
&=-\sum_{n=1}^\infty\frac{(-1)^nH_n^{(2)}}{n}-\ln2\zeta(2)
\end{align} Also the integral $I$ can be related to $\sum_{n=1}^\infty\frac{(-1)^nH_n}{n^2}$ . So I am looking for a different way to evaluate $I$ besides using these two sums.","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'riemann-zeta']"
3348487,How many glue flaps are needed for each shape's net?,"So I was creating some dice from printed nets, and I noticed it doesn't matter where you put the glue flaps(1) around the net(2) of a d6(cube) you'll always end up with 7 flaps if the net can produce a valid cube: This also happens for d20(icosahedron), for which there can be many nets with different shapes, But still with the same number of flaps(11): and d12(dodecahedron) which one would think should have a simpler net because the smaller number of faces, actually had even more flaps than d20 which made it much harder to craft: So this made me curious, is there a set number of flaps needed for a certain shape or this is a coincidence that I found nets with the same number of flaps? if there is a certain number, is there a formula for it? and if there isn't, how can I make sure the net I make is the most efficient one available (there are other factors like the number of creases needed and having a least one flapless face for that, but we only talk about the number of the flaps for now). Any additional information about nets and creatable shapes is appreciated. Internet seems void of any information on any net other than the net of a normal cube. (1) A flap is used to glue two faces of the shape which aren't already connected in the net and every edge between two such faces needs a flap on one of the faces it connects. you can search for a video of a cube being made from the net to fully understand the flap's usage. (2) Opened 3d shape on the 2d plane that can be folded to make the 3d shape.",['geometry']
3348489,The upper half plane as a hermitian manifold,"I am reading about Shimura Varieties and I am at odds with some of the claims being made (I realize this problem really has nothing to do with number theory, but perhaps some number theorists have come across this). Here are the definitions that I am working with: Let $M$ be a smooth manifold. A riemannian metric on $M$ is a smooth 2-tensor field $g$ such that $$g_{p} : T_{p} M \times T_{p}M \rightarrow \mathbb{R}$$ is symmetric and positive definite for all $p$ . An almost-complex structure on $M$ is a smooth tensor field $J = (J_{p})_{p \in M}$ $$ J_{p} : T_{p}M \rightarrow T_{p}M$$ such that $J^2 = -1$ for all $p \in M$ . If $M$ is a complex manifold and $z^1 , \dots , z^n$ are local coordinates about $p$ and $x^1 , \dots , x^n , y^1, \dots, y^n$ are the corresponding real coordinates, then $J_{p}$ acts by $$\frac{\partial}{\partial x^j} \mapsto \frac{\partial}{\partial y^j} \quad \text{ and } \quad \frac{\partial}{\partial y^j} \mapsto -\frac{\partial}{\partial x^j}$$ A hermitian metric on a complex (or almost complex) manifold $M$ is a riemannian metric $g$ such that $$ g(JX , JY) = g(X , Y) \quad \text{for all vector fields } X , Y.$$ A hermitian manifold $(M , g)$ is a complex manifold $M$ with a hermitian metric $g$ . My problem is that the notes claim that the complex upper half plane $\mathcal{H}$ becomes a hermitian manifold (among other things) when endowed with the metric $g: = \frac{dxdy}{y^2}$ . While $g$ is certainly symmetric, my calculations show that $g$ is not positive definite; I have worked it out a few different ways, but maybe the easiest way to see this is that the matrix representation of $g$ with respect to the basis $\left\{ \frac{\partial}{\partial x} , \frac{\partial}{\partial y} \right\}$ is $$ [g] = \begin{pmatrix} 0 & \frac{1}{2y^2} \\ \frac{1}{2y^2} & 0  \end{pmatrix},$$ which is certainly not positive definite. Also I am getting that $g(JX, JY) = - g(X, Y)$ for $X,Y$ vector fields on $\mathcal{H}$ . I can outline my calculations if necessary, but is anything I have stated incorrect? I am assuming that $dxdy$ is denoting the symmetric product of $dx$ and $dy$ , i.e. $dxdy = \frac{1}{2} ( dx \otimes dy + dy \otimes dy)$ , perhaps the notation is indicating something else?","['number-theory', 'riemannian-geometry', 'differential-geometry']"
3348530,Proving this non-empty set and binary operation is a group [duplicate],"This question already has answers here : A semigroup $X$ is a group iff for every $g\in X$, $\exists! x\in X$ such that $gxg = g$ (2 answers) Closed 4 years ago . Suppose we have a non-empty set $P$ equipped with an associative binary operation $\bullet$ such that for every $a \in P$ there exists a unique $b \in P$ with $aba=a$ . How would we go about proving this is a group? I have tried various things, and proved some smaller results such as for the element $b$ , the corresponding unique element $c$ such that $bcb=b$ satisfies $c=a$ , but every attempt to show this structure is in fact a group seems to rely on circular logic that either a unique identity exists, or each element has a unique inverse, both of which we obviously have to prove! Any help would be much appreciated.","['finite-groups', 'semigroups', 'associativity', 'binary-operations', 'group-theory']"
3348546,Proof of the CS (cosine-sine) matrix decomposition,"The CS decomposition is a way to write the singular value decomposition of a matrix with orthonormal columns. More specifically, taking the notation from these notes (pdf alert), consider a $(n_1+n_2)\times p$ matrix $Q$ , with $$Q=\begin{bmatrix}Q_1 \\ Q_2\end{bmatrix},$$ where $Q_1$ has dimensions $n_1\times p$ and $Q_2$ has dimensions $n_2\times p$ .
Assume $Q$ has orthonormal columns, that is, $Q_1^\dagger Q_1+Q_2^\dagger Q_2=I$ . Then the CS decomposition essentially tells us that the SVDs of $Q_1$ and $Q_2$ are related. More specifically, there are unitaries $V, U_1, U_2$ such that \begin{aligned}
U_1^\dagger Q_1 V=\operatorname{diag}(c_1,...,c_p), \\
U_2^\dagger Q_2 V=\operatorname{diag}(s_1,...,s_q),
\end{aligned} with $c_i^2+s_i^2=1$ (from which the name of the decomposition comes).
As far as I understand, this means that there is a set of orthonormal vectors $\{v_k\}_k$ such that both $\{Q_1 v_k\}_k$ and $\{Q_2 v_k\}$ are orthogonal sets of vectors (with some relations between their norms). To prove that this is the case, I start by writing down the SVDs of $Q_1$ and $Q_2$ , which tell us that there are unitaries $U_1, U_2, V_1, V_2$ , and diagonal positive matrices $D_1, D_2$ , such that \begin{aligned}
Q_1= U_1 D_1 V_1^\dagger, \\
Q_2= U_2 D_2 V_2^\dagger.
\end{aligned} The condition $Q_1^\dagger Q_1+Q_2^\dagger Q_2=I$ then translates into $$V_1 D_1^2 V_1^\dagger + V_2 D_2^2 V_2^\dagger=I.$$ Denoting with $v^{(i)}_k$ the $k$ -th column of $V_i$ , and $P^{(i)}_k\equiv v^{(i)}_k v^{(i)*}_k$ the associated projector, this condition can be seen to be equivalent to $$\sum_k (d^{(1)}_k)^2 P_k^{(1)}+\sum_k (d^{(2)}_k)^2 P_k^{(2)}=I,\tag A$$ where $d^{(i)}_k\equiv (D_i)_{kk}$ . Now, however, I'm a bit stuck into how to proceed from (A). It seems a generalisation of the things proved in this post and links therein, which show that if a sum of projectors gives the identity then the projectors must be orthogonal, but I'm not sure how to prove this in this case.","['matrices', 'projection-matrices', 'linear-algebra', 'matrix-decomposition']"
3348645,upper bound of outer measure on compact support of continuous function,"Given $(\mathbb R^n,\mathcal B,\mu)$ , where $\mu$ is a positive finite  Radon measure, define the function $$
\mu^*(A) = \inf \left\{
\sum_{i=1}^n\mu(B_i) \,\,|\,\, A\subseteq \cup_i B_i, \,\, n \in \mathbb N 
\right\}
$$ where $B_i$ are balls (both closed and open). Take now $G:\mathbb R^n \to \mathbb R_+$ a continuous function with compact support $E$ and call $$
E_r = \{x\in \mathbb R^n | G(x)>r \}.
$$ Given any $\varepsilon>0$ , is it true that $$
\mu^*(E_\epsilon) \le \mu(E_0)?
$$","['measure-theory', 'borel-measures', 'outer-measure', 'compactness']"
3348650,Prove that this function is continuous,"I saw this problem in my textbook and I am stuck at a step Let $C\subset R^d$ and $D\subset R^s$ be closed bounded sets and $f: C \times D \to R $ a continuous function. Show that $x \in C \to \min_D f(x,y)$ is continuous. My attempt: (Writing the new function as $g(x)$ ) $$ |g(x) - g(z) | = |f(x,\alpha) - f(z,\alpha) + f(z,\alpha) - f(z,\beta)| $$ Where $\alpha$ is the vector in $R^s$ where $f(x,y)$ is maximum and $\beta$ is the vector in $R^s$ where $f(z,y)$ is maximum. Next I take distance between $x$ and $z$ as $ \lt \delta$ and try to apply triangle inequality but the term $|f(z,\alpha) - f(z,\beta)|$ is problematic. I can't proceed further.","['continuity', 'functions', 'epsilon-delta', 'real-analysis']"
3348661,"Number of words using $\{a,b,c,d,e\}$ without ""de"" and ""abd""","consider the words over the alphabet $\{a,b,c,d,e\}$ of length $7$ . What is the number of words that does not contain ""de"" and ""abd"" ? A reasonable solution (I think) is to set $t_n$ to be the number of $n$ -th long words without ""de"" and ""abd"",    and then to find a recurrence relation. From this recurrence we can compute $t_7$ . What is that recurrence relation? Is there another solution without recurrence? 
Thanks!","['combinatorics', 'discrete-mathematics']"
3348869,Consistency of a family of probabilities in the construction of a pre-brownian motion,"I'm trying to understand how to construct the pre-brownian motion and I'm stuck at trying to prove the consistency of a family to be able to apply the Kolmogorov extension theorem. Definition. Let $S$ be any arbitrary set and $(X,\mathcal{F})$ a events space. Let $\Omega=X^{J}$ and for all $J\subset S$ ( $J$ finite) and define $\pi_{J}$ the projection from $\Omega$ to $X_{J}$ . Now, suppose that for each $J\subset S$ ( $J$ finite) we have a probability measure $P_{J}$ defined over $X^{J}$ . We say that $\{P_{J}:J\subset S, J~\text{finite} \}$ is a consistent family if for $J' \subset J$ we have that $$P_{J}\Bigl( \pi_{J}\left(\pi_{J'}^{-1}(A) \right) \Bigr)=P_{J'}(A)$$ For $A\in \prod _{i\in J'} \mathcal{F}$ . Now, lets consider the space $\displaystyle\left(\mathbb{R}^{(0,\infty)}, \mathcal{B}(\mathbb{R})^{(0,\infty)} \right)$ and the density function $\displaystyle p(t,x)=\frac1{\sqrt{2\pi t}} e^{\frac{-x^{2}}{2t}}$ . So for $J=\{t_{1},t_{2},...,t_{n}\}$ and for $A_{1},A_{2},...,A_{n} \in \mathcal{B}(\mathbb{R})$ we define the probability measure $$P_{J}(A_{1} \times \cdots \times A_{n})=\int_{A_{n}}\int_{A_{n-1}} \cdots \int _{A_{1}} p(t_{1},x_{1})\prod p(t_{j+1}-t_{j}, x_{j+1} - x_{j}) dx_{1}dx_{2} \cdots dx_{n}$$ Where $P_{J}$ is defined over $(\mathbb{R}^{J},\mathcal{B}(\mathbb{R})^{J})$ How can I prove that $P_{J}$ is a consistent family of probability measures? Thanks so much for the help.","['measure-theory', 'brownian-motion', 'probability-theory']"
3348884,explicit formula for position of lowest bit of binary representation of number,"Given some positive integer $x>0$ , let $h(x)$ be the number of trailing zeros in the binary representation of $x$ . For Example, if $x = 12$ then the binary representation of $x$ is $1100_{2}$ and $h(x) = 2$ Is there a known explicit formula for $h(x)$ ? Thank you all for you responses especially ganeshie8 I wanted to add a few more properties of $h(x)$ $$
  h(2m+1) = 0 \hspace{5mm}\forall m \geq 0\\
  h(2^m x) = m + h(x) \hspace{16mm}
$$","['binary', 'number-theory', 'elementary-number-theory', 'functions', 'binary-operations']"
3348897,Evaluating integral delta function,"I am trying to evaluate the integral below (delta function) and not sure if I evaluated correctly? The integral is the following: $$\int^{100}_{-100}x^3\sin(2x)\delta(x^2-9)dx$$ I have the following $x=\pm 3$ , $$\therefore \int^{100}_{-100}x^3\sin(2x)\delta(x^2-9)dx = \int^{0}_{-100}x^3\sin(2x)\delta(x^2-9)dx + \int^{100}_{0}x^3\sin(2x)\delta(x^2-9)dx= \ (-3)^3\sin(2\cdot(-3)) + (3)^3\sin(2\cdot(3)) = \ -27\sin(-6) + 27\sin(6)$$","['multivariable-calculus', 'calculus', 'vector-analysis']"
3348951,A lemma for generic freeness,"say a B-algebra A satisfies (†) if for each finitely generated A-module M, there exists a nonzero f ∈ B such that $M_f$ is a free $B_f$ -module. Grothendieck's generic Freeness lemma States that if B is a Noetherian domain and A is a finitely generated B algebra, then A satisfies (†). Its an exercise (7.4.G) in Ravi Vakil's  algebraic geometry notes to reduce this statement to following claim: if A is a finitely-generated B-algebra satisfying (†), then A[T] does too.   that is the exercise is to assume this claim to be true and prove the generic freeness lemma. ** My question is how to do this?** In The exercise preceeding this one I proved that B itself satisfies (†).  Thus if I could prove (†) is Preserved under  passing to a quotient  I could just Adjoin the generators to B as indeterminates (using the claim inductively) and then take a quotient to get A.  but I don't know how to prove that (†)  is preserved by passing to a quotient.","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3348987,Union of continuous functions on closed (or open) subsets is continuous,"Good morning, I'm doing Problem III.2.13 from textbook Analysis I by Amann. My attempt: Let $C \subseteq Y$ be closed in $Y$ . Because $g$ is continuous, $g^{-1}[C]$ is closed in $A$ . As such, there is $X_1 \subseteq X$ such that $X_1$ is closed in $X$ and $g^{-1}[C] = X_1 \cap A$ . Similarly, there is $X_2 \subseteq X$ such that $X_2$ is closed in $X$ and $h^{-1}[C] = X_2 \cap B$ . We have $$\begin{aligned}f^{-1}[C] &= g^{-1}[C] \cup h^{-1}[C]= (X_1 \cap A) \cup (X_2 \cap B) \\ & = (X_1 \cup X_2) \cap (X_1 \cup B) \cap (X_2 \cup A) \cap (A \cup B)\end{aligned}$$ It follows from $X_1,X_2,A,B$ are closed in $X$ that $(X_1 \cup B), (X_2 \cup A), (A \cup B)$ are closed in $X$ . As such, $D := (X_1 \cup B) \cap (X_2 \cup A) \cap (A \cup B)$ is closed in $X$ . Hence $f^{-1}[C] = (X_1 \cup X_2) \cap D$ is closed in $X_1 \cup X_2$ . Thus $f$ is continuous. My questions: Could you please verify if my proof look fine or contains logical gaps/errors? Any suggestion is greatly appreciated. I found that my proof only relies on topological concepts such as open and closed . As such, I think that the theorem holds for not only metric spaces but also for topological spaces. Is my understanding correct? If we change the assumption from $A,B$ are closed subsets to $A,B$ are open subsets , then the theorem still holds true. This is because I can adjust my proof by starting with open subset $C \subseteq Y$ rather than closed subset $C \subseteq Y$ . More specifically, Let $C \subseteq Y$ be open in $Y$ . Because $g$ is continuous, $g^{-1}[C]$ is open in $A$ . As such, there is $X_1 \subseteq X$ such that $X_1$ is open in $X$ and $g^{-1}[C] = X_1 \cap A$ . Similarly, there is $X_2 \subseteq X$ such that $X_2$ is open in $X$ and $h^{-1}[C] = X_2 \cap B$ . We have $$\begin{aligned}f^{-1}[C] &= g^{-1}[C] \cup h^{-1}[C]= (X_1 \cap A) \cup (X_2 \cap B) \\ & = (X_1 \cup X_2) \cap (X_1 \cup B) \cap (X_2 \cup A) \cap (A \cup B)\end{aligned}$$ It follows from $X_1,X_2,A,B$ are open in $X$ that $(X_1 \cup B), (X_2 \cup A), (A \cup B)$ are open in $X$ . As such, $D := (X_1 \cup B) \cap (X_2 \cup A) \cap (A \cup B)$ is open in $X$ . Hence $f^{-1}[C] = (X_1 \cup X_2) \cap D$ is open in $X_1 \cup X_2$ . Thus $f$ is continuous. Is this generalization correct? Thank you so much for your help!","['proof-verification', 'metric-spaces', 'real-analysis', 'continuity', 'general-topology']"
3348995,$G$-invariant linear functions on $V \otimes \mathfrak{g}$ are $N(T)$-invariant linear functions on $V \otimes \mathfrak{h}$,"Suppose $G$ is a reductive algebraic group with Lie algebra $\mathfrak{g}$ and Cartan $\mathfrak{h} \subseteq \mathfrak{g}$ which is the Lie algebra for a torus $T \subseteq G$ . Is it true that $Hom_G(V \otimes \mathfrak{g}, \mathbb{C})$ is naturally isomorphic to $Hom_{N(T)}(V \otimes \mathfrak{h}, \mathbb{C})$ via the restriction map, for every $G$ -module $V$ ? On the LHS we consider algebraic representations of $G$ . I'm pretty sure this is equivalent to the statement that $\mathfrak{g}^*$ is isomorphic as $G$ -representations to sections of the vector bundle $G \times_{N(T)} \mathfrak{h}^* \to G/N(T)$ (the induction of $\mathfrak{h}^*$ as a $N(T)$ -representation to $G$ , where $N(T)$ is the normalizer of $T$ in $G$ ). I was thinking this might be true since it's reminiscent of the Chevalley restriction theorem which provides a graded algebra isomorphism $\mathcal{O}(\mathfrak{g})^G \to \mathcal{O}(\mathfrak{h})^W$ between rings of invariant functions on $\mathfrak{g}$ and $\mathfrak{h}$ , and in particular gives us an isomorphism $Hom_G(\mathfrak{g}, \mathbb{C}) \cong Hom_W(\mathfrak{h}, \mathbb{C})$ . Here $W=N(T)/T$ is the Weyl group of $T$ .","['algebraic-geometry', 'representation-theory', 'algebraic-groups']"
3349006,Question about discontinuous function with directional derivatives at a points,"For a function, if at a point $a$ , the function has directional derivatives along some lines, but the function is discontinuous at $a$ , does that mean along those lines, the function is continuous, but along some other directions the function is not? What does the graph of such a function look like? Continuous in some direction but discontinuous in others?","['multivariable-calculus', 'calculus']"
3349087,Discrepancy between explicit ODE solution and phase line analysis,"Suppose we have the separable ODE, $$ \frac{dy}{dt} = e^t\frac{y^2-9}{2y}, \;\; y(0) = -5 $$ The explicit solution to this problem is, $$ y = -\sqrt{9 + 16e^{e^t-1}} $$ I'm confused about the behavior of the solution when $t \rightarrow -\infty$ . According to the explicit solution, $y \rightarrow -\sqrt{9 + 16e^{-1}}$ . However, if we do a phase line analysis, we can show that $y = -3$ is an unstable stationary point. So as we go back in time, shouldn't, $y \rightarrow -3$ ? Why do the answers not match? Does phase line analysis not work for non-autonomous equations like above?","['calculus', 'ordinary-differential-equations', 'dynamical-systems']"
3349101,Showing the nth roots of unity satisfy two properties,"Assuming $ω_0,ω_1,...,ω_n$ are the $n^{th}$ roots of unity, I am asked to show $$(x−ω_0)(x−ω_1)···(x−ω_{n−1}) =x^n−1$$ and $$\sum^{n−1}_{a=0}ω_a= 0$$ I understand that by definition, the $n^{th}$ roots of unity are the roots of the polynomial $x^n-1$ . I'm not sure I know the properties of the roots of unity well enough to even know where to begin. Thank you.","['complex-analysis', 'roots-of-unity']"
3349153,Why is $\mathscr C\to \mathbf{Mon}$ an equivalence?,"In Example 1.3.21 Leinster says that the functor $F: \mathscr C\to \mathbf{Mon}$ sending a one-object category to the monoid of arrows from the unique object to itself is full, faithful, and essentially surjective on objects. He says that fullness and faithfullness follows from Example 1.2.7 which says that a functor between categories corresponding to monoids is the same as a homomorphism of monoids. How does this imply that $F$ is full and faithful? I also don't understand why $F$ is essentially surjective on objects. This would mean that every monoid is a set of arrows from some object to itself under composition. Why does this hold?","['abstract-algebra', 'category-theory']"
3349159,Example of complete but not closed Riemannian submanifold,"I am working on an exercise where I am asked to construct an example of a complete Riemannian metric $(M,g)$ and a connected embedded Riemannian submanifold $P \subseteq M$ that is complete, but not closed. And I am not certain that such an example exists. Suppose $x \in M \setminus P$ is a limit point of $P$ . Then there is a sequence $\left\{x_n\right\}_{n \geq 1} \subset P$ that  converges to $x$ in the metric $d_g$ induced by the Riemannian metric on $M$ . In particular, $\left\{x_n\right\}$ is a Cauchy sequence in $M$ . So in order for this to be true, we would need $\left\{x_n\right\}$ to fail to be a Cauchy sequence in $P$ ; otherwise by completeness of $P$ , $x_n\to x \in P$ in the induced topology on $P$ , contradicting our hypothesis. What I need: I want an example of a complete Riemannian manifold $(M,g)$ admitting a connected, complete, embedded submanifold $P \subset M$ where Cauchy sequences in $M$ are not necessarily Cauchy in $P$ . But I'm not sure how to construct such a thing. Any tips?","['general-topology', 'differential-topology', 'riemannian-geometry', 'differential-geometry']"
3349163,Calculate $ \left \lfloor \frac{2017^{3}}{2015 \cdot 2016} - \frac{2015^{3}}{2016 \cdot 2017} \right \rfloor $,"Calculate $$ \left \lfloor \frac{2017^{3}}{2015 \cdot 2016} - \frac{2015^{3}}{2016 \cdot 2017} \right \rfloor   $$ attempt: $$ \frac{2017^{3}}{2015 \cdot 2016} - \frac{2015^{3}}{2016 \cdot 2017} = \frac{2017^{4} - 2015^{4}}{2015 \cdot 2016 \cdot 2017} $$ $$ \frac{(2017^{2} - 2015^{2})(2017^{2} + 2015^{2})}{2015 \cdot 2016 \cdot 2017}  
 = \frac{2(4032)(2017^{2} + 2015^{2})}{2015 \cdot 2016 \cdot 2017}  $$ $$ =\frac{4(2017^{2} + 2015^{2})}{2015 \cdot 2017}  = \frac{4 \cdot 2017}{2015} + \frac{4 \cdot 2015}{2017} $$ $$ = \frac{8068}{2015} + \frac{8060}{2017} = \frac{8060 + 8}{2015} + \frac{8068 - 8}{2017}  $$ $$ = 8 + \frac{8}{2015} - \frac{8}{2017} $$ So the simplified value is 8. Are there more simpler ways?","['algebra-precalculus', 'ceiling-and-floor-functions']"
3349186,Finding the value of an infinite sum from a definite integral:,It can be computed that $$\int_0^1 \frac{x^2+1}{x^4+x^2+1}dx = \frac{\pi}{2\sqrt{3}}.$$ The integral can be done using $$\frac{2(x^2+1)}{x^4+x^2+1} = \frac{1}{x^2-x+1}+\frac{1}{x^2+x+1}.$$ But I got stuck in the following part: We need to show that $$1-\frac{1}{5}+\frac{1}{7} - \frac{1}{11}+\frac{1}{13}- \cdots = \frac{\pi}{2\sqrt{3}}$$ using the above definite integral. The sum of the above series can be computed using Fourier series. Life becomes hard for me when the above sum is to be shown using the above integral. Any suggestions of help is much appreciated.,"['definite-integrals', 'sequences-and-series']"
3349230,Fast way to check if two integers don't have any prime factors in common,"I would like to know if two integers $a$ and $b$ have at least one prime factor in common. I know calculating the GCD (by e.g. the Euclidean algorithm) would produce the right answer. However since I only care about any factor and not necessarily the largest, can it be done faster?","['number-theory', 'gcd-and-lcm', 'discrete-mathematics']"
3349257,Prove that $0<\sum_{k=1}^n \frac{g(k)}{k} - \frac{2n}{3} < \frac{2}{3}$,"Prove $$0<\sum_{k=1}^n \frac{g(k)}{k} - \frac{2n}{3} < \frac{2}{3}$$ where $g(k)$ is the greatest odd divisor of k Please Find Holes in my Proof. Let $k=2m+1$ if we show that the right hand side of the equation is true for odd numbers, then it is true for even numbers since there is a net total of $1/3$ since $g(k)/k = 1$ for odd numbers. $$\sum_{k=1}^n\frac{g(k)}{k} <\frac{2n}{3} + \frac{2}{3}$$ $$\sum_{k=1}^n\frac{g(k)}{k} <\frac{2(2m+1)}{3} + \frac{2}{3}$$ $$\sum_{k=1}^n\frac{g(k)}{k} <\frac{4m}{3} + \frac{4}{3}$$ From $1$ to $2m+1$ there are $m$ even numbers and $m+1$ even numbers, the value of $\frac{g(k)}{k}$ for even numbers is $\frac{1}{2^{V2(k)}}$ where $V2(k)$ is the exponent of 2 in the factorization of k $$\sum_{k=1}^n\frac{g(k)}{k}  = m+1 + (m)\frac{1}{2} -((\lfloor{\frac{m}{2}\rfloor \frac{1}{4}) +(\lfloor{\frac{m}{4}\rfloor \frac{1}{8}}})...)$$ $$\leq    m+1 + (m)\frac{1}{2} - (\frac{m}{8} + \frac{m}{32}...) = \frac{4m}{3} + 1 <\frac{2(2m+1)}{3} + \frac{2}{3}$$ Solving for the left hand side of the inequality $$0<\sum_{k=1}^n \frac{g(k)}{k} - \frac{2n}{3}$$ Let $k = 2m$ with the same reasoning as above $$\sum_{k=1}^n\frac{g(k)}{k}  = m + (m)\frac{1}{2} -((\lfloor{\frac{m}{2}\rfloor \frac{1}{4}) +(\lfloor{\frac{m}{4}\rfloor \frac{1}{8}}})...)$$ $$\geq    m + (m)\frac{1}{2} - (\frac{m}{8} + \frac{m}{32}...) = \frac{4m}{3} + \frac{1}{3} >\frac{2(2m)}{3}$$ I'm not sure about the solution since it was a strict inequality to begin with. Is this a correct solution? Any other solutions are welcome","['number-theory', 'proof-verification', 'sequences-and-series']"
3349260,Prove that $\lim\limits_{x\to0^+}\frac{f(x)}{f'(x)}=0$.,"Let $f:(0,\infty)\to\mathbb{R}$ be a twice differentiable function with $f''$ continuous and let $\lim\limits_{x\to0^+}f'(x)=-\infty$ and $\lim\limits_{x\to0^+}f''(x)=+\infty$ . Prove that: $$\lim_{x\to0^+}\frac{f(x)}{f'(x)}=0.$$ My problem is not a proof of this itself (e.g. using $\epsilon-\delta$ definition). I recently found this in an old high-school textbook where no mention of the ""traditional"" $\epsilon-\delta$ definition is made, so, is it possible to find a solution without it? What we can do is find some $a>0$ such that $f$ is strictly decreasing and $f'$ strictly increasing in $(0,a)$ which proves that $$\lim_{x\to0^+}f(x)=\ell$$ exists (either number or $+\infty$ ) and we can easily prove what we want in case $\ell\in\mathbb{R}$ . But that case $\ell=+\infty$ is one I cannot solve without proving some inequality of the form: $f(x)+\epsilon f'(x)<0,$ for $x\in(0,\delta)$ for some $\delta>0$ . But this is not supposed to be the solution in a high school textbook. So, does anyone have a more ""elementary"" solution or an appropriate rephrasing of a current one?","['limits', 'calculus']"
3349261,"if $0 < x <1$, How can I prove $ \ln{x} > 1- \frac{1}{x}$ without derivative or integral","If $0 < x <1$ , how can I prove $$ \ln x > 1- \frac{1}{x}$$ without derivative or integral? In the process of proving $$\sin x ^ {\sin x}> \cos x ^ {\cos x}$$ without calculus, I had to solve the above equation, but the idea does not come to mind.",['trigonometry']
3349268,Continuous function and Continuous functor,"Let $X, Y$ be topological spaces and $Op(X), Op(Y)$ be corresponding categories of open sets, where morphisms are given by inclusions. For any continuous and open function $f:X\to Y$ , there exists a functor $F_{f}:Op(Y) \to Op(X)$ defined as $F_{f}(U) := f^{-1}(U)$ , which is continuous in the sense that it preserves limits: $$
F_{f}\left(\lim_{i} U_{i}\right) \simeq \lim_{i} F_{f}(U_{i}).
$$ (This equation is equivalent to $$
f^{-1} \left( \left( \bigcap_{i} U_{i}\right)^{\circ}\right) = \left(\bigcap_{i} f^{-1}(U_{i})\right)^{\circ}
$$ which is true if $f$ is both continuous and open. If $f$ is not open, taking iterior may not commutes with takeing inverse image.) I want to know if there's a sort of a converse of this theorem: for given $G:Op(Y) \to Op(X)$ , there exists unique $g:X\to Y$ which is continuous (and maybe also open) and $G \simeq F_{g}$ . If $X =Y= \{a, b\}$ are topological spaces with an indiscrete topology, then $f_{1} = \mathrm{id}$ and $f_{2}(a) =b, f_{2}(b)=a$ induces same $F_{f_{1}} = F_{f_{2}}$ . I want to reconstruct $f$ from $G:Op(Y) \to Op(X)$ by imposing some condition on $G, X,$ and $Y$ . It seems like the theorem is true if $X, Y$ are both Hausdorff, but I'm not sure about this.","['continuity', 'general-topology', 'category-theory']"
3349286,Smooth Manifold Chart Lemma for Manifolds with Boundary,"Let's start with Lemma 1.35 (Smooth Manifold Chart Lemma for Manifolds Without Boundary) in John Lee's Textbook ""Introduction to Smooth Manifolds"" (Second Edition). The precise statement is: Let $M$ be a set and $\{U_\alpha\}_{\alpha\in J}$ be a collection of subsets of $M$ , along with maps $\varphi_\alpha:U_\alpha\to\mathbb R^n$ , such that the following properties are satisfied: (i) $\forall \alpha\in J$ : $\varphi_\alpha$ is an injective map and $\varphi_\alpha(U_\alpha)$ is open in $\mathbb R^n$ . (ii) $\forall \alpha,\beta\in J$ : the sets $\varphi_\alpha(U_\alpha\cap U_\beta)$ and $\varphi_\beta(U_\alpha\cap U_\beta)$ are open in $\mathbb R^n$ . (iii) $\forall\alpha,\beta\in J$ : $U_\alpha\cap U_\beta\neq \emptyset
			\quad
			\Rightarrow
			\quad \varphi_\beta\circ\varphi_\alpha^{-1}:\varphi_\alpha(U_\alpha\cap U_\beta)\to \varphi_\beta(U_\alpha\cap U_\beta)$ is smooth. (iv) Countably many of the sets $U_\alpha$ cover $M$ . (v) $
\left.
\begin{array}{c}
p,q\in M\\
p\neq q
\end{array}
\right\}
\quad
\Rightarrow
\quad
\left\{
\begin{array}{c}
\exists \alpha\in J\text{ such that } p,q\in U_\alpha,\quad\text{ or}\\
\exists \alpha,\beta\in J\text{ such that } p\in U_\alpha, q\in U_\beta \text{ and } U_\alpha\cap U_\beta=\emptyset
\end{array}
\right.
$ Then $M$ has a unique manifold structure such that each pair $(U_\alpha,\varphi_\alpha)$ is a smooth chart. Let $\mathcal B=\{\varphi_\alpha^{-1}(V):\alpha\in J, V\text{ open in } \mathbb R^n\}$ . From $(iv)$ we see that the elements of $\mathcal B$ cover $M$ .
Now let $\varphi_\alpha^{-1}(V)$ and $\varphi_\beta^{-1}(W)$ be two elements of $\mathcal B$ , where $V$ and $W$ are open in $\mathbb R^n$ .
To show that $\mathcal B$ forms a basis, it is enough to show that $ \varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ itself lies in $\mathcal B$ .
Note that \begin{equation*}
\varphi_\alpha^{-1}(V)\cap \varphi_\beta^{-1}(W)=\varphi_\alpha^{-1}\Big(V\cap(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)\Big)
\tag{1}
\end{equation*} But by (iii), $\varphi_\beta\circ\varphi_\alpha^{-1}$ is continuous, and therefore $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\varphi_\alpha(U_\alpha\cap U_\beta)$ .
By (ii), $\varphi_\alpha(U_\alpha\cap U_\beta)$ is open in $\mathbb R^n$ and therefore $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\mathbb R^n$ .
Using this in $(1)$ , we immediately see that $\varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ is in $\mathcal B$ .
This settles the claim. The maps $\varphi_\alpha:U_\alpha \to \mathbb{R}^n$ are automatically continuous. To see they are homeomorphisms with the images, it is equivalent to show that $\varphi_\alpha$ is an open map. To this purpose, it is sufficient to show that $\varphi_\alpha(B)$ is open in $\mathbb{R}^n$ whenever $B$ is an element of $\mathcal{B}$ contained in $U_\alpha$ . An arbitrary element of $\mathcal {B}$ is of the form $\varphi^{-1}_\beta(W)$ with $W$ open in $\mathbb{R}^n$ .
  We have $\varphi_\alpha(\varphi^{-1}_\beta(W))=\varphi_\alpha\circ\varphi_\beta^{-1}(W)$ is open in $\varphi_\alpha(U_\alpha \cap U_\beta)$ and thus in $\mathbb{R}^n$ . Question 1) Lee says that each map $\varphi_\alpha$ is an homeomorphism onto its image ""essentially by definition"" , but according to my argument above we are using again hypothesis (iii) and (ii). So, I would say that the continuity of the $\varphi_\alpha$ 's is ""essentially by definition"" (since we are putting in $\mathcal{B}$ all the counter images of the open subsets of $\mathbb{R}^n$ ) but not the openness. So, does my argument above (to show that the $\varphi_\alpha$ 's are homeomporphism onto their images) use unnecessaryly the hypothesis (iii) and (ii)? In other words, is there a simpler way (that justifies the sentence ""essentially by definition"") to see that the $\varphi_\alpha$ 's are homeomorphism onto their images? Question n° 2 On page 28 Exercise 1.42 says: Show that Lemma 1.35 holds with $\mathbb{R}^n$ replaced by $\mathbb{R}^n$ or $\mathbb{H}^n$ and ""smooth manifold"" replaced by ""smooth manifold with boundary"". I think I can copy the same proof of Lemma 1.35, but when I arrive to the point of showing that $ \varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ itself lies in $\mathcal B$ I'm in trouble because I cannot show that $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\mathbb{R}^n$ . What I know is that $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\varphi_\alpha(U_\alpha\cap U_\beta)$ , and this last one can be open in $\mathbb{R}^n$ or $\mathbb{H}^n$ . In the latter case I have $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)=\mathbb{H}^n \cap S$ with $S$ open subet of $\mathbb{R}^n$ , but the set $\varphi_\alpha^{-1}(S)$ can be greater than the set $\varphi_\alpha^{-1}((\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W))$ . My current thought is that: if in the statement of Lemma 1.35 I change (ii) with (j) $\forall \alpha,\beta\in J$ : the set $\varphi_\alpha(U_\alpha\cap U_\beta)$ is open in $\varphi_\alpha(U_\alpha)$ nothing change in Lemma 1.35 but as regard Exercise 1.42, I have that $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\varphi_\alpha(U_\alpha\cap U_\beta)$ , which is open in $\phi_\alpha(U_\alpha)$ and this last one can be open in $\mathbb{R}^n$ or $\mathbb{H}^n$ . In the latter case I have $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)=\mathbb{H}^n \cap S$ with $S$ open subet of $\mathbb{R}^n$ , but since the image of $\varphi_\alpha$ lies in $\mathbb{H}^n$ I have also $\varphi_\alpha^{-1}(S)=\varphi_\alpha^{-1}((\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W))$ . Is my modification correct? Is my modification necessary? I suspect there are many simple things I'm missing, my apologies for this.","['multivariable-calculus', 'general-topology', 'smooth-functions', 'smooth-manifolds']"
3349311,Prove that J is a subgroup of G,"Could somebody please help me with the following question? Let $G$ be the group consisting of all invertible $2\times2$ matrices with coefficients in $\mathbb Z/3\mathbb Z$ . Here the group is the usual matrix multiplication, and the unit element is $e:=\begin{bmatrix}1&0\\0&1\end{bmatrix} $ Consider the matrices $g:=\begin{bmatrix}0&1\\1&1\end{bmatrix} $ $h:=\begin{bmatrix}1&1\\0&2\end{bmatrix} $ Show that $J:=\{h^n* g^m : m,n \in \mathbb{Z}_{>0} \}$ is a subgroup of $G$ . I have determined that the unit element is in $J$ , but I don't know how to show the other axioms of the subgroup criterion as the group is not commutative.
Thank you!","['modular-arithmetic', 'finite-groups', 'matrices', 'abstract-algebra', 'group-theory']"
3349364,"Prove that $\int_0^1 \frac{x^2}{\sqrt{x^4+1}} \, dx=\frac{\sqrt{2}}{2}-\frac{\pi ^{3/2}}{\Gamma \left(\frac{1}{4}\right)^2}$","How to show $$\int_0^1 \frac{x^2}{\sqrt{x^4+1}} \, dx=\frac{\sqrt{2}}{2}-\frac{\pi ^{3/2}}{\Gamma \left(\frac{1}{4}\right)^2}$$ I tried hypergeometric expansion, yielding $\, _2F_1\left(\frac{1}{2},\frac{3}{4};\frac{7}{4};-1\right)$ . Can this be evaluated analytically? Any help will be appreciated.","['integration', 'definite-integrals', 'closed-form', 'gamma-function']"
3349423,The best $n$-digit password?,"I suddenly thought of a question today: What is the best $n$ -digit password? It is not specific so I'll write it in a better way: There is a password lock that has $n$ digits. There are $t$ choices for every digit. There is a thief that wants to  crack the password lock, so he blows some powder into the lock that  will show the fingerprints and will tell him the digits used (If there are repeated digit in the password, it only shows one fingerprint on the repeated digit). If the password consists of $m$ distinct digits, then find $m$ ( $m\le n$ ) that makes the number of the combination of the possible password $P\left(m\right)$ the most. Let me show a example: For $n=4,t=4$ , $P\left(1\right)=1,$ $P\left(2\right)=C^4_2+2C^4_1=14$ $P\left(3\right)=3\times2C^4_2=36$ $P\left(4\right)=4!=24$ $\therefore m=3$ is the answer for the case $n=4,t=4$ . However, when $n,t$ are bigger number, it will be hard to calculate. Hence, I want to ask you guys the general case or making a table. Thank you!","['permutations', 'combinations', 'combinatorics']"
3349441,Vanishing of Chern-Simons invariant,"I am computing Chern-Simons invariants using the metric given by the Bianchi Types, associated naturally to seven of the eight Thurston geometries. However, many of them result to be identically zero. Since I am just testing my code, I am not sure if this is a correct result. I only have that the code does compute correctly the invariant for $\mathbb{S}^3$ with its standard metric, but I do not have other results for 3-mflds to really check if my code works. Would there be any reason to believe this vanishing is true? Especially that $\mathbb{H}^3$ , and $\mathbb{H}^2\times\mathbb{R}$ with their std metrics by Bianchi classification turn out to have invariant $\Phi = 0$ .","['characteristic-classes', 'differential-geometry']"
