question_id,title,body,tags
695511,Deforming 2D Points (Square -> Triangle... sort of),"I am in a weird situation where I have to convert colors from a ""white+green"" color space to an RGB color space: $$(w,g)\rightarrow(R,G,B)\\\
w,g,R,G,B\in[0,1]$$ Essentially, I have to take a ""white"" ($w$) and ""green"" ($g$) coordinate and map it to some point on the half of the $R=B$ plane where $G\geq{R}$ (image below is range, black triangle excluded): I've come up with a list of four known mapped points. Since $R=B$ I'm going to refer to both as $R$. The constant $p\in(0,1)$ below is a value I can adjust to taste (sorry about incorrect notation): $$
f:(w,g)\rightarrow(R,G)\\
f(0,0)\rightarrow(0,0)\\
f(1,0)\rightarrow(1,1)\\
f(1,1)\rightarrow(p,1)\\
f(0,1)\rightarrow(0,1)
$$ Graphically, it looks like this: I'm taking a square and deforming it to a triangle, where the bottom right point of the square becomes the top right point of the triangle, and the top right point of the square moves left along the top edge. The dotted line should remain straight and the deformation of each half of the square (either side of dotted line) should be linear -- these are arbitrary choices but it seems to make sense for my situation, and is simpler to think about. If it over-complicates the math, though, it doesn't need to stay that way (sorry it's so ill-defined -- the nature of the problem has some subjective aspects). My question is : I need help creating $f(w,g)$. I understand it well, graphically, but I can't really get my head around the actual math for some reason. Sorry about all notation errors above, I'm not really a math guy, I'm just guessing.",['geometry']
695522,Proof involving group homomorphisms,"The question is as follows: Let $G_1$ and $G_2$ be groups. Define $\pi_1 : G_1 \times G_2 \rightarrow G_1$ by $\pi_1((a_1,a_2))=a_1.$ Define $\pi_2 : G_1 \times G_2 \rightarrow G_2$ by $\pi_2((a_1,a_2))=a_2.$ Let $G$ be any group, and let $\phi : G \rightarrow G_1 \times G_2$ be a function. Show that $\phi$ is a group homomorphism if and only if $\pi_1\circ \phi$ and $\pi_2\circ \phi$ are both group homomorphisms. Going forward is easy, but I'm not sure how to do the backwards direction (proving that if $\pi_1\circ \phi$ and $\pi_2\circ \phi$ are both group homomorphisms, then $\phi$ is a group homomorphism.)","['group-theory', 'abstract-algebra']"
695529,"Example of a subset of $\mathbb{R}^2$ that is closed under vector addition, but not closed under scalar multiplication?","I've found several examples which are closed under scalar multiplication, but not vector addition, but I can't come up with one that is closed under vector addition, but not scalar multiplication.",['linear-algebra']
695538,I need to understand $t=\cos(x) \implies x=\arccos(t)$,I need to understand this because I think that I don't know the meaning of arc... $t=\cos(x) \Rightarrow x=\arccos(t)$ ?? Thanks,"['trigonometry', 'functions']"
695566,How do I solve $yy'+x=\sqrt{x^2+y^2}$?,"I tried this: $yy'+x=\sqrt{x^2+y^2}$ $y'=-\frac{x}{y}+\frac{1}{y}\sqrt{x^2+y^2}$ $y'=-\frac{x}{y}+\sqrt{(\frac{x}{y})^2+1}$ Substitution: $v=\frac{y}{x}$ $v'x+v=-\frac{1}{v}+\sqrt{(\frac{1}{v})^2+1}$ $v'x=-\frac{1-v^2}{v}+\sqrt{(\frac{1}{v})^2+1}$ $v'x=-\frac{1-v^2+ v\sqrt{(\frac{1}{v})^2+1}}{v}$ $v'x=-\frac{1-v^2+\sqrt{1+v^2}}{v}$ If I have to separate at this point, it's going to be pretty awkward to work with. Is there a better way?","['ordinary-differential-equations', 'calculus', 'integration', 'analysis']"
695570,Is there a proof for the following series to diverge/converge?,"I was wondering weather the series $$\sum_{n=1}^{\infty} \frac {\tan(n)} {n^b}$$
diverges or converges whenever $b \geq 1$ is an integer. Does anyone have a proof for either statement? Does it converge for some positive integers but not for others? In that case, which are they?","['sequences-and-series', 'calculus']"
695593,Analyzing data to determine seasonal indices?,"The quarterly sales levels for the past four years of a leading tyre manufacturer are displayed on the table table How to analyze the data to determine the specific seasonal indices,and what conclusion can be deduced from the results? Generally after $Q2$(second quarter) i notice a slight decrease in manufacturing ,which implies the relationship is not linear,and also with the average production for each season being respectively $2397,2623,2537,2645$, i would like to know how further this data can be analyzed and how to obtain sales for the next quarter of 2013(assuming that cyclical and irregular components are negligible)","['statistics', 'data-analysis', 'descriptive-statistics']"
695601,"Convincing proofs, proofs by contradiction and countability","Disclaimer: I have a (modest) background in mathematical physics, not logic, so I know very little of the latter. Although when I understood Cantor's argument for the first time (from one of Martin Gardner's books) I was immediately taken by its beauty, recently I have grown slightly suspicious of it. I realize that it sounds like a beginning of a very cranky opinion, but I'll state it anyway: Cantor's argument, an argument by contradiction, seems to be very unlike the direct arguments for countability of $\mathbb{Q}$ and $\mathbb{Z}$. It is surprising, especially taken in its historical context, and, from a naive point of view that I do not necessarily espouse, almost unconvincing: why can't this ingenious construction be toppled with some other, even more ingenious? Given these, admittedly dubious, considerations, I'll try to pose the question: is there a possibility of direct argument that would prove the uncountability of reals? And if there is not, what would be the reasons for the lack of its existence? P.S.: I have just discovered this question and think that another way to reformulate my question would be: is the uncountability of reals provable in minimal logic?","['logic', 'elementary-set-theory']"
695613,Reference request: Introduction to Finite Group Cohomology,"I don't know anything about group cohomology and I'd like to. What is the best text to learn this subject? I'd prefer as soft an introduction as possible - that is, lots of motivation, lots of examples, slow moving development of intuition.  (Something like Simmons' Intro to Category Theory, if you've read that.)  I have a background in finite group theory and some character theory.  The text should actually show how to compute group cohomologies, preferably not too far in, something I have not found in the group cohomology books in my University library. A textbook would be great, but good lecture notes or papers would be fine too.","['motivation', 'group-cohomology', 'finite-groups', 'reference-request', 'group-theory']"
695616,How do I get from $¥frac{-x+1}{-x+2}$ to $1 + ¥frac{1}{x-2}$,"wolframalpha tells me it's the same but I can not follow how to get from one to another. $$¥frac{-x+1}{-x+2} =  ¥frac{1-x}{2-x} = ¥>? ¥dots$$ I don't get any further, always end up where I started.",['algebra-precalculus']
695619,"Integral, Definite Integral $ \int_{-\infty}^\infty \exp{\big(\alpha x^4+\beta x^3+\gamma x^2 +\delta x+\epsilon}\big)dx, \ \alpha <0. $","Calculate  the integral $$
I=\int_{-\infty}^\infty \exp{\big(\alpha x^4+\beta x^3+\gamma x^2 +\delta x+\epsilon}\big)dx, \ \alpha <0.
$$
The answer can be expressed analytically in terms of a series which will have a $\Gamma$ function in it.  I am not sure how to approach it since I do not know how to work with the argument of the exponential.  The other constants we can assume to be real.  The answer can be expressed as 
$$
I=e^{\epsilon} \sum_{n,m,p=0} \frac{\beta^{4n}}{(4n)!}\frac{\gamma^{2m}}{(2m)!}\frac{\delta^{4p}}{(4p)!}\frac{\Gamma(3n+m+p+\frac{1}{4})}{\alpha^{3n+m+p+\frac{1}{4}}}
$$","['definite-integrals', 'contest-math', 'integration', 'real-analysis']"
695630,How do I find the number of sides of a regular polygon given only its side length and area?,How do I find the number of sides of a regular polygon given only  its side length and area? Absolutely no IDEA where to start. Anyone?,"['geometry', 'trigonometry', 'area']"
695633,Calculate the integral of a 2 form,"I am trying to compute the integral
$$
\int\int_{S}\frac{1}{x}dy\wedge dz+\frac{1}{y}dz\wedge dx+\frac{1}{z}dx\wedge dy
$$
over an ellipsoid given by
$$
\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1.
$$ The way I tried to do it was by using the divergence theorem. For $F:=<\frac{1}{x},\frac{1}{y},\frac{1}{z}>$,
$$
\int\int_{S}\frac{1}{x}dy\wedge dz+\frac{1}{y}dz\wedge dx+\frac{1}{z}dx\wedge dy=\int\int_{S}F\cdot dS=\int\int\int_{D}\nabla\cdot F dV.
$$
Then $\nabla\cdot F=-(\frac{1}{x^2}+\frac{1}{y^2}+\frac{1}{z^2})$ so
$$
\int\int\int_{D}\nabla\cdot F dV=-\int\int\int_{D}(\frac{1}{x^2}+\frac{1}{y^2}+\frac{1}{z^2})dV.
$$
Finally I changed to spherical coordinates by substituting $x=a\rho\cos\theta\sin\phi$,$y=b\rho\sin\theta\sin\phi$,$z=c\rho\cos\phi$ to get
$$
-\int\int\int_{D}(\frac{1}{x^2}+\frac{1}{y^2}+\frac{1}{z^2})dV\\
=-abc\int_{0}^{\pi}\int_{0}^{2\pi}\int_{0}^{1}(\frac{1}{a^2\rho^2\cos^2\theta\sin^2\phi}+\frac{1}{b^2\rho^2\sin^2\theta\sin^2\phi}+\frac{1}{c^2\rho^2\cos^2\phi})\rho^2\sin\phi d\rho d\theta d\phi\\
=-abc\int_{0}^{\pi}\int_{0}^{2\pi}\int_{0}^{1}(\frac{1}{a^2\cos^2\theta\sin\phi}+\frac{1}{b^2\sin^2\theta\sin\phi}+\frac{\sin\phi}{c^2\cos^2\phi}) d\rho d\theta d\phi.
$$
I plugged the last integral into Maple to find that the integral was divergent. Did I do something wrong or is that what I am supposed to get? If its correct, how can the integral over a bounded surface be infinite... Sorry my multivariable is a little rusty.","['multivariable-calculus', 'differential-geometry']"
695649,Under what conditions are trigonometric integrals over a period zero?,"Often times, while solving a physics problem, for example, an integral involving only sines and cosines (and constants), over a period, must be solved. In many cases this may prove difficult, so it's useful to know when we can just cross it out. Under what conditions can we assume such an integral to be zero, and most importantly, why? What theorems and properties can we make use of?","['trigonometry', 'calculus', 'integration']"
695673,"Asymptotic normal-behaviour of the MLE, question about proof.","In this proof they prove that the MLE is asymptotically normal. But as you see, they divide by $S'(\theta)$. But what if this value is 0?, you can't divide by zero? Is there a special case when this happen, or can it never happen?","['statistics', 'proof-verification']"
695692,Homework: calculation about differential form,"Here is the question: Let $\omega = A dy\wedge dz + B dz \wedge dx + C dx \wedge dy$ in $\mathbf{R}^3$, and $d\omega = 0$. Denote
\begin{eqnarray}
\alpha = \int_0^1 tA(tx,ty,tz)dt\cdot(ydz-zdy)\\
+\int_0^1 tB(tx,ty,tz)dt\cdot(zdx-xdz)\\
+\int_0^1 tC(tx,ty,tz)dt\cdot(xdy-ydx).
\end{eqnarray}
Then show that $d\alpha = \omega$. Can you teach me how to do this calculation?","['differential-forms', 'smooth-manifolds', 'differential-geometry']"
695701,How can we describe the graph of $x^x$ for negative values?,"We usually only see the graph $y=x^x$ for $x>0$, because $x^x$ is a complex number for most negative values of $x$.  Yet here is a full graph of $y=x^x$ on the real line: This graph may seem like it's not even a function, failing the vertical line test, but what's actually going on is that the graph contains infinitely many holes.  It's true that $x^x$ is not a real number for almost all values of $x<0$, but it is real in the rare situation when $x$ is a rational number which has an odd denominator when written in simplest form.  In that case, $x^x$ is a positive real number when $x$ can be written as an even number divided by an odd number, and a negative real number when $x$ can be written as an odd number divided by an odd number.  So just those rational points are being graphed, but since the rational numbers with odd denominators are dense in the real numbers it looks like we have continuous curves. My question is, what are the continuous curves that seem to be there?  Any continuous curve defined on a dense subset of the reals can be uniquely extended to a continuous function on all the reals.  So what continuous function passes through all the points $(x,x^x)$ where $x<0$ and $x$ can be written as an even number divided by an odd number?  (I'd ask the analogous question about the second curve, but it seems to be a mirror image of the first.) Any help would be greatly appreciated. Thank You in Advance.","['complex-analysis', 'exponential-function', 'real-analysis', 'graphing-functions']"
695706,Is a morphism of reduced schemes over an algebraically closed field determined by its values on closed points?,Let $X$ and $Y$ be reduced schemes over an algebraically closed field $k$ of positive characteristic.  Suppose $f$ and $g$ are morphisms $X \to Y$ with $f(x) = g(x)$ for every $k$-point $x$ of $X$.  Does $f = g$ as morphisms of schemes?,['algebraic-geometry']
695727,A line integral,"If $\mathbf{B}(\mathbf{x})=\rho^{-1}\mathbf{e}_{\phi}$ in cylindrical polars, find: $$\int_{C}\mathbf{B}\cdot\mathrm{d}\mathbf{x}$$ where $C$ is the circle $z=0,\rho=1,\;0\leq \phi\leq 2\pi$ . Also find $\nabla\times\mathbf{B}$ My try: $$\int_{C}\mathbf{B}\cdot\mathrm{d}\mathbf{x}=\int_C (\rho^{-1}\mathbf{e}_{\phi})\cdot (\mathbf{e}_{\rho}d\rho+\rho\mathbf{e}_{\phi}d\phi+\mathbf{e}_{z}dz)=\int_C \mathrm{d}\phi=2\pi$$ This seems way too easy. Is it wrong? For the second part I get $\nabla\times\mathbf{B}=-\rho^{-3}\mathbf{e}_z$ but a friend of mine says it should be $0$ ...","['multivariable-calculus', 'vector-analysis']"
695738,Prove Parallelogram Area Is Twice Triangle Area,"I thought this would be easy but I can't seem to find the answer. Edit: I did my best to draw the diagram: $\overline{EC}=\frac{1}{3} \overline{AC}, \overline{AF}=\frac{1}{3} \overline{AB}, \overline{BD}=\frac{1}{3} \overline{BC}$ I drew a line parallel to $\overline{BE}$ through $R$. I called the intersection of that line and $\overline{AB}$ point $M$. I drew a line parallel to $\overline{AD}$ through $B$, and called the intersection of that line and my previous line $G$. Then I want to prove $BGRP = 2\triangle PRQ$. This is for the ultimate goal of solving the $1/7$ area triangle problem. In addition I need to prove $\triangle BGM = \triangle ARM$, and to prove that I think I need to prove $M$ is the midpoint. I think I'm close with similar triangles $\triangle ARM$ and $\triangle APB$ but I can't get the relationship. Thanks if you managed to read all this. Edit: A full proof is given here , I just need someone to clarify the dialations and transformations.","['geometry', 'triangles']"
695772,Is there a prime between every pair of consecutive triangular numbers?,Between two triangular numbers there is at least one prime number. Is there a mathematical proof for this statement?,['number-theory']
695773,Sine defined for a triangle inscribed in a circle with a diameter of one,"Let a circle be drawn with a diameter of one (and thus a radius of one half). Then let a triangle with vertices A, B, and C be inscribed in the circle (i.e. points A, B, and C are arbitrary points on the circle). Then a, the side of the triangle opposite angle A is equal to sin(A) Likewise, b=sin(B) and c=sin(c). I have attempted to find or devise a proof of this, but I don't know where to start!","['geometry', 'triangles', 'trigonometry', 'circles']"
695826,Sub-Basis of a Topology James Munkres,"James Munkres defines a subbasis $\mathcal S$ for a topology on a set $X$ as a collection of subsets of $X$ whose union equals $X$. Then the topology generated by the subbasis $\mathcal S$ is defined to be the collection $\mathcal T$ of all unions of finite intersections of elements of $\mathcal S$. To prove that $\mathcal T$ is indeed a topology, one only needs to show that the collection $\mathcal B$ of all finite intersections of elements of $\mathcal S$ is a basis. My question is what if $\mathcal S$ is a partition of $X$? Then any finite intersection of the elements of $\mathcal S$ is either $\emptyset$ or the elements of $\mathcal S$. It is clear that $\emptyset$ is not enough to generate a topology. Hence the topology is essentially generated by all the unions of the elements of $\mathcal S$, which is in fact the property of a basis rather than a subbasis. Hence, if my argument is correct, then I can conclude that if elements of $\mathcal S$ form a partition of $X$, then there is no difference between basis and subbasis. Is this right, please? Thank you!","['general-topology', 'self-learning']"
695832,"Is there a limit to $(0,0)$ approaching $\infty$ for the function $x^y$?","Take the function $f(x,y) = x^y$ where $x \in [0,\infty)$ and $y \in (-\infty,\infty)$. The value of $f(0,0)$ is indeterminate. I want to know: Is there some path $S$ on the $(x,y)$-plane that ends at the origin, $(0,0)$, such that $$\lim_{S\to(0,0)} x^y \to\infty$$ And if not, how do you prove that there isn't one? It's trivial to show that there are limits that can equal $0$ or $1$: For $x = 0$, $\lim\limits_{y \to 0} \ 0^y = 0 $, and for $y = 0$, $\lim\limits_{x \to 0} \ x^0 = 1 $. However, I suspect there could be a limit approaching $\infty$ because, If you take some $\delta < 0$ that may be arbitrarily close to $0$, then $$ \lim_{x \to 0} x^{\delta} \to \infty$$ Therefore, in all neighbourhoods centred at $(0,0)$ there exist points at which $x^y$ is arbitrarily large (or approaching infinity if that can be claimed of a point). It seems, to me, that if there's a path for which $x \to 0$ faster than $y \to 0$ than the value of $x^y$ could keep rising as the path goes on and the limit approaching the origin will approach infinity.","['calculus', 'functions', 'limits']"
695837,How prove $|f'(x)|\le 4$ if $|f(x)|\le 1$,"Let $f(x)$ be differentiable on $\Bbb R$, and for any $x_{0}\in \Bbb R$, 
  $$0<f'(x_{0}+x)-f'(x_{0})<4x \qquad(x>0)$$
  and if $|f(x)|\le 1$, show that
  $|f'(x)|\le 4$. I tried to use Langrange’s theorem, but I couldn’t. This is an exam problem from yesterday. Thank you for you help!",['analysis']
695851,What's the fewest number of sides required to make a polytope in n dimensions?,"In 2 dimensions it takes at least 3 sides to make a polygon, the triangle, and in 3 dimensions it takes at least 4 faces (so far as I'm aware) to make a polyhedron. Can this rule be generalized to higher dimensions, so that the minimum number of sides or faces to make a polytope in n-dimensions is equal to n+1? If so, is there a proof for it? And if not, is there a counterexample?","['geometry', 'polygons', 'polytopes']"
695853,Understanding the Gram-Schmidt process,"I would like to better understand the gram-schmidt process. The statement of the theorem in my textbook is the following: The Gram-Schmidt sequence $[u_1, u_2,\ldots]$ has the property that $\{u_1, u_2,\ldots, u_n\}$ is an orthonormal base for the linear span of $\{x_1, x_2, \ldots, x_k\}$ for $k\geq 1$. The formula for $\{u_1, u_2,\ldots, u_n\}$ is:
  \begin{equation}
x_k   = \left|\left| x_k - \sum\limits_{i<k}\langle x_k, u_i\rangle u_i \right|\right|_2^{-1} \left(x_k - \sum\limits_{i<k}\langle x_k, u_i\rangle u_i\right)
\end{equation} Note that I am primarily interested in how all of the vectors are orthogonal. The norm term in the above equation tells me that all the vectors will be unit vectors and hence we get an orthonormal set. Anyway, I see how this works algebraically; Let $v = x_k - \sum\limits_{i<k}\langle x_k, u_i\rangle u_i$. Now, take the dot product of $\langle v, u_j\rangle$ for some $j<k$:
\begin{equation}
  \langle v, u_j\rangle = \langle x_k, u_j\rangle - \sum\limits_{i<k}\langle x_k, u_i\rangle\langle u_i, u_j\rangle
\end{equation}
When we assume in the induction hypothesis that we have an orthonormal basis for $i<k$ then the sum is zero except when $i=j$. This leaves us with:
\begin{equation}
  \langle v, u_j\rangle = \langle x_k, u_j\rangle - \langle x_k, u_j\rangle = 0
\end{equation} OK, I can logically follow algebra, but how can I see this geometrically? Can someone provide both 2D and 3D examples/plots? Since I am specifically interested in seeing how all the vectors meet at 90 degrees.","['geometry', 'gram-schmidt', 'linear-algebra', 'visualization', 'orthonormal']"
695875,Prove that $h< \frac{(k+l)^{k+l}}{(k^{k}l^{l})}$.,"Let $\left \{ \left ( A_{i},B_{i} \right ),1\leq i\leq h \right \}$ be a family of pairs of subsets of the set of
integers such that $\left | A_{i} \right |=k$ for all $ i$ and $\left | B_{i} \right |=l$ for all $i$, $A_{i}\cap B_{i}=\emptyset$ and
$(A_{i}\cap B_{j})\cup (A_{j}\cap B_{i})\neq \emptyset$ for all $i\neq j$ . Prove that $h< \frac{(k+l)^{k+l}}{(k^{k}l^{l})}$. this is problem 7 of chapter one from alon and spencer The Probabilistic Method. this is very near to the concepts of $(k,l)-system$ which is discussed there.
I want to call an event which its probability will be $\frac{(k^{k}l^{l})}{(k+l)^{k+l}}$.this events must be disjoint.then I want to say that the number of these events are $h$.then from the rule of probability we have $h\frac{(k^{k}l^{l})}{(k+l)^{k+l}}<1$ and it is done.it was the basic method. now I don't know what is that  specific event that make every thing done.I have thought about taking red and blue balls from a box because of similarity to $\frac{k}{k+l}$ and $\frac{l}{k+l}$ which they happen $k$ and $l$ times with putting the ball in the box after taking it,but it seems not to work,so please help me,thank you very much.","['probabilistic-method', 'discrete-mathematics', 'probability', 'combinatorics']"
695881,Analysis/Inequality question about proving an infinite product greater than 0,"This is from David Williams' book Probability using Martingales. I'm self-studying. Question Prove that if $$0\leq p_n < 1 \quad\text{ and }\quad S:=\sum p_n < \infty$$ then $$\prod (1-p_n) > 0$$ Hint: First show that if $S<1$, then $\prod (1-p_n)\geq 1-S$. I was able to prove the hint using induction. Assume $\prod\limits_{n=1}^N (1-p_n) \geq 1-\sum\limits_{n=1}^N p_n$. Consider $\prod\limits_{n=1}^{N+1}(1-p_n) \geq (1-\sum\limits_{n=1}^N p_n)(1-p_{N+1})=1-\sum\limits_{n=1}^{N+1}p_n+p_{N+1}\sum\limits_{n=1}^{N}p_n \geq 1-\sum\limits_{n=1}^{N+1}p_n$. But I'm unable to use this to prove the general result for arbitrary $S$. Any guidance would be appreciated. I'm also surprised that he asks this question after stating the 2nd Borel Cantelli lemma, I don't see the connection.","['inequality', 'infinite-product', 'measure-theory', 'self-learning', 'real-analysis']"
695908,Online tools for generating the NULL SPACE of the matrix over Finite Field of size 2,"Is there any online tool where I just enter the values in (0,1) Finite Field of size 2 and it's give me the NULL SPACE matrix ? I have 25x25 , 36x36 , 25x36 , 36x25 matrix. Below is my 25 x 25 matrix 1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   
1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   
0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   
0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   
0   0   0   1   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   
1   0   0   0   0   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   
0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   
0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   
0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   
0   0   0   0   1   0   0   0   1   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   
0   0   0   0   0   1   0   0   0   0   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0   
0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   
0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   
0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   
0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   0   0   0   0   1   0   0   0   0   0   
0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   1   1   0   0   0   1   0   0   0   0   
0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   0   
0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   0   
0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   0   1   0   
0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   0   0   0   0   1   
0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   1   1   0   0   0   
0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   0   
0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   0   
0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1   1   
0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   1   1 Below is my 36 x 36 matrix. 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1","['matrix-equations', 'matrices', 'linear-algebra', 'online-resources']"
695910,How to conclude that $r^t(E\cos(\theta t)+Fsin(\theta t))$ ossilates with increasing magnitude?,"Given: $r^t(E\cos(\theta t)+Fsin(\theta t))$ Assume $r>1$, $E>0$, $t\ge0$ and $F$ is not known. How do we conclude that the given expression oscillates with increasing magnitude? My attempt: Since $r>1$, $r^t$ will tend to infinity as $t$ tends to infinity. Therefore, if the expression is supposed to oscillate with increasing magnitude, then $(E\cos(\theta t)+Fsin(\theta t))$ will need to change regularly change sign. I know that the $\cos$ and $sin$ function will alternate from -1 to 1 but I don't know how to apply that property to this question. Please help.","['algebra-precalculus', 'limits']"
695923,Estimating the maximum of a Brownian motion over the unit interval,"Let $\left(B_t\right)_{t \in \left[0,\infty\right)}$ be a standard Brownian motion over the probability space $\left(\Omega, \mathcal{A}, P\right)$. For each $x \in \left(0, \infty\right)$, give an upper bound $q\left(x\right)$ on
$$
P\left(\max_{t \in \left[0,1\right]} B\left(t\right) > x\right)
$$ so that the following requirement is satisfied: $$
\forall \epsilon \in \left(0, \infty\right),\ 
\Sigma_{n = 1}^\infty q\left(n\varepsilon\right) < \infty
$$ Attempted solution #1 Consider Paul Lévy's construction of the Brownian motion on the interval $\left[0,1\right]$ as the limit of piecewise linear functions $F_n$ with knots at the dyadic fractions $\frac{m}{2^n} \in \left[0,1\right]$. Let $\omega \in \Omega$ be such that the path $t \in \left[0, \infty\right) \mapsto B_t\left(\omega\right)$ is continuous. Then if $B_d > x$ for some dyadic fraction, then clearly $\max_{t \in \left[0,1\right]} B_t > x$; whereas if $B_d > x$ for no dyadic fraction, then due to the density of the dyadics on the real line, $\max_{t \in \left[0,1\right]} B_t \leq x$. Therefore, denoting the set of dyadic fractions in the unit interval by $\mathcal{D}$, we have $$
\left\{\max_{t \in \left[0,1\right]} B_t > x\right\} =
\bigcup_{d \in \mathcal{D}}\left\{B_d > x\right\}
$$ The only way I know how to bound the probability of a union from above is using the subadditivity property of the probability measure: $$
P\left(\bigcup_{d \in \mathcal{D}}\left\{B_d > x\right\}\right) \leq \sum_{d \in \mathcal{D}}P\left(B_d > x\right)
$$ Now, $B_d \sim N\left(0, d\right)$ and the tightest upper bound on the normal distribution that I'm familiar with is $$
P\left(N\left(0, d\right) > x\right) = P\left(N\left(0,1\right) > \frac{x}{\sqrt{d}}\right) \leq \frac{1}{\sqrt{2\pi}}\frac{1}{x/\sqrt{d}}\exp\left(-\frac{\left(x/\sqrt{d}\right)^2}{2}\right)
$$ The problem is, for any given dyadic point there are an infinity of other dyadic points that lie very closely, and hence yield values that lie very near the expression on the right. Therefore, the infinite sum of these expressions will go to infinity. Attempted solution #2 According to Wikipedia , $E\left(M\right) = \sqrt{\frac{2}{\pi}}$, where $M$ denotes $\max_{t \in \left[0,1\right]} B_t$. Now, since $0$ is almost surely not a maximum point, $M \geq 0$ a.s., whence, by the Markov inequality $$
P\left(M > x\right) \leq \frac{\sqrt{2/\pi}}{x} := q\left(x\right)
$$ There are two problems with this solution: It does not satisfy the requirement $\sum q\left(n\varepsilon\right) < \infty$ I haven't learned yet that $E\left(M\right) = \sqrt{\frac{2}{\pi}}$. Ideally, the solution should be based on Lévy's construction of the Brownian motion and on the most basic of properties that can be derived from it.","['probability-theory', 'stochastic-processes', 'optimization', 'brownian-motion']"
695934,Surface of earth seen is 1/4,"At what height from the ground can one see exactly 1/4 th of the Earth's surface ? 
Take earth to be sphere of radius r.",['trigonometry']
695948,Prove that an annulus is not simply connected?,"I don't have complex analysis at my beck and call, and I only have a low level of knowledge in topology, but I need to prove that this metric space (for any real $r$ and $R$ with $r < R$)$$ X = \{ (x, y) \in \mathbb{R}^2 \ | \ r \leq x^2 + y^2 \leq R \}$$ with the Manhattan metric $d((x_1, y_1), (x_2, y_2)) = |x_1-x_2| + |y_1-y_2|$ is not simply connected. I've already prooven that it's path connected, and now I need to show there are some points $P$ and $Q$ with two paths between them such that one cannot be continuously 'morphed' into the other. $ \ $ What I have so far is as follows: I take $P = (0, r)$ and $Q = (0, -r)$, with $f_0$ being a path from $P$ to $Q$ going clockwise around the circle radius $r$ and $f_1$ being much the same but going counterclockwise. Now I assume there is a function $g : [0, 1]^2 \to X$ such that: $g(s, 0) = f_0 (s)$ $g(s, 1) = f_1 (s)$ $g(0, t) = P$ $g(1, t) = Q$ To get the final result, I need to show that this function cannot be continuous, but for the life of me I cannot. For some context, these are the topics which have been visited during the course, roughly in order of recentness. Multiple connectedness Simple connectedness Pathwise connectedness Interior points Boundary points Open sets Compactness Complete metric spaces Bounded metric spaces Totally bounded metric spaces Closed sets Closure of a metric space Limit points Cauchy sequences Convergence Continuity Metric space quivalence Metric equivalence Edit : I might have an argument that works, though it's far from rigourous. We can shrink $R$ to be as close to $r$ as we want, so we can essentially constrain the annulus down to a circle and thus force any path from the left side of the circle to the right side to go through $P$ or $Q$. So holding $s \in (0, 1)$ constant and varying $t$ must produce a path through $P$ or $Q$ for any $s$. If for some $s$ it passes through $P$ and for some other $s$ it passes through $Q$, then there must be $s_0$ such that $\forall \epsilon >0  \ \exists \delta \leq \epsilon$ st. $s_0$ produces a path through $P$ and $s_0 + \delta$ produces a path through $Q$. Now we can consider the path $g(s, \frac{1}{2})$, and note that it must have a discontinuity at $s_0$. Now consider the case where all $s$ produce paths through only one of $P$ or $Q$. WOLOG: $P$. Now, at $t = \frac{1}{2}$, $s$ arbitrarily close to $1$ are mapped away from $Q$, but $1$ is always mapped to $Q$ by definition, so $g(s, \frac{1}{2})$ has a discontinuity at $s=1$. Therefore $g(s, t)$ is not continuous. This argument is definitely iffy to me, if no one has their own argument (using sufficiently low level concepts), then criticism on the above would be appreciated.","['general-topology', 'connectedness']"
695979,Does every prime divide some Fibonacci number?,"I am tring to show that $\forall a \in \Bbb P\; \exists n\in\Bbb N : a|F_n$, where $F$ is the fibonacci sequence defined as  $\{F_n\}:F_0 = 0, F_1 = 1, F_n = F_{n-1} + F_{n-2}$ $(n=2,3,...)$. How can I do this? Originally, I was trying to show that $\forall a\in\Bbb N\;\exists n\in\Bbb N:a|F_n$. I soon found out that if the $k$-th Fibonacci can be divided by $m$, then the $nk$-th Fibonacci can also be divided by $m$, and this can be reduced to my original problem in this post.","['sequences-and-series', 'modular-arithmetic', 'elementary-number-theory', 'prime-numbers', 'fibonacci-numbers']"
695980,About linear bijection between Banach spaces!,"It is well-known that, by Banach theorem, every continuous, linear and bijective operator between Banach spaces is a isomorphism. There must be a linear bijective and discontinuous operator between Banach spaces! How can we show/construct such a map? Thanks for all helpings!","['examples-counterexamples', 'real-analysis']"
695999,Why do some say that $f(x)=\frac{1}{x}$ discontinuous?,"A continuous function $f:X\to Y$ is one which satisfies the following property: for every open set $U\subset Y$, the set $f^{-1}(U)$ is open in $X$. I don't see why according to this definition $f(x)=\frac{1}{x}$ is discontinuous at $0$. The inverse image of every open set of the form $(a,\infty)$ is open, it is $(0,\frac{1}{a})$. Similarly, the inverse image of $(-\infty,-a)$ is $(-\frac{1}{a},0)$.
And one can see that the inverses of other forms of open sets are also clearly open. Why then is $1/x$ discontinuous according to some?","['calculus', 'continuity', 'real-analysis']"
696043,Why there is not the next real number?,"We can't say what is the just next real number (or rational or irrational number) of a given real number (or rational or irrational number respectively), what is the actual fundamental reason  behind it?      Is it for the property of denseness of the sets?   Please help me to sure about the answer of this question.","['elementary-set-theory', 'real-analysis']"
696046,Local parameter of curves in affine n-space,"I'm looking for a double answer to this question: a mathematical one (say, if the statement is correct or not) and a philosophical one (say, why we do expect this to be true, or not). Let $k$ be a field, that we may or may not assume to be algebraically closed. Let $A = k[x_1, \ldots, x_n]$ be the polynomial ring in $n$-variables and coefficients in $k$. Consider an embedded curve $C$ in $\mathbb{A}^n$, regular at a point $P$ (say, the origin). Let $I = (f_1, \ldots, f_r)$ be the ideal defining the curve. By the Jacobian criterion, we know that not all the derivatives of $f_i$ are $0$ in $P$. Let $\mathcal{O}_{C,P} = A_P/I_P$ be the local ring of $C$ at $P$: it is a discrete valuation ring and we can choose a local parameter $t$ for $C$ at $P$, i.e. a generator for the maximal ideal. We can therefore write down a local parametrization of the curve: $$ x_i=x_i(t)= t^{c_i}g_i(t), c_i\in \mathbb{Z}, v_t(g_i(t))=0 $$
where $v_t$ denotes the valuation. The Jacobian criterion recalled above tells us that, in particular, there is one $x_i$ (say $x_n$) such that $c_i=1$. By passing to the completion $\hat{\mathcal{O}}_{C,P}$ we can absorb the unit term in the local parameter. This gives in particular that we could have chosen directly $x_n\in \mathcal{O}_{C,P}$ as parameter and we could have written down $$x_i =h_i(x_n), h_i(x_n)\in k[[x_n]]$$ Now the question is: is it true that we have a canonical isomorphism $$\hat{\mathcal{O}}_{C,P} \cong k[[x_1, \ldots, x_n]]/(x_i-h_i(x_n))$$
(hopefully one should not complete again on the right)? For $n=2$, one can invoke Hensel's lemma, in the form that reminds the implicit function theorem: let $f(x,y)\in k[[x]][y]$ and suppose $f(0,0)=0$, $\partial f/\partial y(0,0)\neq 0$. Then there exists $g(x)\in k[[x]]$ such that $g(0)=0$ and $f(x, g(x))=0$. If I understand correctly, this statement gives that, after passing to the completion, one has 
$$k[[x,y]]/(f(x,y)) \cong k[[x,y]]/(y-g(x))\cong k[[x]]/(g(x)).$$ Side question: we know that the implicit function theorem does not hold in algebraic geometry, in the sense that Zariski topology has too large open sets to expect that an étale map is a local isomorphism. On the other hand, we generally say that ""this is true étale-locally"". So I ask: is the above statement correct after passing to the Henselianization of the ring $\mathcal{O}_{C,P}$? Is this true after passing to the strict Henselianization?","['commutative-algebra', 'implicit-function-theorem', 'algebraic-geometry', 'algebraic-curves']"
696059,Qualifying Exam Question On Elementary Group Theory,"Question. Let $G$ be a finite group and $p$ be the smallest prime dividing $|G|$. Let $x$ be n element of order $p$ in $G$. Assume that there exists an element $h\in G$ such that $hxh^{-1}=x^{10}$. Show that $p=3$. What I have done so far is use the fact that $o(hxh^{-1})=o(x)=p$ and $o(x^{10})=p/\gcd(p,10)$. By hypothesis we have $p=p/\gcd(p,10)$, giving $\gcd(p,10)=1$. Here I am stuck. I have not been able to make use of the fact that $p$ is the smallest prime divisor of $|G|$. Can somebody help?","['finite-groups', 'group-theory']"
696064,Differentiating $y=x^x$ with the formal definition of a derivative,"A friend and I were messing around with derivatives, and while we both know the procedure for finding the derivative of $y=x^x$ with logarithmic differentiation, i.e. $$y=x^x\\
\ln(y)=x\ln(x)\\
\dfrac{\mathrm{d}y}{\mathrm{d}x}\dfrac{1}{y}=1+\ln(x) \\
\dfrac{\mathrm{d}y}{\mathrm{d}x}=y(1+\ln(x))\\
\dfrac{\mathrm{d}y}{\mathrm{d}x}=x^x(1+\ln(x))$$ when we tried to do it with the formal definition of the derivative, we got this $$\lim_{h \to 0}\frac{f(x+h)-f(x)}{h}\\
\lim_{h \to 0}\frac{x^{x+h}-x^x}{h}\\
\lim_{h \to 0}\frac{x^xx^h-x^x}{h}\\
\lim_{h \to 0}\frac{x^x(x^h-1)}{h}$$ then we pulled out the $x^x$ $$x^x\lim_{h \to 0}\frac{x^h-1}{h}$$ Then, using l'Hopital's rule, we differentiated with respect to $h$ , like this $$\lim_{h \to 0} \frac{x^h-1}{h}\\
\lim_{h \to 0} \frac{x^h\ln(x)}{1}$$ and since $x^h$ approaches zero, we get $\ln(x)$ for the limit Putting that together, we have $$\dfrac{\mathrm{d}y}{\mathrm{d}x}=x^x \ln(x)$$ and somewhere in between, we lost an $x^x$ . Where did I go wrong here? Am I not allowed to take the derivative with only respect to $h$ ?","['logarithms', 'calculus', 'derivatives']"
696073,Generalisation of kth derivative to real values of k,"The answer to this question is most likely no, but I'm asking anyway: Assume that $f\in C^n(\mathbb {R,R})$. Is their any natural generalisation of the map $$\{1,2,\ldots,n\}\to C(\mathbb{R, R})\\k\mapsto f^{(k)}$$
to a map
$$
[1, n]\to\{g\colon\mathbb{R\to R}\}\\
x\mapsto f^{(x)}?
$$
That is, can we generalise ""the $k$th derivative"" to ""the $x$th derivative"" for real values of $x$? What I mean by ""natural"" is: Anything that has desirable properties and that has been explicitly formulated by someone, somewhere.",['derivatives']
696086,Two dependent random variables with standard normal distribution and zero covariance,"I need to find two dependent random variables with standard normal distribution, but with zero covariance. It is easy too find just two dependent random variables with such a distribution ( X and -X , for example), but how I can reach zero covariance? Thanks in advance.","['probability-theory', 'probability-distributions', 'probability']"
696107,Why Steiner Symmetrization makes a measurable set to a measurable one?,"I find the Steiner Symmetrization is very useful in proving that the Hausdorff measure coincide with Lebesgue in the Euclidean space. However, I never saw anybody mention that the Steiner Symmetrization takes a measurable set to a measurable one. To know how this is done, see here . Here is also a related problem.","['geometric-measure-theory', 'measure-theory', 'functional-analysis', 'real-analysis']"
696112,Why do people look into modules over Dedekind domains?,It is said in this blog that: The reason this turns out to be useful is that many examples in algebraic/arithmetic geometry require you to look no further than understanding modules over Dedekind domains. Could anyone provide me some examples illustrating this?,"['commutative-algebra', 'algebraic-geometry', 'dedekind-domain']"
696124,"$f$ a real, continuous function, is it measurable?","Let $f: \mathbb{R} \to \mathbb{R} $ be a continuous function. I need to show that is a measurable function. I tried working with the definition: 
Let $f: X \to \mathbb{R}$ be a function. If $f^{-1}(O)$ is a measurable set for every open subset $O$ of $\mathbb{R}$ , then $f$ is called a measurable function. Since $f^{-1}(O)$ also lies in $\mathbb{R}$ , I think it is sufficient to show that every subset of $\mathbb{R}$ is measurable. But is this possible? So far I concluded that $\mathbb{R}$ itself is measurable, since $$\mu(A) = \mu(A \cap \mathbb{R}) + \mu(A \cap \mathbb{R}^c) = \mu(A) + \mu(\emptyset) = \mu(A).$$ How do I need to approach?","['measure-theory', 'lebesgue-measure', 'measurable-functions', 'real-analysis']"
696145,Find $f(10)$ in the functional equation $f(f(n))=3n$,"For each positive integer $n$ , define $f(n)$ such that $f(n+1) > f(n)$ and $f(f(n))=3n$ . What is the value of $f(10)?$ This question was really hard for me. Since $n$ is a positive integer and $f(f(n)) = 3n$ , I deduced that $1<f(1)<f(f(1))$ so $f(1) = 2$ and I couldn't manage to carry on because if i used $2<f(2)<f(f(2))$ , I would get $f(f(2)) = 6$ but I wouldn't know how to work out $f(2)$ . If someone could please show me step by step how to get the answer, I would appreciate it as I would like to know how to get the answer, thanks.","['functions', 'functional-equations']"
696163,"If $B$ is a graded $A$-algebra, then $\operatorname{Proj}B$ is an $A$-scheme","If $B$ is a graded ring, then for me is clear that $\operatorname{Proj}B$ with affine covering given by $D_+{(f)}\cong\operatorname{Spec} B_{(f)}$ is a scheme. The problem arises when $B$ is a graded $A$-algebra, because in this case $\operatorname{Proj}B$ should be an $A$-scheme: clearly  we have a morphism of rings $A\longrightarrow B_{(f)}$ that induces a morphism of affine schemes ${\operatorname{Spec}{B}}_{(f)}\longrightarrow\operatorname{Spec} A$. Now, to get the structure of $A$-scheme, we must define a morphism from $\operatorname{Proj}B$ to $\operatorname{Spec} A$, and the simplest thing to do is glueing the above morphisms of affine schemes.
But nobody ensures that this glueing is possible; to be precise my question is the following: why do the affine morphisms  match on the intersections? Many thanks in advance.","['algebraic-geometry', 'schemes', 'projective-schemes']"
696224,probability of a function f(x) to be increasing,"Suppose $f(x)=x^3+ ax^2 + bx +c$ . Now a,b,c are chosen respectively by throwing a dice 3 times. Now find the Probability that $f(x)$ is a increasing function ? MY APPROACH : i really have given a lot thought to it but i have no clue. i cant find even the first step towards solving the problem . Didnt understand what they meant by saying f(x) is a increasing function . when a function becomes an increasing function? what are the conditions of that ? and what is the solution of this question?","['probability', 'functions', 'combinatorics']"
696268,Why does the same limit work in one case but fail in another?,"The following questions has been bugging me since high-school calculus. Please help me find my peace once and for all: Consider a revolution solid generated by rotating a nice curve $f(x)$ around the $x$-axis on the interval $[a,b]$ (provided that $f(x)$ does not cross the $x$-axis on this interval). Let us first find the volume of this solid, $V$. We slice the interval $[a,b]$ into small segments of width $\delta_x$. Each segment is approximately a cylinder of radius $f(x)$ and height $\delta_x$, hence having a volume of $\pi [f(x)]^2 \delta_x$. Taking the limit we get $$V = \pi \int_a^b [f(x)]^2 \, dx$$ which is the right formula: great. Now we apply the exact same argument to find the surface area of the solid, $S$. The surface area of each cylindrically-approximated segment is $2 \pi f(x) \delta_x$, and taking the limit we obtain $$S = 2 \pi \int_a^b f(x) \, dx$$
which is not correct. We would obtain the correct formula for $S$ if we take the heights of the segments to be the arc lengths of $f(x)$ over each $\delta_x$, so I suspect that what is going wrong has something to do with this . But my question is: why does this argument work for finding $V$, but not $S$?","['calculus', 'integration', 'limits', 'analysis', 'fake-proofs']"
696269,"Integral $\int_0^\infty \frac{1}{(1+x^m)(1+x^2)}\,dx$ [duplicate]",This question already has answers here : Is the integral $\int_0^\infty \frac{\mathrm{d} x}{(1+x^2)(1+x^a)}$ equal for all $a \neq 0$? (4 answers) Closed 10 years ago . I saw somewhere that the above integral is equal to $\pi/4$ for all real number $m$. This seems to be surprising. Does anyone have a nice proof?,"['definite-integrals', 'analysis']"
696285,Subspaces in the image of compact operator,"Let $X$ and $Y$ be some infinite dimensional Banach spaces. Let $T:X\longrightarrow Y$ be some compact linear operator. It is easy to understand that $T$ cannot be surjective: the Open Mapping Theorem due to Banach, states that surjective operators should be open, and it follows that the image of the unit ball $\mathbb{B}_{1,X}$ should contain an open ball $\{||y||<r\}$ for some $r>0$, so its closure can't be compact. Is it true that the image of $T$ cannot contain  any closed subspace of infinite dimension?","['operator-theory', 'compact-operators', 'functional-analysis', 'banach-spaces']"
696286,How to solve : $\lim_{n\rightarrow \infty} \frac{n!}{n\cdot 2^{n}}$,$$\lim_{n\rightarrow \infty} \frac{n!}{n\cdot 2^{n}}$$ I need to solve the limit problem above. I have no idea about what to do. What do you suggest? Thanks in advance.,"['calculus', 'limits']"
696322,"Why doesn't this approach work for $\int \sec^4 x\,dx$?","I been trying to integrate $\sec^4$ , without much luck. But I don't entirely understand why my result is invalid and would like some feedback if possible. I'm attacking the issue in the following way $$
\int (\sec^2{x})^2dx = \int (\tan^2+1)^2dx
$$ then, I put $u=\tan^2+1$ which means $x = \arctan(\sqrt{u-1})$, which allows me to do the following backwards substitution $$
\int (\sec^2{x})^2dx = \int (\tan^2+1)^2dx = \int u^2 \frac{1}{2u\sqrt{u-1}} dx = \frac{1}{2}\int u (u-1)^{\frac{-1}{2}} dx 
$$ Now using integration by parts I get $$\begin{align*}
\int u (u-1)^{\frac{-1}{2}} dx &= \frac{1}{2}(2u(u-1)^{\frac{1}{2}} - \int 2(u-1)^{\frac{1}{2}})\\\\
&= \frac{1}{2}(2u(u-1)^{\frac{1}{2}}-\frac{4}{3}(u-1)^{3/2}) \\\\
&= \frac{1}{2}(2(\tan^2{x}+1)(\tan^2{x})^{\frac{1}{2}}-\frac{4}{3}(\tan^2{x})^{3/2})
\end{align*}$$ This however, seems to be incorrect. How come?","['calculus', 'integration', 'indefinite-integrals']"
696327,"Proof of ""Eigenvectors corresponding to different eigenvalues are linearly independent."" [duplicate]","This question already has answers here : How to prove that eigenvectors from different eigenvalues are linearly independent [duplicate] (8 answers) Closed 10 years ago . ""Eigenvectors corresponding to different eigenvalues are linearly independent."" My professor told us this during a lecture, but gave no proof or explanation.",['linear-algebra']
696338,Tensor product of monoids and arbitrary algebraic structures,"Question. Do you know a specific example which demonstrates that the tensor product of monoids (as defined below) is not associative? Let $C$ be the category of algebraic structures of a fixed type, and let us denote by $|~|$ the underlying functor $C \to \mathsf{Set}$. For $M,N \in C$ we have a functor $\mathrm{BiHom}(M,N;-) : C \to \mathsf{Set}$ which sends an object $K \in C$ to the set of bihomomorphisms $M \times N \to K$, i.e. maps $|M| \times |N| \to |K|$ which are homomorphisms in each variable when the other one is fixed. Then one can show as usual that $\mathrm{BiHom}(M,N;-)$ is representable and call the universal bihomomorphism $M \times N \to M \otimes N$ the tensor product of $M,N$. This is a straight forward generalization of the well-known case $C=\mathsf{Mod}(R)$ for a commutative ring $R$. Actually, this is a special case of a more general tensor product in concrete categories, studied in the paper ""Tensor products and bimorphisms"", Canad. Math. Bull. 19 (1976) 385-401, by B. Banaschewski and E. Nelson. Here are some examples: For $C=\mathsf{Set}$, the tensor product equals the usual cartesian product. This is also true for $C=\mathsf{Set}_*$. For $C=\mathsf{Grp}$, we get $G \otimes H \cong G^{\mathsf{ab}} \otimes_{\mathbb{Z}} H^{\mathsf{ab}}$, using the Eckmann-Hilton argument . (This differs from the ""tensor product of groups"" studied in the literature). The case $C=\mathsf{CMon}$ is very similar to the well-known case $C=\mathsf{Ab}$ and is spelled out here ; namely, we have internal homs and therefore a hom-tensor-adjunction. The same is true for $C=\mathsf{Mod}(\Lambda)$ for a commutative algebraic monad $\Lambda$, see here , Section 5.3. Note that the tensor product is commutative, and that it commutes with filtered colimits in each variable. However, the case $C=\mathsf{Grp}$ shows that it does not have to commute with coproducts. In particular, tensoring with some object is no left adjoint. Also, the free object on one generator is not a unit in general: Let us consider $C=\mathsf{Mon}$. Then, we have $\mathbb{N} \otimes M = M / \{ (mn)^p = m^p n^p \}_{m,n \in M, p \in \mathbb{N}}$ The usual proof of the associativity of the tensor product breaks down: There is a map $\beta : M \times (N \otimes K) \to (M \otimes N) \otimes K$ mapping $(m, n \otimes k) \mapsto (m \otimes n) \otimes k$, which is a homomorphism in the second variable. But what about the first variable? The equation $\beta(mm',t) = \beta(m,t) \beta(m',t)$ is clear if $t \in N \otimes K$ is a pure tensor. But for $t=(n \otimes k) (n' \otimes k')$ we end up with the unlikely equation $((m \otimes n) \otimes k) ((m' \otimes n) \otimes k) ((m \otimes n') \otimes k') ((m' \otimes n') \otimes k')$
$=((m \otimes n) \otimes k)  ((m \otimes n') \otimes k') ((m' \otimes n) \otimes k) ((m' \otimes n') \otimes k')$","['abstract-algebra', 'tensor-products', 'category-theory', 'monoid', 'universal-property']"
696356,Let $F$ be a field of order $2^n$. Prove that characteristic of $F$ is 2.,"I figure that Lagrange's theorem and the fact that the characteristic of an integral domain is either $0$ or prime should be used, but just can't figure it out exactly.","['ring-theory', 'abstract-algebra', 'field-theory']"
696417,$\mathbb{F}_p[X]/(X^2+X+1)$ is a field iff $p \equiv 2 \bmod 3$,"Let $p$ be a prime. Prove that $\mathbb{F}_p[X]/(X^2+X+1)$ is a field iff $p \equiv 2\bmod3$. So: If $p \equiv 2 $ mod $ 3$, I have to show that every element of $\mathbb{F}_p[X]/(X^2+X+1)$ has an inverse. If $\mathbb{F}_p[X]/(X^2+X+1)$ is a field I have to show $p \equiv 2 $ mod $ 3$.","['abstract-algebra', 'field-theory']"
696421,Proving onto of a two variable function,"So I know how to prove a function is onto if it has 1 variable. But this one has two and I'm confused about how to approach it. $f: \mathbb{Z} \times \mathbb{Z} \to \mathbb{Z}$ such that for any $(x,y) \in \mathbb{Z} \times \mathbb{Z}$ $f(x,y) = ax + by$",['functions']
696423,Difficulty in solving challenging trig equation,"Find $\theta$ on $[0, 2\pi)$ such that $$\cos{\theta}^{\sin{\theta}^{\cos{\theta}^{\dots}}} = 2 + 2\sec^2{\theta}\tan^2{\theta} - \sec^4{\theta} - \tan^4{\theta}$$ I'm not sure on how to tackle this problem. I've never really dealt with exponentiation of trig functions. Any help is helpful. Thank you very much","['trigonometry', 'problem-solving']"
696441,Convergence in distribution ( Two equivalent definitions),"I read that for convergence in distribution it is equivalent to have that either the characteristic functions of the random variables convergence pointwise or we have that $F_{X_n} \rightarrow F_{X}$ pointwise, where $F$(the distribution function) is continuous. I could not find a proof of this, so I was wondering how hard it is to show? Does anybody here have a (Internet)-reference or could sketch the idea?","['probability-theory', 'stochastic-calculus', 'real-analysis', 'probability-distributions', 'probability']"
696447,Direct image of an ideal sheaf along a blow-up,"Suppose that $I\subseteq\mathbb{C}[x_0,\ldots,x_n]$ is a saturated homogeneous ideal. Let $\mathcal{I}\subseteq\mathcal{O}_{\mathbb{P}^n}$ denote the corresponding coherent ideal sheaf, and then let $$\pi:Y=\mathrm{Bl}_{\mathcal{I}}(\mathbb{P}^n)\longrightarrow\mathbb{P}^n$$ be the blow-up of $\mathbb{P}^n$ along $\mathcal{I}$. Since $\mathbb{P}^n$ is normal, we know that $\mathcal{J}=\pi_*(\mathcal{I}\cdot\mathcal{O}_Y)$ is a coherent ideal sheaf of $\mathcal{O}_{\mathbb{P}^n}$. In general, $\mathcal{I}$ and $\mathcal{J}$ are not the same, so my question is: Given $I$, how can I compute the saturated homogeneous ideal $$J=\bigoplus_{d\geq 0}\Gamma(\mathbb{P}^n,\mathcal{J}(d))\subseteq\mathbb{C}[x_0,\ldots,x_n]$$ (which, of course, is just the graded ideal attached to $\mathcal{J}$)? Is there a way to do it efficiently? By 'efficiently' I mean using a computer program like Macaulay2. Note that if we took the normalised blow-up, $J$ would simply be the integral closure of $I$.","['commutative-algebra', 'algebraic-geometry']"
696450,"If ten points are on a unit square, one pair is at most $\sqrt2/3$ apart","Ten points are placed in a unit square. Show that there is a pair of points at most $\sqrt2/3$ apart. 
I'm not sure how to proceed with this problem, and have not had any luck so far.","['geometry', 'pigeonhole-principle']"
696465,"$\hom(V,W)$ is canonic isomorph to $\hom(W^*, V^*)$","Introduction My Semester just started and we have a new Professor for Linear Algebra II (replacing our former Professor). Apparently we are behind our schedule and thus we only had a brief introduction (5 Minutes on the Blackboard) about the Dual Space and canonical isomorphisms . In the current problem set there is this optional (not mandatory and not accredited) exercise which I understand as good as nothing about: Problem : Let $V$ and $W$ be finite dimensional $\mathbb{K}$-Vectorspaces$^{1)}$. Show that $\hom(V,W)$ is canonical isomorph to $\hom(W^*,V^*)$ and find the canonical isomorphism. $^{1)}$ ($\mathbb{K}$ denotes a field here, I presume in english literature they write $\mathbb{F}$) Hint (given by my tutor): $$ \Phi: \hom(V,W) \longrightarrow  \hom(W^*,V^*) \\ \Psi \longmapsto (\varphi \longmapsto \varphi\circ \Psi)$$ My problems are vast now: The literature I am reading does a bad job at explaining this topic The online literature I find seems to be way beyond my level, they usually include tensor algebra to solve this. So I fall down the math rabbit hole see, On ""familiarity"" (or How to avoid ""going down the Math Rabbit Hole""?) I don't understand the Hint , I did not encounter such a function before, not even in Analysis and I don't know what's happening. I can only guess that it is a function that somehow completes a circle. On the bright side : I believe to understand what a canonical isomorphism is. My Professor said it is an isomorphism that does not involve making a choice for a basis. In the above function we do not make such a decision and therefore it would be a candidate for a canonical isomorphism. If I would understand the above function, I'd merely have to show that it is injective (trivial Kern) and surjective to complete the task. Unfortunately, as far, we've only done such things using an explicit Matrix and not a function. I do know the definition of the Dual Space, also using the Kronecker Delta.  (although I know nothing about it's meaning and geometric intrepreation, if there is any) The way my tutors sell this exercise it's supposed to be very easy, once the definitions are clear. To-Do-List : Understand the function, know what's happening. Show that the function is surjective Show that the function is injective (trivial Kern)","['linear-algebra', 'self-learning', 'vector-space-isomorphism', 'definition']"
696479,Deep Understanding of Independence of Probabilities,"I really want to have a deep understanding of the independent probabilities of two events.
That means to me that I just do not want to use and know the definition. I want to fully understand the why. Definition 3.1. (a) Two events $A$ and $B$ are independent if $\text{P}(A \cap B) = \text{P}(A)P(B)$. (b) $A$ (possibly infinite) collection of events $(A_i)_{i \in I}$ is an independent collection if for every finite subset $J$ of $I$, one has
  $$\text{P}\left(\bigcap_{i \in J} A_i\right) = \prod_{i \in J}\text{P}(A_i).$$
  The collection $(A_i)_{i\in I}$ is often said to be mutually independent. Therefore my question: Let's consider two events of two train crashes $A$ and $B$. $A$ is in London and $B$ is in New York. If the intersection of the two trains is a multiple of the probabilities of the two events then these two events are independent.(In my opinion this should be $0$ for independent events) If not they are dependent. If we just know this kind of information, logically these two events should not be dependent, because a train crash in London should not have anything to two with one in New York. (Could I also say shares the same information?) However, if I get that these two events are dependent is my equation wrong? AND is this value the probability of their dependency? I appreciate your answer!","['probability-theory', 'intuition', 'probability']"
696500,"If $p$ is a polynomial, then either $\,p(z)=z^n\,$ or $\,\max_{|z|=1}|p(z)|>1$.",Let $p(z)=z^{n}+a_{n-1}z^{n-1}+...+a_{0}$ be a polynomial of degree $n\geq1$. How can you prove that either $p(z)=z^{n}$ or there exists $z'$ with $|z'|=1$ such that $|p(z')|>1$. Maybe we can use the maximum modulus principle and consider $q(z)=z^{n}p(1/z)$.,"['polynomials', 'complex-analysis', 'analysis']"
696506,Computation of fundamental group of pseudo circle,"A common example of a weak homotopy equivalence which isn't symmetric is the pseudo circle $\mathbb{S}$. Wikipedia gives the following map $f\colon S^{1}\rightarrow\mathbb{S}$
$$f(x,y)=\begin{cases}a\quad x<0\\b\quad x>0\\c\quad(x,y)=(0,1)\\d\quad(x,y)=(0,-1)\end{cases}$$ As to why it's a weak homotopy equivalence, Wikipedia says This can be proved using the following observation. Like $S^1$, $\mathbb{S}$ is the union of two contractible open sets $\{a,b,c\}$ and $\{a,b,d\}$ whose intersection $\{a,b\}$ is also the union of two disjoint contractible open sets $\{a\}$ and $\{b\}$. I understand why $f$ is continuous and why the quote is true. I have no idea why the quote shows that the fundamental group of the pseudo circle is infinite cyclic, other homotopy groups are zero, and $f$ induces an isomorphism on fundamental groups. Would you please tell me why?","['general-topology', 'algebraic-topology', 'fundamental-groups']"
696511,Finding the Absolute Maximum and Minimum of a 3D Function,"Find the absolute maximum and minimum values of the function: $$f(x,y)=2x^3+2xy^2-x-y^2$$ on the unit disk $D=\{(x,y):x^2+y^2\leq 1\}$.","['optimization', 'multivariable-calculus']"
696521,Measurable vector bundles trivial,"I hope you can help: If $E$ is a measurable vector bundle over a compact metric space $(X,\mu)$ then there is a subset $Y\subset X$ such that $\mu(Y)=1$ and $\pi ^{-1}(Y)$ is isomorphic to a trivial vector bundle. There is a suggestion that I do not quite understand: Since $\bigcup_{r>0}\partial B(x,r)$ is an uncountable disjoint union, there $r_x>0$ such that: 1- $\mu(\partial B(x,r_x))=0$. 2- $\pi| B(x,r_x)$ is measurably isomorphic to $B(x,r_x)\times \mathbb{R}^{n}$. Thanks for your attention.","['fiber-bundles', 'measure-theory', 'vector-bundles', 'analysis']"
696523,How do they call the topological tensor product that classifies operators from Hilbert space?,"Let $V$ and $W$ be topological vector spaces. There are different ways to complete the tensor product $V \otimes W$, and the only ones that are usually discussed in introductory literature are the injective and projective tensor products of locally convex spaces. The tensor product defined below is very different, and I'd like to know how it is called and where to find information about it. Let $H$ be a Hilbert space, $\varphi: H \to V$ and $\psi: H \to W$ be continuous linear operators, and let $\{e_\alpha\}$ and $\{f_\beta\}$ be two orthonormal bases in $H$. Then formally the following identity should be true: $$ \sum_\alpha \varphi(e_\alpha) \otimes \psi(e_\alpha) = \sum_\beta \varphi(f_\beta) \otimes \psi(f_\beta) $$ The tensor product that I'm talking about is the space of all formal sums $ \sum_\alpha v_\alpha \otimes w_\alpha $, $v_\alpha \in V, w_\alpha \in W$, for which $\varphi(e_\alpha) := v_\alpha, \psi(e_\alpha) := w_\alpha$ extends to continuous operators from Hilbert space, modulo the identity above (and, of course, the obvious relation $\sum_\alpha v_\alpha \otimes 0 + \sum_\alpha 0 \otimes w_\alpha = 0$). The importance of this space stems from the fact that the positive elements of $V \otimes V$ (the ones representable as $\sum v_\alpha \otimes v_\alpha$) are essentially unitary equivalence classes of maps from Hilbert space to $V$, so the topic looks like it should have been studied extensively 50 years ago. What I know so far are just explicit descriptions of this space in several cases ($\ell^2 \otimes \ell^2$, $C \otimes C$ (RKHS theory), $\ell^1 \otimes \ell^1$ (Grothendieck), $L^0 \otimes L^0$, nuclear spaces). What should I google to find a general theory?","['reference-request', 'topological-vector-spaces', 'functional-analysis', 'tensor-products']"
696533,Quasi circle is not contractible,"I'm trying to show that the quasi circle (picture below) doesn't have the homotopy type of a CW complex. I proved that all homotopy groups are zero. Now I need to show that it is not contractible to use Whitehead's theorem. I know that we can collapse the vertical interval to a point to get a circle. Maybe we can use this map to show that the quasi circle is not contractible, but I don't know how. Thanks","['general-topology', 'homotopy-theory', 'algebraic-topology']"
696574,Another Epsilon-N Limit Proof Question,"How to prove the limit of the following sequence using epsilon-N argument. $$a_n=\frac{3n^2+2n+1}{2n^2+n}$$ I took the limit to be $\frac{3}{2}$ and proceeded with the argument, $$\left|\frac{3n^2+2n+1}{2n^2+n}-\frac{3}{2}\right|<\epsilon$$
$$\frac{n+2}{4n^2+2n}<\epsilon$$
How do I complete the argument from this point?","['epsilon-delta', 'sequences-and-series', 'calculus', 'real-analysis', 'limits']"
696578,"How many positive integers n can we make with the digits 3, 3, 4, 5, 5, 6, 7, if the number n > 4, 000, 000?","According to my study guide the answer to the exercise, How many positive integers, (n), can we make with the digits 3, 3, 4, 5, 5, 6, 7, if the number n > 4, 000, 000, : The total of numbers n > 4, 000, 000 is equal to the number of arrangements of 3, 3, 5, 5, 6, 7 of size 6; thus,= $\frac{6!}{2!2!} = 180$. The total of numbers n > 5, 000, 000 is equal to the number of arrangements of 3, 3, 4, 5, 6, 7 of size 6; thus, $ \frac{6!}{2!}= 360$. The total of numbers n > 6, 000, 000 is equal to the number of arrangements
of 3, 3, 4, 5, 5, 7 of size 6; thus, $\frac{6!}{2!2!} = 180$ The total of numbers n > 7, 000, 000 is equal to the number of arrangements of 3, 3, 4, 5, 5, 6 of size 6; thus, $\frac{6!}{2!2!}=180$ The total is 3(180) + 360 = 900. There are a couple of things I don't understand regarding this answer. Why are we getting n > 4,000,000, n > 5,000,000, and so forth? Why are we dropping the 4 from the set of digits when figuring out n > 4,000,000, the 5 from n > 5,000,000, and so on? I thought I would need to use something like: $\frac{n!}{(n-r)!}$ = $\frac{7!}{(7-2)!}$ to get the answer. I have (7-2)! because the number 3 < 4 and therefore cannot make a number > 4,000,000 but, when using all 7 digits the remaining numbers will create numbers > 7. For example, 4,556,733 > 4,000,000 and 5,567,334 > 4,000,000, but 3,345,567 < 4,000,000. I hope I explained this properly. Thanks for any insight. Tony","['permutations', 'self-learning', 'discrete-mathematics']"
696593,Prove the trigonometric identity $\sin^4{x} = \frac{3-4\cos{2x}+\cos{4x}}{8}$,"I need to show the steps to prove this identity:
$$\sin^4{x} = \frac{3-4\cos{2x}+\cos{4x}}{8}$$ I know that $\cos{2x}=\cos^2{x}-\sin^2{x}$. From there I do not know what to do.
The solution should look like: $$\sin^4{x}=sin^4{x}$$ I need to prove the right side equals the left side.",['trigonometry']
696600,Bounding $\sum_{p\leq x} \chi(p )$ for non-principal character $\chi$,"Suppose $\chi$ is a non-principal Dirichlet character mod $k$. Let $A(x)=\sum_{n\leq x} \chi(n)$. Since $\sum_{n\leq k} \chi(n)=0$, we easily get the bound $|A(x)|\leq \varphi(k)$ where $\varphi$ is the Euler totient function. Now let's define $B(x)=\sum_{p\leq x} \chi(p )$ where the sum extends over primes $p\leq x$. What kind of upper bounds do we have on $|B(x)|$? I am looking for any kind of big Oh estimates. I appreciate any help!","['analytic-number-theory', 'number-theory']"
696618,"Prove that $DT = I_v$, $TD \neq I_v$, where $D$ = differentiation operator and $T$ is integration","Let $V$ be the linear space of all real polys $p(x)$. Let $D$ denote the differentiation operator, and let $T$ the integration operator that maps each polynomial $p$ onto the polynomial $q$ given by $q(x) = \int_0^x p(t) dt$. Prove that $DT = I_v$ and $TD \neq I_v$. Describe the null space and range of $TD$. $My$ $Previous$ $work$: $D\int_0^x p(t) dt = D(P(x) -P(0)) = D(P(x)) - D(P(0)) = p(x)$. First, is this correct? It can't be because $p(x)$ can't be $I_v$ (which I take to mean the identity element in $V$). $\int_0^x Dp(t) dt  = \int_0^x p'(t) dt = p(x) - p(0)$. I'm not sure what to do with this? And what is the null space and range of this?","['vector-spaces', 'linear-algebra', 'integration', 'derivatives']"
696621,Differentiable function in n dimensions,"If a function $f:\mathbb R^{n} \rightarrow \mathbb R^m $  is differentiable at a point $a$ can we say that there is a neighbourhood of $a$ such that $f$ is locally Lipschitz? (i.e. 
there is some constant $M < \infty$ such that for all $x$ in that neighbourhood $||f(x)-f(a)|| < M ||x-a||$). I can easily prove this is true when the derivative is bounded but then if it is not bounded could I prove there is some small neighbourhood where the derivative is bounded?","['multivariable-calculus', 'bounded-variation', 'derivatives', 'real-analysis']"
696630,How to evaluate $\int_0^\infty\operatorname{erfc}^n x\ \mathrm dx$?,"Let $\operatorname{erfc}x$ be the complementary error function. I successfully evaluated these integrals:
$$\int_0^\infty\operatorname{erfc}x\ \mathrm dx=\frac1{\sqrt\pi}\tag1$$
$$\int_0^\infty\operatorname{erfc}^2x\ \mathrm dx=\frac{2-\sqrt2}{\sqrt\pi}\tag2$$ (Both $\operatorname{erfc}x$ and $\operatorname{erfc}^{2}x$ have primitive functions in terms of the error function.) But I have problems with
$$\int_0^\infty\operatorname{erfc}^3x\ \mathrm dx\tag3$$
and a general case
$$\int_0^\infty\operatorname{erfc}^n x\ \mathrm dx.\tag4$$
Could you suggest an approach to evaluate them as well?","['calculus', 'integration', 'special-functions', 'definite-integrals', 'error-function']"
696661,Prerequisites for Freedman's proof of the 4-dimensional Poincaré conjecture,"I have a good understanding of differential geometry, enough at least to understand many details of Hamilton & Perelman's approach to the 3-dimensional Poincaré conjecture. I have no such understanding of Freedman's work, not even enough to be able to identify what I don't know. Where can I begin? I understand algebraic topology on about the level of Hatcher (I realize this isn't very much).","['differential-geometry', 'general-topology', 'algebraic-topology', 'reference-request', 'differential-topology']"
696669,Can one show a beginning student how to use the $p$-adics to solve a problem?,"I recently had a discussion about how to teach $p$-adic numbers to high school students. One person mentioned that they found it difficult to get used to $p$-adics because no one told them why the $p$-adics are useful. As a graduate student in algebraic number theory, this question is easy to answer. But I'm wondering if there's a way to answer this question to someone who only knows very basic things about number theory and the $p$-adics. I'm thinking of someone who has learned over the course of a few days what the $p$-adic numbers are, what they look like, etc, but doesn't know much more. I'm specifically wondering if there's any elementary problem that one can solve using $p$-adic numbers. It's okay if the answer is no, and that it takes time to truly motivate them (other than more abstract motivation).","['education', 'p-adic-number-theory', 'number-theory']"
696673,Show that $f(z) = z^2 \overline z$ is not analytical anywhere,"Show that $f(z) = z^2 \overline z$ is not analytical anywhere, i.e. $f(z) = z^2 \overline z$ is non holomorphic anywhere. I think I am supposed to use Cauchy-Riemann equations but not sure how to.",['complex-analysis']
696690,Random walk on $\mathbb{Z}^d$,"Problem Let $\{X_n\}_{n=0}^{\infty}$ be a random walk on $\mathbb{Z}^d$ such that; $X_0=(0,0,\cdots,0)$ and $\{X_n-X_{n-1}\}_{n=1}^{\infty}$ are mutually independent, identitically distributed $\mathbb{Z}^d$-valued random variables(not necessarily nearst neighbor). It's known that: $\exists \: C,c_1, c_2,\cdots, c_d \in \mathbb{R^+\cup{0}} \ \ \ \mbox{with} \ \ \sum_{i=1}^{d}c_i>1 \ \ \ \mbox{s.t.}$
$$ P((X_n)_i=0)\leq C n^{-c_i} \ \ \ \forall n\geq 1$$
Where $(X_n)_i$ is the $i$th coordinate of random variable $X_n$. Prove that the probability coming back to start point is less than $1$, ie. $P(\exists n\geq1 \ \ X_n=0)<1$ What I've done Since Fubini-Tonelli we have: $P(\exists n\geq1 \ \ X_n=0)<1 \Longleftrightarrow E [ \sum \limits_{n=0}^{\infty} \chi_{\{X_n=0\}}] < \infty$ $E [ \sum \limits_{n=0}^{\infty} \chi_{\{X_n=0\}}] =  \sum \limits_{n=0}^{\infty} E[\chi_{\{X_n=0\}}] = \sum \limits_{n=0}^{\infty} P(X_n=0) $ So we have: $P(\exists n\geq1 \ \ X_n=0)<1 \Longleftrightarrow \sum \limits_{n=0}^{\infty} P(X_n=0)<\infty $ So we need a summable upper bound for $P(X_n=0)$. By conditional probability we know: $P(X_n=0)=P((X_n)_1=0,(X_n)_2=0,\cdots,(X_n)_d=0)$ $=P((X_n)_1=0 \ |(X_n)_2=0,\cdots,(X_n)_d=0)\times \\ P((X_n)_2=0 \ |(X_n)_3=0,\cdots,(X_n)_d=0)\times \cdots \times \\ P((X_n)_{d-1}=0 \ |(X_n)_d=0) \times P((X_n)_d=0)$ Trouble: It would be great if following was true for $1\le i \le d-1$: $P((X_n)_i=0 \ |(X_n)_{i+1}=0,\cdots,(X_n)_d=0) < P((X_n)_i=0)$ But is not. Actually right hand side might be also replaced by $K_n P((X_n)_i=0)$, for some suitable $K_n$. However I couldn't find. Could you please help me with this?","['probability-theory', 'random-walk']"
696711,How many points determine a two variable polynomial of degree n+k?,"I am working with sequences and it would be extraordinarily useful to have a two variable version of the following: A degree-$n$ polynomial is uniquely characterized by its values at any $n+1$ distinct points. The polynomial $p(x)$of degree $n$ is determined completely up to a constant factor, by the fundamental theorem of algebra, by exactly $n$ roots. Any other point of $p(x)$ would determine this constant factor. Because of the aforementioned theorem in practice we may not need $d+1$ distinct points, repeated roots would simplify things. I would like to know the answer to the following question(I restrict the question to two-variable polynomials, I am not interested in the general case): Let $P(x,y)$ be a polynomial of degree $n$ in $x$ and $k$ in $y$. The Degree of $P(x,y)$ being $n+k$. How many points will uniquely determine any such polynomial? Any references to books, theorems, articles, papers are welcomed. Thank you.","['sequences-and-series', 'algebra-precalculus', 'analysis']"
696732,Finding the general solution to a system of differential equations,"How can I solve the following system of differential equations? I am getting confused with the constants of integration... $$\dot{x}=2x-(2+y)e^{y}$$ 
$$\dot{y}=-y$$ I know that $y=Ce^{-t}$ and the integrating factor method for solving a linear differential equation, but it gets complicated quickly.","['ordinary-differential-equations', 'systems-of-equations']"
696742,"Prove that for every vector $V$, $||V||_{\infty} \leq ||V||_2 \leq || V||_1$","$\newcommand{\inf}{||V||_\infty}$
$\newcommand{\two}{||V||_2}$
$\newcommand{\one}{||V||_1}$ Prove that for every vector $V$, $\inf \leq \two \leq \one$ I have tried to look online for a solution to this question, but I only have figured out the easy part of it. I know by definition: $\inf = \text{max}|x_i|$ $\two = \displaystyle(\sum_{i=1}^n(x_i^2))^\frac{1}{2}$ $\one = \displaystyle\sum_{i=1}^n|x_i|$ Now, to me, it's obvious why $\inf \leq \one$. If the $\inf$ is the single maximum entry in the vector, and the $\one$ is the sum of all entries in the vector, it's clear that $\one$ contains $\inf$ in its sum. I suppose this logic would hold for why $\inf \leq \two$ also. I'm having a hard time seeing why $\two \leq \one$.","['vector-spaces', 'matrices', 'numerical-methods']"
696825,"Prove that the function $f(x,y) = ax + by$ is onto","I have been thinking about this problem for a while and have gotten stuck. This is a homework question so I just require some hints to push me to the answer. Question:
Let $a, b$ be integers. Consider the following function: $$ f : \mathbb{Z} \space \times \space \mathbb{Z} \rightarrow \mathbb{Z}  $$ such that for any $(x, y) \in \mathbb{Z} \times \mathbb{Z},\space f(x, y) = ax + by. $ Give a simple condition on $a$ and $b$, and then prove the proposition. Proposition 1. The function $f$ is onto if and only if ......... Reasoning: The function needs to cover all the possible coordinates. So we can see that if we let $a = 4, b = 8$ then all the real coordinates are not being covered by $f(x,y) = ax + by$ since all the coordinates are multiples. So $a$ and $b$ cannot be multiples of each other. We can assert this condition by letting $a$ and $b$ be co-primes. So we can say $\gcd(a,b) = 1$. �Attempt: Since this is an if and only if proof, we need to show that: A. If $f$ is onto, then $\gcd(a,b) = 1$. B. If $gcd(a,b) = 1$, then $f$ is onto. Proof of A: 
Lets assume that $f$ is onto. By that assumption we can say that: $\forall \space m \in \mathbb{Z}, \space \exists \space (x,y) \in \mathbb{Z} \space \times \space \mathbb{Z}$, such that $f(x,y) = m$ Let $m = ax + by$ since $ax+by \in \mathbb{Z}$. So from that we have $f(x,y) = ax+by$ More of the proof: Since $f(x,y) = ax+by$ is onto, we know that there must be a point where $ax+by = 1$ (by definition of onto). $$ax + by = 1$$ $$\implies gcd (a,b) = 1$$ Proof of B:
Leb $gcd(a,b) = 1$. From that, we know that $ax+by = 1$. We must show that: $\forall \space ax+by \in \mathbb{Z}, \space \exists \space (x,y) \in \mathbb{Z} \space \times \space \mathbb{Z}$, such that $f(x,y) = ax + by$ �Attempt: Can I say that since $gcd (a,b) = 1$, it always maps to an integer?","['divisibility', 'functions']"
696835,Proving the falsity of the Riemann Hypothesis,"The Riemann Hypothesis is equivalent to the statement: $$|\pi(x)-{\rm li}(x)|\le \frac {1}{8\pi}\sqrt {x}\log (x)\text { for all }x \geq 2657,\text{ (Schoenfeld, 1976)}
$$
Which can be visually represented in the plot: $$\text{with }\frac{1}{8\pi}\sqrt{x}\log(x)-|\text{J}(x)-\text{li}(x)|,\text{ (blue) }\\
\frac{\sqrt{x}}{\log(x)},\text{ (red) }\\
|\pi(x)-\text{J}(x)|,\text{ (yellow) }\\
|\text{J}(x)-\text{li}(x)|,\text{ (green) }\\
\text{where J}(x)=\sum_{n=1}^\infty\frac{\mu(n)}{n}\text{li}(x^{1/n}); 
$$
and on a larger scale: where it is not so difficult to imagine the oscillations crossing the green line eventually (Littlewood, 1914), but requires a leap of faith to say the least, that the oscillations will eventually cross the blue line. I believe I am correct in assuming that it is only the oscillations that are in question here, & not the general asymptotic of $J(x)$, but am willing to be corrected! If the crossing of the oscillations of the green line begin at Skewe's number (whatever the actual value of that is), then if the RH is false, the magnitude of the number at which the oscillations cross the blue line must be significantly larger than that - which, even at the current rate of advances in computing, quantum computers being developed at some point in the future notwithstanding, I find it difficult to believe that the RH will be proven false in my lifetime (I am 37! - not factorial btw). My question is, is the falsity of the RH (a) believable; and (b) ever provable (if, in the unlikely event that it is true) in terms of computing limits? It seems to me, in the spirit of Hardy, to be an analogue of Russell's teapot analogy!","['prime-numbers', 'riemann-hypothesis', 'number-theory']"
696849,Dual space of $l^1$,"I m taking a course in functional analysis. The book state that the dual space of $l^1$ , the set of real valued absolutely summable sequence, is $l^\infty$ . Can anyone explain why the dual space of $l^1$ is $l^\infty$ . I read a proof online http://math.uga.edu/~clayton/courses/608/608_5.pdf ( Wayback Machine , new link ). I don't understand the correspondence between $l^1$ and $l^\infty$ they mentioned. Can some one explain more about this. Thanks","['dual-spaces', 'functional-analysis', 'lp-spaces']"
696869,"Show square matrix, then matrix is invertible","Question:
Show that if a square matrix $A$ satisfies the equation $A^2 + 2A + I = 0$, then $A$ must be invertible. My work: Based on the section I read, I will treat I to be an identity matrix, which is a $1 \times 1$ matrix with a $1$ or as an square matrix with main diagonal is all ones and the rest is zero. I will also treat the $O$ as a zero matrix, which is a matrix with all zeros. So the question wants me to show that the square matrix $A$ will make the following equation true. Okay so I pick $A$ to be $[-1]$, a $1 \times 1$ matrix with a $-1$ inside. This was out of pure luck. This makes $A^2 = [1]$. This makes $2A = [-2]$. The identity matrix is $[1]$. $1 + -2 + 1 = 0$. I satisfied the equation with my choice of $A$ which makes my choice of the matrix $A$ an invertible matrix. I know matrix $A *$ the inverse of $A$ is the identity matrix. $[-1] * inverse = [1]$. So the inverse has to be $[-1]$. So the inverse of $A$ is $A$. It looks right mathematically speaking. Anyone can tell me how they would pick the square matrix A because I pick my matrix out of pure luck?","['matrices', 'linear-algebra']"
696907,Visualizing topology of a Vector Bundle,"I've started reading Milnor, Stasheff - Characteristic Classes and at page $18$ they proved that $\mathbb{R}^n$-bundle $\xi$ is trivial if and only if $\xi$ admits $n$ cross sections $s_1, \dots , s_n$ which are everywhere independent. Inside the proof they define the operator   $$f: B \times \mathbb{R}^n \to E $$ $$ f(b,x) = x_1 s_1(b)+ \cdots + x_n s_n(b) $$ and they claim it is continuous. But my doubt here is: which topology $E$ is equipped with? Looking at the definition of vector bundle $E \to B$ I have: 1) $E$ is a topological space (so I don't know what topology I have) 2) a continuous map $\pi : E \to B$ called the projection (so at least I have all the open of the form $\pi^{-1}(U)$ where $U$ is open in $B$ (which has a fixed topology). 3) each fiber is a vector space and then the conditions of local triviality hold: for each $b \in B$ there exist a neighborhood $U \subset B$, a natural number $n$ and a homeomorphism $$ h: U \times \mathbb{R}^n \to \pi^{-1}(U)$$ so that, for each $b \in B$, the correspondence $x \mapsto h(b,x)$ is an isomorphism between $\mathbb{R}^n$ and the fiber over $b$.he this last property gives me some information about the subspace topology of each $\pi^{-1}(U)$. I think it's not a problem considering $U$ open and so I have a whole new class of open subset in $E$ : every $V$ such that $V=h(A \times B)$ where $A$ and $B$ are respectively open subsets of $B$ and $\mathbb{R}^n$. So is this classification of the topology over E exhaustive? in other terms, these and only these are the open subsets in $E$? other two doubts related to the main question: A) Is the property (in relation to $E$) of being an Hausdorff space dependent on the fact that $B$ is Hausdorff ? (and so without any new information over $B$ we can't say anything?) B) Can someone shows me how to prove (a kind of step by step) the continuity of the function $f$ defined above? so I can understand the basic mechanics of this kind of reasoning. ADDENDUM I write down this kind of proof of the continuity. I can't judge if it is correct or no because I'm not very convicted of it, so please give it a check: Consider $W \subset E$ an open set. So by the discussion above its intersections with open of the form $\pi^{-1}(U)$ with $U$ open in $B$ are homeomorphic to open set of $B \times \mathbb{R}^n$. Consider one of this intersection $\bar{W}$. Then $f^{-1}(\bar{W})$ (I'm using local coordinates) contains elements of the form $(b,v)$ where $b \in B$ and $v$ is the image of the linear map which assign at every n-uple $v_1, \dots , v_n$ $v_1s_1(b)+ \cdots + v_ns_n(b)$ and a linear mapping in a finite dimensional vector space is continuous. So it's pre image is an open set of $\mathbb{R}^n$ and by definition of product topology the pre image of $\bar{W}$ throughout $f$ is an open. It is clear that I'm a novice in this field, (I've started to read this topic after attending a basic course about classical differential geometry which ended with an extremely rapid view over the concepts of vector bundle and vector fields) so I need exhaustive answers without implicit passages (I need to learn those passages, so I must see them at least ) :) thanks in advance","['general-topology', 'vector-bundles', 'algebraic-topology']"
696922,Jacobian criterion for projective varieties,"Let $P\in Y=Z(f_{1},\cdots ,f_{s})$ be a projective variety. Then $Y$ is non singular at $P$ if and only if rank of the matrix $\Vert\partial f_{i}/x_{j}(P)\Vert=n-\dim{Y}$. I know of the statement for affine varieties, and I am trying to prove it for projective varieties. This is what I have so far. If $P\in \mathbb{P}^{n}$ then $P$ is in some open set $U_{i}=\{(a_{0},\cdots ,1,\cdots a_{n})\in\mathbb{P}^{n}\}$ where the $1$ appears in the $i^{th}$ spot. WLOG we may assume $i=0$ is this case. So $X\cap U_{0}$ is an affine variety. Defined by
$$X\cap U_{0}=Z(f_{1}(1,x_{1},\cdots x_{n}),\cdots ,f_{s}(1,x_{1},\cdots x_{n}))$$
Since this is affine we have that $X\cap U_{0}$ is nonsingular iff and only if the jacobian criterion is satisfied. I don't really see where to proceed from here since I don't know how the partials of the dehomoginzed polynomials compares to that of the homogeneous polynomials. Any suggestions would be very appreciated.",['algebraic-geometry']
696932,Prime number that are recursively made up of other prime number -- what is this called,"I've noticed that some prime number are composed entirely of other prime numbers for example -- some have parents on the left hand side (all the numbers below are prime): 59393339
5939333
593933
59393
5939
59
5 Others for example -- some have parents on the right hand side (all the numbers below are prime): 633396997
 33396997
  3396997
   396997
    96997
     6997
      997
       97
        7 Others have parents on both side, for example: 739397 on the right hand side
 39397
  9397
   397
    97
     7

739397 on the left hand side
73939
7393
739
73
7 I'd like to know what these type of Prime numbers are called? Thanks.","['prime-numbers', 'elementary-number-theory', 'number-theory']"
696939,Calculating the second moment of binomial random variable,I don't understand how they got the equality E[Y+1]= np[(n-1)p+1]. https://i.sstatic.net/v9Yxs.jpg,"['statistics', 'probability']"
696964,Selberg's Symmetry Formula,"I'm going through a proof of the Prime Number Theorem and the derivation of Selberg's Symmetry Formula. However, in it there is one step that is perplexing me. Would anyone be able to help explain why this is true? $\displaystyle\sum\limits_{d^{\prime} \leq \frac{x}{d}} log^2(d^{\prime}) = log^2(\frac{x}{d}) - 2xlog(\frac{x}{d}) + 2x + O\left(\displaystyle\sum\limits_{d \leq x} log^2(\frac{x}{d})\right)$ This apparently derives from:
$\displaystyle\sum\limits_{n \leq x} \frac{log(n)}{n} = \frac{1}{2}log^2(x) + C + O\left(\frac{log(x)}{x}\right)$ I don't see how. If I can get this step, then I understand the entire proof which would be awesome! Edit: I can derive the second equation. If possible, I'm after help with the first. Edit 2: After thinking about this for a couple of days, I've just realised an easy explanation and it doesn't require the second formula at all. You can just bound it with integrals of log^2.","['asymptotics', 'number-theory']"
696986,Queuing Theory with Poisson Distribution,"Suppose customers arrive in a one-server queue according to a Poisson distribution with rate lambda=1 (in hours). Suppose that the service times equal 1/4 hour, 1/2 hour, or one hour each with probability 1/3. (a) Assume that the queue is empty and a customer arrives. What is the expected amount of time until that customer leaves? (b) Assume that the queue is empty and a customer arrives. What is the expected amount of time until the queue is empty again? (c) At a large time t what is the probability that there are no customers in the queue? I'm trying to do couple of practice problems involving queuing before my exam and I am really confused, I would really appreciate it if someone can show me how to do this problem. Thanks","['statistics', 'queueing-theory', 'probability', 'statistical-inference']"
696989,How many ways are there to represent a monomial order by term order via matrices?,"During the lecture, my professor brought up a list of project ideas to work on. One of the ideas I am interested and currently working on is term order via matrices. That is: I need to find the number of ways to order $n$-tuples with matrices in any type of orders. Here is the problem: $$\Large\textbf{Problem}$$
Let $>$ be a monomial ordering and $A$ be the following $m$-by-$n$ matrix: $$\begin{pmatrix}
a_{11} & \cdots & a_{1m}\\
\vdots & \ddots & \vdots\\
a_{n1} & \cdots & a_{nm}
\end{pmatrix}$$ such that the integers $m,n > 0$ and $a_{ij} \in \mathbb{R}$ for $1 \leq i \leq n$ and $1 \leq j \leq m$.  Define $>_A$ by $$\overline{a} = (a_1, \dots, a_n) > _A \overline{b} = (b_1, \dots, b_n)\text{ iff }\overline{a}A > \overline{b}A.$$ How many ways are there to represent a monomial order by term order via matrices?  Determine conditions such that $>_A$ defines a monomial ordering. $$\Large\textbf{My Current List of Term Orders Via Matrices}$$ Let $\overline{a} = (a_1, \dots, a_n)$ and $\overline{b} = (b_1, \dots, b_n)$ for each of the following orders.  Here are my results: $$\large\textbf{Lexicographic Order}$$ If $A = I$, then clearly $>_A$ is $>_{\text{lex}}$. $A = (1, \dots, 1)^T$ is the column matrix consisting of $n$ $1$'s, such that $\overline{a}A$ and $\overline{b}A$ exist. Next parts are not easy.  I found few of them. $$\large\textbf{Degree Lexicographic Order}$$ $A$ is the following $n$-by-$m$ matrix:
$$A = \begin{pmatrix}
1 & 1 & \cdots & 1 & 1\\
1 & 0 & 0 & \cdots & 0\\
0 & 1 & 0 & \cdots & 0\\
\vdots & 0 & \ddots & 0 & 0\\
0 & \vdots & 0 & 1 & 0\\
0 & 0 & \vdots & 0 & 1
\end{pmatrix}$$
So if $\overline{a} > \overline{b}$, then $\overline{a}A >_{\text{deglex}} \overline{b}A$. If $A$ is the following square $n$-by-$n$ matrix
$$A = \begin{pmatrix}
1 & 1 & \cdots & 1 & 1\\
1 & 0 & 0 & \cdots & 0\\
0 & 1 & 0 & \cdots & 0\\
\vdots & 0 & \ddots & 0 & 0\\
0 & \cdots & 0 & 1 & 0
\end{pmatrix}$$
then $>_A$ is $>_{\text{deglex}}$ $A = (1, \dots, 1)^T$ might work for this order. $$\large\textbf{Degree Reversed Lexicographic Order}$$
 1. If $A$ is the following $m$-by-$n$ matrix
$$\begin{pmatrix}
1 & 1 & \cdots & 1 & 1\\
0 & 0 & \cdots & 0 & -1\\
0 & \cdots & 0 & -1 & 0\\
\vdots & 0 & \kern3mu\raise1mu{.}\kern3mu\raise6mu{.}\kern3mu\raise12mu{.} & 0 & \vdots\\
0 & -1 & 0 & \vdots & 0\\
-1 & 0 & \cdots & 0 & 0
\end{pmatrix}$$
Then, $>_A$ is $>_{\text{degrev}}$. If $A$ is the following $n$-by-$m$ matrix
$$\begin{pmatrix}
1 & 1 & \cdots & 1 & 1\\
0 & 0 & \cdots & 0 & -1\\
0 & \cdots & 0 & -1 & 0\\
\vdots & 0 & \kern3mu\raise1mu{.}\kern3mu\raise6mu{.}\kern3mu\raise12mu{.} & 0 & \vdots\\
0 & -1 & 0 & \cdots & 0
\end{pmatrix}$$
Then, $>_A$ is also $>_{\text{degrev}}$. I think that $A = (1,\dots,1)^T$ also works for this order. $$\large\textbf{Inverse Lexicographic Order}$$ Same list of term orders via matrices as lexicographic order list. $$\Large\textbf{Results and Thoughts}$$
After hours of investigating the number of ways to represent types of order via matrices, I took down the following conditions I believe may be correct: Given $\overline{a} = (a_1, \dots,a_n)$, in order for $\overline{a}A$ to be defined, we need the row of a matrix $A$ to corresponds with the column of $\overline{a}$. In order to specify the order by matrices, each term in $\overline{a}$ must be multiplied by each nonzero term in the matrix $A$.  Otherwise, the ordering of the tuples is not defined very well.  In other words, for this case, if $\overline{a} >_A \overline{b}$, then we can't conclude that $\overline{a}A > \overline{b}A$ for an ordering $>$. I believe the list of matrix-orderings I have is not enough; there might be more types of matrix-ordering that works for orders, like $\text{lex}$, $\text{deglex}$ and $\text{invlex}$, that I haven't figured out yet. Any comments or thoughts you have for the problem I am working on?  I exhausted lots of tries to determine the number of matrix-orderings.","['matrices', 'groebner-basis', 'commutative-algebra', 'order-theory']"
696996,How to prove infinitely many integer values for a square root equation?,"I have the equation $y = \sqrt{3x^2 + 1}$, and I need to prove that there will be infinitely many integer solutions. I saw possible solutions with things like Pell's equation, but I did not fully understand these methods. It would be awesome if someone could help me out with simpler methods. Thanks, John","['algebra-precalculus', 'functions']"
697000,"Show that if $A$ is invertible and $AB = AC$, then $B = C$.","Question:
Show that if $A$ is invertible and $AB = AC$, then $B = C$. My work:
My thought process: If I can find the inverse of $A$, then I can show A is invertible. I will prove by example.
$A$ is a $2 \times 2$ matrix. first row: 2 3. second row: 4 5. Where $a = 2$, $b = 3$, $c = 4$, $d = 5$ such that $ad - bc$ is not zero. $ad-bc$ or the determinant is $-2$ which is not equal to zero so I know matrix $A$ is invertible. $A$ inverse would be...first row is -5/2 3/2. second row is 2 -1. Matrix $C$ is equal to $A$ inverse or matrix $B$. $A$ inverse and matrix $B$ are the same thing.","['matrices', 'linear-algebra']"
697073,"Chinese Remainder Theorem stuff (but more advanced, certainly derived from)","First, let $m$,$n$ be coprime. Suppose we want to find: $x\equiv y\text{ mod }m$ $x\equiv z\text{ mod }n$ As m,n are coprime $\exists a,b\in\mathbb{Z}:am+bn=1$ (GCD=1 basically) Then, for $y\in\mathbb{Z}$ we have $ybn=y\text{ mod }m$ and $ybn = 0\text{ mod }n$ Then, for $z\in\mathbb{Z}$ we have $zam=z\text{ mod }n$ and $zam = 0\text{ mod }m$ Thus $$ybn+zam\equiv y\text{ mod }m$$
and
$$ybn+zam\equiv z\text{ mod }n$$ I am happy with this, I am them asked to find $x$ where $x\equiv 2\text{ mod }7$ and $x\equiv -2{ mod }11$ this is easy you just choose $y,b,n,z,a,m$ so the forms match, which explains why the first part wanted an explicit solution to $7a+11b=1$ The actual question Part 2 is different, it wants me to give an explicit solution to $$77a+13b=1$$ (easy enough, $a=-1,b=6$ works) and to find $k$ such that: $k\equiv 2\text{ mod }7$ $k\equiv -2\text{ mod }11$ $k\equiv -1\text{ mod }13$ I'm not sure how to do this in the way I'd like to / the question wants, I may not say $k\equiv \text{(something) mod }77$ but 77 is 7*11, and the last part was about a 7 and an 11! How do I do this in the spirit of the question? I have tagged this as ""Abstract algebra"" and ""Ring theory"" because it follows on from some work about defining a bijection from rings that are cyclic groups of coprime orders. I have titled it Chinese Remainder Theorem because that can be phrased to state ""The rings $Z_mXZ_n$ are isomorphic if and only if m, n are coprime"" and then it finds them.","['ring-theory', 'abstract-algebra', 'number-theory']"
697089,Trigonometric Substitution,"I am having trouble with this problem even though everything I did seemed right to me since we went over a similar one in my class. I used the method of setting up a triangle, my hypotenuse is $\sqrt{54+9x^2}$ and my sides are $\sqrt{54}$ and $3x$. I got $\tan(t)=3x/\sqrt{54}$ so $$x=\sqrt{54} \tan(t) \frac{1}{3}$$ which left $$\sec(t) = \frac{\sqrt{54+9x^2}}{\frac{\sqrt{54}}{3}}$$ and then $$\frac{\sqrt{54}}{3} \sec(t) = \sqrt{54+9x^2}.$$ This left me with a simplified $6 \int \sec^3(t) \, dt$. After using the reduction formula my answer was $$3 \tan(t) \sec(t) +3 \ln |\sec(t) + \tan(t)| +C$$ and then I plugged back in with my $x$ values. If anyone can help it would be greatly appreciated!","['trigonometry', 'triangles', 'integration']"
