question_id,title,body,tags
1888930,Is Wolfram Alpha linear independence wrong or am I missing something?,"Maybe it's because you can't ask those questions to wolfram & I should use a matrix instead but when imputting linear independence {$t$, $t^2+1$, $t^2+1-t$} It says the three functions are linearly independent when the third one is clearly a linear combination of the other two. How should I input this to get a valid answer? I wanna check whether or not my results are correct.","['wolfram-alpha', 'linear-algebra', 'functions']"
1888954,Closed form of $\iint_{\mathbb{R}^2} \ln \left(\frac{1}{|x-y|}\right) \frac{4}{(1+|y|^2)^2} dy$,"While reading a paper I stumbled across the integral
$$
\iint_{\mathbb{R}^2} \ln \left(\frac{1}{|x-y|}\right) \frac{4}{(1+|y|^2)^2} d^2y\,,
$$
where $x \in \mathbb{R}^2$ is fixed. I think the paper implicitly claims that this is equal to $-2 \pi \ln (1+|x|^2)$. I'm not sure if this is a hard integral at all, but considering the amount of proficient integrators on this site, I thought that I should post this question here. To provide some context, the term $\ln \frac{1}{|x-y|}$ comes from the Laplacian's Green function (it is the leading term near $x$) and the term $\frac{4}{(1+|y|^2)^2}$ is of course the ""density"" of the stereographic projection metric.","['calculus', 'closed-form', 'integration', 'definite-integrals', 'vector-analysis']"
1889002,Conditional Probability: Two die randomly chosen with red and blue faces,"I have been going through and doing some (non-assessed) homework questions, but am getting really stuck on conditional probability. The following problem is one that I simply cannot get my head around. Question: Die A has four red and two blue faces, and die B has two red and four blue faces. One of the dice is selected at random for use. i). What is the probability of red being thrown? ii). If the first two throws resulted in red, what is the probability of red for the third throw? I was able to get i), no trouble, it came out as 1/2. The second part has me entirely lost though.",['probability']
1889027,What do we intuitively mean by embedding a manifold in an $n$-dimensional space?,"What do we intuitively mean by embedding a manifold in an $n$-dimensional space? Also, why does a circle look so differently when is is embedded in $3$-space than $2$-space?","['manifolds', 'general-topology', 'differential-geometry']"
1889033,Is a cylinder a differentiable manifold?,"First of all! I mean a cylinder with a circle at the top and a circle at the bottom. Not the volume but its surface. Intuition tells me YES. But... How can charts be defined for the points on the edge?
What I thought first is that since a sphere is a differentiable manifold and I could find a bijection projecting the cylinder on a sphere placed in its center (of symmetry) I could extend the properties of the sphere to the cylinder. Now some doubts arise since the metric that I would define on the cylinder would be spherical, while I would expect to get standard euclidean geometry on the flat surfaces.
Anyway, no metric is yet defined on differentiable manifolds and I can imagine to define the metric that best fits after. So Wthout a metric, does the differential manifold structure allows me to distinguish between a cylinder and a sphere? With a metric can I be sure whether my manifold is a cylinder or a sphere or anything else? Where can I get a handy summary on the structure information given by topology, manifold, and metric when I only know some of the three?
thank you in advance","['manifolds', 'general-topology', 'differential-geometry', 'differential-topology']"
1889049,Conjecture: $\pi(x)\ge \pi\circ\pi(x)+\pi\circ\pi\circ\pi(x)+\cdots$,$x\ge 13\implies\pi(x)\ge \pi\circ\pi(x)+\pi\circ\pi\circ\pi(x)+\cdots$ Can this be proved?,"['number-theory', 'inequality', 'prime-numbers']"
1889061,Is there a way to prove continuity without using epsilon-delta?,"I'd like to know if there is an easier way of provining continuity instead of using the epsilon-delta criteria? I cannot understand it because it's way too complicated for me... There is no workaround? Like converting the series to a function, then prove convergence on the function. If the converted function is continuous, the series will be continuous as well. Something like that would be possible? Or there are other ways which are a bit easier? Sorry for asking a question like that but I couldn't find anything on the internet. I really hope there is another way...","['sequences-and-series', 'calculus', 'continuity', 'convergence-divergence', 'analysis']"
1889080,How many nodes in the smallest $k$-dense graph?,"Let's call a directed graph $k$ -dense if: Each node has exactly two children (outgoing neighbors); Each two nodes have at least three different children (besides themselves); Each three nodes have at least four different children (besides themselves); ... Each $k$ nodes have at least $k+1$ different children (besides themselves); What is the smallest number of nodes required for a $k$ -dense graph? Here are some special cases. For $k=1$ , the smallest number of nodes is $3$ : 1->[2,3],   2->[3,1],   3->[1,2] For $k=2$ , the smallest number of nodes is $7$ . To see this we can build the graph greedily based on the following constraint: a node's child must be different than its parent(s) and is sibling(s). Why? Because a node and its parent together must have three children besides themselves. $1$ has two children: call them $2$ and $3$ . $2$ must have two children different than its parent ( $1$ ) and sibling ( $3$ ): call them $4$ and $5$ . $3$ must have two children different than its parent ( $1$ ) and sibling ( $2$ ). The first can be $4$ . Now, $3$ and $2$ together have only two children besides themselves ( $4$ and $5$ ), so $3$ must have another different child - call it $6$ . $4$ must have two children different than its parents ( $2$ and $3$ ) and siblings ( $5$ and $6$ ). The first can be $1$ and the second must be new - call it $7$ . $5$ must have two children different than its parent ( $2$ ) and siblings ( $4$ ). The first can be $1$ . The second cannot be one of $1$ 's children ( $2$ and $3$ ) or siblings ( $7$ ) so it must be $6$ . $6$ must have two children different than its parents ( $3$ and $5$ ) and siblings ( $4$ and $1$ ). These must be $2$ and $7$ . $7$ must have two children different than its parents ( $4$ and $6$ ) and siblings ( $2$ and $1$ ). These must be $3$ and $5$ . All in all, we have the following $2$ -dense graph with $n=7$ nodes: 1->[2,3]  2->[4,5]  3->[4,6]  4->[1,7]  5->[1,6]  6->[2,7]  7->[3,5] For $k=3$ , I used a similar greedy algorithm (with more constraints) to construct the following graph: 1->[2,3]    2->[4,5]    3->[6,7]    4->[6,8]     5->[7,9]
 6->[10,11]  7->[12,13]  8->[1,9]    9->[10,14]  10->[2,12]  
11->[1,13]  12->[8,15]  13->[4,14]  14->[3,15]   15->[5,11] I used a computer program to check all possibilities with at most $14$ nodes, and found none, so (assuming my program is correct) $n=15$ is the minimum number required for $k=3$ . This hints that the minimum number of nodes in a $k$ -dense graph should be: $2^{k+1}-1$ . Is this true? What is the smallest number of nodes required for general $k$ ? UPDATE 1: I have just learned about vertex expansion . It seems closely related but I am still not sure how exactly.","['combinatorics', 'graph-theory', 'directed-graphs']"
1889084,Dirichlet product of distinct prime factors and the Möbius function,"In text book Analytic number theory by Apostol on page $47$, Exercise $5$ we have the following: Define $v(1)=0$, and for $n>1$ let $v(n)$ be the number of distinct prime factors of $n$. Let $f=\mu*v$ and prove that $f(n)$ is either $0$ or $1$. The symbol $*$ is taken as the Dirichlet product. I tried to divide cases into whether $n$ is square free or not. But I can't find anything. Please help me to solve it.","['number-theory', 'analytic-number-theory']"
1889107,Why does universal generalization work? (the rule of inference),"This is an excerpt from Discrete Mathematics. Universal generalization is the rule of inference that states that ∀xP(x) is true, given the premise that P(c) is true for all elements c in the domain. Universal generalization is used when we show that ∀xP(x) is true by taking an arbitrary element c from the domain and showing that P(c) is true. The element c that we select must be an arbitrary, and not a specific, element of the domain. That is, when we assert from ∀xP(x) the existence of an element c in
  the domain, we have no control over c and cannot make any other
  assumptions about c other than it comes from the domain. Universal
  generalization is used implicitly in many proofs in mathematics and is
  seldom mentioned explicitly. However, the error of adding unwarranted
  assumptions about the arbitrary element c when universal
  generalization is used is all too common in incorrect reasoning. I have two questions: 1. What is meant by the second paragraph ? 2. How come just by taking arbitrary c in domain, we can conclude that if P(c) is true then so is ∀xP(x). (There may exist some counterexamples).","['intuition', 'quantifiers', 'discrete-mathematics']"
1889109,An integral: magnetic fied of infinite wire,"Let $\boldsymbol{l}:\mathbb{R}\to\mathbb{R}^3$ be the piecewise smooth parametrization of an infinitely long curve $\gamma$. Let us define$$\boldsymbol{B}(\boldsymbol{x})=\int_\gamma\frac{d\boldsymbol{l}\times(\boldsymbol{x}-\boldsymbol{l})}{\|\boldsymbol{x}-\boldsymbol{l}\|^3}=\int_{-\infty}^{+\infty}\frac{\boldsymbol{l}'(t)\times(\boldsymbol{x}-\boldsymbol{l}(t))}{\|\boldsymbol{x}-\boldsymbol{l}(t)\|^3}dt.$$A physical interpretation of the integral is that $\boldsymbol{B}$ represents the magnetic field generated by an infinitely long wire $\gamma$ carrying a current $I$ such that $\mu_0 I=4\pi$ (where $\mu_0$ is vacuum permeabilty). Can we be sure that the integral converges and, if we can, how can it be proved? I think that the best way to approach the problem is verifying whether the integral converges as a Lebesgue integral, which is equivalent to verifying whether the integral of the absolute value of the integrand converges, and I notice that every component of the integral is the difference of two terms having the form $l_i'(t)(x_j-l_i(t))\|\boldsymbol{x}-\boldsymbol{l}(t)\|^{-3}$. I see that $|l_i'(t)(x_j-l_i(t))|\|\boldsymbol{x}-\boldsymbol{l}(t)\|^{-3}$ $\le |l_i'(t)||x_j-l_i(t)|^{-2}$, but the absolute value does not allow me to use the rule $l_i'(t)dt=dl_i$...","['multivariable-calculus', 'physics', 'improper-integrals', 'lebesgue-integral']"
1889153,Reciprocal of a normal variable with non-zero mean and small variance,"$X$ is a normal random variable: $$X \sim \mathcal{N}(\mu,\sigma^2)$$ Then $Y = 1/X$ has the following probability density function (see wiki ): $$f(y) = \frac{1}{y^2\sqrt{2\sigma^2\pi}}\, \exp\left(-\frac{(\frac{1}{y} - \mu)^2}{2 \sigma^2}\right)$$ This distribution of $Y$ does not have moments since ( stackExchange ): $$\int_{-\infty}^{+\infty}|x|f(x)\,dx = \infty$$ An intuitive explanation of this is that the distributions tails are too heavy and consequently the law of large number fails. The more samples that are drawn and averaged the less stable this average is. The non-zero probability density that $X = 0$ means that $Y$ will not have finite moments since there is a non-zero probability that $Y = \infty$. However in simulation for a non-zero mean and small variance $X \sim \mathcal{N}(1,0.1)$ the distribution of $Y$ is seemingly well-behaved with $E[Y] = 0.1010$ and $\text{Var}(Y) = 0.0109$. However theoretically these moments are not finite. As the variance of $X$ increases the mean and variance of $Y$ become both larger and increasingly unstable. As the variance of $X$ continues to increase the moments of $Y$ become increasingly unstable as the number of samples of $Y$ increases. This is contrary to the typical expectation that the variance of the mean estimate should decrease as the number of samples increases. Could you offer any insights into this strange behaviour? Why did the moments of $Y$ appear stable for $X \sim \mathcal{N}(1,0.1)$?","['means', 'simulation', 'probability-distributions', 'probability', 'inverse']"
1889165,Unconstrained quadratic programming problem with positive semidefinite matrix,"I want to find $x\in\mathbb{R^n}$, where $x$ minimizes $$f(x) = \frac{1}{2}x^TA x + b^Tx$$ There are no constraints. I do know that $A$ is symmetric positive semidefinite, and $f(x) \ge 0$ for all $x$. If $A$ is invertible, then the problem is easy, but I am interested in a general solution that handles the case where $A$ is singular. If the solution is not unique, that's ok. I just need any solution, but preferably a sparse one. Through some reading, it looks like the pseudoinverse obtained via SVD would give a solution, but I haven't seen much theory about that. Would that work? And if it does, can I get a proof? Or is there another way to do this? Edit: forgot to mention that $A$ is symmetric","['optimization', 'quadratic-programming', 'convex-optimization', 'positive-semidefinite', 'linear-algebra']"
1889173,Point that divides a quadrilateral into four quadrilaterals of equal area,"Consider an irregular quadrilateral $ABCD$. Let $E,F,G,H$ be the midpoints of its edges. It seems that there is a point $K$ such that
$$
S_{AHKE} = S_{EKFB} = S_{KHDG} = S_{KGCF} \left(= \frac{1}{4} S_{ABCD}\right)
$$
I'm curious whether the point $K$ has any other interesting properties. Here's the proof that this point does exist:
Assuming that $A,B,C,D,I$ have coordinates $\mathbf p_1, \mathbf p_2, \mathbf p_3, \mathbf p_4, \mathbf p$, respectively. Then
$$
\mathbf S_{AHKE} = \frac{1}{2} (\mathbf p - \mathbf p_1) \times \frac{\mathbf p_2 - \mathbf p_4}{2} = \frac{1}{4} (\mathbf p - \mathbf p_1) \times (\mathbf p_2 - \mathbf p_4)\\
\mathbf S_{EKFB} = \frac{1}{4} (\mathbf p_3 - \mathbf p_1) \times (\mathbf p_2 - \mathbf p) = \frac{1}{4} (\mathbf p - \mathbf p_2) \times (\mathbf p_3 - \mathbf p_1)\\
\mathbf S_{KHDG} = \frac{1}{4} (\mathbf p_3 - \mathbf p_1) \times (\mathbf p - \mathbf p_4) = \frac{1}{4} (\mathbf p_4 - \mathbf p) \times (\mathbf p_3 - \mathbf p_1)\\
\mathbf S_{KGCF} = \frac{1}{4} (\mathbf p_3 - \mathbf p) \times (\mathbf p_2 - \mathbf p_4)
$$
It is easy to see that 
$$
\mathbf S_{AHKE} + \mathbf S_{KGCF} = \frac{1}{2} \mathbf S_{ABCD}\\
\mathbf S_{EKFB} + \mathbf S_{KHDG} = \frac{1}{2} \mathbf S_{ABCD}
$$
thus there is exactly two linear equations
$$
\mathbf S_{AHKE} - \mathbf S_{KGCF} = 0\\
\mathbf S_{EKFB} - \mathbf S_{KHDG} = 0
$$
to determine two components of $\mathbf p$. And they are
$$
(2\mathbf p - \mathbf p_1 - \mathbf p_3) \times (\mathbf p_2 - \mathbf p_4) = 0\\
(2\mathbf p - \mathbf p_2 - \mathbf p_4) \times (\mathbf p_3 - \mathbf p_1) = 0
$$
which is equivalent to 
$$
\mathbf p = \frac{\mathbf p_1 + \mathbf p_3}{2} + \lambda(\mathbf p_2 - \mathbf p_4) = \frac{\mathbf p_2 + \mathbf p_4}{2} + \mu(\mathbf p_3 - \mathbf p_1), \quad \lambda,\mu \in \mathbb R
$$
The geometrical definition of $K$ should be obvious now: the point $K$ is reflection of diagonal intersection point $M = AC \cap BD$ about the vertices' centroid $P$","['quadrilateral', 'area', 'centroid', 'geometry']"
1889181,True or false: Every Field is a UFD.,"I need to check true or false of the above statement. But unfortunately I haven't found any counter example yet. So if the statement is false, can anyone one give me a counterexample or if it is true, just give me a hint to prove it. I know that $F[x]$ is a PID if and only if $F$ is a field. And every PID is an UFD. Please help me. Thanks.","['abstract-algebra', 'unique-factorization-domains']"
1889187,Open subscheme of an irreducible component remains open?,"Let $X$ be a scheme (e.g. of finite type over $\mathbb C$, but it does not matter) and let $Z\subset X$ be an irreducible component of $X$. Suppose we have an open subscheme $U\subset Z$. How to characterize when $U$ will still be open in $X$? The answer is always if the irreducible components are the connected components of $X$, which happens for regular schemes.
If two irreducible components meet (hence $X$ is not regular), 
I did some examples (so I know the answer is not always ), but still I cannot figure out a pattern. However, I feel this should be well established. Thanks for any help.",['algebraic-geometry']
1889201,Whether there is a Riemannian metric on $S^2\times S^2$ with positive scalar curvature?,"Whether there is a Riemannian metric on $S^2\times S^2$ with positive scalar curvature ? If there is a such metric, how make the section curvature is positive under some suitable flow ?","['riemannian-geometry', 'partial-differential-equations', 'ricci-flow', 'curvature', 'differential-geometry']"
1889230,"$X,Y$ be NLS , $T:X \to Y$ be a linear map such that $T^{-1}(\{y\})$ is closed for every $y \in Y$ and $T$ has closed graph , then is $T$ continuous?","Let $X,Y$ be NLS , $T:X \to Y$ be a linear map such that $T^{-1}(\{y\})$ is closed for every $y \in Y$ and $T$ has closed graph , then is it true that $T$ is continuous ? I know that the statement is true if $Y$ is finite dimensional because in that case $\ker T$ closed implies continuity of $T$  , and I also know that if $X,Y$ are Banach spaces then it is true by closed graph theorem . But I don't know what happens in general  . Since $T$ has closed graph , I know that $T$ maps compact sets to closed sets ; for general metric spaces I know that a function having closed graph and carrying compact sets to ""compact ""sets must be continuous , so it seems we are very close . Though for $\mathbb R$ and only maps ( not linear ) the statement is false as can be seen from $f : \mathbb R \to \mathbb R$ as $f(x)=1/x , \forall  x\ne 0 ; f(0)=0$","['normed-spaces', 'functional-analysis', 'continuity', 'linear-transformations', 'metric-spaces']"
1889253,Integral trigonometry,"$\int\sin3x\sin^2x\,dx$ $=\int \sin3x \frac{(1-cos2x)}{2}dx$ $=\frac{1}{2}(\int \sin 3x dx - \int \sin 3x \cos 2x dx)$ $I=\frac{-1}{2}\frac{1}{3}cos 3x-1/4(\int \sin 5x dx+ \int \sin x dx)$ So my question is how do i get from: $\int \sin (3x)\cos (2x) dx$   to $\frac{1}{2}(\int \sin (5x) dx+ \int \sin (x) dx)$ Thanks for fast answer i solved it.",['trigonometry']
1889284,For the following function decide for which numbers $a$ the limit $\lim_{x\to a}f(x)$ exists:,"For the following function decide for which numbers $a$ the limit $$\lim_{x\to a}f(x)$$ exists: $$f(x) = \text{1st number in decimal expansion of } x $$ the solution says that all $a$ not of the form $$n + \frac{k}{10}$$ for integers  $n$ and $k$ can work. I'm trying to reconcile this notion. I personally thought that all values of $a$ would be fine, but are we just taking into consideration all values except for $a$ itself? I mean all values that approach $a$? But with that being the idea, every value can have a decimal representation which would make it difficult for the limit to exist....","['calculus', 'limits']"
1889318,Moments of uncorrelated random variables,"Let $X$, $Y$ and $Z$ be three pairwise uncorrelated random variables
with $E\left(X\right)=E\left(Y\right)=E\left(Z\right)=0$, $Var\left(X\right)=Var\left(Y\right)=Var\left(Z\right)=1.$ Is it true that $E\left[XY^{2}\right]=0$ and $E\left[XZY^{2}\right]=0?$
I don't know where to start.What kind of results do I need to show this? What are the minimal assumptions we need in order to make the statements true? ? Thank you","['probability-theory', 'probability', 'statistics']"
1889331,Four-Dogs Pursuit [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Four dogs start at the corners of square $ABCD$ (labelled anti-clockwise). Running anti-clockwise, the dog starting at $A$ pursues the dog starting at $B$ , which pursues the dog starting at $C$ , which pursues the dog starting at $D$ , which pursues the dog starting at $A$ . They run at the constant speed of $7$ meters per second and the sides of the square are $30$ meters long. The pursuit stops when at least one dog has reached the centre of the square. Use a system of ordinary differential equations to model the
trajectories of the dogs. Make a plot of the paths followed by the dogs. Determine how long the pursuit lasts.","['ordinary-differential-equations', 'differential-games']"
1889339,Show $f$ is differentiable at $x=1$.,"Let $f$ be a real valued continuous function on the interval $[0,2]$ which is differentiable at all points except $1$.Also $\lim f^{'}(x)=5$ .Show $f$ is differentiable at $x=1$. My effort : Consider $h\neq 0$ very small.Then $f$ is differentiable at $1+h$. By definition of derivative $f^{'}(1+h)=\lim _{h_1\to 0}\dfrac{f(1+h+h_1)-f(1+h)}{h_1}\rightarrow (1)$ Also $\lim _{x\to 1}f^{'}(x)=5\implies \lim_{h\to 0}f^{'}(1+h)=5\rightarrow (2)$ Now putting $(2)$ in $(1)$ we have $\lim_{h\to 0}\lim _{h_1\to 0}\dfrac{f(1+h+h_1)-f(1+h)}{h_1}=5$ $\hspace{45mm}\implies $$\lim_{h_1\to 0}\lim _{h\to 0}\dfrac{f(1+h+h_1)-f(1+h)}{h_1}=5$ As $f$ is continuous ;$\lim_{h_1\to 0}\dfrac{f(1+h_1)-f(1)}{h_1}=5$ Similarly we have $\lim_{h_1\to 0}\dfrac{f(1)-f(1-h_1)}{h_1}=5$ Thus $f$ is differentiable at $x=1$ Is it right?Please check and suggest required edits","['derivatives', 'real-analysis', 'limits']"
1889368,Describe all metric spaces whose completions are compact.,"So, I'm basically being asked to prove the following Theorem: A metric space is totally bounded if and only if its completion is compact. Here is the definition of completion: A completion of a metric space $(X,d)$ is a pair consisting of a complete metric space $(X^{*},d^{*})$ and an isometry $\phi :X\rightarrow X^{*}$ such that $\phi (X)$ is dense in $X^{*}$. Proof. $(\Rightarrow )$ Suppose a metric space $(X,d)$ is totally bounded, then so is its completion.  So, the completion is a totally bounded, complete metric space.  (A metric space is totally bounded and complete if and only if it is compact.) Hence, the completion is compact. $(\Leftarrow )$ Suppse the completion is compact.   (A metric space is totally bounded and complete if and only if it is compact.) Then it is totally bounded and so are its subsets.  So, the metric space is totally bounded. Can someone explain to me further why we have that if a metric space is totally bounded, then so is its completion?  I'm not quite understanding why this is true.","['complete-spaces', 'general-topology', 'metric-spaces']"
1889374,Proof that the conjugacy class association scheme is an association scheme,"I was looking at the conjugacy class association scheme (where, given some group $G$, each conjugacy class $C_i$ gets a relation $R_i$, where $R_i=\{(x,y)|xy^{-1}\in C_i\}$), and trying to show that it's an association scheme. Defining a set $S_{ij}^k(x,y)=\{g\in G|(x,g)\in R_i,(g,y)\in R_j\}$, one needs to show that $\vert S_{ij}^k(x,y)\vert=\vert S_{ij}^k(z,w)\vert$ for all pairs $(x,y),(z,w)\in R_k$. The approach that I've seen is that, for any $h\in G$, $(xh,yh)\in R_k$, so that if $g$ is such that $(x,g)\in R_i,(g,y)\in R_j$, then $(xh,gh)\in R_i,(gh,yh)\in R_j$. This gives a bijection between $S_{ij}^k(x,y)$ and $S_{ij}^k(xh,yh)$, so for all such pairs in $R_k$, the cardinality of $S_{ij}^k$ is the same. But if the size of the conjugacy class is more than one, there will definitely be some $y'\neq y$ such that $(x,y')\in R_k$, and then there is no $h$ such that $(xh,yh)=(x,y')$. So how can I show that $\vert S_{ij}^k(x,y)\vert=\vert S_{ij}^k(x,y')\vert$?","['combinatorial-designs', 'association-schemes', 'group-theory']"
1889384,Does finite variance imply on a finite mean?,"Assume that a random variable has a finite variance. Does it mean it also has a finite mean? My approach: I think since it has a finite variance, it means it is in $\mathcal{L}_2$ space of the probability measure $\mu$. Therefore, it should be in $\mathcal{L}_1$ space of the probability measure $\mu$ and thus the mean is finite. IS that correct?","['stochastic-processes', 'probability-theory', 'probability-distributions', 'probability', 'stochastic-calculus']"
1889389,Bridge probability question,"Standard 52-card deck:
  suits: clubs (♣), diamonds (♦), hearts (♥) and spades (♠)
  each suit possible cards and their values being:A,2,3,4,5,6,7,8,9,10,J,Q,k

now 4 men pick the deck in turn. pick one card each time.
at last each one has 13 cards in hand.

The probability question is 
  <1> what is the probability for at least one men hold 13 cards of same suit.
  <2> what is the probability for only the first man hold 13 cards of same suit I think the 1> in halfway and stuck there:
     4 *  13! * 39! / 52!, but this number is not the result, I think it still need to be divided by a number, I think the number is just the ways of allocating 13 same balls to 52 boxes.","['probability', 'card-games']"
1889397,Simplifying $\big(\sum_{i=0}^n\binom{k}{i}\binom{M-k}{n-i}\frac{k-i}{M-n}\big)/{\binom{M}{n}}$,"Show that 
  $$\frac{\sum_{i=0}^n\binom{k}{i}\binom{M-k}{n-i}\frac{k-i}{M-n}}{\binom{M}{n}}=\frac{k}{M},$$ where $M-k>n$ and $k>n$ From Vandermonde's identity, I get $\sum_{i=0}^n\binom{k}{i}\binom{M-k}{n-i}=\binom{M}{n}$. But what about the sum of the product in the numerator? Any hint will be helpful.","['combinatorics', 'binomial-coefficients', 'probability-distributions']"
1889401,Extending 'Guess 2/3 of the Average' Game,"In game theory, 'Guess $\frac{2}3$ of the Average' is a game where $n$ people are asked to choose a real number between $0$ and $100$ inclusive. The person with the closest answer to $\frac{2}3$ of the average value wins. It can be shown that there is a unique pure strategy Nash equilibrium where everyone picks the number $0$. (The reasoning is that the desired number can't be greater than $\frac{2}3 \cdot 100$ so everyone picks between $0$ and $\frac{2}3 \cdot 100$. Then iterate.) Can we generalize this game. Specifically, say that you survey $n$ people who each pick a real number from a set $S \subset \mathbb{R}$. From their responses, you can form a vector $\vec{v}$ where the $i$ th entry is the $i$ th person's response. Now suppose you have function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ that is known to all of the $n$ people. The person whose value is closest to $f(\vec{v})$ is the winner. What strategy should each of the $n$ people employ? Can we find essentially different functions and sets such that everyone ends up guessing the same number? For example, we could have chosen a different fraction $< 1$ rather than $\frac{2}3$ but in spirit, this is the same example. There are also examples of functions and sets where everyone does not end up picking the same answer. For example, if we restrict the people in our example above to choose only integers, then the strategy is pick $1$ or $0$ depending on what you think the majority of the people will pick.","['game-theory', 'functions', 'limits']"
1889423,Calculating the scale factor to resize a polygon to a specific size,"For some graphics programming I am doing, I am trying to scale a polygon so it has a specific area. The reason I am doing this is because I know the shape of something like the outline of a room, but I need to know what the position of each point would be if it were of a certain size in square meters. For example: As you can see, I am scaling the polygon so that it retains the same shape, but it has a different area. I have searched for solutions to this problem, but most results appear to be unrelated; they are usually either about scaling a polygon by a scale factor or calculating the area of a polygon. I don't know if there is a specific name for this process; I know for vectors you often normalize the vector and then multiply them by the desired length, but searching for how to normalize polygons doesn't seem to get results either. I have considered using a scaling method as described in this post to get the resulting polygon. However, while I know the coordinates of every point $p_i$ in the polygon as well as its area $A$, I do not know how to calculate the scale factor $\alpha$ to scale the points with to get the desired area $A'$. How do I calculate the scale factor $\alpha$ that will scale a polygon to the desired area of $A'$? Is there a different approach that will solve my problem?","['area', 'polygons', 'geometry']"
1889430,Lusternik-Schnirelmann category: nullhomotopic inclusion vs. contractible,"The Lusternik-Schnirelmann category of a topological space $X$ is the smallest integer $k$ (if it exists) such that there is an open cover $\{U_0, \dots, U_k\}$ of $X$ such that each inclusion map $U_i \hookrightarrow X$ is nullhomotopic; we denote this by $LS(X) = k$. If no such integer exists, we write $LS(X) = \infty$. It should be noted that some references (e.g. Wikipedia ) use a different normalisation which differs from the above by one. The Lusternik-Schnirelmann category is a homotopy invariant which enjoys has several nice properties, making it an interesting invariant to study. I wonder, however, whether there is any difference between using an open cover by sets where the inclusions are nullhomotopic (sets which are sometimes called 'contractible in $X$') and using an open cover by contractible sets. Define the alternative Lusternik-Schnirelmann category of a topological space $X$ to be the smallest integer $k$ (if it exists) such that there is an open cover $\{U_0, \dots, U_k\}$ of $X$ such that each $U_i$ is contractible; we denote this by $LS'(X) = k$. If no such integer exists, we write $LS'(X) = \infty$. Question 1: Is $LS'(X)$ a homotopy invariant? If $LS'(X)$ is a homotopy invariant, we can compare the invariants $LS(X)$ and $LS'(X)$. If $U \subseteq X$ is contractible, the inclusion $U \hookrightarrow X$ is nullhomotopic, so it follows that $LS(X) \leq LS'(X)$. Question 2: Is $LS(X) = LS'(X)$?","['algebraic-topology', 'general-topology']"
1889441,Integral $\int_{0}^{1} \frac{\ln^2 x \ln^2 (1+x)\ln^2(1-x)}{x^2}dx$,"Due to curiosity and also since I evaluated lower degree sums like these but this one is too hard to manipulate I am eager to know does this have a closed form ? I broke it into the series $\displaystyle \sum_{m,n\ge 1}(-1)^{m+n}\frac{{\rm H}_m{\rm H}_n}{(m+1)(n+1)} \frac{2}{(2n-1)^3} $ , but does this help ?","['summation', 'integration', 'definite-integrals']"
1889443,"Prove that if integral of a squared function is zero, then function is zero function","I almost got this proof done but I can't seem to justify a little step. It goes: Let $f$ be a real-valued, continuous function on $[a,b]$. Prove that if $$\int_a^b [f(x)]²\ dx = 0$$ then $$f(x)=0 \,\,\,\,\,\,\,\,\forall x \in [a,b]$$ I start by defining $$F(x) = \int_a^x [f(t)]²\ dt $$ Since $f$ is continuous, then $F'(x)=[f(x)]²\ge0 \;\;\;\;\; \forall x \in [a,b]$. Thus $F$ is increasing in $[a,b]$. It's clear that $F(a)=0$ and by hypothesis $F(b)=0$. If I could justify why this means that $F$ must be a constant function in $[a,b]$ then my proof would be completed, since that would mean $F'(x)=0\;\;\forall x\in[a,b]$ and therefore $f(x)=0\;\;\forall x\in[a,b]$. Could anyone please tell me if there's a theorem or anything that would let me justify the key step???","['integration', 'definite-integrals', 'calculus', 'functions']"
1889450,Extrema of ellipse from parametric form,"I'm trying to derive a formula to determine a tight bounding box for an ellipse. This is trivial for non-rotated ellipses, but I'm having trouble figuring out how to compute bounds for ellipses that have been rotated about their center. Consider an ellipse $E$ centered at the origin with $x$ and $y$ radii $r_x$ and $r_y$ respectively. Then a point on $E$ is given by the parametric coordinate pair $\left[\begin{matrix}r_x \cos t \\ r_y \sin t\end{matrix}\right]$ for $t \in [0, 2\pi]$. Suppose we rotate $E$ about the origin by $\theta$ radians. Then a point on $E$ has the coordinates $$\left[ \begin{matrix} x(t) \\ y(t) \end{matrix} \right] = \left[\begin{matrix}r_x \cos \theta \cos t - r_y \sin \theta \sin t \\ r_x \sin \theta \cos t + r_y \cos \theta \sin t \end{matrix}\right]$$ My approach to determine extrema was to consider each coordinate separately, take the derivative and set it equal to zero. For instance, we have $$x'(t) = -r_x \cos \theta \sin t - r_y \sin \theta \cos t$$
and setting $x'(t) = 0$ yields: $$
\begin{align}
-r_x \cos \theta \sin t - r_y \sin \theta \cos t &= 0 \\
-r_x \cos \theta \sin t &= r_y \sin \theta \cos t \\
\tan t &= -\frac{r_y \sin \theta}{r_x \cos \theta}
\end{align}
$$ I don't know how to go from this equation to the actual extreme values of $x$ for the rotated ellipse. I'm assuming it's something easy that I've just forgotten how to do. Edit: I'm looking for tight axis-aligned bounds. Rotating the bounds of a non-rotated ellipse and then computing axis-aligned bounds of the rotated bounding box doesn't result in tight bounds. Here is a diagram to illustrate:","['trigonometry', 'calculus', 'geometry']"
1889459,How to plot $x^{2}=y^{2}-z^{2}$?,I have plotted this equation $x^{2}=y^{2}-z^{2}$ using Wolfram|Alpha and I got this graph: I have made these changes to the equation: First equation solution: $y=-\sqrt{y^{2}-x^{2}}$ Second equation solution: $y=\sqrt{y^{2}-x^{2}}$ I want to make this by hand. How do I can do it? Which coordinate system I need to use to graph it?,['multivariable-calculus']
1889460,Find $x$ and $y$ where $20!=\overline{24329020081766xy\dots}$,"Find $x$ and $y$ where $20!=\overline{24329020081766xy\dots}$(without using calculator.) My attempt :I first find how many zeroes does it have:
$$\left\lfloor {\frac{20}{5}} \right\rfloor=4.$$ It can be solved easily if we know that after $y$ there are only three digits then we can know: 
$$y=0.$$ Then $\overline {6x}$ is divisible by $4$ which gives us:
$$x=4\ \ \ \text{ or }x=8.$$ Then if we check divisiblity role of $8$ we will get that $\overline {66x}$ is divisible by $8$ that tells to us $x$ can only be $4$. Thus
$$x=4.$$ But know the biggest problem is that we don't know how many digits are there after $y$. Or in a bigger amount how many digits are there in $20!$. Thanks.","['calculus', 'elementary-number-theory']"
1889478,"Given $\tan a = \frac{1}{7}$ and $\sin b = \frac{1}{\sqrt{10}}$, show $a+2b = \frac{\pi}{4}$.","Given
  $$\tan a = \frac{1}{7} \qquad\text{and}\qquad \sin b = \frac{1}{\sqrt{10}}$$
  $$a,b \in (0,\frac{\pi}{2})$$
  Show that $$a+2b=\frac{\pi}{4}$$ Does exist any faster method of proving that, other than expanding $\sin{(a+2b)}$? Thank You!",['trigonometry']
1889537,Prove for non-zero $a_k$ satisfying $\sum a_k=0$ there exists a permutation such that $a_1a_2+a_2a_3+a_3a_4+\cdots+a_{n-1}a_{n}+a_{n}a_1 \lt 0$.,"Let $b_1,b_2,\dots,b_n$ denote non-zero real numbers satisfying $\sum_{i=1}^n {b_i}=0$ . Prove that there exists a permutation $ a_1,a_2,\dots,a_n$ of these numbers such that $a_1a_2+a_2a_3+a_3a_4+\cdots+a_{n-1}a_{n}+a_{n}a_1 \lt 0$ . I'm very grateful for your guidance in solving this problem.","['combinatorics', 'calculus', 'discrete-mathematics']"
1889560,Intuition for curvature in Riemannian geometry,"Studying the various notion of curvature, I have not been able to get the intuition and deeper understanding beyond their definitions. Let me first give the definitions I know. Throughout, I will consider a $m-$dimensional Riemannian manifold $(M,g)$ equipped with Levi-Civita connection $\nabla$. We have defined Riemannian curvature tensor to be the collection of trilinear maps $$R_p:T_pM \times T_pM \times T_pM \to T_pM, \ (u,v,w)\mapsto R(X,Y)Z(p), \quad p\in M$$ 
where $X,Y,Z$ are vector fields defined on some neighbourhood of $p$ with $X(p)=u,Y(p)=v,Z(p)=w$, and $R(X,Y)Z:=\nabla_Y\nabla_XZ-\nabla_X\nabla_YZ+\nabla_{[X,Y]}Z.$ This seems to be a purely algebraic defintion; I don't see any geometry here. Second is the sectional curvature. For $p \in M$, let us take a two-dimensional subspace $E \leq T_pM.$ Suppose $(u,v)$ be the basis of $E$. We then define the sectional curvature $K(E)$ of $M$ at $p$ with respect to $E$ as $$K(E)=K(u,v):=\frac{\langle R(u,v)v,u\rangle}{\langle u,u\rangle\langle v,v\rangle-\langle u,v\rangle^2}.$$ 
Third is the Ricci curvature. Let $p\in M$ and $x\in T_pM$ be a unit vector. Let $(z_1,\cdots,z_m)$ be an orthonormal basis of $T_pM$ s.t. $z_m=x.$ The Ricci curvature of $M$ at $p$ with respect of $x$ is $$Ric_p(x):=\frac{1}{m-1}\sum_{i=1}^{m-1}K(x,z_i)$$ where $K(x,z_i)$ is the sectional curvature defined above. Finally the scalar curvature of $M$ at $p$ is defined to be $$K(p):=\frac{1}{m}\sum_{i=1}^m Ric_p(z_i).$$ My questions are about understanding these four notions beyond the defintions. How should I think of each of them? Are they related to one another in a sense that is one notion of curvature stronger than another? I am sorry if these questions are too much for one post.","['general-relativity', 'riemannian-geometry', 'differential-geometry', 'curvature']"
1889569,Is there a good notion of an étale topos associated to a noncommutative ring?,"The title of my question basically sums up what I wish to know. I'm looking into trying to generalize étale cohomology to noncommutative rings (without having to go through some sort of De Rham or motivic cohomology theory) by trying to find what a good candidate for an étale topos of a noncommutative ring might be. I'm most interested in any references to what people have tried in the past, as nLab states that people have tried to look at such a topos in the past, but gives no references for me to chase down and learn from. Here is where I have gotten so far: While we may want to look at algebras over a noncommutative ring $R$ with unit as objects in the coslice category $R/\mathbf{Ring}$ (as the category of unital algebras over a commutative ring $A$ may be identified with the coslice categories $A/\mathbf{Ring}$ or $A/\mathbf{Cring}$ depending on one's taste for commutativity), and while we certainly have a natural analogue of finite generation of an algebra $R \xrightarrow{f} S$ over $R$, what I wish to know is primarily if there has been any work in looking at lifting properties and extensions. In particular, for commutative algebras $A \xrightarrow{f} B$ over a commutative ring with unit $A$, $B$ is étale over $A$ if and only if $B$ is finitely generated over $A$ and for any algebra $A \xrightarrow{g} C$ with $N \trianglelefteq C$ nilpotent, there exists a unique $h:B \to C/N$ making the diagram
$$
\begin{array}
s & A & \xrightarrow{f} & B \\
 & g\downarrow & & \downarrow\exists!h \\
 & C & \xrightarrow{\pi_N} & C/N
\end{array}
$$
commute. This gives many important geometric properties, as étale maps are stable under base change, they allow a descent theory, and localizations give an étale map $A \xrightarrow{\lambda_S} S^{-1}A$ for finitely generated monoids $S \subseteq A$. What I'm worried about primarily is in the noncommutative case what kind of (let's say two-sided) ideal we would want $N \trianglelefteq C$ to be; while nilpotent ideals could remain useful to look at, I have been led to believe that it may be more appropriate to look at ideals $N$ contained inside the Jacobson radical $J(C)$. The reason I suspect this is more appropriate is because when $S \subseteq R$ is a (two-sided) Ore set (so that $S^{-1}R$ has all its elements take the form $\lambda_S(r)\lambda_S(s)$ for $r \in R, s \in S$, and universal $S$-inverting morphism $\lambda_S$, or at least be uniquely isomorphic to a representation of this form, and two-sided so we don't have to worry about any stupid things happening with sidedness) we should be able to lift any element of $C/N$ in the diagram
$$
\begin{array}
s & R & \xrightarrow{\lambda_S} & S^{-1}R \\
 & f\downarrow & & \\
 & C & \xrightarrow{\pi_N} & C/N
\end{array}
$$
and induce a morphism $h:S^{-1}R \to C/N$ rendering the whole thing commutative. The problem I am having is that I am not sure if we would need $N$ to be contained instead in some sort of radical that allows the lifting of nilpotents of $C$ that is distinct from the Jacobson radical, like the upper or lower nilradical, or if someone has already done this in full detail and I have just could not find it. As I said earlier, I am especially interested in this because it should give a notion of étale cohomology for a noncommutative ring, and I would like to see if this gives an aspect of noncommutative algebraic geometry that works in a quasi-sane fashion. Please let me know as well if you think this question is more relevant on MO instead of here. Thanks in advance!","['algebraic-geometry', 'reference-request', 'noncommutative-algebra', 'noncommutative-geometry', 'category-theory']"
1889593,Why in these matrices are $AB=BA$ not equal? What is the logic behind them?,"We know that in matrices AB=BA.Why in this Matrices $A=\begin{bmatrix} -1 & 3\\
 2 & 0\end{bmatrix}$, $B=\begin{bmatrix} 1 & 2\\
-3 & -5\end{bmatrix}$ are not equal to $AB=BA$. WHY? This is matrix  of order $2\times 2$ for both $A$ and $B$.","['matrices', 'matrix-rank', 'linear-algebra', 'education']"
1889613,Moment generating function and probability,"Problem:Let $X$ and $Y$ be identically distributed independent random variables such that the moment generating function of $X +Y$ is
$$M(t) = 0.09 e^{−2t} + 0.24 e^{−t} + 0.34 + 0.24 e^t + 0.09 e^{2t}$$  for $−\infty < t < \infty$. Calculate $P[X \le 0]$. Answer: Because $X$ and $Y$ are independent and identically distributed, the moment generating function of $X+ Y$ equals $K^2(t)$, where $K(t)$ is the moment generating function common to $X$ and $Y$. Thus, $$K(t) =
0.30e^{-t} + 0.40 + 0.30e^t$$ This is the moment generating function of a discrete random variable that
assumes the values $-1$, $0$, and $1$ with respective probabilities $0.30$, $0.40$, and $0.30$. The value we
seek is thus $0.70$. My question is how to factor the moment generating function of $X+Y$ to $0.30e^-t + 0.40 + 0.30e^t$, is there a general formula to use? I'm also sorry for not using MathJax I'm really having trouble with it.","['probability', 'moment-generating-functions']"
1889663,Are there topological properties that are finitely productive but not countably productive?,"Let $X_i, i \in I$ be a set of topological spaces with property $P$. We would like to know whether $P$ holds for $\prod_{i \in I} X_i$ for $I$ of different cardinalities. I have looked over a list of topological properties, it seems only ""finiteness"" is finitely productive (finite products of finite set is finite) but not countably productive. In the literature, it seems there is a tendency to divide topological properties to finitely productive, countably productive, and arbitrarily productive. For example, in Munkres, compactness is first proved to be finitely productive, then immediately we jump to Tychonoff theorem. But I have rarely seen instances where a property $P$ is held under finitely product, but fails hold under countable product. On the other hand, a lot of properties seems to fail to cross the line between countably productive and arbitrarily productive. This includes separability, first countable, second countable, suslin, metrizability. Are there any interesting or well known topological properties that holds under finite product but not countable products?","['big-list', 'general-topology', 'cardinals', 'soft-question']"
1889686,show that $g(f(z))$ has an essential singularity at $z=z_0$?,"Question : Let $f(z)$ be analytic in an open set $G\subset \mathbb{C}$ except for a pole at $z_0\in G$. $g(z)$ be an entire function that is not a polynomial. how to show that $g(f(z))$ has an essential singularity at $z=z_0$? My work: I tried to prove by contradiction from that if it is a pole, then $\forall \delta>0 \exists R>0$ such that $\{w:|w|>R\}\subset f(\{z\in\mathbb{C}:|z-z_0|<\delta\})$. If it is a removable singularity, then $\lim_{z\to z_0}g(f(z))=c$ for some $c\in\mathbb{C}$. If it is a pole, then it is a removable singularity of $\frac{1}{g(z)}$, then I cannot find the contradiction come from? Could anyone kindly help? Thanks!","['complex-analysis', 'analysis']"
1889720,$\mathbb{R}$ is a closed subset of $\mathbb{R}$,"Question: Show that $\mathbb{R}$ is a closed subset of $\mathbb{R}$. $\mathbb{R}\setminus \mathbb{R}=\left \{ x \in \mathbb{R} \mid x\notin\mathbb{R} \right \}.$ I need to show that $\forall x \in \mathbb{R}\setminus \mathbb{R}, \exists \epsilon >0$ s.t $B_{\epsilon }\left ( x \right )\subseteq \mathbb{R}\setminus \mathbb{R}$. But, the complement of $\mathbb{R}$ itself doesn't make sense. Or rather, for it to make sense, it must be an empty set.","['real-analysis', 'metric-spaces', 'elementary-set-theory']"
1889740,$G$-set isomorphism equivalence,"Why are the following statements equivalent? (Let $P$ and $Q$ be groups and $\varphi$ an isomorphism between them. Let $X$ be a finite $P$-set): ${}_PX\cong {}_P^{\varphi}X$ as $P$-sets. $\vert {}_PX^R\vert=\vert {}_P^{\varphi}X^R\vert$ for all $R\leq P$ Where ${}_PX$ is the set $X$ under the action of $P$, the set ${}_P^{\varphi}X$ is the set $X$ under the action of $P$ given by $p\ast x=\varphi(p)\cdot x$ for $p\in P$ and $x\in X$, and $X^R$ is the set of fixed points under the action of $R$.","['group-actions', 'group-theory']"
1889742,Characterizing differences of squares in $\mathbb Z[x]$,"It is well known that a natural number can be written as a difference of two squares iff it is not of the form $4k+2$. I'm wondering if there is any characterization of which polynomials $f(x)\in\mathbb Z[x]$ with integer coefficients can be written as a difference $g(x)^2-h(x)^2$, for $f,g\in \mathbb Z[x]$. I tried googling this, but any search involving ""difference of squares"" and ""polynomial"" invariably returns a list of pages explaining the simple algebraic rule $a^2-b^2=(a+b)(a-b)$.","['abstract-algebra', 'ring-theory', 'polynomials']"
1889747,Intersection of Affine Subsets of a Vector Space.,"Hey guys I am teaching myself linear algebra and have no real way of confirming that a proof is correct. So I was wondering if the proof to this question is correct. The problem that is given is Show that the intersection of every collection of affine subsets of a
  vector space is either empty or an affine subset. My Attempt: Let $B$ be a collection of affine subsets of the vector space W. Either its intersection is empty or non-empty. Assume $\bigcap_{V \in B} 
	V\neq \emptyset$ then if $v,w\in \bigcap_{V \in B} 
	V\neq \emptyset$ this implies that $(\lambda v + (1-\lambda)w \in V \ \ \forall V\in  B) \Rightarrow (\lambda v +(1-\lambda)w \in \bigcap_{V \in B} 
	V)$. Since $v,w$ were abritrary it holds for all elements of the intersection of B. Thus the intersection is an affine subset and hence the proof is complete. Note that I use the fact that $\lambda v +(1-\lambda)w \in A \ \forall v, w \in A ,\ \forall \lambda\in F$ iff A is an affine subset. Where F is the field over the vector space. Thanks!","['linear-algebra', 'elementary-set-theory', 'proof-verification']"
1889765,"What is the field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2)$?","What is the field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2)$? Remarks: (1) I think it is clear that $\mathbb{Q}[x,y]/(x^2+y^2)$ is an integral domain;  indeed, $x^2+y^2 \in \mathbb{Q}[x,y]$ is irreducible (by considerations of degrees) hence prime. (2) The field of fractions of $\mathbb{Q}[x,y]/(x^2+y^2-1)$ is isomorphic to $\mathbb{Q}(t)$, see this question and also this question .","['abstract-algebra', 'ring-theory', 'commutative-algebra']"
1889769,describe the surfaces r=constant theta=constant and a =constant in the cylindrical coordinate system,"A question arises in my Multivariable calculus book that appears as follows: Describe the surfaces $r=$constant, $\theta$ = constant, $z$ = constant in the cylindrical coordinate system. I am unsure they mean to consider each one separately or together. If r is constant we have a circle, and if z is constant we have a flat 2-dimensional plane translated z units, not sure about theta. Any thoughts or answers appreciated. There is a similar question concerning spherical co-ordinates: 
if $\rho$ is constant $\theta$ is constant $\phi$ is constant",['multivariable-calculus']
1889772,Understanding the Definition for collections of events being independent,"I will put the definitions here given in Rosenthal's ""A First Look at Rigorous Probability Theory"" (chapter 3 section 2 in my (granted old) edition) Anyway, Rosenthal says a possibly-infinite collection $\{A_\alpha\}_{\alpha \in I}$ of events is said to be independent if for each $j \in N$ and each distinct finite
  choice $\alpha_1,\alpha_2,\dotsc, \alpha_j\in I$ we have
          $$ \tag{3.2.1}
			P(A_{\alpha_1}\cap A_{\alpha_2} \cap \dots A_{\alpha_j}) = P(A_{\alpha_1})P(A_{\alpha_2})
			\dots P(A_{\alpha_j})
		$$ Then he says Collections of events $\{\mathcal{A_\alpha} ;\alpha \in I \}$ are independent if for all $j \in N$ , for all distinct $\alpha_1,\alpha_2,\dotsc, \alpha_j\in I$, and for all $A_1 \in \mathcal{A}_{\alpha_1},\dotsc ,A_j \in \mathcal{A}_{\alpha_j}$, equation (3.2.1) holds. My question is whether someone can help me understand the second definition? My current understanding is that $\mathcal{A}_\alpha$ (notice script notation) denotes collections of events, $\{ A_\alpha\}_{\alpha \in I}$, and that collections of events $\mathcal{A}_\alpha$ are independent if for any (finite?) distinct collection of events $\mathcal{A}_{\alpha_1},\dotsc, \mathcal{A}_{\alpha_j}$ (with $j\in\mathbb{N}$), If I take any one event from within each collection, those events (or I guess more specifically the collection formed by those events) satisfies $(3.2.1)$. Is that correct? Also, I guess what I feel most confused about is that he is talking about collections( plural) of events being independent, but he denotes it 
$$
\{\mathcal{A_\alpha} ;\alpha \in I \}
$$
which to me looks like just one collection (of whatever $\mathcal{A}_\alpha$ are). I believe that $\mathcal{A}_\alpha$ are themselves collections of events, but I don't see that stated anywhere. Is that something I am just supposed to infer or implicitly understand? Thanks","['probability-theory', 'measure-theory']"
1889795,$-1$ raised to the $\pi$,"We know that the following conditions are true: $(-1)^{2n}$ is $1$ where $n$ is an integer $(-1)^{2n+1}$ is $-1$ where $n$ is an integer. We can extend this reasoning for rational numbers. If we let a number be written in the form of $a+\frac{b}{c}$ such that $\gcd(b,c) = 1$ and $a, b, c$ are integers,
then to evaluate $(-1)^{a+\frac{b}{c}}$, we can separate $(-1)^{a+\frac{b}{c}}$ into $(-1)^{a}\times\frac{(-1)^b}{(-1)^c}$. The terms $(-1)^{a}$, $(-1)^b$, $(-1)^c$ can be reduced to either of the two cases above; and we solve for $-1$ or $1$. Now what is $(-1)^\pi$. It isn't rational, so there isn't a perfect ratio that can be done with the method above. I'm suspecting that roots of unity come to play here or DeMoirve's Theorem, but don't they resolve to whether or not you can solve $r^n$ where r is the radius of the complex number and n is exponent. NOTE: I'm still in high school, so I am looking for an answer that does not have any advance math- but will gladly accept any response to the question for curiosity's sake. Thank you :)","['algebra-precalculus', 'irrational-numbers', 'exponentiation']"
1889816,What is $10$ in base $11$ and what is $11$ in base $11$?,"I am not understanding how to write numbers in bases. For example, $10=10\times11^0$ so it should be $10$ in base $11$. But also $11=0\times11^0+1\times11^1$ so $11$ is $10$ in base $11$. So both $10$ and $11$ are $10$ in base $11$?","['algebra-precalculus', 'decimal-expansion']"
1889822,How to solve this determinant,"Question Statment:- Show that
  \begin{align*}
\begin{vmatrix}
(a+b)^2 & ca & bc \\ 
ca & (b+c)^2 & ab \\
bc & ab & (c+a)^2 \\ 
\end{vmatrix}
=2abc(a+b+c)^3
\end{align*} My Attempt:- $$\begin{aligned}
&\begin{vmatrix}
\\(a+b)^2 & ca & bc \\ 
\\ca & (b+c)^2 & ab \\
\\bc & ab & (c+a)^2 \\\
\end{vmatrix}\\
=&\begin{vmatrix}
\\a^2+b^2+2ab & ca & bc \\ 
\\ca & b^2+c^2+2bc & ab \\
\\bc & ab & c^2+a^2+2ac \\\
\end{vmatrix}\\
=&\dfrac{1}{abc}\begin{vmatrix}
\\ca^2+cb^2+2abc & ca^2 & b^2c \\ 
\\ac^2 & ab^2+ac^2+2abc & ab^2 \\
\\bc^2 & a^2b & bc^2+a^2b+2abc \\\
\end{vmatrix}\\\\
&\qquad (C_1\rightarrow cC_1, C_2\rightarrow aC_2, C_3\rightarrow bC_3)\\\\
=&\dfrac{2}{abc}\times\begin{vmatrix}
\\ca^2+cb^2+abc & ca^2 & b^2c \\ 
\\ab^2+ac^2+abc & ab^2+ac^2+2abc & ab^2 \\
\\bc^2+a^2b+abc & a^2b & bc^2+a^2b+2abc \\\
\end{vmatrix}\\\\
&\qquad (C_1\rightarrow C_1+C_2+C_3)\\\\
=&\dfrac{2abc}{abc}\left(\begin{vmatrix}
\\a^2+b^2 & a^2 & b^2 \\ 
\\b^2+c^2 & b^2+c^2+2bc & b^2 \\
\\c^2+a^2 & a^2 & c^2+a^2+2ac \\\
\end{vmatrix}+
\begin{vmatrix}
\\1 & ca^2 & b^2c \\ 
\\1 & ab^2+ac^2+2abc & ab^2 \\
\\1 & a^2b & bc^2+a^2b+2abc \\\
\end{vmatrix}\right)
\end{aligned}$$ The second determinant in the last step can be simplified to 
\begin{vmatrix}
\\1 & ca^2 & b^2c \\ 
\\0 & ab^2+ac^2+2abc-ca^2 & ab^2-b^2c \\
\\0 & a^2b-ca^2 & bc^2+a^2b+2abc-b^2c \\\
\end{vmatrix} I couldn't proceed further with this, so your help will be appreciated and if any other simpler way is possible please do post it too.","['linear-algebra', 'determinant']"
1889832,"If maximal tori are self centralizing in $R(G)$, why do Levi subgroups exist?","Let $G$ be a connected algebraic group, $L$ a connected subgroup.  We say that $L$ is a Levi subgroup of $G$ if the product map $L \times R_u(G) \rightarrow G$ is an isomorphism of varieties. Then $L$ is necessarily reductive, the restriction of $G \rightarrow G/R_u(G)$ to $L$ is a bijective morphism of algebraic groups, $R(L) = Z(L)^0$ is a maximal torus of $R(G)$ , and $R(L)$ can be recovered as $L \cap R(G)$ . The following proposition is from Borel, Linear Algebraic Groups . I understand the proof of (i), but (ii) I do not at all.  Borel does not give a proof of (ii).  He just says it follows from (i) and the following two facts: Let $H$ be a connected solvable group. (1) Maximal tori in $H$ are conjugate under $\bigcap\limits_{n=1}^{\infty} C^n$ , where $C^1 \supseteq C^2 \supseteq \cdots$ denotes the descending central series. (2) If $S \subseteq H$ is a subgroup of $H$ consisting of semisimple elements, then $S$ is contained in a torus, and $Z_G(S)$ is connected and equal to $N_G(S)$ . I don't understand how (ii) follows so easily.  I let $T$ be a maximal torus of $R(G)$ , and I'm trying to show that the product map $Z_G(T) \times R_u(G) \rightarrow G$ is an isomorphism of varieties. So far, all I've got is that $Z_G(T) \cap R_u(G)$ is trivial.  This is because of the hypothesis that $T = Z_{R(G)}(T) = Z_G(T) \cap R(G)$ , whence $Z_G(T) \cap R_u(G)$ is a unipotent group contained in $Z_G(T) \cap R(G) = T$ , which implies that $Z_G(T) \cap R_u(G)$ is both diagonalizable and unipotent, hence trivial.","['algebraic-groups', 'lie-algebras', 'algebraic-geometry', 'lie-groups']"
1889843,How to solve this determinant equation in a simpler way,"Question Statement:- Solve the following equation
  $$\begin{vmatrix}
x & 2 & 3 \\ 
4 & x & 1 \\
x & 2 & 5 \\
\end{vmatrix}=0$$ My Solution:- $$\begin{vmatrix}
x & 2 & 3 \\ 
4 & x & 1 \\
x & 2 & 5 \\
\end{vmatrix}=
\begin{vmatrix}
x+5 & 2 & 3 \\ 
x+5 & x & 1 \\
x+7 & 2 & 5 \\
\end{vmatrix} \tag{$C_1\rightarrow C_1+C_2+C_3$}$$
$$=\begin{vmatrix}
0 & 2 & 3 \\ 
0 & x & 1 \\
2 & 2 & 5 \\
\end{vmatrix}+
(x+5)\begin{vmatrix}
1 & 2 & 3 \\ 
1 & x & 1 \\
1 & 2 & 5 \\
\end{vmatrix}\tag{1}$$ On opening the first determinant in the last step above we get $2(2-3x)$. On simplifying the secind determinant we get,
$$(x+5)\begin{vmatrix}
1 & 2 & 3 \\ 
1 & x & 1 \\
1 & 2 & 5 \\
\end{vmatrix}=(x+5)\begin{vmatrix}
1 & 2 & 3 \\ 
0 & x-2 & -2 \\
0 & 0 & 2 \\
\end{vmatrix} 
(R_2\rightarrow R_2-R_1) 
(R_3\rightarrow R_3-R_1)$$
$=2(x+5)(x-2)$ Substituting the values obtained above in $(1)$, we get
$$=\begin{vmatrix}
0 & 2 & 3 \\ 
0 & x & 1 \\
2 & 2 & 5 \\
\end{vmatrix}+
(x+5)\begin{vmatrix}
1 & 2 & 3 \\ 
1 & x & 1 \\
1 & 2 & 5 \\
\end{vmatrix}=2(2-3x)+2(x+5)(x-2)=2(2-3x+x^2+3x-10)=2(x^2-8)$$ Now, as $\begin{vmatrix}
x & 2 & 3 \\ 
4 & x & 1 \\
x & 2 & 5 \\
\end{vmatrix}=0$, $\therefore 2(x^2-8)=0\implies x=\pm2\sqrt2$ As you can see there was lot of work in my solution so if anyone can provide me with some techniques to solve it faster, or a technique which includes less amount of pen and more thinking.","['algebra-precalculus', 'linear-algebra', 'determinant']"
1889865,"given a concave function $f(x)$, why $f(x)- xf'(x)>0$?","Given a concave function $f(x)$ defined for $x \ge 0$, I am trying to understand whether $g(x) = f(x)- x f'(x)$ should be positive or not. From what I am reading it seems that it should be positive, but I cannot understand why. Any help?",['functions']
1889880,"How to Calculate: How many draws must I attempt, to get 90% of getting at least 1 of every 18 colour balls?","this is beyond my Mathematical skill, I apologise.... and I seek your help. Say there are 18 differently-coloured balls in an urn. You can draw one ball each time, with replacement. The goal is to get at least one ball of every colour. (So getting more than once of the same colour is okay) I wish to calculate, how many drawings must I attempt, to get a 90% chance of getting at least one of each colour. Can anyone help me?","['combinations', 'random', 'percentages', 'statistics', 'permutations']"
1889914,Is $\sqrt{2\sqrt[3]{3!\sqrt[4]{4!\sqrt[5]{5!..}}}}=2\log \pi$,Is  $$\sqrt{2\sqrt[3]{3!\sqrt[4]{4!\sqrt[5]{5!..}}}}=2\log \pi$$ Can anyone help me to know the way of proving above if it is true?,"['real-analysis', 'limits', 'pi', 'nested-radicals', 'sequences-and-series']"
1889929,How to show global instability of a system?,"Consider the system: $
\dot x_1 = x_2
$ $
\dot x_2 = {x_1}^2
$ It is obviously unstable, I say that because by inspection the derivative of $x_2$ can never be negative. How can we concretely show that, in the general case? If we were to prove stability we can use Lyapunov, but we cannot use that in the opposite way.","['control-theory', 'ordinary-differential-equations', 'dynamical-systems']"
1889947,What is the hypervolume of a 4D tetrahedron ($5$-cell)?,"Here's how this question arose in my mind: area of a triangle: $\frac{1}{2} \cdot b \cdot h$ volume of a tetrahedron: $\frac{1}{3} \cdot A \cdot h$ So the 2D object has $\frac{1}{2}$ in the formula , the 3D object has $\frac{1}{3}$ in its formula ...does the 4D object have $\frac{1}{4}$ in its formula? And if so, why is there a linear progression instead of something exponential? The concrete question is, what is the hypervolume of a $4$-dimensional tetrahedron?, aka $5$-cell or pentachoron. (PS, i saw 2D and 3D as tags, but not 4D or hyper dimensional tag. Don't know what else to tag.)",['geometry']
1890021,diameter of Riemannian manifolds,"Let $M$ be a compact Riemannian manifold of dimension $n$. If $M\subset N$ is an embedding in another Riemannian manifold, we can define the diameter $d(M,N$) of $M$ in $N$ as the longest distance in $N$ of two points in $M$. For example if $S^2$ is a sphere of radius $R$ in ${\mathbb{R}}^3$, we have
$$d(S^2,S^2)=\pi R , \qquad d(S^2,{\mathbb{R}}^3)=2R.$$
If $d>0$ is an integer we can then define
$$e(M,d)=\inf\big(d(M,N);\quad M\subset N \quad \text{and} \quad \dim(N)=\dim(M)+d\big)$$
If there a way (a formula) to compute $e(M,d)$ ? Is it true that
$$\lim_{d\to\infty}e(M,d) \ = \ 0 \ ?$$","['riemannian-geometry', 'differential-geometry']"
1890033,Planes of a dodecahedron divide the space $\mathbb R^3$,"In how many disjunct parts divide the planes of a regular dodecaheadron the space $\mathbb R^3$?
I encountered this task at university where we discussed it a lot, but nobody found a solution. Does anybody know the solution? May it work with graph theory?","['graph-theory', 'geometry']"
1890062,Submanifolds of oriented manifolds,"Let $M$ be an $n$-dimensional oriented manifold. Let $f:M\to\mathbb{R}$ be a smooth function. Suppose $c$ is a regular value of $f$ with $f^{-1}(c)$ nonempty. Show that $f^{-1}(c)$ is an oriented regular submanifold of $M$. By constant rank thoerem , I know that $f^{-1}(c)$ is an $(n-1)$-dimensional regular submafold of $M$, but how to show that it is orientable?",['differential-geometry']
1890070,Structure group of quaternionic manifold,"Quaternionic manifolds, also called almost hypercomplex, are defined by the existence of an ($\mathbb{R}$-linear) action of quaternions on each tangent space such that $I,J,K\in\mathbb{H}$ are global sections of $\operatorname{End} TX$. Several classes of manifolds can be defined by the reduction of their structure group from $GL(n,\mathbb{R})$ to a subgroup: $O(n)$: Riemannian manifold ($\exists g$ symmetric positive); $Sp(2(n/2),\mathbb{R})$: almost symplectic manifold ($\exists\omega$ nondegenerate $2$-form); $GL(n/2, \mathbb{C})$: almost complex manifold ($\exists J\in\operatorname{End}(TX)$ with $J^2=-1$) $U(n/2)$: almost Hermitian manifold ($\exists\omega,J$ as above) Can we put a group here? : almost hypercomplex manifold ($\exists I, J, K\in\operatorname{End}(TX)$ with $I^2=J^2=K^2=IJK=-1$) For completeness, let me recall the following.  A reduction to $G\subset GL(n,\mathbb{R})$ is a section of the quotient by $G$ of the tangent frame bundle, namely a (continuous) choice at each point of a ""copy of $G$"" ($G$-torsor) among bases of the tangent space. For example a reduction to $O(n)$ is a (continuous) choice of which bases of tangent space are orthonormal.  Similarly a reduction to $GL(n/2, \mathbb{C})$ is a choice of which bases are compatible with the almost complex structure $J$.","['quaternions', 'principal-bundles', 'kahler-manifolds', 'differential-geometry', 'lie-groups']"
1890121,Expectation value of trials needed to get $k$ consecutive outcomes,"Suppose that independent trials, each of which is equally likely to have any of $m$ possible outcome, are performed until the same outcome occurs $k$ consecutive times. If $N$ denotes the number of trials, show that
$$E[N] = \frac{m^k-1}{m-1}$$ This is a homework question. I was trying to reverse engineer this into a GP but without success. I also tried an induction approach to $k$. For getting one outcome, the number of trials needed is always $1$, so $k=1$ is a trivial case. Now assume that the expectation value of trials needed for $k$ consecutive outcomes is $E[N]$, then how do I find the update to $E[N]$ for $k+1$. I am very confused on the approach. Looks like a one-liner would do. Please help.","['probability-theory', 'probability']"
1890126,IMO 2016 Problem 5,"The equation
$$
(x-1)(x-2)(x-3)\dots(x-2016)=(x-1)(x-2)(x-3)\dots(x-2016)
$$
is written on a board, with $2016$ linear factors on each side. What is the least possible value of $k$ for which it is possible to erase exactly $k$ of these $4032$ factors so that at least one factor remains on each side and the resulting equation has no real solutions?","['polynomials', 'recreational-mathematics', 'roots', 'combinatorics', 'contest-math']"
1890130,Find all integral solutions of $ x^4 + y^4 + z^4 -w^4 = 1995 $,"Find all integral solutions of $ x^4 + y^4 + z^4 -w^4 = 1995 $. Attempt: From FLT it can be concluded that either all of $ x , y , z$ and $w$  are multiples of 5 ( which is not possible since that would lead to $ x^4 + y^4 + z^4 -w^4 $ being a multiple of $5^4$ which it is not since it's equal to 1995) or
$ w^4 $ and  exactly one of $x^4, y^4, z^4 $ are of the form $5k+1$ . So, there can be 3 cases with each having either $x^4, y^4  $ or $ z^4 $, along with $w^4$ , of the form $5k+1$ . I am unable to find the solutions from there.",['number-theory']
1890139,Area enclosed by the curve $5x^2+6xy+2y^2+7x+6y+6=0$,"We have to find the area enclosed by the curve
$$5x^2+6xy+2y^2+7x+6y+6=0.$$ I tried and I got that it is an ellipse, and I know its area is $\pi ab$ where $a$ and $b$ are the semiaxis lengths of the ellipse. But I am unable to find the value of $a$ and $b$.",['geometry']
1890160,Calculate the limit: $\lim_{x\rightarrow \infty}\frac{\ln x}{x^{a}}$,"Calculate the limit: $$\lim_{x\rightarrow \infty}\frac{\ln x}{x^{a}}$$ When try calculate limit, we get $\frac{\infty}{\infty}$, so use L'Hôpital again. $$(\ln x)' = \frac{1}{x}$$ $$x^{a} = e^{\ln x \cdot a} \Rightarrow (e^{\ln x \cdot a})'= e^{\ln x \cdot a} \cdot \frac{1}{x} \cdot a$$ $$\Rightarrow$$ $$\lim_{x\rightarrow\infty}\frac{\frac{1}{x}}{e^{\ln x \cdot a} \cdot \frac{1}{x} \cdot a}= \lim_{x\rightarrow\infty}\frac{x}{e^{\ln x \cdot a} \cdot a \cdot x} = \lim_{x\rightarrow\infty} \frac{1}{e^{\ln x \cdot a} \cdot a} = \frac{1}{\infty} = 0$$ Is correct result and limit?","['limits', 'functions', 'calculus', 'convergence-divergence', 'analysis']"
1890203,"Converting $\frac{d\, y}{d\, x} = x^2 + y^{\frac{2}{3}}$ to variable separable form","The question is as follows: Use method of separation of variables to solve 
  $$\frac{d\, y}{d\, x} = x^2 + y^{\frac{2}{3}}$$ I am aware of following two methods (as given here ) for converting differential equations to variable separable form: If $\frac{d\, y}{d\, x} = F\left(\frac{y}{x}\right)$ If $\frac{d\, y}{d\, x} = F(ax + by + c)$ But I don't know how to use this knowledge to convert given differential equation to variable separable form.",['ordinary-differential-equations']
1890214,Challenge: Prove $\displaystyle \sum_{n \in \mathbb{N}} \frac{n!}{(2n+1)!}=e^{1/4}\sqrt{\pi}\ \ \mathrm{erf}(\frac{1}{2})$,"I stumbled upon this cute sum while messing about, and I want to see what other solutions people propose before I put forward my own (which may be unnecessarily complicated). You can use any maths you like. NB: $\displaystyle \mathrm{erf}(x)=\frac{2}{\sqrt{\pi}}\int_0^xe^{-t^2}dt$","['recreational-mathematics', 'sequences-and-series', 'analysis']"
1890239,ODE and raw moments,I've read a piece in MathWorld where a distribution function $P(A)$ satisfies the ODE $$A^{3}(1-2A)P^{(4)}(A)+A^{2}P^{(3)}(A)-4A^{2}P''(A)+8AP'(A)-8P(A)-96(2A-1)=0.\label{a}\tag{1}$$ It is then inferred that the raw moments of $P$ are $$\mu_{n}'=\frac{3\cdot2^{3-n}\left[\left(n+2\right)H_{n+1}+1\right]}{(n+1)(n+2)^{3}(n+3)^{2}}\label{b}\tag{2}$$ Where $\mu_n'=\mathbb{E}[X^n]=\int_0^1x^ndP(x)$ are the raw moments and $H_n = \sum_{k=1}^n\frac{1}{k}$ is the harmonic number. My question is: how is (2) derived from (1)? My guess is this has to do with the Laplace transform but this is my first encounter with this type of ODEs so I don't know how they may be solved.,"['ordinary-differential-equations', 'probability', 'laplace-transform', 'harmonic-numbers']"
1890245,Constructing an Equidistributed set,"I want to construct a subset $A \subset [0,1]$ of measure $0<\epsilon <1$, such that for any interval $J \subset [0,1]$ we have $m(A \cap J)=m(A)m(J)$. If anyone has any hints it would be great.","['real-analysis', 'ergodic-theory', 'measure-theory']"
1890250,Discrete Harmonic Function Problem,"Suppose we have a function $f$ defined on the 2D lattice points that takes values between $[0, 1]$. Furthermore, suppose that $f$ satisfies $$f(a,b) = \frac{f(a-1,b) + f(a + 1,b) + f(a, b-1) + f(a, b+1)}4.$$ That is, the value of $f$ at $(a,b)$ is the average value of its neighbors. (This is also knows as the discrete harmonic property.) The problem is: Prove that $f$ must be the constant function. I have tried is to assume that $f$ is only defined on a finite grid of lattice points. Using an extremal argument, we can prove that $f$ must take its maximal value on the boundaries. However, this doesn't seem to lead anywhere in the infinite case. Any ideas?","['harmonic-functions', 'functions', 'discrete-mathematics']"
1890261,Graph $y = x^2$ in space,"I have graphed this equation $y = x^2$ and I got this output: Is it correct? On the other hand, this I what I got in Wolfram|Alpha: How do I can analog/compare these two graphs in such a way I can deduce one from the other?",['multivariable-calculus']
1890292,"$H, K$ conjugate subgroups of $G$, then $G/H$ and $G/K$ are isomorphic as G-sets","Let $H, K$ be conjugate subgroups of $G$. Then we can regard $G/H, G/K$ as G-sets defining $g'(gH) := (g'g)H$ and similarly for $K$. Two G-sets $X, Y$ are said to be isomorphic if there exists some bijection $\phi: X \rightarrow Y$ such that $$\phi(gx) = g\phi(x) \; \forall x \in X, g \in G$$ My intuition seems to be that $\phi(H) = K$ and so $\phi(gH) = gK$, but I'm having trouble trying to show $\phi$ is well defined, since $\phi(ghH) = ghK =_{?} gK = \phi(gH)$ does not look right. I've found this question here in this site, but the only answer is rather brief and I don't fully understand what is going on, as seems to be the case for the OP. Anyway, it was never restated or further detailed, so I'd really appreciate if someone would care to give some insight into it.","['group-actions', 'abstract-algebra', 'group-theory']"
1890310,Difference between $C^k$s and $C^\infty$,"What is the true difference between $C^0$, $C^1$, $\dots$, and $C^\infty$ objects and morphisms? (Or less dramatically formulated, what are deep differences between them?) For instance, we do know that the existence of certain maps of classes $C^0$ and $C^\infty$ on $C^\infty$-manifolds is equivalent, as $C^0$ maps can be arbitrarly approximated by those of class $C^\infty$, even in a manner that respects $C^\infty$-ly treated closed subsets. The lists of connected closed surfaces essentially coincide in $C^0$ and $C^\infty$. (That is, exactly one smooth structure per genus and orientability.) There is exactly one $C^\infty$-structure on the topological space $S^2$. Not every $C^k$-manifold is $C^\infty$, as we might consider an embedded cube in $\mathbb R^n$ with edges that are $C^k$, but not $C^{k+1}$. Are there possibilities to classify all $C^k$-structures on a given topological space, say for $k\ge 1$, just by knowing the nature of its smooth structures, in some more general setting than those of closed surfaces?","['differential-topology', 'smooth-manifolds', 'manifolds', 'differential-geometry', 'philosophy']"
1890312,Hamel basis for the vector space of real numbers over rational numbers and closedness of the basis under inversion,"Let $\mathcal B$ be a Hamel basis for $\mathbb R$ over $\mathbb Q$. Then is it true that for every $0\ne a \in \mathbb R , \exists y \in \mathcal B$ such that $\dfrac a y \notin \mathcal B$ ? If the answer to the above in general is no then can we take $a$ to be $1$, that is, Does there exist a Hamel basis $\mathcal B$ for $\mathbb R$  over $\mathbb Q$ such that $a\in \mathcal B \implies \dfrac 1a \in \mathcal B$ ? See Hamel basis for $\mathbb{R}$ over $\mathbb{Q}$ cannot be closed under scalar multiplication by $a \ne 0,1$","['abstract-algebra', 'linear-algebra', 'vector-spaces']"
1890316,What distributions generate random unit vectors,"I was reading about generating random unit vectors for n-dimensional space. I read one method in which the person suggested that we can take n-random samples from standard normal distribution and if we normalize it then we will get a random vector. The reason he gave was that Gaussian distribution is spherically symmetric. Then I thought of another method , If we pick values from uniform distribution from  $-\infty$  to $+\infty$ and then also after normalizing it, We will get a random vector. Since,probability for each point to be getting selected is same then probability for each random vector will be also same. So ,I was wondering whether what I thought is correct or not? and also what are all distributions for which this will work and if normal distribution is the only distribution for which it will work then what is the reason behind it?","['statistics', 'probability', 'analytic-geometry']"
1890317,"Does there exist a Hamel basis $\mathcal B$ for $\mathbb R$ over $\mathbb Q$ such that $a,b \in \mathcal B \implies \dfrac ab \in \mathcal B$?","This is part of an attempt to understand what multiplicative structure a Hamel basis of the reals over the rationals can have. Does there exist a Hamel basis $\mathcal B$ for $\mathbb R$ over $\mathbb Q$ such that $a,b \in \mathcal B \implies \dfrac ab \in \mathcal B$ ? Additionally, as proposed by Noah Schwerber, if the answer to the above is negative, what if the restriction that $a \neq b$ is imposed, that is: Does there exist a Hamel basis $\mathcal B$ for $\mathbb R$ over $\mathbb Q$ such that $a,b \in \mathcal B $ distinct $ \implies \dfrac ab \in \mathcal B$ ? The following earlier question showing that such a Hamel basis cannot be closed under multiplication by a (non-trivial) constant could be helpful Hamel basis for $\mathbb{R}$ over $\mathbb{Q}$ cannot be closed under scalar multiplication by $a \ne 0,1$ A recent related but distinct question Hamel basis for the vector space of real numbers over rational numbers and closedness of the basis under inversion focuses on whether a Hamel basis can be closed under taking inverses.","['abstract-algebra', 'extension-field', 'linear-algebra', 'vector-spaces']"
1890346,"If A and B are independent sequences of Bernoulli trials w/ different p, what is the probability that success occurs in A before success occurs in B? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Suppose a sequence of Bernoulli trials continues until a success occurs. For two independent such sequences, say $A$ and $B$, with respective success-probabilities $a$ and $b$, what is the probability that $A$ is shorter than $B$? Here's an example of what I mean: Suppose that I have two unfair coins. Coin 1 has a probability of coming up heads of $\frac{1}{3}$, and coin 2 has a probability of coming up heads of $\frac{2}{3}$. I flip both coins at the same time. What is the probability that Coin 1 is heads before coin 2? Let $C_n$ be the number of flips it takes coin $n$ to come up heads. $P(C_1<C_2) = ?$","['probability', 'geometric-series']"
1890361,A topological space such that every subspace from it is connected.,"Let $\tau$ be the topology in $\mathbb{R}^2$ whose open sets are of the form
  $$G_t = \{ (x,y)\in \mathbb{R}^2 \mid x>y+t\}, \; t\in \mathbb{R}$$
  Is the union of two lines $r\cup s$ connected in $(\mathbb{R}^2,\tau)$? What I did was consider $r\cup s$ as subspace of $\mathbb{R}^2$ and assume that therexist $A$ and $B$ such that 
$$r\cup s = A\cup B$$
and $A\cap B =\emptyset$.
Then we can write $A$ and $B$ as
$$A=(r\cup s)\cap G_{t_1},\, B= (r\cup s)\cap G_{t_2}$$
But since for every $t_1, t_2 \in \mathbb{R}$, $G_{t_1}\subset G_{t_2}$ or $G_{t_2}\subset G_{t_1}$, we have that
$$A\subset B\; \text{or}\; B\subset A$$
In any case, $A\cap B\neq \emptyset$ and hence there is no separation of $r\cup s$, so $r\cup s$ is connected. My question then is if this proof is okay, and also if it works too for any subspace of $(\mathbb{R}^2,\tau)$ since I haven't use at all anything about the two lines. Also Are there other examples of topologies in $\mathbb{R}^2$ such that all subspaces are connected?","['general-topology', 'connectedness']"
1890376,Challenging definite integral of hypergeometric functions,"Given $\ell\in\mathbb{N}\land\left(m,n\right)\in\mathbb{Z}_{\ge0}^{2}\land\left(a,b,c\right)\in\mathbb{R}^{3}\land0<a<b<1\land0<c<1$ , define the function $\mathcal{J}_{\ell,m,n}{\left(a,b,c\right)}$ via the definite integral $$\small{\mathcal{J}_{\ell,m,n}{\left(a,b,c\right)}:=\int_{0}^{1}\mathrm{d}t\,\frac{t^{m-\frac12}\left(1-t\right)^{\ell+n-\frac12}}{\left(1-at\right)^{\ell}}\,{_2F_1}{\left(\frac12,m+\frac12;m+\frac32;bt\right)}\,{_2F_1}{\left(\frac12,n+\frac12;n+\frac32;c\left(1-t\right)\right)}}.$$ The Gauss hypergeometric function ${_2F_1}$ may be defined via the infinite series $${_2F_1}{\left(\alpha,\beta;\gamma;z\right)}:=\sum_{n=0}^{\infty}\frac{\left(\alpha\right)_{n}\,\left(\beta\right)_{n}}{\left(\gamma\right)_{n}}\cdot\frac{z^{n}}{n!};~~~\small{\left|z\right|<1}.$$ Question: Does the integral above possess a closed form representation in terms of hypergeometric (or simpler) functions? Possible starting point: Lacking any obvious way to evaluate this integral, one strategy that came to mind was to expand the integral as a multiple infinite series, which could then be converted into some hypergeometric representation (assuming such exists). As you can see below, things get messy, and it's hard to tell if any headway is being made. Let $\ell\in\mathbb{N}\land\left(m,n\right)\in\mathbb{Z}_{\ge0}^{2}\land\left(a,b,c\right)\in\mathbb{R}^{3}\land0<a<b<1\land0<c<1$ . We find $$\begin{align}
\mathcal{J}_{\ell,m,n}{\left(a,b,c\right)}
&=\int_{0}^{1}\mathrm{d}t\,\frac{t^{m-\frac12}\left(1-t\right)^{\ell+n-\frac12}}{\left(1-at\right)^{\ell}}\,{_2F_1}{\left(\frac12,m+\frac12;m+\frac32;bt\right)}\\
&~~~~~\times\,{_2F_1}{\left(\frac12,n+\frac12;n+\frac32;c\left(1-t\right)\right)}\\
&=\int_{0}^{1}\mathrm{d}t\,\frac{t^{m-\frac12}\left(1-t\right)^{\ell+n-\frac12}}{\left(1-at\right)^{\ell}}\,{_2F_1}{\left(\frac12,m+\frac12;m+\frac32;bt\right)}\\
&~~~~~\times\sum_{k=0}^{\infty}\frac{\left(\frac12\right)_{k}\,\left(n+\frac12\right)_{k}\,c^{k}}{\left(n+\frac32\right)_{k}\,k!}\left(1-t\right)^{k}\\
&=\small{\sum_{k=0}^{\infty}\frac{\left(\frac12\right)_{k}\,\left(n+\frac12\right)_{k}\,c^{k}}{\left(n+\frac32\right)_{k}\,k!}\int_{0}^{1}\mathrm{d}t\,\frac{t^{m-\frac12}\left(1-t\right)^{\ell+n+k-\frac12}}{\left(1-at\right)^{\ell}}\,{_2F_1}{\left(\frac12,m+\frac12;m+\frac32;bt\right)}}\\
&=\small{\sum_{k=0}^{\infty}\frac{\left(\frac12\right)_{k}\,\left(n+\frac12\right)_{k}\,c^{k}}{\left(n+\frac32\right)_{k}\,k!}\int_{0}^{1}\mathrm{d}t\,\sum_{j=0}^{\infty}\binom{j+\ell-1}{j}a^{j}t^{m+j-\frac12}\left(1-t\right)^{\ell+n+k-\frac12}}\\
&~~~~~\times\,{_2F_1}{\left(\frac12,m+\frac12;m+\frac32;bt\right)}\\
&=\sum_{k=0}^{\infty}\frac{\left(\frac12\right)_{k}\,\left(n+\frac12\right)_{k}\,c^{k}}{\left(n+\frac32\right)_{k}\,k!}\sum_{j=0}^{\infty}\binom{j+\ell-1}{j}a^{j}\\
&~~~~~\times\int_{0}^{1}\mathrm{d}t\,t^{m+j-\frac12}\left(1-t\right)^{\ell+n+k-\frac12}\,{_2F_1}{\left(\frac12,m+\frac12;m+\frac32;bt\right)}\\
&=\sum_{j=0}^{\infty}\sum_{k=0}^{\infty}\frac{\binom{j+\ell-1}{j}\left(\frac12\right)_{k}\,\left(n+\frac12\right)_{k}\,a^{j}\,c^{k}}{\left(n+\frac32\right)_{k}\,k!}\,\operatorname{B}{\left(\frac12+m+j,\frac12+\ell+n+k\right)}\\
&~~~~~\times\,{_3F_2}{\left(\frac12,\frac12+m,\frac12+m+j;\frac32+m,1+\ell+m+n+j+k;b\right)}\\
&=\sum_{j=0}^{\infty}\sum_{k=0}^{\infty}\frac{\binom{j+\ell-1}{j}\left(\frac12\right)_{k}\,\left(n+\frac12\right)_{k}\,a^{j}\,c^{k}}{\left(n+\frac32\right)_{k}\,k!}\,\operatorname{B}{\left(\frac12+m+j,\frac12+\ell+n+k\right)}\\
&~~~~~\times\sum_{p=0}^{\infty}\frac{\left(\frac12\right)_{p}\,\left(\frac12+m\right)_{p}\,\left(\frac12+m+j\right)_{p}\,b^{p}}{\left(\frac32+m\right)_{p}\,\left(1+\ell+m+n+j+k\right)_{p}\,p!}.\\
\end{align}$$ Does anybody have any ideas for finishing the derivation, or another approach entirely? This is a difficult and time-consuming problem, but also one that I'm quite eager to crack. Any help would be greatly appreciated!","['closed-form', 'hypergeometric-function', 'integration', 'definite-integrals', 'special-functions']"
1890383,Is there another topology on $\mathbb{R}$ that gives the same continuous functions from $\mathbb{R}$ to $\mathbb{R}$?,"If we look at any set $X$ with the trivial topology, then all functions from $X$ to $X$ are continuous. We could also take the discrete topology and get the same result: all functions are continuous. Another example: Take the Sierpinski space, all functions from it to itself, except the function that switches 0 and 1, are continuous. Again there is another topology that gives the same continuous functions (just take the other singleton as open). Is this true for $\mathbb{R}$ aswel? Note that I'm not asking if $\mathbb{R}$ is completely regular , which is a seemingly similar but different property (In that property, the image space is equipped with the Euclidean topology if I'm not mistaken). I'm interested in $\mathbb{R}$ especially because this would give another way to think about continuous functions on it. High school students learn an epsilon delta definition but you can teach them what an open set is and define continuous that way. The usual definition of open is then ""union of open intervals"", but maybe there is a different choice of opens to get the same notion of continuous functions. That being said, I'm also interested in other spaces on which the topology can be changed to obtain the same continuous functions to itself, like the examples I gave, or in spaces where you can show that the topology is the only one that gives those continuous maps. Thanks in advance edit: Assume $X$ has more than 1 element. The argument that CarryonSmiling makes can be generalised as follows: Let's call a space that is T1 and connected a Tc space. If two topologies on $X$ have the same continuous maps from $X$ to itself, then they are either both Tc or both not Tc. This is true because Tc is equivalent to the property that CarryonSmiling uses, that is expressed only with continuous maps from $X$ to itself: $$(*)\quad\mbox{No map $h:X\rightarrow X$ whose range has exactly two elements is continuous.}$$ To see this equivalency, note that $$T1 \iff \mbox{closed singletons} \iff \mbox{every subspace with exactly 2 elements is discrete}$$
$$\mbox{connected} \iff \mbox{every continuous map to the discrete space with 2 elements is constant}$$
That means that T1 and connectedness together are exactly $(*)$.
Maybe this can help to find a space that is determined by its continuous maps to itself. Please let me know if any part of this reasoning is invalid.","['continuity', 'general-topology']"
1890395,How come $\lim_{n\rightarrow \infty} \frac{a_n}{a_{n-1}}$ be different than 1?,"There is a theorem that ""$\forall_{n}: a_n>0 ~and~ \lim_{n\rightarrow \infty} \frac{a_n}{a_{n-1}}=L \Rightarrow \lim_{n\rightarrow \infty} \sqrt[\leftroot{-2}\uproot{2}n]{a_n}=L$. Does the left hand side of the statement also implies that $a_n$ does not converges to a finite limit? (since if $a_n$ has a limit $L$ then $a_{n-1}$ has the exact same limit $L$. Now, a series $c_n=\frac{a_n}{b_n}$ has a limit $L_c=\frac{L_a}{L_b}$. Thus, $\lim_{n\rightarrow \infty} \frac{a_n}{a_{n-1}}=\frac{L}{L}=1$). Then the remaining cases are $a_n$ converges to $\infty$ or not at all.",['sequences-and-series']
1890412,What can be said about a convex combination of orthogonal matrices?,"Let $A$ and $B$ be two orthogonal matrices (of order $n\geqslant 2$ ) such that $$\det A=1 \qquad\qquad \det B=-1$$ Can we say that: there is $\lambda \in [0,1]$ such that $\lambda A + (1-\lambda) B$ defines a projection operator? there is $\lambda \in [0,1]$ such that $\lambda A + (1-\lambda) B$ is a singular matrix? I was wondering why can't we say that every orthogonal matrix is a projection matrix that projects onto $\mathbb{R^n}$ (so that the first question is answered by $\lambda = 0$ or $\lambda = 1$ )?","['matrices', 'orthogonal-matrices', 'linear-algebra']"
1890416,"for every $n\ge{1} , \binom{2n}{n}\ge \frac{2^{2n}}{4\sqrt{n}+2} $",Prove this inequality for every $n\ge{1}$ $$\binom{2n}{n}\ge \frac{2^{2n}}{4\sqrt{n}+2} $$ I try to prove it with simplification this inequality but i don't find right path to get solution.,"['combinatorics', 'inequality', 'discrete-mathematics']"
1890418,"Determine a solution of an ODE by ""inspection""","I'm checking Zill's A First Course in Differential Equations with Modeling Applications , and there's an exercise that says: From the following problems determine by inspection at least two solutions of the given IVP. $y'=3y^{2/3},\,y(0)=0$ $xy'=2y,\,y(0)=0$ I don't quite understand what in means by "" by inspection "", what's the difference between just finding the solutions and determine by inspection?",['ordinary-differential-equations']
1890430,Finding the basis for the intersection of two subspaces,"Find a basis for the intersection of the subspaces $X_1$ and $X_2$ of $\mathbb{R^4}$ where $$X_1=\text{span}\left\{ (1,1,0,0), (0,1,1,0), (0,0,1,1)\right\}$$
and $$X_2=\text{span}\left\{ (1,0,t,0), (0,1,0,t)\right\},$$ where $t\in \mathbb{R}$ is given. Well, I know that if $v\in X_1\cap X_2$, then $v=a(1,1,0,0)+ b(0,1,1,0)+ c(0,0,1,1)=d(1,0,t,0)+ m(0,1,0,t)$, where $a, b, c, d, m \in \mathbb{R}$. Then
this implies that $(0,0,0,0)=v-v=(a-d,a+b-m,b+c-dt,c-mt)$, that is $$a-d=0$$ $$a+b-m=0$$ $$b+c-dt=0$$ $$c-mt=0.$$ Since $t\in \mathbb{R}$ is given, I have 5 unknowns and 4 equations. I can't solve this! Is there any other way to solve this problem?? Thank you!","['matrices', 'linear-algebra']"
1890443,Show that $\int_0^1 \frac{\ln^3(x)}{1+x} dx = \sum_{k=0}^{\infty}(-1)^{k+1} \frac6{(k+1)^4}$,Show that; $$ \int_0^1 \frac{\ln^3(x)}{1+x} dx = \sum_{k=0}^{\infty}(-1)^{k+1} \frac6{(k+1)^4}$$ I arrived to the fact that $$ \int_0^1 \frac{\ln^3(x)}{1+x} dx = \sum_{k=0}^{\infty}(-1)^k\int_0^1 x^k \ln^3(x)dx$$ But I am unable to continue further.,['integration']
1890462,How to justify differentiating an asymptotic series in WKB method,"Given a second-order linear ordinary differential equation,
\begin{equation}
\epsilon^2 \frac{d^2y}{dx^2} = Q(x) y(x),
\tag{1}\label{1}
\end{equation}
where $\epsilon$ is regarded as a small positive number,
a typical explanation of the WKB method (e.g. Ch. 10 of Bender and Orszag, Advanced Mathematical Methods for Scientists and Engineers, 1978) starts with writing $y(x)$ as
\begin{equation}
y(x) = \exp\left(\frac{1}{\delta}S(x,\delta)\right),
\tag{2}\label{2}
\end{equation} 
and assuming that $S(x,\delta)$ has an asymptotic series in $\delta$,
\begin{align}
S(x,\delta) \sim& \sum_{n=0}^{\infty} \delta^n S_n(x) &
\text{ as } \delta\rightarrow&0+.
\tag{3}\label{3}
\end{align}
Then, by substituting eqs. (\ref{2}) and (\ref{3}) into eq. (\ref{1}) and dividing both sides by $\exp(S/\delta)$, it is claimed that
\begin{align}
\frac{\epsilon^2}{\delta^2} 
\left[\sum_{n=0}^{\infty} \delta^n \frac{d S_n}{dx}\right]^2
+\frac{\epsilon^2}{\delta}
\sum_{n=0}^{\infty} \delta^n \frac{d^2 S_n}{dx^2}
\sim& Q(x) &
\text{ as } \delta\rightarrow&0+.
\tag{4}\label{4}
\end{align}
From here, the argument proceeds that we can set $\delta = \epsilon$ from dominant balance, and that we can equate the like powers of $\epsilon$ on both sides to yield differential equations for the coefficient functions $\{S_n(x)\}$ as
\begin{align}
\left(\frac{dS_0}{dx}\right)^2 =& Q(x), 
\tag{5}\label{5}\\
2 \frac{dS_0}{dx}\frac{dS_1}{dx}+\frac{d^2S_0}{dx^2}=&0,
\tag{6}\label{6}\\
\dots
\end{align}
and these equations are solved one after another. Here is my question. How is it justified to differentiate the asymptotic series in eq. (\ref{3}) to derive eq. (\ref{4})? I wondered that maybe we can use the fact that $y(x)$ is a solution of eq. (\ref{1}) in some way, but I don't find a way so far. I read that the derivatives of both sides of an asymptotic relation does not always construct another asymptotic relation, and I guess that even if 
\begin{align}
f(x,\epsilon)\sim& g_0(x) + g_1(x) \epsilon + g_2(x) \epsilon^2 +\cdots&
\text{ as } \epsilon\rightarrow& 0,
\tag{7}\label{7}
\end{align} 
uniformly in some domain of $x$, it does not necessarily follow that 
\begin{align}
\frac{df}{dx}(x,\epsilon) 
\sim& \frac{dg_0}{dx}(x) 
+ \frac{dg_1}{dx}(x)\epsilon + \frac{dg_2}{dx}(x) \epsilon^2 +\cdots&
\text{ as }\epsilon \rightarrow& 0.
\tag{8}\label{8}
\end{align}
Or, does it follow (under some conditions)?","['asymptotics', 'mathematical-physics', 'perturbation-theory', 'formal-power-series', 'ordinary-differential-equations']"
1890464,A tricky trigonometric integral,"How can I evaluate
$$I = \int_0^{\pi / 2} 5x \sin(6x) \cos (9x^5) \,\textrm{d}x$$ without Computer Algebra Systems? Mathematica fails to find the value of $I$ and RIES isn't very helpful too. I've tried expanding the function under integral sign into power series with no results. If it's too hard, I will be satisfied with $$\int_0^{\pi/2} x \sin x \cos (x^2) \,\textrm{d}x$$ or anything like that.","['integration', 'definite-integrals', 'calculus']"
1890482,"Show that $1, (x-5)^2, (x-5)^3$ is a basis of the subspace $U$ of $\mathcal P_3(\Bbb R)$","In Axler's LADR book example 2.41:
Show that $1, (x-5)^2, (x-5)^3$ is a basis of the subspace $U$ of $\mathcal P_3(\Bbb R)$ defined by: $$U = \{p \in P_3(\Bbb R):p'(5) = 0\}$$ Book shows that $1, (x-5)^2, (x-5)^3$ is linear independent, hence $\dim U \ge 3$ .
It also must be $\dim U \le 4$ .
But I dont understand this part: However, $\dim U$ cannot equal $4$ , because otherwise when we extend a basis of $U$ to a basis of $P_3(\Bbb R)$ we would get a list with length greater than 4. Why we will get basis with length greater than $4$ ?","['polynomials', 'linear-algebra']"
1890517,How can I construct genus 2 curves,"One of the first big formula's you learn in algebraic geometry is the genus-degree formula which states that an irreducible homogeneous polynomial in $f \in \mathbb{C}[x,y,z]$ of degree $d$ gives a genus $(d-1)(d-2)/2$ curve. Unfortunately, this does not help with constructing genus 2 curves since we have the following table of degrees and genera for $f$
$$
\begin{matrix}
\text{degree} & 1 & 2 & 3 & 4 & 5 & \cdots \\
\text{genus} & 0 & 0 & 1 & 3 & 6 & \cdots
\end{matrix}
$$
How can I find a generalization of the genus-degree formula so that I can construct curves in some projective space with the desired genus?","['algebraic-curves', 'riemann-surfaces', 'curves', 'algebraic-geometry']"
1890531,"Proof of existence of a limit for the sequence recursively-defined with $a_1=1$, $a_2=1$ and $a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}$ for $n\ge2$","I have a sequence defined by $$
a_1=1,\quad a_2=1,\quad a_n=\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}\text{ for } n\ge2\text.
$$ Now, if $\lim\limits_{n\to \infty}a_n=g$ then $\lim\limits_{n\to \infty}a_n=\lim\limits_{n\to \infty}\Bigl(\frac{1}{a_{n-1}}+\frac{1}{a_{n-2}}\Bigr)=\frac{2}{g}$ , so $g=\sqrt{2}$ or $g=-\sqrt{2}$ , but $a_n>0$ , so $g=\sqrt{2}$ . Now, how do I prove that it has an actual limit? Also, it can be proven that $1\le a_n\le2$ , and it's not monotonic because $a_4 \gt a_5 \lt a_6$ .
Also, it's not monotonic after any $N\in\mathbb N$ .","['recurrence-relations', 'real-analysis', 'sequences-and-series', 'limits']"
1890534,"What is $\text{Res}_{\mathbb{F}_p(t)/\mathbb{F}_p(t^p)}(\text{Spec}\,\mathbb{F}_p(t)[x]/(x^p - t))$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $L = \mathbb{F}_p(t)$ and $k = \mathbb{F}_p(t^p)$. Let $X$ be the $L$-scheme $\text{Spec}\,L[x]/(x^p - t)$. What is $\text{Res}_{L/k}\,X$? Here $\text{Res}$ denotes the Weil restriction of scalars.","['algebraic-geometry', 'abstract-algebra', 'algebraic-number-theory', 'number-theory', 'arithmetic-geometry']"
1890542,Intuitively understanding Fatou's lemma,I learnt Fatou's lemma a while ago. I am able to prove it and use it. I know examples showing that the inequality may be strict. But I don't really have an intuitive way to understand it. Any good thoughts?,"['intuition', 'real-analysis', 'lebesgue-integral']"
1890545,How to prove a power series can be analytically continued?,"Consider the complex function $f(z)=\sum_{n=1}^{\infty} \frac{(-1)^n}{2n+1}z^{2n+1} \, .$ (i) Determine its domain. (ii) Let $\Gamma = \{iy:y\in\mathbb{R}, |y| \geq 1 \}$, show that there exists an analytic continuation of $f$ to $\mathbb{C}-\Gamma$. (iii) (optional) Discuss the existence of other maximal analytical continuations of $f$ to domains of the Riemann sphere $\mathbb{C} \cup \{\infty\}$ of the form $D= (\mathbb{C} \cup \{\infty\})-\Gamma',$ where $\Gamma'$ is a compact set of $\mathbb{C}$. For the first part: I think the radius of convergence is $1$. And I can see it converges when $z=1$, but I don't know about the rest of the border $S^1$. However, the real problem is point (ii). Is there a general way to tackle this kind of problem?","['complex-analysis', 'power-series']"
1890563,Solving differential equation $x y^2 y' = x+1$,"I am asked to solve the following differential equation: $$
x y^2 y' = x+1
$$ My process was $$
\begin{align*}
x y^2 y' &= x+1\\
xy^2 \frac{dy}{dx} &= x+1\\
y^2 dy &= \frac{x+1}{x} dx\\
\int y^2 dy &= \int \frac{x+1}{x} dx\\
\int y^2 dy &= \int dx + \int \frac{1}{x} dx\\
\frac{y^3}{3} &= x + \ln |x| + C\\
y &= \sqrt[3]{3 \left( x + \ln |x| + C \right)}
\end{align*}
$$ but when I was checking my result on Wolfram I noticed that it was given in a different way. Is my result incorrect? What caused the results to be different? Is it the absolute value sign of the $\ln$? Thank you.","['ordinary-differential-equations', 'calculus']"
