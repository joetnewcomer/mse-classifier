question_id,title,body,tags
1523540,Is $\prod_{n=1}^\infty P_{2n-1}$ regularizable?,"Assume that $P_n$ denotes the $n$'th prime for this entire question. Inspriation: I was dumbfounded by the fact that: $$\hat\prod_\limits{n=1}^\infty P_{n}=4\pi^2$$ 
After further investigation, I learned of many other properties of zeta-regulation, as well as their proofs (to a reasonable extent). I realized nothing had been done of this question: $$2*5*11\cdots=\hat\prod_\limits{n=1}^\infty P_{2n-1}=\kappa$$
and solve for $\kappa$. Issues: I am fairly competent in the usage of zeta-regularization, but am lost here, because it seems that zeta regularization doesn't work with $2n-1$ used instead of $n$. Unfortunately, I couldn't really figure out how to apply that on to this here. I was driven, from Resource 1, that a potential to use bounds was created, but my inability to logically understand this problem made it impossible to determine if $4\pi^2$ or $\sqrt{2\pi}$ would be upper or lower. Questions: a) Can $\kappa$ be zeta-regularized? b) If it can, could you please assist me in a calculation of $\kappa$? Side notes: I have had this question on my mind almost forever, and would really love an answer. Although I would most appreciate a proof, really anything will help me here. I am also somewhat uncertain with my tag choices, so please consider editing before immediately downvoting. The following were helpful in the construction of this problem. 1) When is an infinite product of natural numbers regularizable? 2) http://mathworld.wolfram.com/Zeta-RegularizedProduct.html (I realize the former has been unanswered, but the problem had helpful comments as well as the idea to find a bound. )","['regularization', 'prime-numbers', 'number-theory', 'infinite-product']"
1523546,partial derivative of a facet normal wrt to one of its vertex,"I am struggling to understand the derivation of an equation in a paper ( A Bayesian Method for Probable Surface Reconstruction and Decimation , specifically Eqn. 16). Basically they define three vertices of a facet: $x_k, x_{k'},x_{k''}$ 
The normalized facet normal is defined as: $n_i = \dfrac{(x_{k'}-x_k) \times (x_{k''}-x_k)}{|(x_{k'}-x_k) \times (x_{k''}-x_k)|}$ So far so good. The problem is then that they need to compute $\frac{\partial n_i}{\partial x_k}$. Firstly ${n_i}$ and ${x_k}$ are both vectors, hence I'd expect that this partial derivative notation means in effect the Jacobian of ${n_i}$ wrt. ${x_k}$? In that case that is a 3x3 matrix. However the formula below (see Eqn 16) implies that the result is a 3x1 vector?? (confused!) $\frac{\partial n_i}{\partial x_k} = \frac{I - n_in_i^T}{|(x_{k'} - x_k) \times (x_{k''} - x_k)|} (x_{k''} - x_{k'}) \times x_k$ I was hoping someone could shed some light on the dimensionallity confusion and also how that formula was derived, or if incorrect what is the correct forumation for $\frac{\partial n_i}{\partial x_k}$?  Thanks for the help!","['computer-science', 'calculus', 'partial-derivative', 'multivariable-calculus', 'derivatives']"
1523578,"Show that for any a ∈ ℤ, 42 | $(a^7 − a).$","Show that for any $a \in \mathbb{Z}, 42 \mid (a^{7} − a)$. I saw this question on Rosen textbook and it doesn't have answer key so I am wondering can you guide me how to do it? What I have tried is that since I don't know the number a so I substitute a number for a.","['number-theory', 'induction', 'modular-arithmetic', 'discrete-mathematics']"
1523593,Abelian group as direct product of its p-Sylow subgroups.,"I have read the Sylow 3 theorems, but I don't think I fully understand what they mean. Could someone help clarify them for me. Especially how they might apply to this question. Thanks.","['abstract-algebra', 'group-theory', 'finite-groups']"
1523604,Taylor Series and Differentiation with Sigma notation $f(x) = \frac{x}{(2-3x)^2}$,"Use Term By Term Differentiation to Find the Taylor Series about $x$=3 for 
Give The Open Interval of Convergence and express as sigma notation 
 $\sum A_n(x-3)^n$ $f(x) = \frac{x}{(2-3x)^2}$ So I have Found the Taylor Series for 1/(2-3x) to be $\sum{(-3)^{n}\cdot(x-3)^{n} }\cdot{(-7)^ {n+1}}$ How Do you find the original function taylor series and its interval of convergence and then express in sigma notation of the form  $\sum A_n(x-3)^n$","['taylor-expansion', 'summation', 'sequences-and-series', 'derivatives']"
1523614,Restriction of a dominant map,"Let $X$ be a variety over a field $k$, and suppose that we have a dominant map $\varphi: \mathbb{A}^{m} \dashrightarrow X$. Assume that $m > \dim(X)$. Then we can find a dense open set $U\subset \mathbb{A}^{m}$ such that $\varphi|_{U}$ is an open map whose fibers are $m-\dim(X)$ dimensional. Let $u\in U$ be a point. I would like to understand the next statement: If $u \in Z \subset \mathbb{A}^{m}$ is a hypersurface which does not
  contain the irreducible component of the fiber of $\varphi|_{U}$
  through $u$, then $\varphi|_{Z}: Z \dashrightarrow X$ is dominant. What is the geometric intuition here? Why does restricting a dominant map to a certain hypersurface preserve the dominance?",['algebraic-geometry']
1523622,Continuous function with compact domain has continuous inverse,"Let $A,B\subset\mathbb R$ and $f:A\to B$ be an invertible function (so 1-1 and onto). Prove that if $A$ is compact and $f$ is continuous, then the inverse $f^{-1}:B\to A$ is continuous. And give a counterexample when $A$ is not compact (no transcendentals). If $f$ is continuous, then for every sequence $\{x_n\}$ in $A$ that converges to $L$, $\lim_{n\to\infty}f(x_n)=f(L)$. We need to prove that for every sequence $\{y_n\}$ in $B$ that converges to $K$, $\lim_{n\to\infty}f^{-1}(y_n)=f^{-1}(K)$ (Is this sufficient to prove that $f^{-1}$ is continuous?), I'm not sure how to proceed from there, and I'm having trouble coming up with a counterexample as well.","['continuity', 'real-analysis']"
1523628,"Direct formula for area of a triangle formed by three lines, given their equations in the cartesian plane.","I read this formula in some book but it didn't provide a proof so I thought someone on this website could figure it out. What it says is:
If we consider 3 non-concurrent, non parallel lines represented by the equations :
$$a_1x+b_1y+c_1=0$$
$$a_2x+b_2y+c_2=0$$
$$a_3x+b_3y+c_3=0$$
Then the area of the triangle that these lines will enclose is given by the magnitude of :
$$\frac{det\begin{bmatrix}a_1 & b_1 & c_1\\a_2 & b_2 & c_2\\a_3 & b_3 & c_3\end{bmatrix}^2}{2C_1C_2C_3}$$
Where $C_1,C_2,C_3$ are the co-factors of $c_1,c_2,c_3$ respectively in the above matrix. What I'm wondering is, where did this come from? And why isn't it famous? Earlier we had to calculate areas by finding the vertices and all but this does it in a minute or so and thus deserves more familiarity.","['coordinate-systems', 'analytic-geometry', 'determinant', 'algebra-precalculus', 'geometry']"
1523636,The element that is an associate of everything.,"Suppose I have an integral domain $R$ containing an element $a \in R$ with the following property: $$(\forall r \in R)\, a \text{ is an associate of } r.$$ Is it true that the ring must be either the zero ring or the ring $\{0,1\}$? ""Associates"" are defined as follows: For $a,b \in R$, $a$ and $b$ are associates if $a \vert b$ and $b \vert a$. I used the equivalence relation: $$a \thicksim  b \stackrel{def}\iff \text{$a$ and $b$ are associates}.$$ This leaves us with $( R\big/\!\sim) = \{ 0 \}$, but that's not the same as saying $R$ is the zero ring... is it?","['abstract-algebra', 'ring-theory']"
1523674,Does $\sum_{i=1}^{\infty} i^{-p}a_i$ converge for some $p>1$ given that $\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{i=1}^{n}a_i$ converges?,"Given a non-negative sequence $a_i\geq 0$ and $\lim_{n\rightarrow\infty} \frac{1}{n}\sum_{i=1}^{n}a_i = a^* < \infty$. Can we show that, for some $p>1$,
$$ \lim_{n\rightarrow\infty} \sum_{i=1}^{n} i^{-p}a_i < \infty$$ I have tried using the one-sided limit comparison test as follows
$$\lim\sup_{i\rightarrow\infty} \frac{i^{-p}a_i}{n^{-1}a_i} \leq \lim\sup_{i\rightarrow\infty}\frac{i}{i^{p}} = \lim\sup_{i\rightarrow\infty} i^{1-p}=1$$
Is the above proof correct? I am tempted to conclude that my conjecture is correct and the second sequence converges. But what puzzles me is the value $n$ in the limit comparison test. Thanks in advance!","['sequences-and-series', 'real-analysis']"
1523687,"Find $P\left(X ≤ \frac12, Y≥\frac34\right)$. Joint Probability Density Function","Textbook: Mathematical Statistics with Applications Wackerly Let $X$ and $Y$ have the joint probability density function given by 
$$f(x,y) = \cases{6(1-y), \quad 0≤x≤y≤1 \\ 
0, \quad \text{elsewhere}}$$ Find $P\left(X ≤ \frac34, Y≥\frac12\right)$ The correct integral is supposed to be
$$\int_{1/2}^1\int_{1/2}^16(1-y)\text{ dy dx }+\int_{1/2}^{3/4}\int_{x}^{1}6(1-y)\text{ dy dx }$$ This makes no sense to me. Aren't we only interested in the small triangular region under the density function $f(x,y) = 6(1-y)$? This integral 
$$\int_{1/2}^{3/4}\int_{1/2}^{x}6(1-y)\text{ dy dx }$$ makes more sense to me.","['probability-theory', 'probability-distributions']"
1523689,Geometry question on square,$ABCD$ is a square and $AB$ = 1. Equilateral triangles $AYB$ and $CXD$ are drawn such that $X$ and $Y$ are inside the square.How can I find the length of $XY$ ?,['geometry']
1523694,Prove that in every sequence of 79 consecutive positive numbers written in decimal system there is a number whose sum of the digits is divisible by 13,"Prove that in every sequence of $79$ consecutive positive numbers written in decimal notation there is a number the sum of whose digits is divisible by $13$. I tried to take one by one sets of $79$ consecutive positive numbers. Then I tried to solve with sets,relation,function. But I am not getting any idea how to start solving the question.","['contest-math', 'number-theory', 'decimal-expansion', 'modular-arithmetic', 'pigeonhole-principle']"
1523698,"Let $A$ be an $8 \times 5$ matrix of rank 3, and let $b$ be a nonzero vector in $N(A^T)$. Show $Ax=b$ must be inconsistent.","Here's the entire question: Let $A$ be an 8 $\times$ 5 matrix of rank 3, and let $b$ be a nonzero vector in $N(A^T)$ . a) Show that the system $Ax = b$ must be inconsistent. Gonna take a wild stab at this one... If the rank is 3, that means the dimension of the column space is 3. But $A$ has 5 columns, so they are not all linearly independent and therefore $Ax = b$ is inconsistent. b) How many least squares solutions will the system $Ax = b$ have? Explain. On previous problems, I found the best least squares linear fit, where the approximation of $x$ was a vector that contained sometimes regular numbers, and sometimes variables. Does this mean that there must be either 1 linear solution or infinite (because you can always find an approximation)? In the example that apparently had an infinite number of least squares solutions, it appeared that one row of $A^TA$ was a constant multiple of another row, leading to a row of zeros in reduced row echelon form. From this problem I know that $A^TA$ is a 5x5 matrix, but I don't think I can prove that any rows are a scalar multiple of other rows, so I'm guessing I have to use some other means of figuring this out. Sorry if I sound like I have no idea what I'm talking about. Just wanted to try out the problem to my best ability before asking about it.","['transpose', 'matrices', 'least-squares', 'matrix-rank', 'linear-algebra']"
1523739,Find specific 4 curves touching $y=\cos10x+\cos21x$.,"The following is the graph of $y=\cos10x+\cos21x$. You can see that there seems to be four curves that can touch this graph. I tried $y=\cos(x/2+\pi/2\pm\pi)+1$ and $y=-\cos(x/2\pm\pi/2)-1$: But unfortunately, they cut the graph. What actually are that four curves touching the graph? Thanks.","['trigonometry', 'calculus', 'analytic-geometry', 'functions']"
1523741,Find $n$ sets such that $A_i\cap A_j\ne\emptyset$ and $A_i\not\subseteq A_j$,Can we find $n$ sets such that the pairwise intersection of any two is non-empty and no set is a subset of another? Here is an example for $n=4$:,['elementary-set-theory']
1523750,Is this sufficient to show that the partial sums converge?,"I am trying to show explicitly that the partial sums (for the series $\sum \frac{1}{j(j+1)}$ from j=1 to $\infty$) converge. Would it be sufficient to say that by looking at $\sum \frac{1}{j(j+1)}$ = $\frac{1}{j}-\frac{1}{j+1}$ and $\frac{1}{j}-\frac{1}{j+1} \rightarrow 0$ as $j \rightarrow \infty$? There is a theorem in the book that says that if $\sum a_j$ converges, then $a_j \rightarrow 0$ as $j \rightarrow \infty$, but I dont know if this is an iff condition that holds the other way.","['calculus', 'real-analysis', 'functions', 'sequences-and-series', 'convergence-divergence']"
1523755,"least common multiple of $\{1,2,...,n\}$ is bigger than $2^{n-1}$","The least common multiple of $\{1,2,...,n\}$ is greater than $2^{n-1}$ for any $n \ge 3$ . I found this in a MATHEMATICA book, but I don't know how to prove this. Can you help me? [Edit: This thread has a discussion of an asymptotic stronger result, but that relies on the Prime Number Theorem . What else is known about this? JL]","['number-theory', 'gcd-and-lcm', 'elementary-number-theory', 'inequality']"
1523783,Berkeley Problems in Mathematics 7.5.22,"This is the problem: Let $A$ be a real symmetric $n \times n$ matrix with non negative entries. Prove that $A$ has an eigenvector with non-negative entries I looked at the answer key and don't quite understand it. In the expression containing max, why should it correspond to the eigenvalue $\lambda_0$? I thought that this may be because if Ax is parallel to x, then the dot product between $Ax$ and $x$ is maximised, but is it not possible that it still attains a large value if $A$ transforms $x$ in a way that scales x by so much that Ax is large enough to make $\langle Ax,x\rangle$ large even though they may not be parallel? Solution(as in answer key): Let $\lambda_0$ be the largest eigenvalue of $A$. We have $$\lambda_0 = \max{\{\langle Ax, x\rangle\mid x\in\mathbb{R}^n,\|x\| = 1\}}$$ and the maximum it attains precisely when $x$ is an eigenvector of $A$ with 
eigenvalue $\lambda_0$. Suppose $v$ is a unit vector for which the maximum is attained, and let $u$ be the vector whose coordinates are the absolute values of the coordinates of $v$. Since the entries of $A$ are nonnegative, we have $$\langle Au,u \rangle \ge \langle Ax,x\rangle =\lambda_0$$ implying that $\langle Au,u\rangle = \lambda_0$, so that $u$ is an eigenvector of $A$ for the eigenvalue $\lambda_0$.",['linear-algebra']
1523820,We roll a six-sided die ten times. What is the probability that the total of all ten rolls is divisible by 6?,"So the question is really hard I think. I tried using a simple way by calculating the probability of each combination that makes a sum divisible by six, but it would take forever. Does anyone have any ideas? Suppose that we roll a six-sided die ten times. What is the probability
that the total of all ten rolls is divisible by six?","['dice', 'probability']"
1523829,Elementary proof that monotone functions are differentiable somewhere,"It is well-known that every monotone function $f : \mathbb{R} \to \mathbb{R}$ is differentiable almost everywhere (with respect to Lebesgue measure). It is also known if $E$ has measure $0$, then there exists a continuous, monotone function that is differentiable at no point of $E$. The proofs of these results, at least those I have seen, are a bit too technical for first-year calculus students to digest. On the other hand, I'm willing to settle for a much weaker result: Every monotone function is differentiable at some point. Is there an elementary way avoiding all measure theory, and preferably also avoiding Baire's theorem or other topological concepts that won't be familar to most calculus students showing this? Edit: to clarify, I'd like to avoid integrals too. See the motivating example further down. If we have the Riemann integral at our disposal, there are much simpler ways to define $x^y$ which gives differentiability with less effort. If you need to assume continuity to simplify the proof, that's ok. (One possible) motivation Let's try to define exponentiation $x^y$ for $x >0$, $y \in \mathbb{R}$.If $y$ is a positive integer, of course
$$ x^n = \underbrace{x \cdot x \cdots x}_{n~\text{times}}. $$
Assuming we have dealt with $q$:th roots of real numbers, the extension to rational exponents is also straight-forward:
$$ x^{p/q} = \big(\sqrt[q]{x}\big)^p $$
Finally, it's a little tedious, but not too bad to extend first to negative rational numbers $x^{-r} = 1/x^r$ and finally to real exponents by ""continuity"". Doing all this will give (for a fixed $x$) a continuous monotone function $f(y) = x^y$ satisfying the functional equation
$$f(y_1+y_2) = f(y_1)f(y_2).$$
How do we prove that this function $f$ is differentiable? (See Show $\lim\limits_{h\to 0} \frac{(a^h-1)}{h}$ exists without l'Hôpital or even referencing $e$ or natural log for an expanded version of this question.) Among the answers is a clever way to do it using convexity, but I'm still curious if it's possible to give an elementary solution by just exploiting monotonicity. If we can show that $f$ is differentiable at a single point, then the functional equation implies diffentiability everwhere.",['real-analysis']
1523832,One-to-one function's inverse,"I've been trying to solve this question for a while and couldn't find the correct way. We're looking for the inverse of the given function $r$ in terms of $f^{-1}$, where $r$ is defined by:
$$r(x) = 1 - 2f(3-4x).
$$ I've tried setting $r(x)$ equal to $h(f(3-4x))$ but couldn't solve it. If you have any solution please let me know.","['inverse', 'functions']"
1523842,Expectation value and conditional expectation,"I was wondering how the ordinary expectation value $E(X)$ is related to $E(X|\mathcal{F})$ where $\mathcal{F} \subset \mathcal{E}$ where the latter is supposed to be the sigma algebra on our probability space. My first thought was that $E(X|\mathcal{E}) = E(X),$ but this is clearly wrong, as $X$ is $\mathcal{E}$ measurable and thus $E(X|\mathcal{E})= X.$ Then I noticed that by the total law of expectation $E(E(X|\mathcal{F}))=E(X)$ we have something like a tower property for the standard expectation value, but in the sense that $E(.)$ wins over any $E(.|\mathcal{F}).$ Spoken in terms of tower properties, this would mean that if $E(X)$ can be represented as a conditional expectation, it must be a maximally small sigma algebra. So my guess is $E(X|\{\emptyset, \Omega\})=E(X),$ is this true? At first glance, it seems to fulfill all the properties of the conditional expectation, so my guess is yes, but I would like to have your confirmation.","['probability-theory', 'probability', 'stochastic-processes']"
1523862,Second order derivative of log of vector,I have a vector of size $n$ x $1$ named $\alpha$. Let $f(\alpha) = u\cdot\mathbf 1^{\!\top}ln(\alpha)$ where $u$ is scalar. What is the $f'(\alpha)$ and $f''(\alpha)$ and equivalent Matlab code? According to me the first derivative is $$f'(\alpha) = u/\alpha$$ and equivalent MATLAB code is -- f_a_1 = u ./ a and for the second derivative $$f''(\alpha) = u\cdot(Diag(\alpha)*Diag(\alpha))^{-1}$$ Equivalent MATLAB code is f_a_2 = u*inv(diag(a)*diag(a)) Is my inference correct?,"['calculus', 'matlab', 'matrix-calculus', 'matrices']"
1523877,"If $n$ is a square, can $n$ consist of only odd digits?","The question is: If $n$ is a square, can $n$ consist of only odd digits? I have a feeling that the answer is no, with the only exceptions being $n=1,9$. I am not sure how to go about proving this though. Any help or hints would be appreciated.","['number-theory', 'decimal-expansion', 'elementary-number-theory']"
1523893,How to evaluate $\lim_{q\to \infty} \left(\sum_{i=1}^m p_i^{q}\right)^{\frac{1}{1-q}}$?,Here is the problem. I have to compute the limit: $$ \lim_{q\to \infty} \left(\sum_{i=1}^m p_i^{q}\right)^{\frac{1}{1-q}}  $$ where $p_i$s are numbers from $0$ to $1$ and $\sum_{i=1}^mp_i=1$. I found that solution should be $\frac1{p_{max}}$ but I don't know why. Thanks a lot for your time.,"['summation', 'limits']"
1523928,A Bound for the Error of the Numerical Approximation of a the Integral of a Continuous Function,"How to numerically integrate a nasty function? Suppose $f$ is only continuos; which method can you employ to approximate $$\int_0^t f(s)ds$$ Since $f$ is continuos the integral exists, but all the numerical approximation methods I studied bound the error term with the hypothesis that $f$ is at least $C^2$ or something. I also know of the left rectangle method that only requires $f$ to be holder-continuos for some $\alpha$, but suppose this $f$ is not even Holder continuos. Can we find a meaningful error bound?","['real-analysis', 'definite-integrals', 'integration', 'analysis', 'numerical-methods']"
1523933,Sum of residues modulo $m$,"Let $c_1,c_2,\ldots,c_{\varphi(m)}$ be the reduced residue set modulo $m>2$. Show that $$c_1+c_2+\cdots+c_{\varphi(m)} \equiv 0 \pmod{m}.$$ My solution looks something like this. If $c_i \in {\mathbb{Z}_m}^*$, then $m-c_i \in {\mathbb{Z}_m}^*$. Hence, we may take the reduced residue system $$\{c_1,c_2,\ldots,c_{\varphi(m)/2},m-c_{\varphi(m)/2},\ldots,m-c_2,m-c_1\}.$$ Hence, 
\begin{align} 
c_1+c_2+\cdots+c_{\varphi(m)} &= c_1+c_2+\cdots+c_{\varphi(m)/2}+m-c_{\varphi(m)/2}+\cdots+m-c_2+m-c_1 \\
&=m \cdot \varphi(m)/2 \equiv 0 \pmod{m},
\end{align} since $\varphi(m)$ is even for $m >2$. Is this on the right track?","['number-theory', 'elementary-number-theory']"
1523996,How to evaluate $\int\sqrt[3] {\frac{1}{(x+1)^2(x-1)^4}} dx$?,"My integral is
$$I=\int\sqrt[3] {\frac{1}{(x+1)^2(x-1)^4}} dx$$
and hence
$$I=\int\frac{1}{(x-1)(x+1)}\sqrt[3] {\frac{x+1}{x-1}}dx $$
$\cos2\theta$ substitution wont be helpful here because of the cube root. Should I apply by parts ?","['calculus', 'indefinite-integrals']"
1523998,geometry question on areas in arcs,PS is a line segment of length 4 and O is the midpoint of PS. A semicircular arc is drawn with PS as diameter. Let X be the midpoint of this arc. Q and R are points on the arc PXS such that QR is parallel to PS and the semicircular arc drawn with QR as diameter is tangent to PS. How can I get the area of the region QXROQ bounded by the two semicircular arcs?,['geometry']
1524025,"Why is the dimension of a kernel with the basis $\{[0,0,0]\}$ equal to zero","What is the dimension of a kernel with the basis $\{[0,0,0]\}$ ? I'm confused because the definition of the dimension is number of vectors in a basis. So there is $1$ vector here which is $[0,0,0]$ . Why does my professor say that the dimension of kernel is zero? He mentioned something about the zero vector space.","['vector-spaces', 'linear-algebra', 'discrete-mathematics']"
1524038,Cycles of equally spaced points on a circle,"Take $n$ equally spaced points on a circle. Connect them by a cycle(circuit) with $n$ line segments. Two cycles are considered equivalent if same when rotated or reflected. How many cycles are there? It can also be viewed as integer sequence. Take an integer sequence $a_i(1 \leq i \leq n, \: 1 \leq a_i \leq n, \: a_i \neq a_j)$. Two sequences $a_n, \: b_n$ are considered equivalent if there exists some integers $k, \: l$ such that $a_i \equiv b_{i+l \bmod n}+k(\bmod n)$ or $a_{i+l} \equiv -b_{i+l \bmod n}+k(\bmod n)$","['sequences-and-series', 'geometry', 'combinatorial-geometry', 'combinatorics']"
1524059,When is $\bigl( \frac{a}{b} \bigr)^{3} \pm \bigl( \frac{x}{y}\bigr)^{3}$ an integer?,"I am trying solve this form, but it appears not easy problem, and also I can't find references about it. I suppose some constrains should be stated, like "" $b,y > 1$ "" and "" $\gcd(a,b) \gcd(x/y) = 1$ "" . Here some examples $$
\left( \frac{17}{21} \right)^{3} + \left(\frac{37}{21} \right)^{3} = 6
$$ $$
\left(\frac{73}{38} \right)^{3} - \left( \frac{17}{38}\right)^{3} = 7
$$ Example with two solutions $$
\left(\frac{36}{13}\right)^{3} - \left(\frac{17}{13}\right)^{3} = \left( \frac{109}{31}\right)^{3} - \left(\frac{90}{31}\right)^{3} = 19
$$ Solutions to this problem seems to be scarce, so can any integer be written in this form? Thanks ******** edited feb 22 2020 ************************************ Now turning to this question.
I do not know if these formulas are known (probably yes), but since I have not seen them in books or publications, they could be of interest for someone. I found that the equation $a^3 + b^3 = n.c^3$ can be solved in many cases immediately if this much simpler one can also be solved $s^2t + t^2s = st(s+t) = n.k^3$ ....... [A] having the gift that now k = 1 is not a trivial solution, but a very valid one Once resolved (A) we immediately have this form to help $[2(s-t)^3 + 18s^2t]^3 + [-2(s-t)^3 + 18st^2]^3 = st(s+t)[6(s^2+st+t^2)]^3$ ....... [B] When k>1 in [A], $k^3$ goes into the right parenthesis in [B] isolating n In this way, all $n = st(s+t)$ are immediately solved, and most difficult cases remains when it is necessary find value of $k^3$ to reduce n . Example for s=7, t=3 -> $n=3.7(3+7)=210$ $(2(7-3)^3+18.7^2.3)^3 + (-2(7-3)^3+18.7.3^2)^3 = 210.(6(7^2+7.3+3^2))^3$ = $2774^3 + 1006^3 = 210 . 474^3$ dividing all greater common divisor $gcd(2774,1006)^3 = 8$ we have $1387^3 + 503^3 = 210.237^3$ I didn't find a simple way to solve (A) for all n , especially when the value of k is very large, but for small k the work is still easy. For example n = 13 has no immediate solution in [A] but it has for $n = 13.42^3 = 343.8(343+8)$ s=343, t=8, $n = 13.42^3$ , replacing s, t in [B] produces $92132206^3 - 74795614^3 = 13.42^3.722742^3$ dividing by $gcd(921322206,74795614)^3 = 8$ we have $4606103^3 - 3739780^3 = 13.(42.361371)^3$ RECURSION From [B] we have a recursive formula to find infinite solutions. In effect, the above solution was possible because we already knew there was a previous solution $7^3+2^3 = 13.3^3$ So if $Uj^3 + Vj^3 = n.Bj^3$ then s=Uj, t=Vj and we have $n = Uj^3.Vj^3.(Uj^3+Vj^3)$ and substituting in [B] $Uj+1^3 + Vj+1^3 = n.(Uj.Vj.Bj+1)^3$ (please somebody could help me to post j and j+1 values as subscripts?) which is the example mentioned above NOTES: 1) The formula in [B] generally cannot produce the simplest results for n, for example $5^3 + 4^3 = 7.3^3$ , or $7^3 + 2^3 = 13.3^3$ . Maybe these simpler results could be achieved by using complex numbers s=a+bi, t=c+di , but I found a bit difficult to solve this way. 2) In a table for n up to 100 , I was unable to solve [B] ​​for n = 31,67,71,89 which indeed have solutions $31 = (137/42)^3 + (-65/42)^3$ $67 = (5353/1323)^3 + (1208/1323)^3$ $71 = (53/13)^3 + (36/13)^3$ $89 = (197/43)^3 + (-126/43)^3$ Tested values ​​were s, t <= 10,000 Thanks for any comment.",['number-theory']
1524064,Derivative of the integral with respect to the function,"Consider this function:
$$ E[L] = \int\int\{ y(x) - t \}^2p(x,t)dx dt $$ I try to figure out how to take the derivate of this function with respect to $y(x)$.
In the book it is:
$$ \frac{ \delta E[L] }{ \delta y(x)} = 2 \int \{ y(x) - t\}p(x,t)dt $$ This I cannot understand. My initial thought was to use chain-rule of the derivative and push derivative operator under integral, but I cannot achieve the same result. Thanks in advance!","['derivatives', 'calculus', 'integration']"
1524077,Union and sum of ideals is not ideal,"For the union case, I'm trying $2\mathbb Z \cup3\mathbb Z$, the two are ideal of $\mathbb Z$ but in their union, when I multiply some element of $\mathbb Z$ by $2\mathbb Z \cup3\mathbb Z$ I still get it inside the union. However, I think that the union cannot be a subring, since $2+3 = 5$ which is not in the union, therefore one of the axioms broke. Is my reasoning right? I showed a counter example therefore it shouldn't be true. For the sum case, It's harder, because I cannot do it in the way I did for the union. Any ideas?","['abstract-algebra', 'group-theory', 'ring-theory']"
1524097,Existence of a section of non-zero measure,"Let $X$ and $Y$ be measurable spaces, and $A \subseteq X\times Y$ is a measurable subset of the product space. For any $y\in Y$ let $A_y = \{x\in X: (x,y)\in A\}$ be the $y$-section of $A$. Under which condition for any probability measure $p$ on $X$ there exists $y\in Y$ such that $p(A_y) > 0$? Motivation: I was thinking of a zero-sum game with a payoff of $(p\otimes q)(A)$, and would like to consider cases when neither of players can fix this measure to be $0$ over $A$ just by choosing his own marginal measure. What I did: For simplicity I assume that any singleton is measurable. Necessary condition is that $A$ has the full projection, otherwise on can put $p$ to be a Dirac measure outside of projection of $A$. Furthermore, let's sat that $A$ has a countably complete projection property (CCPP) if there exists $y_1, y_2, \dots\in Y$ such that $\bigcup_n A_{y_n} = X$. Clearly, CCPP is a sufficient condition, e.g. if $X$ is Lindelof and $A$ has full projection and open sections. This condition is not necessary, though. For example, consider $X = Y = [0,1]$, and let $A_y = F + y$ where $C$ is a nowhere dense set with positive Lebesgue measure. Here $+$ is a cyclic shift addition over $[0,1]$. Then any countable union of $A_y$ is nowhere dense again , hence never $X$ itself. At the same time, one can use Fubini's theorem to show the desired property. What I expect from the bounty: answer to the original question - Under which condition for any probability measure $p$ on $X$ there exists $y\in Y$ such that $p(A_y) > 0$? I am looking for a complete/partial characterization besides the fact already stated here, or a reference on the subject.","['probability-theory', 'descriptive-set-theory', 'measure-theory']"
1524109,"Prove that if each row of a matrix sums to zero, then it has no inverse.","Could anyone help me with this proof without using determinant? I tried two ways. Let $A$ be a matrix. If $A$ has the property that each row sums to zero, then there does not exist any matrix $X$ such that $AX=I$, where $I$ denotes the identity matrix. I then get stuck. The other way was to prove by contradiction, and I failed too.","['inverse', 'linear-algebra', 'matrices']"
1524134,The number of self normalizing subgroup in $G$,"Let $G$ be a group define $f(G)$ be the number of proper subgroups  with the property $N_G(H)=H$. We can say $G$ is nilpotent if and only if $f(G)=0$. Hence, we can think that when $f(G)$ increase then $G$ beceomes far away from being nilpotent. I wonder is there any good bound $k$ for $G$ such that $f(G)\leq k\implies G$ is solvable. Edit: By the way it is easy to show  that if $G$ is not nilpotent then $f(G)>2$.","['abstract-algebra', 'group-theory', 'finite-groups']"
1524157,"Independent coin tosses , double or halve current sum","(Quant job Interviews - Questions and Answers - Joshi et al, Question 3.5) Suppose you have a fair coin. You start with 1 dollar, and if you toss a H your position doubles, if you toss a T your position halves. What is the expected value of the money you have if you toss the coin to infinity ? Now the answer is stated as follows: We work out what happens with one toss, then $n$ tosses and then let $n$ tend to infinity.

Let $X$ denote a toss then: $$\mathbb E (X) = \frac{1}{2} \cdot 2 + \frac{1}{2} \cdot 0.5= {5\over4} $$ Provided the tosses are independent, the product of expectations is the expectation of the product. Let $X_j$ be the effect of toss $j$ . This means that $$ \mathbb E \left(\prod_{j=1}^n X_j\right) = \prod_{j=1}^n \mathbb E (X_j) = \left({5\over4}\right)^n$$ this clearly tends to infinity as $n$ tends to infinity Now, I don't understand this answer :( First, the way the answer is written out, surely the ${5\over4}$ is the expectation of the outcome of the first toss $X_1$ , not that of a toss $X_j , j \ge 1$ ? Secondly, whilst I do understand that the tosses are independent, it would seem that the $X_{j+1}$ is actually quite heavily dependent on the $X_{j}$ before it ? So then why is it so obvious that $\mathbb E ( X_{j+1} ) = \mathbb E ( X_j)$ ?","['probability', 'expected-value']"
1524185,When is $\binom{n}{k}$ divisible by $n$?,Is there any way of determining if $\binom{n}{k} \equiv 0\pmod{n}$.  Note that I am aware of the case when $n =p$ a prime.  Other than that there does not seem to be any sort of pattern (I checked up to $n=50$).  Are there any known special cases where the problem becomes easier?  As a place to start I was thinking of using $e_p(n!)$ defined as: $$e_p(n!) = \sum_{k=1}^{\infty}\left \lfloor\frac{n}{p^k}\right \rfloor$$ Which counts the exponent of $p$ in $n!$ (Legendre's theorem I believe?) Then knowing the prime factorization of $n$ perhaps we can determine if these primes appear more times in the numerator of $\binom{n}{k}$ than the denominator. Essentially I am looking to see if this method has any traction to it and what other types of research have been done on this problem (along with any proofs of results) before.  Thanks!,"['binomial-coefficients', 'number-theory', 'modular-arithmetic', 'combinatorics', 'divisibility']"
1524235,Ranges of projection operators,"Suppose that $X$ is a Banach space and $P$ and $Q$ be bounded linear projections on $X$ such that $PQ$ and $QP$ are compact. Does it follow that $PQ$ and $QP$ are finite-rank operators? My attempt: I claim that both $PQ$ and $QP$ have closed range so if the range of one of them were not finite-dimensional, we would find a bounded sequence in it without a convergent subsequence. Is it fine? If so, can we find a projection $R$ with finite-dimensional range such that $PQ$ and $QP$ commute on the image of $I-R$?","['operator-theory', 'banach-spaces', 'functional-analysis']"
1524246,Why are the coefficients of the equation of a plane the normal vector of a plane?,"Why are the coefficients of the equation of a plane the normal vector of a plane? I borrowed the below picture from Pauls Online Calculus 3 notes: http://tutorial.math.lamar.edu/Classes/CalcIII/EqnsOfPlanes.aspx And I think the explanation he provides is great, however, I don't understand how one of the concepts work. If the equation of a plane is $ax+by+cz=d$ how is it that $\overrightarrow n = \langle a,b,c \rangle$?  From the picture below I suppose I can see this since $\overrightarrow r_0$, if continued past the plane, would clearly be perpendicular, but what about $\overrightarrow r$?  That one is clearly not perpendicular if extended past the plane? Sorry if what I'm asking is confusing.","['plane-geometry', 'vectors', 'calculus', 'multivariable-calculus']"
1524311,What is the relation between the structure group and fundamental group of an affine manifold?,I have picked up a vague idea that the structure group of transition functions between coordinate charts on an affine manifold is specified by a representation of it's fundamental group. Could someone please say why and how?,"['algebraic-geometry', 'differential-geometry', 'general-topology']"
1524315,"Evaluating $\int\frac{x^4}{x-1} \, dx$","This question involves long division. I calculated the value. However, I want to ask two concept questions: 1) Why am I doing long division rather than writing out the form of the partial fraction decomposition of the function. 2) When utilizing long division do I place a constant at the end and if not why? Here is my set up $\dfrac{x^4+0x^3+0x^2+0x+1}{x-1}$","['calculus', 'indefinite-integrals', 'integration']"
1524328,If X is simply-connected then any two paths are homotopic via a homotopy relative to the points where they agree,"Let $X$ be a simply-connected space and $f,g:I\to X$ two paths with the same endpoints and $A=\{s\in I:f(s)=g(s)\}$. Since $X$ is simply-connected there is a homotopy $F:I\times I\to X$ relative $\{0,1\}$. The question is: can we pick $F$ relative $A$? I've tried considering the open set $I-A$ which is a countable union of disjoint segments $(a_n,b_n)$. Then one can get a homotopy $F_n:[a_n,b_n]\times I\to X$ from $f|[a_n,b_n]$ to $g|[a_n,b_n]$. One may try to glue all these homotopies (or some sort of modifications) $F_n$ to get $F:I\times I\to X$ (which is defined to be $f(s)$ in $A\times I$) but I'm not sure if $F$ ends up being continuous. Note that this is true for $X\subseteq R^n$ any convex set (just take the linear homotopy). I'm particularly interested in the case where $X=S^2$.","['algebraic-topology', 'general-topology']"
1524330,Intuition behind $\text{Re}(z)$ not being analytical,"Is there any way to ""see"" the reason for which the $\text{Re}(z)$ is not analytical? Edit: what I need is intuition(and maybe something graphic) and not definition of analytic function. So, the question is, why isn't $\text{Re}(z)$ analytic(does not satisfy the definition of an analytic function)?","['complex-analysis', 'real-analysis', 'complex-numbers']"
1524337,Is there a Rellich-Kondrachov theorem for manifolds with boundary?,"As special case, consider the cylinder $C=[0,T]\times S^n$. Is there a compact embedding $H^1(C)\subset\subset L^2(C)$? The Wikipedia entry to the Rellich-Kondrachov theorem claims that such an embedding exists for every compact manifold with $C^1$ boundary, but does not give a reference, nor clarifies what is meant by a compact manifold. But this is crucial since most books don't treat manifolds with boundary. Is there a good reference that treats the case I need?","['sobolev-spaces', 'differential-geometry', 'reference-request']"
1524410,Computing Lie derivative,"Can anyone help me with computing Lie derivative ${L}_{X}Y$ using its definition for these two vector fields: $X=y\frac{\partial}{\partial x}-x\frac{\partial}{\partial y}, Y=x^2\frac{\partial}{\partial x}$ ? I know how to find it using definition of Lie bracket but I don't quit understand definition of Lie derivative and I can't find anywhere simple example showing how it should work.","['differential-geometry', 'differential-forms', 'lie-derivative']"
1524415,Globally Lipschitz if and only if derivative is bounded?,"If I have a function $f:\mathbb R\to\mathbb R^n$ I can say that it is globally Lipschitz in $t$ if its Jacobian is bounded in $t$. However, does it work the other way around? If I find that the function Jacobian is not bounded, does this mean that the function is not globally Lipschitz?","['lipschitz-functions', 'real-analysis', 'derivatives']"
1524424,Prove that the average of iid Gaussian random variables is Gaussian,"Given $x_1, \ldots, x_N$, independent and all distributed as a
  Gaussian with mean $\mu$ and variance $\sigma^2$. Then, the average
  $$\bar{x} = \frac{1}{N}\sum_{i=1}^Nx_i$$ is distributed as a Gaussian
  with mean $\mu$ and variance $\frac{\sigma^2}{N}.$ This is a very well-known result. Anyway, I'm looking around to find a proof for this and I'm not having luck.","['probability', 'statistics']"
1524434,Solving an autonomous ODE with discontinuous right hand side,"I am trying to solve the following ODE, which looks very simple but it has discontinuous RHS. $$\dot{x}(t)=-x+f(x)$$  where $$f(x)=\begin{cases}1 \quad\text{ if } x>c \\ 0 \quad\text{ if }  x<c \\ z \quad\text{ if } x=c\end{cases}$$ 
 where $z$ is a constant between $0$ and $1$. The initial condition is $x(0)=0$. So first, I don't know there is a unique solution to this ODE. Second, how to solve this ODE? I have an approach, which is: I use a piece-wise linear Lipschitz continuous function $g$ to approximate this $f$, then I solve for $\dot{x}(t)=-x+g(x)$, then I let $g$ goes to $f$, to see the limit of the solution to $\dot{x}(t)=-x+g(x)$, then I claim this is the solution to $\dot{x}(t)=-x+f(x)$. This makes sense intuitively, but I was wondering how to make this rigorous, I guess eventually, I need to first know whether $\dot{x}(t)=-x+f(x)$ has unique solution and another question is, if I use a different continuous function $g_1$ which is not $g$, to approximate $f$, then via the same limiting procedure, will I get a different limit?",['ordinary-differential-equations']
1524444,Connection between rank and positive definiteness,"I would like to know, is there a connection between the rank of a matrix and whether it is positive definite? Specifically, if I can prove that a matrix is not full rank, then can I say that it is not positive definite? If so, why? Thanks a lot for your help.","['positive-definite', 'matrix-rank', 'linear-algebra', 'matrices']"
1524473,How many ways can $32$ cards be distributed so that three players receive $10$ cards each?,"A card deck consists of 32 cards. Three players play together and get 10 cards each. The remaining cards form the extra deck, used during the game.
How many distributions of the deck exist? my answer: $$\binom{32}{10} \binom{22}{10} \binom{12}{10} \binom{2}{2}$$ but the answer is very big, am i missing something here? any hints? thanks","['discrete-mathematics', 'combinatorics']"
1524482,Proving the closed form of $\sin48^\circ$,"According to WA$$\sin48^\circ=\frac{1}{4}\sqrt{7-\sqrt5+\sqrt{6(5-\sqrt5)}}$$ What would I need to do in order to manually prove that this is true? I suspect the use of limits, but I don't know where to start.","['closed-form', 'proof-writing', 'trigonometry']"
1524484,Does $Z_n=\sum_{k=1}^{n}\sqrt{k}X_k$ satisfy the strong law of large numbers if $ X_n...$,"Does $Z_n=\sum_{k=1}^{n}\sqrt{k}X_k$ satisfy the strong law of large numbers if $ X_n: \begin{matrix}-\frac{1}{n} & \frac{1}{n} \\ \frac{1}{2} & \frac{1}{2} \end{matrix}, n=1,2,...$ are independent random variables. I have the following theorems, but I cannot prove this, I have tried all which I understand, the theorems I have are: 1.) Strong Law of large numbers states that the sequence $X_1,X_2,...$ must satisfy: $$\frac{1}{n}\sum_{k=1}^{n}(X_k-EX_k)\to^{a.s.}0, n\to \infty$$ 2.) Kolmogorov Law: If $(X_n)$ independent random variables, such that $\sum_{n=1}^{\infty} \frac{\text{Var}(X_n)}{n^2}<\infty$, then the strong law of large numbers is satisfied. 3.)Borels:  If $ S_n:\mathcal B(n,p)$ (binomial distribution), then $$\frac{S_n}{n}\to^{a.s.}p, n \to \infty$$ or the consequence: Let $X_n$, sequence of independent random variables, equally distributed, such that $EX_k=a$ and $\text{Var}X_k= \omega^2, k=1,2,3... \implies$ $$\frac{1}{n}\sum_{k=1}^{n}X_k\to^{a.s.}a, n\to \infty$$","['probability-theory', 'probability', 'random-variables', 'law-of-large-numbers']"
1524489,Whats the domain of the sample average in Strong Law of Large Numbers?,"The strong law of large numbers states that the sample average converges almost surely to the expected value $\overline{X}_n\ \xrightarrow{\text{a.s.}}\ \mu \qquad\mathrm{when}\ n \to \infty$ . That is,$$\Pr\left( \lim_{n\to\infty}\overline{X}_n = \mu \right) = 1.$$ I want to ask whats the domain of the random variable $\overline{X}_n$, given that all $X_n$ have same domain $\Omega$? For the coin tossing problem $\Omega =\{H,T\} $ and $X_n(H)=1 \quad and \quad X_n(T)=0 \quad\forall n $ so, if the domain of $\overline{X}_n$ was $\Omega$ the $\overline{X}_n(H)=1 \quad \overline{X}_n(T)=0 \quad \forall n$, so $\Pr\left({\omega \in \Omega : \overline{X}_n(\omega)=1/2}\right)=0$ , which is not what strong law says. I want to know whats the domain of this random variable $\overline{X}_n$?","['probability-theory', 'probability', 'probability-limit-theorems', 'law-of-large-numbers']"
1524517,Let G be a group of order $2^n$ for $n\geq 2$. Show that G has at least $4$ conjugacy classes,"Let $G$ be a group of order $2^n$ for $n\geq 2$. (A) Show that $G$ has at least 4 conjugacy classes; (B) Show that if $G$ has exactly 4 conjugacy classes, then $n = 2$ or $n = 3$ For the case of $n=2$ Order of G is $2^2=4$
By corollary (Dummitt and Foote pg.125) If G is a group of order $p^2$ where $p$-prime,
then $G$ is abelian. So for the case of $n=2$,
$G$ is abelian, and so the singletons $\{a\}$ for a in $G$ are the conjugacy classes. Thus there are $4$ conjugacy classes. This is all I have. I have no idea how to go for $n=3$ and there on.","['abstract-algebra', 'group-theory']"
1524526,2-Norm of a Submatrix is $\leq$ 2-Norm of Original Matrix,"Say $A$ is a submatrix of $B$. How do I prove that the $\|A\|_2 \leq \|B\|_2$?
I can easily show this for $\|\cdot\|_1, \|\cdot\|_\infty, $ and $\|\cdot\|_F$ and thought maybe the solution lies in relating the inequalities of these other norms to the 2-norm, but this path hasn't proved fruitful.",['linear-algebra']
1524534,Writing real numbers as sums of zeros and ones,"Call a number $\delta\in(0,1)$ ""good"" if it satisfies the following property: Every real number $a\in(0,1)$ can be written as an infinite sum of the form:
  $$a = \sum_{i=1}^\infty \delta^i a_i$$
  where $a_i\in\{0,1\}$. What numbers are good? I know that $1/2$ is good, since when $\delta=1/2$, the $a_i$ are just the digits in binary representation of $a$. On the other hand, $1/3$ is not good, since in order to represent a real number in ternary, we also need the digit 2. It is easy to prove that every $\delta<1/2$ is not good, since the maximum number that can possibly be represented is $\frac{\delta}{1-\delta}$, and it is strictly smaller than 1. My conjecture is that every $\delta\in [1/2,1)$ is good. Is this true?","['sequences-and-series', 'real-analysis']"
1524540,"In a group of 4 people, is it possible for each person to have exactly 3 friends?","In a group of 4 people, is it possible for each person to have exactly 3 friends? Why? My solution n Let G be a graph with 4 vertices, one vertex representing each person in the group.
Join two vertices u and v by an edge if and only if u and v are friends. Then the degree of
each vertex equals the number of friends that the corresponding person has. If each person
has exactly 3 friends, then each vertex has degree 3. Therefore, the total degree would be
3 · 4 = 12. This is an even number. $n\equiv 0\pmod{2}$ and $n>3$ So It is possible. Is this correct?","['discrete-mathematics', 'graph-theory', 'combinatorics']"
1524541,Relation between Bombieri theorem and p-adic squares,"Koblitz states in his book on p-adic numbers on page 84: Suppose that $\alpha \in \mathbb Q$ is such that $1 + \alpha$ is the square of a nonzero rational number $a/b$.
  Let $S$ be the set of all primes $p$ for which the binomial series for $(1 + \alpha)^{1/2}$ converges in $|\cdot|_p$.
  There is no $\alpha$ other than $8$, $16/9$, $3$, $5/4$ for which $(1 + \alpha)^{1/2}$ converges to the same value in $|\cdot|_p$ for all $p \in S$. Why is this an example of a very general theory of E. Bombieri? What does the theory (or theorem) say and what are its possible connections with p-adic numbers? Is it the Bombieri–Vinogradov theorem from analytic number theory?","['p-adic-number-theory', 'number-theory', 'analytic-number-theory']"
1524581,"If $f:[a,b]\to \mathbb{R}$ satisfies $|f'(x)|<1, \forall x\in [a,b]$, is $f$ necessarily a contraction?","If $f:[a,b]\to \mathbb{R}$, $f'(x)$ exists for all $x\in [a,b]$ (derivatives at endpoints $a,b$ are one-sided) and satisfies $|f'(x)|<1, \forall x\in [a,b]$, is $f$ necessarily a contraction (i.e. $|f(x)-f(y)|\leq c|x-y|$, for some $0<c<1$)? I've tried to prove it by contradiction. Define $E=\left\{\dfrac{|f(x)-f(y)|}{|x-y|}: x\neq y\in [a,b]\right\}\neq \emptyset$. By mean value theorem, $|f(x)-f(y)|<|x-y|,\forall x\neq y\in [a,b]$. Therefore, $E$ has an upper bound $1$, hence the least upper bound $s=\sup E\leq 1$. Suppose that $s=1$, take $\epsilon_n=\dfrac{1}{n}$, we can find $a_n=\dfrac{|f(x_n)-f(y_n)|}{|x_n-y_n|}\in E$ such that $1-\dfrac{1}{n}<a_n<1$, thus a sequence $\{a_n\}$ with limit $1$. For the two sequences $\{x_n\},\{y_n\}$, with $x_n<y_n$. According to Bolzano-Weierstrass Theorem, there exist subsequences $\{x_{n_k}\},\{y_{n_k}\}$ converging to $x_0,y_0$,respectively. If $x_0\neq y_0$，then since $a_{n_k}$ converges to $1$, we can obtain $\dfrac{|f(x_0)-f(y_0)|}{|x_0-y_0|}=1$, which is a contradiction. The proof gets stuck at the case $x_0=y_0$. Since the following proposition may fail to hold if $x_n<x_0=y_0<y_n$ doesn't hold. If $x_n<x_0<y_n$, both $\{x_n\},\{y_n\}$ converge to $x_0$ and $f'(x_0)$ exists, then $\lim\limits_{n\to\infty}\dfrac{f(x_n)-f(y_n)}{x_n-y_n}=f'(x_0)$. And now I don't know whether the original proposition holds. If we add the condition that the derivative $f'$ is continuous on $[a,b]$, then by the maximum value theorem, $f$ is surely a contraction. So, if there is any counterexample, then $f'$ must be discontinuous. Since some text requires a contraction maps a space into itself, how about adding this as a condition, i.e. consider $f:[a,b]\to [a,b]$?","['examples-counterexamples', 'real-analysis']"
1524603,If $A$ is closed and $B$ is compact in $\mathbb R^n$ then $A+B=\{a+b : a \in A \text{ and } b \in B\}$ is closed.,"If $A$ is closed and $B$ is compact in $\mathbb R^n$ then $A+B=\{a+b : a \in A \text{ and } b \in B\}$ is closed. (In other words, the vector/Minkowski sum of a closed set and a compact set is closed.) What I've tried so far: 
Let $ c_n $ be a sequence in $A+B$; $c_n =a_n+b_n$ where $a_n \in A$ and $b_n \in B$. Since $B$ is compact, there exists a subsequence $(b_{n_k})$ which converges $b$ which is in $B$. Now I'm stuck in how to show that the subsequence  $(a_{n_k})$ converges to some number in $A$ so that $(c_{n_k})$ converges to the sum of two limits in $A+B$.","['sumset', 'real-analysis', 'compactness']"
1524691,Are all solutions of $ f_n (x)^{2n} + f_n ' (x)^{2n} = 1$ periodic?,"Let $n$ be a strict positive integer and $x$ is a complex number.
Define $f_n(x)$ as one of the solutions to $$ f_n (x)^{2n} + f_n ' (x)^{2n} = 1$$ Where the derivative is with respect to $x$. Why is every entire solution $f_n(x) $ periodic on the complex plane ? For instance the solutions for $f_1(x)$ are ${-1, 1, -\sin(x),\sin(x),-\cos(x),\cos(x)}$.
All of them are periodic with period $2 \pi$. I assume implicit differentiation helps.","['periodic-functions', 'implicit-differentiation', 'square-numbers', 'ordinary-differential-equations']"
1524724,"If the derivative of a function is zero, is the function a constant function?","If the derivative of a function is zero, is the function then  a constant function ? I think it is not true, because if f in the sub interval be constant function then derivative of $f$ is zero, is it true?","['analysis', 'real-analysis']"
1524752,Trigonometric problem?,"This may be really easy but is giving a hard time. I'm a beginner at trigonometry so hope I can understand it. If $\sin{\frac{x}{2}}+\cos{\frac{x}{2}}= 1.4$, then $\sin{x}=?$ If $\sin{a}-\cos{a}=a$, then $\sin(2a)=?$",['trigonometry']
1524761,When can infinite regular graphs be embedded in the plane?,"An infinite $r$-regular graph is a graph with $\infty$ vertices where each vertex touches precisely $r$ edges. We say an $r$-regular graph can be embedded in the $R^2$ Euclidean plane if its set of edges and vertices can be represented as a set of points on the plane where each point is connected via an edge to precisely the $r$ closest points to it. For example, some $4$-regular graphs can be embedded in the plane by placing each vertex of the graph on a unique point $(m,n)$ on the plane where $m$ and $n$ are integers. Some $8$-regular graphs can be embedded using the same placement. The question is: for what values of $r$ do there exist connected $r$-regular graphs that can be embedded in the plane? The graphs need not be planar, but an answer dealing with the planar case is welcome.","['discrete-mathematics', 'graph-theory', 'geometry', 'discrete-geometry', 'recreational-mathematics']"
1524797,Can a sum of three fifth power of integers be 8?,"With $a,b,c \in \mathbb{Z},$ by congruence computation we get that $n= a^5+b^5+c^5$ implies $n \not \equiv  4,5,6,7  \pmod{11} $ . For $a,b,c \in \{-100,-99, \dots , 99, 100\}$ , the set of integers $n \in \{0,1,\dots , 99,100 \}$ we get is $$\{ 0, 1, 2, 3, 12, 30, 31, 32, 33, 34, 63, 64, 65, 96 \}$$ The smallest non-obvious solution being $n=12$ , $$13^5 + 16^5 - 17^5 = 12$$ The point is that it is exactly the same for $a,b,c \in \{-10000,-9999, \dots , 9999, 10000\}$ , so that we could expect that there is no other natural number $n \le 100$ representable like that. Nevertheless according to what happens for cubes (see here ), we could also expect the existence of such representations with large integers. By the congruences above, the smallest natural numbers to look is $n=8$ . Question: Can a sum of three fifth power of integers be $8$ ? Next we should look to $n = 9,10,11,13,14,19,20,21,22,23,24,28,29, \dots$","['number-theory', 'diophantine-equations']"
1524854,Understanding theorem $9.21$ from Rudin -- Partial Derivatives.,"Let's say that $f: E \subset \mathbb{R}^n \to \mathbb{R}^m$, where $E$ is an open set,  is continuously differentiable if $f'$ is a continuous mapping of $E$ into $L(\mathbb{R}^n,\mathbb{R}^m)$, and denote the set of such functions by $\mathcal{C}'(E)$. Now, consider the following theorem: Suppose $\mathbf{f}$ maps an open set $E \subset \mathbb{R}^n$ into
  $\mathbb{R}^m$. Then $f \in \mathcal{C}'(E)$ if and only if the
  partial derivatives $(D_jf_i)$ exist and are continuous on $E$ for $1
> \leq i \leq m$ and $1 \leq j \leq n$. $f \in \mathcal{C}'(E)$ means
  class of continuous differentiable functions with domain $E$. This is theorem $9.21$ of Rudin 3rd edition (page $219$). I am having trouble understanding the proof. For the $\implies $ side of the proof, I do not understand where they use the assumption that $f \in \mathcal{C}'(E)$ as well as how they form the first inequality. For the $\Leftarrow$ implication, I definitely do not follow the argument given. Can anyone break down what is going? I would definitely appreciate help in understand how the proof of this theorem works.","['calculus', 'real-analysis']"
1524866,Can fundamental theorem of algebra for real polynomials be proven without using complex numbers?,"Update 24 Nov 2015: It is solved. Please refer to this arXiv paper . For polynomials with real coefficients,  I am trying to prove the following version of fundamental theorem of algebra, which avoids using complex numbers in the proof. Existence of complex roots will be a corollary of this theorem,  if proven successfully. Sorry for the long post. This is my own method and I could not make it shorter right now. Theorem: For every polynomial with real coefficients of order greater than 2,  there exists a quadratic polynomial with real coefficients which factorizes it. Why? Every real odd polynomial can be factored using only one variable, which produces a real root. Odd and even numbers interlace, but real even polynomials cannot always be factorized using one variable. Maybe two variables can factorize them always. My question: In the quotient formalism , if we divide a monic polynomial with positive coefficients with divisor $q(x)=x^{2}-ax-b$, the remainder is of the form $P(a,b)x+Q(a,b)$. I can show that $P(a,b)=0$ has one solution for large positive $b=b2$ and $n-1$ roots for large negative $b=-b1$ using Sturm chain . Equivalently, using Sturm's chain I can show that $Q(a,b)=0$ has two asymptotic solutions for $b=0$ on the lower half $a/b$ plane, as well as $n-2$ solutions for $Q(a,b)=0$ for the large negative $b=-b1$. I am certain that for large negative $b=-b1$, the solutions of $P(a,b)=0$ and $Q(a,b)=0$ interlace. Since the zero contours form connected curves, applying Jordan's curve theorem in the rectangle ABCD, A=[-a1 -b1] and C=[a2 b2] for will force at least once intersection of $P(a,b)=0$ and $Q(a,b)=0$ inside the rectangle, thus proving the theorem. **I have not being able to show the interlacing yet. Can someone please help me with relevant ideas or existing previous work regarding the interlacing? Please open the image in new tab for easier viewing Procedure of my proof: Part 1. Given any monic polynomial of order even order $n$,  shifting it  by $s$ gives the polynomial $$f(x+s)=\sum_{k=0}^{n} \frac{d^{k} f(s) }{k! \ d x^{k}}x^{n-k}=\sum_{k=0}^{n} C^{n}_{k} \ (1+\epsilon(k,s)) \ s^{n-k} \ x^{n-k} \ ....(1)$$
$\lim_{s \to \infty} \epsilon(k,s)=0$ $C^{n}_{k}$ is the permutation formula. Now, if any polynomial has a quadratic factor, any shift of origin still retains the factorization. So it suffices to prove the proposed theorem for transformed polynoials of the form $(1)$, which have positive and increasing coeffcients with decreasing power of $x$. Part 2. We can derive the quotient by repeatedly replacing $x^{2}=ax+b$. For any power $m$, if we write the quotient formula as $x^{m}\equiv p_{m}x+q_{m}$  , we can use the recursion formula $p_{m}=ap_{m-1}+q_{m}$ and $q_{m}=b q_{m-1}$. Using this method to write the quotient formula for $f(x+s)$, we get $$P(a,b)=\sum_{k=1}^{n-1} l_{k} \ g(k,b) \ a^{n-k}$$
$$Q(a,b)=\sum_{k=2}^{n} p_{k} \ h(k,b) \ a^{n-k}$$ $g(k,b)$ is monic polynomial with positive coefficients of $b$ with highest power $ \lfloor {\frac{k}{2}} \rfloor $ $h(k,b)$ is monic polynomial with positive coefficients of $b$ with highest power $ 1+\lfloor {\frac{k}{2}} \rfloor $ $l_{k}$ and $p_{k}$ are positive increasing sequences of $k$ (Which can be ensured by using large $s$ for $f(x+s)$). For sufficiently large positive $b$, applying Sturm chain method directly shows that there is only one root for $P(a,b)=0$. $Q(a,b=0)=Constant \ne 0$. So $Q(a,b=0)=0$ does not have any solution for $a$. However, by using the transformation $b=ma$ and using the recusrion formula, we can show that 
$$\lim_{m \to 0} [P(a,m)-n \ (1+\epsilon(n-1,s)) s^{n-1}] 
= \lim_{m \to 0} [Q(a,m)- \frac{ \ (1+\epsilon(n,s)) \ s^{n}}{m}]$$
 With some work, this directly shows that $Q(a,b)=0$ has two asymptotic solutions along $+a$ and $-a$ in the lower half $a/b$ plane. Using Sturm chain, it can be proved that large negative $b$, $P(a,b)=0$ has $n-1$ roots and  $Q(a,b)=0$ has $n-2$ roots. This happens because the coefficients of the polynomial of $a$ increase in magnitude with decreasing power and changes sign after every second power I have a feeling this is the basic structure behind the Fundamental Theorem of Algebra, since sign change over four consecutive powers is what complex numbers are cpable of producing The vertical sides of the rectangle ABCD can be directly estimated by taking a lower and upper limit of the roots of $P(a,-b1<b<b2)=0$, in presence of interlacing. Part 3. What is left We need to show that for large negative $b$, the $n-1$ roots of $P(a,b)=0$ and  $n-2$ roots of $Q(a,b)=0$ interlace. I am certain it can be used by comparing $l_{k}$ and $p_{k}$ and using the recursion formula. If there is an easy way to prove this from the recursion formula, it will be great. Update: Here is the outline of the proof. $$f(x)=\sum_{k=0}^{n} c_{k} \ x^{n-k} $$
$$g_{0}=P(f(x))=P(\sum_{k=0}^{n} c_{k} \ x^{n-k} )= \sum_{k=0}^{n} c_{k} \ P(x^{n-k}) ....(1)$$
$$ \frac{g_{1}}{b} =\frac{Q(f(x))}{b}=P(\sum_{k=0}^{n-1} c_{k} \ x^{n-k-1} )= \sum_{k=0}^{n-1} c_{k} \ P(x^{n-k-1})+ \frac{c_{0}}{b}....(1)$$ Using $g_{0}$ and $g_{1}$ as the first two entries of of Sturm chain, we get 
$$ \frac{-1^{i-1} g_{i}}{b^{i}} \approx \sum_{k=0}^{n-i} c_{k} \ P(x^{n-k-i})....(1)$$ for large $b$. Using the recursion formula between $g_{i-1},g_{i}$ and $g_{i+1}$, the intermediate value theorem and the growth properties of real polynomials, if the roots of $g_{i}$ and $g_{i+1}$ interlace,  it can be shown that $g_{i-1}$ and $g_{i}$ have interlacing roots for large negative $b$. The quadratic and linear terms of $g$ have interlacing roots for large negative $b$. This implies that $P(a,b)$ and $Q(a,b)$ have interlacing roots for large negative $b$. The quadratic term of $g$ does not have a root for large positive $b$.Using the same technique as above, it can be shown that $P(a,b)$ has one root and  $Q(a,b)$ has no root  for large positive $b$. I will follow up with a full write up over the weekend.","['elementary-functions', 'proof-verification', 'real-analysis', 'complex-numbers']"
1524879,Does there exist function that behaves in this way around some point and is continuous at that point?,"Suppose that we have some function $f: \mathbb R \to \mathbb R$ such that $f$ is integrable (Riemann or Lebesgue, choose one, or some other maybe more general type of integration, if there is such) on some inteval $(a,b)$. Now suppose that there exist point $x_0 \in (a,b)$ and sequence $\varepsilon_n$ such that $\varepsilon_n$ is positive and strictly decreasing and $\lim_{n \to \infty} \varepsilon_n =0$ and that $\varepsilon_n$ is such that we have $\int_{x_0}^{x_0 + \varepsilon_{2k-1}} f(x)dx>0$ and $\int_{x_0}^{x_0 + \varepsilon_{2k}} f(x)dx<0$ for every $k \in \mathbb N$. The question is: 1) Can we have such an $f$ that is continuous at $x_0$?","['continuity', 'real-analysis', 'functions', 'integration']"
1524891,Domain of $\ln(\ln(\ln(x)))$?,"So my problem states, Find the Domain and Derivative of the Function $$\ln(\ln(\ln(x))).$$ I know that I can just use the chain rule to find the derivative, but to find the domain, I don't know. All I know is that I need to use the identity $$e^{\ln x}=x.$$","['calculus', 'algebra-precalculus']"
1524894,Closed form for $f(z)^2 + f ' (z)^2 + f ' ' (z) ^2 = 1 $?,"Can we give a closed form for $f(z)$ in $$ f(z)^2 + f ' (z)^2 + f ' ' (z) ^2 = 1 $$ Apart from $f(x)= 1$ or $f(x)= -1$. Where "" closed form "" means in terms of standard functions , integrals and the inv operator ( e.g. $\text{Inv}( z \exp(z) ) = \text{LambertW}_0(x)$ ). Other insights are also appreciated.
( example uniqueness , singularities , periodicity ... )","['calculus', 'ordinary-differential-equations']"
1524930,Definition of integration of differential forms,"I am trying to understand precisely the following paragraph: Question Why would he define the support $K$ of a form $\omega$ defined on an open set $U$ as a subset $K\subseteq M$ instead of a subset $K\subseteq U$? This doesn't make sense for me and can't be just a typo because he later says ""assume that the support $K$ is contained in $U$"", but this is sort of obvious from the definition, isn't it? I'd appreciate any explanation. Thanks.","['differential-geometry', 'differential-forms', 'integration']"
1524933,How do I find a third side of a triangle with two sides and a bisecting line segment?,"I am using a laser range finder to calculate the height of a second story wall. I have a fixed point and three separate lengths hitting the top, the bottom, and an indeterminate point on the wall. With the exact lengths of all three line segments, how do I find the length of the wall? Note: I am unable to create a right triangle due to the height and the uneven wall underneath.","['triangulation', 'geometry', 'triangles', 'trigonometry']"
1524940,How would you determine $\sin(x) = -\cos(x)$,I can pretty much look at the equation and say the answer is $\frac{3\pi}{4} + 2\pi k$ and $\frac{7\pi}{4} + 2\pi k$ (where $k \in \mathbb N$) but how can I show work for this?,"['algebra-precalculus', 'trigonometry']"
1525000,Standard deviation for measurements with errors - least squares?,"I have been bugged by a simple problem in statistics recently. Let's assume that I have made a set of measurements of a certain quantity, each with an uncertainty estimate. I have a set of tuples $\{x_i,s_i\}$ ($x$ is a value, $s$ its uncertainty). The goal is to calculate the most likely true value $y$ and its uncertainty $S$. My solution: I assume that each measurement $x_i$ follows a Gaussian distribution with a standard deviation $s_i$, meaning that the probability that $y$ is the true value provided $x_i$ is
$$
P(y|x_i,s_i) \propto \exp \left ( -\frac{(x_i-y)^2}{2s_i^2} \right ) \,.
$$
Therefore the total probability (the measurements are independent) that $y$ is the true value should be
$$
P(y|\{x_i,s_i\}) \propto \exp \left ( -\sum_i \frac{(x_i-y)^2}{2s_i^2} \right ) \,.
$$
Searching for the most probable $y$, I just set $\partial P / \partial y = 0$. I then get
$$
\sum_i \frac{y}{s_i^2} = \sum_i \frac{x_i}{s_i^2} \, .
$$
Therefore the most probable value should just be an average measurements, using the squares of reciprocals of their uncertainties as weights. So far so good. I would then like to know that the standard deviation (its estimate) in $y$ is. I therefore look at $P(y+a|\{x_i,s_i\})/P(y|\{x_i,s_i\})$ (for some $a$). What I get is
$$
\frac{P(y+a)}{P(y)} = \exp \left ( - \sum_i \frac{a^2}{2s_i^2} \right ) \, ,
$$
therefore the standard deviation should be
$$
\frac{1}{S^2} = \sum_i \frac{1}{s_i^2} \, .
$$ That all makes sense. Provided that all the errors are the same, then $S = s/\sqrt{N}$. However, if I set all errors to 0 ($s_i = 0$), then the $S$ is also be 0. But there is still some uncertainty due to the  spread of values $\{x_i\}$. My question is: How should I approach the problem in order to incorporate both the spread of $\{x_i\}$ and their uncertainties $\{s_i\}$ in the total uncertainty $S$? Thanks a lot. SSF","['statistics', 'least-squares', 'standard-deviation']"
1525015,Functional equation $f(x^3) - f(x^3 - 2) = (f(x))^2 + 12$,"$$f(x^3) - f(x^3 - 2) = (f(x))^2 + 12$$ Given the functional equation above, I am trying to find the value of $f(3)$. I do not remember the exact statement of the problem precisely, so I am not sure whether an initial value of the form $f(a) = p$ was provided. I started off by finding the degree of $f(x)$ on both sides, which must be equal. If the degree of $f(x)$ is $n$, then the right side clearly has degree $2n$, while the left side seems to have a degree of the form $3(n-1)$. Equating this, I got that $f(x)$ is a polynomial of degree $3$. Now I am stuck — I thought of setting $f(x) = a x^3 + b x^2 + cx + d$ but I don't believe that will help much. EDIT: Ok I did that, and substituted back into the functional equation to get: $$a x^9-a \left(x^3-2\right)^3+b x^6-b \left(x^3-2\right)^2+c x^3-c \left(x^3-2\right)=\left(a x^3+b x^2+c x+d\right)^2+12$$ Ew. I guess I could expand and equate coefficients on both sides (and indeed, churching through that with Mathematica gives $6x^3 - 6$), but seeing as this is an AIME-esque problem, there should probably be an easier way. Is there one?","['algebra-precalculus', 'functional-equations']"
1525048,How to linearize this second order differential equation?,"I want to linearize this second order non linear differential equation arround P( $\pi/2 $ ,0) $\frac{d^2y}{dt}+\frac{dy}{dt}-9.8\sin(y)=5\sin(3t)$ I undestand how to linearize single variable functions like $f(x)=Cos(x)$ , but I'm clueless with the differential equation case.","['numerical-methods', 'ordinary-differential-equations']"
1525054,Why are removable discontinuities even discontinuities at all?,"If I have, for example, the function
$$f(x)=\frac{x^2+x-6}{x-2}$$
there will be a removable discontinuity at $x=2$, yes? Why does this discontinuity exist at all if the function can be simplified to $f(x)=x+3$? I suppose the answer is that you can't simplify it because you can't divide by something that could potentially equal $0$. But what if you start with $f(x)=x+3$? What's stopping you from multiplying it by $1$ in the form $\frac{x-2}{x-2}$? Can multiplying by $1$ really introduce a discontinuity to the function?","['continuity', 'limits', 'algebra-precalculus', 'functions']"
1525090,Two different definitions of big O notation,"I find there are two different definitions of big O notations for $f(n)=O(g(n))$ as $n\rightarrow\infty$: There exist $M>0$, and $N\in\mathbb{N}$, such that $|f(n)|\leq M|g(n)|$ for $n\geq N$. There exist $M>0$, such that $|f(n)|\leq M|g(n)|$ for $n\in\mathbb{N}$. I do not which one is right or when two of them is equivalent.","['nonstandard-analysis', 'calculus', 'limits']"
1525110,"Relationship between BIBO, Marginal and Asymptotic stability: statements","I know that asymptotic stability implies BIBO stability.
But then, which of the following can be held true: 1. If a system is BIBO stable would it definitely be asymptotic stable?

  2. If a system is marginally stable, it will definitely be   
asymptotically stable? 
  3. If a system is asymptotic stable, it will   
definitely be marginally stable? Kepeing in view the poles real part values in mind, what could be held true?","['vector-spaces', 'nonlinear-system', 'matrices', 'matrix-equations', 'linear-algebra']"
1525113,Fermat's infinite descent for finding the squares that sum to a prime,"Fermat's theorem on sum of two squares states that an odd prime $p = x^2 + y^2 \iff p \equiv 1 \pmod 4$ Applying the descent procedure I can get to $a^2 + b^2 = pc$ where $c \in \mathbb{Z} \gt 1$ I want $c = 1$, so how do I proceed from here? How do I apply the procedure iteratively? Example: $$
p = 97
$$ $$97 \equiv 1 \pmod 4 \implies \left(\frac{-1}{97}\right) = 1 \implies x^2 \equiv -1 \pmod {97}$$ has a solution $$x^2 + 1 \equiv 0 \pmod {97}$$
$$x^2 + 1 = 97m$$
We find an $x,m$ that solves the equation.
$$x = 75, m = 58$$
Now, we pick an $a,b$ such that $\frac{-m}{2} \leq a,b \leq \frac{m}{2}$
$$a \equiv x \pmod m = 17$$
$$b \equiv y \pmod m = 1$$ Observations: $ a^2 + b^2 \equiv x^2 + 1 \equiv 0 (\mod m)$ $ (a^2 + b^2) = mc$ $ (x^2 + 1) = mp$ Plugging in $a,b,m$ for 2, we get $c = 5$ By this identity, we know that $(a^2 + b^2)(c^2 + d^2) = (ac + bd)^2 + (ad - bc)^2$ **$(a^2 + b^2)(x^2 + 1^2) = (ax + b)(a - bx) = m^2pc$ Dividing ** by $m^2$, $pc = (\frac{ax+b}{m})^2 + (\frac{a-bx}{m})^2$ Plugging in $a,b,m,p,c$ we get that $22^2 + (-1)^2 = 97*5$ So we have two squares that add up to 5 times our $p$. How do we turn the 5 into a 1? What is the next step in the descent?","['sums-of-squares', 'infinite-descent', 'prime-numbers', 'number-theory', 'elementary-number-theory']"
1525114,"Calculating $\iint (x+y) \, dx \, dy$","By using the change of variable $u=x+y$ , $v=x$ evaluate
$$\iint_{Ta} (x+y) \, dx \, dy$$
where $Ta$ is the region in the $xy$ plane bounded by the $x$ and $y$ axes and the line $x+y = a$. Update: I have since worked out the Jacobian = -1
so am now onto:
$$\iint_{Ta} (x+y) \, dx \, dy$$
$$=\iint_{Ta} (v+u-v) \, du \, dv$$
since $x=v$ and $y=u-v$, so
$$\iint_{Ta} u \, du \, dv$$
I am still struggling with what to put as the limits though!","['calculus', 'multivariable-calculus', 'integration']"
1525152,divergence free vector fields on non-simply connected domains,"We know that divergence free vector fields are themselves curls of vector fields on simply connected domains. I want to construct a counter example in the case the domain is not simply connected. So consider an infinite line of charge along the $z$-axis of constant charge density. Then its electric field is given (unless I have made a mistake!) by $$\vec{E} = k\langle\frac{x}{x^2+y^2}, \frac{y}{x^2+ y^2},0\rangle.$$ By Gauss' theorem this should be divergence free (also follows from a simple computation). Can it be shown that this is not the curl of some vector field? I guess in general if we can find a surface without boundary on which the flux is not zero then by Stokes' theorem the electric field cannot be the curl of a vector potential. But the problem is that there cannot find a closed surface without boundary around the $z$-axis, and so maybe one has to take the unit sphere and remove a small cylinder and use some approximation argument. Any ideas?",['multivariable-calculus']
1525162,How would I take this derivative?,"I am not really sure how I would take the following derivative: $\frac{\partial}{\partial r}\left( F(r) \right) = \frac{\partial}{\partial r}\left( \int_{0}^{2 \pi} f(r,\theta) d\theta \right)$ Would it maybe just be: $\frac{d}{dr}\left( F(r) \right)  = \left( \int_{0}^{2 \pi} \frac{\partial f(r,\theta)}{\partial r} d\theta \right)$ Is this right?","['derivatives', 'calculus', 'integration']"
1525163,Is the set of invertible operators on a normed space open?,"I am aware that if $X$ is a Banach space then the set of invertible operators is open in $L(X,X)$ where we use the notation $L(X,X)$ for the space of all linear bounded maps from $X$ to itself. Does the result still hold if $X$ is just a normed space? Is there any ""easy"" counterexample?","['functional-analysis', 'general-topology', 'normed-spaces']"
1525166,Visualization of SU(3),"I am trying to visualize the $SU(3)$ group used in quantum field theory. I have a (reasonably) good understanding of $SU(2)$ as the double cover of $SO(3)$ and also that this is homeomorphic to $S^3$. I have also read from other questions here that $SU(3)$ is ""something like"" $S^5\times SU(2)$ (would that make it ""something like"" $S^5\times S^3$?) but I am not sure if the ""something like"" entails homeomorphism or if it is some more complicated bundle. Is there a way to visualize $SU(3)$ as a real manifold (ignoring its group structure if necessary to focus on its properties as a manifold)?","['lie-groups', 'group-theory', 'manifolds', 'differential-topology', 'topological-groups']"
1525217,Prove that :$\frac{1}{100\pi}>\int_{100 \pi}^{200\pi}\frac{\cos(x)}{x}>0$,"Using integration by parts, prove that $$0<\int_{100\pi}^{200\pi}\frac{\cos(x)}{x}<\frac{1}{100\pi}.$$ Using integration by parts prove that $\frac{1}{100\pi}>\int_{100 \pi}^{200\pi}\frac{\cos(x)}{x}>0$. Could anyone give me a help with this problem? I have tried using integration by parts but I don't get what integrating by parts achieves. Intuitively I can see why the integral must be greater than 0 as $\cos(100\pi) = \cos(200\pi) = 1$ and $\frac{1}{x}$ is a decreasing function, so the various areas above and below the $x$ axis and $\frac{\cos(x)}{x}$ would cancel to something positive, but this isn't using integration by parts.","['analysis', 'calculus', 'definite-integrals', 'integration']"
1525219,Dense Subspace of $L_{0}^{1}(\mathbb{R}^{n})$,"Let $L_{0}^{1}(\mathbb{R}^{n})$ denote the the closed subspace of $L^{1}$ functions whose Fourier transform vanishes at the origin (equivalently, $\int f=0$). At the top of pg. 231 in E.M. Stein, Singular Integrals and Differentiability Properties of Functions , the author claims that a dense subspace of $L_{0}^{1}(\mathbb{R}^{n})$ is the subspace $$\left\{f\in L^{1}(\mathbb{R}^{n}) : \text{supp}(\widehat{f}) \text{ compact }, \text{supp}(\widehat{f})\subset\mathbb{R}^{n}\setminus\left\{0\right\}\right\}$$ and that density ""...can be proved directly by elementary computation, or one can appeal to Wiener's theorem characterizing the maximal ideals of $L^{1}(\mathbb{R}^{n})$."" I am not familiar with Wiener's theorem, so I tried the direct route. I know that $L^{1}$ functions with compactly supported Fourier transforms are dense in $L^{1}$, but I don't see how to extend this result where the support is disjoint from the origin in frequency space. I tried taking a cutoff function $\varphi$ which is $\equiv 1$ on the unit ball $B_{1}(0)$ and supported in $B_{2}(0)$ and then considering the sequence of functions defined by $$f_{\delta}(x):=(\widehat{f}[1-\varphi(\cdot/\delta)])^{\vee}(x)$$ But it's not clear to me at the moment how to estimate the $L^{1}$-norm of $f-f_{\delta}$. Any suggestions?","['harmonic-analysis', 'fourier-analysis', 'real-analysis']"
1525221,definition of outer automorphism group,"I am taking an introductory course of group theory, and outer automorphism group is briefly mentioned in class, here are ""two"" definitions: An automorphism of a group which is not inner is called an outer automorphism. Outer automorphism group of a group G is the quotient Aut(G) / Inn(G). Are they contradicting each other? because it seems to me that the 1st definition is suggesting that Outer automorphism is Aut(G) - Inn(G)....and since identity is in Inn(G)...I don't know how can we ""group"" all the outer automorphisms (I am trying to identify the similarity with Inn(G), which is a subgroup of Aut(G)) ? the 2nd definition looks very weird to me...I mean it make some sense when G is abelian, we have Inn(G) = {e}, so that elements in the outer automorphism group are indeed outer automorphisms...but when Inn(G) = {$\phi_a,\phi_b...$} where $\phi_a(g) = aga^{-1}$, isn't outer automorphism just a coset of Inn(G)?...why are we calling {$\psi\phi_a,\psi\phi_b...$} an element of outer automorphism group? also we proved that Inn(G) is a normal subgroup of Aut(G)...why does outer automorphism group has to be a quotient group?...can't it just be a left/right cosets? I am try to do a bonus question in my assignment...but since there are very little information given in class about outer automorphism, I figure I should get a better understand of it first.","['group-theory', 'normal-subgroups']"
1525248,On the number of $2 \times 2$ matrices over ${\Bbb Z}_3$ with unit determinant,"Determine the number of matrices in ${\Bbb Z}_3^{2 \times 2}$ with determinant $1$ . I know that the elements in ${\Bbb Z}_3$ are $\{0,1,2\}$ now possibly determinant can be $1$ in this case $$
\begin
{bmatrix}
1&2\\
0&1\\
\end{bmatrix}
$$ and there can be many more but how to find the exact number of such matrices? I know that the answer is $24$ .","['determinant', 'linear-algebra', 'finite-fields', 'matrices']"
1525249,Uniformly sampling points from inside a region of cube,"Let the dimension n=200 be fixed. The problem I am interested in is sampling points in n-dimensional Euclidean space uniformly from the region 
$$
\sum_{i=1}^{n} x_{i}\leq 1,
$$
     where $0\leq x_{i}\leq 1$ for all $1\leq i\leq n$. One naive approach is to sample n points uniformly from the unit cube and then reject the sample if the sum is greater than 1. But this is a very inefficient approach. By simple MonteCarlo simulations I am observing that the Probability of the event $\sum_{i=1}^{n} x_{i}\leq 1$ is less than $10^{-6}$. So is there any efficient way to do this sampling?","['geometry', 'random-variables', 'sampling']"
1525292,"Is the relation {(2,3),(3,3),(4,2),(5,1)} a function with domain and co-domain {1,2,3,4,5}?","I got a question marked incorrect, however, searching around, I found that the general consensus was that I got the answer correct. I promise that I am not asking you to do my homework as it has already been graded, but I really need to know the truth if I am to learn anything. The task was to decide whether a relation is a function. The one I got wrong: Problem: The domain and co domain are {1,2,3,4,5}  and the relation R is given by the set of ordered pairs:  {(2,3),(3,3),(4,2),(5,1)}. my answer was that is was a function - and it was marked as incorrect my instructor said that is was not a function because 1 does not have an associated value my response was that 5 had the associated value of 1 so it was still a function her response was that 5 was clearly in the co domain. From what I can tell, no indication was given as to what values in the set were in the domain or in the co domain simply by this: {1,2,3,4,5} Was I incorrect in my finding that 1 was not the domain but the co domain and that 5 was in the domain based on the information provided?","['relations', 'discrete-mathematics']"
1525346,How can I prove every positive real number has square root?,Does it ask that we can express any positive real number as square root of something? like 4 is equal to square root of 16?,"['calculus', 'real-analysis']"
1525347,About isosceles triangles,Let $ABC$ be an acute-angled triangle in which $\hat{ABC}$ is the largest angle. Let $O$ be its circumcenter. The perpendicular bisectors of $BC$ and $AB$ meet $AC$ at $X$ and $Y$ respectively. The internal bisectors of $\hat{AXB}$ and $\hat{BYC}$ meet $AB$ and $BC$ at $D$ and $E$ respectively. How do I prove that $BO$ is perpendicular to $AC$ if $DE$ is parallel to $AC$.,"['geometry', 'triangles']"
1525349,Differentiation under an integral with respect to a function,"Consider the functional $F$ defined via the integral
$$
F(\mu)=\int_0^\ell\int_0^\ell f(s,t)\mu(s)\mu(t)\,ds\,dt.
$$
How would I differentiate this with respect to $\mu$? I realize that this has something to do with the functional derivative , but I can't seem to put it all together here.  There appear to be other questions that deal with a similar topic, but this one seems to be complicated by the fact that each factor of $\mu$ is dependent on a different variable. For simplicity, just assume that $f$ and $\mu$ are as nice as we would need them to be.","['derivatives', 'calculus-of-variations', 'functions', 'integration']"
1525354,Differential Equations Complex Eigenvalue functions,"Show that a function of the form $x(t) = K_1 \cos\beta t + K_2 \sin\beta t$ Can be written as $x(t) = K\cos(Bt-\phi)$ Where $K = \sqrt {K_1^2 + K_2^2}$ I know that linear systems with complex coefficients are sometimes expressed in this form, however I'm not sure if/how that would be useful to solve this problem. Any suggestions on how to approach this would be greatly appreciated.","['eigenfunctions', 'complex-numbers', 'ordinary-differential-equations', 'trigonometry']"
1525361,Why is this sum equal to $0$?,"While solving a differential equation problem involving power series, I stumbled upon a sum (below) that seemed to be always equal to $0$, for any positive integer $s$. $$
\sum_{k=0}^s \left( \frac{ \prod_{r=1}^k (-4r^2+10r-3) \prod_{r=1}^{s-k} (-4r^2+6r+1)}{2^s (2k)! (2s-2k+1)!} \times (2s-4k+1) \right)
$$ Why is this sum always equal to $0$? The simplified version of this equation would be:
$$
\frac{1}{(-2)^s (2s+1)!} \sum_{k=0}^s \left( \binom{2s+1}{2k}  (2s-4k+1) \prod_{r=1}^k (4r^2-10r+3) \prod_{r=1}^{s-k} (4r^2-6r-1)  \right)
$$
or
$$
\frac{1}{(-2)^s (2s)!} \sum_{k=0}^s \left( \left( \binom{2s}{2k} - \binom{2s}{2k-1} \right) \prod_{r=1}^k (4r^2-10r+3) \prod_{r=1}^{s-k} (4r^2-6r-1)  \right)
$$ Update: $4r^2-10r+3$ and $4r^2-6r-1$ were derived from $n^2-5n+3$ by replacing $n$ with $2r$ and $2r+1$, respectively, which means this could be rewritten as:
$$
\frac{1}{(-2)^s (2s)!} \sum_{k=0}^s \left( \left( \binom{2s}{2k} - \binom{2s}{2k-1} \right) \prod_{r=1}^k a_{2r} \prod_{r=1}^{s-k} a_{2r+1}  \right)
$$
where $a_n=n^2-5n+3$ If the sum on the first line is indeed equal to $0$, then this would also be true:
$$
\sum_{k=0}^s \left( \binom{2s}{2k} \prod_{r=1}^k a_{2r} \prod_{r=1}^{s-k} a_{2r+1} \right) = \sum_{k=0}^s \left( \binom{2s}{2k-1} \prod_{r=1}^k a_{2r} \prod_{r=1}^{s-k} a_{2r+1} \right)
$$ Then, I changed the coefficients of $a_n$ into unknown constants to check whether this equality is true in other cases: $a_n=n^2-bn+c$ It seemed that this equality stands when $b$ is an odd integer greater than or equal to $5$ and $s$ is an integer greater than or equal to $(b-3)/2$; when these conditions are met, the value of $c$ does not seem to affect anything. How could one mathematically derive or prove the above conclusion?","['analysis', 'sequences-and-series', 'summation', 'products']"
1525362,How to prove the series converges?,"Show that the series $\sum\limits_{j=1}^\infty  = \frac{2^j+j}{3^j-j}$ converges. I know that if I look at each sequential case j=1,2,3... the limit of the partial sums approaches 0 as $j \rightarrow \infty$, but how can I show that the series converges more explicitly?","['calculus', 'real-analysis', 'sequences-and-series', 'convergence-divergence', 'complex-analysis']"
