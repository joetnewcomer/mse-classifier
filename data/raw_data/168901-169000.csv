question_id,title,body,tags
2964422,Conditional Probability --- Card Question,"Suppose you have two cards: one is painted black on both sides and the other is painted black on one side and orange on the other You select a card at random and view one side. You notice it is
black. What is the probability the other side is orange? What I have done is following: Card 1: $B_{1}$ , $B_{2}$ Card 2: $B_{1}$ , $O_{2}$ Now, we want to calculate $P(O_{2}|B_{1})$ , which is $$P(O_{2}|B_{1})=\dfrac{P(B_{1}\cap O_{2})}{P(B_{1})}$$ $P(B_{1}\cap O_{2})=\dfrac{1}{2}$ as there is only $1$ card (out of $2$ ) giving us black and orange. $P(B_{1})=\dfrac{3}{4}$ . Therefore, the resulting conditional probability is $\dfrac{2}{3}$ However, the solution of this question telling me $\dfrac{1}{3}$ is the correct answer (without explanation, just a number). What's wrong here? Thank you!","['conditional-probability', 'probability']"
2964459,How to prove that a vector field with holes in its domain is conservative without finding a potential?,"I have to prove that $$\vec{F}=\frac{\vec{r}}{r^2}$$ is a conservative vector field without finding it's potential function. However, $\vec{F}$ has a hole in its domain, at $(x,y,z)=(0,0,0)$ , so I can't just check it's curl. How do I go about proving this?","['vector-fields', 'multivariable-calculus', 'vectors', 'vector-analysis']"
2964486,What does $2.5437065e\!−\!5$ mean? [scientific notation] [duplicate],This question already has answers here : What does E mean in 9.0122222900391E-5? [closed] (3 answers) Closed 5 years ago . $$\frac{0.314^5}{120}=2.5437065e\!−\!5$$ I did this calculation by my android phone's calculator. I can't understand the result I got (The RHS of calculation). Please help. What is this?,['algebra-precalculus']
2964490,closed form of the sequence $a_{n+1} = a_ne^{-a_n}$,"There isn't much documentation available for finding closed forms of sequences, given their recurrence relation. I couldn't find out the closed form of the sequence $$a_{n+1} = a_ne^{-a_n}$$ Given $$a_0 = 1$$ I tried everything from trying to guess then prove by induction to exponential generating functions and I always end up just proving that $0 = 0$ . Do sequences like the aforementioned one have a closed form? How should I approach this one specifically?","['generating-functions', 'discrete-mathematics', 'sequences-and-series']"
2964511,Transitive closure applied to a relation,"I have a hard time understanding the transitive closure applies to a relation example the relation $$\alpha =\{⟨x,y⟩∈ \Bbb N^2\mid x=y+10\}.$$ What is the transitive closure of this relation? Wouldn't it be $\alpha+ =  \alpha$ so it would stay the same? Because if we graph the relation we only have an element relied to an other once so we can't have $R^2 \cup R^3\dots$ Since the segment are only of length $1$ we only have $R^1$ which would be $R+$ right ? In other words, if the properties irreflexivity, anti-symmetry and symmetry held for the relation $\alpha$ , even if we had the transitive closure to this relation, $\alpha +$ would still be : irreflexive, anti-symmetric and symmetric, right? Thank you!","['elementary-set-theory', 'relations', 'logic', 'discrete-mathematics']"
2964512,What is the purpose of differentiating between norms and metrics?,"A metric $d(x,y)$ takes two points from some domain $X$ and returns a non-negative real number. It is the distance between two points. A norm $n(x)$ takes only one point from $X$ and 
also returns a non-negative real number. It is the length of a vector when viewed as an arrow from the origin, or simply the distance between $x$ and $0$ . My question is, why is there a need for distinguishing between norms and metrics when a norm is just a metric with one of its inputs being $0$ ? Is it correct to say that a norm is a type of metric, where one of the inputs is $0$ ?","['general-topology', 'normed-spaces', 'functional-analysis', 'metric-spaces']"
2964515,Limit of $\frac{N^{n}(N!)^{n}}{(n-1)!}$ as $n$ tends to infinity,How to prove that $$\lim_{n\rightarrow\infty}\frac{N^{n}(N!)^{n}}{(n-1)!}=0?$$ Any help would be greatly appreciated.,"['limits', 'calculus', 'factorial']"
2964554,Cyclic Golomb ruler,"Golomb rulers are widely researched, but apart from an old problem by Dudeney I could not find anything about cyclic Golomb rulers. A cyclic Golomb ruler would be a circle of integer length on which markers are placed at integer distances, such that all distances between two different markers are different.
Clearly with $n$ marks there are $n(n-1)$ distances to consider.
A perfect cyclic Golomb ruler (PCGR) with $n$ marks would have all distances $1,\ldots,n(n-1)$ and a total length of $n(n-1)+1$ .
The $n$ marks break the circle in $n$ pieces of integer length, giving a sequence of $n$ consecutive piece-lengths.
This can be done in $2n$ different ways (we can start at $n$ different points and then move either clockwise or counterclockwise).
We will use the lexicographically smallest sequence to describe the configuration. Following things are easy to show: . $[1,2]$ is the unique PCGR with two marks (length 3). . $[1,2,4]$ is the unique PCGR with three marks (length 7). . $[1,3,2,7]$ and $[1,2,6,4]$ are the only PCGRs with four marks (length 13). . There is no PCGR with five marks (Oops, this turns out to be untrue, but I found the flaw in the argument). And although it is very easy to show that there are no ""normal"" perfect Golomb rulers with more than $4$ marks, I have not yet been able to come up with a proof that there is no PCGR with more than $4$ marks (because it is not true). Does anyone know how to prove this, or maybe provide references to research on this subject?","['graph-theory', 'number-theory']"
2964650,Limit $\lim_\limits{x\to0}{\tan{x}-\sin{x}\over x^3}$,"What is the limit of: $$\lim_\limits{x\to0}{\tan{x}-\sin{x}\over x^3}$$ So what I tried is: $$\lim_\limits{x\to0}{{\sin{x}\over\cos{x}}-\sin{x}\over x^3}=\lim_\limits{x\to0}{{\sin{x}}({1\over\cos x}-1)\over x\cdot x^2}$$ From here, using the rule $\lim_\limits{x\to0}{\sin{x}\over{x}}=1$ it remains to evaluate $$\lim_\limits{x\to0}{{1\over\cos{x}}-1\over x^2}.$$ I tried changing it a lot of ways but it always gets messier so I'm not sure what to apply here to complete the question.","['limits', 'trigonometry']"
2964665,Automorphisms of the Weil restriction,"Given a complex variety, say $\mathbb{P}^1_\mathbb{C}$ , I want to compute $$\text{Aut}_\mathbb{R}(\mathbb{P}^1_\mathbb{C}\vert_{\mathbb{R}}).$$ Using the definition of Weil restriction, one can show that for a complex variety $X$ , $X\vert_\mathbb{R}\times_\mathbb{R}\mathbb{C}=X\times_\mathbb{C}X$ , so that $$\text{Hom}_\mathbb{R}(\mathbb{P}^1_\mathbb{C}\vert_{\mathbb{R}},\mathbb{P}^1_\mathbb{C}\vert_{\mathbb{R}}) \ = \ \text{Hom}_\mathbb{C}(\mathbb{P}^1_\mathbb{C}\vert_{\mathbb{R}}\times_\mathbb{R}\mathbb{C},\mathbb{P}^1_\mathbb{C})\ = \ \text{Hom}_\mathbb{C}(\mathbb{P}^1_\mathbb{C}\times_\mathbb{C}\mathbb{P}^1_\mathbb{C},\mathbb{P}^1_\mathbb{C}).$$ However, I don't know which maps on the right correspond to automorphisms, and how to compute the group of them. Edit: GetOffTheInternet has noted that the above formulas are not quite correct, but the questions below still stand: What is the answer in this case? Are they just the complex automorphisms composed with a Galois action? What about for other complex curves? For instance, are there $168\cdot 2$ automorphisms of the Klein quartic over $\mathbb{R}$ ? $$\text{}$$ The reason I care about this is to get useful examples of Galois descent of schemes. Indeed, the varieties over $\mathbb{R}$ which go to to $X$ upon tensoring with $\mathbb{C}$ biject with $$H^1(\text{Gal}\mathbb{C}/\mathbb{R}, \text{Aut}_\mathbb{R}(X_0))$$ where $X_0$ is a particular one going to $X$ . In the affine case $\text{Aut}(X_0)$ is too ugly to deal with, so I'm looking at the next simplest case of projective curves. Edit: I had forgotten the actual result; it is $H^1(\text{Gal}(\mathbb{C}/\mathbb{R}, \text{Aut}_\mathbb{C} X)$ , where $\text{Gal}$ acts on $\text{Aut}_\mathbb{C} X=\text{Aut}_\mathbb{C}(X_0\otimes_\mathbb{R}\mathbb{C})$ by conjugation.",['algebraic-geometry']
2964684,Proof that when $R ∪ S$ is an equivalence relation then it is equal to $R ∘S$,"Let $R$ and $S$ be equivalence relations on the same set. I have to prove that when $R ∪ S$ is an equivalence relation, then $R∘S=R∪S$ . I know that I will have to use the definitions of composition and union to achieve this but I have no clue how I can show that those are the same. And I know that $R ∪ S = R \lor S$ otherwise the union couldn't be transitive. $R∪S=(x, y)\in R\lor(x, y)\in S$ $R$ ∘ $S$ $=$ $\{(x,z)\in X\times Z\mid \exists y\in Y:(x,y)\in S\land (y,z)\in R\}$ .","['elementary-set-theory', 'discrete-mathematics']"
2964702,Limit $\lim_\limits{x\to0}{2x-\sin{x}\over3x+\sin{x}}$,"What is the limit of: $$\lim_\limits{x\to0}{2x-\sin{x}\over3x+\sin{x}}$$ What I've tried: $$\lim_\limits{x\to0}{2x-2\sin{x\over2}\cos{x\over2}\over3x+2\sin{x\over2}\cos{x\over2}}=\lim_\limits{x\to0}{2(x-\sin{x\over2}\cos{\frac{x}{2}})\over3x+2\sin{x\over2}\cos{x\over2}}$$ I'm lost at this point, no idea what to do, or if I should've done something else.","['limits', 'trigonometry']"
2964704,Proving $\int_0^\pi \frac{\log(1+x\cos (y))}{\cos y}dy=\pi \arcsin x$,"How would I go about proving that, $$\int_0^\pi \frac{\log(1+x\cos (y))}{\cos (y)}\,dy=\pi \arcsin (x)$$ I have tried to do this by computing the integral directly, but it appears to be too difficult. Maybe there is a better approach to this that I do not know of.","['integration', 'calculus', 'real-analysis']"
2964711,Definition of a semiring of sets,"I'm reading Halmos's Measure Theory and his definition of semiring seems to disagree with the ones that I find on the internet. Halmos's definition (p. 22): A semiring is a non empty class $\mathbf{P}$ of sets such that if $E\in\mathbf{P}$ and $F\in\mathbf{P}$ . then $E\cap F\in\mathbf{P}$ . and if $E\in\mathbf{P}$ and $F\in\mathbf{P}$ and $E\subset F$ , then there is a finite class $\{C_0, C_1, \cdots, C_n\}$ of sets in $\mathbf{P}$ such that $E=C_0\subset C_1\subset\cdots\subset C_n=F$ and $D_i=C_i-C_{i-1}\in\mathbf{P}$ for $i=1,\cdots,n$ . Wikipedia's definition (for example): A semiring (of sets) is a non-empty collection $S$ of sets such that $\emptyset \in S$ If $E\in S$ and $F\in S$ then $E\cap F\in S$ . If $E\in S$ and $F\in S$ then there exists a finite number of mutually disjoint sets $C_{i}\in S$ for $i=1,\ldots ,n$ such that $E\setminus F=\bigcup _{i=1}^{n}C_{i}$ . These definitions are not equivalent!  For example, the collection $\{\emptyset,\{a\},\{b\}, \{c\}, \{a,b,c\}\}$ is a semiring under the second definition, but not the first. Questions: History question: why does Halmos use a different definition than we do today?  Was the definition weakened at some point in order to be more general? Math question: what are the advantages/disadvantages of these two definitions from the standpoint of measure theory?",['measure-theory']
2964716,Space with semi-locally simply connected open subsets,"A topological space $X$ is semi-locally simply connected if, for any $x\in X$ , there exists an open neighbourhood $U$ of $x$ such that any loop in $U$ is homotopically equivalent to a constant one in $X$ or, equivalently, if the functor $$\Pi_1(U)\rightarrow\Pi_1(X)$$ induced by the inclusion $U\subseteq X$ factorizes through a groupoid in which for each pair of objects there is at most one morphism. My question is: is it true that if a locally path connected space $X$ is such that, for any open subset $U\subseteq X$ , $U$ is semi-locally simply connected, then $X$ must be locally simply connected ?","['general-topology', 'homotopy-theory', 'algebraic-topology']"
2964843,Finding the best rank-one approximation of the matrix $\bf A$,"I have computed the singular value decomposition (SVD) of the following matrix $A$ . $$ {\bf A} := \begin{bmatrix}1&2\\0&1\\-1&0\\\end{bmatrix} = \underbrace{\left[\begin{matrix}0 & \sqrt{\frac 5 6} & \frac{1}{\sqrt 6} \\ \frac{1}{\sqrt 5} & \sqrt{\frac 2 {15}} & -\sqrt{\frac 2 3} \\ \frac{2}{\sqrt 5} & -\frac{1}{\sqrt 30} & \frac{1}{\sqrt 6}\end{matrix}\right]}_{=: {\bf U}} \underbrace{\left[\begin{matrix}1 & 0 \\ 0 & \sqrt 6 \\ 0 & 0\end{matrix}\right]}_{=: {\bf \Sigma}} \underbrace{\left[\begin{matrix}-\frac{2}{\sqrt 5} & \frac{1}{\sqrt 5} \\ \frac{1}{\sqrt 5} & \frac{2}{\sqrt 5}\end{matrix}\right]^\top}_{=: {\bf V}^\top} $$ The singular value decomposition can be used to obtain the best rank $p\leq r $ approximation of a matrix $A$ , by only keeping the first $p$ terms. Find the best rank-one approximation of the matrix $\bf A$ . How can I find the best rank-one approximation of the matrix $\bf A$ ?","['svd', 'rank-1-matrices', 'matrices', 'optimization', 'matrix-decomposition']"
2964897,Using Leibniz on $\sum_{n=1}^\infty \sin(\pi \sqrt{n^2+1})$,Using Leibniz on $\sum_{n=1}^\infty \sin(\pi \sqrt{n^2+1})$ So the question actually is how to rewrite $\sin(\pi\sqrt{n^2+1})$ in the form of $(-1)^n\times a_n$ so that I can apply Leibniz and decide the convergence or divergence? I'm sorry but I'm pretty new in studying series .,"['trigonometric-series', 'trigonometry', 'sequences-and-series']"
2964898,A question about limits of algebraic functions,"I am a high school math teacher, and I recently put the following question on one of my assessments: Find the numbers a and b such that $\lim\limits_{x \to 0}\frac{\sqrt{ax+b}-4}{x}=1$ . The concept I was testing was for students to realize that, since the limit exists but the denominator approaches 0, the numerator must also approach 0, i.e. $\lim\limits_{x \to 0}{\sqrt{ax+b}-4}=0$ . Instead, some of my students made a different argument which seems a bit off to me.  I don't want to tell them that their thinking is correct without being able to supply a justification for it.  Note that, due to constraints in time and curriculum, we don't cover the definition of a limit (but I will gladly take an epsilon-delta proof if someone can supply one).  I'm thinking, more likely, that there is a counter-example and if anyone can supply one I will be grateful. The student argument goes like this: Consider $\lim\limits_{x \to 0}\frac{x}{x}$ We know that that limit has a value of 1. Note that the limit of the denominator is zero, i.e. , $\lim\limits_{x \to 0}{x} = 0$ Since $\lim\limits_{x \to 0}\frac{\sqrt{ax+b}-4}{x}$ has the same value as $\lim\limits_{x \to 0}\frac{x}{x}$ , and since the denominators of both expressions are equal and their limits are equal, we can say that the limit of the numerators must be equal, i.e. $\lim\limits_{x \to 0}{\sqrt{ax+b}-4} = \lim\limits_{x \to 0}{x}$ . From there, they arrive at the same result which I had intended by solving the limit on the right side of the equation.  But something about this argument bothers me and I'm not certain what it is; perhaps it's because it is so specific in that the limit has to be going to zero, both denominators are just the identity function, and the original limit of the algebraic expressions is 1. If I had made the original limit equal to 2, then could they have  used their argument only changing the considered function from $\frac{x}{x}$ to $\frac{2x}{x}$ ?  I feel like...maybe? Anyway, can anyone provide a counter-example to this specific example of a limit approaching zero of a fractional expression whose denominators are identical, and where both approach zero, and the limit of the entire fractional expression is 1?  Is there a counter-example, or can it be proven that this will always work?  And then what about extrapolating it to when the limit of the original is an arbitrary constant k?  And then when the denominators are unequal functions but both approach zero? Thank you everyone for your help!  I'm very big on rigorous explanations in my math classes (to the point where they can be made...I do an optional epsilon-delta lesson after school for those who are interested) and I'd like to either be able to tell my students that they are correct, or show them a counter-example.  Thank you!","['limits', 'calculus']"
2964920,Differentiation Operator is not a bounded operator for polynomials,"If you consider the space of all polynomials on [0,1] (defined as $P_{[0,1]}$ as subspace of $C_{[0,1]}$ ) then the differentiation operator is not a linear bounded operator on this space. Why is that? this doesn'
t make any sense to me.","['linear-algebra', 'functional-analysis', 'linear-transformations']"
2964944,Asymptotics of inverse of normal CDF,"Let $\Phi(x)$ denote the cdf of the standard normal distribution.  What are the asymptotics of $\Phi^{-1}(p)$ , as $p \to 1$ ?  In particular, is there an asymptotic expression for $\Phi^{-1}(1-x)$ , as $x \to 0$ ?  A first-order approximation would be fine.","['statistics', 'probability-distributions', 'normal-distribution', 'asymptotics', 'real-analysis']"
2964961,Is $\mathbb{R}$ the only complete ordered Abelian group?,"I know that the field of real numbers is the only complete, ordered field in the sense that any field satisfying these properties is isomorphic to $(\mathbb{R},+,\cdot,<)$ . Question 1. Is it true that any complete, ordered Abelian group is isomorphic to $(\mathbb{R},+,<)$ ? If not, is there an example of a complete, ordered Abelian group $(G,+,<)$ which is not isomorphic to $\mathbb{R}$ ? I am using the following definition of complete: A partially ordered set $(P,\leq)$ is complete if each subset $E\subseteq P$ which is bounded above has a least upper bound in $P$ . This is modeled after the completeness axiom for $\mathbb{R}$ , but I can't find a good source for this more general definition. Edit 1. It is false. A counterexample is $\mathbb{Z}$ . It is complete since any subset has a maximum, and ordered as usual,  but not isomorphic to $\mathbb{R}$ . Question 2. What if we require $G$ to be ""dense"" in the following sense? $$\forall a,b\in G, \quad \{g\in G\mid a<g<b\}\neq\emptyset$$ Does this additional condition imply $G$ is isomorphic to $\mathbb{R}$ ? Edit 2. It is true. It was shown the only complete ordered Abelian groups are $\mathbb{Z}$ and $\mathbb{R}$ , and the ""dense"" condition leaves only $\mathbb{R}$ .",['abstract-algebra']
2964970,"Show that if the norms $\| \cdot \|_1$ and $\| \cdot \|_2$ are equivalent, then $(X, \| \cdot \|_1)$ is Banach iff $(X, \| \cdot \|_2)$ is Banach","Exercise : Show that if the norms $\| \cdot \|_1$ and $\| \cdot \|_2$ are equivalent, then the space $(X, \| \cdot \|_1)$ is a Banach space if and only if the space $(X, \| \cdot \|_2)$ is a Banach space. Attempt : Let $x_n$ be a Cauchy sequence in $(X, \| \cdot \|_2)$ . Let $\epsilon >0$ , then $\exists k_0 \in \mathbb N :$ $$\|x_k - x_l \|_2 < \frac{\epsilon}{2} \; \forall \; n,l \geq k_0$$ Every term $x_k$ is of the form $x_k = (x_n^k)_{n \in \mathbb N}=(x_1^k, x_2^k, \dots)$ . Thus : $$\|x_n^k - x_n^l\|_2 < \frac{\epsilon}{2} \; \forall \; k,l \geq k_0$$ which means that the sequence of real numbers $(x_n^k)_{n \in \mathbb N}$ is Cauchy $\forall n=1,2,\dots$ . Thus, it converges to some real number $x_n$ , which means that $\lim_{k \to \infty} x_n^k = x_n \forall n$ . Now, for $l \to \infty$ , we have that : $$\|x_n^k - x_n\|_2 < \frac{\epsilon}{2} \underset{n \to \infty}{\implies} \| x_k - x\|_2 < \epsilon $$ Thus $\lim_{k \to \infty} x_k = x$ which means that the sequence converges in $(X, \| \cdot \|_2)$ . But since the norms are equivalent, it holds that : $$c_1\|\cdot\|_1 \leq \|\cdot \|_2 \leq c_2\|\cdot \|_1$$ Thus, it would also be : $$c_1\|x_k - x_l\|_1<\frac{\epsilon}{2} \implies \|x_k - x_l\|_1 < \frac{\epsilon '}{2}$$ But that's the definition of a Cauchy sequence in $(X, \| \cdot \|_1)$ and thus a sequence $(x_n)$ is Cauchy in $(X, \| \cdot \|_1)$ if and only if it's Cauchy in $(X, \| \cdot \|_2)$ . This means that the sequence would also converge in $(X, \| \cdot \|_1)$ if and only if it converges in $(X, \| \cdot \|_2)$ . Thus $(X, \| \cdot \|_2)$ must be complete and thus a Banach space. Question : Is my solution mathematically rigorous enough and correct ? I would appreciate any comments or corrections as I am a beginner at Functional Analysis.","['banach-spaces', 'normed-spaces', 'metric-spaces', 'real-analysis', 'functional-analysis']"
2964974,Finding range of function,"$$f(x) = \frac{1}{\sqrt{1+x}}+\frac{1}{\sqrt{1+a}}+\sqrt{\frac{ax}{ax+8}}$$ Prove that for all positive real number $a$ , $1<f(x)<2$ According  to me i think question is not correct.
as at $a= 16$ , we have case when function reaches
infinite value in left of $-1/2$ .","['calculus', 'proof-verification']"
2964977,Understanding the second condition of the pumping lemma,"I'm confused about a very specific detail in the following solution The second condition of the pumping lemma states that 
|xy| <= p. We also know that w = xyz . In this case , w = $0^p1^p2^p $ Then how can 'y' ever reach the $1$ s or the $2$ s ? The complete word has to be xyz and xy can't be bigger than p. I don't understand how 'y' can contain more than just zeros. In other words, the only valid seperation of this word that I see is xy being only zeroes (because xy <= p and w = xyz) z being the rest (zeroes or not, $1$ s and $2$ s)","['formal-languages', 'discrete-mathematics', 'regular-language']"
2964991,"Question on injective-surjective functions, regarding cardinality of domain, codomain","Ok so we know that if A, B are finite sets and f : A to B is injective, then cardinality( A )≤cardinality( B ),
 and that the opposite inequality holds for a surjection. My question is, if we know that f is not injective, can we assume that cardinality( A )>cardinality( B )
 (and similarly for a surjection)? I'm asking this because I need to prove that there is no f : A to A that is either (injective but not surjective) or (surjective but not injective), with A finite. Thanks! (Sorry for my bad typing, I can't figure out how to use the symbols)","['cardinals', 'functions']"
2965025,Square root of Diagonal matrix,"I cannot find an answer to if it is generally possible to take the square root of a diagonal matrix $A$ by taking the square root of each individual component along the main diagonal, e.g. for a 2-by-2 matrix $$
        \sqrt{A} = \begin{pmatrix}
        \sqrt{a_1} & 0 \\
        0 & \sqrt{a_2} \\
        \end{pmatrix}.
$$ Is this OK to do provided that it is a (square) diagonal matrix?","['matrices', 'linear-algebra']"
2965036,Absolute convergence of f(nt) when f is integrable,"I'm working on the following exercise: Let $f \in \mathcal L^1([0,\infty), \lambda)$ be a Lebesgue integrable function on $[0,\infty)$ . Show that for $\lambda$ -almost every $t \in (0,\infty)$ , the series $\sum_{n=1}^\infty f(nt)$ converges absolutely. Here $\lambda$ is Lebesgue measure. I'm not really sure how to go about this. I thought I could use monotone convergence on the functions $F_n = \sum_{k=1}^n f(kt)$ , but I have no reason to suspect these are integrable. I'm wondering if there's a Fatou argument I can make instead, but I'm having trouble seeing it. This exercise comes from Section 4.2 of Achim Klenke's book on probability theory (this section is on Fatou's lemma and monotone convergence). The series in question looks suspiciously similar to a limiting term in a Riemann integral, but this is discussed in the following section, so I'd like to avoid using Riemann integration arguments here. (Though the exercise could just be misplaced.)","['integration', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
2965046,Solutions to $x^x=1$?,"When $x>0$ , how many solutions does $x^x=1$ have? I found that $\lim_{x \to 0} x^x=1$ . How does one show that this is the only possible answer?","['limits', 'calculus']"
2965049,second order differential equation $xy^n + 2\frac{dy}{dx} = 12x^2$,"$xy^n + 2\frac{dy}{dx} = 12x^2$ Solve the second-order diﬀerential equation
by making the substitution $u = \frac{dy}{dx} $ this is the question. I tried to solve it using the integration factor. But since it has a $y^n$ in i can't figure it out. They do say solve the second order differential equation does this mean that since it is second order that $y$ should equeal $2$ ? 
Should i use the integration factor or use a different technique?
I also dont get how substituting $u$ for $\frac{dy}{dx}$ would do anything.","['calculus', 'ordinary-differential-equations']"
2965055,Does a data-dependent sampling rule induce correlation?,"I'm struggling to understand whether a data stream sliced up in a certain way could produce two quantities that are dependent but uncorrelated. Suppose I have two iid streams of data that are independent of each other: $X = (X_1, X_2, \ldots)$ and $Y = (Y_1, Y_2, \ldots)$ . I want to estimate the difference in means between the two groups. Between the two streams, I want to sample a total of $n$ points. For notation's sake, say I'm sampling one point per unit of time for $T$ total time units. Now consider the following sampling scheme which divides up the $T$ time period into two halves: Up until time $t = T/2$ , sample from $X$ and $Y$ with equal
probability. From $t = (T/2+1)$ until $T$ , sample from $X$ with probability $p$ and from $Y$ with probability $1-p$ , where $p$ is some function of the data I observed in
the first half and also $p \in (0,1)$ . Now consider $\hat{\theta}_1 := \bar{X}_1 - \bar{Y}_1$ , the difference in sample means calculated from only the data collected up until time $t=T/2$ and $\hat{\theta}_2 := \bar{X}_2 - \bar{Y}_2$ calculated from only the data collected from time $t=(T/2+1)$ to $t=T$ . Question: Without knowing more about how $p$ depends on the data in the first half, can we tell whether $\hat{\theta}_1$ and $\hat{\theta}_2$ are correlated ? Obviously, $\hat{\theta}_1$ and $\hat{\theta}_2$ are not independent, but nevertheless I thought they would be uncorrelated. My reasoning was that the dependence of $p$ only affects the allocation between $X$ and $Y$ , and doesn't introduce any bias as far as the expected value of $\bar{X} - \bar{Y}$ . I feel like I oversimplified this, but I'm a bit stuck as to how to work this out rigorously. EDIT: As an answer below pointed out, this problem may be more interesting if we restrict $p \in (0,1)$ . Or to put it another way, if we require $\bar{X}_1, \bar{X}_2, \bar{Y}_1$ and $\bar{Y}_2$ to all have nonzero probability of containing points. Edit made above.","['statistics', 'independence', 'probability', 'sampling']"
2965071,Functional equation $f(x+y) = f(x)e^y+ f(y)e^x + 2xye^x e^y$,"If $f(x)$ be a differentiable function which satisfies the functional equation $f(x+y) = f(x)e^y+ f(y)e^x + 2xye^x e^y~~ \forall ~x,y \in \mathbb R,$ and $f'(0)= 0$ then the number of solutions of $f(x)= 0$ is? Attempt: I have obtained $f(0)=0$ by putting $x=y=0$ . But I am really struggling after that. I have tried by putting $y=-x$ but that isn't helping. Even after differentiating wrt x then putting $y =-x$ doesn't help. What is the trick/method to solve this question? Answer is: 1","['calculus', 'functions', 'derivatives']"
2965106,Can a sequence of finitely many elementary operations/algorithm give a specific closed form for a recurrence relation?,"$$\color{blue}{\textbf{Tldr : How to prove the following algorithmically without induction?}}$$ $$\color{red} {a_{n} = 1 + \left(\dfrac{n+1}{2n}\right) a_{n-1} \implies a_{n} = \sum _{r=0}^{n} \dfrac{1}{\binom{n}{r}}}  $$ Consider the sequence $$ a_{n} = \sum _{r=0}^{n} \dfrac{1}{\binom{n}{r}} \tag{*}$$ I proved here (Lemma 1) that it satisfies the recurrence relation $$a_{n} = 1 + \left(\dfrac{n+1}{2n}\right) a_{n-1} \tag{$\dagger$}$$ Now, we can solve this recurrence relation by forming telescopic sums by a sequence of finitely many elementary operations (addition, multiplication, compositions of elementary functions etc.), to obtain an alternative closed form. In particular, $$\dfrac{2^n}{n+1}a_n - a_1 = \sum_{r=2}^{n} \left(\dfrac{2^r}{r+1} a_{r} - \dfrac{2^{r-1}}{r} a_{r-1} \right) = 
\sum_{r=2}^{n} \dfrac{2^r}{r+1}$$ Which, after simplifying, gives the elegant identity, $$ a_n = \sum_{r=0}^{n} \dfrac{1}{\binom{n}{r}} = \left(\dfrac{n+1}{2^{n+1}}\right) \sum_{r=1}^{n+1} \dfrac{2^r}{r} $$ Question : Is it possible to recover the original closed form $(*)$ , without prior knowledge of it and just from the recurrence $(\dagger)$ and some initial values, by using a sequence of finitely many elementary operations (similar to what was done for the other closed form obtained here)? Elaborating on what I'm looking for : I'm looking for an algorithm to get $(*)$ from $(\dagger)$ , involving finite combinatorial methods (elementary operations, binomial transforms etc.), so Integrals are excluded. I wrote ""without prior knowledge"" to avoid the use of ansatz . Methods based on induction assume prior knowledge and are excluded. I'm seeking an algorithm so that it can be generalized to a large class of recurrence relations.","['combinatorics', 'recurrence-relations', 'discrete-mathematics', 'sequences-and-series']"
2965126,"Borel-Cantelli and ""infinitely often""","The problem: Let $(X_n)_{n\geq 1}$ be a real-valued sequence of i.i.d. random variables and let $c > 0$ . Use Borel-Cantelli's lemma to show that $$\sum_{n=1}^\infty P(X_n^2 > n) < \infty \Rightarrow P(|X_n|\geq c\sqrt{n} \hspace{7pt} \text{i.o.} \hspace{7pt} )=0.$$ My attempt: So from Borel-Cantelli we have $$P(X_n^2 > n \hspace{7pt}\text{i.o.}\hspace{7pt})=0$$ and using the definition of ""infinitely often"": $$\bigcap_{m=1}^\infty \bigcup_{n=1}^\infty (X_n^2 > n)=\bigcap_{m=1}^\infty \bigcup_{n=1}^\infty (|X_n| > \sqrt{n})$$ But I don't see how I get the inclusion into the event containing $c$ .","['borel-cantelli-lemmas', 'probability-limit-theorems', 'probability-theory', 'probability']"
2965136,Martingale oscillating between three values,"I'm self-studying Martingales. I came accross the following exercise (exercise 4.3.1.) in Durrett's Probability Theory and Examples (5th Edition). Exercise. Give an example of a martingale $X_n$ with $\sup_n|X_n|<\infty$ and $\mathbb P(X_n = a \text{ i. o. } )=1$ for $a=-1,0,1$ . Attempt 1. I think that something in the following lines works. Fix the probability space $(\Omega,\mathcal F,\mathbb P)$ . Define the independent sequence of random variables $\xi_k$ such that $$\mathbb P(\xi_k= 0) = \frac 1{k^2}, \ \ \ \ \mathbb P(\xi_k = 1) = 1-\frac{1}{k^2} $$ Then I set \begin{align*}
X_n = \sum_{k=1}^n (-1)^k (\xi_k-\mathbb E[\xi_k])
\end{align*} This $X_n$ is a martingale with respect to its natural filtration. I know from the First Borel Cantelli that for $\mathbb P$ -a.s. $\omega \in \Omega$ after some index $K$ we have $\xi_k(\omega)=1$ for all $k>K$ . So I guess that I can say that $X_k$ is almost surely oscillating. I think it is very clear that this does not mean that it oscillates between the three values $-1,0$ and $1$ . I think that something like that works, but I am at the same time skeptic about that because $$ |X_{n+1}-X_n| = |\xi_{n+1}-\mathbb E[\xi_{n+1}]| \leq 2$$ But then from a previous theorem (in the same book) I know that $X_n$ either converges or oscillates between $-\infty$ and $\infty$ which makes the confusion only worse. This means that if I take $X_n= \sum_{k=1}^n \eta_k$ with $\eta_k$ independent random variables, then we should have that $|\eta_k|$ is not bounded by a real number. Attempt 2. I thought maybe three values for $a$ is a little difficult. I tried to construct one martingale oscillating between two values. Let $U_n$ and $V_n$ be two Martingales w.r.t. some filtration $\mathcal F_n$ that converge to $0$ and $1$ respectively. Let $A_n$ be a Bernouilli random variable that is predictable. Then I take $X_n$ as $$X_n = A_n U_n + (1-A_n)V_n$$ This $X_n$ is clearly a Martingale, but I don't know how to proceed rigorously or if it even works. How can I make sure that for almost surely $\omega\in\Omega$ the sequence $A_n(\omega)$ is oscillating?","['stochastic-processes', 'probability-theory', 'martingales']"
2965155,Using the sequential definition of a limit to show $\lim_{x\to 0} \frac{x^2}{x} = 0.$,"I have the following definition for a limit: Definition : Given a function $f : D \rightarrow \mathbb{R}$ and a limit point $x_{0}$ of its domain $D$ , for a number $\ell$ , we write $$ \lim_{x\to x_{0}} f(x) = \ell$$ provided that whenever $\{x_{n}\}$ is a sequence in $D \ - \{x_{0}\}$ that converges to $x_{0}$ , $$\lim_{n\to\infty} f(x_{n}) = \ell. $$ Using this definition, I want to show that $\lim_{x\to 0} x^2/x = 0$ . Here is my attempt: Let $\{x_{n}\}$ be a sequence in $\mathbb{R} - \{0\}$ such that $\{x_{n}\}$ converges to $0$ . This means for all $\epsilon > 0$ , there exists an index $N$ such that $$|x_{n} - 0| < \epsilon $$ for all $n \geq N$ . To prove the original claim, we need to show for all $\epsilon > 0$ , there is an index $N'$ such that $$|\frac{x_{n}^{2}}{x_{n}} - 0| < \epsilon $$ for all $n \geq N'$ . But, note that $$|\frac{x_{n}^{2}}{x_{n}} - 0| = |\frac{x_{n}^{2}}{x_{n}}| = |x_{n}| = |x_{n} - 0|,$$ so setting $N' = N$ suffices. $\blacksquare$ Is my proof correct? Is there anything that can be made better?","['limits', 'real-analysis']"
2965184,Basic but illuminating examples of statistical modeling,"I'd like to know the best examples that are simple and easy to understand, but which also capture the essence and the spirit of statistical modeling. What are some simple but also fundamental and illuminating examples of statistical modeling? Edit: Here is another way to phrase the question: If a student asked you what statistical modeling is, what examples would you tell them? You would want the examples to somehow capture the essence of the subject without being too complicated. Edit 2: I'll attempt to provide an example myself.
 What fraction of the population is planning to vote for candidate A? We introduce a random variable $X$ that is the result of selecting
a person at random from the population and checking whether or not the person is planning to vote for A. If the person is planning to vote for A
then $X = 1$ , otherwise $X = 0$ . We make a modeling assumption that $X$ has a Bernoulli distribution with parameter $p$ . This is a simple but concrete and fundamental example of a statistical model. Suppose that we select $n$ people at random from the population (with replacement) and the random variable $X_i$ is $1$ if the $i$ th person is planning to vote for A, and zero otherwise. Then $$
\hat p = \frac{X_1 + \cdots + X_n}{n}
$$ estimates the value of $p$ . When we estimate the parameter $p$ in this way we have performed statistical inference . I think this little example contains the key ideas of statistical modeling and statistical inference. A student can think of this example and say, ""Ah, now I know what statistical modeling and statistical inference are."" But please correct me if you have any disagreements, or if I've used any terms incorrectly, as I'm a bit of an outsider to the field of statistics. I'd be interested in hearing other examples like this that are basic but fundamental and illuminating.","['p-value', 'statistical-inference', 'statistics']"
2965187,How many different tournament orderings are there?,"Assume you have 4 people or teams in a tournament. There will be three games: 3
    1     2
  a   b  c  d The people/teams in this case are the letters, and 3 (i.e., $n - 1$ ) games must be played. The only requirement is that games 1 and 2 must happen before game 3. Below are the possible orderings that the games can be played: 12 | 3 21 | 3 Simple enough. Now let's say there are 8 players/teams, and therefore 7 total games. We'll have two trees the same size as above: 7
      3           6
   1     2      4    5 Each total ordering will be of format xxxxxx7 , but the number of orderings will clearly not be the number of ways to arrange 6 items ( $6!$ ), because we have some requirements: Game 6 must be before both games 4 and 5 Game 3 must be before both games 1 and 2 So we have the two sets of orderings for each tree, ( $(123, 213)$ , and $(456, 546)$ ), and we somehow have to merge them. We can't just take the cartesian product of the two sets though, because we have to account for the game orderings to be intertwined (orderings like $1423567$ ) This feels very factorial-esque but I'm not entirely sure how to treat the restrictions. For example any one of 4 possible games can be played first: 4 * _ * _ * _ * _ * _ Any one of 3 possible games can be played second: 4 * 3 * _ * _ * _ * _ But for the third game, some combinations up to this point have 3 possibilities, and some have 2, which makes the rest complex. I'm not sure how to extend the ""merging"" or the math in this case, to either: Find the number of total orderings of $n$ games ( $n + 1$ players) Actually generate all possible combinations of $n$ games","['trees', 'combinations', 'combinatorics', 'discrete-mathematics']"
2965193,"Prove that given any ﬁve integers, there will be three for which the sum of the squares of those integers is divisible by 3.","Basically the question is asking us to prove that given any integers $$x_1,x_2,x_3,x_4,x_5$$ Prove that 3 of the integers from the set above, suppose $$x_a,x_b,x_c$$ satisfy this equation: $$x_a^2 + x_b^2 + x_c^2 = 3k$$ So I know I am suppose to use the pigeon hole principle to prove this. I know that if I have 5 pigeons and 2 holes then 1 hole will have 3 pigeons. But what I am confused about is how do you define the hole? Do I just say that the container has a property such that if 3 integers are in it then those 3 integers squared sum up to a multiple of 3?","['pigeonhole-principle', 'discrete-mathematics']"
2965220,"Random variables and co-variance, Statistics 318","For the given example in the book John E. Freund's Mathematical Statistics with Applications, 8th edition, by Miller and Miller. ISBN: 9780321807090 I've highlighted using colors what numbers corespond with what is given (Blue, Green, and Yellow). What I don't understand is where the highlighted red numbers come from. The example states it uses ""Theorem 15"" I'm just confused on how. ""The following is another important theorem about linear combinations of random
variables; it concerns the covariance of two linear combinations of n random
variables.""","['statistics', 'covariance', 'variance', 'discrete-mathematics', 'random-variables']"
2965228,"If rank$(A) = 2$, then $A^2 \neq 0_3$","Let $A$ be a real $3 \times 3 $ matrix such that rank $(A) = 2$ . Prove that $A^2 \neq 0_3$ . where $0_3$ represents the null matrix of order $3$ . I am looking for a solution involving only basic manipulation using matrices. I already have a better solution using the range and the nullity of $A$ . Thank you in advance! Edit. No Sylvester's inequality, Jordan form or range+nullity / linear transformations. At most use the definition of the rank as the dimension of the column/row space.","['matrices', 'matrix-rank', 'linear-algebra']"
2965285,Closed sets: definition(s) and applications,"My textbook has not been very clear (at least to me) with respect to closed sets. I have the following understanding. These two definitions are equivalent with respect to closed sets: (1) A closed set is any set that contains all of its limit points. (2) A closed set is any set that contains all of its boundary points. Does (1) imply (2), and vice versa, or is the implication only from (1) to (2)? Are there any other definitions of a closed set? It is not true that simply because a set contains a point $p$ such that all neighborhoods $N_rp$ contain points in the set and points not in the set that the set is closed. In other words, simply because a set contains some of its boundary points does not mean it is closed. So, I was thinking about the $\mathbb{N}$ atural numbers and was confused when considering any singleton $\{a\} \subset \mathbb{N}.$ First, can you even talk about neighborhoods of non-integer radii when talking about the natural numbers? Isn't there something unnatural, or ""unfair"" about considering a radius $r$ such that $0 < r < 1?$ Does the radius have to be an element of the metric space you are considering? Assuming you can, it is easily apparent that the singleton is open, for there exists a neighborhood $N_ra$ of $a$ that contains only points in $\{a\},$ namely any neighborhood that has a positive radius less than 1. By definition (1), the singleton is closed, as we can construct the constant sequence $(x_n)$ such that $x_n = a$ for all $n \in \mathbb{N}.$ This is the only singleton that may defined in $\{a\},$ it it converges to $a,$ which, of course, is in the set. How would you consider the singleton under the second definition? I suppose it doesn't have ANY boundary points, as there are neighborhoods of $a$ that do not contain points in $\mathbb{N} \setminus \{a\}.$ If we consider any singleton set in $\mathbb{R},$ the set is closed, but not open by the same understanding.","['general-topology', 'real-analysis']"
2965338,Find the function given partial derivatives and points,"Find $f$$(x,y)$ given $f_x$$= $$3x^2y-4y^2$ and $f_y$$=$$x^3-8xy+6y$ and $f$$(1,1)$$=$$5$ Can anyone steer me in the right direction here? I assume I have to integrate but we haven't done integration with multivariable functions yet. Any help at all is appreciated.","['partial-derivative', 'multivariable-calculus']"
2965360,Frobenius Norm Inequality; Spectral Radius is smaller than Frobenius Norm,"Let $A \in \mathbb{R}^{n \times m}$ and $x \in \mathbb{R}^n$ . Prove the following inequality. $\left\lVert \cdot \right\rVert_F$ denotes the Frobenius norm and $\left\lVert \cdot \right\rVert_2$ denotes the $p$ -norm with $p=2$ . $$\left\lVert Ax \right\rVert_2 \leq \left\lVert A \right\rVert_F \left\lVert x \right\rVert_2$$ tl;dr: I'm essentially stuck at this (or similar) inequality: $$ \lambda_{max} (A^T \cdot A) \leq \left\lVert A^T \cdot A \right\rVert_F$$ while $\lambda_{max}$ is the largest eigenvalue of $A^T \cdot A$ . I know that this inequality holds if the norm was a natural norm, but since frobenius norm isn't induced by a vector norm, I'm not sure how to proceed. How I got to this point: $$\left\lVert Ax \right\rVert_2 \leq \left\lVert A \right\rVert_2 \left\lVert x \right\rVert_2$$ So we have to show: $$\left\lVert A \right\rVert_2 \leq \left\lVert A \right\rVert_F$$ or $$\left\lVert A \right\rVert_2^2 \leq \left\lVert A \right\rVert_F^{2}$$ We have: $$\left\lVert A \right\rVert_2^2 = \lambda_{max}(A^TA) \leq \left\lVert A^T A \right\rVert_F$$ The last inequality is the part I can't prove. If I could show it, we have: $$\left\lVert A^T A \right\rVert_F \leq \left\lVert A^T \right\rVert_F \left\lVert A \right\rVert_F = \left\lVert A \right\rVert_F^2$$ Which was the thing we wanted to show above. These threads were helpful: Show that $ \lVert A \rVert_2^2 \leq \lVert A \rVert _1 \lVert A \rVert _ \infty $ The spectral radius of the matrix $A$ is less than or equal any natural norm Anyways, thank you for your help. It is greatly appreciated.","['matrices', 'spectral-radius', 'linear-algebra', 'matrix-norms', 'inequality']"
2965376,Maximum of beta-distributed random variables,"Let $X_i \sim \operatorname{Beta}(\alpha_i, \beta_i)$ be independent beta-distributed random variables for $i = 1, \ldots, k$ .    What can we say about $$X =\max(X_1, \ldots, X_k)?$$ In particular, can we estimate $\alpha$ and $\beta$ so that $X$ is approximately distributed like $\operatorname{Beta}(\alpha, \beta)$ ?  We may assume that $\sum_i \alpha_i + \sum_i \beta_i$ is large if it helps. We can reduce the question to the case $k =2$ , since $$\max(X_1, \ldots, X_k) = \max(\max(\max(X_1, X_2),X_3, \ldots))),$$ although some accuracy might be lost in making successive approximations.  Note also that we have $$P(\max(X_1, X_2) \leq z) = P(X_1 \leq z, X_2 \leq z) = P(X_1 \leq z) P(X_2 \leq z),$$ giving the cumulative distribution function for $X$ . Using Sage I was able to take the case $\alpha_1 = 10,\beta_1 = 15,\alpha_2 = 13,\beta_2 = 12$ and approximate the density function of $X$ pretty well with $\alpha =  16.796, \beta = 14.830$ .  See image. Context: This would be useful for the bandit problem or Monte-Carlo tree search .  Suppose you are playing $k$ games $Y_i$ , and $Y_i$ is either a win, with probability $p_i$ , or a loss.  Then the game $Y$ which consists of a choice of one of the games $Y_i$ can be modeled by a Bernoulli random variable with parameter $p = \max(p_1, \ldots, p_k)$ , since the best strategy is to always choose the game $Y_i$ that has the highest win rate.  If we only have limited information about each $Y_i$ (some samples of each, for example), we can put a prior $p_i \sim \operatorname{Beta}(\alpha_i, \beta_i)$ on each parameter $p_i$ and try to infer information about $p$ from this.",['statistics']
2965451,What are the necessary and sufficient condions for a laplacian to be zero?,"Let $F$ be a function of $x,y,z$ , namely $F(x,y,z)$ . My question: What are the necessary and sufficient conditions for $\triangledown$$^2$$F(x,y,z)$ = $0$ , what does it signify? I am aware that if $d$ is a differential operator, then $d$ $(\triangledown$$F(x,y,z))$$=0$ , where $i, j, k$ are $dx,dy,dz$ respectively. That is, $d(\frac{\partial F}{\partial x}dx,\frac{\partial F}{\partial y}dy,\frac{\partial F}{\partial z}dz)=0$ . I know this is true if $F(x,y,z)$ is the force associated with a conservative potential function or in other words conservative vector field. However, I can not seem to relate it with the Laplacian. Are the two related, or they just seem related to me? Thank you.","['laplacian', 'physics', 'multivariable-calculus', 'vector-analysis']"
2965459,How to convince someone with calculus or plots that the curve $x y - 1 = 0$ is connected over complexes?,"Some curves defined by polynomial equations are disconnected over reals but not over complexes, e.g., $x y - 1 = 0$ . How can we convince someone with background only on equations over reals that the curve drawn by above equation  is connected over complexes? Is a plot or something possible, for example? It will be a 4d plot if x and y are expanded to real and imaginary parts.
Any other plot, or algebraic way to show connectedness?","['path-connected', 'connectedness', 'algebraic-geometry', 'complex-numbers']"
2965499,How to prove $f(x) = 4x^{3} + 4x - 6$ has exactly one real root?,"How can I show that $f(x) = 4x^{3} + 4x - 6$ has exactly one real root? I think the best way is to show $f'(x) = 12x^2 + 4 > 0$ for all $x \in \mathbb{R}$ . Thus, $f'(x)$ has zero real roots. Thus, $f(x)$ has at most one real root. I thought about trying to show that if $f$ is a polynomial and $f'$ has $n$ real roots, then $f$ has $n + 1$ roots by using Rolle's Theorem or Mean Value Theorem, but I don't think this fact, in general, is true. I would need to prove this statement. Can someone please help me prove this fact?",['real-analysis']
2965514,Suppose $f : \mathbb{R} \rightarrow \mathbb{R}$ is a function with the following properties,"I've been stuck on the following math question: Let $f : \mathbb{R} \rightarrow \mathbb{R}$ have two derivatives with $f(0) = 0$ and $f'(x) \leq f(x)$ for all $x$ . Is $f(x) = 0$ for all $x$ ? I've tested several functions, and I believe the answer is true. I have no clue about how to prove this statement though. For example, if we have a constant function $f(x) = c$ , then we must have $c = 0$ due to the $f(0) = 0$ condition. I've also tried polynomial and trignometric functions, and I cannot find a counterexample. I thought about somehow using the Mean Value Theorem or Rolle's Theorem, but I didn't get anywhere with either of those.","['functions', 'derivatives', 'real-analysis']"
2965544,"Partial Derivatives of $F(x,y,z)$ where $z = f(x,y)$","When finding the tangent plane of a surface, given by $z = f(x,y)$ , one method for doing so is writing $z$ implicitly: $F(x,y,z) = z - f(x,y) = 0.$ It is well established that the tangent plane of $F(x,y,z) = 0$ at $P(a,b,c)$ , in general, is (1) $$F_x(a,b,c)(x-a) + F_y(a,b,c)(y-b) + F_z(a,b,c)(z-c) = 0.$$ However, the corollary of this theorem is that if $z = f(x,y)$ , then the tangent plane is given by (2) $$-f_x(a,b)(x-a) + -f_y(a,b)(y-b) + (z-c) = 0.$$ What I do not understand is why this follows from the (1). In particular, let's examine $F_x(a,b,c). F_x(a,b,c) = F_x(z - f(x,y))$ . I am confused why $F_x(z) = 0$ . I thought $z = f(x,y)$ , so shouldn't $F_x(z) = F_x(f) = f_x(a,b)$ ? Why can we treat $z$ as a constant here if it is a function of $x$ (and $y$ ).","['partial-derivative', 'multivariable-calculus']"
2965640,Why is the number of ways of choosing $0$ items from $n$ items $1$?,It seems easy to grasp that number of ways of choosing $n$ items from $n$ items is 1. But I am unable to understand why is it 1 for choosing 0 items.,['combinatorics']
2965711,On Hartshorne Chapter II exercise 1.13,"I am trying to solve the question about espace etale of a presheaf on Hartshrone (Chap II ex 1.13): Given a presheaf $\mathcal{F}$ , we define a topological space $$\mathrm{Spe(\mathcal{F})}=\coprod_{p\in X}\mathcal{F}_p$$ with the strongest topology such that for all the maps $$\bar{s}:U\rightarrow \mathrm{Spe(\mathcal{F})}$$ which sends $P$ to the germ $s_P$ for all $U$ , and all $s\in\mathcal{F}(U)$ are continuous. Show that for any $U\subset X$ , the associated sheaf $\mathcal{F}^+(U)$ is the set of continuous sections of $\mathrm{Spe(\mathcal{F})}$ over $U$ . My try: Here the only difficult part is to show any continuous section $\bar{s}$ of $\mathrm{Spe(\mathcal{F})}$ over $U$ is an element in $\mathcal{F}^+(U)$ , i.e. $\bar{s}(P)\in \mathcal{F}_P$ for any $P\in U$ : this is clear from the definition of section; for every $P\in U$ , there exists a neighborhood $V$ and $t\in \mathcal{F}(V)$ such that for every $Q\in V$ we have $s(Q)=t_Q$ . I am struggling about the second part. Naturally, if we take a point $P\in U$ , then $s(P)=\langle V,t\rangle$ for some open subset $V\subset X$ and $t\in \mathcal{F}(U)$ . I don't know how to continue. It seems that the only thing we can use here is $\bar{s}$ is continuous. So the expected neighborhood might be of the form $\bar{s}^{-1}(W)$ for some open set in $\mathrm{Spe(\mathcal{F})}$ . Any hints and answers are welcome! Remark: Someone did some relevant work here , but I think there is a mistake at the third equivalence $$\cdots\iff \bar t(P) = \bar s (P) 
\iff \langle V,t\rangle_P=\langle U,s\rangle_P \iff \cdots$$ I think $\bar{s}(P)=t_Q$ cannot imply $\langle V,t\rangle_P=\langle U,s\rangle_P$ because we do not know what $s$ is. However, if the above is true, then it will solve the problem. So probably I missed something obvious.","['algebraic-geometry', 'general-topology', 'abstract-algebra', 'sheaf-theory']"
2965725,Glueing two affine curves along a map,"Let $C = V(y^2 - x^4 - 1) \subset \Bbb A^2$ and set $C_0 = C \times \{0\}, C_1 = C \times \{1\} \subset \Bbb A^3$ . Consider the space $X$ obtained by quotienting $C_0 \sqcup C_1$ but the relation $((x, y) ; 0) \sim (1/x, y/x^2)$ for all $y$ and all $x \neq 0$ .
According Miranda III.1.7, $X$ is a smooth projective curve (and hyperelliptic).
Thus $X = Proj(S)$ for some graded ring $S$ . My question: can you describe explicitly the ring $S$ (up to isomorphism of $k$ -algebras)? Typically, the comments in this question tells that if we replace $C$ by $\Bbb A^1$ and $\sim$ by $(x;0) \simeq (1/x, 1)$ , we get $S = k[x_0,x_1]$ , yielding $X = \Bbb P^1_k$ . But what is $S$ in our case?","['curves', 'algebraic-geometry']"
2965737,Finding an Expression as an Elementary Function for a Power Series,"Consider $$h(z)=\sum_{n=1}^{\infty}\frac{(z-2)^n}{n}.$$ I wish to find an expression for $h$ as an elementary function. This question has me stumped. I considered another function, $$f(z)=\sum_{n=1}^{\infty} n(z-2)^n.$$ This is much easier to express as an elementary function, as $$f(z)=\sum_{n=1}^{\infty} n(z-2)^n=(z-2)\frac{d}{dz}\sum_{n=1}^{\infty} (z-2)^n=\frac{z+3}{(z+2)^2}.$$ But for the function $h$ , I cannot see a similar technique or a manipulation to yield such a function. I would really appreciate a hint .","['complex-analysis', 'power-series', 'proof-verification']"
2965740,"What is the limit of zero times x, as x approaches infinity?","I am having difficulty determining is the solution for the following problem: $$\displaystyle \lim_{x \rightarrow \infty}\left( x \times 0 \right)$$ To clarify, this question assumes ${0}$ is a constant and is absolutely zero (""true zero""), and not another figure approaching or is approximately zero (""near zero""). Thus, the question is not asking what ""near zero"" times ""near infinity"" is. I know that ${\infty *0}$ is undefined, however my difficulty is that I'm unsure whether the answer to the problem is undefined because ${\infty *0}$ is undefined. From my understanding, a limit does not ever 'reach' infinity - it only approaches infinity, thus there are a rational amount of numbers. As ${x\cdot 0=0}$ , when x is not ${\infty}$ , it seems to me that in all cases of $x$ approaching infinity the answer could also be ${0}$ .",['limits']
2965769,Are these conditions equivalent to the definition of regular coordinate ball?,"In page 15 of Lee's book ""Introduction to Smooth Manifolds"", there's a paragraph as follows: We say a set $B\subset M$ is a regular coordinate ball if there is a smooth coordinate ball $B'\supset \bar B$ and a smooth coordinate map $\varphi:B'\to \Bbb R^n$ such that for some positive real numbers $r<r'$ , $\varphi (B)=B_r(0),\quad\varphi(\bar B)=\bar B_r(0),\quad$ and $\varphi (B')=B_{r'}(0).$ If we change the above definition as follows: We say a set $B\subset M$ is a regular coordinate ball if there is a smooth coordinate ball $B'\supset B$ and a smooth coordinate map $\varphi:B'\to \Bbb R^n$ such that for some positive real numbers $r<r'$ , $\varphi (B)=B_r(0), \quad\varphi (B')=B_{r'}(0).$ Are they equivalent?","['smooth-manifolds', 'geometric-topology', 'manifolds', 'general-topology', 'differential-topology']"
2965880,About the proof that “ a bounded and monotone sequence is convergent”,"I read a reference about the proof of  “a bounded and monotone sequence is convergent”, in a certain PDF written by a physics professor. Details of the reference is that the proposition  “a bounded and monotone sequence is convergent” cannot be proved without the contradiction method. But,I look up the proof of the theorem in other three books , This theorem is apparently not proved with indirect proof in any books. I am very confused.
Maybe,
I think that we implicitly use reductio ad absurdum in the demonstration of the proposition. I wish people familiar with this problem which answer.","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
2965884,How would you integrate the trignometric integral function Si(x)?,"The function Si(x) can be obtained when we integrate $\frac {sin(x)}x$ .
But how would we go about integrating Si(x)? More information about the function Si(x) can be found here https://en.wikipedia.org/wiki/Trigonometric_integral","['integration', 'calculus', 'functions', 'indefinite-integrals', 'trigonometry']"
2965909,How to prove that a function belongs (or does not belong) to $H^{\frac12}_{00}$,"Given a domain $\Omega$ , the space $H^{1/2}(\partial \Omega)$ can be defined as the image of the trace operator $\gamma: H^{1}(\Omega) \rightarrow H^{1/2}(\partial \Omega)$ , which (roughly speaking) is the linear operator that associates to each $\varphi \in D(\overline{\Omega})$ its restriction over $\partial \Omega$ i.e. $\gamma 
 \varphi = \varphi|_{\partial \Omega}$ . Note that extending the definition of $\gamma$ from $D(\overline{\Omega})$ to $H^1({\Omega})$ is legit because the latter is dense in the former. In my understanding, given a portion of the boundary $\Gamma \subset \partial \Omega$ , the space $H^{1/2}_{00}(\Gamma)$ is defined as the space of functions with support on $\Gamma$ whose trivial extension by zero outside of $\Gamma$ belongs to $H^{1/2}(\partial \Omega)$ . My question is: given a generic function on $\Gamma$ , how can one be sure that it belong to $H^{1/2}_{00}(\Gamma)$ ? I believe that this question can be linked to the well-posedness of the following problem. Let us consider the domain $\Omega = (0,1)^2$ and the problem $-\Delta u = f$ in $\Omega$ , $u = g$ on $\Gamma_D = \{1\} \times (0,1)$ and $u = 0$ on $\partial \Omega \setminus \Gamma_D$ . Does this equation admit a solution $u \in H^1(\Omega)$ for a general function $g$ ? If not, under which conditions does the solution live in such space?","['trace', 'functional-analysis']"
2965913,Primitive Pythagorean Triples odd number pattern,"I'm reading ""Friendly Introduction to Number Theory"". Now I'm working on Primitive Pythagorean Triples Exercises 2.3 (a) on P19. 2.3. For each of the following questions, begin by compiling some data; next examine the
     data and formulate a conjecture; and finally try to prove that your conjecture is correct. (But
     don't worry if you can’t solve every part of this problem; some parts are quite difficult.) (a) Which odd numbers $a$ can appear in a primitive Pythagorean triple ( $a, b, c)$ ? https://www.math.brown.edu/~jhs/frintch1ch6.pdf (1) $a^2 + b^2 = c^2$ with $a$ odd, $b$ even, $a$ , $b$ , $c$ having no common factors (2) $a^2 = c^2 - b^2 = (c-b)(c+b)$ (3) $c + b = s^2$ and $c - b = t^2$ (4) $c = \frac{(s^2 + t^2)}{2}$ and $b = \frac{(s^2 - t^2)}{2}$ (5) $a = \sqrt{(c-b)(c+b)} = st$ (6) $a = st$ , $b = \frac{(s^2 - t^2)}{2}$ , $c = \frac{(s^2 + t^2)}{2}$ I compiled some data and examining it but I can't find the pattern. Can you see any patterns? I need a hint. https://github.com/y-zono/friendly-introduction-number-theory/blob/master/02/2-3/main.go {a   b  c   s  t}
--------------
{3   4  5   3  1}
{5  12  13  5  1}
{7  24  25  7  1}
{9  40  41  9  1}
{11 60  61  11 1}
{13 84  85  13 1}
{15 8   17  5  3}
{15 112 113 15 1}
{17 144 145 17 1}
{19 180 181 19 1}
{21 20  29  7  3}
{33 56  65  11 3}
{35 12  37  7  5}
{39 80  89  13 3}
{45 28  53  9  5}
{51 140 149 17 3}
{55 48  73  11 5}
{57 176 185 19 3}
{63 16  65  9  7}
{65 72  97  13 5}
{77 36  85  11 7}
{85 132 157 17 5}
{91 60  109 13 7}
{95 168 193 19 5}
{99 20  101 11 9}

a:   3 5 7 9 11 13 15 15 17 19 21                33 35    39       45       51    55 57       63 65                77          85       91    95    99
odd: 3 5 7 9 11 13 15    17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 Update 1 According davidlowryduda's advice, I compiled some more data. Then I found 23 was appeared. // max of s = 20
a:   3 5 7 9 11 13 15 15 17 19 21                33 35    39       45       51    55 57       63 65                77          85       91    95    99
odd: 3 5 7 9 11 13 15    17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99

// max of s = 30
a:   3 5 7 9 11 13 15 15 17 19 21 21 23 25 27 29    33 35    39       45       51    55 57       63 65    69       75 77          85 87    91    95    99
odd: 3 5 7 9 11 13 15    17 19 21    23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 And now 31 is not appeared but I can assume that the number exist when I compile some data more. $s=31$ and $t=1$ or $s=1$ and $t=31$ $s=31$ , $t=1$ then $(s^2−t^2)/2=(961−1)/2=480$ and $(s^2+t^2)/2=(961+1)/2=481$ $31^2+480^2=481^2$ So it turns out that 31 appears. // max of s = 40
3 5 7 9 11 13 15 15 17 19 21 21 23 25 27 29 31 33 33 35 35 37 39 39       45       51    55 57       63 65    69       75 77          85 87    91 93 95    99
3 5 7 9 11 13 15    17 19 21    23 25 27 29 31 33    35    37 39    41 43 45 47 49 51 53 55 57 59 61 63 65 67 69 71 73 75 77 79 81 83 85 87 89 91 93 95 97 99 I confirmed that 31 appeared when I showed the data more. And the 41 is not showed this time.. So I can assume that all odds numbers appear and I think I can find something the pattern.",['number-theory']
2965974,Understanding the proof of infinitely many primes $\equiv 3\pmod{\!4}$,"Theorem: There are infinitely many primes congruent to $3 \mod 4$ . Proof: Assume that $p_1 = 3, . . . , p_n$ are primes of the form $p_j ≡ 3 \mod 4$ . We will construct a new one by looking at $N = 4p_1 · · · p_n − 1$ (putting $N = 4p_1 · · · p_n+3$ would also work). There is more to this proof but the rest of it I understand, what I don't get is where it says "" $N = 4p_1 · · · p_n − 1$ (putting $N = 4p_1 · · · p_n+3$ would also work)"". I do not understand why we are writing $4p_1 · · · p_n − 1$ . Is there a more clear way to prove this theorem?","['number-theory', 'discrete-mathematics', 'prime-numbers']"
2966023,"Suppose $ \alpha, \beta>0 $. Compute: $ \int_{0}^{\infty}\frac{\cos (\alpha x)-\cos (\beta x)}{x}dx $","Suppose $ \alpha, \beta>0 $ . Compute: $$ \int_{0}^{\infty}\frac{\cos (\alpha x)-\cos (\beta x)}{x}dx $$ Here is what I do: $$\begin{align}
\int_{0}^{\infty}\frac{\cos (\alpha x)-\cos (\beta x)}{x}dx &= \int_{0}^{\infty}dx\int_{\alpha}^{\beta}\sin (yx)dy\\
&=\int_{\alpha}^{\beta}dy\int_{0}^{\infty}\sin(yx)dx\\
& \\
&   \qquad\text{let $ yx=u $}\\
& \\
&=\int_{\alpha}^{\beta}\frac{1}{y}dy\int_0^{\infty}\sin u du\\
&=\int_{\alpha}^{\beta}\frac{1}{y}dy\left( -\cos u|_{\infty}+\cos u|_0 \right)\\
&=\log\frac{\beta}{\alpha}(-\cos(\infty)+1)\\
&=\log\frac{\beta}{\alpha}-\cos(\infty)\log\frac{\beta}{\alpha}
\end{align}$$ But $ \cos(\infty) $ does not exist right? Does it mean the integral actually diverse? Edit: The question comes from https://math.uchicago.edu/~min/GRE/files/week1.pdf Who can point out my mistake in the above deduction?","['integration', 'calculus']"
2966084,What is wrong with this fake proof that subgroup of a cyclic group is cyclic?,"Let $G$ be a cyclic group generated by $a$ and $H$ its subgroup. This is a proof by contradiction. Assume there is no $r$ in $H$ such that $\langle r \rangle = H$ . If some $s$ in $G$ is not in $H$ then $\langle s \rangle \neq H$ . So for all $s$ in $G$ , $\langle 
s \rangle \neq H$ Thus for all $s$ in $G$ there exists an $h\in H$ such that $h \notin \langle s \rangle$ . But this is a contradiction with the fact that $a$ generates $G$ . I know this proof is fake, because it does not use the fact that $H$ is a subgroup but I am unable to find the mistake(s).","['group-theory', 'fake-proofs']"
2966123,Formula for the least element on the spectrum,"Let $A$ be a self-adjoint operator defined on a dense subset of an Hilbert space $\mathcal{H}$ . Assume that $A$ is bounded below in the sense there is $m \in \mathbb{R}$ such that $$\langle Ax,x\rangle \geq m,~\forall x : \|x\| = 1.$$ I want to show that: $$ m = \inf\{\lambda : \lambda \in \sigma(A)\} = \inf \{\langle Ax,x\rangle : \|x\| = 1\}.$$ I know that if $E_A$ denotes the unique spectral measure that represents $A$ , then $\mathrm{supp}~E_A = \sigma(A),$ from which follows the first equality. So, it is only left to prove the last equality. Any hints? Thanks in advance.","['hilbert-spaces', 'functional-analysis']"
2966129,Expected value of playing a game,A game has probability $\frac13$ of winning. Someone would like to play this game and continue to play until he loses two in a row. What is the expected number of playing the game?,['probability']
2966181,Is $\Vert x \Vert_{H^m(\Omega)} = 1$ (Sobolev-norms) always a unit ball if you plot/visualise it it?,"We know that for $L^p$ norms one gets a fascinating visual display of the norms as included. Do the Sobolev norms follow the same or a similar pattern or are they always unit balls? If they are always unit balls, are for example, $H^2(\Omega)$ norm balls smaller than those in $H^1(\Omega)$ because of the compact embedding theorem? Thank you very much for your time.","['normed-spaces', 'sobolev-spaces', 'functional-analysis', 'real-analysis']"
2966238,Showing $\lim_{x\to 0} \frac{x - 1}{\sqrt{x} - 1} = 1$,"I'd like to use the sequential definition of a limit to show $\lim_{x\to 0} \frac{x - 1}{\sqrt{x} - 1} = 1$ . Here's the definition I'm using: Given a function $f : D \rightarrow \mathbb{R}$ and a limit point $x_{0}$ of its domain $D$ , for a number $\ell$ , we write $$\lim_{x \to x_{0}} f(x) = \ell $$ provided that whenever $\{x_{n}\}$ is a sequence in $D - \{x_{0}\}$ that converges to $x_{0}$ , we have $$\lim_{n\to\infty} f(x_{n}) = \ell$$ Note that this is not the standard $\epsilon-\delta$ definition of a limit . Here's my attempt at proving this claim: Let $\{x_{n}\}$ be a sequence in $\mathbb{R} - \{0\}$ that converges to $0$ . For all $\epsilon > 0$ , $\exists N$ such that $$|x_{n} - 0| < \epsilon $$ for all $n \geq N$ . To prove the claim, we require $\forall \epsilon > 0$ , $\exists N'$ such that $$\left|\frac{x_{n} - 1}{\sqrt{x_{n}} - 1} - 1\right| < \epsilon$$ for all $n \geq N'$ . However, $$\left|\frac{x_{n} - 1}{\sqrt{x_{n}} - 1} - 1\right| = \left|\frac{(\sqrt{x_{n}} + 1) (\sqrt{x_{n}} - 1)}{\sqrt{x_{n}} - 1} - 1\right| = $$ $$|\sqrt{x_{n}} + 1 - 1| = |\sqrt{x_{n}}| \leq |x_{n}|  = |x_{n} - 0|,$$ so setting $N' = N$ completes the proof. Is this correct?","['limits', 'real-analysis']"
2966250,Summation of $\sum_{i=1}^n i2^i.$ [duplicate],"This question already has answers here : Formula for calculating $\sum_{n=0}^{m}nr^n$ (4 answers) Closed 5 years ago . An intermediate step in a problem I was working on was to find a closed form for the sum $$\sum_{i=1}^n i2^i.$$ WolframAlpha returns $2^{n+1}(n-1) + 2$ , but didn't provide any step-by-step solution.  I would usually provide progress that I made, but I wasn't sure how to proceed(although I solved the problem by bashing out small values).","['algebra-precalculus', 'closed-form', 'summation']"
2966252,Convert $x^2 + y^2 = xy$ into the form $f(x) = y$ OR $f(y) = x$?,"How should I take all the ""x"" elements free from y , in order to form a ""function of x"" or a "" function of y "" ? Is this even possible ?",['functions']
2966293,"Directed, planar graph and special type of 2-colorability.","Consider a connected, planar, directed graph G whose vertices are either degree 1 or 3. Suppose further that at each order 3 vertex of G either (1) exactly two of the three adjacent edges are oriented inwards (i.e., towards the vertex) and the third edge points outwards (away from the vertex), or (2) two edges point outwards, one inwards. Assign to each order 3 vertex either 1 or 2 according to which case holds. If such a labeling of the order 3 vertices exists such that 1s and 2s are never adjacent, this gives a 2-coloring of G (the order 1 vertices are colored canonically after the order 3s are). Is it true that if such a graph G as above is 2-colorable, then there is a 2-coloring arising in this way?","['graph-theory', 'combinatorics', 'discrete-mathematics']"
2966327,Application of Lyapounov's Theorem,"I have the following exercise to fullfill: Given the system of differential equations $x'=f(x)=-\nabla{g}$ , where $x(t)\in\Bbb{R^3}$ and $g$ is $C^1$ and $f(0)=0$ and $0$ is a total maximum for $g$ , decide about the stability of the point $0$ . My attempt: I consider the function $V=g(0)-g(x)$ . Now, If the $0$ is an isolated point of maximum of $g$ and isolated equilibrium point of $f$ , we conclude that $V$ is a Lyapounov function with $\nabla{V}\cdot{f}$ $=\nabla{g}\cdot\nabla{g}$ , which is positive for $x\neq0$ . So according to the Lyapunov theorem the $0$ is unstable. My question is if we can solve the exercise given by not using the fact that $0$ is isolated, as stated in my proof. Thanks.","['linearization', 'ordinary-differential-equations', 'dynamical-systems']"
2966376,"What is the cardinality of the set {a, {a, {a}}}?","I think that the answer is 2, but I'm not 100% sure. If the answer isn't 2, could someone help lead me to the correct answer?",['discrete-mathematics']
2966454,How to prove $\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\ldots}}}}}}=\frac {\sqrt {4a-3}-1}2$,"So, I was watching this video by blackpenredpen where he mentions that $$\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\ldots}}}}}}=\frac {\sqrt {4a-3}-1}2$$ so I wanted to try and prove it myself. Let $\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\ldots}}}}}}=x$ But $\sqrt {a-\sqrt {a+\underbrace{\sqrt {a-\sqrt {a+\sqrt {a-\sqrt {a+\ldots}}}}}_x}}=x$ $\therefore \sqrt {a-\sqrt {a+x}}=x$ $a-\sqrt {a+x}=x^2$ $x^2-a=-\sqrt {a+x}$ $x^4-2ax^2+a^2=a+x$ $x^4-2ax^2-x+a^2-a=0$ Note that this is of the form $y^4+py^2+qy+r=0$ so we can use Ferrari-Cardano . We need to find a $z$ such that $(2z-p)y^2-qy+(z^2-r)$ has a discriminant of $0$ . The discriminant of $(2z-p)y^2-qy+(z^2-r)$ is equal to $q^2 - 4(2z - p)(z^2 - r),$ which simplifies to $8z^3 - 4pz^2 - 8rz + (4pr - q^2) = 0$ Substituting values from $x^4-2ax^2-x+a^2-a=0$ into $8z^3 - 4pz^2 - 8rz + (4pr - q^2) = 0$ gives us $8z^3-4\cdot(-2a)\cdot z^2-8\cdot(-a)\cdot z+\left(4\cdot (-2a) \cdot (-a) - (-1)^2 \right)=0 \implies 8z^3+8az^2+8az+(8a^2-1)=0$ Using Cardano's formula, or in my case Wolfram Alpha, we get that $$z_1 = \frac {\sqrt [3]{-16 a^3 - 144 a^2 + 3 \sqrt 3 \sqrt {256 a^5 + 512 a^4 + 224 a^3 - 288 a^2 + 27} + 27}}{6\sqrt[3]2} - \frac {192 a - 64 a^2}{48\cdot 2^{\frac 23} \sqrt [3]{-16 a^3 - 144 a^2 + 3\sqrt 3 \sqrt {256 a^5 + 512 a^4 + 224 a^3 - 288 a^2 + 27} + 27}} - \frac a3$$ I simply can not solve that quintic and continue as it is already too cluttered. Was there a mistake in my problem or is there any other way to do it? Also, I am sincerely sorry but I am not sure how to tag this question. Edit $1:$ After Ross Millikan's answer, I snooped around in the comment section of the video and found someone who found that it is true using alternating root series . Was his proof correct as $\frac {\sqrt {4a-3}-1}2$ does not seem to have real values for $a \lt \frac 34$ ? Thank you!","['nested-radicals', 'polynomials', 'sequences-and-series', 'radicals', 'quartics']"
2966535,Proof explanation: Why we can select unit vectors $z_n\in M_n$?,"Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on a complex Hilbert space $(F,\langle\cdot\mid\cdot\rangle)$ . Let $T\in \mathcal{B}(F)$ and assume that there exists sequences of unit vectors $(x_n)_n$ and $(y_n)_n$ in $F$ such that $$\lim_{n\to \infty}\langle T x_n\mid x_n\rangle=\lambda,\;\lim_{n\to \infty}\langle T y_n\mid y_n\rangle= \mu,$$ with $\lambda$ and $\mu$ are two distinct complex numbers. Let $M_n$ be a subspace spanned by $x_n$ and $y_n$ and $P_n$ be a projection of $F$ onto ${M_n}$ . Consider $T_n=P_nTP_n$ . Why we can select unit vectors $z_n\in M_n$ such that $\langle T z_n\mid z_n\rangle$ is a convex combination of $\langle T x_n\mid x_n\rangle$ and $\langle T y_n\mid y_n\rangle$ ?","['hilbert-spaces', 'operator-theory', 'functional-analysis']"
2966540,Proving $\lim_{p\to\infty} $ $\left\lVert x \right\rVert_p = \left\lVert x \right\rVert_\infty$,"How can one prove, that $\lim_{p\to\infty} $ $\left\lVert x \right\rVert_P = \left\lVert x \right\rVert_\infty$ applies to all $x \in \mathbb{R^n}$ ? I know that two norms $\left\lVert \cdot \right\rVert_a$ and $\left\lVert \cdot \right\rVert_b$ in $\mathbb{R^n}$ are equivalent, if there are constants $c_1,c_2 > 0 $ so that for all $x \in \mathbb{R^n}$ there is an inequation chain $c_1 \left\lVert x \right\rVert_a \leq \left\lVert x \right\rVert_b \leq c_2 \left\lVert x \right\rVert_a$ I think I have to use the inequation above somehow to prove the former, yet I don't know how","['limits', 'normed-spaces']"
2966559,Convergence of infinite product $\prod(1+a_n)$ where $a_n$ changes sign,"I know that an infinite product $\prod_{n=1}^\infty (1+a_n)$ with $a_n \geq0$ for all $n$ converges if and only if the series $\sum_{n=1}^\infty a_n$ converges.  I can prove this using the inequality $e^x \geq 1+x$ which gives $$\sum_{n=1}^N a_n \leq \prod_{n=1}^N(1+a_n) \leq \exp\left({\sum_{n=1}^N a_n}\right)$$ The left inequality here relies on the $a_n$ being of the same sign. There is also a theorem that the product converges if and only if the series converges when $-1 < a_n < 0$ for all $n$ .  The proof also uses the fact that the $a_n$ are all of the same sign. My question is are there general convergence theorems for infinite products where $a_n$ is of alternating sign or changing sign infinitely often less frequently?  If so, how would it be proved?","['infinite-product', 'sequences-and-series']"
2966567,How is the quotient of two ideals defined?,"If $A$ is a commutative ring and $I \subset A$ an ideal, then I do know what $A / I$ means. However my professor now sometimes writes $J / I$ where $J$ is not a ring, but an ideal $I \subset J \subset A$ (for example $\sqrt{I} / I$ ). I was wondering is this is common notation and if someone could tell me how the 'quotient' of two ideals is defined.","['ring-theory', 'abstract-algebra', 'ideals']"
2966715,Confusion between dual of continuous functions and borel functions,"Let $X$ be a compact Hausdorff space and let $$C(X) = \{\text{ Continuous complex functions on } X\}$$ $$B(X) = \{ \text{Bounded complex Borel-measurable functions on X}\}$$ both equipped with the sup-norm, and therefore Banach spaces. We have that $C(X)^*=M(X)$ is the set of complex Radon measures, while $B(X)^* = \operatorname{ba}(X)$ are the bounded, finitely additive measures . Each element $T$ of $\operatorname{ba}(X)$ is continuous when restricted to $C(X)\subset B(X)$ . Thus, by the Riesz representation theorem, there is a countably additive Radon measure on $C(X)$ corresponding to $T$ . However, all the elements of $M(X)$ are countably additive, while those in $B(X)$ need not be! I am wondering where I am going wrong as I get this contradictory conclusion. Thank you.","['banach-spaces', 'general-topology', 'functional-analysis', 'measure-theory']"
2966743,"Name of a particular matrix with $M_{ij}=t_{\min(i,j)}$?","I'm looking to see if there's a name for a particular type of matrix $M_{ij}=t_{\min(i,j)}$ , ie.: \begin{bmatrix}
t_1 & t_1 & t_1 & t_1 \\
t_1 & t_2 & t_2 & t_2 & \cdots\\
t_1 & t_2 & t_3 & t_3 \\
t_1 & t_2 & t_3 & t_4 \\ 
 & \vdots & & & \ddots 
\end{bmatrix} Such a matrix has determinant $t(t_2-t_1)(t_3-t_2)(t_4-t_3)\cdots$ and its inverse is a very simple tridiagonal matrix. But it isn't a Vandermonde matrix or a Moore matrix . It looks like it's an alternant matrix , but that doesn't capture any of the interesting properties of the determinant or inverse. It seems like something with these special properties should be named or well-known somewhere. This matrix came up in looking at a particular probabilistic process, where $P(x_1,t_1 ; x_2,t_2;\cdots)\propto \exp(-\frac{1}{2}\vec{x}^T M^{-1}\vec{x})$ (hence the significance of the simple tridiagonal structure of $M^{-1}$ ).","['matrices', 'linear-algebra', 'terminology']"
2966773,What happens if matrix $A^2$ has a zero column?,"Let me assume that $A$ is a square matrix and the matrix $A^2$ has a column of zeros. Is it possible for me to prove that A has a column of zeros. I know that the determinants are both zero, however it did not help me. I assumed that jth column is the zero row and had [i,j] term $(a_{i1}*a_{1j}+a_{i2}*a_{2j}+...+a_{ij}*a_{ij}+...+a_{in}*a_{nj}=0)$ equal to zero. I summed it for all $i$ in range 1 and $n$ , and tried to prove it. But I was not able to do it. Are there anything I am missing?","['matrices', 'proof-verification', 'linear-algebra']"
2966778,Taking the gradient of $||\nabla f(x) - p||$ with respect to $x$ and $p$,"$$||\nabla f(x) - p||$$ I'm trying to take the gradients of this with respect to $x$ and $p$ . For $x$ , this is what I did: $$g(x) = ||\nabla f(x) - p || = \sqrt{(\frac{\partial f}{\partial x_1}-p_1)^2 + \cdots +(\frac{\partial f}{\partial x_n}-p_n)}\implies\\ \frac{\partial g}{\partial x_i} = \frac{2(\frac{\partial f}{\partial x_i}-p_i)\frac{\partial ^2 f}{\partial x_i^2}}{2\sqrt{(\frac{\partial f}{\partial x_1}-p_1)^2 + \cdots +(\frac{\partial f}{\partial x_n}-p_n)}}$$ however I don't think there's a closed form of writing $\nabla g$ . Am I right? For $p$ : $$h(p) = ||\nabla f(x) -p|| = \sqrt{(\frac{\partial f}{\partial x_1}-p_1)^2 + \cdots +(\frac{\partial f}{\partial x_n}-p_n)}\implies \\ \frac{\partial h}{\partial p_i} = \frac{2(\frac{\partial f}{\partial x_i}-p_i)(-1)}{2\sqrt{(\frac{\partial f}{\partial x_1}-p_1)^2 + \cdots +(\frac{\partial f}{\partial x_n}-p_n)}}$$ So $$\nabla h(p) = \frac{p-\nabla f(x)}{||\nabla f(x) -p||}$$ but the result in my book is just $p-\nabla f(x)$ . What am I doing wrong?","['multivariable-calculus', 'calculus', 'linear-algebra', 'derivatives']"
2966876,Are rational points dense on every circle in the coordinate plane?,"Are rational points dense on every circle in the coordinate plane? First thing first I know that rational points are dense on the unit circle.
However, I am not so sure how to show that rational points are not dense on every circle. How would one come about answering this.
Any hits are appreciate it.","['coordinate-systems', 'general-topology', 'rational-numbers']"
2966959,Solving a system of ordinary differential equations,"Consider the simultaneous system of differential equations: $$ \begin{equation}
x'(t)=y(t) -x(t)/2\\
y'(t)=x(t)/4-y(t)/2
\end{equation} $$ If $ x(0)=2 $ and $ y(0)=3 $ , then what is $ \lim_{t\to\infty}((x(t)+y(t)) $ ? Here is what I do: $$ \frac{dy}{dx}=\frac{\frac{1}{4}x-\frac{1}{2}y}{-\frac{1}{2}x+y}=-\frac{1}{2} $$ So $$ y=-\frac{1}{2}x+4 $$ and $$ x(t)+y(t)=\frac{1}{2}x(t)+4 .$$ Now solve for $ x(t) $ , we have $$ x(t)=4-\frac{2}{e^t} .$$ Hence $ \lim_{t\to\infty}((x(t)+y(t))=2+4=6 $ . However, there should be another method involving using matrices in the standard way. How to do it via matrices? The question is from:(14) of https://math.uchicago.edu/~min/GRE/files/week2.pdf",['ordinary-differential-equations']
2966985,"Showing formally that $H:=\langle x,y| x^2, y^n, yxyx^{-1} \rangle$ is a presentation of $D_{2n}$","I want to Show formally that $H:=\langle x,y| x^2, y^n, yxyx^{-1} \rangle$ is a presentation of $D_{2n}$ . To start with, by the universal property of the free group, there is a group homomorphism $\phi: H \to D_{2n}$ . Then it remains to show that the kernel of $\phi$ is the smallest normal subgroup containing $x^2, y^n, yxyx^{-1}$ . I am so confused as to how to prove this, because all of the sources that I found never prove this directly by definition. Most of them even do not mention that we need to prove this. But isn't this the definition of the group presentation? My $D_{2n}$ is defined to be the group of symmetries of an $n-gon$ , and assume that I know $ D_{2n} = \{e, a, b, b^1, \ldots, b^{n-1}, ba, \ldots, b^{n-1}a\}$ , where $a^2 = e$ , $b^n = e$ and $ab = b^{-1}a$ .","['group-presentation', 'group-theory', 'abstract-algebra']"
2967023,How to use limit definition to find derivative with a radical,I'm trying to find the derivative of $f(x)=3\sqrt x$ at $25$ . How would you go about this using the limit definition of a derivative? I'm currently stuck at $(3\sqrt{25+h}+15)/h$ .,"['limits', 'derivatives', 'real-analysis']"
2967054,Symmetric powers of odd spheres,"Given a sufficiently nice space $X$ , say a connected and compact polyhedron, one has a nice formula for the Poincaré polynomial of the orbit space $SP^n X:= X^n/S_n$ of the $n$ -fold Cartesian product under the usual symmetric group action. In particular, writing $b_i$ for the $i$ th Betti number of $X$ : $ p_t(SP^nX) = \text{the } x^n \text{ coefficient of } \frac{(1+tx)^{b_1}(1+t^3x)^{b_3} \cdots}{(1-x)(1-t^2x)^{b_2}\cdots}. $ One can then compute that, for $X = S^{2k+1}$ an odd-dimensional sphere, we have $p_t(SP^n S^{2k+1}) = 1 + t^{2k+1} = p_t(S^{2k+1}).$ In fact, when $k=0$ , this equality comes from a homotopy equivalence. There is always the inclusion $i: X \hookrightarrow SP^nX \qquad i(x) = x + x_2 + \cdots + x_n,$ where the $x_i$ are fixed constants and we use additive notation for elements of $SP^n X$ . On the other hand, thinking of $S^1$ as the unit complex numbers, we can write down a retract $r: SP^nS^1 \to S^1 \qquad r( \, \sum_i x_i \, ) = \prod_i x_i.$ One can then show that $r$ and $i$ together constitute a homotopy equivalence $S^1 \simeq SP^n S^1$ . Now this is all wildly false for even-dimensional spheres. In particular, one can show $SP^n S^2 \cong \mathbb{CP}^n$ . Also the previously mentioned homotopy equivalence does not hold for odd spheres: in light of the cofibration (see these notes if interested) $ \Sigma^n \mathbb{RP}^{n-1} \to S^n \hookrightarrow SP^2 S^n $ we have the formula $H_*(SP^2(S^n)) \cong H_*(S^n) \oplus \tilde{H}_*(\Sigma^n \mathbb{RP}^{n-1})$ , so there is 2-torsion in $SP^2(S^{2k+1})$ whenever $k>0$ . However I'm curious if one can construct a map $SP^n S^{2k+1} \to S^{2k+1}$ inducing an isomorphism on $H_*(-;\mathbb{Q})$ . The only idea I've got, thinking of $S^{2k+1} \subset \mathbb{C}^{k+1}$ , is $f: SP^n S^{2k+1} \to \mathbb{C}^{n(k+1)}-0 \qquad f((b^1_0,\dots,b^1_k)+\cdots+(b^n_0,\dots,b^n_k)) = (\dots, e_i(b_j), \dots),$ where $e_i$ is the $i$ th elementary polynomial in $n$ variables and $b_j$ stands for the tuple $(b^1_j,\dots,b^n_j)$ , defined up to permutation. This mimics the usual formulas used to show $SP^n \mathbb{C}^m \cong \mathbb{C}^{nm}$ . Of course, in this attempt, the dimension of the image is much too large. The big trouble with directly generalizing to $k>0$ seems to be that higher-dimensional spheres no longer have an abelian group structure, and I can't think of an alternative way to take an $n$ -tuple of vectors on the sphere and produce a new non-zero vector in a symmetric way.","['spheres', 'rational-homotopy-theory', 'homotopy-theory', 'algebraic-topology', 'differential-geometry']"
2967073,Help on proving that $\{x:f(x)>\alpha\}=\bigcup_{n=1}^{\infty}\{x:f(x)\geq \alpha+\frac{1}{n}\}$.,"I am currently studying Real Analysis by Royden. In one of the proof of an important theorem on measurable functions, it was stated that: $\{x:f(x)>\alpha\}=\bigcup_{n=1}^{\infty}\{x:f(x)\geq \alpha+\frac{1}{n}\}$ . But the book did not show that indeed the statement is TRUE. In showing that the statement is TRUE, one must use double set inclusion. Here is what I have done. Let $z\in \bigcup_{n=1}^{\infty}\{x:f(x)\geq \alpha+\frac{1}{n}\}$ . Then there is an index $n$ such that $z\in \{x:f(x)\geq \alpha+\frac{1}{n}\}$ . That is, for that $n$ we have $f(z)\geq \alpha+\frac{1}{n}$ . But $f(z)\geq \alpha+\frac{1}{n}$ means that $f(z)>\alpha$ . Thus $z\in \{x:f(x)>\alpha\}$ . Is this correct? Also, how do we show the reverse inclusion? Lastly if $\alpha<\beta<\alpha +\frac{1}{n}$ , is it true that $\bigcup_{n=1}^{\infty}\{x:f(x)\geq \alpha+\frac{1}{n}\}=\bigcup_{n=1}^{\infty}\{x:f(x)> \beta\}$ ? Thanks for the help.","['functions', 'real-analysis']"
2967107,Showing that $\ddot{x}=x-x^3$ is a conservative system,"I am aware that there are multiple ways of showing that the  system $\,\ddot{x}=x-x^3$ is Conservative. One of which is applying Newton's law from physics $$\frac{dE(t)}{dt}=\frac{d}{dt}\left[\frac12m\dot{x}^2+V(x)\right]=0$$ where, in this case, $$-\frac{dV(x)}{dx}=x-x^3\quad\text{and}\quad m=1.$$ However, I was wondering why the following method would not work. For a consertive system the curl is $0$ (assuming the domain of definition is simply connected), in other words, $\nabla\times\boldsymbol{F}=\boldsymbol{0}.$ The given differential equation can be written as $$\begin{cases} \dot{x(t)}=y(t) \\ \dot{y(t)}=x(t)-x^3(t)\end{cases}$$ where $\boldsymbol{F}=y\hat{i}+(x-x^3)\hat{j}.$ But $\nabla\times\boldsymbol{F}=-3x^2\hat{k}\neq\boldsymbol{0}.$ What is wrong with this reasoning?","['ordinary-differential-equations', 'dynamical-systems']"
2967135,Intuition on Double Integrals,"Frequently, I am met with problem that ask to evaluate a double integral over a bounded region. For example, evaluate the double integral $$\int\int_R 2x\cos(y)+3 \space dA$$ over the region $R$ bounded by $y=2x^2$ , $y=0$ , and $x=1$ . Graphically, Setting up the integral, I get $$\int_0^1\int_0^{2x^2} 2x\cos(y) \space dy \space dx$$ My question is how exactly does this double integral evaluate the volume above the region R, since the limits of integration seem to have no dependence on the z-axis; the limits of integration are in terms of $x$ and $y$ . Evaluating the inner integral, wouldn't you get the area between $y=0$ and $y=2x^2$ of $2x\cos(y)$ . If so, how does integrating that area between $x=0$ and $x=1$ give you the volume underneath the surface? The double integral seems random. The question may be broad, but any intuition on this would be helpful. Thanks.","['integration', 'volume', 'multivariable-calculus', 'multiple-integral', 'intuition']"
2967187,Generate a circle centered on a line and touching 2 other circles,"I'm working on an art project where I have a set of circles. I grow each circle around its center until it touches another circle. Once 2 circles touch, the point of contact remains fixed and they grow away from each other. Now I'm working on dealing with 1 circle touching 2 others. Once they are actually touching, I can continue to grow them properly, but finding the proper parameters to get them to touch at exactly one point is proving tricky for me. What's happening is that 2 circles are growing apart from one another. I expand the radius of one of them (and move it's center), but find that it's now overlapping a 3rd circle (that is, it intersects the 3rd circle at 2 points instead of 1). I'd like to back off the center and radius until it's touching the 3rd circle at exactly 1 point while still touching the 2nd circle at exactly 1 point. Here are some pictures to make it more clear. Circle A is stationary at the moment, Circle B has just been expanded, and it now overlaps Circle C. I'd like to move Circle B's center along line AB and change its radius until it just touches Circle A and Circle C at a single point each. How can I do that? I feel like there's some system of equations I could solve to find the proper center and radius, but my attempts at creating the proper system of equations always end up with 2 equations and 3 unknowns. The circles can be of arbitrary size and may not be as nearly equally sized as in  the above image.","['conic-sections', 'circles', 'geometry']"
2967207,On the notion of 'winding numbers' of maps $\mathbb{C} \setminus \{0\} \to \mathbb{C} \setminus \{0\}$,"In complex analysis, the winding number (around the origin) of a continuous loop $\gamma: [0,1] \to \mathbb{C} \setminus \{0\}$ is the number of times the loops ""winds"" around zero, which is given by the integral $$\frac{1}{2 \pi i}\int_\gamma \frac{dz}{z}$$ One of the basic results of algebraic topology is that loops with the same winding numbers are homotopic. I think it is pretty clear that any continuous map $f: \mathbb{C} \setminus \{0\} \to \mathbb{C} \setminus \{0\}$ should also carry a similar notion of 'winding number'. It should be defined by the integral $\frac{1}{2 \pi i} \int_\gamma \frac{dz}{z}$ (where $ \gamma: [0,1] \to \mathbb{C} \setminus \{0\}$ is given by $\gamma(t) = f(e^{2 \pi it})$ ). In this scenario, does the result above still hold, i.e. that continuous maps $\mathbb{C} \setminus \{0\} \to \mathbb{C} \setminus \{0\}$ with the same winding number are homotopic (through continuous maps $\mathbb{C} \setminus \{0\} \to \mathbb{C} \setminus \{0\})$ ? How can I see this? Is it possible to use the result above (the equivalent one for loops) to construct this homotopy?","['complex-analysis', 'homotopy-theory', 'algebraic-topology']"
2967260,Finding How Many Roots $2z^4-3z^3+3z^2-z+1=0$ has in the First Quadrant,"I am trying to determine how many roots $$p(z)=2z^4-3z^3+3z^2-z+1=0$$ has in the first  quadrant. My attempt: We first note that $p(z)$ has real coefficients. Thus by the conjugate root theorem, the roots of $p(z)$ occur in complex conjugate pairs. Next, we determine if $p(z)$ has roots on the axes. Case 1: Suppose $p(z)$ has a root on the real axes, then $p(x)=2x^4-3x^3+3x^2-x+1=0$ for some $x\in\mathbb{R}$ . Now by the rational root theorem, the only possible roots that $p(x)$ can have is when $x=1$ . But $p(1)\neq 0$ and hence $p(z)$ cannot have a root on the real axes by contradiction. Case 2: Suppose $p(z)$ has a root on the imaginary axes, then $p(iy)=2y^4+3iy^3-3y^2-iy+1=0$ for some $y\in\mathbb{R}$ . Then, $$\Im(p(iy))=0\implies y(3y^2-1)=0.$$ But, $p(0)\neq 0$ and $p\left(\pm\frac{1}{\sqrt{3}}\right)\neq 0$ . Hence $p(z)$ does not have a root on the imaginary axes, by contradiction. So, the roots are $a\pm ib$ and $c\pm id$ for $a,b,c,d\in\mathbb{R}$ and $a,b,c,d\neq 0$ . Now the sum of the roots equals zero, which implies $a=-c$ . Hence, there is only one root in each quadrant. My questions are, is my explanation of case $1$ and case $2$ correct? Also, (a very basic question) why does the sum of the roots equal zero?","['complex-analysis', 'proof-verification', 'polynomials']"
2967278,Pullback of differential forms and determinant,"I'm studying differential geometry using the book ""Godinho Natàrio - An introduction to Riemannian Geometry"". These are the definitions and theorems I'm working with: Definition 1 (Pullback of a linear map) Let $V,W$ be finite dimensional real vector spaces, $F : V → W$ be a linear map. Then for every $k$ positive integer we define the pullback of $F$ as $$ F^* : \mathcal{T}^k(W^*) \to \mathcal{T}^k(V^*) \quad \quad (F^*T)(v_1, \dots, v_k) = T(F(v_1), \dots, F(v_k)) $$ for any $v_1, \dots, v_k \in V$ . Here $\mathcal{T}^k(W^*)$ is the space of $k$ -covariant tensors on $W$ . Theorem 1.13 Let $V$ be a $n$ -dimensional real vector space, $F : V → V$ be a linear map and let $T \in 􏰁\Lambda^n(V^*)$ (the space of $n$ -covariant alternating tensors on $V$ ). Then $F^*T = (\det A)T$ , where $A$ is any matrix representing $F$ . Definition 2 (Pullback of a tensor field) Let $M, N$ be smooth manifolds, $f : M \to N$ be a differentiable map. Then, each differentiable $k$ -covariant tensor field $T$ on $N$ defines a $k$ -covariant tensor field $f^*T$ on $M$ in the following way: $$ (f^*T)_p(v_1,...,v_k) = T_{f(p)}((df)_p(v_1),...,(df)_p(v_k)) $$ for any $ v_1, \dots,v_k \in T_pM$ . Then this last definition applies also to a differential form (being it a $k$ -covariant differentiable alternating tensor field). What I can't understand is the following remark at page 73 : Let $M,N$ be smooth manifolds and let $f: M \to N$ be a differentiable map s.t. $\dim(M)=\dim(N)=n$ . Let $p \in M$ and consider a coordinate systems $x = (x^1, \dots, x^n)$ around $p$ s.t. $x: V \to \mathbb{R}^n$ and $y=(y^1, \dots, y^n)$ around $f(p)$ s.t. $y: W \to \mathbb{R}^n$ . Let $\hat{f}:= y \circ f \circ x^{-1}$ be the local representation of $f$ . Then from Theorem 1.13 : $$(f^*(dy^1 \wedge \dots \wedge dy^n))_p = \det(d \hat{f})_{x(p)}(dx^1\wedge \dots \wedge dx^n)_p$$ How can I apply Theorem 1.13 in this situation? I mean, ""translating"" Definition 2 into Definition 1, I have the pullback of the linear map $dF_p : T_pM \to T_{f(p)}N$ applied to the element $dy^1 \wedge \dots \wedge dy^n$ of $\Lambda^n(T_{f(p)}N^*)$ .  But those vector spaces are not the same (as in the hypothesis of the Theorem)! Edit I think it can be fixed in this way: Let $I_1 : \mathbb{R}^n \to T_pM$ and $I_2 : \mathbb{R}^n \to T_{f(p)}N$ be two isomorphisms s.t.: $$ I_1(e^i) = \frac{\partial}{\partial x^i} \quad \quad I_2(e^i) = \frac{\partial}{\partial y^i} \quad \forall \, i = 1, \dots, n $$ where $ \{ e^1, \dots, e^n \}$ is the standard basis of $\mathbb{R}^n$ . Then $$ F :=  I_2^{-1} \circ df_p \circ I_1 : \mathbb{R}^n \to \mathbb{R}^n$$ is an endomorphism in $\mathbb{R}^n$ . By Theorem 1.13 $F^* = \det(A) \cdot$ being $A$ the matrix representing $F$ . By pullback's properties we have $$\det(A) \cdot = F^* = (I_2^{-1} \circ df_p \circ I_1)^* = I_1^* \circ (df_p^*) \circ (I_2^*)^{-1} \Rightarrow df_p^* = (I_1^*)^{-1} \circ (\det(A) \cdot) \circ I_2^*$$ Then $$ (f^*(dy^1 \wedge \dots \wedge dy^n))_p = df_p^* (dy^1 \wedge \dots \wedge dy^n)=  ((I_1^*)^{-1} \circ (\det(A) \cdot) \circ I_2^*) (dy^1 \wedge \dots \wedge dy^n)= \det(A) (I_2 \circ I_1^{-1})^*(dy^1 \wedge \dots \wedge dy^n) $$ Moreover $$I_2 \circ I_1^{-1} : T_p(M) \to T_{f(p)}N \quad \quad \frac{\partial}{\partial x^i} \mapsto \frac{\partial}{\partial y^i} $$ and then $$(I_2 \circ I_1^{-1})^*(dy^i) \biggl (\frac{\partial}{\partial x^j} \biggr) = dy^i \biggl ( (I_2 \circ I_1^{-1}) \biggl (\frac{\partial}{\partial x^j} \biggr) \biggr ) = dy^i \biggl ( \frac{\partial}{\partial y^j} \biggr ) = \delta_{ij} = dx^i \biggl (\frac{\partial}{\partial x^j} \biggr)  $$ i.e. $$(I_2 \circ I_1^{-1})^*(dy^i) =dx^i $$ and then since $ (I_2 \circ I_1^{-1})^* ( dy^i \wedge dy^j) = ((I_2 \circ I_1^{-1})^*dy^i) \wedge ((I_2 \circ I_1^{-1})^*dy^j)$ we have $$(f^*(dy^1 \wedge \dots \wedge dy^n))_p = \det(A)(dx^1 \wedge \dots dx^n) $$ and it is easy to show that $A = [d\hat{f}]_{ij}$ . Is it ok?","['pullback', 'differential-forms', 'differential-geometry']"
2967367,How to obtain the lower bound of $\dfrac{n}{\sqrt[n]{n!}}$ by Taylor's series?,"We want to prove $$\lim_{n \to \infty}a_n=\lim_{n \to \infty}\frac{n}{\sqrt[n]{n!}}=e.$$ I have some solutions for this, but I want to find another method applying the squeeze theorem. Thus, a natrual thought is to find the upper bound and the lower bound of $a_n$ . Notice that $$e^x=1+x+\frac{x^2}{2!}+\cdots+\frac{x^n}{n!}+\cdots.$$ If we substitute $x$ for $n$ , then $$e^n=1+n+\frac{n^2}{2!}+\cdots+\frac{n^n}{n!}+\cdots>\frac{n^n}{n!}.\tag1$$ Thus, we obtain $$e>\frac{n}{\sqrt[n]{n!}},$$ which shows $e$ is a upper bound of $a_n$ . But how to obtain the lower bound by $(1)$ ? Say it again. I have other methods to deal with it. I just wonder whether there is some method depending on $(1)$ only or not.","['limits', 'sequences-and-series']"
2967368,"Different roots of irreducible polynomial $p(x) \in F[x]$ generate isomorphic fields, yet $p(x)$ factors differently in each?","This seems counter intuitive to me. For example, the roots of $p(x)=x^3-2$ over $\mathbb{Q}$ are $2^{(1/3)},\gamma2^{(1/3)}, \gamma^22^{(1/3)}$ where $\gamma$ is a primitive third root of unity. So, $\mathbb{Q}(\gamma^22^{(1/3)})$$\cong$$\mathbb{Q}(2^{(1/3)})$ , okay, but something isn't quite clicking for me, and perhaps it's because i want to believe that two roots of $p(x)$ is in $\mathbb{Q}(\gamma^22^{(1/3)})$ when that's not true, I mean if it did have two roots then it would have to have all three and so that's obviously not true. So is it safe to say that in the splitting field generated by different roots of an irreducible polynomial, that irreducible polynomial will split in ""isormorphic"" ways in each respective splitting field? It must, it's just I've been discovering more and more places where i'm learing how ""isomorphic"" does not mean ""equal"" and so maybe that's why i'm so unsure. Sorry, i understand my phrasing is not perfect, but I hope that i'm getting my question across, and if not i hope someone just comes here and gives me general insight into the genereal area.","['field-theory', 'abstract-algebra']"
2967389,Prove that $2z^4-3z^3+3z^2-z+1=0$ has exactly one complex root in each of the four quadrants.,"I am trying to show that $$p(z)=2z^4-3z^3+3z^2-z+1=0$$ only has a single root in all four quadrants. From two previously related posts, I have shown that $p(z)$ does not have a root on neither the imaginary or real axes. We also know that as the coefficients of $p(z)$ are real, then the roots of $p(z)$ occur in complex conjugate pairs. Hence we have roots $$w_1=a\pm ib \ \ \text{and} \ \ w_2=c\pm id \ \ \text{where} \ \ a,b,c,d\in\mathbb{R} \ \ \text{and} \ \ a,b,c,d\neq 0.$$ Ideally if we could show that $\Re(w_1)=-\Re(w_2)$ , then we could conclude the result. But the sum of the roots is $\frac{3}{2}$ and not $0$ . How can we show only a single root exists in each quadrant? edit In consultation with my professor, he suggested using a corollary of Cauchy's argument principle: ""If $f\in H(\Omega)$ , $\Omega$ is a domain, $\gamma:[a,b]\rightarrow\Omega$ is a simple closed contour, $f(\gamma(t))\neq 0 \ \ \forall t\in [a,b]$ , then the number of zeros of $f$ in Int( $\gamma$ ) (counting multiplicities) is equal to the number of times $f\circ\gamma$ winds around $0$ "". We can consider $\gamma(t)=Re^{it}$ where $t\in\left[-\frac{\pi}{2},\frac{\pi}{2}\right]$ and $R>0$ . We would expect the result of this to be $2$ , meaning that there is a root $w$ in the first quadrant and $\overline{w}$ in the forth quadrant.","['complex-analysis', 'roots', 'polynomials']"
2967393,Question about the defining equivalence relations on sets,"Suppose I have an equivalence relation $\sim$ on $S=\{e,f,g,h,i\}$ such that $e \sim f, f \sim g$ and $e \nsim i$ . I’m trying to find the number of such relations that can be defined on $S$ . I know that $\{e,f,g\}$ will always be an equivalence class and that $\{i\}$ will also always be an equivalence class. The questions therefore is equivalent to asking how many different equivalence classes can $h$ belong to and the answer is obviously $3$ since it can belong to its own equivalence class $\{h\}$ , $\{i\}$ or $\{e,f,g\}$ . However I’m not sure if it’s possible that $h$ does not belong to any equivalence class, i.e. the set of equivalence classes for the relations would be $\{\{e,f,g\},\{i\}\}$ . I think the answer is no because the set of equivalence classes has to partition $S$ but I’m not 100% sure.","['elementary-set-theory', 'equivalence-relations', 'relations']"
2967419,Almost all non-negative real numbers have only finitely many multiple lies in a measurable set with finite measure,"Let $A$ be Lebesgue measurable subset of $[0,\infty)$ such that Lebesgue measure of $A$ is positive i.e. $0<\lambda(A)<\infty$ . Let $S$ be the set defined as follows: $$S:=\{t\in [0,\infty):nt\in A\text{ for infinitely many }n\in\Bbb N\}$$ What can we conclude about the measure of $S$ ? I can guess that $\lambda (S)=0$ for when $A$ is an open set but can't prove it.
More particular case, when $A$ is open with finitely many components then I can conclude that $\lambda(S)=0$","['measure-theory', 'lebesgue-measure', 'ergodic-theory', 'real-analysis', 'probability-theory']"
2967420,Prove that $U$ is an open set of a topological space $X$ iff for all $A\subset X$ we have $Cl(U\cap Cl(A))=Cl(U\cap A)$,"I'm stuck with this one, is the 14th exercise on my notes and the most difficult so far. Prove that $U$ an open set of a topological space $X$ iff for all $A\subset X$ we have $Cl(U\cap Cl(A))=Cl(U\cap A)$ . I've been struggling thinking both implications and I didn't get anything. What I only proved before is $$Cl(A\cap B)\subset Cl(A) \cap Cl(B).$$ I'd appreciate a hint or some help with this one. Thanks for your time.",['general-topology']
2967522,How many persons eat at least two out of the three dishes?,"Out of a group of 21 persons, 9 eat vegetables, 10 eat fish and 7 eat eggs. 5 persons eat all three. How many persons eat at least two out of the three dishes? My take : Let $A∩B∩C = x$ , then $(A∩B+B∩C+A∩C)$ , this already contains $3x$ . therefore subtracting $2x$ from this should result into POSITIVE value, but it is zero.
 Moreover, they are asking for ""at least 2"" which means $(A∩B+B∩C+A∩C) - 2x$ . Is something wrong with given data ? The answer given in book is any number between [5,11]. Please help me understand & solve this question. Any help is appreciated in advance.","['elementary-set-theory', 'combinatorics', 'probability']"
2967560,Conformal mappings are always biholomorphic,Are conformal mappings biholomorphic? $f$ is considered a conformal mapping when $f:D \rightarrow G$ is holomorphic and injective and holds $f(D) = G$ . This implies that $f$ is also surjective on $G$ right? We know that when $f:D \rightarrow G$ is holomorphic then $f^{-1} : G \rightarrow D$ is also holomorphic on $G$ . So doesnt this implie that conformal mappings are biholomorphic? This would mean that the conformal mappings are exactly the biholomorphic functions?,"['complex-analysis', 'calculus']"
