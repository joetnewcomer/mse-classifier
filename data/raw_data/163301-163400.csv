question_id,title,body,tags
2838672,Realizing subring as ring of invariants?,"Let $R$ be a finite type integral domain over field $k$, $S$ be a subring of $R$, such that $[f.f(R)\colon f.f(S)]=d$, does there exist a group $G$ with $|G|=d$ such that $S=R^G$? (Here $f.f(R)$ means the fraction field of $R$) (I am confused by [ACGH] Geometry of algebraic curves Vol II, P.262 Line 14-16. How shall I understand the claim in [ACGH]? If $S=R^G$ and both $R,S$ are smooth, and the extension is not etale, can we show $\mathrm{Spec}(R)\to\mathrm{Spec}(S)$ has to be a cyclic cover over smooth divisor? I think the following is a counterexample.) (Original question: Let $k[x,y]$ be the polynomial ring over $k$ with two variables. Does there exist an action of some finite group $G$ on $k[x,y]$ such that $k[x,y]^G=k[x^2,y^2]$? The naive $x\to -x,y\to -y$ has a larger invariant subring $k[x^2,xy,y^2]$.)","['abstract-algebra', 'invariant-theory', 'algebraic-geometry', 'commutative-algebra']"
2838689,Explicit Map from $\mathbb{T}^{3}$ to $SU(2)$,"I'm looking for a smooth map from the 3-torus to $SU(2)$, i.e. some $f:\mathbb{T}^{3}\to SU(2)$, that is injective near identity, $f^{-1}(1)=\{p\}$. I know that the homotopy classes of maps from $\mathbb{T}^{3}\to S^{3}\simeq SU(2)$ are labeled by $\mathbb{Z}$, but I need to find an explicit example (I think of the $n=1$ class) for my work. If there's an easy, explicit construction, I'm all for it. Below I've tabulated my attempt at first embedding $\mathbb{T}^{2}$ in $\mathbb{R}^{3}$ and projecting to the unit sphere, hoping that the same idea works with $\mathbb{T}^{3}$ in $\mathbb{R}^{4}$. Because I can't think in four dimensions, my initial idea was to knock off one dimension from both spaces and try to find a map from a 2-torus to $S^{2}$ that satisfies this. So I've got a Torus parameterized as:
$$ x=(R+r\cos\theta)\cos\phi-R,\hspace{.5cm} y=(R+r\cos\theta)\sin\phi, \hspace{.5cm}z=r\sin\theta$$
Crucially, this torus has the origin inside of it, so that when I project to the unit sphere
$$ (x, y, z)\mapsto \frac{(x, y, z)}{\sqrt{x^{2}+y^{2}+z^{2}}}$$
only one point ($\theta=0, \phi=0$) is mapped to $(1, 0, 0)$ on the unit sphere. So I can map $\mathbb{T}^{2}\to S^{2}$ by:
$$(\theta, \phi) \mapsto \frac{(x, y, z)}{\sqrt{x^{2}+y^{2}+z^{2}}}$$ (1) I'm not sure that this is even a smooth map, even though it seems like it should be. The issue is that one ends up with a $\sqrt{...+\cos\theta}$ in the denominator, which contains arbitrarily high powers of $\cos\theta$. (Ultimately I'm using this for a physics application which needs a local formulation, and $\theta$ will be a momentum,  so I need there to be a finite maximum power of $\cos\theta$, $\sin\theta$, $\cos\phi$, etc) (2) If this lower dimensional case is smooth, can the same idea be extended to a map $\mathbb{T}^{3}\to SU(2)$? Can one parameterize $\mathbb{T}^{3}$ in a similar way to $\mathbb{T}^{2}$, then project to the unit sphere, and be done with it? (3) Is there an altogether better way to construct a map from $\mathbb{T}^{3}\to SU(2)$ that avoids all of this messiness?","['multivariable-calculus', 'general-topology', 'differential-geometry']"
2838692,Extensions of Bounded Linear Operators,"I am currently lacking in some basic knowledge regarding extensions of linear operators.  Let $ X $ and $ Y $ be Banach spaces and let $ A $ be dense subspace of $ X $.  Let $ T : A \to Y $ be a bounded linear operator. Is it true that there exists a unique extension $ \tilde{T} : X \to Y $ of $ T $ that is also bounded? I believe this is common result but I can't seem to figure out what to search if there is a name for this result, or is this somehow a consequence of the Hahn-Banach theorem? Also is this result true if $ X $ and $ Y $ are just normed spaces? Any help would be appreciated.  Thanks!",['functional-analysis']
2838789,How is is Bayes Rule being applied to arrive at the following formula?,"In Sebastian Thrun's Intro to Atificial Intelligence course on Udacity, Problem Set 2, Simple Bayes Net, he asks the following question. Given a simple Bayes network with a single causal variable, A, and three conditionally independent variables that depend on the causal variable, $X_1, X_2, X_3$, what is $P(A|X_1, X_2, \neg X_3)$. In the answer video, his first step is $$P(A|X_1, X_2, \neg X_3) = \frac{P(\neg X_3|A, X_1, X_2)P(A|X_1, X_2)}{P(\neg X_3|X_1, X_2)}$$ He says he arrives there using Bayes Rule, but that is nothing like Bayes Rule. I am able to arrive at the resulting equation by going through several steps, beginning with Bayes Rule but also requiring things like the definition of conditional probability and by transforming joint probabilities into conditional probabilities multiplied by the prior. Can anyone explain (A) Why he seems to think that it is self-evident that he is using Bayes Rule and (B) Why he would bother to transform the equation to produce terms like $P(\neg X_3|A, X_1, X_2)$ for which the value was not given in the question? I was able to easily solve this simply by applying Bayes Rule and evaluating the terms using provided values. ($P(A) = .5, P(X_i|A) = .2, P(X_i|\neg A) = .6$) Edit: Here is how I able to arrive at his ""first"" step: $\frac{P(X_1, X_2, \neg X_3|A)P(A)}{P(X_1, X_2, \neg X_3)}$ via Bayes Rule $\frac{\frac{P(X_1, X_2, \neg X_3, A)P(A)}{P(A)}}{P(X_1, X_2, \neg X_3)}$ $\frac{P(X_1, X_2, \neg X_3, A)}{P(X_1, X_2, \neg X_3)}$ via cancellation $\frac{P(\neg X_3|A, X_1, X_2)P(A, X_1, X_2)}{P(X_1, X_2, \neg X_3)}$ by the definition of conditional probability $\frac{P(\neg X_3|A, X_1, X_2)P(A|X_1, X_2)P(X_1, X_2)}{P(X_1, X_2, \neg X_3)}$ via the definition of conditional probability $\frac{P(\neg X_3|A, X_1, X_2)P(A|X_1, X_2)P(X_1, X_2)}{P(\neg X_3|X_1, X_2)P(X_1, X_2)}$ via the definition of conditional probability $\frac{P(\neg X_3|A, X_1, X_2)P(A|X_1, X_2)}{P(X_3|X_1, X_2)}$ by cancellation","['bayes-theorem', 'probability-theory', 'bayesian-network', 'probability']"
2838793,Arctangent integral that I'm having difficulty on,"Question: Show that$$\int\limits_0^1 dx\,\frac {\arctan x}{\sqrt{x(1-x)}}=\pi\arctan\sqrt{\frac {\sqrt2-1}2}$$ I'm just having a hard time figuring out what to do. I tried to make the substitution $x=\frac {1-t}{1+t}$ but that didn't help very much because the denominator is slightly different. My next thought was to try to represent $\arctan x$ as an infinite series$$\arctan x=\sum\limits_{n\geq1}\frac {(-1)^{n-1}x^n}n\sin\left(\frac {\pi n}2\right)$$
But seeing as to how the result is in terms of $\arctan(\cdot)$, I doubt an infinite series would help much. Especially if the argument is a nested radical. Perhaps there is some sort of hidden symmetry one may exploit for this one?","['improper-integrals', 'integration', 'definite-integrals']"
2838794,Why ${(2S)}^{-1} - {(2S)}^{-1}({I + 4S})^{-1} =2\times({I + 4S})^{-1}$,"I met an interesting matrix question in a paper. My answer is ${(2S)}^{-1} - {(2S)}^{-1}({I + 4S})^{-1}$, but the answer in the paper is $ 2\times({I + 4S})^{-1}$. When I plugged in some value in $S$, I found they are equal, so why
$${(2S)}^{-1} - {(2S)}^{-1}({I + 4S})^{-1} =2\times({I + 4S})^{-1}$$ where $I$ is the identity matrix, and S is a symmetric positive definite matrix.","['matrices', 'matrix-equations', 'linear-algebra']"
2838842,Prove that the ideal of $p\in \mathbb Z[x]$ with $p(1)$ even is not principal,"Consider the set $I$ of polynomials $p(x)$ in $\mathbb Z[x]$ such that $p(1)$ is even. Prove that this is a non-principal ideal. That this is an ideal is clear. I was wondering whether my proof that $I$ is non-principal correct? Assume $I=(f)$. Since $2\in I$, $2=f(x)g(x)$ for $f,g\in \mathbb Z[x]$, and this implies that $f$ must be constant. This constant can only be equal to $2$ because otherwise $2\notin I$. But on the other hand, $x^2+1\in I$, so $x^2+1=2g(x)$. This is impossible because the LHS is not divisible by $2$.","['abstract-algebra', 'ring-theory', 'ideals']"
2838864,Proving that the polynomial $10X^6-15X^2+7$ is irreducible in $\mathbb{Q}[X].$,"As stated, I am trying to prove that $10X^6-15X^2+7$ is irreducible in $\mathbb{Q}[X].$ I have been given the hint to compare the above polynomial with $7X^6 - 15X^4+10.$ I know that $7X^6 - 15X^4+10$ is irreducible in $\mathbb{Q}[X]$ because of eisenstein's criterion for $p=5$, but I have no idea how one could prove that $10X^6-15X^2+7$ is irreducible because $7X^6 - 15X^4+10$ is irreducible. Any help would be appreciated","['irreducible-polynomials', 'abstract-algebra', 'ring-theory']"
2838893,Complex power series on the circle of convergence,"I'm trying to find examples of complex power series $\sum a_n z^n$ with radius of convergence $1$ and where: (1) The series converges everywhere on the circle $|z| = 1$ except one point; 
(2) The series diverges everywhere on the circle $|z| = 1$ except one point. For (1) I found $\displaystyle \sum_{n=1}^\infty \frac{z^n}{n}$ which is a harmonic series when $|z| = 1$. It converges for $|z|=1, z \neq 1$ by Dirichlet test: $\sum_{n=1}^N e^{in\theta}$ bounded and $1/n$ decreasing Can anyone give an example for part (2)?","['complex-analysis', 'power-series']"
2838928,Representation of differentiation operator,"So I have to find a basis for a polynomial space such that differentiation operator is in Jordan form. I noticed that if I chose a basis to be ${1,x^2,x^3,x^4,...,x^n}$ then the differentiation operator is 
$$\begin{matrix}
0&1&0&0&\dots&0
\\0&0&2&0&\dots&0
\\0&0&0&3&\dots&0
\\\vdots&&&&\ddots
\\0&0&0&0&\dots &n
\\0&0&0&0&\dots&0
\end{matrix}$$
This is Jordanish but not Jordan... I wanted to try with a basis where instead of vector $x^n$ I have $\frac{1}{n} x^n$  but of course it does not work. What is the trick here? Update:
That was quick but I think I found it $\{n!,n!x,\frac{n!}{2!}x^2,\dots,\frac{n!}{(n-1)!}x^{n-1},n!x^n\}$ does the job.","['linear-algebra', 'linear-transformations']"
2838937,Probability of having the two best football players in different teams,"I have problems understanding the solution for this lesson: From $22$ football players we create two teams with $11$ players each.
What is the probability of having the two best players in different teams? I am pretty sure that the number of overall possible outcomes is $\binom{22}{11}$, which will divide the favorable number of outcomes. However I don't know how to get that. As far as I know the solution is $\frac{11}{21}$. Thanks in advance!","['combinatorics', 'probability-theory', 'probability']"
2838946,Identify the quotient of $\mathbb Z^3$ by a certain subgroup,"Consider the quotient of $\mathbb Z^3$ by the subgroup generated by
  $(2,1,5),(1,2,10),(2,1,7)$. Write it as a product of cyclic groups. I was wondering if this solution is complete and rigorous enough? Recall that any homomorphism of $R$-modules $R^n\to R^m$ is given by a matrix $A$ with entries in $R$, and we say that $A$ is a presentation matrix of the quotient module $R^m/AR^n$. In our case $m=n=3$, $R=\mathbb Z$. Let $A$ be the matrix whose columns are $(2,1,5)^t,(1,2,10)^t,(2,1,7)^t$. Then $AR^3$ is the subgroup of $R^3$ from the question. $A$ is a presentation matrix for the quotient group we need to identify. After using elementary integer row and column operations, the matrix reduces to the matrix with columns $(1,0,0)^t$, $(0,3,0)^t$, $(0,0,2)^t$. Since these operations yield a matrix that present the same module, we see that the quotient group is isomorphic to $C_3\times C_2$.","['modules', 'abstract-algebra', 'abelian-groups', 'finitely-generated', 'group-theory']"
2838970,Counterexample involving tensor product of $A$-modules equals zero,"I have proved the following statement and I'm looking for a counterexample where $M$ or $N$ is not finitely generated so that the implication does not hold. I would apppreciate any tips. Let $A$ be a local ring, $M$ and $N$ finitely generated $A$-modules. Show that if $M \otimes_A N = 0$ then $M=0$ or $N=0.$","['abstract-algebra', 'examples-counterexamples', 'tensor-products', 'commutative-algebra']"
2838976,Confused about when to convert units,"It shouldn't matter when I convert units in a calculation, the final answer should be the same. However: $-30\ °C - 0\ °C = -30\ °C = (-30 + 273.15)\ K = 243.15\ K$ $-30\ °C - 0\ °C = (-30 + 273.15)\ K - (0 + 273.15)\ K = 243.15\ K - 273.15\ K = -30\ K$ where $T_C = T_K - 273.15\ K$, $C$ is Celsius, $K$ is Kelvin. How come they're different?","['algebra-precalculus', 'physics']"
2838983,Fitting subgroup of wreath product of $\Bbb Z_p$ with an infinite abelian $p$-group.,"Let say I have an infinite elementary abelian $p$-group $E$ (i.e. with presentation $E= \langle x_1,x_2,x_3,... \mid x_i^p=1, \  x_i x_j = x_j x_i \rangle$). How do I find the Fitting subgroup of the wreath product $G := \mathbb{Z}_p \wr E$, or more precisely, how could I prove that $\operatorname{Fitt}(G) = G$? What my thinking is, find a series of normal subgroups with increasing nilpotency class, so something like $\mathbb{Z}_p \times E$, $(\mathbb{Z}_p  \oplus \mathbb{Z}_p) \times E, \ldots$ but these don't seem to be normal in $G$ and I can't think of any better ones. Any ideas?","['abstract-algebra', 'group-theory']"
2838987,Divergence of power series in commutative Banach algebras,"Let $(A,||\cdot||)$ be a commutative Banach algebra over $\mathbb{C}$. Consider a formal power series $f(z):=\sum_{n=0}a_n z^n\in A[[z]]$ and let 
$$
r:=\frac{1}{\limsup\limits_{n\to\infty}||a_n||^{1/n}}
$$
For $b\in A$ denote by $\rho(b)$ its spectral radius. Is it generally true that $f(b)$ is divergent (in the $||\cdot||$-topology) for any $b\in A$ with $\rho(b)>r$? I believe one can easily show in certain cases that $f(b)$ is divergent if
$$
\rho(b)> \frac{1}{\limsup\limits_{n\to\infty}\rho(a_n)^{1/n}}=:R,
$$
but $R$ can be much bigger than $r$.","['functional-analysis', 'power-series', 'banach-algebras']"
2839002,Derive Outer Measure from $\sigma$-Algebra,"It is well-known that an outer measure $\mu$ gives rise to a $\sigma$-algebra given by $$\mathcal A_\mu = \left\{Q\subseteq\Omega : \mu(X) = \mu(X\cap Q) + \mu(X\cap Q^\complement)\;\;\text{for each $X\subseteq \Omega$}\right\}.$$
Now, I wonder, given a $\sigma$-algebra $\mathcal F$, does that imply (maybe with some additional requirements?) that there exists an outer measure that fully describes $\mathcal F$. In other words, can a $\sigma$-algebra be characterized by an outer measure and vice versa.",['measure-theory']
2839013,Continuous analogy of the matrix inversion,"I am thinking on matrix-like entities with continuous indexes. I think, maybe such ""continuous matrices"" could be defined as complex-valued functions on $\mathbb{R}^+\times\mathbb{R}^+$. I think it is trivially visible that the continuous analogy of the unit matrix is $\delta_{xy}$. Multiplication could be defined as $$(f \circ g)(x,y)=\int_0^\infty f(x,u)g(u,y)du$$ I am looking for the $f \in \mathbb{R}^+\times\mathbb{R}^+ \rightarrow \mathbb{C}$ with a given $g \in \mathbb{R}^+\times\mathbb{R}^+ \rightarrow \mathbb{C}$, for which $$\int_0^\infty f(x,u)g(u,y) du = \delta_{xy} | \forall \{x,y\} \subset \mathbb{R}^+ $$ Does this algebra has a name? What could be the continuous analogy of the matrix inversion in it?","['matrices', 'functional-analysis']"
2839041,Removing a point from a sphere,"Let $\Sigma^n$ be a smooth manifold homeomorphic to an $n$-sphere (possibly exotic) and let $p\in\Sigma$ be a point. Then the complement $\Sigma^n\setminus \{p\}$ is homeomorphic to $\mathbb{R}^n$. Is the complement $\Sigma^n\setminus\{p\}$ also a smooth manifold? If so, then I think it must be diffeomorphic to $\mathbb{R}^n$. The case $n=4$ seems to be a special case because $\mathbb{R}^4$ does not have a unique smooth structure. Can $\Sigma^4\setminus\{p\}$ be diffeomorphic to an exotic $\mathbb{R}^4$, or is it always standard $\mathbb{R}^4$? Also, if you add a point to an exotic $\mathbb{R}^4$, can you get an exotic $S^4$? I guess this isn't possible, as someone would have already thought of it.","['smooth-manifolds', 'differential-geometry', 'differential-topology']"
2839085,"Given a subgroup of $GL_2(\mathbb C)$ generated by two elements, prove that all its subgroups are normal","Consider the subgroup $G$ of $GL_2(\mathbb C)$ generated by
   $$a=\begin{bmatrix}i&0\\0&-i\end{bmatrix},\
 b=\begin{bmatrix}0&1\\-1&0\end{bmatrix}.$$ Find its order and prove
   that every subgroup of $G$ is normal in $G$. My guess is that $G=\{1,a,a^2,a^3,b,b^3,ab,a^3b\}$. I checked that these elements are distinct and that these relation hold in $G$: $$b^2=a^2,\ ba=a^3b,\ a^4=b^4=1$$ (maybe some other hold too). Do I need to write out 32 expressions $a^ib^j, b^ia^j$ with $0\le i,j \le 3$ and check that no other elements except those listed above can be obtained? Also, assuming that $G$ has order 8, can I conclude that $G$ is isomorphic to $Q_8$ since there is no relation $a^2=b^2$ in the dihedral group of order 8 (and the group in question is not abelian)? For the second part, it's a big hassle to list its subgroups and check directly whether they are normal. Is there a quick way to see that all subgroups are normal?","['finite-groups', 'abstract-algebra', 'normal-subgroups', 'group-theory']"
2839093,Show that $\lim_{n \to \infty} \int_0^{\infty} \frac{1}{1+x^n}~dx = 1$,I need help proving the following limit: $$\lim_{n \to \infty} \int_0^{\infty} \frac{1}{1+x^n}~dx = 1$$ In WolframAlpha I was playing around with the values of the sequence defined by the integral and noticed that the values seem to get arbitrarily close to 1. I guess the difficulty is finding a closed expression for the value of the definite integral.,"['limits', 'calculus', 'integration', 'definite-integrals', 'convergence-divergence']"
2839095,Problem with Complex Variables,"Solve the equation $z^2 + z + 1 = 0$ for $z = (x,y)$ by writing $(x,y) (x,y) + (x,y) + (1,0) = (0,0)$ and then solving a pair of simultaneous equations in $x$ and $y$. My main difficulty is finding the answer is using the suggestion in that book that there isn't a real solution implies that $y \neq 0$, but I will work out the rest of this solution just to be sure that I grasp the logic. First, using the fact that we have some complex variable $z = (x,y)$ and that we can represent a purely real number as $x = (x,0)$, meaning that $1 = (1,0)$, we can reason, as the problem suggests, that
\begin{equation}
z^2 + z + 1 = 0 \implies (x,y)(x,y) + (x,y) + (1,0) = (0,0)
\end{equation}
Using multiplication and addition of complex variables, we get 
\begin{equation}
\left(x^2 - y^2, 2xy \right) + \left(x + 1, y\right) = (0,0) \implies \left(x^2 - y^2 + x + 1, 2xy + y\right) = (0,0)
\end{equation}
which then implies that
$x^2 - y^2 + x + 1 = 0$ and $2xy + y = 0$. From this second equation, we get $2xy + y = y(2x + 1) = 0$, which implies $y = 0$ or $2x + 1 = 0 \implies x = - \frac{1}{2}$. Plugging $y = 0$ into the first equation gives us $x^2 - 0^2 + x + 1 = x^2 + x + 1 = 0$, which doesn't have any real solutions. Now, the suggestion states that the lack of a real solution solution, $x$, when $y = 0$ is justification for throwing out this value of $y$. If I'm not mistaken, and this may well be completely obvious, the logic for this is that we're trying to solve for some value $z = (x,y)$, so we obviously require a real solution even if our result is purely imaginary, though no such $x$ exists. I still I think am not completely convinced of this, as I'm not totally sure why we couldn't reason that we have a purely imaginary solution, i.e., $x = 0$. But, I think my confusion is in the above step. After this, the algebra follows and gives me the same answer as the textbook, $z = \left(-\frac{1}{2}, \pm \frac{\sqrt{3}}{2}\right)$.","['algebra-precalculus', 'complex-numbers', 'quadratics']"
2839121,Notion of convergence on the space of compactly supported continuous functions,"Let $E = C_c^0(\mathbb{R}^n;\mathbb{R}^m)$ be the space of compactly supported continuous functions on $\mathbb{R}^n$ with values on $\mathbb{R}^m$. There is a natural norm on this space: given $\varphi \in E$, we put 
$$ \Vert \varphi \Vert = \sup_{x \in \mathbb{R}^m} \Vert \varphi(x) \Vert.$$ First question: is $E$ equipped with this norm a Banach space? In the book ""Sets of finite perimeter and geometric variational problems"", by Francesco Maggi, the author introduces the following notion of convergence on $E$: a sequence $(\varphi_k)_{k \in \mathbb{N}}$ in $E$ converges to a function $\varphi \in E$ if $\Vert \varphi_k - \varphi \Vert \to 0$ as $k \to \infty$ and if there is a compact set $K \subset \mathbb{R}^n$ such that $$ \text{supp}(\varphi) \cup \bigcup_{k \in \mathbb{N}} \text{supp}(\varphi_k) \subseteq K,$$ that is, if the supports of the functions do not ""escape"" to infinity. Second question: does this notion of convergence somehow generates a topology on $E$? Is it metrizable?","['general-topology', 'real-analysis', 'banach-spaces', 'functional-analysis']"
2839139,$\hat{Y} = X^T\hat{\beta}$ Matrix Dimension For Linear Regression Coefficients $\beta$,"While reading about least squares implementation for machine learning I came across this passage in the following two photos: Perhaps I’m misinterpreting the meaning of $ \beta $ but if $ X^T$ has dimension $ 1 \times p $ and $\beta$ has dimension $ p \times K $, then $\hat{Y} $ would have dimension $1\times K$ and would be a row vector. According to the text, vectors are assumed column vectors unless otherwise noted. Can someone provide clarification? Edit: the matrix notation in this text is confusing me. The pages preceding the above passages state the following: Should the matrix referenced not have dimensions $ p \times N$, assuming a $p$-vector is a vector with $p$-elements? Or are the input vectors assumed to be row vectors. Note: The passage is taken from “Elements of Statistical Learning” by Hastie, Tibshirani, & Friedman.","['matrices', 'statistics', 'linear-regression', 'linear-algebra']"
2839200,If $P$ or $Q$ is normal then both $P$ and $Q$ are characteristic in $PQ$,"Abstract Algebra, Dummit and Foote e3 states that: ""If $G$ is a group of order 30 and $P\in Syl_5(G)$ and $Q\in Syl_3(G)$ with one of them being normal, then both are characteristic subgroups of $PQ$; this then implies that since $PQ$ is normal, both $P$ and $Q$ have to be normal."" Why is it that if either $P$ or $Q$ is normal in $G$ then both are characteristic in $PQ$? I realize that, by Sylow theorem, the normal Sylow subgroup has to be characteristic, but I do not get why the other one has to be also.","['normal-subgroups', 'group-theory', 'sylow-theory']"
2839241,"Double integration over a ""triangular"" semialgebraic set","I must compute the double integral $$\iint_D x^6y^6 dx dy$$ where $$D = \left\{ (x,y) : x^{2}\le y\le x^{1/8} \right\}$$ Functions $x^2=x^{1/8}$ are going to be equal for $0$ and $1$. The region looks as follows. So, I have $$\int_0^1 \left[ \cfrac{x^6y^7}{7} \right]_{x^2}^{x^{1/8}}$$ But that gives me $$\left[ \cfrac{x^{55/8}-x^{20}}{7} \right]_{0}^{1} = 0$$ I am missing a big chunk of the theory. But, what?","['multivariable-calculus', 'definite-integrals', 'calculus']"
2839267,Need help with this limit problem from Stewart's Calculus,"This is from Stewarts's Calculus Early Transcendentals 8e, Chapter 4, Problem Plus, #8. The topics discussed in chapter 4 are: ""Maximum and Minimum Values"", ""The Mean Value Theorem"", ""How Derivatives Affect the Shape of a Graph"", ""Indeterminate Forms and L'Hospital's Rule"", ""Summary of Curve Sketching"", ""Graphing with Calculus and Calculators"", ""Optimization Problems"", ""Newton's Method"", and ""Antiderivatives"". The problem is:
$$\lim_{x\to\infty}\frac{(x+2)^{1/x}-x^{1/x}}{(x+3)^{1/x}-x^{1/x}}$$ I found the limits of each term become 1, which makes the fraction $\frac{0}{0}$, so I tried using L'Hospital's but it doesn't really help as the derivatives become even more complicated. I tried rationalizing either top or bottom, but it's not too easy either because the exponents contain $x$. I also tried using Squeeze Theorem, but all failed. I think there is a way to rationalize this to simplify and then use L'Hospital's from there but I really can't find a way. I don't normally give up but as I've been struggling with this for a month, I think it's time to seek help from others :( According to graphing devices, it looks like the limit approaches $\frac{2}{3}$. I want to find a way to verify this only using elementary calculus (no series expansion, or etc) as I think that's how Stewart intended.","['calculus', 'limits']"
2839288,Determining an orthonormal set of basis vectors for the linear space,"The following is example C.4 from Appendix C (Linear Spaces Review) of Introduction to Laplace Transforms and Fourier Series, Second Edition , by Phil Dyke: Example C.4 Determine an orthonormal set of vectors for the linear space that consists of all real linear functions: $$\{a+bx:a,b\in\mathbb{R}\ 0\leq x\leq1\}$$ using an inner product $$\langle f,g\rangle=\int_0^1f g\,dx.$$ Solution The set $\{1,x\}$ forms a basis, but is is not orthogonal. Let $a+bx$ and $c+dx$ be two vectors. In order to be orthogonal we must have $$\langle a+bx,c+dx\rangle=\int_0^1(a+bx)(c+dx)\,dx=0.$$ Performing the elementary integration gives the following condition on the constants $a,b,c$ and $d$ $$ac+\frac{1}{2}(bc+ad)+\frac{1}{3}bd=0.$$ In order to be orthonormal too we also need $$\|a+bc\|=1\,\text{ and }\,\|c+dx\|=1$$ and these give, additionally, $$a^2+b^2=1,\ c^2+d^2=1.$$ There are four unknowns and three equations here, so we can make a convenient choice. Let us set $$a=-b=\frac{1}{\sqrt{2}}$$ which gives $$\frac{1}{\sqrt{2}}(1-x)$$ as one vector. The first equation now gives $3c=-d$ from which $$c=\frac{1}{\sqrt{10}},\ \ d=-\frac{3}{\sqrt{10}}.$$ Hence the set $\{(1-x)/\sqrt{10},(1-3x)/\sqrt{10}\}$ is a possible orthonormal one. $\ $ $ \ $ Of course there are infinitely many possible orthonormal sets, the above was one simple choice. The next definition follows naturally. I have the following questions: How do we determine $a^2 + b^2 = 1$ and $c^2 + d^2 = 1$ from $\|a + bx\| = 1$ and $\|c + dx\| = 1$? This seems similar to the norm of a complex number $a + bi$, but we're not dealing with complex numbers in this case, since we're dealing with the space of all real linear functions, so I'm not sure how these are being derived? If we have $a = -b = \dfrac{1}{\sqrt{2}}$ and $3c = -d$, then we have the following: $$\begin{align}
\dfrac{1}{\sqrt{2}}c + \dfrac{1}{2} \left[ \left( \dfrac{-1}{\sqrt{2}} \right)c + \left( \dfrac{1}{\sqrt{2}} \right) (-3c) \right] + \dfrac{1}{3} \left( \dfrac{-1}{\sqrt{2}} \right)(-3c) = 0
\\
\rightarrow \dfrac{c}{\sqrt{2}} - \dfrac{c}{2 \sqrt{2}} - \dfrac{3c}{2\sqrt{2}} + \dfrac{c}{\sqrt{2}} = 0
\\
\rightarrow \dfrac{2c}{\sqrt{2}} - \dfrac{4c}{2\sqrt{2}} = 0
\\
\rightarrow 0 = 0\ ?\end{align}$$ Have I made an error? Where does the $c = \dfrac{1}{\sqrt{10}}$ and $-\dfrac{3}{\sqrt{10}}$ come from? I would greatly appreciate it if people could please take the time to clarify these. EDIT: The following is proved in the textbook: Example C.3 Prove that $\|a\|=\sqrt{\langle\mathbf{a}.\mathbf{a}\rangle}\in V$ is indeed a norm for the vector space $V$ with inner product $\langle,\,\rangle$. Which seems to suggest that $\|x\| = \sqrt{\langle x,x\rangle}$?","['orthonormal', 'normed-spaces', 'functional-analysis', 'inner-products', 'linear-algebra']"
2839321,Ball-dimension of space,"I have to find ball-dimension of space $\{0\}\cup\{\frac{1}{n}:n\in\mathbb{N}\}$, which is $\limsup_{\epsilon\to 0}\frac{\log\beta(\epsilon)}{|\log\epsilon|}$. Here, $\beta(\epsilon)$ is minimum cardinality of a covering of metric space by $\epsilon$-balls. Diameter of $\epsilon$ ball is $2\epsilon$, therefore $\beta(\epsilon)>\frac{1}{2\epsilon}$ and $\limsup_{\epsilon\to 0}\frac{\log\beta(\epsilon)}{|\log\epsilon|}\geq 1$. How to conclude what is ball-dimension of this space? I'm also looking for textbook with similar problems or notes where I can read about ball dimension. By joriki's answer dimension of space is $\frac{1}{2}$, is there any way to see it intuitively? Any help is welcome. Thanks in advance.","['reference-request', 'metric-spaces', 'dynamical-systems', 'limits']"
2839354,How to derive this factorization $ax^2 + bx + c = a(x − x_1)(x − x_2) $?,"I faced this factorization formula $$ax^2 + bx + c = a(x − x_1)(x − x_2)$$ where $x_1$ is the first solution and $x_2$ is the second one. But I don't understand how the formula gets derived... Could anybody explain it to me? Thanks! I know I can solve a quadratic equation and substitute the solutions into this formula $a(x − x_1)(x − x_2)$, but I want to understand how it works.","['algebra-precalculus', 'polynomials', 'factoring', 'quadratics']"
2839361,Is there a way to solve composite exponential equations precisely?,"I have a, seemingly, trivial question. Find $x$ such that
$$
l = x^x,
$$
for some constant value $l \in \mathbb{R}^{>0}$ and $x \in \mathbb{R}^{>0}$. Obviously, this equation has a unique solution that can aprroximated. Neverthelss, I do not see an obvious approach to solve this equation precisly, nor can I find one on this website or using google. Maybe I am only missing the appropriate terminology to express the question. EDIT: I would also be fine with a good explanation why it is difficult or not possible. EDIT 2: As discussed in the comments, the equation, of course, has no unique solution for $l, x \in \mathbb{R}^{>0}$ as stated by me above.","['analysis', 'exponentiation']"
2839384,Subtraction Magmas,"I was looking at a collection of related closed binary operations on sets ( magmas ): Subtraction on the integers, reals, etc. Set difference Set symmetric difference Saturating subtraction on the nonnegative integers Ceilinged division on the positive integers Each of these operations has the following properties, where the operation is represented by $\sim$: There exists an identity element $e$ such that for all elements $a$:
$$a \sim a = e \text{ and } a \sim e = a$$ For all elements $a, b, c$:
$$(a \sim b) \sim c = (a \sim c) \sim b$$ I call these operations subtraction magmas because they often take the form of some kind of subtraction. I have two questions: Do these operations share any other nontrivial properties? That is, is there a tighter characterization of these operations? Have such operations been studied in the past?","['abstract-algebra', 'magma']"
2839385,What does it mean to substitute $y = x''$,"The textbook I'm reading says this for this problem: $$x^2y''+2xy' − 2y=0.$$ Since differentiating a power pushes down the exponent by one unit,
  the form of this equation suggests that we look for possible solutions
  of the type $y=x''$. On substituting this in the differential equation
  and dividing by the common factor $x''$, we obtain the quadratic
  equation $n(n − 1)+2n − 2=0$ What do they mean by this substitution, taking it like a literal substitution gives this nonsense which I obviously can't divide out the common factor $x''$ Literal substiution gives $$x^2(x'')'' + 2x(x'')' -2(x'') = 0$$ I can't divide everything by $x''$ because not everything is being multiplied by $x''$, for example, $(x'')''$ is the second derivative of $x''$ so I can't factor out $x''$ from that. What does the author mean by substituting $y=x''$, how did he end up with a quadratic? Screenshot:",['ordinary-differential-equations']
2839396,"On the product $\prod_{1\leq a<b\leq \frac{p-1}{2}}\,\left(a^2+b^2\right)$, where $p$ is prime","Let $p$ be an odd prime natural number.  Define 
$$M(p):=\prod_{1\leq a<b\leq \frac{p-1}{2}}\,\left(a^2+b^2\right)\,.$$
Prove that, over the field $\mathbb{F}_p=\mathbb{Z}/p\mathbb{Z}$ (i.e., in modulo $p$),
$$M(p)= \left\{
\begin{array}{ll}
0&\text{if }p\equiv1\pmod{4}\,,\\
+1&\text{if }p\equiv3\pmod{16}\text{ or }p\equiv15\pmod{16}\,,\\
-1&\text{if }p\equiv7\pmod{16}\text{ or }p\equiv11\pmod{16}\,.
\end{array}
\right.$$
The first equality (i.e., that $M(p)=0$ for $p\equiv 1\pmod{4}$) is trivial.  For now (see this thread ), we know that $M(p)=\pm1$ for $p\equiv 3\pmod{4}$.  Under my answer in that thread, jpvee found that the claim above holds for prime natural numbers $p$ such that $p\leq  1000$.  Does anybody know whether the claim is true, and if it so, how to prove the claim?","['finite-fields', 'reference-request', 'number-theory', 'prime-numbers', 'elementary-number-theory']"
2839404,Proof of Serre Duality in Hartshorne,"I'm currently reading Hartshorne, Algebraic Geometry , Chapter III.7 The Serre Duality Theorem . I'm stuck at Corollary 7.7 : If $X$ is a projective Cohen-Macaulay scheme of equidimension $n$ over $k$. Then for any locally free sheaf $\mathcal{F}$on X there are natural isomorphisms $H^i(X, \mathcal{F}) \cong H^{n-i}(X, \mathcal{F}^{\vee}\otimes \omega_X^\circ)'$ Now his "" Proof "" is just Use $(6.3)$ and $(6.7)$. Trying this I get the following: $H^i(X, \mathcal{F}) \cong \text{Ext}^i(\mathcal{O}_X, \mathcal{F})$ by $(6.3)$ $H^{n-i}(X, \mathcal{F}^\vee \otimes \omega_X^\circ)' \cong \text{Ext}^i(\mathcal{F}^\vee \otimes \omega_X^\circ, \omega_X^\circ)$ by Theorem $7.6$ $\text{Ext}^i(\mathcal{F}^\vee \otimes \omega_X^\circ, \omega_X^\circ) \cong \text{Ext}^i(\omega_X^\circ, \mathcal{F} \otimes \omega_X^\circ)$ by $(6.7)$ But how do I know conclude, that the first and the last term are the same?","['homology-cohomology', 'sheaf-cohomology', 'algebraic-geometry']"
2839426,Prove or disprove that $ \sum\limits_{k = 1 }^T f(k)=0 $ where $f(m)=\sum\limits_{n = 1 }^ m (-1)^n \sin(\frac{n(n+1)(2n+1)}{6}x) $,"$$f(m)=\sum\limits_{n = 1 }^ m (-1)^n  \sin\left(\frac{n(n+1)(2n+1)}{6} \frac{a \pi}{b}\right) \tag 1 $$ Where $a,b,m$ positive integers. 
I have tested in WolframAlpha for many $a$ and $b$ values. I conjecture ( 1 ) without proof that $f(m)$ function is periodic when $a,b,m$ positive integers and the sum of $f(m)$ is $0$ between period. Edit: In other way to express my claim above in my conjecture ($1$) that 
$ \sum\limits_{k = 1 }^T f(k)=0 $
where ($T$) is the period value. The wolframalpha link for testing some $a,b$ values I also conjecture ( 2 ) without proof that the sum of $f(m)$ should be zero if $x$ is any real number. $$f(m)=\sum\limits_{n = 1 }^ m (-1)^n  \sin\left(\frac{n(n+1)(2n+1)}{6}x\right) \tag 2 $$ $$ \lim\limits_{n \to \infty}\sum\limits_{k = 1 }^ n f(k)=0 \tag 3 $$ What is the period formula when $a,b$ are positive integers? Please help me to prove my conjectures 1 and 2 or disprove . Note that:$$\sum\limits_{k = 1 }^ n k^2=  \frac{n(n+1)(2n+1)}{6} $$ EDIT: The period value is ($T$) and $f(m)$ satisfies $f(m)=f(m+kT)$ relation where $k$ is non-negative integer. Period values for some $a,b$ values: $a=3$, $b=17$ ,$x=\frac{3 \pi}{17} \Rightarrow T=68$  (this example is given in the link) and $ \sum\limits_{k = 1 }^{68} f(k)=0  $ $a=1$, $b=2$ ,$x=\frac{ \pi}{2} \Rightarrow T=8$ and $ \sum\limits_{k = 1 }^8 f(k)=0  $ $a=1$, $b=3$ ,$x=\frac{ \pi}{3} \Rightarrow T=36$ and $ \sum\limits_{k = 1 }^{36} f(k)=0  $ $a=1$, $b=4$ ,$x=\frac{ \pi}{4} \Rightarrow T=16$ and $ \sum\limits_{k = 1 }^{16} f(k)=0  $ $a=1$, $b=5$ ,$x=\frac{ \pi}{5} \Rightarrow T=20$ and $ \sum\limits_{k = 1 }^{20} f(k)=0  $ $a=1$, $b=6$ ,$x=\frac{ \pi}{6} \Rightarrow T=72$  and $ \sum\limits_{k = 1 }^{72} f(k)=0  $ $a=1$, $b=7$ ,$x=\frac{ \pi}{7} \Rightarrow T=28$  and $ \sum\limits_{k = 1 }^{28} f(k)=0  $ $a=2$, $b=7$ ,$x=\frac{ 2\pi}{7} \Rightarrow T=14$  and $ \sum\limits_{k = 1 }^{14} f(k)=0  $ $a=3$, $b=7$ ,$x=\frac{ 3\pi}{7} \Rightarrow T=56$  and $ \sum\limits_{k = 1 }^{56} f(k)=0  $ $a=4$, $b=7$ ,$x=\frac{ 4\pi}{7} \Rightarrow T=14$  and $ \sum\limits_{k = 1 }^{14} f(k)=0  $ $a=5$, $b=7$ ,$x=\frac{ 5\pi}{7} \Rightarrow T=28$  and $ \sum\limits_{k = 1 }^{28} f(k)=0  $ Thanks a lot for answers. Please note that: I have posted a new question to generalize the problem. the link to the question","['sequences-and-series', 'trigonometric-series']"
2839435,How to eliminate $\theta$ & $\phi$ from above equations,Eliminate $\theta$ & $\phi$ from above equations. $\cos(\theta)+\cos(\phi)=a$--------------(say Eq1) $\cot(\theta)+\cot(\phi)=b$--------------(say Eq2) $\operatorname{cosec}(\theta)+\operatorname{cosec}(\phi)=c$--------------(say Eq3) What I tried: From: $(Eq3)^2 -(Eq2)^2$ $c^2-b^2-2=2(\operatorname{cosec}(\theta)\cdot\operatorname{cosec}(\phi)-\cot(\theta)\cdot\cot(\phi))      $ From: $Eq1\times Eq3$ $ca-b=\frac{\sin(\theta)\cos(\theta)+\sin(\phi)\cos(\phi)}{sin(\theta)\cdot\sin(\phi)}$ From these two derived expressions I was able to simplify it further.( But could not completely eliminate). I'm not sure whether my approach is correct.  Can you please give me a hint. Thanks.,['trigonometry']
2839450,Compactness of unitary group [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question How to see the unitary group is not compact in norm topology of $B(H)$ for infinite dimensional Hilbert space? What if norm topology is replaced by SOT?","['functional-analysis', 'general-topology', 'compactness']"
2839456,Finding orthonormal basis from orthogonal basis,"The following is example C.5 from Appendix C (Linear Spaces Review) of Introduction to Laplace Transforms and Fourier Series, Second Edition , by Phil Dyke: Example C.5 Show that $\{\sin(x),\cos(x)\}$ is an orthonormal basis for the inner product space $V=\{a\sin(x)+b\cos(x); a,b\in\mathbb R, 0\le x\le\pi\}$ using as inner product $$\langle f,g \rangle = \int_0^1 fg dx, \qquad f,g\in V$$ 
  and determine an orthonormal basis. Solution $V$ is two dimensional and the set $\{\sin(x),\cos(x)\}$ is obviously a basis. We merely need to check orthogonality. First of all, $$\begin{align}\langle\sin(x),\cos(x)\rangle=\int_0^\pi\sin(x)\cos(x)\,dx&=\frac{1}{2}\int_0^\pi\sin(2x)\,dx\\ &=\left[-\frac{1}{4}\cos(2x)\right]_0^\pi \\ &=0.\end{align}$$ Hence orthogonality is established. Also, $$\langle\sin(x),\sin(x)\rangle=\int_0^\pi\sin^2(x)\,dx=\frac{\pi}{2}$$ and $$\langle\cos(x),\cos(x)\rangle=\int_0^\pi\cos^2(x)\,dx=\frac{\pi}{2}.$$ Therefore $$\left\{\sqrt{\dfrac{2}{\pi}}\sin(x),\sqrt{\dfrac{2}{\pi}}\cos(x)\right\}$$ is an orthonormal basis. I understand that, for orthonormality, we require that $\| \mathbf{a} \| = 1$. However, I'm unsure of how the orthonormal basis was found at the bottom of the proof? I would appreciate it if people could please take the time to clarify this.","['functional-analysis', 'orthonormal', 'linear-algebra']"
2839477,Remainder on division with $22$,"What is the remainder obtained when $14^{16}$ is divided with $22$ ? Is there a general method for this, without using number theory? I wish to solve this question using binomial theorem only - maybe expressing the numerator as a summation in which most terms are divisible by $22$ , except the remainder? How should I proceed?","['binomial-theorem', 'divisibility', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
2839494,"expected sum of the numbers that appear on two dice, each biased so that a 3 comes up twice as often as each other number?","This question is already posted here ,but i want to check my approach. Question What is the expected sum of the numbers that appear on
two dice, each biased so that a $3$ comes up twice as often
as each other number? My Approach Let the probability of getting number other than $3$ is $p$ so $$\frac{1}{p}+\frac{1}{p}+\frac{2}{p}+\frac{1}{p}+\frac{1}{p}+\frac{1}{p}=1 \Rightarrow p=\frac{1}{7}$$ Proability of getting $3=\frac{2}{7}$ and rest other $=\frac{1}{7}$ let $E(X_1)$ be the expectation of getting sum on rolling $1$ dice. $E(X_1)=1 \times \frac{1}{7}+2 \times \frac{1}{7}+3 \times \frac{2}{7}+4 \times \frac{1}{7}+5 \times \frac{1}{7}+6 \times \frac{1}{7}=\frac{24}{7}$ Now
expected sum of the numbers that appear on two dice $$E(X_1 +X_2)=E(X_1)+E(X_2)=\frac{24}{7}+\frac{24}{7}=\frac{48}{7}\approx 6.86$$ Is my approach correct?","['expectation', 'probability']"
2839521,What conditions would guarantee $\Psi: \mathbb{R}^n \rightarrow \mathbb{R}^2$ to be non-zero in a small neighbourhood?,"Suppose I have $\Psi: \mathbb{R}^n \rightarrow \mathbb{R}^2$ where 
$\Psi(\mathbf{0}) = \mathbf{0}$. I would like to show that there exists a small open set $U$ around $\mathbf{0}$ such that it is non-zero for all points in $U \backslash \{ \mathbf{0} \}$. I am wondering what kind of conditions on $\Psi$ would ensure this is satisfied? Any comments are appreciated. Thank you.","['multivariable-calculus', 'differential-geometry', 'maxima-minima']"
2839532,"If $f:\mathbb{R}\to \mathbb{R}$ is an invertible function, is it necessary that the function has to be strictly monotonic?","If $f:\mathbb{R}\to \mathbb{R}$ is an invertible function, is it necessary that the function has to be strictly monotonic without any additional condition? For invertibility to hold, we have to ensure that it's a bijective function on $\mathbb{R}$. Now, let's say, a function is continuous and has a convex up form starting from $-\infty$ and is finally asymptotic at $y=5$. At point $x=3$, it has a jump discontinuity such that $(x,y)=(3,8)$. Can such a function satisfy the conditions of $f$ in question? I don't think so as the codomain is $\mathbb{R}$ and therefore, it has to be surjective on the codomain I guess.  Like, we won't be able to find $f^{-1}(12)$. Right? Or, there's no relationship with the range and codomain here? Can this be a suitable example to the function in question? (Please see the picture below) In the picture, the green coloured circles represent open intervals and the filled-blue circles represent closed intervals.","['real-analysis', 'functions']"
2839567,What is the probability that the player $P_4$ reaches the semi final,"$16$ players $P_1,P_2,....,P_{16}$ play a knockout tournament.
It is known that whenever the players $P_i$ and $P_j$ play, the player $P_i$ will win if $i<j$.
Assuming the players are paired at random in each round, what is the probability that the player $P_4$ reaches the semi final? I know that $P_1$ will anyhow reach final and $P_{16}$ will not clear the first round.
I dont know how to solve further.","['combinatorics', 'probability']"
2839588,Are integrals taught in Precalculus?,"I am high school student with an interest in mathematics. My school allowed me to self-study Pre-calculus over the summer so that I can move into AP Calculus AB next school year. I'm using a course on edX called Discovery Precalculus and things are ok for the most part, but I've recently hit a rough patch. I've come across a question that's asking me to find the algebraic measure of the space between a curve and the x-axis. From what I know, this would imply using integrals, but how does this make sense if this is meant to be a precalculus course? I've never worked with integrals or derivatives before. The Question I am given the function $f(t) = \frac{1}{t}$. It says our activities are restricted to the interval $t\in[1,3]$, which I'm guessing, in the language of calculus, would be the limits. The next things it tells me to do is plot the function on a coordinate plane with a scale of 0.1. The $f(t)$ axis goes from $0$ to $1.1$ and the $t$ axis ranges from $0$ to $3.1$. Now, from what I know so far about functions, $f(t)$ should be representing the y-axis and $t$ should be representing the x-axis. Finally, I'm told to plot the function along the domain interval $[1,3]$. So after I've done all of this, it states: The function that represents the accumulated area under $f(t)$ on the interval $[1,x]$ where $x\in[1,3]$  will be called $L(x) $. What is the value of $L(1)$? The issue I'm pretty sure it's asking me to find the area between the point $[1,1]$ and $[1,3]$, but how do I do this? It can't possibly be asking me to use integrals when the concept has never been brought up within in the scope of the course. I tried to sort it out and the farthest I got was $\int_1^3$, which I'm not even sure is right. Is there some sort of intuitive thing that I'm missing? edit - Here is the entire problem as presented in the course (This just includes the first part, where it asks for $L(1)$):","['algebra-precalculus', 'integration', 'functions']"
2839593,Solution of the ode,"Consider the IVP $$y'=h(t)y(t)$$ with $y(0)=1$ initial condition and $h(t)=1$ for $ t\geq 0 $ and $0$ elsewhere. Prove that it does not have a solution. Sollution: Let $y$ be a sollution then i get $y(t)=e^t$, $t \geq 0$ and 1 else. but that $y$ is not differentiable zero. hence no sollution. But isn't the $$y=1+ \int_{0}^{t}h(s)y(s)ds $$ a solution, or equivalent to the problem? And  now  the function $y(t)=e^t$ $t \geq 0$ and 1 else is a solution to the $y=1+ \int_{0}^{t}h(s)y(s)ds $ I think im confused . Can someone explain me the difference between the integral form and the ODE??","['ordinary-differential-equations', 'calculus']"
2839631,A naive question about the scheme theory: regard $\mathbb C^n$ as a scheme,"Note that $\mathbb C$ can be regarded as the set of closed points of $\mathrm{Spec} ~\mathbb C[T]$. And, $\mathbb C^n$ should be regarded as that of $\mathrm{Spec} ~\mathbb C[T_1,\cdots,T_n]$ What if we replace $\mathbb C$ here by a general ring $R$? What can we say about a ring $R$ (resp. $R^{\oplus n}$)and the set of closed points in $\mathrm{Spec}R[T]$(resp. $\mathrm{Spec}R[T_1,\cdots,T_n]$)? Specifically, under what conditions on a given ring $R$, can we find another ring $S$ so that $R$ can be identified with (the set of closed points of) the affine scheme $\mathrm{Spec}(S)$? For example, is it necessary that $R$ is a field?","['schemes', 'affine-schemes', 'soft-question', 'algebraic-geometry']"
2839634,Problem with open map that is not holomorphic,"This is the problem: Let $0\in\Omega\subset \mathbb{C}$ connected, open neighborhood of the origin.
  Let $f,g:\Omega\to\mathbb{C}$ holomorphic functions such that
  $f(0)\neq0\neq g(0).$ Let $h:\Omega\to\mathbb{C}$ to be
  $h(z)=f(z)\overline{g(z)}z^a\overline{z}^b$ with $a\neq b,$ positive
  integers. Take $U$ a neiberhood of the origin. show that $h(U)$ is a
  neighborhood of the origin. Clearly, the only thing I have to prove is that $h(U)$ is open. $h$ is not holomorphic but I've tried to mimic the proof for the open map theorem with no succes. I've tried to some arguments with isolated zeros of $f$ and $g$ but no luck.","['complex-analysis', 'real-analysis', 'calculus', 'analysis']"
2839636,"A closed-form expression for $\int_0^\infty \frac{\ln (1+x^\alpha) \ln (1+x^{-\beta})}{x} \, \mathrm{d} x$","I have been trying to evaluate the following family of integrals: $$ f:(0,\infty)^2 \rightarrow \mathbb{R} \, , \, f(\alpha,\beta) = \int \limits_0^\infty \frac{\ln (1+x^\alpha) \ln (1+x^{-\beta})}{x} \, \mathrm{d} x \, . $$ The changes of variables $\frac{1}{x} \rightarrow x$, $x^\alpha \rightarrow x$ and $x^\beta \rightarrow x$ yield the symmetry properties
$$ \tag{1}
f(\alpha,\beta) = f(\beta,\alpha) = \frac{1}{\alpha} f\left(1,\frac{\beta}{\alpha}\right) = \frac{1}{\alpha} f\left(\frac{\beta}{\alpha},1\right) = \frac{1}{\beta} f\left(\frac{\alpha}{\beta},1\right) = \frac{1}{\beta} f\left(1,\frac{\alpha}{\beta}\right) $$
for $\alpha,\beta > 0$ . Using this result one readily computes $f(1,1) = 2 \zeta (3)$ . Then $(1)$ implies that
$$ f(\alpha,\alpha) = \frac{2}{\alpha} \zeta (3) $$
holds for $\alpha > 0$ . Every other case can be reduced to finding $f(1,\gamma)$ for $\gamma > 1$ using $(1)$. An approach based on xpaul's answer to this question employs Tonelli's theorem to write
$$ \tag{2}
f(1, \gamma) = \int \limits_0^\infty \int \limits_0^1 \int \limits_0^1 \frac{\mathrm{d}u \, \mathrm{d}v \, \mathrm{d}x}{(1+ux)(v+x^\gamma)} =  \int \limits_0^1 \int \limits_0^1 \int \limits_0^\infty \frac{\mathrm{d}x \, \mathrm{d}u \, \mathrm{d}v}{(1+ux)(v+x^\gamma)} \, .$$
The special case $f(1,2) = \pi \mathrm{C} - \frac{3}{8} \zeta (3)$ is then derived via partial fraction decomposition ($\mathrm{C}$ is Catalan's constant). This technique should work at least for $\gamma \in \mathbb{N}$ (it also provides an alternative way to find $f(1,1)$), but I would imagine that the calculations become increasingly complicated for larger $\gamma$ . Mathematica manages to evaluate $f(1,\gamma)$ in terms of $\mathrm{C}$, $\zeta(3)$ and an acceptably nice finite sum of values of the trigamma function $\psi_1$ for some small, rational values of $\gamma > 1$ (before resorting to expressions involving the Meijer G-function for larger arguments). This gives me some hope for a general formula, though I have not yet been able to recognise a pattern. Therefore my question is: How can we compute $f(1,\gamma)$ for general (or at least integer/rational) values of $\gamma > 1$ ? Update 1: Symbolic and numerical evaluations with Mathematica strongly suggest that
$$ f(1, n) = \frac{1}{n (2 \pi)^{n-1}} \mathrm{G}_{n+3, n+3}^{n+3,n+1} \left(\begin{matrix} 0, 0, \frac{1}{n}, \dots, \frac{n-1}{n}, 1 , 1 \\ 0,0,0,0,\frac{1}{n}, \dots, \frac{n-1}{n} \end{matrix} \middle| \,  1 \right) $$
holds for $n \in \mathbb{N}$ . These values of the Meijer G-function admit an evaluation in terms of $\zeta(3)$ and $\psi_1 \left(\frac{1}{n}\right), \dots, \psi_1 \left(\frac{n-1}{n}\right) $ at least for small (but likely all) $n \in \mathbb{N}$ . Interesting side note: The limit
$$ \lim_{\gamma \rightarrow \infty} f(1,\gamma+1) - f(1,\gamma) = \frac{3}{4} \zeta(3) $$
follows from the definition. Update 2: Assume that $m, n \in \mathbb{N} $ are relatively prime (i.e. $\gcd(m,n) = 1$). Then the expression for $f(m,n)$ given in Sangchul Lee's answer can be reduced to
\begin{align}
 f(m,n) &= \frac{2}{m^2 n^2} \operatorname{Li}_3 ((-1)^{m+n}) \\
&\phantom{=} - \frac{\pi}{4 m^2 n} \sum \limits_{j=1}^{m-1} (-1)^j \csc\left(j \frac{n}{m} \pi \right) \left[\psi_1 \left(\frac{j}{2m}\right) + (-1)^{m+n} \psi_1 \left(\frac{m + j}{2m}\right) \right] \\
&\phantom{=} - \frac{\pi}{4 n^2 m} \sum \limits_{k=1}^{n-1} (-1)^k \csc\left(k \frac{m}{n} \pi \right) \left[\psi_1 \left(\frac{k}{2n}\right) + (-1)^{n+m} \psi_1 \left(\frac{n + k}{2n}\right) \right] \\
&\equiv F(m,n) \, .
\end{align}
Further simplifications depend on the parity of $m$ and $n$. This result can be used to obtain a solution for arbitrary rational arguments: For $\frac{n_1}{d_1} , \frac{n_2}{d_2} \in \mathbb{Q}^+$ equation $(1)$ yields
\begin{align}
f\left(\frac{n_1}{d_1},\frac{n_2}{d_2}\right) &= \frac{d_1}{n_1} f \left(1,\frac{n_2 d_1}{n_1 d_2}\right) = \frac{d_1}{n_1} f \left(1,\frac{n_2 d_1 / \gcd(n_1 d_2,n_2 d_1)}{n_1 d_2 / \gcd(n_1 d_2,n_2 d_1)}\right) \\
&= \frac{d_1 d_2}{\gcd(n_1 d_2,n_2 d_1)} f\left(\frac{n_1 d_2}{\gcd(n_1 d_2,n_2 d_1)},\frac{n_2 d_1}{\gcd(n_1 d_2,n_2 d_1)}\right) \\
&= \frac{d_1 d_2}{\gcd(n_1 d_2,n_2 d_1)} F\left(\frac{n_1 d_2}{\gcd(n_1 d_2,n_2 d_1)},\frac{n_2 d_1}{\gcd(n_1 d_2,n_2 d_1)}\right) \, .
\end{align} Therefore I consider the problem solved in the case of rational arguments. Irrational arguments can be approximated by fractions, but if anyone can come up with a general solution: you are most welcome to share it. ;)","['special-functions', 'integration', 'definite-integrals']"
2839661,"Theorem 1.14 (b) Rudin functional analysis, few clarifications.","Going through such theorem which states: In a topological vector space $X$ : (a) every neighborhood of $0$ contains a balanced neighborhood of $0$ and (b) every convex neighborhood of $0$ contains a balanced convex neighborhood of $0$ Proof of (a): We pick a neighborhood $U$ of $0$ because of continuity of multiplication there's a $\delta > 0$ and a neighborhood $V$ such that $\alpha V \subset U$ when $|\alpha| < \delta$. Now we pick $$
W = \bigcup_{|\alpha| <\delta} \alpha V
$$ And $W$ is a neighborhood of $0$ (this is because is obtained as arbitrary union of open sets that are neighborhoods of $0$ right?). It is also balanced because if we pick $0 \leq |\beta| \leq 1$ we have $$
\beta W = \beta \bigcup _{|\alpha| < \delta} \alpha V = \bigcup _{|\alpha| < \delta} \beta \alpha V \subset W
$$ is this right? Proof of (b): This is a bit confusing to me, all over the proof, I'll just try to highlight what I don't understand. Is $W$ chosen as balanced neighborhood subset of $U$ (convex neighborhood of $0$), is it because of (a)? Why $\alpha^{-1}W = W$? This should be consequence of the fact that $W$ is balanced, but I really don't see why. Why $A^o \subset U$? Given $A$ is convex so is $A^o$, why? I guess this because of theorem 1.13 (d), right? It might be me but I really get confused with the proof that $A$ is balanced, can you clarify? Proof of (b) : Suppose $U$ is a convex neighborhood of $0$ in $X$. Let $A = \bigcap \alpha U$ where $| \alpha | = 1$, choose $W$ as in part (a). Since $W$ is balanced, $\alpha^{-1} W = W$ when $|\alpha| = 1$; hence $W \subset \alpha U$. Thus $W \subset A$, which implies that the interior $A^o$ of $A$ is a neighborhood of $0$. Clearly $A^o \subset U$. Being an intersection of convex sets, $A$ is convex; hence so is $A^{o}$. To prove that $A^o$ is a neighborhood with the desired properties we have to show that $A^o$ is a neighborhood with the desired properties, we have to show that $A^o$ is balanced; for this it suffeces to prove that $A$ is balanced. Choose $r$ and $\beta$ so that $0 \leq r \leq 1, |\beta| = 1$. Then
  $$
r\beta A = \bigcap_{|\alpha| = 1} r\beta \alpha U = \bigcap_{|\alpha| = 1} r\alpha U,
$$
  Since $\alpha U$ is a convex set that contains $0$, we have $r \alpha U \subset \alpha U$. Thus $r\beta A \subset A$ which completes the proof.","['functional-analysis', 'topological-vector-spaces', 'proof-explanation']"
2839669,The twisting sheaf,"The definition given of the twisting sheaf on $\textrm{Proj}S$ for some graded ring $S$ is $\mathcal O_S(n) = \widetilde{S(n)}$. I'm having trouble seeing what this sheaf is though, I'm not even totally sure what the module $S(n)$ is (I think it's the same set as $S$ but the grading is such that degree $i$ elements in $S(n)$ are degree $n+i$ elements in $S$?). I guess it's not helped by the construction of the sheaf associated to a module being not particularly easy to visualise. For example of one of the things I'm having trouble understanding I've seen that $s \in S_d$ can be naturally associated to a global section of $\mathcal O_S(d)$ but I can't explicitly work out what this section should be. Perhaps this question is too general/vague so if it is just let me know and I'll try and add in some more specific questions.","['schemes', 'sheaf-theory', 'algebraic-geometry']"
2839678,Handshake/pigeonhole principle problem?,"There a number of people in a party. Each person shakes hands with exactly 20 people. For each pair of people that shakes hands with each other, there is exactly 1 other person who shakes hands with both of them; while for each pair of people that don’t shake hands with each other, there are exactly 6 other people who shake hands with both of them. I am tasked to find the total number of people in the room. I am very confused as to how to invoke 3rd condition, could someone guide me in this respect? Thank you!","['combinatorial-designs', 'combinatorics', 'graph-theory']"
2839693,double integral in polar coordinates formula proof,"I'm currently reading Calculus by Thomas and I cant seem to understand the argument for the following double integral in polar form formula . The text says that the double integral of a function over a region R in polar coordinates is defined as: $$\iint_R f(r,θ) dA = lim_{n\to \infty} \sum_{k=1}^n f(r_k, θ_k) \Delta A_k$$ where $\Delta A_k$ is the area of the kth polar rectangle when we divide the region R into n polar rectangles. The text then says that the area of each polar rectangle $\Delta A_k$ = $r_k$ $\Delta r$ $\Delta θ$ as per the following image from the book: sector image which gives $$\iint_R f(r,θ) dA = lim_{n\to \infty} \sum_{k=1}^n f(r_k, θ_k)r_k \Delta r \Delta θ$$ The text then says as $n\to \infty$  and  $\Delta r\to 0$ and $\Delta θ\to 0$, the sum converges to $$lim_{n\to \infty} \sum_{k=1}^n f(r_k, θ_k)r_k \Delta r \Delta θ =\iint_R f(r,θ)r dr dθ $$ Lastly the text says, "" A version of Fubini's theorem says that the limit approached by these sums can be evaluated by single integrations with respect to r and θ as $$\iint_R f(r,θ) dA = \int_{θ=a}^{θ=b} \int_{r = g_1(θ)}^{r= g_2(θ)} f(r,θ)r dr dθ  $$ "" My question is the integral in the last statement inferred from the riemann sum of the polar rectangles * height of the function
or is it inferred like in case of rectangular coordinates where the inner integral represents the cross sectional area or does it come about as a particular case of a general change of variables.","['multivariable-calculus', 'integration']"
2839697,Number of possible functions satisfying the given conditions,"I Have to find the number of functions $f(x)$ from {1,2,3,4,5} to {1,2,3,4,5} that satisfy $ f(f(x)) = f(f(f(x)))$ for all $x$ in {1,2,3,4,5} . However I am unable to understand from where to start. The number of cases I am trying to analyze is too much. I tried classifying it into functions which are onto, which are not unto wherein only 1 image appears twice and so on but I am realising that the list is becoming too huge. Can anyone help me with a simpler analysis of this question.","['combinatorics', 'functions']"
2839704,Integration of $\int \arcsin(a \sin{x}) dx $,"I'm an engineering student and I'm working on a probability problem. I'm trying to find out the probability that two random diagonals of two circumferences intersect. I'm considering two circumferences with the same ray r and with their center points at distance c. In according to the value of a=c/r the problem assumes different formulations anyway in any case emerge a strange integral I'm not able to solve. The integral is the following: $$\int \arcsin(a \sin{x}) dx $$ the value of the limits of integration is in according to the value of the parameter a ( for example one integral is integrated between $0$ and $\arccos (a/2)$ ). The software 'Mathematica' doesn't give me any results for this integral so I have tried to work on the integral expanding it with the definition of $\arcsin$, using by parts method and various substitutions with the hope to find out some known form that can be expressed in terms of some special function, but my efforts has been vain up to now. I have found some papers dealing with integrals involving $\ln{sin}$ that maybe have something to do with my problem.Probably I'm facing some hard mathematics that I'm not able to deal with or there is not a solution as the one I'm looking for. I'm waiting for some advice. Thank you.","['special-functions', 'integration', 'probability']"
2839737,"Consider symplectic vector fields $X,Y$ and a symplectic connection $\nabla$. Is $\nabla_{X}Y$ symplectic?","Consider a symplectic manifold $(M,\omega)$, together with a symplectic connection $\nabla$, i.e . a torsion-free connection such that $\nabla{\omega} = 0$. Fix two symplectic vector fields $X$ and $Y$. Is it true that $\nabla_{X}Y$ is again a symplectic vector field? I tried with Cartan calculus but I'm stuck, not beeing able to collect the terms in a clever way. Any other suggestion is welcomed.","['vector-fields', 'lie-derivative', 'connections', 'symplectic-geometry', 'differential-geometry']"
2839751,Checking Lyapunov stability of non linear system,"I need to check the stability of the equilibrium point of the following system, $n \in \Bbb N$:
$$
\left\{ 
\begin{array}
\dot \dot x_1=x_2 \\ 
\dot x_2=-x_1^n 
\end{array}
\right. 
$$ I tried using linearization, but the eigenvalues are zero, which means it's not the way to go. I also searched for a Lyapunov function, but couldn't find one. Any ideas?","['stability-in-odes', 'lyapunov-functions', 'ordinary-differential-equations']"
2839754,3D Rep-tiles and Irreptiles,"There are various known 3D Rep-Tiles and Irreptiles .  Almost all of them are based on polycubes OR  2D reptiles.  What are the 3D rep-tiles and irreptiles not based on polycubes and 2D reptiles? One infinite set uses $n$ bricks of size $(r^0,r^1,r^2)$ where $r=\sqrt[3]{n}$.  The Delian Brick uses two bricks based on the Delian constant . The first to use the Delian brick may have been Thickfun and Dale Walton, who expanded this into the Fifth Chair puzzle, a 4-irreptile. Of the five space-filling tetrahedra , at least two are 8-reptiles. I've put together code for all of these .  Are there any other 3D shapes which can be self-divided into smaller similar shapes, where the underlying shape is not a 2D reptile or a polycube?","['recreational-mathematics', 'tiling', 'fractals', 'geometry']"
2839812,Singular points of analytic continuation,"In Knopp's theory of functions part 1, the following fact about analytic continuation is mentioned without proof. And I am looking for a simple proof. Let $$f(z) = a_0 + a_1(z-z_0) + a_2(z-z_0)^2 + \dots$$ be a power series around $z_0$ with radius of convergence $R$ where $0 < R < \infty.$ Let $z_1$ be a point in the region of convergence with $ 0 < |z_1 - z_0| <  R.$ Assume that $f$ can be expanded in a power series around $z_1$ with a radius of convergence exactly equal to $R_1 = R - |z_0 - z_1|$. Clearly, $C$, the circle with center $z_0$ with radius $R$ and, $C_1$ the circle with its center at $z_1$ with radius $R_1$ intersect at exactly one point, say $z_2$ and $C_1$ lies within $C$. 
Knopp mentions that $z_2$ is a singular point of $f$ in the following sense : given any neighborhood of $z_2$,say $U = B(z_2,r)$, there is no analytic function, $g$ defined on $U$  whose values coincide with the values of $f$ on $U \cap B(z_0,R)$. My observations : To prove this, it is sufficient to show that given any $r > 0$ there exists a $\delta > 0$ such that $B(z_1,R_1+\delta) \subseteq B(z_0,R) \bigcup B(z_2,r) \tag{*} \label{e:1}. $ To see this notice that if an analytic function $g$ exists on $B(z_2,r)$ for some $r > 0$, such that the values of g coincide with the values of $f$ on $B(z_0,R) \bigcap B(z_2,r)$  then $g$ is an analytical extension of $f$ on $B(z_0,R) \bigcup B(z_2,r)$ and moreover assuming $\eqref{e:1}$ it means that $f$ can be extended to an analytical function on $B(z_1,R_1+\delta)$. However this means the radius of convergence of the power series determined by $f$ at $z_1$ must be strictly larger than $R_1$ which is a contradiction. So it remains to prove $\eqref{e:1}$ which is a purely geometric problem. A visual representation suggests that if $\delta$ is chosen to be less than the length of a segment joining $z_1$ and $A$ where $A$ is a point of intersection of the circle at $z_2$ with radius $r$ and $C$ the circle with center at $z_0$ with radius $R$ we should be good. But I don't see an easy proof.",['complex-analysis']
2839828,Finding Lyapunov function for a stable equilibruim of a non linear system,"Given the following system: $$
\left\{ 
\begin{array}{c}
\dot x=y-x^2-x \\ 
\dot y=3x-x^2-y 
\end{array}
\right. 
$$ I need to find the equilibrium points, and if stable, to find a Lyapunov function. I have found two equilibrium points: $(0,0), (1,2)$. By linearization I'v found $(0,0)$ to be unstable, and $(1,2)$ to be stable. I tried to find a Lyapunov function for $(1,2)$ with no success. How can I find such a function?","['stability-in-odes', 'lyapunov-functions', 'ordinary-differential-equations']"
2839841,eigenvalues of $AA^T$ and $A^TA$ [duplicate],This question already has answers here : Let $A$ be an $m \times n$ matrix. Show $A^TA$ and $AA^T$ have the same eigenvalues (4 answers) Closed 5 years ago . Is it true (and under which conditions) that the products of an non-square matrix $A$ and its transpose and vice versa (so the product of the transpose and $A$) share the same eigenvalues (multiplicities omitted)?,"['matrices', 'transpose', 'eigenvalues-eigenvectors']"
2839843,"Converting to Complex coordinates to check injectivity of $f(x,y)=(e^x\cos{y},e^x\sin{y})$",I have posted the problem below.  I know that this question has been asked  before but I have a question about the proof. I wrote the expression in polar form as $f(z)=e^z$ and to check injectivity I assumed that $f(z_1)=f(z_2)$ which gives $e^{z_1}=e^{z_2}$.  Is that enough to conclude that $z_1=z_2$?  Or should I rewrite the functions as $e^{z_1}=e^{x_1}\cos{y}+ie^{x_1}\sin{y}$?  The first case I doesn't consider the restriction on $y$ and then if that's the case then it seems pointless to have converted to complex form. Thanks!,"['real-analysis', 'calculus', 'proof-verification', 'multivariable-calculus', 'complex-analysis']"
2839877,Second Derivative with respect to a Matrix,"I have a question regarding (second order) derivative with respect to a matrix. I encounter this question because I am calculating Fisher Information, but I guess the context is not very relevant in this question. Here is the derivative: $$
\frac{\partial}{\partial \Sigma} \Sigma^{-1}A\Sigma^{-1}
$$ where $\Sigma$ is a covariance matrix (positive semi-definite, symmetric), and $A = (x_i - \mu_0)(x_i -\mu_o)^T$, but we may simply use $A$ instead while knowing $A$ is symmetric. Before posting this question, I have searched on google, and found several sources useful and relevant, but do not answer my question straightaway: https://www.ics.uci.edu/~welling/teaching/KernelsICS273B/MatrixCookBook.pdf Second order derivative of the inverse matrix operator Consequently, I have made a coarse attempt to derive it, but I am not confident whether it is correct. ==================================================================== Consider a very small $\delta\Sigma$ \begin{align*}
(\Sigma + \delta\Sigma)^{-1}A(\Sigma+\delta\Sigma)^{-1} &= [\Sigma(I+\Sigma^{-1}(\delta\Sigma))]^{-1}A[(I+(\delta\Sigma)\Sigma^{-1})\Sigma]^{-1}\\
&=(I+\Sigma^{-1}(\delta\Sigma))^{-1}\Sigma^{-1}A\Sigma^{-1}(I+(\delta\Sigma)\Sigma^{-1})^{-1}\\
&=(\sum_{n=0}^\infty(-1)^n[\Sigma^{-1}(\delta\Sigma)]^n)\Sigma^{-1}A\Sigma^{-1}(\sum_{n=0}^\infty(-1)^n[(\delta\Sigma)\Sigma^{-1}]^n)\\
&\approx (I-\Sigma^{-1}(\delta\Sigma))\Sigma^{-1}A\Sigma^{-1}(I-(\delta\Sigma)\Sigma^{-1})\\
&=\Sigma^{-1}A\Sigma^{-1} - \Sigma^{-1}(\delta\Sigma)\Sigma^{-1}A\Sigma^{-1}-\Sigma^{-1}A\Sigma^{-1}(\delta\Sigma)\Sigma^{-1}\\
+\Sigma^{-1}(\delta\Sigma)\Sigma^{-1}A\Sigma^{-1}(\delta\Sigma)\Sigma^{-1}
\end{align*} Then, we may have \begin{align*}
(\frac{\partial}{\partial \Sigma} \Sigma^{-1}A\Sigma^{-1})\delta\Sigma &= \lim_{||\delta\Sigma||\rightarrow0}(\Sigma + \delta\Sigma)^{-1}A(\Sigma+\delta\Sigma)^{-1} - \Sigma^{-1}A\Sigma^{-1}\\
&\approx \lim_{||\delta\Sigma||\rightarrow0}- \Sigma^{-1}(\delta\Sigma)\Sigma^{-1}A\Sigma^{-1}-\Sigma^{-1}A\Sigma^{-1}(\delta\Sigma)\Sigma^{-1}
\end{align*} (somehow by magic or by speculating, I guess)
$$
\frac{\partial}{\partial \Sigma} \Sigma^{-1}A\Sigma^{-1} = - \Sigma^{-2}A\Sigma^{-1}-\Sigma^{-1}A\Sigma^{-2}
$$ ==================================================================== I have a feeling that I may be around there, but not quite yet. I am really hoping to get from this question the output of the derivative. Thank you so much for all of your time! p.s.: You do not have to follow my trail of thoughts (which could be wrong per se), and you may just show the correct way of doing this. I call this second order derivative because $\Sigma^{-1}A\Sigma^{-1}$ is what I have obtained by taking first derivative of $(x_i-\mu_0)^T\Sigma^{-1}(x_i-\mu_0)$, and yes, all you smart people may have realized this is multivariate normal. ==================================================================== In a month after I posted this question, I managed to find a great reference I would like to share. For those people who are having similar questions, here is a book that will give you a great insight (which closely resembles the method presented by @greg). ""Matrix Differential Calculus with applications in statistics"" by Magnus and Neudecker. Take a look at its Chapter 2, which offers great explanations (and examples) about kronecker product and vector operation, two important concepts when dealing with matrix differential.","['matrices', 'fisher-information', 'matrix-calculus', 'derivatives']"
2839939,Comparing sums of numbers in table,"Given a table with $a$ rows and $2b+1$ columns. Each cell contains a nonnegative real number. What is the largest number $k\in[0,1)$, independent of $a$ and $b$, for which we can always choose $b$ columns so that for at least $k\cdot a$ rows, the sum of the $b$ numbers in each row is at least the sum of any other $b$ (out of the remaining $b+1$) numbers in the same row? Example: Suppose we have a table corresponding to the $3\times 3$ identity matrix. Then no matter which column we choose, the condition is only satisfied for one of the three rows. This shows that the largest $k$ is no more than $1/3$. Is $1/3$ the largest possible $k$?","['algebra-precalculus', 'combinatorics']"
2839945,Exercise about primes in the ring of Gaussian integers,"Let $p$ be a prime in $\mathbb{Z}$ of the form $4n + 1, n \in \mathbb{N}$. Show that $\left(\frac{-1}{p}\right) = 1$ (here $\left(\frac{\#}{p}\right)$ is the Legendre symbol). Hence prove that $p$ is not a prime in the ring $\mathbb{Z}[i]$. Here is my solution: Since $p > 2$, we have $\left(\frac{-1}{p}\right) = 1$ if and only if $(-1)^{\frac{p - 1}{2}} \equiv_p 1$ if and only $(-1)^{2n} \equiv_p 1$ which is true. Now suppose $p$ is prime in $\mathbb{Z}[i]$, which means that there exists $x \in \mathbb{Z}$ such that $-1 \equiv_p x^2$, from which $p \mid (x^2 + 1) = (x - i)(x + i)$ and, since $p$ is prime, $p \mid (x - i)$ or $p \mid (x + i)$. In either case we have $m + ni \in \mathbb{Z}[i]$ such that $p(m + ni) = x \pm i$, which implies $pn = x$, that is $p \mid x$, and $x^2 + 1 \equiv_p 1$, which is not congruent to $0$, contradiction. Is it correct? thanks in advance Edit: (I've tried to write it better using Robert Soupe advice) Since $p>2$ we have $(-1)^{(p-1)/2}\equiv_p (-1)^{2n} \equiv_p 1$, that is $\left(\frac{-1}{p} \right)= 1$. Now suppose $p$ is prime in $\mathbb{Z}[i]$, this means that there exists $x \in \mathbb{Z}$ such that $x^2 \equiv_p -1$, hence $p \mid (x^2 + 1) = (x - i)(x + i)$ and, since $p$ is prime, $p \mid (x + i)$. Therefore there exists $m + ni \in \mathbb{Z}[i]$ such that $p(m + ni) = x + i$, but this is absurd because $p$ does not divide $1$. We can conclude that $p$ is not prime in $\mathbb{Z}[i]$.","['gaussian-integers', 'abstract-algebra', 'proof-writing', 'prime-numbers', 'group-theory']"
2839950,How to solve a nonlinear ODE with multiple product of derivative terms?,"I came across a highly nonlinear 4th order ODE, with multiple derivative product terms, after applying a transformation to an even more complex ODE. I have two queries, one rather specific and other more general. Is there a general solution to $A^2 \nu  G^{(4)}(\eta )-4 A \nu  G^{(3)}(\eta )-A G(\eta ) G^{(3)}(\eta )+A G'(\eta ) G''(\eta )+4 \nu  G''(\eta )+2 G(\eta ) G''(\eta )=0$ $A$ and $\nu$ are constants from the transformation which for our purposes is arbitrary. It does have a trivial solution $G(\eta) = \alpha \eta + \beta$, the linear function. I could not find any other solutions with all the usual methods. Can somebody suggest a different solution or a method to solve the equation? How do we approach such ODE's with multiple derivative product terms? i.e the kind of ODE's which are nonlinear but without any other functions appearing in it. I mean ODE's of the type $L\left(G^{(4)}(\eta),G^{(3)}(\eta),G^{(2)}(\eta),G^{(1)}(\eta),G(\eta)\right)=0$","['multivariable-calculus', 'ordinary-differential-equations', 'nonlinear-system', 'analysis']"
2839956,Using a function in set-builder notation?,"I want to formulate a set $K$ with the set-builder notation, but I am not sure if I am ""allowed"" to use a function, $m$, as a predicate without explicitly defining the function. I want to accomplish the following: Given two sets $A$ and $B$, I want to define set $K$ in way that members of $K$ are also members of either set $A$ or $B$, provided that the function $m$ of $k$ evaluates to $e$, where $k \in K$ and $e \in E$. Furthermore, the ""inner workings"" of $m$ are irrelevant, it only matters that $m$ maps members of $K$ to members of $E$. I tried to formulate it as follows: Suppose $m: K \rightarrow E$ and $e \in E$, then $K$ is: $K = \{x \in (A \cup B)\ :\ e = m(x)\}$",['elementary-set-theory']
2839981,General singular cubic surface consists of $6$ lines of multiplicity two and $15$ single lines?,"Let $X\subset \mathbb P^4$ be a smooth cubic threefold, $\{S_t\}_{t\in \mathbb P^1}$ be a generic pencil of hyperplane sections (so each one is a cubic surface, for smooth one it contains $27$ lines). I read from somewhere the following statement: This defines a degree $27$ cover $\pi: C\to \mathbb P^1$ with $24$ branch points in $\mathbb P^1$, and over each of the $24$ points, the fiber consists of $6$ points of multiplicity two and $15$ single points. I can understand the number of branch points $24$ is because the degree of dual variety $\check{X}$ is $24$. But why such fiber consists $6$ points of multiplicity two? Everything is over $\mathbb C$.",['algebraic-geometry']
2839993,Techniques to prove that solutions of ODE are defined for all time.,"What are the main techniques for proving that the solutions of ODE are defined for all times? Obviously I refer to qualitative study of $$y'=f(t,y)$$ with $f:\mathbb{R}\times\mathbb{R}^n\to\mathbb{R}^n $ at least $C^0$. The standard way is to use classical reults (e.g. prove that $f$ is sublinear or globally lipschitz) but these rusults are often not applicable. In this case I try to show that the solutions are bounded (it is known that if the orbits are bounded then the solutions are defined for all time ). To do this I usually try one of the following techniques: I look for a constant of the motion and I study the level sets to understand the shape of the orbits (and see if they are bounded); I find a particular solution that is a closed and curve (e.g. a circle): in fact for the uniqueness the orbits can not intersect and therefore all orbits that start from inside this closed curve will have to remain there and will therefore be limited; I study the function $h(t): = x^2(t) + y^2(t)$: I make the derivative and I try to show that it is limited; I try a change of variables (e.g. polar coordinates) that simplifies the equations. In conclusion: 1) Do you know other general techniques to show that the orbits are bounded? 2) However, boundedness is only a sufficient condition to prove that solutions are defined for all time! In case the solutions are unbounded how can I prove that they are defined for all time? For example consider $$\begin{cases}\dot x=-y^2\\
\dot y = x^2\end{cases}$$ or $$\begin{cases}\dot x=y^2\\
\dot y = x^2\end{cases}$$
The level sets of the constants of motion ($E:=x^3\pm y^3$) of these system are open and unbounded curve. In this case the only techniques that I know is to cumpute $t=\int^{+\infty}_{x_0}...dx$ and understand if this integral converges or diverges (for other details see the end of this page: Qualitative study of $ \dot x = - y^2$, $\dot y= x^2 $ ). 3) Advice on books and readings about this problem are welcome.","['alternative-proof', 'dynamical-systems', 'reference-request', 'ordinary-differential-equations', 'analysis']"
2840001,Having trouble simplyfing radicals of this sort,"I'm studying radicals and rational exponents. I'm having lots of hardships with problems of this sort: prove $$\sqrt{43+24\sqrt{3}}=4+3\sqrt{3}$$ I keep going around and around experimenting with factoring. I can't seem to be able to prove this one in particular. Am I missing any common practice in regards to solving these and thus complicating it further? Is there any thing in particular I should always have in mind, or is this just lack of practice?","['radicals', 'algebra-precalculus', 'proof-explanation', 'nested-radicals', 'exponentiation']"
2840030,Weird sum that is almost definitely not $\sqrt 2$,I have not the ability to compute more than four digits of $$\sum_{n=1}^\infty \frac{1}{n^2 H_n^{(\ln n)}}$$ $H_n^{(m)} = \sum_{k=1}^n \frac{1}{k^m}$ is the generalized harmonic number . I know this is the weirdest sum and it offers me no actual interest.  All I know is that the decimal number starts off as $1.414...$ and I want to settle my mind that it is not actually $\sqrt 2$. That would be crazy. I have no reason to expect it. I just want some confirmation. My calculations were from Desmos here https://www.desmos.com/calculator/helb1dgf1g .,"['decimal-expansion', 'sequences-and-series']"
2840152,Alternative ways to represent the complex numbers as matrices,"The canonical way to represent the complex number $a+bi$ as a $2\times2$ matrix is with $\pmatrix{a &b\\-b&a}$, but I have also found that $\pmatrix{a&bx\\\frac{-b}{x}&a}$ will do for any non-zero $x$. Is there some error here or is this also a perfect representation? Furthermore, is this the only way to represent the complex numbers as matrices?","['matrices', 'complex-numbers']"
2840190,How much ketchup is on the table? (Ketchup flow rate problem),"This is a question I came up with while watching my friend squirt ketchup onto his table. He was squirting the ketchup out of a bottle while moving the bottle upwards. A ketchup bottle starts upside down with the tip at the table. Ketchup is squirted out at a volume flow rate of $Q(t)$, in $\frac{m^3}{s}$, while the bottle itself is moving upwards at a rate of $v(t$), in $\frac{m}{s}$. When the ketchup comes out of the bottle it is always initially not moving, but immediately starts falling to the table due to gravity ($g = 10 \frac{m}{s^2}$ downwards). Find $V(t)$, the volume of ketchup on the table as a function of time. Edit 1: We can ignore the fact that in real life the accumulating ketchup on the table will, in some sense, increase the height of the table.","['derivatives', 'physics', 'calculus', 'integration', 'word-problem']"
2840203,Clarification on the definition of separable Metric Space.,"In the 3rd edition of the Principles of Mathematical Analysis by Rudin, he defined a countable set as one which has a bijection between the set of Natural numbers and itself ie. it is infinite. He also defined a separable metric space as a set which possessed a countably dense set. Does this mean that all separable metric spaces have infinite dense subsets? The reason for this question is the following: A metric space in which every infinite set has a limit point is separable In the solution provided in the link above and other solutions I've seen, a countably dense set was constructed but their definition of countable includes finite sets as well. No effort was shown to determine if the set needed to be infinite. So for this particular question shown i Take countable as referring to finite sets as well?","['analysis', 'functions']"
2840212,Factoring a convergent infinite product of polynomials.,"Suppose that $f(z)=\displaystyle\prod_{k=1}^\infty p_k(z)$ is a convergent product of polynomials $p_k$ such that $p_k(0)=1$. I want to know if I can ""factor"" $f(z)$ in the following way: if we list the roots of all the $p_k$ as $r_1, r_2, r_3, \ldots$, must the product $\displaystyle\prod_{j=1}^\infty \left( 1-\frac{z}{r_j}\right)$ converge? I understand that the Weierstrass Factorization Theorem gives a factorization for $f(z)$ that involves exponential terms to ensure convergence, but I am wondering whether knowing only that $\displaystyle\prod_{k=1}^\infty p_k(z)$ converges is enough to conclude that the roots grow fast enough.","['complex-analysis', 'infinite-product']"
2840252,How to find the relation between Area and Radius?,"Let $S$ be the circumcircle of a right triangle $ABC$ with $\measuredangle A = 90^{\circ}$ . Circle $X$ is a tangent to the lines $AB$ and $AC$ and internally to $S$ . Circle $Y$ is tangent to $AB$ and $AC$ and externally to $S$ . Prove that (radius of $X$) ·(radius of $Y$) is equal to four times the area of $\Delta ABC$. My attempts: The Circle X is touching the lines AB and AC and the Circle S, so I'm trying to calculate the relation between the radius of X and AB and AC, because half of product of AB and AC is the area of ABC, but so a relation between the radius of X and AB and AC can help. But I'm unable to find, I'm still thinking, Please help..","['circles', 'euclidean-geometry', 'triangles', 'geometry', 'area']"
2840289,How can an elliptic curve be regarded as a group scheme?,"If I understand correctly: A scheme is a functor $\mathbf{CRing} \rightarrow \mathbf{Set}$ satisfying certain axioms. A morphism of schemes is a natural transformation. A group scheme is a group object in the category of schemes, so in particular it includes the data of a scheme $G$ together with a natural transformation $\mu : G \times G \rightarrow G$. This means, in particular, that given any commutative ring $R$, we get a corresponding function $\mu_R : G(R) \times G(R) \rightarrow G(R).$ Every elliptic curve can be viewed as a group scheme. This means, in particular, that given an elliptic curve $E$ and a commutative ring $R$, we get a function $\mu_R : E(R) \times E(R) \rightarrow E(R)$. However, this last statement contradicts something else that I thought was true; namely, I thought that $E(R)$ only carried a group structure in the special case where $R$ is a field. In particular, recall that the group structure is defined by considering lines through points on the curve $E$. AFAIK, these lines might ""miss"" the curve if we're not working over a field. Question. What's going on here?","['schemes', 'group-schemes', 'elliptic-curves', 'algebraic-geometry']"
2840298,What are the homotopy groups of the space of matrices with rank bigger than $k$?,"Let $H_{>k}$ be the space of real $d \times d$ matrices of rank bigger than $k$, for some fixed $k$. What are the homotopy groups $\pi_n(H_{>k})$? In particular, I would like to know whether or not they are finitely generated for $n \ge 2$? (The reason is that this is a necessary condition for a manifold to be a homogeneous space , and I wonder whether or not $H_{>k}$ is such a space .)","['higher-homotopy-groups', 'homotopy-theory', 'matrices', 'algebraic-topology', 'matrix-rank']"
2840317,When is the submodule of a product a product of submodules?,"Let $(M_i)_{i \in I}$ be a family of submodules, $M :=\prod_{i \in I}M_i$, and $S \subseteq M$ a submodule. My main question is the following: Under which conditions can we say that $S = \prod_{i\in I}S_i$ with $S_i$ submodules of each $M_i$? What if we only ask for $S \simeq \prod_{i\in I}S_i$? from which stem this other two questions, Is the specific case in which $M_i$ are commutative rings with unity  and $\prod_{i \in I}M_i$ is thought as a module over itself any easier? What if we replace products for direct sums? I have though about this for a while but I'm not too familiar with these objects yet. The motivating example for this question was $G_{p,q} := \mathbb{Z}_p \oplus \mathbb{Z}_q$ for $p,q$ prime as a $\mathbb{Z}$-module. When $p \neq q$ a nontrivial subgroup has order either $p$ or $q$. Without loss of generality (since they are symmetric) let's consider $H \leq G_{p,q}$ of order $p$. If $(a,b) \in H$, necessarily either $(a,b) = (0,0)$ or $\operatorname{ord}(a) = p$ and $b = 0$, since $\operatorname{ord}(a,b) = \operatorname{lcd}(\operatorname{ord}(a), \operatorname{ord}(b))$. Thus since $|H| = p$, necessarily $H = \mathbb{Z}_p \oplus \{0\} \leq G_{p,q}$. However, if $p = q$, the subgroup $H' = \langle (1,1) \rangle$ has order $p$ but neither $H' = \mathbb{Z}_p \oplus \{0\}$ nor $H' = \{0\} \oplus \mathbb{Z}_p$. What is true, however, is that $H' \simeq \mathbb{Z}_p \simeq \mathbb{Z}_p \oplus \{0\} \leq G_{p,p}$. Thoughts?","['abstract-algebra', 'ring-theory', 'modules']"
2840394,Find the number of natural solutions of $5^x+7^x+11^x=6^x+8^x+9^x$,"Find the number of natural solutions of $5^x+7^x+11^x=6^x+8^x+9^x$ It's easy to see that $x=0$ and $x=1$ are solutions but are these the only one? How do I demonstrate that? I've tried to write them either: $$5^x+7^x+11^x=2^x*3^x+2^{3x}+3^{2x}$$ or $$5^x+7^x+11^x=(5+1)^x+(7+1)^x+(11-2)^x$$ and tried to think of some AM-GM mean inequality or to divide everything by $11^x$, but those don't seem like the way to go. Any hints?","['real-analysis', 'exponential-function', 'calculus', 'functions', 'karamata-inequality']"
2840408,$\int\dfrac{dx}{x^2-a^2}$,"For evaluating $\int \dfrac{dx}{x^2 - a^2}$, how can we make the substitution $x= a\sec \theta $
because $\sec \theta$ can be 1 and then that would give 1/0 form. So how can we do that and why does it work? Why not use $a\tan \theta$? And: $a^2 \sec^2 \theta$ misses the values less than $a^2$. What do we do about that?",['calculus']
2840414,European Call Option - Expectation of Normal CDF,"I'm trying to understand a paper of Sergii Kuchuk-Iatsenko and Yuliya Mishura, Pricing the European Call Option in the Model with Stochastic Volatility Driven by Ornstein-Uhlenbeck Process, Exact Formula, as its has similarity of what I am researching right now. So we know that European call option at $t=0$ is
$$V_0=SN(d_1)+Ke^{-r(T-t)}N(d_2)$$
where
$$d_1=\frac{ln(S/K)+(r+\frac{1}{2}\sigma^2)T}{\sigma\sqrt{T}}$$
$$d_2=d_1-\sigma\sqrt{T}$$
$S$ is price of underlying asset, $N(.)$ is standard normal CDF, $K$ is strike price, $r$ is risk-free rate, and $T$ is time to expiration. In Sergii Kuchuk paper, $N(d_1)$ can be stated into below equation
$$N(d_1)=\frac{1}{2}+\frac{1}{\sqrt{2\pi}}I_{d_1\gt0}\int_{0}^{d_1}e^{-s^2/2}ds-\frac{1}{\sqrt{2\pi}}I_{d_1\lt0}\int_{d_1}^{0}e^{-s^2/2}ds$$
I already understand until this part. Then the paper stated that
$$\mathbf{E}(N(d_1))=\frac{1}{2}+\frac{1}{\sqrt{2\pi}}\int_{0}^{\infty}\mathbf{Q}(S\lt{d_1})e^{-s^2/2}ds-\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{0}\mathbf{Q}(S\gt{d_1})e^{-s^2/2}ds$$
where $\mathbf{Q}$ is probability measure which is equivalent to objective measure $\mathbf{P}$. Which means
$$\mathbf{E}(\frac{1}{\sqrt{2\pi}}I_{d_1\gt0}\int_{0}^{d_1}e^{-s^2/2}ds)=\frac{1}{\sqrt{2\pi}}\int_{0}^{\infty}\mathbf{Q}(S\lt{d_1})e^{-s^2/2}ds$$
I don't have a clue on this part.","['stochastic-processes', 'statistics', 'finance', 'stochastic-calculus']"
2840428,Find expected value of last roll,"Suppose that you play the following game: You roll a fair die at most $N$ times and get an amount of dollars equal to the last number rolled. You can decide to stop the game at any time. What is the (approximate) value of this game for $N=60$? Here is my approach: If you can only roll the die once then the expected value is $3.5\$$. Therefore, if you can only roll the coin twice it makes sense to roll again only if your first roll is $1,2$ or $3$. Thus, the expected value is $\frac{1}{2}(3.5)+\frac{4+5+6}{6}=4.25$. If you have two rolls left, then the expected value of those is $4.25$. Hence, you roll again only if you get 1,2,3 or 4. The expected value is thus $\frac{2}{3}(4.25)+\frac{5+6}{6} \approx 4.67$. Similarly, if you have three rolls left, the expected value is $\frac{2}{3}(4.67)+\frac{5+6}{6} \approx 4.94$. With four rolls left, the expected value is $\frac{2}{3}(4.94)+\frac{5+6}{6} \approx 5.13$. Thus for the first $45$ rolls you stop only if you roll a $6$. It follows that the expected value should be $6(1-(5/6)^{45})+(5/6)^{45}\cdot 5.13 =5.999762..$ Is this correct? Somehow this seems too high. Thanks!",['probability']
2840442,Pick the closest number game,"Suppose three players play the following game: Player 1 picks a number in $[0,1]$. Then player $2$ picks a number in the same range but different from the number player $1$ picked. Player $3$ also picks a number in the same range but different from the previous two. We then pick a random number in $[0,1]$ uniformly randomly. Whoever has a number closer to the random number we picked wins the game. Assume all players play optimally with the goal of maximizing their probability of winning. If one of them has several optimal choices, they pick one of them at random. 1)If Player 1 chooses zero, what is the best choice for player 2? 2)What is the best choice for player 1? I have some trouble seeing how this problem is well-defined. For instance, if Player $1$ picks $0$ and Player $2$ picks 1, then I cannot see what the optimal choice would be for the last player since he has to pick different numbers. Can someone help? EDIT: I now understand better how the problem works, but I still have no idea how to approach this. Can someone give me some hints?","['game-theory', 'probability']"
2840476,Finding a metric to write a vector field as a gradient of a given function,"Let $M$ be a smooth manifold, and $f$ a smooth function with an isolated local minimum at $p$. Furthermore, let $X$ be a vector field vanishing at $p$ such that for some neighborhood $U$ of $p$, $df_q(X_q)<0$ for all $q\in U\setminus\{p\}$. Is it possible to find a Riemannian metric g on $U$ such that $X|_U=-\text{grad}_gf$? If not, what is a counterexample?","['gradient-flows', 'riemannian-geometry', 'differential-geometry', 'vector-analysis']"
2840480,Is probability-raising closed under union?,"Suppose that $\Pr(X \mid A) > \Pr(X)$, and that $\Pr(X \mid B) > \Pr(X)$.  Does it follow that $\Pr(X \mid A \cup B) > \Pr(X)$? $\Pr(X \mid A \cup B) > \Pr(X)$ holds just in case 
$$
[\Pr(X A) - \Pr(X) \cdot \Pr(A)] + [\Pr(XB) - \Pr(X) \cdot \Pr(B)] > \Pr(X A B) - \Pr(X) \cdot \Pr(A B)
$$
($XA$ is the intersection of $X$ and $A$).  Both of the differences on the left-hand-side are positive, so the left-hand-side is positive.  But the difference on the right-hand-side could also be positive, and I don't see why it couldn't be more positive than the sum on the left.  I went looking for simple counterexamples, but couldn't find any.",['probability']
2840491,A conjecture related to a circle intrinsically bound to any triangle,"Given a triangle $ABC$ , whose (one of the) longest side is $AC$ , consider the two circles with centers in $A$ and $C$ passing by $B$ . (The part in italic is edited after clever observations pointed out buy some users: see below for details). EDIT: You may be interested also in this other question Another conjecture about a circle intrinsically bound to any triangle . The two circles determine two points $D$ end $E$ ,  where they intersect the side $AC$ . We draw two additional circles: one with center in $A$ and passing by $D$ , and the other one with center in $C$ and passing by $E$ . The new circles determines two points $F$ and $G$ where they intersect the sides $AB$ and $BC$ , respectively. My conjecture is that the points $BGEDF$ always determine a circle, whose center coincides with the incenter of the triangle. Is there an elementary proof for such conjecture? Since I am not an expert in the field, this can be a very well known theorem. I apologize in that case. Thanks for your help.","['euclidean-geometry', 'triangles', 'geometry']"
2840502,How can I find the general form of an orthogonal matrix?,"I know that the general form of orthogonal matrices is $$\begin{pmatrix} \cos \theta & \sin \theta \\ -\sin \theta & \cos \theta \end{pmatrix}$$ since they are all rotation matrices but how do I prove it? I have done the reverse, i.e., for such a rotation matrix proven that it is orthogonal:
$$\vec r^\prime . \vec r^\prime = \sum_{p=1}^n r_p r_p = \sum_{p=1}^n (\sum_{j=1}^n R_{pj} r_j) (\sum_{k=1}^n R_{pk} r_k) = \sum_{pjk} R_{pj} R_{pk} r_j r_k = \sum_{i} r_i r_i = \vec r . \vec r$$
which is only possible if $\sum_{p} R_{pj} R_{pk}$ = $\delta_{jk}$
which defines an orthogonal matrix. Does just reversing this process work for finding the general form? If not, what's the correct method?","['matrices', 'orthogonal-matrices', 'linear-algebra']"
2840503,Leibniz rule derivation,"How is Leibniz Integral rule derived? $$\frac {\mathrm{d}}{\mathrm{d}x}\left(\int_{a(x)}^{b(x)}f(x, t) \,\mathrm{d}t\right)= f(x,b(x))\frac{\mathrm{d}}{\mathrm{d}x}b(x)- f(x, a(x))\dfrac{\mathrm{d}}{\mathrm{d}x}a(x)+ \displaystyle\int_{a(x)}^{b(x)}\dfrac{\partial f(x,t)}{\partial x} \,\mathrm{d}t.$$ Also, what is the intuition behind this formula?",['calculus']
2840539,bounding a $C^1$ function that upholds $f'(t)\leq 1-f(t)^2$,"Let $f:\mathbb{R}\to\mathbb{R}$ be a function which is continuously differentiable. Suppose that $\forall t\in\mathbb{R}$ it holds 
$$f'(t)\leq 1-f(t)^2$$ Prove that $\forall t\in\mathbb{R}:|f(t)|\leq 1$. I know about some comparison theorems, i.e. if we have a solution (in a compact domain) of the Riccati equation $\dot{x}(t)=1-x(t)^2$, with the same initial value as of $f$, then in this domain we get that $f\leq x$. My problem is that it only gives an upper bound and not a lower bound.",['ordinary-differential-equations']
2840543,"Please Check my proof: $\mathbb{Q}(\sqrt2,\sqrt3) = \mathbb{Q}(\sqrt2 +\sqrt3)$","$\mathbb{Q}(\sqrt2 + \sqrt3) \subset \mathbb{Q}(\sqrt2,\sqrt3)$ is obvious. Now for the converse. Since $p(x) = x^4 - 10x^2 + 1$ has $\sqrt2 + \sqrt3$ as a root, is monic and irreducible in $\mathbb{Q}$, $[\mathbb{Q}(\sqrt2 + \sqrt3) : \mathbb{Q}] = \text{deg}(p(x)) = 4$. However, $[\mathbb{Q}(\sqrt2,\sqrt3) : \mathbb{Q}] = 4$ and since $\mathbb{Q}(\sqrt2 + \sqrt3)$ is a subspace of $\mathbb{Q}(\sqrt2, \sqrt3)$ from the first implication, we must have equality as they have equal dimensions. Is this correct? Thank you for your time.","['abstract-algebra', 'proof-verification']"
2840582,Compactness criterion for operator between reflexive Banach spaces,"I found (without any proof) the following proposition: Let $T \in \mathcal{L}(X,Y)$ be a linear continuous operator between two reflexive Banach spaces $X,Y$, then $T$ is compact if and only if for every sequence $\left(x_n\right)_{n\in\mathbb{N}} \subseteq X$ weakly converging to $0$ and for every sequence $\left(y^*_n\right)_{n\in\mathbb{N}} \subseteq Y^*$ weakly-$*$ converging to $0$ it turns out that $\left< y^*_n,T x_n \right> \to 0$ I already know that: If $X$ is reflexive then $T$ is compact if and only if for every every sequence $\left(x_n\right)_{n\in\mathbb{N}} \subseteq X$ weakly converging to $0$ the sequence $\left(T x_n\right)_{n\in\mathbb{N}}$ converges strongly in $Y$. I tried to prove that given $\left( y_n \right) \subseteq Y$ (with $Y$ reflexive) that converges weakly to $0$ if for every $\left( y^*_n \right) \subseteq Y^*$ that converges weakly-$*$ to zero it turns out that $\left< y^*_n, y_n \right> \to 0$ then $y_n \to 0$ strongly, but without success. So I have a couple of questions: Q1: is my last proposition true? Can we infer strong convergence from the weak one and with this ""dual tests""? Q2: how can I prove the original proposition?","['functional-analysis', 'reflexive-space', 'compact-operators', 'banach-spaces']"
2840594,Gaga and quasicoherent sheaf,"Let $X$ be a complete algebraic variety over $\mathbb{C}$. Ad Serre GAGA stases, its analytification $X^{an}$ is compact and the analytification functor induces an equivalence of categories between $Mod_c(\mathcal{O}_X)$ and $Mod_c(\mathcal{O}_{X^{an}})$. What can we say about quasicoherent modules?","['quasicoherent-sheaves', 'complex-geometry', 'algebraic-geometry']"
2840671,"Nice identity: the norm of the second fundamental form and scalar, Ricci, mean, Gauß curvatures together","Let $M$ be a $3$ -Riemannian manifold and $\Sigma$ an embedded surface in $M$ . Using the Gauß equation, I want to show the following identity on $\Sigma$ : $$R-2\mathrm{Ric}(\nu,\nu)-|A|^2=2K-H^2,$$ where $R$ is the scalar curvature, $\mathrm{Ric}$ is the Ricci tensor, $\nu$ is a unitary vector normal to $\Sigma$ , $A$ is the second fundamental form, $K$ and $H$ are the Gauß and mean curvatures of $\Sigma$ , respectively. This appears for example at the beginning of the proof of Proposition 2, here. Gauß equation: $\langle \overline{\boldsymbol{R}}(X,Y)Z,W\rangle=\langle \boldsymbol{R}(X,Y)Z,W\rangle-\langle A(Y,W),A(X,Z)\rangle+\langle A(X,W),A(Y,Z)\rangle$ , where the bold letters $\overline{\boldsymbol{R}},\boldsymbol{R}$ indicates the curvature tensors of $M$ and $\Sigma$ , respectively. What I have tried: First of all, I was doubtful about the normal vector $\nu$ . Since we don't
know if $\Sigma$ is orientable, it might be that a (unitary differentiable)
normal vector field does not exist on $\Sigma$ . However, looking at the
definitions, we have ( is this really right? ) $R(\nu)=R(-\nu)$ , $\mathrm{Ric}(\nu,\nu)=\mathrm{Ric}(-\nu,-\nu)$ , etc., in such a way that the
identity makes sense, regardless the (non)orientability of $\Sigma$ . Then, with the definitions of $R$ and $\mathrm{Ric}(\nu,\nu)$ , I tried to work on the term $R-2\mathrm{Ric}(\nu,\nu)$ , getting an expression which does not seem to clarify very much... Then came the next doubt: what is the usual norm for $A$ ? There are many equivalent ones, right? Generally, this is not important when we talk about continuity, but in the present case, it seems important because we deal with an equation/identity . I was not able to do much more... Other useful definitions: Given an orthonormal basis $\{x_1,x_2,x_3=\nu\}$ of $T_pM$ , $p\in \Sigma$ , $$\mathrm{Ric}(\nu,\nu)=\frac{1}{2}\big(\langle \overline{\boldsymbol{R}}(\nu,x_1)\nu,x_1\rangle+\langle \overline{\boldsymbol{R}}(\nu,x_2)\nu,x_2\rangle\big)$$ $$R=\frac{1}{3}\sum_{j=1}^3\mathrm{Ric}(x_j,x_j)$$ $$A(X,Y)=\overline{\nabla}_{\overline{X}}\overline{Y}-\nabla_XY.$$","['riemannian-geometry', 'differential-geometry', 'curvature']"
2840683,Deriving the Bending Energy equation for Eulers Elastica,In many (all?) papers regarding elastic curves the bending energy for the elastica is given by $$B[\gamma] = \int_{\gamma} \kappa^2(s)ds$$ where $\gamma$ denotes a planar curve of fixed length and clamped endpoints. Here $s$ denotes the arc length of the curve and $\kappa$ is the (signed) curvature. I want to know where this equation comes from and how it is derived. Here is one of the papers I am reading: https://arxiv.org/pdf/1710.05890.pdf In all of the material I have found the above bending energy is given as a definition and no motivation for it is given. Any help is greatly appreciated.,"['differential-geometry', 'plane-curves']"
2840685,Application of Borel Cantelli Lemma 1,"$\textbf{Problem} $ Let $m$ be the Lebesgue measure on $\mathbb{R}$. Let $f_n: \mathbb{R} \rightarrow [0,\infty)$ be sequence of Lebesgue measurable functions. Show that there is a sequence $c_n$ of positive numbers such that 
  \begin{align*}
\sum_{n=1}^\infty \frac{f_n(x)}{c_n} \quad \textrm{converges m-a.e. x.}
\end{align*}
  (Hint. For a measurable function $f : X \rightarrow [0,\infty)$, for any sequence $a_m \downarrow 0$, and for any $\epsilon>0$, let $A_m:=\{x:a_mf(x)>\epsilon\}$. Then $\cap_m A_m=\emptyset$.) My attempt: Take $A_n= \{x: \frac{f_n(x)}{c_n}>1/2^n\}$ . By hint, $\cap_n A_n=\emptyset$. However, we don't know $A_n$ be deceasing sequence of subset.. Any help is appreciated.... Thank you!","['borel-cantelli-lemmas', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2840756,"prove $\int_0^a\sin x\, dx + \int_0^b \arcsin x\, dx \geq ab$","I want to prove that for $$ 0\lt a \lt {\frac \pi 2}\\\\ 0\lt b \lt 1$$ then $$\int_0^a \sin x\, dx + \int_0^b \arcsin x\, dx \geq ab$$ Thinking about these integrals geometric-wise, i thought that the integral on $\sin x$ is the area bounded between $y=0$ and $\sin x$ on the interval $[0,a]$, and the integral on $\arcsin x$ on the interval $[0,b]$ is in fact the area that completes the previous area to a rectangle, but in that case - i would get that 
$$\int_0^a \sin x\, dx + \int_0^b \arcsin x\, dx = ab$$ what do i miss here?","['definite-integrals', 'trigonometry', 'calculus']"
2840794,What is dimension over $\mathbb R$ of the space of $n\times n$ Hermitian matrices? [duplicate],"This question already has answers here : What is a basis for the space of $n\times n$ Hermitian matrices? (3 answers) Closed 3 years ago . what is dimension over $\mathbb{R}$ of $H_n( \mathbb{C})$ , the set of $n \times n$ Hermitian matrices? My attempt: every real number is a complex number as  all symmetric matrices  are  Hermitian. In my view the dimension of $H_n( \mathbb{C})$ is $\frac{n(n+1)}{2}$","['matrices', 'hermitian-matrices', 'linear-algebra']"
2840848,$\int_{0}^{2008}x|\sin\pi x| dx$,"Evaluate: $$\int_{0}^{2008}x|\sin\pi x| dx$$ That modulus sign is causing problems. How do I handle it?
I am trying integration by parts I have even evaluated: $\int_0^1 {|\sin \pi x|}= \frac 2 \pi$. Not sure how to utilise it in the problem. I just need help with the modulus part.",['calculus']
2840872,Is this proof that $100!$ is not divisible by $101$ correct?,"Is it enough to say that because $101$ is a prime number and $100!$ consists of numbers, and each of these numbers is composed of prime numbers which are less than $101$, and every number can't be decomposed in two different ways such that product of different primes is equal to another product of second group of a different primes, therefore $100!$ is not divisible by $101$? Is this enough as a proof?","['number-theory', 'elementary-number-theory']"
