question_id,title,body,tags
1478388,Finding the derivative for a product of two polynomial functions?,"In my problem, I am attempting to find $f'(x)$ when $f(x)=(5x^2-2x+8)(4x^2+7x-3)$. For my work I have: \begin{align}
& \frac{d}{dx} (uv) = u\frac {dv}{dx} + v\frac {du}{dx} \\[8pt]
= {} & (5x^2-2x+8)(8x+7)+(4x^2+7x-3)(10x-2) \\[8pt]
= {} & 40x^3+35x^2-16x^2-14x+64x+56+40x^3-16x^2+70x^2-14x-30x+6 \\[8pt]
= {} & 80x^3 + 73x^2+6x+62
\end{align} But when I plugged my original equation [$f(x)=(5x^2-2x+8)(4x^2+7x-3)$] into an online derivative calculator to check my answer, it comes out as: $$=80x^3+81x^2+6x+62\ldots\text{ ?}$$ Can anyone spot where I am going wrong (if I am)?","['graphing-functions', 'calculus', 'algebra-precalculus']"
1478391,Torsion and curvature of a curve,"A regular curve $\textbf{$\gamma$}$ in $\mathbb{R}^3$ with curvature $> 0$ is called a generalized helix if its tangent vector makes a fixed angle $\theta$ with a fixed unit vector $\textbf{a}$. Show that the torsion $\tau$ and curvature $\kappa$ of $\textbf{$\gamma$}$ are related by $\tau = ±\kappa \cot \theta$. Show conversely that, if the torsion and curvature of a regular curve are related by $\tau = \lambda \kappa$ where $\lambda$ is a constant, then the curve is a generalized helix. $$$$ I have done the following: $\textbf{a}$ is a fixed unit vector: $||\textbf{a}||=1$ and since it is fixed we have that $\textbf{a}'=0$. $$\textbf{a} \cdot \textbf{t}=||\textbf{a}|| ||\textbf{t}|| \cos \theta = ||\textbf{t}|| \cos \theta \\ \Rightarrow (\textbf{a} \cdot \textbf{t})'=0 \Rightarrow \textbf{a}' \cdot \textbf{t}+\textbf{a} \cdot \textbf{t}'=0 \Rightarrow \textbf{a} \cdot \kappa \textbf{n}=0 \overset{ \kappa >0 }{ \Rightarrow } \textbf{a} \cdot  \textbf{n}=0 \Rightarrow \textbf{a} \bot \textbf{n}$$ $\textbf{t}$, $\textbf{n}$ and $\textbf{b}$ consists an orthonormal basis of $\mathbb{R}^3$. So, $$\textbf{a}=A \textbf{t}+ B \textbf{n}+ C\textbf{b}$$ We have that $\textbf{a}$ is on the plane spanned by $\textbf{t}$ and $\textbf{b}$. So, $B=0$. Therefore, $$\textbf{a}=A \textbf{t}+C\textbf{b}$$ How could we continue?","['differential-geometry', 'curves', 'curvature']"
1478409,"Finding $\sum_{i = 1}^{n} \frac{n} { \gcd(i, n)}$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I am trying to solve this problem, the most important part of this problem is to find
?$$\sum_{i = 1}^{n} \frac{n}{\gcd(i, n)}$$ Where $n$ could be $10^{12}$","['summation', 'number-theory', 'gcd-and-lcm']"
1478433,Series of the totient function,"Good morning, I wonder if : $$\sum_{n} \frac{(-1)^n}{\varphi (n)}$$ converges or not. where $\varphi (n)$ is the Euler function. Do you have any idea ?","['multiplicative-function', 'number-theory', 'analytic-number-theory']"
1478456,Calculating $P(X+Y=0)$ for independent random variables (Problem in Durrett),"Exercise 2.1.8 in Durrett's Probability: Theory and Examples is the following: Show that if $X$ and $Y$ are independent with distributions $\mu$ and
  $\nu$, then $$P(X+Y=0) = \sum_y \mu(\{-y\})\nu(\{y\}).$$ If I define $h(x,y) = \chi_{x=-y}$, then using Fubini and the change of variables formula, I get $$P(X+Y=0) = Eh(X,Y) = \int_{\mathbb{R}^2} h\,d(\mu\times \nu) = \int_{-\infty}^\infty \int_{-\infty}^\infty h(x,y)\,\mu(dx)\nu(dy)=\int_{-\infty}^\infty \mu(\{-y\})\,\nu(dy).$$ How do I get to the final sum form? What bothers me here is that the sum in the problem description seems to be over an uncountable set, so is this again an example of Durrett using strange notation that is not defined anywhere in the book and the integral that I've computed above means the same?",['probability-theory']
1478460,Linear autonomous systems in the plane: When do phase curves rotate clockwise?,"For a linear autonomous system in the plane
$$ \mathbf{\dot{x}} = \begin{pmatrix} a & b\\ c & d \end{pmatrix}\mathbf{x} \qquad (a,b,c,d \in \mathbb{R})$$
with determinant $D = ad - bc$ and trace $T = a + d$ we have the characteristic polynomial
$$ \chi(\lambda) = \lambda^2 - T\lambda + D$$
and the eigenvalues
$$ \lambda_{1, 2} = \frac{T \pm \sqrt{\Delta}}{2}, \qquad \Delta = T^2 - 4D $$
We know that the phase curves will rotate around the origin iff $\Delta < 0$. Question: How can one determine using $a, b, c, d$ , whether the phase curves turn clockwise or counter-clockwise? Counterexample: The System
$$ \mathbf{\dot{x}} = \begin{pmatrix} 1 & s\\ -s & 1 \end{pmatrix}\mathbf{x} \qquad (s \in \mathbb{R} \setminus \{ 0 \})$$
will rotate clockwise for $s > 0$ and counter-clockwise for $s<0$, but in both cases we have
$$ D = 1 + s^2 > 0, \qquad T = 2, \qquad \Delta = -4s^2 < 0 $$
so these quantities will not suffice to determine the orientation.",['ordinary-differential-equations']
1478469,"Double Integral $\int\limits_0^1\!\!\int\limits_0^1\frac{(xy)^s}{\sqrt{-\log(xy)}}\,dx\,dy$","Is it possible to get a closed form of the following integral?
$$I=\int_0^1\!\!\!\int_0^1\frac{(xy)^s}{\sqrt{-\log(xy)}}\,dx\,dy\quad\quad\quad(s>0).$$ My attempt :  I’ve tried a change of variables from cartesian coordinates to polar coordinates:
$$\begin{align}x&=r \cos (\theta)\\y&=r \sin (\theta).\end{align}
$$ I’ve computed the jacobian:$$
J=\left|\frac{D(x,y)}{D(r,\theta)}\right|=|\cos (\theta) r \cos (\theta)-(-r \sin (\theta)) \sin (\theta)|=r.$$ From here I'm stuck.","['definite-integrals', 'bounds-of-integration', 'multiple-integral', 'integration', 'multivariable-calculus']"
1478487,"Sets with same Cardinality, but no Explicit Bijection?","Are there any good examples of sets where we know that they have the same cardinality, but have not found any explicit bijection between them?","['elementary-set-theory', 'soft-question', 'cardinals']"
1478542,Measurable functions in a countable co-countable $\sigma$-algebra,"I found a interesting problem that says: Let $(X,S)$ be a measurable space where $X=\mathbb R$ and $S$ is the countable co-countable $\sigma$-algebra in $\mathbb R$, i.e. $S=\{A\subset\mathbb R: A\ \lor\ \mathbb R-A\ \ is\ finite\ or\ countable\}$. So the point is to describe the S-measurable functions $\ f:X\to \Bbb R^*$, where $\Bbb R^*$ are the extended real numbers.",['measure-theory']
1478544,Basis one-form and basis vector confusion,"Still trying to teach myself some basic differential geometry in relation to general relativity. I've read that, in relation to basis vectors $e_{\nu}=\partial_{\nu}$ and basis one-forms $\omega^{\mu}=dx^{\mu}$,
  then $$e_{\nu}\omega^{\mu}=\partial_{\nu}dx^{\mu}=\frac{\partial x^{\mu}}{\partial x^{\nu}}=\delta_{\nu}^{\mu}.$$
 Fair enough, but why does the partial derivative operator $\partial_{\nu}$
  (which I thought meant $\frac{\partial}{\partial x^{\nu}}$
 , where the slot is for an arbitrary function) when applied to $dx^{\mu}$
  give $\frac{\partial x^{\mu}}{\partial x^{\nu}}$
  and not $\frac{\partial\left(dx^{\mu}\right)}{\partial x^{\nu}}$? Or does $\frac{\partial x^{\mu}}{\partial x^{\nu}}=\frac{\partial\left(dx^{\mu}\right)}{\partial x^{\nu}}$? But if that's the case what does $\partial_{\nu}x^{\mu}$ give? It can't also be correct that $$\partial_{\nu}x^{\mu}=\frac{\partial x^{\mu}}{\partial x^{\nu}}=\delta_{\nu}^{\mu},$$
 but I can't see why not. I'm confused. Thanks.",['differential-geometry']
1478599,Ideals of $\mathbb{Z}[i]$ geometrically,"It is pretty easy to visualize the ideals of $\mathbb{Z}$ in the ""integer line"". Let's go up to $\mathbb{Z}[i]$ and consider the ideal $3\cdot\mathbb{Z}[i]$. We can visualize it as a ""sub-lattice"" of the gaussian integers that contains the vertex $0+0i$ and has edges of lenght 3. This is because \begin{equation}
3\cdot\mathbb{Z}[i]=\{(3a)+(3b)i)\:|\:a,b\in\mathbb{Z}\}
\end{equation} and so this is kind of obvious and intuitive. What about, for example, the ideal $(2+i)\cdot\mathbb{Z}[i]$? We can see a copy of $5\cdot\mathbb{Z}$ inside it and also the elements of $\mathbb{Z}[i]$ lying over the line $y=\frac{1}{2}x$. Are there any others points I am missing? I think that yes, but I'm not sure how to find those. Every element of $(2+i)\cdot\mathbb{Z}[i]$ is of the form $(2a+b)+(a+2b)i$, but is not clear to me which geometric figure we get from this. I'd appreciate if someone could explain it to me. Thank you in advance. Also, a small extra question: Is there any online website where I can draw things in the plane described by 2 parameters? That would answer my question, even though an algebraic explanation would be great.","['ring-theory', 'ideals', 'integer-lattices', 'abstract-algebra', 'algebraic-number-theory']"
1478646,Is the orientation double cover unique?,"My question comes from the following. We usually say ""the universal cover"" because, as we know, it is unique up to isomorphism on the adequate category (in particular, every universal cover is homeomorphic to each other). I never dwelled in thinking about the orientation double cover. I just read its construction and knew that, if a manifold is orientable, the construction would yield two copies of the manifold. If it is not orientable, it will yield a connected orientable manifold. And unconsciously I absorbed the fact that it should be ""unique"". But it seems like it isn't the case. For instance, take $\mathbb{R}P^3$. It is orientable and, as such, its orientation double cover should be two disjoint $\mathbb{R}P^3$. But $S^3$, through the projection, is also a double cover, and orientable, and obviously $S^3$ is not homeomorphic to two disjoint $\mathbb{R} P^3$. Therefore, I have these questions: 1) Am I getting something wrong? (For instance, is my implicit definition of orientation double cover as a two-fold orientable cover wrong?)
EDIT: Thanks @GrumpyParsnip for telling me that my definition is wrong. Based on the answers, I think I didn't get my intention with this question clear. Now that my definition is ""wrong"", I'll ask: Why defining it the way it is? What makes this special cover... special? Why not allow any two-fold orientable cover to be a orientation double cover? 2) Does this issue not happen when the base manifold is non-orientable?","['algebraic-topology', 'general-topology']"
1478647,limsup of a sequence vs limsup of a subsequence,"Let $X$ be a set and let $(E_n)$ be a sequence of subsets of $X$. The $\limsup E_n$ is defined as follows:  $$\limsup E_n = \bigcap^{\infty}_{m=1} \bigcup^{\infty}_{n=m} E_n .$$ Suppose $(E_{n_k})$ is a subsequence of $(E_n)$. Will $\limsup E_{n_k}$ differ from $\limsup E_n$ by a zero set or something larger? I believe their difference is probably a zero set, but how to actually check this? EDIT: the claim is wrong in general, but would it be correct if we add Cauchy condition ? Thanks!","['elementary-set-theory', 'real-analysis', 'limsup-and-liminf']"
1478671,Stokes' Theorem and Vector Fields with Jump Discontinuities,"What are the continuity requirements on a vector field $\boldsymbol{A}$ such that Stokes' theorem, $$
\iint_S\nabla\times\left[(\boldsymbol{\hat{x}}\cdot\nabla\phi)\boldsymbol{A}\right]\cdot d\boldsymbol{s} = \oint_C \left(\boldsymbol{\hat{x}}\cdot\nabla\phi\right)\boldsymbol{A}\cdot d\boldsymbol{l},
$$ holds? Here $\boldsymbol{\hat{x}}$ is a constant vector, $\phi$ is a smooth function (1) over all of $\mathbb{R}^3$, $S\subset\mathbb{R}^3$ is a bounded, connected and open set with boundary $C$. More specifically, can it suffer a jump discontinuity on $C$? To put this into context (2), there is an article that supposes that the vector field must be continuous on $S$ and across $C$. Since $\boldsymbol{A}$ suffers a jump discontinuity on $C$, Stokes' theorem fails. This is used to argue that some integral representation of electromagnetic fields fail. On the other hand, I have this article saying that even if $\boldsymbol{A}$ is discontinuous across $C$, Stokes' theorem still holds, citing the work of Whitney (3, p.100). (1): It can be singular at isolated points on $S$, but for our purposes it can be considered smooth. (2): I can provide PDFs via email, see my bio. (3): H. Whitney, Geometric Integration Theory, Princeton University Press: Princeton, 1957. Update : This first article seems to say that the divergence theorem (not Stokes' theorem, but I suppose the arguments would be the same as for the divergence theorem) holds if the vector field is discontinuous in a set $Z$, contained in $S+C$, that is of logarithmic capacity zero. The way I understand it, this seems to preclude a jump discontinuity on $C$. This second article , however, includes an additional term due to the discontinuity at $C$. Is that second article right? Would that carry over to Stokes' theorem?","['stokes-theorem', 'physics', 'vector-analysis', 'integration']"
1478714,Proving a bound with binomial coefficients,I'm trying to prove the inequality below: $$ \frac{\sum^{n/2 + \sqrt{n}}_{j=0} {n \choose j}}{2^n} \geq 0.95 $$ I have no idea where to start. I have tried to fill in the formula for small values of n and I see that it holds but I'm unable to proof this. Can anyone give a hint on how to prove this? Any help would be greatly appreciated.,"['probability', 'binomial-coefficients', 'inequality']"
1478742,Interpreting the results of a Lagrange multiplier problem,"I was looking for example problems online and came across this problem: a) Use Lagrange multipliers to find the absolute min and absolute max
  values of $f(x,y)=x^2+4y^2$ subject to the constraint $y=x^2-2$, if
  they exist b) Sketch the level set diagram of $f(x,y)=x^2+4y^2$ and the constant
  curve $y=x^2-2$. Where are the candidate points that the Lagrange
  multipliers finds? Solution: For a) I get the points $\displaystyle{P=\left(\pm\sqrt{\frac{15}{8}},\frac{-1}{8}\right)}$. I can't real say if they are max or min points the function gives the same value at both points. I know the graph is a paraboloid and was trying to think of the constant curve projected onto the graph. I also tried plugging the constraint into the function and running optimization in one variable. The result is all critical values are complex. How can we confirm if they are max, min or neither? Part b) is easy enough to plot and think about level curves being tangent to the constraint curve. Here is a contour plot","['lagrange-multiplier', 'calculus', 'multivariable-calculus']"
1478774,Discontinuous bilinear form separately continuous,Do you have an example of a real normed space $V$ and a bilinear form $B : V \times V \to \mathbb R$ that is discontinuous but such that $B$ is separately continuous for each variable? $V$ has to be not complete in order to not conflict Banach-Steinhaus theorem.,"['bilinear-form', 'functional-analysis', 'normed-spaces']"
1478785,Ellipse Perimeter,"I've seen lots of methods of getting an approximation of the perimeter of an ellipse, however, I was wondering if there is an exact method that exists, no matter how complex.","['calculus', 'conic-sections']"
1478841,"What is the connection between outer product, quadratic form and definiteness?","In proving whether a function is convex or concave, I frequently encounter people who ends their analysis on something the sort: Since $\nabla^2 f(x,y) = \begin{bmatrix} a^2 & b a\\ ab & b^2
 \end{bmatrix}$ is an outer product of $\begin{bmatrix} a & b
 \end{bmatrix}$ therefore $f(x,y)$ is convex Can someone clarify what is this so special about outer product that we can make quick statements such as this? Is it true that every single hessian that can be expressed as an outer product is positive semidefinite?","['optimization', 'linear-algebra', 'multivariable-calculus', 'matrices']"
1478865,Exact sequence splits?,"I am stuck in the following problem: Show that every group of order 4 is an extension of $\mathbb{Z}_{2}$ by $\mathbb{Z}_{2}$. Which of the exact sequences splits? Ok, i have to consider two cases for a group of order 4: $\mathbb{Z}_{4}$ and $\mathbb{Z}_{2}\times \mathbb{Z}_{2}$, so i get two exact sequences: $0\rightarrow \mathbb{Z}_{2}\overset{\psi }{\rightarrow}\mathbb{Z}_{4}\overset{\varphi }{\rightarrow}\mathbb{Z}_{2}\rightarrow 0$  and $0\rightarrow \mathbb{Z}_{2}\overset{\tilde{\psi} }{\rightarrow}\mathbb{Z}_{2}\times \mathbb{Z}_{2}\overset{\tilde{\varphi} }{\rightarrow}\mathbb{Z}_{2}\rightarrow 0$ For both cases i checked the conditions of exact sequence and proved that these are exact sequences. Now i have a problem how to show if they split or not. 
We say that an exact sequence splits if for the first sequence there exists a group homomorphism $\pi :\mathbb{Z}_{2}\rightarrow \mathbb{Z}_{4}$ with $\varphi \circ \pi =id_{\mathbb{Z}_{2}}$ and for the second $\tilde{\varphi} \circ \tilde{\pi} =id_{\mathbb{Z}_{2}}$, right? But how to show if these group homomorphisms exist or not? Can anybody help me, please? I would appreciate any hints and comments.
Thank you in advance!","['exact-sequence', 'abstract-algebra', 'group-theory']"
1478876,Underdog leading at least once in an infinite series of games,"We are observing a tournament where 2 players play a series of games. Exactly one player wins each game. So we can keep count and 5:3 might be the standing after 8 games. The first player is the favorite and will win a game with probability $p > 1 - p$. What is the probability that the underdog will lead the standing at least once at some point in an infinite series of games? Or maybe more important than the specific value: Is it $1$ or not? Somehow I think that it should be $1$, independent of $p$, but I am not sure how much my intuition is worth here. Maybe I can take it to the infinite case with a hint about finite series of $k$ games.","['sequences-and-series', 'probability', 'binomial-distribution']"
1478889,Show $(A \cup B)\setminus(A \cap B) = (A\setminus B) \cup (B\setminus A)$,Show $(A \cup B)\setminus(A \cap B) = (A\setminus B) \cup (B\setminus A)$. What I have so far... This is (A or B) and (A and B)' = (A and B') or (B and A') (A or B) and (A' or B') = (A and B') or (B and A') ((A or B) and A') or ((A or B) and B') = (A and B') or (B and A') I feel like I'm just getting farther away. There must be something simple I'm missing.,"['elementary-set-theory', 'discrete-mathematics']"
1478911,Is a bijective projection function measure preserving?,"A subspace with dimension strictly less than the dimension of vector space has (Lebesgue) $measure=0$. Let $V$ be a vector space with $dimension=n$. To show that some set $S$ in V is zero-measure, is it enough to show the existence of bijective projection between $S$ and a subset of a subspace of $V$ with $dimension < n$?","['lebesgue-measure', 'geometric-measure-theory', 'descriptive-set-theory', 'measure-theory']"
1478990,Number Theory: Chinese Remainder Theorem $x^2\equiv x\pmod{180}$,"How can I use the Chinese Remainder Theorem to solve these two problems: $x^2\equiv x\pmod{180}$ and $x^2\equiv 1\pmod{140}$. I was able to solve similar problems without using the Chinese Remainder Theorem, but I was wondering how to do these problems with the remainder theorem. Thanks!","['congruences', 'number-theory', 'modular-arithmetic', 'elementary-number-theory', 'chinese-remainder-theorem']"
1478996,Square root of two,How would you find root 2? I have been told to use a number line. I have tried to visualize it on a number line using triangles. But am unsure of where to go from there.,"['radicals', 'geometry']"
1479001,Show if $f\colon A\to B$ is surjective and $H\subseteq B$ then $f(f^{-1}(H))=H$,I'm supposed to show that if $f\colon A\to B$ is surjective and $H\subseteq B$ then $f(f^{-1}(H))=H$. I have managed to show that $f(f^{-1}(H))\subseteq H$ but I am really struggling to show that $H\subseteq f(f^{-1}(H)$. Is it easier to prove this dealing with sets or an element of a set?,"['elementary-set-theory', 'functions']"
1479013,How to use the Lagrange Multipliers to find the min and max of this function?,"So I have the function $$f(x,y)=x^2+y^2$$ with constraint $$(x-1)^2+4y^2=4$$ How can I find the minimum and maximum values for this using Lagrange multipliers? My attempt:
I got the equations: 1) $$2x = λ(2x-2)$$
2) $$2y = λ8y$$
3) $$(x-1)^2+4y^2=4$$ I solved for x and y with no luck. Cant seem to find the min and max. Any help is appreciated","['optimization', 'lagrange-multiplier', 'multivariable-calculus']"
1479021,What is the significance of operating on random variables. Like finding E[x^2 + 3],I had read the wiki page about moments. But still unable to get the real life significance. https://en.wikipedia.org/wiki/Moment_(mathematics) It also says the second moment of the distribution is the variance. Does it mean E[x^2] is the variance ?? I also know variance is E[x^2]-(E[x])^2. I am lost. Any input will help. Thanks.,"['probability', 'statistics', 'probability-distributions', 'moment-generating-functions']"
1479022,Can two points be added?,"Can two points be added? The reason I ask is because when I think about it all I see is vector addition. I understand the difference between vectors and points. I know we used to talk about points on the number line as a kid, and we added numbers, but I can't assume equivalency. It also feels strange to say ""if I add this location with this other location I get a new location."" What is the answer, and what is the root of my confusion?","['geometry', 'binary-operations']"
1479095,$E \subset \{ x | f \text{ is differentiable at }x\}$. Then $|E|=0 \Rightarrow |f(E)|=0$.,"For $f:[0,1]\to \mathbb{R}$ let $E\subset\left\{x \mid f'(x) \text{exists}\right\}$. Prove that if $|E|=0$, then $|f(E)|=0$. My attempt: Let $E_{nk}=\left\{x\in [0,1]|\frac{|f(x+h)-f(x)|}{h}\leq n, |h|< \frac{1}{k} \right\}$. I am not sure where to go from here, but  I think that $E\subset \bigcup E_{nk}$, but I am not sure. Any hints? Thank you.","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1479114,Some questions about open and closed maps,"Let $f:\mathbb{R}^2\rightarrow\mathbb{R}$ be a map as follows: 1.$f(x,y)=x+y$ is an open map or a closed map? 2.$f(x,y)=x^2-y^2$ is an open map or a closed map? 3.$f(x,y)=x^2+xy+y^2$ is an open map or a closed map? 4.$f(x,y)=(x+y)^2$ is an open map or a closed map? 5.$f(x,y)=x^3+y^3$ is an open map or a closed map? 6.$f(x,y)=x^3+y$ is an open map or a closed map? 7.$f(x,y)=x^5+y^2$ is an open map or a closed map? Is there any (effective) necessary and sufficient condition to testify that a map is a closed map? Thanks a lot.",['general-topology']
1479126,"Prove that the four-group $\{1,a,b,c \}$ is not cyclic.","I just want to make sure I have the right idea here. The Statement of the Problem: Prove that the four-group $\{1,a,b,c \}$ is not cyclic. My Answer: As far as I can tell, this is the Klein four-group and I just need to check the subgroups generated by each element. If any of them is the entire group, then it is cyclic; otherwise, it is not cyclic. Well: \begin{align}\langle1\rangle &= \{ 1 \} \\ \langle a\rangle  &= \{ 1, a \} \\ \langle b\rangle &= \{ 1,b \} \\ \langle c\rangle &= \{ 1, c \}\end{align} Obviously, none of these are equal to $\{1,a,b,c \}$ , therefore the group is not cyclic. Is that it?","['solution-verification', 'abstract-algebra', 'group-theory', 'finite-groups', 'cyclic-groups']"
1479127,Basic neighborhoods in weak topology,"I am trying to visualize the basic neighborhoods of the form $V(x_0;\varepsilon,f_1,...,f_n) = \bigcap_{j=1}^n \{ x \in E : |f_j(x-x_0)|<\varepsilon \}$ where $x_0 \in E$, $\varepsilon>0$ and $f_1,...,f_n \in E'$ on the weak topology of a normed infinite-dimensional vector space $E$. I had imagined some way ""to see"" these neighborhoods like open stripes bounded in a ""finite number of directions"", just like the vertical open stripes are the standard visualization of the basic neighborhoods in the product topology on a infinite product of topological spaces. In this sense can I say that these basic neighborhoods are rotated stripes?","['analysis', 'functional-analysis', 'topological-vector-spaces']"
1479136,Variance of Expected Value,"Given a random variable $x$, what is $Var(E[x])$? My intuition is that it would simply be the same as $Var(x)$, but I'm not sure how to prove that. Any and all help would be greatly appreciated!","['probability', 'statistics']"
1479139,fiber products of curves,"Let $X,Y,Z$ be three nonsingular curves over a field $k$ (not necessarily proper, ie, possibly affine). Let $f : X\rightarrow Z$ and $g : Y\rightarrow Z$ be finite morphisms. We know the fiber product $X\times_k Y$ is a nonsingular surface. The projection maps from $X\times_Z Y$ to $X$ and $Y$ induce a map $X\times_Z Y\rightarrow X\times_k Y$, which basically realizes it as the subset $\{(x,y) : f(x) = g(y)\}$. Can someone explain to me, being as detailed and rigorous as possible, ideally using the language of schemes, why the point $(x,y)$ of $X\times_Z Y$ is singular if and only if $f$ is ramified at $x$ and $g$ is ramified at $y$? I would appreciate some geometric intuition as well. I can ""sort of"" see it, but I feel like I'm missing the language. For example, what would the local ring look like? What kind of singularity is it?",['algebraic-geometry']
1479167,Proving $\rm \frac i 2 \ln\frac {x+i}{x-i}=\arctan x$ .,"Proving $$\rm \frac i 2 \ln\frac {x+i}{x-i}  =\arctan x$$ I'd like to prove this identity without taking the derivatives and integrating, what are some cool ways to prove this?","['logarithms', 'complex-numbers', 'trigonometry']"
1479267,How many six digit numbers start with the same two digits and end with the same three digits?,"Say that there is a 6 digit number 
the first digit is not allowed to be 0 or 1 so How many number combinations start with the same two digits and end with the same three digits ie.119333, 448222, 889888 etc.. My thoughts are 8_ 1_ 10_ 10_ 1_ 1_ = 8*10*10=800? and how would I do it if instead of the and it said Or? first of all, I'm I on the correct path here?
any other examples similar would help.","['combinations', 'big-list', 'discrete-mathematics']"
1479284,Is $f(x)=\frac{|x|^2}{x}$ continuous?,"$$f(x) =
\begin{cases}
\frac{|x|^2}{x},  & \text{if $x \neq 0$} \\
0, & \text{if $x=0$}
\end{cases}$$ Can someone please explain if f is continuous? Assume $x$ is a complex number Hints would do Thanks in advance!","['calculus', 'continuity', 'real-analysis', 'functions', 'complex-analysis']"
1479287,Power set of a set with three elements,"I need help with the set operation. for example I got
$$A=\{0,1,2\}$$
and * the question is asking how many elements in the power set are proper
  subsets of A? * my answer is zero because there's no proper subset of itself. Am I right? and what do they mean by how many elements in the power set are nonempty subsets of A? ****please explain... thank you :)",['elementary-set-theory']
1479316,"Show that Cov(X,Y)=Cov(X,E(Y|X)).","Let X, Y be independent random variables.  I've been working on this for a while and I think this question just requires skillful manipulation of the expectations E(X) and E(Y|X).  At one point I got that Cov(X,Y) is 0... which is incorrect.  Since then I have started over and here's what I have: Cov(X, E(Y|X))=E((X-E(X)(E(Y|X)-E(E(Y|X)))
=E(X E(Y|X))-X E(E(Y|X))-E(X)E(Y|X)+E(X) E(E(Y|X))
=E(E(XY|X))-E(E(XY|X)) And I'm not so sure what to do from there.  Did I just make things more complicated?","['probability-theory', 'probability', 'statistics']"
1479337,is an empty set an element of {empty set},"I am on set section right now and I have questions about empty set is an empty set an element of {empty set}?
is an empty set a subset of {empty set}?
is an empty set a proper subset of {empty set}? I am just wondering because on the textbook didn't mention about these three? please bear with me I am really doubt a lot of things. I got the questions online and I am practicing it right now so please correct me if I am wrong. 
  a) {empty set} is an element of {empty set} = false 
  b) {empty set} is a subset of {empty set} = false 
  c) empty set is an element of {empty set,{empty set}}= true 
  d) {empty set} is an element of {{empty set}} = true 
  e) {{empty set}}is a proper subset of {empty set,{empty set}} = false I hope I get em all right after you explained to me. thank you :)","['elementary-set-theory', 'discrete-mathematics']"
1479342,Laws of logic Assertion/Reason format,"I am taking a Discrete Math class and we have this question. $(B-A) \cup (C-A) = (B \cup C) -A$ Our section notes barely gloss over this, and Discrete Mathematics and Its Application, 7th Edition by Kenneth Rosen, glosses over it also. I would just like some guidance on how to solve this. My course notes , page 104, example 1.11.2 has an example but not much else.","['elementary-set-theory', 'discrete-mathematics']"
1479347,Defining differentiability on a topological manifold,I am currently watching a series of lectures which are a part of International Winter School on Gravity and Light 2015 (by Prof. Frederick P. Schuller). In one of the lectures on differentiable manifolds he asks- Is the structure of a topological manifold enought to talk about differentiability of curves on the manifold?Can you construct from it a notion of differentiability? And he answers in the negative saying that the structure of a topological manifold is not good enough to define a notion of differentiability. Why is this true? What is missing in the structure of a topological manifold that is preventing us from defining differentiability on it? Here is the video lecture link. Go to 01:43,"['differential-topology', 'differential-geometry', 'manifolds']"
1479359,Discrete Math: Finding the inverse of (natural) modulo (natural),"Basically the style of the question is like this: Find the inverse of $24$, modulo $35$. The answer I get is $-16$ whereas wolframalpha gets 19. I know that $35 - 16 = 19$. The question isn't necessarily how I find the inverse- but rather (since my exam is tomorrow)- how do I know when to convert a negative inverse into a positive one? And do I always use the rule of adding the negative to the larger number to get the desired inverse? I ask mainly because I thought I've been getting the wrong inverses but its just that my book's answer key converts the negative to a positive inverse. However I don't recall my professor ever mentioning anything of this so I'm not sure what answer I should put on my exam tomorrow- and I don't know if context matters (is it okay to put down the inverse even if its negative sometimes). TLDR; If the extended Euclidean Algorithm gives a negative inverse: How do I know what answer my instructor or someone else is looking for? Thanks.","['number-theory', 'modular-arithmetic', 'discrete-mathematics']"
1479392,Upper bound on expectation of n non independent random variables,"Given $X_i$ are (not necessarily independent) and $\max_{j \leq n} (E|X_j|^p)^{1/p} = \sigma_p < \infty$, $p>1$ Prove that : $E\ \max_{j \leq n} |X_j| \leq n^{1/p} \sigma_p$ Approach: $$
E\ \max|X_i| \leq E\ \max|X_i|^P \leq \sum_{j \leq n} E|X_j|^p \leq n\ \max E|X_j|^p = n\sigma_p^p
$$","['probability-theory', 'order-statistics', 'expectation', 'probability', 'inequality']"
1479410,"If the probability of a single point of a continuous distribution is zero, why can I obtain density values from the normal?","I was hoping to clarify a possibly wrong notion I have. I understand that for a continuous distribution, say the normal, the probability of a single point, say 0, has zero probability. However, if I plug into the standard normal density, I get 0.3989423 in R. Does anyone know what part I am missing here? Thanks.","['probability', 'statistics']"
1479429,"Can ""Taxicab geometry"" be given a Hilbert-style axiomatization?","Hilbert's axioms provide a synthetic system for Euclidean geometry. Is it possible to do the same thing for the Taxicab plane? It would seem that one would only need to alter the axioms for congruence, since all the other properties are the same as in the Euclidean plane, and the congruence axioms are the ones that determine the metric properties of the plane. If so, how? Note that if we remove SAS and leave all the other axioms in place, Taxicab geometry becomes a model of the Hilbert axioms, but can we add some more axioms in place of it that make it the unique model? If so, which ones, and if not, why not?",['geometry']
1479437,Wronskian zero with linearly independent solutions,"Any ideas how to go about proving this? Functions $\phi(x)$ and $\psi(x)$ are linearly independent on the interval $[\alpha,\beta]$, but their Wronskian $W(\phi,\psi)=0$ for some $x\in [\alpha, \beta]$. Prove that exist at least two points $x_1,x_2 \in [\alpha, \beta]$ such that $\phi(x_1)=\psi′(x_2)=0$. I've naturally started with considering the point at which the Wronskian vanishes, say $\phi(x_0)\psi'(x_0)-\phi'(x_0)\psi(x_0)=0$ and then took them to each side and arrive at the logs being equal when evaluated at x0 but I'm not sure if this makes sense and if it doesn, where to go from there? I'm not sure how the linear independence comes in to play? Should I'm be attempting this at a higher level rather than constructively? Any help would be greatly appreciated!","['wronskian', 'ordinary-differential-equations']"
1479483,When does the inverse of a covariance matrix exist?,We know that a square matrix is a covariance matrix of some random vector if and only if it is symmetric and positive semi-definite (see Covariance matrix ). We also know that every symmetric positive definite matrix is invertible (see Positive definite ). It seems that the inverse of a covariance matrix sometimes does not exist. Does the inverse of a covariance matrix exist if and only if the covariance matrix is positive definite? How can I intuitively understand the situation when the inverse of a covariance matrix does not exist (does it mean that some of the random variables of the random vector are equal to a constant almost surely)? Any help will be much appreciated!,"['probability-theory', 'positive-definite', 'matrices', 'covariance', 'linear-algebra']"
1479495,ODEs are invariant under the given Lie groups?,"$\frac{dy}{dx} = \frac{x^{2}y}{x^{3}+xy+y^2}$ is invariant under $(x,y) \mapsto (\frac{x}{1+\varepsilon y},\frac{y}{1+\varepsilon y})$ I can't make both sides equal when I have a variable depends on two variables
I use $\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\mathrm{D}y}{\mathrm{D}x}$ ($D=$ total derivative), but I can't make both equal!!
How to do that? I want to mention that this example is arbitrary I can not make any invariant when any variable equal any combination of $x$ and $y$.","['symmetry', 'lie-groups', 'symmetric-groups', 'ordinary-differential-equations']"
1479531,Eigenvalues of differentiable matrices,"I have a real-valued matrix, $M(a)$, which is a differentiable function of $a$, but not continuously differentiable, with $M(0)=I$. I'll assume $M'(0)$ has distinct eigenvalues. I'm looking for results proving the differentiability of the eigenvalues of $M(0)$.  I suspect it may be a challenging proof because when I read the literature, I see people making very restrictive assumptions, usually that the eigenvalues are distinct (clearly not true for me), and if not, it seems that people assume the matrix is symmetric, also not true for me. If I assume the eigenvalues and eigenvectors are differentiable, say with $v_1(a)$ being one of the eigenvectors, then I believe I can conclude that $v_1(0)$ is an eigenvector of $M'(0)$ and I can work out $\lambda_1'(0)$.  If so I've got the result I'm trying to prove. Is it known whether the eigenvalues of a differentiable real matrix are in fact differentiable, even if repeated?  If true - where can I find a reference?  If false, where can I found a counterexample?  If unknown - what's the challenge in proving it?","['derivatives', 'eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1479557,Proof of trigonometric relationship of angle bisector,"I have to prove the following equation: $$CD=\frac{2ab\cos\frac{C}{2}}{a+b}$$ where $CD$ is the angle bisector of $C$ in $\Delta ABC  $. My attempt: I've started by rearranging the equation in terms of $\cos \frac{C}{2}$ ,then by squaring and subtracting $\sin^2 \frac{C}{2}$ from both sides, yielding thus: $$\cos^2 \frac{C}{2}-sin^2\frac{C}{2} =\frac{(a+b)^2 \cdot CD^2}{(2ab)^2}-  \ \sin^2\frac{C}{2}\tag{1}$$ $$\cos C  =\frac{(a+b)^2 \cdot CD^2}{(2ab)^2} - \frac{(s-a)(s-b)}{ab}\tag{2}$$ Now i express $ \cos C $ in terms of $a,b,c$ ,then I simplify by multiplying for $ab$ both sides and I multiply out $(s-a)(s-b)$ , getting now: $$2(b^2+a^2-c^2)=\frac{(a+b)^2 \cdot CD^2}{4ab}-(ab+bc-b^2+c^2-a^2)\tag{3}$$ By simplifying this and rearranging for $CD^2$ I get: $$CD^2=\frac{(a^2+b^2-c^2 +ab+ bc)(ab)}{(a+b)^2}\tag{4}$$ Finally by replacing $CD^2=ab-(abc^2)/(a+b)^2\tag{5}$ and doing all the algebraic manipulation i get the final result that $a+c=2a$ which is clearly wrong...And here i am asking for humble help on math.stackexchange","['geometry', 'trigonometry']"
1479587,"Vector Space Structures over ($\mathbb{R}$,+)","Consider the abelian group ($\mathbb{R}$,+) of real numbers with the usual addition. Is there a scalar multiplication
\begin{equation}
\cdot : \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R},
\end{equation}
other than the usual multiplication, which makes ($\mathbb{R}$,+,$ \cdot $) a real vector space?","['abstract-algebra', 'linear-algebra', 'modules', 'functional-equations']"
1479631,Help with an integral $\int_0^{2 \pi} {d \theta \over (a + b \cos^2 \theta)^2}$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I need evaluate the following integral using residue theorem: With $a>0$ and $b>0$ $\int_0^{2 \pi} {d \theta \over (a + b \cos^2 \theta)^2}$ I have this: $\int_0^{2 \pi} {d \theta \over (a + b \cos^2 \theta)^2} = \int_{|z| = 1}{ {16z^4} \over{bz^4 + (2a+b)2z^2 +b}} {1 \over iz} dz$ But I do not know how to follow, I really need help.",['complex-analysis']
1479658,Trigonometric equation with parameter,"Find $p$ for which $\cos^2(x) - \cos(x) + p + 1 = 0$ has EXACTLY two solutions for $0 \le x \le 2\pi$ I tried to substitute $t = \cos(x)$ and then I got two solutions, but I don't know what to do next. $t_1 = \frac{1 + \sqrt{-3 - 4p}}{2}$ $t_2 = \frac{1 - \sqrt{-3 - 4p}}{2}$","['parametric', 'trigonometry']"
1479703,Natural proofs of theorems or exercises [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 8 years ago . Improve this question Some mathematicians wants to hide their reasoning and proof process so that they appear smart. As most of the mathematics lovers I am not a genius and this is why I hate the magical proofs because they don't learn me anything. Do you have striking theorems or exercises you encoutered many times in your life and you never understood up until you finally got the right natural proof ? 
If it's the case please feel free to share your knowledge. Even if it is an heuristic and not a proof For exemple here is a topic for natural Cauchy - Schwarz proofs : A natural proof of the Cauchy-Schwarz inequality I should start : Theorem. [PNT] If $p_n$ denotes the $n$-th prime number, then $p_n \sim n \log n$. Here is an heuristic based on the ideas of Euler. The excellent idea of Euler is to aknowledge that we have a better knowledge of the sums than the numbers. We all know that with a simple integral test we have :  $$\sum _{1 \leqslant k \leqslant n} \frac{1}{k} \sim \log n $$ The idea is then to find each integer $n$ with the primes. For the powers of a prime Euler simply wrote : $$ \frac{1}{1-\frac{1}{p}}= \sum_{ \alpha  \geqslant 0} \frac{1}{p^{\alpha}} $$ 
To find each $\displaystyle \frac{1}{n}$ we just have to take the product : $$ \prod_{ p\in \mathbb{P} \atop p \leqslant N} \frac{1}{1-\frac{1}{p}}= \prod_{ p\in \mathbb{P} \atop p\leqslant N} \sum_{ \alpha  \geqslant 0} \frac{1}{p^{\alpha}}$$
In the right hand side we find each $\frac{1}{n}$ pour tous les $n$ for $n$ that only involves primes such that $p \leqslant N$ so we basicly have every $1/n$ up to $n=N^2$.  Let's say : $$\prod_{ p\in \mathbb{P} \atop p \leqslant N} \frac{1}{1-\frac{1}{p}} \approx \sum_{n \leqslant N^2} \frac{1}{n} \sim \log N^2 \sim \log N$$
Taking the logarithm : $$-\sum_{p \leqslant N} \log \left( 1-\frac{1}{p} \right) \sim \log \log N $$ Since : $$\log \left( 1- \frac{1}{p}\right) \sim - \frac{1}{p}$$ by summation we have : $$ \sum_{p \leqslant N} \frac{1}{p} \sim \ln \ln N $$ A discrete derivation (but not licite still) gives us :  $$ \frac{1}{p_N}=\frac{1}{N \log N}$$ so that : $$ p_N \sim N \log N $$ it's the prime number theorem  ! It's a quite simple way of understanding the theorem I found very clear. Of course this is not a proof,","['abstract-algebra', 'sequences-and-series', 'analysis', 'learning']"
1479722,Confusion with the narrow and weak* convergence of measures,"Think of a LCH space $X.$ Consider the spaces $C_{0}(X)$ of continuous functions ""vanishing at infinity"" and the space $BC(X)$ of bounded continuous functions. Consider as well the space of Radon (Borel regular) measures $M(X).$ What follows is an incorrect reasoning which gets me to an absurd situation. However, I fail to see the mistake(s) in it, and that's where I would like some help! By the Riesz's representation theorem, we have that the topological dual of $C_{0}(X)$ is isometrically isomorphic to the space of finite Radon measures. Hence, we have in $M(X)$ the natural weak* star topology: We say that $\mu_{n}$ converges weak* to $\mu$ if $$\int _{X} \psi \ d\mu_{n} \rightarrow \int _{X} \psi \ d\mu, \ \forall \psi \in C_{0}(X).$$ On the other hand, we say that $\mu_{n}$ converges in the narrow topology to $\mu$ if $$\int _{X} \phi \ d\mu_{n} \rightarrow \int _{X} \phi \ d\mu, \ \forall \phi \in BC(X). $$ Prokhorov's theorem gives a characterization of sequential compactness in $M(X)$ with the narrow topology (actually, of compactness, since it is metrizable). This theorems is quite technical and involves the notion of tightness, which is a necessary condition for compactness. However, if we think of $M(X)$ with the weak* topology it inherits from being a dual space, compactness is very easy to characterize thanks to the Banach-Alaoglu theorem. Furthermore, it is a not-too-hard exercise to show the equivalence of the following two propositions: i) $\mu_{n}$ converges narrowly to $\mu$ ii) $\mu_{n}$ converges weakly* to $\mu$ and $\mu_{n}(X) \rightarrow \mu(X).$ And here is where I got confused: Consider a collection of probability measures, $\{ \mu_{n} \}_{n \in \mathbb{N}}.$ Clearly, this family is bounded in the dual norm. Therefore, by the Banach-Alouglu theorem, it must contain a weakly* convergente subsequence (which I do not relabel) to a measure $\mu$. This subsequence trivilly satisfies $\mu_{n}(X)=1 \rightarrow 1=\mu(X).$ By the remark above, $\mu_{n}$ must converge narrowly to $\mu...$ But the tightness condition has not appeared anywhere! What is my mistake? What am I doing wrong? Also, if this were so easy, Prokhorov's theorem would be meaningless (of course that's not the case!) Thank you for your help","['probability-theory', 'weak-convergence', 'convergence-divergence', 'real-analysis']"
1479738,"Minimizing the Frobenius norm of a matrix involving the Hadamard product, $\|X(A\odot Y)-S\|_F$","Let $S\in\mathbb{R}^{L\times N}$ and $A\in\mathbb{R}^{M\times N}$ be known and arbitrary. I'd like to solve the following system:
\begin{align}
\min_{X\in\mathbb{R}^{L\times M},Y\in\mathbb{R}^{M\times N}} \frac{1}{2}\|X(A\odot Y)-S\|_F^2,
\end{align}
where $\odot$ is the Hadamard product. I've proceeded by defining $Z=X(A\odot Y)-S$ and then rewriting the objective function by $f=\frac{1}{2}Z:Z$, where ($:$) is the Frobenius product. Differentiating, we have
\begin{align}
\text{d}f&=Z:dZ\\
&=Z:\text{d}[X(A\odot Y)-S]\\
&=Z:[X\text{d}(A\odot Y)+\text{d}X(A\odot Y)-\underbrace{\text{d}S}_{=0}]\\
&=Z:[X(A\odot \text{d}Y+\underbrace{\text{d}A}_{=0}\odot Y)+\text{d}X(A\odot Y)]\\
&=Z:[X(A\odot \text{d}Y)+\text{d}X(A\odot Y)]\\
&=[X(A\odot Y)-S]:[X(A\odot \text{d}Y)+\text{d}X(A\odot Y)]\\
&=[X(A\odot Y)-S]:[X(A\odot \text{d}Y)]+[X(A\odot Y)-S]:[\text{d}X(A\odot Y)]\\
&=[X(A\odot Y)]:[X(A\odot \text{d}Y)]+[X(A\odot Y)]:[\text{d}X(A\odot Y)]\\
&\qquad-S:[X(A\odot \text{d}Y)]-S:[\text{d}X(A\odot Y)]
\end{align} This is as far as I have been able to get. I know that I need to find the gradient of $f$ with respect to $X$ and $Y$ and then try to find a pair $(X^*,Y^*)$ that satisfies the two first-order conditions. I'm also aware that such a pair may not be unique (e.g., for any $c\in\mathbb{R}\not\cap\{0\}$, the pair $(cX^*,c^{-1}Y^*)$ is also a solution to this system), but I'm willing to overlook this for now, as I want to first characterize what a solution set would look like. I've done a search, but haven't been able to figure out whether operations of the form $X(A\odot Y)$ simplify nicely, so I'm unsure how to proceed from here.","['real-analysis', 'matrix-calculus', 'normed-spaces', 'optimization', 'linear-algebra']"
1479759,"$\min_{a\in \mathbb{R} }E \left[|Z-a|^p\right]$ where $Z \sim \mathcal{N}(\mu,1)$","Let $Z \sim \mathcal{N}(\mu,1)$ and optimize the following problem. For a given $p>0$
\begin{align}
\min_{a\in \mathbb{R} }E \left[|Z-a|^p\right]
\end{align} The goal is to find optimal  $a$. Things I tried W.l.o.g we can transform the problem over $N \sim \mathcal{N}(0,1)$ since \begin{align}
\min_{a\in \mathbb{R} }E \left[|Z-a|^p\right]=\
\min_{a\in \mathbb{R} }E \left[|N+\mu-a|^p\right]=\min_{b\in \mathbb{R} }E \left[|N-b|^p\right].
\end{align} Moreover, we know that $E[|N|^p]=\frac{2^{p/2} \Gamma \left( \frac{p+1}{2}\right)}{\sqrt{p}} $ and $E[N^p]=0$ for $p$=odd. So, the problem becomes kind of manageable for $p$=even since \begin{align}
\min_{b\in \mathbb{R} }E \left[|N-b|^p\right]=\min_{b\in \mathbb{R} }E \left[(N-b)^p\right]=\min_{b\in \mathbb{R}} \sum_{n=0}^p{p \choose n}E[N^{p-n}]a^n
\end{align} and we basically have to find a minimum of a polynomial of order $p$. However, getting a close form solution for large $p$ is not that easy. (At least for me). My main difficulty is how to approach a general $p>0$? At first, I thought that the minim was going to be $a=E[N]$ but I don't think this is true. Thanks for your help in advance.","['probability-theory', 'optimization', 'expectation']"
1479760,Find the range of $f(x)=x/(3x^2−3x)$,"Find the range of $f(x)=x/(3x^2−3x)$ From my computations, the range I get is all reals except for -1/3. However, after I looking at the graph of the function on google, it looks as if the range is all reals except for 0. I've been working on this for hours but I don't know what I did wrong.","['algebra-precalculus', 'functions']"
1479767,How Does the ($\sqrt{x^2+x}+x)$ Equal $(\sqrt{x^2}+x)$ When Calculating The Limit of Infinity?,"I am asking this because of the following question: What is the Limit of positive infinity for the equation $\frac{1}{\sqrt{x^2+x}+x}$? The following steps are done to get the answer, which is 2. I am not sure how the 3rd step went from having a numerator of $\sqrt{x^2+x}+x$ to having a numerator of $\sqrt{x^2}+x$. It's as if the $\sqrt{x}$ just disappeared. Can anyone explain why this happens? All help is appreciated.","['infinity', 'calculus', 'limits']"
1479774,$F(F(x)+x)^k)=(F(x)+x)^2-x$,"I have no idea about this problem. But I feel we have to use chain rule of differentiation here. The Function $F(x)$ is defined by the following identity: $F(F(x)+x)^k)=(F(x)+x)^2-x$ The value of $F(1)$ is such that a finite number of possible values of $F'(1)$ can be determined solely from the above information.The maximum value of $k$ such that  $F'(1)$ is an integer can be expressed as $\frac{a}{b}$, where $a , b$ are co-prime integers. What is the value of $a+b$","['puzzle', 'calculus', 'real-analysis', 'functional-equations', 'derivatives']"
1479778,"Prove for all sets A,B,C: If $C-B=\varnothing$ then $(A\cup C)-(B-C^c)=A-(B\cap C)$","To be proven: If $C-B=\varnothing$ then $(A\cup C)-(B-C^c)=A-(B\cap C)$. I've been stuck on this problem for a few days, I try to use set identities on both sides of the equation to try and make them equal but I can't figure it out. Here's where I keep getting stuck $$(A\cup C)-(B-C^c) = (A\cup C)-(B\cap(C^c)^c) = (A\cup C)-(B\cap C)$$ I don't know how to make $(A\cup C)$ into $A$ so that the equation is true.",['elementary-set-theory']
1479837,How to get $P(X > x)$ where $K$ is a geometric random variable with parameter $p$?,"I'm trying to understand why $P(K > k)$ where $K$ is a geometric random variable with parameter $p$ and PMF equal to $p(1 − p)^{k}$ for all positive $k$ . It seems to me the answer should in fact be a summation of $(1 − p)^{k}$ over all $K > k$ , but apparently it is not. The reasoning behind that is completely escaping me and I can't find anything on the web explaining it.","['probability', 'random-variables']"
1479844,Variation of the Kempner series – convergence of series $\sum\frac{1}{n}$ where $9$ is not a digit of $1/n$.,"It is easy to argue that the Kempner series converges: 
$$
 \sum\limits_{\substack{n \text{ s.t. 9 is}\\\text{ not a digit} \\\text{ of } n}}
 \frac{1}{n} < \infty$$ Let $E \subset \Bbb N_{>0}$ the subset of the positive integers  such that $9$ is not a digit of the decimal expansion of $1/n$ (the decimal expansion is not allowed to have a trailing infinite sequence of ""$9$""s. For instance $0.24999...$ is not allowed). Here are the first numbers that don't belong to $E$ : $11,13,17,19,21,23,29,31,34,38,41,…$ (not known by the OEIS, by the way). My question is: Does the series 
  $$ \sum\limits_{n \in E} \frac{1}{n} \tag 1$$ converge? My attempt is : Let $1/n = 0,a_1 a_2 \dots a_k \overline{b_1 b_2 \dots b_m}$ with $n \in E$. Since $1/n$ has no digit ""9"", we have at most $9^{k+m}$ possibilities for the $a_i$'s and $b_j$'s. Moreover, $1/n ≥ 0,00...0\overline{00...01}≥1/10^{k+m}$. But then I can only bound my series $(1)$ from below, by some real number. So, this is not a clue for the divergence of the series. Apparently, the numbers of the form $n=10k+1$ don't belong to $E$. Maybe we can find sufficiently many numbers that have $9$ in the decimal representation of their reciprocals, so that $(1)$ could converge... Any comment will be appreciated !","['decimal-expansion', 'sequences-and-series', 'convergence-divergence', 'real-analysis']"
1479930,How to properly handle multivariate limits.,"Consider the function $f : \mathbb{R}^2 \to \mathbb{R}$ defined by $$
f(x,y) = \begin{cases}
    \frac{xy(x^2-y^2)}{x^2+y^2} & \text{for  $(x,y) \neq (0,0),$}\\
    0 & \text{for  $(x,y) = (0,0).$}
  \end{cases}
$$ I am hoping to show this is continuous, but I do not know how to handle multivariate limits, can I simply take one and then the other or what do you do? I have no $\varepsilon-\delta$ version of continuity at hand, only the usual limit formulation.","['calculus', 'multivariable-calculus']"
1479939,"Prove that if $f(x_n) \rightarrow f(x)$ for every continuous real-valued function in the metric space M, $x_n \rightarrow x$ on M.","The problem goes like: Suppose that we are given a point $x$ and a sequence $x_n$ in a metric space $M$, and suppose that  $f(x_n) \rightarrow f(x)$ for every continuous real-valued function $f$ on $M$. Prove that $x_n \rightarrow x$ in $M$. I was thinking that since the $f(x_n) \rightarrow f(x)$ for EVERY $f$, then we can find one with a continuous inverse (could it just be $f(x) = x$?). Then since both $f$ and $f^{-1}$ are continuous and also $f$ is bijective, it is a homeomorphism. Therefore, the preimage converges based on the fact that $f$ being a homeomorphism. Is this correct?","['continuity', 'real-analysis', 'functions']"
1480091,Show that there exists a diagonal matrix $B$ the diagonal entries of which are $±1$ such that $A + B$ is nonsingular.,"Let $n$ be an odd positive integer let $A ∈ M_{n×n}(\mathbb{R})$. Show that there exists a
diagonal matrix $B$ the diagonal entries of which are $±1$ such that $A + B$ is nonsingular. Any solutions/hints are greatly appreciated. I'm not sure how to do this.","['linear-algebra', 'matrices']"
1480093,Convergence of $\sum_{n=1}^{\infty} \log\left(\frac{(2n)^2}{(2n+1)(2n-1)}\right)$,"I have to show that the series 
$\sum_{n=1}^{\infty} \log\left(\frac{(2n)^2}{(2n+1)(2n-1)}\right)$
converges. I have tried Ratio Test and Cauchy Condensation Test but it didn't work for me. I tried using Comparison Test but I couldn't make an appropriate inequality for it. Could you please give me some hints. Any help will be appreciated.","['sequences-and-series', 'calculus', 'convergence-divergence']"
1480103,What is “Basis of a Group”?,"I have an assignment, that beside other things, asks about a basis of a group, more precisely, it have been asked to ""give an example of a basis for $T_d$"" (tetrahedron group). But I been on all lectures and searched internet for such a definition, but found nothing. Any idea what ""Group Basis"" means? maybe it has some other name also? P.S There was no mentioning of any kind of group representations in this questions, so I suspect that this is something related to representations.","['group-theory', 'finite-groups']"
1480147,outer measure of set equals outer measure of closure,Giving the outer measure for $E \subset\mathbb{R}^n$ $\mu^*(E) = \inf\left\lbrace\sum_{i=1}^{\infty} \textrm{diam}(U_i) | E \subset \bigcup_{i=1}^{\infty} U_i\right\rbrace$ we want to prove $\mu^*(E)= \mu^*(\overline{E})$ for every $E \in \mathbb{R}^n$ bounded and connected. In this context we have already proven that the cover of $E$ can be taken open. Furthermore we have proven $\textrm{diam}(E) = \textrm{diam}(\overline{E})$ We have already proven that a bounded and connected set $E \in \mathbb{R}^n$ satifies $\textrm{diam}(\overline{E})= \mu^*(\overline{E})$. Hope somebody can help us.,"['real-analysis', 'measure-theory']"
1480164,"For any $18$ distinct two-digit numbers, are there four distinct numbers $a,b,c,d$ such that $a+b=c+d$ ? Can we make $18$ small?","I've known that the following proposition is true for $n=20$. Proposition : For any $n$ distinct two-digit numbers, there exists a set of four distinct numbers $a,b,c,d$ such that $a+b=c+d$. Then, I began to try to find the minimum of $n$ such that the proposition is true. Then, I've got that the proposition is true for $\color{red}{n=19}$. Proof that the proposition is true for $n=19$ : Let the given $19$ numbers be $a_1\lt a_2\lt \cdots\lt a_{19}$. Also, let $\{a_2-a_1,a_3-a_2,\cdots, a_{19}-a_{18}\}=\{b_1,b_2,\cdots, b_{18}\}$ where $b_1\le b_2\le\cdots\le b_{18}$. Suppose that there exists no set of four distinct numbers $a,b,c,d$ such that $a-c=d-b$. If $b_n=b_{n+1}$, then there exist $p,q\ (p\lt q)$ such that $a_{p+1}-a_p=a_{q+1}-a_q$, but from the supposition, $q=p+1$ has to hold. It follows from this that there are no three same numbers in $b_n$ and that 
$\sum_{k=1}^{18}b_k\ge 1+1+2+2+\cdots +9+9=90$, which contradicts that we have $\sum_{k=1}^{18}b_k=a_{19}-a_1\le 99-10=89$. QED This is all I've been able to get so far. So, my question is the following : Question : How can we find the minimum of $n$ such that the proposition is true? Added : Byron Schmuland proves that the proposition is true for $n=14$ under the condition that $a,b,c,d$ are not necessarily distinct. Also, he comments that we can prove that the proposition is true for $n=15$ under the condition that $a,b,c,d$ are distinct according to the solution for a related question . What I mean in this question is that $a,b,c,d$ are distinct . (sorry, this might not be obvious. So, I add the word ""distinct"") We now know that the minimum of $n$ has to be less than or equal to $15$. Here, I'm going to write the proof for $n=15$ by getting the key idea from the above solution. Proof that the proposition is true for $n=15$ where $a,b,c,d$ are distinct : Suppose that there exists no set of four numbers $a,b,c,d$ such that $a-c=d-b$. There are $\binom{15}{2}=105$ ways to choose $2$ numbers from the given $15$ numbers. From the supposition, each difference of their $2$ numbers are distinct except the case when $$i-j=j-k\tag1$$ where $i\gt j\gt k$. Here, for every $j$, there exists at most one $(i,k)$ satisfying $(1)$. This is because if there were distinct $(i,k),(i',k')$ such that $i-j=j-k,i'-j=j-k'$, then the four numbers $i,k,i',k'$ would be distinct and would satisfy $i-i'=k'-k$, which contradicts the supposition. Since $j$ can neither the maximum number nor the minimum number, the number of the patterns where $(1)$ happens is at most $15-2=13$. Hence, if we eliminate at most $13$ sets of $2$ numbers, then each difference of the $2$ numbers from the remaining $105-13=92$ is distinct. However, the difference of $2$ numbers is either $1,2,\cdots, 88,89(=99-10)$, which is a contradiction. QED Added : Byron Schmuland and Ross Millikan independently show eleven 2-digit numbers so that every pair has a different sum. So, we now know that the minimum $n_{\text{min}}$ of $n$ has to satisfy $\color{red}{12\le n_{\text{min}}\le 15}$.","['summation', 'combinatorics']"
1480180,Board game on a $m\times n$ board - winning strategy,"Two friends, $A$ and $B$ , play a game with one single game piece on a rectangular board with $m$ rows and $n$ columns. $A$ begins the game by moving the game piece from its starting point $(1, 1)$ to either $(1, 2)$ or $(2,1)$ i.e one can only move one step in a horizontal or vertical direction  every move. No point is allowed to be entered twice. The player that no longer can make any move loses. Is there any winning strategy? Intuitively, it feels like we need to consider rows and columns with equal and non-equal parities, and I tried to reduce the problem to smaller cases, but it gave me nothing. Any suggestions?","['contest-math', 'puzzle', 'combinatorics', 'combinatorial-game-theory']"
1480202,"Let $2^A$ be the set of functions from a set $A$ to $\{0, 1\}$. Prove that there is a bijection between $2^A$ and the power set of $A$","I realize that there's already this thread: Prove that there is a bijection between the set of all subsets of $X$, $P(X)$, and the set of functions from $X$ to $\{0,1\}$. I thought maybe there's a shorter proof? Let $f : A \to B$ be any function. Then the graph $Γ_f := \{(a, b) \in A \times B | b = f(a)\} \subseteq A \times B$ of $f$ is isomorphic to $A$. Let $f: 2^A \to P(A)$ and $g: P(A) \to 2^A$. Then $2^A$ is bijective to $Γ_f \subseteq 2^A \times P(A)$ and $Γ_g \subseteq P(A) \times 2^A$ is bijective to $P(A).$ Since $Γ_g$ and $Γ_f$ are bijective and bijection is an equivalence realtion, $2^A$ is bijective to $P(A).$ Is it possible to argue like the above? Thanks. edit: Let $A = \{0, 1\}$. Subsets of $A$ can either contain an element of $A$ or not. Set up a bijection like so: $\{0, 1\} \leftrightarrow (yes, yes)$ $\{0\} \leftrightarrow (yes, no)$ $\{1\} \leftrightarrow (no, yes)$ $\{\} \leftrightarrow (yes, no)$ If an element in the subset of $A$, then it corresponds to yes in the corresponding list. Now we can simply count the number of lists. Consider the set $\{yes, no\}$. There are $2$ choices for $yes$ and $2$ choices for $no$. So that there are $2^2$ lists of the form $(yes, no)$.",['elementary-set-theory']
1480224,"Twin square-free numbers of the form $6k-1,6k+1$?","Is it easy to show (or even known) that there are infinitely many square-free pairs $6k-1,6k+1$? (Presumably, not disproven yet, since a lot of people would be wasting their time on the twin prime conjecture if it was.)","['number-theory', 'twin-primes']"
1480248,How to compute the coefficients of this generating function,"Working on some combinatorial problem, I arrived at the following generating function $$K_m(x) = \sum_{n\geq 0}K_{mn}x^n =\frac{x}{1-\sqrt{1+x^2}\cdot\frac{\displaystyle{y_+(x)^{m+1}+y_-(x)^{m+1}}}{\displaystyle{y_+(x)^{m+1}-y_-(x)^{m+1}}}}$$
with
$$y_\pm(x) =x\pm\sqrt{1+x^2}.$$ I aim to compute the coefficients $K_{mn}$ in a closed form. I solved many problems with generating functions, but this one I tried for days, and I'm not sure if it is impossible at all, or if I lack an important skill. For comparison I give the first coefficients, which I computed by hand $$K_1(x) = -2x^2-4x^3-4x^4+8x^6+16x^7+O(x^8) \\
K_2(x) = x+3x^2+9x^3+19x^4+33x^5+59x^6+121x^7+O(x^8)\\
K_3(x) = -4x^2-16x^3-40x^4-64x^5-32x^6+192x^7+O(x^8)\\
K_4(x) = x+5x^2+25x^3+85x^4+225x^5+541x^6+1385x^7+O(x^8)$$ also the dependence of the first coefficients on $m$ for the first orders $n$ is given here for odd $m$ $$K_m(x) = (-m-1)x^2-(m+1)^2x^3-\frac{2}{3}m(m+2)(m+1)x^4-\frac{1}{3}(m+1)^2(m-1)(m+3)x^5-\frac{1}{15}(2m^4+8m^3-13m^2-42m-15)(m+1)x^6-\frac{2}{45}m(m+2)(m^2+2m-33)(m+1)^2x^7+O(x^8)$$ and here for even $m$ $$K_m(x) = x+(m+1)x^2+(m+1)^2x^3+\frac{1}{3}(m+1)(2m^2+4m+3)x^4+\frac{1}{3}(3+m^2+2m)(m+1)^2x^5+\frac{1}{15}(m+1)(2m^4+8m^3+27m^2+38m+15)x^6+\frac{1}{45}(2m^4+8m^3+62m^2+108m+45)(m+1)^2x^7+O(x^8)$$ I decided to not post the underlying combinatorial problem, as the point of my question is really to see, if a generating function approach is possible here. One idea, which I did not finish, however, would be to use the substitution $$x=i\sin(u)$$ which transforms the generator into $$K_m(u) = \frac{\sin(u)}{\cos(u)\tan((m+1)u)-i}$$ which looks much simpler. Possibly, one could compute the coefficients $$K_m(u)=\sum_{n\geq0}R_{mn}u^n$$ and then transform the $R_{mn}$ into the $K_{mn}$ somehow, but I'm not sure if any of these two steps is possible, and even simpler than directly computing $K_{mn}$. Any suggestions are highly appreciated.","['power-series', 'sequences-and-series', 'generating-functions', 'combinatorics']"
1480277,"Why is the dimension of this Grassmann manifold $G_{d, n}$ equal to $(d+1)(n-d)$ formed by the Plucker coordinates of a $d$-plane?","A $d$-plane $L \subset \mathbb{P}^{n}$ is defined as the set of points $P=(p(0), p(1), \ldots, p(n)) \in \mathbb{P}^{n}$ that satisfy equations $\sum_{j=0}^{n} b_{\alpha j}p(j) = 0$, where $\alpha = 1, \ldots, (n-d)$. If these equations are independent, then we say that the dimension of $L$ is $d$. Form the $(d+1)\times(n+1)$ matrix $[p_{i}(j)]$ formed from the spanning vectors $P_{i} = (p_{i}(0), p_{i}(1), \ldots, p_{i}(n))$ of $L$ and consider all possible determinants of the $(d+1)\times(d+1)$ minors. There are $\binom{n+1}{d+1}$ such determinants, and we form a point $(d_{1}, \ldots, d_{N+1}) \in \mathbb{P}^{N}$, where $N = \binom{n+1}{d+1} - 1$. There is a bijective correspondence between such points in $\mathbb{P}^{N}$ that satisfy certain quadratic relations and the $d$-planes $L \subset \mathbb{P}^{n}$. This is where I'm confused : There is a proposition stating that there is a bijective correspondence between the set of points of $\mathbb{P}^{N}$ (as defined above) and the affine $(d+1)(n-d)$-space of $(d+1)(n+1)$ matrices $[p_{i}(j)]$ with $i=0, \ldots, d$ and $j=0, \ldots, n$ such that the $(d+1)\times(d+1)$-submatrix $[p_{i}(k_{\gamma})]$ with $i, \gamma = 0, \ldots, d$ is the identity. This set of points in $\mathbb{P}^{N}$ is covered by $(N+1)$ copies of affine $(d+1)(n-d)$-space, called the Grassmann Manifold (of $d$-planes in $n$-space). Why is the dimension of $G_{d, n}$ equal to $(d+1)(n-d)$? I would have thought it's just $(d+1)(n+1)$. [I hope this is the appropriate place to post this question!]","['intersection-theory', 'abstract-algebra', 'algebraic-geometry', 'grassmannian', 'linear-algebra']"
1480307,Prove or Disprove: $m^2-n^2=2$ where m and n are integers. (Checking),"Prove or Disprove: The following statement: There are integers m and n such that $m^2-n^2=2$ Solution: $m^2-n^2=(m-n)(m+n)=2\times1$ Since 2 is a prime number, then Case 1: $m-n=2$ and  $m+n=1$ Solve the two equations, then $m=\frac{3}{2}$ which is not integer. Case 1: $m-n=1$ and  $m+n=2$ Solve the two equations, then $n=\frac{1}{2}$ which is not integer. Therefore, there are no two integers m and n such that $m^2-n^2=2$ Note: This is a question from the test I just took. I am just checking if I did it right.","['number-theory', 'discrete-mathematics']"
1480318,How to prove the formula for the residue of $f$ at a pole of order $m$?,"Let $f$ holomorphic on $z_0$. I saw this awesome formula on a book : the residual of $f$ on $z_0$ is given by $$\text{Res}_{z_0}(f)=\frac{1}{(m-1)!}\frac{\mathrm d^m}{\mathrm dz^{m-1}}(z-z_0)^mf(z)$$
How can I prove it? ($m$ is the order of pole that $f$ is assumed to have at $z_0$).","['complex-analysis', 'residue-calculus']"
1480344,Why is the following NOT a proof of The Chain Rule?,"In Leibniz notation of the chain rule, 
$$\frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx}$$ Where $y\left ( u\left ( x \right ) \right )$ is a composite function of x. I understand that the du 's don't simply cancel out because $\frac{dy}{du}$ and $\frac{du}{dx}$ are defined as specific limits making the numerator and denominator infinitesimals and thus making the whole thing indeterminate and inoperable on. But applying the definition of a derivative, we can express the above like so: $$\lim_{\Delta x\to 0} \frac{\Delta y}{\Delta x} = \lim_{\Delta u\to 0} \frac{\Delta y}{\Delta u} \cdot \lim_{\Delta x\to 0} \frac{\Delta u}{\Delta x}$$ At this point we can't use the Product Law of Limits to combine the two limits on the right. But if we consider a coordinate system u vs x , doesn't $\Delta u \rightarrow 0$ when $\Delta x \rightarrow 0$ ? And if so,  then whenever $\Delta u \rightarrow 0$ we necessarily have $\Delta x \rightarrow 0$. Then can't we rewrite the above limit equation as: $$\lim_{\Delta x\to 0} \frac{\Delta y}{\Delta x} = \lim_{\Delta x\to 0} \frac{\Delta y}{\Delta u} \cdot \lim_{\Delta x\to 0} \frac{\Delta u}{\Delta x}$$ And then can't we use the Product Law of Limits to say: $$\lim_{\Delta x\to 0} \frac{\Delta y}{\Delta x} = \lim_{\Delta x\to 0} \left (  \frac{\Delta y}{\Delta u} \cdot \frac{\Delta u}{\Delta x} \right )$$ And since $\frac{\Delta y}{\Delta u}$ and $\frac{\Delta u}{\Delta x}$ within the quantity who's limit is being taken are no longer ""quotients"" infinitesimals, Δu 's can cancel, leaving us with: $$\lim_{\Delta x\to 0} \frac{\Delta y}{\Delta x} = \lim_{\Delta x\to 0}   \frac{\Delta y}{\Delta x} $$ Which in Leibniz notations looks like: $$\frac{dy}{dx} = \frac{dy}{dx}$$ Q.E.D (Since we manipulated the right hand side of the equation into looking the same as the left hand side).","['calculus', 'limits', 'chain-rule', 'recreational-mathematics', 'derivatives']"
1480370,Delta-epsilon proof of $\lim_{x\rightarrow\infty} \frac{x}{x+1} = 1$,"I have an exercise where I'm supposed to show, by delta-epsilon proof that $\frac{x}{x+1}$ tends to 1 as $x$ goes to positive infinity. In our faculty and literature, for limits at infinity we usually call $\delta$ small omega ($\omega$) instead. So the definition I use is the following: $$x > \omega \Rightarrow |f(x)-A|\leq\epsilon$$
where
$$x > 0,\; \omega(\epsilon),\; \epsilon > 0$$
So pretty standard definition. Now here's my attempted proof of:
$$\lim_{x\rightarrow\infty} \frac{x}{x+1} = 1$$ We have
$$\left|\frac{x}{x+1}-1\right|\Leftrightarrow \left|-\frac{1}{x+1}\right|$$
Also for positive $x$, $x + 1 > 0$ so:
$$\frac{1}{x+1} \leq \epsilon$$
Which (again with assumption $x > 0$) gives:
$$\frac{1}{\epsilon} - 1 \leq x$$
so we can use $\omega(\epsilon) = \frac{1}{\epsilon} - 1$ I am struggling somewhat in real analysis at the moment, so I have very low confidence that I'm not missing something important. It would be greatly appreciated if someone could take a look at my proof and give feedback.","['limits', 'epsilon-delta']"
1480409,Computing real de Rham cohomology of Hironaka's 3-manifold example,"I have read the construction of Hironaka's famous 3-manifold example: in short, it is a union of two smooth curves $C$ and $D$ in a smooth projective 3-manifold $P$ which intersect each other at two points $c$ and $d$, which are nodes for the (reducible) union of the two curves.  One blows up $C$ at point $c$, and $D$ at point $d$.  The resultant manifold is a compact 3-manifold that that contains two smooth rational curves $L$,$M$ lying over $c$ and $d$ such that $L+M$ is algebraically equivalent to $0$, and hence, the Hironaka example is not Kaehler. I would like to know if the Hironaka example admits non-Hard Lefschetz symplectic structures.  This seems quite likely, but my web searches so far have turned up no confirmation.  Do any of you know of a specific paper providing examples of such symplectic structures? I am a novice in algebraic geometry (I'm coming from a symplectic geometry background), so do you any of you know the best source to learn how to compute real de Rham cohomology of manifolds like Hironaka's example?","['algebraic-geometry', 'homology-cohomology', 'symplectic-geometry', 'kahler-manifolds']"
1480411,"Looking at three wires, can I make it look like they meet?","I was walking down the street and there were three wires (used by the tram) above my head. I looked up and by hazard it looked to me like they intersected all three in the same point. I asked myself if this is always the case for three wires. Mathematically speaking, let there be three straight lines $a,b,c$ in the three dimensional space. What are the conditions that there exists a fourth line $d$ that actually intersects $a$, $b$ and $c$? I found some questions about related things but there were things like quadrics and projective spaces and it went a bit over my head. But I could not come up with a simple, elegant proof, that can be understood by, say, a first semester student.","['geometry', '3d']"
1480427,Why are Eigenvectors of an orthogonal matrix with respect to different eigenvalues orthogonal to one another.,"Why are Eigenvectors of an orthogonal matrix with respect to different eigenvalues orthogonal to one another? I tried to find this question, if this is a duplicate post a link and I will cancel this one. Also take an orthogonal matrix $A \in O(3)$ and the linear application associated with it $f: R^3 \rightarrow R^3$ Why is it that if $1$ is an eigenvector then $dim(V_1) = R^3$ and $A = I$
but if $1$ is not an eigenvector then $dim(V_2) $ is $2$ or $1$?","['eigenvalues-eigenvectors', 'linear-algebra']"
1480442,Example of distinctions between multiple integral and iterated integrals.,"The following question is asked in the book of Analysis On Manifolds by Munkres, and given at page 103 as question 3. $Q=A\times B$,where $A$ is a rectangle in $\mathbb{R^k}$ and $B$ is a rectangle in $\mathbb{R^n}$. Give an example where $\int_{Q}f$ exists and one of the iterated integral $$\int_{x\in A}\int_{y\in B} f(x,y) \; \text{and} \; \int_{y\in B}\int_{x\in A} f(x,y)$$ exists, but the other does not. Find an example where both the iterated integrals of 1. exist, but the integral $\int_Q f$ does not. [Hint: One approach is to find a subset $S$ of $Q$ whose closure equals $Q$, such that $S$ contains at most one point on each vertical line and at most one point on each horizontal line.] I'm having difficulty coming up with examples for the second case using the hint. For the first one, I found $f(x,y)= 1/n$ if $y$ is rational and $x=m/n$, where $(m,n)=1$. However, I have no clue about the second one, and what the hint even means. I'd appreciate it if anyone can help me with this problem.","['calculus', 'real-analysis', 'riemann-integration', 'integration', 'multivariable-calculus']"
1480463,Prove that $\forall z \in \Bbb C : \lvert \Re(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z)\rvert$,I'm having difficulties trying to prove these two complex inequalities : $\forall z \in \Bbb C :$ $$\lvert \Re(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z)\rvert$$ $$\lvert \Im(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z) \rvert$$ By the defintion of the modulus of a complex number we have : $$\lvert z \rvert = \lvert x+iy \rvert = \sqrt{x^2+y^2} = [(\Re(z))^2 + (\Im(z))^2]^{1/2}$$ If I square both side of the equality I get : $${\lvert z \rvert}^2 = (\Re(z))^2 + (\Im(z))^2$$ but I don't know how to continue from here.,"['complex-analysis', 'complex-numbers', 'inequality']"
1480485,Dimension of reducible polynomial with Zarisky topology,"Consider the set of polynomials with n variables and degree at most d.Denote this as $V_d$. This is a vector space, and consider it as an affine space by regarding the coefficients of monomials as coordinates of affine space. For example, when d=1, it is just $\mathbb A^n$. In general, when d=m, the affine space is $A^N$ where N=${d+n-1 \choose n-1}$. Let $V_{red}$ denote the set of reducible polynomials in $V_d$. My question now is what is the dimension of the closure of $V_{red}$ in Zarisky topology of affine space? Actually $V_{red}$ can be considered as union of image of multiplication map $F_d'$:$V_{d'} \times V_{d-d'} \to V_d$, where $1<d'<d $. All the above vector space of polynomial can be considered as some affine space, hence they are irreducible. Then I can replace the codomain of $F_{d'}$ as $C_{d'}$, the closure of image($f_{d'}$). And the fiber of $x^2$ is one-dimensional. Then $F_{d'}$ is dominant and we have dim$V_{d'}$+dim$V_{d-d'}$$\ge$C_{d'}$\ge$dim$V_{d'}$+dim$V_{d-d'}-1$. Every $C_d'$ is irreducible, since it is the closure of irreducible set. $C_{1}$ is the component that has the largest dimension among $C_{d'}$. So now the question is just what is the dimension of $C_1$, which I am looking for. Could you please help?",['algebraic-geometry']
1480536,Find element with order 12 of multiplicative group using CRT,"I have been stuck on this question for a long time and don't really understand how the Chinese remainder the is related to the order of a unit. Use the Chinese Remainder Theorem to find an element of order 12 in G =
(Z/105Z)^×. Are there any elements of larger order in G? Here G is the multiplicative ring mod 105.","['cryptography', 'number-theory', 'modular-arithmetic', 'group-theory', 'chinese-remainder-theorem']"
1480545,Proving Cartan's magic formula using homotopy,"On page 198 of Arnold's Mathematical Methods of Classical Mechanics , he asks the reader to prove Cartan's formula
$$\tag{1}L_X=\mathrm{d}i_X+i_X\mathrm{d}$$
where $L_X$ is the Lie derivative wrt. $X$, $\mathrm{d}$ is the exterior derivative, and $i_X$ is the interior derivative (interior product). I am aware of the ""usual"" proof, i.e. to show that the action of $L_X$ on functions and differentials agrees with that of the action of the rhs. of (1). From that one may show this equality holds on all $p$-forms. However, Arnold offers a hint that completely changes the nature of the problem: We denote by $H$ the ""homotopy operator"" associating to a $k$-chain $\gamma: \sigma\to M$ the $(k + 1)$-chain $H\gamma: (I \times \sigma) \to M$ according to the formula $(H\gamma)(t, x) = g^t\gamma(x)$ (where $I = [0, 1]$).
  Then $g^1\gamma - \gamma = \partial(H\gamma) + H(\partial\gamma).$ ($g^t$ is the flow of $X$. I understand how to obtain the equation for the boundary of the homotopy of $\gamma$.) Since we are given the equation for the boundary of $H\gamma$, I thought it would be a good idea to integrate the differential of a $k$-form $\omega$ over $H\gamma$ and use Stokes' theorem, followed by the equation for the boundary:
$$\int_{H\gamma}\mathrm{d}\omega=\int_{\partial(H\gamma)}\omega=\int_{g^1\gamma-\gamma-H(\partial\gamma)}\omega$$
I don't see how this helps. Alternatively, on the right hand side, we can use the equation $\int_{f(D)}\omega=\int_Df^*\omega$ ($f^*$ is the pullback of $f$) to write
$$\int_{H\gamma}\mathrm{d}\omega=\int_{I\times\sigma}(H\gamma)^*\mathrm{d}\omega$$
Unfortunately, I don't know how to calculate $(H\gamma)^*\mathrm{d}\omega$. How does one continue here?","['differential-geometry', 'lie-derivative', 'homotopy-theory']"
1480590,How can I visualize the Cartesian product of sets?,"I saw the question asking about intervals and simple Cartesian products, but how can I visualize things like $S^1 \times S^1$, the Cartesian product of the unit 1-sphere? I understand that this is a Torus, but what should my thought process be here?","['geometry', 'general-topology']"
1480646,Definition of Riemannian Metric,"Let $(M, g)$ be a Riemannian manifold. Standard definitions of a Riemannian metric $g$ states that $g$ specifies a symmetric, bilinear, positive definite form on each tangent space $T_{p}M$ that varies smoothly with $p$. Why do we not require $g$ to satisfy the triangle inequality in our definition of a Riemannian metric? Is it simply because all we really need to study geometry is an inner product structure which induces a distance function that satisfies the usual definition of a metric?","['differential-topology', 'differential-geometry', 'riemannian-geometry', 'terminology']"
1480651,Is $f(x) = \frac{x + 1}{x + 2}$ a function?,"My discrete mathematics book has the following problem: 22. Determine whether each of these functions is a bijection from $\mathbb{R} \to  \mathbb{R}.$ c) $f (x) = \frac{x + 1}{x + 2}$ Since one element of the domain doesn't have an image, namely when $x = -2$ , is $f(x) = \frac{x + 1}{x + 2}$ even a function?","['rational-functions', 'functions']"
1480670,"If one of two sets has larger cardinality, there is a map onto the other set",Let A and B be sets with the cardinality of A less than or equal to B. Show there exists an onto map from B to A. I am struggling with this proof. I don't know how to show this. Any help would be greatly appreciated,"['elementary-set-theory', 'cardinals']"
1480671,How to prove the interchange of integral and expectation,"How to prove $\int_{0}^{\infty}{h(t)\mathbb{E}(I(X>t))dt}=\mathbb{E}(\int_{0}^{\infty}{h(t)I(X>t)dt})$.
Can I treat $h(t)$ as a constant respect to $X$? Then, directly get the result? The point is I do not understand what $\mathbb{E}(\int_{0}^{\infty}{h(t)I(X>t)dt})$ is.","['probability-theory', 'measure-theory']"
1480675,"If $x^{x^4} = 4$, what is the value of $x^{x^2} + x^{x^8}$? [duplicate]","This question already has an answer here : Finding the value of $x^{x^2}+x^{x^6}$ given that $x^{x^4}=4$ (1 answer) Closed 8 years ago . If $x^{x^4} = 4$, what is the value of $x^{x^2} + x^{x^8}$ ? I can find by trial and error, that $x=\sqrt 2$. But, what is the general process to answer questions like this?","['exponentiation', 'algebra-precalculus']"
1480792,How to evaluate $ \int_0^\infty \frac{\log x}{(x^2+a^2)^2} dx $,"Evaluate $$  \int_0^\infty \frac{\log x}{(x^2+a^2)^2} dx $$ $$(a>0) $$ How can I use contour appropriately? What is the meaning of this integral? (additionally posted) I tried to solve this problem. First, I take a branch $$  \Omega=\mathbb C - \{z|\text{Re}(z)=0\; \text{and} \; \text{Im}(z)\le0\}  $$ Then ${\log_\Omega z}=\log r +i\theta (-\frac{\pi}{2}\lt\theta\lt\frac{3\pi}{2})$ Now, $\frac{\log z}{(z^2+a^2)^2}$ is holomorphic in $\Omega - \{ai\}$ with double poles at $ai$. Now I'll take the contour which forms an indented semicircle. For any $0\lt\epsilon\lt{a}$, where $\max (1,a)\lt R$, $\Gamma_{R,\epsilon}\subseteq\Omega - \{ai\}$ and in $\Omega$, $i=e^{i\pi/2}$. Now using the residue formula, $$2\pi{i}\operatorname*{Res}_{z=ai}\frac{\log_\Omega{z}}{(z^2+a^2)^2}=2\pi{i}\operatorname*{lim}_{z\to ai}\frac{d}{dz}(z-ai)^2\frac{\log_\Omega{z}}{(z^2+a^2)^2}=\frac{\pi}{2a^3}(\log_\Omega{ai}-1)$$ Now, the last part, take $i=e^{i\pi/2}$, then is equal to $\frac{\pi}{2a^3}(\log{a}-1+i\pi/2)$ So, I can split integrals by four parts, $$\int_{\epsilon}^R dz + \int_{\Gamma_R} dz + \int_{-R}^{-\epsilon} dz + \int_{\Gamma_\epsilon} dz$$ First, evaluate the second part, $$\left|\int_{\Gamma_R} dz\right|\le\int_0^{\pi}\left|\frac{\log_\Omega{Re^{i\theta}}}{(R^2e^{2i\theta}+a^2)^2}iRe^{i\theta}\right|d\theta$$ Note that $$\left|\log_\Omega{Re^{i\theta}}\right|=\left|\log R+i\theta\right|\le\left|\log R\right|+|\theta|$$
$$\left|R^2e^{2i\theta}+a^2\right|\ge R^2-a^2\quad (R\gt a)$$ Then, 2nd part $\le\frac{R(\pi R+\frac{\pi^2}{2})}{(R^2+a^2)^2}\to 0\; \text{as} \; R \to \infty\quad \left|\log R\right|\lt R\;\text{where}\;(R\gt 1)$ So, 4th part similarly, goes to $\;0$. Then 3rd part, substitute for $\;t=-z$, $$\int_\epsilon^{R}\frac{\log t}{(t^2+a^2)^2}dt + i\pi\int_\epsilon^{R}\frac{dt}{(t^2+a^2)^2}$$ And $\;i\pi\lim\limits_{{\epsilon \to 0},\;{R\to\infty}}\int_\epsilon^{R}\frac{dt}{(t^2+a^2)^2}=\frac{\pi}{4a^3}$ With tedious calculations, I got $\frac{\pi}{4a^3}(\log a -1)$.","['contour-integration', 'complex-analysis']"
1480815,Topology on $\text{Homeo}(X)$ Which Captures Topological Group Actions.,"Definition. Let $G$ be a group and $X$ be any set.
We may define a group action of $G$ on $X$ as map $\cdot: G\times X\to X$ such that $e\cdot x=x$ for all $x\in X$ and $g\cdot(h\cdot x)=gh\cdot x$ for all $g, h\in G$ and $x\in X$ (Here, of course, $g\cdot x$ is just a way of writing $\cdot(g, x)$). Alternatively, we may equivalently say that a group action of $G$ on $X$ is a group homomorphism $G\to \text{Bijections}(X)$, where $\text{Bijections}(X)$ is the set of all the bijections of $X$ which makes a group under composition (This is the permutation group on $X$. I have avoided the use of the notation $S_X$). Definition. Now suppose $G$ is any group and $X$ be a topological space.
We may say that $G$ acts on $X$ if there is a map $\cdot:G\times X\to X$ such that $\cdot$ is an action when $X$ is considered as a set along with an extra condition that the map $x\mapsto g\cdot x:X\to X$ is continuous for all $g\in G$. This may again be equivalently phrased as follows: A group action of $G$ on a topological space $X$ is a group homomorphism $G\to \text{Homeo}(X)$, where $\text{Homeo}(X)$ is the set of all the homoemorphism $X\to X$ under composition. The ""alternative descriptions"" have a sense of uniformity. In fact, if $X$ is any object, then we may say that an action of $G$ on $X$ is a homomorphism $G\to \text{Aut}(X)$. My Question is the following: Suppose that $G$ is a topological group, that is, $G$ has a topology under which the binary operation and the inverse map are continuous.
Let $X$ be a topological space.
The standard definition of a continuous action of $G$ on $X$ is a continuous map $G\times X\to X$ which is also a group action when $X$ is thought of only as a set. What I was wondering is can we give a topology on $\text{Homeo}(X)$ such that a continuous group homomorphisms correspond exactly to continuous actions of $G$ on $X$.","['general-topology', 'group-actions']"
1480825,What are the elements of $2^A$ if $A$ is a set,"I have always seen $2^A$ as an alternative notation for the power set of $A$, so I always assumed $2^A$ must contain the same elements as does $P(A).$ Having just seen the proof of bijection between $2^A$ and $P(A)$, I am not so sure anymore. That proof (using characteristic function) only(?) makes sense if $2^A$ contains only two elements. But then I can't seem to make sense of the elements in $2^A$. My thinking is $2 = \{\emptyset, \{\emptyset\}\}$ if $0 = \emptyset$ and $1 = \{\emptyset \}$. So, then $2^A = \{\emptyset, \{\emptyset\}\}^A$, but what does that even mean? Please, elaborate on this. Thanks.","['elementary-set-theory', 'notation']"
1480831,"If $a + b + c + d = 45$, how many combinations are there of $a,b,c$, and $d$ if $a \le 5$ and $b \le 3$?","I'm stumped on binomial coefficients and counting problems in discrete math. To be clear, this is not the same problem I'm having to do for homework. I changed the numbers around, but had to include a constant as the answer for the sake of time. How many combinations of a, b, c, and d are there when $a + b + c + d = 45$, $a \leq 5$ and $b \leq 3$? EDIT: I want a general answer, so I can know HOW to solve the problem. So, a general formula would be nice.","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
1480899,How to solve recurrence $T(n) = nT(n - 1) + 1$,"Assume $T(n) = \Theta(1)$ for $n \leq 1$. Using iterative substitution. So far I have: \begin{align*}
&T(n) = nT(n - 1) + 1\\
&= n((n - 1)T(n - 2) + 1) + 1\\
&= n(n - 1)T(n - 2) + n + 1
\end{align*} I'm stuck on how I'm supposed to get the asymptotic value from this. Or how would I keep expanding? Thanks!","['asymptotics', 'recurrence-relations', 'discrete-mathematics']"
