question_id,title,body,tags
996628,Binomial theorem - a special case. Calculate sums.,"I have just started my first course in discrete math and have some reflections. If I want to calculate the sum ${n \choose 0}+{n \choose 1}x+{n \choose 2}x^2+...+{n \choose n-1}x^{n-1}+{n \choose n}x^n$,    (1) where $n$ is a natural number, I can effectively use the binomial theorem to see that the sum equals $(x+1)^n$. I can also give a combinatorial explanation for it which indeed is one way to prove the aforementioned theorem. Many basic ""standard exercises"" ask me to calculate sums on this form with different values of $x$ and in these cases I have just applied the binomial theorem and quickly got an satisfying answer. But after some reflections it now feels like I´m ""attacking"" the problems from behind, with the proviso that I knew the sum took the form of a binomial expansion. Maybe this is a tool in problem solving? As an example: For $x=10$ in the sum (1). I would see that $x=10$ just got substituted into the binomial expansion of $(x+1)^n$ and so the answer would be $11^n$. But is there any other ""easy"" way to see that the result of (1). is $(x+1)^n$
without starting out with just recognizing the form of the sum? Let´s say I didn´t recognize that it was the binomial expansion of $(x+1)^n$ at first, how would I convince myself that´s clearly the case? Is there maybe some nice combinatorial explanations to attack the problem from this way also? I do understand that I´ve already might have solve the problem in a effective way, but my reflections worries me that I have missed something fundamental in the theory. I prefer to achieve a deeper understanding of concepts than just memorizing facts.","['discrete-mathematics', 'combinatorics']"
996643,Selecting a Random Point Inside a Cube,"A point $P$ is selected at random inside a cube. Find the probability that $\angle APB \geq 135^o$, where $\overline{AB}$ is a body diagonal of the cube. I am not able to come up with the right condition or the right variable to integrate. Geometrically, I think, $P$ has to move in a region which is an intersection of two spheres and the given cube. I am not able to visualise that out properly too. Please help me out. Thank you.","['geometry', 'probability', 'geometric-probability']"
996651,weak convergence of a pair of random elements,"Consider two sequences $(X_n)$ and $(Y_n)$ of random elements in some nice (e.g. Polish) space s.t. $X_n\Rightarrow X$ and $Y_n\Rightarrow Y$ (""$\Rightarrow$"" denotes weak convergence). Then we know that in general $(X_n,Y_n)\Rightarrow(X,Y)$ doesn't hold. However, if for instance $Y=c$ is deterministic, then $(X_n,Y_n)\Rightarrow(X,c)$ is true. One can find this in every basic book on proba theory. Now are there any more interesting conditions apart from the one I gave where one still gets weak convergence of the pair $(X_n,Y_n)$? Like $(X_n,Y_n)$ independent, or somehow mixing. Or $X_n$ and $Y_n$ independent/mixing. Are there some results out there? The weaker the condition, the better ;)","['probability-theory', 'weak-convergence']"
996654,How to solve this to find the Null Space,"What I did: I put this into reduced row echelon form: $$\begin{bmatrix} 1 & -2 & 2 & 4 \\ 0 & 0 & 1 & 1 \\ 0 & 0 & 0 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix}$$ It is clear that the $r(M)=2$, because there are two independent rows. Now for the null space, I wrote down the equations from the reduced row echelon form: $$x-2y+2z+4t=0$$ $$z+t=0$$ I can't seem to write $x$ and $y$ separately in terms of $z$ and $t$. Any hints?","['vector-spaces', 'linear-algebra']"
996668,Solve $ \int_{0}^{\infty} \sin^2 \left(\frac{1}{x}\right)\mathrm{d}x$,"I think this integral does not converge. I want to  estimate downward the integral, but don't know how to.",['integration']
996679,Question about dimension of varieties: where is this hypothesis necessary?,"I found the following result on the web: Theorem. Let $f:X\rightarrow Y$ be a morphism of varieties, and assume that the dimension of all fibers $n=f^{-1}(P)$ is the same for all $P\in Y$. Then $\dim X=\dim Y+n$. Question 1: Should I also ask that all the fibers are irreducible (to enable me to talk about its dimension)? Then the proof goes by induction on $\dim Y$, with the case $\dim Y=0$ trivial, since $Y$ must be a point. On the inductive step, we may assume $Y$ is affine. For a nonzero regular function $g\in \mathcal{O}_Y(Y)$, we have that $Z(g)=\{y\in Y:g(y)=0\}$ has pure codimension $1$, hence any of its irreducible components has codimension $1$. Now, putting $X'=f^{-1}(Y')$, where $Y'$ is some irreducible component of $Z(g)$, we have by inductive hypothesis that $\dim X=\dim X'+1=\dim Y'+n+1=\dim Y+n$. My attempt to justify the above conclusion is to observe that $$X'=Z(g\circ f)=\{x\in X:g\circ f(x)=0\}.$$ So, if $g\circ f$ is nonzero, then it has codimension $1$ on $X$ and everything works fine. However, I cannot guarantee this (at least I don't see how), so: Question 2: The hypothesis about the dimension of the fibers can be used to justify my attempt? If not, how the hypothesis should be used to finish the inductive proof? Thank you very much for your attention.",['algebraic-geometry']
996685,Evaluate the limit using only the following results,"Let $u_2>u_1>0$ and also let $u_{n+1}=\sqrt{u_n u_{n-1}}$ for all $n \geq 2$. Then prove that the sequence $\{u_n\}$ converges. For this, use of only the following results is permissible, Archimedean Property . For two sequence $\{x_n\}$ and $\{y_n\}$ $$\displaystyle\lim_{n\to\infty}\left(x_n+y_n\right)=\displaystyle\lim_{n\to\infty}x_n+\displaystyle\lim_{n\to\infty}y_n$$ $$\displaystyle\lim_{n\to\infty}\left(x_n\cdot y_n\right)=\left(\displaystyle\lim_{n\to\infty}x_n\right)\cdot\left(\displaystyle\lim_{n\to\infty}y_n\right)$$ provided they exists. For a sequence $\{z_n\}$, the limit $\displaystyle\lim_{n\to\infty}z_n$ doesn't exist is equivalent to saying that, $$\exists \varepsilon>0\mid \left\lvert z_n-l\right\rvert\geq\varepsilon \ \forall l \in \mathbb{R} \land \forall n\geq n_0 (\in \mathbb {N})$$ I have been able to prove that $\displaystyle\lim_{n\to\infty}\left(u_n u_{n+1}^2\right)=u_1u_2^2$. Now one can conclude from 1 and 2 that the limit must be $\sqrt[3]{u_1u_2^2}$ but that happens only if we can prove that the limits exist. And this is exactly where I am stuck. Using only the three mentioned results I can't prove that. Any help will be appreciated.","['epsilon-delta', 'real-analysis', 'limits']"
996701,"Solve $y'= \sin(x+y) ,\ \ y(0) = -\frac{\pi}{2}$","How can I solve this differential equation $$y'= \sin(x+y) ,\ \  y(0) = -\frac{\pi}{2}, -\infty < x < \infty$$ I tried to denote $z=x+y$ but I got an unfamiliar integral. Please help.
Thanks",['ordinary-differential-equations']
996708,Direct way to solve $y' = y^2$,"My problem is to solve the ODE $y' = y^2$. What I would want to do is to divide by $y^2$ then integrate : it yields $y = \frac{1}{c-x}$ on an interval where $y$ does not vanish, then by continuity it is ok since there would be no way $y$ could actually vanish : it's done. Sorry if I have been a bit unclear, but my problem is not here ; what I am asking you is : Is there a direct way to solve this ? By direct I mean avoiding the discussion about $y$ vanishing, for example like the way $y' = y$ is classically solved (multiply by $e^{-x}$ then integrate). (My ultimate goal is this to show that if $y' - y^2 \rightarrow_{+\infty} 0$ then $y \rightarrow_{+\infty} 0 $)",['ordinary-differential-equations']
996710,Why is $|x| \neq x$?,"I was just thinking about the absolute value function. Why does the following equality not hold? $$|x| = \sqrt{x^2} = (x^{2})^{1/2} = x^1 = x$$ After all, there are clearly some values of $|x|$ that are not equal to $x$. Is this a domain/range issue?","['calculus', 'algebra-precalculus']"
996732,"Do there exist an infinite number of integer-solutions $(x,y,z)$ of $x^x\cdot y^y=z^z$ where $1\lt x\le y$?","Question : Do there exist an infinite number of integer-solutions $(x,y,z)$ of $x^x\cdot y^y=z^z$ where $1\lt x\le y$ ? Motivation : After struggling to find a solution, I've just got one solution, which is 
$$(x,y,z)=(1679616, 2985984, 4478976).$$ In the following, I'm going to write how I got this solution. Letting $d$ be the greatest common divisor of $x,y,z$, we can represent
$$x=ad, y=bd, z=cd$$
where $a,b,c$ are coprimes with each other. Then, we get
$$d^{a+b-c}\cdot a^a\cdot b^b=c^c.$$ In the following, let's consider without the condition $x\le y$. Here, I suppose $$a=2^m, b=3^n, a+b-c=1.$$ (As a result, this supposition works.) Then, we get
$$d=\frac{c^c}{2^{ma}\cdot 3^{nb}}.$$ Hence, letting $c=2^k\cdot 3^l$, if 
$$kc\ge ma=m\cdot 2^m, lc\ge nb=n\cdot 3^n,$$
then $d$ is an integer. Since $(m,n)=(4,2)$ satisfies the above conditions, then we get $d=2^8\cdot 3^6=186624.$ Hence we can get 
$$x=9d=2^8\cdot 3^8=1679616, y=16d=2^{12}\cdot 3^6=2985984, z=24d=2^{11}\cdot 3^7=4478976.$$
Note that here I interchanged $x$ and $y$. P.S : I was surprised to get this solution because I got this almost by chance. So, I don't know the other solutions. If you have any helpful information, please teach me.","['diophantine-equations', 'number-theory']"
996755,"If all Subgroups are Cyclic, is group Cylic? [duplicate]","This question already has answers here : Proper subgroups of non-cyclic p-group cannot be all cyclic? (2 answers) Give an example of a noncyclic Abelian group all of whose proper subgroups are cyclic. (7 answers) Closed 9 years ago . I am having difficulty seeing if it is the case that if all subgroups of a group are cyclic, that the group itself is cyclic.",['group-theory']
996790,Property of Entire Functions,Suppose $f$ and $g$ are entire functions with $|f(z)|\leq|g(z)|$ for all $z$. How can we show that $f=cg$ for some complex constant $c$? Thanks for any help :),['complex-analysis']
996797,Sorting out some integrals from physics,"I'm doing some physics for a change, and I'm trying to sort things out a bit. From the definitions of mass, torque, momentum and angular momentum I've come up with the following integrals:
\begin{equation}
\int_D \rho(r)dV:\qquad\text{mass}\\
\int_D r\ \rho(r)dV:\qquad\text{center of mass times total mass}\\
\int_D \|r\|^2\ \rho(r)dV:\qquad\text{moment of inertia}\\
\int_D \frac{dr}{dt}\rho(r)dV:\qquad\text{momentum}\\
\int_D r\times\frac{dr}{dt}\rho(r)dV:\qquad\text{angular momentum}\\
\int_D r\times\frac{d^2r}{dt^2}\rho(r)dV:\qquad\text{torque (not sure)}\\
\end{equation}
where $dV=d\lambda^3$ is the volume form, $D$ is some bounded domain in $\mathbb{R^3}$, $r:\mathbb{R}\rightarrow\mathbb{R^3}$ is the position vector and $\rho:\mathbb{R^3}\rightarrow\mathbb{R}$ is the mass density function. They are supposed to be smooth. All these integrals seem to originate from some common ""ancestor"", some kind of moment generating function. My question is: is it true? i.e. is it possible to order these integrals in some sensible way, or to derive them from a single function?","['mathematical-physics', 'moment-generating-functions', 'integration', 'physics']"
996802,why there is no derivative in sharp turns?,"why there is no derivative in sharp turns in functions? I understand that it may be difficult or impossible to actually draw a tangent at that point, but is there a mathematical proof that there is no derivative in sharp turns? thanks!",['derivatives']
996831,Product to vertices in triangle maximal,"Suppose we're given a triangle $ABC$. At which interior point $T$ is the product of distances $|AT|\cdot |BT|\cdot |CT|$ maximal? Is it a known point, like the centroid or incenter?",['geometry']
996863,Every $3\times 3$ square has even number of painted cells,"Given a $1000\times 1000$ board. We paint some cells (at least one) so that in every $3\times 3$ square, an even number of cells are painted. What is the minimum number of painted cells? One way to paint the cells is to paint every cell except the cells $(3k,3k)$ (assuming the cells are arranged by coordinates from $(1,1)$ to $(1000,1000)$). Every $3\times 3$ square contains exactly one such cell, so $8$ cells are painted. In total, $1000^2-333^2=889111$ cells are painted. We should be able to reduce this number. [Source: Based on Russian competition problem]","['extremal-combinatorics', 'contest-math', 'combinatorics']"
996910,"There is no holomorphic function in $\Omega=\{0<r<\lvert z\rvert <R\}$ with real part $u(x,y)=\frac{1}{2}\log(x^2+y^2)$","Consider $u(x,y)=\dfrac{\text{log}(x^2+y^2)}{2}$ on $\Omega=\{0<r<|z|<R\}.$ Show there is no holomorphic function on $\Omega$ whose real part is $u.$ My attempt: I understand that $u$ is real part of $\text{log}(z)$ and $\text{log}(z)$ is not well defined on $\Omega.$ How do I use this fact and identity theorem to show there isn't any holomorphic function on $\Omega$ whose real part is $u \ ?$ Thank you.","['harmonic-functions', 'complex-analysis', 'analysis']"
996949,What is the most elementary way of proving a sequence is free of non-trivial squares?,"Given the sequence A001921 $$
0, 7, 104, 1455, 20272, 282359, 3932760, 54776287, 762935264, 10626317415, 148005508552, 2061450802319, 28712305723920, 399910829332567, \dots
$$
which obeys the recurrence relation
$$
  a_0 := 0,\ a_1 := 7, \quad a_{n+2} = 14a_{n+1} - a_n + 6.
$$ How can I prove (or, I suppose, disprove) my conjecture that $a_0 = 0$ is the only square? In case it helps, the conjecture is equivalent to saying that $x$ and $3x^2+3x+1$ cannot both be [positive integer] squares, though I am particularly interested in any general method of proof that attacks the recurrence relation directly. EDIT: Here's an application .","['recurrence-relations', 'sequences-and-series', 'divisibility', 'elementary-number-theory', 'square-numbers']"
996950,Find the value of k which makes f a density function.,"Observe the following probability density function for a continuous random variable X
$$f (x) = \begin{cases}
k\sqrt x (1-x) &\text{ for }x\in(0,1)\\
 0 &\text{ otherwise}
\end{cases}
$$ Find the value of $k$ which makes $f$ a density function. My thoughts, is it the integral from $0$ to $1$ of $f(x)$?","['statistics', 'probability-distributions', 'probability']"
996970,Dual space of a finite dimensional normed space,"My lecturer gave us this result today in class, but he didn't give a proof, he said we can prove it ourselves, only I'm really struggling to see how to do it. Let $E$ be a normed space with dual $E'$. Then $E$ is finite dimensional if and only if $E'$ is finite dimensional, and in fact $\dim{E} =\dim{E'}$. Would appreciate any input!",['functional-analysis']
996985,Proving that $\sum_{k=0}^\infty\frac{2^{-5k}(6k+1)((2k-1)!!)^3}{4(k!)^3} = {1\over\pi}$,"While trying to prove that $$(1)\qquad x\sum_{k=0}^\infty\frac{2^{-5k}(6k+1)((2k-1)!!)^3}{4(k!)^3} = 1 \implies x=\pi$$ I got to a point, using W|A, where I have to prove that $$\color{red}{(2)\qquad \pi = -\frac{8 \left (\sqrt{16-3 K\left ({1\over4} (2-\sqrt{3})\right )^2\, _3 F_2\left ({3\over2}, {3\over2}, {3\over2};\,2, 2;{1\over4}\right )}-4\right )}{\left (3\, _3 F_2\left ({3\over2}, {3\over2}, {3\over2};\,2, 2;\,{1\over4}\right )\right )}}$$ Where $K(x)$ is the complete elliptic K function, and $_xF_y(a_1 ... a_p;b_1 ... b_q; z)$ is the generalized hypergeometric function. IMPORTANT: As user153012 pointed out, there is likely an error in $(2)$, as I translated it from mathematica to Latex by hand, so I'll just post the mathematica query so that there is no misunderstanding: -8 (-4 + Sqrt[16 - 3 EllipticK[(2 - Sqrt[3])/4]^2 HypergeometricPFQ[{3/2, 3/2, 3/2}, {2, 2}, 1/4]]))/(3 HypergeometricPFQ[{3/2, 3/2, 3/2}, {2, 2}, 1/4]) Here's a LINK to the query ( If W|A show a message similar to ""Wolfram|Alpha doesn't know how to interpret your input"", just recompute the query by either refreshig the page or pressing the orange and white $=$ sign ). I will be correcting this error asap. Is there a way to prove $(2)$ to be true, or another way to prove $(1)$ to be true (by eliminating the double factorial? I haven't had any success in doing this myself.)? Thanks.","['sequences-and-series', 'pi', 'elliptic-integrals', 'factorial', 'hypergeometric-function']"
996986,How to prove this statement $x \not\in D$ then $x \in B$,"I am quite a beginner writing proofs, that's why I am asking such a simple question. I have an exercise: Suppose A\B ⊆ C ∩D and x ∈ A. Prove (by using proof techniques) that
  if $x \notin D$ then x ∈ B which, I think, I have proved using contrapositive: Initial givens: $A \setminus B \subset C \cap D$ $ x \in A$ If $x \not\in D \rightarrow x \in B$ which I reversed to: $\neg(x \in B) \rightarrow  x \in D$ Now my givens are: $A \setminus B \subset C \cap D$ $ x \in A$ $\neg(x \in B)$ and we want to prove that $x \in D$ So we can say that $x \in A \land x\not\in B$, which is a subset of $C \cap D$, so $x \in C \land x \in D$, so $x \in D$, if $x \not\in B$, which is the contrapositive of the initial statement... Is this a valid proof?","['elementary-set-theory', 'proof-verification']"
997038,Calculate the derivative and find its domain: $\;f(x)= \sqrt{\ln(x)+2}$,I calculated the derivative as $$f'(x) = \frac{1}{2x \sqrt{2+\ln x}}$$ How do I find out the domain?,['derivatives']
997049,Expectation of vector valued functions,"Let $t_1,\ldots,t_m$ be $m$ random variables that are independently and identically drawn from a Bernoulli distribution with a constant parameter $p$. Now, we define some functions of $t_1,\ldots,t_m$, for constant $w_1,\ldots,w_m$, in the following way: $$f_i(t_1,\ldots,t_m)=t_i\mathbf{I}(1-\sum_{j=1}^m w_jt_j\geq 0)$$ where $\mathbf{I}(x\geq 0)=1$ if $x\geq 0$, and $\mathbf{I}(x\geq 0)=0$ if $x< 0$. My question: what is the joint expected value of $f_i$'s as a function of $w_1,\ldots,w_m$ and $p$. $$g_i(w_1,\ldots,w_m,p)=\mathbf{E}[f_i(t_1,\ldots,t_m)]=?$$ Edit: If $f(t_1,\ldots,t_m)=[f_1(t_1,\ldots,t_m),\ldots,f_m(t_1,\ldots,t_m)]^T$, then I am interested in: $$g(w_1,\ldots,w_m,p)=\mathbf{E}_{t_1,\ldots,t_m~\text{iid}\sim Bernoulli(p)}[f(t_1,\ldots,t_m)]$$","['statistics', 'probability', 'expectation']"
997066,A limit evaluating to $2 K$ (Catalan's constant),"Experimentally I discovered the limit below that says that $$\lim_{n\to\infty} \int_0^{\pi/2} \frac{1}{\displaystyle \cos\left(\frac{x}{2}\right)\left(\cos\left(\frac{x}{2}\right)-\cos\left(\frac{x}{2^2}\right)\right)\cdots \left(\cos\left(\frac{x}{2}\right)-\cos\left(\frac{x}{2^{2n+1}}\right)\right)}+\cdots$$
$$+\frac{1}{\displaystyle \cos\left(\frac{x}{2^{2n+1}}\right)\left(\cos\left(\frac{x}{2^{2n+1}}\right)-\cos\left(\frac{x}{2}\right)\right)\cdots \left(\cos\left(\frac{x}{2^{2n+1}}\right)-\cos\left(\frac{x}{2^{2n}}\right)\right)} \ dx=2 K$$ or as @robjohn suggested $$\lim_{n\to\infty}{\Large\int}_0^{\pi/2}\operatorname*{\Large\sum}_{j=1}^{2n+1}\left[\cos\left(\frac{x}{2^j}\right)\prod_{\substack{k=1\\k\ne j}}^{2n+1}\left(\cos\left(\frac{x}{2^j}\right)-\cos\left(\frac{x}{2^k}\right)\right)\right]^{-1}\mathrm{d}x=2 K$$
Do you see any easy way of proving this result?","['calculus', 'definite-integrals', 'limits', 'real-analysis', 'catalans-constant']"
997091,Linear Order relations,"Im having a slight issue grasping the concept of Linear Orders among relations. It was made apparent to me that linear orders must first be partial orders(reflexive, anti-symmetric and transitive) and in addition, for all (a,b)∈A (for example). either (a,b)∈R OR (b,a)∈R but not both. e.g. (1,3)∈R and (3,1)∉R However, my issue is, i feel that this would always be the case as a partial order is antisymmetric anyway Where am I going wrong here?","['relations', 'discrete-mathematics']"
997093,"Every metric space can be isometrically embedded in a Banach space, so that it's a linearly independent set","I'm trying to prove the following:  Every metric space can be isometrically embedded in a Banach space, so that it's a linearly independent set. I came up with the following idea: Let $ (X,d) $ be a metric space. We can take the vector space of all functions from $ X $ to $ \mathbb{R} $. Now we can send an element $ x \in X $ to the function which takes the value $ 1 $ on $ x $ and $ 0 $ everywhere else. This would embed $ X $ in $ \mathbb{R}^X $, so that it would be a linearly independent set and actually a basis. The problem seems to be finding a suitable norm, to make the embedding also an isometry. With that, we could just use the fact that every normed space can be isometrically embedded in a Banach space to get the desired result. Any hints on constructing the metric? Or have I chosen a bad space?","['metric-spaces', 'functional-analysis', 'banach-spaces']"
997099,"Prove, without using Cauchy’s Theorem, that any finite group of even order contains an element of order two","Prove, without using Cauchy’s Theorem, that any finite group $G$ of even order contains an element of order two. [Hint: Let $S = \{\,g ∈ G : g \ne g^{−1}\,\}$. Show that $S$ has even number of elements. Argue that every element not in $S$ and not equal to the identity element has order two]. My Solution: Let $S = \{\,g ∈ G : g \ne g^{−1}\,\}$. If $g ∈ S$ then $g^{-1} ∈ S$. This implies that the number of elements in $S$ must be even. Since $g\ne g^{−1}$, we can eliminate all non-identity elements. Then the number of elements of the group is $2n+1$, where $n$ is the number of pairings and $1$ is the identity element $e$. But we stated that $S$ is even. Therefore, this is a contradiction and $G$ has an element of order $2$.","['finite-groups', 'group-theory']"
997109,Basis of a Kernel,How would i find the basis of the kernel of the differential operator below $$8y'' + 3y' + 7y$$ We know the equation was homogenous and i believe the basis is two dimensional,"['differential', 'ordinary-differential-equations', 'homogeneous-equation']"
997139,Gauss-Green Theorem from generalized Stoke's Theorem.,"I am trying to deduce the next identity (Green-Gauss theorem)  $$\int_\Omega \dfrac{\partial u}{\partial x_i} dx = \int_{\partial \Omega} uv_i dS$$
from the generalized Stoke's theorem for manifolds. Here $u$ is a $C^\infty$ function on an open bounded set $\Omega$ with $C^1$ boundary and $v_i$ denotes the i-th component of the unit normal vector field. I've been trying to define $n-1$ forms on $\Omega$ whose derivatives are $\dfrac{\partial u}{\partial x_i} dx$ to apply the theorem but I cannot prove that those forms have the same integral as $uv_i$ on $\partial \Omega$. Any ideas? Also, I would really appreciate references of the proofs of classical calculus integration results using the generalized Stoke's theorem. Thanks in advance.","['multivariable-calculus', 'integration', 'manifolds-with-boundary']"
997140,Bounded area for any triangle formed by polygons,"Let $P_1,P_2,P_3$ be closed polygons on the plane. Suppose that for any points $A\in P_1$ (meaning $A$ can be inside or on the boudary of $P_1$), $B\in P_2,C\in P_3$, we have $[ABC]\leq 1$. Is it possible that two of $P_1,P_2,P_3$ have area $\geq 4$? What about all three having area $\geq 4$? Here, $[X]$ denotes the area of the polygon $X$. [Source: Hungarian competition problem]","['geometry', 'combinatorial-geometry', 'contest-math']"
997152,Why does $n$-time differentiation of product have the same structure as raising sum to $n$th power?,"A formula for differentiating a product is well known: $$(ab)'=a'b+ab'.$$ At first sight it doesn't resemble anything interesting. But what if we differentiate twice? We'll get $$(ab)''=a''b+2a'b'+ab''.$$ Now this does resemble something: $$(a+b)^2=a^2b^0+2a^1b^1+a^0b^2.$$ Of course, going to the next level now gives us the expected result: $$(ab)'''=a'''b+3a''b'+3a'b''+ab''',$$ in full accordance to known binomial expansion: $$(a+b)^3=a^3b^0+3a^2b^1+3a^1b^2+a^0b^3.$$ I know that binomial expansion stems from distributive law of multiplication over addition. It's easy because integer powers can be interpreted as iterated multiplication. But I can't seem to see any simiar distributive law of differentiation over product. Observing this, I wonder: how to explain this striking similarity between seemingly unrelated things? Can this be explained by some generalized form of distributive law?","['algebra-precalculus', 'derivatives']"
997161,How to compute or simplify this integration?,"Any hints on solving an integration of the following form, $$\int_{x}^{+\infty}\left(1-\frac{1}{1+sy^{-1}}\right) \left(\text{exp}(-\sqrt{y})+ y^{-\frac{1}{2}}(1-\text{exp}(-\sqrt[4]y)\right)dy $$ This arises pretty much in Poisson point processes after using the probability generating function property. I know the above looks pretty much hopeless, I tried using Mathematica and Wolfram Alpha, both don't really help much. I also have $x>0$ and $s>0$ real numbers if that helps. I tried the following Wolfram|Alpha input and it gives a result in terms of $i$ imaginary, I don't understand why. Also is there any valid approximation for which I can say that this integral can be approximately upper and lower bound by?
Thanks in advance for any help.","['improper-integrals', 'integration', 'definite-integrals', 'probability-theory', 'probability-distributions']"
997173,Can you pick a random natural number? And a random real number?,Is it possible to pick a random natural number? How about a random real number? Is the axiom of choice involved in this?,['probability']
997177,A Question about Shuffling a Deck of Cards,"Currently I am following Sheldon Ross' A first course in probability.
And I got stuck in this question: Consider the following technique for shuffling a deck of $n$ cards: For any initial ordering of the cards, go through the deck one card at a time and at each card, flip a fair coin. If the coin comes up-heads, then leave the card where it is; if the coin comes up-tails, then move that card to the end of the deck. After the coin has been flipped $n$ times, say that one round has been completed. For instance, if $n=4$ and the initial ordering is $(1,2,3, 4)$, then if the successive flips result in the outcome $(H,T,T,H)$ then the ordering at the end of the round is $(1,4,2,3)$. Assuming that all possible outcomes of the sequence of $n$ coin flips are equally likely, what is the probability that the ordering after one round is the same as the initial ordering? The book says the answer is $\frac{n+1}{2^n}$, but the answer I got is $\frac{2}{2^n}$ since we have two successive flips that will produce the same ordering (I.e.  $(H,H,...,H)$ and $(T,T,...,T)$)? Thanks on any hint/help.","['probability', 'combinatorics']"
997180,"A geometric assembly: Triangle, circle, square, pentagon.","Let say we have an equilateral triangle and I draw its circumscribed circle, to continue we draw a square in which the previous circle is inscribed. After that we draw the circle circumscribed to the square and to continue the process we plot a regular pentagon in which the previous circle is inscribed and plot its circumscribed circle. Here is a picture: So the question is : Can we continue this process infinitely? I would say that at some point the figure will somehow ""explode"". Any ideas what tools I need to understand this process? As a remark (perhaps false) is to do the inverse processus, starting with an equilateral triangle and drawing this inscribed circle and so one. I guess that the dimension tends to $0$, right?",['geometry']
997193,Product rule for Hessian matrix,"Let $f: \mathbb{R}^n \to \mathbb{R}$ and $g: \mathbb{R}^n \to \mathbb{R}$. Is there a general formula for the Hessian matrix of their product? That is, what is $H(f(x) g(x))$, where $H(f(x)) = \left(\frac{\partial^2 f}{\partial x_i \partial x_j}\right)_{i,j = 1 \dots n}$?","['products', 'partial-derivative', 'real-analysis', 'analysis', 'derivatives']"
997196,Cartesian Product and the empty set,"I am not quite sure about the Cartesian Product in combination with the empty set. 
Let's say: $A := \{\{5\}\}$ and  $B := \{\varnothing\}$. What's the proper Cartesian Product?
Is it $A\times B = \{(\{5\}, \varnothing), (\varnothing, \{5\})\}$ or simply $A\times B = \{\varnothing\}$ because of $A\times \varnothing = \varnothing$? Edit: As Brian M. Scott, Mauro ALLEGRANZA and amWhy said: A×B={({5},∅)} is right. Thank you really much!",['elementary-set-theory']
997198,path metrics without geodesics,"This is a follow-up of this question . Recall that a metric space $(X,d)$ is called a path-metric space if the distance between any two points in $X$ equals the infimum of lengths of paths between these points. Such $(X,d)$ contains a plenty of rectifiable paths (unless $X$ is either empty or is a one-point set). A geodesic between the two points $x, y\in X$ is a 
path $c$ from $x$ to $y$, whose length equals the distance $d(x,y)$. Question. Is there a complete path-metric space $(X,d)$ (of infinite cardinality) such the only geodesics in $(X,d)$ are constant maps to $X$? (I think so, but do not see a clear proof.) Obviously, such space $X$ cannot be locally compact (at any point). Note that in the example given in the linked question, there are pairs of points without geodesics connecting them. Another example (an infinite-dimensional complete Hilbert manifold) is mentioned in this wikipedia article . However, in both examples, the space contains plenty of geodesics (Hilbert manifolds always do). Edit. I just discovered that the same question was posted (in 2010) and answered on Mathoverflow here .","['geometry', 'metric-spaces']"
997210,Misconception of Cantor's Theorem(no seqeuence can contain all real numbers.),"When reading the proof of Cantor's Theorem(the one that says no sequence can contain all reals), I feel unsure. The Cantor's Theorem are proved by contradicting the fact that there are some real number, call it x, in the nested intersection. However, the assumption that all reals are in the sequence leads us to the fact that no element can be in the nested intersection and thus a contradiction. I am wondering what if we let this number, x, put this x in the original sequence. Then what happens?
 I thought about we can apply the same method and just prove it again. So that some number y in real number is still not in the sequence. But we shouldn't have to prove this again. What part of my thoughts went wrong? The proof I am talking about is to use the nested interval theorem to show it. Not the argument Cantor proposed. This proof show the connection with the completeness axiom. Proof: The proof is by contradiction. Suppose that such a sequence A exists. Let $I_0$ be the interval $[0, 1]$.
At least one of the thirds of I0 does not contain A(1). Let I1 be such a third.
At least one of the thirds of I1 does not contain A(2). Let I2 be such a third.
At least one of the thirds of I2 does not contain A(3). Let I3 be such a third.
At least one of the thirds of I3 does not contain A(3). Let I4 be such a third.
Etc.
This way we have constructed a nested sequence
I0 ⊃I1 ⊃I2 ⊃I3 ⊃I4... 4
of compact intervals. We see that the intersection of them is a singleton since the length of the interval is going to zero.
tervals Theorem. Since α∈I1 andA(1)∈/I1,it must be that α=A(1). Since α∈I2 andA(2)∈/I2,it must be that α=A(2). Since α∈I3 andA(3)∈/I3,it must be that α=A(3). Since α∈I4 andA(4)∈/I4,it must be that α=A(4). Etc. This shows that this real number α is not a term in A. Yet we have as
sumed that all real numbers appear as terms in A. A contradiction. The proof is complete!","['elementary-set-theory', 'real-analysis']"
997263,$\frac{d^2 y}{dx^2}-2y=2\tan^3\left(x\right)$,"Problem:
\begin{equation}
\frac{d^2 y}{dx^2}-2y=2\tan^3\left(x\right).
\end{equation}
using the method of undetermined coefficients or variation of parameters, with $y_p\left(x\right)=\tan\left(x\right)$. This is what I have so far:
\begin{equation}
r^2-2=0\implies r=\pm\sqrt{2},\:\:\:\:\:\therefore\:\: C_1 e^{\sqrt{2}t}+C_2 e^{-\sqrt{2}t},
\end{equation}
so that is my ""complimentary solution"" but I do not know what to do with it.",['ordinary-differential-equations']
997292,"How to prove that $L^p [0,1]$ isn't induced by an inner product? for $p\neq 2$","I'd like to know how could I prove that $L^p [0,1]$ isn't induced by an inner product? (For $p\neq 2$, including $p=\inf$). It is clear to me that I would need to find two functions $f$, $g$ in $L^p$ that would not fulfill the parallelogram-law. I'm having trouble finding these functions (for both finite and infinite cases).
Could you guide me how to find such functions? what intuition is there for these kind of questions? What would be special about them? Any guidenss would be blessed.
Thank you","['functional-analysis', 'inner-products', 'lebesgue-integral', 'lp-spaces', 'complex-analysis']"
997294,How is it true that zero is neither a positive number nor a negative number?,"At first, the number zero looked like it was positive to me because positive numbers can be written with or without a plus sign to the left of them, but it's false.  I was surprised when I heard that zero is neither positive nor negative, but it's still a number and it's still even.  At least I know it's in between the positive and the negative numbers, so that must be why.  Also, because zero is neither negative nor positive, it's also known as neutral.  Am I on the right track?  Also, is there such thing as ±0, since it's neutral?  That's why I put the plus/minus sign there.  Is this how zero is neither negative nor positive?  I can see happy faces in your answers!",['number-theory']
997295,Can 2 different random variables have the same CDF?,"I'm looking for proof that two different random variables can have the same Cumulative Distribution Function; in other words, I'd like to disprove that a CDF uniquely defines a random variable. (Probably a silly question, but I couldn't find anything usable so far).","['statistics', 'probability-distributions', 'probability', 'probability-theory']"
997301,Expectation and Variance of stochastic equation,"My questions is related to this question: Stochastic Differential equation, expectation and variance I.e how do you calculate the variance and expectation of $U_t = e^{-\gamma t}U_0 + \int_0^t e^{\gamma (s-t)}\sigma dX_s$?","['stochastic-processes', 'ordinary-differential-equations', 'expectation']"
997327,distribution of $\|P_VX\|^2$ with orthogonal projection $P$ onto $V$,"We've had the following question discussed today but without any result: Let $X_1,\dots,X_d$ be random variables, iid and $X_n\sim N(\mu_n,1)$. How can we describe the distribution of $\|P_VX\|^2$ with $X=(X_1,\dots,X_d)$, $V\subset \mathbb R^d$ and an orthogonal projection $P$?","['probability-theory', 'normal-distribution', 'probability-distributions']"
997338,Definitions of a very ample invertible sheaf,"At the moment, I'm struggling with the following definitions i) and ii). I'd like to know why they are equivalent: Let  $\mathcal{L}$ be an invertible sheaf on a variety X. i) $\mathcal{L}$ is called very ample , if there is an embedding $i\colon X \rightarrow \mathbb{P}^n$ such that $\mathcal{L}$ is isomorphic to $i^{∗}\mathcal{O}_{\mathbb{P}^n}(1)$. ii) For a basis $f_0, \dots ,f_r$ of $\Gamma(X, \mathcal{L})$ we define 
$$\varphi \colon X \rightarrow \mathbb{P}^r, \quad x \mapsto [f_0(x), \dots , f_r(x)].$$ The invertible sheaf $\mathcal{L}$ is called very ample , if it is base-point-free and $\varphi$ is a immersion. Thanks in advance!","['sheaf-theory', 'algebraic-geometry']"
997359,$\frac{1}{1+2}+\frac{1}{1+2+3}+\dots+\frac{1}{1+2+3+\dots+x}=\frac{2011}{2013}$,"I want to see OTHER approaches than this one. Make sure they are significantly different and not a direct restatement. $$\frac{1}{1+2}+\frac{1}{1+2+3}+\dots+\frac{1}{1+2+3+\dots+x}=\frac{2011}{2013}\tag{1}$$ $$\sum_{n=1}^x n=\frac{x(x+1)}{2} \; \forall x >0\tag{2}$$ $$\begin{align*}
(1)&\stackrel{(2)}{\iff} \frac{2}{2\cdot 3}+\frac{2}{3\cdot 4}+\frac{2}{4\cdot 5}+\dots+\frac{2}{x(x+1)}=\frac{2011}{2013}\\\\
&\iff 2\left (\frac12 -\frac13+\frac13-\frac14+\frac14-\dots+\frac{1}{x}-\frac{1}{x+1}\right )=\frac{2011}{2013}\\\\
&\iff 1-\frac{2}{x+1}=\frac{2011}{2013}\\\\
&\iff x=2012
\end{align*}$$","['alternative-proof', 'sequences-and-series', 'algebra-precalculus']"
997381,Show that f solves the so called wave equation,"Task $\text{Let } \; c \in \mathbb{R} \; \text{ be a given parameter, with } \; c > 0$ $\text{ Show that } \; f: (\mathbb{R}^3 \setminus \{ \vec{0} \}) \times \mathbb{R} \to \mathbb{R} \; \text{ with:}$ $$
f(x,y,z,t) :=  \frac {\cos(\|(x,y,z)\|_2 -ct)}{\|(x,y,z)\|_2}
$$ $\text{ solves the so called }$ wave equation : $$
\frac {\partial^²f}{\partial x^2}(x,y,z,t) + \frac {\partial^²f}{\partial y^2}(x,y,z,t) + \frac {\partial^²f}{\partial z^2}(x,y,z,t) - \frac {1}{c^2} \frac {\partial^²f}{\partial t^2}(x,y,z,t) = 0
$$ $\text{for all } \; (x,y,z,t) \in (\mathbb{R}^3 \setminus \{ \vec{0} \}) \times \mathbb{R}$ This task seems to require more thinking and knowledge than actual calculations, since calculating all those by hand and adding them up will only lead to a giant unsolvable equation IMHO. There is a extra hint given to support this: You may use following rule: $ \text{Let } \; g \in \mathscr{C}^2(\mathbb{R}), r: \mathbb{R}^3  \setminus \{ \vec{0} \} \to \mathbb{R} \text{ with } r(\vec{x}) := \|\vec{x}\|_2 \; \text { and } \; \vec{x} \in \mathbb{R}^3  \setminus \{ \vec{0} \} \; \text{ then: }$ $$
\frac {\partial^2 (g \circ r)}{\partial x_i^2}(\vec{x}) = \frac {g'(r(\vec{x}))}{r(\vec{x})} + \left( g''(r(\vec{x})) - \frac {g'(r(\vec{x}))}{r(\vec{x})} \right) \frac {x_i^2}{r^2(\vec{x})} \quad \text {for $\quad$ i = 1,2,3}
$$ My Efforts I tried to simply calculate the partial derivates for x,y,z and t and put them into the equation, but even with the use of the hint I ended up with a giant mess. The partial derivates for t should be fairly easy: $$
\frac {\partial^2 f}{\partial t^2} = -\frac {c^2\cos(\|(x,y,z)\|_2-ct)}{\|(x,y,z)\|_2}
$$ But I struggle to make use of the hint, after a couple of tries I came up with this: $$
\text{Let } \; g(x) = \frac{\cos(x-ct)}{x} \; \text{ and } \; \vec{x} = (x,y,z)
$$ $$
=> (g \circ r)(\vec{x}) = f(\vec{x},t) = f(x,y,z,t)
$$ $$
=> \frac {\partial^2 f}{\partial x_i^2} (\vec{x},t) = \frac {\partial^2 (g \circ r)}{\partial x_i^2} (\vec{x})$$
$$
= -\frac{\|\vec{x}\|_2 \sin(\|\vec{x}\|_2 - ct) + \cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_2} + \left( \frac{2\|\vec{x}\|_2 \sin(\|\vec{x}\|_2 - ct) + (2 - \|\vec{x}\|_4) \cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_6}  +  \frac{\|\vec{x}\|_2 \sin(\|\vec{x}\|_2 - ct) + \cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_2} \right)  *  \frac{x_i^2}{\|\vec{x}\|_4}
$$ After tons of simplifications (since the derivates for the $x_i$'s are almost the same) e.g.: $$
\|\vec{x}\|_2 = \|(x,y,z)\|_2 = \left( \sqrt{x^2+y^2+z^2} \right)^2 = x^2 + y^2 + z^2
$$ $$
... \frac{x^2}{\|\vec{x}\|_4} + ... \frac{y^2}{\|\vec{x}\|_4} + ... \frac{z^2}{\|\vec{x}\|_4} = \frac{\|\vec{x}\|_2}{\|\vec{x}\|_4} = \frac{1}{\|\vec{x}\|_2}
$$ I came up with this equation: $$
-3 * \left( \frac{\|\vec{x}\|_2 \sin(\|\vec{x}\|_2 - ct) + \cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_2} \right)  +  \frac{2\|\vec{x}\|_2 \sin(\|\vec{x}\|_2 - ct) + (2 - \|\vec{x}\|_4) \cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_8}  +  \frac{\|\vec{x}\|_2 \sin(\|\vec{x}\|_2 - ct) + \cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_4}   +  \frac{\cos(\|\vec{x}\|_2 - ct)}{\|\vec{x}\|_2} = 0
$$ The solution I can think of right now would be to set $\|\vec{x}\|_2$ = $1$: $$
-3 * ( \sin(1 - ct) + \cos(1 - ct) ) + 2 \sin(1 - ct) + \cos(1 - ct) + \sin(1 - ct) + \cos(1 - ct)  + \cos(1 - ct)
$$
$$
= -3\sin(1 - ct) -3\cos(1 - ct) + 3 \sin(1 - ct) + 3\cos(1 - ct) = 0
$$ But that seems more like a stupid hack instead of a solution, since this does not solve the equation for every $(x,y,z) \in \mathbb{R}^3$ but only for those where $\|\vec{x}\|_2$ = $1$. But it solves the equation for every $t \in \mathbb{R}$ Question What is that fact, relation or obvious simplification I'm missing here? Since this is a quite unusual amount of work that needs to be put into calculating those per hand.","['multivariable-calculus', 'partial-derivative', 'trigonometry', 'partial-differential-equations']"
997414,Proof of sum of binomials over upper index (induction),"How would you proof 
$$
\sum_{m=k}^{n}\binom{m}{k} = \binom{n + 1}{k + 1}
$$ 
with $n \geq k$ and $n$, $k \in \mathbb{N}$ by induction? I had some approaches but wasn't sure if they were right, so I'd appreciate if you could share some solutions!","['induction', 'discrete-mathematics']"
997428,Is there a group which has precisely all finite groups as subgroups?,"I would like to ask the following question: Does there exist a group $G$ such that every finite group can be embedded in $G$, and every proper subgroup of $G$ is finite? The closest example to this I have seen is the group $S_{\omega}$, i.e. bijections of $\mathbb{N}$ fixing all but finitely many elements. However, this group contains isomorphic copies of itself as its proper subgroups (even continuum many - for every $S \subseteq \mathbb{N}$ that is not cofinite, bijections from $S_{\omega}$ fixing all points in $S$ form a group isomorphic to $S_{\omega}$). So obviously such a group needs to contain some subgroup isomorphic to $S_n$ for every $n$, but not infinite ascending chain of these. I am not sure how to even look for something like that (to be honest, I am inclined to believe that such a group cannot exist). I would also appreciate pointing me towards some infinite subgroups of $S_{\omega}$ not isomorphic to $S_{\omega}$ (the more bizarre, the better. : ) ). Thanks in advance for any help. Edit: OK I see that even the $S_\omega$ is far from having these properties - one can, for example, take an arbitrary countable family of finite groups $G_n$ and then find $\bigoplus_{n<\omega}G_n$ as a subgroup by partitioning the set $\mathbb{N}=\bigcup_{n < \omega}M_n$ and realizing $G_n$ as a subgroup of $S(M_n). $ So there are in fact even uncountably many up to isomorphism infinite subgroups of $S_{\omega}$. Edit2: The only idea I came up with is the following: Obviously such a group, assuming it exists, is a union of all its proper subgroups, hence it is a direct limit (i.e. directed colimit) of some diagram consisting of a set of finite groups s.t. every finite group is isomorphic to some of theose groups. Finding the ""right diagram"" could resolve the problem (by showing the colimit has desired properties, or showing that if some group does, it is necessarily that one, and finding a proper infinite subgroup there). However, it is not clear to me which morphisms should one use. My first idea was to use all possible injections (something like ""whenever some injection exists, fix one""), but that obviosly doesn't work - the resulting limit would contain $S_{\omega}$ as a subgroup. So maybe one needs to use less injections (which I suspect would make the limit even bigger) or more general morphisms, than injections.","['examples-counterexamples', 'permutations', 'group-theory', 'abstract-algebra']"
997434,"How to show for a simple regression with an intercept and one independent variable $R^2 = r ^2$ , where $r$ is the ordinary correlation coefficient.","How to show for a simple regression with an intercept and one independent variable $R^2 = r ^2$, where $r$ is the ordinary correlation coefficient. Here is where I'm at. $R^2= \textrm{SSR}/\textrm{SST}$ 
then I substituted for $\hat{Y}$. 
Now my question is what is the difference and meaning between $\hat{Y}$, $\bar{Y}$, and $Y$ in the substitution of SSR and SST?","['statistics', 'regression']"
997450,Does the operation of addition on the subspaces of V have an additive identity? Which subspaces have additive inverses?,"I was reading Linear Algebra Done Right. I came across the following question (Ch-1, Q12), for which I have solution , but I am having little confusion regarding it: Q12. (a) Does the operation of addition on the subspaces of V have an additive
identity? Sol. The subspace {${0}$} is an additive identity for the operation of addition on the subspaces of V. More precisely, if U is a subspace of V, then U + {${0}$} = {${0}$} + U = U. This is quite obvious as subspaces are itself vector spaces and so must have {${0}$}, or even their addition, whether uniquely expressed or not. If not expressed uniquely then it won't be a direct product but will still be a subspace (Am I right here about subspace?) Q12. (b) Which subspaces have additive inverses? Sol. For a subspace U of V to have an additive inverse, there would have to be another subspace W of V such that U + W = {${0}$}. Because both U and W are contained in U + W, this is possible only if U = W = {${0}$}. Thus {${0}$} is the only subspace of V that has an additive inverse. What I don't get here is that since a subspace is a vector space itself, why do  we need to consider another subspace W for U to have additive inverse? Can't U contain its own element's additive inverse?","['vector-spaces', 'linear-algebra']"
997462,"Evaluating $\int\frac{x^3}{\left(\sqrt{4x^2+9}\right)^3}\,dx$ using a trigonometric substitution","I have this integral:
$$\int\frac{x^3}{\left(\sqrt{4x^2+9}\right)^3}\,dx$$
I tried to solve it with a trigonometric substitituon but I can't get any result.
I would appreciate if somebody could help me.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
997517,Differential geometry: Conformal map,"Let $f:\mathbb{R}_{>0} \times (0,2\pi) \rightarrow \mathbb{R}^3$ $$f(t,\xi) := (r(t) \cos( \xi) , r(t) \sin(\xi),z(t))$$ be a surface of revolution, where we assume that $r>0$ and $r'^2+z'^2>0.$ Then the metric tensor of this immersion can be written as 
$(g_{ij})(t):=\begin{pmatrix} r'(t)^2+z'(t)^2 & 0 \\ 0 & r(t)^2 \end{pmatrix}.$ By exploiting the fact that there is an arc-length parametrization ($\psi(t) = \int_0^t r'(s)^2+z'(s)^2 ds$) for the underlying curve of the surface of revolution, the map $f$ can be reparametrized so that we get the metric tensor $\tilde{g_{ij}}(t) = \begin{pmatrix} 1 & 0 \\ 0 & r(\psi(t))^2 \end{pmatrix}.$ Now, I am asked in my exercise, if there is also a reparametrization $\phi: \hat{U} \rightarrow U$, such that we locally(!) (for some open set $U$ in the domain of $f$) get a map $\hat{f}: \hat{U} \rightarrow \mathbb{R}^3$ satisfying $\hat{f} =  f \circ \phi$, where the new metric tensor $(\hat{g}_{ij})(p) = \lambda(p) \ Id$ for all $p \in \hat{U}$. I know that a reparametrization would give rise to the following equation regarding the metric tensor:
$$(\hat{g}_{ij}) = D \phi^T ( g_{ij}) D \phi$$. I also got the hint that I shall look for an ODE and use the Picard-Lindelöf theorem to show the local existence, but I just don't see a differential equation showing up here anywhere. If anything is unclear, please let me know.","['ordinary-differential-equations', 'differential-geometry', 'plane-curves', 'real-analysis', 'surfaces']"
997521,"Prove that f is uniformly continuous on [0, ∞].","Exercise: Suppose that f:[0, ∞] → R is continuous, and that there is an real value L, such that f(x) → L as x → ∞. Prove that f is uniformly continuous on [0, ∞]. Attempt: I will try to use the definition and theorem. Definition:  a function f: E → R is uniformly continuous iff for every ε > 0, there is a δ > 0 such that |x-a| < δ and x,a are elements in E implies |f(x) - f(a)| < ε. Theorem: Suppose a < b and that f: (a,b) → R. Then f is uniformly continuous on (a,b) iff f can be continuously extended to [a,b]; that is iff there is a continuous function g: [a,b] → R such that f(x) = g(x), and x is in (a,b). Then, suppose that f:[0, ∞] → R, and that there is an real value L, such that f(x) → L as x → ∞. 
Then let ε > 0. Then since [0,∞), we can try to make it of the form [0,N]. So it can look as the theorem. Suppose x >= N so that |f(x) - L | < ε. Then there is δ > 0 such that |x-a| < δ, and x,a are in [0,N], so that |f(x) - f(a)| < ε. Can someone please help me? I don't know how to continue.
Thank you in advance.","['uniform-continuity', 'real-analysis', 'limits']"
997537,"Proving ($\left|\left|Ax\right|\right| = \left|\left|x\right|\right|$, for all $x\in\mathbb{C}^n$) $\implies A$ is unitary","As the title states, I'm trying to prove that $\left|\left|Ax\right|\right| = \left|\left|x\right|\right|$ for all $x\in\mathbb{C}^n\implies$ $A$ is unitary, where $A$ is a square matrix. This is part of a larger problem and the only thing I 'know' for the purposes of this proof is that $\left|\left|Ax\right|\right| = \left|\left|x\right|\right|$ for all $x\in\mathbb{C}^n$, nothing else, e.g. I don't know that the rows or columns of $A$ are orthonormal. Any hints on where I can start with this? I'm quite stuck. Thank you very much for your time.","['matrices', 'linear-algebra']"
997547,Maximum of $\sin A\sin B\cos C+\sin B\sin C\cos A+\sin C\sin A\cos B$ in triangle,"What is the maximum value of $$\sin A\sin B\cos C+\sin B\sin C\cos A+\sin C\sin A\cos B,$$ where $A,B,C$ are angles in a triangle? We can rewrite as $$-\sin A\sin B\sin(A+B)+\sin B\sin(A+B)\cos A+\sin(A+B)\sin A\cos B$$ Expanding, this becomes $$-\sin^2 A\sin B\cos B-\sin^2B\sin A\cos A+2\sin B\sin A\cos B\cos A+\cos^2A\sin^2B+\sin^2A\cos^2B$$","['trigonometry', 'inequality']"
997551,Finding Sylow p-subgroups,"I am trying some examples of finding Sylow p-subgroups in specific groups and looking for the most efficient way to do so. For example, lets say we need to find Sylow-3 subgroups in $A_4$ and $D_6$, dihedral group of order 12. Using sylow theorems I found there can be only $1,4$ sylow 3-subgroups in group of order 12. But how do we actually find these subgroups? Since these groups are of small order maybe check the orders of each element might work but this is not the best way. Are there any tricks or theorems out there to find the subgroups?","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
997583,Lagrange interpolation for rational functions,"Lagrange interpolation is very useful. I was wondering if there was an equivalent that is not using polynomials but rational functions, one polynomial divided by another. Look at this example: Say I want a function that passes through the $(x,y)$ points $(3,0),(4,-1),(6,3)$ and $(7,2)$. Using Lagrange interpolation I get $$-\frac{x^3-15x^2+70x-102}{2}$$ but using this interpolation method for rational functions I get the much simpler $(x-3)/(x-5)$. This is a case where the rational function interpolation is a lot simpler than polynomial interpolation. Is there a method to get $(x-3)/(x-5)$ given the points above, a sort of interpolation method that uses rational functions?","['interpolation', 'algebra-precalculus']"
997589,cardinality of $\mathbb R$ is the same as the cardinality of $\mathbb R^2$,"A problem in my homework is to prove the cardinality of $\mathbb R$ and the cardinality of $\mathbb R^2$ is the same. I'm in my first semester and I have no clue how to do this, do I need the axiom of choice to prove this? Can I find a bijection, or must I use Cantor-Schroeder-Bernstein? Apparently if we assume choice we can go further and prove the cardinality of any set $A$ is is equal to the cardinality of $A^2$ thank you very much, I need help. Regards.",['elementary-set-theory']
997602,Show $1/(1+ x^2)$ is uniformly continuous on $\Bbb R$.,"Prove that the function $x \mapsto \dfrac 1{1+ x^2}$ is uniformly continuous on $\mathbb{R}$ . Attempt: By definition a function $f: E →\Bbb R$ is uniformly continuous iff for every $ε > 0$ , there is a $δ > 0$ such that $|x-a| < δ$ and $x,a$ are elements of $E$ implies $|f(x) - f(a)| < ε.$ Then suppose $x, a$ are elements of $\Bbb R. $ Now \begin{align}
|f(x) - f(a)| 
&= \left|\frac1{1 + x^2} - \frac1{1 + a^2}\right|
\\&= \left|  \frac{a^2 - x^2}{(1 + x^2)(1 + a^2)}\right|
\\&= |x - a| \frac{|x + a|}{(1 + x^2)(1 + a^2)}
\\&≤ |x - a| \frac{|x| + |a|}{(1 + x^2)(1 + a^2)}
\\&= |x - a| \left[\frac{|x|}{(1 + x^2)(1 + a^2)} + \frac{|a|}{(1 + x^2)(1 + a^2)}\right]
\end{align} I don't know how to simplify more. Can someone please help me finish? Thank very much.","['real-analysis', 'uniform-continuity']"
997604,likely open number theory problem: finite sum of $\zeta(2)$ equal to a square of rationals,"Which $n$ can let $S=1+\frac14+\frac19+\cdots+\frac1{n^2}$ be a square of a rational number? Obviously, $1$ and $3$ work, but how to prove they are the only ones? I think this problem is really hard. I have asked many professional number theorists in a top-5 math department in US, and none of them can give any clue. I am thinking this could be an open question. If you cannot solve this, try this: let $S=1+\frac12+\frac13+\cdots+\frac1{n}$. Which n can make this an integer. Prove your result. This is proposed by a famous mathematician Shing Tung Yau for a college math competition. Hopefully someone can give a clue to No.1. I suggested if you cannot solve the first one but would like to see an answer, rate this problem up so that it may have a better chance to bring in more experts for a solution. Thanks! It is also appreciated if you would like to post your thoughts on Yau's problem!","['contest-math', 'number-theory', 'analytic-number-theory', 'algebraic-number-theory', 'open-problem']"
997613,Integrating a function from negative infinity to infinity,"i got this weird question about integration from infinity to infinity. $$\int_{-\infty}^{\infty} \frac{1}{z^2+25}$$ First idea was to take the factor out to get $(z+5)(z-5)$ but that really did not achieve anything. Then i tried let $x= z^2$  and the $\frac{dx}{dz}= 2z$ then dz = 1/2z but that also went nowhere Then i tried..... $x=z$, $\frac{dx}{dz}= 1$ hence $dz = dx$ $$\int_{-\infty}^{\infty} \frac{dx}{x^2+25}$$ which has not achieved anything. Please help! Wait i just remember how this applies to partial fractions. But still confused how to grom infinity to infinity. So start wit
$$\frac{1}{z^2+25}=\frac{1}{(z+5)(z-5)}$$
$$\frac{1}{(z+5)(z-5)}=\frac{A}{x+5}+\frac{B}{x-5}$$
$$1=A(x-5)+B(x+5)$$
At x = 5 $1=10B$ hence $B=0.1 At x=-5 $A=1/-10$ But i'm not sure where to go from there","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'rational-functions']"
997622,How to solve this complicated double integral problem?,"I have written this in way to make it as much as possible non-confusing. I will start describing my problem and I will walk you through my question, I have a double integration which I am trying to solve of the following form, $$F=\int\limits_{0<\gamma_1<\gamma_2<+\infty} \mathcal{L}\bigl(\sum_{i=1}^2\gamma_i^{-1} \bigl)\ g(\gamma_1,\gamma_2)\ d\gamma_1 d\gamma_2$$ where  $$\mathcal{L}(t) = \text{exp}\left(- \int_{\gamma_2}^\infty (1- \frac{1}{1+t \ x^{-1}})\ h(x)\ dx\right) $$
Now assume that $h(x)$ is a very complex expression,  I tell you that $\mathcal{L(t)}$ can not be integrated in closed form analytically and should be solved numerically. So to solve my problem I have to take numerical values of $t$ in order to integrate numerically. But notice that to solve my main integration $F$ defined above, I need to set $$t=\sum_{i=1}^2\gamma_i^{-1} $$ and then integrate numerically to obtain $L\bigl(\sum_{i=1}^2\gamma_i^{-1} \bigl)$ by taking numerical values of $\gamma_1$ and $\gamma_2$. Now that I took numerical values of $\gamma_1$ and $\gamma_2$ to solve my $\mathcal {L}(t)$. My inner integral is then numerical values for certain values of $\gamma_1$ and $\gamma_2$ that I picked. My question is, since I was obliged to take certain values of $\gamma_1$ and $\gamma_2$ to solve for my non-integrable function $\mathcal{L}(t)$ - since it happened to be that by $t$ is a function of $\gamma_1$ and $\gamma_2$. How would I proceed to solve my function $F$? Am I now obliged to integrate numerically over the same values of $\gamma_1$ and $\gamma_2$ I picked to solve for  $\mathcal{L}(t)$ ? In general do you think this way of analyzing such a problem is correct. Any better ideas on tackling such a problem? for example approximations/ Thanks","['definite-integrals', 'improper-integrals', 'integration', 'indefinite-integrals']"
997631,Why is a graph Laplacian matrix positive semidefinite?,Why is a graph's Laplacian matrix positive semidefinite? Can anyone provide an intuitive explanation and a proof?,"['graph-laplacian', 'matrices', 'graph-theory', 'linear-algebra', 'algebraic-graph-theory']"
997653,Motivation behind study of martingales,"Today I wanted to ask a question which I am sure has been answered in multiple places but for which I do not yet have a very clear understanding. Though martingales is a very well explored area of probability and I have seen it come up in a course on randomized algorithms, I kept feeling that it required more deeper thinking than most other things in the course. As in, I would time and again have difficulties articulating to myself why is this an interesting mathematical object to look at or maybe more precisely, I was not able to convince myself how martingales will arise in ordinary ruminations of abstract thought. (I know it did arise in ""some ruminations"", but so far I have been unable to see a clear motivation behind these objects). I have seen a few applications -- like they can be used to get concentration inequalities even when your random variables are dependent (and the absolute deltas are bounded). I have also seen the gambler motivation; that did not reduce my uneasiness with martingales much :( I guess what I would like  is the following. I have given a few lectures on (basic) applications of probabilistic method and I have a good feel for this. But I cannot say the same for martingales. As of now, it seems like an alien mathematical object to me and I certainly cannot imagine myself talking about martingales yet. Please let me know if you have some suggestions/reading material which can help with this. Also, I guess I would be perfectly happy with some more approachable/playful applications of martingales. Thanks!","['probability-theory', 'martingales', 'big-picture', 'random-variables']"
997678,Linear Algebra: What do vector spaces represent?,"I understand what a vector can represent, but I still don't understand what a vector space represents. I understand that you can add two vectors and that becomes a vector space. What else can you do with them? What can you apply it to? I am taking a linear algebra course right now and understand the calculation steps, but not really what these tools are for. I hope that adds some context to my strange and probably vague question. Thanks!","['vector-spaces', 'linear-algebra']"
997709,Integral of bounded continuous function on $R$,"Let $f$ be a bounded continuous function on $R$. Prove that $$\lim_{n \to \infty} \frac{n}{\pi} \int_{ R} \frac {f(t)}{1+n^{2}t^{2}} dt=f(0)$$ I solved this question as follows, but I ran into a problem: Solution: Since $f$ is continuous at $0$, given $\epsilon>0$, there is $\delta >0$ such that $|f(x)-f(0)| \leq \epsilon, \forall x \in [-\delta \hspace{2 mm} \delta]$. Now consider $f_{n}(x)=\frac{nf(x)}{1+n^{2}x^{2}}$,$n \in N$, is a sequence of continuous function that converges to $0$ on $R-[-\delta \hspace{2 mm} \delta]$ when $n \to \infty$. Also, according to guestion, $f$ is bounded (i.e.$|f_{n}(x)|<g(x)$). Therefore according to Dominated Convergence Theorem 
 $$\lim_{n \to \infty} \frac{n}{\pi} \int_{ R-[-\delta \hspace{2 mm} \delta]} \frac {f(t)}{1+n^{2}t^{2}} dt=\lim_{n \to \infty} \frac{n}{\pi} \int_{ R-[-\delta \hspace{2 mm} \delta]} 0 \hspace{2 mm} dt=0$$ Now I have a problem to solve the second part. I want to prove $\lim_{n \to \infty} \int_{ -\delta}^{\delta} \frac {nf(t)}{1+n^{2}t^{2}} dt =  \lim_{n \to \infty} \int_{ -\delta}^{\delta} \frac {nf(0)}{1+n^{2}t^{2}} dt $ which $\lim_{n \to \infty} \int_{ -\delta}^{\delta} \frac {nf(0)}{1+n^{2}t^{2}} dt =\pi f(0)$ If I can prove that, the rest of question is easy, because I can say: $\lim_{n \to \infty} n \int_{ R} \frac {f(t)}{1+n^{2}t^{2}} dt=\lim_{n \to \infty} n \int_{ R-[-\delta \hspace{2 mm} \delta]} \frac {f(t)}{1+n^{2}t^{2}} dt+\lim_{n \to \infty} n \int_{ R} \frac {f(t)}{1+n^{2}t^{2}} dt=\lim_{n \to \infty} n \int_{ [-\delta \hspace{2 mm} \delta]} \frac {f(t)}{1+n^{2}t^{2}} dt=\pi f(0)$ Now how can I prove:
$\lim_{n \to \infty} \int_{ -\delta}^{\delta} \frac {nf(t)}{1+n^{2}t^{2}} dt =  \lim_{n \to \infty} \int_{ -\delta}^{\delta} \frac {nf(0)}{1+n^{2}t^{2}} dt $",['real-analysis']
997745,Question about Cartesian products at the elementary level,"Suppose $\{ X_\alpha  \}_{\alpha \in A} $ is a family of sets indexed by $A$. If $A $ is $\mathbb{N}$, then the Cartesian product of them is just $$ X_1 \times X_2 \times \cdots $$ Reading Folland's book, he defines the Cartesian product of them $\prod_{\alpha \in A} X_{\alpha } $ as $$ \{ f: A \to \bigcup_{\alpha \in A} X_\alpha : f( \alpha) \in X_\alpha \; \; \forall \alpha \} $$ I am having a hard time understanding this definition. Can someone explain it to me? I was trying to relate this definition to the case when $A = \mathbb{N}$ but still I am somewhat lost.",['elementary-set-theory']
997755,Contents of Tor modules,"I'm interested in knowing a concrete description of what elements of Tor modules $\mathrm{Tor}^i_R(M,N)$ ""are"". As it stands I have no real intuition for, say, maps between Tor modules induced by functoriality. I have a couple of pipe dreams -- one is to have a description in the same vein as the well-known description of Ext in terms of extensions (and the Baer sum). Another is to have a description in special cases, e.g. $\mathrm{Tor}^i(R/I,M)$ over a local ring $R$. (is there something along the lines of the description of $\mathrm{Ext}$ in terms of regular sequences?) Of course there are a handful of nice cases, like $\mathrm{Tor}^1(R/I,R/J) = I \cap J / IJ$ and $\mathrm{Tor}^1(R/I,M) = I \otimes M$ when $I \subseteq \mathrm{Ann}(M)$. Or, somewhat similarly, if $$0 \to K \to F \to M \to 0$$ is a short exact sequence with $F = R^n$ a free module, then $\mathrm{Tor}^1(R/I,M) = (K \cap IF)/IK$. So this gives a semi-concrete description as ""$I$-linear relations between generators modulo $I$-multiples of relations"" or something. I will also accept explanations as to why such a description doesn't seem to exist, or why the best we can do is try to understand things in terms of free resolutions and ""generators and relations and relations between relations..."".","['homological-algebra', 'commutative-algebra', 'algebraic-geometry']"
997773,"Poisson distribution variance, probability, and mean.","Let $X$ be the poisson random variable such that $\mathbb P(X=2)=9\mathbb P(X=4)+90\mathbb P(X=6)$ . a) Find the mean and variance of $X$ . b) Find $\mathbb P(X\geq1)$ . c) Find $\mathbb P(X\leq10)$ . For a), I need to turn each probability into its respective $p(x)$ form and solve for $\lambda$ . I got that $\lambda$ was $1$ so therefore, the mean and variance should be $1$ . Now, for the second question, I have that $\mathbb P(X\geq 1)=1- \mathbb P(X<1)$ . Am I to assume that $\lambda$ is still $1$ ? If so, is $1-\mathrm e^{-1}$ the correct answer for b)? For c), I'm just lost here... it was asked to solve this problem through R programming language. Correct me if I'm wrong, but is is not just simply $\mathbb P(X \leq10)=1-\mathbb P(X>10)$ ? If so, I'd think that solving for $\mathbb P(X>10)$ would be plugging in ppois(10,1) into R, but I'm just getting $1$ as the output... that means a $100\%$ change of $\mathbb P(X>10)$ ... sorry if this question isn't what this MSE is for but if you know what I'm talking about, that'd be really helpful.","['statistics', 'poisson-distribution', 'probability', 'random-variables']"
997775,Find all numbers $c$ that satisfy Mean Value Theorem,"Verify that the function satisfies the hypotheses of the Mean Value Theorem on the given interval. Then find all numbers $c$ that satisfy the conclusion of the Mean Value Theorem. My function is a simple one: $x^{1/3}$ on the interval $[0,1]$. Where I'm screwing up (I believe) is setting the derivative $1/3(x^{-2/3})$ equal to $1$.
Sorry if that too many parentheses or too silly of a question. It's my first on here.
I know (via the back of the book) that the answer should be $\frac{\sqrt{3}}{9}$ Thanks.","['calculus', 'derivatives']"
997822,Collection of subsets with adding one element property,"Let $\mathcal{F}$ be a collection of subsets of $\{1,2,\ldots,n\}$ such that for any set $A\in\mathcal{F}$, there exists $B\not\in \mathcal{F}$ such that $A\subset B\subseteq\{1,2,\ldots,n\}$ and $|B|=|A|+1$. What is the maximum size of $\mathcal{F}$? One bound is that $\mathcal{F}$ can be of size at least $2^{n-1}$. Indeed, if $n$ is even, put all subsets of odd size in $\mathcal{F}$ (and vice versa if $n$ is odd.) And of course $\mathcal{F}$ is of size no more than $2^n$, the number of subsets of $\{1,2,\ldots,n\}$. Any better upper/lower bounds?","['extremal-combinatorics', 'combinatorics']"
997903,limit of double binomial sum,"Prove that $$\lim_{\max(M,N) \to \infty} \frac{\sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i}}{\min (\frac{M}{p}, \frac{N}{1-p})} = 1 $$ where $0<p<1$ and $M, N$ are positive integers. I did it for the case that one of $M, N$ is fixed by using the differentiation of power series representation of $\frac{1}{1-p}$, but I have no idea about the remaining case - both of $M, N$ go to infinity. My work - Proof for the special case where $N$ is finite: The original problem becomes $$\lim_{M \to \infty} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i} = \frac{N}{1-p}. $$ To see this, for each $j$, $$(1-p)^{j} \sum_{i=0}^{\infty} p^{i}  {i+j \choose i} = (1-p)^{j} \frac{1}{j!} \frac{d^{j}}{dp^{j}} \big( \frac{1}{1-p} \big) = \frac{(1-p)^{j}}{(1-p)^{j+1}} = \frac{1}{1-p}, $$ whence $$\lim_{M \to \infty} \sum_{i=0}^{M-1} \sum_{j=0}^{N-1} p^{i} (1-p)^{j} {i+j \choose i}  = N \cdot \frac{1}{1-p} = \frac{N}{1-p}. $$","['calculus', 'combinatorics']"
997904,How to decide completeness of $\ell^\infty$?,"Let $\ell^\infty$ denote the set of all bounded sequences $x \colon = (\xi_j)_{j=1}^\infty$, $y \colon= (\eta_j)_{j=1}^\infty$ of complex numbers with the metric $d$ defined as follows: 
$$ d(x,y) \colon= \sup_{j\in\mathbb{N}} |\xi_j - \eta_j|. $$ Then how to determine if $\ell^\infty$ is complete? My work: Let $(x_n)$, where $x_n \colon= (\xi_j^{(n)})$, be a Cauchy sequence in $\ell^\infty$. Then, given $\epsilon > 0$, there exists an integer $N$ such that $m$, $n > N$ implies that $$d(x_m, x_n) = \sup_{j\in\mathbb{N}} |\xi_j^{(m)} - \xi_j^{(n)}| < \epsilon.$$ So, for each $j \in \mathbb{N}$, we have 
$$ |\xi_j^{(m)} - \xi_j^{(n)}| < \epsilon,$$ from which it follows that, for each $j\in \mathbb{N}$, the sequence $(\xi_j^{(n)})_{n=1}^\infty$ is a Cauchy sequence in the complete mertic space $\mathbb{C}$, the set of complex numbers under the usual metric, and hence this sequence is convergent; let 
$$\xi_j \colon= \lim_{n\to\infty} \xi_{j}^{(n)} $$ for each $j \in \mathbb{N}$. Let $x \colon= (\xi_j)_{j=1}^\infty$. We now need to show that $x\in \ell^\infty$ and that $x_n \to x$ as $n \to \infty$. In order to show that $x \in \ell^\infty$, we show that $x$ is a bounded sequence. Since $\xi_j^{(n)} \to \xi_j$ as $n \to \infty$, there exists $N_j$ such that $n > N_j$ implies that $$|\xi_j^{(n)} - \xi_j| < \epsilon.$$ 
And since, for example, $x_{N+1} = (\xi_j^{(N+1)} )_{j=1}^\infty$ is a sequence in $\ell^\infty$, it is a bounded sequence of complex numbers; so there is a non-negative real number $k_{N+1}$ such that 
$$ |\xi_j^{(N+1)} | \leq k_{N+1}$$ 
for each $j \in \mathbb{N}$. Hence, for each $j \in \mathbb{N}$, we have 
$$|\xi_j| = | \xi_j - \xi_j^{(N+1)} + \xi_j^{(N+1)} | \leq  | \xi_j - \xi_j^{(N+1)} | + |\xi_j^{(N+1)} | < \epsilon + k_{N+1},$$ which shows that $x \in \ell^\infty$. Am I right so far? Now how to rigorously prove that $(x_n)$ converges to $x$? My effort: Fix $m \in \mathbb{N}$. Then as, for each $j = 1, \ldots, m$, we have 
$$ \lim_{n\to\infty} \xi_{j}^{(n)} = \xi_j,$$ 
so, given $\epsilon > 0$, we can find an integer $M_j$ such that $n > M_j$ implies that 
$$|\xi_j^{(n)} - \xi_j| < \frac{\epsilon}{2}. $$ Now let's take $M \colon= \max(M_1, \ldots, M_m)$. Then $n  > M$ implies 
$$ |\xi_j^{(n)} - \xi_j| < \frac{\epsilon}{2} $$ for each $j= 1, \ldots, m$. That is, $n > M$ implies that 
$$ \sup \{|\xi_j^{(n)} - \xi_j| \colon j = 1, \ldots, m \} \leq \frac{\epsilon}{2}.$$ What next?","['cauchy-sequences', 'real-analysis', 'analysis', 'metric-spaces', 'functional-analysis']"
997971,"Existence of unique solution on $(-\delta,\delta)$ for $f(x)=1+x+\displaystyle\int^x_0\sin(tf(t))dt$","The following was a question previously given in a test at my university: Show that there exists some $\delta>0$ for which there is a unique
  continuous function $f:(-\delta,\delta)\to\mathbb{R}$ satisfying
  $$f(x)=1+x+\int^x_0\sin(tf(t))dt$$ and give a value of $\delta$ for
  which this is true. ($\mathbb{R}$ has the Euclidean metric) I'm really not sure what to do with this question. If it were on a closed interval I think I could use the Banach contraction theorem to show that some mapping $Q$ with $Qf=f$ if and only if $f$ satisfies the above equation is a contraction, then finish. Or, I think Picard's theorem might've worked too, but the fact that it's an open interval has got me pretty confused. How can I solve this?","['real-analysis', 'analysis']"
997972,"A function is smooth at a point and not smooth in any neighbourhood of it, exist or not?","Suppose that a function $f$ defined in an open set $U \subseteq \mathbb{R}^m$ is smooth at a point $p \in U$. Then we have that there exists an open set $U_n \subseteq U$ $($ say $U_{n+1} \subseteq U_{n} \subseteq U$ $)$ contains $p$ such that $f$ is $n$- derivable in $U_n$, that is, all $n$th-order partial derivatives of $f$ exist in $U_n$. Hence, the smooth domain of $f$ is $$V\overset {\text{def}}{=} \bigcap^{\infty}_{n=1}U_n ~.$$ My question: Does there exist a function $f$ defined in an open set $U$ such that it is smooth at a point $p \in U$ and not smooth in any nonempty open subset of $U$ ? To put it another way, if we do not choose those $U_n$ too small artificially, then, is $V^{\circ}$ always an nonempty open set ?","['derivatives', 'functions']"
998029,Wedge product = set intersection?,"In a research article [1] I found the following formulation: The wedge product may be considered as set intersection. For
  example, surfaces of constant $f(x,y,z)$ and surface of constant $g(x,y,z)$
  intersects along the lines given by $df \wedge dg$. The notion
  of interpreting the wedge product as set intersection is appealing
  from a topological standpoint. The article almost does not make use of exterior differential systems or other sophisticated math. It also gives no precise reference for the above statement. Questions: Does this viewpoint (wedge product = set intersection) make sense at all? What is meant with ""the lines given by $df \wedge dg$""? Edit: E.g. When I set $f(x,y,z) = \frac{1}{2}(x^2 + y^2 + z^2) $ and $g(x,y,z) = ax + by + cz$ with real constants $a,b,c$. Then we have $df\wedge dg = (x dx + y dy + z dz)\wedge(a dx + b dy + c dz)$. But what line does correspond to this 2-form. (I would suspect that we obtain circles.) [1] http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990890","['differential-topology', 'exterior-algebra', 'differential-forms', 'differential-geometry']"
998043,Proving a mod b < a/2 when a > b > 0,"Suppose that $a \gt b \gt 0$.  How can one prove that $a$ mod $b \lt a/2$? I understand why is that happening: if $a$ mod $b \gt a/2$ that means that $a/b \lt a/2$ and $a/b$ has enough ""space"" to get inside the $a$ mod $b$ one more time, since $a$ mod $b \gt a/2$.  This is a contradiction to the division result. What is the formal proof for that? I couldn't find it anywhere.","['discrete-mathematics', 'divisibility']"
998063,How to prove $ \sum_{r=1}^{k-1} \binom{k}{r}\cdot r^r \cdot (k-r)^{k-r-1} = k^k-k^{k-1} $,"How to prove the following identity:
$$
\sum_{r=1}^{k-1} \binom{k}{r}\cdot r^r \cdot (k-r)^{k-r-1} = k^k-k^{k-1}
$$
I have no idea how to tackle it because of the $r^r$. Any help is highly appreciated!",['sequences-and-series']
998083,Closed sets with empty interior measure zero,"Is the Lebesgue measure of a closed set with empty interior in $\mathbb{R}^{n}$ always zero? Trying to understand something in the math notes that I don't understand, and if the above is true, it would make more sense. Not sure if true though!","['general-topology', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
998084,Affine Functions as Equality Constraints in Convex Optimization Problems,"I am studying an introduction to convex optimization. When defining a convex optimization problem, we have a convex objective function, $f(x)$, a set of convex functions $g_i(x)$ where the feasible region is the intersection of their $0$-sublevel sets, $G_i=\{x \mid g_i(x) \leq 0\}$. We can have equality constraints as well, which are defined using affine functions $h_i$, where the constrained sets are $H_i=\{x \mid h_i(x)=0\}$. So the final feasible region for that problem should be $G_1 \cap G_2 \cap \dots \cap G_n \cap H_1 \cap \dots \cap H_m$. For $n$ inequality and $m$ equality constraints. I have two questions about this definition of the convex optimization problem. As far as I know, in very general, an affine function is defined as $h(x) = Ax + b$, where $A$ is a $m \times n$ matrix and $x \in \mathbb{R}^n$. But since here we deal with scalar valued functions, due to the nature of the optimization problem, I assume that $h(x)$ functions should have the form of $h(x) = w^Tx + b$ where $b$ is just a scalar. Is this true? I have the following understanding about introducing the affine equality constraints into the problem. When the domain of the problem is $D$ dimensional, equality constraints introduce a $D-1$ dimensional surface limitation into the feasible region. This is a line in a two dimensional problem, a plane in a three dimensional problem and a hyperplane for higher dimensions, due to the form of the constraint $h(x) = w^Tx + b = 0$, assuming my first question is valid. Since the subset of $\mathbb{R}^D$ which belongs to a constraint must constitute a convex set, and a function of the form $h(x)=0$ defines a $D-1$ dimensional level surface in $\mathbb{R}^D$, the only way to make this surface convex is to define it as a hyperplane, which is what the affine function defines. Is this view about affine constraints correct? Thanks in advance.","['optimization', 'multivariable-calculus', 'convex-analysis', 'convex-optimization']"
998112,Find $S=\frac{1}{2}+\frac{3}{2^2}+\frac{5}{2^3}+\frac{7}{2^4}+...+\frac{2n-1}{2^n}+...$,"I'm trying to calculate $S$ where $$S=\frac{1}{2}+\frac{3}{2^2}+\frac{5}{2^3}+\frac{7}{2^4}+...+\frac{2n-1}{2^n}+...$$ I know that the answer is $3$, and I also know ""the idea"" of how to get to the desired outcome, but I can't seem to actually go through with the proof. The idea for solving this question is: First we will only work on the partial sum $S_n$ and once we find a closed form for it, we will limit $n$ to $\infty$ to find our answer. Notice that for example $\frac{3}{2^2}$ can be rewritten as $\frac{1}{2^2}+\frac{2}{2^2}$, knowing this, we can write $S_n$ a bit differently: $$S_n=(\frac{1}{2}+\frac{1}{2^2}+\frac{1}{2^3}+\frac{1}{2^4}+...+\frac{1}{2^n})+\frac{2}{2^2}+\frac{4}{2^3}+\frac{6}{2^4}+...+\frac{2n-2}{2^n}$$ Notice that the part in the brackets is a finite sum that we can calculate, we know it converges to $1$ when $n$ approaches $\infty$ And now we can repeat the process again for what's not in the brackets and we can repeat this an infinite amount of times. And if we keep going like that, we will indeed see that the sequence of whats in the bracket is: $1,1,\frac{1}{2},\frac{1}{4},\frac{1}{8}...$ and if we sum them all up it will converge to the desired outcome which is $3$. And that is exactly what I am having problems showing, that the sequence of whats in the brackets at each step is $\frac{1}{2^k}$. I hope this was clear enough, it is a bit difficult to explain it, and my english is not perfect so I apologize in advance.","['convergence-divergence', 'sequences-and-series', 'summation']"
998214,Even Number cards?,"There are $15$ cards on a table, marked with an integer $1$ from to $15$ . How many ways can I take cards such that the sum of the numbers on the cards is even?
Please help me?","['permutations', 'combinatorics']"
998286,Finding the infinite sum of $e^{-n}$ using integrals,"I am trying to understand this: $\displaystyle \sum_{n=1}^{\infty} e^{-n}$ using integrals, what I have though: $= \displaystyle \lim_{m\to\infty} \sum_{n=1}^{m} e^{-n}$ $= \displaystyle \lim_{m\to\infty} \frac{1}{m}\sum_{n=1}^{m} me^{-n}$ So, suppose this is an right-hand Riemann sum, with $m$ Equal subintervals. $f(x_i) = me^{-n}$ represents the height of the function, we will have the integral for. $\Delta(x) = \frac{1}{m}$ But, How can this be represented as an integral? Thanks!","['sequences-and-series', 'calculus', 'real-analysis', 'analysis', 'summation']"
998295,"Is ""to be married"" a transitive relation?","If you define a relation on the set of people, given by $R=\{x,y : x\text{ is married with } y\}$. Is this relation transitive? I would say it depends: In the western culture: If $x$ is married with $y$ and $y$ is married with $z$ then $z$ has to be $x$ and thus $x$ is also married with $z$.
In cultures where you can be married to multiple persons it is not because $z$ is not necessarily $y$. Am I right?","['logic', 'equivalence-relations', 'elementary-set-theory']"
998296,Evaluating by real methods $\int_0^{\pi/2} \frac{x^5}{2-\cos^2(x)}\ dx$,"$\def\Li{{\rm{Li}}}$I'm sure you guys can briefly get the result by some methods of complex analysis, but now I'm only interested in real analysis methods of proving the result. What would you propose for that?
\begin{align*}
\int_0^{\pi/2} \frac{x^5}{2-\cos^2(x)}\ dx=&\,\frac{\pi^6 \sqrt{2}}{768}+\frac{5 \sqrt{2}\pi^4}{64}\Li_2\left(2\sqrt2-3\right)-\frac{15\sqrt{2}\pi^2}{16}\Li_4\left(2\sqrt2-3\right)\\
&+\,\frac{15\sqrt{2}}{8}\bigg[\Li_6\left(2\sqrt2-3\right)-\Li_6\left(3-2\sqrt2\right)\bigg]
\end{align*} And a supplementary question for another version, that is $$\int_0^{\pi/2} \frac{x^5}{1+\cos^2(x)}\ dx$$ again, by real analysis methods only.","['closed-form', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
998297,Integrals of compactly supported functions of positive type,"Consider a continuous function $f: \mathbb{R} \rightarrow \mathbb{R}$, supported on $[-1,1]$, of positive type. Assume $f(0) = 1$; what is the ""largest"" area $\int f\,dx$ that can be achieved? To be more precise, let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function satisfying: $f$ is supported on $[-1,1]$, for all $x$, $0 \leq f(x) \leq 1 = f(0)$, and $f$ has positive type: for any finite family of points $x_1 < \cdots < x_n$ in $\mathbb{R}$, the matrix $(f(x_i - x_j))_{ij}$ is positive semi-definite. How large can $\int f(x)\,dx$ be? Remarks One example of such a function is the ""triangle"" $t(x) = \max(1 - |x|,0)$. This achieves $\int t(x)\,dx = 1$. Is that the best one can do? There are functions $g$ of positive type (and satisfying the other requirements above) for which $g(x) > t(x)$ for some $x$. (However, I do not know of any for which $\int g(x)\,dx > 1$.)","['harmonic-analysis', 'fourier-analysis', 'duality-theorems', 'analysis']"
998299,Intersect and Union of transitive relations,"Let $R$ and $S$ be relations on a set $A$. Assume $A$ has at least three elements. These are my best guesses at these two proofs. The first one I don't feel confident about at all, as it seems I'm making too many assumptions. If $R$ and $S$ are transitive, then $R \cap S$ is transitive Let $(a,b),(b,c) \in R \cap S$ $\implies$ $(a,b),(b,c)\in R$ and $(a,b),(b,c)\in S$ $\implies$ $(a,c)\in R$ and $(a,c) \in S$ (as $R$ and $S$ are transitive) $\implies$ $(a,c) \in R \cap S$. Thus, $R \cap S$ is transitive. If $R$ and $S$ are transitive, then $R \cup S$ is transitive Proof by counterexample: If $A = \{x,y, z\}$, suppose $R = \{(x,y)\}$ and $S = \{(y,z)\}$ $R$ and $S$ are both transitive by default. However, $R \cup S$ is not transitive because $(x,z)$ is not a member of $R \cup S$.","['relations', 'elementary-set-theory']"
998301,Normal distributions sums,"I read this property about normal distribution If $X\sim\mathcal N(\mu_X,\sigma_X^2)$ and $Y\sim\mathcal N(\mu_Y,\sigma_Y^2)$ are independent, then
$$
X+Y\sim\mathcal N(\mu_X+\mu_Y,\sigma_X^2+\sigma_Y^2).
$$ However I also read
$$
X = \sigma Z + \mu\,
$$ If I sum X + Y using this property I get $$
X+Y = (\sigma_x + \sigma_y) Z +  \mu_x + \mu_y = N(\mu_x + \mu_y, (\sigma_x + \sigma_y)^2),
$$ Why do I get different result on variance?","['statistics', 'normal-distribution']"
998313,Borel Measures: Atomic Decomposition,"Context The notion of atoms and point masses agree to certain extent. (See Summary on Atoms .) Measures decompose w.r.t. atoms. (See Paper on Atoms .) Here, the goal is a direct approach to decompose w.r.t. point masses! Problem Consider a sigma-finite measure $\mu:\Sigma\to\mathbb{R}_+$. Does it decompose into a discrete and a continuous part:
$$\mu=\mu_0+\mu_\infty$$ (For a precise definition see corresponding paragraph of Summary on Atoms .) Attempt My sort of dumb idea is to simply subtract all discrete masses:
$$\mu_\infty:=\mu-\sum_{\#D\leq\aleph_0}\mu(D)$$ (However, there are a loooot of double countings...)","['measure-theory', 'elementary-set-theory']"
998337,List of ODE's that can be solved by Fourier transform,"I am teaching introductory level Fourier analysis and I want to give my students some basic and some not so basic examples of how to solve ordinary differential equations with the method of Fourier transform. Looking at various sources there seems to be basically just one instance $u''-u=f$ where the method is applicable (the other examples seem to be derived from it. Since there also other methods to deal with these examples and the students may be unconvinced what they actually gain by using this method, I wonder where could one find a list of ODE's (maybe with non-constant coefficients but  not PDE's) which are solvable (at least in principle) precisely by the method of Fourier transform (not Laplace transform, Fourier series etc., I know these are related, yet my question is a particular one). Preferably the list should contain cases when distribution theory is either needed or is avoided.","['ordinary-differential-equations', 'fourier-analysis']"
998339,Paternity probability calculator based on blood group and eye color,"I am currently writing a paternity probability calculator. I am struggling with finding the correct statistical approach to determining probability based on blood type and on eye colour. For example, assume the following family: Blood Type     Eye Colour
Alleged Father    A              Blue
Mother            AB             Blue
Child             A              Green A father of type A and a mother of type B can produce the following blood types for their child: Child's possible blood types    Occurrence
A                               50%
B                               25%
AB                              25%
O                               0% A father of eye colour Blue and a mother of eye colour Blue can produce a child of the following eye colours: Child's possible eye colours    Occurrence
Brown                           0%
Blue                            90%
Green                           10% I would like to provide the probability of paternity for the alleged father given this data. I am struggling with the following: If the father is of blood type A and the mother is B , then knowing that the child is A should increase our confidence in the paternity of the father - Because we eliminated the less likely results (e.g. O ) from the equation. Should I start the calculation at a ""pseudo-random"" value (say 50%), then multiply this value using a confidence factor derived from the occurrence percentage? How to derive the confidence factor from the occurrence percentage? In this case, even though the occurrence of blood type A is 50%, it seams that I should multiply the pseudo-random value by a factor above 1. If the blood type of the child would be B instead, it also seems that the factor should be above 1, but less than blood type A would be. If the child's blood type would be O , the multiplication factor should be zero.",['statistics']
998368,A problem on the sum of the reciprocals of two derivatives,"If $f(x)$ is continuous in the closed interval $[a,b]$ and differentiable in the open interval $a<x<b$, and if $f(a)=a$, $f(b)=b$, prove there exist points $x_1$ and $x_2$ with $a<x_1<x_2<b$ for which the following equation is true: $1/f'(x_1)+1/f'(x_2)=2$.",['analysis']
998388,Range of vectors that turn into eigenvectors after recursive multiplication by a matrix,"Suppose $\mathbf{x}$ is a vector, and $\mathbf{A}$ is a square matrix. Which $\mathbf{x}$'s will satisfy the equation $\mathbf{A}^n\mathbf{x} = \lambda\mathbf{A}^{n-1}\mathbf{x}$, where $\lambda$ is an eigenvalue of the matrix and $n \in\mathbb{N^+}$? So I want to determine what range of vectors $\mathbf{x}$ will generate an eigenvector $\mathbf{y}$ for the matrix $\mathbf{A}$ where $\mathbf{y}=\mathbf{A^{n-1}x}$. Also, is the value of $n$ needed for a specific vector predictable?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
998402,Outer measure is not finitely additive,"I know similar questions have been asked before, but I'm looking for clarification of a proof. In Royden's book on real analysis, he proves that every set of positive measure contains a non-measurable set. To prove that outer measures are not finitely additive, he proves the following claim: there are disjoint sets $A,B \subset \mathbb{R}$ for which $m^{*}(A \cup B) < m^{*}(A) + m^{*}(B)$. His proof goes as follows: Assume $m^{*}(A \cup B)= m^{*}(A) + m^{*}(B)$ for every disjoint pair of sets $A$ and $B$. Then, by the definition of measurable set, every set must be measurable. This contradicts the preceding theorem (that every set of positive measure contains a non-measurable set). I'm not exactly seeing the contradiction. Are the details of the proof that every set of positive measure contains a non-measurable set relevant?","['measure-theory', 'real-analysis']"
998422,Inequality $(1+x_1)(1+x_2)\ldots(1+x_n)\left(\frac{1}{x_1}+\frac{1}{x_2}+\cdots+\frac{1}{x_n}\right)\geq 2n^2.$,"Let $n\geq 2$, and $x_1,x_2,\ldots,x_n>0$. Show that $$(1+x_1)(1+x_2)\ldots(1+x_n)\left(\dfrac{1}{x_1}+\dfrac{1}{x_2}+\cdots+\dfrac{1}{x_n}\right)\geq 2n^2.$$ For $n=2$, this reduces to $(1+x_1)(1+x_2)(x_1+x_2)\geq 8x_1x_2$. We may apply the Arithmetic-Geometric mean inequality on each of the term on the left to get the result. However, when $n\geq 3$, this doesn't work anymore. [Source: Ukrainian competition problem]","['inequality', 'algebra-precalculus', 'contest-math']"
998487,Application of Slutsky's Theorem,"Let $X_i$ be a random variable. Let $\{X_i\}_{i=1}^{n}$ be a sample of observations i.i.d. over $i$ with $ \mathbb{E}(X_i)=\mu$ and $Var(X_i)=\sigma^2>0$. Let $\bar{X}_n:=\frac{1}{n}\sum_{i=1}^{n}X_i$. Let $\hat{\sigma}_n^2\geq 0$ be a consistent estimator of $\sigma^2$ as $n \rightarrow \infty$. By CLT, $\frac{\bar{X}_n-\mathbb{E}(\bar{X}_n)}{\sqrt{Var(\bar{X}_n)}} =\sqrt{n}\frac{\bar{X}_n-\mu}{\sigma} \rightarrow_d N(0,1)$ as $n \rightarrow \infty$. Using $\hat{\sigma}_n^2 \rightarrow_p \sigma^2$ as $n\rightarrow \infty$ and applying the Slutsky's Theorem,  we can conclude that
\begin{equation}
\sqrt{n}\frac{\bar{X}_n-\mu}{\hat{\sigma}_n} \rightarrow_d N(0,1)
\end{equation}
as $n \rightarrow \infty$. Let $\{\epsilon_n\}_{n=1}^{\infty}$ be a sequence of positive constants approaching zero as $n \rightarrow \infty$. Hence $\tilde{\sigma}_n^2:=\hat{\sigma}^2_n+\epsilon_n$ is a consistent estimator of $\sigma^2$ as $n \rightarrow \infty$. Therefore, 
\begin{equation}
\sqrt{n}\frac{\bar{X}_n-\mu}{\tilde{\sigma}_n} \rightarrow_d N(0,1)
\end{equation}
as $n \rightarrow \infty$. Questions: 1) Are all steps above right (in particular the final convergence in distribution result)? 2) How fast the sequence $\{\epsilon_n\}_{n=1}^{\infty}$ approaches zero is relevant somewhere? If it is relevant, how can I set that rate of convergence?","['convergence-divergence', 'weak-convergence', 'probability-theory', 'central-limit-theorem', 'probability']"
