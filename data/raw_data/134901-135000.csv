question_id,title,body,tags
2128905,Solve this integral equation that results in a linear function,"I need to find the family of real-valued single variable functions $F:\, (0,1) \to [0,1]$ that satisfy the following integral equation: $$\int_{\theta = 0}^{\pi} F\big(~ x\, \sin\theta ~\big)\text{d} \theta + \int_{\theta = \pi}^{2\pi} \bigg[ 1 - F\big(~ 1 + x\, \sin\theta ~\big) \bigg] \text{d} \theta = Ax $$ or equivalently $$\int_{\theta = 0}^{\pi} \bigg[ F\big(~ x\, \sin\theta ~\big) + 1 - F\big(~ 1 - x\, \sin\theta ~\big) \bigg]\text{d} \theta  = Ax $$ where $0 < x < 1$ and $0 < A < 1$ , with $F$ required to be non-decreasing and differentiable (just once is needed). The open- or closed-ness of the domain and range of $F$ is not important to me. The idea is that the integrations yield a RHS that is directly proportional to the coefficient of the argument in the integrand. My Questions: How can this be solved? I'm open to additional assumptions (necessary or not) or restrictions to the solution $F$ . If this kind of problem is hard to tackle in general, what material (like a particular topic, or some textbooks) should I familiarize myself with to even begin considering this task? So far I know that linear $F(u) = u$ and quadratic $F(u) = u^2$ both satisfy the equation. The cubic $F(u) = u^3$ is not a solution. Due to the some possible skew-symmetry with respect to $\theta = \pi$ and $\frac12$ for the argument of $F$ , it's tempting to guess that rotational symmetric function (odd functions) like $F(u) = \int_{0}^{u} [1+8(s-\frac12)^3 ]\;\text{d}s$ , which is a quartic polynomial, might do the job, but it doesn't. Nor do $F(u) = \frac14 \int_{0}^{u} [1 - \cos( \pi s) ]\;\text{d}s = \frac14\left[u- \frac1{\pi} \sin(\pi u)  \right]$ or the several sinusoidal functions I looked at. Taking the derivative $\partial_x$ to the whole equation isn't very helpful. If I'm not mistaken the equation is sensitive to the range of $\theta$ angle integration as well as the "" $1-$ "" in the 2nd integral and the "" $+1$ "" in $F$ , as seen in the first format. Thank you. P.S. One might notice that $F$ can be a probability CDF. This is indeed the context within which this integral equation emerged. As of now I don't see much reason to provide the context, which might be a distraction.","['integral-equations', 'integration', 'functional-equations']"
2128946,"Closed form for $\int_{0}^{\infty }\!{\rm erf} \left(cx\right) \left( {\rm erf} \left(x \right) \right) ^{2}{{\rm e}^{-{x}^{2}}}\,{\rm d}x$","I encountered this integral in my calculations: $$\int_{0}^{\infty }\!{\rm erf} \left(cx\right) \left( {\rm erf} \left(x
\right) \right) ^{2}{{\rm e}^{-{x}^{2}}}\,{\rm d}x$$ where $c>0$ and $c\in \mathbb{R}$ but could not find a closed-form representation for it. I also tried to find possible closed forms using Inverse Symbolic Calculator and WolframAlpha but they did not find anything. I was looking in the book ""Integrals ans Series Volume 2-Prudnikov-Brychkov-Marychev"" but did not find a similar formula. I am not sure it exists, but if it exists I want to know it. Closed forms are easier to manipulate, sometimes closed forms of different integrals or sums contain terms that cancel each other etc Could you please help me to find a closed form (even using non-elementary special functions), if it exists?","['calculus', 'closed-form', 'integration', 'definite-integrals', 'error-function']"
2128962,strong mixing of AR(1) process,"Let $x_t = φx_{t−1} + e_t$ where, $|φ| < 1$
Assume $e_t$ is iid with mean $0$ and variance $\sigma^2$, has a continuous distribution, with a density function that is bounded on $R$. Now I have to prove that it is strong mixing. The error term satisfies the density requirements to be able to show mixing, but I am stuck after that. I know that to show strong mixing you have to show that $α(F, G) := \sup |P(A ∩ B) − P(A)P(B)|, A ∈ F, B ∈ G;$ goes to $0$. However, I am having a very hard time figuring out how to start the proof. I know that this AR($1$) process is geometrically strong mixing but I am struggling to formally prove it. Also, I am wondering if there is a clear relationship between covariance or correlation and showing mixing. Any help or hints would be appreciated!","['time-series', 'mixing', 'probability-theory']"
2129011,$ \sum_{k=2}^{\infty} \left( \frac{1}{k-1} - \frac{1}{k} \right) = 1$,"I'm reading a proof and very rusty. I'm missing something simple I suspect. Have a little mercy and give me a nudge in the right direction? $2\epsilon + \sum_{k=2}^{\infty} 2\epsilon \left( \frac{1}{k-1} - \frac{1}{k} \right) = 4\epsilon$ I can use $\sum k^{-2}=\frac{\pi^2}{6}$ to show that it is less than $6\epsilon$ which also works for the proof this is from, but how do I show it is exactly $4\epsilon$ since that is how the book does it? In other words how do I show: $ \sum_{k=2}^{\infty} \left( \frac{1}{k-1} - \frac{1}{k} \right) = 1$ I would prefer a hint.","['sequences-and-series', 'limits']"
2129053,"Let $z \in \mathbb{C}$, show that if $\left(\dfrac{z+i}{z-i}\right)^{2016}=1$ then $z$ is a real number.","Let $w = \dfrac{z+i}{z-i}$, then $w^{2016} = 1$, hence we solve for $w$ first. $$|w^{2016}| = |1+ 0i| = 1 \Rightarrow |w| = 1$$
$$\text{arg}(w^{2016}) = 0+2k\pi \Rightarrow \text{arg}(w) = \dfrac{k\pi}{1008}$$ Hence $w = e^{k\pi i/1008}$ And then $$w = \dfrac{z+i}{z-i} \Rightarrow z = \dfrac{-i(1+w)}{1-w}$$ We know that $w = e^{k\pi i/1008}  = \cos \dfrac{k\pi}{1008} + i\sin \dfrac{k\pi}{2016}$ Denote $\dfrac{k\pi}{1008} = a$, now we expand and we have $$z = \dfrac{-i(1+\cos a + i\sin b)}{1- \cos a - i\sin a} =  \dfrac{-i-i\cos a + \sin a}{1- \cos a - i\sin a}$$ Now recall we can use the denominator of $z$ and times it by the denominator's conjugate $$z = \dfrac{(-i-i\cos a + \sin a)(1-\cos a + i\sin a)}{(1- \cos a - i\sin a)(1-\cos a + i\sin a)} = \dfrac{\sin a}{1- \cos a}  \in \mathbb{R}$$ I have came up with the above solution and i think it should be right, but then i read the answer and it says that $z$ is real if and only if $z = \overline{z}$. Now i dont dispute that but they claim that $\overline{z} = \dfrac{(-i)(-1-\overline{b})}{1-\overline{b}}$ where $b$ is just $e^{k\pi i/1008}$. I am confused over one thing, which is how they managed to know what $\overline{z}$ is. For me my understanding of conjugate of $z$ is changing the sign of $z$'s imaginary part. Which i clearly cant see any short cut?","['complex-analysis', 'complex-numbers']"
2129061,*-homomorphism between concrete von Neumann algebras is SOT-SOT continuous iff it is WOT-WOT continuous,"Let $\mathcal H, \mathcal K$ be Hilbert spaces and $M \subseteq B(\mathcal H)$ a (concrete) von Neumann algebra (Here, $B(\mathcal H)$ denotes the algebra of bounded operators on $\mathcal H$). Furthermore, let $$\pi \colon M \to B(\mathcal K)$$ be a *-Homomorphism. Note that $\pi$ is automatically a contractive, i.e. especially bounded, operator. I want to prove that $\pi$ is strong-strong (SOT-SOT) continuous if and only if $\pi$ is weak-weak (WOT-WOT) continuous. strong-strong means that $B(\mathcal H)$ as well as $B(\mathcal K)$ carry the strong operator topology (SOT). Same goes for the term weak-weak and the weak operator topology (WOT). I know that the topological duals of $B(\mathcal H)$ w.r.t the strong/weak operator topologies coincide, i.e. a linear functional on $B(\mathcal H)$ is strongly continuous if and only if it is weakly continuous. The same property is inherited by the sub-von Neumann Algebra $M$. Do you know how to prove this or can you share a reference on this matter? EDIT .
I have asked another more general question which could yield an answer to this concrete problem. See here . However, I am not conviced that there is a closed-graph theorem for the strong and weak operator topologies. 2nd EDIT (06.04.2017) I think one can prove WOT-WOT implies SOT-SOT in a straigthforward way: It suffices to prove that if $x_i \overset{\mathrm{SOT}}{\to} 0$ then $\pi(x_i) \overset{\mathrm{SOT}}{\to} 0$. We know that $$x_i \overset{\mathrm{SOT}}{\to} 0 \iff x_i^* x_i \overset{\mathrm{WOT}}{\to} 0 \tag{$\ast$}.$$ Now if $x_i \overset{\mathrm{SOT}}{\to} 0$, since $\pi$ is WOT-WOT continuous, ($\ast$) gives that $$\pi(x_i)^* \pi(x_i) = \pi(x_i^* x_i) \overset{\mathrm{WOT}}{\to} 0$$
which, again by ($\ast$) implies that $\pi(x_i) \overset{\mathrm{SOT}}{\to} 0$.","['reference-request', 'operator-theory', 'functional-analysis', 'von-neumann-algebras', 'topological-vector-spaces']"
2129106,Bolzano--Weierstrass Theorem implies Nested Interval Property,"This question is from abbott's Understanding Analysis: Start with the Bolzano--Weierstrass Theorem and use it to 
  construct a proof of the Nested Interval Property. My try: Let $I_n=[a_n,b_n]$ be closed intervals such that $I_1 \supseteq I_2 \supseteq \dots$. So here $a_n$ is a (nondecreasing) bounded sequence, so it contains a convergent subsequence by hypothesis, so does $b_n$. But here I am stuck. I have temptation to use Monotone Convergence Theorem, but that would imply that I am assuming Axiom of Completeness, or worse, Nested Interval Property itself!","['real-analysis', 'sequences-and-series']"
2129116,Derivative of a function involving diagonal matrix,"Let $A$ be a $n\times n$ matrix, $\text{diag}(x)$ is the diagonal matrix with $x$ on the diagonal. How can I find $dF(x)$ for $F(x) = \text{diag}(x)Ax$? Thank you very much in advance!","['derivatives', 'matrices', 'matrix-calculus', 'multivariable-calculus', 'linear-algebra']"
2129120,Probability of being a palindrome?,"I often see how people points out that a certain number is a palindrome in some base, the implication being that it is somewhat a special number. Of course such considerations are rather subjective, but that made me wondering; is it the property of being a palindrome so rare ? To be precise: What is the probability that a given natural number $n$ is a palindrome in at least one base $b\in\{2,3,\ldots,10\}$? What about if we let $b\in\{2,3,\ldots,n-2\}$? For those who might be bothered for the use of ""probability that a given natural number"": You can understand that I am asking about the natural density of palindromes, with the above precisions. I just stated the question as it is because I might content myself with some simulation or insight on the subject (the reason being that I haven't found much about this on the web and couldn't come up with an answer myself, so just in case it is harder than expected...), and because of future readers who might also be intrigued about this and don't know about natural density.","['probability', 'palindrome']"
2129121,How to complete this simple example of the Vitali-Hahn-Saks Theorem?,"I'm studying the Vitali-Hahn-Saks Theorem and I need some help with an example in which the conclusion of the theorem fails. Theorem. Let $(\Omega,\mathcal{F}, P)$ be a finite measure space, and let $(P_n)$ a sequence of finite measures on $(\Omega, \mathcal{F})$ each of which is absolutely continuous with respect to $P$. Suppose the sequence $(P_n(\Omega))$ is bounded. If $(P_n)$ converges setwise to the set function $P_\infty$, then $(P_n)$ is uniformly absolutely continuous with respect to $P$ ($\forall \epsilon > 0, \exists \delta>0, \forall n, \forall A \in \mathcal{F}, P(A) < \delta$ implies $P_n(A) < \epsilon$). Moreover, $P_\infty$ is a finite measure that is absolutely continuous with respect to $P$. I thought I'd cook up a simple example where uniform absolute continuity fails in order to see how setwise convergence fails. Start with a countable probability space given by $P(\omega_n) = 2^{-n}$. Let the events $E_n = \Omega - \cup_{i=1}^n \{\omega_i\}$. And let $P_n = P(\cdot \mid E_n)$. Note that $\inf_n\{P(E_n) \}=0$. The sequence $(P_n)$ is not uniformly absolutely continuous with respect to $P$. To see that let $\epsilon = 1/2$, and let $\delta > 0$ be given. For large enough $n$, $P(E_n) < \delta$ but $P_n(E_n) = 1 > \epsilon.$ Question. How to see that $(P_n)$ does not converge setwise? I've played around with a few example events $A$, but $(P_n(A))$ always converges. Hints are appreciated.","['real-analysis', 'limits', 'probability-theory', 'probability', 'measure-theory']"
2129126,Fréchet derivative of a functional.,"I need to show that the functional defined by
$$\int_{0}^{1} \cos(u(x)) dx$$ is not Fréchet differentiable in $L^2((0,1))$. A hint is that the requested property of the remainder for a Fréchet derivative is already violated for step functions. I was looking for similar questions and see that under a Taylor expansion, one can introduce a first order aproximation of $\cos(\cdot)$ and then take the second order residual as a step function. For example, If we consider the functional defined as
$$y(x)=\sin(u(x)), \quad u \in L^2(\Omega)$$
then we have
$$\sin(0+h(x))=\sin(0)+\cos(0)h(x)+\int_{0}^{1}[\cos(0+sh(x))-\cos(0)]ds$$
for $h\in L^p(0,1)$ given and $s \in (0,1)$. As far I know, that expansion is a  Taylor expansion in the integral form, but I dont see why we can put those terms in the integral, because I know that a expansion of this kind wold be of the form:
$$f(a+x)=f(a)+f'(a)x+\int_{0}^{1}\frac{f''(a+sx)}{2}x^2ds.$$ Is the last expression wrong? And, would it be usefull a Taylor expansion to show the non-differentiability of the first functional given? A important fact is that in the $\sin(\cdot)$ example, taking $h$ as the step function
$$h(x)=\begin{cases}1,&x\in [0,\epsilon]\\0,&x\in[\epsilon,1]\end{cases}$$ it's possible to show the non-differentiability of $\sin(\cdot)$ as a funtional, and I was thinking in a similar argument. Please any help with this question will be aprecciated. Thanks.","['functional-analysis', 'optimization', 'analysis']"
2129216,numbers in non-decreasing order,"How many numbers smaller than one million have digits in a non-decreasing order? I tried doing it by finding numbers with strictly decreasing order, and subtracting them from $1000000.$ $$1000000-\left( {10 \choose 6}+{10 \choose 5}+{10 \choose 4}+{10 \choose 3}+{10 \choose 2}\right)$$ I'm choosing 6 unique digits out of 10 and put it in decreasing order (we can put every 6 numbers in decreasing order) and so on. So I subtract the number of decreasing ordered numbers from one million. Is it a good way of thinking?","['combinatorics', 'discrete-mathematics']"
2129237,elementary set theory (being a member and subset of a set)?,"I have to prove or give a counterexample for these two statements: For the following statements about sets $A$ , $B$ , and $C$ , either prove the statement is true or give a counterexample to show that it is false. A. If $A \in B$ and $B \subseteq C$ , then $A \subseteq C$ . B. If $A \in B$ and $B \subseteq C$ , then $A \in C$ . I tried to do it by creating random sets like $A = \{2\}$ , $B = \{2,3\}$ and $C = \{2,3,4\}$ and so both statements would be true right? I can't think of a counterexample but I don't know how to actually prove these statements. Also, if A was the empty set then wouldn't both statements always be true (because the empty set is a member of every other set)?","['elementary-set-theory', 'discrete-mathematics']"
2129251,There is a (unique) compactification $X^*$ where $X^*-X=\{w\}$ of $X$ if $X$ is locally compact,"I've been trying to prove the following proposition: Let $X$ be a locally compact Hausdorff space. Then, there is a (unique) compactification $X^*$ where $X^*-X=\{w\}$, with $w$ a point of $X^*$. (For now, I'm not interested in proving uniqueness, only existence). As far as I understand, we can define compactification as follows: Definition: Let $X$ be a nonempty set. If $Y$ is a compact space,$X$ is a subset of $Y$ and $X$ is dense in $Y$, then we say that $Y$ is a compactification of $X$. Question 1: Is this the most general definition? So, I must find a set $X^*=X\cup \{w\}$ such that $X^*=\overline{X}$. Question 2: How exactly can I go about it? EDIT: I know that the chosen topology for $X^*$ is of the form 
$$
\tau^*=\tau \cup \{X^*-C : C\text{ is compact and } C\subseteq X \}
$$
and I want to know how can I motivate this topology. (This can replace my second question). What I thought: $\{w\}$ can't be open in $X^*$ since $X^*$ is the closure of $X$, and if $\{w\}$ is open there is one point of $X^*$ which has a neighborhood with no points of $X$ (contradiction). $X$ must have the subspace topology. Hence, given an open set $U$ of $X$, it must be $U=X\cap U^*$ for some open set $U^*$ of $X^*$. One way this can happen is if $U$ is open in $X^*$. The other one is if $U\cup \{w\}$ is open in $X^*$. So, for each open set $U$ of $X$, either $U$ is open in $X^*$ or $U\cup \{w\}$ is (or both). I'm not seeing how one excludes these second ones, and also how one uses the compactness of $X^*$ to motivate the $\{X^*-C : C\text{ is compact and } C\subseteq X \}$ part of the topology.",['general-topology']
2129293,Transition from a Riemann sum to an Integral,"The Riemann sum over an interval $[a,b]$ is usually defined as
$$\lim\limits_{N\to\infty}\sum\limits_{k=0}^Nf\left(a+k\cdot\frac{b-a}{N}\right)\frac{b-a}{N}$$ Thus if we encounter a sum of the form
$$\lim\limits_{N\to\infty}\sum\limits_{k=0}^Nf\left(k\cdot\frac{1}{N}\right)\frac{1}{N}$$
we can conclude that it is equal to an integral over the interval $[0,1]$.
$$\lim\limits_{N\to\infty}\sum\limits_{k=0}^Nf\left(k\cdot\frac{1}{N}\right)\frac{1}{N}=\int_0^1f(x)dx\tag{1}\label{1}$$ What can we conclude about the following sum $$\lim\limits_{N\to\infty}\lim\limits_{M\to\infty}\sum\limits_{k=0}^M f\left(k\cdot\frac{1}{N}\right)\frac{1}{N}\tag{2}\label{2}$$ To clarify, this is an infinite sum \eqref{2}, that differs from the Riemann sum \eqref{1}, in the upper limit of the sum. In the Riemann sum \eqref{1}, there is a relation between $M$ and $N$, namely $N=M$, while there is no such relation specified in \eqref{2}. If we can equate it to an integral, how are we to determine the limits of integration? The equation \eqref{2} is to be taken, that the $M\to\infty$, we thus have an infinite sum (suppose it is convergent). Than we form a sequence of infinite sums, where $N$ increases for each element of the sequence. That is
$$S_N=\lim\limits_{M\to\infty}\sum\limits_{k=0}^M f\left(k\cdot\frac{1}{N}\right)\frac{1}{N}$$
What does this sequence tend to? Is it true that (or when is it true)
$$\lim\limits_{N\to\infty}S_N=\int_0^\infty f(x)dx$$ Also the general term in \eqref{2} is $C_k=f\left(k\cdot\frac{1}{N}\right)$. How does it behave in the limit, namely
$$\lim\limits_{N\to \infty}\lim\limits_{M\to \infty}f\left(M\cdot\frac{1}{N}\right)$$","['riemann-sum', 'integration', 'definite-integrals', 'limits']"
2129311,How many numbers smaller than $10^6$ contain exactly three '$9$'s and have an odd sum of digits?,"i came up with an idea that i choose Even Even Even 9 9 9 - and i sort it in ways such that 
all even are the same - $\frac{6!}{3!*3!}$
two are the same - $\frac{6!}{3!*2!}$
all are different - $\frac{6!}{3!}$ other one is that Odd Odd Even 9 9 9 odd are the same - $\frac {6!}{3!*2!}$
all three are differnt - $\frac{6!} {3!}$ and my result is a sum of all this options.
Am i right?","['combinatorics', 'discrete-mathematics']"
2129326,On an expansion of $(1+a+a^2+\cdots+a^n)^2$,"Question: What is an easy or efficient way to see or prove that
  $$
1+2a+3a^2+\cdots+na^{n-1}+(n+1)a^n+na^{n+1}+\cdots+3a^{2n-2}+2a^{2n-1}+a^{2n}\tag{1}
$$
  is equal to
  $$
(1+a+a^2+\cdots+a^n)^2\tag{2}
$$
  Maybe this is a particular case of a more general, well-known result? Context: This is used with $a:=e^{it}$ to get an expression in terms of $\sin$ for the Fejér kernel . Thoughts: I thought about calculating the coefficient $c_k$ of $a^k$. But my method is not so obvious that we can get from $(1)$ to $(2)$ in the blink of an eye. $\mathbf{k=0}$ : clearly $c_0=1$. $\mathbf{1\leq k\leq n}$ : $c_k$ is the number of integer solutions of $x_1+x_2=k$ with $0\leq x_1,x_2\leq k$, which in turn is the number of ways we can choose a bar $|$ in
$$
\underbrace{|\star|\star|\cdots|\star|}_{k\text{ stars}}
$$
So $c_k=k+1$. $\mathbf{k=n+i\quad(1\leq i\leq n)}$ : $c_k$ is the number of integer solutions to $x_1+x_k=n+i$ with $0\leq x_1,x_2\leq n$, which in turn is the number of ways we can choose a bar $|$ in
$$
\underbrace{|\star|\star|\cdots|\star|}_{n+i\text{ stars}}
$$
different from the $i$-th one from each side. So $c_k=(n+i)+1-2i=n-i+1$.","['algebra-precalculus', 'combinatorics', 'factoring']"
2129331,"Find a finite generating set for $Gl(n,\mathbb{Z})$","I need to find a finite generating set for $Gl(n,\mathbb{Z})$. I heard somewhere once that this group is generated by the elementary matrices - of course, if I'm going to prove that $GL(n,\mathbb{Z})$ has a finite generating set, I would need to prove that any matrix $M\in  GL(n,\mathbb{Z})$ can be generated by only finitely many of them. At first, I didn't have a clue as to how to do this, so I did a bit of scouring the internet for any information that might be useful. There were a few proofs or hints at proofs, including here on MSE and also on MathOverflow, but they were either too advanced, didn't give enough details, assumed theory I can't assume at this point (for example about rings or principle ideal domains), or were extremely complicated (as in 4 pages with 4 lemmas that needed to be proven first - and this example didn't even prove exactly what the finite generator of $GL(n,\mathbb{Z})$ is). This looks promising. In their notation, essentially, if $n$ is even, then $GL(n,\mathbb{Z})$ is generated by $s_{1}$ and $s_{3}$ And when $n$ is odd, $-s_{1}$ and $s_{3}$ generate $GL(n,\mathbb{Z})$, where $s_{1}=\begin{pmatrix} 0&0&0&\cdots &0&1\\ 1&0&0&\cdots & 0&0\\0&1&0&\cdots & 0 &0 \\ \vdots & \vdots & \vdots & & \vdots &\vdots \\ 0&0&0&\cdots & 0&0\\ 0&0&0&\cdots &1 & 0\end{pmatrix}$ and $s_{3}=\begin{pmatrix} 1&1&0&\cdots &0&0\\ 0&1&0&\cdots & 0&0\\0&0&1&\cdots & 0 &0 \\ \vdots & \vdots & \vdots & & \vdots &\vdots \\ 0&0&0&\cdots & 1&0\\ 0&0&0&\cdots &0& 1\end{pmatrix}$ How is a relatively simple way to prove this, that does not invoke rings or ideals at all (only group theory is permissible), and does not amake reference so to papers or $Hom(G,C_{p})$ (whatever that is)? I'm guessing since the group operation in $GL(n,\mathbb{Z})$ is matrix multiplication, I'm guessing I'd have to show that any matrix $A$ can be generated by multiplying various combinations of $s_{1}$ and $s_{3}$ in the case when $n$ is even and various combinations of $-s_{1}$ and $s_{3}$ in the case when $n$ is odd. But what do those combinations look like when we're dealing with matrix multiplication? Do they include scalar multiples like integer linear combinations when the operation is addition? And how do we know what order to put them in, since matrix multiplication is not commutative? Thank you.","['linear-groups', 'matrices', 'abstract-algebra', 'finite-groups', 'group-theory']"
2129365,The matrix exponential is smooth,"Let $ \exp : M(n, \mathbb{C}) \rightarrow GL(n, \mathbb{C}) $ be the matrix exponential defined by $$ \exp(X) = \sum_{k=0}^{\infty} \frac{X^k}{k!} $$
Is this map smooth as a map from $ \mathbb{C}^{n^2} \rightarrow \mathbb{C}^{n^2} $ ? My attempt: I show that the derivative at $ 0 $, $ D\exp(0) $ is the identity linear transformation on $ \mathbb{C}^{n^2} $, thus the derivative is nonsingular. This is because we have $$ \frac{|| \exp(H) - \exp(0) - H ||}{||H||} = \frac{||\sum_{k=2}^{\infty} \frac{H^k}{k!}||}{||H||} \le \sum_{k=1}^{\infty} \frac{||H||^{k}}{(k+1)!} $$ and the limit of the last expression as $ ||H|| \rightarrow 0 $ is clearly $ 0 $. My problems begin at the following: (1) I can calculate the derivative only at scalar matrices in $ M(n, \mathbb{C}) $ (I need commutativity for the identity $ \exp(A+B)=\exp(A)\exp(B) $ to hold) (2) I cannot apply the inverse function theorem yet, because I have established differentiability at only a point. How would one get around these difficulties? I know that the inverse function theorem holds for analytic functions too, but I would like to avoid it, and in any case, I would need to show that the derivative is nonsingular everywhere. I cannot see a coordinate free approach.","['matrices', 'lie-algebras', 'lie-groups']"
2129368,The integral of $\left|\frac{\cos x}x\right|$,"I'm looking to determine whether the following function is unbounded or not:
$$
F(x) = \int_1^x\left|\frac{\cos t}{t}\right|\text{d} t
$$
I can't seem to do much with it because of the $|\cos(t)|$. I thought of using the fact that $\int |f| \ge |\int f|$, but the problem is that the integral of $\frac{\cos t}t$ (without the absolute values) is bounded, and so that doesn't prove that $F(x)$ is unbounded or bounded. I tried re-expressing this as a cosine integral (the function $\text{Ci}(x)$) but to no avail. I'm not sure where else to go with this; the main problem seems to be the fact that its very difficult to derive an inequality with the $|\cos(t)|$ without a $|\cos(t)|$ on the other side of the inequality (or at least some trig function). Any help would be appreciated.","['definite-integrals', 'integration', 'trigonometry', 'calculus']"
2129419,Is it possible that the only proper subgroups of a finite group are p-groups?,"I wonder whether it is possible that the only proper subgroups of a finite group are p-groups (of course, except the case when the whole group is a p-group). I know that I can't find it in solvable groups. After investigating some small simple groups, I think it is possible to prove that such a group doesn't exist. How to do it? Edit: Except $|G|=pq$ and $|G|$=$p^2q$, $p,q$-primes. I forgot about it.","['finite-groups', 'group-theory']"
2129420,Totient function: $φ(2^n)$,"I was wondering how to go about finding $\varphi(2^n)$. I know that $\varphi(2)=1$ and that $φ(mn) = φ(m)φ(n)$, but in this case having $\varphi(2^n) = \varphi(2\times2\times2\cdots\times 2)$ does not work since we end up with $1$ and this is not the answer.","['combinatorics', 'totient-function', 'discrete-mathematics']"
2129470,Error in Textbook Appendix; Or my Error?,"I'm taking a discrete mathematics course. We are covering logic and proofs in the current section, specifically argument form and validity. I am doing one of the practice problems which is similar to an assigned problem that I must turn in for credit, and the provide answer to the practice problem seems to contradict what is said in the text, as well as contradict itself. There is either a mistake, or I am somehow mistaken. So here is the basis of what I'm doing. The problem is to construct a truth table from a set of provided premises and a provided conclusion. The truth table will indicate whether or not the the argument has valid form. This is done determining if the truth value of the conclusion is true wherever all premises are true. I am also instructed to highlight the premises in the truth table. So when setting up the truth table I break the premises down to there individual components and expand out to the whole of the premises. The most basic of individual components are p, q, and r. But then there are inverses and possible combinations of these that may be part of the problem, but as I understand, are not part of the premises as a whole. In the appendix all components other than the most basic p, q, and r, are being marked as the premises. Earlier in the chapter it is not explained this way. One is not to even test the conclusion for it's truth value unless all premise of the same row are true, and some of the components in which the example has marked as being part of the premises aren't even true, and the book still tests the conclusion for it's truth value there. What is actually part of what I believed to be the premise is in fact true in these rows though, making it rightly so that the conclusion should be tested for it's true or false value. I hope what I am explaining is understandable, as I'm new to this branch of mathematics so I'm a little fuzzy on my explaining abilities here. I will upload some pictures of what's happening. From the chapter: The above example shows that the only part being marked as the premises are the actual parts that are wholly in the originating argument. This is from the textbooks chapter on this subject . From the appendix: The above example is from the Appendix which provides an example answer to one the questions at the end of the chapter. As you can see it has marked the individual component of NOT q as one of the premises. NOT q does not show up on its own in the individual argument, and it isn't even true in the last 2 rows in which the conclusion was tested. What I perceive to be the premises are the three columns to the right of NOT q. I don't think NOT q is supposed to be part of the premises. I just want to get it right so I can turn in accurate work. Either the answer to the example question provided is wrong, because it seems to differ from what the example in the chapter shows, or I am missing something. Please advise.","['logic', 'discrete-mathematics']"
2129475,Prove if $\lim_{x\to\ c} \ f'(x) = K$ then $f'(c) = K$ [duplicate],"This question already has answers here : Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$. (6 answers) Closed 7 years ago . Suppose $f: (0, 1) \rightarrow {\rm I\!R}$ is continuous, with $c \in (0, 1)$, and suppose that $f'$ exists $\forall x \in (0, 1)$\{$c$}. Prove that if
$\lim_{x\to\ c} \ f'(x) = K$ then $f'(c) = K$. $$\lim_{x\to\ c} \ f'(x) = K \Rightarrow \forall \epsilon > 0, \exists \delta > 0 \text{ such that } |f'(x) - K| < \epsilon \text{ for } x \in (c-\delta, c+\delta)$$ Since $f$ is continuous and differentiable on the open interval we can use the Mean Value Theorem on $[x, c]$ where $x \in (c-\delta, c)$. So $\exists x_1 \in (x, c)$ such that $f'(x_1) = \frac{f(x) - f(c)}{x-c}$. By our limit definition $|f'(x_1) - K| = |\frac{f(x) - f(c)}{x-c} - K| < \epsilon$. $$\Rightarrow \left|\frac{f(x)-f(c)}{x-c} - K\right| < \epsilon \text{ for } x \in (c-\delta, c)$$ We can use the MVT again on $[c, x]$ where $x \in (c, c+\delta)$, find an $x_2 \in (c, c+\delta)$ and get similar result. $$\Rightarrow \left|\frac{f(x)-f(c)}{x-c} - K\right| < \epsilon \text{ for } x \in (c-\delta, c+\delta)$$ $$\Rightarrow \lim_{x\to\ c} \frac{f(x)-f(c)}{x-c} = K$$ $$\Rightarrow f'(c) = K$$ I'm not sure that I did this right - I'm not too comfortable with proofs yet (especially unfamiliar with using the MVT in proofs). I didn't use the fact that the domain of f is (0,1) which is concerning.","['real-analysis', 'proof-writing', 'analysis', 'proof-verification']"
2129533,Folland Real Analysis 5.2,"In Folland's second edition of Real Analysis , part of Proposition 5.2 (paraphrased) reads: Let $\mathcal X$ and $\mathcal Y$ be normed vector spaces and
  $T:\mathcal X\to\mathcal Y$ a linear map. If $T$ is continuous at $0$,
  then $T$ is bounded. His proof is as follows: If $T$ is continuous at $0\in\mathcal X$, there is a neighborhood $U$
  of $0$ such that $T(U)\subset\{y\in\mathcal Y:\|y\|\leq1\}$, and $U$
  must contain a ball $B=\{x\in\mathcal X:\|x\|\leq\delta\}$ about $0$;
  thus $\|Tx\|\leq1$ when $\|x\|\leq\delta$. Since $T$ commutes with
  scalar multiplication, it follows that $\|Tx\|\leq a\delta^{-1}$
  whenever $\|x\|\leq a$, that is,
  $\color{red}{\|Tx\|\leq\delta^{-1}\|x\|}$. I do not understand how the highlighted part was obtained since $\|x\|\leq a$ (It would make sense to me if $\|x\|\geq a$.).","['functional-analysis', 'real-analysis', 'banach-spaces', 'linear-transformations']"
2129537,How to integrate $\int_{0}^{1} \frac{1-x}{1+x} \frac{dx}{\sqrt{x^4 + ax^2 + 1}}$?,"The question is how to show the identity $$ \int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{x^4 + ax^2 + 1}} = \frac{1}{\sqrt{a+2}} \log\left( 1 + \frac{\sqrt{a+2}}{2} \right), \tag{$a>-2$} $$ I checked this numerically for several cases, but even Mathematica 11 could not manage this symbolically for general $a$, except for some special cases like $a = 0, 1, 2$. Addendum. Here are some backgrounds and my ideas: This integral came from my personal attempt to find the pattern for the integral $$ J(a, b) := \int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{1 + ax^2 + bx^4}}. $$ This drew my attention as we have the following identity $$ \int_{0}^{\infty} \frac{x}{x+1} \cdot \frac{dx}{\sqrt{4x^4 + 8x^3 + 12x^2 + 8x + 1}} = J(6,-3), $$ where the LHS is the integral from this question . So establishing the claim in this question amounts to showing that $J(6,-3) = \frac{1}{2}\log 3 - \frac{1}{3}\log 2$, though I am skeptical that $J(a, b)$ has a nice closed form for every pair of parameters $(a, b)$. A possible idea is to write \begin{align*}
&\int_{0}^{1} \frac{1-x}{1+x} \cdot \frac{dx}{\sqrt{x^4 + ax^2 + 1}} \\
&\hspace{5em}= \int_{0}^{1} \frac{(x^{-2} + 1) - 2x^{-1}}{x^{-1} - x} \cdot \frac{dx}{\sqrt{(x^{-1} - x)^2 + a + 2}}
\end{align*} This follows from a simple algebraic manipulation. This suggests that we might be able to apply Glasser's master theorem, though in a less trivial way. I do not believe that this is particularly hard, but I literally have not enough time to think about this now. So I guess it is a good time to seek help.","['integration', 'definite-integrals']"
2129538,"Using importance sampling to simulate the mean of a normal distribution truncated to interval [0,1]","So in these notes it says that importance sampling is:
$$\int_F sf(s)ds = \int_G s \frac{f(s)}{g(s)}g(s)ds$$ And then it proceeds to give the following example: In this example, if we draw from $f(x)$, are we effectively drawing from the truncated standard normal distribution? Also, can someone explain why it says that $g(x)=1$ if we draw $x$ from $U[0,1]$?","['simulation', 'normal-distribution', 'sampling', 'statistics', 'probability']"
2129541,Number of $32$-character alphanumeric strings with certain conditions,"I'm seeking a solution of one of the most complicated Math problem of my life. Here it is : First we need to figure out how many strings of set [a-zA-Z0-9] (Which is 26 Small Letters, 26 Capital Letters, and 0 to 9 digits] Are possible to construct of length 32 characters . Then we need to subtract these 3 out of our result. Possible 32 character strings which has only small letters . [a-z] Possible 32 character strings which has only big letters . [A-Z] Possible 32 character strings which has only digits . [0-9] Let me know if any questions.",['combinatorics']
2129549,Parameterising the intersection of a plane and paraboloid,"Suppose we have the paraboloid $z=x^2+y^2$ and the plane $z=y$. Their intersection produces a curve $C$, and certain surfaces bounded by it, for example the disc $S$ which directly fills the area of $C$ and the paraboloid $S'$ given by $z=x^2+y^2$ which extends from $C$ downwards and is bounded by $C$. My question is on how to parameterise these objects. My initial instinct is to substitute one equation into the other giving the circle $(y-\frac{1}{2})^2+x^2=\frac{1}{4}$. Now I could go ahead and parameterise this circle using polars or even do integrals directly using $x$ and $y$. But this gives the projection of the intersection of the plane and paraboloid in the xy-plane. But I have not directly parameterised $C$. Since the $z=y$ plane makes a $45$ degree angle with the xy-plane, I think that we can introduce a factor of $\sqrt2$ into our parameterisation, but I would like to know if there is a way to directly parameterise $C$ (and also the surfaces $S$ and $S'$)? Note my question is similar to this one except instead of being level, my disc is slanted (and I would also like to find out how to parameterise the 'bowl shaped' surface). Many thanks for any help.","['surface-integrals', 'multivariable-calculus', 'parametric', 'parametrization', 'surfaces']"
2129555,Linear isometry between Hilbert spaces has a closed range,Let $U$ be a linear isometry between Hilbert spaces. Why does the fact that the range of $U$ is dense imply that the range of $U$ is closed? I am trying to understand the proof of theorem 5.4 in Conway's A Course in Functional Analysis .,"['functional-analysis', 'isometry', 'hilbert-spaces']"
2129623,Linear Map is injective iff Adjoint has dense image,"$A,B$ are locally convex topological spaces, $f:A\to B$ is linear, continuous. I want to verify the adjoint map has dense image in $A^*$ with respect to the weak* topology if and only if $f$ is injective. Attempted Proof: 
If $fx=0$ then $\langle fx,g\rangle=0$ for each $g\in A^*$. Hence $\langle x,f^*g\rangle=0$ so the denseness implies $\langle x,g\rangle=0$ for each $g\in A^*$. Thus $x=0$. On the other hand, suppose the range is not dense. By Hahn Banach, there is some nonzero $g\in A^*$ such that $g(fx)=0$ for each $x\in A$. Then $\langle x,f^*g \rangle=0$ for all $x$. So $f^*g=0$. This is a contradiction since injectivity of $f^*$ means that $g=0$. Question: Am I using the correct version of Hahn-Banach? And does my argument show that $f^*$ has dense image with respect to the weak topology?","['functional-analysis', 'locally-convex-spaces']"
2129679,Is the sum of the entries of a symmetric positive semidefinite matrix positive?,"Given that $A$ is an $n\times n$, symmetric and positive semidefinite, how would you prove that the sum of the entries of $A$ is positive?","['matrices', 'symmetric-matrices', 'positive-semidefinite', 'linear-algebra']"
2129697,Calculate the radius of a helix,"This is actually an applied engineering situation, not a homework problem. I hope this is the right forum to ask for help. I have a cable with a minimum bend radius of 10 cm. I need to coil it around a cylinder to make a helix shape. I understand that if I coil with a small pitch (near 90°, based on this diagram ) the cylinder will need to have a 10 cm radius. But if I coil the cable with a large pitch, the cylinder can be much smaller. I've looked into the equations for the helix, but the radius in those equations is the cylinder radius, not the radius of the coil. I'm trying to find the relationship that tells me the pitch if I have a 5 cm cylinder and the 10 cm minimum radius constraint. Or conversely, if I want 10 cm vertical coil spacing, and have the 10 cm radius constraint, what is the minimum cylinder radius?","['curves', 'geometry']"
2129720,Computing surface integral on paraboloid,"This question is loosely related to a question I asked earlier today about surface parametrisation. I have the vector field $\boldsymbol{v}=(2z,x,y)$ and want to find the surface integral $$  \int_S (\nabla \times \boldsymbol{v}) \cdot d\boldsymbol{A} $$ where $S$ is the surface of the paraboloid $z=x^2+y^2$ underneath the plane $z=y$, bounded by the curve $C$ formed by the intersection of the paraboloid $z=x^2+y^2$ and the plane $z=y$. I realise that there are simpler surfaces to pick (the disc) or I could use Stokes' Theorem and find the line integral over $C$, but my question specifically concerns the surface described above. I can use the fact that we have a level set $$ f=x^2+y^2-z=0 \implies \nabla f = (2x, 2y, -1)$$
which describes our surface and the normals to it. Then by a well known result, $$  
\begin{split}
\int_S (\nabla \times \boldsymbol{v}) \cdot d\boldsymbol{A} &= \int_A \frac{ (\nabla \times \boldsymbol{v}) \cdot \nabla f}{\boldsymbol{e}_3 \cdot \nabla f} \, dx \, dy  \\
&=\int_A(1-2x-4y) \, dx \, dy
\end{split}
$$ but I'm not really sure where to go from here (i.e. how to pick the limits of integration). I was thinking about parameterising the projection of $C$ in the $xy$ plane using polars but this seems completely wrong as I'm considering the surface of the paraboloid, not the disc. But I have no idea how you'd find the limits to use here/how you would even parameterise the paraboloid's surface to do the integral. There are a lot of questions similar to this one on this site, but having read a lot of them, I'm still unsure as to whether a problem like this always gets reduced to a region in the $xy$ plane or if sometimes, you have to do some kind of a 3d parameterisation. The answer for me seems to be no, having looked at the proof of the result I've used above, and also simply due to the fact that the integral only has $dx \, dy$ at the end - no $dz$. I'd be very grateful if anyone could shed some light on this - thanks.","['surface-integrals', 'multivariable-calculus', 'parametric', 'integration', 'surfaces']"
2129756,"Why is this ""proof"" of the Uniform Boundedness Principle via the contrapositive erroneous?","In class, we stated the Uniform Boundedness Principle as follows: Let $X$ be a Banach space, let $Y$ be a normed vector space, and let $A \subseteq L(X, Y)$ be a family of bounded linear operators.  If for each $x \in X$, $\sup\{\Vert T(x) \Vert \; \vert \; T \in A \} \lt \infty$, then $\sup\{\Vert T \Vert \; \vert \; T \in A \} \lt \infty$. We then proved the result directly, making use of the Baire Category Theorem along the way. I had a notion that the proof of the UBP would have been much easier using the contrapositive.  I immediately suspected that I was wrong, but I asked my professor about this because I couldn't discern why my ""proof"" would be wrong.  He told me that I was negating the conclusion incorrectly, but I still don't really understand why.  Can someone please explain to me why the following ""proof"" is erroneous? Proof: We proceed via the contrapositive.  Assume that $\sup\{\Vert T \Vert \; \vert \; T \in A \} = \infty$.  Then there exists some $S \in A$ such that $S$ is unbounded.  Hence, by the definition of the operator norm, it follows that there exists some $y \in X$ such that $\Vert S(y) \Vert = \infty$.  QED. Actually, I think I may have answered my own question in the process of formally typing it up.  The fact that $\sup\{\Vert T \Vert \; \vert \; T \in A \} = \infty$ can still hold even when every operator in $A$ is actually bounded, right?  Did I find my own mistake, or am I still missing something important? Thank you.","['functional-analysis', 'normed-spaces', 'banach-spaces']"
2129764,"Consider events $A, B, C$ such that $P(A\mid B) > P(A)$ and $P(B\mid C) > P(B)$.","Hey guys I have a problem that I'm having trouble solving. Here is the question: Consider events $A, B, C$ such that $P(A\mid B) > P(A)$ and $P(B\mid C) > P(B)$. Does it follow that $P(A\mid C) > P(A)$? Either prove it to be so or provide a counterexample. And here is what I have so far: Partial solution I would greatly appreciate it if you guys can give a hit or a suggestion to complete the problem.","['statistics', 'probability', 'combinatorial-proofs']"
2129772,What method did this person use to rotate the points in 2D Space to imitate 3D Rotation?,"I've been wondering about how people seem to rotate graphs on a 2D area, and came across this Desmos 2D graph, found Here (desmos.com) . Once I saw this, I looked at the equations and was blown by the complexity to rotate them with different variables ($a$, $b$, and $c$). An example of the one of the equations of the points, which are cartesian in the format of $(x,y)$: $\left(\cos (u)\cos (v)-\sin (u)\cos (v)+\sin (v),\sin (u)\sin (w)-\cos (u)\sin (v)\cos (w)+\sin (u)\sin (v)\cos (w)+\cos (u)\sin (w)+\cos (v)\cos (w)\right)$ Quite the long equation to find a point- but understandable. I'm just interested in knowing the mathematical reasoning behind him using the functions to find the location of the points, not the lines (They are just connecting multiple points). Is this related to the rotation matrix in any way? Or is it using something else that I could possibly know the name of so I could pursue future research? Thanks!","['trigonometry', 'rotations']"
2129830,Is every open set the interior of a closed set?,"I am wondering if this is generally true for any topology. I think there might be counter examples, but I am having trouble generating them.",['general-topology']
2129859,"Explanation of a proof in Colding-Minicozzi's ""A Course in Minimal Surfaces"".","I have just started reading ""A Course in Minimal Surfaces"" by Colding-Minicozzi on my own. I have to clarify some points in the proof of a lemma given in the book. On page $30$ of the book, they prove the following lemma (Lemma $1.19$) Now I understand that since the image of the Gauss map $N$, in this case is the upper hemisphere, which is contractible and exterior derivative commutes with pullback, hence $N^*\omega =N^*(d\alpha)=d(N^*\alpha)$ What I don't understand are the following two points :- 1) Why is $|A|^2d$Area=$-2Kd$Area=$2N^*\omega$ ? Here $A$ is the Second Fundamental form and $K$ is the Gaussian curvature. I know that for a minimal graph $|A|^2=-2K$ so the first equality is fine. But why the second equality ? 2) It's written ""since $\alpha$ is a one form, hence $\exists$ a constant $C_{\alpha}$ so that $|N^*\alpha|\leq C_{\alpha}|dN|$"" ? Why is this true ?
Also, on what quantities does this constant $C_{\alpha}$ depends ? Thank you for your help.","['minimal-surfaces', 'riemannian-geometry', 'differential-geometry', 'proof-explanation']"
2129863,Show E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big] = \frac{(n-1)p((1-p)}{n^2}$,"I am trying to show E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big] = \frac{(n-1)p((1-p)}{n^2}$, for $X_1, X_2,\ldots, X_n\sim\operatorname{b}(1,p)$. I can get to E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big]$ = $\frac{1}{n^2}(np) - (\frac{1}{n}E\big[\bar{X}^2\big])$,which I'm pretty sure is correct, but I'm having trouble simplifying E$\big[\bar{X}^2\big]$. I have: \begin{align} 
\frac{1}{n} E\big[\bar{X}^2\big] &= \frac{1}{n^3} E\big[\sum_{i=1}^n X_i^2\big]\\ 
&= \frac{1}{n^3} E\big[(\sum_{i=1}^n X_i)(\sum_{i=1}^{n}X_i)\big]\\ 
&= \frac{1}{n^3} \Big(\sum_{i=1}^n\big(E(X_i)E(X_i)\Big)\\
&= \frac{1}{n^3} \Big(\sum_{i=1}^n(np)^2\Big)\\
&= \frac{1}{n^3} (n^3p^2)\\
&= p^2 \end{align}   If I use $p^2$, however, then I get $(\frac{1}{n^2})np - p^2 = \frac{p(1-np)}{n}$, which is incorrect. If someone could explain where I've gone wrong I'd greatly appreciate the help. Thank you very much.",['statistics']
2129898,How can we show that $4\arctan\left({1\over \sqrt{\phi^3}}\right)-\arctan\left({1\over \sqrt{\phi^6-1}}\right)={\pi\over 2}$,"$$4\arctan\left({1\over \sqrt{\phi^3}}\right)-\arctan\left({1\over \sqrt{\phi^6-1}}\right)={\pi\over 2}\tag1$$
  $\phi$;Golden ratio I understand that we can use $$\arctan{1\over a}+\arctan{1\over b}=\arctan{a+b\over ab-1}$$ that would take quite a long time and simplifying algebraic expressions involving surds is also difficult task to do. How else can we show that $(1)={\pi\over 2}$?","['golden-ratio', 'trigonometry']"
2129905,Children disliking in square,"$n^2\geq 4$ children are to be placed in an $n\times n$ square. Some pairs of children dislike each other and do not want to be next to each other. Disliking is mutual, and being next to each other means being directly above/below/left/right of each other. What is the maximum $k$ such that if each child dislikes no more than $k$ other children, then a placement is always possible? If a child dislikes $n^2-2$ other children, a placement is obviously not possible because we cannot find two children to be next to this child even if we place the child in a corner. To do better than this, we can divide the children into two groups of roughly equal size, and let each child dislike all children in the other group. Then each child dislikes about $n^2/2$ other children, and clearly we cannot place them in the square in the desired way.","['combinatorics', 'graph-theory']"
2129912,Find the equivalent value of radians,"A function $f$ is called periodic with period $T$ if $f (x + T ) = f (x)$ (for all x) and $T$ is the smallest positive number with this property. The sine and cosine functions are periodic with period $T = 2\pi$ because the radian measures $x$ and $x + 2\pi k$ correspond to the same point on the unit circle for any integer $k$: $$\textbf{sin x = sin(x+2pi k)}$$ Now that The Point $P$ on the unit circle corresponding to the angle $\theta=\displaystyle\frac{4\pi}3$ lies opposite with angle $\theta=\displaystyle\frac{\pi}3$. $$\sin\frac{4\pi}3 = - \sin\frac{\pi}3$$ But how do I find the relation as to why $\displaystyle\sin\frac{4\pi}3 = - \sin\frac{\pi}3$ ? I tried $$\pi/3 = \pi/3+ 2\pi (1/2)$$ According to the definition above so that $\pi/3 = 4\pi/3$. But with this, it'll take a while to find the $k$ is $1/2$. Are there any short ways to find out why  $\sin\frac{4\pi}3 = - \sin\frac{\pi}3$? Assuming you never know that $2\pi =  360^{\circ} $. Additional information I read: In general, two radian measures represent the same angle if the corresponding rotations differ by an integer multiple of $2\pi$. But I couldn't seem to link $\sin\frac{4\pi}3 = - \sin\frac{\pi}3$ with this approach.",['trigonometry']
2129950,Convolution formulas,"I have a doubt about convolution. I have found this definition : $$(f*g)(t)=\int_{-\infty}^{+\infty} f(t-\alpha) \ g(\alpha) \ d\alpha$$ This integral does not converge: $$\cos(t)*t=\int_{-\infty}^{+\infty} \cos(t-\alpha) \ \alpha  \ d\alpha$$ Contrariwise:
$$ \mathscr{L} \{ \cos(t) * t \} =\mathscr{L} \{ \cos(t) \} \ \mathscr{L} \{t \}=\frac{1}{s^3+s}$$ Partial fraction decomposition: $$\frac{1}{s^3+s}=\frac{A}{s}+\frac{B}{s-i}+\frac{C}{s+i}$$ $$A=\lim_{s\rightarrow 0} \ \frac{1}{s^2+1}=1$$
$$B=\lim_{s\rightarrow i} \ \frac{1}{s^2+is}=-\frac{1}{2}$$
$$C=\lim_{s\rightarrow -i} \ \frac{1}{s^2-is}=\frac{1}{2}$$ $$\frac{1}{s^3+s}=\frac{1}{s}+\frac{-\frac{1}{2}}{s-i}+\frac{\frac{1}
{2}}{s+i}$$ $$\mathscr{L}^{-1} \{ \frac{1}{s}+\frac{-\frac{1}{2}}{s-i}+\frac{\frac{1}{2}}{s+i}  \}=1-\frac{1}{2} \ e^{it}+\frac{1}{2} \ e^{-it}$$ Then, I have found  this other definition of convolution (in a lesson about Laplace transform): $$(f*g)(t)=\int_{0}^{t} f(t-\alpha) \ g(\alpha) \ d\alpha$$ Why are there two different definitions about convolution? When have I to use one or another? Thanks!","['laplace-transform', 'integration', 'convolution', 'analysis']"
2130041,$f(x)\in\mathbb{Q}[x]$ such that $f(\mathbb{Z})\subseteq \mathbb{Z}$ Then show that $f$ has the following form,"Let $f(x)\in\mathbb{Q}[x]$ be a polynomial of degree $n$ such that $f(\mathbb{Z})\subseteq \mathbb{Z}$. I want to show that $f$ has the following form $$f(x)=\sum_{j=0}^{j=n} a_{j}\binom{x}{j}$$ with $a_{j}\in \mathbb{Z}$ Attempt: Base case $n=0$, is clear Induction Hypothesis: Assume the result for degree$=n-1$ Consider the polynomial $\Delta f(x)=f(x+1)-f(x)$.
One can observe that it has degree $n-1$, so  $\Delta f$ has the above mentioned form. Can I deduce something from here ? Any other approach ? Kindly correct the tags if necessary, I am studying Hilbert Polynomial and Hilbert Series. If I am correct, The above problem characterize all numerical polynomial.","['induction', 'polynomials', 'functions']"
2130091,Distance from centroid to hypotenuse,We got triangle $\triangle \text{ABC}$ and $\angle \text{C}=90^{\circ }$. The area of $\triangle \text{ABC}=\text{S}$ and $\angle \text{BAC}=\alpha$. Prove that the distance from the centroid to the hypotenuse is equal to $\frac{1}{2}\sqrt{\text{S}\sin\left(2\alpha \right)}$. Any ideas how to solve that? Would be grateful if someone helps me.,"['trigonometry', 'triangles']"
2130108,construct a square without a ruler [duplicate],"This question already has answers here : Having two points of a square and only a compass, how to find the remaining two? (2 answers) Closed 2 years ago . How can I construct a square using only a pencil and a compass, i.e. no ruler. Given: a sheet of paper with $2$ points marked on it, a pencil and a compass. Aim: plot $2$ vertices such that the $4$ of them form a square using only a compass. P.S.: no cheap tricks involved.",['geometry']
2130175,Does the unique map on the zero space have determinant 1?,"The trivial vector space over any field $K$, consisting of only the zero vector, admits exactly one endomorphism, let's call it $z$, sending $0$ to itself. It is the identity map, so it should have determinant $1$. On the face of it, the zero map should have determinant $0$. But this is usually argued via $\lambda z = z$ for all $\lambda \in K$, so $\det z = \det (\lambda z) = \lambda^n \det z$, i.e. $(\lambda^n - 1)\det z = 0$. Normally that's enough to conclude that $\det z = 0$, but of course $n = 0$ in this case, so $\lambda^n = 1$ for all $\lambda$, and we learn nothing. Despite being the zero map, it's full rank and has trivial kernel. There are no nonzero vectors, so it has no eigenvectors, so it has no eigenvalues, so their product is $1$. On the other hand, the determinant is meant to be multilinear, and so should map the zero matrix to zero. But should we say that $z$ is represented by a zero matrix, given that its matrix representation is $0\times 0$ and doesn't have any entries at all? I can't help but feel like this is all very silly, but clearly the answer can't be anything other than $1$. Is there anything wrong with giving this answer? Does it cause any problems with any other typical properties of the determinant? Does it simplify any definitions or theorems?","['linear-algebra', 'determinant']"
2130197,How do solve inequality $|\frac{z}{1+z}|<1$?,"How do I solve for $z$ in $$\left|\frac{z}{1+z}\right|<1$$ I tried using $z= x + iy$ but that becomes complicated, any idea guys?","['complex-analysis', 'inequality', 'complex-numbers']"
2130208,Ab*surd* Integrals,"I am unable to find a proof for these integrals on the internet. emphasized text $$\displaystyle \int_0^{\frac{\pi}{2}} \cot^{-1}(\sqrt{1+\csc{\theta}}\,) \, \text{d}\theta = \frac{\pi^2}{12}$$ $$\displaystyle \int_0^\frac{\pi}{2} \csc^{-1}(\sqrt{1+\cot{\theta}}\,) \, \text{d}\theta = \frac{\pi^2}{8}$$ Sources: Brilliant, AoPS I tried differentiating under the integral sign but I can't think of an appropriate parameter that leaves easily integrable rational functions. I have tried exploiting the bounds to reflect and transform the integrand but to no avail. A real solution is preferred but a complex solution is perfectly acceptable. A geometric solution is not something I have considered but I'm just grasping at straws here.","['improper-integrals', 'integration', 'definite-integrals']"
2130223,Casimir Operator of $\mathfrak{sl}_n(\mathbb{C})$.,"If I have the Lie algebra $\mathfrak{g} = \mathfrak{sl}_n(\mathbb{C})$ and the trace form $B(x,y) = \text{tr}(x,y)$ for $x, y \in \mathfrak{g}$ how does one calculate by which scalar the Casimir element $C \in Z(\mathscr{U}(\mathfrak{g}))$ acts on the highest weight module $V(\lambda)$? I know that one defines the Casimir by $C = \sum_i x_i x_i^*$ where $\{x_i\}$ is a basis for the Lie algebra and $\{x_i^*\}$ a dual basis, which are arbitrary (i.e. C is independent of the choice of bases). I have calculated by hand some simple examples (n=3 acts by the scalar $\frac{8}{3}$ for example on V(2)). How should one proceed in general? Thanks.","['abstract-algebra', 'representation-theory', 'lie-algebras']"
2130224,Sum of all rationals between 0 and 1 squared,"Yesterday I came with a question: if rational numbers are countable, that means that all rational numbers between 0 and 1 can be listed in a sequence. Let be $Q(n)$ that sequence. It is pretty clear that $\sum_{n=1}^{\infty}Q(n) >\sum_{n=1}^{\infty}\frac{1}{n}$, it diverges. But what about $\sum_{n=1}^{\infty}Q(n)^2$? Does this serie converge? Is there even a way to define $Q(n)$ in a precise way? Many thanks in advance!!","['real-analysis', 'rational-numbers', 'sequences-and-series', 'convergence-divergence']"
2130229,Evaluating $\int \frac{1-7\cos^2x}{\sin^7x\cos^2x}dx$ [duplicate],This question already has answers here : Evaluating this integral : $ \int \frac {1-7\cos^2x} {\sin^7x \cos^2x} dx $ (4 answers) Closed 7 years ago . How do i evaluate $$\int \frac{1-7\cos^2x}{\sin^7x\cos^2x}dx$$. I tried using integration by parts and here is my approach $\int \frac{ sinx}{(1-cos^2x)^4\cos^2x} dx$ and then put $cos x=t$ and then tried to use partial fractions.I applied similar logic for the other part.But that made it lengthy to solve as decomposition into partial fractions is very time consuming.This question came in an objective examination in which time was limited.Can anyone help me with a shorter way to solve this problem.Thanks.,['integration']
2130248,"Only multiplicative linear functionals on $C[0,1]$","Consider the Banach space ($C[0,1], \vert\vert\cdot\vert\vert_{\infty}$) of all continuous complex-valued functions on $[0,1]$ w.r.t  $\vert\vert\cdot\vert\vert_{\infty}$. A linear functional $Z: C([0,1]) \to \mathbb{C}$ is called multiplicative if $Z(fg) = Z(f)Z(g)$ for all $f,g \in C([0,1])$. How do I show now that the functionals $$ d_x: C([0,1]) \to \mathbb{C},\quad d_x(f) = f(x)$$ are the only multiplicative functionals on $C([0,1])$ apart from the zero functional? 
I am familiar with Riesz representation theorem. Since the underlying set $[0,1]$ is compact, it holds that $C([0,1]) = C_0([0,1]) = C_c([0,1])$: Therefore, according to the Riesz representation theorem every positive linear functional has the form $$Z(f) = \int_{[0,1]} f d\mu.$$ This doesn't help me though since we are not necessarily talking about positive functionals. Should I assume that there is another linear functional that is multiplicative and then, on grounds of Riesz, show that this would lead to a contradiction. What should I consider here?","['functional-analysis', 'banach-spaces']"
2130264,Sum of random decreasing numbers between 0 and 1: does it converge??,"Let's define a sequence of numbers between 0 and 1. The first term, $r_1$ will be chosen uniformly randomly from $(0, 1)$, but now we iterate this process choosing $r_2$ from $(0, r_1)$, and so on, so $r_3\in(0, r_2)$, $r_4\in(0, r_3)$... The set of all possible sequences generated this way contains the sequence of the reciprocals of all natural numbers, which sum diverges; but it also contains all geometric sequences in which all terms are less than 1, and they all have convergent sums. The question is: does $\sum_{n=1}^{\infty} r_n$ converge in general? (I think this is called almost sure convergence ?) If so, what is the distribution of the limits of all convergent series from this family?","['real-analysis', 'probability', 'sequences-and-series', 'convergence-divergence']"
2130274,Find equation of circle with center at focus of parabola $y^2=8x$ which touches the given parabola.,"Find equation of circle with center at focus of parabola $y^2=8x$ which touches the given parabola. My attempt : 
Focus of the given parabola  is $(2,0)$ Therefore, equation of required circle is $x^2+y^2-4x+k=0\tag1$ On solving the parabola and the above circle simultaneously, we must get the point of tangency.
On substituting $y^2=8x$  in $(1)$ , we get $x^2+4x+k=0\tag2$ Now $(2)$ must be a perfect square since the circle touches the parabola. If this equation had $2$ distinct roots, then it would mean that the parabola intersects the circle at two distinct points. For $(2)$ to be a perfect square, $k=4$ Therefore, the required equation of circle is $x^2+y^2-4x+4=0$ The answer given in my textbook is $x^2+y^2-4x=0$. Also, if $k=4$ as I obtained above then $r^2=-8$ since $k= -(r^2+4)$ . Where am I wrong? ( I am not looking for more possible solutions to this questions )","['circles', 'coordinate-systems', 'geometry', 'tangent-line', 'conic-sections']"
2130282,Bishop ML and pattern recognition calculus of variations linear regression loss function,"On page $46$,  there is ($1.87$) $E[L]=\int \int \{y(x)-t\}^2p(x,t)dxdt$ Calculus of variations is used to give ($1.88$) $\dfrac{\partial E[L]}{\partial{y(x)}} = $2$ \int \{y(x)-t\}p(x,t)dt = 0$ The reader is referred to appendix $D$ on calculus of variations, but I am still confused. How does one get from ($1.87$) to ($1.88$), step by step?","['calculus-of-variations', 'calculus']"
2130291,The derivative of $x!$,"I was trying to calculate the derivative of $x!$ but i ran into a large amount of numbers. Is it even possible to calculate it? Because in an app called GRAPHER when i type in $(x!)'$ it returnes the graph of this function.
Here it is:",['derivatives']
2130340,"Dilation, shrink a triangle by $30\%$ [closed]",Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I would like to know how I shrink a triangle by $30\%$ using dilation not changing its center?,['trigonometry']
2130388,"Finding maxima and minima of $f(x,y)= x^4 + y^4 - 2x^2 - 2y^2 + 4xy$","For $f(x,y)=x^4+y^4-2x^2-2y^2+4xy$, I need to find maxima or minima. There are three critical points: $(0,0),(\sqrt2, -\sqrt2),(-\sqrt2,\sqrt2)$
So at $(\sqrt2, -\sqrt2)$, $f$ has minimum value, $-8$ and at $(-\sqrt2,\sqrt2),$ it has same minimum value, $-8$. At $(0,0)$, after inspecting, I get that it has neither maxima or minima. But when we substitute $(0,0),$ we get $0\le f \le8,$ so should not we get $(0,0)$ as a point of maxima?","['a.m.-g.m.-inequality', 'partial-derivative', 'cauchy-schwarz-inequality', 'multivariable-calculus', 'maxima-minima']"
2130423,"By considering $g(z)=f(z)f(-z)$, show that $f(-z)=\frac{1}{f(z)}$ for all $z$.","According to the question, we must let f be a function, which is holomorphic on the plane and satisfies $f'(z) = f(z)$ and $f(0)=1$. We are also told to assume that a function which is holomorphic on the plane with zero derivative is constant. I know that a holomorphic function is a ""complex-valued function of one or more complex variables that is complex differntiable"", but I am still unsure how to answer the question above. Could someone please offer some assistance? Thank you :)","['derivatives', 'holomorphic-functions', 'complex-numbers']"
2130454,Composition of two functions - Bijection,"I keep going around in circles with this problem: Given the functions $f:X\to Y$ and $g:Y\to Z$, if $g\circ f:X\to Z$ is bijective, then prove $f$ must be one-to-one and $g$ must be onto. I was able to prove this without difficulty. However the second part of the problem has me stumped: a) Find functions $f,g$ where $g\circ f$ is bijective but $f$ fails to be onto. b) Find functions $f,g$ where $g\circ f$ is bijective but $g$ fails to be one-to-one. My attempt for (a): Let $f:\mathbb{R}\to \mathbb{R}^+$ be defined by $f(x)=e^x$ and $g:\mathbb{R}^+\to \mathbb{R}$ be defined by $g(x)=\ln(x)$. Then $g\circ f(x)=g(f(x))=g(e^x)=\ln(e^x)=x$ which is bijective, $g$ is onto and $f$ fails to be onto... or so I thought. Upon closer inspection $f$ $\underline{is}$ onto for the given codomain $\mathbb{R}^+$. And now I'm stuck in a rut. Anyone out there have any hints?","['function-and-relation-composition', 'functions']"
2130459,A specific example regarding the inscribed square problem,"Toeplitz' conjecture (also called inscribed square problem) says that: For every Jordan curve $\mathscr C$, there exists four distincts points $A$, $B$, $C$ and $D$ belonging to $\mathscr C$ such that $ABCD$ is a square. A Jordan curve is a non self-intersecting continuous loop. Here is a drawing to illustrate the situation, and a link to the Wikipedia page if you want to find out more about this conjecture. The conjecture has already been proven in several cases, including when $\mathscr C$ is piecewise analytic. So we know that for these two figures, there exists an inscribed square. The question is how do I find those squares?",['geometry']
2130538,"Conditions on $\alpha, \beta$ under which $A \rtimes_{\alpha} B $ and $A \rtimes_{\beta} B$ are isomorphic","Let $Q$ and $N$ be two groups. If there are two homomorphisms $\alpha,\beta : Q \rightarrow \operatorname{Aut}(N)$ then we can construct the semidirect products $G_a = N \rtimes_{\alpha} Q $ and $G_b = N \rtimes_{\beta} Q $ . I'm interested to know for which $\alpha$ and $\beta$ these two groups are isomorphic. We can assume that both groups have the same underlying set $K = N \times Q$ . Let $\psi$ be an automorphism in $\operatorname{Aut}(N)$ , and let's write $n^{\psi}$ for $\psi(n)$ where $n \in N$ . Let's extend $\psi$ to the whole of $K$ by $\psi(n,q) = (n^{\psi},q)$ . Note that in both groups we can write $n$ for $(n,1)$ and $q$ for $(1,q)$ . We will see what it gives when we express the product $qn$ in both groups. Let us denote by $\circ_a$ and $\circ_b$ the group operations in $G_a$ and $G_b$ respectively. In $G_a$ we have $q \circ_a n = (1,q) \circ_a (n,1) = (n^{\alpha(q)},q)$ , by definition of semidirect product. For $\psi$ to be a homomorphism we have to have $\psi(q \circ_a n ) = q \circ_b \psi(n)$ . This equation reduces to $\psi(n^{\alpha(q)}) = n^{\psi \beta(q)}$ or $n^{\alpha(q)} = n^{\psi \beta(q) \psi {-1}}$ . We can conclude that if $\exists \psi \in \operatorname{Aut}(N)$ such that $\alpha(q) = \psi \beta(q) \psi^{-1} \forall q \in Q$ then the two semidirect products are isomorphic. This does not mean that if $\alpha(q)$ and $\beta(q)$ belong to different automorphism classes they give rise to non isomorphic semidirect products. Examples of this are given here , where cases are given where $\alpha(q)$ is trivial and $\beta(h)$ is not and here where similar and additional conditions are discussed (without proof) for finite groups.","['semidirect-product', 'group-theory', 'group-isomorphism']"
2130552,"How prove if $\{x,y\}=\{u,v\}$ then $[x=u \land y=v]\lor [x=v \land y=u]$","In the book says: Consider the cases $x=y$, $x \not =y$, separately. Use Axiom of extent. Case 1: $(x=y)$ If $x=y$ by hypothesis $\{x\}=\{u,v\}$. Let $z\in \{u,v\}$, by hypothesis we have  $z\in\{x\}$, then $u=x \land v=x$. Using idempotence rule:
$$(u=x \land v=x) \lor (u=x \land v=x)$$
By hypothesis:
$$(u=x \land v=y) \lor (u=y \land v=x)$$. But, how i can prove the proposition with $x\not =y$ ?. Thanks",['elementary-set-theory']
2130583,Partition edges of complete graph into paths of distinct length [duplicate],"This question already has an answer here : Complete Graphs as Unions of Paths (1 answer) Closed 2 years ago . Let $K_n$ be the complete undirected graph on $n$ vertices. Can you partition the edges of $K_n$ into $n-1$ paths of lengths $1,2,\ldots,n-1$ such that the edge-sets of the paths are pairwise disjoint? I believe the statement to be true, but I cannot prove it. It also possible that this is an open problem.","['combinatorics', 'graph-theory']"
2130596,How many linearly independent eigenvectors are there?,"The number of linearly independent eigenvectors for eigenvalue $1$ for the given matrix ? $\begin{bmatrix} 1 & 3 & 2 \\ 0 & 4 & 2\\ 0 &-3 & -1 \end{bmatrix}$ Eigenvalues are $1,1,2$ for the above matrix .So, $1$ has multiplicity $2$ and $2$ has multiplicity $1$. After putting the value $1$, I am getting $ i= $any value, and the relation $3j = -2k$. Now, How to proceed further ?","['matrices', 'eigenvalues-eigenvectors']"
2130648,Find all the differentiable functions $f$ with the property $f\left(x^4+y\right) = x^3f(x) + f(y)$ [duplicate],"This question already has answers here : Solve functional equation $f(x^4+y)=x^3f(x)+f(y)$ (5 answers) Closed 2 years ago . I'm having a hard time answering this question: Find all the differentiable functions $f$ such that $$\forall x,y\in\mathbb R : f\left(x^4+y\right) = x^3f(x) + f(y) \text.$$ I would love to get a hint about how to start since this is my first time answering this type of questions. Thanks a lot.","['derivatives', 'functional-equations', 'calculus', 'functions']"
2130659,"Is $\langle\ a,b\ \vert\ aba=bab,\ abab=baba\ \rangle$ a presentation of the free group on a single generator?","Is the following a presentation of the free group generated by a single element? $\langle\ a,b\ \vert\ aba=bab,\ abab=baba\ \rangle.$ My thinking is the following: $abab = baba=b(bab)=b^2ab$ by substituting the first relation into the second. Simplifying, we get $a=b$ . Since these steps give equivalent statements, the above presentation is in fact $\langle\ a,b\ \vert\ a=b\ \rangle$ , i.e. , the free group on one generator. Is this correct?","['combinatorial-group-theory', 'group-presentation', 'group-theory', 'proof-verification']"
2130665,Why the surjective map $\pi: X \rightarrow X/G$ verifies the universality property?,"I am working about that the quotient of an affine set by a finite group has also a structure of an affine set. In Algebraic Geometry by J.Harris (pgs 124-125) there is a construction of $Y = X/G$ given $X$ an affine set and $G$ a finite group.
He defines $A(Y)$ as $A(X)^G$ and proves that $Y$ has an affine set structure and that its points correspond to the orbits of $X$ by the action of $G$.
He also proves that the projection $\pi: X \rightarrow Y$ is surjective.
(The way he do this is natural. Every time he uses the definition of $A(Y)$ and its properties.) Until here, everything is clear and the only thing we must do is to prove that the map $\pi$ satisfies the universality property, i.e., every morfism $\rho:  X\longrightarrow Z$ factors through $\pi$ if and only if 
$\rho(p) = \rho(gp)$ for every $x \in X$ y $g \in G$.
\begin{equation*}
\begin{gathered}
X\\
^\rho\swarrow \: _\varphi \: \searrow ^\pi\\
Z \enspace \longleftarrow \enspace Y
\end{gathered}
\end{equation*}
Unfortunately I don't know how to do this. If someone can help me it would be great. By the way, I know that this result also is true in the category of affine schemes, but I don't have the knowledge to understand that proof. I am only interested in the case of affine sets of the affine space $\mathbb{A}_k^n$.
Thank you in advance!","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra', 'geometry', 'group-theory']"
2130684,Limit of $(1/n)^{(1/n!)}$ as $n \to \infty$,"A computer algebra system told me that
\begin{equation}
\lim_{n \to \infty} \left( \frac{1}{n} \right)^{1/n!} = 1
\end{equation}
How can I show this? I tried applying the exponential and logarithm to see that this is equal to
\begin{equation}
\exp \lim_{n \to \infty} \left( \frac{1}{n!} \log \frac{1}{n} \right)
\end{equation}
But I'm not sure how to proceed.",['limits']
2130688,Definition of subsequence,"I need help understanding the following definition: We say that a sequence $b:\Bbb N\rightarrow S$ is a subsequence of a sequence $a:\Bbb N\rightarrow S$ if there exists a strictly increasing sequence $p:\Bbb N\rightarrow \Bbb N$ such that $b=a\circ p.$ So if I take for example that $a$ is a sequence of natural numbers and $b$ is a sequence of even numbers, then what is $p$ here?","['real-analysis', 'sequences-and-series', 'calculus']"
2130690,Is 0 an eigenvalue of the right shift operator?,"My friend and I are a little bit confused about this, the question we are working on asks us to find the eigenvalues of $R$, the right shift operator. The main point of contention is that $\sigma(R)$ is non-empty, and so should surely(?) contain an eigenvalue of $R$. Does the non-emptiness of $\sigma(R)$ only apply in finite dimensional Hilbert spaces? A detailed reply to clear up the confusion would be appreciated.","['functional-analysis', 'operator-theory', 'analysis', 'linear-transformations']"
2130692,"Distribution on $(0, \infty)$ which cannot be extended to $\mathbb{R}$","I am working on exercises from Friedlander's Introduction to the Theory of Distributions and I am stuck in a particular problem. The question is: ""Show that $\langle u, \phi\rangle = \sum_\limits{k \geq 1} \partial^k \phi(1/k)$ is a distribution on $(0, \infty)$, but that there is no $v\in \mathcal{D}'(\mathbb{R})$ whose restriction to $(0, \infty)$ is equal to $u$."" I believe I have managed to prove the first part: Given any compact $K \subset (0,\infty)$, take a test function $\phi\in C^{\infty}_c(0, \infty)$ with $\operatorname{supp} \phi \subset K$. Take then $N$ such that $\frac{1}{N+1} < \min \operatorname{supp} \phi$. We have that $\langle u, \phi\rangle = \sum_\limits{k = 1}^N \partial^k \phi(1/k)$, since $\phi(1/k) = 0, \forall k>N+1$. And so it is clear that $\exists C$ and $\exists N$ such that $u$ satisfies the seminorm estimates $|\langle u, \phi\rangle| \leq \sum\limits_{k=1}^N |\sup\partial^k \phi|$ for any $\phi$. Now, the second part is troubling me. I believe the way is to suppose there is a distribution $v\in \mathcal{D}'(\mathbb{R})$ with $v|_{(0,\infty)} = u$, and show that it would not satisfy the seminorm estimate because of the restriction. However, I am struggling to see how that should be done. Note: I have recognized this distribution to be equivalent to $\sum\limits_{k\geq 1} \delta^{(k)}(x-1/k)$ but I am not sure how this helps!","['functional-analysis', 'distribution-theory']"
2130693,Are groups ordered pairs or sets?,"Some books say stuff like ""if $\forall x \in G$, $x^2=e$, then $G$ is abelian"". But the notation of a group is $\langle G, \circ \rangle$, and that looks like an ordered pair. So, should not the elements of the group be $\{G\}$ and $\{\circ,G\}$ by definition of ordered pair? Or am i getting wrong the notation? I got this doubt also with the notation of partially ordered sets.","['abstract-algebra', 'notation', 'group-theory']"
2130746,Convex sets as intersection of half spaces,"I want to prove that any closed convex sets can be written as an intersection of half spaces using only the separation theorem as a pre-requisite. I'm getting a feel that I need to show two sets are subsets of each other, but not being able to understand how exactly to go about it.","['real-analysis', 'convex-analysis']"
2130773,"Prove $\sqrt{2}$ irrational by discreteness of $\,\Bbb Z[\sqrt{2}] = \Bbb Z+\sqrt 2\,\Bbb Z$. Same for any algebraic integer $\not\in\Bbb Z$","I was hoping for more insight of this specific proof of the irrationality of $\sqrt{2}$. According to this proof by Alex Healy: ""Consider the set $W=a+b \sqrt{2}$ , a,b integers. Clearly $W$ is closed under multiplication and addition. Define $\alpha=(\sqrt{2}−1)$, an element of $W$. Obviously, $0 \lt \alpha \lt 1$, so that $$\alpha^k \to 0 \;\;\text{as}\;\; k \to \infty \tag{1}$$ Assume $\sqrt{2}=p/q$. Since $W$ is closed, $\alpha^k=e+f \sqrt{2} =(eq+fp)/q \ge 1/q$ contradicting $(1)$."" Here's the link to the proof, it is the 9th one: http://www.cut-the-knot.org/proofs/sq_root.shtml Thanks in advance!!","['number-theory', 'discrete-mathematics', 'alternative-proof', 'elementary-number-theory']"
2130775,Continuity in a compact metric space.,"Let $(X,d)$ be a compact metric space and let $f, g: X \rightarrow \mathbb{R}$ be continuous such that $$f(x) \neq g(x), \forall x\in X.$$
  Show that there exists an $\epsilon$ such that $$|f(x) - g(x)| \geq \epsilon, \forall x \in X.$$ I'm assuming he means $\epsilon > 0$. Well, suppose to the contrary that for all $\epsilon > 0$, there exists an $x' \in X$ such that $|f(x') - g(x')| < \epsilon.$ Since $f(x')$ and $g(x')$ are fixed values, we must have $f(x') = g(x')$, a contradiction. Seems uh... too easy? I didn't even have to use continuity or compactness? So seems wrong? (I'm really sick, so terrible at math this week, but is this right?)","['real-analysis', 'proof-verification']"
2130780,What's the function poly() ??,"In cryptographic context, we often observe the function $\mathsf{poly}$. For example , let $n$ be an integer, this function is called in  a manner such as $\mathsf{poly}$(n). What's the exact meaning of $\mathsf{poly}$(n) ??","['cryptography', 'coloring', 'functions']"
2130917,Double Quotienting of a Ring is Isomorphic to Ring Quotient by Sum of Ideals,"First let me say, please edit my title if their is a more appropriate one and if this is a duplicate please direct me and close the question. I tried searching for my question, but I don't know if the theorem I am trying to prove has a name - so it was difficult to know what to search. Also let me say that I have already tried to squeeze this theorem out of one of the isomorphism theorems, but I cant quite see how to get it, so if your hint or answer is `check the isomorphism theorems for rings' I might need more then that. I would like to understand this for personal benefit, but I am kind of limited on time. I am specifically working with $A$ as a commutative ring with unity, $\mathfrak{a}$ is an ideal of $A$, and I believe $\mathfrak{b}$ is to be taken as an ideal in $A/\mathfrak{a}$, and $\mathfrak{b}'$ is the ideal in $A$ that corresponds to $\mathfrak{b}$. Then I would like to show that $$A/\mathfrak{a}/\mathfrak{b} \approx A/(\mathfrak{a} + \mathfrak{b}').$$ I tried work through the mechanics of a specific example in full formality for insight, specifically I investigated $$\mathbb{Z}/<12>/<3+<12>>$$ where <12> is my ideal generated by 12 in $\mathbb{Z}$, and <3+ <12>> is my ideal generated by the coset with representative 3 in $\mathbb{Z}/<12>$. Sorry for the horrible notation here. I am aware this is probably unusually formal approach to the ""coset"" approach to quotienting, But I want to make sure I understand the nuts and bolts before passing off to theorems and the more ""homomorphic image"" approach to quotienting. Anyways In this example we get $\mathbb{Z}/<12>/<3+<12>>$ = $$\{ <0+<12>>, <1 + <12>>, <3+<12>> \}$$ Which should be easily isomorphically mapped to $\mathbb{Z}/<12>+<3>$ since that sum of ideals is just <12>+<3> = <3>. If you have any advice or direction please let me know.","['abstract-algebra', 'ideals']"
2130925,Find that solution satisfying $ϕ(1) = 3ϕ(0)$ for $y' + 5y = 2$.,"Find that solution satisfying $ϕ(1) = 3ϕ(0)$ for the following second order linear ordinary differential equation: $y' + 5y = 2$ I found the solution to be $ϕ(x) = \frac{2}{5} + ce^{5x}$ . Now how do I find a particular solution satisfying $ϕ(1) = 3ϕ(0)?$ Please help me with this. In the previous part, I was asked to find the solution satisfying $ϕ(1) = 2$ which I found to be $ϕ(x) = \frac{2}{5} + \frac{8}{5}e^5e^{-5x}$ if that helps.","['integration', 'ordinary-differential-equations', 'proof-verification']"
2130937,Reduction of order for third order ode,"This question is similar to this question, however I do not understand the method I should be using.
I need to solve $$x^3y'''+7x^2y''+xy'-16y =0 \,\,\,\,\,\,\, \text{knowing that} \,\,\,\,\,\ y_1 = x^2$$ Okay so normally for second order ODE I simply use the formula $$y_2  =y_1\int \frac{e^{-\int p(x)dx}}{y_1^2}dx$$ where $p(x)$ comes from $$y''+p(x)y'+q(x)y = 0$$ I know the formula comes from the intuition that the second solution has the following relation with the first one: $y_2 = v(x)y_1$ where $v(x)$ is the function to be found. However how do I find a second solution for the equation above? Edit : Trial Trying $y_2 = vy_1$ I get $y_2' = v'y_1+vy_1'$ and $y_2''=v''y_1+v'y_1'+v'y_1'+vy_1'' = v''y_1+2v'y_1'+vy_1''$ and also $y_2''' = v'''y_1+v''y_1'+2(v''y_1'+v'y_1'')+v'y_1'''+v''y_1''=v'''y_1+v''(3y_1'+y_1'')+v'(2y_1''+y_1''')$ but they are all positive and if I sub them into the main equation I will just get a very big amount of terms. Indeed we would have: $$x^3y_2'''+7x^2y_2''+xy_2'-16y_2 =3(v'''y_1+v''(3y_1'+y_1'')+v'(2y_1''+y_1'''))+7x^2(v''y_1+2v'y_1'+vy_1'')+x(v'y_1+vy_1')-16(vy_1)$$","['reduction-of-order-ode', 'ordinary-differential-equations']"
2130978,"Morphisms which are ""finite"" or ""finite type""","Let $X$ and $Y$ be schemes and $f:X\to Y$ a morphism between them. We say that $f$ is of finite type if for every affine open $spec(A)=U\subset Y$ there exists a finite affine (open) cover of $f^{-1}(U)$ by $\{ V_i\}_{i=1}^n$, where $V_i=spec(B_i)$, such that $B_i$ is a finitely generated $A$-algbera. On the other hand $f$ is finite if $f^{-1}(U)$ is affine, say $f^{-1}(U)=spec(B)$, and $A$ is finite $B$-module. I was wondering why don't we have the intermediate notion as following. The map $f$ is such that for every affine $U=spec(A)$ we have $f^{-1}(U)=\bigcup_{i=1}^n V_i$ where $V_i=spec(B_i)$ and $B_i$ is finite $A$-module. 
Let's call the this property quasi finite type . So the question is as follows:
Suppose $f$ a morphism of schemes was of quasi finite type then would it imply that it is actually finite . If yes, then there is no need of such a definition. If no, is it just because we don't see this kind of property in ""nature"" and hence don't need to define it.","['schemes', 'algebraic-geometry']"
2130998,array of letters with no two consecutive rows identical,"Consider a 5×5 array. In how many ways can we fill the array with X-s and O-s so that no two consecutive rows are identical? So first one we can do $2^5$ ways. Second row in $2^5-1$, the same as 3,4,5 rows. So final answer is $2^5*(2^5-1)^4$ Is it correct way of thinking?","['combinatorics', 'discrete-mathematics']"
2131014,Identify the Quotient Group $G/H$ Using the First Isomorphism Theorem,"I'm trying to go through Harvard's Abstract Algebra lectures on my own, and would like a little help with one of the homeworks. The problem asks: Let $G$ be the group of invertible real upper $2 \times 2$ matrices. Determine whether or not the following conditions describe normal subgroups $H$ of $G$ . If they do, use the First Isomorphism Theorem to identify the quotient group $G/H$ . (a) $\quad a_{11}$ = 1 (b) $\quad a_{12}$ = 0 (c) $\quad a_{11}$ = $a_{22}$ (d) $\quad a_{11}$ = $a_{22}$ = 1 To do this, we'll need to go one by one and determine whether the subgroup $H$ described is normal or not. If it's normal then it must be kernel of a surjective homomorphism. It can easily be shown that $$\det: G \rightarrow R^{*}$$ is a surjective homomorphism. Then, $G/H$ must be isomorphic to $R^{*}$ by the First Isomorphism Theorem. So, we'll go one by one and see if they're normal. NOTE: I have put *'s in places where computation would be too long simply to indicate the presence of some value determined through multiplying through. (a) $$H = \begin{bmatrix}
1 & b \\ 
0 & d 
\end{bmatrix},$$ $$aha^{-1} \;=\; \begin{bmatrix} a & b\\ 0 & d \end{bmatrix} \begin{bmatrix} 1 & b'\\ 0 & d'
\end{bmatrix} \begin{bmatrix} \frac{1}{a} & \frac{-b}{ad} \\ 0 & \frac{1}{d} \end{bmatrix} \;=\; \begin{bmatrix}
1 & * \\ 
0 & d' 
\end{bmatrix}.$$ This is a normal subgroup and therefore $G/H \simeq R^{*}.$ (b) $$H = \begin{bmatrix}
a & 0 \\ 
0 & d 
\end{bmatrix},$$ $$aha^{-1} \;=\; \begin{bmatrix} a & b\\ 0 & d \end{bmatrix} \begin{bmatrix} a' & 0\\ 0 & d'
\end{bmatrix} \begin{bmatrix} \frac{1}{a} & \frac{-b}{ad} \\ 0 & \frac{1}{d} \end{bmatrix} \;=\; \begin{bmatrix}
a' & * \\ 
0 & d' 
\end{bmatrix}.$$ This is NOT a normal subgroup. (c) $$H = \begin{bmatrix}
a & b \\ 
0 & a 
\end{bmatrix},$$ $$aha^{-1} \;=\; \begin{bmatrix} a & b\\ 0 & d \end{bmatrix} \begin{bmatrix} a' & b'\\ 0 & a'
\end{bmatrix} \begin{bmatrix} \frac{1}{a} & \frac{-b}{ad} \\ 0 & \frac{1}{d} \end{bmatrix} \;=\; \begin{bmatrix}
a' & * \\ 
0 & a' 
\end{bmatrix}.$$ This is a normal subgroup and therefore $G/H \simeq R^{*}.$ (d) This is an instance of (c), and therefore it follows trivially that it is a normal subgroup. Is this correct? Any and all help is greatly appreciated. Thanks.","['abstract-algebra', 'group-theory', 'group-isomorphism', 'solution-verification']"
2131041,"What distribution does X/(X+Y), follow, when X and Y are gamma distributed. Prove that the R.V is independent of (X+Y)","What distribution does the following r.v follow: $$X/(X+Y)$$ $$X \sim  Gamma(a,1)$$
$$ Y \sim Gamma(b,1)$$ and the variables are independent. Further, how to prove that the random variable is independent of: $X+Y \sim Gamma(a+b,1)$? I am sure there is some kind of a hack to get the result without using the convolution technique, and only relying on the moment generating functions. But I can't come up with it.","['statistics', 'probability', 'random-variables']"
2131054,Computing sums and double sums,I would like to check if my answer is correct: 1) Compute $$\sum_{i=1}^n(3i+4)$$. I got $(3n^2 + 11n) / 2$ using the property that $\sum_{i=1}^n i = n(n+1)/2$ 2) I'm unsure how to approach double summations like this: $$\sum_{x = 1}^n\sum_{y=1}^n(x+y−1)$$. Please help explain and the correct answer would be appreciated!,"['summation', 'discrete-mathematics']"
2131087,Closed form for $\int x^ne^{-x^m} \ dx\ ?$,"While entertaining myself by answering a question , the following problem arose. For what natural numbers $n,m$ does the following undefined integral have a closed form $$\int x^ne^{-x^m} \ dx\ ?$$ Closed form means that the antiderivative consists only of powers of $x^{...}$ and $x$ in $e^{-x^{...}}$. I created the following matrix showing for different pairs of $n$ and $m$ the nature of the antiderivative. $$\begin{matrix}
& m&1&2&3&4&5&6&7\\
n\\
1&&\checkmark&\checkmark&\Gamma&\text{erf}&\Gamma&\Gamma&\Gamma\\
2&&\checkmark&\text{erf}&\checkmark&\Gamma&\Gamma&\text{erf}&\Gamma&\\
3&&\checkmark&\checkmark&\Gamma&\checkmark&\Gamma&\Gamma&\Gamma&\\
4&&\checkmark&\text{erf}&\Gamma&\Gamma&\checkmark&\Gamma&\Gamma\\
5&&\checkmark&\checkmark&\checkmark&\text{erf}&\Gamma&\checkmark&\Gamma\\
6&&\checkmark&\text{erf}&\Gamma&\Gamma&\Gamma&\Gamma&\checkmark\\
7&&\checkmark&\checkmark&\Gamma&\checkmark&\Gamma&\Gamma&\Gamma\\
\end{matrix}$$
$$$$
The $\checkmark$ sign stands for a closed form, ""erf"" signals that the antiderivative contains the  erf function , and $\Gamma$ signals that the antiderivative contains the upper incomplete $\Gamma$ function . I have no clue. Does anybody?","['real-analysis', 'gamma-function', 'calculus']"
2131093,Transformation of Random Variable $Y = X^2$,"I'm learning probability, specifically transformations of random variables, and need help to understand the solution to the following exercise: Consider the continuous random variable $X$ with probability density function $$f(x) = \begin{cases} \frac{1}{3}x^2 \quad  -1 \leq x \leq 2, \\ 0 \quad \quad \text{elsewhere}. \end{cases}$$ Find the cumulative distribution function of the random variable $Y = X^2$. The author gives the following solution: For $0 \leq y \leq 1: F_Y(y) = P(Y \leq y) = P(X^2 \leq y) \stackrel{?}{=} P(-\sqrt y \leq X \leq \sqrt y) = \int_{-\sqrt y}^{\sqrt y}\frac{1}{3}x^2\, dx = \frac{2}{9}y\sqrt y.$ For $1 \leq y \leq 4: F_Y(y) = P(Y \leq y) = P(X^2 \leq y) \stackrel{?}{=} P(-1 \leq X \leq \sqrt y) = \int_{-1}^{\sqrt y}\frac{1}{3}x^2\, dx = \frac{1}{9} + \frac{1}{9}y\sqrt y.$ For $y > 4: F_{Y}(y) = 1.$ Previous to this exercise, I've managed to follow the solutions of two similar (obviously simpler) problems for a strictly increasing and strictly decreasing function of $X$, respectively. However in this problem, I don't understand the computations being done, specifically: How does the three intervals $0 \leq y \leq 1$, $1 \leq y \leq 4$ and $y > 4$ are determined? In the two previous problems I've encountered, we only considered one interval which was identical to the interval where $f(x)$ was non-zero. In the case where $0 \leq y \leq 1$, why does $P(X^2 \leq y) = P(-\sqrt y \leq X \leq \sqrt y)$ and not $P(X \leq \sqrt y)$? I have put question marks above the equalities that I don't understand. I think I have not understand the theory well enough. I'm looking for an answer that will make me understand the solution to this problem and possibly make the theory clearer.","['probability', 'density-function', 'random-variables']"
2131124,Prove Big-Oh using Induction,"Prove using induction: $n! = O(n^n)$. Just need to prove this, and I was told that it could be done with induction. The base case is easy to solve for, but how would I go about solving the case of $n=k$,$n=k+1$? I know that it is true just by plugging in a number, but I don't think it is supposed to be proved my contradiction...","['induction', 'factorial', 'asymptotics', 'discrete-mathematics']"
2131155,Is Bayesian probability at odds with traditional theories?,"I am studying conditional probability, and I came across this Bayes theorem. Though I am no statistician, I kinda get the idea of the theorem, that probabilities can be updated using newly given informations. What I am curious about is: I heard that Bayesian statistics was a ""new"" approach to statistics, and therefore was met with many objections and criticisms. But I learned that the Bayesian theorem
$$P(B|A)=\frac{P(A|B)P(B)}{P(A)}$$
can be derived from the definition of conditional probability. I can't understand why this was met with criticisms.  I heard that they were due to different views about the meaning of probability and inference (like frequentists and propensitists), but I don't really see any difference between these. Would someone please explain how Bayesians were at odds with other views about statistics, and why Bayesian approach aroused numerous arguments and confusions (with some examples if possible)? Now my question might sound a bit vague, but I have almost no background information about advanced statistics, so this is the best I can give. Thank you in advance!","['bayesian', 'statistics', 'bayes-theorem', 'probability']"
2131175,What are some examples of the norm for a map of elliptic curves?,"Given the canonical map $\mathbb{C}[x] \to \mathbb{C}[x,y]/(y^2 - x(x-1)(x-2))$, how can I compute the norm of a $\mathbb{C}(x)$-algebra morphism
$$
\text{Frac}\left( \frac{\mathbb{C}[x,y]}{(y^2 - x(x-1)(x-2))} \right) \xrightarrow{\cdot r} \text{Frac}\left( \frac{\mathbb{C}[x,y]}{(y^2 - x(x-1)(x-2))} \right)
$$
for some $r \in \mathbb{C}(x)$? I am trying to understand how to construct example computations of proper pushforward for maps of curves using the formula at the bottom of page 9 of http://www.cmi.ac.in/~asengupta/Intersection_Theory.pdf Thank you, Mohan. Given
$$f + g\cdot y \in \text{Frac}\left( \frac{\mathbb{C}[x,y]}{(y^2 - x(x-1)(x-2))} \right)$$
multiplying this element by $y$ gives
$$
f\cdot y + g\cdot x(x-1)(x-2)
$$
hence the matrix of the morphism is given by
$$
\begin{bmatrix}
0 & x(x-1)(x-2) \\
1& 0
\end{bmatrix}
$$
giving a norm of $-x(x-1)(x-2)$.","['intersection-theory', 'algebraic-geometry', 'commutative-algebra']"
2131305,find total number of maximal ideals in $\mathbb{Q}[x]/\langle x^4-1\rangle$.,"find total number of maximal ideals in $\mathbb{Q}[x]/\langle x^4-1\rangle$. Let $J=\langle x^4-1\rangle$, $R=\mathbb{Q}[x]$. I want to use $(R/J)/(I/J)\simeq R/I$, where $I $ is ideal of $R$ which contain $J$. Then $R/I$ is field, and $R$ is a principal ideal domain. Let $I=\langle f(x) \rangle$ hence $f(x)$ must be irreducible in $R$, so only choice for $f(x)$ are $x-1,x+1,x^2+1$. So answer should be $3$. Is it right explanation? and better method thanks in advance","['abstract-algebra', 'ring-theory', 'field-theory', 'proof-verification']"
2131320,What are the group homomorphisms from $ \prod_ {n \in \mathbb {N}} \mathbb {Z} / \bigoplus_ {n \in \mathbb {N}} \mathbb {Z} $ to $ \mathbb {Z} $?,"By a theorem of Specker, there’s only the zero map since any map out of $ \prod_{n \in \mathbb{N}} \mathbb{Z} $ is determined by the values of the unit vectors, which all lie in $ \bigoplus_{n \in \mathbb{N}} \mathbb{Z} $, but the original proof is more general, uses a bunch of machinery, and in German. Isn’t there an easier way?","['abstract-algebra', 'group-theory']"
2131327,For what values of $n$ does the limit $\lim\frac{x^2y}{x^{2n}+y^2}$ exists?,"For what values of n does the following limit exist? $$\lim_{(x,y) \to (0,0)} \frac{x^2y}{x^{2n}+y^2}$$ I've tried using the squeeze theorem but couldn't come up with anything good. Also converting it to cylindrical coordinates gave me the answer that the limit exists for all n (which I don't know if it's correct).","['multivariable-calculus', 'limits']"
2131355,What would be the Lyapunov exponent of this map,"$p_i$ is the probability of the occurence of unique symbol $i$. In the case of Tent map, the Lyapunov exponent (LE) is log of the derivative of the tent map which is almost always 2. So, $\lambda = log(2)$. For the probabilistic Bernoulli map, I tried to find the derivative like this:
$f'(x) = 1/p_1$ for $0<x<p_1$, or $f'(x) = 1-p_1/p_2$ for 
$p_1<x\le p_2$ and so on. Please correct me if the derivative and limits are wrong. In K Feltekh, D Fournier-Prunaret, S Belghith, Analytical expressions for power spectral density issued from one-dimensional continuous piecewise linear maps with three slopes. Signal Process. 94:, 149–157 (2014). the anlytical expression for LE for any piecewise linear map in general is $\lambda = (1-p)\ln(2/(1-p)) + p\ln(1/p)$ where $p$ is a constant and $p \in (0,1)$. Then, How can I apply the above result and calculate the LE for the map in Eq(6)? Since, Tent map is conjugate to Bernoulli map, so would the probabilistic Bernoulli map have the same LE as Tent Map which is log(2)?","['derivatives', 'eigenvalues-eigenvectors', 'dynamical-systems', 'chaos-theory', 'probability']"
2131437,Prove that the center of G has order divisible by p,"Let $G$ be a non-trivial finite group and $p$ a prime number. If every subgroup $H\leq$ G has index divisible by $p$, prove that the center of $G$ has order divisible by $p$. So I have that $[G:H]=pk$ for some integer $k$, and we need to prove that $|Z(G)|=pl$ for some integer $l$. Let $|G|=n$, I can prove the case if assume $G$ is an abelian group, then $|Z(G)|=n$, so the center has order divisible by $p$. How should I approach if $G$ is not abelian?","['finite-groups', 'abstract-algebra', 'abelian-groups', 'group-theory']"
2131479,Prove that $\sum\limits_{n=1}^{\infty} \frac{n}{3^n} = \frac{3}{4}$,"How can you derive that 
$$ \sum\limits_{n=1}^{\infty} \frac{n}{3^n} = \frac{3}{4} \, ?$$ 
I suspect some clever use of the geometric series will do, but I don't know how.","['sequences-and-series', 'calculus']"
2131503,How many elements of $S_9$ commute with $(123)(4567)$?,"I know that I need to find a $\theta \in S_9$ such that $\theta \sigma \theta^{-1}=(\theta(1),\theta(2),\theta(3))\cdot (\theta(4),\theta(5),\theta(6),\theta(7))=(1,2,3)(4,5,6,7)$. Kind of stuck here. How do I check which elements of $S_9$ will satisfy it?",['group-theory']
2131523,The rate of convergence of Cesaro average of Fourier series,"Do you know any estimates of rate of convergence of Cesaro average of Fourier series? It does not matter for which classes of functions. It would be great if you can give some estimates depending on the smoothness of the function. It is well known that Cesaro average convergence uniformly for all continuous functions. Also for example there well known estimate for Fourier series (not Cesaro average) that looks like $O(\frac{\log n}{n^p})$ where $p$ is smoothness of the functions. I would like to know some analogical results for Cesaro sums. Great thanks for any links, papers, books and so on!","['real-analysis', 'fourier-series', 'fourier-analysis', 'functional-analysis', 'convergence-divergence']"
