question_id,title,body,tags
4780094,Almost sure convergence in density of infinite dimensional product measure of normal distributions unsing Kakutani's theorem,"In measure theory Kakutani's Theorem is used to determine if two infinite product measures are equivalent, meaning they are both absolutely continuous with respect to each other. In one of my text books on martingale theory there is an exercise where we should use Kakutani's Theorem to investigate this for the product measure $\mathcal{P}=\otimes_{n=1}^\infty \mu_n$ and $\mathcal{Q}= \otimes_{n=1}^\infty \nu_n$ where $\mu_n$ is the Gaussian measure with expectation $0$ and variance $1$ and $\nu_n$ has variance $1$ and the expectation is given by a sequence $(\alpha_n)_{n\in\mathbb{N}}$ . Thus we have $$\frac{\mathrm{d} \nu_n}{\mathrm{d} \mu_n}(x)=\frac{\exp \left(-\left(x-\alpha_n\right)^2 / 2\right)}{\exp \left(-x^2 / 2\right)}=\exp \left(\alpha_n x-\alpha_n^2 / 2\right), \quad x \in \mathbb{R}. $$ And according to Kakutani's criterion, the product measures have a common density iff. $\prod_{n=1}^\infty a_n >0$ , where in our case $a_n$ is equal to $$\begin{align} a_n & =\int_{\mathbb{R}} \sqrt{\frac{\mathrm{d} \nu_n}{\mathrm{~d} \mu_n}} \mathrm{~d} \mu_n=\int_{\mathbb{R}} \exp \left(\frac{\alpha_n x}{2}-\frac{\alpha_n^2}{4}\right) \frac{1}{\sqrt{2 \pi}} \exp \left(-x^2 / 2\right) \mathrm{d} x \\
& =\exp \left(-\alpha_n^2 / 8\right) \int_{\mathbb{R}} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{1}{2}\left(x-\frac{\alpha_n}{2}\right)^2\right) \mathrm{d} x=\exp \left(-\alpha_n^2 / 8\right). \end{align}$$ We can use a result from calculus, that says $\prod_{n=1}^\infty a_n >0$ iff. $\sum_{n=1}^\infty \log a_n <\infty$ . Using this we know that Kakutani's criterion holds iff $(\alpha_n)_{n\in\mathbb{N}}\in\ell^2$ . In this case the density between the product measures is $$
\frac{\mathrm{d}\mathcal{Q}}{\mathrm{d}\mathcal{P}} (X)= \prod_{n=1}^\infty \frac{\mathrm{d}\nu_n}{\mathrm{d}\mu_n}(x_n) = \exp\left(\sum_{n=1}^\infty \alpha_n x_n - \frac{1}{2}
    \sum_{n=1}^\infty \alpha_n^2\right),
$$ where $X = (x_n)_{n\in\mathbb{N}}\in \mathbb{R}^{\mathbb{N}}$ . Now in this density we know that the right series in the exponential converges, since $(\alpha_n)_{n\in\mathbb{N}}\in\ell^2$ .
Where I am stuck, is reasoning in what sense the left series converges, or if it even converges at all. Thank you for your time.","['martingales', 'measure-theory']"
4780108,How to calculate the new $X$ and $Y $ position of an object after changing its size? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question I have some objects that will be positioned in certain $X$ and $Y$ coordinates and that will start with a size of $40\times60$ at an angle of $15^\circ$ . I need to change the size of these objects to $200\times200$ for example, with this the $X$ and $Y$ coordinates will change, it is important that the objects do not collide and respect the angle, and if there is a Gap this must be respected as well. I included some examples of how the objects will be initially, and a gif showing that after changing the size they occupy a new $X$ and $Y$ position and do not collide. I made these examples using Figma software to facilitate the explanation. I need to calculate the new $X$ and $Y$ coordinates of the objects dynamically, respecting the criteria above. Pictures examples:","['trigonometry', 'geometry', 'rotations']"
4780149,How to do the derivation of the MLE for Linear Discriminant Analysis,"Derivation of the MLE for Linear Discriminant Analysis $$
\ell(\phi, \mu, \Sigma) = \log \prod_{i=1}^{M} p(x^{(i)}, y^{(i)}; \phi, \mu, \Sigma)
$$ $$
= \log \prod_{i=1}^{M} p(x^{(i)}|y^{(i)}; \mu, \Sigma) p(y^{(i)}; \phi)
$$ $$
= \log \prod_{i=1}^{M} \frac{1}{\sqrt{2\pi}^N |\Sigma|} \exp\left(-\frac{1}{2}(x^{(i)} - \mu_{y^{(i)}})^T \Sigma^{-1} (x^{(i)} - \mu_{y^{(i)}})\right) \prod_{c=1}^{C} \phi^{I[y^{(i)}=c]}
$$ $$
= \sum_{i=1}^{M} \left[-\frac{N}{2} \log(2\pi) - \frac{1}{2} \log|\Sigma| - \frac{1}{2}(x^{(i)} - \mu_{y^{(i)}})^T \Sigma^{-1} (x^{(i)} - \mu_{y^{(i)}}) + \sum_{c=1}^{C} I[y^{(i)} = c] \log \phi_c\right].
$$ Now we need to take partial derivatives with respect to each parameter and equate it to zero. For $\mu_c$ , $$
\frac{\partial\ell(\phi, \mu_c, \Sigma)}{\partial \mu_c} = \sum_{i=1}^{M} I[y^{(i)} = c] \Sigma^{-1}(x^{(i)} - \mu_c) = 0.
$$ My question So my question is, I don't really know how to do derivation of this kind of vector-equation aka going from this step: $$
= \sum_{i=1}^{M} \left[-\frac{N}{2} \log(2\pi) - \frac{1}{2} \log|\Sigma| - \frac{1}{2}(x^{(i)} - \mu_{y^{(i)}})^T \Sigma^{-1} (x^{(i)} - \mu_{y^{(i)}}) + \sum_{c=1}^{C} I[y^{(i)} = c] \log \phi_c\right].
$$ to this step: $$
\frac{\partial\ell(\phi, \mu_c, \Sigma)}{\partial \mu_c} = \sum_{i=1}^{M} I[y^{(i)} = c] \Sigma^{-1}(x^{(i)} - \mu_c) = 0.
$$ I know basic linear algebra and calculus, but I have not encountered this kind of derivation problem before, and I don't know where to learn it, I have been stuck here for a long time, can someone provide me a step-by-step proof of going from that step to this step please?","['machine-learning', 'multivariable-calculus', 'calculus', 'linear-algebra', 'probability']"
4780159,2 lines 1 plane question in 3 dimension,"The question I need help with is
line $D: x = {y-2\over -1} = z$ line $D': {x-2\over2} = {y-3\over1} = {z+5\over-1}$ Find plane $(α)$ for $(α)$ containing $D$ and the angle between $(α)$ and $D' $ is 60 degrees. This is what I did
let $v,v'$ be the vector for line $D,D'$ respectively.
I got $v = ( 1, -1, 1)$ ; $v' = ( 2, 1, -1)$ , which is perpendicular (got from their dot product) meaning $D$ and $D'$ is perpendicular. I calculated that $D$ and $D'$ do not intersect.","['calculus', 'linear-algebra', '3d', 'plane-geometry']"
4780173,Regular Variation and Maximal Moments,"Let $X$ be a non-negative random variable. We call $X$ regularly varying with tail index $\alpha>0$ if $$\lim_{u\to\infty}\frac{\mathbb P[X>ut]}{\mathbb P[X>u]}=t^{-\alpha}, \hspace{1cm}\forall t>0.$$ It is well-known, see e.g. Heavy-Tailed Time Series Proposition 1.4.6., that for such random variables we have $$\forall\beta<\alpha:\mathbb E|X|^\beta<\infty,\hspace{1cm}\forall\gamma>\alpha: \mathbb E|X|^\gamma=\infty,$$ hence we can view $\alpha$ as describing how heavy-tailed the distribution of $X$ is. Now, more generally for a random variable $X$ define $$\eta_X:=\sup\big\{\beta\geq 0: \mathbb E|X|^\beta<\infty\big\}.$$ From the basic result listed above we have for a regularly varying random variable $X$ with tail index $\alpha$ that $\eta_X=\alpha$ . I want to know whether it is possible to derive a result in the other direction: Are there any known conditions under which a random variable $X$ with $\eta_X\in(0,\infty)$ is regularly varying with index $\eta_X$ ? As a first remark, I doubt that $\eta_X$ being finite and positive is sufficient for $X$ to be regularly varying, since by Karamata's Characterization Theorem we can write any regularly varying tail function as $$(*)\hspace{1cm}\mathbb P[X>t]=t^{-\alpha}\cdot \ell(t)$$ for a slowly varying function $\ell$ . Now $\eta_X\in(0,\infty)$ only tells us that $$\int_0^\infty \mathbb P[X>t^{1/\beta}]dt<\infty, \hspace{1cm}\forall \beta<\eta_X.$$ However, i doubt that from the finiteness of these integrals alone it is possible to derive a representation as in $(*)$ .","['expected-value', 'probability-distributions', 'probability', 'distribution-tails']"
4780186,"How does the space $L^2(\Omega_T)$ compares to $L^2(0,T; L^2(\Omega))$?","Let $\Omega \subset \mathbb{R}^n$ and $\Omega_T = \Omega \times (0,T)$ . I am confused with regards to the difference between the space $L^2(\Omega_T)$ and $L^2(0,T; L^2(\Omega))$ . Are they equivalent? The norm for the latter is $$\int_0^T \|u\|_2^2 = \int_0^T \int_{\Omega} |u|^2$$ I am not sure what will be the norm for the former (Although the domain will be $\Omega_T$ )","['function-spaces', 'bochner-spaces', 'functional-analysis', 'partial-differential-equations']"
4780187,Is there a topology for nondecreasing continuous functions?,"Let $I=[0,1]$ be the unit interval, with $\tau_0$ the usual topology. Inspired by this question , I've been wondering whether it is possible to topologize $I$ so that the continuous functions are precisely the usual continuous functions that are also nondecreasing.  That is, Is there another topology $\tau$ on $I$ such that $f\colon I\to I$ is $\tau$ -continuous if and only if it is $\tau_0$ -continuous and nondecreasing? (Here by $\tau$ -continuous we mean continuous when both domain and codomain are equipped with $\tau$ .) There are some related topologies in this vein. If we only want to get nondecreasing functions (i.e., $f$ is continuous iff $f$ is nondecreasing), we have the Alexandrov topology given by: $$\tau_a=\{U\in \mathcal P(I)\mid x\in U\wedge y\geq x\implies y\in U\}$$ Similarly, if we let $\tau_-=\{(a,1]\mid 0\leq a<1 \}\cup\{\emptyset\}$ , it is routine to verify $f$ is $\tau_-$ -continuous if and only if $f$ is nondecreasing and $\tau_0$ -continuous from the left. We could similarly get right continuity by defining $\tau_+=\{[0,a)\mid 0<a\leq 1\}\cup\{\emptyset\}$ . However, these kinds of simple constructions don't seem to have an obvious way to modify them to get all nondecreasing continuous functions - trying to combine the open sets in $\tau_+$ and $\tau_-$ gives us back $\tau_0$ , so we lose monotonicity. I'd be very interested in either an example of such a topology $\tau$ or a proof that one cannot exist. More generally, one can replace $I$ with any totally ordered set $T$ with its order topology, and ask the same question.  The topologies $\tau_a$ , $\tau_+$ , and $\tau_-$ defined above all generalize easily, and as a result, it is easy to see that if $T$ is any well-ordered set, or more generally, any total ordered set in which every element has an immediate successor, the answer is yes, since we can just take $\tau_-$ , as every function is already continuous from the right.  But it would be interesting to know if there are other examples.","['continuity', 'general-topology', 'monotone-functions', 'order-theory']"
4780246,Left adjoint to the forgetful functor from Hilbert spaces to topological spaces,"I'm trying to generalize a method which can solve a problem involving discrete group to continuous group. And the method involve construct a ""free vector space"" from discrete space. So I'm trying to find a way to construct some kind of ""free Hilbert space"" from a topological space. But I have no idea how to achieve this goal. Then I find that one can get a free group or free vector space by considering the left adjoint of forgetful functor, so I wonder if one can go this way to get ""free Hilbert space"". But I don't know how to construct this adjoint. Let $\mathbf{Hil}$ be the category of Hilbert spaces, $\mathbf{Top}$ be the category of topological spacces, and consider the forgetful functor $ F : \mathbf{Hil} \to \mathbf{Top}.$ Does this functor $F$ have a left adjoint? If it does, what is this left adjoint?","['adjoint-functors', 'functional-analysis', 'category-theory']"
4780283,Spivak 4-23 How to construct the $k$-cell?,"I'm going through Spivak's Calculus on Manifolds, and I'm trying to do question 4-23 because I'm trying to understand how the chains and geometry works, but I'm having some trouble since most mark schemes cut off before this point.  The question is For $R>0$ and $n$ an integer, define a singular $1$ -cube $c_{R,n}:[0,1]\rightarrow\mathbb{R}^2-0$ by $c_{R,n}(t)=(R\cos2\pi nt,R\sin2\pi nt)$ .  Show that there isa singular $2$ -cube $c:[0,1]^2\rightarrow\mathbb{R}^2-0$ s.t. $c_{R_1,n}-c_{R_2,n}=\partial c$ I've been visualising $c_{R,n}$ as some phasor, and I've been working backwards, so I'm trying to construct a function in $[0,1]^2$ s.t. when $y=0$ , $f(x,0)=(\cos\left(\frac{\pi}{4}nx\right),\sin\left(\frac{\pi}{4}nx\right))$ .  I think $$f(x,y)=(R_1-R_2)\left(\cos\left(\frac{\pi}{4}nx\right)+\cos\left(\frac{\pi}{4}n(1+y)\right),\sin\left(\frac{\pi}{4}nx\right)+\sin\left(\frac{\pi}{4}n(1+y)\right)\right)$$ works, but I'm not sure whether I've done it correctly, since in my case surely this could've been done with a single $c_{R,n}$ ?  I feel as though I'm completely missed the point of the exercise.  In the words of Pauli, it seems that ""it's not even wrong""!","['multivariable-calculus', 'solution-verification']"
4780301,Multi variable integral : $\int_{0}^{1}\int_{0}^{\sqrt{1-x^2}} \frac{e^y}{\sqrt{1-x^2-y^2}} dy dx$,"How can I solve the following multi variable integral: $\int_{0}^{1}\int_{0}^{\sqrt{1-x^2}} \frac{e^y}{\sqrt{1-x^2-y^2}} dy dx$ I have seen it in an exam. I tried to rewrite it in polar coordinates as follows, but to no avail. $x^2+y^2 = r ^2$ $y = r.sin(\theta)$ $x = r.cos(\theta)$ $dydx =  r dr d\theta$ $\int_{0}^{\pi/2}\int_{0}^{1} \frac{e^{r.sin\theta}}{\sqrt{1-r^2}} r dr d\theta$",['multivariable-calculus']
4780305,$I = \int_0^{\pi/2} \left( \int_0^{\pi/2} \frac{\log(\cos(x/2)) - \log(\cos(y/2))}{\cos(x) - \cos(y)} dx\right) \ dy $,"\begin{align*}
I = \int_0^{\pi/2} \left( \int_0^{\pi/2} \frac{\log(\cos(x/2)) - \log(\cos(y/2))}{\cos(x) - \cos(y)} dx\right) \ dy
\end{align*} What I do so far Let $u = \cos(x/2)$ and $v = \cos(y/2)$ . Then $du = -\sin(x/2) dx/2$ and $dv = -\sin(y/2) dy/2$ . $$I = \int_0^{\pi/2} \left( \int_0^{\pi/2} \frac{\log(u) - \log(v)}{u - v} \cdot \frac{-2 du}{2 \sin(x/2)} \right) \cdot \frac{-2 dv}{2 \sin(y/2)}$$ Logu=u $$I = \int_0^{\pi/2} \left( \int_0^{\pi/2} \frac{\log(u) - \log(v)}{u - v} \cdot \frac{-2 du}{2 \sin(x/2)} \right) \cdot \frac{-2 dv}{2 \sin(y/2)} - \int_0^{\pi/2} \frac{\log(u) - \log(v)}{u - v} \cdot \frac{1}{\sin(x/2)} \cdot \frac{-2 dv}{2 \sin(y/2)}$$ $$\int \frac{\log(u) - \log(v)}{u - v} du = \log \left| \frac{u}{v} \right| + C$$ $$I = \int_0^{\pi/2} \left( \log \left| \frac{u}{v} \right| \cdot \frac{2}{\sin(y/2)} - \frac{\log(u) - \log(v)}{u - v} \cdot \frac{1}{\sin(x/2)} \cdot \frac{2 dv}{2 \sin(y/2)} \right)$$ This looks very scary","['integration', 'improper-integrals', 'catalans-constant', 'definite-integrals']"
4780345,Is $\sin\left(\frac{2\pi k}{N}\right) + \sin\left(\frac{2\pi k(N-1)}{N}\right) =0$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question I am working on a proof where I know a quantity vanishes. When I reduce the expression I obtain, $$\sin\left(\frac{2\pi k}{N}\right) + \sin\left(\frac{2\pi k(N-1)}{N}\right)$$ for natural numbers $N$ and $k$ with $k<N$ ,
but it is not clear to me why this vanishes. I cannot find an example where it does not.",['trigonometry']
4780368,Must two groups with all subgroups of the same order be isomorphic? [duplicate],"This question already has an answer here : Does the order, lattice of subgroups, and lattice of factor groups, uniquely determine a group up to isomorphism? (1 answer) Closed 9 months ago . Let $G,H$ be finite groups such that there's bijection $\varphi$ from the subgroups of $G$ into the subgroups of $H$ satisfying: $|g_1|=|\varphi(g_1)|$ ; $g_1 < g_2$ if and only if $\varphi(g_1)<\varphi(g_2)$ ; $g_1 \triangleleft g_2$ if and only if $\varphi(g_1)\triangleleft\varphi(g_2)$ . Is it always true that $G\cong H$ ? This question arises if you consider two Galois extensions $F_1, F_2$ of $K$ . If all intermediate extensions $K\subseteq E_1\subseteq F_1$ and $K\subseteq E_2\subseteq F_2$ look the same as $K$ -vector fields then $gal(F_1 |K)\cong gal(F_2|K)$ ?","['group-isomorphism', 'finite-groups', 'galois-theory', 'normal-subgroups', 'group-theory']"
4780404,"Evaluating $\int_{-\infty}^\infty \coth x \exp(-a \cosh x + b \sinh x) \, dx$ and $\int_0^b K_0(\sqrt{a^2 - b'^2}) \, db'$","I am trying to evaluate the integral $$I = \int_{-\infty}^{\infty} \underbrace{\coth x}_{f(x)} \exp(-a \cosh x + b \sinh x) \, dx \, ,$$ where $a \in \mathbb{R}^+$ , $b \in \mathbb{R}$ , and $|b/a| < 1$ . Related integrals, where one replaces $f(x) = \coth x$ by $\cosh^n x \sinh^m x$ for $n, m \in \mathbb{N}$ , are relatively straightforward to solve by repeatedly differentiating under the integral, i.e. $$\int_{-\infty}^{\infty} \cosh^n x \sinh^m x \exp(-a \cosh x + b \sinh x) \, dx = (-\partial_a)^n \partial_b^m \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx \, .$$ This integral can be evaluated to get a modified Bessel function of the second kind $$\int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx = 2 K_0(\sqrt{a^2 - b^2}) \, ,$$ whereupon one may straightforwardly apply the derivatives to generate the even $(\cosh^n x)$ and odd $(\sinh^m x)$ moments of the distribution. However, this same approach does not work for the negative integer moments, since one must integrate for negative powers, with the integral in question being rather non-trivial to evaluate. For example, in the case that $f(x) = 1/\sinh x$ , one finds $$I'(b) = \int_{-\infty}^{\infty} \exp(-a \cosh x + b \sinh x) \, dx \, .$$ Then, using the fact that the integrand of $I(0)$ is odd, such that $I(0) = 0$ , one must find $$I = \int_0^b \int_{-\infty}^{\infty} \exp(-a \cosh x + b' \sinh x) \, dx \, db' = \int_0^b 2 K_0(\sqrt{a^2 - b'^2}) \, db' \, ,$$ and I do not know how to proceed. Similar difficulties are encountered for $f(x) = 1/\cosh x$ . If one wants to evaluate the original integral by this method, with $f(x) = \coth x$ (or also for $f(x) = \tanh x$ ), then one must evaluate the above cases. I would greatly appreciate any suggestions on how to evaluate the above integrals (for $f(x) = 1/\sinh x$ and $f(x) = 1/\cosh x$ ), or any suggestions of alternative approaches that would avoid these difficulties.","['integration', 'definite-integrals', 'special-functions', 'hyperbolic-functions', 'bessel-functions']"
4780486,Bounding a Real Function in Absolute Value,"Show that if $\omega$ is a primitive $2m^\text{th}$ root of unity, where $m\geq 1$ is an integer, then for all $i\geq 0$ and $x\in [0,1]$ , we have the inequality $$\prod_{j=0}^{2m-1}|1-x^{(2i+1)m+j}\omega^j|\leq 1.$$ I am convinced of this result, and numerical experimentation seems to confirm it, although I have yet to find a simple proof of it. I came across this result trying to show that a certain complex analytic function has a natural boundary of the unit circle, but the statement itself seems to be of independent interest (or at least independent musing-ability). I believe the following to be true: the quantity on the left is a decreasing function of $x$ for fixed $i$ and an increasing function of $i$ for fixed $x$ ; if we can prove either of these assertions, then we will be done, but neither seems to be very tractable. Further, no such result is true (even with minor modifications to account for indexing problems) for primitive odd roots of unity. Here's one proof attempt: one could try to compare with the product $$\prod_{j=0}^{2m-1}|1-x^{(2i+1)m}\omega^j|=|1-x^{2(2i+1)m^2}|\leq 1,$$ but this doesn't work because in general it is not true that $$\prod_{j=0}^{2m-1}|1-x^{(2i+1)m+j}\omega^j|\leq \prod_{j=0}^{2m-1}|1-x^{(2i+1)m}\omega^j|.$$ However, this proof attempt works for $m\in \{1,2\}$ (for which this last inequality does hold), and gives some insight to why such a result could be true in general. Note that the limit as $x\to 1^{-}$ of the quantity on the left hand size is $0$ , so the question is really only challenging when $x$ (or more specifically $x^i$ ) is small.","['complex-analysis', 'roots-of-unity', 'upper-lower-bounds', 'real-analysis']"
4780496,"Point $D$ in $\triangle{ABC}$ such that $\angle{DBC}=\angle{DCB}=10^{\circ}$, $\angle{BAD}=20^{\circ}, \angle{DAC}=40^{\circ}$, show that $AD=AC$","Point $D$ In $\triangle{ABC}$ such that $\angle{DBC}=\angle{DCB}=10^{\circ}, \angle{BAD}=20^{\circ}, \angle{DAC}=40^{\circ}$ , show that $AD=AC$ . Wonder if there is pure geometric approach to prove this statement? Thanks For trigonometric solution, apply Ceva's theorem in angles:
Let $\angle{ABD}=x$ $$
\begin{multline}\nonumber
\shoveleft \dfrac{\sin20}{\sin40} \dfrac{\sin(100-x)}{\sin10} \dfrac{\sin10}{\sin x}=1 \\
\shoveleft \implies \dfrac{\sin(100-x)}{2\sin x \cdot \cos20}=1 \\
\shoveleft \implies \cos(x-10)=2\sin x \cdot \cos20\\
\shoveleft \implies \cos x \cdot \cos10+\sin x \cdot \sin10=2\cos20 \cdot \sin x\\
\shoveleft \implies \tan x = \dfrac{\cos10}{2\cos20-\sin10}=\dfrac{\sin30 \cdot \cos10}{\cos20 -\sin30 \cdot \sin10}\\
\shoveleft =\dfrac{\sin30 \cdot \cos10}{\cos20-\tfrac{1}{2}(\cos20 + \cos40)}=\dfrac{\sin30 \cdot \cos10}{\tfrac{1}{2}(\cos20-\cos40)}\\
\shoveleft = \dfrac{\sin30 \cdot \cos10}{\cos30 \cdot \cos10}=\tan30 \implies x=30^{\circ} \implies \angle{ACD}=70^{\circ} \implies AC=AD \blacksquare
\end{multline}
$$","['triangles', 'euclidean-geometry', 'trigonometry', 'geometry']"
4780551,Is every series a telescoping series?,"This question may seem silly at first. We say that a series $\sum a_n$ is a telescoping series if there exists a sequence $(b_n)$ with $a_n=b_n-b_{n+1}$ for every $n$ . One can show that $\sum a_n$ converges if and only if the sequence $(b_n)$ converges. It is thus desirable to know if a series is a telescoping series, and then find a ""telescoping form"". This begs the question, which is in the title, is every series a telescoping series?
I have little doubt that the answer is that not every series is a telescoping series.
The problem I have in finding a counterexample is that it seems hard to prove that given a sequence $(a_n)$ there is no sequence $(b_n)$ such that $a_n=b_n-b_{n+1}$ for every $n\in\mathbb{N}$ . I have another question which is related enough to the first question so I'll ask it in this post.
If we have $a_n=b_n-b_{n+1}$ then we also have $a_n=c_n-c_{n+1}$ where $c_n=b_n+c$ for some $c$ . Somewhat analogous to antiderivatives, given sequences $(a_n),(b_n)$ with $a_n=b_n-b_{n+1}$ then if $(c_n)$ satisfies $a_n=c_n-c_{n+1}$ then does there exist a $c$ such that $c_n=b_n+c$ ?
If the answer is affirmative then given a telescoping series we can find all of its ""telescoping forms"".","['telescopic-series', 'sequences-and-series']"
4780659,A very intuitive question about iterated expectations,"I am struggling to prove a very intuitive property about iterated expectations. We know that $$\mathbb E[X] = \mathbb E[\mathbb E[X\vert Y]].$$ I want to argue the following: \begin{align*}
\mathbb E[XY \vert Z ] = \mathbb E[X \mathbb E[Y \vert X,Z] \vert Z]
\end{align*} But I am having a hard time establishing this using the definition of conditional expectations. To prove this would entail proving, \begin{align*}
\int_S XY d\mathbb P = \int_S X \mathbb E[Y \vert X,Z] d\mathbb P
\end{align*} for all $S \in \sigma(Z)$ . This would be true if, for example, $Y = \mathbb E[Y \vert X,Z]$ which seems way demanding and is, most likely, not true. Could anyone help please?","['conditional-expectation', 'probability-theory']"
4780673,Does embedding of the Banach space into its bidual preserve extreme points of the unit ball?,"Consider Banach space $X$ with unit ball $B_X$ . There is the cannonical embeding $\iota:X\to X^{**}$ . Does this always preserve extreme points of $B_X$ ? I.e., is it always true that $\iota(\partial_e(B_X))\subset \partial_e(B_{X^{**}})$ ? I tried to prove it by having $x\in\partial_eB_X$ and $y,z\in B_{X^{**}}\setminus\{x\}$ such that $\frac{y+z}2=x$ and looking at the sequances $(y_k),(z_k)\subset B_X$ weakly-* converging to $y$ and $z$ , but I can't seem to squeeze the contradiction out of it. Also, by Milman's theorem, it is obvious for isolated points of $\partial_eB_X$ , but that really don't need to be all of them...","['banach-spaces', 'functional-analysis']"
4780740,Epimorphism between free groups that inject on a finite subset,"I asked a question on MathOverflow ( https://mathoverflow.net/q/454012/513011 ) where the following lemma appeared: Folklore lemma: Let $S$ be a finite subset of the free group $F_n$ of finite rank $n$ . If $n>2$ then there is an epimorphism $\psi:F_n\to F_{n-1}$ that is injective on $S$ . I want to prove this lemma now but I have some problems with that. I have the following hints for the proof: As you can see already from the question that I asked on MathOverflow, the proof of this lemma might have to do something with the theory of limit groups/fully residually free groups. Here is a good reference for that if you don't know anything about that topic: An Introduction to Limit Groups by Wilton ( pdf ). In particular we can see from Example 2.2 that free groups are fully residually free, so there is always a homomorphism from $F_n\to F_{n-1}$ that is injective on $S$ . But we need an epimorphism . But maybe this theory is not needed at all and there exists an elementary proof for that.","['geometry', 'abstract-algebra', 'free-groups', 'geometric-group-theory', 'group-theory']"
4780783,Series with numbers $\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}$,"I'm looking for series alike in the literature containing in their summands numbers of the type $\displaystyle Q_n=\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}$ . The following three series have recently been presented by C.I.Valean in this short exposition , \begin{equation*}
i) \ \sum _{n=1}^{\infty } \frac{ 2^n}{\displaystyle n^2 \binom{2 n}{n}}\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}=\sum _{n=1}^{\infty } \frac{ 2^n Q_n}{\displaystyle n^2 \binom{2 n}{n}}=2 G;
\end{equation*} \begin{equation*}
\small ii) \ \sum _{n=1}^{\infty } (-1)^{n-1} \frac{ 2^n}{\displaystyle n^2 \binom{2 n}{n}}\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}=\sum _{n=1}^{\infty } (-1)^{n-1} \frac{ 2^n Q_n}{\displaystyle n^2 \binom{2 n}{n}}=\frac{\pi}{3}  \log(2+\sqrt{3})-\frac{2}{3}G;
\end{equation*} \begin{equation*}
iii) \ \sum _{n=1}^{\infty } \frac{ 4^n}{\displaystyle n^2 \binom{4 n}{2n}}\sum _{k=0}^{2n-1}\frac{1}{2^k }\binom{2 k}{k}=\sum _{n=1}^{\infty } \frac{ 4^n Q_{2n}}{\displaystyle n^2 \binom{4 n}{2n}}=\frac{16}{3}G-\frac{2}{3}\pi \log(2+\sqrt{3}),
\end{equation*} where here $\displaystyle G=\sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{(2n-1)^2}$ is the Catalan's constant. For example, in the case of the second series, we may proceed as follows: exploiting that $\displaystyle \int_0^{\pi/2} \sin(n \theta) \cos^{n-1}(\theta) \textrm{d}\theta=\frac{2^n}{\displaystyle n \binom{2n}{n}}\sum_{k=0}^{n-1} \frac{1}{2^k}\binom{2k}{k}$ , which is found and evaluated in More (Almost) Impossible Integrals, Sums, and Series (2023) , page $16$ (exploiting simple recurrence relations is enough to extract a solution), we have $$\sum _{n=1}^{\infty } (-1)^{n-1} \frac{ 2^n}{\displaystyle n^2 \binom{2 n}{n}}\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}=\sum _{n=1}^{\infty} (-1)^{n-1}\frac{1}{n} \int_0^{\pi/2} \sin(n \theta) \cos^{n-1}(\theta) \textrm{d}\theta$$ $$=\int_0^{\pi/2}\frac{1}{\cos(\theta)}\Im \biggr\{\sum_{n=1}^{\infty} (-1)^{n-1}\frac{(\cos(\theta) e^{i \theta})^n}{n}\biggr\}\textrm{d}\theta=\int_0^{\pi/2} \frac{\Im \{\log(1+\cos(\theta) e^{i \theta})\}}{\cos(\theta)}\textrm{d}\theta$$ $$\small =\int_0^{\pi/2}\frac{1}{\cos(\theta)} \arctan\left(\frac{\cot(\theta)}{1+2\cot^2(\theta)}\right)\textrm{d}\theta\overset{\theta\mapsto \pi/2-\theta}{=}\int_0^{\pi/2}\frac{1}{\sin(\theta)} \arctan\left(\frac{\tan(\theta)}{1+2\tan^2(\theta)}\right)\textrm{d}\theta$$ $$\overset{\theta \mapsto 2 \arctan(\theta)}{=}\int_0^1 \frac{1}{\theta}\arctan\left(\frac{2\theta (1-\theta^2)}{1+6 \theta^2+\theta^4}\right)\textrm{d}\theta$$ $$=\int_0^1 \frac{1}{\theta}\arctan\left(\frac{4\theta/(1-\theta^2)-2\theta/(1-\theta^2)}{1+(4 \theta/(1-\theta^2)) \cdot (2 \theta/(1-\theta^2))}\right)\textrm{d}\theta$$ $$=\int_0^1 \frac{1}{\theta}\arctan\left(\frac{4\theta}{1-\theta^2}\right)\textrm{d}\theta-\int_0^1 \frac{1}{\theta}\arctan\left(\frac{2\theta}{1-\theta^2}\right)\textrm{d}\theta$$ $$=\int_0^1 \frac{1}{\theta}\arctan\left(\frac{(2-\sqrt{3})\theta+(2+\sqrt{3})\theta}{1-(2-\sqrt{3})\theta\cdot (2+\sqrt{3})\theta}\right)\textrm{d}\theta-2\int_0^1 \frac{\arctan(\theta)}{\theta}\textrm{d}\theta$$ $$=\int_0^1 \frac{\arctan((2-\sqrt{3})\theta)}{\theta}\textrm{d}\theta+\int_0^1 \frac{\arctan((2+\sqrt{3})\theta)}{\theta}\textrm{d}\theta-2\int_0^1 \frac{\arctan(\theta)}{\theta}\textrm{d}\theta$$ $$=\operatorname{Ti}_2(2-\sqrt{3}) +\operatorname{Ti}_2(2+\sqrt{3}) -2 \operatorname{Ti}_2(1)=\frac{\pi}{3}  \log(2+\sqrt{3})-\frac{2}{3}G,$$ where we also needed to employ the well-known special values of the Inverse tangent integral like $\displaystyle \operatorname{Ti}_2(1)=G$ , $\displaystyle \operatorname{Ti}_2(2-\sqrt{3})=\frac{2}{3}G+\log(2-\sqrt{3})\frac{\pi}{12}$ , and $\displaystyle \operatorname{Ti}_2(2+\sqrt{3})=\frac{2 }{3}G-\frac{5}{12}\log \left(2-\sqrt{3}\right)\pi$ . For another solution, one might think of using Wallis' integrals. Question 1: Given the simplicity of the first result I wonder if that series already appeared in the literature (if so, the presentation will be updated accordingly). Have you ever met it before (together with a reference)? Question 2: More generally, I'm interested in finding more series involving those $Q_n$ numbers if they are available in the literature. Any references? Personally, I would also find very interesting more general cases like $$S_m=\sum _{n=1}^{\infty } \frac{ 2^n Q_n}{\displaystyle n^m \binom{2 n}{n}}, \ m \ge3,$$ and note that for $m=2$ we get the series from the point $i)$ . Update 1: Another fantastic example , given the generalization above, is the case $m=3$ . Cornel says that by using a strategy similar to the one in the reference above, we get that $$\sum _{n=1}^{\infty } \frac{ 2^n}{\displaystyle n^3 \binom{2 n}{n}}\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}=\sum _{n=1}^{\infty } \frac{ 2^n Q_n}{\displaystyle n^3 \binom{2 n}{n}}=2 \log(2)G,$$ and it looks too beautiful to be real! This closed form makes me wonder if (there is any chance) we can relate this series to this integral problem in this post How to show $\int_0^1\frac{\operatorname{Li}_2\left(\frac{1+x^2}{2}\right)}{1+x^2}dx=\ln(2)G$ . Update 2: Okay, I've just found an answer to my thoughts in the previous update, and, Yes , they can be perfectly related. So, we can, for example, evaluate this series at this point by three solutions (a bit subtle this part in the sense that they are different only from the perspective of getting the core integral evaluated differently), and now I refer to the integral at the reference in the previous update (it represents the toughest obstacle in the evaluation). So, for that integral we already have two solutions in More (Almost) Impossible Integrals, Sums, and Series (2023) and one by Sujeethan Balendran available at that link. Update 3: The version $m=4$ has just been derived by Cornel, and together with the closed form all looks more than amazing, $$\sum _{n=1}^{\infty } \frac{ 2^n}{\displaystyle n^4 \binom{2 n}{n}}\sum _{k=0}^{n-1}\frac{1}{2^k }\binom{2 k}{k}=\sum _{n=1}^{\infty } \frac{ 2^n Q_n}{\displaystyle n^4 \binom{2 n}{n}}$$ $$=\log^3(2)\frac{\pi}{12}-\frac{\pi ^2 }{3}G-\frac{5 }{48}\pi ^4   +\frac{5 }{384}\psi ^{(3)}\left(\frac{1}{4}\right)$$ $$-4 \log (2) \Im\left \{\text{Li}_3\left(\frac{1+i}{2}\right)\right\}-8 \Im\left \{\text{Li}_4\left(\frac{1+i}{2}\right)\right\}.$$ In the derivation process, the same starting ideas in the paper above were exploited.","['integration', 'reference-request', 'real-analysis', 'calculus', 'sequences-and-series']"
4780789,$(1\pm\frac{1}{3})(1\pm\frac{1}{5})(1\pm\frac{1}{7})(1\pm\frac{1}{9})(1\pm\frac{1}{11})\cdots$ and related products,"In the following paper, the authors present a proof of: $$2=(1+1)\left(1+\dfrac{1}{3}\right)\cdot\left(1-\dfrac{1}{5}\right)\cdot\left(1-\dfrac{1}{7}\right)\cdot\left(1+\dfrac{1}{9}\right)\cdots--(1) (++--++--)$$ (Reference: "" New Wallis- and Catalan-Type Infinite Products "", by Jonathan Sondow and Huang Yi) Similarly,
by applying the same method, we can prove that: $$\sqrt{2}=(1+1)\left(1-\dfrac{1}{3}\right)\cdot\left(1+\dfrac{1}{5}\right)\cdot\left(1-\dfrac{1}{7}\right)\cdot\left(1+\dfrac{1}{9}\right)\cdots--(2)(+-+-+-+-)$$ This resulted in a generalization for a certain 'n' where n represents the number of alterations of signs (In (1), n= $2$ , In (2), n= $1$ ) as: $$\prod{\dfrac{\sin(\pi k/(2n))}{\sin(\pi (2k-1)/(4n))}}$$ (k= $1$ to n) Now I have two questions: First, How do I calculate the product if 'n' varies. For instance, consider: $(1+1)(1-\dfrac{1}{3})(1+\dfrac{1}{5})(1+\dfrac{1}{7})(1-\dfrac{1}{9})(1-\dfrac{1}{11})\cdots-->(3)(+-++--+++---\cdots)$ How can one evaluate such a product? Secondly,
I used Euler's reflection formula and Weierestrass infinite product of gamma function(the referenced paper's method) to derive the general result. These are admittedly hard concepts for me currently. Can this result be derived in another simpler way perhaps? Edit:
I have found a ""solution"" for the sign fluctuating with increasing frequency $(3)(+-++--+++---\cdots)$ The product is a variant of $(2)$ . $(3)=\sqrt{2}\cdot\dfrac{1+(1/7)}{1-(1/7)}\cdot\dfrac{1-(1/9)}{1+(1/9)}\cdot\dfrac{1+(1/15)}{1-(1/15)}\cdot\dfrac{1-(1/21)}{1+(1/21)}\cdots$ This results in: $(3)=\dfrac{4\sqrt{2}}{3}\cdot \left(\dfrac{8\cdot16\cdot20\cdot28\cdot32\cdots}{10\cdot14\cdot22\cdot26\cdot34\cdots}\right)=\dfrac{4\sqrt{2}}{3}\cdot \left(\dfrac{4\cdot8\cdot10\cdot14\cdot16\cdots}{5\cdot7\cdot11\cdot13\cdot17\cdots}\right)=\left(\dfrac{4\sqrt{2}}{3}\cdot \prod{\dfrac{(6n+4)\cdot(6n+8)}{(6n+5)\cdot(6n+7)}}\right)$ $(3)=\dfrac{4\sqrt{2}}{3}\cdot\dfrac{\Gamma{(5/6)}\Gamma{(7/6)}}{\Gamma{(2/3)}\Gamma{(4/3)}}=\dfrac{2\sqrt{2}}{\sqrt{3}}$ (Consequently, from the cosine factorisation, the series $(4)(+--++---+++\cdots)$ : $(1+\dfrac{1}{3})(1-\dfrac{1}{5})(1-\dfrac{1}{7})(1+\dfrac{1}{9})(1+\dfrac{1}{11})\cdots=\dfrac{\pi}{4}\cdot\dfrac{2\sqrt{2}}{3}\cdot \dfrac{\Gamma{(2/3)}\Gamma{(4/3)}}{\Gamma{(5/6)}\Gamma{(7/6)}}=\dfrac{\pi\sqrt{3}}{4\sqrt{2}}$ So now my question becomes 1): Can we generalize a formula for any fluctuating sign series?(Could be AP or GP) Or at least find all the possible fluctuations of 'n' for which the final result is deducible. 2): Now, there does exist a simpler proof for the first product, https://math.stackexchange.com/q/4777515 . Please try to prove $(1)$ using any method except the one mentioned here and the cited answer. You are free to use advanced mathematics.","['alternative-proof', 'infinite-product', 'sequences-and-series']"
4780795,Infinite series over recursive digit-counts,"Given a positive integer $n,$ let $S(n)$ be the number of digits in the decimal expansion of $n,$ and let $$f(n)=n\cdot S(n)\cdot S(S(n))\cdot\ldots$$ Note that this is well-defined, since repeatedly applying $S$ eventually yields a stable state at $1$ . For example, $$f(99)=99\cdot 2\cdot 1\cdot1\cdot\ldots=198$$ and $$f\left(10^{100}\right)=10^{100}\cdot 101\cdot 3\cdot 1\cdot1\cdot\ldots=303\cdot 10^{100}.$$ Does the sum $\displaystyle\sum_{n=1}^{\infty}\frac{1}{f(n)}$ converge or diverge? Some context: I'm trying to find the limits of what can be done with the integral test. The functions $\frac{1}{x},$ $\frac{1}{x\ln(x)},$ $\frac{1}{x\ln(x)\ln(\ln(x))},$ etc. have integrals of $\ln(x),$ $\ln(\ln(x)),$ $\ln(\ln(\ln(x)))$ etc. respectively, so infinite sums over these functions diverge ever more slowly as you add more terms; this is an attempt to find out what the limiting behavior looks like. Base 10 used for ease of reading, but the answer in any base should be the same since sums are off by at most a constant factor.","['calculus', 'improper-integrals', 'recursion', 'sequences-and-series']"
4780822,What is the cardinality of the set of all groups (up to isomorphism) of countable order?,"Apologies if this is a known result, I have looked around and could not find it. There is a pretty vast literature on the number of groups up to isomorphism of order $n$ , for any natural number $n$ . This paper for instance classifies for which $n$ are there are one, two, or three groups of order $n$ . However, I haven't been able to find any results, not even partial, on the cardinality of the number of groups up to isomorphism of order $|\mathbb N|$ . Is this known, and if not are there partial results on it? I suspected that the number of abelian groups up to isomorphism would be known (as it is a well-known result for finite groups) but I cannot find the result, if it is published.","['group-theory', 'infinite-groups']"
4780883,infinite limit with $n^2$ root of $n!$,"If $\displaystyle p=\lim_{n\rightarrow \infty}\frac{\sqrt[n^2]{1!\cdot 2!\cdot 3!\cdots n!}}{n^q}.$ Then finding value of ordered pair $(p,q)$ , Where $p>0 ,q\neq 0$ . What I try: $\displaystyle (1!\cdot 2!\cdot 3!\cdots n!)^{\frac{1}{n^2}}=e^{\ln(1!\cdot 2!\cdots n!)^{\frac{1}{n^2}}}$ $\displaystyle =e^{\frac{1}{n^2}\ln(1!\cdot 2!\cdot 3!\cdots n!)}=e^{\frac{1}{n^2}(n\ln(1)+(n-1)\ln(2)+(n-2)\ln(3)+\cdots +1\ln(n)}$ I have seems that it must be in Riemann sum , but could not understand
how do i Convert it, please have a look , Thanks",['limits']
4780895,Global orientation class of $M$ implies top homology is $\mathbb{Z}$,"Let $M$ a compact, connected $m$ -manifold. Assume that there exists a global orientation class, i.e. an $\sigma_M \in H_m(M;\mathbb{Z})$ such that for all $x\in M$ the element $(\rho_{x,M})_{\ast}(\sigma_M)$ is a generator of the local homology group $H_m(M,M\setminus x;\mathbb{Z})\cong \mathbb{Z}.$ Here $(\rho_{x,M})_{\ast}\colon H_m(M;\mathbb{Z})\rightarrow H_m(M,M\setminus x;\mathbb{Z})$ is the morphism induced by the map of pairs $\rho_{x,M}\colon (M,\emptyset)\rightarrow (M,M\setminus x)$ . I want to prove that then $H_m(M;\mathbb{Z})\cong \mathbb{Z}.$ First, since no generator of $\mathbb{Z}$ has finite order and since applying a group homomorphism can not increase the order of an element, $\sigma_M$ has infinite order. Now I want to prove that $\sigma_M$ is a generator of $H_m(M;\mathbb{Z})$ . To see this, let $a\in H_m(M;\mathbb{Z})$ . Then for all $x\in M$ there exists $k_{x,a}\in \mathbb{Z}$ with $(\rho_{x,M})_{\ast}(a)=k_{x,a}\cdot (\rho_{x,M})_{\ast}(\sigma_M)$ , since $(\rho_{x,M})_{\ast}(\sigma_M)$ is a generator. My notes now read as follows: As the $(\rho_{x,M})_{\ast}(\sigma_M)$ are all coherent, these $k_{x,a}$ have to be constant, i.e. equal to some $k$ , and if we set $b:=a-k\sigma_M$ , we see $(\rho_{x,M})_{\ast}(b)=0$ for all $x\in M$ . Therefore $b=0$ . How does the sentence marked in bold follow from the fact that the local orientations $(\rho_{x,M})_{\ast}(\sigma_M)$ are all coherent? Put differently, why is $\sigma_M$ a generator? Edit on the definitions used: Let $M$ be an $m$ -manifold. For $x\in M$ , a choice of generator $\sigma_x\in H_m(M,M\setminus x)$ is called a local orientation at x . A family of local orientations $(\sigma_x)_{x\in M}$ is called coherent if for any $x\in M$ there exists an open neighbourhood $U_x$ of $x$ and an element $\sigma_{U_x}\in H_m(M,M\setminus U_x)$ such that $(\rho_{y,U_x})_{\ast}(\sigma_{U_x})=\sigma_y$ for all $y\in U_x$ . An orientation on $M$ is a choice of a coherent family of local orientations.","['orientation', 'manifolds', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
4780961,Alternate definition of riemannian manifold,"By the Nash embedding theorem, it seems the definition of riemannian smooth manifold is equivalent to the zero locus of some functions $f_1,\dots,f_r : \mathbb{R}^n\to\mathbb{R} $ which are $C^\infty$ and which differentials are zero at no point. This alternate definition is simpler, because it does not introduce partial charts, the metric tensor is just the restriction of the euclidean inner product and the Levi-Civita connection is just the orthogonal projection of the usual derivative of vector fields. And as a bonus, the zero locus approach is closer to the definition of affine schemes in algebraic geometry. Pseudo-riemannian manifolds can also be defined this way, under the additional assumption of stable causality. So what is the advantage of the standard definition of riemannian manifold through charts and custom metric tensors? Is it just that the dimension increase of the Nash embedding $n(n+1)(3n+11)/2$ makes computations intractable? The story of an internal observer's viewpoint is not very convincing, because the only riemannian manifolds with rigid body motions (as would be a true internal observer) are the ones with constant curvature, so a tiny part of riemannian manifolds.",['differential-geometry']
4781017,Show that $\mathfrak{Re}(\textrm{Li}_2(e^{ix}))=\frac{x^2}{4}-\frac{\pi x}{2}+\frac{\pi^2}{6}$ (polylogarithm),I am working with the polylogarithm function and want to find closed expressions for $\textrm{Li}_2(e^{ix})$ . If I plot the function $\mathfrak{Re}(\textrm{Li}_2(e^{ix}))$ I get $y=\dfrac{x^2}{4}-\dfrac{\pi x}{2}+\dfrac{\pi^2}{6}$ in the interval from 0 to $2\pi$ . How can I see this connection? Is there something similar possible for $\mathfrak{Im}(\textrm{Li}_2(e^{ix}))$ ? Edit: I saw this but was not able to use it.,"['complex-analysis', 'polylogarithm', 'analysis']"
4781031,Is there a translational invariant probability measure over $\mathbb Z$?,"I hope to find a non-trivial probability measure $\mu:\mathcal B\subset\mathcal P(\mathbb Z)\to[0, 1]$ such that $\mu(A) = \mu(c+A),~\forall A\in\mathcal B,~\forall c\in\mathbb Z$ . Of course, no finite subset of $\mathbb Z$ could be $\mu-$ measurable (as discussed here ). Furthermore, if $A\in \mathcal B$ has a least element $a\in A$ , then $\displaystyle S = \{a+1,a+2,\dots\} = \bigcup_{i\ge1} i+A$ is measurable, therefore, so is $R = -1+S^C = \{\dots, a-2, a-1\}$ and $(S\cup R)^C = \{a\}$ . Contradiction! The same reasoning shows no set $A\in\mathcal B$ can have a maximum.","['measure-theory', 'set-invariance']"
4781043,Proving that the set of polynomials is closed under addition,"I'm working through Axler's Linear Algebra Done Right (third edition).
On p30-31 we are told: P(F) is the set of all polynomials with coefficients in F And then it is left to the reader to verify that $P(F)$ is a vector space over F. I'm having a bit of trouble showing that $P(F)$ is closed under addition. This is not a problem if I can assume that $P(F)$ is the set of all polynomials $p(x)$ with coefficients in $F$ and $x \in F$ . In other words I have no problem showing that $p_{1}(x) + p_{2}(x) \in P(F)$ . But Axler's definition of $P(F)$ states that it is ""the set of all polynomials with coefficients in F."" Does this include $p_{1}(x)$ and $p_{2}(z)$ for $x,z \in F$ ? If so then I'm having trouble showing that $p_{1}(x)+p_{2}(z) \in P(F)$ for $x,z \in F$ . I'm still wrapping my head around vector spaces of functions. Is there a convention with respect to the functions' arguments that I'm not aware of? (E.g., when discussing vector spaces of functions is it assumed that the argument of the functions is the same for all functions in that space? I.e. $p_{1}(x), p_{2}(x), p_{3}(x)...$ or can we assume the space includes $p_{1}(x), p_{2}(y), p_{3}(z)...$ ?) Any guidance here would be appreciated.","['linear-algebra', 'polynomials', 'vector-spaces']"
4781085,Shortest distance between the origin and a parabola,"What is the smallest distance between the origin and a point on the graph of $y = \frac{1}{\sqrt{2}} (x^2 - 18)?$ I used the distance formula to get $$\sqrt{x^2 + \frac{1}{2}(x^2-18)^2},$$ but I don't know what to do from there.",['geometry']
4781090,Evaluation of the following algebraic equation using binomial coefficients,"Given \begin{align} 
a &= {2015\choose0}+{2015\choose3}+{2015\choose6}+\cdots \\[2pt]
b &= {2015\choose1}+{2015\choose4}+{2015\choose7}+\cdots \\[2pt]
c &= {2015\choose2}+{2015\choose5}+{2015\choose8}+\cdots
\end{align} We have to find $(b-c)^2+(c-a)^2$ Note: Here $${n\choose{k}}=\frac{n!}{k!\cdot(n-k)!}$$ where $k \leq n$ for all $n,k \in \mathbb{N}$ . It is called the binomial coefficient. I have observed that $(a+b+c)=2^{2015}$ using the binomial expansion but the given fact does not provide clue to solve the given problem. Hence how can we solve the given problem?","['contest-math', 'algebra-precalculus', 'binomial-coefficients', 'binomial-theorem']"
4781122,Asymptotic behavior of a sequence of integrals of non-analytic functions,"I am interested in the asymptotic behavior of the sequence $(I_n)_{n=1}^\infty$ of integrals $$I_n=\int_0^1(1-x)^ne^{-1/x}\,dx.$$ Motivation: It is straightforward to show that, for any $f\in C[0,1]$ with $f(0)\neq0$ , $$\int_0^1(1-x)^nf(x)\,dx\sim\frac{f(0)}{n}.$$ (One method is to approximate $f$ by a $C^1$ function, then integrate by parts.) In fact, using essentially the same argument, one can show that for any $f\in C^\infty[0,1]$ , if there is a $k\in\mathbb{N}$ such that $f^{(k)}(0)\neq0$ and $f(0),f'(0),\ldots,f^{(k-1)}(0)=0$ , then $$\int_0^1(1-x)^nf(x)\,dx\sim\frac{f^{(k)}(0)}{n^{k+1}}.$$ So what about smooth functions which have every derivative at $0$ equal to zero? Such functions are either identically zero (boring) or non-analytic, so appeals to Taylor series expansions will not help to analyze them. The choice $f(x)=e^{-1/x}$ for $x\in(0,1]$ and $f(0)=0$ is one of the classical examples of a smooth but non-analytic function. The integration by parts argument doesn't seem as helpful here - we can use the formula $$\frac{d^k}{dx^k}e^{-1/x}=e^{-1/x}\sum_{\ell=1}^k(-1)^{k+\ell}\binom{k}{\ell}\binom{k-1}{\ell-1}x^{-(k+\ell)}$$ (proved here ) to rewrite the integral as $$I_n=\frac{k!}{(n+k)!}\sum_{\ell=1}^k(-1)^{k+\ell}\binom{k}{\ell}\binom{k-1}{\ell-1}\int_0^1(1-x)^{n+k}\frac{e^{-1/x}}{x^{k+\ell}}\,dx,$$ but this doesn't seem to make things any easier, except to see that the sequence $(I_n)_{n=1}^\infty$ must converge to zero faster than $n^k$ for any $k\in\mathbb{N}$ (as expected). Any ideas for how to attack this?","['definite-integrals', 'sequences-and-series', 'asymptotics', 'real-analysis']"
4781182,Proving $\sum_{n=1}^{\infty}\binom{2n}{n}^2\frac{4H_{2n}-3H_n}{n2^{4n}}=\zeta(2)$,"While trying to solve Prove $\int_{0}^{1}\frac1k K(k)\ln\left[\frac{\left(1+k \right)^3}{1-k} \right]\text{d}k=\frac{\pi^3}{4}$ I was able to reduce it to the following form, $$\sum_{n=1}^{\infty}\binom{2n}{n}^2\frac{4H_{2n}-3H_n}{n2^{4n}}=\zeta(2)$$ Where, $H_n$ is the $n$ th Harmonic Number. This should be correct if I did all the steps correctly, but I am unable to prove this further. I tried searching more about series of this form which have the Central Binomial Coefficient Squared with Harmonic Numbers but was not able to find any. Any help would be appreciated. EDIT: Considering, $$M(x)=\int_{0}^{x}\left(\frac{2K\left(\sqrt{s}\right)-\pi}{s}\right)ds$$ where $K(k)$ is the Complete Elliptical Integral of the First Kind. Then the question is reducible to, $$\int_{0}^{1}\frac{M\left(1\right)+3M\left(x\right)-4M\left(x^{2}\right)}{1-x}dx=\frac{\pi^3}{6}$$ Though no idea comes to mind after this. Here are some related results: $$M(1)=4\pi\ln2-8G$$ $$\int_{0}^{1}M\left(x\right)dx=-8G-4+\pi+4\pi\ln2$$ where $G$ is Catalan's Constant. EDIT: Let, $$A=\Im \operatorname{Li_{3}}\left(\frac{1+i}{2}\right)$$ where $\operatorname{Li_{3}}(.)$ is the trilogarithm. and $G$ be the Catalan's Constant. Using the Twin Integrals Mentioned in the Post at the Beginning, was able to arrive at these. $$\sum_{r=1}^{\infty}\binom{2r}{r}^2\frac{H_{2n}}{n2^{4n}}=24\frac{G\ln2}{\pi}+48\frac{A}{\pi}-\frac{3}{2}\ln\left(2\right)^{2}-\frac{29}{24}\pi^{2}$$ $$\sum_{r=1}^{\infty}\binom{2r}{r}^2\frac{H_{n}}{n2^{4n}}=32\frac{G\ln2}{\pi}+64\frac{A}{\pi}-2\ln\left(2\right)^{2}-\frac{5}{3}\pi^{2}$$","['integration', 'summation', 'harmonic-numbers', 'calculus', 'binomial-coefficients']"
4781190,Integrate $\sqrt{\frac{e^x-1}{e^x+1}}$,The question was as follows: $$\int{\sqrt{\frac{e^x-1}{e^x+1}}}dx$$ Which I evaluated as follows: $$\int{\sqrt{\frac{e^x-1}{e^x+1}}}dx$$ $$=\int{\frac{e^x-1}{\sqrt{e^{2x}-1}}}dx$$ $$=\int{\frac{t-1}{t \sqrt{t^2-1}}}dt$$ (Taking $t=e^x$ and $dt= tdx$ ) $$=\int{\frac{t}{t\sqrt{t^2-1}}}dt-\int{\frac{1}{t\sqrt{t^2-1}}}dt$$ $$=\sin^{-1}(t)-\int{\frac{z}{z×t^2}}dz$$ (Taking $z^2=t^2-1$ and $dt=\cfrac{z}{t}dz$ ) $$=\sin^{-1}(t)-\int{\frac{1}{z^2+1}}dz$$ $$=\sin^{-1}(t)-\tan^{-1}(z)$$ $$=\sin^{-1}(e^x)-\tan^{-1}(\sqrt{e^{2x}-1})+C$$ But the answer given is: $$\ln (e^x+\sqrt{e^{2x}-1})-\sec^{-1}(e^x)+C$$ What did I do wrong and How to obtain the correct answer?,"['integration', 'proof-explanation', 'calculus', 'solution-verification', 'indefinite-integrals']"
4781272,A matrix $A \in k^{n \times n}$ of rank $1 \leq r \leq n-1$,"Let $k$ be a field and let $A$ an $n \times n$ matrix over $k$ , with $n \geq 2$ , $A \in k^{n \times n}$ . Assume that $1 \leq rank(A)=r \leq n-1$ ; this means that $A$ has: $r$ $k$ - linearly idependent rows $r$ $k$ -linearly independent columns invertible sub-matrix $B \in k^{r \times r}$ of maximal order Question: Is it possible to obtain additional properties if we further assume that every possible sub-matrix of order $r$ is invertible? In view of Amateur_Algebraist's comment, I would like to divide this question to two cases: (i) $|k| < \infty$ ; (ii) $|k|=\infty$ . Notice that the additional assumption not always holds, for example: $ A=
\begin{pmatrix} 
1 & 0 & 0 & 0\\ 
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}$ , $n=4$ , $r=2$ . Any comments are welcome; thank you!","['matrices', 'ring-theory', 'linear-algebra', 'commutative-algebra']"
4781276,Top homology $\mathbb{Z}$ implies orientability,"Let $M$ a compact, connected $m$ -manifold. Assume that $H_m(M;\mathbb{Z})\cong \mathbb{Z}.$ I want to show that then $M$ is orientable. My ideas: Let $o_M$ one of the two generators of $H_m(M;\mathbb{Z})\cong \mathbb{Z}.$ If I could show that for any $x\in M$ the restriction map $(\rho_{x,M})_{\ast}\colon H_m(M;\mathbb{Z})\rightarrow H_m(M,M\setminus x;\mathbb{Z})$ is an isomorphism I would be done, since then $((\rho_{x,M})_{\ast}(o_M) \vert x\in M)$ would be a family of coherent generators. I convinced myself that $(\rho_{x,M})_{\ast}\colon H_m(M;\mathbb{Z})\rightarrow H_m(M,M\setminus x;\mathbb{Z})$ is injective for any $x\in M$ using the LES and Poincaré duality. But why is each restriction surjective? Can't it be multiplication by some $n\neq 0,1,-1$ ? If so it would have to be multiplication by the same $n$ for all $x$ by the argument given in the answer to my question Global orientation class of $M$ implies top homology is $\mathbb{Z}$ . But why can't that be? My notes argue like that: For surjectivity consider $(\rho_{x,M})_{\ast}o_M)\vert x\in M)=(k_xo_x)\vert x\in M )$ for some collection $k_x$ . But $k_x$ is locally constant on $M$ and thus constant, and if there is a coherent choice $(ko_x\vert x\in M)$ it follows that $(o_x \vert x\in M)$ is a coherent choice of orientation. I included the typos, maybe how I am fixing them in my head is not how they should be fixed. Anyway, I do not understand that passage. EDIT: Mikhail Katz claims in the comments that my question is equivalent to asking why the map $H_m(S_m)\rightarrow H_m(S^m,S^m\setminus x)$ is surjective. Why is that equivalent to my question? I would also be happy with a reference.","['orientation', 'manifolds', 'general-topology', 'homology-cohomology', 'algebraic-topology']"
4781295,"If $a_1=1, a_n=|\cot a_{n-1}|$, then what is $\lim\limits_{n\to\infty}\text{median}\{a_1,a_2,\dots,a_n\}$?","I made up the following sequence: $a_1=1, a_n=|\cot a_{n-1}|$ . What is $\lim\limits_{n\to\infty}\text{median}\{a_1,a_2,\dots,a_n\}$ ? My thoughts Here is the graph of $a_n$ against $n$ , for $1\le n \le 25$ . Using Excel, we have $\text{median}\{a_1,a_2,\dots,a_{100}\}\approx 1.107$ $\text{median}\{a_1,a_2,\dots,a_{1000}\}\approx 1.172$ $\text{median}\{a_1,a_2,\dots,a_{10000}\}\approx 1.204$ $\text{median}\{a_1,a_2,\dots,a_{20000}\}\approx 1.201$ It seems that the median converges to something like $1.2$ . Here are the graphs of $y=|\cot x|$ and $y=x$ . We start at $(1, |\cot 1|)$ , then go horizontally to the line $y=x$ , then go vertically to the curve $y=|\cot x|$ , then go horizontally to the line $y=x$ , etc. Among the points that we meet on the curve $y=|\cot x|$ , apparently (based on Excel) about half of them are below the line $y=1.2$ . Note: If we change $a_n$ from $1$ to any other non-zero integer, the median seems to converge to the same number, approximately $1.2$ .","['median', 'ergodic-theory', 'recurrence-relations', 'sequences-and-series', 'trigonometry']"
4781349,Exercise 4.4 (b) for Isaacs' Character Theory of Finite Groups,"The exercise is as follows: Let $G = HK$ be a finite group, with $H \subset C_G(K)$ . Let $\rho \in \operatorname{Irr}(H)$ and $\psi \in \operatorname{Irr}(K)$ be such that $\rho \mid_{H\cap K}$ and $\psi\mid_{H\cap K}$ share an irreducible constituent. Prove that there exists a unique $\chi \in \operatorname{Irr}(G)$ such that $\chi \mid_H = \psi(1)\rho$ and $\chi \mid_K = \rho(1) \psi$ . My attempt Let $\phi: H \times K \to G$ be such that $\phi(h, k) = hk$ . It's clear that $\phi$ is a surjective homomorphism. In particular, if $N = \ker \phi = \{(h, h^{-1}) \mid h \in H \cap K\}$ , we can identify $G$ with a quotient of the direct product, meaning we can use lifting to obtain the character $\chi$ ; that is to say, the desired character will be induced by an irreducible character of $H \times K$ with $N$ contained in its kernel. Any irreducible character of $H \times K$ is of the form $\alpha \times \beta$ , for $\alpha \in \operatorname{Irr}(H)$ and $\beta \in \operatorname{Irr}(K)$ . And $N \subset \ker (\alpha \times \beta)$ iff $\alpha(h)\beta(h^{-1}) = \alpha(1)\beta(1)$ for all $h \in H \cap K$ . This is, in turn, equivalent to saying $\alpha(h) = m \omega_h$ and $\beta(h) = n \omega_h$ , for some $o(h)$ -root of unity $\omega_h \in \mathbb{C}$ , for each $h \in H \cap K$ . The existence would be established, then, if we could prove $N \subset \ker (\rho \times \psi)$ . Since they have a common constituent, we know: $$ \langle \rho \mid_{H \cap K}, \psi \mid_{H \cap K} \rangle = \frac{1}{|H \cap K|} \sum_{h \in H \cap K} \rho(h)\psi(h^{-1}) \neq 0$$ If we knew $N \subset \ker(\rho \times \psi)$ , then the above sum would reduce to $\rho(1)\psi(1)$ . At the same time, since $H \cap K$ is abelian, $\rho(1)$ is the number of irreducible constituents of $\rho \mid_{H \cap K}$ . So $\rho$ and $\psi$ have $\rho(1)\psi(1)$ constituents in common, while $\rho$ has $\rho(1)$ constituents. This means $\psi(1) = 1$ . The same logic applied to $\psi$ yields $\rho(1) = 1$ , meaning $\rho \mid_{H \cap K} = \psi \mid_{H \cap K}$ . If we knew $\rho \mid_{H \cap K} = \psi \mid_{H \cap K}$ and $\rho(1) = 1$ , in turn , we'd get $\rho(h)\psi(h^{-1}) = \rho(hh^{-1}) = \rho(1) = 1 = \rho(1)^2$ , for all $h \in H \cap K$ , implying $N \subset \ker(\rho \times \psi)$ . So the two statements are actually equivalent, and it suffices to show the latter. This is where I get completely stuck. I'm not quite sure if there's a mistake in the above reasoning, but it seems farfetched to obtain that the two characters are both equal in $H \cap K$ and linear just from the fact that they share a constituent... Any help is greatly appreciated! Thanks in advance!","['group-theory', 'abstract-algebra', 'finite-groups', 'characters']"
4781484,"If $x_n \to c$ and and $f(x_i)=f(c)$, then all the derivatives at $a$ vanish","My book claims the following Let $x_n \in (a,b)\setminus\{c\}$ be a sequence that converges to $c \in (a,b)$ . If $f: (a,b) \to \mathbb{R}$ satisfies that $f(x_i)=f(c)$ for all $i$ , then all the derivatives at $c$ that exist vanish. This seems right, but I haven't been able to prove it, the book just says that it follows from Taylor's formula. What's a proof of this, preferably using Taylor's formula? What I tried is use the formula on the $f(x_i)$ , so we get that we have a sequence $h_n=x_n - c$ with $h_n \to 0$ and $$f(x_k)=f(c+h_k)=\sum^n_{i=0}\frac{f^{(i)}(c)}{i!}h^i_k+r(h_k)=f(c)$$ Making $k$ go to infinity doesn't seem to accomplish anything, yet there doesn't seem like there's more to do with the data available.","['derivatives', 'taylor-expansion', 'real-analysis']"
4781488,geometry problem involving a half equilateral triangle and its angle bissector - can it be solved without coordinate geometry?,"Triangle $ ABC $ , has $ \angle ACB = 60^{\circ} $ . The point $ E $ lies on $ AB $ such that $ CE $ bisects $ \angle ACB $ . The point $ D $ lies on $ BC $ such that $ AD \perp BC $ . The point $ F $ lies on $ AC $ such that lines $ AD $ , $ CE $ and $ BF $ are concurrent at a point $ O $ . Lines $ EF $ and $ AD $ intersect at $ G $ . Line $ BG $ is extended and a point $ K $ lies on it such that $ AK \perp BK $ . How can we prove that $ |BK|^2 = |BD|^2 + |DK|^2 + 2 |AK|^2 $ ? There is a solution using coordinate geometry to this here . It uses coordinate geometry to establish that $ |AG| = |DG| $ i.e. $ G $ is the midpoint of $ AD $ , and from there, 'normal' geometry techniques (trig, angle theorems etc) can be used to finish it off. My question is, can we find a proof of this using only 'normal' geometry? My thoughts: I spent a while on this and couldn't do it. I wondered if maybe this problem is linked to the famously hard Langley's adventitious angles type of problem, usually requiring a difficult-to-spot construction. I can spot two potentially 'adventitious quadrangles' in this problem - $ BEFC $ and $ AKBD $ . However, these kinds of problems can also be solved with the trigonometric Ceva's theorem, which I tried with no success on this occasion. I'm also familiar with things like the angle bisector/midpoint/Appolonius'/Stewart's/Menelaus'/Ceva's two theorems, but couldn't make it work with any of them. In addition to the sine/cosine rules, a solution using these techniques is what I'm looking for. Thanks.","['euclidean-geometry', 'triangles', 'geometry']"
4781504,What is the conventional notation for a function that returns 2 dissimilar items?,"I see similar questions here and here but they do not answer my question. The backstory is a little complicated but short version is I have a function $f(\cdots)$ that effectively returns 2 dissimilar results, a scalar $x$ and a vector $\mathbf{y}$ .  I do not mean there are multiple possible solutions as in e.g. polynomial root solving.  I mean $f(\cdots)$ produces $x$ and if you have $x$ you have a unique value for $\mathbf{y}$ .  The long way to write this out would be $$ x=f(\cdots) \\ \mathbf{y}=g(x,\cdots)$$ but I don't want to break this out into 2 stages and I do not want to stack them into a vector like this $$ \begin{bmatrix}x\\\mathbf{y} \end{bmatrix}=f(\cdots). $$ I would like something like $$ x,\mathbf{y}=f(\cdots) $$ to denote that $x$ and $\mathbf{y}$ are a matched set. Is there common notation to convey this?","['notation', 'functions', 'linear-algebra']"
4781614,Convergence of series with terms $\frac{\ln(n)}{n^2}$,"So, I'm currently a TA for a calculus class, and I came across the following problem: Use the limit comparison test to determine that $$\sum_{n=1}^\infty \frac{\ln(n)}{n^2}$$ converges (I'm currently grading this exact problem on an exam students have already taken). I didn't initially think this was a problem since I was thinking they could compare this series with a series whose terms are $b_n = n^{-3/2}$ , but the issue is that the version of the limit comparison test that students learned in this class required having $$0< \lim_{n \to \infty} \frac{a_n}{b_n} < \infty$$ so that $\sum a_n$ converges $\iff \sum b_n$ converges. I've been trying to find an appropriate choice of $b_n$ for awhile now given the strict lower bound on the limit, but I haven't had any success. Would anyone happen to have any suggestions? Is this even possible? I will say none of the students in the class of $130+$ have provided a convincing answer, and I can see the difficulty myself haha.","['limits', 'calculus', 'convergence-divergence', 'sequences-and-series']"
4781633,"Find $f(x)$ : $ f'(x) = f(x)^2 + f^{-1}(x) + \int_{x}^{-\infty} \frac{e^t}{t} \, dt $","\begin{align}
f'(x) &= f(x)^2 + f^{-1}(x) + \int_{x}^{-\infty} \frac{e^t}{t} \, dt
\end{align} How to find $f(x)$ What i do so far \begin{align} f'(x) &= f(x)^2 + f^{-1}(x) + \int_{x}^{-\infty} \frac{e^t}{t} , dt \end{align} \begin{align} (f^{-1})'(x) &= \frac{1}{f'(f^{-1}(x))} \end{align} \begin{align} f'(x) &= f(x)^2 + \frac{1}{f'(f^{-1}(x))} + \int_{x}^{-\infty} \frac{e^t}{t} , dt \end{align} u = f(x): \begin{align} u &= f(x) \ f'(x) &= \frac{du}{dx} \end{align} \begin{align} \frac{du}{dx} &= u^2 + \frac{1}{f'\left(f^{-1}(u)\right)} + \int_{x}^{-\infty} \frac{e^t}{t} , dt \end{align} \begin{align}\frac{du}{dx} &= u^2 + \frac{1}{f'\left(f^{-1}(u)\right)} - \frac{e^x}{x} \end{align}","['ordinary-differential-equations', 'inverse-function', 'solution-verification', 'derivatives', 'exponential-function']"
4781635,Very Sparse Graphs are Far from Regular,"I am trying to prove the following statement: Consider a random graph $G \sim G(n, p)$ with expected degrees $d = O(1)$ . Show that with high probability, (say, $0.9$ ), $G$ has a vertex with degree $$
\Omega\left( \frac{\log{n}}{\log{\log{n}}} \right).
$$ This exercise appears in the application of Chernoff's inequality chapter from High-Dimensional Probability by Roman Vershynin. Chernoff's Bound for upper tail : Let $X_i$ be independent Bernoulli r.v. with parameter $p_i$ . Consider the sum $S_n = \sum_{i= 1} ^N X_i$ and $\mu = \mathbb{E}S_N$ . Then for any $t > \mu$ , we have $$
\mathbb{P}\{ S_N \geq t \} \leq e^{-\mu}\left( \frac{e\mu}{t} \right)^t.
$$ Chernoff's Bound for lower tail : Let $X_i$ be independent Bernoulli r.v. with parameter $p_i$ . Consider the sum $S_n = \sum_{i= 1} ^N X_i$ and $\mu = \mathbb{E}S_N$ . Then for any $t < \mu$ , we have $$
\mathbb{P}\{ S_N \leq t \} \leq e^{-\mu}\left( \frac{e\mu}{t} \right)^t.
$$ Reverse Chernoff Bound: If $S_N$ is a Binomial r.v. with mean $\mu$ , then $$
\mathbb{P}\{ S_N \geq t \} \geq e^{-\mu}\left( \frac{\mu}{t} \right)^t, \ \ \ \forall t \geq \mu.
$$ My Attempt: We wish to show there exists some $C > 0$ such that $$
\mathbb{P}\{ \exists i \leq n: d_i \geq C\frac{\log{n}}{\log{\log{n}}} \} \geq 0.9.
$$ Since the graph is very sparse, we can assume with high probability that some subgraph has independent degrees. Therefore, the question is equivalent to showing $$
\mathbb{P}\{ \forall i \leq n: d_i < C\frac{\log{n}}{\log{\log{n}}} \} = \prod_{i = 1} ^n \mathbb{P}\{ d_i < C\frac{\log{n}}{\log{\log{n}}} \} \leq 0.1.
$$ This is really where I got stuck and can't seem to unstuck myself from. I want to use the Chernoff's bound to somehow bound this product, but since $n$ can be large, the Chernoff lower bound doesn't necessarily apply here. It is then natural to me to use the reverse Chernoff bound: $$
\mathbb{P}\bigcup_{i = 1} ^n \{ d_i < C\frac{\log{n}}{\log{\log{n}}} \} = \prod_{i = 1} ^n (1 - \mathbb{P}\{ d_i \geq C\frac{\log{n}}{\log{\log{n}}} \}).
$$ In particular, if we can show $(1 - \mathbb{P}\{ d_i \geq C\frac{\log{n}}{\log{\log{n}}} \}) > 0$ using the reverse Chernoff bound, then the result will be true for large enough $n$ . This prompts me to do the following estimate: \begin{align*}
\mathbb{P}\{ d_i \geq C \frac{\log{n}}{\log{\log{n}}} \} \geq e^{-d}\left( \frac{d}{C\frac{\log{n}}{\log{\log{n}}}} \right)^{C\frac{\log{n}}{\log{\log{n}}}}.
\end{align*} But I am not sure how one can show this is greater than $0$ when $n \to \infty$ . Any suggestions?","['random-graphs', 'graph-theory', 'analysis', 'probability-theory', 'probability']"
4781658,When does this iterated logarithm series converge / diverge?,"Question: Let $b > 1$ be a positive real, let $\ell_b(n) = \max(1, \lfloor \log_b n \rfloor)$ , and let $f_b(n) = n \ell_b(n) \ell_b^2(n) \dots $ (where we iterate $\ell_b$ until we hit $1$ ). For what values of $b$ does the series $$\sum_{n=1}^{\infty} \frac{1}{f_b(n)}$$ converge or diverge? This previous question asks about the case $b = 10$ . There I gave an argument which shows that the series diverges for all $b > e$ . I thought I had convinced myself awhile ago that this series ought to diverge for all $b > 1$ but surprisingly the argument does not show it; actually it suggests that the series converges for $b < e$ and it's unclear what happens if $b = e$ . My motivation is the same as Alan's in the linked question: this is an interesting test of the limits of common convergence tests. The integral test or Cauchy condensation shows that the analogue of this series where we only iterate $\ell_b(n)$ a fixed number of times diverges for any $b > 1$ but that argument doesn't work here. Actually Cauchy condensation produces nearly the same series again, which is basically the idea I use in my argument in the linked question.","['logarithms', 'sequences-and-series']"
4781671,What is the relationship between Hölder spaces and differentiability?,"Let $C^{k,\alpha}$ be a Hölder space where $0 \leq \alpha \leq 1$ . I have seen various sources informally describe these spaces as functions having at least "" $k + \alpha$ "" derivatives. How does some sense of fractional differentiability follow from the definition of the Hölder norm?","['real-analysis', 'functional-analysis', 'fractional-calculus', 'derivatives', 'holder-spaces']"
4781674,8 Drawer Desk Conditional Probability Problem: Use Bayes' Theorem using the given statement,"A desk has eight drawers. There is a probability of 1/2 that someone placed a letter in one of the desk's eight drawers and a probability of 1/2 that this person didn't place a letter in any of the desk's eight drawers. You open the first 7 drawers and find that they are all empty. What is the probability that the 8th drawer has a letter in it? This answer makes use of a slightly different Event A while this answer takes advantage of $P(A \cap B)$ . I want to use the alternative form $P(A) * P(B|A)$ instead. This answer touches on the other part of the disjoint equation in the denominator that I am trying to figure out. Here is what I have so far: Let $A$ denote the event in which there is a letter in the 8th drawer. Let $B$ denote the event in which the first 7 drawers are all empty. Then $P(A|B) = \frac{P(A) * P(B|A)}{P(B)}$ $P(A) = \frac{1}{2} * \frac{1}{8}$ since there's a 1/2 chance that there's a letter in the drawers and only 1 of the 8 possible scenarios is there a letter in the 8th drawer. $P(B) = P(B|A)*P(A) + P(B|A')*P(A')$ - This means the probability of having the first seven drawers empty is equal to: The probability that the first seven drawers are empty given that the
letter is in the 8th drawer $P(B|A)$ times the probability that the
letter is in the 8th drawer $P(A)$ PLUS The probability that the first seven drawers are empty given that the letter is NOT in the 8th drawer $P(B|A')$ times the probability that the letter is NOT in the 8th drawer $P(A')$ $P(B|A)$ = 1 since if it's in the 8th drawer, the other seven have to be empty since there's only one letter. $P(A)$ was already calculated as $\frac{1}{2} * \frac{1}{8}$ $P(B|A')$ = unsure $P(A')$ = $(\frac{1}{2} * \frac{7}{8}) + \frac{1}{2} * 1$ (I think this is true - 1/2 of the time we will be in the letter state and there will be 7 out of 8 states in which the letter is not in the 8th spot). The other 1/2 of the time when there is no letter, it will be 8/8 times that the letter is not in the 8th spot. I am focused on filling in the gaps on this specific method. There are other elegant solutions that I understand, but this is how I've been solving other Baye's Theorem problems, so I want to solidify my understanding by pointing out where I went wrong or how I can count $P(B|A')$ Judging by the correct answers, if everything I wrote is correct, then $P(B|A')$ has to be 8/15, but what does 8/15 represent? Also, I wouldn't know what this is beforehand, so I'd like to know how to calculate this.","['statistics', 'bayes-theorem', 'probability']"
4781749,A lemma in the application of Concentration compactness principle in Hardy-Littlewood-Sobolev inequality,"I'm encountering some problems when reading Lions' paper ""the concentration-compactness principle in the calculus of variations. The limit case, Part 2"". The Hardy-Littlewood-Sobolev (HLS) inequality is stated as $$
\| K*u\|_q\le C\|u\|_p
$$ where $K=|x|^{-\lambda}$ and $1<p<q<\infty, 0<\lambda<n, \tfrac 1p+\tfrac \lambda n=1+\tfrac 1q$ . When proving the existence of maximizers of HLS inequality, he used his second concentration compactness principle. (Lemma2.1) Let $u_n$ converge weakly in $L^p(\mathbb R^n)$ to $u$ and assume $|u_n|^p$ is tight. We may assume without loss of generality that $|K*u_n|^q$ , $|u_n|^p$ converge weakly (or tightly) in the sense of measure to some bounded nonnegative measures $\nu, \mu$ on $\mathbb R^n$ . Then we have: there exist some at most countable set (possibly empty) and two families $(x_j)_{j\in J}$ of distinct points in $\mathbb R^n$ , $(\nu_j)_{j\in J}$ in $(0,\infty)$ such that: $$ \nu=|K*u|^q+\sum_{j\in J}\nu_j\delta_{x_j}$$ where $K$ is the kernel $|x|^{-\lambda}$ . To prove this lemma (lemma 2.1 in his paper), he cited his another lemma in his paper ""the concentration-compactness principle in the calculus of variations. The limit case, Part 1"" (Lemma 1.2) Let $\mu,\nu$ be two bounded nonnegative measures on $\mathbb R^n$ satisfying for some constant $C_0\ge 0$ $$\left(\int_{\mathbb R^n} |\varphi|^qd\nu\right)^{1/q}\le C_0 \left( 
 \int_{\mathbb R^n} |\varphi|^pd\mu\right)^{1/p}~~~~\text{for any}~\varphi\in C_c^\infty(\mathbb R^n)\tag 1$$ In order to get the inequality (1). After some progress, we can assume that $u=0$ , i.e., $u_n\to 0$ weakly in $L^p$ . And he showed that we only need to estimate an upper bound of (See the page 51 of his paper) $$
v_n(x)=\left|\int_{|y|\le R}\cfrac{\varphi(y)-\varphi(x)}{|x-y|^\lambda}u_n(y)dy       \right|
$$ He wrote ' Denoting by $R(x,y)=(\varphi(y)-\varphi(x))|x-y|^{-\lambda}$ and observing that $R(x,y) 1_{|y\le R}\in L^r(\mathbb R^n)$ for each $x$ where $r<\frac{n}{\lambda-1}$ if $\lambda>1$ , $r\le \infty$ if $\lambda \le 1$ , we see that: $v_n\to 0$ a.e. on $\mathbb R^n$ '. My question: 1 . It seems that we cannot get that $R(x,y)1_{|y|\le R}\in L^{p'}$ for a.e. $x\in \mathbb R^n$ if we only have $R(x,y)1_{|y|\le R} \in L^r$ . Thus we can not use the assumption that $u_n\to 0$ weakly in $L^p$ . I am wondering whether I missed some other important information in his proof and note that if $R(x,y)1_{|y|\le R}$ is not in $L^{p'}$ , we don't know whether $v_n$ exists. 2 . It seems that we do not need the statement about ' $R(x,y)1_{|y|\le R}$ '. In his beginning, he got $K*u_n \to K*u$ a.e.. Since $u=0$ , we have $$
\int \cfrac{u_n(y)}{|x-y|^{\lambda}}dy\to 0 ~~~a.e.~x\in \mathbb R^n
$$ and hence $$
|v_n|\le 2\|\varphi\|_\infty \int \cfrac{u_n(y)}{|x-y|^{\lambda}}dy \to 0.
$$ (We can take $u_n$ as nonnegative sequence since $|u_n|$ is also a maximizing sequence) Does my way work? Thanks in advance . Thanks for your attention and I hope you can help me with this.","['concentration-of-measure', 'functional-inequalities', 'weak-convergence', 'real-analysis']"
4781790,Does $\mathbb{E}\left[\frac{X}{X+Y}\right]\le \frac{\mathbb{E}[X]}{\mathbb{E}[X+Y]}$ hold?,"Assume that two random variables $X$ and $Y$ satisfy $X\ge 0$ , $Y\ge0$ and $X+Y\ge 1$ . Does it hold that $$\mathbb{E}\left[\frac{X}{X+Y}\right]\le \frac{\mathbb{E}[X]}{\mathbb{E}[X+Y]},$$ whereby $\mathbb{E}[\cdot]$ denotes the expected value? Jensen's inequality may be helpful, but I don't know how to apply it here. I want to add the additional condition that X increases if X+Y increases.","['expected-value', 'statistics', 'probability', 'inequality']"
4781798,"Need an intuitive example for how ""P is necessary for Q"" means ""Q$\implies$P""?","I am confused about how ""P is necessary for Q"" means ""Q $\implies$ P"" (source: Kenneth Rosen DMGT). Intuitively, I interpret ""P is necessary for Q"" as ""for Q to happen, P must happen"", which I basically feel is equivalent to ""if P happens then Q must occur"", i.e, ""P $\implies$ Q"". Could someone correct my understanding?","['propositional-calculus', 'logic', 'discrete-mathematics', 'computer-science']"
4781885,Applications of Measure Theory in Set Theory,"Today my question is a bit generic. I'm interested in facts about set theory that need some kind of measure-theoretic knowledge to be proven, for example the covering theorem, the Radon-Nikodym theorem, the Lebesgue density theorem... For example, I know that, if $\mathbb P$ is the poset of subsets of $(0,1)$ having positive Lebesgue measure, that is a partial order that is very useful in set theory to do forcing, then it is $\sigma$ -linked. The only proof I know of this fact, that can be found here: Positive Lebesgue measure Poset - $\sigma$-linked , uses deeply the Lebesgue density theorem. I really like this result since I'm a set theorist that is also sometimes interested in analysis and measure theory, so I'm looking for more results of this kind to look at how deeply these subjects are connected. Thank you all in advance!","['measure-theory', 'set-theory']"
4781892,Kurzweil-Stellmacher. The Theory of Finite Groups. Exercise 1.1.13 hint request,"I'm afraid I would need a hint to solve the following Exercise 13: Let $G$ be a finite group and $A$ a subgroup. If $\{A^x\mid x\in G\} = \{A_1, \dots, A_n\}$ then $\langle A_1, \dots, A_n\rangle = A_1\cdots A_n$ . My attempt: Re-write $A_{\sigma(1)}\cdots A_{\sigma(n)}$ as a conjugate of $A_1\cdots A_n$ . Note: As indicated in the title, the exercise appears in the first section of the book, before the concepts of homomorphism and normal subgroup have been presented. At this point, the reader is only familiar with the definitions of group and subgroup, the Lagrange theorem, the $HK=KH$ condition, and transversal sets. A previous exercise shows that the union of all conjugates of a proper subgroup is a proper subset of the group. Another, that $G=AA^g\implies G=A$ . Information: Someone provided me with an approach using Character Theory. However, the expectation is for an elementary argument.","['group-theory', 'finite-groups']"
4781897,Roots of the polynomial involving trigonometric function,"Given $$f(x)=a_0+a_1\cos x+a_2\cos2x+\cdots+a_n\cos nx$$ where $a_0,a_1,a_2,\cdots,a_n$ are non-zero reals such that $a_n>|a_0|+|a_1|+\cdots+|a_n-1|$ then how many roots of $f(x)=0$ are there in $0\le{x}\le{2\pi}$ ?
I have tried to check the conditions for lower power equations. For $a_0+a_1\cos x=0$ there are two roots and for $a_0+a_1\cos x+a_2\cos 2x=0$ I am getting four roots. After this I tried to use induction on the equation but could not find any possible way to solve the problem. So how can we approach this type of problem?","['trigonometry', 'combinatorics', 'polynomials']"
4781918,Game on guessing which is larger between two random number from 0 to 1,"Alice and Bob are playing a game. Each time, two numbers are generated uniformly in the interval $[0,1] $ , Alice can see the two numbers and choose one to tell Bob. And Bob needs to determine whether it's the larger one. Bob wins if he is correct, otherwise, Alice wins. Alice and Bob's strategies can be represented as functions. $ F : [0,1]^2 \rightarrow [0,1]$ for Alice, and $f:[0,1] \rightarrow [0,1]$ for Bob. It means that when Alice is told two numbers $p$ and $q$ , she has probability of $F(p,q)$ to tell Bob number $p$ . When Bob is told number $p$ , he has probability of $f(p)$ to guess $p$ is bigger. Then for given $(p,q)$ , the probability for Bob to win is $$\Phi (p,q) = \left\{
\begin{array}{ll}
    F(p,q)f(p)+(1-F(p,q))(1-f(q))  &\text{if } p > q \\
    F(p,q)(1-f(p))+(1-F(p,q))f(q) & \text{if } p < q \\
\end{array}
\right.$$ And $$E = \int \int_{[0,1]^2} \Phi (p,q) dp dq$$ is the expection for Bob to win. It's not hard to know that if Bob takes $$f= \left\{ 
\begin{array}{ll}
    1  &\text{if } p > \frac 1 2 \\
    0 & \text{if } p < \frac 1 2 \\
\end{array}
\right.$$ There will always be $E \ge \frac 1 2$ , i.e. $f$ guarantees Bob's not losing (in long term). I want to know whether the game is fair(Alice also has a not -losing strategy), namely, there exists an $F$ , s.t. for any $f$ , $E \le \frac 1 2$ . If not, I also want to know whether the following is true. For any $f$ , there exists an $F$ , s.t. $E \le \frac 1 2$ . (Alice still has a chance not to lose).","['game-theory', 'probability']"
4781942,Conjecture: If $a_1\in\mathbb{Z}$ and $a_n=\sec (a_{n-1})$ then the proportion of positive terms approaches $\frac{1}{\sqrt{2\pi}}$ as $n\to\infty$.,"I made up the following family of sequences: $a_1\in\mathbb{Z}$ and $a_n=\sec (a_{n-1})$ for $n>1$ . I conjecture that, for any $a_1\in\mathbb{Z}$ , the proportion of positive terms approaches $\frac{1}{\sqrt {2\pi}}$ as $n\to\infty$ . Is my conjecture true? Evidence for my conjecture For $a_1=1$ , here is the graph of $a_n$ against $n$ for $1\le n \le 25$ . Using Excel, it seems that, the proportion of positive terms approaches a limit as $n\to\infty$ , and the limit is independent of the value of $a_1$ . I found that, for $a_1=1, 2, 3, \dots, 25$ , among the first $10000$ terms, the average proportion of positive terms is $0.398940$ , which is very close to $\frac{1}{\sqrt {2\pi}}\approx 0.398942$ . Another look at the sequence Here are the graphs of $y=\sec x$ and $y=x$ . We start at $(1,\sec 1)$ , then go horizontally to the line $y=x$ , then go vertically to the curve $y=\sec x$ , then go horizontally to the line $y=x$ , etc. Among the points that we meet on the curve $y=\sec x$ , about $0.39894$ of them are above the $x$ -axis.","['conjectures', 'ergodic-theory', 'recurrence-relations', 'sequences-and-series', 'trigonometry']"
4781970,Show that $x<\dfrac{\sqrt [8]{128}}{2}$,"Exercise. The polynomial equation $x^{19}+2x^{17}+x^{15}-x^{2}+x-1=0$ has exactly one positive real root. Show that $x<\dfrac{\sqrt [8]{128}}{2}$ . My attempt The upper bound is quite sharp. $x<\dfrac{\sqrt [8]{128}}{2}\approx 0.91700404321...$ According to WolframAlpha $x\approx 0.91700324071...$ So the difference is $\approx 0.0000008025$ I wanted to proceed by assuming $x=\dfrac{\sqrt [8]{128}}{2}-\epsilon$ for some $\epsilon>0$ . The expansions are so tedious .
Can I get a result from here by plugging $x=\dfrac{\sqrt [8]{128}}{2}-\epsilon$ instead of $x$ ? That is $ \bigg(\dfrac{\sqrt [8]{128}}{2}-\epsilon\bigg)^{19}+2\bigg(\frac{\sqrt [8]{128}}{2}-\epsilon\bigg)^{17}+\bigg(\frac{\sqrt [8]{128}}{2}-\epsilon\bigg)^{15}-\bigg(\frac{\sqrt [8]{128}}{2}-\epsilon\bigg)^{2}+\frac{\sqrt [8]{128}}{2}-\epsilon-1=0 $ My idea is showing that $\epsilon>0$ by opening the parentheses using Binomial theorem.  Am I on the right track ?","['contest-math', 'algebra-precalculus', 'inequality', 'real-analysis']"
4781987,What the set $D=\{|\sigma(x+1)-\sigma(x)||x\in\mathbb{Z}\}$ could be?,"Let $\sigma$ be a permutation of $\mathbb{Z}$ such that the set $D=\{|\sigma(x+1)-\sigma(x)||x\in\mathbb{Z}\}$ is finite. What the set $D$ could be? Let $d$ be the greatest common divisor of all elements of $D$ , then by induction we easily have that $\sigma(x)\equiv \sigma(0) (mod\;d),\forall x\in\mathbb{Z}$ , because $\sigma$ is a permutation we must have $d=1$ , so the all elements of $D$ are coprime. We have: If $|D|=1$ , then $D$ must be $\{1\}$ , we just take the identity permutation. If $|D|=2$ , then $D=\{a,b\}$ such that $gcd(a,b)=1$ . Let $c=a+b$ , we have $gcd(c,a)=1$ . We build the permutation $\sigma$ as follow: For $x\in\mathbb{Z}$ , we write $x=cq+r,q,r\in\mathbb{Z},0\leq r<c$ . We choose the unique $s\in\mathbb{Z}$ such as $ar\equiv s(\mod\;c)$ and define $\sigma(cq+r)=cq+s$ . Because $gcd(c,a)=1$ so $\sigma$ is a permutation. By the construction we have $\sigma(x+1)-\sigma(x)\equiv a(mod\;c),|\sigma(x+1)-\sigma(x)|<c$ so either $\sigma(x+1)-\sigma(x)=a$ or $\sigma(x+1)-\sigma(x)=-b$ , so we have $D=\{|\sigma(x+1)-\sigma(x)||x\in\mathbb{Z}\}$ as we want. I don't know how to deal with the case $|D|>2$ since the trick for $|D|=2$ does not work in this case in general.","['permutations', 'number-theory', 'elementary-number-theory']"
4781996,Possible group operations on a finite set,"Suppose $X=\{x_1, x_2, \ldots, x_n\}$ is a finite set of $n$ elements. I learned that there are $n^{n^2}$ binary operations $*:X\times X \to X$ and $n^{n(n+1)/2}$ of them are commutative. I was wondering how many of them are associative. I came across this post ; there's a very complicated formula in terms of $n$ . As it was discussed there, a semi-group being a set with associative binary operation, its easy to see that ""number of associative binary operations on $X$ "" is equal to ""the number of distinct non-isomorphic semi-groups of order $n$ "". How many binary operations $*$ are there on $X$ such that $(X,*)$ is a group? Let's denote this by $c(n)$ . I looked online to find if there's an explicit formula for $c(n)$ . I couldn't find anything. $c(n)$ is not equal to the number of distinct non-isomorphic groups of order $n$ because it is possible that there are group operations $\circ_1\neq \circ_2$ for which $(X,\circ_1) \cong (X,\circ_2)$ . However, intuitively, I feel that $\circ_1$ and $\circ_2$ are basically somehow rearrangements of each other. I apologise, I am unable to explain. I kind of believe that $\frac{c(n)}{n!}$ is equal to number of distinct non-isomorphic groups of order $n$ . Is this correct ? If not, is there any way to avoid counting operations like $\circ_1$ and $\circ_2$ more than once and hence relate $c(n)$ to the number of distinct non-isomorphic groups of order $n$ ?","['binary-operations', 'group-theory', 'set-theory']"
4782061,Mathematical proof for the following infinite double summation.,"In this Physics Stack Exchange post , I detailed my discovery of the following equation $$\sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\frac{(-1)^{i+j}}{(2i+1)(2j+1)\cosh\left(\frac{\sqrt{(2i+1)^2+(2j+1)^2}\pi}{2}\right)} = \frac{\pi^2}{48},$$ through solving a physics problem in two different ways. Question: I was wondering if there exists any other proof of this equation, that is more 'mathematical'? Here, I mean 'mathematical', in the sense that it does not delve into the physical context of a specific problem as done in the post, but rather relies on theorems of pure mathematics to prove the result.","['physics', 'mathematical-physics', 'sequences-and-series']"
4782064,Connected subset of $\Bbb R^2$ that disconnects with countable points removed.,"I am asked to find a subset $A$ of $\Bbb R^2$ with the following property: $(1).$ $A$ is connected. $(2).$ $A-F$ is connected if $F$ is finite. $(3).$ $A-C$ is disconnected for some countably infinite subset $C\subset A$ . I am beginning this problem with an attempt of setting $A=\{(x,y):x\in\Bbb Q\text{ or }y\in\Bbb Q\}$ . I am guessing $A-\Bbb Q^2$ is disconnected. In fact, intuitively $A-\Bbb Q^2$ is totally path-disconnected: there could be no path connecting any of the two distinct points in $A-\Bbb Q^2$ . Can we deduce $A-\Bbb Q^2$ is disconnected from here? Fun fact: such space is not homeomorphic to $\Bbb R^2$ as removing countably many points in $\Bbb R^2$ doesn’t affect connectedness.","['general-topology', 'geometry', 'connectedness']"
4782078,When is sufficiency and completeness of a statistic preserved?,"I have been given these definitions in my statistical inference class: Let $(X_1,...,X_n)$ be a simple random sampling of $X\rightarrow\{P_\theta:\theta \in \Theta\}$ and $T\equiv T(X_1,...,X_n)$ a statistic. We say that $T$ is sufficient for $\theta$ if the conditional distribution of $(X_1,...,X_n)$ to each value of $T$ is independent of $\theta$ ( $\theta$ does not appear). $T$ is complete if for every unidimensional measurable function $g$ $$
E_\theta[g(T)]=0 \ \forall \theta \in \Theta \Rightarrow P_\theta[g(T)=0]=1 \ \forall \theta \in \Theta
$$ I'm interested in knowing under what functions sufficiency and completeness are preserved.
I already know that if $T$ is sufficient for $\theta$ and $T=f(U)$ then U is sufficient for $\theta$ , and therefore, if $f$ is biyective, $T'=f(T)$ is also sufficient. However, we haven't seen any properties for completeness and I have done the following: Let $T$ be a complete statistic, and $T'=f(T)$ with $f$ measurable. Then $T'$ is complete. I proceed as follows: Let $g$ be an unidimensional and measurable function such that $E_\theta[g(T')]=0 \ \forall \theta \in \Theta$ . Then $E_\theta[g(f(T))]=0 \ \forall \theta \in \Theta$ and by completeness of $T$ , $P_\theta[g(f(T))=0]=1 \ \forall \theta \in \Theta$ , so $P_\theta[g(T')=0]=1 \ \forall \theta \in \Theta$ and $T'$ is complete. I wasn't told what ""measurable"" means in the definitions, but I guess it is borel measurable (so that $g\circ f$ is borel measurable and the previous line makes sense). Is this last result correct? If $T$ is sufficient and complete and $f$ is biyective and measurable, can I conclude that $T'=f(T)$ is also sufficient and complete?","['statistical-inference', 'statistics', 'solution-verification', 'sufficient-statistics']"
4782093,"Evaluating $\lim_{x\to\pi/6}\frac{2\cos(ax)-\sqrt3}{\pi-6x}$, for positive integer $a$ satisfying $\cos(a\pi/6)=\sqrt{3}/2$ and $\cos(t+ab)=\cos(t+b)$","Let $a$ be a positive integer such that $\cos\left(\frac{a\pi}{6}\right)=\frac{\sqrt{3}}{2}$ and $\cos(\theta+a\cdot\beta)=\cos(\theta+\beta)$ For any $\theta,\beta \in \mathbb{R}$ . Calculate $$
    \lim_{x\to\pi/6}\frac{2\cos(ax)-\sqrt{3}}{\pi-6x}
$$ Proof. For $\cos\left(\frac{a\pi}{6}\right)=\frac{\sqrt{3}}{2}$ . We have the following table. $\cos(x)$ table of periodic values with $2n\pi$ intervals. Be $\frac{a\pi}{6}=\frac{\pi}{6}+2\pi n$ , for $n\in \mathbb{N}$ . Hence $a=1+12n$ , for $n\in \mathbb{N}$ . Taking this into account, let us assume that it is $a=1+12(0)=1$ , so $$\lim_{x\to\pi/6}\frac{2\cos(x)-\sqrt{3}}{\pi-6x} \tag1$$ $$\lim_{x\to\pi/6}\frac{\sqrt{3}-2\cos(x)}{6x-\pi} \tag2$$ By applying L’Hopital $$\lim_{x\to\pi/6}\frac{(\sqrt{3}-2\cos(x))'}{(6x-\pi)'} \tag3$$ $$\lim_{x\to\pi/6}\frac{-2\sin(x)}{6} \tag4$$ $$\frac{-2\sin(\frac{\pi}{6})}{6} \tag5$$ $$\frac{-2\cdot\frac{1}{2}}{6} \tag6$$ $$-\frac{1}{6} \tag7$$ This is what I managed to do, I'm not sure it's correct; I would appreciate it if you could help me clear up this doubt.","['trigonometry', 'limits', 'calculus', 'algebra-precalculus']"
4782122,Visual or intuitive proof of $\sum_{k=0}^\infty\frac{(-1)^k}{2k+1}=\frac{\pi}{4}$,"It is well known that the alternate sum of the reciprocals of the odd numbers adds up to $\frac{\pi}{4}$ . That is $$1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots = \sum_{k=0}^\infty\frac{(-1)^k}{2k+1}=\frac{\pi}{4}.$$ A proof can be obtained by using geometric series and termwise integration to compute the Taylor series of $\arctan(x)$ and then evaluating it at $x=1$ : $$\arctan'(x)=\frac{1}{1+x^2}=\sum_{k=0}^\infty(-1)^kx^{2k}\Rightarrow\arctan(x)=\sum_{k=0}^\infty(-1)^k\frac{x^{2k+1}}{2k+1}\Rightarrow\arctan(1)= \sum_{k=0}^\infty\frac{(-1)^k}{2k+1}$$ and now use that $\arctan(1)=\frac{\pi}{4}$ . Now, is there any visual (geometric) or other sort of intuitive proof on why this should be true? An example of the sort of visual proof I'm thinking would be something like starting by taking a quarter circle inscribed in an area 1 square and alternatingly adding and substrating squares of areas 1/3, 1/5, 1/7, etc. from the original square in a way that we keep approximating the quarter circle. Still, any other intuitive proof on why the alternate sum of reciprocals of odd numbers is related to $\pi$ would be great to have.","['alternative-proof', 'proof-without-words', 'visualization', 'sequences-and-series']"
4782149,Prove or disprove a particular statement in proximity spaces,"A proximity space is a set $X$ with a relation $\sim$ between its subsets such that it satisfies the following axioms $A\sim B\Rightarrow B\sim A$ $A\sim B\Rightarrow A,B\ne \varnothing$ $A\cap B\ne \varnothing\Rightarrow A\sim B$ $A\sim (B\cup C)\iff (A\sim B)\text{ or }(A\sim C)$ $A\not\sim B\Rightarrow \text{ There exists }E\subseteq X \text{ such that } A\not\sim E \text{ and } B\not\sim E^c$ I want to consider the following statement in a proximity space. If $\{x\}\sim A$ and for all $y\in A, \{y\}\sim B$ , then $\{x\}\sim B$ . Till now, I have looked at some examples of proximity spaces (two subsets are related if 1. they are both non-empty; 2. if they have non-trivial intersection; 3. if distance between the sets is 0 [in a metric space]) and this seems to be true in all these cases. But I can't really prove the statement, neither disprove it. I have tried the following. Suppose $\{x\}\not\sim B$ . Then there is a $E$ such that $\{x\}\not\sim E$ and $B\not\sim E^c$ . This implies that $x\in E^c$ and $B\subseteq E$ . But then I am lost. It can be proven that if there exists $x$ such that $A\sim\{x\}$ and $\{x\}\sim B$ , then $A\sim B$ . I can use this if I could show that $\{x\}\sim A$ implies there is $y\in A$ such that $\{x\}\sim \{y\}$ . But this is not true in the above example number 3. If such a $y$ exists, then $d(x,y)=0$ implies $x=y$ . But $\{x\}\sim A$ implies $x\in\bar{A}$ which implies $x\in A$ . But then $A$ is a closed set. This is not necessarily true. There are a couple of other approaches I tried but all led to dead ends pretty quickly. Any help is appreciated.","['elementary-set-theory', 'general-topology', 'relations']"
4782155,Trying to find a counterexample for a false theorem,"I am trying to find a counter example for the following theorem: Suppose there are three functions $h$ , $f$ , and $g$ that satisfy the following inequalities: $$ 
h(x) < f(x) < g(x) 
$$ for all $x$ such that $0 < |x - c| < p$ for some $p > 0$ , and \begin{align*}
\lim_{{x \to c}} h(x) &= H, \\
\lim_{{x \to c}} f(x) &= F, \quad \text{and} \\
\lim_{{x \to c}} g(x) &= G,
\end{align*} for some real numbers $H$ , $F$ , and $G$ . We claim that $H < F < G$ . I have tried everything that I can think of to find a counter example but nothing worked. For instance, if I were to choose $h(x) = 2x$ , $f(x) = 4x$ , and $g(x) = 6x$ , then as $x$ approaches $0$ the claim would be violated, but the conditions would also be violated meaning it is not a counter example. I have tried piecewise functions as well and ran into a very similar issue where if the claim is violated, then the conditions were also violated and vice versa. I thought of using a Dirichlet function for $f(x)$ so that $f(x)$ would have no limit, but that would also violate the conditions. I am currently at a loss and would appreciate any sort of feedback/advice/input from anyone. Thank you. By the way, sorry for any possible formatting issues, it is my first time posting here.","['limits', 'calculus']"
4782254,Proving/disproving $\exists n {\in} \mathbb Z \;\forall k {\in} \mathbb Z \;\exists d {\in} \mathbb Z \;\;k+ n = 2d$,"I am struggling to wrap my head around what this multiply quantified statement means: $$\exists n {\in} \mathbb Z \quad \forall k {\in} \mathbb Z \quad \exists d {\in} \mathbb Z \quad k+ n = 2d.$$ Interpreting it as ‘There exists an integer $n$ which for all integers $k$ there exists another integer $d$ where $k+n=2d$ ’, I think it's true? Where to even begin to (dis)prove this statement?","['quantifiers', 'predicate-logic', 'logic', 'discrete-mathematics']"
4782269,How many Sylow-p subgroups contain a given p-subgroup?,"I am trying to solve the following question: Let $G$ be a group of finite order and let $P$ be a p-subgroup of $G$ . Then $$|\{Q \in Syl_p(G) : P \subset Q\} | \equiv 1 \pmod{p}$$ A couple of thoughts about this. We know that the set we are trying to find the size of is not empty (because of Sylow Theorems). Moreover, if $P$ itself is a Sylow p-subgroup, then the result follows trivially. Likewise, if $P$ is a normal subgroup of $G$ then every Sylow-p subgroup of $G$ contains it, which then forces LHS to be $n_p$ and we are done. I have tried the following approach. Let $P$ act on $Syl_p(G)$ by conjugation. Certainly, if $P \subset Q$ , then $Q$ is a fixed point under the action. If, we could show that $Q$ is a fixed point if and only if $P\subset Q$ , then, by applying the orbit-stabilizer theorem, we would have $$|\{Q \in Syl_p(G) : P \subset Q\} | = |Syl_p(G)^{P}| \equiv |Syl_p(G)| \pmod{p}$$ where $|Syl_p(G)^{P}|$ denotes the fixed points under the action of $P$ on $Syl_p(G)$ , and we would be done. I seem to be very close, however, I am having trouble proving that forward implication in the aforementioned if and only if statement. That is, proving that if $Q$ is a fixed point under the action, then $P$ sits inside it. Is this even true? If not, how can we prove this statement? Also, in more generality, can we ever get a precise number for such Q, depending on P? Other than the trivial examples for when P is normal or P is itself Sylow-p? Any ideas are welcome.","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
4782270,Does the Linear Dependence Lemma imply that one of at least TWO possible vectors can be removed from a list without changing the span?,"Does the Linear Dependence Lemma imply that there are always at least TWO possible vectors of which one can be removed from a linearly dependent list without changing the span? The Linear Dependence Lemma as presented in Axler, Linear Algebra Done Right (3rd Edition): It seems to me that there exist at least 2 such $j$ , because if $v_{j}$ is in the span of the other vectors in the list then it can be written as a linear combination of those others, (i.e., $v_{j}=a_{1}v_{1}+a_{2}v_{2} +...+ a_{m}v_{m}$ ). And if so, then by rearranging terms between RHS and LHS you could always specify at least one other $v$ in terms of $v_{j}$ (and assuming $v_{j} \neq 0$ then at least one $a$ is also $\neq 0$ ). In which case you could remove that $v$ from the list without changing the span. So there should always be at least 2 candidates for removal from a linearly dependent list without changing the span, right? Perhaps this is obvious, but I want to make sure I'm not missing something. Any and all feedback is welcome. Thanks!","['linear-algebra', 'vector-spaces']"
4782327,Chain rule when sum is differentiable but individual functions are not,"Let $g_1 , g_2 : \mathbb{R} \to \mathbb{R}$ be differentiable. Suppose we know that the following derivative exists at some point $x_0$ : $$
\frac{d}{dx}[g_1(f_1(x))+g_2(f_2(x))]
$$ but do not know if $f_1$ and $f_2$ individually are differentiable at that point. Can we write the above derivative at that point as follows? $$
\frac{d}{dx}|_{x=x_0}[g_1'(f_1(x_0))\cdot f_1(x) + g_2'(f_2(x_0))\cdot f_2(x)]
$$","['calculus', 'derivatives', 'chain-rule']"
4782415,Expectation of real zeroes of random algebraic polynomials.,"I am currently working on calculating the expectation of real zeroes of random n-th degree algebraic polynomials with independently and identically distributed random variables as coefficients. That is, the expectation of real zeroes for: $$X_0 + X_1x+X_2x^2 +X_3x^3+...+X_{n-1}x^{n-1}$$ M. Kac had tackled this problem for $X_i \sim N(0,1)$ in his paper in 1943 . However, I am trying to extend his results to the random coefficients following a t-distribution or a Laplace distribution. In seeing the tedious calculations through for each case (both the Laplace and the t-distribution), it turns out that the expectation of real zeroes that I am getting is exactly the same as that of Kac - for both distributions. I was just wondering if this intuitively makes sense. Since all three distributions have a different probability density function, this seems rather counter-intuitive to me.","['statistics', 'analysis', 'real-analysis', 'polynomials', 'probability']"
4782420,How to transform genus zero curve to conic section?,"I have a curve of genus zero: $$C: 2 x^5-4 x^3 y+x^2 y+2 x y^3+2 x y^2+y^5$$ or in homogenized form: $$C': 2 x^5-4 x^3 y z+x^2 y z^2+2 x y^3 z+2 x y^2 z^2+y^5$$ How to transform it to some conic section curve with rational substitutions $x\to f_1(u, v), y\to f_2(u, v)$ ? (or do you know Sagemath code that would do that?) I computed singular points of the curve and also rational parametrization of the curve if that can be useful to find the transformation. Singular points: $$(-1:1:1), (0:0:1), (\frac{1}{2}+\frac{i \sqrt{3}}{2}:-\frac{1}{2}+\frac{i \sqrt{3}}{2}:1), (\frac{1}{2}-\frac{i \sqrt{3}}{2}:-\frac{1}{2}-\frac{i \sqrt{3}}{2}:1)$$ Rational parametrization (in one parameter or in two parameters): $$x\to -\frac{p (2 p+1)}{4 p^5+1}, y\to \frac{2 p^3 (2 p+1)}{4 p^5+1}$$ $$x\to -\frac{p q^3 (2 p+q)}{4 p^5+q^5}, y\to \frac{2 p^3 q (2 p+q)}{4 p^5+q^5}$$ Also some small rational points on the curve: $$(0,0), (-1,1), (\frac{1}{3},-\frac{2}{3}), (-\frac{3}{5},\frac{6}{5}), (-\frac{8}{9},\frac{4}{9}), (-\frac{54}{53},\frac{48}{53}), (-\frac{96}{13},\frac{108}{13})$$ UPDATE: Here is an example of a curve of degree 3 and genus 0 that I was able to transform to conic - specifically parabola (with forward and backward transformations): $$y^2=x^3-x^2,\left(x\to \frac{v}{u^2},y\to \frac{v}{u^3}\right)\\
v=u^2+1,\left(u\to \frac{x}{y},v\to \frac{x^3}{y^2}\right)$$","['algebraic-geometry', 'transformation', 'parametrization', 'birational-geometry']"
4782448,"Does Banach space $C^{n}[0,1]$ contains isometric copy of $c_0$?","Consider Banach space $C^{1}[0,1]$ of continuously differentiable functions provided with the norm $$ ||f|| = \sup_{x \in [0,1]} |f(x)| + \sup_{x \in [0,1]} |f'(x)|.$$ Similarly we define space $C^{n}[0,1]$ of $n$ times continuously differentiable functions. $\textbf{My question}$ : Does $C^{1}[0,1]$ contains a subspace which is isometrically isomorphic to the Banach space $c_0$ of all sequences converging to zero? What about $C^{n}[0,1]$ ? $\textbf{My thoughts}$ : I know that Banach space C[0,1] of all continuous functions equipped with norm $||f|| = \sup_{x \in [0,1]} |f(x)|$ contains isometric copy of $c_0$ . To produce such copy one chooses any sequence $(f_n) \subset C[0,1]$ of disjointly supported functions of norm one and considers space $X = \overline{span}(f_n: n \in \mathbf{N})$ . Then $\sum \alpha_n f_n$ converges iff $\alpha_n \rightarrow 0$ or, in other words, $(\alpha_n) \in c_0$ . Consequently, mapping $$c_0 \ni (\alpha_n) \mapsto \sum \alpha_n f_n \in X $$ is isometric isomorphism and $X$ is copy of $c_0$ sitting inside $C[0,1]$ . Example of sequence $(f_n) \subset C[0,1]$ satisfying the above properties is easy to define:
put $f_n(t) = 0$ for $t \in [0,1] \setminus \Bigl(\frac{1}{2^{n+1}},\frac{1}{2^{n}}\Bigr)$ and $f_n\Bigl( \frac{3}{2^{n+2}} \Bigr) = 1$ and let $f_n$ be linear elsewhere. Let us pass to the space $C^{1}[0,1]$ with the norm defined at the beginning. I think the above procedure will also work in this case i.e. in order to find copy of $c_0$ inside this space one only needs to find a sequence $(f_n) \subset C^{1}[0,1]$ of smooth disjointly supported functions such that $\|f_n\| = 1$ for all $n$ .  However I'm having troubles to construct explicitly such a sequence.","['banach-spaces', 'smooth-functions', 'functional-analysis']"
4782487,Find differential equation,"Given the differential equation $y''+a(t)y'+b(t)y=0$ , it has a solution $y(t) = t$ for $t>0$ . Suppose that the Wronskian associated with two linearly independent solutions has the form $W(t) = 1-\ln(t)$ . Determine the functions $a(t)$ and $b(t)$ explicitly. My steps: After hours of work, I found the second soluction is $y_2(t) = \ln(t)$ My question is any idea to use this information, to find $a(t)$ and $b(t)$ . Thanks","['differential', 'ordinary-differential-equations']"
4782559,"How to evaluate the limit: $\lim_{t \to \infty} \int_0^1 \frac{e^{it^2(1+y^2)}}{1+y^2} \, dy$","I was evaluating the Fresnel integral: $$
\int_{-\infty}^{\infty} e^{ix^2}dx
$$ After some calculations, I successfully evaluated it correctly. However, there is one problem that I don't know how to evaluate strictly and not just logically. I want to evaluate this limit: $$
\lim_{{t \to \infty}} \int_{0}^{1} \frac{e^{it^2(1+y^2)}}{1+y^2} \, dy
$$ So, I have done this: Let $y={x\over t}$ , then our limit will become: $$
\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2 \left(1+\frac{x^2}{t^2}\right)}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx
$$ Now, let's do something like this: $$
\begin{align*}
&\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2(1+\frac{x^2}{t^2})}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx \\
&= \lim_{{t \to \infty}} \left(\int_{0}^{t} \frac{\cos(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx + \int_{0}^{t} \frac{i\sin(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx\right)
\end{align*}
$$ Now, let's look at the first member and evaluate the limit for it: $$
\lim_{{t \to \infty}} \int_{0}^{t} \frac{\cos(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx
$$ Instead of this integral, let's evaluate this kind of integral: $$
\int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx
$$ Now, let's use the Dominated Convergence Theorem: $$
\left| \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq \int_{0}^{t} \frac{1}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx
$$ As we evaluate the integral on the right side, it will give us: $$
\int_{0}^{t} \frac{1}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx = \frac{\pi+2}{8t}
$$ So, we have: $$
\left| \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq \frac{\pi+2}{8t}
$$ Now, let's take the limit on both sides, and we will get: $$
\left| \lim_{{t \to \infty}} \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq 0
$$ And from this: $$
\lim_{{t \to \infty}} \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx = 0
$$ And from this: $$
\lim_{{t \to \infty}} \int_{{0}}^{{t}} \frac{{\cos(t^2(1+\frac{x^2}{t^2}))}}{{1+\frac{x^2}{t^2}}} \cdot \frac{1}{t} \, dx = 0
$$ With the same logic, the second member is also $0$ .
Therefore: $$
\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2(1+\frac{x^2}{t^2})}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx = 0
$$ But I can't properly explain why it was right to say if the limit of the integral from the square of the integrand function is $0$ , then the limit of the integral from the integrand function (without the square) is also $0$ . Can someone please explain this to me mathematically and not just logically? I know the first equation, which we desire to evaluate, oscillates very fast and therefore is zero, but I want to show all this mathematically, and I don't want to use the Gamma function. Basically, we said that if: $$
\lim_{{t \to \infty}} \int_{{0}}^{{t}} \left(f(x;t)\right)^2 \, dx = 0
$$ then: $$
\lim_{{t \to \infty}} \int_{{0}}^{{t}} f(x;t) \, dx = 0
$$ But it isn't true for every function. Then, what makes it work in this case? Thanks to everyone in advance who will try it.","['analysis', 'parametric', 'solution-verification', 'fresnel-integrals', 'limits']"
4782619,Proof the quaternions are 4-dimensional?,"The quaternions can be defined as $$\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$$ From these relations, it is relatively easy to prove that $1,X,Y,XY$ span the quaternions over $\mathbb{R}$ . But I cannot find any way to prove that this is a basis. The quaternions could alternatively be constructed as the set $\mathbb{R}^4$ together with the product $$(a_1,b_1,c_1,d_1)\cdot(a_2,b_2,c_2,d_2)=(a_1a_2-b_1b_2-c_1c_2-d_1d_2,a_1b_2+b_1a_2+c_1d_2-d_1c_2,a_1c_3-b_1d_2+c_1a_1+d_1b_2,a_1d_2+b_1c_2-c_1b_2+d_1a_2)$$ From this point you can prove the product is distributive and associative to show that it forms a ring. You can also prove the identities used in constructing $\mathbb{H}$ as a quotient of the free algebra on 2 generators. Hence, using the universal property, you could show that it is a quotient of $\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$ , so $\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$ must have dimension at least $4$ . So this is technically an answer. However, this feels very much like going the long way around, so I want to know if there is a neater way to show that $\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$ is $4$ dimensional.","['ring-theory', 'abstract-algebra', 'algebras', 'quaternions']"
4782625,Show $f(x)=1/x$ and $g(x)=(x-1)/x$ produce a group of functions isomorphic to the symmetric group $S_3$ when binary operation is used as map.,"I found this question Isomorphisms between group of functions and $S_3$ but they don't show why $\phi$ is an isomorphism. I found that $$f(x) = 1/x$$ $$g(x) = (x-1)/x$$ $$f(f(x)) = x$$ $$f(g(x)) = x/(x-1)$$ $$g(f(x)) = (1/x - 1)/(1/x) = 1 - x$$ $$g(g(x)) = (((x-1)/x)-1)/((x-1)/x) = ((x-1) -x)/(x-1) = 1/(1-x)$$ The symmetrical group $S_3$ is defined as $$S_3 = (\text{id}, (12), (13), (23), (123), (321))$$ It seems obvious that there are six different possibilities in both cases, and $x$ seems to be equal to $\text{id}$ , but how do I show that there is an isomorphism between them ?","['group-theory', 'group-isomorphism', 'linear-algebra']"
4782631,Volume of a solid bounded by surfaces [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question can someone help me with setting up the required integral? The solid is bounded by $z = 4x^2 + 4y^2 -27$ and by $z = x^2+y^2$ . Should I project this on $x-y$ plane or use cylindrical or spherical coordinates or do something else? I am a bit lost and could use an example to crystalize how to approach these types of problems.","['integration', 'volume', 'geometry', 'multivariable-calculus', 'calculus']"
4782713,Intuition for geometric multiplicity $\leq$ algebraic multiplicity,"Can someone provide intuition (not a proof) for why geometric multiplicity (i.e. the dimension of the $\lambda$ -eigenspace) $\leq$ algebraic multiplicity (i.e. the number of times $\lambda$ appears as a root of $\det(A - \lambda I) = 0$ ). Here is my bad intuition:
Since there are $k$ linearly independent vector solutions to $(A - \lambda I)\vec{v} = 0$ , where $k$ is the geometric multiplicity of $\lambda$ , $\lambda$ must have a ""degree"" of at least $k$ , which translates to algebraic multiplicity. Hopefully, someone can provide some better intuition, perhaps in terms of a visualisation (I struggle to visualise the geometric significance of the algebraic multiplicity of $\lambda$ ).","['linear-algebra', 'eigenvalues-eigenvectors']"
4782745,Derivative of sum of compositions,"A follow up to a previous question: Chain rule when sum is differentiable but individual functions are not Take some $g_1, g_2, h_1,h_2: \mathbb{R}\to \mathbb{R}$ that are everywhere twice differentiable and and always have a strictly positive derivative. Take also some $f_1,f_2: \mathbb{R}\to \mathbb{R}$ which need not be differentiable. However, we know that for some $x_0$ : $$
g_1'(f_1(x_0)) = h_1'(f_1(x_0)) >0
$$ $$
g_2'(f_2(x_0)) = h_2'(f_2(x_0)) >0
$$ $$
\frac{d}{dx}[g_1(f_1(x))+ g_2(f_2(x))] \big|_{x=x_0} = 0
$$ (We only know that the above derivative exists at $x_0$ , not everywhere). Can we say the following? $$
        \frac{d}{dx}[h_1(f_1(x))+ h_2(f_2(x))] \big|_{x=x_0} = 0
$$ (We do not assume that the derivative right above exists).","['calculus', 'derivatives', 'chain-rule']"
4782752,What angle halves the volume of a hemisphere?,"Similar to this question , when needing to measure out 1/2 tablespoon, I use my hemispherical tablespoon, but I hold mine at an angle and fill to the lowest edge. At what angle should I tilt so that my tablespoon is only half full? Convention note: 0 degrees is level where the tablespoon holds a full tablespoon. 90 degrees would be holding the tablespoon sideways where it holds no liquid. In practice I usually hold at a little less than 45 degree angle, i.e. more level than tipped.",['geometry']
4782772,Sheaf cohomology on quotient stacks,"Suppose I have a scheme $X$ over $\mathbb C$ , acted on by a finite group $G$ . Let $\mathcal F$ be a $G$ -equivariant coherent sheaf of $\mathcal O_X$ -modules.
Then I can form the stack quotient $[X/G]$ , and $\mathcal F$ descends to $\mathcal F'$ on this stack. Suppose that I know the dimensions of the groups $H^i([X/G], \mathcal F')$ . What can I say about $\operatorname{dim} H^i(X, \mathcal F)$ ? I know that $(H^i(X, \mathcal F))^G \cong H^i([X/G], \mathcal F')$ , but ideally I'd like to know if there is something like an upper bound for $\operatorname{dim} H^i(X, \mathcal F)$ .
If there is no answer in such generality, I'd be happy to know of special cases.","['algebraic-stacks', 'algebraic-geometry', 'sheaf-cohomology', 'quotient-spaces']"
4782833,How do I test whether two events are independent?,"I'm trying to understand how to mathematically determine whether two events are independent. This is for introduction to statistics, so the solution and explanation to this is likely very simple, yet there's something I'm not understanding. Here's the question from my textbook: A statistical experiment has 11 equally likely outcomes that are
denoted by a, b, c, d, e, f, g, h, i, j, k. Event A = {b, d, e, j} Event B = {a, c, f, j} If two events, A and B, are independent, then $P(A) = P(A|B)$ . Therefore if I want to determine whether the two events are independent, I need to solve for $P(A)$ and $P(A|B)$ to check whether they are equal. However $P(A|B) = \frac{P(A∩B)}{P(B)}$ , and this is where I get stuck, because I can't know which multiplication rule to use to figure out $P(A∩B)$ since I don't yet know whether the events are independent or not? If the events are independent, then $P(A∩B) = P(A) * P(B)$ . Otherwise if they are dependent, then $P(A∩B) = P(A) * P(B|A)$ . I know that I can solve the question from my textbook by looking at the outcomes that intersect between the two events, but is it possible to figure out whether the two events are independent solely by using the formulae above?","['conditional-probability', 'statistics', 'probability']"
4782903,Is a non-differentiable function Lipschitz continuous if and only if its subgradient is bounded?,"It's well known that a differentiale continuous function is Lipschitz if and only if its gradient is bounded. ( Is a function Lipschitz if and only if its derivative is bounded? ) Can this result be generalized to non-differential case? The tricky thing here is to replace the gradient with Clarke subgradient ( https://en.wikipedia.org/wiki/Clarke_generalized_derivative ). In other word, is the following statement correct? Consider a continuous function $f(x)$ whose Clarke subgradient is $\partial f(x)$ on $x$ . $f(x)$ is $L$ -Lipschitz continous, i.e. $$\|f(x)-f(y)\|\le L\|x-y\|, \forall x, y\in{\rm dom}(f)$$ if and only if $\|g\|\le L$ for all $g\in\partial f(x)$ and $x\in{\rm int}({\rm dom}(f))$ , where ${\rm int}({\rm dom}(f))$ represents the interior of ${\rm dom}(f)$ .","['subgradient', 'calculus', 'functional-analysis', 'lipschitz-functions']"
4782909,Are local martingals always have locally integrable quadratic variation?,"I am reading the book: ""P. Protter, Stochastic Integration and Differential Equations. Second edition, Springer-Verlag, (2004)"",
where the following are mentioned: (1) Local martingales are not always locally square integrable. (2) A martingale $M$ is square integrable, namely, $\,\mathbb{E}(M_t^2)<\infty$ for all $t\in[0,\infty)$ , if and anly if $\,\,\mathbb{E}[M]_t<\infty\,$ for all $t\in[0,\infty)$ . (3) Any local martingale is a special semimartingale. On top of that, in the exercise part of Chap IV, it says as: Exercise 1. A semimartingale $X$ is special if and only if the increasing process $[X]$ is locally integrable,
that is, there exists a sequence of stopping times $\,T_n\underset{n}{\nearrow}\infty$ a.s. such that $\,\mathbb{E}[X]_{T_n}<\infty$ for each $n\in\mathbb{N}$ . I could not understand the assertion in Exercise 1.
If the assertion is correct,
given any local martingale $M$ , which is a special semimartingale by (3),
we can choose a sequence of stopping times $S_n\le T_n$ which tends to $\infty$ a.s. and
which makes each $M_{\cdot\wedge S_n}$ martingale,
and hence $M_{\cdot\wedge S_n}$ becomes square integrable martingale by (2).
This contradicts to (1). The assertion in Exercise 1 above implies that local martingales $M$ always have locally integrable quadratic variation (increasing process) $[M]$ . I would realy appreciate if you tell us what is correct and what is wrong in this argument.","['local-martingales', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
4782922,Set partition with some conditions,"This is the problem I am trying. Define $S_k(n)$ to be the number of partitions of the set $[n]$ so that if $i$ and $j$ are in the same block, then $|i-j| > k$ holds. Show that $S_k(n) = B(n - k)$ , for all $n \geq k$ . I first tried to find a bijection and also tried to find a recursive formula for the left hand side, but wasn't succesful. Can anyone help with this question?","['set-partition', 'combinatorics', 'discrete-mathematics']"
4782930,Density points and family of Borel sets,"Let $x \in \mathbb R^n$ , $s>0$ and $\{C_r\}_{0<r<s}$ be a family of borel sets such that $B(x, \alpha r) \subset C_r \subset B(x, \beta r)$ for some fixed $0< \alpha < \beta$ . Show that if $E$ is a Lebesgue measurable set and $t \in \{0,1\}$ then $$\lim_{r \to 0^{+}} \frac{\lambda(E \cap C_r)}{\lambda(C_r)}=t \Leftrightarrow \lim_{r \to 0^{+}} \frac{\lambda(E \cap B(x,r))}{\omega_n r^n}=t$$ But can be fails for some $t \in (0,1)$ . For see the limits i try to use the monotonicity of the measure and a change of variable e.g $t=\alpha r$ , but i cant conclude. I think to i can study these problem via cases and using the theorem of lebesgue density points of $E$ . EDIT: I can conclude the case when $t=0$ but the case when $t=1$ not work with the change of variable, topologically i understand what happen, but i cant justify. Any hint or help will be very grateful.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
4782948,Integral $\int_{0}^{1}\frac{K\left(x\right)\ln\left(1-x^{2}\right)}{x^{2}}dx=-4\ln2$,"Consider the Elliptical Integral of the First Kind: $$K\left(k\right)=\int_{0}^{\pi/2}\frac{1}{\sqrt{1-k^{2}\sin^{2}t}}dt$$ then, $$\int_{0}^{1}\frac{K\left(x\right)\ln\left(1-x^{2}\right)}{x^{2}}dx\stackrel{?}=-4\ln2$$ I was working on Integrals of similar form and I decided to check some values in Integer Relation Algorithms and unexpectedly this came up. It can be converted to the following Series Representation: $$\sum_{n=1}^{\infty}\binom{2n}{n}^2\frac{H_{n-\frac{1}{2}}}{(2n-1)2^{4n}}=2\left(\frac{4}{\pi}-1\right)\ln2$$ or the equivalent, $$\sum_{n=1}^{\infty}\binom{2n}{n}^2\frac{2H_{2n}-H_n-2\ln2}{(2n-1)2^{4n}}=2\left(\frac{4}{\pi}-1\right)\ln2$$ I am aware of the techniques required to solve these Series but this seems like a round about way to solve the Original Integral. That's why I am looking for a possibly straightforward evaluation of the Integral.","['integration', 'calculus', 'definite-integrals']"
4782971,How to find the following limit without using l'Hopital's rule: $\lim_{{x \to 0}} \frac{1 - \cos 3x}{\cos^2 5x - 1}$,"\begin{align*}
\lim_{{x \to 0}} \frac{1 - \cos 3x}{\cos^2 5x - 1} &= \lim_{{x \to 0}} \frac{1 - \cos 3x}{-\sin^2 5x} \\
&= \lim_{{x \to 0}} (1 - \cos 3x) \cdot \lim_{{x \to 0}} \frac{1}{-\sin^2 5x} \\
&= \lim_{{x \to 0}} (1 - \cos 3x) \cdot (-1) \left( \lim_{{x \to 0}} \frac{5x}{\sin 5x} \right)^2 \cdot \frac{1}{5x}=(0/0)
\end{align*}","['trigonometry', 'limits-without-lhopital']"
4782983,"Show that if $\frac{S_n - m_n}{s_n} \xrightarrow{d} \mathcal{N}(0, 1)$ with $X_k \sim \text{Ber}(p_k)$ then $\sum_k p_k(1-p_k) = +\infty$","Let $(X_n)$ be a sequence of independent random variables, $X_k \sim \text{Ber}(p_k) \ \forall k \ge 1$ . Set $S_n = \sum_{k = 1}^n X_k, m_n = \sum_{k = 1}^n p_k, s_n^2 = \sum_{k = 1}^n p_k(1-p_k)$ . Show that $$
      \dfrac{S_n -m_n}{s_n} \xrightarrow{d} \mathcal{N}(0, 1) \Longleftrightarrow \sum_{k = 1}^{\infty} p_k(1-p_k) = +\infty
$$ I'm able to show the $\Leftarrow$ direction by checking the Linderberg conditions. However, I'm getting stuck at the $\Rightarrow$ direction, and I don't know any possible directions to show this, so any hints are appreciated, thank you. Update: The Lindeberg conditions that I'm using is in Allan Gut's ""Probability: A Graduate Course"" book. In this book, the author state the following Lindeberg-Levy-Feller theorem: Theorem. Let $X_1, X_2, \ldots$ be independent random variables with finite variances, and set, for $k \ge 1, \mathbb{E}(X_k) = \mu_k, \text{Var}(X_k) = \sigma_k^2$ and, for $n \ge 1$ , $S_n = \sum_{k = 1}^n X_k, s_n^2 = \sum_{k = 1}^n \sigma_k^2$ . The Lindeberg conditions requires: $$
     L_1(n) = \max_{1 \le k \le n} \dfrac{\sigma_k^2}{s_n^2} \rightarrow 0 \text{ as } n \rightarrow \infty \tag{1}
$$ and $$
     L_2(n) = \dfrac{1}{s_n^2}\sum_{k = 1}^n \mathbb{E}[\vert X_k - \mu_k \vert^2 1\{\vert X_k - \mu_k \vert > \epsilon s_n\}] \rightarrow 0 \text{ as } n \rightarrow \infty\tag2
$$ Then:
(i) If $(2)$ is satisfied, then so is $(1)$ and $$
        \dfrac{1}{s_n}\sum_{k = 1}^n (X_k - \mu_k) \xrightarrow{d} \mathcal{N}(0, 1) \tag3
$$ (ii) If $(1)$ and $(3)$ are satisfied, so is $(2)$ .","['central-limit-theorem', 'probability-limit-theorems', 'probability-theory', 'weak-convergence']"
4782984,"Number of subsets $\{1, 2, \dots, n\}$ without numbers with forbidden differences.","Let $S = \{1, 2, \dots, n\}$ . Let $R = \{r_1, r_2, \dots, r_m\}$ be a set of forbidden differences. How many subsets of $S$ don't have two numbers the difference of which belongs to $R$ ? I have found that recursive approach helps to solve some cases.
For example let's start with $R = \{1, 2\}$ . Then let $a_n$ be a number of these subsets of $\{1, 2, \dots, n\}$ . Let $A$ be a subset with given conditions. We begin by looking at some cases: $n \in A$ , then $n-1 \not\in A$ and $n-2 \not \in A$ , so $a_n = a_{n-3}$ $n\not\in A$ , then $a_n = a_{n-1}$ So $a_n = a_{n-1} + a_{n-3}$ . Similarly if $R = \{1, \dots, m\}$ then $a_n = a_{n-1} + a_{n-m-1}$ . Let then $R = \{2\}$ . Again some cases: $n \in A, n-1 \in A$ . Then $n-2 \not\in A$ and $n-3 \not\in A$ , $a_n = a_{n-4}$ . $n \in A, n-1 \not\in A$ . Then $n-2 \not\in A$ so $a_n = a_{n-3}$ . Finally if $n \not\in A$ $a_n = a_{n-1}$ This way $a_n = a_{n-1} + a_{n-3} + a_{n-4}$ . However I struggle to find a recurrence for $R = \{m\}$ and generalize solution to any set of $R$ .","['elementary-set-theory', 'combinatorics', 'recurrence-relations']"
4783044,Evaluating $\lim _{x \to \infty} \frac{e^x+e^{-x}}{e^x-e^{-x}}$,"Is the approach made to this question good enough to be used? My professor multiplies with $e^x/e^x$ instead of making this approach $$\lim _{x \rightarrow \infty} \frac{e^x+e^{-x}}{e^x-e^{-x}}$$ Solution: $$\frac{e^x\left(1+\frac{e^{-x}}{e^x}\right)}{e^x\left(1-e^{-x}/e^x\right)} \tag1$$ $$
\begin{align}
&=\frac{1+\frac{e^{-x}}{e^x}}{1-\frac{e^{-x}}{e^x}}=\frac{1+e^{-2 x}}{1-e^{-2 x}} \tag2\\[4pt]
&\Rightarrow \lim _{x \rightarrow \infty} \frac{1+e^{-2 x}}{1-e^{-2 x}} \tag3\\[4pt]
&=\frac{1+\lim _{x \rightarrow \infty} e^{-2 x}}{1-\lim _{x \rightarrow \infty} e^{-2 x}} \tag4\\[4pt]
&=\frac{1+0}{1-0}=1 \tag5
\end{align}
$$","['limits', 'calculus', 'algebra-precalculus']"
4783175,(Method of transformation for discrete random variable) Compute the probability mass function of $W=\cos{\frac{2\pi X}{N}}$ where $X$ is geometric,"Let $X$ be a geometric random variable with the following distribution: \begin{align}
\mathbb P\{X=x\}=p^x(1-p) 
\end{align} where $$x=0,1,2,...$$ The random variable $$W=\cos{\frac{2\pi X}{N}}$$ for some integer $N$ . Compute the probability mass function of $W$ . You should consider the case when $N$ is odd or $N$ is even separately. My attempt: Let $$Y=\frac{2\pi X}{N}$$ Although $W=\cos{\frac{2\pi X}{N}}=\cos{Y}$ is not a monotone function, it can be divided into a finite number of regions in which it is monotone. Due to the symmetry of the cosine function, it is sufficient to consider the case where $y\in[0,\pi]$ and then scale the density with factor $n$ , where $n$ denotes the number of regions. If $y\in[0,\pi]$ , or equivalently $x\in[0,\frac{N}{2}]$ then $W=\cos{\frac{2\pi X}{N}}=\cos{Y}$ is a one-to-one function, and we can now compute the inverse transformation: \begin{align}
    x=\frac{N}{2\pi}\arccos{w}
\end{align} The probability mass function of $W$ in this special case is: \begin{align}
    f_W(w)&=f_X\bigg(\frac{N}{2\pi}\arccos{w}\bigg)\\
    &=p^{\frac{N}{2\pi}\arccos{w}}(1-p)
\end{align} In the general case, we have: \begin{align}
    f_W(w)=np^{\frac{N}{2\pi}\arccos{w}}(1-p)
\end{align} If $N$ is even, we count the point $w=-1$ twice each time we add regions, hence we need to subtract it: \begin{align}
    f_W(w)&=n\bigg[p^{\frac{N}{2\pi}\arccos{w}}(1-p)-p^{\frac{N}{2}}(1-p)\bigg]\\
    &=n(1-p)\bigg(p^{\frac{N}{2\pi}\arccos{w}}-p^{\frac{N}{2}}\bigg)
\end{align} My questions: My answer looks quite messy so I am not sure if it is correct or not. If someone can comment on that or suggest other simpler methods for solving it would be greatly appreciated. Thank you!","['statistics', 'probability-distributions', 'transformation', 'probability']"
4783209,Asymptotic normality of Kernel Density Estimator,"Set up We consider kernel density estimation. $X_1, \ldots, X_n \overset{\mathrm{i.i.d.}}{\sim} F$ (c.d.f., unknown). $F$ has a density $f$ and then the object it wants to estimate pointwise. Kernel Density Estimator: $$
\hat{f_n} := \frac{1}{n}\sum_{j=1}^n \frac{1}{h}K \left(\frac{y-X_j}{h} \right).
$$ $h$ means bandwidth. What I know If $h$ satisfied $h \to 0, nh \to \infty$ , then \begin{align}
\mathrm{bias\ of\ }\hat{f_n}(y) &= \frac{1}{2}h^2 f''(y)\tau^2 + o(h^2),\\
\mathrm{Var}[\hat{f_n}(y)] &= \frac{1}{nh}f(y) \int K^2(y)dy + o(\frac{1}{nh}),
\end{align} where $$
\tau^2 := \int y^2 K(y)dy.
$$ Question Why do the following limitation hold? $$
\frac{\mathrm{bias\ of\ }\hat{f_n}(y)}{\sqrt{\mathrm{Var}[\hat{f_n}(y)]}}\to \xi,
$$ where $\xi$ is a constant.","['statistics', 'probability-theory', 'asymptotics']"
4783323,A and B are sets in a universe set U. Proof: If $A\cap B=\emptyset$ so $A\subseteq B^c$.,How can I do this demonstration? $A^c$ is A complement: $A'$ Please help me What I'm doing is $\forall x \in U: x\in A \subseteq x\in B^c$ therefore $\forall x \in U: x\in A \subseteq x\notin B$ $A\cap B = \emptyset \rightarrow  A\subseteq B^c$ $A\cap B = \emptyset \rightarrow  A\nsubseteq B$ Proof by Reductio ad absurdum ~( $A\cup B= \emptyset)$ $A\cup B \neq \emptyset$ $\exists x \in A\cap B$ $x\in A \wedge x\in B$ this is a contradiction since element x is not in B $\therefore $ Proof is valid,['elementary-set-theory']
4783377,Calculating $\int_{0}^{2\pi} \frac{d x_1}{2\pi}...\int_{0}^{2\pi} \frac{d x_N}{2\pi} (\sum_{j=1}^N e^{i x_j})^n (\sum_{k=1}^N e^{-i x_k})^n$,"I'm working on a problem about correlated random walks, and in trying to solve it, I've run across integrals of the following form for non-negative integers $N,n$ : $$I(N,n) = \int_{0}^{2\pi} \frac{d x_1}{2\pi}...\int_{0}^{2\pi} \frac{d x_N}{2\pi} \left(\sum_{j=1}^N e^{i x_j}\right)^n \left(\sum_{k=1}^N e^{-i x_k}\right)^n$$ These integrals appear to be degree $n$ polynomials in $N$ with integer coefficients, at least from the lowest few orders. In the following, I'll use the fact that $\int_{0}^{2\pi} \frac{d x}{2\pi} e^{i m x} = \delta_{m 0}$ for integer $m$ . For $n=0$ , the integral is trivially $1$ , so that $I(N, 0)= 1$ . For $n=1$ , note that $\int_{0}^{2\pi} \frac{d x_1}{2\pi}...\int_{0}^{2\pi} \frac{d x_N}{2\pi} e^{i (x_i - x_j)} = \delta_{i j}$ , so that $I(N,1)=N$ . For $n=2$ , I have a little bit of a harder time. By considering cases of when pairs of indices are equal, I've convinced myself that $\int_{0}^{2\pi} \frac{d x_1}{2\pi}...\int_{0}^{2\pi} \frac{d x_N}{2\pi} e^{i (x_i + x_j - x_k - x_l)} = \delta_{ik}\delta_{jl}+\delta_{il}\delta_{jk} - \delta_{i j k l}$ , so that $I(N,2) = 2N^2-N$ . As an aside, I'm curious if there might be a connection to combinatorics and counting arguments, given that the coefficients of the polynomials appear to be integers. What is the explicit form for $I(N,n)$ as a degree- $n$ polynomial in $N$ ? This might be too tricky, so please note that I will also accept an answer that allows me to explicitly write the polynomials up to $n=50$ , so that I can check some of the subleading asymptotics and check the coefficients on the OEIS.","['integration', 'combinatorics']"
4783380,Is 2d space a subset of 3d?,"I’m working on some exercises on sets. One of the tasks asked if $R^2 \subseteq R^3$ So talking in terms of sets, it’s false (which is confirmed by the book), since $R^2$ is a set of pairs and $R^3$ is a set of triplets. When I’m thinking in a bit more natural way, I see $R^3$ as an infinite stack of $R^2$ . I’m not sure if I can write it like that, but to some extent I feel like I could define it as $R^3 = \{(R^2, z) : z \in R\}$ I can’t seem to see the logical error in the latter. Any help?",['elementary-set-theory']
4783381,Circle tangent to rotated ellipse and horizontal line,"I would like to find the position for the center of a circle $(x_0, y_0)$ that is tangent to both an ellipse and a horizontal line.
The ellipse is positioned at $(0,0)$ and is defined by major axis $a$ and minor axis $b$ and can be rotated by $\alpha$ .
The line $h$ is horizontal and can be moved on the $y$ -axis. The Python snippet in this answer works well but doesn't allow for the ellipse to be rotated. Edit: I'm a technical artist in the game industry working on a procedural tool that involves calculating the center of a circle to create an almost accurate 3D model. I need to understand the math behind it in order to generate code to solve it.
My math knowledge ranges from high school level to math applicable to basic 3D graphics.","['conic-sections', 'tangent-line', 'circles', 'geometry']"
4783425,"How to parametrize a ""SpongeBob flower""","I am trying to figure out a way of generating a 5 lobed shaped like the flower sin the sky of spongebob: I.e. a parametric curve that is at least twice differentiable, closed and that transitions from convex to concave in regular lobes.","['curves', 'geometry', 'parametric', 'parametrization', 'differential-geometry']"
4783441,Convergence in distribution of weighted average,"Consider the following setting: $X_i\sim P_X$ iid for $i = 1,2,\dots, n_X$ , where $P_X$ is a probability distribution with mean $\mu_X$ and variance $1$ , $Y_i\sim P_Y$ iid for $i = 1,2,\dots, n_Y$ , where $P_Y$ is a probability distribution with mean $\mu_Y$ and variance $1$ , $P_X$ and $P_Y$ are independent. Assume that $\frac{n_X}{n_X + n_Y}\rightarrow\lambda_X$ and $\frac{n_Y}{n_X + n_Y}\rightarrow\lambda_Y$ as $\min(n_X,n_Y)\rightarrow\infty$ . Consider the following definitions: \begin{align*}M &:= \frac{n_X}{n_X+n_Y}\left(\frac{1}{n_X}\sum_{k=1}^{n_X}X_k\right) + \frac{n_Y}{n_X+n_Y}\left(\frac{1}{n_X}\sum_{k=1}^{n_Y}Y_k\right),\\
\nu &:= \frac{n_X}{n_X+n_Y}\mu_X + \frac{n_Y}{n_X+n_Y}\mu_Y
\end{align*} Then $$\sqrt{\frac{n_Xn_Y}{n_X+n_Y}}(M - \nu) = \underbrace{\sqrt{\frac{n_Y}{n_X+n_Y}}}_{\rightarrow\sqrt{\lambda_Y}}\underbrace{\frac{n_X}{n_X + n_Y}}_{\rightarrow\lambda_X}\underbrace{\sqrt{n_X}(\hat\mu_X - \mu_X)}_{\leadsto\mathcal N(0,1)} + \underbrace{\sqrt{\frac{n_X}{n_X+n_Y}}}_{\rightarrow\sqrt{\lambda_X}}\underbrace{\frac{n_Y}{n_X + n_Y}}_{\rightarrow\lambda_Y}\underbrace{\sqrt{n_Y}(\hat\mu_Y - \mu_Y)}_{\leadsto\mathcal N(0,1)}.$$ That is, the resulting limiting distribution is $\sqrt{\lambda_X\lambda_Y}(\sqrt{\lambda_X} + \sqrt{\lambda_Y})\mathcal N(0,1)$ . Is that correct? Two things confuse me: 1. the result looks not very familiar, and 2. usually we have that the ""parameter"", in this case, $\nu$ does not depend on the sample size. Thanks for any help!",['statistics']
