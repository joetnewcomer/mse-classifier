question_id,title,body,tags
3539726,finite index subgroups in free group non-trivial intersection with each of the non-trivial subgroups of the free group.,"I was reading a paper and find this statement in the abstract, ""If $H$ has finite index in $F_m$ , then $H$ has non-trivial intersection with each of the non-trivial subgroups of $F_m$ "" where $F_m$ is a free group of rank m. The author claims that it's a obvious statement but I don't see how. All I know is, as $[F_m:H]<\infty$ , $H$ is finitely generated and free(being subgroup of a free group $F_m$ ). Thanks for any help!","['combinatorial-group-theory', 'group-theory', 'free-groups', 'covering-spaces']"
3539745,Prove that all cyclic groups are Abelian.,"Prove that all cyclic groups are Abelian. For some group $G$ , define a cyclic subgroup of $G$ as $\left \langle a \right \rangle = \{a^n : n \in \mathbb{Z}, a \in G\}$ Then it follows that $a^n,a^m \in \left \langle a \right \rangle$ is always true. We wish to show that $\left \langle a \right \rangle$ is abelian, or that $$a^na^m = a^ma^n$$ So... $$a^na^m=a^{n+m}=a^{m+n}=a^ma^n$$ Hence, every cyclic group is Abelian since for all $m,n \in \mathbb{Z}$ , $a^na^m=a^ma^n$ . Is that really all we have to do? This proof seems way too easy but also right. Thanks!","['group-theory', 'solution-verification', 'cyclic-groups']"
3539750,"A CMIMC Integration Bee integral: $\int_0^\infty \left( \sin(1/x) - \frac{\sin(\pi/x)}{\pi} \right) \,dx$","At the 2020 CMIMC Integration Bee, the following integral was one of the qualifying problems: $$\int_0^\infty \left( \sin(1/x) - \frac{\sin(\pi/x)}{\pi} \right) \,dx.$$ I attempted to use differentiation under the integral sign: $$f(t) = \int_0^\infty \left( \sin(t/x) - \frac{\sin(\pi t/x)}{\pi} \right) \,dx$$ $$f'(t) = \int_0^\infty \left( \frac{\cos(t/x) - \cos(\pi t/x)}{x}\right) \,dx.$$ We are very close to being able to use the Frullani integral, that is, $$\int_0^\infty \frac{f(ax)-f(bx)}{x} \, dx = \ln \left( \frac{b}{a} \right) \cdot \left( f(0) - \lim_{x \to \infty} f(x) \right)$$ for $f$ continuously differentiable on the nonnegative reals. However, if we try to use it with $f(x)=\cos(1/x)$ , we obtain $$f'(t) = (\ln \pi) \left( \cos(1/0) - \lim_{x \to \infty} \cos(1/x) \right),$$ which is nonsensical. This happens, of course, because $f$ is not continuously differentiable or even defined at $0$ . But if we were able to show that $$\int_0^\infty \left( \frac{\cos(t/x) - \cos(\pi t/x)}{x}\right) \,dx = (\ln \pi) \left(\lim_{x \to \infty} \cos(1/x) \right) = \ln \pi,$$ (which is true according to Wolfram Alpha,) then we would have $$f(1) = f(0) + \int_0^1 f'(x) \, dx = \int_0^1 \ln \pi \, dx = \ln \pi,$$ which is the correct answer. Any hints or solutions for how to complete my solution or for an entirely different solution are appreciated!","['integration', 'calculus', 'contest-math']"
3539814,"If $f'' \ge 0$, $\int_0^2 f(x)dx \ge 2f(1)$","Question: If $f'' \ge 0$ in interval $[0, 2]$ , prove that $$\int_0^2 f(x)dx \ge 2f(1)$$ The question is graphically trivial I think, but not in mathematically. I wanted to use the fact that there $\exists c$ s.t. $$\int_0^2f(x)dx = 2f(c)$$ and the Jensen's Thm, which is $$f(tx_1+(1-t)x_2)\le tf(x_1)+(1-t)f(x_2)$$ I tried to find the characteristics that $c$ can have, but it was still hard for me to get an idea. Could you please give some key points to the problem? Thanks.","['integration', 'calculus', 'jensen-inequality']"
3539841,Why does this formula from Silverman give the tangent lines of a cusp or node?,"On page 44 of Arithmetic of ECs, Silverman explains that given a weierstrass equation $f \in K[x,y]$ and singular point $P=(x_0, y_0)$ with $\partial f / \partial x(P) = \partial f / \partial y (P) = 0$ that one can rearrange the Taylor expansion of $f$ at P to get: $$f(x,y) - f(x_0, y_0) = ((y-y_0) - \alpha (x-x_0))((y-y_0) - \beta (x-x_0)) - (x- x_0)^3,$$ for some $\alpha, \beta \in \overline K$ . He then goes on to say $(y-y_0) - \alpha (x-x_0)$ and $(y-y_0) - \beta (x-x_0)$ are the tangent lines of $f$ at $P$ (if $P$ is a cusp then they coincide). This might be a silly question, but why are these the tangent lines? I assume this follows from where they appear in the Taylor expansion but I can't figure out why.","['algebraic-geometry', 'elliptic-curves']"
3539856,"Prove that $~a,~b~$ are integers and $~a \ge2~$, then either $~b~$ is not divisible by $~a~$ or $~b+1~$ is not divisible by $~a~$. [duplicate]","This question already has answers here : Proof of divisibility: if $a|b$ and $a|(b+c)$ then $a|c$ (8 answers) Closed 3 years ago . Prove that $~a,~b~$ are integers and $~a \ge2~$ , then either $~b~$ is not divisible by $~a~$ or $~b+1~$ is not divisible by $~a~$ . Should I use contradiction of uniqueness of prime factorisation to prove or simply prove by mathematical induction?",['algebra-precalculus']
3539882,"$f(a)=f(b), f'(a)=f'(b)$, Existence of zeros of $f''(x)-\lambda (f'(x))^2 =0$ in $(a, b)$","Question: $f:[a, b]\to\mathbb R $ is a function, which is contiunous and twice differentiable. If $f(a)=f(b)$ and $f'(a)=f'(b)$ , for $\forall\lambda\in\mathbb R$ , show that there exists at least one zero of the equation $$f''(x)-\lambda (f'(x))^2 =0$$ in the interval (a, b). I first wanted to use the fact that $$\exists c_1\space\space s.t\space\space \frac{f(a)-f(b)}{a-b}=f'(c_1)=0$$ $$\exists c_2\space\space s.t\space\space \frac{f'(a)-f'(b)}{a-b}=f''(c_2)=0$$ However, I still do not know how these facts can be applied to the differential equation. Also, I multiplied LHS and RHS with $e^{\lambda x}$ but nothing happened. Could you please give me some key ideas about this problem? Thanks for answering.","['calculus', 'derivatives', 'ordinary-differential-equations']"
3539892,Can there exist $\{X_n\}_{n\ge 1}$ such that $X_n \to -\infty$ a.s. and $EX_n\to 0$?,Can there exist variables $\{X_n\}_{n\ge 1}$ such that $X_n \to -\infty$ a.s. and $EX_n\to 0$ ? How can we prove or disprove this analytically?,"['measure-theory', 'probability-theory', 'random-variables']"
3539895,Is there any significance to the convergence point of recursive interior irregular pentagons?,"Draw the diagonals in an irregular convex pentagon, forming a new, smaller, irregular pentagon. Repeat until the resulting area is vanishingly small. Does that point have any significant relationship to the original figure?",['geometry']
3539934,Does there exist $\{X_n\}$ for which $\liminf_{n\to \infty}X_n$ doesn't exist but the negative parts $\{X^-_n\}$ are uniformly integrable?,Are there random variables $\{X_n\}_{n\ge 1}$ for which the expected value of $ \liminf\limits_{n\to \infty} X_n $ doesn't exist but the negative parts $\{X^-_n\}_{n\ge 1}$ are uniformly integrable? How can we prove analytically that there exists?,"['measure-theory', 'uniform-integrability', 'examples-counterexamples', 'probability-theory', 'random-variables']"
3539935,Connection between an algebraic invariant and a maximisation issue,"I came to be interested by the following rational function : $$f(x)=\dfrac{(x^2-x+1)^3}{x^2(x-1)^2}\tag{1}$$ while writing this answer ; I discovered that $f$ is connected to rather deep features of ""abstract algebra"" (Klein $j$ -invariant (see paragraph ""sextic functions"") ; as well( https://hsm.stackexchange.com/q/5038/3730 ) ; see also LurÃ¶th theorem. Surprisingly, in this question and its second answer , one finds $f$ connected  to a maximisation/minimization issue ; precisely, the largest value of constant $M$ such that : $$(a^2+b^2+c^2-ab-bc-ca)^3 \geq M[((a-b)(b-c)(c-a)]^2\tag{2}$$ for all $a,b,c \geq 0$ , is the minimum of values taken by $f(a)$ . Remark : This solution is based on the change of variables $$(a,\ b, \ c) \rightarrow  \ \ (ka+p, \ \ kb+p, \ \ kc+p)\ $$ Beyond this result and its short proof, is there a ""higher level"" rationale for a connection between expression (1) and maximisation problem (2) ? The only feature I have noticed is that the RHS of (2) is the discriminant of polynomial $(x-a)(x-b)(x-c)$ . Another reference . Another one explaining what a j-invariant is Connection with elliptic curves","['optimization', 'abstract-algebra', 'finite-groups', 'discriminant']"
3539958,Evaluating $\sqrt{9-5\sqrt{3-\sqrt{9-5\sqrt{3-\sqrt{9-\cdots}}}}}$.,"I was wondering if it was possible to evaluate $$\sqrt{9-5\sqrt{3-\sqrt{9-5\sqrt{3-\sqrt{9-5\sqrt{3-\sqrt{9-\cdots}}}}}}}$$ I let the expression equal $x>0$ and wrote $$x=\sqrt{9-5\sqrt{3-x}}$$ However, there is not just one value $x$ can take; $x=2$ or $x=3$ . How do I find out which one it is, or does this infinite-nested radical converge at all? Perhaps it merely oscillates between $2$ and $3$ , but I am not entirely sure. Any help or hints would be much appreciated. Thank you in advance. The ellipsis means ""and so on"". It measures the following: $$\sqrt{9-5}$$ $$\sqrt{9-5\sqrt{3-\sqrt{9-5}}}$$ $$\sqrt{9-5\sqrt{3-\sqrt{9-5\sqrt{3-\sqrt{9-5}}}}}$$ $$\vdots$$ Incidentally, I did not refuse to clarify the meaning. I am only active on Math.SE for so long. Whatever requests that occur can only be followed up the moment I am active, can see them and have time to act.","['nested-radicals', 'convergence-divergence', 'radicals', 'sequences-and-series']"
3540028,Contact vector field,"I am not sure if I understand the definition of a contact vector field: Let $(W, \xi)$ be a contact manifold. A vector field $Y$ is called a contact vector field, if the flow of $Y$ preserves $\xi$ . If $\lambda$ is a defining contact form, then this means that $\mathcal{L}_Y \lambda= p \lambda$ where $p: W \rightarrow \mathbb{R}$ . Now what exactly does ""the flow of $Y$ preserves $\xi$ "" mean? As far as I understand, it is the following: Let $\varphi_t(x)$ be the flow of $Y$ . Then for each $t$ , it holds: $\varphi_t^{*} \xi = \xi $ so for each tangent vector $v \in \xi_p$ , it holds that the tangent vector $f \mapsto v(f \circ \varphi_t)$ is in $\xi_{\varphi_t(p)}$ Is that correct? And if yes, how does it correspond to $\mathcal{L}_Y \lambda= p \lambda$ where $p: W \rightarrow \mathbb{R}$ Locally, $\xi= \ker\{\lambda\}$ . $\mathcal{L}_Y \lambda = d(\iota_Y \lambda)+ \iota_Y(d \lambda)$ But why is that equivalent?","['manifolds', 'contact-topology', 'vector-fields', 'differential-geometry']"
3540068,What is the optimal number of dice to roll a Yahtzee in one roll?,"Description In the game of Yahtzee, 5 dice are rolled to determine a score. One of the resulting rolls is called a Yahtzee. To roll a Yahtzee you must have 5 of a kind. (5 1's or 5 2's or 5 3's etc..). In the game of Yahtzee you can only have 5 dice. However, for the purpose of this question I want to entertain adding more dice to the equation. Therefore I'd like to define a Yahtzee as follows: To roll a Yahtzee you must have exactly 5 of a kind, no more or no less. (5 1's or 5 2's or 5 3's etc..). Examples Let's look at some rolls with 6 dice The following would be a Yahtzee: 1 1 1 1 1 4 6 3 3 3 3 3 5 5 3 5 5 5 The following would not be a Yahtzee: 1 1 1 3 3 3 1 1 1 1 5 3 1 1 1 1 1 1 - Note that the last roll does technically contain 5 1's, however because the roll as an entirety contains 6 1's this is not a Yahtzee. Let's look at some rolls with 12 dice The following would be a Yahtzee: 1 1 2 1 2 1 4 4 1 3 6 2 1 1 1 1 1 2 2 2 2 2 3 3 1 1 1 1 1 2 2 2 2 2 2 2 - Note that the first roll is a Yahtzee with 5 1's, this roll is to illustrate that order doesn't matter. - Note that the second roll has 2 Yahtzees, this is a roll that counts as a Yahtzee - Note that the third roll has a Yahtzee with 1's but has 7 2's. This roll is a Yahtzee because it contains exactly 5 1's. The 7 2's do not nullify this roll. The following would not be a Yahtzee: 1 1 1 2 2 2 3 3 3 4 4 4 1 1 1 1 1 1 6 6 6 6 6 6 - Note that the last roll has 6 1's and 6 6's. Because exactly 5 of one number (no more, no less) is not present, this roll does not contain a Yahtzee. The Question What is the optimal number of dice to roll a Yahtzee in one roll? A more generalized form of the question is as follows: Given $n$ dice, what is the probability of rolling a Yahtzee of length $y$ in one roll.","['probability-theory', 'inclusion-exclusion', 'dice', 'recreational-mathematics', 'problem-solving']"
3540087,Shilov or Axler for Linear Algebra?,I'm looking for a book on linear algebra. I found that Axler's and Shilov's books have a good reputation. Which of them is better? Which is more complete and suitable for theoretical study?,"['linear-algebra', 'book-recommendation', 'reference-request']"
3540089,Orientation of stereographic projection,"I was reading Lee and was wondering if the stereographic projection of the north pole and the south pole are in the same oriented smooth atlas. To be more precise, we have $\sigma_N: S^n \to \mathbb{R}^n$ defined by: $$
\sigma_N(x^1, \ldots, x^{n+1}) = \frac{(x^1, \ldots, x^n)}{1-x^{n+1}}
$$ and: $$
\sigma_N^{-1}(u^1, \ldots, u^n) = \frac{(2u^1, \ldots, 2u^n, |u|^2 - 1)}{|u|^2+1}
$$ Then the projection from the south pole is given by: $\sigma_S(x) = -\sigma_N(x)$ . The composition of these two maps yields: $$
\sigma_S \circ \sigma_N^{-1} (x) = \frac{x}{|x|^2}
$$ If the determinant of the total derivative of this map is negative, then these two functions do not belong to the same oriented smooth atlas. I have been able to show this in two and in three dimensions with some laborious computations in Mathematica, but I don't see how I can can compute that in the $n$ -dimensional case. Is there an easier way to show that these two maps do not belong to the same oriented smooth atlas?","['smooth-manifolds', 'differential-geometry']"
3540093,"$\sum_{k=1}^\infty\frac{1}{k^3|x-x_k|^2}$ converges a.s. in [0,1]","Show that for any sequence $x_k$ in $[0,1]$ the series: $$S(x)=\sum_{k=1}^\infty\frac{1}{k^3|x-x_k|^2}$$ converges a.s. w.r.t Lebesgue measure on $[0,1].$ Iv'e tried to take intervals of size $k^{-\alpha}$ around $x_k$ and use Borel Canteli but no luck so far. To get convergence I need $\alpha < 1$ and to use Borel Canteli I need $\alpha  > 1$ .","['measure-theory', 'lebesgue-measure', 'sequences-and-series', 'real-analysis']"
3540152,"$a_{n+1}a_n=a_n^2+a_n+1$, $a_1=1$","$a_{n+1}a_n=a_n^2+a_n+1$ , $a_1=1$ ,how to find integer $k$ , make $\left|\sqrt{a_{2020}}-k\right|$ as small as possible. Using computer, I get $a_{2020}\approx 2027.38$ . then $\sqrt{a_{2020}}\approx 45.0264,k=45$ But without computer, how to calculate it? I notice that if $\sqrt{a_{2020}}=XXX.6$ ,etc ,then $k=XXX+1$ , else $k=XXX$ . But then my  ideas stuck.",['sequences-and-series']
3540188,Limit as $n\to+\infty$ of $\prod_{k=1}^{n} \frac{2k}{2k+1}$,"I'm trying to evaluate $$\lim_{n\to+\infty} \prod_{k=1}^{n} \frac{2k}{2k+1}$$ First I notice that since $k\geq1$ it is $\frac{2k}{2k+1}>0$ for all $k\in\{1,...,n\}$ ; so $$0\leq\lim_{n\to+\infty} \prod_{k=1}^{n} \frac{2k}{2k+1}$$ Then I notice that $$\prod_{k=1}^{n} \frac{2k}{2k+1}=\exp{\ln\left(\prod_{k=1}^{n} \frac{2k}{2k+1}\right)}=\exp{\sum_{k=1}^{n}\ln\left(\frac{2k}{2k+1}\right)}=$$ $$=\exp{\sum_{k=1}^{n}\ln\left(1-\frac{1}{2k+1}\right)}$$ Since $\ln(1+x)\leq x$ for all $x>-1$ and since $\exp$ is an increasing function it follows that $$\exp{\sum_{k=1}^{n}\ln\left(1-\frac{1}{2k+1}\right)}\leq\exp{\sum_{k=1}^{n}-\frac{1}{2k+1}}$$ So $$\lim_{n\to+\infty}\prod_{k=1}^{n} \frac{2k}{2k+1}\leq\lim_{n\to+\infty}\exp{\sum_{k=1}^{n}-\frac{1}{2k+1}}$$ Since $\exp$ is a continuous function it follows that $$\lim_{n\to+\infty}\exp{\sum_{k=1}^{n}-\frac{1}{2k+1}}=\exp{\sum_{k=1}^{+\infty}-\frac{1}{2k+1}}=e^{-\infty}=0$$ So by the comparison test we deduce that the limit is $0$ . Is this correct? Thanks for your time.","['infinite-product', 'limits', 'sequences-and-series', 'real-analysis']"
3540190,Finding the coefficients of the power series representation given a function,"I'm trying to solve this problem: Find the coefficients $a_k$ and the interval of convergence of the series: $f(x)=\frac{arctan(x)}{x+1}=\sum_{k=0}^\infty a_k(2x+1)^k$ So far what I've tried is to get the series representation of $arctan(x)$ centered in $(x-\frac{1}{2})$ like this: $\frac{1}{1+x^2}=\frac{1}{\frac{5}{4}+(x^2-\frac{1}{4})}=\frac{1}{\frac{5}{4}}\frac{1}{1-(-\frac{4}{5}(x^2-\frac{1}{4}))}=\frac{4}{5}\sum_{k=0}^\infty (\frac{4}{5}(-(x^2-\frac{1}{4})))^k=\frac{4}{5}\sum_{k=0}^\infty(-1)^k\frac{4^k}{5^k}(x+\frac{1}{2})^k(x-\frac{1}{2})^k$ However I'm not sure how to proceed from here. Oh also I can easily get a series representation of $\frac{1}{1+x}$ of the form $\sum_{k=0}^\infty a_k(2x+1)^k$ , but in that case I don't know how to incorporate the $arctan(x)$ .","['power-series', 'functions', 'taylor-expansion', 'sequences-and-series']"
3540214,The Hankel Integral Representation for $\Gamma(z)$,"I am trying to understand some details hidden in the proof of the Hankel integral representation for the gamma function: $$\frac{1}{\Gamma(z)} = -\frac{1}{2\pi i} \int_{\mathcal{H}} (-t)^{-z} e^{-t} dt$$ for all $z \in \mathbb{C}$ . Here $\mathcal{H}$ denotes the Hankel contour: $\mathcal{H} = [i + \infty,i] + \mathcal{H}_{sc} + [-i,-i + \infty]$ , where $\mathcal{H}_{sc}$ joins $i$ with $-i$ along a positively oriented semicircle centered at $0$ . A typical approach to the proof, as far as I understand it, goes as follows: Cut the plane along the positive real axis and choose a fixed branch of the multifunction $(-t)^{-z}$ by taking its principal branch for negative real $t$ , and by continuing this branch analytically to the cut plane. Let $\varepsilon\mathcal{H}$ denote $\mathcal{H}$ scaled by $\varepsilon$ , i.e., after applying the transformation $z \mapsto \varepsilon z$ . The integral along $\varepsilon\mathcal{H}$ is then said to be the same as the one along $\mathcal{H}$ by Cauchy's theorem. This is a first step that I find unclear: I understand that the integrand is analytic in $\mathbb{C} \setminus [0,\infty)$ ; however I do not know about any deformation theorem for improper contours. Could someone describe a rigorous argument that is used here? Assume $z < 0$ and take $\varepsilon \to 0$ . The integral can then be decomposed into three integrals, two of which can be manipulated to obtain an integral much alike the usual integral representation of $\Gamma(1-z)$ for $\mathrm{Re}(1-z) > 0$ , while the remaining one can be shown to be negligible when $\varepsilon \to 0$ , thanks to the assumption $z < 0$ . The Hankel representation is then proved for $z < 0$ . Finally, the result is extended to the whole complex plain via analytic continuation. This is a second step that I find unclear , as it can only be performed if one knows that $$I(z) = \int_{\mathcal{H}} (-t)^{-z} e^{-t} dt$$ is an analytic function of $z$ . This property is usually qualified as obvious. Nevertheless, I have no idea about why it is obvious. Could someone explain the rigorous arguments needed to perform the two critical steps mentioned above? I would also be very grateful for pointers to literature that treats the Hankel representation rigorously (the treatements that I have found seem more-or-less sketchy to me). Many thanks in advance.","['improper-integrals', 'special-functions', 'complex-analysis', 'gamma-function', 'contour-integration']"
3540218,Understanding Lens space in Hatcher's Algebraic Topology,"Update: I put my understanding in the answer. If you find any mistakes, please let me know. Thanks for your time. This is from Hatcher's Algebraic Topology , Example 2.43: Lens Spaces, page 144--146. Given integer $m > 1$ and integers $l_{1}, \ldots, l_{n}$ relatively prime to $m$ . 
Define action of $\mathbb Z_{m} = \langle \rho \rangle$ on $S^{2n-1} \subset \mathbb C^{n}$ by $\rho(z_{1}, \ldots, z_{n}) = (e^{2\pi i l_{1}/m} z_{1}, \ldots, e^{2\pi i l_{n}/m} z_{n})$ . Lens space $L = L_{m}(l_{1}, \ldots, l_{n}) := S^{2n-1} / \mathbb Z_{m}$ . Devide unit circle $C$ in $n$ -th $\mathbb C$ factor of $\mathbb C^{n}$ by taking points $e^{2\pi ij/m} \in C$ as vertices, $j = 1, \ldots, m$ . Joining the $j$ -th vertex of $C$ to unit sphere $S^{2n-3} \subset \mathbb C^{n-1}$ by arcs of great circles in $S^{2n-1}$ . All these arcs form a $(2n-2)$ -dimensional ball $B_{j}^{2n-2}$ , which is homeomorphic to $D^{2n-2}$ and bounded by $S^{2n-3}$ . Similarly, joining the $j$ -th edge of $C$ to $S^{2n-3}$ gives a ball $B_{j}^{2n-1}$ bounded by $B_{j}^{2n-2}$ and $B_{j+1}^{2n-2}$ . Rotation $\rho$ takes $S^{2n-3}$ to itself while rotating $C$ by angle $2\pi l_{n} / m$ , hence $\rho$ permutes the $B_{j}^{2n-1}$ 's and $B_{j}^{2n-2}$ 's. For $r$ s.t. $r l_{n} = 1 \bmod m$ , $\rho^{r}$ takes each $B_{j}^{2n-1}$ and $B_{j}^{2n-2}$ to the next one. $(r, m) = 1$ , $\rho^{r}$ is a generator of $\mathbb Z_{m}$ . We may obtain $L$ as quotient of one $B_{j}^{2n-1}$ by identifying its two faces $B_{j}^{2n-2}$ and $B_{j+1}^{2n-2}$ together via $\rho^r$ . The two faces $B_{j}^{2n-2}$ and $B_{j+1}^{2n-2}$ are identified via a reflection across $B_{j}^{2n-1}$ fixing $S^{2n-3}$ , followed by a rotation. My question: $1$ . What's the relation of these $B_{j}^{2n-1}$ 's? Do we have $\bigsqcup_j B_{j}^{2n-1} = S^{2n-1}$ ? $2$ . Since $B_{j}^{2n-2}$ and $B_{j+1}^{2n-2}$ identified together via $\rho^r$ , where does that reflection come from?","['general-topology', 'cw-complexes', 'algebraic-topology']"
3540234,Continuity over a Compact Implies Uniform Continuity,"There is a well-known theorem in mathematical analysis that says Suppose $f:M\to N$ is a function from a metric space $(M,d_M)$ to another metric space $(N,d_N)$ . Assume that $M$ is compact. Then $f$ is uniformly continuous over $(M,d_M)$ . For now, let us take $M=[a,b]$ , $N=\mathbb{R}$ , $d_M=d_N=|\cdot|$ . I have seen two different proofs for this case. T. A. Apostol, Calculus, Volume 1, 2nd Edition, Page 152, 1967. C. C. Pugh, Real Mathematical Analysis, 2nd Edition, Page 85, 2015. Apostol argues by contradiction using the method of bisections and the least upper bound property. Pugh also explains by contradiction but prefers to use a technique that one of my teachers called it continuous induction to prove that $[a\,\,\,b]$ is sequentially compact and then uses this property to prove the theorem. Both proofs can be found on the pages mentioned above. Recently, I noticed that Pugh has suggested another approach in exercise 43 of chapter 1 on page 52. However, I couldn't riddle it out. Here is the question Prove that a continuous function defined on an interval $[a\,\,\,b]$ is uniformaly continuous. Hint . Let $\epsilon>0$ be given. Think of $\epsilon$ as fixed and consider the sets \begin{align*}A(\delta)&=\{u\in[a,b]\,|\,\text{if}\,x,t\in[a,u]\,\text{and}\,|x-t|<\delta\,\text{then}\,|f(x)-f(t)|<\epsilon\}, \\
A&=\bigcup_{\delta>0}A(\delta).
\end{align*} Using the least upper bound property, prove that $b\in A$ . Infer that $f$ is uniformly continuous. Can you shed some light on what Pugh is trying to suggest in the hint? Uniform Continuity In the definition of continuity we have that $$\forall x\in[a,b],\,\,\forall\epsilon>0,\,\,\exists\delta>0,\,\,\forall t\in[a,b]\,\wedge\,|t-x|<\delta\,\implies|f(t)-f(x)|<\epsilon$$ Here the delta depends on $x$ and $\epsilon$ . Now, fix $\epsilon$ and let $\Delta_{\epsilon}$ be the set that contains all values of $\delta$ corresponding to different $x$ 's. Then uniform continuity is just telling us that $\Delta_\epsilon$ has a minimum. Consequently, this means that there is a $\delta$ that works for all $x\in[a,b]$ . This leads to the following definition $$\forall\epsilon>0,\,\,\exists\delta>0,\,\,\forall x\in[a,b],\,\,\forall t\in[a,b]\,\wedge\,|t-x|<\delta\,\implies|f(t)-f(x)|<\epsilon$$ where $\delta$ only depends on $\epsilon$ .","['continuity', 'uniform-continuity', 'analysis']"
3540243,What's the number of decibinary numbers that evaluate to given decimal number?,"Let's define a decibinary number system, where each bit (or digit) can range from $0$ to $9$ , but it's place value corresponds to the one in the binary system. For example: $$(2020)_{decibinary} = 2 \times 2^3 + 0 \times 2^2 + 2 \times 2^1 + 0 \times 2^0 = 16 + 2 = (18)_{10}$$ Note, that many decibinary numbers can evaluate to the same decimal value, e.g. $$(1220)_{decibinary} = 1 \times 2^3 + 2 \times 2^2 + 2 \times 2^1 + 0 \times 2^0 = 8 + 8 + 2  = (18)_{10}$$ I am looking for an expression (say function $f$ ) or an efficient algorithm, that, given a decimal number $n$ , gives me a number of decibinary numbers that evaluate to $n$ . Of course I am treating e.g. $(05)_{decibinary}$ the same as $(5)_{decibinary}$ (leading zeros do not matter). As an aside, I found the concept of decibinary numbers in this HackerRank question , where I thought it might actually be useful to be able to quickly compute $f(n)$ to solve the problem efficiently. $$\\$$ Below are my thoughts and approaches to tackle the problem. What I tried was to first see if there is a pattern: $$f(0) = 1 \\ f(1) = 1 \\ f(2) = 2 \\ f(3) = 2 \\ f(4) = 4 \\ f(5) = 4 \\ f(6) = 6 \\ f(7) = 6 \\ f(8) = 10 \\ f(9) = 10 \\ f(10) = 13$$ but $10$ seems to break the pattern, as there are (if I didn't skip anything) $13$ decibinary numbers that evaluate to $(10)_{10}$ : $18, 26, 34, 42, 50, 106, 114, 122, 130, 202, 210, 1002, 1010$ (if it was $14$ I could see some pattern, but unfortunately $10$ cannot be encoded using one digit in decibinary ). What I spotted, however, is that I could recursively calculate $f$ (or use dynamic programming to build up a lookup table bottom-up in order to be able to reuse the computations). For instance, I know that the decibinary number evaluating to $10$ will have at max. $4$ digits (because $(10000)_{decibinary}$ already evaluates to $16$ ). So I can represent $f(10)$ as a sum of the number of ways I can encode $10$ using $4, 3, 2$ and $1$ digit (the latter being $0$ as there is no way I can represent $10$ using 1 digit). Let's try to compute the number of ways to represent $(10)_{10}$ using $b=4$ digits: The first leading digit can only be $1$ ( $1 \times 2^3$ ), and then, the remaining digits need to evaluate to $10 - 8 = 2$ and we can use the lookup : $f(2) = 2$ . Using $b=3$ digits we can use $1$ and $2$ as non-zero leading digits: $1$ will require a lookup $f(6)$ and $2$ will require a lookup of $f(2)$ , giving a sum of $6 + 2 = 8$ which is false (there are only $6$ ways to encode $10$ using $b=3$ bits) because $6$ itself can be encoded using $b=3$ bits and here I am considering two representations two times instead of one (if this makes sense). It seems to me like the lookup needs to be built such that it does not store $f(n)$ but $f(n, b)$ , i.e. the number of ways to encode $(n)_{10}$ in decibinary using $b$ bits (without a leading zero), which already seems like quite a complex (and inefficient) approach to me. Also each time I'd need to perform a check for a minimum number of bits needed to encode a number (e.g. $10$ cannot be encoded using $b=1$ ). What are your thoughts? Is there a neat and a simple way to find $f(n)$ ?","['combinations', 'combinatorics', 'discrete-mathematics', 'algorithms', 'computer-science']"
3540267,Checking if given matrix is perfect square of another matrix with real entries,"The question is from JEE Advanced(2017), where it asks to identify matrices which are the square of a matrix with real entries: I first found out the determinant of all the matrices. Options (A & B) both have negative determinant value and hence can't be expressed as square of a matrix with real entries. For explanation let any of the two be called as $A$ . Given they are square of another matrix(let $B$ ) so $B^2=A$ . Taking the determinant on both sides, I get $|B|^2=|A|$ and since $|A|$ is negative, I get $|B|^2<0$ . So $B$ can't have all real entries. Option C is $I$ whose square is $I$ or vice versa. I am having trouble with option D . Since it's determinant is also positive and I can't find a simple matrix which when squared gives that option. I have talked to my teacher . He said there is a method to find square root of a matrix but that's far beyond our level. I am a High school student studying in grade 12. So please, if possible, give a simplified hint/answer.
Thanks in advance!","['matrices', 'determinant', 'contest-math']"
3540342,"How to describe the function operation ""composition"", $\circ$, using the convention of function notation.","I am in the process of reading Tao's Analysis I after completing Pinter's A Book of Abstract Algebra (pretty new to maths). It recently occurred to me that all operations, ( $+,*, $ etc), seem to behave like functions. This made me think about the function operation of composition , $\circ$ , and how one could possibly define composition in the convention of function notation. I've been playing around with the notation a little bit, and this is what I have so far. Firstly, I'm pretty certain that composition behaves as a binary operation, and the domain is effectively the set of all ordered pairs of all functions (which I will call $T \times T$ ...where $T$ by itself is simply the set of all functions). From what I can tell, the only proposition $P(f,g)$ that needs to be fulfilled for composition is: $\forall x \in \operatorname {dom}(f), f(x) \in \operatorname{dom}(g)$ . Therefore, we have the following definition of composition: $\circ : T \times T \to T$ $(f,g)\mapsto h$ s.t. $\forall x \in \operatorname {dom}(f), f(x) \in \operatorname{dom}(g)$ I'm sure this is probably incorrect, so any assistance would be greatly appreciated! EDIT: After reading some of the comments, it seems like I need to make the following change: $(f,g) \mapsto h=g(f(x))$ s.t. $\forall x \in \operatorname {dom}(f), f(x) \in \operatorname{dom}(g)$","['notation', 'functions']"
3540443,Is it true that $f(X)$ is countable implies $f$ is measurable?,"Let $(X, \mathcal{A})$ and $(Y, \mathcal{B})$ be measurable spaces, and $f:X \to Y$ . We call $f$ is measurable if and only if $$\forall B \in \mathcal B: f^{-1} (B) \in \mathcal A$$ I would like to ask if $f(X)$ is countable implies $f$ is measurable. Thank you so much!","['measure-theory', 'measurable-functions']"
3540510,"Looking for class of functions $f_n$ with $n$ variables $(x_1,...,x_n)$ and $f_n=k_n a^{nâ1}$ if $x_i=a\;\forall i$","Is there a class of functions that fulfills or partly fulfills following conditions? For any $n\in\mathbb{N}_{>1}$ there is a function $f_n$ with following properties: $f_n$ is a function of $n$ variables, i.e. $f_n=f_n(x_1,...,x_n)$ with $x_i\ge0 \;\forall i$ if $x_i=a \;\forall i\;$ then $f_n=k_n a^{n-1}$ with $k_n>0$ $f_n\ge0$ $f_n=0$ iff $x_i=0 \;\forall i$ It is not known that 1-4 are sufficient conditions to define a unique function class but it would be good to know at least one class that fulfills all conditions. What is known? Following function scheme fulfills conditions 1,2 but not conditions 3,4 and might be a starting point: $$f_n=\frac{\prod_{i=1}^{n} x_i}{\frac{1}{n}\sum_{i=1}^{n} x_i}$$ As an expample $n=4$ is used: condition 1 fulfilled: $$f_4=\frac{x_1x_2x_3x_4}{\frac{1}{4}\left(x_1+x_2+x_3+x_4\right)}$$ condition 2 fulfilled: $$f_4=\frac{a\cdot a\cdot a\cdot a}{\frac{1}{4}\left(a+a+a+a\right)}=a^3 \;\;\;\text{with}\;\;\; k_4=1$$ condition 3 only fulfilled if $\neg(x_i=0\; \forall i)$ : $$\sum_{i=1}^n x_i\ge0 \land \prod_{i=1}^n x_i\ge0 \to f_4\ge0$$ condition 4 not fulfilled: $$f_4=\frac{0\cdot 1\cdot 1\cdot 1}{\frac{1}{4}\left(0+1+1+1\right)}=0 \nleftrightarrow x_i=0\; \forall i$$",['functions']
3540558,Show that $n= 5 + 5^2+ 5^3+...5^{150}$ is divisible by $930$.,"Show that $n= 5 + 5^2+ 5^3+...5^{150}$ is divisible by $930$ . I'm thinking to show that $n$ is divisible by each of the prime factors of $930$ , is that right? I'm stuck","['number-theory', 'elementary-number-theory']"
3540585,Arbitrary continuous function expressed by purely discontinuous composition,"I'm trying to determine whether the following statement is true. For any continuous function $h:\mathbb{R}\rightarrow\mathbb{R}$ , there exist two purely discontinuous functions $f, g : \mathbb{R}\rightarrow\mathbb{R}$ so that $h = f\circ g$ . Here a purely discontinuous function is one that is not continuous at any point. Think, $\chi_{\mathbb{Q}}(x) = \left\{\begin{array}{rl}
1 & x \in \mathbb{Q} \\
0 & x \notin \mathbb{Q} \\
\end{array}\right.$ , the indicator function of the rationals. I've thought of trying to do a construction along the lines of letting $f(x) = \left\{\begin{array}{rl}
h(x-1) & x \in \mathbb{Q} \\
h(x) & x \notin \mathbb{Q} \\
\end{array}\right.$ and $g(x) = \left\{\begin{array}{rl}
x+1 & x \in \mathbb{Q} \\
x & x \notin \mathbb{Q} \\
\end{array}\right.$ Then $(f\circ g)(x) = h(x)$ . It is clear that $g(x)$ is purely discontinuous, but $f(x)$ isn't necessarily. For example, if $h(x) = \sin(2\pi x)$ , then its period of $1$ would cause $f(x)$ to be continuous (indeed, $f$ would just equal $h$ ). Can this idea be tweaked to make a proof? Or is there a function one can construct that cannot be a composition of purely discontinuous functions?","['continuity', 'functions', 'function-and-relation-composition']"
3540603,Radial eigenfunctions of the Laplace operator in spherical coordinates,"I am trying to find solutions for the following ODE (which was derived trying to find the fundamental solution of the PDE $\Delta u+cu=0$ where $c > 0$ see below for the approach) The ODE is $v''(r)+\frac{2}{r} v'(r)+cv(r)=0$ I am not really sure how to solve this. I haven't done a computational ODE course, and I did look around but couldn't find any resource which tells a way to approach such problems clearly. Any help or at least a hint or a resource would be appreciated. As for solving the PDE, I was looking for radial solutions and thats how I arrived at the ODE. (Mainly following the Laplace Equation method from Evans). Please let me know if there is anything wrong with this approach too Thank You","['spherical-coordinates', 'ordinary-differential-equations', 'partial-differential-equations']"
3540641,"Location of zeros of the ""real part"" of a polynomial","I came across the following question on an old qualifying exam: Let $p$ be a polynomial, all of whose zeros lie in the lower half plane $\lbrace z : \text{Im}(z) < 0 \rbrace$ . Let $a$ and $b$ be the unique pair of polynomials with real coefficients such that $p(z) = a(z) + ib(z)$ . Prove that $a$ and $b$ have only real zeros. I tried to think of a creative way of using the argument principle to approach this, but my attempts so far have been unsuccessful. Does anyone have any insight into this problem? A solution or hint would be appreciated.","['complex-analysis', 'roots', 'polynomials']"
3540666,How to find the orthogonal projection of a vector onto an arbitrary plane?,"We have an arbitrary plane $H$ (not necessarily a linear subspace) described by the equation $\theta_0 + \theta \cdot x = 0 $ , where $\theta_0$ is the offset parameter (a scalar) and $\theta_= [\theta_1, \theta_2, \theta_3]^T$ is an orthogonal vector, not necessarily of unit length. What is the formula for the orthogonal projection of an arbitrary vector $v \in \mathbb{R}^3$ onto this plane? How do we derive it? In other words, I'm looking for an expression for the vector in $H$ that represents the orthogonal projection of some arbitrary vector $v \in \mathbb{R}^3$ onto $H$ , in terms of $v$ , $\theta$ , $\theta_0$ , and their dot products only.","['linear-algebra', 'geometry', 'plane-geometry']"
3540670,Number of solution of a rational sum,"Let $$f(x)=\sum\limits_{i=1}^{2020}\frac{i^2}{x-i}$$ . Then, what is the number of solutions of $f(x)=0$ ? I am struck at this problem. Specifically, would not $f(x)$ become undefined when $i=x$ . Since the numerator is always positive, therefore the sum becomes zero only when there are points when $x>i $ and $x<i$ . Then, would not a point when $x=i$ appear? Any hints? Thanks beforehand.","['calculus', 'rational-functions', 'sequences-and-series']"
3540682,$x+y$ is closed or discrete map,"Is not the function $f:\mathbb{R}^2\to\mathbb{R}$ defined by $f(x,y)=x+y$ a closed map? And will not the image of any discrete set in $\mathbb{R}^2$ be discrete? I think it should be a closed map and that the image of any discrete set under $f$ must be discrete. Since $f$ is continuous and surjective, therefore, I think it must also take closed sets to closed sets. The portion concerning discrete sets seems obvious I think. Am I wrong? Thanks beforehand.","['multivariable-calculus', 'calculus', 'general-topology', 'real-analysis']"
3540683,When does a proof need to be proved both ways?,"I am very sorry I understand that the title is confusing, but I am not totally sure how to reword it because I am completely lost on this subject. I am taking a discrete mathematics course right now, and one subject that is confusing me is proofs. I understand the basic methods of proving usually start with an implies statement or an if...then statement, but in class there are times when it seems we need to prove it going both ways. Like we start with ""Prove: If A, then B"" and we need then need to prove both ""If A, then B"" and ""If B, then A"".  I am completely lost because I don't know when this style of proof is needed.  I have also heard the term ""If and only if Proofs"" getting thrown around and this confuses me even more because I don't know if they are using direct proofs or contradiction. I understand if this gets downvoted because I have no idea what I am talking about right now. But, any honestly any advice on how to get started with understanding this topic would be great.",['discrete-mathematics']
3540701,Existence of fixed point for a continuous function on an infinite closed set,"Why is it that a continuous surjection from $X\to X$ has a fixed point when $X=[1,2]\cup[3,\infty)$ and $X=[3,\infty)$ but not when $X=[1,2]\cup[3,7]$ ? When $X=[3,\infty)$ , since the set is closed and connected, therefore the image should also be connected, whence it seems intuitive to expect a fixed point. But, how does $[1,2]\cup[3,\infty)$ have a fixed point but $[1,2]\cup[3,7]$ does not? Any rigorous reasoning? Thanks beforehand.","['fixed-points', 'fixed-point-theorems', 'real-analysis', 'calculus', 'general-topology']"
3540713,Maximum cardinality of a subspace of a vector space on a finite field,Let $k$ be a field with five elements. Let $V$ be the $k$ -vector space of $5\times1$ matrices with entries in $k$ . Let $S$ be a subset of $V$ such that $u^t v=0$ for all $u$ and $v$ in $S$ . What is the maximum possible cardinality of $S$ ? The question seems to be asking the maximum number of mutually orthogonal vectors over $k$ . How do we compute it? Is it same as the number of orthogonal matrices over $k$ ? Thanks beforehand.,"['finite-fields', 'linear-algebra', 'vector-spaces']"
3540756,Understanding the determinant of an infinite matrix,"The fredholm determinant of an infinite matrix $A$ is defined by $$
\det(I+A) = \exp(\text{tr}(\log(I+A))).
$$ I'm trying to understand the formula and how to use it. To be concrete here are my questions: Let $$
A=I=\begin{pmatrix}1 & 0 & 0 & \ldots \\
0 & 1 & 0 & \ddots  \\
\vdots & \ddots & \ddots &\ddots \\
\end{pmatrix}
$$ ( $A$ is the infinite matrix with diagonal elements equal to 1 and 0's everywhere else). If $A$ were finite dimensional then mutlipyling the diagonal elements, the determinant equals 1. It seems natural that the infinite matrix should also have determinant equal to 1 but I don't see how the above formula gets this. What about a triangular matrix with diagonal elements  equal to 1?
What about a diagonal matrix with elements not equal to 1? Why is the definition not $\det(A) = \exp(\text{tr}(\log(A)))$ ? Say $\det(I+A)=3$ then what is $\det(A)$ ?","['matrices', 'determinant', 'linear-algebra', 'functional-analysis']"
3540781,Mathematics for Computer Science Prob. 2.6 Well Ordering Principle,"Problem (From Mathematics for Computer Science (Lehman, Leighton, Meyers), Prob. 2.6) You are given a series of envelopes, respectively containing 1, 2, 4,
..., $2^m$ dollars. Define Property m : For any nonnegative integer less than $2^{m+1}$ , there is a selection of envelopes whose contents add up to exactly that number of dollars. Use the Well Ordering Principle (WOP) to prove that Property m holds for all nonnegative integers m . Hint : Consider two cases: first, when the target number of dollars is less than $2^m$ and second, when the target number is at least $2^m$ . Solution attempt Let's refer to Property m as $P(m)$ to make things simpler. Let $C$ be the following set: $C = \{ m \mid \text{P(m) doesn't hold for } m\}$ Then, by the WOP, there is a smallest integer $m_0$ in $C$ . $P(m)$ holds for m = 0, since any nonnegative integer less than $2^{0+1} = 2$ can be represented with a selection of envelopes (the integer $0$ can be represented by a selection of no envelopes, and the integer $1$ can be represented with the envelope containing $1$ ). So, $m_0 > 0$ . Also, $P(m_0-1)$ holds (since $m_0-1 < m_0$ ), which means that all nonnegative integers less than $2^{m_0}$ can be represented by a selection of envelopes that contain up to $2^{m_0-1}$ . Since $P(m_0)$ is false, this means that there is a nonnegative integer $c$ less than $2^{m_0 + 1}$ such that $c$ can't be obtained by a selection of the envelopes $1$ , $2$ , $4$ , ..., $2^{m_0}$ . From the above paragraph, we know that $c < 2^{m_0+1}$ , and, from the fact that $P(m_0-1)$ holds, we know that $c \geq 2^{m_0}$ . So: $2^{m_0} \leq c < 2^{m_0+1}$ To show that there is a contradiction, there are two cases: If $c$ is even: Dividing the above inequality by 2, $2^{m_0-1} \leq c/2 < 2^{m_0}$ . So, since $c/2$ is smaller than $2^{m_0}$ , $P(c/2)$ holds and $c/2$ can be represented by a selection of envelopes. However, this means that $2(c/2) = c$ can also be represented as a selection of envelopes, which is a contradiction. If $c$ is odd: Subtracting 1 from the above inequality and dividing it by 2, $2^{m_0-1} - 1/2 \leq (c - 1)/2 < 2^{m_0} - 1/2$ . Since $(c - 1)/2$ is smaller than $2^{m_0}$ , $P((c - 1)/2)$ holds and $(c - 1)/2$ can be represented by a selection of envelopes. However, this means that $2((c - 1)/2) + 1 = c$ can also be represented as a selection of envelopes, which is a contradiction. So, $C$ is empty and $P(m)$ holds for all nonnegative integers $m$ . I didn't use the provided hint in my solution attempt, which makes me think that there might be something incomplete about this attempt.
Is there anything missing from this proof attempt?","['well-orders', 'proof-writing', 'solution-verification', 'discrete-mathematics']"
3540820,Bundle cohomology under a flop,"This question is about the behaviour of line bundle cohomologies under flops. Specifically, my question is: is the (dimension of the) zeroth cohomology of a line bundle preserved by a flop? This is motivated by the following example. For a toric variety, a flop corresponds to a change of the triangulation of the associated fan. But the zeroth cohomology of a line bundle is determined by the toric rays / weight system alone, i.e. it is unaffected by the triangulation. Hence it is unaffected by a flop. Is the same true for more general varieties? Or is this specific to toric varieties? A couple of notes: I have only been able to find statements about quantum cohomology being preserved, but this is too unfamiliar, so I do not understand the consequences. The zeroth line bundle cohomology is the same as the complete linear system of the associated divisor, and I am happy to discuss in either terminology.","['algebraic-geometry', 'homology-cohomology', 'algebraic-topology']"
3540844,$ \int_{E} |f|d\mu \Leftrightarrow \sum_{n=1}^{\infty}{\frac{1}{n^2} \int_{E}f^21_{\{|f|\leq n\}}d\mu} $,"Let $(E,\mathcal {A},\mu)$ be a finite measure space. Let $f:(E,\mathcal{A}))\to (\mathbb {R},\mathcal{B}(\mathbb{R})) $ be a measurable function. Show that : $$
\int_{E} |f|d\mu <\infty \Leftrightarrow \sum_{n=1}^{\infty}{\frac{1}{n^2} \int_{E}f^21_{\{|f|\leq n\}}d\mu} <\infty
$$ My first step of demo is : we have : $$
\sum_{n=1}^{\infty}{\frac{1}{n^2} \int_{E}f^2 1_{\{|f|\leq n\}}d\mu} =\sum_{n=1}^{\infty}{\frac{1}{n^2} \int_{E}f^2 1_{\biguplus_{k=0}^{n-1}\{k<|f|\leq k+1\}}d\mu} = \sum_{n=1}^{\infty}{\frac{1}{n^2} \sum_{k=0}^{n-1}\int_{E}f^2 1_{\{k<|f|\leq k+1\}}d\mu} = \sum_{k=0}^{\infty}  \left(\sum_{n=k+1}^{\infty}{\frac{1}{n^2}}\right) \left(\int_{E}f^2 1_{\{k<|f|\leq k+1\}}d\mu\right)
$$ but i can't continue, an idea please",['measure-theory']
3540888,Doob's Decomposition Theorem and Uniform Integrability,"Let { $X_n$ } be a uniformly integrable $(F_n)$ -submartingale and $
\tau$ be the collection of all $F_n$ -stopping times. Prove that { ${X_T: T \in \tau}$ } is uniformly integrable. I want to use Doob's Decomposition to show that this also holds for submartingales. By Doob's Decomposition Theorem, we have that $X_n=M_n+A_n $ , where $A_n $ is an increasing $F_n$ -predictable process, and $M_n$ is a $(F_n)$ -martingale. Now we just have to show that $M_n$ and $A_n$ are uniformly integrable. I've shown that { $M_T$ } is uniformly integrable. Now I just have to show that it also holds for { $A_T$ }. But I'm not sure how to proceed from here. Please help. Thank you!","['uniform-integrability', 'stochastic-processes', 'martingales', 'stopping-times', 'probability-theory']"
3541001,"Elements of $H_1(SO(3), \mathbb{Z}_2)$","I am currently reading this paper: https://arxiv.org/abs/gr-qc/9512041 . 
It is investigating the spin structures connection to skein modules. I'm having a hard time understanding a part of the proof of theorem 1. We have a bundle of orthonormal frames.  The author describes the lifts of two diagrams (to this bundle) as being specific elements in $H_1(SO(3), \mathbb{Z}_2)$ . Of the diagram above, the author says: ""Therefore the difference in their homology classes is just the homology class of the lift of $p_1$ , which consists of oriented differentiable segments. The lift of $p_1$ is a continuous curve and its homology class is zero.""
Why is the lift of oriented differentiable segments to the bundle of orthonormal frames a continuous curve? Of this diagram, the author says: ""this time the homology class of $\tilde{p_2}$ is the generator of $H_1(SO(3), \mathbb{Z}_2)$ ."" I guess I'm just struggling to understand what the lifts of these diagrams look like in the tangent bundle. Also, the arrows on the diagrams are confusing me. Any insight would be appreciated.","['general-topology', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
3541051,"$f(x)=\max|x_i|, f(Ax)=f(x), \forall x \in \mathbb{R}^n \Rightarrow A^m=I$","Let $f(x) = \max|x_i|, \forall x=(x_1, x_2, \dots, x_n)^T \in \mathbb{R}^n$ and a matrix $A \in M_n[\mathbb{R}]$ such that $f(Ax)=f(x), \forall x \in \mathbb{R}^n$ . Prove that $\exists m \in \mathbb{Z}^+, A^m=I $ . Here my attempts: Suppose $A = [a_1, a_2, \dots, a_n]$ and I choose $x = \{e_1=(1, 0, \dots, 0), e_2=(0, 1, \dots, 0), ..., e_n=(0, 0, \dots, 1)\}$ so that $f(Ae_i)=\max a_i=f(e_i)=1$ which means maximum absolute value of each column of $A$ is $1$ . Can anyone give me some hints?","['functions', 'linear-algebra']"
3541057,$S_n$ converging in $S$,"We have a sequence $\{X_n\}_{n\ge 1}$ given (i) $EX^2_n <\infty$ for all $n\ge 1$ ,also (ii) $E(X_m X_n)=0$ for all $ m\not =n$ and (iii) $\sum ^ \infty _ {n=1} EX^2_n <\infty$ I was trying to show that if $S_n=\sum ^ n _ {j=1} X_j$ for all $n\ge 1$ $$$$ Then $S_n$ converges in $L^2$ to some $S$ . $$$$ ( Even though I think that I probably have to show first that $S_n=\sum ^ n _ {j=1} X_j$ is Cauchy in $L^2$ and after use the fact that $L^2$ is complete. I feel like I am missing something  ). So I started like below. $sup_{m>n} E [ (S_m-S_n)^2] = sup_{m>n} E [ (\sum ^ m _ {j=n+1} X_j)^2]  =  sup_{m>n} E [ (\sum ^ m _ {j,k=n+1} X_j X_k)] = sup_{m>n}\sum ^ m _ {j,k=n+1} E[  X_j X_k ] = sup_{m>n}\sum ^ m _ {j=n+1} E[  X_j^2  ]= \sum ^ \infty _ {j=n+1} E[  X_j^2  ] \to0        $ as $n\to \infty$ Hence, $S_n $ is Cauchy in $L^2$ . If I have done everything correctly how do I finish the proof? is it enough to infer that $S_n$ converges in $L^2$ to some $S$ just from the completeness of $L^2$","['self-learning', 'measure-theory', 'probability-theory', 'random-variables']"
3541092,Assume that $\int_{a}^{ab} f(x) dx$ is independent of $a$. Prove $f(x)=\frac{c}{x}$,"Assume $f$ is integrable on $[0,\infty)$ and assume that for $a,b>0$ , the value of $\int_{a}^{ab} f(x) dx$ is independent of $a$ . Prove that $f(x)=\frac{c}{x}$ , where $c$ is a constant. I have tried several things, like showing $g(x)=xf(x)$ must have derivative zero, but I am unsure how to use the integral assumption. Thanks!","['calculus', 'real-analysis']"
3541122,Can a set of functions be orthogonal w.r.t. more than one weight function?,"A random thought that I had: suppose you have a set of real-valued one-dimensional functions $\{f_i(x)\}$ which are: Smooth over the domain of interest. Orthogonal with respect to integration against some weight function $w_1(x)$ (which is also smooth over the domain of interest): $$\int_a^b f_i(x) f_j(x) w(x)\,dx=\delta_{ij} $$ Complete for smooth functions defined over that interval, i.e. any smooth function can be written as a series expansion in $\{f_i(x)\}$ : $$g(x)=\sum_{n=0}^{\infty} c_n f_n(x)$$ Is it possible for the same set of functions $\{f_i(x)\}$ to be orthogonal with respect to a separate weight function $w_2(x)$ , which is independent from $w_1(x)$ ? (i.e. the Wronskian of the two functions is non-zero everywhere) If yes, can you provide an example?","['linear-algebra', 'ordinary-differential-equations', 'real-analysis']"
3541143,"2018 MathCounts: Let $D(k)$ be the number of diagonals for a polygon with $k$ sides. If $D(m) + D(n) = 125$, what is the value of $m+n$?","The question was asked in the 2018 Raytheon MATHCOUNTS National Competition. It appears in the video around the 35:34 mark: https://www.youtube.com/watch?v=dSnOLW_W6og&t=2134 Let $D(k)$ be the number of diagonals for a polygon with $k$ sides. If $D(m) + D(n) = 125$ , what is the value of $m+n$ ? The formula for the number of diagonals is well-known and easily derived as $k(k-3)/2$ . I then computed several values, and found a suitable pair of numbers to solve the problem. But is there any easier way to solve this equation: $$\frac{n(n-3)}{2} + \frac{m(m-3)}{2} = 125$$ $$n,m \in {3, 4, ...}$$ The students were supposed to solve this in minutes without a calculator. My guess is there is not a simpler way--in MathCounts the students may have just memorized many values.","['elementary-number-theory', 'geometry']"
3541290,Can derivatives have simple poles?,"Let $f$ be be holomorphic on the punctured disk $D'(z_0,r)$ with $z_0$ being an isolated singularity. Is it possible for $f'$ to have a simple pole at $z_0$ ? Just looking at the Laurent expansion of $f$ about $z_0$ I think the answer should be ""No"". I am somewhat unsure about this. Can anyone help me out?","['complex-analysis', 'singularity', 'laurent-series']"
3541310,"Let $A, B$ be square matrices of equal size ($n \times n$) and $A^2 + B =A^2B$. Prove that $AB=BA$","I need help with solving the problem about square matrices of equal size.
I know that if $A + B = AB$ , then $AB = BA$ , but I can't prove this one.
Please advise how to solve or think about this.
Thanks in advance )",['matrices']
3541313,What is the point of the definition $\lim_{n \to \infty }\sup A_n$ for events $A_n$?,"I'm looking to get to grips with the purpose of this definition.
"" Let $(\omega,\mathbb{F},P)$ be a probability space and let $A_n$ belong to $\mathbb{F}$ for $n \geq 1$ .
We define $$\limsup_{n\to \infty}A_n:=\bigcap_{n=1}^{\infty}\bigcup_{k=n}^{\infty}A_k$$ "" In the notes through which I am working, it says that $$\bigcap_{n=1}^{\infty}\bigcup_{k=n}^{\infty}A_k$$ is the event that infinitely many of $A_n$ occur.
But why is this definition necessary if we can say that $$\bigcap_{n=1}^{\infty}A_n$$ is the event that infinitely many of the A_n occur? I feel that there's a subtlety that I'm overlooking at the moment...","['elementary-set-theory', 'limsup-and-liminf', 'probability-theory', 'probability']"
3541319,An integral estimate regarding tails of solutions in Di CastroâKuusiâPalatucci,"Let $x_0 \in \mathbb{R}^n$ and suppose $u \colon B_r(x_0)\to(0,\infty)$ be an $L^p$ integrable function and let $k=\sup_{x \in B_r(x_0)} u(x)$ .
Also let $\phi\in C_c^{\infty}(B_r(x_0))$ be such that $0 \le \phi\le 1$ in $B_r(x_0)$ , $\phi \equiv 1$ on $B_{\frac{r}{2}}(x_0)$ and $|\nabla\phi| \le \frac{c}{r}$ in $B_r(x_0)$ .
Then for $y\in \mathbb{R}^n\setminus B_r(x_0)$ and $x\in B_r(x_0)$ , we have \begin{multline}
\int_{\mathbb{R}^n\setminus B_r(x_0)}\int_{B_r(x_0)}|u(x)-u(y)|^{p-2}(u(x)-u(y))(u(x)-2k)\phi^p(x)\,dx dy \\
\ge \int_{\mathbb{R}^n\setminus B_r(x_0)}\int_{B_r(x_0)}k(u(y)-k)_{+}^{p-1}\phi^p(x)\,dx dy \\
-\int_{\mathbb{R}^n\setminus B_r(x_0)}\int_{B_r(x_0)}2k\chi_{\{u(y)<k\}}(y) \cdot (u(x)-u(y))_{+}^{p-1}\phi^p(x)\, dx dy.
\end{multline} This has been written in this article on page 17. Can someone kindly help with how to get it?","['integration', 'parabolic-pde', 'analysis', 'partial-differential-equations', 'regularity-theory-of-pdes']"
3541391,FrÃ©chet Derivative of a functional appearing in variational calculus,"I would like to compute the FrÃ©chet derivative of the functional $$ J: C^1[a,b] \rightarrow \mathbb R$$ $$y \mapsto \int_a^b L(x,y(x),y'(x)) \, dx $$ where $L$ is $C^2$ in all components. The FrÃ©chet derivative of $J$ in a point $y$ is defined to be the bounded linear operator $A_y$ such that $$\lim_{||h||_{C^1([a,b])} \rightarrow 0} \frac{|J(y+h) -J(y) -A_yh|}{||h||_{C^1([a,b])}}=0$$ In my book, it says it is easily computable by Taylor expansions, but I really do not see how. They just go from there to Euler-Lagrange equation immediately. Online, I saw many convincing heuristics but no rigorous proof using the definition of the FrÃ©chet derivative.","['derivatives', 'functional-analysis', 'analysis', 'real-analysis']"
3541410,Explain why Mandelbrot set escape radius is 2 to a dummy,"I'm curious, in the Mandelbrot set, why is the escape radius $2$ ? I've seen few proofs of that on the internet, but i can't understand them enough. Why is the bailout value of the Mandelbrot set 2? Mandelbrot sets and radius of convergence https://mrob.com/pub/muency/escaperadius.html Some of the statements in them seem ""out of the blue"" for me. For example, in the second in-site link I gave above: $ |c|â¤2 \Rightarrow|z_n+1|â¥|z_n|2â|c|>2|z_n|â2$ Where does $2|z_n|â2$ come from?","['complex-analysis', 'complex-numbers', 'fractals']"
3541435,"One to one correspondence between all $F[x]$-module $V$ and all linear transformations $T\colon V\to V$, $V$ being a vector space over $F$.","I am fairly a beginner in module theory. While discussing the $F[x]$ -modules, my text book (Dummit & Foote) describes: $\left\{
    V \text{ an } F[x] \text{-module}
\right\}\longleftrightarrow \left\{
\begin{aligned}
    V \text{ is a vector space }\\
    \text{               and               }\\
T\colon V\to V \text{ a linear transformation }\end{aligned}
\right\}\tag*{}$ given by $\text{ the element } x \text{ acts on } V \text{ as the linear transformation } T\tag*{}$ This is saying that we can't find any $F[x]$ -module without specifying the linear transformation $T$ . But how can we exclude the possibility of having some other $F[x]$ -module which can be obtained without the help of the linear transformation $T\colon V\to V$ ? Is it the case that if $x$ acts on the vectors $v\in V$ , then it must be a linear transformation? If it is the case, how can I prove it?","['abstract-algebra', 'linear-algebra', 'linear-transformations', 'modules']"
3541466,Is it true that $\int_0^t W_s ds = tW_t?$,"Given a Brownian motion $(W_t)_{t\geq 0},$ it is well-known that $W_t^3$ is not a Brownian motion as its SDE $$d(W_t^3) = 3W_t^2 dW_t + 3W_t dt$$ contains a nonzero drift term.
To make it to be a martingale, one can consider $$W_t^3 - 3\int_0^t W_s ds.$$ On the other hand, this post shows that $W_t^3 - 3tW_t$ is a martingale. Question: Is it true that $$\int_0^t W_s ds = tW_t?$$ I have a feeling that they are no equal as LHS is deterministic whereas RHS is random.","['stochastic-integrals', 'brownian-motion', 'stochastic-calculus', 'probability']"
3541519,Solving the sequence $a_{n+1}=a_{n}a_{n-1}+\sqrt{(a_n^2-1)(a_{n-1}^2-1)}$: proving that $2+2a_n$ is a perfect square,"Question: Let $a_1=a_2=97$ and $a_{n+1}=a_{n}a_{n-1}+\sqrt{(a_n^2-1)(a_{n-1}^2-1)}$ for $n>1$ . Prove that (a) $2+2a_n$ is a perfect square, and (b) $2+\sqrt{2+2a_n}$ is a perfect square. I changed the given recursive formula by squaring, and the result was as follows: $$(a_{n+1}^2+a_n^2+a_{n-1}^2)-2a_{n+1}a_na_{n-1}-1=0$$ $\Rightarrow$ $$(a_{n+1}+a_n+a_{n-1})^2-2(a_{n+1}a_n+a_na_{n-1}+a_{n-1}a_{n+1}+a_{n+1}a_na_{n-1})-1=0$$ $\Rightarrow$ $$(1+a_{n+1})^2+(1+a_n)^2+(1+a_{n-1})^2-2(a_{n+1}+a_n+a_{n-1}+a_{n+1}a_n+a_na_{n-1}+a_{n-1}a_{n+1}+a_{n+1}a_na_{n-1}+1)-2=0$$ $\Rightarrow$ $$(1+a_{n+1})^2+(1+a_n)^2+(1+a_{n-1})^2-2(1+a_{n+1})(1+a_n)(1+a_{n-1})-2=0$$ And consequently, I lost the way :( I thought of proving in a inductive way, that is : $$2+2a_1=196=14^2$$ When we set $2+2a_n=k^2$ , $2+2a_{n-1}=l^2$ , $$ 2+2_{n+1}=\frac{(k^2-2)(m^2-2)}{4}+\sqrt{\left(\left(\frac{k^2-2}{2}\right)^2-1\right)\left(\left(\frac{m^2-2}{2}\right)^2-1\right)}$$ As a result, I again lost the way :/ I think I sill have not got the main points. Could you give me some clues about this problem? Thanks.","['square-numbers', 'calculus', 'recurrence-relations', 'sequences-and-series']"
3541524,Is it true that $|\arcsin z | \le |\frac {\pi z} {2} |$?,"Decide whether the following ie true  or false $$\lvert\arcsin z \rvert \le \left\lvert \frac {\pi z} {2} \right\rvert $$ whenever $z\in\Bbb C$ . $\arcsin z =-i \text{Log } (\sqrt{1-z^2}+iz)$ , $\text{Log }z=\log|z|+i\arg z,\arg z\in(-\pi,\pi] $ The problem is related to the series $\sum_{n=1}^{\infty}\arcsin(n^{-2}z) $ converges normally in the whole complex plane .","['complex-analysis', 'inequality', 'functional-inequalities']"
3541555,"ODE, and Questioning Method","I have a question about the method used to answer this question: IVP, and ODE problem $$\frac{dy}{dx}=ye^{-x^2} \ \ \ \ \ \ y(4)=1 $$ \begin{align}
\frac{dy}y&=\int e^{-x^2}dx \\
\ln(y)&=\int(e^{-x^2})dx \\
\end{align} Then this is where I get confused the work suddenly jumps to the following: \begin{align}
\frac{dy}y&=e^{-x^2}dx \\
\frac{1}{y}\frac{dy}{dt}dt&=e^{-x^2}dx \\
\int_4^x\frac{1}y\frac{dy}{dt}dt&=\int_4^xe^{-t^2}dt \\
\ln(\lvert(y(t)\rvert)\Bigg\vert_4^x&=\int_4^xe^{-t^2}dt
\end{align} The final answer is the following: $$y=e^{\int_4^xe^{-t^2}dt}$$ My Question My question is could someone explain the use of the dummy variables, and how the method actually works? Because I am confused about the final answer to the ODE.","['calculus', 'ordinary-differential-equations']"
3541556,The amount of $n$ so that $n!+1$ is divisible by $p$,Consider any prime number $p$ and sequence $(n!+1)_{n=1}^{\infty}$ How many elements from this sequence are divisible by p? Let's denote this number as $f(p)$ I know that $f(p)$ is finite since for all $n\ge p$ ; $n!+1$ is not divisible by $p$ . I also know that from Wilson theorem we have $p|(p-1)!+1$ so $f(p)\ge1$ . What is upper bound for $f(p)$ ? Regards,"['number-theory', 'factorial', 'divisibility']"
3541578,Has anyone used the Atiyah-Singer Index Theorem in number theory?,"The Atiyah-Singer Index theorem is one of the most influential theorems in geometry/PDE/topology. It generalizes many previous theorems in geometry such as $V - E + F = 2$ , Gauss-Bonet theorem, Riemann-Roch theorem, etc. Part of Tate's thesis was to prove the Riemann-Roch theorem for curves over finite fields, this was done through the use of the Poisson summation formula in harmonic analysis. It is my understanding that the Poisson summation formula has also a lot of depth and has been generalized in the form of the Selberg trace formula. My question is if these two ""families"" of theorems meet again. Perhaps more specifically, has there been a significant use of the Atiyah-Singer Index theorem in problems of number theory or representation theory?","['number-theory', 'representation-theory', 'algebraic-topology', 'differential-geometry']"
3541609,$-1$ is not a sum of two squares in $\mathbb{Q}(\sqrt{-7})$,"The question is the following:
Prove that $-1$ is not the sum of two squares in $\mathbb{Q}(\sqrt{-7})$ . I have a solution which makes use of Algebraic Number Theory, namely the Dirichlet Unit Theorem about units in a number field. Hopefully this solution is correct. Suppose that $x^2 + y^2 = -1$ with $x, y \in \mathbb{Q}(\sqrt{-7})$ . By working in $\mathbb{Q}(\sqrt{\pm 7})$ , we can factor this as $(x+iy)(x-iy) = -1$ , where $x, y \in \mathbb{Q}(\sqrt{-7})$ . It follows that $x+iy$ is an element with complex absolute value $1$ , for any embedding $\mathbb{Q}(\sqrt{\pm 7}) \hookrightarrow \mathbb{C}$ , so by the Dirichlet Unit Theorem it follows that $x+iy$ is a root of unity, which must be inside $\mathbb{Q}(\sqrt{\pm 7})$ . However it is not too difficult to find that those are $\pm 1, \pm i$ and those do not give solutions to the equation. However I am wondering if there is a more elementary solution to this problem, especially one that does not require the use of the Dirichlet Unit Theorem.","['field-theory', 'number-theory', 'sums-of-squares', 'algebraic-number-theory']"
3541617,Bound for the sum of vectors in $\mathbb{R}^n$,"I have the following problem (it seems to be very famous, but I couldn't find reference) Problem. Given $k$ vectors $v_1,v_2,\ldots,v_k\in\mathbb{R}^n$ such that for each $i$ the inequality $|v_i|\leq 1$ holds (here $|v|$ is the euclidean $|\cdot|_2$ norm). Prove that there exist $\varepsilon_1,\varepsilon_2,\ldots,\varepsilon_k\in\{-1,1\}$ such that the following inequalty holds $$
\left|\sum_{i=1}^{k}\varepsilon_i v_i\right|\leq\sqrt{n}.
$$ For $k\leq n$ it can be shown by probabilistic argument (i. e. by averaging $\left|\sum\varepsilon_i v_i\right|^2$ over all $2^k$ possible $k$ -tuples $(\varepsilon_1,\varepsilon_2,\ldots,\varepsilon_k)\in\{-1,1\}^n$ ). However, this approach can't be extended for $k>n$ . Moreover, this bound is sharp because we can take any orthonormal basis $v_1,v_2,\ldots,v_n$ in $\mathbb{R}^n$ and then inequality will turn to equality (for any choice of $\varepsilon_i$ ). It's unclear for me how even to solve the problem in case $n=2$ . So, how to solve this problem? Update. It seems that this is an open problem for $n\geq 3$ (found the following question on MO: https://mathoverflow.net/questions/272373/balanced-vectors )","['discrete-geometry', 'combinatorics', 'vectors']"
3541677,Exercise about the fixed point,"I'm studying the fixed point and I found this exercise on my text book.  I've tried to study the function: $f(x)=x^2+1/4$ and find the possible fixed attracting or repelling point. Now I find that the fixed point $x=1/2$ but now to prove if it is a repelling or an attracting fixed point it's a little bit difficult.
I've two general definition of this two type of points but I can't find a way to apply it correctly.","['analysis', 'real-analysis']"
3541685,Vector in kernel of all linear functionals must be $0$,"Let $E$ be a vector space over a field $K$ . Suppose that $e\in E$ is such that $\forall f\in \mathcal L(E,K)$ , $f(e)=0$ . Then prove that $e=0$ . Elements of $\mathcal L(E,K)$ need not be continuous. This is claimed in the Remark following Definition 3.2 in Fabian's Banach Space Theory . I quote ""[it] follows from a simple linear algebra argument"". What is this ""simple linear algebra argument"" they are alluding to ? With the axiom of choice, one could define a basis $(b_i)_{i\in I}$ of $E$ and the corresponding coordinate functionals $f_i$ . Then obviously $e=0$ . Is there a simpler argument, preferably something that doesn't resort to choice ?","['linear-algebra', 'functional-analysis']"
3541732,Limits with $a_n+\log a_n = 1+\frac{1}{n}$,"If $a_n+\log a_n = 1+\dfrac{1}{n}$ , compute: $\lim_\limits{n\to \infty}a_n$ $\lim_\limits{n\to \infty} n(a_n-1)$ If $a_n$ is convergent to $l$ , then passing to limit $l+\log l = 1$ . But $f(x)=x+\log x$ is increasing, so unique solution is $l = 1$ . But I don't know how to prove $a_n$ is bounded and monotonic.",['limits']
3541848,Tangent space of a product of algebraic group.,"I need help with this problem from Shafarevich Basic Algebraic Geometry . Let $G$ be an algebraic group and $\Psi:G\times G\rightarrow G$ the
  regular map defined by the group law. Let $T_{e}G$ and be $T_{e'}(G\times G)$ the tangent spaces to $G$ and $G\times G$ at their
  respective identity elements. Prove that $T_{e'}(G\times G)=T_{e}G\oplus T_{e}G$ and that $d_e \Psi:T_{e}G\oplus
 T_{e}G\rightarrow T_{e}G$ is given by addition of vectors. I tried this way but I'm not acquainted with the tensor product. Let $T_{e'}(G\times G)=\left( \frac{M_{e'}}{M_{e'}^2} \right)^{*}$ where $M_{e'}=\{ f\in k[G\times G]\mid f(e')=0 \}$ . But $k[G\times G]=k[G]\otimes_k k[G]$ so $M_{e'}=M_{e}\otimes M_{e}$ .
Then $$T_{e'}(G\times G)=\left( \frac{M_{e'}}{M_{e'}^2} \right)^{*} = \left(\frac{M_{e}}{M_{e}^2} \otimes \frac{M_{e}}{M_{e}^2}\right)^{*}=T_e G\oplus T_e G$$ . I'm not sure about the second and the third equalities. Could you help me, please? Thanks!","['algebraic-geometry', 'algebraic-groups', 'tangent-spaces']"
3541872,Proof of lack of memoryless property,"Consider a chain which is not Markov that waits a time $T^{*}$ before leaving the current state, where $T^{*}$ has uniform distribution over the set of times $\{1, 2, 3, 4\}$ . I would like to show that it does not hold the memoryless property, i.e: $$\Bbb P(T \gt t+s \mid T \gt t)= \Bbb P(T \gt s)$$ So, here's how I tackle the problem: I deduce that $T^{*}\sim\mathcal U\{1,4\}$ (discretely uniformly distributed on the interval $[1,4]$ . So, the support is $x\in \{1,2,3,4\}$ The cumulative distribution function is: $$\text{CDF}= \frac{\lfloor x \rfloor - 1+1}{4} = \frac{\lfloor x \rfloor}{4}= \Bbb P(T \leq x)$$ $$\Rightarrow 1- \text{CDF} = \Bbb P(T \geq x)= 1- \frac{\lfloor x \rfloor}{4}= \frac{4-\lfloor x \rfloor}{4}$$ $$\Rightarrow \Bbb P(T \geq s+t | T \geq t)= \frac{\Bbb P(T\geq s+t ; T\geq t)}{\Bbb P(T \geq t)}= \frac{\Bbb P(T \geq s+t)}{\Bbb P(T \geq t)} = \frac{\frac{4- \lfloor s+t \rfloor}{4}}{\frac{4- \lfloor t \rfloor}{4}}= \frac{4 - \lfloor s+t \rfloor}{4 - \lfloor t \rfloor} \neq \Bbb P(T\geq s) = \frac{4- \lfloor s \rfloor}{4}$$ Hence $T^{*}$ does not hold the memoryless property Is this alright? Also, if $(W_k)_{k\geq}$ would be a stochastic process constructed so that it stays in each state $i$ for a time distributed to $T^{*}$ , what would be an intuitive explanation of why this is not a Markov chain?","['markov-chains', 'markov-process', 'probability-theory', 'probability', 'random-variables']"
3541910,Limit of $a_n = \frac{1}{1^3\cdot 1}+\frac{1}{1^3\cdot 2+2^3\cdot 1}+\cdots+\frac{1}{1^3\cdot n+2^3\cdot (n-1)+\cdots+n^3\cdot 1}$,"Let $$a_n = \frac{1}{1^3\cdot 1}+\frac{1}{1^3\cdot 2+2^3\cdot 1} + \cdots +\frac{1}{1^3\cdot n+2^3\cdot (n-1)+\cdots+n^3\cdot 1}$$ Does this sequence converge to a simple number? My thought was to compute each denominator: $$1^3\cdot n+2^3\cdot (n-1)+\cdots+n^3\cdot 1=(n+1)\sum_{k=1}^n k^3-\sum_{k=1}^nk^4$$ and this are known, I find $\frac{1}{60}n(n+1)(2n+1)(3n^2+6n+1)$ . But can we find maybe a closed formula for $a_n$ after this?","['limits', 'calculus', 'sequences-and-series']"
3541971,Philosophy of simple field extensions,"In B. L. van der Waerden's Algebra stuck on the problem 6.9: The polynomial $f(x) = x^4 + 1$ is irreducible in the field of rationals.
  Adjoin a root $\theta$ and resolve the polynomial in the extended
  field $\mathbb Q (\theta)$ into prime factors. Seems like I haven't nailed the idea of extending fields, so I'm asking to control my thoughts and help with troubled places. We can obtain the desired extension by two ways: either we use the fact, which states that we know, in which field would that polynomial have a root ( nonsymbolic adjunction ), or we can build residue class field modulo that polynomial ( symbolic adjunction ). I don't realize what I'm supposed to do in both cases. In nonsymbolic way, should I just completely factorize $f(x)$ over $\mathbb C$ , or am I to find only one (any shall do) root? I can write $f(x) = (x^2-i)(x^2+i) = (x-\sqrt i)(x + \sqrt i)(x - \sqrt{-i})(x + \sqrt{-i})$ but what would that give me? Or I could simply say that $\theta = \sqrt{\sqrt{-1}}$ is an obvious root, divide $f(x)$ by $(x - \theta)$ and think hard what to do next with the quotient $x^3 + \theta x^2 + {\theta}^2 x + {\theta}^3$ ? In symbolic way, I have to find residue class field modulo $f(x)$ . Is this possible at all? I haven't seen yet a single example of making that with polynomials. I'm really sorry for the size of the question. The systematic ignorance reminds of itself. However, I feel, that a proper answer will amend many other problems in my knowledge. I am really grateful at least for the time you spent on reading it.","['extension-field', 'abstract-algebra', 'polynomials']"
3542033,The product of a normal variable by the cossine of another normal variable is a Laplace distribution?,"Let $Z=X \cos(Y)$ be a random variable where $X\sim\mathcal N(0,\sigma_1)$ , $Y\sim\mathcal N(0,\sigma_2)$ . $X$ and $Y$ are independent.My goal it to obtain the PDF of Z or at least prove some behaviors. My first approach was to evaluate the pdf of $\cos (Y)$ and after that, use the convolution theorem to get $Z$ . However, I think that it's not a good way because the pdf of $\cos (Y)$ is a mess] 1 . After lost time with this approach, I investigated pdf of $Z$ numerically. [ 2 ] This distribution resembles a Laplace (exponential) distribution! Because of the exponential decay behavior (figure), I tried to discover the characteristic function of $Z$ . The reason to do that, itâs because if the characteristic function of $Z$ coincides with the characteristic function of the Laplace distribution then IÂ solve my problem. I obtained the following integral for the characteristic function of $Z$ , $$
\varphi_Z(t) = 
  \frac{1}{\sqrt{2\pi}\sigma_2}
  \int\limits_{-\infty}^\infty
    \exp\left(-\frac{(t \sigma_1 \cos(y))^2}{2}\right) \exp\left(-\frac{y^2}{2\sigma_2^2}\right) 
  \mathrm{d} y,
$$ I tried to solve that integral expanding the first exponential. $$
\varphi_Z(t) = \sum_{n=0}^\infty\frac{(-1)^n}{n!} \left(\frac{\sigma_1 t}{\sqrt{2}}\right)^{2n}
\frac{1}{\sqrt{2\pi}} \sum_{k=0}^{2n} \binom{2n}{k} \exp(-2\sigma_2^2(n-k)^2).
$$ However, I donât know if Iâm doing something wrong. This equation doesnât look useful. My questions are Is there another way to calculate the pdf of $Z$ ? How to prove the exponential decaying behavior of pdf $Z$ without knowing the pdf of $Z$ ?","['statistics', 'probability-distributions', 'characteristic-functions', 'random-variables']"
3542046,Need help identifying what property of these integrals make them 0,"The integral in question is this one: $$
A_n=\int_0^1{\sin(n\pi x)\big[\sin(6 \pi x)-\sin(\pi x)\big]\,\mathrm dx}
$$ I had a feeling that this integral would not have non-zero answers for all $n$ , so I checked and it turns out that it only has non-zero answers for $n=1,6$ . My main question is really just how do I explain why this is the case? I can see clearly when I plot the function that the area underneath the curve sums to $0$ for n $\neq$ 1,6, however explaining that ""by looking at the plots..."" is most likely not a sufficient answer for this professor. Taking the n=1 case, the integral is: $$
A_1=\int_0^1{\sin(\pi x)\big[\sin(6 \pi x)-\sin(\pi x)\big]\,\mathrm dx}
$$ Breaking this up into the difference of two integrals, the integral over $\sin(\pi x)\sin(6 \pi x)$ evaluates to $0$ for a similar reason. I cannot, however, figure out what it is that I am trying to say. I feel like there is some underlying trigonometric property or concept that I am totally spacing on. It seems to have to do with the product of two sine functions of different periods/frequencies that makes the integrals of said functions evaluate to $0$ . The kind of answer that this professor has accepted in the past has been one like ""clearly $\int_{-\infty}^\infty x\exp(-x^2)\,\mathrm dx$ evaluates to $0$ because the function $x\exp(-x^2)$ is odd."" So if I could just explain why the $n=1,6$ cases yield non-zero values for the $A_n$ integral I would be golden! Any help that could be offered would be greatly appreciated! My apologies if this is a silly question.","['trigonometry', 'definite-integrals', 'trigonometric-integrals']"
3542063,Injection and surjection of a function,"Let $f:(â1,\infty)\to (â1,\infty)$ be defined by $f(x)=x^2+2x $ , study the injection and surjection of $f$ , then find the inverse function if exist . So i showed that the function is not $1-1$ . my problem is am struggling with showing whether itâs surjective or not i know itâs surjective if the range of the function =the codomain of the function but i dont know how to .. also the inverse doesnât exist since itâs not one-to-one ?? any help would be appreciated!",['discrete-mathematics']
3542071,Testing for Sequence Convergence with Surds,"The general term $a_n$ for a sequence is given below. Test if the sequence converges and find the limit if it exists. $$a_n = \sqrt{n^2 + 5n} - \sqrt{n^2 + 2n}$$ Now, I know from plotting this sequence using software that it does indeed converge to $1.5$ . My problem is that I'm having trouble showing it analytically. The root test for sequence convergence doesn't lead anywhere, so the most likely successful approach appears to be the ratio test, where to start I am required to evaluate $$
L = \lim_{n \to \infty} \left|\frac{a_{n+1}}{a_n}\right|,
$$ but this turns very messy very quickly: $$
L = \lim_{n \to \infty} \left|\frac{ \sqrt{(n+1)^2 + 5(n+1)} - \sqrt{(n+1)^2 + 2(n+1)}}{\sqrt{n^2 + 5n} - \sqrt{n^2 + 2n}}\right|,
$$ $$
L = \lim_{n \to \infty} \left|\frac{ \sqrt{(n+1)^2 + 5(n+1)} - \sqrt{(n+1)^2 + 2(n+1)}}{\sqrt{n^2 + 5n} - \sqrt{n^2 + 2n}} \frac{\sqrt{n^2 + 5n} + \sqrt{n^2 + 2n}}{\sqrt{n^2 + 5n} + \sqrt{n^2 + 2n}}\right|.
$$ etc. I've made various attempts from this point onwards to get to a point where I could evaluate the limit, but it doesn't lead to me getting a value for $L$ (and then confirming that the sequence does indeed converge to $1.5$ ). Am I missing something obvious here?","['limits', 'convergence-divergence', 'sequences-and-series']"
3542077,How different can $f(g(x))$ and $g(f(x))$ be?,"Given $f,g: \mathbb{R} \rightarrow \mathbb{R}$ , how ""different"" can $f(g(x))$ and $g(f(x))$ be? By ""how different"" I mean: Given two real-valued functions $a,b$ do there exist two real-valued functions $f,g$ such that $f(g(x))=a(x)$ and $g(f(x))= b(x)$ ? If not, is there some sens in which $f(g(x))$ and $g(f(x))$ can't be ""too different""?","['real-numbers', 'functions', 'real-analysis']"
3542084,Artin 2.2.15: identity in a subgroup,"Could someone take a look at my solution to this exercise in Artin? 2.2.15. a) In the definition of subgroup, the identity element in $H$ is required to be the identity of $G$ . One might require only that $H$ have an identity element, not that it is the same as the identity in $G$ . Show that if $H$ has an identity at all, then it is the identity in $G$ , so this definition would be equivalent to the one given. b) Show the analogous thing for inverses. Solution. a) Let $e$ be the identity element of $H$ and $e'$ be the identity element of $G$ . Hence, \begin{align*}
& \forall h \in H, \; he = eh = e \\
& \forall g \in H, \; ge' = e'g = g.
\end{align*} Let $h \in H$ . Then, we have $he = eh = e$ by the identity in $H$ . But $H < G$ , so $H \subset G$ , meaning that $h \in G$ , so $he' = e'h = h$ by the identity in $G$ . But the identity in a group is unique, so $e = e'$ . Hence, the identity in $H$ is also the identity in $G$ . (I'm not sure if a lemma is needed for uniqueness of the identity, but let me write one for the sake of completion.) Lemma. The identity element in a group is unique. Let $e$ and $e'$ be identity elements of $G$ . Then, since $e$ is an identity, we have $$ee' = e'e = e'.$$ Since $e'$ is an identity, we have $$e'e = ee' = e.$$ Hence, $e' = e$ , and the identity is unique. b) Let $h \in H$ . Then there exists an inverse $x \in H$ such that $hx = xh = e$ , where $e$ is the identity in both $H$ and $G$ . But $H < G$ , so $H \subset G$ , meaning $h \in G$ . Since $G$ is a group, there exists an inverse $y \in H$ such that $hy = yh = e$ . But the inverse is unique, meaning that $x = y$ .","['group-theory', 'solution-verification']"
3542104,"Proving $\int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{2\pi}{1-r}\log(1-r)$, when $0 < r < 1$.","I'm trying to prove that when $0 < r < 1$ , \begin{equation} \int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{2\pi}{1-r}\log(1-r).\end{equation} References : Evaluating an easier integral $\int_0^{\pi} \log (1+r-2\sqrt{r}\cos(t))\,dt$ has many references, for example: A question in Complex Analysis $\int_0^{2\pi}\log(1-2r\cos x +r^2)\,dx$ But I couldn't find a direct reference for the above problem. My approach : Motivated by solutions in the above post, I tried to express my integral as a contour integral: $$
\int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{1}{2} \int_0^{2\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \int_{\gamma} \frac{\log |1-z|^2}{2iz|1-z|^2} \,dz,
$$ here $\gamma$ is the circle of radius $\sqrt{r}$ centered at the origin. I couldn't proceed further. Could you help me with my approach or any other approach? Thank you in advance.","['integration', 'contour-integration', 'complex-integration']"
3542115,Are $U=\frac{X}{X+Y}$ and $V=X+Y$ independent if $X$ and $Y$ are?,"Suppose $X$ and $Y$ are independent random variables. Under what conditions, $ U=\frac{X}{X+Y}$ and $V=X+Y$ are independent? Notes: 1- Of course if you have independent $X,Y\sim \text{Uniform}(0,1)$ , $0\leq U\leq 1$ and $0\leq V\leq 2$ , but $U$ and $V$ are not independent, e.g. $V=2$ implies $U=\frac{1}{2}$ . So we may restrict our attention to independent unbounded random variables $X, Y$ . (Maybe even positive r.v.s so that $X+Y$ will be non-zero. 2- I think when $X$ and $Y$ are unbounded, then scaling both of them with same constant keeps $U$ unchanged, but we can make $V$ as large or small as possible by varying that constant. So it seems given $U$ , we don't have any information about $V$ . 3- Today in our stat class we showed that for independent $X\sim \text{Gamma}\left(\alpha_1,\beta\right)$ and $Y\sim \text{Gamma}\left(\alpha_2,\beta\right)$ , joint pdf $f_{_{U,V}}\left(u,v\right)$ decomposes into product of marginal pdfs of $U\sim \text{Beta}\left(\alpha_1,\alpha_2\right)$ and $V\sim \text{Gamma}\left(\alpha_1+\alpha_2,\beta\right)$ , hence they are independent. That's where I started to think if there is a general result.","['independence', 'probability-distributions', 'probability']"
3542156,"Special irreducible polynomials in $k[x,y]$","Let $k$ be a field of characteristic zero, $n \in \mathbb{N}$ . Definitions: (1) $0 \neq f \in k[x_1,\ldots,x_n]$ is always irreducible , if for every $\lambda \in k$ , $f+\lambda$ is irreducible in $k[x_1,\ldots,x_n]$ . (2) $0 \neq f \in k[x_1,\ldots,x_n]$ is infinitely irreducible , if for infinitely many $\lambda \in k$ , $f+\lambda$ is irreducible in $k[x_1,\ldots,x_n]$ , and call those $\lambda$ 's for which $f+\lambda$ is irreducible good scalars . (3) $0 \neq f \in k[x_1,\ldots,x_n]$ is never irreducible , if there exist no $\lambda \in k$ for which $f+\lambda$ is irreducible in $k[x_1,\ldots,x_n]$ . Examples: (i) In $\mathbb{R}[x]$ , $x$ is always irreducible, $x^2$ is infinitely irreducible with good scalars $\in (0,\infty)$ . (ii) In $\mathbb{C}[x]$ , $x$ is always irreducible, $x^2$ is never irreducible. Question 1: Is it possible to somehow characterize all always irreducible polynomials in $\mathbb{C}[x,y]$ ? Question 2: Is there a way to distinguish between always irreducibles and infinitely irreducibles? Examples of always irreducible polynomials in $\mathbb{C}[x,y]$ are: (a) $\lambda x- \mu$ , where $\lambda,\mu \in \mathbb{C}$ . (b) $\lambda y- \mu$ , where $\lambda,\mu \in \mathbb{C}$ . (c) $\lambda x + H(y)$ , where $\lambda \in \mathbb{C}$ , $H(y) \in \mathbb{C}[y]$ . (d) $\lambda y + H(x)$ , where $\lambda \in \mathbb{C}$ , $H(x) \in \mathbb{C}[x]$ . Actually, (c) includes (a) and (d) includes (b) .
If I am not wrong, (c) and (d) can be proved by Eisenstein's criterion . One has to be careful, for example $x+y^2$ , in wikipedia's notations we should take $p=x$ not $p=y$ . (e) By the fourth answer to this question, $f=g(x)-h(y)$ is irreducible when $\gcd(\deg(g),\deg(h))=1$ ; in particular, taking $g$ linear yields (c) , and taking $h$ linear yields (d) . If I am not wrong, in $k[x,y]$ : If $(f,g)$ is an automorphic pair ,
then $f$ (and $g$ ) is always irreducible, where $(f,g)$ is an automorphic pair if $k[x,y]=k[f,g]$ or, equivalently, if $(x,y) \mapsto (f,g)$ is an automorphism of $k[x,y]$ . Moreover, if $(f,g)$ is a Jacobian pair ,
then $f$ (and $g$ ) is always irreducible, where $(f,g)$ is a Jacobian pair if $\operatorname{Jac}(f,g):=f_xg_y-f_yg_x$ belongs to $k-\{0\}$ .
Indeed, $\frac{k[x,y]}{\langle f \rangle}$ is an integral domain (I can add an argument for this later), so $\langle f \rangle$ is a prime ideal, hence by the second link below, $f$ is irreducible. Repeat this argument for $f + \lambda$ for every $\lambda \in k$ , and get that $f + \lambda$ is irreducible for every $\lambda \in k$ . Please see the following related questions: Irreducibility of polynomials in two variables , What do prime ideals in $k[x,y]$ look like? , Irreducibility of Polynomials in $k[x,y]$ . Thank you very much! I later asked the above question in MO .","['irreducible-polynomials', 'algebraic-geometry', 'polynomials', 'commutative-algebra']"
3542160,Is multiplication by $n$ always an isogeny on an abelian scheme?,"Given $n$ a non-zero integer, it is known that multiplication by $n$ on an abelian variety (defined over any field $k$ ) is an isogeny. The proof of this fact uses the existence of an ample symmetric divisor on these varieties, which are projective. Is this statement also true in general for abelian schemes, which may not be projective ? I know that it is true for elliptic curves (as schemes), as it is proved in Katz and Mazur's book. However, the proof also makes use of the projectivity of such curves and their concrete description in terms of a WeierstraÃ equation. For reference, an abelian scheme $X$ over a base scheme $S$ is a smooth proper $S$ -group scheme with geometrically connected fibers. A homomorphism $f:X\rightarrow Y$ (as $S$ -group schemes) of abelian schemes is an isogeny if it is surjective with a finite kernel. By ""finite"", we mean that the kernel is an $S$ -group scheme which is locally free of finite rank over $S$ . When the base is noetherian, this is just a finite flat group scheme over $S$ .","['group-schemes', 'algebraic-geometry', 'schemes', 'abelian-varieties']"
3542226,Focal points to geodesic submanifolds defined by tangent vectors,"The following definitions are from Comparison Theorems in Riemannian Geometry by Cheeger & Ebin. Let $(M,g)$ be a Riemannian manifold. The geodesic submanifold defined by a tangent vector $v\in T_pM$ is $\exp_p(B)$ where $B\ni0$ is a small ball in $\operatorname{span}(v)^\perp\subset T_pM$ , so small that $\exp_p|_B$ is an embedding. Let $\gamma(t):=\exp_p(tv)$ . We consider points focal to the geodesic submanifold defined by $v$ along the geodesic $\gamma$ . In the book there is a Rauch II, i.e., second Rauch comparison, which requires the geodesic to have no focal points in the above sense. Question. Let $c:[0,\ell]\to M$ be a geodesic and $E$ a parallel field along $c$ orthogonal to $c'$ . Does there exist an $\varepsilon>0$ such that for all $t\in[0,\ell]$ , the there are no points on the geodesic $$\gamma_t:[0,\varepsilon]\to M,s\mapsto\exp_{c(t)}(sE(t))$$ that is focal to the geodesic submanifold defined by $E(t)$ along $\gamma_t$ ? This seems to be implicitly assumed in the proof of a lemma for the CheegerâGromoll soul theorem. However, I don't see why this is true. The existence of such a focal point is equivalent to having a critical point of some restriction of $\exp$ , but for each $t$ the restrictions are different and don't seem to be related. So I don't know how to make the $\varepsilon$ uniform with respect to $t$ . Any help is deeply appreciated! Edit: It seems that the notion of focal points is not so well-known. Here it is in the sense as in, e.g., Morse Theory by Milnor. Let $N$ be a submanifold, $\gamma$ a unit-speed geodesic with $\gamma(0)\in N$ , $\gamma'(0)\perp T_{\gamma(0)}N$ . Let $T^\perp N\subset TM$ be the normal bundle of $N$ . A point $\gamma(a)$ is said to be focal to $N$ along $\gamma$ if $\exp_p|_{T^\perp N}:T^\perp N\to M$ is singular at $a\gamma'(0)$ (note that $\exp(a\gamma'(0))=\gamma(a)$ ). In particular, when $N$ is a single point this reduces to the usual notion of conjugate points along a geodesic.","['riemannian-geometry', 'differential-geometry']"
3542249,What is the decay of the convolution of these two slowly decaying functions?,"Let $f(x) = \sqrt{1+x^2}^{-\alpha}$ , and $g(x) = \sqrt{1+x^2}^{-\beta}$ for some $\alpha, \beta > 0$ satisfying $\alpha + \beta >1$ . Then let $$(f * g)(y) := \int _{\mathbb{R}} \frac{1}{(1+x^2)^{\alpha/2} (1+(x-y)^2)^{\beta/2}} dx~.$$ For all fixed $y$ the above integral converges, thanks to $\alpha+\beta >1$ , but we don't assume $f, g \in L^1$ , only $fg \in L^1$ . How to prove the decay rate of $f*g$ ? I suspect it's something like $O(y^{-\min(\alpha,\beta)})$ . Thanks EDIT: Thanks to the calculation of reuns, I also wonder what is the answer in the case where $\alpha = 1$ , $\beta >0$ ? ! Thanks","['approximation-theory', 'fourier-analysis', 'convolution', 'analysis']"
3542327,How to show that the Billiard flow is invariant with respect to the area form $\sin(\alpha)d\alpha\wedge dt$,"Consider a plane billiard table $D \subset \mathbb{R}^2$ (i.e. a bounded open connected set) with smooth boundary $\gamma$ being a closed curve. Next, let $M$ denote the space of tangent unit vectors $(x,v)$ with $x$ on $\gamma$ and $v$ being a unit vector pointing inwards. We then define the billiard map $$
T : M \to M.
$$ To understand the map $T$ , we consider a point mass traveling from $x$ in direction $v$ . Let $x_1$ be the first point on $\gamma$ that this point mass intersects and suppose that $v_1$ is the new direction of the mass upon incidence. Then $T$ maps $(x,v)$ to $(x_1, v_1)$ . We now introduce an alternate ''coordinate system'' describing $M$ . Parametrize $\gamma$ by arc-length $t$ and fix a point $(x,v) \in M$ . We can find $t$ such that $x = \gamma(t)$ and let $\alpha \in (0, \pi)$ be the angle between the tangent line at $x$ and $v$ . The tuple $(t, \alpha)$ uniquely determines the point $(x,v)$ in $M$ , and thus offers and alternative description of this space. My question is as follows: I want to show that the area form given by $$
\omega := \sin{\alpha}\,\mathrm{d}\alpha \wedge \mathrm{d}t
$$ is invariant under $T$ . I found a proof of this invariance property proof in S. Tabachnikov's Geometry and billiards but I'm having some trouble understanding a critical part of the proof. If anyone can explain the proof to me (or provide me with another proof) I would highly appreciate it. An intuitive explanation is also appreciated, but I am looking for a rigorous proof if possible. We restate this theorem formally below and provide the proof as given by Tabachnikov. Theorem 3.1. The area form $Ï = \sin Î± \,dÎ± \wedge dt$ is $T$ -invariant. Proof . Define $f(t, t_1)$ to be the distance between $\gamma(t)$ and $\gamma(t_1)$ . The partial derivative $\frac{\partial f}{\partial{t_1}}$ is the projection of the gradient of the distance $\left\vert{\gamma(t)\gamma(t_1)}\right\vert$ on the curve at point $\gamma(t_1)$ . This gradient is the unit vector from $\gamma(t)$ to $\gamma(t_1)$ and it makes angle $\alpha_1$ with the curve; hence $\partial f/\partial t_1 = \cos{\alpha_1}$ . Likewise, $\partial f/\partial t = -\cos{\alpha}$ . Therefore, $$
  \mathrm{d}f = \frac{\partial f}{\partial t} \mathrm{d}t + \frac{\partial f}{\partial t_1}\mathrm{d}t_1
= -\cos{\alpha}\,\mathrm{d}t + \cos{\alpha_1}\,\mathrm{d}t_1
$$ and hence $$
0 = \mathrm{d}^2f = \sin{\alpha}\mathrm{d}\alpha \wedge \mathrm{d}t - \sin{\alpha_1} \mathrm{d}\alpha_1 \wedge \mathrm{d}t_1.
$$ This means that $\omega$ is a $T$ -invariant form. The above proof is copied directly from the book. I have the following questions about his method: Is the domain of $f$ the set $M\times M$ ? In the proof, are we specifically considering $(t, \alpha)$ and $(t_1, \alpha_1)$ such that $T (t, \alpha) =(t_1,\alpha_1)$ ? I am having a hard time understanding how the author obtains $\partial f/\partial t_1 = \cos{\alpha_1}$ and $\partial f/\partial t = -\cos{\alpha}$ . The explanation given feels mostly heuristic, how could I go about constructing a rigorous proof?","['dynamical-systems', 'billiards', 'geometry', 'differential-geometry']"
3542415,For $p\geqslant 1$ there is some $f\in L^1$ s.t. $\sum_{k\in \Bbb Z }|\hat f(k)|^p=\infty $,"Im having trouble with this exercise. Show that for any chosen $p\geqslant 1$ there is some $f\in L^1((-\pi,\pi])$ such that $\sum_{k\in \Bbb Z }|\hat f(k)|^p=\infty $ There $$
\hat f(k):=\frac1{2\pi}\int_{-\pi }^{\pi }f(x)e^{-ikt}\,\mathrm d t\tag1
$$ is the classical Fourier coefficient. Let $f(z):=\sum_{k\geqslant 1}\frac1{k^r} z^k$ , then $f\in L^2(\partial \Bbb D )$ when $r>1/2$ , and because for any space of finite measure we knows that $L^p\subset L^q$ for $p>q$ , then $f\in L^1(\partial \Bbb D )$ also and $\sum_{k\in \Bbb Z }|\hat f(k)|^p=\infty $ whenever $rp\leqslant 1$ , what happens when $p\in[1,1/r]$ , and so we proved the case for all $p\in[1,2)$ . However Im having trouble finding a way to show the statement for $p\geqslant 2$ . I tried to find some lower bound for $|\hat f(k)|^p$ (or it sum) using Jensen's inequality and similar ideas but I dont find something useful.  Some help will be appreciated, thank you.","['fourier-analysis', 'analysis', 'real-analysis']"
3542426,Minimum number of lattice points required so that there exists three points whose mean is also a lattice point,"I proved via pigeonhole principle that $5$ is enough is if we're taking mean of two points. Define a function which maps the lattice point to its modular class in $\mathbb Z_2\times \mathbb Z_2$ , then atleast one of the classes will have 2 points and hence we are done. I am looking for a similar proof in which we preferably only apply the pigeonhole principle once. I know $13$ works by repeated applications of pigeonhole, but I don't know if $12$ doesn't work out. The proof for $13$ goes as follows. Define $f:\mathbb N\times\mathbb N$ as $f(x,y)=x(mod \,\,3)$ . Then atleast one of the classes will have $5$ elements. Then consider those $5$ points only. We are distribution the $5$ points in $3$ classes (based on second coordinate) thus either all classes have atleast $1$ element or one class has $3$ elements and hence we done.","['pigeonhole-principle', 'combinatorics']"
3542464,Given $h \in \mathbb R^n $ is it true that $\lim_{h \to 0 } \frac{|h^T S h|}{\|h\|}=0$,"Given a symmetric matrix $S $ and a vector $h =(h_1, \cdots , h_n ) \in \mathbb R^n $ , is it true that $$\lim_{h \to 0 } \frac{|h^T S h|}{\|h\|}=0$$ Expanding the numerator one may observe that it would be sufficient to check that $$\lim _ {h \to 0 } \frac {|h_1^{i_1}  h_2^{i_2 } ...h_n^{i_n }|} {h_1^2 + h_2^2 + \cdots + h_n^2 }  $$ where $i_1 + i_2 + \cdots + i_n = n$ Is this true and what inequality could one use? Thanks in advance!","['limits', 'multivariable-calculus', 'analysis', 'quadratic-forms']"
3542489,Index of a subgroup in $SL_2(\mathbb{Z})$,"Let $SL_2(\mathbb{Z})$ denote the group (under usual matrix multiplication) of $2\times2$ matrices with integer entries and determinant $1$ . Let $H$ be the subgroup of $SL_2(\mathbb{Z})$ consisting of those matrices such that the diagonal entries are all equivalent to $1 \pmod 3$ and the off-diagonal entries are all divisible by $3$ . What is the index of $H$ in $SL_2(\mathbb{Z})$ ? There are a total of $3^4=81$ different equivalence classes of matrices in $SL_2(\mathbb{Z})$ modulo $3$ (each of the entries can have $0,1,2$ as remainders). Now, the given condition implies only one of the possible $81$ combinations modulo $3$ . How do we proceed? any hints? Thanks beforehand.","['matrices', 'group-theory', 'normal-subgroups', 'linear-algebra']"
3542514,"Solving the wave equation, with boundary conditions, in the sense of distributions (Generalized functions)","After learning some distribution theory, I find that in my book, all PDEs given as examples are in free space (without any boundary conditions). I wonder if distribution theory can be used to tackle PDEs with boundary conditions. To be more specific, let's consider this problem. Let there be a string of length $\pi$ with both ends fixed. Transverse waves can be produced on the string, satisfying the classical wave equation $$
\partial^2_t u(x,t)=c^2\partial^2_x u(x,t).
$$ The boundary conditions are $u(0)=u(\pi)=0$ . Now, let impose a wired initial condition: let's pluck the string in the middle, so initially, the string is at rest, in the position $$
u(x,0)=A(\pi/2-|x-\pi/2|), A\in \mathbb R.
$$ As one can see, the initial condition is not everywhere differentiable. However, $u$ can be seen as an element of $\mathcal D'(\mathbb R)$ or $\mathcal S'(\mathbb R)$ , the space of (tempered) distributions. The differential equation therefore make sense in the sense of distributions. Using Fourier transform and convolution, we can manage to get a solution, IF there are no boundary conditions. However, in this situation, I do not know how to state the boundary condition in term of distributions. So, my question now is: can we make sense out of this problem, possibly in the sense of distributions, and solve the equation? Edit: we can use Fourier series expansion to solve this, but then I don't feel it really a way of ""understanding"" how it really works - after all, the original equation ceases to make sense when it is not differentiable. I want to somehow have some formalism in making sense of the derivative of a function which is not differentiable. Possibly weak derivative? Edit: Fourier transform over a bounded interval doesn't seem to be obvious to define; it appears that Fourier series are really easier.","['fourier-transform', 'distribution-theory', 'functional-analysis', 'wave-equation', 'partial-differential-equations']"
3542548,matrices with huge numbers as components,"If $A=\begin{bmatrix}
 10^{30}+5& 10^{20}+4 &10^{20}+6 \\ 
10^{4}+2 & 10^{8}+7 &10^{10}+2n \\ 
 10^{4}+8&10^{6}+4  &10^{15}+9 
\end{bmatrix}$ for all $n\in \mathbb{N},$ Then $(a)\;\;A$ is invertible for all $n\in \mathbb{N}$ $(b)\;\;A$ is not  invertible for all $n\in \mathbb{N}$ $(c)\;\;A$ may or may not be invertible depending on the values of $n\in \mathbb{N}$ $(d)\;$ Data Insufficient What I try If $A$ is invertiable, then $\det(A)\neq 0$ $$A=\begin{vmatrix}
 10^{30}+5& 10^{20}+4 &10^{20}+6 \\ 
10^{4}+2 & 10^{8}+7 &10^{10}+2n \\ 
 10^{4}+8&10^{6}+4  &10^{15}+9 
\end{vmatrix}$$ Expanding along $1^\mathrm{st}$ row $\displaystyle A=\bigg(10^{30}+5\bigg)\bigg[\bigg(10^8+7\bigg)\bigg(10^{15}+9\bigg)-\bigg(10^6+4\bigg)\bigg(10^{10}+2n\bigg)\bigg]-\bigg(10^{20}+4\bigg)\bigg[\bigg(10)^4+2\bigg)\bigg(10^{15}+9\bigg)-\bigg(10^{10}+2n\bigg)\bigg(10^8+4\bigg)\bigg]+\bigg(10^{20}+6\bigg)\bigg[\bigg(10^4+2\bigg)\bigg(10^6+4\bigg)-\bigg(10^8+7\bigg)\bigg(10^4+8\bigg)\bigg]$ How do I simplify such a huge calculation? Please help me.",['matrices']
3542557,Proving that sheaf of ideals of a closed subscheme is quasi-coherent,"Let $X$ be a scheme and $Y$ be a closed subscheme, where we have $(\iota, \pi): (Y, O_Y) \to (X, O_X)$ . I want to prove that the sheaf of ideals of $Y$ , which is the kernel of $O_X \to \iota_* O_Y$ is quasi-coherent. I know that the kernel of quasi-coherent sheaves is quasi-coherent and the structure sheaf $O_X$ is quasi-coherent. It remains to show that $\iota_* O_Y$ is quasi-coherent. Any explanation about this last point would be appreciated. Thank you!","['algebraic-geometry', 'schemes']"
3542562,Expected winning of a player with highest lowest and second highest lowest grouping,"The following is an interview question. Question:     Given 4 players $A,B,C,D$ and a fair $50$ -sided dice, assume that we do not allow repeated score (i.e. next player cannot get the same score as all previous players. Otherwise, the player roll again). We group players with the highest and lowest scores together and second and third highest together. The winning team is the group that has the larger sum which will win the difference between team score. For example, say $A,B$ and $C,D$ form 2 groups and $A=1,B=7,C=3,D=2,$ then $A,B$ groups wins with $8-5=3$ units. What number should player $A$ hopes to get to maximize his expected winning? I totally have no idea how to start this question at all.","['expected-value', 'combinatorics', 'discrete-mathematics', 'probability-theory', 'probability']"
3542681,Does uniformly bounded sequence in Lp which converges almost everywhere converge in norm?,"I'm trying to solve problem $17$ from chapter $6$ of Royden's Real Analysis. The problem is - Let $(f_n)_{n=1}^\infty$ be a sequence of functions in $L^p([0,1]), p\in(1,\infty)$ , which converge almost everywhere to some $f\in L^p$ . Suppose that there is a constant $M$ s.t $||f_n||_p\leq M$ for all $n$ . Then for each $g\in L^q$ (where $\frac{1}{q}+\frac{1}{p}=1$ ) we have - $\int fg=lim_{n\rightarrow \infty}\int f_ng$ I want to solve this problem using the Riesz representation theorem for $L^p$ spaces, which states that any bounded linear functional in $(L^p)^*=L^q$ is of the form - $\phi _g (h)=\int hg$ , where $g\in L^q$ . Since $g$ corresponds to a bounded (and thus continuous) linear functional, the problem is basically solved, if I prove that $f_n\rightarrow f$ in norm. But I'm not sure that this is the case. I know that generally, $f_n\rightarrow f$ almost everywhere does not imply convergence in norm. But since $f_n$ are uniformly bounded in norm by $M$ , I'm hoping that I can somehow conclude that this is indeed the case (I know that if moreover $||f_n||_p\rightarrow ||f||_p$ then there actually is convergence in norm, maybe I can somehow use this fact?). Does anyone know if this it true and how to prove this? If not, can anyone suggest a different approach? Thanks in advance.","['banach-spaces', 'measure-theory', 'real-analysis', 'lp-spaces', 'functional-analysis']"
3542719,Showing $A= \mathbb{Q}/\mathbb{Z}$ is not finitely generated and $A_\text{tor}=A$.,"(i) $A= \mathbb{Q}/\mathbb{Z}$ the additive Group and I want to show first that $A_\text{tor}=\{a\in A:\text{ord}(a)<\infty \}=A$ . $q\in \mathbb{Q} \Rightarrow q=\frac{a}{b}$ with $a,b \in \mathbb{Z}, b\neq 0$ . Now : $q+\mathbb{Z} = \frac{a}{b} +\mathbb{Z}$ . But $b\cdot (\frac{a}{b} +\mathbb{Z})=a+\mathbb{Z}=\mathbb{Z}$ what am I missing here? This seems far too easy. (ii) If $A=(a_1,...,a_n)$ then from (i) it follows that the order of $a_i<\infty$ , so there is a (if you want the smallest common multiple is enough) $k\in \mathbb{N}$ with $a_i^k=e, \, \forall a_i$ . This follows from the fact that $A= \mathbb{Q}/\mathbb{Z}$ is abelian and ord $(a_1\cdot...\cdot a_n) | \text{lcd}(a_1,...,a_n) $ But beause the ord $(\frac{1}{n}+\mathbb{Z})=n$ for all $n\in \mathbb{N}, n\neq 0$ , the order of elements of in $A= \mathbb{Q}/\mathbb{Z}$ cannot have an upper barrier like $\text{lcd}(a_1,...,a_n)$ . Is that ok?","['group-theory', 'abstract-algebra', 'finite-groups']"
3542732,non measurable sets,"In Royden's text Vitali's theorem states that ""Any set E of real numbers with positive outer measure contains a subset that fails to be measurable"". So my question the Cantor set is a set of real numbers with outer measure zero does this set have a subset which fails to be measurable?",['analysis']
3542734,Alternatives for sigmoid curve starting from 0 with interpretable parameters,"I am looking for alternative of sigmoid curves going through $(0,0)$ , whose parameters can be sensed by eyeballing the function graph. As an example, consider this curve: $$f(x) = {{a x ^ b} \over 1 + a x ^ b}$$ Where $ a, b $ are meaningless parameters without any straightforward interpretation. However, we can write the curve equation in such a way that both parameters will be meaningful. Imagine new parameters $c, d$ such that: $$\begin{cases} f (c) = 0.1 \\ f (d) = 0.9 \end{cases}$$ Then expressing the curve with parameters a, b defined as follows, that is by parameters c, d, does the job. $$\displaystyle{a}={9}\cdot{d}^{{-{b}}}$$ $$\displaystyle{b}=\frac{{-{4}\cdot \log{{\left({3}\right)}}}}{ \log{{\left(\frac{c}{{d}}\right)}}}$$ So looking at the example below, we can easily guess the values of parameters c, d. The function is in 10% and 90% value in approximately $x=1$ (parameter c) and $x=3$ (parameter d). Job done. https://www.desmos.com/calculator/fmalvakguo Why I ask for alternatives? The curve equation lacks ""symmetry."" I do not ask for exact symmetry but what I mean is that the function above $f(d)=0.9$ approaches asymptote of 1 very slowly. While below $f(c)=0.1$ the function gets to zero quite quickly.","['curves', 'functions', 'logistic-regression']"
3542832,are $T_{b-a}$ and $T_b - T_a$ equal in distribution?,"let $u > 0$ , $b > a > 0$ and $T_u = \inf \{t \geq0 \,|\, B_t = u\}$ where $B$ is a standard Brownian motion. I was reading some lecture notes and noticed that the author treats $T_{b-a}$ and $T_b - T_a$ as identical in distribution. intuitively I can see why this is the case, but in a previous problem, when $a$ was negative such that $a < 0 < b$ it was proven that $$\mathbb{\mathbb{P}}(T_b - T_a < 0) = -\frac{a}{b-a}$$ but in this case $$\mathbb{\mathbb{P}}(T_{b-a} < 0) = \mathbb{\mathbb{P}}(T_{b-a} - T_{0} < 0) = 0$$ so are $T_{b-a}$ and $T_b - T_a$ actually equal in distribution ? if so how come the sign of $a$ has such an influence on the distribution of $T_{b-a}$ ?","['martingales', 'stopping-times', 'brownian-motion', 'probability-theory']"
3542881,Existence of a bounded sequence for a family of continuous linear functionals over a Banach space,Let $\{\varphi_j\}_{j=1}^{\infty}$ be a family of continuous linear functionals over a Banach space $X$ s.t. $\|x\|\leq \sum\limits_{j=1}^{\infty}|\varphi_j(x)|<\infty$ . Prove that for every continuous linear functional $\varphi : X \longrightarrow \mathbb{K}$ there exists a bounded sequence $\{a_j\}_{j=1}^{\infty} \subset \mathbb{K}$ such that $\varphi(x) = \sum\limits_{j=1}^{\infty}a_j\varphi_j(x)$ for all $x\in X$ . It is obvious that $|\varphi(x)|\leq \alpha\|x\| \leq \alpha  \sum_{j=1}^{\infty}|\varphi_j(x)|$ for some $\alpha$ . It seems to me that it may be possible that this $\alpha$ is the upper bound of the desired sequence but I am not sure how to show it.,"['continuity', 'banach-spaces', 'functional-analysis']"
3542882,Semidirect product action and its geometry,"I'm going by the maxim Groups, like men, are known by their actions This naturally leads one to ask ""given groups $G, H$ which act on sets $S, T$ and the semidirect product $G \rtimes H$ , how does one visualize the action of $G \rtimes H$ ? What does it act on? Some combination of $S$ and $T$ ? ( $S \times T$ perhaps?) I know some elementary examples, likr $D_n \simeq \mathbb Z_n \rtimes \mathbb Z_2$ . However, given an unknown situation, I am sure I cannot identify whether it is a semidirect product that is governing the symmetry. The best responses on similar questions like intuition about semidirect product tend to refer to this as some kind of ""direct product with a twist "". This is shoving too much under the rug: the twist is precisely the point that's hard to visualize. Plus, not all ""twists"" are allowed --- only certain very constrained types of actions turn out to be semidirect product. I can justify the statement by noting that: the space group of a crystal splits as a semidirect product iff the space group is symmorphic --- this is quite a strong rigidity condition on the set of all space groups. The closest answer that I have found to my liking was this one about discrete gauge theories on physics.se , where the answer mentions: If the physical space is the space of orbits of $X$ under an action $H$ . Ie, the physical space is $P \equiv X / H$ . Then, if this space $P$ is acted upon by $G$ . to extend this action of $G \rtimes H$ onto $X$ we need a connection . This seems to imply that the existence of a semidirect product relates to the ability to consider the space modulo some action, and then some action per fiber . I feel that this also somehow relates to the short exact sequence story(though I don't know exact sequences well): Let $1 \rightarrow K \xrightarrow{f}G \xrightarrow{g}Q \rightarrow 1$ be a short exact sequence. Suppose there exists a homomorphism $s: Q \rightarrow G$ such that $g \circ s = 1_Q$ . Then $G = im(f) \rtimes im(s)$ . ( Link to theorem ) However, this is still to vague for my taste. Is there some way to make this more rigorous / geometric? Visual examples would be greatly appreciated.","['semidirect-product', 'group-theory', 'group-actions', 'exact-sequence']"
3542930,Venn diagramm: at least one not,"I have trouble understanding the solution for a venn-diagram exercise our statistics professor gave us. 
The question is: Of the three events $A, B, C\subset W$ occurs at least one not . Write the
  corresponding event and draw the venn diagram. The correct solution was: $(\overline {A\text{ }\cup B\text{ } \cup C}\text{ })$ My solution was: $(\overline{A\text{ }\cap B\text{ }\cap\text{ }C}\text{ })$ I just can't wrap my head around where I went wrong. If only A, or A and B happens for example, the requirement of one not is still met, isn't it? So the overlap of one or only one should be colored in too. That's at least my thought","['elementary-set-theory', 'statistics']"
