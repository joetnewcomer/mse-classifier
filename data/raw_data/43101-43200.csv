question_id,title,body,tags
427341,"You have 4 prizes, 3 tickets, n tickets- what is the probability of winning","You have bought 3 tickets in a lottery. There are n total tickets and 4 prizes. What are the odds of winning at least one prize? I thought of it like this: The total possible ways of extracting 4 prizes is: a= $${n\choose 4}$$ The possibilities of extracting at least 1 winning prize is: b=$${4\choose 1} + {4\choose 2} +{4\choose 3}$$ so the probability of winning is $$\frac{{4\choose 1} + {4\choose 2} +{4\choose 3}}{{n\choose 4}}$$ If I'm wrong, which might be the case, please tell me what the right solution is, as this is the only I could come up with. Thank you",['statistics']
427355,Question about the Galois extension of a given field extension,"Let $K=\mathbb{Q}(\omega)$ be given, where $\omega^3=1$. I want to know: (1) Whether there is a Galois extension $L/\mathbb{Q}$ containing $K$ such that $\mathrm{Gal}(L/\mathbb{Q})\cong\mathbb{Z}_4$? (2) Whether there is a Galois extension $L/\mathbb{Q}$ containing $K$ such that $\mathrm{Gal}(L/\mathbb{Q})\cong Q$, where $Q$ is the quaternion group with 8 elements. I have no idea how to solve such problem.","['galois-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
427367,Show $\nabla\cdot\left(\mathbf{F}\times\mathbf{G}\right)=\mathbf{G}\cdot(\nabla\times\mathbf{F})-\mathbf{F}\cdot(\nabla\times\mathbf{G})$,"Question as follows. Suppose that $\mathbf{F}$,$\mathbf{G}:\mathbb{R^3}\rightarrow\mathbb{R^3}$ and $\phi:\mathbb{R^3}\rightarrow\mathbb{R}$ are smooth. Show using the summation convention that $$\nabla\cdot\left(\mathbf{F}\times\mathbf{G}\right)=\mathbf{G}\cdot(\nabla\times\mathbf{F})-\mathbf{F}\cdot(\nabla\times\mathbf{G}).$$ So far I have $$\mathrm{LHS}=\partial_i\mathbf{e}_i\cdot\left(F_j\mathbf{e}_j\times G_k\mathbf{e}_k\right)=\partial_i\mathbf{e}_i\cdot(F_j G_k \epsilon_{jki}\mathbf{e}_i)=\partial_iF_jG_k\epsilon_{ijk}.$$ I'm under the impression that this should be $0$ as expanding the $\mathrm{RHS}$ gives $2\partial_iF_jG_k\epsilon_{ijk}$. Is this true and is it true because for $\partial_iF_jG_k\ne0$ iff $i=j$ or $i=k$ but if $i=j$ or $i=k$ then $\epsilon_{ijk}=0$?",['multivariable-calculus']
427372,A gambler with the devil's luck?,"A gambler with $1$ dollar intends to make repeated bets of $1$ dollar until he wins $20$ dollars or is ruined. Probabilities of  win/loss are $p$ and $(1-p)$, and each bet brings a gain/loss of $1$ dollar. Unfortunately, the devil is active, and ensures that every time he reaches $19, he loses! Obviously, the poor guy will get ruined sooner or later! The question is, what is the expected number of bets he makes until he is ruined?","['recreational-mathematics', 'probability', 'combinatorics']"
427383,Infinite divisibility of random variable vs. distribution,The distribution of any infinitely divisible random variable is itself infinitely divisible. But this link says the converse is not always true. Can you explain?,"['probability-theory', 'random-variables']"
427396,"Union of proper subspaces, which is correct?","My textbook asks this: Suppose that $K$ is a finite field with $k$ elements, and that $V$ is an $r$-dimensional vector space over $K$. Show that if $V = \bigcup_{i=1}^n U_i$, where $U_1,\dotsc,U_n$ are proper subspaces of $V$, then $n\geq (k^r - 1)/(k-1)$. Struggling to prove this for a while, I did some googling and found this paper which claims to show $n = k+1$ is possible, a result which is independent of the dimension of $V$. Which is correct?","['vector-spaces', 'finite-fields', 'linear-algebra']"
427398,Set of ODE: how can I solve it?,"I want to solve this system, but I have never solved a system of ODE, can you help me? $$ \begin{cases} \frac{dA}{dt}=-aA\\
\frac{dB}{dt}=aA-bB\\
\frac{dC}{dt}=bB \end{cases}$$ I have solved the first equation:
$$A(t)=A_0e^{-a t}$$
Thanks for any help!","['ordinary-differential-equations', 'systems-of-equations']"
427410,Why is $ \lim_{n \to \infty} \left(\frac{n-1}{n+1} \right)^{2n+4} = \frac{1}{e^4}$,"According to WolframAlpha , the limit of $$ \lim_{n \to \infty} \left(\frac{n-1}{n+1} \right)^{2n+4} = \frac{1}{e^4}$$ and I wonder how this result is obtained. My approach would be to divide both nominator and denominator by $n$, yielding $$ \lim_{n \to \infty} \left(\frac{1-\frac{1}{n}}{1 + \frac{1}{n}} \right)^{2n+4} $$ As $ \frac{1}{n} \to 0 $ as $ n \to \infty$, what remains is $$ \lim_{n \to \infty} \left(\frac{1-0}{1 + 0} \right)^{2n+4} = 1 $$ What's wrong with my approach?","['sequences-and-series', 'limits']"
427438,Euclidean Metric and Convexity,"Question: Consider the Euclidean metric space $(\mathbb{R}^n , \Vert\cdot \Vert)$. Let $X\subset \mathbb{R}^n$ and $f\colon X \to \mathbb{R}$. $X$ is said to be a convex set if for every $x,y \in X$ and $t \in (0,1)$, we have $tx+(1-t)y \in X$. $f$ is said to be a convex function at $x\in X$ if for every $y \in X$ and $t\in(0,1)$, $tx+(1-t)y\in X$ implies $f(tx+(1-t)y) \le tf(x) +(1-y)f(y)$. $f$ is said to be a convex function if it is a convex function at every $x \in X$. Prove the following statements: If X is a convex set, then $f\colon X \in \mathbb{R}$ is a convex function iff $\{ (x,y) \in X \times \mathbb{R} \mid f(x) \le y \}$ is a convex set. If $X$ is open in $\mathbb{R}^n$ and $f$ is convex and differentiable at $x \in X$, then
$$f(y)-f(x) \ge Df(x)\cdot (y-x)$$
for every $y\in X$, where $Df(x)$ is the derivative of $f(x)$ at $x$. If $X$ is open in $\mathbb{R}^n$ and $f$ is convex and twice differentiable at $x \in X$, then $D^2f(x)$ is positive semidefinite. EDIT : I am deleting how I tried Part 1 as I got my mistake and now it is solved. Part 2 and Part 3 are still unsolved","['multivariable-calculus', 'convex-analysis', 'inner-products']"
427442,Can we always find an analytic function if we know countable points?,"I hope to find an analytic function such that $f(n)=b_{n}$, $n\in \mathbb{N}$? Can we always take an analytic function $f$?","['complex-analysis', 'analysis']"
427443,$||f-f_n||_{L^1} \rightarrow 0$ but $f_n \rightarrow f$ for no $x$,Show that there are $f\in L^1(\mathbb{R}^d)$ and a sequence $\{ {f_n}\}$ with ${f_n}\in L^1(\mathbb{R}^d)$ such that $||f-f_n||_{L^1} \rightarrow 0$ but $f_n \rightarrow f$ for no $x$ Thanks.,['real-analysis']
427448,A Basic question on intuition of rational cut set in the construction of real numbers,"The intuition for cuts presumably comes from the standard experience of approximation by terminating decimals. For example, we can approximate $\sqrt{2}$ by the sequence $1,1.4,1.41,1.414,1.4142, \dots$. Now, why a cut set for $\sqrt{2}$ requires ""all"" rationals less than $\sqrt{2}$. Intuitively, only these rationals $1,1.4,1.41,1.414,1.4142, \dots$ uniquely identifies $\sqrt{2}$. Are not they sufficient ? Related question : Why the addition of two cut set is defined as the set of all possible summation of elements of the two cutsets ?","['intuition', 'elementary-set-theory']"
427456,Why the members of $\mathbb R$ will be certain subsets of $\mathbb Q$?,"$\mathbb{R}$ is real numbers set, $\mathbb{Q}$ denotes rational numbers set. This is quoted from Rudin's mathematical analysis book page 17 about Dedekind' s construction. Why the members of $\mathbb{R}$ will be certain subsets of $\mathbb{Q}$? There are two levels' confusing, one is that in Mathematics, another is this English sentence, or the expression of this fact. Maybe I'd like to comprehend like this: members of $\mathbb{R}$ are some thing decided by some certain subsets of of $\mathbb{Q}$. At first glance, it seems like members of $\mathbb{R}$ are are equal to some subsets of $\mathbb{Q}$. But which subset is $\sqrt{2}$ correspoinding to ? This maybe not so obvious. IMO As @Hagen von Eitzen's answer mentioned, it means that $\mathbb{Q}$ is obtained from Integers . And this is just one construction, I agree. That is obvious. And the same to $\mathbb{C}$, Complex number is a pair of real numbers, we do accept the fact quikly. But if you say, $\mathbb{C}$ is some certain subsets of  $\mathbb{R}$ $\mathbb{C}$ is some certain subsets of  $\mathbb{Q}$ $\mathbb{C}$ is some certain subsets of  $\mathbb{Z}$ There will also be some confusions at first glance in my point of view. @Robert Israel 's answer is more about the fact what Real Number is.",['analysis']
427471,Berger's theorem on holonomy,"Can someone clarify to me what the correct hypothesis of Berger's theorem are (if at all what I write is correct)? Theorem : assume $M$ is a Riemannian manifold, with irreducible reduced holonomy group; moreover that $M$ is not homogeneous, and it is compact. Then its holonomy must be one of the well-known list ( http://en.wikipedia.org/wiki/Holonomy#The_Berger_classification ). In particular, I'd like to understand i. In which sense $M$ must be something trivial (no Lie groups, etc.)? ii. Is simply-connectedness already implied by the above hypothesis or can it be omitted? Could you point me to some good references, other than the original paper?","['holonomy', 'riemannian-geometry', 'differential-geometry']"
427484,Simplify the square of a sum of cosine functions,"I have a square sum of exponantials as below:
$$\left|\sum_{l=0}^{M-1}\exp\left(jl^2a\right)\,\exp\left(\frac{-j2\pi l}{M}b\right)\right|^2 $$ where $a$ is constant and $b$ is an integer .
and I have rewritten the above expression as below
$$\left|\sum_{l=0}^{M-1}\cos\left(l^2a-\frac{2\pi l}{M}b\right)\right|^2 + \left|\sum_{l=0}^{M-1}\sin\left(l^2a-\frac{2\pi l}{M}b\right)\right|^2 $$ how could I simplify $\left|\sum_{l=0}^{M-1}\cos\left(l^2a-\frac{2\pi l}{M}b\right)\right|^2 $","['power-series', 'sequences-and-series', 'discrete-mathematics']"
427491,Approximating hypergeometric distribution with poisson,"I'm am currently trying to show that the hypergeometric distribution converges to the Poisson distribution. $$
\lim_{n,r,s \to \infty, \frac{n \cdot r}{r+s} \to \lambda} \frac{\binom{r}{k} \binom{s}{n-k}}{\binom{r+s}{n}} = \frac{\lambda^k}{k!}e^{-\lambda}  
$$ I know, how to show for specific values, that the hypergeometric distribution converges to the binomial distribution and from there we proved in our script that the binomial distribution converges to the Poisson distribution for specific values. No the question is, can i show the approximation directly via the limit above? I came from the limit above to $$
\lim_{n,r,s \to \infty, \frac{n \cdot r}{r+s} \to \lambda} \frac{\binom{r}{k} \binom{s}{n-k}}{\binom{r+s}{n}} = \cdots = \frac{\lambda^k}{k!}\frac{\frac{(r-1)!}{(r-k)!}\binom{s}{n-k}}{\binom{r+s-1}{n-1}}\left(\frac{1}{\lambda}\right)^{k-1}
$$ But how to show that ?
$$
\frac{\frac{(r-1)!}{(r-k)!}\binom{s}{n-k}}{\binom{r+s-1}{n-1}}\left(\frac{1}{\lambda}\right)^{k-1}
= e^{-\lambda}
$$","['binomial-coefficients', 'convergence-divergence', 'probability']"
427500,Show that $e^x \geq (3/2) x^2$ for all non-negative $x$,"I am attempting to solve a two-part problem, posed in Buck's Advanced Calculus on page 153. It asks ""Show that $e^x \geq \frac{3}{2}x^2$  $\forall x\geq 0$. Can $3/2$ be replaced by a larger constant?"" This is after the section regarding Taylor polynomials, so I have been attempting to leverage the Taylor expansion for $e^x$ at $0$. $e^x \geq 1+x+\frac{x^2}{2}$, and by quadratic formula, we have $1+x+\frac{x^2}{2}\geq \frac{3}{2}x^2$ for $x\in [0, \frac{1+\sqrt{5}}{2}]$. Now also $e^x\geq 1+x+\frac{x^2}{2}+\frac{x^3}{6}$. We know there exists a $c\in \mathbb{R}^{\geq 0}$ such that for all $x\geq c$, we have $1+x+\frac{x^2}{2}+\frac{x^3}{6}\geq \frac{3}{2}x^2$. I want to find this point without messing with the cubic formula, etc. I think I am missing a simpler way. Any ideas?","['inequality', 'calculus', 'taylor-expansion']"
427501,Establishing equality between two functions $\mathbb{Z}_5[x]$; $a(x) = x^5 + 1$ and $b(x) = x-4$,"Consider the following two polynomials in $\mathbb{Z}_5[x]$ :* $$
a(x) = x^5 + 1
$$ $$
b(x) = x - 4
$$ You may check that $a(0) = b(0), a(1) = b(1), \ldots, a(4) = b(4)$ , hence $a(x)$ and $b(x)$ are equal functions
from $\mathbb{Z}_5$ to $\mathbb{Z}_5$ . Why and how $a(0)=b(0)$ for the above two functions?","['functions', 'abstract-algebra', 'polynomials']"
427528,Why is the determinant the volume of a parallelepiped in any dimensions?,"For $n = 2$ , I can visualize that the determinant $n \times n$ matrix is the area of the parallelograms by actually calculating the area by coordinates.  But how can one easily realize that it is true for any dimensions?","['matrices', 'volume', 'geometry', 'determinant']"
427529,Computing eigenvalues from characters,"This is a question in Representation theory, a first course , where the authors try to explain why character theory turns out to be so effective for the study of representations of finite groups. In particular they want to show by knowing the character $\chi_{V}$ of a representation of $G$, we can actually compute all eigenvalues (and their multiplicity) of any element. I tried something but did not go very far. Also it seems a little bit vague that how much information of the group is available. Can someone give a hint? Thanks!","['finite-groups', 'group-theory', 'representation-theory']"
427538,Sobolev embeddings,"I'm doing some reading on embeddings of Sobolev spaces and at the moment I am trying to understand why $H^1(0,1)\subset C(0,1)$.
The proof I found basically shows that for any $u\in H^1(0,1)$ the inequality
$$||u||_\infty \leq c ||u||_{H^1(0,1)}$$
holds for some constant $c>0$, but I don't understand yet why this proves the subset statement.","['sobolev-spaces', 'functional-analysis']"
427548,The space of probability measures or probability distributions,"I am noticing some probability theory notions like the space of Borel probability measures on some specific metric spaces. But then I cannot quite understand the reason of defining different kinds of ""spaces"". Concretely, we might have the following spaces in consideration: (1) the space of probability measures; (2) the space of cumulative distribution functions; (3) the space of probability distribution functions; I am not sure if some certain property like convergence or continuity of one space would imply some property of the other space. Nevertheless, except the reason that not all probability measures are defined on the real line, what could be the intuitive reasons to define different notions of spaces. One example I am considering is the following. Suppose we want to define some notion regarding ""symmetry"". Then, we could start from defining what would be a symmetric probability measure. Then, this symmetry property would be inherent to the corresponding cumulative probability function, if the probability measure is a Stieltjes measure. Also, it is also equivalent to define symmetry by using the corresponding probability density function. Is there any counter-example that shows there is no simple way to induce the symmetry property from one element in one space to one element in another space?","['probability-theory', 'probability-distributions', 'real-analysis']"
427552,How to examine if multivariable functions are differentiable?,"How to examine if functions: $f(x,y)=|x+y|$ and $g(x,y)=\sqrt{|xy|}$ are diffirentiable in points: $(0,0)$ for $f(x,y)$ and $(0,1)$ for $g(x,y)$",['multivariable-calculus']
427559,Prove $\frac{\cos^2 A}{1 - \sin A} = 1 + \sin A$ by the Pythagorean theorem.,How do I use the Pythagorean Theorem to prove  that $$\frac{\cos^2 A}{1 - \sin A} = 1 + \sin A?$$,"['trigonometry', 'alternative-proof']"
427596,Faithful group actions and dimensions,"Just a quick question.  I'm trying to understand the answer to one of my previous questions .  The precise problem I want to show is as follows. Let $G$ be a group acting faithfully on a manifold $X$.  If $G$ is such that $\dim G$ makes sense (for example, $G$ is also a manifold), then $\dim G \leq \dim X$. Suppose not, i.e., $\dim G > \dim X$.  Then we wish to show that the kernel of the homomorphism $G \to \operatorname{Aut}(X)$ is nontrivial.  This should follow if $\dim \operatorname{Aut}(X) = \dim X$, but in general $\operatorname{Aut}(X)$ can be much larger than $X$.  (Also, does $\dim \operatorname{Aut}(X)$ make sense?) Any suggestions? EDIT: It turns out that this proposition is false as the examples below show, and the answer I linked to has been retracted (and is being rewritten?). Thanks  to everyone for the help.","['group-theory', 'group-actions']"
427608,The wedge product,"I have seen the wedge-product as being defined in differential geometry in the definition of a differential form or p-form. Now in the course we have proven the basic properties of this product and how to take the differential. Now when we apply this to the differentiation of a function in on a curved manifold, we make the following change in the integral $\int dx^n\rightarrow\int dx^0\wedge dx^1\wedge...\wedge dx^{n-1}$. I don't see how the wedge product is related to the volume element, I was hoping that you guys might be able to clear that up for me ? Second, I already asked around about this, the wedge product is said to be the generalisation of the cross vector product and the 3D volume element to higher dimensions. I was woundering of anyone could explain that ?","['exterior-algebra', 'differential-geometry']"
427634,A Topology such that the continuous functions are exactly the polynomials,"I was wondering which fields $K$ can be equipped with a topology such that a function $f:K \to K$ is continuous if and only if it is a polynomial function $f(x)=a_nx^n+\cdots+a_0$. Obviously, the finite fields with the discrete topology have this property, since every function $f:\Bbb F_q \to \Bbb F_q$ can be written as a polynomial. So what is with infinite fields. Does anyone see any field $K$ where such a topology can be found? If there is no such field, can anyone supply a proof that finding such a topology is impossible. I would even be satisfied if one could prove this nonexistence for only one special field (say $\Bbb Q, \Bbb R,\Bbb C$ or $  \Bbb F_q^\text{alg} $). I suspect that there is no such topology, but I have no idea how to prove that.
$$ $$ (My humble ideas on the problem: Assume that you are given such a field $K$ with a topology $\tau$. Then for $a,b \in K$ , $a \ne 0$, $x \mapsto ax+b$ is a continuous function with continuous inverse, hence a homeomorphism. Thus $K$ is a homogenous space with doubly transitive homeomorphism group. Since $\tau$ cannot be indiscrete, there is an open set $U$, and $x,y \in K$ with $x \in U,y \not\in U$. Now for every $a \in K$, $a*(U-y)/x$ includes $a$ but not $0$, and thus $K\setminus\{0\}=\bigcup_{a \in K^\times}a*(U-y)/x$, is an open subset. Thus $K$ is a T1 space, i. e. every singleton set $\{x\}$ is closed. Also $K$ is connected: Otherwise, there would be a surjective continuous function $f:K \to \{0,1\} \subset K$, which is definitely not a polynomial.) EDIT: This question asks the analogous question with polynomials replaced by holomorphic functions. Feel free to post anything which strikes you as a remarkable property of such a hypothetical topology.","['general-topology', 'continuity', 'polynomials']"
427635,Grandi's series contradiction [duplicate],"This question already has answers here : Finding the fallacy in this broken proof (6 answers) Closed 10 years ago . This is the Grandi's series: $1-1+1-1+1-1+\dots$ The series can be equal to $0$ $$(1-1)+(1-1)+(1-1)+\dots=0+0+0+\dots=0,$$ or to $1$ $$1-(1-1)-(1-1)-(1-1)-\dots=1-0-0-0\dots=1,$$ or to $1/2$ $$S=1-1+1-1+1-\dots,\quad\quad    S=1-(1-1+1-1+1-1+1-...)$$
$$\Rightarrow   S=1-S\Rightarrow     2S=1\Rightarrow    S=1/2$$ Isn't this a contradiction? The integers are closed under addition and subtraction, but we get a fraction. Why?",['sequences-and-series']
427652,What's the most efficient way to put all the stones in one pile?,"There are $k$ piles of $n_i$ stones, on every move you can choose two piles with sizes $a$ and $b$ and if $a \ge b$ take from the first pile $b$ stones and put to the second one, on other hand if $a < b$ - take $a$ from the second and put them to the first. What is the necessary and sufficient condition to put all stones in one pile and what is the smallest number of such operations to do it? The first question is rather simple: iff $\frac{\sum{n_i}}{\gcd(n_1, n_2 ... n_k)}=2^p$
But I dont know answer for the second one, I can prove that it is $O(kp)$, but I think that we can do it much more quicker and my hypothesis is $O(k + p))$. Can anyone to prove it or may be refuse it? May be there exists some better estimation for the number of moves, if you have, please tell me.","['discrete-mathematics', 'algorithms', 'number-theory']"
427659,How to understand rank-nullity / dimension theorem proof?,"OK, I am working on proofs of the rank-nullity (otherwise in my class known as the dimension theorem). Here's a proof that my professor gave in the class. I want to be sure I understand the reasoning. So I will lay out what he had here with a less-precise layman's wording, as I want to be sure I know what I am doing. It makes the proof easier to memorize for me. So: Let V and V be vector spaces. T:V→W is linear and V is finite-dimensional and function $f \in Hom_K (V,W)$ Let dim(V) = n for some n$\in \mathbb N$ and dim(ker($f$) = $r$ dim(V) = nullity(T) + rank(T) = dim(ker($ f$ ) + dim(Im($ f$ )) in some notations (like the one in our text) this wold look like dim(V) = nullity(T) + rank(T) = dim(N(T)) + dim(R(T)) on to the proof: $ker(f) \subseteq V$. And it is a subspace. Why a subspace? Because, since the kernel of any function is the set of vectors that goes to zero, adding to those vectors another vector in V will still be in V, a will multiplying them (since they go to zero). since we let dim(V)=n all the bases (basis-es?) of V will have n elements. therefore  $  \exists$  a basis {$x_1 , x_2 , ... , x_r$} of $ ker(f)$  where r≤n. (The reason is that any basis will have an equal or lesser number of dimensions than the space it describes. ker(f) is a subspace). by the exchange lemma, which says that given any linearly independent subset 
$ \exists  {y_1 , y_2 , ... y_s } \in V $ such that {$y_1 , y_2 , ... y_n $}$ \cap $ {$x_1 , x_2 ,... ,x_r$}$ = \varnothing $ the next step says that {$y_1 , y_2 , ... y_n$}$ \cup ${$x_1 , x_2 ,... ,x_r$} is a basis of V. Now, my question is if that is because the intersection of the two sets is the empty set and they are linearly independent? After that, we get to saying that {$ f(y_1), f(y_2),... f(y_n)$ } is a basis of Im($ f$ ). But I am not sure why that is. He then says we can claim the following: 
$  λ_1 f(y_1) + λ_2 f(y_2)+... +λ_s f(y_s)= 0 $ for some $λ_1, λ_2, ..., λ_s $  \in $  K so taking 
$$f \Big( \sum_{i=1}^s x_i y_i \Big) = 0 $$
we can make that into 
$$ \Big[ \Big( \sum_{i=1}^s \lambda_i f(y_i) \Big) \Big] =   \sum_{i=1}^s \lambda_i y_i  \in ker(f)$$ That step I am a bit fuzzy on the reasoning. IIUC, it's just saying that taking the sum of f using the union of x an y sets equals zero (its just f(x,y) ) and the summation of the product of λ and all the f(y) terms is the same as the sum of all the λy terms and they are all in the kernel of f. But I wanted to be sure. He then said that the above implies that there exists some set of scalars, $α_1, α_2, ... α_s \in$  K s.t. $$ \sum_{i=1}^s \lambda_i y_i = \sum_{j=1}^r y_i x_j$$  and that further implies $$\sum_{j=1}^r \alpha_j x_j - \sum_{i=1}^s \alpha_i x_i  = 0 $$ which implies $α_j, λi = 0$ for all 1≤j≤r and 1≤i≤s. and that further implies that the set {$f(y_1), f(y_2), ... ,f(y_s )$} is linearly independent. Then he says: for all z in the Im(f) there exists x$ \in V$ s.t. $z=f(x)$ (this seems obvious at one level but I felt like it was just sleight of hand). then $z = f \Big(\sum_{j=1}^r \alpha_j x_j - \sum_{i=1}^s \lambda_i y_i \Big) = \sum_{j=1}^r \alpha_j f(x_i) + \sum_{i=1}^s x_i f(y_i)= 0 + \sum_{i=1}^s x_i f(y_i)$ and then he says dim(V) = r + s = dim(ker(f)) + dim(Im(f)) its the last few steps I can't seem to justify in my head. Any help would be appreciated (and seeing if I copied this wrong from the board).","['vector-spaces', 'linear-algebra']"
427660,Extension theorem on acyclic relations,"By Sziplrajn's Theorem, we know that every partial order $\succsim$ (i.e. reflexive, transitive and antisymmetric relation) on a nonempty set $X$ can be extended to a linear order (i.e. a complete partial order) on $X$ , where an extension of $~\succsim$ is a preorder $~\trianglerighteq$ such that for all $x,y \in X$ , $x\succsim y$ implies $x\trianglerighteq y$ . I am looking for a variant of this theorem in which the extension should simply be a preorder (reflexive and transitive), and the initial relation would only be required to be acyclic (an acyclic relation is one for which there exists no list $(x_1, x_2, \dots, x_n)$ with $x_i \in X$ for all $i\in \{1,\dots,n\}$ and $x_1\succsim x_2 \succsim \dots \succsim x_n \succsim x_1$ ) So can any acyclic relation be extended to a preorder?","['relations', 'discrete-mathematics']"
427664,bijective measurable map existence,"Does there exist bijective measurable maps between $\mathbb{R}$ and $\mathbb{R}^n$? If so, could you give me an example of that? Thank you.","['measure-theory', 'real-analysis']"
427667,Proving Tychonoff's theorem with the Compactness theorem of logic,"It seems to be known that Tychonoff's Theorem for Hausdorff spaces and the Compactness theorem of first order logic are both equivalent over ZF to the ultrafilter lemma. Does anyone know a slick proof for the implication ""Compactness Theorem $\rightarrow$ Tychonoff for Hausdorff spaces"" (without using the ultrafilter lemma as an intermediate step)?","['model-theory', 'general-topology', 'logic', 'compactness', 'first-order-logic']"
427685,Rewrite constrained optimization objective,"I wanted to ask, under which conditions can one rewrite the optimization objective $\min_x f(x)\;\;\;s.t.\;\;\;g(x) \leq s$ as $\min_x g(x)\;\;\;s.t.\;\;\;f(x) \leq t$ I have particular interest in the case where $f(x) = \|x\|_1$ and $g(x) = \|y - Ax\|_2$ (i.e. for the Lasso!), but would like to know the details for the general case. References to appropriate books would be equally useful. Thank you!","['optimization', 'statistics', 'numerical-optimization', 'convex-optimization', 'linear-programming']"
427691,Demonstrating a coin is not fair with as few flips as possible,"Suppose you have an ""unfair"" coin, that lands heads with probability $p\in(1/2,1]$ (where $p$ is known to you). You are given some $\epsilon>0$, and want to demonstrate to someone that this coin is not fair with confidence $1-\epsilon$, using as few flips as possible. What is the optimal method for doing this? Formally, this is what I mean: define $X=\{H,T\}^\omega$, the space of infinite sequences consisting of heads and tails. This space has two probability measures on it: $\mu_p$, the probability measure coming from the unfair coin, and $\mu_{1/2}$, the probability measure that would come from a fair coin. We choose an event $E\subset X$ satisfying $\mu_{1/2}(E)\leq \epsilon$, and define a function $f_E:X\to \mathbb{Z}_{>0}\cup\{\infty\}$,
$$
f(a_1,a_2,\ldots)=\inf \{n:(b_1,b_2,\ldots)\in E\text{ whenever }b_1=a_1,\ldots,b_n=a_n\}.
$$
Thus $f(a_1,a_2,\ldots)$ is the number of coin flips required to establish that $(a_1,a_2,\ldots)\in E$. In particular, $f(a_1,a_2,\ldots)=\infty$ if $(a_1,a_2,\ldots)\not\in E$. We would like to choose $E$ so that the quantity
$$
\int_X f(x)\,d\mu_p(x)
$$
is finite and as small as possible. One possibility is to take
$$
E=\{(a_1,\ldots):\exists N\geq N_0\text{ s.t. }\#\{n\leq N:a_n=H\}>\frac{\frac{1}{2}+p}{2}N\},
$$
where $N_0$ is chosen to be sufficiently large (depending on $\epsilon$). In other words, we flip at least $N_0$ times, the stop when the proportion of heads is closer to $p$ than to $\frac{1}{2}$. By choosing $N_0$ sufficiently large, we will have $\mu_{1/2}(E)\leq \epsilon$, and I believe we also get $\int_X f(x)\,d\mu_p(x)<\infty$. It seems clear that this choice of $E$ is not optimal, however.",['probability']
427692,"In $S_9$: for given $\sigma$ is there $\tau$ with $\tau^2=\sigma, \; \tau^3 = \sigma$?","Struggling with these: Let $\sigma$ in $S_9$ be given by $\sigma=(8\,9)(5\,6\,7\,1\,2\,3\,4)$. 1: Is there a $\tau\in S_9$ with $\tau^2=\sigma\,?\;$ Tip : think of $ \epsilon ( \sigma)$. 2: Is there a $\tau\in \langle\sigma \rangle$ with $\tau^3=\sigma\,?\;$ Tip : think of $ \operatorname{order}( \sigma)$. Thanks in advance!","['symmetric-groups', 'group-theory', 'abstract-algebra']"
427694,Prove that the matrix is totally unimodular,"Is there any (theoretic) way I can prove the matrix is totally unimodular? I have tested it by Matlab and know it is TU, however I cannot prove it. -1 -1 -1 -1  0  0  0  0  0  0  0  0
 0  0  0  0 -1 -1 -1 -1  0  0  0  0
 0  0  0  0  0  0  0  0 -1 -1 -1 -1
 1  1  1  1  0  0  0  0  0  0  0  0
 0  0  0  0  1  1  1  1  0  0  0  0
 0  0  0  0  0  0  0  0  1  1  1  1
 1  0  0  0  1  0  0  0  1  0  0  0
 0  1  0  0  0  1  0  0  0  1  0  0
 0  0  1  0  0  0  1  0  0  0  1  0
 0  0  0  1  0  0  0  1  0  0  0  1","['matrices', 'integer-programming', 'total-unimodularity', 'determinant']"
427703,Prove this block matrices are similar,"Prove that the block matrices
$
\left(
\begin{array}{cc}
AB & 0\\
B & 0\\
\end{array}
\right)
$
and
$
\left(
\begin{array}{cc}
0 & 0\\
B & BA\\
\end{array}
\right)
$
are similar. Where $\mathbf{K}$ is any field, $A\in \mathbf{K}^{m\times n}$, $B\in \mathbf{K}^{n\times m}$
and both matrices in $\mathbf{K}^{(m+n)\times (m+n)}$. I searched the Internet well enough and found no similar problem. Thanks in advance!","['matrices', 'linear-algebra', 'block-matrices']"
427718,generalisations of Lagrange's four-square theorem,"For which  positive integers $a, b, c, d$, any natural number $n$ can be represented as
$$n=ax^2+by^2+cz^2+dw^2$$
where $ x, y,z,w$ are integers? Lagrange's four-square theorem states that $(a,b,c,d)=(1,1,1,1)$ works. Ramanujan proved that  there are exactly $54$ possible choices for $a, b, c, d$. 2  . For which  positive integers $a, b, c, d$, 
$$n=ax^2+by^2+cz^2+dw^2$$
 is solvable in integers $ x, y,z,w$ for all positive integers $n$  except one number? For example, $n=x^2+y^2+2z^2+29w^2$ is solvable for all natural number $n$ except $14$, $n=x^2+2y^2+7z^2+11w^2$ and $n=x^2+2y^2+7z^2+13w^2$  except $5$ P.R.Halmos proved that there are exactly $88$ possible choices for $a, b, c, d$. How to get that? Can recommend some references? Thanks",['number-theory']
427721,Show that the interior of a convex set is convex,"Question: Let $P\subseteq \mathbb{R}^n$ be a convex set. Show that $\text{int}(P)$ is a convex set. I know that a point $x$ is said to be an interior point of the set $P$ if there is an open ball centered at $x$ that is contained entirely in $P$ . The set of all interior points of $P$ is denoted by $\text{int}(P)$ . Also, to say that a set $P$ is convex means that if $x,y \in P$ then $tx+(1-t)y \in P$ for all $t \in (0,1)$ . How to go about the above proof?","['general-topology', 'convex-analysis']"
427722,Singularity in matrix when inverting in Matlab,"As data I get a matrix A but in my algorithm I need to work on its inverse. What I do is: C = inv(A) + B; Then in another line I update A. In the next cycles I also need (updated) A inverse, again for this algorithm. And so on. In the later cycles I get this: Matrix is close to singular or badly scaled. Results may be inaccurate. RCOND = 1.425117e-019 or this: Warning: Matrix is singular to working precision. or this: Warning: Matrix is singular, close to singular or badly scaled. Results may be inaccurate. RCOND = NaN. Can you help me how to avoid such singularity? Matrix is squared always.","['matrices', 'matlab', 'inverse']"
427726,The minimal polynomial of a primitive $p^{m}$-th root of unity over $\mathbb{Q}_p$,"Proposition 7.13 of Neukirch's ANT states that for a primitive $p^{m}$-th root of unity $\zeta$ ($p$ prime) the extension $\mathbb{Q}_{p}(\zeta)/\mathbb{Q}_{p}$ is totally ramified of degree $(p-1)p^{m-1}$. In the proof he shows that the polynomial $\phi(X)=X^{(p-1)p^{m-1}}+X^{(p-2)p^{m-1}}+\cdots+1$ is the minimal polynomial of $\zeta$ over $\mathbb{Q}_p$ . I can't see how to obtain the congruence $\phi(X)=(X^{p^m}-1)/(X^{p^{m-1}}-1)\equiv(X-1)^{p^{m-1}(p-1)}$ mod $p$ as claimed in the book. 
Here, I take it that mod $p$ means mod $p\mathbb{Z}$ and not mod $p\mathbb{Z}_{p}$ ? Also, does Eisenstein's irreducibility criterion extend to polynomials in $\mathbb{Q}_{p}[X]$ ? Any help would be very much appreciated.","['cyclotomic-polynomials', 'number-theory']"
427784,help with a blowup,"I'm currently learning the basics of blowups and I find that a bit hard. I would like to work out the following example. Could you help me? Let $k$ be a field and $\mathbb{A}^n_k=\operatorname{Spec}(k[x_1, \ldots, x_n])$. Consider the linear subspace generated by the $r$ first vectors, that is, 
$$
\Lambda=(x_{r+1}=\cdots=x_n=0) \subset \mathbb{A}^n 
$$
and let $X=\operatorname{Bl}_\Lambda \mathbb{A}^n_k$ be the blowup of $\mathbb{A}^n_k$ along $\Lambda$. Question 1 : Which are the explicit equations of $X$? Question 2 : What is the exceptional divisor in these equations? Now let $\Lambda'$ and $\Lambda''$ be two other linear subspaces with the property that 
$$
\Lambda \cap \Lambda', \quad \Lambda \cap \Lambda'' \quad and \quad \Lambda' \cap \Lambda''
$$ are all reduced to $\{0\}$. We can assume WLOG that $$
\Lambda'=(x_1=\cdots=x_r=x_{r+s+1}=\cdots=x_n=0) \subset \mathbb{A}^n_k
$$ $$
\Lambda'=(x_1=\cdots=x_{r+s}=x_{r+s+t+1}=\cdots=x_n=0) \subset \mathbb{A}^n_k
$$ Question 3 : Which are the equations of the proper transforms of $\Lambda'$ and $\Lambda''$? Question 4 : What does the intersection of these transforms with the exceptional divisor look like?","['blowup', 'algebraic-geometry']"
427787,Characterization of the Subsets of Euclidean Space which are Homeomorphic to the Space Itself,"I have no real experience in topology (although I have done a course in metric spaces) but in the course of a project I am doing it has become useful to produce (if possible) a characterization of the subsets of arbitrary dimensional Euclidean Space (with the usual metric and topology) that are homeomorphic to the whole space. I started by looking at the sorts of properties which are conserved under homeomorphism and found that such a subset is open and connected. I have also shown that convex open sets are homeomorphic to R^n. However, what I am really looking for is an equivalence between subsets homeomorphic to R^n and subsets with a list of specific properties (e.g. open, convex). That I can use to identify any possible homeomorphic subset. Hints and statements of characterization would be appreciated as starting points. However, I would like to work through the necessary proofs on my own if possible. Thank You","['general-topology', 'metric-spaces']"
427816,how to integrate $\int\underbrace{x^{x^{\cdot^{\cdot^x}}}}_ndx$,"how to integrate $$\int\underbrace{x^{x^{\cdot^{\cdot^x}}}}_ndx$$ $\color{red}{\text{or how to calculate  this integral  when its bounded}}$ $$\color{red}{\int_0^1\underbrace{x^{x^{\cdot^{\cdot^x}}}}_ndx}$$ Thanks in advance. $\color{green }{\text{my attempt}}$ :
its easy to integrate $\int x^xdx$ $$\int{x^xdx} = \int{e^{\log x^x}dx} = \int{\sum_{k=1}^{\infty}\frac{x^k\log^k x}{k!}}dx=  \sum_{k=0}^\infty \frac{1}{k!}\int x^k(\log x)^k\,dx \Rightarrow$$ substitute ${u = -\log x}$ then  $$ \int x^xdx=\sum_{k=0}^\infty \frac{(-1)^k}{k!}\int e^{u(k+1)}u^k\,du=\sum_{k=0}^\infty \frac{(-1)^k}{k!}\frac{1}{(k+1)^k}\int e^{u(k+1)}[(k+1)u]^k\,du.$$
Ii substitute  $t = (k+1)u$ and  $$\sum_{k=0}^\infty \frac{(-1)^k}{k!}\frac{1}{(k+1)^k}\int e^tt^k\,dt $$ if i put bound for this integral we have $$\int _0^1x^xdx=\sum_{k=0}^\infty \frac{(-1)^k}{k!}\frac{1}{(k+1)^k}\int_0^{\infty} e^tt^k\,dt =\sum_{k=0}^\infty \frac{(-1)^k}{(k+1)!}\frac{1}{(k+1)^k}\Gamma(k+1)=\sum_{k=0}^\infty \frac{(-1)^k}{(k+1)^{k+1}} = \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n^n}$$ $$\int_0^1\underbrace{x^{x^{\cdot^{\cdot^{x}}}}}_ndx=\int_0^1e^{\log\underbrace{x^{x^{\cdot^{\cdot^{x}}}}}_n}dx=\sum_{k=0}^\infty\frac{1}{k!}\int_0^1\biggl(\underbrace{x^{x^{\cdot^{\cdot^{x}}}}}_{n-1}\biggr)^k(\log x)^k~dx$$","['integration', 'power-towers']"
427820,"Show that the Beta Function $\beta (x,y)$ Converges When $x \gt 0, \space y \gt 0$","Given $ \beta (x, y) = \int_0^1 t^{x-1}(1-t)^{y-1} dt$, Show that $\beta (x,y)$ converges when $x \gt 0, \space y \gt 0$. $$\int_0^1 t^{x-1}(1-t)^{y-1} dt = \int_0^{0.5} t^{x-1}(1-t)^{y-1} dt + \int_{0.5}^1 t^{x-1}(1-t)^{y-1} dt$$
Now, according to the text, for the integral from $0$ to $1 \over 2$, $t^{x-1}(1-t)^{y-1} \le t^{x-1}$. $\int_0^{0.5} t^{x-1} dt \lt {\infty}$ entails that $\int_0^{0.5} t^{x-1}(1-t)^{y-1} dt$ converges. Well, $t^{x-1}(1-t)^{y-1} \le t^{x-1}$ when $y \ge 1$, not for all $y \gt 0$. Then the text does something similar for the integral from ${1 \over 2}$ to $1$: Since $t^{x-1}(1-t)^{y-1} \le (1-t)^{y-1}$, $\int_{0.5}^1 (1-t)^{y-1} dt \lt {\infty}$ entails that $\int_{0.5}^1 t^{x-1}(1-t)^{y-1} dt$ converges. Well, $t^{x-1}(1-t)^{y-1} \le (1-t)^{y-1}$ when $x \ge 1$. So the text shows that $\beta (x,y)$ converges when $x, y \ge 1$. Did I make a mistake somewhere or misunderstand something?","['convergence-divergence', 'integration']"
427834,Can all real/complex vector spaces be equipped with a Hilbert space structure?,"Let $X$ be a vector space over $\mathbb K \in \{\mathbb R, \mathbb C\}$. 
Does there exists a pairing $X \times X \rightarrow \mathbb K$ that induces a Hilbert space structure on $X$? I have been thinking that one may choose an arbitrary basis of $X$, which exists by the axiom of choice, and declare it as the orthonormal basis of the Hilbert space, but then limits of series might become unhandy.","['set-theory', 'linear-algebra', 'functional-analysis']"
427843,"If $ 5x+12y=60$ , what is the minimum of $\sqrt{x^2+y^2}$?","I know this can be easily done by solving for $y$ and substituting, so that you only have to find the minimum value of the parabola $\large x^2 + \left ( \frac {60-5x}{12} \right)^2$ using standard techniques, but is there a less messy way to do this using inequalities? I tried various things such as $AM-GM$, but I don't get anywhere. One thing which I did notice about the restriction is that it is of the form $ax+by=ab$, but I don't know how to make any use of that. Thanks.","['inequality', 'algebra-precalculus']"
427844,A terminology to analysts,"When analysts say ""$\epsilon$ (or whatever greek symbol) can be chosen arbitrary small"", do they really just mean we can take $\epsilon = 0$ or $\epsilon \to 0$ later? When I asked myself this question, I immediately began doubting my understanding of limits. That is $\forall \epsilon>0 ,\exists \delta > 0 :|x-a|<\delta \implies |f(x) - L|<\epsilon$. I was taught that a very long time ago, a limit is something you approach very closely , but not exactly equal to . So what logic rule am I breaking if i take $\epsilon = |f(x) - L|$? Also, what is the advantage of proving two things are equal by saying they are epsilon close to each other? Isn't this really just make it harder than it needs it to be? EDIT I have also noticed that some other definitions that uses epsilon distance instead of just saying they are equal to each other. $f \in R(\alpha)$ on $[a,b] \iff \forall \epsilon >0, \exists$ partition $P$ such that $$U(f,P,\alpha) - L(f,P,\alpha) < \epsilon$$ Now what is wrong with saying $f \in R(\alpha)$ on $[a,b] \iff  \exists$ partition $P$ such that $$U(f,P,\alpha) =  L(f,P,\alpha) $$","['logic', 'calculus', 'limits']"
427868,Book recommendations for relearning high school math to study Calculus and beyond?,"Assume someone has very limited knowledge of math: low level high school, 5-6 years ago. How would they learn from the basics of algebra, geometry and trigonometry to a solid foundation for calculus and beyond? I would like to relearn math and go to university for computer science. I am looking for book recommendations , math learning strategies (how to comprehend math texts), and a brief explanation as to how one knows when they are ready to learn calculus. Some books' prose is quite overwhelming. How can I better understand? How essential is geometry for calculus? What about for further math such as linear algebra, discrete math or differential equations? How can I make sure that what I am reading/learning will stick? How can I maximize comprehension of a textbook and rule /definitions? Is notetaking out of a textbook effective? Is it essential to master high-school math before attempting calculus or can holes be patched in the process of learning calculus? I am not simply looking for youtube videos, though they are useful I want more substance than simply being spoon-fed.","['algebra-precalculus', 'education', 'self-learning', 'reference-request', 'soft-question']"
427886,Finite union of compact sets is compact,"Let $(X,d)$ be a metric space and $Y_1,\ldots,Y_n \subseteq X$ compact subsets. Then I want to show that $Y:=\bigcup_i Y_i$ is compact only using the definition of a compact set. My attempt: Let $(y_n)$ be a sequence in $Y$. If $\exists 1 \leq i \leq n\; \exists N \in \mathbb N \; \forall j \geq N\; y_j \in Y_i$ then $(y_n)$ has a convergent subsequence because $Y_i$ is compact. Otherwise,
$$
\forall 1 \leq i \leq n \; \forall N \in \mathbb N\; \exists j \geq N\; y_j \notin Y_i
$$ Assuming for the moment that $n = 2$ and using induction later we have that
$$
\forall N \in \mathbb N \; \exists j \geq N \; y_j \in Y_1 \backslash Y_2
$$ With this we can make a subsequence $\bigl(y_{n_j}\bigr)_{j=0}^\infty$ in $Y_1 \backslash Y_2$. This sequence lies in $Y_1$ and thus has a convergent subsequence. This convergent subsequence of the subsequence will then also be a convergence subsequence of the original sequence. Now we may use induction on $n$.","['general-topology', 'metric-spaces', 'compactness']"
427894,Any good books on Mathematics and Programming?,"I've been on google for a while now searching for a good book on mathematics combined with programming, but either the level of math they're starting at is too high or the level of programming is too high, so now I'm here for your help. My math is pretty bad(still struggling with pre-calculus), I'm trying to improve. I also just started to learn programming for about a month now. Is there a good book that could improve my understanding of mathematics through programming?(any programming language will do) Thank you.","['book-recommendation', 'discrete-mathematics', 'reference-request']"
427910,A simple way to obtain $\prod_{p\in\mathbb{P}}\frac{1}{1-p^{-s}}=\sum_{n=1}^{\infty}\frac{1}{n^s}$.,"Let $ p_1<p_2 <\cdots <p_k < \cdots $ the increasing list in set $\mathbb{P}$ of all prime numbers .
By sum of infinite geometric series we have $\sum_{k=0}^\infty r^k = \frac{1}{1-r}$ , for $0<r<1$ . For all $s>1$ and $r=\frac{1}{p_k^{s}}$ we have $$
\begin{array}{cccccc}
\dfrac{1}{1-p_{1}^{-s}}
&
=
&
1+\dfrac{1}{(p_1^s)^1}+\dfrac{1}{(p_1^s)^2}+\dfrac{1}{(p_1^s)^3}+
&
\!\!\cdots\!\!
&
+\dfrac{1}{(p_1^{s})^{\alpha_1}}+
&
\cdots
\\
\dfrac{1}{1-p_{2}^{-s}}
&
=
&
1+\dfrac{1}{(p_2^s)^1}+\dfrac{1}{(p_2^s)^2}+\dfrac{1}{(p_2^s)^3}+
&
\!\!\cdots\!\!
&
+\dfrac{1}{(p_2^s)^{\alpha_2}}+
&
\cdots
\\
\dfrac{1}{1-p_{3}^{-s}}
&
=
&
1+\dfrac{1}{(p_3^s)^1}+\dfrac{1}{(p_3^s)^2}+\dfrac{1}{(p_3^s)^3}+
&
\!\!\cdots\!\!
&
+\dfrac{1}{(p_3^s)^{\alpha_3}}+
&
\cdots
\\
\vdots 
&
\vdots
& 
\vdots
&
\vdots
&
\vdots
&\vdots
\\
\\
\vdots 
&
\vdots
& 
\vdots
&
\vdots
&
\vdots
&
\vdots
\\
\dfrac{1}{1-p_{k}^{-s}}
&
=
&
1+\dfrac{1}{(p_k^s)^1}+\dfrac{1}{(p_k^s)^2}+\dfrac{1}{(p_k^s)^3}+
&
\!\!\cdots\!\!
&
+\dfrac{1}{(p_k^s)^{\alpha_k}}+
&
\cdots
\\
\vdots 
&
\vdots
& 
\vdots
&
\vdots
&
\vdots
&
\vdots
\\
\end{array}
$$ And the Fundamental Theorem of Arithmetic tells us that every integer $ n> 1$ can be decomposed uniquely as a product $$
 n= p_{i_1}^{\alpha_{i_1}}p_{i_2}^{\alpha_{i_2}}\cdots p_{i_k}^{\alpha_{i_k}}
$$ of powers of prime numbers $p_{i_1}< p_{i_2}< \cdots < p_{i_k}$ for integers $\alpha_{i_1},\alpha_{i_2},\ldots,\alpha_{i_k}\geq 1$ . Since $
 n^s= (p_{i_1}^s)^{\alpha_{i_1}}(p_{i_2}^{s})^{\alpha_{i_2}}\cdots (p_{i_k}^s)^{\alpha_{i_k}}$ and
 using brute force with I can prove that $$
\prod_{p\in\mathbb{P}}\frac{1}{1-p^{-s}}=\sum_{n=1}^\infty \frac{1}{n^s}
$$ But I would like to know if there is a simple and elegant way to achieve this result is up through the above list.","['number-theory', 'independence', 'probability-theory', 'real-analysis', 'prime-numbers']"
427924,Real number construction : prove that $Q$ is a subfield of $R$,"I am slightly confused about the proof presented in Rudin. It says that the ordered field $Q$ is isomorphic to the ordered field $Q*$ whose elements are the rational cuts. It is this identification of $Q$ with $Q*$ which allows us to regard $Q$ as a subfield of $R$. Now, I know that if I have to prove that $A$ is a subfield of $(B,+,.)$ then first I need to prove that $A$ is a subset of $B$ and the field operations in $B$ can be extended to $A$. For example, let $a, b \in A$ then $a+b \in A$ should be true. Now for the above case, let $p$ and $q$ be two rational numbers each represented by the rational numbers less than them in $R$. Now if we add them using the $+$ operation in $R$, does that gives the rational number $p+q$ ? I don't think so.","['intuition', 'elementary-set-theory', 'real-analysis']"
427934,Basis reduction and continued fractions,"While reading several articles about lattice basis reduction I am left with a few questions. For one, I came across this piece of text Let $\alpha$ and $\beta \in \mathbb{R}$. Then there are two almost the same ways to compute small values for $\alpha x + \beta y$ with not too large $x,y \in \mathbb{Z}$. 1) applying the continued fraction algorithm 2) Applying the lattice basis reduction algorithm to the lattice generated by the columns of the matrix \begin{pmatrix} 1 & 0 \\ C\alpha & C\beta \end{pmatrix}
  for $C$ large enough. Why are those (for me different algorithms) in the above sense the same? And also, where is the $C$ coming from? When is it large enough? It obviously depends on something... All hints, examples or explanations are very much welcome.","['integer-lattices', 'discrete-mathematics']"
427944,Why inverse modulo exponentiation is harder than inverse exponentiation without modulo,I am new to number theory. I read in cryptography  inverse modulo exponentiation is used because it is hard. But I couldn't understand the advantage of it over  inverse exponentiation without modulo. Could someone please explain the advanatge,"['modular-arithmetic', 'exponentiation', 'elementary-number-theory', 'number-theory']"
427945,extrema and saddle points,"Examine the following function for relative extrema and saddle points:
$$f(x, y) = 9x^2-5y^2-54x-40y+4.$$ I did this and got that the point should be at $(3, -4, 3)$. Is that right? Also, how do I know if it is a saddle point or a minimum?",['multivariable-calculus']
427971,Determine whether $F(x)= 5x+10$ is $O(x^2)$,"Please, can someone here help me to understand the Big-O notation in discrete mathematics? Determine whether $F(x)= 5x+10$ is $O(x^2)$","['asymptotics', 'discrete-mathematics']"
427972,Probability Puzzle : Robot and coins,"Someone walks into your room and dumps a huge bag of quarters all over the floor. They spread them out so no quarters are on top of any other quarters. a robot then comes into the room and is programmed such that if it sees a head, it flips it to tails. If it sees a tail, it throws it in the air. the robot moves around randomly forever. Will there be a convergence in distribution of heads vs. tails? I am trying this puzzle for the past two days . But got lot of confusions !! As i don't know what is convergence in probability,i cannot proceed further. Please don't provide a link to wikipedia for convergence in probability.Can someone give me a simple definition of convergence in probability and explain the solution to the puzzle ?","['puzzle', 'convergence-divergence', 'probability']"
427975,Linear form does not vanish on any component,"I read Shafarevich basic algebraic geometry on page 70 he says for any $X \subseteq \Bbb{P}^N$ can find a linear form $L$ that does not vanish on any component of $X$, I tried to prove this by induction but failed how to prove this?",['algebraic-geometry']
427979,Finding the angle of a moving target,"I'm developing a submarine game and found a mathematical problem that exceeds my knowledge. A submarine has $x$ and $y$ coordinates in the plane, a speed $v$, and two angles: one indicates the direction in which it moves and the other direction it shoots. If a submarine in motion plans to shoot another that also is in movement, which the angle of rotation of the weapon that results in the destruction of the target? Besides the known data of the submarines we know that: Rotational speed of the weapon: $\tfrac {20^\circ}{\text{tick}}$. Shooting speed: $20 - \frac{1200}{\text{distance from target}} \frac{\text{space unit}} {\text {tick}}$. Maximum shooting speed: 3. The submarine is a rectangle of width $w$ and height $h$. Does anyone have any idea how to get a formula? The case that I will need more is when the shooter is stopped so, if someone can at least for this case, I'm grateful.","['geometry', 'computer-science', 'algorithms']"
427999,Does this system have a root?,"I have a set of nonlinear equations to solve which came up in my research. I take the conditional expected value of $N$ functions (which are $log()$) of $N$ independent non-identically distributed exponential random variables $X_1,..,X_i,..,X_j,...X_N$. These random variables are all known by their mean values. Then I obtain the set of functions $ f_1(\cdot),..,f_i(\cdot),..., f_N(\cdot)$, where the $i^{th}$ function $f_i(\cdot)$ is as follows: $$f_i(d_1,...,d_N)=[P(A_i)\cdot E_{X \mid A_i}\log(1+\cfrac{d_i}{\sum_{j \neq i}  X_j})] -c_i$$ The summation $\sum_{j \neq i}  X_j$ is the sum of all the $N-1$ random variables except $X_i$ i.e., sum over all $j=\{1,...,N\}\smallsetminus\{i\}$ The probability of the event $A_i$ is given by $P(A_i)=\prod_{j\neq i} P(X_j>d_j, X_j=\max\{X_j,Y_j,Z_j\})$. Here too the product is over all $j=\{1,...,N\}\smallsetminus\{i\}$ For a given $j={1,...,N}$ the three random variables $X_j, Y_j, Z_j$ are i.i.d., i.e., the $N$ sets $\{X_j, Y_j, Z_j\}$ for $j=1,...N$ are individually i.i.d. The $c_i$ for $i=1,...N$ are positive constants. Then I have $N$ functions of the $N$ unknowns $d_i$ for $i={i,..., N}$. Then I want to find a root of this set of functions such that $f_i=0$ for all $i$. Is there a method to solve it or is there some criteria that would assure the existence of a solution? I have tried Banach's fixed point theorem. But find it difficult to find a metric so that this set of functions has a contraction. Thank you.","['probability-theory', 'systems-of-equations', 'probability', 'real-analysis']"
428022,Linear Differential Equation,So I asked this question a while back but the answer I recorded really did not help me solve it. Find the general solution to: $a_0 + a_1x + a_2y + a_3dy/dx = 0$ If $a_0 = 0$ this becomes quite easy to solve (just set y = vx and factor it) but separation of variables doesn't work otherwise. I think it is important to note that this is non homogenous. Can someone give the general solution with an explanation of how it was solved (and if it isn't too much) as well as an explanation of intuitions/motivations behind the methods used?,"['ordinary-differential-equations', 'calculus']"
428023,"Let A be a family of pairwise disjoint sets. Prove that if B⊆A, then B is a family or pairwise disjoint sets.","I know that for this problem I have to use contradiction. Could anyone check my work and guide me through the problem if it's wrong? So far, this is what I have.Thanks!! Contradiction: $\mathcal B\subseteq \mathcal A$, then $\mathcal B$ is not a family of pairwise disjoint sets. If  $\mathcal B$ is not pairwise disjoint then  $\mathcal A \neq \mathcal B$ or $\mathcal A \cap \mathcal B\neq \varnothing $ then,
x $\in \mathcal A$ and x$\notin \mathcal B$ However, x $\in \mathcal B\subseteq \mathcal A$ , which is a contradiction since we said that x$\notin \mathcal B$.",['elementary-set-theory']
428046,Find $\lim_{n\to\infty}2^n\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}$.,"Find $\displaystyle \lim_{n\to\infty}2^n\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}$. By geometry method, I know that this is $\pi$. But is there algebraic method to find this
? Thank you.","['calculus', 'limits']"
428052,Dominated convergence and $\sigma$-finiteness,"I am curious about the Dominated Convergence Theorem for a sequence of functions that converges in measure. Theorem: Let $(X,\mathcal{S},\mu)$ be a measure space. If $\{f_n\}, f$ are measurable, real-valued (i.e. finite) and such that $f_n \to f$ in measure and $|f_n| \leq g$ with $\int g \,\mathrm{d}\mu < \infty$, then
$$ \int f_n \,\mathrm{d}\mu \to \int f \,\mathrm{d}\mu $$ Proof: Since $f_n \to f$ in measure, then for any subsequence of $\{f_n\}$, call it $\{f_k\}$, we have also $f_k \to f$ in measure. Now we can extract a further subsequence $\{f_{k_j}\}$ such that $f_{k_j} \to f$ almost everywhere. Applying the a.e. version of dominated convergence to this subsequence gives:
$$ \int f_{k_j} \,\mathrm{d}\mu \to \int f \,\mathrm{d}\mu $$
Now defining the sequence of real numbers $\{a_n\}$ by $a_n = \int f_n \,\mathrm{d}\mu$, we want to show that
$$a_n \to \int f \,\mathrm{d}\mu$$
But we have just shown that for any subsequence $\{a_k\}$ of $\{a_n\}$, there exists a further subsequence $\{a_{k_j}\}$ that converges to $\int f \,\mathrm{d}\mu$. Thus $a_n$ converges to $\int f \,\mathrm{d}\mu$ as well. QED. Question: So, nowhere in this proof did I use the fact that $\mu$ is $\sigma$-finite. However, everywhere that I look, I keep seeing this result with the condition that $\mu$ be $\sigma$-finite (e.g: Generalisation of Dominated Convergence Theorem ). So I must be doing something wrong? The only place I can think of where $\sigma$-finiteness might be required is in extracting an a.e. convergent subsequence from the ""in measure"" convergent sequence $\{f_k\}$. But I am pretty sure that $\sigma$-finiteness is not required to extract an almost uniformly convergent subsequence from an ""in measure"" convergent subsequence. And since almost uniformly convergent subsequences are also almost everywhere convergent, then I'm stumped. Any pointers?","['probability-theory', 'convergence-divergence', 'probability', 'real-analysis']"
428064,Distance of a test point from the center of an ellipsoid,"I'm trying to learn about Mahanalobis distance and I'm pretty close to getting the idea. I've learned that the distance has got a lot to do with the properties of an ellipsoid . I have understood so far that: The Mahalanobis distance is simply the distance of the test point $\textbf{x}$ from the center of mass $\textbf{y}$ divided by the width of the ellipsoid in the direction of the test point and is given by the formula: $$D(\textbf{x},\textbf{y})=\sqrt{ (\textbf{x}-\textbf{y})^TC^{-1}(\textbf{x}-\textbf{y})} $$ Now my question is: ""Why does this formula give us the distance of a point $\textbf{x}$ from the center of mass $\textbf{y}$ divided by the width of the ellipsoid in the direction of the test point?"" =) I don't understand or see how this formula describes that distance, could someone help explaining this distance more? How is the plain distance of a point $\textbf{x}$ from the ellipsoid's center of mass $\textbf{y}$ in the direction of the test point found and why? =) I hope my question is clear enough. My question could be analogous with for example ""Why does $c^2 = a^2 + b^2$"" Then you would prove this to me with a geometric proof or something =) Thank you for any help =) P.S. $C$ is the covariance matrix of vector $\textbf{x} = (x_1, ..., x_n)$","['geometry', 'multivariable-calculus', 'statistics', 'linear-algebra', 'probability']"
428075,"Do there exist polynomials $f,g$ such that $\mathbb{C}[a,b,c]\le\mathbb{C}[f,g]$ for $a,b,c$ given polynomials?","I want to prove something bigger than the problem in the title and I want to create a lemma that is useful for the solution of the problem. But I am unable to prove (or give a counterexample) the ""lemma"": Suppose that $a,b,c$ are given polynomials in $\mathbb{C}[x]$ such that $\mathbb{C}[a,b,c] \subsetneq \mathbb{C}[x]$. There exist polynomials $f,g \in \mathbb{C}[x]$ such that $\mathbb{C}[a,b,c]\le\mathbb{C}[f,g]$ where $\mathbb{C}[f,g]\subsetneq \mathbb{C}[x]$? (The symbol $\le$ obviously means subring.) Does anyone have any idea to prove this if it is true? Or give a counterexample if it is false?","['commutative-algebra', 'abstract-algebra', 'polynomials']"
428088,"Find nth derivative of $\frac{x^{n}}{(1-x)^{2}}$, please?","I need to find the nth derivative of $\frac{x^{n}}{(1-x)^{2}}$ for $0<x<1$ So far, I tried the same method used for $\frac{x^{n}}{1-x}$ and here's what I got:
\begin{equation}
\frac{x^{n}}{(1-x)^{2}}=x^{n}(1+2x+3x^{2}+4x^{3}+....)=(x^{n}+2x^{n+1}+3x^{n+2}+...)
\end{equation}
Take nth derivative to get:
\begin{align}
\frac{\partial^n }{\partial x^n} \frac{x^{n}}{(1-x)^{2}} \notag\\ = 
& (n!+2(n+1)!x+3\frac{(n+2)!}{2!}x^{2}+...) \notag\\ =
& n!(1+2(n+1)x+3\frac{(n+2)(n+1)}{2!}x^{2}+4\frac{(n+3)(n+2)(n+1)}{3!}x^{3}+..) 
\end{align}
Next would be finding a a function whose taylor expansion is the series in the parenthesis but I couldn't think of one. Any ideas for a function or for another method to do this? Thanks!","['taylor-expansion', 'calculus', 'derivatives', 'analysis']"
428092,$e^A=\lim_{j\to +\infty}(I+\frac{1}{j}A)^j$,I'm wondering if this is true: $e^A=\lim_{j\to +\infty}(I+\frac{1}{j}A)^j$ I need help thanks a lot.,['ordinary-differential-equations']
428100,Prove that $(3+5\sqrt{2})^m=(5+3 \sqrt{2})^n$ has no positive integer solutions?,"Is my proof ok? I set $b=3+5 \sqrt{2}$, so that we have $b^m=(b+2-3 \sqrt{2})^n$  , or $b^m=(b+\sqrt2(\sqrt2- 3))^n$. Since $RHS<LHS$, $n>m$ .  However, from what we know about binomial expansion, we will have a $b^n$ on the $RHS$ which will not cancel out with anything since it is the highest power, so we will never be able to reduce the $RHS$ to just $b^m$ . I don't really like my proof, is there a better one? And does this have a solution for rational powers, and how can you prove that it does/doesn't? Thanks.","['elementary-number-theory', 'algebra-precalculus', 'diophantine-equations']"
428102,$\lim_{t \to 0}g(t)=10$ $\lim_{t \to 10}f(t)=100$ but $\lim_{t \to 0}f(g(t))$ does not exist,"$\lim_{t \to 0}g(t)=10$ $\lim_{t \to 10}f(t)=100$ but $\lim_{t \to 0}f(g(t))$ does not exist.
Can anyone suggest two possible functions for f(t) and g(t)?
Both functions are defined on R","['functions', 'real-analysis', 'analysis']"
428115,"Isomorphism between quotient rings of $\mathbb{Z}[x,y]$","I need to find the condition on $m,n\in\mathbb{Z}^+$ under which the following ring isomorphism holds:
  $$
\mathbb{Z}[x,y]/(x^2-y^n)\cong\mathbb{Z}[x,y]/(x^2-y^m).
$$ My strategy is to first find a homomorphism
$$
h:\mathbb{Z}[x,y]\rightarrow\mathbb{Z}[x,y]/(x^2-y^m)
$$
and then calculate the kernel of $h$. To achieve this, I furthermore try to identify the isomorphism between $\mathbb{Z}[x,y]$ and itself, which I guess is 
$$
f:p(x,y)\mapsto p(ax+by,cx+dy)
$$ where $ad-bc=\pm 1,a,b,c,d\in\mathbb{Z}$. Then $f$ induces a homomorphism $h$. But from here I failed to move on. I believe there is some better idea, can anyone help? Updated: It should be isomorphism between quotient rings, not groups. Very sorry for such mistake.",['abstract-algebra']
428151,"Questions on ""All Horse are the Same Color"" Proof by Complete Induction","I'm bugged by the following that's summarized on p. 109 of this PDF . False theorem: All horses are the same color. Proof by induction: $\fbox{$P(n)$ is the statement: In every set of horses of size $n$, all $n$ horses are the same color.}$ $\fbox{Base Case or $P(1)$:}$ One horse is the same color as itself. This is true by inspection. $\fbox{Induction Step:}$ Assume $P(k)$ for some $k \geq 1$. $\fbox{Proof of $P(k + 1) :$}$ Since $\{H_1, H_2, ... , H_n\}$ is a set of $n$ horses, the induction hypothesis applies to this set. Thus, all the horses in this set are the same color. Since $\{H_2, H_3, ... , H_{n+1}\}$ is also a set of $n$ horses, the induction step likewise holds for this set. Thus, all the horses in this set are the same color too. Therefore, all $n +1$ horses in $\{H_1, H_2, H_3, ... , H_n , H_{n+1}\}$ are the same color. QED. The issue the instructor was trying to point out is clearly valid. For the case $n = 1$, there is only ${H_1}$. So this case says nothing about possible overlapping elements of each set of $(n + 1)$, for instance $H_2$ in the above proof. But it was proposed in the class discussion that this was the only problem. Had you been able to prove $P(2)$ true, then a proof of the above format would have been fine. My interpretation is that yes, you could prove all horses are the same color, if you can prove that any set of two horses will be the same color. But this format would not work. Why not? The problem I see is that the above proof is for the existence of at least one particular pair of sets of horses of sizes $n$ and $n + 1$, such that in each set, all horses are the same color.  Particularly when the set of size $n$ is a subset of the set of size $n + 1$.  In order to prove the induction step, don't you need to prove that sets of sizes $n$ and $n + 1$, do not necessarily contain the same, overlapping elements? You could prove that any horse can be added to a set of 2 horses.  Take the last two, and they must be the same color, and so on.  Wwhatever color the first two happen to be, all other horses must thus be the same color. Am I misinterpreting the example, or am I making a logical error? Thanks in advance.","['induction', 'discrete-mathematics', 'fake-proofs']"
428152,Polynomials mapping factorials to factorials,"I'm looking for all polynomials $P(x)$ with integer coefficients such that for every $n \in \Bbb N$ there is an $m \in \Bbb N$ such that $P(n!)=m$!. The only solutions seem to be the constant polynomials and $P(x)=x$. Any ideas? EDIT: When $P$ is linear, i. e. $P(x)=ax+b,a \ne 0$, we easily see that we must have $(n+1) n! > P(n!) > (n-1)!$ for large enough $n$, which yields $P(x)=x$. Thus we can restrivt ourselves to the case deg P>1. A divisibility argument now shows that $P(0)=0$ (by the way, $0 \not \in \Bbb N$). Any suggestions how to proceed further?","['factorial', 'elementary-number-theory', 'number-theory']"
428177,Existence of embeddings does not imply the existence of a homeomorphism,"Suppose there exist embeddings $f:X\to Y$ and $g:Y\to X$. Show by means of an example that $X$ and $Y$ need not be homeomorphic. I set $X=(0,1)$ and $Y=(0,\frac{1}{2})\cup (\frac{1}{2}, 1)$. 
I think $f:X\to Y$ defined by $f(x)=\frac{x}{2}$ is an embedding, correct? 
Also, clearly $g:Y\to X$ defined by $g(y)=y$ is an embedding. 
But as $X$ is connected and $Y$ is disconnected, there is no homeomorphism between them. Is this okay?",['general-topology']
428182,Proof of $e^z \neq 0$,"Proof: Let $a \in \mathbb{C}$ be s.t. $e^{a} =0$. Then $0=e^a e^{-a} = e^{-a+a} = e^0 =1$, contradicting the existence of $a$. But why can we multiply by $e^{-a}$?? If $e^a=0$, then $e^{-a}=\frac{1}{e^a}=\frac{1}{0}$ which can't be defined?","['exponential-function', 'complex-analysis']"
428204,"Calculate the Wronskian of $f(t)=t|t|$ and $g(t)=t^2$ on the following intervals: $(0,+\infty)$, $(-\infty, 0)$ and $0$?","How to Calculate the Wronskian of $f(t)=t|t|$ and $g(t)=t^2$ on the following intervals: $(0,+\infty)$, $(-\infty, 0)$ and $0$. And then how would I show that the Wronskian of the two functions $f$ and $g$ is equal to zero, i.e. $W(f,g)=0$? Also how would I establish that functions f and g are linearly independent on the interval $(-\infty, +\infty)$. Can a Wronksian be zero on all points and yet still be linearly independent?","['ordinary-differential-equations', 'real-analysis']"
428205,Degree and dimension of intersection of projective variety and hypersurface,"I am looking at Theorem 7.7 of Hartshorne where he states the general form of Bezout's Theorem. The hypotheses of the theorem are as follows. Let $H$ be a hypersurface of degree $d$ and $Y \subseteq \Bbb{P}^n$ a projective variety of dimension $r$. If $Z_1,\ldots,Z_s$ are the irreducible components of $Y \cap H$, then we have $$\sum_{i=1}^s i(Y,H;Z_i)\deg Z_i = (\deg Y)(\deg H)$$ where $i(Y,H;Z_j)$ is the length of $S/(I_Y + I_H)_{\mathfrak{p}_j}$ as a $S_{\mathfrak{p}_j}$ module. $S = k[x_0,\ldots,x_n]$, $\mathfrak{p}_j = I(Z_j)$ and $I_Y,I_H$ the homogeneous ideals of $Y$ and $Z$ respectively. My questions are: Is it possible to deduce the degree of the intersection $Y \cap H$ from this theorem? I could if I knew that $I_Y + I_H = I(Y \cap H)$ but this may not be true here. What do we know about $\dim Y \cap H$? At the moment I only know that every irreducible component of $Y \cap H$ has dimension $r-1$ but not necessarily $Y \cap H$ itself. Is there any relation between the dimension of a projective variety and its degree?",['algebraic-geometry']
428216,Finding integrating factor for inexact differential equation?,"Suppose we have the following differential equation that is NOT exact, i.e. $M_y \ne N_x$:
$2xy^3+y^4+(xy^3-2y)y'=0$ How would I find an integrating factor $μ(x,y)$ so that when I multiply this integrating factor by the differential equation, it become exact? Update: Here's what I got:",['ordinary-differential-equations']
428223,How can I add a curve to my otherwise linear values?,"I have built an interactive map for the Web that transitions smoothly from lon/lat point to lon/lat point. The duration of the transition is calculated dynamically and depends on the distance between the two points. I have commented my code, shown below, to better illustrate the current set-up. // Multiply the distance between points (given in radians)
// by the mean radius of the earth (given in kilometers) to
// give us the distance between points (in kilometers).

var distanceInKm = d3.geo.distance(fromPoint, toPoint) * 6371;


// The base speed - currently 5 kilometers per millisecond

var flySpeed = 5 / 1000;


// The duration of the transition (in milliseconds)

var flyTime = distanceInKm / flySpeed; My problem is flyTime increases and decreases linearly. I want bring down the top end to form a curve (something that looks like the top-left quarter of a circle, maybe), so I can reduce the transition time for particularly long (~10,000km+) journeys. I am not trying to model a real flight, but create a good user experience. Please could someone help me write an equation to do that, keeping it as simple as possible and also enlighten me as to which area of math my question covers? Edit: I have been exploring using the use of JavaScript's Math.log(x) function, with better results. I have been passing distanceInKm in to it to reduce the long journeys and better my transition time. Unfortunately, the curve that this function produces seems to be too harsh. For those feeling inclined, I have pasted a copy of my code, heavily commented, here: http://pastebin.com/kFkUTNC2 . Many thanks.","['interpolation', 'functions']"
428237,Why are asymptotically one half of the integer compositions gap-free?,"Question summary The number of gap-free compositions of $n$ can already for quite small $n$ be very well approximated by the total number of compositions of $n$ divided by $2$. This question seeks to understand why. The details A composition of an integer $n$ is a way of writing $n$ as the sum of a sequence of positive integers where order is important. This is different from partitions, where order is unimportant. It can easily be shown that the number of compositions of $n$ is $2^{n-1}$. See the Wikipedia article for a proof. A lot has been published about how the number of compositions changes when you put restrictions on them. One really interesting such restriction is ""gap-freeness"", i.e. containing every integer which is between the smallest and the largest integer in the composition. For example, $2+3+2+4+5$ is a gap-free composition of $16$, but $2+4+2+1+5+2$ is not, since there is a gap between $2$ and $4$. Furthermore, a composition is called ""complete"" if it is gap-free and contains the number $1$, i.e. all numbers from $1$ up to some integer $m$ are used in the summation. An example, the compositions of $n = 5$. g stands for gap-free and c for complete. 5           g
4+1
3+2         g
3+1+1
2+3         g
2+2+1       g, c
2+1+2       g, c
2+1+1+1     g, c
1+4
1+3+1
1+2+2       g, c
1+2+1+1     g, c
1+1+3
1+1+2+1     g, c
1+1+1+2     g, c
1+1+1+1+1   g, c So, the number of compositions of $n=5$ is $2^{5-1} = 16$, the number of gap-free compositions is $11$ and the number of complete compositions is $8$. Enumerating the number of compositions (#c), the number of gap-free compositions (#gc) and the number of complete compositions (#cc) for n from 1 to 10 gives the following table. n       #c      #gc     #cc
1       1       1       1
2       2       2       1
3       4       4       3
4       8       6       4
5       16      11      8
6       32      21      18
7       64      39      33
8       128     71      65
9       256     141     127
10      512     276     264 Continuations of these series can be found at oeis.org/A107428 and oeis.org/A107429 respectively. From this short sample, it can be conjectured that the number of complete compositions is asymptotically half of the total number of compositions. (This is also true for the gap-free compositions, since almost all of the gap-free compositions are complete, but it's not as obvious from this short sample.) A plot of the deviation between the percentage of gap-free compositions from $\frac12$ for $50 \leqslant n \leqslant 4000$ is quite remarkable. $50 < n < 500$ $500 < n < 4000$ Not only does it seem to converge quite rapidly, it also shows a strange oscillating behavior. A couple of proofs of this fact have been published $[1,2]$. The first paper was written by Hitczenko and Knopfmacher $[1]$, where they used randomly generated compositions to obtain a probability that a composition was complete (a probability that approaches $1/2$ as $n \to \infty$). The proof takes a probabilistic view of the compositions and says nothing (at least as far as I can understand) about why the ratio is exactly one half. However, the fact that asymptotically exactly half of the number of compositions are complete has lead me to think that there should be a way of thinking about this that is more intuitive or, perhaps, combinatorial in nature. For example, the number of complete compositions of $n$ is asymptotically the same as the total number of compositions of $n-1$. A bijection can of course not be found, since it is only an asymptotic relation. But for large $n$, is there some way to make a qualitative (and asymptotic) relation between these two sets of compositions? Are there other ""asymptotic bijections"" that can be used to shed some light on this? Maybe something can be said about how the completeness or gap-freeness restriction relates to other restrictions? I am not looking for rigorous proof here, it's just that it seems as there should be some way to think about this more intuitively. References $[1]$ P. Hitczenko and A. Knopfmacher, Gap-free compositions and gap-free samples of geometric random variables, Discrete Math. 294 (2005) 225-239 $[2]$ R. Warlimont, Complete compositions of a natural number, Quaestiones Mathematicae Volume 29, Issue 2, 2006 Edit July 1, 2013 No progress has been made here, but I thought I'd just write down some facts that might give some inspiration and food for thought. The number of complete partitions of $n$, $\# p_c(n)$, is the same as the number of partitions into distinct parts. The bijection can easily be seen using a Ferrers diagram. This is a very well-known series with the generating function $\prod_{k \ge 1} (1+x^k)$. ( A000009 at oeis.org ) The number of complete compositions of $n$, $\# c_c(n)$, can be calculated by counting the number of permutations of all complete partitions. In more detail: Generate a list of all complete partitions of $n$. For each partition $P$ in the list, check the maximum part $m$. For each number $k = \{1,2,\dots,m\}$, check the number of occurences $\alpha_k$ of $k$ in $P$. The number of complete compositions generated by $P$ is $\frac{m!} {\alpha_1! \dots \alpha_m!}$, i.e. the multinomial $\binom{m}{\alpha_1,\dots,\alpha_m}$ Can something be said about the asymptotic behavior of how the above operation maps $\# p_c(n)$ to $\# c_c(n)$? If so, $\# c_c(n) \sim f(n) \cdot \# p_c(n)$, where $f(n)$ is this asymptotic function. $\# p_c(n)$ is asymptotic to $$\frac{e^{\pi(n-\frac{1}{24})^{1/2}}}{4 \cdot 3^{1/4}(n-\frac{1}{24})^{3/4}}$$ (according to oeis.org ). We $\begin{cases} \text{know that} \\ \text{would like to prove that } \\ \text{would like to understand why} \end{cases} \Biggr\}$ the number of complete compositions of $n$ $\# c_c(n) \sim 2^{n-2}$. Edit July 9, 2013 Just a small note and a humble request. The number of compositions of $n$ starting with 1 is $2^{n-2}$. (Link) Are there other enumerations that have (asymptotically) the same dependence of $n$? Thought it might give some ideas/insight. Edit Feb 13, 2015 The generation of the number of gap-free and complete compositions can be done using recursive formulas published as Maple code on OEIS . Using memoization techniques, the sequences for $n$ up to $4000$ were generated. The oscillating behavior can be quite well modeled by the following function $$f(n)=\frac{An^B}{\log Cn}\sin\left(\frac{2 \pi}D \log(Dn+E)+F\right)$$
$$\begin{align}
A &= 3.53292387 \cdot 10^{-4}\\
B &= -8.47099853 \cdot 10^{-1}\\
C &= 9.11885892 \cdot 10^{-3}\\
D &= 6.94057582 \cdot 10^{-1}\\
E &= 1.35920759 \cdot 10^1\\
F &= -1.15542736 \cdot 10^1\\
\end{align}$$","['asymptotics', 'integer-partitions', 'discrete-mathematics', 'combinatorics']"
428240,Expected steps to obtain a connected graph,"We have a country containing $N$ cities with no road between any two cities (what a poor country). Each day we choose two cities such that there is no road between them and build a road between them. We choose each pair of non-connected cities with equal probability. Let $X$ be the number of days until we obtain a connected country. What is the expected value of $X$? A friend asked me, I have no idea yet.","['graph-theory', 'probability', 'random-graphs']"
428244,Examples of applications of Linear differential equations to physics.,"I wonder which other real life applications do exist for linear differential equations, besides harmonic oscillators and pendulums.
I'm looking for examples to include in a document that talks about the topic. So basically I need things that are easy to model with a single differential equation.","['mathematical-physics', 'physics', 'ordinary-differential-equations', 'soft-question']"
428246,Calculating area of astroid $x^{2/3}+y^{2/3}=a^{2/3}$ for $a>0$ using Green's theorem,"question as follows.
Show that for any planar region $\Omega$, $$\mathrm{area}\left(\Omega\right)=\frac{1}{2}\oint_{\partial\Omega}(xdy-ydx).$$ Use this result to find the area enclosed by the astroid $x^{2/3}+y^{2/3}=a^{2/3}$ for $a>0$. The first part's easy: $$\begin{array}{l c l} 
\mathrm{RHS}&=&\frac{1}{2}\oint_{\partial\Omega}(xdy-ydx)\\
&=&\frac{1}{2}\oint_{\partial\Omega}(-ydx+xdy)\\
&=&\frac{1}{2}\iint_{\Omega}(1+1)dA\\
&=&\iint_{\Omega}1dA\\
&=&\mathrm{area}(\Omega)\\
&=&\mathrm{LHS}.
\end{array}$$ But the next part really has me stumped. In this case $\Omega=\{ (x,y) : x^{2/3}+y^{2/3}\le a^{2/3} \}$ and $$\mathrm{area}(\Omega)=\iint_{\Omega}1dA=\frac{1}{2}\oint_{\partial\Omega}(xdy-ydx)$$ but I have a lot of problems coming up with $\partial\Omega$ to make it work. Any ideas would be welcome! Thanks.","['definite-integrals', 'multivariable-calculus', 'integration']"
428263,"When a limit does not exist, can its derivative be found?","I am learning derivatives of complex numbers (functions, actually) and what a learned community member pointed to me was that there is a subtle difference between finding derivatives of real numbers. He said that the derivative of a complex function can be calculated iff it satisfies the Cauchy Riemann equations. Which means, limit at the point $z$ exists. Back to reals . Have a look at the diagram above. I can calculate derivatives in both the cases. The 'mechanical' derivative using chain rule, quotient rule, product rule, etc. The derivative will fail if I plug in x = 13 (in both the cases) but for all other values of $x$, I can calculate the derivative (slope). In other words, $f(x)$ is not differentiable at $x = 13$. The same concept applies in case of complex functions, right ? You use Cauchy Riemann equations to see if $f(z)$ is differentiable at a given $z$. Even if it is not differentiable, I can still calculate the derivative mechanically, right ? And the derivative will fail if I plug in the given $z$ at which it was not differentiable Please clarify.","['derivatives', 'complex-analysis', 'limits']"
428290,"$y - y_0 = \frac{d^2}{dx^2}\left[ \ln\left( \frac{y}{y_0} \right) \right]$, solve for $y$.","I'm looking at a simple differential equation of the form:
$$y - y_0 = \frac{d^2}{dx^2}\left[ \ln\left( \frac{y}{y_0} \right) \right].\tag{$\star$}$$
Here $y=y(x)$ is a function of $x$ only, $y_0$ is a constant, and $x,y,y_0 \in \mathbb{R}$ are real. After an hour or so working on a problem, Eq. $\left(\star\right)$ popped out. I haven't made a significant effort to solve this DE just yet, because it is so simple looking and I thought it'd be a nice question for this site. This is ""work-work"", not ""homework"". Is there a name for this DE? Are there simple solutions, besides the trivial solution $y(x) = y_0$?",['ordinary-differential-equations']
428295,"For $G$ group and $H$ subgroup of finite index, prove that $N \subset H$ normal subgroup of $G$ of finite index exists","Let $G$ be a group and $H$ be a subgroup of $G$ with finite index. I want to show that there exists a normal subgroup $N$ of $G$ with finite index and $N \subset H$. The hint for this exercise is to find a homomorphism $G \to S_n$ for $n := [G:H]$ with kernel contained in $H$. The standard solution suggests to choose $\varphi$ as the homomorphism induced by left-multiplication $\varphi: G \to S(G/H) \cong S_n$. I'm not 100% sure if I understand this correctly. What exactly does $\varphi$ do? We take $g \in G$ and send it to a bijection $\varphi_g: G/H \to G/H, xH \mapsto gxH$? If so, how can I see that its kernel is contained in $H$? Also, the standard solution claims its image is isomorphic to $G/N$ and thus $N$ has a finite index in $G$, how can I see that the image is isomorphic to $G/N$? Thanks in advance for any help.",['abstract-algebra']
428303,Find number of solutions of $|2x^2-5x+3|+x-1=0$,"Problem : Find number of solutions of $|2x^2-5x+3|+x-1=0$ Solution :
Case 1: When $2x^2-5x+3 \geq 0$ Then we get, $2x^2-5x+3+x-1=0$ x=1,1 Case 2: When $2x^2-5x+3 < 0$ Then we get, $-2x^2+5x-3+x-1=0$ x=1,2 In both cases, common value of x is 1 Hence solution is x=1 Am I doing right ?? Somebody told me solution is x=2",['functions']
428306,Is the derivative the natural logarithm of the left-shift?,"(Disclaimer: I'm a high school student, and my knowledge of mathematics extends only to some elementary high school calculus. I don't know if what I'm about to do is valid mathematics.) I noticed something really neat the other day. Suppose we define $L$ as a ""left-shift operator"" that takes a function $f(x)$ and returns $f(x+1)$. Clearly, $(LLL\ldots LLLf)(x)=f(x+(\text{number of $L$s}))$, so it would seem a natural extension to denote $(L^hf)(x)=f(x+h)$. Now, by the definition of the Taylor series, $f(x+h)=\sum\limits_{k=0}^\infty \frac{1}{k!}\frac{d^kf}{dx^k}\bigg|_{x}h^k$. Let's rewrite this as $\sum\limits_{k=0}^\infty \left(\frac{\left(h\frac{d}{dx}\right)^k}{k!}f\right)(x)$. Now, we can make an interesting observation: $\sum\limits_{k=0}^\infty \frac{\left(h\frac{d}{dx}\right)^k}{k!}$ is simply the Taylor series for $e^u$ with $u=h\frac{d}{dx}$. Let's rewrite the previous sum as $\left(e^{h\frac{d}{dx}}f\right)(x)$. This would seem to imply that $(L^hf)(x)=\left(e^{h\frac{d}{dx}}f\right)(x)$, or equivalently, $L=e^\frac{d}{dx}$. We might even say that $\frac{d}{dx}=\ln L$. My question is, does what I just did have any mathematical meaning? Is it valid? I mean, I've done a bit of creative number-shuffling, but how does one make sense of exponentiating or taking the logarithm of an operator? What, if any, significance does a statement like $\frac{d}{dx}=\ln L$ have?","['power-series', 'calculus', 'finite-differences', 'functional-analysis', 'taylor-expansion']"
428311,Is $\mathbb{Q}\otimes_\mathbb{Z}\mathbb{Z}/n=0$?,"Is $\mathbb{Q}\otimes_\mathbb{Z}\mathbb{Z}/n=0$? Because 
\begin{equation}\frac{a}{b}\otimes_\mathbb{Z}1=\frac{na}{nb}\otimes_\mathbb{Z}1=\frac{a}{nb}\otimes_{\mathbb{Z}}n=\frac{a}{nb}\otimes_\mathbb{Z}0=0?\end{equation}",['abstract-algebra']
428313,What is the orbit of a permutation?,"I have the following statement: $\sigma, \tau \in S_n$ are conjugated if and only if their orbits have the same length. I only know orbits in the context of groups acting on a set. Namely, let $X$ be a set and $G$ be a group. Then, $Gx := \{gx |\, g \in G\}$ is called orbit of $x$ in $G$. What in this case is $X$ and what is $G$?","['group-actions', 'symmetric-groups', 'group-theory', 'abstract-algebra']"
428324,"How to compute the limit $\lim\limits_{q \rightarrow 1} (1-q)^3 \sum_{n>0} n^{1+\epsilon} q^n$ for $\epsilon \in (0,1)$","I am able to show that $\lim\limits_{q \rightarrow 1} (1-q)^3 \sum_{n>0} n q^n  = 0 $
and $ \lim\limits_{q \rightarrow 1} (1-q)^3 \sum_{n>0} n^2 q^n  = 2$ and now I want to prove that $$ \lim\limits_{q \rightarrow 1} (1-q)^3 \sum_{n>0} n^{1+\epsilon} q^n = 0 $$ for $\epsilon \in (0,1)$. Do you guys have any hints for me doing so? I can't use the methods which I used to proof the first two statements because they are just valid for integral exponents of $n$. Thanks in advance!","['special-functions', 'limits']"
428344,show that every continuous real-valued function defined on $S_{\mathbb{\Omega}}$ is eventually constant,"show that every continuous real-valued function defined on $S_{\mathbb{\Omega}}$ is eventually constant.Where $S_{\mathbb{\Omega}}$ denote the first uncountable ordinal. There is a hint that for each $\epsilon$,there is an element $\alpha$ of $S_{\mathbb{\Omega}}$  such that $|f(\alpha)-f(\beta)|<\epsilon$ for all $\beta>\alpha$. However, I couldn't figure out how to prove this statement.","['general-topology', 'ordinals']"
428347,"For submersion and submetry,why can we lift a geodesic ""horizontally"" to a geodesic?","A map $\sigma:X\to Y$ between locally compact complete inner metric spaces is called a submetry if $\sigma(B_r(p))=B_r(\sigma(p))$ for all $r>0$ and $p\in X$. Why is that a geodesic in $Y$ can be lifted ""horizontally"" to a geodesic in $X$. And the case for submersion? The problem lies when we lift a point we don't know where we lift in the fiber.","['geometry', 'differential-geometry', 'geodesic']"
428348,What is trivializing open cover?,"Here is where I read ""trivializing open cover"", but I was not able to find out what it is.",['differential-geometry']
428349,A vector field is a section of $T\mathcal{M}$.,"By definition, a vector field is a section of $T\mathcal{M}$. I am familiar with the concept of vector field, as well as tangent plane of a manifold. But such definition is not intuitive to me at all. Could some one give me some intuition? Thank you very much!",['differential-geometry']
428363,Calculus on the Sobolev space valued function of one real variable $t$?,"Now I am interested in the calculus on Banach space valued function, especially the function with value in a certain Sobolev space. I want to prove that $$\bigcap_{k=0}^m C^k([0,T];H^{m-k}(\Omega))\subset C^{m-[\frac{n}{2}]-1}(\overline{Q_T}),\tag{1}$$by Sobolev imbedding  theorem. Here $\Omega\subset\mathbb{R}^n$ and $Q_T:=(0,T)\times\Omega$. Since I'm not familiar with the theory of Banach space valued function (only know some basic concepts), I wish to see the detail proof of $(1)$. Any reference which contain the detail proof of $(1)$ is exceedingly welcome! Any answer and reference will be appreciated!","['sobolev-spaces', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
428372,Find a $2$-Sylow subgroup of $\mathrm{GL}_3(F_7)$,"We have $|\mathrm{GL}_3(F_7)| = 7^3 \cdot 2^6\cdot 3^4\cdot 19$. I can find the $3,7,19$-Sylow subgroup of it, but failed to find a $2$-Sylow subgroup. Can one help?","['sylow-theory', 'finite-groups', 'abstract-algebra']"
428380,"What is the definition of curl of $\mathbf{F}(x_1, x_2) = ( F_1 (x_1,x_2) F_2(x_1,x_2))$ in $\mathbb{R}^2?$","What is the definition of curl of $\mathbf{F}(x_1, x_2) = ( F_1 (x_1,x_2) F_2(x_1,x_2))$  in $\mathbb{R}^2?$ Most textbook says only of vector fields in the space $\mathbb{R}^3$...",['multivariable-calculus']
