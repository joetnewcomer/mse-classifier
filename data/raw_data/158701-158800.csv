question_id,title,body,tags
2725031,Is the sum of two sine waves periodic? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Is the sum of two sine waves periodic? Specifically, what will be the period of $\sin(mx)+\sin(nx)$ where $m$ and $n$ are real constants? When $m$ and $n$ are integers, it is not difficult to show by definition that $\sin(mx)+\sin(nx)$ is periodic. But I don't know how to handle the general cases. Can anyone help?","['periodic-functions', 'trigonometry']"
2725063,Probability of 3 numbers chosen between 0 and 10 being within 1 of each other,"I was trying to find the probability that 3 real numbers uniformly chosen from 0 to 10 are within 1 of each other (the largest number minus the smallest number is at most 1). I tried using geometric probability, and I got a region that looks like what you would get if you put one vertex of a unit cube at the origin (and orient the edges such that they line up with the positive axes), and move the corner at the origin from (0,0,0) to (9,9,9) (is this region correct?). I calculated the volume by finding the area of the one of the faces of the cube (which is 1), and multiplying it by the distance it moved (which is 9). Since there are three of these squares, the volume is 27. I then add this to the volume of the cube, which results in 28. The total volume is 10^3 = 1000, so the probability is 28/1000 = 7/250. Is this correct? Any feedback would be greatly appreciated. Thanks!","['volume', 'probability', 'geometry']"
2725089,Degree of hypersurfaces in Grassmannians,"In the book Discriminants, Resultants, and Multidimensional Determinants of Andrei Zelevinsky and Izrail' Moiseevič Gel'fand, the authors give the following definition of degree of a hypersurface in a Grassmannian. As they say, in generale a hypersurfaces in a projective variety is not given by the vanishing of a polynomial in its coordinate ring, but for Grassmannians this is true, since its coordinate ring is a UFD, therefore every height-one prime is principal by Krull Theorem. However I'm stuck on the definition of degree of a hypersurface in a Grassmannian. To be more precise...I wuold prove that this definition is well posed, as in the case of projective hypersurfaces. For doing this I think it's enough to check: The maximum number of intersection points of $Z$ with a flag is finite, say equals to $d\geq 0$; There exist two  Zariski-open $U\subset G(k-1,n)$ and $V\subset G(k+1,n)$, such that for every flag with $N\in U$ and $M\in V$, the cardinality of $P_{NM}\cap Z$ is equals to $d$. Any help or reference it's well accepted.","['reference-request', 'proof-writing', 'algebraic-geometry']"
2725099,Can a function be well-defined on an integral of $\mathbb{R}$ but not Lebesgue integrable?,"I was thinking about a comment on this question , and how some functions are not Riemann integrable but are Lebesgue integrable. But are there any functions which are defined everywhere in an interval of $\mathbb{R}$ but are not Lebesgue integrable ? In other words, does it make sense for a function to have no antiderivative by Lebesgue integration? For example, is there an $f(t)$ that satisfies the properties of the third section below: $$\begin{aligned}
&\quad\quad\text{$\sin(t)$ defined everywhere ✓}\\
\int_0^x \sin(t) \;\mathrm{d}t :&\quad\quad\text{Riemann integrable ✓} \\
&\quad\quad\text{Lebesgue integrable ✓} \\
\\
\hline
\\
&\quad\quad\text{$I_\mathbb{Q}(t)$ defined everywhere in interval ✓}\\
\int_0^x I_\mathbb{Q}(t) \;\mathrm{d}t :&\quad\quad\text{Riemann integrable ✗} \\
&\quad\quad\text{Lebesgue integrable ✓} \\
\\
\hline
\\
&\quad\quad\text{$f(t)$ defined everywhere in interval ✓}\\
\int_0^x f(t) \;\mathrm{d}t :&\quad\quad\text{Riemann integrable ✗} \\
&\quad\quad\text{Lebesgue integrable ✗} \\
\end{aligned}$$ Where $I_\mathbb{Q}(t)$ is the Dirichlet function.","['integration', 'lebesgue-integral', 'functions']"
2725102,A multiple-choice examination consists of $75$ questions- Probability,"A multiple-choice examination consists of $75$
 questions, each having possible choices a, b, c, d, and e. Approximate the probability that a student will get at most $13$
 answers correct if she randomly guesses at each answer. (Note that, if she randomly guesses at each answer, then the probability that she gets any one answer correct is $0.2$.) Use the normal approximation to the binomial with a correction for continuity. I tried a bit 
Binomial Problem with n = 75 P(correct answer)=0.2 Binomial probability:P(X = x)=$0.10171948927$ I am I correct?","['probability-theory', 'probability', 'statistics']"
2725129,Is this proof that the derivative of $\ln(x)$ is $1/x$ correct?,"\begin{align}
\frac{\mathrm{d}}{\mathrm{d} x}\ln x &= \lim_{h\to0} \frac{\ln(x + h) - \ln(x)}{h} \\
&= \lim_{h\to0} \frac{\ln(\frac{x + h}{x})}{h} \\
&= \lim_{h\to0} \frac{\ln(1 + \frac{h}{x})}{h} \\
\end{align} \begin{align}
&= \lim_{h\to0}{\ln(1 + \frac{h}{x})}^\frac{1}{h} \\
\end{align}
Now this is the part I'm asking about, because I see most people set the reciprocal of my limit, but this one seems to work:
\begin{align}
n=\frac{x}{h},  h=\frac{x}{n}, \frac{1}{h} = \frac{n}{1}*\frac{1}{x}
\end{align}
So when h tends towards 0, n tends towards infinity.
\begin{align}
&= \lim_{n\to\infty}{\ln\biggl((1 +\frac{1}{n})}^n\biggl)^\frac{1}{x} \\
\end{align}
Here we have
\begin{align}
{\ln\lim_{n\to\infty}\biggl((1 +\frac{1}{n})}^n\biggl)^\frac{1}{x} \\
\end{align}
\begin{align}
=\frac1x\ln(e) = \frac1x
\end{align}
This is my first post, I was just curious. Please don't berate me if it's a silly question.","['derivatives', 'limits', 'logarithms', 'exponential-function', 'calculus']"
2725147,"determine a orthogonal basis $(v_1,v_2,v_3)$ of $\mathbb R^3$, such that $Av_1,Av_2,Av_3$ are pairwise orthogonal","Let $A=
 \begin{bmatrix}
1& 0& -4\\
2& 1& 1\\
2& -1& 1
\end{bmatrix}
$ $A^TA=\begin{bmatrix}
9& 0& 0\\
0& 2& 0\\
0& 0& 18
\end{bmatrix}$ I am asked to determine a orthogonal basis $(v_1,v_2,v_3)$ of $\mathbb R^3$, such that $Av_1,Av_2,Av_3$ are pairwise orthogonal. If we take the columns of $A^TA$ as the basis $(v_1,v_2,v_3)$, they are obviously an orthogonal basis of $\mathbb R^3$  and we can calculate $A\begin{bmatrix}
9\\
0 \\
0 
\end{bmatrix}=$$\begin{bmatrix}
9\\
18 \\
18 
\end{bmatrix}$. $A\begin{bmatrix}
0\\
0 \\
18 
\end{bmatrix}=$$\begin{bmatrix}
-72\\
18 \\
18 
\end{bmatrix}$ $A\begin{bmatrix}
0\\
2 \\
0 
\end{bmatrix}=$$\begin{bmatrix}
0\\
2 \\
-2 
\end{bmatrix}$ These vectors are pairwise orthogonal again. Could someone explain why this works?","['matrices', 'orthogonality', 'linear-algebra']"
2725189,An inequality involving a quasiconvex function with binomial and power terms,"The question is as follows.
Let us consider a positive integer number $x \in \{1,2,3,...\}$ and a positive real number $q \in [1,x]$. Show that
\begin{equation}
\sum_{m=0}^{x-1} \left( \frac{x+2-q}{m+1} -\frac{x+q}{\min(m+q,x)} \right) \binom{x-1}{m} \left ( \frac{x-q}{x+q}\right)^m \geq 0.
\end{equation} I've tried to solve the inequality as follows. First, let us denote the LHS as $f(x,q)$ \begin{equation}
f(x,q)=\sum_{m=0}^{x-1} \left( \frac{x+2-q}{m+1} -\frac{x+q}{\min(m+q,x)} \right) \binom{x-1}{m} \left ( \frac{x-q}{x+q}\right)^m.
\end{equation} 
I want to show that $f(x,q) \geq 0$ for $x \in \{1,2,3,...\}$ and any positive real number $q \in [1,x]$.
It is easy to verify that $f(x,1)=0$ and $f(x,x)=0$. The first idea I pursued was to try by induction over $x$, while considering $f(x,q)$ with a fixed $q$. In fact, numerical results seem to verify that $f(x+1,q) \geq f(x,q)$
(the inequality is strict for $q > 1$). I tried to prove it by induction but I could not succed as I could not manage the terms $\binom{x-1}{m} \left ( \frac{x-q}{x+q}\right)^m$, which are very difficult to manipolate. The second way I tried was to consider $f(x,q)$ by fixing $x$ and letting $q$ to vary in $[1,x]$. In this case $f(x,q)=0$ at the two extremes of the interval ($q=1$ and $q=x$), while numerical results show that $f(x,q)$ is greater than zero inside the interval, suggesting that $f(x,q)$ is quasiconvex in $q \in [1,x]$. My idea was to consider the different intervals of $q$ given by $q \in [1,2)$, $[2,3)$ (where $f(x,q)$ is differentiable), and show that in each of this interval the function is either convex or concave, while being quasiconcave all over the interval. In fact, by considering $q \in [a,a+1)$, for any integer $a$ in $[1,x]$, we have that \begin{equation}
f(x,q)=\sum_{m=0}^{x-a-1} \left( \frac{x+2-q}{m+1} -\frac{x+q}{m+q} \right) \binom{x-1}{m} \left ( \frac{x-q}{x+q}\right)^m + \sum_{m=x-a}^{x-1} \left( \frac{x+2-q}{m+1} -\frac{x+q}{x} \right) \binom{x-1}{m} \left ( \frac{x-q}{x+q}\right)^m .
\end{equation} 
However, taking the derivate with respect to $q$ is very difficult and I wasn't able to conclude anything after this. To sum up, it looks like that the issues are given by the terms $\binom{x-1}{m} \left ( \frac{x-q}{x+q}\right)^m$, which are very difficult to manage. If someone can help me by providing new directions to look at, pointing me out similar inequalities in the literature which I don't know, or give me new ideas, I would be grateful.","['real-analysis', 'inequality', 'convex-analysis', 'functions', 'analysis']"
2725192,Weird limit with $e^x$,"Here's a limit that is testing my strengths. $$\lim\limits_{x\to -\infty} [(x^2+1)e^x]$$ Personal work: $$\lim\limits_{x\to -\infty} [(x^2+1)e^x] = \lim\limits_{x\to -\infty} (x^2e^x+e^x) = \lim\limits_{x\to -\infty} (x^2e^x)=L.$$ Let $x^2=u \iff x=-\sqrt u$ , then $u_0=\lim\limits_{x\to+\infty}{x^2}=+\infty$ So, $$ L=\lim\limits_{u\to+\infty}{(u*e^{-\sqrt u})} =...$$ Although it looks correct for me, both Microsoft mathematics and symbolab show me the answer "" $0$ "" so what am I doing wrong?",['limits']
2725204,Well-formedness of hypersurfaces in weighted projective space,"Consider a weighted projective space $\mathbb{P}_{a_1, \dotsc, a_r}$ and assume it is well-formed i.e. each $r-1$ of the $a_i$ are coprime. Let $g \in \mathbb{K}[T_1, \dotsc, T_r]$ be a weighted homogeneous polynomial and write $d := \deg(g)$. We call the hypersurface $X := V(g) \subseteq \mathbb{P}_{a_1, \dotsc, a_r}$ well-formed if $X$ does not contain any $2$-codimensional singular orbit of $\mathbb{P}_{a_1, \dotsc, a_r}$. One of the standard references for weighted complete intersections is Iano-Fletcher . There 6.10 says that $X$ is well-formed if and only if
$$ \gcd(a_i;\; i \neq i_1, i_2) \mid d $$
holds for all $1 \leq i_1 < i_2 \leq r$. I don't see why this is true. For example, consider $\mathbb{P}_{1,1,4,6}$ and $g = T_1^2 + T_2^2 + T_1 T_2$. Let $Z$ be the torus orbit of $[0,0,1,1]$. Then $Z$ is 2-dimensional singular orbit due to $\gcd(4,6) = 2 \neq 1$. However we have $Z \subseteq X$ because $g$ depends only on the first to variables. Could you give me a reference for a proof and/or a hint what I'm doing wrong?","['projective-space', 'algebraic-geometry']"
2725246,Show that $[k(t): k(t^4 + t) ] = 4$,"Let $k$ be the field with $4$ elements, $t$ a transcendental over $k$, $F = k(t^4 + t)$ and $K = k(t).$ Show that $[K : F] = 4.$ I think I have to use the following theorem, but I'm not quite putting it together. If $P = P(t), Q = Q(t)$ are nonzero relatively prime polynomials in $F[t]$ which are not both constant, then $[F(t) : F(P/Q)] = $ max(deg $P$, deg $Q$).","['galois-theory', 'transcendental-numbers', 'galois-extensions', 'abstract-algebra', 'transcendence-degree']"
2725249,Are there any formulas that compute the coordinate of the spiral numbers,"Just like the title I want to ask about formula for $n \times n$ spiral matrix. In particular, I want to know if there's a formula for a given entry in the matrix, without computing the full matrix. Here is an example of the kind of matrix I'm talking about:
$$\left[\begin{matrix}
1 & 2&  3&  4&  5&  6 \\
20& 21& 22& 23& 24&  7 \\
19& 32& 33& 34& 25&  8 \\
18& 31& 36& 35& 26&  9 \\
17& 30& 29& 28& 27& 10 \\
16& 15& 14& 13& 12& 11
\end{matrix}\right]$$",['discrete-mathematics']
2725263,Evaluate $\int_0^1(x\ln(x))^{50}dx$,"Evaluate $$\int_0^1(x\ln(x))^{50} dx.$$ Here are my steps so far using differentiation under the integral sign: $$I(t) = \int_0^1(x\ln(x))^t dx$$
$$I'(t) = \frac d{dt}\int_0^1(x\ln(x))^t dx = \int_0^1\frac \partial{\partial t}(x\ln(x))^t dx = \int_0^1(x\ln(x))^t\ln(x\ln(x)) dx$$ I can't find a way to continue so hints are appreciated.","['real-analysis', 'definite-integrals', 'calculus']"
2725267,How to show that a set with injections into and from $\mathbb{N}$ is uncountable? [duplicate],"This question already has answers here : Proving a set of functions is uncountable (4 answers) Closed 6 years ago . Let's say we have two injective functions $u : \mathbb{N} \to A$ and $v : A \to \mathbb{N}$. How can I demonstrate that $A$ is uncountable ? If there is an injective function $u : \mathbb{N} \to A$ and $v : A \to \mathbb{N}$, consequently there is a bijection between $\mathbb{N}$ and $A$. But what can I do from that? Thanks!",['elementary-set-theory']
2725277,Understanding a notion of family of Jacobians,"I am currently studying A. Beauville's article Determinantal Hypersurfaces . At (3.2), the author discuss about a family of Jacobians: For $\delta\in\mathbf{Z}$, let $\mathcal{J}_d^\delta\rightarrow |\mathcal{O}_{\mathbb{P}^n}(d) |_{sm}$ be
  the family of degree-$\delta$
  Jacobians:
  $\mathcal{J}_d^\delta$
  parameterizes pairs
  $(C,L)$
  of a smooth plane
  curve of degree
  $d$
  and a line bundle of degree
  $\delta$
  on $C$.
  Finally, we denote by
  $\Theta_d$
  the divisor in
  $\mathcal{J}_d^\delta$
  consisting of pairs
  $(C,L)$ with $H^0(C,L)\neq 0$.
  It is an ample
  divisor, so its complement in
  $\mathcal{J}_d^\delta$
  is affine. I do not understand what exactly is this family of Jacobians. How does the space $\mathcal{J}_d^\delta$ look like and the map onto $|\mathcal{O}_{\mathbb{P}^n}(d) |_{sm}$? Why is that divisor ample? I only know that a Jacobian variety of a curve $C$ is a torus which can be identified with the space $\textrm{Pic}^0(C)$ of degree-$0$ line bundles. I would be very grateful if you could explain me this definition or if you would give valuable references.","['divisors-algebraic-geometry', 'algebraic-geometry']"
2725298,How can I find the total number of figures in a puzzle where they seem to overlap?,"The problem is as follows: In the following sequence of figures. Which is the total number of
  right trapezoids which do make up $\textrm{figure 10}$? The figure is below: The alternatives given are: 66 60 56 64 72 What I tried to do is to account for the number of trapezoids: $\textrm{In figure 1:}$ There is just $1$ $\textrm{In figure 2:}$ This is some tricky: I thought that there are $4$ $2$ make up a small individual unit $1$ accounts for the other two $1$ accounts for the all of them $\textrm{In figure 3:}$ $3$ are consisting of only one figure. $2$ are two figures. $1$ has three figures. $1$ accounts for the three trapezoids in horizontal arrangement and the first oblique bar next to them. $1$ accounts for the previous set plus the second oblique bar next to them. Therefore in the figure are $8$ $\textrm{In figure 4:}$ $4$ are sets of 1 figure. $3$ are sets of 2 figures. $2$ are sets of 3 figures. $1$ is a set of 4 figures. $1$ is a set of the previous 4 figures in horizontal direction plus the first oblique bar appearing next to the trapezoids. $1$ is the previous set and the second oblique bar. $1$ is the previous set and the third oblique bar. This accounts for $13$ figures. So in total the series is comprised of. $\textrm{1, 4, 8, 13,...}$ From this series I found that the recursion formula is stated as: $$T_{n}=\frac{1}{2}n^{2}+\frac{3}{2}n-1$$ By replacing with the fourth term it seems to check. $$T_{4}=\frac{1}{2}\left( 4 \right )^{2}+\frac{3}{2}\left( 4 \right )-1=8+6-1= 13$$ So if what it is being asked is figure number $10$ then by replacing in the previous equation: $$T_{10}=\frac{1}{2}\left( 10 \right )^{2}+\frac{3}{2}\left( 10 \right )-1=50+15-1= 64$$ Therefore I would choose $64$ as the number of figures in the $\textrm{10th figure}$. I'm not very certain if is it correct? The answer appears within the alternatives but the process to find the figures was very tedious and it took me a long time to find it, needless to say that to find the recursive formula was another problem as well but eased due the fact which I had some idea of how to find it, as a result. Is there any other method to speed up the calculations or to find an answer in this situation or to avoid miscounting or double counting the figures?","['recreational-mathematics', 'sequences-and-series']"
2725352,Graph Combinatorics - Upper and lower bound on the number of group isomorphism classes,"I have this problem which seems to be hard, and of course I am looking for a simple solution, which is quite absurd, but that's mathematics anyways. The problem states that if $f(n)$ is the number of group isomorphism classes for graphs with n vertices, then there are $a>1, b>0,c>0$ such that 
$$a^nc\leq f(n)\leq b^{n^2}  \tag{1} $$ Finding $f(n)$ using the Bernstein theorem gives a starting point, but this in no way shows that the bounds (1) are possible. I thought about checking on the edges that a graph with n vertices will have. The extreme cases are the cases where are no edges (which could lead to the lower bound) and the case where every vertex communicates with every other (which could lead to the upper bound). But I cannot see how the exponents come to be...
Is this approach feasible?
Is there a simple way to prove the bounds? The bounds are possibly not sharp. 
Thanks in advance for any replies...","['combinatorics', 'functions']"
2725364,Find volume of the cone using integration,"A cone can be though as a concentration of circles of radius tending to $0$ to radius $r$ and there will be infinitely many such circles within a height of $h$ units. Area of one such circle of radius $r$ will be $\pi r^2$. 
Volume of cone = sum of all such circles but that will be $\int_{0}^{r} \pi x^2 \text {d}x$ and that wouldn't be correct as the volume is $\pi r^3 h /3$ and not that. I rather find that $$\int_{0}^{h}\left(\int_{0}^{r} \pi x^2 \text {d}x\right)$$ works.
Why?",['integration']
2725426,Finite dimensional central division $\mathbb K$-algebra as a subalgebra of a matrix $\mathbb K$-algebra,"The question is as follows: A finite-dimensional central division $\mathbb K$-algebra $D$  is a $\mathbb K$-algebra isomorphic to a subalgebra  of $M_r(\mathbb K)$ if and only if $\dim_{\mathbb K} D \mid r$. In what comes, we already know that the other direction is true by a beautiful answer from @Algeboy. Also, I understood that the comment by @Jyrki give a very nice and reasonable way for to show the statement. But I don't know how to use it. For to prove this statement, I think for to show the statement, I think we need to use the notion of splitting field for the central division algebra $D$
of dimension say $d^2$ and to show that $[L:K]=rd$ by using $[D:K]=[L:K]^2$. I know how to prove these facts but I still do not know how to apply it for to prove our statement? Also there is some hint for to prove it in the book Finite dimensional division algebras over fields (1996 Springer) by Nathan Jacobson and you can download it by clicking on this link , in the beginning of the section 2.12 is written that this is a direct sequence from the theorem 2.3.17 and some statements from its proof. But I still cannot see it! Thanks!","['division-algebras', 'splitting-field', 'abstract-algebra', 'noncommutative-algebra', 'field-theory']"
2725434,Distance of points in Banach space,"Let $B_1(X)$ be the closed unit ball of Banach space $X$. Let $x\in X\setminus B_1(X)$ and $x_1=\dfrac{x}{\|x\|}$. Question : Is it true that for all $y\in B_1(X)$, $\|x-y\|\ge\|x_1-y\|$? If it is not true, can you give me a counterexample? And what about strictly convex space or uniformly convex space?","['functional-analysis', 'banach-spaces', 'convex-analysis']"
2725460,Japanese Multiplication: 日本の掛け算,Is  the Japanese Multiplication really a thing or a joke? How does it work? Here is the video on youtube https://www.youtube.com/watch?v=JVgnUMdM6ME,"['algebra-precalculus', 'arithmetic']"
2725481,How to compute a prediction interval for an exponentially distributed random variable.,"I have fitted an exponential model to some data using maximum likelihood estimation and am now trying to compute a prediction interval for a new observation, $P$, which has a corresponding explanatory variable equal to $70$. Under my model, $P \sim \text{Exp}(e^{\beta_1 + \beta_2 \times 70})$ and I have estimated $\hat{\beta}_1 = -4.317$ and $\hat{\beta}_2 = -0.028$. Further, the inverse observed fisher information for the model is: $$-H(\boldsymbol{\hat{\theta}})^{-1} = \begin{bmatrix} 0.615 & -0.009 \\ -0.009 & 0.00017 \end{bmatrix}$$ My question is, how can I create a $95\%$ prediction interval for $P$ using this information?","['maximum-likelihood', 'statistics', 'mathematical-modeling', 'statistical-inference']"
2725488,Can we find the asymptotic behavior of this $f(x) =\int_{0}^{\infty}\frac{u^2}{1+\frac{e^{u^2}}{x}}du$?,"I encountered this function in Statistical Mechanics.  $$f(x) =\int_{0}^{\infty}\frac{u^2}{1+\frac{e^{u^2}}{x}}du$$ 
For $x=0$, we define its value to be zero.
I wanted to see it's asymptotic behavior in the limit x tending to $\infty$. Can we express the asymptotic behavior of this function, in the limit x tending to $\infty$, in terms of other known mathematical functions (if possible; in elementary functions)? For some physical reasons (which are irrelevant here), $x$ belongs to $[0,\infty)$.","['special-functions', 'asymptotics', 'functions']"
2725531,Proving that in neutral geometry a line cannot be wholly contained in a triangle,"Below is a list of (some of) the axioms I'm allowed to use (they are just the usual ones, it's just too much work to list them all). The book doesn't provide a definition for what the interior of a triangle is, but here I'm using that it is the smallest convex set that contains its vertices. Given any line $r$, there exist points on $r$ and points not on $r$. Given two different points $A$ and $B$ there exists only one line that
  contains $A$ and $B$. Given three points in a line, only one of them is between the other two. Given two points $A$ and $B$ there always exists a point $C$ between $A$ and $B$ and a point $D$ such that $B$ is between $A$ and $D$. I'm having a hard time proving the statement. I've tried for a while now but keep making mistakes and making a mess of everything. Any help would be appreciated. EDIT: To clarify, here the definition of a triangle doesn't include degenerate cases.",['geometry']
2725539,Maximum likelihood estimator of categorical distribution,"The task is: Population of the students has been divided into the following three
  groups: Students with the mean of grades below 3.5 Students with the mean of grades between 3.5 and 4.5 Students with the mean of grades above 4.5 Each  student  in  the  population  is  described  by  a  vector  of 
  random  variables $x=  (x^1\ x^2\ x^3)^T$, taking one of three
  possible states:   $(1\ 0\ 0)^T$ if the student belongs to the first
  group,   $(0\ 1\ 0)^T$ if the student belongs to the second group, and $(0\ 0\ 1)^T$ if the student belongs to the third group.   The
  distribution of $x$ is categorical distribution (also known as
  generalized Bernoulli distribution or Multinoulli distribution) with
  parameters $\theta= (\theta_1\ \theta_2\ \theta_3)^T$. From the
  population of the students N examples were drawn. Calculate the
  maximum likelihood estimator of $\theta$. I tried to do it similarly to Bernoulli case, but I'm stuck. The idea was to find $\theta^*$ by finding the maximum of probability distribution function. So my try was $$
M(x\mid\theta)=\prod_{d=0}^D \theta_d^{x_d}=\theta_1^{x_1} \theta_2^{x_2} \theta_3^{x_3}\\
\theta^* = \operatorname*{argmax}_\theta M(x\mid\theta) = \operatorname*{argmax}_\theta \ln(M(x\mid\theta))\\
\ln(M(x\mid\theta))= \ln(\theta_1^{x_1} \theta_2^{x_2} \theta_3^{x_3}) = x_1\ln\theta_1 + x_2\ln\theta_2 + x_3\ln\theta_3 = x^T (\ln\theta_1\ \ln\theta_2\ \ln\theta_3)^T
$$ Next step would be calculating derivative with respect to $\theta$ and finding it's zero, but we don't have $\theta$ in the function. I'm not sure where is my mistake. Or perhaps there is no mistake and it is possible to convert $(\ln\theta_1\ \ln\theta_2\ \ln\theta_3)^T$ to some form with $\theta$?",['statistics']
2725543,Prove $u$ is a unit if and only if $N(u) = 1$?,"The norm $N:\mathbb{Z}[\sqrt[3]{2}] \rightarrow \mathbb{N}$ defined by $N(a+b\sqrt[3]{2} + c\sqrt[3]{4}) = |a^3 + 2b^3 + 4c^3 - 6abc|$ is multiplicative. (Already proven). Show that $\alpha \in \mathbb{Z}[\sqrt[3]{2}]$ is a unit if and only if $N(\alpha) = 1$. So far proved it one direction, but am struggling with the other. Proof $\rightarrow$
Let $\alpha$ be a unit, so by defintion $\exists \beta$ such that $\alpha\beta = 1$. We can then use the norm, knowing that $N(\alpha\beta) = |(1)^3 + 2(0)^3 + 4(0)^3 - 6(1)(0)(0)| = 1$. Since the norm is multiplicative, $N(\alpha\beta) = N(\alpha)N(\beta) = 1$, and since the results of the norms have to be positive integers, we know $N(\alpha)=1$. Proof $\leftarrow$ Let $N(\alpha)$ = 1. Then for $\alpha = a+b\sqrt[3]{2} + c\sqrt[3]{4}$, $|a^3 + 2b^3 + 4c^3 - 6abc|=1$ Any help on where to go?","['abstract-algebra', 'ring-theory', 'normed-spaces', 'proof-explanation']"
2725564,How can I push the derivative through the following sum?,"Let $f$ be a probability density and $F$ the corresponding distribution function. In other words $f$ is non-negative, integrates to 1, and $F' = f$. I'm interested in the following:
$$
\frac{d}{dx}\sum_{i\in\mathbb{Z}}F(i+x)-F(i)\stackrel{?}{=}\sum_{i\in\mathbb{Z}}f(i+x)
$$
I'm doubtful that this result holds in general. But what if I add assumptions such as that $f$ be Lipschitz-continuous?","['derivatives', 'probability', 'sequences-and-series']"
2725598,Stochastic model over a gambling game,"Problem : You have $1$$\$$ and you want to gather $10\$$ fast. For this reason, you decide to play a game with the following rules. On each round, the probability of winning is $0<p<1$ , regardless of the outcome of the previous rounds. Before each round, you choose the amount you will bet. If you win, you get double your bet and if not, you lose the amount that you have bet. You have decided to bet all the money you have, if these are less than $5\$$ , or in any other case, as much as you need to get to $10\$$ . (a) What is the probability of getting to $10\$$ ? (b) What is the probability of reaching $10\$$ , if you bet $1\$$ per round ? (c) What is the expected time until you lose all your money or reach $10\$$ on each one of the cases above ? Attempt - Discussion : For part (a), solving the following Boundary Values Problem for the probability that we need to calculate $\mathbb{P}[T_{10} < T_{0} | X_0 = 1]$ yields the corresponding dynamical function $\Phi_{10,5}$ which is the answer to the question $$$$ \begin{cases} h(x) = p \cdot h(2x), \; x = \{1,2,3,4\}\\ h(x) = p + (1-p)\cdot h(2x-10), \; x = \{5,6,7,8,9\} \\ h(0) = 0 \\ h(10) = 1\end{cases} $$$$ My question though is about part (b) and (c). For part (b), one could form the transition probability matrix and solve a new boundary values problem, but that would be an $11 \times 11$ matrix which would be very lengthy. As for part (c), I can't seem how to proceed. I would appreciate any thorough help for (b) and (c).","['stochastic-processes', 'probability-theory', 'markov-chains', 'markov-process', 'probability']"
2725638,"""Least Squares"" of Dirac Delta?","It is well known that the first $N$ terms of a Fourier series of an even function $f$ corresponds to the least squares approximation of $f$ on $[-\pi,\pi]$ using the functions $S = \{1,\cos(x), \cos(2x),\dots,\cos(Nx)\}$. The least squares method doesn't make sense for approximating the delta function, since $$\int_{-\pi}^\pi(f(x)-\delta(x))^2\,dx$$ diverges. However, the Fourier series technique can approximate this distribution without issue. Moreover, one can populate the least-squares matrix with values when approximating the delta function. In what sense, then, is the Fourier series approximating the delta function? Is there a generalized ""least-squares"" that will quantify how close a function is to the delta function?","['least-squares', 'fourier-series', 'integration', 'dirac-delta', 'approximation']"
2725643,Non-distributive fields?,"I am thinking about construction of a structure that ""obeys"" all of the axioms for a field except an axiom of distributivity of multiplication over addition, and I am not sure is that possible at all? I mean, it ought to be possible, because, it seems that an axiom of distributivity is not necessarily redundant in a sense that it is implied by other axioms of a field. But I am really really not sure. Do you have somewhere already an example of such a structure, it could even be some familiar field with addition and multiplication specially defined to suit the purpose.","['abstract-algebra', 'field-theory']"
2725664,Vector Bundle Locally Free Sheaf,"Let $f: X \to Y$ a morphism of ringed spaces and $E$ a vector bundle over $Y$ for finite rank $r$. My questions are: Why $E$ can be interpreted as locally free sheaf of rank $r$, therefore for each $y \in Y$ there exist an open set $U$ that contains $y$ such that $E \vert _U \cong \mathcal{O}_Y ^{\otimes r}\vert _U$ Conversly, how can a locally free sheaf of rank $r$ turned to a vector bundle formally correct? Background of my question: How to interpret $f^*E$? Problem:$f^*$ accepts as arguments only sheafs on $Y$...","['vector-bundles', 'sheaf-theory', 'algebraic-geometry']"
2725671,"Inverse of a matrix belonging to $GL(2,\mathbb{Z}_{11})$","$GL(2,\mathbb{Z}_{11})$ is a general linear group whose elements are $2\times 2$ matrices where every element of matrices belongs to the set $\mathbb{Z}_{11}$ (so modulo 11 arithmetic would take place) and determinant should non-zero for matrices. So I have been given a matrix 
$$
A = \begin{pmatrix}
2 & 6 \\ 
3 & 5 
\end{pmatrix},
$$ where A belongs to $GL(2,\mathbb{Z}_{11})$ and I have to find it's inverse. So what confused me is the way the inverse would be solved ? What is process to find it's inverse ?","['abstract-algebra', 'group-theory']"
2725726,Limit of eigenvalues of a matrix sequence.,"Suppose $H$ is an $n\times n$ symmetric positive definite matrix, $M_k$ is a sequence of $n \times n$ matrix ( not necessarily symmetric ) such that $M_k \to O$ where $O$ is the zero matrix. Let $\lambda_i(H),i=1,...,n$ denote the $i$th largest eigenvalue of $H$. My question is, is it true that $\mathop {\lim }\limits_{k \to \infty } \lambda_i (H + {M_k}) = \lambda_i (H),i=1,...,n$? If this is not true for every $i$, is it true for $i=1$ (largest eigenvalue) and $i=n$ (smallest eigenvalue)? ( My application only needs this one to hold ) Any explanation, counterexample or reference is helpful. Thanks!","['matrices', 'functional-analysis', 'linear-algebra']"
2725744,Insertion and deletion of cubed words $w^3$,"Evan Chen's seminal text presents the following as (spicy) problem 11C: Consider the set of finite binary words. Show that you can't get from $01$ to $10$ using only the operation ""insert or delete any cubed word $www$."" Given a word $w = a_1 a_2 \cdots a_n$, we can define an invariant $$f(w) := a_1 - a_2 + a_4 - a_5 + a_7 - a_8 + \cdots$$ and it's not hard to show that if $v$ and $w$ are equivalent under the operation, then $f(v) \equiv f(w) \pmod{3}$. Thus, $1 = f(10) \not\equiv f(01) = 2 \pmod{3}$ tells us $10$ and $01$ are inequivalent. But this problem appears in Evan's section on group actions. Is there a group-theoretic way to preempt the invariant defined above? (I thought of it by guessing a bunch of things) Edit: Here is a proof that the above $f$ is invariant. Start with the binary word $v:= a_1 \cdots a_n$ and insert the cubed word $(b_1 \cdots b_m)^{3}$ between $a_k$ and $a_{k+1}$. Denote the new word by $w:= c_1 \cdots c_{n+3m}$. Let $\chi: \mathbb{Z}/3 \to \{-1,0,1\}$ be given by $\chi(1) = 1$, $\chi(2) = -1$, and $\chi(3) = 0$. Then we have $$f(w) = \sum_{j=1}^{n+3m} \chi(j) c_j = \sum_{j=1}^{k} \chi(j) c_j + \sum_{j=k+1}^{k+3m} \chi(j) c_j + \sum_{j = k+3m+1}^{n+3m} \chi(j) c_j$$ $$ = \sum_{j=1}^{k} \chi(j) a_j + \sum_{j=1}^{m} (\chi(k+j) + \chi(k+j+m) + \chi(k+j+2m)) b_j  + \sum_{j=k+1}^{n} \chi(j) a_j$$ Since $\chi(x) + \chi(x+a) + \chi(x+2a) \equiv 0 \pmod{3}$ for any $x$, $a$, we see that $$f(w) \equiv \sum_{j=1}^{n} \chi(j) a_j = f(v) \pmod{3}$$ as desired.","['combinatorics', 'combinatorics-on-words', 'group-theory', 'discrete-mathematics']"
2725780,Orthogonal Projection Area of a 3-d Cube,"If you're given a 3-d cube centered at the origin, i.e. the center of the cube is at $(0,0,0)$. If you rotate the cube in $x$, $y$, and $z$ direction, then how can you find the area of its orthogonal projection. For example, if you don't rotate the cube at all, then the area is just $1$. However, say you rotate the cube $45^\circ$ along the line $x=y=0$, then the area comes out to $\sqrt{2}\cdot 1 = \sqrt{2}$. Is there a general formula for this where you're given some rotation and you have to find the orthogonal projected area? What about the other way, i.e. if you're given the area, can you find the coordinates of the cube (more interested in this case)? I think this may be related to my question: Width of a tilted cube But, instead of width, I'm working with area.","['trigonometry', 'projective-geometry', 'geometry']"
2725786,"Terminology: Semigroups, only their ""binary operations"" aren't closed.","Motivation: Consider $\mathcal{X}=(X, +)$ , where $X=\{-1, 0, 1\}$ and $+$ is standard addition. Then $\mathcal{X}$ is associative (where defined) but not closed. NB: There is an identity element in $X$ and inverses exist in $X$ all with respect to $+$ . This example is taken from here . The Question: This question seems difficult to pose due to certain subtleties so, to make life easier, here's the rough idea first. What d'you call a ""magma"" that's associative but not closed? An attempt at refining the question: What do you call the mathematical objects $\mathcal{S}=(S, T, \ast)$ for which $S$ is a set and $\ast$ is some function with domain $S\times S$ and codomain some set $T$ with $S\subset T$ , such that for all $s,t,u\in S$ we have $$s\ast (t\ast u)=(s\ast t)\ast u$$ whenever $t\ast u, s\ast t\in S$ (or $T$ if that's necessary to keep the question in spirit) and there exist $x, y\in S$ such that $x\ast y\in T\setminus S$ ? (Please disregard this attempt if it complicates the idea of the question needlessly.) Thoughts: I'm not sure whether naming these things is necessary. I'm interested in them out of curiosity. Whether the question even makes sense, I don't know. Are they simply subsets of semigroups? I made sure to say function and not binary operation above, since the latter implies closure by definition.","['functions', 'terminology', 'magma', 'semigroups', 'binary-operations']"
2725809,Tautological Line Bundle coincides with Invertible Sheaf $\mathcal{O}_{\mathbb{P}_n}(-1)$,"Let consider the complex projective space in two ways: Topologically by setting $$\mathbb{P}_n =\mathbb{P}(\mathbb{C}^{n+1}) = \mathbb{C}^{n+1}/{\sim}$$ as space of complex lines and via $$\mathbb{P}^n = \operatorname{Proj}(\mathbb{C}[T_0, T_1, \ldots, T_n])$$ as $\mathbb{C}$-scheme. We have the (tautological) invertible sheaf $\mathcal{O}_{\mathbb{P}_n}(1)$ defined locally by $\mathcal{O}_{\mathbb{P}_n}(1) \vert _{D_+(T_i)} = \operatorname{Spec}(\mathbb{C}[T_0, T_1, \ldots, T_n]_{(T_i),1})= \operatorname{Spec}(\mathbb{C}[T_0, T_1, \ldots, T_n])$ where $\mathbb{C}[T_0, T_1, \ldots, T_n]_{(T_i),1}$ means the $1$-graded part of canonically graded ring $\bigoplus _i \mathbb{C}[T_0, T_1, \ldots, T_n]_{(T_i),i}$. Let $\mathcal{O}_{\mathbb{P}_n}(-1)$ be the dual sheaf of $\mathcal{O}_{\mathbb{P}_n}(1)$. It's easy to see that $\{(l,u)\in \mathbb{P}_n \times \mathbb{C}^{n+1}  \vert v \in l\}$ is a line bundle over $\mathbb{P}_n$. My question is why holds $$\mathcal{O}_{\mathbb{P}_n}(-1) = \{(l,u)\in \mathbb{P}_n \times \mathbb{C}^{n+1}  \mid v \in l\}$$ Remark: I know that we can identify locally free sheaves with vector bundles if global sections of the structure sheaf are given as regular functions $U \to \mathbb{C}$, but I don't see how to conclude the desired equation.","['vector-bundles', 'algebraic-geometry']"
2725831,Finding unit digit of $f(10)$,"If we define $$f(x)=\left\lfloor \frac {x^{2x^4}}{x^{x^2}+3}\right\rfloor$$ and we have to find unit digit of $f(10)$ I had tried approximation, factorization and substitutions like $x^2=u$ but it proved of no use. Moreover the sequential powers are feeling the hell out of me.  Can someone please provide me with some hints","['contest-math', 'calculus', 'functions']"
2725833,Showing the closed ball of the dual space X* is weak-star closed,I am practicing some elementary problems from functional analysis.  I am trying to show when X is a normed space then the closed unit ball of its dual $ X^* $ is weak-star closed. I can show whenever a sequence weak-star converges in the closed unit ball of X^* then the weak-star limit is also in the closed unit ball.  Is this enough to show that the closed unit ball of $ X^* $ is weak-star closed? Thanks!,['functional-analysis']
2725839,Find Coordinates of the Center of a Circle After It's Made a Quarter-Turn,"The question is below. I was able to solve part (a) because the $x$-coordinate would just be the circumference of the circle, which is $2\pi$. Therefore, $P = (2\pi, 0)$. I am confused with parts (b) and after,  but I know that the $y$-coordinate will remain to be $1$ because that's the radius of the circle and how far it is off from the $x$-axis. Any help with how to find the $x$-coordinate will help for part (b). Thank you in advance.","['algebra-precalculus', 'circles', 'trigonometry', 'geometry']"
2725861,Bound third moment and Fourth moment,"1) I have seen it mentioned that if X is a zero mean random variable then $\frac{E[X^4]}{\sigma^4} \geq \left\{\frac{E[X^3]}{\sigma^3}\right\}^2 + 1$ , where $E[X^2]=\sigma^2$ . Is this true, if yes ,what is the proof for this?
(I am able to prove that $\frac{E[X^4]}{\sigma^4} \geq \left\{\frac{E[X^3]}{\sigma^3} \right\}^2 $) 2) Similar to the above statement, is it possible to find an upper bound or lower bound for the third moment $E[X^3]$ in terms of the second moment $E[X^2]$ , for a zero mean $X$? I had tried using Holder's and Jensen's inequality to prove these, but it didn't give me the right direction for the bounds. I got bounds like $E[X^3] \leq \sqrt{E[X^2]\cdot E[X^4]} )$. This gives me that $E[X^4] \geq \{E[X^3]/\sigma\}^2$","['probability-theory', 'statistics']"
2725867,Can the quantum harmonic oscillator be solved by power series methods without going for asymptotic analysis?,"Although this is a question pertaining to Physics, since this is related to the mathematical treatment of a differential equation, I believe it is well suited for this community. While deriving the wave function for harmonic oscillator potential using Schrodinger's equation, we obtain the following equation through rearrangement of constants and nondimensionalization of the variables.
$$\frac{d^2\psi}{du^2}+(\epsilon-u^2)\psi=0 \tag1$$
And then we use the technique of asymptotic analysis. This is achieved by checking the behaviour of $\psi$ at large $u$ and guessing the form of the solution as $$\psi \approx \exp(-u^2) g(u)$$ And then we obtain Hermite's differential equation for $g(u)$ which can solved by power series solution. My Question: Why can't we avoid Asymptotic Analysis and directly go for a Series Solution?
  Why can't we just directly take $$\psi(u)=\sum_\limits{n=0}^{\infty} a_n u^n \tag2$$ I have checked everywhere in the internet and also in all standard books on quantum mechanics. What I have observed is that they directly go for the asymptotic analysis without stating any reason. They simply say that the asymptotic analysis will help in simplifying the calculations. However they do not mention anything about a direct solution by power series method. They do not make any comments on the possible of a direct series solution; neither why we may be able to go for such solutions nor why we can't go for such a method and have to adopt something called asymptotic analysis. I tried solving Schrödinger's Equation using such a power series as in $(2)$.
What I got was:
 $$2a_2+\epsilon a_0+(6a_3+\epsilon a_1)u+\sum_\limits{n=0}^{\infty} \left[(n+4)(n+3)a_{n+4}+\epsilon a_{n+2}-a_n\right]u^{n+2}=0$$ These gives 2 constants and $1$ recursion.
$$(n+4)(n+3)a_{n+4}+\epsilon a_{n+2}-a_n=0$$ I know that it is difficult to obtain any nice desired result from this recursive relation. But is this correct? Is this process feasible here? I checked for singularities and found none. In case this is correct, is it so that both asymptotic analysis and my procedure are allowed but the asymptotic analysis method is most favoured since in that case we get closed form results which can be used to derive other useful results? Or is this series solution not feasible due to some reason more general?","['quantum-mechanics', 'asymptotics', 'calculus', 'ordinary-differential-equations', 'power-series']"
2725922,Solve $\tan (\theta) + \tan (2\theta) = \tan (3\theta)$,"Find the general solution of:
  $$\tan (\theta) + \tan (2\theta) = \tan (3\theta)$$ My Attempt:
$$\tan (\theta) + \tan (2\theta) = \tan (3\theta)$$
$$\dfrac {\sin (\theta)}{\cos (\theta)}+ \dfrac {\sin (2\theta)}{\cos (2\theta)}=\dfrac {\sin (3\theta)}{\cos (3\theta)}$$
$$\dfrac {\sin (\theta+2\theta)}{\cos (\theta) \cos (2\theta)}=\dfrac {\sin (3\theta)}{\cos (3\theta)}$$",['trigonometry']
2725945,What is the size of the face-centered orthogonal projection of a regular dodecahedron?,"What is the edge length of the regular decagon that is the external boundary of the face-centered orthogonal projection of a regular dodecahedron of edge length 1? In other words, in this diagram of a regular dodecahedron: If the edge length of the pentagons in the middle are 1, then what is the edge length of the decagon on the outside?","['polyhedra', 'projection', 'geometry']"
2726003,Splitting Field in Group Representation and Polynomial,"I am reading a textbook about group representation and it says: A field $\mathbb{F}$ is called a splitting field for a finite group $G$ if for every irreducible representation $\rho$ of $G$ the only intertwining operator (a morphism) between $\rho$ and itself are the scalar multiples $cI$ of the identity map $I$: $V_\rho \rightarrow V_\rho$, where $V_\rho$ is the vector space over $\mathbb{F}$. However, when I read the splitting field in Wiki, it says something about polynomial: https://en.wikipedia.org/wiki/Splitting_field My question is: are both ""splitting field"" the same thing?  I am really confused about both definitions.","['representation-theory', 'abstract-algebra', 'group-theory']"
2726016,How to find the gradient of $f(x)=-\sum_{i=1}^n \log x_i$?,"I am trying to find the gradient $\nabla f(x)\,\,$ of $\,f: \mathbb{R}^n\rightarrow\mathbb{R}$ of $$f(x)=-\sum_{i=1}^n \log x_i,$$ but I am getting stuck when it comes time to deal with the log. I know there are several options for taking the derivative: delta method, which involves basically applying the extreme value theorem.  Add a small perturbation, and then isolating the parts of the function which involve an inner product of the perturbation with a function of the variable $$ f(x+h) = f(x) + \langle \nabla f, h \rangle + o(\|h\|) $$ where $o(\|h\|)$ is a function such that the limit as $h \to 0$ is zero (comes straight from the definition of differentiability); vector calculus using chain rule. Since the equation $f(x)$ is not expressed in a vector here, I figured it would be easier to do 1) via perturbation, so here's what I tried: I try to add $h$ which is my perturbation to the vector $x$ : $$f(x+h)= - \sum_{i=1}^n \log (x_i+h_i)$$ But now here, there are not many options for taking the logarithm of the sum of two numbers.  So, I'm wondering if maybe I can split this out into $\log (x_i) + \log(h_i)$ and just call my perturbation $log(h_i)$ instead of $h_i$ ? Are there any other hints to finding the gradient of this function $f$ ?","['derivatives', 'partial-derivative', 'scalar-fields', 'calculus', 'multivariable-calculus']"
2726080,Evaluating $\lim_{x\to-\infty}\frac{x^3+1}{x^3+\sqrt{4x^6+1}}$,"$$\displaystyle \lim_{x\to-\infty}\frac{x^3+1}{x^3+\sqrt{4x^6+1}}$$ I understand that we need to divide by the highest power, but first we want to factor out the $x^6$ from the radical. This gives $$\displaystyle \lim_{x\to-\infty}\frac{x^3+1}{x^3+\sqrt{x^6}\sqrt{4+\frac{1}{x^6}}}.$$ My confusion is when I plug this limit into a program such as symbolab is that it says this fraction should simplify to $$\displaystyle \lim_{x\to-\infty}\frac{x^3+1}{x^3-x^3\sqrt{4+\frac{1}{x^6}}}$$ because as $x\to-\infty\Rightarrow\sqrt{x^6}=-x^3$. Why is it that we apply this computation here, and not anywhere else in this fraction? I'm mostly confused as to why we need to make this computation in the first place.","['algebra-precalculus', 'calculus', 'limits']"
2726098,"In any triangle, if $\frac {\cos A+2\cos C}{\cos A+2\cos B}=\frac {\sin B}{\sin C}$, then the triangle is either isosceles or right-angled","In any triangle, if $\dfrac {\cos A+2\cos C}{\cos A+2\cos B}=\dfrac {\sin B}{\sin C}$, prove that the triangle is either isosceles or right angled. My Attempt: Given:
$$\dfrac {\cos A+2\cos C}{\cos A+2\cos B}=\dfrac {\sin B}{\sin C}$$
$$\dfrac {\dfrac {b^2+c^2-a^2}{2bc}+2\dfrac {a^2+b^2-c^2}{2ab}}{\dfrac {b^2+c^2-a^2}{2bc}+2\dfrac {a^2+c^2-b^2}{2ac}}=\dfrac {b}{c}$$
On simplification,
$$\dfrac {ab^2+ac^2-a^3+2a^2c+2b^2c-2c^3}{ab^2+ac^2-a^3+2a^2b+2bc^2-2b^3}=\dfrac {b}{c}$$","['trigonometry', 'triangles']"
2726162,Convergence of $\sum\limits_{n=1}^{\infty}a_n$ implies convergence of $\sum\limits_{n=1}^{\infty}a_n^{\sigma_n}$ where $\sigma_n=\frac{n}{n+1}$?,"I really don't want spoilers for this problem, but I am wondering if my approach is correct. (I am of course looking for a solution based on ""standard"" stuff regarding series, not relying on some exotic theorem from which it may follow immediately.) Let $ a_n > 0 $ for all $ n = 1, 2, 3, \ldots$ and suppose $ \sum\limits_{n=1}^{\infty} a_n $ converges. Let $ \sigma_n = \frac{n}{n+1} $. To show that $ \sum\limits_{n=1}^{\infty} a_n^{\sigma_n} $ converges, first observe that $$ \limsup\limits_{n \to \infty} ([a_n^{\sigma_n}]^{1/n}) = \limsup\limits_{n \to \infty} (a_n^{1/(n+1)}) = \limsup\limits_{n \to \infty} (a_n^{1/n}) $$ so since $ \sum a_n $ converges, $ \limsup \sqrt[n]{a_n^{\sigma_n}} \leq 1 $. If $ \limsup (\sqrt[n]{a_n^{\sigma_n}}) < 1 $, the result follows (by the Root test). Suppose $ \limsup (\sqrt[n]{a_n^{\sigma_n}}) = 1 $ intsead. Then ( this part may be totally wrong ) since $ a_n > 0 $ and $ a_n \to 0 $, $ \lim\limits_{n \to \infty} \sqrt[n]{a_n^{\sigma_n}} = 1 $, which means $$ \lim\limits_{n \to \infty} \dfrac{1}{\sqrt[n]{a_n}} = \liminf\limits_{n \to \infty} \dfrac{1}{\sqrt[n]{a_n}} = 1. $$ Hence one can find $ N \in \mathbf{N} $ such that for all $ n \geq N $, (i) $ 0 < a_n < 1 $ and (ii) $ 1 < \dfrac{1}{a_n^{1/(n+1)}} < 2 $. Then $$ |a_n^{\sigma_n}| = \left|a_n^{1 - \tfrac{1}{n+1}}\right| = |a_n| \cdot \left|\dfrac{1}{a_n^{1/(n+1)}}\right| \leq 2|a_n| $$ so $ \sum\limits_{n=1}^{\infty} a_n^{\sigma_n} $ must converge by the Comparison test.","['real-analysis', 'sequences-and-series']"
2726176,Differentiable everywhere,"So I want to show that $f(z)=|z|$ where $z$ is a complex number is not differentiable anywhere, and that $g(z)=|z|^2$ is differentiable at $z=0$ only. 
Now with some computation, I got: $\lim_{h\rightarrow 0}\frac{|z+h|-|z|}{h}=\frac{\partial}{\partial x}\sqrt{x^2+y^2}=\frac{x}{\sqrt{x^2+y^2}}$ and $\lim_{ih\rightarrow 0}\frac{|z+ih|-|z|}{ih}=\frac{1}{i}\frac{\partial}{\partial y}\sqrt{x^2+y^2}=\frac{y}{i\sqrt{x^2+y^2}}$. Thus they are not equal for $z\ne x+iy.$ Now what I do not get it is, this result would imply what I have to prove in the question, but why would this mean that this $f(z)$ is not differentiable anywhere? Similary, for $g(z)$, the computation I get for $\lim_{h\rightarrow 0}\frac{|z+h|^{2}-|z|^2}{h}=2x$ and $\lim_{ih\rightarrow 0}\frac{|z+ih|^{2}-|z|^2}{ih}=\frac{2y}{i}$, this is not equal unless $z=0$. The conclusion once again is $g$ is not differentiable unless at $z=0.$ Questions 1) Why is $f$ not differentiable anywhere? Is it because the only possible place where it is differentiable is if $z=0?$, but that would imply the denominator is $0 $ and hence undefined? 2) Why do we have to have the condition in which the partials have to be equal in order for the function to be differentiable at some given domain? I would appreciate some clear explanation. Thank You.","['derivatives', 'complex-analysis']"
2726236,Proving that $x\ast y = f^{-1}(f(x)+f(y))$ defines a group operation.,"I wasn't sure how to title this; it would either be too detailed or not detailed enough. So I have an interval $I$ of $\mathbb R$ and $f : I \rightarrow \mathbb R$ is a bijection. Also, $\forall x,y \in I$, $x*y=f^{-1}(f(x) + f(y))$ I want to prove that $(I,*)$ is a group. My confusion is the fact that I don't know what the function actually is. For example, when finding the neutral element: I want to find a $e\in I$ such that $\forall x\in I$, $x*e = e*x = x$ This means that I want to find a e such that
$f^{-1}(f(x) + f(e)) = x$ Which means that I need to find an e such that
$f(e) = 0$ but since I don't know what the function actually is, I can't do that. I was also thinking that I could maybe prove that $f$ is an isomorphism, prove that $(\mathbb R, *)$ is a group, and thus so is $(I,*)$, but I don't think this is possible either. How should I be going about this problem? Thank you.","['abstract-algebra', 'group-theory']"
2726321,1 to 27 - Guess my number,Each of four people wear a hat with a distinct positive integer $<28$. Everyone can see everyone’s number except his own. At 12:00 pm everyone can say something: either “Red” or “Yellow” or nothing. After 12:00 everyone must know his own number. How can they achieve this? Source: Brilliant,['discrete-mathematics']
2726327,"Order of subgroup generated by $ \{ 2,...,k \}$ in multiplicative group $(\mathbb{Z}/ N\mathbb{Z})^\times$","Suppose $ \{ 2,3,4,...,k \}$ is such that no element in it is a factor of N. Then is there a way of determining how large $k$ has to be, in order to generate at least half of $(\mathbb{Z}/ \text{N}\mathbb{Z})^\times$? For smaller N, having just $\{ 2 \}$ works fine, however I'm not sure how this extends to larger N. N can be assumed either prime or composite, and is not Carmichael.","['number-theory', 'abstract-algebra', 'multiplicative-order']"
2726367,What is an example where $G(p)/H(p) \not \cong (G/H)(p)$?,"Let $G$ be a finite abelian group and $H \subset G$ a subgroup. Let $G(p)$ be the $p$-torsion subgroup of $G$ for a prime $p$. Can we conclude that
$$
G(p)/H(p) \cong (G/H)(p)
$$
I've been told this is false, but the few examples I did by hand all work out. I'm probably just not trying anything big enough. Can someone provide a concrete example of where this fails? Or if it is true, can someone provide a proof? I'm sure someone has already asked this, but I don't know the right words to search to find this. EDIT: The answers given to the previous question are excellent. However, they made me realize that I gave the wrong definition. I meant to define $G(p)$ as
$$
G(p) = \{g  \in G: \exists n, \; g^{p^n} = 1\}
$$
If we define $G(p)$ in this way, is the isomorphism still false?","['finite-groups', 'abelian-groups', 'group-theory']"
2726378,Interior Area of Circle of Circles,"I am looking for the area of the white region interior to a set of circles with radius A, oriented on the edge of a larger circle with radius B, spaced apart from each other with distance C. You can assume that C is less than 2 times A, so that each smaller circle overlaps with its neighbors. To clarify, I am looking for the area of the circle with radius b, not covered by small circles.","['circles', 'geometry']"
2726470,Find $f'(a)$ if $f(x) = \frac {x^n - a^n}{x-a}$,"I'll state the multiple choice question from my textbook below: If $f(x) = \frac {x^n - a^n}{x - a}$ for some constant '$a$', then $f'(a)$ is (A) $1$ (B) $0$ (C) does not exist (D) $\frac 12$ Here's what I tried: By using quotient rule we get: $f'(x) = \frac {(n-1)x^n - nax^{n-1} + a^n}{(x-a)^2}$ Clearly, $f'(a) = \frac 00$ And the correct choice according to my book is (C). Does getting $\frac 00$ for a particular value of the variable (in this case, for $x=a$) mean that the derivative of the function doesn't exist at that point? Not satisfied by the answer I factorised the numerator of $f(x)$ and cancelled the factor $(x-a)$ as below: $f(x) = \frac {(x-a)(x^{n-1} + x^{n-2}a + x^{n-3}a^2 +..........+ xa^{n-2} + a^{n-1})}{x-a}$ $\implies f(x) = x^{n-1} + x^{n-2}a + x^{n-3}a^2 +..........+ xa^{n-2} + a^{n-1}$ Differentiating with respect to $x$ we get, $f'(x) = (n-1)x^{n-2} + (n-2)x^{n-3}a + (n-3)x^{n-4}a^2 +..........+ a^{n-2}$ $\implies f'(a) = \Big[(n-1) + (n-2) + (n-3) + .......... + 1\Big]a^{n-2}$ $\implies f'(a) = \frac {n(n-1)}2 a^{n-2}$ Now this is a completely different answer. So what have I done wrong? Is there some problem with cancelling the factor $(x-a)$? Does it have something to with the continuity and differentiabilty of $f(x)$ at $a$? What if the function was $f(x) = \begin{cases} \frac {x^n - a^n}{x - a},  & \text{if $x \ne a$} \\ na^{n-1}, & \text{if $x = a$}
\end{cases}$? How do I find the derivative at $x = a$ in this case?","['derivatives', 'calculus']"
2726526,How can we write a non-central chi-squared distribution as gamma distribution?,"Consider a random variable that has a non-central chi-squared distribution
\begin{eqnarray*}
L & = & \chi_{1}^{2}(b^{2}),
\end{eqnarray*}
where$\chi_{1}^{2}(b^{2})$ represents a non-central chi-squared with
one degree of freedom. In fact $\chi_{1}^{2}(b^{2})$ is the square
of $\mathcal{N}(b,1)$. How can we write $L$ as a Gamma distribution
please? I know that if $b=0,$ we can write 
\begin{eqnarray*}
L & \sim & \Gamma(\frac{1}{2},2).
\end{eqnarray*}
What happens when $b\neq0$ please? Thanks.","['gamma-distribution', 'statistics', 'chi-squared', 'probability-distributions']"
2726552,Some confusion about the complex logarithm and the Riemann zeta function,"I'm confused on a few things from Algebraic Number Theory by Serge Lang, Chap. VIII. I assume that $\log$ means the principal value logarithm, which is defined on $\mathbb{C} - 0$, but only continuous and analytic on $\mathbb{C} - (-\infty,0]$.  In that case, for a convergent product $\prod_n z_n$ of nonzero complex numbers with nonzero limit $z$, we only have $\log z = 2 \pi i k + \sum\limits_n \log z_n$ for some integer $k$.  See for example Theorem 18 of these notes . However, Lang immediately writes $$\log \zeta(s) =  \sum\limits_{p,m} \frac{1}{mp^{ms}}$$ where $\sum\limits_{p,m} \frac{1}{mp^{ms}} =\sum\limits_p \log (1 - \frac{1}{p^s})^{-1}$, skipping any discussion of the possibility of the $2\pi i k$.  Why is this?  Is he just skipping the proof that $k$ has to be zero? I also don't understand what is meant by the comparison $$\log \zeta(s) \sim \log \frac{1}{s-1}$$ at the end.  Neither of these functions are analytic in a punctured neighborhood of $1$, right?  How does it make sense to talk about their difference being analytic with a singularity at $1$?","['number-theory', 'complex-analysis']"
2726646,Show that $\int_0^\infty\frac{\arctan(\mathrm{πx})-\arctan(\mathrm x)}xdx=\;\frac{\mathrm\pi}2\ln(\pi)$ using 12th grade calculus.,I have to show that $\int_0^\infty\frac{\arctan(\mathrm{πx})-\arctan(\mathrm x)}xdx=\;\frac{\mathrm\pi}2\ln(\pi)$ using 12th grade calculus wich means single variable calculus. What I've tried: First I tried to make a single arctan from those 2: $\arctan(\mathrm{πx})-\arctan(\mathrm x)=\arctan(\frac{(\mathrm\pi-1)\mathrm x}{1+\mathrm{πx}^2})$ as you can see it's still not very pleasant... and it looks like I don't get anywhere with this..,"['integration', 'definite-integrals', 'calculus']"
2726666,"Prove properties of $\frac{\ln x}{x}$, and use them to show $(\sin x)^{\cos x} > (\cos x)^{\sin x} $","Given $$f(x)={\ln x \over x}, x>0$$ I) Find the monotony of $f.$ ΙΙ) Calculate the following integral: $$\int_1^2{\ln x \over x}{dx}$$ IIΙ) Find the domain of $f$ and, then, show that the equation $$3f(x)=1$$ has got exactly two positive roots $.$ IV) If $x_1,x_2 (x_1<x_2)$ the roots of question II . Show that exists $ξ\in(x_1,x_2)$ such as that $$3f(ξ)+3ξf'(ξ)=1.$$ V) Solve at $(0,{π\over 2})$ the inequality $$(\sin x)^{\cos x} > (\cos x)^{\sin x}.$$ Personal work: I) $f$ is increasing at $(0,e]$ and decreasing at $[e,+\infty)$ . Also, $e$ is the global maximum of $f$ . $f(e)={1\over e}$ II) Let $u=\ln x$ hence $du=\frac {dx}{x}\iff xdu=dx$ The integral changes to $$\int_0^{\ln2} udu=\frac {u^2}{2}=\frac {(\ln 2)^2}{2}$$ III) The domain of $f$ is: $(-\infty,{1 \over e}]\cup[e,+\infty)=[e,+\infty)$ I've tried solving for $f(x)$ so this is what I got: $$3f(x)=1\iff f(x)={1\over 3}\iff{\ln x\over x}={1\over 3}\iff 3\ln x=x\iff\ln x={x\over 3}\iff e^{\ln x}=e^{x\over 3}\iff x=e^{x\over 3}.$$ And then I could get to nowhere. Since all the questions are linked to each other, if question III remains unsolved, thus, questions IV and V cannot be solved. IV) I've thought of using Rolle's theorem since all the conditions are met. I chose Rolle over Bolzano because the equation has a derivative in it. Also, another idea would be that I find the anti-derivative of $$3f(ξ)+3ξf'(ξ)$$ and then let that be a function $g(x)$ and apply either Bolzano's theorem or Rolle's theorem. V) I really have no idea about connecting $f(x)$ with either part of the inequality.","['derivatives', 'real-analysis', 'calculus']"
2726670,Derivatives and Lebesgue measure.,"Is it true that, if $f:\mathbb{R}\rightarrow \mathbb{R}$ is continuously differentiable, then for all $E\subseteq\mathbb{R}$ with $\lambda(E)=0$, it holds that $\lambda(f(E))=0$. My thoughts would be applying the mean value theorem to f and get the measure of both sides. But the proof seems not that simple... Is there a simple proof about this?
Unless my intuition is wrong and the proposition doesn't hold.
Thanks in advance...",['functions']
2726756,How to prove identity $\nabla f(x) = \nabla F(x)*F(x)$ for 2-norm squared when chain rule says otherwise?,"I know that the chain rule says that $f(x)=h(g(x))$ and if we want the gradient then $\nabla f = \nabla h*g'(x)$. I am trying to prove the identity: $\nabla f(x) = \nabla F(x)*F(x)$  when $f(x)=\frac{1}{2}||F(x)||^2$ and $F:\mathbb{E_1}\rightarrow\mathbb{E_2}$ where $\mathbb{E}$ is a Euclidean space and $F$ is a $C^1$ smooth mapping. I am struggling with this because it seems to me like based on the definition for chain rule that I said above then wecan say $f(x)=h(g(x))$, and $h(y)=1/2||y||^2$ and $g(x)=F(x)$.  Then obviously $\nabla h=F(x)$, but then how do I get $\nabla F$ for the next part? question: Unless we are able to assume that $\nabla F=g'(x)$, and hence also assume that $g'(x)=F'(x)$ then how can I get this identity to work out? and then in general when can I assume that the derivative equals the gradient?  I was told to not assume that in general.  thanks.","['derivatives', 'vector-spaces', 'gradient-descent', 'calculus', 'vector-analysis']"
2726775,Is a principal bundle of a principal bundle still principal?,"Let $\left(P_1,\pi_1,M,G_1\right)$ and $\left(P_2,\pi_2,P_1,G_2\right)$ be two principal bundles, where $M$, $P_1$ and $P_2$ are differential manifolds, and $G_1$ and $G_2$ are Lie groups. With these settings, the chain
$$
P_2\xrightarrow{\pi_2}P_1\xrightarrow{\pi_1}M
$$
would induce
$$
\pi_1\circ\pi_2:P_2\to M.
$$ My questions are: (1) Is this $\pi_1\circ\pi_2$ always a principal bundle, and (2) In the case where $\pi_1\circ\pi_2$ is a principal bundle, is its structure group always $G_1\times G_2$? Motivation . That $\pi_1\circ\pi_2$ is always a fiber bundle seems straightforward, but I am curious as to whether this hierarchical system preserves the Lie group structure (especially if it does in the direct-product fashion). Thank you!","['principal-bundles', 'fiber-bundles', 'differential-geometry', 'lie-groups']"
2726805,Question about Product Rule? (basic calculus),"so as you all know the product rule states $\frac{d}{dx}[f(x)g(x)]=f'(x)g(x)+f(x)g'(x)$ Lets say we have the following: $\frac{d}{dx}[x^2\sin(x)]$ In this case we can use the product rule as such that we take both functions separately: $f(x)=x^2$ and $g(x)=\sin(x)$ $f'(x)=2x$ and $g'(x)=\cos(x)$ Now this is exactly what I don't get. Like at all. How is it that at the beginning we had this one function ""$\frac{d}{dx}[x^2\sin(x)]$"" that we had to take the derivative of, and we just split it in half and turned this into two separate functions? It just doesn't make any sense to me unless I'm missing something. Thanks in advance!","['derivatives', 'calculus']"
2726817,Show that this ring has no identity.,"Let $R=\left \{ g:\Bbb{R}\to \Bbb{R} \mid g \text{ is continuous and } g(1)=0 \right \}$ be a ring. Show that $R$ has no identity. The answer says there does not exist a function $h(x)\in R$ such that $h(x)=1$, which I don't understand why, since the only condition in $R$ is $g(1)=0$. Please help me understand what I am missing.","['abstract-algebra', 'ring-theory', 'functions']"
2726828,Show that the range of a linear transformation is a subspace,"Let $T : \mathbb V \to \mathbb W$ be a linear transformation from a vector space $\mathbb V$ into a vector space $\mathbb W$. Prove that the range of $T$ is a subspace of $\mathbb W$. OK here is my attempt... If we let $x$ and $y$ be vectors in $\mathbb V$, then the transformation of these vectors will look like this... $T(x)$ and $T(y)$. If we let $\mathbb V$ be a vector space in $\mathbb R^3$ and $\mathbb W$ be a vector space in $\mathbb R^2$, then $$
T \begin{pmatrix} x_1\\ x_2 \\ x_3 
\end{pmatrix} = T\begin{pmatrix} x_1 + 2x_2 \\ 3x_3 + 4 \end{pmatrix}.
$$ Now if we tried to row reduce the matrix $\begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}$ we would get $\begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix} .$ SO the range of $T$ are the linear combinations of the pivot colums of the matrix above. This is as much as I can do by myself. But now that i think about it, I believe this is wrong because the linear combinations of the pivot columns will give out any vector in $\mathbb R^2$, and not in the subspace of $\mathbb W$. Any help will be appreciated.","['matrices', 'linear-transformations', 'linear-algebra', 'vectors', 'vector-spaces']"
2726886,Show that the product topology on $X\times Y$ is the same as the disjoint union topology on $\bigsqcup_{y\in Y}X$.,"(Exercise 3.45 Lee’s Introduction to Topological Manifolds) Let $(X,\mathscr{T})$ and $Y$ be topological spaces, the latter of which is discrete. Show that their cartesian product $X\times Y$ is equal to the disjoint union $\bigsqcup_{y\in Y}X$, and the product topology the same as the disjoint union topology. My attempt: The first bit is easy. By definition, the two expressions are equivalent. The part the part that bothers me is the second: how is the product topology the same as the disjoint union topology? How can we show that
$$\mathscr{T}^{\times} =:\bigcup_{\alpha\in A}\{U_{\alpha}\times V_{\alpha}:U_{\alpha}\in\mathscr{T}, V_{\alpha}\in \mathcal{P}(Y)\},$$
and
$$\mathscr{T}^{\sqcup} =: \{U\subseteq X\times Y :U\cap X\in\mathscr{T}\},$$
are equivalent. Could anyone please give a hint which will point me in the right direction? Thanks in advance.","['product-space', 'general-topology']"
2726917,Holomorphic 1-form on Projective Curve,"Given a projective curve $C$ defined by the equation $X^5 + Y^5 +Z^5 = 0$, I would like to produce a global holomorphic 1-form $\omega$ such that for some fixed $P\in C$, I have $\operatorname{ord}_P(\omega) = 1$. In Algebraic Curves and Riemann Surfaces , Miranda defines a gluing condition of locally defined $1$-forms $f(z)\,dz$ on $V_1$, $g(w)\,dw$ on $V_2$ by requiring that
$$
g(w) = f(T(w))T'(w)
$$
where $T: V_2 \to V_1, w\mapsto z$, which I believe would be relevant for my approach to this question, which I now outline: Assuming $P = (a:b:1)\in C\cap U_2$, we have local coordinate $z$ defined by 
$$
(X:Y:Z)\mapsto \frac{X-aZ}{Z}
$$
Then $f(z)\,dz = z\,dz = \left(\frac{X-aZ}{Z}\right)\,d\left(\frac{X-aZ}{Z}\right)$ is a local holomorphic 1-form on $C\cap U_2$, which has order $1$ at $P$. I was then hoping to produce a suitable local coordinate $w$ on $C\setminus (C\cap U_2) \subseteq C\cap U_0$ and define a holomorphic transformation $T$ from this new coordinate. However, the ""obvious"" (at least to me) candidate for $w$ is $\frac{Z}{X}$, which seems not to transform in a holomorphic way to $\frac{X-aZ}{Z}$ (since $C\cap U_0$ contains points of the form $(1:\zeta:0)$ for some  $\zeta^5 = -1$). Can someone please tell me whether my approach is totally wrong, or whether I should somehow be using the equation of the curve to find a clever change of coordinate?","['riemann-surfaces', 'projective-space', 'algebraic-geometry']"
2726928,Which are the products of $\mathsf{Set}$?,"It's clear that $X \times Y$, the Cartesian product of two sets, satisfies the universal property of the product of $X$ and $Y$ in the category $\mathsf{Set}$ of sets. It is possible to show that $Y \times X$ satisfies the same property, so that it is ""the"" product of $X$ and $Y$ as much as $X \times Y$ is. Moreover, the two are canonically isomorphic, that is, there exists a unique isomorphism between them: this is a consequence of the universality of the product. My question then is: are there other objects of $\mathsf{Set}$ which are products of $X$ and $Y$? Considering just equinumerous sets shouldn't work in principle, because they are isomorphic to $X \times Y$ but not uniquely so. Then I don't have a lot of other ideas... I know that $\prod_{i \in I} X^I \cong X^I$, but I can't generalize this to the case where $X \neq Y$.","['category-theory', 'products', 'elementary-set-theory']"
2727037,"In Wasserstein, what is the relationship between $W_2 (\widehat{\mathbb{P}}_{N},\mathbb{P})$ and $W_2 (\widehat{\mathbb{P}}_{N}^{x},\mathbb{P}^{x})$?","Before presenting my question (which I already formulate in the title of this post)  is important to establish the context of my problem: Definition: The $p$-Wasserstein metric $W_{p}(\mu,\nu)$ between $\mu,\nu\in\mathcal{P}_{p}(\Xi)$ is defined by
  $$W_{p}^{p}(\mu,\nu):=\min_{\Pi\in\mathcal{P}(\Xi\times\Xi)}\left\{\int_{\Xi\times\Xi}d^{p}(\xi,\zeta)\Pi(d\xi,d\zeta)\: :\: \Pi(\cdot \times\Xi)=\mu(\cdot),\: \Pi(\Xi\times\cdot)=\nu(\cdot)\right\}$$
  where 
  $$\mathcal{P}_{p}(\Xi):=\left\{\mu\in\mathcal{P}(\Xi)\: :\: \int_{\Xi}d^{p}(\xi,\zeta_{0})\mu(d\xi) < \infty\ \mbox{for some }\zeta_{0}\in\Xi\right\}$$
  where $d$ is a metric on  $\Xi$. The $p$-Wasserstein metric (with $p\geq 1$) is also defined for any measure in $\mathcal{P}(\Xi)$ the space of all the measures of probability, the only difference is that in that set it can take values as infinite. We consider $\Xi=\mathbb{R}^{m}$ and $\xi$ a random vector with support in $\Xi$ and distribution $\mathbb{P}$, let $\widehat{\xi}_{1},\ldots,\widehat{\xi}_{N} $ be a sample of $\xi$, then we consider the empirical distributión given by
$$\widehat{\mathbb{P}}_{N}:=\sum_{i=1}^{N}\delta_{\widehat{\xi}_{i}}.$$
Given $x\in\mathbb{R}^{m}$ we consider the random variable $\zeta^{x}:=\langle x,\xi\rangle$, let $\mathbb{P}^{x}$ the distribution of $\zeta^{x}$, note that as   $\widehat{\xi}_{1},\ldots,\widehat{\xi}_{N} $ is a sample of $\xi$,  then  $\widehat{\zeta}^{x}_{1},\ldots,\widehat{\zeta}^{x}_{N}$ given  by $\widehat{\zeta}^{x}_{i}:=\langle x,\widehat{\xi}_{i}\rangle$ is a sample of $\zeta^{x}$, therefore,  we have $\widehat{P}^{x}_{N}$ the empirical distribution given by
$$\widehat{\mathbb{P}}_{N}^{x}:=\sum_{i=1}^{N}\delta_{\widehat{\zeta}_{i}^{x}}.$$
From now on we consider the $2$-Wasserstein metric with $d$ as euclidean distance, that is $d(x,y)=\left\|x-y\right\|$ where $\left\|\cdot\right\|$ is the euclidean norm. The question: What is the relationship between $W_2^2(\widehat{\mathbb{P}}_{N},\mathbb{P})$ and $W^{2}_{2}(\widehat{\mathbb{P}}_{N}^{x},\mathbb{P}^{x})$? My attepmt: I think that $$ W^{2}_{2}(\widehat{\mathbb{P}}_{N}^{x},\mathbb{P}^{x}) \leq \left\|x\right\|^{2}  W_{2}^{2}\left( \widehat{\mathbb{P}}_{N} ,\mathbb{P}\right)$$
The next is my attempt to prove it, although there are steps of which I do not feel safe. We consider $\widehat{\widehat{\xi}}_{1},\ldots,\widehat{\widehat{\xi}}_{M}$ other sample of $\xi$, then we consider $\widehat{\widehat{\mathbb{P}}}_{M}$ the empirical distribution determined by this sample. Also, we consider of sample   $\widehat{\widehat{\zeta}}^{x}_{1},\ldots,\widehat{\widehat{\zeta}}^{x}_{M}$ of $\zeta^{x}$ given by $\widehat{\widehat{\zeta}}^{x}_{i}:=\left\langle x, \widehat{\widehat{\xi}}_{i}\right\rangle$ and $\widehat{\widehat{\mathbb{P}}}^{x}_{M}$ the empirical distribution determined by this sample. We know that $ \widehat{\widehat{\mathbb{P}}}_{M} \rightarrow \mathbb{P}$ weakly, then,  by Corollary 6.11 in Villani , we have
$$W_{2}^{2}\left( \widehat{\mathbb{P}}_{N} ,\widehat{\widehat{\mathbb{P}}}_{M}\right)\overset{{\scriptstyle M\rightarrow \infty}}{\longrightarrow}W_{2}^{2}\left( \widehat{\mathbb{P}}_{N} ,\mathbb{P}\right). \tag{I}$$
Analogously we have $ \widehat{\widehat{\mathbb{P}}}^{x}_{M} \rightarrow \mathbb{P}^{x}$ weakly, then,  by Corollary 6.11 in Villani , we have
$$W_{2}^{2}\left( \widehat{\mathbb{P}}^{x}_{N} ,\widehat{\widehat{\mathbb{P}}}^{x}_{M}\right)\overset{{\scriptstyle M\rightarrow \infty}}{\longrightarrow}W_{2}^{2}\left( \widehat{\mathbb{P}}_{N}^{x} ,\mathbb{P}^{x}\right). \tag{II}$$ But note that $$
\begin{align}
W_{2}^{2}\left( \widehat{\mathbb{P}}^{x}_{N} ,\widehat{\widehat{\mathbb{P}}}^{x}_{M}\right) &= \inf\left\{\sum_{i=1}^{N}\sum_{j=1}^{M} \lambda_{i,j}\left|\widehat{\zeta}^{x}_{i}-\widehat{\widehat{\zeta}}^{x}_{j}  \right|^{2} \:\left|\: \begin{array}{l} \sum_{i=1}^{N}\lambda_{i,j}=\frac{1}{M},\\ \sum_{j=1}^{M}\lambda_{i,j}=\frac{1}{N},\\ \lambda_{i,j}\geq 0, \\ i=1,\ldots,N,\\ j=1,\ldots,M \end{array}  \right.\right\} \\
&= \inf\left\{\sum_{i=1}^{N}\sum_{j=1}^{M} \lambda_{i,j}\left|\left\langle x, \widehat{\xi}_{i}\right\rangle-\left\langle x, \widehat{\widehat{\xi}}_{j}\right\rangle   \right|^{2} \:\left|\: \begin{array}{l} \sum_{i=1}^{N}\lambda_{i,j}=\frac{1}{M},\\ \sum_{j=1}^{M}\lambda_{i,j}=\frac{1}{N},\\ \lambda_{i,j}\geq 0, \\ i=1,\ldots,N,\\ j=1,\ldots,M \end{array}  \right.\right\}  \\
&\leq  \inf\left\{\sum_{i=1}^{N}\sum_{j=1}^{M} \lambda_{i,j} \left\|x\right\|^{2}\left\| \widehat{\xi}_{i}- \widehat{\widehat{\xi}}_{j}  \right\|^{2} \:\left| \: \begin{array}{l} \sum_{i=1}^{N}\lambda_{i,j}=\frac{1}{M},\\ \sum_{j=1}^{M}\lambda_{i,j}=\frac{1}{N},\\ \lambda_{i,j}\geq 0, \\ i=1,\ldots,N,\\ j=1,\ldots,M \end{array}  \right.\right\} \:\: \begin{array}{l}\mbox{by Hölder}\\ \mbox{inequality}\end{array}\\
&= \left\|x\right\|^{2}W_{2}^{2}\left( \widehat{\mathbb{P}}_{N} ,\widehat{\widehat{\mathbb{P}}}_{M}\right).
\end{align} 
$$
Therefore, by $(I)$ and $(II)$ we have 
$$W_{2}^{2}\left( \widehat{\mathbb{P}}_{N}^{x} ,\mathbb{P}^{x}\right)\leq \left\|x\right\|^{2} W_{2}^{2}\left( \widehat{\mathbb{P}}_{N} ,\mathbb{P}\right).$$ Remark: I feel that it was a very simple demonstration, for this reason I do not trust my argument, I would like someone to help me see if my reasoning has errors. In my research this result is very important, for that reason I need to know if my idea is correct. I published my question here because I feel that here are the people trained to answer it.","['probability-theory', 'probability-distributions', 'weak-convergence', 'probability', 'measure-theory']"
2727047,Lebesgue integral of the extended Cantor function,"Let $f: [0,1] \to [0,1]$ be the extended Cantor function, and let $C$ denote the Cantor set. That is: $f(x) = \sum_{n=1}^{\infty} \frac{b_n} {2^n}$ where $b_n \in \{0,1\}$ for $x \in C$ and $f(x) = \sup\{f(y) : y \in C, y \leq x\}$ for $x \in [0,1]\setminus C$ , i.e. $f(x) = \sum_{n=1}^{\infty}\frac{2b_n}{3^n}$ for $x \in [0,1]\setminus C$ . Show that the Lebesgue integral of $f$ on the set $[0,1]$ is $1/2$ . A hint in the textbook is: note that $f$ is constant on each interval in the complement of $C$ . Edit: I have seen a somewhat convincing proof that uses symmetry, but I’m trying to follow the technique suggested by the textbook instead.","['real-analysis', 'integration', 'lebesgue-integral', 'measure-theory', 'cantor-set']"
2727056,Relationship between fundamental matrix and exponential of a matrix,"Let $A$ be an $n \times n$ matrix. I need to show that if $\Phi$ is a fundamental matrix of the system $$Y^{\prime}=AY $$
then there exists an invertible matrix B such that $\Phi = e^{At}B$, where $e^{At}$ is the exponential of the matrix $A$. I started out supposing I have $n$ linearly independent solutions $Y_{1},Y_{2},\cdots , Y_{n}$ to the system $Y^{\prime}=AY$. Then, $\Phi$ a fundamental matrix implies that $$\Phi = \begin{pmatrix} Y_{1} & Y_{2} & \cdots & Y_{n} \end{pmatrix}$$ But, I don't know where to go from here. Could somebody please help me with this proof? Thank you ahead of time for your time and patience.","['dynamical-systems', 'matrix-equations', 'ordinary-differential-equations', 'linear-algebra']"
2727081,"Power of a complex number, find $(\sqrt{3} + i)^{99}$","Question: let $$z = \sqrt{3} + i. $$ Find $$z^{99}.$$ Put your answer in $$a + bi$$ form. My work: $$r = 2$$
$$z = r(\cos \theta + i \sin \theta)
 = (2(\cos(\pi/6) + \sin(\pi/6))^{99}
 = 2^{99}(\cos(99\pi/6) + i \sin(99\pi/6))$$ Now to get it back to the $$a + bi$$ form, what do I do with the $99$?","['trigonometry', 'complex-numbers']"
2727082,"What does a symmetric matrix transformation do, geometrically?","I need some visual intuition behind what exactly a symmetric matrix transformation does. In a $2 \times 2$ and $3 \times 3$ vector space, what are they generally?",['linear-algebra']
2727102,A Lie Group and Lie Algebra Problem,"I am a physicist doing some research and I come across with the following Lie algebra problem. Consider the Lie Group $G$ (compact and connected, if you wish), and two generators in the corresponding Lie algebra $X$ and $Y$. By successive action of exponential map you can get the following element in the Lie group
$$e^{\alpha_1 X}e^{\beta_1 Y}...e^{\alpha_n X}e^{\beta_n Y} \in G.  $$ The question is: when will the whole Lie group be generated by the action above? And if some part of the Lie group cannot be generated, what is the subgroup that can be generated? Extensions: What is the closure of the generated subgroup? Can you extend the above results to 3 or more generators? Example: 
(1) Consider $SU(2)$ and $X=i\sigma_x, Y=i\sigma_y$ ($\sigma$ are Pauli matrices), then they can generate the whole $SU(2)$. (2) Consider $S^1\times S^1$ as a Lie group and $X=Y=i(a,b)$ (in the naturally chosen coordinate system). Of course only a one dimensional subgroup can be generated. However, if $\frac{a}{b}$ is irrational, the closure is the whole group. Thank you for your attention!","['abstract-algebra', 'topological-groups', 'group-theory', 'lie-algebras', 'lie-groups']"
2727104,Is Girsanov the only way to change measure?,"Let $\mathbb{P}$ and $\mathbb{Q}$ be equivalent measures and let $Z = \frac{d\mathbb{Q}}{d\mathbb{P}}$ . Let $L_t = \mathbb{E}^\mathbb{P}[Z \mid \mathcal{F}_t]$ . This is a martingale under $\mathbb{P}$ . Assume $\mathcal{F}_t$ is a filtration generated by a $\mathbb{P}$ -Brownian motion $W_t$ . Then $dL_t = \varphi_t L_t \, dW_t$ for some process $\varphi_t$ , by the martingale representation theorem. If we assume $Z \in \mathcal{F}_T$ for some $T$ , then we get a Girsanov transformation. Am I missing some important conditions, or is it really the case that all change of measures arise this way?","['stochastic-processes', 'probability-theory', 'measure-theory', 'finance', 'stochastic-calculus']"
2727124,"Show that the rectangle of largest possible area, for a given perimeter, is a square.","Show that the rectangle of largest possible area, for a given perimeter, is a square. My Attempt: Let $\textrm {length}=x$ and $\textrm {breadth}=y$. Then, Perimeter of rectangle $=2(x+y)$ Also, Area of rectangle $=x.y$
$$A=x.y$$
Now, $\dfrac {dA}{dx}=x.\dfrac {dy}{dx}+y.\dfrac {dx}{dx}$
$$=x.\dfrac {dy}{dx}+y$$","['derivatives', 'area', 'maxima-minima', 'calculus']"
2727168,Find an estimator of $\theta$ using the method of moments; call it $\hat \theta$. Prove $\hat \theta$ is a consistent estimator of $\theta$,"A random sample of size $n$, $Y_1, Y_2, \ldots, Y_n$ is drawn from a population. The population distribution has the following probability density function $f(y;\theta)=
\begin{cases}
\sqrt{\theta}y^{\sqrt{\theta}-1},  & \text{when 0 $\le$ y $\le$ 1} \\
0, & \text{elsewhere}
\end{cases}$ Find an estimator of $\theta$ using the method of moments; call it $\hat \theta$. Prove $\hat \theta$ is a consistent estimator of $\theta$ What I have done so far: First I opted to find $\mu$. So I set up my integral and solved: $$\mu = \int_0^1 \sqrt{\theta}y^{\sqrt{\theta}}dy = \frac{\sqrt{\theta}}{\sqrt{\theta}+1}$$ Then I solved the equation for $\theta$ to get $\theta = \frac{\mu^2}{(\mu-1)^2}$. So I let the estimator be $\hat{\theta} = \frac{\bar{Y^2}}{(\bar{Y}-1)^2}$ My trouble is coming from how I will prove $\hat{\theta}$ is consistent. I know two ways to show something is consistent, but I am not entirely sure how to apply that in this case. I know if: 1) $\lim \limits_{n \to \infty}E(\hat{\theta})= \theta$ and $\lim \limits_{n \to \infty}V({\hat{\theta}}) = 0$ or 2) $\lim \limits_{n \to \infty}P(|\hat{\theta_n} - \theta| \le \epsilon)=1$ or $\lim \limits_{n \to \infty}P(|\hat{\theta_n} - \theta| \gt \epsilon)= 0$ Then $\hat{\theta}$ is a consistent estimator for $\theta$. I'm just struggling to make use of those definitions. I'm not sure if my estimator is incorrect, or if I'm forgetting something, but any help would be greatly appreciated.","['statistics', 'probability', 'probability-distributions']"
2727169,Why is the group of sphere rotations isomorphic to $SO(3)$?,"If we consider the sphere in $\mathbb{R}^3$, the set of all possible rotations of it forms a group isomorphic to $SO(3)$. That is, rotations of the sphere are exactly the orthogonal linear transformations from $\mathbb{R}^3$ to $\mathbb{R}^3$ with determinant $1$. I understand why rotations of the sphere are linear transformations, and I also understand that since they all preserve length they must be orthogonal. What I don't understand is why are they necessarily of determinant $1$? My intuition is that if we allow for negative determinant that would correspond to some reflection of the sphere, which would reverse its 'orientation' and that's impossible for rotation. I don't know how to make this intuition precise and follow up on it though. Is there a way to precisely define the 'orientation' of a space and 'orientation-preserving transformations' and then conclude such transformations have non-negative determinants? If not, is there some other geometric notion that would explain why sphere rotations can't have determinant $-1$?","['group-theory', 'linear-algebra', 'linear-transformations', 'geometry']"
2727194,A few conjectured limits of products involving the Thue–Morse sequence,"( related to my previous questions $^{[1]}$ $\!^{[2]}$ ) Let's define the signed Thue–Morse sequence $t_n$ by the recurrence
$$t_0 = 1, \quad t_n = (-1)^n \, t_{\lfloor n/2\rfloor},\tag1$$
or by the generating function
$$\sum_{n=0}^\infty t_n \, x^n=\prod_{n=0}^\infty\left(1-x^{2^n}\right).\tag{$1^\prime$}$$
It seems that the following conjectures hold:
$$\lim_{n\to\infty}\prod_{k=0}^{2^n-1}\left(k+\tfrac12\right)^{t_k}\stackrel{\color{gray}?}=\frac12\tag2$$
$$\lim_{n\to\infty}\prod_{k=0}^{2^n-1}\left(k+1\right)^{t_k}\stackrel{\color{gray}?}=\frac1{\sqrt2}\tag3$$
$$\lim_{n\to\infty}\prod_{k=0}^{2^n-1}\left(k+1\right)^{(-1)^k\,t_k}\stackrel{\color{gray}?}=\frac1{2\sqrt2}\tag4$$
How can we prove these? Are there any other limits of products similar to these?","['conjectures', 'limits', 'number-theory', 'products', 'sequences-and-series']"
2727196,Set theory vocabulary: the unique subsets which compose a set?,"I'm struggling for the correct vocabulary/notation for the following situation. Let's say S is a (very simple) set with the following composition: S = {1, 2, 3, 4, 5, 6} Now, there are two subsets which compose this set, A and B : A = {1, 2}
B = {3, 4, 5, 6} Obviously, A is a subset of S, $A \subseteq S$, and B is a subset of S, $B \subseteq S$. Not only are A and B subsets of S, these are subsets which uniquely compose S, i.e. $A \cup B = S$ and $A \cap B =  \varnothing$ (1) What is the vocabulary used to describe these type of subsets? A ""unique"" subset? (2) If there is no special terminology, how would one best convey this concept notationally? e.g. $A \subseteq S$ and $B \subseteq S$ s.t. $A \cap B =  \varnothing$ maybe be one possibility, but it doesn't show that the union of A and B are the set S...","['terminology', 'elementary-set-theory']"
2727222,Canonical decomposition of absorbing chains,"An absorbing Markov chain on $n$ states for which $t$ states are transient and $n-t$ states are absorbing can be reordered in a canonical decomposition with transition matrix $$\boldsymbol{P}=
\left[
\begin{array}{c|c}
\boldsymbol{Q} & \boldsymbol{R} \\
\hline
\boldsymbol{0} & \boldsymbol{I}
\end{array}
\right]$$ where $\boldsymbol{Q}$ is a $t\times t$ matrix and $\boldsymbol{R}$ is a $t\times (n-t)$ matrix.  As usual, $\boldsymbol{0}$ is a matrix of zeros and  $\boldsymbol{I}$ is the identity matrix. An example would be the transition matrix
$$\boldsymbol{P'}=\begin{bmatrix}
0 & .6 & 0 &  0& .4 & 0\\ 
 .4&  0&  .6&  0& 0 &0 \\ 
 0&  .4&  0&  .6& 0 & 0\\ 
 0&  0&  .4&  0&  0&.6 \\ 
 0&  0&0  & 0 & 1 &0 \\ 
 0& 0 &0  & 0 &0  & 1
\end{bmatrix}.$$ Now, using the fundamnetal matrix $\boldsymbol{F}=(\boldsymbol{I}-\boldsymbol{Q})^{-1}$, we can calculate absorbtion probabilities and expected times until absorption. One example gives the doubly stochastic transition matrix $$\boldsymbol{T} = \begin{bmatrix}
.3 & .5 & .2\\ 
 .2& .4 & .4\\ 
.5 & .1 & .4
\end{bmatrix}$$ and asks to find $E(S \mid X_0 =1)$ where $S$ is the first time that $X_n=3$. The fundamental matrix is used, and the solution defines $$\boldsymbol{Q}=\begin{bmatrix}
.3 & .5\\ 
 .2& .4
\end{bmatrix}.$$ How does this make sense if the matrix is clearly not in its canonical form, and what is an efficient method to transform a matrix into its canonical form?","['stochastic-processes', 'matrices', 'markov-chains', 'statistics', 'probability']"
2727254,Every convergent sequence is bounded: what's wrong with this counterexample?,"A basic result in analysis states that convergence of a sequence implies its boundedness. I was wondering: what's wrong with $x_n = 1/(n-a)$ for some $a \in N$? This sequence is convergent to $0$, but $x_a$ is unbounded. What am I missing here? Thanks!","['real-analysis', 'sequences-and-series']"
2727275,Is the set of all Irrational Numbers a ring or a field? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I would really appreciate a proof of either one.
I think it should be a field as it satisfies the multiplicative and additive identities and is commutative.","['ring-theory', 'group-theory']"
2727300,Compact operator can be approximated by finite rank operator,"I'm beginner of functional analysis and few days ago, I learned about compact operators. If $H$ is a Hilbert space, we know that the space of finite rank operators $F(H)$ is not closed in the space of continuous (or bounded) linear operators $L(H)$ in general, and its closure is same as the space of compact operators $K(H)$. I find a different proof of the direction $K(H)\subseteq \overline{F(H)}$ and I want to know whether this is right or wrong. Let $T\in K(H)$ be a compact operator. Then we can decompose $T$ as $$ T = \frac{1}{2}(T+T^{*}) + \frac{1}{2}(T-T^{*})=:T_{1}+T_{2}$$
where $T_{1}$ is self-adjoint and $T_{2}$ is anti-self-adjoint (I mean, $T_{2}^{*}=-T_{2}$), which follows from $T^{**}=T$. By the spectral theorem, $T_{1}$ can be written as
$$
T_{1} = \sum_{n=1}^{\infty} \lambda_{n}P_{n}
$$
where $\lambda_{n}$'s are eigenvalues of $T_{1}$ satisfying  $\lim_{n\to \infty} \lambda_{n}=0$, and $P_{n}$'s are orthogonal projections to the eigenspaces $E(\lambda_{n})$, which are all finite dimensional (so $P_{n}$'s are finite rank operators). Similarly, since $T_{2}^{*}=-T_{2}$, $(iT_{2})^{*} = -iT_{2}^{*}= iT_{2}$, $iT_{2}$ is a self-adjoint compact operator, so we can apply the spectral theorem again and we get 
$$
T_{2} = -i(iT_{2}) = -i\sum_{n=1}^{\infty} \lambda_{n}'P_{n}'
$$
where $\lambda_{n}'s$ are eigenvalues of $T_{2}$ with $\lim_{n\to\infty} \lambda_{n}'=0$ and $P_{n}'$'s are orthogonal projections to the eigenspaces $E(\lambda_{n}')$, which are finite dimensional spaces. Hence $$ \lim_{N\to\infty} ||T- \sum_{n=1}^{N}(\lambda_{n}P_{n}-i\lambda_{n}'P_{n}')||=0$$ and we get the result.","['functional-analysis', 'compact-operators', 'operator-theory', 'proof-verification']"
2727358,If $x\sqrt{1+y}+y\sqrt{1+x}=0$ find $y'$,"Find $\frac{dy}{dx}$ if $x\sqrt{1+y}+y\sqrt{1+x}=0$ for $-1\leq x\leq 1$ My Attempt $$
x\sqrt{1+y}=-y\sqrt{1+x}\implies x^2(1+y)=y^2(1+x)\implies x^2+x^2y=y^2+xy^2\\
2x+2xy+x^2\frac{dy}{dx}=2y\frac{dy}{dx}+y^2+2xy\frac{dy}{dx}\\
\frac{dy}{dx}\Big[ x^2-2y-2xy \Big]=y^2-2x-2xy\\
\frac{dy}{dx}=\frac{y^2-2x-2xy}{x^2-2y-2xy}
$$
How do I proceed further and find the derivative ?","['derivatives', 'calculus']"
2727367,A problem of limit: $\lim\limits_{n\to \infty}\left\{\frac{(n+1)^{n}}{n!} \right\}^{(1/n)}$ [duplicate],"This question already has answers here : Why does $\;\lim_{n\to \infty }\frac{n}{n!^{1/n}}=e$? (3 answers) Closed 6 years ago . I need to find the limit of $$\lim\limits_{n\to \infty}\left\{\left(\frac{2}1\right) \left(\frac{3}2\right)^{2} \left(\frac{4}3\right)^{3} ... \left(\frac{n+1}n\right)^{n} \right\}^{(1/n)}$$ Cancelling out the same quantities in numerators and denominators, I have reached the step: $$\lim\limits_{n\to \infty}\left\{\frac{(n+1)^{n}}{n!} \right\}^{\frac1n}$$ Now I am stuck here. I have searched google for help, but found only the result for $\lim\limits_{n\to\infty}\left\{\frac{1}{n!} \right\}^{(\frac1n)}$. Which formulae/properties should I use now to proceed from this stage? Edit: The options for the answer are: a) $e$, b) $1/e$, c) $\pi$, d) $1/\pi$","['real-analysis', 'limits']"
2727378,Is the image of $\Phi_n(x) \in \mathbb{Z}[x]$ in $\mathbb{F}_q[x]$ still a cyclotomic polynomial?,"Let $\Phi_n(x) \in \mathbb{Z}[x]$ denote the $n$-th cyclotomic polynomial, and let $\mathbb{F}_q$ be the finite field with $p^k = q$ elements ($p$ prime). Let $\Phi'_n(x)$ be the reduction of $\Phi_n(x)$ mod $p$ (i.e., $\Phi'_n(x)$ is the image of $\Phi_n(x)$ in $\mathbb{F}_q[x]$). Is it true that $\Phi'_n(x)$ is the $n$-th cyclotomic polynomial in $\mathbb{F}_q$; that is, are the roots of $\Phi_n'(x)$ precisely the primitive $n$-th roots of unity in $\mathbb{F}_q$? If so, I want to prove this is the case, but I'm not sure how I'd go about doing this.","['finite-fields', 'abstract-algebra', 'galois-theory', 'cyclotomic-polynomials']"
2727385,Newtons method for finding reciprocal,"Define a function 1 which is $f_1(x)=a-1/x$
and function  2 which is $f_2(x)=1-ax $ If I set both to zero I am looking for when $x=1/a$ as the root using Newtons method. When I do this I get two different answers however and they should surely both be the same. for 1 I get $$x(n+1)=x(n)+x(n) (1-ax(n) )$$
and for 2 I get
$$x(n+1)=x(n)+(1/a)(1-ax(n))$$ difference being the $1/a$ term.","['derivatives', 'linearization', 'newton-raphson', 'functions', 'numerical-methods']"
2727395,Is there a closed form of this sequence?,"The sequence is  $\frac{1}{1}$ , $\frac{1}{2}$ , $\frac{2}{1}$ , $\frac{1}{3}$ , $\frac{2}{2}$ , $\frac{3}{1}$ , $\frac{1}{4}$ , $\frac{2}{3}$ , $\frac{3}{2}$ , $\frac{4}{1}$ , ...
                   and I need to find n th.. Here's my approach.. I bound them with who has same sum of denominator and numerator. So $\frac{1}{1}$ is set_1 . $\frac{1}{2}$ , $\frac{2}{1}$ are set_2.. $\frac{1}{3}$ , $\frac{2}{2}$ , $\frac{3}{1}$ are set_3 . $\frac{1}{4}$ , $\frac{2}{3}$ , $\frac{3}{2}$ , $\frac{4}{1}$ are set_4 and so on.. If I suppose that n is in set_K , I can conclude n th number is $$ \frac{1+( (n-1)-\sum_{i=1}^K (i-1) ) }{ K - ( (n-1)-\sum_{i=1}^K (i-1) ) } $$ ( because set_K starts with $\frac{1}{K}$ and n is ( n - $\sum_{i=1}^K (i-1)$ ) th member of set_K.. ) As a result my conclusion is $$\frac{2n-(K-1)K}{K(K+1) - 2(n-1) }$$ but I don't know the relationship between n and K.. Is there anyone to help me? I really want to know.. :(","['sequences-and-series', 'closed-form', 'discrete-mathematics']"
2727417,"Number of roots of the equation $x\sin x-1=0$ for $x\in [0,2\pi]$","Number of roots of the equation $x \sin x-1=0$ for $x\in [0,2\pi]$ My attempt is using the bisection method
where I initially took $a=0$, $b=\frac{\pi}{2}$ as $f(a)\cdot f(c)<0$ We can proceed along the lines we get one root $\in[0,\frac{\pi}{2}]$ Similarly we get another root $\in[\frac{\pi}{2},\pi]$ as $f(a)\cdot f(c)<0$ again but no roots   $\in[\pi,2\pi]$
as $f(a)\cdot f(c) \not< 0$ Hence we can concude we have two roots $\in[0,2\pi]$ Please tell me if I am on the correct lines. Ideas,solutions are appreciated. And if possible tell me tricks to solve such types of transcendental equations. The curve of xsinx =0 is given above. See that the ampltude of the curve goes on increasing as $(\frac{\pi}{2},\frac{5\pi}{2}...)$ This proves that if $x \in [0,2\pi]$, the function $xsinx$ can attain a value $=1$ only at two instances i.e on the +ve half of the first wave. Hence we are done . This is a lot handwavy still gives us a correct answer I guess.","['trigonometry', 'transcendental-equations']"
2727443,"In any $\triangle ABC$, prove that: $\frac {\cos B-\cos C}{\cos A +1}=\frac {c-b}{a}$","In any $\triangle ABC$, prove that: $\dfrac {\cos B-\cos C}{\cos A +1}=\dfrac {c-b}{a}$ My Attempt:
$$\begin{align}
\text{R.H.S.}&=\dfrac {c-b}{a} \\[4pt]
&=\frac {a\cos B+b\cos A-a\cos C-c\cos A}{b\cos C+c\cos B} \\[4pt]
&=\dfrac {a(\cos B-\cos C)+(b-c)\cos A}{b\cos C+c\cos B}
\end{align}$$","['trigonometry', 'triangles', 'geometry']"
2727526,Compute $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2}$,"I have to compute $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2}$. I tried say that this limit exists and it's l, so we have $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2} = L$ then I rewrited it as:
$\lim_{n\rightarrow\infty}(\frac{\sqrt n}{\sqrt[n]{n!}})^{2n}$ then I used natural log over the whole expresion but didn't got into a nice place. I don't know about Pi function or gamma function so therefore can't really use L'Hospital's rule.","['limits-without-lhopital', 'limits']"
2727614,Number of ways of minimum path,"I have no idea if this is the right place to ask a question like this. As I searched if it was, I couldn't get the answer. If not, please remind me and I will delete this. I have a specific problem that I can't solve. Please suggest solutions if possible. The problem goes like: We have n1 boxes of 50kg and n2 boxes of 100kg cargo. We have a plane which contains at most k kg. We have to ship all the cargo from one mountain to another. The principle of shipping is that at any given time (from 1 mountain to 2 or vice versa) there should be at least 1 cargo on the plane. The question is, how many ways are there to ship all the cargo in minimum number of shippings. (Like if the minimum number of flights required to ship is 5, then question is how many ways are there to ship all the cargo in 5 flights). A way is considered different if at least one flight had different amount of boxes. I'm  guessing that graph traversal should be used. Tell me if I'm wrong.","['combinatorics', 'graph-theory', 'discrete-mathematics']"
2727642,A series about $n!$ and Riemann zeta function,"Compute 
$$
\sum_{n=1}^{\infty}{\left( \frac{n^n}{n!e^n}-\frac{1}{\sqrt{2\pi n}} \right)}.
$$
By the software Mathematica, I find
$$
\sum_{n=1}^{\infty}{\left( \frac{n^n}{n!e^n}-\frac{1}{\sqrt{2\pi n}} \right)}=-\frac{2}{3}-\frac{\zeta \left( 1/2 \right)}{\sqrt{2\pi}}.
$$","['real-analysis', 'sequences-and-series', 'calculus', 'analysis']"
2727673,Convergence in Skorokhod topology implies convergence in $L^1$.,"Suppose we have a sequence of càdlàg functions $(x_n)_{n\in\mathbb{N}}\subset \mathbb{D}[0,1]$ that converges in the Skorokhod topology to $x\in \mathbb{D}[0,1]$. Do we then know that $x_n \to x$ in $L^1[0,1]$? This seems like it shouldn't hold, but I wouldn't know how to construct a counter example. As for proving the statement, I end up with for all $\epsilon > 0$ there is an $N$ such that for all $n\geq N$ there is a homeomorphism $\alpha_n: [0,1]\to[0,1]$ such that
\begin{align*}
\int_0^1 |x_n(t) - x(t)|dt
&\leq \int_0^1  |x_n(t) - x(\alpha_n(t))| + |x(\alpha_n(t)) - y(t)|  dt\\
&\leq \epsilon + \int_0^1 |x(\alpha_n(t)) - x(t)| dt.
\end{align*}
My intuition says that this last integral does not necessarily go to $0$ as $n \to \infty$. Is there an easy way to show that this does (not) hold?","['general-topology', 'lp-spaces']"
2727733,A way to directly see that the interior angles of triangle sum to $180^\circ$?,"I'm looking for a way to look at a triangle, and perhaps visualize a few extra lines, and be able to see that the interior angles sum to $180^\circ$. I can visualize that supplementary angles sum to $180^\circ$. I'd like to be able to see the interior angle sum similarly... I can see that the exterior angles must sum to $360^\circ$, because if you walked around the perimeter, you would turn around exactly once (though I can tell this is true, I don't really see it). I also saw a proof on KA, where the exterior angles were superimposed, to show they summed to $360^{\circ}$ (though I'm not 100% comfortable with this one). Finally, for $a$, $b$, and $c$ exterior angles $a+b+c=360$: \begin{align}
 (180-a) + (180-b) + (180-c) & = 3\times 180 - (a+b+c) \\
                             & = 3\times 180 - 360 \\
                             & = 180 \\
\end{align} But I find this algebra hard to see visually/geometrically. Is there proof that enables one to directly see that the interior angles of triangle sum to $180^\circ$? A couple of secondary questions: am I visually deficient in my ability to imagine? or, am I asking too much of a proof, that I be able to see it, and that beimg able to tell that it is true should be enough...?","['visualization', 'geometry']"
2727738,What is the meaning of vector measures?,"In the case measures, assume that we are considering a positive measure $\mu$ on $\mathcal{B}(R^{2})$-which is the set of borel sets in $R^{2}$, that has density f(x,y)-it can be seen as density of polulation. Then, when we consider a borel set $A\subset R^{2}$, we obtain the information of the population in the set A which is $$\mu(A)=\int_{A} f(x,y)d\mu.$$ So, now could you give me some practical examples that can illustrate the concept of vector measures?.","['geometric-measure-theory', 'measure-theory']"
2727769,"What about sequences $\{\sum_{k=1}^n (\operatorname{rad}(k))^p\}_{n\geq 1}$ containing an infinitude of prime numbers, where $p\geq 1$ is integer?","We denote the radical of the integer $n> 1$ as
$$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\ p\text{ prime}}}p,$$
taking $\operatorname{rad}(1)=1$ that is this definition from Wikipedia . In this post we do a comparison with the so-called Faulhaber polynomials (their factorization), see this Wikipedia in the way that I am going to define sequences using the arithmetic function $a(k)=\operatorname{rad}(n)$ instead of the arithmetic function $a(k)=k$ inside the finite sums $$\sum_{k=1}^n (a(k))^p$$
where $p\geq 1$ is a fixed integer. The comparison that we evoke is ask us when (for a fixed integer $p\geq 1$) the sequence $$\sum_{k=1}^n (\operatorname{rad}(k))^p\tag{1}$$
reaches/contains infinitely many prime numbers, this is that our sequence $(1)$ has infinitely many terms being prime numbers for a fixed choice of $p$. I think that this conjecture is wild, since I did few experiments (and I hope that these were rights) and by the mentioned comparison. Any case I would like to know feedback about our question from this MSE. Question. Can you find an integer (or what do you think about it) $p\geq 1$ such that the sequence $$\sum_{k=1}^n (\operatorname{rad}(k))^p$$ contains only a finite number of prime numbers in its terms as $n$ runs over the positive integers $\geq 1$? Or well, what are your heuristic or reasoning to elucidate if this kind of sequences $(1)$ should have finitely many or infinitely many prime numbers for a choice of $p$, when $n\geq 1$? Many thanks. I think that this question can be very difficult. I should to choice some answer that provide good feedback about it, thus isn't required solve all minor questions. I did this variation since the radical of an integer $\operatorname{rad}(n)$ is an important arithmetic function (related to the so-called abc conjecture) in analytic number theory, is a multiplicative function and it's like a substitute of the function $a(n)=n$.","['analytic-number-theory', 'prime-factorization', 'experimental-mathematics', 'prime-numbers', 'sequences-and-series']"
2727793,Find general solution to this PDE,"$$x^2z{\partial z\over\partial x} + y^2z{\partial z \over \partial y} = x+y$$ 
My attempt: 
$${dx\over x^2z}={dy\over y^2z}={dz\over x+y}$$ Notice ${dx\over x^2z}={dy\over y^2z} \text{ we can multiply by } z \text{ and after integration} \Rightarrow {1\over x} = {1\over y} + C_1$ Here I stuck, 'cause I can't find new combination to integrate. I'm sure there are a lot of people quite good at finding these combination. So my question is also what are you looking at first. Is there common tricks to get this done?","['ordinary-differential-equations', 'partial-differential-equations']"
