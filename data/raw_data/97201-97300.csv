question_id,title,body,tags
1340659,Calculate in closed form $\sum_{n=1}^{\infty} \frac{\arctan(1/n) H_n}{n}$,"Playing with Taylor series is not helpful enough. What else would you try out? $$\sum_{n=1}^{\infty} \frac{\arctan(1/n) H_n}{n}$$
$$\approx 2.1496160413898356727147400526167103602143301206321$$
It's easy to see the series converges since $\arctan(1/n) \approx 1/n$ when $n$ large.
Maybe its integral representation makes us feel more comfortable $$1/4\int_0^1 \frac{ 2(\gamma  \pi  x \coth (\pi  x)+\gamma) +i x \left(\psi ^{(0)}(-i x)^2-\psi ^{(0)}(i x)^2-\psi ^{(1)}(-i x)+\psi ^{(1)}(i x)\right)}{ x^2} \, dx$$","['sequences-and-series', 'calculus', 'real-analysis']"
1340719,Numerically find a potential field from gradient,"I know that the gradient of a potential field/scalar field is a vector field, and given the function of the gradient I know how to integrate each component to get back the original scalar field. But is it possible to do this numerically? For example, if I know the value of the gradient as a vector at a finite number of points in 2 dimensions, how can I determine (or at least approximate) the value of the scalar potential function at each of those points?","['numerical-methods', 'multivariable-calculus']"
1340723,Big O Notation basics,"Having some problems with big O notation question... getting confused on how to figure this out. I'm working on a problem (exam coming up so doing extra ones) where it asks us to arrange the functions in a list so that every function is big-O of the next. $$2^{100n}, 2^{n^2}, 2^{n}, n\log n, \log \log n, n^{\frac{1}{2}}, n(\log n)^{1/2}, n^{4/3}(\log n)^2$$ Big O is extremely confusing to me so I don't know where to start.. edit: fiddling around with Latex, please bear with me!",['discrete-mathematics']
1340732,"When proving that f(z) is a polynomial, is it enough to consider just one point instead of keeping z arbitrary?","I think so - but I'd rather ask the MSE community too. Say I am given the bound |f(z)| < $|z|^3$, and that f is entire.  Show f must be a polynomial. I used Cauchy's Integral Formula for derivatives and showed that for n>3, all of the derivatives are zero, when we let the closed contour grow to infinity. But, I have only used CIF at the point z = 0 - I didn't keep z arbitrary. Then the CIF shows that, at z = 0, the Taylor series has only finitely many terms and so f(z) must be a polynomial. So I feel there's actually no need to apply the CIF to an arbitrary z. We have enough information on f(z) just from looking at z=0. Thanks,","['taylor-expansion', 'polynomials', 'laurent-series', 'complex-analysis']"
1340741,How to remember/rederive the isomorphisms from the half planes to the unit disc,"I know that $$z \mapsto \frac{z-i}{z+i}$$ maps the upper half plane to the unit disc, and $$z \mapsto \frac{z-1}{z+1}$$ maps the right half plane.  Is there an intuitive way to construct such maps from scratch?",['complex-analysis']
1340744,Higher direct image of morphism with generic fiber $\mathbb{P}^1$,"Let $f:X\to Y$ be the morphism of smooth varieties over $\mathbb{C}$ with generic fiber equal to $\mathbb{P}^1$. How to prove that $R^if_*\mathcal{O}_X=0$ for $i>0$? (I do not need the complete solution, just an idea)","['algebraic-geometry', 'sheaf-cohomology']"
1340753,Best estimate using Cauchy integral formula: why is a circle the optimal path?,"I once encountered this question from Ahlfors' Complex Analysis. An analytic function $f$ has the property that for $|z|<1$, $|f(z)|\leq \frac{1}{1-|z|}$. Find the best estimate of $|f^{(n)}(0)|$ that Cauchy's formula will yield. I solved it by finding an estimate via the Cauchy integral formula over a circle of general radius and then optimized the result by differentiating it with respect to the radius. I later wondered, why should we expect the optimal path to be a circle? I applied the Euler-Lagrange Equations to this problem and got a completely untractable O.D.E. I expect that a circle is the optimal path, but is there a concrete reason why? Edit Here is my application of the Euler-Lagrange equations: Suppose we want to integrate on a path $\gamma(t)=r(t)e^{i\theta(t)}$ for $0\leq t\leq 1$ with the stipulation the $\gamma(0)=\gamma(1)$ and $0<r(t)<1$. This leaves us with $|f(z)|<\frac{1}{1-r(t)}$, and $|dz|=|r'(t)+ir(t)\theta'(t)|dt.$ Then the problem is to minimize
$$|f^{(n)}(0)|\leq\frac{n!}{2\pi}\int_0^1\frac{1}{r^{n+1}(t)(1-r(t))}|r'(t)+ir\theta'(t)|dt.$$ It is sufficient that we optimize the integrand. Let the integrand be written $$F(r,\theta,r',\theta')=\frac{\sqrt{r'(t)^2+r(t)^2\theta'(t)^2}}{r^{n+1}(t)(1-r(t))}.$$ I simply apply the variational derivative:
$$\frac{\partial F}{\partial r}-\frac{d}{dt}\frac{\partial F}{\partial r'}=0,$$
$$\frac{d}{dt}\frac{\partial F}{\partial \theta'}=0.$$ As much as I hate to spoil the joy of working out the differential equations on your own, I have computed them form you: $$\frac{r(t)^{-n} \theta '(t) \left(r(t) \theta '(t) \left(r(t) \left(r''(t)-n \theta '(t)^2\right)+(n+1) r(t)^2 \theta '(t)^2-r''(t)\right)+(n r(t)-n+1) r'(t)^2 \theta '(t)-(r(t)-1) r(t) r'(t) \theta ''(t)\right)}{(r(t)-1)^2 \left(r'(t)^2+r(t)^2 \theta '(t)^2\right)^{3/2}}=0,$$
$$-\frac{r(t)^{-n} r'(t) \left(r(t) \theta '(t) \left(r(t) \left(r''(t)-n \theta '(t)^2\right)+(n+1) r(t)^2 \theta '(t)^2-r''(t)\right)+(n r(t)-n+1) r'(t)^2 \theta '(t)-(r(t)-1) r(t) r'(t) \theta ''(t)\right)}{(r(t)-1)^2 \left(r'(t)^2+r(t)^2 \theta '(t)^2\right)^{3/2}}=0$$ It is not too hard to see that these reduce to equations solved by the result for the circle assuming that $r'(t)=0$ and $\theta'(t)=\text{const}$. Thus, the circle I initially found is a stationary point, but it may not be unique. I am stymied at the prospect of finding other solutions.",['complex-analysis']
1340766,How to find intersection of two hypotenuses,"I am a web developer who is bad with mathematics. I have never needed some math/geometry formulas before. But now I realize it is needed for more advanced design tecniques. I decided to learn math but I need some urgent formulas for some project that I am working on right now. So here is the problem: I am drawing some shape with canvas in HTML. I need to calculate point that shown on the image. The bottom side shape and right side shape are looks like triangle. so the hypoenuse degrees are static but I need to find intersection point on different screen sizes. I am drawing this shape exactly as it is on a screen. I want to keep angle these hypotenuses' angles on every screen resolutions. Edge A: always 112pixels Edge D: always 77pixels Edge B: changes according to screen resolution (Height) Edge C: changes according to screen resolution (Width) Angle A-Hypotenuse: 22.7deg Angle D-Hypotenuse: 9.16deg Coordinate(0, 0): top, left of the image. Here is how I draw this edges: MoveTo (maxWidth - 112, 0) DrawLine(maxWidth, 0) // Drawing A edge DrawLine(maxWidth, maxHeight) // Drawing B edge DrawLine(0, maxHeight) // Drawing C edge DrawLine(0, maxHeight - 77) // Drawing D edge DrawLine(?, ?) // the point that showed with arrow remaining loyal to the given angles. PS: I know it should be very easy for you but It's hard for me since I forgot everything that I got from school","['geometry', 'coordinate-systems']"
1340790,Integration by parts for general measure?,"Let $\mu$ be a general measure, suppose $f,g$ has compact support on $\mathbb{R}$, when does the integration by parts formula hold
$$\int f'g d\mu = - \int g'fd\mu?$$
I know in general this is false, we can take $\mu$ to be supported on a point, say $0$, then it is not necessarily true that 
$$f'(0)g(0) = -g'(0)f(0).$$ If $\mu$ is absolute continuous w.r.t. Lebesgue measure, we have $\frac{d\mu}{dx} = h$
$$\int f'gd\mu = \int f'gh dx = -\int f(gh)'dx$$
where $(gh)'dx$ might be a measure. but we can not recover the form $\int g'fh dx$. Thank you very much!","['partial-differential-equations', 'real-analysis', 'measure-theory', 'integration']"
1340809,Inequality with reciprocals of $n$-variable sums,"Let $a_1,a_2,\ldots,a_n$ be positive real numbers. Is it always true that
$$\sum_{i=1}^n\frac{1}{a_i}-\sum_{1\leq i<j\leq n}\frac{1}{a_i+a_j}+\sum_{1\leq i<j<k\leq n}\frac{1}{a_i+a_j+a_k}-\cdots+\frac{(-1)^{n-1}}{a_1+\ldots+a_n}>0?$$ The inequality is trivially true when $n=1,2$. For $n=3$, we have $$\frac{1}{a_1}>\frac{1}{a_1+a_2},\frac{1}{a_2}>\frac{1}{a_2+a_3},\frac{1}{a_3}>\frac{1}{a_3+a_1}, \frac{1}{a_1+a_2+a_3}>0.$$ For $n=4$ it is harder to compare terms directly. Note: This is related to this question about inclusion-exclusion-like sum , but neither question implies the other.","['real-numbers', 'algebra-precalculus', 'inequality']"
1340829,Proving that there exist products of $a_k \equiv 1 \pmod {a_i}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $n>2$ be an integer. Prove that there exist numbers $a_1, a_2, \ldots ,a_n$ such that
  $$a_1a_2\cdots \widehat{a_i}\cdots a_n \equiv  1 \pmod{a_i}$$
  for $i=1,2,3,\ldots,n$. Here $\widehat{a_i}$ means that $a_i$ is omitted. Thank you!!","['contest-math', 'number-theory', 'congruences']"
1340830,Basis for $l^{\infty}$,"As the question stated, we know that $\{e_i\}$ doesn't form a basis for $l^{\infty}$. So how can we find a basis for $l^{\infty}$, no matter it is Schauder or Hamel basis.",['functional-analysis']
1340832,Real Projective Space Homeomorphism to Quotient of Sphere (Proof),"I need to construct a function $f : (\mathbb{R}^{n+1}-\{0\})/{\sim} \to S^n/{\sim}$,  by 
$$f ([x]_{\mathbb{RP}^n}) = \left[\frac{x}{\|x\|}\right]_{S^n/{\sim}},$$ 
where  $S^n = \{ x \in \mathbb{R}^{n+1} : \|x\| = 1\} $ , $\sim$ on $S^n$ by $x \sim y \iff x = -y \lor x = y $. ${\mathbb{RP}^n}$ for real project space on $\mathbb{R}^{n+1}$. I have shown that this function is bijective and continuous. However, in order to prove it's homeomorphism, I need its inverse to be continuous, and I find it's very hard to prove this part. Any hint is appreciated.","['projective-space', 'general-topology']"
1340856,Using Multiple Scale Analysis to solve a non-linear differential equation,"I would like to know if there are other methods to solve equations such as this one below. I don't really understand the theory behind the multiple scale analysis and why it works I understand some of the reasoning behind it just not the proof and theory. I kind of chose a differential equation for which I think it works and tried it out following a example from a similar equation. I think the answer seems strange but I was very thorough in my calculations. I welcome any comments or advice to problems like these thanks! \begin{equation}u^{''} +\omega_0^2u=-2\epsilon \mu u^{'}-\epsilon u^2 u^{'} + \epsilon k \cos \Omega t\end{equation}
First we introduce two time variables (fast and slow) and define them as \begin{equation}T_0=t\;\;\;T_1=\epsilon t\end{equation} where $T_0$ is the fast time scale and $T_1$ is the slow time scale. The first order expansion of the problem is \begin{equation}u(t)=u_0(T_0,T_1)+\epsilon u_1(T_0,T_1)\end{equation} Differentiating the time derivative becomes \begin{align}
\frac{du}{dt}=\frac{\partial u_0}{\partial T_0} \frac{dT_0}{dt}(1)+(\epsilon) \frac{\partial u_1}{\partial T_1} \frac{dT_1}{dt}=\frac{\partial u_0}{\partial T_0}+\epsilon \frac{\partial u_1}{\partial T_1}
\end{align} 
Define the linear operators, and functions \begin{equation} D_0=\dfrac{\partial}{\partial T_0},\hspace{10pt} D_1=\dfrac{\partial}{\partial T_1}\end{equation} The time derivative becomes $\dfrac{d}{dt}=D_0+\epsilon D_1$. The second order time derivative is then expressed as 
\begin{equation}\frac{d^2}{dt^2}=(D_0+\epsilon D_1)^2=D_0^2+2D_0D_1 \epsilon +\epsilon ^2 D_1^2\end{equation} The $\epsilon ^2$ term is neglected. We are now ready to substitute our results in the original equation to obtain, 
\pagebreak $$(D_0^2+2\epsilon D_0 D_1)(u_0+\epsilon u_1)+\omega^2_0(u_0+\epsilon u_1)=-2\epsilon \mu (D_0+ \epsilon D_1)(u_0+\epsilon u_1)-$$$$\epsilon (u_0+\epsilon u_1)^2(D_0+\epsilon D_1)(u_0+\epsilon u_1) + \epsilon k \cos \Omega t$$
$$\implies (D_0^2u_0+\epsilon D^2_0  u_1+2\epsilon D_1D_0 u_0 +2\epsilon ^2D_0 D_1 u_1^2)+\omega_0^2u_0+\epsilon \omega_0^2  u_1=-2 \epsilon \mu D_0u_0-2\epsilon^2\mu (...)$$ $$-\epsilon u^2_0D_0u_0+\epsilon^2(...)+\epsilon k \cos \Omega t
$$
\begin{equation}\implies D_0 u_0+ \epsilon D_0 u_1 +2 \epsilon D_1 D_0 u_0+ \omega_0^2 u_0+\epsilon \omega_0^2 u_1=-2\epsilon \mu D_0 u_0-\epsilon u_0^2D_0u_0+\epsilon k \cos \Omega t\end{equation}
Now we construct a system of differential equations in powers of $\epsilon$ called zero-order and first order problems and given by,
\begin{align} D_0^2u_0+\omega_0^2u_0=0\end{align} \begin{align} D^2u_1 +\omega_0^2u_1=-2D_1D_0 u_0-2\mu D_0u_0-u_0^2D_0u_0+k \cos \Omega t \end{align} The first equation is a second order linear, homogeneous equation with constant coefficients and has general solution
 \begin{equation}u_0(T_0,T_1)=A(T_1)e^{i\omega_0T_0}+\bar{A}(T_1)e^{-i\omega_0T_0}\end{equation}
 where $A(T_1)$ is the complex amplitude afterwards. Our next step is to investigate primary resonance of the system, which occurs when the actuation frequency $\Omega$ is near the natural frequency, $\omega_0$. This can be written as
 \begin{align}\Omega=\omega_0+\epsilon \sigma\\ \Omega T_0=\omega T_0 +\epsilon T_0 \sigma\\\Omega t= \omega T_0+T_1\sigma \end{align} We substitute $u_0$ into the equation (2) to get, 
\begin{equation*}D_0^2u_1+\omega_0^2u_1= -2D_0D_1[A(T_1)e^{i \omega_0 T_0}+\bar{A}(T_1)e^{-i \omega T_0}]-2\mu D_0[A(T_1)e^{i\omega_0T_0}+\bar{A}(T_1)e^{-i \omega T_0}]- \end{equation*}\begin{equation} [A(T_1)e^{i\omega_0T_0}+\bar{A}(T_1)e^{-i\omega T_0}]^2D_0u_0+k\frac{e^{i \omega_0 T_0}e^{i\sigma T_1}+e^{-i\omega_0T_1}e^{-i\sigma T_1}}{2}\end{equation} Thus applying the linear operations to the above to get $$-2[A^{'}e^{i\omega_0T_0}(i\omega_0)+\bar{A}^{'}e^{-i\omega_0T_0}(-i\omega_0)]-2\mu[Ae^{i\omega_0 T_0}(i\omega_0)+\bar{A}e^{-i\omega_0T_0}(-i\omega_0)]+$$$$\bigg(-A^2e^{2i\omega_0T_0}-2A\bar{A}-\bar{A}^2e^{-2i\omega T_0}\bigg)\bigg(Ae^{i\omega_0T_0}(i\omega_0)-\bar{A}e^{-i\omega_0T_0}(i\omega_0)\bigg)+\frac{k}{2}\bigg(e^{i(\omega T_0+\sigma T_1)}+e^{-i(\omega_0 T_0+\sigma T_1)}\bigg)$$
 $$\implies -2A^{'}e^{i\omega_0T_0}(i\omega_0)+2\bar{A}^{'}e^{-i\omega_0T_0}(i\omega_0)-2\mu Ae^{i\omega_0 T_0}(i\omega_0)+2\bar{A}e^{-i\omega_0T_0}(i \omega_0)$$$$-A^3e^{3i\omega_0T_0}(i\omega_0)+A^2\bar{A}e^{i\omega_0T_0}(i\omega_0)-2A^2\bar{A}e^{i\omega_0T_0}(i\omega_0)+2A\bar{A}^2e^{-i\omega T_0}(i\omega_0)-A\bar{A}^2e^{-3i\omega_0T_0}(i\omega_0)+\bar{A}^3e^{-3i\omega_0T_0}(i\omega_0)$$\begin{equation}+\frac{k}{2}\bigg(e^{i\omega T_0}e^{i\sigma T_1}+e^{-i\omega_0} e^{-i\sigma T_1}\bigg)\end{equation} Consider $A(T_1)=\dfrac{1}{2}ae^{i\beta}$ where $a$ and $\beta$ are the real amplitude and phase from the secular\ terms equation. Secular terms are nonhomogenous terms that make the function unbounded they are inconsistent with the behavior of the physical system, thus they must be eliminated. A term is secular if it is a solution of the homogenous equation.  Therefore, the sum of the coefficient of $e^{i \omega T_0}$ must be $0$. $$-2A^{'}(i\omega_0)-2\mu A(i\omega_0)-A^2\bar{A}(i\omega_0)+\dfrac{k}{2}e^{i\sigma T_1}=0$$
$$e^{-i\beta}\bigg(-a^{'}(i\omega_0)e^{i\beta}+a\beta^{'}\omega_0e^{i\beta}-\mu ae^{i\beta}(i\omega_0)-\frac{1}{8}a^3e^{i\beta}(i\omega_0)+\frac{k}{2}e^{-i\sigma T_1})=0\bigg)
$$
\begin{equation}-a^{'}(i\omega_0)+a\beta^{'}\omega_0-\mu a(i \omega_0)-\frac{1}{8}a^3(i \omega_0) +\frac{k}{2}\bigg(\cos(\sigma T_1-\beta)+i\sin(\sigma T-\beta)\bigg)=0\end{equation}
For the entire function to be zero Real and Imaginary parts must be 0.  \begin{equation}a\beta^{'}\omega_0+\frac{k}{2}\cos(\sigma T_1-\beta)=0
\end{equation} \begin{equation}-a\omega_0-\frac{1}{8}a^3\omega_0 + \sin(\sigma T_1-\beta)-\mu a \omega_0=0\end{equation}
We make a change of variables and set $\gamma=\sigma T_1-\beta$ so that $\beta^{'}=\sigma T_1-\gamma^{'}$. Therefore we have that,
\begin{equation}a\gamma^{'}=a\sigma +\frac{k}{2\omega_0}\cos \gamma\end{equation}
\begin{equation}a^{'}=-\mu a-\frac{1}{8}a^3+ \frac{\sin \gamma}{\omega_0}\end{equation}
Steady states occur when $a\gamma^{'}=0$ and $a^{'}=0$ therefore we have that
\begin{equation}-\mu a-\frac{1}{8}a^3 +\frac{\sin \gamma}{\omega_0}=0\end{equation}
\begin{equation}a\sigma+\frac{k}{2\omega_0} \cos \gamma=0\end{equation}
There fore the solution is 
\begin{equation}\begin{cases} a+\dfrac{1}{8}a^3=\dfrac{\sin \gamma}{\mu \omega_0} \\ a\sigma=-\dfrac{k}{2\omega_0}\cos \gamma \end{cases}\end{equation}","['calculus', 'perturbation-theory', 'numerical-methods', 'ordinary-differential-equations', 'partial-differential-equations']"
1340863,Infimum taken over $\lambda$ in $\mathbb{C}$,"I want to calculate the infimum of 
$$ |\lambda-2|^2+|2\lambda-1|^2+|\lambda|^2 $$
over $\lambda\in\mathbb{C}.$ I choose $\lambda=2,1/2,0$ so that one term in the above expression becomes zeros and minimum comes out $5/2$ at $\lambda =1/2.$ Is this infimum also, please help.","['sums-of-squares', 'complex-numbers', 'algebra-precalculus', 'supremum-and-infimum', 'normed-spaces']"
1340875,How long will this take to reach.. kimye?,"I found the 1bc29b36f623ba8 twitter account on 4chan last night, it's a user who is posting md5 hashes every 10 minutes in a sequential order, starting at ! and I assume with no end in sight. The twitter account has a specific twitter post structure [sequence hashed] #[sequence in plaintext] #md5 #allday #ðŸ’¯ which in my eyes reads quite upbeat about performing md5 hashing all day . The most interesting thing, I think, is that this crypto focused account is following a rather odd selection of users. Kim Kardashian and Kanye West . Could someone do the math and figure out when it will reach kimye ? ( kimye is a common abbreviation of Kim Kardashian and Kanye West, as a couple).. I'm barely interested in the couple, but from what I can tell kimye will be the first string to reference the accounts two favourite people. The characters used appear to be limited to the following: !#$%&()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~",['sequences-and-series']
1340884,Find the Laurent series about $z=0$,"Let $f(z)=\cfrac{e^{-3z}}{z^2(z-2)^2}$, find the Laurent series about $z=0$. On the region $0<|z|<2$,  I get $\cfrac{1}{(z-2)^2}=\displaystyle\sum_{n=1}^{\infty}\cfrac{nz^{n-1}}{2^{n+1}}$, then
$\cfrac{1}{z^2(z-2)^2}=\displaystyle\sum_{n=1}^{\infty}\cfrac{nz^{n-3}}{2^{n+1}}$ And I get confused here, is it ok if I let $f(z)=\cfrac{e^{-3z}}{z^2(z-2)^2}=e^{-3z}\displaystyle\sum_{n=1}^{\infty}\cfrac{nz^{n-3}}{2^{n+1}}$ Or I have to express $e^{-3z}$ as its Taylor series and the multiplicate? Thank you","['laurent-series', 'complex-analysis']"
1340888,What is happening in the picture,"I came across the picture below through random means. What is being demonstrated? All I could think of is maybe the center of the triangle is moving back and forth between the focii of the ellipse, but even if that's true (which it may or may not be - it's purely conjecture on my part), there's clearly more going on here.",['geometry']
1340901,show that the ordered square is locally connected~,"show that the ordered square is locally connected but not locally path connected. what are the path components of this space? this problem is exercise munkres 25-3, and also example 24-6
and there, let $Ux$ = $f^-1(x$x$(0,1))$ and get contradiction using injective mapping of I into Q. however another solution from https://onesidey.wordpress.com/2012/03/09/munkres-25/ why 'neighborhood of x contains a subsapce homeomorphic to the ordered square itself' means not path connected? and if you possible, show me another solution or explanation for this problem",['general-topology']
1340903,Separated Schemes and Intersection,"Let $X$ be a separated scheme. I am trying to show that if $U$ and $V$ are affine open sets then $U\cap V$ is also. I can see that $U\cap V$ is homeomorphic to $d(X)\cap (U\times V)$. Where $d$ is the diagonal map from $X$ to $X\times X$. Thus, $U\cap V$ is homeomorphic to a closed subset of $U\times V$. I do not see why ""affineness"" follows from this. If $U=\text{spec}(A)$ and $ V = \text{spec}(B)$ then $U\times V$ is the spectrum of $A\otimes_{\mathbb{Z}}B$. But how does this help in completing the proof?",['algebraic-geometry']
1340939,A Banach space of (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0}=\kappa$,"A Banach space of (Hamel) dimension $\kappa$ exists if and only if $\kappa^{\aleph_0}=\kappa$. How will we prove the converse implication. One sided implication for Hilbert Space is proved in question: Can you equip every vector space with a Hilbert space structure? If we don't assume Axiom of Choice, and we have a Banach space with (Hamel Basis B existence given). Will it be true $B^\Bbb N$ equinumerous with $B$? Note: $B^\Bbb N$ is not empty as $B$ is specified.","['banach-spaces', 'functional-analysis', 'axiom-of-choice']"
1340973,Can a fractal be a manifold? if so: will its boundary (if exists) be strictly one dimension lower?,"So it is weekend! and I am reading a nice book, ""The PoincarÃ© conjecture"", written by a mathematician (Donal O'Shea, topologist). The book introduces step by step basic concepts of Topology, and talks about the mathematical advances since PoincarÃ© stated the conjecture up to the moment it was demonstrated, providing a glimpse of the solution that Perelman gave to the conjecture. It is not technical, narrative, a very light reading. My question is about the following: when the author defines a manifold, states that ""if a manifold has a boundary, its boundary will be one dimension lower"". Then I thought about fractals, for instance: can a fractal be a manifold? (I understand that manifold means the same as ""surface"" in this context) and then, if the answer is yes, then if it has boundaries, are the boundaries strictly one dimension lower? My beginner doubt is basically if the statement of the author would be still valid in that case. Maybe I am confusing the ""fractal dimension"" concept with the generic ""dimension"" concept. Thank you! UPDATE 2015/08/28 There is a very nice follow-up on this question, with an interesting explanation as well by another user here (link) .","['manifolds', 'fractals', 'general-topology']"
1340986,Fourier sine transform of $\frac{1}{2}+\frac{1-x^2}{4x}\ln\vert\frac{1+x}{1-x}\vert$,"Show that
$$
\int_0^{\infty} kF(k)\sin(ka)\,dk = \frac{\pi}{2}aG(a)
$$
where
$$
F(x) = \frac{1}{2}+\frac{1-x^2}{4x}\ln\vert\frac{1+x}{1-x}\vert
$$
and
$$
G(x) = \frac{\sin x-x\cos x}{x^4}
$$ EDIT: The source can be found here . One should notice that the function $F(x)$ is not continuous at $x=1$. EDIT2: The integral below may be of some help.
$$
\ln\vert\frac{a+x}{a-x}\vert = 2\int_0^{\infty}\frac{\sin at\sin xt}{t}\,dt 
$$ EDIT3: Here is a mathematica code of my question: F[x_] := (1/2 + (1 - x^2)/(4 x)*Log[Abs[(1 + x)/(1 - x)]]) x Sin[a*x]; Integrate[F[x], {x, 0, Infinity}, Assumptions -> a > 0] The result is: ([Pi] (-a Cos[a] + Sin[a]))/(2 a^3) EDIT4: By virtue of Bessel function $J_{\frac{1}{2}}(z)=\sqrt{\frac{2}{\pi z}}\sin(z)$, the integral identity turns to be
$$
\int_0^{\infty} k^{\frac{3}{2}}F(k)J_{\frac{1}{2}}(ka)\,dk = \sqrt{\frac{\pi}{2}a}G(a)
$$
In this occasion, some refs are useful: (1) Lin Q.G.: Inï¬nite integrals involving Bessel functions by an improved approach of contour integration and the residue theorem. (2) Lucas S.K.: Evaluating inï¬nite integrals involving Bessel functions of arbitrary order.","['bessel-functions', 'fourier-analysis', 'improper-integrals', 'integration']"
1340999,Quotient of the upper-half plane as a projective line,"In the discussion of the Belyi theorem here one pointed out that $\mathbb{H}^{*}/SL(2, \mathbb{Z})$ is isomorphic to the (complex) projective line $\mathbb{P}^1$, where $\mathbb{H}^{*}=\mathbb{H} \cup \mathbb{P^1(\mathbb{Q})}$. Could anyone give an explanation of this fact, please?","['modular-forms', 'group-theory']"
1341012,Part of Lomonosov's Invariant Subspace Theorem,"Let $X$ be a complex Banach space of infinite dimension, let $T\in\mathcal{B}(X)\backslash\{0\}$ be compact. Define $$\Gamma := \{S\in\mathcal{B}(X)\,|\,S\circ T=T\circ S\}$$and define, for each $y\in X$, $$\Gamma(y):=\{S(y)\,|\,S\in\Gamma\}$$ I am trying to prove that $\Gamma(y)\in Closed(X)$ for each $y\in X$. I have already proven that $\Gamma \in Closed(\mathcal{B}(X))$, which was easy, but I don't see how from that it follows that $\Gamma(y)$ is closed. This is part of theorem $\boxed{10.35}$ (""Lomonosolv's Invariant Subspace Theorem"") in Rudin's Functional Analysis book. What I have tried: I tried to take a convergent sequence in $\Gamma(y)$ and show it converges to a point necessarily within $\Gamma(y)$. That entails taking a sequence of points in $\Gamma$, $\{S_n\}_{n\in\mathbb{N}}$ such that the limit exits in $X$: $$\lim_{n\to\infty} S_n(y)$$Now if it would be possible to show that $\{S_n\}_{n\in\mathbb{N}}$ converges to some $S\in\Gamma$ then we would be finished. However, I'm not sure how to use the data to show that, because in order for $\{S_n\}_{n\in\mathbb{N}}$ to converge you need to know something about, let's say, $||S_{n_1}-S_{n_2}|| $ whereas you only know something about $||S_{n_1}(y)-S_{n_2}(y)||$ and you then only have $||S_{n_1}(y)-S_{n_2}(y)||\leq||S_{n_1}-S_{n_2}||||y|| $ by linearity. I tried to define a mapping $\Psi_y:\mathcal{B}(X)\to X$ by $S\mapsto S(y)$. Then $\Psi$ is linear and continuous. The goal would be to prove $\Psi_y$ is a closed mapping, but I am not sure how to do that.","['banach-algebras', 'banach-spaces', 'functional-analysis']"
1341014,"Another Evaluation of the Ramsey number $\mathcal{R}(3,3,3)$","The problem Show that $\mathcal{R}(3,3,3)=17$ The story behind the problem and some notation It was first proven by Greenwood and Gleason in 1955 in their paper Combinatorial relations and chromatic graphs . Later, in 1984 Sun and Cohen published an easy proof of the Greenwood-Gleason evaluation of the Ramsey number $\mathcal{R}(3,3,3)$ . I can understand this proof, but I don't like it, because in my opinion it lacks intuition. Instead, I found another proof of the above result in Problems in Combinatorics and Graph Theory book by Ioan Tomescu (page 324). Firstly, let me explain the notation, which I used above: Ramsey's Theorem for c colors states that: For every positive integer $c \geq 2$ and positive integers $n_{1},n_{2}, \cdots ,n_{c} \geq 2$ there exists a (minimal) positive integer $\mathcal{R}(n_{1},n_{2}, \cdots ,n_{c})$ with the following property: If we color the edges of a complete graph of $\mathcal{R}(n_{1},n_{2}, \cdots ,n_{c})$ vertices with colors $1,2, \cdots , c$ then for some $i \in \{1,2, \cdots c\}$ there exists a complete subgraph with $n_{i}$ vertices whose edges are $i$ -colored. So, to prove $\mathcal{R}(3,3,3)=17$ , we have to 3-color the edges of a $K_{16}$ avoiding monochromatic triangles. The three colored $K_{16}$ without monochromatic triangles that you get from Sun and Cohen's coloring is the following $\mathcal{R}(3,3,3)>16$ ""> My question Tomescu in his proof uses the following coloring: Let $P$ be a pentagon and $M=\{1,2,3,4,5\}$ the set of its vertices. Let $X$ be the set of vertices of the graph $K_{16}$ and $Y$ be the set of subsets of $M$ with even cardinality. Let $f$ be any bijection from $X$ to $Y$ . The edges of $K_{16}$ will be colored as follows: If $a,b \in X$ and $a \neq b$ color the edge joining $a$ and $b$ according to the following rule: with color $c_{1}$ if $f(a) \triangle f(b)$ is a side of $P$ with color $c_{2}$ if $f(a) \triangle f(b)$ is a diagonal of $P$ with color $c_{3}$ if $|f(a) \triangle f(b)|=4$ where $f(a) \triangle f(b)$ represents the symmetric difference between the vertex sets $f(a)$ and $f(b)$ , which must clearly be an even number of vertices of $P$ , and in the case of 2 vertices we treat it as an edge. I am having trouble understanding the argument that he uses in order to prove that there are no monochromatic triangles by contradiction. The argument goes like this: Suppose that there is a triangle with sides colored $c_{1}$ and having vertices $a,b,c$ . It can be seen that $f(a) \triangle f(b), f(a) \triangle f(c)$ and $f(b) \triangle f(c)$ are sides of the polygon $P$ . 
      But $$(f(a) \triangle f(b)) \triangle (f(b) \triangle f(c)) = f(a) \triangle f(c)$$ and thus $ f(a) \triangle f(c)$ cannot be a side of the polygon $P$ . In fact, if the sides $f(a) \triangle f(b)$ and $f(b) \triangle f(c)$ have a common vertex, then their symmetric difference is a diagonal of the pentagon $P$ and hence  the edge joining $a$ and $c$ is colored $c_{2}$ . If the sides have no common vertex, then their symmetric difference has cardinality 4 and thus the edge joining $a$ and $c$ is colored $c_{3}$ , which is a contradiction. An analogos argument can be used if it is supposed that the monochromatic triangle is colored $c_{2}$ or $c_{3}$ . Why $ f(a) \triangle f(c)$ cannot be a side of the polygon? Why is it true that if two sides have a common vertex then its symmetric difference is a diagonal? Why is it true that if they do not have a common vertex then its symmetric difference is of cardinality 4? I am thankful for any suggestions on the problem!","['graph-theory', 'ramsey-theory', 'combinatorics']"
1341021,Among $k$ consecutive numbers one has sum of digits divisible by $11$,"Find the least positive integer $k$ with the property that given any $k$ consecutive positive integers, there is at least one whose sum of digits is divisible by $11$. I can show for $k\leq 57$. Among any $29$ consecutive positive integers with the same hundreds' digit and higher digits, at least one has sum of digits divisible by $11$. This can be checked by casework. Since our consecutive positive integers may span two different hundreds' digits, we have $k\leq 29+28=57$. On the other hand, among the numbers $1,2,\ldots,28$ none has sum of digits divisible by $11$, so $k\geq 29$.",['combinatorics']
1341043,Theorem of Portmanteau: It suffices to show it for a base?,"I have a question to the Theorem of Portmenteau, see here. Two equivalent statements to $P_n\to P$ weakly, are (1) $\limsup_n P_n(C)\leq P(C)$ for all closed sets $C$. (2) $\liminf_n P_n(O)\geq P(O)$ for all open sets $O$. Now suppose that we know that the sets $A_i$ form a base. That is, each open set can be expressed as an union of sets $A_i$. Would it then suffice to show (2) for the sets $A_i$?","['probability-theory', 'weak-convergence', 'measure-theory']"
1341048,How is the area of a circle calculated using basic mathematics?,"Area of a circle is addition of circumference of layers of a onion. If n is radius of a onion then area is $$
A = 2 \pi \cdot 1 + 2 \pi \cdot 2 + 2\pi \cdot 3 + \ldots + 2  \pi \cdot n
$$
which $$
= 2 \pi \cdot \frac{n(n+1)}{2}
= \pi (n^2 + n)
$$ But the answer is wrong. Please tell me where am I wrong?","['circles', 'geometry', 'calculus', 'area']"
1341061,"The asymptotic equivalence of LR, Wald and score tests","Suppose that $Y_1, \ldots, Y_{n}$ are iid from a Bernoulli distribution with parameter $p$ and consider $H_0 : p = p_0\,.$ The test statistics are 
$$ T_W = \frac{n ({\widehat p} - p_0)^2}{{\widehat p} (1 - {\widehat p})}\,, \:\:\:\: T_S = \frac{n ({\widehat p} - p_0)^2}{p_0 (1 - p_0)} \,,$$
and $ T_{LR} = -2 [ X \log(p_0/{\widehat p}) + (n-X) \log[(1 - p_0)/(1 -\widehat p)] ], $
where $X = \sum_{i=1}^{n} Y_i\,.$ 
I want to Show that $T_W, T_S$ and $T_{LR}$ are asymptotically equivalent under $H_0$ by showing that their differences converge to $0$ in probability. I showed that $T_W $ is  asymptotically equivalent to $T_S$ as follows
We have 
\begin{align*}
T_W-T_S &=n ({\widehat p} - p_0)^2 [\frac{1}{{\widehat p} (1 - {\widehat p})}-  \frac{1}{p_0 (1 - p_0)}]\\
&= p_0 (1 - p_0) \left(  \frac{\sqrt{n} ({\widehat p} - p_0)}{\sqrt{p_0 (1 - p_0) }}\right)^{2}[\frac{1}{{\widehat p} (1 - {\widehat p})}-  \frac{1}{p_0 (1 - p_0)}]
\end{align*}
From the asymptotic normality of the MLE, we have that $$\left(  \frac{\sqrt{n} ({\widehat p} - p_0)}{\sqrt{p_0 (1 - p_0) }}\right)^{2} \overset{d}{\rightarrow} \mathcal{N}(0,1)^{2}=\chi^{2}(1),$$
and from the consistency of the MLE we have that 
$$  {\widehat p} \overset{p}{\rightarrow} p_0.  $$
From Slutskyâ€™s theorem and the continuous mapping theorem (CMT) we have
$$ [\frac{1}{{\widehat p} (1 - {\widehat p})}-  \frac{1}{p_0 (1 - p_0)}] \overset{p}{\rightarrow} 0.$$
This implies that
\begin{align*}
 T_W-T_S  & \overset{d}{\rightarrow} 0\\
 T_W-T_S  & \overset{p}{\rightarrow} 0.
\end{align*} But I did not succeed at showing the same conclusion for $T_W$ and $T_{LR}$. Can someone help?","['probability-theory', 'probability-distributions', 'statistical-inference', 'hypothesis-testing', 'statistics']"
1341063,principal curvature of the flat torus,"I am looking at the Hopf-fibration and I am looking at the preimage of the equator in $\mathbb{S}^2$. I think that I have proved that this is just the flat torus and now I want to calculate the principal curvatures of this torus. My general approach to the problem has been: I consider $\mathbb{R}^4$ as $\mathbb{C}^2$ and $\mathbb{S}^3$ to be ""the unit circle"" in this ""plane"", every point on the circle determines a line through the origion. And the lines through the origion intersects the sphere in a unique circle. Mapping $\mathbb{S^3}$ to the space of lines through the origion gives me an onto map to $\mathbb{C}\mathbb{P}^1$ which I diffeomorphically identify with $\mathbb{S}^2$. The preimage of any point $(z_1:z_2)$ in $\mathbb{S}^3$ is just the circle $\frac{z_1}{z_2}=z$. Hence the preimage of the equator is all circles satisfying $\frac{|z_1|}{|z_2|}=1$, i.e $|z_1|=|z_2|$, hence the preimage is a product of two circles, i.e a torus. Since my torus is just $S^1\times S^1$ in $\mathbb{C}\times \mathbb{C}$ it is equipped with the product metric, and hence in this case flat. I am now stuck, here is two ways I would like to go forward: Calculating the Weingarten map. 
Using the parametrization $(e^{i\theta },e^{i\psi })$, what is the normal direction inside of $\mathbb{S}^3$? I have also tried to look at the normal curvature of curves in $S^1\times S^1$ are these just ""circles wrapping around the torus"" the smaller ones curving more then the bigger? This way of thinking would give me principal curvature $1$ and something depending on where on the torus I am being $-1$ in ""the inner circle""?",['differential-geometry']
1341064,Is a continuous function $f : \mathbb{Q}\to\mathbb{Q}$ always bounded on a closed interval?,"Can a function $f : \mathbb{Q} \to \mathbb{Q}$ that is continuous on an interval $[a,b]$ not be bounded on $[a,b]$? I'm asking this because in Spivak's Calculus , the ""Boundedness Theorem"", which states that any real-valued function that is continuous on a closed interval is bounded on that interval, is proved using the properties of real numbers. However, I cannot think of a counterexample in which it fails for rationals.","['rational-numbers', 'real-analysis', 'general-topology']"
1341065,The value of $x$ for which function attains max value,"At what value of $x,\ x\in \mathbb{Z}$ will the function $\dfrac{x^2+3x+1}{x^2-3x+1}$ attain its maximum value . $\color{green}{a.)\ 3 }\\
b.)\ 4 \\
c.) -3 \\
d.)\ \text{none of these} \\ $ $\dfrac{x^2+3x+1}{x^2-3x+1}\\
=1+\dfrac{6x}{x^2-3x+1}\\
=1+\dfrac{6}{x-3+\frac{1}{x}}\\
$ here i thought to use $\text{AM-GM}$ inequality for the part $x+\dfrac{1}{x}$ and concluded that $x+\dfrac{1}{x}=2 \implies x=1$ But after inspecting some values i  came up with $$\begin{array}{|c|c|} \hline
x & k  \\ \hline
-4 & \dfrac{5}{29}  \\ \hline
-3 & \dfrac{1}{19}  \\ \hline
-2 & -\dfrac{1}{11}  \\ \hline
-1 & -\dfrac{1}{5}  \\ \hline
0 & 1 \\ \hline
1 & -5 \\ \hline
2 & -11 \\ \hline
\color{green}{3 }& \color{red}{19} \\ \hline
4 &\dfrac{29}{5}\\ \hline
\end{array}$$ I look for a short and simple way . also i don't want to use calculus. I have studied maths up to $12$th grade.","['algebra-precalculus', 'functions']"
1341076,Point set where each point has unity distance to all other points ($L_1$ metric),"I want to construct a point set where each point has the same (w.l.o.g., unit) distance to all other points in the $L_1$ metric. Example: The points $\left(\frac{1}{2},0\right)$, $\left(-\frac{1}{2},0\right)$, $\left(0,\frac{1}{2}\right)$ and $\left(0,-\frac{1}{2}\right)$ have unit distance between each other. Similarly, it is possible to embed six points into $\mathbb{R}^3$, eight points into  $\mathbb{R}^4$, etc.. Question : Is this the most efficient layout, or is it possible to e.g. embed eight ($=2^3$) points into $\mathbb{R}^3$, or 16 points into $\mathbb{R}^4$? Notes : The metric is fixed, I'm only free to move the points. (I could use another metric for the problem; however, for instance, in $L_2$ it isn't even possible to embed four points as required.) Perhaps related: Is there any object/metric within all points are at same distance to each other? Existance and uniqueness of solution for a point with fixed distances to three other points","['metric-spaces', 'geometry', 'normed-spaces']"
1341096,$ \cos ^2\left(x\right)+\cos ^2\left(2x\right)+\cos ^2\left(3x\right)=\frac{3}{2} $,"$$ \cos ^2\left(x\right)+\cos ^2\left(2x\right)+\cos ^2\left(3x\right)=\frac{3}{2} $$ How can I solve this one, I mean I get something like this:
$-3+\left(-1+2\cos ^2\left(x\right)\right)^22+2\left(-3\cos \left(x\right)+4\cos ^3\left(x\right)\right)^2+2\cos ^2\left(x\right)=0$ This equation seems rather hard to solve from here, any tips or other ways to come to an solution?",['trigonometry']
1341135,"How to translate set propositions involving power sets and cartesian products, into first-order logic statements?","As seen from an earlier question of mine one can translate between set algebra and logic, as long as they speak about elements (a named set A is the same as {x âˆ£ x âˆˆ A}). However I've stumbled upon propositions that involve cartesian products and power sets and I'm not sure how to translate those into logic statements. For instance: (A  Ã— B)    =   (B  Ã— A)    if and only if  A   =   B or if   A   =   â„˜(A)    then    â„˜(A)    =   âˆ… if   A   âŠ† â„˜(A)  then    â„˜(A)    =   âˆ… if A âˆˆ â„˜(A)  then    â„˜(A)    =   âˆ… and even a combination of the two: â„˜(A Ã—   B)  âŠ†       â„˜(A)    Ã—   â„˜(B) Note that ""Ã—"" is the cartesian product symbol, and â„˜ the power-set. Can someone provide any insight on this?","['logic-translation', 'first-order-logic', 'elementary-set-theory', 'predicate-logic', 'logic']"
1341160,"$\|f(x)-f(y)\|\ge c\|x-y\|$ for all $x,y\in U, c>0$-> continuously differentiable inverse function $g:f(U)\to U$","Let $U\subset\mathbb{R}^n$ open, $f:U\to \mathbb{R}^n$ continuously differentiable, $\|f(x)-f(y)\|\ge c\|x-y\|$ for all $x,y\in U, c>0$.
Why is $\det(Df(x))\neq 0$ for all $x\in U$ and $f\colon U\mapsto f(U)$ global invertible with inverse function g, wich is continuously differentiable ? First of all, here If $f: U \rightarrow \mathbb{R}^n$ differentiable such that $|f(x)-f(y)| \geq c |x-y|$ for all $x,y \in U$, then $\det \mathbf{J}_f(x) \neq 0$ is a solution for 1. Now 2.
My ideas: and from $\|f(x)-f(y)\|\ge c\|x-y\|$ for all $x$, $y\in U$, $c>0$ follows that f is injective. Because otherwise for $x\not=y$ such that $f(x)=f(y)$ it follows that $0=\|f(x)-f(y)\|\ge c\|x-y\|>0$ which is a contradiction. Clearly $f\colon U\to f(U)$ is surjective . And with the argument above $f$ onto $f(U)$ is bijective with inverse function $g$. But why is $g$ continuously differentiable ?",['derivatives']
1341175,"If $\frac{(bâˆ’c)}{a} + \frac{(a+c)}{b} + \frac{(aâˆ’b)}{c}=1$ and $a-b+c \neq 0 $, then prove that $\frac 1a = \frac 1b + \frac 1c$","The question given is If  $\dfrac{(bâˆ’c)}{a} + \dfrac{(a+c)}{b} + \dfrac{(aâˆ’b)}{c}=1$ and $a-b+c \neq 0 $ then prove that $\dfrac 1a = \dfrac 1b + \dfrac 1c$ I tried to take $abc$ on the right hand side after taking the LCM, but ended up with $b^2(c-a)+a^2(b+c)+c^2(a-b)=abc$. I could not simplify any further. Please provide only hints, not complete solution.","['arithmetic', 'least-common-multiple', 'contest-math', 'algebra-precalculus', 'recreational-mathematics']"
1341184,Why aren't there 21 players in this tournament?,"In a tournament each player played exactly one game against each of
  the other players. In each game the winner was awarded 1 point, the
  loser got 0 points, and each of the two players earned 1/2 point if
  the game was a tie. After the completion of the tournament, it was
  found that exactly half of the points earned by each player were
  earned against the ten players with the least number of points. (In
  particular, each of the ten lowest scoring players earned half of
  her/his points against the other nine of the ten). What was the total
  number of players in the tournament? Here is my approach: Let $n$ be the number of players. It is safe to assume that the player at first place  has won all of his games, after all the number of games the first place player has won can vary and yet the number of players will stay the same. Then he has $n-1$ points and thus $\frac{n-1}{2} = 10$, so $n=21$. Keep in mind that I am looking for the mistake in my reasoning not a solution to the problem itself.",['combinatorics']
1341198,Can we define $â„^A$ where A is uncountable?,"The question is pretty straightforward. How can we define the expression $â„^A$ when $A$ is an uncountable set? For example what is defined by forms such as $â„^â„$ or $â„^â„‚$? If $A$ is countable,then $A \sim â„•$ and thus $A=[a_n:n=1,2,...]$ for $a_n$ such that $a_n\neq a_m$ if$n\neq m$ and $â„^A$ is linearly isomorphic to $â„^â„•$ via $$â„^Aâˆf\rightarrow(f(a_n))_{n{\in \mathbb(N)}} \inâ„^â„•$$
where$f$ is an isomorphism. PS I suppose this is a topic more relevant to topology than real-analysis,but I am not sure,thus I tagged both.","['elementary-set-theory', 'real-analysis', 'general-topology']"
1341201,Is the cardinality of $\mathbb{Z^R}$=$\mathbb{R^Z}$?,"Previously in this question , we have found that $\mathbb{R^Z}$ is uncountable and its multiset of components, denoted by $$K = \{ (..., 0, 0, w, 0, 0, ... ) : w \in \mathbb{R} \}$$ where for each real number $x$ there's a sequence $(k_m)$ in $K$ with $k_0 = w$ and $k_j = 0$ for all $j \ne 0$ . OR $$A = \{ Y_j : j \in \mathbb{Z} \}$$ where $$Y_j = \{ (..., 0, x_j, 0, 0, ... ) : x_j \in \mathbb{R} \}$$ is also uncountable and a sub(multi)set of of $\mathbb{R^Z}$ ========================================================== Now I am wondering about the cardinality of $\mathbb{Z^R}$ and $\mathbb{R^Z}$ Using my half baked understanding of cardinal exponentiation and multiplication, (assuming the Axiom of Choice), learnt from here , and also some properties of cardinality here , I use the following formulae If 2 â‰¤ Îº and 1 â‰¤ Î¼ and at least one of them is infinite, then: $$\max (Îº, 2^Î¼) â‰¤ Îº^Î¼ â‰¤ \max (2^Îº, 2^Î¼)$$ If either Îº or Î¼ is infinite and both are non-zero, then $$\kappa\cdot\mu=\max\left\{\kappa,\mu\right\}$$ $$|\mathbb{R}|=2^{\aleph_0}>\aleph_0=|\mathbb{N}|=|\mathbb{Z}|$$ and get $$\max (|\mathbb{Z}|, |2^\mathbb{R}|) â‰¤ |\mathbb{Z^R}| â‰¤ \max (|2^\mathbb{Z}|, |2^\mathbb{R}|)$$ $$\max (|\mathbb{R}|, |2^\mathbb{Z}|) â‰¤ |\mathbb{R^Z}| â‰¤ \max (|2^\mathbb{R}|, |2^\mathbb{Z}|)$$ Simplifying using the formulae $$|2^\mathbb{R}| â‰¤ |\mathbb{Z^R}| â‰¤ |2^\mathbb{R}|$$ $$\max (|\mathbb{R}|, |2^\mathbb{Z}|) â‰¤ |\mathbb{R^Z}| â‰¤ |2^\mathbb{R}|$$ $\hspace{1mm}$ $$|\mathbb{Z^R}| = |2^\mathbb{R}|=2^{2^{\aleph_0}}$$ $$\max (2^{\aleph_0}, 2^{\aleph_0}) â‰¤ |\mathbb{R^Z}| â‰¤ 2^{2^{\aleph_0}}$$ $\hspace{1mm}$ $$|\mathbb{Z^R}| = |2^\mathbb{R}|=2^{2^{\aleph_0}}$$ $$2^{\aleph_0} â‰¤ |\mathbb{R^Z}| â‰¤ 2^{2^{\aleph_0}}$$ And finally $$|\mathbb{R}| < |\mathbb{R^Z}| â‰¤ |\mathbb{Z^R}|$$ But then what are the approaches I should use in order to seek for a bijective function (if it exists) that maps elements of $\mathbb{Z^R}$ to $\mathbb{Z^R}$ and vise versa, so that I can work out whether $|\mathbb{R^Z}| < |\mathbb{Z^R}|$ or $|\mathbb{R^Z}| = |\mathbb{Z^R}|$ ?","['elementary-set-theory', 'cardinals']"
1341221,Limit involving binomial coefficient: $\lim_{n\to\infty} \left(\frac n{n-1}\right)^2 \left(\frac12\right)^n \sum_{i=1}^n \binom ni \cdot \frac{i-1}i$,"I was trying to find the below limit. The sum can be written in a hypergeometric function but it doesn't seem to help me to find the limit. Any help will be appreciated. $$
\lim_{n \rightarrow \infty} \left. \left(  \frac{n}{n-1} \right)^2 \left(  \frac{1}{2} \right)^n   \sum_{i=1}^n {\binom{n}{i} \cdot \frac{i-1}{i}} \right.
$$ Thanks.","['summation', 'limits', 'hypergeometric-function', 'binomial-coefficients']"
1341222,Elementary number theory - prerequisites [duplicate],"This question already has answers here : Books on Number Theory for Layman (32 answers) Closed last year . Since summer comes with a lot of spare time, I've decided to select a mathematical subject I want to learn as much as possible about over the next three months. That being said, number theory really caught my eye, but I have no prior training in it. I've decided to conduct my studying effort in a library; I prefer real books to virtual ones, but as I'm not allowed to browse through the books on my own, I have to know beforehand what I'm looking for and this is where I'm kind of lost. I'm not really sure where to start. Basically I wanna know about the following: What are the prerequisites?
(I'm currently trained in Linear Algebra, Calculus, Complex Analysis - all on an undergraduate level ) Can you recommend some reading materials? Thank you.","['number-theory', 'soft-question', 'elementary-number-theory', 'reference-request']"
1341230,What is the difference between Nakano Postivity and Griffiths Positivity of Hermitian vector bundles?,"I am currently reading ""Complex Differential Geometry"" by FY Zheng on the curvature of Hermitian vector bundles. In section 7.5, he described a Hermitian vector bundle $(E,h)$ over a complex manifold $M$ to be positively curved or Griffiths positive if $$\sqrt{-1}\Theta_{u\bar u}(X,\bar X) >0 \Longleftrightarrow R_{X\bar X u \bar u} >0$$ for any nonzero $(1,0)$ tangent vector $X$ of $M$ and nonvanishing section $u$ of the vector bundle $E$. On the other hand, he described a stronger condition of positivity: He described a Hermitian vector bundle $(E,h)$ over a complex manifold $M$ to be Nakano positive if $\sqrt{-1}Q(\xi, \xi)>0$, where $\xi$ is a nowhere vanishing section of $E \otimes \overline{TM}$, and $Q$ is the Hermitian bilinear form defined on $E \otimes \overline{TM}$ by
\begin{equation}Q(u\otimes \bar X, v \otimes \bar Y)=R_{Y\bar X u \bar v} \; \; \; \; (*)
\end{equation} He then says that Nakano Positivity implies Griffiths Positivity since ""$R_{X\bar X u \bar u}$ is just the restriction of $Q$ along the diagonalizable element, i.e. elements of the form $u \otimes \bar X$."" My confusion is in $(*)$. If $\xi$ is a section of $E \otimes \overline{TM}$, then isn't $\xi$ of the form $\xi=u \otimes \bar X$? This would yield that
$$Q(\xi, \xi)=Q(u\otimes \bar X, u\otimes \bar X)=R_{X\bar X u \bar u}>0$$
which is the same definition as Griffiths Positivity. Am I getting my wires crossed with certain definitions?","['complex-geometry', 'algebraic-geometry', 'differential-geometry', 'kahler-manifolds']"
1341254,"About the integral $\int_{0}^{1}\frac{\log(x)\log^2(1+x)}{x}\,dx$","I came across the following Integral and have been completely stumped by it. $$\large\int_{0}^{1}\dfrac{\log(x)\log^2(1+x)}{x}dx$$ I'm extremely sorry, but the only thing I noticed was that the limits of the Integral were similar to the Beta function. I also got a hint that solving it would require the Polylogarithm, Gamma and the Riemann Zeta Functions.
$$$$Would it be possible to solve this without using Complex Methods (I haven't learnt them yet) unless absolutely necessary? Any help on this Integral would be greatly appreciated. Many, many thanks in advance! EDIT: From the comments given below byDavid H Sir, and Alex S Sir, the Integral becomes: $$\int_0^1 \dfrac{\ln^2(1+x)\ln(x)}{x}dx$$ Just an observation: This is strikingly similar to the Beta Function. Also, if we consider $$\int^1_0 (1+x)^ax^bdx$$ and differentiate twice with respect to $a$ and once with respect to $b$ and set $a=b=0$, we get the above Integral (except the $x$ in the denominator). I'm not sure, but I think taking series representations of the Integrals would be of help, especially since the closed form includes the Riemann Zeta and the Polylogarithm functions.","['calculus', 'improper-integrals', 'definite-integrals', 'integration', 'polylogarithm']"
1341312,What is the minimum degree of a polynomial for it to satisfy the following conditions?,"This is the first part of a problem in the high-school exit exam of this year, in Italy. The differentiable function $y=f(x)$ has, for $x\in[-3,3]$, the graph $\Gamma$ below: $\Gamma$ exhibits horizontal tangents at $x=-1,1,2$. The areas of the regions $A,B,C$ and $D$ are respectively $2,3,3$ and $1$. (Also, note that we are supposed to deduce $f(-2)=f(0)=f(2)=0$ from the graph) If $f(x)$ is a polynomial, what is its minimum degree? Let me explain the issue with this. In fact, the question in bold is a reformulation of mine, while the original was In case $f(x)$ were expressible with a polynomial, what could be its minimum degree? The use of ""could"" has been criticized because in fact it does not exclude incorrect answers such as $0$. Then again, it is argued that such a lexical choice was due to the high difficulty (for a high-school student) of an answer to the more precise question ""what is its minimum degree?"", therefore ""necessary, not sufficient, accessible and not trivial conditions have been provided."" (there are several articles on the subject, in Italian)
Nonetheless, there is an answer generally regarded as correct: $4$. Most students came up with that, and important websites provided it as well. Their reasoning is simple: since $f'(x)$ has $3$ zeros, its degree is at least $3$, and thus $f(x)$ is at least a quartic.
However, it is also relatively simple, solving a system with enough of the information we are given, that the assumption $f(x)=a_4x^4+a_3x^3+a_2x^2+a_1x+a_0$ yields null coefficients. I personally didn't go further, but according to some articles I would have stopped at degree $9$, thus the answer to the question in bold; though this polynomial ""in any case doesn't abide by $\Gamma$"". Here's my objection. It is clearly specified that $\Gamma$ is the plot of $f(x)$ in the considered interval, hence the minimum degree cannot be that of a polynomial which does not abide by it. The polynomial $P(x)$ must satisfy \begin{cases}
\int_{-3}^{-2}P(x)\,dx+2=\int_{-2}^0 P(x)\,dx-3=\int_0^2 P(x) \, dx + 3 = \int_2^3 P(x)\,dx+1=0 \\[6pt]
P(-2)=P(0)=P(2)=0 \\[6pt]
P'(-1)=P'(1)=P'(2)=0\\[6pt]
P''(x)=0 \ \text{twice in $[-3,3]$, at the same points where $\Gamma$ changes concavity}
\end{cases} Of course not knowing the exact coordinates of the inflection points is problematic, but in such an exam a strong resemblance would be enough. With these constraints, is there really no hope?","['polynomials', 'real-analysis', 'definite-integrals', 'derivatives']"
1341334,How do one rigorously prove that the electric potential energy of an conducting sphere with charge $Q$ is $\frac{Q^2}{8\pi\epsilon_0R}$,"How do one rigorously prove that the electric potential energy of an conducting sphere with charge $Q$ is $\frac{Q^2}{8\pi\epsilon_0R}$? Is integration the only way? Homogeneous charge distribution is assumed, I guess.","['electromagnetism', 'physics', 'integration']"
1341342,Cantor-Bernstein Proof,"Currently, I am studying Set Theory, and have come to the point of proving the Cantor-Bernstein Theorem (if $|A| \leq |B|$ and $|B| \leq |A|$, then $|A| = |B|$).  Now, I am studying from Jech and Hrbacek's ""Introduction to Set Theory,"" but my professor provided me with a proof of the theorem that is significantly different from the book.  I worked through it, and I think I get the gist of it, but things start unravelling at the end and I need help understanding it.  So, Statement:  If $\phi:A\rightarrow B$ and $\psi:B\rightarrow A$ are one-to-one functions, then $A$ is equipotent to $B$. Proof: For $a,a'\in A$, set $a\equiv a' \iff \exists\ k\in\mathbb{N}\ s.t. (\phi^{-1}\circ\psi^{-1})^k(a)=a'$.
Then clearly $\equiv$ is an equivalence relation (I have a hard time proving this, but this is beyond the point I suppose). Consider the set of equivalence classes $H$ of $\equiv$.  Then, any $E\in H$ is one of two types: i) $\forall\ a\in E, \exists\ a'\ s.t.\ a' = \phi^{-1}\circ\psi^{-1}(a)$ ii) $\exists\ \dot a\in E \ s.t.\ \dot a \notin\ any\ (\psi\circ\phi)$ In this case, $\dot a$ is at the top of the class (in the obvious order).  Such an $\dot a$ is of two types: 1) $\psi^{-1}(\dot a)$ exists but $\phi^{-1}\circ\psi^{-1}(\dot a)$ doesn't. 2) $\psi^{-1}(\dot a)$ doesn't exist. We then define $\eta: A\rightarrow B$ by: $\eta(a) = \phi(a)$ if $[a]$ is of type (i) or of type (ii)-2 and $\eta(a) = \psi^{-1}(a)$ if otherwise. Claim: $\eta$ is one-to-one:  Consider $\eta(a)=\eta(a')$.  Then clearly $[a]=[a']$.  Hence, if $[a]$ is of type (ii)-1, then $\eta(a) = \psi^{-1}(a) = \psi^{-1}(a') = \eta(a')$, and since $\psi^{-1}$ is one-to-one, $a=a'$.  If $[a]$ is of type (i) or (ii)-2, then $\eta(a) = \phi(a) = \phi(a') = \eta(a')$, and since $\phi$ is one-to-one, $a=a'$. Claim: $\eta$ is onto:  Let $b\in B$ and consider $\psi(b)=a$.  If $[a]$ is of type (i) or (ii)-2, then $\phi^{-1}(b)$ exists and $\eta(\phi^{-1}(b))=b$.  If $[a]$ is of type (ii)-1, then $\eta(a)=b$. Therefore, there exists a bijection between $A$ and $B$ so that they are equipotent. QED Really, defining our $\equiv$ relation is straightforward and makes since in pictures.  But when we start getting into the different types I get a little shaky.  Type (i) is just saying that $(\phi^{-1}\circ\psi^{-1})$ gets mapped to something for any $a$ within the equivalence class.  Is type (ii) just saying the opposite?  That is, there is some $a$ within the equivalence class that $(\phi^{-1}\circ\psi^{-1})$ can't be mapped from?  The changing of the wording throws me off, and I'm not sure the significance of it. Now, if (ii) is true, then it has to be one of the other two types trivially, correct?  For either (1) or (2), $(\phi^{-1}\circ\psi^{-1})(\dot a)$ can't exist simply because it fell into type (ii).  At this point, are we just saying $\phi^{-1}(\dot a$ either works or doesn't? I suppose the big problem here is that I'm not understanding things intuitively.  He drew a picture which looks like a function mapping some $a$ between $A$ and $B$ in a cascading way, but I don't know what to make of the picture other than that fact that we can keep reapplying out composite or one of our original functions to move around between the sets. If anyone can shed any light on this proof that may make it easier for me to understand, I'd appreciate it.  And I tried my best to eliminate any errors in it, but if something seems wrong, there's a good chance it is, so let me know.",['elementary-set-theory']
1341358,Continuity of $f^{(n-1)}$ in Taylor's Theorem with Mean-value remainder,"I refer to Rudin's proof of Taylor's Theorem with the Mean-value form of the remainder. I'm not sure if I'm understanding the proof correctly. Why must $f^{(n-1)}$ be continuous on $[a,b]$ ? I believe continuity at the endpoints is only used in the application of the mean value theorem for $g(\beta)$ and $g(\alpha), g'(\alpha), \cdots, g^{(n-1)}(\alpha)$ . Also, I don't get the point of $a$ and $b$ . Thus, is it ok to restate Taylor's theorem as follows: Suppose $f : D \to \mathbb{R}$ is continuous on $[\alpha, \beta] \subseteq D$ , $n$ is a positive integer, $f^{(n-1)}$ is continuous on $[\alpha, \beta)$ , $f^{(n)}(t)$ exists for every $t \in (\alpha, \beta)$ . Then there exists a point $x \in (\alpha, \beta)$ such that $$f(\beta) = \sum_{k=0}^{n-1}\frac{f^{(k)}(\alpha)}{k!}(\beta-\alpha)^k + \frac{f^{(n)}(x)}{n!}(\beta-\alpha)^k.$$ I checked the statement of the theorem on Wikipedia and it also has the condition of continuity of $f^{(n-1)}$ on the closed interval between $\alpha$ and $\beta$ . So I thought I might be missing something. Thanks!","['taylor-expansion', 'calculus', 'continuity', 'real-analysis', 'derivatives']"
1341385,Why memorize trig identities?,"I want to be a mathematician or computer scientist. I'm going to be a junior in high school, and I skipped precalc/trig to go straight to AP Calc since I've studied a lot of analysis and stuff on my own. My dad wants me to memorize about 30 trig identities (though some of them are very similar) since I'm missing trig. I've gone through and proved all of them, but memorizing them seems like a waste of effort. My dad is a physicist, so he is good at math, but I think he may be wrong here. Can't one just use deMoivre's theorem to get around memorizing the identities?","['self-learning', 'soft-question', 'algebra-precalculus', 'trigonometry']"
1341394,Does $\Bbb R-\Bbb Q$ have a well ordered subset of type $\omega\cdot\omega$,"Does $\Bbb R- \Bbb Q$ have a well ordered subset of type $\omega\cdot\omega$? I thought of taking the subset to be A={$n\cdot \sqrt{m}:n\in\Bbb N,m\in P$} where P is the set of all prime numbers, with the well ordering -
 $\sqrt{2}<\sqrt{3}<\sqrt{5}<\sqrt{7}<...<2\cdot\sqrt{2}<2\cdot\sqrt{3}<2\cdot\sqrt{5}<...<3\cdot\sqrt{2}<3\cdot\sqrt{3}<...<m\cdot\sqrt{2}<m\cdot\sqrt{3}<m\cdot\sqrt{5}<...$ A is indeed a subset of  $\Bbb R- \Bbb Q$ and the well ordering is of type $\omega\cdot\omega$. Am I correct? And if I have to use the regular order of numbers, does there still exist a subset with such an ordering type?",['elementary-set-theory']
1341400,Finding real money on a strange weighing device,"You have 50 coins which each weigh either 20 grams or 10 grams. Each is labelled from 0 to 49 so you can tell the coins apart.  You have one weighing device as well. At the first turn you can put as many coins as you like on the weighing device and it will tell you exactly how much they weigh. However, there is something strange about the weighing device.  If you put coins $x_1, x_2, ..., x_j$ on the device the first time, then you have to put coins $(x_1+1) \bmod 50, (x_2+1) \bmod 50, ..., (x_j+1) \bmod 50$ on the scale the next time, and coins  $(x_1+2) \bmod 50, (x_2+2) \bmod 50, ..., (x_j+2) \bmod 50$ the next time and so on. In other words, all the weighings are defined by the choice of coins you choose to weigh the first time. Under this rule, what is the smallest number of weighings that will always tell you
  exactly which coins weigh 10 grams and which weigh 20? Clearly you could just put one coin on the device in the first turn and then it would take exactly $50$ weighings to solve the problem. Here is an example when you have only $4$ coins that takes only $3$ weighings.  First put coins $1$,$2$ and $3$ on the scale. For the next weighing you will have coins $0$, $2$ and $3$. For the last weighing you will have coins $0$, $1$ and $3$ and you will then know exactly which coins are real and which are fake. Here is another example when you have $9$ coins that takes only $6$ weighings. First put coins $2,5,7,8$ on the scale (indexing from $0$ again). Answers so far (smaller is better) 38 by san 35 by Tad 31 by Tad 26 by joriki 25 by joriki (A very impressive record!)","['puzzle', 'combinatorics']"
1341405,On the definition of degree of a hypersurface,"Let $f \in \mathbb{C}[x_1, ..., x_n]$ be a homogeneous polynomial of degree $d$. I was trying to understand the definition of degree of hypersurfaces. It says on Wikipedia https://en.wikipedia.org/wiki/Degree_of_an_algebraic_variety that ""The degree of a hypersurface F = 0 is the same as the total degree of the homogeneous polynomial F defining it (granted, in case F has repeated factors, that intersection theory is used to count intersections with multiplicity, as in BÃ©zout's theorem)."" I was a bit confused with this. So is the degree of a hypersurface $f = 0$ always the total degree of $f$ or is it different when $f$ has a repeated factor? Thank you!",['algebraic-geometry']
1341418,Long polynomial expansion with 34 roots,"This is a very tricky problem, I just need a few hints. I think the $(-x^{17})$ is also there for a specific trick. In the end if it is $ax^{17}$, I see that $a = 17 - 1 + 1 = 17$. Also, another possible approach is: $$(1 + x + \cdots + x^{17})^2 = x^{17}$$ $$1 + x + \cdots + x^{17} = x^{17/2}$$ But that doesn't do much. Only hints please! UPDATE: $$P(x)=0\implies x\ne 1.$$ By the geometric series formula this changes to: $$\left(\sum_{n=0}^{17}  x^n \right)^2 = x^{17} \text{ where } |x| < 1.$$ $$ \left( \frac{1 - x^{18}}{1-x}  \right)^2 = x^{17}.$$ $$(1 - x^{18})^2 = (1-x)^2(x^{17}) = x^{19} - 2x^{18} + x^{17}.$$ $$x^{36} - 2x^{18} + 1 = x^{19} - 2x^{18} + x^{17}.$$ $$x^{36} - x^{19} - x^{17} + 1 = 0.$$ $$x^{19}(x^{17} - 1) - (x^{17} - 1) = 0.$$ $$(x^{19} - 1)(x^{17} - 1) = 0.$$ With zero prod. property, we have to use roots of unity. $$x^{19} = 1 = e^{2\pi i*k}.$$ $$1\ne x = e^{2\pi i \cdot k/19}.$$ $$1\ne x = e^{2\pi i \cdot k/17} \space \text{for the other case}.$$ the smallest root obviously is $a_1 = 1/19, a_2 = 1/17, a_3 = 2/19, a_4 = 2/17, a_5 = 3/19$. $$\sum a_k = \frac{6}{19} + \frac{3}{17} = \frac{102 + 57}{323} = \frac{159}{323} = \frac{m}{n}$$ $m + n = 482$.","['complex-numbers', 'contest-math', 'algebra-precalculus', 'sequences-and-series', 'complex-analysis']"
1341419,"Inverse Laplace transform of $\operatorname{arccot}(s)$, $\arctan(s)$",How would one find inverse Laplace transforms of  $\operatorname{arccot}(s)$ or of  $\arctan(s)$  without knowing in advance that this is related to  $\dfrac{\sin x}{x}$?,"['inverse', 'calculus', 'laplace-transform', 'ordinary-differential-equations']"
1341438,A problem on order of a Group. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $G$ be a group of order $8$ and $x$ be an element of $G$ of order $4$. Show that $x^2 \in Z(G)$, the center of $G$. How this result can be proved?",['group-theory']
1341440,Borel-Cantelli lemma: non-negative iid random variables,"I came across a claim in a paper on branching processes which says that the following is an immediate consequence of the B-C lemmas: Let $X, X_1, X_2, \ldots$ be nonnegative iid random variables. Then $\limsup_{n \to \infty} X_n/n = 0$ if $EX<\infty$, and $\limsup_{n \to \infty} X_n/n = \infty$ if $EX=\infty$. So to apply the BC lemmas to these, I want to essentially show that
$$(1) \; \textrm{If } EX<\infty, \textrm{ then } P(\limsup \{X_n/n > \epsilon\}) = 0 \quad \forall \epsilon>0$$
$$(2) \; \textrm{If } EX=\infty, \textrm{ then } P(\limsup \{X_n/n > \delta\}) = 1 \quad \forall \delta>0$$ But I keep getting stuck. For example if I want to apply the first BC lemma to (1), then using Markov's inequality only gives $P(X_n > n\epsilon) < EX/n\epsilon$, which isn't summable. Am I missing something right under my nose?","['probability', 'real-analysis']"
1341450,Proving that $x^m+x^{-m}$ is a polynomial in $x+x^{-1}$ of degree $m$.,"I need to prove, that $x^m+x^{-m}$ is a polynomial in $x+x^{-1}$ of degree $m$ . Prove that $$x^m+x^{-m}=P_m (x+x^{-1} )=a_m (x+x^{-1} )^m+a_{m-1} (x+x^{-1} )^{m-1}+\cdots+a_1 (x+x^{-1} )+a_0$$ on induction in $m$ . $m=1$ ; $m=k$ ; $âŠn=k+1$ . Than $$x^{k+1}+x^{-k-1}=(x+x^{-1} )^{k+1} + (x+x^{-1} )^{k}+ (x+x^{-1} )^{k-1}+\cdots+(x+x^{-1} ).$$ I stuck on step 3. How to prove this expression?","['polynomials', 'induction', 'algebra-precalculus']"
1341456,Property of complex borel measures with absolutely convergent Fourier series (Wiener algebra),"Let $\mu$ be a complex Borel measure on the circle $\mathbb{R}/\mathbb{Z}$ with
$$
\sum_{n \in \mathbb{Z}} \lvert\hat{\mu}(n)\rvert < \infty.
$$
How does it follow that $d\mu(x) = f(x) dx$ for $f$ continuous on the circle? I suppose it is due to the fact that the hypothesis is equivalent to $\mu \ast D_n$ being continuous and converging uniformly, where $D_n$ the the Dirichlet kernel. But how do I know that $\mu \ast D_n$ relates to $\mu$ in any way with no convergence results? This is the start of an exercise (1.2) from the beginning of Classical and Multilinear Harmonic Analysis Vol 1. by Muscalu and Schlag. More generally, I am somewhat struggling with the use of complex Borel measures in statements where I am accustomed to seeing functions that are $L^p$ with respect to some positive measure. I understand that they are related via Radon-Nikodyn, but I struggle with how to think about certain statements: in particular, the convolution of a continuous function and a complex Borel measure, among others. Any advice/reading recommendations on getting more familiar with the heavy use of these measures and their interaction with functions? Thanks.","['fourier-analysis', 'measure-theory']"
1341468,No Adjacency Combinatorics Problem via Generating Function,"I would like to find the generating function solution for the following combinatorics/probability problem. I have a combinatorial solution and the generating function deduced thereof. But I can not fathom the direct interpretation of it. I would like to reverse the current solving process and directly deduce the following or some other generating function, then get the relevant coefficient as the solution. In a stack of $W$ white cards, $G$ green cards and $R$ red cards, what is the number of arrangement for no green card is next to a red card? One solution is to view the $W$ white cards as dividers and leaving $W+1$ slots in between them together with both ends. For each $r\in \{1,2,\dots,R\}$ and $g\in\{1,2,\dots, G\}$, designate non-overlappingly $r$ slots for inserting the red cards and $g$ slots for the green cards. There are ${W+1\choose r,g}$ combinations. For each of these combinations, we insert $R$ red cards into the previously designated $r$ red slots, and there are ${R-1\choose r-1}$ ways of insertion. Do the same for the $g$ green cards and there are ${G-1\choose g-1}$ ways of insertion. Multiplying them and summing over $r$ and $g$, we arrive at the desired total number of arrangements: $$\sum_{r=1}^R\sum_{g=1}^G{W+1\choose r,g}{R-1\choose R-r}{G-1\choose G-g}.$$ But this is the coefficient of $x^Ry^G$ in $(1+x+y)^{W+1}(1+x)^{R-1}(1+y)^{G-1}$. Now how do I deduce this generating function directly from the problem?","['probability', 'generating-functions', 'combinatorics']"
1341471,counting function of system of equations and Circle method,"I came up with the follwing question while looking on Davenport's book: Analytical Methods for Diophantine equations and Inequalities. When introducing the Circle method gives an example on how to apply this in the case of Waring's problem. More precisely, starting with the sum of exponentials $$ T(\alpha) = \sum_{x=1}^P e(\alpha x^k)$$ where $e( \cdot)= e^{2 \pi i (\cdot) }$ he says's that using orthogonal relation of the exponentials we can represent the number of solution's of Waring's problem, i.e. $$ r(N)= \{ 1 \leq x_i \leq P, \hspace{0.1in} i=1,2,\cdots, s \hspace{0.1in}| x_1^k +x_2^k + \cdots + x_s^k = N \} $$ as an integral, namely we get $$ r(N) = \int_0^1 T(\alpha)^s e(-\alpha N) d \alpha $$. I proved the above formula, and my question is how one can generalize this ""method"" in order to prove the similar problem : Let $f_1, \cdots, f_r \in \mathbb Z [x_1,\cdots,x_s]$, be homogeneous
  polynomials of degree $d$, and consider the counting function $$
 r(n,P) = \# \{ |x_i| \leq P \hspace{0.1in} | f_i (x_1, \cdots,x_s)=
 n_i , \hspace{0.1in} i=1,\cdots,r \}$$ where $n=(n_1,\cdots, n_r) \in
 \mathbb N_{\geq 0}^r$ How can we write the counting function $ r(n,P)$ as an integral ? Thank you in advance. P.S. If the title is not the best one, please feel free to change it, so it will became more clear my question.","['number-theory', 'analytic-number-theory']"
1341495,Exponential of powers of the derivative operator,"A translation operator The Taylor series of a function $f$ is $$f(x)=\sum_{n=0}^\infty\frac{(\partial_x^nf)(a)}{n!}(x-a)^n$$ where $\partial_x$ is the derivative operator. Expanding about $x+b$: $$f(x+b)=\sum_{n=0}^\infty\frac{(\partial_x^nf)(a)}{n!}(x+b-a)^n$$ Letting $a=x$: $$f(x+b)=\sum_{n=0}^\infty\frac{(\partial_x^nf)(x)}{n!}b^n=\sum_{n=0}^\infty\frac{((b\partial_x)^nf)(x)}{n!}$$ By definition $$e^{b\partial_x}=\sum_{n=0}^\infty\frac{(b\partial_x)^n}{n!}$$ Hence $$f(x+b)=(e^{b\partial_x}f)(x)$$ Hence $e^{\partial_x}=T$ where $T$ is the translation operator and $(Tf)(x)=f(x+1)$. A scaling operator We can also find a closed form for a scaling operator $S$ where $(Sf)(x)=f(ax)$. $$f(xa)=f(e^{\log{xa}})=f(e^{\log x+\log a})=f(e^{y+\log a})$$ where $y=\log x$. Letting $g(z)=f(e^z)$: $$f(xa)=g(y+\log a)$$ By our first theorem, $g(y+b)=(e^{b\partial_y}g)(y)$. Letting $b=\log a$: $$f(xa)=(e^{(\log a)\partial_y}g)(y)=(a^{\partial_y}g)(y)=(a^{\partial_{\log x}}f)(e^y)$$ Since $$\frac{\partial}{\partial \log x}=\frac{\partial x}{\partial \log x}\frac{\partial}{\partial x}=x\frac{\partial}{\partial x}$$ Then $$f(xa)=(a^{x\partial_x}f)(e^{\log x})=(a^{x\partial_x}f)(x)$$ Therefore $S=a^{x\partial_x}$ defines our scaling operator. A general operator Suppose we want an operator $G$ such that $(Gf)(x)=f(g(x))$. Consider: $$(e^{\partial_{h(x)}}f)(x)=(e^{\partial_y}f)(x)=(e^{\partial_y}f)(h^{-1}(h(x)))=(e^{\partial_y}f)(h^{-1}(y))$$ where $y=h(x)$. Letting $j=f\circ h^{-1}$ yields: $$(e^{\partial_{h(x)}}f)(x)=(e^{\partial_y}j)(y)=j(y+1)=f(h^{-1}(y+1))=f(h^{-1}(h(x)+1))$$ Hence solving the functional equation $$h^{-1}(h(x)+1)=g(x)$$ for $h(x)$ allows us to define our general operator $G=e^{\partial_{h(x)}}$. For example, letting $g(x)=xa$, the function $h(x)=\frac{\log x}{\log a}$ is a solution: $$h^{-1}(y)=a^y$$
$$h^{-1}(h(x)+1)=a^{h(x)+1}=a^{\frac{\log x}{\log a}+1}=a^{\frac{\log x}{\log a}}a=e^{\log x}a=xa$$ Hence the corresponding operator takes the form $$e^{\partial_{h(x)}}=e^{\partial_{\frac{\log x}{\log a}}}=e^{\log a\partial_{\log x}}=a^{x\partial_x}$$ This is the scaling operator we derived before. The case $e^{\partial_{h(x)}}=e^{x^n\partial_x}$ or equivalently $h(x)=\frac{x^{1-n}}{1-n}$ corresponds to the basis for the Witt algebra . The question My question is as follows: Can a similar procedure be used to find $e^{{\partial_x}^2}$, or $e^{{\partial_{h(x)}}^n}$ in general? Note that the commutator of $x$ and $\partial_x$ is nonzero and given by: $$[\partial_x,x]=\partial_xx-x\partial_x=1$$ Furthermore, given the product rule $Dab=(Da)b+aDb$, it seems to be the case that $$(x\partial_x)^2=x\partial_x+x^2\partial_x^2$$
$$(x\partial_x)^3=x\partial_x+3x^2\partial_x^2+x^3\partial_x^3$$
$$(x\partial_x)^4=x\partial_x+7x^2\partial_x^2+6x^3\partial_x^3+x^4\partial_x^4$$ and in general $$(x\partial_x)^n=\sum_{k=1}^n \genfrac{\lbrace}{\rbrace}{0pt}{}{n}{k} x^k\partial_x^k$$ where $\genfrac{\lbrace}{\rbrace}{0pt}{}{a}{b}$ are the Stirling numbers of the second kind . I have a strong suspicion the answer might have to do with properties of the Fourier and Laplace transforms, as seen here and here .","['taylor-expansion', 'partial-derivative', 'exponential-function', 'analysis', 'lie-algebras']"
1341496,"Is the supremum norm the only $ C^{*} $-norm on $ {C_{c}}(X) $, equipped with the usual pointwise operations?","Let $ X $ be a locally compact Hausdorff space. Then $ {C_{c}}(X) $ is a commutative $ * $-algebra with respect to addition, multiplication, scalar multiplication and conjugation (all pointwise operations). Question. If $ \| \cdot \|: {C_{c}}(X) \to \Bbb{R}_{\geq 0} $ is a (not-necessarily-complete) $ C^{*} $-norm on this $ * $-algebra, then is it true that $ \| \cdot \| $ is actually the supremum norm on $ {C_{c}}(X) $? If so, then $ {C_{0}}(X) $ is the only $ C^{*} $-completion of this $ * $-algebra. This question seemed trivial at first sight, but after a while, I realized that it was not at all. Thanks for your help!","['c-star-algebras', 'operator-algebras', 'functional-analysis', 'normed-spaces']"
1341498,Example verification: $E$ and $E'$ might not have the same limit points,"Let $E'$ be the set of all limit points of a set $E$ . Do $E$ and $E'$ always have the same limit points? Proof: $E''\subset E'$ because $E'$ is closed. But inclusion $E'\subset E''$ is false. We can take $\mathbb{R}^1$ with metric $\rho(x,y)=|x-y|$ and set $E=\{1/n: n\in \mathbb{N}\}$ . Then $E'=\{0\}$ but $E''=\varnothing$ . Is my example true?","['examples-counterexamples', 'general-topology']"
1341505,Prove that $E[U(X)] Â¥ge E[U(Z)]$,"Let U: $Â¥mathbb R$ -> $Â¥mathbb R$ be a concave function, let X be a random variable with a finite expected value, and let Y be a random variable that is independent of X and has an expected value 0. Define Z=X+Y. Prove that $E[U(X)] Â¥ge E[U(Z)]$ I know that $E(X)=E(Z)$, and by Jensen's inequality $U[E(X)] Â¥ge E[U(X)]$ but it gives me nothing so far. Please help. Thanks a lot.","['economics', 'probability', 'statistics', 'statistical-inference']"
1341534,Isomorphic or equal?,"Let $\sim_n$ be the usual equivalence relation of congruence modulo $n$ in $\mathbb{Z}$, i.e., for $a,b\in\mathbb{Z}$, $a\sim_nb\Leftrightarrow a-b=k\cdot n$ for some $k\in\mathbb{Z}$. For $n=0$ the element in the equivalence class of, say, $a\in\mathbb{Z}$ is just $a$ itself . So to every element of $\mathbb{Z}/\sim_0$ corresponds one, and only one, element of $\mathbb{Z}$. My question is: What is mathematically more correct, to say that the two sets $\mathbb{Z}/\sim_0$ and $\mathbb{Z}$ are equal or to say that those rings are isomorphic ?","['ring-theory', 'elementary-set-theory', 'terminology', 'equivalence-relations', 'abstract-algebra']"
1341535,What is the proper use of Leibniz notation for one-sided derivatives?,"The only notation I've seen has been restricted to either Lagrange's prime notation or Euler's $D$. Here are some of the variants:
$$f'(a^+):=\lim_{x\to a^+}\frac{f(x)-f(a)}{x-a}$$
$$D_+f(x):=\lim_{h\to0^+}\frac{f(x+h)-f(x)}{h}$$
Is there a standard notation for the right- and left-handed derivatives using $\dfrac{df}{dx}$?","['notation', 'derivatives']"
1341537,Cardinality of all linear transformations from $\Bbb R^3$ to $\Bbb R^2$,"I tried to calculate the cardinality of all linear transformations from $\Bbb R ^3$ to $\Bbb R^2$. This is my answer-  I would like to know how to formalize it better. A transformation is defined in a unique way on the basis elements. Let $B_1=\{\bar v_1, \bar v_2,\bar v_3\}$ be a basis of $\Bbb R ^3$ and $B_2=\{\bar u_1, \bar u_2\}$ be a basis of $\Bbb R ^2$. Any element in the codomain of the transformation is a linear combination of $\bar u_1, \bar u_2$. The number of different linear combinations of two elements is $\aleph^2$,
 so in the construction of a linear transformation $T:\Bbb R^3 \rightarrow \Bbb R^2$ , every $v_i \space (i=1,2,3)$ can be matched with $\aleph^2$ different elements of $\Bbb R^2$. Since there are 3 elements in $B_1$, there are $(\aleph^2)^3=\aleph^6=\aleph$ possible ways to construct $T$. Therefore, the cardinality of all linear transformations  from $\Bbb R^3$ to $\Bbb R^2$ is $\aleph$. What do you think? Is the reasoning right? Is there another way to think about it?",['elementary-set-theory']
1341548,Concluding three statements regarding $3$ real numbers.,"$\{a,b,c\}\in \mathbb{R},\ a<b<c,\ a+b+c=6 ,\ ab+bc+ac=9$ Conclusion $I.)\ 1<b<3$ Conclusion $II.)\ 2<a<3$ Conclusion $III.)\ 0<c<1$ Options By the given statements $\color{green}{a.)\  \text{Only conclusion $I$ can be derived}}$ . $b.)\ $ Only conclusion $II$ can be derived. $c.)\ $ Only conclusion $III$ can be derived. $d.)\ $ Conclusions $I,\ II,\ III$ can be derived. $e.)\ $ None of the three conclusions can be derived. $\quad\\~\\$ I tried $(a+b+c)^2=36 \implies a^2+b^2+c^2=18$ and found that $(a,b,c)\rightarrow \{(-1,1,4),(-3,0,3)\}$ satisfies the two conditions $a^2+b^2+c^2,\ a<b<c $ but not this one $a+b+c=6$ I thought a lot but can't find any suitable pairs. I look for a simple and short way. I have studied maths upto $12$ th grade.","['systems-of-equations', 'symmetric-polynomials', 'algebra-precalculus', 'inequality']"
1341551,Prove $e^x$ limit definition from limit definition of $e$.,"Is there an elementary way of proving
$$e^x=\lim_{n\to\infty}\left(1+\frac xn\right)^n,$$
given
$$e=\lim_{n\to\infty}\left(1+\frac1n\right)^n,$$
without using L""Hopital's rule, Binomial Theorem, derivatives, or power series? In other words, given the above restrictions, we want to show
$$\left(\lim_{n\to\infty}\left(1+\frac1n\right)^n\right)^x=\lim_{n\to\infty}\left(1+\frac xn\right)^n.$$","['limits-without-lhopital', 'algebra-precalculus', 'exponential-function']"
1341555,How do I find the Laplace Transform of $ \delta(t-2\pi)\cos(t) $?,"How do I find the Laplace Transform of $$ \delta(t-2\pi)\cos(t) $$ where $\delta(t) $ is the Dirac Delta Function. I know that it boils down to the following integral $$ \int_{0}^\infty e^{-st}\delta(t-2\pi)\cos(t)dt $$ and I know that the answer is simply $$ e^{-2\pi s} $$ and I know how to integrate just the Dirac Delta Function. I don't know how to integrate it as the product of another function of the same variable. It doesn't explain anywhere in the chapter in my text, either, so I'm a bit confused. I assume I'll have to integrate by parts, or something, but I'm not to sure what to do with that Delta Function in there. Any help would be appreciated. Thanks!","['calculus', 'laplace-transform', 'integration', 'dirac-delta', 'ordinary-differential-equations']"
1341558,Are differentiable and strictly decreasing functions always concave?,"If a demand function is continuously differentiable  and strictly decreasing in price, does that mean it will be always concave?","['convex-analysis', 'functions']"
1341568,Understanding an example of a prime-like non-finite additive basis,"In this answer on MO, the user Gene S. Kopp gives an example of a relatively ""big"" set $A\subset \mathbb{N}$ with relatively ""small"" gaps that fails to be an asymptotic finite basis. I'm having a problem in trying to understand one of the steps. Firstly, let $A_n$ for $n\geqslant 1$ and $A$ be as in the link. Given that $|A_n| = \frac{2^{2^n}- 2\cdot2^{2^{n-1}}}{2^n} > \frac{2^{2^n}-2^{2^{n-1}}}{2^{n-1}}$, we will have, in fact, that: $$A(x) \geqslant \sum_{k\leqslant \log_2\log_2{\lfloor x\rfloor}} |A_k| > \sum_{k\leqslant \log_2\log_2{\lfloor x\rfloor}} \frac{2^{2^k}- 2^{2^{k-1}}}{2^{k-1}} \geqslant \frac{\lfloor x\rfloor-2}{\log_2{\lfloor x\rfloor}}\gg \frac{x}{\log{x}}.$$ I'll skip show that the gaps are in fact $\ll \sqrt{x}~$ and that it contains infinitely many non-multiples of $m$ for every $m>1$ (I haven't tried to do this, but I think it's reasonable...). Now the claim is: Claim [G.S. Kopp]. $2^{2^n}$ cannot be written as a sum of fewer than $nâˆ’\log_2{n}$ elements of $A$. So, to prove this, we suppose the converse: take $a_1,\ldots,a_k \in A$ with $a_1\leqslant\cdots\leqslant a_k$ such that $2^{2^n} = a_1+\ldots +a_k$ and suppose $k< n-\log_2{n}$. Now clearly $a_k\in A_n$, otherwise we would have $a_1+\ldots +a_k < k\cdot 2^{2^{n-1}} < 2^{2^n}$. From $a_k \leqslant 2^{2^n}-2^{2^{n-1}}-2^n+1$ follows $2^{2^n}-a_k \geqslant 2^{2^{n-1}}+2^n-1>2^{2^{n-1}}$, and one may deduce by a similar argument that $a_{k-1}\in A_n\cup A_{n-1}$. However, I wasn't able to show in the same way that $a_{k-2}\in A_n\cup A_{n-1}\cup A_{n-2}$, and I have no clue how to do this is general. So, my actual question is: My actual question: How do I prove that $\displaystyle a_j \in \bigcup_{i=n-k+j}^n A_i$ ? The remainder of the counterexample seems to follow almost directly once this part is done.","['number-theory', 'examples-counterexamples', 'additive-combinatorics']"
1341573,Why is this map a MÃ¶bius transformation?,"Question : Let $D_2=\bar D(2,1)$ and $D_{-2}=\bar D(-2,1)$ be the closed disks of radius $1$ centered at $z=2$ and $z=-2$ in the complex plane, respectively. Set $X= \mathbb C-\{D_2 \cup D_{-2} \}$, and suppose $$f:X \rightarrow X,$$
is analytic, 1-1, and satisfies $f(X)=X.$ Show that $f$ is a MÃ¶bius transformation. Attempt(s) : (1) I was thinking this could be done by contradiction. Here is a vague sketch of what I had in mind. Assume it's not a MÃ¶bius transformation. Viewing $f$ as a map on the Riemann sphere/extended complex plane minus these two disks, either $\infty\rightarrow \infty$ or some point on the boundary of one of the two disks is mapped to $\infty$. (If both ""large complex numbers"" and points near the boundary headed to $\infty$ we would not have injectivity. If neither, then we wouldn't have surjectivity.) If all points on the boundary of the disks do not go to $\infty$, then we can extend $f$ into the disks... (I get lost here) then somehow need to show that this maps $D_{-2}$ to $D_2$ and $D_2$ into $D_{-2}$, or fixes them both. What I would like to end up with is some automorphism of the Riemann sphere which must be a MÃ¶bius transformation. (2) Use symmetry and the Schwarz reflection principle somehow, but I don't know that the real line is mapped into real line.","['mobius-transformation', 'analyticity', 'complex-analysis']"
1341577,When can we use Differentiation under the Integral sign?,"Let me elaborate, 'Feynman's' trick ranks up in the top ten on most people's list, right behind contour integration, for best ways to evaluate definite integrals. However, unlike contour integration , this method doesn't really seem to have a users manual on how and when to use the method. In addition I rarely see the trick used on this site, and even when I do, it's usually in conjunction with contour integration or some other trick, so it makes it hard to see exactly what property is being exploited. Are there certain classes of integrals where using this method makes sense? In general, when is it best to use Feynman's trick? Here are my own thoughts. $e^{p \cdot x}$ is an important kernel used in the Laplace transform. In addition, it's derivative with respect to $p$ adds an $x$ term to the integral increasing the likelihood that a trick like integration by parts would work. Thus, functions with Laplace transforms might be solvable using Feynman Integration.","['soft-question', 'integration']"
1341589,"What 'limit point' means in $\Bbb Z_+\times {\{a,b}\}$?","Here was a question, but raised another question of meaning of a neighborhood. According to the answer: [Let] $Y=\{a,b\}$. If $S$ is a subset of $\Bbb Z_+\times Y$ and $(n,a)\in S$, then $(n,b)$ is a limit point of $S.$ Conversely, if $(n,b)\in S$, then $(n,a)$ is a limit point of $S.$. I know two 'application' of the definition of limit point: in the standard topology, the way to recognize whether a point as a limit point is to have an arbitrary $(a,b)$ including the limit point to know if the $(a,b)$ intersects other points of the set also; in case of $A={\{a,b,...}\}$, although ${\{a,b}\}$ is a neighborhood of $a$, but ${\{a}\}$ is itself also is a neighborhood of $a$. Having said that, since ${\{a}\}$ doesn't include other points in addition to $a$, so no element/point of $A={\{a,b,...}\}$ is limit point since not every neighborhood intersects $A$ in another point. So is for the case of $\Bbb Z_+\times Y$. Since $(n,b)\in S$ is also a neighborhood of $(n,b)$, why then $(n,a)$ is a limit point of $S$? Forgive me if my question is disappointing, but I am a beginner in topology. Thank you.",['general-topology']
1341608,Is a nontrivial finite group of order $n$ always isomorphic to a subgroup of $GL_{n-1}(\mathbb{Z})$?,I saw this question on an old qualifying exam: Let $G$ be a group of order $n\ge2$. Is such a  group always isomorphic to a subgroup of $GL_{n-1}(\mathbb{Z})$? A simpler problem would be to show that $G$ is isomorphic to a subgroup of $GL_{n}(\mathbb{Z})$. This seems to follow from that $G$ is isomorphic to a subgroup $H$ of $S_{n}$ and each element of $h$ is associated to a permutation matrix $h' \in GL_{n}(\mathbb{Z})$.  We can consider that the subgroup $H$ which $G$ is isomorphic to is the set of maps $f_{g}: G \rightarrow G$ that multiply on the left by $g$. We then have that every element of $H$ fixes the identity element of $G$ and hence can be viewed as a permutation of $n-1$ elements. Is there anything more to show from here?,"['abstract-algebra', 'group-theory', 'linear-groups', 'finite-groups']"
1341641,Prove that the following function is $C^{\infty}$ [duplicate],"This question already has answers here : Infinitely differentiable functions: how to prove that $e^\frac{1}{x^2-1}$ has derivative of any order? (2 answers) Closed 9 years ago . Prove that the following function: $$r:x \mapsto
\begin{cases}
e^{-{1\over (1-x^2)}},  & \text{if $|x|<1$} \\
0, & \text{if $|x| \ge 1$}
\end{cases}$$  is $C^{\infty}$ I found this problem on internet and i was interested to find a proof but i did't find any otheÏ similar with this exercise.It would be very nice if we can have a proof for this.","['calculus', 'fourier-analysis', 'real-analysis', 'fourier-series', 'analysis']"
1341652,Integer Partitions and distinguishable permutations,"I'm not a mathematician but I'm faced with a problem where I can't find an
answer, also because I do not know what I shall ask for: I have to deal with partitions of an integer k, only small values, up to 30
at most. If we write this partitions down, lets say for k=4, we have p(k) = 5,
namely: 1,1,1,1
2,1,1
2,2
3,1
4 So far, so good. Now we have to build distinguishable permutations with these partitions, where the length of the permutation l is always greater or equal than k,
let's say l = 6 for this explanation. (so they are filled up with 0s) My task now is to find the sum s(k,l) of distinguishable permutations to be build out of the given partitions , for the given length 1,1,1,1,0,0
2,1,1,0,0,0
2,2,0,0,0,0
3,1,0,0,0,0
4,0,0,0,0,0 I have learned in my school-days (it's long ago), that this could be achieved
with the multinomial coefficient, that I have to apply for every single
partition. Finally I have to sum it up, and my problem would be solved. I can do this - with the help of a computer program. But, and this is my question, is there a more mathematical solution?
Does anyone know whether there is a term or a 
definition or a function name what I would like to calculate? Thank you very much for your assistance.","['integer-partitions', 'multinomial-coefficients', 'combinatorics']"
1341677,Why is this not a valid proof?,"A thread I saw recently has led me to believe that this is not a valid proof of the fact that for matrices $A$ and $B$, $AB=I\implies BA=I$. Suppose $AB=I$. Then $$A^{-1}AB=A^{-1}I$$ $$B=A^{-1}$$ $$BA=A^{-1}A$$ $$BA=I$$ what step is wrong in this? I assume $A$ has an inverse because $\det A\det B=\det AB=\det I=1$, so $\det A\neq 0$.","['linear-algebra', 'matrices']"
1341680,Same Expected Value but different variances. Is $E[U(X)] \ge E[U(Y)]$?,"Let $U: \mathbb R -> \mathbb R$ be a concave function, and let $X$ be a random variable with a normal distribution, expected value $\mu$, and standard deviation $\sigma$. Let $\lambda \gt 1$, and let $Y$ be a random variable with a normal distribution, expected value $\mu$, and standard deviation $\mu \sigma$. (a)Prove that $U(\mu + c) + U(\mu-c) \ge U(\mu + c\sqrt{\lambda}) + U(\mu - c\sqrt{\lambda})$ for all $c \gt 0$ (b) By changing appropriate varible, and using a), prove that $E[U(X)] \ge E[U(Y)]$ I can only know Jensen's inequality which is $U[E(X)] \ge E[U(X)]$. I have no idea how to prove a) and b). Can you please help me? I have forgone statistics for a long time so I greatly appreciate for your help. Thanks.","['economics', 'statistics', 'statistical-inference']"
1341694,Complex integral with exponential and tangent,"Suppose that $k \in \mathbb{R}.$ Evaluate as a function of $k$ the integral
$$I(k) : = \int_{-\pi/2}^{\pi/2} e^{i \ k \ \mathrm{tan}(\phi)} d \phi.$$ Any suggestions on how to approach this problem? I thought about changing the integrand into a function of $z \in \mathbb{C}$ since $z=re^{i \theta}$, but that didn't seem to lead to anything fruitful. I also thought about using the fact that $e^{i \theta} = \mathrm{cos(\theta)} +  i \ \mathrm{sin(\theta)}$. Thanks.","['complex-analysis', 'integration']"
1341714,how to sum the floors of ratios n/k when prime factorization of n is known,"According to @harald-hanche-olsen the sum of the floors of ratios of $n/k$ is approximately: $$n(\ln n-1-\ln2)<\sum_{k=2}^{n-1}\Bigl\lfloor \frac nk\Bigr\rfloor<n\ln n.$$ If the prime factorization of $n$ is known (that is, if $n=\Pi_i{k_i^{\alpha_i}}$), can a closer approximation be obtained? In my case the exact value of $n$ is not important, just the accuracy of the sum of the floors of the ratios.  One approach is to let $n=\Pi^p_i{i}$ so the the first $p$ sums would be exact (equal to $nH_p$ where $H_p$ is the $p^{th}$ harmonic number) and the approximation is needed only for: $$
\sum_{k=p+1}^{n-1}\Bigl\lfloor \frac{\Pi^p_i{i}}k\Bigr\rfloor
$$ The reduction in the range is marginal using this approach:  it can be expressed as:
$$nH_p+n(\ln n-1-\ln2)-p(\ln p-1-\ln2)\le\sum_{k=2}^{n-1}\Bigl\lfloor \frac nk\Bigr\rfloor\le nH_p+n\ln n-p\ln p.$$ Other optimizations may be possible. For example: If $n=p^{2^k}$ then $n\Pi_{i=0}^k(1+p^{-2^i})$ sums for all combinations of factors from $p^0$ to $p^{2^k}$ If $n=4!=24$ then $$\sum_{k=2}^{n-1}\Bigl\lfloor \frac nk\Bigr\rfloor=12+8+6+\Bigl\lfloor \frac {24}5\Bigr\rfloor+4*(6-5)+3*(8-6)+2*(12-8)+1*(24-12)$$ So the biggest region of uncertainty for a factorial $f!$ lies between $f<k<(f-1)!$.  Furthermore we have $$((f-1)!-1)((f-1)!-f-1) < \sum_{k=f+1}^{(f-1)!-1}\Bigl\lfloor \frac nk\Bigr\rfloor < f((f-1)!-f-1)$$ Edit The answer should be in the form of: Given: $$
a_v <= \sum_{k}^{v-1}\Bigl\lfloor \frac{v}k\Bigr\rfloor <= a_v+\mathcal{O}(\sqrt{v})\\
a_u <= \sum_{k}^{u-1}\Bigl\lfloor \frac{u}k\Bigr\rfloor <= a_u+\mathcal{O}(\sqrt{u})
$$ Conclusion: a method exists to compute $a_{uv}$ such that:
$$
a_{uv} <= \sum_{k}^{uv-1}\Bigl\lfloor \frac{uv}k\Bigr\rfloor <= a_{uv} + \xi \text{ where } \xi << \mathcal{O}(\sqrt{uv})
$$","['summation', 'ceiling-and-floor-functions', 'discrete-mathematics']"
1341723,What are some easier books for studying martingale?,"What are some easier books for studying martingale? They are defined to be comprehensive but easier than Roger and William's martingale book. For example, to study Q and F martingales? It should cover continuous-time martingale, stochastic integrals and most other basic topics for martingle","['probability-theory', 'soft-question', 'stochastic-calculus', 'martingales', 'reference-request']"
1341726,Confidence interval for sample,"I have a sample of size $n=19593$ of count data 1      2     3    4    5   6   7   8   9   10  11  12  13  14  15  16  17  18  19 20 21 22 23 24 25 26 27  
18890  3032  1542  727  599 530 409 363 298 266 261 273 231 268 129 131 145 120 119 29 62 48 0  18 0  38 10 I want to find a confidence interval for the center of the data, specifically in the form $n \mu$. Do I have enough data to estimate $\sigma$ and use the central limit theorem. The negative binomial seems to be the best fit among known distributions, but I  don't think it is the right fit because of the long tail in the data, so would bootstrapping be a better approach and using the median instead of the mean to measure the center of the data.","['estimation', 'statistics', 'statistical-inference']"
1341740,Group $G$ whose center $Z(G)$ is cyclic and with $G/Z(G)$ commutative,I have some issue to solve following exercise. The exercise is from a French book on Algebra (cours d'AlgÃ¨bre) from Jean QuerrÃ©. The book is from the 1970's. If the center $Z(G)$ of a group $G$ is cyclic and $G/Z(G)$ is commutative then there exists a group $H$ such that $H \times H$ is isomorphic to $G/Z(G)$.,"['abstract-algebra', 'group-theory']"
1341763,$W(t)=t^2 Z(t)-2\int_0^t sZ(s)ds$. What is $dW(t)$?,"This is a sample question for the actuarial exam MFE. Let $Z(t)$ be a standard Brownian motion. Let $W(t)=t^2 Z(t)-2\int_0^t sZ(s)ds$ . What is $dW(t)$ ? The only thing I know is Ito's Lemma. So I computed the following: $\frac{\partial W}{\partial Z}=t^2-\frac{\partial}{\partial Z} \big( 2\int_0^t sZ(s)ds\big).$ $\frac{\partial^2 W}{\partial Z^2}=-\frac{\partial}{\partial Z^2}\big(2\int_0^t sZ(s)ds\big)$ . $\frac{\partial W}{\partial t}=2Z(t)t-\frac{\partial}{\partial t}\big(2\int_0^t sZ(s)ds\big)$ But then I don't know how to deal with the parts with integral? Here's the solution which I don't fully trust (partially because I haven't taken a proof-based class in stochastic calculus). $dW(t)=d[t^2Z(t)]-2tZ(t)dt$ . Because $d[t^2Z(t)]=t^2dZ(t)+2tZ(t)dt$ , we have $dW(t)=t^2dZ(t)$ .","['probability-theory', 'probability', 'stochastic-processes']"
1341771,Proving that the cross ratio is a MÃ¶bius transformation,"I'm trying to show that given three distinct points $z_1,z_2,z_3\in\mathbb C$, the rational function
$$
f(z) = \frac{(z-z_1)(z_2 - z_3)}{(z - z_3)(z_2 - z_1)} = \frac{(z_2 - z_3)z + (z_1z_3 - z_1z_2)}{(z_2 - z_1)z + (z_1z_3 - z_2z_3)} = \frac{az + b}{cz + d}
$$
is a MÃ¶bius transformation. That is, I must show that $ad - bc \neq 0$. I worked out that
        \begin{align*}
		ad - bc & = (z_1z_2z_3 - z_2^2z_3 - z_1z_3^2 + z_2z_3^2) - (z_1z_2z_3 - z_1^2z_3 - z_1z_2^2 + z_1^2z_2) \\
		& = - z_2^2z_3 - z_1z_3^2 + z_2z_3^2 + z_1^2z_3 + z_1z_2^2 - z_1^2z_2 \\
		& = (z_2z_3^2 - z_2^2z_3) + (z_1^2z_3 - z_1z_3^2) + (z_1z_2^2 - z_1^2z_2) \\
		& = z_1^2(z_3 - z_2) + z_2^2(z_1 - z_3) + z_3^2(z_2 - z_1),
		\end{align*}
but I'm unsure of where to go from here to show that this expression is nonzero.","['mobius-transformation', 'complex-analysis']"
1341805,plot graph of function $f(z)=\frac{1+z}{1-z}$,I am not able to plot graph of function $f(z)=\frac{1+z}{1-z}$. can anyone tell me how to do this without using any software?,"['graphing-functions', 'complex-analysis']"
1341815,Nonexistence of local isometry between equidimensional Riemannian manifolds,"Recall that all inner product spaces of the same dimension are isometric. For example, if $(M,\mathrm{g})$ and $(N,\mathrm{h})$ are Riemannian manifolds of the same dimension, then $(T_pM,\mathrm{g}_p)$ and $(T_qN,\mathrm{h}_q)$ are isometric inner product spaces. Let $\beta:T_pM\to T_qN$ be a (linear) isometry. Question : Why isn't $\exp_q\!\circ\,\beta\circ\exp_p^{-1}$ a local isometry wherever it is defined? To clarify, I know that it isn't a local isometry, at least in general. If it was, then I'd have a local isometry between neighborhoods of every point on each equidimensional Riemannian manifold, which is clearly absurd. I'm looking for an explanation as to why this composition is not a local isometry. I'm not looking for a counterexample. I think my mental impasse comes from Gauss' lemma, but I'm not sure. Using the chain rule, shouldn't $\exp_{q*}\!\circ\,\beta\circ\exp_{p*}^{-1}$, as a composition of linear isometries, itself be a linear isometry?","['isometry', 'differential-geometry', 'inner-products', 'riemannian-geometry']"
1341836,"Unsolvability of a Quintic and its link with ""Simplicity"" of $A_{5}$","At the outset I must mention that I don't have a fairly working knowledge of Galois Theory (but do have some idea of group theory in the sense that I can understand normal subgroups). I read the proof of unsolvability of a general quintic via radicals from  J P Tignol's ""Galois Theory of Algebraic Equations"". Here he discusses the proof by Abel and goes on to establish the following theorem (see details in my blog post ): Theorem : Let $x_{1}, x_{2}, \ldots x_{n}$ be indeterminates and let  elements $a, b$ be in field $K = \mathbb{C}(x_{1}, x_{2}, \ldots, x_{n})$ such that $a = b^{p}$ for some prime number $p$. Let $n \geq 5$ and define permutations $\sigma, \tau$ such that $\sigma$ permutes $x_{1}, x_{2}, x_{3}$ cyclically and $\tau$ permutes $x_{3}, x_{4}, x_{5}$ cyclically. If $a$ in invariant under both $\sigma, \tau$ then so is $b$. Because of the equation $a = b^{p}$ the above theorem implies that when $n \geq 5$ there are some symmetries (invariance under $\sigma, \tau$) which remain even after taking radicals. Thus starting with the elementary symmetric function $s_{1}, s_{2}, \ldots, s_{n}$ of the indeterminates $x_{i}$ the process of taking radicals will preserve the symmetries related to $\sigma, \tau$. On the other hand each one of the indeterminates $x_{1}, x_{2}, x_{3}, x_{4}, x_{5}$ is changed via at least one of $\sigma$ and $\tau$. Thus the field $K$ has elements which are changed by $\sigma, \tau$ but any element of a radical extension of $F = \mathbb{C}(s_{1}, s_{2}, \ldots, s_{n})$ is invariant under $\sigma, \tau$ and hence it is not possible to get to $K$ from $F$ via radical extensions. On the other hand most modern treatments of unsolvability of quintic base it on the simplicity of alternating group $A_{5}$. Understanding the above mentioned theorem in Tignol's book is quite easy (simple algebraic manipulation) but its not same as regards to simplicity of $A_{5}$. Is simplicity of $A_{5}$ somehow linked with the above basic theorem? What I need is a proper link between properties of $A_{5}$ and the above theorem. What is so special about elements $\sigma = (1,2,3), \tau = (3,4,5)$ of $A_{5}$? And why don't we have such permutations when $n < 5$ whose symmetries are preserved when taking radicals. Update : I think I need to clarify my point very clearly. The message of the theorem described above is that for $n \geq 5$ there exists a set $P$ of permutations on $n$ symbols such that $P$ includes at least one non-identity permutation and the process of root extraction preserves the symmetries induced by the permutations of $P$. For $n < 5$ root extraction preserves the symmetries induced only by the identity permutation (trivially). My real problem is that I am unable to map this simple concept with the comparatively difficult concept of unsolvability / simplicity of $A_{5}$. There is a feeling that probably the solvability of polynomials is a much simpler concept than the solvability of groups (as least as far the general polynomials with indeterminate coefficients are concerned). At the same time this feeling is crushed by the theorem of Galois that ""a polynomial is solvable by radicals if and only if its galois group is solvable"" so that these concepts are at the same level of depth/difficulty. If it helps, I checked Tignol's book and he mentions that the theorem mentioned above is by Paolo Ruffini and he gives the reference: P. Ruffini, Opere Matematiche (3 vols), E. Bortolotti, ed., Ed. Cremonese 
della Casa Editrice Perrella, Roma, 1953-1954. The result is available in pages 162-170 in vol 2. Further Update : I am not getting the kind of answer I need. Perhaps I need to provide a context in the language of Galois Theory. Let's assume fields to be of characteristic $0$ in what follows. Let $f(x) \in F[x]$ be a polynomial and $K$ be splitting field of $f$. Galois theory says that the galois group of $f$ (over field $F$) is the set of automorphisms of $K$ which leave $F$ fixed. Also if $L$ is another field with $F \subseteq L \subseteq K$ then galois group of $f$ over $L$ is a subgroup of its galois group over $F$. Also note that the galois group can be viewed as a subgroup of the group of permutations of roots of polynomial $f(x)$. It is further known that when the field $L$ is obtained by adjoining all roots of an irreducible polynomial $p(x) \in F[x]$ (of degree $k$) so that $L = F(\alpha_{1}, \dots, \alpha_{k})$ and $p(\alpha_{i}) = 0$ for $i = 1, 2, \dots, k$ then the galois group $Gal(K/L)$ is a normal subgroup of $Gal(K/F)$. This case is relevant when $L$ is a radical extension of $F$. In our case $F = \mathbb{C}(s_{1}, \dots, s_{n}), K = \mathbb{C}(x_{1}, \dots, x_{n})$ and we are directly able to find a set of permutations of $x_{i}$ which leave every element of $L$ fixed where $L$ is a radical extension of $F$. Hence if $L$ is any radical extension of $F$ with $F \subseteq L \subseteq K$ then $Gal(K/L)$ contains two permutations $\sigma, \tau$ given above. Since radical extensions correspond to a chain of reducing (getting smaller in size) normal subgroups of $S_{n}$, this shows that the series can never get to the trivial group consisting of identity. In my opinion the theorem by Paolo Ruffini provides a very direct and easily accessible proof of unsolvability of the $S_{5}, A_{5}$ and it is so unlike the usual proofs of unsolvability of $A_{5}$. Let me know if my views are correct.","['abstract-algebra', 'galois-theory']"
1341838,Convergence and divergence depending on whether $n$ is odd or even,"It is part of one problem I am working on: I want to prove the following conjecture ($x\ne q\pi$ where $q\in\Bbb Q$) $$\sum_{n=1}^{\infty}\frac{\sin^{2k-1}(nx)}{n^{\alpha}}\quad\text{converges if}\quad0<\alpha\le1,k\in\Bbb N$$
  $$\sum_{n=1}^{\infty}\frac{\sin^{2k}(nx)}{n^{\alpha}}\quad\text{diverges if}\quad0<\alpha\le1,k\in\Bbb N$$ So far I have tested cases for $\sin^{1,2,3,4}$ and the results agree with the conjecture. I believe it holds for all natural numbers. I tried using induction but I failed. Could you help me or improve my method? Best regards. My failed induction method, for the $\sin^{2k}$ cases, was as follows: Hypothesis $$\sin^{2k}\theta=\xi_k+T_k(\theta)$$
  where $\xi_k\in\Bbb R^+$ (the positivity of $\xi$ is needed in the context of the bigger problem, though it is not necessary in the conjecture), $T_k(\theta)$ is a linear combination of ""first-order"" trignometric terms: $\sin\theta,\sin 2\theta,\sin 3\theta,\cdots$ or $\cos\theta,\cos2\theta,\cos3\theta\cdots$ but not $\sin^2\theta,\sin^3 2\theta,\cos^45\theta$ etc. If this hypothesis holds, then by Abel-Dirichlet criterion it is easy to prove the second part of the conjecture. Proof by induction Initial case $k=1$ is trivial. If for any given $k$ the hypothesis stands, then for $(k+1)$ $$
\begin{align*}
\sin^{2k+2}\theta=&\xi_k\sin^2\theta+\sin^2\theta T_k(\theta)\\
=&\xi_k\left(\frac{1-\cos 2\theta}{2}\right)+\left(\frac{1-\cos 2\theta}{2}\right)T_k(\theta) \\
=&\frac12\xi_k-\frac12\xi_k\cos2\theta+\frac12T_k(\theta)-\frac12\cos(2\theta)T_k(\theta)
\end{align*}
$$
  Now the hard part lies in the last term of RHS: it definitely contains terms like $\cos2\theta\sin m\theta$ or $\cos2\theta\cos m\theta$, to reduce them to the ""first order"", it must yield some constant terms, which might threaten the existence of a positive $\xi_{k+1}$. I don't know how to proceed.","['sequences-and-series', 'calculus', 'induction', 'trigonometry']"
1341841,The Rubik Square permutation groups,This post was inspired by this webpage of mathematical challenge due to MickaÃ«l Launay (French). Let $G_n$ be the subgroup of $S_{n^2}$ generated by the red arrow permutations as for the following picture with $n = 5$: ( Source : http://www.micmaths.com/defis/defi_07.html ) We can call $G_n$ the n-th Rubik Square permutation group. Question : Is $G_n$ a strict subgroup of $S_{n^2}$?,"['group-theory', 'finite-groups', 'recreational-mathematics', 'permutations']"
1341843,Prove that $\tan^6 20Â°+\tan^6 40Â°+\tan^6 80Â°$ is an integer,"Prove that $\tan^6 20Â°+\tan^6 40Â°+\tan^6 80Â°$ is an integer. Doesn't this problem seem a little out of the box? It seems beautiful, but I don't have an idea on how to start. Calculating the value does give me an integer-$32733$. Thanks.","['trigonometric-series', 'algebra-precalculus', 'trigonometry']"
1341848,Proving that $\lim_{x {\to} \infty}f(x)=\infty $,"Given $\ f(x)$ that is differential in $\ (x_0,\infty), f'(x)\ge a,$ for every $\ x> x_0$ and $\ a>0$, trying to show that $\lim_{x\to\infty}f(x)=\infty$. So far I've tried using Mean Value Theorem on $\ [b,b+1],$ so that $\ b>x_0$. From there I assumed in order to contradict, that $\ f(x)$ converges to a finite $\ L$. So 
$$ \lim_{x\to\infty}f(x)=  \lim_{x\to\infty} f(b+1)-f(b)= L -L=0$$
This is against that (*)$\ f'(x) > 0$ so $\ f(x)$ does not converge to a finite value. Finally $\ f(x)$ is strictly increasing ($\ f'(x)\ge a>0$) so it tends to infinity. 
$$$$
I think that * might be faulty, if the limit of a derivative is zero it doesn't mean that the actual derivative is affected so. Maybe there is a different direction to approach this. Any input? Maybe this should be solved in a different way?","['calculus', 'limits', 'derivatives']"
1341870,Use Wilson theorem to show that $63! + 1 \equiv 0 \mod ~ 71$,Use Wilson theorem to show that $63! + 1 \equiv 0 \mod ~ 71$. 71 is prime then Wilson theorem says that $(71-1)!+1=0 \mod ~ 71$ i.e $70!+1\equiv 0 \mod ~ 71$ then how to proceed further?,"['number-theory', 'elementary-number-theory']"
1341882,Find the intersection of two lines entirely outside the given sheet of paper by straightedge alone,"This is a problem from Courant : Two straight lines entirely outside the given sheet of paper are each
given by two pairs of straight lines intersecting at points of the
lines outside the paper. Determine their point of intersection by a
pair of lines through it. Using Brianchon's theorem the solution (with all the lines/points on the paper) is: The two lines can be regarded as two of the three concurrent diagonals of the theorem. From the intersecting two pairs of lines a third concurrent diagonal can be constructed for each line. These two diagonals intersect in the point of intersection of the two original lines.
However, for this construction you need all intersection points, don't you?
Any idea? Or different approach?","['projective-geometry', 'geometric-construction', 'geometry']"
1341902,In how many ways I can write a number $n$ as sum of $4$ numbers?,"The precise problem is in how many ways I can write a number $n$ as sum of $4$ numbers say $a,b,c,d$ where $a \leq b \leq c \leq d$. I know about Jacobi's $4$ square problem which is number of ways to write a number in form of sum of $4$ squares number. There is a direct formula for it. Is there a direct formula for this problem too? Edit: All the numbers are positive integers greater than $0$.
Example: For $5$ there is only one way $1,1,1,2$.","['number-theory', 'discrete-mathematics']"
1341929,"Sum numbers game with numbers $n,n-1,n-2,\ldots,3,2,1,2,3,\ldots,n-2,n-1,n$","On a line, there are $2n-1$ numbers lined up as follows: $$\text{$n$ , $n-1$ , $n-2$ , $\cdots$ , $3$ , $2$ , $1$ , $2$ , $3$ , $\cdots$ , $n-2$ , $n-1$ , $n$}\,.$$ At each step, one can choose any number in the line and add it to each of its neighbours before removing it. The leftmost and rightmost numbers only have one neighbour each. The process stops when there is a single number left. What is its maximum possible value? This problem is inspired by and a generalization of the one at http://www.micmaths.com/defis/defi_05.html where $n = 5$ . I thought that the optimal would be to start with the number at the centre and then alternate between the left and right neighbour of the previously chosen number. However, it turns out to be not optimal for $n > 3$ . But I do not even know the optimal answer for $n = 5$ , except that it must be at least $174$ .","['puzzle', 'combinatorial-game-theory', 'recreational-mathematics', 'combinatorics']"
1341945,Are there simple unsolved problems in statistics?,"In number theory, calculus and various fields of mathematics, there are many unsolved problems. But are there simple unsolved problems in statistics?","['open-problem', 'statistics']"
