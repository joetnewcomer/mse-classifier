question_id,title,body,tags
3180252,If $M$ is a maximal subgroup and $f$ a surjective homomorphism then $f(M) = H$,"Let $G$ be a group and let $M \le G$ be a maximal subgroup of $G$ . Let $f:G \to H$ be a surjective homomorphism such that $M$ doesn't contain $kerf$ . The task is to prove that $f(M) = H$ . My attempt: I say the $\{s_1, ..., s_n \}$ is the generating set of $M$ . I assume by contradiction that $f(M) \ne H$ so there exists $e \ne h \in H$ such that $h \notin f(M)$ . Since $f$ is surjective, there exists $e \ne g \in G$ such that $f(g) = h$ , which implies $ g \notin M$ . The I want to look at the subgroup that is generated by $\{s_1, ..., s_n, g \}$ which is bigger then $M$ and show that it is not $G$ which means it is a contradiction. However, I couldn't manage to prove it is not $G$ , and I am stuck here. Another direction at which I thought about is to somehow use the correspondence theorem, since $kerf$ is a normal subgroup of $G$ , but I am not sure how can I use it here. Help would be appreciated.","['group-homomorphism', 'group-theory']"
3180366,convergence RATE of the square root of a self-adjoint operator.,"I am assuming $T$ is a compact operator and $\{T_j\}$ is a sequence of compact operators such that $\|T-T_j\| < \epsilon_j$ where $\epsilon_j$ is a quantity that goes to zero as $j \to \infty$ . It is easy to show that this implies $\|T^*T-T^*_jT_j\| \leq C\epsilon_j$ for some constant $C$ . I am wondering if it is also true that $\|\sqrt{T^*T}-\sqrt{T^*_jT_j}\| \leq D\epsilon_j$ for some constant $D$ ? I have seen several proofs that $\sqrt{T^*_jT_j}$ converges to $T^*T$ in the operator norm, but I am wondering about the rate of this convergence. I am pretty sure that just assuming $\|T^*T-T^*_jT_j\| \leq C\epsilon_j$ does not imply that $\|\sqrt{T^*T}-\sqrt{T^*_jT_j}\| \leq D\epsilon_j$ . But I was wondering if $\|T-T_j\| < \epsilon_j$ did imply the result. Any help or direction to a reference would be greatly appreciated. If the result is false, a counterexample would also be great.","['operator-theory', 'compact-operators', 'functional-analysis']"
3180377,Obtaining the Parameterization of a Space-Filling Curve,"So, I am working with a grid that has $N_x$ , $N_y$ and $N_z$ voxels along the $x$ , $y$ and $z$ axis respectively. There is this bijection that I apply in order to use the grid as one large vector and it is as such: $$
\tag{1}
\label{eq:param}
l(i,j,k)=i⋅(N_x)^2+j⋅(N_y)^1+k⋅(N_z)^0 
$$ where $i,j,k$ are the indices of a voxel in the grid. It occurred to me that this is a very arbitrary way of having a grid turned into a vector, of converting 3D to 1D and I started looking into it a little bit more. I came across the concept of a space-filling curve and it seemed to me like those curves were better behaved and had interesting properties. I wanted to work with them, it turns out that in order to do that I need a way to compute the values $l(i,j,k)$ for these curves. So my question is: Is there a way to obtain a parameterization such as the one in Equation \ref{eq:param} for a space-filling curve? P.S. If there is no general method, it is enough to discuss one particular example of a space-filling curve where that is possible. P.P.S. In case there are no examples with a neat closed-form expression like Equation \ref{eq:param}, it is okay if there is a computational procedure to compute an $l(i,j,k)$ , given the indices $i,j$ and $k$ .","['curves', 'general-topology', 'discrete-mathematics']"
3180388,Why is $\pi$ a solution to $\tan^2x \cos{x}=\tan^2x$?,The equation $\tan^2x \cos{x}=\tan^2x$ has the solutions $\pi$ and $0$ however I'm not sure why. If I divide both sides by $\tan^2x$ I would end up with $\cos{x}=1$ which is $0$ .  Am I just making a big mistake here?,"['algebra-precalculus', 'trigonometry']"
3180413,"ACL characterization of functions in $W^{1,\infty}(\Omega)$","I am reading ""A First Course in Sobolev Space"" by Leoni. Theorem 10.35 states that for $1\leq p<\infty$ , a function $u\in L^p(\Omega)$ belongs to $W^{1,p}(\Omega)$ if and only it has a representative $\bar{u}$ that is absolutely continuous on $a.e.$ line segments of $\Omega$ that are parallel to the coordinate axes. The proof in the book is not valid for $p=\infty$ . However, according to Wikipedia, this theorem also holds for $p=\infty$ . Can anyone provide a proof?","['partial-differential-equations', 'functional-analysis', 'real-analysis']"
3180414,Is there always a way to generate nontrivial finite extensions of a field?,"Suppose I have a field $k,$ an algebraically closed field $L,$ and an embedding $k \hookrightarrow L.$ Then we know that for any algebraic extension of $k, E$ we can extend the embedding to $E \hookrightarrow L.$ However, if we take $L$ to be the algebraic closure of $k$ and $E$ to be a nontrivial finite extension of $L$ then $E$ is algebraic over $k$ and we have an embedding of $E \hookrightarrow L.$ So this would mean that $L$ and $E$ are infinite dimensional, otherwise, if $L$ and $E$ were finite, $E$ would have strictly greater dimension and such an embedding would not make sense. However, we have something like $\mathbb{C}$ that is a finite dimensional algebraic closure of $\mathbb{R}.$ So would this mean that there are no nontrivial finite extensions of algebraically closed fields in the first place? For finite fields, we can always take its polynomial rings and modulo out by some irreducible. For example, $\mathbb{R}[X]/X^2 + 1.$ However, this does not work for algebraically closed fields. But I feel that we should be able to make nontrivial extensions for any field. Is this not the case?","['field-theory', 'abstract-algebra']"
3180421,"Let $G$ be a ""Normed"" Abelian Group, is this a topological equivalent Norm over $G$?","Let $G$ be an abelian group. We say $\Vert \cdot \Vert : G \rightarrow \Bbb R_{\ge0}$ is a norm if it satisfies $\Vert x \Vert =0 \Leftrightarrow x=0$ $\Vert -x \Vert = \Vert x \Vert$ $\Vert x+y \Vert \le \Vert x \Vert+\Vert y \Vert$ It's easy to prove $d(x,y)=\Vert x-y \Vert$ is a metric over $G$ and satisfies $d(x+z,y+z)=d(x,y)$ $d(-x,-y)=d(x,y)$ In fact, any metric over $G$ satisfying this properties is induced  by a Norm over $G$ . We say two Norms over $G$ are topologically equivalent if they induce the same topology over $G$ . Let $G$ be an abelian group with a Norm, I've manage to prove the following function $$\Vert x \Vert_*= \frac{\Vert x \Vert}{1+\Vert x \Vert}$$ is a norm over $G$ and is topologically equivalent to the original norm. Also $\Vert x \Vert_*<1$ for all $x \in G$ and if $\Vert \cdot \Vert$ is unbounded then $\sup_{x \in G}{\Vert x \Vert}_*=1$ .
Now let $G$ be an abelian group with a norm such that $\Vert x \Vert<1 \ \ \forall \ x \in G$ and $\sup_{x \in G}{\Vert x \Vert}=1$ , is the following function a norm over $G$ ? $$\Vert x \Vert^*= \frac{\Vert x \Vert}{1-\Vert x \Vert}$$ Is it topologically equivalent to the original norm? If this is true then the unbounded norms over an abelian group $G$ are in bijection with the bounded norms with $\Vert x \Vert<1 \ \ \forall \ x \in G$ and $\sup_{x \in G}{\Vert x \Vert}=1$ , and the biyection ""behaves well"" with the topology (meaning it preserves the relation ""being topologically equivalent""). This is what I'm trying to prove.","['general-topology', 'normed-spaces', 'metric-spaces', 'group-theory']"
3180427,"Given probability vectors $x$ and $y$, how can I compute probability vector of $z = x + y$ using linear algebra operations","I have probability vector $t_1$ (hours to get ' $A$ ' done), $p({t^{a}_{1})} = [0.25, 0.25, 0.25, 0.25]$ (here: $0.25$ probability for $A$ done in $1, 2, 3$ or $4$ hours). Another probability vector $t_2$ (hours to get ' $B$ ' done), $p({t^{b}_{2})} = [0.33, 0.33, 0.33]$ . How can I get to probability vector $p({t^{a}_{1}+t^{b}_{2}))}$ (hours to get both $A$ and $B$ done assuming they can only be done one after the other and distributions are independent) using linear algebra operations ? p.s.: I am looking for linear algebraic solution and suspect that there may be a solution via markov chain etc.","['markov-chains', 'linear-algebra', 'probability']"
3180433,Understanding Mathematical Induction problems,"I have problem to understand this 3 formulas, I am new in this type of problems.
I have to solve this problems by induction. \begin{align}
\sum_{j = 1}^{j = n} j^3 &= \left(\frac{n(n + 1)}{2}\right) ^ 2  &\text{where } n \geq 1 \\
\sum_{j = 1}^{j = n} j(j + 1) &= \frac{1}{3}n(n + 1)(n + 2)  & \text{where } n \geq 1 \\
\sum_{j = 1}^{j = n} j(j!) &= (n + 1)! - 1 
\end{align}","['education', 'number-theory', 'induction', 'discrete-mathematics']"
3180443,Integral $\int_0^\infty \frac{|\sin\sqrt{qx}|-|\sin\sqrt{px}|}{x}dx$,"Prove that $$
\int_{0}^{\infty}
\frac{\left\vert\sin\left(\sqrt{qx}\right)\right\vert-
\left\vert\sin\left(\sqrt{px}\right)\right\vert}{x}\,\mathrm{d}x =
\frac{2}{\pi}\,\log\left(\frac{q}{p}\right)
$$ This is a Frullani integral, but I am not sure if it converges. Anyway, I investigated it in my article on ""fascinating integrals"" (see here ) if you are interested about how I came to that result. My interest in this integral is because I solved it using non-traditional methods ( purely based on statistical analysis ), Wolfram Alpha is unable to compute it ( thought it provides the exact value of other Frullani integrals ), and I want to make sure my answer is correct or makes sense, maybe not in the context of Rienman integrals, but some other types of integrals.","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
3180447,Is a vector space a subspace of itself?,"We know that a subspace (of a vector space $V$ ) is a vector space that follows the same addition and multiplication rules as $V$ , but is a vector space a subspace of itself? Also, I'm getting confused doing the practice questions, on when we prove that something is a vector space by using the subspace test and when we prove V1 - V10, which are the ten axioms of vector spaces. So for example in $\Bbb R^2$ , we have that $\vec{x} + \vec{y} = \vec{y} + \vec {x}$ , etc..","['linear-algebra', 'vector-spaces']"
3180453,Decompose vector fields on product manifolds,"So, I know that tangent bundle of a product manifold $M \times N$ splits in a sum $$
T_{(x,y)}(M \times N) = T_xM \oplus T_yN,
$$ so that is obvious that the sum $X \oplus Y$ of smooth vector fields $X \in \mathcal{T}(M)$ and $Y \in \mathcal{T}(N)$ is a smooth vector field of $M \times N$ . I've been told that, though not every vector field in $\mathcal{T}(M \times N)$ is a sum, locally one can always find one such decomposition, which will in turn be unique due the fact the sum is a direct one. How can I show that this decomposition exists locally? More than that, if $X = X_1 + X_2$ is the decomposition, is there a way the express the coordinate functions of $X_1$ and $X_2$ in terms of those of $X$ ? First I thought about taking two frames that locally spam $TM$ and $TN$ and write down $X$ using them, but then the coordinate functions are of the form $X^i: M \times N \to \mathbb R$ , and the vector field components in each subspace are not exactly fields of $M$ and $N$ because their coordinate functions don't have the right domains. Is there another better way to see this decomposition holds locally?","['vector-fields', 'vector-bundles', 'direct-sum', 'differential-geometry']"
3180466,How many letters suffice to construct words with no repetition?,"Given a finite set $A=\{a_1,\ldots , a_k\}$ , consider the sequences of any length that can be constructed using the elements of $A$ and which contain no repetition, a repetition being a pair of consecutive subsequences (of any length) that are equal.  Is it true that $k = 4$ is the minimum number of elements in $A$ that allows the construction of sequences of any length containing no repetition? Can anyone indicate a reference for this result, if true?","['combinatorics-on-words', 'combinatorics']"
3180476,Find the positive root of $100^{2}=x^{2}+ \left( \frac{100x}{100+x} \right)^{2}$,"I was struggling with this problem: $$100^{2}=x^{2}+ \left( \frac{100x}{100+x} \right)^{2}$$ It came up when i was developing a solution to a geometry problem. I've already checked in Mathematica and the solution is right, according to the answer. The answer needs to be a real positive number because it's a measure of a segment. I've tried factoring, manipulating algebraically, but i couldn't solve the resulting 4th degree polynomial. I appreciate if someone could help me. Thanks!","['contest-math', 'real-numbers', 'factoring', 'polynomials', 'algebra-precalculus']"
3180501,Can $p(x)q(x+1)$ and $q(x)p(x+1)$ be the same?,Suppose $p(x)$ and $q(x)$ are distinct polynomials with integer coefficients. Can we conclude that $p(x)q(x+1)$ and $q(x)p(x+1)$ are distinct expressions?,"['abstract-algebra', 'polynomials']"
3180508,Coverings of CW complexes are also CW complexes: How do I show that it has the weak topology?,"Let $X$ be a CW complex, $p:E\to X$ a covering map. Then $E$ has an induced CW complex structure defined as follows. If $\Phi:D^n\to X$ is a covering, it lifts to a map $D^n\to E$ (since $D^n$ is simply connected and we can apply the lifting criterion). These give the desired cell decomposition. However, I don't know how to prove that $E$ has the weak topology induced by the aforementioned cell decomposition. Somehow I must use the fact that $p:E\to X$ is a covering and that $X$ has the weak topology, but I don't know how... This question has been asked several times on this site, e.g., here , and here . But (surprisingly) none of the answers there give a proof of this... Thanks in advance!","['general-topology', 'cw-complexes', 'algebraic-topology', 'covering-spaces']"
3180552,Jacobi Identity for Poisson Bracket [duplicate],"This question already has an answer here : Showing Jacobi identity for Poisson Bracket (1 answer) Closed 2 years ago . We define the so-called rigid body Poisson bracket as $\{F,G\}(\Pi) = -\Pi \cdot(\nabla{F} \times \nabla{G}) $ . I want to prove Jacobi's identity, which is : $\{F,\{G,H\}\} + \{G,\{H,F\}\}+\{H,\{F,G\}\} =0.$ My (naive) approach is to go ahead and use the definition of the bracket mentioned above and write: $\{F,\{G,H\}\}= -\Pi\cdot(\nabla{F} \times \nabla{\{G,H\}})$ . I can then write that $\nabla{\{G,H\}}= \nabla({-\Pi}\cdot(\nabla{G}\times\nabla{H})).$ I then use the vector identity $\nabla({A \cdot B}) = \nabla{A}\cdot B + \nabla{B}\cdot A$ . This gives me: $\nabla{\{G,H\}}= \nabla({-\Pi}\cdot(\nabla{G}\times\nabla{H})) = -\nabla{\Pi}\cdot(\nabla{G}\times\nabla{H})+ \nabla{(\nabla{G}\times\nabla{H)}}\cdot(-\Pi).$ I am almost tempted to say that the second term vanishes, so $\nabla{(\nabla{G}\times\nabla{H)}}\cdot(-\Pi) =0$ . But I am not so sure we can do that. I lack a good argument for this part. I also know that $\nabla{\Pi} = I$ , since the coordinates are $\Pi = (\Pi_1,\Pi_2,\Pi_3)$ . Can anyone help point me in the right direction? Also, I am trying to avoid using coordinates (I don't want to turn to the dark side of the force...) Update: I am open to using coordinates (yes, I am a Sith lord now). But since I am not so familiar with this approach, can someone please enlighten me? Update 2: The operation above $\nabla{(\nabla{G}\times\nabla{H)}}$ does not make sense unless we think of $\nabla$ as a Jacobian. This makes me even more confused...","['poisson-geometry', 'differential-geometry']"
3180580,Are there any other methods to apply to solving simultaneous equations?,"We are asked to solve for $x$ and $y$ in the following pair of simultaneous equations: $$\begin{align}3x+2y&=36 \tag1\\ 5x+4y&=64\tag2\end{align}$$ I can multiply $(1)$ by $2$ , yielding $6x + 4y = 72$ , and subtracting $(2)$ from this new equation eliminates $4y$ to solve strictly for $x$ ; i.e. $6x - 5x = 72 - 64 \Rightarrow x = 8$ . Substituting $x=8$ into $(2)$ reveals that $y=6$ . I could also subtract $(1)$ from $(2)$ and divide by $2$ , yielding $x+y=14$ . Let $$\begin{align}3x+3y - y &= 36 \tag{1a}\\ 5x + 5y - y &= 64\tag{1b}\end{align}$$ then expand brackets, and it follows that $42 - y = 36$ and $70 - y = 64$ , thus revealing $y=6$ and so $x = 14 - 6 = 8$ . I can even use matrices ! $(1)$ and $(2)$ could be written in matrix form: $$\begin{align}\begin{bmatrix} 3 &2 \\ 5 &4\end{bmatrix}\begin{bmatrix} x \\ y\end{bmatrix}&=\begin{bmatrix}36 \\ 64\end{bmatrix}\tag3 \\ \begin{bmatrix} x \\ y\end{bmatrix} &= {\begin{bmatrix} 3 &2 \\ 5 &4\end{bmatrix}}^{-1}\begin{bmatrix}36 \\ 64\end{bmatrix} \\ &= \frac{1}{2}\begin{bmatrix}4 &-2 \\ -5 &3\end{bmatrix}\begin{bmatrix}36 \\ 64\end{bmatrix} \\ &=\frac12\begin{bmatrix} 16 \\ 12\end{bmatrix} \\ &= \begin{bmatrix} 8 \\ 6\end{bmatrix} \\ \\ \therefore x&=8 \\ \therefore y&= 6\end{align}$$ Question Are there any other methods to solve for both $x$ and $y$ ?","['systems-of-equations', 'linear-algebra', 'big-list']"
3180595,Can we prove the irrationality of pi from its expression as a limiting product with the nested square roots?,"Is it possible to prove the irrationality of $ \pi $ from the expression $ \pi = Lim_{m \to \infty} [2^m(\sqrt(2-\sqrt(2+\sqrt(2+...)...)))]$ , where there are $m$ square roots in the nested expression? This expression is obtained by considering the ratio of the perimeter of a regular $n$ -sided polygon to the diameter of its circumcircle and then letting $ n \to \infty$ . This expression was found by Archimedes I think.But didn't see Archimedes' name as one of those proving the irrationality. Makes me suspect whether this can be done. Can anyone please provide me a method (if it exists)? Any indirect method starting from here would be fine.","['number-theory', 'calculus', 'geometry']"
3180658,Is a proof of the Law of Cosines using the Pythagorean Theorem inherently circular?,"We're doing Basic Mathematics for Introductory level Physics in class, and my prof. illustrated a proof of the Law of Cosines. This he did by considering the following triangle and making use of the Pythagorean Theorem. Proposed Proof : Let $AB=c$ , $AC=b$ , $BC=a$ . $\angle ADC$ by construction is a right angle, so the Pythagorean Theorem applies here. Also $AD=b\cos\theta$ and $CD=b\sin\theta$ where $\theta$ is the same as $\angle CAD$ . Using Pythagorean Theorem we have: $(c+b\cos\theta)^2+(b\sin\theta)^2=c^2$ . All that is to be done now is to rewrite $\theta=180^{\circ}-A$ and the result follows. However is this proof not circular because it assumes the Pythagorean Theorem being true which itself is a special case of the Law of Cosines at $\theta=90^{\circ}$ ? Is this proof valid?","['trigonometry', 'proof-verification']"
3180674,"If you have a prime, and a claim that it's the nth prime, is there a fast way to check?","I know there are fast ways to rule it out for special cases, but assuming it is actually true, how fast can you verify it? I also wonder about sequences the primes are a subset of such as OEIS A050376 and A000961, whether verifying an index is any easier in those.","['number-theory', 'prime-numbers']"
3180682,Passing to weak-strong limit in pointwise inclusions,"Let $F:\mathbb R^m\rightrightarrows\mathbb R^n$ be a set-valued map (or multi-function, correspondence) with $F(x)\ne\emptyset$ for all $x\in \mathbb R^m$ . Let $I\subset\mathbb R$ be an interval.
  Let be sequences of functions $(y_n)$ and $(x_n)$ in $L^2(I,\mathbb R^n)$ and $L^2(I,\mathbb R^m)$ be given such that $x_n(t) \to x(t)$ for almost all $t\in I$ , $y_n \rightharpoonup y$ in $L^2(I,\mathbb R^n)$ $y_n(t) \in F(x_n(t))$ for almost all $t\in I$ . If $F$ satisfies certain properties then this implies $$
y(t) \in \overline{conv} ( F(x(t))) 
$$ for almost all $t\in I$ . This is proven in the book of Aubin & Frankowska under the assumption that $F$ is outer semicontinuous (i.e., the graph of $F$ is closed) and local boundedness of $F$ (each point $x$ has a small neighborhood $U$ such that $F(U)$ is bounded). In the book by Aubin & Cellina, $F$ is assumed to be upper hemicontinuous ( $x\mapsto \sup_{y\in F(x)}y^Tp$ is upper semicontinuous for all $p$ ). The following mapping $F$ does not satisfy these assumptions: $$
F(x) = \begin{cases} \{0\} & x\le 0\\
\{0,\frac 1x\} & x>0\end{cases}.
$$ My question is: is the statement of the theorem true or false for this kind of map? Can one find a counterexample? Is there a complete characterization of properties of $F$ to reach the conclusion?","['set-valued-analysis', 'functional-analysis']"
3180686,How do I properly do back substitution and put equations into the form of Bezout's theorem after using the Euclidean Algorithm?,"For some problems, even longer ones, I've been able to see the pattern and properly do back substitution to bring a series of equations I've derived using the Euclidean algorithm to the form of Bezout's theorem: $sa+tm$ Where $s$ and $t$ are parameters. But, on some problems I get stuck and have no idea how to move forward. For example, starting from finding the $gcd(3454,4666)$ : Using the Euclidean Algorithm I find: $4666 = 3454 * 1 + 1212$ ------------- $1212 = 4666 - 3454 * 1$ $3454 = 1212 * 2 + 1030$ ---------------- $1030 = 3454 - 1212 * 2$ $1212 = 1030 * 1 + 182$ ----------------- $182 = 1212 - 1030 *1$ $1030 = 182 * 5 + 120$ ------------------ $120 = 1030 - 182 * 5$ $182 = 120 * 1 + 62$ --------------------- $62 = 182 - 120 * 1$ $120 = 62 * 1 + 58$ ---------------------- $58 = 120 - 62*1$ $62 = 58 * 1 + 4$ ------------------------ $4 = 62 - 58 * 1$ $58 = 4 * 14 + 2$ ------------------------ $2 = 58 - 4 * 14$ For my first step I substitute for the $4$ : $2 = 58 - (62 - 58) * 14$ Where do I go from here? What are some general strategies to solve problems of this form? I'm having an inordinately hard time with some of these problems, but find others trivial--what is going on? What should I look out for when approaching problems of this type? If you would like me to clarify content, please ask me such and I will edit accordingly. Thank you for taking the time to read this!","['cryptography', 'euclidean-algorithm', 'modular-arithmetic', 'discrete-mathematics']"
3180688,Solve this specific large sparse system of linear equations,"I want to solve the system $Ax = b$ where $A \in \mathbb R^{n \times n}$ and $b \in \mathbb R^n$ with $n \approx 10^6$ . If $A$ would be a fully dense matrix this would be hopeless of course but luckily the matrix is sparse and highly structured. The matrix $A$ can be written as \begin{align}
A = \begin{pmatrix}
B_0 & B_1 &     &     &     \\
    & C_1 & B_2 &     &     \\
    &     & C_2 & B_3 &     \\
    &     &     & C_3 & B_4 \\
D   &     &     &     & C_4 \\
\end{pmatrix}
\end{align} where $B_i$ are upper triangular matrices, $C_i$ are diagonal with each entry being equal to $-1$ , and $D$ is a square matrix. The figure below provides a schematic overview of $A$ where every possibly nonzero entry is green and all zeroes are gray. The upper triangular matrices $B_i$ have approximately the same structure but do not necessarily have the same entry values. The submatrices $B_i$ , $C_i$ , and $D$ typically have dimension $m\times m$ with $m \approx 10^5$ . I don't know whether it is useful, but we also know for all non-zeroes with $i \neq j$ that $a_{ij} \in (0, 1]$ and the entries on the diagonal equal $-1$ except for the part that overlaps with $B_0$ , i.e., we have $C_i = -I$ . Note that the corresponding system $(A + I)y = b$ , where $I$ is an identity matrix, is relatively easy to solve as the submatrices $C_i$ become null matrices. Then we can first solve $D \hat x = \hat b$ where $\hat x$ and $\hat b$ are the last entries of $x$ and $b$ . Next, we can iteratively solve the triangular matrices one by one starting with the one closest to the bottom. Maybe we can use the solution $y$ (or a transformation of $y$ ) as an initial solution for $x$ for an iterative approach. Is there a better way to solve this system compared to naively feeding the system to a solver such as Matlab or LAPACK? EDIT 1: Green entries indicate a possibly positive value. However, for the square at the bottom, around half of the entries are expected to be zero. EDIT 2: Given the enormous size of this problem, approximate methods are also more than welcome.","['systems-of-equations', 'matrices', 'linear-algebra', 'sparse-matrices', 'block-matrices']"
3180813,Regularity of infinity harmonic functions in $~\mathbb{R}^{2}~$.,"Lets consider the PDE $\Delta_{\infty}f=0$ . The function $f(x,y)=x^{4/3}-y^{4/3}$ is a viscosity solution of that PDE. It has been shown that viscosity solutions of $\Delta_{\infty}f=0$ in an open set $U$ of $\mathbb{R}^{2}$ belongs to $C^{1}(U)$ . In particular, it is said that $f$ belongs to $C^{1,1/3}(\mathbb{R}^{2})$ , but I'm not able to demostrate this fact. Does anyone know how to do that? In every article I read, it's written that it's an ""easy matter"" to prove it. But for me it's not! Thanks a lot.","['real-analysis', 'functional-analysis', 'partial-differential-equations', 'inequality', 'holder-spaces']"
3180887,Sigma algebras generated by independent sets of events,"I am interested in knowing wether the following statement is true of false. Let $ (\Omega, \Sigma , \mathbb{P})$ be a probability space and $\mathcal{A}, \mathcal{B} \subseteq \Sigma$ independant subsets. Then $\sigma A(\mathcal{A})$ and $\sigma A(\mathcal{B})$ are independent sigma algebras. I think the statement is true but haven't been able to finish the proof. What I've done thus far is the following. First define $\{M \in \Sigma : \forall A \in \mathcal{A} \text{ it holds } A, M \text{ independent}\}$ and I claim that it's a sigma algebra. Assuming that's true and since it contains $\mathcal{B}$ . This implies that it must contain $\Sigma_2 = \sigma A(\mathcal{B})$ . We then define the set $\{M \in \Sigma : \forall B \in \Sigma_2 \text{ it holds } B, M \text{ independent}\}$ Then clearly by the last part this set contains $\mathcal{A}$ . I think here (were we able to probe that the first set is a sigma algebra) we should be able to recycle the argument to show that this new set is also a sigma algebra. This would imply $$\Sigma_1 \subseteq  \{M \in \Sigma : \forall B \in \Sigma_2 \text{ it holds } B, M \text{ independent}\}$$ where $\Sigma_1 = \sigma A(\mathcal{A}) $ so we would be done. Now I just have to show that $\mathcal{O}=\{M \in \Sigma : \forall A \in \mathcal{A} \text{ it holds } A, M \text{ independent}\}$ is a sigma algebra. But I have been unable to do so. The part that I'm having trouble with is the countable union part. UPDATE: So as someone in the comments suggested if we restrict the case to only showing that the countable union of pairwise disjoint elements $M_n$ is still in $\mathcal{O}$ we get the result directly since. \begin{align} \mathbb{P}(A \cap (\cup_{i=1}^\infty M_n)) &= \mathbb{P}( \cup_{i=1}^\infty (A \cap M_n))\\
&= \sum_{i=1}^\infty \mathbb{P}(A \cap M_n)\\
&=\sum_{i=1}^\infty \mathbb{P}(A)\mathbb{P}(M_n)\\
&=\mathbb{P}(A)\mathbb{P}(\cup_{i=1}^\infty M_n)
\end{align} However I was still unable to show that it's possible to restrict the general case to that case. I tried using induction on the sequence $M_n' = M_n \setminus (\cup_{i=1}^{n-1} M_i')$ but failed.","['measure-theory', 'independence', 'probability-theory', 'probability']"
3180888,Chi square goodness of fit test for Exp(1) in r,"Our teacher has posted the following task:
We have 100 random numbers in our disposal that come from Exp(1) and the task is to perform the chi square test in order to check if the numbers come indeed from Exp(1)(he basically wants us to get more confortable with the r environment,so we have to look for everything by ourselves*).
Although i know how to perform the test and answer about the null hypothesis based on the pvalue, i have no clue on how to separate the interval from zero to infinity(in the r environment)We need that in order to calculate the probabilities. I also have in mind that we need all our expected values to be bigger than 5. Any ideas? *we are amateurs who started using r one week ago,we are familiar with basic stuff only.","['chi-squared', 'statistics']"
3180889,Is there a Visualization of sets other than Venn diagram?,Is there a visualization of sets other than Venn diagram?,['elementary-set-theory']
3180898,The probability of double chance being a good or bad virus when killing a virus and automatically double itself every time,"This is a question I read somewhere else and think so much about getting an answer, but still struggling. Here is the problem: I have 9 virus which is 5 of them are good, and 4 of them are bad. Every time I kill a virus, it dies, and 2 viruses will be born from its body which is having 50-50 chances to be a good or bad virus. What is the probability that after 100 times I kill a virus randomly and the amount of bad virus is zero? Which probability formula or theory should I learn to solve this one? Thanks.","['statistics', 'conditional-probability', 'probability-distributions', 'probability-theory', 'probability']"
3180904,Error in Algebraic Curves by Fulton?,"The following lemma is from section 3.3 of Fulton's algebraic curves. Notation: $\psi$ is a map from $k[X,Y]/I^n×k[X,Y]/I^m$ to $k[X,Y]/I^{m+n}$ I'm having some difficulty understanding the paragraph marked in yellow. Should it be $r<n$ or $s<m$ instead? Otherwise, how does it follow that $r+m=s+n$ and $A_rF_m=-B_sG_n$ ? I realize that this must have something to do with the degree of $A_rF_m$ or $B_sG_n$ being less than $m+n$ , but it seems to me as though this doesn't follow from the premise $r<m$ or $s<n$ (although replacing or with and seems to suffice ).","['algebraic-curves', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3180906,limit of a series homework question,"I need some help with this question. The question: Prove or disprove the following statement: If $$a_n\cdot a_{n+1} \rightarrow 0$$ and $a_n > 0$ for all $n$ , then $$a_n \rightarrow 0$$ Solution attempt: The solution I was given disproves this statement using an example (which I understand): $$a_n = \left\{\begin{matrix}
1\quad & {n\quad odd} \\ 
\frac{1}{n}\quad &  n \quad even
\end{matrix}\right.$$ but I don't understand what is wrong with this proof: For all $\epsilon>0$ , there exists an $N$ so that for all $n\geq N$ , $a_n\cdot a_{n+1} < \epsilon$ . Therefore (because $a_n > 0$ for all $n$ ): $$a_n<\frac{\epsilon}{a_{n+1}}<\epsilon$$ which prooves the statemant. Can anyone explain what I am doing wrong?","['limits', 'calculus']"
3180910,Degree of splitting field of $X^4+2X^2+2$ over $\mathbf{Q}$,"Find the degree of splitting field of $f=X^4+2X^2+2$ over $\mathbf{Q}$ . By Eisenstein, $f$ is irreducible. By setting $Y=X^2$ , we can solve for the roots: $Y=-1\pm i \iff X=\sqrt[4]{2}e^{a\pi i/8}$ , $a\in\{3,5,11,13\}$ . Clearly $f$ splits in $\mathbf{Q}(\sqrt[4]{2},\zeta_{16})$ . $\zeta_{16}$ is a zero of $X^8+1$ , which is irreducible over $\mathbf{Q}$ by Eisenstein applied to $(X+1)^8+1$ . I was not able to go further. Could someone help me to proceed?","['irreducible-polynomials', 'galois-theory', 'abstract-algebra', 'splitting-field', 'quartics']"
3180987,How to prove the expanding Ricci soliton is Einstein metric?,"As picture below ,I want to prove the expanding Ricci soliton is Einstein metric. I can get $R+\Delta f-n\lambda=0$ . Besides ,I want to prove $R+|\nabla f|^2= C$ for some constant $C$ . But fail. I just get $R+|\nabla f|^2-2\lambda f=C'$ . So, how to do it ? Just give a little hint is enough . Thanks. Picture below is from the 176 page of paper . And, the definition of expanding Ricci soliton can be found in here .","['soliton-theory', 'riemannian-geometry', 'ricci-flow', 'partial-differential-equations', 'differential-geometry']"
3181047,Bernoulli numbers and $\pi^2$.,"It is probably well-known that: $$
\lim_{n\to\infty}\frac{b_{2n}n^2}{b_{2n+2}}=-\pi^2,
$$ where $b_n$ are the Bernoulli numbers. By a numerical experiment I have found that the quotient $$
\frac{b_{2n}(n+a_1)(n+a_2)}{b_{2n+2}}
$$ with $a_1=1, a_2=\frac12$ converges to $-\pi^2$ extremely fast. Already $n=35$ gives correctly 20 decimal places of $\pi^2$ ! No other combination of $a_1$ and $a_2$ is even nearly close to this result. For example $a_1=a_2=\frac12$ gives only two correct decimal places for $n=400$ . What is the secret of this extremely good convergence for $a_1=1, a_2=\frac12$ ?","['rate-of-convergence', 'pi', 'bernoulli-numbers', 'sequences-and-series', 'limits']"
3181050,Can we apply L'Hopital's rule where the derivative is not continuous?,"My doubt arises due to the following : We know that the definition of the derivative of a function at a point $x=a$ , if it is differentiable at $a$ , is: $$f'(a) = \lim_{h \rightarrow 0} \frac {f(a+h) - f(a)}{h}$$ Suppose that the function $f(x)$ is differentiable in a finite interval $[c,d]$ and $a \in (c,d) $ So, we can apply L'Hopital's rule. On differentiating numerator and denominator with respect to $h$ , we get: $$f'(a) = \lim_{h \rightarrow 0} \frac {f(a+h) - f(a)}{h} = \lim_{h \rightarrow 0} \frac {f'(a+h)}{1}$$ Which implies that $$f'(a) = \lim_{h \rightarrow 0} f'(a+h)$$ Which means that the function $f'(x)$ is continuous at $x=a$ But this not necessarily true. A function may have a derivative everywhere but its derivative may not be continuous at some point. One of many counterexamples is: $$f(x) = \begin{cases} 0 \text{ ;    if x=0} \\ x^2 \sin \frac{1}{x} \text{;       if x $\neq$ 0 } \end{cases}$$ Whose derivative isn't continuous at $0$ So, is something wrong with what I have done ? Or is it necessary that for applying L'Hopital's rule, the function's derivative must be a continuous function? If the latter is true, why does that condition appear in the proof for L'Hopital's rule ?","['limits', 'derivatives', 'continuity']"
3181058,An interesting formula for $\pi$,"Looking through some old notebooks I found this monster of a formula: For any integer $r>1$ , we have $$\pi=(-1)^{\left\lfloor\frac{r}{2}\right\rfloor-\left\lfloor\frac{2r-1}{4}\right\rfloor}\sum_{n=1}^\infty \frac{(2r-1)((2r-1)(n-1))!}{(n(2r-1)-1)!}\left(\sum_{k=1}^{\left\lfloor\frac{2r-1}{2}\right\rfloor} (-1)^{f(k,r)}\frac{\cot\left(\frac{\pi kr}{2r-1}\right)}{(2r-3)!} {2r-3\choose g(k,r)}\right)^{-1},$$ where we have $$f(k,r)=k+1+\frac{1}{2} \left(\left\lfloor \frac{2r-1}{4}\right\rfloor -\left\lfloor \frac{r}{2}\right\rfloor+k-1\right) \left(\left\lfloor \frac{2r-1}{4}\right\rfloor -\left\lfloor \frac{r}{2}\right\rfloor+k\right)$$ and $$g(k,r)=k \left\lfloor \frac{2r-1}{2}\right\rfloor -1\ \% \ 2 r-1,$$ with $\%$ denoting the modulo operation. It's kind of messy but I can't seem to simplify it much more. A number of years have passed since I found it and I don't even remember how I derived it (also, I haven't done any mathematics for over five years so I'm kind of rusty). I'm pretty sure it has something to do with rising or falling factorials though. It seems to converge pretty quickly. To get the first one thousand decimals of $\pi$ with, say $r=300$ , we don't really need the series to go to infinity, $17$ will suffice. So, my question is if anyone knows anything about this formula. Is it well-known? Are there any other, similar formulas? What's going on with the cotangents? I have a hard time ""visualizing"" what's going on (and I really wish I kept better, more detailed notes). Edit: If anyone is interested, here is more compact (and hopefully more legible) version which holds true if and only if $r\equiv 3\pmod{4}$ : $$\pi=\sum_{n=1}^\infty \frac{r(r(n-1))!}{(nr-1)!}\left(\sum_{k=1}^{\frac{r-1}{2}} i^{k (k-1)-2}\frac{\cot\left(\frac{\pi k(r+1)}{2r}\right)}{(r-2)!} {r-2\choose \frac{k (r+1)-2}{2}\ \% \ r}\right)^{-1}.$$ Edit 2 (some background): Just to give some context: I think this formula grew out of the study of series such as $$\sum_{n=1}^{\infty} (rn)_{1-r}=\sum_{n=1}^{\infty}\left(\prod_{i=1}^{r-1}(rn-i)\right)^{-1}=\sum_{n=1}^{\infty}\frac{1}{(rn-1)(rn-2)\cdots (rn-r+1)},$$ where $(n)_r$ is the Pochhammer symbol. The basic idea is that $$\sum_{\substack{\gcd(r,a_i)=1 \\ a_i<r}}^{\infty}\frac{A}{(rn-1)(rn-a_1)\cdots (rn-a_s)}=\pi,$$ for some (increasingly unruly and complicated) factor $A$ . For example: $$\sum_{n=1}^{\infty}\frac{8}{(4n-1)(4n-3)}$$ $$\sum_{n=1}^{\infty}\frac{\frac{150}{\sqrt{250-110\sqrt{5}}}}{(5n-1)(5n-2)(5n-3)(5n-4)}$$ $$\sum_{n=1}^{\infty}\frac{8\sqrt{3}}{(6n-1)(6n-5)}$$ and for $r=7$ the factor looks something like this: $$-\frac{5040 (-1)^{4/7} \left(2 \sqrt[7]{-1}-2 (-1)^{5/7}+(-1)^{6/7}-1\right) \sqrt[3]{26767+44439 i \sqrt{3}}}{56 i \sqrt[3]{26767+44439 i \sqrt{3}}+\sqrt[3]{14} \left(\sqrt[3]{2} \left(26767+44439 i \sqrt{3}\right)^{2/3} \left(\sqrt{3}-i\right)-1238 \sqrt[3]{7} \left(\sqrt{3}+i\right)\right)}.$$ Moving around some terms here and there I guess we end up with the infinite series of factorials to the left and $A$ being the inverted sum on the right. What would be cool to know is if there's any way of simplifying the whole binomial-mod-thing. Any thoughts are welcome!","['pochhammer-symbol', 'pi', 'factorial', 'sequences-and-series']"
3181122,Finding Angle using Geometry,"In an equilateral triangle $ ABC $ the point $ D $ and $ E $ are on sides $ AC $ and $AB$ respectively, such that $ BD $ and $ CE $ intersect at $P$ , and the area of the quadrilateral $ ADPE $ is equal to area of $ \Delta BPC $ find $ \angle BPE $ . 
This question when I first tried looked easy and I was also able to guess the answer but when I tried to proof, was not able to work it out. I want some help. Thank you. No image was provided in question. I am attaching my drawing.","['euclidean-geometry', 'triangles', 'area', 'geometry']"
3181171,Number of equal triangles in a chessboard,"$1\times 1$ is cut and taken out from every corner of a $8\times 8$ chess board. At least, how many equal triangles (equal triangles means congruent triangles, and color is not important) can be drawn on the remaining figure? What is the answer when we cut a $1\times 1$ from a single corner of chessboard? For the first part of the question I cover chessboard by 20 equal triangles after removing corners like this: Is less than this possible?","['contest-math', 'combinatorics', 'geometry']"
3181199,Is the gradient of the self-intersections of a curve zero?,"Suppose a curve with self-intersections can be described by $\phi(x,y)=0$ . Suppose the intersections are $T_i$ , $i=1,2,...$ and the gradient $\nabla \phi$ at those intersections are well defined. Then is it true that $\nabla\phi(T_i)=0$ for all $i$ ? In other words, are the gradients at those intersections all zero?","['calculus', 'differential-geometry', 'geometry', 'real-analysis']"
3181228,Understanding literature - defining a matrix operation in a basis independent manner,"I have been reading some notes: Vector Symmetries by Lyubashenko and I'm looking to understand some of the works to apply to my own research. In it, he writes a matrix operation in a basis independent way so that it may be used in the context of operators. Essentially, he defines the ""sharp"" operation on a matrix $M: \mathcal{V} \otimes \mathcal{V} \to \mathcal{V} \otimes \mathcal{V}$ (where $\mathcal{V}$ is a finite dimensional vector space) as $$(M^{\#})^{\alpha \beta}_{\delta \gamma} = M^{\beta \gamma}_{\alpha \delta}$$ He then goes on to describe the same operation on an operator $T: \mathcal{H} \otimes \mathcal{H} \to \mathcal{H} \otimes \mathcal{H}$ ( $\mathcal{H}$ a Hilbert space). He says ""Let $T^{\#} : \mathcal{H}\otimes \mathcal{H}^* \to \mathcal{H}^*\otimes \mathcal{H}$ ( $\mathcal{H}^*$ the duel space of $\mathcal{H}$ ) and let an element $h_1^* \otimes h_2^* \otimes h_1 \otimes h_2 \in \mathcal{H}^* \otimes \mathcal{H}^* \otimes \mathcal{H}\otimes \mathcal{H}$ represent $T$ . After a cyclic rearrangement of factors, it yields $h_2 \otimes h_1^* \otimes h_2^* \otimes h_1$ that represents the operator $T^{\#}$ via $$T^{\#}(\eta \otimes \xi^*) = \langle h_2, \xi^*\rangle \langle \eta, h_1^*\rangle h_1^*\otimes h_2.$$ "" My questions are: What does it mean for an element to ""represent an operator""? Does this ""cyclic rearrangement of factors"" corresponds to the 'rotation' of indices in the matrix case? How does this formula definition get applied in calculation? For example, we have the operator $F$ defined as $F(\eta \otimes \xi) = \xi \otimes \eta$ . This operator should be invariant under the sharp operation, i.e $F^{\#} = F$ , but how do we show this using the expression above? Furthermore, how is this definition consistent with the matrix case? I apologise for the list of questions, and I'm very grateful for help.","['operator-theory', 'functional-analysis']"
3181284,"Equality of sets, transitive closure of a relation.","We can prove that the intersection of a set of transitive relations in a set $ A $ is also a transitive relation in the set $ A $ . With this, given $ S \subset A \times A $ we can find the lowest transitive relation that contains $ S $ that we call $ \overline {S} $ transitive closure. With this construction of the transitive closure I am trying to prove: $$\overline{S} = \{ (x,y) \in A \times A : \exists n\in \mathbb{N} \text{ and }a_0=x,a_1,...,a_n=y \text{ such that } (a_i,a_{i+1}) \in S \text{ for } 0\leq i<n \}$$ It's easy to show that $$\{ (x,y) \in A \times A : \exists n\in \mathbb{N} \text{ and }a_0=x,a_1,...,a_n=y \text{ such that } (a_i,a_{i+1}) \in S \text{ for } 0\leq i<n \} \subset \overline{S}$$ I can not show that $$\overline{S} \subset \{ (x,y) \in A \times A : \exists n\in \mathbb{N} \text{ and }a_0=x,a_1...,a_n=y \text{ such that } (a_i,a_{i+1}) \in S \text{ for } 0\leq i<n \}$$","['elementary-set-theory', 'relations']"
3181288,Under what conditions does Jensen's inequality hold with equality?,"From what I understand Jensen's Inequality is $$E(f(X))\leq f(E(X)) \;\text{ when $f$ is a concave function}$$ Are there any conditions on the distribution of $X$ (rather than the function f) under which this holds with equality: $E(f(X))=f(E(X))$ ? (eg. when $VAR(X)=0$ , $X$ is a constant so it should hold with equality) Also, is there any term $O$ which would make this true: $E(f(X)) = f(E(x)) + O $ (I was thinking some sort of Taylor Expansion) I am mainly interested in the case $f(x)=ln(x)$","['statistics', 'probability', 'inequality']"
3181349,Question related to amicable numbers not divisible by 3,"In a paper by W. Borho and S. Battiato, the authors show that there do exist odd amicable numbers which are not divisible by 3. For their examples they found a common factor: $a=5^{4}\cdot 7^{3}\cdot11^{2}\cdot 13^{2} \cdot 17^{2} \cdot 19 \cdot 61^{2} \cdot 97 \cdot 307$ . What I am trying to understand is if every odd amicable pair that is not divisible by $3$ (either member) must have this common factor $a$ or if this was just one example of such an $a$ ? Link to paper provided below in comment, sorry for poor link","['number-theory', 'elementary-number-theory']"
3181350,"Why is it the case that $\rm\langle Socrates\rangle = Socrates$, while $\rm\{Socrates\}\neq Socrates$?","In Nolt's book called Logics (part III, chapter 7, § 7.1 Sets and $n$ -tuples) one can read: Ordered one-tuples, unlike unit sets, are the same things as the object they contain. Thus , for example, the one-tuple $\rm (Socrates) = Socrates$ ; and more generally, for any object $x$ , $(x)  = x$ . Could you please explain Nolt's (too) short explanation (at least for me)? Is this explanation a way of saying that a "" $1$ -tuple"" is not a well defined object? Is there a way to derive the formula $(x) = x$ from the set theoretic definition of an $n$ -tuple?",['elementary-set-theory']
3181359,Existence of a function on some sets,"Let $A$ be a set of size $k^2$ , and let $B$ be another set. Assume that there exists a function $f : A \times B \to \{1,2\}$ such that the following holds: For every subset $A' \subseteq A$ of size $k$ and every function $g:A' \to \{1,2\}$ , there exists $x \in B$ such that $f(y,x) = g(y)$ for every $y \in A'$ . Clearly, we must have $|B| =\Omega(2^k)$ . What is the best asymptotic lower bound on $|B|$ in terms of $k$ ? e.g. is it possible that $|B| = O(2^k)$ or we must have something like $|B| = \Omega(2^{k\log{k}})$ ?","['functions', 'combinatorics', 'discrete-mathematics']"
3181394,Can we plug in values before evaluating a partial derivative?,"If $f(x,y)$ is a function, to compute $\partial f / \partial y$ at some point $(a,b)$ , is it always acceptable to plug in the value $a$ for $x$ before computing the derivative?  I am convinced the answer is ""yes"", and that no justification needs to be given: literally the definition of the partial derivative at a point $(a,b)$ involves doing this.  Is this correct (including the justification)? The source of my thinking about this question is Problem 2-19 in Spivak's Calculus on Manifolds , which asks us to compute $\partial f / \partial y$ at a point of the form $(1,y)$ , where $f$ is some more complicated version of $$f(x,y) = x^{x^y}.$$ Clearly the trick is to plug in $x = 1$ first, and I am convinced no justification for this step needs to be given, but something about it makes me nervous. Thank you!",['multivariable-calculus']
3181497,Hessian matrix equal to zero,"The function $x\times y + e^{-x\times y}$ has the points that form $x$ -axis and $y$ -axis as critical points, how can I prove that they are points of minimum, the Hessian matrix in those points is equal to zero.",['multivariable-calculus']
3181529,Confusion about non-derivable continuous functions,"I am reading a definition which claims that a function is continuous in point $p$ iff all its first derivations exist and are continuous in the point $p$ . And what confuses me are functions such as $f(x)=|x|$ which should be continuous by intuition, but is clearly not derivable in $x=0$ . I am almost certain I am getting something wrong here, but I can not even pin-point what.","['continuity', 'functions', 'derivatives', 'real-analysis']"
3181547,Dualizing Sheaf of $\tilde{\mathbb{P}}^{3}$,"Let $\pi :\widetilde{\mathbb{P}^{3}} \longrightarrow \mathbb{P}^{3}$ be the blowup of $\mathbb{P}^{3}$ along a regular curve $\mathcal{C}$ , with exceptional divisor $E$ . We know the following: If $X$ is a projective nonsingular variety over an algebraically closed field $\mathcal{K}$ , then dualizing sheaf $\omega^{\circ}_{X}$ is isomorphic to the canonical sheaf $\omega_{X}$ . What's the dualizing sheaf of $\widetilde{\mathbb{P}^3}$ ? Any help is welcome.",['algebraic-geometry']
3181603,How gradient transform under homotety,"Let $\Sigma^n \subseteq \mathbb{R}^{n+1}$ be a smooth hypersurface. 
Let $\lambda > 0$ be a constant and let define $\tilde{\Sigma} := \lambda \Sigma$ . Let $f$ be a smooth function on $\Sigma$ . This defines a function $\tilde{f}$ on $\tilde{\Sigma}$ as follows: for every $p \in \tilde{\Sigma}$ , $$
\tilde{f}(p) := f(\frac{p}{\lambda}).
$$ Let $V$ be a constant vector field in $\mathbb{R}^{n+1}$ . I would like to express $$
\langle \nabla^{\Sigma} f, V \rangle_{\mathbb{R}^{n+1}} 
$$ in terms of $\nabla^{\tilde{\Sigma}} f$ . On a point $p \in \tilde{\Sigma}$ it should hold \begin{equation}
\nabla^{\tilde{\Sigma}}\tilde{f}(p) = \frac{1}{\lambda^2} \nabla^{\Sigma}f(\frac{p}{\lambda}). \tag{1}
\end{equation} I obtain this formula from expressing the gradient in local coordinates and from the observation that the pull-back metric on $\Sigma$ induced by the metric on $\tilde{\Sigma}$ is basically $\tilde{g}_{ij} = \lambda^2 g_{ij}$ , where $g_{ij}$ is the metric on $\Sigma$ induced by the ambient Euclidean metric. But somehow I feel that there is something fishy. I would expect the gradient to scale as $\frac{1}{\lambda}$ and I would expect a formula of the kind: $$
\langle \nabla^{\Sigma} f(\frac{p}{\lambda}), V \rangle_{\mathbb{R}^{n+1}}  = \langle \nabla^{\tilde{\Sigma}} \tilde{f}(p), \lambda V \rangle_{\mathbb{R}^{n+1}}.
\tag{2}
$$ Can anyone help me? I'm getting very confused... EDIT : Consider the case where $f$ is the restriction on $\Sigma$ of a function $F : \mathbb{R}^{n+1} \to \mathbb{R}$ . We can always assume that, at least locally. Then it is known that $\nabla^{\Sigma} f = \left( \nabla^{\mathbb{R}^{n+1}} F|_{\Sigma}\right)$ . Therefore, given $p \in \tilde{\Sigma}$ , and identifying the tangent spaces $T_p \tilde{\Sigma}$ and $T_{\frac{p}{\lambda}} \Sigma$ we have: $$
\nabla^{\tilde{\Sigma}} \tilde{f}(p) = \left( \nabla^{\mathbb{R}^{n+1}} F(\frac{y}{\lambda}) \right)^{\top} = \frac{1}{\lambda} \left(\nabla^{\mathbb{R}^{n+1}} F \right)^{\top}(\frac{p}{\lambda}) = \frac{1}{\lambda} \nabla^{\Sigma}f(\frac{y}{\lambda}).
\tag{3}
$$ I now believe that $(3)$ is correct and from this $(2)$ follows. Therefore $(1)$ should be wrong. I think that I was mislead by the intrinsic approach showed in the answer by Trevis. I think I got confused from the fact that in the intrinsic approach one thinks about $\Sigma$ and $\tilde{\Sigma}$ as the same manifold but with different Riemannian metrics. The equation of Trevis is of course correct, but then my equation $(1)$ is wrong probably because one should be careful in translating the instrinsic equation back into the extrinsic situation. In fact the same abstract coordinates genereates two different local frames on $\Sigma$ and $\tilde{\Sigma}$ (as hypersurfaces) and one frame is the other one rescaled by a factor of $\lambda$ .","['homothety', 'riemannian-geometry', 'differential-geometry']"
3181635,The expected weight-ratio between weighted and un-weighted balls when picked from a bin without replacement,"The Problem The problem, I believe, can be stated in the following way: Given $K$ white balls all with without weight (one can say that the weight is $0$ ) and $N - K$ red balls with individual strictly positive weights $> 0$ , if $n \leq N$ balls are picked at uniformly random without replacement, what is the expected weight ratio between the $k$ selected balls' weights and the total sum of all $N-K$ red balls' weights? Comment: without any knowledge of neither how the weights are distributed among the red balls, nor of how many red balls there are compared to white, I guess that it could be the case that the answer is too general. I have, either way, not been able to come up with the precise algebraic formula for the solution. My Thoughts & Efforts I have in my efforts followed two trains of reasoning, none of which if followed could result in the sought after solution. They are mentioned as to point out that my approach has been towards finding ways that could give a rough idea of the bounds of a solution. The calculations are when no reference is found mostly my own calculation, and as such not reviewed by anyone, so consequently both these paths might be and likely are, subject to a high degree of miscalculations. I highly value any input. The Heaviest Ball (I) - Firstly, the heaviest ball is expected to be one of the first $\lceil {log\ N} \rceil + 1$ visited elements. This I believe can be shown by letting $X$ denote the random variable such that $X_i = 1$ for $1 \leq i \leq N$ represents the event of the heaviest ball being the $i:th$ ball being evaluated, and $X_i = 0$ of it not being the heaviest. For any specific $j$ the expected value of the heaviest being evaluated can be written as in (1). \begin{equation}
\mathbb E[X_i] = 0 \times P[X_i=0]  + 1 \times P[X_i=1] = P[X_i=1] \quad \quad (1)
\end{equation} If we assume that all such events are mutually independent and that the balls are picked without replacement, then the probability of $P[X_i=1]$ can be written as (2). \begin{equation}\label{fun:fun_ct}
P[X_i=1] = \frac{1}{N+1-i} \quad \quad (2)
\end{equation} The expected number of tries before an interval from the optimal solution follows from linearity of expectation over the random variables. \begin{align*}
\mathbb E[X] &= \sum_{i=1}^n P[X_i]\\
&= \sum_{i=1}^N (\frac{1}{N+1-i}) \\
&< \sum_{i=1}^N \frac{1}{i} \\
&\leq log(N) + 1 
\end{align*} From the Wikipedia page on harmonic series [1] the following relation is stated $\sum_{i=1}^{N} \frac{1}{i} \leq log(N) + 1$ which leads me to believe that if $n \geq log(N) + 1$ the, searched for, expected weight ratio should be bounded by $\frac{1}{N-K}$ . If this process is repeated for rounds $r := \lceil \frac{n}{\log(N) + 1} \rceil$ wherein for each round $n$ balls are picked, then by linearity of expectation , should we not receive a weight ratio bounded from above(?) by $\frac{r}{N-K}$ ? The Heaviest m Balls (II) - Secondly, with a arguably severe abuse of terminology, I say that the expected number of red balls after picking $n$ follows from the hypergeometric distribution such that $Y \sim Hypergeometric(N, N-K, n)$ and could, therefore, be expressed, by following the example in [2] , algebraically as the expression $\mathbb E[Y] = \sigma n$ where $\sigma := \frac{N-K}{N}$ . If one re-colors the $m$ heaviest red balls green such that $m < n$ , then by the same reasoning the expected number of green balls after picking $n$ balls, should be $\hat{\sigma} := \frac{N-m}{N}$ . The expected ratio should, therefore, be bounded from below by \begin{equation}
L := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=\hat{\sigma}n +1 }^{\sigma n} \beta^{j}} {\sum_{j=1}^{N-K}\alpha^{j}} 
\end{equation} where $\beta^j$ is the weight of $j:th$ lightest ball, and from above by \begin{equation}
U_1 := \frac{\sum_{j=1}^{\sigma n} \alpha^{j}}{\sum_{j=1}^{N-K}\alpha^{j}}  
\end{equation} where $\alpha^j$ is the weight of the $j:th$ heaviest ball. Comment: we have for the upper-bound here settled with the sequence of the heaviest weights, but if one could compute the expected number of index between $n\sigma$ and $n\hat{\sigma}$ and denote it $\mathbb E[I]$ , then the upper-bound can be tightened to \begin{equation}
U_2 := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=\hat{\sigma}n + \mathbb E[I]}^{\sigma n + \mathbb E[I]} \alpha^{j}} {\sum_{j=1}^{N-K}\alpha^{j}} 
\end{equation} It might actually be that case that $\mathbb E[I] = \mathbb E[X]$ I guess, and if that is maybe we could have \begin{equation}
U_3 := \frac{\sum_{j=1}^{\hat{\sigma} n} \alpha^{j} + \sum_{j=1}^{\sigma n - \hat{\sigma}n} \alpha^{j(log(N))}} {\sum_{j=1}^{N-K}\alpha^{j}} 
\end{equation} Conclusion Finally, my conclusion is that the expected ratio $\mathbb E[Z]$ must be in-between \begin{equation}
L  \leq \mathbb E[Z] \leq U_3 \leq U_2 \leq U_1
\end{equation} where $0 \leq Z \leq 1$ is a continuous random variable expressing the ratio in question.","['statistics', 'expected-value', 'discrete-mathematics', 'upper-lower-bounds', 'probability']"
3181647,Why is a set inclusion true regarding the maximum likelihood estimator?,"The following doubt regards a step of a proof of consistency of the maximum likelihood estimator in the case of independent NON identically distributed random variables. Assume the parameter space is given by $\Omega \subset \mathbb{R}$ , denote the maximum likelihood estimator on a sample of $n$ INID random variables $Y_1, \dots, Y_n$ , that have probability densities respectively $f_1(y; \theta) , \dots, f_n(y;\theta)  $ ,  by $\hat{\theta}_n$ and the true parameter value $\theta_0$ . The maximum likelihood estimator $\hat{\theta}_n$ in this framework is taken to be the value that maximizes (for simplicity let's assume it exists) $$\ln \prod_{i= 1 }^n  f_i(Y_i; \theta)$$ Define $\Omega(\eta) := \Omega \setminus B(\theta_0, \eta) $ where $B(a,r)$ is the open ball centered at $a$ of radius $r$ and $\eta > 0$ . Define $$R_n^* = \sup_{\theta} \{ \ln \prod_{i= 1 }^n [ f_i(Y_i; \theta) / f_i( Y_i; \theta_0)  ] : \theta \in \Omega(\eta)   \}$$ I want to prove that $\{ \hat{\theta}_n \in \Omega(\eta)  \} \subset \{ R_n^* \ge 0   \}$ , how can this be seen?","['optimization', 'statistics']"
3181696,How to change the limits of integration,I am attempting to solve the integral of the following... $$\int_{0}^{2 \pi}\int_{0}^{\infty}e^{-r^2}rdr\Theta $$ So I do the following step... $$=2 \pi\int_{0}^{\infty}e^{-r^2}rdr$$ but then the next step is to substitute $s = -r^2$ which results in... $$=2 \pi\int_{- \infty}^{0}\frac{1}{2}e^{s}ds$$ The limits of integration are reversed now and the $r$ somehow results in $1/2$ . Can someone explain why this works? Why did substituting cause the limits change and result in the integration above?,"['integration', 'limits', 'calculus']"
3181770,Characterizing group operation properties by its multiplication table,"Let $G = \{x_1,\dots, x_n\}$ be a set equipped with an operation $*$ . Let $A = [a_{ij}]$ be its multiplication table, $a_{ij} = x_i*x_j$ . Assume $G$ has a identity $e$ (such that $e*x=x*e=x$ for all $x\in G$ ). Show that every element $x\in G$ has a two sided inverse (i.e., there is a $x'\in G$ with $x*x' = x'*x = e$ ) if and only if the multiplication table $A$ is an Latin square; that is, no $x\in G$ is repeated in any row or column (= every row or column is a permutation of $G$ ). If every $x$ has a inverse, then given $a_{ij} = a_{ik}$ for $1\le i,j,k\le n$ then $x_i*x_j = x_i*x_k$ and multiplying by $x_i^{-1}$ in the left on both sides we get $x_j = x_k$ then no two elements in distinct positions in line $i$ are equal. The same applies for columns using inverses in the right. Then $A$ is Latin square. But I'm struggling with the converse. Given $x_i\in G$ , there is a $a_{ij}$ in line $i$ such that $x_i*x_j = e$ and in the column $i$ there is a $a_{ki}$ such that $x_k*x_i = e$ , and I must show that $x_j = x_k$ . I tried other similar ways to write these multiplications but I don't see how to show the equality without using associativity (which is not assumed). Thanks for the help.","['group-theory', 'abstract-algebra', 'finite-groups']"
3181774,What is the purpose of $\frac{1}{\sigma \sqrt{2 \pi}}$ in $\frac{1}{\sigma \sqrt{2 \pi}}e^{\frac{(-(x - \mu ))^2}{2\sigma ^2}}$?,"I have been studying the probability density function... $$\frac{1}{\sigma \sqrt{2 \pi}}e^{\frac{(-(x - \mu ))^2}{2\sigma ^2}}$$ For now I remove the constant, and using the following proof , I prove that... $$\int_{-\infty}^{\infty}e^{\frac{-x^2}{2}} = \sqrt{2 \pi }$$ The way I interpret this is that the area under the gaussian distribution is $\sqrt{2 \pi }$ . But I am still having a hard time figuring out what the constant is doing. It seems to divide by the area itself and by $\sigma$ as well. Why is this done?","['statistics', 'probability-distributions', 'normal-distribution', 'gaussian-integral', 'probability']"
3181775,"$n/5$, $(n-1)/2$, $(n-2)/3$, $(n-3)/4$ are prime numbers, what is the 18-digit $n$?","$n$ is an 18-digit number, while $n/5$ , $(n-1)/2$ , $(n-2)/3$ , $(n-3)/4$ are all primes.  Find $n$ . Is there a theorem that can solve this kind of problem? For example, The Chinese Remainder Theorem could solve issues that if one knows the remainders of the Euclidean division of an integer $n$ by several integers, then one can determine uniquely the remainder of the division of $n$ by the product of these integers, under the condition that the divisors are pairwise coprime. However, this question is one step further, constraints are not only on the remainder but also on quotients. So, are there related theorems, or such kind of questions are to be solved by brute force?",['number-theory']
3181789,If $t_n=\frac{1}{2n+1}-\frac{1}{2n+2}+\frac{1}{2n+3}-\frac{1}{2n+4}+\cdots +\frac{1}{4n-1}-\frac{1}{4n}$. Find $\lim_{n \to \infty} nt_n$,"If $t_n=\frac{1}{2n+1}-\frac{1}{2n+2}+\frac{1}{2n+3}-\frac{1}{2n+4}+\cdots +\frac{1}{4n-1}-\frac{1}{4n}$ Find $\lim_{n \to \infty} nt_n$ First attempt: $t_n$ is positive(grouping two terms and performing subtraction we will get it) so is $nt_n$ . Now can we prove it is monotonically decreasing? If so then $\lim_{n \to \infty} nt_n=\lim_{n \to \infty}[(\frac{1}{2+1/n}-\frac{1}{2+2/n})+(\frac{1}{2+3/n}-\frac{1}{2+4/n})+\cdots +(\frac{1}{4-1/n}-\frac{1}{4})]$ and each of these terms will go to zero so is the limit. Second attempt: I was trying to use Riemann summation $t_n=\frac{1}{2n+1}-\frac{1}{2n+2}+\frac{1}{2n+3}-\frac{1}{2n+4}+\cdots +\frac{1}{4n-1}-\frac{1}{4n}=
\frac{1}{2n+1}+\frac{1}{2n+2}+\frac{1}{2n+3}+\frac{1}{2n+4}+\cdots +\frac{1}{4n-1}+\frac{1}{4n}-2[\frac{1}{2n+2}+\frac{1}{2n+4}+\cdots \frac{1}{4n}]\Rightarrow \lim \frac 1n [nt_n]=\int_0^2\frac{dx}{2+x}-\int_0^1\frac{dx}{1+x}=\ln4-\ln 2-\ln 2=0$ So $\lim t_n=0$ So what will happen with $\lim nt_n$ Edit: As I got the answer is not $0$ because of the flaw. So can we have different approaches even with Riemann Sum to have the answer?","['proof-verification', 'analysis', 'real-analysis', 'calculus', 'sequences-and-series']"
3181798,show solutions of $y'' + p(t)y' + y = 0$ tend to 0,"I'm trying to show that, if $p$ is a continuous periodic function (with period 1, but I don't think it matters), then all solutions to $y'' + p(t)y' + y = 0$ go to $0$ at $t=\infty$ . I can show that $y' \to 0$ , but I'm not sure if this is helpful. I know that, in general, a vanishing derivative does not imply a convergent antiderivative, but I'm hoping that is the case in the context of this particular ODE.","['calculus', 'ordinary-differential-equations']"
3181833,Proving Talagrand's contraction lemma for Gaussian processes with the Banach fixed-point theorem,"I've done the standard proof of Talagrand's contraction lemma for Gaussian processes (see Exercise 7.2.13 in Vershynin's High-Dimensional Probability ) using the Sudakov-Fernique inequality as suggested. Here's my proof: We let $T\subset \mathbb{R}^n$ be bounded and $Z$ be a standard $n$ -variate normal vector. Letting $f : \mathbb{R}^n\to \mathbb{R}^n$ be a contraction mapping, we will show that $$\mathbb{E}[\sup_{t\in T} \langle Z, f(t)\rangle]\leq \mathbb{E}[\sup_{t\in T} \langle Z, t\rangle]$$ We recall the Sudakov-Fernique inequality: for mean-zero Gaussian processes $(X_t)_{t\in T}$ and $(Y_t)_{t\in T}$ , if for all $s, t\in T$ we have $\mathbb{E}[(X_t-X_s)^2]\geq \mathbb{E}[(Y_t-Y_s)^2]$ , then $$\mathbb{E}[\sup_{t\in T} X_t]\geq \mathbb{E}[\sup_{t\in T} Y_t]$$ We define $X_t := \langle Z, t\rangle$ and $Y_t := \langle Z, f(t)\rangle$ , and we note that $$(X_t-X_s)^2 = \left[\langle Z, t-s\rangle\right]^2 = (t-s)^{\mathrm{T}}ZZ^{\mathrm{T}}(t-s)$$ Recalling that $\mathbb{E}[ZZ^{\mathrm{T}}] = I$ , we have $$\mathbb{E}[(X_t-X_s)^2] = \lvert t-s\rvert^2$$ Similarly, we will have $$\mathbb{E}[(Y_t-Y_s)^2] = \lvert f(t)-f(s)\rvert^2$$ By the fact that $f$ is a contraction, we therefore have that $\mathbb{E}[(Y_t-Y_s)^2]\leq \mathbb{E}[(X_t-X_s)^2]$ , which directly implies the problem inequality as the result of Sudakov-Fernique. However, I'm wondering if there's a way to leverage the existence of a fixed point of $f$ to achieve the same result without using Sudakov-Fernique. I think this proof would go something like rewriting the problem inequality as $$\mathbb{E}[\sup_{t\in T} \langle Z, f(t)-f(s)\rangle]\leq \mathbb{E}[\sup_{t\in T} \langle Z, t-s\rangle]$$ for $f(s) = s$ and then using again the fact that $f$ is a contraction, but I'm not quite seeing how to proceed. Does anybody else have any ideas? Thank you!","['probability-theory', 'fixed-point-theorems']"
3181973,"The IVP, $x'(t)=x^{2/3};x(0)=0$ in an interval arount $t=0$ has a","The IVP, $\dot x(t)=x^{2/3};x(0)=0$ in an interval arount $t=0$ has a (a)No solution (b)Unique solution (c)Finitely many solutions (d)Infinitely many solutions. Solution:- Applying Picard's -Lindelof Uniqueness and existence theorem. $f(x,t)=3x^{3/2}$ , Will it be continuous at $(0,0)$ ? When $x<0$ , $f(x,t)$ no more real valued. So, Discontinuous at $(0,0)$ . So, I can not judge from the theorem. I solved using variable separable form. I got the solution, $3x(t)^{1/3}=t+c$ . When I apply initial condition, I get $3x(t)^{1/3}=t$ . A unique solution. But in the answer key it is written that equation has infinitely many solutions. How it is possible? Please explain.",['ordinary-differential-equations']
3181993,Finding the solution set for a quadratic inequality $x^2-2<\frac{7}{2}x$,"If $x^2-2<\frac{7}{2}x$ then what is the solution set for $x$ ? I have most of the problem done, I just don't know how to lay out my answer. The answer is supposed to be $$\boxed{-\frac12<x<4}$$ First, I rewrote the problem saying $x^2-\frac{7}{2}x-2<0$ , and to be able to conveniently factor it I decided to multiply both sides by 2: $$2x^2-7x-4<0$$ $$(2x+1)(x-4)<0$$ $$x<-\frac12, x<4, \ \text{or}\ (-\infty, -\frac12) \cup (-\infty, 4)$$ I know that doesn't make sense because that's the solution set for the equation less than $0$ , when really we want to find the solution set for it less than $\frac72x$ . So how do I get the above solution? Would it suffice to just draw a number line and say if all values less than $-\frac12$ and all values greater than $4$ turn the equation to $<0$ then it must be values between $-\frac12 \ \text{and} \ 4$ ?","['algebra-precalculus', 'quadratics', 'inequality']"
3182042,Find all functions $f$ for which $f(x-y) = f(x) + f(y) - 2xy$ for all real numbers $x$ and $y$.,"Find all functions $f$ for which $f(x-y) = f(x) + f(y) - 2xy$ for all real numbers $x$ and $y$ . I have tried assume $f(x) = n^2$ , the equality holds.  How can I find other functions that satisfy the equality?","['functional-equations', 'functions']"
3182084,Decomposition of tensor product of permutation representation of $S_n$.,"Please be kind to me - I'm a combinatorist so this question might be a bit naive... If $U$ is the representation space of the permutation representation of $S_n$ , is there any known decomposition into irreducibles of $U\otimes U$ ? Cheers.","['symmetric-groups', 'representation-theory', 'combinatorics']"
3182096,Inner product of a character,"We let $G$ be a finite group. If $\chi$ is a complex character of $G$ , we define $\overline{\chi}:G \to \mathbb{C}$ by $\overline{\chi}(g)=\overline{\chi(g)}$ for all $g \in G$ , and define $\chi^{(2)}:G \to \mathbb{C}$ by $\chi^{(2)}(g) = \chi(g^2)$ . We write $\chi_{S}$ and $\chi_{A}$ for the symmetric and alternating part of $\chi$ . We note that $\chi_{S}$ and $\chi_{A}$ are characters of $G$ with $\chi^2=\chi_{S} + \chi_{A}$ and $\chi^{(2)}=\chi_{S} - \chi_{A}$ . We write $\nu(\chi):= \frac{1}{|G|}\displaystyle\sum_{g \in G}\chi(g^2)$ for the Frobenius Schur Indicator. First, let $\chi_{1}$ be the trivial character of $G$ , i.e. $\chi_{1}(g)=1$ for all $g \in G$ . We want to show that $\langle \chi , \overline{\chi} \rangle= \langle \chi_{S},\chi_{1}\rangle + \langle \chi_{A}, \chi_{1} \rangle$ . We have: \begin{split}
\langle \chi , \overline{\chi} \rangle &= \frac{1}{|G|}
\displaystyle\sum_{g \in G} \chi(g)\overline{\overline{\chi(g)}}\\ &= \frac{1}{|G|}
\displaystyle\sum_{g \in G} \chi(g)\chi(g)1\\ &= \frac{1}{|G|}\displaystyle\sum_{g \in G} (\chi_{S}+\chi_{A})(g)1 \\ &=\langle \chi_{S}+\chi_{A}, 1 \rangle \\  &= \langle \chi_{S},1 \rangle
+\langle \chi_{A} , 1 \rangle \\ &= \langle \chi_{S},\chi_{1} \rangle
+\langle \chi_{A} , \chi_{1} \rangle 
\end{split} Is this correct? Next, we let $\chi$ be irreducible. We want to show that $\nu(\chi) \in \{-1,1\}$ if $\chi$ is real-valued, and that $\nu(\chi)=0$ otherwise. Let us start from the 'otherwise' case first. We have: \begin{split}
\nu(\chi) &:=\frac{1}{|G|} \displaystyle\sum_{g \in G} \chi(g^2)\\
&= \frac{1}{|G|} \displaystyle\sum_{g \in G} (\chi_{S}-\chi_{A})(g) \\
&= \langle \chi_{S},\chi_{1} \rangle - \langle \chi_{A},\chi_{1} \rangle \\
&= \langle \chi , \overline{\chi} \rangle - 2\langle \chi_{A} , \chi_{1} \rangle
\end{split} and I get stuck here. I think, for the 'otherwise' case, $\langle \chi, \overline{\chi} \rangle = 0$ , because we assumed that $\chi$ is irreducible and so it follows that $\overline{\chi}$ is also irreducible and we also know that the irreducible characters form an orthonormal basis (but is it for an arbitrary field?) and so it follows(?). For the real case we'd have that $\langle \chi , \overline{\chi} \rangle = \langle \chi , \chi \rangle =1 $ from irreducibility of $\chi$ , but then again, I am still not sure how to deal with $1- 2\langle \chi_{A} , \chi_{1} \rangle$ ...I'd very much appreciate some help.","['group-theory', 'abstract-algebra', 'representation-theory', 'characters']"
3182104,I am not sure how to finish the proof of showing that the intersection of finitely many open subsets is open.,"I am trying to prove the following: Let $(X,d)$ be a metric space. An intersection of finitely many open subsets of $X$ is open. The following is my attempt: Let $x \in \bigcap_{i=1}^n U_i$ be arbitrary, where $U_i$ 's are open subsets in $X$ , for each $i=1,2,3,\ldots,n-1,n.$ Since $x \in \bigcap_{i=1}^n U_i$ , $x \in U_i$ for all $i=1,2,3, \ldots,n-1,n.$ Because all $U_i$ 's are open, for each $i,$ there exists $\epsilon_i>0$ such that $B_{\epsilon_i}(x) \subseteq U_i.$ Let $\epsilon = \min\{\epsilon_1, \epsilon_2, \epsilon_3, \ldots , \epsilon_{n-1}, \epsilon_n\}.$ Then $B_\epsilon(x)\subseteq B_{\epsilon_i}(x)$ for all $i=1,2,3, \ldots,n-1,n.$ Question: I am not quite sure of how to finish the proof, by showing that $B_\epsilon(x) \subseteq \bigcap_{i=1}^n U_i.$ My reasoning for the ending of the proof: Intuitively, it makes sense that $B_\epsilon(x) \subseteq \bigcap_{i=1}^n U_i$ , since the open ball centred at $x$ , with radius $\epsilon$ contains all points that are only in all of the sets $B_{\epsilon_1}(x),\,B_{\epsilon_2}(x),\,B_{\epsilon_3}(x),\ldots,\,B_{\epsilon_{n-1}}(x)$ and $\,B_{\epsilon_n}(x).$ Would it be correct in writing \begin{equation*}
B_{\epsilon}(x) = \bigcap_{i=1}^n B_{\epsilon_i}(x)?
\end{equation*} Then would it be the case that $$B_{\epsilon}(x) =\bigcap_{i=1}^n B_{\epsilon_i}(x) \subseteq \bigcap_{i=1}^nU_i,$$ therefore $\bigcap_{i=1}^nU_i$ is open?","['elementary-set-theory', 'general-topology', 'metric-spaces']"
3182183,Chern class of tautological line bundle over the projectivization of a vector bundle,"Let $\mathbb{C}^k\hookrightarrow E\to B$ be a complex vector bundle.
  Let $\mathbb{CP}^{k-1}\hookrightarrow\mathbb{P}(E)\to B$ be its projectivization. We can consider the tautological line bundle $L$ over $\mathbb{P}(E)$ which is the line bundle $$L= \{([x],V) \in \mathbb{P}(E)\times E | \ V \in [x] \} \to \mathbb{P}(E)$$ $$([x],V)\mapsto [x].$$ I would like to compute the first Chern class of this line bundle. In the case when $E = B\times \mathbb{C}^k$ is the trivial vector bundle, then $\mathbb{P}(E) = B\times \mathbb{CP}^{k-1}$ and the tautological line bundle is $L = B\times \mathcal{O}(-1)$ where $\mathcal{O}(-1)\to \mathbb{CP}^{k-1}$ is the tautological line bundle. Therefore in this case we get that the first Chern class is given by $- P.D.([B\times \mathbb{CP}^{k-2}])$ .
But what can we say in general? Motivation: study the normal bundle of $\mathbb{P}(E)$ inside $L$ in order to understand the blow-up along a submanifold.","['blowup', 'algebraic-topology', 'complex-geometry', 'algebraic-geometry', 'characteristic-classes']"
3182185,Are there incongruent pythagorean triangles with the same perimeter and same area?,"I found there are two incongruent isosceles triangles with integer sides and areas, where both have same perimeter, same area. I looked around Dickson's History of Number Theory but couldn't find where the right triangle version is treated. [I thought if a nonexistence proof was simple it would pop up in my search, but found none.] It may be simple to show none exist, but I had no luck, only filled  few notebook pages with formulas going nowhere. Reference/example/proof appreciated. Thanks.",['geometry']
3182260,"Quickest way to find $a^5+b^5+c^5$ given that $a+b+c=1$, $a^2+b^2+c^2=2$ and $a^3+b^3+c^3=3$","$$\text{If}\ \cases{a+b+c=1 \\ a^2+b^2+c^2=2 \\a^3+b^3+c^3=3}
 \text{then}\ a^5+b^5+c^5= \ ?$$ A YouTuber solved this problem recently and, though he spent some time explaining it, took over 40 minutes to solve it. Like the video, the best I can do with this is relying on expansion formulas and substitution. As trivial a problem this is, the numerous trinomials and binomials with mixed terms makes it very, very tedious. What is the quickest/shortest approach to this problem (meaning it doesn't need to be solved algebraically)? You don't have to type the entire solution out, I think if I'm given a good hint then I can take it from there.","['algebra-precalculus', 'systems-of-equations', 'roots', 'binomial-coefficients']"
3182286,Change of variables - Lebesgue-Stieltjes integral,"I am trying to find a proof of a result as follows: Let $\rho(\lambda)$ be a real function. Suppose that $\rho(\lambda)$ is monotone increasing and bounded. Suppose that $f(\lambda)$ is measurable and essentialy bounded with respect $\rho(\lambda)$ . Denote by $\chi_{\mu}(\lambda)$ the function defined by $\chi_{\mu}(\lambda)=1$ if $f(\lambda) \leq \mu$ and $\chi_{\mu}(\lambda)=0$ if $f(\lambda)>\mu$ . Define $\beta(\mu)=\int_{\mathbb{R}}\chi_{\mu}(\lambda) d\rho(\lambda)$ . Proposition: Let $g(\mu)$ be a real function Lebesgue-Stieltjes integrable over $\mathbb{R}$ with respect $\beta(\mu)$ . Then, $g(f(\lambda))$ is Lebesgue-Stieltjes integrable over $\mathbb{R}$ with respect $\rho(\lambda)$ and $\int_{\mathbb{R}}g(f(\lambda))d\rho(\lambda)=\int_{\mathbb{R}}g(\mu)d\beta (\mu).$ Unfortunately, I could not find anything like that.","['measure-theory', 'stieltjes-integral']"
3182293,Elementary way to evaluate $\lim_{x\to0}\frac{\sqrt[n]{a+x} - \sqrt[n]{a-x}}{x}$,"Evaluate: $$
\lim_{x\to0}\frac{\sqrt[n]{a+x} - \sqrt[n]{a-x}}{x},\ a>0,\ n\in\Bbb N
$$ I've given it several tries but couldn't find an elementary method to find the limit. Two other ways that worked are L'Hospital's rule and generalized binomial expansion. First method: $$
\lim_{x\to0} f(x) = \lim_{x\to0}\frac{g(x)}{h(x)} = \lim_{x\to0}\frac{g'(x)}{h'(x)} \\ = \lim_{x\to0}\left({1\over n}\left(a+x\right)^{{1\over n} -1} + {1\over n}(a-x)^{{1\over n} - 1}\right) = {2\over n}{a^{n-1\over n}} = \frac{2\sqrt[n]{a}}{na}
$$ Second method: $$
(a+x)^{1\over n} = \sqrt[n]{a}\left(1 + {x\over a}\right)^{1\over n} =\\
\sqrt[n]{a}\left(1 + {1\over n}{x\over a} + \frac{\left({1\over n}\right)\left({1\over n} - 1\right)}{2!}\left({x\over a}\right)^2 + \cdots \right)
$$ Also: $$
(a-x)^{1\over n} = \sqrt[n]{a}\left(1 - {x\over a}\right)^{1\over n} = \\
\sqrt[n]{a}\left(1 - {1\over n}{x\over a} + \frac{\left({1\over n}\right)\left({1\over n} - 1\right)}{2!}\left({x\over a}\right)^2 + \cdots \right)
$$ Combining those ones may obtain: $$
\lim_{x\to0}f(x) = \lim_{x\to0}\frac{\sqrt[n]{a}\left({2x\over na} + O(x^2)\right)}{x} = \frac{2\sqrt[n]{a}}{na}
$$ The problem is I'm not supposed to use derivatives for solving that limit. Also, generalized binomial expansion is somewhat too complicated as well. Are there any elementary methods to evaluate the limit from the problem section? I've also been trying to cast the expression to the form: $$
\lim_{x\to a}\frac{x^n - a^n}{x - a} = na^{n-1}
$$ but failed.","['limits', 'calculus', 'limits-without-lhopital', 'real-analysis']"
3182338,Permutation of 6 girls and 15 boys in a circle following a specific rule,"How many ways are there to arrange 6 girls and 15 boys in a circle such that there are at least 2 boys between any 2 adjacent girls?
Please help me how to proceed with this. My approach: Arrange first the girls in $5!$ ways, now we must choose $12$ boys from the $15$ in $15 \choose 12$ ways, and these boys will be arranged such that each girl has $2$ boys next to them in $12!$ Ways, then the remaining $3$ boys are left. We have already placed $18$ people, so we have $19$ position left for first boy, then $20$ position for 2nd boy and $21$ position for 3rd.
So I get it as, $5!$$15 \choose 12$ ( $12!$ )( $19*20*21$ ) But this looks clumsy and I'm not sure if its correct. I searched for similar circular permutation questions on this site, but it was mostly regarding equal number of boys and girls, and since this question is different I couldn't co relate. If question is repeated, apologies and kindly redirect me to such duplicate question, else please help me find the solution. 
Thank you","['combinatorics', 'discrete-mathematics', 'permutation-cycles']"
3182444,"if $f\phi \in L^p(\mathbb{R})$ for every $f \in L^p(\mathbb{R})$, then $\phi \in L^{\infty}(\mathbb{R})$.","Let $\phi: \mathbb{R} \to \mathbb{C}$ be a measurable function and fix $1 \leq p \leq \infty $ . Show if $f\phi \in L^p(\mathbb{R})$ for every $f \in L^p(\mathbb{R})$ , then $\phi \in L^{\infty}(\mathbb{R})$ . I have the hint if $p< \infty$ and $\phi \notin L^{\infty}(\mathbb{R})$ , then infinitely many $E_k=\{k\leq |\phi | \leq k+1\}$ must have positive measure. So basically I'm proving the contrapositive of the statement. I've shown the case when $p=\infty$ , but the case when $p< \infty$ , using the hint, is giving me trouble.","['measure-theory', 'lebesgue-measure', 'operator-theory', 'real-analysis', 'lp-spaces']"
3182524,Solving numerically a strongly stiff nonlinear ODE system with ill-conditioned Jacobian,"Using Matlab, I am trying to solve numerically the following nonlinear system of ODEs: $$\begin{aligned}
  \dot B &= -\alpha B -\nu BV   \\ 
  \dot X &= A-\mu_1 X -c E(B)VX \\
  \dot Y &= -\mu_2 Y +c E(B)VX  \\
  \dot V &= kY - (\gamma B + E_0)V - \delta V \\
  \end{aligned}$$ with $$E(B)=(\gamma B +E_0)e^{-\beta \gamma B}$$ The system tries to capture the dynamics of how the body of an infant reacts to the presence of the dengue virus. $V$ is the number of virus. $B$ the number of antibody. $X$ the number of healthy cells. $Y$ the number of infected cells. $E$ is a function enhancing the effect of antibodies, depending on the number of antibodies. Implementing this model and trying different solver, I noticed that solvers ode15s and ode23s are performing way better than ode45 . Hence, I deduced that my problem was stiff. But with certain set of parameters I had the following warning from Matlab: Warning: Matrix is close to singular or badly scaled. Results may be inaccurate. RCOND = 2.334107e-017. I worried for a while but I found the malicious ill-conditionned matrix. It's actually that solvers ode23s and ode15s use the Jacobian of the system. I have then computed myself this Jacobian and found the following: $$DJ(B,X,Y,V)= \begin{pmatrix}
-\alpha - \nu V & 0 & 0 & - \nu B \\
-c V X E'(B) & -c V E(B)-\mu_1 & 0 & -c X E(B) \\
c V X E'(B) & c V E(B) & -\mu_2 & c E(B) X\\
-\gamma V & 0 & k & -(\gamma B+E_0+\delta) \\
\end{pmatrix}
$$ with $$ E'(B)=e^{-\beta \gamma B}(\gamma-\beta \gamma^2 B-E_0 \beta \gamma)$$ at this point you have to know a bit more about the dynamics of the system. There is two stable points , one where the virus dies , the antibody disappears , the cells stays healthy $$P_0=(0, \frac{A}{\mu_1},0,0)$$ And another one, depending of the pararameters in a more complex way : $$ P_1 = \left(0,\mu_2 \frac{E_0+\delta}{k c E_0},\bar{Y}, \frac{k}{E_0+\delta} \bar{Y }\right) \text{  with } \bar{Y}= \frac{A}{\mu_2} - \frac{\mu_1(E_0+\delta)}{k c E_0} $$ which means, basically, that some cells become infected and stay infected, the virus population explodes before stabilising, and the antibodies disappear. This second point is the problem because lots of initial conditions seems to be attracted by it and it means that $V$ becomes huge (around $10^{12}$ ) when the total number of cells doesn't exceed $10^{7}$ and the population of antibodies stays below $10^{4}$ . When $V$ becomes huge, I check the Jacobian again, knowing that $\gamma \approx 1$ . We have this one value in the left down corner becoming really huge compared to the other values, also the parameter $c$ is around $10^{-10}$ , so really it's mostly about this left corner term. From there I'm not sure what to do. Is there a way to make a time-varying, well-conditioned Jacobian matrix? Or do you know about any other numerical method that could fit my needs? It doesn't have to be implemented in Matlab. For now, the results I get are mainly garbage.","['condition-number', 'matlab', 'ordinary-differential-equations', 'nonlinear-system', 'numerical-methods']"
3182528,Expected number of vertices of a given degree in a random graph,"How many vertices of degree exactly $\lfloor n/2 \rfloor$ does the random graph $G(n,1/2)$ contain? My calculations show that asymptotically this number is around $n^{1/2}$ but I feel like I have made a mistake somewhere. Let $n = 2m+1$ (for easier notation). $$\mathbb{P}(deg(v)=m) = {2m \choose m} (1/2)^{m}(1/2)^{m}$$ since we choose the $m$ neighbours of $v$ from the remaining $2m$ vertices. If the random variable $X$ counts the number of vertices of degree exactly $m$ , $$\mathbb{E}X = (2m+1){2m \choose m}(1/2)^{2m}$$ Using the bound $m^{1/2}{2m \choose m} \geq 2^{2m-1}$ (for large enough $m$ ), $$\mathbb{E}X \geq 2m^{1/2}2^{2m-1}(1/2)^{2m} = m^{1/2}$$ Is this correct? $m^{1/2}$ seems like too large a number but I am unable to find a mistake.","['graph-theory', 'random-graphs', 'discrete-mathematics', 'probability']"
3182544,Constructing tangent to a curve in $\mathbb{R}^2$,"I've been studying Basic Mathematics for Physics courses. While teaching about derivatives my prof. said that there are actually two points the tangent at a point passes through (and those points are almost coincident). Symbolically $x_0$ and $x_0+\mathrm dx$ . Clearly this sounds absurd because a tangent by definition touches any curve only at a single point. But also, this puts forth the discrepancy that at least two points are required to construct a line. I thought that if we somehow know the curvature of the curve we would indeed be able to construct a tangent using only a single point by using definition of curvature, $\kappa=1/r$ and follow as we do in the case of a circle. But how to actually measure the curvature of curve using only its derivative? Feel free to present a model of constructing a tangent this way or any other that you may find relevant and fitting into intermediate-to-advanced calculus courses.","['calculus', 'derivatives', 'geometry', 'tangent-line']"
3182580,"On the unit sphere $S^2$, show the antipodal map $A:S^2\to S^2$ is orientation reversing using definitions.","I want to show that on the unit sphere $S^2$ , the antipodal map $A:S^2\to S^2$ given by $(x,y,z) \mapsto (-x,-y,-z)$ is orientation reversing. I know that $S^2$ is a regular connected orientable surface so that it has two distinct orientation. What I tried: Consider an orientation $\{X_i(U_i)\}_{i \in I}$ where $X_i :U_i \underset { \text{open}}{\subseteq} \mathbb R^2  \to S^2$ is a familiy of parametrizations. Suppose that $AX_i(U_i) \cap X_j(U_j) \neq \emptyset$ . I need to show that the determinant of the Jacobian of the change of coordinate map $X_j^{-1} AX_i$ is negative. Note $X_j^{-1} AX_i=X_j^{-1}  (-X_i)$ . Then, $\det \ d(X_j^{-1} AX_i)=\det\ \ dX_j^{-1}(-X_i) \circ d(-X_i)=-\det \ \ dX_j^{-1}(-X_i)\circ dX_i$ . It suffices to show $\det \ \ dX_j^{-1}(-X_i)\circ dX_i >0$ , but this composition is not even well defined since $dX_j^{-1}$ is evaluated at $-X_i$ . I would like to know if such an ""elementary type"" argument is possible. Any help is appreciated.","['orientation', 'differential-geometry']"
3182643,What is a good way to prove that the function $\Bbb Z_n \rightarrow \Bbb Z_u \times\Bbb Z_v$ is well defined?,"Given a function of the type $\Bbb Z_n \rightarrow \Bbb Z_u \times\Bbb Z_v$ ( $[x]_n\rightarrow([x]_u, [x]_v)$ ) where of course $n=u*v$ how can I prove that is a well defined function?","['direct-product', 'group-theory', 'functions', 'discrete-mathematics']"
3182681,"Does all proofs of irrationality are the same way: ""Find an integer between $0$ and $1$""?","Excluding square/cubic etc roots of numbers, I've read proofs about the irrationality of $e,\pi,\ln 2,\zeta(2)$ and $\zeta(3)$ . In all of them is: assume $x=p/q$ , where $x$ is the number trying to proved irrational and $p,q$ integers.
Long story short, by assuming $x=p/q$ we found an integer between $0$ and $1$ . Is no other way to prove a number is irrational? Maybe finding a combination of $p,q$ that is not integer. For example, assume $x=p/q$ then $p+q = \text{something not integer}$ . PS. The only proof that I've that does not end this way is the beuker's proof for $\pi$ , where he find the estimation $1/p^n<1/n!$ which is not possible thus $\pi$ is irrational.","['number-theory', 'irrational-numbers']"
3182706,Quotients and exact sequences of algebraic group schemes,"Now I study group schemes to understand fundamental properties about semi abelian varieties and generalized jacobian varieties. Let $G$ be an algebraic group scheme over a field $k$ ( $=$ $k$ group schemes of finite type), $H$ an algebraic group sub-scheme.
In Milne's online note, the author defines that the quotient $G/H$ is the representable algebraic scheme of the sheaf associated to the presheaf $S \mapsto G(S)/H(S)$ , in the ""faithfully flat finite type site"". (not fppf.)
But in Conrad's ""semistable reduction for abelian varieties"", the author uses the different definition.
(It seems for me that he uses the fppf site.) And so these 2 references define exact sequences in the different way.
The former says that a sequence $1 \to G' \xrightarrow{f} G \xrightarrow{g} G'' \to 1$ is exact if $g$ is faithfully flat and $f$ identifies $G'$ to $\ker g$ .
(The author shows that $g$ is faithfully flat $\iff$ $g$ is surjective $\iff$ $g$ induces $G / \ker g \cong G''$ .)
Are these two definitions same? Next, In Serre's ""algebraic groups and class fields"", the author says that if $k$ is algebraically closed, a sequence of group varieties (= algebraic groups that are varieties = smooth algebraic groups) $1 \to G' \xrightarrow{f} G \xrightarrow{g} G'' \to 1$ is exact iff this is exact on the rational points as abstract groups and it induces the exact sequence of the tangent spaces at $1$ .
Is this true?
I don't know the Weil's foundation, so I don't understand whether this is true for schemes. And please suggest me some references. Thank you very much!","['arithmetic-geometry', 'algebraic-geometry', 'algebraic-groups']"
3182764,Non-flat locus for smooth schemes,"Let $X$ , $Y$ be connected smooth schemes of finite type over an algebraically closed field of characteristic 0. Let $f:X\rightarrow Y$ be a non-birational morphism surjective on underlying topological spaces. Can the non-flat locus of $f$ be non-empty of codimension $\geq 2$ in $X$ ? For birational morphism, I belive ZMT plus a purity theorem show that the answer is ""no"".","['algebraic-geometry', 'schemes']"
3182791,Exercise 1.3.16 in Hatcher,"I know this question has been asked before, but I couldn't find a satisfying answer so I hope to find it now. Let $p:X\to Y$ and $q:Y\to Z$ be maps such that $q$ and $q\circ p$ are covering map and $Z$ is locally path-connected. Then $p$ is a covering map, too. So, I choose $y\in Y$ and choose $U_y$ a neighbourhood of $y$ such that $q|_{U_y}:U_y\to q(U_y)$ is a homeomorphism. Then, the set $\{q(U_y)\colon y\in Y\}$ covers $Z$ . We see that $(q\circ p)^{-1}(q(U_y))=p^{-1}(U_y)$ . Now, I that I only have to show that $p|_{p^{-1}(U_y)}$ is a homeomorphism. How can I do this, and where do I need locally path-connectedness?","['general-topology', 'algebraic-topology']"
3182882,Finding the maximum relative misalignment of numbered rings on a combination lock?,"I've been trying to figure out a general formula to calculate the maximum relative misalignment of m identical rings with n symbols each on a combination lock like the one shown below. By ""maximum relative misalignment"" I mean the maximum number of turns that would be required to align all the rings with each other so their numbers match up. You could think of this as the maximum number of turns that would be needed to unlock the combination shown, if the combination lock will unlock if all the numbers between the dots are the same number. For this particular lock where m=5 and n=10, I've calculated the number to be 12. You could also think of this as the maximum total number of rotational shifts required to align m arrays containing the same n unique numbers each. I've been unable to figure out a generalized formula for this even though it seems like it shouldn't be terribly complicated. I brute forced the answer for m and n between 2 and 12 and the results were as follows: 2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  19
2   1   1   2   2   3   3   4   4   5   5   6   6   7   7   8   8   9   9
3   1   2   2   3   4   4   5   6   6   7   8   8   9   10  10  11  12  12
4   2   2   4   4   6   6   8   8   10  10  12  12  14  14  16  16  18  18
5   2   3   4   6   7   8   9   10  12  13  14  15  16  18  19  20  21  22
6   3   4   6   7   9   10  12  13  15  16  18  19  21  22  24  25  27  28
7   3   4   6   8   10  12  13  15  17  18  20  22  24  25  27  29  30  32
8   4   5   8   9   12  13  16  17  20  21  24  25  28  29  32  33  36  37
9   4   6   8   10  13  15  17  20  22  24  26  28  31  33  35  37  40  42
10  5   6   10  12  15  17  20  22  25  27  30  32  35  37  40  42  45  47
11  5   7   10  13  16  18  21  24  27  30  32  35  38  40  43  46  49  51
12  6   8   12  14  18  20  24  26  30  32  36  38  42  44  48  50  54  56
13  6   8   12  15  19  22  25  28  32  35  38                          
14  7   9   14  16  21  24  28  31  35  38  42                          
15  7   10  14  18  22  25  29  33  37  40  44                          
16  8   10  16  19  24  27  32  35  40  43  48                          
17  8   11  16  20  25  29  33  37  42  46  50                          
18  9   12  18  21  27  30  36  40  45  49  54                          
19  9   12  18  22  28  32  37  42  47  51  56 I noticed that the value seems to be the same if you swap m and n. I've determined the formula for even values of m and n seems to just be (n/2)*(m/2) Thanks for any help","['contest-math', 'puzzle', 'combinatorics']"
3182917,Is there a name for a transitive and reflexive but not symmetric relationship?,"How do you call a relationship that is transitive and reflexive but not symmetrical? Not antisymmetrical or asymmetrical or anything - just not symmetrical? Where there exist a and  that a is in a relation with b, but b is not in relation with a and nothing more.","['elementary-set-theory', 'relations']"
3182936,Minimal number of questions to identify a subset,"This is a curiosity question. Recently I stumbled across the following problem : Given three integers $k,m, n$ such that $m+k\leq n$ . A friend chooses a subset $S\subseteq\lbrace1,\ldots,N\rbrace$ with $k$ elements, and you have to guess what it is. You can ask him specific questions of the form: for each question you choose a subset $G \subseteq\lbrace1,\ldots,N\rbrace$ with $m$ elements and ask him does it have elements in common with $G$ ?, and you get an answer ""Yes"" or ""No"". How many questions do you need to find the subset? Attempt I was working on this question for some time without any breakthrough, let $f(n,m,k)$ be the minimal number of questions needed. I was particularly interested in $f(8,4,4)$ . I managed to find a formula for very specific cases for example : Obviously $f(n,m,0)=0$ $f(n,n-1,1)=n-1$ and $f(n,1,k)=n-1$ $f(n,n-2,1)=f(n,2,1)=\lfloor \frac n 2 \rfloor+1$ Some complicated formulas for $k=2$ but I am not sure if they are correct nothing for $k\geq 3$ . It seems that $f(n,m,k)=f(n,n-m,k)$ but I could not prove it. I added the condition $m+k\leq n$ because sometimes, it's not possible to find the subset (I think it's sufficient to ensure the existence of a solution, but I am not sure if it's necessary ). Question : Is there an algorithm to solve the problem ? to compute $f(n,m,k)$ ? or just any formulas for $k=3,4$ ?","['contest-math', 'puzzle', 'extremal-combinatorics', 'combinatorics', 'algorithms']"
3182955,Definition of Martingale,"I'm a little bit confused by the definition of a martingale. We say that a sequence of RV's is a martingale if: $E[X_n|X_{n-1}]=X_{n-1}$ . I'm confused because it seems like the LHS should be just a number since we are taking an expectation while the RHS is a random variable, i.e., a function. How does it make sense grammatically to say that they are equal?","['martingales', 'probability-theory']"
3182976,An apparently harmless exercise concerning induction,"Let $b \in \mathbb{R}, b \ge 2$ . Prove by induction that $$(b^n - 1)(b^n - b)(b^n -b^2)\cdots(b^n - b^{n-2}) \ge b^{n(n-1)}-b^{n(n-1)-1}$$ for all $n \in \mathbb{N}, n \ge 1$ . For the case $n = 2$ , I have to show that $$b^2 - 1 \ge b^2 - b$$ which is true for $b \ge 1$ . Suppose the result holds for $k \ge 2$ , I want to show that it holds for $k + 1$ too. I know that $$(b^k - 1)(b^k - b)(b^k -b^2)\cdots(b^k - b^{k-2}) \ge b^{k(k-1)}-b^{k(k-1)-1}$$ thanks to the inductive hypothesis, and I want to prove that $$(b^{k+1} - 1)(b^{k+1} - b)(b^{k+1} -b^2)\cdots(b^{k+1} - b^{k-1}) \ge b^{(k+1)k}-b^{(k+1)k-1}.$$ The LHS is $$(b^{k+1} - 1)(b^{k+1} - b)(b^{k+1} -b^2)\cdots(b^{k+1} - b^{k-1}) =$$ $$ (b^{k+1} - 1)b(b^k-1)b(b^k-b)b(b^k-b^2)\cdots b(b^k-b^{k-2})=$$ $$ b^{k-1}(b^{k+1} - 1)(b^k-1)(b^k-b)(b^k-b^2)\cdots(b^k-b^{k-2}) \ge$$ $$ b^{k-1}(b^{k+1} - 1)(b^{k(k-1)}-b^{k(k-1)-1}) =$$ $$ b^{k^2+k}-b^{k^2+k-1}-b^{k^2-1}+b^{k^2-2}.$$ The RHS is $$b^{(k+1)k}-b^{(k+1)k-1}= b^{k^2 + k} - b^{k^2 + k - 1}.$$ So I am left to prove that $$b^{k^2+k}-b^{k^2+k-1}-b^{k^2-1}+b^{k^2-2} \ge b^{k^2 + k} - b^{k^2 + k - 1} \Leftrightarrow b^{k^2-2} \ge b^{k^2-1}$$ which is unfortunately not true.","['real-numbers', 'natural-numbers', 'algebra-precalculus', 'induction']"
3183007,convexity of a relatively open subset of a compact set,"I'm struggling  with the following problem: it seems to be true but I'm not able to prove it!
Let $C$ be a compact convex subset of a locally convex metric vector space and $\hat{C}$ be a relatively open subset of $C$ , i.e. there exists an open set $\Omega$ such that $\hat{C}=C\cap\Omega$ .
Clearly if $\Omega$ is convex then $\hat{C}$ is also convex; is the converse true? I mean, if I assume that $\hat{C}$ is convex, can I suppose the existence of an open and convex set $\Omega$ such that $\hat{C}=C\cap \Omega$ ?","['general-topology', 'convex-analysis', 'locally-convex-spaces']"
3183060,Help with proving that $( A - B ) ∩ B$ is equal to the empty set,"I am trying to prove $( A - B ) ∩ B = Ø$ I know I need to prove the following while $x∈ B$ that $x∉ ( A - B ) ∩ B$ while $x∉ B$ that $x∉ ( A - B ) ∩ B$ I'm completely stuck, can anyone help?",['elementary-set-theory']
3183068,How to count the number of strings of length 5 in which at least one symbol occurs two or more times.,Suppose that A is a set of 8 (distinct) symbols and consider strings (i.e. sequences) over A. How can I calculate the number of strings of length 5 which at least one symbol occurs two or more times. I started by calculating the total number of strings of length 5 by doing $8^5$ ( since we have 8 choices for each number) and then I subtracted the amount of strings of length 5 that do not have any repetition ( $ 8\times 7\times 6\times 5 \times 4$ ) and I got the wrong answer. I think this is because my logic is wrong. Can someone help me?,"['permutations', 'combinations', 'combinatorics']"
3183133,What knowledge should I have before learning projective geometry? (I'm an 11th grade student),"I wanted to learn projective geometry. I don't know much about it. I came across projective geometry in a book called 'Euclidean geometry in mathematical olympiads' and I was very interested in it. So I tried the book projective geometry by HSM Coxeter but so far it has no mention of cross ratios which seemed quite important. I looked at a previous thread about what book to read on it Book suggestions on projective geometry but the book mentioned 'perspectives on projective geometry' is out of my skill level (I am just starting my 11th grade). So is there any book within an 11th grade skill range and if not, what do I need to learn before I am ready for projective geometry?","['self-learning', 'projective-geometry', 'geometry', 'reference-request']"
3183139,A query about Atiyah's proof of the convexity of moment map,"This is about proving connectedness of level sets of moment map of a $\mathbb T^n$ $\implies$ convexity of image of moment map for $\mathbb T^{n+1}$ action. I am following Ana Cannas's wonderful lecture notes but I got stuck at a point in the proof where it says for any two points $p_0,p_1 \in M$ there is a sequence of points $q_n \rightarrow p_0,l_n\rightarrow p_1$ such that $\mu(p_1) - \mu(p_0)$ is in $ker A^t$ for some integer $(n+1) \times (n)$ matrix $A$ with rank n. I realised that it'd be enough to get a sequence such that $\mu(p_1) - \mu(p_0)$ has all rational coefficients is enough, but I am confused about how to do this. I looked at this part in Dusa Mcduff's book and it doesn't elaborate on this topic either, so I have a feeling it might be really trivial but I guess I am missing some trick/ easy observation.","['moment-map', 'symplectic-geometry', 'differential-geometry']"
3183170,Calculating Volume: how to find Z when it's given inside a range e.g. $x^2+y^2\leq z \leq 4$?,"I'm having trouble with these questions, mainly because I don't know how to find the Z function when it's inside a range. Calculate the volume of: a) $x^2+y^2\le z \le 4$ (answer: $48\pi$ ) b) $x^2+y^2\le4 , x^2+y^2+z^2\le9$ (answer $\frac{(\pi)}{4}\times(e^4-e)$ ) For a) I tried the following: I converted to polar coordinates $x^2+y^2=r^2$ $r^2\le4, 0\le r\le2$ $0\le\theta\le2\pi$ For the Z function (height) I considered it as: $4-r^2$ since $x^2+y^2\le z\le4$ So I got this integral for the volume: $$\int_0^{2\pi}\int_0^2(4-r^2)rdrd\theta = 8\pi$$ which is not even close to $48\pi$ I also tried b) but got it wrong as well.","['multivariable-calculus', 'definite-integrals']"
3183192,Knights and knaves on a square grid,"Today Gathering For Gardner posted a video by Yoshiyuki Kotani called ""Liar/Truth Teller Patterns on Square Planes"". The idea is that you fill a grid with knights and knaves so that both the knights and knaves can say ""I am horizontally/vertically adjacent to $k$ knaves""—naturally the knights are telling the truth, and the knaves are lying. Examples For all of these examples, let $k=1$ and let . represent a knight and x represent a knave. For $k=1$ , the ""boring"" solutions are those that consist of horizontal or vertical strips, such as x x . . x x .
x x . . x x .
x x . . x x .
x x . . x x .
x x . . x x .
x x . . x x .
x x . . x x . Here is a non-boring solution on a $4 \times 4$ grid. . x . .
. . . x
x . . .
. . x . Similarly the video claims that there is exactly one non-boring solution for a $5 \times 5$ grid up to symmetry of the square: . . x . .
x . . . x
. . . . .
. x x x .
. x x x . Question The video claims that there may be no solution for $k=1$ on the $6 \times 6$ board. That is, all of the solutions consist of horizontal/vertical strips. Is this the case? Is there a way to prove it? Also, are there any corresponding OEIS sequences?","['graph-theory', 'puzzle', 'combinatorics']"
3183219,Prove minimum number of edges in a graph given constraints.,"So essentially I was instructed to draw a graph with 8 vertices and 12 edges that satisfied the following constraints: Between every group of 3 vertices at least two are connected At most one connection can exist between an two vertices No vertex can be connected to itself I was able to complete said graph and now I've been tasked with proving that it is impossible for such a graph to exist with fewer than 12 edges. I was given a hint that it has something to do with each vertex having at least three connections (a degree of 3), but I don't know how one could come to that conclusion. How is it that you can just assume that each vertex has a degree of three?","['graph-theory', 'discrete-mathematics']"
3183274,Fitting points to curve $g(t) = \frac{100}{1+\alpha e^{-\beta t}}$ by thinking about projections and inner products,"This is a reinterpretation of my old question Fit data to function $g(t) = \frac{100}{1+\alpha e^{-\beta t}}$ by using least squares method (projection/orthogonal families of polynomials) . I need to understand things in terms of orthogonal projections and inner products and the answers were for common regression techniques. t  ---   0 1 2 3 4 5 6 F(t)   10 15 23 33 45 58 69 Adjust $F$ by a function of the type $$g(t) = \frac{100}{1+\alpha
 e^{-\beta t}}$$ by the discrete least squares method First of all, we cannot work with the function $g(t)$ as it is. The way I'm trying to see the problem is via projections. So let's try to transform the problem like this: $$\frac{100}{g(t)}-1 = \alpha e^{-\beta t}\implies \ln \left(\frac{100}{g(t)}-1\right) = \ln \alpha -\beta t$$ Since we want to fit the function to the points, we want to minimize the distance of the function from the set of points, that is: $$\min_{\alpha,\beta} \left(\ln\left(\frac{100}{g(t)}-1\right)-\ln\alpha + \beta t\right)$$ Without using derivative and equating things to $0$ , there's a way to see this problem as an orthogonal projection problem. I know I need to end up with something like this: $$\langle \ln\left(\frac{100}{g(t)}-1\right)-\ln\alpha + \beta t, 1\rangle = 0\\ \langle \ln\left(\frac{100}{g(t)}-1\right)-\ln\alpha + \beta t, t\rangle=0$$ And I know this comes from the knowledge that our minimum is related to some projection and this projection lives in a space where the inner product with $span\{1, t\}$ (because of $\ln\alpha,\beta t$ ), gives $0$ . In order to end up with $$\begin{bmatrix}
    \langle 1,1\rangle & \langle t,1\rangle  \\
    \langle 1,t\rangle & \langle t,t\rangle \\ 
\end{bmatrix} \begin{bmatrix}
   \ln \alpha  \\
    -\beta  \\ 
\end{bmatrix}= \begin{bmatrix}
    \langle \ln\left(\frac{100}{g(t)}-1\right) , 1\rangle  \\
    \langle \ln\left(\frac{100}{g(t)}-1\right) , t\rangle  \\ 
\end{bmatrix}$$ Where the inner product is $$\langle f,g\rangle = \sum f_i g_i $$ *why? Can someone tell me what reasoning gets me to the inner products above, if I did everything rigth and how to finish the exercise?","['numerical-linear-algebra', 'multivariable-calculus', 'linear-algebra', 'numerical-methods']"
3183275,Equivalence relation of group members.,A group of $n\geq 6$ members decide to split up and travel in $n-3$ parties. How many equivalence relations exist on the set of members such that the members in each travel party form an equivalence class? I'm finding equivalence relations to be challenging in my discrete math course and I'm expected to know the material for an upcoming midterm so could someone help guide me through a solution for the above problem?,"['equivalence-relations', 'discrete-mathematics']"
3183331,Let $x$ be a Dedekind cut. Prove $x + (-x) = 0*$,"This is a question from Pugh's Real Mathematical Analysis. My attempt: Let $x = A|B$ where $\forall a\in A, \forall b\in B$ , $a<b$ . Then $-x = A'|B' = \{r\in\mathbb{Q}:$ for some $b\in B$ , not the smallest in $B$ , $r=-b\}$ |rest of $\mathbb{Q}$ . Suppose $0\in A+A'$ . Then, there exists $a\in A$ and $a'\in A'$ such that $a+a' = 0$ . But, $a+a'=0 \implies -a=a' \implies -a\in A'  \implies$ for some $b\in B$ , not the smallest in $B$ , $-a=-b$ $\implies a \in B$ . This contradicts our earlier assumption that $\forall a\in A, \forall b\in B$ , $a<b$ . So $0 \notin A+A'$ . As the sum of cuts is a cut itself, this means $\forall a''\in A+A'$ , $a''<0$ . Therefore, $A+A'|$ rest of $\mathbb{Q}$ is equivalent to $0*$ . I'm unsure if this is correct as I feel like the way I've ""proven"" it is quite trivial, which shouldn't be the case as the book implies. Any help would be appreciated!","['elementary-set-theory', 'proof-verification', 'real-analysis']"
3183424,Prove divergence of series $1-\frac{1}{3}+\frac{2}{4}-\frac{1}{5}+\frac{2}{6}-\frac{1}{7}+\ldots$,"Prove the divergence of the series: $$  1-{1\over3}+{2\over4}-{1\over5}+{2\over6}-{1\over7}+\ldots$$ Attempt. Of course the test of Leibniz for alternating series does not apply, since the terms $1,1/3,2/4,...$ are not decreasing (besides, it would imply the convergence of the series, which is not our case). I thought of working on the partial sums $(s_n)$ , especially $$s_{2n}=1-{1\over3}+{2\over4}-{1\over5}+{2\over6}-{1\over7}+\ldots
{2\over2n}-{1\over 2n+1}$$ in order to prove divergence, but i didn't manage to do so. Thanks in advance for the help.","['convergence-divergence', 'calculus', 'sequences-and-series', 'real-analysis']"
3183453,Pedagogical example of nonlinear ODE for numerical methods,"I am teaching numerical solution of first order ODEs. I wanted to show to my students how choosing step size can be critical when solving ODEs numerically. I was looking for a problem to demonstrate that i.e. when choosing a step size within a certain range gives an accurate answer but choosing a different step size can make the solution go off track or unstable solution. I have been unable find such an example. If anyone here has a problem(s) which I can use to this end, it would be very helpful to me if you could share it here.","['nonlinear-system', 'numerical-methods', 'ordinary-differential-equations']"
3183459,"German translation of the word ""ample""","I am looking for a German translation of the word ""ample"" as in ""ample line bundle"". The literal translation of the word is reichlich but I am not so sure whether the term reichliches Geradenbündel is actually being used. Any help would be appreciated.","['algebraic-geometry', 'mathematical-german', 'translation-request']"
