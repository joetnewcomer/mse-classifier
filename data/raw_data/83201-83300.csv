question_id,title,body,tags
1086375,Interpreting The Weak Law of Large Numbers,"Given the usual setup, the weak law of large numbers states that for any $\epsilon > 0$ $$
\lim_{n\rightarrow \infty}P(|M_n - \mu| > \epsilon) = 0
$$ According to this author, the interpretation is as follows: (1) For large values of $n$, (i.e. $n \ge N$ for some $N$) the
  probability that the value of $M_n$ (the sample mean) differs from the
  population mean $\mu$ by more than any given number $\epsilon > 0$
  is 0. (2) Alternatively, all probability is concentrated in an $\epsilon$
  interval around $\mu$. (3) Alternatively, almost surely, for large samples, the sample mean is
  within an $\epsilon$ neighborhood of the population mean. I understand all of this, but am having trouble reconciling this interpretation with the following statement from Exploring Monte Carlo Methods by Dunn and Shultis, which states (notation adapted slightly) The weak form of the law of large numbers states that, for a specified
  large $N$, the sample mean $M_N$ is likely to be near $\mu$. But
  it leaves open the possibility that cases when $|M_N - \mu|
> \epsilon$, i.e. when the deviation of $M_N$ from $\mu$ is
  outside some small tolerance interval $\epsilon$, can occur an
  arbitrary (even infinite) number of times as $N$ increases; however
  such occurrences happen at infrequent intervals. Is there a contradiction between these two interpretations? The first author is saying that for all $n \ge N$, with probability 1, the sample mean is within $\epsilon$ of $\mu$, but the second author says that for $n > N$ the weak law leaves open the possibility we have an infinite number of deviations larger than $\epsilon$. But if this happens an infinite number of times, how can the event occur almost surely ?","['statistics', 'probability', 'random-variables']"
1086398,$(123)!$ divided by $(25!)^x$. What is the maximum possible integral value of $x$?,"The answer given is $5$. But I am getting $4$. Here is what I have done.
$$25!= 2^{22}\cdot3^{10}\cdot5^6\cdot7^3\cdot11^2\cdot13\cdot17\cdot19\cdot23$$
$$123!=2^{117}\cdot3^{59}\cdot5^{28}\cdot7^{19}\cdot11^{12}\cdot23^5\dots$$ So, the minimum value comes in exponent of five. It would be $\lfloor\frac{28}{6}\rfloor=4$. What is wrong with this approach?","['discrete-mathematics', 'elementary-number-theory', 'combinatorics']"
1086402,Compact surfaces with boundary of constant negative curvature,"Consider a surface (with boundary) diffeomorphic to $S^1 \times [0, 1]$ and with constant negative curvature, sitting inside $\mathbb{R}^3$. All the examples I know of such surfaces are ""part of"" (or ""cut out of"", if that makes better sense) a surface of revolution (examples are the catenoid, tractricoid, etc.; O'Neill's ""Elementary Differential Geometry"" has a comprehensive list on page 261, Exercise 7). I was wondering, are all constantly negatively curved $S^1 \times [0, 1]$ obtained this way (that is, cut out from a surface of revolution)?","['hyperbolic-geometry', 'surfaces', 'differential-geometry']"
1086431,How many combinations can a group of n people form?,"how many groups can $20$ (or $n$) people form? The size of the groups vary from $2$ to $20$, where no group should have only a single member, and the order doesn't matter I'm sorry if this is a common question, but every single question I've found refers to ""$3$ teams from $30$ people"" or ""How many ways can $10$ people be split intro groups of $2$ and $3$"". The question stems from a discussion about how many chat groups our family of $20$ would form if everyone had a different chat group with everyone. I've thought about this for a long time now but I'm not getting anywhere. Surely the answer isn't $20!$, because that would count AB and BA as $2$, while in this case it's only a single group","['permutations', 'combinatorics']"
1086437,How many zeroes would be there at the end of $11^{(5!)!}-1$?,"$$11-1=10 \\
121-1=120 \\
1331-1=1330$$ Now it can be seen that the tens digit increases by 1 at each increment of exponent. So, only in case of $11^{10}$ the tens digit is zero and the units digit will  be $1$. So, total $2$ zeros at the end. After that at each power increment of $10$ the occurence of 0 will shift until $11^{20}$. So, number of zeroes should be $2$. Because $(5!)!$ is a multiple of 10. On second thought:
Is it like tens place 0 has a cyclicity of 10; hundreth place has 10^2; thousand place 10^3......Now 120! has 28 number of 10s. So, the tens and hundredth place will have zero. But the thousand place will not. So total 3 trailing zeros. Is my understanding ok? But the answer given is $1$.","['discrete-mathematics', 'elementary-number-theory', 'factorial', 'exponentiation', 'combinatorics']"
1086443,Condition that a quadratic function may be resolved into two linear factors,"If we are given a general quadratic function in $x, y$, there is a condition that it can be resolved into two linear factors of the form $ax+by+c$. I found the following proof for this. If we have a quadratic function $$f(x, y) = ax^2 + 2hxy + by^2 + 2gx + 2fy + c$$ To factorize this, it is sufficient to find the roots of the equation: $$ax^2 + 2hxy + by^2 + 2gx + 2fy + c = 0$$ Considering this to be a quadratic in $x$ and applying the quadratic formula yields $$x = \frac{-(hy + g) \pm \sqrt{(hy+g)^2 - a(by^2 + 2fy + c)}}{a}$$ $$\implies ax + hy + g = \pm \sqrt{(hy+g)^2 - a(by^2 + 2fy + c)}$$ Now, it is claimed that if $f(x, y)$ is the product of two linear factors the quantity under the square root sign must be a perfect square ie. the expression must be resolvable in to two identical linear factors. As the expression under the square root is a quadratic in $y$ we can set its discriminant equal to zero and get the condition. However, why must the expression be a perfect square if the quadratic has two linear factors? I was not able to exactly understand the reason behind it. If we can write $$f(x, y) = (px + qy + r)(p'x + q'y + r') = 0$$ Then $$px + qy + r = 0 \implies ax + hy + g = (a-p)x + (h-q)y + (g-r)$$ which should mean that the quantity under the radical is a perfect square. However, I am not sure if this is the correct reason. Moreover, how do we go the other way, I have proved that if the quadratic is resolvable into two linear factors then the quantity under the square root is a perfect square. How do I prove the converse?","['quadratics', 'algebra-precalculus']"
1086451,A generalized derivative,"Suppose that we define a ""derivative"" in the following way: $$\mathcal{D^{*^\alpha}}=\lim_{x\to x_0}\frac{f(x)^\alpha-f(x_0)^\alpha}{x-x_0}, $$ where $\alpha$ is a real number. What would be the rules of derivation of a function (product, sum,
composition,...)? What could we say about a ""Taylor Polynomial"" using
this kind of derivative? Is there any advantage in using this object?","['calculus', 'real-analysis', 'analysis']"
1086458,Evaluating$ \int_{-\infty}^{\infty} \frac{x^6}{(4+x^4)^2} dx $using residues,"I need help to solve the next improper integral using complex analysis: $$  \int_{-\infty}^{\infty} \frac{x^6}{(4+x^4)^2} dx $$ I have problems when I try to find residues for the function $ f = \displaystyle \frac{1}{(z^4+4)^2}$. This is what I tried. $$\displaystyle \text{res}(f,\sqrt{2}e^{i\left(\frac{\pi}{4}+k\frac{\pi}{2} \right)}) = \lim_{z\to \sqrt{2}e^{i\left(\frac{\pi}{4}+k\frac{\pi}{2} \right)}} \left( \frac{\left(z-\sqrt{2}e^{i\left(\frac{\pi}{4}+k\frac{\pi}{2} \right)}\right)^2}{(z^4-4)^2}\right)'$$ with $k\in\{0,1,2,3\}$. What do you think about it? I know there is a little more general problem involving this integral; for all $a>0$ $$ \int_{-\infty}^{\infty} \frac{x^6}{(a^4+x^4)^2} dx= \frac{3\pi\sqrt{2}}{8a}  $$ Edit. I've had an idea: from the integration by parts
$$\int u dv = uv - \int vdu$$ and if we let 
$$ dv = \frac{4x^3 }{(4+x^4)^2}, \, u = \frac{x^3}{4}$$ with $$dv = -\frac{d}{dx} \frac{1}{4+x^4} = \frac{4x^3 }{(4+x^4)^2}$$ we get finally $$ \int_{-\infty}^{\infty} \frac{x^6}{(4+x^4)^2} dx = 0 + \frac{3}{4} \int_{-\infty}^{\infty}  \frac{x^2}{1+x^4} dx $$ which I think is more easy to solve. Anyway, if you know another idea or how to complete my first try will be welcome.","['improper-integrals', 'complex-analysis', 'contour-integration']"
1086466,re-writing a mathematical expression with trig idnetities,"I have the following equation: $$ u = \frac{g}{c} A \left\{e^{-y/R_{o}} \sin \left(kx - \omega{t} \right) - e^{y/R_{o}} \sin \left(kx + \omega{t} \right)\right\} $$ which needs to be simplified using the following assumptions $$y = \frac{b}{2}, x = x_{1}, q = \frac{b}{2R_{o}}$$ Using some notes found online, here is my attempt: $$ u = \frac{gA}{c} \left\{e^{-b/2R_{o}} \sin \left(kx - \omega{t} \right) - e^{b/2R_{o}} \sin \left(kx + \omega{t} \right)\right\} $$ $$ u = \frac{gA}{c} \left\{ e^{-b/2R_{o}} \left( \sin\left(kx - \omega{t}\right) - \sin \left(kx + \omega{t}\right)\right) - \left(e^{b/2R_{o}} - e^{-b/2R_{o}}\right) \sin \left(kx - \omega{t}\right)\right\} $$ $$ u = \frac{gA}{c} \left\{e^{-q} \left( 2 \cos kx \sin \omega t \right) - 2 \sinh{q} \sin\left( kx + \omega{t}\right) \right\} $$ $$ u = \frac{2gA}{c} \left\{ e^{-q} \cos kx \sin \omega{t} - \sinh{q} \left( \sin kx \cos \omega{t} + \cos kx \sin \omega{t} \right) \right\} $$ $$ u = \frac{2gA}{c} \left\{ \sin \omega{t} \left( \cos kx_{1} \left( e^{-q} - \sinh{q} \right)\right) - \cos \omega{t} \left( \sin{kx_{1}} \sinh{q} \right) \right\} $$ However, I am pretty sure that I've done something wrong with the trig identities.",['algebra-precalculus']
1086471,Line Integral $\int_{C} \frac{x dy - y dx}{x^{2}+y^{2}}$,"Find $$\int_{C} \frac{x dy - y dx}{x^{2}+y^{2}}$$ along the oriented broken line $C$ with vertices $(2,-2)$, $(4,4)$, $(-5,5)$ oriented counterclockwise. I noted that $C$ is a closed curve which passes through the origin, so Green's theorem cannot be applied here. Also, the vector field is not conservative, so the integral is nonzero.",['multivariable-calculus']
1086472,Fourier Transform of Partial Derivative w.r.t x of [ x*f(x) ],"Can someone please help with the Fourier Transform of : Thank you in advance! ::Edit:: This is what I am trying to solve: $\frac{\partial(p(x, t))}{\partial t} = -A\frac{\partial(xp(x, t))}{\partial x}+\frac{B}{2}\frac{\partial^{2}(xp(x, t))}{\partial x^{2}}$ Where:[{A, B} = Constants] Define:
$FT\{p(x, t)\}(\omega) = \int_{-\infty }^{\infty }p(x, t)e^{-2\pi ix\omega }\,dx$
and $FT^{-1}\{\bar{p}(\omega , t)\}(x) = \int_{-\infty }^{\infty }p(\omega , t)e^{2\pi ix\omega }\,d\omega$ The next step is to convert each term so I can reduce the order but I started reading about Fourier Transforms two days ago, so I do not know all the tricks. I did use the properties below to get rid of the derivative - but I have no idea how to convolve x with p(x,t) - since p(x,t) is unknown. p(x,t) is a density function - so it goes to zero in the infinities (if this is important) Thank you again!","['fourier-analysis', 'ordinary-differential-equations', 'calculus', 'partial-differential-equations']"
1086474,Inclusions regarding the limsup and liminf of sets: $ \liminf E_n \subset \limsup E_n $ [duplicate],"This question already has an answer here : Is this proof of $\liminf E_k \subset \limsup E_k $ correct? (1 answer) Closed 9 years ago . Let $\{ E_n \}_{n \in \mathbb{N} }$ be a sequence of sets in some ambient set $\Omega $. I want to show that $$ \liminf E_n \subset \limsup E_n $$ My attempt: IF $x \in \liminf E_n = \bigcup_{k=1}^{\infty} \bigcap_{n \geq k} E_n $, then there is some $k_0 \in \mathbb{N}$ so that $x \in \bigcap_{n \geq k_0} E_n $. How can I show that $x \in \bigcap_{k =1}^{\infty} \bigcup_{n \geq k} E_n = \limsup E_n $ ??","['elementary-set-theory', 'real-analysis', 'limsup-and-liminf']"
1086516,Modeling temperature using a trigonometric function,"In the month of March, the temperature at the South Pole varies over the day in a periodic way that can be modeled approximately by a trigonometric function.
  The highest temperature is about $-50°C$, and it is reached around $2$ p.m. The lowest temperature is about $-54°C$ and it is reached half a day apart from the highest temperature, at $2$ a.m. Find the formula of the trigonometric function that models the temperature $T$ in the South Pole in March $t$ hours after midnight. Define the function using radians. What is the temperature at $5$ p.m.? Round your answer, if necessary, to two decimal places. Steps I took: So right away I set out to find the amplitude and midpoint of the function and those came out to be: Amplitude: $2$ The mid-line was $-52°C$. I also knew that the period would be $\dfrac { 2\pi  }{ 24 } $ since it takes $12$ hours to get to the minimum temperature and another $12$ to get to complete the period. Now I am confused by which trigonometric function to use . I know that cosine would start with the max temperature and sine would start with the lowest temperature but it isn't clear to me which one I should start with since 24 hours could start from $2$ am or $2$ pm .","['trigonometry', 'algebra-precalculus']"
1086520,Is the Fractional integral operator well-defined?,"How to prove the fractional integral operator $J_{\alpha}:L^p(\Bbb R^+)\rightarrow L^p(\Bbb R^+)$ (of order $\alpha>0$)
which is defined for each $f\in L^p(\Bbb R^+)$ by $$J_{\alpha}f(x):={1\over \Gamma(\alpha)}\int_0^x(x-y)^{\alpha-1}f(y)\,dy~~~~~x\in\Bbb R^+$$
 is well-defined?","['fractional-calculus', 'functional-analysis']"
1086524,Character Table Dihedral group of $D_6$,"I'm having real troubles with finding the character table of the dihedral group $D_6$ of order 12: $D_6 = \langle a,b |a^6 = 1 , b^2 = 1, aba = b \rangle$. I've already found the conjugacy classes: $\{1\}, \{a, a^5\} , \{a^2,a^4 \}, \{a^3\} , \{b,ba^2,ba^4 \}$ and $\{ba,ba^3,ba^5\}$. But from there, I'm completely stuck. Any help would be dearly appreciated.","['dihedral-groups', 'representation-theory', 'group-theory', 'characters']"
1086541,simplification of trig identities math check,"I'm looking over some class notes, and I'm sure that my professor has made an error. Consider the following equation: $$ e^{-q} \sin \left(kx - \omega{t} \right) - e^{q} \sin \left(kx + \omega{t} \right)$$ In my notes, this can be simplified as: $$ e^{-q} \left(\sin\left(kx - \omega{t}\right) - \sin \left(kx + \omega{t}\right)\right)- \left(e^{q} - e^{-q}\right) \sin \left(kx - \omega{t}\right)$$ However, I'm not convinced this is correct. I thought that the simplification for the left hand terms should be $$\sin\left(kx - \omega{t}\right) =  \sin(kx)\cos(\omega{t}) - \cos(kx) \sin(\omega{t})$$ which is different from his solution. Also, I'm not sure what is happening with the terms on the right hand side. For example, why is $e^q$ simplified to $e^q - e^{-q}$ Any advice would be appreciated",['algebra-precalculus']
1086545,Stone's One Parameter Unitary Group Theorem and the Fourier transform,"Stone's theorem on one parameter unitary groups asserts a one-to-one correspondence between strongly continuous one parameter groups of unitary operators $\mathcal{H}\to\mathcal{H}$ on a Hilbert space $\mathcal{H}$ and self-adjoint operators $\mathcal{H}\to\mathcal{H}$ i.e. for each unitary group $$\left\{U:\mathbb{R}\times\mathcal{H}\to\mathcal{H};\begin{array}{ll}U(t)\,U^\dagger(t)=\mathrm{id}&\forall\,t\in\mathbb{R}\\ U(t)\,U(s)=U(s+t)&\forall\,s,\,t\in\mathbb{R}\\\lim\limits_{t\to t_0}U(t)\,X = U(t_0)\,X&\forall t_0\in \mathbb{R};\;X\in\mathcal{H}\end{array}\right\}$$ there is precisely one self adjoint $P:\mathcal{H}\to\mathcal{H}$ such that $U(t) = e^{i\,P\,t}$. My question is simple: with $\mathcal{H}$ the separable Hilbert space of complex $\mathbf{L}^2$ functions on $\mathbb{R}$, is there any such one parameter group which includes the Fourier transform? More informally: can we deform the identity operator into the Fourier transform through a one parameter family of unitary operators? I suspect the answer is no, but cannot see a reason for it.","['fourier-analysis', 'functional-analysis', 'representation-theory']"
1086547,A question regarding a double series.,"Let $\{a_{mn}\}$ be a double series, where $a_{mn}>0$ for all $m,n\in\Bbb{N}$. If $\sum\limits_{i=1}^\infty{a_{ik}}$ is finite for all $k\in\Bbb{N}$ and $\sum\limits_{j=1}^\infty{a_{hj}}$ is finite for all $j\in\Bbb{N}$, then $\sum\limits_{i=1}^\infty \sum\limits_{j=1}^\infty{a_{ij}}=\sum\limits_{j=1}^\infty\sum\limits_{i=1}^\infty{a_{ij}}$. Is the above statement true? If it is, how does one go about proving it?",['analysis']
1086559,Eigenvalue of the substraction of 2 matrices,"Consider you have two $n \times n$ matrices $A,B$ with the same eigenvalue $\pi$. Then $A-B$ has an eigenvalue of $0$. The question is, is this correct or not? I was looking for properties in my head and in the course text, but i didn't find anything useful. Cause we don't know if $\pi$ is die only eigenvalue. We also don't know if the eigen vectors corresponding to the eigenvalues are the same. So we don't know if the matrices are similar or not. The only thing I tried was: Consider that they have the same eigen vector. Then you could write: $Av-Bv$ = $(A-B)v$ 
and
$\pi v-\pi v = (\pi-\pi) v$ and $\pi-\pi = 0$ So then you could proof this, but this is not the case unfortunately. I can also find no example that it's not true. Thank you","['linear-algebra', 'eigenvalues-eigenvectors']"
1086566,Largest rectangle bounded under a function,"Let $f$ be a positive monotonically increasing real function in $[0,1]$. Let $F$ be the area under the curve of $f$ ($F=\int_0^1{f(x)dx}$) For every $x\in[0,1]$, let $G(x)=f(x)\cdot (1-x)$ = the area of a rectangle bounded below the curve of $f$ and the $x$ axis: Let $L=\left\lceil\log_2{\frac{f(1)}{f(0)}}\right\rceil$. Prove that there exists an $x$ such that: $$G(x)\geq F/(2L)$$ Here is a possible proof: Partition the interval $[0,1]$ to bins such that, in each bins $[a,b]$, $f(b)\leq 2f(a)$ (i.e. the value of $f$ grows by at most a factor of 2). The number of such bins is at most $L$. Hence, by the pigeonhole principle, there is a bin $[a,b]$ in which the area under the curve ($= \int_a^b{f(x)dx}$) is at least $F/L$. Now, this area is bounded below the rectangle $(b-a)f(b)$. By definition of a bin, $f(a)\geq f(b)/2$. Hence:\begin{align}G(a) &= (1-a)f(a) \\&\geq (b-a)f(a) \\&\geq (b-a)f(b)/2 \\&\geq F/2L\end{align} MY QUESTIONS ARE: Is there a simpler proof? Is there a better bound for the area of the maximal rectangle?","['geometry', 'rectangles', 'integration', 'area', 'alternative-proof']"
1086571,Solving system of first-order PDEs with Frobenius theorem,"I've been stuck trying to solve this system: $$\ \frac{\partial u}{\partial x} = \frac{-2xy^2}{u} + 3y $$
$$\ \frac{\partial u}{\partial y} = \frac{-2x^2y}{u} + 3x $$ Which must satisfy $ \ u(0,0) = 1$ and the solution lies on $u(x,y) = z$ I've started by choosing vector fields $ \ X = \ \left(1,0,\dfrac{\partial u}{\partial x}\right)$  and $ \ Y = \ \left(0,1,\dfrac{\partial u}{\partial y}\right)$ which by the Frobenius theorem must satisfy $\left[X,Y\right] =0$ where the brackets indicate the jacobi brackets . Then to work out the flow of the X vector field: $ \dfrac{dx}{dt} = 1$ =>  $ x = t $ $ \dfrac{dy}{dt} = 0$ =>  $ y = 0 $ $ \dfrac{dz}{dt} = \dfrac{-2xy^2}{z} + 3y$ where at $t=0, z= 1$ Now I am stuck integrating this last equation. I believe there is a simple trick such as making a substitution. Don't worry, this isn't homework","['multivariable-calculus', 'manifolds', 'integration', 'partial-differential-equations']"
1086583,pattern in decimal representation of powers of 5,"The first few powers of $5$ are given by: \begin{array}{r}
5 \\
25 \\
125 \\
625 \\
3125 \\
15625\\
                                        78125\\
                                       390625\\
                                     1953125\\
                                    9765625\\
                                   48828125\\
                                  244140625\\
                                 1220703125\\
                                  6103515625\\
\end{array} We can see that the last digit is always $5$ and the second to last digit is always $2$. The preceding digit cycles between $1$ and $6$, and the one before that between $3,5,8$ and $0$. We can continue: \begin{array}{ll}
\text{digit} & \text{period} \\
1 & 5\\
2 & 2\\
3 & 16\\
4 & 3580\\
5 & 17956240\\
6 & 3978175584236200
\end{array} Apart from the first 2 $(5$ and $2)$ we see that all these periods appear to be congruent to 7 modulo 9. Can this be proven?","['modular-arithmetic', 'number-theory']"
1086587,Asymptotic distribution for MLE of exponential distribution,"Let $X$ have an exponential distribution with parameter $\theta$ (pdf is $f(x, \theta) = \theta e^{-\theta x}$). I already found that the MLE for $\theta$ after $n$ observations is $$\hat{\theta}_{MLE} = \bar{X}^{-1} = \frac{n}{\sum_{i=1}^n{X_i}}$$
and that $\bar{X} \tilde{} \Gamma(n, n\theta)$. The question is to derive directly (i.e. without using the general theory for asymptotic behaviour of MLEs) the asymptotic distribution of $$\sqrt n (\hat{\theta}_{MLE} - \theta)$$
as $n \to \infty$. According to the general theory (which I should not be using), I am supposed to find that it is asymptotically $N(0, I(\theta)^{-1}) = N(0, \theta^2)$. However, I don't know where to start - for other distributions I was able to use CLT (if their MLE was the sample mean), but I can't think of a way to do it here.","['statistics', 'parameter-estimation']"
1086597,set algebra having union and minus,"Using algebra of sets, show that: $$A \cup (B\setminus C) = (A \cup B)\setminus (C\setminus A)$$ I have tried using venn diagram, and they come out to be equal. Please help on proving them equal using the laws of set algebra.",['elementary-set-theory']
1086610,$\overline{X\cap Y} \subseteq \overline{X} \cap \overline{Y}$,"Let $X$ and $Y$ be two arbitrary subsets of $\mathbb{R}$. Show that $\overline{X\cap Y} \subseteq  \overline{X} \cap \overline{Y}$ Proof since 
$X\cap Y \subseteq X$ and $X\cap Y \subseteq Y$ $\implies \overline{X\cap Y} \subseteq \overline{X}$ and $\overline{X\cap Y} \subseteq \overline{Y}$ In other words, $\overline{X\cap Y}$ is present in both $\overline{X}$ and $\overline{Y}$.
$$\implies \overline{X\cap Y} \subseteq  \overline{X} \cap \overline{Y}$$
Is my proof correct?","['general-topology', 'proof-verification', 'real-analysis', 'analysis']"
1086645,Is Russell's paradox really about sets as such?,"It seems to me that Russell's paradox rather is a ""paradox"" concerning relations. Suppose we want to construct a graph (with finite or infinite number
  of nodes) and want some node to be adjacent to exactly those nodes
  that are not adjacent to them selves. It's the same problem, which seems to arise from the fact that it is not possible to define relations with nodes of certain adjacent specifications. And there are a lot of other examples of impossible constructions of relations. Suppose we want to construct a graph and want some node $s$ to be adjacent
  to exactly those nodes $x$ such that: all chains $x\to x_1\to x_2\to x_3\to\cdots$ are finite; given a surjection $f$ for the construction, $f(x)\nrightarrow x$. $($Set $s=f(x)\dots)$ It seems to be necessary to point out that I don't mean that there is a paradox of Russell (it was just a paradoxical consequence of a construction), and that I don't know if mathematicians really mean that the construction of Russell say something about sets as such. But I do believe that a lot of people think that Russell's paradox really is just about sets.","['relations', 'graph-theory', 'elementary-set-theory', 'paradoxes']"
1086675,How many lines bisect both perimeter and area of a 3-4-5 triangle?,"How many lines exist that divide both the perimeter and the area of a triangle with sides $3$ , $4$ and $5$ into half?","['geometry', 'euclidean-geometry']"
1086707,Property of complex numbers.,"Let $z \in \mathbb{C}$ such that $Re(z^{n})\geq0, \forall n\in\mathbb{N}$, where $Re(z^{n})$ is the real part of $z^{n}$. Show that $z\in\mathbb{R}^{+}$. If $z=a+bi$, $a,b\in\mathbb{R}$, then for $n=1\Rightarrow Re(z)\geq0\Rightarrow a\geq0$. So $a\in\mathbb{R}^{+}$, now we only need show that $b=0$. $n=2$ $Re(z^{2})=a^{2}-b^{2}\geq0\Rightarrow a^{2}\geq b^{2}\Rightarrow a\geq|b|.$ $n=3$ $Re(z^{3})=a^{3}-3ab^{2}\geq0\Rightarrow\frac{a}{\sqrt{3}}\geq|b|.$ $n=4$ $Re(z^{4})=a^{4}-6a^{2}b^{2}+b^{4}\geq0\Rightarrow(a^{2}-3b^{2})^{2}-8b^{4}\geq0\Rightarrow\frac{a}{\sqrt{\sqrt{8}+3}}\geq|b|.$ $\vdots$ In this way I think we can make a sequence $(a_{n})_{n\in\mathbb{N}}$ such that $a_{n}\geq|b|, \forall n\in\mathbb{N}$ and $a_{n}\longrightarrow0$ when $n\longrightarrow\infty$, so by the Squeeze theorem $|b|=0\Rightarrow b=0$. Is that right(Can anyone give me some hints on how to find this sequence?)? Or I can show what I want in an easier way? Thanks! Alec: $z=\rho e^{i\theta}=\rho(\cos(\theta)+i\sin(\theta))\Rightarrow z^{n}=e^{in\theta}=\rho^{n}(\cos(n\theta)+i\sin(n\theta)).$ Suppose the number has ANY imaginary component, i.e.,  $\sin(\theta)\neq0\Rightarrow\theta\neq k\pi,\forall k\in\mathbb{Z}$. You are saying that for some $n_{0}\in\mathbb{N}$ we'll have: $\cos(n_{0}\theta)<0$. Like this: For $0<\theta<\frac{\pi}{2}$ then take $\frac{\pi}{2\theta}<n_{0}<1+\frac{\pi}{2\theta}$, so $0<\theta<\frac{\pi}{2}<n_{0}\theta<\theta+\frac{\pi}{2}<\pi$. In other words I'm adding $\theta$ until $n_{0}\theta$ lies on 2nd quadrant. We can do the same way for $\frac{3\pi}{2}<\theta<2\pi.$","['complex-numbers', 'complex-analysis']"
1086713,Is $0$ an Infinitesimal?,"For the definition of Infinitesimal, wikipedia says In common speech, an infinitesimal object is an object which is
  smaller than any feasible measurement, but not zero in size; or, so
  small that it cannot be distinguished from zero by any available
  means. MathWorld says An infinitesimal is some quantity that is explicitly nonzero and yet
  smaller in absolute value than any real quantity. BUT I met some definition of Infinitesimal in textbooks says If $\lim_{{{x}\to{x}_{{0}}}} f{{\left({x}\right)}}={0}$, then we call
  $f(x)$ is an infinitesimal when ${x}\to{x}_{{0}}$. I found the textbooks's definition conflict with the above two definitions.. Obviously, $f(x)=0$ satisfy the textbooks's definition ,then can we call 0 an Infinitesimal ?","['calculus', 'infinitesimals', 'limits']"
1086716,Strong markov property in two dimensional Brownian motion,"I don't understand the following claim from my book: Let $(B_t)$ be a standard Brownian motion. Let $u:\Omega \rightarrow \mathbb{R}$ be a continuous function, where $\Omega$ is a domain and $B(x, \delta) \subset \subset \Omega$. Also, let
$$ \tau = \inf \{ t>0 : B_t + x \in \partial B(x, \delta) \} \quad \text{ and } \quad \tau(\partial \Omega) = \inf \{ t>0 : B_t + x \in \partial \Omega \}.   $$ 
Then, it claims that, by strong Markov property,
$$\mathbb{E} \bigg( u (B_{\tau (\partial \Omega)} + x ) \bigg| \mathcal{F}_\tau \bigg) = \mathbb {E}   \bigg( u \big( B_{\tau (\partial \Omega)} +y \big) \bigg) \bigg|_{y=B_{\tau}+x}. $$ But I get \begin{eqnarray}
 \mathbb{E} \bigg( u (B_{\tau (\partial \Omega)} + x ) \bigg| \mathcal{F}_\tau \bigg) & = & \mathbb{E} \bigg( u \big( B_{\tau + (\tau (\partial \Omega) - \tau \big)} - B_{\tau} +  B_{\tau}  + x ) \bigg| \mathcal{F}_\tau \bigg) \\
& = & \mathbb {E}   \bigg( u \big( B_{ \{\tau (\partial \Omega) - \tau \} } +y \big) \bigg) \bigg|_{y=B_{\tau}+x},
\end{eqnarray}
since $u$ is a Borel function, $\{B_{\tau+t}- B_\tau \}_{t \geq 0}$ is a Brownian motion independent of $\mathcal{F}_{\tau}$ and $B_{\tau}+x$ is $\mathcal{F}_{\tau}$-measurable.","['probability-theory', 'stopping-times', 'brownian-motion']"
1086722,Converse of Beltrami-Enneper theorems,"To investigate if two of three scalars $ \{k_n =0,\tau_g,  K = -1 \} $ are constant, then it follows the third is also a constant. To build a single valid relation among these three scalars viz.,  geodesics, asymptotic lines on pseudospherical surfaces ( with or without rotational symmetry ) and Gauss curvature. For surfaces in $\mathbb R^3$ given that geodesic torsion $\tau_g$ and Gauss negative curvature $K$ are constant along a line on a surface show that the line must be asymptotic, i.e., must have a vanishing normal curvature $\kappa_n$ . This is Beltrami-Enneper converse theorem Number 1. Given that if along a curve geodesic torsion $\tau_g$ is constant and also that it has zero normal curvature $\kappa_n$ as an asymptotic line show that the surface has constant negative Gauss curvature $K$ . This is Beltrami-Enneper converse theorem Number 2. Important Remark: If $ |K| \ne \tau_g$ , $|K| = 1/b$ , $b \ne a$ then the asymptotics would be different, do not have vanishing Euler normal curvature, given by roots of normal curvature equation: $$ k_n^2 -2 k_n \cot 2 \psi/b + (1/a^2 + 1/b^2) = 0 $$ $$ k_{n1} = \cot (2\psi) /b  - \sqrt{{(\csc (2 \psi)/b )}^2 - 1/a^2}  $$ For $ K = -1/a^2$ , $b =a $ , its roots are $ k_n = [0, 2 \cot( 2 \psi)/a] $ which are asymptotic and non-asymptotic normal curvatures respectively. As scalar curvature expressions are readily available, no need to visit original derivations of Enneper again, only algebraic manipulations are required for me to answer. Notation $K$ Gauss curvature, $k_n $ normal curvature, $ k_1$ , $k_2$ principal curvatures, $\tau_g $ geodesic torsion, $ k_1 >0 $ because $K<0$ . $\psi $ angle between asymptotic and principal curvature lines First Converse theorem: Given const. $K$ , $ \tau_g $ , show that $ k_n =0$ . $$ K = k_1 k_2 =\tau_g^2  \tag{1*}  $$ $$  (k_1 +k_2)\sin\psi  \cos\psi   = \tau_g  \tag{2*} $$ Eliminate $\tau_g $ between  (1*)  (2*) by squaring (2*) and equating, $$ k_1^2 + 2 k_1 k_2 \left[ 1- {\dfrac{1/2}{(\sin \psi \cdot \cos \psi  )^2}} \right]   + k_2^2 = 0 \tag{3*} $$ Let $ \tan \psi = t $ , so the square bracket term  equals $ -(t^2 + 1/t^2))/2 $ . Letting $ R= \dfrac{k_1}{k_2} $ $$ R^2 - R (t^2 + 1/t^2)  +1 =0  \tag{4*} $$ $$ R = t^2, R = 1/t^2  \tag{5*} $$ These give (Euler) normal curvatures zero brought back to classical forms : $$ k_n = k_1 \cos ^2\psi +  k_2 \sin^2 \psi = 0 \tag{6*}$$ $$ k_n = k_2 \cos^2 \psi +  k_1 \sin^2 \psi = 0 \tag{7*}$$ as required to be shown. The second result was not expected but should not be surprising as prevails between conjugate pairs of warped surface parts around saddle point/asymptotic lines for $K <0$ . Second Converse theorem: Given $ k_n =0 $ and $ \tau_g = const.$ , show $ K = -\tau_g^2. $ $$ k_n = -k_1 \cos ^2\psi +  k_2 \sin^2 \psi = 0 \tag{8*}$$ From (8*) and (2*) $$ \sin\psi = \sqrt{ k_1 a} ;\, \cos\psi=   \sqrt{ k_1 a} \tag{9*}$$ where $a$ is an arbitrary constant for scaling in  trig. triangles. $$ \cos^2\psi + \sin^2\psi = 1 = a (k_1 + k_2)  \tag{10*} $$ Plug in (9*) and (10*) into (2*) and squaring, $$ 1/a \cdot \sqrt{k_1 k_2 } \cdot a = \tau_g \rightarrow K = k_1 k_2 = \tau_g^2 = 1/a^2  \tag{11*} $$ whose signs need to be changed to get into classical form. Actually my aim/motivation for this post has been: To verify converse theorems  of Beltrami-Enneper as stated for constant $K$ , which I have already done as above and also To demonstrate/verify general validity in converse theorems even when $K$ is variable , which is still an open question now. It is here perhaps that the machinery of differential geometry would be brought to work.",['differential-geometry']
1086739,Union of $x$-axis and $y$-axis is not a manifold,"Show that the union $X$ of the $x$-axis and the $y$-axis in $\mathbb{R}^2$ is not a manifold. Is the following a valid way of arguing? Suppose $X$ were a manifold. Then there would be a nbhd $U$ of the origin in $X$ that is homeomorphic to $\mathbb{R}^2$. Then we also have that $U$ with the origin removed is homeomorphic to $\mathbb{R}^2$ with one point removed. But this can't be since $U$ without the origin is not connected, whereas $\mathbb{R}^2$ with one point removed is connected.",['general-topology']
1086742,"Completeness implies geodesic completeness, a more conceptual way?","We know from Riemannian geometry that for Riemannian manifolds, completeness and geodesic completeness are equivalent, which is usually a consequence of Hopf-Rinow theorem. However, I'm considering a more conceptual reformalization of this fact. Let's consider the simpler direction for this. Suppose $M$ is a Riemannian manifold and $UM$ is its unit sphere bundle. Levi-Civita connection gives an horizontal vector field $W$ on $UM$, which determines the local geodesic flow. If $M$ is complete, we need to show that the geodesic flow on $UM$ is complete, i.e. integral curves are indefinitely extendable. I guess that it will follow from a more general result on fiber bundles and vector fields on it. For example, we know that the fibers of $UM\to M$ are compact, and $W$ is horizontal. It's just like the theorem on completeness of flows of vector fields on compact manifolds. It seems a more natural way to formalize the statement. Any help? Thanks!","['differential-topology', 'riemannian-geometry', 'ordinary-differential-equations', 'differential-geometry']"
1086768,Prime number proof for tiling a rectangle,"The following theorem has many proofs, several of which are highlighted in this document . Whenever a large rectangle is tiled by rectangles, each of which has at least one integer side - the large rectangle has at least one integer side, too. The document has a proof using prime numbers and scaling: Prime numbers (Raphael Robinson, Univ. of California, Berkeley) We claim
  that for each prime $p$, either the height or width of $R$ is within $1/p$ of an integer. It follows that one of these is an integer. To prove the claim, scale the entire tiling up by a factor of $p$ in each direction, and consider the tiling obtained by replacing all tile-corners $(x, y)$ in the scaled-up tiling by $([x], [y])$. This yields an integer-sided  rectangle tiled by integer-sided rectangles, each of which has one side a multiple of $p$. Therefore, the area of the large integer-sided rectangle is a multiple of $p$, whence one of its sides must be a multiple of $p$. Moreover, the dimensions of this rectangle differ from the dimensions of the scaled-up rectangle by less than $1$. It follows that R has a side that differs from an integer by less than $1/p$ . I couldn't figure out why it is necessary to have the condition that $p$ be prime.","['geometry', 'tiling']"
1086776,Way to compute Stirling numbers of the second kind from a multiset,"I was wondering what algorithm would compute S(n, k {occurences of each element}) Where S(6, 3, {1, 2, 3} ) would give the total number of ways a set with 6 elements in which 3 are the same element and a different 2 are another element (and 1 is its unique element) could be split into 3 non-empty sets, ignoring permutations. This is basically the extension of Stirling numbers of the second kind to deal with multisets.",['combinatorics']
1086802,Is it possible to use physics or other form of non-canonical reasoning to study functions?,"It is well-known (see, for example, the books New Horizons in geometry , Maxima and minima without calculus and The Mathematical Mechanic ) that it is possible to use some forms of ""physical reasoning"", ""geometric reasoning"", or ""probabilistic reasoning"" or otherwise non-canonical arguments to find minima and maxima of some functions or to solve some problems that normally require calculus. Are there such methods to calculate limits, find derivatives, or
  verify the continuity of a function? Could you provide some examples?","['geometry', 'physics', 'reference-request', 'soft-question', 'probability']"
1086839,A confusion regarding the definition of a quasi-affine variety.,A quasi-affine variety is an open subset of an affine variety. Open under Zariski topology? How does this make sense?,['algebraic-geometry']
1086843,"Sum of squares of Binom(n,p) values","Let $x_{n,p}(j)$ be the probability that a random variable distributed according to a binomial distribution with parameters $n \in \mathbf{N}_+$ and $p \in (0,1)$ takes the value $j \in \{0,1,\ldots,n\}$, i.e.
$$x_{n,p}(j)=\binom{n}{j}p^j(1-p)^{n-j}.$$
Is it true that, independently of the value of $p$, we have that 
$$\sum_{j=0}^n x_{n,p}^2(j)=o(1)?$$ I am aware of Vandermonde identity which implies the claim holds true for $p=1/2$: indeed  $\binom{2n}{n}=\sum_{i=0}^n \binom{n}{i}^2$, so that 
$$\sum_{j=0}^n x_{n,p}^2(j)=\sum_{j=0}^n \binom{n}{j}^2 \frac{1}{2^{2j}}\frac{1}{2^{2n-2j}}=\frac{1}{4^n}\binom{2n}{n}=O\left(\frac{1}{\sqrt{n}}\right),$$
where the last approximation has been obtained with Stirling's formula. Does a similar result hold in general?","['binomial-coefficients', 'asymptotics', 'summation', 'probability']"
1086852,Closed form for integral of inverse hyperbolic function in terms of ${_4F_3}$,"While attempting to evaluate the integral $\int_{0}^{\frac{\pi}{2}}\sinh^{-1}{\left(\sqrt{\sin{x}}\right)}\,\mathrm{d}x$, I stumbled upon the following representation for a related integral in terms of hypergeometric functions: $$\small{\int_{0}^{1}\frac{x\sinh^{-1}{x}}{\sqrt{1-x^4}}\,\mathrm{d}x\stackrel{?}{=}\frac{\Gamma{\left(\frac34\right)}^2}{\sqrt{2\pi}}\,{_4F_3}{\left(\frac14,\frac14,\frac34,\frac34;\frac12,\frac54,\frac54;1\right)}-\frac{\Gamma{\left(\frac14\right)}^2}{72\sqrt{2\pi}}{_4F_3}{\left(\frac34,\frac34,\frac54,\frac54;\frac32,\frac74,\frac74;1\right)}}.$$ I'm having some trouble wading through the algebraic muckity-muck, so I'd like help confirming the above conjectured identity. More importantly, can these hypergeometrics be simplified in any significant way? The ""niceness"" of the parameters really makes me suspect it can be... Any thoughts or suggestions would be appreciated. Cheers!","['definite-integrals', 'closed-form', 'integration', 'hypergeometric-function']"
1086864,"If $S$ is a finitely generated graded algebra over $S_0$, $S_{(f)}$ is finitely generated algebra over $S_0$?","Let $S = \bigoplus_{n\ge 0} S_n$ be a graded commutative ring.
Let $f$ be a homogeneous element of $S$ of degree $> 0$ .
Let $S_{(f)}$ be the degree $0$ part of the graded ring $S_f$ , where $S_f$ is the localization with respect to the multiplicative set $\{1, f, f^2,\dots\}$ .
Suppose $S$ is finitely generated algebra over $S_0$ .
Then $S_{(f)}$ is a finitely generated algebra over $S_0$ .","['commutative-algebra', 'graded-rings']"
1086880,Integrals of Trigonometry functions,"Show that $$\int^\pi_0 \frac{\sqrt{1+\cos x}}{\sqrt{1+\cos x}+\sqrt{1-\cos x}}\,dx =\int^\pi_0 \frac{\sqrt{1-\cos x}}{\sqrt{1+\cos x}+\sqrt{1-\cos x}}\,dx$$ I tried to use to check if $$\int^\pi_0\left(\frac{\sqrt{1+\cos x}}{\sqrt{1+\cos x}+\sqrt{1-\cos x}} - \frac{\sqrt{1-\cos x}}{\sqrt{1+\cos x}+\sqrt{1-\cos x}}\right)\,dx=0$$ but it didn't turn out well. Please help.","['definite-integrals', 'trigonometry']"
1086895,Evaluating an alternating sum using contour integrals,"Evaluate: $$\sum_{n=1}^{\infty} \frac{(-1)^n}{3n-1}$$ Using contour integration. Normally I would use $\pi\csc(\pi z)f(z)$ and evaluate the residue multiply by (-1) and divide by $2$ if the function $f(n)$ were even, in this case it is not even. I was wondering if I could use contour integration here. I converted it into an integral. Without showing the working, (well it was mostly integration and division) $$\sum_{n=1}^{\infty} \frac{(-1)^n}{3n-1} = \int_{0}^{1} \frac{1}{1+x^3}dx$$ I considered a contour $C$ quarter circle, radius $1$ the y-axis is the imaginary axis. into section $A,B,D$ With the quad formula, I found three roots. $x = ${$ \displaystyle \frac{1 + \sqrt{3}}{2}, \frac{1 - \sqrt{3}}{2}, -1   $} Let the poles be called $a,b,c$ respectively, we will only consider $a$ since its the only one in the contour, the radius $R = 1$. $$\oint_{C} f(z) dz = \int_{0}^{1} f(x) dx + \int_{B} f(z) dz - \int_{0}^{1} f(iy) d(iy)$$ By the residue theorem I got: $$\oint_{C} f(z) dz = \frac{4\pi i}{3 + \sqrt{3}i}$$ But I am not sure what to do next.","['sequences-and-series', 'calculus', 'integration', 'complex-analysis', 'contour-integration']"
1086898,Show that $ \lim_{n \rightarrow \infty} \frac{|f(T^n(x))|}{n}=0 $,"Let $T: (X, \mathcal{A},\mu) \rightarrow (X, \mathcal{A},\mu)$ be ergodic wrt a measure $\mu$ on $(X,\mathcal{A})$ . Show that for any $f \in L^1(X,\mathcal{A})$ and $\mu$ -almost every $x \in X$ we have $$ \lim_{n \rightarrow \infty} \frac{|f(T^n(x))|}{n}=0 .$$ This question screams out for the use of the Birkhoff Ergodic Theorem for ergodic transformations (which is essentially $\displaystyle \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{k=0}^{n-1}f(T^k(x)) = \int f d\mu$ ). How can you make this work? Or am I on the wrong track?","['probability-theory', 'dynamical-systems', 'ergodic-theory']"
1086899,Two different matrix representations of complex numbers,"There are two different ways to represent a complex number with $2 \times 2$ real matrices:
$$
\rho: \mathbb{C} \rightarrow M_2(\mathbb{R}) \qquad 
\rho(z)=\rho(a+ib)= 
\left[ 
 \begin{array}{ccccc}
a&b  \\
 -b &a
\end{array}
\right]
$$
and
$$
\bar\rho: \mathbb{C} \rightarrow M_2(\mathbb{R}) \qquad 
\bar\rho(z)=\bar\rho(a+ib)= 
\left[ 
 \begin{array}{ccccc}
a&-b  \\
 b &a
\end{array}
\right]
$$
We can find one or the other in many sources, and somewhere both, as in History of the matrix representation of complex numbers Clearly this two representations generate the same subring of $M_2(\mathbb{R})$ but ve have: $\bar \rho(z)=\rho(\bar z)$. The existence of this double representation  has some (hidden for me) significance or is purely fortuitous ?","['matrices', 'complex-numbers', 'soft-question', 'field-theory']"
1086909,A operator is unitary if and only if it is a surjective isometry,"I'm trying to prove the following result. Let U be an operator of a Hilbert space H, then $U$ is an unitary operator $\iff$ $U$ is an isometry and $R_u = H$ ($U$ is onto and isometry) I tried to use the fact that $U$ is a linear operator and the fact that $U^*U=I$ defines an isometry but I couldn't proceed.","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
1086915,Online resource for solved ODEs,"I'm looking for some sort of list of solved ODEs, that is, ODEs with solution included. I was hoping to find something like this on the internet but I haven't been able to. Does someone know of a place? I'm basically looking for standard ""solvable-by-quadrature"" ODEs, simply to gain some mechanical ability and ""pattern recognition"", if you will. I know plenty of books but my school's library is closed these days.","['ordinary-differential-equations', 'reference-request']"
1086927,"Let $a,b \in \mathbb R$ and $f(x)=a\cos x+b\cos3x$. Prove that $|b|\le 1$.","Let $a,b \in \mathbb R$ and $f(x)=a\cos x+b\cos3x$. It is known that $f(x)>1$ has no real solutions. Prove that $|b|\le 1$. We can write the given equality as 
\begin{align}
&f(x)=(a-3b)\cos x+4b\cos^3x\\[2ex]
\Rightarrow\quad&f'(x)=(3b-a)\sin x-12b\cos^2x\sin x=0\\[1ex]
\Rightarrow\quad&\sin x=0,\quad \cos^2x=\frac {3b-a}{12b}
\end{align}
Therefore $f(x)$ has minima or maxima when $\sin x=0$, so $\cos x=\pm 1$ or when $\cos x=\pm\sqrt{\frac {3b-a}{12b}}$. Hence $f(x)=\pm(a+b)$ or $\pm\frac 23(3b-a)$. Now what should I do?","['trigonometry', 'inequality']"
1086946,"Infinite Double Exponential Sum, with Functional Equation $g(x) = g(\sqrt{x})$",What is a closed form for $$ \lim_{n\to-\infty}\sum_{i=n}^{\infty}\frac{x^{2^i}(x^{2^i}-1)}{(x^{2^{i+2}}+1)} $$ The series has the form: $$... \frac{x^{\frac{1}{4}}(x^{\frac{1}{4}}-1)}{x+1} + \frac{x^{\frac{1}{2}}(x^{\frac{1}{2}}-1)}{x^{2}+1}  + \frac{x(x-1)}{x^4+1} +\frac{x^2(x^2-1)}{x^8+1}  ... $$ Among other things the closed form satisfies $$g(x) = g\left(\sqrt{x}\right)$$ where we select the principal square root.,"['exponential-sum', 'sequences-and-series', 'convergence-divergence', 'calculus', 'functional-equations']"
1086956,Is this point on the unit circle?,"I was working through my Precalculus 12 book, when I came across these questions: Is each point on the unit circle? Give evidence to support your answer a) $(0.65, -0.76)$ b) $\left(-\frac{\sqrt{2}}{2}, -\frac{\sqrt{2}}{2}\right)$ My book says that both of these points lie on the unit circle, but I can't understand how.","['trigonometry', 'algebra-precalculus']"
1086972,Does a conformal map take boundaries to boundaries?,"I think it is a well-known result that conformal maps between sets in $\mathbb{C}$ take boundaries to boundaries.  However, I looked around a little and I had trouble finding this result.  Is it true?  Also, is there a quick proof of it? I apologize if this has already been asked.","['conformal-geometry', 'complex-analysis']"
1086974,Continuous bijection from $\mathbb{R}^n$ to $\mathbb{R}^m$,"Is there a continuous bijection from $\mathbb{R}^n$ to  $\mathbb{R}^m$, for $n \neq m$? Such a map would not be an open map, since $\mathbb{R}^n$ and  $\mathbb{R}^m$ are not homeomorphic.","['general-topology', 'real-analysis']"
1086981,Algebra on a Louvre tablet,"Problem: On a Louvre tablet of about 300 B.C. are four problems concerning rectangles of unit area and given semiperimeter. Let the sides and semiperimeter be $x,y$ and $a$. Then we have
\begin{equation}
xy=1, \qquad x+y=a. \tag{1}
\end{equation}
Solve this system by using the identity
$$
\biggl(\frac{x-y}{2}\biggr)^2 = \biggl(\frac{x+y}{2}\biggr)^2 - xy \tag{2}
$$ Attempted solution: By elimination: To eliminate $y$, we note that $y = \frac{1}{x}$, and we substitute this $y$-value into the equation $x+y=a$ to obtain
$$
x = \frac{a \pm \sqrt{a^2-4}}{2},
$$
where this solution was obtained by using the quadratic formula. By using the given identity: Start by letting $y=a-x$. Using this and the fact that $x+y=a$, we have the following:
\begin{align*}
\biggl(\frac{2x-a}{2}\biggr)^2 = \biggl(\frac{a}{2}\biggr)^2 - 1 &\longleftrightarrow 4x^2-4xa+a^2 = a^2-4\\ &\longleftrightarrow x^2-ax+1=0,
\end{align*}
whereby we get that $x = \frac{a \pm \sqrt{a^2-4}}{2}$, as we did above by using elimination. Main question: My solution using (2) seems to work , but is there a ""slicker"" approach? That is, it seems like the originally posed problem wants me to do something nifty with (2) rather than using it in such a brutish fashion. Anyone have a cleaner approach in mind in regards to solving (1) by using (2)?","['algebra-precalculus', 'math-history']"
1086984,A curious expression involving the nearest-integer function whose sum appears to be 3,"Let $ \def\nint#1{\langle #1\rangle}\nint x$ denote the integer closest to $\sqrt x$.  This is ambiguous whenever $\sqrt x$ is a half-integer; fortunately such will not arise in the rest of this question, and we  may simply take $\nint x = \left\lfloor \sqrt x+\frac12\right\rfloor$. Now consider the sum $$S(k) = \def\nint#1{\langle #1\rangle} \sum_{i=1}^\infty \frac{k^{\nint i} + k^{-\nint i}}{k^i}$$ Computer calculations unequivocally suggest that $$S(k)=\frac{k+1}{k-1}$$ for all $k>1$; in particular $$S(2) = 3.$$  Is this correct, and if so, what is a proof?  I imagine a counting argument that calculates the number $C_n$ of different $i$ at  which the function $\nint i$ takes the value $n$, but I have not worked out the details. I would also be interested to see an argument about the region in which $S$ converges. [ The $k=2$ case of this question has been asked at least twice 1 2 in the past couple of days, and closed both times, but I think it deserves more attention. ]",['sequences-and-series']
1086993,Why can't suspace topologies be the empty set?,"Let $(X,\mathcal{J})$ be a topological space and let $Y\subset X$, Define the collection $\mathcal{J}'$ of subsets of $Y$ as $\mathcal{O}'\subset Y$ of the form $\mathcal{O}'=\mathcal{O}\cap Y$ where $\mathcal{O}\in\mathcal{J}$ Then $(Y,\mathcal{J}')$ is a topological space - Provided $Y\ne \emptyset$ I am happy with the proof but it doesn't use $Y\ne\emptyset$ anywhere, and I can't see what would break if $Y$ were the nullset, yes it'd be a pretty useless topology, but useless topoligies are still topologies. I'm sure $(\emptyset,\{\emptyset\})$ is a topological space because: The entire set is a member of the topology The null set is a member of the topology Finite intersections are closed Unions are closed So why is it saying ""Provided $Y\ne\emptyset$"" Book: Mendelson Introduction To Topology, Dover, page 92, chapter 3 proposition 6.2. This is probably a really simple question, but it bothers me that I cannot see why he writes this, so I must find out! I would of course call such a topology useless, but as I said, useless topologies are still topologies!",['general-topology']
1087003,Can the cross product be a matrix?,"On the Wikipedia article on the cross product is says that a vector $a$ which is itself a cross product (that is $a=c\times d$), can be represented in the expression $a \times b$ for some other vector $b$ by the matrix $$[a]_{\times}=\begin{bmatrix} 0 & -a_3 & a_2 \\ a_3 & 0 & -a_1 \\ -a_2 & a_1 & 0 \end{bmatrix}$$ where $a\times b = [a]_{\times} b = (dc^T - cd^T)b = (c\times d)\times b$. I'm wondering if this matrix representation of the cross product of a vector encodes any of the other properties of the cross product. I don't see a way of extracting a scalar from it to reproduce the triple scalar product. It's determinant and trace are always $0$. $[a]_{\times}^T=-a$ It's Frobenius norm is $\sqrt{a_2^2+a_3^2+a_1^2+a_3^2+a_1^2+a_2^2} = \sqrt{2}\sqrt{a_1^2+a_2^2+a_3^2}=\sqrt{2}\|a\|$.  So up to a factor of $\sqrt{2}$, the Frobenius norm is the same as the norm of $a$. A vector orthogonal to $c$ and $d$ (finding such a vector is one of the main purposes of the cross product) will be a member of the kernel of this matrix.  $\operatorname{Ker}[a]_{\times}=t\begin{bmatrix} a_1 \\ a_2 \\ a_3\end{bmatrix}$ This means that the plane spanned by $c$ and $d$ is the row space of $[a]_{\times}$ because $\operatorname{Ker}(A)^{\bot} = \operatorname{Row}(A)$ for all matrices $A$.  And because this matrix equals its negative transpose, the plane is also given by the column space of $[a]_{\times}$. The mapping $[a]_{\times} \mapsto a$ is linear, so if someone could come up with an explicit expression for this mapping, then we could expression the triple scalar product in terms of that mapping.  As in, let $T$ be the name of that mapping, then $T(a)\cdot b = (c\times d) \cdot b$, though I admit this is cheating.  Even so, it'd be useful to have an explicit expression for $T$. Are there any other useful properties of this matrix?","['matrices', 'cross-product', 'linear-algebra']"
1087011,"Calculating the radius of the circumscribed sphere of an arbitrary tetrahedron, edge lengths given","In two dimensional Euclidean space, it is not hard to calculate the radius of the circumscribed circle of an arbitrary triangle when all the side lengths are given. We can use Heron's formula to calculate the area of the triangle, then immediately obtain the requested radius since there is $$S=abc/4R$$where R is the radius. So what about the case in three dimensional Euclidean space? Now there is a tetrahedron whose edge lengths are $a,b,c,d,e,f$ such that they can construct a tetrahedron. So far 
I have proved that for any possible given edge lengths there always exist one and only one circumscribed sphere. Let its radius be $R$, then it is clear that there exists an unique function $F$ such that$$R=F(a,b,c,d,e,f)$$
Since I haven't seen $F$ in any books I read, I started my exploration then, trying to work out $F$. But every time I had to give up because the calculation was scarily daunting.I have tried many different ways, but none of them seemed to remove the pain of huge amount of calculation which I just don't want to spend too much time and energy in. Further observation tells that $F$ should be symmetrical as to all the $a,b,c,d,e,f$, but that's, till now, all the knowledge I have about it. So I am wondering if there is a simple way, like in the two dimensional case, to get the result I want. I don't expect $F$ to take a simple form. I am just seeking an intuitive (and simple, if possible) METHOD that shows how to deduce $R$ from $a,b,c,d,e,f$.",['geometry']
1087017,Calculate $\lim_{x \to 0^+} (1+\sin x)^{\frac{1}{\sqrt{x}}}$,I have this problem : Calculate : $$\lim_{x \to 0+} (1+\sin x)^{1/\sqrt{x}}$$ I don't really know to approach this. Any ideas?,"['calculus', 'limits']"
1087027,Is integration by parts the best method for $\int_0^1 x^3(1-x)^6 dx$?,"It came up when finding a constant such that the integral is equal to 1 and thus behaves like a pdf. I used the parts method but have made an error, just curious how others might approach the problem.","['self-learning', 'probability']"
1087036,disintegration of infinite convex combination of measures,"One expects that the disintegration (under a map $X \to Y$) of a convex combination of probability measures on X is the convex combination of disintegration of the measures. My question is if this can be stated rigorously and proved. I suspect that its proof is trivial once the correct statement is formulated, but I am stuck at how to state it precisely. Background ($M(X)$ denotes the set of probability measures on $X$) Given a Borel map $\pi: X \to Y$ between standard Borel spaces, any probability measure $\mu \in M(X)$ can be decomposed into two parts: its pushforward image $\pi \mu \in M(Y)$ and its disintegration $y \in Y \mapsto \mu_y \in M(X)$. The disintegration $y \mapsto \mu_y$ is unique in the $\pi\mu$-a.e. sense. Now suppose $\mu \in M(X)$ is given as some infinite convex combination of other measures on X. In other words, suppose $\mu = \int_A \mu^\alpha\ d\rho(\alpha)$ where $A$ is another standard Borel space and $\alpha \in A \mapsto \mu^\alpha \in M(X)$ is a Borel map and $\rho \in M(A)$. One can check that the pushforward image $\pi\mu$ is the $\rho$ convex combination of $\pi(\mu^\alpha)$. In other words, $$\pi\mu = \int_A \pi(\mu^\alpha) \ d\rho(\alpha)$$ And one then intuitively expects the following proposition: The disintegration $y \mapsto \mu_y$ is the $\rho$ convex combination
  of the disintegration $y \mapsto (\mu^\alpha)_y$, in other words,
  $$\mu_y = \int_A (\mu^\alpha)_y \ d\rho(\alpha)$$ But the integrand on the right side does not seem measurable and even if it is measurable, perturbing each $y \mapsto (\mu^\alpha)_y$ on a $\pi(\mu^\alpha)$-null set can perturb $y \mapsto \int_A (\mu^\alpha)_y \ d\rho(\alpha)$ on the whole Y (this issue can be demonstrated with a simple example with finite $A$), so the proposition as stated is false. How should I modify the proposition to make it true? Example demonstrating the issue Let $\mu = \frac12 \mu^1 + \frac12 \mu^2$ where $\mu^1, \mu^2 \in M([0,1]\times[0,1])$ are the uniform distributions on $[0,1]\times [0,\frac12]$, $[0,1]\times [\frac12, 1]$ respectively. Then $\mu$ is the uniform distribution on the unit square $[0,1]\times [0,1]$. Denote by $\lambda$ the uniform distribution on $[0,1]$, i.e., the Lebesgue measure restricted to $[0,1]$. Denote by $\delta_y$ the Dirac measure on $y \in [0,1]$.
The map $y \mapsto \mu^1_y$ defined by
$$\mu^1_y = 
\begin{cases}
  \lambda \times \delta_y & \text{if } y \in [0,\frac12] \\
  \delta_0 \times \delta_0 & \text{otherwise}
\end{cases}
$$
is a disintegration of $\mu^1$ w.r.t. the 2nd projection map $\pi: [0,1]\times [0,1] \to [0,1]$ defined by $\pi(x,y) = y$. Similarly, the map $y \mapsto \mu^2_y$ defined by
$$\mu^2_y = 
\begin{cases}
  \lambda \times \delta_y & \text{if } y \in [\frac12,1] \\
  \delta_0 \times \delta_0 & \text{otherwise }
\end{cases}
$$
is a disintegration of $\mu^2$ w.r.t. the same $\pi$. On the other hand, the map $y \mapsto \frac12 \mu^1_y + \frac12 \mu^2_y$ is not a disintegration of $\mu$ w.r.t. $\pi$.","['measure-theory', 'probability']"
1087053,Closed subsets in metric space,"I want to prove that any closed subset $F$ from a metric space $(E,d)$ can be written as a denumerable  intersection of open sets i.e., $$F=\bigcap_{n\in\mathbb{N}} \Theta_n; \Theta_n=\bigcup_{x\in F} B(x,\frac{1}{n})$$ It is clear that $F\subset \bigcap_{n\in\mathbb{N}} \Theta_n$ I suppose that $y\in \Theta_n$ for all $n\in \mathbb{N}^*$ and $y\notin F$ i.e., $\exists \delta>0; B(y,\delta)\cap F\neq \emptyset$ but the fact $y\in \Theta_n$ means that there exist $x\in F$ such that $d(x,y)<\frac1n, \forall n\in \mathbb{N}$ it still right for $n$ such that $\frac1n<\delta$ and then $x\in F\cap B(y,\delta)$ contradiction. But I don't know where to use the fact that $F$ is closed and $\Theta_n$ is open? Thank you.","['general-topology', 'metric-spaces', 'analysis']"
1087064,Non-zero eigenvalues of $AA^T$ and $A^TA$,"As a part of an exercise I have to prove the following: Let $A$ be an $(n \times m)$ matrix. Let $A^T$ be the transposed matrix of $A$. Then $AA^T$ is an $(n \times n)$ matrix and $A^TA$ is an $(m \times m)$ matrix. $AA^T$ then has a total of $n$ eigenvalues and $A^TA$ has a total of $m$ eigenvalues. What I need to prove is the following: $AA^T$ has an eigenvalue $\mu \not = 0$ $\Longleftrightarrow$ $A^TA$ has an eigenvalue $\mu \not = 0$ In other words, they have the same non-zero eigenvalues, and if one has more eigenvalues than the other, then these are all equal to $0$. How can I prove this? Thanks and regards.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
1087076,Proving a subring of $\mathbb{Q}$ containing $\mathbb{Z}$ is a PID,"Let $S$ be a subring of $\mathbb{Q}$ containing $\mathbb{Z}$. Prove that it is a principal ideal domain. So here is what I tried. Take any ideal $I\subset S$. Take any two elements, say $a=p/q, b=r/s$ in $I$. Rationalize denominators (we can do that since $\mathbb{Z}\subset S$. Now we have $aqs=p=K(r)=K(bqs)+R$, that is, just apply the Euclidean Algorithm. Now, $a-Kb=R/qs\in I$, so take the set of all such remainders $R/qs$. There are two possibilities. Either this set has a smallest positive element, or it does not. Suppose it has a smallest such element, call it $x=m/n$. Let $a=p/q\in I$. We show $a=lx$. For suppose not. Rationalizing denominators with $n, q>1$, $p=Lm+Z$, so then $Z<m$ so $Z/qn<m/n=x$, giving a contradiction. Now though, I am stuck on the case where there is no such smallest element :( Any thoughts? EDIT: For those marking it as a duplicate: The first answer in the linked question, as mentioned in the comments, feels somewhat unnatural and requires all this extra machinery. On the other hand, the second answer given is incomplete: The poster says ""Now show that the ideal generated by $t=\frac{t}{1}$ in R is the ideal you started out with."" But if $\frac{r}{s}\in I$, then there exists $k$ such that $r=kt$, so $\frac{r}{s}=\frac{k}{s}\cdot \frac{t}{1}$, but $\frac{k}{s}$ is not necessarily in $S$.","['principal-ideal-domains', 'ring-theory', 'abstract-algebra']"
1087077,Proving the inequality $ \left|\prod_{i=0}^n \left(x - \frac{i}{n}\right)\right| \le \frac{n!}{4n^{n+1}}$,"Let $n \in \Bbb{N}$ and $x \in [0,1]$ prove 
$$ \left|\prod_{i=0}^n \left(x - \frac{i}{n}\right)\right| \le \frac{n!}{4n^{n+1}}$$ I manage to show that $\left| (x-\frac{n-1}{n})(x-\frac{n}{n})\right| \le \frac{1}{4n^2}$ by taking derivative and finding the maximum, but I didn't manage to show that the rest  $\le \frac{n!}{n^{n-1}}$","['inequality', 'infinite-product', 'calculus', 'products', 'real-analysis']"
1087080,How does adding $0$ to the set $\mathbf A = \bigl\{\frac{1}{n}: n \in \mathbb N \bigr\}$ make it a closed set?,"By definition, a closed set is a set that contains its limit points. However, by the time the closed set contains its limit points, those points are no longer limit points and become isolated points. For example: $\mathbf A = \{\frac{1}{n}: n \in \mathbb N \}$. The limit of this set (set $\mathbf A$) is clearly equal to $0$. This is because the $\epsilon$ -neighborhood $\mathbf V_{\epsilon}(0) \cap \mathbf A = \{\frac{1}{n} \}$, and $\frac{1}{n} \neq 0$. However, when $0$ is included, the $\epsilon$ -neighborhood $\mathbf V_{\epsilon}(0) \cap \mathbf A = \{0 \}$ for $\mathbf A=[0,\frac{1}{n} ]$. This will contradicts the definition of limit point of set A and hence $0$ must be an isolated point. Another example: $\left(a,b\right)$ is an open interval with limit $a$ and $b$. Then its closure $\bar A$ will be $\left[a,b\right]$. By definition, the $\epsilon$ -neighborhood of any point in $\left[a,b\right]$ intersects the closure $\bar A$ at that same point, and hence, no points in that closure set is a limit point: A contradiction that closure sets are closed sets. Also, I am trying to prove the lemma: If x is a limit point of $A \subseteq A'$, then x is limit point of $A'$.
Proof: Suppose x is a limit point of $A$, then there exists a sequence $(a_n)$ $\subset A \subseteq A'$: lim($a_n$)=x with $a_n$ $\neq x \forall n \in \mathbb N$. Then since $(a_n)$ $\subset A'$, it follows that x must be a limit point of $A'$. So my questions are: 1. What is wrong with my contradiction in the 2 examples? Please explain them to me.
2. Is my proof for the lemma correct? I am going to use it for the proof that closure set is closed. My background: I am studying elementary Real Analysis by starting with Abbot. I thank you very much for your help. Extra question : We have this theorem: x is a limit point of set $A$ if and only if there exists a sequence $(a_n) \subset A$ such that $\lim (a_n)=x$ $\forall a_n \neq x$. So, for some finite $n \in \mathbb N$ such that $a_n = x$, x is still a limit point of set A . Is this correct? I thought that x would be an isolated points since we need $a_n \neq x \forall n \in \mathbb N$ I thank you again for your answers.","['general-topology', 'calculus', 'real-analysis']"
1087083,"Proving if an integral is positive, negative, or zero","Find $$\text{sgn}\left[\int_0^{2\pi} e^{-2014x^2}\sin(x) \, dx\right]$$
Source: TCU Calculus Bee 2014 (Held 8 months ago)
By logic because the $\displaystyle\int_0^\pi \sin(x)\,dx=-\int_\pi^{2\pi} \sin(x)\,dx$ and the exponential is smaller in the interval $[\pi,2\pi]$, the area of the 2nd part is minimized, making it positive. Can anyone provide a more rigorous proof of the answer?","['definite-integrals', 'calculus', 'integration']"
1087094,Solve $x^4+3x^3+6x+4=0$... easier way?,"So I was playing around with solving polynomials last night and realized that I had no idea how to solve a polynomial with no rational roots, such as $$x^4+3x^3+6x+4=0$$ Using the rational roots test, the possible roots are $\pm1, \pm2, \pm4$ , but none of these work. Because there were no rational linear factors, I had to assume that  the quartic separated into two quadratic equations yielding either imaginary or irrational ""pairs"" of roots.  My initial attempt was to ""solve for the coefficients of these factors"". I assumed that $x^4+3x^3+6x+4=0$ factored into something that looked like this $$\left(x^2+ax+b\right)\left(x^2+cx+d\right)=0$$ because the coefficient of the first term is one.  Expanding this out I got $$x^4+ax^3+cx^3+bx^2+acx^2+dx^2+adx+bcx+bd=0$$ $$x^4+\left(a+c\right)x^3+\left(b+ac+d\right)x^2+\left(ad+bc\right)x+bd=0$$ Equating the coefficients of both equations $$a+c = 3$$ $$b+ac+d = 0$$ $$ad+bc = 6$$ $$bd = 4$$ I found these relationships between the various coefficients.   Solving this system using the two middle equations: $$\begin{cases} b+a\left(3-a\right)+\frac4b=0 \\ a\frac4b+b\left(3-a\right)=6 \end{cases}$$ From the first equation: $$a = \frac{3\pm\sqrt{9+4b+\frac{16}{b}}}{2}$$ Substituting this into the second equation: $$\frac{3\pm\sqrt{9+4b+\frac{16}{b}}}{2}\cdot\frac4b+b\cdot\left(3-\frac{3\pm\sqrt{9+4b+\frac{16}{b}}}{2}\right)=6$$ $$3\left(b-2\right)^2 = \left(b^2-4\right)\cdot\pm\sqrt{9+4b+\frac{16}b}$$ $$0 = \left(b-2\right)^2\cdot\left(\left(b+2\right)^2\left(9+4b+\frac{16}b\right)-9\left(b-2\right)^2\right)$$ So $b = 2$ because everything after $\left(b-2\right)^2$ did not really matter in this case.  From there it was easy to get that $d = 2$ , $a = -1$ and $c = 4$ .  This meant that $$x^4+3x^3+6x+4=0 \to \left(x^2-x+2\right)\left(x^2+4x+2\right)=0$$ $$x = \frac12\pm\frac{\sqrt7}{2}i,\space x = -2\pm\sqrt2$$ These answers worked!  I was pretty happy at the end that I had solved the equation which had taken a lot of work, but my question was if there was a better way to solve this ?","['algebra-precalculus', 'polynomials', 'quadratics', 'factoring', 'quartics']"
1087100,Prove that: if $T$ is an irreducible linear operator then $T$ is cyclic,"Let $T:V\to V$ be a linear operator on a finite dimensional vector space $V$. I need to prove that: If $T$ is irreducible then $T$ is cyclic My definitions are: $T$ is an irreducible linear operator iff $V$ and {$0$} are the only complementary invariant subspaces T is a cyclic linear operator iff $V$ is a cyclic subspace (i.e. there is a vector $v\in V$ such that $V$ is generated by the set of vectors {$v, T(v),T^2(v),...$} I don´t know where to start. Any comment, suggestion or hint would be highly appreciated",['linear-algebra']
1087103,Maps between two line bundles versus sections of their tensor product,"There is a point about maps betwen line bundles (continuous or smooth or holomorphic --- I don't think it matters for this question) that is glossed over in many texts. A map from one line bundle $N_1$ to another $N_2$ over the same space $X$ is a map $h$ that makes a commutative triangle with the projections to $X$. These maps form a vector space over the base field, and we will call this vector space $\mbox{Hom}_X(N_1,N_2)$.  Let's fix the base field to be $\mathbb C$ and take the fibres of the $N_i$ to be copies of $\mathbb C$, to make things concrete. On the other hand, maps between $N_1$ and $N_2$ can also be thought of as (continuous, smooth, holomorphic) global sections of the line bundle $N_1^*\otimes N_2$, i.e. as elements of $H^0(X;\mathcal O(N_1^*\otimes N_2))$, where $\mathcal O$ denotes the sheaf of continuous or smooth or holomorpic sections, as appropriate. Question: Why is $\mbox{Hom}_X(N_1,N_2)=H^0(X;\mathcal O(N_1^*\otimes N_2))$, at least as sets?  (Once set-theoretic equivalence is established, the vector space isomorphism should come for free.) The reason why these two view points on line bundle maps are equivalent is not explained in any of the standard texts that I use. I understand the correspondence at the level of a single fibre, i.e. the linear algebra of why maps from one copy of $\mathbb C$ into another copy are given by $\mathbb C^*\otimes\mathbb C$.  But thinking at the level of open sets or globally, a bundle map from the first view point is a map between the total spaces of $N_1$ and $N_2$ that commutes with projections to $X$.  From the second point of view, it is a map from the space $X$ into the total space of $N_1^*\otimes N_2$ that commutes with a projection to $X$. How can I reconcile these? (As part of the question, I'm also not sure how the projection of $N_1^*\otimes N_2$ to $X$ is determined by the data of $N_1$ and $N_2$.  I understand how the transition functions of the tensor product relate to those of $N_1$ and $N_2$ --- I'm not asking about that. How is the projection map for the tensor product is obtained?)","['sheaf-theory', 'algebraic-geometry', 'vector-bundles']"
1087107,"How to express $E[\max(x,y)]$ as an integral?","In Hull (2008, p. 307) , the following equation is found (Eq. 13A.2): $$E[\max(V-K,0)]=\int_{K}^{\infty} (V-K)g(V)\:dV$$ Where $g(V)$ is the PDF of $V$ and $V,K>0$. I'd like to extrapolate from this to find a general expression for $E[\max(x,y)]$ where $x,y>0$. I guess it would be: $$E[\max(x,y)]=\int_{0}^{\infty} x g(x)\:dx+\int_{0}^{\infty} y f(y)\:dy$$ Where $g(x)$ and $f(y)$ are the respective PDFs of variables $x$ and $y$.  Is that right?","['probability-theory', 'expectation']"
1087133,Correspondence between countably generated sigma algebras and partitions,"Let X be a standard Borel space and $\mathcal C, \mathcal D$ be countably generated sub sigma algebras of the Borel sigma algebra of X. Suppose that for each $x \in X$ we have $[x]_{\mathcal C} \subset [x]_{\mathcal D}$ where $[x]_{\mathcal C}$ means the intersection of all elements in $\mathcal C$ containing $x$. Does it follow that $\mathcal D \subset \mathcal C$? Even for finite $\mathcal D$, I don't know how to proceed. But once the finite $\mathcal D$ case is done, the infinite case follows easily. Special cases where this implication is known include: the case where $\mathcal D$ is the Borel sigma algebra of X the case where $\mathcal C, \mathcal D$ are both finite A related question where ignoring null sets is allowed is: Two possible senses of a random variable being a function of another random variable","['measure-theory', 'descriptive-set-theory']"
1087149,"parity problems for sieve methods, is it only for Selberg Sieve or for all sieve methods?","It is said that sieve methods have parity problems. Terence Tao gave this ""rough"" statement of the problem: ""Parity problem. If A is a set whose elements are all products of an odd number of primes (or are all products of an even number of primes), then (without injecting additional ingredients), sieve theory is unable to provide non-trivial lower bounds on the size of A. Also, any upper bounds must be off from the truth by a factor of 2 or more."" Does this problem only happen to Selberg Sieve or does it also happen to all other type of sieve methods ?","['sieve-theory', 'number-theory', 'goldbachs-conjecture', 'analytic-number-theory', 'riemann-hypothesis']"
1087154,"(complex measures) $d\nu=d\lambda +f\,dm \Rightarrow d|\nu|=d|\lambda| +|f|\,dm$ and $f\in L^1(\nu)\Rightarrow f\in L^1(|\nu|)$","Two simple exercises on complex measures I don't know how to solve, from Folland's Real Analysis . I find it difficult to manipulate the definitions in computations. For context, if $\nu$ is a complex measure on $(X,\mathcal{M})$ then $|\nu|$ is defined as $d|\nu|=|g|\,d\mu$ where positive measure $\mu$ and $g\in L^1(\mu)$ are such that $\nu \ll \mu$ and $\nu = g\,d\mu$ (and in the textbook it's shown that this definition does not depend on the choice of $\mu$). 1) Let $\nu$ be a reguar complex Borel measure on $\mathbb{R}^n$, $m$ denote   Lebesgue measure, and
  let $d\nu = d\lambda + f\,dm$ be its Lebesgue-Radon-Nikodym
  representation. Then (""it is easily verified"")
  $d|\nu|=d|\lambda|+|f|\,dm$. 2) If $f\in L^1(\nu)$ then $f\in L^1(|\nu|)$. I was able to prove the
  reverse implication, but not this one. The definition of $|\nu|$ in the case of real signed measures (as $|\nu|=\nu^+ + \nu^-$) makes sense to me but I can't see intuitively into the definion of $|\nu|$ for complex measures as given in the textbook. Do you have any advice on this? Thank you!","['derivatives', 'measure-theory', 'integration', 'real-analysis']"
1087155,Constructing functions such that integral along any closed curve is non-zero,"Consider smooth maps $f: \mathbb R^2 \setminus \{(0,0)\} \to \mathbb R$. How can I construct such an $f$ with the property that $$ \oint_C f \neq 0$$ for any closed curve $C$ around the origin? Note that I am aware that $\frac{xdy-ydx}{x^2+y^2}$ has this property but knowing the answer is unhelpful to me as it does not tell me how to find such a function. Ideally, I would like to see an answer with $$ f \neq
 \frac{xdy-ydx}{x^2+y^2}$$","['multivariable-calculus', 'differential-forms']"
1087185,Generators of $H^1(T)$,"Let $T$ denote the torus. I am working towards an understanding of de Rham cohomology. I previously worked on finding generators for $H^1(\mathbb R^2 - \{(0,0)\})$ but then realised that for better understanding I had to look at different examples, too. For the purpose of this question I am only interested in finding just one generator, I'll think about finding a second generator later. Can you tell me if this is correct? My work: By definition, $H^1 = {\ker d_2 \over \mathrm{im} d_1}$ where $d_2: \Omega^1 \to \Omega^2$ and $d_1: \Omega^0 \to \Omega^1$ are the exterior derivatives. My goal is to find a differential $1$-form that is closed and not exact, that is, not in the image of $d_1$. My idea is to randomly examine different $1$-forms and verifying their properties, starting with the simplest one that comes to mind: $$ dx + dy$$ Since $$ d(dx + dy) = dx \wedge dy - dx \wedge dy = 0$$ this is a candidate for a generator. The only remaining thing to do is to verify whether this is in the image of $d_1$. If it was in the image of $d_1$, by Stokes' theorem $$ \oint dx + dy$$ would have to vanish as the torus has an empty boundary. I am sure this should not vanish but I'm not sure how to calculate such an integral. One would have to parametrise the torus somehow but this is where stuff gets messy. Is there an easy way to do it? Hence my question: How to calculate $ \oint dx + dy$ on the torus?","['homology-cohomology', 'differential-forms', 'differential-geometry', 'solution-verification']"
1087199,Applying the Frobenius theorem to a decomposable 2-form,"So I have the following problem: Suppose $\omega=\phi \wedge \theta$ is a closed decomposable 2-form on $M$ a manifold (decomposable just means it can be written as a wedge of 1-forms). Suppose $p\in M$ is a point such that $\omega\neq 0$. Use the Frobenius Theorem to prove that $\omega=dx^{1}\wedge dx^{2}$ in some coordinate system in a neighborhood around $p$. So the formulation of the Frobenius theorem that I now is the one about completely integrable and involutive distributions being equivalent. Even if I show that $\omega$ somehow defines an involutive distribution, I don't know how to use the flat chart to get $\omega$ into the desired form. Thanks for any help!","['differential-topology', 'differential-forms', 'smooth-manifolds', 'differential-geometry']"
1087212,Prove that $\frac{e^{2x}-1}{e^{2x}+1}i=\tan{ix}$,I have a doubt in complex numbers which I am unable to solve. The question is Prove that $$\left(\frac{e^{2x}-1}{e^{2x}+1}\right)i=\tan{ix}$$ I tried using hyperbolic sin and cosines but failed. Can anybody guide me how to tackle this question,"['trigonometry', 'complex-numbers', 'exponential-function']"
1087213,Confused by how to derive the derivative of $f(\boldsymbol{x})=g(\boldsymbol{y})$,"I was watching an online tutorial and saw this derivation. It seems the the author took the derivative with respect to y on left side and to x on right side. I thought dx should always be in the denominator and should on both side of the equation. Is it partial derivative? Or maybe my misunderstanding of the notation? Could anyone explain how this works? FYI the link of the tutorial is https://www.youtube.com/watch?v=aXBFKKh54Es&list=PLwJRxp3blEvZyQBTTOMFRP_TDaSdly3gU&index=98 , the differentials was taken at around 2'20"" Much appreciated! Happy New Year.",['ordinary-differential-equations']
1087264,Solve $x+a^x<b$ algebraically,"The answer to $x+3^x<4$ is $x<1$ by plotting the graph of $y=x+3^x$ and $y =4$. Is there a way to get to the solution algebraically? Updated: is there a way to get to the solution of $x+a^x<b$ in general, algebraically?","['inequality', 'calculus', 'algebra-precalculus']"
1087270,Fundamental Theorem of Calculus: Why Doesn't the Integral Depend on Lower Bound?,"The second part of the Fundamental Theorem of Calculus essentially states that if $$F(x) = \int^x_a{f(t)}\,dt\,,$$ then $$F'(x) = f(x)\,.$$ My question is: why does the result not depend on the lower limit of integration $a$?","['calculus', 'integration']"
1087283,Find all trig ratios of $\cot \beta = -\frac13$,"Find all the trig ratios where $\cot \beta = -\dfrac13$, and $\pi < \beta < 2\pi$. I understand how to do this type of problem for sine and cosine, but with tangent and cotangent I don't understand how to do it. The answers for some of the trig ratios are $\sin \beta = -\dfrac1{\sqrt{10}}$ and $\cos \beta = \dfrac{-3}{\sqrt{10}}$. In particular, how do we arrive at the $\sqrt{10}$?",['trigonometry']
1087303,A basic question on spaces of probability measures,"This problem is regarding the space of probability measures. For $N \geq 1$, let $\{e_i^N(.), i\geq 1\}$ denote a complete orthonormal basis for $L_2[0,N]$. Let $\{f_j\}$ be countable dense in the unit ball of $C(S)$. Then it is true that $\int f_jd\nu_1 =  \int f_jd\nu_2 \forall j$ implies $\nu_1=\nu_2$. Then define the metric $$d(\nu_1(.),\nu_2(.))=\sum_{N\geq1}\sum_{i\geq1}\sum_{j\geq1}2^{-(N+i+j)} \left|\int_{0}^{N}e_i^N(t)\int f_jd\nu_1(t)dt - \int_{0}^{N}e_i^N(t)\int f_jd\nu(t)dt\right| $$ Now given that $$\frac{1}{m}\sum_{k=1}^{m}\int f_jd\nu_{n}(t) \to \int f_jd\nu*(t)$$ a.e. $t$ One paper claims that $d(\nu_{n}(.), \nu*(.)\to 0$. I have no clue how can one conclude convergence of the original sequence from the convergence in ceasaro mean","['probability-theory', 'weak-convergence', 'real-analysis']"
1087307,Solve a system of differential equations,"I want to know how solve the following system of differential equations. $$\frac {dy}{dx} = z-x$$ $$\frac{dz}{dx}=y+x$$ Where $y(0)=1, z(0)=1$ As I can understand I cannot represent this system as $x'=Ax$. What is the correct method to solve this system.","['linear-algebra', 'ordinary-differential-equations']"
1087319,How to determine whether a differential $1$-form is globally welldefined?,"This is a question that occurred after working on finding a generator of the first de Rham cohomology group of the torus. It was pointed out to me that the differential $1$-form $$ dx + dy$$ was well defined on all of $T$ and that this is generally not the case. Hence my question(s): (1) Given a differential form, how do I find out whether it is
  globally well defined or only locally? (2) In this concrete example how can I prove that $dx + dy$ is well
  defined on $T$? Since the two questions seem so closely related I posted them in one question but if this is inappropriate please leave a comment and I will split them into two separate quetions.","['differential-forms', 'differential-geometry']"
1087326,Showing that $g$ is continuous by showing that a series converges?,"Define $g:\Bbb{R}\setminus\Bbb{Z}\to\Bbb{R}$ by
  $$g(x)=\dfrac{1}{x}+\sum\limits_{n=1}^\infty\dfrac{2x}{x^2-n^2}.$$Show
  that $g$ is continuous. $g$ can be rewritten as $$g(x)=\dfrac{1}{x}+\sum\limits_{n=1}^\infty\dfrac{1}{n+x}-\dfrac{1}{n-x}.$$Let $\epsilon>0$. Now, our job is to find a $\delta>0$ such that whenever $\left|x-y\right|<\delta$, $$\left|\dfrac{1}{x}-\dfrac{1}{y}+\sum\left(\dfrac{1}{n+x}-\dfrac{1}{n+y}+\dfrac{1}{n-y}-\dfrac{1}{n-x}\right)\right|<\epsilon.$$ That is; $$\left|\dfrac{y-x}{xy}+(y-x)\sum\left(\dfrac{1}{(n-y)(n-x)}-\dfrac{1}{(n+x)(n+y)}\right)\right|<\epsilon.$$ I believe I need to find the limit of that last sum, but I don't know how. Or at least I should find an upper bound $A$ so that I can find a $\delta$ such that $\delta<\dfrac{\epsilon}{AB}$ where $\dfrac{1}{xy}<B$. What should I do?","['sequences-and-series', 'continuity', 'real-analysis', 'limits']"
1087348,Cardinality of subsets of $\mathbb{N}$ with fixed asymptotic density,"For a set $S\subset \mathbb{N}$, let $$a(S)=\lim_{n\rightarrow\infty}\frac{\#\{s\in S\>|\>s\le n\}}{n}$$ be the limiting asymptotic density of $S$ in the natural numbers if the limit exists, and $a(S)=0$ if it does not. Now take $0<\alpha<1$ and let $$A_\alpha = \{S\subset \mathbb{N}\>|\>a(S)=\alpha\}$$ be the set of all subsets of $\mathbb{N}$ with asymptotic density $\alpha$. Is $A_\alpha$ countable?","['natural-numbers', 'elementary-set-theory']"
1087354,If $A$ is a symmetric and positive definite matrix then $\text{tr}(A)^n\geq n^n\det A$,If $A$ is an $n \times n$ symmetric and positive definite matrix then is the following relation $\text{tr}(A)^n\geq n^n\det A$ true? How to show this?,"['matrices', 'linear-algebra']"
1087365,How to solve $x^x=100$?,"$x^x = 100$. I have no clue on how to solve this. If you guys have, please show me your solution as well.",['algebra-precalculus']
1087375,"Given a unitary matrix $U$, how do I find $A$ such that $U=e^{iA}$?","A unitary matrix $U \in \mathbb C^{n \times n}$ can always be written in exponential form $$U = e^{iA} \tag{1}$$ where $A$ is Hermitian. My goal is to find the Hermitian matrix $A$ , given the unitary matrix $U$ . I figured out a way by diagonalizing $U$ , in the following form: $$U = V^{\dagger} [e^{ia_{kk}}] V$$ Therefore, we get $$A = V^{\dagger} [a_{kk}] V$$ Is this the standard way for finding the Hermitian matrix $A$ in equation (1)? If I'd like to learn more about the exponentiation of unitary operators, and their general properties, what topics should I read?","['unitary-matrices', 'matrix-exponential', 'operator-theory', 'matrices', 'matrix-calculus']"
1087382,Showing Differentiability of Function,"Prove that $$f(t) = \int_{1}^{\infty} \frac{\sin(tx)}{1+x^{2}} dx $$ is differentiable on $(0, \infty)$. I tried to use dominated convergence theorem but have trouble finding the dominating function.... If we take the derivative $\frac{d}{dt}$ inside the integral, we get $$f_{t}(x) = \frac{x \cos(tx)}{1+x^{2}}$$ inside the integral, but I don't see how I can use the theorem here...","['derivatives', 'real-analysis']"
1087389,$f: X \mapsto X$ is a function with $f^n =\operatorname{ id}_X$ for a $n \geq 1$. Prove that $f$ is a bijection.,"The problem above is easy to see with $n = 1$ , because then every element of $X$ maps to itself and the function $f$ is obviously bijective. By $n = 2$ we have for every $x \in X$ one $y \in X$ s.t. $(x) = y, f(y) = x$ . So every element of $X$ maps to exactly one other element of $X$ and $f$ is thus bijective. However, the proof does not cover all $n \geq 1$ , but only the first two $n's$ . Is there a better possiblility to make a proof that covers all $n \geq 1$ ?",['elementary-set-theory']
1087412,What is a function?,"I have been quite confused by the definition of functions and their uses.. First of all can one define functions in a clear understandable way, with a clear explanation of their uses, how they work and what they do? Also I have some specific questions regarding functions Let me give you a examples: $y = f(x) \rightarrow$ This is one of the main reasons I have difficulties understanding functions... What does the above statement tell me, and if $y$ is a function why do we use $y=$ at all for a formula like $y = mx + b$ would it be the same as writing $f(x) = mx + b$? Something like $y = x^2$ is apparently a function......
but where is the function name? Which is the input and which is the output? Lastly another example : Let me suppose $f =$ distance $f(t) = t^2$ $f(2) = 4 \rightarrow$ Does this mean distance is $4$.. which is the input which is the output? Mainly what I'm looking for in an answer is a clear and 'easy' explanation with examples to help me understand this new topic","['notation', 'algebra-precalculus', 'functions']"
1087413,Prove equation has only one root in a specific interval,"Prove that the following equation has only one solution in the interval $[-\text{min}(a_i), +\infty]$: $f(x) = \left(\sum_{i=1}^n \frac{1}{a_i + x}\right)\times \left(\sum_{i=1}^n \frac{a_i b_i}{(a_i + x)^2}\right) 
- \left(\sum_{i=1}^n \frac{a_i}{a_i + x}\right) \times \left(\sum_{i=1}^n \frac{b_i}{(a_i + x)^2}\right)
=0$ $x\in \mathbb{R}$ $n>1$. $a_i$ and $b_i,\,\, i=1,..., n$, are all positive real numbers. $a_1> a_2> ... > a_n$ $a_i \neq a_j\quad\forall i, j = 1,..,n, i\neq j$. The context of the problem is as follows: $a_i$ are the squared singular values of a random matrix. $b_i$ are the diagonal elements of a sample covariance matrix. I tried solving the equation for different parameter values using Newton's method. It always converges when initialized at zero. The plot of the function in the interval of interest always shows increasing function from the start of the interval, zero crossing, a maximum, then the function continuously decreases. The function approaches zero as $x$ increases following the peak value. We note/can prove the following: $f(x)$ has $n$ discontinuities at $-a_i$. $f(x)$ is continuous in the interval of interest $[-\text{min}(a_i), +\infty]$ = $[-a_n, +\infty]$. $\lim_{x \to +\infty} = 0$. $\lim_{x \to -a_n} = -\infty$. $f(x)$ is infinitely differentiable in the interval of interest. $f(x)$ can be put in the form:
$f(x) = \sum_{\{i,j\}} \frac{a_i - a_j}{(a_i + x)(a_j + x)} \left(\frac{b_i}{a_i + x} - \frac{b_j}{a_j + x} \right)$ for all permutations of $\{i,j\}\subset\{1,...,n\}, i< j$. I tried the following steps to prove that $f(x)$ has a single root in the interval $[-\text{min}(a_i), +\infty]$: Assume $x_0\in [-\text{min}(a_i), +\infty]$ is a root. Tried to show that $x_0$ is not a solution of $f^{'}(x)$, but the derivative expression is far more complex to figure that out. Any suggestion for an alternative way to obtain the required proof?","['roots', 'functions']"
1087420,What is $\rightarrowtail$ used for?,"I have come across this symbol many times, but I am unsure as to how to correctly use it. So I can read up on it, what is the name of this mapping function? When would it be correct to use and when wouldn't you use it? I think it may be used when you haven't specified a function for the mapping, but just a guess. Example: Any wellordered set $\langle X,\prec\rangle$ is order isomorphic to the set of its segments ordered by $\subset$ Proof: Let $Y=\{X_a\vert a\in X\}$ . Then $a\rightarrowtail X_a$ is a (1-1) mapping onto $Y$ , and since $a\prec b\Leftrightarrow X_a\subset X_b$ the mapping is order preserving. Is it necessary to use $\rightarrowtail$ here, could you just use $\mapsto$ or $\rightarrow$ , in this example why did we use this symbol?","['notation', 'functions']"
1087448,"Is ""being solvable"" a geometric property for linear algebraic groups?","Say $G$ is a solvable linear algebraic group over some field $k$ of characteristic 0. This means that its derived series eventually terminates with a 1. My question is: Is ""being solvable"" a geometric property? By this, I mean: is it true that $G$ is solvable iff $G_{\bar{k}}$ is solvable? I know that ""being virtually solvable"" is not a geometric property, but it's not clear to me that this holds also for ""being solvable"" Details and references in the answers are very welcome.","['solvable-groups', 'algebraic-geometry', 'algebraic-groups', 'group-theory']"
1087458,Simple limit problem without L'Hospital's rule,"$$\lim_{x \to 1}\frac{\sqrt{x^4 + 1} - \sqrt{2}}{\sqrt[3]{x} - 1}$$ We are not supposed to use any derivatives yet, but I can't find any formula that helps here. It's a $\frac{0}{0}$ indeterminate form, and all I think of doing is $$\frac{\sqrt{x^4 + 1} - \sqrt{2}}{\sqrt[3]{x} - 1} = \frac{\sqrt{x^4 + 1} - \sqrt{2}}{\sqrt[3]{x} - 1} \cdot \frac{\sqrt{x^4 + 1} + \sqrt{2}}{\sqrt{x^4 + 1} + \sqrt{2}} = \frac{x^4-1}{(\sqrt[3]{x}-1)\cdot(\sqrt{x^4+1}+\sqrt{2})}$$ but I don't see if this leads anywhere.","['limits-without-lhopital', 'calculus', 'limits']"
1087500,Are the sets in a basis open in the topology the basis generates?,"A collection $\mathcal{B}$ of subsets of a set $X$ is called a basis if: For each $x\in X$, $\exists B\in\mathcal{B}$ with $x\in B$. If $x\in B_1\cap B_2$ for $B_1,B_2\in\mathcal{B}$, then $\exists B_3\in\mathcal{B}$ with $x\in B_3\subset B_1\cap B_2$. Let $\mathcal{J}$ be the topology on $X$ generated by $\mathcal{B}$: $U \subset X$ is open (that is, $U \in \mathcal{J}$) if $\forall x\in U\; \exists B\in\mathcal{B}:x\in B\text{ and }B\subset U$. So are basis elements open? Let $U\in\mathcal{B}$. I need to show that $\forall x\in U$ there exists a basis element that contains $x$ and this basis element must itself be contained in $U$",['general-topology']
1087513,Isomorphism between stalk and stalk of the pushforward sheaf.,"Let $f \colon X \to Y$ be a continuous map and $\mathcal{O}_X$ a sheaf (of sets) on $X$. Question: Is the stalk $(f_*\mathcal{O}_X)_{f(p)}$ for $P \in X$ isomorphic to the stalk $\mathcal{O}_{X,P}$ ?
If it is, how exactly does the isomorphism map elements of these stalks (which are equivalence classes of pairs $(U,g)$) to one another ? Is the isomorphism unique/universal/canonical in some sense? Remark: I know (just) a little bit about adjunctions, but if the answer is related to the inverse image functor (which I don't feel familiar with) and the adjunction to the pushforward, please give me a detailed explanation. Thank you.","['sheaf-theory', 'algebraic-geometry']"
1087530,Area common to two equal ellipses with same centre but axes rotated by an acute angle,Been some time since I did this kind of geometry and it seems to have me stumped already but looks so innocent. Any help would be most welcomed. The answer is quoted to be : $2ab \arctan\left(\dfrac{2ab}{(a^2 - b^2) \sin\theta}\right)$,['geometry']
1087543,Two scheme morphisms agree on a dense open subset must be equal,"I'm trying to prove this statement Let $ f,g:X\rightarrow Y$ be two $ S $-scheme morphisms that agree on $ U $, a dense open subset of $ X $. If $ X $ is reduced and $ Y$ separated, then $ f = g $. I've gone so far as showing that the locus of agreement of $ f $ and $ g $ must be all of $ X $. The locus of agreement is a closed subscheme of $ X $ defined via this universal property If $h:Z\rightarrow X$ is another $ S $-morphism such that $ f\circ h=g\circ h $, then $ h $ factors uniquely through the locus of agreement. How can I show that since the locus of agreement is all of $ X$, then $ f=g$? It sounds intuitive, but I'm unable to show it via the universal property above. Thank you",['algebraic-geometry']
1087545,A simple proof that $\bigl(1+\frac1n\bigr)^n\leq3-\frac1n$?,"The inequality
$$
e_n:=\left(1+\frac1n\right)^n\leq3-\frac1n,
$$
where $n\in\mathbb{N}_+$, is certainly true, because we know, how LHS is connected with $e$. The other argument is the standard proof of boundedness of $(e_n)$, which uses the binomial theorem. Are there any more elementary proofs of this inequality?",['algebra-precalculus']
