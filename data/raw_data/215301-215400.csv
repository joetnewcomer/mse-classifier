question_id,title,body,tags
4368345,Why can't I have $\dot{x}(t) < 0$?,"I'm in the very beginning of ""Ordinary Differential Equations and Dynamical Systems"" by Gerald Teschl and on page 9 he starts with differential equations of the form: $$\dot{x} = f(x), \quad x(0) = x_0, \quad f \in C(\mathbb{R})$$ To solve these he quickly goes to: $$\int_{0}^t\frac{\dot{x}(s)ds}{f(x(s))} = t$$ Letting $F(x) =\int_{x_0}^x\frac{dy}{f(y)}$ he points out that any solution must satisfy that $F(x(t)) = t$ . So, since $F(x)$ is is strictly monotone in some neighborhood of $x_0$ , any solution $\phi$ will need to satisfy $$\phi(t) = F^{-1}(t), \phi(0) = F^{-1}(0) = x_0$$ Assuming, WLOG, $f(x_0)>0$ we can find a maximal interval $(x_1, x_2) \ni x_0$ where $f$ is positive in this interval as well. So we can define: $$T_+ = \lim_{x \uparrow x_2} F(x) \in (0, +\infty]$$ $$T_- = \lim_{x \downarrow x_2} F(x) \in [-\infty, 0)$$ So, $\phi \in C^1((T_-, T_+))$ . So far, so good. But, where I get confused is the following statement. Teschl states that: In particular, $\phi$ is defined for all $t > 0$ if and only if: $$T_+ = \int_{x_0}^{x_2}\frac{dy}{f(y)} = +\infty$$ This is what I don't understand. I understand the ""if"" direction - if the integral evaluates to infinity, then the approaches $x_2$ but keeps slowing down so that it never actually reaches $x_2$ . But, the ""only if"" direction confuses me. $x_2$ is just the maximal point to the right of $x_0$ where the velocity stays positive (since it started out positive). To me, this indicates that if the velocity starts out positive, it cannot every become negative, but that doesn't seem right. Can anyone help me understand why this must be true?",['ordinary-differential-equations']
4368397,An uncountable collection of groups with no nontrivial homomorphisms,"There are pairs of nontrivial groups having no nontrivial homomorphisms between them, for instance $\mathbb{Z}/2\mathbb{Z}$ and $\mathbb{Z}/3\mathbb{Z}$ . (I can think of at least one proof, using Lagrange's theorem.) With that example, it is easy to form at least one countable collection of groups such that no two groups exhibit nontrivial homomorphisms, namely $\{ \mathbb{Z}/p\mathbb{Z}\}_{p \text{ prime}}$ . What is an example of an uncountable collection of distinct groups containing no two groups with nontrivial homomorphisms between each other?","['group-theory', 'examples-counterexamples']"
4368402,application of Neyman–Pearson Lemma,"Suppose that the distribution of lifetimes of TV tubes can be modelled by an exponential distribution with mean $\lambda$ so $f(x|\lambda)$ = $\frac{1}{\lambda}$ $e^\frac{-x}{\lambda}$ , $x>0$ . Under usual production conditions the mean lifetime is $50$ hours but if a fault occurs in the process the mean lifetime drops to $40$ hours
A random sample of $20$ tube lifetimes is to taken in order to test the hypothesis $H_0:\lambda = 50$ vs $H_1:\lambda = 30$ and the following statistics is observed $\sum_{i=0}^n X_i = 680$ .
Use Neyman–Pearson lemma to find the most powerful test with signficance level $\alpha = 0.05$ . My attempt was to start with the joint probability ratio under $H_0$ and $H_1$ $$\frac{\frac{1}{50^{20}}e^{\frac{-\sum_{i=1}^{20} x_i}{50}}}{ \frac{1}{30^{20}}e^{\frac{-\sum_{i=1}^{20} x_i}{30}}} .$$ We reject $H_0$ when $(\frac{1}{\lambda_1} -\frac{1}{\lambda_0}) \sum_{i=1}^n X_i <k$ . Since in the parenthesis we have a positive quantity should we reject $H_0$ ? I do not understand the importance of the data $40$ since the alternative hypothesis is $30$ and not $40$ . Is this the right way to solve this exercise?
I am trying to understand Neyman–Pearson lemma and any help would be appreciate.","['statistical-inference', 'statistics', 'hypothesis-testing']"
4368434,"$A,B,C$ pairwise not disjoint, compact, connected subsets of $\mathbb{R}^2; A \cap B \cap C=\emptyset$ then $(A\cup B\cup C)^c$ is disconnected.","Note: I have simplified the question. I think trying to generalise this straight away is biting off more than I can chew. If $\ A, B, C\ $ are pairwise not disjoint, compact, connected subsets of $\ \mathbb{R}^2\ $ with $\ A \cap B \cap C = \emptyset\ $ then $\ \left(A\cup B\cup C\right)^c\ $ is disconnected. Is this true? Example diagram: Note that if we did not require $\ A, B, C\ $ to be compact, and therefore closed, then $\ A = B'(\ (-1,0);\ 2\ ), B = B'(\ (1,0);\ 2\ ), C = \overline{B'(\ (0,10),\ 10-\sqrt{3})}\ $ where $\ B'(\ x;\ r)\ $ means the open ball centred at $\ x\ $ with radius $\ r,\ $ is an example where $\ \left(A\cup B\cup C\right)^c\ $ is not disconnected.","['connectedness', 'general-topology', 'geometry', 'compactness']"
4368454,Conditions on space of smooth almost complex structures so that it's a banach manifold,"In the following paper by A.Abbondandolo and M. Schwarz https://arxiv.org/pdf/math/0408280.pdf in section $1.6$ we consider the set of smooth almost complex structures $\mathcal{J}$ on $T^*M$ compatible with $\omega_{can}$ and such that $||J-\hat J||_{\infty}<\infty$ , where $\hat J$ is the almost complex structure give by the splitting into the verical and horizontal components. They claim that one can put a distance on $\mathcal{J}$ defined as $\text{dist}(J_1,J_2)=||J_1-J_2||_{\infty}+dist_{C^{\infty}_{loc}}(J_1,J_2)$ , so that it's a complete metric space.
I was able to see that this was true. However can't we say something more general ? I.e. that this will be a banach space, if we define a norm as $||J||=||J||_{\infty}+\sum_{k=1}^{\infty}\sum_{l=0}^{\infty}2^{-r-l}\frac{||J||_{C^l(K_k)}}{1+||J||_{C^l(K_k)}}$ where $K_k=\{(t,q,p\in S^1\times T^*M:|p|\leq k)\}$ .  I also belive this is true but the authors don't say anyhting about this, hence this makes me feel at little suspicious. The reason I want this to be a banach space is so that when we prove that there exists a dense set of almost complex structures that give us transversality, we need to use the regular value theorem for banach manifolds. Edit: Nevermind this won't be a banach space since we won't have linearily. However I wonder if we can give this a structure of a banach manifold instead of a Frechet manifold. Any insight is appreciated, thanks in advance.","['banach-spaces', 'symplectic-geometry', 'almost-complex', 'differential-geometry']"
4368460,Finite groups $G$ such that every Galois extension of group $G$ is totally real,"I was playing with Galois extensions of small degree while preparing the final exam for my course in Galois thoery, when the following question came up: Question. Can we characterize the finite groups $G$ such that every Galois extension $L/\mathbb{Q}$ with Galois group $G$ is totally real ? Note that every finite group $G$ with odd order satisfies this condition: if $\alpha$ is a primitive element of $L/\mathbb{Q}$ , its minimal polynomial $f$ has odd degree, so it has a real root $\beta$ . Now $\beta$ is also a primitive element of $L$ , that is $K=\mathbb{Q}(\beta)$ . Now, since $L$ is Galois it contains all the roots of $f$ , so all the roots of $f$ are real. I strongly suspect that the answer to the question above is related somehow to the representations of $G$ , but I am not expert enough in representation theory to confirm this hunch. I am happy to assume the the Galois inverse conjecture is true, so we don""t have to care about the existence of Galois extensions $L/\mathbb{Q}$ of given group $G$ . Addendum. I don't know any example of group having even-order satisfying the required property.","['number-theory', 'finite-groups', 'representation-theory', 'galois-theory', 'group-theory']"
4368542,Finite Cartesian product of naturals is countably infinite + notation.,"$\newcommand{\N}{\mathbb{N}}$ I tried to prove $ |\N| = |\N^n| $ for all $n \in \N$ by mathematical induction. base step: $|\N| = |\N|$ is trivial inductive step: Let $|\N| = |\N^n|$ . Then, there is a bijection $f: \N \to \N^n$ . We can define $g: \N \times \N \to \N \times \N^n$ such that $$
\forall i, j \in \N: g(i, j) = (i, f(j))
$$ $g$ is bijective. Let $h: \N \times \N \to \N^{n+1}$ be defined as $$
\forall i, j \in \N:\forall k \le n+1: (\pi_k \circ h)(i,j)
=
\begin{cases}
i, & k = 1\\
(\pi_{k-1} \circ f)(j), & k \neq 1
\end{cases}
$$ $h$ is also bijective. Since $|\N| = |\N \times \N|$ , there is a bijection from $\N$ onto $\N^{n+1}$ Questions : Is this a valid proof? I defined $h$ from $g$ using a canonical projection $\pi_k$ to explicitly show the existence of a bijection to $\N^{n+1}$ . This is somewhat redundant, but $g(i, j) = (g_1, (g_2, g_3,\cdots))$ is actually not what we are looking for. When I am supposed to write them in a technical paper, should I explicitly define $h$ ? This question is not confined to my proof.","['elementary-set-theory', 'notation']"
4368551,Why is $1- \cos ( x+ \sin (x+ \sin(x +\sin(x + \cdots))))$ the cycloid?,"As many of you probably know, the cycloid is given by the parametric equation: \begin{equation}
x= t-\sin t\tag{1} \label{eq:x}
\end{equation} \begin{equation}
y= 1- \cos t\tag{2}\label{eq:y}.
\end{equation} I would like to have an equation for the cycloid that does not depend on the parameter $t$ .
If we could just solve \eqref{eq:x} for $t$ we could just plug that expression into \ref{eq:y} and I would be happy. But, as far as I know we can't solve \ref{eq:x} for $t$ . However, it is easy enough to find that $t= x+ \sin t $ . We know that $\sin t$ must be somewhere between $-1,1$ , so for an approximation, we might decide to simply drop this term and substitute $t = x$ into equation \ref{eq:y} to get $1- \cos(x)$ . Looking at a graph this looks like a reasonable but very rough approximation of the actual cycloid. I noticed that there is a simple way to improve this approximation. Recall that $t= x+ \sin t $ . What happens if we just plug in the expression $x+ \sin t$ for $t$ into the right hand side to get $t= x+ \sin( x+ \sin t)$ . Again, since we are approximating, we can just let $\sin t = 0$ . Substitute $t= x+ \sin x$ into \ref{eq:y} to obtain the much better approximation to the cycloid $$ y= 1-\cos( x+ \sin(x)).$$ This has lead me to conjecture the following:
Let $f_1(x) = x $ and $f_n(x) = x + \sin \big( f_{n-1} (x) \big)$ .
Define $g_n(x) = 1- \cos f_n(x)$ . Then, $g(x)= \lim_{n \to \infty} g_n(x)$ is the cycloid. I do not have a proof of this and could not find this description of the cycloid anywhere (maybe because it is a pain to work with). So, I have two questions: How can I prove my conjecture? Is the recursive method to ""solve"" equation \ref{eq:x} for $x$ used elsewhere?","['curves', 'uniform-convergence', 'limits', 'trigonometry', 'cycloid']"
4368588,Understanding a proof that $|\mathbb{R}^{\mathbb{N}}| = |\mathbb{R}|$,"I'm reading a set of lecture notes that gives a proof that $|\mathbb{R}^{\mathbb{N}}| = |\mathbb{R}|$ . I don't think I fully follow it, though it makes sense to me that this would give a bijection. It first notes that $|\mathbb{R}| = |(0,1)|$ , so it suffices to defines a bijection $(0,1) \to (0,1)^{\mathbb{N}}$ . We do so as follows. Given $x \in (0,1)$ with decimal expansion $x = 0.r_1 r_2 r_3 \ldots$ , define \begin{align*} 
x_1 & = 0. r_1 r_3 r_5 r_7 \\
x_2 & = 0.r_2 r_6 r_{10} r_{14} \\ 
x_3 & = 0.r_4 r_{12} r_{20} r_{28} \\ 
& \vdots \\ 
\end{align*} so I believe the general formula (but I'm not fully sure) comes out to $$
x_n = \sum\limits_{i=1}^\infty r_{2n - i} \cdot 10^{-i}.
$$ I don't fully understand why this is a bijection, though it seems I really only need it to be a surjection. I can certainly inject $(0,1)$ into $(0,1)^{\mathbb{N}}$ by taking $x \in (0,1)$ and sending it to a constant sequence, so if I can surject $(0,1)$ onto $(0,1)^{\mathbb{N}}$ , I can inject $(0,1)^{\mathbb{N}}$ into $(0,1)$ and conclude there exists a bijection by the Schroeder-Bernstein theorem. The proof, for the sake of well-definedness, surely requires that I make clear which decimal expansion of $x$ I'm using, so I think I need to say, ""if $x$ has two decimal expansions, pick the one that doesn't terminate in $9$ 's."" If I fix a decimal expansion (or a ""class"" of decimal expansions), I can claim this map is well-defined.
This doesn't guarantee that the resulting expansion of each $x_n$ doesn't terminate in $9$ 's, so that may be the reason this is only a surjection. If I pick a sequence in $(0,1)$ , I can expand each $x_n$ in a decimal expansion. That gives me a construction of the above form, and then I should be able to reconstruct $x$ by the above pattern. I'm not completely certain about injectivity, but I think it likely will fail because of issues with infinite $9$ 's in the decimal expansions. I would appreciate any help with making sense of this.","['elementary-set-theory', 'proof-explanation']"
4368590,Is there an easy way for a person to compute the determinant of an arbitrary matrix?,"I'm having a tough time proving statements that involve the determinant of an arbitrary matrix and was wondering if there is just an easier way to compute it or some simpler equivalent definition for it. Just to give an example: Let $K$ be a field, let $\lambda,a_0,a_1 \dots a_n \in K$ and $n \in \mathbb{N}$ . Prove that $$
A= \begin {pmatrix} \lambda &0 &0 &\dots  & a_0 \\ -1 & \lambda &0 &  \dots &a_1 \\0 &-1&\lambda &\dots& a_2  \\ \vdots & \dots & \dots & \dots &a_n\end{pmatrix}\in K^{(n+1)\times(n+1)}, \det(A)= a_n\lambda^n+\dots+ a_2\lambda^2+a_1\lambda+a_0$$ I have zero clue how I can go about this and the definition of the determinant is not very intuitive . My best guess was using the Laplace expansion so that $n+1 \times n+1$ matrix is not worrysome so that I can deal with the submatrix but I'm not sure where I can go from there. I would appreciate tips on how I should approach these proofs. (Also I would appreciate some help regarding the example problem as well).","['matrices', 'determinant', 'linear-algebra', 'laplace-expansion']"
4368607,"Rolling a pair of six-sided dice, what is the probability that the larger number is at least 5?","You have two six-sided dice. What is the probability that the larger number rolled will be at LEAST 5? I have listed out all the possible rolls.
You can set dice 2 equal to 5, and roll dice one. The possible rolls are (1,5), (2,5), (3,5), (4,5). Do the same thing, but this time dice 2 is set to 6. We have (1,6), (2,6), (3,6), (4,6), and (5,6). These 9 possible rolls can happen with setting the 1st dice to both 5 and 6 as well. Giving us a total of 18 possible rolls $$\therefore P=18/36$$ However, the answer I'm given states that $P=20/36$ . I'm having trouble understanding why.",['probability']
4368638,"Proof of $a^3 - b^3 = c^3 + d^3$, where $a,b,c,d$ all rational?","Reading Wikipedia article on Diophantus, it says in a book that survived that he makes reference to a lost book called Porisms and the theorem stated in the title: the difference between the cubes of any 2 rationals can be expressed as the sum of the cubes of 2 rationals. Anyone point me to this proof?","['number-theory', 'diophantine-equations']"
4368687,Finding every complex number that fulfills |z| = 1 and $|\frac{z}{\bar z} + \frac{\bar z}{z} | = 1$,"I wanna find out every complex number that fulfills $|z| =1 $ and $$ |\frac{z}{\bar z} + \frac{\bar z}{z} | = 1$$ The first thing i do is that i expand both of the denominators with their conjugates and since $ |z| = 1$ i get that $ z * \bar z = |z|^{2} = 1 $ So i'm left with the following expression $| z^{2}+(\bar z)^{2}|=1 $ The next thing i do is to change to polar form. Since $ |z|=1$ , i get that $$ z=|z|e^{i\theta}=e^{i\theta} $$ and $$ |e^{i2\theta}+e^{-i2\theta} | = 2|\frac{e^{i2\theta}+e^{-i2\theta}}{2}| = 2|cos(2\theta)|=1$$ Now, if i solve this i get 4 different complex numbers. However there should be 8 numbers so it seems that i lose answers somewhere or there is something im doing wrong that i can't seem to find.","['complex-analysis', 'complex-numbers']"
4368700,Prove the integration formula for arc length,"Suppose $f:J\to\mathbb R$ is differentiable and $f'$ is continuous on the domain. Then if $a,b\in J$ and $a<b$ , the length of the curve of the function on interval $[a,b]$ is \begin{equation}
  l(f)=\displaystyle \int ^a_b \sqrt{1+f'(x)^2} dx
\end{equation} This is my proof: Since the arc length is defined as $l(f,P)=\displaystyle \sum_{i=1}^n \sqrt{1+\dfrac{f(t_i)-f(t_{i-1})}{t_i-t_{i-1}}}\Delta t_i$ $f'(x)$ is the result from using MVT one each interval $[t_{i-1},t_i]$ created by the partition P then the definition of arc length can be turned to be \begin{equation}
l(f,P)=\displaystyle \sum_{i=1}^n \sqrt{1+f'(x_i)^2} \Delta t_i
\end{equation} Then since $f'$ is continuous on $[a,b]$ ,so $\sqrt{1+f'(x)^2}$ is continuous on $[a,b]$ . Hence it is also bounded on $[a,b]$ . Thus $\sqrt{1+f'(x)^2}$ is integrable on $[a,b]$ For any partition P= $\{t_0,...,t_n\}$ , and on any interval $[t_{i-1},t_i]$ , suppose $M_i$ is the supremum of $\sqrt{1+f'(x_i)^2}$ and $m_i$ is the infimum of $\sqrt{1+f'(x_i)^2}$ Then it's clear that $\displaystyle \sum m_i\Delta t_i\leq \sum \sqrt{1+f'(x_i)^2}\Delta t_i\leq\displaystyle \sum M_i\Delta t_i$ Then take $\displaystyle \lim_{|P|\to 0}$ to this inequality Since $\sqrt{1+f'(x)^2}$ is integrable on $[a,b]$ $\displaystyle \lim_{|P|\to 0} \displaystyle \sum m_i\Delta t_i=\displaystyle \lim_{|P|\to 0} \displaystyle \sum M_i\Delta t_i=\int^a_b \sqrt{1+f'(x)^2}dx$ Thus $\displaystyle \lim_{|P|\to 0} \sum_{i=1}^n \sqrt{1+f'(x_i)^2} \Delta t_i=\int^a_b \sqrt{1+f'(x)^2}dx=l(f)$","['integration', 'solution-verification', 'arc-length', 'analysis']"
4368712,What happens when the lower limit is greater than the upper limit in a definite integral?,"For example, what is $$
\int_2^1 f(x) \, dx
$$ equal to? Some said it equal to $$
-\int_1^2 f(x) \, dx
$$ but others said it equal to $0$ because $(x \geq 2 ) \cap ( x \leq 1 ) = \varnothing$ . Which one is correct? or such cases 'the lower limit bigger than the upper limit' actually are undefined (illegal) that they should be avoided?","['integration', 'notation']"
4368727,Examples of Cauchy complete ordered fields that are not $\mathbb{R}$?,"According to this post , it is not true that Cauchy completeness (every Cauchy sequence has a limit) and Dedekind completeness (every nonempty set that is bounded above has a supremum) are equivalent for ordered fields. The link in the post is sadly not working (I wish people kept their notes up). The user says, Since the Archimedean hypothesis often goes almost without saying in calculus / analysis courses, many otherwise learned people are unaware that there are non-Archimedean sequentially complete fields. In fact there are rather a lot of them, and they can differ quite a lot in their behavior: e.g. some of them are first countable in the induced (order) topology, and some of them are not. This is actually surprising to me, because I had a contrary false misconception. I think my misconception comes from the mantra that "" $\mathbb{R}$ is the unique complete ordered field,"" which is misleadingly false unless we either refer to Dedekind completeness (which is usually termed as the least upperbound property) or we are presupposing the Archimedean property (which to be honest should be stated explicitly). So I'm very curious, what are the examples of Cauchy complete ordered fields that are not isomorphic to $\mathbb{R}$ ? Can we make a list of these fields?","['complete-spaces', 'big-list', 'examples-counterexamples', 'analysis', 'ordered-fields']"
4368739,Banach space $\mathbb{C}^2$ with different norm,"Let $(\mathbb{C}^2,\|\cdot\|)$ be the Banach space over $\mathbb{C}$ with $\|(z_1,z_2)\|=\max\{|z_1|,|z_2|\}$ for any $(z_1,z_2)\in\mathbb{C}^2$ . Let $w_1=(1,1)$ and $w_2=(1,0)$ . Then show that there is NO linear isometry on $\mathbb{C}^2$ which maps $w_1$ to $w_2$ . The above problem looks very simple, and it may have a totally trivial solution but I am unable to prove it. My Attempt : It is immediate that $\|\cdot\|$ does not satisfy the parallelogram law on $\mathbb{C}^2$ . So there does not exist any inner product on $\mathbb{C}^2$ which induces $\|\cdot\|$ . I also noticed that the set $\{w_1,w_2\}$ is a basis of $\mathbb{C}^2$ over $\mathbb{C}$ . If there exists a linear isometry $T$ on $\mathbb{C}^2$ such that $T(w_1)=w_2$ then $T$ is an isometric isomorphism. Now I am not able to proceed further and obtain contradiction.","['banach-spaces', 'functional-analysis']"
4368748,Proving that existence of injection $f : S\to \mathbb{N}$ implies $S$ is countable?,How does one formally prove that if there exists an injective function $f:S \rightarrow \mathbb{N}$ then $S$ is countable? If there exists an injective function $f:S \rightarrow \mathbb{N}$ then there exists a bijection $g:S \rightarrow f(S)$ and $f(S)\subseteq \mathbb{N}$ is a countable set. But the definition of countable set requires a bijection from $\mathbb{N}$ to $S$ ? What is missing here?,"['elementary-set-theory', 'functions']"
4368783,"Solving the system $2x^2 = \frac{y}{z}+\frac{z}{y}$, $2y^2 = \frac{z}{x}+\frac{x}{z}$, $2z^2 = \frac{x}{y}+\frac{y}{x}$","Find all triplets $\{ x, y, z\}$ , such that all three of them are real and nonzero, and satisfies: $$2x^2 = \frac{y}{z}+\frac{z}{y}$$ $$2y^2 = \frac{z}{x}+\frac{x}{z}$$ $$2z^2 = \frac{x}{y}+\frac{y}{x}$$ I'm stuck in this problem. My first thought was that the only solutions that are possible are $\{ 1, 1, 1 \}$ and $\{ -1, -1, -1\}$ , but I do not know how to prove that these are the only solutions. I know for a fact that there seems something ""fishy"" about the fractions, and I am thinking of changing those into: $$2x^2yz=y^2+z^2$$ $$2y^2xz=x^2+z^2$$ $$2z^2xy=y^2+x^2$$ but I do not know how to proceed from here. Can anybody give me a hint on how to proceed?","['algebra-precalculus', 'systems-of-equations']"
4368814,Prove the following argument $\forall x \exists y (Px → Rxy) ⊢ \forall y (Py → \exists x Ryx)$ using the rules of sequent calculus,"Prove the following argument $\forall x \exists y (Px \to Rxy) \vdash \forall y (Py \to \exists x Ryx)$ using the rules of sequent calculus. I've been struggling how to prove this argument. I've tried to use different paths using the Left and Right rules for the $\forall $ and the $\exists$ , but everything I've tried so far hasn't worked. Can someone help solve this, find a good way to use the rules in order to reach the goal? This what I had so far: $1. -\forall x \exists y (Px → Rxy) ⊢ \forall y (Py → \exists x Ryx)$ $2. -\forall x \exists y (Px → Rxy) ⊢ Py → \exists x Ryx$ $3. -Py, \forall x \exists y (Px → Rxy) ⊢ \exists x Ryx$ $4. -Py, \forall x \exists y (Px → Rxy) ⊢ Ryt$ Thank you in advance. I tried also by starting by the left side, and didn't reach to the goal.","['sequent-calculus', 'predicate-logic', 'first-order-logic', 'logic', 'discrete-mathematics']"
4368825,"Please tell me how to formalize my thought if my thought is not wrong. (""obvious by symmetry"", ""symmetric group"")","Let $S_4$ be the symmetric group of order $4$ . $S_4=\{\operatorname{id},(1 2), (1 3), (1 4), (2 3), (2 4), (3 4),
(1 2)(3 4), (1 3)(2 4), (1 4)(2 3),
(1 2 3), (1 3 2), (1 2 4), (1 4 2), (1 3 4), (1 4 3), (2 3 4), (2 4 3),
(1 2 3 4), (1 2 4 3), (1 3 2 4), (1 3 4 2), (1 4 2 3), (1 4 3 2)\}.$ Let $H:=\{(1 2)(3 4), (1 3)(2 4), (1 4)(2 3)\}$ . Prove that $\phi(a)\in H$ for any $a\in H$ and for any $\phi\in\operatorname{Aut}(S_4)$ If I must solve the above problem, do I need to calculate the values of $\phi((1 2)(3 4)),\phi((1 3)(2 4)),\phi((1 4)(2 3))$ for all $\phi\in\operatorname{Aut}(S_4)$ ? By symmetry, I think each element of $H$ has the same algebraic properties in $S_4$ . And $\phi\in\operatorname{Aut}(S_4)$ is an automorphism. So, I think it is obvious that $\phi(a)\in H$ holds for any $a\in H$ and for any $\phi\in\operatorname{Aut}(S_4)$ . But I don't know how to formalize my thought. Please tell me how to formalize my thought if my thought is not wrong. (I used $S_4$ as an example.)","['symmetric-groups', 'group-theory', 'symmetry', 'automorphism-group']"
4368862,Determining whether a given mapping between tangent bundle $TU$ and $\phi(U)\times\mathbb{R}$ is also a diffeomorphism,"Let $M$ be an $n$ -dimensional smooth manifold, $(U,\phi) = (U,x^1\dots,x^n)$ a coordinate chart and $c^1,\dots,c^n$ coefficients. Then at the point $p\in M$ , any $v \in T_pU = T_pM$ can be written as $v = \sum_{i=1}^nc^i \frac{\partial}{\partial x^i}\bigg|_p$ . Given Loring's ( An Introduction to Manifolds , pp.130-131) homeomorphism $\psi:TU\to \phi(U)\times \mathbb{R}^n$ , $\psi(v) = (x^1(p),\dots,x^n(p),c^1(v),\dots,c^n(v))$ and its inverse $\psi^{-1}(v) = (\phi(p),c^1,\dots,c^n) = \sum c^i \frac{\partial}{\partial x^i}\bigg|_p$ , I'd like to know whether this mapping is also a diffeomorphism? Bijectivity and smoothness of $\psi$ are evident (smootness is due to the smoothness of $\phi$ and the projection mappings $c^1,\dots,c^n$ ). And while it is easy to argue about the partial derivatives of $\psi^{-1}$ w.r.t. $c^1,\dots,c^n$ , I've hit a brick while trying to argue about the partial derivative w.r.t. $\phi(p)$ . Namely how can you argue that the evaluation mapping $p \mapsto \frac{\partial}{\partial x^i}\bigg|_p$ is smooth in this context, where the partial derivatives represent the basis vectors of $TU$ at the point $p$ ?","['differential-geometry', 'smooth-manifolds', 'vector-analysis', 'real-analysis']"
4368908,Picking a special function from the set of random functions,"Consider a fixed integer $q$ . Consider the set of all functions from $\{0, 1\}^{n+1}$ to $\{0, 1\}^{m}$ . Let us pick one function from this set uniformly at random. Now, let's say we want functions $f$ with the following property. There exists a $b_f \in \{0, 1\}^{m}$ (depending on the function $f$ ) such that for every $x \in \{0, 1\}^{n}$ , $$f(0, x) - f(1, x) = b_f~~~mod~q.$$ What is the probability we pick such a function?","['random', 'probability-distributions', 'functions', 'linear-algebra', 'random-functions']"
4368911,Prove that the multivariable integral is equal to the binomial summation,"I came across this multivariable integral which states that for any $s\in\mathbb{C}$ and $n>0$ , we have the equity below \begin{align} \sum_{k=0}^n (-1)^k \binom{n}{k}(u+k)^{1-s} = (s-1)_n\int_0^1 \cdots \int_0^1 (u+x_1+\cdots+x_n)^{1-s-n} \,dx_1\cdots dx_n \end{align} where $(a)_n=a(a+1)\cdots(a+n-1)$ is the Pochhammer symbol. I have notice that \begin{align} \int_0^1 \cdots \int_0^1 \bigg(u+\sum_{j=1}^n x_j\bigg)^{1-s-n} \,dx_1\cdots dx_n &= \int_0^1 \cdots \int_0^1 \left.\frac{(u+\sum_{j=1}^n x_j)^{2-s-n}}{2-s-n}\right|_{x_1=0}^1 \,dx_2\cdots dx_n\\ &= \frac{1}{s+n-2} \int_0^1 \cdots \int_0^1 \bigg(u+\sum_{j=2}^n x_j\bigg)^{2-s-n}-\bigg(u+1+\sum_{j=2}^n x_j\bigg)^{2-s-n} \,dx_2\cdots dx_n\\ &= \frac{1}{(s+n-3)(s+n-2)}\int_0^1 \cdots \int_0^1 \bigg(u+\sum_{j=3}^n x_j\bigg)^{3-s-n}-2\bigg(u+1+\sum_{j=3}^n x_j\bigg)^{3-s-n}+\bigg(u+2+\sum_{j=3}^n x_j\bigg)^{3-s-n}\,dx_3\cdots dx_n \\ &\vdots \\ &= \frac{1}{(s-1)_n}\bigg(u^{1-s}-n(u+1)^{1-s}+\cdots+(-1)^{n-1}n(u+n-1)^{1-s}+(-1)^n(u+n)^{1-s}\bigg) \end{align} by repeating this process $n$ times. Other than that, I have also try to use multinomial theorem but could not get to anywhere \begin{align} \bigg(u+\sum_{j=1}^n x_j\bigg)^{1-s-n} &= \sum_{m=0}^{1-s-n} \binom{1-s-n}{m}u^{1-s-n-m}\bigg(\sum_{j=1}^n x_j\bigg)^m\\ &= \sum_{m=0}^{1-s-n} \binom{1-s-n}{m}u^{1-s-n-m} \sum_{k_1+\cdots+k_n=m} \frac{m!}{k_1!\cdots k_n!} \prod_{t=1}^n x_t^{k_t} \end{align} I would be appreciated if someone could help me with this with a non-heuristic approach.","['integration', 'multivariable-calculus', 'calculus', 'binomial-coefficients']"
4368929,Eigenvalues of symmetric matrix AB,"If matrices $A$ and $B$ are symmetric and matrix $AB$ is also symmetric, then show that every eigenvalue of $AB$ can be written as one eigenvalue of $A$ times one eigenvalue of $B$ . I tried so much but I could not find a good answer for that","['matrices', 'linear-algebra', 'symmetric-matrices', 'eigenvalues-eigenvectors']"
4368943,Radon Nikodym Derivative for conditional expectation?,"Let $\mathbb{P},\mathbb{Q}$ be two equivalent probability measures on the space $(\Omega,\mathcal{F})$ . And let $\frac{d\mathbb{Q}}{d\mathbb{P}}$ be the Radon-Nikodym derivative ( $\mathbb{Q}$ w.r.t $\mathbb{P}$ ) and $Y$ an integrable random variable defined on $\Omega$ . Then we have $$\mathbb{E}_\mathbb{Q}[Y] = \mathbb{E}_{\mathbb{P}}\left[\frac{d\mathbb{Q}}{d\mathbb{P}}Y\right] $$ Do we also have that $$\mathbb{E}_\mathbb{Q}[Y|\mathcal{G}] = \mathbb{E}_{\mathbb{P}}\left[\frac{d\mathbb{Q}}{d\mathbb{P}}Y|\mathcal{G}\right] $$ where $\mathcal{G}$ a sub sigma field of $\mathcal{F}$ .","['conditional-expectation', 'probability-theory']"
4368967,Convergence of $\sum_{\alpha\in \Bbb N^n} z^\alpha$ in $\{z\in \Bbb C^n: |z_i| < 1 \text{ for all } 1\le i\le n\}$,"I am reading Introduction to Complex Analysis in Several Variables by Volker Scheidemann. The convergence of power series in several complex variables is defined in the following way: Let $\{c_\alpha\}_{\alpha\in\Bbb N^n} \subset\Bbb C$ . The power series $\sum_{\alpha\in \Bbb N^n}c_\alpha (z-a)^\alpha = \sum_{\alpha\in \Bbb N^n} c_\alpha (z_1-a_1)^{\alpha_1} \ldots (z_n-a_n)^{\alpha_n}$ in $n$ variables $z:= (z_1,z_2,\ldots,z_n)$ centered at $a\in \Bbb C^n$ converges at $w\in \Bbb C^n$ if there exists $C> 0$ such that $$\sum_{\alpha\in F} |c_\alpha| |(w-a)^\alpha| \le C$$ for all finite subsets $F\subset\Bbb N^n$ . I am trying to understand the convergence behavior of $\sum_{\alpha\in \Bbb N^n} z^\alpha$ in the unit polycylinder $P^n_1(\mathbf 0) := \{z\in \Bbb C^n: |z_i| < 1 \text{ for all } 1\le i\le n\}$ . This is Example $1.5.7$ of the book. Let $z\in P^n_1(0)$ and $F\subset \Bbb N^n$ be finite. There exists $q\in [0,1)$ such that $|z_j| \le q$ for all $1\le j\le n$ . Hence, $$\sum_{\alpha\in F} |z^\alpha| = \sum_{\alpha\in F} |z_1|^{\alpha_1} \ldots |z_n|^{\alpha_n} \le \color{blue}{\sum_{\alpha\in F} q^{\alpha_1 + \ldots + \alpha_n} \le \sum_{j=0}^\infty q^j} = \frac{1}{1-q}$$ Why is the inequality in blue true? Certainly, there may exist distinct $\beta,\gamma\in F$ such that $\sum_{i=1}^n \beta_i = \sum_{i=1}^n \gamma_i$ . In such a case, I don't see how to get the above inequality. Perhaps the homogeneous expansion may be useful at some point: $$\sum_{\alpha\in \Bbb N^n} c_\alpha (w-a)^\alpha = \sum_{j=0}^\infty \left(\sum_{|\alpha| = j} c_\alpha (w-a)^\alpha \right)$$ In fact, using the above homogeneous expansion (once convergence issues are settled) the author goes on to say that $$\color{blue}{\sum_{k=0}^\infty \left(\sum_{|\alpha| = k} z^{\alpha} \right) = \sum_{k_1 = 0}^\infty \ldots \sum_{k_n = 0}^\infty z_1^{\alpha_1} \ldots z_n^{\alpha_n}}$$ Why is this true? Notation . For $\alpha\in \Bbb N^n$ , $|\alpha|$ denotes $\alpha_1 + \ldots + \alpha_n$ .","['several-complex-variables', 'analysis', 'complex-analysis', 'power-series', 'convergence-divergence']"
4369015,In the category of Lie algebras are mono-/epimorphisms precisely the injective/surjective morphisms?,"In any concrete category surjective (injective) morphisms are epimorphisms (monomorphisms). However, the converse does not hold (e.g. Examples of categories where epimorphism does not have a right inverse, not surjective ). What about the category of Lie algebras over a given field $\mathbb F$ ? Is any epimorphism (monomorphism) in that category surjective (injective)?","['functions', 'abstract-algebra', 'lie-algebras', 'category-theory']"
4369050,What is wrong in the second method of computing limits?,"We begin by considering the limit: $$\lim_{\displaystyle x \to \frac{\pi}{2}}{\frac{\cos{x}}{\sin{x}-1}}$$ By applying L' Hôspital's rule to each side of the limit, we can prove that they are different and so the limit therefore does not exist. Furthermore, it can be proven like this: $$\lim_{\displaystyle x \to \frac{\pi}{2}}{\frac{\cos{x}}{\sin{x}-1}}=\lim_{\displaystyle x \to \frac{\pi}{2}}{\frac{\cos{x}(\sin{x}+1)}{-\cos^2{x}}}=\lim_{\displaystyle x \to \frac{\pi}{2}}{\frac{\sin{x}+1}{-\cos{x}}}$$ and now by checking each side of the limit, I have definitively concluded that the limit does not exist. However, I got curious and tried a $u$ -substitution, by setting $u=\displaystyle x-\frac{\pi}{2}$ and then of course $u_0=\lim_{x \to \frac{\pi}{2}}{\left(\displaystyle x-\frac{\pi}{2}\right)}=0$ and so the limit becomes: $$\lim_{\displaystyle x \to \frac{\pi}{2}}{\frac{\cos{x}}{\sin{x}-1}}=\lim_{u \to 0}{\frac{\sin{x}}{-\cos{x}-1}}=0$$ What is the substitution not valid in the last method or why does it not work?","['limits', 'calculus']"
4369072,Planar graph with circuit bounding outer face of length $(n-5)/2$ is 4-colorable,"I am struggling with an exercise. I am asked to prove the following: Let $G$ be a simple and undirected graph with a fixed planar embedding such that the circuit bounding the outer face has length at least $\frac{n-5}{2}$ . Furthermore, assume that $\chi(G - v) \leq 4$ for all vertices $v \in V(G)$ . Then $\chi(G) \leq 4$ . Here is my attempt so far: First, w.l.o.g. assume that $G$ is $2$ -connected: Otherwise pick a vertex $w$ such that $G - w$ is disconnected. Color both connected components with $4$ colors and combine them to a coloring of $G$ . Now, if we manage to prove that there is a vertex $v \in V(G)$ with $\deg(v) \leq 3$ then we are done. Hence, suppose to the contrary that $\deg(v) \geq 4$ for all $v \in V(G)$ . Therefore we have $$ m \geq 2n.$$ Since $G$ is 2-connected, every face of the embedding is bounded by a circuit and each circuit has length at least $3$ ( $G$ is simple). Hence $$ 2m \geq \frac{n-5}{2} + (f-1)\cdot 3 .$$ My hope is that both inequalities together contradict Euler's formula, but I don't see how. Am I missing something? Or maybe my approach is not promising in the first place? Any help is appreciated.","['graph-theory', 'coloring', 'discrete-mathematics', 'planar-graphs']"
4369104,Greedy algorithm for matroids is $1/k$-approximation for the following graph problem (and $k$ is tight),"I am currently stuck on the following exercise: Let $G$ be a simple, undirected, connected and bipartite graph with weights $c: E(G) \to \mathbb{N}_{>0}$ . Let $$ \mathcal{I} = \{F \subseteq E(G) \mid F \text{ is a matching and } G - F \text{ remains connected} \}.$$ For which (smallest) number $k$ is the Matroid greedy algorithm an $1/k$ approximation-algorithm for the problem of finding a maximum weight set $F \in \mathcal{I}$ . Prove that the choice of $k$ is tight. Here is what I've got so far: A reasonable choice would be $k=3$ : Let $V(G) = A \dot \cup B$ be the bipartition. Define the following independence systems: $$ \mathcal{I}_1 := \{F \subseteq E(G) \mid |\delta_G (v) \cap F| \leq 1 \text{ for all } v \in A \} \\ \mathcal{I}_2 := \{F \subseteq E(G) \mid |\delta_G (v) \cap F| \leq 1 \text{ for all } v \in B \} \\ \mathcal{I}_3 := \{F \subseteq E(G) \mid G - F \text{ remains connected} \} \quad$$ Now, $\mathcal{I} = \mathcal{I}_1 \cap \mathcal{I}_2 \cap \mathcal{I}_3 $ and these three are actually matroids as $\mathcal{I}_3$ is the dual matroid of the graphic matroid. Therefore $$ \frac{|B_\min|}{ |B_\max|}  \geq \frac{1}{3}$$ which is a lower bound for the approximation ratio, where $B_\max$ is a base of $\mathcal{I}$ with maximum cardinality and $B_\min$ respectively. Therefore, $k = 3$ is a legitimate choice and it remains to show that it is indeed tight. This is the problem that I'm having. We are looking for a graph where there are two bases $B_1, B_2$ of $\mathcal{I}$ with $$ \frac{|B_1|}{|B_2| } = \frac{1}{3}.$$ I tried some subgraphs of $K_{3,3}$ , but they don't seem to work out. That is why I am wondering whether my choice of $k$ is actually tight or one could improve it. If not, what is a graph where there are two such bases? Any help is appreciated.","['graph-theory', 'matroids', 'discrete-mathematics', 'algorithms', 'discrete-optimization']"
4369105,Conflicting results in finding orthogonal curves,"I'm told to find the set of orthogonal curves to the curve of equation $y=cx^2$ . Using implicit differentiation, $\frac{dy}{dx}=2cx$ . Then, the desired curves obey the differential equation $\frac{dy}{dx}=-\frac{1}{2cx}$ . Integrating, we find the curves $y=-\frac{1}{2c}\log{|x|}+K$ , for some real constant $K$ . The thing is in some solution I found, they rewrite $2cx$ as $\frac{2y}{x}$ , because $c=\frac{y}{x^2}$ , and in doing so they get a different differential equation with different curves $\left(y=\pm \sqrt{K-\frac{1}{2}x^2}\right)$ . Which are clearly different curves. Plotting them on geogebra makes it seem like mine is wrong. What error did I make?",['ordinary-differential-equations']
4369110,Holonomy of a flat connection,"I am trying to prove that for a vector bundle with a flat connection, holonomies between points $p$ and $q$ are the same for smoothly homotopic paths. If we talk about a local trivialisation, and all the curves are within it, the problem can be solved with straightforward computation using path ordered exponents. I cannot understand what to do if curves travel all around the manifold and do not stay within one trivialisation patch. So far, I have the idea that the image of homotopy $\gamma_s:[0,1]^2 \rightarrow M$ is compact as an image of compact space. Therefore, the image is coverable with a finite number of coordinate trivialisations. Looking for different pictures of how it possibly can happen, I think that some induction on the number of charts can help here. I hope the following images clarify what I mean. Coloured regions here are different trivialisation charts. Red lines are curves that help to reduce a problem with the given number of charts to the subproblem with a smaller amount of patches. It seems like it is always possible to come up with some red line. However, it is unclear how to define it in the general case. Coloured regions here are different trivialisation charts. Red lines are curves that help to reduce a problem with the given number of charts to the subproblem with a smaller amount of patches. It seems like it is always possible to come up with some red line. However, it is unclear how to define it in the general case. Another idea is to consider the question in terms of contractible loops. I thought it could be possible to represent holonomy around a big loop as a sum over smaller ones and use that a holonomy around a small loop for a vanishing curvature is $O(\epsilon^3)$ , where $\epsilon$ is the size of the loop. It seems not to be the case.","['connections', 'holonomy', 'differential-geometry']"
4369113,Can we generate a sub-sigma-algebra using a sub-pi-system?,"Let $X$ be a set, let $\Sigma$ be a $\sigma$ -algebra on $X$ , and let $P$ be a $\pi$ -system generating $\Sigma$ . Take now a sub- $\sigma$ -algebra $\Sigma'\subseteq \Sigma$ . Let $P'=P\cap\Sigma'$ . Note that $P'$ is again a $\pi$ -system, which by construction is contained in $\Sigma'$ , and so it generates a sub- $\sigma$ -algebra of $\Sigma'$ . Can we say that $P'$ generates the whole of $\Sigma'$ ? (If not, are there extra requirements?) I'm trying to use the $\pi$ - $\lambda$ theorem, but I get stuck - I'm feeling that I'm missing something obvious.",['measure-theory']
4369114,How do I show that the following is a definition of an alternating form?,"Suppose $E$ is an open set in $\mathbb{R}^n$ . A differential form of order $k$ in $E$ (briefly, a k-form in E) is a function $\omega$ , which assigns to each $k$ surface $\Phi$ in $E$ a number $\omega(\Phi) = \int_{\Phi} \omega$ $$\int_{\Phi}\omega = \int_{D} \sum a_{i_1 \cdots i_k}(\Phi(u)) \frac{\partial(x_{i_1},\cdots,x_{i_k})}{\partial(u_{i_1},\cdots,u_{i_k})}du  \cdots \cdots \cdots (1)$$ where $\omega$ is symbollically representated as $\omega = \sum a_{i_1 \cdots i_k}(x) dx_{i_1} \wedge \cdots \wedge dx_{i_k}$ The definition of differential forms that was given to us in class is that $\omega(x)$ is an alternating $k$ tesnor. How are these two definitions related?How do I show that $(1)$ is an alternating $k$ tensor?","['tensors', 'differential-geometry']"
4369122,How to fix a proof of $g\left( X_{n} \right) \rightarrow g\left(X\right)$ in probability?,"If $g$ is a continuous function and $X_{n}\rightarrow X$ in probability, where $X_{n}$ is a sequence of random variable, then $g\left( X_{n} \right) \rightarrow g\left(X\right)$ in probability. For a special case $X=c$ for a constant $c$ , I know how to prove it. Since $f$ is continuous at $c$ , given any $\epsilon>0$ , there exists $\delta>0$ s.t. $|f(X_n)-f(c)|\le \epsilon$ whenever $|X_n-c|\le \delta$ . Thus, $$P(|X_n-c|\le \delta)\le P(|f(X_n)-f(c)|\le \epsilon)
$$ which implies $$P(|f(X_n)-f(c)|\ge \epsilon)\le P(|X_n-c|\le \delta)\to 0.
$$ But how about a general case $X$ ? Can we fix this proof?","['analysis', 'probability']"
4369127,Why a discrete group of diffeomorphisms $\mathbb S^2\rightarrow\mathbb S^2$ can't have exactly one fixed point?,"Context: while reading Thurston's notes on the geometry of 3-manifolds, I have found the assertion that the orbifold obtained from a sphere by adding a single conic point is a bad orbifold. However, his argument relies on the nonexistence of a discrete group of diffeomorphisms of the sphere fixing exactly one point. How can we prove this? I thought that there should be an easy argument involving properties of degrees of maps between spheres that should clarify the situation, but I have not found it. Thanks in advance for your answers.","['spheres', 'geometry', 'fixed-point-theorems', 'manifolds', 'algebraic-topology']"
4369163,Convergence in Bochner space.,"Let $\Omega \subset \mathbb{R}^n$ be a bounded set and $\{f_n\}_{n \in \mathbb{N}}$ be a sequence which converges to $f$ in $C([0,T];L^2(\Omega))$ . I need to prove that $\int_\Omega f_n^2 \phi \,dx \to \int_\Omega f^2\phi\,dx$ in $L^\infty([0,T])$ as $n \to \infty$ for any $\phi \in C^\infty_c(\Omega)$ . And does boundedness really matter, can we choose $\Omega =\mathbb{R}^n$ as well? We have $\lim_{n \to \infty} \sup_{[0,T]} \int_\Omega |f_n(t)-f(t)|^2\,dx = 0$ . We therefore consider $\left| \int \left(f^2_n\phi-f^2\phi\right) \,dx \right|\le \int \left|f^2_n-f^2\right| \phi\,dx \le \|\phi\|_\infty \int |f^2_n-f^2|\,dx $ . But I do not understand how this dominating part tends to zero.","['bochner-spaces', 'functional-analysis', 'analysis']"
4369217,A possible misconception on the weak law of large numbers,"Let $\{X_n\}_{n\geq1}$ be a sequence of i.i.d. random variables having
common probability density function $f(x)=xe^{-x}, x\geq0$ Let $\bar{X_n}=\frac{1}{n}\sum_{i=1}^nX_i$ Then, $\lim_{n\to\infty}P(\bar{X_n}=2)$ equals?? $\because \bar{X_n}\xrightarrow[n\to\infty]{P} 2=E[X_i].$ (hence, $\bar{X_n}$ converges in probabilty to a discrete distribution, that is equal to $2$ with probability $1$ ) $\therefore \forall \epsilon>0, \lim_{n\to\infty}P(|\bar{X_n}-2|<\epsilon)=1$ $\therefore  \lim_{n\to\infty}P(\bar{X_n}=2)=1 $ (here I derive intuition from the result in real analysis that says, that if two numbers are arbitrarily close to each other, then those numbers are the same.) But, the given answer is that $\lim_{n\to\infty}P(\bar{X_n}=2)=0$ . So, what did i do wrong? and how to prove that $\lim_{n\to\infty}P(\bar{X_n}=2)=0$ Also, looking at the answer, I get the feeling that even as $n\to\infty, \bar{X_n}$ still remains a continuous random variable. But this is very counterintuitive, because all the probability  of $\bar{X_n}$ is getting concentrated inside smaller and smaller intervals around $2$ , but still in the limit, $\bar{X_n}$ does not become a discrete random variable. How is this possible? Note: I do know that $\lim_{n\to\infty}P(|\bar{X}_n-\mu|\leq\epsilon)=1$ does not imply that, for large $n$ , $|\bar{X}_n-\mu|\leq\epsilon$","['law-of-large-numbers', 'probability-theory', 'random-variables']"
4369223,Short document/slides on basic definitions and results probability theory,"I'm looking for a compact set of notes/slides that state the most important definitions and results in probability theory and stochastic processes. In particular, the target audience is master's students in engineering/CS that don't have a background in measure theory and should serve as a refresher at the beginning of a course that in part covers stochastic optimization algorithms. Edit: Everything that is needed for the course can be found in ""Probability and Random Processes"" by Grimmett and Stirzaker, so it seems like I'll just need to write up a cheat-sheet-like document based on that book unless something similar already exists.","['lecture-notes', 'stochastic-processes', 'education', 'optimization', 'probability-theory']"
4369271,Possible analytical solution to $g''(x)=\alpha\left[g(x)^3-g(x)\right]+\beta g(x) e^{-\kappa x}$,"kind of related to a previous question of mine. I am describing a physical phenomena related to charged molecules and am interested in the following quantity: $$\xi=\int_0^{\infty}\left[1-g(x)^2\right]\text{d}x$$ where $g(x)$ is the solution to the following differential equation: $$g''(x)=\alpha\left[g(x)^3-g(x)\right]+\beta g(x) e^{-\kappa x}$$ with boundary conditions $g(0)=0$ and $g(\infty)=1$ . For $\beta=0$ this has a nice analytical solution $g(x)=\tanh{\frac{\sqrt{\alpha}x}{\sqrt{2}}}$ with $\xi=\frac{\sqrt{2}}{\sqrt{\alpha}}$ . What I have tried so far: getting an approximate solution by rewriting equation 2 to $1-g(x)^2$ and integrating, splitting the integration between $0\leq x \leq l$ and $x>l$ , where $l$ is the region where the exponential term of equation 2 is dominating. I haven't managed to prove the value of $l$ to make this work. What I did find through some ""educated"" and accidental guesses is $\xi \approx \frac{\sqrt{2}}{\sqrt{\alpha}}+\frac{\ln{\left[\frac{\beta}{\kappa \sqrt{2\alpha}}+1\right]}}{\kappa}$ , which is surprisingly accurate. However, I am in no form able to derive something close to this. This has me thinking that there might be a solution in the form of $g(x)=g(x)_{\beta=0}+c_1 y(x)$ . What I'm wondering is if there is an analytical solution to the actual differential equation, and if so, could someone point me in the correct direction such that I can (learn to) solve it. If not, what might be other methods to obtain an approximate expression for $\xi$ . Thank you. Edit : I have some software which solves a lattice-based model for this physical problem and found that indeed for a certain region $0\leq x \leq l$ $g(x)$ is very small and almost stationary, after this point the $\tanh$ solution seems to describe $g(x)$ with high accuracy. Edit : Analysis of the parameters $\alpha$ and $\kappa$ shows that $\frac{2}{\alpha}>\kappa^2$ . In general $\kappa>0$ ,and $\alpha<\kappa<\beta$ . Edit : For the physicists with us, the problem here is seemingly equivalent to describing the spin order parameter in a correlated magnetic field $\beta g(x) e^{-\kappa x}$ see for instance Lubensky, T. C., and Morton H. Rubin. ""Critical phenomena in semi-infinite systems. II. Mean-field theory."" Physical Review B 12.9 (1975): 3885.","['asymptotics', 'approximation', 'ordinary-differential-equations', 'perturbation-theory']"
4369295,Differentiability in relation to strange limit,"Please do not give a specific answer, just some guidance is what I'm looking for. This is a problem from an analysis module I am currently taking that has left me scratching my head: ""Suppose that $g:I \to \mathbb{R}$ and that $g$ is differentiable at the point $x=x_0$ does the following limit exist? $\lim_{h \to 0} \frac{g(x_0+h)-g(x_0-h)}{2h}$ Edit: From testing of a few well-defined functions this appears to be some alternative way of expressing a derivative.","['limits', 'derivatives', 'real-analysis']"
4369300,How do we find the derivative of the following function: $F(x)=\sin\Big(\int_0^x \sin\big(\int_0^y \frac{1}{1+t^4}\ dt\big)\ dy\Big)$ using FTC.,"Find the derivative of the following function: $F(x)=\sin\Big(\int_0^x \sin\big(\int_0^y \frac{1}{1+t^4}\ dt\big)\ dy\Big)$ I tried applying fundamental theorem of calculus directly but the the integral $\int_0^y \frac{1}{1+t^4}\ dt$ is giving me problems, I started by deriving both sides with respect to x, and by chain rule, the derivative should be f'(g(x))*g'(x). I reached this point and couldn't complete, does anyone have the key for the solution?","['integration', 'derivatives', 'analysis', 'real-analysis']"
4369330,Geometrical meaning of $x^2+y^2+z^2-xy-xz-yz$,"I am looking for a geometrical interpretation of the symmetrical expression $$f=x^2+y^2+z^2-xy-xz-yz\tag{1}$$ with $x,y,z \in \mathbb{R}$ . I could for example $f$ interprete as dot products of a vector with its permuted vector $$f=\begin{pmatrix}x\\y\\z\end{pmatrix}\begin{pmatrix}x\\y\\z\end{pmatrix}-\begin{pmatrix}x\\y\\z\end{pmatrix}\begin{pmatrix}y\\z\\x\end{pmatrix}\tag{2}$$ however I think there are more symmetrical ways to represent $f$ geometrically. Maybe $x,y,z$ can be thought of sides of a triangle, etc. Geometrical interpretations in $\mathbb{R},\mathbb{R^2}, \mathbb{R^3}$ are of interest.","['geometric-interpretation', 'linear-algebra', 'geometry', 'quadratic-forms']"
4369346,Confusion over boundary definition in topology,"I am watching the below lecture by Dr Tadashi Tokieda on Topology: https://www.youtube.com/watch?v=J7vojBbvudQ&t=710s At around the 12:00 minute mark he states that the boundary ( $\partial$ ) of an ""ordinary strip""(e.g. a Mobius strip but 'without a twist') is two disconnected circles. This confuses me as I thought the topological boundary of a set was the closure of the set, set minus it's interior. But surely, the entirety of the strip is not in the interior (as I can't create an open set that does not intersect the space around the strip so no open set is contained in the interior) and therefore the boundary should be the whole set. Have I misunderstood here? What am I getting wrong?","['geometry', 'manifolds-with-boundary', 'smooth-manifolds', 'manifolds', 'general-topology']"
4369361,Optimal stopping of $\mathbb{E}\frac{|B_{\tau}|}{1+\tau}$,"Let $(B_t)_{t\ge 0}$ be a standard Brownian motion. Consider $$\sup_{\tau} \mathbb{E}\frac{|B_{\tau}|}{1+\tau},$$ where supremum is taken over stopping times $\tau$ adapted to the natural filtration of $B$ .
Is there an easy way of finding this value? I know that there is a whole theory devoted to optimal stopping of stochastic processes (Snell envelope, etc.) but I am pretty sure that there should be a straightforward and short solution - it was given as a one point (out of 5) of a warmup question in lecture notes - the rest of them were more or less obvious....","['stochastic-processes', 'stopping-times', 'brownian-motion', 'probability']"
4369431,"Is the Mathieu Groupoid $M_{13}$ even special, besides its construction?","The Mathieu groupoid $M_{13}$ has a beautiful construction from a ""sliding block puzzle"" produced from the projective plane of order $3$ ; put $12$ labelled counters on $12$ of the $13$ points of the projective plane, and look at all the configurations one can reach by moving a counter on a line with the empty spot onto the empty spot, and swapping the other two counters on that line. This gives a groupoid (like a group, but two moves can only be composed if they are compatible as to where the empty spot is). The marvelous things is that look at all permutations of the $12$ counters the occur with the empty spot in a common place (which now form a group), you get the sporadic group $M_{12}$ . For those not familiar with $M_{12}$ , note it and $M_{24}$ are the only finite groups that are $5$ transitive (besides the obvious symmetric and alternating groups), though there's a lot more that can be said about their exceptionality! My questions is as follows: while this construction is excellent, is the structure of $M_{13}$ itself any more interesting than $M_{12}$ ? If we just see it as a groupoid, the answer seems to be no; any two connected groupoids on the same number of objects with same fundamental group are isomorphic , so such an object existing is not a surprise. However, this groupoid also comes with a group action by the symmetries of the projective plane, and maybe the groupoid equipped with this action is more of a ""surprising"" or exceptional fact? It makes me ask the question: for any group $G$ acting on a set $S$ , and group $K$ , is there always a connected groupoid with objects $S$ , automorphism group of any object being $K$ , and an action by $G$ that when restricted two the groupoids objects, is the action on $S$ ? And is it unique? That is, are connected groupoids with a group action classified by more than a the group action and the automorphism group of objects? And if so, is there some clear way in which $M_{13}$ is particularly special, besides involving a sporadic group? Possibly there is some structure even beyond that of the group action we want to imagine $M_{13}$ having, that demonstrates its exceptionality. I'd appreciate any perspectives on $M_{13}$ that clarify any of these questions, even if they aren't exactly what I have in mind. Even if it turns out only the construction is exceptional (in some sense) and not the resulting object, I'd still be happy enough!","['permutations', 'abstract-algebra', 'groupoids']"
4369443,Calculating the number of injections,"I have the following problem: Let $S = \{1, 2, 3, 4, 5\}$ and let $R = \{1, 2, 3, 4, 5, 6, 7\}$ . How
many injective functions are there from $S$ to $R$ ? my answer is that $f(1)$ can take $7$ values, $f(2)$ can take $6$ , $f(3)$ can take $5$ , $f(4)$ can take $4$ , and $f(5)$ can take $3$ . and so $7 \times 6 \times 5 \times 4 \times 3= 2520$ functions. I would appreciate any feedback/help. thanks.","['functions', 'combinatorics']"
4369456,How to find operator norm of shift operator,"Shift operator is $S:\ell^2(\mathbb{Z}) \to \ell^2(\mathbb{Z})$ defined by $$
(Sa)_n = a_{n-1}
$$ for $a = (a_n)_{n = 1}^\infty \in \ell^2(\mathbb{Z})$ . Let $I$ be the identity operator, then How to find the norm of $I-S-S^2$ ? What I know is following: $\|I-S-S^2\| \leq \|I\| + \|S\| + \|S\|^2 = 3$ $\|I-S-S^2\| \geq \sqrt{11/3}$ because of $(\cdots, 0, 1,1,-1, 0,\cdots)$","['operator-theory', 'functional-analysis']"
4369462,Semisimplicity of a group representation,"Consider a representation $A$ of a group $G$ in a complex vector space ${\mathbb{V}}\,$ : $$
 A:\;\;G\,\longrightarrow\,GL({\mathbb{V}})\;\;,
 $$ and let ${\mathbb{V}}$ be decomposable into a finite or infinite direct sum $$
 {\mathbb{V}}\,=\,\bigoplus_{i\in\cal I} {\mathbb{V}}_i
 $$ of invariant subspaces carrying irreducible subrepresentations of $A\,$ : $$
 A(G)\,{\mathbb{V}}_i\subseteq{\mathbb{V}}_i\;\;,\qquad A(G)\,=\,\bigoplus_i \underbrace{A_i(G)}_{  \stackrel{\;}{\textstyle{\rm{irreducibles}}}   }
 \;.
 $$ On page 23 of his book ""Representation Theory"" (page 27 of the pdf file ), Kowalsky issues a warning that the said decomposition does not imply that any subrepresentation is a subsum $$
\bigoplus_{i\in\cal J} {\mathbb{V}}_i\;\;,\quad{\cal J}\subset{\cal I}\;.
$$ The author emphasises that this would be false even for $G$ trivial, where the only irreducible representation is the trivial one, and writing a decomposition would amounts to choosing a basis. He then states that there are usually many subspaces of $\mathbb V$ which are not literally direct sums of a subset of the basis directions. Could someone please offer me a simple example or two, illustrating the author's point?","['representation-theory', 'group-theory', 'linear-algebra', 'lie-groups']"
4369472,would a set of all countable sets have any paradoxical properties?,"I recently talked with a friend about set theory and he mentioned ""set of all countable sets"". I think that such set does not exist (just like ""set of all sets"" does not exist) and I would like to explain to him why I think so.
I could just ask him to prove, using axioms of set theory, that it exists - and reject the existence of this set until its existence is proven.
However, I would prefer to show that assumption of its existence would lead to some paradoxes. So, would a set of all countable sets have any paradoxical properties?","['elementary-set-theory', 'paradoxes']"
4369495,If every metric on a set X is equivalent to the discrete metric then can we say X is a finite set?,I know the result and the proof of the statement that If X is a finite set then any two metrics are equivalent and every metric on X is equivalent to the discrete metric on X. But I don't know whether the above result characterize finite sets?,"['general-topology', 'metric-spaces', 'analysis', 'real-analysis']"
4369523,The maximal complete bipartite subgraphs of the partition graph $\mathcal{P}(3^3)$.,"The concept of a partition graph is similar to the Kneser graph concept. Every vertex of a partition graph $\mathcal{P}(g^g)$ is a partition of $\{1,2, ..., g^2 \}$ into $g$ cells of size $g$ . Two vertices $u$ and $v$ are adjacent if the intersection of each cell of $u$ with each cell of $v$ be nonempty. I am working on $\mathcal{P}(3^3)$ . The vertices of this graph are partitions of $\{1,2, ..., 9\}$ into $3$ cells of size $3$ , and two vertices $u$ and $v$ are adjacent if each cell of $u$ has an element in each cell of $v$ . I am looking for all maximal complete bipartite subgraphs of this graph. I have already managed to find $K_{1,36}$ (th degree of each vertex is $36$ ), $K_{2,2}$ , $K_{4,4}$ , $K_{6,4}$ , $K_{2,12}$ . I am not looking for the number of complete bipartite subgraphs, I need to find all maximal complete bipartite subgraphs. Any help would be appreciated.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
4369535,Let $f(x) = \sin^{-1}(\frac{2x}{1+x^2})$ Show that $f(x) = 2\tan^{-1}(x)$,"Let $$f(x) = \sin^{-1}\left(\frac{2x}{1+x^2}\right) ~~   -\infty<x<\infty.$$ Show that, (a) $f(x) = 2\tan^{-1}(x)$ for $-1\leq x \leq 1$ and (b) $f(x) = \pi-2\tan^{-1}(x)$ for $x \geq 1.$ Proof: I started off by equating $$\sin^{-1}\left(\frac{2x}{x^2+1}\right)=2\tan^{-1}(x)$$ (a) We wish to show that these are equal for $-1\leq x \leq 1$ . For this domain $\displaystyle -1 \leq\frac{2x}{x^2+1} \leq 1 \implies -\frac{\pi}{2} \leq \sin^{-1}\left(\frac{2x}{x^2+1}\right) \leq \frac{\pi}{2}$ $$\frac{2x}{x^2+1} = \sin(2\tan^{-1}(x))$$ The task is now to show $\sin(2\tan^{-1}(x))=\frac{2x}{x^2+1}$ $$2\sin(\tan^{-1}(x))\cos(\tan^{-1}(x))=\frac{2x}{x^2+1}$$ For $-1 \leq x \leq 1 \implies -\frac{\pi}{4}\leq\tan^{-1}(x)\leq\frac{\pi}{4} \implies -\frac{\sqrt{2}}{2}\leq \sin(\tan^{-1}(x)) \leq \frac{\sqrt{2}}{2}$ Also, $\frac{\sqrt{2}}{2}\leq\cos(\tan^{-1}(x)) \leq 1$ $$2\sin(\tan^{-1}(x))\cos(\tan^{-1}(x)) \iff 2(\frac{x}{\sqrt{x^2+1}})(\frac{1}{\sqrt{x^2+1}})= \frac{2x}{x^2+1}$$ Which was to be shown. (b) $\displaystyle x \geq 1 \implies 0<\frac{2x}{1+x^2}\leq 1 \implies 0< \sin^{-1}\left(\frac{2x}{x^2+1}\right) \leq \frac{\pi}{2}$ Hence, We must show that $$\sin^{-1}(\frac{2x}{x^2+1}) = \pi - 2\tan^{-1}(x) \iff \frac{2x}{x^2+1} = \sin(\pi - 2\tan^{-1}(x))$$ for $x\geq 1$ $$\sin(\pi - 2\tan^{-1}(x))=\sin(\pi)\cos(2\tan^{-1}(x)) - \cos(\pi)\sin(2\tan^{-1}(x))=\sin(2\tan^{-1}(x))$$ $$\sin(2\tan^{-1}(x)) = 2\sin(\tan^{-1}(x))\cos(\tan^{-1}(x))=\frac{2x}{x^2+1}$$ Which was to be demonstrated. Note: This problem didn't flow like I thought it would. I had imagined that during some of the intermediate steps, I would be presented with the option of choosing an $f(x)$ or trig function value that would only be true in one of the intervals. But no such situation presented itself. Did I do something wrong? Did I overlook something?","['algebra-precalculus', 'solution-verification', 'trigonometry']"
4369570,Measurement Errors in Gaussian Process,"If we consider a Gaussian process for one-dimensional variable $$
S(X) \sim GP(\mu,\sigma^2K),
$$ where $K$ is the exponential kernel ( $K(x,y) = e^{-\frac{||x-y||_2}{\phi}}$ ), I am wondering how can we find a new process $R(x)$ that $$ 
R(x) = \frac{1}{2\theta}\int_{x-\theta}^{x+\theta}S(z)dz
$$ and figure out its mean, variance, and kernel function?","['stochastic-processes', 'statistics', 'probability']"
4369583,Difference between Levy's modulus of continuity and Law of Iterated Logarithm,"So the Levy's modulus of continuity theorem says that almost surely, $\limsup_{h \to 0} \sup_{0 \leq t \leq 1-h} \frac{B(t+h)-B(t)}{\sqrt{2h \log\frac{1}{h}}}=1.$ while Khinchtine's Law of Iterated Logarithm says that almost surely, $\limsup_{t\to \infty} \frac{B(t)}{\sqrt{2 \frac{1}{t}\log \log t}}=1.$ Using the fact that $tB(\frac{1}{t})$ is also a Brownian motion and letting $h=\frac{1}{t}$ , we get: $\limsup_{h \to 0} \frac{B(h)}{\sqrt{2h\log \log\frac{1}{h}}}=1.$ Now I'm finding it difficult to understand the difference between these two statements. If we put $t=0$ in the first statement, we get $\limsup_{h \to 0}\frac{B(h)}{\sqrt{2h \log\frac{1}{h}}}=1$ .
I thought Levy's modulus of continuity was optimal for the behaviour of Brownian motion near $0$ .
Is the only difference that Levy's modulus controls the supremum?","['stochastic-processes', 'brownian-motion', 'probability-theory']"
4369594,Question about basis transform and its direction,"This question has been bothering me for a while. It's in connection with diagonalisation: I can never remember, whether it's $A = PDP^{-1}$ or $A = P^{-1}AP$ . I have an explanation but it's wrong because it leads to the wrong formula but I don't see the flaw. Can anyone please point out the mistake in the following argument? Let $A$ be some finite-dimensional linear map given as a matrix. Say, it is, as usually is the case, given with respect to the standard basis. Let's call this basis Basis 1. Let's assume it has as many different eigenvalues as its dimension $n$ so we can find $n$ distinct and linearly independent eigen vectors. They form a basis for the eigen space. Let's call this basis Basis 2. So far so good. Now, $P$ is the matrix containing these eigen vectors. Also, $P$ is a matrix that represents a change of basis: If we apply $P$ to the first standard basis vector $(1,0,0,\dots, 0)^T$ then we get the first column of $P$ which is the first eigen vector. So we have $$ P(e_i) = v_i$$ where $e_i$ are the basis vectors of Basis 1 and $v_i$ are the basis vectors of Basis 2. Therefore, $P$ transforms Basis 1 into Basis 2. Now to get the same linear map $A$ but with respect to Basis 2 I want to take a vector with respect to Basis 1 transform it into Basis 2 apply $D$ (i.e. the map $A$ but expressed w.r.t. Basis 2) transform the result from Basis 2 back into Basis 1 Therefore, expressing steps 1)-4), we should have $$ A = P^{-1}D P$$ But this is wrong: the correct formula is the other way around. So where is my mistake?","['linear-algebra', 'linear-transformations']"
4369607,"Is the set $A = \left\{ x \in \mathbb{R}\, |\, x^2 \text{ is rational}\right\}$ countable?","Is the set $A = \left\{ x \in \mathbb{R} \,|\, x^2 \text{ is rational}\right\}$ countable? I know that the set of all rational numbers is countable. But for some irrational numbers, $x^2$ is rational. Example: $(\sqrt2)^2$ is rational. So that the set $A$ includes all rational numbers and some irrational numbers. Then how can we prove that the set $A$ is countable?","['real-numbers', 'real-analysis', 'elementary-set-theory', 'radicals', 'rational-numbers']"
4369613,Double integral with absolute function,"If we have a double integral that $$
\frac{1}{2\theta} \int_{x_2 - \theta}^{x_2 + \theta} \int_{x_1 - \theta}^{x_1 + \theta} \exp\Big(- \frac{|z_1 - z_2|}{\phi}\Big) dz_1dz_2,
$$ where $x_i, z_i \in\mathbb R$ ,
I think that it may be good to pass $$
d = x_1 - x_2
$$ into the integral but I don't know how to deal with the lower and upper bound in double integral.","['integration', 'statistics', 'stochastic-integrals', 'calculus', 'exponential-function']"
4369624,Local minima of $f(x) = \begin{cases} 5 x^2 (2 - \sin \tfrac{1}{x}) & \text{ if } x \neq 0 \\ 0 & \text{ if } x = 0 \end{cases}$ dense near $0$,"Consider $$f(x) = 
\begin{cases} 
5 x^2 (2 - \sin \tfrac{1}{x}) & \text{ if } x \neq 0 \\ 
0 & \text{ if } x = 0.   
\end{cases} 
$$ For any given $\delta > 0$ it is very clear from the graph of $f$ that there is at least one (in fact infinitely many) point $x_\delta$ in $(-\delta, \delta)$ at which $f'(x_\delta) = 0$ . Somehow, I am not getting how to mathematically prove this. Can anyone help me out?","['maxima-minima', 'functions', 'derivatives', 'real-analysis']"
4369646,On the proof of the existence of solutions to SDE via step function approximation,"I am reading the proof on the existence of solutions to SDEs from the following post: https://almostsuremath.com/2010/02/10/existence-of-solutions-to-stochastic-differential-equations/ Here, $Z^1, \dots, Z^m$ are semimartingales, $X=(X^1,\dots, X^n)$ is a cadlag adapted process and $X \mapsto a_{ij}(X)$ is a map from the space of cadlag functions to the set of $Z^j$ -integrable processes that satisfy some Lipschitz continuity condition. Namely, we allow $a_{ij}(X)_t$ to be a function of the process $X$ at all times up to $t$ . And then assume the two properties on it. For any cadlag adapted $X$ , we define the following $n$ -dimensional process, $F(X)^i = N^i + \sum_{j=1}^m \int a_{ij}(X)dZ^j$ . In the proof below, the author constructs inductively a process $X^{(r+1)}$ that approximates $X$ based on the first jump sizes with respect to $F(X)$ . $M$ is defined as $1_{[0,\tau)} (X-F(X))$ . My questions are : in the proof below, why do we have the identity $$\lambda_r (X^i)^{\tau_r} = \sum_{j=1}^m \int \lambda_r 1_{(0,\tau_r]} (a_{ij}(X)-a_{ij}(0))dZ^j + \lambda_r (\sum_{j=1}^m \int 1_{[0,\tau_r)} a_{ij}(0)dZ^j + (N^i)^{\tau_r}+(M^i)^{\tau_r}?$$ I cannot figure out how to get this kind of an expansion. Below this equation in the proof, it says that the final term on the right hand side tends ucp to zero as $r \to \infty$ . That $\lambda_r M^{\tau_r}$ tends to zero is clear since $M^{\tau_r}$ is bounded by $\epsilon$ and $\lambda_r \to 0$ . But why do $\lambda_r N^{\tau_r}$ and $\lambda_r \sum_j \int_{1_{[0,\tau_r})}a_{ij}(0)dZ^j$ tend to zero? $N$ is just assumed to be some cadlag adapted process so I cannot see why stopping it on $\tau_r$ would make it tend to $0$ when multiplied by $\lambda_r$ . Also I don't understand why the stochastic integral with integrand $1_{[0,\tau_r)} a_{ij}(0)$ tend to zero when multiplied by $\lambda_r$ . Why do the assumptions on $a_{ij}$ give this? Moreover, I posted this as another question before. I can't figure out why the sequence $X_{\tau_r \wedge t}^*$ being bounded in probability, where $*$ represents the running supremum of the normed process, imply that $X$ is almost surely bounded on the interval $[0,\tau)$ whenever $\tau<\infty$ . I would greatly appreciate if anyone takes a look at this one as well. Bounded in probability of the running maximum of a stopped process implies almost sure boundedness on the interval $[0,\lim \tau_r)$? Finally, it seems like the boundedness of $X$ on the interval $[0,\tau)$ for $\tau<\infty$ is used to show that $1_{(0,\tau)}(a_{ij}(X)-a_{ij}(0))$ is a locally bounded process. However, from (P2) we always have that $$|1_{(0,\tau)}(a_{ij}(X)-a_{ij}(0))|_t \le KX^*_{t-}$$ and $X^*$ is a cadlag adapted process, hence $X^*_{t-}$ will be left continuous with right handed limits adapted, so locally bounded. Hence, isn't $1_{(0,\tau)}(a_{ij}(X)-a_{ij}(0))$ immediately locally bounded from (P2)? Why do we need $X$ almost surely bounded on $[0,\tau)$ whenever $\tau<\infty$ for this?","['stochastic-integrals', 'analysis', 'stochastic-differential-equations', 'probability-theory', 'stochastic-calculus']"
4369668,"Evaluate $\int_{0}^{\infty }\!{\frac {\ln \left( x \right) \arctan \left( x \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x$","I have the idea of this integral when I see $$\int_{0}^{\infty }\!{\frac {\arctan \left( x \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x$$ and so I know that the closed form is $${\frac{1}{2}}-{\frac {\ln  \left( 2 \right) }{2}}.$$ But really, I don't know any paper where I can evaluate for example $$\int_{0}^{\infty }\!{\frac {\ln  \left( x \right) \arctan \left( x  \right) }{{{\rm e}^{\pi\,x}}-1}}\,{\rm d}x.$$ In the same time, I see that Wolfram can't give a closed form. Does someone has an idea please?
Thanks","['integration', 'definite-integrals', 'closed-form']"
4369713,When is a subspace of a Hilbert space large?,"In this paper , Halmos defines what it means for a subspace of a Hilbert space to be large . Definition. A subspace $H$ of a Hilbert space $K$ is large if $H$ contains infinitely many orthogonal copies of its orthogonal complement, or, in other words, if $\dim H \ge \aleph_0 \dim (K\setminus H)$ . Thus, for example, a subspace of a separable Hilbert space is large if and only if it is infinite-dimensional. What does the author mean by ""infinitely many orthogonal copies of its orthogonal complement"" ? Does it refer to infinitely many subspaces inside $H$ , which are all orthogonal, and also isomorphic to $H^\perp$ ? A concrete example would help me appreciate this more! If $H$ is not closed, $K\setminus H$ may not be a vector space, so how can we talk about its dimension? How would you prove that a subspace of a separable Hilbert space is large if and only if it is infinite-dimensional? This is the first time I have seen this definition, so it would be great if you could point me to any other related references. Thank you!","['operator-theory', 'vector-spaces', 'hilbert-spaces', 'definition', 'functional-analysis']"
4369726,Proof request: Polynomial long division proof aimed at pre-calculus level of knowledge,"There is already proof of polynomial long division: Proof of the polynomial division algorithm but alas, it was written in context of question related to abstract algebra. Maybe this proof can be adapted for pre-calculus level of mathematical knowledge","['alternative-proof', 'algebra-precalculus', 'polynomials']"
4369784,Criterion to establish if there is a biholomorphic function between 2 sets in $\mathbb{C}$,"The Riemann mapping theorem states in particular that if $\emptyset \neq \Omega \neq \mathbb{C}$ and $\Omega$ is open and simply connected, then there is a biholomorphic function $f:\Omega \longrightarrow \{ z \in \mathbb{C}: |z|<1 \} $ . It is then easy to see that there is a biholomorphism between any two sets $\Omega_1$ , $\Omega_2$ satisfying the assumptions. Is it true that if $\Omega_1$ satisfies all assumptions, and $\Omega_2$ satisfies all the assumptions except for the simply connectedness, then there can't exist a biholomorphism between $\Omega_1$ and $\Omega_2$ ? I can't prove or disprove this. I noted that for example if we pick a point $a$ in a ""hole"" in $\Omega_2$ then every function on $\Omega_1$ has a primitive and this does not hold for $\Omega_2$ anymore (for example $\Omega_2= B_1(0) - \{0 \}$ and $f(z)=\frac{1}{z}$ which I think can be generalised to any not simply connected set ). Im studying complex analysis now and I don't have a good topological background. Are there good general criteria to determine if there exist a biholomorphism between $2$ given sets?","['complex-analysis', 'general-topology']"
4369797,Shifting of graph of function $y = f(x)$ to $y = f(x - c)$,"I am trying to understand if we have $y = f(x)$ , then consider the function $g(x) = f(x - c)$ translate $y = f(x)$ to the right by c. I understand that if we put $x = c + j$ , then we have $f(j) = g(c + j)$ , so everything is shifted to the right by c. When I saw this initially it seemed to me that $g(x)$ shifts to the left instead of the right. Why are we getting this difference in x-axis and y-axis shifts? For instance, if we set $h(x) = f(x) - c$ we shift $h(x)$ downards?","['algebra-precalculus', 'functions', 'transformation', 'graphing-functions']"
4369805,Two-sided confidence interval for the sample for the mean length,"A sample of $n \in \mathbb{N}$ screws is taken from a large batch of screws that are produced. The length of a bolt is approximated as normally distributed with variance $4$ and the lengths of the screws are distributed as independent and identical. (a) $n = 10$ screws were taken and their length (in mm) was measured, with the following result: $$10 \ \ \ 8 \ \ \ 9 \ \ \ 10 \ \ \ 11 \ \ \ 11 \ \ \ 9 \ \ \ 12 \ \ \ 12 \ \ \ 8$$ Calculate the sample mean and determine a two-sided confidence interval for the above sample for the mean length of the confidence probability $0.95$ . Also state the quantile used and its (approximate) value. (b) How many screws had to be tested at least, thus a confidence interval for the mean length with a confidence level of $0.95$ has at most the length $2$ or length 1? Explain. $$$$ I have done the following : (a) The sample mean is equal to \begin{equation*}\overline{x}_{10}=\frac{1}{10}\left (10+8+9 + 10 + 11 + 11 + 9 + 12 + 12 +8\right )=\frac{1}{10}\cdot 100=10\end{equation*} For the two-sided confidence interval do we use the formula \begin{equation*}\left [M(x)-\frac{\sigma}{\sqrt{n}}q_{1-\frac{a}{2}},M(x)+\frac{\sigma}{\sqrt{n}}q_{1-\frac{a}{2}}\right ] \end{equation*} where $M(x)$ is the mean, i.e. $M(x)=10$ and $\sigma=\sqrt{4}=2$ ? The value of $q$ is related to the confidence level, right?","['statistics', 'confidence-interval', 'means', 'probability']"
4369872,Coefficients of inverse conformal metric,"I'm trying to understand some proof written in local coordinates. The situation is as follows: We have a $2$ -dim Riemannian manifold $(M,g)$ and a conformal diffeomorphism $f:M\rightarrow M$ such that $\tilde{g}:=f^*g=e^{2\lambda}g$ . The claim in the proof is that $$
e^{2\lambda}g^{ij}= \sum_{k,l=1}^2g^{kl}\frac{\partial f_i}{\partial x_k}\frac{\partial f_j}{\partial x_l}
$$ but I don't see this. By calculation I got $$
e^{2\lambda}g_{ij}=\tilde{g}_{ij}:=\tilde{g}(\partial_i,\partial_j)=\sum_{kl=1}^2 g_{kl}\frac{\partial f_k}{\partial x_i}\frac{\partial f_l}{\partial x_j}
$$ and don't now how to continue. I'd be thankfull for some help!","['conformal-geometry', 'riemannian-geometry', 'differential-geometry']"
4369954,"If $pqp = p$ and $qpq=q$, is it true that $p=q?$","Let $A$ be a unital $C^*$ -algebra and $p,q \in A$ projections in $A$ with the property $$pqp = p, \quad qpq = q.$$ I am trying to show that $p=q$ , but I don't really see why this should be the case. The obvious algebraic manipulations don't seem to work. Of course, we can WLOG assume that $A= B(H)$ . This question occurs because I'm trying to justify a step in the proof of Takesaki's first volume (chapter III, theorem 4.2, p141 below, where they deduce that $q= q_1$ from the equalities $q= qq_1q$ and $q_1 = q_1qq_1$ ).","['hilbert-spaces', 'c-star-algebras', 'functional-analysis', 'operator-algebras']"
4369955,Trigonometric equation $\tan x \tan 2x = \cot 2x \cot 3x$,"Find $\cos 8x$ if: $$\tan x \tan 2x = \cot 2x \cot 3x$$ We can verify quickly that $\tan 2x \to \infty$ and $\tan 3x \to \infty$ are not solutions of the trig equation, so the equation may be rewritten as: $$\tan x \tan^2 2x \tan 3x = 1$$ Using expansion formulas, we may see that: $$\tan 2x = \frac{2 \tan x}{1 - \tan^2 x}$$ And also: $$\tan 3x = \frac{3 \tan x - \tan^3 x}{1 - 3 \tan^2 x}$$ By long calculations, I have obtained that: $$\tan x \in \{-1 - \sqrt{2}, -1 + \sqrt{2}, 1 - \sqrt{2}, 1 + \sqrt{2}\}$$ However, I am not able to take those calculations further. I have learnt about Chebyshev polynomials, but using WolframAlpha , the expression is really hairy and not realy easy to cope with. Is there a smarter trick to solve the question? If not, how should I simplify my calculations?","['problem-solving', 'algebra-precalculus', 'polynomials', 'trigonometry']"
4370001,How to compute $\int_0^\pi \ln^2(\sin x)dx$ using complex analysis?,"I would like to know if the integral $$\int_0^\pi \ln^2(\sin x)dx$$ could be attacked with contour integration. I have seen the integral evaluated using the Fourier series for $\ln(\sin x)$ and Cauchy product for infinite sums, but this method gets extremely hard for higher degrees than 2, which is why I want to see it evaluated using complex analysis.","['integration', 'definite-integrals', 'complex-analysis', 'calculus', 'contour-integration']"
4370019,"Proving that a function $f:[0,\infty)\to[0,\infty)$ satisfying these conditions is necessarily non-decreasing","I have a function $f: [0, \infty) \to [0, \infty)$ which is smooth. I also have that $f(0) = 0$ $f'(0) > 0$ $f''(x) \leq 0$ , for all $x \in [0, \infty)$ It intuitively makes sense then that $f$ on $[0, \infty)$ must be strictly non-decreasing (since if it was ever decreasing, we would have to eventually ""pull up"" and contradict clause 3). I want to prove this, and I was able to derive contradictions if at some point the slope was negative. If at point $c$ in $(0, infty)$ , $f'(c) < 0$ , take some point $c + h$ further on in $[0, \infty)$ , $h > 0$ , and three cases occur: a. $f(c + h) = f(c)$ -> got a contradiction b. $f(c + h) > f(c)$ -> got a contradiction But for $f(c + h) < f(c)$ , this leads nowhere since it can still technically happen. I am at a complete loss on how to go forward. I was able to show that $f$ can never intersect $0$ . Edit: My main goal is to claim that $f(a) \leq f(b)$ for any $a < b$ on $[0, \infty)$","['calculus', 'monotone-functions', 'real-analysis']"
4370055,Can $(x^2+a^2)^{-\frac{3}{2}}$ be integrated without using trigonometric substitutions?,"I know that $$
\int\frac{1}{(x^2+a^2)^{\frac{3}{2}}}\,dx
$$ can be solved using a trigonometric substitution, but is there a trick to calculate this integral without using trigonometric substitutions? I think something in the same spirit with solving $$
\int\frac{1}{(x^2+1)^2}\,dx
$$ by adding and subtracting $x^2$ to the numerator and then integrating by parts once one knows (and it is simple) how to integrate $$
\int\frac{1}{(x^2+1)}\,dx
$$ Any suggestion or reference will be appreciated.","['integration', 'indefinite-integrals', 'real-analysis']"
4370072,Expected number of card draws from a standard deck until an ace is drawn,"The problem: What is the expected number of draws from a standard deck of
52 cards until an ace is drawn? This question has been asked many times on this forum so I'm not looking for a solution, but I would like to better understand a part of this specific solution: Consider any card as just it’s suit A, C, D, and S for ace, club,
diamond, and spade, respectively. Since we don’t care about any
particular ace, we can encode the order of the deck as a string of
repeated letters. In fact, we only care about aces, so our deck can be
considered a binary string of 4 A’s and 48 O’s, where O stands for
“other.” The number of such strings is $\binom{52}{4}$ We now consider cases: The number of strings with A in the first
position is $\binom{51}{3}$ The number of strings with A in the second position is $\binom{50}{3}$ This continues until the number of strings with A in the 49th
position is $\binom{3}{3}$ I'm looking to understand why the total number of such strings is $\binom{52}{4}$ . Specifically, why would combinations be appropriate here and why those parameters specifically? Is there an intuitive reason for this? I am new to combinations in general but haven't really seen combinations used like this before. Thank you.","['combinations', 'combinatorics', 'card-games']"
4370119,Converting one form of the Gompertz equation into another,"Consider the Gompertz equation that models the dynamics of the population of a single-species $$\frac{dN}{dt}=r_0e^{-\alpha t}N$$ and convert it to the following form $$\frac{dN}{dt}=\alpha N\ln\left(\frac{K}{N}\right)$$ So here's my attempt, the problem doesn't explicitly say that the constant of integration is $0$ or not, so I consider two cases when solving and derived, $$ N(t) = N_0 \exp \left( \frac{r_0}{\alpha}\left(1-e^{-\alpha t}\right) \right) $$ where I took $N(0)=N_0$ , and, $N(t)=e^{-\frac{r_0}{\alpha}e^{-\alpha t}}$ , for the case where the constant is $0$ . So, taking the limit we arrive at the carrying capacity to get, $$ K=\lim N=\lim e^{-\frac{r_0}{\alpha}e^{-\alpha t}}=e^{-\frac{r_0}{\alpha}}\iff\ln K=-\frac{r_0}{\alpha}\iff r_0=-\alpha\ln K $$ Now, observe $$ N(t)=e^{-\frac{r_0}{\alpha}e^{-\alpha t}}\iff\ln N=-\frac{r_0}{\alpha}e^{-\alpha t}\Rightarrow\ln N=\ln Ke^{-\alpha t} $$ so that $\frac{\ln N}{\ln K}=e^{-\alpha t}$ . Plugging all these in to the initial Gompertz equation should get you to arrive at the conclusion, I would believe. Now here's where I'm running into trouble, the fact that I have $\frac{\ln N}{\ln K}$ and not $\ln(\frac{K}{N})$ . Not sure if it's here where my mistake lies, but if you can provide some guidance that would be useful. I'll attempt derivation using the first form of the solution I got without a constant of integration equaling to zero in the mean time.","['biology', 'calculus', 'derivatives', 'ordinary-differential-equations']"
4370126,Convergence in distribution of the two-sample $t$-test statistic,"I would appreciate either one of the following, or both: A source (if a book, with page numbers) where I can find this result proven A proof of the result The question at hand: Let $X_{11}, \dots, X_{1n_1}$ be independent and identically distributed random variables with mean $\mu_1$ and variance $\sigma_1^2$ , and let $X_{21}, \dots, X_{2n_2}$ be independent and identically distributed random variables with mean $\mu_2$ and variance $\sigma_2^2$ . Assume $n_1 \neq n_2$ and $\sigma_1^2 \neq \sigma_2^2$ . Denote $\bar{X}_{1, n_1} = \dfrac{1}{n_1}\sum_{i=1}^{n_1}X_{1i}$ and $\bar{X}_{2, n_2} = \dfrac{1}{n_2}\sum_{i=1}^{n_2}X_{2i}$ . Also, let $S_1^2 = \dfrac{1}{n_1 - 1}\sum_{i=1}^{n_1}(X_{1i} - \bar{X}_{1, n_1})^2$ and $S_2^2 = \dfrac{1}{n_2 - 1}\sum_{i=1}^{n_2}(X_{2i} - \bar{X}_{1, n_2})^2$ . As $n_1 \to \infty$ and $n_2 \to \infty$ , does the statistic $$T = \dfrac{\bar{X}_{1, n_1} - \bar{X}_{2, n_2}}{\sqrt{\dfrac{S_1^2}{n_1} + \dfrac{S_2^2}{n_2}}}$$ converge in distribution to a random variable; and if so, with what distribution? Context . The test statistic $T$ is that which arises from Welch's t-test . Conventional statistical wisdom (e.g., here , here ) is that regardless of the population distributions of $X_{1i}$ and $X_{2j}$ (i.e., they are not iid normal), the Central Limit Theorem (CLT) may be used so as to justify that $T$ is approximately $\mathcal{N}(0, 1)$ . I haven't seen a proof of this, and I am doubtful the classical CLT may be used. My Efforts . I demonstrated that for a single population, with obvious notational extensions, it holds that $\dfrac{\bar{X} - \mu}{S/\sqrt{n}}$ converges in distribution to a random variable with an $\mathcal{N}(0, 1)$ distribution. However, this  result cannot be used in this question. For one thing, $\bar{X}_{1, n_1} - \bar{X}_{2, n_2}$ cannot be written as a single arithmetic mean as in the result above. For another thing, while $S_1^2 \to \sigma_1^2$ and $S_2^2 \to \sigma_2^2$ in probability, since $\sigma_1^2 \neq \sigma_2^2$ they cannot be ""factored out"" like in my demonstration, prohibiting direct use of the CLT.","['statistics', 'central-limit-theorem', 'hypothesis-testing', 'probability-theory', 'probability']"
4370161,Easy computation by Ravi Vakil (jet bundles),"I landed on some short notes by Ravi Vakil from the 90s, the Beginner's Guide to Jet Bundles from the Point of View of Algebraic Geometry . The notes are very clear but on the very first page there is an easy computation whose result seems wrong to me. We are working on $\mathbb P^2$ an Vakil says that $$ c_2(\mathcal O(d) \otimes (\mathcal O \oplus \Omega))=3(d-1)^2$$ EDIT: where $\Omega=T^*\mathbb P^2$ is the cotangent bundle. If we call $H$ the hyperplane class in $A\mathbb P^2$ , I think that the total Chern class for $\Omega$ is $$c(\Omega)=1-3H+6H^2 \ \ (\star)$$ If $(\star)$ above is correct, we should have that $$c_2(\mathcal O(d)\oplus \Omega(d))=d^2 + (2d-3)\cdot d+(d^2-3d+3),\ \ (\square)$$ which is not the above value. I couldn't find anyone pointing this error out on the internet, therefore I'm supposing that I am the one who is wrong: I think that my mistake is somewhere in the $(\square)$ evaluation, and maybe I am missing something about the general techniques of evaluation of total Chern classes.","['jet-bundles', 'algebraic-geometry', 'characteristic-classes']"
4370221,Find an equation of the curve that satisfies the condition.,"My question is as follows; In the book Anton Calculus 12th edition, Question 56 in section 5.2 has a solution contradicting my own; I will break the reasoning down for my answer to aid a reader in helping me. Or, possibly the book's solution is incorrect. Problem: Find an equation of the curve that satisfies the given. At each point (x,y) on the curve, the slope equals three times the square of the distance between the point and the y-axis; the point (-1,2) is on the curve. Book Solution: \begin{align*}
dy/dx=x^2,y&=\int x^2dx = x^3/3+C;\\
y&=2 \textrm{ when } x=-1,\textrm{ so } (-1)^{3}/3+C = 2, C=7/3\\
\textrm{thus } y&=x^{3}/3+7/3
\end{align*} My solution: Here is my first thought for solving this, possibly $\vec{v} = (x,y)$ then we get, $$\frac{dy}{dx} = 3\|\vec{v}||^{2}\implies y =\int3\|\vec{v}||^{2}dx $$ After doing said integration, solve the initial value problem to get $C_{1}$ . The above must be incorrect since this would mean that $\vec{v}$ is a vector from the origin; So I will do my best to break my thought process into an algorithm the reader can understand, which may aid in helping me. What I think I know. The labels (1, 2, ... 7) can be used to aid in replying to my question. (1) F(x) = y (2) ""at each point"", every (x,F(x)). (3) ""on the curve"", the equation F(x). (4) ""the slope"", $\frac{dy}{dx}$ (5) ""equals three times the square,"" three times a square is 3(x^2). (6) ""the distance between the point and the y-axis"", Since it's asserting the distance between the point and the y-axis, I think it's safe to assume what ever vector I come up with will not be going through the origin, so possibly if $P1 = (0,y)$ , and $P2 = (x,y)$ then $\vec{P1P2} = (x,y)-(0,y) = (x,y-y) = (x,0)$ (7) ""the point (-1,2) is on the curve"". This will be used to find our $C_{1}$ Here is my Second thought. Using $\vec{P1P2}$ from (6) \begin{align}
\frac{dy}{dx} &= 3||\vec{P1P2}||^2\\
&= 3x^2 \\
\therefore y &= \int3x^2dx = 3\frac{1}{3}x^{3}=x^3+C_{1} \\
\end{align} Finally finding $C_{1}$ (7) \begin{align}
y(-1) & = (-1)^3 + C_{1}\\
\implies 2 &= -1 +C_{1} \\
3 &= C_{1}
\end{align} So we now have, $F(x) = y = x^{3} + 3$ . Any help that can be provided is greatly appreciated; thanks in advance.","['differential', 'calculus', 'derivatives']"
4370239,Verify that an implicit equation is the solution to the differential equation.,"Verify that \begin{equation}
a.\;x^3+y^3-3xy=0,\; \mathbb{R}_{x\neq2^{2/3}}
\end{equation} is the solution to \begin{equation}
b.\;(y^2-x)y' - y+x^2=0
\end{equation} As we know the function g(x) of a. is not easily attainable, therefore we resort to stating one graphically. Such that at $2^{2/3}$ does not exist meaning it makes a jump. The book I'm reading says that if we implicitly differentiate a. then it agrees with b. and hence the definition of the solution is met. Definition of solution:
Implicit Solution of ODE
f(x,y) is the implicit solution of a differential equation: \begin{equation}
F(x, y, y',\dots,y^{(n)})=0,\: D
\end{equation} on the domain D if it defines a function $g(x)$ in D such that
f[x,g(x)]=0 which \begin{equation}
F[x, g(x) g(x)',\dots,g(x)^{(n)}]=0
\end{equation} I don't understand the logic behind the author's assertion and the definition.","['ordinary-differential-equations', 'differential', 'calculus', 'functions', 'problem-solving']"
4370305,Prove that $\mathbb{Z} \times\Bbb Z_2$ and $\mathbb{Z}$ are not isomorphic.,"Prove that $\mathbb{Z} \times\Bbb Z_2$ and $\mathbb{Z}$ are not isomorphic. Here by $\mathbb{Z}$ I mean the group $(\mathbb{Z},+)$ and by $\Bbb Z_2$ I mean the cyclic group of order 2. This is exercise 2.3.13 part (a) from Dummit/Foote, Abstract Algebra - I am aware the solution may be posted somewhere online, but I try to look at full solutions as little as possible for my own understanding. Here is my general argument. Is this a correct approach, and is it missing any important details? Let $\Bbb Z_2=\{0,1\}$ . The element $(0,1)$ in $\mathbb{Z} \times\Bbb Z_2$ has order 2, and since isomorphism preserves order of elements and there exists no integer with order 2, there cannot be an isomorphism between the groups.","['group-isomorphism', 'cyclic-groups', 'abstract-algebra', 'solution-verification', 'group-theory']"
4370307,Interpretation of $\exp\left(\frac{d}{dx} \ln( f(x) ) \right)$?,"Is there any intuitive interpretation or simplification of $\exp\left(\frac{d}{dx} \ln(f(x))\right)$ ? Forms like $\phi=\exp\left(\frac{d}{dN} \ln(f(N))\right)$ are common in thermal physics/chemistry. Typically $N\gg 0$ , and $f(N)$ is the ratio of two increasing, positive-definite, ""very large"" functions ( multiplicities ). For example, $\phi(T,P,N)=\exp\left( \frac{∂}{∂N} \left( \ln Ω_{IG}(T,P,N) - \ln Ω(T,P,N) \right) \right)$ is the fugacity coefficient.",['derivatives']
4370341,To show that a complex-valued function is injective,"Given a complex-valued function $w=f(z) = - \dfrac{1}{2} \left( z + \dfrac{1}{z} \right)$ from $\{ z= x+iy : |z| < 1 \}$ to $\{ w : \text{Im}(w) >0 \}$ , show that $f$ is injective. My Approach : Let $f(z_1) = f(z_2)$ which yields $$(z_1-z_2) + \left( \frac{\overline{z_1}}{|z_1|^2} - \frac{\overline{z_2}}{|z_2|^2} \right) = 0 .$$ From here how can I conclude that $z_1 = z_2$ ? Any help is much appreciated.","['complex-analysis', 'complex-numbers']"
4370344,Lining up 6 blocks when 2 can't touch,"Did I do this correctly?: edit: I’m told I did this correctly if I distinguish the blue blocks from each other. That’s what I intended I have to find how many ways I can line up $6$ colored blocks (blue, blue, green, yellow, red, orange) such that the two blue blocks are not next to each other . I found there to be 5 ways their positions can be next to each other (numbers represent position): ${(1,2),(2,3),(3,4),(4,5),(5,6)}$ Now, for each of these possibilities, the pair has $2!$ ways to align in relation to each other while the remaining $4$ blocks have $4!$ ways to line up in relation to each other... so I get $6! - (5)*(2!)*(4!) = 480$ ways the 2 blue blocks are not next to each other. Thanks for any pointers and help.","['statistics', 'combinatorics']"
4370370,Is there an elementary proof for $\int_{0}^{\infty} \frac{d x}{x^{n}+1}= \frac{\pi}{n} \csc \left(\frac{\pi}{n}\right) $,"When I first encounter the integral $$\int_{0}^{\infty} \frac{d x}{x^{n}+1},$$ I am trying to resolve the integrand into partial fractions. Then I found it is very tedious and complicated and look for infinite series.
I first split the integral into 2 parts. $$
\begin{aligned}
\int_{0}^{\infty} \frac{d x}{x^{n}+1} =& \underbrace{\int_{0}^{1} \frac{d x}{x^{n}+1}}_{J}  +\underbrace{\int_{1}^{\infty}\frac{d x}{x^{n}+1}}_{K}
\end{aligned}
$$ $$
\begin{aligned}
J &=\int_{0}^{1} \sum_{k=0}^{\infty}(-1)^{k} x^{n k} d x =\sum_{k=0}^{\infty}\left[\frac{(-1)^{k} x^{n k+1}}{n k+1}\right]_{0}^{1} =\sum_{k=0}^{\infty} \frac{(-1)^{k}}{n k+1}=\frac{1}{n} \sum_{k=0}^{\infty} \frac{(-1)^{k}}{k+\frac{1}{n}}
\end{aligned}
$$ Similarly, $$
\begin{aligned}
K&=\int_{1}^{\infty} \frac{1}{x^{n}+1} d x =\int_{1}^{\infty} \frac{x^{-n}}{1+x^{-n}} d x =\int_{1}^{\infty} x^{-n} \sum_{k=0}^{\infty}(-1)^{k}x^{-k n} d x=\sum_{k=0}^{\infty} \frac{(-1)^{k+1}}{-(k+1) n+1} \end{aligned}$$ Rearranging and re-indexing yields $$K=\frac{1}{n} \sum_{k=0}^{\infty} \frac{(-1)^{k+1}}{-(k+1)+\frac{1}{n}}=\frac{1}{n} \sum_{k=-1}^{-\infty} \frac{(-1)^{k}}{k+\frac{1}{n}}
$$ Grouping $J$ and $K$ yields $$\int_{0}^{\infty} \frac{d x}{x^{n}+1} =\frac{1}{n}\left(\sum_{k=0}^{\infty} \frac{(-1)^{k}}{k+\frac{1}{n}}+\sum_{k=-1}^{-\infty} \frac{(-1)^{k}}{k+\frac{1}{n}}\right) $$ Using the theorem $$
\pi \csc (\pi \alpha)=\lim _{N \rightarrow \infty} \sum_{k=-N}^{N} \frac{(-1)^{k}}{k+\alpha}
$$ and putting $\alpha=\frac{1}{n}$ yields $$\int_{0}^{\infty} \frac{d x}{x^{n}+1}=\frac{\pi}{n} \csc \left(\frac{\pi}{n}\right).$$ My question : Is there any elementary proof?","['integration', 'power-series', 'trigonometric-integrals']"
4370392,Find all positive integers s.t. $\frac{1}{a^2} - \frac{1}{b^2} = \frac{1}{c^2} - \frac{1}{d^2}$,"Find all positive integers $a, b, c, d$ such that : $$\frac{1}{a^2} - \frac{1}{b^2} = \frac{1}{c^2} - \frac{1}{d^2}$$ The original problem came from atomic electron transitions : I would like to find out non-trivial positive integer solutions; since it is trivial if $a = b$ and $c = d$ , or $a = c$ and $b = d$ . I found some of the solutions, and they look like : There is some pattern in these integers, but it seems difficult to obtain a gerneralized form of the solution.",['number-theory']
4370398,How can you get a pre-image from the inverse if it's not defined?,"From Discrete Math course notes on Inverse functions If a function $g:\mathbb{Z}\rightarrow\mathbb{Z}$ is many-to-one, then it does not have an inverse function. This makes the notation $g^{−1}(3)$ meaningless. Nonetheless, $g^{-1}(\{3\})$ is well-defined, because it means the preimage of {3}. If $g^{−1}(\{3\})=\{1,2,5\}$ , we know $g(1) = g(2) = g(5) = 3$ . Why are we allowed to say $g^{-1}(D)$ where D is a set if $g^{-1}$ is undefined? Is this just a notational sleight of hand, where $g^{-1}$ is not taken to refer to an inverse function, but rather only to the domain of $g$ , when you pass in a set? It seems nonsensical to pass a parameter in to a function that does not exist. Or is $g^{-1}$ actually defined but not as a function, but rather as a relation?","['elementary-set-theory', 'functions', 'inverse', 'discrete-mathematics']"
4370433,Calculate $\lim_{j \rightarrow \infty} \int_0^j (1+\frac{x}{j})^j e^{-\pi x}dx$,"My approach: $$\lim_{j \rightarrow \infty} \int_0^j \left(1+\frac{x}{j}\right)^j e^{-\pi x}dx = 
\lim_{j \rightarrow \infty} \int_0^{\infty} \left(1+\frac{x}{j}\right)^j e^{-\pi x}dx.$$ I'm not sure if I can do the above, but I need it to apply Lebesgue as follows: I see that $(1+\frac{x}{j})^j \rightarrow e^x$ and $(1+\frac{x}{j})^j$ is monotonic increasing, so $e^x$ is a dominating function that is integrable. Hence I can apply Lebesgue: \begin{align*}
\lim_{j \rightarrow \infty} \int_0^{\infty} \left(1+\frac{x}{j}\right)^j e^{-\pi x} dx & = \int_0^{\infty} \lim_{j \rightarrow \infty} \left(1+\frac{x}{j}\right)^j e^{-\pi x}dx \\ &= \int_0^{\infty} e^x e^{-\pi x} dx= \int_0^{\infty} e^{(1-\pi) x} dx= - \frac{1}{1-\pi}.
\end{align*} My colleagues all have a different result though and Wolfram Alpha exceeds computation time. I cannot spot a mistake.","['integration', 'complex-analysis', 'lebesgue-integral', 'real-analysis']"
4370452,Number of ways to cover half of a grid by an orthogonally connected region,"Suppose that we have a grid of size $2n$ by $2n$ , with $4n^2$ cells in total. How many ways are there to label each cell in the grid using two labels, say zero and one , such that all ones are orthogonally connected and exactly half of the grid contains ones ? For example, there are four ways to label the grid if $n=1$ : 1 1 | 0 0 | 1 0 | 0 1
0 0 | 1 1 | 1 0 | 0 1 Brute force search suggests that there are $1474$ ways to label the grid when $n=2$ , here are some examples: 1 1 1 1 | 0 0 1 1 | 1 1 1 1
1 1 1 1 | 0 0 1 1 | 0 1 0 0
0 0 0 0 | 0 0 1 1 | 0 1 0 0
0 0 0 0 | 0 0 1 1 | 1 1 0 0 To clarify, this is what I mean by ""orthogonally connected"". Let $A$ be a $2n$ by $2n$ matrix representing the grid, let $V = \lbrace (i, j) : A[i,j] = 1 \rbrace$ denote the positions of ones and let $E = \lbrace ((i_1, j_1), (i_2, j_2)) \in V \times V: (i_1, j_1) \in \lbrace (i_2 + 1, j_2), (i_2 - 1, j_2), (i_2, j_2 + 1), (i_2, j_2 - 1) \rbrace \rbrace$ . All ones are orthogonally connected whenever the graph $(V, E)$ is connected. In the examples above, ones are orthogonally connected. In the following examples, ones are not orthogonally connected. 1 0 0 1 | 1 0 0 0
1 0 0 1 | 0 1 0 1
1 0 0 1 | 0 0 1 0
1 0 0 1 | 1 1 1 1 For reference, here is the python code I used to compute the number 1474. It iterates over $2^{(4n^2)}$ possible ways to fill the grid, and uses scipy.ndimage to detect orthgonally connected components. In the problem, I only consider cases where k is even. import numpy as np
from scipy.ndimage import label

def count_solutions(k, print_patterns=False):
  count = 0
  k2 = k * k
  for i in range(2**k2):
    arr = np.array([int(x) for x in np.binary_repr(i).zfill(k2)]).reshape(k, k)
    if label(arr)[1] == 1 and arr.sum() == k2 // 2:
      if print_patterns: print(arr)
      count += 1
  return count","['recreational-mathematics', 'combinatorics']"
4370454,Using Mantel's theorem to prove a probabilistic inequality,"I'm self-learning Yufei Zhao's ""Graph Theorey and Additive Combinatorics"" , one problem I encounter is the following: The next exercise can be solved by a neat application of Mantel's theorem. Exercise 1.1.10. Let $X$ and $Y$ be independent and identically distributed random vectors in $\mathbb{R}^{d}$ according to some arbitrary probability distribution. Prove that $$
\mathbb{P}(|X+Y| \geq 1) \geq \frac{1}{2} \mathbb{P}(|X| \geq 1)^{2} .
$$ Mantel's theorem . Every $n$ -vertex triangle-free graph has at most $\left\lfloor n^{2} / 4\right\rfloor$ edges. AKA $$
\operatorname{ex}(n, H)=\left\lfloor\frac{n^{2}}{4}\right\rfloor \text {. }
$$ I have no clue how this inequality of integral is connected with graph theorey, please at least give me a hint. Proof not using Mantel's theorem is also welcome.","['graph-theory', 'geometry', 'integral-inequality', 'extremal-graph-theory', 'probability']"
4370461,Character group of non-split torus in $GL_2$,"Let $E=\mathbb Q(\sqrt{-d})$ be an imaginary quadratic field and let $R_{E/\mathbb Q}(\mathbb G_m)$ be the restriction of scalars of the multiplicative group, i.e. $R_{E/\mathbb Q}(\mathbb G_m)(X) = \mathbb G_m(X \times_{\mathbb Q} E)$ for each $\mathbb Q$ -scheme $X$ . Picking a basis $\langle 1, -\sqrt{-d}\rangle$ for $E$ and letting $E$ act on itself, we can embed $E$ into $M_2(\mathbb Q)$ by $(\alpha, \beta) \mapsto \begin{bmatrix}\alpha&-d\beta\\\beta&\alpha\end{bmatrix}$ . Question 1: This embedding should give rise to an embedding of algebraic groups over $\mathbb Q$ , $R_{E/\mathbb Q}(\mathbb G_m) \hookrightarrow GL_2$ . Is $R_{E/\mathbb Q}(\mathbb G_m)$ a maximal (non-split) torus in $GL_2$ ? I seem to remember that the elements of maximal non-split tori in $GL_n$ all satisfy $\det = 1$ , which is not the case here. What went wrong? Question 2: Whatever the correct definition of the maximal torus in $GL_2$ obtained from $E$ is, how can we describe its character group explicitly?","['algebraic-number-theory', 'algebraic-geometry', 'algebraic-groups']"
4370477,Projecting bounded functions on a Gaussian Hilbert Space,"Let $\{g_n\}_{n=1}^{\infty}$ be an infinite sequence of mutually independent, normally distributed random variables, all with zero expectation and unit-variance, all defined in some probability space. I believe I can prove that if $f$ is a real-valued bounded function, then $$\sum_{n=1}^{\infty}[\mathbf{E}(fg_n)]^2\leq\frac{2}{\pi}\sup|f|^2$$ and that $\frac{2}{\pi}$ is the best possible constant, attained by certain bounded functions. My question is this: has anyone seen this before and can provide reference?",['probability-theory']
4370482,Using trig to determine angles from a compound cut,"Trigonometry was never my strong point so any help would be much appreciated. Below is an image of a solid square section bar with a compound cut at one end. Given the two angles $\alpha$ & $ \beta$ (which are measured from a plane perpendicular to the bar's neutral axis to an edge on the cut face), is there any way one can determine the angles $\gamma$ & $\theta$ ? Where $\gamma$ is the single cut angle from the imaginary plane to the face and $\theta$ is the amount the bar has to rotate so that the cut face is perpendicular to the sheet or worktop. I am looking for a mathematical solution to what is currently solved through empirical work which takes time. I wish to create a table for a metalworker to reference when receiving drawings that show compound cuts in an orthographic view ( $\alpha$ & $\beta$ )","['euclidean-geometry', 'trigonometry', 'geometry']"
4370507,Showing $M_n = M_{n-1}^2 U_n^{M_{n-1}-1}$ is a martingale.,"I am currently studying for a measure-theoretic probability exam. In an old exam, I encountered the following question: Let $(U_n)_{n \in  \mathbb{N} }$ be i.i.d. sequence of $\text{Uniform}((0,1))$ random variables on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ . Set $\mathcal{F}_n = \sigma(U_0, U_1,...,U_n)$ . Set $M_0=U_0$ and $M_n = M_{n-1}^2U_n^{M_{n-1}-1}$ . We are asked to show that $(M_n)_{n \in \mathbb{N}}$ is a martingale. Furthermore we are given the hint to use the following theorem: Let $X,Y \in \mathcal{L}^1(\Omega, \mathcal{F}, \mathbb{P})$ , let $\mathcal{G} \subseteq \mathcal{F}$ be a sub- $\sigma$ -algebra. Let $X$ be a $\mathcal{G}$ -measurable random variable and let the random variable $Y$ be independent of $\mathcal{G}$ . Assume that $h ∈ B(\mathbb{R}^2)$ is such that $h(X, Y )\in \mathcal{L}^1(\Omega, \mathcal{F}, \mathbb{P})$ . Put $\hat{h}(x) = \mathbb{E} [h(x, Y )]$ . Then $\hat{h}$ is a Borel function and $\hat{h}(X)$ is a representative of $\mathbb{E}[h(X, Y )|\mathcal{G}]$ . Adaptedness is clear, but I struggle with the martingale property and the integrability. I have tried the following: To show the martingale property I think we have to use the theorem given in the hint. Setting $X=M_{n-1}$ , $Y=U_n$ and $\mathcal{G}=\mathcal{F}_{n-1}$ . Then $M_{n-1}$ is clearly $\mathcal{F}_{n-1}$ measurable and $U_n$ is independent of $\mathcal{F}_{n-1}$ . Let $h(x,y)=x^2y^{x-1}$ . Then $h$ is measurable because it is a composition of measurable functions. To show the criterium $h(M_{n-1}, U_n )\in \mathcal{L}^1(\Omega, \mathcal{F}, \mathbb{P})$ is the same as integrability of $M_n$ , which I have not figured out. Using the above I get: $$\mathbb{E}[M_n|\mathcal{F}_{n-1}]=\mathbb{E}[M_{n-1}^2U_n^{M_{n-1}-1}|\mathcal{F}_{n-1}]=\mathbb{E}[h(M_{n-1}, U_n )|\mathcal{F}_{n-1}]= \hat{h}(M_{n-1})$$ also, $$\hat{h}(x) = \mathbb{E}[h(x,U_n)]=\mathbb{E}[x^2U_n^{x-1}]=x^2\mathbb{E}[U_n^{x-1}]=x1^x=x$$ Putting this together gives: $\mathbb{E}[M_n|\mathcal{F}_{n-1}]= M_{n-1}$ .
Where in the last equality, I used that the $x-1$ 'th moment of a $\text{Uniform}((0,1))$ random variable is given by: $\mathbb{E}[U_n^{x-1}]=\frac{1^x}{x}$ .
But even then I am not sure how to show integrability. Any help is much appreciated! EDIT: I think integrability follows from the above. Note that $M_n \geq 0$ , $\mathbb{E}[|M_n|]=\mathbb{E}[M_n]=\mathbb{E}\left[\mathbb{E}[M_n|\mathcal{F}_{n-1}]\right]=\mathbb{E}[M_{n-1}]=\mathbb{E}[M_{0}]=\frac{1}{2} < \infty$ .","['stochastic-processes', 'measure-theory', 'probability-theory', 'martingales']"
4370524,Number of Ways of Ordering Numbers,"How many ways you can order the numbers $0, 1, 2, 3,..., 12$ using each number exactly once, such that the sum of two adjacent numbers are not greater than $13$ ? (This is a first round's question of the four rounds of Bangladesh Mathematical Olympiad for class $11$ – $12$ .) For example, these are some orderings which satisfy the condition: $0, 12, 1, 11, 2, 10, 3, 9, 4, 8, 5, 7, 6$ $12, 1, 11, 2, 10, 3, 9, 4, 8, 5, 7, 6, 0$ $1, 12, 0, 11, 2, 10, 3, 9, 4, 8, 5, 6, 7$ $11, 2, 10, 1, 12, 0, 3, 9, 4, 8, 5, 6, 7$ $6, 7, 2, 11, 0, 12, 1, 10, 3, 5, 8, 4, 9$","['contest-math', 'combinatorics']"
4370526,Solve trigonometric inequality $2\cos^2x+\cos(2x) \geq 1$,Can I solve it this way? $2\cos^2x+\cos^2x-\sin^2x \ge \sin^2x+\cos^2x$ $2\cos^2x-2\sin^2x \ge 0$ $2(\cos^2x-\sin^2x) \ge 0$ $2\cos(2x) \ge 0$ $\cos(2x) \ge 0$,"['trigonometry', 'solution-verification', 'inequality']"
4370573,What is the point of (Lie) derivations?,"Probably some very naive questions, but ... Definition Let $A$ be a vector space together with a bilinear map $\mu: A \times A \rightarrow A$ .
We call a map $D: A \rightarrow A$ a derivation if it satisfies the Leibniz rule $D(\mu (a,b))=\mu(D(a), b) + \mu(a, D(b))$ for all $a,b \in A$ . There are many examples of derivations, differential operators on a suitable associative algebra being one of them. Lie derivations One can look at derivations of Lie algebras (where $\mu$ is the Lie bracket).
Given a Lie algebra $\mathfrak g$ (in fact any vector space with bilinear product) one can show that the derivations on $\mathfrak g$ form a Lie subalgebra of $End(\mathfrak g)$ with respect to the commutator. Furthermore, the Jacobi identity is precisely the statement that $ad_x$ is a derivation with respect to the Lie bracket for any $x \in\mathfrak g$ . Question(s) Why should we care?
What is the relevance of Lie derivations? Why study them? What do they tell us about a Lie algebra? Are they somehow a generalization of differential operators? Are they related to the Lie algebra-Lie group correspondence? Is there any category theoretic perspective on them?","['lie-algebras', 'category-theory', 'abstract-algebra', 'intuition', 'lie-groups']"
4370619,Implementation of a constructive algorithm for Deuring's correspondence,"Let $E_0$ be a supersingular elliptic curve. By Deuring's correspondence, $\text{End}(E_0)\simeq \mathcal{O}_0$ is a maximal order in the quaternion algebra $B_{p,\infty}$ over $\mathbb{Q}$ ramified at $p$ and $\infty$ . When $p=17$ , $B_{p,\infty} =(-p, -q)=(17, 3)$ and $\mathcal{O}_0 =\langle \frac{1+j}{2}, \frac{i+k}{2}, \frac{j+ck}{q}, k \rangle$ (I'm omitting what the value $c$ is) is a maximal order.
I'm trying to implement a constructive algorithm for Deuring's correspondence [Algorithm 3, EHL+18] , which computes a supersingular $j \in \mathbb{F}_p$ such that $\text{End}(E(j))\simeq\mathcal{O}_0$ . Let me briefly explain how the algortihm works; they constructed an isomorphism of $\mathbb{Q}$ -algebras $B_{p,\infty} \rightarrow \text{End}(E)\otimes \mathbb{Q}, (1, i, j, k) \mapsto(1,\pi, \phi, \pi\phi)$ , where $\pi$ is a $p$ th-power Frobenius endomorphism (they presumed that $\mathcal{O}_0 \simeq \text{End} (E)$ is supersingular so that $\pi$ lies in $\text{End}(E)$ ). To find $\phi$ with $\phi^2=[-q]$ , they first computed all $j$ -invariants with an embedding $\mathcal{O}_K\subset\text{End}(E)$ where $\mathcal{O}_K$ is the ring of integers of $K=\mathbb{Q}(\sqrt{-q})$ , by finding roots of the hilbert class polynomial (modulo $p$ ) of $K$ (by the construction of $p$ and $q$ , the roots are precisely the $j$ -invariants with the embedding). Then they computed all endomorphisms of degree $q$ for each $E(j)$ and checked if one of them satisfies $\phi^2=[-q]$ . Now this is my implementaion on Sagemath: sage: def j_with_embedding(p, q):
sage:  F = GF(p) 
sage:  R.<x> = PolynomialRing(F) 
sage:  K = QuadraticField(-q) 
sage:  o = K.maximal_order() 
sage:  d = o.discriminant() 
sage:  H = hilbert_class_polynomial(d)
sage:  return R(H).roots(multiplicities=False) j_with_embedding(p, q) computes all $j$ -invariant in $\mathbb{F}_p$ with $\mathcal{O}_{\mathbb{Q}(\sqrt{-q})} \subset\text{End}(E(j))$ . When $p=17$ and $q=3$ , it returns $0$ . sage: j_with_embedding(17,3)
 [0] Then I used 'E.isogenies_prime_degree(q)' which computes all isogenies over $K$ of degree $q$ from $E/K$ . There are 4 isogenies of degree $3$ from $j=0$ . The first isogeny is the only endomorphism of degree $3$ . You can get the endomorphism by post-composing an isomorphism of curves. sage: E = EllipticCurve(j=GF(17^2)(0)); E
Elliptic Curve defined by y^2 = x^3 + 1 over Finite Field in z2 of size 17^2
sage: E.isogenies_prime_degree(3)
[Isogeny of degree 3 from Elliptic Curve defined by y^2 = x^3 + 1 to Elliptic Curve defined by y^2 = x^3 + 7,
Isogeny of degree 3 from Elliptic Curve defined by y^2 = x^3 + 1 to Elliptic Curve defined by y^2 = x^3 + 13*x + 15,
Isogeny of degree 3 from Elliptic Curve defined by y^2 = x^3 + 1 to Elliptic Curve defined by y^2 = x^3 + (3*z2+9)*x + 15,
Isogeny of degree 3 from Elliptic Curve defined by y^2 = x^3 + 1 to Elliptic Curve defined by y^2 = x^3 + (14*z2+12)*x + 15 ]
sage: phi = E.isogenies_prime_degree(3)[0]
sage: phi.set_post_isomorphism(phi.codomain().isomorphism_to(E))
sage: phi
Isogeny of degree 3 from Elliptic Curve defined by y^2 = x^3 + 1 to Elliptic Curve defined by y^2 = x^3 + 1
sage: phi.rational_maps()
(((-4*z2 + 5)*x^3 + (z2 + 3))/x^2, ((3*z2 + 7)*x^3*y + (-7*z2 - 5)*y)/x^3) but this endomorphism doesn't satisfy $\phi^2=[-q]$ . sage: (X1, Y1) = phi.rational_maps()
sage: (X2, Y2) = phi.rational_maps()
sage: X3 = X2.subs(x=X1, y=Y1)
sage: Y3 = Y2.subs(x=X1, y=Y1)
sage: (X3, Y3) == E.multiplication_by_m(-3)
False I'm not sure where it went wrong. Even if I work over an algebraic closure $\overline{\mathbb{F}}_p$ , I get only one curve $j=0$ and there is a unique endomorphism of degree $q$ . I guess $\text{End}(E(0)) \simeq \mathcal{O}_0$ , but for some reason I can't construct an endomorphism of degree $q$ .","['sagemath', 'elliptic-curves', 'algebraic-geometry', 'isogeny', 'quaternions']"
4370621,Asymptotic behaviour of implicit functions,"Suppose we have an implicit equation $F\left(x,y\right)=0$ which we know defines $y = y(x)$ as a function of $x$ . Are there sufficient or necessary conditions under which we can obtain information about the asymptotic behaviour of $y(x)$ ? Particularly, what is the limit $\lim _{x\to +\infty }y\left(x\right)$ (if it even exists)? Or if we constrain ourselves to the domain $x,y>0$ then what is $\lim _{x\to 0^+ }y\left(x\right)?$","['implicit-function', 'asymptotics', 'calculus', 'implicit-function-theorem', 'limits']"
4370639,Continuous function composed with itself is equal to propagation of a differential equation.,"This question has been bugging me for a while. It was given as the last question of a first year undergrad analysis exam and so should be solvable with little machinery,
yet it seems to point straight at ODEs which have yet to be covered. Here is the question: Let $F:\mathbb{R} \to \mathbb{R}$ be a bounded $\mathscr{C}^1$ function and $\left(f_t:\mathbb{R}\to\mathbb{R}\right)_{t\in\mathbb{R}}$ a family of continuous functions with $f_0(x)=x$ such that $$\lim_{h\to 0} \frac{f_{t+h}(x)-f_t(x)}{h}=F(f_t(x))$$ Show that there exists a continuous function $g:\mathbb{R}\to\mathbb{R}$ such that $f_1 = g\circ g$ . I have attempted this with a classmate and we've come to various levels of understanding of the question, but the required conclusion keeps escaping us. Our main issues with the question are that we have very little understanding on continuous functions composed with themselves, and additionally we haven't managed to use the $\mathscr{C}^1$ and boundedness condition on $F$ . Note that the question also states that we are allowed to assume that the family of functions $(f_t)_{t\in\mathbb{R}}$ is uniquely determined by the given conditions: this again points to the domain of differential equations, which ideally we should not need to refer to in order to solve this.","['calculus', 'function-and-relation-composition', 'ordinary-differential-equations', 'real-analysis']"
4370645,Convergence and divergence of a Complex Series,"I've been given the following series: $$\frac{z}{1-z^2} + \frac{z^2}{1-z^4} + \frac{z^4}{1-z^8} + ...$$ and been told to investigate the convergence. Clearly this diverges if $z=1$ (possibly if $\vert{z}\vert = 1$ ?), but other than that I am at a loss as to how to proceed. Wolfram Alpha tells me that this converges to $\frac{z}{1-z}$ if $\vert{z}\vert<1$ and to $\frac{1}{1-z}$ if $\vert{z}\vert>1$ but how would one go about showing this?","['convergence-divergence', 'sequences-and-series']"
