question_id,title,body,tags
896186,How can I prove that the span of a subspace and its orthogonal complement is the whole vector space?,"The book Linear and Geometric Algebra explains the following theorem in a way that I haven't been able to figure out: If $\mathbf{A}$ and $\mathbf{B}$ are subspaces of a vector space $\mathbf{B}$ then the set of all combinations $\mathbf{a} + \mathbf{b}$ such that, $\mathbf{a} \in \mathbf{A}$ and $\mathbf{b} \in \mathbf{B}$ is called the span of $\mathbf{A}$ and $\mathbf{B}$, written as $\text{span}(\mathbf{A}, \mathbf{B})$. Furthermore let $\mathbf{U}^{\bot}$ be the subspace consisting of all vectors orthogonal to a subspace $\mathbf{U}$, in the sense that $\mathbf{u} \in \mathbf{U}^{\top}$ if and only if, $\mathbf{u} \perp \mathbf{v}$ for all vectors $\mathbf{v} \in \mathbf{U}$. I have of course been able to prove that $\mathbf{U}^{\bot}$ is indeed a subspace for all subspaces $\mathbf{U}$, if this turns out to be useful. The theorem I want to prove is: if $\mathbf{U}$ is a subspace of $\mathbf{V}$ then 
$\text{span}(\mathbf{U}, \mathbf{U}^{\perp}) = \mathbf{V}$. The book mentioned above proves it as follows: If $\text{span}(\mathbf{U}, \mathbf{U}^{\perp}) \neq \mathbf{V}$ then there is a nonzero $\mathbf{u} \perp \text{span}(\mathbf{U}, \mathbf{U}^{\perp})$ because any orthonormal basis for a subspace of an inner product space can be extended into an orthonormal basis for the entire inner product space. In particular $\mathbf{u} \perp \mathbf{U}$, i.e. $\mathbf{u} \in \mathbf{U}^{\perp}$, a contradiction. I understand how an orthonormal basis for a subspace of an inner product space can be extended into an orthonormal basis for the whole inner product space essentially using Gram-Schmidt orthogonalisation. I don't understand how this process allows you to go from, $\text{span}(\mathbf{U}, \mathbf{U}^{\perp}) \neq \mathbf{V}$ to $\exists \mathbf{u} \in \mathbf{U} : \mathbf{u} \perp \text{span}(\mathbf{U}, \mathbf{U}^{\perp})$. So my question would be how does this implication work?","['orthogonality', 'linear-algebra', 'inner-products', 'orthonormal']"
896191,"The vector space of absolutely continuous functions on $[0,1]$ endowed with a special norm, then the space is complete.","The vector space of absolutely continuous functions $V$ on $[0,1]$ endowed with a special norm $||\cdot ||$ as $||f||=\int_0^1 |f(t)|dt +\int_0^1 |f'(t)dt|=||f||_1+||f'||_1, \quad f\in V$.   Then the space is complete. Here is what I tried: we want to prove $V$ is complete, so it suffices to prove that $V$ is summable, i.e for any $\sum_{n=1}^\infty ||f_n||<\infty$, we can get $\sum_{n=1}^\infty f_n$ converges in $V$. Define $F:=\sum_{n=1}^\infty f_n, f:=\sum_{n=1}^\infty f'_n$,  then $||F||_1\leq \sum_{n=1}^\infty ||f_n||_1<\infty$ so that  $f\in L^1[0,1]$ and $||f||_1\leq \sum_{n=1}^\infty ||f'_n||_1<\infty$ so that  $f\in L^1[0,1]$. $\int_0^x f'=\int_0^x\sum_{n=1}^\infty f'_n=\sum_{n=1}^\infty \int_0^x f'_n=\sum_{n=1}^\infty (f_n(x)-f_n(0))=F(x)-F(0)$. So $F$ is absolutely continuous, i.e $F\in V$, we get $\sum_{n=1}^\infty f_n$ converges to $F$ in $V$. Is this process right? or there are other correct proof?","['functional-analysis', 'absolute-continuity']"
896206,Group of order $224$,Any one can give a hint to prove this? Every group of order $224$ have a subgroup of order $28$.,"['finite-groups', 'group-theory']"
896209,Solving $x^3+y^3=x^2y^2+1$ in non-negative integers,"I wanted to solve $x^3+y^3=x^2y^2+1$ in non-negative integers. First I set $a=x+y$ and $b=xy$ to get $b^2+3ab+1=a^3$. View as a quadratic in $b$, the discriminant = $4a^3+9a^2-4$, which needs to be a perfect square. Secondly, rearranging the quadratic in $b$ we get $4a^3+9a^2-4=(2b+3a)^2$. So the discriminant is always a perfect square. Therefore we have (quadratic formula): $b=\frac{-3a\pm (2b+3b)}{2}$ so $b\in \{b,-\frac{3a}{2}\}$. Since we want $a,b\ge 0$, the only possibility is $a=b=0$ to give $x=y=0$. This is the unique solution. Note: I wasn't sure if it works, I never tried this way before. Thanks!","['elementary-number-theory', 'diophantine-equations', 'number-theory']"
896249,Definition of $H^{-1}$ space in Evans' PDE book,"Let $U$ be an open, bounded subset of $\mathbb{R}^n.$ Evans' well known PDE book defines the spaces: $H_0^1(U)$ := $\{f\in H^1(U): \text{there exists a sequence} \; \phi_n \to f \; \text{in the} \; H^1(U) \;\text{norm, with} \; \phi_n \in C_c(U)\}.$ $H^{-1}(U)$ is the dual space of $H_0^1(U).$ My question: how come $H_0^1(U)$ is not self-dual? Indeed, if we consider the inner product $(f,g):= \int f g + \int f' g',$ then it seems to me that all the Hilbert space axioms are satisfied. So the Riesz Representation Theorem would imply that $H_0^1(U)$ is self-dual.  But then Evans would have defined the same space twice, which seems strange...","['functional-analysis', 'partial-differential-equations']"
896270,Collection of all finite sets,"Is the collection of all finite sets a set or a proper class? If it's a set how to prove otherwise alos how to prove? And finite set means sets which are in 1-to-1 correspondence with $\{1,2,3,...,n\}$ where $n$ is a natural number.",['elementary-set-theory']
896282,Normalizer and centralizer of abelian subgroups of a group are equal [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I have a question: Let $G$ be a finite group. If for each abelian subgroup $H$ of $G$ the centralizer and the normalizer of $H$ are equal, that is, $C_G(H)=N_G(H)$, prove that $G$ is abelian group.","['finite-groups', 'group-theory', 'abstract-algebra']"
896289,If a one-to-one function's inverse is the same what must be true of the graph of f?,As a followup to this question . I'm trying to determine what must be true of the graph of $f$ in these cases. I've examined the two functions $f(x)= x$ and $f(x)= \frac{1}{x}$ and I'm not seeing any unifying graphic truth. Is there a graphic truth to be found for one-to-one function's where the inverse happens to be the same?,"['graphing-functions', 'inverse', 'functions']"
896326,Calculus - prove that limit doesn't exists using esplion and delta,"Using epsilon and delta proof this : $$\lim_{x \to 3} \sqrt{x+1}\neq1$$ Exist $\varepsilon>0$ All $\delta>0$ so for some $x$ that appiles $0<|x-3|<\delta$ and however $|\sqrt{x+1}-1|\geq\varepsilon$ I don't really know how to approach this, any help will be appreciated.","['epsilon-delta', 'calculus', 'limits']"
896331,On the decomposition of stochastic matrices as convex combinations of zero-one matrices,"Let ""stochastic"" matrix be the matrix whose rows sum to one and deterministic matrix be a stochastic matrix whose all rows consist of a one and zero. For example $\left [ \begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
1 & 0 & 0      \end{array} \right] $ is a deterministic matrix. I am trying to show that any stochastic matrix can be written as a convex combination of deterministic matrices.","['matrices', 'convex-analysis', 'linear-algebra', 'reference-request']"
896332,"$S$, $I$, $O$ are circumcenter, incenter and orthocenter then $SO\ge IO \sqrt2$","Let $S$, $I$ and  $O$ be the circumcenter, incenter and orthocenter of $\triangle ABC$ then prove that $SO\ge IO \sqrt2$, or equivalently $SO^2\ge 2IO^2$. I was able to derive an expression for $SO^2$ using the cosine law: $$SO^2=R^2(1+4\cos^2A+2\cos A [ \cos 2B+\cos 2C])$$
I was able to get an expression for $IO^2$ as well but it was too long, and seemed unfit for this question. Besides that, I can't think of any useful tricks in this inequality. Can anyone help?","['geometry', 'triangles', 'trigonometry', 'inequality']"
896365,Using Stokes theorem to integrate $\vec{F}=5y \vec{\imath} −5x \vec{\jmath} +4(y−x) \vec{k}$ over a circle,"Find $\oint_C \vec{F} \cdot d \vec{r}$ where $C$ is a circle of radius $2$ in the plane $x+y+z=3$ , centered at $(2,4,−3)$ and oriented clockwise when viewed from the origin, if $\vec{F}=5y \vec{\imath} −5x \vec{\jmath} +4(y−x) \vec{k}$ Relevant equations: Stokes theorem: $$\int_S \operatorname{curl}{F} \cdot \mathbf{n} \, dS = \oint_{\partial S} F \cdot d\mathbf{r}$$ My attempt: For the curl I get $(4,4,-10)$ . For $d\vec{S}$ I get $(1,1,1)$ from $z = 3-x-y$ Dotted together its $-2$ . So: $-2 \iint_S dA$ . Area of circle is $4\pi$ . My answer would be $-8\pi$ but the online homework system says it's not correct. Please help!","['multivariable-calculus', 'calculus', 'integration', 'definite-integrals', 'vector-analysis']"
896385,How many ways can 5 dice produce a total of 20?,"How many ways can $5$ dice produce a total of $20$? I set up the equation $x_1+x_2+x_3+x_4+x_5 = 20$. The total possible number of combinations is $\binom{19}4$. From there I subtracted the number of possibilities where $1$ of the variables is greater than $6$, which I got as $5\times\binom{13}4$. I also subtracted the possibilities where $2$ variables is greater than $6$, which I used $10 \times \binom74$. I got the $10$ from the number of ways I can choose $2$ of the variables to be greater than $6$ out of the $5$ total variables. So I have $$\binom{19}4 -5\times\binom{13}4 -10\times\binom74$$ However, I get a negative answer, which can't be right. Can anyone point a flaw in my logic?","['combinations', 'discrete-mathematics', 'combinatorics']"
896391,Separability of a set with norm $\thickapprox$ $L^1$ +$L^{\infty}$,"Let $(M, \mathcal{A}, \mu)$ a complete separable probability space. Recall that complete means that any subset of a measurable set with zero measure is measure (and has zero measure) and separable means that there exists a countable family $E\subset \mathcal{A}$ such that for any $\varepsilon >0$ and any $B \in \mathcal{A}$ the exists $A_k \in E$ such that $\mu(B\triangle A_k)<\varepsilon$. Let $Y$ compact metric space. We define the family $\mathcal{F}$ so that $\phi \in \mathcal{F}$ sss $\phi$ is measurable ($Y$ with borel sigma algebra) for all $x\in M$, $\ $  $\phi(x,.): Y \rightarrow \mathbb{R}$ is continuous i.e. $\phi(x,.)\in (C^0(Y),\Vert . \Vert_0  )$ (supremum norm) $x \mapsto \Vert \phi(x,.) \Vert_0 \in L^1(\mu)$ equip $\mathcal{F}$ of a norm: 
 $\Vert \phi \Vert_1=\int \Vert \phi(x,.) \Vert_0 d\mu$ Then $(\mathcal{F}, \Vert . \Vert_1 )$ is a separable Banach space. I tried that $(\mathcal{F}, \Vert . \Vert_1 )$ is a Banach space I have difficulty with the separability: I show my progress using the fact that $C^0(Y)$ is separable, and the assumption that the probability space is separable we obtain: $\lbrace f_i\rbrace $ countable and dense in $C^0(Y)$ and $\Gamma= \lbrace \sum _{k=1}^{r}  c_k\chi_{A_k} : A_k \in E, c_k\in \mathbb{Q} \rbrace $ countable and dense in $L^1(\mu)$. Now note that for $\phi \in \mathcal{F}$, $\phi(x,.)$ can be approximated by $\lbrace f_i\rbrace $ and  $\phi(.,y) \in L^1(\mu)$ since for fixed $y$ $$\int \vert\phi(x,y)\vert d\mu(x)\leq \Vert \phi\Vert_1$$ then $\phi(.,y)$ can be approximated by $\Gamma$ but how to unite these facts... I appreciate the patience to read my query and hope you can help","['integration', 'measure-theory', 'real-analysis', 'lebesgue-measure', 'functional-analysis']"
896394,Mean value theorem inside the Expectation,"Consider a stochastic process $X_t$ with continuous paths. I'd like to apply the mean value theorem inside the expectation, i.e. write something like
$$ \operatorname{E} \left[ \int_0^t X_s \, \mathrm{d}s\right] = t \operatorname{E} [X_{\xi_{\omega}}] \leq  t \operatorname{E} \left[ \sup_{\xi_{\omega} \in (0,t)} X_{\xi_{\omega}}\right].$$
Is it enough to require something like $\operatorname{E} [ \sup_{s \in (0,t)} |X_s|] < \infty$ for this reasoning to be valid or does one need additional assumptions? I'm concerned about the measurability of $\omega \mapsto X_{\xi_{\omega}}(\omega)$.","['probability-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals']"
896437,Integration of some floor functions [closed],Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 months ago . Improve this question Can anyone please answer the following questions ? 1) $\int\left \lfloor{x}\right \rfloor dx$ 2) $\int$ $ \left \lfloor{\sin(x)}\right \rfloor $ $dx$ 3) $\int_0^2$ $\left \lfloor{x^2+x-1}\right \rfloor$ $dx$ 4) $\int_o^\pi$ $\left \lfloor{x(1+\sin(\pi x)}\right \rfloor$ Also can anyone please make me understand the way in which to proceed in these types of sums? $\left \lfloor{x}\right \rfloor$ is the floor function Thanks,"['calculus', 'integration', 'definite-integrals', 'indefinite-integrals', 'ceiling-and-floor-functions']"
896444,Using resultants to check if multivariate polynomials have a common factor - is my proof correct?,"Proposition: Let $f, g \in \mathbb R[x,y,z]$. Then the condition that $f, g$ have a common polynomial factor is an algebraic condition on their coefficients. By algebraic condition, I mean there is a finite set of algebraic (polynomial) expressions in the coefficients, such that all expressions are zero if and only if $f, g$ have a common factor. My proof: Let $\operatorname{Res}_x(f,g)$ be the resultant of $f, g$ when viewed as univariate polynomials in $(\mathbb R[y,z])[x]$. Then $\operatorname{Res}_x(f,g) \in \mathbb R[y,z]$ is zero if and only if $f, g$ have a common factor that depends on $x$. As a polynomial in $y,z$, it is zero if and only if all of its coefficients are zero. But the coefficients of the resultant are simply polynomial expressions in the coefficients of $f, g$. Therefore there is an algebraic condition on the coefficients of $f,g$ that determines when $f,g$ have a common factor that depends on $x$ . Repeating the argument, there are two more algebraic conditions on the coefficients of $f,g$, which determine when they have a common factor that depends on $y$ and when they have one that depends on $z$. The union of all 3 conditions is what we're after. Questions: Is my proof correct? I'm especially concerned about the claim that the resultant is the zero polynomial if and only if there is a common factor that depends on $x$. (Does the resultant behave ok for polynomials over rings instead of over fields?) Do you have comments or suggestions for improvement? Any recommended books on this subject?","['proof-verification', 'abstract-algebra', 'polynomials']"
896481,What is the meaning of $d\vec S$ in a surface integral?,"Can someone explain if I have a surface $z= 9-x^2-y^2$ What would $\vec{n}$ be? What would $d\vec{S}$ be? Why is $d\vec{S}$ $(2x,2y,1)$ and not $(2x,2y,1)/\sqrt{4x^2+4y^2+1}$?
Thanks!","['multivariable-calculus', 'integration', 'surfaces']"
896494,area formed by a box and line,"suppose we have a box defined by coordinates $(1,1)$, $(-1,1)$, $(-1,-1)$, $(1,-1)$.
Suppose, a line $y=m(x+b)$ crosses the box with $m>0$ and $b>0$. What is the area of left upper triangle.  Assume that the line crosses the box. 
Thank you very much. Partial Answer: the line intersects a box at $(x,y)=(\frac{1}{m}-b,1)$ and $(x,y)=(-1,m(b-1))$ Area is formed by $(-1-(\frac{1}{m}-b)) \cdot (1-m(b-1))$ ,correct?",['geometry']
896510,When does $(a^p-1)/(a-1)$ have a $p$th power factor?,"Today I noted that $(18^3-1)/(18-1) = 343 = 7^3$, and that there are no other solutions to the equation $(a^3-1)/(a-1) = b^3$ with $b \le 100000$. There are, however, many solutions to the equation
$$
\frac{a^p-1}{a-1} = cb^p  \qquad(\star)
$$
for some integer $c \ge 1$, when $p=3$. When $p=5$, there are far fewer solutions to $(\star)$, two of which are $a=37107$ and $a=46709$. My question is: Under what conditions does $(\star)$ have any solutions? This is clearly related to problems like Fermat's Last Theorem and Catalan's Conjecture, but is not nearly as restrictive, e.g. , I'm not requiring that $a-1$ also be a $p$th power.","['factoring', 'number-theory']"
896513,Modeling Rain on a Windshield for various Speeds using Calculus,"A question was recently posed to Click & Clack Talk Cars ( http://www.greatfallstribune.com/story/life/2014/08/07/click-clack-rainy-day-raises-physics-question/13750681/ ). The topic is rain hitting an automobile windshield and the basic question asked is, ""Are more raindrops hitting the windshield while moving."" Their response is that this problem ""is a very straightforward calculus problem"" and that ""...yes, your windshield does get hit with more raindrops per second if you are moving forward."" They state that they are incapable of solving the calculus problem and then provide an analogy which seems to support their conclusion. My request: Would a calculus person please explain the steps involved in solving this ""straightforward calculus"" problem?","['self-learning', 'calculus']"
896526,"Let $G$ be finite, $H\unlhd G.$ Let $P$ be a Sylow $p$-subgroup of $H.$ Use Sylow's theorem to show $G = H N_G(P).$","I am stumped on this question. Does anyone have some helpful hints or a solution to this question? Thanks! Let $G$ be a group of finite order. Let $H$ be a normal subgroup of $G.$ Let $P$ be a Sylow $p$-subgroup of $H.$ Using Sylow's theorem, show that $G = H N_G(P).$","['sylow-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
896584,System of equations in Lagrange multiplier problem,"Continuing from Confounding Lagrange multiplier problem : I'm having trouble solving the system of equations below arisen from a Lagrange multiplier problem where we are to optimize $f(x,y,z) = 4x^2 + 3y^2 + 5z^2$ over $g(x,y,z) = xy + 2yz + 3xz = 6$. $$ \begin{cases} 8x = \lambda (y + 3z) \\ 6y = \lambda (x + 2z) \\ 10 z = \lambda (2y + 3x) \\ xy + 2yz + 3xz = 6 \end{cases} $$ One suggestion I have got is to eliminate the terms $xy$, $yz$ and $xz$, however I have been unable to figure out how to do so. Help much appreciated!","['optimization', 'multivariable-calculus', 'calculus', 'lagrange-multiplier']"
896589,"If $b$ is a regular value of $f$, $f^{-1}(-\infty,b]$ is a regular domain?","I'm trying to prove the first part of Proposition 5.47 of Lee's Smooth Manifolds, which is left to the reader. It says Suppose $M^m$ is a smooth manifold, and $f\colon M\to\mathbb{R}$ smooth. For each regular value $b$ of $f$, the sublevel set $f^{-1}(-\infty,b]$ is a regular domain, that is, a properly embedded codimension $0$ submanifold with boundary. First, $f^{-1}(\infty,b)$ is open, hence an embedded submanifold of codimension $0$. Also, $f^{-1}(-\infty,b]$ is closed in $M$, so if $f^{-1}(-\infty,b]$ is a embedded submanifold, it  is in fact a properly embedded submanifold of codimension $0$. I want to show $S:=f^{-1}(-\infty,b]$ satisfies the local $m$-slice condition. If $p\in f^{-1}(-\infty,b)$, then since this set is open, we can find a chart $(U,\varphi)$ around $p$ in $S$. But then $\varphi(S\cap U)=\varphi(U)$, so $(U,\varphi)$ is an $m$-slice chart around $p$. I suspect $f^{-1}(b)$ is the boundary of $S$. Since $f^{-1}(b)$ is a regular level set, it is a properly embedded submanifold of dimension $m-1$ in $M$. I could then find an $m-1$ slice chart $(U,\varphi)$ in $M$ for $f^{-1}(b)$, so that
$$
\varphi(f^{-1}(b)\cap U)=\{(x^1,\dots,x^m)\in\varphi(U):x^m=0\}
$$ I want to try to modify it somehow to a chart such that 
$$
\varphi(U\cap S)=\{(x^1,\dots,x^m)\in\varphi(U):x^m\geq 0\}
$$
to show it is an $m$-dimensional half slice. Is there maybe a way to restrict to a precompact open set, so that the coordinate functions achieve a mimnimum, and then just shift the coordinate map so the last coordinate is always nonnegative?","['differential-topology', 'manifolds', 'smooth-manifolds', 'differential-geometry']"
896604,"$f'$ exists, but $\lim \frac{f(x)-f(y)}{x-y}$ does not exist","Suppose $f$ is differentiable at $a$, i.e. $\lim_{x\to a}\frac{f(x)-f(a)} {x-a}$ exists. I wondered whether it was necessarily true that $$\lim_{\substack{x,y\to a\\x\neq y}}\frac{f(x)-f(y)}{x-y} \tag{1}$$
exists and equals the same thing. I believe that my friends and I have found a counterexample, which I'll place below the fold. I believe we have found some conditions under which (1) must exist and equal $f'(a)$, and I wonder if anyone has some others: If $x$ and $y$ approach from opposite sides of $a$, then I claim that
the secant line from $x$ to $y$ has slope between the slope of the
secant line from $x$ to $a$ and the slope of the secant line from $y$
to $a$. (Draw a picture.) Therefore a counter-example can only come
where $x$ and $y$ do not approach $a$ from different sides. ( Wrong ) Note that if $a,b\geq 0$ and $c,d>0$, then $\frac{a+c}{b+d}$ is
between $\frac{a}{c}$ and $\frac{b}{d}$. So, assuming that $x$ and
$y$ are approaching from the same side, if $f(x)-a$ and $f(y)-a$ have
the same sign in a neighborhood of $a$, then (1) must exist and equal
$f'(a)$. So a counter-example can only come when for all $\delta>0$,
$f(x)-f(a)$ is both positive and negative either on $(a,a+\delta)$ or
on $(a-\delta, a)$. From the definition of the derivative, this also
shows that a counterexample can only come when $f'(a)=0$. Edit: TonyK has pointed out that I am in error here. One of my friends conjectured that if $f$ were rectifiable, then a counterexample cannot exist. Does anyone have any thoughts on this? Counterexample. Suppose $$f:x\mapsto \begin{cases}x^2\sin \left( 1/x \right) & x \neq 0 \\ 0 & x=0.\end{cases}$$ $f$ is differentiable at zero with $f'(0)=0.$ Take $x_n$ and $y_n$ to be adjacent peaks and valleys:
$$x_n := \frac1{\pi/2 + 2\pi n}\\ y_n := \frac1{3\pi/2 + 2\pi n}.$$ $x_n$ and $y_n$ go to zero as $n\to \infty$. Then I claim 
$$\frac{f(x_n)-f(y_n)}{x_n-y_n} \xrightarrow{n\to\infty}\frac2\pi \neq f'(0)$$","['calculus', 'derivatives', 'limits']"
896654,Is this Integral calculation correct?,"Can someone confirm if my solution is right or if I have done something that is not permitted $$
\begin{align}
& \int_\gamma e^{\pi z}=\int_\gamma \left( \frac{ e^{\pi z}}{\pi}\right)' \, dz \\[8pt]
= {} & \int_{-1}^1 \left(\frac{e^{\pi (3-3t^2+i(t^3-3t+1))}}{\pi}\right)' (3-3t^2+i(t^3-3t+1))' \,dz \\[8pt]
={} & \int_{-1}^1 \left(\frac{e^{\pi (3-3t^2+i(t^3-3t+1))}}{\pi} (3-3t^2+i(t^3-3t+1))\right)'dz \\[8pt]
= {} & \frac{e^{\pi(3-3t^2 +i(t^3-3t+1))}}{\pi} (3-3t^2+i(t^3-3t+1))
\end{align}
$$","['complex-integration', 'complex-analysis']"
896661,Cubic polynomial equal to a cube,"I've been researching cubes and I'm trying to solve this Diophantine equation over the integers. $$ax^3 + bx^2 + cx + d = y^3$$where a, b, c, d are parameters for a given $n$. For example, for $n = 5$, you have$$5x^3 + 30x^2 + 90x + 100 = y^3$$ Is there any way to solve this Diophantine equation? Or does anyone know any references or links to point me to? (Either for general $a,b,c,d$ or for the specific one above). Thanks! Also a, b, c, and d are functions of n:
$$a = n$$
$$b = (3/2)n(n-1)$$
$$c = (1/2)n(2n-1)(n-1)$$
$$d = (1/4)n^2(n-1)^2$$ It's theorized that there are no solutions (to this specific one). But I want to prove it. Surely, I can't check for every single x, I'm mainly looking for a bound on x as a function of n. Essentially, ""After some finite x, it will never be a cube"" ...","['cubics', 'diophantine-equations', 'number-theory']"
896677,Is the lacunary series $\sum_{n = 1}^{\infty}z^{n!}$ bounded along some sequences converging to the boundary?,"Let $f(z) = \sum_{n = 1}^{\infty}z^{n!}$. Is it possible to have a sequence $z_{n} \in \mathbb{D}$ such that $|z_{n}| \rightarrow 1$ as $n \rightarrow \infty$ and $|f(z_{n})| \rightarrow M < \infty$? I know that if $z_{n} = r_{n}e^{i\theta}$ for some fixed $\theta$, the answer is no, but what if $\theta$ varies with $n$?",['complex-analysis']
896691,Does absolute convergence of a sequence imply convergence?,In my real analysis notes I've got that absolute convergence of a real SERIES implies convergence of the series. However what about absolute convergence of a sequence? Does this imply convergence of the sequence?,['real-analysis']
896727,Itô Excursion Measure,I am looking for any source of information regarding Itô Excursion Measure (for Brownian Motion). I am looking for a selfcointained reference (Though I have basic knowledge on Local Times and Poisson Point Processes). In particular I am looking forward to studying random trees derived from excursion processes and I was trying to cover as thoroughly as posible the prequisites. I have found some references (particularly the Revuz Yor book) but it takes too long to get to what I want and notation is really strange for me (in particular the way he defines point poisson processes). Any help will be apreciated,"['probability-theory', 'probability']"
896733,Factoring numbers,"I was given the following problem: Prove that 767, 76767, 7676767 ... are all composite. Making a sequence $a(n)$ = {767, 76767, 7676767, ...} you can show that $a(3k+1)$ is divisble by 13, $a(3k+2)$ is divisible by 3, and $a(3k+3)$ is divisible by 7, for $k$ = 0, 1, 2, ... Then, I gave the same question but for the following: Prove that 343, 34343, 3434343, ... are all composite. Prove that 717, 71717, 7171717, ... are all composite. I wasn't able to use the same method that I used above. Any help with this?","['factoring', 'number-theory']"
896743,Bisecting an angle doesn't lead to Trisecting?,"http://en.wikipedia.org/wiki/Talk:Angle_trisection If you take the angle, and draw a circle at the corner of the angle. You mark two points along the edges of the angle.
Those two points form the tangent of an isosceles triangle. If you can trisect a line, trisecting the tangent doesn't equal trisecting the angle?",['geometry']
896761,"In a non-Hausdorff space, can a compact subset fail to be closed?","In a Hausdorff space $X$, every compact subset $Y$ is closed. So if I relax the condition on $X$ being Hausdorff, is it possible compact subset $Y$ of $X$ not being closed?","['general-topology', 'examples-counterexamples', 'compactness']"
896763,"Compute $\iint_S \mathbf{F}\cdot d\mathbf{S}$ where $S$ is the surface that bounds the sphere $x^2+y^2+z^2=16$ and $\mathbf{F}=\langle z,y,x \rangle$","The problem is actually to verify the divergence theorem by computing both $\iiint_E \text{div } \mathbf{F\space} dV$, which was relatively easy to compute and gives $\frac{256\pi}{3}$. To find $\iint_S \mathbf{F}\cdot d\mathbf{S}$, I parametrized the surface with spherical coordinates: $\mathbf{r}=\langle 4\sin\phi\cos\theta,4\sin\phi\sin\theta,4\cos\phi\rangle$ with $0\leq\phi\leq\pi,0\leq\theta\leq2\pi$. Now, noting that $\iint_S\mathbf{F}\cdot d\mathbf{S}=\iint_S \mathbf{F}\cdot \mathbf{n}\space dS$ where $\mathbf{n}$ is the normal vector to the $S$, and since $S$ is a sphere, we have $\mathbf{n}=\langle\sin\phi\cos\theta,\sin\phi\sin\theta,\cos\phi\rangle$, and $$\mathbf{F\cdot n}=4\sin\phi\cos\phi\cos\theta+4\sin^2\phi\sin\theta\cos\theta+4\sin\phi\cos\phi\cos\theta$$ But the integral of this is 0. Where am I going wrong?",['multivariable-calculus']
896780,"Why is the value of $\int_0^{2\pi}|2\cos(nx)+\sqrt{3}|\,dx$ independent of integer parameter $n$?",I am not able to find an easy solution for the following formula $$\int_0^{2\pi}|2\cos(nx)+\sqrt{3}|dx=4+\frac{4}{3}\pi\sqrt{3}.$$ Please help me  prove it. Why it does not depend on the (positive) integer parameter $n$?,"['definite-integrals', 'trigonometry', 'absolute-value']"
896782,Is this a manifold?,"I am trying to get started with differential geometry, and am having a difficult time wrapping my head around the concept of a manifold. One thing that would make it easier to understand would be if authors would give more examples of things that aren't manifolds.  Anyway, here's one potential example that I came up with that I think will help me along quite a bit if I can understand it. So, let's say we're in $\Bbb R^3$ and we have the unit sphere $x^2+y^2+z^2=1$.  Even I can tell that this is a manifold.  But now let's take the disc $z=0, x^2+y^2<2$, cut a hole out of it at $x^2+y^2<1$ and ""attach"" it to our sphere.  Now, is the resulting object a manifold?  Why or why not?  What happens if we take our disc again and cut out the hole $x^2+y^2 \leq 1$? I can't see how this object violates any explicit part of the definition of a manifold, but it just doesn't seem right. Thanks for helping me get some sleep again.","['manifolds', 'differential-geometry']"
896802,Consecutive Prime Gap Sum (Amateur),"List of the first fifty prime gaps: 1, 2, 2, 4, 2, 4, 2, 4, 6, 2, 6, 4, 2, 4, 6, 6, 2, 6, 4, 2, 6, 4, 6, 8, 4, 2, 4, 2, 4, 14, 4, 6, 2, 10, 2, 6, 6, 4, 6, 6, 2, 10, 2, 4, 2, 12, 12, 4, 2, 4. My conjecture is that the sum of consecutive prime gaps is always prime whenever a prime gap of 2 is added. $$ 1 + 2 = 3 $$
$$ 1 + 2 + 2 = 5 $$
$$ 1 + 2 + 2 + 4 + 2 = 11 $$
$$ 1 + 2 + 2 + 4 + 2 + 4 + 2 = 17 $$
$$ 1 + 2 + 2 + 4 + 2 + 4 + 2 + 4 + 6 + 2 = 29 $$ I don't know if this is meaningful or how to go about testing it completely (I've tested it up to 461) so I'll just leave this here and see what comes of it.","['prime-numbers', 'sequences-and-series', 'pattern-recognition']"
896837,Poles of Fourier transform,Let $f\in L_2(\mathbb R_+)$ and consider its Fourier transform $$F(\zeta)=\int_0^\infty f(x)e^{ix\zeta}dx$$ Is it true that analytic continuation of $F(\zeta)$ has at most finitely many poles in a half-plane $\{\mathrm{Im}(\zeta)>-a\}$ for any $a>0$? Any counterexample or proof would be much helpful.,"['fourier-analysis', 'analyticity', 'complex-analysis']"
896863,Compute the derivative of Plucker Embedding,"Let V be an n-dimensional vector space over $\mathbb{R}$, and $$\Psi: G(k,V)\rightarrow \mathbb{P}(\Lambda^k V)$$ be the Plucker embedding, where $$L=span \{u_1, ..., u_k\} \mapsto \Psi(L)=[u_1 \wedge u_2 \wedge ... \wedge u_k].$$ (a) How can I show that this map is smooth? (b) How can I compute its derivative? ($\Psi_*:Hom(L,L^\perp)\rightarrow Hom(det(L), det(L)) $) Any help is appreciated!","['geometry', 'differential-geometry']"
896879,Non-symmetric matrix with orthogonal eigenvectors,"Given that a symmetric matrix with real entries has orthogonal eigenvectors, is the converse true? That is, if a matrix has orthogonal eigenvectors, does it have to be symmetrical and real?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
896917,How to solve inequalities with absolute values on both sides?,"If you have an inequality that has two absolute value bars like $|4x+1|<|3x|$, how do you go about doing this? I know that if $4x+1<3x$, then those $x$'s will work but what else do I do? I think you do $4x+1<-3x$. Is this correct?","['inequality', 'absolute-value', 'algebra-precalculus']"
896920,Upper bound for Euler's totient function on composite numbers,I've seen before the general bound $\phi(n) \leq n - n^{1/2}$ for composite $n$. Can this bound be improved at least for those $n$ when we don't have equality above? Say could we possibly have at least $\phi(n) \leq n - kn^{1/2}$ for some $k > 1$?,"['analytic-number-theory', 'number-theory']"
896922,Blow up in holomorphic dynamics,"Someone could explain the concept of blow up used in holomorphic dynamics? 
Specifically in the context of iteration of holomorphics functions. This concept could be taken to some of the deformation spaces of a particular function? Bibliography is very welcomed.","['dynamical-systems', 'teichmueller-theory', 'complex-dynamics', 'algebraic-geometry', 'complex-analysis']"
896963,Closure operator and topology problem,"Statement If $c:\mathcal P(X) \to \mathcal P(X)$ is a closure operator on $X$, then the set $\tau=\{U \in \mathcal P(X) : c(X \setminus U)=X \setminus U\}$ is a topology on $X$. First let me write the properties of a closure operator 1) $c(\emptyset)=\emptyset$, 2) if $A \in \mathcal P(X)$, then $A \subset c(A)$, 3)if $A \in \mathcal P(X)$, then $c(c(A))=c(A)$, 4) if $A, B \in \mathcal P(X)$, then $c(A \cup B)=c(A) \cup c(B)$ Using these axioms, I could show $X \in \tau$ and finite intersection of elements in $\tau$ remains in $\tau$. I couldn't show $\emptyset \in \tau: c(X \setminus \emptyset)=c(X)$, now I am not so sure which axioms could I use to prove $c(X)=X$. And for arbitrary union of elements in $\tau$, I have to prove that $c(X \setminus \bigcup_{i \in I} U_i)=X \setminus \bigcup_{i \in I} U_i$. The inclusion $X \setminus \bigcup_{i \in I} U_i \subset c(X \setminus \bigcup_{i \in I} U_i)$ is satisfied by 2), how could I prove the other inclusion? I would appreciate any help.","['general-topology', 'elementary-set-theory']"
896968,Bolzano–Weierstrass theorem for random variables?,"I am wondering if there is something similar to the Bolzano–Weierstrass theorem for random sequences. Namely, let $\{x_n\}$ be a bounded random sequence. Is it true that, under some reasonable conditions (I cannot be specific), there exists a subsequence of it that converges almost surely to a constant (not random variable)? thanks in advance.","['random-variables', 'convergence-divergence', 'probability', 'real-analysis']"
896989,Is there a bijection from a bounded open interval of $\mathbb{Q}$ onto $\mathbb{Q}$?,"It is easy to create a bijection between two bounded open intervals of $\mathbb{R}$, such as: $$
\begin{align}
 f : (a,b) &\to (\alpha,\beta) \\
 x &\mapsto \alpha+(x-a)(\beta-\alpha).
\end{align}
$$ It is also possible to biject a bounded open interval of $\mathbb{R}$ onto the whole of $\mathbb{R}$, e.g.: $$
\begin{align}
 f : (a,b) &\to \mathbb{R} \\
 x &\mapsto \tanh^{-1} x.
\end{align}
$$ Consider now the set of rational numbers $\mathbb{Q}$. The bijection between two bounded open intervals still holds, but is it possible to biject:
$$
f : (p,q) \to \mathbb{Q}
$$ where $p,q\in\mathbb{Q}$ and $(p,q) = \{x\in \mathbb{Q} : p < x < q\}$?","['rational-numbers', 'elementary-set-theory', 'real-analysis', 'analysis']"
897030,Prove $f: X \rightarrow Y$ is continuous if $A_a$ is closed and $f|A_a$ is continuous for any $a$ and $\text{{$A_a$}}$ is locally finite collection,Let $f:\bigcup_{\alpha}A_{\alpha} \rightarrow Y$ be a function between the topological spaces Y and $X=\bigcup_{\alpha}A_{\alpha}$. Suppose that $f|A_{\alpha}$ is a continuous function for every $\alpha$ and that $\text{{$A_{\alpha}$}}$ is locally finite collection. Suppose that $A_{\alpha}$ is closed for every $\alpha$. Show that: $f$ is continuous. Any hints?,"['general-topology', 'continuity']"
897034,Why learn to solve differential equations when computers can do it?,"I'm getting started learning engineering math. I'm really interested in physics especially quantum mechanics, and I'm coming from a strong CS background. One question is haunting me. Why do I need to learn to do complex math operations on paper when most can be done automatically in software like Maple. For instance, as long as I learn the concept and application for how aspects of linear algebra and differential equations work, won't I be able to enter the appropriate info into such a software program and not have to manually do the calculations? Is the point of math and math classes to learn the big-picture concepts of how to apply mathematical tools or is the point to learn the details to the ground level? Just to clarify, I'm not trying to offend any mathematicians or to belittle the importance of math. From CS I recognize that knowing the deep details of an algorithm can be useful, but that is equally important to be able to work abstractly. Just trying to get some perspective on how to approach the next few years of study.","['linear-algebra', 'self-learning', 'ordinary-differential-equations', 'physics']"
897035,Suppose that $f(x)$ and $g(x)$ are irreducible over $F$ and that $\deg f(x)$ and $\deg g(x)$ are relatively prime.,"Suppose that $f(x)$ and $g(x)$ are irreducible over $F$ and that $\gcd(~\deg g(x),\deg f(x)~)=1$. If $a$ is a zero of $f(x)$ in some extension of $F$, show that $g(x)$ is irreducible over $F(a)$ Attempt: Let $b$ denote a zero of $g(x)$ in some extension of $F$. We have : $[F(a,b):F(a)][F(a):F]=[F(a,b):F] = [F(a,b):F(b)][F(b):F] ~~~~..... (1)$ $\deg f(x) = [F(a):F ] ~~~~...... (2)$ $\deg g(x) = [F(b):F ] ~~~~......(3)$ Since, $\deg g(x)$ and $ \deg f(x)$ are prime to each other $\implies [F(b):F]$ divides $[F(a,b):F(a)][F(a):F] \implies [F(b):F]$ divides $[F(a,b):F(a)]$ How do I move ahead? Let $a,b \in \mathbb Q~~|~~b \neq 0$. Show that $\mathbb Q(\sqrt a) = \mathbb Q(\sqrt b)$ if and only if there exists some $c \in \mathbb Q$ such that $a = bc^2$ Attempt: Case $1$: When $ a = {p_1}^2/{q_1}^2$ where $p_1,q_1 \in \mathbb Z,\gcd(p_1,q_1)=1$ Then : $\mathbb Q(\sqrt a) = \mathbb Q(p_1/q_1) =\mathbb Q = \mathbb Q(\sqrt b)$ only if $\sqrt b = \dfrac {p_2}{q_2}$ or $b=\dfrac {{p_2}^2}{{q_2}^2} $ In such a case : $\dfrac {{p_1}^2}{{q_1}^2}=   \dfrac {{p_2}^2}{{q_2}^2} {(\dfrac {q_2 p_1}{p_2q_1})}^2$. Hence $c = (\dfrac {q_2 p_1}{p_2q_1})$ Did I do this correctly? How do i move ahead? Thank you for your help..","['ring-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
897061,Alternate Proof for $e^x \ge x+1$,"This is just a standard problem from my high school's calculus text, but my proof seems sort of off. This is it: Let $f(x) = e^x$. The tangent line of $f(x)$ at $x=0$ is $g(x)=x+1$. Since $f''(x_0) \gt 0$ for all $x_0 \in \mathbb R$,the tangent line $g(x) \le f(x)$ for all $x$. Q.E.D. I didn't show all of the work, but is there something wrong here? It is pretty short. Anyways, I would like to see some alternate proofs because I tried to think of another but when my brain said, ""meh"", I realized that there are probably tons of ways to prove this. So just any valid proof would be cool with me. I don't care if they're crazy. It's even cooler when they're crazy. But in particular the simplest proof would be appreciated.","['inequality', 'calculus', 'proof-verification']"
897070,What is the set with characteristic function $\chi_A(x) + \chi_B(x)-\chi_A(x)\chi_B(x)$?,"Suppose that $A$ and $B$ are subsets of $X$ Find the subset $C$ whose characteristic function is given by: $\chi_C(x)=\chi_A(x) + \chi_B(x)-\chi_A(x)\chi_B(x)$ The answer given is $C=(A\cup B) - (A \cap B)$ My answer is $A \cup B$ because: $\begin{align}
x\in A \cup B & \Rightarrow & x \in A \text{ or } x\in B \\
 & \Rightarrow & \chi_A(x)=1 \text { or } \chi_B(x)=1 \\
& \Rightarrow & \chi_C(x)=1\\
\end{align}
$ $\begin{align}
x\notin A \cup B & \Rightarrow & x \in (A^c \cap B^c) \\
 & \Rightarrow & x \notin A \text { and } x \notin B \\
& \Rightarrow & \chi_A(x)=0 \text { and } \chi_B(x)=0 \\
& \Rightarrow & \chi_C(x)=0
\end{align}$ What is wrong with my answer and how to I get the correct answer?","['characteristic-functions', 'elementary-set-theory', 'proof-verification']"
897114,how to find $(I + uv^T)^{-1}$,"Let $u, v \in \mathbb{R}^N, v^Tu \neq -1$. Then I know that $I +uv^T \in \mathbb{R}^{N \times N}$ is invertible and I can verify that $$(I + uv^T)^{-1} = I - \frac{uv^T}{1+v^Tu}.$$ But I am not able to derive that inverse on my own. How to find it actually? That is if am given $A =  I +uv^T$ and I am asked to find $A^{-1}$, how to get the answer?","['matrices', 'linear-algebra']"
897118,"What is the non-trivial, general solution of these equal ratios? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Provide non-trivial solution of the following: $$\frac{a}{b+c}=\frac{b}{c+a}=\frac{c}{a+b}$$ $a=?, b=?, c=?$ The solution should be general.","['fractions', 'linear-algebra', 'algebra-precalculus', 'systems-of-equations']"
897149,Simplifying $\sqrt[3]{a\pm\sqrt{b}}$,"Let
$$x=\sqrt{a\pm\sqrt{b}}$$
We know that
$$x=\sqrt{\frac{a+\sqrt{a^2-b}}{2}}\pm\sqrt{\frac{a-\sqrt{a^2-b}}{2}}$$
But, what about cubic root? Let
$$y=\sqrt[3]{a\pm\sqrt{b}}$$
Is there any formula to find $c$ and $d$ such that $c,d\in\mathbb{Q}$ and $c\pm\sqrt{d}=y$ if $c$ and $d$ exists? For example, let
$$a=\sqrt[3]{45+\sqrt{1682}}$$
It can be solved factoring terms:
$$a=\sqrt[3]{45+29\sqrt{2}}=\sqrt[3]{27+27\sqrt{2}+18+2\sqrt{2}}=\sqrt[3]{(3+\sqrt{2})^3}=3+\sqrt{2}$$
Is there any formula for cubic root like square root?","['radicals', 'nested-radicals', 'algebra-precalculus']"
897162,Modern mathematics for dummies,"I have poor university mathematical education, but Math fascinates me, so I decided to educate myself for a bit. I know there is a dozen modern mathematical fields I know nearly nothing about like differential and abstract topology, differential and abstract geometry, homological algebra, Lie groups etc. I am looking for some books, but not deep textbooks, something like ""for dummies"" which will spell these fields out, with not very many proofs, not very many abstract symbols. I know there's Roger Penrose — The Road to Reality, the first half of which covers modern differential geometry very well, I know there's Charles Nash, Siddhartha Sen — Topology and Geometry for Physicists, which tries to cover the beginning of abstract topology. Is there anything like that? Thank you.","['general-topology', 'book-recommendation', 'group-theory', 'differential-geometry']"
897165,Contour Integration Confusion,"I am trying to find the value of $\displaystyle\int_0^\infty\frac{(\log x)^2}{1 + x^2}\,dx$ using contour integration. My approach: I have calculated the residue at z = $i$ and have shown that integration over small circle is equal to $0$. However I am having trouble in establishing that $\int_\Gamma f(z) = 0$ The book that I am following states that to show that it is equal to zero it is sufficient to show that $\lim_{z \to \infty} zf(z) = 0$
But if I use this method then the limit tends to $\infty$ and not zero. Am I applying any wrong concept ?","['complex-analysis', 'contour-integration']"
897174,Show that a finite union of compact subspaces of a topological space $X$ is compact.,"I am aware that there is a similar question elsewhere, but I need help with my proof in particular. Can someone please verify my proof or offer suggestions for improvement? Show that a finite union of compact subspaces of a topological space $X$ is compact. Let $A_1, \ldots, A_n$ be compact subspaces of a topological space $X$. Let $\mathscr{B}$ be a collection of open sets of $X$ which covers $\displaystyle{\bigcup_{i=1}^n A_i}$. Then, $\mathscr{B}$ covers $A_i$ for each $1 \leq i \leq n$. Since each $A_i$ is compact, we can choose a finite subcover $\mathscr{B}_i$ of $A_i$. But then, $\displaystyle{\bigcup_{i=1}^n \mathscr{B}_i}$ forms a finite subcover of $\displaystyle{\bigcup_{i=1}^n A_i}$.","['general-topology', 'compactness', 'proof-verification']"
897202,Is this relation symmetric,"$R = \{(X, Y) \in \mathscr{P}(A)^2| X \subset Y \text{ and }X \neq Y \}$ I know that $(X,Y) \in R$ holds true since $X \subset Y$. However I'm unsure if $(Y,X) \in R$ since if $Y \subset X$ then that would make $X = Y$ (I think) breaking the condition that $X \neq Y$. Am I correct in thinking this and concluding that this relation is not symmetric?","['relations', 'discrete-mathematics', 'elementary-set-theory']"
897208,Generalization of log-convexity (log-concavity): log-log-convexity (log-log-concavity)?,"$\underline{\mathrm{Background\; on\; function\; Convexity}}$ A function, $f$, is convex if:
$$f( x\theta+y(1-\theta) ) \leq \theta f(x) + (1-\theta)f(y).$$
$f$ is concave if $-f$ is convex,  [ 1 ]. If we can demonstrate the convexity (or concavity) of a function, then function optimization can be performed using the well understood theory of convex optimization. Thus, if we can, it is beneficial to be able to do so. In some situations, a function may not be convex (or concave). However, its logarithm may still be. This is termed log-convexity (log-concavity). Determining log-convexity (log-concavity) allows us to exploit the same convex optimization procedures. $\underline{\mathrm{Question}}$ I want to know if the idea of log-convexity can be extended further. In particular, can we describe a function as being log-log-convex (log-log-concave) ? By log-log-convex (log-log-concave) I mean that if the logarithm of a function is plotted on a set of axes in which the abscissa has been expressed using a logarithmic scale, convexity (concavity) is observed. Said in a different way, if we plot a function on a set of axes where both the ordinate and abscissa have been expressed using a logarithmic scale, convexity (concavity) is observed.","['convex-analysis', 'convex-optimization', 'functional-analysis']"
897278,Gallai & Milgram path covers theorem from Diestel,"I have a question about the theorem of Gallai and Milgram stating that every directed graph $G$ has a path cover $P$ such that one can make an independent set of $G$ by picking vertices from each of the paths of $P$. (A path cover means a set of paths of $G$ such that each vertex of $G$ belongs to exactly one of these paths.) More specifically I have a question related to the proof one can find in Diestel's graph theory book. The relevant part is pasted here for convenience. I am having some trouble understanding the inductive step. The idea is to use induction to show that the path cover that minimizes the set of terminal vertices $\rm{ter}(\mathcal{P})$ will do the trick. If this is not the case, then one creates the graph $G'$ by removing from $G$ one specific vertex $v \in \rm{ter}(\mathcal{P})$ The idea is then that the path cover $\mathcal{P'}$ obtained by removing the end-vertex $v$ has a minimal set of terminal vertices among path covers of $G'.$ And here is where I get confused since it is assumed that if $\mathcal{P'}$ is not a path cover with minimal $\rm{ter}(P')$ then there is a path cover $\mathcal{P''}$ such that $\rm{ter}(\mathcal{P''}) \subset \rm{ter}(\mathcal{P'}).$ Why is this so? Can't it be that the terminal vertices of a ""minimall"" path cover in $G'$ is not a subset of $\rm{ter}(P')?$","['graph-theory', 'combinatorics']"
897290,"For a Hilbert space $\mathcal{H}$, is every bounded linear operator on $\mathcal{H}$ a linear combination of unitary operators?","Let $(\mathcal{H}, (\cdot, \cdot))$ be a Hilbert space, and let $B \in \mathcal{B}(H)$ be a bounded linear operator on $H$ . If $\mathcal{H}$ is a complex Hilbert space, then $B$ can be written as a linear combination of unitary operators. How do we do this? First, we write $B$ as a linear combination of self-adjoint operators: $$B = \frac{1}{2}(B + B^*) - \frac{i}{2}(iB - iB^*)$$ So so it suffices to show that any self adjoint operator $A \in \mathcal{B}(H)$ is a linear combination of unitary operators. Even more, it is no problem to assume the operator norm $\|A\| \le 1$ . Then, a short computation shows that $(A \pm i\sqrt{I - A^2})$ is unitary, and furthermore we have: $$A = \frac{1}{2}(A + i\sqrt{I - A^2}) + \frac{1}{2}(A - i\sqrt{I - A^2}).$$ Note that, because $\|A\| \le 1$ , it's easy to see that $I-A^2$ is a positive operator, hence it has a well-defined square root. My concern is, can we still write $B$ as a combination of unitary operators, even if $\mathcal{H}$ is just a real Hilbert space? In the real case, we do not have the complex number $i$ to work with, and it seems to be crucial in the above argument. Hints or solutions are greatly appreciated.","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
897294,A field extension of prime degree,"Suppose that $E$ is an extension of $F$ of prime degree. Show that $~~\forall~ a \in E : ~ F(a)=F$ or $F(a)=E$ Attempt : Suppose that $E$ is an extension of a field $F$ of prime degree, $p$. Therefore $p = [E :F] = [E : F(a)][F(a) : F]$. Since $p$ is a prime number, we see that either $[E : F(a)] = 1$ or $[F(a) : F] = 1$. Now, $[E : F(a)] = 1 \implies $ there is only one element $x \in E$ which forms a basis and every element in $E$ is generated by $x$ i.e. $E = \{x~c~|~ c \in F(a)\}$ $[F(a) : F] = 1 \implies $ there is only one element $y \in F(a)$ which forms a basis and every element in $F(a)$ is generated by $y$ i.e. $F(a) = \{y~d~|~ d \in F\}$ Have I inferred it correctly? How do I move ahead? Thank you for your help.","['ring-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
897299,Initial-value problem for non-linear partial differential equation $y_x^2=k/y_t^2-1$,"For this problem, $y$ is a function of two variables: one space variable $x$ and one time variable $t$. $k > 0$ is some constant. And $x$ takes is value in the interval $[0, 1]$ and $t \ge 0$. At the initial time, $y$ follows a parabolic profile , like $y(x, 0) = 1 - (x-\frac{1 }{2})^2$. Finally, $y$ satisfies this PDE:
$$ \left(\frac{\partial y} {\partial x}\right)^2  = \frac{k}{\left(\frac{\partial y} {\partial t}\right)^2} - 1.$$ Does anyone have an idea how to solve this problem (and find the expression of $y(x,t)$) ? About: The problem arise in physics, when studying the temporal shift of a front of iron particles in a magnetic field. Edit: I solved it numerically on a (badly-designed) 1st-order numerical scheme with a small space & time discretization, with the initial condition I wanted ( in Octave/Matlab , in Python and in OCaml + GNUplot ). The numerical result was enough to confirm the theory and the experiment (the observation done in the lab), so I did not try any further to solve it analytically. See here for an animation of the front of iron matter, and here for more details (in French) .","['ordinary-differential-equations', 'partial-differential-equations']"
897303,Property that defines Quadric Surface,"The book < Geometry and the Imagination >  (written by David Hilbert) introduces a property of a Quadric Surface  without a proof. Property : The cone consisting of all the tangents from a fixed point to a quadric cuts every plane in a conic, and the points of contact of this cone with the surface form a conic. Moreover, the quadrics are the only surfaces having any of these properties. It was easy to prove the property itself, but i found it difficult to prove that it is a sufficient condition for a surface to be a quadric. (the statement starting with ""Moreover, ..."") I would like to know the proof of this statement.","['algebraic-geometry', 'quadrics', 'surfaces']"
897313,Multiplicity and regular sequences,"We define multiplicity of a module $M$ of dimension $d>0$ as $$e(M) := \operatorname{lc} (P_M) (d-1)!,$$ where $P_M$ denotes the Hilbert polynomial of $M$ and $\operatorname{lc}(P_M)$ its leading coefficient. Equivalently, we have $e(M) = Q_M(1)$, where $HP_M (z) = \frac{Q_M(z)}{(1-z)^d}$ and $HP_M$ is the Hilbert-Poincaré series of $M$. I can prove that if $I = (f_1, \dots, f_r)$, with $\deg(f_i)=d_i$ and $f_1, \dots, f_r$ is an $M$-regular sequence, then $$e(M/IM) = d_1 \cdots d_r \cdot e(M)$$ Consider now $R= \mathbb{k}[x_1, \dots, x_n]$, $I = (f_1, \dots, f_r)$, with $\deg(f_i)=d_i \geq 2$ and $f_i$ homogeneous. Does it holds the reverse implication, i.e. 
  $$ e(R/I) = d_1 \cdots d_r \quad \Rightarrow \quad f_1,\dots,f_r \quad \text{is a $R$-regular sequence?}$$","['commutative-algebra', 'ideals', 'algebraic-geometry', 'graded-modules']"
897318,Prove that the multiplicative inverse of $a$ modulo $m$ exists if and only if $a$ and $m$ are coprime. [duplicate],"This question already has answers here : If $q$ is coprime to $a$ then $a\mid nq-1,\,$ so $q$ is invertible mod $a$ (3 answers) Closed 3 hours ago . Prove that the multiplicative inverse of $a$ modulo $m$ exists if and only if $a$ and $m$ are coprime. Can someone help me with this?",['abstract-algebra']
897433,Lower bounds on eigenvalues of a symmetric matrix based on the diagonals,"A symmetric matrix $A$ always has real eigenvalues. If I know the elements on the diagonals, is it possible to have a lower bound on the smallest eigenvalue? How sharp would this bound be? For now I only found a paper of Hemy WoIkowicz and George P. H. Styan titled as ""Bounds for Elgenvalues Using Traces"", however, their bounds require the trace of $A^2$ which needs the other entries. Is there any other bounds or references on this topic? p.s. I cannot assume that $A$ is positive-definite coz I know that the smallest eigenvalue is $0$ indeed.","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
897460,Solution of differential equations with discontinuity,"Suppose that we have scalar differential equation \begin{equation}
\dot{x}(t)=u(t)
\end{equation} Here $u(t)$ is a piecewise constant function with discontinuity. If the points of discontinuity is infinitely many, how would it affect the solution of the ordinary differential equation above?","['ordinary-differential-equations', 'continuity', 'analysis']"
897466,Logarithm Expansion Question,"How do you expand the following logarithm:
$$ \log_5 \left(\frac{u}{v^3}\right)^6 $$ The result I got was:
$$ 6\log_5u -18\log_5v $$ Is that fully expanded?",['algebra-precalculus']
897469,Determinant of a matrix with $t$ in all off-diagonal entries.,"It seems from playing around with small values of $n$ that $$
\det \left( \begin{array}{ccccc}
-1 & t & t & \dots & t\\
t & -1 & t & \dots & t\\
t & t & -1 & \dots & t\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
t  & t & t & \dots& -1
\end{array}\right) = (-1)^{n-1}(t+1)^{n-1}((n-1)t-1)
$$ where $n$ is the size of the matrix. How would one approach deriving (or at least proving) this formally? Motivation This came up when someone asked what is the general solution to: $$\frac{a}{b+c}=\frac{b}{c+a}=\frac{c}{a+b},$$ and for non-trivial solutions, the matrix above (with $n=3$) must be singular. In this case either $t=-1\implies a+b+c=1$ or $t=\frac{1}{2}\implies a=b=c$. So I wanted to ensure that these are also the only solutions for the case with more variables.","['matrices', 'linear-algebra', 'determinant', 'polynomials']"
897495,Let $K$ be a field extension of $F$ and let $a \in K$. Show that $[F(a):F(a^3)] \leq 3$,"Let $K$ be a field extension of $F$ and let $a \in K$. Show that $[F(a):F(a^3)] \leq 3$. Find examples to illustrate that $[F(a):F(a^3)]$ can be $1,2$ or $3$. Attempt: $F \subset F(a^3) \subseteq F(a)$ The minimal polynomial for $a^3$ over $F$ is $ x-a^3=0$ I, unfortunately, don't have much idea than this on this problem. Could you please tell me how to move ahead? Let $K$ be an extension of $F$. Suppose that $E_1$ and $E_2$ are contained in $K$ and are extensions of $F$. If $[E_1:F]$ and $[E_2:F]$ are both prime, show that $E_1 = E_2$ or $E_1 \bigcap E_2 = F $ Attempt: $[K:F] = [K:E_1][E_1:F] = [K:E_2][E_2:F]$ Since, $[E_1:F]$ and $[E_2:F]$ are both prime $\implies [E_2:F]$ divides $[K:E_1]$ and $[E_1:F]$ divides $[K:E_2]$ How do i move ahead? Thank you for your help.","['ring-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
897496,"Meaning of notation $\operatorname{ord}_Q(g)$ in ""Algebraic Curves"" by Fulton",I didn't understand this notation in the chapter 7 page 93 of Fulton's algebraic curves book : What the author means by $\text{ord}_Q(g)$? Maybe he would like to say $\text{ord}_Q(G) := \text{ord}_P(g)$? I need help Thanks in advance,"['notation', 'algebraic-geometry', 'algebraic-curves', 'abstract-algebra']"
897524,Is the Least Integer Principle an axiom?,"I'm really sorry if this question has been asked before, I looked but couldn't find anything. I'm going through an elementary number theory book and in the first chapter it introduces the least integer principle. There is no proof accompanied with it, it just states: ""a nonempty set of integers that is bounded below contains a smallest element."" Is the reason the book doesn't give a proof because we take this as an axiom? Or is the proof so trivial that it need not be written? Thanks!",['elementary-set-theory']
897548,Verifying an antiderivative found in any integral table,"If $a > 0$, and $0 < b < c$.
\begin{equation*}
\int \frac{1}{b + c\sin(ax)} \, {\mathit dx}
= \frac{-1}{a\sqrt{c^{2} - b^{2}}} \, \ln\left\vert\frac{c + b\sin(ax) + \sqrt{c^{2} - b^{2}}\cos(ax)}{b + c\sin(ax)}\right\vert .
\end{equation*}
(This is the antiderivative given in any calculus book.) With calculations that I made, I showed that
\begin{align*}
\int \frac{1}{b + c\sin(ax)} \, {\mathit dx}
&= \frac{-1}{a\sqrt{c^{2} - b^{2}}}
\ln \left\vert
\frac{
\ \
\dfrac{c - \sqrt{c^{2} - b^{2}}}{b} \, \sin(ax) + 1 + \cos(ax)
\ \
}
{
\dfrac{c + \sqrt{c^{2} - b^{2}}}{b} \, \sin(ax) + 1 + \cos(ax)
}
\right\vert
,
\end{align*}
and since the sum of an antiderivative of $1/[b + c\sin(ax)]$ and a constant is another antiderivate of $1/[b + c\sin(ax)]$, and since
\begin{equation*}
\dfrac{c - \sqrt{c^{2} - b^{2}}}{b}
\qquad \text{and} \qquad
\dfrac{c + \sqrt{c^{2} - b^{2}}}{b}
\end{equation*}
are reciprocals of each other,
\begin{align*}
&\int \frac{1}{b + c\sin(ax)} \, {\mathit dx} \\
&\qquad \qquad = \frac{-1}{a\sqrt{c^{2} - b^{2}}}
\ln \left\vert
\frac{
\ \
\dfrac{c - \sqrt{c^{2} - b^{2}}}{b} \, \sin(ax) + 1 + \cos(ax)
\ \
}
{
\dfrac{c + \sqrt{c^{2} - b^{2}}}{b} \, \sin(ax) + 1 + \cos(ax)
}
\right\vert \\
&\qquad \qquad \qquad\qquad - \frac{1}{a\sqrt{c^{2} - b^{2}}} \ln\left( \frac{c + \sqrt{c^{2} - b^{2}}}{b} \right) \\
&\qquad \qquad = \frac{-1}{a\sqrt{c^{2} - b^{2}}}
\ln \left\vert
\frac{
\ \
\sin(ax) + \dfrac{c + \sqrt{c^{2} - b^{2}}}{b} + \dfrac{c + \sqrt{c^{2} - b^{2}}}{b} \, \cos(ax)
\ \
}
{
\dfrac{c + \sqrt{c^{2} - b^{2}}}{b} \, \sin(ax) + 1 + \cos(ax)
}
\right\vert \\
&\qquad\qquad = \frac{-1}{a\sqrt{c^{2} - b^{2}}}
\ln \left\vert
\frac{
c + b\sin(ax) + \sqrt{c^{2} - b^{2}} \, \cos(ax) + \sqrt{c^{2} - b^{2}} + c \cos(ax)
}
{
b + c\sin(ax) + \sqrt{c^{2} - b^{2}} \, \sin(ax) + b\cos(ax)
}
\right\vert .
\end{align*}
Furthermore, we have the following trigonometric identity:
\begin{align*}
&\frac{c + b\sin(ax) + \sqrt{c^{2} - b^{2}}\cos(ax)}{b + c\sin(ax)} \\
&\qquad\qquad =\frac{
c + b\sin(ax) + \sqrt{c^{2} - b^{2}} \, \cos(ax) + \sqrt{c^{2} - b^{2}} + c \cos(ax)
}
{
b + c\sin(ax) + \sqrt{c^{2} - b^{2}} \, \sin(ax) + b\cos(ax)
} .
\end{align*}
So, the antiderivative given in any calculus book is the same function as the second antiderivative that I obtained:
\begin{align*}
&\frac{-1}{a\sqrt{c^{2} - b^{2}}} \, \ln\left\vert\frac{c + b\sin(ax) + \sqrt{c^{2} - b^{2}}\cos(ax)}{b + c\sin(ax)}\right\vert \\
&\qquad = \frac{-1}{a\sqrt{c^{2} - b^{2}}}
\ln \left\vert
\frac{
c + b\sin(ax) + \sqrt{c^{2} - b^{2}} \, \cos(ax) + \sqrt{c^{2} - b^{2}} + c \cos(ax)
}
{
b + c\sin(ax) + \sqrt{c^{2} - b^{2}} \, \sin(ax) + b\cos(ax)
}
\right\vert .
\end{align*} Here are my questions.  Is it evident to anyone that the function on the right side of the trigonometric identity simplifies to the function on the left side? (It is surprising that the two sides are equal. The numerators and denominators on each side are ""almost"" the same: the numerator and denominator on the right side have two more terms than those on the left side.) If it is not evident, can someone give me calculations, starting from integration using the technique of trigonometric substitution, that show that the antiderivative of $1/[b + c\sin(ax)]$ is the function that is found in the integral tables of any calculus book - calculations that avoid all the algebraic manipulations?","['calculus', 'integration']"
897597,Finding the second derivative of an infinite series,"I'm asked to find the 2nd derivative of 
$$f(x)=-2x+\frac{2x^3}{3!}-\frac{2x^5}{5!}+\cdots+(-1)^{n+1}\frac{2x^{n+1}}{(2n+1)!}+\cdots=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n+1}2x^{2n+1} }{(2n+1)!}$$ Applying the power rule to $f(x)$, I find I can simplify the coefficient, since $\frac{(2n+1)(2n)}{(2n-1)!}=\frac{1}{(2n-1)!}$. Also, because the first term of $f''(x)$ is positive, the $(-1)^{n+1}$ changes to $(-1)^{n}$, which leaves me with: $$f''(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^n2x^{2n-1} }{(2n-1)!}$$ However, the answer given on the homework solution is $\sum \limits_{n=0}^\infty \frac{(-1)^n2x^{2n+1} }{(2n+1)!}$. I don't see how I can get from my answer to the given solution.","['sequences-and-series', 'calculus', 'derivatives']"
897608,$x$-intercept of cosine graph,"I am having problems understanding how to find the $x$-intercept of a cosine graph. Example:
$10\cos(x/2)$ Answer:$((2n + 1)\pi , 0 )$ I have the answer just need help understanding the steps, thanks","['trigonometry', 'algebra-precalculus']"
897633,Exact interpretration of p-value and significance of test,"First question: Let's say we have a hypothesis test: ${ H }_{ 0 }:u=100$
and ${ H }_{ 1 }:u\neq 100$. The sample has a size of 10 and gives an average $u=103$ and a p-value = 0.08.
The level of significance is 0.05. I'm asked the following question (exam): A) We can conclude that $u=100$ B) We cannot conclude that $u\neq100$ The 2 answers are rather similar, but not the same. I would say B) but I'm not so sure given what I've read. The p-value here indicates that we cannot reject the null hypothesis, so we cannot accept H1 ? Second question: What does it mean exactly that a test is significant ? Does it mean that we can reject the null hypothesis ? Thanks in advance. Regards,",['statistics']
897647,Mutually commuting matrices,"Let $A_{1},..., A_{m}$ be $n \times n$ matrices with entries in a field $K$ such that $A_{i}A_{j} = A_{j}A_{i}$ for all $ 1 \leq i, j \leq n$ and the product $A_{1}A_{2} ... A_{m} = 0$ is the zero matrix. Prove that there are $h \leq n$ distinct indices $i_{1}, ..., i_{h}$ such that $A_{i_{1}} ... A_{i_{h}} = 0$. I showed, by inducting on $m$, that the matrices in question have a set of common eigenvectors, say $B$ and not necessarily same eigenvalues. Then on $B$, we see that some eigenvalues have to be zeros. From here, I can use a hint. Someone mentioned a hint: reduce the rank to zero, which did not get me very far [sorry to you, I posted this problem in math overflow, which was not appropriate for a mere linear algebra qual prep problems and so I moved it here].","['matrices', 'linear-algebra']"
897650,"Show that each integer of the form $a^2+b^2$ has all the factors of this form, where $(a, b)$ are distinct integers and relatively prime","Show that each integer of the form $a^2+b^2$ has all the factors of this form, where $(a, b)$ are distinct integers and relatively prime Progress If $a^2+b^2$ is prime then it is already proved, since every prime is a factor of its self and $1=0^2+1^2$ , but I don't know how to prove for the rest of the case. Thanks!","['elementary-number-theory', 'divisibility', 'abstract-algebra']"
897653,Intuition for the compactness of real projective space $\mathbb{R}\mathbb{P}^n$.,"I want to have an intuition for why the $n$-dimensional real projective space defined as $$\mathbb{R}\mathbb{P}^n:=\mbox{set of 1-dimensional subspaces of }\mathbb{R}^{n+1}$$ is compact. I don't see how it is bounded since the subspaces can ""extend"" to as much as I want. But I know the proof: Define a relation on $\mathbb{R}^{n+1}\setminus\{0\}$ via $x\sim y \Leftrightarrow \ x=\lambda y, \ \lambda\in \mathbb{R}\setminus\{0\}.$ Then, w.r.t. this equivalence relation, $$\mathbb{R}^{n+1}\setminus\{0\}/\sim \ \equiv \mathbb{R}\mathbb{P}^n.$$   There is a homeomorphism from $\mathbb{R}\mathbb{P}^n \mbox{ to } \mathbb{S}^n/\sim$ where $x\sim -x, \forall x\in \mathbb{S}^n$. It is $$f:\mathbb{R}\mathbb{P}^n \to \mathbb{S}^n/\sim, \ [x]\mapsto \bigg[\frac{x}{||x||}\bigg].$$ The compactness of $\mathbb{R}\mathbb{P}^n$ follows from $\mathbb{S}^n/\sim$ being compact. To repeat: My question is about having an intuition. I cannot see how $\mathbb{R}\mathbb{P}^n$ is bounded. Perhaps, you should give me the precise set that will contain $\mathbb{R}\mathbb{P}^n.$","['general-topology', 'intuition', 'differential-geometry', 'smooth-manifolds']"
897660,Extending Homomorphism into Algebraically Closed Field,"If we are given a homomorphism $g$ between a field $k$ and an algebraically closed field $\Omega$, and a field $k'$ which is a finite algebraic extension of $k$, how do we extend $g$ to a homomorphism $g'$ from $k'$ to $\Omega$?","['abstract-algebra', 'field-theory']"
897665,Logarithm Equality,"$$\sqrt{\log_x\left(\sqrt{3x}\right)} \cdot \log_3 x = -1$$ I am not entirely sure how to go about solving for $x$. I cannot square each side because the product isn't $≥ 0$, I can't think of any more approaches right now.","['logarithms', 'algebra-precalculus']"
897693,What is the purpose of studying Sturm-Louville eigenvalue problem?,"After a cursory read on the SL eigenvalue problem, I did not immediately feel enlightened and failed find much usefulness except for knowing that SL generalizes a broader class of differential equations. Firstly, knowing a DE is Sturm-Louville system doesn't automatically produce a solution. Also, it does not give you the form of the eigenvalues. I would think these are the most important aspect of studying DE. What is done however, is to first solve the DE and then recognize it is a SL DE and hence satisfies a bunch of useful properties such as minimum eigenvalue, etc. But even knowing all this, I have not been able to solve DE faster knowing that it is a SL DE or it satisfies a myriad of properties. Why do we characterize an ODE as SL problem at all?","['eigenfunctions', 'ordinary-differential-equations', 'eigenvalues-eigenvectors', 'partial-differential-equations']"
897716,Show there exists a value such that each partial sum equals its limit in modulus,"For each $n \in \mathbb{N}_0$ , and for all $z \in \mathbb{C}$ , define $$p_n(z) := \sum^{n}_{k=0} {z^k \over {k!}}.$$ Show that for all $r > 0$ and for all $n \in \mathbb{N}_0$ , there exists $z \in \mathbb{C}$ with $|z|=r$ such that $|p_n(z)| = |e^z|$ . There is a first part to this problem that asks one to show that for all $r > 0$ , there exists $N \in \mathbb{N}$ such that for all $n > N$ , $p_n$ has no zeros in $B(0,r)$ .  This follows pretty immediately from $e^z$ being the limit of $p_n$ and Hurwitz's Theorem.  So far, I haven't found this useful. I'm also curious as to what the assignment $z(n;r)$ looks like, and if it's a function.  I know $z(0;r) = ir$ thus far, and these also appear to be the only solutions for $n=0$ . Edit: tag for Bessel functions added since one of the answers makes an interesting use of them for a more technical approach to this problem.","['bessel-functions', 'complex-analysis']"
897720,Finding equation of an ellipsoid,"Consider I have an ellipsoid (let say an egg) lies in a general form in 3D space. Suppose, I have the equations of two projected views of this egg (e.g. one projected view on x-y plane and another one on y-z plane and naturally, each projected view would be an ellipse with an equation like: $ax^2+bxy+cy^2+dx+ey+f=0$).
Please be advised that since the egg has been placed in space in a general form, none of the axes of the ellipsoid has necessarily the same length as the corresponding axis in its projected view.
When I suppose the ellipsoid center to be at the Origin, its equation would be: $$
\begin{pmatrix}x & y & z\end{pmatrix}
\begin{pmatrix}
\alpha_1 & \beta_3 & \beta_2\\
\beta_3 & \alpha_2 & \beta_1\\
\beta_2 & \beta_1  & \alpha_3
\end{pmatrix}
\begin{pmatrix}x\\y\\z\end{pmatrix} = 1\tag{1}$$
If I write equations of two projected ellipses on xy and yz planes, after simplifying I can make a set of 6 Eqs. with 6 unknowns. However, I think that only 5 of them are independent and so they are not enough to derive the equation of ellipsoid and I need one more equation. What is your opinion?
(LHS values are known)
$$
\begin{cases}
X_1= \beta_1 - \frac{\beta_2\beta_3}{\alpha_1}\\
X_2= \alpha_2 - \frac{\beta_3^2}{\alpha_1}\\
X_3= \alpha_3 - \frac{\beta_2^2}{\alpha_1}\\
Z_1= \alpha_1 - \frac{\beta_2^2}{\alpha_3}\\
Z_2= \alpha_2 - \frac{\beta_1^2}{\alpha_3}\\
Z_3= \beta_3 - \frac{\beta_1\beta_2}{\alpha_3}\\
\end{cases}\tag{2}
$$","['analytic-geometry', 'geometry']"
897726,Understanding what the Sylow theorems say about $p$-groups,"I have a simple question. If we consider a group $G$ with order $p^k$ for a prime $p$. For example $125=5^3$. What we can obtain from sylows theorem? (I already understood it for the other cases, where we have something like $p^km$). Thanks.","['sylow-theory', 'group-theory', 'abstract-algebra']"
897735,Prove that $T^n$ is diagonalizable.,"Prove or give a counterexample: If $V$ is a complex vector space and $\text{dim V} = n$ and $T \in L(V)$, then $T^n$ is diagonalizable. In order to show that $T$ is diagonalizable I need to show that I have $n$ distinct eigenvalues. If I use the theorem that states that if $V$ is a complex vector space and $T \in L(V)$ then there is a basis consisting of the generalized eigenvectors of $T$, then is this sufficient, because I feel like this is more complicated than that? Any tips or help? Thank you!","['linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
897764,Characterize the natural numbers $n$ such that there is a surjective group homomorphism from $S_n$ to $S_{n-1}$.,"This has always been one of my most favorite exercises from Group Theory, and I was surprised to see that this hasn't been asked before. To repeat: Characterize the natural numbers $n$ such that there is a surjective group homomorphism from $S_n$ to $S_{n-1}$. I have a solution which I will post in a couple days (if someone doesn't recreate it), but I am more interested in seeing how other people would approach this problem. I am very interested in alternate proofs of this characterization.","['alternative-proof', 'symmetric-groups', 'group-theory', 'abstract-algebra']"
897775,Is $\mathbb{R}$ a subspace of $\mathbb{R}^2$?,"I think I've been confusing myself about the language of subspaces and so on.  This is a rather basic question, so please bare with me.  I'm wondering why we do not (or perhaps ""we"" do, and I just don't know about it) say that $\mathbb{ R } $ is a subspace of $\mathbb{ R }^2 $.  It's elementary to prove that the set
$$ S:= \left\{ c \cdot \mathbf{x} \mid c \in \mathbb{ R }, \mathbf{x} \in \mathbb{ R }^2  \right\}$$
is a vector subspace of $\mathbb{ R } ^2$.  What is confusing me is that there seems to be an isomorphism between the set $S$ and $\mathbb{ R } $:
\begin{align*}
\varphi: S &\rightarrow \mathbb{ R }   \\
 c \cdot \mathbf{x} &\mapsto c \\
\end{align*}
If this is indeed true, as I believe it is having checked that $\varphi$ gives an isomorphism, wouldn't we say that $\mathbb{ R } $ is a subspace of $\mathbb{ R } ^2$? Any help sorting out this (language) problem will be greatly appreciated!",['linear-algebra']
897792,Showing that $z^3 e^z = 1$ has infinitely many solutions,"On an old complex analysis prelim, I encountered the following problem. Show that the equation $z^3 e^z =1$ has infinitely many solutions. How many are real? Well many sources in complex analysis utilize Picard's Big Theorem to show that $e^z -z =0$ has infinitely many solutions. Picard's Big Theorem states that if an analytic function $f$ has an essential singularity at a point $w$, then on any punctured neighborhood of $w$, $f(z)$ takes on every possible complex value, with at most one exception, infinitely often. Clearly, $f(z) = e^z -z$ has an essential singularity at $\infty$. Thus, $f$ takes on every value infinitely many times with at most one exception, at most one value can be achieved finitely often, and that value could possibly be $0$. But we recall that the exponential function is $2 \pi i$-periodic and so $f(z+ 2 \pi i)= f(z)- 2 \pi i$. So now $f$ takes on at least one value in $\{0,2 \pi i\}$ infinitely often. Applying Picard's Big Theorem to both these cases, implies that $e^z -z =0$ has infinitely many solutions. Can Picard's Big Theorem also be used to show that $z^3 e^z =1$ has infinitely many solutions? We can rewrite this equation as $e^z - z^{-3} =0$ so that we could let $f(z)= e^z - z^{-3}$ and see that it has an essential singularity at $\infty$, correct? If so, then I think that maybe Picard's Big Theorem might be OK here, though I'm not really sure. Now the second part of the problem is to find how many solutions are real; there is a hint (hardly expected on a prelim) that suggests using the Argument Principle. I'm familiar with how to find the number of zeros in a particular quadrant/half plane of a complex polynomial of finite degree through use of the Argument Principle, but don't know how to apply it here. I'd appreciate any help I can get.",['complex-analysis']
897810,Motivation and intuition of double cosets,"In Dummit and Foote, there was a problem on double cosets. Let $H$ and $K$ be subgroups of $G$ and $x\in G$, $HxK$ is the double coset of $x$. I can prove the double cosets partitions $G$. However, I could not see any intuition or motivation of this gear. I can understand it as a mapping $H:\frac{G}{K}\to gK$ or $K:Hx\to Hy$ where $y$ may be different from $x$. Is there anything deep for this motivation other than the mapping itself?","['finite-groups', 'group-theory', 'abstract-algebra']"
897822,Can anyone recommend an easy to read algebraic number theory book?,"Can anyone recommend an easy to read algebraic number theory book? I prefer a book with good examples. (Hints or answers to selected questions, if possible. Not sure if it is possible for a book of this topic.)","['book-recommendation', 'number-theory', 'analytic-number-theory', 'algebraic-number-theory', 'reference-request']"
897823,Prove that the gradient transforms as a vector under rotations,"I have not been able to make the following problem: Consider that $f$ is a function of only two variables, $y$ and $z$. Show that the gradient: $$\nabla f=\left(\frac{\partial f}{\partial y}\right)\hat{e_{y}}+\left(\frac{\partial f}{\partial z}\right)\hat{e_{z}}$$ transforms as a vector under rotations. My idea is to use relationships: $$\bar{y}=y\cos\phi+z\sin\phi$$
$$\bar{z}=-y\sin\phi+z\cos\phi$$ Solving this system of equations for $y$ and $z$, and determining the derivative: $\partial y/\partial \bar{y}$, $\partial z/\partial \bar{y}$, $\partial y/\partial \bar{z}$ y $\partial z/\partial \bar{y}$. I can perform these steps without any problem, but then I do not know what to do. If anyone could help me I would appreciate it too.","['multivariable-calculus', 'calculus']"
897831,"Minimum number of attempts to guess a PIN code, given constraints","I'm playing a video game at the moment called Sleeping Dogs, in which some of the mini-missions are to 'hack' a security camera, by guessing a four-digit PIN code. Here are the rules: 1) You are allowed 6 attempts to enter a four-digit PIN code. After 6 attempts, the PIN code resets to a random (other) one. 2) Repeated digits are not allowed (e.g. $9981, 1131, 5555,$ etc. are not allowed). 3) 
If the correct digit is in the correct place, that digit will be green. If the correct digit (i.e. a digit that is in the actual PIN) is in the incorrect place, that digit will be amber. If an incorrect digit is entered (i.e. a digit that is not in the actual PIN), that digit will be red. e.g. Suppose that the actual code is $\boxed{1234}.$ If I entered $1427$, it would show up as $$\color{green}1\color{orange}4\color{orange}2\color{red}7.$$ My question is this: What is the minimum number of attempts in order to guarantee entry to the system, (can it be achieved with certainty in fewer than six attempts)? There seem to be so many factors that I can't come up with a quick solution. Any hints/tips would be welcome. (Background info-- I'm familiar with elementary probability and statistics).","['statistics', 'probability']"
897840,Show that the trace class operators on a Hilbert space form an ideal,"Let $(H, (\cdot, \cdot))$ be a separable Hilbert space over $\mathbb{L} = \mathbb{R}$ or $\mathbb{C}$. Suppose that $\{\phi_n\}_{n=1}^\infty$ is an orthonormal basis for $H$. Let $\mathcal{B}(H)$ denote the bounded linear operators $H \to H$. For $A \in \mathcal{B}(H)$, let $|A|$ denote the positive, self-adjoint square root of $A^*A$. We say that that $A \in \mathcal{B}(H)$ is of trace class if and only if $$\sum_{n=1}^\infty (\phi_n, |A|\phi_n) < \infty.$$ Let $\mathscr{I}_1(H)$ denote the trace class on $H$. For $A \in \mathscr{I}_1(H)$, set $\operatorname{Tr}(A) = \sum_{n=1}^\infty (\phi_n, |A|\phi_n).$ I would like to prove that the trace class operators on $H$ form a two sided ideal. That is, I would like to show that, if $A \in \mathscr{I}_1(H)$ and $B \in \mathcal{B}(H)$, then $AB, BA \in \mathscr{I}_1(H).$ I am studying trace class operators from Reed and Simon's Method's of Modern Mathematical Physics, Vol.1 , and this proposition above is stated in the text. Some things that I know from my studies so far: For $A \in \mathscr{I}_1(H)$, $\operatorname{Tr}(A)$ is independent of the orthonormal basis $\{\phi_n\}_{n=1}^\infty$ that we choose for $H$. $\mathscr{I}_1(H)$ is vector subspace of $\mathcal{B}(H).$ If $A \in \mathscr{I}_1(H)$ and if $U \in \mathcal{B}(H)$ is unitary (i.e., if $\operatorname{Ran}U = H$ and $(Ux,Uy) = (x,y)$, all $x,y \in H$), then $UAU^{-1} \in  \mathscr{I}_1(H)$. I am hoping that I can prove that  $\mathscr{I}_1(H)$ is an ideal without using too much more that (1)-(3), and perhaps some calculations. I do know some basics about adjoints and compact operators, and I am familiar with the construction of the polar decomposition for elements in  $\mathcal{B}(H)$. Although I am not sure if any of these topics are relevant. I am not familiar with the spectral theorem or the continuous functional calculus (I have yet to reach that chapter in Reed and Simon). In fact, Reed and Simon offer a proof that $\mathscr{I}_1(H)$ forms an ideal, and their proof goes in two stages: a) First, they prove that every $B \in \mathcal{B}(H)$ can be written as a linear combination of four unitary operators. b) Then, they prove that, if $A \in \mathscr{I}_1(H)$  and $U$ is unitary, then $UA, AU \in \mathscr{I}_1(H)$. Using a) and b), we can conclude that  $\mathscr{I}_1(H)$ is a two-sided ideal, because it is already known that  $\mathscr{I}_1(H)$ is a vector space. The difficulty is, I do not understand the proofs that Reed and Simon give for a) and b). Based on this question I asked previoulsy, I am not even sure that a) is true in the case $\mathbb{L} = \mathbb{R}$. And in proving b), Reed and Simon claim that $|UA| = |A|$ and $|AU|= U^{-1}|A|U$, and I have had no luck proving these equalities either. Any solutions or hints are greatly appreciated, whether it be an explication of Reed and Simon's proof, or a brand new argument.  I have been stuck on this proposition for some time and I'd really like to get this figured out!","['trace', 'ideals', 'hilbert-spaces', 'functional-analysis']"
897852,Is this a proper subset?,"Let $A \cap C = \{1\}$ and $C = \{1,5\}$. Is it true that: $A \cap C = C$? For this to be true I know that they $A \cap C$ must be a subset of $C$ and $C$ must be a subset of $A \cap C$. So I found that $A \cap C$ is a subset of $C$ since $1$ belongs to $C$. But I wasn't sure if $C$ was a subset of $A \cap C$ since the former containes $5$?",['elementary-set-theory']
897857,Is there a book only about epsilon delta proofs?,"I want to know if there is such book, with beautiful epsilon delta proofs of all kind.","['epsilon-delta', 'calculus', 'reference-request', 'real-analysis', 'complex-analysis']"
897876,A nonnegative random variable has zero expectation if and only if it is zero almost surely,"Let $Y$ be a non-negative random variable. Prove that $E(Y) = 0$ if and only if $P(Y=0)=1$ . My understanding is that while you can prove it for discrete $Y$ , the result is true for all $Y$ .","['probability-theory', 'measure-theory']"
897880,Hartshorne Exercise III 6.2 (a),"Let $X=\mathbb{P}^1_k$, with $k$ an infinite field. Show there does not exist a projective object $\mathcal{P}\to\mathcal{O}_X\to 0$. The author suggests to consider surjections of the form $j_!(O_{X}|_{V})\to k(x)\to 0$, where $x$ is a closed point, $V$ an open neighbourhood of $x$. We have maps $\mathcal{P}\to j_!(O_{X}|_{V})$ by lifting property, but how to use the conditions $\mathbb{P}^1_k$, with $k$ being infinite and $x$ being closed?","['sheaf-theory', 'algebraic-geometry']"
897896,Surgery presentations and gluing,"It is well known that every closed oriented 3dimensional manifold can be obtained from a framed link in $S^3$. Let $M$ and $N$ be topological 3-manifolds with boundary such that boundaries $\partial M$ and $\partial N$ are homeomorphic. Suppose those boundary are a surface with genus $g$. We fix a genus $g$ handlebody $H$ in $\mathbb{R}^3$. Let $f:\partial H \to \partial M$ and $g:\partial H \to \partial N$ be homeomorphisms (with a good choice of orientation preserving or reversing.) Now we make closed oriented 3-manifolds $M\cup_f H$ and $N\cup_g H$. By the Theorem I stated at the beginning, there are framed links $L_1$ and $L_2$ that represent $M\cup_f H$ and $N\cup_g H$ respectively. Next, we can construct another closed oriented 3-manifold $M\cup_{g^{-1}\circ f} N$. My question is;
 Is there any way to get a surgery link for $M\cup_{g^{-1}\circ f} N$ from $L_1$ and $L_2$?","['general-topology', 'surgery-theory', 'manifolds', 'algebraic-topology', 'differential-topology']"
