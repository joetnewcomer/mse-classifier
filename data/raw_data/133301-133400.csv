question_id,title,body,tags
2092605,Is it possible to calculate the area of a golygon?,"Silly question, how would one calculate the area of something like this? https://en.wikipedia.org/wiki/Golygon And not just the simple example they have in the picture. Is it any different from a normal polygon?","['area', 'geometry']"
2092611,How to prove that this set is countable?,"Suppose that $(S, \Sigma)$ is a measurable space and $\mu$ is a finite measure on $(S, \Sigma)$. Suppose that whenever $x \in S$, the singleton $\{x\}$ belongs to $\Sigma$. Prove that the set $\{x \in S : \mu(\{x\}) > 0 \}$ must be countable.",['measure-theory']
2092649,Compute ${11 \choose 1} + {11 \choose 3} + ... + {11 \choose 11}$?,"I did this with brute force, and got 1024. What is the faster method of solving this?","['combinatorics', 'arithmetic']"
2092682,What is the meaning of the last part of the proof of this theorem?,"I am trying to understand the last part of the proof of this theorem but I am really confused as to what the author has done. I have an exam in a couple of days and I don't like memorising things without understanding them but just got lost between the meanings of $y_m, y_{1,m}, y_{2,m}, \beta^{(m)}_{1}$ and $\beta^{(m)}_{2}$. Thanks. Any help is appreciated.","['functional-analysis', 'sequences-and-series', 'convergence-divergence']"
2092688,Dropping a Lowest Score,"I have a lab class, where I drop the lowest score students receive, easy enough. Except, all items are not weighted equally,  (lab A might be worth 10 points, while lab B might be worth 23 points, and so on). Right now, what I do in an excel file is calculate the total points earned and the maximum points, except in each instance I remove a different assignment from the calculation. Then compare the various percentages and drop the one that yields the highest overall percentage. TL;DR, here is the main question part ;) Is this a problem that can be solved more easily, or can I answer the question of which to drop with a formula? I'd love to include the calculation in my grade book so it happens automatically. Right now, I have to go in and drop an assignment manually for each student, since my only option is to drop ""lowest score"" which doesn't work since 5/10 has a different impact than 3/30. (I realize I could scale everything and make them all worth the same amount, but that complicates other parts of the grade for me, so isn't ideal) I've included a screen shot of what I do in excel for hopeful clarity. The bottom three rows are what I look at. Total Score w/o: Total earned points (from row 2) without the lab corresponding to that column Total Max w/o: Total maximum points possible (from row 3) without the lab corresponding to that column Combined Percent w/o: Just the values from $\displaystyle\frac{\text{Total Score w/o}}{\text{Max Score w/o}}$ for each column. I have conditional highlighting which shows me the highest percentage, so in this case, I would drop the student ""Hydrate"" lab assignment from their grade. *Note: I will confess I really wasn't sure what tags I should use. This stackexchange is way out of my comfort zone, so most terms were not familiar. Feel free to change them to whatever is most appropriate.",['statistics']
2092723,What is $P$ of either Heads or Tails having a lead $\geq 10$ at some point during game of $300$ flips?,"Question refers to $P$ of getting lead of at least $10$ at any point during a game, with game lasting only $300$ flips. I tried to apply the formula given in an answer to a similar question here $P(X_n≥ (n+10/2))$ but that works out to summing $300 + 10$, and dividing by $2$ which = $155$. Following from that previous answer, it would seem that the $P$ of a lead of $10$ or greater at some point in a $300$ flip Game would be only $.155$ ...and that does not fit with the results when
I simply use a simulator to repeatedly sample games of $300$ flips and count the times that a lead of at least 10 appears. Is there something wrong in the way I am applying this formula? or is wrong for the question I am asking?",['probability']
2092732,How to prove that $\gamma'(n+1)\gamma(n+1)$ is incremental,"Not so long before I asked this question, I encountered a question that asked me to prove a proposition, but I'm not sure how to go about it. Prove that $\gamma'(n+1)\gamma(n+1)$ is incremental",['analysis']
2092754,Calculate $\int_{0}^{\infty }e^{-x^{2}-x^{-2}}dx$,"How to calculate 
$$\int_{0}^{\infty }e^{-x^{2}-x^{-2}}dx$$
I have no idea where to start.Is it connect with the euler-poisson integral?",['integration']
2092764,Explain a mapping?,"Let $Z = \{(a, b) : a \ge 0 \text{ and } b = 0, \text{ or } a = 0 \text{ and } b \ge 0\}$. Find a $C^\infty$ smooth function $\phi : \mathbb{R} \to \mathbb{R^2}$ which is $1$−$1$ and onto $Z$. Q) Can someone please explain what $\phi$ is? I think it's a tangent vector to my function evaluated with respect to or dependent on time?","['multivariable-calculus', 'real-analysis', 'ordinary-differential-equations']"
2092774,sufficient conditions for an operator on a Banach space to be a dual operator?,"If $X$ is a Banach space, we denote by $\mathcal{L}(X)$ the algebra of continuous linear operators acting on $X$.  Suppose $T\in\mathcal{L}(X^*)$, where $X^*$ is the dual space to $X$.  I am interested in conditions on $T$ to guarantee that it is a dual operator, i.e. so that there exists $S\in\mathcal{L}(X)$ with $S^*=T$. Clearly, if $X$ is reflexive then every $T\in\mathcal{L}(X^*)$ is a dual operator.  So we can assume $X$ is nonreflexive. It is well-known that $T$ is a dual operator if and only if it is weak*-to-weak* continuous.  However, this is not always easy to check, so I am interested in ""nicer"" sufficient conditions for $T$ to be a dual operator.  One question that immediately comes to mind is this: Question 1. Suppose $T\in\mathcal{L}(X^*)$ is compact.  Is it necessarily a dual operator? ( UPDATE :  The answer to Q1 is obviously not; see comments below.) I am especially interested in the case where $X=c_0$ and hence $X^*=\ell_1$. So: Question 2. What are some ""nice"" sufficient conditions to guarantee that $T\in\mathcal{L}(\ell_1)$ is a dual operator? Actually, I only need $T$ to be a dual operator up to finite-rank perturbation.  So: Question 3. If $T\in\mathcal{L}(X^*)$, what are some ""nice"" sufficient conditions to guarantee that $T=S^*+F$ for some $S\in\mathcal{L}(X)$ and some finite-rank $F\in\mathcal{F}(X^*)$? Note: In the context I am working, I can assume that $X^{**}/X$ is infinite-dimensional and that $X^*$ is separable. Thanks guys!","['functional-analysis', 'banach-spaces', 'operator-theory']"
2092814,Prove $\sum_{k=1}^{\infty }\frac{\left ( -1 \right )^{k}}{k}\sum_{j=1}^{2k}\frac{\left ( -1 \right )^{j}}{j}=\frac{\pi ^{2}}{48}+\frac{1}{4}\ln^22$.,"How to prove the following series,
$$\sum_{k=1}^{\infty }\frac{\left ( -1 \right )^{k}}{k}\sum_{j=1}^{2k}\frac{\left ( -1 \right )^{j}}{j}=\frac{\pi ^{2}}{48}+\frac{1}{4}\ln^22$$
I know a formula which might be usful.
$$\sum_{j=1}^{n}\frac{\left ( -1 \right )^{j-1}}{j}=\ln 2+\left ( -1 \right )^{n-1}\int_{0}^{1}\frac{x^{n}}{1+x}\mathrm{d}x$$
any hint will be appreciate.","['integration', 'sequences-and-series', 'calculus', 'analysis']"
2092851,"Showing $e^A$ is positive definite, for any Hermitian matrix $A$","Show that $e^A$ is positive definite for any Hermitian Matrix $A\in M_{n\times n}(\mathbb{C})$. I'm not sure  that my argument is valid, but by following lemma it seems fine to me. I appreciate any correction and suggestion. Lemma: If $V$ is an inner product space finitely generated over $\mathbb{C}$. A nomral endomorphism of $\alpha$ is positive definite iff each of its eigenvalues is positive. Define $\alpha:v\to Av$ where $v\in \mathbb{C}^n$. Since $A$ is Hermitian, so $\alpha$ is normal, and it's orthogonality diagonalizable. Hence there exists an orthonormal basis $B=\{v_1,\dots,v_n\}$ for $\mathbb{C}^n$, composed of eigenvectors of $\alpha.$ Thus, $\phi_{BB}(\alpha)=[a_{ij}]$ is a diagonal matrix where each $a_{ii}$ is eigenvalue of $\alpha$ associated with the eigenvector $v_i$ for all $1\leq i \leq n$.  $A$ is similar to $\phi_{BB}(\alpha)$, so there exists a nonsingular matrix $P$ satisfying $A=P^{-1}\phi_{BB}(A)P$. Since $A$ is hermitian then $e^A$ is Hermitian, so it's normal, and by the properties of an exponential matrix, we can get $$e^A=P^{-1}\begin{bmatrix}
e^{a_{11}}&\dots& 0\\ 
\vdots&\ddots&\vdots\\ 0&\dots &e^{a_{nn}}
\end{bmatrix}P
$$
As, all of eigenvalues of $e^A$ is positive, hence it's positive definite.","['orthonormal', 'matrix-exponential', 'linear-algebra', 'inner-products']"
2092874,Feller Probability - putting r balls in n cells,"This is fundamental, but I think I should have it clarified. In the first chapter of Feller's Introduction to probability theory , the author writes I always thought that if we label the cells $1,2,3,\ldots,n$ and form $r$-tuples of the form $\{1,1,1\}$,$\{1,1,2\}$,...,$\{4,4,4\}$, there are $n^r=4^3=64$ sample points. Please correct me. Quasar.","['probability-theory', 'probability']"
2092879,Find probability that the sum of two dice is not 6 and not 5?,"When rolling two fair dice, what is P(sum of two dice is not 6 and not 5)? Calculation: 
First, I found the probability of two numbers that would roll a sum of 6: (1,5) (2,4) (3,3) (4,2) (5,1)  = 5/36 (each probability is 1/36) Then, I found the probability of two numbers that would roll a sum of 5: (1,4) (2,3) (3,2) (4,1) = 4/36 My first method was to add the probabilities and then subtract from one to give the probability of NOT rolling a sum of 6 or 5: (5/36) + (4/36) = 9/36 1 - 9/36 = 27/36 = 0.75 This turned out to be the accepted answer of my online homework. But then, I realized that the original question asked for P(not sum of 6 AND not sum of 5). So, I recalculated: 1 - 5/36 = 31/36 1 - 4/36 = 32/36 (31/36)(32/36) = 992/1296 ~ 0.7654 (using multiplication rule) When I entered this fraction in, it was incorrect. But since the questions asks for ""AND"" and not ""or"", wouldn't the second probability be the actual correct answer?","['statistics', 'probability', 'dice']"
2092904,Determinant composed from polynomials $p_1(x) = x + a$ and $p_2(x) = x^2 + bx + c$,"Let $p_1(x) = x + a$ and $p_2(x) = x^2 + bx + c$ be two polynomials with real
coefficients, and $x_1$ and $x_2$ be two arbitrary real numbers. Consider the
following determinant $$D(x) = \begin{vmatrix} 
  1     & p_1(x_1) & p_2(x_1)\\ 
  1 & p_1(x_2) & p_2(x_2)\\
1 & p_1(x) & p_2(x)\
\end{vmatrix}
$$ Show that $D(x) = m(x-x_1)(x-x_2)$","['matrices', 'polynomials', 'linear-algebra', 'determinant']"
2092941,Likelihood function & MLE without known values of observed data,"Question : Let $X_1,\dots,X_n$ be iid exponential rate $\lambda$. Suppose we don't know the observed values of our experiments, but we know that $k$ values were $\le M$ and the remaining $n-k$ were $>M$ for some constant $M$. Find the MLE of $\lambda$. I need to find the likelihood function $L(\lambda; \vec x) $, which is typically defined as $ \prod_{i=1}^n f(x_i;\lambda)$ for iid data. Now, I intuitively believe that the $L(\lambda; \vec x)$ will equal ${n \choose k} [P(X \le M)]^k [P(X > M)]^{n-k}$, but I'm not satisfied with my explanation why. The likelihood function is defined as $L(\theta) = f(x_1,\dots,x_n;\theta)$, where $\theta$ is allowed to vary. I don't know how to relate this definition in terms of the pdf to the fact that precisely $k$ observed values were $\le M$. Can someone help with a more rigorous explanation?","['statistics', 'statistical-inference']"
2092954,This function must be open if these points are isolated,"Let $U\subset \mathbb R^m$ be an open and $f:U\to \mathbb R^m$ be a function of class $C^1$. If the points where the determinant of the Jacobian Matrix of $f$ is zero are isolated ones and $m>1$, how do I prove this function must be open? I don't know even how to begin, I need some hints.","['general-topology', 'real-analysis', 'differential-topology']"
2092957,"Morphisms $X\to\text{Spec }A$ are in natural bijection with ring morphisms $A\to\Gamma(X,\mathscr O_X)$. [duplicate]","This question already has answers here : Prove that the natural map $\alpha : \text{Hom}(X,\text{Spec} A) \rightarrow \text{Hom}(A,\Gamma(X,\mathcal{O}_X))$ is an isomorphism (4 answers) Closed 5 years ago . $\newcommand{\Spec}{\operatorname{Spec}}$I'm working on the following problem from Vakil's notes: Show that (scheme) morphisms $X\to\Spec A$ are in natural bijection with ring morphisms $A\to\Gamma(X,\mathscr O_X)$. Of course, any map $X\to\Spec A$ induces a map of global sections $A\to\Gamma(X,\mathscr O_X)$. I am working out the other direction. It is certainly true if $X$ is affine, because affine scheme morphisms $\Spec B\to\Spec A$ are in bijection with ring maps $A\to B$. In the general case, we cover $X$ with affine open sets $\Spec B_i$. Then for each $i$ we get a map $$A\to\Gamma(X,\mathcal O_X)\overset{\text{res}}{\to}\Gamma(\Spec B_i,\mathcal O_X)=B_i$$ which in turn gives a map $\pi_i:\Spec B_i\to\Spec A$ (in particular, if we let $\pi_i^{\#}$ be the map $A\to B_i$, then the map is given by $\pi_i(p)=(\pi_i^{\#})^{-1}(p)$). How can I show that these glue correctly to give a morphism of schemes $\pi:X\to\Spec A$?","['schemes', 'algebraic-geometry']"
2092967,Help to Prove that $\int_{0}^{\pi\over 4}\arctan{(\cot^2{x})}\mathrm dx={2\pi^2-\ln^2({3+2\sqrt{2})}\over 16}$,"I need help on proving $(1)$.
$$I=\int_{0}^{\pi\over 4}\arctan{(\cot^2{x})}\mathrm dx={2\pi^2-\ln^2({3+2\sqrt{2})}\over 16}\tag1$$
This is what I have attempted; Enforcing a sub: $u=\cot^2{x}$ then $du=-2\cot{x}\csc^2{x}dx$ Recall $1+\cot^2{x}=\csc^2{x}$ $$I={1\over2}\int_{1}^{\infty}\arctan{u}\cdot{\mathrm dx\over u^{1/2}+u^{3/2}}$$ Recall $u^3+1=(u+1)(u^2-u+1)$ $$I={1\over2}\int_{1}^{\infty}\arctan{u}\left({A\over u^{1/2}}+{B\over u+1}+{Cu+D\over u^2-u+1}\right)\mathrm du$$ I am stuck at this point. Can anyone help to prove $(1)$?","['integration', 'definite-integrals']"
2092994,Which number is bigger than the others?,"Which number is bigger? $2^{431},3^{421},4^{321},21^{43},31^{42}$ My attempt : $4^{321}=2^{642}>2^{431},4^{321}=2^{642}>2^{640}=32^{128}>31^{42}$ $3^{421}>3^{420}=27^{140}>21^43$ But I don't know how to compare $4^{321}$ and $3^{421}$ Any hints?",['algebra-precalculus']
2093037,Probability - find the number of balls in a box,"There are $20\%$ less white than black balls in a box. Two balls are randomly chosen. If the probability that at least one chosen ball is white is $12/17$, how many black balls are in a box? If $w$ is the number of white balls, and $b$ is the number of black balls, then:
$$w=b-b/5=4b/5$$ Total number of balls in a box is $t=9w/4$ or $t=9b/5$. How can we find the total number of black balls after two are randomly chosen?",['probability']
2093052,Place the numbers by their size.,"Place the following numbers by their size: $$A=2^{4^{2^{.^{.^{.^{2^{4}}}}}}},B=4^{2^{4^{.^{.^{.{4^{2}}}}}}},C=2^{2^{2^{.^{.^{.^{2^{2}}}}}}}$$ In number $C$ there are $2000$ ""$2$"" digits, and in numbers $B,A$ there are $500$ ""$2$"" and $500$ ""$4$"" digits. It seems to me that $C>B>A$, but I can't give a proof. Any hints? Here is the same problem in art of problem solving. I hope that it helps.",['algebra-precalculus']
2093053,A coarser topology of the topology with 'compact set equals sequentially compact set',"I study about weak and weak* topology in functional analysis. By Eberlein-Smulian, every weakly compact set is weakly sequentially compact. How about weak* topology? I learned that $(B_{X^*},\omega^*)$($\omega^*$ means weak* topology.) is metrizable when $X$ is separable, so it is clearly true for $(B_{X^*},\omega^*)$, but I don't know the result for $(X^*,\omega^*)$. On the other hand, does this hold about general topology? i.e., if $(X,\tau_1)$ is a topological space that $\{K\subset X:K$ is compact$\}$=$\{K\subset X:K$ is sequentially compact$\}$ and $(X,\tau_2)$ is a coarser topology than $\tau_1$, does the same hold for $(X,\tau_2)$? I think it is false but cannot find examples.","['weak-convergence', 'general-topology', 'compactness']"
2093059,Expected properties for a PDE whose solution is supposed to be something that doesn't exist,"My understanding of Lecture #33, 34: The Characteristic Function for a Diffusion : As an alternative to directly computing the characteristic function of a random variable $X_t$ in a stochastic process $\{X_t\}_{t \in [0,T]}$, we can solve a (boundary?) value problem, whose PDE has parameters are given by the dynamics of the stochastic process, and then conclude by Feynman-Kac that it is the characteristic function of said random variable. An example is Arithmetic Brownian Motion: If we solve $$
\frac{\partial f}{\partial t} + \mu \frac{\partial f}{\partial x} + \frac{1}{2}\sigma^2 \frac{\partial^2 f}{\partial x^2} = 0, x \in \mathbb R, t \in [0,T]$$
$$f(T,x) = e^{i \theta x} \tag{1}$$ then we get a function $f(t,x)$ s.t. $f(0,x)$ is the characteristic function of $X_t$ where $$dX_t = \sigma dW_t + \mu dt$$ So what does this mean for the (boundary?) value problem $$
\frac{\partial f}{\partial t} + \mu x \frac{\partial f}{\partial x} + \frac{1}{2}\sigma^2 x^2\frac{\partial^2 f}{\partial x^2} = 0, x \in \mathbb R, t \in [0,T]$$
$$f(T,x) = e^{i \theta x} \tag{2}$$ ? My guess is that solution of $(2)$, $f(t,x)$, will be s.t. $f(0,x)$ is the characteristic function of $X_t$ where $$dX_t = \sigma X_t dW_t + \mu X_t dt$$ i.e. $X_t$ is Geometric Brownian Motion and hence is lognormal, the distribution of which doesn't have a characteristic function . So $(2)$ has no solution then? I'm looking for an answer like 'We don't expect $(2)$ to have a solution. This can be proven through (some PDE things).' or 'While we don't expect $(2)$ to have a solution, it actually does because (some PDE things), but then (some PDE things).' So the (some PDE things) may or may not prove lognormal distribution doesn't have a characteristic function, but I'm looking more for consistency e.g. because Lognormal doesn't have a characteristic function For any random variable, its characteristic function is supposed to be able to be computed by solving a PDE of Feynman-Kac said PDE must have no solution.","['stochastic-processes', 'partial-differential-equations', 'characteristic-functions', 'probability-theory', 'complex-analysis']"
2093122,How do I solve these trivial partial differential equations?,"In every book I have, these are solved like “we guessed this solution”, but I’m sure there is analytic way to solve them: $y\frac{\partial u}{\partial x} - x\frac{\partial u}{\partial y} = 0$ $(x + 2y)\frac{\partial z}{\partial x} - y \frac{\partial z}{\partial y} = 0$ There are more similar equations but I guess I just need to see at least one analytically solved.","['ordinary-differential-equations', 'partial-differential-equations']"
2093144,Polynomial solution of the equation $(1-x^2)y''-2xy'+6y=0$,"Let $y$ be a polynomial solution of the differential equation  $(1-x^2)y''-2xy'+6y=0$. If $y(1)=2$, then the value of the integral $\int_{-1}^{1}y^2dx$ is $\frac{1}{5}$ $\frac{2}{5}$ $\frac{4}{5}$ $\frac{8}{5}$ First of all I can solve it by conventional method, which is long and provided this is a competitive exam question, the maximum time I can give is $2-3$ mins. Is there is shortcut method or trick to solve this kind of problems? I tried to integrate the equation though but ended up with a term of $y(-1)$ which has no value given. How can I do this in less time? Any help would be great. Thanks.","['polynomials', 'ordinary-differential-equations', 'initial-value-problems', 'analysis']"
2093187,What will be the number of solutions for the givem differential equation?,"If $y''+(\sin(x^2))y' + ( \cos( x^3))y=0$ be a second order linear differential equation. If $y(1)=0 ;y'(1)=0$, then what is the number Of solutions. 
 What is the fundamental theorem of existence and uniqueness theorem . using that how do we solve this.?",['ordinary-differential-equations']
2093206,Definition of backwards martingales,"I'm not sure, if I understand the definition of backwards martingales. The definition I have says that it is a martingale $(X_n)_{n\in -\mathbb{N}}$ adapted to an increasing $\sigma$-Field $\mathcal{F}_n$. So does that mean that we have also negative indexes on the $\sigma$-Algebras: $\mathcal{F}_{-1}\subseteq \mathcal{F}_{-2}\subseteq \cdots \subseteq \mathcal{F}_{n}\quad n\in -\mathbb{N}$ And $\mathcal{F}_{n}=\sigma(X_{n})=\sigma(X_{-1},X_{-2}\dots,X_{n})$ So we only have changed the index $\mathbb{N}\to -\mathbb{N}$ but the real difference is that $\mathbb{E}(X_{n+1}\mid \mathcal{F}_{n})=X_{n}$ means for example
$\mathbb{E}(X_{-2}\mid \mathcal{F}_{-3})=X_{-3}$ Is this correct? If not, could someone make an example and writing indexes instead of abbreviations?","['stochastic-processes', 'probability-theory', 'martingales']"
2093271,Can dual vector spaces be thought of as linear coordinate functions?,"Note: This question seems like it might have been asked before, but the poster deleted it and I don't have enough reputation to see it. Let $V$ be a finite-dimensional real vector space. Such an object is, in a canonical way, a smooth manifold. Thus it makes sense to speak of smooth charts $(U,\varphi)$ for such a space (where $U \subseteq V$ is open of course). Let us restrict attention to those charts for which $U=V$. Then if the chart function $\varphi: V \to \mathbb{R}^n$ is linear, each of its component functions (which I call coordinate functions, since each specifies a different coordinate of the chart) is a linear function $V \to \mathbb{R}$, thus an element of $V^*$. (Obviously none of this works over arbitrary fields or for infinite-dimensional vector spaces, hence the restrictions I assume/gave above.) Question: Thus, does it make sense to interpret or even define dual bases to be linear charts from $V$ to $\mathbb{R}^n$, and $V^*$ to be the space of all linear coordinate functions? In particular, this would provide a ready explanation for why the components of a vector are written with the opposite index placement when using the Einstein summation convention. If $E = x^i E_i$ is a vector in $V$, then the components $x^i$ could be interpreted as short-hand for the evaluation of the linear coordinate functions (i.e. elements of $V^*$) evaluated at $E$ rather than just scalars, i.e. $$E = x^i(E) E_i \,.$$ Since the $x^i$ are elements of $V^*$, rather than scalars in $\mathbb{R}$, it becomes quite obvious why they should have the index placement they do. Also components/linear coordinates transform the same way that dual vectors do under changes of basis (i.e. they are covariant), so thinking about vectors/dual spaces/tensors the way physicists do, interpreting components/linear coordinate functions as being the same thing as elements of $V^*$ seems to make a certain amount of sense. It might also make dual vector spaces easier to understand for those who tend to think physically or geometrically ( e.g. ). However, I have not seen this practice mentioned in any texts on differential geometry or linear algebra which I have ever read, so I imagine that there are probably problems with it which I am not noticing or understanding yet.","['intuition', 'soft-question', 'differential-geometry', 'linear-algebra', 'definition']"
2093272,Polynomial factorization into irreducibles over $\mathbb{Q}[x]$,I need to find irreducible factors of $f(x)=x^4+3x^3+2x^2+1$ in $\mathbb{Q}[x]$ and explicitely prove that these factors are indeed irreducible. I believe we can't reduce $f(x)$ any further but I have to prove that this is the case. I have already shown that there can't be any linear factors if there was such a factorization using the rational root theorem. But another possibilty is a factorization into two polynomials of degree $2$. So something like: $f(x)=(ax^2+bx+c)(mx^2+nx+p)$. I tried writing it out but since we're working with rationals I find it difficult to find or rule out such polynomials. What do I have to do in this case? And more general: is there a way to find such second degree factors more easily in $\mathbb{Q}$?,"['irreducible-polynomials', 'abstract-algebra', 'ring-theory', 'factoring']"
2093295,Total number of odd numbers in a row of Pascal's triangle is a natural power of two,"This seems like a combinatorial problem so there might be something simple that hasn't struck me.
Although I do have an idea but I am unable to proceed from it.
The statement of the question is: Prove that in any row of Pascal's triangle , the number of odd elements is $2^k$ , for some $k \in \mathbb{N}$ . I was working on a Pascal's triangle but in a binary format, where two adjacent 1's add up to 0. Something of the sort: 1
               1   1
             1   0   1
           1   1   1   1
         1   0   0   0   1
       1   1   0   0   1   1 It is a definitive sequence and the thing I liked about it was that you can add up the adjacent 1's in a row to get the number of odd elements, but I haven't been able to generalize this information.
I was thinking along the lines of a recursive relation in polynomials whose coefficients would represent the rows of this triangle, then I can just feed 1 into the equation and inductively prove that it is a perfect power of 2. Can someone help me out on a proof along these lines, if I'm going in the right direction here? P.S. I know there is the modulo 2 proof but can someone help me generalize that binary pascal's triangle?","['combinatorics', 'contest-math', 'discrete-mathematics']"
2093297,"If $m$ denote the minimum value of $f(x)= \left (\frac{\cos x}{\sin^2x(\cos x-\sin x)}\right)$ where $x\in\left(0,\frac{\pi}{4}\right)$","If $m$ denote the minimum value of $f(x)= \left (\frac{\cos x}{\sin^2x(\cos x-\sin x)}\right)$ where $x\in\left(0,\frac{\pi}{4}\right)$ then find $\lfloor  m\rfloor$. My Attempt: I am trying to find the minimum value of $f(x)$ though the question wants us to find the two consecutive integers between which the function lies.It is clear $f(x)$ is positive over the given interval. Let $t=\tan x$.  Here $0<t<1$. $f(x)$ reduces to  $\frac{1+t^2}{t^2(1-t)}$. Let $g(t)=\frac{1+t^2}{t^2(1-t)}$  ; $0<t<1$ $g'(t)=\frac{t^3+3t-2}{t^3(1-t)}$ Putting $g'(t)=0$. From here I go blank. Should somehow get some inequality to get the two consecutive integers between which $m$ lies","['inequality', 'trigonometry', 'calculus']"
2093314,Rotation Matrix of rotation around a point other than the origin,"In homogeneous coordinates, a rotation matrix around the origin can be described as $R = \begin{bmatrix}\cos(\theta) & -\sin(\theta) & 0\\\sin(\theta) & \cos(\theta) & 0 \\ 0&0&1\end{bmatrix}$ with the angle $\theta$ and the rotation being counter-clockwise. A translation amongst $x$ and $y$ can be defined as: $T(x,y) = \begin{bmatrix}1&0&x\\ 0& 1&y\\0&0&1\end{bmatrix}$ As I understand, the rotation matrix around an arbitrary point, can be expressed as moving the rotation point to the origin, rotating around the origin and moving back to the original position. The formula of this operations can be described in a simple multiplication of $T(x,y) * R * T(-x,-y) \qquad (I)$ I find this to be counter-intuitive. In my understanding, it should be $T(-x,-y) * R * T(x,y) \qquad (II)$ The two formulations are definitely not equal.
The first equation yields $E1 = \begin{bmatrix}\cos(\theta) & -\sin(\theta) & -x\cdot\cos(\theta)+y\cdot\sin(\theta)+x\\\sin(\theta) & \cos(\theta) & -x\cdot\sin(\theta)-y\cdot\cos(\theta)+y \\ 0&0&1\end{bmatrix}$ The second one: $E2 = \begin{bmatrix}\cos(\theta) & -\sin(\theta) & x\cdot\cos(\theta)-y\cdot\sin(\theta)-x\\\sin(\theta) & \cos(\theta) & x\cdot\sin(\theta)+y\cdot\cos(\theta)-y \\ 0&0&1\end{bmatrix}$ So, which one is correct?","['matrices', 'affine-geometry', 'homogeneous-spaces', 'rotations']"
2093369,Bayesian information criterion derivation for linear regression,"As you may know Bayesian Information Criterion (BIC) can be used in model selection for linear regression: The model which has the min BIC is selected as the best model for the regression. BIC formula is given by:( https://en.wikipedia.org/wiki/Bayesian_information_criterion ) $$BIC(M)=k\log(n)-2\log(\bar{L})$$ or for linear regression: $$BIC(M)=k\log(n)+n*\log(RSS/n)$$ where $\bar{L}$ is the maximized value of the likelihood function of the model, i.e. $\bar{L}=p(x|M,\theta)$, $k$ is the number of parameters, i.e. independent variables, in the regression and $n$ is the number of data points. I am looking for the derivation of it. I googled but could not find a document explaining the derivation of BIC for linear regression. I tried to derive the formula myself but I get confused about the model: what is my model, what am I trying to maximize, what is $\theta$? Can you please provide any information regarding the derivation of BIC for linear regression please?
Thanks.","['bayesian', 'probability-theory']"
2093375,Product of sets containing tuples,"How do I work out the Cartesian product of two sets containing tuples? $A := \{(a,b)\}$ $ B:= \{(c,d,e)\}$ Would this: $ A \times B = \{((a,b),(c,d,e))\} $ be correct?",['elementary-set-theory']
2093413,When Schrodinger operator has discrete spectrum?,"On $L^{2}(\mathbb{R})$ we have a linear operator $S=-\frac{d^{2}}{dx^{2}}+u(x)$. As I understand for some choices of potential $u$ (like harmonic oscillator $u(x)=\frac{\omega x^2}{2}$) Schrodinger operator will have  only a countable set of $\lambda_{n} \in \mathbb{R}, f_{n} \in L^{2}(\mathbb{R}), (f_{n} \neq 0)$ such that $S f_{n}=\lambda_{n} f_{n} \\$. My question is for what other choices (if any) of a linear subspace $V$ (possibly without a non-trivial norm) of the space of set-theoretical functions $Map(\mathbb{R},\mathbb{R})$ Schrodinger operator will have only countably many real eigenvalues (say $u$ has finitely many poles on $\mathbb{R}$ and outside poles is infinitely differentiable. Probably a satisfactory answer can be achieved with weaker  regularity assumptions on the potential)?","['functional-analysis', 'mathematical-physics']"
2093415,Rudin Chapter 5 Exercise 14,"The question is as follows. Let $f$ be differentiable real function defined in $(a,b)$. Prove that $f$ is convex iff $f'$ is monotonically increasing. Assume next that $f″(x)$ exists for every $x\in (a,b)$, and prove that $f$ is convex iff $f″(x)\geq 0$ for all $x\in (a,b)$. For the second part of the question, can we directly say that $f'(x)$ is monotonically increasing if and only if $f''(x)\geq 0$? I have this question because the theorem derived from the Mean Value Theorem only directly implies the backwards direction (i.e. if the derivative is larger than 0, the function is monotonically increasing).","['real-analysis', 'analysis']"
2093442,Prove conjecture $a_{n+1}>a_{n}$ if $a_{n+1}=a+\frac{n}{a_{n}}$,"Let sequence $\{a_{n}\}$ such $a_{1}=a>0$,and 
$$a_{n+1}=a+\dfrac{n}{a_{n}}$$ I used the software to find this following conjecture :
if $n>\dfrac{4}{a^3}$,we have 
$$a_{n+1}>a_{n}$$","['recurrence-relations', 'sequences-and-series']"
2093483,Limit of multivariable $\frac{x^2+y^2}{ x^4+y^4}$,"Find the limit $$\lim_{(x, y) \to (0,0)} \frac {x^2+y^2 }{x^4+y^4 }$$ This limit does not exists since when convert it into polar we get $\frac {1 }{ r^2 (1-2 \sin^2 \theta   \cos^2 \theta)}$  which is one over zero right?","['multivariable-calculus', 'functions', 'limits']"
2093485,Advanced mathematics in stringed instrument industry,"This is a soft question. I play classical guitar and I find stringed instrument industry a very fascinating art. I know that, at least for classical guitar, this industry is still developing and exploring new techniques, so it is a very alive research field. I know that it must involve at least some basic mathematics, but I was wondering if anyone has tried to apply deep mathematical tools and concepts in this field, for example from geometric analysis. On the other hand I guess that these techniques could inspire very interesting mathematical questions. What is the state of art of the interaction between maths and stringed instrument industry?","['partial-differential-equations', 'music-theory', 'soft-question', 'applications', 'differential-geometry']"
2093487,What's a closed form for $\sum_{k=0}^n\frac{1}{k+1}\sum_{r=0\\r~is~odd}^k(-1)^r{k\choose r}r^n$,"I want to use a closed form of
$$\sum_{k=0}^n\frac{1}{k+1}\sum_{\ \ \ r=0\\r\text{ is odd}}^k(-1)^r{k\choose r}r^n$$
and
$$\sum_{k=0}^n\frac{1}{k+1}\sum_{\ \ \ r=0\\r\text{ is even}}^k(-1)^r{k\choose r}r^n$$
Thanks.","['combinations', 'binomial-coefficients', 'calculus', 'summation', 'analysis']"
2093502,Why does not Fubini's theorem apply to this double integral?,"Consider the space $ (\Omega \times \Omega,\mathcal{A}\otimes \mathcal{A}, \mu \times \nu) $, where $ \Omega=\mathbb{N} $, $ \mathcal{A} $ is the collection of all subsets of $ \mathbb{N} $ and $ \nu=\mu $ denotes the counting measure, i.e., $ \mu(A)=\nu(A)=\# A $ for all $ A\in \mathcal{A} $. Consider the function $ f:\Omega\times\Omega\to\mathbb{R} $ given by:
$$ f(x,y)=
\begin{cases}
x &\text{if } y=x \text{, } x\in \mathbb{N}\\
-x &\text{if } y=x+1 \text{, } x\in \mathbb{N}\\
0 &\text{otherwise}
\end{cases} $$ I compute two integrals:
\begin{align*}
\iint f \text{ } d\mu\text{ }  d\nu&=\int\left( \int f_y d\mu \right) d\nu\\
&=\int\left( \sum_{x=1}^{\infty}f_y(x) \right) d\nu\\
&=\int\left( f_y(1)+\cdots+f_y(y-2)+f_y(y-1)+f_y(y)+f_y(y+1)+\cdots \right) d\nu\\
&=\int\left( 0+\cdots+0-(y-1)+y+0+\cdots \right) d\nu\\
&=\int 1 d\nu\\
&=\sum_{y=1}^{\infty} 1 \\
&=\infty.
\end{align*}
and
\begin{align*}
\iint f \text{ } d\nu\text{ }  d\mu &=\int\left( \int f_x d\nu \right) d\mu\\
&=\int\left( \sum_{y=1}^{\infty} f_x(y) \right) d\mu\\
&=\int\left( f_x(1)+\cdots +f_x(x-1)+f_x(x)+f_x(x+1)+f_x(x+2)+\cdots \right) d\mu\\
&=\int\left( 0+\cdots +0+x+-x+0+\cdots \right) d\mu\\
&=\int 0 d\mu\\
&=\sum_{x=1}^{\infty}(0)\\
&=0+0+0+\cdots\\
&=0.
\end{align*} Why is not
$$ \iint f \text{ } d\mu\text{ }  d\nu = \iint f \text{ } d\nu\text{ }  d\mu$$
in accordance with Fubini's theorem? Has it something to do with $f$ not being in $L^1(\mu\times\nu)$? If so, how can I show that this is the case?","['integration', 'measure-theory']"
2093526,"Is there a definition of a ""pseudo period"" for $f(x)=\sin(3x)+\sin(\pi x)$?","Sums of trigonometric functions may or may not be periodic functions; in particular, $\sin(ax)+\sin(bx)$ is periodic if $a/b$ is rational. If we consider the function
\begin{equation}
f(x) = \sin(3x) + \sin(\pi x)
\end{equation}
it surely looks periodic, even if it's not; to me it feels like the period itself is somewhat periodic (or is the result of a kind of ""period cascade""). My question is: is there some way to capture this ""quasiperiodic"" nature of this kind of functions, i.e. does there exist a measure of how ""repetitive"" a function is even if it is not a periodic function? To narrow the scope of the question, I'm trying at the moment to figure out the case of the above sum of sines.","['periodic-functions', 'trigonometry', 'irrational-numbers', 'rational-numbers', 'quasiperiodic-function']"
2093530,Shouldn't the harmonic series converge?,"If a sequence converges in a metric space, it is Cauchy, and in $\mathbb{R}^k$ every Cauchy sequence converges. Therefore, in $\mathbb{R}^k$ a sequence converges iff it is Cauchy. Let $\{s_n\}$ be a sequence in $\mathbb{R}$ where each $s_n=\sum_{k=1}^na_k$.
Therefore, by the above, every series converges iff 
$$\left | \sum_{k=m}^n a_k\right| <\epsilon$$
For a given $\epsilon >0$ and an integer $N$ such that $N\le m\le n$. If $n=m$ then the statement reduces to: A series converges if and only if $$|a_n| < \epsilon $$ For a given $\epsilon >0$ and an integer $N$ such that $N\le n$. This clearly cannot be (e.g Harmonic series). When does the equivalence become an implication.","['real-analysis', 'metric-spaces', 'proof-writing']"
2093531,Are the statements about the confidence interval correct?,"We have a 90%-confidence interval. I want to check if the following statements are correct. If double the sample, the possibility that the value that we are looking for is out of the confidence interval is smaller. The bigger the standard error, the smaller the confidence interval. Since the confidence interval is $\left (\overline{x}- Z_{a/2}\cdot s_x, \overline{x}+ Z_{a/2}\cdot s_x\right )$, where $s_x$ is the standard error, I think that the second statement is wrong and it should be that the bigger the standard error, the bigger the confidence interval. 
Is this correct? What about the first statement?","['probability-theory', 'probability', 'confidence-interval', 'standard-error']"
2093569,Points on an ellipse,"For an app, I want to equally distribute a certain number of points on the perimeter of a known ellipse, and, to draw them, I need to know, for every point, the angle of the line that connects it to the center of the ellipse . Here is an horrible drawing of what I must achieve: number of the points is known, distance of the points on the ellipse is constant (or at least should be) but unknown (well, it is circumference/number of points), horizontal and vertical radiuses are known, I look for the angles a0-an I already know that this is a not easy problem, that does not have a finite solution. The fact is that I don't need perfection in the points distribution, but I need speed in the calculation of the positioning. Is there a way or an easy formula that approximates the real solution? Some altorithm that makes it possible to be implemented? Thank you in advance.","['conic-sections', 'geometry']"
2093647,Cantor Theorem assumes set is non-empty?,"Cantor's Theorem: For any set $X$, there is no onto function $f:X\to \mathcal{P}(X)$ While I was looking at the proof for this, my head decided to stop understanding it. I mean, I think I understand the proof itself, but doesn't it assume that the subset of the objects that aren't in the defined function is non-empty? Looking at it, I think that it only proves that that subset has no element. Doesn't it derive a contradiction from an assumption made earlier?
Can you guys help me understand?",['elementary-set-theory']
2093650,Prove that $0<\det(A) \le 1$,"$A=(a_{ij})$ is a $n\times n$ symmetric real matrix such that: $a_{ii}=1$ and $\sum_{j=1}^{n}|a_{ij}|<2$ for all $i \in \{1,2,3,...,n\}$. Prove that $0< \det(A) \le 1$. My approach: That is a question that I have tried before and I am trying again but still without success. I'm trying to use spectral theorem (maybe prove that $|\lambda| \le1$) but I got nothing. I also tried brute force using the definition (using permutations) of $\det A$. Any idea?",['linear-algebra']
2093663,The differences between the following conception [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Till now I've not understood the differences between ( function ) , (mapping ) , (application) ,","['real-analysis', 'functions']"
2093668,Group Cohomology is a universal $\delta$-Functor,"Let $G$ be a group, and let $P_\bullet \to \mathbb{Z}$ be a fixed projective resolution of the trivial $G$-module $\mathbb{Z}$. Then we can define the i-th cohomology group $H^i(G,M)$ of $G$ with coefficients in a $G$-module $M$ to be the i-th cohomology of the chain complex $\mathrm{Hom}_G(P_\bullet,M)$.
With this definition I have no problems to find certain connecting morphisms such that $H^*(G,-)$ forms a cohomological $\delta$-functor. However, I don't see a neat way to show it is universal. I tried to adapt the proof of Weibel's book that left derived functors are universal, but for doing so I need the fact that any module embeds into some injective module. This seems a bit over the top in my opinion (plus it obfuscates how natural transformations of $H^0(G,-)$ extend to $H^*(G,-)$ explicitly). Are there other ways to show universality of $H^*(G,-)$ which avoid injective modules?","['category-theory', 'abstract-algebra', 'group-cohomology', 'group-theory']"
2093673,Proving that the set of all increasing sequences is uncountable,"Claim: Prove that the set of all increasing sequences $n_1<n_2<...<n_n<...$ is uncountable. Here's my attempt: Let $X=\{(x_n)_{n\in N};(x_n)_{n\in N}$ is increasing$\}$. Consider $f:N\rightarrow X$. We claim that no $f$ can be surjective. Denote $(u_n)_{n\in N}$ the image of $f$ at the point $u\in N$, ie, $f(u) =(u_n)_{n\in N}$ . We construct a sequence $(s_n)_{n\in N}$ such that $(s_n)_{n\in N}$$\neq f(s)$ for all $s\in N$. For, construct $(s_n)_{n\in N}$ taking $s_1=\prod_{k=1}^{\infty} f(k)_1$, $s_2=\prod_{k=1}^{\infty} f(k)_2$, ... , $s_n = \prod_{k=1}^{\infty} f(k)_n$, ... By the monoticity of multiplication, we guarantee that $(s_n)_{n\in N} \in X$. But by the way we built it, it is such that $(s_n)_{n\in N} \neq f(s)$ for all s natural. Hence, $f$ cannot be surjective and therefore X is not countable. Is it correct? And if yes, i find pretty intuitive that $(s_n)_{n\in N} \neq f(s)$ for all s natural. But can someone turn it out more rigorous and clear? EDIT: I came up with a new solution and better notation. Here it is: Let $X=\{(x_n)_{n\in N};(x_n)_{n\in N}$ is increasing$\}$. Consider $f:N\rightarrow X$. Denote $(u_n)_{n\in N}$ the image of $f$ at the point $u\in N$, ie, $f(u) =(u_n)_{n\in N}$ . We may write this sequence as $f(u)= (f(u)_1,...,f(u)_n,...)$. Also define $A_u=\{f(u)_1,...,f(u)_n,...\}$ as the set of all elements of the sequence $f(u)$. We define this set for every $u \in N$. Now we construct a new sequence $(s_n)_{n\in N}$ inductively given by: Define $f(s)_1 $= the smallest element of $A_1$. Supposing defined $f(s)_1,...,f(s)_n$, let $S_{n+1} = \{x \in A_{n+1};  x>y$, where $y$ is the smallest element of $A_{n}\}$. Then take $f(s)_{n+1}$= smallest element of $S_{n+1}$. Therefore the sequence $(s_n)_{n\in N}$ is now defined inductively, and by construction $(s_n)_{n\in N}$ is increasing. Therefore, $(s_n)_{n\in N} \in X$ and $(s_n)_{n\in N}$ is such that $(s_n)_{n\in N} \neq f(s)$, for all $s \in N$. Therefore $f$ is not surjective and hence X is not countable.","['real-analysis', 'proof-verification']"
2093721,Why do we need rationalisation? [duplicate],This question already has answers here : Why rationalize the denominator? (15 answers) Closed 7 years ago . While solving a problem I came to an answer $\frac{1}{\sqrt{3}+1}$. But this was not the answer. The answer was $\frac{\sqrt{3}-1}{2}$ which comes on rationalisation of my answer. Then I divided both results and get the same decimal value. Then why do we need rationalisation if it doesn't change decimal value?,"['algebra-precalculus', 'radicals', 'elementary-number-theory']"
2093730,The monomials constitute a basis of the polynomials over $\mathbb R$,"I know this has been asked a lot, but I haven't found a good solution: Show that the set $\{1, x, x^2, ..., x^n\}$ constitutes a basis of the vector space of polynomial functions $\varphi : \mathbb R \to \mathbb R$. My problem is to proof linear independency. Suppose $$\sum_{i=0}^na_ix^i = 0$$
for $a_i \in \mathbb R. $ From plugging in $x = 0$ I get $a_0 = 0$. But how to proceed from here? I know I can factorize $x$ like this: $$x(a_1 + a_2x  + ... + a_nx^{n-1}) = 0$$
and for $x\neq 0$ it must be $$a_1 + a_2x  + ... + a_nx^{n-1} = 0$$
but here I am stuck. I would like to proof this with basic algebra and possibly without theorems from which this easily follows.","['abstract-algebra', 'polynomials', 'linear-algebra', 'functions']"
2093801,"Prove $\exists T\neq \emptyset,\sum\limits_{v\in V}C=0$","I have a set of points in the complex plane that the parameters of the real and imaginary values are integers $P=\{a+bi,\enspace a,b\in\mathbb{Z}\}$ so the set P makes up a grid. There is a second grid $V$ offsetted by $\frac{1+i}{2}$ and it is defined by $V=\{p+\frac{1+i}{2},\enspace p\in P\}$. An element of $P$ and $V$ are called $p$ and $v$ respectively, formally: $p\in P,\enspace v\in V$. The point $v$ represents a cylinder which can be rotated clockwise or counterclockwise by $90^{\circ}$, we can map the rotations $\{\text{right},\text{up},\text{left},\text{down}\}$ to $\{0,1,2,3\}$. Every cylinder starts at rotation $0$. A person starts in position $0$ or $0+0i$ and each step he moves up, down, left or right $1$ unit at a time. Whenever the person passes through two $v_1$ and $v_2$ next to each other, $v_1,v_2\in V$, the one on the left is rotated $90^{\circ}$ counterclockwise and the one on the right is rotated $90^{\circ}$ clockwise. Question: Is it possible to make a path so that the initial state is the same as the end state? If yes, what conditions should $T$ have? My attempt: There are infinitely many trivial solutions such as $T=(1,-1)$ or $T=(1,1,-1,-1)$ or $T=(i,i,i,-i,-i,-i)$ which doesn't count. The general form of these solutions is $T=(t_1,\dots, t_n,-t_1,\dots ,-t_n)$ or $T=(t_1,\dots, t_n,-t_n,\dots ,-t_1)$ The path $T=(t_1,\dots,t_n),\enspace t_i\in\{1,i,-1,-i\}$. The position of the person after $n$ steps is given by $p_n=\sum\limits_{i=1}^{n}t_i$. At any step $n$ the position of the cylinder in the left is given by
$$V_L(n)=p_n+\frac{1+i}{2}t_{n+1}=\frac{1+i}{2}t_{n+1}+\sum_{i=1}^{n}t_i$$
and the one on the right by
$$V_R(n)=p_n+\frac{1-i}{2}t_{n+1}=\frac{1-i}{2}t_{n+1}+\sum_{i=1}^{n}t_i$$ $$V_L:\mathbb{N_0}\rightarrow V ,\quad V_R:\mathbb{N_0}\rightarrow V$$
$C_L(v)$ and $C_R(v)$ tells us the number of times the path has passed from the left and right, respectively, in any given cylinder at position $v$. Formally,
$$C_L:V\rightarrow\mathbb{N_0} ,\quad C_R:V\rightarrow\mathbb{N_0}$$
$$C_L(v)=|\{k\mid v=V_L(k),\enspace k=1,\dots,\vert T\vert-1\}|$$
$$C_R(v)=|\{k\mid v=V_R(k),\enspace k=1,\dots,\vert T\vert-1\}|$$ The total rotation of the cylinder, is given by the number of path segments in the left minus the ones on the right modulo $4$. $$C(v)= (C_L(v)-C_R(v))\mod{4}$$
$$\text{or}\quad C= (C_L-C_R)\mod{4}$$ Now I have to prove $$\Large\quad\exists T\neq \emptyset,\sum\limits_{v\in V}C=0$$ Addendum: By experiment, any path $T=(t_1,\dots, t_n,t_1,\dots, t_n,t_1,\dots, t_n,t_1,\dots, t_n)$ is a valid solution for this problem, but I don't know how to get there or even if these are the only valid solutions. For this $T$, $$\sum\limits_i t_i=0$$ which means that the path started in the same position as it has ended. Does this mean that for the solutions to be valid the only way is to make a path that starts and ends at the same point and go through it $4$ times one after another? $$4C\equiv 4(C_L-C_R)\mod{4}$$
$$4C\equiv 0\mod{4}$$
I think this is why passing through a closed path 4 times resets everything, but is it the only solution? Is it possible for a path which doesn't end in the start position?","['modular-arithmetic', 'complex-numbers', 'elementary-set-theory', 'geometry']"
2093810,"Solving the integral $\int\sqrt{\ln(x)}\,dx $","How to solve the following integral $$
\int\sqrt{\ln(x)}\,dx
$$ If the above integral is not solve-able, how to proof that the 
function $\sqrt{\ln(x)}$ is not integrable.","['indefinite-integrals', 'integration', 'calculus']"
2093827,Solutions of $(\frac{d}{dt}x)y-(\frac{d}{dt}y)x=0$,"I would like to find all the possible solutions of the following differential equation, with two variables: $$(\frac{d}{dt}x)y-(\frac{d}{dt}y)x=0.$$ I have the feeling that I should expect infinitely many solutions, however I don't really know how to approach the problem of finding their general expression. 
I'm sure about the trivial one $x=0,y=0$ and about the following
\begin{align*}
x&=(\frac{d}{dt}x),\\
y&=(\frac{d}{dt}y)
\end{align*} Did I miss ""some"" of them?","['ordinary-differential-equations', 'linear-algebra', 'calculus', 'proof-verification']"
2093841,Moments of the Conditional variance,"If $X$ and $Y$ are two random variables, then the law of total variance allows us to calculate the first moment of $\text{Var}(X|Y)$ by
$$E[\text{Var}(X|Y)] = \text{Var}(X) - \text{Var}(E[X|Y]).$$
In particular we have that $E[\text{Var}(X|Y)] < \text{Var}(X)$. I'm wondering if similar relations may hold for higher moments of $\text{Var}(X|Y)$. For example can we say something about $E[\text{Var}(X|Y)^2]$ compared to  $\text{Var}(X)^2$? I will just comment that for any $n\in \mathbb{N}$ we have the following
$$\text{Var}(X|Y)^n \leq E[X^2|Y]^n$$ and so $$E[\text{Var}(X|Y)^n]\leq E[X^{2n}].$$","['probability-theory', 'conditional-expectation', 'probability']"
2093861,tempered distribution convergence,"I have a question that looks somehow very easy, but I cannot find a proof.
We say that a sequence $(\psi_k)$ in the space of tempered distributions $\mathcal{S}'(\mathbb{R}^d)$ converges to $\psi$, if $\psi_k(\phi) \to \psi(\phi)$ for every $\phi \in \mathcal{S}(\mathbb{R}^d)$. Assume now $\psi_k \to \psi$ in $\mathcal{S}'(\mathbb{R}^d)$ and $\varphi_k \to \varphi$ in the Schwartz-space $\mathcal{S}(\mathbb{R}^d)$. Then the following holds: $\psi_k(\phi_k) \to \psi(\phi)$. There is a hint that one should consider the Banach-Steinhaus theorem. I can prove this result if one replaces $\mathcal{S}(\mathbb{R}^d)$ by some Banachspace. But in this case, I am stuck. I tried it this way: $|\psi_k(\phi_k)-\psi(\phi))|\leq |\psi_k(\phi_k-\phi)|+|\psi_k(\phi)-\psi(\phi)|$.
Now the last term vanishes, but what can I do with the first term?","['functional-analysis', 'distribution-theory']"
2093870,Parabola and tangents in analytic geometry,"A linear function which has a slope of $- \frac{4}{3} $ is intersects with the parabola $y^2 = 8x$ at two points, $A$ and $B$. Prove that the tangent to the parabola at the point of $A$ and the tangent to the parabola at the point of $B$ are perpendicular. EDIT1 Suggested (Narasimham) INSTEAD OF A linear function which has a slope of $- \frac{4}{3} $ is intersects with SUBSTTUTE *A straight line of slope  $-\frac43 $ and passing through focus $ F \, (2,0)$ intersects * My attempts: I've expressed the points in this way $$ A(\frac{a^2}{8},a) $$
$$B(\frac{b^2}{8},b)$$ Substituted them in the slope formula: $$m = \frac{y_1 - y_2}{x_1-x_2}$$
And equated it to the slope of the linear function from the beginning (-4/3).
Then tried to use the fact that the multiplication of slopes of perpendicular linear functions equals to -1. Yet nothing lead me to answer.
Will be grateful for help, thanks in advance :)","['analytic-geometry', 'calculus', 'functions']"
2093896,Generate integer solutions from a hyperbolic equation,"I want to generate any integer solution from the equation $\sqrt{8r^2+1} = n$. I know there are integer solutions to this, but I have no idea how to approach this. (When working with whole numbers) Since division and square roots are the only operations that can turn a whole number to a fraction, I thought I would be able to manipulate it to get rid of those operations, but any manipulating of the equation gets me nowhere closer and it seems I simply lack the mathematical understanding to solve this. Is there any way to solve this problem?","['number-theory', 'functions']"
2093919,Solution to a given matrix initial value problem,"Consider the IVP : $y''(x)+A \cdot y(x)=0,$ where $A$ is an $n \times n$ positive definite matrix. Also $y(0)=c_0$ and $y'(0)=c_1,$ where $c_0 , c_1 \in \mathbb{R}^n$ are constant vectors. Since $A$ is positive definite, it possesses a square toot. The solution is given by 
$$y(x)=C \cos \sqrt{A}x+ D  \sin \sqrt{A}x.$$
Also, 
$$y'(x)=-C \sqrt{A} \sin \sqrt{A}x+ D \sqrt{A}  \cos \sqrt{A}x.$$
Using $y(0)=c_0$ and $y'(0)=c_1,$ I got $C=c_0$ and $D \sqrt{A}=c_1.$
Is my approach correct ? Can I just write $D=c_1 \cdot  (\sqrt{A})^{-1}$ ? 
Any help is much appreiciated.","['ordinary-differential-equations', 'initial-value-problems']"
2093989,\epsilon - packings in compact metric spaces,"Let $(X,d)$ be a compact metric space. Fix some $\epsilon >0$. Then it is clear that any set $S\subset X$ such that for all $x,y \in S$ one has that $d(x,y) > \epsilon$ is finite. In fact, an infinite one would contain a sequence with no convergent subsequence contradicting the compactness of $X$. But now one can ask, whether there is a constant $N$, such that any subset $S$ of $X$ with that property has at most $N$ elements. Unfortunately I have no clue how to prove this or find a counterexample. I'm thinking of the following (somewhat analogous) question where there is no such $N$: Let $X$ be a noetherian scheme. Then its topological space is noetherian meaning that every descending chain of closed subsets of $X$ stabilizes. However this does not imply that dim$(X)$ is finite. (see for example here: https://mathoverflow.net/questions/21067/noetherian-rings-of-infinite-krull-dimension ) So my question is, if there exists such a bound $N$ in general (i.e. for arbitrary compact metric spaces) or if there are nice conditions under which such a bound exist. Moreover I would be interested if there is a way to build up a dimension theory using the minimal bound. (It seems to be similar to the following: https://en.wikipedia.org/wiki/Equilateral_dimension , but without the assumption that all distances coincide. Here one could also ask, whether the best possible choice is always given by equilateral points, I'm also not sure about that.) To finish I want to add that I'm not familiar with the notions of nets, filters and ultrafilters (and so on), so I would appreciate, if a solution would be more elementary if possible (if not, I'm willing to accept that I have to learn about those things first..)","['general-topology', 'analysis']"
2094001,Conditions for l'Hôpital's rule,"According to l'Hôpital's rule, given functions $f,g$ which are differentiable around $a\in \mathbb R$, such that -- $\lim_{x\to a} f(x)=\lim_{x\to a}g(x)=0$ $g'(x)\neq 0$ on some deleted neighborhood of $a$. $\lim_{x\to a} {\frac {f'(x)}{g'(x)} }$ exists (widely). Then  $\ \ \lim_{x\to a} {\frac {f(x)}{g(x)} } = \lim_{x\to a} {\frac {f'(x)}{g'(x)} }$. Condition 2 is necessary for the proof, but I can't find a counterexample for the theorem without it. Could you give an example of differentiable functions $f,g$ aroud $a$, such that conditions 1,3 hold, but $\ \ \lim_{x\to a} {\frac {f(x)}{g(x)} } \neq \lim_{x\to a} {\frac {f'(x)}{g'(x)} }$?","['calculus', 'limits']"
2094007,Evaluating $\lim_{ x \to+ \infty }\left[\frac{[x]}{x}\right]$ and $\lim_{ x \to- \infty }\left[\frac{[x]}{x}\right]$,"Find the limit : $$\lim_{ x \to+ \infty }\left[\frac{[x]}{x}\right]=?
\\\lim_{ x \to- \infty }\left[\frac{[x]}{x}\right]=?$$ $[x]:$ floor function I tried: $[u]∼u :\text{where}  x→∞$ $$\lim_{ x \to+ \infty }\left[\frac{[x]}{x}\right]=\lim_{ x \to+ \infty }\frac{[x]}{x}=1!!!$$","['fractional-part', 'limits']"
2094016,Trig-Issue: calculate triangle height for overlapping rectangles,"In the image below there are two rectangles of known width (w) and height (h), that rotate by a known angle (a) around their centres. I need to solve for n. I've tried the following on squares: n =  sqrtf(powf(w, 2.0f) + powf(w, 2.0f))/2; and where ang equals the transform angle: n = (h-w) * (fabsf(ang) / 90) / 2; but both attempts fail between angles 0 and -90. I've  considered calculating all the angles (e.g. b) within the triangle of n, but without knowing any of the lengths I'm struggling. I need the equation for a swiping animation in a mobile app. w = 320
h = 568
a = -20 EDIT: I've included a second image to show the changing shape of the triangle to a quadrilateral to a rectangle (at 90 degrees). Is it fair to assume the solution would need to include more than just triangle trig?",['trigonometry']
2094040,determine the size of angle [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Can you help me to determine the angle marked with a question mark? $\overline {AB}$ and $\overline {DE}$ are parallel",['geometry']
2094051,Is this induction question wrong or am I going insane?,"Here's a question that I've come across: Prove by induction that for every integer $n$ greater than or equal to $1$, $${\sum_{i=1}^{2^n}} \frac{1}{i} \ge 1 +\frac{n}{2}.$$ Now I know how to prove by induction, but wouldn't this fail $p(1)$ since $$\frac{1}{1} \ge 1 +\frac{1}{2}$$ is not true?","['induction', 'discrete-mathematics']"
2094087,M Balls in N Bins: Expectation,"Question : I have a typical $m$ balls in $n$ bins question, where I'm trying to find the expected number of balls in each bin. 
Each ball is independently placed into one of the n bins, so there is a $\frac1n$ chance for each bin. My Guess : I believe that the expected value should be something like $\frac mn$, but I'm not sure how to prove it. I started by using an indicator random variable $X_i$ = the event in which the $i$-th ball is in a bin. $X_i = 1$ with probability $\frac 1n$ OR $0$ with probability $1-\frac 1n$. E(number of balls in each bin) = $E(X_1)+E(X_2)+ ... + E(X_m) = m\cdot E(X_i) = \frac mn$ But I think that the proof doesn't seem correct, can anyone explain where I went wrong (if I did go wrong)? Thanks!","['balls-in-bins', 'statistics', 'probability']"
2094116,How do we know that Cantor's diagonalization isn't creating a different decimal of the same number?,"Edit: As the comments mention, I misunderstood how to use the diagonalization method. However, the issue I'm trying to understand is a potential problem with diagonalization and it is addressed in the answers so I will not delete the question. Cantor's diagonalization is a way of creating a unique number given a countable list of all reals. I can see how Cantor's method creates a unique decimal string but I'm unsure if this decimal string corresponds to a unique number. Essentially this is because $1 = 0.\overline{999}$. Consider the list which contains all real numbers between $0$ and $1$: $0.5000 \mathord\ldots \\
0.4586 \mathord\ldots \\
0.3912 \mathord\ldots \\
0.3195 \mathord\ldots \\
0.7719 \mathord\ldots\\
\vdots$ The start of this list produces a new number which to four decimal places is: $0.4999 \mathord\ldots$ But $0.5$ was the first number and $0.4\overline{999} = 0.5$ so this hasn't produced a unique number. Of course my list is very contrived, I admit that it's hard to imagine a list of the reals where numbers would align nicely to give a problem like this (since some numbers have no nines). However, I can't see a good reason why such an enumeration of numbers would be impossible.","['decimal-expansion', 'elementary-set-theory']"
2094178,Notation regarding integral curves and vector fields,"trying to solve some integral curve of vector field I am really confused about the notation used in many textbook. I can see problem of this sort : Find the integral curves of the following vector field :
\begin{align}
X(x,y) = x^2\frac{\partial}{\partial x} + xy\frac{\partial}{\partial y}
\end{align} So to set up the notation in this setting, a curve should be $\gamma : \mathbb{R} \rightarrow \mathbb{R}^2$ and any vector field of the curve can be written as :
\begin{align}
X_{{\gamma},p} = \frac{\partial }{\partial x^i}.(x^i\circ\gamma)'(0)
\end{align} Where $\gamma(0) = p$. So if we want to find the integral curve of the vector field we have to make sure at any point of the curve (any $t$) the tangent vector of the curve is the same as the vector field evaluated at $\gamma(t)$. The problem is when equating the two equation we end up with something like $x^2 = (x^i\circ\gamma)'(0)$ which do not make sense. Are we abusing notation in this sort of problems where $x^2$ is actually the composition of the coordinate function $x$ with the curve at the specific point of interest ? If this is the case, how inaccurate is the drawing of the vector field in 2D ? ( I can see in my textbook the drawing of the vector field where at each $(x,y)$ an arrow is drawn with direction $(x^2, xy)$. I can see some other textbook which define the curve to be $\gamma(t) = (x(t), y(t))$ which again do not make sense as it is conflicting with the coordinate function definition $x : \mathbb{R^2} \rightarrow \mathbb{R}$. I am asking this question because the books go ahead solving an ODE where they have no problem solving stuff like : $x' = x^2$ and $y' = xy$. So is this abusing the notation ?","['ordinary-differential-equations', 'differential-geometry', 'vectors']"
2094187,book recommendation for algebraic geometry,"I have just finished my undergraduate studies and i want to study some algebraic geometry. i have taken 1 year analysis, topology, algebra courses and finished 1 semester complex analysis, homological algebra, fourier analysis, differential geometry. with this background i'm planning to study atiyah's commutative algebra. then next, where should be the starting point for studying the A.G? hartshorne is surely too tough for me. i want to read some A.G books which are not too hard to follow, and kind of self contained.","['book-recommendation', 'soft-question', 'algebraic-geometry']"
2094198,How to prove that $(x+ {\sqrt{1+x^2}} ) ( y+ {\sqrt {1+y^2}}) = 1$ if $(x+ {\sqrt{1+y^2}} ) ( y+ {\sqrt {1+x^2}}) = 1$,"Let $x,y$ be real numbers such that : $(x+ {\sqrt{1+y^2}} ) ( y+ {\sqrt {1+x^2}}) = 1$. Prove that : $(x+ {\sqrt{1+x^2}} ) ( y+ {\sqrt {1+y^2}}) = 1$. I tried taking $x=y$. It simplifies everything a lot. But I'm not able to progress when both $x$ and $y$ are in the same equation.","['algebra-precalculus', 'radicals', 'quadratic-forms', 'systems-of-equations']"
2094253,Show that if the sum of components of one vector adds up to 1 then the sum of the squares of the same vector is at least 1/n,"(NOTE: Already posted here , but closed without an answer) Hi, I've been trying to complete the following question: Suppose we have two vectors of $n$ real numbers, $[x_1,x_2,⋯,x_n]$ and $[y_1,y_2 ⋯,y_n]$ and the following inequality holds:
$$(x_1y_1+x_2y_2+⋯+x_ny_n)^2≤(x_1^2+x_2^2+⋯+x_n^2)(y_1^2+y_2^2+⋯+y_n^2)$$
Show that if the sum of components of one vector adds up to 1 then the sum of the squares of the same vector is at least $\frac 1n$. I've tried a few avenues, and have come up a proof that I am not confident is right. Proof by induction: Base case is $n=1$, which is trivial, since $x_1^2 = 1^2 = 1$ and so
$1 \ge \frac 1 1$. Therefore base case is true. Assume it is true for n. $$x_1^2+...+x_n^2+x_{n+1}^2 \ge \frac 1 {n+1}$$ Since $x_1^2+...+x_n^2 \ge \frac 1 n$ by our assumption, $$\frac 1 n + x_{n+1}^2 \ge \frac 1 {n+1}$$ It is this step that I think is incorrect, as the $x_1^2+...+x_n^2$ must get smaller in order to accomodate the new value of $x_{n+1}$, and still remain equal to 1. Therefore I don't think I can do this step? $$x_{n+1}^2 \ge \frac 1 {n+1} - \frac 1 n$$ The left hand side must always be $\ge 0$ and the right hand side must always be negative for values of $n \ge 1$. Therefore true for $n+1$, so must be true for all $n$. QED. Can you confirm it is wrong? If it is wrong, could you please explain how to prove it in your answer. Thanks.","['induction', 'real-analysis', 'analysis', 'proof-verification']"
2094282,Negative Hypergeometric Distribution expectation,"I am reading Introduction to Probability by Blitzstein and Hwang - Expectation. The book states : An urn contains $w$ white balls and $b$ black balls, which are randomly drawn one by one without replacement. The number of black balls drawn before drawing any white balls has a negative hypergeometric distribution. For example, if we shuffle a deck of cards and deal them one at a time, the number of cards dealt before uncovering the first ace is a negative hypergeometric with $w=4,b=48$ . Finding the expected value of a negative hypergeometric r.v. directly from the definition results in very complicated sums of products. But the answer is very simple-looking: $b/(w+1)$ . Let us prove this using indicator r.v.s. Label the black balls as $1,2,3,\ldots,b$ and let $I_{j}$ be the indicator of the black ball $j$ being drawn before any white balls have been drawn. Then, $P(I_{j}=1)=1/(w+1)$ , since listing out the order in which black ball $j$ and the white balls are drawn (ignoring the other balls), all orders are equally likely by symmetry, and $I_{j}=1$ is equivalent to black balls $j$ being first in this list. I know that, when sampling without replacement, the number of failures(drawing a black ball) until the first success(drawing a white ball) is a negative hypergeometric r.v. But, why is $P(I_{j}=1)=1/(w+1)$ ? And why do we ignore the other black balls?","['probability', 'polya-urn-model', 'probability-distributions']"
2094289,Monty Hall extension,"Lets explore an extension of the monty hall problem. Assume the usual scenario with two goats and one car. Also assume that there are two types of hosts, and you do not know which type your host is. Host type A is the standard host that gives you a choice to switch. Host type B only gives you a choice if you choose the right door at the beginning, otherwise he reveals that you have lost immediately. You know that host A appears with probability P(A), and host B with probability 1-P(A) what does P(A) have to be so there is no dominant strategy if you have been given the choice? My first attempt is to state that the probability of winning P(W) has to be 1/2 if you always switch, so there is no dominant strategy. Thus P(W)=P(W|A) P(A) + P(W|B) (1-P(A))=1/2
Note that  P(W|B)=0 if you always switch. Hence P(A)= P(W)/P(W|A)=1/2/2/3=3/4 Is this correct? I cannot take away the feeling that the fact that you have a choice gives you new information that should change the problem, but I may be simply over thinking everything.","['statistics', 'monty-hall']"
2094295,Why does the derivative of $\ln(\sin x)$ = $\cot x$?,I thought the derivative of $\ln(u)$ was $\frac{u'}{u}$.  So why does the derivative of $\ln(\sin x)$ = $\frac{1}{\sin x}(\cos x)$ instead of $\frac{\cos x}{\sin x}(\cos x)$?,"['derivatives', 'calculus']"
2094304,How to mentally flip a coin?,"If you've ever played rock-paper-scissors, and you are reading this on math.stackexchange, you probably know that always playing $1$ of the $3$ choices at random (more precisely: uniformly at random and independently of previous choices) guarantees even chances of victory against any opponent. But ""playing at random"" is harder than it looks, particularly if you have no tools - from old-fashioned dice to tech accessing thermal noise. In fact, I've seen a little piece of code that marginally, but consistently over time, beats most humans at rock-paper-scissors simply by looking at biases in how they've been playing so far, and predicting future throws accordingly. For example, humans tend to to play long sequences of identical throws with the ""wrong"" frequency. I was wondering if anyone knows good ways to produce reasonably random bits without tools ; say, enough to compete with even or as-even-as possible odds against a computer trying to predict one's choices. I realize ""good"" and ""reasonably"" (and even ""tools"") is a bit fuzzy, but I'm sure folks will understand the spirit of the question... I don't want to simulate a Mersenne Twister in my head (though a pseudorandom generator with a reasonable balance of randomness and simplicity would definitely be a possibility), nor use the painful method a friend of mine suggested: pull a random hair from one's head, and check if it's white (for most people it's a biased toss, but as long as one's hair is salt-and-pepper one can trade hair for fairness in the toss ). Buried in the comments below, there's a link to a web page allowing you to test any such scheme !","['probability', 'card-games', 'random']"
2094306,Probability of getting off at the bus stop,"6 stops on the line, and a car with 4 passengers. Assume they are equally likely to get off at any stop. What is the probability that A $2$ passengers get off stop 2, and $2$ get off stop 4? B $2$ get off stop 1, and $2$ get of at another stop (but they get off at the same stop as each other?) A I get $1/81$ which is wrong? B I get $5/6^4$ which is also wrong? Why are both of these wrong?","['combinatorics', 'probability']"
2094318,Prove $aX$ is a random variable,"Let $X$ be a r.v. on a given probability space and let $a \in \mathbb{R}$. Show that $aX$ is a r.v. I need to check if my proof is correct. Proof: A random variable is a function $X : \Omega \rightarrow \mathbb{R}$ with the property that $\{\omega \in \Omega : X(\omega) \leq x\} \in \mathcal{F}$ for each $x \in \mathbb{R}$. So $aX$ will be the random function such that $aX : \Omega \rightarrow \mathbb{R}$ with the property that $\{\omega \in \Omega : aX(\omega) \leq x\} \in \mathcal{F}$ for each $x \in \mathbb{R}$. Updated Proof Let $Y = aX$ be a random variable.
Then $Y : \Omega \rightarrow \mathbb{R}$ such that $\{\omega \in \Omega : Y(\omega) \leq x \} \in \mathcal{F}$. This is implies that $\{\omega \in \Omega : aX(\omega) \leq x \} \in \mathcal{F}$ which implies that $\{\omega \in \Omega : X(\omega) \leq \frac{x}{a} \} \in \mathcal{F}$. Therefore $aX$ is a random variable. Corrected Proof Let $Y = aX$.
Then $Y : \Omega \rightarrow \mathbb{R}$ such that $\{\omega \in \Omega : Y(\omega) \leq x \}$. This is implies that $\{\omega \in \Omega : aX(\omega) \leq x \}$ which implies that $\{\omega \in \Omega : X(\omega) \leq \frac{x}{a} \} \in \mathcal{F}$ since $\frac{x}{a} \in \mathbb{R}$. Therefore $aX$ is a random variable.","['probability-theory', 'proof-verification']"
2094319,expansion of logarithmic matrix,"Let $A,B$ be Hermitian matrices ($A$ has positive or zero eigenvalues and $Tr A=Tr[A+\lambda B]=1$), and $\lambda$ is infinitesimal constant. How to expand
\begin{equation}  
\ln(A+\lambda B)
\end{equation}
and 
\begin{equation}  
Tr[(A+\lambda B)\ln(A+\lambda B)]
\end{equation}
into powers of $\lambda$ as usually do in Taylor expansion of functions?","['matrices', 'matrix-calculus']"
2094327,Evaluate $\int_0^1 \frac{\ln \left(1+x+x^2+\cdots +x^{n} \right)}{x}dx$,"How to evaluate
$$\int_0^1 \frac{\ln \left(1+x+x^2+\cdots +x^{n} \right)}{x}dx$$
My attempt:
\begin{align*}
\int_0^1 \frac{\ln \left(1+x+x^2+\cdots +x^{n} \right)}{x}dx &= \int_0^1 \frac{\ln \left(\dfrac{1-x^{n+1}}{1-x} \right)}{x}dx \\ 
&= \int_0^1 \frac{\ln \left({1-x^{n+1}} \right)}{x}dx -\int_0^1 \frac{\ln \left({1-x} \right)}{x}dx \\  
&=\frac{1}{n+1} \int_0^1 \frac{\ln \left({1-x} \right)}{x}dx -\int_0^1 \frac{\ln \left({1-x} \right)}{x}dx 
\end{align*}
but what's next?I have been stuck here for a while.","['integration', 'calculus']"
2094337,Why do this algorithm for finding an equation whose roots are cubes of the roots of the given equation works?,"Let a polynomial, $p(x)$, of degree $n$ is given. Our aim is to find another polynomial, $q(x)$, whose roots are the cubes of the roots of $p(x)$. Our algorithm go like this: Step 1 Replace $x$ by $x^\frac{1}{3}$. Step 2 Collect all the terms involving $x^\frac{1}{3}$ and $x^\frac{2}{3}$ on one side. Step 3 Cube both the sides and simplify. Although I get the correct answer by following this algorithm but I can't get my head around the reasoning behind its working. So, can you kindly help me to figure it out? $\fbox{EDIT 1:}$ Proof that the final equation of $q(x)$ so obtained will be a polynomial: We originally had $$p(x)=0$$ Step 1 Replace $x$ by $x^\frac{1}{3}$. After replacing $x$ by $x^\frac{1}{3}$ we get an equation like 
$$p_{1}(x)+x^\frac{2}{3}p_{2}(x)+x^\frac{1}{3}p_{3}(x)=0$$ Here, $p_{1}(x)$, $p_{2}(x)$ and $p_{3}(x)$ are polynomials in $x$. Step 2 Collect all the terms involving $x^\frac{1}{3}$ and $x^\frac{2}{3}$ on one side. Now we have
$$x^\frac{2}{3}p_{2}(x)+x^\frac{1}{3}p_{3}(x)=-p_{1}(x)  \qquad(1)$$ Step 3 Cube both the sides and simplify. Cubing both the sides of $(1)$ we get
$$x^{2}p^{3}_{2}(x)+xp^{3}_{3}(x)+3xp_{2}(x)p_{3}(x)[x^\frac{2}{3}p_{2}(x)+x^\frac{1}{3}p_{3}(x)]=-p^{3}_{1}(x)$$ $$p^{3}_{1}(x)+x^{2}p^{3}_{2}(x)+xp^{3}_{3}(x)+3xp_{2}(x)p_{3}(x)[x^\frac{2}{3}p_{2}(x)+x^\frac{1}{3}p_{3}(x)]=0 \qquad(2)$$ Now, from $(1)$ and $(2)$ we have
$$p^{3}_{1}(x)+x^{2}p^{3}_{2}(x)+xp^{3}_{3}(x)+3xp_{2}(x)p_{3}(x)[-p_{1}(x)]=0$$ Therefore, $q(x)=p^{3}_{1}(x)+x^{2}p^{3}_{2}(x)+xp^{3}_{3}(x)-3xp_{1}(x)p_{2}(x)p_{3}(x)$ Clearly, $q(x)$ is a polynomial.","['polynomials', 'transformation', 'roots', 'algebra-precalculus', 'algorithms']"
2094343,countable intersection of open set argument,"I know that countable intersection of open sets could be closed or open. But I was wondering what is wrong with my argument here: Given an element say x in a countable intersection of open sets say denoted as $\bigcap_{i\in\mathbb{N}}A_{n}$ where each of $A_n$ is an open set. Then since x is an element that belongs to each of $A_i$, so for each $A_i$, we have an $\epsilon_i>0$ such that ($x-\epsilon_i, x+\epsilon_i$) is entirely contained in $A_i$. Then out of all the $\epsilon_i$, we can pick the minimum of all those $\epsilon_i$ say denoted as $\epsilon^*$ such that $\epsilon^* \leq \epsilon_i$. Then we have $(x-\epsilon^*, x+\epsilon^*)$ within each of the $A_i$. Since we can do it for arbitrary element of x in $\bigcap_{i\in\mathbb{N}}A_{n}$ , then we can conclude that $\bigcap_{i\in\mathbb{N}}A_{n}$  is open. I know it is incorrect, but which part is incorrect? Is it because of the ""countable intersection"" part? I know that instead of coutable, if I have ""finite intersection"", then the finite intersection of those open sets will be open. But not sure how to get the concept correct for the ""countable intersection"" to understand that ""countable intersection"" of open interval is not necessarily open without using Counterexample. I saw many counter example that shows intersection of open set could be closed. But I just want to know which part of my thinking above is incorrect.  Thank you.","['general-topology', 'real-analysis', 'lebesgue-measure', 'measure-theory']"
2094351,Arranging Bubbles,"Recently, I attained quite some skill at blowing bubbles. At first I would blow bubbles like this: But then things started getting strange: After a while, I was blowing some pretty weird bubbles: After blowing hundreds, maybe even thousands of such bubbles, my forehead suddenly wrinkled with the question: Given n bubbles, how many different ways can you arrange them? For example if n = 1, there is only 1 arrangement. If n = 2, there are 2 arrangements. If n = 3, there are 4 arrangements. If n = 4, there are 9 arrangements (I think, but not completely sure). Here are the 9 arrangements of 4 bubbles: For some reason, my wrinkled forehead doesn't have quite enough neurons within it to figure out the answer to my question. Can someone else try wrinkling their forehead to see if they might be able to get an answer? Given n bubbles, how many different ways can you arrange them?","['combinatorics', 'graph-theory', 'sequences-and-series']"
2094357,How can this expression be calculated? $\dfrac{1 + \dfrac{3\cdots}{4\cdots}}{2 + \dfrac{5\cdots}{6\cdots}}$,"I can't see any obvious way this could be calculated. It seems to converge to a value of approximately 0.6278... $\dfrac{1 + \dfrac{3}{4}}{2 + \dfrac{5}{6}} \approx 0.6176 $ $\dfrac{1 + \dfrac{3 + \dfrac{7}{8}}{4 + \dfrac{9}{10}}}{2 + \dfrac{5 + \dfrac{11}{12}}{6 + \dfrac{13}{14}}} \approx 0.6175 $ Going all the way up to 62 gives a result of 0.627841944566, so it seems to converge. Is it possible to find a value for this? Will it have a closed form solution?","['fractions', 'sequences-and-series']"
2094362,Limit of the exponential functions: $\lim_{x\to 0} \frac{e^x-e^{x \cos x}} {x +\sin x}$,"I want to find the limit of this function by simply using algebraic manipulation. Though I have computed the limit through L' Hospital's method but still I want to compute the limit purely by function's manipulation to yield a form where limit can be applied 
$$\lim_{x\to 0} \frac{e^x-e^{x \cos x}}  {x +\sin x} $$ Till now we have been taught basic limits such as $\lim_{x\to 0} \frac{e^x-1}{x}=1$ and that's why I have been trying to bring such form in this expression. P.S. I got the current answer by L'Hospital's rule i.e. $0$","['exponential-function', 'limits-without-lhopital', 'limits']"
2094400,The Global Sections Functor and the Hom Functor,"Why is it possible for us to think of the global sections functor $\Gamma(X,-)$ as the Hom functor $\text{Hom}(\mathbb{Z},-)$ where $\mathbb{Z}$ here refers to the constant sheaf with the integers as the stalk? And why do we need the integers to be the stalk? I believe expressing the global sections functor as the Hom functor means that the sheaf cohomology would  then be expressible in terms of the Ext functor. Using the Hom functor, I can see somewhat of an analogy with the way cohomology is defined in basic algebraic topology, as the ""dual"" of singular homology (the cochains are made up of maps from the chains with integer coefficients to the abelian group of the coefficients of the cohomology), so perhaps this is where the integers come from; however I cannot yet see what this has to do with global sections. Please tell me where I can read more about this viewpoint too.","['sheaf-theory', 'algebraic-geometry', 'sheaf-cohomology', 'homological-algebra', 'algebraic-topology']"
2094459,"finding $ \int^{4}_{0}(x^2+1)d(\lfloor x \rfloor),$ given $\lfloor x \rfloor $ is a floor function of $x$","finding $\displaystyle \int^{4}_{0}(x^2+1)d(\lfloor x \rfloor),$ given $\lfloor x \rfloor $ is a floor function of $x$ Assume  $\displaystyle I = (x^2+1)\lfloor x \rfloor \bigg|^{4}_{0}-2\int^{4}_{0}x\lfloor x \rfloor dx$ ( integration by parts ) i have a doubt about limit part , did not understand whether the limit corresponding to $x$ or corrosponding to $\lfloor x \rfloor$ because when we take $\displaystyle \int^{b}_{a}f(x)dx,$ then limits are corrosponding to $x$ but when we take  $\displaystyle \int^{b}_{a}f(x)d(\lfloor x \rfloor ),$ then limit corrosonding to $\lfloor x \rfloor$ please clearfy my doubt and also explain me whats wrong with my method above , thanks","['integration', 'definite-integrals', 'calculus']"
2094475,Probability density of a stochastic process,"Good morning, recently I had to solve the two-dimensional SDE, and the solution process I found was $$\left\{\begin{array}{rcl}\xi^1_t&=&\xi^1_0+\int_0^t dw(s),\\ \xi_2^t&=&\xi_0^2+\int_0^t(\xi_s^1)^2ds\end{array}\right.,$$ where $w(t)$ is a standard one-dimensional brownian motion. Then $\xi_t^1$ has a normal distribution with mean $\xi_0^1$ and variance $t$. What kind of process is $\xi_t^2$? More generally what can I say on the whole process $(\xi_t^1,\xi_t^2)$ (as a Joint process)? I didn't find any reference in the literature unfortunately so that's why I'm asking. Thank you for all your kind replies.","['stochastic-processes', 'reference-request', 'probability', 'stochastic-calculus', 'stochastic-differential-equations']"
2094506,50% probability of seeing all cards,"I have a deck of $20$ different cards. Each time, a card is pulled randomly, then put back in the deck.
We shuffle and proceed to pull another card (thus keeping the randomness of pulls). The question is this: After how many pulls the probability of seeing all cards in the deck is $50$$\%$?","['coupon-collector', 'probability']"
2094538,Linear independence of a set of solutions and the Wronskian,"Consider a general $n$th order linear equation
  $$x^{n}(t)+a_{n-1}x^{n-1}(t)+ \dots + a_{1}x'(t) + a_{0}x(t)=0\tag{$*$}.$$
  Let $x_1, x_2 , \dots , x_n$ be a fundamental set of solutions of above and set $W(t)=W(x_1, x_2 , \dots , x_n ; t).$ Question. Show that a set of solutions $x_1 , x_2 , \dots , x_k$ of $(*)$ are linearly  independent over $(-\infty, \infty)$ if and only if their Wronskian $W(x_1 , x_2 , \dots , x_k; t_0) \neq 0$ for some $t_0 \in (-\infty, \infty).$ Also show that those solutions form a vector space of dimension $n$. My approach : Writing the equivalent first order system, $$y_1=x ,~y_2=x' ,~\dots~,y_n=x^{(n-1)},$$
from which we get
$$y_1'=y_2,~~y_2'=y_3,~~\dots~~,y_{n-1}'=y_n,~~y_n'=-a_{n-1}(t) y_n- \cdots - a_{1}(t) y_2-a_{0}(t) y_1.$$ For the contrapositive statement: i.e., if $W(x_1 , x_2 , \dots , x_k; t_0) = 0,$ for some $t_0 \in (-\infty, \infty),$ doesn't that clearly implies that the set of vectors $\{ x_1 , x_2 , \dots , x_k \}$ is linearly dependent. I'm stuck in progressing any further. Any help in proving this is much appreciated.","['real-analysis', 'ordinary-differential-equations', 'linear-algebra']"
2094567,Origin of Jacobian determinant [duplicate],"This question already has answers here : Intuitive proof of multivariable changing of variables formula (Jacobian) without using mapping and/or measure theory? (5 answers) Closed 5 years ago . What is the origin of the Jacobian determinant for changing variables in multiple integrals? I mean, how to derive the formula for the Jacobian determinant? I have seen the use of Jacobian in some books but could not find how it arises.","['matrices', 'integration', 'multivariable-calculus', 'jacobian']"
2094596,Why can we resolve indeterminate forms?,"I'm  questioning myselfas to why indeterminate forms arise, and why limits that apparently give us indeterminate forms can be resolved with some arithmetic tricks. Why $$\begin{equation*}
\lim_{x \rightarrow +\infty}
\frac{x+1}{x-1}=\frac{+\infty}{+\infty}
\end{equation*} $$ and if I do a simple operation, $$\begin{equation*}
\lim_{x \rightarrow +\infty}
\frac{x(1+\frac{1}{x})}{x(1-\frac{1}{x})}=\lim_{x \rightarrow +\infty}\frac{(1+\frac{1}{x})}{(1-\frac{1}{x})}=1
\end{equation*} $$ I understand the logic of the process, but I can't understand why we get different results by ""not"" changing anything.","['indeterminate-forms', 'limits']"
2094617,Compute the integral $\int_0^{\pi/2}\sin(1+\cos^2x)\mathrm{d}x $,"My attempt.
$$\int\limits_0^{\pi/2}\sin(1+\cos^2x)\mathrm{d}x $$
Let $t=1+\cos^2x \Rightarrow \mathrm{d}t -2\sin x\cos x~ \mathrm{d}x. $
We have $\cos^2x=t-1 \Rightarrow \cos x=\sqrt{t-1}$ and $\sin x = \sqrt{2-t}.$ So $$\mathrm{d}x = \frac{-\mathrm{d}t}{2\sqrt{2-t}\sqrt{t-1}}$$
Now,
$$\frac{1}{2}\int\limits_1^2\frac{\sin t}{\sqrt{2-t}\sqrt{t-1}}\mathrm{d}t$$
I tried substituting by parts letting $u=\sin t$, and $dv = \int \mathrm{d}t/(\sqrt{(2-t)(t-1)})$. But the integral just gets more complicated.","['bessel-functions', 'integration', 'definite-integrals', 'calculus']"
2094621,Proof that Rényi divergence = KL divergence when $\alpha \rightarrow 1$,"Kullback–Leibler divergence between two parametrized distributions is defined as: $$
D_{KL}(q(\theta) || p(\theta)) = \int q(\theta) \log \frac{q(\theta)}{p(\theta)} d\theta
$$ Rényi divergence is defined as: $$
D_{\alpha}(q(\theta) || p(\theta)) = \frac{1}{\alpha-1} \log\int p(\theta)^\alpha q(\theta)^{1-\alpha} d\theta
$$ It is known that the KL divergence is a particular case of Rényi divergence when $\alpha \rightarrow 1$. But what is the proof for that?","['statistics', 'divergence-operator', 'limits']"
2094629,Eigenvalue decomposition of non symmetric matrix,"Often in examples, eigenvalue decomposition $A=U\Lambda U^T$, $A$ is usually assumed to be a symmetric matrix. I am wondering what are the differences and implications when $A$ is a non-symmetric (still positive values if that helps). What can we say about the eigenvalues and eigenvectors of such decomposition?","['eigenvalues-eigenvectors', 'matrix-decomposition', 'spectral-theory', 'linear-algebra']"
2094657,Very interesting integral limit,"I found this interesting problem on AoPS forum but no one has posted an answer. I have no idea how to solve it. $$
\int_0^\infty \sin(x^n)\,dx
$$
  For all positive rationals $n>1$, $I_n$ denotes the integral as above. If $P_n$ denotes the product
  $$
P_n=\prod_{r=1}^{n-1}I_{\bigl(\!\frac{n}{r}\!\bigr)}\,,
$$
  then evaluate the following limit $L$
  $$
L=\lim_{n\to\infty}\bigl(\sqrt{n}\,P_n\bigr)^{\frac{1}{n}}
$$","['integration', 'calculus', 'limits']"
2094679,Generalizing the alternating series of the cubes of the reciprocals of odd numbers,"The series
$$
S_{1/2} := \sum_{k\in\mathbb Z} \frac{(-1)^k}{(2k+1)^3}
$$
can be summed using a rather standard trick, namely by defining a suitable meromorphic function
$$
f(z) := \frac{\csc(\pi z)}{(2z + 1)^3}
$$
and observing that its contour integral on an infinite-radius circle around the origin evaluates to both 0 (by asymptotic analysis) and $ 2\pi \mathrm{i}\left(S_{1/2}/\pi - \pi^2/16\right) $ (by the residue theorem ), which entails $ S_{1/2} = \pi^3/16 $. I am trying to use the same approach to compute a generalized version of that series,
$$
S_\alpha := \sum_{k\in\mathbb Z} \frac{\sin\left[(2k + 1)\pi\alpha\right]}{(2k+1)^3},
$$
which, I have reasons to believe, should be equal to $ S_\alpha = \pi^3\alpha (1-\alpha)/4 $. I can now proceed in a similar way as before and note that
$$
f_\alpha(z) := \frac{\sin\left[(2z + 1)\pi\alpha\right] \cot(\pi z)}{(2z + 1)^3}
$$
has the property that
$$
\lim_{n\to\infty} \frac{1}{2\pi\mathrm{i}} \oint_{C_n} f_\alpha(z)\,\mathrm{d}z = \frac{S_\alpha}{\pi} + \frac{\pi^2\alpha}{8},
$$
where $ {\{C_n\}}_n $ is a sequence of positive-oriented circles with radius going to infinity without ever intercepting any poles.
The problem is that the left hand side is not 0 anymore (because the integrand is now unbounded in the complex plane), so this does not give any useful information unless I am able to also compute the residue at infinity of $ f_\alpha $.
However, calculating the residue of $ f_\alpha(1/z)/z^2 $ is hard, because the function develops an essential singularity at $ 1/z = 0 $, and the residue itself ends up being expressed as a nasty series—much nastier-looking, in fact, than the one I was trying to compute in the first place. I would appreciate any help, whether a simple hint or a full solution, to crack this series. Thank you very much in advance.","['complex-analysis', 'sequences-and-series']"
2094682,Dimensions of image and kernel of a $n \times n$ matrix,"Let $K$ be a field, $V$ a vector space over $K$ of a finite dimension $n=dim_K(V)$. Let $f : V \rightarrow V$ be a  $K$-linear map and $\mathfrak{B}$ an ordered basis of $V$ with $$M_{f, \mathfrak{B}, \mathfrak{B}} = 
 \begin{pmatrix}
  0 & 1 & 1 & 1 & \cdots &1 \\
  0 & 0 & 1 & 1 &\cdots&1 \\
  0 & 0 & 0 & 1 & \cdots &1 \\
  \vdots  & \vdots  & \vdots & \ddots & \ddots & \vdots  \\
  &&&&&1\\
  0 & 0 & 0 & 0 & \cdots & 0 
 \end{pmatrix}$$ Side questions : Does this matrix have a name? Does the basis with the columns as vectors have a name? I need to calculate the dimensions of the image and the kernel of $f$, I know how to do it with a completely given matrix and basis, but without it I have problems. Any hints welcome.","['matrices', 'linear-algebra']"
2094732,Limit of $\sin 2^n$,"I am trying to show that
$$\lim_{n\to \infty}\sin 2^n$$
diverges for
$n \in \mathbb N$ I could show that assuming the limit converges, say to $L$ then $$L=\lim_{n\to \infty}\sin 2^{n+1}$$
$$=2\lim_{n\to \infty}\sin 2^n\lim_{n\to \infty}\cos 2^n$$
$$=2L\lim_{n\to \infty}\cos 2^n$$ It cannot be
$$\lim_{n\to \infty}\cos 2^n=\frac{1}{2}$$
since it implies
$$\frac{1}{2}=\lim_{n\to \infty}\cos 2^{n+1}$$
$$=2(\lim_{n\to \infty}\cos 2^n)^2-1$$
$$=-\frac{1}{2}$$
So either $$\lim_{n\to \infty}\sin 2^n=0$$
or it diverges. For the sequence to converge, necessarily it must be that $2^n$ gets  arbitrarily close to $m\pi$ for some integer $m(n)$ as $n$ goes to infinity, which seems counterintuitive. But I couldn't prove it, so anyone has some good idea?",['limits']
