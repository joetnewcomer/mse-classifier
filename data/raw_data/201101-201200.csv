question_id,title,body,tags
3949524,Compare $\ln(\pi)$ and $\pi-2$ without calculator,"Unlike the famous question of comparing $e^\pi$ and $\pi^e$ , which I solved almost instantly, I am stuck with this problem.  My thought was the following. Since exponential function is order-preserving, we exponentiate both terms and get $\pi$ and $e^{\pi-2}$ .  Then we study the function $f(x) = e^{x-2} - x$ or the function $g(x) = \frac{e^{x-2}}{x}$ , and compare them with zero and one respectively.  I tried both.  But both involve solving the equation $$e^{x-2} = x.$$ I tried Lagrange error terms and have $$f(x) = -1 + \frac{(x-2)^2}{2!} + R_2(x-2),$$ where $$\frac{(x-2)^3}{3!} \le R_2(x-2) \le \frac{e^{x-2}}{3!} (x-2)^3.$$ It is easy to see that the equation have a root between $3$ and $2 + \sqrt2$ .  But I don't know how close it is to $\pi$ .  It is to provide some lower bounds since we can plug in some values and calculate to show that $f(x) > 0$ for such values.  But for the upper bound, it is hard to calculate by hands since it has the $e^{x-2}$ factor.  At my best attempt by hand, I showed that $f(3.15) > 0$ .  All it entails is that for all $x \ge 3.15$ , $e^{x-2}$ is greater than $x$ .  But it tells nothing about the other side. Then I looked at the calculator and find that $e^{\pi-2} < \pi$ . I also tried Newton-Raphson iteration, but it involves a lot of exponentiation which is hard to calculate by hand and also involves approximation by themselves.  And I don't know how fast and close the iteration converges to the true root of the equation. Any other hint for comparing these two number purely by hand?","['calculus', 'approximation', 'numerical-methods']"
3949538,Number of arbitrary constants in an ODE,"Consider the general solution of a differential equation- $$y=(C_1+C_2)\cos(x+C_3)+C_4\exp(x)+C_5$$ Without differentiating this equation and finding the differential equation for it, how can we say what the order of that DE is. Ofcourse, we can always count the number of arbitrary constants, which in this case I think are $4$ (since $C_1+ C_2$ is just one ). But my textbook says that the DE has order $3$ . Am I missing something? I think my mistake is in not absorbing one more constant, which I tried doing in the following way- $$y=K (\cos C_3 \cos x-\sin C_3 \sin x)+C_4\exp(x)+C_5$$ and then we can also absorb the cosine and sine of $C_3$ . But even here, it appears to me that we still have $4$ constants.
Any help is appreciated.","['constants', 'ordinary-differential-equations']"
3949589,"$T_f:L^2[0,1] \to L^2[0,1]$ defined as $T_f=fg$ is bounded and compact only if $f=0$.","I am trying to solve the following problem: Let $f:[0,1] \to \mathbb{C}$ be a continuous function and $T_f:L^2[0,1] \to L^2[0,1]$ be the operator given by $T_f(g)=fg, \; g \in L^2[0,1].$ Prove that $T_f$ is a bounded linear operator on $L^2[0,1]$ and that $T_f$ is compact iff $f=0$ . Now, the linearity of $T_f$ follows by linearity of the usual operations. Indeed $$
T_f(\alpha g_1 + g_2)= f(\alpha g_1 + g_2)= \alpha fg_1 + fg_2= \alpha T_f g_1 + T_f g_2.
$$ For boundedness, we have that \begin{align*}
\|T_f\|^2_{L^2[0,1]} = \int_{0}^{1} |f|^2|g|^2 &\leq  \int_{0}^{1} |f|^2 \quad (\|g\|\leq 1) \\
&\leq \|f\|^2_{L^2[0,1]}.
\end{align*} Then if $f=0$ clearly $T_f$ is compact (being the range just $\{0\}$ ), but I am having trubles showing that if $f\neq 0$ then $T_f$ is not compact. Any help is appreciated.",['functional-analysis']
3949632,Moving exterior differential/derivative inside a wedge product,"Assumptions : Let $M$ be smooth $m$ -manifold. (If needed: Let $M$ be orientable and then oriented. Let $M$ be compact. Let $(M,g)$ be a Riemannian manifold.) Let $\Omega^jM$ be the set of smooth $k$ -forms on $M$ , for $j=0, 1, ..., m$ . Let $d_j: \Omega^jM \to \Omega^{j+1}M$ be exterior differential / derivative on $\Omega^jM$ (based on $d: \Omega(M) \to \Omega(M)$ , with $\Omega(M)$ $:= \bigoplus_{j=0}^{m} \Omega^jM$ ). Let $k \in \{0, 1, ..., m\}$ . Let $(\alpha, \gamma) \in \Omega^kM \times \Omega^{m-(k+1)}M$ . Observations : $d_k \alpha \wedge \gamma$ is a smooth top form (aka smooth $m$ -form) $(-1)^{1+k^2} \alpha \wedge d_{m-(k+1)}\gamma$ is a smooth top form (aka smooth $m$ -form) Question 1 : Assuming the above observations are correct, are they equal? Question 2 : In general, can we just move exterior differential/derivative through wedge products and just multiply $(-1)^{\text{something}}$ ? Question 3 : In anything above, are we assuming any additional things on $M$ like orientable/oriented/compact/Riemannian? Question 4 : If no to question 1, then do each of the 2 forms at least have equal integrals, i.e. the values we get when we plug each into $\int_M$ are equal? Here, we now suppose $M$ is orientable and then oriented and I guess compact (otherwise I guess we have to assume the forms have compact support or something). Context : This comes from some definitions and propositions leading to Hodge decomposition theorem, including the definition of Hodge star operator, but I'm trying to see if I understand the non-Hodge parts correctly. ( $\gamma$ is actually the image of some $\beta \in \Omega^{k+1}M$ under the Hodge-star operator.)","['differential-geometry', 'riemannian-geometry', 'derivatives', 'differential-forms', 'exterior-algebra']"
3949671,Is there any way to calculate $\binom{10}{1}-\binom{10}{3}+\binom{10}{5}-\binom{10}{7}+\binom{10}{9}$ faster?,"During solving a problem I get this expression: $$\binom{10}{1}-\binom{10}{3}+\binom{10}{5}-\binom{10}{7}+\binom{10}{9}$$ To calculate it normally, I do this way: $$\binom{10}{1}-\binom{10}{3}+\binom{10}{5}-\binom{10}{7}+\binom{10}{9}=2\binom{10}{1}-2\binom{10}{3}+\binom{10}{5}$$ And here we have to evaluate $\binom{10}{3}$ and $\binom{10}{5}$ . after all I got $32$ as the result correctly. My question: Is there any other way to calculate this expression easier (faster)? I suspect there is because the answer is $32=2^5$ and I guess maybe there is other way to calculate it for example by combinations or other ways.","['combinatorics', 'complex-numbers']"
3949708,Proving that this function is entire,"This question is from Ponnusamy and silvermann complex analysis Pg 436 . Question : Suppose that $0\leq |a_1|\leq  |a_2| \leq |a_3| \ldots \to \infty$ . Show that $\prod_{n=1}^{\infty} ( 1- z/a_n) e^{Q_n(z) }$ represents an entire function with $Q_n(z) = z/a_n + (z/a_n)^2/2 + \ldots + (z/a_n)^{[\ln n]}/[\ln n]$ . I attempted the question on the same lines as I attempted Show that This infinite product is entire When in last step I have to use Weierstrass Theorem, I got the series ${1/a_n}^{[\ln n]+1}$ . This series is to be proved convergent. But I am unable to prove it. I am uncertain on which result should I use. Please help with it. Rest of details of solutions I checked and They are correct.","['complex-analysis', 'entire-functions', 'sequences-and-series']"
3949765,"Integration of $e^{-\langle Ax , x \rangle}$ over $\mathbb{R}^n$ [duplicate]","This question already has answers here : If $A$ is positive definite, then $\int_{\mathbb{R}^n}\mathrm{e}^{-\langle Ax,x\rangle}\text{d}x=\left|\det\left({\pi}^{-1}A\right)\right|^{-1/2}$ (3 answers) Closed 3 years ago . Problem : If $A_{n \times n}$ is a symmetric, positive-definite matrix, show that : $$\int_{\mathbb{R}^n} e^{-\langle Ax , x \rangle}~ dx = \sqrt{\dfrac{\pi^n}{\det(A)}}$$ where $\langle a , b\rangle$ denotes the inner product of $a$ and $b$ . Approach : I was approaching the problem using the Change of Variable Formula, using the function $\varphi(x) = A^{-1}x$ . Since $A$ is p.d., I can show that it is invertible. But I can't proceed anymore. I found a similar-looking problem here , but couldn't understand anything.","['integration', 'multivariable-calculus', 'linear-algebra']"
3949776,"Equivalency between a ""mixed modular equation"" of Gauss and a later theorem of Ramanujan.","In p. 476 of volume 3 of Gauss's collected works, appear several interesting identities on Jacobi theta functions which were used by the czech mathematician Karel Petr in an 1904 article "" Bemerkung zur einer Gausschen Formel Ã¼ber die Thetafunktionen ""  to derive relations giving the number of representations of a number $N$ by three quaternary quadratic forms: $x^2 + y^2 + 9z^2 + 9u^2$ , $x^2+y^2+z^2+9u^2$ , $x^2+9y^2+9z^2+9u^2$ . The identities by Gauss are: $$(\frac{3P^2-P^0\cdot P^0}{2})^2= p^4-4(\frac{pqr}{2})^{\frac{4}{3}}$$ $$(\frac{3Q^2-Q^0\cdot Q^0}{2})^2=q^4+4(\frac {pqr}{2})^{\frac{4}{3}}$$ where the relevant quantities are defined to be: $$P(x^3,1)=P , P(x,1)=p, P^0=P(x^{\frac{1}{3}},1)$$ $$Q(x^3,1)=Q , Q(x,1)=q, Q^0 = Q(x^{\frac{1}{3}},1)$$ $$R(x^3,1)=R , R(x,1)= r$$ and the three functions $P(x,y),Q(x,y),R(x,y)$ are equivalent to Jacobi's theta functions $\vartheta_3,\vartheta_4,\vartheta_2$ and defined to be: $$P(x,y)=1+x(y+\frac{1}{y})+x^4(y^2+\frac{1}{y^2})+x^9(y^3+\frac{1}{y^3})+...$$ $$Q(x,y)= 1-x(y+\frac{1}{y})+x^4(y^2+\frac{1}{y^2})-x^9(y^3+\frac{1}{y^3})+...$$ $$R(x,y)=x^{\frac{1}{4}}(y^{\frac{1}{2}}+y^{-\frac{1}{2}})+x^{\frac{9}{4}}(y^{\frac{3}{2}}+y^{-\frac{3}{2}})+x^{\frac{25}{4}}(y^{\frac{5}{2}}+y^{-\frac{5}{2}})+...$$ To see the equivalency between Gauss's notation and Jacobi's theta functions, look at the post Interpretation of a certain general theorem used by Gauss in his work on theta functions. . User Paramanand Singh helped me understand the meaning of Gauss's identities and remarked that they are essentialy a ""mixed modular equation"" which connects theta functions of $x^{\frac{1}{3}},x,x^3$ (or, equivalently, $\tau,\tau^3,\tau^9$ ), and said that Ramanujan also gave this modular equation. According to Paramanand Singh's comments, the following identity (from p. 142 of the book "" pi and the AGM "") of Ramanujan is equivalent to Gauss's: $$\frac{\theta_3(q)}{\theta_3(q^9)} - 1 = (\frac{\theta_3^4(q^3)}{\theta_3^4(q^9)}-1)^{\frac{1}{3}}$$ However, he didn't provide proof of equivalency. Therefore, it's not certain this is the desired identity of Ramanujan, and it's not even certain that Ramanujan stated an equivalent identity at all. Therefore, my questions are: Can anyone familiar with Ramanujan's results on mixed modular equations say which of Ramanujan's theorems is equivalent to Gauss's identities? and where can i find the relevant fragment of Ramanujan's writings on the internet? Can someone also give a proof of equivalency between Ramanujan's theorem and Gauss's identities? this doesn't have to be a proof of correctness of Gauss's identities (which can be quite complicated), just a proof of equivalency to Ramanujan's theorem.","['complex-analysis', 'theta-functions', 'math-history']"
3949835,"If $\mathcal{L}$ is an invertible sheaf on $\mathbb{P}(\mathcal{E})$, then is the restriction to the fibers constant?","Let $X$ be a Noetherian regular scheme, and $\mathcal{E}$ a locally free sheaf of rank $n+1\geq 2$ on $X$ . Let $\pi:\mathbb{P}(\mathcal{E})\to X$ be the natural morphism. Then for every $x\in X$ , the fiber of $\pi$ over $x$ is isomorphic to $\mathbb{P}_{k(x)}^n$ . So if $\mathcal{L}$ is an invertible sheaf on $\mathbb{P}(\mathcal{E})$ , then for every $x$ we get a unique integer $n_x=n_x(\mathcal{L})$ such that the restriction of $\mathcal{L}$ to $\mathbb{P}_{k(x)}^n$ is $\mathcal{O}_{\mathbb{P}_{k(x)}^n}(n_x)$ . Then is it true that $x\mapsto n_x$ is constant? How could one prove this elementarily? Some thoughts: if $U=\operatorname{Spec}A$ is an affine open subset which trivializes $\mathcal{E}$ , then $\pi^{-1}(U)\cong \mathbb{P}_A^n$ . So if we can show the statement in this much simpler case, then we already obtain that $x\mapsto n_x$ is locally constant.","['algebraic-geometry', 'projective-schemes', 'sheaf-theory']"
3949914,What is the maximum possible value of $E[X_1 X_2 X_3]$?,"Assume $X_1,X_2,X_3$ are discrete random varibles defined on a common probability space $\Omega$ and taking values in $\{-1,1\}$ . Further, assume that $E[X_1]=E[X_2]=E[X_3]=E[X_1 X_2]=E[X_2 X_3]=E[X_3 X_1]=0$ . Given this, what is the maximum possible value of $E[X_1 X_2 X_3]$ ? It's easy to see that $P(X_i=\pm 1)=P(X_i X_j = \pm 1)={1 \over 2}$ for each $i,j \in I_3 (i \neq j)$ . But how do I progress further? Any help would be appreciated.","['expected-value', 'inequality', 'probability', 'random-variables']"
3949949,Question regarding second derivatives and maximums. Justifying a specific part,"Note: My question is regarding the bolded parts. Read those and my explanation below to see what I am asking. Let $f$ be a real-valued function on an open subset $U$ of $R$ that is twice differentiable at $x_0 \in U$ . Show that if $f'(x_0) = 0$ and $f''(x_0) < 0$ , then the restriction of $f$ to some open ball of center $x_0$ attains a maximum at $x_0$ . Here is my proof To show there is a maximum, we want to show that $f(x) < f(x_0) + f'(x_0)(x - x_0) \ \forall x \neq x_0, x_0 \in U$ Case 1.) Assume $x < x_0$ . Applying the Mean Value Theorem on the interval $[x,x_0], \exists c \ where \ x < c < x_0 \ s.t.$ $f(x_0) - f(x) = f'(c)(x_0 - x)$ $f(x) = f(x_0) - f'(c)(x_0 - x)$ $f(x) = f(x_0) + f'(c)(x - x_0)$ Since $f''(x) < 0 \forall x \in U, f'(x)$ must be decreasing. Since we know from the MVT that $c < x_0$ , we can put these results together to have. $f'(x_0) < f'(c)$ Multiplying this by $x - x_0$ (which is negative, so flip the inequality), $f'(c)(x - x_0) < f'(x_0)(x - x_0)$ Adding $f(x_0)$ to both sides, $f(x_0) + f'(c)(x - x_0) < f(x_0) + f'(x)(x - x_0)$ The left side is $f(x)$ $f(x) < f(x_0) + f'(x)(x - x_0)$ as desired. Case 2.) Assume $x_0 < x$ . Using the MVT on the interval $[x_0,x], \exists d \ where \ x_0 < d < x_0 \ s.t.$ $f(x) - f(x_0) = f'(c)(x - x_0)$ $f(x) = f(x_0) + f'(c)(x - x_0)$ Similar to before, $f''(x) < 0$ means $f'(x)$ is decreasing. We know from this application of MVT that $x_0 < c$ Therefore, $f'(c) < f'(x_0)$ Multiplying by $x - x_0$ (positive this time) $f'(c)(x - x_0)) < f'(x_0)(x - x_0)$ Adding $f(x_0)$ , $f(x_0) + f'(c)(x - x_0) < f(x_0) + f'(x_0)(x - x_0)$ The left side is $f(x)$ $f(x) < f(x_0) + f'(x_0)(x - x_0)$ still holds. So we have shown that $\forall x \in U \ s.t. \ x \neq x_0$ , the function will be concave down. Therefore, it has a maximum at $x_0$ I bolded the parts that were unclear. My professor told me that this is not necessarily true. The function will admit a negative second derivative at $x_0$ , but not in the entire neighborhood. He said in this case, what I did is correct, but he said it is not obvious as to why. He said I have to say something about why I can make that claim. Can someone help me figure out what I can say to make that part clear? I'm not seeing it right now.
Edit: I am thinking it maybe due to the fact that I'm claiming this happens on all of R. So like, the neighborhood wouldn't really matter? But then again, I feel like that would be trivial, so I don't think he would ask the question. I think I just defined it that way. I'm really not sure. Please, any help is appreciated!
Thanks in advance!","['maxima-minima', 'calculus', 'derivatives', 'real-analysis']"
3949970,The union of two simple planar graph have chromatic number $\leq 12$,"Consider of graph $G$ being the union of two simple planar graph both on the same set of vertices. I want to show $\chi(G) \leq 12$ . Four colour theorem indicates that the chromatic number of a planar graph is less than 4, and for general graphs $\chi(G1 \cup G2) \leq \chi(G1)*\chi(G2)$ .  But this would only yield an upper bound of 16. Is there anything particular to planar graph that helps to reduce the bound?","['graph-theory', 'discrete-mathematics']"
3950016,isomorphism between $\mathbb H P^1$ and $S^4$,"Let $G\subset \mathbb H$ be the Lie groups of unit quaternions that acts from the right on $S^7:=\{(q_1,q_2)\in \mathbb H^2: |q_1|^2+|q_2|^2=1\}$ . If $S^4:=\{(q,x)\in \mathbb H\oplus \mathbb R: |q|^2+x^2=1\}$ , I want to prove that the map $f:S^7/G\to S^4$ defined by $$f([q_1,q_2]):=(2q_1\overline{q_2}, |q_1|^2-|q_2|^2)$$ is a diffeomorphism. Proving that it's well defined is trivial but the bijectivity is already tricky. I tried to find the inverse but i can't find it.
Another way is through $\mathbb H P^1$ : It's not difficult to prove that $S^7/G\cong \mathbb H P^1$ but i can't prove that $\mathbb H P^1\cong S^4$ . Any help?","['general-topology', 'quaternions', 'lie-groups', 'differential-geometry']"
3950044,$\prod_{n=1}^{\infty} (1- z/ a_n) $ is entire iff $\sum_{n=1}^{\infty} 1/(z-a_n) $ is meromorphic,This question was asked in a masters exam previous year paper and I was unable to prove it. Show that the $$\prod_{n=1}^{\infty} (1- \frac{z}{a_{n}}) $$ is entire iff $$\sum_{n=1}^{\infty} \frac{1}{z-a_n} $$ is meromorphic. $\prod_{n=1}^{\infty}( 1- \frac{z}{a_{n}})$ is entire if Convergence of infinite product is uniform and that happens if: $$\sum_{n=1}^{\infty} \frac{z}{a_{n}}$$ converges for all z. But I am not able to correlate it with: $$\sum_{n=1}^{\infty} \frac{1}{z-a_n} $$ . Can you please help by telling which result should be helpful. Thank you!,"['complex-analysis', 'entire-functions', 'meromorphic-functions']"
3950070,Unit quarternion as rotation in $\mathbb{R}^3$,"I'm pretty confused by the following statement on page 6 in the book The Seiberg-Witten Equations and Applications to the Topology of Smooth Four-Manifolds , which is meant to expain the fact that unit sphere $S^3$ in the quarternion algebra $\mathbb{H}$ is naturally associated with the group of rotation in $\mathbb{R}^3$ : I don't think the statemet is true at the very first place, $\alpha$ does not act trivially on $\mathbb{C}\alpha$ , since by that we require for any complex number $z$ , the equation $\alpha (z \alpha) \alpha^{-1}=z \alpha$ , i.e. $$\alpha z \alpha^{-1}=z$$ i.e. we need $\alpha$ commutes with any $z$ . But this is not even true for $j \in S^3$ and $i \in \mathbb{C}$ . Can anyone tells me where I went wrong?","['group-theory', 'abstract-algebra', 'quaternions']"
3950130,"Prove that $f: X \rightarrow Y$ is one-to-one, if and only if : $g: P(Y)\rightarrow P(X)$ , $g(Y)= \{ x\in X : f(x)\in Y \} $ is onto","My attempt (for first direction), I said that suppose that $f$ is one-to-one and $g$ is not onto, then there exists $X'\subset X$ , such that for all $Y'\subset Y$ : $g(Y')\ne X$ then if $f$ is one to one : $\forall x\in X, \exists! y\in Y : f(x)=y $ hence there must be a subset $Y'\subset Y$ that satisfies $g(Y')=X'$ which contradicts that $g$ is not onto. but I really think I have made some mistakes since looking at it again I could have proved it in the same way without $f$ being one to one.
Any help or corrections or answers are appreciated.
Thanks in advance!","['functions', 'discrete-mathematics']"
3950165,Implicit Differentiation + Related Rates,"I have a very simple question, but different methods lead me to different solutions which is where I am confused. (Q) Obtain a relationship for change between circumference $C$ and the area $A$ of a circle over time. $
A = \pi r^2 \\
C = 2\pi r
$ Method 1: So $A = \frac{1}{4\pi}C^2$ after substituting $r$ in terms of $C$ . Then implicit differentiation gives us $\frac{dA}{dt} = \frac{1}{2\pi} \cdot \frac{dC}{dt}$ Method 2: Differentiating the first two equations, we have $\frac{dA}{dt} = 2\pi r \frac{dr}{dt}$ and $\frac{dC}{dt} = 2 \pi \frac{dr}{dt}$ respectively. Then I isolated for $\frac{dr}{dt}$ in the second equation here and substituted into the first equation resulting in the relation $\frac{dA}{dt} = 2\pi r \left(\frac{1}{2\pi} \cdot \frac{dC}{dt}\right) = r \frac{dC}{dt}$ . I believe the second method is incorrect; however, I am unsure why it is incorrect. If there is any reading that might solidify my knowledge in terms of related rates/implicit differentiation, I would appreciate it.","['related-rates', 'implicit-differentiation', 'derivatives', 'geometry']"
3950171,Countour Integration,"I had to evaluate this integral $ \int_{-\infty}^{\infty} \frac{x \sin(x)}{x^2 - b^2}dx  $ , according to Wolfram this had the following result $$ \int_{-\infty}^{\infty} \frac{x \sin(x)}{x^2 - b^2}  dx= \pi e^{ib}$$ However, when I integrated it: $$\oint_C f(z) dz = \oint_{\gamma_{1}} f(z) dz + \oint_{\gamma_{2}} f(z) dz + \oint_{\Gamma} f(z) dz $$ The last term goes to zero applying Jordan's Lemma and to get the result of the integral over $\gamma_{1}$ and $\gamma_{2}$ , in which $\gamma_{1}$ is the contour over the first pole and $\gamma_{2}$ is the contour over the second pole. So, I get $$\oint_{\gamma_{1}} f(z) dz = i \pi  \lim_{z \rightarrow -b} \frac{z \sin(z)}{(z-b)(z+b)}(z+b) =  i \pi \frac{\sin(-b)}{-2} $$ and $$\oint_{\gamma_{2}} f(z) dz = i \pi  \lim_{z \rightarrow b} \frac{z \sin(z)}{(z-b)(z+b)}(z-b) =  i \pi \frac{\sin(b)}{2} $$ The result that I'm getting is: $$\oint_C f(z) dz = i \pi \left( \frac{\sin(b)}{2} - \frac{\sin(-b)}{-2} \right) = \frac{\pi}{2} \left( e^{ib} - e^{-ib} \right)$$ That according to Wolfram is not the correct result. What am I doing wrong? Edit: In this case, I used $$f(z) = \frac{z \sin(z)}{z^2 - b^2}$$ Edit 2: Edit 3: Using @Ted Shifrin 's suggestion to change $f(z)$ to a more well-behaved function when $|z|$ is very large, I got: $f(z) = \frac{z \exp(iz)}{z^2 - b^2}$ So, I get $$\oint_{\gamma_{1}} f(z) dz = i \pi  \lim_{z \rightarrow -b} \frac{z \exp(iz)}{(z-b)(z+b)}(z+b) =  i \pi \frac{\exp(-ib)}{2} $$ and $$\oint_{\gamma_{2}} f(z) dz = i \pi  \lim_{z \rightarrow b} \frac{z \exp(iz)}{(z-b)(z+b)}(z-b) =  i \pi \frac{\exp(ib)}{2} $$ The result that I'm getting is: $$\oint_C f(z) dz = i \pi \left( \frac{\exp(ib)}{2} + \frac{\exp(-ib)}{2} \right) = i \pi \cos(b)$$ and in conclusion: $$\int_{-\infty}^{\infty} \frac{x \sin(x)}{x^2 - b^2}dx = \Im(i \pi cos(b)) = \pi \cos(b) $$ I still don't understand, according to some of you this integral doesn't converge how do I prove that? This result is equal to @FelixMarin 's result and he used another method of integration, but is different of Wolfram's result and assuming that $b \in \Re $ this integral is supposed to diverge. What am I missing?","['integration', 'complex-analysis', 'contour-integration', 'improper-integrals']"
3950193,Solve the differential equation: $\frac{dy}{dx}=1 + a\frac{y}{x}$,What are the steps to get to $y(x)$ ? $$\frac{dy}{dx}=1 + a\frac{y}{x}$$,['ordinary-differential-equations']
3950308,Differential equation system solution: do I get the right solution?,"I am very stuck with differential equation systems. For example: $
Y'(x) = 
    \begin{pmatrix}
    2 & 0 & 1 \\
    0 & 2 & 0 \\
    0 & 1 & 3 \\
    \end{pmatrix}
Y(x)
$ I get the eigenvalues and eigenvectors: $ \lambda = 2  (double)  \rightarrow   \vec v_{\lambda2} =  \begin{pmatrix}
    1 \\
    0 \\
    0 \\
    \end{pmatrix}
$ and $ \lambda = 3   \rightarrow   \vec v_{\lambda3} =  \begin{pmatrix}
    1 \\
    0 \\
    1 \\
    \end{pmatrix}
$ I obtain just one vector asociated with $ \lambda = 2 $ value, so that I suppose I've to get another vector. For this eigenvalue: $ (A-\lambda I) = \begin{pmatrix}
    0 & 0 & 1 \\
    0 & 0 & 0 \\
    0 & 1 & 1 \\
    \end{pmatrix}
$ So that the vector I'm looking must meet: $
\begin{pmatrix}
    0 & 0 & 1 \\
    0 & 0 & 0 \\
    0 & 1 & 1 \\
    \end{pmatrix}
\begin{pmatrix}
    v_{x} \\
    v_{y} \\
    v_{z} \\
    \end{pmatrix}
=
\begin{pmatrix}
    1 \\
    0 \\
    0 \\
    \end{pmatrix}
$ From doing this I get: $
\begin{pmatrix}
    v_{x} \\
    v_{y} \\
    v_{z} \\
    \end{pmatrix}
\sim
\begin{pmatrix}
    \alpha \\
    -1 \\
    1 \\
    \end{pmatrix}
$ , and I choose the vector $
\begin{pmatrix}
    0 \\
    -1 \\
    1 \\
    \end{pmatrix}
$ The problems come from this point. I think the general solution should be: $
y(x) = C_{1}
\begin{pmatrix}
    1 \\
    0 \\
    0 \\
    \end{pmatrix}
e^{2x}
+
C_{1}x
\begin{pmatrix}
    1 \\
    0 \\
    0 \\
    \end{pmatrix}
e^{2x}
+
C_{2}
\begin{pmatrix}
    0 \\
    -1 \\
    1 \\
    \end{pmatrix}
e^{2x}
+
C_{3}
\begin{pmatrix}
    1 \\
    0 \\
    1 \\
    \end{pmatrix}
e^{3x}
$ But this result is wrong. I've tried to proove it and it doesn't work. I've read in some books about it but I think I'm following the mathematic method fine...
Does anyone know what I'm doing wrong? Thanks in advance.","['systems-of-equations', 'ordinary-differential-equations']"
3950314,"Sequence space s (Functional analysis, Kreyszig)","I'm reading Kreyszig's functional analysis book, in which are the following example: $\textbf{1.2-1 Sequence space s.}$ This space consists of the set of all (bounded or unbounded) sequences of complex numbers and the metric $d$ defined by $$
{d(x,y) = \sum_{j=1}^{\infty} \frac{1}{2^j}\frac{|\epsilon_{j}-\eta_{j}|}{1 + |\epsilon_{j}-\eta_{j}|}},
$$ where $x = (\epsilon_{j})$ and $y = (\eta_{j})$ . Could you give me more references about this sequence space (I didn't find any on the Internet by this name), or about metric spaces like this (namely, defined by series)? Note: Much more, better, because I'm a beginner in functional analysis.","['reference-request', 'functional-analysis', 'analysis', 'sequences-and-series']"
3950347,"Question about the proof of Theorem D.5, Introduction to Smooth Manifolds by Lee","I am trying to understand the proof of the following theorem from Lee's ""Introduction to Smooth Manifolds"": The following statement is in the proof: Question: What I don't see is how $\frac{2\epsilon e^{CT}}{E}\cdot(e^{ET}-1)$ can be made as small as desired by choosing $h$ and $\tilde{h}$ sufficiently small. How does the expression depend on $h$ and $\tilde{h}$ ? To me it looks like an upper bound. The only idea I have is the following: There is the following statement Let $k\in\mathbb{N}$ such that $k>\frac{2e^{CT}}{E}\cdot(e^{ET}-1)$ and $\tilde{\epsilon}:=\frac{\epsilon}{k}$ ,  and $\epsilon$ as above.
By the above statement I can find a $\tilde{\delta}$ such that $|y_{1}-y_{2}|<\tilde{\delta}$ implies \begin{align}
|\frac{\partial V^{i}}{\partial y^{k}}(y_{1})-\frac{\partial V^{i}}{\partial y^{k}}(y_{2})|<\tilde{\epsilon}=\frac{\epsilon}{k}
\end{align} Now the book says I would instead say ""Suppose that $h$ and $\tilde{h}$ are both less than $\frac{\tilde{\delta} e^{-CT}}{n}$ "". From here on I would proceed exactly as in the book to end up with the inequality \begin{align}
|\Delta_{h}(t,x)-\Delta_{\tilde{h}}(t,x)|\leq...\leq\frac{2\tilde{\epsilon} e^{CT}}{E}\cdot(e^{ET}-1)=\frac{2\epsilon e^{CT}}{k\cdot E}\cdot(e^{ET}-1)<\epsilon
\end{align} Does the statement ""choosing $h$ and $\tilde{h}$ sufficiently small  "" refer to the line "" $h$ and $\tilde{h}$ are both less than $\frac{\delta e^{-CT}}{n}$ "" ? I hope this makes any sense. Thank you very much in advance!","['manifolds', 'ordinary-differential-equations', 'differential-geometry']"
3950414,'Proof' that $f''(x)=\frac{f'(x)}{x}$,Consider the following: $$f''(x)=\lim_{h\to0}\frac{f'(x+h)-f'(x)}{h}$$ Now using L'Hopital's rule (as this is a case of an inderterminate) we have $$f''(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{hx}$$ But this is $$\frac{1}{x}\lim_{h\to0}\frac{f(x+h)-f(x)}{h}$$ which is $\frac{1}{x}f'(x)$ . So it would seem that $$f''(x)=\frac{f'(x)}{x}$$ which is quite obviously false. Where is my error? Thanks in advance.,"['limits', 'calculus', 'derivatives', 'fake-proofs']"
3950538,"Suppose $|A|=n, f:A\to A$ is injective $\implies \exists k\in [n]:f^k(x)=x$","My Attempt Case 1 Suppose $f:A \to A$ is an identity function. then $k=1\in [n]:f(x)=x$ . Case 2 Suppose $f:A \to A$ is an injective function and non identity function. so, there exists $x\in A$ such that $f(x) \neq x.$ So, there are $n-1$ possibilities for $f(x).$ if $f(f(x))=x, $ then $k=2.$ so on. I am not able to complete the proof. Is my method correct?","['graph-theory', 'functions', 'combinatorics', 'real-analysis']"
3950580,Prove $\frac{( 4n+5 ) ( ( 2n+2 )! ) ^2}{2}( \int_{-1}^1{f( x ) \text{d}x} ) ^2\le \int_{-1}^1{( f^{( 2n+2 )}( x ) )^2 \text{d}x}$,"Let $f \in C^{2n+2}[-1,1]$ , and $$
f\left( 0 \right) =f''\left( 0 \right) =\cdots =f^{\left( 2n+2 \right)}\left( 0 \right) =0
$$ Prove that $$
\frac{\left( 4n+5 \right) \left( \left( 2n+2 \right) ! \right) ^2}{2}\left( \int_{-1}^1{f\left( x \right) \text{d}x} \right) ^2\le \int_{-1}^1{\left( f^{\left( 2n+2 \right)}\left( x \right) \right)^2 \text{d}x}
$$ I even don't know how to deal with the basic circumstances, such as when $n=0$ , we have $$
10\left( \int_{-1}^1{f\left( x \right) \text{d}x} \right) ^2\le \int_{-1}^1{\left( f''\left( x \right) \right) ^2\text{d}x}
$$ I tried to apply CauchyâSchwarz inequality and Integration by parts , but they didn't work. Also I think the general formula may relate to Taylor series since it has factorials on the left side. Can anyone help?","['inequality', 'analysis', 'real-analysis']"
3950617,Solve $\frac{d^2y}{dx^2}+y=\frac{1}{y^3}$,"Solve the equation, $$\frac{d^2y}{dx^2}+y=\frac{1}{y^3}$$ We have $$y^3\frac{d^2y}{dx^2}+y^4=1$$ I tried using change of dependent variable Let $z=y^3\frac{dy}{dx}$ Then we get $$y^3\frac{d^2y}{dx^2}+3y^2\left(\frac{dy}{dx}\right)^2=\frac{dz}{dx}$$ But i could not get an equation completely involving $z,x$","['nonlinear-system', 'algebra-precalculus', 'ordinary-differential-equations']"
3950632,Solving $\sin\left(2x\right)+5\bigl(\sin\left(x\right)+\cos\left(x\right)\bigr)+1=0$,"I attempted to do this trig problem I have written below with steps I took to reach an answer. Did I do this correctly? $$\sin\left(2x\right)+5\bigl(\sin\left(x\right)+\cos\left(x\right)\bigr)+1=0$$ using the well known identity: $\sin^2\left(x\right)+\cos^2\left(x\right)=1$ , I get: $$\color{red}{\sin\left(2x\right)}+5\bigl(\sin\left(x\right)+\cos\left(x\right)\bigr)+\color{red}{\sin^2\left(x\right)+\cos^2\left(x\right)}=0$$ Then I see that the ""red"" is just $\bigl(\sin\left(x\right)+\cos\left(x\right)\bigr)^2$ , so $$\bigl(\sin\left(x\right)+\cos\left(x\right)\bigr)^2+5\bigl(\sin\left(x\right)+\cos\left(x\right)\bigr)=0$$ Then I let $u=\sin\left(x\right)+\cos\left(x\right)$ , I get $$u^2+5u=0$$ $$u=0,\:\text{and}\:u=-5$$ removing $u=-5$ as no solution, leaving just $u=0$ as the only solution, plugging back into the defined "" $u$ "", $$0=\sin\left(x\right)+\cos\left(x\right)$$ $$\sin\left(x\right)=-\cos\left(x\right)$$ $$\tan\left(x\right)=-1$$ the solution I get is $$x=\frac{3\pi }{4}+\pi n$$ No need to see if there are any extraneous solutions since the function is continuous. Thanks for any feedback!","['algebra-precalculus', 'solution-verification', 'trigonometry']"
3950704,integral representation of matrix logarithm,"Consider the following integral representation of $ln(X)$ : $$\ln(X) = \int_{0}^{\infty}[\frac{1}{1+t}I - (X+tI)^{-1}]dt.$$ I do not understand how they derived this formula. The only formula I found is $\ln(A) = (A-I)\int_{0}^{1}[s(A-I)+I]^{-1}ds$ from page 13 in the link http://scipp.ucsc.edu/~haber/ph251/exp19.pdf I appreciate if someone could send a reference of this formula, or its derivation. Thank you","['integration', 'matrices']"
3950705,Silverman *Arithmetic of Elliptic Curves* Problem 1.12 (a),"I am trying to understand Problem 1.12 (a) in Silverman's Arithmetic of Elliptic Curves . Here is the problem Let $K$ be a perfect field, $V/K$ be an affine variety, and let $G_K = \operatorname{Gal}(\overline{K}/K)$ . Prove that $K[V] = \{f\in\overline{K}[V]:f^\sigma=f\;\;\forall\sigma\in G_K\}$ . Here is the hint: the $\subset$ direction is clear. Conversely, if $F\in\overline{K}[X]$ is a representative of $f$ , the map $G_K\to\mathcal{I}(V)$ via $\sigma\mapsto F^\sigma-F$ is a 1-cocycle (indeed, if $f^\sigma=f$ in $\overline{K}[V]$ , then $F^\sigma-F\in\mathcal{I}(V)$ and $F^{\sigma\tau}-F = (F^{\sigma}-F)^\tau+ (F^\tau-F)$ ). It's the next point that I do not understand. Using $H^1(G_K,\overline{K}^+) = 0$ , I'm supposed to deduce that there is some $G\in\mathcal{I}(V)$ such that $F+G\in K[X]$ . I see that this would solve the problem, since in that case $f = (F+G)+\mathcal{I}(V)\in K[V]$ . Here's what I don't understand. Since $H^1(G_K,\overline{K}^+) = \frac{Z^1(G_K,\overline{K}^+)}{B^1(G_K,\overline{K}^+)}$ , so if $H^1 = 0$ , this means $Z^1(G_K,\overline{K}^+) = B^1(G_K,\overline{K}^+)$ , so the function $\sigma\mapsto F^\sigma-F$ out to come from a boundary. Question 1: It seems that $\sigma\mapsto F^\sigma-F$ is already in $B^1(G_K,\overline{K}^+)$ by definition, so how am I supposed to use the condition that $H^1 = 0$ ? Question 2: In addition, it seems to me that $H^1(G_K,\overline{K}^+)$ is also the wrong group to be looking at. We're treating $\overline{K}[X]$ as an additive $G_K$ -module, not $\overline{K}^+$ , so shouldn't I be looking at $H^1(G_K,\overline{K}[X])$ or $H^1(G_K,\overline{K}[V])$ ? Any elucidation would be much appreciated.","['algebraic-geometry', 'galois-cohomology']"
3950829,Height of a cube edge from the floor,"A cube $ABCD.EFGH$ has side length $2a$ cm. Point $A$ is lifted $a$ cm from the floor, point $C$ is still on the floor, point $B$ and point $D$ are on the same height from the floor. What is the height of point $E$ from the floor? I'm sorry for my bad English, but I try to illustrate it as follows. The left cube is the original one while the right side is the cube after we lifted the point $A$ . In my mind, to find the height of point $E$ from the floor is to find the length of line $EN$ . We can use Pythagorean theorem $EN^2=ME^2-MN^2$ . But how to find the length of line $ME$ and $MN$ ?","['triangles', 'pythagorean-triples', 'geometry']"
3951000,Gaussian space generated by Gaussian process,"I have a somewhat silly question after reading the following definition in Brownian motion, martingales and stochastic calculus by Jean-FranÃ§ois Le Gall Proposition 1.7 If $(X_t)_{t\in T}$ is a Gaussian process, the closed linear subspace of $L^2$ spanned by the variables $X_t, t\in T$ , is a Gaussian space, which is called the
Gaussian space generated by the process $X$ . My question is: how do we prove that this space is closed? If I denote this space by $G$ , and I take a sequence $(Y_n)_{n\in\mathbb{N}}$ in $G$ that converges to some $Y\in L^2$ , I can show that $Y$ is a centered Gaussian. But how do I show that $Y$ is a linear combination of the $(X_t)_{t\in T}$ ?","['hilbert-spaces', 'probability-theory', 'linear-algebra', 'functional-analysis']"
3951052,groups of conics,"Let $\mathcal{C}$ be a conic on the projective plane $PG(2,\mathbb{F})$ where $\mathrm{char}\mathbb{F}\neq 2$ . Let $\ell$ be a line and let $N$ be a point on $\mathcal{C}\setminus \ell$ . For $A,B\in \mathcal{C}$ , let $L_{AB}=AB\cap \ell$ . Prove that the following operation defines an abelian group $G$ on $\mathcal{C}\setminus\ell$ : $$A \circ B =\begin{cases} 
      N, & \text{ if } L_{AB}N \text{ is the tangent at } N \text{ on  }\mathcal{C} \\
      M, & \text{ if } L_{AB}N = \{N,M\}
   \end{cases}.$$ Further show that if $\ell$ intersects the conic in one point (tangent) then $G$ is the additive group of $\mathbb{F}$ $\ell$ intersects the conic in two points (secant) then $G$ is the multiplicative group of $\mathbb{F}$ Proof. Here is a figure where $A\circ B$ equals a point $M$ and $A\circ C$ equals the point $N$ . For the first part I can easily show closure, abelianity, identity (which is $N$ ) and inverses. I am a bit stuck on the associative part $(A\circ B)\circ C = A\circ (B\circ C)$ . Let $A\circ B = M_1$ and $B\circ C = M_2$ . I thought we can use Pascal's theorem to show that $M_1C$ is parallel to $AM_2$ but I am not sure how to continue.
The second part of the exercise is not clear to me at all. Has anyone seen this type of group construction before? I've been looking at literature and cannot find anything else. Update: The group part is done, and now we have to consider the cases when $\ell$ is a tangent and when $\ell$ is a secant. I think we can use the parabola and hyperbola for these cases and then use the fact that we can map conics to parabola and hyperbola - we usually do things like this but not sure how to continue.","['group-theory', 'abstract-algebra', 'conic-sections', 'finite-geometry']"
3951059,Does a bounded from below linear operator with target set equal to the domain always have closed image?,"I'm using the definition of a bounded from below linear operator as a linear operator $X\overset{T}{{\to}}Y$ , where $X$ and $Y$ are Banach spaces and the operator satisfies: for all $x \in X$ , $\lVert T(x) \rVert \geq C \lVert x \rVert$ , for some constant $C \gt 0$ . In this question i will refer only to such an operator in a Banach space $B$ , $ T \colon B{{\to}}B$ . Note that I don't assume it to be continuous. With only these conditions, can we guarantee that the image of $T$ is closed in $B$ ? (Which is equivalent to asking if these assumptions imply continuity of the operator, by the open mapping theorem applied to the inverse of the operator, which exists since $\lVert T(x) \rVert = 0 \Rightarrow \lVert x \rVert = 0$ ). I have tried to prove that it is closed with only these conditions and checked out other posts that have similar questions, but they don't seem to answer this one, at least in an immediate way. At this point, I believe that it is not generally true, but I also haven't been able to write a counter-example. I appreciate any help and thank you in advance!","['banach-spaces', 'functional-analysis', 'linear-transformations']"
3951082,Use Mittag-Leffler to prove Weierstrass Factorization Theorem,"Use the Mittag-Leffler theorem to prove the following:  Let $(a_n)$ be a sequence in a simply connected domain $D \subset \mathbb{C}$ that does not have an accumulation point in $D$.  Prove that there exists a holomorphic function $f$ so that its zero set equals $(a_n)$ counting multiplicity. In particular, do not use the Weierstrass Factorization Theorem, Weierstrass Products, or Blaschke Products in your answer. I have no idea how to do this problem.  Can someone help?","['complex-analysis', 'analytic-functions']"
3951135,Equivalent inequality of $\left|\sin^{-1}(x) + \sin^{-1}(y)\right|\le\frac{\pi}{2}$ only in terms of x and y?,"I was working with the inequality, $$\left|\sin^{-1}(x) + \sin^{-1}(y)\right|\le\frac{\pi}{2} , \{|x|,|y|\le1\}.$$ I was trying to find an inequality only in terms of x and y without containing any trigonometric functions. Then after some hit and trial I found following beautiful inequality, $$\biggl|x|x| + y|y| \biggr|\le 1 , \{|x|,|y|\le1\}.$$ But the problem is I couldn't derive this inequality and couldn't show their equivalence. I know they are equivalent by plotting them in Desmos(Function Plotting Program). Can you derive the proof showing the equivalence of these two inequalities ? Note : The above inequality is the condition for the following relation to satisy, $$\sin^{-1}(x) + \sin^{-1}(y) = \sin^{-1}\left(x\sqrt{1-y^2} + y\sqrt{1-x^2}\right)$$ I had thought this formula works for every value of $|x|,|y|\le1$ but turns out it doesn't. It only works when x and y satisfy above inequality.","['trigonometry', 'inverse', 'inequality']"
3951201,Find $\lim_{m \to \infty} m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) \right]$ where $N$ is Poisson random variable with mean $m$,"Let $N$ be a Poisson random variable with the mean parameter $m$ .
We are interested in finding the following limit \begin{align}
\lim_{m \to \infty} m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) \right]. 
\end{align} Things that I tried: First, I found an upper bound by using Jensen's inequality \begin{align}
\lim_{m \to \infty} m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) \right]\le  \lim_{m \to \infty} m  \log\left( \frac{ E \left[ N  \right]+\frac{1}{2}}{m+1} \right)= \lim_{m \to \infty} m  \log\left( \frac{ m+\frac{1}{2}}{m+1} \right)=-\frac{1}{2}. 
\end{align} For the lower bound I tried to use the CLT argument from a related question in here : \begin{align}
m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) \right]= m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) | N \ge \frac{m}{k} \right] P[ N \ge \frac{m}{k} ]+ m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) | N < \frac{m}{k} \right] P[ N < \frac{m}{k} ]
\end{align} for some $k>0$ .  Via the CLT it can be shown that $P[ N < \frac{m}{k} ] \to 0$ for all $0<k <1$ , and we have that \begin{align}
\lim_{m\to \infty}m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) \right]= \lim_{m\to \infty}m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) | N \ge \frac{m}{k} \right] .
\end{align} Now if we use the lower bound at this point, we get \begin{align*}
 \lim_{m\to \infty}m E \left[ \log\left( \frac{N+\frac{1}{2}}{m+1} \right) | N \ge \frac{m}{k} \right]  \ge   \lim_{m\to \infty}m  \log\left( \frac{ \frac{m}{k}+\frac{1}{2}}{m+1} \right) =-\infty,
\end{align*} for all $k \in (0,1)$ .","['poisson-distribution', 'limits', 'probability-theory', 'probability']"
3951214,Rate of Change Calculus Application question,"My teacher gave us this unit assignment and its today. I'm so confused. What we learned this unit was everything about Rate of Change, limits, and derivatives. I'm panicking. If anyone can help with any semblance of a solution, I will be so thankful questions: I need to catch my flight. Iâm at the airport and Iâm running late. I need to make it $1000m$ to get to my gate. I have two choices. I can either run or take the moving sidewalk. The moving sidewalk moves at a constant speed of $2 \frac{m}{s}$ . If Iâm running, I start out quick, but because Iâm old I quickly tire and slow down. Equations for these situations are: $$M(t)=2t$$ $$R(t)=\sqrt{2000x}$$ I cannot run on the moving sidewalk because itâs too crowded, but I can to go onto or off of the moving sidewalk whenever I want to. Assume that I never recover my energy, so I can only have one burst of running. How can I get to my gate in less than $500$ s? Explain the process and determine the minimum time it takes me to reach the gate. If the moving sidewalk moved at $2.5$ m/s, what is the best strategy and how quickly can I reach the gate? If the moving sidewalk is moving at $2$ m/s, but running speed is modeled by $R(t) = 153(x2)^{\frac{1}{3}}$ , what is the best strategy and how long will it take me to reach the gate? For 1. I know that $M(t)$ is the distance traveled after $t$ seconds on the moving sidewalk. $R(t)$ is the distance traveled after t seconds running.
I'm going to spend some time running and some time on the sidewalk, so I need to find possible values of $t_{0}$ and $t_{1}$ such that $M(t_{0})+R(t_{1})=1000$ and $t_{0}+t_{1}<500$ . Then I am trying to minimize $t_{0}+t_{1}$ (the time it takes to get to your gate).
if you just run the whole way, or just take the sidewalk the whole way, you get there in $500$ seconds, so the problem is asking you to do better than that.
I'm just not sure how to translate this information into an equation. Once I can do #1 the #2, and#3 will be easy.
if you just run the whole way, or just take the sidewalk the whole way, you get there in $500$ seconds, so the problem is asking you to do better than that.","['contest-math', 'calculus', 'derivatives']"
3951239,Distribution of $8n\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} )$,"Let $X_1, ..., X_n$ be a random sample taken from a Bernoulli $(p)$ distribution. Consider $\hat{p} = (1/n)\sum_i X_i = \bar{X}_n$ as the estimator of $p$ . We wish to test $H_0: p=0.2$ against $H_1: p\neq 0.2$ using the statistic $$
8nB = - 8n\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} )
$$ where $B = -\operatorname{ln}(\sqrt{0.2\hat{p}} + \sqrt{0.8(1-\hat{p})} )$ is the Bhattacharya's distance . The Problem: Determine the asymptotic distribution of $8nB$ . I haven't been able to create any analytical solution to the problem. I have verified that $\hat{p}$ satisfies the WLLN, that is, $\hat{p} \stackrel{P}{\longrightarrow} p$ . Simulation (using R) suggests that $8nB$ converges in distribution to a $\chi^2_1$ : N <- 10^4
n <- 10^4

B_distr <- c()

for(i in 1:N){
  X <- sample(0:1, n, prob=c(0.8, 0.2),replace=TRUE)
  p_hat <- mean(X)

  B <- -8*n*log(sqrt(0.2*p_hat) + sqrt(0.8*(1 - p_hat)))
  B_distr <- c(B_distr, B)
}

hist(B_distr)
psych::describe(B_distr)
ks.test(B_distr, p=""pchisq"", 1)","['probability-limit-theorems', 'statistics', 'probability-distributions', 'probability']"
3951267,How would I find the volume of a torus with an elliptical cross-section using calculus?,"I know that, by Pappus' centroid theorem, the volume of a torus with an elliptic cross-section of major axis $a$ and minor axis $b$ is $2ð^2abc$ , where $c$ is the distance from the center of the torus to the center of the elliptic cross-section. My doubt is how I would prove this using calculus? What I have gotten so far is the parametric equations of the $x$ , $y$ , and $z$ co-ordinates of all the points in the elliptic torus, with the parameters being $u$ and $v$ ( $v$ is the angle between the $a$ point and the $x$ or $y$ axes, and $u$ is the angle at which the cross-section has been rotated). It is: $$
x(u, v) =  (c + a\cos v)\cos u$$ $$
y(u, v) = (c + a\cos v)\sin u$$ $$
z(u, v) = b\sin v$$ This is also what I get from this source . Using these parametric equations how can I derive the formula for the volume of a torus with an elliptic cross-section? I've seen many different things online such as using the Jacobian matrix but I am not too sure how to move on from here. Please help! I'm a high school student so I don't know much.","['integration', 'geometry', 'multivariable-calculus', 'calculus', 'differential-geometry']"
3951325,$n$th derivative of a function that depends both explicitly and implicitly on a variable,"I would like to have a closed-formula for the $n$ th derivative of a function of the type $f(x,g(x))$ , i.e. a function that depends both explicitly and implicitly on a (scalar) variable: $$
\frac{d^n f}{d x^n} = ?
$$ It can be assumed that all partial derivatives up to order $n$ included exist. I can calculate the first (or second, or third...) derivatives by hand by using the chain rule. For example: $$
\frac{d f}{d x} = \frac{\partial f}{\partial x} + \frac{\partial f}{\partial g}\frac{\partial g}{\partial x} = f^{(1,0)} + g'f^{(0,1)}.
$$ or $$
\frac{d^2 f}{d x^2} =  f^{(2, 0)} +  2 g' f^{(1, 1)} + (g')^2 f^{(0, 2)} + g'' f^{(0, 1)}
$$ I however cannot see a pattern for a general formula. I am aware of the FaÃ  di Bruno formula for calculating high order derivatives of a purely implicit function, but I am failing in seeing how to use it in combination with an explicit dependence of the function on the variable.","['implicit-differentiation', 'derivatives', 'chain-rule']"
3951341,Conjecture : A lower bound for the prime counting function .,"Well it take my a little bit of time to find it but now I think that my conjecture is ready .
Conjecture : Let $n\geq 100$ and then define the sum : $$S(n)=\sum_{k=1}^{n}\frac{1}{\operatorname{argtanh}\left(\frac{k}{k+1}\right)}$$ Then we have : $$\lceil{S(n)}\rceil\leq 2\pi(n)$$ Where we see the ceiling function and the prime counting function .Nicely the equality case is $n=100$ .
I have checked my conjecture with wolfram alpha up to $n=1000$ and extra values of $n$ up to $n=1000000$ Obviously I'm inspired by the prime number theorem and it's not a chance if I choose $\operatorname{argtanh}$ in my conjecture . I have several questions: Well first I would like to know if it's true for larger $n$ . Is my conjecture equivalent to other conjecture (stronger or weaker conjecture) . Can we improve the conjecture by adding (by example) a fixed exponent ? What my conjecture involves ? If it's not true for small $n$ can we take a larger $n$ to start with ? Thanks!","['conjectures', 'hyperbolic-functions', 'number-theory', 'inequality', 'prime-numbers']"
3951373,A union of proper filters in a chain is a proper filter,"I was looking into the proof of the Ultrafilter lemma by Zorn's lemma, and I wasn't able to find a sufficient explanation for the following claim: If $\mathcal{C}\subseteq P$ is a chain of proper filters, then $F:=\cup \mathcal{C}$ is also a proper filter. I'm okay with showing that $F$ is a filter, but it's not clear to me why it is proper.","['elementary-set-theory', 'filters', 'order-theory']"
3951376,Non-numerical proof of an inequality,"Let $ 0 < s < 1 $ be the unique solution to the equation $$ \frac{1}{2^s} + \frac{1}{6^s} + \frac{1}{12^s}=1, $$ and show that $$ \frac{1}{6^s}+\frac{1}{12^s} \geq \left(\frac{2}{7}\right)^s. $$ It is easy do this numerically; you can compute $ s \simeq 0.7584 $ with a calculator, and show that the desired inequality holds with this value plugged in. I'm looking for a more general proof, maybe geometric, using some calculus, or using concavity of the function $ x \mapsto x^s $ for $ 0 < s < 1 $ .","['exponentiation', 'nonlinear-optimization', 'calculus', 'optimization', 'inequality']"
3951390,"Assuming the earth is a sphere, what is the shortest distance between 2 points through the earth? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Assuming the earth is a perfect sphere, is there a way to find out the straight line distance (which goes through the earth) between any 2 points on the surface of the earth?
I've tried searching for this on Google, but it keeps showing me the Great Circle Distance which is the shortest distance on the surface of the earth, but not through the earth.","['algebra-precalculus', 'geometry']"
3951418,Prove that $x \mapsto \boldsymbol{\mathrm P} \left[ \mathrm{B}(\boldsymbol\cdot + x ) \in A \right]$ is measurable for a Brownian motion $\mathrm B$,"Given a (one-dimensional) Brownian motion $\mathrm{B}$ and any $A \in \mathcal B\left(\mathbb R^{[0,1)}\right)$ , how may one prove that the map, from $\mathbb R$ to $[0,1]$ , given by $$
x \mapsto \boldsymbol{\mathrm P} \left[ \mathrm{B}(\boldsymbol\cdot + x ) \in A \right] 
$$ is measurable? The notation $$
\boldsymbol{\mathrm P} \left[ \mathrm{B}(\boldsymbol\cdot + x) \in A \right]
$$ means that we consider the whole path; or in other words, if the function $$
t \mapsto \mathrm{B}(t + x) 
$$ is in $A$ . Most grateful for any advice provided!","['stochastic-processes', 'measure-theory', 'brownian-motion', 'probability-theory']"
3951424,Can infinitely many points on the boundary $C$ of a domain be singular without $C$ being a natural boundary,"This question was asked in my complex analysis quiz and I was unable to do it. Can infinitely many points on the boundary $C$ of a domain  be singular without $C$ being a natural boundary ? I thnik it can be as on the boundary there are uncountable many points and if countably finite points are singular then it's not a problem as natural boundary in that case can be extended as there are points that are still regular. But I want it to be checked. So I posted here. Useful definitions: Suppose $f(z)$ is analytic in a domain $D$ . A point $z_1$ is said to be a regular point of $f(z)$ if the function element $(f,D)$ can be analytically continued along some curve from a point in $D$ to the point $z_1$ . Any boundary point of $D$ that is not a regular point of $f(z)$ is said to be a singular point of $f(z)$ .","['complex-analysis', 'solution-verification', 'analytic-continuation']"
3951434,Generators of level $2$ modular forms,"The ring of modular forms for $\Gamma_1=\text{SL}(2,\mathbf{Z})$ $$M(\Gamma_1)\ =\ \bigoplus_{k\ge 0} M(\Gamma_1)_k\ =\ k[E_4,E_6]$$ is a free ring, with a generator in weight $4$ and weight $6$ . (The reason is that $\mathfrak{H}/\Gamma_1=\mathbf{P}(4,6)$ is a weighted projective space, and the above is $\bigoplus_{k\ge 0}H^0(\mathbf{P}(4,6),\mathcal{O}(k))$ ). The generators are Eisenstein series. Question: what is the ring of modular forms of level $2$ $$M(\Gamma_2)\ =\ \bigoplus_{k\ge 0} M(\Gamma_2)_k\ ?$$ Since $\mathfrak{H}/\Gamma_2=\mathbf{P}(2,2)$ I believe it should be free on two generators of weight $2$ , but I don't know what they are explicitly as functions on $\mathfrak{H}$ .","['number-theory', 'modular-forms']"
3951437,Solving Vandermonde-style set of simultaneous equations,"Imagine there's a set of ordered coefficients $\lambda_1>\lambda_2>\ldots>\lambda_n>0$ which I don't know. However, I know the set of relations $$
\sum_{i=1}^n\lambda_i^k(-1)^{i+1}=a_k
$$ for $k=1$ to $n$ , with known values $a_k$ . Is there anything smart that I can do in order to determine the $\lambda_i$ ? I realise that if it weren't for the $(-1)^{i+1}$ term in my sum, we could use Newton's identities/Viete's formula to determine the polynomial which has roots $\{\lambda_i\}$ , but have so far failed to spot a way of making use of this in my problem. An alternative way to view this problem is that there's an unknown Vandermonde matrix $V$ for which we have to solve $Vx=a$ given known $x,a$ . (Indeed, $x=(1,-1,1,-1,1,\ldots,1)^T$ .) Original context: I have a real symmetric tridiagonal matrix H with 0 on the diagonal, and it is also centrosymmetric. So, it looks something like $$
H=\left(\begin{array}{ccccccc}
0 & J_1 & 0 & \ldots & 0 & 0 \\
J_1 & 0 & J_2 &&0 & 0 \\
0 & J_2 & 0 && 0 & 0 \\
\vdots &&& \ddots &\vdots & 0 \\
0 & 0 & 0 & \ldots & 0 & J_1 \\
0 & 0 & 0 & \ldots & J_1 & 0
\end{array}\right).
$$ For the $N\times N$ matrix, I want to fix $2k+1$ of the eigenvalues. If $2k+1=N$ , this is a standard symmetric inverse eigenvalue problem, but I want to consider smaller values of $k$ . You might formulate this generally, although I'm actually interested in the case where the eigenvalues are $0,\pm 1,\pm 2,\ldots \pm k$ . The remaining eigenvalues are unspecified. They have to occur in $\pm\lambda$ pairs, and I want the smallest (positive) value to be larger than $k$ . These will be determined by the additional constraint - that I want to fix the $N-1-2k$ central coupling strengths to be a specific set of values (again, in the specific case I'm looking at, I'm assuming they're all the same value $J$ , and that $J$ happens to be in a range that allows a solution. I'm deferring the problem of determining what that range might be). The way that I'm trying to approach this is to use some symmetry properties. If $S$ is the swap operator, we can evaluate $\text{Tr}(SH^k)$ both in terms of the eigenvalues of $H$ and in terms of the known coupling strengths. I then get a bunch of equations for my unknown eigenvalues which are those of the original problem statement. With those eigenvalues, I can run the standard inverse eigenvalue routine to determine the matrix $H$ . I've got some good numerical techniques for finding solutions based on this paper . I was just wondering if I could find solutions more directly.","['systems-of-equations', 'linear-algebra', 'polynomials', 'roots']"
3951500,Classical number theoretic applications of the $p$-adic numbers,"I am sure we can all agree that the $p$ -adic numbers are highly fascinating objects in their own right - just as the closely related theory of valuations. Having independently read up on the $p$ -adic numbers for a few weeks now, I have so far only seen one application of them to what I would call classical number theory - namely the proof given in Serre's Cours d'arithmÃ©tique that a natural number is expressible as the sum of $\leq 3$ squares if and only if it is not of the form $4^a(8b-1)$ for some $a,b \in \mathbb{N}$ . Since I have a tendency to appreciate the value of the higher theories of mathematics in proportion to their applications to elementary number theory, I immediately found myself wondering if there are any other applications. So my question to the community is: What are the most delightful applications of the $p$ -adic numbers and the theory of valuations to elementary number theory? Many thanks. P.s.: I am aware that there are already several posts on the forum about the applications of the $p$ -adic numbers, but none that refers to elementary number theory specifically. Edit: I agree that I have been too vague in what I mean by ""elementary number theory"", so I will try to be a little more specific: By a classical ""elementary"" number theoretic proposition, I mean a number theoretic proposition that Fermat might have come up with. Thus, the above proposition about the sum of three squares is an elementary number theoretic proposition, as is e.g. Fermat's Last Theorem and the Twin Prime Conjecture, while e.g. the BSD Conjecture or the Class Number Problem are not. Edit 2: Thank you for all the answers below - they are all excellent! In case anyone should come up with another one, I should like to say that bonus-points are given for results that have so far only been proven using the theory of $p$ -adic numbers, or whose proof using $p$ -adic numbers is far more conceptual and insightful than the original / more elementary one.","['number-theory', 'p-adic-number-theory', 'elementary-number-theory', 'abstract-algebra', 'valuation-theory']"
3951544,Invertible matrix whos square is not invertible?,"Of course, this scenario is impossible for finite dimensional matrices. I am trying to understand what it means for an unbounded linear operator to have a well defined inverse, but the square of its inverse does not exist. It's pretty easy to find examples of this happening. Take the matrix $$M_{nm}=2\delta_{nm}-\delta_{n+1m}-\delta_{n-1m}$$ Defined for $n,m\geq 1$ . This has the inverse $M^{-1}_{nm}=\text{min}(n,m)$ . The square of the inverse obviously diverges and so does not exist. The square goes like $M^{-2}_{nm}\sim nm/3*N$ where $N$ is the size of the matrix. What does this mean for the matrix $M^2$ ? Does $M^2$ somehow pick up a zero eigenvalue that $M$ didn't have? Edit 1: I'd like to say also that $M$ itself can be said to have zero eigenvalues, with eigensequence $a_n=n$ , but if we define everything to be in the Hilbert space $l^2$ of finite norm sequences $\sum_{n=1}^{\infty}|a_n|^2<\infty$ , then those sequences don't belong to the space, hence why we are able to define an inverse. Perhaps theres something about the incompatibility of the linear operator $M$ with the Hilbert space? Edit 2: After playing around with this a little more, I've come to the conclusion that the operator $M^{-1}_{nm}=\text{min}(n,m)$ maps $l^2$ vectors to a different space (that I don't know), in the same sense that the derivative operator takes $x^{1/2}$ out of $L^2([0,1])$ . It just so happens that one of the problem $l^2$ vectors is $a^{(m)}_{n}=\delta_{mn}$ , hence why the norm $|M^{-1}a^{(m)}|^2=M^{-2}_{mm}=\infty$ . If this is the case, in what sense can we define $M^{-1}$ ? do we need to use a different basis other than $a^{(m)}_n$ ?","['hilbert-spaces', 'linear-algebra']"
3951595,Show that $f(x)=x+\frac{1}{x^2+1}$ is strictly increasing.,"Show that $f(x)=x+\frac{1}{x^2+1}$ is always increasing. I noticed that $f'(x)=1-\frac{2x}{(x^2+1)^2}$ , by looking at this function graph, I noticed it must be always positive, however I can't find a way to prove that. My attempt: If $x\le0$ , then clearly $f'(x)>0$ . If $x\ge1$ , it is also quite evident that $\frac{2x}{(x^2+1)^2}\le1$ . Then, when $0<x<1$ , I'm a bit lost. I can't seem to find an algebraic trick to show that $2x<(x^2+1)^2$ , I'd love some help.","['algebra-precalculus', 'functions', 'derivatives']"
3951599,"When does a space admit a ""multiplication-defining"" metric?","Define a Thales space to be a topological space $\mathcal{X}=(X,\tau)$ such that there is some $d:X^2\rightarrow\mathbb{R}$ such that the following hold: The map $d$ is a metric and the topology it induces is $\tau$ . The map $\mathbb{R}^2\rightarrow\mathbb{R}: (x,y)\mapsto xy$ is (first-order, with parameters) definable in the two-sorted structure $$(X\sqcup \mathbb{R}; +,<,d).$$ For example, the usual metric witnesses that $\mathbb{R}^n$ is a Thales space for each $n>1$ as a consequence of Thales' intercept theorem (hence the name). [Stupid claims removed.] Ultimately I'd love an exact characterization of Thales spaces, but I think that's rather ambitious. An easier question would be something along the lines of, ""Is there a non-pathological Thales space which doesn't lean on the intersection theorem?"" I'll make that precise in the following way: Is there a Thales space which is separable and into which $\mathbb{R}^2$ does not continuously embed? (As Eric Wofsey's answer demonstrate separability doesn't actually rule out pathological examples, but it's what I asked.) I'd love to add ""connected"" but that might make the question too hard.","['model-theory', 'logic', 'metric-spaces', 'abstract-algebra', 'general-topology']"
3951680,Problem on Stokes' Theorem,"I'm really struggling to understand Stokes' Theorem. I tried this exercise: Let D be the portion of $z=1-x^2-y^2$ above the xy-plane, oriented up, and let $\vec{F}=\langle xy^2,-x^2y,xyz\rangle$ . Compute $$\iint_{D}^{}(\nabla\times \vec{F})\cdot \hat{n}dS$$ Here is my work: $$\nabla\times \vec{F}=\langle xz,-yz,-4xy\rangle$$ $$\vec{f}(r,\theta) = \bigl\langle r\cos\theta ,r\sin\theta ,1-r^2 \bigr\rangle$$ $$\frac{\partial\vec{f} }{\partial r}= \langle\cos\theta,\sin\theta,-2r\rangle$$ $$\frac{\partial \vec{f}}{\partial\theta }= \langle -r\sin\theta ,r\cos\theta ,0 \rangle$$ $$\frac{\partial\vec{f} }{\partial r}\times \frac{\partial \vec{f}}{\partial \theta}=\left \langle 2r^2\cos\theta ,2r^2\sin\theta ,r\right \rangle$$ $$\left \|\frac{\partial\vec{f} }{\partial r}\times \frac{\partial \vec{f}}{\partial \theta } \right \|=r\sqrt{3}$$ $$\widehat{n}= \biggl\langle \frac{2r\cos\theta}{\sqrt{3}} ,\frac{2r\sin\theta }{\sqrt{3}},\frac{1}{\sqrt{3}}\biggr\rangle$$ Integrating, I have $$\frac{1}{\sqrt{3}}\int_{0}^{2\pi }\int_{0}^{1}2r^2\cos^2\theta (1-r^2)-2r^2\sin^2\theta (1-r\cos\theta )-4r\sin\theta\cos\theta\,dr\,d\theta $$ $$=\frac{1}{\sqrt{3}}\int_{0}^{2\pi }\int_{0}^{1}-2r^2\sin^2\theta (1-r\cos\theta )+2r^2\cos\theta\, \theta (1-r^2)-2r\sin(2\theta )\,dr\,d\theta$$ After splitting the integral into three integrals, I have $$\frac{1}{\sqrt{3}}\int_{0}^{2\pi }\int_{0}^{1}-2r^2\sin^2\theta (1-r\cos\theta )\,dr\,d\theta=-\frac{2\pi }{3\sqrt{3}}$$ $$\frac{1}{\sqrt{3}}\int_{0}^{2\pi }\int_{0}^{1}2r^2\cos\theta (1-r^2)\,dr\,d\theta =0$$ $$\frac{1}{\sqrt{3}}\int_{0}^{2\pi }\int_{0}^{1}-2r\sin(2\theta )\,dr\,d\theta =0$$ $$=-\frac{2\pi }{3\sqrt{3}}+0+0$$ But the answer is zero. What am I doing wrong?","['multivariable-calculus', 'stokes-theorem', 'vector-analysis']"
3951705,Evaluating a Lie Derivative of a Meromorphic Complex Form over a Holomorphic Vector Field.,"Given a meromorphic form $\omega : \Omega^{1, 0}$ , we can get the form $\; \mathrm{d}\omega = \partial \omega + \bar \partial \omega \;$ through the use of Dolbeault operators. I'm trying to find the lie derivative $\mathcal{L}_v \; \omega$ , where $v$ is a holomorphic vector field. How can I find this for non-holomorphic forms? For example, suppose we allow the following definitions: $$ \omega = \frac{z+4}{z-3i} \; \mathrm{d}z, \quad v = 2z-1.$$ What is the Lie derivative $\mathcal{L}_v \;\omega$ ?","['complex-analysis', 'multivariable-calculus', 'differential-forms', 'differential-geometry']"
3951717,Entropy of the difference of two random variables,"Let $X$ and $Y$ be two i.i.d (independent and identically distributed) discrete random variables with distribution $P=(p_0, p_1, \ldots, p_{q-1})$ and support $\{0,1,...,q-1\}$ with $q \geq 2$ . Take $$
P_M = \arg\max_{P} H(X-Y)
$$ where $H$ is the Shannon entropy function, i.e. $H(X) = \sum_{i=0}^{q-1} -p_i \log p_i$ . For which $P_M$ we achieve the maximum? For $q=2$ it is not difficult to show that the uniform distribution achieve the maximum. Is it true also for $q>2$ ?","['optimization', 'entropy', 'lagrange-multiplier', 'probability']"
3951722,"Does the norm of a (1,1) tensor depend on the conformal factor?","If we have a $(1,1)$ tensor $T$ on a (pseudo-)Riemannian manifold $(M,g)$ , its norm is $$
g(T, T) = g_{AB}g^{CD}T^A_C T^B_D.
$$ If we let $h = \phi^2 g$ be a conformally equivalent metric, then its inverse is $h^{-1} = \phi^{-2}g^{-1}$ and thus the norm of $T$ as measured by $h$ is identical, as the conformal factors cancel out. This only happens when $T$ is a mixed tensor which is covariant in the same number of indices as it is contravariant. Questions: Is this proof correct? Is there any geometric reason why these types of tensors have their norm preserved by conformal transformations?","['tensors', 'solution-verification', 'riemannian-geometry', 'differential-geometry']"
3951723,"Sketch the region of integration for the integral $\int_{-2}^2 \int_0^{2y} f(x,y)dx\,dy$","I am slightly confused when sketching the region for the double integral $$\int_{-2}^2 \int_0^{2y} f(x,y)dx\,dy$$ When I sketch the region I get a triangle in the top right quadrant, however my textbook says the region is two triangles, one in the top right quadrant, one in the bottom left quadrant. I don't understand how this can be if the inequalities for the regions are $0<x<2y$ and $-2<y<2$ .","['multivariable-calculus', 'multiple-integral']"
3951745,Show that the multiplicative group of integers mod 35 is not isomorphic to the additive group of integers mod 24,"I got this question on an abstract algebra test back when I was still in undergrad. I was going over some old notes from undergrad (just for fun) and I realized I had a completely wrong answer to this question so I set about trying to solve it. I am really struggling with it. To be honest, I think I just have a hard time disproving two groups are isomorphic unless they have different cardinality. Any suggestions?","['group-theory', 'abstract-algebra', 'group-isomorphism']"
3951776,Surface area of $z=4-x^2-y^2$ over a square region,"Find the surface area of the paraboloid $z=4-x^2-y^2$ over the square region $-2\le x\le 2 $ and $-2\le y\le 2$ . I can parametrize this surface with $x=u,\ y=v,\text{and}  \>z=4-u^2-v^2$ ,
where $-2\le u\le 2$ and $-2\le v\le 2$ . Then I can parametrize the surface with a vector function as follows: $$\mathbf r(u,v)=\langle u, v ,4-u^2-v^2\rangle $$ Then $\mathbf r_u(u,v)=\langle 1,0,-2u\rangle,\>
\mathbf r_v(u,v)=\langle 0,1,-2v\rangle$ and $$\mathbf r_u\times\mathbf r_v=\left|\matrix{\mathbf i&\mathbf j&\mathbf k\cr 1 & 0 & -2u\cr 0 & 1 & -2v}\right|=\langle 2u,2v,1\rangle$$ so $\|\mathbf r_u\times\mathbf r_v\|=\sqrt{4u^2+4v^2+1}$ .
The surface area is then defined by $$A=\int\int_D\|\mathbf r_u\times \mathbf r_v\|\,dA=\int_{-2}^2\int_{-2}^2\sqrt{4u^2+4v^2+1}\,dv\,du$$ But now, how do I perform this integral? Here's an image of this surface. Update Due to symmetry, we can calculate the surface area over the region $R=\{(u,v):\ 0\le u\le 2\text{ and }0\le v\le 2\}$ , then multiply the result by 4. That is, the surface area is $$A=4\int_{0}^2\int_{0}^2\sqrt{4u^2+4v^2+1}\,dv\,du$$ Now, it was suggested that I try polar coordinates. Here's an image of the region $R=\{(u,v):\ 0\le u\le 2\text{ and }0\le v\le 2\}$ . Note that the angle of the dashed segment from $(0,0)$ to $(2,2)$ has an angle of $\pi/4$ with the $u$ -axis. Also, note that \begin{align*}
\cos\theta&=\frac2r\\
r\cos\theta&=2\\
r&=\frac{2}{\cos\theta}\\
r&=2\sec\theta
\end{align*} Again, because of the symmetry of our image, we can determine the surface area over the region $\{(r,\theta):\ 0\le \theta\le \pi/4\text{ and } 0\le r\le 2\sec\theta\}$ and multiply the result by 8. Thus, using $$ u=r\cos\theta\qquad\text{and}\qquad v=r\sin\theta$$ the surface area is \begin{align*}
A&=8\int_0^{\pi/4}\int_0^{2\sec\theta}\sqrt{4r^2\cos^2\theta+4r^2\sin^2\theta+1}\ r\,dr\,d\theta\\
A&=8\int_0^{\pi/4}\int_0^{2\sec\theta}\sqrt{4r^2+1}\ r\,dr\,d\theta\\
\end{align*} Then I was able to integrate and manipulate a bit: \begin{align*}
A&=8\int_0^{\pi/4}\left[\frac1{12}(4r^2+1)^{3/2}\right]_0^{2\sec\theta}\,d\theta\\
A&=\frac23\int_0^{\pi/4}\left[(16\sec^2\theta+1)^{3/2}-1\right]\,d\theta\\
A&=\frac23\int_0^{\pi/4}(16\sec^2\theta+1)^{3/2}\,d\theta-\frac23\int_0^{\pi/4}d\theta\\
A&=\frac23\int_0^{\pi/4}(16\sec^2\theta+1)^{3/2}\,d\theta-\frac{\pi}{6}
\end{align*} But now I am unable to calculate this current integral. Thanks. Update Click the link below to see the work I had to do to understand Quanto's nice suggestion. Surface Area Solution","['integration', 'multivariable-calculus']"
3951790,Behavior of Legendre polynomials $P_\ell(\cos\theta)$ under $\theta\to\pi-\theta$,"I'm studying some notes on the hydrogen atom which define the Legendre polynomials via Rodrigues's formula, $$P_\ell(z)=\frac{1}{2^\ell \ell!}\frac{d^\ell}{dz^\ell}(z^2-1)^\ell,\quad z=\cos\theta.$$ I'm trying to figure out what happens when $\theta\to\pi-\theta$ or equivalently, $z\to-z$ . By computing some of the lowest order Legendre polynomials I believe I've convinced myself that $P_\ell(-z)=(-1)^\ell P_\ell(z)$ , but I don't see how I can prove this given the above formula, i.e. I don't see what exactly will happen to the $\ell$ -th order derivative. Is it mathematically meaningful to write $$P_\ell(-z)=\frac{1}{2^\ell \ell!}\frac{d^\ell}{d(-z)^\ell}[(-z)^2-1]^\ell?$$","['calculus', 'derivatives', 'legendre-polynomials']"
3951836,Show the series defines an infinitely differentiable function,"show $f(x) = \sum\limits_{n=1}^{\infty} \frac{1}{n(x+n)}$ defined on $[0, \infty)$ is $C^\infty$ I'm working on this practice problem.  I differentiated each term to get $$g(x) = \sum \frac{d}{dx} \frac{1}{n(x+n)}=\sum \frac{-1}{nx^2+2xn^2+n^3} = \frac{d}{dx} \sum  \frac{1}{n(x+n)}=f'(x)$$ interchanging the differentiation and the sum becasue the sum of the derivatives converges uniformly on the domain. Then I continued by induction, using the fact that the order of the numerator of $g$ is 3 less than the order of the denominator, to say that if we keep taking the derivative we will keep getting uniformly convergent series and can interchange the differentiation and the sum. This seems messy to me - I'm not sure it works 100%.  Am I missing something?  Or is there a cleaner way to do this problem like transform it into a power series?","['derivatives', 'sequences-and-series', 'analysis', 'real-analysis']"
3951846,On the proof of The Bounded Convergence Theorem,"From the text Real Analysis by Royden, he gives the following proposition Proposition 8: Let $\{f_n\}$ be a sequence of bounded measurable functions on a set of finite
measure $E$ . $$\text{If } \{f_n\}\to f \text{ uniformly on $E$, then } \lim_{n\to\infty}\int_{E}f_n = \int_{E}f.$$ The proof is given as: Proof: Since the convergence is uniform and each $f_n$ is bounded, the limit function $f$ is
bounded. The function $f$ is measurable since it is the pointwise limit of a sequence of
measurable functions. Let $\epsilon>0$ . Choose an index $N$ for which $$\left|f-f_n\right|<\epsilon/\operatorname{m}\left(E\right)\text{ on $E$ for all $n\geq N$}.$$ By the linearity and monotonicity of integration and the preceding corollary, for each $n\geq N$ , $$\left|\int_{E}f - \int_{E}f_n\right| = \left|\int_{E}[f - f_n]\right|\leq\int_{E}\left|f-f_n\right|\leq [\epsilon/\operatorname{m}\left(E\right)]\cdot\operatorname{m}\left(E\right) = \epsilon.$$ Therefore $\lim_{n\to\infty}\int_{E}f_n = \int_{E}f$ . My question is: How come if we switch bounded to uniformly bounded, and uniform convergent to pointwise convergent the proof no longer holds? Moreover, how come we can not longer say: Let $\epsilon>0$ . Choose an index $N$ for which $$\left|f-f_n\right|<\epsilon/\operatorname{m}\left(E\right)\text{ on $E$ for all $n\geq N$}.$$ Is this statement no longer true if $\{f_n\}\to f \text{ pointwise on $E$}$ ?","['measure-theory', 'real-analysis']"
3951869,"Element of minimum norm in a closed subset of $L^2[-\pi,\pi]$","Let $$Y=\Bigg\{ f\in L^2[-\pi,\pi]\, :\, \int_{-\pi}^\pi xf(x)\, dx=1,\,\, \int_{-\pi}^\pi (\sin x)f(x)\, dx=2 \Bigg\}.$$ My goal is to calculate the minimum norm element in $Y$ . The indication that appears to me is: to calculate $f\in Y$ of minimum norm, find a function of the type $g(x)=sx+t\sin x$ such that $f\in Y$ is fulfilled if and only if $f-g\in Z^\perp$ where $Z=\textrm{Span}[x,\sin x]$ , that is, that $Y=g+Z^\perp$ is fulfilled. Then $f=g$ . But I don't understand why with this procedure I will get an $f$ element of minimum norm...","['hilbert-spaces', 'orthogonality', 'functional-analysis']"
3951872,Tetrahedron circumradius in high dimensions [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I guess this answer had already been answered a long time ago, but indeed I cannot find any reference. What is the circumradius of a $n$ -dimensional regular hypertetrahedron? Does it approach the length of the hypertetrahedron edges as $n$ increases?","['euclidean-geometry', 'discrete-geometry', 'geometry', 'reference-request', 'solid-geometry']"
3951902,Convex hull of rank-$1$ matrices is the nuclear norm unit ball,"Let $$A := \left\{ u v^T : u \in \mathbb{R}^m, v \in \mathbb{R}^n, \|u\|_2 = \|v\|_2 = 1 \right\}$$ I would like to show that $$\textrm{conv}(A) = B_* := \left\{ X \in \mathbb{R}^{m \times n}: \|X\|_* = \textrm{Tr} \left( \sqrt{XX^T} \right) \le 1 \right\}$$ I have shown that $\textrm{conv}(A) \subset B_*$ . However, I have been stuck proving the opposite inclusion $ B_* \subset \textrm{conv}(A)$ . Does anyone have any tips on how to show this inclusion? One idea that I have is to take the SVD of an arbitrary matrix $X \in B_*$ such that $X=U\Sigma V^T$ where the sum of the elements of the diagonal matrix $\Sigma \le 1$ . We also know that $U,V^T$ are orthonormal square matrices. However, I'm not sure where to go from there.","['nuclear-norm', 'convex-hulls', 'rank-1-matrices', 'matrices', 'convex-analysis']"
3951946,Why is a miracle happening on this double integral?,"I am trying to solve a double integral of the form $$\int_0^\infty du\int_0^\infty dx \frac{1}{x}\left(\frac{\partial}{\partial x}\right)^{2n+1}f\left(\sqrt{x^2+u}\right),$$ where $f$ is a well-behaved even function that decays rapidly at infinity. The content of this question (and miracle) does not depend on the specific $f$ , as long as it is even and well behaved, but $f(t)=e^{-t^2}$ is a fine example. Note that since $1/x$ multiplies an odd function, the integrand is nonsingular as $x\to0$ . I would like to have a solution for a generic integer $n$ , in terms of the known quantities $f^{(m)}(0)$ (i.e., arbitrary $m$ th derivatives of $f$ evaluated at zero). Amazingly, such a solution seems to always exist (I have tested up to $n = 5$ ), but the method I am using is extremely tedious, relies on Mathematica, and results in infinite terms that miraculously cancel. So the question is, what's a more efficient and clear method to get the same result? Step 1: Evaluate all $2n+1$ derivatives. Step 2: Transform the first integral with the change of variables $u=y^2,du=2ydy$ . Step 3: Convert to polar coordinates. Step 4: Evaluate the $\theta$ -integral. Step 5: What remains is an integral of the form $\int_0^\infty dr\left(c_1\frac{1}{r^{p_1}}f^{(q_1)}(r) + \cdots + c_r r^{p_N}f^{(q_N)}(r)\right)$ . Some of the terms with powers of $x$ in the denominator are infinite, but integrating by parts on some terms always makes these cancel. The terms with positive powers of $x$ can be integrated by parts repeatedly until they become $\int_0^\infty dr f^{(m)}(r) = - f^{(m-1)}(0)$ . Steps 1â4 can be performed by Mathematica using the single line (here $n=2$ ): Integrate[
 Assuming[{r, \[Theta]} \[Element] PositiveReals, 
  2r Tan[\[Theta]] D[f[Sqrt[x^2 + u]], {x, 2*2 + 1}] /. {x -> 
      r Cos[\[Theta]], u -> r^2 Sin[\[Theta]]^2} // 
   Simplify], {\[Theta], 0, \[Pi]/2}] I invite you to copy/paste this line in, examine the output and verify what I have claimed in step 5. It may seem pointless for me to ask this question, given that I already have a method for getting to a solution; however, Mathematica starts taking a very long time to compute this even for $n=5$ , and even still the above line does not consider the final integrations by parts that make several more terms vanish and combine, so I think a better method is needed for both efficiency and understanding's sake.","['integration', 'multivariable-calculus', 'polar-coordinates']"
3952040,Evaluate $\lim_{x\to+â}\frac{(\sum_{n=0}^â{(\frac{x^n}{n!})^2})^2}{(\sum_{n=0}^â{(\frac{x^n}{n!})^1}) (\sum_{n=0}^â{(\frac{x^n}{n!})^3})}$,"Prove the following limit: $$
\lim_{x\rightarrow +\infty} \frac{\left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^2} \right) ^2}{\left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^1} \right) \left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^3} \right)}=\frac{\sqrt{3}}{2} \tag{1}
$$ Mathematica tells me that $$
\sum _{n=0}^{\infty } \left(\frac{x^n}{n!}\right)^2=I_0(2 x)\\
\sum _{n=0}^{\infty } \left(\frac{x^n}{n!}\right)^3 = \, _0F_2\left(;1,1;x^3\right)
$$ but they don't make sense to me for calculating the limits, since I don't have any knowledge about Special Functions . How can I prove $(1)$ in an elementary way (not involving special functions)?","['limits', 'analysis', 'sequences-and-series']"
3952065,Evaluating $\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}$,"I am trying to evaluate the following series: $$\sum_{n=1}^\infty\frac{1}{n^3\sin\left(\sqrt{2}\pi n \right)}\tag{a} $$ where, using the well-known result: $$\frac{1}{\sin\left(\pi x\right)}=\frac{2x}{\pi}\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k^2-x^2}+\frac{1}{\pi x}\tag{1} $$ connecting $(1)$ in $(a)$ and $x\to \sqrt{2}n$ got the step: $$\sum_{n=1}^\infty\frac{1}{n^3\sin\left(\sqrt{2}\pi n \right)}=\frac{2\sqrt{2}}{\pi}\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}+\frac{1}{\sqrt{2}\pi}\zeta(4)\tag{b} $$ I tried to apply partial fractions in the double series above, then i found that: $$\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}=\frac54\zeta(4)+2\sum_{k=1}^\infty\sum_{n=1}^\infty\frac{(-1)^{k-1}}{k^2\left(k^2-2n^2\right)}\tag{2} $$ To conclude, I do not know to what extent this last step can help to solve the Double Series. Maybe I'm not seeing the obvious. It will be interesting to see some approach to resolve it. At Wolfram , she is: $$\therefore\ \sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}=-\frac{17}{16}\zeta(4).  $$","['summation', 'closed-form', 'sequences-and-series']"
3952067,Why isn't every finite locally free morphism etale?,"I have been reading the notes here . There, a finite locally free morphism of schemes is defined as as a morphism of schemes $f: X \rightarrow Y$ which is finite and for which the sheaf $f_{*} \mathcal{O}_{X}$ is locally free as an $\mathcal{O}_{Y}$ -module. A finite etale morphism is then defined as a morphism of schemes $f: X \rightarrow Y$ which is finite locally free, and for which the fiber over any point $q \in Y$ is an etale $\kappa(q)$ -algebra. I am struggling to understand what the part about the fibers being etale algebras adds at all. It seems like every finite locally free morphism would trivially satisfy this. Take $f: X \rightarrow Y$ to be a finite locally free morphism of schemes. For any $q \in Y$ , choose an affine $\operatorname{spec}A$ around $q$ small enough so that $f_{*} \mathcal{O}_{X}$ is free, say of degree $d$ . Then since $f$ is finite, it is in particular affine, so the morphism looks locally like $\operatorname{spec}(A^{\oplus d}) \rightarrow \operatorname{spec}A$ . Then the fiber over $q$ is just $\operatorname{spec}(\kappa(q)^{\oplus d})$ . This seems to trivially be an etale $\kappa(q)$ -algebra, since tensoring with some algebraic closure $\Omega$ would give $d$ copies of $\Omega$ . Where is the flaw in my reasoning? Or is it just the case that every finite locally free morphism is etale? Further to this, the same notes say that for a finite etale morphism, the degree of the morphism at a point $q \in Y$ is the same as the cardinality of the fiber over $q$ . But again the above reasoning seems to show this for any finite locally free morphism. Where does etale come into it at all?","['algebraic-geometry', 'schemes']"
3952080,Cosine angles and finite nested square roots of 2,"Let us consider interesting factors about cosine angles $2\cos(\frac{\pi}{2^3}) = \sqrt{2+\sqrt2}$ $2\cos(\frac{\pi}{2^4}) = \sqrt{2+\sqrt{2+\sqrt2}}$ To generalize $2\cos(\frac{\pi}{2^n}) = \sqrt{2+\sqrt{2+\sqrt{2+...\text{(n-1) times}}}}$ Let us imagine the angles $p \over q$ radians where $1 \over 4$ < $p \over q$ < $1 \over 2$ which satisfy 2^n as denominator and numerator as odd number p satisfying $2^{(n-2)} < p < 2^{(n-1)}$ Let us see the simplest example $2\cos(\frac{3\pi}{2^3}) = \sqrt{2-\sqrt2}$ where $3 = 2^2-1$ $2\cos(\frac{5\pi}{2^4}) = \sqrt{2-\sqrt{2-\sqrt2}}$ where $5 = 2^3-(2^2-1)$ ---> let us represent as $n\sqrt2(2-)$ $2\cos(\frac{7\pi}{2^4}) = \sqrt{2-\sqrt{2+\sqrt2}}$ where $7 = 2^3-1$ ---> let us represent simply as $n\sqrt2(1-1+)$ We have $2^n$ number of odd numbers between $2^{n+1}$ to $2^{n+2}$ Let us explore little further We have $4$ odd numbers from $8$ as $9, 11, 13, 15$ to $16$ where we can represent cosine angles as nested square roots of 2 as follows $2\cos(\frac{9\pi}{2^4})$ = $n\sqrt2(1-1-1+)$ or $n\sqrt2(2-1+)$ where $9 = 2^4-(2^3-1)$ $2\cos(\frac{11\pi}{2^4})$ = $n\sqrt2(1-1-1-)$ or $n\sqrt2(3-)$ where $11 = 2^4-(2^3-(2^2-1))$ $2\cos(\frac{13\pi}{2^4})$ = $n\sqrt2(1-1+1-)$ where $13 = 2^4-(2^2-1)$ $2\cos(\frac{15\pi}{2^4})$ = $n\sqrt2(1-1+1+)$ or $n\sqrt2(1-2+)$ where $15 = 2^4-1)$ Here are the observations All odd numbers can be represented as sum (addition and subtraction) of $2^n$ in descending order. The total number of signs ( $+$ and $-$ ) is $a$ where $2^a < p < 2^{(a+1)}$ and total number of $2$ s inside the nested radical is $(a+1)$ The missing power of 2 is $+$ s and others are $-$ s What if the odd number is 57 or 149 or big numbers? The wonder is we can make the odd numbers as sums of 2^n in decreasing order For example if odd number is 57 then the cosine angle is $57 \over 2^7$ radians which can be derived as finite nested square roots of 2 as follows $57 = 2^6-7$ and $7 = 2^3-1$ and $\therefore 57 =Â  2^6-(2^3-1)$ Now $2\cos(\frac{57\pi}{2^7}) = \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+\sqrt2}}}}}$ or simply as $n\sqrt2(1-2+1-1+)$ $149 = 2^8-107$ and $107 = 2^7-21$ and $21 = 2^5-11$ and $11 = 2^4-5$ and $5 = 2^3-3$ and $3 = 2^2-1$ $\therefore 149 =Â  2^8-(2^7-(2^5-(2^4-(2^3-(2^2-1)))))$ Now $2\cos(\frac{149\pi}{2^9}) = \sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt2}}}}}}}$ or simply as $n\sqrt2(2-1+4-)$ One more easier method that I tried as follows E.g $2\cos(\frac{3\pi}{2^3})$ = $\sqrt{2+2\cos(\frac{3\pi}{2^2}})$ = $\sqrt{2-2\cos(\frac{\pi}{2^2}})$ = $\sqrt{2-\sqrt2}$ $2\cos(\frac{5\pi}{2^4}) = \sqrt{2+2\cos(\frac{5\pi}{2^3}}) = \sqrt{2-2\cos(\frac{3\pi}{2^3}}) = \sqrt{2-\sqrt{2+2\cos(\frac{3\pi}{2^2}}}) = \sqrt{2-\sqrt{2-2\cos(\frac{\pi}{2^2}}}) = \sqrt{2-\sqrt{2-\sqrt2}}$ $\therefore$ for any odd number we can derive the finite nested square roots of 2 easily As it is too lengthy I'll restrict with 1 big number example For $2\cos(\frac{57\pi}{2^7}) = \sqrt{2+2\cos(\frac{57\pi}{2^6}}) = \sqrt{2-2\cos(\frac{7\pi}{2^6}}) = \sqrt{2-\sqrt{2+2\cos(\frac{7\pi}{2^5}}}) = \sqrt{2-\sqrt{2+\sqrt{2+2\cos(\frac{7\pi}{2^4}}}}) = \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+2\cos(\frac{7\pi}{2^3}}}}}) = \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-2\cos(\frac{\pi}{2^3}}}}}) = \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+2\cos(\frac{\pi}{2^2}}}}}}) = \sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+\sqrt2}}}}}$ Conclusion : For a given odd number $'p'$ in numerator of angle with corresponding denominator $'q'$ as $2^n$ in the angle as radians, satisfying $1 \over 4$ < $p \over q$ < $1 \over 2$ , the cosine angle can be represented as finite nested square roots of 2 These steps I have derived myself and verified the results. Is there any more simpler method to derive the finite nested square roots of 2?","['nested-radicals', 'trigonometry']"
3952083,Stacky Nakayama Lemma,"It can be proven using Nakayama's lemma that
if ð´ is a local Artinian $ð$ -algebra, $ð_1$ , $ð_2$ are finite type schemes flat over $ð´$ , and $ð:ð_1 \to ð_2$ is a morphism over $ð´$ which restricts to an isomorphism on closed fibers, then ð is an isomorphism. I am wondering if such a statement can be generalized to stacks in the following sense: Let $X, Y$ denote stacks over the category $\operatorname{Spec} A$ , where $A$ is as above, and let $f: X \to Y$ be a morphism of stacks over $\operatorname{Spec} A$ which restricts to an isomorphism on $\operatorname{Spec} k$ . Then is $f$ an isomorphism (equivalence of categories)?","['algebraic-stacks', 'algebraic-geometry', 'category-theory', 'commutative-algebra']"
3952159,Solve integral $\int^1_0 \frac{1-x^2}{{(1+x^2)}\sqrt{1+x^4}}dx$ using subsituition $\sqrt{1+x^4} = {(1+x^2)}\cos{\theta}$,"Hi this question has been posed in my integration book where it has been asked to solve it using the given substitution or any other substitution, I've found identical question posted here {1} with different substitutions The problem is when using the given substitution I end up with integral $$\int^{\pi/4}_0 \frac{\sin{\theta}}{2x}d\theta $$ Solving for $x$ : $\sqrt{1+x^4} = {(1+x^2)}\cos{\theta}$ According to WolframAlpha: $$x = \frac{|\csc{\theta}||1 \pm \sqrt{\cos{2\theta}}|}{\sqrt{2}} $$ I do know the sign for x is $+ve$ so I'll take $+ve$ solutions after opening the modulus, I do not know which sign to prefer in $ \pm \sqrt{\cos{2\theta}} $ term Eitherway, I solved for both cases : $$  \frac{1}{\sqrt{2}}\int^{\pi/4}_0\frac{\sin^2{\theta}}{1 + \sqrt{\cos{2\theta}}} d\theta -(I) $$ $$  \frac{1}{\sqrt{2}}\int^{\pi/4}_0\frac{\sin^2{\theta}}{1 - \sqrt{\cos{2\theta}}} d\theta -(II) $$ Which leads to : $$  \frac{1}{\sqrt{2}}\int^{\pi/4}_0 1 \pm \sqrt{\cos{2\theta}} d\theta = \frac{\pi}{4\sqrt{2}}
\pm\frac{\Gamma(\frac{3}{4})^2}{2\sqrt{2}} $$ Here I cheated and used WolframAlpha as I was exhausted. Both the cases lead to a similar answer with difference of a function unknown to me: $\pm\frac{\Gamma(\frac{3}{4})^2}{2\sqrt{2}}$ The correct answer is : $$\frac{\pi}{4\sqrt{2}}$$ My main questions are: What am I doing wrong? How did author arrive at this ingenious  substitution $\sqrt{1+x^4} = {(1+x^2)}\cos{\theta}$ , this doesn't appear to me trial n' error kind of substitution , I have spent hours doing algebraic transformation on this and no matter how you procced and plug the variable your integrand will only have one of these terms only $2x$ , $1-x^2$ , $1+x^2$ and $ \sqrt{1+x^4}$ and $2x$ being the simplest. Related question: How do I integrate the following? $\int{\frac{(1+x^{2})\mathrm dx}{(1-x^{2})\sqrt{1+x^{4}}}}$","['integration', 'calculus', 'definite-integrals']"
3952166,Who found the proof for the quartic formula?,"A quartic equation is a 4th degree polynomial, in the form of $ax^4+bx^3+cx^2+dx+e$ . There are 4 different formulae for the 4 roots of the quartic equation. Here are the formulae: $$x_1=-\frac{b}{4 a}-\frac{1}{2} \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}-\frac{1}{2} \sqrt{-\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{2 a^2}-\frac{4 c}{3 a}-\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}-\frac{-\frac{b^3}{a^3}+\frac{4 c b}{a^2}-\frac{8 d}{a}}{4 \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}}}$$ $$x_2=-\frac{b}{4 a}-\frac{1}{2} \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}+\frac{1}{2} \sqrt{-\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{2 a^2}-\frac{4 c}{3 a}-\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}-\frac{-\frac{b^3}{a^3}+\frac{4 c b}{a^2}-\frac{8 d}{a}}{4 \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}}}$$ $$x_3=-\frac{b}{4 a}+\frac{1}{2} \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}-\frac{1}{2} \sqrt{-\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{2 a^2}-\frac{4 c}{3 a}-\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}+\frac{-\frac{b^3}{a^3}+\frac{4 c b}{a^2}-\frac{8 d}{a}}{4 \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}}}$$ $$x_4=-\frac{b}{4 a}+\frac{1}{2} \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}+\frac{1}{2} \sqrt{-\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{2 a^2}-\frac{4 c}{3 a}-\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}+\frac{-\frac{b^3}{a^3}+\frac{4 c b}{a^2}-\frac{8 d}{a}}{4 \sqrt{\frac{\sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}{3 \sqrt[3]{2} a}+\frac{b^2}{4 a^2}-\frac{2 c}{3 a}+\frac{\sqrt[3]{2} \left(c^2-3 b d+12 a e\right)}{3 a \sqrt[3]{2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e+\sqrt{\left(2 c^3-9 b d c-72 a e c+27 a d^2+27 b^2 e\right)^2-4 \left(c^2-3 b d+12 a e\right)^3}}}}}}$$ Yep, they are really long, I apologize for the loading time. I want to know who spent so much time finding these formulae and how they found them.","['roots', 'math-history', 'polynomials', 'algebra-precalculus', 'quartics']"
3952198,Can we deduce strictly increasing on a sub-interval for such a function?,"Assume that we have a function $f : [0, 1] \rightarrow [0, 1]$ which is differentiable, $f(0) = 0$ and $f(1)=1$ . Can we deduce that there exists an open sub-interval in $[0, 1]$ in which $f$ is strictly increasing over that? Note that here, continuity of $f^{\prime}$ is not mentioned.",['analysis']
3952272,Prove that $\ell^p$ is complete.,"Prove that $(\ell^p, \|\cdot\|_p)$ is complete. My attempt $:$ Let $\sum\limits_{n=0}^{\infty} x^{(n)}$ be an absolutely summable series in $\ell^p.$ Let $x^{(n)} = \left (x_j^{(n)} \right )_{j \geq 0}.$ Need to show that $\sum\limits_{n=0}^{\infty} x^{(n)}$ converges in $\ell^p.$ Let $M = \sum\limits_{n=0}^{\infty} \left \|x^{(n)} \right \|_p.$ Let $(y^{(n)})_{n \geq 1}$ be the sequence of partial sums of the series $\sum\limits_{n=0}^{\infty} x^{(n)}.$ So for each $n \geq 0$ we have $$y^{(n)} = \sum\limits_{k=0}^{n} x^{(k)} = \left (\sum\limits_{k=0}^{n} x_j^{(k)} \right )_{j \geq 0} = \left (y_j^{(n)} \right )_{j \geq 0}.$$ where $y_j^{(n)} = \sum\limits_{k=0}^{n} x_j^{(k)}, j \geq 0.$ Now for each $j \geq 0$ consider the sequence $\left (z_j^{(n)} \right )_{n \geq 0}$ defined by $$z_j^{(n)} = \sum\limits_{k=0}^{n} \left |x_j^{(k)} \right |,\ n \geq 0.$$ Then it is easy to see that $\left (z_j^{(n)} \right )_{n \geq 0}$ is increasing and bounded above by $M$ for all $j \geq 0$ and hence it is convergent for all $j \geq 0.$ Let $z_j : = \lim\limits_{n \to \infty} z_j^{(n)},\ j \geq 0.$ For each $n \geq 0$ define the sequence $\left |x^{(n)} \right | : = \left (\left |x_j^{(n)} \right | \right )_{j \geq 0}.$ Let $z^{(n)} : = \sum\limits_{k=0}^{n} \left |x^{(k)} \right | = \left (\sum\limits_{k=0}^{n} \left |x_j^{(k)} \right | \right )_{j \geq 0} = \left (z_j^{(n)} \right )_{j \geq 0},\ n \geq 0.$ Then by Minkowski's inequality it follows that $$\left \|z^{(n)} \right \|_p \leq \sum\limits_{k=0}^{n} \left \|x^{(k)} \right \|_p \leq M.$$ Now for each $j \geq 0$ we have $\left (z_j^{(n)} \right )_{n \geq 0}$ increases to $z_j.$ So by MCT it follows that $$\sum\limits_{j=0}^{\infty} z_j^p = \lim\limits_{n \to \infty} \sum\limits_{j=0}^{\infty} {z_j^{(n)}}^p = \lim\limits_{n \to \infty} \left \|z^{(n)} \right \|_p^{p} \leq M^p.$$ This shows that $\|z\|_p \leq M,$ where $z = (z_j)_{j \geq 0}.$ Hence $z \in \ell^p.$ Now since $\left (z_j^{(n)} \right )_{n \geq 0}$ is convergent for each $j \geq 0,$ it follows that $\left (y_j^{(n)} \right )_{n \geq 0}$ is convergent for each $j \geq 0.$ Let $y_j = \lim\limits_{n \to \infty} y_j^{(n)},\ j \geq 0.$ Let $y = (y_j)_{j \geq 0}.$ If we can prove that $y \in \ell^p$ and $\left \|y^{(n)} - y \right \|_p \to 0$ as $n \to \infty$ then we are through. Now $$\left |y_j^{(n)} \right | \leq \sum\limits_{k=0}^{n} \left |x_j^{(k)} \right | = z_j^{(n)}.$$ Hence we have $$\left |y_j^{(n)} \right |^p \leq {z_j^{(n)}}^p.$$ Since $\left \|z^{(n)} \right \|_p \lt \infty$ it follows from DCT that $y \in \ell^p$ and $$\left \|y^{(n)} - y \right \|_p \to 0\ \text {as}\ n \to \infty.$$ Is my attempt correct at all? Please check it. Thanks in advance.","['complete-spaces', 'measure-theory', 'solution-verification', 'functional-analysis']"
3952304,How to measure the width,"In the attached picture, RS can be determined as follows:
RS is obtained from fitting the function $$0.5(1+\operatorname{erf}((I\%-50)/RS))$$ where $I\%$ is the current pulse amplitude as percentage of threshold and $\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x}e^{-\lambda^2}d \lambda$ .
It is about determining the spread of a curve.","['statistics', 'calculus', 'discrete-mathematics', 'probability-theory', 'probability']"
3952342,Another approach for calculating the sum,"$$
\sum_{n=0}^{\infty}(-\cos \beta)^{n} \frac{\sqrt{\pi} \Gamma\left(\frac{n}{2}+\frac{1}{2}\right)}{2 \Gamma\left(\frac{n}{2}+1\right)}, \beta\in(o,\pi)
$$ Answer: $$\frac{\pi-2\arcsin\cos\beta}{2\sin\beta}=\frac{\beta}{\sin\beta}$$ I have an indirect proofï¼ but it is more complicated. I believe there is a more elegant way to do this. My complicated answer: $$\int_{0}^{\frac{\pi}{2}} \frac{\mathrm{d} \alpha}{1+\cos \alpha \cos \beta} =\int_{0}^{\frac{\pi}{2}} \sum_{n=0}^{\infty}(-\cos \alpha \cos \beta)^{n} \mathrm{~d} \alpha \\
		=\sum_{n=0}^{\infty}(-\cos \beta)^{n} \int_{0}^{\frac{\pi}{2}} \cos ^{n} \alpha \mathrm{d} \alpha \\
		=\sum_{n=0}^{\infty}(-\cos \beta)^{n} \frac{\sqrt{\pi} \Gamma\left(\frac{n}{2}+\frac{1}{2}\right)}{2 \Gamma\left(\frac{n}{2}+1\right)} \\
$$ On the other hand: $$\int \frac{d x}{1+\varepsilon \cos x}=\frac{1}{\sqrt{1-\epsilon^{2}}} \operatorname{arctan}\left(\sqrt{\frac{1-\varepsilon}{1+\varepsilon}} \operatorname{tan} \frac{x}{2}\right)+C, \varepsilon\in(-1,1)$$ In this way, I can get the answer. But it is complicate. So I need help.","['integration', 'definite-integrals', 'sequences-and-series']"
3952355,Problem: Integrate using the Trigonometric Substitution method,"Exercise about Trigonometric Substitution Objective: Resolve using the Trigonometric Substitution method. I've already tried solving the exercise by taking the following steps: I take e^x as 2sen(t) and I substitute. Take dx as 2cos(t)dt. After some easy straight-foward steps, I came out with this: The result has to be and the integral of sen(t) is cos(t).","['multivariable-calculus', 'calculus', 'algebra-precalculus']"
3952365,Why is it called 'King's Property of Integration'?,"Recently I learned about ""King's Property"" or ""King's Rule"" and I was wondering about its etymology? I understand that it's a basic change of variables but it has a name for a reason. I've been unable to find this reason online. I speculate that the person who first encountered it had the popular surname King. In case terminology is different elsewhere, here's what I'm talking about: $$\int_{a}^{b}f(x)dx=\int_{a}^{b}f(a+b-x)dx$$","['integration', 'definite-integrals', 'calculus', 'math-history', 'soft-question']"
3952369,A question related to $f(n)=n^4+n^2+1$,"If $$f(n)=n^4+n^2+1$$ then we have to evaluate $$\frac{f\left(3\right)f\left(5\right)f\left(7\right)f\left(9\right)f\left(11\right)f\left(13\right)}{f\left(2\right)f\left(4\right)f\left(6\right)f\left(8\right)f\left(10\right)f\left(12\right)}$$ which, when run in Desmos, returns 61. But obviously we can't evaluate this with brute force. The farthest I have reached is that $$n^4+n^2+1=n^2(n+1)+\frac{n+1}{n+1}=(n^2+\frac{1}{n+1})(n+1)$$ Any hints?","['fractions', 'functions', 'factoring', 'polynomials']"
3952379,"Let $A_1,A_2\in L(V,V)$, $A_i(V)=V$ and $\dim\ker A_i=n_i\in\mathbf{N}$. Is $\dim\ker (A_2A_1)=n_1+n_2$ even if $\dim V=\infty$?","Let $V$ be a vector space that is not necessarly finite dimensional. Consider two surjective linear operators $A_1,A_2\in L(V,V)$ with finite-dimensional kernel: $A_i(V)=V$ and $\dim\ker A_i=n_i\in\mathbf{N}$ . Can it be proven that $\dim\ker (A_2A_1)=n_1+n_2$ ? In words: Is the dimension of the kernel of the composition of surjective linear operators with finite dimensional kernels the sum of the dimensions of the kernels? Looking at this formula, one might think that the formula $\dim\ker A_2A_1=n_1+_2$ is valid, but I have looked at the answers and they are based on the rank nullity theorem, which I can't use, since $V$ is not finite dimensional. Motivation: I want to prove that the solution space of homogeneous linear differential equations of order $n$ is $n$ -dimensional by writing the $n$ -th order differential operator as composition of first-order differential order with one-dimensional kernel. Actually, the answer to this question completes my proof .","['operator-theory', 'linear-algebra']"
3952504,Spectrum of semi-infinite Toeplitz matrices,"I am considering a self-adjoint semi-infinite Toeplitz matrix , by which I mean $$M = \left(\begin{array}{ccccc}
a_0  & a_1  & a_2  &  a_3 & \cdots \\
a_1^*& a_0  & a_1  &  a_2 & \ddots \\
a_2^* & a_1^*& a_0  & a_1  &  \ddots \\
a_3^*& a_2^* & a_1^*& a_0  & \ddots \\
\vdots & \ddots & \ddots & \ddots & \ddots
\end{array}\right) $$ where $\{a_n\}_{n=-\infty}^{+\infty}$ are complex numbers, and the star "" $^*$ "" indicates the complex conjugation. It is assumed that $\sum_n \left|a_n\right|$ is finite. I would like to understand the eigenvalue spectrum of $M$ , especially when compared to its infinite analog $M_0$ . It is well known (and shown e.g. by going to a Fourier-transformed basis) that the eigenvalues of $$M_0 = \left(\begin{array}{cccccc}
\ddots & \ddots  & \ddots  & \ddots  &  \ddots & \ddots \\
\ddots & a_0  & a_1  & a_2  &  a_3 & \ddots \\
\ddots & a_1^*& a_0  & a_1  &  a_2 & \ddots \\
\ddots & a_2^* & a_1^*& a_0  & a_1  &  \ddots \\
\ddots & a_3^*& a_2^* & a_1^*& a_0  & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots & \ddots
\end{array}\right) $$ form a one-dimensional family $$\lambda(\omega) = a_0 + 2\sum_{n=1}^{+\infty} \left[\Re[a_n] \cos(n \omega)+\Im[a_n] \sin(n \omega )\right]$$ where $\omega\in [0,2\pi)$ . It then follows from the finiteness of $\sum_n |a_n|$ that the spectrum of $M_0$ is both compact and connected, namely an interval $$\textrm{spec}(M_0) = [x_1,x_2]$$ where $|x_{1,2}|<\infty$ are some finite numbers. However, the spectrum of the semi-infinite matrix $M$ cannot be found using the same Fourier-transform trick, and I suspect there is no exact solution in this case. The question: Is it true that $\textrm{spec}(M)\subseteq \textrm{spec}(M_0)$ ? My simple numerical tests suggest that this should be true, but I didn't manage to prove this and I also failed to find a suitable reference. I was hoping that someone in the Stack Exchange community either readily knows the answer, or could point me to the relevant references/books. If the answer turns out to be ""no"", then I also have a second question: Is $\textrm{spec}(M)$ always connected (as is the case for $M_0$ ), or is it possible that it exhibits some isolated eigenvalues detached from the continuum part of the spectrum?","['eigenvalues-eigenvectors', 'toeplitz-matrices', 'infinite-matrices', 'matrices', 'spectral-theory']"
3952518,How to find the limit of $f(x)$.,"Let $$f(x) = {\frac{e^{e^x - 1} - \frac{1}{1 - x}}{\ln(\frac{1 + x}{1-x}) - 2\sin x}}$$ I need to find a $ \lim_{x \to 0}f(x)$ . As I understand, we have to do some Taylor series decomposition and problem should be pretty easy. But I have had some troubles with it. P.S : I can decompose $\ln(\frac{1 + x}{1-x})$ as $\ln(1 + \frac{2x}{1-x})$ to use some standard Taylor formulas. I know $\sin x$ Taylor series, but I've got some troubles with $e^{e^x-1}$ and some further transformations.","['limits', 'real-analysis']"
3952619,Evaluate $\underset{n\to \infty }{\text{lim}}\left(\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}\right)$,"Evaluate the limit $$
\underset{n\to \infty }{\text{lim}}\left(\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}\right)
$$ I got stuked when trying to evaluate it and I even don't know where to begin. Mathematica tells me that $$
\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}=\frac{2^{1/n} \left(-\left(2^{1/n}\right)^n \Phi \left(2^{1/n},1,n+1+\frac{1}{n}\right)+\left(2^{1/n}\right)^{n+1} \Phi \left(2^{1/n},1,n+1+\frac{1}{n}\right)-2^{1/n} \Phi \left(2^{1/n},1,1+\frac{1}{n}\right)+\Phi \left(2^{1/n},1,1+\frac{1}{n}\right)+n \left(2^{1/n}\right)^n-n\right)}{\left(2^{1/n}-1\right) n^2}
$$ However it doesn't give the result of the limit either. And I tried $n=10000$ numerically, the answer is $1.44274..$ . So how to calculate the limit ?","['limits', 'summation', 'special-functions']"
3952680,Hartshorne Chapter V Proposition 1.5,"This proposition states as follows, What confuses me is the last sentence. Notice that the Lemma 1.3 states as follows. We also have the fact that, The pairing  Div $X \times \operatorname{Div} X \rightarrow \mathbf{Z},$ only depends on the linearly equivalence class. If $C$ and $D$ are nonsingular curves meeting transversally, then $C . D=$ $\#(C \cap D),$ the number of points of $C \cap D.$ So my qusetion is (1) In the case of Adjunction formula, how to guarantee  there exists $H\in|C+K|$ such that $H$ meets $C$ transversally? (2) As mentioned in the statement of self-intersection, for a nonsingular curve $C$ on the smooth projective variety, we also have $C^2=\text{deg}\mathcal O_C(C)$ . So, it seems that we always have $C . D=\text{deg}\mathcal O_C(D)$ for any nonsingular irreducible curve $C$ ? Is it right? Why? Any help would be appreciated. Thanks a lot!","['complex-geometry', 'algebraic-geometry', 'intersection-theory']"
3952728,If the line at infinity is a secant line of a conic then the conic is a hyperbola?,"I'm learning perspective geometry and I have a question about the line at infinity. Is it true that if the conic has the line at infinity as its secant then the conic represents a hyperbola in Euclidean geometry? If it is, how can I imagine the shape hyperbola using the line at infinity? I think I can lift up the line to infinity but it seems like a parabola than a hyperbola. I draw a conic going through $A, B, C, D, E$ , and I choose AB as the line at infinity. Then I lift it up and it seems like a parabola P.S: I'm quite new to this field so I may use the wrong jargon. Thank you","['euclidean-geometry', 'projective-geometry', 'conic-sections', 'geometry']"
3952732,Why are these two double integrals different ? A question on Dirac delta distribution,"Consider the following two integrals: \begin{align}
I_1&:=\iint_{0\leq x,\, y\leq 1,\,x=y}\,dx\, dy,\\
I_2&:=\int_0^1\int_0^1 \delta(x-y)\,dx \,dy.
\end{align} I believe $I_1=0$ because it is the measure ""surface area"" of the line segment $y=x$ inside a two dimensional rectangle. From the properties of the delta function, we have $$I_2=\int_0^1\int_0^1 \delta(x-y)\, dx\, dy=\int_0^1 1 \,dy=1$$ as $$\int_0^1 \delta(x-y)\, dx =1$$ for any $y\in ]0,1[.$ Question : I understand very well that the integrands are different in $I_1$ and $I_2$ . In $I_1$ , the integrand is
the characteristic function $\chi_{0\leq x,y\leq 1,x=y}(x,y)$ . But these integrands are different on a negligible set... I am confused!","['multivariable-calculus', 'lebesgue-measure', 'dirac-delta']"
3952773,"Given that matrix $A$ is diagonalizable and has eigenvalues of $0$ or $1$, show that $A^2 = A$","Suppose that $A$ is a diagonalizable $n \times n$ matrix such that the characteristic polynomial of $A$ is $p(Î»)=Î»^k(1âÎ»)^{nâk}$ , where $k$ is a positive integer such that $0â¤kâ¤n$ . I want to prove $A^2=A$ . I know that for this, I'll need to prove that for any eigenvector $v$ , $A^2 v=Av$ . I tried setting up my proof like this: Since $A$ is diagonalizable, there exists an invertible matrix $P$ such that $A=P^{-1}DP$ , where $D$ has all the eigenvalues of $A$ on its diagonal. But since every eigenvalue is either $0$ or $1$ , $D= \lambda I$ . From there, we get: $$A = P^{-1}DP = P^{-1}(\lambda I_n)P = (\lambda I_n)(P^{-1}P) = \lambda I_n$$ $$ \implies A \times A = (\lambda I_n) \times (\lambda I_n) = \lambda ^2$$ All I've succeeded in doing here is showing $A^2 = \lambda ^2$ . How can I show also that $A^2 = A$ ? Any guidance is greatly appreciated!","['matrices', 'diagonalization', 'linear-algebra', 'eigenvalues-eigenvectors']"
3952798,Genericity of an induced projection map,"Let $X,Y$ be smooth manifolds, $S'$ a submanifold of $Y$ , and $f:\mathbb{R}\times X\to Y$ a smooth function. Generically, we have that $f$ is transverse to $S'$ , which implies that $S:=f^{-1}(S')$ is a smooth submanifold of $\mathbb{R}\times X$ . It comes with a projection map, namely the restriction of the projection on $\mathbb{R}$ to $S$ . My question is: Is there a generic property I can also ask $f$ to check in order for this projection to be a Morse function? So far analyzing this first transversality condition, I can describe the tangent space of $S$ , $$T_{(t,x)}S=\left\{(\dot{t},\dot{x})\in \mathbb{R}\times T_xX\,;\,(d_Xf)_{(t,x)}(\dot{x})+\dot{t}\frac{\partial f}{\partial t}(t,x)\in T_{f(t,x)}S'\right\},$$ and thus if $(t,x)$ is a critical point of $\pi|_S$ , then every tangent vector of $S$ at $(t,x)$ is sent to $0$ by $d\pi_{(t,x)}$ , which amounts to say that $$T_{(t,x)}S=\left\{(0,\dot{x})\in \mathbb{R}\times T_xX\,;\,(d_Xf)_{(t,x)}(\dot{x})\in T_{f(t,x)}S'\right\}\simeq(d_Xf)_{(t,x)}^{-1}(T_{f(t,x)}S').$$ From this we can say that $f_t$ is not transverse to $S'$ , otherwise we would have a problem of dimension ( $T_{(t,x)}S$ would be 1 dimension less than expected). So by the transversality parametric theorem, I can conclude that the regular values of the projection are generic. But there is nothing about the critical values being non-degenerate, and I can even construct a counter-example where the transversality condition alone does not result in the projection being Morse: take $f:\mathbb{R}\times\mathbb{R}\to \mathbb{R}^2$ given by $f(t,x)=(t,x)$ and $S'=g(\mathbb{R})$ with $g(x)=(x^3,x)$ . So I have to add something else, probably a transversality condition involving the 1-jet of $f$ , but I can't find it and every help will be much appreciated. Thanks for reading my question! Edit regarding Ted Shifrin's comment: Taking a metric on $S$ , the fact that $\pi$ is Morse translates as $\mathrm{grad}\,\pi$ is transverse to $0_{TS}$ , or again that for all $(t,x)\in S$ s.t. $d\pi_{(t,x)}=0$ , then $$\nabla\mathrm{grad}\,\pi:T_{(t,x)}S\to T_{(t,x)}S,(0,\dot{x})=\dot{x}\mapsto\nabla_{\dot{x}}\mathrm{grad}\,\pi$$ is onto. Since in coordinates, $\nabla_{\dot{x}}\mathrm{grad}\,\pi$ is given by $$\left(\dot{x}^i\partial_l\pi(\partial_ig^{lk}+g^{lj}\Gamma_{lj}^k)\right)\frac{\partial}{\partial x^k},$$ this amounts to show that for all $\dot{y}=\dot{y}^k\frac{\partial}{\partial x^k}$ s.t. $(d_Xf)_{(t,x)}(\dot{y})\in T_{f(t,x)}S'$ , there exists a $\dot{x}=\dot{x}^i\frac{\partial}{\partial x^i}$ s.t. $(d_Xf)_{(t,x)}(\dot{x})\in T_{f(t,x)}S'$ and $$\dot{x}^i\partial_l\pi(\partial_ig^{lk}+g^{lj}\Gamma_{lj}^k)=\dot{y}^k.$$ What bothers me from this writing is that I still can't see what property I could add to $f$ in order to this be verified (it will be as soon as $\det\left(\partial_l\pi(\partial_ig^{lk}+g^{lj}\Gamma_{lj}^k)\right)_{ik}\neq 0$ , but I think that this is equivalent to ask that $\mathrm{Hess}(\pi)_{(t,x)}$ is non-degenerate, which is simply the definition of $\pi$ being a Morse function ; and I don't manage to involve the condition $(d_Xf)_{(t,x)}(\dot{y})\in T_{f(t,x)}S'$ ). Again, every help from here will be much appreciated!","['transversality', 'morse-theory', 'differential-geometry']"
3952821,Continuous curve for 2-adic valuation of x,"I am trying to find a continuous curve that will go trough all the points in the graph created if you were to plot the 2-adic valuation of x which is defined as how many times you can divide a number by two before the result gives an odd number. This can be defined by the function: $$f(x)=\left\{\begin{array}
 &0\text{ when x is odd}\\
 f(\frac{x}{2})+1\text{ when x is even}\\
 \end{array}\right. $$ The problem with this is that I cant differentiate since I need a continuous curve, and right now this only gives me what the values go like: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,etc. $$$$ What I am currently trying is to find a trigonometric function that represents it. For example $\cos^2{\left(\frac{\pi}{2}x\right)}$ works for some values (just the alternating 0's and 1's) but I dont know how I could modify this to fit all values.","['continuity', 'trigonometry', 'recurrence-relations']"
3952822,Riemann-Stieltjes integral with respect to a discontinuous function,"I have to find if the function $f(x)=x^2$ is Rieman-Stieltjes integrable respect to the function $g(x)=3x$ if $x\in[0,1)$ and $g(1)=4$ . Now, because $f$ is continuous and $g$ is of bounded variation, the integral indeed exists. To find the value of the integral, I chose to find the integral: $$\int_0^1f(x)d(g(x))-\int_0^1f(x)d(3x)$$ By definition of $g$ , this is: $$\int_0^1f(x)d(h(x))$$ Where $h(x)=g(x)-3x$ , so $h(x)=0$ for $x\in[0,1)$ and $h(1)=1$ Finding it by definition, if $\epsilon>0$ , and I chose the partition $P=\{0,1-\epsilon,1\}$ , then: $S(P,f,h)=f(0)(h(1-\epsilon)-h(0))+f(1-\epsilon)(h(1)-h(1-\epsilon))=f(1-\epsilon)=(1-\epsilon)^2$ From here, I could conclude that: $$\int_0^1f(x)d(h(x))=1$$ Is this correct? Because intuitively I thought it was going to be $0$ , or did I do something wrong?.","['integration', 'calculus', 'analysis', 'real-analysis']"
3952843,Proving a floor function is injective/surjective [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question Is the function $\lfloor x/2\rfloor$ injective or surjective? If so why? The domain is $\mathbb R$ and the co-domain is $\mathbb Z$ . I think it is not injective as if we take x to be $20$ and $y$ to be $21$ , we end up with $f(x)=10=f(y)$ , but $x$ is not equal to $y$ . I know that to check for surjection, we have to solve in terms of $x$ , but since this is a floor function, I'm not sure what to do with the floor symbol while solving for $x$ . Thanks in advance.",['discrete-mathematics']
3952962,How many ways can 7 seats and 4 seats car fill with 9 people at the same time?,I applied my combination skill and came up with bunch of answers that does not correspond to the correct answer please explain first where did I miss or break my logic If I put 3 people in 4 seats car then there will be 7 people to pick for 7 seats car 9 C 2 * 7 C 7 = 36 If I put 3 people in 4 seat car then there will be 6 people to pick for 7 seats car 9 C 3 * 7 C 6 = 588 If i put 4 people in 4 seats car the there will be 5 people to choose for 7 seats car 9 C 4 * 7 C 5 = 4410 total = 5034 the correct answer is 246. P.S:New to combinations.,"['permutations', 'combinations', 'combinatorics']"
3952975,How can I solve this absolute value inequality: $|-2x|> \frac{-x}{2} -3$?,"$|-2x|> \frac{-x}{2} -3$ This inequality isn't from a textbook, I made it out because I felt like there must be some cases when the methods I learnt in class won't work. These are the methods I used and that I only know: First method $-2x>\frac{-x}{2}-3$ â $x<2$ $-(-2x)>\frac{-x}{2}-3$ â $x>-1.2$ Answer: $-1.2<x<2$ And after checking by substituting any number smaller than $2$ or bigger than $-1.2$ , I get correct answers. Second method $(|-2x|)^2 > (\frac{-x}{2}-3)^2$ Answer: $-1.2<x<2$ But this answer is wrong because looking at the graph I can see that the absolute value function is always above the straight line. The answers I get are true if the straight line had an absolute value sign too or because of the parts under the x-axis of functions $-2x$ and $-(-2x)$ that no longer exist because of the absolute value sign. So how can I solve this inequality without drawing? And how does I know that the answers I get are wrong or incomplete when solving anything similar?","['functions', 'absolute-value']"
3952977,How to demonstrate that there would exist a vertex with degree less than $ 5$? [duplicate],"This question already has answers here : Every planar graph has a vertex of degree at most 5. (3 answers) Closed 3 years ago . Question: Letting S be a planar graph. 
                Demonstrate that there would exist a vertex of S whose degree
                       would be no greater than 5, ie, $\leq 5$ I have just gotten started with Discrete Math Graph Theory and it would be a great help if someone could assist me in working out the steps to understand the problem and work through the answer with a detailed explanation? Thanks.","['graph-theory', 'discrete-mathematics']"
3953105,"Soft question, limit of $n\mathbb{Z}$","I was trying to think of countable subsets of $\mathbb{R}$ that were, in a sense, small. By that I mean how 'spread out' the terms were. I know this isn't at all concise, but for example, $3\mathbb{Z}$ is 'smaller' (in the manner described above) than say $2\mathbb{Z}$ . So this got me thinking, looking at specifically $n\mathbb{Z}$ , is there anything meaningful to talk about $\lim_{n\to\infty}{n\mathbb{Z}}$ ? Firstly I thought, does this even make sense? Is it just a meaningless thing to consider? What made intuitive sense is, if we consider the extended reals, that the limit is $\{-\infty,+\infty\}$ , but that just seemed somehow not quite right. Is there any resources available, or anything to talk about limits, or limits alike?","['limits', 'soft-question']"
3953136,"Which equilateral triangles does the P-hexiamond (the ""sphinx"") tile?","There's been lots of work investigating the polyominoes which can tile a square (equivalently, a rectangle). However, as far as I can tell there's been less investigation into the polyiamonds which can tile an equilateral triangle. Two obvious restrictions come to mind. First, the polyiamond has to actually fit into a corner - i.e., there is some 60-degree angle the tile covers the tip of without exceeding its bounds. Second, we have a simple coloring argument: the number of right-side-up and upside-down triangles in the tile can't be the same, because in an equilateral triangle there are more of one than the other. Applying these two conditions to all the polyiamonds on at most 4 triangles as listed e.g. here , every case is either immediately ruled out or can be easily seen to work for every triangle of a plausible side length (i.e., $s$ such that $s^2$ is a multiple of the number of triangles in the tile). For the pentiamonds, we have: C $5$ : Can't fit in the corner, ruled out. L $5$ : If placed in the corner, it leaves a $60$ degree angle void which must be filled by a piece in the same orientation, which repeats infinitely and never fits into the other corner of an equilateral triangle: P $5$ : Can be ruled out by a small amount of casework: there's only one way to place the first piece in the corner, and then a second triangle in the ""concave part"" of the piece can only be filled in one way, but placing those two pieces leaves a void that can't be filled. I $5$ : Very difficult; it turns out the answer is yes for all triangles with side length $5k\ge 30$ , as discussed in this MathOverflow thread . I'm interested in extending this to the hexiamond case. The two considerations outlined above rule out every piece but F $6$ and P $6$ . For F $6$ , I've managed to show that the tiles must join into parallelograms in a way that prevents them from ever lining up with a third side of an equilateral triangle. For P $6$ , however, things are more complicated. (Since it is a rep-tile , it can certainly tile an infinite triangular ""quadrant"" (hexant?).) Via an exhaustive search with a computer program, I have verified that P $6$ does not tile an equilateral triangle of side length $6$ . However, it does tile an equilateral triangle of side length $12$ : A search for side length $18$ did not reveal any solutions after running for a while, but it was nowhere near completion when I halted the search - the tools I'm using don't seem very tractable for this or higher cases. Which equilateral triangles can be tiled by the sphinx polyiamond? Edit: I think that computing the tile homotopy group of the sphinx, as described in this paper , may be promising; as Theorem $7.16$ in the paper shows, it can be used to answer questions of this type for very similar kinds of tiles. Tile homology techniques may work as well, although not if it turns out that there is a signed tiling of the size- $6$ equilateral triangle with the sphinx.","['geometry', 'tiling']"
3953152,How to write any member of a sigma algebra as a subset of a countable union of members of the generating algebra,"Iâm currently working my way through Real Analysis by Folland and, in his proof of theorem 1.14 he does something I donât quite understand: Take some algebra $\mathcal{A}$ on some set $X$ which generates some $\sigma$ -algebra $\mathcal{M}$ . If we have $E \in \mathcal{M}$ then we write $E \subset A$ , where $A := \cup_{1}^{\infty} A_j$ for some $A_j \in \mathcal{A}$ . Now, I believe this is possible because $X \in \mathcal{A}$ and $E \subset X$ . However, what I donât understand is that he then goes on to say that, given some $\epsilon > 0$ we can choose the $A_j$ âs in such a way that $\mu(A) \leq \mu(E) + \epsilon$ for a measure $\mu$ on $(X, \mathcal{M})$ . How can we make such a choice?","['measure-theory', 'outer-measure', 'real-analysis']"
3953164,Verify that ~(P â Q) â¡ P â ( ~Q) using logical equivalencies (not truth tables),I have been able to verify this via truth tables but not with logical equivalencies yet. I understand some of the basic principles of logical equivalencies but I cannot seem to get to the end of this problem where one side equals the other.,"['logic', 'discrete-mathematics']"
3953188,"Find x, and prove by induction that Q(n) holds for all n â¥ x.","Question: Let $Q(n)$ be a statement $""n! < "" n^n""$ and let $x$ be the smallest natural number
for which $Q(n)$ would be true.  Find $x$ , and prove using induction that $Q(n)$ would hold for all $nâ¥ x.$ [Note: Take $0^0 = 1$ ] Here is what I have so far, Let $Q(n)$ be $""n! < "" n^n""$ where $n$ is an integer greater than 1. Replacing $n$ by 2 in the expression for $Q(n)$ , $$Q(2): 2! < 2^2$$ Basis Step: $\qquad \qquad \qquad \qquad \qquad \qquad 2! = 2 < 4 = 2^2$ $\qquad \qquad \qquad \qquad \qquad \qquad \qquad  \qquad \qquad  Q(2)$ holds true Induction Hypothesis: $\quad \quad \quad \quad \quad \quad$ Let $Q(k)$ be true, $\qquad \qquad \qquad \qquad \qquad \qquad \qquad  \qquad \qquad  k! < k^k$ $\qquad \qquad \qquad \qquad \qquad \qquad \qquad $ Need to prove that $Q(k+1)$ is true , $\qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad (k+1)! < (k+1)^{k+1}$ Induction Step: $\quad \quad  \qquad \qquad $ Need to prove that Q(k+1) is also true, $$(k+1)! = (k+1) \cdot k!\\
< (k+1) \cdot k^k \quad \leftarrow 1\\ 
< (k+1) \cdot (k+1)^k \quad \leftarrow 2 \quad (\mbox{Since } k < k+1 )\\
= (k + 1)^{k+1}$$ $\qquad \qquad \qquad \qquad \qquad \qquad \qquad  \qquad \qquad  Q(k+1)$ holds true Conclusion: $\qquad \qquad$ By Induction, $Q(n)$ is true for all positive integer $n$ greater than 1. Would there be a need, in between the steps labelled by arrows 1 and 2 to expand: $$(k+1)^k = k^k$$ $$(k+1)^k = k$$ I have been trying to work this problem out and I have been wondering whether this would be the right way to go about solving it.If not, could someone work it out to show me how? All help appreciated. Thanks.","['induction', 'discrete-mathematics']"
