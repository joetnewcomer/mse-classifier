question_id,title,body,tags
1266700,"For a polynomial $f\in K[x]$, when is there a constant $c\in K$ such that $f+c$ is irreducible?","I was working on a different problem when the following question occurred to me: For a polynomial $f\in K[x]$, is there always a constant $c\in K$ such that $f+c$ is irreducible? Obviously this is false for some fields, consider $x^2$ over $\mathbb{F}_2$, $x^2$ factors as does $x^2+1$. In general it must be false for finite fields as $x^q+c$ has a root at $c$ for all $c$ in $\mathbb{F}_q$. Or take any algebraically closed field, trivially this cannot be done for a nonlinear polynomial since all nonlinear polynomials are reducible. If $K=\mathbb{R}$, then this is also clearly false for any polynomial of degree greater than 2, but it is true for polynomials of degree 2, since $x^2+ax+b$ has discriminant $a^2-4b$ so for $b>a^2/4$, the polynomial is irreducible. So my question is actually the following: Are there any fields for which this is true for all polynomials? Also is it true in for all fields in the restricted sense? I.e. as in $\mathbb{R}$, true for all polynomials of at most degree $n$ and only true for these polynomials. Note that $n$ may be 1. Also can we compute this $n$? I guess what I'm asking is when can I add a constant to make a polynomial irreducible? Also interesting is the case when $K$ is replaced with a ring. I have no idea how to begin this question, any suggestions would be appreciated. I would prefer a good indication of what direction to go if it would be reasonable to solve this problem with my background (undergraduate algebra/number theory/basic galois theory/very little analysis) rather than a complete solution, but either is appreciated. I should mention that I did google this and found nothing, but if you find something, that would also be appreciated. Thanks, I hope I'm not missing something obvious.","['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
1266705,"Evaluating a seemingly simple limit, using continuity of the partial derivative","I am stuck with a seemingly easy problem. I have a function $f(x,y)$ which has continuous first derivatives. Now, I want to show that: $$ \lim_{h \to 0}\dfrac{f(a+hu,b+hv)-f(a,b+hv)}{hu} =f_x(a,b)$$ This is what I have thought: Since the derivatives are continuous, we know that, for each $\epsilon > 0$, there is a $\delta > 0$ such that it is: $$0 < ((x-a)^2 + (y-b)^2)^{1/2} < \delta \implies |f_x(x,y) - f_x(a,b) | = \left|\lim_{h \to 0}\dfrac{f(x+h,y)-f(x,y)}{h} - \lim_{h \to 0}\dfrac{f(a+h,b)-f(a,b)}{h} \right| < \epsilon$$ My plan was to relate the first expression to this definition of the continuity of partial derivative. But the $hv$ which is added to $b$ spoils this idea. I think I am missing something very obvious here, but annoyingly I can't figure what. How should I proceed?","['calculus', 'limits', 'multivariable-calculus']"
1266752,Factorising trigonometric functions,"In order to factorise $x^2-1$ one way of thinking about it would be to set it equal to zero and solve to get $x=1$ and $x=-1$. You can then write $x^2-1=(x+1)(x-1)$ Can we do the same with trigonmetric functions, i.e sin$x=0 \implies x=n\pi$ so sin$x=x(x-\pi)(x+\pi)(x-2\pi)(x+2\pi)...$","['factoring', 'trigonometry']"
1266758,Are complex split-octonions isomorphic to a more easily-defined algebra?,"I write fiction and nonfiction, both which are mathy.  My fiction is not usually supermathy but I'm working on a fictional story that has some math in it, and I prefer accuracy to mathbabble.  I'm stepping outside my particular math domain so what I am asking may be incredibly naive, but here it is. I have two questions. $0)$ Are complex split-octonions (that is, split-octonions with complex coefficients) isomorphic to another algebra more easily defined or described?  I mention this because the Muses's so-called ""conic sedenions"" are isomorphic to complex octonions, and for all I know complex split-octonions can be reduced to some other algebra. $1)$ Can complex split-octonions be represented as a simple subalgebra (I am using this word very loosely, obv.) of trigintaduonions?  If not, could they be represented as a simple subalgebra of a higher Cayley construction? Thanks for your time, and if this question is ludicrous in some way, let me know so I can fix or remove it.","['octonions', 'abstract-algebra', 'sedenions']"
1266769,Show that $α$ is a perfect square in the quadratic integers in $\mathbb Q[\sqrt{d}]$,"Question: Suppose that $\mathbb Q[\sqrt{d}]$ is a UFD, and $α$ is an integer in $\mathbb Q[\sqrt{d}]$ so that $α$ and $\barα$ have no common factor, but $N(α)$ is a perfect square in $\mathbb Z$. How can I show that $α$ is a perfect square in the quadratic integers in $\mathbb Q[\sqrt{d}]$? What I have Done: I'm not sure if I'm approaching this correctly but if  $\alpha$ and  $\bar{\alpha}$ have no common factor, then $\alpha=\pi_{1}\pi_{2}\cdots\pi_{k}$ and  $\bar{\alpha}=\pi'_{1}\pi'_{2}\cdots\pi'_{j}$ where $ \pi_{i}$ and  $\pi'_{i} $ are prime in  $\mathbb{Q}(\sqrt{d})$. But $N(\alpha) = \alpha\bar{\alpha}=\pi_{1}\pi_{2}\cdots\pi_{k}\pi'  _{1}\pi'_{2}\cdots\pi'_{j}=n^{2}$ where  $n \in \mathbb{Z}$. Somehow I need to show that $\alpha=\beta^{2}$ where  $\beta$ is a quadratic integer in $ \mathbb{Q}(\sqrt{d})$ (i.e.,  $\alpha$ is a perfect square in the quadratic integers in  $\mathbb{Q}(\sqrt{d})$)","['ring-theory', 'field-theory', 'number-theory', 'elementary-number-theory']"
1266784,Is a polynomial ring over a UFD in countably many variables a UFD?,"Let $R$ be a UFD. It is well know that $R[x]$ is also a UFD, and so then is $R[x_1,x_2,\cdots,x_n]$ is a UFD for any finite number of variables. Is $R[x_1,x_2,\cdots,x_n,\cdots]$ in countably many variables also a UFD? If not, what about if we take $\tilde{R} = R[x_1,\cdots,x_n,\cdots]$ where each polynomial must be given in finitely many of the variables?","['abstract-algebra', 'unique-factorization-domains', 'ring-theory']"
1266791,I need a Hint on this Differential equation,"Let $f$ and $g$ be two real functions, and we have 
$$ (f*g)(t)= \int_0^tf(s)g(t-s) \, ds $$
we have the following equation 
$$y'+ay=f(t) $$ where a is a constant and f is a function 
-/ prove that if $$ g(t)=e^{-at}, $$ then $$ y =f*g$$ is a solution to the equation verifing $$ y(0)=0.$$
by jsut replacing y in the equation as $$ \int_0^t f(s)g(t-s) \, ds $$ does that mean that $$ y' = f(s)g(t-s)$$
if so we will have 
$$ f(s)g(t-s) +a \int_0^t f(s)g(t-s)ds=f(t) $$
and by replacing g with $$ g(t)=e^{-at}, $$ 
then we have 
$$ f(s) e^{-a(t-s)}+a \int_0^t f(s) e^{-a(t-s)} =f(t) $$
How Do we solve this ?","['definite-integrals', 'real-analysis', 'ordinary-differential-equations']"
1266792,Choosing a Cauchy sequence for a real,"It is easy to form in ZF, for each real $a$ , a ""canonical"" Cauchy sequence that converges to $a$ . For example, one can take the sequence of finite initial segments of the decimal expansion of $a$ , being careful when $a$ is a base-10 rational to pick one of the two decimal expansions explicitly. But what if we are given a set of Cauchy sequences of rationals, all converging to the same real. The set might not contain all the Cauchy sequences for that real. How hard is it to pick a ""canonical"" representative from the sequences that are in the set? To make this question precise: consider a family of sets $C$ so that each $X \in C$ is a set of Cauchy sequences of rationals that all converge to the same real $a(X)$ . Note that $X$ is not required to have the entire set of Cauchy sequences for $a(X)$ . Does ZF prove the existence of a choice function for each family $C$ of this kind? There are two aspects of Cauchy sequences that make this problem interesting. First, every infinite subsequence of a Cauchy sequence is again a Cauchy sequence converging to the same real. So we cannot hope for a ""minimal"" sequence. Also, we may prepend any finite sequence to a Cauchy sequence to yield a new Cauchy sequence converging to the same real. So we cannot hope for a ""maximal"" sequence. Cauchy sequences are very slippery in this way. Dedekind cuts behave differently: once we specify whether cuts for rationals can have a maximum element, we have a unique Dedekind cut for each real, whereas we always have infinitely many Cauchy sequences. I have a vague memory of encountering something similar to this question in the past, but I cannot remember any details.  It also seems to have a flavor related to Borel equivalence relations, although this question is not written in that way.","['elementary-set-theory', 'logic', 'axiom-of-choice']"
1266858,Is there any geometrical interpretation as to why matrix product is not commutative?,"Is there any geometrical interpretation as to why matrix product is not commutative? Similarly, is there any geometrical interpretation of matrix product when you have  matrices $A$, $B$ such that $AB=BA$?","['geometry', 'matrices']"
1266870,Set theory $A-(B-A) = A-B$,"Determine which of he following statements are true for all sets $A,B,C,D$. If a double implications fails, determine whether one or the other statement of the possible implication holds, If an equality fails, determine whether the statement becomes true if the “equals” is related by one or the other of the inclusion symbols $\subseteq$  and left contains sign). I was trying to solve this and stumbled upon a solution using the Universal set, but I don't know how to use the universal set. Is it possible to solve without it? This is what the first part of the solution looks like. Q:  $A-(B-A) = A-B$
this statement is false, so I proceed to try the other statement: $A-(B-A) \subseteq A-B$: $$A-(B-A) = A\cap(U - (B\cap(U - A)))$$ and he expanded this, but again I have no experience with the Universal set so can I show the statement is true without it? Edit\attmept at $A-(B-A) \subseteq A-B$: let $x\in A-(B-A)\implies x\in A$ or $x\notin B-A$  or $x\in A$ and ($x\in B\ and\ x\notin A)\implies$ but $x\in A$ in both case therefore $A-(B-A)\subseteq A-B$",['elementary-set-theory']
1266969,Nonparametric Skew of Data,"Recently in my studies of statistics, I have come across the second skewness coefficient to determine the skewness of the set of data. The formula is given by:
$$ \frac{3(\mu - \nu)}{\sigma}$$
However, as a positive skew is indicated by a larger positive number, and a negative one by a larger negative number, I do not see the need for the factor of 3. Pearson thought it important enough to adopt this new way, but now most people simply drop the factor of 3. The reason on Wikipedia is ""..the difference between the mean and the mode for many distributions is approximately three times the difference between the mean and the median"", which I do not understand. Please can someone explain why the factor of 3 is there? 
Thanks for the help","['statistics', 'statistical-inference']"
1266972,A holomorphic function which takes real values at $ 1/n $ has real coefficients,"I'm facing the following problem: Let $ f : U \rightarrow \mathbb{C} $ be holomorphic ($ U $ is a complex domain and $ 0 \in U $). Suppose that for all $ n = 1,2,3 \dots $ it holds that $ f(1/n) \in \mathbb{R} $. Prove that the coefficients $ a_0, a_1, \dots $ such that $ f(z) = \sum_{i=0}^\infty a_iz^i $ are real. So, obviously, those $ a_i$ are equal to $ f^{(i)}(0) $. It's easy to see that $ a_0 = f(0) $ is real as a limit of real numbers. So is $ a_1 = f'(0) = \lim\limits_{n \rightarrow \infty} \frac{f(1/n) - f(0)}{1/n} $. If I knew that $ f'(1/n) $ is real for all $ n $, I could use the same argument to prove that $ f''(0) \in \mathbb{R} $ and go inductively. However, I can't think of a way to figure this out. I would appreciate some help",['complex-analysis']
1266973,Understanding of the probability,"I have a problem with understanding some of my statistics homework. I hope that some of you could help me understand. In summary the question is as follows: There are 30 people in a group, which are split up in 2 groups of 15. The first group we call group1 and the other group2.  Group1 has been placed in an order from 1 till 15 and group 2 is ordered 16 till 30.  In the question we need to find two persons. We do this by removing each time the 3rd person till we only have 2 people left. So for example: 1 2 3 4 5 6 7 8 9 10 11.. 30; We start with number 4, first number 7 will be removed. Then number 10 will be removed. Next will be number 13. Etc, And after number 28 number 1 will be removed. till there are only 2 people left. The start position is random, so it could be 1 till 30. I need to answer the following questions: What is the probability that there are 0 persons left from group1? What is the probability that there is 1 person left from group1? What is the probability that the two persons, who are still there are both from group1? Someone told me the answers, but I do not understand them. So I hope that someone could explain it to me. I got the following answers: 1) 4/30 2) 22/30 3) 4/30","['probability', 'statistics']"
1266982,"Example 5, Sec. 24 in Munkres' TOPOLOGY, 2nd ed: Is this map always continuous?","Let $(X, \Vert \cdot \Vert)$ be a given normed space that has elements other than the zero vector $\theta_X$. And let $T \colon X-\{\theta_X \} \to X$ be defined by 
$$T(x) \colon= \frac{1}{\Vert x \Vert} x \ \ \ \mbox{ for all } \ x \in X, \ x \neq \theta_X.$$ Then how to determine if $T$ is continuous? Is $T$ always continuous or discontinuous? If $X = \mathbb{R}^n$, then $T$ is of course continuous. Right? After some thought: Let $x$ be an arbitrary element of $X-\{\theta_X\}$. Let $x_n$ be a sequence in $X-\{\theta_X\}$ such that $x_n$ converges to $x$. Then the sequence $\Vert x_n \Vert$ of non-zero real numbers converges in the usual metric space $\mathbb{R}$ to the non-zero real number $\Vert x \Vert$. So the sequence $\frac{1}{\Vert x_n \Vert}$ of reciprocals converges in $\mathbb{R}$ to $\frac{1}{\Vert x \Vert}$. Therefor, the image sequence $T(x_n)$ converges in $X$ to $T(x)$. Hence $T$ is continuous at $x$. Is there anything wrong about this reasoning?","['continuity', 'real-analysis', 'general-topology', 'normed-spaces', 'analysis']"
1267041,"Sheafification, stalks and quotient","I gave a problem that I can't finish by myself. Any help would be appreciated. Consider a sheaf $\mathcal{F}$ of abelian groups on a topological space. I would like to show that given two sheaves $\mathcal{F}, \mathcal{F}'$ we get $\mathcal{F}_x/\mathcal{F}'_x \cong (\mathcal{F}/\mathcal{F}')_x$. This question has been addressed here: Stalk of the quotient presheaf , but with no accepted answer, and the answers that are there didn't help me much. I was hoping that this could be proven without going into category theory explicitly (as was suggested in one answer to that question). I already figured that one should take the sheaf generated by $\mathcal{F}/\mathcal{F}'$, call it $\mathcal{G}$, and then one can consider the following exact sequence: $\mathcal{F} \rightarrow \mathcal{F}' \rightarrow \mathcal{G}$, where the second map is the composition of the quotient map with the natural morphism $\tau: \mathcal{F}/\mathcal{F}' \rightarrow \mathcal{G}$. Where to go from here, or if I am right so far, I do not know. Thanks in advance.","['algebraic-geometry', 'sheaf-theory']"
1267054,Equation for dye in pool,"I recently began my first course in intro do ordinary differential equations. The textbook recommended for the class is ""Elementary Differential Equations and Boundary Value problems, 10th edition"" by Boyce and DiPrima. I also have the solutions manual, but not all questions are worked in it. There is one question near the start that I decided the work, and it wasn't in the back so I thought people here could share their input. I will write the problem, then explain what I have done so far. I am not sure if it is correct however, or if I am making some mistakes. Your pool containing $60\,000$ gallons of water is contaminated by $5\,\rm kg$ of a non-toxic dye. The filtering system can take water from the pool, remove the dye and return the clean water at a rate of $200\,\rm gal/min$. It then asks a variety of questions, such as, write an initial value problem, is the system capable of removing enough dye such that the concentration is less than $0.02\,\rm g/gal$ within $4$ hours, find the time $T$ at which is first is $0.02\,\rm g/gal$, and lastly the flow sufficient to achieve the concentration of $0.02\,\rm g/gal$ in $4$ hours. What I did so far; Let $q(t)$ be the amount of dye present at time $t$. The original concentration of the dye is $$q(0)=\frac{5\,\rm kg}{60\,000\,\rm gal}\quad\text{or}\quad q(0)=8.33\cdot 10^{-2}\,\rm g/gal$$ The filter is capable of removing the dye at $t=0$ of a rate calculated by the product of this initial concentration by $200\,\rm gal/min$, that is, $$16\frac{\rm g}{\rm min}$$ But after this I know I need to calculate it as $$\frac{dq}{dt}$$ I am not sure the best way, I'm thinking along the lines of, the volume of the pool is not changing so the flow of chemical out at time $t$ would be equal to $200\,\rm gal/min$ $(q(t)/60\,000\,\rm gal)$ I was thinking also that since no new dye is being added, it may just be something like $$8.33\cdot 10^{-2}-\left[\left(200\frac{\rm gal}{\rm min}\right)\left(\frac{q(t)}{60\,000\,\rm gal}\right)\right]$$ But I am having a bit of trouble formulating this. Is it on the right track at least? Thank you for reading and taking any time to help or respond.",['ordinary-differential-equations']
1267065,Precalculus algebra: Greatest term in polynomial,"What is the term with the highest power in $$(x^3-2)^{16}-(x^4 + 3)^{12}$$ The textbook answer is $-32x^{45}$, but not sure I understand the method used to handle such a problem. Most answered questions on the Internet assumes that there are no unknowns by specifying what x is, or contains too little information. What I can gather, I need to find two things: the power of the largest term and then the coefficient of that term. As long as I know the power, I know how to get the coefficient and then I compare them between the two expansions. To find the largest power, I need to compare one term and the following one to try to find a spot where the ratio switches from above 1 to below 1, and that is my maximum. I start by writing down the general terms: $$(x^3-2)^{16} = \sum_{k=0}^{16} = \binom{16}{k}(x^3)^k(-2)^{16-k}$$ $$(x^4+3)^{12} = \sum_{k=0}^{12} = \binom{12}{k}(x^4)^k(3)^{12-k}$$ Approach 1 Assume that $T_k$ is the largest term. Then $$\frac{T_{k+1}}{T_k} = \frac{16-k+1}{k} \cdot \frac{-2}{x^3} = \frac{2k-34}{kx^3}$$ This means that as long as $$2k-34 > kx^3$$ or $$k > \frac{34}{2-x^3}$$ ...the terms will continue to increase. Not really sure how to go on from here, especially since k is expressed in terms of x. Am I even on the right track? Approach 2 Surely, the largest power of x in both parts of the original expression is $x^{48}$ where k equals 16 and 12, respectively. However, since there is a minus sign between the two parts of the original expression, these cancel. The second largest power in the left part occurs when k = 15, which is then $3 \cdot 15 = 45$ and for the other it is $4 \cdot 11 = 44$. To get the coefficient, we do the following: $$16-k = 45 \Leftrightarrow k = 16-45 = -29$$ $$\binom{16}{-29}(x^3)^{-29}(-2)^{16--29} = \binom{16}{-29}(x^3)^{-29}(-2)^{45}$$ However, this does not seem to make much sense. I have never seen a negative number (e. g. -29) in a binomial expression like that before. Where have I gone wrong and what are some other productive approaches to this question?",['algebra-precalculus']
1267078,Confusion with seeming lack of notational coherence between $\sin^{-1}(x)$ and $\sin^2(x)$,"It seems that $\sin^2(x)$ is used to denote the square of whatever value $\sin(x)$ is, instead of the expected $(\sin(x))^2$. Based on that, I would assume that $\sin^{-1}(x) = \frac{1}{\sin(x)}$, but it turns out that $\sin^{-1}(x)$ is used to indicate the inverse function of sin, arcsin. What are the reasons for this apparent lack (to me, at least) of notational coherence, and how do you write $\frac{1}{\sin(x)}$ in exponential notation? I saw this: $\sin^2$ notation and uses of the alternative. , but I don't think it really answers what I'm asking (specifically, answers are along the lines of ""it is what it is"").","['notation', 'trigonometry', 'functions']"
1267101,"Solve the following recurrence relation: $S(1) = 2$; $S(n) = 2S(n-1)+n2^n, n \ge 2$","Solve the following recurrence relation:
$$\begin{align}
S(1) &= 2 \\
S(n) &= 2S(n-1) + n 2^n, n \ge 2
\end{align}$$ I tried expanding the relation, but could not figure out what the closed relation is: +-------+------------------------------------------------+
|   n   |  S(n)                                          |
+-------+------------------------------------------------+
|   1   |  2                                             |
|   2   |  2S(1)+2*2^2 = 2*2 + 2*2^2 = 2^2 + 2*2^2 =     |
|       |              = 4 + 8 = 12                      |
|   3   |  2S(2)+3*2^3 = 2*(2^2 + 2*2^2) + 3*2^3 =       |
|       |              = 8 + 16 + 24 = 48                |
|   4   |  2S(3)+4*2^4 = 2*(2*2^2 + 2*2*2^2 + 3*2^3) +   |
|       |              + 4*2^4 =                         |
|       |              = 16 + 32 + 48 + 64 = 160         |
|   5   |  2S(4)+5*2^5 = 2*(2*2*2^2 + 2*2*2*2^2 +        |
|       |              + 2*3*2^3 + 4*2^4) + 5*2^5 =      |
|       |              = 32 + 64 + 96 + 128 + 160        |
|       |              = 384 + 96 = 480                  |
+-------+------------------------------------------------+ Edit : is it $S(n)=2^n\frac{n(n+1)}{2}$?","['recurrence-relations', 'induction', 'discrete-mathematics']"
1267108,What wolfram does to factor $x^6+x^2+2$?,"I am learning polynomials and I am trying to understand what wolfram did to obtain $$(x^2+1)(x^4-x^2+2)$$ from $$x^6+x^2+2$$ It does not show me the step-by-step option in this case and I got confused. I only see $$x^2(x^4+1)+2$$ for this case.
Thank you.","['polynomials', 'algebra-precalculus']"
1267122,How to solve the eigenvalues of a complex matrix of very high condition number?,"WHAT I FACE: I'm dealing with a complex matrix of very high condition number and I have to solve the eigenvalue and eigenfunction of it. But in Matlab, I got the problem that the results are not converging with increasing resolution number, so these results are not reliable. WHAT I NEED: I in fact only need to get one eigenvalue and its associated eigenfunction (largest real part), so I tried with eigs in Matlab, but it says that ""znaupd did not find any eigenvalues to sufficient accuracy"", even though I have relaxed the tolerance to a very high value. WHAT I HAVE TRIED: As I said, I have tried eig and eigs in Matlab, but these two commands can't give me accurate results. What should I do if I want to solve this kind of problem (to get one eigenvalue of a very-high-condition-number matrix)? 
Should I move to other solvers other than Matlab? I think Matlab is already the best we can do, right? Thanks. Any discussion will be appreciated. By the way, I'm using the collocation spectral method for the grid discretization.","['condition-number', 'eigenvalues-eigenvectors', 'matlab', 'matrices']"
1267134,Taking a time derivative of a function of 3 variables.,"I have a function of $3$ variables which are all functions of $t$. $$x = \frac{v_1t-y}{\sqrt{(v_2/\dot{x})^2 -1}} \tag 1 $$ In the equation $v_1,v_2$ are constant and $x$ and $y$ are both function of $t$ (also $\dot{x}$ is $\frac{dx}{dt}$). I am trying to differentiate $(1)$ with respect to $t$, but I am not sure how to do this as there are three variables and an $\dot{x}$ already. I tried holding $x,y$ constant but that instinctively does not make sense as these change with respect to $t$.","['derivatives', 'calculus', 'functions']"
1267148,Differentiation method for evaluating $ \sum_{n=1}^\infty \frac{n^2}{3^n} $,"I evaluated the following infinite sum (the original and broader question regarding this sum can be found at Evaluating $\sum_{n=1}^\infty \frac{n^2}{3^n} $ ). $$ \sum_{n=1}^\infty \frac{n^2}{3^n} $$ However, I'm getting the feeling that I made some mistake(s) during my evaluations. My particular concern regards the changes made in the sum's index. The following is what I did. I first defined a power series as the function f. $$ \sum_{n=1}^\infty \frac{n^2}{3^n} = \sum_{n=1}^\infty n^2 (\frac{1}{3})^n = f(\frac{1}{3}) \Rightarrow f(x) = \sum_{n=1}^\infty n^2 x^n $$ I then attempted to manipulate the sum in order to transform it through the geometric series. This is where I'm quite unsure whether I did everything correctly. One of the things I did here looks wrong to me, but somehow, I still ended up with the correct answer (which is 3/2). $$
\begin{align*}
f(x) &= \sum_{n=1}^\infty n^2 x^n
\\ &= x \sum_{n=1}^\infty n^2 x^{n-1}
\\ &= x \frac{d}{dx} ( \sum_{n=0}^\infty n x^n )
\\ &= x \frac{d}{dx} ( x \sum_{n=0}^\infty n x^{n-1} )
\\ &= x \frac{d}{dx} ( x \frac{d}{dx} ( \sum_{n=-1}^\infty x^n ) )
\\ &= x \frac{d}{dx} ( x \frac{d}{dx} ( \frac{1}{1-x} ) )
\\ &= x \frac{d}{dx} ( x \frac{1}{(1-x)^2} )
\\ &= x \frac{d}{dx} ( \frac{x}{(1-x)^2} )
\\ &= x \frac{1+x}{(1-x)^3}
\\ &= \frac{x(1+x)}{(1-x)^3}
\\ &\Rightarrow f(\frac{1}{3}) = \frac{3}{2}
\end{align*}
$$ The main concern of mine is the transition step to the closed-form geometric series. Of course, the proper equation for a geometric series is this: $$ \sum_{n=0}^\infty x^n = \frac{1}{1-x} $$ However, what I did is this: $$ \sum_{n=-1}^\infty x^n = \frac{1}{1-x} $$ The difference here is that the starting index is -1 instead of 0. This makes my translation of the sum incorrect. And yet, I still get the correct answer. On the other hand, I've tried the correct(?) form of an infinite geometric series that starts at n=-1: $$ \sum_{n=-1}^\infty x^n = \frac{\frac{1}{x}}{1-x} = \frac{1}{x(1-x)} $$ However, this yields an incorrect answer. I'm guessing that the final index I should've had for the sum was n=0 instead of n=-1. I'm guessing I did something wrong with the index shifts caused by the derivatives? Either way, I'm not seeing it. I do realize that there are other ways to go about evaluating this sum, but I'd really like to understand this derivative method.","['summation', 'sequences-and-series', 'derivatives']"
1267196,Cardinality of a basis of an infinite-dimensional vector space,"How would you find the cardinality of the basis of $\mathbb{R}$ over $\mathbb{Q}$? Is it countable or uncountable? In general, how do you find the cardinality of a basis of an infinite-dimensional vector space? Do you just search for a bijection between the basis and, say, $\mathbb{N}$ or $\mathbb{R}$? What are some instructive examples?","['elementary-set-theory', 'linear-algebra', 'functional-analysis']"
1267201,Matrix Calculus and Matrix Derivatives,"Consider a map $f : \mathbb R^{n\times m} \to \mathbb R^{p \times l}$ between matrix spaces, what is the differential of such a mapping? I looked at a really simple example, $\operatorname{id} : \mathbb R^{n\times n} \to \mathbb R^{n\times n}$ given by $\operatorname{id}(X) = X$. Then (in analogy to the the case $f : \mathbb \to \mathbb R$ oder $f : \mathbb R^n \to \mathbb R^n$) we should have $d\operatorname{id}(A) = I$ for all matrices $A$, where $I$ is the identity matrix (and $d\operatorname{id}$ denotes the differential, i.e. the best linear approximation map). Now I read about matrix derivatives, for example on Wikipedia the derivate of a mapping $F : M(n,m) \to M(p,q)$ between matrix spaces is said to be:
$$
 \frac{\partial\mathbf{F}} {\partial\mathbf{X}}=
\begin{bmatrix}
\frac{\partial\mathbf{F}}{\partial X_{1,1}}  & \cdots & \frac{\partial \mathbf{F}}{\partial X_{n,1}}\\
\vdots  & \ddots  & \vdots\\
\frac{\partial\mathbf{F}}{\partial X_{1,m}} & \cdots & \frac{\partial \mathbf{F}}{\partial X_{n,m}}\\
\end{bmatrix} 
$$
And also in the Matrix Cookbook the basic formula (on page 8) is written as
$$
 \frac{\partial X_{kl}}{\partial X_{ij}} = \delta_{ik}\delta_{lj}
$$
(where $\delta_{ij}$ denotes the Kronecker delta) and this I guess is essentially the derivation formula for the identity map. So If I apply this on the above map $\operatorname{id} : \mathbb R^{n\times n} \to \mathbb R^{n\times n}$ I get an $4\times 4$ matrix
$$
 \begin{pmatrix} 
  \frac{\partial X}{\partial x_{11}} & \frac{\partial X}{\partial x_{21}} \\
  \frac{\partial X}{\partial x_{12}} & \frac{\partial X}{\partial x_{22}}
 \end{pmatrix}
 = 
 \begin{pmatrix}
  \frac{\partial \begin{pmatrix} x_{11} & x_{12} \\ x_{21} & x_{22} \end{pmatrix}}{\partial x_{11}} &
 \frac{\partial \begin{pmatrix} x_{11} & x_{12} \\ x_{21} & x_{22} \end{pmatrix}}{\partial x_{21}} \\
 \frac{\partial \begin{pmatrix} x_{11} & x_{12} \\ x_{21} & x_{22} \end{pmatrix}}{\partial x_{12}} &
 \frac{\partial \begin{pmatrix} x_{11} & x_{12} \\ x_{21} & x_{22} \end{pmatrix}}{\partial x_{22}}
 \end{pmatrix}
  = \begin{pmatrix} 
     1 & 0 & 0 & 0 \\
     0 & 0 & 1 & 0 \\
     0 & 1 & 0 & 0 \\
     0 & 0 & 0 & 1 \end{pmatrix}          
$$
(where I on the last line had not written out the blockmatrices). But this result is quite different from what I would intuitively expect, so what did I wrong? Maybe I am interpreting all these matrix derivatives wrong, could someone please explain?","['matrices', 'matrix-calculus', 'analysis', 'differential-geometry', 'multivariable-calculus']"
1267224,Disjoint union of uncountable measurable sets of positive measure,"Let $X$ be a measure space, $\mu$ its measure function.
Suppose $X$ is a disjoint union of a family of measurable sets $\{X_\alpha : \alpha\in A\}$. Suppose $\mu(X_\alpha)\gt 0$ for all $\alpha\in A$.
If $A$ is countable, it is quite possible that $\mu(X) \lt \infty$. For example, this is the case if $A =\{1,2,\dots\}$ and $\mu(X_\alpha) = 1/2^\alpha$ for each $\alpha \in A$. Now suppose $A$ is uncountable. Is the following assertion true? $\mu(X) = \infty$. This seems true, but I was unable to prove it.",['measure-theory']
1267268,Why can't differentiability be generalized as nicely as continuity?,"The question : Can we define differentiable functions between (some class of) sets, ""without $\Bbb R$ "" * so that it Reduces to the traditional definition when desired? Has the same use in at least some of the higher contexts where we would use the present differentiable manifolds? Motivation/Context: I was a little bit disappointed when I learned to differentiate on manifolds. Here's how it went. A younger me was studying metric spaces as the first unit in a topology course when a shiny new generalization of continuity was presented to me. I was thrilled because I could now consider continuity in a whole new sense, on function spaces, finite sets, even the familiar reals with a different metric, etc. Still, I felt like I hadn't escaped the reals (why I wanted to I can't say, but I digress) since I was still measuring distance (and therefore continuity, in my mind) with a real number: $$d: X\to\huge\Bbb R$$ If the reader for some reason shares or at least empathizes with (I honestly can't explain this fixation of mine) the desire to have definitions not appeal to other sets/structures * , then they will understand my excitement in discovering an even more general definition, the standard one on arbitrary topological spaces. I was home free; the new definition was totally untied to the ever-convenient real numbers, and of course I could recover my first (calculus) definition, provided I toplogized $\Bbb R^n$ adequately (and it seemed very reasonable to toplogize $\Bbb R^n$ with Pythagoras' theorem, after all). Time passed and I kept studying, and through other courses (some simultaneous to topology, some posterior) a new sort of itch began to develop, this time with differentiable functions. On the one hand, I had definitions (types of convergence, compact sets, orientable surfaces, etc.) and theorems (Stone-Weierstrass, Arzelá-Ascoli, Brouwer fixed point, etc.) completely understandable through my new-found topology. On the other hand, the definition of a derivative was still the same as ever, I could not see it nor the subsequent theorems ""from high above"" as with topological arguments. But then a new hope (happy may 4th) came with a then distant but closely approaching subject, differential geometry. The prospect of ""escaping"" once again from the terrestrial concepts seemed very promising, so I decided to look ahead and open up a few books to see if I could finally look down on my old derivative from up top in the conceptual clouds. My expectation was that, just like topology had first to define a generalized ""closeness structure"" i.e. lay the grounds on which general continuous functions could be defined via open sets, I would now encounter the analogous ""differentiable structure"" (I had no idea what this should entail but I didn't either for topology so why not imagine it). And so it went: ""oh, so you just... and then you take it to $\Bbb R^n$ ... and you use the same definition of differentiable "". Why is this so? How come we're able to abstract continuity into definitions within the same set, but for differentiability, we have to ""pass through"" the reals? I realize that this really has to do with why we have to generalize in the first place, so what happens is that the respective generalizations have usefulness in the new contexts, hence the second point in my question statement. Why I imagine this is plausible, a priori, is because there's a historical standard: start with the low-level definitions $\rightarrow$ uncover some properties $\rightarrow$ realize these are all you wanted anyhow, and redefine as that which possesses the properties. Certainly, derivatives have properties that can be just as well stated for slightly more general sets! (e.g. linearity, but of course this is far from enough). But then, we'll all agree that there's even been a lust for conducting the above process, everywhere possible, so maybe there are very strong obstructions indeed, which inhibit it's being carried out in this case. In this case, I should ask what these obstructions are, or how I should begin identifying them. Thank you for reading this far if you have, I hope someone can give some insight (or just a reference would be great!). * If I'm being honest, before asking this I should really answer the question of what on earth I mean, precisely, by ""a structure that doesn't appeal to another"". First of all, I might come across a new definition that apparently doesn't use $\Bbb R$ , but is ""isomorphic"" to having done so (easy example: calling $\Bbb R$ a different name). Furthermore, I'm always inevitably appealing to (even naïve) set theory, the natural numbers, etc. without any fuss. So, if my qualms are to have a logical meaning, there should be a quantifiable difference in appealing to $\Bbb R$ vs. appealing to set theory and other preexisting constructs. If the respondent can remark on this, super-kudos (and if they can but the answer would be long and on the whole unrelated, say this and I'll post another question).","['differential-topology', 'differential-geometry', 'general-topology', 'derivatives']"
1267277,How can I solve this ODE with nonconstant coefficient?,"$x(1-x)f''(x) - \lambda f(x) = 0$, where $\lambda$ is just any constant. So far, I've just tried guessing certain functional forms, but none of them seem to work.",['ordinary-differential-equations']
1267283,Cardinality of Sets and injections,"Let A,B,C,D sets. if |A| $\le$|B| and |B| < |C|, show that |A| < |C| Proof: Case1: suppose |A| < |B| then there exists injection f: A$\to$B and |B| < |C| then there exists injection g: B$\to$C let h(x) = f(g(x)) = h:A$\to$C h(x) is an injection because it is the composition of two injections, thus, |A| < |C| Case2: suppose |A| = |B| then there exists a bijection f:A$\to$B (repeat for |B|<|C|) let h(x) = f(g(x)) = h:A$\to$C h(x) is an injection thus |A| < |C| This is my proof and I'm not sure I'm doing it correctly. I'm not sure this is the correct procedure","['cardinals', 'functions']"
1267285,Recurrence relations help please? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How do I solve this recurrence relation? $$
a_k = a_{k-1} + k
$$
when $a_0 = 2$.","['recurrence-relations', 'discrete-mathematics']"
1267310,Infinite Pigeonhole Proof?,Suppose we arrange finitely many pigeons in infinitely many pigeon holes. How do I use the Infinite Pigeonhole Principle to prove that there are infinitely many pigeonholes that contain no pigeons.,['discrete-mathematics']
1267330,On the horizontal integration of the Lebesgue integral,"I'm studying Lebesgue integral and its difference with respect to the Riemann one.
I'm reading that the key difference (at least graphically speaking) is that the first slices the function horizontally, while the latter works vertically. This concept is summed in the figure. In Riemann integral definition the graphical procedure is trivial, as we have
$$\int f(x) dx= \lim_{x\to+\infty}\sum_{i=1}^n f(x_i) (x_i-x_{i-1})$$
and so the $(x_i-x_{i-1})$ is the basis of my rectangle while $f(x_i)$ is the height. In Lebesgue we have (following Rudin pg.19)
$$\int_E f d\mu = \sup\int_E s d\mu = \sup \sum_{i=1}^n \alpha_i \mu(A_i \bigcap E_i)$$
but I can't get in any formulation of the Lebesgue integral which is the basis of the rectangle and which is the height, also because in Lebesgue there is no $x$ in the integral. I think that $d\mu$ in this case become the small height of each rectangle but I don't figure out how $f$, which was the height in Riemann, now could become the basis. Vice versa, if $d\mu$ is still the basis and I integrate according to the variation of $\mu$, this technique does not seem to cut horizontally the function. What is the idea behind this horizontal integration?
I read Lebesgue integral basics a possible answer but still I can't figured out a completely clear explanation. Any suggestion is really appreciated.","['riemann-sum', 'lebesgue-integral', 'integration']"
1267338,I can't find the critical points for this function. I showed my work :),"So, I have to find Critical Points of $y=\frac{1}{(x^3-x)}$
I know the derivative. Derivative = $(3x^2-1)/(x^3-x)^2$ To find Critical Points I equal to $0$. $x=1/\sqrt3$ and $x=-1/\sqrt3 $ But Critical points are the Max and Min value of your graph... and the graph is a little tricky... I don't know what to do... Because in my opinion, there are no critical points. It goes to infinity and -infinity.
Opinions? Help please!","['calculus', 'derivatives']"
1267351,How can we know what cos(-75) is?,We need to prove it using the sum and difference formula. We also need to use special triangles. how? I've tried doing cos(a-b) but I did cos(-30)cos(-75),['trigonometry']
1267380,Properties of Ackermann's function,"I want to show the following properties of Ackermann's function : $A(x,y)>y$. $A(x,y+1)>A(x,y)$. If $y_2>y_1$, then $A(x,y_2)>A(x,y_1)$. $A(x+1, y) \geq A(x,y+1)$. $A(x,y)>x$. If $x_2>x_1$, then $A(x_2, y)>A(x_1, y)$. $A(x+2, y)>A(x,2y)$. I'm looking for hints to prove the properties $3$ and $6$. I think that I should use properties $2$ and $4$ respectively but I'm unsure how to do so. My try for $3$ By induction on $x$, for the base case $x = 0$ we have: $y_2 > y_1 \implies A(0,y_2)=y_2+1>y_1+1=A(0,y_1)$ where we have used the inequality in the hypothesis and the definition of the Ackermann's function. For the inductive hypothesis, assuming the property holds for $x=n$, that means: $y_2 > y_1 \implies A(n,y_2)>A(n,y_1)$ (I.H) in the inductive step we want to show that: $y_2 \implies A(n+1,y_2)>A(n+1,y_1)$. I don't know how to continue from here. My try for $5$ By $4$, we have: $A(x+1, y) \geq A(x,y+1)$ So, we have: $A(x,y) \geq A(x-1, y+1) \geq A(x-2, y+2) \geq \dots \geq A(0,x+y)=x+y+1>x$. How can I formalize this reasoning.","['ackermann-function', 'induction', 'discrete-mathematics']"
1267394,I draw a hand of 13 from a deck of 52 cards. What is the probability that I do not have a card from every suit?,"I draw a hand of 13 from a deck of 52 standard playing cards. What is the probability that I do not have a card from every suit? I count the number of ways I can draw 13 from 3 suits $$\frac{{4\choose3}{39\choose13}}{52\choose13}$$ but I mind the intersection. Each possible pair of suits that I may have drawn from only is counted twice. And in the possibility that I pick from only one suit: each possibility is counted three times. $$\frac{{4\choose3}{39\choose13}-{4\choose2}{26\choose13}}{52\choose13}$$ This removes the overcounted iterations from the pair of suits I could have drawn from, but now I'm not considering the possibility that I drew from only one suit, so: $$\frac{{4\choose3}{39\choose13}-{4\choose2}{26\choose13}+{4\choose1}{13\choose13}}{52\choose13}$$ which is the probability I'm looking for. Is my reasoning sound? Have I made any mistakes? Is there a better solution?","['probability', 'combinatorics']"
1267401,Informal interpretation of meager sets,"I've been wondering if there is a nice informal interpretation of meager sets akin to the respective interpretations I give below to other notions of ""small"" sets. The general setup to tease out these interpretations is as follows. Imagine you flip a coin infinitely many times, thereby picking a point $x \in 2^\omega$. If it turns out $x \in B \subseteq 2^\omega$, something Bad happens. If $B$ is ""small"", that should correspond to some informal notion of safety. For example: If $B$ is codense, we can interpret that to mean that, as we are in the process of flipping the coin, there is always some possible hope of avoiding the bad outcome (i.e., we can't guarantee the bad outcome with only finitely many flips). If $B$ is nowhere dense, that means that, as we flip coins, there will always be hope that, with only finitely many more flips, we can guarantee a non-bad outcome. (In contrast, if $B$ were only codense, we might not be able to have our hopes realized until after we've seen all $\omega$ flips.) If $B$ is measure zero, we will almost surely avoid the bad outcome (in the sense of probability). So, I inquire whether there is a similar informal judgment we can make if $B$ is meager.","['descriptive-set-theory', 'general-topology', 'soft-question']"
1267412,Short question about definition in ODEs,"Hello I just have a short question about a remark made in my first class of intro ODE. My Professor was just motivating with a simple example, he wrote, $$\frac{dy}{dx}=y(x)$$ So of course it was clear that he was referring in general to $y(x)=ce^{x}$ where $c \in \mathbb{R}$ and then he also added and for all $ \ x \in \mathbb{R}$. Now here is where I got briefly confused , because I thought for example consider $y(x)=e^9$, then $\frac{dy}{dx}=0 \neq e^{9}$ So what I took this to mean is that $y(x)=ce^x$ is the solution, and if you evaluate it at any x the equation is true, i.e. simply because $e^x$ was the solution? I just want to make sure that is what is meant in this context, or if there was some error in my understanding/notation? Thanks all.",['ordinary-differential-equations']
1267415,"In a ring $(A,+, \cdot)$ if $aba = a$ then $bab = b$ and all non zero elements in $A$ are invertible. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $\left(A,+, \cdot\right)$ be a ring with $1$  that satisfies the following condition: For any nonzero $a\in A$, there exists a unique $b\in A$ such that $aba = a$. Show that $b$ also satisfies $bab = b$, and that all nonzero elements of $A$ are invertible.","['abstract-algebra', 'ring-theory']"
1267417,"Let $f:(X, \mathfrak T_X) \rightarrow (Y, \mathfrak T_Y)$ be a continuous function. Then $f(Cl(A) = Cl(f(A))$.","Let $f:(X, \mathfrak T_X) \rightarrow (Y, \mathfrak T_Y)$ be a continuous function.  Then $f(Cl(A) = Cl(f(A))$. My definition of closure is: Let $(X,\mathfrak T)$ be a topological space and let $ A \subseteq X$ . The closure of $A$ is $Cl(A) = \bigcap \{U \subseteq X: U$ is a closed set and $A \subseteq U\}$ 
Based on this I know $A \subseteq Cl(A)$ My definition of continuous is ""A function $f : \mathbb R \rightarrow \mathbb R$ is said to be continous if for each open subset $V$ of $ \mathbb R,  f^{-1}(V)$ is an open subset of $\mathbb R$. I am supposed to determine if this is true or false and if true prove it and if false give a counterexample. I have the definitions but I really do not even know where to start.  I have all the relevant definitions gathered but do not know where to go from here.","['elementary-set-theory', 'general-topology']"
1267454,a variant of MLE of a normal distribution,"It is well-known that if we have ""n"" sample observations from normal distribution with unknown mean, then the sample mean would be the MLE for the mean of the normal distribution. However, let's assume that before we collect our sample, somebody has already collected ""n"" sample observations, and the only information we get from that guy is that all the ""n"" sample observations were smaller or equal to A for some real number A. Is there any way we could somehow use ""n"" and ""A"" into MLE for the mean when we collect our sample? Any input would be greatly appreciated. I'm just curious.","['probability', 'statistics', 'bayesian']"
1267464,Mass and center of mass using double integrals,"Disclaimer: This was given as a homework from college but the teacher didn't teach us anything about density or mass or anything related. A lamina has the form of the region limited by the parabola $ y = x^2 $ and the straight line $ y = x $. The density varies as the distance from the $ X $ axis. Find the mass and center of mass. what i could find however is that the formula of mass is the following
$$M = \int\int_R \rho(x,y)dA $$ so i tried doing something like this
$$ \int_0^1\int_y^{\sqrt(y)} ? dxdy $$ the thing is that they say the density varies as the distance from the x axis, so i don't know what to replace for the density.. is it $ x + y $?","['calculus', 'multivariable-calculus', 'integration']"
1267472,Prove that two functionals with identical differentials differ by a constant.,"I am self-studying Calculus of Variations and am struggling to prove results about the variation of a functional that are analogous to results in elementary analysis about differentials/derivatives. Prove that if two differentiable functionals defined on the same normed linear space have the same differential (first variation) at every point of the space, then they differ by a constant. ( Gelfand & Fomin, ""Calculus of Variations"" , Problem 1.13) So far, I have reasoned as follows: Suppose $J_1[y]$ and $J_2[y]$ are functionals on the normed linear space $V$, and that $\delta J_1[y,h] = \delta J_2[y,h]$. Consider the functional $J[y] = J_2[y] - J_1[y]$.  It follows directly from the definition that $\delta J[y,h] = \delta J_2[y,h] - \delta J_1[y,h]$ is the principal linear part of the variation $\Delta J$, and hence is the first variation of $J[y]$. By hypothesis, $\delta J[y,h] \equiv 0 \;\forall y\in V$. Thus, I have reduced the original problem to proving that a functional whose variation vanishes everywhere is everywhere constant, but I can't figure out how to proceed.  The common proof of the analogous result in standard calculus relies on the Mean Value Theorem, which I don't think will work here. Pointers?","['analysis', 'calculus-of-variations']"
1267474,General probability equation,"I am really struggling with statistics. I am trying to come up with the basic equation/concept of calculating the probability for something. for example: 
I know that the probability of coming up with exactly 3 heads in 4 flips of a coin is 1/4, but I don't know why (other than writing out all possibilities- but I can't apply that to large numbers). heres what I know so far: 
Each flip has a 1/2 Chance of coming up heads, meaning you have two possibilities with each flip. 
I know then that the number of total possible outcomes for this particular example is 2^4 (possibilities ^ # of tries). I just don't know how to apply that so I can come up with the general equation for the probability of something. another example:
rolling a die 2x and having it come up with even numbers both times.",['statistics']
1267504,Cyclic Equation. Prove that: $\small\frac { a^2(b-c)^3 + b^2(c-a)^3 + c^2(a-b)^3 }{ (a-b)(b-c)(c-a) } = ab + bc + ca$?,"This is how far I got without using polynomial division: \begin{align}
\tiny
\frac { a^{ 2 }(b-c)^{ 3 }+b^{ 2 }(c-a)^{ 3 }+c^{ 2 }(a-b)^{ 3 } }{ (a-b)(b-c)(c-a) }
&\tiny=\frac { { a }^{ 2 }\{ { b }^{ 3 }-{ c }^{ 3 }-3bc(b-c)\} +{ b }^{ 2 }\{ { c }^{ 3 }-{ a }^{ 3 }-3ca(c-a)\} +c^{ 2 }\{ a^{ 3 }-b^{ 3 }-3ab(a-b)\}  }{ (a-b)(b-c)(c-a) } \\
&\tiny=\frac { { a }^{ 2 }({ b }^{ 3 }-{ c }^{ 3 })-3{ a }^{ 2 }bc(b-c)+{ b }^{ 2 }({ c }^{ 3 }-{ a }^{ 3 })-3ab^{ 2 }c(c-a)+c^{ 2 }(a^{ 3 }-b^{ 3 })-3abc^{ 2 }(a-b) }{ (a-b)(b-c)(c-a) } \\
&\tiny=\frac { { a }^{ 2 }({ b }^{ 3 }-{ c }^{ 3 })+{ b }^{ 2 }({ c }^{ 3 }-{ a }^{ 3 })+c^{ 2 }(a^{ 3 }-b^{ 3 })-3{ a }^{ 2 }bc(b-c)-3ab^{ 2 }c(c-a)-3abc^{ 2 }(a-b) }{ (a-b)(b-c)(c-a) } \\
&\tiny=\frac { { a }^{ 2 }({ b }^{ 3 }-{ c }^{ 3 })+{ b }^{ 2 }({ c }^{ 3 }-{ a }^{ 3 })+c^{ 2 }(a^{ 3 }-b^{ 3 })-3{ a }bc\{ (b-c)+(c-a)+(a-b)\}  }{ (a-b)(b-c)(c-a) } \\
&\tiny=\frac { { a }^{ 2 }({ b }^{ 3 }-{ c }^{ 3 })+{ b }^{ 2 }({ c }^{ 3 }-{ a }^{ 3 })+c^{ 2 }(a^{ 3 }-b^{ 3 }) }{ (a-b)(b-c)(c-a) } \\
&\tiny=\frac { { -a }^{ 3 }(b^{ 2 }-c^{ 2 })+{ a }^{ 2 }({ b }^{ 3 }-{ c }^{ 3 })-b^{ 2 }c^{ 2 }(b-c) }{ (a-b)(b-c)(c-a) } \\
&\tiny=\frac { { -a }^{ 3 }(b+c)+{ a }^{ 2 }({ b }^{ 2 }+{ bc+c }^{ 2 })-b^{ 2 }c^{ 2 } }{ (a-b)(c-a) }
\end{align} Would it be possible to solve this answer easily without direct polynomial division? By the use of some known identities, perhaps?","['polynomials', 'algebra-precalculus']"
1267507,Domain of the given function,"A function $y(x)$ is defined as $$ 2^y+2^x=2 $$ The question is about finding it's domain. Pretty simple. By observing the function I could say all the negative numbers are in the domain. But, I think $0$ is included in the domain because the function is defined at $0$ . The text book says $0$ is not included. How is that?",['functions']
1267509,"Number of rearrangements of the word ""INDIVISIBILITY""","In how many ways can the word "" INDIVISIBILITY "" be rearranged, such
that no two I s come close to each other? My attempt Total number of ways of rearranging the word = $\dfrac{14!}{6!}$ Number of ways of rearranging the word such that at the least, a pair of I s come close to each other (the motivation for this comes from the negation of ""no two I s come close to each other"") = $\binom{6}{2} \times \dfrac{13!}{4!}$ Then, required number of arrangements = $\dfrac{14!}{6!} - \binom{6}{2} \times \dfrac{13!}{4!}$. But this gives me a negative number. Where am I going wrong? Could anyone tell me how to go about this problem?",['combinatorics']
1267510,How to approximate Heaviside function by polynomial,"I have a Heaviside smooth function that defined as
$$H_{\epsilon}=\frac {1}{2} [1+\frac {2}{\pi} \arctan(\frac {x}{\epsilon})]$$ I want to use polynominal to approximate the Heaviside function. Could you suggest to me a solution? Thanks UPDATE: This is Bombyx mori result in blue line and my expected result is red line","['linear-approximation', 'approximation', 'polynomials', 'trigonometry']"
1267540,Solve $x(x-1)y''+6x^2y'+3y=0$ using Frobenius's Method,"Solve $x(x-1)y''+6x^2y'+3y=0$ using Frobenius's Method I can't solve this ODE. How can I get first two term? and indicial equation is also very confusing. I can solve two term recurrence relation by Frobenius Method, but it's too hard to solve three term recurrence relation. P.S Recurrence relation that I write above is correct. And Sorry for my bad English",['ordinary-differential-equations']
1267559,Solve in positive integers: $5x^2+6x^3=z^3$,"Solve in positive integers: $5x^2+6x^3=z^3$. $x^2(6x+5)=z^3$ If $(x,5)=5$, let $x=5k$. So $k^2(6k+1)=\left(\frac{z}{5}\right)^3$, we're left with solving $6n^3+1=m^3$. If $(x,5)=1$, then we're left with solving $6n^3+5=m^3$. Here we only used $(a,b)=1,\: ab=c^3$ gives $a=n^3, b=m^3$. How to solve these 'cubic Pell equations'?","['number-theory', 'diophantine-equations', 'elementary-number-theory']"
1267561,Hard question in simple trigonometry,"This question is from S.L.LONEY-
If $\tan(45°+\frac{y}{2})=\tan^3(45°+\frac{x}{2})$, prove that $\frac{\sin y}{\sin x}=\frac{3+\sin^2x}{1+3\sin^2x}$. I don't know what to do. I am getting nasty expressions but nothing in $\sin x$. Thanks.",['trigonometry']
1267587,Family of functions that are bounded in $L^1$ but *NOT* Uniformly Integrable,"I'm having a difficult time constructing a counter example to this. My intuition (sloppily) is to construct a family of functions {$X_n$} that have Dirac pulses at $n$ and $-n$. Such that $\sup_n \Bbb E[|X_n|\Bbb 1_{X≥n}]=1$ However, I'm not sure if this is correct.","['probability-theory', 'probability', 'uniform-integrability', 'measure-theory']"
1267634,Expectation with respect to empirical distribution,"Let $(\Omega,\mathcal{A})$ be a measure space and $X$ a random variable with distribution $P$ . The expectation of some measurable function $g$ with respect to $P$ is $$
\mathbb{E}_P[g(X)] = \int_\Omega g(X(\omega))\, dP(\omega).
$$ The empirical distribution $Q$ of i.i.d. samples $x_1,\dotsc,x_n$ from $P$ is defined as $$
Q(B) = \frac{1}{n} \sum_{i=1}^n \mathbb{1}_B(x_i) \quad B \in \mathcal{A} \,.
$$ I know that $$
\mathbb{E}_Q[g(X)] = \frac{1}{n} \sum_{i=1}^n g(x_i)
$$ but it is not obvoius how to derive this starting with $$
\mathbb{E}_Q[g(X)] = \int_\Omega g(X(\omega))\, d\left[ \frac{1}{n} \sum_{i=1}^n \mathbb{1}_\omega(x_i) \right]
$$","['probability-theory', 'probability', 'measure-theory']"
1267635,Compute variance of logistic distribution,"Consider a random variable $X$ with normalized logistic distribution(
so that its pdf is $\frac{e^{-x}}{(1+e^{-x})^2}$). It is well known 
that its variance $V$ equals $\frac{\pi^2}{3}$ but I couldn't find a direct proof so far. It is easy to see that $$V=\int_{-\infty}^{\infty}\frac{x^2e^{-x}}{(1+e^{-x})^2}dx=
\int_{0}^{1}\Bigg(\ln\bigg(\frac{p}{1-p}\bigg)\Bigg)^2dp$$ This last integral is well-known according to Wikipedia, but the only
reference it gives for this is a certain link in the OEIS and I got lost
browing through the miscellaneous links in that OEIS page. I am aware that one can use the moment generating function to compute $V$, but I'd prefer a solution that tackles the integral above directly, preferably without using complex analysis. Any help appreciated.","['reference-request', 'probability-distributions', 'definite-integrals', 'integration']"
1267679,Number of Sylow $p$-subgroups of a direct product of groups,"Let $G$ be the group $S_4\times S_3$ . Prove or disprove the following: a $2-$Sylow subgroup of G is normal a $3-$Sylow subgroup of G is normal I've got $|S_4\times S_3|=144$ and the group as not simple. While applying Sylow's theorem I've got possible values of no. of Sylow $2 $subgroups as $9, 3, 1$ and no. of Sylow $3$ subgroups as $16, 4, 1. $ Then  which value I've to exclude?","['abstract-algebra', 'sylow-theory', 'group-theory']"
1267686,Is $\sin^4 x-\cos^4 x = \cos2x$ or is it $-\cos2x=\cos2x$?,A test question I received and got wrong stated that $$\sin^4x-\cos^4x = \cos2x$$ After solving the equation from lower powers of tragicomic functions it came out $$\frac{-1}{2}(\cos2x)-\frac{1}{2}(\cos2x)=-cos2x$$ which ≠ RHS. Our professor showed that it is correct by solving it as $$(\sin^2x-\cos^2x)(\sin^2x+\cos^2x) =(\sin^2x-\cos^2x)(1) = \cos2x$$ which works out correctly. Who is right? Here is a Wolfram Alpha solution that shows the solution I came up with to be correct.,"['algebra-precalculus', 'trigonometry']"
1267700,Meaning of the identity $\det(A+B)+\text{tr}(AB) = \det(A)+\det(B) + \text{tr}(A)\text{tr}(B)$ (in dimension $2$),"Throughout, $A$ and $B$ denote $n \times n$ matrices over $\mathbb{C}$. Everyone knows that the determinant is multiplicative, and the trace is additive (actually linear).
\begin{align*}
\det(AB) = \det(A)\det(B) && \mathrm{tr}(A+B)= \mathrm{tr}(A) + \mathrm{tr}(B).
\end{align*}
On the other hand, the opposite equations
\begin{align}
\det(A+B) = \det(A)+\det(B) && \mathrm{tr}(AB)= \mathrm{tr}(A)\mathrm{tr}(B) \tag{1}.
\end{align}
don't hold for all $A,B$ unless $n=1$. For instance, taking $A=B=I$ in (1), we get
\begin{align*}
\det(A+B) = 2^n && \det(A)+\det(B) = 2 && \mathrm{tr}(AB)= n && \mathrm{tr}(A)\mathrm{tr}(B) = n^2.
\end{align*}
When $n=2$ a very curious thing happens, which is that, even though the equations (1) are typically false, their sum is actually valid. That is,
\begin{align}
\det(A+B) +  \mathrm{tr}(AB)= \det(A)+\det(B)+  \mathrm{tr}(A)\mathrm{tr}(B) \tag{2}
\end{align}
for all $A$ and $B$ when $n=2$. However, (2) does not hold when $n>2$. Indeed, specializing to $B=I$ in (2), we get
\begin{align}
\det(A+I) +  \mathrm{tr}(A)= \det(A)+1+  n \cdot \mathrm{tr}(A)
\end{align}
or, equivalently,
\begin{align}
\det(A+I) = \det(A)+(n-1) \cdot \mathrm{tr}(A) +1 \tag{3}.
\end{align}
If $n \geq 2$ and $A$ is projection onto the first coordinate, we have
\begin{align}
\det(A+I) = 2 && \det(A)+(n-1)\cdot \mathrm{tr}(A) +1 = n,
\end{align}
so (3) is only an identity for $n=2$ (or, trivially, when $n=1$). Question: Is there any special significance to the equation
  \begin{align}
\det(A+B) +  \mathrm{tr}(AB)= \det(A)+\det(B)+  \mathrm{tr}(A)\mathrm{tr}(B) ,
\end{align}
  which is valid for all $2 \times 2$ matrices? It seems very strange to me that the sum of two obviously false equations should turn out true. Are there any nice applications of this identity?","['determinant', 'quadratic-forms', 'reference-request', 'linear-algebra', 'trace']"
1267708,What is a formal definition of 'randomness'?,What is a rigorous mathematical/logical definition of 'randomness'? Under what conditions can we truthfully apply the predicate 'is random'?,"['random', 'probability', 'statistics']"
1267710,what can I say about the solution $y(x)$ of the ODE?,"Let $y:\mathbb R\to \mathbb R$ be differentiable and satisfy the ODE:
$$\frac{dy}{dx} =f(y),x\in\mathbb R$$
$$y(0)=y(1)=0$$ where $f:\mathbb R\to \mathbb R$ is a Lipschitz continuous function. Then $y(x)=0$ if and only if $x\in\ ${$0,1$} $y$ is bounded $y$ is strictly increasing $\frac{dy}{dx}$ is unbounded. I've got this question from an exam paper, and I cannot understand how to solve it. How should I use the condition of Lipschitz continuity of $f$ to solve it? Please help. Thanks in advance.",['ordinary-differential-equations']
1267714,Weights in the Dynkin Basis and Eigenvalues of the Cartan Generators for SU(3)?,"The Cartan Generators of $SU(3)$ in the three dimensional rep have eigenvalues $(1,-1,0)$ and $\frac{1}{\sqrt{3}} (1,1,-2)$ . Therefore we have the weights: $$ (1,\frac{1}{\sqrt{3}}) \quad  (-1,\frac{1}{\sqrt{3}}) \quad (1,\frac{-2}{\sqrt{3}}) $$ In the Dynkin basis the weights of the 3 dimensional rep are $$ [1,0] \quad [-1,1] \quad [0,1] $$ How are these connected to the eigenvalues of the Cartan generators quoted above? I thought that I get them by multiplying the weights in the Dynkin basis with the corresponding metric tensor (=the inverse of the Cartan matrix) of $SU(3)$ : $$ G=\frac{1}{3} \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix} $$ For example, $$ G [1,0] = \frac{1}{3} \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix} \begin{pmatrix}1 \\ 0 \end{pmatrix} = \begin{pmatrix}\frac{2}{3} \\ \frac{1}{3}\end{pmatrix}  $$ Unfortunately this yields the wrong weights. What is wrong and how can I compute correctly the eigenvalues of the Cartan generators from the weights in the Dynkin basis?","['lie-groups', 'group-theory', 'lie-algebras']"
1267777,Product of principal ideals: $(a)\cdot (b) = (a b)$,"In which kinds of rings $R$ does the following hold: $$(a)\cdot (b) = (ab) \; ?$$ With $a, b\in R$, $(a)$ denoting the (two-sided) ideal generated by $a$ and the multiplication of ideals $I, J\subset R$ defined as 
$$ I\cdot J = \biggl\{\sum_{i=1}^n x_i y_i : n\in\mathbb{N}, x_i \in I, y_i \in J \biggr\}\, .$$ It seems to me that it only holds for commutative rings with $1$. Is that right? Ok, I'm trying a proof: Let $R$ be commutative with $1\in R$. Then $(a)\cdot (b) = (a b)$ for any $a, b\in R$. First let $I_a := \{ra : r\in R\}$, we're going to show that 
$$(a) = I_a\, .$$
$I_a$ is obviously an ideal. Since $1 \in R$ we have $1 \cdot a \in I_a$, so $(a) \subset I_a$. On the other hand, any $x \in I_a$ can be written as $x = ra$ and so must be an element of $(a)$. This proves that $(a) = I_a$. Then $$(a)\cdot (b) = I_a \cdot I_b = \biggl\{\sum_{i=1}^n x_i y_i : n\in\mathbb{N}, x_i \in I_a, y_i \in I_b \biggr\}  = \biggl\{\sum_{i=1}^n (r_i a)  (s_i b) : n\in\mathbb{N}, r_i, s_i \in R \biggr\} = \biggl\{a b \sum_{i=1}^n r_i s_i : n\in\mathbb{N}, r_i, s_i \in R \biggr\} = \biggl\{a b r : r \in R \biggr\} = I_{ab} = (ab)\, .$$ We obviously had to use that $R$ is commutative. In the last step we also used that every $r \in R$ can be written as $r=\sum_{i=1}^n r_i s_i$. This is because $1 \in R$, so with $n=1$ we have $r = 1\cdot r$.","['abstract-algebra', 'ring-theory']"
1267780,Total Variation of Constant Function,"I want to prove that the total variation of, $f:[a,b] \to \mathbb{R}$, is $0$ iff $f$ is a constant function, but i'm not entirely sure how. I can intuitively see why that it would be zero since the Total Variation of a function represents the number of peaks of the function. Though, how to rigorously prove it i'm not sure.","['analysis', 'real-analysis']"
1267803,Points of $4$-contact of an ellipse and a circle,"Consider an ellipse $x^2 + 4y^2 = 4$ given in parametrised form $(2 \cos t, \sin t)$. At a given point $p_0 = (2 \cos t_0, \sin t_0)$ we want to measure how round the ellipse is (i.e. how similar to a circle it is). To do this, let $C(x,y) = (x-a)^2 + (y-b)^2 - \lambda$ be a circle with centre $(a,b)$. If this circle goes through the point $p_0$ then $$ (2\cos t_0 - a)^2 + (\sin t_0 - b)^2 -\lambda = 0 = g(t_0)$$ A point of $k$ contact between this circle and ellipse is any point for which the first $k-1$ derivatives $g^{(i)}$ vanish and $g^{(k)} \neq 0$. For this example there are only four points for which we can have $4$-point contact. The centres of the corresponding circles are: $(\pm {3 \over 2}, 0), (0, \pm 3)$. My question is: Why are these the only points where $4$-point contact
  is possible? Ideally, I would like to gain geometric insight from any answer, if possible. It is clear to me that $3$-point contact is possible at every point on the ellipse.",['differential-geometry']
1267817,Angle between two 4D vectors,"I was wondering if there is any difference between finding the angle between two 4D vectors as opposed to finding the angle between two 3D vectors? I have $u = (1, 0, 1, 0)$ , $v = (-3, -3, -3, -3)$ and used the dot product to find the angle between them. We have that: $u\cdot v = -6$ $||u|| = \sqrt 2$ $||v|| = \sqrt{36}$ Then, $$\cos(\theta) = \frac{u . v} {||u||\cdot ||v||}=\frac{-6 }{ \sqrt 6 \cdot \sqrt{36}} = -0.71,$$ so $$\theta = \cos^{-1} (-0.71)$$ And the angle between $u$ and $v$ is $135$ degrees or $2.36$ radians.",['linear-algebra']
1267832,Why are there infinitely many positive $k$ such that $\lfloor \frac{n^k}{k}\rfloor$ is odd?,"Give the postive integer $n>1$, there exist infinite positive integer $k$
such that $\lfloor \dfrac{n^k}{k}\rfloor$ is odd Maybe we can Use Euler's theorem,$$n^{\phi{(k)}}\equiv 1\pmod k$$
let
$$n^{\phi{(k)}}=rk+1\Longrightarrow n^k=\left(kr+1\right)^{\frac{k}{\phi{(k)}}}\Longrightarrow \dfrac{n^k}{k}=\dfrac{\left(kr+1\right)^{\frac{k}{\phi{(k)}}}}{k}$$I don't think this last part is relevant to understanding the exercise as stated, but I may be wrong.",['number-theory']
1267838,A question about endomorphism rings of elliptic curves,"This is probably a very trivial question, but I haven't been able to find a rigorous explanation anywhere so far or at least haven't understood it. Assume we have an elliptic curve $E$ over $\mathbb{F}_p$ where $p$ is a prime. Then we often talk about $\text{End}(E)$, the ring of endomorphisms of the curve $E$. The thing I'm confused about is the following. The claim generally is that $\text{End}(E)\cong \mathbb{Z}+\delta\mathbb{Z}$ where $\delta$ is a complex root of the discriminant of a complex quadratic order. So far so good. Now the thing that confuses me is what is the $\text{End}(E)$ the endomorphism ring of? It can't be the endomorphism ring of the curve $E(\mathbb{F}_p)$ since that is a finite group and it's endomorphism ring must thus also be finite (by a combinatorial argument). My guess is it's the endomorphism ring of $E(\bar{\mathbb{F}_p})$ i.e. $E$ interpreted over the algebraic closure. But then there are places which specifically deal with $\text{End}_{\bar{\mathbb{F}_p}}(E)$ distinguishing it from $\text{End}(E)$. My other guess was that it might be the endomorphisms of $E(\bar{\mathbb{{F}_p}})$ which are defined over $\mathbb{F}_p$ as morphisms (i.e. (slightly restricted) rational functions if I understand it correctly). The second interpretation is the one I'm leaning towards the most but it would be nice to get confirmation or explanation what I'm missing. Thank you.= Edit After the discussion with Ferra I've determined that at least part of my issue is in not correctly understanding the abuse of notation used when we say an elliptic curve $E$ (defined over $\mathbb{F}_p$). Without a given base field I'm not sure what this is supposed to mean. In other words, when we write $\text{End}(E)$ which $E$ is meant? Are we in some way thinking of the homogenous polynomial defining $E$? Or are we thinking of the projective variety over the field $E(\overline{\mathbb{F}_p})$? Or are we thinking of the group $(E(\mathbb{F}_p),+,0)$ or $(E(\overline{\mathbb{F}_p}),+,0)$? Or are we thinking of both the group structure and the projective variety structure? I would think the last though I'm still not sure if we have the closure field or the base field. I'm also not sure whether there are group endomorphisms which are not algebraic curve morphisms.","['elliptic-curves', 'abstract-algebra', 'algebraic-geometry']"
1267866,Power function of fixed numbers.,"Prove that $3^x-4^x+2x4^{x-1}\le0$, where $x\in[-0.5,0]$.Here is it's plot . I tried to do it by first and second derivative test but it involves $log$  which make the expression more complicated.","['calculus', 'multivariable-calculus', 'inequality']"
1267869,Eigenvalues and positivity of Hermitian Toeplitz matrices,"I want to check the eigenvalues (and also the positivity) of the $n \times n$ complex Toeplitz matrix \begin{equation}
T = \begin{bmatrix}
r & z_1 & z_2 & z_3 &\cdots & z_{n-1}\\
\bar{z}_1 & r & z_1 & z_2 & \cdots & z_{n-2}\\
\bar{z}_2 & \bar{z}_1 & r & z_1 & \cdots & z_{n-3}\\
\vdots & \vdots &\vdots &\vdots &\ddots &\vdots \\
\bar{z}_{n-1} & \bar{z}_{n-2} & \bar{z}_{n-1} & \cdots & \cdots & r
\end{bmatrix}_{n \times n}.
\end{equation}
$\bar{z}$ is the complex conjugate of $z$, and $r$ is a real number. Is there a canonical way to calculate the eigenvalues of the above matrix? I am sure,this question has been answered somewhere in the stackexchange, but I can not determine where. Please help.","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1267886,Which axiom of set theory does this formula represent ? Why? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Which axiom of set theory does the statement below represent? Why?
\begin{align}\exists x\bigg(&\forall y\Big(\neg\exists z\left(z\in y\right)\to y\in x\Big)\\&\land\forall w\Big(w\in x\to\forall u\big(\forall v\big(v\in u\leftrightarrow\left(v=w\lor v\in w\right)\big)\to u\in x\big)\Big)\bigg)\end{align}","['elementary-set-theory', 'logic', 'axioms']"
1267908,Prove divisibility is a partial order relation over natural numbers,"I have proceeded like this so far: (The natural number set includes $0$ ) Reflexivity:
Proof: $a = k \cdot a,$ since $k$ also belongs to natural number, it is proved. Anti-symmetry: $a \mid b$ means $a = k_1 \cdot b$ and $b \mid a$ means $b = k_2 \cdot a$ . Now, $a = k_1\cdot k_2\cdot a.$ This means $a = b.$ Transitivity:
Not sure how to prove this. I know it holds but not sure how it can be shown mathematically.","['elementary-set-theory', 'order-theory']"
1267910,Proof of inverse of composite functions,"Let $A$, $B$ & $C$ sets, and left $f:A \rightarrow B$  and $g:B \rightarrow C$ be functions. Suppose that $f$ and $g$ have inverses.  Prove that $g\circ f$ has an inverse, and that $(g\circ f)^{−1} = f^{−1}\circ g^{−1}$. Assuming that f and g have reverse,$f^{-1}=h$ and $g^{-1}=s$ with $h:B\rightarrow A$  e $s:C\rightarrow B$. from that above i infer that the inverse of $(g \circ f)$ is 
      $(s \circ g):C\rightarrow A$ that is $g^{-1} \circ f^{-1}=(g \circ         f)^{-1}$;
 Hence for proof of $(g \circ f)^{-1}=f^{-1} \circ g^{-1}$, proceed as before, only swapping functions , right?","['elementary-set-theory', 'proof-writing']"
1267935,Lyapunov equation for stability analysis - what's the point?,"Straight from Wikipedia : In the following theorem $A, P, Q \in \mathbb{R}^{n \times n}$ , and $P$ and $Q$ are symmetric. The notation $P>0$ means that the matrix $P$ is positive definite. Given any $Q>0$ , there exists a unique $P>0$ satisfying $A^T P + P A + Q = 0$ if and only if the linear system $\dot{x}=A x$ is globally asymptotically stable.  The quadratic function $V(z)=z^T P z$ is a Lyapunov function that can be used to verify stability. Recently I became quite familiar with tools to solve Lyapunov equation $A^T P + P A + Q = 0$ and obtain $P$ . However in the context of stability analysis I see one huge problem. It's that you still have to check that $P$ is positive definite or equivalently that its eigenvalues are positive. But for the linear system the fact that all eigenvalues of $A$ have negative real parts ensures that the system is globally asymptotically stable in the first place. So what's the point of going through all the hassle just to end up with looking for the eigenvalues ( $P$ and $A$ are of the same size!) anyway? Does the symmetric matrix make such a big difference?","['eigenvalues-eigenvectors', 'dynamical-systems', 'stability-in-odes', 'matrix-equations', 'ordinary-differential-equations']"
1267961,Parametrising a Sphere,"If parametrising a sphere $r=(\cos{u}\cos{v},\cos{u}\sin{v},\sin{u})$ is it true that limits for $u$ and $v$ will be $-\pi/2$ and $\pi/2$ and $0$ and $2\pi$ respectively? Why is this different to when parametrising a sphere, with parametrization $\rho\sin{\phi}\cos{\theta}, \rho\sin{\phi}\sin{\theta}, \rho\cos{\phi}$ where the limits of $\phi$ are between and $0$ and $\pi$?","['calculus', 'multivariable-calculus']"
1267970,Which ellipses settle to 1-point contacts within a snow-globe circle?,"Suppose you have a solid ellipse with axes $a$ and $b$, $(x/a)^2 + (y/b)^2 = 1$,
confined inside a unit-radius circle.
You shake the circle like a snow globe, and the ellipse settles to
the bottom under gravity, assume with frictionless ellipse-circle contact. Q . For which $a$ and $b$ will the ellipse settle to a single point of contact? I would especially appreciate an answer that avoids excessive calculations.","['geometry', 'classical-mechanics', 'curvature']"
1267974,Quadratic Reciprocity,"I've been asked to see if $x^2\equiv83$ $\pmod{101^{2000}}$ has solutions. Now I know $x^2\equiv83\pmod{101}$ has no solutions since the quadratic reside symbol $(\frac{83}{101})=-1$ using the quadratic reciprocity law. So by the Chinese Remainder Theorem, does this mean the former congruence has no solutions? Similarly does $x^2\equiv83$ $\pmod{29^{2000}}$ have solutions since $(\frac{83}{29})=1$ ?","['number-theory', 'quadratic-reciprocity']"
1267989,Why does the probability of a bivariate Poisson distribution behaves like this? (see example),"I am a beginner in working with statistics and I wanted to generate a bivariate Poisson distribution $(X_1, X_2)$ and to do so, I did according to the indication found on wikipedia (bottom of the page, http://en.wikipedia.org/wiki/Poisson_distribution ), therefore, I have generated three independent random variables which have a Poisson distribution $(Y_1, Y_2, Y_3)$, with means $\lambda_1 = \lambda_2 = \lambda_3 = 2$. Provided I have set: $X_1 = Y_1 + Y_3$ $X_2 = Y_2 + Y_3$ Then, $X_1$ ~ Poisson($2+2$) = Poisson($4$) $X_2$ ~ Poisson($2+2$) = Poisson($4$) In order to compute the bivariate probability I use the formula found on wikipedia (bottom of the page, http://en.wikipedia.org/wiki/Poisson_distribution ). When I try to compute the following probabilities (both in Matlab - set the format short - and on the paper), I obtain: $P(X_1 = 4, X_2 = 4) = 0.0446$ $P(X_1 = 3, X_2 = 3) = 0.0474$ Basically, it indicates that $P(X_1 = 4, X_2 = 4) < P (X_1 = 3, X_2 = 3)$, which seems completely counterintuitive, since the mean for both random variables $X_1$ and $X_2$ is $4$. Initially, I have doubted my Matlab code and my calculation skills, but I tested it thouroughly and I obtain the same results. Is there any potential explanation for this or I am simply wrong in performing my calculations? Thank you all.","['poisson-distribution', 'statistics', 'bivariate-distributions']"
1268047,Proving that $A\cap B \subseteq C \iff A \subseteq \overline{B} \cup C$,"I'm trying to prove the following statement: $$A\cap B \subseteq C \iff A \subseteq \overline{B} \cup C$$ I need to do it using a formal proof..
I've tried to do it for some time now and couldn't find anything close.. Thanks!",['elementary-set-theory']
1268086,Compute limit using Taylor's expansion,"Using Taylor’s expansion, prove that the following limit exists and compute it. $$\lim_{x \to 0}\left(\frac {x^2}{\frac {1}{1-x} - e^x}\right)$$ In this if I am using the taylor series expansion of $e^x$ then denominator has some value as $$ 1 + (1 + x + x^2 + x^3 + \ldots) + x (1 + x + x^2 + x^3 + \ldots) $$ I am not getting how to proceed further with this.","['taylor-expansion', 'calculus', 'limits']"
1268103,Prove that each component of $X$ is a closed subset of $X$.,"Definition: Let $X$ be a topological space and let $\sim_C$ be the equivalence relation on $X$ defined by $x \sim_C y$ if $x$ and $y$ lie in a connected subset of $X$. The components of $X$ are the equivalence classes of the equivalence relation $\sim_C$. Question: Prove that each component of $X$ is a closed subset of $X$. Please guide me how to start to prove, or any clue. Thank you.","['connectedness', 'general-topology']"
1268107,Prove that $\lim_{x \rightarrow 0} \mathrm {sgn} \sin (\frac{1}{x})$ does not exist.,"My progress: Using the sequential criterion for limits, I constructed two sequences $(x_n), (y_n)$ with $\lim(x_n)=\lim(y_n)=0$, such that $\lim(f(x_n))\neq \lim(f(y_n))$, where $f(x)=\sin\frac 1 x$. So, $\lim_{x \rightarrow 0} \sin (\frac{1}{x})$ does not exist. I also showed separately in the same way that  $\lim_{x \rightarrow 0}  \mathrm{sgn} (x)$ does not exist. I know that  $$\lim_{x \rightarrow 0} f(x)=M ,\,  \lim_{x \rightarrow 0} g(x)=N \Rightarrow \lim_{x \rightarrow 0} (fg)(x)=MN$$ Here, I have two functions $f,g$ which do not have limits at $x=0$. Does it follow from here that $\lim_{x \rightarrow 0} (fg)(x)$ also doesn't exist? Is it any other way to approach the problem?","['limits', 'real-analysis']"
1268113,Least squares aproximation,"In a Problem of least squares aproximation of a function 
$f:\mathbb R\longrightarrow\mathbb R$, 
in an interval $[a, b]$  by a polynomial of degree $n$ $$p(x)=c_0+c_1x+c_2x^2+\ldots+c_nx^n,\;\;\;\;\;\;c_n\neq 0,$$ we have to minimize the function $\psi$ defined by 
$$\psi(c_0, c_1,\ldots, c_n)=\int_a^b|f(x)-p(x)|^2dx. $$ It is customary to solve the problem as follows: Solve the system: $$\frac{\partial\psi}{\partial c_i}=0,\;\;\;\;for\;i=0,\ldots, n,$$ then the solution of this system is the minimum. My question is: Why  the point where the partial derivatives are zero is the minimum and not the maximum or an inflection point?","['calculus', 'functions']"
1268122,Are not all neighborhoods of $0$ in a locally convex space absorbent?,"A locally convex space (LCS) can be defined as a topological vector space (i.e. scalar product and sum are continuous) whose topology is generated by translation of  a family of balanced and absorbent convex sets. Now let's imagine that I want to trim this definition as much as possible considering that we are in a topological vector space. For example it would be enough to say that a base of open neighborhoods of $0$ is given by a family $\{U_\alpha\}_\alpha$ of balaced absorbent convex sets since then a base of neighborhoods for $x$ would be $\{x+U_\alpha\}_\alpha$. A set $U$ in $X$ is absorbent if given $x\in X$ there is $r\geq 0$ such that $x\in rU$. My question is Isn't every neighborhood of $0$ in a topological vector space absorbent?. This is because given $x\in X$ the function from $\mathbb{R}$ or $\mathbb{C}$ that does $\lambda\mapsto \lambda x$ is continuous and so for $\lambda>0$ sufficiently small we have
$$
\lambda x \in U \Rightarrow x\in \frac{1}{\lambda} U.
$$ Hence it is enough to say a that a LCS is a top. vector space where a base of open neighborhoods of $0$ is given by a family of balanced convex sets, and being absorbent would be but a necessary condition for the neighborhoods (I always thought before that the absorbent condition was made so that the seminorms could be defined). Extra question: Is every family closed under intersection of absorbent sets containing zero sufficient to define by translation a base for a topology in a vector space where sum and scalar product are continuous? Or in other words, is any of the other conditions (being balaced, convex or any other) also necessary given that a LCS is a topological vector space? EDIT: Okay by looking at possible basis of open neighborhood of $0$ in $\mathbb{R}$ it becomes clear that they need not be formed by convex or balanced sets, but my question still remains as if there is any other condition that is necessary if we want them to generate a topological vector space.","['analysis', 'convex-analysis', 'functional-analysis', 'locally-convex-spaces']"
1268144,Question about characteristic polynomial of the Frobenius endomorphism on elliptic curves.,"I have another possibly trivial question about elliptic curves. A lot of papers I've seen state that the characteristic polynomial of the Frobenius endomorphism of an elliptic curve over a finite field of characteristic $q$ is $\varphi^2-t\varphi+q$, where $t$ is the trace of the endomorphism. Is there some simple derivation of this characteristic polynomial and if so where could I find it? Thank you very much.","['elliptic-curves', 'algebraic-geometry', 'reference-request']"
1268152,Cadlag process and measurability.,"Let $(\Omega,(\mathcal{F_t})_{t\geq0},P)$ be a filtered probability space and $X=(X_t)_{t\geq0}$ a real-valued adapted cadlag process. Let $A\subset\Omega$ (resp. $B\subset\Omega$) be the event that $X$ is continuous (resp right-continuous) on $[0,t)$. Show that $A$, $B\in\mathcal{F_t}$. I am not to show how to show this for $A$ but is it not trivial for $B$ as since $X$ is cadlag, we must then have $B=\Omega$?? Any help is most welcomed and needed. Thanks.","['probability-theory', 'stochastic-processes', 'measure-theory']"
1268155,Prove that $4x^2-8xy+5y^2\geq0$ - is this a valid proof?,"I need to prove that $4x^2-8xy+5y^2\geq0$ holds for every real numbers $x, y$. First I start with another inequality, i.e. $4x^2-8xy+4y^2\geq0$, which clearly holds as it can be factorized into $(2x-2y)^2\geq0$. Now we can add $y^2$ (which is always nonnegative) to the left side, thus obtaining $4x^2-8xy+5y^2\geq0$, which is always true - we've just added a nonnegative expression to another, so the sum is still greater or equal to zero. Is my proof correct? I had it on my final math exam and would like to be sure.","['proof-verification', 'algebra-precalculus', 'inequality']"
1268183,How to prove this ODE is stable but not asymptotically stable?,"Consider the ODE in polar coordinates:
$$
r'=f(r),\theta ' =1
$$
where
$$
f(r)=r\sin (1/r^2), r\neq 0, f(0)=0.
$$
show that the origin is stable but not asymptotically stable.","['stability-in-odes', 'polar-coordinates', 'ordinary-differential-equations']"
1268191,"Find the standard matrix representation of the linear transformation T in M2,2","let  $T: M_{2,2} \rightarrow M_{2,2}$ be a linear transformation defined by: $$T \left(\begin{bmatrix}
        a & b\\
        c & d\\
        \end{bmatrix}\right) = \begin{bmatrix}a + b& b + a \\ c - d&d+b\end{bmatrix}
$$ Find the standard matrix for $S$ by using the standard basis of $M_{2,2}$ This is what i've done so far: $$T \left(\begin{bmatrix}
        1 & 0\\
        0 & 0\\
        \end{bmatrix}\right) = \begin{bmatrix}1& 1 \\ 0&0\end{bmatrix} = x_1
$$ $$T \left(\begin{bmatrix}
        0 & 1\\
        0 & 0\\
        \end{bmatrix}\right) = \begin{bmatrix}1& 1 \\ 0&1\end{bmatrix} = x_2
$$ $$T \left(\begin{bmatrix}
        0 & 0\\
        1 & 0\\
        \end{bmatrix}\right) = \begin{bmatrix}0&0\\ 1&0\end{bmatrix} = x_3
$$ $$T \left(\begin{bmatrix}
        0 & 0\\
        0 & 1\\
        \end{bmatrix}\right) = \begin{bmatrix}0& 0\\ -1&1\end{bmatrix} = x_4
$$ But I'm not too sure where to go from here. All I know that these need to somehow become part of a larger matrix","['linear-transformations', 'linear-algebra', 'matrices']"
1268202,Is every family of almost commuting matrices close to some family of commuting matrices?,"Suppose that there are many matrices $A_i\in M_n(C)$, $i=1,2,3,\cdots,m$, that almost commute with each other (what I means is that they are not commute with each other, but $||[A_i, A_j]||$ is very small). Can I slightly change the matrices, e.g., $A_i^\prime:=A_i+\delta_i$ with $||\delta_i||$ very small, such that the new matrices $A_i^\prime$ commute with each other?",['linear-algebra']
1268213,Differential Equation (Non linear to linear differential equation),"Show that the substitution $u=\frac{1}{y}$ transform the non-linear differential equation $$\frac{dy}{dx}+\frac{y}{x}=y^2\ln (x)$$ into the linear differential equation $$\frac{du}{dx}-\frac{u}{x}=-\ln (x)$$. Solve this linear differential equation, and hence obtain $y$ in terms of $x$, given that $y=\frac{1}{2}$ when $x=1$ My attempt, $\frac{dy}{dx}+\frac{y}{x}=y^2\ln (x)$ $\frac{-\frac{dy}{dx}}{y^2}-\frac{1}{xy}=-\ln (x)$ Let $u=\frac{1}{y}$ $\frac{du}{dx}=\frac{-\frac{dy}{dx}}{y^2}$ $\frac{du}{dx}-\frac{y}{x}=-\ln (x)$ $e^{\int -\frac{1}{x}dx}=\frac{1}{x}$ $\frac{\frac{du}{dx}}{x}-\frac{u}{x^2}=-\frac{\ln (x)}{x}$ $\frac{\frac{du}{dx}}{x}+\frac{d}{dx}(\frac{1}{x})u=-\frac{\ln (x)}{x}$ $\frac{d}{dx}(\frac{u}{x})=\frac{-\ln (x)}{x}$ $\int \frac{d}{dx}(\frac{u}{x})dx=\int \frac{-\ln (x)}{x}dx$ $\frac{u}{x}=-\frac{1}{2}\ln ^2(x)+c_1$ $u=x(-\frac{1}{2}\ln ^2(x)+c_1)$ $y=\frac{1}{u}=\frac{2}{-x\ln ^2(x)+2c_1x}$ $y=\frac{2}{-x\ln ^2(x)+c_1x}$ When $x=1$, $y=\frac{1}{2}$
I got $c_1=4$ Therefore, $y=\frac{2}{-x\ln ^2(x)+4x}$ Is this working right? Is there another method to solve this question?","['calculus', 'ordinary-differential-equations', 'integration']"
1268216,"$f: \mathbb R \rightarrow \mathbb R, f(x+y)=f(x)+f(y), \forall x,y \in \mathbb R$. If $lim_{x \rightarrow 0} f=L$, prove that $L=0$","$f: \mathbb R \rightarrow \mathbb R, f(x+y)=f(x)+f(y), \forall x,y \in \mathbb R$ I can see that $f(2x)=f(x)+f(x)=2f(x)$ and $f(x-c)=f(x)-f(c)$, also that $f(0)=0$. Nothing is mentioned about continuity of the function, so I cannot use the assumption of continuity. To prove that $L=0$, I need to show that $|f(x)|<\varepsilon$ when $|x-c|<\delta$ I don't know how to go about it. Please help!","['limits', 'real-analysis']"
1268230,Characteristic function of a product of two dependent random variables,"If you're given the characteristic function of a continuous random variable, say X, and the distribution of another discreet random variable, say U, which is dependent of X, how do you explicitly find the characteristic function of UX? Consider the case that X is normal random variable while U is a random variable defined as $$
U=\begin{cases}
 v & \text{if }X<1 \\
  r & \text{ }Otherwise 
 \end{cases}
 $$ where
$$
v=\begin{cases}
1 & \text{with probability }\frac{1}{2} \\ 
-1 & \text{with probability }\frac{1}{2}%
 \end{cases}
$$ and 
$$
r=\begin{cases}
0.25 & \text{with probability }0.75 \\ 
0.7& \text{with probability }0.25%
 \end{cases}
$$","['probability-theory', 'conditional-expectation', 'probability', 'probability-distributions']"
1268259,How do I find the finite limits of this infinite product?,"What is... $$\lim_{\omega \to \infty} 
\left( {1 \over {a^{\omega}}} \cdot  \prod_{N=1}^{\omega} (1+e^{b \cdot c^{-N}}) \right)$$ I'd like closed form solutions, and in this case that means any solution. So you don't need to concern yourself over ""elementary"" solutions. (although I'd prefer that). As I discuss below, the values that are infinite or zero are already known, I'd like expressions for finite values only... What I know: I made a bounty on this question. I got a proof that showed that the limit of the above equation is infinite for $1 \lt a=c \lt  2$ and 0 for $a=c \gt 2$. So knowing the limit is volatile, I've made a generalization to find the analytical methods to get the finite values from this equation. My attempt: I have absolutely no clue except for the case of $a=2 \ $, $b=1$ and  $c=2$, which is just a horrible coincidence, considering that its the only finite non zero limit preserved in the proof given in the link, which does generalize to any b... Create a line integral over the unit line evaluated with a uniform measure...
$$\int_L e^x d \mu=\int_{L/2} e^x \ d\mu+\int_{L/2} e^{x+1/2} \ d\mu$$
This identity should be evident by self-similarity. Prepare for recursion...
$$\int_L e^x d \mu=\int_{L/2} e^x+e^{x+1/2} \ d\mu=(1+e^{1/2}) \cdot \int_{L/2} e^x \ d\mu$$
$$\Rightarrow \int_L e^x d \mu=(1+e^{1/2}) \cdot \left( \int_{L/4} e^x \ d\mu+\int_{L/4} e^{x+1/4} \ d\mu \right)$$
$$\Rightarrow \int_L e^x d \mu=(1+e^{1/2}) \cdot (1+e^{1/4}) \cdot \left( \int_{L/4} e^x \ d\mu \right)$$
It wouldn't be hard to prove by induction then that...
$$\Rightarrow \int_L e^x d \mu=\lim_{\omega \to \infty} 
\left(\prod_{N=1}^{\omega} (1+e^{2^{-N}}) \cdot \int_{L/{2^{\omega}}} e^x \ d\mu \right)$$
Yet we know what the left hand side equals, since it can be evaluated as a definite integral, also we know what the integral on the right equals. Since the measure is uniform and the number of values x will be allowed to take on the interval decreases to just the value, namely $0$...
$$e-1= \lim_{\omega \to \infty} 
\left( {1 \over {2^{\omega}}} \cdot \prod_{N=1}^{\omega} (1+e^{2^{-N}}) \right)$$ Motivation: Getting an answer will allow me to derive methods to integrate a function like $e^x$ over fractals. As I hinted at above, its easy to find the numerical solution to the above limit. For instance for $a=2 \ $ , $b=2$ , $c=3$, the limit is $1.753$...","['closed-form', 'limits', 'infinite-product']"
1268278,How to integrate $\int \cos^2(3x)dx$,$$\int \cos^2(3x)dx$$ The answer according to my instructor is: $${1 + \cos(6x) \over 2} + C$$ But my book says that: $$\int \cos^2(ax)dx = {x \over 2} + {\sin(2ax) \over 4a} + C$$ I'm not really sure which one is correct.,"['calculus', 'trigonometry']"
1268315,equality of Cardinality of $\mathbb{R}$ and $\mathbb{R^2}$,"There was a question in our exam which wanted us to prove that $\mathbb{R}$ and $\mathbb{R^2}$ both have same Cardinality. My approach to prove this problem was to try to make a bijection between $\mathbb{R}$ and $\mathbb{R^2}$. You can see my proof below, but the teacher assistant gave to my proof 3.5 out of 10! Can you tell me what is wrong with my proof?! This is my proof: To prove that $\mathbb{R}$ and $\mathbb{R^2}$ both have same size, it's sufficient to show that there is a bijection between these two.
consider $f : \mathbb{R} \rightarrow \mathbb{R^2}$ which images each $x\in \mathbb{R}$ to $(x,0)$. this function is clearly one to one. Assume another function $g : \mathbb{R^2} \rightarrow \mathbb{R}$.The function formula is this: give any $(x,y) \in \mathbb{R^2}$ . Write x and y by their standard decimal expansion (you can't use infinitely many 9 in expansion), so $(x,y)=(A_0A_1...A_n.a_0a_1...., B_0B_1...B_m.b_0b_1...)$ without loss of generalitty assume that $m\ < n$ . say $g(x,y)=A_0B_0A_1b_1...A_mB_mA_{m+1}...A_n.KFa_0b_0a_1b_1....$, which $K=0$ if x is positive and $K=1$ if x is not. and Also $F=0$ if y is positive and $
F=1$ if y is not. it's obvious that the function $g$ is one to one. so by using the Schroeder-Bernstein Theorem there is a bijection between $\mathbb{R}$ and $\mathbb{R^2}$. So, we proved that $\mathbb{R} \sim \mathbb{R^2}$ .","['elementary-set-theory', 'real-analysis', 'cardinals']"
1268337,Square of a convex non-negative function is still convex,"Let $f: \mathbb R \rightarrow \mathbb [0, \infty)$ be a convex function. If $f$ is twice-differentiable, then
$$ (f^2)'' = (2ff')' = 2(f')^2 + 2f f'', $$
which is $\geq 0 $ since $f, f'' \geq 0.$
But how can I prove that $f^2$ is convex without smoothness assumptions? Recall the definition of convexity: $\forall t \in (0,1), \forall x,y \in \mathbb R,$
$$ f((1-t)x+ty) \leq (1-t) f(x) + t f(y). $$
Squaring both sides I get
$$ f^2((1-t)x+ty) \leq (1-t)^2 f^2(x) + t^2 f^2(y) + 2t(1-t)f(x)f(y).$$
Now, from the fact that $t \in (0,1)$ and the inequality $2t(1-t) \leq t^2 + (1-t)^2 \leq 1 $ I get
$$ f^2((1-t)x+ty) \leq (1-t)f^2(x) + tf^2(y) + f(x)f(y). $$
But that's a $f(x)f(y)$ too much...","['convex-analysis', 'calculus']"
1268338,Solving seemingly easy differential EQ,"I have the differential equation $2\frac{d^2\phi}{d^2\zeta}=e^{-\phi}$, where $\phi=\Phi/\sigma_z^2$, $\zeta=z/z_0$. I also have the fact that $ln(\rho/\rho_0)=-\Phi/\sigma_z^2$. Given the boundary conditions $\phi(0)=0=\frac{d\phi}{d\zeta}\big{|}_0$, we need to show that the solution is $\rho(z)=\rho_0sech^2(\frac{z}{2z_0})$. I show below what seems to be the correct method, but I cannot reproduce the quoted answer: $$\frac{d^2\phi}{d^2\zeta}=\frac{e^{-\phi}}{2}$$ $$\frac{d\phi}{d\zeta}-\frac{d\phi}{d\zeta}{|}_0=\frac{e^{-\phi}}{2}\zeta+c_1$$ $$\frac{d\phi}{d\zeta}=\frac{e^{-\phi}}{2}\zeta+c_1$$ to get $c_1$:
$$\frac{d\phi}{d\zeta}|_0=\frac{e^{-\phi(0)}}{2}\zeta+c_1$$
$$0=\frac{e^{0}}{2}\zeta+c_1$$
thus $c_1=-.5\zeta$ $$\frac{d\phi}{d\zeta}=\frac{1}{2}\zeta({e^{-\phi}}-1)$$ $$\frac{d\phi}{({e^{-\phi}}-1)}=\frac{1}{2}\zeta d\zeta$$ letting $u\equiv e^{-\phi}-1,du\equiv -d\phi e^{-\phi}\rightarrow du\equiv -d\phi (1+u)$. thus this becomes
$$\int-\frac{du}{(1+u)u}=\int\frac{1}{2}\zeta d\zeta$$ I use the partial fraction method to beget the LHS in a tractable form, and integrating this equation I get the following: $$-ln(1-e^{\phi})+ln(1-e^{\phi(0)})=\frac{\zeta^2}{4}+c_3$$ $$-ln(1-e^{\phi})-\infty=\frac{\zeta^2}{4}+c_3$$ $$-ln(1-e^{\phi(0)})-\infty=\frac{\zeta^2}{4}+c_3$$ $$\infty-\infty=\frac{\zeta^2}{4}+c_3$$
so $c_3$ is supposedly $-\zeta^2/4$. This is problematic, for then I get that $\rho/\rho_0=0$. What may be leading it astray?",['ordinary-differential-equations']
1268368,Why are the Cauchy-Riemann equations in polar form 'obvious'?,"In my book on complex analysis I'm asked to prove the Cauchy-Riemann equations in polar form, which I did. However, at the end of the question the author asks why these relations are 'almost obvious'. Now I get the derivation using chain rules and also the idea of approach along a circle and along a radial line and then equating. But the fact that the author asks this question to me suggests that there is an even simpler way of seeing this. That or maybe the author just regards one of these approaches to be 'almost obvious'. So I'm looking for a more intuitive (so it also does not need to be 100% rigorous) way of thinking about the Cauchy-Riemann relations in polar form. These  relations are $$u_r=\frac{1}{r}v_\theta, \quad \frac{1}{r}u_\theta = -v_r$$","['complex-analysis', 'intuition', 'derivatives']"
1268369,Is this a property of commutative differential operators?,"I found this claim in a paper but the proof escapes me. I'm sure that it's simple. Suppose we have $\psi$, a solution to the ODE $LQ\psi=0$, where $L$ and $Q$ are commutative differential operators. Then it is possible to write $\psi=\psi_1+\psi_2$ such that $L\psi_1=0$ and $Q\psi_2=0$. Thanks",['ordinary-differential-equations']
1268392,The composition of a nowhere-differentiable function with a differentiable function.,"This is actually Problem $ 17 $ from Chapter $ 10 $ of the Fourth Edition of Michael Spivak’s Calculus . The statement is quite simple, but I have not had any success in finding an example. Here is the statement: Problem. Give an example of functions $ f: \Bbb{R} \to \Bbb{R} $ and $ g: \Bbb{R} \to \Bbb{R} $ such that $ g $ takes on all values (i.e., is surjective), and $ f \circ g $ and $ g $ are differentiable, but $ f $ is not differentiable. Note: I want to assume that $ f $ is nowhere differentiable, otherwise the problem is quite easy. Note that this is in the second chapter of limits, which means that simple examples are expected. No functions defined in terms of integrals or power series should be necessary!","['calculus', 'functions', 'function-and-relation-composition', 'examples-counterexamples', 'derivatives']"
1268400,"Probability of choosing subsets $A$, $B$ such that $A\cap \!\,B=\varnothing \!\,$ and $A\cup \!\,B=X$","I'm given a set $X={\{\ \!\,1,2,3,...,n\!\ \}} $, and I have to calculate the probability that, for two randomly chosen, different, non-empty sets $A, B$: $A,B\subseteq \!\,X$, we have $A\cap \!\,B=\varnothing \!$ and $A\cup \!\,B=X$. I'm aware that the number of possible cases is $(2^n-1)(2^n-2)$, but I don't know how to count the cases which satisfy the above, which is the gist of the question. Also, what would be the probability for the same problem, just without the $A\cup \!\,B=X$ part? Edit: This was my professor's solution for the first problem (with both conditions): $\frac{\displaystyle\sum_{k=1}^{n-1} {n \choose k} \displaystyle\sum_{i=1}^{n-k} {n-k\choose i}}{(2^n-1)(2^n-2)}$ Does this make any sense to anyone?","['probability', 'combinatorics']"
