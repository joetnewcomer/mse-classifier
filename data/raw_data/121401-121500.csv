question_id,title,body,tags
1822127,$\lim_{x \to 0} \frac{\sin(a + b)x + \sin(a - b)x + sin(2ax)}{\cos^2 bx - cos^2 ax}$,"Question : - $$\lim_{x \to 0} \frac{\sin(a + b)x + \sin(a - b)x + \sin(2ax)}{\cos^2 bx - \cos^2 ax}$$ My attempt :- $$\lim_{x \to 0} \frac{2* \sin ax * \cos bx + 2*\sin ax * \cos (ax)}{(\cos bx - \cos ax)*(\cos bx +\cos ax)}$$
  $$\lim_{x \to 0} \frac{2* \sin ax * (\cos bx + \cos (ax))}{(\cos bx - \cos ax)*(\cos bx +\cos ax)}$$
  $$\lim_{x \to 0} \frac{2* \sin ax}{(\cos bx - \cos ax)}$$
  $$\lim_{x \to 0} \frac{2* \sin ax}{(-2 * \sin {bx-ax\over2} * \sin {bx+ax\over2})}$$
  $$-\lim_{x \to 0} \frac{{\sin ax \over ax} * {ax }}{\frac{\sin {bx-ax\over2} * \sin {bx+ax\over2}}{ {bx+ax\over2} * {bx-ax\over2}} * {bx+ax\over2} * {bx-ax\over2}}$$
  $$-\lim_{x \to 0} \frac{ax}{{bx+ax\over2} * {bx-ax\over2}}$$
  $$-\lim_{x \to 0} \frac{ax}{{(bx)^2 - (ax)^2\over 4}}$$
  $$\lim_{x \to 0} \frac{4 * ax}{(ax)^2 -(bx)^2}$$
  $$\lim_{x \to 0} \frac{4 * a}{x (a^2 - b^2)}$$ There i hit the dead end, i can't do anything now. Can anyone please tell me what i have done incorrect here ? Sorry but i can't confirm the legitimacy of the question, i just found it on net and there is no answer given.","['calculus', 'limits']"
1822137,The expansion of $(a+b+c+d)^{20}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let us consider the expansion of $$(a+b+c+d)^{20}.$$
Find: The coefficients of $a^{11}b^6c^2d$ and $a^{11}b^9$, The total number of terms of this expansion, The sum of all the coefficients. Thank you for your help.","['combinatorics', 'multinomial-coefficients', 'polynomials', 'discrete-mathematics']"
1822160,Why is column space on the vertical in a matrix?,"Why is the ""column space"" on the vertical in a matrix? In my mind the column space is that space that the vectors in the matrix have created.
I mean, for example take the equations: 3x + 4y = 5

2x + 8y = 6 Then the matrix will be: \begin{pmatrix}
3 & 4 \\
2 & 8 
\end{pmatrix} But why is the space defined by this matrix on the vertical? Aren't the two vectors: 3i + 4j and 2i + 8j defining the space we're working in?","['matrices', 'linear-algebra']"
1822172,Evaluate $\int_{1/10}^{1/2}\left(\frac{\sin{x}-\sin{3x}+\sin{5x}}{\cos{x}+\cos{3x}+\cos{5x}}\right)^2dx$,"How can I evaluate the following integral? $$\int_{1/10}^{1/2}\left(\frac{\sin{x}-\sin{3x}+\sin{5x}}{\cos{x}+\cos{3x}+\cos{5x}}\right)^2dx$$ I notice that the numerator and the denominator are very similar. So my direction is to evaluate this integral by substitution. However, I cannot find a suitable substitution so that the integral can be nice.","['definite-integrals', 'integration', 'trigonometry', 'calculus']"
1822213,$c_1\cosh(x)+c_2\sinh(x)=A\cosh(x+y)$ always true?,"My question: Can I rewrite $c_1\cosh(x)+c_2\sinh(x)$, which is a solution to a differential equation as $$A\cosh(x+x_0)$$
introducing the new constants of integration $A$ and $x_0$? How can I deal with $c_1=0$? This is how I can set up a relationship between the coefficients: $A\cosh(x+x_0)=A\cosh(x)\cosh(x_0)+A\sinh(x)\sin(x_0)$ Compare coefficients: $c_1=A\cosh(x_0)$ and $c_2=A\sinh(x_0)$. Now square and subtract both equations: 
$$c_1^2-c_2^2=A^2 \implies A=\pm\sqrt{c_1^2-c_2^2}.$$ Now devide second equation by first equation: $$\tanh(x_0)=c_2/c_1 \implies x_0=\tanh^{-1}(c_2/c_1 )$$","['ordinary-differential-equations', 'functions']"
1822246,A novelty integral for $\pi$,"My lab friends always play a mentally challenging brain game every month to keep our mind running on all four cylinders and the last month challenge was to find a novelty expression for $\pi$. In order to stick to the rule, of course we must avoid the good old Ramanujan and online available expressions, for instance: the coolest ways of expressing $\pi$ on Quora. The winner of the last month challenge is this integral $${\large\int_0^\infty}\frac{(1+x)\log(1+x)(2+\log x)\log\left(\!\frac{1+x}{2}\!\right)-2x\log(1+x)\log x}{x^{3/2}(1+x)\log^2x}\ dx={\Large\pi}$$ The equality is precise to at least thousand decimal places. Unfortunately, my friend who proposes this integral keeping the mystery to himself. I tried to crack this integral while waiting for a solution to be offered by one of my friends, but failed to get any. I have tried to break this integral into two part: $${\large\int_0^\infty}\frac{\log(1+x)(2+\log x)\log\left(\!\frac{1+x}{2}\!\right)}{x^{3/2}\log^2x}\ dx-2{\large\int_0^\infty}\frac{\log(1+x)}{\sqrt{x}(1+x)\log x}\ dx$$ but each integrals diverges. I have tried many substitutions like $x=y-1$, $x=\frac{1}{y}$, or $x=\tan^2y$ hoping for familiar functions, but couldn't get one. I also tried the method of differentiation under integral sign by introducing $$I(s)={\large\int_0^\infty}x^{s}\cdot\frac{(1+x)\log(1+x)(2+\log x)\log\left(\!\frac{1+x}{2}\!\right)-2x\log(1+x)\log x}{(1+x)\log^2x}\ dx$$ and differentiating twice with respect to $s$ to get rid of $\log^2x$ couldn't work either. I have a strong feeling that I miss something completely obvious in my calculation. I'm not having much success in evaluating this integral since two weeks ago, so I thought it's about time to ask you for help. Can you help me out to prove it, please?","['calculus', 'proof-verification', 'improper-integrals', 'integration', 'pi']"
1822271,Strict inequality in Fatou's lemma,"Put $f_n={1}_E$ if $n$ is odd, $f_n=1-1_E$ if $n$ is even. What is the relevance of this example to Fatou's lemma? Proof: We see that $\int \limits_{X}f_nd\mu= \mu(E^c)$ if $n$ is even and $\int \limits_{X}f_nd\mu= \mu(E)$ if $n$ is odd. It's easy to check that $\liminf \limits_{n\to \infty} f_nd\mu=0$ hence $\int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu=0$. But $\liminf \limits_{n\to \infty}\int \limits_{X} f_nd\mu=\min \{\mu(E^c), \mu(E)\}$ and Fatou's lemma states that $$\int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu\leqslant \liminf \limits_{n\to \infty}\int \limits_{X} f_nd\mu.$$ In our case it's equivalent to $0\leqslant \min\{\mu(E), \mu(E^c)\}$. But if we consider $X=\mathbb{N}, \mathfrak{M}=2^{\mathbb{N}}$ and $\mu$ be counting measure. Taking $E=\{1\}$ we see that it's measurable and $E^c=\mathbb{N}\setminus\{1\}$. In this case $\mu(E)=1$ and $\mu(E^c)=+\infty$ and we get the following strict inequality: $$0< \min\{\mu(E), \mu(E^c)\}=1.$$ Sorry if this topic is repeated. But I would like to know is my proof correct?
Would be very grateful for any suggestions and remarks!","['real-analysis', 'measure-theory', 'proof-verification']"
1822274,Solving an equation with logarithms: $x^{\log_2(\sqrt{x})-1} = \sqrt{8}$,"The equation I'm given is
$$\large x^{\log_2(\sqrt{x})-1} = \sqrt{8}$$ I've tried on solving it and my best try is on the photo. Got stuck there and not sure how to proceed any further.",['linear-algebra']
1822319,Picking cards sequentially vs consecutively,"We have a pack of 6 cards over the table. Cards are: {A, A}, {B, B}, {C}, {D}. There are 3 players ( Papa , Pepe , Popo ) sat around the table. Cards are all upside down, so the players cannot see which card they are picking. Now we are presented with two scenarios: Case 1: each player picks one card at a time. That is, first Papa picks a card, then Pepe, then Popo, until there are no cards over the table (i.e. cards are being picked sequentially ). Case 2: each player picks their 2 cards directly, that is: Papa picks 2 cards, then Pepe, then Popo. (i.e. cards are being picked consecutively ). I am being asked if the probability that Papa has the two A's is the same (or not) for both cases. My knowledge on statistics and probability is not very advanced, but I'd say that the chance for Papa picking the two A's will not be the same, but I don't have a convincing argument in favour. Maybe someone could point me towards the right direction in solving this problem.","['probability-theory', 'probability', 'statistics', 'card-games']"
1822335,Geometric interpretation of multiplication of probabilities?,"When dealing with abstract probability space $\Omega$ which consists of atomic events with measure ($P: \Omega \rightarrow \mathbb{R}$) defined for them, it seems natural to start immediately imagining simple cases like this: $\Omega$ is some closed area in 2-D space partitioned into subareas, representing atomic events. Measure is the area. The total area of $\Omega$ is 1. In fact this is what they sometimes picture in textbooks with the help of vienne diagrams or whatever. This intuition works fine for simple cases, especially with adding probabilities. But then it comes to probability multiplication: I don't understand how to interpret it within this simple model. Is there a way?.. Is there at all some mental model to think about probability multiplication in simple geometric terms, besides Lebesgue terms? Thank you!","['probability-theory', 'probability']"
1822336,How would you find the exact roots of $y=x^3+x^2-2x-1$?,"My friend asked me what the roots of $y=x^3+x^2-2x-1$ was. I didn't really know and when I graphed it, it had no integer solutions. So I asked him what the answer was, and he said that the $3$ roots were $2\cos\left(\frac {2\pi}{7}\right), 2\cos\left(\frac {4\pi}{7}\right)$ and $2\cos\left(\frac {8\pi}{7}\right)$. Question: How would you get the roots without using a computer such as Mathematica? Can other equations have roots in Trigonometric forms? Anything helps!","['polynomials', 'roots', 'trigonometry', 'algebra-precalculus', 'cubics']"
1822342,Minimum number of flips to guarantee heads,"This is a weird problem that popped into my head: given a fair coin, how many flips is required to guarantee heads? If I get a tails, then another tails, and another etc., the chance of getting a heads increases every time. But there is still a small chance that I will get another tails. This seems to imply that there is no finite number of flips to guarantee a heads. Does this mean that infinity is the correct answer (although infinity isn't a number as far as I understand) or is this question even answerable in the first place?",['probability']
1822351,My proof that $f[f^{-1}(D)] \subseteq D.$,"I've just started studying formal proof and set theory, so it'll be really cool if someone can check out my proof for a pretty basic set theory problem. It'll be great if you can tell me if my proof is correct and other tips to making it better. So here it goes: Theorem: Suppose that $f: A \rightarrow B$. Let $D$ be a subset of $B$. Prove that $$f[f^{-1}(D)] \subseteq D.$$ Proof: Let $y \in f[f^{-1}(D)].$ Then, there exists an $x \in A$ such that $y = f(x)$. Hence, $x \in f^{-1}(D)$, or in other terms, $x \in \{a \in A: f(a) \in D\}.$ Therefore, $f(x) \in D$ and since $f(x) = y, y \in D$. As a result, $f[f^{-1}(D)] \subseteq D.$","['proof-writing', 'elementary-set-theory']"
1822358,"Prob. 4 (b), Sec. 20 in Munkres' TOPOLOGY, 2nd ed: Which of these sequences are convergent w.r.t. the product, uniform, and box topologies?","Let $\mathbb{R}^\omega$ denote the set of all the (infinite) sequences of real numbers. Then which of the following sequences in $\mathbb{R}^\omega$ are convergent (and if so, then to which points(s)) in $\mathbb{R}^\omega$ in the product, uniform, and box topologies? 
$$ \begin{align} 
w_1 &= \left( 1, 1, 1, 1, \ldots\right), \\ 
w_2 &= \left( 0, 2, 2, 2, \ldots \right), \\ 
w_3 &= \left( 0, 0, 3, 3, 3, \ldots \right), \\ 
& \ldots; 
\end{align} $$
$$ \begin{align} 
x_1 &= \left( 1, 1, 1, 1, \ldots\right), \\
x_2 &= \left( 0, \frac 1 2, \frac 1 2, \frac 1 2, \ldots \right), \\ 
x_3 &= \left( 0, 0, \frac 1 3, \frac 1 3, \frac 1 3, \ldots \right), \\
&  \ldots; 
\end{align} $$
$$ \begin{align} 
y_1 &= \left( 1, 0, 0, 0, \ldots\right), \\
y_2 &= \left( \frac 1 2, \frac 1 2, 0, 0, 0, \ldots \right), \\ 
y_3 &= \left( \frac 1 3, \frac 1 3, \frac 1 3, 0, 0, 0, \ldots \right), \\ 
& \ldots; 
\end{align} $$
$$ \begin{align} 
z_1 &= \left( 1, 1, 0, 0, 0, \ldots\right), \\
z_2 &= \left( \frac 1 2, \frac 1 2, 0, 0, 0, \ldots \right), \\ 
z_3 &= \left( \frac 1 3, \frac 1 3, 0, 0, 0, \ldots \right), \\ 
& \ldots. 
\end{align} $$ My effort: We can prove the following result. Let $X$ be a non-empty set with topologies $T_1$ and $T_2$ such that $T_1 \subset T_2$. Let $p_n$ be a sequence of points of $X$, and let $p \in X$. Then we have the following: If $p_n $ converges to $p$ in the topology $T_2$, then $p_n$ converges to $p$ in the topology $T_1$ also. In other words, if $p_n$ fails to converge to $p$ in $T_1$, then $p_n$ fails to converge to $p$ in $T_2$ also. Am I right? Also, the product and uniform topologies on $\mathbb{R}^\omega$ are the metric topologies induced by the metrics $D$ and $\tilde{\rho}$, respectively, on $\mathbb{R}^\omega$ defined as follows: 
$$D\left( x, y \right) = \sup \left\{ \ \frac{ \min \left\{ \left\vert x_n - y_n \right\vert, 1 \right\}  }{n} \ \colon \ n \in \mathbb{N} \  \right\}$$ 
and 
$$\tilde{\rho}\left( x, y \right) = \sup \left\{ \ \min \left\{ \left\vert x_n - y_n \right\vert, 1 \right\} \ \colon \ n \in \mathbb{N} \ \right\}$$
for all $x = \left(x_n \right)_{n \in \mathbb{N}}$ and  $y = \left( y_n \right)_{n \in \mathbb{N}}$ in $\mathbb{R}^\omega$. Am I right? Moreover, in a metric space, every convergent sequence is Cauchy; so every non-Cauchy sequence in a metric space fails to converge. We can also state and prove the following. Let $p_n = \left( \xi_{n1}, \xi_{n2}, \xi_{n3}, \ldots \right)$ be a sequence of points in $\mathbb{R}^\omega$, and let $p = \left( \xi_1, \xi_2, \xi_3, \ldots \right)$ be a point of $\mathbb{R}^\omega$. Suppose that $\mathbb{R}^\omega$ is given the product topology. Then the sequence $p_n$ converges to $p$ in $\mathbb{R}^\omega$ if and only if, for each $j \in \mathbb{N}$, the sequence $\left( \xi_{nj} \right)_{n \in \mathbb{N}}$ converges to $\xi_j$ in $\mathbb{R}$. Am I right? If so, can we extend the above result (or part of it) to the uniform and the box topologies on $\mathbb{R}^\omega$? If the last result I've stated is correct, then in the product topology on $\mathbb{R}^\omega$, all of the given sequences can only converge to the point $\mathbf{0} = (0, 0, 0, \ldots)$. So none of these sequences can converge to a point distinct from $\mathbf{0}$ in either the uniform or the product topology. Am I right? Now for all $n \in \mathbb{N}$, we have $$D\left( w_n , \mathbf{0} \right) = \frac 1 n \to 0 \ \mbox{ as } \ n \to \infty, $$ showing that $w_n$ does converge to $\mathbf{0}$ in the product topology. Am I right? However, in the uniform metric, we have $$\tilde{\rho}\left(w_n, \mathbf{0} \right) = 1$$ for all $n \in \mathbb{N}$, showing that $w_n$ cannot converge to $\mathbf{0}$ and hence $w_n $ cannot converge to any other point of $\mathbb{R}^\omega$ either. Therefore $w_n$ cannot converge to any point of $\mathbb{R}^\omega$ in the box topology either. Am I right? For each $n \in \mathbb{N}$, we have $$D\left( x_n , \mathbf{0} \right) = \frac{1}{n^2} \to 0 \ \mbox{ as } \ n \to \infty,$$ showing that $x_n$ converges to $\mathbf{0}$ in the product topology. Am I right? For each $n \in \mathbb{N}$, we have $$ \tilde{\rho}\left( x_n, \mathbf{0} \right) = \frac 1 n \to 0 \  \mbox{ as } \ n \to \infty,$$ which shows that $x_n$ converges to $\mathbf{0}$ in the uniform topology also. Am I right? Now there is no $x_n$ in the box topology basis element $$ \left(- \frac{1}{1^3}, \frac{1}{1^3} \right) \times \left( - \frac{1}{2^3}, \frac{1}{2^3} \right) \times \left( - \frac{1}{3^3}, \frac{1}{3^3} \right) \times \left( \frac{1}{4^3}, \frac{1}{4^3} \right) \times \cdots $$ containing $\mathbf{0}$. So $x_n$ cannot converge in the box topology. Am I right? For each $n \in \mathbb{N}$, we have 
$$\tilde{\rho}\left( y_n, \mathbf{0} \right) = \frac 1 n \to 0 \ \mbox{ as } \ n \to \infty,$$ 
which implies that $y_n$ converges to $\mathbf{0}$ in the uniform topology and hence also in the product topology. Am I right? However, there is no $y_n$ in the box topology basis element $$\left(- \frac 1 2, \frac 1 2 \right) \times \left(- \frac 1 3, \frac 1 3 \right) \times \left(- \frac 1 4, \frac 1 4 \right) \times \cdots$$ containing $\mathbf{0}$, thus showing that $y_n$ cannot converge in the box topology. Am I right? Let $$ \left( a_1, b_1 \right) \times \left( a_2, b_2 \right) \times \left( a_3, b_3 \right) \times \cdots$$ be a box topology basis element containing $\mathbf{0}$. Then $a_j < 0 < b_j$ for each $j \in \mathbb{N}$. By the Archimedian property of real numbers, there are natural numbers $N_1$ and $N_2$ such that $b_1 N_1 > 1$ and $b_2 N_2 > 1$. Let $N$ be a natural number such that $N \geq \max \left\{ N_1, N_2 \right\}$. Then $$z_n \in  \left( a_1, b_1 \right) \times \left( a_2, b_2 \right) \times \left( a_3, b_3 \right) \times \cdots$$ for all $n \in \mathbb{N}$ such that $n > N$, from which it follows that $z_n$ converges to $\mathbf{0}$ in the box topology. Hence $z_n$ converges to $\mathbf{0}$ in both the uniform and the product topology also. Am I right? Have I been able to get the correct conclusions? If not, where have I erred? If yes, then can we determine the convergence of these sequences using only the machinery developed by Munkres up to this point in the book? An afterthought: If that if and only if result about the product topology is correct, then we don't need to bother doing the calculations involving the metric $D$. Am I right?","['general-topology', 'convergence-divergence', 'sequences-and-series', 'proof-verification']"
1822395,How to find the class number of $\mathbb{Q}(\sqrt{-17})$?,"I tried to calculate the class number with help of the Minkowski bound of $M \approx 5$. So if an ideal has norm $1$, it is the ring of integers. If it has norm $2$, it is $(2, 1+\sqrt{-17})$, which is not principal. Norm 3 gives us the ideals $(3, 1+\sqrt{-17})$ and $(3, 2+\sqrt{-17})$, which are both not principal. The only ideal of norm 4 is the ideal (2) and there arent any of norm 5. I don't know how to find the class number given this information. Can you guys please help? Thanks in advance!","['number-theory', 'algebraic-number-theory']"
1822419,"What if epsilon, delta are rational?","The precise formulation of the (ε, δ)-definition of limit as written here in wikipedia https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit doesn't specify which kind of number the epsilon, delta are. I wonder if it matters.","['epsilon-delta', 'calculus', 'limits']"
1822421,Is the class of imaginable objects which cannot exist a worthwhile thing to talk about?,"Clearly, in mathematics, there are certain objects which we can imagine, yet which have no real meaning, or do not exist. The real number whose square is negative, the quantity represented by ${1 \over 0}$, integer solutions to $a^3 + b^3 = c^3$, the largest prime number, the set of all sets which do not contain themselves, etc. All of these things are imaginable and can be studied and spoken of, and their properties more or less enumerated, yet none of them actually ""exist"", in the sense that assuming they exist creates contradictions. 
I can imagine, then, a class containing all these objects, the class of imaginable objects which cannot exist. Is there any inherent structure to this class, or is it meaningful at all to study this class? Is this class a member of itself, and is this a paradox? And would this class be a member of the class of all mathematical objects, or the Universal set, or can this not be?","['soft-question', 'elementary-set-theory']"
1822472,Multidimensional taylor series $sin (x^3y^2) $,"A homework of mine was to compute the Taylor series of $f(x,y)=\sin(x^3y^2)$ around $(0,0)$ to the 25th order. I assumed, as $\sin(z)=\sum\limits^{\infty}_{k=0}(-1)^k\frac{z^{2k+1}}{(2k+1)!}$, that I could just plug in my $x^3y^2$ in the formula and that this was covered by the identity theorem for power series. Is this right? Can somebody give me the exact reasoning?","['multivariable-calculus', 'taylor-expansion', 'power-series']"
1822484,Find an expression for $\frac{dy}{dx}$ in terms of $x$ and $y$ and verify that $P$ is a stationary point.,"A curve is defined by the equation $$2y+e^{2x}y^2=x^2+\frac{2}{e}$$ Find an expression for $\frac{dy}{dx}$ in terms of $x$ and $y$ \begin{align}
2y+e^{2x}y^2 & = x^2+\frac{2}{e} \\
2\frac{dy}{dx}+2e^{2x}y^2+2e^{2x}y\frac{dy}{dx} & = 2x \\ 
\frac{dy}{dx}+e^{2x}y^2+e^{2x}y\frac{dy}{dx} & = x \\ 
\frac{dy}{dx}\left(1+e^{2x}y\right) & = x-e^{2x}y^2 \\ 
\frac{dy}{dx} & = \frac{x-e^{2x}y^2}{1+e^{2x}y} \\ 
\end{align} Verify that $P$ $(1, \frac{1}{e})$ is a stationary point on the curve. Stationary point when $\frac{dy}{dx}=0$ $$\frac{x-e^{2x}y^2}{1+e^{2x}y}$$ \begin{align}
& = \frac{(1)-e^{2(1)}(\frac{1}{e})^2}{1+e^{2(1)}(\frac{1}{e})} \\ 
& = \frac{1-e^{2}e^{-2}}{1+e^{2}e^{-1}} \\ 
& = \frac{1}{1+e} \\ 
\end{align} $$\frac{1}{1+e}\neq0$$ Thanks",['ordinary-differential-equations']
1822495,"Calculating the integral $\int_{-\infty}^{\infty} e^{-x^2}\sin^{2}(2016x)\,dx$","I want to calculate the improper integral
$$\int_{-\infty}^{\infty} e^{-x^2}\sin^{2}(2016x)\,dx$$
but I don't know how to change the variable. Please guide me.",['integration']
1822505,Bijection between compact space $K$ and maximal ideals of real-valued functions on $K$,"Let $K$ be a compact topological space, and denote by $R$ the ring of continuous functions $K \to \mathbb{R}$, with addition and multiplication defined pointwise. We prove that there is a bijection between $K$ and the ""maximal spectrum"" of $R$ as follows: For $p \in K$, let $M_p = \{f \in R | f(p) = 0\}$. Prove that $M_p$ is a maximal ideal in $R$. Prove that if $f_1, \dots, f_r \in R$ have no common zeros, then the ideal generated by $f_1, \dots, f_r$ (let's call it $(f_1, \dots, f_r)$) is equal to $R$. (Hint: Consider $f_1^2 + \cdots + f_r^2$) Prove that ever maximal ideal $M$ in $R$ is of the form $M_p$ for some $p \in K$. (Hint: you will use compactness of $K$ and part 2) (This is problem III.4.17 in Paolo Aluffi's Algebra Chapter 0 ) Part 1 is not difficult, but for part 2 I thought I had a proof, that I now realize is horribly faulty, and didn't use the hint. Am I missing something fairly obvious? Thanks for the help.","['abstract-algebra', 'general-topology', 'ring-theory']"
1822519,Probability of getting a $7$ in Minesweeper,"Let's say you have a $30$ by $16$ grid and $99$ mines. What is the probability of having at least one empty block surrounded by exactly $7$ mines? For the sake of this question, assume that the mines are generated randomly.",['probability']
1822540,My proof that $f^{-1}(D_1 \cap D_2) = f^{-1}(D_1) \cap f^{-1}(D_2)$,"I'm currently self studying proof and set-theory, and I'm quite new to both of them. As an exercise, I'm practicing proving some basic theorems, so it'll be great if you can give me some feedback on how I'm doing so far. I'm not sure if there are any logical gaps in what I have done here. Theorem: Suppose $f:A \rightarrow B$ and let $D_1$ and $D_2$ be subsets of $B$. Prove that $$f^{-1}(D_1 \cap D_2) = f^{-1}(D_1) \cap f^{-1}(D_2).$$ Proof: First, let $x \in f^{-1}(D_1 \cap D_2)$. Then, there exists a $y \in D_1 \cap D_2$ that satisfies $f(x) = y.$ As $y \in D_1 \cap D_2$, $y \in D_1$ and $y \in D_2$. Therefore, $x \in f^{-1}(D_1)$ and $x \in f^{-1}(D_2)$, or $x \in f^{-1}(D_1) \cap f^{-1}(D_2)$. Hence, $f^{-1}(D_1 \cap D_2) \subseteq f^{-1}(D_1) \cap f^{-1}(D_2)$. Conversely, let $x \in f^{-1}(D_1) \cap f^{-1}(D_2)$. Then, $f(x) \in D_1$ and $f(x) \in D_2$ or $f(x) \in D_1 \cap D_2$. Because of this, $x \in f^{-1}(D_1 \cap D_2)$. Therefore, $f^{-1}(D_1) \cap f^{-1}(D_2) \subseteq f^{-1}(D_1 \cap D_2)$. Thus, ${f^{-1}(D_1 \cap D_2) = f^{-1}(D_1) \cap f^{-1}(D_2)}.$","['elementary-set-theory', 'functions', 'proof-verification']"
1822541,Proving the ratio of curvature and torsion is constant.,"This question has been asked slightly differently in a few different forums, but I wanted to discuss my approach and see if I was on the right track: Prove that if the tangent lines of a curve make a constant angle with a fixed direction, then the ratio of its curvature to its torsion is constant. So, I started by letting the curve be parameterized by arclength for convenience. Then, I let the fixed direction be the principal normal of the curve (as suggested by my professor). I know that the ratio of curvature to torsion is constant for a helix, so I was thinking of trying to prove that the assumptions imply that the curve must be a helix. I tried using the cosine similarity formula as follows (with $T$ being the tangent vector, and $u$ being my fixed principal normal direction: $cos(\theta)=\frac{T\cdot u}{\Vert{T}\Vert \Vert{u}\Vert}$ is constant I think I can say that both $T$ and $u$ are unit, so then I'd have that $cos(\theta) =T\cdot u$ is constant. Then, I was thinking if I showed $\frac{d}{ds}(T\cdot u)=0$, then I could somehow relate that back to curvature. Am I on the right track? Thank you very much for any help!","['curves', 'differential-geometry', 'proof-verification']"
1822588,Existence of solutions of $\Delta u = f$ such that $|u|_{L^\infty} < \infty$ if $|f|_{L^\infty} < \infty$.,"I am struggling with figuring out the details of proposition 7.1. in the paper Curvature and Uniformization - R. Mazzeo and M. Taylor . Setting is as follows. Let $\Omega$ be a noncompact Riemann surface with compatible Riemannian metric $g_0$, and let take a sequence $(\Omega_\nu)_\nu$ of compact, smoothly bounded subsets $\Omega_0 \subset \subset \Omega_1 \subset \subset \ldots$ exhausting $\Omega$ (i.e. for any compact $K \subset\Omega$ there exists $\nu$ such that $K \subset \Omega_\nu$). Let $u_\nu \in C^\infty(\Omega_\nu)$ denote the solution to PDE
  $$\Delta u_\nu = e^{2u_\nu} + k(x) \ \ \ \ \ \ \ \ (\star),$$
  where $k(x)$ is a Gaussian curvature associated to the metric $g_0$.
  ( We get the existence of $u_\nu$ by a results established in preceding sections. They satisfy $u_\nu|_{\partial\Omega_\nu} = +\infty$, and moreover these solutions are monotonically decreasing in a following sense: $\forall \nu \ u_\nu \ge u_{\nu+1}$ on $\Omega_\nu$ ) Proposition 7.1: For every such $\Omega$ one of the following must happen: $u_\nu \searrow u \in C^\infty(\Omega)$, where $u$ satisfies PDE $(\star)$, or $u_\nu \searrow -\infty$ on $\Omega$. Now I will try to go through the proof, and emphasize the parts which I don't understand. By a results from preceding sections we know that the case 1. holds if there exists a function $v : \Omega \to \mathbb{R}$ which is locally bounded such that $\forall \nu$ we have $u_\nu \ge v$. So we'd like to assume that there is no such $v$ and show that it implies that 2. must hold. There is no such $v$ if we can find a sequence $(p_\nu)_\nu \subset \mathcal{O} \subset \subset \Omega_N$ for some open set $\mathcal{O}$ and $N \in \mathbb{N}$, such that $$u_\nu(p_\nu) \to -\infty \ \ \text{as} \ \ \nu \to \infty.$$ From now on let's assume that $\nu \ge N+1$, then we have a following uniform bound (w.r.t. indices $\nu$) on $u_\nu$'s by a monotonicity:
$$u_\nu \le A_N := \sup_{x \in \bar \Omega_N}{u_{N+1}(x)} < \infty \ \ \text{for} \ \ \nu \ge N+1.$$
And similarly we may define a uniform bound
$$|e^{2u_\nu}+k| \le A_{2n} := \sup_{x \in \bar \Omega_N}{|e^{2u_{N+1}(x)}+k(x)|} < \infty \ \ \text{for} \ \ \nu \ge N+1.$$ My question is: now the authors claim that hence we can find $v_\nu \in C^1(\bar \Omega_N)$ for $\nu \ge N + 1$, such that
$$\Delta v_\nu = e^{2u_\nu} + k \ \ \text{on} \ \Omega_N, \ |v_\nu|_{L^\infty(\Omega_N)} \le A_{3N}.$$
How do we know that? Reference to the result implying this will be enough.","['riemannian-geometry', 'partial-differential-equations', 'reference-request', 'complex-analysis', 'laplacian']"
1822611,If $(f_n)\to f$ uniformly and $f_n$ is uniformly continuous for all $n$ then $f$ is uniformly continuous,"Show if is true or false: if $(f_n)$ converges uniformly to $f$, and $f_n$ is uniformly continuous for all $n$ then $f$ is uniformly continuous I think is true. My attempt to prove it: if $(f_n)\to f$ uniformly then we can write $$(\forall\varepsilon>0)(\exists N\in\Bbb N)(\forall x\in\mathcal D):|f_n(x)-f(x)|<\varepsilon,\quad\forall n>N\tag{1}$$ and cause all $f_n$ are uniformly continuous $$(\forall\varepsilon>0)(\exists\delta>0)(\forall x,y\in\mathcal D):|x-y|<\delta\implies|f_n(x)-f_n(y)|<\varepsilon,\quad\forall n\in\Bbb N\tag{2}$$ and I want to prove that both conditions implies $$(\forall\varepsilon>0)(\exists\delta>0)(\forall x,y\in\mathcal D):|x-y|<\delta\implies|f(x)-f(y)|<\varepsilon\tag{3}$$ where $\mathcal D$ is the domain of all of them (cause I have the previous knowledge that uniform convergence of continuous functions implies that the limit function is continuous). Then from $(3)$ I can write $$|f(x)-f(y)|=|f(x)-f_m(x)+f_m(x)-f(y)|\le |f(x)-f_m(x)|+|f_m(x)-f(y)|$$ Then I will use some $m$ that holds $(1)$ for some $\frac{\varepsilon}{3}$. And from $(2)$ I will use the $\delta$ that holds for the same $\frac{\varepsilon}{3}$. If $|f(y)-f_m(y)|<\frac{\varepsilon}{3}$ then $f(y)<f_m(y)+\frac{\varepsilon}{3}$. And then finally I can write: $$\begin{align}|f(x)-f(y)|&\le|f(x)-f_m(x)|+|f_m(x)-f(y)|\\&<\frac{\varepsilon}{3}+|f_m(x)-f_m(y)-\frac{\varepsilon}{3}|\\&<\frac{\varepsilon}{3}+|f_m(x)-f_m(y)|+\frac{\varepsilon}{3}\\&<\frac{\varepsilon}{3}+\frac{\varepsilon}{3}+\frac{\varepsilon}{3}=\varepsilon\end{align}$$ then it proves that exists a $\delta$ such that $|f(x)-f(y)|<\varepsilon$ for some $\varepsilon$ in the required conditions. Now, can you check my proof, telling me if it is right or if it lacks something? Thank you in advance.","['real-analysis', 'proof-verification']"
1822646,Laplace Transform with initial value,"Use the Laplace transform to solve the following initial value
  problem: $$y'' + y = 2t$$ with $y(\pi/4) = \pi / 2 $ and $y'(\pi/4) = 2 - \sqrt{2}$. I understand this type of problems but with initial values for $y(0)$ and $y'(0)$ .. How could I solve it with $y(\pi /4)$ and $y'(\pi /4)$ ?","['ordinary-differential-equations', 'laplace-transform']"
1822665,Why does simplifying a function give it another limit [duplicate],"This question already has answers here : Why does factoring eliminate a hole in the limit? (16 answers) Closed 8 years ago . I'm asked: $$\lim_{x\to 1} \frac{x^3 - 1}{x^2 + 2x -3}$$ This does obviously not evaluate since the denominator equals $0$. The solution is to: $$\lim_{x\to 1} \frac{(x-1)(x^2+x+1)}{(x-1)(x+3)}$$
$$\lim_{x\to 1} \frac{x^2 + x + 1}{x + 3}$$
$$\frac{1+1+1}{1+3} = \frac{3}{4}$$ My question: what is actually happening? How can simplifying a function give it another limit? Is it a complete other function and if so why would it be relevant to our original question?","['indeterminate-forms', 'paradoxes', 'limits']"
1822671,"Computing the matrix of $Tp(x) = p'(x) + x^2 p''(x)$ relative to the basis $\{1, x, x^2\}$","Show that the operator $T \colon P_2(\mathbb{R}) \to P_2(\mathbb{R})$ given by
  $$
  Tp(x) = p'(x) + x^2 p''(x)
$$
  is a linear operator. Compute the matrix $[T]_{B,B}$ of $T$ relative to the standard basis $B = \{1, x, x^2\}$ for $P_2(\mathbb{R})$. So I know that a polynomial in $P_2(\mathbb{R})$ is of the form $ax^2 + bx + c$, and $P'(x) = 2ax + b$, $P''(x) = 2a$. So $Tp(x) = 2ax+b + 2ax^2 = b + 2ax + 2ax^2$. But I am having trouble expressing it in terms of a matrix. Just to make sure I understand it, I have tried the question with a new basis $B=(1,x,x^2+x+\frac{1}{2}$) and I get the matrix: $$
        \begin{pmatrix}
        0 & 1 & 0 \\
        0 & 0 & 0 \\
        0 & 0 & 2 \\
        \end{pmatrix}
$$ Applying the operator $x^2+x+\frac{1}{2}$ gives me $2x^2+2x+1$, which is 2 lots of the basis. Comments: -A linear operator is always unique. -Since the only basis that changed was the last one, that means I can borrow the first 2 columns from my first matrix.","['matrices', 'linear-algebra']"
1822687,Help with a linearly dependent proof on differential equations,"Show that any two solutions $y_1$ and $y_2$ of the equation $y' + p(x)y = 0$
are linearly dependent. How do I prove this question?",['ordinary-differential-equations']
1822732,Prove that a square-integrable entire function is identically zero,"Suppose $f$ is entire and 
  $$\iint_\mathbb{C}|f(z)|^2dxdy < \infty$$Prove that $f\equiv 0.$ So far I have: Suppose $f$ is bounded. Then $f$ is constant by virtue of Liouville and so the conclusion is obvious.  Thus, assume $f$ non-bounded.  Then 
$$\Big|\iint_\mathbb{C}f^2(z)dA\Big| \leq \iint_\mathbb{C}|f(z)|^2dxdy < \infty$$
We can parameterize
\begin{align*} \iint_\mathbb{C}f^2(z)dA &= \int_0^{\infty}\int_0^{2\pi}f^2(re^{i\theta})\;d\theta\;rdr \\
&= \int_0^{\infty}\int_0^{2\pi}f^2(re^{i\theta})\;ire^{i\theta}[-i\frac{1}{r}e^{-i\theta}]d\theta\;rdr \\
&= \int_0^{\infty}\oint_{C_R}f^2(z)\;[-i\frac{1}{z}]dz\;rdr \\
&= \int_0^{\infty}2\pi r dr\frac{1}{2\pi i}\oint_{C_R}\frac{f^2(z)}{z}dz \\ \\
&= 2\pi f^2(0)\int_0^\infty rdr 
\end{align*} Whence f(0) = 0.  And I have no idea where to go from there. The ""entire"" bit seems to suggest Liouville but I have already dealt with the bounded case.  Please advise ...","['complex-analysis', 'contour-integration', 'complex-integration', 'entire-functions']"
1822752,Using Burnside's Lemma in GAP to handle special variations of the Rubik's Cube?,"If you want to count the number of distinct positions of a standard 2x2x2 Rubik's Cube simple counting arguments will suffice: There are 8 corners, all distinct The 8 corners can be in any permutation (because a quarter turn is an odd cycle) The twist of the 8th corner is determined by the twist of the other 7 There are 24 orientations of the cube that must be accounted for $$\frac{8! \cdot 3^7}{24} = 3674160$$ But there is an implicit assumption in this calculation that each counted position occurs 24 times, once for each orientation of the cube.  When this is true the $8! \cdot 3^7$ overcounts by a factor of 24.  Since every corner on a normal 2x2x2 is unique there is no extra symmetry and this assumption is true. But there are variations on a 2x2x2 like the following: On this 2x2x2 there are two identical all-white corners and six identical red and yellow corners along the equator.  The position shown has extra symmetry (e.g. rotating by $120^{\circ}$ through the axis that keeps the white corners stationary). Now if you try to use simple counting arguments you run into trouble:
$$\frac{\frac{8!}{2! \cdot 6!} \cdot 3^6}{24} = \frac{1701}{2}$$ Obviously $\frac{1701}{2}$ can't be right since it isn't even a whole number.  The problem is that with the extra symmetry, Burnside's Lemma must be used.  Thanks to Jaap Scherphuis this isn't too hard to do by hand: 24 rotations are: Identity rotation: All $\frac{8!}{2! \cdot 6!} \cdot 3^6 = 20412$ positions stay the same if you don't rotate it. $\pm 120^{\circ}$ corner rotation: There are $8$ of such rotations. The two white corners must lie on the axis, and the other 6 pieces form two orbits of 3 pieces. The only freedom we have is to orient each orbit, so there are $3^2$ position that stay the same under such a rotation. $\pm 90^{\circ}$ degree face rotation: There are $6$ of these rotations, but there is no position that has this symmetry. We only get 4-cycles, and don't have 4 pieces of each type. $180^{\circ}$ face rotation: There are $3$ of these rotations. The pair of white pieces can be in 4 pairs of locations. The other 6 pieces form 3 pairs that can be oriented at will, so there are $4 \cdot 3^3$ positions with this symmetry. $180^{\circ}$ edge rotation: There are $6$ of these rotations. This is the same as above, $4 \cdot 3^3$ positions with this symmetry. Putting all that together:
$$\frac{(1 \cdot 20412) + (8 \cdot 3^2) + (6 \cdot 0) + (3 \cdot (4 \cdot 3^3)) + (6 \cdot (4 \cdot 3^3))}{24} = 894$$ So there are 894 distinct positions for this 2x2x2 variation (which matches the output of a program I wrote to enumerate them all). But, if you want to use GAP you run into the same problem.  Using the labels in the above image: # Turn U face
TU := (1, 2, 3, 4)(5, 7, 9, 11)(6, 8, 10, 12);
# Rotate whole puzzle around U face
RU := (1, 2, 3, 4)(5, 7, 9, 11)(6, 8, 10, 12)
      (13, 15, 17, 19)(14, 16, 18, 20)(21, 22, 23, 24);
# Rotate whole puzzle around L face
RL := (5, 6, 14, 13)(1, 7, 22, 20)(2, 15, 21, 12)
      (4, 8, 23, 19)(3, 16, 24, 11)(10, 9, 17, 18);

# The whole 2x2x2 cube group
custom222 := Group([TU, RU, RL]);

# The 24 orientations of a 2x2x2
custom222o := Group([RU, RL]);

gap> Size(custom222o);
24

gap> Size(custom222) / 24;
3674160

samecolors := [[1, 5, 12, 16, 17, 23],[3, 7, 10, 14, 19, 21],
               [2, 4, 6, 8, 9, 11, 13, 15, 18, 20, 22, 24]];

gap> (Size(custom222) / Size(Stabilizer(custom222, samecolors, OnTuplesSets))) / 24;
1701/2 Note that the samecolors list identifies which stickers are indistinguishable and the Stabilizer() call finds the group of positions that are all identical.  Unfortunately GAP is running into the same issue as the naive calculation and not taking into account positions that have extra symmetry. I would like to use GAP to apply Burnside's Lemma and get the correct value of 894.  You can see that I defined the custom222 using only 3 generators where the first is a face turn and the other two are $90^{\circ}$ rotations of the whole puzzle about different axes.  It's these rotations that define the 24 orientations of the cube and I suspect I'll have to use another group with just these two orientation generators to guide GAP about the specifics of what positions are considered identical. For example, using the group of the 24 rotations of the cube I can get the number and types of symmetries of the cube which are needed by Burnside's Lemma: gap> List(ConjugacyClasses(custom222o), Size);
[ 1, 6, 3, 8, 6 ] I think this problem is nearly identical to There are 5472730538 essentially different Sudoku grids but I don't see how they used GAP to apply Burnside's Lemma.  It seems to have something to do with ConjugacyClasses() but I don't understand the details. Note that this question isn't really about this specific 2x2x2.  If I can figure out how to use GAP with Burnside's Lemma on this simple 2x2x2 I should be able to handle much more complex puzzles like this one that defy manual applications of Burnside's Lemma. So, how do I use GAP with Burnside's Lemma to analyze variations on the Rubik's Cube like the one I've shown here?","['rubiks-cube', 'gap', 'symmetry', 'combinatorics', 'group-theory']"
1822754,Almost Alternating sequence general formula,"We know that the typical alternating sequence has the term
$$
(-1)^n
$$
to represent a sequence of numbers that change in sign for every term.
Similarly, the 'almost alternating' sequence has the term
$$
(-1)^{n(n+1)/2}
$$
to represent a sequence of numbers that change in sign for every two terms. I was wondering whether there is a general formula for a sequence that alternates sign every $k$ terms. If there isn't a general formula, what is the formula for the ""(-1)"" term for sequences that alternate signs every $3$ and $4$ terms?","['algebra-precalculus', 'sequences-and-series']"
1822757,Find the sets for $f:R \rightarrow R$ given by $f(x) = \left|x\right|$,"Find the sets for $f:R \rightarrow R$ given by $f(x) = \left|x\right|$.  Let $S= [0,4]$ and $T = [-3,0]$. Find the sets: $f(S)$, $f(T)$, $f(S) \cap f(T)$, and $f(S \cap T)$.  Is $f(S) \cap f(T) = f(S \cap T)$? Here is my work: $f(S)=\{x \;|\; x \in \mathbb R,  0 \le x \le 4\}$ $f(T)=\{x \;|\; x \in \mathbb R,  0 \le x \le 3\}$ $f(S) \cap f(T) =\{x \;|\; x \in \mathbb R,  0 \le x \le 3\}$ $f(S \cap T) = \{0\}$ Is $f(S) \cap f(T) = f(S \cap T)$? NO Did I go about this the correct way?","['elementary-set-theory', 'functions']"
1822767,Conjugates and commutators for twisty puzzles -- so what?,"This question isn't just rhetorical. I want to know what I'm missing. Twisty puzzle tutorials keep talking about how useful conjugates (operation sequences of the form ${XYX}^{-1}$) and commutators (${XYX}^{-1}Y^{-1}$) are. I understand the concepts but I just don't see how the concepts are actually useful. Early in a solve, when there's plenty of space to work, I work out simple sequences on the fly like anyone would. They don't really take any brain power, so it's pretty clear these concepts don't help in this case. Later on things get more challenging. I need to think harder to get results. Maybe it would be useful to employ the concepts in this case, but it doesn't turn out that way. Even though the sequences I find often turn out to be conjugates, I'm not thinking ""${XYX}^{-1}$"", I'm just getting stuff out of the way, putting something where I want it, and then putting the stuff back where it was. It's like one person tells you rotating the whole puzzle won't scramble it, and you see the truth of that, then someone else comes along and says the symmetry group of these-and-such rotations is a normal subgroup of yada yada yada. Thanks, but I already got the gist. Let's say you're deliberately inventing a commutator or conjugate. The paradigm doesn't seem to save you any brain power because you still need to visualize what's happening. Just because they're easy to talk about, and due to their structure there are some constraints on their effects, doesn't mean they're easy to devise. You want me to square a 4-digit number in my head? Yeah OK, polynomials, but it's still going to strain my short term memory and be quite prone to error. Finally, let's take a look at some essential sequences for Rubik's Cube provided by Lars Petrus . None of them are conjugates or commutators. (I don't see how to refactor them, anyway.) ( Here is a notation reference.) $${R U R}' {U R U}^2 R' U^2$$
$${L U}' R' {U L}' U' {R U}^2$$
$$F^2 {U L R}' F^2 {R L}' {U F}^2 U^2$$ So sometimes a simple passing sequence happens to be a conjugate; thinking in terms of conjugates and commutators doesn't seem to simplify the harder parts; the most useful sequences seem to ignore the paradigm. So why is this paradigm useful?","['finite-groups', 'rubiks-cube', 'recreational-mathematics', 'group-theory']"
1822769,"How to Axiomize the Notion of ""Continuous Space""?","EDIT (to clear up controversy and misunderstandings caused by my poor wording) : Historically, Riesz's efforts to try and make rigorous a notion of a ""continuous space"" (as opposed to ""discrete ones"") were part of some of the movements in mathematics which lead to the establishment of the axioms of topology. Some people tout topologies as being ""the axiomization of the notion of a continuous space"". However, they are clearly too general, as I argue below. What is an appropriate level of axiomization to make rigorous a notion of ""continuous space""? Why do we allow either discrete or trivial topologies in the definition of topology? (if we want it to define ""continuous spaces"", otherwise there is no issue) More generally, why do we allow points to be open (the existence of isolated points) or the failure of the T0 axiom (existence of topologically indistinguishable points)? (if we want it to define ""continuous spaces"", otherwise there is no issue) Both scenarios could be prevented by addition of the following axioms to the definition of topology: No point is open Every point has a unique neighborhood system This question is a follow-up to my previous question: Why study non-T1 topological spaces? The historical motivation for topology, as far as I have read, was to give a rigorous notion to the intuition of a ""continuous space"". The three axioms commonly used are equivalent to those proposed by Kuratowski, Riesz, and Hausdorff, who were trying to axiomatize ""continuous space"". But discrete spaces are the exact opposite of that, and in general allowing isolated points allows the possibility of spaces with ""discrete components"". It also makes the definition of ""limit"" unnecessarily complicated. The discrete topology is also equivalent to the power set, so is in effect not a new notion. Also every function from a discrete space is continuous, and any definition of a function at an isolated point is continuous, which goes counter to the expectation that the morphisms of a given category should be ""special"" functions. Basically discrete topologies gains us no new insights compared to elementary set theory. Moreover, points not having unique neighborhood systems lead to all sorts of pathologies (for example here: Non-T1 Space: Is the set of limit points closed? ), and even the Zariski topology, which is the most pathological commonly used topology of which I am aware, is still in general $T0$. Finally, any non-$T0$ space should be homeomorphic (I think) to the quotient of the space under the equivalence relation "" $x \sim y$ if and only if $x$ and $y$ are topologically indistinguishable"". This question is similar in spirit to this one , but to me it is very clear why we would want to consider non-metric spaces, at least as someone who is interested non-metricizable spaces like those which can occur in functional analysis. I am aware of the notion of continuum , but since the definition requires the space to be metric, and focuses more on compactness than separation axioms and connectedness rather than path-connectedness, I believe it to be the incorrect axiomization of a ""continuous space"". The existence of indecomposable continua lends credence to this notion, in my view. However, it seems clear to me that the proper axiomization of a ""continuous space"" must lie somewhere in between the notion of ""metric space"" and ""topological space"", as the former is far too restrictive, and the latter far too general. I would enjoy your thoughts on the matter. (I want to better axiomize the notion of ""continuous space"" so as to better facilitate the study of stochastic processes, not that this is directly relevant to the immediate question at hand.) EDIT: At least Riesz appeared to have been clearly interested in defining some notion of ""continuous space"" or ""continuum"" (excerpt from ""History of Topology"" on google books ( https://books.google.com/books?id=7iRijkz0rrUC&pg=PA212&lpg=PA212&dq=riesz+topology+axioms&source=bl&ots=B_xcnG6StL&sig=EajpOCr3XRUtA9hwqpLwArKLmoY&hl=ru&sa=X&ved=0ahUKEwj3pMPs9ZvNAhVBGFIKHcXmB28Q6AEIJzAC#v=onepage&q&f=false ): In a footnote Riesz criticisms the way in which philosophers have dealt with notions like continuous and discrete and he repeats Russell’s remark about the followers of Hegel: «the Hegelian dictum (that everything discrete is also continuous and vice versa) has been tamely repeated by all of his followers. But as to what they meant by continuity and discreteness, they preserved a discrete and continuous silence ; […]» (Riesz [147]). The relation of our subjective experience of space and time and mathematical continua is described by Riesz as follows. Mathematical continua possess certain properties of continuity, coherence and condensation. On the other hand, our subjective experience of time is discrete and consists of countable sequences of moments. Systems of subsets of a mathematical continuum can be interpreted as a physical continuum when subsets with common elements are interpreted as undistinguishable and subsets without common elements as distinguishable. Rise [147, p. 111] is an interesting paper in which Riesz, who had read Frechet’s work and appreciated it, developed a different theory of abstract spaces, based on the notion of «Verdichtungsstelle», i.e. «condensation point», or as we will translate «limit point». In his theory Riesz succeeded in deriving the Bolzano-Weierstrass Theorem and the Heine-Borel Theorem. We will not discuss this paper. We will restrict ourselves to a shorter paper that was presented by Riesz in 1908 at the International Congress of Mathematicians in Rome. In that paper, «Stetigkeit und Abstract Mengenlehre» (Riesz [148]), concentrates on the characterization of mathematical continua. We will briefly describe some of the ideas the Riesz describes in the paper. As we said, Riesz’s basic notion is the notion of a limit point (Verdichtungsstelle). I'm not asking anyone to agree with Riesz's basic goal (to get a rigorous distinction between ""continuous"" and ""discrete"" spaces or time). To those who might object that the standard three axioms are all that are necessary to define the notions of connectedness and compactness, I have several responses: Connectedness actually isn't that nice of a property. We could look at the topologist's sine curve or the infinite broom for examples, but for me the fact that there exists a countable, Hausdorff, and connected set implies that topological connectedness is not quite the intuitive connectedness from Euclidean spaces which we want to generalize for an arbitrary ""continuous space"". In my mind, path connectedness better satisfies this criterion, since every non-trivial T1 path-connected space is uncountable . Path connectedness does provide reasonable properties, although one can object that the definition is somewhat of a tautology (""a space behaves like the real line if it behaves like the real line"") and requires the prior construction of the real line in order to define, rather than being constructible from first principles. Compactness also isn't very nice unless we are in a Hausdorff space, since otherwise compact sets aren't even closed. Sure $T0$ isn't Hausdorff, but it's certainly a step in the right direction. (Hence why the distinction between ""compactness"" and ""quasicompactness"" is so prevalent in algebraic geometry where the non-Hausdorff Zariski topology so frequently comes into play). For non-$T0$ spaces, the set of limit points isn't even closed, limits aren't unique or well-defined... the notion of limit so intrinsic to the idea of a ""continuous space"" clearly requires at least $T0$, if not even $T1$ or $T2$, to function even remotely similarly to intuition. Related but different: Why the axioms for a topological space are those axioms? The definition of metric space,topological space What concept does an open set axiomatise? Why do we require a topological space to be closed under finite intersection? https://xorshammer.com/2011/07/09/a-logical-interpretation-of-some-bits-of-topology/ https://mathoverflow.net/questions/19152/why-is-a-topology-made-up-of-open-sets https://en.wikipedia.org/wiki/Decidability_(logic)#Semidecidability meaning of topology and topological space Motivation behind topology Why is discrete space ``discrete"" Discretizations of Differential, Geometric and Topological Notions Origins of the modern definition of topology","['general-topology', 'math-history', 'soft-question']"
1822774,"For what $m,n$ does the limit exist.","Let $f: (0, \infty) \times (0, \infty) \to [0, \infty)$ by given by $$f(x,y) = \frac{x^ny^m}{x+y}.$$ Find all $m,n$ such that $\lim_{(x,y) \to (0,0)} f(x,y)$ exists. Consider the line $y=kx$ for some $k \in \mathbb{R}$. We observe that \begin{eqnarray*}
\lim_{(x,y) \to (0,0)} \frac{x^ny^m}{x+y} &=& \lim_{(x,kx) \to (0,0)} \frac{x^n(kx)^m}{x+(kx)} \\
&=& \lim_{(x,kx) \to (0,0)} \frac{k^m x^{n+m}}{x(1+k)} \\
&=& \lim_{(x,kx) \to (0,0)} \frac{k^m}{1+k} \cdot x^{n+m-1}.
\end{eqnarray*} This diverges if $n+m-1 < 0$. Also, the limit is dependent on $k$ if $n+m-1=0$. Therefore, we see that $\lim_{(x,y) \to (0,0)} f(x,y)$ exists if $n+m -1 > 0$. My question is regarding sufficiency, sure, my solution is necessary, but it is sufficient to simply take the path $y=kx$?","['real-analysis', 'metric-spaces', 'calculus', 'limits']"
1822788,Proving by induction that the sequence $a_{n+1}=\sqrt{3a_n-1}$ is increasing,"$a_1=1$;  $a_{n+1}=\sqrt{3a_n-1}$  $\quad$    $(n\ge1)$ Now I have to show it is true for $n=1$, which is easy. I have to assume it is true for $n=k$, therefore: $\sqrt{3a_{k}-1}$ $\gt$ $\sqrt{3a_{k-1}-1}$ And I have to show that it is true for $n=k+1$ , so I have to prove: $\sqrt{3a_{k+1}-1}$ $\gt$ $\sqrt{3a_{k}-1}$ Have I set this out correctly? This is the point where I get stuck. From looking at it, it already looks like a very weak induction.","['induction', 'sequences-and-series']"
1822811,"Continuity of $\frac{x^3y^2}{x^4+y^4}$ at $(0,0)$? [duplicate]","This question already has answers here : Multivariable Delta Epsilon Proof $\lim_{(x,y)\to(0,0)}\frac{x^3y^2}{x^4+y^4}$ --- looking for a hint (2 answers) Closed 8 years ago . Suppose a function $f$ is defined as follows: $$f(x,y)=\begin{cases} \frac{x^3y^2}{x^4+y^4}&\text{ when }(x,y)\neq(0,0),\\0 & \text{ when }(x,y)=(0,0).\end{cases}$$ Is this function continuous at $(0,0)$? How is this shown? I've tried considering limits for different $y=g(x)$ functions and I am unable to find a counterexample. But I do not see how to prove continuity in general.","['multivariable-calculus', 'real-analysis', 'continuity']"
1822837,Proving the complete additivity of the Big Omega function $\Omega(n)$ (total number of prime factors of n) .,"The Big Omega function $\Omega(n)$ gives you the total number of prime factors of the number n. A function $f(x)$ is completely additive if $f(ab)=f(a)+f(b)$ for all positive numbers $a$ and $b$, even if they aren't coprime. Wiki states that $\Omega(n)$ is completely additive. How could I go about proving this, if possible,, rigorously? [ https://en.wikipedia.org/wiki/Additive_function#Completely_additive]","['number-theory', 'prime-numbers', 'functions']"
1822854,Finding units in quadratic integer rings,"I want to find the units in $\mathbb{Z}[\alpha]$, where $\alpha=\frac{1+\sqrt{-11}}{2}$. One can of course use norms to find the units in quadratic integer rings of the form $\mathbb{Z}[\sqrt{D}]$ for some squarefree integer $D$. This is my attempt at generalizing this method... Let $r_1,r_2,s_1,s_2\in \mathbb{Z}$ such that 
$(r_1+r_2\alpha)(s_1+s_2\alpha)=1$. Then
$$4 = (2r_1+r_2(2\alpha))(2s_1+s_2(2\alpha))=(2r_1+r_2+r_2\sqrt{-11})(2s_1+s_2+s_2\sqrt{-11}).$$
Taking norms, we have
$$16 = ((2r_1+r_2)^2 + 11r_2^2)((2s_1+s_2)^2 + 11s_2^2) .$$
We can write $16$ as the product of two positive integers in three different ways: $16=4\times 4,8\times 2, 16\times 1$. The latter two factorizations present no solutions while the former presents the trivial solutions $(r_1+r_2\alpha,s_1+s_2\alpha)=(\pm 1, \pm 1)$. The units in $\mathbb{Z}[\alpha]$ are therefore $\pm 1$.","['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
1822875,How to prove the power set of the rationals is uncountable?,"Recently a professor of mine remarked that the rational numbers make an ""incomplete"" field, because not every subsequence of rational numbers tends to another rational number - the easiest example being
$$\lim_{N\to \infty} \sum_{n=1}^N {1 \over n^2} = { \pi ^2 \over 6}$$
He then said that the ""completion"" of the rational numbers is, then, the real numbers $\Bbb{R}$. This led me to think that every real number could be identified with an infinite sequence of rational numbers. And clearly this must be so - the rationals are dense in the reals, so given any arbitrary real number $r$ and rational number $a_0$, there always exists another rational number $a_1$ between $a_0$ and $r$. Infinitely repeated iterations of this process would produce a sequence of rationals $a_n$ which tends to $r$.
This implies then that the set of all possible subsequences of rational numbers (necessarily, the power set of the rationals) must be at least as large as $\Bbb{R}$, thus uncountable. Is this proof valid, or rigorous enough? Or one that is commonly used to show uncountability?","['real-numbers', 'proof-verification', 'proof-writing', 'rational-numbers', 'elementary-set-theory']"
1822890,How many generators needed for Pell-equation-related group,"Let $d$ be a positive integer which is not a perfect square. We have the norm 
multiplicative group homomorphism, $N:{\mathbb Q}[\sqrt{d}] \to {\mathbb Q}$ defined
by $N(x+y\sqrt{d})=x^2-dy^2$. It is well-known that the restricted kernel
$\lbrace z\in {\mathbb Z}[\sqrt{d}] \ \big| \ N(z)=1 \rbrace$ is an ""infinite cyclic""
group, i.e. it is generated by a single element. What about the unrestricted kernel 
$\lbrace z\in {\mathbb Q}[\sqrt{d}] \ \big| \ N(z)=1 \rbrace$ ? Is it also finitely
generated, and if so how many generators are needed to generate it ?","['diophantine-equations', 'group-theory']"
1822894,Calculate $\int_0^{1/10}\sum_{k=0}^9 \frac{1}{\sqrt{1+(x+\frac{k}{10})^2}}dx$,How can we evaluate the following integral: $$\int_0^{1/10}\sum_{k=0}^9 \frac{1}{\sqrt{1+(x+\frac{k}{10})^2}}dx$$ I know basically how to calculate by using the substitution $x=\tan{\theta}$ : $$\int_0^1 \frac{dx}{\sqrt{1+x^2}}$$ But I cannot find out a way to apply the result to the question.,"['trigonometry', 'calculus', 'integration', 'definite-integrals', 'summation']"
1822918,Questions on J. F. Nash's answer about his errors in the proof of embedding theorem,"In the interview of John Nash taken by Christian Skau and Martin Gaussen, in EMS Newsletter, September, 2015 when asked Is it true, as rumours have it, that
  you started to work on the embedding problem as a result
  of a bet? Nash answered I began to work on it. Then I got shifted onto the
  $𝐶^1$ case. It turned out that one could do it in this case
  with very few excess dimensions of the embedding space
  compared with the manifold. I did it with two but then
  Kuiper did it with only one. But he did not do it smoothly,
  which seemed to be the right thing—since you are given
  something smooth, it should have a smooth answer. and But a few years later, I made the generalisation to
  smooth. I published it in a paper with four parts. There
  is an error, I can confess now. Some forty years after the
  paper was published, the logician Robert M. Solovay from
  the University of California sent me a communication
  pointing out the error. I thought: “How could it be?” I
  started to look at it and finally I realized the error in
  that if you want to do a smooth embedding and you have
  an infinite manifold, you divide it up into portions and
  you have embeddings for a certain amount of metric on
  each portion. So you are dividing it up into a number of
  things: smaller, finite manifolds. But what I had done was
  a failure in logic. I had proved that—how can I express
  it?—that points local enough to any point where it was
  spread out and differentiated perfectly if you take points
  close enough to one point; but for two different points
  it could happen that they were mapped onto the same
  point. My question is: 1- What did Nash mean by very few excess dimensions of the embedding space compared with the manifold? It means that the they can do it in the case the dimension of the embedding space is a little bit greater than the dimension of the manifold, doesn't it? 2- What did Nash mean by his generalization to smooth? 3- What did Nash mean by a certain amout of metric on each portion? Does this mean that each portion has some different metrics? 4- What did Nash mean by ""I had proved that that points local enough to any point where it was spread out and differentiated perfectly if you take points close enough to one point""? How can a point spread out and differentiated? Please explain for me. Thanks.","['manifolds', 'riemannian-geometry', 'differential-geometry', 'smooth-manifolds']"
1822932,How to solve this 1st order ODE,"$$ \frac{dy}{dx} = \frac{2x^2 + 3y^2 - 7}{3x^2 + 4y^2 + 8}$$ This does not satisfy the exactness and I can't find any integrating factor to transform it. I can't make it homogeneous too. Thanks in advance for the replies. edit: The question was written incorrectly by the instructor, so in this version there is no analytic solution for it.",['ordinary-differential-equations']
1823024,Prove $\sum\limits_{i=1}^{n}\frac{a_{i}^{2}}{b_{i}} \geq \frac{(\sum\limits_{i=1}^{n}a_i)^2}{\sum\limits_{i=1}^{n}b_i}$,"So I have the following problem, which I'm having trouble solving: Let $a_1$ , $a_2$ , ... , $a_n$ be real numbers. Let $b_1$ , $b_2$ , ... , $b_n$ be positive real numbers. Prove $$ \frac{a_{1}^{2}}{b_{1}} + \frac{a_{2}^{2}}{b_{2}} + \cdot \cdot \cdot +\frac{a_{n}^{2}}{b_{n}} \geq \frac{(a_{1}+a_{2}+\cdot \cdot \cdot+a_{n})^2}{b_{1}+b_{2}+\cdot \cdot \cdot+b_{n}} $$ I was thinking that I somehow could use the Cauchy–Schwarz inequality, but with no success. Any help would be very appreciated","['algebra-precalculus', 'inequality']"
1823051,Solve $z^5 +32 =0$,"Solve $z^5 +32 =0$ My attempt : $$z^5 = -32$$
            Multiply the powers on both sides by $\frac{1}{5}$ we get $$z = 2 * (-1)^\frac{1}{5}$$ Now I'm stuck at this step I don't know how to proceed. Kindly help.","['algebra-precalculus', 'complex-numbers']"
1823095,Prove triangle similiarity by given expression,"I am working on the following problem, but I can't seem to figure it out. The length of the sides in the triangle $T_1$ are $a_1$, $b_1$ and $c_1$. The length of the sides in the triangle $T_2$ are $a_2$, $b_2$ and $c_2$. Moreover: $$\sqrt{a_1 a_2} + \sqrt{b_1 b_2} + \sqrt{c_1 c_2} = \sqrt{(a_1 + b_1 +c_1)(a_2 + b_2 +c_2)}.$$ Show that the triangles are similar. Any help would be appreciated","['euclidean-geometry', 'triangles', 'geometry']"
1823096,Limit of the solutions of a trigonometric equation,"Consider the equation \begin{equation}
2\cos(\sqrt{\lambda} \pi) \sin(\sqrt{\lambda} \frac{\pi}{n}) + \sin(\sqrt{\lambda} \pi) \cos(\sqrt{\lambda} \frac{\pi}{n})=0
\end{equation} for $n \in \mathbb{N}$. This came up when solving an eigenvalue equation. I want to show the existence of a unique solution $\lambda (n) \in (0,1)$ which satisfies $\lambda (n) \rightarrow 1$ as $n \rightarrow \infty$. Intuitively the solution, if existent, should have this property since the first part of the sum approaches $\sin(\sqrt{\lambda} \pi)$ and the second part approaches $0$ as $n \rightarrow \infty$. However, I don't see how to prove this. Bonus question: What if 2 is replaced by an arbitrary $k \in \mathbb{N}$. Do the solutions, if existent, still converge to $1$? Edit: I'm sorry to break the symmetry, but I forgot a factor in the first part of the sum.","['trigonometry', 'limits']"
1823122,reciprocal factor of absolute value when evaluating a square root expression,"Learning with an old russian math book, i found the following evaluation for the function $f(x)=\sqrt{1+x^2}$: $f(\frac1x)=\vert x \vert^{-1}\sqrt{1+x^2}$ My evaluation gave me $\sqrt{1+\dfrac1{x^2}}$ Are these two statements algebraically equivalent? I don't see the connection to the absolute values here. Any help is appreciated.","['absolute-value', 'functions']"
1823137,Prove $\int_{0}^{\infty}{1\over (1+{\phi^{-2}}x^2)(1+{\phi^{-4}}x^2)}dx={\pi\over 2}$,"Prove $\phi$; golden ratio $$I=\int_{0}^{\infty}{1\over (1+{\phi^{-2}}x^2)(1+{\phi^{-4}}x^2)}dx={\pi\over 2}\tag1$$ Let $q=\phi^{-2}$ and $p=\phi^{-4}$ $${1\over (1+qx^2)(1+px^2)}={Ax+B\over 1+qx^2}+{Cx+D\over 1+px^2}\tag2$$ Result $A=0$, $B=\phi$, $C=0$ and $D=-{1\over  \phi}$ Sub the result into $(2)$ and we got $${1\over (1+\phi^{-2}x^2)(1+\phi^{-4}x^2)}={\phi\over 1+\phi^{-2}x^2}-{\phi^{-1}\over 1+\phi^{-4}x^2}$$ Hence $$I=\int_{0}^{\infty}\left({\phi\over 1+\phi^{-2}x^2}-{\phi^{-1}\over 1+\phi^{-4}x^2}\right)dx\tag3$$ Simplified $(3)\rightarrow (4)$ $$I=\phi^3\int_{0}^{\infty}{1\over \phi^2+x^2}dx-\phi^3\int_{0}^{\infty}{1\over \phi^4+x^2}dx\tag4$$ Recall $$\int_{0}^{\infty}{1\over a^2+x^2}dx={\pi \over 2a}\tag5$$ Utilise $(5)$ to brings $(4)$ to $(6)$ $$I=\phi^3\cdot{\pi\over 2\phi}-\phi^3{\pi\over 2\phi^2}\tag6$$ $$I={\pi\over 2}(\phi^2-\phi)={\pi\over 2}\tag7$$ This method it is a bit tedious, can someone tackle integral (1) with a quicker method?","['integration', 'definite-integrals', 'calculus']"
1823140,"Show that sequence (1,1,2,2,3,3,…k,k) is graphic for every k ∈ N","Hi there I need to show that the sequence $s(n) = \{1,1,2,2,3,3,4,4,...,n,n\}$ can be the degrees of the vertices of a simple graph, $\forall n\geq 1$.
So far I have tryied to prove this by induction using the Havel-Hakimi theorem. $s(1) = {1,1}$ And by applying the HH algorithm we see that $s(1)$ hold. The same for $s(2)$ but I don't know how to do it for the $s(n)$ case. Another way I was thinkig of was by using the Erdös- Gallai theorem. It is simple to prove that the sum of $s(n)$ is even but I don't know how to prove the second condition: $\sum_{i=1}^{k}d_i \leq k(k-1)+\sum_{i=k+1}^{n}\min(d_i,k)$","['combinatorics', 'graph-theory']"
1823149,"Prob. 4, Sec. 4.3, in Kreyszig's Functional Analysis textbook: Application of the Hahn Banach Theorem","Here is Prob. 4, Sec. 4.3, in the book Introductory Functional Analysis With Applications by Erwine Kreyszig: Let $X$ be a (real or complex) vector space, and let $p \colon X \longrightarrow \mathbb{R}$ be a real-valued function satisfying $$p(x+y) \leq p(x) + p(y) \ \mbox{ for all } \ x, y \in X$$ and $$p(\alpha x) = \lvert \alpha \rvert p(x) \ \mbox{ for all } x \in X \mbox{ and for all scalars } \alpha.$$ Let $x_0$ be a point of $X$ . Then (how to show that?) there is a linear functional $\tilde{f}$ on $X$ such that $\tilde{f}(x_0) = p(x_0)$ and $\left\lvert \tilde{f}(x) \right\rvert \leq p(x)$ for all $x \in X$ . First of all, here is the (generalized) Hahn Banach Theorem for (real or complex) vector spaces. Let $X$ be a real or complex vector space; let $Z$ be a subspace of $X$ ; let $p \colon X \longrightarrow \mathbb{R}$ satisfy $$p(x+y) \leq p(x) + p(y) \ \mbox{ for all } x, y \in X$$ and $$p(\alpha x ) = \lvert \alpha \rvert p(x) \ \mbox{ for all } x \in X \mbox{ and for all scalars } \alpha;$$ and let $f$ be a linear functional defined on $Z$ such that $$\lvert f(x) \rvert \leq p(x) \ \mbox{ for all }  x \in Z.$$ Then there is a linear functional $\tilde{f}$ defined on all of $X$ such that $$\tilde{f}(x) = f(x) \ \mbox{ for all } x \in Z$$ and $$\left\lvert \tilde{f}(x) \right\rvert \leq p(x) \ \mbox{ for all } x \in X.$$ This is Theorem 4.3-1 in the book Introductory Functional Analysis With Applications by Erwine Kreyszig. My effort: Let $Z$ be the subspace of $X$ spanned by $x_0$ , and let the functional $f$ be defined on $Z$ by $$f(\alpha x_0) = \alpha p(x_0) \mbox{ for all scalars } \alpha .$$ We can show that $p(x) \geq 0$ for all $x \in X$ , and $f$ satisfies all the conditions in the hypothesis of the above theorem. So there is a linear functional $\tilde{f}$ on $X$ such that $\tilde{f}(x) = f(x)$ for all $x \in Z$ and $\left\lvert \tilde{f}(x) \right\rvert \leq p(x)$ for all $x \in X$ . Thus, $\tilde{f}(\alpha x_0) = \alpha p(x_0)$ for all scalars $\alpha$ and hence $\tilde{f}(x_0) = p(x_0)$ . Is this proof correct and clear enough in each and every detail? Or, are there any issues therein of accuracy or clarity?","['real-analysis', 'normed-spaces', 'functional-analysis', 'analysis', 'solution-verification']"
1823157,If a limit is finite does it have to be of the form $0/0$?,In my text book it is written that if $$\lim_{x\to0}\;\frac{\cos(4x) + a\cos(2x) + b}{x^4}$$ is finite then  $\frac{\cos(4x) + a\cos(2x) + b}{x^4}$ should be of the form $0/0$ and therefore $\cos4x + a\cos2x + b$ must be zero at $x=0$. I do not understand why. Please explain this to me.,"['real-analysis', 'convergence-divergence', 'calculus', 'limits']"
1823175,Necessary and sufficient condition for uniform convergence.,"Let $a_n$ and $b_n$ be real sequences and let $f_n(x) = a_nx + b_nx^2$ be a sequence of polynomials. What should be the necessary and sufficient conditions on the sequences $a_n$ and $b_n$ so that the $f_n$ converges uniformly to $f(x) = 0$ on $\mathbb{R}$ ? I have some conclusions: Since the convergence is unform, $\lim_{n\rightarrow \infty}f_n(1) = \lim (a_n + b_n) = 0$. Similarly, for $x = -1$, we have $\lim(-a_n + b_n) = 0$. Adding, we get $\lim{b_n} = 0$, and so we also have $\lim a_n = 0$. But these conditions are not sufficient.","['real-analysis', 'sequences-and-series', 'uniform-convergence', 'limits']"
1823180,How to prove that there exists $\lambda_{\sigma(1)}$ such that $\mu(A\cap\{\lambda_{\sigma(1)}\neq0\})>0$?,"Let $(\mathcal F,\Omega,\mu)$ be a measure space and $A\subseteq\Omega$ such that $\mu(A)>0$. Let $L^0$ be the space of all measurable functions. We say $X_1,\ldots,X_k\in(L^0)^d=\prod_{k=1}^dL^0$ are linearly independent on $A$ if $(0,\ldots,0)$ is the only vector $(\lambda_1,\ldots,\lambda_k)\in1_A(L^0)^d$ satisfying
$$\lambda_1X_1+\ldots+\lambda_kX_k=0$$
Suppose $X_1,\ldots,X_k\in(L^0)^d$ are linearly independent on $A$ and
$$\text{span}_A\{X_1,\ldots,X_k\}\subseteq\text{span}_A\{Y_1,\ldots,Y_l\}$$
for some $Y_1,\ldots,Y_l\in(L^0)^d$. I'm  trying to prove that there exists a $\sigma(1)\in\{1,\ldots,l\}$ such that 
$$\mu(A\cap\{\lambda_{\sigma(1)}\neq0\})>0$$
I tried to conclude this from the fact we can write
$$1_AX_1=\sum_{i=1}^l\lambda_i1_AY_i$$
while couldn't arrive to any result, Can somebody help me, please?","['real-analysis', 'probability-theory', 'measure-theory', 'conditional-expectation', 'linear-algebra']"
1823185,"Find a continuous function $f:[1,\infty)\to\Bbb R $ such that $f(x) >0 $, $\int_1^\infty f(x)\,dx $ converges and $\int_1^\infty f(x)^2\,dx$ diverges","I'm trying to find an example of a continuous function $f:[1,\infty) \to \Bbb R $ such that 
$$f(x) >0 $$ $$\int_{1}^{\infty} f(x) \ dx \ \text{converges and } \int_{1} ^{\infty} f(x)^2 dx \ \text{diverges}.$$","['examples-counterexamples', 'integration', 'calculus']"
1823214,Are there any constructive axioms which disprove the continuum hypothesis?,"I understand that the Continuum hypothesis is independent of ZFC, so that we may comfortably add either the continuum hypothesis or its negation to ZFC without creating any paradoxes (unless ZFC had them to begin with), and in fact there are several large Cardinal axioms that are inconsistent with CH. My question is this: are there any proposed additions to ZFC which not only imply the negation of CH, but in fact allow for the explicit construction of a set with cardinality between $\mathbb{N}$ and $\mathbb{R}$? If not, could such axioms be lurking about? Do we have any idea what such sets may ""look"" like? I know that there are quite a few questions on CH lying about on this site, so if I missed a duplicate of this question I'd appreciate being directed to it as much as an answer.","['large-cardinals', 'cardinals', 'elementary-set-theory']"
1823237,Evalute the value of limit,"$$
\lim_{x\to 0}\frac{(1+\sin x)^{\operatorname{cosec}x} - e + \left(\dfrac{\sin x}{2}\right)e}{\sin^2x}
$$ I am stucked here , please tell me how to proceed further and Is there any way to solve this problem",['limits']
1823244,Intuitive proof of $\sum_{k=1}^{n} \binom{n}{k} k^{k-1} (n-k)^{n-k} = n^n$,"Is there an intuitive way, though I am not sure how to find a conceptual proof either, to establish the following identity:
$$\sum_{k=1}^{n} \binom{n}{k} k^{k-1} (n-k)^{n-k} = n^n$$
for all natural numbers. I am thinking about binomial formula
$$\sum_{k=0}^n\binom nk x^{n-k}y^k=(x+y)^n$$
but I'm not sure how to use it. I find this problem tantalizing because it looks as if there should be some sort of intuitive way so that is why I share it here. I am looking for an answer like my question before if possible. Can you find one?","['binomial-theorem', 'binomial-coefficients', 'algebra-precalculus', 'recreational-mathematics', 'summation']"
1823311,Limit of integral with measure with parameter $\alpha$,"Suppose $\mu$ is a positive masure on $X$, $f:X\to [0,\infty]$ is measurable, $\int \limits_{X}fd\mu=c$, where $0<c<\infty,$ and $\alpha$ is a constant. Prove that $$\lim \limits_{n\to \infty}\int \limits_{X}n\log [1+(f/n)^{\alpha}]d\mu=
\begin{cases}
\infty,  & \text{if} \quad0<\alpha<1, \\
c,  & \text{if} \quad\alpha=1, \\
0, & \text{if} \quad 1<\alpha<\infty.
\end{cases}$$ Remark: $[\cdot]$ is not integer part! Proof: $\color{blue}{Case \quad \alpha=1}$.
Consider functions $f_n(x):X\to [0,\infty]$ defined by $f_n(x)=n\log \left[1+\dfrac{f(x)}{n}\right]$. It's easy to check  that $0\leqslant f_1\leqslant f_2\leqslant \dots \leqslant f$ on $X-S$ where $S=\{x\in X:f(x)=\infty\}$ and note that $\mu(S)=0$ (otherwise $\int \limits_{X}fd\mu=\infty$ which is contradiction). Also $f_n$ is measurable for each $n$ since it's a compostion of continuous and measurable functions. Using Monotone Convergence Theorem we get: $$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}\lim \limits_{n\to \infty}f_nd\mu=\int \limits_{X}fd\mu=c.$$ $\color{blue}{Case \quad 0<\alpha<1}$. Using Fatou's lemma to functions $f_n=n\log[1+(f/n)^{\alpha}]$ which is measurable in $X-S$ for each $n$ we get the following inequality: $$\liminf \limits_{n\to \infty} \int \limits_{X}f_nd\mu\geqslant  \int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu$$ Since $\int \limits_{X}fd \mu=\int \limits_{X\setminus S}fd \mu=c$ then the set $E=\{x\in X-S: f(x)>0\}$ has positive measure. 
And $$\int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu=\int \limits_{X\setminus S}\liminf \limits_{n\to \infty} f_nd\mu=\int \limits_{E}+\int \limits_{(X\setminus S)\setminus E}=$$ Since on $(X\setminus S)\setminus E$ we have that $f_n(x)=0$
$$=\int \limits_{E}\liminf \limits_{n\to \infty} f_nd\mu=+\infty$$ since $\liminf \limits_{n\to \infty} f_n=+\infty$ on $E$ and $\mu(E)>0.$ $\color{blue}{Case \quad \alpha>1}$. Our functions $f_n$ are measurable and non-negative on $X-S$ and $f_n(x)\to 0$ as $n\to \infty$ on $X-S$. Using derivative test we can show that $f_n\leqslant \alpha f$ for $n\in \mathbb{N}$ on $X-S$. Note that $\alpha f\in L^1(\mu)$. By Dominated Convergence theorem $$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}\lim \limits_{n\to \infty}f_nd\mu=0.$$ Here we use that $\mu(S)=0$ because the measure of zero set in negligible in integration. Sorry if this topic is repeated but I would be thankful if anyone checks out my solution.","['real-analysis', 'measure-theory']"
1823316,"Prove that if $\lim _{x\to \infty } f(x)$ exists ,then $\lim_{x\to \infty} f(x)=0$","Let $f:\Bbb R\to \Bbb R$ be a continuous function such that $\int _0^\infty f(x)\text{dx}$ exists. Prove that If $\lim _{x\to \infty }  f(x)$ exists, then $\lim_{x\to \infty} f(x)=0$ If $f$ is non-negative then $\lim _{x\to \infty }  f(x)$ must exist and $\lim_{x\to \infty} f(x)=0$ My try To prove that $\lim_{x\to \infty} f(x)=0$ we should show that $\exists G>0$ such that $x>G\implies |f(x)|<\epsilon $ for any $\epsilon>0$ But I can't find out how to show this.
Please help.","['continuity', 'real-analysis', 'limits']"
1823337,Derivation of Shell Method,"I recently saw a 'derivation' of the shell method of integration for volumes in a book that went like this: To find the element of volume contained in a shell of inner radius $r = x$ and out radius $R = x + \Delta x$ , length $y$ , we have: $$\begin{align*}\Delta V &= \pi(R^2-r^2)y\\ &=\pi y(x^2+2x\Delta x + \Delta x^2 - x^2)\\&=2\pi xy\Delta x + \pi y\Delta x^2\end{align*}$$ As $\Delta x$ is very small, $(\Delta x)^2$ is negligible, hence $$\Delta V = 2\pi xy\Delta x\\\therefore V = 2\pi \int_a^bxy\,dx $$ I completely understand this, but I'm unsatisfied with the reasoning that $\Delta x^2$ is negligible. Formally, why are we allowed to ignore the $\Delta x^2$ term?","['volume', 'integration']"
1823348,Give an example of a non-Lebesgue measurable function $f:\mathbb R \to \mathbb R $ such that $|f|$ is a measurable function and ...,Give an example of a non-Lebesgue measurable function $f:\mathbb R \to \mathbb R $ such that $|f|$ is a measurable function and $f^{-1}(\{a\})$ is a measurable set for each $a \in \mathbb R$. Can anyone please help show me how I can construct such an example?,['measure-theory']
1823368,integral inequality for $f(x)$ and $f(\sqrt{x})$,"Show that if $f(x)\in [0;1]$, $f\in C$ and $\int\limits_{1}^{+\infty}f(t)dt=A$ then $\int\limits_{1}^{+\infty}tf(t)dt>\frac{A^2}{2}$ I only have noticed two small things: If $A=1$ inequality is obvious, as expectation of random variable, that takes values greater than $1$ $\int\limits_{1}^{+\infty}tf(t)dt = \dfrac{1}{2}\int\limits_{1}^{+\infty}f(\sqrt{t})dt$ Please, provide hint for next steps Also, some time left I obtain: $$
A^2 = \left[\int\limits_{1}^{+\infty}f(x)x\dfrac{1}{x}dx\right]^2 \leq
\int\limits_{1}^{+\infty}\left(f(x)x\right)^2dx\int\limits_{1}^{+\infty}\left(\frac{1}{x}\right)^2dx\leq \int\limits_{1}^{+\infty}f(x)x^2dx
$$","['real-analysis', 'improper-integrals', 'integral-inequality']"
1823399,Geometric mean of random geometric variables converging with probability to a constant,"I have the following question at hand.. Let $X_1,X_2,\cdots, X_n$ be a sequence of iid random variables with common uniform distribution on $[0,1]$. Define $$Z_n=\left(\prod_{\ i=1}^{\ n}X_i \right)^{1/n}$$ be the geometric mean of $X_1,X_2,\cdots, X_n$. Show $Z_n \xrightarrow {P} c$ where $c$ is a constant. I first found out the joint $pdf$ $f_{X_1,X_2,\cdots, X_n}$.Then I substituted $X_1$ by the $Z_n$ to find out the joint $pdf$ $f_{Z_n,X_2,\cdots, X_n}$(by calculating the jacobian and applying things). It came out to be a good looking one(I dont know whether I am right or wrong..Please help) $${n\over x_2\cdots x_n}z_n^{n-1}$$ Here the problem lies. I thought I would integrate out $X_2,\cdots, X_n$ and get the $pdf $ of $Z_n$ but on integrating this it turns out $-\infty$. Where am I going wrong? Is there some better process?","['probability-theory', 'convergence-divergence', 'probability-distributions']"
1823418,Show that the Lie Algebra of $O(n)$ is the set of $n \times n$ skew-symmetric matrices,"I'm trying to show that the Lie Algebra for $O(n)$ is the set of $n \times n$ skew-symmetric matrices. Here is what I have so far. Since $O(n)$ is the union of two disjoint subsets, the matrices with determinant of $1$ ($SO(n)$) and determinant $-1$, then the Lie Algebra of $O(n)$ is the same as the Lie Algebra for $SO(n)$ because of course, $I \in SO(n)$. I'll denote the set of skew-symmetric matrices by $Sk(n)$ (is there a convention for denoting this set?) and the Lie Algebra of $O(n)$ with $\mathfrak{so}(n)$. A skew-symmetric matrix is such that $-M = M^\top$. Then $\exp(-M) = [\exp(M)]^{-1}$. So then, $\exp(M^\top) = [\exp(M)]^{-1}$. But the LHS equals $[\exp(M)]^\top$. Thus, $\exp(m) [\exp(M)]^\top = I$ which implies that $\exp(M) \in O(n)$. Consider $A \in Sk(n)$. We know that $\exp(A) \in O(n)$. In fact, it is not hard to show that $\exp(tA) \in O(n)$ as well. Consider the curve $\alpha(t) = \exp(tA)$. Now, $\alpha(0) = I$, $\alpha'(t) = A \exp(tA)$, and $\alpha'(0) = A$. So we've shown that $Sk(n) \subseteq \mathfrak{so}(n)$. However, I'm having trouble showing the other direction: $\mathfrak{so}(n) \subseteq SK(n)$. I don't think this direction should require much theory beyond the definitions. Hints are very welcome. Thank you.","['differential-geometry', 'lie-algebras', 'lie-groups']"
1823443,How can I find an explicit expression for this recursively defined sequence?,"We define the sequence $(u_n)_{n=1}^\infty$by:$$u_{n+1}=1+\frac{1}{u_n}$$
How can I find the limit of this sequence as it goes to infinity? By induction, I can prove that it is bounded above and below. I have also proved that $$u_{n+2}-u_n=\frac {u_n-u_{n-2}}{(1+u_n)(1+u_{n-2})}$$
Therefore, I can show that $\lim_{n\to\infty} u_{2n}$ and $\lim_{n\to\infty} u_{2n+1}$ exist. However, I am unable to find the limits themselves or a an explicit formula. How does one go around doing this? Are there any standard methods?","['recurrence-relations', 'sequences-and-series']"
1823459,Prove ${2\over \pi}\int_{0}^{\infty}\prod_{k=1}^{n\ge1}{k^2\over k^2+x^2}dx={n\over 2n-1}$,"Prove $$I={2\over \pi}\int_{0}^{\infty}\prod_{k=1}^{n\ge1}{k^2\over k^2+x^2}dx={n\over 2n-1}\tag1$$ Expand out $(1)$ $$I={2n!\over \pi}\int_{0}^{\infty}{1\over (1+x^2)(2^2+x^2)(3^2+x^2)\cdots(n^2+x^2)}dx\tag2$$ Noticing $${1\over (1+x^2)(4+x^2)}={1\over 3}\left({1\over 1+x^2}-{1\over 4+x^2}\right)$$ $${1\over (1+x^2)(4+x^2)(9+x^2)}={1\over 2x^2-12x+30}\left({1\over 1+x^2}-{2\over 4+x^2}+{1\over 9+x^2}\right)$$ $${1\over (1+x^2)(4+x^2)(9+x^2)(16+x^2)}={1\over -60x^2+300}\left({1\over 1+x^2}-{3\over 4+x^2}+{3\over 9+x^2}-{1\over 16+x^2)}\right)$$
and so on..., k is a polynomial function of x, we have (I just realised that if k is a function of x, then what follow from (3) are all wrong!) $${1\over (1+x^2)(2^2+x^2)\cdots(n^2+x^2)}=k\left({{n-1\choose 0}\over 1+x^2}-{{n-1\choose 1}\over 2^2+x^2}+{{n-1\choose 2}\over 3^2+x^2}-\cdots{{n-1\choose n-1}\over n^2+x^2}\right)\tag3$$ Recall $$\int_{0}^{\infty}{1\over a^2+x^2}dx={\pi\over 2a}\tag4$$ Sub $(3)$ into $(2)$ and applying $(4)$ hence we have $$I={2n!k\over \pi}\cdot{\pi\over 2}\left[{{n-1\choose 0}\over 1}-{{n-1\choose 1}\over 2}+{{n-1\choose 2}\over 3}-\cdots-{{n-1\choose n-1}\over n}\right]\tag5$$ $$I={n!k}\left[{{n-1\choose 0}\over 1}-{{n-1\choose 1}\over 2}+{{n-1\choose 2}\over 3}-\cdots-{{n-1\choose n-1}\over n}\right]\tag6$$ How can we get from $(6)$ to $I={n\over 2n-1}$? Can anyone produce another method less lengthy than this method above to tackle Integral (1)? I have saw some authors using the residue theorem to tackle another simple case like the above (1) but I don't know how to apply it.","['integration', 'definite-integrals', 'calculus']"
1823466,Is there an elegant way to evaluate $ I={ \int \sqrt[8]{\frac{x+1}{x}} \ \mathrm{d}x}$?,"Is there an elegant way to evaluate the following integral? $$ I={ \int \sqrt[8]{\dfrac{x+1}{x}} \ \mathrm{d}x}$$ This seems to me a very lengthy question, yet it was given in my weekly worksheet, so there must be an elegant solution. Any help will be appreciated.","['indefinite-integrals', 'integration', 'calculus']"
1823470,"If $(X, \mathcal{T})$ has a countable subbasis, then it has a countable basis","Given $(X, \mathcal{T})$ a topological space. Let $\mathcal{S}$ be a subbasis on $(X, \mathcal{T})$ Claim: If $\mathcal{S}$ is countable, then $\mathcal{T}$ has a
  countable basis $\mathcal{B}$ I am not sure how to go about approaching this quetion but here's my attempt: I want to show that there exists a surjection $g$ from $\mathcal{S}$ to $\mathcal{B}$, and there is an injection $f$ from $\mathcal{B}$ and $\mathcal{S}$ thus $|\mathcal{S}| = \aleph_0 = |\mathcal{B}|$ Define $g$ as 
$$g(S_1, S_2, \ldots, S_n) = S_1 \cap S_2 \cap \ldots \cap S_n = B$$ where $S_1, \ldots, S_n \in \mathcal{S}$, and $B \in \mathcal{B}$ But how does the countability of $\mathcal{S}$ come in? I'm really lost Per Henno's suggestion re-attempt: Let $\mathcal{S}$ be a countable subbase of $(X, \mathcal{T})$. Then
$\mathcal{S}$ can be listed as $\{S_1, S_2, \ldots \}, S_i \in S, i
   \in \mathbb{N}$ By definition, each basis element is the finite intersection of
subbasic elements written as $\bigcap\limits_{i \in F_n} S_i$, where
$F_n$ is a finite set in $\mathbb{N}$. Since there exists countably many finite sets in $\mathbb{N}$, we can
list all the finite sets as $\{F_1, F_2, \ldots\}$ Then correspondingly we can list all the basis elements as:$\{\bigcap\limits_{i \in F_1} S_i, \bigcap\limits_{i \in F_2} S_i,
   \ldots\}$ which is a countable set. Hence $\mathcal{B}$ is countable.","['general-topology', 'second-countable', 'cardinals', 'proof-verification']"
1823486,$A = \sum_{n=0}^\infty a_n$ and $b_n \to B$ implies $\sum_{k=0}^n a_k b_{n-k} \to AB$,"This question is motivated by the answer With $y_n$ a sequence of real numbers, prove that if $y_n=x_{n-1}+2x_{n}$ converges then $x_n$ also converges ,
where essentially the following fact is used: Let $A = \sum_{n=0}^\infty a_n$ be an absolutely convergent series,
  and $(b_n)$ a convergent sequence, $b_n \to B$.
   Then
  $$
 \lim_{n \to \infty} \sum_{k=0}^n a_k b_{n-k} = A B \, . 
$$ This is not too difficult to prove (sketch): Write
$$
 \sum_{k=0}^n a_k b_{n-k} = B \sum_{k=0}^n a_k +
 \sum_{k=0}^n a_k \bigl( b_{n-k} - B \bigr) 
$$
The first sum converges to $AB$. For $\varepsilon > 0$, split the second sum into two parts
$$
 \sum_{k=0}^{n-N} a_k \bigl( b_{n-k} - B \bigr) + \sum_{k=n-N+1}^n a_k \bigl( b_{n-k} - B \bigr) \\
=  \sum_{k=0}^{n-N} a_k \bigl( b_{n-k} - B \bigr) + \sum_{j=0}^{N-1} a_{n-j} \bigl( b_j - B \bigr) 
$$
where $N$ is chosen such that $\lvert b_n - B \rvert < \varepsilon$
for $n \ge N$. The first part can be estimated by $\varepsilon
\sum_{n=0}^\infty |a_n|$, and the second (finite) sum converges to zero. Now I am fairly sure that this is not new and must have been done before.
However, I could  not find a reference. So my question is: Is there a name for the above statement, or
is there some ""well-known theorem"" for which this is just a special case? The term $  \sum_{k=0}^n a_k  b_{n-k}$ reminds me of the Cauchy product,
but nothing is given about $\sum b_n$ here. Or is it perhaps 
related to summation methods for series? (Or is it so trivial that everybody just knows it?)","['alternative-proof', 'reference-request', 'cauchy-product', 'sequences-and-series']"
1823520,"Is there a mathematical property which could help ""sum up"" information from certain matrix areas?","I have a matrix $$A=
\begin{pmatrix}
2 & -1 & 4 \\
-3 & 8 & -5\\
12 & -7 & 16
\end{pmatrix}
$$ and I would like to create the matrix $$B=
\begin{pmatrix}
6 & 5 & 6 \\
11 & 26 & 15\\
10 & 21 & 12
\end{pmatrix}
$$ where each entry of B is the sum of its surrounding cells in $A$. So the first entry of $B$ is $2-1-3+8=6$. The $3\times 3$ matrix and the summing ""radius"" are a simplification, the question aims at $m \times n$ matrices along with arbitrary rectangular areas to be measured. Is there some mathematical property which could help avoid having to implement something along the lines of
$$b_{kl}=\sum_{l-a}^{l+b}\sum_{k-c}^{k+d}a_{kl} ~~~\text{given that the entries exist}$$
? Special case: would things be easier if the entries only consisted of a fixed amount of $0$ and $1$?","['matrices', 'programming']"
1823553,How to find $\lim_{n \to \infty} \int_0^1 \cdots \int_0^1 \sqrt{x_1+\sqrt{x_2+\sqrt{\dots+\sqrt{x_n}}}}dx_1 dx_2\dots dx_n$,"Here I mean the limit of the following sequence: $$p_1=\int_0^1 \sqrt{x} ~dx=\frac{2}{3}$$ $$p_2=\int_0^1 \int_0^1 \sqrt{x+\sqrt{y}} ~dxdy=\frac{8}{35}(4 \sqrt{2}-1) =  1.06442\dots$$ $$p_3=\int_0^1 \int_0^1 \int_0^1 \sqrt{x+\sqrt{y+\sqrt{z}}} ~dxdydz =  1.242896586866\dots$$ $$p_4 \approx 1.314437693607766$$ $$p_5 \approx  1.34186271753784$$ Here the approximate values are computed by Mathematica . In principle every one of these integrals can be evaluated in closed form, but it becomes very complicated (see $p_3$ at the bottom of the post). How can we find the limit at $n \to \infty$? It should be finite because of the range of variables chosen. $$\lim_{n \to \infty}p_n=\lim_{n \to \infty} \int_0^1 \cdots \int_0^1 \sqrt{x_1+\sqrt{x_2+\sqrt{\dots+\sqrt{x_n}}}}dx_1 dx_2\dots dx_n=?$$ I find it very likely that $\lim_{n \to \infty}p_n=\phi$ (the Golden Ratio), but I'm not sure (this is not correct, see the comments). Edit : With the help of Wolfram Alpha I tackled $p_3$ (see the updated numerical value above): $$p_3=\frac{64}{135135} (2 \sqrt{3244081+2294881 \sqrt{2}}-664\sqrt{2}-1092\cdot 2^{3/4}+305)$$ This confirms my suspicions that there is no hope for apparent pattern in the first few $p_k$. Now an interesting challenge is to see how many $p_k$ can be realistically computed in closed form.","['golden-ratio', 'limits', 'integration', 'definite-integrals', 'nested-radicals']"
1823594,Decomposition of Harmonic function into sum of holomorphic and anti-holomorphic function,"How do you prove that a harmonic planar mapping $f(x,y) = u(x,y) + i v(x,y)$ for real $u,v$ can be written as $f(x,y) = \phi(x,y) + \overline{\psi}(x,y)$ where $\phi$ is a holomorphic function, and $\overline{\psi}$ is an anti-holomorphic function (conjugate of a holomorphic function)?","['complex-analysis', 'holomorphic-functions', 'harmonic-functions']"
1823616,When can a set of numbers be the moments of a random variable?,"Suppose that I have a set of known measurable scalar-valued functions $f_{1},\ldots,f_{K}$. Associated with these functions, I also have a set of known real numbers $a_{1},\ldots,a_{K}$. Under what conditions on $f_{1},\ldots,f_{K}$ and $a_{1},\ldots,a_{K}$ does there exist a random variable $X$ such that $E[f_{k}(X)] = a_{k}$ for all $k = 1,\ldots,K$? Can you provide a reference to the literature where such a result is established? If the general case is too difficult, suppose that $f_{k}(x) = x^{k}$ for all $k$. As an example, suppose that $K = 2$, $f_{1}(x) = x$, and $f_{2}(x) = x^{2}$. Then if $a_{1} = 0$ and $a_{2} = 1$, I know that such an $X$ exists---for example take $X \sim N(0,1)$. On the other hand, if $a_{1} = 2$ and $a_{2} = 1$, then no such $X$ could exist, for if it did we would have $Var(X) = 1 - 2^{2} = -3 < 0$.","['probability-theory', 'probability']"
1823621,Can you solve a trig equation with a variable both inside a trig function and outside one?,I have the equation: $$d=\frac{t}{2}-\frac{sin(t)}{4}$$ I'm completely failing at how to get this in terms of $t$ I only care about it for values of $0<t<2\pi $ I've seen the graph so I know there's an inverse of it but I'm struggling on getting there,['trigonometry']
1823630,Notation for conditional set complement?,"As far as I know, given $U=\{1,2,3,4,5,6\},A=\{1,2,3\}$ the notation for its set complement is $A^C = \{4,5,6\}$ Is there any sort of notation for a conditional set complement? For example, lets say I had a true/false variable $x_1$ who determines in an equation if $A$ should be itself or its complement. I think I could do a piece-wise function like so: $$B=\begin{cases}
A& \text{if $x_1$ is true},\\
A^C& \text{if $x_1$ is false}.
\end{cases}$$ but I actually have many conditionally complemented sets that I am using. If I use a single piece-wise function, that would be $2^{n}$ cases, or I could use set operators between $n$ different piece-wise functions, but that seems very verbose. Thanks!","['notation', 'elementary-set-theory']"
1823632,How is the function $f: \mathbb{Z} \to \mathbb{R}$ continuous?,"Where $\mathbb{Z}$ is the set of integers and $\mathbb{R}$ the set of real numbers. In a question in a problem sheet, it said this statement was correct, however I do not understand how. You clearly cannot even begin to draw this function without a lot of gaps. I suppose when the $\lim_{x\to Z_1} f(x) = f(Z_1)$. So is that the reason why the function is continuous? Edit: This question came up in a first year university analysis module so I'm not too sure what topology means. Also, I use the standard epsilon, delta definition of continuity.","['continuity', 'functions']"
1823669,What is the difference between conditional and posterior probability?,"I'm having having understanding the difference between conditional and posterior probability. Conditional probability: ...a measure of the
  probability of an event given that (by assumption, presumption,
  assertion or evidence) another event has occurred. Source: https://en.wikipedia.org/wiki/Conditional_probability Posterior probability: ...the conditional probability that is
  assigned after the relevant evidence or background is taken into
  account. Source: https://en.wikipedia.org/wiki/Posterior_probability Are they essentially the same?",['probability']
1823688,$\arctan x=\frac{1}{2}i[\ln(1-ix)-\ln(1+ix)]$,"In wikipedia it says, $$\arctan x=\frac{1}{2}i[\ln(1-ix)-\ln(1+ix)]$$ I want to now why is this true and what does a logarithm of a complex number even mean. I'm guessing that if I use the Taylor series I can prove this result. Thanks","['logarithms', 'trigonometry', 'complex-numbers']"
1823693,"What is the meaning of $1/(D+a)$, where $D$ is the derivative operator?","Today I read the answer to this post , in which the poster integrates $x^5e^x$ by making these manipulations with the differential operator $D$: $$\frac1Dx^5e^x=e^x\frac{1}{1+D}x^5=e^x(1-D+D^2+...)x^5$$ which I was amazed by but yet suspicious of. After reading a bit on differential operators, I know a few properties. For example, $D+a$ (where $a$ is constant) is a polynomial differential operator which comes from the differential equation $y'+ay = q(x)$. Also, for polynomials $f$ and $g$, $f(x)\cdot g(x)=h(x)$ implies $h(D)u=f(D) \circ [g(D)u]$ with $u$ being a function and $f(D), g(D), h(D)$ being polynomial differential operators. Since $(1+x) \cdot \frac1{1+x} = 1$, I know that if we applied the operator $(1+D)$ to some function, $\frac{1}{1+D}$ would invert it back to the original function. However, this still doesn't help me make sense of the meaning of $\frac{1}{1+D}$. For example: If $1+D$ comes from the differential equation $y'+ay+q$, where does $\frac{1}{1+D}$ come from? In other words, if $(1+D)y = 1\cdot y + Dy = y' + y$, how do we compute $\frac{1}{1+D}y$? (Is it even possible, and how does it relate to integration?) How do we justify the power series of the operator? How do we know there are no convergence issues?","['abstract-algebra', 'integration', 'differential-operators', 'calculus']"
1823696,Why does $(\sin x)^2=x^2$ and $\sin x=x$ in these contexts?,"Contexts (it must also be noted that as $\delta t$ tends to zero, $\delta \theta$ also tends to zero): First context
$$
\lim_{\delta t \to 0} \frac{-2v\sin(\delta\theta/2)^2}{\delta t} = \lim_{\delta t \to 0} \frac{-2v(\delta\theta/2)^2}{\delta t}\quad\text{[since $\sin(x) \to x$ as $x \to 0$]}
$$
Second context
$$
\lim_{\delta t \to 0} \frac{v\sin(\delta\theta) - 0}{\delta t} = \lim_{\delta t \to 0} \frac{v\sin(\delta\theta)}{\delta t} = \lim_{\delta t \to 0} \frac{v\delta\theta}{\delta t} = v\omega = r\omega^2\quad\text{[since $\sin(x) \to x$ as $x \to 0$]}
$$
The only reason that I am given is that as $x$ tends to zero, $\sin x$ tends to $x$, which for one does not only not make sense, but also doesn't help to clarify why $(\sin x)^2=x^2$ in the first context. So, I was wondering if someone could either provide me with the correct explanations or explain the ones provided.","['trigonometry', 'approximation', 'limits']"
1823713,solving $y' - yy'x^2-x=0$,"How can i solve this? $$y' - yy'x^2-x=0$$ I only got to the homogeneous solution wich I found is (I just divided by $y'$) $$y=\frac{1}{x^2}$$ But I don't know how to get the particular solution, I have for certain that it's not a constant as I tried to find it in every way possibile, could anybody help me? Thanks.",['ordinary-differential-equations']
1823771,Simple proof of uniqueness of Lebesgue Decomposition?,"Lebesgue's Decomposition Thm states: if $\lambda,\mu$ are $\sigma$-finite measures on a measurable space $(X,\textbf{X})$, then $\exists$ unique measures $\lambda_1,\lambda_2$ on $(X,\textbf{X})$ s.t. $\lambda=\lambda_1+\lambda_2$ $\lambda_1 \perp \mu$ (mutually orthogonal: $\exists A,B \in \textbf{X}$ that partitions X, and $\lambda_1(A)= \mu(B)=0$ $\lambda_2 << \mu$ (abs cont: $E \in \textbf{X}, \mu(E)=0$ implies $ \lambda_2(E)=0$) I have read Bartle's pf of this fact in his ""Elements of Integration"".  I'm comfortable with the existence part, but my question is about the uniqueness part. Bartle says it follows from the fact that if $\alpha$ is a measure s.t. $ \alpha \perp \mu$ and $\alpha << \mu$, then $\alpha$=0. This post gives an answer that deals with signed measures, starting with finite measures and then extending to the $\sigma$-finite case, but I suspect there is an easier way since I don't feel Bartle would have ""buried that much work"" inside one sentence, given the nature of his previous proofs.  So I guess my question is if there's a way to avoid signed measures. What I've tried so far is essentially in the link above.  Let (since we already have existence) $\lambda=\lambda_1+\lambda_2 = \lambda_3 + \lambda_4$ $\lambda_1, \lambda_3 \perp \mu$ $\lambda_2,\lambda_4 << \mu$ I'm tempted to use $\alpha= \lambda_3 - \lambda_1$, but we don't know that this is a measure.","['real-analysis', 'measure-theory']"
1823780,Relation between linear independence and inner product,"I was given the following question: Let $V$ be an inner product space and let $u,v\in V$ be two nonzero vectors. Prove or disprove: If $\langle u,v\rangle=0$, then $u,v$ are linearly independent. If $u,v$ are independent, then $\langle u,v\rangle=0$. I know that $u,v$ are arthogonal if $\langle u,v\rangle = 0$.
So, since $\langle u,v\rangle = 0$, and $u,v$ are non zero vectors can I claim linear independence between the vectors directly? And if so, how do I explain it? This just seems wrong... I don't see how linear independence leads to this vectors having inner product of zero, meaning they are orthogonal.
Any help or direction would be very helpful.","['linear-algebra', 'inner-products']"
1823802,"Eisenbud-Harris Exercise II-14, limit scheme isomorphic to triple point and remembers both tangent line, osculating $2$-plane to subscheme","Let $C$ be the subscheme of $\mathbb{A}_K^n$ given by the ideal$$J = (x_2 - x_1^2, x_3 - x_1^3, \ldots).$$A closed point in $C$ is of the form $f(t) = (t, t^2, t^3, \ldots, t^n)$, for $t \in K$; that is, it has ideal $(x_1 - t, x_2 - t^2, \ldots)$. Consider for $t \neq 0$ the three-point subscheme$$X_t = \{f(0), f(t), f(2t)\} \subset C.$$ How do I see that the limit scheme as $t \to 0$ is$$X_0 = \text{Spec}\,K[x_1, \ldots, x_n]/(x_2 - x_1^2, x_1x_2, x_3, x_4, \ldots, x_n)$$and is isomorphic to the triple point $\text{Spec}\,K[x]/(x^3)$ above? How do I see that $X_0$ is not contained in the tangent line to $C$ at the origin, and that rather, the smallest subspace of $\mathbb{A}_K^n$ in which $X_0$ lies is the osculating $2$-plane$$x_3 = x_4 = \ldots = x_n = 0$$to $C$, while the tangent line to $C$ is the smallest subspace of $\mathbb{A}_K^n$ containing the subscheme defined by the square of the maximal ideal in the coordinate ring of $X_0$? Thus, in this sense, $X_0$ ""remembers"" both the tangent line and the osculating $2$-plane to $C$.",['algebraic-geometry']
1823811,"Can we say that, there is a neighborhood of $x_0$ such that, $f$ is differentiable in all points of neighborhood?","Let $f:\mathbb{R} \to \mathbb{R} $, and $f$ is differentiable in $x_0$. Can we say that, there is a neighborhood of $x_0$ such that, $f$ is differentiable in all points of this neighborhood? Which conditions say that this question is true?","['derivatives', 'implicit-function-theorem', 'partial-derivative', 'calculus']"
1823812,Non-self Adjoint Operator Algebra References,"The problem I am working on has led me to define a norm closed sub-algebra $\mathscr{A}$ of $\mathscr{B}(\mathscr{H})$.  The algebra is generated by some mild relations, and in general, will not be closed under taking adjoints. Every operator algebra I have played with up until this point has been a C*-algebra, and so I am currently a bit uncomfortable with the object I am working with. In seeking out references for some basic theory of non-self adjoint operator algebras, I have come across papers over particular results but nothing I would label as a collection of essentials.  Thus my question: Is there a book or paper that goes over the basics of non-self adjoint operator algebras? If not, what are the fundamental results that I should seek out? Thanks in advance.","['functional-analysis', 'operator-algebras', 'operator-theory']"
1823820,$x^2$ modulo a prime,"Prove that $x^2$ modulo a prime $p>2$ takes on exactly $\dfrac{p+1}{2}$ different values. I thought of first saying the residues modulo $p$ can be written as follows: $$0,1,\ldots,\frac{p+1}{2}-1,-\left(\frac{p+1}{2}-1\right),\ldots,-1.$$ Thus if it weren't the case that $x^2$ took on exactly $\dfrac{p+1}{2}$ different values modulo $p$, then there would exist $x_1 \neq x_2 $ such that $x_1,x_2 \leq \frac{p-1}{2}$ and $x_1^2 \equiv x_2^2 \pmod{p}$. How do I prove a contradiction here?",['number-theory']
1823864,Limit distributions for Markov chains $X\to\sqrt{U+X}$,"This question spawned from a recent, very interesting problem . Let $\varphi=\frac{1+\sqrt{5}}{2}$ and $T$ denote the map on the space of continuous probability density functions supported over $\left(0,\varphi\right)$, defined by
  $$ (T f)(x) = 2x\cdot\left( f * \mathbb{1}_{(0,1)}\right)(x^2). \tag{1}$$ What are the fixed points of $T$? If we assume that $T(f_n)=f_{n+1}$ and that $f_n$ is the PDF of $X_n$, we are simply looking for the limit distribution of the Markov chain $(X_n)$ defined by $$X_{n+1}=\sqrt{U_{n+1}+X_n},$$ where $(U_n)_{n\geqslant1}$ is i.i.d. uniform on $(0,1)$ and independent of $X_0$. One might be tempted to switch to Fourier transforms/series in (1), but the $x^2$ term does not make this approach very attractive. In the comments to the original question, user Did proved that, assuming $f_1(x)=2x\cdot\mathbb{1}_{(0,1)}$, i.e. $X_0=0$, we have $\mathbb{E}[X_n]< \frac{1+\sqrt{3}}{2}$ for every $n\geqslant1$, by convexity. Numerical simulations suggest that $\lim\limits_{n\to +\infty}\mathbb{E}[X_n]$ is very close to $\frac{1+\sqrt{3}}{2}$, but the exact value of the limit depends on the answer to this question. Thanks to mercio , here it is how the limit distribution looks like, over the interval $[1,\varphi]$:","['stochastic-processes', 'probability-theory', 'markov-process']"
1823888,Image of a disconnected set is disconnected,"I'm aware that the image of a connected set is connected and the preimage of a disconnected set is disconnected. However, I'm struggling to find an example of a disconnected set such that the image of the disconnected set is also disconnected. Can the preimage of a connected set be disconnected?","['general-topology', 'examples-counterexamples', 'connectedness']"
1823891,What is the meaning of subtracting from the identity matrix?,"If I subtract the matrix $A$ from the identity matrix $I$, $I - A$, is there a meaning to the resulting matrix perhaps given some conditions like invertibility or symmetry? For example, $$
\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
- \begin{bmatrix} a & b \\ c & d \end{bmatrix}
= \begin{bmatrix} 1-a & -b \\ -c & 1-d \end{bmatrix}
$$ For future reference, is there a good reference to lookup answers to such questions when I can't derive the answer on my own?",['linear-algebra']
1823909,The $2 \times 3$ matrices with rank $\leq 1$ cannot be defined by two polynomial equations,"Let $X$ be the space of all ${2 \times 3}$ matrices over $\mathbb{C}$ that have rank at most 1. This is naturally a subspace of $\mathbb{C}^6.$ We can express $X$ using 3 polynomial equations, namely the three $2\times 2$ minors of the matrix. I want to prove that we can't do that with fewer than 3 equations: There are no two polynomials $f,g$ (in 6 variables) such that their common roots are exactly $X$. or equivalently : There are no two polynomials $f,g$ in the variables $x,y,z,w,t,u$ such that $\{ f=g=0 \}=\{xt-wy=xu-zw=yu-zt=0\}$ Since $X$ is 4-dimensional in the space $\mathbb{C}^6$, this shows that the variety $X$ is not a set-theoretic complete intersection . Surprisingly, I didn't find any examples of a variety which is not a set-theoretic complete intersection, not in SE nor in Shafarevich or Harris. A starting point for manipulations is to write $f$ and $g$ as linear combinations of the $3$ minors (which generate the ideal of $X$).","['polynomials', 'algebraic-geometry']"
1823925,"Is this a bijective function for $f:(0,1) \rightarrow (-2,5)$?","$f:(0,1) \rightarrow (-2,5)$ I'm basically trying to prove the two intervals above have the same cardinality by finding a bijective function.  I'm not sure I did it properly but the function I found was: $y=-2x+1$ It satisfies both intervals, but is this a bijective function?  It seems to be both surjective and injective.","['real-analysis', 'elementary-set-theory']"
1823935,Why do the infinitely many infinitesimal errors from each term of an infinite Riemann sum still add up to only an infinitesimal error?,"Ok, so after extensive research on the topic of how we deal with the idea of an infinitesimal amount of error, I learned about the standard part function as a way to deal with discarding this infinitesimal difference $\Delta x$ by rounding off to the nearest real number, which is zero. I've never taken nonstandard analysis before, but here's my question. When you take a Riemann sum, you are approximating an area by rectangles, and each of those rectangles has an error in approximating the actual area under the curve for the corresponding part of the graph.  As $\Delta x$ becomes infinitesimal, the width of these rectangles becomes infinitesimal, so each error becomes infinitesimal.  But since there are infinitely many rectangles in that case, why is it that the total error from all of them still infinitesimal? In other words, shouldn't an infinite amount of infinitesimals add up to a significant amount?","['nonstandard-analysis', 'real-analysis', 'integration', 'calculus']"
1823936,Fundamental group and curvature,"Is there any paper about the $\pi_1$ group and curvature ? Because  how close a curve depends on the curvature near the curve . I think there must have some condition which decide  whether there is closed curve on manifold. Besides,     curvature decide the genus.So, I guess there should be some connection between fundamental group and curvature. If there are any unclear , sorry for my poor English.","['riemannian-geometry', 'differential-geometry', 'curvature']"
1823972,"Prove that $\gcd(3^n-2,2^n-3)=\gcd(5,2^n-3)$","Prove that $\gcd(3^n-2,2^n-3)=1$ if and only if $\gcd(5,2^n-3)=1$ where $n$ is a natural number. I didn't see an easy way to prove this using the Euclidean algorithm, but it seems true that both gcd's are not $1$ only if $n = 3+4k$. Is there an easy way to prove the statement?","['gcd-and-lcm', 'contest-math', 'divisibility', 'elementary-number-theory']"
1823980,"Determine the largest natural number $r$ with the property that among any five subsets with $500$ elements of the set $\{1,2,\ldots,1000\}$","Question: Determine the largest natural number $r$ with the property that among any five subsets with $500$ elements of the set $\{1,2,\ldots,1000\}$ there exist two of them which share at least $r$ elements. By Now, I claim that $\color{red}{ r \le 200} $ ** reasons were as follows For all $ k \in \{1, 2, \dots, 10\} $ let $\color{red}{ A_k = \{100k - 99, 100k - 98, \dots, 100k\}}. $ Then if we look at the subsets $ A_1 \cup A_5 \cup A_6 \cup A_7 \cup A_9 $ and $ A_1 \cup A_2 \cup A_7 \cup A_8 \cup A_{10} $ and $ A_2 \cup A_3 \cup A_6 \cup A_8 \cup A_{9} $ and $ A_3 \cup A_4 \cup A_7 \cup A_9 \cup A_{10} $ and $ A_4 \cup A_5 \cup A_6 \cup A_8 \cup A_{10} $ we see that any two of these subsets share exactly $ 200 $ elements which implies that $\color{blue}{ r \le 200. }$ I conjecture $\color{red}{r_{\max}=200?}$ and I can't prove it.Thanks","['combinatorics', 'discrete-optimization', 'optimization', 'extremal-combinatorics']"
