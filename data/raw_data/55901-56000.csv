question_id,title,body,tags
606085,differentiable maps between topological spaces without using the idea of manifolds,Is it possible to define differentiable maps between topological spaces without using the idea of manifolds?,"['differential-topology', 'differential-geometry']"
606094,Intuition for a function that belongs to a $L^p$ space,"Does a function $f(x):[0,\infty)\rightarrow R$ with $f\in L^p$ for $p<\infty$ have to die down to $0$ as $x\rightarrow \infty$? I some how feel that the $L^p$ norm exist only when the function dies down to $0$ and the rate at which it dies down to $0$ depends on $p$. Is this right?","['lp-spaces', 'real-analysis']"
606106,Roots of $f(x)=\sin(x)-ax$,"How many roots are there of the function $f(x)=\sin(x)-ax$, where $a$ is a positive number? Clearly for all $a$, $x=0$ is a root; if $a>1$ that is the only root. The roots will also be symmetric about the origin. I conjecture that there are $2\lfloor 1/(a\pi)\rfloor+1$, but I'm not sure how to prove this.","['trigonometry', 'roots']"
606136,"Find all continuous functions $f$ : $\mathbb{R} \rightarrow \mathbb{R}$ satisfying: $f(xy)+f(x+y)=f(xy+x)+f(y)\quad\forall x,y \in \mathbb{R}$","Find all continuous functions $f$ : $\mathbb{R} \rightarrow \mathbb{R}$ satisfying:
$$f(xy)+f(x+y)=f(xy+x)+f(y)$$ $\forall x,y \in \mathbb{R}$ I have tried that : $P(y;x)-P(x;y)$: $f(xy+y)+f(x)=f(xy+x)+f(y)$ $P(x;1)$: $f(x)+f(x+1)=f(2x)+f(1)$ $P(x+1;1)$:$f(x+1)+f(x+2)=f(2x+2)+f(1)$
So $f(x+2)-f(x)=f(2x+2)-f(2x) , \forall x \in \mathbb{R}$ let $g(x)=f(x+2)-f(x)$ We have $g(2x)=g(x)=g(\frac{x}{2})=...=g(0)=c$ because $g$ is the continous functions.
To here, I have no idea to solve the problem.","['real-analysis', 'functional-equations']"
606143,Showing a functor that takes a group to its set of subgroups is not representable,"Let $F:\text{Grp} \rightarrow \text{Set}$ be the functor that takes a group to its set of subgroups. Suppose $A$ is such a representing object, then $\text{Hom}(A,A) \simeq F(A) \Rightarrow \text{Hom}(S_{|A|},S_{|A|}) \simeq F(S_{|A|})$, i.e. $Aut(S_{|A|}) \underset{\text{Set}}\simeq F(S_{|A|}),$ but $Aut(S_n) = S_n$ for all $n$ other than $2$ and $6$ and $|F(S_{|A|})|>|A|!$ for all $|A|>3$, and so we obtain a contradiction after eliminating the cases $2,3$ and $6.$ Is there (there has to be) a better, more structural proof of this?","['category-theory', 'abstract-algebra']"
606150,Why is $\tan(z)$ entire if $\tan(z)$ is not differentiable at $\cos(z)=0$,"The solution manual of my complex analysis textbook said that $\tan(z)$ is entire, why is that so, $\tan(z)$ is not differentiable when $\cos(z) = 0$",['complex-analysis']
606172,"If $ \lim_{n \to \infty} (2 x_{n + 1} - x_{n}) = x $, then is it true that $ \lim_{n \to \infty} x_{n} = x $?","If $ (x_{n})_{n \in \mathbb{N}} $ is a sequence in $ \mathbb{R} $ and $ \displaystyle \lim_{n \to \infty} (2 x_{n + 1} - x_{n}) = x $, then is it necessarily true that
$$
\lim_{n \to \infty} x_{n} = x?
$$ Could anyone kindly offer suggestions on how to approach this problem? Thanks!","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
606175,"Define a relation on the set of all real numbers $x,y \in \mathbb{R} $ as follows:","Define a relation on the set of all real numbers $x,y \in \Bbb{R} $  as follows: $x \sim y$ if and only if $x - y \in \Bbb{Z}$ Prove this is an equivalence relation and find the equivalence class of number $\dfrac {1}{3}$. ATTEMPT: Reflexive: For any $x\in\Bbb Z$, ${x} - {x}=0$ and $0 \in \mathbb{Z}$. Symmetric: For any $x,y \in \Bbb Z$, if  $x - y \in \Bbb Z$ then $y -  x \in \Bbb Z$. Transitive: For any $x,y,z \in \Bbb Z$, if $ {x} - {y} = 2k$ and ${y} - {z}= 2l$ for some $k,l \in \Bbb Z$, then ${x} - {z} = 2(k+l)$ Is the proof correct? And how do I find equivalence class?","['relations', 'equivalence-relations', 'discrete-mathematics']"
606177,The statements $f(n) = O(n^{\epsilon})$ for all $\epsilon > 0$ and $f(n) = n^{o(1)}$.,"Consider the statements
\begin{align}
\tag{A}
f(n) &= O(n^{\epsilon}) \text{ for all } \epsilon > 0 \\
\tag{B}
f(n) &= n^{o(1)}
\end{align} Questions: It's clear that (B) implies (A). Does (A) imply (B)? If the answer to the first question is no, is there a more brief way to write (A)?","['asymptotics', 'sequences-and-series', 'real-analysis', 'analysis']"
606184,Volume of $n$ dimensional ellipsoid,"Let $c_1,c_2,...,c_n$ be positive constants. Consider the $n$ dimensional ellipsoid given by $\{(x_1,...,x_n)|\sum_{k=1}^n\frac{x_k^2}{c_k^2}<1\}$. Prove that it's $n$ dimensional volume is $\frac{\pi^{n/2}}{\Gamma(n/2+1)}\prod_{k=1}^nc_k$ I'm know from http://en.wikipedia.org/wiki/Volume_of_an_n-ball that the volume of the $n$ ball is exactly the above formula with $c_1=c_2=...=c_n=r$, which at least confirms the formula in this special case. It seems we can argue by scaling in each coordinates, but how to make this rigorous?","['linear-algebra', 'integration', 'real-analysis', 'measure-theory']"
606189,Ultraproduct of the algebraic closure of finite fields,"Ok, I have done a little research on the next problem, and there are simple proofs of it using model theory, logic and the Łoś's theorem. But here, the idea is to prove it using only Field Theory, Galois Theory and the basic theory of transcendental extensions. This is the problem: Let $W$ be the set of prime numbers and let $\mathfrak{U}$ be a non principal ultrafilter over $W$. For every prime $p$, let $\overline{\mathbb{F}_p}$ denote an algebraic closure of $\mathbb{F}_p$. In the following product
$$
\prod_{p\in W} \overline{\mathbb{F}_p},
$$
define the equivalence relation $(a_p)\sim (b_p)$ if and only if $\{p\in W: a_p=b_p\}$ belongs to $\mathfrak{U}$. Let
$$
A=\prod_{p \in W} \overline{\mathbb{F}_p} ~/~ \sim
$$
denote the set of equivalence classes, such that $[a_p]$ is the class of $(a_p)$. Show that $A$ is not countable. Show that $A$ is isomorphic to $\mathbb{C}$. Proving that the addition and product ($[a_p]+[b_p]=[a_p+b_p]$, $[a_p][b_p]=[a_pb_p]$) are well defined on $A$ and that $\text{char}(A)=0$ is tedious but quiet straightforward. On the other hand proving (1) and (2) has been a rather difficult task. For (1), I honestly have no idea how to proceed; and for (2) I've tried using the fact that $\mathbb{C}$ has an infinite number of automorphism, but I haven't had any luck. Also I think that in order to prove (2) I actually need to show that $|A|=2^{\aleph_0}$. Any suggestions on how to proceed will be really appreciated. Thanks in advance for any help you provide.","['filters', 'finite-fields', 'abstract-algebra', 'galois-theory', 'field-theory']"
606204,Fibonacci proof question: $f_{n+1}f_{n-1}-f_n^2=(-1)^n$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Show that 
$$f_{n+1}f_{n-1}-f_n^2=(-1)^n$$
when $n$ is a positive integer and $f_n$ is the $n$th Fibonacci number.","['fibonacci-numbers', 'discrete-mathematics']"
606205,Why is it that $E(xy) = E(x)E(y)$ if $x$ and $y$ are uncorrelated random variables?,"Also, why does $E(xy) = E(x)E(y)$ not hold if $x$ and $y$ are correlated? Perhaps at a more basic, intuitive level, what's the difference between $E(xy)$ and $E(x)E(y)$?",['probability']
606222,Expected value vs using method of indicator,"I am having a hard time understanding the difference between getting the Expected value by finding the mean E(X)=np and using the method of indicator to find the expected value. For example if we wanted to find the expected value after throwing a die it would be: 1/6 * 1 + 1/6 * 2 + 1/6 *3 + 1/6 * 4 + 1/6 * 5 + 1/6 *6 = 3.5 Now using the method of indicator it says to take make event Xi equal to 1 if the event occurs or 0 if the event does not occur. So instead of taking the random variable 1,2,3,4,5,6 and multiplying times the probability of getting that random variable, we are suppose to find E(Xi) where Xi is (assuming) the event of rolling the number that leads to the event happening. We multiple 1*P(number showing up on roll)=E(Xi) . Since the chances are equally likely it is 1/6 so we get 1*1/6. We then get E(X) by calculating E(X)=E(X1)+E(X2)+...+E(Xn) which is taking the expected value of each event which is really just taking the probability of each event times 1 or 0(lost here - 1 if the event happened but 0 if it didnt. The problem i am having is wont it always be 1 since we are finding the expected value of that specific event?). Clearly my answer does not come out to be the same as just doing 1/6 * 1 + 1/6 * 2 + 1/6 *3 + 1/6 * 4 + 1/6 * 5 + 1/6 *6 so i have no idea what the heck i am doing. Very frustrating. I don't understand the method of indicator, i am hoping someone can help by maybe showing me another example doing it both ways so i can understand the difference.","['discrete-mathematics', 'random-variables', 'probability-theory', 'normal-distribution', 'probability']"
606246,Pure Mathematics proof for $(-a)b$ =$-(ab)$,How can I prove this without using the Multiplicative Property of zero? $(a*0=0)$,['number-theory']
606251,"Integrating $\int\frac{\sqrt{\cos 2x}}{\sin x}\,\text{d}x$","The integral is $$\int\frac{\sqrt{\cos 2x}}{\sin x}\,\text{d}x$$ I have tried solving this by taking the sine inside the radical as follows: $$\int\sqrt\frac{\cos 2x}{\sin^2 x}\,\text{d}x$$ $$\int\sqrt\frac{\cos^2x-\sin^2x}{\sin^2 x}\,\text{d}x$$ $$\int\sqrt{\cot^2x-1}\,\text{d}x$$ I don't know how to proceed from here, or whether this is even right. Any suggestions?","['trigonometric-integrals', 'integration', 'indefinite-integrals']"
606257,If $g\circ f$ is injective and $f$ is surjective then $g$ is injective,"Let $f:A\rightarrow B$ and $g:B\rightarrow C$ be functions, prove that if $g\circ f$ is injective and $f$ is surjective then $g$ is injective. I need advise or correction if something is incorrect with my proof. Thank you beforehand. We must show that $g$ is injective, i.e for $x,y\in B, g(x)=g(y)\implies x=y$ Let $x,y\in B$ such that $g(x)=g(y)$. Because $f$ is surjective there exists $a,b \in A$ such that $f(a)=x$ and $f(b)=y$ $\implies g(f(a))=g(f(b))$ $\implies g\circ f(a)=g\circ f(b)$ $\implies a=b$ (by injectivity of $g\circ f$) $\implies f(a)=f(b)$ $\implies x=y$ Would appreciate any correction in proof writing also!",['functions']
606260,An Easier way to solve simple equations of this type,"Im currently working with ellipses and I've been given two points on a ellipse whose major axis is along the x-axis, $(4,3)$ and $(-1,4)$. The question asks me to find the length of the major and minor axis. Now, I have two equations and I need to solve for $a$ and $b$, where $a$ is half the length of the major axis and $b$ is half the length of the minor axis.
$$\frac{16}{a^2} + \frac{9}{b^2} = 1$$
$$\frac{1}{a^2} + \frac{16}{b^2} = 1$$ Ofcourse it's a basic mathematical idea to equate the two equations together and get the relation $7a^2 = 15b^2 $ or $\space\large{ a^2 = \frac{15}{7}b^2}$ Now I substitute that in the second equation,
$$\frac{7}{15b^2} + \frac{16}{b^2} = 1$$
$$\Rightarrow\frac{7 + 240}{15b^2}= 1$$
$$\Rightarrow b^2 = \frac{247}{15} \approx 16.46 $$ Now, I have to go put that in one of the equations again, to save me a bit of pain, I'll put it my relation,
$$a^2 = \frac{15}{7}\cdot\frac{247}{15} = \frac{247}{7} \approx 35.28$$ And so, after all that I get,
$$ a \approx 5.94 \text{ units}$$
$$ b \approx 4.05 \text{ units}$$ Is there a more efficient way to do these kinds of equations?
One idea that came to my mind was to take $\frac{1}{a^2} = u$ and $\frac{1}{b^2} = v$ and the solve. But you great mathematicians must have better and faster ways of doing these equations. I'd like as many different approaches to this as possible. Also does this type of equations have a name?","['conic-sections', 'linear-algebra', 'algebra-precalculus']"
606279,"How many pairs of nilpotent, commuting matrices are there in $M_n(\mathbb{F}_q)$?","As a follow-up to this question , I've been doing some work counting pairs of commuting, nilpotent, $n\times n$ matrices over $\mathbb{F}_q$.  So far, I believe that for $n=2$, there are $q^3+q^2-q$ such pairs, and for $n=3$ there are $q^8+q^7+q^6-q^5-q^4$ such pairs.  Can anybody recognize these polynomials, generalize to arbitrary $n$, and prove the result?","['matrices', 'finite-fields', 'polynomials', 'combinatorics']"
606295,Are most matrices invertible? [duplicate],"This question already has answers here : Probability of having zero determinant (5 answers) Closed 10 years ago . I asked myself this question, to which I think the answer is ""yes"". One reason would be that an invertible matrix has infinitely many options for its determinant (except $0$), whereas a non-invertible must have $0$ as the determinant. Do you have another approach to this question, in terms of probability for example?","['matrices', 'inverse']"
606301,Convergence to half Euler's constant,"Euler's constant is defined by $$\gamma=\lim_{N\rightarrow\infty}\sum_{n=1}^N\dfrac1n-\log N.$$ So we can write it as $$1+\dfrac12+\dfrac13+\ldots+\dfrac1n-\log n\rightarrow \gamma.$$ How can we show that $$1+\dfrac13+\dfrac15+\ldots+\dfrac{1}{2n-1}-\dfrac12\log n\rightarrow\dfrac{\gamma}{2}+\log 2?$$ The fractions are similar, but when they skip the even terms, it's not clear how to relate.","['convergence-divergence', 'real-analysis']"
606307,Gamma function has no zeros,"I want to show that $\Gamma(z)$ has no zeros. My idea is to use the formula $$\Gamma(z)\Gamma(1-z)=\dfrac{\pi}{\sin(\pi z)}$$ which holds for all $z\in\mathbb{C}$. If $\Gamma(z)=0$, then the left-hand side is $0$ and the right-hand side isn't, so impossible. But I'm worried that it wouldn't work if $\Gamma(1-z)=\pm\infty$. How to resolve this case?","['gamma-function', 'special-functions', 'complex-analysis']"
606335,Functions from a powerset to itself,"Let $S$ be a set, and let $f$ be a function from the powerset of $S$ to the powerset of $S$. If, for all subsets $A$ of $S$, both 1) $f(f(A))=A$ and 2) $A \cap f(A)= \emptyset$, must $f$ be the complement function $S-A$? My 2nd question is, if we replace condition 2 by 2') A union $f(A) = S$, is $f$ the complement function $S-A$? I have tried working on both these problems, but I haven't made any progress.",['elementary-set-theory']
606379,References request: Ramanujan's tau function.,"References request: Ramanujan's tau function.
Let $\Delta(z)=q\prod_{n=1}^{\infty} (1-q^n)^{24}=\sum_{n=1}^{\infty} \tau(n)q^n$, $q=e^{2\pi i z}$.
How can one show the following using representation theory?
$$
\tau(n)=\sum_S \frac{(a-b)(a-c)(a-d)(a-e)(b-c)(b-d)(b-e)(c-d)(c-e)(d-e)}{1!2!3!4!}, 
$$ where $S$ is the set of ordered tuples $(a,b,c,d,e)\in \mathbb{Z}^5 $ with $$(a,b,c,d,e) \equiv (1,2,3,4,5) \pmod 5 $$ $$ a+b+c+d+e=0 $$  $$a^2+b^2+c^2+d^2+e^2=10n.$$
Thank you very much.","['automorphic-forms', 'number-theory']"
606449,$f'/f\in\mathbb{Z}[[x]]$ for polynomials vs. formal power series $f$,"I am curious about the following problem from MIT's Problem Solving Seminar (#25 in https://dspace.mit.edu/bitstream/handle/1721.1/121169/18-s34-fall-2007/contents/assignments/cong.pdf ): Let $f(x) = a_0+a_1x+\cdots\in\mathbb{Z}[[x]]$ be a formal power series with integer coefficients, such that $a_0\ne0$ . If $f'/f\in\mathbb{Z}[[x]]$ , must $f/a_0\in\mathbb{Z}[[x]]$ ? (If I haven't made a mistake below, the answer is yes.) The special case of integer polynomials, $f(x) = C\prod_{i=1}^{n}(1-r_i x)^{\alpha_i}\in\mathbb{Z}[x]$ , translates (more or less) to the following classical problem: If $\sum_{i=1}^{n} \alpha_i r_i^k \in\mathbb{Z}$ for all $k\ge0$ , then $\prod_{i=1}^{n}(1-r_ix)^{\alpha_i}\in\mathbb{Z}[x]$ , or equivalently (by considering minimal polynomials of the $r_i$ over $\mathbb{Q}$ , with coefficients suitably reversed), $\prod_{i=1}^{n}(1-r_ix)\in\mathbb{Z}[x]$ . There are a few ways to do the polynomial version, which I'll outline below. However, the only solution I can find right now to the original goes as follows: Yes. WLOG scale so that $\gcd(a_0,a_1,\ldots) = 1$ . For $k\ge1$ , define $g_k = f^{(k)}f^{-1}$ . Note that if we have $g_k\in\mathbb{Z}[[x]]$ for some $k\ge1$ , then differentiating gives $f^{(k+1)}f^{-1} - f^{(k)}f'f^{-2}\in\mathbb{Z}[[x]]$ . But $f^{(k)}f^{-1},f'f^{-1}\in\mathbb{Z}[[x]]$ , so adding their product, $f^{(k)}f'f^{-2}\in\mathbb{Z}[[x]]$ , yields $g_{k+1} = f^{(k+1)}f^{-1}\in\mathbb{Z}[[x]]$ . (A perhaps more natural, but equivalent, way to do the induction: If $f^{(k)} = f g_k$ , then $$f^{(k+1)} = f'g_k + f g'_k = f[g_1g_k + g'_k],$$ and of course $g_1g_k + g'_k\in\mathbb{Z}[[x]]$ .) Thus by induction, $g_k\in\mathbb{Z}[[x]]$ for all $k\ge1$ . But $$g_kf = f^{(k)} = k!\sum_{i\ge0}\binom{i+k}{k}a_{i+k}x^i,$$ so by Gauss's lemma (for formal power series) and the fact that $\gcd(a_0,a_1,\ldots) = 1$ , we in fact have $g_k/k!\in\mathbb{Z}[[x]]$ . In particular, evaluating at $0$ (looking at constant terms) gives $a_0 \mid \binom{0+k}{k}a_{0+k} = a_k$ for all $k\ge1$ , so $f/a_0$ indeed has integer coefficients, as desired. Unfortunately, I don't really grok this proof, even in the simple case of integer polynomials $F = C\prod_{i=1}^{n}(1-r_i x)^{\alpha_i}\in\mathbb{Z}[x]$ described above. (I'll use capital $F$ for clarity.) For the polynomial case, I've seen two more intuitive methods that I feel might/should generalize, but unfortunately I can't see exactly how right now: I think the standard proofs more or less use valuations in some way. Note that the conditions hold with $r_i$ replaced by $r_i^s$ , for any fixed $s\ge1$ . By Newton's identities, it's not hard to see that $k$ th symmetric sum $\sigma_k(r_i^s)$ , with multiplicity $\alpha_i$ for $r_i$ , is divisible by $1/k!$ (i.e. $k!\sigma_k\in\mathbb{Z}$ ), so $(\sum\alpha_i)!\prod_{i=1}^{n}(1-r_i^s x)^{\alpha_i}\in\mathbb{Z}[x]$ . Thus $(\sum\alpha_i)!r_i^s$ is an algebraic integer for every $s\ge1$ ( $i$ fixed), and we can finish using valuations (as in the second post, or more elementarily but in the same spirit, as in the first post) here . Admittedly, it seems hard to directly extend Newton's identities to ""infinitely many roots"" for formal power series, but I imagine there could be something more indirect. I suppose I'm really wondering if we can define some fruitful kind of ""valuation"" (possibly for some sort of ""roots"") for arbitrary $f\in\mathbb{Z}[[x]]$ . Write $F'/F = \sum -\alpha_i r_i/(1-r_i x)$ as $P/Q$ with $P\in\mathbb{Z}[x]$ coprime to $Q = D\prod (1-r_ix)\in\mathbb{Z}[x]$ ( $D\ne0$ chosen so $Q$ , and therefore $P$ , has integer coefficients). By Bezout's identity, there exist $A,B\in\mathbb{Z}[x]$ such that $AP+BQ = c$ for some nonzero integer $c$ , so $$c/Q = (AP+BQ)/Q = A(P/Q)+B \in \mathbb{Z}[[x]].$$ By Gauss's lemma (for formal power series), the only way $c = Q(c/Q)$ can occur is if $Q(0)$ and $(c/Q)(0)$ (which multiply to $c$ ) are the gcd's of the coefficients of $Q$ and $c/Q$ , respectively, so $Q/Q(0) = \prod(1-r_ix)$ has integer coefficients, as desired. So in that vein, I would be interested in some version of Bezout's identity for integer formal power series. (Especially one that helps for the formal power series version of the problem.) Of course, to actually use such a fact, we would have to first factor out a gcd of $f$ and $f'$ (in $\mathbb{Z}[[x]]$ ), as when we have multiple roots in the polynomial case.","['divisibility', 'power-series', 'algebraic-number-theory', 'number-theory']"
606487,How can we proof that number ternary strings that do not contain two consecutive 0s or 1s is $a_n = 2a_{n-1} + a_{n-2}$,"How can we proof that number ternary strings that do not contain two consecutive 0s or 1s is $a_n = 2a_{n-1} + a_{n-2}$ What I tried so far: Let $a_n$ be the number ternary strings that do not contain two consecutive 0s or 1s. If the first digit start with 2 there will be $a_{n-1}$ such strings. Or if the first digit start with 0 there will be $ (2/3) a_{n-1}$ such strings. Same goes for the case starting with 1. That means $(4/3)a_{n-1}$ and in total $(4/3)a_{n-1} + a_{n-1} = (7/3) a_{n-1}$ And if the first digit is 0 and second 1 or 2 there'll be $a_{n-2}$
Similarly starting with 1 and second digits are 0 or 2 there'll be $a_{n-2}$
and  in total $ 2a_n{-2}$ So as you can see I get $a_n =(7/3)a_{n-1} + 2a_{n-2}$ I have no clue what I am missing here","['recurrence-relations', 'discrete-mathematics']"
606498,Closed but not exact one-form on $S^2$,"I would like to know whether there is any nice prescription to give an example of a closed but not exact one-form on $S^2$ (not the $3$-ball). I assume to take some points out of this surface, e.g. 3. On $\mathbb{R}^2-\{0\}$ a closed but not exact one-form would be $\frac{x dy-y dx}{x^2+y^2}$. Can I use this also for $S^2$?","['differential-geometry', 'homology-cohomology', 'differential-forms', 'real-analysis', 'complex-analysis']"
606502,Can a square be cut parallel to its sides to make a rectangle of non-square-rational proportion?,"For arbitrary positive integers $m$ and $n$, a unit square can be dissected along a regular grid dividing it into $mn\times mn$ subsquares and reassembled into an $m/n\times n/m$ rectangle. But can it be cut another, nonrational, way into rectangles to form a rectangle whose ratio of sides is not the square of a rational number? (The usual rules apply: finitely many cuts, and no gaps, overlaps, or discarding.)",['geometry']
606512,How can I algebraically solve $n-\log(na)=b$ for $n$,"How can I algebraically solve $n-\log(na)=b$ for $n$. I figured out a simple algorithm to get arbitrary close to the solution (estimate, then negate log term and use answer in the log term, then repeat), but I want to know how I can solve this exact.","['logarithms', 'algebra-precalculus']"
606513,system of 2 linear differential equations with variable coefficients,"I have a system of 2 linear diff equations but with a variable coefficients: $$f''(x)+af'(x)+(1+x)g'(x)+bg(x)=0\\g''(x)+ag'(x)+(1-x)f'(x)-bf(x)=0$$ where $a,b$ are some positive constants. I have no idea how to solve this system (or even if it has an anayltic solution), I'll appreciate any help or some reference.","['ordinary-differential-equations', 'systems-of-equations']"
606523,Real polynomial in two variables,"I have problems proving the following result: Each $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ such that $\forall a,b \in \mathbb{R} \ : \ f_a(y) := f(a,y), \ f_b(x) := f(x,b) $ are polynomials is a polynomial with two variables. If I consider $f$ as a function of $x$, then its derivative  $f'(x) = \frac{\partial f}{\partial b}(x)$. Similarly if we treat $f$ as a function of $y$. I assume that $f_a(y) = \frac{\partial f}{\partial a} (y) $ and $f_b(x)=\frac{\partial f}{\partial b}(x)$. But I am not sure if we can assume that, because  the degree of the derivative should be smaller than the degree of the original function (and it isn't). Actually, I'm not even sure if what I'm trying to prove is true, because in the original formulation of the problems there is written $f_a(y) := (a,y), \ f_b(x):=(x,b)$. But that didn't make sense. Could you help me here? Thank you.","['partial-derivative', 'real-analysis', 'polynomials']"
606544,A simpler solution to a limit question?,"Okay I saw this limit question in Thomas' Calculus 12th Edition: $\lim \limits_{x \to 0} \frac{\tan3x}{\sin8x}$ The answer is $\frac{3}{8}$. I was able to get the correct answer using this ridiculously lengthy and messed up rubbish... ... but I have a feeling there should a simpler, more concise and more elegant solution. Perhaps there is something I am missing? Maybe a trig identity? Or a theorem?","['trigonometry', 'probability-limit-theorems', 'limits']"
606547,$z\exp(z)$ surjectivity with the Little Picard Theorem,"I would like to prove the surjectivity of this function : \begin{align*} 
f\colon\mathbb{C}&\to\mathbb{C}\\
z&\mapsto z\exp(z)
\end{align*} You can use the Little Picard Theorem : If a function $f\colon\mathbb{C}\to\mathbb{C}$ is entire and non-constant, then the set of values that $f(z)$ assumes is either the whole complex plane or the plane minus a single point. Thanks.","['exponential-function', 'complex-analysis']"
606559,Evaluate limit of a sequence... NBHM $2013$,"Question is to Evaluate $$\lim_{n\rightarrow \infty} \sin((2n\pi + \frac{1}{2n\pi}) \sin(2n\pi + \frac{1}{2n\pi}))$$ All I could do was to see that $$\sin(2n\pi + \frac{1}{2n\pi}))=\sin( \frac{1}{2n\pi})$$ Just because $\sin(2n\pi+\theta)=\sin(\theta)$.. So, we now have $$\lim_{n\rightarrow \infty} \sin((2n\pi + \frac{1}{2n\pi}) \sin( \frac{1}{2n\pi}))$$ Now, as $\lim _{x\rightarrow \infty}x\sin(\frac{1}{x})=1$ we would have 
$$\lim_{n\rightarrow \infty}2n\pi \sin( \frac{1}{2n\pi})=1$$ So, we now have $$\lim_{n\rightarrow \infty} \sin(1 + \frac{1}{2n\pi} \sin( \frac{1}{2n\pi}))$$ Now, as $\sin(x)$ is bounded and $\frac{1}{2n\pi} \rightarrow 0$ we would have $$\lim_{n\rightarrow \infty}\frac{1}{2n\pi} \sin( \frac{1}{2n\pi})=0$$ So, we would now left with : $$\lim_{n\rightarrow \infty} \sin(1)=\sin(1)$$ After all i would like to say that as $\sin (x)$ is continuous I can take limits inside. So, we have $$\lim_{n\rightarrow \infty} \sin((2n\pi + \frac{1}{2n\pi}) \sin(2n\pi + \frac{1}{2n\pi}))=\sin 1$$ I would like somebody to check if I have done correctly and I would be thankful if any body can let me know if there is anything more to be specified to do so. Thank you... :)","['real-analysis', 'limits']"
606562,Use implicit differentiation to find dy/dx,"$xy+x=2$ I know the answer is $-(1+y)\over x$, but I don't know how to solve to get the answer. Thank you!","['multivariable-calculus', 'implicit-differentiation', 'calculus']"
606566,Properties of the relation $R=A\times B \cup B\times A$,"A is a set. Let $B\subsetneq A$. $R=A\times B \cup B\times A$ Determine if the relation is (a)reflexive, (b)symmetric, (c)transitive, (d)anti-reflexive, (e)anti-symmetric, (f)asymmetric, (g)equivalence relation. This is what I did: It isn't reflexive because there can't be a set that is a proper subset of itself. So it is anti-reflexive. It is symmetric because a union is symmetric:  $A\times B \cup B\times A=B\times A\cup A\times B$ It isn't transitive because not every ordered pair of (A and B) and (B and C) is in A and C, example: $A=\{1\} \ B=\{1,2\} \ C=\{1,2,3\}
\\ A\times B \cup B\times A = (1,1),(1,2),(2,1)
\\ C\times B \cup B\times C = (1,1),(1,2),(1,3),(2,1),(2,2),(2,3),(3,1),(3,2)
\\ A\times C \cup C\times A = ( 1,1 ),( 1,2 ),(1 ,3 ),( 2,1 ),( 3,1 )
$ There is no equivalence relation. Is it correct ? Thanks.","['relations', 'equivalence-relations', 'elementary-set-theory']"
606589,"If $E\subset\mathbb R^d$ has positive measure, then the set $E-E=\{x-y:x,y\in E\}$ contains an open Ball $B_{\epsilon}(0)$","If $E\subset\mathbb R^d$ has positive measure, then the set $E-E=\{x-y:x,y\in E\}$ contains an open Ball $B_{\epsilon}(0)$ with radius $\epsilon$ around the origin $\textbf {Hint}:$ Use the continuity of $f*g$ (convolution), with $f(x):=\mathbb 1_E(x)$ and $g(x):=1_E(-x)$ What is the sense of choosing $g(x):=1_E(-x)$ ? $\underline{My Attempt}$ $f*g=\int f(x-y)g(y)\ dy\overset{?}=\int\mathbb 1_E(x-y)\cdotp\mathbb 1_E(-y)\ dy\overset{or\le} =\int_{E-E} 1dy$ So, $f*g=\int_{E-E} 1dy$ remains to show that the integral above is nonzero. If $E$ has positive measure can we say it contains an open ball with radius $ar$ (s.t. $a>1$ ) let $g':=\mathbb 1_{B_{(0,ar)}}$ then $(g\ge g')$ $\Rightarrow$ $(f*g\ge f*g')$ and for $\lvert x\rvert<r$ $E-E=f*g\ge f*g'(x)=\int_{\lvert y\rvert<ar} f(x-y)\ dy\ge \int_{\lvert x-y\rvert<ar-r} f(x-y) dy=\int_{B_{(0,ar-r)}}\ dy>0$ Hence $E-E$ contains a ball with radius $ar-r$ centered at the origin ????","['measure-theory', 'real-analysis']"
606592,Hodge diamond of complete intersections,"Suppose we have a smooth complete intersection of hypersurfaces with degrees $d_1,...,d_r$ in some $\mathbb{P}^N$. This should be a surface and in certain situations a surface of general type. What can one say about the Hodge diamond? Or what is its Grothendieck group ?",['algebraic-geometry']
606598,Fitting ideals and Grassmannians,"Let $L$ be a locally free and finitely presented sheaf over a Noetherian scheme $X$ and $$ E\overset{\varphi}\to F \to L \to 0$$ a free presentation of $L$ , where $E$ and $F$ have finite ranks $n$ and $m$ . Moreover, let $$ \pi:G=G(n-k, E)\to X $$ be the Grassmannian bundle of $(n-k)$ -hyperplanes of sections of $E$ . For any integer $k$ we can associate to $L$ two objects: The ideal sheaf $\operatorname{Fitt}_k(L) \subset \mathcal{O}_X$ over $X$ , defined for example here . The ideal sheaf $\operatorname{Grass}_k(L) \subset \mathcal{O}_G$ over $G$ , defined below. Def: Consider the natural short exact sequence of sheaves over $G$ $$ 0\to S \to \pi^* E \to Q \to 0 $$ where $S$ and $Q$ are the universal subbundle and quotient bundle of $G$ . We define $\operatorname{Grass}_k(L)$ to be the zero locus of the morphism of sheaves $$ S\longrightarrow \pi^*E \overset{\pi^*\varphi} \longrightarrow \pi^* F $$ (i.e. the minimal ideal sheaf $I\subset\mathcal{O}_G$ such that $S/I\to \pi^* F/I$ is the zero morphism). Now it's time to ask my question. What is the relationship between $\operatorname{Fitt}_k(L)$ and $ \operatorname{Grass}_k(L)$ ? Notice that we can pull back $\operatorname{Fitt}_k(L)$ using $G\overset{\pi}\to X$ , and we get an ideal sheaf $\pi^* \operatorname{Fitt}_k(L) \subset \mathcal{O}_G $ . Maybe it's better to compare this one with $\operatorname{Grass}_k(L)$ ? Of course the above sheaves are not isomorphic, as they even have different fibers. Indeed if we choose coordinates we see that, for $W\in \pi^{-1}(x)$ , the fiber $$ \pi^* \operatorname{Fitt}_k(L)_W = \operatorname{Fitt}_k(L)_x $$ is generated by the $(n-k)\times (n-k)$ minors of the matrix representation of $\varphi$ , while the fibers $$ \operatorname{Grass}_k(L)_W \quad\text{and}\quad \operatorname{Grass}_k(L)_{W'} $$ are in general not the same for $W,W' \in \pi^{-1}(x)$ . If I understand correctly they are generated by the entries of the matrices corresponding to $\varphi_{\mid W}$ and $\varphi_{\mid W'}$ . Intuitively, the subscheme of $G$ corresponding to $\operatorname{Grass}_k(L)$ is kind a blow-up of the subscheme of $X$ corresponding to $\operatorname{Fitt}_k(L)$ : if $x \in X$ is a point where the rank of $\varphi_x$ is smaller than $t$ , it gets in some sense unwinded into couples $(x, W)$ where $W$ is a $t$ -plane in the kernel of $\varphi_x$ . Could you help me making my intuition precise? Any thought, comment or correction is really appreciated.","['algebraic-geometry', 'grassmannian']"
606603,Exercise 3.3.25 of Karatzas and Shreve,"This is the Exercise 3.25 of Karatzas and Shreve on page 163 Whith $W=\{W_t, \mathcal F_t; 0\leq t<\infty\}$ a standard, one-dimensional Brownian motion and $X$ a measurable, adapted process satisfying
  $$E\int_0^T|X_t|^{2m}dt<\infty$$
  for some real numbers $T>0$ and $m\geq1$, show that
  $$E\left|\int_0^TX_tdW_t\right|^{2m}\leq(m(2m-1))^mT^{m-1}E\int_0^T|X_t|^{2m}dt$$
  (Hint: Consider the martingale $\{M_t=\int_0^tX_sdW_s, \mathcal F_t; 0\leq t\leq T\}$, and apply Ito's rule to the submartingale $|M_t|^{2m}$.) By the hint, using Ito's rule I get
$$E|M_T|^{2m}=m(2m-1)E\int_0^T|M_t|^{2m-2}dt$$
I don't know how to continue. I tried to use Holder's inequality, but failed. Thanks very much!","['probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
606620,How to prove relation is asymmetric if it is both anti-symmetric and irreflexive,"Prove a relation is asymmetric if it is both anti-symmetric and irreflexive (anti-reflexsive). I tried to go from the definitions of the relations: Anti symmetric: $\forall x,y \, (xRy \land yRx \Rightarrow x=y )$ Irreflexsive: $\forall x\in A \ ,((x,x)\notin R)  $ Assymetric: $\forall x,y \in A \,(xRy \Rightarrow \lnot yRx ) $ But it doesn't get me anywhere... I also tried to think about proof by contraposition but I can't seem to be able to connect the definitions. Any help would be appreciated.","['relations', 'discrete-mathematics', 'elementary-set-theory']"
606644,Does there exist a $\nabla$-notation variant of the product rule applied to $\nabla[\mathbf{f}(\mathbf{x})\otimes\mathbf{g}(\mathbf{x})]$?,"This is a vector-calculus notation question; as a disclaimer, I am working in rectilinear space! For vector functions $\mathbf{f},\mathbf{g}:\mathbb{R}^n\rightarrow\mathbb{R}^n$, the chain rule for $\mathbf{f}(\mathbf{g}(\mathbf{x}))$ in $\nabla$-notation reads
$$\nabla\left[\mathbf{f}(\mathbf{g}(\mathbf{x}))\right]=\nabla\mathbf{f}(\mathbf{g}(\mathbf{x}))\cdot\nabla\mathbf{g}(\mathbf{x})$$ where the usual convention that $\nabla$ appends an additional index to an array has been used. My question is, is there a similar version for the product rule? Ie, 
$$\nabla[\mathbf{f}(\mathbf{x})\otimes\mathbf{g}(\mathbf{x})]=\mbox{}?$$ It is reasonably simple in indicial comma-derivative notation, whereupon we have $[f_i(\mathbf{x})g_j(\mathbf{x})]_{,k}=f_i(\mathbf{x})g_{j,k}(\mathbf{x})+f_{i,k}(\mathbf{x})g_{j}(\mathbf{x})$ which is reminiscent of the product rule in single-variable calculus. When I try rewriting this in $\nabla$-notation, the best I can come up with is 
$$\nabla[\mathbf{f}(\mathbf{x})\otimes\mathbf{g}(\mathbf{x})]=\mathbf{f}(\mathbf{x})\otimes\nabla\mathbf{g}(\mathbf{x})+\mbox{Transpose}[\nabla\mathbf{f}(\mathbf{x})\otimes\mathbf{g}(\mathbf{x}),\{1,3,2\}]$$
where the Transpose operator permutes the indices of an array in the same manner as implemented in Mathematica. I find this a bit unsightly, although still usable for handwritten work. Is there a less hideous way of expressing this identity using $\nabla$ notation, or is indicial notation the only way to express this identity without resorting to expressions involving array index permutations?","['multivariable-calculus', 'matrix-calculus', 'tensor-products']"
606646,Matrix derivative $(Ax-b)^T(Ax-b)$,"I am trying to find the minimum of $(Ax-b)^T(Ax-b)$ but I am not sure whether I am taking the derivative of this expression properly. What I did is the following:
\begin{align*}
\frac{\delta}{\delta x_i}\left(\sum_i \sum_j (A_{ij}x_i-b_i)(A_{ij}x_j-b_j)\right)&= \sum_j A_{ij}(A_{ij}x_j-b_j) + \sum_i A_{ij}(A_{ij}x_j-b_i) 
\end{align*} but I'm not quite sure if this is correct and what the derivate would then be. Any help is appreciated.","['matrices', 'matrix-calculus', 'calculus', 'derivatives']"
606666,Magnitude of $\Gamma(1/2+it)$,"I want to prove that $$|\Gamma(1/2+it)|=\sqrt{\frac{2\pi}{e^{\pi t}+e^{-\pi t}}}$$ My idea is to use the formula $\Gamma(s)\Gamma(1-s)=\pi/\sin \pi s$. Plugging in $s=1/2+it$ and taking absolute values, we get $$|\Gamma(1/2+it)\Gamma(1/2-it)|=\dfrac{\pi}{\sin(\frac{\pi}{2}+it\pi)}$$ How to continue from here?","['gamma-function', 'complex-analysis']"
606668,What are the conditions for a polygon to be tessellated?,"Upon one of my mathematical journey's (clicking through wikipedia), I encountered one of the most beautiful geometrical concept that I have ever encountered in my 16 and a half years on this oblate spheroid that we call a planet. I'm most interested in the tessellation of regular polygons and their 3D counterparts.
I've noticed that simple shapes like squares or cubes can be tessellated but not circles or spheres. Somewhere after hexagons, shapes lose that ability to be tessellated by only themselves. Although it is intuitively clear to me when  shape can be tessellated, I cant put it into words. Please describe to me, in a fair amount of detail, what the lesser sided shapes had that the greater sided shapes did not inorder to be tessellated.","['tessellations', 'geometry', 'algebraic-geometry', 'intuition']"
606678,Matrices such that $A^2=A$ and $B^2=B$,"Let $A,B$ be two matrices of $M(n,\mathbb{R})$ such that $$A^2=A\quad\text{and}\quad B^2=B$$
Then $A$ and $B$ are similar if and only if $\operatorname{rk}A = \operatorname{rk}B$. The first implication is pretty easy because the rank is an invariant under matrix similarity. But the second one is kind of baffling me. I thought of reasoning about linear mappings instead of matrices. My reasoning was, basically, that if we consider the matrix as a linear mapping with respect to the canonical basis ($T(v)$ for the matrix $A$, $L(v)$ for the matrix $B$) then we have $$T(T(v))=T(v)\quad\text{and}\quad L(L(v))=L(v)$$
for all $v \in V$. Then the mapping must be either the $0$ function or the identity function (if this was the case, then the rest of the demonstration would be easy). But I soon realised that equating the arguments of the function, in general, doesn't work. Thanks in advance for your help.","['matrices', 'linear-algebra']"
606679,Is there such a thing as partial integration?,"Recently in my mathematics courses I was taught partial derivatives, and I wondered if the reverse exists for integrals. This may sound like a stupid question, and it probably is, but let me explain: By the fundamental theorem of calculus: 
$$ \int \frac{d}{dx}f(x)~dx = f(x) $$
So is there an operator such that:
$$ \int \frac{\partial}{\partial x}f(x,y)~\partial x = f(x,y) $$
or is this complete bogus? What I am saying is that if the partial derivatives of a multi-variable equation is the slope of the line along the derivative axis, is there an operator, a ""partial integral"" that is the area under the curve along the integrated axis? Or is that just $\int f(x,y) ~dx$, since doing it over more than one axis requires $\iint f(x,y) dx dy$? Physically, this could be related to finding the x-component of the velocity given the acceleration function. Also, how stupid of a question is this?","['partial-derivative', 'calculus', 'integration', 'derivatives']"
606692,Prove that :$\frac{1}{a+b} +\frac{1}{b+c} +\frac{1}{c+a}\ge \frac{4}{a^2+7} +\frac{4}{b^2+7} +\frac{4}{c^2+7}$,"Let $a,b,c>0$ and satisfying $a^2+b^2+c^2=3$. Prove that :$\dfrac{1}{a+b} +\dfrac{1}{b+c} +\dfrac{1}{c+a}\ge \dfrac{4}{a^2+7} +\dfrac{4}{b^2+7} +\dfrac{4}{c^2+7}$","['inequality', 'algebra-precalculus']"
606696,Calculation of $\Gamma(n+\frac12)$,I want to show that $$\Gamma\left(n+\dfrac12\right)=\dfrac{1\cdot 3\cdot 5\cdots(2n-1)}{2^n}\sqrt{\pi}=2^{1-2n}\dfrac{\Gamma(2n)}{\Gamma(n)}\sqrt{\pi}.$$ I know that $\Gamma(\frac12)=\sqrt{\pi}$. The definitions of $\Gamma$ are such as $$\Gamma(z)=\lim_{n\rightarrow\infty}\dfrac{n^zn!}{z(z+1)\ldots(z+n)}$$ and $$\Gamma(z) = \lim_{n\to \infty} e^{-\gamma z}\frac1z\prod_{k=1}^n \left(1+\frac{z}{k}\right)^{-1}e^{z/k}$$ How can those help?,"['gamma-function', 'complex-analysis']"
606710,Morita-invariance of Hochschild (co)homology.,"Ok, I’m reading the paper Homology and cohomology of associative algebras. A concise introduction to cyclic homology by Christian Kassel, and on page 19 he says that Hochschild homology is Morita-invariant, by which he means that if $R$ and $S$ are two Morita equivalent rings then $$
  H_*(R,M) \cong H_*(S, Q \otimes_R M \otimes_R P)
$$ (here $H_*$ denotes Hochshild homology).
He then shows how $$
  H_*(M,M) \cong H_*(S,S) \,,
$$ and states that Hochschild cohomology groups are Morita-invariant in a similar way. I wanted to find a proof or reference for this? Just wanted to be completely sure about this and avoid any confusion, in what similar way are Hochschild cohomology groups Morita-invariant? Please be nice lol.","['homology-cohomology', 'abstract-algebra', 'homological-algebra', 'hochschild-cohomology', 'category-theory']"
606712,Factorial limit from gamma function calculation,"I want to show that $$\lim_{n\rightarrow\infty}\dfrac{\Gamma\left(n+\frac12\right)}{\sqrt{n}\Gamma(n)}=1$$ Using the formula for $\Gamma\left(n+\frac12\right)$ here , it reduces to $$\lim_{n\rightarrow\infty}\dfrac{(2n)!\sqrt{\pi}}{2^{2n}\sqrt{n}(n-1)!n!}=1$$ How to prove that?","['factorial', 'gamma-function', 'limits']"
606719,"Is there any good reason not to define $0^0=1$ , such as contradictions in algebra or arithmetic?","Math people: The title is the question: Is there any good reason not to define $0^0=1$ , such as contradictions in algebra or arithmetic? I searched for similar questions before I posted this question, and couldn't find any.  After I posted it,  I got some comments citing similar questions.  There is a similar question at What values of $0^0$ would be consistent with the Laws of Exponents? .  I checked some of the other questions in the links in the comments and the links posted with those links.  There is a closer match at How to define the $0^0$? That question was closed as a duplicate, but the older, duplicated question was not identified.  I could not find a convincing answer anywhere to my essential question: ""does defining $0^0=1$ lead to contradictions in algebra and arithmetic?"" I'll leave it up to others to decide whether my question is a duplicate.  If it is, maybe you can close this question and give a better (in my opinion) answer to one of the older questions. Let me get one thing out of the way up front: yes, I know ""$0^0$"" is an indeterminate form.  That is, if $f$ and $g$ are real-valued functions with $f(t) \to 0^+$ as $t \to 0$ and $g(t)\to 0$ as $t \to 0$, then you don't know what $\lim_{t\to 0}f(t)^{g(t)}$ is, or even whether exists, without more information.  I don't consider this a good reason to declare that $0^0$ itself must be considered undefined.  I know many people will disagree with me here.  I expect at least one answer and some comments arguing why this is a good reason for $0^0$ to be considered undefined.  Everyone is entitled to their opinion, and you are free to leave such an answer.  I will not attempt to change your mind, beyond what I write in this question. If you define $f(x,y) = x^y$, then $f$ cannot be continuous on $[0,\infty) \times \mathbb{R}$ no matter what value, including $1$, you assign to $f(0,0)$.  But why should every function have to be continuous? If the mathematical community ever does come to the consensus that $0^0=1$, and I were teaching calculus students about limits involving indeterminate forms, I probably would not even mention the question of whether $0^0$ itself had a value, because it probably just confuse the students.  They probably wouldn't even notice the omission. To me, a ""good reason"" not to define $0^0=1$ would be if this definition resulted in a contradiction, when used in expressions involving multiplication and exponentiation of real numbers and the rules used to simplify such expressions.  Here is an attempt to produce such a contradiction: assuming $0^0=1$, $(0^0)^2=1^2=1$, and $(0^0)^2=0^{(0*2)}=0^0=1$.  No contradiction.  In constrast, if you define $0/0 = 1$ and you want the associative property to hold (a reasonable expectation), then you can derive the contradiction $1=0/0=(2*0)/0=2*(0/0)=2*1=2$. It just occurred to me that there is another good reason for not declaring officially that $0^0$ must always equal $1$: if defining $0^0=0$ does not lead to contradictions in algebra or arithmetic, either. I am not claiming $0^0 = 0/0$.  Of course you can never divide by zero, or raise zero to a negative power. Of course, when people use power series, they use $0^0=1$ all the time, and no one complains.  I have read that ""$0^0=1$"" is used often in combinatorics, but I don't know much about combinatorics. Based on what I have seen in the older questions, their answers, and the answers and comments to this question, it seems that no one has discovered any way in which defining $0^0$ to be $1$ leads to contradictions when using the usual rules of multiplication and exponentiation.  It also seems that defining $0^0$ to be $0$ does not lead to such a contradiction. So I'm guessing it is impossible to produce such a contradiction.  But I have never heard of anyone wanting to define $0^0$ as $0$.",['algebra-precalculus']
606726,Nilpotent/invertible polynomial over commutative ring. [duplicate],"This question already has answers here : Nilradical and Jacobson's radical. [duplicate] (2 answers) Closed 10 years ago . Let $p(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0$ be a polynomial over a commutative ring $R$ . Prove that (a) $p$ is unit in $R[x]$ iff $a_0$ is unit and $a_1,a_2,\ldots,a_n$ are nilpotent in $R$ . (b) $p$ is nilpotent in $R[x]$ iff $a_0,a_1,\ldots,a_n$ are nilpotent in $R$ . I have got no lead in part (a) and in part (b) I have proved the if part.
for the only if part can we use the fact that a polynomial is vanish everywhere iff all its coefficients are $0$ ?","['commutative-algebra', 'ring-theory', 'abstract-algebra', 'polynomials']"
606727,Prove that $P'$ has $n-1$ distinct real roots,"Suppose a polynomial $P$ of degree $n$ has $n$ distinct real roots then $P'$ (the derivative of $P$) has $n-1$ distinct real roots. Proof by Induction: Base case: For $n=1$, $P_1 (x)=a_0+a_1x, a_1\neq 0$ has $1$ real (distinct) root, $x=\frac{-a_0}{a_1}$. Then $P_1 ' (x)=a_1$ has $1-1=0 $ real distinct root. Induction step: Assume that the claim holds for some $n\in\mathbb{N}, n>1$. That is, $$P_n (x) = a_0+a_1x+a_2x^2+...+a_nx^n$$ has $n$ distinct real roots implies that $$P_n'(x)=a_1+2a_2x+3a_3x^2+...+na_nx^{n-1}$$ has $n-1$ real distinct roots. Now, suppose that for $n+1$, $$P_{n+1} (x) = a_0+a_1x+a_2x^2+...+a_nx^n+a_{n+1}x^{n+1}$$ has $n+1$ real distinct roots.  Claim is that $P_{n+1}'(x)$ has $n$ real distinct roots. We know: $$P_{n+1}'(x)=a_1+2a_2x+3a_3x^2+...+na_nx^{n-1} +(n+1)a_{n+1} x^n$$. I know by Induction Hypothesis that $$a_1+2a_2x+3a_3x^2+...+na_nx^{n-1}$$ has $n-1$ real distinct roots. But I cannot think how to use this fact to argue the case for $P_{n+1}'(x)$.","['polynomials', 'analysis']"
606732,Products of ideals is an ideal and comaximal ideals,"Let $I$ and $J$ be two ideals in a ring $R$. Prove that $IJ$ is an ideal. Prove that if $R$ is a commutative ring with two ideals satisfying $I+J=R$ then $IJ=I\cap J$. I could prove that $IJ$ has an identity, inverse as viewed over addition. I have also prived left and right multiplication property but I am unable to proof the closure over addition.","['ring-theory', 'ideals', 'abstract-algebra']"
606737,How the step of squaring the deviations in Standard Deviation overcomes the drawback of ignoring the signs of mean deviation.,"$$\text{Mean deviation from mean}=\frac1N\sum_{i=1}^nf_i|x_i-\bar x|$$and $$\text{Standard Deviation ($\sigma$)}=\sqrt{\frac1N\sum_{i=1}^nf_i(x_i-\bar x)^2}$$
  The step of squaring the deviations in SD overcomes the drawback of ignoring the signs of mean deviation. How is the problem overcome? In the SD too, we ignore the signs by squaring, aren't we?",['statistics']
606746,Obtuse-angled triangle equation,Give a obtuse-angled triangle and the obtuse angle is 105º. Find n such that the acute angles be the roots of the equation. $$3\sec(x)+n\left(\frac{1}{\sec(x)}-\frac{1}{\csc(x)}\right)=3\left(\frac{1}{\sec(x)}+\frac{1}{\csc(x)}\right)$$,"['trigonometry', 'triangles']"
606765,Try to solve the following differential equation: $2y''=e^y$,"I am trying to solve this equation:
$$2y''=e^y$$
No $x$ in equation so: 
$$y''=P'P , y'=p
\\
\implies 2P'P=e^y$$ 
After the integrating on both sides I got:
$$P^2=e^y$$
and back to $y$:
$$y'2=e^y
\\
\implies y'=\sqrt[]{e^y}$$
and now how I solve the integral? I hope I didn't mistake in my way
thanks.","['ordinary-differential-equations', 'integration']"
606779,Prove that these 3 points are in a straight line,"$\triangle ABC$ is equilateral with a circle $\omega$ inscribed in it. MN is a tangent of $\omega$ and it intersects $AC$ and $BC$ at points $M$ and $N$ respectively. $AM_1=MC$ and $BN_1=CN$. $D,E,F$ touch the circle. $O$ is the center of $\omega$ and $OH_1 = r$. Prove that $M_1N_1$ intersects the center of $\omega$. I've tried adding some additional segments (as you can see on the 2nd image). I've created $AR$ such that $AR=CN \Rightarrow MN=M_1R$ and $BP$ such that $BP=MC \Rightarrow PN_1=MN$. $\triangle CMN = \triangle AM_1R = \triangle BN_1P$. And if I want to prove that $M_1R$ and $N_1P$ touch $\omega$, I could say that it's because of symmetry (tell me if I'm wrong). That's all I've tried so far. Solving this problem would be equivalent to finding out that $M_1N_1$ bisects both the angle $\angle PN_1N$ and $\angle RM_1M$.","['geometry', 'circles']"
606789,Get from point A to point B efficiently.,"This is a question I thought about while crossing the street. Suppose you're standing at the bottom-left corner of a rectangle. Your goal is moving to the the top-right corner, efficiently, Considering the following rules: As you get closer to the center it's becoming more dangerous. You want to get as fast as possible to the top-right corner. Let $a \in (0,1)$ the importance of rule #1. Let $b \in (0,1)$ the importance of rule #2. So, if $a=0.5$ and $b=0.5$ then your path would be a straight line between the two corners. What would be the general function for the curve? (the path) for any $a,b$","['geometry', 'puzzle', 'calculus', 'graph-theory']"
606794,How many times are the hands of a clock at $90$ degrees.,"How many times are the hands of a clock at right angle in a day? Initially, I worked this out to be $2$ times every hour. The answer came to $48$ . However, in the cases of $3$ o'clock and $9$ o'clock, right angles happen only once. So the answer came out to be $44$ . Is the approach correct?","['geometry', 'puzzle']"
606803,Number of relations on a set with n elements,"Let $A$ be a set with $n$ elements. How many (1)symmetric, (2)anti-symmetric and (3)asymmetric relations are there on $A$ ? (4)How many linear relations are there ? Here's what I did: For symmetric, for every $n$ there are $n$ options, multiply all of them and remove all the duplicates we'll get $n^n-n$ For antisymmetric, there can only be relations of one kind: $(x,x)$ so we'll get $n$ relations. For asymmetric, I start to run into trouble because for every relation there are fewer possible relations. I think there are $(n-1)+(n-2)+...+(n-n+1)+(n-n)$ relations. About linear relations, I think it's $n^n$ . Is it correct ? Thanks.","['relations', 'discrete-mathematics']"
606809,A strange application of the Heine-Borel lemma (Ahlfors),"In Ahlfors' Complex Analysis text, pages 289-290, the author discusses analytic continuation along arcs. Among other things, he proves the equivalence with analytic continuation using a chain of function elements $(f_k ,\Omega_k)$. The fact that two function elements being related by a chain of direct analytic continuations implies that an appropriate analytic continuation along an arc is possible is clear to me. However, in page 290 Ahlfors is trying to prove the converse. Namely, that the arc from the analytic continuation can be ""followed"" by a chain of direct analytic continuations, from the initial point of the arc to its endpoint. His words are: Conversely, if $\bar{\gamma}$ is given, we can find a chain of direct analytic continuations which follows the arc $\gamma$ in the same way as in the preceding construction. In fact, by Heine-Borel's lemma the parametric interval $[a,b]$ can be subdivided into $[a,t_1], [t_1,t_2], \dots , [t_{n-1},b]$ such that $\bar{\gamma}(t)$ = $(f_k,\gamma(t))$ in $[t_{k-1},t_k]$ for suitably chosen function elements $(f_k,\Omega_k)$. Although $(f_k,\Omega_k)$ and $(f_{k+1},\Omega_{k+1})$ need not be direct analytic continuations of each other, they are at least direct continuations of their common restrictions to a neighborhood of $\gamma(t_k)$. I'm having a hard time understanding this. As far as I know the Heine Borel lemma characterises compact subsets of Euclidean space alone as bounded and compact ones. The only set I see here which lies in Euclidean space is the parameter interval $[a,b]$ of the arc. But, even if that's where the lemma is applied, the outcome should be a finite open subcover of $[a,b]$, while the intervals $\{[t_{k-1},t_k]\}$ are only closed. Can anyone please help me understand this proof? Thanks! P.S. Here $\bar{\gamma}:[a,b] \to \mathfrak{S_0}(\mathbf{f})$ takes values on some Riemann surface, and $\gamma= \pi \circ \bar{\gamma}:[a,b] \to \mathbb C$ is its projection.","['sheaf-theory', 'riemann-surfaces', 'complex-analysis']"
606875,Combining set builder and summation notation,"What's the best notation for the sum of a subset? Given $S = \{1,2,3,4,5,6,7\}$, let's say I want to find the sum of the squares of elements less than 4. Initially I used the following notation:
$$\sum_{\{i \in S:i<4\}}i^2$$ But I thought there is missing information, since only the set is provided. Here's alternative #1:
$$\sum_{i\in\{x \in S:x<4\}}i^2$$ That seems verbose, so here's alternative #2, with some reordering:
$$\sum\{i^2:i \in S:i <4\}$$ Which of the above is best, and is there an even better notation?","['notation', 'summation', 'elementary-set-theory']"
606889,Limit $(t-1)\zeta(t)$ as $t\rightarrow 1^+$,"Show that $\lim_{t\rightarrow 1^+}(t-1)\zeta(t)=1$. For $t>1$, we can use the definition $\zeta(t)=\sum_{n=1}^\infty \dfrac{1}{n^t}$, so it is approximately $\int_1^\infty \dfrac{1}{x^t}dx$. How can this lead to the limit?","['riemann-zeta', 'integration', 'limits']"
606891,Finding $\lim_{x \to 0^+} x^{\sin x}$,Find $\displaystyle \lim_{x \to 0^+} x^{\sin x}$ This is how I started but I get to a dead end fast: $\displaystyle\lim_{x \to 0^+} e^{\ln x^{\sin x}}=\lim_{x \to 0^+} e^{\sin x \ln x}$ I guess I can bound it below with $e^0=1$ but I have no idea with what from above. Any advice on how to continue ? PS: we can't use integration/derivation nor Taylor's theorem because we haven't covered that.,"['calculus', 'limits']"
606901,How to express a matrix as a product of two symmetric matrices?,"Let $A$ be a matrix and $J$ its Jordan canonical form. How can one express $A$ as a product of two symmetric matrices? I expressed $J$ as a product of two symmetric matrices: block by block in the following manner: $$\begin{bmatrix}\lambda&1 & \\ &\lambda&1 \\ & &\lambda \end{bmatrix} =\begin{bmatrix} & & 1\\ &1& \\1& & \end{bmatrix}\begin{bmatrix} & & \lambda\\ &\lambda&1 \\\lambda& 1& \end{bmatrix}$$
and then I was trying to make use of the fact that $A$ and $A^t$ are similar. Yet I got stuck. Any hints are hugely appreciated.","['jordan-normal-form', 'matrices', 'linear-algebra', 'block-matrices']"
606917,"""Well defined"" function - What does it mean?","What does it mean for a function to be well-defined?
I encountered this term in an exercise asking to check if a linear transformation is well-defined.","['linear-algebra', 'transformation', 'functions']"
606937,Meromorphic function at conjugate,"Let $f$ be a meromorphic function. Is it true that $f(\bar{z})=\overline{f(z)}$ for all complex numbers $z$? A meromorphic function can be written as a ratio of two holomorphic functions. Moreover, at any point $s\in\mathbb{C}$, the function $f$ can be expressed as a Laurent series in a neighborhood of $s$. But still, the Laurent series is different at $s$ than at $\bar{s}$. How can we show the result?",['complex-analysis']
606955,Estimate of $n$th prime,"There is a result that if $p_n$ is the $n$th prime, then $p_n\sim n\log n$ as $n\rightarrow\infty$. I wonder: Is it a direct consequence of the prime number theorem $\pi(x)\sim x/\log x$? The theorem says that there are approximately $n/\log n$ primes less than or equal to $n$. So there are approximately $n$ primes less than or equal to $n\log n$. So $p_n$ is approximately $n\log n$. But I'm having trouble turning this into a formal argument. We have $\lim_{n\rightarrow\infty}\dfrac{\pi(n)\log n}{n}=1$. How would it show that $\lim_{n\rightarrow\infty}\dfrac{p_n}{n\log n}=1$?","['prime-numbers', 'limits']"
606970,"Coloring $[0,1]$.","Here is an interesting coloring problem that I am unable to prove. Any help is appreciated. Can we partition the closed interval $[0,1]$ into finitely many intervals, such that each sub-interval is colored red or blue in an alternating fashion, so that $$\int_{\text{red}}P(x)dx=\int_{\text{blue}}P(x)dx$$ for all polynomials $P$ with a fixed degree $n$?","['coloring', 'calculus', 'integration']"
606985,What is the idea behind the $^2$ in the mean squared error?,Mean Squared Error: $\operatorname{MSE}=\frac{1}{n}\sum_{i=1}^n(\hat{Y_i} - Y_i)^2.$ <-- what is the purpose of the '$^2$'  in here? Mean Absolute Error: $\mathrm{MAE} = \frac{1}{n}\sum_{i=1}^n \left| f_i-y_i\right| =\frac{1}{n}\sum_{i=1}^n \left| e_i \right|$,"['probability-theory', 'probability']"
607010,Prove that $\mu\left(\cup_{k=1}^\infty A_k\right)=\sum_{k\ge1}\mu(A_k)$,"Suppose that the measurable sets $A_1,A_2,...$ are ""almost disjoint"" in the sense that $\mu(A_i\cap A_j) = 0$ if $i\neq j$. Prove that $$\mu\left(\cup_{k=1}^\infty A_k\right)=\sum_{k\ge1}\mu(A_k)$$ Conversely, suppose that the measurable sets $A_1,A_2,...$ satisfy $$\mu\left(\cup_{k=1}^\infty A_k\right) = \sum_{k=1}^\infty\mu(A_k)<\infty$$ Prove that the sets are almost disjoint. Here $\mu(A)$ denotes the Lebesgue measure of $A$.
I know that if the sets $S_1,S_2,...$ are all measurable, then $$\mu(\cup_{k=1}^\infty S_k)\le\sum_{k=1}^\infty \mu(S_k)$$
and equality holds if the sets are disjoint. How can I accommodate this for almost disjoint sets?","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-measure', 'geometric-measure-theory']"
607015,Show that $\left( g\circ h\right) ^{-1}=h^{-1}\circ g^{-1}$,"Given that $f\left( x\right) =\dfrac {\log \left( x\right) }{1-\log \left( x\right) }$ , $ g\left( x\right) =\dfrac {x}{1-x}$ , $h\left( x\right) =\log \left( x\right) $ show: $f=g\circ h$ and that $\left( g\circ h\right) ^{-1}=h^{-1}\circ g^{-1}$ Showing that $f=g\circ h$ : $ g\left( x\right) =\dfrac {x}{1-x}$ , substituting $h\left( x\right) =\log \left( x\right) $ gives $g\left( log\left( x\right) \right) =\dfrac {\log \left( x\right) }{1-\log \left( x\right) }=g\circ h$ therefore $f=g\circ h$ Showing that $\left( g\circ h\right) ^{-1}=h^{-1}\circ g^{-1}$ : $f^{-1}\left( x\right) =10^{\left( \dfrac {x}{x+1}\right) }$ $g^{-1}\left( x\right) =\dfrac {x}{x+1}$ $h^{-1}\left( x\right) =10^{x}$ As $\left( g\circ h\right) ^{-1}=f^{-1}$ , $f^{-1}=h^{-1}\circ g^{-1}$ . Given that $f^{-1}\left( x\right) =10^{\left( \dfrac {x}{x+1}\right) }$ , $\left( h^{-1}\circ g^{-1}\right) \left( x\right) =10^{\left( \dfrac {x}{x+1}\right) }$ , showing this: $h^{-1}\left( x\right) =10^{x}$ , substituting $g^{-1}\left( x\right) =\dfrac {x}{x+1}$ gives $\left( h^{-1}\circ g^{-1}\right) \left( x\right) =10^{\left( \dfrac {x}{x+1}\right) }$ I'm sorry if that looks convoluted, I've demonstrated that I can do as the question has asked but these are my actual questions: $\left( g\circ h\right) ^{-1}=h^{-1}\circ g^{-1}$ , why in general is this true? Why do the h and g swap places in the last equality? (That's really what's tripping me up). Shouldn't it be: $\left( f\right) ^{-1}=\left( g\circ h\right) ^{-1}=g^{-1}\circ h^{-1}$ . What is the intuition behind this? Furthermore how can an inverse be applied to both sides? I'd be forever grateful if someone could explain all this, bearing in mind I'm studying at a pre-calculus level , I hope I've made sense. Thank you!","['algebra-precalculus', 'functions']"
607023,Generator of End(V),"If V is a finite-dimensional vector space of dimension n and G⊂End(V) such that G generates End(V) meaning that any element of End(V) is expressible as a linear combination of products of a number of elements of G, what is the minimal possible number of elements in G?","['vector-spaces', 'linear-algebra', 'group-theory']"
607060,How generalize the alternating Möbius function?,"Here is what I want to do, I have this matrix: $$\displaystyle T = \begin{bmatrix} +1&+1&+1&+1&+1&+1&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&-2&+1&+1&-2&+1 \\ +1&-1&+1&-1&+1&-1&+1 \\ +1&+1&+1&+1&-4&+1&+1 \\ +1&-1&-2&-1&+1&+2&+1 \\ +1&+1&+1&+1&+1&+1&-6 \end{bmatrix}$$ that I have posted many times before, and which has the definition: $$T(n,k)=a(GCD(n,k))$$ where $a$ is the Dirichlet inverse of the Euler totient function and $GCD(n,k)$ is the Greatest Common Divisiors of $n$ and $k$. I know that the sequence of primes is: $$-\Lambda (n) (\mu (n)) = 0,\log (2),\log (3),0,\log (5),0,\log (7),0,0,0,\log(11),0...$$ where $(\mu (n))$ is the Möbius function, and $\Lambda (n)$ is the von Mangoldt function. The von Mangoldt function can be calculated as a limit of the matrix $T$: $$\Lambda (n) = \sum\limits_{k=1}^{\infty} \frac{T(n,k)}{k}$$ So going about this problem this way I intend therefore to multiply elementwise the Mobius function with the elements in $T(n,k)$: $$\mu(n) \sum\limits_{k=1}^{\infty} \frac{T(n,k)}{k}$$ After an OEIS search I found, by combining two sequences, that: $$\left(\sum\limits_{n=1}^{\infty} \frac{(-1)^{(n+1)}\mu(n)}{n^s}\right)^{-1}$$
$$ =\lim_{S\to \text{s}} \, \left(\sum _{b=0}^{\infty } \left(\sum _{a=0}^{\infty } \left(\frac{1}{\left((2\cdot 2)^a (2 b+1)\right)^S}-\frac{1}{\left(2 (2\cdot 2)^a (2 b+1)\right)^S}\right)\right)\right)$$ and after another OEIS search numerical evidence suggests that this is equal to: $$=\frac{\left(2^s-1\right) \zeta (s)}{2^s+1}$$ where $\zeta (s)$ is the Riemann zeta function. Well and fine, but how about the rest? I guess it will blow up when I reach $$n=6$$ since: $$\Lambda(6)^{-1} = \infty$$ but I would like to try anyways for $n=3$. 
$$\mu(n) \sum\limits_{k=1}^{\infty} \frac{T(n,k)}{k}$$
This is my guess: $$\mu(n) \sum\limits_{n=1}^{\infty} \frac{T(n,3)}{n} = \frac{\left(3^s-2\right) \zeta (s)}{3^s+1}$$ but it doesn't fit numerically very well. Also the switch between $n$ and $k$ confuses me. Can you help me find the sum for any value of $k$ and $n$?","['prime-numbers', 'riemann-zeta', 'number-theory']"
607061,"Which is bigger, $1+3\sqrt{2}$ or $3\sqrt{3}$?","Which is bigger, $a = 1+3\sqrt2$ or $b = 3\sqrt3$? To find out result, I am doing: $(3\sqrt3)^2-(1+3\sqrt2)^2=8-2\sqrt{18}$. But how can I find if the value of $8-2\sqrt{18}$ is positive or negative? Thank you.",['algebra-precalculus']
607070,A family has two children. One child is a girl. What is the probability that the other child is a boy? [duplicate],"This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 10 years ago . My initial thought process: Sample space: GG, GB, BG, BB. I then crossed out BG because it's the same as GB because order doesn't matter here. And because we know one is a girl, there leaves two possibilities left. If the other is a boy, the probability should be 1/2, much like how they deduced it Finding probability of other child also being a boy . However, I was told by my teacher that the answer is not 1/2 . I'm wondering if any of you guys can see a way in how the question is worded so that it's not 1/2... I don't think there's any other factors?",['probability']
607077,Prove cardinals equality,"Let $x,c$ two cardinals, such that: $1\lt x \le c$ $c^2 = c$ Prove: $x^c = 2^c$ So, from the second statement, we know $c$ is infinite, because it cannot be true for a finite cardinal. I know the ""tools"" to prove it must be: CBS theorem cardinals arithmatic squeezing theorem I tried playing with these, but all I got is bunch of inequalities didn't lead to the answer. EDIT :
What I did so far: $$\begin{array}{l}x \le b\\{2^x} \le {2^b}\\{\left( {{2^x}} \right)^b} \le {\left( {{2^b}} \right)^b}\\{2^{xb}} \le {2^{bb}}\end{array}$$ I'm pretty much stuck at this point.","['cardinals', 'elementary-set-theory']"
607103,Prove $\sin^2\theta + \cos^2\theta = 1$,How do you prove the following trigonometric identity: $$ \sin^2\theta+\cos^2\theta=1$$ I'm curious to know of the different ways of proving this depending on different characterizations of sine and cosine.,['trigonometry']
607105,"Upper bound for $S_{n,r}=\sum_{i=0}^n \binom{n}{i} \left(\frac{\binom{n}{i}}{2^n}\right)^{r}$.","I am trying to get an upper bound for $$S_{n,r}=\sum_{i=0}^n \binom{n}{i} \left(\frac{\binom{n}{i}}{2^n}\right)^{r} .$$ Any hints would be greatly appreciated. I thought of using Stirling's approximation but I worried that doesn't give good bounds for binomial coefficients over the full range.","['upper-lower-bounds', 'sequences-and-series', 'binomial-coefficients', 'combinatorics']"
607141,Fourier transform of $f(x)=\frac{1}{e^x+e^{-x}+2}$,"Let $$f(x)=\large \frac{1}{e^x+e^{-x}+2}$$ Compute the Fourier transform of $f$. We can factor the denominator to get $$f(x)=\frac1{(\exp(x/2)+\exp(-x/2))^2}=\frac1{(2\cosh(x/2))^2}$$ I'm thinking of using residue from complex analysis. To find the singularity, we have $$\exp(x/2)=-\exp(-x/2)\iff\exp(x)=-1$$ We know $\exp(i\pi)=-1$. So the singularities are $i\pi+2\pi k i $.","['fourier-analysis', 'integration', 'real-analysis', 'analysis', 'complex-analysis']"
607154,Forms in the ideal generated by linear forms.,"I'm trying to show the following: Let $F_1,\dots,F_m$ be forms of degree one in $K[x_1,\dots,x_{n+1}]$ with $K$ an algebraic closed field and $m\leq n$. Then all the forms of the same degree can not be in the ideal $I=(F_1,\dots,F_m)$, for all degrees. I showed the result for degree one, by means of this simple argument: If a form $G$ of degree $n$ is in $I$ then $G=\sum_{i=1}^m G_iF_i$ with $G_i\in K[x_1,\dots,x_{n+1}]$ then $$ G=\sum_{i=1}^m G_iF_i=\sum_{i=1}^m\sum_{j}G_{j,i}F_i $$ With $G_{k,l}$ a form of degree $k$. By uniqueness of the descomposition in forms, and the fact that $G_{k,l}F_l$ are forms; we obtain: $$ G=\sum_{i=1}^m G_{n-1,i}F_i $$ It means that if a form of some degree is generated by these polynomials, iff is a combination of the polynomials with forms of one degree less. Thus in the case of degree one, we get that all the forms of degree one are in $I$ iff all the forms of degree one are in the $K-$vector space generated by the $F_i$. As $\dim_K\langle F_1,\dots,F_m\rangle\leq m\leq n$ and we have that the dimension of the forms of degree one is $n+1$ over $K$; is not possible that all the forms of degree one are in $I$. I tried with this argument to show the result for larger degrees, but without success. Lastly, I know that the result is true because it's equivalent to a simple problem of elementary algebraic geometry, namely: In the projective space $\mathbb P^n$ the intersection of $m$ hyperplanes is not empty if $m\leq n$; which is solved easily with Cramer's rule. I would be very grateful if someone gives an answer that follows the above path. Thank you.","['commutative-algebra', 'algebraic-geometry']"
607185,Existence of a certain subspace in a vector space,"Let $V$ be a vector space, and $W_1, W_2, \ldots, W_m \subset V$ its $k$-dimensional subspaces. Every their pairwise intersection is $k-1$-dimensional (for all $i \neq j$, $\dim (W_i \cap W_j) = k - 1$). Show that there is either: a $k-1$-dimensional subspace $U \subset W_i$ in all $W_i$, or a $k+1$-dimensional subspace $Z \supset W_i$ containing all $W_i$. My try: First, notice that $\dim W_i < \dim V$, since otherwise $W_i = V$. Thus there is always room for a $Z$. $m=1$ is trivial. For $m=2$ there is definitely a set $U = W_1 \cap W_2$, $\dim U = k - 1$. There is also a set $Z = W_1 + W_2$, since we can consider the basis $u_1, u_2, \ldots, u_{k-1}$ in $U$ add to it two vectors (one to complement the basis in $W_1$ and the other for $W_2$) and obtain a basis of $Z$. So for $m=2$ there are both $U$ and $Z$. For $m=3$ things get interesting. We have k-dimensional $W_1, W_2, W_3$, and their pairwise intersections are all $k-1$-dimensional. $U_1 = W_2 \cap W_3$, $\dim U_1 = k - 1$ $U_2 = W_3 \cap W_1$, $\dim U_2 = k - 1$ $U_3 = W_1 \cap W_2$, $\dim U_3 = k - 1$ $U = W_1 \cap W_2 \cap W_3$, $\dim U = k - 1 - x$ The same can be said about the sums instead of intersections: $Z_1 = W_2 + W_3$, $\dim Z_1 = k + 1$ $Z_2 = W_3 + W_1$, $\dim Z_2 = k + 1$ $Z_3 = W_1 + W_2$, $\dim Z_3 = k + 1$ $Z = W_1 + W_2 + W_3$, $\dim Z = k + 1 + y$ The problem is, essentially, to show that either $x=0$ or $y=0$. It is probably also true that $x \leq 1$ and $y \leq 1$, but I have no idea how to prove that either. So, that's where I got stuck. The picture I have in mind is the sequence of increasing subspaces $(U, U_i, W_i, Z_i, Z)$ with expanding basises, but their basises expand in some complicated manner I do not fully comprehend. I suppose that the method for solving the case $m=3$ could be applied to all other $m$s, probably resulting in a proof by induction. Any help would be appreciated.","['vector-spaces', 'linear-algebra']"
607198,Odd and even square roots of $z^2-1$,"This is a very interesting exercise (provided that it is correct). Find two holomorphic functions $\,f_1: \Omega_1\to\mathbb C$ and $f_2:\Omega_2\to\mathbb C$, which are both square roots of $z^2-1$, with maximal domains (i.e., they can not be extended analytically any further), and $f_1$ is even while $f_2$ is odd. The most interesting part is that $f_2$ is an odd function, and therefore, it can not be thought of as a composition of $\sqrt{}$ and $z^2-1$, which is even!","['radicals', 'analyticity', 'complex-analysis', 'analysis']"
607234,Find $f$ if $f(f(x))=\sqrt{1-x^2}$,"Find $f$ if $f(f(x))=\sqrt{1-x^2} \land [-1; 1] \subseteq Dom(f)$
$$$$Please give both real and complex functions. Can it be continuous or not (if f is real)",['analysis']
607269,Prove $1 + \tan^2\theta = \sec^2\theta$,Prove the following trigonometric identity: $$1 + \tan^2\theta = \sec^2\theta$$ I'm curious to know of the different ways of proving this depending on different characterizations of tangent and secant.,"['trigonometry', 'alternative-proof']"
607293,"Show a convergent series $\sum a_n$, but $\sum a_n^p$ is not convergent","$p>1$ is a integer, Show  a  convergent series $\sum\limits_{n=1}^\infty a_n$, $a_n\in\Bbb R$, such that the series $$\sum_{n=1}^\infty a_n^p$$ is divergent p.s. If $p>1$ is not an integer and $a_n\lt0$, it will be difficult to define $a_n^p$(complex analysis?), so we only consider $p\in\Bbb Z$","['sequences-and-series', 'calculus', 'examples-counterexamples', 'real-analysis']"
607324,Prove that every nonzero prime ideal is maximal in $\mathbb{Z}[\sqrt{d}]$,"$d \in \mathbb{Z}$ is a square-free integer ( $d \ne 1$ , and $d$ has no factors of the form $c^2$ except $c = \pm 1$ ), and let $R=\mathbb{Z}[\sqrt{d}]= \{ a+b\sqrt{d} \mid a,b \in \mathbb{Z} \}$ . Prove that every nonzero prime ideal $P \subset R$ is a maximal ideal. I have a possible outline which I think is good enough to follow. I think that we need to first prove that every ideal $I \subset R$ is finitely generated. So if $I$ is non-zero, then $I \cap \mathbb{Z}$ is a non-zero ideal in $\mathbb{Z}$ . Then I need to find $I \cap \mathbb{Z} = \{ xa \mid a \in \mathbb{Z} \}$ for some $x \in \mathbb{Z}$ . That way if I let $J$ be the set of all integers $b$ such that $a+b\sqrt{d} \in I$ for some $a\in \mathbb{Z}$ , then if there exists a integer $y$ such that $J=\{ yt \mid t\in \mathbb{Z} \}$ , then there must exist $s \in \mathbb{Z}$ such that $s+y\sqrt{d} \in I$ . Then all I need to show is that $I = ( x,s+y\sqrt{d} )$ . Now I need to derive that the factor ring $R / P$ is a finite ring without zero divisors, also finite, then since every finite integral domain is a field, every prime ideal $P \subset R$ is a maximal ideal, then I'll be done.","['ring-theory', 'prime-factorization', 'abstract-algebra', 'ideals', 'field-theory']"
607329,Example of uniformly continuous function on R that is not differentiable on all of R,"Give an example of a uniformly continuous function $g:\mathbb{R} \rightarrow \mathbb{R}$ that is not differentiable on all of $\mathbb{R}$. Hmm. I can't think creatively enough for one! Would f(x) = |x| on (-1,1) be an example? Certainly not differentiabe, but it if uniformly continuous? Another one: Give an example of a sequence of continuous functions $f_n: \mathbb{R}\rightarrow \mathbb{R}$ whose pointwise limit $f:\mathbb{R} \rightarrow \mathbb{R}$ exists, but is discontinuous.","['continuity', 'derivatives', 'real-analysis', 'uniform-continuity']"
607348,Line intersecting three (or four) given lines,"How can I find a fourth line $L$ that intersects three given lines $L_1$, $L_2$, $L_3$ in 3D space? We can assume that $L_1$, $L_2$, $L_3$ are in ""general position"", so no two of them are coplanar, etc. I'm not even sure that three lines is enough to uniquely define $L$, actually. If three lines is not enough, how many do I need? The question is related to this one . Specifically, see idea #4 in my list of suggested approaches. It requires finding a line that intersects with a few given ones. Edit : Apparently, I need four lines, not three, to uniquely define $L$. So, how can I construct a fifth line that interesects four given ones? I found this paper , and this one , but they are both difficult for me to read. Surely there must have been solutions before 2008, and, if so, I'm hoping that these are easier to understand.",['geometry']
607435,How to evaluate this definite integral $\int_0^2(1-x^2)^\frac{1}{3}~dx$,"A student asked me to help him calculate this definite integral
$$\int_0^2(1-x^2)^\frac{1}{3}~dx$$
Although I have tried almost all the methods I have learned, I can not still do with it. I have tried the change of variable $x=\sec t$ , and the method of integral by parts. Can anyone help me?","['definite-integrals', 'calculus', 'integration']"
607436,What do polynomials look like in the complex plane?,"I have a hard time visualizing the fundamental theorem of algebra, which says that any polynomial has at least one zero, superficially I know this is true as every polynomial must have either an imaginary zero or real zero, but how do I visualize this in the complex plane? For example if we have a real polynomial, we know that it is zero when it crosses the x axis this is because $y = 0$, however if $f(z) = 0$, then it must be the case that $f(z) = w = u+iv = 0+i0=0$ therefore every zero in $f(z)$ passes the origin? That does not make sense to me, what am I missing here?","['graphing-functions', 'complex-analysis']"
607462,What is the most relavant math for statistics students?,"As they say ""the more math you learn the better"". Unfortunately, I did not have a lot of mathematical training in my undergraduate. Now I am doing a master in mathematics, mainly to make up some necessary background knowledge in mathematics in order to do my statistics. So far I have done metric space analysis, group and ring, and two numerical computation courses. Now I am considering what subjects to take next semester. So far I have decided to do topological analysis, probability theory. I am not sure whether it is useful to take more algebra course like Galois Theory. Any suggestion, general or specific, would be appreciated. Thank you in advance!","['statistics', 'advice', 'reference-request', 'soft-question']"
607484,Conformal map from unit disk to polygon,"(Stein, Complex analysis, p.253) If $$F(z)= \int_1^z \frac{d\zeta}{(1-\zeta ^n)^{2/n}}$$ then $F$ maps
  the unit disk conformally onto the interior of a regular polygon with
  $n$ sides and perimeter
  $$2^{\frac{n-2}{n}}\int_0^\pi(\sin\theta)^{-2/n}d\theta$$ I know about conformal maps from $\Bbb{H}$(upper half plane) to polygon given by Schwarz-Christoffel integral. So I tried to consider $F \circ G$ where $G: \Bbb H \to \Bbb D$ by $G(z)=\frac{i-z}{i+z}$. But change of variables does not make the integrand simple. $\zeta = G(w), d\zeta = -2idw/(i+w)^2$ so $d\zeta/(1-\zeta ^n)^{2/n}=cdw/((i+w)^n-(i-w)^n)^{2/n}$. So I cannot use Schwarz-Christoffel integral. What should I do? I tried also $\zeta=e^{i\theta}$ but don't know how to proceed.",['complex-analysis']
607539,"How to prove $f: N \to \{0,1\}$ where not exist i where $f(i)=f(i+1)=1$ are uncountable using cantor's diagonal?","I know how to prove that $f: N\to \{ 0,1 \}$ are uncountable but in this case
I have a problem where that might be: $f_1: 000000000000...$ $f_2: 001000000000...$ $f_3: 000100000000...$ If I take the opposite of the diagonal it goes: $111$ and that isn't a function I'm looking for. I think it's very interesting quesion. Thanks!","['discrete-mathematics', 'group-theory']"
607540,Simple examples of $3 \times 3$ rotation matrices,"I'd like to have some numerically simple examples of $3 \times 3$ rotation matrices that are easy to handle in hand calculations (using only your brain and a pencil). Matrices that contain too many zeros and ones are boring, and ones with square roots are undesirable. A good example is something like
$$
M = \frac19 \begin{bmatrix}
1 & -4 & 8 \\
8 &  4 & 1  \\
-4 & 7 & 4
\end{bmatrix}
$$
Does anyone have any other examples, or a process for generating them? One general formula for a rotation matrix is given here . So one possible approach would be to choose $u_x$, $u_y$, $u_z$ and $\theta$ so that you get something simple. Simple enough for hand calculations, but not trivial. Like the example given above.","['matrices', 'linear-algebra', 'rotations']"
607541,Is this a valid argument ? function floor property,"I'm new in that stuff in proving things. I'm always confused about when is a really valid reasoning. Then is this property, i appreciate any help. Prove, for any real x: x - 1 < $\lfloor$x$\rfloor$ $\leq$ x $\leq$ $\lceil$x$\rceil$ < x + 1 by definition: $\lfloor$x$\rfloor$ = n $\iff$ n $\leq$  x < n + 1 $\lceil$x$\rceil$ = n' $\iff$ n' - 1 < x $\leq$ n' so, $\lfloor$x$\rfloor$ $\leq$ x $\leq$ $\lceil$x$\rceil$ , because  x $\leq$ n $\land$ x $\leq$ n' ( $\lfloor$x$\rfloor$ + 1 + (-1) > x + (-1) ) $\land$  ( $\lceil$x$\rceil$ - 1  + (1) < x + (1) ) ($\lfloor$x$\rfloor$ > x - 1)   $\land$    ($\lceil$x$\rceil$  < x + 1) Thereof, x - 1 < $\lfloor$x$\rfloor$ $\leq$ x $\leq$ $\lceil$x$\rceil$ < x + 1","['discrete-mathematics', 'ceiling-and-floor-functions']"
607568,Is $\sqrt{x^2}=|x|$ or $=x$? Isn't $(x^2)^\frac12=x?$ [duplicate],"This question already has answers here : How is it, that $\sqrt{x^2}$ is not $ x$, but $|x|$? (5 answers) Closed 9 years ago . $|x|=\sqrt{x^2}$ as Wolfram|Alpha shows. But, as $(x^2)^\frac12=x$, I can't understand where am I wrong interpreting Square-root.","['radicals', 'arithmetic', 'absolute-value', 'algebra-precalculus']"
607586,Evaluating $\lim_{x\to\frac{\pi}{4}}\frac{1-\tan x}{1-\sqrt{2}\sin x}$,"How can I evaluate $$\lim_{x\to\frac{\pi}{4}}\frac{1-\tan x}{1-\sqrt{2}\sin x}$$ without L'Hopital rule. Using L'Hopital rule, it evaluates to 2. Is there a way to do it without using L'Hopital?","['limits-without-lhopital', 'calculus', 'limits']"
