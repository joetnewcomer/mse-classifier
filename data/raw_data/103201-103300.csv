question_id,title,body,tags
1443059,Why is $f$ constant in this case? [duplicate],"This question already has answers here : Why: A holomorphic function with constant magnitude must be constant. (6 answers) Closed 8 years ago . Reference: Conway - Functions of one complex variable p.55 Exercise 17. Let $\epsilon>0$. Let $f:B(0,\epsilon)\rightarrow \mathbb{C}$ be an analytic function such that $|f(z)|=|f(w)|$ for each $z,w\in B(0,\epsilon)$. In this case, how do I prove that $f$ is constant? I'm completely lost where to start..",['complex-analysis']
1443067,Prove that $|x|$ isn't differentiable at 0 through epsilon-delta logic?,"I remember in high school a proof of this was to show that the right-hand and left-hand limits were not equal to each other. But I was wondering, coming off of learning the $\epsilon - \delta $ notation recently, if a more elegant method existed? I'm still fuzzy on the intricacies of this notation, so I was wondering if this example would help clarify it for me.","['analysis', 'limits', 'real-analysis', 'derivatives']"
1443097,Inclusion Exclusion Principle ( Probability ),"I'm familiar with the Inclusion / Exclusion Principle for general counting but for the life me I'm not able to show the probability version in an exercise I'm trying from a book. I've included a picture below to show my problem. $\mathbf{1.42}$ The inclusion-exclusion identity of Miscellanea $1.8.1$ gets its name from the fact that it is proved by the method of inclusion and exclusion (Feller $1968$, Section IV.$1$). Here we go into the details. The probability $P(\cup_{i=1}^nA_i)$ is the sum of the probabilities of all the sample points that are contained in at least one of the $A_i$s. The method of inclusion and exclusion is a recipe for counting these points. Let $E_k$ denote the set of all sample points that are contained in exactly $k$ of the events $A_1,A_2,\ldots,A_n$. Show that $P(\cup_{i=1}^nA_i)=\sum_{i=1}^nP(E_i)$. If $E_1$ is not empty, show that $P(E_1)=\sum_{i=1}^nP(A_i)$. Without loss of generality, assume that $E_k$ is contained in $A_1,A_2,\ldots,A_k$. Show that $P(E_k)$ appears $k$ times in the sum $P_1$, $\binom{k}2$ times in the sum $P_2$, $\binom{k}3$ times in the sum $P_3$, etc. Show that $$k-\binom{k}2+\binom{k}3-\cdots\pm\binom{k}k=1\;.$$ (See Exercise $1.27$.) Show that parts $(1)-(3)$ imply $\sum_{i=1}^nP(E_i)=P_1-P_2+\cdots\pm P_n$, establishing the inclusion-exclusion identity. Here we define $$\begin{align*}P_1&=\sum_{i=1}^nP(A_i)\\
P_2&=\sum_{1\le i<j\le n}P(A_i\cap A_j)\\
P_3&=\sum_{1\le i<j<k\le n}P(A_i\cap A_j\cap A_k)\\
&\vdots\\
P_n&=P(A_1\cap A_2\cap\cdots\cap A_n)\;.
\end{align*}$$ (Original images here and here .) Nearly every proof I've seen of Inclusion / Exclusion has generally been with induction so I'm not entirely sure how to go about it from this direction. To be specific, I'm only interested in part $(5)$ of this question. Could someone have a go at it using the way the book wants you to? Also, ignore part $(2)$, the question is a typo. Part $(5)$ should really be telling you to use $(1),(3)$, and $(4)$ to establish it.","['inclusion-exclusion', 'probability', 'combinatorics']"
1443098,"Can any physical event ""almost surely"" not happen?","I asked a Question ( Why do we say ""almost surely"" in Probability Theory? ?) about what exactly ""almost surely"" means and got some really good, helpful answers.  The examples of events that almost surely cannot happen were clear, but I noticed that they were also all physically unrealizable events. A coin almost surely will not lands heads an infinite number of times. A random selection from a uniform distribution almost surely will not equal exactly 1/2. Every person who enters a raffle that infinitely many people buy tickets for almost surely will lose. All true. But of course, it's not possible to flip a coin an infinite number of times, it's not possible to express (let alone choose) a truly random number since most numbers are irrational, and there'd be no way to notify the Infite Raffle winner because you couldn't publish his infinite winning number. So, is there any physically realizable process to which any specific and specifiable result almost surely cannot happen?","['probability-theory', 'terminology']"
1443120,a_i are positive integers and not equal to each other .prove : $\frac{a_1^2+a_2^2+\cdots+a_n^2}{a_1+a_2+\cdots+a_n}\geqslant \frac{2n+1}{3}$,I met this inequality : a_i (i from 1 to n)are positive integers and not equal to each other . Prove : $\displaystyle \frac{a_1^2+a_2^2+\cdots+a_n^2}{a_1+a_2+\cdots+a_n}\geqslant \frac{2n+1}{3}$ I tried : $\displaystyle \Leftrightarrow \frac{n(n+1)}{2}\sum_{i=1}^n a_i^2\geqslant\frac{n(n+1)(2n+1)}{6}\sum_{i=1}^n a_i$ $\displaystyle \Leftrightarrow\sum_{i=1}^n i\sum_{i=1}^na_i^2\geqslant\sum_{i=1}^ni^2\sum_{i=1}^na_i$ It seems right.But i don't know how to prove it.Who can help me. Thanks!,"['analysis', 'inequality']"
1443123,"100 coin flips, expect to see 7 heads in a row","So a random piece of information in a video I watched ages ago popped in my head tonight and I started thinking about it.  I believe I am remembering this video properly... They flipped a coin 100 times you saw the ratio of head and tails to be 50/50.  They created a diagram of all the flips.  There was a lot of flip-flopping between heads and tail.  There were even some strings of 4 or 5 heads/tails in a row.  At one point in the chart there were 7 heads in a row.  They said in a sample this size, that was expected. That is where my question is, is there a mathematical formula or something that allows us to compute, in a sample size of 100, where the outcome can go 50% one way or the other, the probability of getting 7 of one outcome in a row?","['probability', 'statistics']"
1443124,Given a Fourier series $f(x)$: What's the difference between the value the expansion takes for given $x$ and the value it converges to for given $x$?,"The question given to me was: Find the Fourier series for $f(x) = e^x$ over the range $-1\lt x\lt 1$ and find what value the expansion will have when $x = 2$? The Fourier series for $f(x)=e^x$ is $$f(x)=e^x=\sinh1\left(1+2\sum_{n=1}^{\infty}\frac{(-1)^n}{(n\pi)^2+1}\left(\cos(n\pi x)-n\pi\sin(n\pi x)\right)\right)$$ My attempt to compute these values:
$$f(2)=\sinh1\left(1+2\sum_{n=1}^{\infty}\frac{(-1)^{n}}{(n\pi)^2+1}\right)$$ $$f(0)=e^0=\sinh1\left(1+2\sum_{n=1}^{\infty}\frac{(-1)^{n}}{(n\pi)^2+1}\right)$$ The answer given was: The series will converge to the same value as it does at $x = 0$, i.e. $f(0) = 1$. Could someone please explain to me the difference between: What value will the expansion take at a given $x$ and the value the series converges to for a given $x$? Many Thanks","['calculus', 'special-functions', 'summation', 'fourier-analysis', 'fourier-series']"
1443156,Find slope at tangent line.,"Ok, so this question is a bit odd: it is asking for the slope of the tangent line to the function $$x^y = y^x$$ at the points $(c,c)$. Yeah, the variable is $c$, I'm somewhat confused. I plugged in to the implicitly derived function $$\frac{dy}{dx}=\frac{y(y-x\ln(y))}{x(x-y\ln(x)}$$ and got this $$\frac{dy}{dx}=\frac{c(c-c\ln(c))}{c(c-c\ln(c)}$$ I'm not sure if I'm overthinking it and the answer is simply 1 .","['implicit-differentiation', 'derivatives']"
1443199,Integral $\int_1^2 \frac1x dx$ with a Riemann sum.,"How do you find the $$ \int \dfrac{1}{x} dx$$ by using the idea of a limit of a Riemann sum on the interval [1,2]? I tried splitting the interval into a geometric progression and evaluating the Riemann sum, but i cant simplify the expression at this stage.","['calculus', 'limits', 'definite-integrals', 'sequences-and-series', 'integration']"
1443203,Symmetric Variety,"What is symmetric variety ?
Let G be a semisimple simply connected algebraic group over the complex numbers. Let $\sigma$ : G $\to$ G be an automorphism of order 2 and H be the sub group of G of the element fixed by by $\sigma$. Then prove that G/H is a symmetric variety.","['algebraic-geometry', 'lie-algebras']"
1443236,what is the Jacobian for transformation from complex coordinate to real coordinate?,"I'm trying to figure out what is the Jacobian when you do this simple transformation: $dzdz^* \rightarrow dxdy$ where $z=x+iy$ and $z^*=x-iy$. Follow the formula we have 
$$J(x,y)=
\begin{vmatrix}
\frac{\partial z}{\partial x} & \frac{\partial z}{\partial y} \\
\frac{\partial z^*}{\partial x} & \frac{\partial z^*}{\partial y}
\end{vmatrix}
=
\begin{vmatrix}
1 & i \\
1 & -i
\end{vmatrix}=-2i
$$
So $dzdz^* =|J(x,y)| dxdy=2dxdy$. However, this is not what is used in literatures where they either use $dzdz^* = dxdy$ or $dzdz^* =2i dxdy$. So is there a definite answer for this seemingly simple question? Thanks!","['several-complex-variables', 'complex-analysis', 'complex-integration', 'linear-transformations']"
1443262,How to find triangle vertices given midpoints?,"I have a task to find vertices if midpoints are given: $M1(2;1)$, $M2(5;3)$, $M3(3;-4)$. I know one way to solve it through making a system of equations with three variables. My teacher says there is faster way by using the midline of a triangle, and I can`t find this way of solving it on the Internet. How can I do it?","['geometry', 'triangles']"
1443282,Determine the values of a and b that makes the function differentiable everywhere,"Given $$f(x)=ax^3\cos(1/x)+bx+b$$ for $$x<0$$
and
$$f(x)=\sqrt{a+bx}$$
for $$x\ge0$$ Where $$a,b$$
are positive constants. Determine the values of a and b, if any, that make f differentiable everywhere. Proposed solution: (1) $$f'(x)=3ax^2\cos(\frac{1}{x})+ax\sin(\frac{1}{x})+b$$ and (2) $$f'(x)=\frac{1}{2}(a+bx)^{-\frac{1}{2}}b$$ From (2), $$f(0)=a^{\frac{1}{2}}, f'(0)=\frac{1}{2}(a^{-\frac{1}{2}})b$$ and
From (1), $$\lim_{x \rightarrow 0-}f(x)=b$$ (Using Squeeze theorem) Since differentiability implies continuity, (3)
$$\lim_{x \rightarrow 0-}f(x)=\lim_{x \rightarrow 0}f(x)=b=f(0)=a^{\frac{1}{2}}$$ For f(x) to be differentiable at 0, using (3), $$\frac{1}{2}=3ax^2\cos(\frac{1}{x})+ax\sin(\frac{1}{x})+a^{\frac{1}{2}}$$ which is unsolvable. So a,b does not exist. Am I right? Thanks.","['continuity', 'calculus', 'derivatives']"
1443342,Solving A Definite Integral:The Feynman way,$ \displaystyle \int_0^\infty \dfrac{\cos xdx}{1+x^2} $ How to calculate the above using differentiation under the integral sign??,"['calculus', 'definite-integrals', 'integration']"
1443348,Playing with closure and interior to get the maximum number of sets,"Can you find $A \subset \mathbb R^2$ such that $A, \overline{A}, \overset{\circ}{A}, \overset{\circ}{\overline{A}}, \overline{\overset{\circ}{A}}$ are all different? Can we get even more sets be alternating again closure and interior?",['general-topology']
1443372,Why Hartman-Grobman theorem does not work when one of the eigenvalues is purely imaginary?,I would be very grateful if someone clever explained to me why Hartman-Grobman theorem does not work when one of the eigenvalues of linearized system is purely imaginary? Is there any intuition behind this?,"['dynamical-systems', 'ordinary-differential-equations']"
1443386,Conditional expectation (understanding the definition),"I would like to check my understanding of some facts related to conditional expectations. We know that a conditional expectation of a non-negative or integrable r.v. $X$ (defined on $(\Omega,\mathcal A, P)$) w.r.t. $\mathcal C \subset \mathcal A$ is another random variable $X_0$ satisfying certain well-known conditions ($\star$). Moreover there is no guarantee that only $X_0$ does satisfy ($\star$). But what we can guarantee is that if $\hat{X}_0$ also satisfies ($\star$), then $X_0 = \hat{X}_0$ a.s. $G(X,\mathcal C)$ is a set of conditional expectations for $X$, can we find $A \in \mathcal A$ such that on $A$ all elements of $G(X,\mathcal C)$ are equal to each other? (I do not know) If the answer to the previous question is no, then would it change if instead of $G(X,\mathcal C)$ we work with a countable subset of $G(X,\mathcal C)$? (I think yes, because a countable union of null-sets is a null set) If $X_0 \in G(X,\mathcal C)$ and $\hat{X}_0 := X_0 * I_{N^c} + a*I_{N}$, $N \in \mathcal C$, $a \in \mathbb R_0^+ \bigcup +\infty$ if $X \ge 0$ or $a \in \mathbb R \bigcup \pm \infty$ if $X$ integrable, $P(N)=0$, would it follow that $\hat{X}_0 \in G(X,\mathcal C)$? (I think yes, because $\hat{X}_0$ is still $\mathcal C$ measurable, non-negative or integrable and has the same value of $P$-integral over any $C \in \mathcal C$) What if in the question above $a$ is a $\mathcal C$ measurable numeric function on $\Omega$ (which is non-negative if $X \ge 0$)? (I think the answer is still yes)","['probability-theory', 'conditional-expectation']"
1443418,Estimating derivatives with randomness,"Assume $Y$ is a continuously differential function of $X$. Given i.i.d. data $(x_i,y_i)_{i=1}^n$, I would like to estimate $E\left[g\left(\left.\frac{\partial Y}{\partial X}\right|_{X=X_0}\right)\right]$ for some known nonlinear function $g$ ($g$ can be assumed continuously differential, if needed, for example $g(x)=x^2$). This question is an extension of Estimating the expectation of a derivative where $g$ was linear and the derivative and integral could be exchanged and kernel techniques used. I am interested to know how the expectation can be estimated when $g$ is nonlinear and the integral and derivative cannot be exchanged. The underlying motivation for the question is estimation of $\frac{\partial Y}{\partial X}$ when there is randomness. My idea was to do something similar to kernel estimation by giving weights to points around $X_0$ based on how close they are to $X_0$ and then sample two points at a time based on the weights, say $(y_i,x_i)$ and $(y_j,x_j)$, and calculate $g(\frac{y_i-y_j}{x_i-x_j})$ and do this many times and take the sample average.","['probability', 'expectation', 'derivatives']"
1443421,Find $\lim\limits_{x\to 0}{\frac{x+\ln (1-x)}{x^2}}$ without derivatives,If we know that $$\lim\limits_{x\to 1}{\frac{\ln x}{x-1}}=1$$ and $$\lim\limits_{x\to 0}{\frac{x+\ln (1-x)}{x^2}}=l\in\mathbb{R}$$ find the value of $l$ without derivatives . I have only managed to find that: $$\lim\limits_{x\to 0}{\frac{\ln (1-x)}{x}}=-1$$ Any hint?,"['limits-without-lhopital', 'limits']"
1443429,Need Examples to Understand Choice Function and Choice Structure.,"Would you please give me a concrete example for the following definitions? Specifically I don't understand why a choice function is defined as $c: B \rightarrow P(X)$. For any nonempty set $X$, let $P(X)$ denote the set of all nonempty subsets of X. For any nonempty subset $B$ of $P(X)$, a function $c: B \rightarrow P(X)$ is called a choice function iff $c(A) \subset A$ for all $A \in B$. The pair $(B, c)$ is called a choice structure . For any binary relation $R$ on $X$, define the function $C_R : P(X) \rightarrow P(X) \cup \{\emptyset\}$ as follows: $$C_R (A) = \{x \in A : ( \forall y \in A ) ( xRy ) \}.$$ This question is in no way a duplicate for the following question: (P(X),CR) may be a choice structure even if R is not a rational relation In this question I am asking people to provide me some examples to understand the definition of Choice function and Choice structure. In the other question, I am asking for an example to show that a relation underlying a choice structure should not necessarily be a rational relation. The only relation between these two questions is the definition included in the latter questions to clarify the question.","['elementary-set-theory', 'relations']"
1443465,Measure on surfaces in $\mathbb{R}^3$,"I am interested in the following three surfaces in $\mathbb{R}^3$: $$S_1=\{(x,y,x+y+x^3+\sqrt{y}): x \in [0,x_0], y\in [0,y_0]\},$$ $$S_2=\{(x,y,x+y+x^2 +y^2+1): x \in [0,x_0], y\in [0,y_0]\},$$ $$S_3=\{(x,y,x+y+x^4 +y^3): x \in [0,x_0], y\in [0,y_0]\}$$
for some $x_0, y_0>0$. I wonder if there is a natural extension of the notion of Lebesgue measure (in $\mathbb{R}^n$) on these surfaces and a natural notion of open sets on these surfaces such that something like the Lebesgue density theorem would hold using these two extended notions?","['lebesgue-measure', 'surfaces', 'measure-theory', 'geometry', 'analysis']"
1443509,"How to prove $(6666\ldots66)^2 + 8888\ldots88 = 4444\ldots44$ (with $n$ 6s and 8s, $2n$ 4s)","How to prove that, if $n$ is a positive integer, then $$
  (\underbrace{666 \ldots 6}_{n \text{ copies of } 6})^2 + 
  \underbrace{888 \ldots 8}_{n \text{ copies of } 8} = 
  \underbrace{444 \ldots 4}_{2n \text{ copies of } 4}?
$$",['algebra-precalculus']
1443598,Can we improve the constant $6$? $\inf_{0\le x\le 1}\sum_{j=1}^{n}\frac{1}{|x-p_{j}|}\le 6n\left(1+\frac{1}{3}+\cdots+\frac{1}{2n-1}\right)$,"Some days ago, when I again read the William Lowell Putnam Mathematical Competition (1979), I found this nice problem: Let $p_{j}\in [0,1],j=1,2,\cdots,n$. Prove, that  $$\inf_{0\le x\le
 1}\sum_{j=1}^{n}\dfrac{1}{|x-p_{j}|}\le
 8n\left(1+\dfrac{1}{3}+\cdots+\dfrac{1}{2n-1}\right)$$ This problem solution can split the inteval $[0,1]$ into $2n$ intervals of the same length, such $I_{k}=[\dfrac{k}{2n},\dfrac{k+1}{2n})$. Next, we choose x in an interval that does not contain any of the numbers $p_{j}$,then it not hard to prove it. But I fell this inequality right constant $8$ can smaller, such $6$ is also hold. Question 1: $$\inf_{0\le x\le 1}\sum_{j=1}^{n}\dfrac{1}{|x-p_{j}|}\le
 6n\left(1+\dfrac{1}{3}+\cdots+\dfrac{1}{2n-1}\right)$$ So I can think, the following problem maybe is also interesting: Question 2 $$\inf_{0\le x\le 1}\sum_{j=1}^{n}\dfrac{1}{|x-p_{j}|}\le
 An\left(1+\dfrac{1}{3}+\cdots+\dfrac{1}{2n-1}\right)$$ Find the best constant of the $A$!","['contest-math', 'inequality', 'measure-theory']"
1443603,"infimum of a functional in $W^{1,p}((0,1))$","Consider the functional 
$$\mathcal{F}(u)=\int_{0}^{1}x^{\alpha}|u'(x)|^pdx,\ \ u\in W^{1,p}((0,1)),$$
where $\alpha\ge 0$ and $1<p<\infty$. Given $a<b$, find the value of 
$$\inf\{\mathcal{F}(u): u\in W^{1,p}((0,1)), u(0)=a, u(1)=b\}.$$ For the case $p>\alpha +1$, my proof look like this: Since $u\in W^{1,p}((0,1))$, we have 
$$u(1)-u(0)=\int_{0}^{1}u'(x)dx.$$
Base on the above equality, we have
\begin{align*}
(b-a)&=u(1)-u(0)\\
&=\int_{0}^{1}u'(x)dx\\
&=\int_{0}^{1}x^{\frac{\alpha}{p}}u'(x)x^{-\frac{\alpha}{p}}dx\\
&\le (\int_{0}^{1}x^{\alpha}|u(x)|^pdx)^{1/p}(\int_{0}^1x^{-\frac{\alpha q}{p}})^{1/q}\\
&=(\int_{0}^{1}x^{\alpha}|u(x)|^pdx)^{1/p}(\int_{0}^1x^{-\frac{\alpha}{p-1}})^{1/q}
\end{align*}
where we have $\frac{1}{p}+\frac{1}{q}=1$. Since $-\frac{\alpha}{p-1}>-1$, we have 
\begin{align*}
\int_{0}^1x^{-\frac{\alpha}{p-1}}&=\frac{1}{1-\frac{\alpha}{p-1}}\\
&=\frac{p-1}{p-\alpha-1}.
\end{align*}
Thus, we imply that 
$$(b-a)\le (\int_{0}^{1}x^{\alpha}|u(x)|^pdx)^{1/p}(\frac{p-1}{p-\alpha-1})^{1/q}.$$
We deduce that 
$$\int_{0}^{1}x^{\alpha}|u(x)|^pdx \ge (b-a)^p(\frac{p-\alpha-1}{p-1})^{p/q}$$ I am trying to prove that 
$$(b-a)^p(\frac{p-\alpha-1}{p-1})^{p/q}=\inf\{\mathcal{F}(u): u\in W^{1,p}((0,1)), u(0)=a, u(1)=b\}$$
by finding a function $u\in W^{1,p}((0,1)), u(0)=a, u(1)=b$ such that $\mathcal{F}(u)=(b-a)^p(\frac{p-\alpha-1}{p-1})^{p/q}$. However, I have not succeeded. Can any one help me with that ?","['analysis', 'calculus-of-variations', 'sobolev-spaces', 'partial-differential-equations']"
1443617,Limit of a product $(1 + \frac{k}{n})$,I am trying to find the limit of $$\displaystyle \lim_{n\to\infty}\left(\prod_{k=1}^n\left(1+\frac{k}{n}\right)\right)^{1/n}$$ I have that it is equivalent to the $$\lim_{n\to\infty}\frac{1}{n}\left(\sum_{k=1}^n\ln\left(1+\frac{k}{n}\right)\right)$$ I can't get any further than this. Any help would be much appreciated.,['calculus']
1443625,Evaluate the limit of the following expression,"Let $n$ and $k$ be positive integers. Let $a>0$. Evaluate:
$$\lim_{n\to +\infty}\frac{\left(a+\frac{1}{n}\right)^n\left(a+\frac{2}{n}\right)^n\cdot\ldots\cdot\left(a+\frac{k}{n}\right)^n}{a^{nk}}$$ I tried to apply the concept of ""Limit as a sum"", by taking log, but I could not do. Somebody, please help!","['calculus', 'limits']"
1443649,Boundedness of a set,"Let $$S = \{(x, y) \in \mathbb{R}^2: x^2 + 2hxy + y^2 =1\}$$ For what values of $h$ is the set $S$ nonempty and bounded? For $h = 0,$ it is surely bounded, the curve being the unit circle. What for other $h$? Please help someone.",['algebraic-geometry']
1443664,Where is the flaw in my proof that the union of two continuous functions is continuous?,"Problem. Let $f:A\to\mathbb{R}$ be a continuous function on $A$ and $g:B\to\mathbb{R}$ be a continuous function on $B$ such that $A\cap B=\emptyset$. Let $h:A\cup B\to\mathbb{R}$ be defined by, $$h(x)=\begin{cases}f(x)& x\in A\\ g(x)& x\in B\end{cases}$$Is $h$ continuous on $A\cup B$? Proof. Let $(x_n)_{n\ge1}$ be any sequence from $A\cup B$ converging to $c\in A\cup B$. Let us now form two subsequences of $(x_n)_{n\ge1}$, namely $(y_n)_{n\ge1}$ and $(z_n)_{n\ge1}$ such that $y_n\in A$ and $z_n\in B$ for all $n\in \mathbb{N}$. Then clearly $(h(y_n))_{n\ge1}\to h(c)$ since $h(y_n)=f(y_n)$ for all $n\in\mathbb{N}$ and $(h(z_n))_{n\ge1}\to h(c)$ since $h(z_n)=g(y_n)$ for all $n\in\mathbb{N}$. Consequently $(h(x_n))_{n\ge1}\to h(c)$ and we are done. But the problem is that when I told our professor about this proof he told me that there should be some other conditions. But the argument seems to work well. Where is the flaw (if any) in my argument?","['proof-verification', 'real-analysis']"
1443670,Formal expansion of differential form on elliptic curves,"First of all everything i'm asking about comes from the beginning of Katz and Mazur's book : Arithmetic moduli of elliptic curves (which you can find here ). I'm considering an elliptic curve  $f : E \to S$ where $S$ is a scheme (i.e. $E$ is a proper smooth $S$-group scheme of relative dimension $1$, with a chosen section $0 : S \to E$). I'm a trying to understand what KM are doing on page 68/69. Since $E \to S$ is separated we know that $D := 0(S)$ is a closed subscheme, it is in fact proven in KM that $D$ is a relative effective cartier divisor i.e. $D \to S$ is flat and $I(D)$ is an invertible sheaf. We write $\omega_{E/S} = 0^*\Omega^1_{E/S} = f_* \Omega^1_{E/S}$. This is a line bundle so Zariski locally on $S$ it is generated by a global section $\omega$. Now they say 1) Zariski locally on $S$, the formal completion of $E$ along $0$ i.e. $Spf(\varprojlim \mathcal{O}_E/I(D)^n)$ is isomorphic to $Spf(R[[T]])$ where $S = Spec(R)$. This in turn, implies (they say) that 2) Zariski locally on $S$, $\omega$ can be written in the form $f(T)dT$ where $f(T) \in R[[T]]$. How does one prove that first fact (I get that for open affine $U = Spec(A)$ containing $0(D)$ we have $A = R \oplus I(D)$ where $I(D)$ is the free ideal of rank $1$ corresponding to $D$, and that by iterating this we get a morphism $A \to R[[T]]$ but i don't know how to go from there). For the second I don't even understand what they mean by the formal expansion of $\omega$.","['elliptic-curves', 'algebraic-geometry']"
1443677,Is there a proof of Noether's formula without using general Riemann-Roch theorem?,Is there an algebraic proof of Noether's formula $\chi(O_S)=\frac{1}{12}(K^2+c_2(T_S))$ without directly applying general Riemann-Roch theorem?,['algebraic-geometry']
1443680,Quantum Mechanics state space,"In Quantum Mechanics one often deals with wavefunctions of particles. In that case, it is natural to consider as the space of states the space $L^2(\mathbb{R}^3)$. On the other hand, on the book I'm reading, there's a construction which it's quite elegant and general, however it is not rigorous. For those interested in seeing the book, it's ""Quantum Mechanics"" by Cohen-Tannoudji. The book proceeds as follows: the first postulate of Quantum Mechanics states that for every quantum system there is one Hilbert space $\mathcal{H}$ whose elements describe the possible states of the system. The idea then is that $\mathcal{H}$ doesn't necessarily is a space of functions. Indeed, Cohen defines (or doesn't define) $\mathcal{H}$ as the space of kets $|\psi\rangle\in \mathcal{H}$, being the kets just vectors encoding the states of the system. The second postulate states that for each physically observable quantity there is associated one hermitian operator $A$ such that the only possible values to be measured are the eigenvalues of $A$ and such that If $A$ has discrete spectrum $\{|\psi_n\rangle : n \in \mathbb{N}\}$ then the probability of measuring the eigenvalue $a_n$ on the state $|\psi\rangle$ is $\langle \psi_n | \psi\rangle$ considering that $|\psi\rangle$ is normalized. If $A$ has continuous spectrum $\{|\psi_{\lambda}\rangle : \lambda \in \Lambda\}$ then the probability density on state $|\psi\rangle$ for the possible eigenvalues is $\lambda \mapsto \langle \psi_\lambda | \psi\rangle$ If, for example, the position operator $X$ for particle in one-dimension, exists, and if its eigenvectors are $|x\rangle$ with eigenvalues $x$, for each $x\in \mathbb{R}$, the probability density of position is $\langle x |\psi\rangle$ which is a function $\mathbb{R}\to \mathbb{C}$ and we recover the wavefunction. This formulation, though, seems to be more general. In that case, wavefunction is just the information about one possible kind of measurement which we can obtain from the postulates. There is nothing special with it. Now, although quite elegant and simple, this is not even a little rigorous. For example: the position operator hasn't been defined! It is just ""the operator associated to position with continuous spectrum"", but this doesn't define the operator. On the book, it is defined on the basis $\{|x\rangle\}$, but this set is defined in terms of it, so we get circular. Another problem is that usually we are dealing with unbounded operators which are not defined on the whole of $\mathcal{H}$. And an even greater problem is that $\mathcal{H}$ was never defined! I've been looking forward to find out how to make this rigorous, but couldn't find anything useful. Many people simply say that the right way is to consider always $L^2(\mathbb{R}^3)$, so that all of this talk is nonsense. But I disagree, I find it quite natural to consider this generalized version. The only thing I've found was the idea of rigged Hilbert spaces, known also as Gel'fand triple. I've found not much material about it, but anyway, I didn't understand how it can be used to make this rigorous. In that case, how does one make this idea of space of states, or space of kets, fully rigorous, overcoming the problems I found out, and possibly any others that may exist? Is it through the Gel'fand triple? If so, how is it done?","['quantum-mechanics', 'functional-analysis', 'hilbert-spaces', 'mathematical-physics', 'spectral-theory']"
1443695,Is the max matrix norm induced?,"Let $\|A \| = \max_{1 \le i,j \le n} |a_{ij}|$, where $A$ is a square matrix. I can prove that this is a matrix norm, but is it an induced norm?","['normed-spaces', 'matrices']"
1443743,Evaluation of $\displaystyle \int_{0}^{1}\left(1-x^3+x^5-x^8+x^{10}-x^{13}+\ldots\right)dx$,"Evaluation of $\displaystyle \int_{0}^{1}\left(1-x^3+x^5-x^8+x^{10}-x^{13}+\ldots\right)dx$ $\bf{My\; try::}$ We can write  $\displaystyle 1-x^3+x^5-x^8+x^{10}-x^{13}+\ldots$ as $$\displaystyle (1-x^3)\cdot (1+x^5+x^{10}+\ldots ) = \frac{(1-x^3)(1)}{1-x^5}$$ So we can write it as $\displaystyle \frac{(1-x)(x^2+x+1)}{(1-x)(x^4+x^3+x^2+x+1)}$ So our Integral Convert into $\displaystyle \int_{0}^{1}\frac{x^2+x+1}{x^4+x^3+x^2+x+1}dx$ Now How can I solve it, Help me Thanks",['calculus']
1443753,Unsolvable Differential Equation?,"Is there an analytic solution to the following equation? $$ \frac{dx}{dy} = \frac{x^2 - y^2}{x^2 + y^2}  $$ I believe the answer is 'no'. It isn't separable or exact
I've had trouble finding any documentation that can help me explore this problem further. I have solved the problem numerically to explore the solution space, and it seems to make sense as the answer, but I also need to show some work in attempting to solve it analytically. Is there a substitution that can be done to solve this? Or is this, in fact, an unsolvable problem (analytically)?",['ordinary-differential-equations']
1443761,Prove $2^{2n} = \sum_{k=0}^{n}\binom{2n+1}{k}$,"I'm trying to prove the following equation above. So far I have:
\begin{align}
2^{2n} &= (1+1)^{2n}\\
&= \sum_{k=0}^{2n}\binom{2n}{k}1^k1^{n-k} = \sum_{k=0}^{2n}\binom{2n}{k} & \text{(By the Binomial Theorem)}
\end{align} I know I have to use the following identity somehow:
$$\binom{n+1}{k} = \binom{n}{k-1} + \binom{n}{k}$$ How do I split my summation to get what I'm looking for? Thanks! EDIT: HERE IS MY SOLUTION \begin{align*}
2^{2n} &= (1+1)^{2n}\\
&= \sum_{k=0}^{2n}\binom{2n}{k}1^k1^{2n-k} & \text{(By the Binomial Theorem)}\\
&= \sum_{k=0}^{n}\binom{2n}{k} + \sum_{k=n+1}^{2n}\binom{2n}{k}\\
&= \sum_{k=0}^{n}\binom{2n}{k} + \sum_{k=n+1}^{2n}\binom{2n}{2n-k} & \text{(Binomial Symmetry)}\\
&= \sum_{k=0}^{n}\binom{2n}{k} + \sum_{k=0}^{n-1}\binom{2n}{k}\\
&= \sum_{k=0}^{n}\binom{2n}{k} + \sum_{k=1}^{n}\binom{2n}{k-1}\\
&= \binom{2n}{0} + \sum_{k=1}^{n}\binom{2n}{k} + \sum_{k=1}^{n}\binom{2n}{k-1}\\
&= \binom{2n}{0} + \sum_{k=1}^{n}\binom{2n+1}{k} & \text{(By Identity listed above)}\\
&= \sum_{k=0}^{n}\binom{2n+1}{k}
\end{align*}","['binomial-theorem', 'summation', 'combinatorics']"
1443799,Progressed : Convergence problem in Hilbert Space and necessity of inner product,"******** PROGRESS : so thanks to Ian's great comment I can get by the proof and that completeness is necessary but I need to know does this hold for general Banach spaces that are not Hilbert spaces? I have this assignment question from Functional Analysis class stating: Let $ \mathcal{H} $ be a Hilbert Space with a sequence $ \{x_n\}_{n=1}^{\infty} $ of elements in $ \mathcal{H} $. There is a constant $ A \in R $ such that for every sequence $ \{a_n\}_{n=1}^{\infty}  $ satisfying $ 0 \leq |a_n| \leq 1 $ all zero except a finite number of elements, we have ||$ \sum_{n} a_nx_n $|| $ \leq $ A. We are asked to prove $\lim_{N\to\infty} {\sum_{n=1}^{N} x_n}$ exists in the norm. Also, does this hold if the space H is not complete? What about a norm space where the norm is not induced from an inner product? Last part before this I proved: For all $ \{ x_n \}_{n=1}^N \in \mathcal{H} $ there are scalars $ \{ a_n \}_{n=1}^N $ on the complex unit circle such that : $||\sum_{n=1}^{N} a_nx_n ||^2 \geq \sum_{n=1}^{N} ||x_n||^2 $ I don't exactly know how to incorporate that previous part or if I even need to for that matter. I would really appreciate help. PROGRESS : so thanks to Ian's great comment I can get by the proof and that completeness is necessary but I need to know does this hold for general Banach spaces that are not Hilbert spaces?","['inner-products', 'functional-analysis', 'hilbert-spaces', 'banach-spaces', 'normed-spaces']"
1443837,A function on an LCH space that is sequentially continuous but nowhere continuous,"This question is an extension of Example of topological spaces where sequential continuity does not imply continuity . In my answer to that question , I gave an example of a topological space $X$ and a function $f : X \to \{0,1\}$ which is sequentially continuous but nowhere continuous.  The space $X$ is completely regular but not locally compact. Is there an example of a locally compact Hausdorff space $X$, another topological space $Y$, and a function $f : X \to Y$ which is sequentially continuous but nowhere continuous? It will be even better if $X$ is compact Hausdorff and/or $Y$ is some nice space like $\{0,1\}$ or $[0,1]$. If we step outside ZFC, we can get an affirmative answer.  Suppose $\kappa$ is a measurable cardinal , so that there is a countably additive measure $\mu : 2^{\kappa} \to \{0,1\}$ such that all finite sets have measure 0.  Then take $X = 2^{\kappa}$ with the product topology (think of the power set of $\kappa$ as the product of $\kappa$ many copies of the discrete space $\{0,1\}$) which is compact Hausdorff, $Y = \{0,1\}$, and $f = \mu$.   The countable additivity of $\mu$ guarantees sequential continuity.  But the finite sets are dense in $X$, as are the cofinite sets.  So every nonempty open set in $X$ contains a finite set and a cofinite sets, whose measures are 0 and 1 respectively.  Thus $\mu$ is nowhere continuous. But I would like an answer in ZFC.","['set-theory', 'general-topology', 'large-cardinals']"
1443839,"Let $ Y = \{ (1,1),(0,0\} \subset \mathbb A_k^2$. Find the $ \mathbb I(Y)$.","Let $ Y = \{ (1,1),(0,0\} \subset \mathbb A_k^2$. Find the $ \mathbb I(Y)$. As if $f(x,y) \in \mathbb I(Y)$ then as $f(0,0)=0$ hence constant term of $f$ is zero and as $f(1,1)=0$ therefore sum of the coefficients of $f(x,y)$ is zero. But how can we describe this set properly?","['algebraic-geometry', 'commutative-algebra']"
1443871,Prove that as a $\Bbb Q$ vector space $\Bbb R^n$ is isomorphic to $\Bbb R$,"Prove that as a $\mathbb{Q}$ vector space, $\mathbb{R}^n$ is isomorphic to $\mathbb{R}.$ I came across this statement somewhere and I have been trying to prove it ever since, but I just don't know how to start or what to define as the map.","['vector-spaces', 'linear-algebra']"
1443876,"If we have $y^2=(x-1)(x-2)\dots(x-2n)$, do the roots get exchanges if we run around the origin once?","This is an example from the much-used Algebraic Geometry notes by Gathmann. He says that if we consider the equation $y^2=(x-1)(x-2)\dots(x-2n)$ , where $x,y\in\Bbb{C}$ , then The solution set is two complex planes with the points $\{1,2,3,\dots,2n\}$ identified. If we run around the origin once, the two solutions of $y$ get exchanged. I don't understand why this is the case. I can understand that for each value of $x$ , there are two values of $y$ . However, do the two complex planes denote the two values of $y$ , or the values of $x$ ? Is it true that all that this diagram of two complex planes joined at the given points indicates is that the two values of $y$ co-incide at these points, and nothing else? Should the two values get exchanged even if $n$ is an even number? I mean if we run around the origin once, we're rotating each factor $(x-p)$ by an angle of $2\pi$ . If $n$ is even, we're rotating the product of all factors by an angle of $4k\pi$ . Shouldn't the values of $y$ remain the same then?",['complex-analysis']
1443940,"Given $2$ sets: $A:=\{1, 2,3\}$ and $B:=\{a, b, c\}.$ Are $A$ and $B$ equivalent?","Given $2$ sets: $A:=\{1, 2, 3\}$ and $B:=\{a, b, c\}.$ Are $A$ and $B$ equivalent? This is one of my question in my homework. I knew that $2$ sets $A$ and $B$ are equivalent with each other, wrote $A\sim B$, if there exists a bijection $\text f: A\to B$, but I wonder if this is true when one set is not in real number's set.",['elementary-set-theory']
1443941,"solving the differential equation $y'=2xy$, $y(0)=2$","When solving the differential equation $y'=2xy$, $y(0)=2$, we say:
$$\int\dfrac{dy}{y}=\int2xdx+C$$
$$ln|y|=x^2+C$$ But how could we divide by y, What if it is equal to zero at some point?",['ordinary-differential-equations']
1443946,all possible inner products in $\mathbb R^2$,"Suppose $\langle., .\rangle: \mathbb R^2\times \mathbb R^2\to \mathbb R$ is an inner product. What would be  all possible function forms of the inner products, i.e. would all of them have the forms either $\langle x, y\rangle=ax_1y_1+bx_2y_2$ or   $\langle x, y\rangle=ax_1 y_2+b x_2y_1,   a,b\in \mathbb R$ or other forms are also possible? How about $\mathbb R^n$$?$","['inner-products', 'linear-algebra', 'real-analysis', 'hilbert-spaces']"
1443956,Arabian circles,"This lovely pattern comes from a show about arabian patterns.  Thus the title. It includes circles touching 8, 7, 6, 5 and 4 other circles. The question: what are the exact sizes of the circles in decreasing order? I know the numerical solution, I am interested in the exact expressions.  I am not sure whether such an expression exists. For the discussion purpose, lets call the radii a, b, c, d and e for the circles with resp. 8, 7, 6, 5 and 4 neighbors.  Let's assume the period of the pattern is 2 units. There is no catch in the picture.  Where 2 circles seem to touch, they do touch.  And you can assume perfect symmetry horizontal, vertical and diagonal. PS: sorry if it is too easy for this forum, I believe it is too difficult and too mathematical for the puzzling forum.",['geometry']
1443986,Application of the pigeon hole principle,"There's a problem in my textbook that I'm having difficulties understanding. The solution given skips steps and is hard to decipher. The problem is as follows: ""During a month with 30 days, a baseball team plays at least one game a day, but no more than 45 games. Show that there must be a period of some number of consecutive days during which the team must play exactly 14 games."" I don't know how to arrive at the conclusion of 14 games. Anyone who can help me understand this application of the pigeon-hole principle would be greatly appreciated, thank you.","['pigeonhole-principle', 'probability', 'discrete-mathematics']"
1443991,Prove or disprove for all sets,"For all sets $A$, $B$, and $C$, if $C \setminus (A \cap B) = (A \cap C) \cup (B \cap C)$, then $C \subseteq B \cup$ A Could you help me to prove it? I tried to use a proof by contrapositive so making it in the following form: if ($C \not\subseteq B \cup$ A) then $C \setminus (A \cap B) \neq (A \cap C) \cup (B \cap C)$ Then I tried to prove that: (1) $C \setminus (A \cap B) \not\subseteq (A \cap C) \cup (B \cap C)$ (2) $(A \cap C) \cup (B \cap C) \not\subseteq  C \setminus (A \cap B)$ The first one seems feasible but as for the second one it is not clear to me how it could be proven?",['elementary-set-theory']
1444039,"Linear Algebra by Hoffman and Kunze, Section 3.4, Exercise Problem 12","I am trying to work out problems from Linear Algebra , by Hoffman and Kunze and came across this problem in the exercise of Section 3.4, I have a difficulty solving the (c) part of the problem. Problem 12 If $V$ is an $n$ - dimensional vector space over the field $F$, and let $B = \{\alpha_1,\alpha_2,\alpha_3, \cdots \alpha_n\}$ be an ordered basis for $V$. (a) There is a unique Linear Operator $T$ on $V$ such that : $$ 
\begin{align}
T(\alpha_j) = \alpha_{j+1}, \quad j=1, \cdots ,n-1 \quad T(\alpha_n)=0
\end{align}
$$ What is the matrix $A$ of $T$ in the ordered basis $B$? (b) Prove that $T^n=0$, but $T^{n-1} \neq 0$ (c) Let $S$ be any linear operator on $V$ such that $S^n=0$, but $S^{n-1} \neq 0$ . Prove that there is an ordered basis $B^{'}$ for $V$ such that the matrix of $S$ in the ordered basis $B^{'}$ is the matrix $A$ of part (a). (d) Prove that if $M$ and $N$ are $n \times n$ matrices $F$ such that $M^n = N^n = 0$, but $M^{n-1} \neq 0 \neq N^{n-1}$, then $M,N$ are similar. However the solution for the problem (c) can be obtained assuming (d) is true, in the following way: Let $[S]_B$ represent the matrix corresponding to the linear operator $S$ under some basis $B$, and we want to show that this operator has the matrix $[S]_{B^{'}}=A$ under some basis $B^{'}$. 
If the two nilpotent matrices of order $n$ are similar, then there must be an invertible matrix $P$ such that $[S]_{B^{'}} = P^{-1}[S]_BP$. The matrix $P$ can be used to prove the existence of another basis $B^{'}$ such that:
$$
\begin{align}
[\alpha]_{B} = P[\alpha]_{B^{'}}
\end{align}
$$ and therefore, there indeed exists a basis $B^{'}$ such that
$$
\begin{align}
[S]_{B^{'}} = P^{-1}[S]_BP
\end{align}
$$ I am also having a problem solving part (d), however, I was wondering if one could prove (c) without using (d) explicitly ? I will be thankful for any hints to solve the problem!",['linear-algebra']
1444071,Prove that $\int_{-\infty}^{\infty} e^{{-x^2}/2} e^{-2itx}dx = \sqrt {2\pi} e^{{-(2t)^2}/2} $.,Why $\int_{-\infty}^{\infty} e^{{-x^2}/2} e^{-2itx}dx = \sqrt {2\pi} e^{{-(2t)^2}/2} $. This value is needed in a problem of Hermite orthogonal functions. I have solved the original using this value but wandering how to prove it?,"['complex-analysis', 'real-analysis', 'improper-integrals', 'integration']"
1444096,Need help understanding the Recursion Theorem (Set Theory),"I'm reading through Introduction to Set Theory by Jech and Hrbacek (3rd edition). I am going through the section on recursion theorem, and I am stuck on two things: I usually see the theorem presented in this way: Recursion Theorem :  Given a set $X$, an element $a$ of $X$ and a function $f:X\rightarrow X$, then there is a unique function $F:\mathbb{N}\rightarrow X$ such that 1) $F(0)=a$ 2)$F(n+1)=f(F(n))$ My first question is, why do we need a second function $f$? If we want our sequence to be factorial, fibonacci, etc, where does this second function $f$ (which to me seems like it kind of came out of nowhere) come into play? While the above form of the theorem is used in most books I have looked up, the main one I am using (Introduction to Set Theory, Jech & Hrbacek) uses the following form: My next question is, why does the function in this case need to be from a product of sets into our original? How come this one uses the $n$ in the argument unlike the one above? Which one is ""better""? Thanks in advance for any reponse.",['elementary-set-theory']
1444138,Differentiable functions such that the derivative is nowhere continuous. [duplicate],This question already has answers here : Discontinuous derivative. [duplicate] (2 answers) Closed 8 years ago . Is there a function $f:\mathbb R\to\mathbb R$ which is differentiable but such that the derivative is nowhere continuous?,['real-analysis']
1444152,Intuition vs Proof of the empty set as a universal subset,"My Discrete Mathematics book talks about the proof of why null set is the subset of every non-empty set. It has raised some questions in my head. Firstly, Why? I mean why will we want to make simple, intuitive things so complicated. I mean why is there need to say tht non-empty set contains an empty set? We can see that a non-empty set has elements and combination of atleast one of them will be a subset of the main set which makes perfect sense. But why will we need to bring up the whole counter intutive idea of null set being a subset? Same question about the set being the subset of itself. What I am looking for is that if somebody can help me understand the purpose and importance of doing so.",['elementary-set-theory']
1444160,"If we know that the sequence of events $A_n$ converges, what can we say about the infinite union and intersection?","Suppose that $\lim_{n\to\infty} A_n = A$. It is intuitive to me for the infinite intersection, that it is equal to $\bigcap_{n\geq1}A_n = A$. However, I am failing to see if there does indeed exist anything for the infinite union. Is there a nice result for that?","['probability-theory', 'elementary-set-theory', 'real-analysis', 'measure-theory']"
1444174,"If $f$ is continuous on $[a,b]$ then $f$ is uniformly continuous on $[a,b]$.","So I want to prove that continuity on $[a,b]$ implies uniform continuity with only using the least upper bound property of the reals. I know the basic idea of this, but am getting confused with choosing the right $\delta$. Here's where I am so far: Proof. Let $\epsilon >0$ and define
$$A(\delta) = \{u \in [a,b] ~| \text{ if } x,t \in [a,u] \text{ and } |x-t| < \delta, \text{ then } |f(x)-f(t)| < \epsilon \},$$
and
$$A = \bigcup_{\delta >0} A(\delta).$$
Since $a \in A$ and $b$ is an upper bound for $A$, $\alpha = \sup(A)$ exists. Now I need to show two things: first that $\alpha = b$, and then that $\alpha \in A$. To show $\alpha = b$ assume that $\alpha <b$. Then by continuity there exists some $\delta(\alpha) > 0$ such that if $|x-\alpha|<\delta(\alpha)$, then $|f(x)-f(\alpha)|< \epsilon$. Now since $\alpha = \sup(A)$, there exists some $x_0 \in A$ such that $\alpha - \delta(\alpha) < x_0 \le \alpha$. Then there exists some $\delta(x_0)>0$ such that $x_0 \in A(\delta(x_0))$. Now let $\delta_{\text{min}} = \min\{\delta(x_0), \delta(\alpha)\}$... So here is where I am stuck. For starters I'm not sure if this $\delta$ will work. Also, I am imagining that I will need to use the triangle inequality to show that $\alpha \in A(\delta^*)$ where $\delta^*$ is whichever $\delta$ that will do the trick, but I'm not sure what to use the triangle inequality on. Basically I've confused myself. Help?","['continuity', 'uniform-continuity', 'real-analysis']"
1444228,Any continuous function with the mean value property is affine,"A function $f(t)$ on an interval $I=(a,b)$ has the mean value property if $$f\left(\frac{s+t}{2}\right)=\frac{f(s)+f(t)}{2} \quad s,t\in I$$
  Show that any affine function $f(t)=At+B$ has the mean value property. Show that any continuous function on $I$ with the mean value property is affine. We have $f\left(\displaystyle \frac {s+t}{2}\right)=A\left(\frac{s+t}{2}\right)+B= \frac{As+At+2B}{2}=\frac{As+B+At+B}{2}=\frac{f(t)+f(s)}{2}$ I showed the first part successfully but I now have trouble proving the second part (any continuous function with the mean value property is affine). Please help me.","['affine-geometry', 'functions']"
1444284,How $a+bi$ becomes $\left(\matrix{a & -b\\b & a}\right)$? [duplicate],This question already has answers here : Why is the complex number $z=a+bi$ equivalent to the matrix form $\left(\begin{smallmatrix}a &-b\\b&a\end{smallmatrix}\right)$ [duplicate] (8 answers) Closed 8 years ago . How do you change something into a matrix? E.g) How does $2+3i$ become $\left(\matrix{2 & -3\\3 & 2}\right)$ Is  there a specific rule for changing an input into a matrix that has to be learned? Or how is it done? Thank you.,"['complex-numbers', 'matrices']"
1444311,A uniformly continuous function whose integral $\int_0^\infty f(x)dx$ exists converges to zero,"Let $f$ be uniformly continuous on $[0,\infty)$ and assume that $\int_0^\infty f(x)dx$ exists. Prove that 
  $$\lim_{x\rightarrow\infty}f(x)=0.$$ This seems obvious, but I couldn't prove it. Edit Thanks to the hint by Did, I managed to prove the theorem (See the answer below).","['uniform-continuity', 'real-analysis', 'integration']"
1444352,Stronger than Nesbitt inequality,"For $x,y,z >0$, prove that
  $$\frac{x}{y+z}+\frac{y}{z+x}+\frac{z}{x+y} \geqslant \sqrt{\frac94+\frac32 \cdot \frac{(y-z)^2}{xy+yz+zx}}$$ Observation: This inequality is stronger than the famous Nesbitt's Inequality
$$\frac{x}{y+z}+\frac{y}{z+x}+\frac{z}{x+y} \geqslant \frac32 $$ for positive $x,y,z$ We have three variables but the symmetry holds only for two variables $y,z$, resulting in a very difficult inequality. Brute force and Largrange Multiplier are too complicated. The constant $\frac32$ is closed to the best constant. Thus, this inequality is very sharp, simple AM-GM estimation did not work. Update: As point out by Michael Rozenberg, this inequality is still unsolved","['multivariable-calculus', 'inequality']"
1444363,How would I solve this higher degree equation?,"$$(x^{ 2 }-2x+3)(x^{ 2 }-2x+3)=121$$ Steps I took: $$x^4-2x^3+3x^2-2x^3+4x^2-6x+3x^2-6x+9=121$$ $$x^{ 4 }-4x^{ 3 }+10x^{ 2 }-12x+9=121$$ $$x^{ 4 }-4x^{ 3 }+10x^{ 2 }-12x-112=0$$ At this point I don't see how I can possibly find the solution using either the quadratic formula, factoring, or completing the square. Please do not provide the solution. I only want hints to guide me in the right direction.",['algebra-precalculus']
1444367,Show that the Wronskian of a fundamental solution set of solutions is a constant.,"Show that the Wronskian of a fundamental solution set of solutions for a L.D.E of the form: $ a_0(x)y^{(n)} + a_2(x)y^{(n-2)} + ... + a_n(x)y = 0$, (there is no derivative term of the order n-1) is a constant: Consider,  $W(x) = det(\Omega(x)) = \begin{vmatrix}
y_1(x) ... y_{n-1}(x)
\\
y_1'(x) ... y_{n-1}'(x)
\\
............
\\
y_1^{n-2}(x) ... y_{n-1}^{n-2}(x)
\end{vmatrix} $. I wanted to use some facts about the determinant to show that the Wronskian is constant, namely: any determinant of a matrix with two rows exactly the same is $0$. However, I am not sure if the row before the last row of $W(x)$ is the same as the last row.",['ordinary-differential-equations']
1444383,Reduction of Principal bundle's,"Let $H⊂G$ be a subgroup and $π:Q→B$ be a principal $H$ -bundle. G has a left H action and one can define a principal G-bundle $π′:Q×_{H}G→B$ where $Q×_{H}G$ is quotiening out the diagonal H-action of $Q×G$ . Morgan, Gauge Theory and the Topology of Four-Manifolds Define Reduction by A 
reduction of a $G$ -bundle $P \to  B$ to an $H$ -bundle is a pair: an $H$ -bundle $Q \to  B$ and an isomorphism of $G$ -bundles $ Q ×_{H} G \to  P$ .In Lectures on K¨ahler Geometry by ANDREI MOROIANU, define a reduction by 
If $H \subset G$ is a subgroup of $G$ , a reduction of the structure
group of $P$ to $H$ relative to the inclusion of $H$ in $G$ is a subset $Q$ of $P$ such that $Q \to M$ is an $H$ -principal bundle over M. I do not understand and relate these two definitions.","['lie-groups', 'algebraic-geometry', 'geometry', 'differential-topology', 'differential-geometry']"
1444395,Showing the Riemann integral is a linear operator over step functions,"Given an interval $[a,b]$, let $S[a,b]$ be the set of all step functions for all possible finite partitions of $[a,b]$. Given a partition $x_0,\dots, x_n$ of $[a,b]$, define $\chi_i$ as the characteristic function on $[x_{i-1},x_i)$.
For the step function $\sum_{i=1} ^ns_i\chi_i(x)$, define $I\Big(\sum_{i=1} ^ns_i\chi_i(x)\Big)=\sum_{i=1} ^ns_i(x_i-x_{i-1})$. I am having difficulty showing $I$ is linear. Given two partitions $x_0,\ldots, x_n$ and $y_0,\ldots, y_m$, how can I show $$I\Big(\alpha\sum_{i=1}^ns_i\chi_i(x)+\beta\sum_{i=1}^mt_i \chi_i(x)\Big)=\alpha I\Big(\sum_{i=1}^ns_i\chi_i(x) \Big)+\beta I\Big(\sum_{i=1}^m t_i\chi_i(x)\Big)$$ I tried to write  $\alpha\sum_{i=1}^ns_i\chi_i(x)+\beta\sum_{i=1}^mt_i \chi_i(x)$ as a single sum $\delta\sum_{i=1}^lr_i\chi_i(x)$, but I don't see how to relate $\gamma$ to $\alpha, \beta$, how to relate $l$ to $m,n$, etc.","['linear-transformations', 'riemann-sum', 'integration']"
1444412,"Qualitatively, what is the difference between a matrix and a tensor?","Qualitatively (or mathematically ""light""), could someone describe the difference between a matrix and a tensor? I have only seen them used in the context of an undergraduate, upper level classical mechanics course, and within that context, I never understood the need to distinguish between matrices and tensors. They seemed like identical mathematical entities to me. Just as an aside, my math background is roughly the one of a typical undergraduate physics major (minus the linear algebra).","['linear-algebra', 'mathematical-physics', 'tensors']"
1444473,"Intuition for idempotents, orthogonal idempotents?","Given a ring $A$ , an element $e \in A$ is called an idempotent if one has $e^2 = e$ . If $e$ is an idempotent, then so is $1 - e$ , since $$(1 - e)^2 = 1 - 2e + e^2 = 1 - 2e + e = 1 - e.$$ Also, we have $e(1 - e) = 0$ . This is a special case of the following situation. A collection of elements $e_1, \dots, e_n \in A$ is said to be a set of orthogonal idempotents if one has $$e_i^2 = e_i \text{ and }e_ie_j = 0 \text{ for }i \neq j.$$ My question is, what is the underlying intuition behind idempotents and orthogonal idempotents? I am finding them quite hard to work with...","['abstract-algebra', 'idempotents', 'soft-question', 'ring-theory']"
1444477,How many surjective functions from set A to B? [duplicate],"This question already has answers here : Calculating the total number of surjective functions (3 answers) Closed 8 years ago . Let $A = \{1, 2, 3, 4\}$ and $B = \{a, b, c\}$ How many surjective functions are there from $A \to B$? My first thought is 3*3*2*1, but I've already written 19 out by hand.","['discrete-mathematics', 'combinatorics']"
1444505,When can $A$ an abelian group be made into a vector space over $\Bbb{F}_p$?,"Let $\Bbb{F}_p$ be the finite field of integers modulo $p, p$ a prime, let $A$ be an abelian group. Precisely when can $A$ be made into a vector space over $\Bbb{F}_p$?","['abstract-algebra', 'group-theory', 'finite-fields']"
1444528,Prove $\prod\limits_{\mathrm{cyc}}(2-x^2+x) \le 4 +x+y+z+xyz$ for $x^2+y^2+z^2=3$,"Let $x,y,z \in \mathbb{R}$ and $x^2+y^2+z^2=3$ . Prove that $$ (2-x^2+x)(2-y^2+y)(2-z^2+z) \leqslant 4 +x+y+z+xyz.$$ Observations At first, I think this inequality is easy. I applied AM-GM to the term $(2-x^2+x) \text{ }$ , $(2-y^2+y) \text{ }$ , $(2-z^2+z) \text{ }$ then try to rewrite the new inequality in term of $u=x+y+z \text{ }$ , $w=xyz \text{ }$ , $\text{ } v=xy+yz+zx$ .  Then I realized that the term $2-x^2+x$ can be negative. So the AM-GM approach fail. I then try to homogenize the inequality, and hope that after expand every thing. I can obtain some obvious inequality. Well, I fail to homogenize it. I try to assume $x\leqslant y \leqslant z$ and come up with some estimations but I get stuck. I appreciate if anyone can attempt to solve it.","['symmetric-polynomials', 'algebra-precalculus', 'inequality']"
1444534,Integral by the given $u$-substitution,"Original equation $$\int\sqrt{e^t-5}dt \qquad u=\sqrt{e^t-5}$$
This is what I've done so far$$\int{u}dt$$ $$du=\frac{e^t}{2\sqrt{e^t-5}}dt$$$$dt=\frac{2\sqrt{e^t-5}}{e^t}du$$$$\int{u}{\frac{2\sqrt{e^t-5}}{e^t}}du$$ From this point on what would i need to do?","['substitution', 'indefinite-integrals', 'derivatives']"
1444537,Will adding a constant to a random variable change its distribution?,"Suppose I have a random variable $X$ and to this, I add a constant $c>0$. Will $X+c$ have a different distribution? From my intuition it seems so, but I am unable to prove it from a measure-theoretic point of view. Does the proof require measure theory? Thanks!","['probability', 'measure-theory']"
1444562,Every open set in $\mathbb{R}$ is a countable union of closed sets,"So, I have proven already that every open set in $\mathbb{R}$ can be written as a countable union of disjoint open intervals; i.e., that $\mathcal{O} = \bigcup_{i=1}^\infty (a_{x_i}, b_{x_i})$. Now, consider the closed interval $\left [ a + \frac{1}{n}, b - \frac{1}{n}\right ] \subset (a, b)$. Since the midpoint of $(a,b)$ is $\frac{b-a}{2}$, we need $\displaystyle n > \frac{2}{b-a}$. Otherwise, $\displaystyle a + \frac{b-a}{2} = a + \frac{1}{ \frac{2}{b-a}} = b - \frac{1}{ \frac{2}{b-a}} = b - \frac{b-a}{2}$, and our interval will be degenerate. Note that $\forall (a,b) \in \mathcal{O}$, $\displaystyle \bigcup_{n = \frac{b-a}{2}+1}^{\infty} \left[ a + \frac{1}{n}, b - \frac{1}{n} \right] = (a,b)$. So, we have $\displaystyle \mathcal{O} = \bigcup_{i=1}^\infty \left ( \bigcup_{n = \frac{b-a}{2} + 1}^\infty \left[ a_{x_i}+\frac{1}{n}, b_{x_i}-\frac{1}{n} \right] \right)$. But, I don't like this. It looks like I'm still just taking a union of open sets.  Please help me get this to look like the union of closed sets. (For unbounded intervals, I know what to do - it should follow from this relatively easily).","['real-analysis', 'general-topology']"
1444603,Boundedness of the solution of class of ODEs,"Let's have linear $$
\tag 1 y''(t) + b(t)y(t) = 0, \quad t \in (t_{0}, \infty )
$$
Here $|b(t)|$ is monotonically decreased function of time, and $\lim_{t\to \infty }b(t) = \frac{a}{t} \to 0$. How to prove that the solution of Eq. $(1)$ is bounded from above? An edit. I've made the mistake. The correct question is about boundedness of $\frac{y(t)}{t^{\frac{1}{4}}}$. Instead of Eq. $(1)$ the following equation arises:
$$
\tag 2 y''(t) + (k^{2} - ab(t))y(t) = 0, \quad b(t) \to \frac{f(t)}{\sqrt{t}},
$$
where $f(t)$ is bounded periodic function. Numerical simulations show that
$$
|y(t)| \leqslant \text{exp}\left[\alpha \times \frac{a}{\sqrt{k}}\right], \quad \alpha = O(1)
$$
It seems that the proof of boundedness can be performed through manipulations with integral representation
$$
y(t) = cos(kt)-a\int \limits_{t_{0}}^{t}sin(s - t)b(s)y(s)ds,
$$
which is equal to Eq.$(2)$. But I can show that Eq. $(2)$ has bounded solutions only in case of $|b(s)| \leqslant \frac{1}{t^{d + 1}}, d > 0$, while in this case $b(s) \to \frac{f(t)}{\sqrt{t}}$.","['asymptotics', 'stability-in-odes', 'ordinary-differential-equations']"
1444635,Find the coefficient $x^{14}$ in the $(1+x)(1+x+x^2)(1+x+x^2+x^3)\dots(1+x+\dots+x^{5})$.,"This is corresponding to finding no. of permutation of $\{1, 2, 3, 4, 5, 6\}$ having exactly $14$ inversions.","['discrete-mathematics', 'generating-functions', 'combinatorics']"
1444652,To prove the mutual independence of events,"If A$,B$ and $C$ are random events in a sample space and if $A,
B$ and $C$ are pairwise independent and $A$ is independent of $(B \cup C)$, then is it true that $A,B$ and $C$ are mutually independent. My Attempt : (with questions of this type at my college the answer is usually in the affirmative.) So to prove that  $A,B$ and $C$ are mutually independent, all that remains to show is that $P(A \cap B \cap C) = P(A) \times P(B) \times P(C)$. We know that $P(A \cap (B \cup C))=P(A) \times P(B \cup C)$. How do I go about this?","['probability-theory', 'probability', 'probability-distributions']"
1444677,How would I simplify my definite integral properly?,"Original equation $$\int_1^3\frac{1}{x^2-2x+5}\mathrm{d}x$$
Here is what I did starting with completing the square.$$(x^2-2x)+5\\(x^2-2x+1)+5+1\\(x-1)^2+6$$Then i plugged in back into the integral to use one of the inverse trig identities specifically tangent.$$\frac{1}{6+(x-1)^2}\\\frac{1}{\sqrt{6}}\mathrm{tan}^{-1}(\frac{x-1}{\sqrt{6}})$$Then i plugged in my limits.$$\frac{1}{\sqrt{6}}\mathrm{tan}^{-1}(\frac{3-1}{\sqrt{6}})-\frac{1}{\sqrt{6}}\mathrm{tan}^{-1}(\frac{1-1}{\sqrt{6}})$$
So how would I go on to simplify further than this?$$\frac{1}{\sqrt{6}}\mathrm{tan}^{-1}(\frac{2}{\sqrt{6}})$$","['solution-verification', 'definite-integrals', 'trigonometry']"
1444755,Use Integration by parts to prove the following reduction formula...,"Use integration by parts to prove the reduction formula $$\int\sin^n(x)\ dx = - {\sin^{n-1}(x)\cos(x)\over n}+{n-1\over n}\int\sin^{n-2}(x)\ dx$$ So I'm definitely on the right track because I'm very close to this result, and I also found an example of this exact question in one of my textbooks. I made f(x)=$\sin^{n-1}(x)$ and g'(x)=$\sin(x)$. And with that I got to the point of having $\int\sin^n(x)\ dx = - \sin^{n-1}(x)\cos(x)+(n-1)\int\cos^2(x)\sin^{n-2}(x)\ dx$ (sorry I haven't shown how I got to this stage, It's taking me way too long to write out these formulas, but the textbook done the same thing) Then the textbook then uses the identity $\cos^2(x)=1-\sin^2(x)$. Which would give: $\int\sin^n(x)\ dx = - \sin^{n-1}(x)\cos(x)+(n-1)\int(1-\sin^2(x))\sin^{n-2}(x)\ dx$ And then I would have thought expanding that last integral would give $\int\sin^n(x)\ dx = - \sin^{n-1}(x)\cos(x)+(n-1)\int\sin^{n-2}(x)-\int\sin^n(x))\\ dx$ However the textbook says you should get $\int\sin^n(x)\ dx = - \sin^{n-1}(x)\cos(x)+(n-1)\int\sin^{n-2}(x)-(n-1)\int\sin^n(x))\\ dx$ Lots of information but essentially my question is just this, where did that extra (n-1) come from? I can't figure it out and its preventing me from finishing the question. Thanks in advance :)","['trigonometry', 'calculus', 'integration']"
1444772,Determinant of a symmetric Toeplitz matrix,"Let $A_n = (a_{ij})$ be an $n\times n$ matrix such that $a_{ii} = 0, a_{ij} = 2$ when $|j − i| = 1$, and $a_{ij} = 1$ otherwise. The question is to find the determinant in terms of $n$. I computed the first six terms, depending on $n$, but, unfortunately, no clear relationship was found. Here they are:
\begin{align}
\det A_1&=0,\\
\det A_2&=-4,\\
\det A_3&=8,\\
\det A_4&=-7,\\
\det A_5&=0,\\
\det A_6&=7.
\end{align}
Laplace expansion turned out to be useful only if $n$ is known. How can one derive a formula for $\det A_n$ in terms of $n$?","['determinant', 'matrices']"
1444816,Solving a polynomial equation,"Find a polynomial $f$ of degree at the most 2, such that for every polynomial $g$ we have $$\int_0^1 f(x)g(x)\mathrm{d}x = g\left(\frac{1}{2}\right)$$ I started off my assuming $f(x) = a_0 + a_1x + a_2x^2$ and integrating for $g(x) = 1$, $x$ and $x^2$ and solving the equations for $a_i$ but it doesn't seem like the results I get satisfy the equation for all $g$. What am I doing wrong?","['polynomials', 'calculus', 'integration']"
1444823,What's special about measurable functions?,"Non-mathematician here, trying to grasp theory of integration. Why is it that the integral (or the $\mu$-integral) in, say, a measure theory book, is defined for measurable functions? The definition itself is first given for a simple function, which makes sense, and then we define the general integral of a positive integrand $g$ as $$ \sup\{ \int f \ d \mu : f \le g, f \ \text{is simple and positive}\}$$
and then further we define the integral of any $g$ in terms of $g^+$ and $g^-$ which are positive. But $g$ is always required to be measurable...where does measurability come into play here? Why is that important? Where does the theory fall apart when $g$ is non-measurable?","['measure-theory', 'integration']"
1444864,Difference between {... | ...} and {... : ...},"Is there a difference between the following two set related notations: $$\{~\dots~:~\dots~\}~\text{vs.}~\{~\dots~|~\dots~\}?$$ I take it they both mean ""such that"" but I was wondering why some authors prefer one to the other, maybe there is a historical background to it?","['elementary-set-theory', 'notation']"
1444892,Connected topological manifolds,"For any connected topological manifold, it is true that for any two points on the manifold, there exists a single local chart that both of two points lie in it. How can I prove it?","['manifolds', 'connectedness', 'general-topology']"
1444908,Finding $\int_0^{\infty} \frac{f(\alpha x)-f(\beta x)}{x}dx$ given $\lim_{x\to 0}f(x)$ and $\lim_{x\to \infty}f(x)$.,"Problem: Solution: $\bf 45. \; (a)\,$ The substitution $u=\alpha x$, $\mathrm{d}u=\alpha\,\mathrm{d}x$ gives $$\int_{\varepsilon}^N\frac{f(\alpha x)}{x}\mathrm{d}x=\int_{\alpha\varepsilon}^{\alpha N}\frac{f(u)}{u}\mathrm{d}u.$$ Similarly, the substitution $u=\beta x$, $\mathrm{d}u=\beta\,\mathrm{d}x$ gives $$\int_{\varepsilon}^N\frac{f(\beta x)}{x}\mathrm{d}x=\int_{\beta\varepsilon}^{\beta N}\frac{f(u)}{u}\mathrm{d}u.$$ So $$\begin{align}\int_{\varepsilon}^N\frac{f(\alpha x)-f(\beta x)}{x}\mathrm{d}x&=\int_{\alpha\varepsilon}^{\alpha N}\frac{f(u)}{u}\mathrm{d}u-\int_{\beta\varepsilon}^{\beta N}\frac{f(u)}{u}\mathrm{d}u\\&=\int_{\alpha\varepsilon}^{\beta\varepsilon}\frac{f(u)}{u}\mathrm{d}u-\int_{\alpha N}^{\beta N}\frac{f(u)}{u}\mathrm{d}u.\end{align}$$ As $\varepsilon\to0$ and $N\to\infty$, this approaches $$\int_{\alpha\varepsilon}^{\beta\varepsilon}\frac{A}{u}\mathrm{d}u-\int_{\alpha N}^{\beta N}\frac{B}{u}\mathrm{d}u=(A-B)\log\frac{\beta}{\alpha}.$$ $\bf (b)\,$ In this case the same substitutions give $$\int_{\varepsilon}^\infty\frac{f(\alpha x)}{x}\mathrm{d}x=\int_{\alpha\varepsilon}^\infty\frac{f(u)}{u}\mathrm{d}u,\qquad\int_{\varepsilon}^\infty\frac{f(\beta x)}{x}\mathrm{d}x=\int_{\beta\varepsilon}^\infty\frac{f(u)}{u}\mathrm{d}u,$$ so $$\int_{\varepsilon}^\infty\frac{f(\alpha x)-f(\beta x)}{x}\mathrm{d}x=\int_{\alpha e}^{\beta\varepsilon}\frac{f(u)}{u}\mathrm{d}u\to A\log\frac{\beta}{\alpha}.$$ I have two questions regarding this solution. First, how is the substitution $u=\alpha x, du=\alpha dx$ guaranteed to be valid? From my knowledge, the change of variables theorem for integrals work when the function $f(u)/u$ is continuous. This is the version I'm referring to, and all other change of variables theorems share this assumption. So I'm curious how the substitution is valid without the fact that the integrand is continuous. THEOREM 6.4.6. (Change of Variables Theorem) Suppose that there exists a differentiable function $g:[c,d]\to[a,b]$ such that $g'\in R[c,d]$. Also, suppose that a function $f:[a,b]\to\mathfrak{R}$ is continuous with $a=g(c)$ and $b=g(d)$. Then $$\int_c^d(f\circ g)(x)g'(x)\,\mathrm{d}x=\int_a^bf(x)\,\mathrm{d}x.$$ Finally, I don't follow the final lines in the solution of (a) and (b). How do $\int_{\alpha \epsilon}^{\beta \epsilon} \frac{f(u)}{u}du$ and $\int_{\alpha N}^{\beta N} \frac{f(u)}{u}du$ turn into $\int_{\alpha \epsilon}^{\beta \epsilon} \frac{A}{u}du$ and $\int_{\alpha N}^{\beta N} \frac{B}{u}du$ as $\epsilon \to 0$ and $N \to \infty$? I can't give a rigorous argument that this must be the case. I would immensely appreciate it if anyone could provide me with a rigorous argument to these questions.","['calculus', 'limits', 'real-analysis', 'integration', 'analysis']"
1444918,(Beginner) Intuition to solve a functional equation and steps for this particular-,"Please can someone please tell me the intuition behind solving a functional equation? For example, $$f(x)+f(y)=2f\left(\frac{x+y}2\right)f'\left(\frac{x-y}2\right)$$
Now at the first look, it seems like $f(x)=\sin x$, but how to solve it rigorously? P.S: As written in the title, I am a beginner and I have no experience at solving a functional equation. I know little bit about series expansions and I know calculus upto 12th grade. (Derivatives, Integrals (Impropers-a bit), Limits)","['functional-analysis', 'functions']"
1444943,Residue theorem for infinitely many singularities,"The residue theorem is a standard result in complex analysis, I state it below so we are on the same page: note that $\overline{\mathbb{C}}$ is the extended complex plane (ie. $\simeq$ Riemann sphere) Let $f : \overline{\mathbb{C}} \rightarrow \overline{\mathbb{C}}$ be a function which is analytic inside a positively-oriented closed contour $C \subset \overline{\mathbb{C}}$ apart from at a finite number of singular points $a_{1}, \ldots a_{n}$ which are contained inside $C$. Then we have the following result known as the residue theorem, \begin{eqnarray} \int_{C} f(z) \ dz = 2 \pi i \sum_{\nu = 1}^{n} \text{Res}_{z=a_{\nu}}f(z). \quad \quad \quad \quad \quad (1)\end{eqnarray} My question is: what if $n = \infty$? There must be extra conditions in this case because, while the left hand side of (1) may converge, the right hand side of (1) becomes a series and may not converge. A thought: if $\sum_{\nu=1}^{\infty} \text{Res}_{z=a_{\nu}}f(z)$ is only a formal series, then perhaps it represents $\frac{1}{2\pi i}\int_{C}f(z) \ dz$ asymptotically. ie. $\frac{1}{2\pi i}\int_{C}f(z) \ dz \sim \sum_{\nu=1}^{n} \text{Res}_{z=a_{\nu}}f(z)$ as $n \rightarrow \infty$, is this the answer?","['analysis', 'complex-integration', 'residue-calculus']"
1444967,Proving that $\Gamma \left(n+ \frac{1}{2}\right) = \frac{(2n)!\sqrt{\pi}}{2^{2n}n!}$.,"The proof I am dealing with is worded exactly as follows: Prove $\Gamma\left(n+ \frac{1}{2}\right) = \frac{(2n)!\sqrt{\pi}}{2^{2n}n!}$. The proof itself can be done easily with induction, I assume. However, my issue is with the domain of the given $n$; granted, the factorial operator is only defined for positive integer values. However, the gamma function, as far as I know, is defined for all complex numbers bar $\mathbb{Z}^-$. I don't think induction will suffice for generalizing the proof for said domain. Would that be necessary, or should I be looking for other methods to tackle the proof?","['gamma-function', 'complex-analysis']"
1444985,Can a non-trivial conjugacy class in $A_n$ contains $<n$ elements?,"In one of the proofs of simplicity of $A_n$ ($n\geq 5$), a fact used is the following: There is no (non-identity) conjugacy class in $A_n$ containing $<n$ elements. I initially was using simplicity of $A_n$; but that was the aim behind use of this fact. Any hint for proving this fact? Also, is there always a conjugacy class in $A_n$ with exactly $n$ elements?","['group-theory', 'simple-groups']"
1444988,Group of order $432$ is not simple,"How do we prove that a group $G$ of order $432=2^4\cdot 3^3$ is not simple? Here are my attempts:
Let $n_3$ be the number of Sylow 3-subgroups.
Then, by Sylow's Third Theorem, $n_3\mid 16$ and $n_3\equiv 1 \pmod 3$.
Thus, $n_3=1, 4$ or 16. Next, let $Q_1$ and $Q_2$ be two distinct 3-subgroups such that $|Q_1\cap Q_2|$ is maximum. If $|Q_1\cap Q_2|=1$, then we can conclude $n_3\equiv 1\pmod {3^3}$, which will force $n_3=1$ and we are done. If $|Q_1\cap Q_2|=3$, similarly we can conclude $n_3\equiv 1\pmod {3^2}$, and we are done. The problem occurs when $|Q_1\cap Q_2|=3^2$, we can only conclude $n_3\equiv 1\pmod 3$ which is of no help. Thanks for help!","['abstract-algebra', 'sylow-theory', 'group-theory', 'finite-groups']"
1445000,Probability of $7$ tails in a row twice in $100$ coin flips,"The starting point for my problem was the chance of having a $7$ tails in a row if you flip a coin $100$ times. I found this excellent explanation of calculating it: http://www.leancrew.com/all-this/2009/06/stochasticity/ My question: What is the chance of having (at least) $7$ tails occurring (at least) two times in a $100$ coin flip sequence? In general: $s$ is a sequence of length $n$ and $r$ is the number of repetitions, what are the odds that I found at least $r$ repetition of sequence $s$ in a sequence $S$ that has a length of $N$.","['probability', 'statistics']"
1445022,what are fundamental groups of (almost) complex manifolds?,Are there any restrictions on the fundamental group of an even-dimensional manifold admitting an almost complex structure? integrable almost complex structure? or can I construct any of these with a given fundamental group (presumably finitely generated)?,"['complex-geometry', 'differential-geometry', 'almost-complex', 'fundamental-groups']"
1445027,"Let $u_{n+2} = u_{n+1} + u_n$ where $u_1 = a, u_2 = b$. How many pairs exists $(a,b)$ such that $u_k = 21$ for some $k$?","A sequence of non negative integers $u_n$ is defined by $u_1 = a, u_2 = b$ and $u_{n+2} = u_{n+1} + u_n$. How many pairs of non-negative integers $(a,b)$ are there such that $21$ is a term of the sequence with $a \not = 21$ and $b \not = 21$? The solution to this question is 40, however I was hoping there was a quicker solution to the question other than brute force. I tried brute force two ways, one was to enumerate values (a,b) and check them, this was quite slow even with some subtle clues: I worked out if $(a,a)$ was a solution then so was $(a,0)$ and $(0,a)$ and that if you write out a sequence for some $(a,b)$ that has $21$ in it, then all pairs before $21$ will work. I also tried another brute force method where I observed the sequence went $a,b,a+b,a+2b,2a+3b,3a+5b,5a+8b,8a+13b,13a+21b,21a+34b$ and then went through the terms and found solutions to the equation, faster but still slow. This question is from a math competition and suspect both are too slow, a third solution I thought of was finding the closed form but this method is still quite slow (and too advanced for the person I am helping) Does anyone have a solution for this, that would be suitable in a maths competition? I'm sure this is some sort of trick but I can't see it. Source of question: Senior Team Maths Challenge 2014/15 regional final Thanks","['contest-math', 'sequences-and-series', 'discrete-mathematics']"
1445058,Which rationals can be written as the sum of two rational squares?,"Which rational numbers can be written as the sum of two rational squares? That is, for which rational numbers $a$, are there rational numbers $x$ and $y$ such that $a = x^2 + y^2$. It is a famous theorem that if an integer can be written as the sum of two rational squares then it can be written as the sum of two integral squares, and then the solution is the famous one by Fermat, but I didn't find anything about the general case.",['number-theory']
1445090,Discrete math combinatorial proof,"Prove that for every positive integer n, $$\sum_{k=0}^{n}\binom{n}{k}^2=\sum_{l=0}^{n}\sum_{r=0}^{\frac{n-l}{2}}\binom{n}{l}\binom{n-l}{r}\binom{n-l-r}{r}$$ I know that $\sum_{k=0}^{n}\binom{n}{k}^2=\binom{2n}{n}$ but I can't seem to find a way to connect it to the right side. Any help would be appreciated, I've been trying to figure this out for days.","['combinatorial-proofs', 'binomial-coefficients', 'discrete-mathematics', 'proof-writing']"
1445111,Is the term $E\left[Z^3E[Z\mid Y] \right]$ positive or negative?,"Let $Z$ be standard normal and $Y$ some other random variable. Is the $E\left[Z^3E[Z\mid Y] \right]$ positive or negative?
I tried a few things like using orthogonality principle
\begin{align}
E\left[Z^3E[Z\mid Y] \right]=E[E[Z^3\mid Y]E[Z\mid Y]]=E[E[Z^3\mid Y]Z]
\end{align} but this didn't go anywhere? This  question is related to something I asked a while ago here . But now the structure of $Y$ is unspecified.","['probability-theory', 'conditional-expectation', 'probability']"
1445115,Why is the support of a measure closed?,"I found the following statement on Wikipedia The support of a measure is closed in $X$ as its complement is the union of the open sets of measure 0. where $X$ is from a topological space $(X, T)$ and the mentioned measure, call it $\mu$, is on the space $(X, \mathcal{B}(T))$. Why are the sets of measure zero open?",['measure-theory']
1445154,Step in computation of the expected cover time for the simple random walk on a discrete circle,"I'm having a little trouble understanding part of an example in Lawler's Intro to Stochastic Processes (""Simple Random Walk on a Circle"" example on page 32). The problem is the following: Suppose $\{X_n, n \geq 0 \}$ is a simple random walk on a cycle (or ""clique"", as in graph theory) of length $N$. Compute the expected number of steps the process takes to hit every vertex. I'll go through the main parts of his solution and point out which part is causing my confusion. Let $T_k$ be the time at which the random walk has hit $k$ distinct vertices (so, $T_1 = 0$ and $T_2 = 1$ a.s.). We compute the quantity
$$
r(k):= \mathbb{E} (T_k - T_{k-1}), \hspace{5mm} 3 \leq k \leq N
$$
Observe that at time $T_{k-1}$, the walk has reached the $(k-1)^{\text{th}}$ distinct vertext, and will either hit a new vertex or return to its other neighbor (a vertex that has already been visited). Now, applying the result of the gambler's ruin problem, $$ r(k) = 1+\frac{1}{2} \Big( (k-3) +r(k) \Big)$$ Hence, $r(k) = k-1$, and
$$
\mathbb{E}(T_N) = 1+ \sum_{n = 3}^{N} r(k) = \frac{N(N-1)}{2}
$$ I understand that the $(k-3)$ in the above blockquote comes from a direct application of the gambler's ruin problem (expected time until absorption for a simple random walk with absorbing boundaries), but I'm having a hard time convincing myself why this formula for $r(k)$ is valid. I'd appreciate any help.","['probability-theory', 'random-walk']"
1445165,Why adjugate matrix 2x2 is different from 3x3 and others?,"I've understand the simple way of calculating the adjugate matrix. In short: 1). We need to calculate all cofactors: Using the next formula: $A_{ij} = (-1)^{i+j} M_{ij}$ 2). Transpose it. It's also can be read from Wikipedia: https://en.wikipedia.org/wiki/Adjugate_matrix In linear algebra, the adjugate, classical adjoint, or adjunct of a
  square matrix is the transpose of the cofactor matrix. If to view examples, such short algorithm is correct for squared matrices 3x3 and larger... But, for 2x2 is just a rule: M = [ a b ]
    [ c d ]

adj( M ) = [  d -b ]
           [ -c  a ] What do I dislike? I dislike that, because it's some kind of prayer. And many forums in web are saying: Just remember it? right? Damn! People, it's a MATH, it's not some humanity science like history. It's A MATH, math consists of logic and explanation as any other technical stuff. I don't want just to remember stupidly some formula, I want understand why is exactly using such adjugate calculation especially for matrix 2x2? I don't understand the next... For the matrix 3x3 we calculate all cofactors and then transpose it, for e.g.: Original:
1   2   3
2   5   4
5   2   3

Cofactor matrix:
  7  14 -21
  0 -12  8
 -7   2  1

Transposed cofactor matrix:
  7   0 -7
 14 -12  2
-21   8  1 As you can see the transpose process for 3x3 didn't exchange the value a11 and a33, but why there is such an exchange for 2x3 matrix? I don't understand... I want to get logical explanation, not just a strict prayer. I want to hear explanation why? and such explanation must be logical.","['linear-algebra', 'matrices']"
1445191,Indefinite integral $\int xe^x (x+1)^{-2}dx$,"I was solving a differential equation by reduction of order, and was required to evaluate the indefinite integral $$I=\int \frac{xe^x}{(x+1)^2}dx.$$ The only method that came to mind was inspection, i.e. recognizing that $$ \frac{d}{dx} \frac{e^x}{x+1} = \frac{xe^x}{(x+1)^2}.$$ I would not trust myself to recognize this under the pressure of a test or exam, so is it possible to evaluate $I$ by substitution, parts, or some other method?","['calculus', 'indefinite-integrals', 'integration', 'analysis', 'ordinary-differential-equations']"
1445199,Picture of set of nilpotent $2 \times 2$ matrices over $\mathbb{R}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What does the set of nilpotent $2 \times 2$ matrices over $\mathbb{R}$ look like?","['abstract-algebra', 'linear-algebra', 'matrices']"
1445204,Showing that $x^x/(2x)!=0$ as $x$ approaches infinity,How would I show $$\lim_{x\to\infty} \frac{x^x}{(2x)!}=0$$ I know $x^x$ grows faster than $(2x)!$ So then would I do $$\frac{x^x}{2x(2x-1)(2x-2)(2x-3)\cdots(2x-(2x-1))}$$ But how do I proceed.,"['factorial', 'calculus', 'limits', 'exponentiation']"
1445264,Finite Population Correction on sample size,"Estimate of percent of an infected species is accurate to within $\pm 0.04%$ with $95\%$ CI Between $15\%$ and $35\%$ of the population are infected Size of the population is between $1100$ and $2300$ Calculate the sample size. My calculations:
For $15\%$ , $n = 306$
For $35\%$, $n = 546$ Since population is between $1100$ and $2300$ , finite population correction is required. How can I determine the sample size adjusted by finite population correction? Do I have to take the weighted average of the smaller and greater $n$? 
Or should I simply use the larger $n$?",['statistics']
1445269,Discrete subgroups of $\mathbb R^n$ are free,"Let $G$ be a nonzero subgroup of the additive group $\mathbb{R}^n$. Assume $G$ is discrete in the sense that for any $x \in G$, there exists an open set $U \subset \mathbb{R}^n$ such that $U \cap G = \{x\}$. Does it follow that there exists an integer $1 \le k \le n$ and $k$-tuple $x_1, \dots, x_k \in \mathbb{R}^n$ of $\mathbb{R}$-linearly independent vectors such that $G = \mathbb{Z}x_1 + \cdots + \mathbb{Z}x_k$, i.e., such that $G$ is the free abelian group with basis $x_1, \dots, x_k$? I suspect the answer is yes... perhaps we could chose an element in $G$ of minimal Euclidean length of use induction on $n$? But then I am stuck. Can anyone help me?","['abstract-algebra', 'group-theory', 'linear-algebra', 'free-groups']"
1445288,Del operator in Cylindrical coordinates (problem in partial differentiation),"I am currently reviewing basic vector analysis and trying to understand every single detail, however, I got stuck in some derivation. What I want to show is the following: Given the del operator (i.e., vector differential operator) in
  Cartesian coordinates $(x,y,z)$ $$\nabla=\frac{\partial }{\partial x}\mathbf{a}_x+\frac{\partial
 }{\partial y}\mathbf{a}_y+\frac{\partial }{\partial z}\mathbf{a}_z$$ show that the corrseponding operator in Cylindrical coordinates
  $(\rho, \phi ,z)$ is given by$$\nabla=\frac{\partial }{\partial\rho}\mathbf{a}_\rho+\frac{1}{\rho}\frac{\partial }{\partial
 \phi}\mathbf{a}_\phi+\frac{\partial }{\partial z}\mathbf{a}_z$$ I tried one approach. However, for curiosity I tried a different method but I couldn't get it right. Approach #1: From the point-to-point transformation
$$\rho=\sqrt{x^2+y^2}, \; \phi=\text{tan}\frac{y}{x}$$ partial differentiation with respect to $x$ and $y$ yields
\begin{align} \frac{\partial \rho}{\partial x} &=\frac{x}{\sqrt{x^2+y^2}}=\frac{\rho \, \text{cos}\phi}{\rho}=\text{cos}\phi \\
                \frac{\partial \rho}{\partial y}&=\frac{y}{\sqrt{x^2+y^2}}=\frac{\rho \, \text{sin}\phi}{\rho}=\text{sin}\phi 
\end{align}
and
\begin{align} \frac{\partial \phi}{\partial x}&=\frac{-y}{x^2}\frac{1}{1+(\frac{y}{x})^2}=\frac{-y}{x^2+y^2}=\frac{-\rho \, \text{sin}\phi}{\rho^2}=\frac{-\text{sin}\phi}{\rho} \\
                \frac{\partial \phi}{\partial y}&=\frac{1}{x}\frac{1}{1+(\frac{y}{x})^2}=\frac{x}{x^2+y^2}=\frac{\rho \, \text{cos}\phi}{\rho^2}=\frac{\text{cos}\phi}{\rho}
\end{align} Now, plugging these in the chain rule differentiation formulas 
\begin{align} \frac{\partial }{\partial x}&=\frac{\partial }{\partial \rho}\;\frac{\partial \rho}{\partial x}+\frac{\partial }{\partial \phi}\;\frac{\partial \phi}{\partial x} \\
\frac{\partial }{\partial y}&=\frac{\partial }{\partial \rho}\;\frac{\partial \rho}{\partial y}+\frac{\partial }{\partial \phi}\;\frac{\partial \phi}{\partial y}
\end{align} and making use of the unit vector transformation from Cartesian to Cylindrical
 \begin{align} \mathbf{a}_x&=\text{cos}\phi\;\mathbf{a}_\rho-\text{sin}\phi\;\mathbf{a}_\phi\\
\mathbf{a}_y&=\text{sin}\phi\;\mathbf{a}_\rho+\text{cos}\phi\;\mathbf{a}_\phi
\end{align} We get
 \begin{align} \nabla&=\frac{\partial }{\partial x}\mathbf{a}_x+\frac{\partial
 }{\partial y}\mathbf{a}_y+\frac{\partial }{\partial z}\mathbf{a}_z  \\
               &=\left (\frac{\partial }{\partial \rho}\;\frac{\partial \rho}{\partial x}+\frac{\partial }{\partial \phi}\;\frac{\partial \phi}{\partial x}  \right )\left ( \text{cos}\phi\;\mathbf{a}_\rho-\text{sin}\phi\;\mathbf{a}_\phi \right )\\
&+\left ( \frac{\partial }{\partial \rho}\;\frac{\partial \rho}{\partial y}+\frac{\partial }{\partial \phi}\;\frac{\partial \phi}{\partial y} \right )\left ( \text{sin}\phi\;\mathbf{a}_\rho+\text{cos}\phi\;\mathbf{a}_\phi \right )+\frac{\partial }{\partial z}\mathbf{a}_z  \\
               &=\left (\frac{\partial }{\partial \rho}\;\text{cos}\phi+\frac{\partial }{\partial \phi}\;\frac{-\text{sin}\phi}{\rho}  \right )\left ( \text{cos}\phi\;\mathbf{a}_\rho-\text{sin}\phi\;\mathbf{a}_\phi \right )\\
&+\left ( \frac{\partial }{\partial \rho}\;\text{sin}\phi+\frac{\partial }{\partial \phi}\;\frac{\text{cos}\phi}{\rho} \right )\left ( \text{sin}\phi\;\mathbf{a}_\rho+\text{cos}\phi\;\mathbf{a}_\phi \right )+\frac{\partial }{\partial z}\mathbf{a}_z\\
&=\left ( \text{sin}^2\phi+\text{cos}^2\phi \right )\frac{\partial }{\partial \rho}\mathbf{a}_\rho+\frac{1}{\rho}\left ( \text{sin}^2\phi+\text{cos}^2\phi \right )\frac{\partial }{\partial \phi}\mathbf{a}_\phi+\frac{\partial }{\partial z}\mathbf{a}_z\\
&=\frac{\partial }{\partial\rho}\mathbf{a}_\rho+\frac{1}{\rho}\frac{\partial }{\partial
 \phi}\mathbf{a}_\phi+\frac{\partial }{\partial z}\mathbf{a}_z 
\end{align} which is the desired result. Approach #2: How can I get the same result starting from the point-to-point transformation
$$x=\rho \, \text{cos}\phi,\; y=\rho \, \text{sin}\phi$$
by using partial differentiation? Maybe implicit differentiation?","['partial-derivative', 'vector-analysis', 'transformation', 'derivatives']"
