question_id,title,body,tags
2019512,Problem 4.4 in Isaacs (Algebra a graduate course),"I'm trying to prove this (problem 4.4 in Isaac's book) Le $\varphi:G\rightarrow H$ be a surjective homomorphism with $|G|$ finite and let $g \in G$. Show that \begin{equation}|C_{G}(g)|\geq|C_{H}(\varphi(g))|\end{equation} HINT: Show that the conjugacy class of $g$ in the inverse image in $G$ of $C_{H}(\varphi(g))$ has size $\leq|ker(\varphi)|$. I'm trying to interpret the hint but I'm stuck in it. 
First, I think that it suggest to restrict the conjugacy class of $g$ (i.e., $\mathcal{O}_g$) to $C_{H}(\varphi(g))$, i.e., \begin{equation}\mathcal{O}^{restricted}_{g} = \{x^{-1}gx\,|\,x\in C_{H}(\varphi(g))\}\end{equation} Second, I think that it maybe suggest that I have to take the intersection between the conjugacy class of 
$g$ and $C_{H}(\varphi(g))$, i.e.,
\begin{equation}\mathcal{O}_g\cap C_{H}(\varphi(g))\end{equation} Either way, I'm stuck. I just want help to interpret the hint. Thank you all.","['finite-groups', 'abstract-algebra', 'group-theory']"
2019525,MLE of $\delta$ for the distribution $f(x)=e^{\delta-x}$ for $x\geq\delta$.,"Let $X_1,X_2,\dots, X_n$ be a random sample form a distribution $f(x)=e^{\delta-x}$ for $x\geq\delta$. Find MLE of $\delta$. My solution : $$L(\hat\gamma)=\prod_{i=1}^nf(x_i\mid \delta)=\prod_{i=1}^ne^{\delta-x} =e^{n\delta}e^{\sum_{i=1}^nx_i}$$ The log likelihood is $l(\hat\delta)=n\delta-\sum_{i=1}^n x_i$. To find the $\max$ we take the 1st derivative with respect to $\delta$:
$$l'(\hat\delta)=n$$
the first derivative cannot be zero. I am not sure how to proceed.","['exponential-distribution', 'maximum-likelihood', 'statistics', 'statistical-inference']"
2019535,Remainder of polynomial divisions(with degrees more than 1),"Let's say we want to calculate the remainder of $$x^7+5x^3+2x+3 $$ divided by $$x^2 + 1$$ My teacher told us to this: $$  x^7+5x^3+2x+3=(x^2+1)Q_{(x)}+r {(x)} $$
$$
({x^2})^3x+5(x^2)x +2x+3=(x^2+1)Q_ {(x)}+r _{(x)}$$ Let $x^2=-1$ $$({-1})^3x+5(-1)x +2x+3=((-1)+1)Q_ {(x)}+r _{(x)}$$ So $$r_{(x)}=-x-5x+2x+3=-4x+3$$ The only problem is: i don't understand why it's legal (!) to assign a value to $x^2$ and not $x $ (won't x be equal to $i$ anyway?) and then calculate the function. (I know that If it was $x+1$ instead of  $x^2+1$ i could calculate the function for $x=-1$ with no problem!) Thanks for your explanation!","['polynomials', 'functions', 'divisibility']"
2019565,definition of gradient vector field.,"I don't understand the definition of gradient vector field. Let $M$ be a manifold, $f:M\rightarrow \mathbb{R}$ be a smooth function and $\varphi_1,\varphi_2:U\rightarrow \mathbb{R}^n$ be coordinate charts of $M$. It's my understanding that grad$f$ on $U$ is the tangent vector firld$:U\rightarrow TU$ 
$$p \mapsto \frac{\partial f_1}{\partial x^1_1}(\varphi_1(p))\frac{\partial}{\partial x^1_1}+\dots +\frac{\partial f_1}{\partial x^1_n}(\varphi_1(p))\frac{\partial}{\partial x^1_n}$$,
 where $f_1=f\circ\varphi_1^{-1}:\varphi_1(U)\rightarrow \mathbb{R}$ and $(x^1_1,...,x^1_n)$ is the coordinate system of $\varphi_1(U)$. If this definition is correct and it doesn't depend on the choice of chart, it must coincide with 
$$p \mapsto \frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\frac{\partial}{\partial x^2_1}+\dots +\frac{\partial f_2}{\partial x^2_n}(\varphi_2(p))\frac{\partial}{\partial x^2_n}$$,
 where $f_2=f\circ\varphi_2^{-1}:\varphi_2(U)\rightarrow \mathbb{R}$ and $(x^2_1,...,x^2_n)$ is the coordinate system of $\varphi_2(U)$. However, these two coincides iff 
$$
\begin{pmatrix}
\frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\\
\dots\\
\frac{\partial f_2}{\partial x^2_n}(\varphi_2(p))
\end{pmatrix}
=D(\varphi_2\circ \varphi_1^{-1})
\begin{pmatrix}
\frac{\partial f_1}{\partial x^1_1}(\varphi_1(p))\\
\dots\\
\frac{\partial f_1}{\partial x^1_n}(\varphi_1(p))
\end{pmatrix}=
D(\varphi_2\circ \varphi_1^{-1})(D(\varphi_2\circ \varphi_1^{-1}))^T\begin{pmatrix}
\frac{\partial f_2}{\partial x^2_1}(\varphi_2(p))\\
\dots\\
\frac{\partial f_2}{\partial x^2_n}(\varphi_2(p))
\end{pmatrix}
$$, where $D(\varphi_2\circ \varphi_1^{-1})$ is the Jacobian matrix, and this doesn't necessarily hold. Where is the misunderstanding?","['differential-geometry', 'calculus', 'vector-analysis']"
2019585,"If $ 0 \le b \le a$, Prove $a \pmod b \lt \frac{a}{2}$","If $ 0 \le b \le a$, Prove $a \pmod b \lt \frac{a}{2}$ Intuitively it sounds right, the remainder of the $a \pmod b$ has to be lower than $\frac{a}{2}$. I tried to solve this like this, let's assume that $a \pmod b \gt \frac{a}{2}$, and look at the numbers $a = 8$ and $b = 0,1,2,...,8$ and check the remainders, we will see that the remainder will be $0,1,2,3$. which means if I go somehow with induction I'll prove that for any $a$,$b$. Is there a chance you can help me write it right with induction? I thought about: Base: $a = 1, b = 1$. Works Assumption: $a = n , b = 1,2,..,n$ Prove for $a = n+1, b = 1,2,..,n+1$ But I'm not sure how to proceed from here, maybe there is a simpler proof? So for my bad math skills :(","['discrete-mathematics', 'elementary-number-theory']"
2019588,Mean value theorem understanding,"So I have this question here which says: Say that f is differentiable and $f'(x)\neq1$ on $(-\infty,\infty)$. Show that there is at most one real number $a$ such that $f(a)=a$ I'm supposed to use the mean value theorem with the function $g(x)=f(x)-x$ but i'm not really sure how I'm supposed to incorporated the mean value theorem into this... I tried to substitute for $f(b)$ with $g(b)+b$ and simplify things but i'm not getting anywhere. Any help on this please?","['derivatives', 'calculus']"
2019620,Different results implicit differentiation,"When trying to differentiate $\frac{x+y}{xy}=x$, I get different results. If I use the quotient rule:
$$
\begin{array}{rcl}
\dfrac{xy(1+y´)-(x+y)(xy´+y)}{(xy)^2} &=& 1 \\
\dfrac{xy+xyy´-x^2y´-xy-xyy´-y^2}{(xy)^2} &=& 1 \\
-x^2y´ -y^2 &=& x^2y^2 \\
y´ &=& \dfrac{-(y^2+x^2y^2)}{x^2}
\end{array}
$$
On the other hand if I do the following
$$
\begin{array}{rcl}
\dfrac{x+y}{xy} &=& x \\
x+y &=& x^2y \\
1+y´ &=& x^2y´ +2xy \\
y´ -x^2y´ &=& 2xy-1 \\
y´ &=& \dfrac{2xy-1}{1-x^2}
\end{array}
$$
I don't understand what's happening.","['derivatives', 'implicit-differentiation', 'calculus']"
2019624,Value of complex integral,"Let $\alpha,\beta,\gamma\in\mathbb{C}$. I'd like to calculate the integral
$$\int_{-\infty}^{0}t^\alpha e^{\beta t}(1-e^{-2t})^\gamma dt.$$ For some special cases like when $\gamma=0$ or if $\gamma\in\mathbb{R}$, I can find the value of the integral explicitly. However, I can't find how to compute this integral for the general case. How can I find it?","['calculus', 'complex-analysis', 'improper-integrals', 'integration', 'definite-integrals']"
2019652,ring of adeles: ring of integers or valuation ring,"I have read different definitions of the ring of adeles: The ring of adeles is defined as the restricted topological product of the completions $K_v$ of a number field $K$ either with respect to the ring of integers of $K_v$ or with respect to the valuation ring of $K_v$. Do these definitions coincide? If not, what is the ""correct"" definition?","['local-field', 'adeles', 'algebraic-number-theory', 'number-theory', 'valuation-theory']"
2019731,"Condition for an algebra to be finite, which does not use the underlying set","I wonder whether there is any categorical property that picks out
  exactly the finite algebras of some algebraic theory without referring to the underlying set. What I mean is: I don't want to use the the structure of a functor $\mathcal{A} \to \mathsf{Set}$ from my algebraic category. This is (obviously) not so interesting, but more importantly I want the property to make sense in the absence of any such structure too (obviously I could have a different interpretation then, I'm open to anything interesting). No cheating allowed, of course! You can't refer to the free object on a singleton, because that doesn't make any sense in a general category (e.g. you can't use $\mathcal{A}(\mathbb Z, G)$ to count the elements in a group $G$ as $\mathbb{Z}$ is determined by some property involving the functor $\mathcal{A} \to \mathsf{Set}$; even though you can characterise $\mathbb{Z}$ by different means, this probably doesn't make much sense for other kinds of algebras besides groups). Here are some necessary conditions for an algebra $A$ to be finite (but I don't see how any of them are sufficient): the poset of subobjects $\operatorname{Sub} A$ is finite $A$ is finitely generated ($\mathcal{A}(X,\_)$ preserves filtered colimits of monos) the monoid of endomorphisms $\operatorname{End} A$ is finite $A$ is Dedekind-finite, i.e.: every mono (injection) $A\to A$ is an isomorphism I'd also be interested in a property for some (not to small ) subclass of all theories or a statement, that what I'm trying to do is infeasible.","['category-theory', 'abstract-algebra', 'universal-algebra']"
2019735,Diophantine equation $7b^2+7b+7=a^4$.,"Solve in positive integers $(a,b)$ the equation 
  $$7b^2+7b+7=a^4.$$ As the left side is divisible by $7$ we must have $7|a^4\implies 7|a$. Let $a=7c$, then the given equation reduces to $$b^2+b+1=343c^4.$$
I'm not sure how to proceed. Any hints or solutions are welcome.","['number-theory', 'diophantine-equations']"
2019744,On polynomials taking infinitely many prime values,"We know Dirichlet's theorem on arithmetic progressions: If $(m,n)\in \mathbb Z^2$ such that $\gcd(m,n)=1$ , then there are infinitely many prime numbers $p$ of the form $$ p=m+kn$$ where $k\in \mathbb Z$ . Then I asked myself the following: Let $P=\displaystyle\sum_{i=0}^n a_iX^i$ be in $\mathbb Z[X]$ such that $n\geqslant 1$ , $\gcd(a_0,\ldots,a_n)=1$ , $P$ is irreducible on $\mathbb Z[X]$ . Do there exist infinitely many integers $k$ such that $P(k)$ is prime? I don't think this is true since I've never heard of it, and we would not talk so much about Dirichlet's theorem if this result were true. Is there a way to disprove that result?","['number-theory', 'prime-numbers']"
2019750,How can I determine that $Y_n$ can be represented as a funtion of $X_n$,"On enter I'm having a sequence of pairs $(X_n, Y_n)$. Consider the following two graphics of two possible sequences. in first case $Y_n$ can be modeled as $f(X_n)$ while in second case it obviously has no sense. The question is how can I determine if trying to represent $Y_n$ as $f(X_n)$ makes sense? Probable there is some criterium or something like that? What can be done in multivariate situation (i.e. when we're trying to represent $Y_n$ as $f(X_1^{(n)}, X_2^{(n)}, ..., X_k^{(n)})$)? Please note that trying to fit points with something graphicaly (e.g. like on first graph) and seeing if it fits the data is not OK. I'm looking for numerical criterium. UPD. the variant that I'm thinking of is trying to look at variation of sequence. I.e. we order $(X_n, Y_n)$ in such a way that $X_{k-1} < X_k < X_{k+1}$ and then look at $\sum_{i=1}^N \frac{|Y_i - Y_{i-1}|}{X_i - X_{i-1}}$. And there can even be an analog for multivariate case.","['regression', 'statistics', 'calculus']"
2019768,Lifting a holomorphic map between Complex Tori to the Complex Plane,"Given a holomorphic map $$\phi:\frac{\mathbb{C}}{\Lambda}\to\frac{\mathbb{C}}{\Lambda'}$$ My aim is to lift it to a holomorphic map $\Phi:\mathbb{C}\to\mathbb{C}$. The author has hinted to use the lifting property for this. I know that if $\tilde{X}$ is a covering space of $X$ then any map $f:Y\to X$ can be lifted to a map $\tilde{f}:Y\to\tilde{X}$. Since $\mathbb{C}$ is the covering space of any complex tori with covering map being the canonical projection map (correct me if I'm wrong). Hence my aim is to find a holomorphic $\Phi$ such that the diagram commutes. $$\begin{array}
A\mathbb{C} & \stackrel{\Phi}{\longrightarrow} & \mathbb{C} \\
\downarrow{p_1} & & \downarrow{p_2} \\
\frac{\mathbb{C}}{\Lambda} & \stackrel{\phi}{\longrightarrow} & \frac{\mathbb{C}}{\Lambda'}  
\end{array}
$$
How do I proceed? Thank you. Edit: I recently checked this question . How can we show that the lift of this holomorphic function will be holomorphic?","['algebraic-topology', 'complex-analysis']"
2019784,Is every odd order skew-symmetric matrix singular?,We call a square matrix $A$ a skew-symmetric matrix if $A=-A^T$ . A matrix is said to be singular if its determinant is zero. Is every odd order skew-symmetric matrix with complex entries singular?,"['matrices', 'linear-algebra', 'skew-symmetric-matrices']"
2019844,Well defined function meaning,A function is said to be well defined if x=y implies f(x)=f(y). If x=y then surely wont f(x)=f(y). I cant get this through my head. Plz explain what a well defined function is n what is an ill defined one. It puzzles me a lot to think of an ill defined one.,['functions']
2019859,Sum of $\sum_{n \geq 1} \frac{(\ln x +1)^n}{n^n}$,"I want to find the sum of the following series $$\sum_{n \geq 1} \frac{(\ln x +1)^n}{n^n}$$ Using theorems on integration and differentiation of series. I can set $t=\ln x+1$ so that I get 
$$\sum_{n \geq 1} \frac{t^n}{n^n}$$ But then I don't see how to proceed, since that $n^n$ is difficult to see as the result of a differentiation or integration.
How can I see it?","['real-analysis', 'sequences-and-series', 'calculus', 'summation', 'power-series']"
2019864,Decreasing term assurance - find the interest rate,"A formula for decreasing term assurance is:
$$
 V_0 = V_k \times \left(\frac{1-(1+r)^{-n}}{1-(1+r)^{-(n-k)}}\right)
$$
where $r$ is the annual rate of interest, $V_0$ is the sum assured at time $t=0$ and $V_k$ is the sum assured at time $t=k$.  The formula is normally used to obtain the original sum assured (ie $V_0)$ when the sum assured $V_k$ at time $t=k$ is known and when $r$ is known. However, if $V_0, V_k, n, k$ are all known, is it possible to determine the annual rate of interest $r$? As $0< r <1$ initially I thought I could use the negative binomial theorem to rearrange the original expression:
$$
(1 + r)^{-n} = 1 - nr + \frac{1}{2}n(n+1)r^2 - \frac{1}{6}n(n+1)(n+2)r^3 +
$$
If I let $L = \frac{V_0}{V_k}$ and if I let $m = n-k$, then the original expression is:
\begin{eqnarray*}
 L &=& \frac{1-(1+r)^{-n}}{1-(1+r)^{-m}} \iff L - L(1+r)^{-m} &=& 1-(1+r)^{-n}
\end{eqnarray*} After substituting in expressions for $(1+r)^{-n}$ and $(1+r)^{-m}$ and then some simple tidying up I obtain the expression:
$$
L\left(mr - \frac{1}{2}m(m+1)r^2 + \cdots \right) = \left(nr - \frac{1}{2}n(n+1)r^2 + \cdots\right)
$$
or equivalently
$$
\left(nr - \frac{1}{2}n(n+1)r^2 + \cdots\right) - L\left(mr - \frac{1}{2}m(m+1)r^2 + \cdots \right) = 0
$$
By grouping terms in the same power of $r$:
$$
r(n-Lm) - \frac{1}{2}r^2\Big(n(n+1) -Lm(m+1)\Big) + \frac{1}{6}r^3\Big( n(n+1)(n+2) - Lm(m+1)(m+2)\Big) - \cdots = 0
$$
As $r>0$, dividing through by $r$ yields
$$
(n-Lm) - \frac{1}{2}r\Big(n(n+1) -Lm(m+1)\Big) 
+ \frac{1}{6}r^2\Big( n(n+1)(n+2) - Lm(m+1)(m+2)\Big) -\cdots = 0
$$ I thought as an approximate answer I could ignore powers higher than $r^2$ and simply consider the above as a quadratic in $r$.  However, this doesn't yield a real value fot $r$ as the discriminant is less than $0$. My questions are: Have I made a mistake in the above, or is the method a dead-end? Is there an alternative mathematical technique that yields better results? Obviously $r$ can be obtained by trial and error when dealing with a few cases.  However, this approach is not practical when dealing with millions of cases.  Is there perhaps an algorithmic method to obtain $r$, and if so what?",['discrete-mathematics']
2019876,Positivity of a convolution integral,"Let $f\in\mathcal{S}(\mathbb{R}^3)$ a real function. Consider the following integral
$$I_f:=\int_{\mathbb{R}^3}\int_{\mathbb{R}^3}\frac{f(x)f(y)}{|x-y|^2}dydx$$
Observe that,  either if $f$ is positive or negative, the integral becomes positive. Is it true that $I_f\geq 0$ for a generic $f$?","['real-analysis', 'integration', 'convolution']"
2019905,Gain or Loss in simple way?,"A person sells an article at a profit of 10% If he had bought it at 10% less and sold it for 3 dollars more ,he would have gained 25%.Find the Cost price. My solution is 120 I derived to the solution by fraction method 
let $x$ be the cost price 
Actual selling price is $(110/100) x$
Supposed cost price $x(90/100)$.
Supposed selling price is $x(90/100) (125/100)$. so 
$$
x(110/100)+3=x(90/100)(125/100)
$$ so $$
x=120
$$",['algebra-precalculus']
2019912,wire intersection puzzle,"Given a rural area is only accessible via railroad. As part of a class on economic development, you've come up with a plan for electrifying these remote settlements. Your plan basically describes n wires connecting some stations along the railroad. ith wire goes between stations l[i] and r[i] . As we all know, wires can't cross because this leads to a short circuit, but they can have the same endpoints. Also, the wires cannot cross the railroad - so in other words, a wire should go either to the left or the right of the railroad. Is it possible to place the wires in such a way that they don't intersect? Example For l = [1, 2, 3] and r = [4, 6, 5], it is possible to arrange the wires such that they do not intesect , so the answer is True For l = [1, 2, 3] and r = [4, 5, 6], it is not possible to arrange, so the answer is False For l=[1,3,2,4] and r=[4,5,5,6] the answer is True What I need is a way to solve the puzzle and how to do it. It seems almost similar to the travelling sales man problem, but I can be wrong too. So how to solve it? How to understand if the arrangements are possible or not?","['puzzle', 'combinatorics', 'graph-theory', 'recreational-mathematics']"
2019924,Sum of any subset of 20 integers should be a perfect square,I am unsure about the exact details of the question. But it asks us to find a set of $20$ non-zero integers such that the sum of all the elements in any of its subsets should yield a perfect square. I don't think this is possible and am unable to make headway. If any modified form of this question is solvable please mention that. If it's not possible to construct such a set we should prove why it's not possible to find such a set.,"['puzzle', 'perfect-powers', 'elementary-set-theory']"
2019967,Finding $\int_{0}^{1}\int_{0}^{1}\int_{0}^{1} \left\{\frac{x}{y}\right\} \left\{\frac{y}{z}\right\}\left\{\frac{z}{x}\right\} dx\space dy\space dz $,"$$\begin{equation}
    \int_{0}^{1}\int_{0}^{1}\int_{0}^{1} \left\{\frac{x}{y}\right\} \left\{\frac{y}{z}\right\}\left\{\frac{z}{x}\right\} dx\space dy\space dz \end{equation}$$ I am struggling with the above, I can deal with the case of double integrals but here due to my poor knowledge of triple integrals I am unable to decide what the limits should be in the transformed integral when I apply the substitution $\displaystyle \frac{x}{y}=u\space,\frac{y}{z}=v $ . The integral turns to $\displaystyle \iiint \left\{u\right\}\left\{v\right\}\left\{\dfrac{1}{uv}\right\}z^2v\space du\space dv\space dz$ , but I have no idea about the limits. Or even I am doing some mistake in these  steps only. {.} Denotes Fractional Part","['integration', 'definite-integrals', 'calculus']"
2019987,"Show that $f(x)=x\sin(2x)$ is uniformly continuous on $(0,1)$","I don't know how easy this is to prove simply by definition of uniform continuity: Let $I\subset R$ be a real interval. A real function $f:I\to R$ is said to be uniformly continuous on $I$ if: $$\text{for every }\epsilon > 0\text{ there exists }\delta>0\text{ such that the following property holds:}$$ $$\forall x,y∈I \text{ s.t. }  |x−y|<\delta\text{ it happens that }|f(x)−f(y)|<\epsilon$$ I know it's possible to show for most functions algebraically by finding an appropriate δ, but simply can't find it. I can't even do so for regular continuity. I'm really struggling with how difficult the algebra is for this function. I've seen other similar questions asked, and people suggested using the Heine-Cantor theorem, and some other theorems related to Metric Spaces. But I'm not working with metric spaces here (I think). This is a question for a Real Analysis module. We are learning Metric Spaces separately at the same time in a different module. Are there versions of these theorems (which would make this proof very easy) for working with functions like this without the domain and range being metric spaces?","['uniform-continuity', 'real-analysis', 'functions']"
2019991,Solve the equation $\sqrt{3x^2-7x-30}-\sqrt{2x^2-7x-5}=x-5$,"Problem Statement:- Solve the equation $\sqrt{3x^2-7x-30}-\sqrt{2x^2-7x-5}=x-5$ Attempt at solution:- Let $\alpha=\sqrt{3x^2-7x-30}\;\;\; \text{&} \;\;\;\beta=\sqrt{2x^2-7x-5}$. Then, we have $$\alpha-\beta=x-5\tag{1}$$ And, we have $$\alpha^2-\beta^2=x^2-25\tag{2}$$ From $(1)$ and $(2)$, we have 
$$\alpha+\beta=\dfrac{(x-5)(x+5)}{x-5}=x+5\qquad(\therefore x\neq5)\tag{3}$$ From $(1)$ and $(3)$, we get
$$\alpha=\sqrt{3x^2-7x-30}=x\qquad\qquad\beta=\sqrt{2x^2-7x-5}=5$$ On solving any one of $\alpha=x$ or $\beta=5$, we get $x=6,-\dfrac{5}{2}$. On putting $x=-\dfrac{5}{2}$, $\alpha=x$ is not satisfied. Hence, $x=6$ is the only solution. But as in $(3)$, we have ruled out $x=5$, as a solution then we can't put $x=5$ in the original equation. But, if we do put $x=5$ in the original equation we see that it is indeed satisfied. So, I tried a solution which also gives $x=5$ as a solution. So I picked the last solution from the $(2)$ without cancelling $(x-5)$. $$(x-5)(\alpha+\beta)=x^2-25\implies (x-5)(\alpha+\beta-(x+5))=0$$. Now, I am pretty much stuck here. Edit-1:- I just saw now and feel pretty stupid about it. If we proceed from the last step i.e. $(x-5)(\alpha+\beta-(x+5))=0$, we get 
$$(x-5)(\alpha+\beta-(x+5))=0\implies (x-5)=0\;\;\;\text{ or }\;\;\;\alpha+\beta=x+5$$ So we have the following equations to be solved:- $$\alpha-\beta=x-5\\
\alpha+\beta=x+5\\
x-5=0$$ Which results in $x=5,6$. Now, since I have put so much effort in posting this question, I might as well ask for better solutions if you can come up with one. And, please don't post a solution which includes a lot of squaring to result into a quartic equation.","['algebra-precalculus', 'quadratics']"
2020069,"If R is a total order and b is a minimal element of B, then b is the smallest element of B.","Suppose $R$ is a partial order on a set $A$, and $B\subseteq A$. Prove that, if $R$ is a total order and $b$ is a minimal element of $B$, then $b$ is the smallest element of $B$. I attempted an indirect proof of the above but I am not sure if it's correct, as the provided solution is A LOT longer and more complicated... My attempt: The goal is $\forall x\in B(bRx)$, so let's do an indirect proof and assume $\sim bRx$. Since this is a total order, for all $x$ and $y$ in $A$, either $xRy$ or $yRx$. But we have $\sim bRx$, so we get $xRb$. And since $b$ is a minimal element, that means that nothing in $B$ is such that it is both $xRb$ and is not identical to $b$. But this just means $\forall x\in B(xRb \to x=b)$. So $x$ is identical to $b$. But if that's the case, the assumption $\sim bRx$ is the same as $\sim xRb$. This contradicts with two things: 1) All relations in a total order are reflexive, but if $x=b$, surely this also means $\sim bRb$. 2) We derived $xRb$ and this contradicts with $\sim xRb$. Hence $\sim bRx$ cannot be true and $bRx$ must be true. ---------------------------- So this is my proof; but the provided solution seems a lot more complicated and it proceeded by proving case by case (namely assuming $x=b$ and $\sim x=b$). So I am not sure if my proof is right. Could anyone please check my proof and see if it's ok please? Thank you!","['relations', 'elementary-set-theory', 'proof-verification']"
2020139,Solve the equation $x^2+\frac{9x^2}{(x+3)^2}=27$,"Problem Statement:- Solve the equation $$x^2+\dfrac{9x^2}{(x+3)^2}=27$$ I have tried to turn it into a quadratic equation so as to be saved from solving a quartic equation, but have not been able to come up with anything of much value. These are the things that I have tried to turn the given equation into a quadratic equation. $$x^2+\dfrac{9x^2}{(x+3)^2}=27\implies 1+\dfrac{1}{\left(\dfrac{x}{3}+1\right)^2}=3\left(\dfrac{3}{x}\right)^2$$ $$\text{OR}$$ $$x^2+\dfrac{9x^2}{(x+3)^2}=27\implies 1+\dfrac{\left(\dfrac{3}{x}\right)^2}{\left(1+\dfrac{3}{x}\right)^2}=3\left(\dfrac{3}{x}\right)^2$$","['algebra-precalculus', 'quadratics']"
2020143,How to choose contour for computing this particular real integral?,"I am trying to solve a exercise from my Complex Analysis book. The exercise says: Show that $\displaystyle\int_0^\infty \frac {\cos(x)}{x^a} \, dx=\Gamma(1-a) \sin \left(\frac{\pi a} 2 \right)$ where $0<a<1.$ I am having trouble in choosing proper contour for this integral. Could someone please explain me how should i choose contour for computing the same integral?","['complex-analysis', 'improper-integrals', 'integration']"
2020147,"How to prove that $\lim\limits_{n\to\infty} \int_0^1 \cos^n(x)\, dx = 0$","I've got this tasks to prove that:
$\lim\limits_{n\to\infty} \int_0^1 \cos^n(x) \,dx = 0$ I tried to think about a partition ${0,t,1}$, and say that if $t$ is small enough, I can get:
$\lim\limits_{n\to\infty} \int_0^t \cos(x)\, dx = 0$
But then I'm stuck with the rest section $[t,1]$ which approaches $1$. Any clue?","['definite-integrals', 'trigonometric-integrals', 'calculus', 'limits']"
2020153,Limit of the sequence $a_n=\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}$,"Find the limit of the sequence $a_n=\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}.$ The limit is supposed to be $e^{-1}$ and there are a couple of posts in MSE proving it. But here is a proof I encountered showing the limit is $1.$ Please tell me what's going wrong here. Proof:  We can write $a_n=\sqrt[n]{n!}(b_n-1),$ where $b_n=\frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}}.$ Hence $$a_n=n\cdot\frac{\sqrt[n]{n!}}{n}\cdot\frac{b_n-1}{\ln{b_n}}=\frac{\sqrt[n]{n!}}{n}\cdot\frac{b_n-1}{\ln{b_n}}\cdot\ln{b_n^n.}$$ But $\lim \limits_{n\to \infty}\frac{\sqrt[n]{n!}}{n}=e^{-1},$ so $b_n\to1$ as $n\to \infty.$ On the other hand, $$\lim \limits_{n\to \infty}b_n^n=\lim \limits_{n\to \infty}\frac{(n+1)!}{n!}.\frac{1}{\sqrt[n+1]{(n+1)!}}=e.$$ Also $$\lim \limits_{n\to \infty}\frac{b_n-1}{\ln{b_n}}=\lim \limits_{n\to \infty}\frac{1}{\ln{[1+(b_n-1)]^{1/(b_n-1)}}}=\frac{1}{\ln e}=1$$ And the author goes on to say that the limit is $e^{-1}.$ But doesn't it say that the limit is $1?$ I must have overlooked something so obvious.","['radicals', 'factorial', 'sequences-and-series', 'limits']"
2020156,Solve $13^x-3^y=10$ in positive integers,"As it is ""well-known"" fact $13-3=10$. Is this true for some other powers of $13$ and $3$, i.e. find all natural numbers $x$ and $y$, such that $13^x-3^y=10$ (there are other, find them all).","['number-theory', 'diophantine-equations', 'modular-arithmetic']"
2020177,Roots of combination of trigonometric functions,"Consider the following function of $\mathbb{R^+}^2$: $$f(s_1,s_2)=r_1^2\sin\big(\tfrac{1}{2}(s_2-s_1)\omega_1\big)\sin\big(\tfrac{1}{2}(s_2+s_1)\omega_2\big)
+
r_2^2\sin\big(\tfrac{1}{2}(s_2+s_1)\omega_1\big)\sin\big(\tfrac{1}{2}(s_2-s_1)\omega_2\big)$$ where $r_1^2+r_2^2=1$. My goal is to find the solution curves of $f$ on $\mathbb{R^+}^2$. There is certainly no closed-form solution, so I'm doing it numerically, for some given values of $(r_1,r_2,\omega_1,\omega_2)$. Symmetries Obviously, $f(s_1,s_2)=-f(s_2,s_1)$ so the solution curves of $f$ are symmetric w.r.t. to $s_2=s_1$: it suffices to focus on $s_1\geq s_2$. Note that also $f(-s_1,s_2)=-f(-s_2,s_1)$ so $s_2=-s_1$ is another axis of symmetry for the solutions of the extension of $f$ to $\mathbb{R}^2$, but it is a priori not intersting on $\mathbb{R^+}^2$. $f$ is a scalar function of two variables so its solution curves are (generically) curves. That's what we can observe to some numeric values of $(r_1,r_2,\omega_1,\omega_2)$: (Note the axial symmetry mentionned above.) Calculating some points on the solution curves For some reason (reduction of computational cost in more complex cases), I'd like to get points on the solution curves of $f$ and then do numerical continuation to compute each curve. By curve , I mean a connex curve, and the solution curves is a family of such connex curves. The idea is that when $\tfrac{1}{2}(s_2+s_1)\omega_i$ approaches $\pi\mathbb{N}$, only one term is the sum remains. For example, when $s_2+s_1=2\pi/\omega_1$, $$f(s_1,2\pi/\omega_1-s_1)=r_1^2 \sin(\pi\tfrac{\omega_2}{\omega_1})\sin(s_1\omega_1)$$ and so the roots of $s_1\mapsto f(s_1,2\pi/\omega_1-s_1)$ are the $\pi/\omega_1\mathbb{N}$. In the, we know that the set of points $$\mathcal{S}=\Big\{ \frac{\pi}{\omega_i}(p,2p-q),\ p,q\in\mathbb{N}, i\in\{1,2\}\Big\} \cap {\mathbb{R}^+}^2$$ is a subset of the solution curves of $f$, as illustrated below: or, for another set of parameters $(r_1,r_2,\omega_1,\omega_2)$: Red and green points correspond to $i=1$ and $i=2$. Question On both figures, all the curves pass through the set of points $\mathcal{S}$. Is this always true, or can there be some curves which do not pass through any green or red points? I am also interested in references or keywords for mathematical tools which could be useful for the study of solution curves of functions of the ""type"" of $f$ (i.e. sum of products of sines), even though I don't think there are miraculous simplification.","['real-analysis', 'trigonometry', 'roots', 'algebraic-geometry']"
2020183,Limit of $\lim_{x\to 0} \frac{\log(1+\sqrt[3]{x})(\sin x -. x)}{(\cos x-1)^3 x^2}$ without hopital,"I am struggling to make this limit:
$$\lim_{x\to 0} \frac{\log(1+\sqrt[3]{x})(\sin x - x)}{(\cos x-1)^3x^2}$$
I know it doesn't exist, and I am really near to prove it but something is blocking me. Skipping some step, I have that $$\frac{\sqrt[3]x(\sin x-x)}{-\frac{1}{2}x^8}$$
From this, I see that $x^8$ could be $x^7$, by making the top term (1-1), and from this I see that this goes to +-infinity, so it doesn't exist. But this isn't a formal method, nor probably a method at all. Would love to see your methods to solve this without hopital!","['limits-without-lhopital', 'limits']"
2020212,Dynamic voting quorum,"Problem: Suppose that a committee with $n$ members needs to vote on whether to accept a proposition. Each member in the committee can cast a yes/no vote ($q_i\in\{1,0\}$ for $i\in \{1,2,...,n \}$), and each member's vote has a  different weight ($w_i\in[0,1]$ for $i\in \{1,2,...,n \}$). The committee rules stipulate that the proposition is to be accepted if the weighted average of votes is more than 50%, namely, if $$\bar{q}(n)=\sum_{i=1}^{n} w_i q_i>0.5$$ Suppose that (i) voting is sequential, (ii) each vote is a random draw from a Bernoulli distribution with unknown mean $p$, and (iii) the order of voting is independent of voting weights. I would like to define a 'dynamic quorum rule', such that a decision (accept vs reject) is made with only a subset of the committee's votes (e.g. the first $k$ votes),  and yet be statistically confident that the decision made is the same as the one that would have been made if all members had voted. What I currently have: This problem is very similar to one that I posted earlier . The only difference is that I am now interested in a weighted solution. That means that for $w_i=w$, the bayesian solution proposed in the related question also applies here.","['stochastic-processes', 'bayesian', 'statistics', 'probability']"
2020216,"Estimator of $\theta$, uniform distribution $(\theta, \theta +1)$","I would like to ask you, if somebody helps me to solve one statistics problem. I have $X_1, ..., X_n$  a sample of independent random variables with uniform distribution $(\theta, \theta +1)$ I have an estimator $\hat{\theta}_n=\max$ $X_i -1$ for $1 \le i \le n$, and I should find if it is unbiased and consistent, I found, that it is consistent but I think that it is biased. I find density of my estimator:
$f_Y(y)=n(y+1-\theta)^{(n-1)}$, where $y=\max$ $X_i$, but I am not sure, if it is correct, because if I calculate $E(\hat{\theta}_n)$, the result was quite strange. The last step, which I should do, is following: how should I change $\hat{\theta}_n$ to make it unbiased. I think that I have to substract 1, but then I am not sure. Please, can somebody check if I calculate the density correctly and how I can find an unbiased estimator (I cannot use MLE)? Thank you","['statistics', 'estimation', 'probability', 'uniform-distribution', 'parameter-estimation']"
2020220,Solutions to $\frac1{\lfloor x\rfloor}+\frac1{\lfloor 2x\rfloor}=\{x\}+\frac13$,"Find all solutions to $$\dfrac{1}{\lfloor x\rfloor}+\dfrac{1}{\lfloor 2x\rfloor}=\{x\}+\dfrac{1}{3}$$ $$$$
Unfortunately I have no idea as to how to go about this. On rearranging, I got $$3\lfloor 2x\rfloor = 3\lfloor x\rfloor\{x\}-2\lfloor x\rfloor$$
I'm not sure about what to do with the $3\lfloor 2x\rfloor $ term; I'd prefer to resolve it in terms of $\lfloor x\rfloor $ but am not able to. All that struck me was using the identity for $\lfloor nx\rfloor, n\in \Bbb Z$. However on first glance, it did not strike me as particularly useful.$$$$
I would be grateful for any help. Many thanks!","['number-theory', 'ceiling-and-floor-functions', 'calculus', 'functions']"
2020235,"How to prove: If $\left\{a,b\right\}=\left\{c,d\right\}$ then $(a=c\;\;and\;\;b=d)\;\;or\;\;(a=d\;\;and\;\;b=c)$","I am trying to prove this: If $\left\{a,b\right\}=\left\{c,d\right\}$ then $(a=c\;\;and\;\;b=d)\;\;or\;\;(a=d\;\;and\;\;b=c)$ My attempt so far was that if $\left\{a,b\right\}=\left\{c,d\right\}$ then by the definition of equality I get that $a,b\in\left\{c,d\right\}\;\; and\;\; c,d\in\left\{a,b\right\}$. Then I get: $\Big((a=c \;\;or\;\;a=d)\;\;and\;\;(b=c\;\;or\;\;b=d)\Big)\;\;and\;\;\Big((c=a \;\;or\;\;c=b)\;\;and\;\;(d=a\;\;or\;\;d=b)\Big)$ ...? Thanks for any help.","['logic', 'elementary-set-theory']"
2020241,Smallest graph that cannot be represented by the intersection graph of axis-aligned rectangles,"Is it known that any outerplanar graph can be represented as the geometric intersection graph of axis-aligned rectangles, while any planar graph can be represented as the intersection graph of axis-aligned boxes in 3d. This is also known as the boxicity of a graph. What is a small example of a graph that has boxicity greater than 2 (i.e cannot be represented by the intersection of axis-aligned rectangles)? I am doing a presentation, and I would like an example to show (to an audience who may not be completely familiar with the area) that these two things are ""clearly"" different (which is why I need a small graph). Edit: I don't really need the smallest such graph. I would like one where others can easily convince themselves that it cannot be represented by intersecting rectangles. Roberts introduced the notion of boxicity in 1969 ( ""On the boxicity and cubicity of a graph"", in Tutte, W. T., Recent Progress in Combinatorics, Academic Press, pp. 301–310) and showed that ""every graph on $n$ vertices has an $⌊n/2⌋$-box and a $⌊2n/3⌋$-cube representation.""  Thus a minimal example of a graph without representation as the intersection graph of axis-aligned rectangles in the plane (dimension $2$) must have (at least) six vertices. Roberts gave a family of ""tight"" examples, often called cocktail party graphs , having $2n$ vertices whose boxicity is exactly $n$.  For $n=3$ the graph is that of a triangular antiprism, and so (as a polyhedron) is planar:","['combinatorics', 'graph-theory', 'examples-counterexamples']"
2020250,Evaluate a given limit,"Evaluate the following limit:
$$\lim_{x \rightarrow 4} \left( \frac{1}{13 - 3x} \right) ^ {\tan \frac{\pi x}{8}}$$ I haven't managed to get anything meaningful yet. Thank you in advance!",['limits']
2020262,Question on a submanifold of $\mathbb{C}^2$ and tangent vectors,"Let $X\subset \mathbb{C}^2$ (with complex coordinates $z,w$) be defined by the equation $|z|^2=|w|^2$. If we see $\mathbb{C}^2$ as $\mathbb{R}^4$ with real coordinates $z=x+iy$, $w=u+iv$ then $X$ is a real submanifold of dimension 3 defined by $x^2+y^2-u^2-v^2=0$. Question 1: is $X$ also a complex submanifold? Question 2: is $(i,0)$ a tangent vector to $X$ in $(1,1)\in X$? I think the answer is no to both questions. In particular for the second one it should be true that $T_{(1,1)}X\simeq Ker(df_{(1,1)})$ with $f= x^2+y^2-u^2-v^2=0$ and $df_{(1,1)}=(2,2,-2,-2)$. But $(i,0)=(0,1,0,0)$ in real coordinates and $df_{(1,1)}(0,1,0,0)\neq 0$. Am I right?","['complex-geometry', 'differential-geometry']"
2020290,A generalization of the Euler Line,"Today, we had a lecture on Euler line and it's various generalizations/applications. One of the tasks we were given as homework is the following one: Let acute $\triangle ABC$ have altitude $\overline{AD}$. Let $P$ and $Q$ be midpoints of sides $\overline{AB}$ and $\overline{AC}$, respectively; and let $X$ and $Y$ be the projections of $D$ onto sides $\overline{AB}$ and $\overline{AC}$, respectively. Lines $\overleftrightarrow{PY}$ and $\overleftrightarrow{QX}$ intersect at point $Z$. Prove that circumcenter $O$ is collinear with $Z$ and $D$. Edit by @Blue. The original problem statement had a weaker condition on $P$ and $Q$, namely: ""Let $P$ and $Q$ be such points, that $|AP|=|PB|$ and $|AQ|=|QC|$."" However, the result with this condition is not true in general. I strengthened the condition to make $P$ and $Q$ midpoints, but the original source might have intended something else (otherwise, why not just call $P$ and $Q$ midpoints from the get-go?). This is supposedly only something like a generalization of Euler's line and should be possible to prove using methods similar to those used to prove that Euler's line always exists, yet I'm having difficulty in proving this theorem, as I fail to notice any helpful analogy. (I managed to find an analytic proof of this theorem, but it's over four pages long and we were not supposed to use such techniques.) Image by @Blue. (This assumes the midpoint condition.)",['geometry']
2020337,Series representation of $2e$,"According to GR9768 , problem 37: $$\sum_{k=1}^{+\infty} \frac{k^2}{k!} = 2e$$
Can someone please explain how to get started in showing that?","['sequences-and-series', 'gre-exam']"
2020341,Examples where $G \cong G \times H$ where $H$ is nontrivial?,"I am new to abstract algebra and ran into the problem yesterday. With my rudimentary knowledge of set theory I can deduce $G$ must be infinite, but I cannot move on any further. One example I can think of is the infinite direct product of some group $G$. I am wondering if there is any other easily understandable example?",['group-theory']
2020399,Division algebra = Field?,"Is a division algebra a field? If not, why does it differ? It is an abelian group with multiplication and division. How not a field?","['division-algebras', 'field-theory', 'linear-algebra']"
2020407,Calculate a limit of recursive sequence,"Prove that infinite recursive sequence 
has limit and calculate it. $x_{1}=0, x_{2}=1$ $x_{n+2}=\frac{1}{2}(x_{n}+x_{n+1})$ I've tried to separate it to even and odd partial series and it looks like one of them is increasing and another is decreasing. But I can't prove that they are increasing and decreasing, because I don't know how to express $x_{n}$ from a recurrence relation. What should I do for example with $x_{n+1}$ when I work with the even partial series? And that is why I can't calculate the limits too, because I need to express somehow $x_{n}$.","['recurrence-relations', 'sequences-and-series', 'limits']"
2020413,Determinant of Cayley table,"Let $G$ be a finite group of order $n$ and $kG$ the group ring over a field of characteristic $0$. Let $C$ denote the Cayley table. The determinant of $C$ in $kG$ is defined as $det(C)=\sum_{\sigma \in S_n}sgn(\sigma)\, C_{1,\sigma(1)}\cdot ... \cdot C_{n,\sigma(n)}$. Does this always vanish? Clearly, $C$ is equivalent to the 'skew-symmetric' matrix $\tilde{C}_{g,h}=gh^{-1}$, but still I have no good argument.. but maybe it's wrong, I checked it only until $n=4$..","['finite-groups', 'group-theory']"
2020473,Prove that $\lim_\limits{n\to\infty }\frac{1}{\log(\log(n))}=0$,How to prove this limit? $$\lim_{n\to\infty }\frac{1}{\log(\log(n))}=0$$ I thought of something like $$0 \le \frac{1}{\log(\log(n))} \le \frac{1}{n}$$ Is it alright?,"['real-analysis', 'analysis', 'limits']"
2020489,A Lagrange Mulipliers Problem,"My problem is this: Find the min and max values of $f(x,y)=x^2+3xy+y^2$ on the domain $(x-1)^2+y^2=1$. I used lagrange multipliers to find that the $y$ coordinate satisfies $f\left(x\right)=8y+(46y^2)/3-16y^3-24y^4=0$ for any critical point $(x,y)$, and $x=2y^2+(2/3)y$
Using Wolfram Alpha, I found that this has roots (aprox.), $y=-0.97110$ $y=-0.45311$ $y=0.75755$ $y=0$ Wolfram alpha tells me that the function is optimized at the first and third points. However, it is unable to get them in exact form that is not horrendous(multiple radicals involving i). But my professor is expecting an exact answer-and certainly not the exact answer I have. Am I missing something?","['multivariable-calculus', 'optimization']"
2020496,Product of commutators not equal to product of fewer than $k$ commutators?,"In a free group $F$ with basis $x_1, \ldots, x_{2k}$, how do I see that the product of commutators$$[x_1, x_2] \ldots [x_{2k - 1}, x_{2k}]$$is not equal to a product of fewer than $k$ commutators $[v_i, w_i]$ of elements $v_i$, $w_i \in F$? Progress. If it helps, I can show that if $\Sigma_g$ denotes the closed orientable surface of genus $g$, then degree $1$ maps$$\Sigma_g \to \Sigma_h$$ exist if and only if $g \ge h$. I know that the $2$-cell of $\Sigma_k$ is attached by the product$$[x_1, x_2] \ldots [x_{2k - 1}, x_{2k}].$$From a relation$$[x_1, x_2]\ldots[x_{2k - 1}, x_{2k}] = [v_1, w_1] \ldots [v_j, w_j]$$ in $F$, perhaps we could construct a degree $1$ map $\Sigma_j \to \Sigma_k$? But I am stuck from here on out. Could anybody help me finish?","['abstract-algebra', 'free-groups', 'algebraic-topology', 'geometric-topology', 'group-theory']"
2020569,$M_2(\mathcal{K}(\mathbb{H})) \cong \mathcal{K}(\mathbb{H} \oplus \mathbb{H} )$?,"Can anybody tell whether the C*-algebras $M_2(\mathcal{K}(\mathbb{H}))$ and $\mathcal{K}(\mathbb{H} \oplus \mathbb{H} )$ are isomorphic? If so, what is the isomorphism exactly? $\mathcal{K}(\mathbb{H})$ denotes the ideal of compact operators on an infinite-dimensional Hilbert space $\mathbb{H}$.","['functional-analysis', 'c-star-algebras', 'compact-operators', 'hilbert-spaces']"
2020574,Solving $x^p-x-1=0$ with Lagrange Inversion Formula,"I am working through the proof that one can solve quintic equations first by reducing the polynomial to one of the form $x^5-x-t$, and then solving $x^5-x-t=0$ using the Lagrange Inversion Formula on the function $x-x^5$. However, to do this it seems as if I need to be able to compute $n$th derivatives of 
$$
\left(\frac{x}{x-x^5}\right)^n,
$$
which I am unable to get a nice closed form for. Could anyone offer some insight into this? Thanks.","['complex-analysis', 'pattern-recognition', 'lagrange-inversion']"
2020583,Genus of projective curves,"I have the projective curve in $\mathbb{P}^2$ given by
\begin{align}
F(X,Y,Z)=Y^2 Z^2-X^4-Y^4.
\end{align}
I want to calculate the genus of the curve. My approach would be to calculate the partial derivatives and use the
multiplicities $r_i$ of the singular points in the formula
\begin{align}
g(F)=\frac{(n-1)(n-2)}{2}-\sum_i \frac{(r_i-1) r_i}{2}.
\end{align}
I get $DF(X,Y,Z)=(4X^3,2YZ^2-4Z^3,2Y^2Z)$, and I get the singular point polynomials $X^3, Z^2(Y-2Z),Y^2Z$. Is the next step to calculate $r_i$ by the intersection number between the curve $F$ and the singular point polynomials? Or do I need to dehomogenize $F$ to get the tangents to intersection between the tangents? Or do I need another approach for the $r_i$?","['plane-curves', 'projective-geometry', 'algebraic-geometry']"
2020601,Two questions about Dirichlet's theorem on arithmetic progressions,"Dirichlet's Theorem on arithmetic progressions states that there are infinitely many primes of the form $$an+b$$ Being $a$ and $b$ coprimes. Very elemental question: Can we say that this Theorem: $$an-b$$ is equivalent to Dirichlet's one? I supose it is, as it would be the same as $a(n-1)+(n-b)$, but I would like to get sure, as I am not used to work with this kind of formulae For which functions $f(n)$ can we say that there are infinitely many primes of the form $$a[f(n)]+b$$
? For example,  $a2^n+b$ or $a(5n)+b$ Thank you!","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2020643,Finding the derivative of $\cos 2 x - 2 \sin x$,"So, I've been teaching myself calculus, and I'm very new to all of this, so apologies in advance for what is probably a rather dumb question. I'm trying to find the derivative of the function $f(x) = \cos 2x - 2 \sin x$. I'm 99% sure that the derivative of $\cos$ is $-\sin$, and that the derivative of $\sin$ is $\cos$. So I got $-\sin 2 + \cos 1$. I just moved through from left to right - $2x$ becomes $2$ and $+-2$ becomes just plus the next thing because constants disappear, etc. However, the answer in my book is $-2 \cos x(1+2 \sin x)$. I have no clue how the book got this. Just in case I misunderstood the problem, it says, In Exercises 1 through 14, determine the derivative $f'(x)$. In each case it is understood that $x$ is restricted to those values for which the formula for $f(x)$ is meaningful. And then for each problem it gives a function like this particular one. Any help would be appreciated. Thanks!","['derivatives', 'trigonometry', 'calculus', 'functions']"
2020658,Show that $\left(X_{(1)} + X_{(n)}\right)/2$ is a consistent estimator for $\theta$,"Let $X_1, \ldots , X_n$ be a random sample from the uniform distribution on the interval
$(\theta − 1/2, \theta + 1/2)$, where $\theta$ is unknown. Let $X_{(1)} = \min(X_1, \ldots , X_n)$ $X_{(n)} = \max(X_1, \ldots , X_n).$ Show that $\left(X_{(1)} + X_{(n)}\right)/2$ is a consistent estimator for $\theta$. Not really sure where to start with this. I tried finding the MLE and saying that is was a consistent estimator but found that the fisher information is 0. I also tried using the MME but that got me no where.","['uniform-distribution', 'statistics', 'probability', 'parameter-estimation']"
2020677,$e^Ae^B$ when $A$ and $B$ anticommute,"I know that if $A,B$ ($n\times n$ real matrices) commute, then $e^{A}e^B = e^{A+B}$.  Is there a similar identity when $A,B$ anti commute?","['matrices', 'linear-algebra', 'exponentiation']"
2020732,Find the limiting distribution of $Z_n=n[1-F(Y_n)]$,Let $Y_n$ denote the maximum (the last order statistic) of a random sample of size $n$ from a distribution of the continuous type that has c.d.f $F(x)$ and pdf $f(x) = F'(x)$. Find the limiting distribution of $Z_n=n[1-F(Y_n)]$ I dont have the solution to this but the answer my teacher gave us is that the limiting distribution of $Z_n$ should be exponential with mean $1$. If you define $Z_n=n[1-Y_n]$ then that limiting distribution is exponential with mean $1$ but I dont know how to work with $F(Y_n)$,"['statistics', 'order-statistics', 'probability-distributions']"
2020740,Equivalence relation on a continuum,"Let $X$ be a continuum $=$ a connected compact metric space. Define $x\sim y$ if $x$ and $y$ are contained in a nowhere dense subcontinuum of $X$. It is easy to see that $\sim$ is an equivalence relation. Examples: $|[0,1]/\sim|=|\mathbb R|$ $|[0,1]^2/\sim|=1$ Question: Is there a continuum $X$ with $1<|X/\sim|<|\mathbb R|$?","['continuum-theory', 'equivalence-relations', 'compactness', 'general-topology', 'metric-spaces']"
2020744,Minimal perimeter,"The problem is: Find the angle to OX axis, at
which a line should be drawn through the point A
(a,b) (a>0, b>0), so, that triangle, formed by this
line and positive coordinate semi-axes had the
minimal perimeter. I.e. the triangle vertices are (0,0), and two intersection points of line passing through A with OX and OY axes: (x,0), x>0 and (0,y),y>0. I found the function appearance: the function to minimize is 
$$
f(\varphi)=\left({a\over\cos \varphi}+{b\over\sin \varphi}\right)(1+\cos \varphi+\sin \varphi)
$$
and found its derivative,but I failed to solve equation derivative=0: there is 4th degree equation with respect to $\sin\varphi$, $\cos\varphi$ which I failed to solve. The answer is known, it was in the same book, but I can't come to that answer. Could somebody, please, help me?","['derivatives', 'trigonometry', 'calculus']"
2020755,What is the geometric interpretation of the Connection?,"I am currently enrolled in a General Relativity course, and was taught about the connection but I can't really wrap my head around it qualitatively. All I can think of is that it must have something to do with the coordinate system that one uses to describe a space(or space-time) but I can't give it a geometric interpretation**(Check the 2nd EDIT)**. Thank you. EDIT 1: I am searching for an explanation in terms of the curvature of the space and the coordinates. EDIT 2: Upon searching for an answer, I found that the relation of the connection with the covariant derivative offers some insight: The connection term in the covariant derivative is an extra term to the normal derivative that is there in order to account for the changes in the coordinate basis vectors. If anybody could use this type of logic to give a complete geometric interpretation of the connection, it would be great!","['coordinate-systems', 'general-relativity', 'differential-geometry', 'curvature']"
2020795,Show that $\sup_{0<x<\infty} (\mathrm{cos}x+\mathrm{sin}\sqrt{2}x)=2$.,"This is a problem in V Arnold's Ordinary Differential Equations. By plotting the function $f(x)=\mathrm{cos}x+\mathrm{sin}\sqrt{2}x$ (the first graph below), I see that the graph is bounded from -2 to 2. But the boundary points $\{2,-2\}$ are not attained by $f(x)$. Intuitively, it seems true that $f(x)$ approaches 2 when both $\mathrm{cos}x$ and $\mathrm{sin}\sqrt{2}x$ approach 1. From the graph of both $\mathrm{cos}x$ and $\mathrm{sin}\sqrt{2}x$ (the second graph below), one can see that around $x=19$, both $\mathrm{cos}x$ and $\mathrm{sin}\sqrt{2}x$ approach 1. But this doesn't seem like much of a proof. Is there another approach to show this equality? Also, I fail to find an ODE-related approach to this problem.","['trigonometry', 'ordinary-differential-equations', 'dynamical-systems', 'supremum-and-infimum']"
2020800,"Structures in the plot of the ""squareness"" of numbers","Please explain the features of this plot of the squareness ratio $r(n)$ versus $n$. I define the squareness of a natural number $n$ to be the closest
its factors can be partitioned into a balanced ratio of $1$.
A perfect square has squareness $1$. A prime $p$ has squareness $1/p$.
In a sense, the squareness measures how close is $n$ to a perfect square. Example . The squareness ratios for the first ten number $n=1,2,\ldots,10$ are
$$1,\frac{1}{2},\frac{1}{3}
   ,1,\frac{1}{5},\frac{2}{3},\frac{1}{7},\frac{1}{2},1,\frac
   {2}{5}$$ Example . $n=1032 = 2 \cdot 2 \cdot 2 \cdot 3 \cdot 43$.
One can partition its $5$ factors into two parts which have
products whose ratios are
$$
\left\{\frac{1}{1032},\frac{1}{2
   58},\frac{3}{344},\frac{2}{12
   9},\frac{3}{86},\frac{8}{129}
   ,\frac{6}{43},\frac{24}{43}\right\}
$$
with $\frac{24}{43} \approx 0.558$ the largest ratio, its squareness. Example . For $n=12600=2 \cdot 2 \cdot 2 \cdot 3 \cdot 3 \cdot 5 \cdot 5 \cdot 7$,
the largest ratio is 
$$\frac{3 \cdot 5 \cdot 7}{2^3 \cdot 3 \cdot 5}=\frac{7}{8}=0.875 \;.$$ Among this plot's evident features are: straight rays from the origin, hyperbolas,
discernable density change at $r=\frac{1}{2}$, interesting patterns near $r=1$.
There is more structure here than I anticipated. (Some detail is lost converting the image for posting.) Added . Riffing on PattuX's idea, for a prime, $n=p$,
all the numbers $k n$ for $k=1,2,\ldots,p$
have squareness ratios $k/p$. For example, for $n=17$,
$$n = 17,34,51,68,85,102,119,136,153
   ,170,187,204,221,238,255,272,
   289$$
have squareness
$$\frac{1}{17},\frac{2}{17}
   ,\frac{3}{17},\frac{4}{17},\frac{5}{17},\frac{6}{17},
   \frac{7}{17},\frac{8}{17},\frac{9}
   {17},\frac{10}{17},\frac{11}{
   17},\frac{12}{17},\frac{13}{1
   7},\frac{14}{17},\frac{15}{17
   },\frac{16}{17},1
$$
and so all lie on a line through the origin.","['number-theory', 'square-numbers', 'prime-factorization']"
2020803,Inner products equal implies the arguments are equal,"Today I was looking at theorems involving inner products which use the 'fact' that if $\langle x,y \rangle = \langle x,z \rangle$ for all $x$ then $y=z$. Is the following a sufficient proof of that? Consider an inner product space $(M,\langle\cdot,\cdot\rangle)$ and $x,y,z\in M$. Assume that $\forall x\in M, \langle x,y\rangle = \langle x,z\rangle$. Then, using the linearity of the inner product, $\forall x\in M, \langle x,y-z\rangle =0$, meaning that $y-z$ is orthogonal to every vector in $M$. Thus, since $0$ is the only vector which is orthogonal to all vectors, $y-z$ is $0\implies y=z$. Or alternatively, since $\forall x\in M, \langle x,y-z\rangle=0$, we can pick $x=y-z$ to get $\langle y-z,y-z\rangle = 0 =||y-z||^2\implies y-z=0\implies y=z$.","['functional-analysis', 'inner-products']"
2020816,"Show that if $f$ is lower continuous then $f^{-1}((\alpha,\infty))$ is open","Let a function $f:X\to\Bbb R$, where $X$ is a metric space. Then $f$ is lower continuous if for all $a\in X$ we have that $f(a)\le \liminf f(x_n)$ for every $(x_n)\to a$. Alternatively we can say that $f$ is lower continuous if for all $\epsilon >0$ exists some $\delta>0$ such that $$x\in\Bbb B(a,\delta)\implies f(a)-f(x)<\epsilon$$ Now I must prove that for any $\alpha\in\Bbb R$ the preimage of $(\alpha,\infty)$ is open. What I tried is set $f(a)=\alpha$, but from this approach I cant conclude that the preimage of $(\alpha,\infty)$ is open. At most I can conclude that for any $\epsilon>0$ exists a ball $\Bbb B(a,\delta)$ where some of it images belong to some set of the kind $(\alpha,\beta)$. Some hint or solution will be appreciated, thank you.","['continuity', 'general-topology', 'analysis']"
2020856,Expressing multivariate functions as tensor product of univariate functions,"I am coming across many instances where multivariate functions are being represented by tensor products of univariate functions.  The basic idea seems to be as follows: Let $\phi_j$ be a univariate function in the variable $x_j$.  Then the rank one tensor $\phi_1\otimes \phi_2 \otimes \dots \otimes \phi_d$ is the multivariate function $\Phi$ defined by $$\Phi(x_1, ..., x_d) = \phi_1(x_1) \cdots \phi_d(x_d) $$ Everywhere I'm seeing this it is stated without justification, and I am wondering how one justifies it.  My attempt at justification requires fixing some bases (assuming that one can) for the $\phi_j$, i.e. suppose $\phi_j \in$ span$\{e_{\ell}\}_{\ell=1}^{p_j}$ with $\phi_j = \sum_{\ell=1}^{p_j} \alpha_{j \ell} e_{\ell}$ for some coefficients $\alpha_{j\ell}$, then by expanding $\phi_1\otimes \phi_2 \otimes \dots \otimes \phi_d$  into the basis, and applying multi-linearity, one would arrive at a sum of the sort $$\sum \alpha_{1 k_1} \cdots \alpha_{d k_d}e_{k_1} \otimes \cdots \otimes e_{k_d} $$ Is this the right idea? Perhaps there is a construction via the universal property, but I only understand this in the case of vector spaces of linear maps.  This is not a homework question, I am just interested in tensors.  Thanks!","['tensor-products', 'tensors', 'functional-analysis', 'approximation-theory', 'approximation']"
2020858,$E'=\overline E'$? (the limit points of a set = the limit points of its closure?),"Let $E'$ be the set of limit points of $E$, and $\overline E \triangleq E'\cup E$ be its closure, in some metric space.  Is it true that $E'=\overline E'$?  That $\overline E' \subset E'$ is shown in Limit Points of closure of A is subset of limit points of A .  And I think the converse ($E' \subset \overline E'$) is clearly also true.  So it appears that we should have $E'=\overline E'$.  Did I mess up somewhere?","['general-topology', 'metric-spaces']"
2020869,Inverse of almost diagonal matrixes,"Consider an $n\times n$ matrix $A$, and it's perturbation matrix $dA$. Let for simplicity $A=I$ be a matrix with ones on the diagonal and zeros off-diagonal. Let $dA$ have zeros on the diagonal and off-diagonal elements in the range $(0,\frac{1}{n})$. Question : Can I argue that the inverse matrix has the off-diagonal elements less than  $\frac{1}{n}$ as well? 
Normalize them by the diagonal ones that get perturbed up a little bit. I ran a bunch of simulations on my computer and it seems like this is indeed true. For n=30, the off-diagonal elements hardly reach 30% of my target bound. For n=100, it hardly exceeds 25% of it. The best theory I could find tells the following. Pick a 1- or $\infty$ norm of the matrix, then $$\frac{||(A+dA)^{-1}-A^{-1}||}{||A^{-1}||} \leq K(A) \cdot  \frac{||dA||}{||A||}, \quad K(A)=||A||\cdot ||A^{-1}||$$ What this means is that if the original matrix $A+dA$ was diagonally dominant, then the inverse $(A+dA)^{-1}$ is diagonally dominant as well, because the conditioning number $K(A)$ is equal to 1. The inequality holds for any sub-multiplicative norm and the problem is that the max-norm is not sub-multiplicative, or I would have got my result immediately. I would really appreciate if somebody knows a way to show this or at least some clue. Thanks!","['matrices', 'linear-algebra', 'perturbation-theory']"
2020872,Problem on fractions,"John's front lawn is $\dfrac13$ the size of his back lawn. If John mows $\dfrac12$ of his front lawn and $\dfrac23$ of his back lawn, what fraction of his lawn is left unmoved? How to solve it without picking numbers? The way to solve with number picking: (size back lawn) = $6$ units (size front lawn) = ( $\dfrac13$ )(size back lawn) = $2$ units (size total lawn) = (size back lawn) + (size front lawn) = $8$ units Now we can use these numbers to calculate how much of each lawn has been mowed: Front lawn: $(\frac 12)(2) = 1$ unit Back lawn: $(\frac 23)(6) = 4$ units So, in total, $5$ units of lawn have been mowed.  This represents $\dfrac58$ of the total, meaning $\dfrac38$ of the lawn is left unmowed.",['algebra-precalculus']
2020882,Are all triangles isosceles?,"There is a rather involved (and it is claimed, well-known) proof that shows that all triangles are isosceles (it can be found in Euclidean and non-Euclidean geometries - Marvin Jay Greenberg, bottom of pg. 23) - but unfortunately after studying it, I cannot seem to find the flaw in the argument. Your help would be much appreciated. It claims: Given triangle ABC. Construct the bisector of angle A and the perpendicular bisector of side BC opposite to angle A. Now consider the various cases (there are diagrams given in the book). Case 1: The bisector of angle A and the perpendicular bisector of segment BC are either parallel or identical. In either case, the bisector of angle A is perpendicular to BC and hence, by definition, is an altitude. Therefore the triangle is isosceles (The conclusion follows from the Euclidean theorem that states: if an angle bisector and altitude from the same vertex of a triangle coincide, the triangle is isosceles.) Suppose now that the bisector of angle A and the perpendicular bisector of the side opposite are not parallel and do not coincide. Then they intersect in exactly one point, D, and there are 3 cases to consider: Case 2: The point D is inside the triangle 
Case 3: The point D is on the triangle 
Case 4: The point D is outside the triangle For each case, construct DE perpendicular to AB and DF perpendicular to AC, and for cases 2 and 4 join D to B and D to C. In each case the following proof now holds: (I don't have the appropriate symbol for congruence on my keyboard so I'll use '=' to mean congruence.) DE = DF because all points on an angle bisector are equidistant from the sides of the angle DA = DA, and angle DEA and angle DFA are right angles Hence triangle ADE is congruent to triangle ADF by the hypotenuse-leg theorem of Euclidean Geometry. Therefore, we have AE = AF. Now, DB = DC because all points on the perpendicular bisector of a segment are equidistant from the ends of the segment. Also, DE = DF, and angle DEB and angle DFC are right angles. Hence, triangle DEB is congruent to triangle DFC by the hypotenuse-leg theorem, and hence FC = BE. It follows that AB = AC, in cases 2 and 3 by addition, and in case 4 by subtraction. The triangle is therefore isosceles. QED","['fake-proofs', 'geometric-construction', 'geometry']"
2020889,What is the value of $0 \choose 0$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question It can be 0 according to $0 \choose n$ and 1 according to $n \choose 0$.","['combinations', 'combinatorics', 'binomial-coefficients']"
2020909,Equivalence of Lebesgue measurability condition,"I'm having trouble proving the following proposition, which is ""left to the reader"". Let $f:[a,b]\to \mathbb{R}$ be a bounded function. Let us define $$s(f) := \left\{\int \phi : \phi \text{ is simple, } \phi \leq f\right\}$$ $$S(f) := \left\{\int \phi : \phi \text{ is simple, } \phi \geq f\right\}$$ and $$\underline\int f := \sup s(f)$$ $$\overline\int f := \inf S(f).$$
  Show that $f$ is Lebesgue measurable iff $\underline\int f = \overline\int f$. Supposing that $f$ is Lebesgue measurable, I thought of approximating $f$ using two sequences of simple functions converging ""from above"" and ""from below"" to $f$, and evaluate the error in the approximation, but I couldn't develop this idea any further.","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
2020937,Proof of Ramanujan doubly exponential series identity,"Apologies if this has been asked here already. On page 7 of this paper the following formula due to Ramanujan is presented: $$\alpha \sum_{k=0}^\infty e^{-n e^{k\alpha}}=\alpha\left(\frac{1}{2}+\sum_{k=1}^\infty\frac{(-1)^{k-1}n^k}{k!(e^{k\alpha}-1)}\right)-\gamma-\ln{n}+2\sum_{k=1}^\infty\varphi(k\beta)$$ where: $$\varphi(\beta)=\frac{1}{\beta}\Im\left(n^{-i\beta}\Gamma(i\beta+1)\right)$$ and $\alpha, n>0$ , for any $\beta>0$ such that $\alpha\beta=2\pi$ . No proof is presented there although it is mentioned that Poisson's formula can be used, with the note that the proof is 'intricate' (although it seems to imply that Ramanujan used properties of the theta function to prove it). The theorem is also mentioned in this answer , which mentions that the proof can be found here , but like the author of that answer I do not have access to this paper. I have tried to prove this myself, but I have not had luck using the Poisson summation formula directly since I do not know how to find the Fourier transform of $e^{a e^{bt}}$ (although using functions like $e^{t}e^{-e^t}$ I was able to formally find some vaguely similar summation identities involving imaginary parts of gamma functions ). I was wondering whether anyone knows how to prove this formula?","['complex-analysis', 'sequences-and-series', 'gamma-function', 'fourier-transform']"
2020944,Computing reverse percentile,"I am actually looking for a way to indicate a certain point on an interpolated curve in a plot (see this question ), but judging by the amount of answers there, that's just not possible. So is there a way to compute the missing coordinate of that point? More formally: Given the 1st, 25th, 50th, 75th, 99th and 100th percentile of some data and a value y , how do I compute x s.t. y is the x-th percentile (i.e. s.t. (x, y) lies on the curve interpolated from the aforementioned percentiles)? If not, can I compute it if I have access to the data? example percentiles: 0.01    1.4
0.25    1.4
0.5     1.5
0.75    1.5
0.99    8.9
1   18907.4

mean:   8.0722091348
stdev: 220.0677459302","['statistics', 'percentile', 'interpolation']"
2020966,Finding the derivative of $e^{x}$ with by taking the limit of e and the derivative in the same limit; done before?,"I am a curious Calculus student with an interesting question. The derivative of $e^{x}$ = $e^{x}$, however taking the derivative using limits, and not sums or some other method, is difficult. Perhaps would taking the limit of e, which is $\lim_{n \to \infty} {(1+{1\over n})^n}$ and the $\lim_{h \to 0}  {(e^{x+h} - e^{x})\over h}$, which is the derivative formula. Now, these limits have different terms, n and h respectively, which go to 0 and infinity. In order to get similar terms, an equivalency of the limits could be set up. $\lim_{h \to 0} {1\over h} = \infty$, and $\lim_{n \to \infty} n = \infty$ $\lim_{h \to 0} {1\over h}$ = $\lim_{n \to \infty} n$ and vice versa for $1\over n$ to $h$. Rearranging the equation now gives: $\lim_{n \to \infty} n({(1+{1\over n})^{n(x+{1\over n})} - (1+{1 \over n})^{nx}})$ or $\lim_{n \to \infty} n({(1+{1\over n})^{nx + 1} - (1+{1 \over n})^{nx}})$ Factoring out $(1+{1 \over n})^{nx}$ gives: $\lim_{n \to \infty} n((1 + {1\over n})^{nx})((1 + {1 \over n})^1 - 1)$ or $\lim_{n \to \infty} n((1 + {1\over n})^{nx})(1 + {1 \over n} - 1)$ Removing the 1's gives $\lim_{n \to \infty} n((1 + {1\over n})^{nx})({1 \over n})$ Distributing out the n gives: $\lim_{n \to \infty} (1 + {1\over n})^{nx}$ = $e^x$ This method works for $e^{ax}$ as well, where a is equal to some constant coefficient. For example: $d\over{dx}$ $e^{3x}$ = $3e^{3x}$. I will apply the previous method to $e^{3x}$. Setting up the limit: $\lim_{n \to \infty} {n}({(1+{1\over n})^{3n(x+{1\over n})} - (1+{1 \over n})^{3nx}})$ or $\lim_{n \to \infty} {n}({(1+{1\over n})^{3nx + 3} - (1+{1 \over n})^{3nx}})$ Factoring out $(1+{1 \over n})^{3nx}$ gives: $\lim_{n \to \infty} {n}((1+{1\over n})^{3nx})((1+{1\over n})^3 - 1)$ Multiplying out the $(1+{1 \over n})^3$ gives: $\lim_{n \to \infty} {n}((1+{1\over n})^{3nx})(1+ {3 \over n} + {3 \over n^2} + {1 \over n^3}- 1)$ Subtracting the 1's gives: $\lim_{n \to \infty} {n}((1+{1\over n})^{3nx})({3 \over n} + {3 \over n^2} + {1 \over n^3})$ Distributing the n gives: $\lim_{n \to \infty} ((1+{1\over n})^{3nx})(3 + {3 \over n} + {1 \over n^2})$ As n approaches $\infty$, $3 \over n$ and $1 \over n^2$ approach $0$. With that in mind, and removing the diminishing numbers, gives us: $\lim_{n \to \infty} 3(1+{1\over n})^{3nx}$ = $3e^{3x}$. It seems that using this method, the only significant term in the expanded binomial is the second term. Using binomial theorem, the second term of an expanded binomial is $\binom{a}{1} \over n$ which multiplied by the $n$ just becomes $\binom{a}{1}$. The second term of any combination is just the ${a}$ in $\binom{a}{k}$ where $k$ is some number $0 \le k\le a$. Thus, for all possible values $a$ in $d \over {dx}$ $e^{ax}$, this method will yield the correct derivative, $a e^{ax}$. My question is, since this ""works"", is it even following the rules of mathematics? Nowhere else have I seen this method, I just tried it out one day and saw that it worked. Can limits be exchanged like that? If all these answers are yes, then has someone does this before, who, and when? I feel like this insight isn't something new, and it'll probably look elementary, but my math teachers haven't seen this method before, so who knows? Thanks for looking and responding! --Additional application for $e^{0x}$-- $\lim_{n \to \infty} n({(1+{1\over n})^{n(0+{1\over n})} - (1+{1 \over n})^{0}})$ which equals: $\lim_{n \to \infty} n(1 + {1 \over n} - 1)$ = $1$, which is equal to $e^{0x}$ = $e^0$.","['derivatives', 'binomial-theorem']"
2020979,Show that Lipschitz $\|\nabla f(x) - \nabla f(y)\| \leq L\|x - y\|$ is implied by $f(y) \leq f(x) + \nabla f(x)^T(y-x) + \dfrac{L}{2}\|y-x\|^2$,"Pg 12 - 14 http://www.seas.ucla.edu/~vandenbe/236C/lectures/gradient.pdf Def : A $C^1$ convex function $f$ is Lipschitz smooth if $\exists L > 0$ s.t. $\forall x, y\in \mathbb{R}^n$
    \begin{equation}
		\|\nabla f(x) - \nabla f(y)\| \leq L\|x - y\|
	\end{equation} Claim: A $C^1$ convex function $f$ that satisfies $$f(y) \leq f(x) + \nabla f(x)^T(y-x) + \dfrac{L}{2}\|y-x\|^2$$ is Lipschitz Smooth (Note: 1. the reverse implication is referred to as the ""quadratic upper bound property"" 2. One poster suggested to use fenchel duality to show this Lipschitz Smoothness, Strong Convexity and the Hessian ) Proof attempt: It seems that the direct approach is through re-arrange and combine, which gives: 
$$0 \leq (\nabla f(x)-\nabla f(y))^T(y-x) +  L\|y-x\|^2$$
$$(\nabla f(y)-\nabla f(x))^T(y-x) \leq    L\|y-x\|^2$$ Using CS-inequality on the above $(\nabla f(y)-\nabla f(x))^T(y-x) \leq    L\|y-x\|^2$ gives: $$(\nabla f(y)-\nabla f(x))^T(y-x) \leq    \|\nabla f(y)-\nabla f(x)\|\|y-x\|$$
Now I have: $$(\nabla f(y)-\nabla f(x))^T(y-x) \leq    L\|y-x\|^2$$ $$(\nabla f(y)-\nabla f(x))^T(y-x) \leq    \|\nabla f(y)-\nabla
    f(x)\|\|y-x\|$$ How do I conclude $\|\nabla f(x) - \nabla f(y)\| \leq L\|x - y\|$?","['inequality', 'convex-analysis', 'multivariable-calculus', 'proof-writing', 'convex-optimization']"
2020999,induced morphism on cohomology groups,"Let $f: X \rightarrow Y$ be a morphism of varieties, and $\mathscr F$ be a sheaf (mamybe of Abelian groups) over $Y$. Does $f$ induce a morphism $H^i(Y,\mathscr F) \rightarrow H^i(X,f^{-1}\mathscr F)$? If it does, then how is this morphism defined? If $f$ is a covering map, or more exactly, a finite Galois covering, is this induced morphism always injective? If not, what additional restrictions are needed to guarantee its injectivity? Regards.",['algebraic-geometry']
2021154,tensorial product of C*-algebras and adjointness,"Given $M,N$, $R$-modules, it is standard verification that $-\otimes Z$ is left adjoint to $Hom(Z,-)$. If we have more structure, particularly if $\mathcal{A}$ and $\mathcal{B}$ are C*-algebras, choosing any suitable norm in the purely algebraic tensor product (so that the product is still a C*-algebra), what more adjunctions arise from this construction ?","['functional-analysis', 'category-theory', 'c-star-algebras', 'operator-algebras']"
2021191,Evaluate $ \int_{0}^{\infty} \frac{1}{x^3+x+1}dx$,"I want to evaluate the following integral $$ \int_{0}^{\infty} \frac{1}{x^3+x+1}\>dx$$ via Residue theorem. Or, any other methods are welcome! Actually i just compute this via mathematica, but it seems
the command Integrate[1/(x^3 + x + 1), {x, 0, Infinity}] gives some terrible output not a compact or simple form. My first trial is factor $x^3+x+1$ into linear terms but it does not seem easy,
I have difficulties for finding poles, $i.e$ , finding zeros for $x^3+x+1=0$ . And having trouble for finding proper contour.","['complex-analysis', 'improper-integrals', 'integration']"
2021213,$\lfloor a n\rfloor \lfloor b n\rfloor \lfloor c n\rfloor = \lfloor d n\rfloor \lfloor e n\rfloor \lfloor f n\rfloor$ for all $n$,"Simple task, but I know only extremely overkill solution :) Let $a,b,c,d,e,f$ be positive irrational numbers. Suppose that for any positive integer number $n$, $$\lfloor a  n\rfloor \cdot \lfloor b  n\rfloor \cdot \lfloor c  n\rfloor  
= \lfloor d n\rfloor \cdot \lfloor e  n\rfloor \cdot \lfloor f  n\rfloor.$$ Prove that the sets $\{a,b,c\}$ and  $\{d,e,f\}$ are equal.","['irrational-numbers', 'number-theory', 'elementary-number-theory', 'contest-math', 'ceiling-and-floor-functions']"
2021231,How can I derive what is $1\cdot 2\cdot 3\cdot 4 + 2\cdot 3\cdot 4\cdot 5+ 3\cdot 4\cdot 5\cdot 6+\cdots + (n-3)(n-2)(n-1)(n)$ ??,"I'd like to evaluate the series $$1\cdot 2\cdot 3\cdot 4 + 2\cdot 3\cdot 4\cdot 5+ 3\cdot 4\cdot 5\cdot 6+\cdots + (n-3)(n-2)(n-1)(n)$$ Since I am a high school student, I only know how to prove such formula's (By principal of mathematical induction). I don't know how to find result of such series. Please help. I shall be thankful if you guys can provide me general solution (Since I have been told that there exist a general solution by my friend who gave me this question).","['binomial-coefficients', 'calculus', 'proof-writing', 'summation', 'sequences-and-series']"
2021247,Solving an integral involving exponential functions $\int_{-\infty}^{+\infty} \frac{1}{\left(e^x+ e^{-x}\right)^n} e^{-\rho x^2 + a x} dx$,"I need to calculate
$$\int_{-\infty}^{+\infty} \frac{1}{\left(e^x+ e^{-x}\right)^n} e^{-\rho x^2 + a x} dx$$ where $n \in \mathbb{N}$, $\rho > 0$ and $a \in \mathbb{R}$, but I don't know how to follow. I've tried to include the expression in symbolic software trying to get a result with respect other functions, but nothing. I start thinking about approximating the integral using numerical integration, but before, I would like to be sure that the integral can not be expressed with respect other functions. Does anybody knows if I should go directly for numerical integration? I am really lost, thank you in advance. Updates: Some particular cases can be computed using Wolfram Alpha. It seems that $$\int_{-\infty}^{+\infty} \frac{1}{\left(e^x+ e^{-x}\right)} e^{-\rho x^2 +  x} dx = \frac{\sqrt{\pi/\rho}}{2}$$ and
$$\int_{-\infty}^{+\infty} \frac{1}{\left(e^x+ e^{-x}\right)} e^{-\rho x^2 + 3 x} dx = \int_{-\infty}^{+\infty} \frac{1}{\left(e^x+ e^{-x}\right)} e^{-\rho x^2 - 3 x} dx = (2 e^{1/\rho}-1)\frac{\sqrt{\pi/\rho}}{2}.$$ More generally (thank you JanG) we have
$$\int_{-\infty}^{+\infty} \frac{1}{\left(e^x+ e^{-x}\right)} e^{-\rho x^2 + (2m+1) x} dx =  \frac{\sqrt{\pi/\rho}}{2} (-1)^m \left( 1 + 2 \sum_{\ell=1}^m (-1)^\ell e^{\ell^2/\rho}\right)$$
for $m$ non-negative integer.","['approximate-integration', 'improper-integrals', 'integration', 'exponential-function']"
2021265,What's wrong with this proof about power sets?,"As an exercise, I was given the task to prove that $$ \mathcal{P}(A) \cup \mathcal{P}(B) \subseteq \mathcal{P}(A \cup B). $$ Wanting to do it in the most rigorous way possible, I used the logical definitions and passages as simple as possible, and this is what I've come up with: $ x \in \mathcal{P}(A) \cup \mathcal{P}(B) \Leftrightarrow x \in \mathcal{P}(A) \  \lor x \in \mathcal{P}(B) \Leftrightarrow x \subseteq A \ \lor x \subseteq B \Leftrightarrow $ $ \Leftrightarrow \forall y (y \in x \Rightarrow y \in A) \ \lor \ \forall y (y\in x \Rightarrow y \in B) \color{red}{ \boldsymbol\Leftrightarrow } \forall y (y\in x \Rightarrow y \in A \ \lor y \in B) \Leftrightarrow $ $ \Leftrightarrow \forall y (y\in x \Rightarrow y \in A \cup B) \Leftrightarrow x \subseteq A \cup B \Leftrightarrow x \in \mathcal{P}(A \cup B).$ All of this seems to prove that $ \forall x(x \in \mathcal{P}(A) \cup \mathcal{P}(B) \Leftrightarrow x \in \mathcal{P}(A \cup B)) $ or equivalently that $ \mathcal{P}(A) \cup \mathcal{P}(B) = \mathcal{P}(A \cup B) $, so I asked myself ""Why does the exercise only ask to prove half of it?"", and I rapidly realized that, for example, $ A \cup B $ is always an element of $\mathcal{P}(A \cup B) $, but it's not generally a subset of $A$ or $B$, so it's not necessarily an element in $\mathcal{P}(A) \cup \mathcal{P}(B)$. So I think there must be a mistake in my procedure. I highlighted in red the passage I'm not confident with, but I don't understand why it should be wrong.","['logic', 'elementary-set-theory']"
2021323,Does observing life on Earth increase the probability of life elsewhere?,"Say I have an implausibly large sack of balls. All I know is that the balls are numbered randomly from $1$ to $n$. For all I know, any value of $n$ (a positive integer) is equally likely. I reach into the sack and choose a ball randomly. The ball says $42$. Does this change at all the probabilities of the values of $n$ used to number the balls where $n \geq 42$? (Intuitively it might seem like $n$ is a low number in that if $n$ were very very large (say $2^{42}$) it seems implausible we would hit on a very low number from the first ball sampled. On the other hand, if $n$ is a very very large number, $42$ is equally as like as any ball to emerge.) Another simplified version might be where the balls are either blue or red, but I don't know how many are blue or how many are red. The first ball I choose is blue. Does this increase the probability of observing further blue balls in later samples? (Again if there were only one blue ball, intuitively it seems unlikely we would choose it on the first sample. On the other hand, if there were only one blue ball, that ball is as equally likely to emerge as any on the first sample.) It seems to be a question that crops up a lot. Like for example in the argument that well there's life here on Earth so it would be an improbable fluke if there were no life elsewhere . Of course this is a more complex question than just what colour the balls are, but the thrust of this argument seems to be a probabilistic one, like it boils down to the idea that we know there's one blue ball in the tiny sample we've seen, so there must be lots of blue balls in the implausibly large sack to explain that. I'm not convinced this latter argument makes sense, but on the other hand, I don't know how to reason about the problem or prove one way or the other whether seeing a blue ball early on affects the (relative) probability of the number of blue balls in the population. Hence I'm wondering, for example, if there's some sort of general theorem from probability that talks about this?",['probability-theory']
2021356,"If $ \sin \alpha + \sin \beta = a $ and $ \cos \alpha + \cos \beta = b $ , then show that $\sin(\alpha + \beta) = \frac {2ab } { a^2 + b^2} $","I've been able to do this, but I had to calculate $ \cos (\alpha + \beta) $ first. Is there a way to do this WITHOUT calculating $\cos(\alpha+\beta)$ first ? Here's how I did it by calculating $\cos(\alpha+\beta)$ first $ a^2 + b^2 = \sin ^2 \alpha + \sin ^2 \beta + 2 \sin \alpha \sin \beta + \cos ^2 \alpha + \cos ^2 \beta + 2 \cos \alpha \cos \beta $ $a^2 + b^2 = (\sin^2\alpha + \cos^2\alpha) + (\sin ^2 \beta + \cos^2 \beta) + 2(\cos\alpha\cos\beta + \sin\alpha\sin\beta)$ $a^2 + b^2 = 2 (1  + \cos(\alpha-\beta))$ $ \frac{a^2 + b^2}{2} = (1 + \cos(\alpha - \beta))$ $ b^2 - a^2 = (\cos ^2\alpha - \sin^2\alpha) + (\cos^2 \beta - \sin^2\beta) + 2\cos\alpha\cos\beta - 2\sin\alpha\sin\beta$ $b^2 - a^2 = (\cos^2\alpha - (1 - cos^2\alpha)) +(1-\sin^2\beta) - \sin^2\beta)) + 2(\cos\alpha\cos\beta - \sin\alpha\sin\beta) $ $b^2 - a^2 = 2 (\cos^2\alpha - \sin^2\beta + \cos(\alpha+\beta))$ $b^2 - a^2 = 2(\cos(\alpha+\beta)\cos(\alpha-\beta)+\cos(\alpha+\beta))$ $\frac{b^2 - a^2}{2} = \cos(\alpha+\beta)\{\cos(\alpha-\beta) + 1 \}$ $\frac{b^2 - a^2}{2} = \cos(\alpha+\beta)\{\frac{b^2+a^2}{2}\}$ $\cos(\alpha+\beta) = \frac {a^2 + b^2 } {a^2 - b^2}$ Then I just calculated $\sin(\alpha + \beta)$ by $1 - \cos^2(\alpha+\beta)$",['trigonometry']
2021365,Eigenvalues and eigenvectors of a unitary operator,"I have $φ: V → V$ as a unitary operator on a complex inner product space $V$. How can I show, without using any diagonalization results, that every eigenvalue $λ$ of $φ$ satisfies $|λ|=1$ and that eigenvectors corresponding to distinct eigenvalues are orthogonal?","['eigenvalues-eigenvectors', 'abstract-algebra', 'linear-algebra', 'inner-products']"
2021429,"Where does ""Additivity"" show up besides measure theory?","The properties of ""additivity"" or ""$\sigma$-additivity"" seem to be quite localized phenomenons at first glance, specific to measures or appropiate generalizations of those. Let $L$ be a lattice. Elements $x,y\in L$ are disjoint , if $x\wedge y = \bot$ (smallest element). A map $f : L \to M$ into some commutative monoid $M$ is additive , if $f(x \vee y) = x + y$ whenever $x,y$ are disjoint. Something similar can be done with $\sigma$-additivity, where $M$ is a complete monoid. I feel like there should be some interesting examples, where $L$ is not just a set of sets ordered by $\subseteq$. So: Where does ""Additivity"" show up besides measure theory? (A more basic problem is perhaps finding instances, where disjointness is useful. Here are two examples: $x,y\in \mathbb Z_{\geq 0}$ are disjoint w.r.t. to $\mid$, if they are coprime; subgroups $M,N\subseteq G$ are disjoint, if $M\cap N \cong 1$. In totally ordered sets, disjointness is of course quite boring).","['abstract-algebra', 'lattice-orders']"
2021494,Limits to infinity of a factorial function: $\lim_{n\to\infty}\frac{n!}{n^{n/2}}$,"How can this limit to infinity be solved? I've tried with d'Alembert but it just keeps coming up with the wrong answer. $$\lim\limits_{n\to\infty}\frac{n!}{n^{n/2}}$$ I might have a problem in simplifying factorial numbers. 
Thank you in advance.","['radicals', 'limits', 'infinity', 'factorial', 'exponentiation']"
2021498,"Proof that in a sequence of vectors of length N, the Nth vector must be zero","I have an assertion about a sequence of vectors which I have tested on a
computer but which I have been unable to prove. The assertion is that when
the vectors defined below are of length $N$, then the $N^{\text{th}}$ vector in the sequence must be zero.  Can anyone prove it? The sequnce of vectors is defined as follows.  Denote the first vector in
the sequence by $\mathbf{v}=\left( v_{1},v_{2},\cdots v_{N},\right) $, where
the sum of the $v_{i}$  is zero, i.e.
\begin{equation}
\sum_{i=1}^{N}v_{i}=0
\end{equation}
Then define vectors $\mathbf{u}^{\left( 1\right) }\left( \mathbf{v}\right) $
, $\mathbf{u}^{\left( 2\right) }\left( \mathbf{v}\right) $, $...$recursively
as follows.  If the elements of $\mathbf{u}^{\left( q\right) }\left( 
\mathbf{v}\right) $ are $u_{i}^{\left( q\right) }$ for $1\leqslant
i\leqslant N$, then for $q=1$ define
\begin{equation}
u_{i}^{\left( 1\right) }=v_{i}
\end{equation}
and for $q\geqslant 2$ define
\begin{equation}
u_{i}^{\left( q\right) }=u_{i}^{\left( q-1\right) }v_{i}-\frac{1}{q}%
\sum\limits_{j=1}^{N}v_{j}u_{j}^{\left( q-1\right) }
\end{equation}
The assertion is that as long as the sum of the $v_{i}$ is zero, then for vectors $\mathbf{v}$ of length $N$, $u_{i}^{\left( N\right) }=0$ for all $i$. The first few $u_{i}^{\left( q\right) }$ are as follows
\begin{equation}
\begin{array}{l}
u_{i}^{(1)}=v_{i} \\ 
u_{i}^{(2) }=v_{i}^{2}-\frac{1}{2}s_{2} \\ 
u_{i}^{(3)}=v_{i}^{3}-\frac{1}{2}v_{i}s_{2}-\frac{1}{3}s_{3} \\ 
u_{i}^{(4)}=v_{i}^{4}-\frac{1}{2}v_{i}^{2}s_{2}-\frac{1}{3}
v_{i}s_{3}-\frac{1}{4}\left( s_{4}-\frac{1}{2}s_{2}^{2}\right)  \\ 
u_{i}^{(5)}=v_{i}^{5}-\frac{1}{2}v_{i}^{3}s_{2}-\frac{1}{3}
v_{i}^{2}s_{3}-\frac{1}{4}v_{i}\left( s_{4}-\frac{1}{2}s_{2}^{2}\right) -
\frac{1}{5}\left( s_{5}-\frac{5}{6}s_{2}s_{3}\right)  \\ 
u_{i}^{(6)}=v_{i}^{6}-\frac{1}{2}v_{i}^{4}s_{2}-\frac{1}{3}%
v_{i}^{3}s_{3}-\frac{1}{4}v_{i}^{2}\left( s_{4}-\frac{1}{2}s_{2}^{2}\right) -
\frac{1}{5}v_{i}\left( s_{5}-\frac{5}{6}s_{2}s_{3}\right) -\frac{1}{6}\left(
s_{6}-\frac{1}{3}s_{3}^{2}+\frac{1}{8}s_{2}^{3}-\frac{3}{4}s_{2}s_{4}\right) \end{array}
\end{equation}
where the $s_{q}$ are the power sum symmetric polynomials defined by
\begin{equation}
s_{q}=\sum_{i}^{N}v_{i}^{q}
\end{equation}
The assertion is trivial for $N=1$, because if there is only one element in
the vector $v_{i}$, then since the sum of $v_{i}$ is zero then the single
element $v_{1}$ must be zero. When $N=2$, then $v_{1}+v_{2}=0$ so $v_{1}=-v_{2}$ and  $%
s_{2}=2v_{1}^{2}=2v_{2}^{2}$, which again gives $u_{1}^{\left( 2\right)
}=u_{2}^{\left( 2\right) }=0$. When $N=3$, then $v_{1}+v_{2}+v_{3}=0$ so
\begin{eqnarray*}
s_{3} &=&v_{1}^{3}+v_{2}^{3}+v_{3}^{3} \\
&=&v_{1}^{3}+v_{2}^{3}-\left(
v_{1}^{3}+3v_{1}^{2}v_{2}+3v_{1}v_{2}^{2}+v_{2}^{3}\right)  \\
&=&3v_{1}v_{2}v_{3}
\end{eqnarray*}
Then without loss of generality, consider $u_{i}^{\left( 3\right) }$ for $i=1
$ so
\begin{eqnarray}
u_{1}^{\left( 3\right) } &=&v_{1}^{3}-\frac{1}{2}v_{1}s_{2}-\frac{1}{3}s_{3}
\\
&=&v_{1}^{3}-\frac{1}{2}v_{1}\left( v_{1}^{2}+v_{2}^{2}+v_{3}^{2}\right)
-v_{1}v_{2}v_{3}  \notag \\
&=&\frac{1}{2}v_{1}\left( \left( v_{2}+v_{3}\right)
^{2}-v_{2}^{2}-v_{3}^{2}\right) -v_{1}v_{2}v_{3}  \notag \\
&=&0
\end{eqnarray} Perhaps there's a recursive proof, but if so, I haven't been able to find
it. Note about symmetry: A comment mentioned symmetric polynomials.  Although each individual $%
u_{i}^{(q)}$ isn't symmetric in all the $\{v_{j}\}$, because of the
dependence on $v_{i}$, the vectors $\mathbf{u}^{(q)}$ are symmetric with
respect to changing the order of the $v_{j}$, i.e. they satisfy
$$\mathbf{M}^{ij}\mathbf{u}^{(q)}\left( \mathbf{v}\right) =\mathbf{u}%
^{(q)}\left( \mathbf{M}^{ij}\mathbf{v}\right)$$ where $\mathbf{M}^{ij}$ is the $N\times N$ matrix that switches the $i^{%
\text{th}}$ element with the $j^{\text{th}}$ element in a vector of length $N
$ with all other elements in the vector unchanged.","['algebra-precalculus', 'polynomials', 'vectors', 'symmetric-polynomials']"
2021531,Find min natural number $n$ so that $2^{2002}$ divides $2001^{n}-1$,"Can someone explain me how this type of examples are being solved?
I know that I can watch this example like this $2001^{n}\equiv 1\ ({\rm mod}\ 2^{2002})$ but I don't know what to do when the divisor is such a large number like $2^{2002}$ $2^{2002}|2001^{n}-1$","['modular-arithmetic', 'discrete-mathematics']"
2021539,Is there a maximal prime number not being a sum of consecutive primes?,"Let $\mathcal S=\{p\in\mathbb P|\exists m,n\in\mathbb Z_+:p=p_n+\cdots+p_{n+m}\}$. For ""small"" primes, not much greater than one million, it seems that about half of the primes belong to $\mathcal S$. But the greater primes the more combinations of consecutive primes available. There are $\pi(p)$ primes less than or equal to $p$ and the number of available prime sequences is 
$1\cdot\pi(p)+2\cdot(\pi(p)-1)+3(\pi(p)-2)+\cdots+(\pi(p)-1)\cdot 2=$
$\displaystyle\frac{\pi(p)^3+3\pi(p)^2+4\pi(p)}{6}$ (If I calculated it right). I suppose it's possible to use the Prime Number Theorem to estimate the probability of $p\in\mathcal S$, but I'm pretty sure that I would mess it up. My questions are: Does $P(p\in\mathcal S)\to 1$ as $p\to\infty$? Can it be proved that there is a maximal prime number not being a sum of consecutive primes? See also How often is a sum of $k$ consecutive primes also prime? which is a similar but not an equivalent question. This is what I got so far. It doesn't support my intuition, but I will let it run up to $10,000,000$ or more.","['number-theory', 'conjectures', 'probability', 'prime-numbers']"
2021561,"How many permutations of $A_1, A_2, A_3, A_4, B_1, B_2, B_3$ have the $A$'s and $B$'s in ascending order.","How many permutations of $A_1, A_2, A_3, A_4, B_1, B_2, B_3$ have the $A$'s in ascending order and $B$'s in ascending order. (i.e, $A_1, A_2, B_1, A_3, B_2, B_3, A_4 $). Can the solution be extended?($A_1,\dots,A_n,B_1,\dots,B_m,C_1,\dots, C_s$)","['number-theory', 'combinatorics', 'discrete-mathematics']"
2021594,Baby Rudin Chapter 4 Exercise 1,"Suppose $f$ is a real function defined on $R^1$ which satisfies
  $$\lim_{h\to 0}[f(x+h)-f(x-h)]=0$$
  for every $x\in R^1$. Does this imply that $f$ is continuous? below is my solution, my answer is yes but I looked up the solution manual which says it doesn't and I am confused which step of my reasoning is incorrect. Thank you. Because $$\lim_{h\to 0}[f(x+h)-f(x-h)]=0$$ Let $$\lim_{h\to 0}f(x+h) = \lim_{h\to 0}f(x-h) = v = f(x)$$ Because $$\lim_{h\to 0}f(x+h) = v$$ thus $$\forall \epsilon>0, \exists h_1>0, \forall h < h_1, d(f(x+h),f(x)) < \epsilon$$ Similarly, for $f(x-h)$, I get 
  $$\forall \epsilon>0, \exists h_2>0, \forall h < h_2, d(f(x-h),f(x)) < \epsilon$$ Let $$H = min(h_1, h_2)$$ Then $$\forall \epsilon>0, \exists H > 0, \forall p\in R^1, \text{if } d(x,p)<H, \text{then } d(f(x), f(p))<\epsilon$$ Thus, $f$ is continuous.","['real-analysis', 'proof-verification']"
2021599,"""Options"", Partial Functions, Pointed Sets in Undergraduate Mahtematics?","As a mathematics undergrad, one is usually taught with basic set theory the notion of direct product $A \times B$ and disjoint union $A \sqcup B$.  But however common, I never encountered ""Option(A)"" (It has many names) with $Opt(A) = A \sqcup \{\blacksquare\}$ where $\blacksquare$ is disjoint from $A$ and is thought of as perhaps ""No A"" or ""None"". For example, a careless mathematician or software engineer may imagine a function $FirstElement : FiniteSeqOf(A) \rightarrow A$ failing to consider how one would define $FirstElement$ on the list of length $0$.  But wrapping the domain with $Opt$ saves the day: $FirstElement: FiniteSeqOf(A) \rightarrow Opt(A)$ with $FirstElement([]) = \blacksquare$. The construction $Opt(A)$ is a functor, of course.  It can also be seen as associating a set $A$ with subsets / finite sequences of $A$ if size $0$ or $1$. Closely related: partial functions, categories of pointed sets. Given the simplicity of this construct compare to others commonly seen, where does this show up, explicitly, in undergraduate mathematics?","['math-software', 'functions']"
2021609,Prove that $X_{(n)}/n$ tends to zero in probability,"Let there be given a sample from the distribution $F$ such that
$$ \lim\limits_{y \to \infty } y(1 - F(y) + F(-y)) = 0$$ Prove that $X_{(n)} / n \to 0$ in probability, where $X_{(n)}$ is order statistics. My attempt to solve it
$$ \mathbb{P}(|X_{(n)}/n| > \epsilon) = \mathbb{P}(|X_{(n)}| > n\epsilon) = 1 - \mathbb{P}(|X_{(n)}| < n\epsilon) = 1 - \mathbb{P}(-n\epsilon < X_{(n)} < n\epsilon) = 1 - \mathbb{P}(X_{(n)} < n\epsilon) + \mathbb{P}(X_{(n)} < -n\epsilon) = 1 - (F(n\epsilon))^n + (F(-n\epsilon))^n$$ So, maybe from the initial statement it can be somehow deduce that the last tends to zero. Thanks for any help!","['real-analysis', 'probability', 'statistics']"
2021615,Infinite Fibonacci sums $\sum_{n=1}^{\infty} \frac{1}{f_nf_{n+2}}$ - diverge or converge,"I am currently going through exercises regarding convergence/divergence. For my previous question I used the ratio test, and managed to get through it all okay (I think). I proved that: $$\sum_{n=1}^{\infty} \frac{n!}{n^n}$$ 
converges, and now I have to show whether or not an inverse Fibonacci sum converges/diverges and I'm not sure what method to use. What is the best way to tackle this problem? $$\sum_{n=1}^{\infty} \frac{1}{f_nf_{n+2}}$$ 
Where $f_n$ is the Fibonacci sequence, $f_n = f_{n-1} + f_{n-2}$ with initial terms $f_1 = f_2 = 1$ I don't believe it's similar to how I completed $\sum_{n=1}^{\infty} \frac{n!}{n^n}$ but let me know if I'm wrong. Based on looking at fairly similar questions on this website I have started trying to use proof by contradiction.","['real-analysis', 'fibonacci-numbers', 'sequences-and-series']"
2021634,What type of set is the intersection of two spheres?,"Let $X$ be a normed space and $S(x, \varepsilon)=\{y\in X: \|x-y\|=\varepsilon\}$​ denote the sphere centered at $x\in X$​ with radius $\varepsilon>0​.$ Consider two different spheres $S_1=S(x_1, \varepsilon_1)$​ and $S_2=S(x_2, \varepsilon_2)$ with non-empty intersection​. What can we say about the set $S_1\cap S_2$​?   Is it true that this set is always homeomorphic to a sphere or a ball of ""one dimension less"" (or even more dimensions less)? What we know for sure: A paper by Jussi Vaisala contains a short proof of the following: Lemma 2.2: The intersection of two spheres in a finite dimensional normed space $X$​ of dimension $n\geq 3$​ is a connected set. Furthermore, if $X$​ is strictly convex , then this intersection   is either a singleton or homeomorphic to an $(n-2)​$-sphere. My guess is that the second claim of the Lemma still holds for $n=2​$, but was omitted from it because of the intersection  not being connected.
So, this should pretty much settle  my question for finite dimensional strictly convex spaces. Without the assumption of $X$​ being strictly convex we may have some more possibilities. Consider $X=\mathbb{R}^3​$  equipped with the $\|⋅\|_\infty$​ norm. The spheres are in fact cubes in $\mathbb{R}^3​$​ and the intersection of two cubes may additionally be (homeomorphic to) a square, which is the closed unit ball of $(\mathbb{R}^2, \|⋅\|_\infty)​$, or   (homeomorphic to) a line segment, which is the closed unit ball of $(\mathbb{R}, \|⋅\|_\infty)$​. So, what can we say if we remove the strict convexity assumption? Is there a counterexample where the intersection is neither a sphere or a ball? I couldn't find any. Additionally what can be said for infinite dimensional normed spaces? I couldn't find any literature regarding this topic and probably for a good reason since Vaisala mentions that while $S_1\cap S_2$ being connected was known by Novikoff in 1955,   $S_1\cap S_2$​ being homeomorphic to the $(n-2)​$-sphere seemed to be a new result [sic] at the time he published it (2010).","['normed-spaces', 'general-topology', 'spheres', 'geometry']"
2021671,Determine the remainder when $f(x) = 3x^5 - 5x^2 + 4x + 1$ is divided by $(x-1)(x+2)$,"This question arose while I was tutoring a student on the topic of the Remainder Theorem. Now, the Remainder Theorem tells us that when a polynomial $p(x)$ is divided by a linear factor $(x-a)$, the remainder is simply $p(a)$. However, in this case we have a product of linear factors. Using the Remainder Theorem we can see that neither $(x-1)$ nor $(x+2)$ is a factor of $f(x)$. Also, if we try to find the remainder using long division, we get a relatively ugly remainder of 
$$
3(14x - 13)
$$
I assume this is not the correct approach as all other questions in this topic used the Remainder Theorem. So perhaps there is a more elegant approach?","['algebra-precalculus', 'polynomials']"
2021732,Suspect unfair die,If I claim to have a fair die that rolls 1-6 uniformly but my die actually only rolls 1-5 uniformly (and never produces a 6) how many rolls would you need to see before you had over 50% confidence that I was messing with you?,['probability']
2021799,"Hypercomplex structure as integrable $Gl(\mathbb{H},n)$-structure.","Although there is some mess with notation, we say that a manifold $M^{4n}$ has an almost hypercomplex structure if there are three almost complex structures $I,J,K$ satisfing quaternions relations. Now classical definition of hypercomplexity requires all of them to be integrable. Since an almost hypercomplex structure is nothing but $Gl(\mathbb{H},n)$ structure, I would like to know if being hypercomplex is equivalento to be an integrable (in the sence of G-structur) almost hypercomplex? Ofcourse being integrable implies integrability of $I,J,K$ yet I can't see if the seperate integrability of them implies that they can be simultaniously presented in a canonical way in some chart?",['differential-geometry']
2021804,Is there a mean-value theorem for volume integrals?,"I have just been reading about the mean value theorems for integrals, surface integrals and line integrals. I did a Google search for a corresponding theorem of volume integrals, and couldn't find any evidence of one. I would guess that, if $f(x,y,z)$ is a differentiable function defined in the region $\Omega$ in $\mathbb{R}^3$, then: $\iiint_{\Omega}f(x,y,z)dxdydz=f(x_0,y_0,z_0)V(\Omega)$, where $(x_0,y_0,z_0)$ is some point in $\Omega$ and $V(\Omega)$ is the volume of the region $\Omega$. This holds for the trivial example $f(x,y,z)=c$, where $c$ is a constant in the domain of interest. Are there counter-examples, or does such a theorem exist?","['real-analysis', 'integration', 'definite-integrals']"
