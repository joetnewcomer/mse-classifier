question_id,title,body,tags
3484467,Supnorms are equivalent with respect to two different bases,"If $F$ is a finite dimensional vector spaces over $\mathbb R$ , I have to show that suprimum norm with respect to two different bases are equivalent. I know how to prove that in a finite dimentional vector space any two norms are equivalent. In that proof we use induction on 
dimention. Edit:  without using that (in finite dimentional spaces two norms are equivalent)
How can one prove this. I tried to do this but no result. Any help","['normed-spaces', 'functional-analysis', 'real-analysis']"
3484472,"Population of P people, where each person knows K others, how many people mutually know each other","If you have a population of $P$ people, where each person knows $K$ others within the population, (does not have to be mutual, i.e. if I know you, you don't necessarily know me), and $1 < K < P$ , How many people at the least must mutually know each other? Is there a general formula for this minimum in terms of $P$ and $K?$",['combinatorics']
3484541,Is there an intuitive way to view the definition of the McShane integral?,"To my understanding the definition of the McShane integral is identical to the definition of the Henstockâ€“Kurzweil integral with the exception that each tag does not have to be contained in the subinterval for which it is assigned to. However, the gauge function in general will force the corresponding subinterval to be relatively close to the tag. Still, the tag can be picked a bit outside of the subinterval. If I am not mistakes this implies that a function is McShane integrable if and only if it is absolutely integrable. This is not the case for the Henstockâ€“Kurzweil integral. I do not understand how such a subtle modification of the definition of the Henstockâ€“Kurzweil integral makes every McShane integrable function absolutely McShane integrable. By functions I am simply refering to functions on $\mathbb{R}$ for the sake of simplicity. Is there an intuitive way to view the differences between the aforementioned integrals and in particular why McShane integrable functions are absolutely integrable?","['integration', 'lebesgue-integral', 'analysis', 'real-analysis', 'gauge-integral']"
3484576,Is an exponential family the same as an exponentially convex set?,"An exponential family of probability distributions is usually defined as $$
p(x) = e^{\theta\cdot f(x) \,-\, \psi(\theta)},
$$ where $\theta$ is a vector of parameters, $f(x)$ is some arbitrary vector-valued function of $x$ , and $\psi= \log\sum_x e^{\theta\cdot f(x)}$ , which ensures normalisation. This defines a set of probability distributions, one for each value of the parameter vector $\theta$ . It's this set that's referred to as the exponential family. Usually, $\theta$ seems to be assumed to be finite-dimensional, but I think this doesn't have to be the case. I'll assume for this question that it isn't, and the $\cdot$ could be any inner product, i.e. it could stand for an infinite sum or an integral rather than a finite sum. One can also define an exponentially convex set of probability distributions in the following way: a set $C$ of probability distributions is exponentially convex if, for all $\lambda\in \mathbb{R}$ , $$
p \in C,q\in C \implies r\in C,
$$ where $$
r(x) = e^{(1-\lambda)\log p(x) \,+\, \lambda \log q(x) \,-\, \psi(\lambda)},
$$ and $\psi = \log\sum_x e^{(1-\lambda)\log p(x) \,+\, \lambda \log q(x)}$ . Note that I don't restrict $\lambda$ to between 0 and 1. One could equivalently define $r(x)$ as $$
r(x) = \frac{1}{Z}p(x)^{1-\lambda}q(x)^\lambda.
$$ My question is, are exponential families and exponentially convex sets the same thing? It's easy to show that all exponential families are exponentially convex sets, but what about the other direction? That is, if I have some set of distributions and I want to show that it's an exponential family, is it enough to show that it is exponentially convex in the above sense, or do there exist exponentially convex sets that are not exponential families? If the answer is no, what would be a simple counterexample?","['probability-theory', 'information-geometry']"
3484622,Prove that the number of self-conjugate partitions of $n$ equals the number of partitions of $n$ into distinct odd parts,"First, I would love if someone can provide some clarification of this problem. Then possibly help me map out/begin a proof. So If I were taking the number $6$ and partitioning for example (just to make sure I understand what the question is asking): The only partition with distinct odd parts would be $6=5+1$ . However, for self-conjugate partitions I understand when I flip over the middle diagonal the picture should look exactly the same? That would also only happen once. How would I go about formulating a proof?","['integer-partitions', 'number-theory']"
3484686,"How to prove that any number from $0$ to $\frac{n(n+1)}{2}$ can be obtained as sum of subset of set {$1,2,3, ... ,n$}","I tried to prove it using pigeon hole principle (by proving that $\frac{n(n+1)}{2}$ distinct numbers can be obtained as sum). Edit :
some good answers are already posted. Thanks to all of them. Do share a proof using different methods . It's sad that i cannot accept more than one answer.","['elementary-number-theory', 'arithmetic', 'pigeonhole-principle', 'discrete-mathematics']"
3484688,$\frac{x}{y}-\frac{y}{x}=\frac56$ and $x^2-y^2=5$,"Solve the system: $$\begin{array}{|l}
 \dfrac{x}{y}-\dfrac{y}{x}=\dfrac{5}{6} \\ x^2-y^2=5 \end{array}$$ First, we have $x,y \ne 0$ . Let's write the first equation as: $$\dfrac{x}{y}-\dfrac{y}{x}=\dfrac{5}{6} \Leftrightarrow \dfrac{x^2-y^2}{xy}=\dfrac{5}{6}$$ We have $x^2-y^2=5$ , therefore $xy=6$ . What to do next?","['algebra-precalculus', 'systems-of-equations', 'quadratics']"
3484698,Why do additional Taylor terms lead to an improved approximation of a function?,"I hope my question becomes clear: I understand what a Taylor polynomial does. It approximates an analytical function in the point $x=a$ in a way that the n'th order Taylor polynomial matches the function up to its n'th derivative in the point $x=a$ . Something I could never answer myself though is: Why does each additional Taylor term improve the approximation of the function in the vicinity of the point $x=a$ ? Can't it be that a Taylor polynomial provides a worse approximation in the vicinity of $x=a$ when taking more Taylor terms (i.e. choosing a later truncation for $n$ )? If this is the case: Is it also safe to say that truncating a Taylor series at larger $n$ also improves the approximation of $f(x)$ for points far away from $x=a$ ? And a last question: Why is an analytic function $f(x)$ almost always equal to the Taylor series of the form $f(x)=\sum_{n=0}^{\infty} \frac{f^{(n)}}{n!} (x-a)!$ Are there function where this is not the case? And is there a clear cut proof, why an infinite Taylor series equals an analytic function in general?","['approximation', 'taylor-expansion', 'real-analysis']"
3484730,Correct usage of Stolz-Cesaro theorem in finding a limit,"Is this solution correct? I've seen this solution before, but I don't know why it is so. And which rule? The task is to find: $\omega=\displaystyle\lim_{n\to +\infty}\left(\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}\right)$ I know that this $\lim$ equals $\frac{1}{e},$ but do you see if this solution is correct or not? Solution is : $\displaystyle\lim_{n\to +\infty}\left(\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}\right)=\displaystyle\lim_{n\to +\infty}\left((n+1)\sqrt[n+1]{\frac{(n+1)!}{(n+1)^{n+1}}}-n\sqrt[n]{\frac{n!}{n^{n}}}\right)$ $=\displaystyle\lim_{n\to +\infty}\frac{\frac{(n+1)!}{(n+1)^{n+1}}}{\frac{n!}{n^{n}}}$ $=\frac{1}{e}$ Notes & suggestions of mine: I think he uses Stolz-Cesaro theorem: See that $\displaystyle\lim_{n\to +\infty}\frac{a_{n}}{b_{n}}=\displaystyle\lim_{n\to +\infty}\frac{a_{n+1}-a_{n}}{b_{n+1}-b_{n}}$ Chosen $a_{n}=n\sqrt[n]{\frac{n!}{n^n}}$ and $b_{n}=n$ clearly $b_{n}$ goes to $+\infty$ and $a_{n}$ goes to $+\infty$ because $n.\frac{1}{e}=+\infty$ we obtain: $\omega=\displaystyle\lim_{n\to +\infty}\frac{n\sqrt[n]{n!}}{n}$ Then use Cauchy-d'Alembert $=\displaystyle\lim_{n\to +\infty}\frac{\frac{(n+1)!}{(n+1)^{n+1}}}{\frac{n!}{n^{n}}}=\frac{1}{e}$ Is my explanation O.K.? 
May I ask for a correction? Any remark ?","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3484759,How to calculate principal value of this complex integral?,"$$I = \text{p. v.}\int_{-\infty}^{\infty}\frac{e^{\alpha x}}{e^{2x} - 1}dx$$ $$ 0<\Re(\alpha)<2$$ Use this contour (see image) $$\lim_{\epsilon\rightarrow 0, \\ R\rightarrow\infty}{\int_{-R+i\pi}^{-R} + \int_{-R}^{-\epsilon} + \int_{C_{\epsilon^{+}}} + \int_{\epsilon}^{R} + \int_{R}^{R+i\pi} +\int_{R+i\pi}^{\epsilon+i\pi} + \int_{C_{\epsilon^{-}}} + \int_{-\epsilon+i\pi}^{-R+i\pi}}$$ Am I do right? $$\int_{-R+i\pi}^{-R} = 0,$$ $$\int_{R}^{R+i\pi} = 0,$$ and $$\int_{C_{\epsilon^{-}}},\int_{C_{\epsilon^{+}}} = -i\pi \ \underset{z=0}{\text{Res}}\left(\frac{e^{\alpha z}}{e^{2z} - 1}\right)$$ How to do next?","['complex-analysis', 'complex-integration', 'cauchy-principal-value']"
3484763,Definition 4.1 Principles of Mathematical Analysis,"Definition 4.1 Let X and Y be metric spaces; suppose E $\subset$ X, if $f$ maps E into Y and $p$ is a limit point of E. We write $f(x)$ $\to$ $q$ as $x$ $\to$ p
  if there is a point $q$ $\in$ Y with the following property: $\forall \epsilon>0, \exists\delta>0 $ s.t $d(f(x),q)<\epsilon$ for all points $x\in E$ for which $0<d(x,q)<\delta$ I have a question about p being the limit point. Is it necessary for this definition? What if $p$ is an isolated point? Thanks in advance!",['real-analysis']
3484795,Solve $\lim_{x\to 0^{+}}x^{x^x-1}$ [duplicate],"This question already has answers here : Limits using L'Hopital's rule $\lim_{x\to0^+} (x^{x^x-1})$ (4 answers) Closed 4 years ago . $$\lim_{x\to 0^{+}}x^{x^x-1}$$ Note:- I have solved this problem and below is the solution but I am searching for the better approach My attempt is as follows:- $x^x$ is indeterminate form $(0^0)$ as $x$ tends to $0^{+}$ $$\lim_{x\to 0^{+}}x^{x^x-1}=e^{\lim_{x\to 0^{+}}\left(x^x-1\right)ln(x)}\tag{1}$$ Let's assume $\lim_{x\to 0^{+}}\left(x^x-1\right)ln(x)=y$ $$y=\lim_{x\to 0^{+}}\left(e^{x\ln x}-1\right)\ln x\tag{2}$$ As $x$ tends to $0^{+}$ , $x\ln x$ is the indeterminate form $(0\cdot\infty)$ So first let's see what this indeterminate form actually tends to $$z=\lim_{x\to 0^{+}}x\ln x$$ Assume $t=\ln x$ $$z=\lim_{t\to -\infty}e^tt$$ $$z=\lim_{t\to -\infty}\dfrac{t}{e^{-t}}$$ So we are getting $\dfrac{-\infty}{\infty}$ and we can apply L's Hospital rule here $$z=\lim_{t\to -\infty}\dfrac{1}{-e^{-t}}$$ $$z=0$$ So going back to equation $(1)$ , now we can say as $x$ tends to $0^{+}$ , $x\ln x$ tends to $0$ $$y=\lim_{x\to 0^{+}}\left(e^{x\ln x}-1\right)\ln x\tag{3}$$ $$y=\lim_{x\to 0^{+}}\dfrac{\left(e^{x\ln x}-1\right)}{x\ln x}\cdot x\ln^2 x$$ $$y=\lim_{x\to 0^{+}}\dfrac{\left(e^{x\ln x}-1\right)}{x\ln x}\cdot x\ln^2x$$ $$y=\lim_{x\to 0^{+}}x\ln^2x$$ $$y=\lim_{x\to 0^{+}}\dfrac{ln^2x}{\dfrac{1}{x}}$$ So we have $\dfrac{\infty}{\infty}$ form here and so we can apply L's hospital rule here $$y=\lim_{x\to 0^{+}}\dfrac{2\ln x\cdot\dfrac{1}{x}}{\dfrac{-1}{x^2}}$$ $$y=\lim_{x\to 0^{+}}\dfrac{2\ln x}{\dfrac{-1}{x}}$$ Again applying L's hospital rule here as we have $\dfrac{\infty}{\infty}$ form $$y=\lim_{x\to 0^{+}}\dfrac{\dfrac{2}{x}}{\dfrac{1}{x^2}}$$ $$y=\lim_{x\to 0^{+}}2x$$ $$y=0$$ Putting value of $y$ back in equation $(1)$ $$\lim_{x\to 0^{+}}x^{x^x-1}=1$$ So lots of ups and down in this problem, can it solved by any simpler means?","['limits', 'calculus', 'exponential-function']"
3484835,"The proportion of binary digits of $\sum_{k=1}^\infty \Big\lfloor{\frac{k}{2}\sqrt{p}\Big\rfloor}\cdot2^{-k}$ equal to one, is $> 0.978$ if $p=143$.","Can you prove this? Is it true? If $p$ is an integer, is this proportion never equal to 50%? See my related question regarding this sum, here . For $p=143$ , I computed the binary digits in Excel using carry-over operations implemented in Excel formulas. The first few digits equal to zero take place at the following locations: 47, 95, 143, 191, 239, 287, 335, 383, 431, 479, 527, 574, 622, 670, 718, 766, 814, 862, 910, 958, 1006, 1054, 1102, 1149, 1197, 1245, 1293, 1341, 1389, 1437, 1485, 1533, 1581, 1629, 1677, 1724, 1772, 1820, 1868, 1916, 1964, 2012, 2060, 2108, 2156, 2204, 2252, 2299, 2347, 2395 The delta between two successive locations with a zero digit, is 48 most of the time, and sometimes 47. So, less than 1 out of 47 binary digits is equal to zero, though this is not a proof, just a statement based on observations. More precisely, the location delta is 47 (rather than 48) between a zero digit and the previous one, only at the following digit positions: $574+ k \cdot 575$ , for $k=0, 1, 2$ and so on. You can thus compute the exact proportion of binary digits equal to one. Can you compute that proportion? It must be - it seems - between $1-\frac{1}{47}$ and $1-\frac{1}{48}$ , and much closer to $1-\frac{1}{48}$ than to $1-\frac{1}{47}$ . I assumed here that we are only interested in the fractional part, and the first digit for the fractional part of the number in question, is assigned position 1. The exciting thing here is the discovery of a class of (presumably) irrational, non-normal numbers, that are rather natural. Usually such numbers are built artificially. Other similar numbers include the rabbit number , and numbers described here (or problem #11 in this article ). Other spectacular examples in the same family Besides $p=143 = 11 \times 13$ , with first zero digit in position 47 , we have: $p = 17 \times 19$ : the first binary digit equal to 0 is in position 71 ; about 98.3% of the digits are equal to 1. $p = 29 \times 31$ : the first binary digit equal to 0 is in position 119 ; about 98.7% of the digits are equal to 1. $p = 41 \times 43$ : the first binary digit equal to 0 is in position 167 ; about 99.1% of the digits are equal to 1. $p = 59 \times 61$ : the first binary digit equal to 0 is in position 239 ; more than 99% of the digits are equal to 1. Sounds like if $p$ is the product of twin primes, it leads to interesting results. Would be interesting to see if the sequence that includes the numbers $47, 71, 119, 167, 239, \cdots$ is well known. A case with known exact solution By known , I mean that the exact proportion of binary digits equal to 1 is a known, explicit algebraic number. Not a proof, but it is based on my experience dealing with this kind of stuff, and strong empirical evidence. The case $p=2$ leads to very strong and simple patterns in the distribution of the binary digits. The proportion of digits equal to 1 is $\sqrt{2}/2$ . An immediate consequence is that the number that has these digits, is irrational. Below are the first 2,000 or so digits. 11011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101101110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011101101110110110111011011101101101110110111011011011101101110110111011011011101101110110110111011011 The lag-1 autocorrelation in this sequence of binary digits seems to be equal to $1 - \sqrt{2} < 0$ , a value that is way too small for the number in question to be normal in any base $b$ with $1< b \leq 2$ . See chart in section 4.1.(b) in this article for details. Useful reference See second half of the following Wolfram article about the Devil's staircase.","['number-theory', 'irrational-numbers', 'binary', 'probability-theory']"
3484838,Counting problem: Checking 9 squares out of $3\times 5$ board,"I'm self learning some combinatorics and I encountered the following counting problem: How many ways are there to check 9 squares out of $3\times5$ boards such that in every column there's at least one checked square? (To be more precise, the board has 3 rows and 5 columns) I think I know the outline of the solution: Let $C$ be the set of all possible checking of $9$ squares off the greed and let $C_i$ be the checking of the board where the $i^{th}$ column has no square checked- I then proceed by using the Inclusion - Exclusion principle and so the solution is $$|C|-|C_1\cup C_2\cup C_3\cup C_4\cup C_5|$$ So I have two questions: How many ways there are actually to check the board without restrictions ? When I try to think about it I think about selecting a subset of 9 squares out of 15 squares so $\binom{15}{9}$ , is this correct? Somehow it does'nt feel like it's the right number ; Is the outline to the solution I wrote above the right approach to this problem? I know this is very elementary but I'm really confused by all the counting arguments and most of the time my initial intuition turns out to be wrong so any help would be much appreciated! Update with solution For each $C_i$ we restrict our board to be one column less now, so it's actually checking $9$ squares on a $3\times 4$ board- there are $\binom{12}{9}$ ways to do so. Furthermore, up to renaming the columns this procedure is symmetric so there are $5$ ways to do that. For any intersection of the form $C_i\cap C_j$ (for $i\neq j$ ) we restrict our board to be $3\times 3$ , and now there's a single way to check the board. There are $\binom{5}{2}$ such intersections. Any bigger intersection would be empty. From the Inclusion - Exclusion principle we get: $$
\begin{aligned}\left|\bigcup_{i=1}^{5} C_{i}\right| &=5 C_{i}-\left(\begin{array}{c}{5} \\ {2}\end{array}\right)\left|C_{i} \cap C_{j}\right| \\ &=5\left(\begin{array}{c}{12} \\ {9}\end{array}\right)-\left(\begin{array}{c}{5} \\ {2}\end{array}\right) \end{aligned}
$$ And so the number of possible checking that fit the decrepstion of the exercise is: $$
|C|-\left|\bigcup_{i=1}^{5} C_{i}\right|=\left(\begin{array}{c}{15} \\ {9}\end{array}\right)-\left(5\left(\begin{array}{c}{12} \\ {9}\end{array}\right)-\left(\begin{array}{c}{5} \\ {2}\end{array}\right)\right)=3915
$$","['solution-verification', 'combinatorics', 'discrete-mathematics']"
3484851,How many roots has the following equation?,"I would please like your guidance to find, depending on $a$ , how many roots the following equation has: $x^4+4x+a=0$ , where $a$ is a real parameter. I tried to use Bolzano's Theorem for a specific interval but I am afraid that my approach would not be accurate.
Thank you very much in advance.",['calculus']
3484856,"Statistics , confidence interval","I have a sample of $x_i$ where $ x_i =\xi + \eta$ , $\xi \sim N(0,\sigma^2)$ and $\eta \sim N(a,1)$ i.i.d. So I need to construct  confidence interval with confidence level $\gamma$ for $\sigma^2$ with unknown $a$ .
My attempt is, I used the following statistic : $S^2 = \frac{\sum (x_i - \overline{x})^2}{n-1}$ but I get an interval which could be with negative endpoints.","['statistics', 'probability-theory']"
3484875,Length of a planar curve,"Let $\gamma:[0,L]\rightarrow \mathbb{R}^2$ be a $C^\infty$ curve parameterized by arc length. We suppose that $\gamma$ is a simple closed curve that bounds a bounded domain in $\mathbb{R}^2$ . We denote by $\nu(t)$ the inward unit normal at $\gamma(t)$ . For any $\epsilon>0$ sufficiently small, $t\in[0,L]\mapsto \gamma_\epsilon(t)=\gamma(t)+\epsilon \nu(t)$ is a still a smooth curve. Question. Is it true that the length of the curve $\gamma_\epsilon$ is less than or equal to the length of $\gamma$ ? ðŸ¤”",['differential-geometry']
3484876,Function space and abelian group.,"Suppose that $G$ is a connected Hausdorff topological group. Let consider $Map([0,1],G)$ the space of all continuous paths in $G$ . Clearly $H=Map([0,1],G)$ is a topological group (compact-open topology). How to prove that $H^{ab}=Map([0,1],G^{ab})$ (as topological groups) where $H^{ab}$ is the abelianisation of $H$ .","['general-topology', 'group-theory']"
3484889,"Is the semigroup of lines $\mathcal{M}_n(\mathbb{Q})$, finitely generated","I was researching $\mathcal{M}_n(\mathbb{Q})$ , the set of square $n\times n$ matrices with rational entries, as a semigroup with matrix multiplication. For $A,B\in\mathcal{M}_n(\mathbb{Q})$ , the equivalence relation $A\sim B$ will be true when $A=cB$ for $c\in\mathbb{Q}$ , non-zero. The quotient, $\mathcal{M}_n(\mathbb{Q})/\sim$ , is also a semigroup (looks like lines in $\mathbb{R}^{n^2}$ , when $\mathcal{M}_n(\mathbb{Q})$ is interpretted in Euclidean space). I was wondering if this quotient semigroup is finitely generated (the set if finitely generated and one only has to hit a point on each line to generate it). I tried to prove by contradiction with finite generators and trying to find a non-generated element but to no avail.","['matrices', 'finitely-generated', 'abstract-algebra', 'linear-algebra', 'semigroups']"
3484901,Why are two open sets isomorphic (Hartshorne Corollary I 4.5),"Let $X,Y$ be birational varieties and $\phi: X \rightarrow Y, \psi: Y \rightarrow X$ mutually inverse rational dominant maps. Let $\phi$ be represented by $(U,\phi_U)$ and $\psi$ by $(V,\psi_V)$ . The proof of Hartshorne's Corollary I 4.5 says that the open sets $\phi_U^{-1}(\psi_V^{-1}(U)) \subset U$ and $\psi_V^{-1}(\phi_U^{-1}(V)) \subset V$ are isomorphic via $\phi$ and $\psi$ respectively. However, I have a very basic question concerning this. I wonder why $\phi_U$ sends $\phi_U^{-1}(\psi_V^{-1}(U))$ into $\psi_V^{-1}(\phi_U^{-1}(V))$ (i.e. why the image is contained in the second set). $\phi_U \circ  \phi_U^{-1}(\psi_V^{-1}(U))\subset \psi_V^{-1}(U),$ but $\psi_V^{-1}(U)$ seems to be bigger than $\psi_V^{-1}(\phi_U^{-1}(V))$ ? I guess I must have missed some information here.","['general-topology', 'algebraic-geometry']"
3484911,Meaning of higher-order derivations in differential geometry?,"In differential geometry, a derivation is defined to be an operator $D:C^{\infty}(M)\rightarrow C^{\infty}(M)$ that is linear and satisfies the first-order product rule: $$ D(fg) = D(f)g + fD(g). $$ When I say ""second-order derivations,"" I mean operators of the form $DD'$ where $D, D'$ are derivations.
In this case, $DD'$ is linear and satisfies $$ DD'(fg) = DD'(f)g + D(f)D'(g) + D'(f)D(g) + DD'(g). $$ Questions. Are there any references that discuss these types of operators? Does anyone have an intuitive/geometric interpretation of these operators? First-order derivations can be interpreted as vector fields (or tangent vectors if we're talking about pointwise derivations). Is there an extension of this type of reasoning? Edit. It looks like my definition has in general $DD'\ne D'D$ . For example, in local coordinates let $D = \partial_{1}$ and $D' = x^{1}\partial_{2}$ . Then $$ DD' = \partial_{1}(x^{1}\partial_{2}) = \partial_{2} + x^{1}\partial_{1}\partial_{2} \ne D'D. $$ I'm not sure what definition is appropriate, actually. The above is only my attempt. Actually, the non-commutativity I just noted above is nothing new. We already know Lie brackets $[X, Y]$ can be nonzero. However, the more I play around, the more surprising nuances I seem to discover.","['reference-request', 'intuition', 'differential-geometry']"
3484930,Proof with uniform distribution and probabilty,"I have the following exercise: Some students make homework with two exercises which are graded with extremely high accuracy. The scores are $a_i, b_i \in [0, 1]$ for exercises one and two respectively. A student is â€˜among the bestâ€™ if
there is no other student with a better score in both exercises. Of course, the students do not cheat, so you can assume that the students' scores on both exercises are independent for each student. The exercises themselves have little relation to each other, so the scores a student gets to either exercise are completely independent as well. Given $n$ , the number of students, and assuming that $a_i$ and $b_i$ of each student is uniformly distributed in $[0, 1]$ , show that there are $O(\log n)$ students worthy of an award, with high probability (which means that the probability that the winners are asymptotically more than $\log n$ goes to zero quickly as $n$ goes to infinity Do you have any ideas on how to prove this?","['asymptotics', 'uniform-distribution', 'probability', 'algorithms']"
3484993,Tetrahedral dice throw,"If we threw $30$ tetrahedral dice and summed the outcomes, how many values in the    distribution would have a non-zero probability? a) If we calculate the distribution of the sum of two thrown tetrahedral dice, how many values have a non-zero probability?",['statistics']
3485027,An Incomplete Metric Space,"I am reading Kolmogorov's ""Introductory Real Analysis"" and I have come across this example of an incomplete metric space ( $C^2_{[a,b]}$ ) on page 59:
If $$\phi_n(t)= \left\{ \begin{array}{lcc}
             -1 & -1 \leq t \leq -\frac{1}{n} \\
             nt & -\frac{1}{n}\leq t \leq \frac{1}{n} \\
             1 & \frac{1}{n}\leq t \leq 1 
             \end{array}
   \right.$$ then { $\phi_n(t)$ } is a fundamental sequence in $C^2_{[-1,1]}$ , since $\\$ $\int^1_{-1}[\phi_n(t)-\phi_{n^{'}}(t)]^2dt \leq \frac{2}{{min\{n,n^{'}\}}}$ , where $C^2_{[a,b]}$ is the metric space on the set of all functions continuous on the interval [a,b], equipped with the distance function $\rho(x,y)=(\int^a_{b}[x(t)-y(t)]^2dt)^{1/2}$ . It is worth noting that 'fundamental sequence' and 'Cauchy sequence' are used interchangeably here. The problem I have is that I don't understand there this upper bound comes from and why it is chosen here. From desmos: https://www.desmos.com/calculator/mrd9tjyrup , the max distance between 2 elements only ever reaches $\frac{2}{3}$ , but the given bound $\frac{2}{{min\{n,n^{'}\}}}=2$ for ${min\{n,n^{'}\}}=1$ . Also, it is my understanding that $\int^1_{-1}[\phi_n(t)-\phi_{n^{'}}(t)]^2dt = \frac{2}{{min\{n,n^{'}\}}}$ is a consequence of the limit taken as $n^{'} \rightarrow \infty.$ Any help would be much appreciated.","['metric-spaces', 'analysis', 'real-analysis']"
3485039,Minimum number of iterations required to introduce all n people to all $n$ in groups of size s?,"I'm not sure if this is a well researched problem, I'm trying to think of a solution, it does not seem very obvious. For eg: If $n = 6$ and $s = 3$ , we can introduce everyone in $4$ iterations 1) A B C | D E F
2) A E F | D B C
3) A D E | F B C
4) A D F | E B C I don't want to figure out a scheme of grouping manually for $n = 12$ and $s = 3$ , please point me to relevant discussion or literature, if someone identifies what problem it is.","['graph-theory', 'discrete-mathematics', 'computer-science']"
3485050,Examples of Riemannian manifolds which are both complete and geodesically convex?,"What are some examples of a Riemannian manifold which is both complete and geodesically convex ?  An obvious example is $R^n$ .  An open hemisphere of $S^n$ is geodesically convex but not complete.  I don't believe hyperbolic space is geodesically convex, although I might be wrong. Edit 1: We say Riemannian manifold $M$ is geodesically convex if given any two points in $M$ , there is a unique minimizing geodesic contained within $M$ that joins those two points.","['manifolds', 'riemannian-geometry', 'differential-geometry']"
3485052,Regression to the mean - a simple question,"In my statistics book there is a following question: In studies dating back over 100 years, it's well established that regression toward the mean occurs between the heights of fathers and the heights of their adult sons. Indicate whether the following statement is true or false: Fathers of tall sons will tend to be taller than their sons. The regression to the mean suggests that sons of tall fathers will be shorter than their fathers but they would still be above average, so they would be in the group of tall sons. So it seems that tall sons would have even taller fathers (otherwise there would be no regression to the mean effect), so the answer to the question should be ""True"" in my opinion, but according to the solution sheet it should be ""False"". What is the error in my reasoning and what is the valid way to answer the question? Thank you in advance for your help.","['regression', 'descriptive-statistics', 'statistics', 'linear-regression']"
3485057,"Finding $n$ points $x_i$ in the plane, with $\sum_{i=1}^n \vert x_i \vert^2=1$, minimizing $\sum_{i\neq j}^n \frac{1}{\sqrt{\vert x_i-x_j \vert}}$","Let $x_1,..,x_n$ be points in $\mathbb R^2$ under the constraint $$\sum_{i=1}^n \vert x_i \vert^2=1.$$ So not all the points are on the circle, but their sum of the norms is constrained. I am looking for the minimizing configuration of the function $$f(x_1,..,x_n):=\sum_{i\neq j}^n \frac{1}{\sqrt{\vert x_i-x_j \vert}}$$ According to some of the first answers, it seems that we get orbits around a centre. Is there any explanation for that? Please let me know if you have any questions.","['global-optimization', 'geometry', 'real-analysis', 'multivariable-calculus', 'optimization']"
3485069,argument principle with a polynomial,"The problem is: How many zeros of the polynomial $$
f(z)=z^4+3z^2+z+1
$$ lie in the right half-plane? To solve this, we use the argument principle, $$
\text{number of zeros}=\frac{1}{2\pi i}\int_{\partial\Omega}\frac{f'(z)}{f(z)}dz.
$$ Here $$
\partial\Omega=\{z=iy, -R\leq y\leq R\}\cup\{ z=Re^{i\theta},-\frac{\pi}{2}\leq \theta\leq\frac{\pi}{2}\}.
$$ It claims that $$
\int_{-iR}^{iR}\frac{f'(z)}{f(z)}dz=0.
$$ But I don't know why above equality holds.",['complex-analysis']
3485070,"Evaluate $\iint |xy|\,dx\,dy$ using polar coordinates","If $R$ is the region bounded by $x^2+4y^2 \ge 1$ and $x^2+y^2 \le 1$ . Then find the integral $$I=\iint_R |xy|\,dx\,dy.$$ I tried using Cartesian system and got the answer as $\frac{3}{8}$ using symmetry. Can we do this in Polar coordinates?","['integration', 'calculus', 'algebra-precalculus', 'polar-coordinates']"
3485106,Bound of trace norm,"Let $\mathcal{H}$ be a separable Hilbert space with complex scalar, $T_1$ be a self-adjoint positive linear operator with finite trace norm, that is $$\|T_1\|_{tr} := \sum_i\langle T_1 e_i,e_i\rangle <\infty.$$ For another linear operator $T_2$ , if for any $e\in \mathcal{H}$ we have $$|\langle T_2 e,e\rangle|\leq \langle T_1 e,e\rangle,$$ will we have $\|T_2\|_{tr}\leq \|T_1\|_{tr}$ ?","['compact-operators', 'operator-algebras', 'operator-theory', 'trace', 'functional-analysis']"
3485122,Uniformly bounded sequence of Riemann integrable functions,"Let { $f_n$ } be a uniformly bounded sequence of Riemann int'ble functions on $[a,b]$ .If $f_n\rightarrow 0$ pointwise then does it follow that $\int _{[a,b]}f_n\rightarrow0$ ? My thoughts: The result doesn't follow from the given assumptions. To justify my claim, I choose $f_n(x)=\frac{x^2}{x^2+(1-nx)^2}$ on $[0,1]$ which satisfies all the criteria. Clearly, $f_n\rightarrow 0$ pointwise but I haven't been able to show that $\int _{[a,b]}f_n$ doesn't converge to $0$ although it's clear that it doesn't. Are there any other counter-examples to justify this result?. I came up with $f_n(x)=nx(1-x^2)^n$ on $[0,1]$ but this choice of function doesn't have the uniform boundedness. Can anybody provide me with a relatively easy example to go with?","['riemann-integration', 'pointwise-convergence', 'analysis', 'real-analysis']"
3485170,Constructing a normal variation using a given smooth function with zero mean,"Let $x_0:\Sigma^n\to\mathbb{R}^{n+1}$ be an immersion of an orientable compact $n$ -dimensional smooth manifold into the Euclidean space. It is well-known that given a smooth function $\varphi:\Sigma\to\mathbb{R}$ satisfying the zero-mean condition: \begin{align}
\int_{\Sigma}\varphi d\mu=0
\end{align} (where $d\mu$ is the area element in the induced metric), there always exist a volume-preserving normal variation $X:\Sigma\times(-\epsilon,\epsilon)\to\mathbb{R}^{n+1}$ whose variation vector field is \begin{align}
Y:=\frac{\partial X}{\partial t}\bigg|_{t=0}=\varphi\nu
\end{align} where $\nu$ is the unit normal. In Barbosa-do Carmo , the proof begins by considering a two-parameter family of immersion \begin{align}
x(t,u)=x_0+(t\varphi+ug)\nu & & (1)
\end{align} (where $g:\Sigma\to\mathbb{R}$ is any smooth function with $g\equiv 0$ on the boundary $\partial\Sigma$ and $\int_{\Sigma}gd\mu\neq 0$ ), then considers the equation \begin{align}
V(t,u)=const
\end{align} (where $V(t,u)$ is the volume of $x(t,u)$ ) and use the implicit function theorem to deduce that $u$ can be expressed as a function of $t$ in a small open neighbourhood of $0\in\mathbb{R}$ . Finally, one checks that $X(p,t)=x(t,u(t))(p)$ is the desired volume-preserving normal variation of $x_0$ . My question is the following: Instead of considering (1), why not the
  proof considers the one-parameter family \begin{align}
x(t)=x_0+t\varphi\nu & & (2) 
\end{align} of immersions? This seems to directly give the desired variation (by setting $X(p,t)=x(t)(p)$ ) and it looks simpler than (1). For one thing, a big theorem like implicit function theorem will not be needed. Is there any reason that I've failed to observe which makes it necessary to consider (2) instead of (1)? Any comment or answer is welcomed and greatly appreciated.","['calculus-of-variations', 'riemannian-geometry', 'differential-geometry']"
3485228,The condition that Euler's prime generating polynomial is a composite number,"I anticipate that the number of lattice points of a special ellipse will be equal to the number of divisors of a number represented by Euler's prime generating polynomial. Euler's prime generating polynomial: $$f(x)=x^2+x+41 \ \ \ \ \ \ \ \ x\in\mathbb{Z} $$ Special ellipse: $$X^2+163Y^2-2(2x+1)Y-1=0 \ \ \ \ \ \ \ \ \ X,Y\in\mathbb{R}$$ $$$$ For example, let $x$ be 40. Euler's prime generating polynomial: \begin{eqnarray*}
    f(40)&=&40^2+40+41\\
    &=&1681\\
    &=&41^2
\end{eqnarray*} The number of divisors of $f(40)$ is equal to 3. Special ellipse: \begin{eqnarray*}
   &X^2&+163Y^2-2(2\cdot40+1)Y-1=0\\
&X^2&+163Y^2-162Y-1=0
\end{eqnarray*} Lattice points of this special ellipse are following. $$(X,Y)=(1,0),(-1,0),(0,1)$$ The number of lattice points is equal to 3. Please watch this video https://www.youtube.com/watch?v=i5c69-A0cEk . If you find a counterexample or proof, please let me know. I assert the following theorem related to this problem. Theorem 1. $ \forall x, \alpha \in \mathbb{N}, \alpha \neq 1$ , The equation $$x=Yy^2+(Y+1)y+Y\alpha$$ has rational solution $y$ and
natural number solution $Y$ $\Rightarrow$ $x^2+x+\alpha$ is a composite number. Proof. We express the two rational solutions as following: $$y=\frac{n_1}{m_1},\frac{n_2}{m_2},\ \ \ \ where \ m_i\in\mathbb{N},\ n_i\in\mathbb{Z},\ gcd(m_i,n_i)=1,\ (i=1,2)$$ From the factor theorem and $gcd(Y,Y+1)=1$ , we can get the following relation. $$(m_1y-n_1)(m_2y-n_2)=Yy^2+(Y+1)y+Y\alpha-x$$ $$m_1m_2y^2-(m_1n_2+m_2n_1)y+n_1n_2=Yy^2+(Y+1)y+Y\alpha-x$$ Hence \begin{eqnarray*}
   m_1m_2 &=& Y \\
   -(m_1n_2+m_2n_1) &=& Y+1 \\
   n_1n_2 &=& Y\alpha-x
\end{eqnarray*} So we can get $$x=m_1m_2\alpha-n_1n_2$$ $$m_1n_2+m_2n_1+m_1m_2=-1.$$ We combine the two equation as following: $$x=\frac{n_1n_2-m_1m_2\alpha}{m_1n_2+m_2n_1+m_1m_2}$$ We enter this $x$ into $x^2+x+\alpha$ and calculate the factorization. We can get $$x^2+x+\alpha = \frac{(n_1^2+m_1n_1+\alpha m_1^2)(n_2^2+m_2n_2+\alpha m_2^2)}{(m_1n_2+m_2n_1+m_1m_2)^2}.$$ Since $\ m_1n_2+m_2n_1+m_1m_2=-1$ , $$x^2+x+\alpha = (n_1^2+m_1n_1+\alpha m_1^2)(n_2^2+m_2n_2+\alpha m_2^2).$$ So $x^2+x+\alpha$ is a composite number. $$\tag*{$\square$}$$ Since $y=\frac{-Y-1 \pm \sqrt{(1-4\alpha)Y^2+2(2x+1)Y+1}}{2Y}$ , we can get a condition from Theorem 1. Lemma. $\forall x,\alpha \in \mathbb{N}$ , The ellipse $$X^2 = (1-4\alpha)Y^2+2(2x+1)Y+1, \ \ \ \ \ \ Y>0$$ has
lattice points $(X,Y)$ . $\Rightarrow$ $y$ is a rational number. If $Y=0$ is allowed, the ellipse has always $(X,Y) = (\pm 1,0)\ \ $ (trivial lattice points). Hence, the following assertion is correct. Theorem 2. $\forall x,\alpha \in \mathbb{N}, \alpha \neq 1$ , The ellipse has one or more non-trivial lattice points. $\Rightarrow x^2+x+\alpha$ is a composite number. The following conjecture is unresolved. Conjecture. $\forall x \in \mathbb{N} ,\ \forall \alpha \in \{3,5,11,17,41\} $ , The ellipse has only trivial lattice points. $\Leftrightarrow x^2+x+\alpha$ is a prime number. (The ellipse has one or more non-trivial lattice points. $\Leftrightarrow x^2+x+\alpha$ is a composite number.) If this conjecture is correct , the number of lattice points and the number of divisors are equal.","['algebraic-number-theory', 'number-theory', 'polynomials', 'quadratics', 'prime-numbers']"
3485229,"When should I take conjugate transpose of a complex matrix, and when transpose of it?","I was taking the inverse of $$A=\begin{bmatrix}
2+i &1 \\ 
 1&-2+i 
\end{bmatrix}$$ and $\det(A)=-6 $ , and cofactor matrix $$C=\begin{bmatrix}
-2+i &-1 \\ 
 -1&2+i 
\end{bmatrix}$$ such that correct way to do it is $$A^{-1}=\frac{1}{\det(A)}C^{T}$$ but I'm wondering why we are not taking conjugate transpose of C?","['matrices', 'hermitian-matrices', 'linear-algebra', 'inverse', 'transpose']"
3485268,Recovering metric from Laplace-Beltrami operator,"On a Riemannian manifold $(M, g)$ , if one is given an oracle $O$ that allows one to evaluate the Laplace-Beltrami operator, how can we recover the metric $g$ ? More precisely, $O: (M \rightarrow \mathbb R) \rightarrow \mathbb R$ , $O(f) \equiv \Delta f = \frac{1}{\sqrt{|g|}} \partial_i (\sqrt{|g|} g^{ij} \partial_j f)$ . We are allowed to pick any number of functions $f$ to evaluate against the oracle $O$ . We do not know the symbolic expression for either $g$ or $\Delta$ . As far as I can tell, the problem is by by using $O$ , we can only access the components of the metric under a $\partial_i$ . I'm at a loss on how to ""recover"" the metric $g$ from $\partial_i (\cdots g^{ij} \cdots)$ .","['laplacian', 'riemannian-geometry', 'differential-geometry']"
3485328,Proving $\phi : \mathbb{R}\rightarrow \mathbb{R}$ with a property is uniformly continuous.,"$\phi : \mathbb{R}\rightarrow \mathbb{R}$ is a function with the property that whenever a sequence $f_n : \mathbb{R}\rightarrow\mathbb{R}, n=1,2,...$ converges uniformly, so does $\phi\circ f_n$ . Show $\phi$ is uniformly continuous. Attempt) Suppose $\phi$ is not uniformly continuous. Then there is an $\varepsilon>0$ such that for every $\delta>0$ , there exist $x,y\in\mathbb{R}$ with $\mid x-y\mid<\delta$ but $\mid\phi(x)-\phi(y)\mid\geq\varepsilon$ . So for $n=1,2,...$ , there exist $x_n,y_n$ such that $\mid x_n-y_n\mid<\frac{1}{n}$ but $\mid\phi(x_n)-\phi(y_n)\mid\geq\varepsilon$ . I am trying to find a uniformly convergent sequence $f_n$ for which $\phi\circ f_n$ does not converge uniformly to draw a contradiction.","['uniform-continuity', 'real-analysis', 'functions', 'uniform-convergence', 'sequences-and-series']"
3485403,If $P_X=P_Y$ then $\mathbb{E}[X]=\mathbb{E}[Y]$,"Let $X$ and $Y$ be real integrable random variables on $(\Omega, \mathcal{A},P)$ . I want to show, that if $P_X:=P\circ X^{-1}=P_Y$ we have $\mathbb{E}[X]=\mathbb{E}[Y]$ . Proof : I need the following Lemma : Let $(\Omega, \mathcal{A})$ and $(\Omega',\mathcal{A}')$ be measurable spaces, let $\mu$ be a measure on $(\Omega,\mathcal{A})$ and let $X\colon \Omega\rightarrow\Omega'$ be measurable. Then let $\mu'=\mu\circ X^{-1}$ be the pushforward measure. Assume that $f\colon\Omega'\rightarrow \overline{\mathbb{R}}$ is $\mu'$ integrable. Then $f\circ X\in\mathcal{L}^1(\mu)$ and $$\int(f\circ X)\,\mathrm{d}\mu=\int f\,\mathrm{d}(\mu\circ X^{-1})$$ Now suppose $P_X=P_Y$ , then $$\int f\circ X\,\mathrm{d}P=\int f\,\mathrm{d}(P\circ X^{-1})=\int f\,\mathrm{d}P_X=\int f\,\mathrm{d}P_Y=\int f\circ Y\,\mathrm{d}P$$ If I could somehow conclude that we then must have $f\circ X=f\circ Y$ a.s. I could finish, because then we could just have picked a bijective integrable $f$ and could obtain $X=Y$ a.s and therfore reach the conclusion. Is there a possibility to save this proof? Moreover, I suppose that there must be a much simpler argument, since this is not even proven in my book. I am not sure such a lemma is needed.","['measure-theory', 'probability-theory']"
3485412,A valid proof for the invariance of domain theorem?,"The invariance of domain theorem states that, given an open subset $U\subseteq \mathbb{R}^n$ and an injective and continuous function $f:U\rightarrow\mathbb{R}^n$ then $f$ is a homeomorphism between $U$ and $f$'s image. I tried proving it by using another theorem: if $g:K\rightarrow X$ is injective and continuous, $K$ is compact and $X$ is Hausdorff then $g$ is a homeomorphism between $K$ and $f(K)$. But I'm not sure on how to prove this (sub)-theorem? or perhaps there exists an easier proof of the invariance of domain theorem?","['general-topology', 'algebraic-topology']"
3485414,How can I solve this equation in $\mathbb Z$?,"$x^{2}+16x+55=3^{y^{2}-2y}$ Could you tell me how to solve this equation, please?
I tried to draw the graphic of the functions but I didn't see how to solve it.","['algebra-precalculus', 'integers']"
3485420,Smallest non-affine scheme. Is this correct?,"Let $X:=\{p,q_1, q_2\}$ be a topological space with topology $\mathcal{T}:=\{\emptyset, \{p\}, \{q_1,p\}, \{q _2, p\}, X\}$ . Define a sheaf $\mathcal{O}$ by $$\mathcal{O}(\emptyset) := \{0\}, \quad  \mathcal{O}(\{p\}) := k(x), \quad  \mathcal{O}(\{p, q_1\})= \mathcal{O}(\{p, q_2\}) = \mathcal{O}(X) := (k[x])_{(x)}$$ with the evident restritions morphisms. Then is it true that? $$\mathcal{O}_p \cong k(x), \quad \mathcal{O}_{q_1} \cong \mathcal{O}_{q_2} \cong  (k[x])_{(x)} $$ Attempt: Yes, it is true, for example every element of the stalk $\mathcal{O}_p$ has a unique representant of the form $(\{p\}, f)$ with $f \in k(X)$ and we see that the multiplication of such classes is exactly the same multiplication of the field $k(x)$ . More formally, $$ k(x) \to \mathcal{O}_p: f \mapsto [(f,\{p\})] $$ is an isomorphism of rings. Is this correct?","['ring-theory', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
3485428,"Spectrum of $-\frac{d^2}{dx^2}$ with respect to space of continuous periodic functions on $[0,2\pi]$","Let $\mathcal{B}$ denote the Banach space of all continuous functions $f: [0,2\pi] \to \mathbb{C}$ such that $f(0) = f(2\pi)$ . Let $A$ denote the operator $$Af = -f'', \qquad \text{Dom}(A) = \{ f \in \mathcal{B} : f \in C^2[0,2\pi] \}.$$ I would like to find the spectrum of $A$ . So far, I've been trying to compute the spectrum by hand, and I conjecture that $\text{spec}(A)$ is $\{n^2 : n = 0,1, 2, \dots\}$ . We get one inclusion simply by noticing that, for each $n = 0, 1, 2, \dots$ , $n^2$ is an eigenvalue of $A$ with periodic eigenfunction $e^{inx}$ . Showing the other inclusion is where I have gotten stuck. By factoring $$-\frac{d^2}{dx^2}- \lambda^2 = (D_x - \lambda)(D_x + \lambda), \qquad D_x = \frac{1}{i} \frac{d}{dx}, \, \lambda \neq 1, 2, \dots $$ and using the integrating factor method twice, we find that the solution $u$ to the equation $$(A - \lambda^2)u = f \in \mathcal{B},$$ is given by $$u(x) = c_2 e^{-i\lambda t} + \frac{c_1}{i2\lambda}e^{i\lambda t} + F(x), $$ for some $c_1, c_2 \in \mathbb{C}$ and where $$F(x) = \int_0^x e^{i2\lambda t} \int^s_0 e^{-i\lambda t} f(t) dt ds.$$ So the above expression for $u$ is our proposed formula for $(A - \lambda^2)^{-1}f$ , but it remains to show that $(A - \lambda^2)^{-1}$ is bounded and that $u$ can indeed be made periodic. Requiring that $u$ be periodic gives rise to a linear system to solve for $c_1$ and $c_2$ . It appears this system has a unique solution unless $\lambda$ is an integer or half-integer. So, it may be that the spectrum consists of more than eigenvalues above. But I'm not sure how to decide if the half-integers are indeed in the spectrum or not. Hints or solutions are greatly appreciated!","['spectral-theory', 'functional-analysis', 'ordinary-differential-equations']"
3485484,What is the geometric difference between partial derivative and ordinary derivative?,"Ordinary derivative of a function let $~y=f(x)~$ represents the slope of the tangent drawn at the point $~x~$ to the curve $~f(x)~$ . But, what about partial derivative ? Please, attach images if possible for understanding.","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3485501,What is an example of a complex function with a zero of infinite order (other than the zero map $z \to 0$)?,"I can't find any example other than the zero map which may very well be because there isn't any other. From Taylor's theorem, it seems obvious that the only possible example is the zero map, since the only power series with only zero coefficients is zero.  Is this correct? (The order of a zero is defined here .)",['complex-analysis']
3485512,Derivative of $\sec^{-1}x$ and integral of $\frac{1}{x\sqrt{x^2-1}}$,"My attempt is as follows:- Derivative of $\sec^{-1}x$ Let $\theta=\sec^{-1}x,$ where $\theta\in [0,\pi]-{\dfrac{\pi}{2}}.$ $$\sec\theta=x.$$ Differentiating both sides with respect to $x:$ $$\sec\theta\cdot\tan\theta\cdot\dfrac{\mathrm d\theta}{\mathrm dx}=1\\
\dfrac{\mathrm d\theta}{\mathrm dx}=\dfrac{1}{x\sqrt{x^2-1}}.$$ As $\sec^{-1}x$ is a strictly increasing function, its derivative should be positive, hence we write $x$ as $|x|$ to ensure that $\dfrac{\mathrm d\theta}{\mathrm dx}$ will not be negative if $x$ is negative. But I wonder why I didn't get $\dfrac{\mathrm d\theta}{\mathrm dx}=\dfrac{1}{|x|\sqrt{x^2-1}}$ in the above calculation? Integral of $\dfrac{1}{x\sqrt{x^2-1}}$ Case $1:x>0$ Then the integral is definitely $\sec^{-1}x.$ Case $2: x<0$ Then the integral is $-\sec^{-1}x.$ But many textbooks write that $\displaystyle\int\frac{1}{x\sqrt{x^2-1}}\,\mathrm dx=\sec^{-1}x+C.$ Shouldn't $\displaystyle\int\frac{1}{|x|\sqrt{x^2-1}}\,\mathrm dx=\sec^{-1}x+C\:?$ What am I missing here?","['integration', 'calculus', 'derivatives']"
3485525,A strange proof of Glivenko-Cantelli with Dini,"The following is an excerpt from John Walsh's Knowing the Odds and it concerns the Glivenko-Cantlli theorem. The proof first derives the convergence for all rationals and then appeals to Dini's theorem for the uniform convergence part, given that $F^0$ and $F_n^{0}$ are nondecreasing. My question is: how is Dini's theorem applicable here? The version of which I am aware, see for example wikipedia , requires that the functions $F_n^{0}$ are continuous and satisfy $F_n^{0}(x) \leq F_{n+1}^{0}(x)$ , neither of which is satisfied here. Am I misunderstanding something?","['probability-limit-theorems', 'probability-theory']"
3485553,prove smoothness of multivariable function,"I am trying to do Exercise 2.66 in Jeffrey Lee's book on differential manifolds. There is one step that escapes me, and I think it reduces to the following problem. Let $g:U\subset\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$ be a continuous function, where $U$ is an open and connected neighbourhood of $\mathbb{R}^{n}$ . Assume that $$x\rightarrow\sum_{i=1}^{n}g_{i}(x)\frac{\partial{}f}{\partial{}x_{i}}(x)$$ is smooth (infinitely differentiable) for all smooth $f:U\subset\mathbb{R}^{n}\rightarrow\mathbb{R}$ . Show that $g$ is smooth.","['multivariable-calculus', 'differential-geometry']"
3485563,"For regular tetrahedron $ABCD$ with center $O$, and $\overrightarrow{NO}=-3\overrightarrow{MO}$, is $NA+NB+NC+ND\geq MA+MB+MC+MD$?","Let $ABCD$ be a regular tetrahedron with center $O.$ Consider two points $M,N,$ such that $\overrightarrow{NO}=-3\overrightarrow{MO}.$ Prove or disprove that $$NA+NB+NC+ND\geq MA+MB+MC+MD$$ I tried to use CS in the Euclidean space $E_3$ , but it does not help, because the minoration is too wide.","['contest-math', 'euclidean-geometry', 'geometry', 'geometric-inequalities', 'geometric-transformation']"
3485635,proving inverse of gradient operator,"I'm trying to prove the inverse of the gradient operation ( $\nabla V$ ): $\vec{E} = \nabla V$ is the line integral operation: $\int\vec{E}\bullet d\vec{\mathcal{l}} = V$ Here's my work: $\vec{E} = \nabla V$ take the line integral of both sides: $\int\vec{E}\bullet d\vec{\mathcal{l}} = \int \nabla V\bullet d\vec{\mathcal{l}}$ then for some reason i don't fully understand, right hand side becomes equal to V: $\int\vec{E}\bullet d\vec{\mathcal{l}} = V$ I guess my question is this.  why does: $\int \nabla V\bullet d\vec{\mathcal{l}} = V$ ?","['multivariable-calculus', 'vector-analysis']"
3485652,Cardinal of the set of all subsets of $\mathbb N$ such that both $A$ and the complement are infinite,Given $M=\{ A \in P( \mathbb{N} ) \mid A\text{ and }   \overline{\rm A}\text{ are infinite} \}$ What is the cardinal of set $M$ ? I thought to find the cardinal of $\{ A \in P( \mathbb{N} ) \mid A\text{ finite}\}$ and cardinal of $\{ A \in P( \mathbb{N} ) \mid  \overline{\rm A}\text{ finite}\}$ But can't see how it helps. Thanks,['elementary-set-theory']
3485696,Mapping $\sigma$-fields to $L^2$,"Let $(\Omega,\mathcal A, P)$ be a probability space, and let $\Sigma$ be the set of sub $\sigma$ -fields of $\mathcal A$ , that is, $$
\Sigma = \{\mathcal F \subset \mathcal A:\; \mathcal F \; \text{is a $\sigma$-field} \}.
$$ For $\mathcal F \in \Sigma$ , let $L^2(\mathcal F)$ be the space of equivalence classes of random variables that are $\mathcal F$ -measurable and have a finite second moment. We know that $L^2(\mathcal F)$ is closed linear subspace of $L^2(\mathcal A)$ , the latter viewed as a Hilbert space with the usual $L^2$ norm. Let $\text{Lin}(L^2(\mathcal A))$ be the set of all closed linear subspaces of $L^2(\mathcal A)$ . Now consider the map $\mathcal F \mapsto L^2(\mathcal F)$ . Is this map a bijection from $\Sigma$ to $\text{Lin}(L^2(\mathcal A))$ ?","['hilbert-spaces', 'measure-theory', 'probability-theory']"
3485697,"If $A$ is a Borel set and $\overline A\setminus A$ is a null set, can we embed $L^p(A)$ into $L^p(\overline A)$?","Let $p\ge1$ and $A\in\mathcal B(\mathbb R)$ and assume that $N:=\overline A\setminus A$ is a Leesgue null set. Can any function $f\in\mathcal L^p(A)$ be extended to a function $g\in\mathcal L^p(\overline A)$ ? Since $N\in\mathcal B(\mathbb R)$ , $$g(x):=\left.\begin{cases}f(x)&\text{, if }x\in A\\0&\text{, otherwise}\end{cases}\right\}\;\;\;\text{for }x\in\overline A$$ should be piecewie Borel measurable, hence Borel measurable. And since $N$ is a Lebesgue null set, $\left\|g\right\|_{L^p(\overline A)}=\left\|f\right\|_{L^p(A)}$ . Am I missing something? Remark : The question came to my mind as I've noticed that a function $f:[a,b]\to\mathbb C$ is called absolutely continuous if there is a $h\in L^1((a,b))$ with $f(x)=f(a)+\int_0^xh(y)\:{\rm d}y$ for all $x\in[a,b]$ and it seems akward to me why one is explicitly assuming that $h$ is defined on the open interval $(a,b)$ and not $h\in L^1([a,b])$ . Is there anything I'm missing? Even uniqueness (in an ""almost everywhere"" sense) shouldn't be a problem, since $\{a,b\}$ is a null set.","['measure-theory', 'lp-spaces', 'functional-analysis']"
3485718,Expressing associativity with only two variables,"I'm wondering if it is possible to axiomatize associativity using a set of equations in only two variables. Suppose we have a signature consisting of one binary operation $\cdot$ . Is it possible to find a set $\Sigma$ of equations containing only variables $x$ and $y$ , such that the equational theory generated by axioms $\Sigma$ is equal to the equational theory generated by axiom $(x\cdot y)\cdot z = x\cdot (y\cdot z)$ ? Or in other words, such that the variety defined by equations $\Sigma$ is equal to the variety defined by equation $(x\cdot y)\cdot z = x\cdot (y\cdot z)$ ? EDIT: We can take as $\Sigma$ the set of all equations in variables $x$ and $y$ that are entailed by equation $(x\cdot y)\cdot z = x\cdot (y\cdot z)$ . For example $(x\cdot y)\cdot x = x\cdot (y\cdot x)$ is one of the many equations contained in $\Sigma$ . The question is whether $\Sigma$ in turn entails $(x\cdot y)\cdot z = x\cdot (y\cdot z)$ . EDIT2: As per Milo Brandt's comment, for any three terms $p(x,y)$ , $q(x,y)$ , $r(x,y)$ containing at most variables $x, y$ , equation $p\cdot (q\cdot r)=(p\cdot q)\cdot r$ is in $\Sigma$ . Thus, for any algebra $A$ in the variety defined by equations $\Sigma$ , every subalgebra of $A$ generated by two elements is associative. So, in a sense, $A$ is ""locally associative"".","['universal-algebra', 'model-theory', 'logic', 'abstract-algebra', 'associativity']"
3485736,Solving $\frac{\ln(x)\ln(y)}{\ln(1-x)\ln(1-y)}=1$ for $y$,I'm trying to solve for $y$ in terms of $x$ for the expression below. $$\frac{\ln(x)\ln(y)}{\ln(1-x)\ln(1-y)}=1$$ First I multiplied both sides by $$ \frac{\ln(1-x)}{\ln(x)} $$ to get $$ \frac{\ln(y)}{\ln(1-y)}=\frac{\ln(1-x)}{\ln(x)} $$ but I don't see how to isolate $y.$ I tried using every technique I know including logarithm properties.,['algebra-precalculus']
3485755,Remainder Theorem Question: Deduce the Polynomial Given the Remainder,"The question states: Find $m$ and $n$ for the polynomial $x^2+mx+n$ when the polynomial is divided by $(x-m)$ , the remainder is $m$ , and when the polynomial is divided by $(x-n)$ , the remainder is $n$ . I essentially started with the remainder theorem: $$\frac{p(x)}{x-m} = f(x)+\frac{m}{(x-m)}$$ $$\frac{p(x)}{x-n} = g(x)+\frac{n}{(x-n)}$$ where $f(x)$ and $g(x)$ are quotients. This expands to: $$p(x)=(x-m)f(x)+m$$ $$p(x)=(x-n)g(x)+n$$ However, I cannot from this information deduce the values of $m$ and $n$ . Any help would be appreciated.","['algebra-precalculus', 'polynomials', 'divisibility']"
3485765,Expectation as expectation of indicator in Hoeffding Identity,"I am confused by a step in the proof of the Hoeffding identity as provided in the book by Denuit, Dhaene, Goovaerts and Kaas . The following is a screen shot of the beginning of the proof: I am confused about the transition from the second last to last step here. If $X$ was a non-negative random variable, then it follows that $$
\mathbb{E}X = \mathbb{E}\left ( \int_0^{\infty} 1_{u \le X} du \right )
$$ but the result here seems to hold for non-negative random variables. A similar question was asked here , but the accepted solution is just for the non-negative case, unless I have missed something. I'm looking for a clear justification of the last step highlighted in red.","['statistics', 'covariance', 'expected-value', 'probability-theory', 'probability']"
3485772,A sequence with no converging subsequence that clusters everywhere,"Let $I = [0,1]$ be the compact unit interval and $T = I^I$ the Tychonoff cube. It is pretty standard to exhibit a sequence in $T$ with no convergent subsequence. It is also fairly standard to show that $T$ is separable (e.g. the polynomials with rational coefficients are dense). A simple cardinality argument can be used to show that this sequence of polynomials has cluster points which are not the limit of any of its subsequences. Now, I believe, but cannot prove, that we may be able to exhibit a sequence in $T$ that has no convergent subsequence, but that its closure is all of $T$ . In particular, I am interested constructing such a sequence $(f_n(t))_{n=1}^\infty$ and for each point $f \in T$ exhibiting a subnet of $(f_n(t))_{n=1}^\infty$ that converges to $f$ . Any ideas?","['general-topology', 'sequences-and-series', 'product-space', 'real-analysis']"
3485803,Tangent space of embedding of $\mathsf{U}(n)$ in $\mathsf{SO}(2n)$,"The realification map $\varphi:\mathbb{C}^{n\times n}\rightarrow\mathbb{R}^{2n\times 2n}$ given by $$Z=A+iB\mapsto\begin{bmatrix}
A & -B\\
B & A
\end{bmatrix}$$ provides an embedding of $\mathsf{U}(n)$ in $\mathsf{SO}(2n)$ . It can be shown that $\varphi \mathsf{U}(n)=\mathsf{SO}(2n)\cap\varphi \mathsf{GL}(n,\mathbb{C})$ (I found this result in a textbook). I am wondering if the orthogonal projection $$\pi_{\varphi U}:\mathbb{R}^{2n\times 2n}\rightarrow\mathsf{T}_{\varphi U}\varphi \mathsf{U}(n):X\mapsto\pi_{\varphi U}X$$ where $U\in\mathsf{U}(n)$ , restricted to $X\in\varphi\mathsf{GL}(n,\mathbb{C})$ , is equal to the orthogonal projection $$\Pi_R:\mathbb{R}^{2n\times 2n}\rightarrow\mathsf{T}_R\mathsf{SO}(2n):X\mapsto (X-X^T)R,$$ restricted to $X\in\varphi\mathsf{GL}(n,\mathbb{C})$ (assuming $R=\varphi U$ )? Attempt: I can show that $\Pi_R$ maps $\varphi\mathsf{GL}(n,\mathbb{C})$ to $\mathsf{T}_{\varphi U}\varphi \mathsf{U}(n)$ (details omitted). Assume there is an $X\in\mathbb{R}^{2n\times 2n}$ such that $\pi_{\varphi U}X\neq\Pi_RX$ , where $R=\varphi U$ . If one of $\|\Pi_RX-X\|$ and $\|\pi_{\varphi U}X-X\|$ is strictly smaller than the other, then this yields a contradiction: If $\|\pi_{\varphi U}X-X\|$ is smallest then this contradictions $\Pi_R$ being the orthogonal projection on $\mathsf{T}_R\mathsf{SO}(2n)$ and vice versa. It follows that $\|\Pi_RX-X\|=\|\pi_{\varphi U}X-X\|$ . Hence both $\pi_{\varphi U}$ and $\Pi_R$ satisfy the condition of being orthogonal projections on $\varphi \mathsf{U}(n)$ , and by the uniqueness of orthogonal projections on convex sets (tangent spaces are convex), the projections must be equal. PS This is a follow-up question to my previous unanswered question (this not a repost since the question has changed): Embedding of $U(n)$ in $SO(2n)$","['solution-verification', 'lie-groups', 'differential-geometry']"
3485812,"Prove that limit $a_n^{b_n} = 0$ when $\lim_{n\to\infty} a_n = 0$, $\lim_{n\to\infty} b_n = \infty$","As $n$ goes to infinity: $\lim_{n\to\infty} a_n = 0$ , $\lim_{n\to\infty}b_n = \infty$ I need to prove that $\lim_{n\to\infty}a_n^{b_n} = 0$ .
Is it enough to say that from a curtain point $|a_n| < 1$ and thus $lim_{a_n^{b_n}} = 0$ because $b_n$ is greater than $1$ from a curtain point?",['limits']
3485847,Proof for showing linear independence,"Very recently I started studying proof based linear algebra on my own and I am having a difficulty because there is no one to tell me whether if my proof is right or wrong. Please keep in mind that this is my first time dealing with proofs. The question is the following: Let a system of vectors $v_1, v_2 ... v_r$ be linearly independent but not generating.
Show that it is possible to find a vector $v_{r+1}$ such that the system $v_1, v_2, \dots, v_r, v_{r+1}$ is linearly independent. Hint: Take for $v_{r+1}$ any vector that cannot be represented as a linear combination of $v_1,v_2,\dots, v_r$ and show that the system $v_1, v_2, \dots, v_r, v_{r+1}$ is linearly independent. My attempt:
question says $v_1,\dots,v_r$ is linearly independent so it has trivial coordinates $a_k$ . $a_1v_1 + a_2v_2 + \dots + a_rv_r = 0; a_1=a_2=\dots=a_r=0$ I add $v_{r+1}$ to the set $\{v_1,v_2,\dots,v_r\}$ and see if they can form linear independence. $a_1v_1 + a_2v_2 + \dots + a_rv_r + a_{r+1} v_{r+1} = 0$ but $a_1=a_2=\dots=a_r=0$ so $a_{r+1} v_{r+1} = 0$ is true if $a_{r+1} = 0$ (which makes it linear independent) as long as $v{r+1}$ is not the $0$ vector. Therefore, there is a $v_{r+1}$ that makes a system $\{v_1,v_2,\dots,v_{r+1}\}$ linearly independent. My proof ends here. **Extra question: In the beginning, it says system of vectors given are linearly independent but not generating. Those this mean it has basis but not all of the basis? Like if the space was R^3, then only 2 or 1 out of 3 basis are in the system?","['solution-verification', 'linear-algebra']"
3485883,"$f:[0,1] \rightarrow \mathbb{R}$ is continuous. What is the value of $\int_{0}^{1} \int_{x}^{1-x} f(y) d y d x ?$ Use Fubini's theorem","Suppose $f:[0,1] \rightarrow \mathbb{R}$ is continuous. What is the value of $\int_{0}^{1} \int_{x}^{1-x} f(y) d y d x ?$ Again, do not forget to justify any use of Fubini's Theorem. My attempt.
I evaluated by the calculator that $\int_{0}^{1} \int_{x}^{1-x} f(y) d y d x=0.$ When we make the variable change $u=1-x, x=0, u=1, x=1, u=0, d u=-d x \int_{0}^{1} \int_{x}^{1-x} f(y) d y d x$ $=\int_{1}^{0} \int_{1-u}^{u} f(y) d y(-d u)=\int_{1}^{0} \int_{u}^{1-u} f(y) d y d u=-\int_{0}^{1} \int_{u}^{1-u} f(y) d y d u$ Then, I couln't continue, can you help? Thanks...","['multivariable-calculus', 'calculus', 'proof-writing', 'real-analysis']"
3485903,Prove that $f'(x) \to 0$ as $x \to \infty$ when $f'+f''$ is bounded abve.,"I am given $f \in C^2([0,\infty))$ and $\lim_{x \to \infty}f(x) = L
 \in \mathbb{R}$ . I am also given there is a real number $M$ such that $f'(x) + f''(x) < M$ for all $x \in [0,\infty)$ . Prove that $\lim_{x
 \to \infty}f'(x) = 0$ . My thoughts This is similar to a frequently asked question: If $\lim_{x \to \infty}f(x) = L$ then if $\lim_{x \to \infty} f'(x)= L'$ exists it is necessary that $L' = 0$ . Possible approaches are: (1) Originally I thought to show upper bound on $f' + f''$ along with $f(x) \to L$ guarantees that the limit of $f'$ exists. but I just realized the function $f(x) = \sin(x^2)/x$ is a counterexample. (2) Somehow use the Taylor expansion $f(y) = f(x) + f'(x)(y-x) + \frac{1}{2} f''(\xi)(x-y)^2$ ( $\xi \in (x,y)$ ). Here I am having difficulty tying $f'$ and $f''$ together to use the bound.",['real-analysis']
3485912,Proof of integrability,"The question states: Suppose $f$ is founded on $[a,b]$ . Suppose also that $f$ is integrable on every closed interval $[c,d]$ contained in the open interval $(a,b)$ . Show that $f$ is integrable on $[a,b]$ . So there are two possible courses of action. Either I can attempt to prove that $f$ must be piecewise monotonic on $[a,b]$ by proving that it is monotonic on every open subinterval, or I can attempt to write a proof via the Riemann criterion. I tried the former idea, but all I know is that $f$ is monotonic on every open subinterval of every [c,d], but I do not know how to bridge the gap between [c,d] and [a,b], despite trying to create a statement of the form $a<c<d<b$ and then finding $a$ and $c$ within $\epsilon$ of each other, and similarly for $b$ and $d$ . Trying to prove it using the Riemann criterion, I struggle to find good functions $s$ and $t$ to use. The textbook has not introduced limits or continuity yet, nor has it introduced the FTOC. So I must rely solely on basic analytical results involving the Riemann Criterion for the most part. Finally, I am not looking for a full proof but rather somewhat of an outline/hint as to how I can proceed.","['integration', 'calculus', 'riemann-integration', 'real-analysis']"
3485929,"Prove that there exists a polynomial p(x) with coefficients belonging to the set {-1, 0, 1} such that p(3) = n, for some positive integer n","Prove that there exists a polynomial p(x) with coefficients belonging to the set {-1, 0, 1} such that p(3) = n, for some positive integer n. I started off my proof by noticing that n = either 3k or 3kÂ±1 and that $p(x) = a_0+a_1x+a_2x^2+\cdots+a_nx^n$ . It follows that $p(3) = a_0+3a_1+3^2a_2+\cdots+3^na_n$ . Thus $p(3) = a_0+3(a_1+3a_2+\cdots+3^{n-1}a_n)$ . We know that $a_0= -1,0 \text{ or }1$ . Thus there exists a polynomial p(x) such that p(3)=3k, or 3kÂ±1 = n. q.e.d. Any help would be greatly appreciated. This is also my first time asking a question on this website so I apologize for my sloppy MathJAX skills.","['elementary-number-theory', 'solution-verification', 'polynomials', 'discrete-mathematics']"
3485941,Integral $\int {1\over x^2+8x-3}\quad dx$,"I am looking for a solution/explanation as to how to solve the following integral (sorry I am not familiar with the math language used here); $$\int {1\over x^2+8x-3}\quad dx$$ I solved this problem a couple times and got the solution; $$\frac{-19}{\sqrt{19}}\text{ln}\left|\frac{x+4+\sqrt{19}}{x^2+8x-3}\right|$$ I am fairly confident in this solution, however, symbolab and wolframalpha disagree. I am not sure if this is simply an alternate form of the solution or if it is incorrect altogether. I began solving the problem by completing the square and making the substitution $x+4=\sqrt{19}\sec(\theta)$ and $dx=\sqrt{19}\sec(\theta)\tan(\theta)$ . From here I was able to pull out the constant $\frac{\sqrt{19}}{19}$ , cancel out a $\tan(\theta)$ and was left with he constant times the integral of $\frac{\sec(\theta)}{\tan(\theta)}$ . This simplifies to $\csc(\theta)$ . I integrated this with the ""multiply by $1/1$ "" method and used the substitution $u=\csc(\theta)+\cot(\theta)$ and $-du=\csc^2(\theta)+\csc(\theta)\cot(\theta)$ . After solving, replacing my substitution, and using the trig identity, $x+4=\sqrt{19}\sec(\theta)$ , I got my answer.
If anyone could help me determine if this answer is a correct form or how to solve it correctly it would be much appreciated. Again, sorry for the math formatting.","['integration', 'calculus', 'trigonometry']"
3485956,Solving the integrand $\frac{x^3}{\sqrt{x^2+10x+16}}$,"I just wanted to make sure that what I did to integrate $\frac{x^3}{\sqrt{x^2+10x+16}}$ is correct. I assumed that it is classified as a trigonometric substitution problem. And so, what I first did is to apply ""completing the square"": $\int \frac{x^3 dx}{\sqrt{x^2+10x+16}} = \int \frac{x^3 dx}{\sqrt{x^2+10x+25+16-25}} = \int \frac{x^3 dx}{\sqrt{(x+5)^2-9}}
$ After that, I assigned values into some variables: let $a = 3 $ $ x + 5 = 3 \sec \Theta \rightarrow \sec \Theta = \frac{x+5}{3} $ $ dx = 3 \sec   \Theta \tan \Theta\, d \Theta$ Next, I have substituted the value of (x+5) to $\sqrt{(x+5)^2-9}$ which leads to $3 \tan \Theta$ . And, $\tan \Theta$ is equal to $\frac{\sqrt{x^2+10x+16}}{3}$ . Afterwards, I have replaced all of the variables to the values that I assigned to them: $\int \frac{x^3}{\sqrt{x^2+10x+16}} \rightarrow \int \frac{(3 \sec \Theta)^3 (3 \sec \Theta \tan \Theta)\, d\Theta}{3 \tan \Theta} \rightarrow \int (3 \sec\Theta - 5)^3 \sec\Theta\, d \Theta$ Expanding the trinomial, distributing $\sec \theta$ to each term and applying the constant theorem will result to: $27\int \sec^4\Theta d\Theta - 135\int sec^3\Theta\, d\Theta + 225 \int sec^2\Theta d\Theta - 125 \int sec \Theta d \Theta$ Now, by making $\sec^2 \Theta$ into $(1 + \tan^2 \Theta)$ and applying u-substitution: $27 \int \sec^4 \Theta \,d\Theta \rightarrow 27 \tan \Theta + 9 \tan^3 \Theta + C$ By applying integration by parts, $\int \sec^3 \Theta\, d\Theta$ would become $\frac{\sec\Theta tan\Theta + \ln\left | \sec\Theta + \tan\Theta \right |}{2}$ . Finally, $\int \sec^2 \Theta\, d\Theta$ would simply become $\tan \Theta$ and $\int \sec \Theta$ would be $ln\left | \sec\Theta + \tan\Theta \right |$ . Since $\sec \Theta$ is equal to $\frac{x+5}{3}$ and $\tan\Theta$ is equal to $\frac{\sqrt{x^2+10x+16}}{3}$ , the whole integral would be (I had added all like terms before this): $9\left [ \frac{\sqrt{x^2+10x+16}}{3} \right ]^3 + 252\left ( \frac{\sqrt{x^2+10x+16}}{3}\right ) -\frac{135}{2} \left ( \frac{x+5}{3}\right ) \left ( \frac{\sqrt{x^2+10x+16}}{3}\right ) - \frac{385}{2} ln \left | \frac{x+5}{3} + \frac{\sqrt{x^2+10x+16}}{3}\right | + C$ Lastly, I simplified the integral: $\frac{1}{3} \left ( x^2 + 10x+16 \right )^\frac{3}{2} + \frac{(93-15x)\sqrt{x^2+10x+16}}{2} - \frac{385}{2} ln \left | \frac{x+5+\sqrt{x^2+10x+16}}{3}\right | + C$ Have I integrated the integrand appropriately? Thanks in advanced.","['integration', 'calculus', 'functions', 'real-analysis']"
3485959,Unexpected yet accessible examples of the probabilistic method,"What are some examples of applications of the probabilistic method to areas where it might not be expected? I was just wondering how feasible it would be to present different ideas about the probabilistic method to those who don't necessarily have a lot of math background. One really interesting example I found was hat games, and the applications of Hamming codes and probabilities to find really slick ways to think about different hat puzzles. I was just wondering if you had any other specific examples that don't take a lot of build up to get to some interesting results. I plan to introduce the basics of probability and expected value, but I don't think I can get to topics like the Local Lemma and Martingales. Also, I don't think I'd like to go very deep into graphs or analysis either, given that a lot of people aren't very familiar with those concepts.","['probabilistic-method', 'soft-question', 'combinatorics']"
3486016,Equivalence of two definitions of Lebesgue integration,"I'm quite new to measure theory, and so far I've come across two different definitions for the integral of a real-valued function over a measure space. I'm having trouble showing that the two definitions are equivalent. Suppose $(X,\Sigma,\mu)$ is a measure space. The first approach starts with defining a simple function on $X$ as any function of the form $g=\sum_{i=0}^n a_i\chi E_i$ ,
 where $a_0,a_1,\ldots,a_n$ are constants in $\mathbb{R}$ , $E_0,E_1,\ldots,E_n$ are measurable subsets of $X$ with finite measure, and $\chi E_i$ is the characteristic function of $E_i$ . For such a function, we define $$\int g =\sum_{i=0}^n a_i\mu E_i.$$ Next, if $f$ is a nonnegative, real-valued function defined on a conegligible/conull subset of $X$ , we say that $f$ is integrable if there is a non-decreasing sequence $\langle f_n\rangle_{n\in\mathbb{N}}$ of non-negative simple functions such that $\sup_{n\in\mathbb{N}}\int f_n<\infty$ and $\lim_{n\to\infty}f_n =f$ almost everywhere. 
In this case, we set $$\int f = \sup\left\{\int g:g\text{ is a simple function and }g\leq f\text{ almost everywhere}\right\}.$$ Finally, if $f$ is an arbitrary real-valued function defined on a conegligible subset of $X$ , we say that $f$ is integrable if we can write $f=f_1-f_2$ where $f_1$ and $f_2$ are nonnegative, integrable functions (in the sense defined earlier). In this case, we set $\int f= \int f_1- \int f_2$ . For the second approach, we start by defining a quasi-simple function on $X$ as any function of the form $g=\sum_{i=0}^{\color{red}\infty} a_i \chi G_i$ where $\langle G_i\rangle_{i\in\color{red}{\mathbb{N}}}$ is a $\color{red}{\text{partition}}$ of $X$ into measurable sets, $\langle a_i\rangle_{i\in\color{red}{\mathbb{N}}}$ is a sequence in $\mathbb{R}$ , and $$\sum_{i=0}^\infty |a_i|\mu G_i<\infty.$$ In the above sum, we count $0\cdot \infty$ as $0$ , so that $G_i$ can have infinite measure so long as $a_i=0$ . For such a function, we define $$\int g=\sum_{i=0}^\infty a_i\mu G_i.$$ We say a real-valued function $f$ defined on a conegligible subset of $X$ is integrable if the two values $$\sup\left\{\int g:g\text{ is a quasi-simple function and }g\leq f\text{ almost everywhere}\right\}$$ $$\inf\left\{\int h:h\text{ is a quasi-simple function and }h\geq f\text{ almost everywhere}\right\}$$ are equal, in which case we set $\int f$ equal to the common value. I noticed that the difference in approach between these two definitions becomes more apparent when considering the case in which $f$ is unbounded. Indeed, if we suppose $f$ is unbounded below, then although there are quasi-simple functions which are less than $f$ , there are no simple functions less than $f$ (so that splitting up $f$ into $f_1-f_2$ as done in the first definition is necessary). I would greatly appreciate any help in showing that these two definitions are equivalent. For further context, showing the equivalence of these two definitions is exercise 122Yd in Fremlin's first volume of Measure Theory .","['integration', 'measure-theory', 'lebesgue-integral']"
3486035,Change of Variables -- is it always an isomorphism?,"I think I'm fundamentally confused about what it means to make a change of variables (in the context of an affine/projective variety). From the usage I see, it seems to be some sort of transformation $\varphi : k[x_1,..,x_n] \rightarrow k[x_1,..,x_n]$ that relabels a polynomial expression as a variable, e.g. $\varphi(y^2/2 + x) = X$ . Do we also require a change of variables to be an isomorphism of $k[x_1,..,x_n]$ ? (Does anyone have a reference for the definition?) For a concrete example, I realized my confusion reading the answers here: Hartshorne exercise 1.1 (c) . I'm not sure I understand why the change of variables used there in the second answer leads to an isomorphism.","['affine-varieties', 'algebraic-geometry']"
3486090,Circle inscribed between quarter circles - proving its center point,"Square $ABCD$ has a side length of $1$ . $BGD$ and $AFC$ are quarter circles, and there is an inscribed circle between the quarter circles. Two points of tangency $F$ and $G$ are labeled. How can I prove $O$ is the center of the inscribed circle? I was thinking to show $EFGH$ is a rectangle (or equivalently an inscribed parallelogram). It is easy to see $FG$ and $EH$ are parallel to $AD$ by symmetry, but I cannot justify why $EF$ and $HG$ are parallel to $AB$ (well I thought it was obvious, but upon further thinking it didn't seem so obvious!). The problem of solving for the radius of the circle has two solutions on Quora . However, I was having issues justifying the steps of the proofs. For example, the first proof seems to assume $O$ is the center of the circle. And the second states the three points of tangency in the circle form an equilateral triangle (which doesn't seem obvious to me). It is definitely true $O$ is the center, but I'm at a mental block for proving this obvious thing. Any suggestions would be much appreciated, thanks! Disclosure: I run the YouTube channel MindYourDecisions. I will give credit by linking to this thread in the ""sources"" for the video/blog post.",['geometry']
3486105,Show that $\mathfrak{sl}_n$ is the Lie algebra of the algebraic group $SL_n$,"I am currently reading the book ""Linear Algebraic Group"" by Springer, more precisely in chapter 4 where Lie algebras of linear algebraic groups are introduced. I would like to prove that the Lie algebra of $SL_n$ is given by the algebra $\mathfrak{sl}_n$ of $n\times n$ matrices with trace zero using the formalism developped in the book. Let $k$ be an algebraically closed field and consider the linear algebraic group $G=GL_n$ , whose affine algebra is given by $k[G]=k[T_{i,j},\Delta^{-1}]_{1\leq i,j \leq n}$ where $\Delta=\det(T_{i,j})$ . Inside $G$ , we have the subgroup $H = SL_n$ which is Zariski closed in $G$ , hence it is again a linear algebraic group whose affine algebra is $k[H]=k[T_{i,j}]/(\Delta - 1)$ . I know already that the Lie algebra $L(G)$ of $G$ can be identified with the algebra $\mathfrak{gl}_n$ of $n\times n$ matrices with usual Lie brackets. That is because the $k$ -derivations of $k[G]$ commuting with all left translations are exactly the $D_X$ for $X=(x_{i,j})\in \mathfrak{gl}_n$ , defined by $$D_XT_{i,j}:=-\sum_{h=1}^nT_{ih}x_{hj}$$ To compute the Lie algebra $L(H)$ of $SL_n$ , the book recommends to proceed in the following manner. I let $J=(\Delta-1)$ be the ideal of $k[G]$ defining $H$ , and I consider $\mathcal D_{G,H}$ the set of all the $k$ -derivations of $k[G]$ preserving $J$ . Then, there is a natural isomorphism $$\mathcal D_{G,H}\cap L(G) \cong L(H)$$ Whence, to prove that $L(H)$ identifies with $\mathfrak{sl}_n$ , I need to show the following: We have $D_X(\Delta - 1) \in (\Delta - 1)$ if and only if $\operatorname{Trace}(X)=0$ . By argueing on dimension, it is actually enough to just prove that $D_X(\Delta - 1) \in (\Delta - 1)$ for $X = E_{i,j}$ or $E_{i,i}-E_{j,j}$ for $i\not = j$ . I thought that it would be easy enough, but well... The computations are terrible and I can't reach the desired conclusion (even considering the case $n=2$ ). Is there any ""clever"" way to tackle this problem ? Also, is there maybe another way to characterize the Lie algebra that would make the argument more direct ?","['affine-varieties', 'algebraic-groups', 'algebraic-geometry', 'commutative-algebra']"
3486118,Relation between $\lim_{x â€Ž\to â€Ž\infty} â€Ž\frac{f f''}{(f')^2}$ and $â€Žâ€â€Œâ€Ž\lim_{x â€Ž\to â€Ž\infty} â€Ž\frac{f' f'''}{(f'')^2}$.,"Let assume â€Ž $â€Žf â€Ž\in â€ŽC^3((0,\infty))â€Ž$ â€Žâ€Žâ€ and â€Ž $â€Žâ€Žâ€Žf,f',f'' >0â€Ž$ . If $$ â€Žâ€Žâ€â€Œâ€Ž\lim_{x â€Ž\to â€Ž\infty} â€Žâ€Ž\dfrac{f' f'''}{(f'')^2} =â€Ž câ€Ž \neq â€Ž1â€Ž $$ â€show that $$ \lim_{x â€Ž\to â€Ž\infty} â€Žâ€Ž\dfrac{f f''}{(f')^2} = â€Ž\dfrac{1}{2-c}. $$ My attempt: By Taylor Theorem we know that: $$f(x+h)=f(x)+f'(x)h+f''(x) \frac{h^2}{2} + f'''(\xi) \frac{h^3}{6}, \qquad \text{for} \,\,\, \text{some} \qquad \xi \in (x,x+h).$$ Multiplying both sides in $f'(x)$ and dividing by $(f'(x))^2$ we obtain: $$ \frac{f(x)f(x+h)}{(f'(x))^2}= \Big(\frac{f(x)}{f'(x)} \Big)^2+\frac{f(x)}{f'(x)}h+\frac{f(x)f''(x)}{(f'(x))^2} \frac{h^2}{2} + \frac{f(x) f'''(\xi)}{(f'(x))^2} \frac{h^3}{6}.$$ Also, multiplying both sides in $f'(x)$ and dividing by $(f''(x))^2$ we obtain: $$ \frac{f'(x)f(x+h)}{(f''(x))^2}= \frac{f'(x)f(x)}{(f''(x))^2} + \Big(\frac{f'(x)}{f''(x)} \Big)^2 h +\frac{f'(x)}{f''(x)} \frac{h^2}{2} + \frac{f'(x) f'''(\xi)}{(f''(x))^2} \frac{h^3}{6}.$$ I don't know how to continue.","['limits', 'calculus', 'analysis', 'real-analysis']"
3486119,Why is the directional derivative zero at any point of the level curve along the direction of the tangent line to the level curve at that point?,"Let $f : \Bbb R^2 \longrightarrow \Bbb R$ be a scalar function defined over the plane $\Bbb R^2.$ Let $l$ be a level curve of the function $f$ where $f(x,y) = k$ for all $(x,y) \in l.$ Let $(x_0,y_0) \in l$ and consider the unit tangent vector $(u,v)$ to $l$ at $(x_0,y_0).$ Suppose that the directional derivative of $f$ exists at $(x_0,y_0).$ Show that the directional derivative of $f$ at $(x_0,y_0)$ in the direction of $(u,v)$ is zero. So what I need to show is that the limit $$\lim\limits_{h \to 0} \frac {f(x_0+hu,y_0+hv) - f(x_0,y_0)} {h} = 0.$$ Now I observe that the point $(x_0+hu,y_0+hv)$ is a point on the tangent to $l$ at $(x_0,y_0).$ Also I know that $f(x_0,y_0)=k.$ Now how do I compute the limit? Any help in this regard is highly appreciated. Thank you very much.","['multivariable-calculus', 'proof-writing']"
3486142,What's the rationale behind rejecting limits of recurrence relation?,"I found this problem in Understanding Analysis by Stephen Abbott. Define a recurrence relation as $x_1=3$ and $x_{n+1}=\frac{1}{4-x_n}$ . Find the limit of the sequence $(x_n)$ . There are other parts to the question, but what I want to ask is: why do we reject a limit and not another when solving for the limit? If $(x_n) \rightarrow L$ , it is not too hard to show that $(x_{n+1}) \rightarrow L$ . Thus we can take the limit of both sides of $x_{n+1}=\frac{1}{4-x_n}$ to get $L=\frac{1}{4-L}$ . We can solve for $L$ to get $L=0.268$ or $L=3.732$ . My question is why $L=0.268$ is the answer, and not $3.732$ . Is there any significance behind $3.732$ popping out here? Logically, we can conclude that $x_n$ is strictly decreasing and reject $3.732$ on the basis that it is greater than $x_1$ , but is that a valid reason though? What about sequences whose behaviour is neither monotone decreasing/increasing? How do we tell if a particular limit we solved for is correct or wrong?",['real-analysis']
3486172,The probability for two random variables to be independent,"I'm learning probability, and many theorems start by assuming that you have a set of mutually independent random variables. However, The condition that two random variables are independent seems to me quite restrictive. Is it? For example: Suppose $(\Omega,p)$ is a finite uniform probability space. How many
  pairs of random variables with range in $\{0,1\}$ are
  independent?. Does their proportion to the total number of pairs grow as the size of $\Omega$ grows? Thanks","['probability-theory', 'probability']"
3486173,"If $p, q$ and $r$ are distinct roots of $x^3-x^2+x-2=0$, find the value of $p^3+q^3+r^3$.","If $p, q$ and $r$ are distinct roots of $x^3-x^2+x-2=0$ , find the value of $p^3+q^3+r^3$ . Here's what I have got, By Vieta's rule $p+q+r=1\text{.               ...........}(1)$ $pq+qr+pr=1\text{.               ...........}(2)$ $pqr=2\text{.               ...........}(3)$ Squaring $(1)$ , $p^2+q^2+r^2+2(pq+qr+pr)=1\text{.               ...........}(4)$ From $(2)$ , $p^2+q^2+r^2=-1\text{.               ...........}(5)$ Putting the roots and adding these equations, $p^3-p^2+p-2=0$ $q^3-q^2+q-2=0$ $r^3-r^2+r-2=0$ We get, $(p^3+q^3+r^3)-(p^2+q^2+r^2)+(p+q+r)-6=0$ Putting the values, $(p^3+q^3+r^3)-(-1)+1-6=0$ $(p^3+q^3+r^3)=4$ Am I doing something wrong in my solution? Because the answer given is -5. Any help would be appreciated.","['cubics', 'algebra-precalculus', 'polynomials']"
3486174,"Is $a_{n+1}=\frac{a_n(a_n+n+k)}{n+1}$ eventually a non-integer, for all $k$?","Given a positive integer $k$ , let $a_1=1$ and $a_{n+1}=\frac{a_n(a_n+n+k)}{n+1}, \forall n \geq 1$ . The sequence terminates when a term is not an integer. I'd like to ask whether for all $k$ , the sequence will always terminate?",['sequences-and-series']
3486179,Finding a formula for a triangle similar to Pascal's.,"I need to find a formula expressed in binomial coefficients of the following triangle: $$D_n^k=\begin{cases}
n \quad\quad\quad\quad\quad\text{ if } n=k \text{ or } k=0 \\
D_{n-1}^k+D_{n-1}^{k-1} \text{ otherwise}
\end{cases}$$ This triangle is the same as the Pascal's triangle, except for the base value ( $n$ instead of $1$ ) .","['binomial-coefficients', 'combinatorics', 'discrete-mathematics']"
3486229,Computing the exponential generating function of the Bell numbers.,"I am trying to compute the exponential generating function of the Bell numbers $B_{n+1} = \sum_{k=0}^n \binom nkB_k, B_1=1$ . So far I have \begin{align}
B(x) &= \sum_{n=0}^\infty B_n\frac{x^n}{n!}\\
&= \sum_{n=0}^\infty \sum_{k=0}^n \binom nk B_k \frac{x^n}{n!}\\
&=\sum_{k=0}^\infty B_k\sum_{n=k}^\infty \binom nk \frac{x^n}{n!},
\end{align} where we can interchange the order of summation by monotone convergence or Tonelli's theorem. But I have no idea how to compute $\sum_{n=k}^\infty \frac{x^n}{k!(n-k)!}$ . According to Mathematica, $$
\sum_{n=k}^\infty \frac{x^n}{k!(n-k)!}  = \frac{e^x x^k}{k!}.
$$ As shown in the answer, $$
\sum_{n=k}^\infty \frac{x^n}{k!(n-k)!} = \sum_{n=0}^\infty \frac{x^{n+k}}{k!n!} = x^k \sum_{n=0}^\infty \frac{x^n}{n!} = \frac{x^ke^x}{k!}.$$ Hence $$
B(x) = \sum_{k=0}^\infty B_k \frac{e^xx^k}{k!} = e^x \sum_{k=0}^\infty B_k\frac{x^k}{k!} = e^x B(x).
$$ But this does not make sense, as $B(x) = e^xB(x)$ implies that $B(x)=0$ . What error have I made? Edit: It turns out that $$B(x) = 1 + \sum_{n=0}^\infty\sum_{k=0}^\infty \binom nk B_k\frac{x^n}{n!},$$ so what I computed above was actually $B'(x)$ . This yields the differential equation $B'(x) = e^x B(x)$ , from which $B(x) = Ce^{e^x}$ . The condition $B(0)=1$ yields $C=\frac1e$ , so that $$B(x) = e^{e^x-1}. $$","['generating-functions', 'combinatorics', 'sequences-and-series']"
3486259,Does there exist such a sequence $B$ when $p>5$?,"Let $A = (a_1, a_2, \ldots, a_n)$ be the sequence of odd primes are less than or equal to a prime number $p$ . Let $C$ be the infinite ascending sequence of composite numbers that their factors are all in $A$ . Let $B$ be a sequence of $n$ consecutive numbers of $C$ such that $b_n - b_{n-1} = a_2 - a_1, \ b_{n-1} - b_{n-2}  = a_3 - a_2, \ldots, \ b_2 - b_1 = a_n - a_{n-1}$ . For example, when $p=5,\ A=3,5, \ C= 9,15,25,27,45,75,81,..., \ B=25,27$ . Does there exist such a sequence $B$ when $p>5$ ? Edit: It seems the question above is not that easy to answer, here's alternative question: If there exist such a sequence $B$ when $p>5$ , then $b_1$ must be greater than $3p$ ?","['algebraic-number-theory', 'number-theory', 'elementary-number-theory', 'prime-gaps', 'prime-numbers']"
3486283,When a nonlinear operator has no fixed point?,"Let B be a normed vector space and $f: B \to B$ be a nonlinear operator. It is well known that the Banach fixed-point theorem or  the Brouwer fixed-point theorem gives conditions which imply that a operator $f$ has a fixed point.
My question is that is there a result on nonexistence of fixed points of a nonlinear operator. That is conditions which ensure that the operator $f$ has no fixed point.","['nonlinear-analysis', 'functional-analysis', 'analysis']"
3486350,Characterizing the dual cone of the squares of skew-symmetric matrices,"Let $X$ be the set of all real $n \times n$ diagonal matrices $D$ satisfying $\langle D,B^2 \rangle \le 0$ for any (real) skew-symmetric matrix $B$ . (I am using the Frobenius Euclidean product here). $X$ is a convex cone. Can we give an explicit characterization of $X$ ? Comment: If we denote by $C$ the space of all  squares of skew-symmetric matrices, we can characterize its dual cone as follows: Since every square of a skew-symmetric matrix is symmetric, and the symmetric and the skew-symmetric matrices are orthogonal, we know that every skew-symmetric matrix belongs to the dual cone of $C$ . So, the question whether a given matrix $A$ belongs to the dual cone of $C$ depends solely on the symmetric part of $A$ . Since $C$ is invariant under orthogonal conjugation , we can orthogonally diagonalize $\text{sym}(A)$ and deduce that $A$ lies in $C^*$ if and only if the diagonal matrix whose entries are the eigenvalues of $\text{sym}(A)$ is in $C^*$ . Thus, the question reduces to determining the case of diagonal matrices. Edit: Omnomnomnom proved in this answer that every $D$ in $X$ has at most one negative entry, and the absolute value of the negative entry is less than or equal to the next-smallest entry. I have a strangely complicated proof for the converse, namely I can prove that every diagonal matrix satisfying the condition above is in $X$ . I would like to find a ""direct"" proof based on linear algebra\matrix analysis. (my proof is based on rather convoluted variational considerations).","['dual-cone', 'matrices', 'matrix-calculus', 'linear-algebra', 'symmetric-matrices']"
3486414,A sequence with dominoes,"My friend ran into this problem years ago. He asked for my help, but I couldn't solve it either. The setting is as follows. Dominoes are placed in a triangular formation. Something like this... ã…
ã…ã…  (n=2) Rules: 1. If a domino is hit, it may fall or it may not. 2. If a domino is not hit, it does not fall. Problem: $D_n$ is the number of scenarioes possible for a given $n$ . Find the explicit formula of $D_n$ . Example: For n=2, The domino on the top may or may not fall. If it does not fall, the two dominoes under it do not fall. If it does, the two dominoes may or may not fall. Therefore $D_2=5$ . Clarification: The rule is: the top domino can fall; for any non-top domino, it can fall only if at least one domino above it falls. Please help. Thank you very much.","['combinatorics', 'sequences-and-series']"
3486424,What does 'dimensions' in this context even mean?,"The book on Integral Calculus by Joseph Edwards in its 24th Art. says: Also it is a further help to observe the dimensions of each side. For instance, $x$ and $a$ being supposed linear, $\int \frac{dx}{\sqrt{a^2 - x^2}}$ is of zero dimensions . There could therefore be no $\frac{1}{a}$ prefixed to the integral. My question is what does the author mean by dimensions ? Here is a similar question but it doesn't really answer what the term dimension means in this context. Here is an archive if you want to read it yourself.","['integration', 'indefinite-integrals', 'calculus']"
3486455,To show that for $n\geq 1$ Each $n$ element set has $2^{n-1}$ subsets of even and odd size each,"So for this, I wrote a different proof than the one given in the textbook I'm studying discrete math from. I was wondering if it was a correct proof because I really like it and want to know if it has any logical pitfalls. Let us consider the expansion of $$(1+x)^n= \binom{n}{0} x^n + \binom{n}{1}x^{n-1} + \ldots + \binom{n}{n-1}x^{1} + \binom{n}{n}x^0$$ Clearly, this contains every power of $x$ from $0$ to $n$ . 
Now this can be seen as the set containing $n$ elements being partitioned into subsets if all sizes from size $0$ to $n$ . For the purposes of this paper we are not concerned with the elements in the subsets only the size. The coefficients $\binom{n}{k}$ in the expansion of $(1+x)^n$ are the number of subsets with $k$ elements if we group them only by size. 
Now, the rest of the proof follows simply, we know that, $$(x+1)^n= \binom{n}{0} x^n + \binom{n}{1}x^{n-1} + \ldots + \binom{n}{n-1}x^{1} + \binom{n}{n}x^0$$ Putting, $x=1$ in this equation, we get, $$(2)^n= \binom{n}{0} + \binom{n}{1} + \ldots + \binom{n}{n-1} + \binom{n}{n}$$ Or, $$2^n = \sum^{i=n} _{i=0} \binom{n}{i}$$ Also, putting $x=-1$ we get, $$0= \binom{n}{0} - \binom{n}{1} + \ldots - \binom{n}{n-1} + \binom{n}{n}$$ Or, $$0= \sum^{i=n} _{i=0} (-1)^i\binom{n}{i}$$ Now adding the two equations, we get, $$2^n = 2\cdot \sum^{i=n} _{i=0,i\neq 2k+1 \forall k =(0,1\ldots \lfloor {\frac{n-1}{2}}\rfloor)} \binom{n}{i}$$ That is the sum of the even coefficients is $2^{n-1}$ which is the same as saying that the sum of all the subsets having an even number of elements (total number of subsets having an even number of elements) is $2^{n-1}$ and now putting this back into the first equation, $$0= \binom{n}{0} - \binom{n}{1} + \ldots - \binom{n}{n-1} + \binom{n}{n}$$ We get, the sum of the odd coefficients, or total number of subsets with odd number of elements is also $2^{n-1}$","['combinations', 'proof-writing', 'solution-verification', 'combinatorics', 'elementary-set-theory']"
3486480,$\sqrt{n}$ with at least five equal among the first six digits,Find all positive integers $n$ which are not perfect squares and such that the decimal representation of $\sqrt{n}$ has the following property: among the first six digits there are at least five equal. For example $\sqrt{2020} = 44.944410108488\ldots$ has five $4$ s and one $9$ among its first six digits.,"['number-theory', 'elementary-number-theory']"
3486496,Is this operator compact,"Consider the operator $$(Tx)_n=  \frac{x_{n+1}}{3} - \frac{2x_{n-1}}{3}  $$ for $n \ge 0$ and $$(Tx)_n = \frac{2x_{n+1}}{3} - \frac{x_{n-1}}{3}  $$ for $n <0$ . I am wondering whether this operator is compact on $\ell^{\infty}(\mathbb Z)$ ? My conejecture is no, but I find it difficult to show.","['calculus', 'functional-analysis', 'real-analysis']"
3486507,When are two neighbouring fractions in Farey sequence are similarly ordered,"I am trying exercises from Tom M Apostol and I could not think about this problem in Chapter 5. Problem is - Two reduced fractions $a/b$ and $c/d$ are said to be similarly ordered if $(c-a)\times(d-b)\ge0$ . Prove that any two neighboring fractions $\frac{a_i}{b_i}$ and $\frac{a_{i+1}}{b_{i+1}}$ are similarly ordered. My attempt - I tried using result - for any two consecutive Farey fractions $a/b<c/d$ , $bc-ad=1$ holds and then using definition of similarly ordered fractions. But it doesn't yields result when $b\neq d$ . Can someone please help.","['analytic-number-theory', 'number-theory', 'farey-sequences']"
3486525,When do the solutions of a linear ODE system lie on ellipses?,"Let $x(t) \in \mathbb{R}^n$ and $A(t)$ be a $n\times n$ matrix. 
When $A(t)$ is a skew-symmmetric matrix, the solutions of the linear system $\dot{x} = A(t) x$ lie on spheres centered at the origin since $$
\frac{1}{2} \frac{d}{dt} \lvert x \rvert^2 = \langle \dot{x}, x \rangle = \langle Ax, x \rangle = 0 \implies \lvert x \rvert^2 = \lvert x(0) \rvert^2
$$ Is there a specific class of matrices $A(t)$ for which the solutions lie on ellipses instead?",['ordinary-differential-equations']
3486592,Theorem 7.18 Rudin's,"I'm studying the example of a continuous function nowhere differentiable on Rudin's book ""Principles of Mathematical analysis"", but I keep missing the point of an assumption. 
Here you can see the proof. The point I'm struggling with is the (?) weird assumption of not allowing any integer lying on the interval (formula n.38). Intuitively, I see that avoiding an integer on my interval let us evaluate $|\phi(4^n(x+\delta_m))-\phi(4^nx)|$ ( $\star$ ) on a straight line, and the result will be $\frac{1}{2}$ . In the second case, if we have a integer $q$ , the graph of the function $\phi$ change the slope in a neighborhood of $q$ (we have something like a $\land$ or $\lor$ , with the segments of different measure), but I don't understand whhy in this case the difference ( $\star$ ) change, and why this should be avoid. I tried to figure it out what's going on here, but I really didn't find anything. Any hints or solution would be much appreciate, thanks in advance.","['analysis', 'real-analysis']"
3486603,Cauchy's formula for repeated integrals proof by induction,I was trying to follow along with the proof on Wikipedia for Cauchy's formula for repeated integrals and I'm stuck on the last step. How do you go from $$\int_a^x \frac {d}{dy} \left( \int_a^y (y-t)^nf(t)dt\right) dy$$ to $$\int_a^x (x-t)^nf(t) dt$$,"['integration', 'multivariable-calculus', 'calculus', 'derivatives']"
3486641,Non-real roots of $z^2=\sin(z)$,"What is the number of roots of $$z^2= \sin(z)$$ in $\left\{z\in\mathbb C\setminus\mathbb R\left||z|<2\right.\right\}$ ? This task is related to the Argument principle and RouchÃ©'s theorem.
Maybe I should estimate $f(z)=z^2$ and $g(z)= \sin(z)$ using an inequality that would hold when $|z|<2$ . I would be grateful if you provide an explanation, so I could learn how to solve similar problems.","['complex-analysis', 'rouches-theorem']"
3486647,Solve $\int x^2e^x\sin x$,Solve $\int x^2e^x\sin x$ My attempt is as follows:- $$I_1=\int e^x\sin x$$ $$I_1=e^x\sin x-\int e^x\cos x$$ $$I_1=e^x\sin x-e^x\cos x-\int\sin (x)e^x$$ $$2I_1=e^x\left(\sin x-\cos x\right)$$ $$I_1=\dfrac{e^x\left(\sin x-\cos x\right)}{2}\tag{1}$$ $$I_2=\int e^x\cos x$$ $$I_2=e^x\cos x+\int e^x\sin x$$ $$I_2=e^x\cos x+e^x\sin x-\int e^x \cos x$$ $$I_2=\dfrac{e^x(\cos x+\sin x)}{2}$$ $$I=\int x^2e^x\sin x$$ $$I=I_1x^2-2\int xI_1$$ $$I=I_1x^2-\int xe^x(\sin x-\cos x)$$ $$I=I_1x^2-\int xe^x\sin x+\int xe^x\cos x$$ $$I=I_1x^2-xI_1+\int I_1+xI_2-\int I_2$$ $$I=I_1x^2-xI_1+xI_2+\int I_1-\int I_2$$ $$I=I_1x^2-xI_1+xI_2+\dfrac{1}{2}\int e^x\left(\sin x-\cos x\right) -\dfrac{1}{2}\int e^x\left(\cos x+\sin x\right)$$ $$I=I_1x^2-xI_1+xI_2+\dfrac{I_1}{2}-\dfrac{I_2}{2} -\dfrac{I_2}{2}-\dfrac{I_1}{2}$$ $$I=I_1x^2-xI_1+xI_2-I_2$$ $$\dfrac{e^x}{2}\left(x^2\sin x-x^2\cos x-x\sin x+x\cos x+x\cos x+x\sin x-\sin x-\cos x \right)+C$$ $$\dfrac{e^x}{2}\left((x^2-1)\sin x-(x-1)^2\cos x \right)+C$$ Is there any better way to solve it which is short and clean. Mine got very long.,"['integration', 'limits', 'calculus']"
3486679,Regarding proving a series result from Tom M Apostol Modular functions and Dirichlet series in number theory,"I was trying a problem from Ch -1( Elliptic Functions problem no. 15) of book Modular functions and Dirichlet series in number theory  whose Statement is this. Image- I have no idea on how to solve this problem, please give some hints. It is after the introduction to Lambert series in the exercises.","['analytic-number-theory', 'number-theory', 'sequences-and-series']"
3486683,Is it in general true that a space is not homeomorphic to the punctured version of this space?,"For non-arbitary spaces we can discuss for such case, like how many components are there or other properties. But is it true for any space? It seems if we have a homeomorphism $f$ from $S$ to $S' = S - \{p\}$ , $f(p) = q$ , but since a space is homeomorphic to itself, there is some $g(r)=q$ . Then there is no inverse if $f$ and $g$ coincide. However they don't have to and maybe $f$ is somehow the homeomorphism since I can't deduce more information. If it is not true, a counter-example will be super helpful! Thank you.",['general-topology']
3486708,Is the Product of a Compact Space and a Countably Compact Space Countably Compact?,"I know the statement does not hold for the product of two countably compact spaces, but I was wondering if it holds if one of the spaces is compact. My idea was to use a cover consisting of basic open sets and show that there is a finite subcover for each space via projections on the basic open sets, and then take the corresponding products of these sets to yield a finite subcover for the product. However, if this is true, then the same technique would show the result for products of countably compact spaces, which I know isn't true. Can anyone shed some light on this?","['general-topology', 'product-space', 'compactness']"
3486725,Intersection of two closed intervals,"I was solving a question on leetcode. I noticed that they defined the intersection of two closed intervals as so: $$[a,b]\cap [c,d] = \left[\max(a,c), \min(b,d)\right]$$ The leetcode question can be found here . I am wondering if there is a formal proof for this? I know that the intersection of two closed intervals yields a closed interval in what I have studied in real analysis but I never came across (or don't remember) this definition. Any suggestions or references are appreciated.","['elementary-set-theory', 'real-analysis']"
3486731,Do a.s. right-continuous paths imply product measurability,"Let $( X_t )_{ t \geq 0}$ be an $\mathbb{R}^d$ -valued stochastic process on the probability space $(\Omega, \mathcal{F}, P)$ which has right-continuous sample paths. The latter means that the map $t \mapsto X_t (\omega)$ is right-continuous for all $\omega \in \Omega$ . Using this fact I know how to show that $(t, \omega) \mapsto X_t (\omega)$ is $\mathcal{B}[0, \infty) \otimes \mathcal{F} - \mathcal{B}(\mathbb{R}^d)$ -measurable. But what if instead of the right-continuity of the sample paths, we require a.s. right-continuity, i.e. assume that there is some $\Omega_0 \in \mathcal{F}$ with $P(\Omega_0) = 1$ such that $t \mapsto X_t ( \omega )$ is right-continuous for all $\omega \in \Omega_0$ . Does it then follow that $(t, \omega) \mapsto X_t (\omega)$ is $\mathcal{B}[0, \infty) \otimes \mathcal{F} - \mathcal{B}(\mathbb{R}^d)$ -measurable? Since I think of the concept of measurability to be related to the measurable space $(\Omega, \mathcal{F})$ , and not necesarrily to the measure $P$ on it, it is not clear how to work with this.","['measure-theory', 'probability-theory']"
3486741,Implication of Matrices in $AX=0$,"I'm not sure how to phrase my question and this is the first time I'm posting on math exchange but basically I'm looking for some feedback on my answer to this question: Let $A$ denote an $mÃ—n$ matrix. If $AX=0$ for every $nÃ—1$ matrix $X$ , show that $A=0$ . I claim that since $X$ is every column vector in the set $R^n$ , and $AX=0$ , it is implied that $A=0$ by considering the constituents of the products of $AX$ : $a_jÃ—x_i$ where $a_j$ represents the $j$ th column of $A$ and $x_i$ represents the $i$ th row of $X$ , and $i=j$ . If $a_jÃ—x_i=0$ and vector $X$ is every possible column vector (where $x_i=n$ ), then it's implied that $A$ must be a zero matrix (where $a_j=0$ ) to satisfy the equation $AX=0$ . I feel like I'm running in circles with this argument...","['matrices', 'logic', 'linear-algebra']"
3486753,"Teaching Dirac delta ""function"" $\delta(t)$","I am about to teach applied mathematics for engineering. So I will teach how to use Laplace Transform to solve differential equations. Some of these differential equations involve the Dirac delta ""function"" as a forcing term, for example: $$y''(t)+y'(t)-y(t)=3\delta(t-1).$$ The students have as prerequisite: Calculus II and Calculus III. I don't know how to introduce the Dirac delta function: 1) Should I first talk about the distributions as linear functionals acting on test functions. Then define Dirac delta function as $\langle\,\delta,\varphi\rangle=\varphi(0)$ . or 2) Define $\delta$ as ""something"" that has a Laplace Transform $\mathcal{L(\delta)}=1$ ,  that is $\delta$ is a limit (in some sense) of a sequence of functions $f_n$ having a tall spike at the origin with $\lim_{n\to \infty}\mathcal{L(f_n)}=1$ . That object can be viewed as a ""function"" defined by $$\delta(t)=\begin{cases}
0, & t\neq0\\
\infty, & t=0
\end{cases}$$","['dirac-delta', 'ordinary-differential-equations', 'laplace-transform', 'distribution-theory', 'education']"
