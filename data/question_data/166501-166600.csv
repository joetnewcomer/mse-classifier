,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Expected value of a ratio. To exist or not to exist, that is the question.","Expected value of a ratio. To exist or not to exist, that is the question.",,"I am given the question. Suppose X and Y are iid uniform random variables on the interval (-2,2). Let $Z=\frac{Y}{X}$ . Does the expectation of Z exist? If it exists, calculate $\mathbb{E}[Z]$ . If it does not exist, explain why. I have 2 different interpretations of this questions and I don't know which one or if any is correct. 1 way I see this is once we calculate the pdf of Z. We can use it to calculate the expected value as, $$\mathbb{E}[Z]=\int zf_{Z}(z)dz$$ But, if we look at as, $$\mathbb{E}[Z]=\mathbb{E}\left[\frac{Y}{X}\right]$$ Since X and Y are independent, $$\mathbb{E}\left[\frac{Y}{X}\right]=E[Y]\cdot\mathbb{E}\left[\frac{1}{X}\right]$$ But, the expected value of 1/X is $$\mathbb{E}\left[\frac{1}{X}\right]=\int_{-2}^2 \frac{1}{x}f_{X}(x)dx$$ This is a divergent integral and thus the expected value is not possible to calculate. I don't know which interpretation if either is correct.","I am given the question. Suppose X and Y are iid uniform random variables on the interval (-2,2). Let . Does the expectation of Z exist? If it exists, calculate . If it does not exist, explain why. I have 2 different interpretations of this questions and I don't know which one or if any is correct. 1 way I see this is once we calculate the pdf of Z. We can use it to calculate the expected value as, But, if we look at as, Since X and Y are independent, But, the expected value of 1/X is This is a divergent integral and thus the expected value is not possible to calculate. I don't know which interpretation if either is correct.",Z=\frac{Y}{X} \mathbb{E}[Z] \mathbb{E}[Z]=\int zf_{Z}(z)dz \mathbb{E}[Z]=\mathbb{E}\left[\frac{Y}{X}\right] \mathbb{E}\left[\frac{Y}{X}\right]=E[Y]\cdot\mathbb{E}\left[\frac{1}{X}\right] \mathbb{E}\left[\frac{1}{X}\right]=\int_{-2}^2 \frac{1}{x}f_{X}(x)dx,"['statistics', 'expected-value']"
1,Cambridge Admissions Exam Statistics 1999,Cambridge Admissions Exam Statistics 1999,,"My work: Since $f$ is the pdf we must have $\int_{0}^{1} Ax\,\mathrm dx=1 \implies A=2$ .  Let $Y$ be the number of currants in my portion. We have $Y\sim B(4,x)$ . For the expectation $$E(Y)=4x,$$ however I don't know how to continue. I had a thought of using the expectation for $x$ in this, however, I can't statistically justify it. For the second part, we require $$P\left(X\geq\frac{1}{2}\mid Y=4\right)=\frac{P\left(X\geq\frac{1}{2},Y=4\right)}{P(Y=4)}.$$ I am completely stuck on how to approach this. I checked the student room for solutions but they seem to disagree with themselves and with other solutions on other websites. If anybody could help me in understanding this problem, and the technique required for it I would be really thankful.","My work: Since is the pdf we must have .  Let be the number of currants in my portion. We have . For the expectation however I don't know how to continue. I had a thought of using the expectation for in this, however, I can't statistically justify it. For the second part, we require I am completely stuck on how to approach this. I checked the student room for solutions but they seem to disagree with themselves and with other solutions on other websites. If anybody could help me in understanding this problem, and the technique required for it I would be really thankful.","f \int_{0}^{1} Ax\,\mathrm dx=1 \implies A=2 Y Y\sim B(4,x) E(Y)=4x, x P\left(X\geq\frac{1}{2}\mid Y=4\right)=\frac{P\left(X\geq\frac{1}{2},Y=4\right)}{P(Y=4)}.","['statistics', 'probability-distributions']"
2,"What are differences between Geometric, Logarithmic and Exponential Growth?","What are differences between Geometric, Logarithmic and Exponential Growth?",,"At past I have read in some ecology text that geometrical, logarithmic and exponential growths are not exactly the same thing; and there were various equations for them. (The book is not available to me now, and I forgot its name). My question is : What is the basic difference of these 3 growth patterns? What would be some real-life analogy to distinguish 3 growth patterns? Note: This question is Not same with existing decay curve question Thanks in advance. Update: I have found a diagram similar to the book in which I saw the concept. Source: https://cmapspublic3.ihmc.us/rid=1R0TPVNFG-113V4JS-1H9C/1R2CJ0126I1VCLY5MI1GHRIimage Looks like there are already confusion about this distinction between exponential and geometric growth. Some sources claim a difference such as There are another source at nature scitable that says ""Exponential growth and geometric growth are similar enough that over longer periods of time, exponential growth can accurately describe changes in populations that reproduce periodically (like bison) as well as those that reproduce more constantly (like humans)"" i.e. it accepts that exponential growth and geometric growth are different at least to some extent. Some other sources critic this idea such as this source says this distinction a ""Zombie idea"" and according to a quora discussion answer ""There is absolutely no difference"" For example, the function 2ˣ tell us that the number 2 can be multiplied “x times” you want. Lets do a simple sequence of the latter function where x goes from 0 to 5. Our sequence looks like this 2⁰=1, 2¹=2, 2²=4, 2³=8, 2⁴=16, 2⁵= 32, … this is exponential growth. Now lets do it using the geometric method that is repeated multiplication, in this case we start with x goes from 0 to 5 and our sequence goes like this: 1, 2, 2•2=4, 2•2•2=8, 2•2•2•2=16, 2•2•2•2•2=32. The conflicts have made me more confused about the concept of a dfference between Geometric and exponential growth.","At past I have read in some ecology text that geometrical, logarithmic and exponential growths are not exactly the same thing; and there were various equations for them. (The book is not available to me now, and I forgot its name). My question is : What is the basic difference of these 3 growth patterns? What would be some real-life analogy to distinguish 3 growth patterns? Note: This question is Not same with existing decay curve question Thanks in advance. Update: I have found a diagram similar to the book in which I saw the concept. Source: https://cmapspublic3.ihmc.us/rid=1R0TPVNFG-113V4JS-1H9C/1R2CJ0126I1VCLY5MI1GHRIimage Looks like there are already confusion about this distinction between exponential and geometric growth. Some sources claim a difference such as There are another source at nature scitable that says ""Exponential growth and geometric growth are similar enough that over longer periods of time, exponential growth can accurately describe changes in populations that reproduce periodically (like bison) as well as those that reproduce more constantly (like humans)"" i.e. it accepts that exponential growth and geometric growth are different at least to some extent. Some other sources critic this idea such as this source says this distinction a ""Zombie idea"" and according to a quora discussion answer ""There is absolutely no difference"" For example, the function 2ˣ tell us that the number 2 can be multiplied “x times” you want. Lets do a simple sequence of the latter function where x goes from 0 to 5. Our sequence looks like this 2⁰=1, 2¹=2, 2²=4, 2³=8, 2⁴=16, 2⁵= 32, … this is exponential growth. Now lets do it using the geometric method that is repeated multiplication, in this case we start with x goes from 0 to 5 and our sequence goes like this: 1, 2, 2•2=4, 2•2•2=8, 2•2•2•2=16, 2•2•2•2•2=32. The conflicts have made me more confused about the concept of a dfference between Geometric and exponential growth.",,"['statistics', 'logarithms']"
3,"Efficiency of $\hat{\theta}_{MLE}$ from $\operatorname{Beta}(\theta,1)$",Efficiency of  from,"\hat{\theta}_{MLE} \operatorname{Beta}(\theta,1)","I am working on a problem which asks me to discuss the efficiency of the MLE $\hat{\theta}$ given that $X_1,\ldots,X_n \sim_{iid} \operatorname{Beta}(\theta,1) $ . I was able to deduce that $$\hat{\theta} = \frac{n}{-\sum_{i=1}^n \ln X_i}$$ and that the Rao-Cramer Lower Bound is $$RCLB=\frac{\theta^2}{n}$$ . Since $E[\hat{\theta}]=\frac{n}{n-1}\theta$ the MLE is asymptotically  unbiased, and I found that $$Var[\hat{\theta}]= \frac{n^2\theta^2}{(n-1)^2(n-2)}$$ . What bothers me a little is that I was able to proove that the coefficient of $\theta^2$ is a value that is larger than $1 \over n$ when $1.57 < n$ so I see that this variance is indeed larger than the RCLB. However, the fact that when $n=1$ and $n=2$ is undefined makes me a bit uneasy. Is there something that needs to be considered in these cases or is there an assumption that I am missing?","I am working on a problem which asks me to discuss the efficiency of the MLE given that . I was able to deduce that and that the Rao-Cramer Lower Bound is . Since the MLE is asymptotically  unbiased, and I found that . What bothers me a little is that I was able to proove that the coefficient of is a value that is larger than when so I see that this variance is indeed larger than the RCLB. However, the fact that when and is undefined makes me a bit uneasy. Is there something that needs to be considered in these cases or is there an assumption that I am missing?","\hat{\theta} X_1,\ldots,X_n \sim_{iid} \operatorname{Beta}(\theta,1)  \hat{\theta} = \frac{n}{-\sum_{i=1}^n \ln X_i} RCLB=\frac{\theta^2}{n} E[\hat{\theta}]=\frac{n}{n-1}\theta Var[\hat{\theta}]= \frac{n^2\theta^2}{(n-1)^2(n-2)} \theta^2 1 \over n 1.57 < n n=1 n=2","['statistics', 'maximum-likelihood', 'parameter-estimation']"
4,Maximum Likelihood estimator for n in binomial with known p,Maximum Likelihood estimator for n in binomial with known p,,"I have a question concerning the ML-estimation of the trials of a Binomial variable. The setting is the following: I have a random variable $X\sim Bin(n,p)$ with $n\in\mathbb{N}$ unknown, $p\in (0,1)$ the known success probability and with density (w.r.t. to the counting measure) $p_n(x)=\binom{n}{x}p^x(1-p)^{n-x}=:L_x(n)$. The log-likehood function is therefore given by  $$l_x(n)=\log L_x(N)=\log(n!)-\log(x!)-\log((n-x)!)+x\log(p)+(n-x)\log(1-p) .$$ Maximizing $l_x(n)$ w.r.t. to $n$ is equivalent to maximizing $\log(n!)-\log((n-x)!)+n\log(1-p)$ or $\frac{n!}{(n-x)!}(1-p)^n$. My problem is that I don't know how to proceed from here. A person in this thread Maximum likelihood estimate of $N$ (trials) in Binomial suggested that a solution is given by $\hat{n}=X/p$. However, $X/p\notin \mathbb{N}$ for most $p$, so I suspect that this can't be the answer.","I have a question concerning the ML-estimation of the trials of a Binomial variable. The setting is the following: I have a random variable $X\sim Bin(n,p)$ with $n\in\mathbb{N}$ unknown, $p\in (0,1)$ the known success probability and with density (w.r.t. to the counting measure) $p_n(x)=\binom{n}{x}p^x(1-p)^{n-x}=:L_x(n)$. The log-likehood function is therefore given by  $$l_x(n)=\log L_x(N)=\log(n!)-\log(x!)-\log((n-x)!)+x\log(p)+(n-x)\log(1-p) .$$ Maximizing $l_x(n)$ w.r.t. to $n$ is equivalent to maximizing $\log(n!)-\log((n-x)!)+n\log(1-p)$ or $\frac{n!}{(n-x)!}(1-p)^n$. My problem is that I don't know how to proceed from here. A person in this thread Maximum likelihood estimate of $N$ (trials) in Binomial suggested that a solution is given by $\hat{n}=X/p$. However, $X/p\notin \mathbb{N}$ for most $p$, so I suspect that this can't be the answer.",,"['statistics', 'maximum-likelihood', 'parameter-estimation']"
5,Is there any statistical method to compare two curves?,Is there any statistical method to compare two curves?,,"Is there any statistical method to visually compare two curves? What is the best and correct way to compare two similar curves and calculate the error/difference in percentage? I have created a program that generates a curve of a column base using Bezier curve. Now, I want to find out how accurate my generation is. So I have a function for the first curve I defined, but I dont have a function for the second one, which is only on the picture.","Is there any statistical method to visually compare two curves? What is the best and correct way to compare two similar curves and calculate the error/difference in percentage? I have created a program that generates a curve of a column base using Bezier curve. Now, I want to find out how accurate my generation is. So I have a function for the first curve I defined, but I dont have a function for the second one, which is only on the picture.",,['statistics']
6,Mutual Information for clustering,Mutual Information for clustering,,"I'm working on a document clustering application and decided to use Normalized Mutual Information as one of the measures of effectivenes. But I don't really understand how to implement this in that situation. In http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html the the formula is transformed to (185), and in this publication (www.shi-zhong.com/papers/comptext2.pdf‎, page 8, formula 17) it looks slightly different, n(h,l) is not divided by total number of documents N. So, which formula is correct? I would be very grateful for possibly simple explantation.","I'm working on a document clustering application and decided to use Normalized Mutual Information as one of the measures of effectivenes. But I don't really understand how to implement this in that situation. In http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html the the formula is transformed to (185), and in this publication (www.shi-zhong.com/papers/comptext2.pdf‎, page 8, formula 17) it looks slightly different, n(h,l) is not divided by total number of documents N. So, which formula is correct? I would be very grateful for possibly simple explantation.",,"['statistics', 'data-analysis', 'pattern-recognition', 'clustering', 'data-mining']"
7,Can Fisher Information be negative?,Can Fisher Information be negative?,,"Can $$I(\theta) = -E\left[\frac{\partial^2}{\partial\theta^2} \ln f(x,\theta)\right] = 0$$ I've heard that Fisher's Information is strictly greater than zero but I'm unsure why. A proof would be much appreciated!","Can $$I(\theta) = -E\left[\frac{\partial^2}{\partial\theta^2} \ln f(x,\theta)\right] = 0$$ I've heard that Fisher's Information is strictly greater than zero but I'm unsure why. A proof would be much appreciated!",,['statistics']
8,Moment Generating Function for a discrete random distribution,Moment Generating Function for a discrete random distribution,,"(Discrete uniform distribution) A discrete random variable is said to be uniformly distributed if it assumes a nite number of values with each value occurring with the same probability. If we consider the generation of a single random digits, then $Y$ , the number generated, is uniformly distributed with each possible digit,$ 0, 1, 2, ... , 9$ occurring with probability $\frac{1}{10}.$ In general, the density for a uniformly distributed random variable X is given by $f(x) = 1=n , \text{ where : n is a postive integer and }  x = x_1, x_2, ... , x_n$ Find the moment generating function for the discrete uniform random variable X. I don't know how to approach this with what I have from class... all I can come up with is $m(t) = \text{ (sum) } e^{tx} \frac{(1)}{(n)}$ which I know is complete rubbish. I am grasping so little of this so any assistance in what a moment generating function is and the concepts needed for this question would be greatly appreciated.","(Discrete uniform distribution) A discrete random variable is said to be uniformly distributed if it assumes a nite number of values with each value occurring with the same probability. If we consider the generation of a single random digits, then $Y$ , the number generated, is uniformly distributed with each possible digit,$ 0, 1, 2, ... , 9$ occurring with probability $\frac{1}{10}.$ In general, the density for a uniformly distributed random variable X is given by $f(x) = 1=n , \text{ where : n is a postive integer and }  x = x_1, x_2, ... , x_n$ Find the moment generating function for the discrete uniform random variable X. I don't know how to approach this with what I have from class... all I can come up with is $m(t) = \text{ (sum) } e^{tx} \frac{(1)}{(n)}$ which I know is complete rubbish. I am grasping so little of this so any assistance in what a moment generating function is and the concepts needed for this question would be greatly appreciated.",,['statistics']
9,What is the difference between MVUE and UMVUE,What is the difference between MVUE and UMVUE,,"I was going through the minimum variance unbiased estimators and I am confused about the concept of MVUE and UMVUE. Is the unbiased estimator whose variance attaining CRLB a UMVUE or MVUE? I referred two books. One of those(A first course on parametric inference by B.K.Kale ) says that the unbiased estimator attaining CRLB is MVUE and the other(An introduction to probability and statistics by Rohatgi) says that it is UMVUE. So, are they same?","I was going through the minimum variance unbiased estimators and I am confused about the concept of MVUE and UMVUE. Is the unbiased estimator whose variance attaining CRLB a UMVUE or MVUE? I referred two books. One of those(A first course on parametric inference by B.K.Kale ) says that the unbiased estimator attaining CRLB is MVUE and the other(An introduction to probability and statistics by Rohatgi) says that it is UMVUE. So, are they same?",,"['statistics', 'statistical-inference', 'parameter-estimation']"
10,Why can we not accept the alternate hypothesis in Chi Squared Testing?,Why can we not accept the alternate hypothesis in Chi Squared Testing?,,"I'm a math teacher, but this aspect of stats is not my strong point.  I've asked several other teachers as to why, and their responses was just ""don't do it"" the why was not very compelling, so I come here. $H_\text{null}$ = $m$ and $n$ are independent. $H_\text{alt}$ = $m$ and $n$ are NOT independent. If condition $p$ is met, we accept the null hypothesis. If condition $p$ is not met, we reject the null hypothesis. Isn't the rejection of the null hypothesis logically equivalent to the alt hypothesis?   Isn't the negation of ( $m$ and $n$ are independent) = ( $m$ and $n$ are Not independent)? Thank you kindly for your response.","I'm a math teacher, but this aspect of stats is not my strong point.  I've asked several other teachers as to why, and their responses was just ""don't do it"" the why was not very compelling, so I come here. = and are independent. = and are NOT independent. If condition is met, we accept the null hypothesis. If condition is not met, we reject the null hypothesis. Isn't the rejection of the null hypothesis logically equivalent to the alt hypothesis?   Isn't the negation of ( and are independent) = ( and are Not independent)? Thank you kindly for your response.",H_\text{null} m n H_\text{alt} m n p p m n m n,"['statistics', 'logic', 'hypothesis-testing', 'chi-squared']"
11,UMVUE for $e^{-\lambda}$,UMVUE for,e^{-\lambda},"Let $X_1\dots,X_n$ be $Poisson(\lambda)$ . Show that $$T= \left( \frac{n-1}{n} \right)^{\sum_{i=1}^{n}X_i}$$ is an UMVUE for $e^{-\lambda}$ I know that $\sum_{i=1}^{n}X_i$ it is a sufficient and complete statistic since the distribution belongs to the exponential family. But I don't know how to go on to show that $T$ is an UMVUE. Any hint?",Let be . Show that is an UMVUE for I know that it is a sufficient and complete statistic since the distribution belongs to the exponential family. But I don't know how to go on to show that is an UMVUE. Any hint?,"X_1\dots,X_n Poisson(\lambda) T= \left( \frac{n-1}{n} \right)^{\sum_{i=1}^{n}X_i} e^{-\lambda} \sum_{i=1}^{n}X_i T","['statistics', 'means']"
12,Difference between Random Variable and Scalar random variable,Difference between Random Variable and Scalar random variable,,"Can anybody explain the basic difference between Random Variable and Scalar random variable. I know it's a silly doubt, But I couldn't find the answer on internet.","Can anybody explain the basic difference between Random Variable and Scalar random variable. I know it's a silly doubt, But I couldn't find the answer on internet.",,"['statistics', 'random-variables']"
13,Sampling Distribution of sample mean for Poisson Distribution,Sampling Distribution of sample mean for Poisson Distribution,,"I am particularly struggling with part b, I don't know where to begin. For part a, I think the answer is that the sampling distribution is a Poisson(n$\lambda$).","I am particularly struggling with part b, I don't know where to begin. For part a, I think the answer is that the sampling distribution is a Poisson(n$\lambda$).",,['statistics']
14,Prove that Standard Deviation is always $\geq$ Mean Absolute Deviation,Prove that Standard Deviation is always  Mean Absolute Deviation,\geq,"Where $$s = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2}$$ and  $$ M = \frac{1}{n} \sum_{i=1}^{n} |x_i - \bar{x}|$$ I came up with a sketchy proof for the case of $2$ values, but I would like a way to generalize (my ""proof"" unfortunately doesn't, as far as I can tell). Proof for $2$ values (I would appreciate feedback on this as well): $$\frac{1}{\sqrt{2}} \sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2} \geq \frac{1}{2} (|x_1- \bar{x}| + |x_2- \bar{x}|)$$ Now let $|x_1- \bar{x}| = a$ and $|x_2- \bar{x}| = b$ be the $2$ legs of a right triangle and $\sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2} = c$ its hypothenuse. And let $\theta$ be the angle between $c$ and either $a$ or $b$. Then $(\sin{\theta} + \cos{\theta}) = \frac{a}{c} + \frac{b}{c} = \frac{a+b}{c} = \frac{\frac{1}{2} (|x_1- \bar{x}| + |x_2- \bar{x}|)}{\frac{1}{\sqrt{2}} \sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2}}$ so that $$ \sqrt{2} \geq (\sin{\theta} + \cos{\theta})$$ And we know that $\max(\sin{\theta} + \cos{\theta}) = \sqrt{2}$. QED? I have no idea how to prove the general case, though .","Where $$s = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2}$$ and  $$ M = \frac{1}{n} \sum_{i=1}^{n} |x_i - \bar{x}|$$ I came up with a sketchy proof for the case of $2$ values, but I would like a way to generalize (my ""proof"" unfortunately doesn't, as far as I can tell). Proof for $2$ values (I would appreciate feedback on this as well): $$\frac{1}{\sqrt{2}} \sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2} \geq \frac{1}{2} (|x_1- \bar{x}| + |x_2- \bar{x}|)$$ Now let $|x_1- \bar{x}| = a$ and $|x_2- \bar{x}| = b$ be the $2$ legs of a right triangle and $\sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2} = c$ its hypothenuse. And let $\theta$ be the angle between $c$ and either $a$ or $b$. Then $(\sin{\theta} + \cos{\theta}) = \frac{a}{c} + \frac{b}{c} = \frac{a+b}{c} = \frac{\frac{1}{2} (|x_1- \bar{x}| + |x_2- \bar{x}|)}{\frac{1}{\sqrt{2}} \sqrt{(x_1 - \bar{x})^2 + (x_2 - \bar{x})^2}}$ so that $$ \sqrt{2} \geq (\sin{\theta} + \cos{\theta})$$ And we know that $\max(\sin{\theta} + \cos{\theta}) = \sqrt{2}$. QED? I have no idea how to prove the general case, though .",,"['statistics', 'inequality', 'solution-verification', 'proof-explanation', 'standard-deviation']"
15,Confusion about the sample mean and random variables,Confusion about the sample mean and random variables,,"As I understand the sample mean you just add a bunch of random variables that constitute a sample from their common distribution and divide by the number of those same random variables. When I apply it in actual problems I get specific numbers from the population and take their mean. This confuses me as I thought that when you add random variables it represents adding all the possible outcomes of those random variables. So my understanding of adding random variables is that if you had random variables $X$ and $Y$, that could take on the values $1$ and $2$, $X + Y$ represents $1+1$, $1+2$, $2+1$, $2+2$. Thus I feel that the definition of a sample mean clashes with it's application where you just take specific values from the population and add them up. I hope that makes sense.","As I understand the sample mean you just add a bunch of random variables that constitute a sample from their common distribution and divide by the number of those same random variables. When I apply it in actual problems I get specific numbers from the population and take their mean. This confuses me as I thought that when you add random variables it represents adding all the possible outcomes of those random variables. So my understanding of adding random variables is that if you had random variables $X$ and $Y$, that could take on the values $1$ and $2$, $X + Y$ represents $1+1$, $1+2$, $2+1$, $2+2$. Thus I feel that the definition of a sample mean clashes with it's application where you just take specific values from the population and add them up. I hope that makes sense.",,"['statistics', 'random-variables']"
16,Is there a concept of asymptotically independent random variables?,Is there a concept of asymptotically independent random variables?,,"To prove some results using a standard theorem I need my random variables to be i.i.d. However, my random variables are discrete uniforms emerging from a rank statistics, i.e. not independent: for two $u_1$,$u_2$ knowing $u_1$ gives me $u_2$. Yet, my interest is in the asymptotics for ($u_i$) growing infinitely large, and thus these r.v. are becoming more and more independent. Is there a concept to formalize this idea? Is this standard? Can I have an entry point in the literature?","To prove some results using a standard theorem I need my random variables to be i.i.d. However, my random variables are discrete uniforms emerging from a rank statistics, i.e. not independent: for two $u_1$,$u_2$ knowing $u_1$ gives me $u_2$. Yet, my interest is in the asymptotics for ($u_i$) growing infinitely large, and thus these r.v. are becoming more and more independent. Is there a concept to formalize this idea? Is this standard? Can I have an entry point in the literature?",,"['statistics', 'asymptotics', 'random-variables', 'uniform-distribution']"
17,correlation between $\sum_{i=1}^{98}X_i$ and $\sum_{i=3}^{100}X_i$,correlation between  and,\sum_{i=1}^{98}X_i \sum_{i=3}^{100}X_i,"Let $X_1,...,X_{100}$ be iid $N(0,1)$ random variables. The correlation between $\sum\limits_{i=1}^{98}X_i$ and $\sum\limits_{i=3}^{100}X_i$ is equal to (A) $0$ (B) $\dfrac{96}{98}$ (C) $\dfrac{98}{100}$ (D) 1 My Steps: $96$ of these $98$ variables of each series have the same value . So, B should be the correct option. Did I solve this correctly ? Please help me confirm my solution.","Let $X_1,...,X_{100}$ be iid $N(0,1)$ random variables. The correlation between $\sum\limits_{i=1}^{98}X_i$ and $\sum\limits_{i=3}^{100}X_i$ is equal to (A) $0$ (B) $\dfrac{96}{98}$ (C) $\dfrac{98}{100}$ (D) 1 My Steps: $96$ of these $98$ variables of each series have the same value . So, B should be the correct option. Did I solve this correctly ? Please help me confirm my solution.",,"['statistics', 'random-variables', 'normal-distribution', 'correlation']"
18,$X<Y$ implies $E[X]<E[Y]$?,implies ?,X<Y E[X]<E[Y],I just read a proof in a text that first established that $$(X-\mu_X)(Y-\mu_Y)\le \frac12\left[(X-\mu_X)^2+(Y-\mu_Y)^2\right]$$ then took the expectation of both sides of the inequality. $$E[(X-\mu_X)(Y-\mu_Y)]\le \frac12E\left[(X-\mu_X)^2+(Y-\mu_Y)^2\right]$$ How is taking the expectation of both sides of the inequality justified?,I just read a proof in a text that first established that $$(X-\mu_X)(Y-\mu_Y)\le \frac12\left[(X-\mu_X)^2+(Y-\mu_Y)^2\right]$$ then took the expectation of both sides of the inequality. $$E[(X-\mu_X)(Y-\mu_Y)]\le \frac12E\left[(X-\mu_X)^2+(Y-\mu_Y)^2\right]$$ How is taking the expectation of both sides of the inequality justified?,,['statistics']
19,Estimating a gaussian distribution from a GMM,Estimating a gaussian distribution from a GMM,,"Suppose that we have a Gaussian mixture model (GMM) in n-dimensional space: $$P_1(x) = \sum_{i=1}^{C}\pi(c_i)\mathcal{N}(\mu_i,\Sigma_i)$$ We want to estimate a single Gaussian distribution from this set. $$P_2(x) = \mathcal{N}(\mu,\Sigma)$$ For example, suppose that we have a GMM (having two Gaussians) like this: And want to convert it into a single Gaussian distribution: Such a way that the distribution of the Gaussian is as close as possible to the original GMM. In other words, if you sample a very large number of samples from $P_1(x)$, the most likely Gaussian for those points should be (close to) $P_2(x)$. How can I estimate $\mu$ and $\Sigma$ for $P_2(x)$??? IMPORTANT NOTE: The dimensions are above 2, so we should deal with the covariance matrix, not a set of independent variances. Important notice: I don't want to re-generate data from $P_1(x)$ to estimate $P_1(x)$. Instead, I want to estimate $P_2(x)$ (Gaussian) using the parameters in $P_1(x)$ (GMM).","Suppose that we have a Gaussian mixture model (GMM) in n-dimensional space: $$P_1(x) = \sum_{i=1}^{C}\pi(c_i)\mathcal{N}(\mu_i,\Sigma_i)$$ We want to estimate a single Gaussian distribution from this set. $$P_2(x) = \mathcal{N}(\mu,\Sigma)$$ For example, suppose that we have a GMM (having two Gaussians) like this: And want to convert it into a single Gaussian distribution: Such a way that the distribution of the Gaussian is as close as possible to the original GMM. In other words, if you sample a very large number of samples from $P_1(x)$, the most likely Gaussian for those points should be (close to) $P_2(x)$. How can I estimate $\mu$ and $\Sigma$ for $P_2(x)$??? IMPORTANT NOTE: The dimensions are above 2, so we should deal with the covariance matrix, not a set of independent variances. Important notice: I don't want to re-generate data from $P_1(x)$ to estimate $P_1(x)$. Instead, I want to estimate $P_2(x)$ (Gaussian) using the parameters in $P_1(x)$ (GMM).",,"['statistics', 'normal-distribution', 'estimation', 'parameter-estimation']"
20,What is the difference between distribution and dispersion?,What is the difference between distribution and dispersion?,,"I need to explain the difference between a distribution (Normal, Chi-square, Poisson, etc.) and Dispersion (as measured by variance, standard deviation) to some students. What is the simplest explanation? Thanks in advance.","I need to explain the difference between a distribution (Normal, Chi-square, Poisson, etc.) and Dispersion (as measured by variance, standard deviation) to some students. What is the simplest explanation? Thanks in advance.",,"['statistics', 'normal-distribution']"
21,Bernoulli Random Variables and Variance,Bernoulli Random Variables and Variance,,"The question is: Suppose $Z_1, Z_2, \ldots $ are iid $\operatorname{Bernoulli}\left(\frac{1}{2}\right)$ and let $S_n = Z_1 + \ldots +Z_n$. Let $T$ denote the smallest $n$ such that $S_n = 3$. Calculate $\operatorname{Var}(T)$. What I know is that $\operatorname{Var}(T) = E(T^2) - E(T)^2$ but I am not sure how to calculate the expectation from the given information. Perhaps need to go through moment-generating function and the formula $M^{(r)}(0) = E(X^r)$?","The question is: Suppose $Z_1, Z_2, \ldots $ are iid $\operatorname{Bernoulli}\left(\frac{1}{2}\right)$ and let $S_n = Z_1 + \ldots +Z_n$. Let $T$ denote the smallest $n$ such that $S_n = 3$. Calculate $\operatorname{Var}(T)$. What I know is that $\operatorname{Var}(T) = E(T^2) - E(T)^2$ but I am not sure how to calculate the expectation from the given information. Perhaps need to go through moment-generating function and the formula $M^{(r)}(0) = E(X^r)$?",,"['statistics', 'probability-distributions', 'random-variables']"
22,Does the Least Squares Regression Method work for any line type?,Does the Least Squares Regression Method work for any line type?,,"I recently learned how to apply the least squares method to do linear regression. I also understand that it can be used for quadratic regression, by minimizing the error for three variables, two coefficients and a constant, instead of two variables. Would the same method apply to most, or all, types of equations? Could I simply assume coefficients wherever possible, and a constant, then find the partial derivative with respect to each, then set them equal to zero and solve? For example, could I regress to *a*log(*b*x)+ c ? Could I use logarithms, sine waves, exponential function, etc? If not, what are the exceptions? Where is this method not possible? Why? Thanks in advance for all responses.","I recently learned how to apply the least squares method to do linear regression. I also understand that it can be used for quadratic regression, by minimizing the error for three variables, two coefficients and a constant, instead of two variables. Would the same method apply to most, or all, types of equations? Could I simply assume coefficients wherever possible, and a constant, then find the partial derivative with respect to each, then set them equal to zero and solve? For example, could I regress to *a*log(*b*x)+ c ? Could I use logarithms, sine waves, exponential function, etc? If not, what are the exceptions? Where is this method not possible? Why? Thanks in advance for all responses.",,"['calculus', 'statistics', 'regression']"
23,A question about a proof of Neyman's factorization theorem,A question about a proof of Neyman's factorization theorem,,"This question comes from the proof of Neyman's factorization theorem in Robert V. Hogg, Joseph W. McKean, Allen T. Craig, ""Introduction to Mathematical Statistics"", 6th edition, pp 376-377. In the proof, a one-to-one transformation is used which is indicated by the red line. But I could not understand why such a one-to-one transformation surely exists. Can you tell me? Thank you for any help!","This question comes from the proof of Neyman's factorization theorem in Robert V. Hogg, Joseph W. McKean, Allen T. Craig, ""Introduction to Mathematical Statistics"", 6th edition, pp 376-377. In the proof, a one-to-one transformation is used which is indicated by the red line. But I could not understand why such a one-to-one transformation surely exists. Can you tell me? Thank you for any help!",,['statistics']
24,In what situations should I use and not use a pooled estimator for $\hat{p}$,In what situations should I use and not use a pooled estimator for,\hat{p},"In a question, it says that a true-false exam is used to discriminate between well-prepared students and poorly prepared students. There are $\frac{205}{250}$ well-prepared students and $\frac{137}{250}$ poorly prepared students who answered a certain item in the exam correctly. The goal is to do a hypothesis test to see whether the given item in the test that is answered correctly can be expected to be at least $15\%$ higher among well-prepared students than among poorly prepared students. So, $p_1=\frac{205}{250}$ and $p_2=\frac{137}{250}$. $H_0: p_1-p_2=0.15\\H_1:p_1-p_2 > 0.15$ I know I could just use the formula: $$Z=\frac { p_{ 1 }-p_{ 2 }-\delta  }{ \sqrt { \frac { p_{ 1 }(1-p_{ 1 }) }{ n_{ 1 } } +\frac { p_{ 2 }(1-p_{ 2 }) }{ n_{ 2 } }  }  } $$ But there is something here that I am very confuse about and that is: should I use a pooled estimator for a $\hat { p } $? The two values of $p_1$ and $p_2$ are merely sample proportions and are not the true population proportion. In a usual two-proportion hypothesis, I would just use a pooled estimator for a $\hat{p}$ to get the ${ \sigma  }_{ \hat { p }  }$. So, what I would do is: $ \hat { p } =\frac { X_{ 1 }+X_{ 2 } }{ n_{ 1 }+n_{ 2 } } =\frac { 205+137 }{ 250+250 } =\frac { 171 }{ 250 } \\ { \sigma  }_{ \hat { p }  }=\sqrt { \frac { \hat { p } (1-\hat { p } ) }{ n_{ 1 } } +\frac { \hat { p } (1-\hat { p } ) }{ n_{ 2 } }  } =\sqrt { \frac { \frac { 171 }{ 250 } (1-\frac { 171 }{ 250 } ) }{ 250 } +\frac { \frac { 171 }{ 250 } (1-\frac { 171 }{ 250 } ) }{ 250 }  } =0.04158\\ Z=\frac { \frac { 205 }{ 250 } -\frac { 137 }{ 250 } -0.15 }{ { \sigma  }_{ \hat { p }  } } =2.9341 $ However, the answer given to this question did not utilise the pooled estimator. Instead, it just uses back the sample proportion for the ${ \sigma  }_{ \hat { p }  }$. So, the answer given is written this way: $ { \sigma  }_{ \hat { p_1 } -\hat{p_2} }=\sqrt { \frac { p_{ 1 }(1-p_{ 1 }) }{ n_{ 1 } } +\frac { p_{ 2 }(1-p_{ 2 }) }{ n_{ 2 } }  } =\sqrt { \frac { \frac { 205 }{ 250 } (1-\frac { 205 }{ 250 } ) }{ 250 } +\frac { \frac { 137 }{ 250 } (1-\frac { 137 }{ 250 } ) }{ 250 }  } =0.03976\\ Z=\frac { \frac { 205 }{ 250 } -\frac { 137 }{ 250 } -0.15 }{ { \sigma  }_{ \hat { p_1 } -\hat{p_2} } } =3.0684 $ Should I use a pooled estimator for $\hat{p}$ in this case? From my understanding, I use the pooled estimator for $\hat{p}$ when I don't have the true population proportion values. In this question, the given values are only the sampled proportions. But often, I wouldn't know the true population proportion values in the first place and therefore, I would always end up using the pooled estimator if I rely on my understanding. So, in what situation should I then be using a pooled estimator and what other situation should I then not be using a pooled estimator?","In a question, it says that a true-false exam is used to discriminate between well-prepared students and poorly prepared students. There are $\frac{205}{250}$ well-prepared students and $\frac{137}{250}$ poorly prepared students who answered a certain item in the exam correctly. The goal is to do a hypothesis test to see whether the given item in the test that is answered correctly can be expected to be at least $15\%$ higher among well-prepared students than among poorly prepared students. So, $p_1=\frac{205}{250}$ and $p_2=\frac{137}{250}$. $H_0: p_1-p_2=0.15\\H_1:p_1-p_2 > 0.15$ I know I could just use the formula: $$Z=\frac { p_{ 1 }-p_{ 2 }-\delta  }{ \sqrt { \frac { p_{ 1 }(1-p_{ 1 }) }{ n_{ 1 } } +\frac { p_{ 2 }(1-p_{ 2 }) }{ n_{ 2 } }  }  } $$ But there is something here that I am very confuse about and that is: should I use a pooled estimator for a $\hat { p } $? The two values of $p_1$ and $p_2$ are merely sample proportions and are not the true population proportion. In a usual two-proportion hypothesis, I would just use a pooled estimator for a $\hat{p}$ to get the ${ \sigma  }_{ \hat { p }  }$. So, what I would do is: $ \hat { p } =\frac { X_{ 1 }+X_{ 2 } }{ n_{ 1 }+n_{ 2 } } =\frac { 205+137 }{ 250+250 } =\frac { 171 }{ 250 } \\ { \sigma  }_{ \hat { p }  }=\sqrt { \frac { \hat { p } (1-\hat { p } ) }{ n_{ 1 } } +\frac { \hat { p } (1-\hat { p } ) }{ n_{ 2 } }  } =\sqrt { \frac { \frac { 171 }{ 250 } (1-\frac { 171 }{ 250 } ) }{ 250 } +\frac { \frac { 171 }{ 250 } (1-\frac { 171 }{ 250 } ) }{ 250 }  } =0.04158\\ Z=\frac { \frac { 205 }{ 250 } -\frac { 137 }{ 250 } -0.15 }{ { \sigma  }_{ \hat { p }  } } =2.9341 $ However, the answer given to this question did not utilise the pooled estimator. Instead, it just uses back the sample proportion for the ${ \sigma  }_{ \hat { p }  }$. So, the answer given is written this way: $ { \sigma  }_{ \hat { p_1 } -\hat{p_2} }=\sqrt { \frac { p_{ 1 }(1-p_{ 1 }) }{ n_{ 1 } } +\frac { p_{ 2 }(1-p_{ 2 }) }{ n_{ 2 } }  } =\sqrt { \frac { \frac { 205 }{ 250 } (1-\frac { 205 }{ 250 } ) }{ 250 } +\frac { \frac { 137 }{ 250 } (1-\frac { 137 }{ 250 } ) }{ 250 }  } =0.03976\\ Z=\frac { \frac { 205 }{ 250 } -\frac { 137 }{ 250 } -0.15 }{ { \sigma  }_{ \hat { p_1 } -\hat{p_2} } } =3.0684 $ Should I use a pooled estimator for $\hat{p}$ in this case? From my understanding, I use the pooled estimator for $\hat{p}$ when I don't have the true population proportion values. In this question, the given values are only the sampled proportions. But often, I wouldn't know the true population proportion values in the first place and therefore, I would always end up using the pooled estimator if I rely on my understanding. So, in what situation should I then be using a pooled estimator and what other situation should I then not be using a pooled estimator?",,['statistics']
25,What is the relationship between the Poisson Distribution and the Monte Carlo Fallacy?,What is the relationship between the Poisson Distribution and the Monte Carlo Fallacy?,,"Gravity's Rainbow has this long passage about the Poisson distribution. Since Pynchon's education included a serious dose of mathematics, and his novels include many references to mathematics, I assume what the characters are saying to each other must make some sort of sense, i.e. must have a formulation in mathematical language. But what exactly are they describing? What is the Monte Carlo Fallacy, and what does it have to do with the Poisson Distribution? The two characters are looking at a grid which represents London. Places where bombs have hit are marked on the grid. Further up in the dialogue, the grid is compared to a sieve the Romans would have used for fortune-telling. ""Can't you . . . tell,"" Pointsman offering Mexico one of his Kyprinos Orients, which he guards in secret fag fobs sewn inside all his lab coats, ""from your map here, which places would be safest to go into, safest from attack?"" ""No."" ""But surely!"" ""Every square is just as likely to get hit again. The hits aren't clustering. Mean density is constant."" Nothing on the map to the contrary. Only a classical Poisson distribution, quietly neatly sifting among the squares exactly as it should . . . growing to its predicted shape. . . . ""But squares that have already had several hits, I mean!"" ""I'm sorry. That's the Monte Carlo Fallacy. No matter how many have fallen inside a particular square, the odds remain the same as they always were. Each hit is independent of all the others. Bombs are not dogs. No link. No memory. No conditioning.""","Gravity's Rainbow has this long passage about the Poisson distribution. Since Pynchon's education included a serious dose of mathematics, and his novels include many references to mathematics, I assume what the characters are saying to each other must make some sort of sense, i.e. must have a formulation in mathematical language. But what exactly are they describing? What is the Monte Carlo Fallacy, and what does it have to do with the Poisson Distribution? The two characters are looking at a grid which represents London. Places where bombs have hit are marked on the grid. Further up in the dialogue, the grid is compared to a sieve the Romans would have used for fortune-telling. ""Can't you . . . tell,"" Pointsman offering Mexico one of his Kyprinos Orients, which he guards in secret fag fobs sewn inside all his lab coats, ""from your map here, which places would be safest to go into, safest from attack?"" ""No."" ""But surely!"" ""Every square is just as likely to get hit again. The hits aren't clustering. Mean density is constant."" Nothing on the map to the contrary. Only a classical Poisson distribution, quietly neatly sifting among the squares exactly as it should . . . growing to its predicted shape. . . . ""But squares that have already had several hits, I mean!"" ""I'm sorry. That's the Monte Carlo Fallacy. No matter how many have fallen inside a particular square, the odds remain the same as they always were. Each hit is independent of all the others. Bombs are not dogs. No link. No memory. No conditioning.""",,"['statistics', 'monte-carlo', 'popular-math']"
26,Why are samples always taken from iid random variables?,Why are samples always taken from iid random variables?,,"In most mathematical statistic textbook problems, a question always ask: Given you have $X_1, X_2, \ldots, X_n$ iid from a random sample with pdf:(some pdf). My question is why can't the sample come from one random variable such as $X_1$ since $X_1$ itself is a random variable. Why do you need the sample to come from multiple iid random variables?","In most mathematical statistic textbook problems, a question always ask: Given you have $X_1, X_2, \ldots, X_n$ iid from a random sample with pdf:(some pdf). My question is why can't the sample come from one random variable such as $X_1$ since $X_1$ itself is a random variable. Why do you need the sample to come from multiple iid random variables?",,['statistics']
27,Statistics: Predict 90th percentile with small sample set,Statistics: Predict 90th percentile with small sample set,,"I have a quite small data set (on the order of 8-20) from an essentially unknown system and would like to predict a value that will be higher than the next number generated by the same system 90% of the time. Both underestimation and overestimation are problematic. What is the mathematically ""correct"" way to do this? If I could also generate a level-of-confidence estimate, it would wow my manager. Also, let me say I'm not a math major, so thanks for any help, however remedial it may be :)","I have a quite small data set (on the order of 8-20) from an essentially unknown system and would like to predict a value that will be higher than the next number generated by the same system 90% of the time. Both underestimation and overestimation are problematic. What is the mathematically ""correct"" way to do this? If I could also generate a level-of-confidence estimate, it would wow my manager. Also, let me say I'm not a math major, so thanks for any help, however remedial it may be :)",,['statistics']
28,Gamma Distribution Moments,Gamma Distribution Moments,,"Problem. Show that for $X \sim \text{Gamma}(\alpha, \beta)$ , for positive constant $\nu$ , $$ E[X^\nu] = \frac{\beta^\nu \Gamma(\nu + \alpha)}{\Gamma(\alpha)} . $$ I have the following solution: However, I don't understand how we get that $$ \frac{1}{\Gamma(\alpha)\beta^\alpha} \int_{0}^{\infty}x^{(\nu+\alpha)-1}e^{-x/\beta} \, \mathrm{d}x = \frac{\Gamma(\nu+\alpha)\beta^{\nu+\alpha}}{\Gamma(\alpha)\beta^{\alpha}} $$ Would appreciate any help on how this step was completed. Basically, I don't understand how: $$ \int_{0}^{\infty} x^{(\nu+\alpha)-1}e^{-x/\beta} \, \mathrm{d}x = \Gamma(\nu+\alpha)\beta^{\nu+\alpha}. $$ I see that the left side is close to the definition of the Gamma function, but can't see how exactly to turn it into the right side.","Problem. Show that for , for positive constant , I have the following solution: However, I don't understand how we get that Would appreciate any help on how this step was completed. Basically, I don't understand how: I see that the left side is close to the definition of the Gamma function, but can't see how exactly to turn it into the right side.","X \sim \text{Gamma}(\alpha, \beta) \nu  E[X^\nu] = \frac{\beta^\nu \Gamma(\nu + \alpha)}{\Gamma(\alpha)} .   \frac{1}{\Gamma(\alpha)\beta^\alpha} \int_{0}^{\infty}x^{(\nu+\alpha)-1}e^{-x/\beta} \, \mathrm{d}x
= \frac{\Gamma(\nu+\alpha)\beta^{\nu+\alpha}}{\Gamma(\alpha)\beta^{\alpha}}   \int_{0}^{\infty} x^{(\nu+\alpha)-1}e^{-x/\beta} \, \mathrm{d}x = \Gamma(\nu+\alpha)\beta^{\nu+\alpha}. ","['statistics', 'probability-distributions', 'statistical-inference', 'gamma-distribution']"
29,Addition Rule for Expectations,Addition Rule for Expectations,,"Why does the addition rule for expectations work no matter if the sub-events involved is independent or dependent? For example: Let $X$ be the number of aces in a 5-card poker hand. The probability   that any particular card is an ace is $\frac{4}{52}$, so the expected   number of aces among 5 cards dealt from a well-shuffled deck is $E(X) = \frac{4}{52} + \frac{4}{52} + \frac{4}{52} + \frac{4}{52} + \frac{4}{52} = 5/13$ Considering the draws are without replacement, why are the probability constant here? Reference:","Why does the addition rule for expectations work no matter if the sub-events involved is independent or dependent? For example: Let $X$ be the number of aces in a 5-card poker hand. The probability   that any particular card is an ace is $\frac{4}{52}$, so the expected   number of aces among 5 cards dealt from a well-shuffled deck is $E(X) = \frac{4}{52} + \frac{4}{52} + \frac{4}{52} + \frac{4}{52} + \frac{4}{52} = 5/13$ Considering the draws are without replacement, why are the probability constant here? Reference:",,['statistics']
30,derivative of generating function for calculating expected value intuition,derivative of generating function for calculating expected value intuition,,"I'm currently studying discrete random variables and I am on using generating functions for calculating the expected value. Given that a generating function is a polynomial of the following kind $g_x(s)=\sum_{k=0}^n P(X=k)s^k$, where the coefficient in front the kth power of s is the probability that the random variable X equals k, we can calculate the expected value for the discrete random variable using the derivative of the generating function at 1. $ EX = g_x'(1) $ I understand the proof for this, but I can't seem to get the intuition behind it. My questions are : What is the intuitive understanding of this? How was this result achieved? Is there a visual way to interpret the statement? The generating function is a polynomial, so how come the first derivative is EX and for the variance is $g''_x(1)+g'_x(1)−g'_x(1)^2$? If getting intuition for this statement requires more work, what prerequisite theory would you advice me to get to in order to understand it? Thanks in advance!","I'm currently studying discrete random variables and I am on using generating functions for calculating the expected value. Given that a generating function is a polynomial of the following kind $g_x(s)=\sum_{k=0}^n P(X=k)s^k$, where the coefficient in front the kth power of s is the probability that the random variable X equals k, we can calculate the expected value for the discrete random variable using the derivative of the generating function at 1. $ EX = g_x'(1) $ I understand the proof for this, but I can't seem to get the intuition behind it. My questions are : What is the intuitive understanding of this? How was this result achieved? Is there a visual way to interpret the statement? The generating function is a polynomial, so how come the first derivative is EX and for the variance is $g''_x(1)+g'_x(1)−g'_x(1)^2$? If getting intuition for this statement requires more work, what prerequisite theory would you advice me to get to in order to understand it? Thanks in advance!",,"['statistics', 'random-variables', 'intuition', 'generating-functions']"
31,"The difference between the Frequentist, Bayesian and Fisherian appraoches to statistical inference [closed]","The difference between the Frequentist, Bayesian and Fisherian appraoches to statistical inference [closed]",,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I'm just trying to get my head around the differences between these three approaches to statistical inference. I'm just not entirely sure what the significant differences are between the three.,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I'm just trying to get my head around the differences between these three approaches to statistical inference. I'm just not entirely sure what the significant differences are between the three.,,"['statistics', 'statistical-inference', 'bayesian']"
32,Is a $90\%$ confidence interval really $90\%$ confident?,Is a  confidence interval really  confident?,90\% 90\%,"Let's say you are estimating a population proportion, which you model as binomial. One source of error already is using the normal approximation to the binomial when getting your critical values. But what bothers me more is that the theoretically sound interval uses the true population proportion in computation of the interval width. This is usually approximated by the sample proportion, but doesn't this no longer make the confidence level accurate? (It seems like a pretty Bayesian assumption for a frequentist approach to get away with.) As a common tactic, I see people use the upper bound for the population variance (by assuming the proportion is $1/2$), and use that to determine their intervals. Is this preferable to using the sample proportion to estimate the population variance? At least in this upper bounding case, we can say with mathematical soundness, that our confidence level is at least $90\%$confident (assuming normal perfectly approximates binomial).","Let's say you are estimating a population proportion, which you model as binomial. One source of error already is using the normal approximation to the binomial when getting your critical values. But what bothers me more is that the theoretically sound interval uses the true population proportion in computation of the interval width. This is usually approximated by the sample proportion, but doesn't this no longer make the confidence level accurate? (It seems like a pretty Bayesian assumption for a frequentist approach to get away with.) As a common tactic, I see people use the upper bound for the population variance (by assuming the proportion is $1/2$), and use that to determine their intervals. Is this preferable to using the sample proportion to estimate the population variance? At least in this upper bounding case, we can say with mathematical soundness, that our confidence level is at least $90\%$confident (assuming normal perfectly approximates binomial).",,"['statistics', 'confidence-interval']"
33,Standard deviation of the product of gaussians,Standard deviation of the product of gaussians,,What is the standard deviation of the product of two random variables that each have Gaussian Distributions? I don't even know where to begin on this problem.,What is the standard deviation of the product of two random variables that each have Gaussian Distributions? I don't even know where to begin on this problem.,,"['statistics', 'standard-deviation']"
34,What real life statistician's job look like?,What real life statistician's job look like?,,"I have recently finished statistics course and would like to know if statisticians really do what we covered in the course (usual college level stat course material). The course made me interested in statstician's work. But I have questions, that are not answered in simple "" statistician's work description "". Does your job consist more of checking using t- and F-tests, etc.? Or is it closer to academic tyoe like trying to find the way to reduce bias, etc.? For example (dumb example), if you are testing accuracy of predictions are you considering going deep into assumptions made by the predictors (e.g. constant prices,etc.)? Basically, if you are statistician, could you please share with me (us, at stackexchange) your work routine (I mean things one would not see in typical ""statistician's work description"")?","I have recently finished statistics course and would like to know if statisticians really do what we covered in the course (usual college level stat course material). The course made me interested in statstician's work. But I have questions, that are not answered in simple "" statistician's work description "". Does your job consist more of checking using t- and F-tests, etc.? Or is it closer to academic tyoe like trying to find the way to reduce bias, etc.? For example (dumb example), if you are testing accuracy of predictions are you considering going deep into assumptions made by the predictors (e.g. constant prices,etc.)? Basically, if you are statistician, could you please share with me (us, at stackexchange) your work routine (I mean things one would not see in typical ""statistician's work description"")?",,"['statistics', 'soft-question']"
35,"Preventing underflow, log sum exp trick","Preventing underflow, log sum exp trick",,"I have some difficulties with understanding the schema to prevent underflow, which is very  often mentioned as The log-sum-exp trick, the partial decription  is The log-sum-exp trick . In short, I will describe the general idea. Assume you need to calculate $w_i=\frac{\prod_{j}^{n}p_{ij}}{\sum_{i}^{n}\prod_{j}^{n}p_{ij}}$, where $p_{ij}$ might be very small value, therefore the overall product is very small and might cause underflow when calculating on computer. Let's apply $\log$ and $\exp$ to the enumerator and denominator and $z_i=\sum_{j}^{} \log p_{ij}$, then $w_i = \frac{e^{z_i}}{\sum_{j}^{n} e^{z_j}}$, of course, ensure that $p_i \neq 0$. The problem with resulting formula is still $e^{z_i}$ might have small value and might cause underflow. So far everything is ok. Then $m = \max_i(z_i)$ $w_{i} = \frac{e^{z_i}}{\sum_{j}^{}e^{z_j}}= \frac{e^{z_i-m}}{\sum_{j}^{}e^{z_j-m}}=$ $=0\ if\ z_i-m<-k$ $=\frac{e^{z_i-m}}{\sum_{j:z_j-m \geq -k}^{}e^{z_j-m}}$, otherwise ,when $k$ is some value such that $e^{-k}$ doesn't cause underflow. The  question is why do we need to use $m$ value. In my opinion, $w_{i} = \frac{e^{z_i}}{\sum_{j}^{}e^{z_j}}$ with the $k$ value, would work just fine, positive values of $z_j$ don't cause the problem, and the negative are filtered out by $-k$, what the reason to artificially decrease the value of $z_j$ by m.","I have some difficulties with understanding the schema to prevent underflow, which is very  often mentioned as The log-sum-exp trick, the partial decription  is The log-sum-exp trick . In short, I will describe the general idea. Assume you need to calculate $w_i=\frac{\prod_{j}^{n}p_{ij}}{\sum_{i}^{n}\prod_{j}^{n}p_{ij}}$, where $p_{ij}$ might be very small value, therefore the overall product is very small and might cause underflow when calculating on computer. Let's apply $\log$ and $\exp$ to the enumerator and denominator and $z_i=\sum_{j}^{} \log p_{ij}$, then $w_i = \frac{e^{z_i}}{\sum_{j}^{n} e^{z_j}}$, of course, ensure that $p_i \neq 0$. The problem with resulting formula is still $e^{z_i}$ might have small value and might cause underflow. So far everything is ok. Then $m = \max_i(z_i)$ $w_{i} = \frac{e^{z_i}}{\sum_{j}^{}e^{z_j}}= \frac{e^{z_i-m}}{\sum_{j}^{}e^{z_j-m}}=$ $=0\ if\ z_i-m<-k$ $=\frac{e^{z_i-m}}{\sum_{j:z_j-m \geq -k}^{}e^{z_j-m}}$, otherwise ,when $k$ is some value such that $e^{-k}$ doesn't cause underflow. The  question is why do we need to use $m$ value. In my opinion, $w_{i} = \frac{e^{z_i}}{\sum_{j}^{}e^{z_j}}$ with the $k$ value, would work just fine, positive values of $z_j$ don't cause the problem, and the negative are filtered out by $-k$, what the reason to artificially decrease the value of $z_j$ by m.",,"['statistics', 'computer-science', 'machine-learning']"
36,Roll dice and ignore worst results,Roll dice and ignore worst results,,"I roll $n$ dice with $k$ sides each (numbered $1$ thru $k$ , laplace). I then add the numbers of the $m$ best dice (the higher the roll the better). This sum is the result. What is the expected value of the result? (And how did you obtain it?) What is the probability of getting the exact result of $x$ ( $m \le x \le mk$ )? As you might have guessed, this question is about AD&D, and I got curious about the maths behind it.","I roll dice with sides each (numbered thru , laplace). I then add the numbers of the best dice (the higher the roll the better). This sum is the result. What is the expected value of the result? (And how did you obtain it?) What is the probability of getting the exact result of ( )? As you might have guessed, this question is about AD&D, and I got curious about the maths behind it.",n k 1 k m x m \le x \le mk,"['statistics', 'dice']"
37,"what is the median of the CDF with the form $F(x) = 1 - e^{-(x/3)^2}$, for $x \gt 0$","what is the median of the CDF with the form , for",F(x) = 1 - e^{-(x/3)^2} x \gt 0,"Consider The distribution of lifetimes, X(in months), of a particular type of component. The Cumulative distribution function (CDF) has the form $$F(x)=\begin{cases} 1 - e^{-(x/3)^2},& \text{if} ~ x \gt 0\\\\ 0,&\text{otherwise}.\\\\ \end{cases}$$ How to calculate the median?","Consider The distribution of lifetimes, X(in months), of a particular type of component. The Cumulative distribution function (CDF) has the form $$F(x)=\begin{cases} 1 - e^{-(x/3)^2},& \text{if} ~ x \gt 0\\\\ 0,&\text{otherwise}.\\\\ \end{cases}$$ How to calculate the median?",,['statistics']
38,Finding the MVUE using Rao-Blackwell Theorem,Finding the MVUE using Rao-Blackwell Theorem,,"The number of breakdowns Y per day for a certain machine is a Poisson random variable with mean $\lambda$. The daily cost of repairing these break downs is given by $C=3Y^2$ If $Y_1, Y_2, ..., Y_n$ denote the observed number of breakdowns for $n$ independently selected days find an MVUE for $E(C)$. We can use the Rao-Blackwell Theorem. We know that $E(C) = E(3Y^2)=3[V(Y) + (E(Y))^2]$ and $E(Y)=\lambda=V(Y)$. With some calculations we see that $E(Y^2)= \lambda + \lambda^2$ $\sum_{i=1}^n Y_i=\bar Y$ is a sufficient statistics for $ \lambda$  So I am assuming we can replace $\lambda$ with $\bar {Y}$ I am unsure where to go from here. Can someone help me pull the strings together?","The number of breakdowns Y per day for a certain machine is a Poisson random variable with mean $\lambda$. The daily cost of repairing these break downs is given by $C=3Y^2$ If $Y_1, Y_2, ..., Y_n$ denote the observed number of breakdowns for $n$ independently selected days find an MVUE for $E(C)$. We can use the Rao-Blackwell Theorem. We know that $E(C) = E(3Y^2)=3[V(Y) + (E(Y))^2]$ and $E(Y)=\lambda=V(Y)$. With some calculations we see that $E(Y^2)= \lambda + \lambda^2$ $\sum_{i=1}^n Y_i=\bar Y$ is a sufficient statistics for $ \lambda$  So I am assuming we can replace $\lambda$ with $\bar {Y}$ I am unsure where to go from here. Can someone help me pull the strings together?",,['statistics']
39,What is the chance of an event happening a set number of times or more after a number of trials?,What is the chance of an event happening a set number of times or more after a number of trials?,,"Assuming every trial is independent from all the others and the probability of a successful run is the same every trial, how can you determine the chance of a successful trial a set number of times or more? For example, You run 20 independent trials and the chance of a ""successful"" independent trial each time is 60%. how would you determine the chance of 3 or more""successful"" trials?","Assuming every trial is independent from all the others and the probability of a successful run is the same every trial, how can you determine the chance of a successful trial a set number of times or more? For example, You run 20 independent trials and the chance of a ""successful"" independent trial each time is 60%. how would you determine the chance of 3 or more""successful"" trials?",,['statistics']
40,How did Target figure out a teen girl was pregnant before her father did?,How did Target figure out a teen girl was pregnant before her father did?,,"First of all I do not have a mathematics degree only a B.S. in finance so please take that into account when writing an answer. Generally what type of mathematics is involved here? And specifically what statistical formulas can be used in a scenario like this? Recently Target was able to predict that a teen girl was pregnant by analyzing the items she had purchased, and sent her the appropriate coupons for her current condition. I would like to know broadly how were they able to do this, and specifically what types of mathematical formulas they used/ can be used to do this. This link will describe the specific situation.","First of all I do not have a mathematics degree only a B.S. in finance so please take that into account when writing an answer. Generally what type of mathematics is involved here? And specifically what statistical formulas can be used in a scenario like this? Recently Target was able to predict that a teen girl was pregnant by analyzing the items she had purchased, and sent her the appropriate coupons for her current condition. I would like to know broadly how were they able to do this, and specifically what types of mathematical formulas they used/ can be used to do this. This link will describe the specific situation.",,"['statistics', 'soft-question', 'mathematical-modeling', 'machine-learning', 'descriptive-statistics']"
41,Finding the joint distribution of $X_{1:n}$ and $\overline{X}$,Finding the joint distribution of  and,X_{1:n} \overline{X},"I need to show that, given a random sample of independent variables $X_1, ... , X_n$, each following a distribution EXP($\theta$,$\eta$), that is, $f(x_i)=\frac{1}{\theta}\exp(-\frac{x_i-\eta}{\theta})$, the statistics $X_{1:n}$ (the first order statistic) and $\overline{X}=(1/n)(X_1+...+X_n)$ are jointly sufficient for $\theta$ and $\eta$. I already did this, by using a so-called ''factorization criterion'' (I'm following the terminology of Bein and Engelhardt's ''Introduction to Probability and Mathematical Statistics'') and the indicator function. See this related post. I'd also like to do it using the formula $f_{\vec{X}|\vec{S}}(x_1,...,x_n)=\begin{cases} \frac{f(x_1,...,x_n;\vec{\theta})}{f_{\vec{S}}(\vec{s};\vec{\theta})} & \text{if } \mathit{s}(x_1,...,x_n)=s \\ 0 & \text{otherwise}\end{cases}$ (one has to show that this is independent of $\vec{\theta}$, the parameters; in this case, $(\theta_1,\theta_2)=(\theta,\eta)$). (To be honest, I don't understand what that formula really means or where it comes from.) My trouble is in finding the joint distribution of $X_{1:n}$ and $\overline{X}$. How does one calculate this?","I need to show that, given a random sample of independent variables $X_1, ... , X_n$, each following a distribution EXP($\theta$,$\eta$), that is, $f(x_i)=\frac{1}{\theta}\exp(-\frac{x_i-\eta}{\theta})$, the statistics $X_{1:n}$ (the first order statistic) and $\overline{X}=(1/n)(X_1+...+X_n)$ are jointly sufficient for $\theta$ and $\eta$. I already did this, by using a so-called ''factorization criterion'' (I'm following the terminology of Bein and Engelhardt's ''Introduction to Probability and Mathematical Statistics'') and the indicator function. See this related post. I'd also like to do it using the formula $f_{\vec{X}|\vec{S}}(x_1,...,x_n)=\begin{cases} \frac{f(x_1,...,x_n;\vec{\theta})}{f_{\vec{S}}(\vec{s};\vec{\theta})} & \text{if } \mathit{s}(x_1,...,x_n)=s \\ 0 & \text{otherwise}\end{cases}$ (one has to show that this is independent of $\vec{\theta}$, the parameters; in this case, $(\theta_1,\theta_2)=(\theta,\eta)$). (To be honest, I don't understand what that formula really means or where it comes from.) My trouble is in finding the joint distribution of $X_{1:n}$ and $\overline{X}$. How does one calculate this?",,"['statistics', 'parameter-estimation']"
42,Ergodic series converge to the expectation?,Ergodic series converge to the expectation?,,"Let $(X_i, Y_i)_{i\in\mathbb{N}}$ be a real-valued stochastic process. We say that $X$ is mean-ergodic, if $$\frac{1}{n}\sum_{i=1}^nX_i\to \mathbb{E}X_1$$ in probability as $n\to\infty$ . Let $S_n:=\{i\in\{1, \dots, n\}: Y_i\in D \}$ where $D$ is some measurable set with $P(Y_i\in D)>0$ . If $(X_i, Y_i)_{i\in\mathbb{N}}$ are mean-ergodic + strictly stationary, does it imply that $$\frac{1}{|S_n|}\sum_{i\in S_n}X_i\to \mathbb{E}[X_1\mid Y_1\in D] $$ in probability as $n\to\infty$ ? I am thinking about the following approach. Let $\tilde{Y}_i := 1[Y_i\in D]$ and let $W_i:=X_i\tilde{Y}_i$ . Now, $$ \frac{1}{|S_n|} \sum_{i\in S_n}X_i =    \bigg( \frac{n}{\sum_{i\leq n}\tilde{Y}_i}\bigg)   \bigg( \frac{1}{n} \sum_{i\leq n}W_i    \bigg) .  $$ The first part converges to $1/P(Y_1\in D)$ . Does the second part converge to its expectation? As @Michael showed, NO. Hence, function of mean-ergodic series is not a mean-ergodic series. However, if we assume ergodicity in the sense of ''the underlying shift operator is an ergodic transformation'', is it sufficient assumption for the convergence to hold?","Let be a real-valued stochastic process. We say that is mean-ergodic, if in probability as . Let where is some measurable set with . If are mean-ergodic + strictly stationary, does it imply that in probability as ? I am thinking about the following approach. Let and let . Now, The first part converges to . Does the second part converge to its expectation? As @Michael showed, NO. Hence, function of mean-ergodic series is not a mean-ergodic series. However, if we assume ergodicity in the sense of ''the underlying shift operator is an ergodic transformation'', is it sufficient assumption for the convergence to hold?","(X_i, Y_i)_{i\in\mathbb{N}} X \frac{1}{n}\sum_{i=1}^nX_i\to \mathbb{E}X_1 n\to\infty S_n:=\{i\in\{1, \dots, n\}: Y_i\in D \} D P(Y_i\in D)>0 (X_i, Y_i)_{i\in\mathbb{N}} \frac{1}{|S_n|}\sum_{i\in S_n}X_i\to \mathbb{E}[X_1\mid Y_1\in D]  n\to\infty \tilde{Y}_i := 1[Y_i\in D] W_i:=X_i\tilde{Y}_i 
\frac{1}{|S_n|} \sum_{i\in S_n}X_i =    \bigg( \frac{n}{\sum_{i\leq n}\tilde{Y}_i}\bigg)   \bigg( \frac{1}{n} \sum_{i\leq n}W_i    \bigg) . 
 1/P(Y_1\in D)","['statistics', 'stochastic-processes', 'dynamical-systems', 'ergodic-theory', 'stationary-processes']"
43,Lehmann–Scheffé theorem's statement,Lehmann–Scheffé theorem's statement,,"In my notes I have the following L-S theorem statement: Let $T(X_1,...,X_n)$ be an estimator for $\theta \in \Theta$ . If $T$ is: unbiased a function of complete and sufficient statistic $S_c(X_1,...X_n)$ , so that we can write: $T=g(S_c(X_1,...X_n))$ $\implies$ $T$ is the unique estimator that is both unbiased and function of a complete and sufficient statistic. My question is: does $g$ have to be a bijective function? In my opinion, it doesn't have to be: in the proof of this theorem, this condition isn't used. However, my lecturer said it is needed. I disagree.","In my notes I have the following L-S theorem statement: Let be an estimator for . If is: unbiased a function of complete and sufficient statistic , so that we can write: is the unique estimator that is both unbiased and function of a complete and sufficient statistic. My question is: does have to be a bijective function? In my opinion, it doesn't have to be: in the proof of this theorem, this condition isn't used. However, my lecturer said it is needed. I disagree.","T(X_1,...,X_n) \theta \in \Theta T S_c(X_1,...X_n) T=g(S_c(X_1,...X_n)) \implies T g","['statistics', 'statistical-inference', 'estimation']"
44,Finding a best fit second order polynomial,Finding a best fit second order polynomial,,"Problem: Assume we have the following points: $(x_0,y_0), (x_1,y_1), (x_2,y_2), (x_3,y_3)$ where $x_0 = -3$ , $x_1 = -2$ , $x_2 = -1$ and $x_3 = 0$ . Given the function $f(x) = Ax^2 + Bx + C$ find the constants $A$ , $B$ and $C$ such that $f(0) = y_3$ and $$d = \sum_{i = 0}^{2} (f(x_i) - y_{i})^2$$ is minimized. Answer: First we apply the requirement that $f(0) = y_3$ . \begin{align*} f(0) &= A(0) + B(0) + C = y_3 \\ C &= y_3 \\ d &= \sum_{i = 0}^{2} (A(x_i)^2 + B(x_i) + y_3 - y_{i})^2 \end{align*} We write $d_A$ to represent the partial derivative of $d$ with respect to $A$ . \begin{align*} d_A &= \sum_{i = 0}^{2} 2(x_i)^2(A(x_i)^2 + B(x_i) + y_3 - y_{i}) \\ d_B &= \sum_{i = 0}^{2} 2(x_i)(A(x_i)^2 + B(x_i) + y_3 - y_{i}) \\ \end{align*} Now we set the partial derivatives to $0$ to find a minimum. \begin{align*} \sum_{i = 0}^{2} 2(x_i)^2(A(x_i)^2 \\  +& B(x_i) + y_3 - y_{i}) &= 0 \\ \sum_{i = 0}^{2} 2(x_i)(A(x_i)^2 + B(x_i) \\   +& y_3 - y_{i}) &= 0 \\ \sum_{i = 0}^{2} (A(x_i)^2 + B(x_i) + y_3 - y_{i}) &= 0 \\ \sum_{i = 0}^{2} (A(x_i)^2 + B(x_i) + y_3 - y_{i}) &= 0 \\ \end{align*} Am I right so far? Now how do I proceed? Now I solve the equation $d_A = 0$ . Here is what I get: \begin{align*}  (A(-3)^2 + B(-3) + y_3 - y_{0})  	+  (A(-2)^2 + B(-2) + y_3 - y_{1}) 	+  (A(-1)^2 + B(-1) + y_3 - y_{2})  &= 0 \\ % 9A - 3B + y_3 - y_{0} +  4A - 2B + y_3 - y_{1} + A - B + y_3 - y_{2} 	&= 0 \\ % 14A - 6B  + 3y_3 - y_{0} - y_{1} - y_{2} &= 0 \\ \end{align*} Now, I need to solve the equation $d_B = 0$ . However, that will produce the same equation as $d_A = 0$ . Therefore, I do not know how to find a unique value for $A$ and $B$ . Based upon the group's comments. I have updated my solution again. I believe my formula for A is correct. However, my formula for B is wrong. Answer: First, I apply the requirement that $f(0) = y_3$ . \begin{align*} f(0) = y_3 &= (A)(0) + (B)(0) + C \\ C &= y_3 \\ f(x) &= Ax^2 + Bx + y_3 \\ d &= (f(x_0) - y_{0})^2 + (f(x_1) - y_{1})^2 + (f(x_2) - y_{2})^2  \\ d &= ( Ax_0^2 + Bx_0 + y_3 - y_{0})^2 + ( Ax_1^2 + Bx_1 + y_3 - y_{1})^2 	+ ( Ax_2^2 + Bx_2 + y_3 - y_{2})^2  \end{align*} I will write $d_A$ for the partial derivative of $d$ with respect to $A$ . \begin{align*} d_A &=  2x_0^2( Ax_0^2 + Bx_0 + y_3 - y_{0}) 	+ 2x_1^2( Ax_1^2 + Bx_1 + y_3 - y_{1}) 	+ 2x_2^2( Ax_2^2 + Bx_2 + y_3 - y_{2}) \\ d_B &=  2x_0( Ax_0^2 + Bx_0 + y_3 - y_{0}) 	+ 2x_1( Ax_1^2 + Bx_1 + y_3 - y_{1}) 	+ 2x_2( Ax_2^2 + Bx_2 + y_3 - y_{2}) \\ \end{align*} Now I set $d_A = 0$ and $d_B = 0$ . I then solve for $A$ and $B$ . \begin{align*} x_0^2( Ax_0^2 + Bx_0 + y_3 - y_{0}) 	+ x_1^2( Ax_1^2 + Bx_1 + y_3 - y_{1}) 	+ x_2^2( Ax_2^2 + Bx_2 + y_3 - y_{2}) &= 0 \\ x_0( Ax_0^2 + Bx_0 + y_3 - y_{0}) 	+ x_1( Ax_1^2 + Bx_1 + y_3 - y_{1}) 	+ x_2( Ax_2^2 + Bx_2 + y_3 - y_{2}) &= 0 \\ \end{align*} Now, I am going to work on the first equation. I will substitute values for $x_0$ , $x_1$ and $x_2$ \begin{align*} 9( 9A - 3B + y_3 - y_0) 	+ 4( 4A - 2B + y_3 - y_{1}) 	+ 1( A - B + y_3 - y_{2}) 	&= 0 \\ 98A - 36B + 14y_3 - 9y_0 - 4y_1 - y_2 &= 0 \\ \end{align*} Now, I work on the second equation. \begin{align*} -3( 9A  - 3B + y_3 - y_{0}) 	- 2( 4A - 2B + y_3 - y_{1}) 	- ( A - B + y_3 - y_{2}) &= 0 \\ -36A + 14B - 6y_3 + 3y_0 + 2y_1 + y_2 &= 0 \\ \end{align*} \begin{align*} 14B &= 36A + 6y_3 - 3y_0 - 2y_1 - y_2 \\ B &= \dfrac{ 36A + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \end{align*} Now we can solve the first equation for $A$ . \begin{align*} 98A - 36 \left( \dfrac{ 36A + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \right) + 14y_3 - 9y_0 - 4y_1 - y_2 &= 0 \\ % 98A - 18 \left( \dfrac{ 36A + 6y_3 - 3y_0 - 2y_1 - y_2  } { 7 } \right) 	+ 14y_3 - 9y_0 - 4y_1 - y_2 &= 0 \\ % 686A - 18 \left( 36A + 6y_3 - 3y_0 - 2y_1 - y_2 \right) + (7)(14)y_3 - 63y_0 - 28y_1 - 7y_2 &= 0 \\ % 686A - 18 \left( 36A + 6y_3 - 3y_0 - 2y_1 - y_2 \right) 	+ 98y_3 - 63y_0 - 28y_1 - 7y_2 &= 0 \\ % 38A - 18( 6y_3 - 3y_0 - 2y_1 - y_2 ) + 98y_3 - 63y_0 - 28y_1 - 7y_2 &= 0 \\ % 38A - 10y_3 - 18( - 3y_0 - 2y_1 - y_2 ) - 63y_0 - 28y_1 - 7y_2 &= 0 \\ 38A - 10y_3 + 18( 3y_0 + 2y_1 + y_2 ) - 63y_0 - 28y_1 - 7y_2 &= 0 \\ 38A - 10y_3 - 9y_0 + 8y_1 + 11y_2 &= 0 \\ \end{align*} \begin{align*} 38A &= 10y_3 + 9y_0 - 8y_1 - 11y_2 \\ A &= \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 } \end{align*} Now we solve for $B$ . \begin{align*} B &= 	\dfrac{ 36 \left(  \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 }\right)  + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \\ % B &= 	\dfrac{ 18 \left(  \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{19 }\right)  + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \\ B &= 	\dfrac{ 18(  10y_3 + 9y_0 - 8y_1 - 11y_2 ) + 19( 6y_3 - 3y_0 - 2y_1 - y_2  ) }{ 19(14)} \\ B &= \dfrac{  180y_3 +162y_0 - 144y_1 - 198y_2 		+ 6(19)y_3 - 3(19)y_0 - 28y_1 - 19y_2  } { 19(14)} \\% B &= \dfrac{  180y_3 +162y_0 - 144y_1 - 198y_2 		+ 114y_3 - 57y_0 - 28y_1 - 19y_2  } {266} \\ B &= \dfrac{  294y_3 + (162-57)y_0 -144y_1 - 28y_1 - 198y_2 - 19y_2  } {266} \\ % B &= \dfrac{  294y_3 + 105 y_0 - 172y_1 - 217y_2  } {266} \\ \end{align*} Now I will try out the formula on the following set of points: $$( -3, 0), (-2,1), (-1,2), (0,5)$$ We have: \begin{align*} y_0 &= 0 \\ y_1 &= 1 \\ y_2 &= 2 \\ y_3 &= 5 \\ C &= 5 \\ A &= \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 } \\ A &= \dfrac{ 10(5) + 9(0) - 8(1) - 11(2) }{38 } 	= \dfrac{ 50 - 8 - 22 }{38 } \\ A &= \dfrac{ 10 }{ 19 } \\ B &= \dfrac{  294y_3 + 105 y_0 - 172y_1 - 217y_2  } {266} \\ B &= \dfrac{  294(5) + 105(0) - 172(1) - 217(2)  } {266} \\ B &= \dfrac{  1470 - 172 - 217(2)  } {266} \\ B &= \dfrac{  1470 - 172 - 434  } {266} = \dfrac{ 864 }{ 266} \\ B &= \dfrac{ 432 } { 133 } \\ B &\doteq 3.2481203 \end{align*} Now I will try out the formula on the following set of points: $$( -3, -1), (-2,1), (-1,2), (0,10)$$ We have: \begin{align*} y_0 &= -1 \\ y_1 &= 1 \\ y_2 &= 2 \\ y_3 &= 10 \\ C &= 5 \\ A &= \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 } \\ A &= \dfrac{ 10(10) + 9(-1) - 8(1) - 11(2) }{38 } \\ A &= \dfrac{ 100 - 9 - 8 - 22 }{38 } \\ A &= \dfrac{ 61}{38} \\ B &\doteq 1.6052632 \\ B &= \dfrac{  294y_3 + 105 y_0 - 172y_1 - 217y_2  } {266} \\ B &= \dfrac{  294(10) + 105(-1) - 172(1) - 217(2)  } {266} \\ B &= \dfrac{  2940 - 105 - 172 - 434 } {266}   \\ B &= \dfrac{ 2229 } {266} \\ B &\doteq 8.3796992 \end{align*} According to R, the correct value for $A$ is $1.605263$ and the correct value for $B$ is $8.34210475$ .","Problem: Assume we have the following points: where , , and . Given the function find the constants , and such that and is minimized. Answer: First we apply the requirement that . We write to represent the partial derivative of with respect to . Now we set the partial derivatives to to find a minimum. Am I right so far? Now how do I proceed? Now I solve the equation . Here is what I get: Now, I need to solve the equation . However, that will produce the same equation as . Therefore, I do not know how to find a unique value for and . Based upon the group's comments. I have updated my solution again. I believe my formula for A is correct. However, my formula for B is wrong. Answer: First, I apply the requirement that . I will write for the partial derivative of with respect to . Now I set and . I then solve for and . Now, I am going to work on the first equation. I will substitute values for , and Now, I work on the second equation. Now we can solve the first equation for . Now we solve for . Now I will try out the formula on the following set of points: We have: Now I will try out the formula on the following set of points: We have: According to R, the correct value for is and the correct value for is .","(x_0,y_0), (x_1,y_1), (x_2,y_2), (x_3,y_3) x_0 = -3 x_1 = -2 x_2 = -1 x_3 = 0 f(x) = Ax^2 + Bx + C A B C f(0) = y_3 d = \sum_{i = 0}^{2} (f(x_i) - y_{i})^2 f(0) = y_3 \begin{align*}
f(0) &= A(0) + B(0) + C = y_3 \\
C &= y_3 \\
d &= \sum_{i = 0}^{2} (A(x_i)^2 + B(x_i) + y_3 - y_{i})^2
\end{align*} d_A d A \begin{align*}
d_A &= \sum_{i = 0}^{2} 2(x_i)^2(A(x_i)^2 + B(x_i) + y_3 - y_{i}) \\
d_B &= \sum_{i = 0}^{2} 2(x_i)(A(x_i)^2 + B(x_i) + y_3 - y_{i}) \\
\end{align*} 0 \begin{align*}
\sum_{i = 0}^{2} 2(x_i)^2(A(x_i)^2 \\
 +& B(x_i) + y_3 - y_{i}) &= 0 \\
\sum_{i = 0}^{2} 2(x_i)(A(x_i)^2 + B(x_i) \\
  +& y_3 - y_{i}) &= 0 \\
\sum_{i = 0}^{2} (A(x_i)^2 + B(x_i) + y_3 - y_{i}) &= 0 \\
\sum_{i = 0}^{2} (A(x_i)^2 + B(x_i) + y_3 - y_{i}) &= 0 \\
\end{align*} d_A = 0 \begin{align*}
 (A(-3)^2 + B(-3) + y_3 - y_{0})
 	+  (A(-2)^2 + B(-2) + y_3 - y_{1})
	+  (A(-1)^2 + B(-1) + y_3 - y_{2})
 &= 0 \\
%
9A - 3B + y_3 - y_{0} +  4A - 2B + y_3 - y_{1} + A - B + y_3 - y_{2}
	&= 0 \\
%
14A - 6B  + 3y_3 - y_{0} - y_{1} - y_{2} &= 0 \\
\end{align*} d_B = 0 d_A = 0 A B f(0) = y_3 \begin{align*}
f(0) = y_3 &= (A)(0) + (B)(0) + C \\
C &= y_3 \\
f(x) &= Ax^2 + Bx + y_3 \\
d &= (f(x_0) - y_{0})^2 + (f(x_1) - y_{1})^2 + (f(x_2) - y_{2})^2  \\
d &= ( Ax_0^2 + Bx_0 + y_3 - y_{0})^2 + ( Ax_1^2 + Bx_1 + y_3 - y_{1})^2
	+ ( Ax_2^2 + Bx_2 + y_3 - y_{2})^2 
\end{align*} d_A d A \begin{align*}
d_A &=  2x_0^2( Ax_0^2 + Bx_0 + y_3 - y_{0})
	+ 2x_1^2( Ax_1^2 + Bx_1 + y_3 - y_{1})
	+ 2x_2^2( Ax_2^2 + Bx_2 + y_3 - y_{2}) \\
d_B &=  2x_0( Ax_0^2 + Bx_0 + y_3 - y_{0})
	+ 2x_1( Ax_1^2 + Bx_1 + y_3 - y_{1})
	+ 2x_2( Ax_2^2 + Bx_2 + y_3 - y_{2}) \\
\end{align*} d_A = 0 d_B = 0 A B \begin{align*}
x_0^2( Ax_0^2 + Bx_0 + y_3 - y_{0})
	+ x_1^2( Ax_1^2 + Bx_1 + y_3 - y_{1})
	+ x_2^2( Ax_2^2 + Bx_2 + y_3 - y_{2})
&= 0 \\
x_0( Ax_0^2 + Bx_0 + y_3 - y_{0})
	+ x_1( Ax_1^2 + Bx_1 + y_3 - y_{1})
	+ x_2( Ax_2^2 + Bx_2 + y_3 - y_{2})
&= 0 \\
\end{align*} x_0 x_1 x_2 \begin{align*}
9( 9A - 3B + y_3 - y_0)
	+ 4( 4A - 2B + y_3 - y_{1})
	+ 1( A - B + y_3 - y_{2})
	&= 0 \\
98A - 36B + 14y_3 - 9y_0 - 4y_1 - y_2 &= 0 \\
\end{align*} \begin{align*}
-3( 9A  - 3B + y_3 - y_{0})
	- 2( 4A - 2B + y_3 - y_{1})
	- ( A - B + y_3 - y_{2})
&= 0 \\
-36A + 14B - 6y_3 + 3y_0 + 2y_1 + y_2 &= 0 \\
\end{align*} \begin{align*}
14B &= 36A + 6y_3 - 3y_0 - 2y_1 - y_2 \\
B &= \dfrac{ 36A + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 }
\end{align*} A \begin{align*}
98A - 36 \left( \dfrac{ 36A + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \right) + 14y_3 - 9y_0 - 4y_1 - y_2 &= 0 \\
%
98A - 18 \left( \dfrac{ 36A + 6y_3 - 3y_0 - 2y_1 - y_2  } { 7 } \right)
	+ 14y_3 - 9y_0 - 4y_1 - y_2 &= 0 \\
%
686A - 18 \left( 36A + 6y_3 - 3y_0 - 2y_1 - y_2 \right)
+ (7)(14)y_3 - 63y_0 - 28y_1 - 7y_2 &= 0 \\
%
686A - 18 \left( 36A + 6y_3 - 3y_0 - 2y_1 - y_2 \right)
	+ 98y_3 - 63y_0 - 28y_1 - 7y_2 &= 0 \\
%
38A - 18( 6y_3 - 3y_0 - 2y_1 - y_2 ) + 98y_3 - 63y_0 - 28y_1 - 7y_2 &= 0 \\
%
38A - 10y_3 - 18( - 3y_0 - 2y_1 - y_2 ) - 63y_0 - 28y_1 - 7y_2 &= 0 \\
38A - 10y_3 + 18( 3y_0 + 2y_1 + y_2 ) - 63y_0 - 28y_1 - 7y_2 &= 0 \\
38A - 10y_3 - 9y_0 + 8y_1 + 11y_2 &= 0 \\
\end{align*} \begin{align*}
38A &= 10y_3 + 9y_0 - 8y_1 - 11y_2 \\
A &= \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 }
\end{align*} B \begin{align*}
B &=
	\dfrac{ 36 \left(  \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 }\right)  + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \\
%
B &=
	\dfrac{ 18 \left(  \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{19 }\right)  + 6y_3 - 3y_0 - 2y_1 - y_2  } { 14 } \\
B &=
	\dfrac{ 18(  10y_3 + 9y_0 - 8y_1 - 11y_2 ) + 19( 6y_3 - 3y_0 - 2y_1 - y_2  ) }{ 19(14)} \\
B &= \dfrac{  180y_3 +162y_0 - 144y_1 - 198y_2
		+ 6(19)y_3 - 3(19)y_0 - 28y_1 - 19y_2  } { 19(14)} \\%
B &= \dfrac{  180y_3 +162y_0 - 144y_1 - 198y_2
		+ 114y_3 - 57y_0 - 28y_1 - 19y_2  } {266} \\
B &= \dfrac{  294y_3 + (162-57)y_0 -144y_1 - 28y_1 - 198y_2 - 19y_2  } {266} \\
%
B &= \dfrac{  294y_3 + 105 y_0 - 172y_1 - 217y_2  } {266} \\
\end{align*} ( -3, 0), (-2,1), (-1,2), (0,5) \begin{align*}
y_0 &= 0 \\
y_1 &= 1 \\
y_2 &= 2 \\
y_3 &= 5 \\
C &= 5 \\
A &= \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 } \\
A &= \dfrac{ 10(5) + 9(0) - 8(1) - 11(2) }{38 }
	= \dfrac{ 50 - 8 - 22 }{38 } \\
A &= \dfrac{ 10 }{ 19 } \\
B &= \dfrac{  294y_3 + 105 y_0 - 172y_1 - 217y_2  } {266} \\
B &= \dfrac{  294(5) + 105(0) - 172(1) - 217(2)  } {266} \\
B &= \dfrac{  1470 - 172 - 217(2)  } {266} \\
B &= \dfrac{  1470 - 172 - 434  } {266} = \dfrac{ 864 }{ 266} \\
B &= \dfrac{ 432 } { 133 } \\
B &\doteq 3.2481203
\end{align*} ( -3, -1), (-2,1), (-1,2), (0,10) \begin{align*}
y_0 &= -1 \\
y_1 &= 1 \\
y_2 &= 2 \\
y_3 &= 10 \\
C &= 5 \\
A &= \dfrac{ 10y_3 + 9y_0 - 8y_1 - 11y_2 }{38 } \\
A &= \dfrac{ 10(10) + 9(-1) - 8(1) - 11(2) }{38 } \\
A &= \dfrac{ 100 - 9 - 8 - 22 }{38 } \\
A &= \dfrac{ 61}{38} \\
B &\doteq 1.6052632 \\
B &= \dfrac{  294y_3 + 105 y_0 - 172y_1 - 217y_2  } {266} \\
B &= \dfrac{  294(10) + 105(-1) - 172(1) - 217(2)  } {266} \\
B &= \dfrac{  2940 - 105 - 172 - 434 } {266}   \\
B &= \dfrac{ 2229 } {266} \\
B &\doteq 8.3796992
\end{align*} A 1.605263 B 8.34210475","['statistics', 'multivariable-calculus']"
45,Log likelihood with exponential function,Log likelihood with exponential function,,"I'm trying to find the maximum likelihood of this function. I have samples in this question as follows: (0.77, 0.82, 0.94, 0.92, 0.98) $$f_Y(y;\theta)=\theta y^{\theta-1} ;, \quad 0 \le y \le 1 ;, 0 \lt \theta$$ $$L(\theta) = \prod\limits_{i=1}^{n} \theta y_i^{\theta-1} \\ = \theta^n\prod\limits_{i=1}^{n}y_i^{\theta-1}$$ From here i'm stuck. I'm not sure if I should take the log now or there is one more move before I take the log. The answer is 8.00. if I put the values it would probably make it easier for me, but it appears to me that I do not know a technique or identity from here to move on. Any help? Continuing on: $$\text{Let }\; T = \frac{\partial}{\partial \theta}\bigg(n\ln \theta + (\theta -1)\sum_{i=1}^n \ln y_i\bigg) = \frac{n}{\theta} + \sum_\limits{i=1}^{n}ln(y_i) \\ \text{Let } \; T = 0 = \frac{n}{\theta} -0.261 - 0.198 - 0.083 - 0.061 - 0.02 \\ \text{implies } \hat{\theta} = \frac{5}{0.623} = 8$$","I'm trying to find the maximum likelihood of this function. I have samples in this question as follows: (0.77, 0.82, 0.94, 0.92, 0.98) From here i'm stuck. I'm not sure if I should take the log now or there is one more move before I take the log. The answer is 8.00. if I put the values it would probably make it easier for me, but it appears to me that I do not know a technique or identity from here to move on. Any help? Continuing on:","f_Y(y;\theta)=\theta y^{\theta-1} ;, \quad 0 \le y \le 1 ;, 0 \lt \theta L(\theta) = \prod\limits_{i=1}^{n} \theta y_i^{\theta-1} \\
= \theta^n\prod\limits_{i=1}^{n}y_i^{\theta-1} \text{Let }\; T = \frac{\partial}{\partial \theta}\bigg(n\ln \theta + (\theta -1)\sum_{i=1}^n \ln y_i\bigg) = \frac{n}{\theta} + \sum_\limits{i=1}^{n}ln(y_i) \\
\text{Let } \; T = 0 = \frac{n}{\theta} -0.261 - 0.198 - 0.083 - 0.061 - 0.02 \\
\text{implies } \hat{\theta} = \frac{5}{0.623} = 8","['calculus', 'statistics', 'maximum-likelihood']"
46,How to find estimator for shifted exponential distribution using method of moment?,How to find estimator for shifted exponential distribution using method of moment?,,"I have $f_{\tau, \theta}(y)=\theta e^{-\theta(y-\tau)}, y\ge\tau, \theta\gt 0$. Assume both parameters unknown. $\mu_1=E(Y)=\tau+\frac1\theta=\bar{Y}=m_1$ where $m$ is the sample moment. $\mu_2=E(Y^2)=(E(Y))^2+Var(Y)=(\tau+\frac1\theta)^2+\frac{1}{\theta^2}=\frac1n \sum Y_i^2=m_2$. $\mu_2-\mu_1^2=Var(Y)=\frac{1}{\theta^2}=(\frac1n \sum Y_i^2)-{\bar{Y}}^2=\frac1n\sum(Y_i-\bar{Y})^2\implies \hat{\theta}=\sqrt{\frac{n}{\sum(Y_i-\bar{Y})^2}}$ Then substitute this result into $\mu_1$, we have $\hat\tau=\bar Y-\sqrt{\frac{\sum(Y_i-\bar{Y})^2}{n}}$ Is my procedure correct?","I have $f_{\tau, \theta}(y)=\theta e^{-\theta(y-\tau)}, y\ge\tau, \theta\gt 0$. Assume both parameters unknown. $\mu_1=E(Y)=\tau+\frac1\theta=\bar{Y}=m_1$ where $m$ is the sample moment. $\mu_2=E(Y^2)=(E(Y))^2+Var(Y)=(\tau+\frac1\theta)^2+\frac{1}{\theta^2}=\frac1n \sum Y_i^2=m_2$. $\mu_2-\mu_1^2=Var(Y)=\frac{1}{\theta^2}=(\frac1n \sum Y_i^2)-{\bar{Y}}^2=\frac1n\sum(Y_i-\bar{Y})^2\implies \hat{\theta}=\sqrt{\frac{n}{\sum(Y_i-\bar{Y})^2}}$ Then substitute this result into $\mu_1$, we have $\hat\tau=\bar Y-\sqrt{\frac{\sum(Y_i-\bar{Y})^2}{n}}$ Is my procedure correct?",,"['statistics', 'expectation', 'estimation', 'moment-generating-functions', 'exponential-distribution']"
47,"Formula for a ""Fairness Variance""","Formula for a ""Fairness Variance""",,"Short question : Propose a formula to apply on x0, x1, x2, ..., xn that returns a number which can sort these 7 datasets in this order: Medium question : Given 3 datasets, I want to have a formula that returns a number to represents the ""(un)fairness"" of a dataset , so I can sort/compare the datasets on that. Let's define fairness as the best situation for the worst, then the best situation for the second worst, and so on . For example, suppose we want to make assigning 15 shifts to 5 employees as fair as possible. In the above example, the middle dataset is the fairest, because the employee worst off (most shifts, so purple), is the best off (least shifts, only 5 in the middle dataset). However, if we calculate the variance ( 2.8 ) on these datasets, the second and third dataset have the same number. Is there a formula for number (let's call it Fairness Variance for now) that would allow us to sort these datasets on fairness? Long question : See this blog article which demonstrates that all common formula's (including standard deviation etc) don't work properly. Does such a formula even exist? Can anyone prove it does or doesn't?","Short question : Propose a formula to apply on x0, x1, x2, ..., xn that returns a number which can sort these 7 datasets in this order: Medium question : Given 3 datasets, I want to have a formula that returns a number to represents the ""(un)fairness"" of a dataset , so I can sort/compare the datasets on that. Let's define fairness as the best situation for the worst, then the best situation for the second worst, and so on . For example, suppose we want to make assigning 15 shifts to 5 employees as fair as possible. In the above example, the middle dataset is the fairest, because the employee worst off (most shifts, so purple), is the best off (least shifts, only 5 in the middle dataset). However, if we calculate the variance ( 2.8 ) on these datasets, the second and third dataset have the same number. Is there a formula for number (let's call it Fairness Variance for now) that would allow us to sort these datasets on fairness? Long question : See this blog article which demonstrates that all common formula's (including standard deviation etc) don't work properly. Does such a formula even exist? Can anyone prove it does or doesn't?",,"['statistics', 'variance']"
48,Likelihood function for logistic regression,Likelihood function for logistic regression,,"In logistic regression, the regression coefficients ( $\hat{\beta_0}, \hat{\beta_1}$ ) are calculated via the general method of maximum likelihood. For a simple logistic regression, the maximum likelihood function is given as $$\ell(\beta_0,\beta_1)=\prod_{i:y_i=1}p(x_i)\prod_{i':y_{i'}=0}(1-p(x_{i'})).$$ What is the maximum likelihood function for 2 predictors? Or 3 predictors?","In logistic regression, the regression coefficients ( ) are calculated via the general method of maximum likelihood. For a simple logistic regression, the maximum likelihood function is given as What is the maximum likelihood function for 2 predictors? Or 3 predictors?","\hat{\beta_0}, \hat{\beta_1} \ell(\beta_0,\beta_1)=\prod_{i:y_i=1}p(x_i)\prod_{i':y_{i'}=0}(1-p(x_{i'})).","['statistics', 'regression', 'logistic-regression']"
49,Deriving the mean of the Gumbel Distribution,Deriving the mean of the Gumbel Distribution,,"I'm trying to determine an expected value of a random variable related to the Gumbel/Extreme Value Type 1 distribution.  I think the answer follows the same process as expected value of the Gumbel itself, but I can't figure out the derivation of the expected value of the Gumbel. I found here a derivation, but there's a step in the middle where magic happens.  Need to understand what's going on there to see if I can apply it to my other problem. Recall, the density of the Gumbel distribution is $f(x) = e^{-e^{-x}}e^x$.  The derivation at the link shows that $$ \int_{-\infty}^{\infty}x e^{-x} e^{-e^{-x}}dx = - \int_{0}^{\infty}{\ln y}e^{-y}dy\quad  [y=e^{-x}]\\ = -\frac{d}{d\alpha}\int_0^\infty y^\alpha e^{-y}dy\bigg|_{\alpha=0}\\ =-\frac{d}{d\alpha}\Gamma(\alpha+1)\bigg|_{\alpha=0}\\ =\Gamma'(1) = \gamma \approx 0.577... $$ The jump from the first line to the second is the one I can't follow.  I've tried doing integration by parts on one or the other to demonstrate the equivalence, but I end up with a floating 1 or infinity. Thanks in advance!","I'm trying to determine an expected value of a random variable related to the Gumbel/Extreme Value Type 1 distribution.  I think the answer follows the same process as expected value of the Gumbel itself, but I can't figure out the derivation of the expected value of the Gumbel. I found here a derivation, but there's a step in the middle where magic happens.  Need to understand what's going on there to see if I can apply it to my other problem. Recall, the density of the Gumbel distribution is $f(x) = e^{-e^{-x}}e^x$.  The derivation at the link shows that $$ \int_{-\infty}^{\infty}x e^{-x} e^{-e^{-x}}dx = - \int_{0}^{\infty}{\ln y}e^{-y}dy\quad  [y=e^{-x}]\\ = -\frac{d}{d\alpha}\int_0^\infty y^\alpha e^{-y}dy\bigg|_{\alpha=0}\\ =-\frac{d}{d\alpha}\Gamma(\alpha+1)\bigg|_{\alpha=0}\\ =\Gamma'(1) = \gamma \approx 0.577... $$ The jump from the first line to the second is the one I can't follow.  I've tried doing integration by parts on one or the other to demonstrate the equivalence, but I end up with a floating 1 or infinity. Thanks in advance!",,"['statistics', 'definite-integrals', 'indefinite-integrals', 'expectation']"
50,Show that sample variance is unbiased and a consistent estimator,Show that sample variance is unbiased and a consistent estimator,,"I am having some trouble to prove that the sample variance is a consistent estimator. I have already proved that sample variance is unbiased. I understand that for point estimates T=Tn to be consistent if Tn converges in probably to theta. However, I am not sure how to approach this besides starting with the equation of the sample variance. Any help would be greatly appreciated. Thank you in advance.","I am having some trouble to prove that the sample variance is a consistent estimator. I have already proved that sample variance is unbiased. I understand that for point estimates T=Tn to be consistent if Tn converges in probably to theta. However, I am not sure how to approach this besides starting with the equation of the sample variance. Any help would be greatly appreciated. Thank you in advance.",,"['statistics', 'statistical-inference']"
51,Difference between stochastic process and chaotic system [closed],Difference between stochastic process and chaotic system [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can anyone please point out some difference and similarity between stochastic system  and chaotic system?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can anyone please point out some difference and similarity between stochastic system  and chaotic system?",,"['statistics', 'soft-question']"
52,Parameters estimation for gaussian function with offset,Parameters estimation for gaussian function with offset,,"I've read the paper Least square fitting of a Gaussian function to a histogram by Leo Zhou on how to perform a Least Square Fitting of a gaussian function to a histogram. The Gaussian function used to fit the data is: $$f(y)=A\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$$ However, the method described in the paper doesn't work if the dataset has a vertical offset (i.e. all the points are shifted on the Y-axis by some amount $K$). I was wondering how to perform LSF (or any other kind of fitting) to estimate the parameters $A$, $\mu$, $\sigma$ and $K$ of the function $$f(y)=A\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)+K$$ (without prior knowledge of the parameter $K$, of course).","I've read the paper Least square fitting of a Gaussian function to a histogram by Leo Zhou on how to perform a Least Square Fitting of a gaussian function to a histogram. The Gaussian function used to fit the data is: $$f(y)=A\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$$ However, the method described in the paper doesn't work if the dataset has a vertical offset (i.e. all the points are shifted on the Y-axis by some amount $K$). I was wondering how to perform LSF (or any other kind of fitting) to estimate the parameters $A$, $\mu$, $\sigma$ and $K$ of the function $$f(y)=A\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)+K$$ (without prior knowledge of the parameter $K$, of course).",,"['statistics', 'data-analysis', 'least-squares', 'parameter-estimation']"
53,Statistics - Book Recommendation [duplicate],Statistics - Book Recommendation [duplicate],,"This question already has answers here : Recommend a statistics fundamentals book (6 answers) Closed 3 years ago . I am taking a course in statistics. It covers: Parameter estimations: point and interval estimations, etc. Hypothesis testing: comparison of means, comparison of probabilities, Chi square tests, etc. Analysis of variance.. And the like. What are some books that you would recommend for such a course? Thanks.","This question already has answers here : Recommend a statistics fundamentals book (6 answers) Closed 3 years ago . I am taking a course in statistics. It covers: Parameter estimations: point and interval estimations, etc. Hypothesis testing: comparison of means, comparison of probabilities, Chi square tests, etc. Analysis of variance.. And the like. What are some books that you would recommend for such a course? Thanks.",,['statistics']
54,Variances for K-Means clustering,Variances for K-Means clustering,,"Can somebody help me understand formulas with an example in the below image? The below image is about K-means clustering. The formulas are about calculations for the variance for within-clusters and between-clusters, and the total variance. Please, let me have your expertise with a small example. Thank you and my apologies if I have put my questions in the wrong place.","Can somebody help me understand formulas with an example in the below image? The below image is about K-means clustering. The formulas are about calculations for the variance for within-clusters and between-clusters, and the total variance. Please, let me have your expertise with a small example. Thank you and my apologies if I have put my questions in the wrong place.",,"['statistics', 'discrete-mathematics', 'mathematical-physics', 'machine-learning']"
55,Expectation of first and second order statistics in a random distribution,Expectation of first and second order statistics in a random distribution,,"Let $E(f_{i}^{n})$ and $E(s_{i}^{n})$ denote the expected first and second order statistics for $n$ draws from the distribution $V_i$ .i.e set $X_{i}^{n}=\{x^1,.....,x^n | x^j \sim V_i \}$ and let $f_{i}^{n}$ be the minimum value of $X_{i}^{n}$ and $s_{i}^{n}$ the second minimum value. I would like your help with understanding if there's a mathematical $O(1)$ complexity way for computing the above expectations of the second and first order statistic in any type of distribution: should I refer this computing as a fixed time action in terms of complexity or is it $O(n)$ in some distributions?","Let $E(f_{i}^{n})$ and $E(s_{i}^{n})$ denote the expected first and second order statistics for $n$ draws from the distribution $V_i$ .i.e set $X_{i}^{n}=\{x^1,.....,x^n | x^j \sim V_i \}$ and let $f_{i}^{n}$ be the minimum value of $X_{i}^{n}$ and $s_{i}^{n}$ the second minimum value. I would like your help with understanding if there's a mathematical $O(1)$ complexity way for computing the above expectations of the second and first order statistic in any type of distribution: should I refer this computing as a fixed time action in terms of complexity or is it $O(n)$ in some distributions?",,"['statistics', 'probability-distributions', 'expectation', 'order-statistics']"
56,Statistics formula for wifi positioning.,Statistics formula for wifi positioning.,,"Assuming I have $3$ access point namely: $AC_1$, $AC_2$ and $AC_3$ and I want to know my location using this access point and a mobile device that will get signal from the access points. First thing that I did is save the signal level for different location in the database. In the first location the signal level for $AC_1$ is $-20 \ \rm{dBm}$, the signal level for $AC_2$ is $-30 \ \rm{dBm}$ and signal level for $AC_3$ is $-40 \ \rm{dBm}$. In second location the signal level for $AC_1$ is $-10 \ \rm{dBm}$, the signal level for $AC_2$ is $-40 \ \rm{dBm}$ and signal level for $AC_3$ is $-50 \ \rm{dBm}$. Finally, for the third location the signal level for $AC_1$ is $-30 \ \rm{dBm}$, the signal level for $AC_2$ is $-50 \ \rm{dBm}$ and the signal level for $AC_3$ is $-60 \ \rm{dBm}$. Now during my actual location detection phase how will I know my current location ? For example I read this signal : $AC_1$ is $-15 \ \rm{dBm}$, $AC_2$ is $-35 \ \rm{dBm}$ and $AC_3$ is $-45 \ \rm{dBm}$. How will I know my current location? My big problem is that signal level is not the same in one location there are times that it will fluctuate. What do you think is the best thing to do for this ?","Assuming I have $3$ access point namely: $AC_1$, $AC_2$ and $AC_3$ and I want to know my location using this access point and a mobile device that will get signal from the access points. First thing that I did is save the signal level for different location in the database. In the first location the signal level for $AC_1$ is $-20 \ \rm{dBm}$, the signal level for $AC_2$ is $-30 \ \rm{dBm}$ and signal level for $AC_3$ is $-40 \ \rm{dBm}$. In second location the signal level for $AC_1$ is $-10 \ \rm{dBm}$, the signal level for $AC_2$ is $-40 \ \rm{dBm}$ and signal level for $AC_3$ is $-50 \ \rm{dBm}$. Finally, for the third location the signal level for $AC_1$ is $-30 \ \rm{dBm}$, the signal level for $AC_2$ is $-50 \ \rm{dBm}$ and the signal level for $AC_3$ is $-60 \ \rm{dBm}$. Now during my actual location detection phase how will I know my current location ? For example I read this signal : $AC_1$ is $-15 \ \rm{dBm}$, $AC_2$ is $-35 \ \rm{dBm}$ and $AC_3$ is $-45 \ \rm{dBm}$. How will I know my current location? My big problem is that signal level is not the same in one location there are times that it will fluctuate. What do you think is the best thing to do for this ?",,['statistics']
57,Highest points in heart cycle graph,Highest points in heart cycle graph,,"I'm working on an application that reads the heart cycle from a device, and I've aimed to get this image: Now, I need to get the highest points that appear in every cycle in order to calculate the period from diastole or systole, but the problem is that every period can be placed on a different y-axis range. How can I find the highest points with math or statistics without performing comparisons to software level? I need to know how often the high points are.","I'm working on an application that reads the heart cycle from a device, and I've aimed to get this image: Now, I need to get the highest points that appear in every cycle in order to calculate the period from diastole or systole, but the problem is that every period can be placed on a different y-axis range. How can I find the highest points with math or statistics without performing comparisons to software level? I need to know how often the high points are.",,"['statistics', 'data-analysis']"
58,help understanding step in derivation of correlation coefficient,help understanding step in derivation of correlation coefficient,,"I'm looking to understand the starred step in the derivation below (also, if someone could help with the LaTex alignment, I'd appreciate it). The regression line is $y= b_0 + b_1 x$, where $b_0$ and $b_1$ can be found by: 1) taking the difference between each observed value $y_i$ and the expected point regression line, $b_0 + b_1 x_i$ $$\text{ difference } = y_i - b_0 -b_1 x_i$$ 2) summing the square of the differences from 1) to get the sum of squares $$SS = \sum \limits_{i=1}^n (y_i - b_0 -b_1 x_i)^2$$ 3) taking the partial derivative with respect to $b_0$ and $b_1$, then solving for each $$ \begin{align} \text{ solving for } b_0 \\ SS &= \sum(y_i - b_0 -b_1 x_i)^2\\ SS &= \sum (Y_i ^2 - 2Y_i b_0 - 2 Y_i b_1+ 2b_0 b_1X_i + b_1^2X_i^2+b_0^2) &\text{expand the square}\\ \frac{ \partial }{\partial_{b_0} }SS &= \sum (-2Y_i + 2b_1 X_i + 2b_0) &\text{partial derivative wrt} b_0\\ 0 &= \sum 2(-Y_i + b_1 X_i + b_0) &\text{factor out 2 from the sum}\\ 0 &= \sum (-Y_i + b_1 X_i + b_0) &\text{divide both sides by 2}\\ 0 &= \sum -Y_i + \sum b_1 X_i + \sum b_0 &\text{split summation into parts}\\ \sum Y_i &= \sum b_1 X_i + \sum b_0 \\ \sum Y_i &= b_1 \sum X_i + n b_0 \\ \frac{1}{n}(\sum Y_i - b_1 \sum X_i ) &=  b_0 \\ \bar Y - b_1 \bar X &=  b_0 \text {  rewrite sums as averages since } \frac{1}{n} \sum Y_i = \bar Y\\ \end{align} $$ $$ \begin{align} \\ \text{solving for } b_1\\ \frac{ \partial }{\partial_{b_1} }SS &= \sum (-2Y_iX_i + 2b_0 X_i + 2 b_1 X_i^2) &\text{ partial derivative wrt } b_1\\ 0 &= 2\sum (-Y_iX_i + b_0 X_i +  b_1 X_i^2) \\ 0 &= \sum (-Y_iX_i + b_0 X_i +  b_1 X_i^2) \\ 0 &=  -\sum Y_iX_i + b_0 \sum X_i +  b_1 \sum X_i^2 &\text{ split summation}\\ 0 &=  -\sum Y_iX_i + (\bar Y - b_1 \bar X) \sum X_i +  b_1 \sum X_i^2 &\text{ substitue } b_0\\ 0 &=  -\sum Y_iX_i + (\bar Y \sum X_i - b_1 \bar X \sum X_i)  +  b_1 \sum X_i^2 &\text{ distribute sum}\\ b_1 \bar X \sum X_i - b_1 \sum X_i^2 &=  -\sum Y_iX_i + \bar Y \sum X_i     &\text{ collect } b_1 \text{ terms}\\ b_1 (\bar X \sum X_i - \sum X_i^2) &=  -\sum Y_iX_i + \bar Y \sum X_i   \\ b_1  &= { \bar Y \sum X_i -\sum Y_iX_i \over (\bar X \sum X_i - \sum X_i^2)   }\\ b_1  &= { \frac{1}{n} \sum Y_i \sum X_i -\sum Y_iX_i \over (\frac{1}{n} \sum X_i \sum X_i - \sum X_i^2)   } \biggr ( \frac{-n}{-n} \biggr )\\ b_1  &= { n \sum Y_iX_i - \sum Y_i \sum X_i   \over n \sum X_i^2 -(\sum X_i)^2     } \\ \end{align} $$ $$ \begin{align} b_0 &= \frac{1}{n} \sum y_i - b_1 \frac{1}{n} \sum x_i\\\\\\ b_1 &= {n \sum x_i y_i - \sum x_i \sum y_i \over n \sum x_i^2-(\sum x_i)^2} \end{align} $$ (derivation shown in http://polisci.msu.edu/jacoby/icpsr/regress3/lectures/week2/5.LeastSquares.pdf ) From this point you can use $b_1$ to get the correlation coefficient as follows: $$ \begin{align} b_1 &= {\frac{1}{n} \sum x_i y_i - (\frac{1}{n}\sum x_i) (\frac{1}{n} \sum y_i ) \over (\frac{1}{n} \sum x_i^2) -(\frac{1}{n}\sum x_i)^2}  & \text{ divide top and bottom by } n^2 \\\\ b_1 &= {\frac{1}{n} \sum x_i y_i - (\bar x) (\bar y ) \over (\frac{1}{n} \sum x_i^2) -(\bar x)^2}  & \text{ rewrite product of sums as averages }  \\\\ b_1 &= {\frac{1}{n} \sum (x_i - \bar x)(y_i - \bar y ) \over \frac{1}{n} \sum (x_i - \bar x)^2}  & \color{red} *\text{application of inscrutably arcane magic} \\\\ b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2} \sqrt{\sum (x_i - \bar x)^2} } & \text{cancel } \frac{1}{n}\text{, factor denominator }\\\\ b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2} \sqrt{\sum ( x_i - \bar x)^2} } \biggr({\sqrt{\sum(y_i - \bar y)^2} \over \sqrt{\sum(y_i - \bar y)^2}}\biggr) & \text{multiply by 1 } \\\\ b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2}  \sqrt{\sum(y_i - \bar y)^2}} \biggr({\sqrt{\sum(y_i - \bar y)^2} \over \sqrt{\sum ( x_i - \bar x)^2} }\biggr) & \text{re-arrange } \\\\ b_1 &= R \frac{S_x}{S_y} \end {align} $$","I'm looking to understand the starred step in the derivation below (also, if someone could help with the LaTex alignment, I'd appreciate it). The regression line is $y= b_0 + b_1 x$, where $b_0$ and $b_1$ can be found by: 1) taking the difference between each observed value $y_i$ and the expected point regression line, $b_0 + b_1 x_i$ $$\text{ difference } = y_i - b_0 -b_1 x_i$$ 2) summing the square of the differences from 1) to get the sum of squares $$SS = \sum \limits_{i=1}^n (y_i - b_0 -b_1 x_i)^2$$ 3) taking the partial derivative with respect to $b_0$ and $b_1$, then solving for each $$ \begin{align} \text{ solving for } b_0 \\ SS &= \sum(y_i - b_0 -b_1 x_i)^2\\ SS &= \sum (Y_i ^2 - 2Y_i b_0 - 2 Y_i b_1+ 2b_0 b_1X_i + b_1^2X_i^2+b_0^2) &\text{expand the square}\\ \frac{ \partial }{\partial_{b_0} }SS &= \sum (-2Y_i + 2b_1 X_i + 2b_0) &\text{partial derivative wrt} b_0\\ 0 &= \sum 2(-Y_i + b_1 X_i + b_0) &\text{factor out 2 from the sum}\\ 0 &= \sum (-Y_i + b_1 X_i + b_0) &\text{divide both sides by 2}\\ 0 &= \sum -Y_i + \sum b_1 X_i + \sum b_0 &\text{split summation into parts}\\ \sum Y_i &= \sum b_1 X_i + \sum b_0 \\ \sum Y_i &= b_1 \sum X_i + n b_0 \\ \frac{1}{n}(\sum Y_i - b_1 \sum X_i ) &=  b_0 \\ \bar Y - b_1 \bar X &=  b_0 \text {  rewrite sums as averages since } \frac{1}{n} \sum Y_i = \bar Y\\ \end{align} $$ $$ \begin{align} \\ \text{solving for } b_1\\ \frac{ \partial }{\partial_{b_1} }SS &= \sum (-2Y_iX_i + 2b_0 X_i + 2 b_1 X_i^2) &\text{ partial derivative wrt } b_1\\ 0 &= 2\sum (-Y_iX_i + b_0 X_i +  b_1 X_i^2) \\ 0 &= \sum (-Y_iX_i + b_0 X_i +  b_1 X_i^2) \\ 0 &=  -\sum Y_iX_i + b_0 \sum X_i +  b_1 \sum X_i^2 &\text{ split summation}\\ 0 &=  -\sum Y_iX_i + (\bar Y - b_1 \bar X) \sum X_i +  b_1 \sum X_i^2 &\text{ substitue } b_0\\ 0 &=  -\sum Y_iX_i + (\bar Y \sum X_i - b_1 \bar X \sum X_i)  +  b_1 \sum X_i^2 &\text{ distribute sum}\\ b_1 \bar X \sum X_i - b_1 \sum X_i^2 &=  -\sum Y_iX_i + \bar Y \sum X_i     &\text{ collect } b_1 \text{ terms}\\ b_1 (\bar X \sum X_i - \sum X_i^2) &=  -\sum Y_iX_i + \bar Y \sum X_i   \\ b_1  &= { \bar Y \sum X_i -\sum Y_iX_i \over (\bar X \sum X_i - \sum X_i^2)   }\\ b_1  &= { \frac{1}{n} \sum Y_i \sum X_i -\sum Y_iX_i \over (\frac{1}{n} \sum X_i \sum X_i - \sum X_i^2)   } \biggr ( \frac{-n}{-n} \biggr )\\ b_1  &= { n \sum Y_iX_i - \sum Y_i \sum X_i   \over n \sum X_i^2 -(\sum X_i)^2     } \\ \end{align} $$ $$ \begin{align} b_0 &= \frac{1}{n} \sum y_i - b_1 \frac{1}{n} \sum x_i\\\\\\ b_1 &= {n \sum x_i y_i - \sum x_i \sum y_i \over n \sum x_i^2-(\sum x_i)^2} \end{align} $$ (derivation shown in http://polisci.msu.edu/jacoby/icpsr/regress3/lectures/week2/5.LeastSquares.pdf ) From this point you can use $b_1$ to get the correlation coefficient as follows: $$ \begin{align} b_1 &= {\frac{1}{n} \sum x_i y_i - (\frac{1}{n}\sum x_i) (\frac{1}{n} \sum y_i ) \over (\frac{1}{n} \sum x_i^2) -(\frac{1}{n}\sum x_i)^2}  & \text{ divide top and bottom by } n^2 \\\\ b_1 &= {\frac{1}{n} \sum x_i y_i - (\bar x) (\bar y ) \over (\frac{1}{n} \sum x_i^2) -(\bar x)^2}  & \text{ rewrite product of sums as averages }  \\\\ b_1 &= {\frac{1}{n} \sum (x_i - \bar x)(y_i - \bar y ) \over \frac{1}{n} \sum (x_i - \bar x)^2}  & \color{red} *\text{application of inscrutably arcane magic} \\\\ b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2} \sqrt{\sum (x_i - \bar x)^2} } & \text{cancel } \frac{1}{n}\text{, factor denominator }\\\\ b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2} \sqrt{\sum ( x_i - \bar x)^2} } \biggr({\sqrt{\sum(y_i - \bar y)^2} \over \sqrt{\sum(y_i - \bar y)^2}}\biggr) & \text{multiply by 1 } \\\\ b_1 &= { \sum (x_i - \bar x)(y_i - \bar y ) \over \sqrt{\sum (x_i - \bar x)^2}  \sqrt{\sum(y_i - \bar y)^2}} \biggr({\sqrt{\sum(y_i - \bar y)^2} \over \sqrt{\sum ( x_i - \bar x)^2} }\biggr) & \text{re-arrange } \\\\ b_1 &= R \frac{S_x}{S_y} \end {align} $$",,"['statistics', 'correlation']"
59,Derive the PDF of the log-normal distribution?,Derive the PDF of the log-normal distribution?,,"If $X \sim N(0,1)$ and $Y = e^X$, find the PDF of $Y$ using the two methods: (i) Find the CDF of of $Y$ and then differentiate. Use the notation $\Phi(x)$ and $\phi(x)$ for the CDF and PDF of $X$ respectively. You may use the fact that $\phi(x) = \Phi'(x)$. So I'm not sure how to differentiate $\Phi\big(\dfrac{\ln x-\mu}{\sigma} \bigg)$ to get $\dfrac{1}{x\sigma\sqrt{2\pi}}e^-\frac{(\ln x-\mu)^2}{2\sigma^2}$ (ii) Use the transformation formula. I'm not sure where to even begin with this one.","If $X \sim N(0,1)$ and $Y = e^X$, find the PDF of $Y$ using the two methods: (i) Find the CDF of of $Y$ and then differentiate. Use the notation $\Phi(x)$ and $\phi(x)$ for the CDF and PDF of $X$ respectively. You may use the fact that $\phi(x) = \Phi'(x)$. So I'm not sure how to differentiate $\Phi\big(\dfrac{\ln x-\mu}{\sigma} \bigg)$ to get $\dfrac{1}{x\sigma\sqrt{2\pi}}e^-\frac{(\ln x-\mu)^2}{2\sigma^2}$ (ii) Use the transformation formula. I'm not sure where to even begin with this one.",,"['statistics', 'probability-distributions', 'logarithms', 'normal-distribution', 'exponential-function']"
60,Can we compute confidence intervals for the variance of an unknown distributions from sample variances?,Can we compute confidence intervals for the variance of an unknown distributions from sample variances?,,"Assume $X_1,\ldots,X_n$ are i.i.d. with unknown distribution $\mathcal D$ - we only know it is not normal and has finite variance. Is there a way to give confidence intervals for the variance of $\mathcal D$? Can we base the confidence interval on the sample variance $\hat \sigma^2 = \frac1{n-1}\sum_{i=1}^n (X_i - \bar X)^2$ with $\bar X = \frac1n\sum_{i=1}^n X_i$ the sample mean? If it helps, we can restrict ourselves to distributions with mean $0$. (From my application, I can compute the exact mean $\mu$ of $\mathcal D$ and then consider $Y_i := X_i - \mu$ to estimate the variance.) I know the approaches via $\chi^2$-distribution if we assume a normal distribution $\mathcal D = \mathcal N(\mu,\sigma^2)$, but I as noted above $\mathcal D$ is not normal.","Assume $X_1,\ldots,X_n$ are i.i.d. with unknown distribution $\mathcal D$ - we only know it is not normal and has finite variance. Is there a way to give confidence intervals for the variance of $\mathcal D$? Can we base the confidence interval on the sample variance $\hat \sigma^2 = \frac1{n-1}\sum_{i=1}^n (X_i - \bar X)^2$ with $\bar X = \frac1n\sum_{i=1}^n X_i$ the sample mean? If it helps, we can restrict ourselves to distributions with mean $0$. (From my application, I can compute the exact mean $\mu$ of $\mathcal D$ and then consider $Y_i := X_i - \mu$ to estimate the variance.) I know the approaches via $\chi^2$-distribution if we assume a normal distribution $\mathcal D = \mathcal N(\mu,\sigma^2)$, but I as noted above $\mathcal D$ is not normal.",,"['statistics', 'parameter-estimation']"
61,"Proof of $ \text{Var}\,\left(\sum_{i=1}^{n}g(X_i)\right)=n\left(\text{Var}\,g(X_1)\right).$",Proof of," \text{Var}\,\left(\sum_{i=1}^{n}g(X_i)\right)=n\left(\text{Var}\,g(X_1)\right).","I have a question about part of a proof of a Lemma in a book (Casella's Statistical Inference) I'm reading. This it how it goes. Let $X_1, \cdots ,X_n$ are a random sample from a population and let $g(x)$ be a function such that $\mathbb{E}g(X_1)$  and $\text{Var}\,g(X_1)$ exist. Then $$ \text{Var}\,\left(\sum_{i=1}^{n}g(X_i)\right)=n\left(\text{Var}\,g(X_1)\right).$$ So this is how I proceeded to to prove it. Since the $X_i's$ are independent, we have that $$ \begin {align*}    \text{Var}\,\left(\sum_{i=1}^{n}g(X_i)\right)&= \text{Var}\,g(X_1)+\cdots +\text{Var}\,g(X_n)\\ &= n\text{Var}\, g(X_1). \end {align*}$$  where the last equality holds because the $X_i's$ are identically distributed.  Can I do this? I'm asking this because the proof in the book started by using the definition of the variance and somewhere along the lines involved the covariance matrix. Thanks.","I have a question about part of a proof of a Lemma in a book (Casella's Statistical Inference) I'm reading. This it how it goes. Let $X_1, \cdots ,X_n$ are a random sample from a population and let $g(x)$ be a function such that $\mathbb{E}g(X_1)$  and $\text{Var}\,g(X_1)$ exist. Then $$ \text{Var}\,\left(\sum_{i=1}^{n}g(X_i)\right)=n\left(\text{Var}\,g(X_1)\right).$$ So this is how I proceeded to to prove it. Since the $X_i's$ are independent, we have that $$ \begin {align*}    \text{Var}\,\left(\sum_{i=1}^{n}g(X_i)\right)&= \text{Var}\,g(X_1)+\cdots +\text{Var}\,g(X_n)\\ &= n\text{Var}\, g(X_1). \end {align*}$$  where the last equality holds because the $X_i's$ are identically distributed.  Can I do this? I'm asking this because the proof in the book started by using the definition of the variance and somewhere along the lines involved the covariance matrix. Thanks.",,['statistics']
62,Variance of $\overline{X}_n^2$,Variance of,\overline{X}_n^2,"Here is a problem a have got in my homework. Given a set of $X_1, ... X_n \sim F$ i.i.d values find the variance of $T_n = \overline{X}_n^2$ where $\overline{X}_n = \frac{\sum_i{X_i}}{n}$. I actualy have an answer for this problem: $V(T_n) = \frac{4 \mu^2 \alpha_2}{n} + \frac{4 \mu \alpha_3}{n^2} + \frac{\alpha_4}{n^3}$ where $\mu = E(X_1)$ and $\alpha_k = \int \left| x - \mu \right|^k dF(x)$. But I can't figure out how it was obtained. Here is what I got so far: $V(\overline{X}_n^2) = E\left[\overline{X}_n^4\right] - \left[E(\overline{X}_n^2)\right]^2 = E\left[\overline{X}_n^4\right] - \left[V(\overline{X}_n) + \left(E(\overline{X}_n)\right)^2\right]^2$ where  $E(\overline{X}_n) = \mu$,  $V(\overline{X}_n) = \frac{\alpha_2}{n}$ so $E(\overline{X}_n^2) = \mu^2 + \frac{\alpha_2}{n}$ the question is what $E(\overline{X}_n^4)$ equals to. If you have any thought about that problem, hint or solution, please, tell me.","Here is a problem a have got in my homework. Given a set of $X_1, ... X_n \sim F$ i.i.d values find the variance of $T_n = \overline{X}_n^2$ where $\overline{X}_n = \frac{\sum_i{X_i}}{n}$. I actualy have an answer for this problem: $V(T_n) = \frac{4 \mu^2 \alpha_2}{n} + \frac{4 \mu \alpha_3}{n^2} + \frac{\alpha_4}{n^3}$ where $\mu = E(X_1)$ and $\alpha_k = \int \left| x - \mu \right|^k dF(x)$. But I can't figure out how it was obtained. Here is what I got so far: $V(\overline{X}_n^2) = E\left[\overline{X}_n^4\right] - \left[E(\overline{X}_n^2)\right]^2 = E\left[\overline{X}_n^4\right] - \left[V(\overline{X}_n) + \left(E(\overline{X}_n)\right)^2\right]^2$ where  $E(\overline{X}_n) = \mu$,  $V(\overline{X}_n) = \frac{\alpha_2}{n}$ so $E(\overline{X}_n^2) = \mu^2 + \frac{\alpha_2}{n}$ the question is what $E(\overline{X}_n^4)$ equals to. If you have any thought about that problem, hint or solution, please, tell me.",,['statistics']
63,"Sufficient statistic for $\theta$ in $N(\theta,\theta)$ model",Sufficient statistic for  in  model,"\theta N(\theta,\theta)","I recently encountered a MCQ question which goes like this: Let $X_1,X_2,...,X_n$ be independent random samples from $N(\theta,\theta)$ , where both the mean and variance are $\theta$ , where $\theta$ is unknown. Then which of the following statements is/are true? (a) $\sum (X_i)^2$ is sufficient for $\theta$ (b) $\sum (X_i)$ is sufficient for $\theta$ (c) [ $\sum (X_i)$ , $\sum (X_i)^2$ ] is sufficient for $\theta$ (d) Sufficient statistics does not exist. My Attempt: Using the factorization theorem, $$f(x_i,\theta) = \frac{1}{\sqrt{2\pi\theta}} e^\frac{-(x_i-\theta)^2}{2\theta}$$ $$\prod f(x_i,\theta) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\theta}} e^\frac{-(x_i-\theta)^2}{2\theta}                       = (\frac{1}{\sqrt{2\pi\theta}})^n e^\frac{-\sum_{i=1}^{n} (x_i-\theta)^2}{2\theta} \\                       =(\frac{1}{\sqrt{2\pi\theta}})^n  (e^\frac{-\sum_{i=1}^{n} (x_i)^2}{2\theta}e^\frac{-\theta}{2})   e^{\sum_{i=1}^{n} (x_i)}   = f_1(t,\theta) f_2(x_i)$$ where $T=\sum_{i=1}^{n}(X_i)^2$ . Thus, the statistic $T$ is sufficient for $\theta$ , implying (a) is ture and (d) is false. However, the answer for the MCQ is given as (a), (b) and (c). I am not able to prove (b) and (c) using the factorization theorem. Please help.","I recently encountered a MCQ question which goes like this: Let be independent random samples from , where both the mean and variance are , where is unknown. Then which of the following statements is/are true? (a) is sufficient for (b) is sufficient for (c) [ , ] is sufficient for (d) Sufficient statistics does not exist. My Attempt: Using the factorization theorem, where . Thus, the statistic is sufficient for , implying (a) is ture and (d) is false. However, the answer for the MCQ is given as (a), (b) and (c). I am not able to prove (b) and (c) using the factorization theorem. Please help.","X_1,X_2,...,X_n N(\theta,\theta) \theta \theta \sum (X_i)^2 \theta \sum (X_i) \theta \sum (X_i) \sum (X_i)^2 \theta f(x_i,\theta) = \frac{1}{\sqrt{2\pi\theta}} e^\frac{-(x_i-\theta)^2}{2\theta} \prod f(x_i,\theta) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\theta}} e^\frac{-(x_i-\theta)^2}{2\theta}
                      = (\frac{1}{\sqrt{2\pi\theta}})^n e^\frac{-\sum_{i=1}^{n} (x_i-\theta)^2}{2\theta} \\
                      =(\frac{1}{\sqrt{2\pi\theta}})^n  (e^\frac{-\sum_{i=1}^{n} (x_i)^2}{2\theta}e^\frac{-\theta}{2})   e^{\sum_{i=1}^{n} (x_i)}  
= f_1(t,\theta) f_2(x_i) T=\sum_{i=1}^{n}(X_i)^2 T \theta","['statistics', 'probability-distributions', 'normal-distribution', 'statistical-inference']"
64,Finding minimum value of $1/(p_1n_1) + 1/(p_2n_2) + 1/(p_3n_3) + \dots + 1/(p_kn_k)$,Finding minimum value of,1/(p_1n_1) + 1/(p_2n_2) + 1/(p_3n_3) + \dots + 1/(p_kn_k),"While solving a statistic problem, I come across an equation: The value of $p_1$ is given, and $p_{i+1} = p_i / (1-(1-p_i)^{n_i})$ . $$E = p_1  (\frac{1}{p_1  n_1} + \frac{1}{p_2 n_2} + \dots + \frac{1}{p_{k-1}  n_{k-1}} + \frac{1}{p_k  n_k}) = p_1  \sum_i\frac{1}{p_i n_i},$$ where $i = 1, \dots, k$ , $0<p_i<1$ , $n_i \in N$ , $n_k = 1$ . The task is to (1) find the number $k$ , and (2) find each $n_i$ , such that $E$ has minimum value. After some brute-force searches with a computer program I wrote, it seems that the $n_i$ and $p_i$ that give the minimum value to $E$ have the property: $n_i/n_{i+1}≈2$ and $p_{i+1}/p_i≈2$ , except the last term. This is all I've got so far. Any thought on solving this problem other than brute-force searches? Thank you. -- Below are some results of the brute-force searches. For $p_1$ >0.01, this program works well to find the best combination of $n_i$ and $k$ . However, for $p_1$ <0.01, it will be too much work to exhaust the search.","While solving a statistic problem, I come across an equation: The value of is given, and . where , , , . The task is to (1) find the number , and (2) find each , such that has minimum value. After some brute-force searches with a computer program I wrote, it seems that the and that give the minimum value to have the property: and , except the last term. This is all I've got so far. Any thought on solving this problem other than brute-force searches? Thank you. -- Below are some results of the brute-force searches. For >0.01, this program works well to find the best combination of and . However, for <0.01, it will be too much work to exhaust the search.","p_1 p_{i+1} = p_i / (1-(1-p_i)^{n_i}) E = p_1  (\frac{1}{p_1  n_1} + \frac{1}{p_2 n_2} + \dots + \frac{1}{p_{k-1}  n_{k-1}} + \frac{1}{p_k  n_k})
= p_1  \sum_i\frac{1}{p_i n_i}, i = 1, \dots, k 0<p_i<1 n_i \in N n_k = 1 k n_i E n_i p_i E n_i/n_{i+1}≈2 p_{i+1}/p_i≈2 p_1 n_i k p_1","['statistics', 'expected-value']"
65,Statistical Odds calculation for a video game occurrence,Statistical Odds calculation for a video game occurrence,,"In a video game I'm playing, there is a random number generator that awards one trophy from a pool of possible trophies.  The pool of possible trophies is approximately 60 different items, and I was supposed to be awarded 5 random ones.  I received 3 of one type, and 2 of another. I'm trying to estimate the odds of this occurrence, versus the odds of receiving 5 different ones. For the ""3 of the same type"" the odds would be 1 out of 3600, and the odds of ""2 of the same type"" is 1 out 60.  Or not? Does the order of events impact the odds?  If so, the order was: #1, #1, #2, #1, #2.  Would this imply the odds at each stage were NA, 1:50, 1:49, 1:48, 1:48 ? Apologies in advance if my terminology is incorrect.  I know ""odds"" and ""probability"" are not interchangeable, but it's been a LOOOONG time since my college statistics class. TIA.","In a video game I'm playing, there is a random number generator that awards one trophy from a pool of possible trophies.  The pool of possible trophies is approximately 60 different items, and I was supposed to be awarded 5 random ones.  I received 3 of one type, and 2 of another. I'm trying to estimate the odds of this occurrence, versus the odds of receiving 5 different ones. For the ""3 of the same type"" the odds would be 1 out of 3600, and the odds of ""2 of the same type"" is 1 out 60.  Or not? Does the order of events impact the odds?  If so, the order was: #1, #1, #2, #1, #2.  Would this imply the odds at each stage were NA, 1:50, 1:49, 1:48, 1:48 ? Apologies in advance if my terminology is incorrect.  I know ""odds"" and ""probability"" are not interchangeable, but it's been a LOOOONG time since my college statistics class. TIA.",,['statistics']
66,"Bayesian statistics notation: ""$P(\text{event}|x)$"" vs ""$P(\text{event}|\theta, x)$""","Bayesian statistics notation: """" vs """"","P(\text{event}|x) P(\text{event}|\theta, x)","Now I am  new to the subject so, having some rotational problems. My issues are - What is the meaning of $P(\text{good bus tomorrow}|x) $ and $P(\text{good bus tomorrow}|\theta, x)$ or what are the differences between these two? Why $ P(\text{good bus tomorrow}|\theta, x)= \theta$ ? Is it because, actually $ P(\text{good bus tomorrow}|\theta, x)= p(\theta)$ but in this case,  the probability of $\theta $ is $\theta$ , i.e. $p(\theta)=\theta$ ? Let me clarify what I am talking about. The problem on page $22$ of the text of Introduction to Bayesian Statistics by Brendon J. Brewer is written as following  - After moving to Auckland, I decided that I would take the bus to work each day. However, I wasn’t very confident with the bus system in my new city, so for the first week I just took the first bus that came along and was heading in the right direction, towards the city. In the first week, I caught 5 morning buses. Of these 5 buses, two of them took me to the right place, while three of them took me far from work, leaving me with an extra 20 minute walk. Given this information, I would like to try to infer the proportion of the buses that are ""good"", that would take me right to campus. Let us call this fraction $\theta$ and we will infer $\theta$ using the Bayesian framework. Here, $\theta =2/5.$ For example, look the following image - Recall that, if there are $N$ repetitions of a ""random experiment"" and the ""success"" probability is $\theta$ at each repetition, then the number of ""successes"" $x$ . To get the likelihoods, we need to think about the properties of our experiment. In particular, we should imagine that we knew the value of $\theta$ and were trying to predict what experimental outcome (data) would occur. Ultimately, we want to find the probability of our actual data set (2 out of the 5 buses were ""good""), for all of our possible $\theta$ values. $P(\theta|x)$ is the posterior probability. It describes $\textbf{how certain or confident we are that hypothesis $\theta$ is true, given that}$ we have observed data $x$ . Calculating posterior probabilities is the main goal of Bayesian statistics! $P(\theta)$ is the prior probability, which describes $\textbf{how sure we were that}$ $\theta$ was true, before we observed the data $x$ . $P(x|\theta)$ is the likelihood. $\textbf{If you were to assume that $\theta$ is true, this is the probability}$ that you would have observed data $x$ . $P(x)$ is the marginal likelihood. This is the probability that you would have observed data $x$ , whether $\theta$ is true or not. So, $P (\theta|x) = \frac{P (\theta) P(x|\theta)}{P (x)}$ The following part is an excerpt from the same text - In the Bayesian framework, our predictions are always in the form of probabilities or (later) probability distributions. They are usually calculated in three stages. First, you pretend you actually know the true value of the parameters, and calculate the probability based on that assumption. Then, you do this for all possible values of the parameter $\theta$ (alternatively, you can calculate the probability as a function of $\theta$ ). Finally, you combine all of these probabilities in a particular way to get one final probability which tells you how confident you are of your prediction. Suppose we knew the true value of $\theta$ was $0.3$ . Then, we would know the probability of catching the right bus tomorrow is $0.3$ . If we knew the true value of $\theta$ was $0.4$ , we would say the probability of catching the right bus tomorrow is 0.4. The problem is, we don’t know what the true value is. We only have the posterior distribution. Luckily, the sum rule of probability (combined with the product rule) can help us out. We are interested in whether I will get the good bus tomorrow. There are $11$ different ways that can happen. Either $\theta=0$ and I get the good bus, or $\theta=0.1$ and I get the good bus, or $\theta=0.2$ and I get the good bus, and so on. These 11 ways are all mutually exclusive. That is, only one of them can be true (since $\theta$ is actually just a single number). Mathematically, we can obtain the posterior probability of catching the good bus tomorrow using the sum rule: $$P(\text{good bus tomorrow}|x) = \sum_{\theta} p(\theta|x) \times P(\text{good bus tomorrow}|\theta, x) $$ $$=  \sum_{\theta} p(\theta|x) \times \theta$$ This says that the total probability for a good bus tomorrow (given the data, i.e. using the posterior distribution and not the prior distribution) is given by going through each possible $\theta$ value, working out the probability assuming the $\theta$ value you are considering is true, multiplying by the probability (given the data) this $\theta$ value is actually true, and summing. In this particular problem, because $P\text{(good bus  tomorrow}|\theta, x) = θ$ , it just so happens that the probability for tomorrow is the expectation value of $\theta$ using the posterior distribution. To three decimal places, the result for the probability tomorrow is $0.429$ . Interestingly, this is not equal to $2/5 = 0.4$ .","Now I am  new to the subject so, having some rotational problems. My issues are - What is the meaning of and or what are the differences between these two? Why ? Is it because, actually but in this case,  the probability of is , i.e. ? Let me clarify what I am talking about. The problem on page of the text of Introduction to Bayesian Statistics by Brendon J. Brewer is written as following  - After moving to Auckland, I decided that I would take the bus to work each day. However, I wasn’t very confident with the bus system in my new city, so for the first week I just took the first bus that came along and was heading in the right direction, towards the city. In the first week, I caught 5 morning buses. Of these 5 buses, two of them took me to the right place, while three of them took me far from work, leaving me with an extra 20 minute walk. Given this information, I would like to try to infer the proportion of the buses that are ""good"", that would take me right to campus. Let us call this fraction and we will infer using the Bayesian framework. Here, For example, look the following image - Recall that, if there are repetitions of a ""random experiment"" and the ""success"" probability is at each repetition, then the number of ""successes"" . To get the likelihoods, we need to think about the properties of our experiment. In particular, we should imagine that we knew the value of and were trying to predict what experimental outcome (data) would occur. Ultimately, we want to find the probability of our actual data set (2 out of the 5 buses were ""good""), for all of our possible values. is the posterior probability. It describes we have observed data . Calculating posterior probabilities is the main goal of Bayesian statistics! is the prior probability, which describes was true, before we observed the data . is the likelihood. that you would have observed data . is the marginal likelihood. This is the probability that you would have observed data , whether is true or not. So, The following part is an excerpt from the same text - In the Bayesian framework, our predictions are always in the form of probabilities or (later) probability distributions. They are usually calculated in three stages. First, you pretend you actually know the true value of the parameters, and calculate the probability based on that assumption. Then, you do this for all possible values of the parameter (alternatively, you can calculate the probability as a function of ). Finally, you combine all of these probabilities in a particular way to get one final probability which tells you how confident you are of your prediction. Suppose we knew the true value of was . Then, we would know the probability of catching the right bus tomorrow is . If we knew the true value of was , we would say the probability of catching the right bus tomorrow is 0.4. The problem is, we don’t know what the true value is. We only have the posterior distribution. Luckily, the sum rule of probability (combined with the product rule) can help us out. We are interested in whether I will get the good bus tomorrow. There are different ways that can happen. Either and I get the good bus, or and I get the good bus, or and I get the good bus, and so on. These 11 ways are all mutually exclusive. That is, only one of them can be true (since is actually just a single number). Mathematically, we can obtain the posterior probability of catching the good bus tomorrow using the sum rule: This says that the total probability for a good bus tomorrow (given the data, i.e. using the posterior distribution and not the prior distribution) is given by going through each possible value, working out the probability assuming the value you are considering is true, multiplying by the probability (given the data) this value is actually true, and summing. In this particular problem, because , it just so happens that the probability for tomorrow is the expectation value of using the posterior distribution. To three decimal places, the result for the probability tomorrow is . Interestingly, this is not equal to .","P(\text{good bus tomorrow}|x)  P(\text{good bus tomorrow}|\theta, x)  P(\text{good bus tomorrow}|\theta, x)= \theta  P(\text{good bus tomorrow}|\theta, x)= p(\theta) \theta  \theta p(\theta)=\theta 22 \theta \theta \theta =2/5. N \theta x \theta \theta P(\theta|x) \textbf{how certain or confident we
are that hypothesis \theta is true, given that} x P(\theta) \textbf{how sure we were that} \theta x P(x|\theta) \textbf{If you were to assume that \theta is true, this is the
probability} x P(x) x \theta P (\theta|x) = \frac{P (\theta) P(x|\theta)}{P (x)} \theta \theta \theta 0.3 0.3 \theta 0.4 11 \theta=0 \theta=0.1 \theta=0.2 \theta P(\text{good bus tomorrow}|x) = \sum_{\theta} p(\theta|x) \times P(\text{good bus tomorrow}|\theta, x)  =  \sum_{\theta} p(\theta|x) \times \theta \theta \theta \theta P\text{(good bus  tomorrow}|\theta, x) = θ \theta 0.429 2/5 = 0.4","['statistics', 'notation', 'proof-explanation', 'statistical-inference', 'bayesian']"
67,What does the Kalman filter generally converge to? And why?,What does the Kalman filter generally converge to? And why?,,"So, i'm guessing whomever shows up here, knows what the Kalman filter is. It's quite an extensive model to type out, so here is an explanation from MIT (see ch. 11.5) We have a feeling that it converges to the observations, but we don't know how to show this. Can anyone help us out?","So, i'm guessing whomever shows up here, knows what the Kalman filter is. It's quite an extensive model to type out, so here is an explanation from MIT (see ch. 11.5) We have a feeling that it converges to the observations, but we don't know how to show this. Can anyone help us out?",,"['statistics', 'convergence-divergence', 'numerical-methods', 'control-theory', 'kalman-filter']"
68,Expectation and variance of top 10% of any normal distribution,Expectation and variance of top 10% of any normal distribution,,"Short: With the standard curve (i.e. mean=0, std dev=1), does the top 10% form its own normal distribution with the expectation about 1.74 and the standard deviation about .40? Long: I wrote a little program that takes the numbers 0.005,.015,.025,...,0.995, which is 100 numbers. I take the top 10 (.905-.995), find their z-score (1.31,1.37,...,2.58), sum them and divide by 10 and get 1.7447. In a similar manner, I go about finding the variance and get .1578, or a standard deviation of about .3972. All seems well so far. I then take the lower 90 numbers and calculate the expectation and get -.194. This works because if I use the law of iterated expectations, the expectation turns out to be 0, which we expect from the standard curve. I then use the law of total variance and get the unusual answer of 1.118, instead of 1. The expectation of the two variances is .658 and the variance of the two expectations is .460. This doesn't seem so bad, after all I'm approximating with 100 numbers. So then I ran it again with 1000 numbers and then with 10,000 numbers. It seems to be converging on a variance of about 1.116, which I did not expect. Any ideas on the discrepancy or a better way to figure this out? TIA, Cary","Short: With the standard curve (i.e. mean=0, std dev=1), does the top 10% form its own normal distribution with the expectation about 1.74 and the standard deviation about .40? Long: I wrote a little program that takes the numbers 0.005,.015,.025,...,0.995, which is 100 numbers. I take the top 10 (.905-.995), find their z-score (1.31,1.37,...,2.58), sum them and divide by 10 and get 1.7447. In a similar manner, I go about finding the variance and get .1578, or a standard deviation of about .3972. All seems well so far. I then take the lower 90 numbers and calculate the expectation and get -.194. This works because if I use the law of iterated expectations, the expectation turns out to be 0, which we expect from the standard curve. I then use the law of total variance and get the unusual answer of 1.118, instead of 1. The expectation of the two variances is .658 and the variance of the two expectations is .460. This doesn't seem so bad, after all I'm approximating with 100 numbers. So then I ran it again with 1000 numbers and then with 10,000 numbers. It seems to be converging on a variance of about 1.116, which I did not expect. Any ideas on the discrepancy or a better way to figure this out? TIA, Cary",,['statistics']
69,UMP level $\alpha$ test with distribution $f(x\mid\lambda) = \lambda x^{-2}$,UMP level  test with distribution,\alpha f(x\mid\lambda) = \lambda x^{-2},"Suppose we have a random sample from the distribution $f(x\mid\lambda) = \lambda x^{-2}$ with $x > \lambda$. I want to find a UMP level $\alpha$ test for the hypothesis test $H_0: \lambda = \lambda_0$ and $H_1: \lambda = \lambda_1$, where $\lambda_1 > \lambda_0$. I believe $\prod_{i=1}^n x_i$ is a sufficient statistic for $\lambda$, but I don't know what to do from here. Any hints/general strategies would be great.","Suppose we have a random sample from the distribution $f(x\mid\lambda) = \lambda x^{-2}$ with $x > \lambda$. I want to find a UMP level $\alpha$ test for the hypothesis test $H_0: \lambda = \lambda_0$ and $H_1: \lambda = \lambda_1$, where $\lambda_1 > \lambda_0$. I believe $\prod_{i=1}^n x_i$ is a sufficient statistic for $\lambda$, but I don't know what to do from here. Any hints/general strategies would be great.",,"['statistics', 'statistical-inference']"
70,Alternative proof that conditioning reduces entropy,Alternative proof that conditioning reduces entropy,,"I was going through some class notes which provide a different proof that conditioning reduces entropy from the usual one which relies on the fact that mutual information is non-negative. In this proof, I am confused by the second step which has an inequality: \begin{align} H(X|Y) &= \sum_x \sum_y p_y \left(- p_{x|y} \log p_{x|y}\right) \\   &\le \sum_x \left\{\left(-\sum_y p_y \, p_{x|y}\right)\left(\log \sum_y p_y \, p_{x|y} \right)\right\} \\  &= \sum_x - p_x \log p_x \\  &= H(X). \end{align} Basically, I'm not sure how the 2nd set of parentheses ends up being a log-sum containing $p_y$. My only thoughts are that maybe Jensen's inequality is being used here, or the Schwartz inequality, or some combination thereof, but I am not sure. Or is this just sloppy note-keeping? Thanks.","I was going through some class notes which provide a different proof that conditioning reduces entropy from the usual one which relies on the fact that mutual information is non-negative. In this proof, I am confused by the second step which has an inequality: \begin{align} H(X|Y) &= \sum_x \sum_y p_y \left(- p_{x|y} \log p_{x|y}\right) \\   &\le \sum_x \left\{\left(-\sum_y p_y \, p_{x|y}\right)\left(\log \sum_y p_y \, p_{x|y} \right)\right\} \\  &= \sum_x - p_x \log p_x \\  &= H(X). \end{align} Basically, I'm not sure how the 2nd set of parentheses ends up being a log-sum containing $p_y$. My only thoughts are that maybe Jensen's inequality is being used here, or the Schwartz inequality, or some combination thereof, but I am not sure. Or is this just sloppy note-keeping? Thanks.",,"['statistics', 'convex-analysis', 'information-theory']"
71,Approximating Poisson binomial distribution with normal distribution,Approximating Poisson binomial distribution with normal distribution,,"Question I am interested in any information about approximating the Poisson binomial distribution with the normal distribution. Specifically, I am interested in either analytic (a la Le Cam's theorem ) or heuristic (e.g. ``works well if the mean is greater than 10'') bounds on what happens if we approximate a Poisson binomial distribution with mean $\mu=\sum_{i=1}^n p_i$ and variance $\sigma^2=\sum_{i=1}^n p_i(1-p_i)$ by a normal distribution with mean $\mu$ and variance $\sigma^2$. Background Research This is the most relevent SE post I could find on the topic, but the subsequent discussion and answers don't seem to address my question. I have been able to find ample discussion (e.g. here ) of approximating the binomial ( not the Poisson binomial) distribution with the normal distribution, and approximating the Poisson distribution with the normal distribution, but neither of these have been helpful. I also found the paper A Refinement of Normal Approximation to Poisson Binomial by Neammanee (2005), where the author states in the first paragraph: [I]t is well known that the distribution of a Poisson binomial random variable can be approximated by the standard normal distribution. The author elaborates no further, and I can't find any other information about this. Disclaimer I am very new to statistics but I'm reasonably well versed in analysis (though not measure). Forgive me if this is a trivial question (as it seems to me it must be).","Question I am interested in any information about approximating the Poisson binomial distribution with the normal distribution. Specifically, I am interested in either analytic (a la Le Cam's theorem ) or heuristic (e.g. ``works well if the mean is greater than 10'') bounds on what happens if we approximate a Poisson binomial distribution with mean $\mu=\sum_{i=1}^n p_i$ and variance $\sigma^2=\sum_{i=1}^n p_i(1-p_i)$ by a normal distribution with mean $\mu$ and variance $\sigma^2$. Background Research This is the most relevent SE post I could find on the topic, but the subsequent discussion and answers don't seem to address my question. I have been able to find ample discussion (e.g. here ) of approximating the binomial ( not the Poisson binomial) distribution with the normal distribution, and approximating the Poisson distribution with the normal distribution, but neither of these have been helpful. I also found the paper A Refinement of Normal Approximation to Poisson Binomial by Neammanee (2005), where the author states in the first paragraph: [I]t is well known that the distribution of a Poisson binomial random variable can be approximated by the standard normal distribution. The author elaborates no further, and I can't find any other information about this. Disclaimer I am very new to statistics but I'm reasonably well versed in analysis (though not measure). Forgive me if this is a trivial question (as it seems to me it must be).",,"['statistics', 'normal-distribution', 'poisson-distribution', 'binomial-distribution']"
72,Find the asymptotic distribution of the MME and MLE.,Find the asymptotic distribution of the MME and MLE.,,"Question: Let $X_1, ..., X_n$ be i.i.d random variables with the density function $$f(x|\theta) = (\theta+1)x^\theta, 0≤x≤1$$ Find the asymptotic distribution of the MME and MLE. My Guess : I know from doing a previous part in the question that the: a) MME: $\hat \theta$ =  $\frac{1-2\bar X}{\bar X-1}$ b) MLE: $\hat \theta$ = $-1 -$ $\frac{n}{\sum_{i=1}^n \log (X_i)}$ However, I'm a little confused as to what the question is asking for in finding the asymptotic distribution. Any help is appreciated. Thanks!","Question: Let $X_1, ..., X_n$ be i.i.d random variables with the density function $$f(x|\theta) = (\theta+1)x^\theta, 0≤x≤1$$ Find the asymptotic distribution of the MME and MLE. My Guess : I know from doing a previous part in the question that the: a) MME: $\hat \theta$ =  $\frac{1-2\bar X}{\bar X-1}$ b) MLE: $\hat \theta$ = $-1 -$ $\frac{n}{\sum_{i=1}^n \log (X_i)}$ However, I'm a little confused as to what the question is asking for in finding the asymptotic distribution. Any help is appreciated. Thanks!",,['statistics']
73,Regression for power law,Regression for power law,,"I have some data (running time of an algorithm) and I think it follows a power law $$y_\mathrm{reg} = k x^a$$ I want to determine $k$ and $a$. What I have done so far is to do a linear regression (least squares) through $\log(x), \log(y)$ and determine $k$ and $a$ from its coefficients. My problem is that since the ""absolute"" error is minimized for the ""log-log data"", what is minimized when you look at the original data is the quotient $$\frac{y}{y_\mathrm{reg}}$$ This leads to large absolute error for large values of $y$. Is there any way to make a ""power-law regression"" that minimizes the actual ""absolute"" error? Or at least does a better job at minimizing it? Example: The red curve is fit through the whole dataset. The green curve is fit through the last 21 points only. Okay, since @JJacquelin asked for it I'm posting the data for the plot. The left column are the values of $n$ ($x$-axis), the right column are the values of $t$ ($y$-axis) 1.000000000000000000e+02,1.944999820000248248e-03 1.120000000000000000e+02,1.278203080000253058e-03 1.250000000000000000e+02,2.479853309999952970e-03 1.410000000000000000e+02,2.767649050000500332e-03 1.580000000000000000e+02,3.161272610000196315e-03 1.770000000000000000e+02,3.536506440000266715e-03 1.990000000000000000e+02,3.165302929999711402e-03 2.230000000000000000e+02,3.115432719999944224e-03 2.510000000000000000e+02,4.102446610000356694e-03 2.810000000000000000e+02,6.248937529999807478e-03 3.160000000000000000e+02,4.109296799998674206e-03 3.540000000000000000e+02,8.410178100001530418e-03 3.980000000000000000e+02,9.524117600000181830e-03 4.460000000000000000e+02,8.694799099998817837e-03 5.010000000000000000e+02,1.267794469999898935e-02 5.620000000000000000e+02,1.376997950000031709e-02 6.300000000000000000e+02,1.553864030000227069e-02 7.070000000000000000e+02,1.608576049999897034e-02 7.940000000000000000e+02,2.055535920000011244e-02 8.910000000000000000e+02,2.381920090000448978e-02 1.000000000000000000e+03,2.922614199999884477e-02 1.122000000000000000e+03,1.785056299999610019e-02 1.258000000000000000e+03,3.823622889999569313e-02 1.412000000000000000e+03,3.297452850000013452e-02 1.584000000000000000e+03,4.841355780000071440e-02 1.778000000000000000e+03,4.927822640000271981e-02 1.995000000000000000e+03,6.248602919999939054e-02 2.238000000000000000e+03,7.927740400003813193e-02 2.511000000000000000e+03,9.425949999996419137e-02 2.818000000000000000e+03,1.212073290000148518e-01 3.162000000000000000e+03,1.363937510000141629e-01 3.548000000000000000e+03,1.598689289999697394e-01 3.981000000000000000e+03,2.055201890000262210e-01 4.466000000000000000e+03,2.308686839999722906e-01 5.011000000000000000e+03,2.683506760000113900e-01 5.623000000000000000e+03,3.307920660000149837e-01 6.309000000000000000e+03,3.641307770000139499e-01 7.079000000000000000e+03,5.151283440000042901e-01 7.943000000000000000e+03,5.910637860000065302e-01 8.912000000000000000e+03,5.568920769999863296e-01 1.000000000000000000e+04,6.339683309999486482e-01 1.258900000000000000e+04,1.250584726999989016e+00 1.584800000000000000e+04,1.820368430999963039e+00 1.995200000000000000e+04,2.750779816999994409e+00 2.511800000000000000e+04,4.136365994000016144e+00 3.162200000000000000e+04,5.498797844000023360e+00 3.981000000000000000e+04,7.895301083999981984e+00 5.011800000000000000e+04,9.843239714999981516e+00 6.309500000000000000e+04,1.641506008199996813e+01 7.943200000000000000e+04,2.786652209900000798e+01 1.000000000000000000e+05,3.607965075100003105e+01 1.258920000000000000e+05,5.501840400599996883e+01 1.584890000000000000e+05,8.544515980200003469e+01 1.995260000000000000e+05,1.273598972439999670e+02 2.511880000000000000e+05,1.870695913819999987e+02 3.162270000000000000e+05,3.076423412130000088e+02 3.981070000000000000e+05,4.243025571930002116e+02 5.011870000000000000e+05,6.972544795499998145e+02 6.309570000000000000e+05,1.137165088436000133e+03 7.943280000000000000e+05,1.615926472178005497e+03 1.000000000000000000e+06,2.734825116088002687e+03 1.584893000000000000e+06,6.900561992643000849e+03 (sorry for the messy scientific notation)","I have some data (running time of an algorithm) and I think it follows a power law $$y_\mathrm{reg} = k x^a$$ I want to determine $k$ and $a$. What I have done so far is to do a linear regression (least squares) through $\log(x), \log(y)$ and determine $k$ and $a$ from its coefficients. My problem is that since the ""absolute"" error is minimized for the ""log-log data"", what is minimized when you look at the original data is the quotient $$\frac{y}{y_\mathrm{reg}}$$ This leads to large absolute error for large values of $y$. Is there any way to make a ""power-law regression"" that minimizes the actual ""absolute"" error? Or at least does a better job at minimizing it? Example: The red curve is fit through the whole dataset. The green curve is fit through the last 21 points only. Okay, since @JJacquelin asked for it I'm posting the data for the plot. The left column are the values of $n$ ($x$-axis), the right column are the values of $t$ ($y$-axis) 1.000000000000000000e+02,1.944999820000248248e-03 1.120000000000000000e+02,1.278203080000253058e-03 1.250000000000000000e+02,2.479853309999952970e-03 1.410000000000000000e+02,2.767649050000500332e-03 1.580000000000000000e+02,3.161272610000196315e-03 1.770000000000000000e+02,3.536506440000266715e-03 1.990000000000000000e+02,3.165302929999711402e-03 2.230000000000000000e+02,3.115432719999944224e-03 2.510000000000000000e+02,4.102446610000356694e-03 2.810000000000000000e+02,6.248937529999807478e-03 3.160000000000000000e+02,4.109296799998674206e-03 3.540000000000000000e+02,8.410178100001530418e-03 3.980000000000000000e+02,9.524117600000181830e-03 4.460000000000000000e+02,8.694799099998817837e-03 5.010000000000000000e+02,1.267794469999898935e-02 5.620000000000000000e+02,1.376997950000031709e-02 6.300000000000000000e+02,1.553864030000227069e-02 7.070000000000000000e+02,1.608576049999897034e-02 7.940000000000000000e+02,2.055535920000011244e-02 8.910000000000000000e+02,2.381920090000448978e-02 1.000000000000000000e+03,2.922614199999884477e-02 1.122000000000000000e+03,1.785056299999610019e-02 1.258000000000000000e+03,3.823622889999569313e-02 1.412000000000000000e+03,3.297452850000013452e-02 1.584000000000000000e+03,4.841355780000071440e-02 1.778000000000000000e+03,4.927822640000271981e-02 1.995000000000000000e+03,6.248602919999939054e-02 2.238000000000000000e+03,7.927740400003813193e-02 2.511000000000000000e+03,9.425949999996419137e-02 2.818000000000000000e+03,1.212073290000148518e-01 3.162000000000000000e+03,1.363937510000141629e-01 3.548000000000000000e+03,1.598689289999697394e-01 3.981000000000000000e+03,2.055201890000262210e-01 4.466000000000000000e+03,2.308686839999722906e-01 5.011000000000000000e+03,2.683506760000113900e-01 5.623000000000000000e+03,3.307920660000149837e-01 6.309000000000000000e+03,3.641307770000139499e-01 7.079000000000000000e+03,5.151283440000042901e-01 7.943000000000000000e+03,5.910637860000065302e-01 8.912000000000000000e+03,5.568920769999863296e-01 1.000000000000000000e+04,6.339683309999486482e-01 1.258900000000000000e+04,1.250584726999989016e+00 1.584800000000000000e+04,1.820368430999963039e+00 1.995200000000000000e+04,2.750779816999994409e+00 2.511800000000000000e+04,4.136365994000016144e+00 3.162200000000000000e+04,5.498797844000023360e+00 3.981000000000000000e+04,7.895301083999981984e+00 5.011800000000000000e+04,9.843239714999981516e+00 6.309500000000000000e+04,1.641506008199996813e+01 7.943200000000000000e+04,2.786652209900000798e+01 1.000000000000000000e+05,3.607965075100003105e+01 1.258920000000000000e+05,5.501840400599996883e+01 1.584890000000000000e+05,8.544515980200003469e+01 1.995260000000000000e+05,1.273598972439999670e+02 2.511880000000000000e+05,1.870695913819999987e+02 3.162270000000000000e+05,3.076423412130000088e+02 3.981070000000000000e+05,4.243025571930002116e+02 5.011870000000000000e+05,6.972544795499998145e+02 6.309570000000000000e+05,1.137165088436000133e+03 7.943280000000000000e+05,1.615926472178005497e+03 1.000000000000000000e+06,2.734825116088002687e+03 1.584893000000000000e+06,6.900561992643000849e+03 (sorry for the messy scientific notation)",,"['statistics', 'algorithms', 'logarithms', 'regression', 'least-squares']"
74,Additive property of Kullback-Liebler divergence.,Additive property of Kullback-Liebler divergence.,,"I was looking in KL divergence lemma, but could not figure out how they derive the additive property of KL divergence. For reference KL divergence which is a measure of difference between two probability distributions $P$ and $Q$ is defined as $D_{KL}(P||Q)=\sum_i \log{\frac{P(i)}{Q(i)}}P(i)$, where $i$ is the support of $P$ and $Q$.Now as mentioned in wikipedia . The Kullback–Leibler divergence is additive for independent distributions in much the same way as Shannon entropy. If ${P_{1},P_{2}} $ are independent distributions, with the joint distribution  $P(x,y)=P_{1}(x)P_{2}(y)$ , and $Q,Q_{1},Q_{2}$ likewise, then $D_{KL}(P||Q)=D_{KL}(P_1||Q_1)+D_{KL}(P_2||Q_2)$ If I split up the $log$ in the definition I get the following $D_{KL}(P||Q)=D_{KL}(P_1||Q_1)\sum P_2 +D_{KL}(P_2||Q_2)\sum P_1$","I was looking in KL divergence lemma, but could not figure out how they derive the additive property of KL divergence. For reference KL divergence which is a measure of difference between two probability distributions $P$ and $Q$ is defined as $D_{KL}(P||Q)=\sum_i \log{\frac{P(i)}{Q(i)}}P(i)$, where $i$ is the support of $P$ and $Q$.Now as mentioned in wikipedia . The Kullback–Leibler divergence is additive for independent distributions in much the same way as Shannon entropy. If ${P_{1},P_{2}} $ are independent distributions, with the joint distribution  $P(x,y)=P_{1}(x)P_{2}(y)$ , and $Q,Q_{1},Q_{2}$ likewise, then $D_{KL}(P||Q)=D_{KL}(P_1||Q_1)+D_{KL}(P_2||Q_2)$ If I split up the $log$ in the definition I get the following $D_{KL}(P||Q)=D_{KL}(P_1||Q_1)\sum P_2 +D_{KL}(P_2||Q_2)\sum P_1$",,"['statistics', 'divergence-operator']"
75,"$X_1,X_2$ iid standard normal with polar coordinates r and p. Are r and p independent?",iid standard normal with polar coordinates r and p. Are r and p independent?,"X_1,X_2","I have two scalar random variables $X_1$ and $X_2$ and they are both independent and both have standard normal distribution $N(0,1)$. I am letting $r$ and $p$ be the polar coordinates of the point $(X_1,X_2)$, so this means that $X_1=rcos(p)$ and $X_2=rsin(p)$. I am trying to decide if the random variables $r$ and $p$ are independent. I think that they are not but I could be wrong, anyone see why they are or are not?","I have two scalar random variables $X_1$ and $X_2$ and they are both independent and both have standard normal distribution $N(0,1)$. I am letting $r$ and $p$ be the polar coordinates of the point $(X_1,X_2)$, so this means that $X_1=rcos(p)$ and $X_2=rsin(p)$. I am trying to decide if the random variables $r$ and $p$ are independent. I think that they are not but I could be wrong, anyone see why they are or are not?",,"['statistics', 'random-variables', 'normal-distribution', 'polar-coordinates']"
76,Sufficient statistic for Uniform distribution.,Sufficient statistic for Uniform distribution.,,"We are given that $ X_i \sim U( 0 , \theta )$ where $\theta$ is unknown. We need to find a sufficient statistic. First we write the conditional distribution : $$ f( x_1 ,\ldots ,x_n \mid \theta ) = \frac 1 {(\theta)^n}, \text{ where } ( x_i \leq \theta , i=1,2,\ldots,n).$$ So , we write the conditional distribution as follows : $$ f( x_1 ,\ldots ,x_n \mid \theta ) = {(\theta)^{-n}} \quad ( x_i \leq \theta , i=1,2,\ldots,n) \tag 1$$ where $(1)$ is taken as an indicator function which gives the value zero if $ x_i \notin [0,\theta]$ So if $x_i \in [0,\theta]$ then $ \max(x_i) \in U(0,\theta)$, so, $$ f( x_1 ,\ldots ,x_n \mid \theta ) = {(\theta)^{-n}} \quad ( \max(x_i) \leq \theta)\tag 1$$ And hence the sufficient statistic $\max(x_i)%$ is taken. Now my question is, in a very similar manner $\min(x_i)$ could also be taken, would that be wrong?","We are given that $ X_i \sim U( 0 , \theta )$ where $\theta$ is unknown. We need to find a sufficient statistic. First we write the conditional distribution : $$ f( x_1 ,\ldots ,x_n \mid \theta ) = \frac 1 {(\theta)^n}, \text{ where } ( x_i \leq \theta , i=1,2,\ldots,n).$$ So , we write the conditional distribution as follows : $$ f( x_1 ,\ldots ,x_n \mid \theta ) = {(\theta)^{-n}} \quad ( x_i \leq \theta , i=1,2,\ldots,n) \tag 1$$ where $(1)$ is taken as an indicator function which gives the value zero if $ x_i \notin [0,\theta]$ So if $x_i \in [0,\theta]$ then $ \max(x_i) \in U(0,\theta)$, so, $$ f( x_1 ,\ldots ,x_n \mid \theta ) = {(\theta)^{-n}} \quad ( \max(x_i) \leq \theta)\tag 1$$ And hence the sufficient statistic $\max(x_i)%$ is taken. Now my question is, in a very similar manner $\min(x_i)$ could also be taken, would that be wrong?",,['statistics']
77,Interpretation of confidence interval,Interpretation of confidence interval,,Say I have a 95% confidence interval of the sample mean. Does that mean there is a 95% probability that the population mean lies within that interval?,Say I have a 95% confidence interval of the sample mean. Does that mean there is a 95% probability that the population mean lies within that interval?,,"['statistics', 'confidence-interval']"
78,Average weighted by inverse distance to median equal to median?,Average weighted by inverse distance to median equal to median?,,"Problem Statement I have a set of $N$ ordered elements such that $x = \{x_1, x_2, ..., x_q, x_p, ..., x_N\}$ where $x_q \le x_m \le x_p$ and $x_m$ is the median of the set $x$. I define a particular inverse weighted mean as $$\langle x\rangle_I \equiv \frac{\sum_{i=0}^N \frac{x_i}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}}$$ Essentially this is just a weighted mean where the weight is the inverse distance each point is from the median. Prove that $\langle x \rangle_I = x_m$ Attempted Solution I ran across this problem because I found someone who had done such a weighted average and realized they were only getting back the median of their set. I then quickly showed with a few scripts that every example I could generate showed the above statement to be true. So I endeavored to rigorously prove it. Case N is odd My first approach was to consider the case when $N$ was odd. This case, I think is trivial since one of the terms, say $x_j$, is actually the median, in which case you get that this average becomes $$\langle x\rangle_I = \frac{\lim_{x_j\to x_m} \frac{x_j}{x_j-x_m} + \epsilon}{\lim_{x_j\to x_m} \frac{1}{x_j-x_m} + \epsilon}$$ where $\epsilon$ is the sum of all the remaining (insignificant) terms and thus they can be ignored. Then you have $$\langle x\rangle_I = \frac{\lim_{x_j\to x_m} \frac{x_j}{x_j-x_m}}{\lim_{x_j\to x_m} \frac{1}{x_j-x_m}} = \lim_{x_j\to x_m}\frac{\frac{x_j}{x_j-x_m}}{\frac{1}{x_j-x_m}} = \lim_{x_j\to x_m} x_j = x_m$$ General case Here is where I run into some difficulties. I don't think I can rely on the same tricks as I did when $N$ was exclusively odd. I can do the following chain though. $$\langle x\rangle_I = \frac{\sum_{i=0}^N \frac{x_i}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}} = x_m \frac{\sum_{i=0}^N \frac{x_i/x_m}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}}$$ If the statement $\langle x\rangle_I = x_m$ is true, then from the last step the fraction must be unity and then following must be true. $$\sum_{i=0}^N \frac{x_i/x_m}{|x_i-x_m|} = \sum_{i=0}^N \frac{1}{|x_i-x_m|}$$ It is at this point where I'm not sure where to go. I've written out this for a few specific cases ($N = 2, 3, ...$ etc.) and it was true for those cases. What's more generating random data sets and running a few quick scripts shows that these two terms are equal. I just want the rigorous proof now. I did think to remove the denominators by getting a common denominator in every term. I can do that by the following. $$\sum_{i=0}^N \Big(\frac{x_i/x_m}{|x_i-x_m|} \prod_{j\ne i}\frac{|x_j-x_m|}{|x_j-x_m|}\Big) = \sum_{i=0}^N \Big(\frac{1}{|x_i-x_m|} \prod_{j\ne i}\frac{|x_j-x_m|}{|x_j-x_m|}\Big)$$ $$\sum_{i=0}^N \frac{x_i/x_m \prod_{j\ne i}|x_j-x_m|}{\prod_{j=0}^N|x_j-x_m|} = \sum_{i=0}^N \frac{\prod_{j\ne i}|x_j-x_m|}{\prod_{j=0}^N|x_j-x_m|}$$ Now I cancel the denominators and I'm left with $$\sum_{i=0}^N \frac{x_i}{x_m} \prod_{j\ne i}|x_j-x_m| = \sum_{i=0}^N \prod_{j\ne i}|x_j-x_m|$$ I don't know if this statement is easier to prove that the one above. In any case, I've reached a point where I'm not sure on the best course of action. Can anyone point me towards a proof? Point to note I'm fairly certain the problem statement is only true if $x_m$ is the median of the set. If it is any other number, it is easy to show the statement is not true because you can readily find a counter-example. That implies to me that one must use the fact that $x_m$ is the median in the proof.","Problem Statement I have a set of $N$ ordered elements such that $x = \{x_1, x_2, ..., x_q, x_p, ..., x_N\}$ where $x_q \le x_m \le x_p$ and $x_m$ is the median of the set $x$. I define a particular inverse weighted mean as $$\langle x\rangle_I \equiv \frac{\sum_{i=0}^N \frac{x_i}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}}$$ Essentially this is just a weighted mean where the weight is the inverse distance each point is from the median. Prove that $\langle x \rangle_I = x_m$ Attempted Solution I ran across this problem because I found someone who had done such a weighted average and realized they were only getting back the median of their set. I then quickly showed with a few scripts that every example I could generate showed the above statement to be true. So I endeavored to rigorously prove it. Case N is odd My first approach was to consider the case when $N$ was odd. This case, I think is trivial since one of the terms, say $x_j$, is actually the median, in which case you get that this average becomes $$\langle x\rangle_I = \frac{\lim_{x_j\to x_m} \frac{x_j}{x_j-x_m} + \epsilon}{\lim_{x_j\to x_m} \frac{1}{x_j-x_m} + \epsilon}$$ where $\epsilon$ is the sum of all the remaining (insignificant) terms and thus they can be ignored. Then you have $$\langle x\rangle_I = \frac{\lim_{x_j\to x_m} \frac{x_j}{x_j-x_m}}{\lim_{x_j\to x_m} \frac{1}{x_j-x_m}} = \lim_{x_j\to x_m}\frac{\frac{x_j}{x_j-x_m}}{\frac{1}{x_j-x_m}} = \lim_{x_j\to x_m} x_j = x_m$$ General case Here is where I run into some difficulties. I don't think I can rely on the same tricks as I did when $N$ was exclusively odd. I can do the following chain though. $$\langle x\rangle_I = \frac{\sum_{i=0}^N \frac{x_i}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}} = x_m \frac{\sum_{i=0}^N \frac{x_i/x_m}{|x_i-x_m|}}{\sum_{i=0}^N \frac{1}{|x_i-x_m|}}$$ If the statement $\langle x\rangle_I = x_m$ is true, then from the last step the fraction must be unity and then following must be true. $$\sum_{i=0}^N \frac{x_i/x_m}{|x_i-x_m|} = \sum_{i=0}^N \frac{1}{|x_i-x_m|}$$ It is at this point where I'm not sure where to go. I've written out this for a few specific cases ($N = 2, 3, ...$ etc.) and it was true for those cases. What's more generating random data sets and running a few quick scripts shows that these two terms are equal. I just want the rigorous proof now. I did think to remove the denominators by getting a common denominator in every term. I can do that by the following. $$\sum_{i=0}^N \Big(\frac{x_i/x_m}{|x_i-x_m|} \prod_{j\ne i}\frac{|x_j-x_m|}{|x_j-x_m|}\Big) = \sum_{i=0}^N \Big(\frac{1}{|x_i-x_m|} \prod_{j\ne i}\frac{|x_j-x_m|}{|x_j-x_m|}\Big)$$ $$\sum_{i=0}^N \frac{x_i/x_m \prod_{j\ne i}|x_j-x_m|}{\prod_{j=0}^N|x_j-x_m|} = \sum_{i=0}^N \frac{\prod_{j\ne i}|x_j-x_m|}{\prod_{j=0}^N|x_j-x_m|}$$ Now I cancel the denominators and I'm left with $$\sum_{i=0}^N \frac{x_i}{x_m} \prod_{j\ne i}|x_j-x_m| = \sum_{i=0}^N \prod_{j\ne i}|x_j-x_m|$$ I don't know if this statement is easier to prove that the one above. In any case, I've reached a point where I'm not sure on the best course of action. Can anyone point me towards a proof? Point to note I'm fairly certain the problem statement is only true if $x_m$ is the median of the set. If it is any other number, it is easy to show the statement is not true because you can readily find a counter-example. That implies to me that one must use the fact that $x_m$ is the median in the proof.",,"['statistics', 'summation', 'products', 'median']"
79,Are there simple unsolved problems in statistics?,Are there simple unsolved problems in statistics?,,"In number theory, calculus and various fields of mathematics, there are many unsolved problems. But are there simple unsolved problems in statistics?","In number theory, calculus and various fields of mathematics, there are many unsolved problems. But are there simple unsolved problems in statistics?",,"['statistics', 'open-problem']"
80,Jacobian Transformation p.d.f,Jacobian Transformation p.d.f,,"Suppose $X$ and $Y$ are continuous random variables with joint p.d.f. $$f(x,y) = e^{-y},\,\, 0<x<y <\infty$$ (a) Find the joint p.d.f. of $U=X+Y$ and $V=X$ . Be sure to specify the support of $(U,V)$ . (b)  Find the marginal p.d.f. of $U$ and the marginal p.d.f. of $V$ . Be sure to specify their support. I can't figure out what I am doing wrong with this question. So far, I have gotten that the support for $U$ and $V$ is $0<v<u<\infty$ , the Jacobean matrix has determinant $-1$ and that the joint p.d.f for part a) is $e^{v-u}$ but this p.d.f doesn't make sense when I try to find the marginals. Could someone help guide me in the right direction?","Suppose and are continuous random variables with joint p.d.f. (a) Find the joint p.d.f. of and . Be sure to specify the support of . (b)  Find the marginal p.d.f. of and the marginal p.d.f. of . Be sure to specify their support. I can't figure out what I am doing wrong with this question. So far, I have gotten that the support for and is , the Jacobean matrix has determinant and that the joint p.d.f for part a) is but this p.d.f doesn't make sense when I try to find the marginals. Could someone help guide me in the right direction?","X Y f(x,y) = e^{-y},\,\, 0<x<y <\infty U=X+Y V=X (U,V) U V U V 0<v<u<\infty -1 e^{v-u}","['statistics', 'probability-distributions', 'bivariate-distributions']"
81,Permutation question of arranging people in a row,Permutation question of arranging people in a row,,"There are $6$ boys and $4$ girls in a class. How many ways are there to arrange them in a row if no girl stands next to each other? I would know how to solve this if there are only $2$ girls. But since there are $4$ here, I'm stumped as how to proceed. The approach that I have tried is wrong, though I fail to see why. The answer I got from this approach is bigger than than $10!$ What I have tried is putting the girls in certain columns alternating with the boys, and I group a couple of girl and boy as $1$. When I did that, that left me with $6!$ I used $4! \cdot 6! \cdot 2 \cdot 6!$ And my answer is way off. So, can someone help me point out the fault in my reasoning and help point me in the correct approach to tackle this question? Thanks very much.","There are $6$ boys and $4$ girls in a class. How many ways are there to arrange them in a row if no girl stands next to each other? I would know how to solve this if there are only $2$ girls. But since there are $4$ here, I'm stumped as how to proceed. The approach that I have tried is wrong, though I fail to see why. The answer I got from this approach is bigger than than $10!$ What I have tried is putting the girls in certain columns alternating with the boys, and I group a couple of girl and boy as $1$. When I did that, that left me with $6!$ I used $4! \cdot 6! \cdot 2 \cdot 6!$ And my answer is way off. So, can someone help me point out the fault in my reasoning and help point me in the correct approach to tackle this question? Thanks very much.",,"['statistics', 'permutations']"
82,Does an exponential model fit my data?,Does an exponential model fit my data?,,"I am measuring accumulation of a fluorescent-tagged protein at a particular location within a cell over time. In previous experiments that I have performed, I see a standard exponential distribution where the fluorescence intensity reaches a plateau, however in my current experiment, I see a distribution as shown below: What is the best model to use for this data? Should I use two separate exponential models, one for the increase in intensity up to the peak and one for the decay phase, or is there another statistical model for this type of distribution. Thanks!","I am measuring accumulation of a fluorescent-tagged protein at a particular location within a cell over time. In previous experiments that I have performed, I see a standard exponential distribution where the fluorescence intensity reaches a plateau, however in my current experiment, I see a distribution as shown below: What is the best model to use for this data? Should I use two separate exponential models, one for the increase in intensity up to the peak and one for the decay phase, or is there another statistical model for this type of distribution. Thanks!",,['statistics']
83,How do I detect anomalies in a real-time data,How do I detect anomalies in a real-time data,,"I'm trying to find a few good algorithms which could solve the problem of finding anomalies in my data. One of the main problems is that I need to find it in the real time data. So I came out with the idea of calculating average as my new data comes in and also calculating standard deviation. After I do that I add standard deviation to my average to get the upper limit . And also take away standard deviation from the average to get bottom limit . And then finally check if that value is outside the range. That's a quick sketch: /\                  /\/\             /  \                /    \           ** IF VALUE IS ABOVE THEN ALERT  ----/\----/----\/\----/\------/------\/\----- > upper limit  ---/--\--/--------\--/--\----/----------\--/- > average  --/----\/----------\/----\--/------------\/-- > bottom limit   /                        \/                    ** IF VALUE IS BELOW THEN ALERT I used the approach from here . The problems I am facing are: so if I have a big spikes, let's say, every weekend I wouldn't like to get them as  anomalies, because they happen every weekend. But if I get something odd, even if it's not as big as the weekend's spikes, I'd like to get anomaly also I'd like to have some other algorithm which will look on the volume on Monday this week and volume on Monday on the previous week and compare those values going a bit more into details with the above I'm also trying to figure out how big the time block supposed to be: let's say that I check for volume daily, I could get volume of 46 the first day and 50 the next day which won't be odd. but if I would look at the second hour in the first day the count will be 3 and second hour in the second day 25 this is an anomaly I would like to know about how do I determine the appropriate frequency of measurement of events based on volume and variance of data? These are the problems I would like to solve, I am not asking for the exact answer, but for pointing the algorithms which will be the best to solve each of these issues","I'm trying to find a few good algorithms which could solve the problem of finding anomalies in my data. One of the main problems is that I need to find it in the real time data. So I came out with the idea of calculating average as my new data comes in and also calculating standard deviation. After I do that I add standard deviation to my average to get the upper limit . And also take away standard deviation from the average to get bottom limit . And then finally check if that value is outside the range. That's a quick sketch: /\                  /\/\             /  \                /    \           ** IF VALUE IS ABOVE THEN ALERT  ----/\----/----\/\----/\------/------\/\----- > upper limit  ---/--\--/--------\--/--\----/----------\--/- > average  --/----\/----------\/----\--/------------\/-- > bottom limit   /                        \/                    ** IF VALUE IS BELOW THEN ALERT I used the approach from here . The problems I am facing are: so if I have a big spikes, let's say, every weekend I wouldn't like to get them as  anomalies, because they happen every weekend. But if I get something odd, even if it's not as big as the weekend's spikes, I'd like to get anomaly also I'd like to have some other algorithm which will look on the volume on Monday this week and volume on Monday on the previous week and compare those values going a bit more into details with the above I'm also trying to figure out how big the time block supposed to be: let's say that I check for volume daily, I could get volume of 46 the first day and 50 the next day which won't be odd. but if I would look at the second hour in the first day the count will be 3 and second hour in the second day 25 this is an anomaly I would like to know about how do I determine the appropriate frequency of measurement of events based on volume and variance of data? These are the problems I would like to solve, I am not asking for the exact answer, but for pointing the algorithms which will be the best to solve each of these issues",,"['statistics', 'algorithms']"
84,The definition of the sample standard deviation,The definition of the sample standard deviation,,"I am reviewing the statistic.  I read the book ""Probability and Statistical Inference"" which is written by Robert V. Hogg and Ellit A. Tanis. There is a statement in the book says that: (Section: The Mean, Variance, and Standard Deviation) The sample standard deviation,  $$ s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2}\geq 0,$$  is a measure of how dispersed the data are from the sample mean. At this stage of your study of statistics,  it is difficult to get a good understanding or meaning of the standard deviation $s$, but you can roughly think of it as the average distance of the values $x_1, x_2, \ldots, x_n$ from the mean $\bar{x}$. This is not true exactly,  for, in general,  $$ s > \frac{1}{n} \sum_{i=1}^{n} |x_i-\bar{x}|, $$ but it is fair to say that $s$ is somewhat larger,  yet of the same magnitude,  as the average of the distances of $x_1, x_2, ..., x_n$ from $\bar{x}$. Question 1: What book could provide a ""good understanding or meaning"" of the standard deviation for me. Question 2: Why don't we define the sample standard deviation as the  average distance of the values $x_1, x_2, \ldots, x_n$ from the mean $\bar{x}$,  that is,  $$ s:=\frac{1}{n} \sum_{i=1}^{n} |x_i-\bar{x}|. $$","I am reviewing the statistic.  I read the book ""Probability and Statistical Inference"" which is written by Robert V. Hogg and Ellit A. Tanis. There is a statement in the book says that: (Section: The Mean, Variance, and Standard Deviation) The sample standard deviation,  $$ s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2}\geq 0,$$  is a measure of how dispersed the data are from the sample mean. At this stage of your study of statistics,  it is difficult to get a good understanding or meaning of the standard deviation $s$, but you can roughly think of it as the average distance of the values $x_1, x_2, \ldots, x_n$ from the mean $\bar{x}$. This is not true exactly,  for, in general,  $$ s > \frac{1}{n} \sum_{i=1}^{n} |x_i-\bar{x}|, $$ but it is fair to say that $s$ is somewhat larger,  yet of the same magnitude,  as the average of the distances of $x_1, x_2, ..., x_n$ from $\bar{x}$. Question 1: What book could provide a ""good understanding or meaning"" of the standard deviation for me. Question 2: Why don't we define the sample standard deviation as the  average distance of the values $x_1, x_2, \ldots, x_n$ from the mean $\bar{x}$,  that is,  $$ s:=\frac{1}{n} \sum_{i=1}^{n} |x_i-\bar{x}|. $$",,['statistics']
85,Joint Probability from Marginal Probabilities,Joint Probability from Marginal Probabilities,,"$X, Y_1, Y_2$ are random variables with (possibly) different finite alphabets. For given conditional probability mass functions $\mathbb{P}(Y_1|X)$ and $\mathbb{P}(Y_2|X)$, is it always possible to find  joint conditional probabilities $\mathbb{P}(Y_1, Y_2|X)$ such that $X\rightarrow Y_1\rightarrow Y_2$ is a Markov chain? Outline the procedure please. The set of joint probabilities need not be unique, but is at least one set guaranteed to exist? P. S. The problem is basically taken from the context of broadcast channel capacity where I am trying to prove that any two user scalar broadcast channel can be converted to an equivalent degraded channel. I tried my best to present it in a way so that someone not familiar with information theory can appreciate the problem. Let me know if I left anything unclear.","$X, Y_1, Y_2$ are random variables with (possibly) different finite alphabets. For given conditional probability mass functions $\mathbb{P}(Y_1|X)$ and $\mathbb{P}(Y_2|X)$, is it always possible to find  joint conditional probabilities $\mathbb{P}(Y_1, Y_2|X)$ such that $X\rightarrow Y_1\rightarrow Y_2$ is a Markov chain? Outline the procedure please. The set of joint probabilities need not be unique, but is at least one set guaranteed to exist? P. S. The problem is basically taken from the context of broadcast channel capacity where I am trying to prove that any two user scalar broadcast channel can be converted to an equivalent degraded channel. I tried my best to present it in a way so that someone not familiar with information theory can appreciate the problem. Let me know if I left anything unclear.",,"['statistics', 'probability-distributions', 'markov-chains', 'information-theory']"
86,Distribution of likelihood ratio in a test on the unknown variance of a normal sample,Distribution of likelihood ratio in a test on the unknown variance of a normal sample,,"EDIT: I have followed up to this discussion with a second question: https://math.stackexchange.com/questions/635567/hypothesis-test-on-variance-of-normal-sample I am preparing for a stat exam and I was trying to derive the distribution of the likelihood ratio statistic for the hypothesis test below. Let $X_1 ... X_{n}$ be a random sample from a $N(\mu,\sigma^2)$ distribution, where $\mu$ is known and $\sigma^2$ is unknown . I want to test the hypothesis $H_0 : \sigma^2 = \sigma_{0}^{2} $ vs. $H_1 : \sigma^2 \neq \sigma_{0}^{2}$ (and, trivially, $\sigma^2 >0$). The generic joint pdf for the n independent random variables (ie. the likelihood function for the random sample) is: $L=\prod_{i=1}^{n} \large(\frac{1}{\sqrt{2\pi\sigma^2}})\cdot e^-\frac{(X_i - \mu)^2}{2\sigma^2}= \large(\frac{1}{\sqrt{2\pi\sigma^2}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma^2}$ Under the null hypothesis, the maximum value taken by $L$ is: $\large(\frac{1}{\sqrt{2\pi\sigma_{0}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}$ If we do not constrain $\sigma^{2}$ to be equal to $\sigma_{0}^{2}$, then $L$ is maximised by deriving the maximum likelihood estimator for $\sigma^{2}$, ie $\hat{\sigma}^{2}=\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{n}$ In this case, the maximum likelihood becomes: $\large(\frac{1}{\sqrt{2\pi\hat{\sigma_{0}}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\hat{\sigma_{0}}^{2}}$ Setting these as numerator and denominator, respectively, I get the following likelihood ratio statistic $\Lambda = \LARGE\frac{\large(\frac{1}{\sqrt{2\pi\sigma_{0}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}{\large(\frac{1}{\sqrt{2\pi\hat{\sigma_{0}}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\hat{\sigma_{0}}^{2}}} \\ = \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\hat{\sigma_{0}^{2}}}}  \\ = \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^{\sum_{i=1}^{n} (X_i - \mu)^2\cdot0.5\cdot\frac{n}{\sum_{i=1}^{n} (X_i - \mu)^2}}} \\ = \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^{0.5}}$ Since the test corresponds to $\Lambda \leq k$ for some constant k, we can write: $\Lambda= \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^{0.5}} \leq k$ And hence: $\large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}} \leq k'$ When I get here, there are two things I do not understand: I do not think that you can also bring ${e^-\frac{\sum_{i=1}^{n} (X_i  - \mu)^2}{2\sigma_{0}^{2}}}$ to the right side as this is a function of the random sample. Am I missing something? If the previous statement is correct, how do you find the distribution of the left hand side? Any clarification, link or reference would be extremely helpful.","EDIT: I have followed up to this discussion with a second question: https://math.stackexchange.com/questions/635567/hypothesis-test-on-variance-of-normal-sample I am preparing for a stat exam and I was trying to derive the distribution of the likelihood ratio statistic for the hypothesis test below. Let $X_1 ... X_{n}$ be a random sample from a $N(\mu,\sigma^2)$ distribution, where $\mu$ is known and $\sigma^2$ is unknown . I want to test the hypothesis $H_0 : \sigma^2 = \sigma_{0}^{2} $ vs. $H_1 : \sigma^2 \neq \sigma_{0}^{2}$ (and, trivially, $\sigma^2 >0$). The generic joint pdf for the n independent random variables (ie. the likelihood function for the random sample) is: $L=\prod_{i=1}^{n} \large(\frac{1}{\sqrt{2\pi\sigma^2}})\cdot e^-\frac{(X_i - \mu)^2}{2\sigma^2}= \large(\frac{1}{\sqrt{2\pi\sigma^2}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma^2}$ Under the null hypothesis, the maximum value taken by $L$ is: $\large(\frac{1}{\sqrt{2\pi\sigma_{0}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}$ If we do not constrain $\sigma^{2}$ to be equal to $\sigma_{0}^{2}$, then $L$ is maximised by deriving the maximum likelihood estimator for $\sigma^{2}$, ie $\hat{\sigma}^{2}=\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{n}$ In this case, the maximum likelihood becomes: $\large(\frac{1}{\sqrt{2\pi\hat{\sigma_{0}}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\hat{\sigma_{0}}^{2}}$ Setting these as numerator and denominator, respectively, I get the following likelihood ratio statistic $\Lambda = \LARGE\frac{\large(\frac{1}{\sqrt{2\pi\sigma_{0}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}{\large(\frac{1}{\sqrt{2\pi\hat{\sigma_{0}}^{2}}})^{n}\cdot e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\hat{\sigma_{0}}^{2}}} \\ = \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\hat{\sigma_{0}^{2}}}}  \\ = \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^{\sum_{i=1}^{n} (X_i - \mu)^2\cdot0.5\cdot\frac{n}{\sum_{i=1}^{n} (X_i - \mu)^2}}} \\ = \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^{0.5}}$ Since the test corresponds to $\Lambda \leq k$ for some constant k, we can write: $\Lambda= \large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}}\cdot{e^{0.5}} \leq k$ And hence: $\large(\frac{\hat{\sigma_{0}}^{2}}{\sigma_{0}^{2}})^{n/2}\cdot {e^-\frac{\sum_{i=1}^{n} (X_i - \mu)^2}{2\sigma_{0}^{2}}} \leq k'$ When I get here, there are two things I do not understand: I do not think that you can also bring ${e^-\frac{\sum_{i=1}^{n} (X_i  - \mu)^2}{2\sigma_{0}^{2}}}$ to the right side as this is a function of the random sample. Am I missing something? If the previous statement is correct, how do you find the distribution of the left hand side? Any clarification, link or reference would be extremely helpful.",,"['statistics', 'statistical-inference']"
87,Definition of white noise vectors,Definition of white noise vectors,,"As is shown in wikipedia: Click [here] ( http://en.wikipedia.org/wiki/White_noise#Mathematical_definitions ) A random vector (that is, a partially indeterminate process that produces vectors of real numbers) is said to be a white noise vector or white random vector if its components each have a probability distribution with zero mean and finite variance, and are statistically independent. Here comes my question, does the vector is still white noise, if the variances of the components are not the same any more? Thank you very much.","As is shown in wikipedia: Click [here] ( http://en.wikipedia.org/wiki/White_noise#Mathematical_definitions ) A random vector (that is, a partially indeterminate process that produces vectors of real numbers) is said to be a white noise vector or white random vector if its components each have a probability distribution with zero mean and finite variance, and are statistically independent. Here comes my question, does the vector is still white noise, if the variances of the components are not the same any more? Thank you very much.",,"['statistics', 'time-series', 'stationary-processes']"
88,How to check if my dataset is normally distributed?,How to check if my dataset is normally distributed?,,"I have data sets (measurements) and I need to know if values are normally distributed. I would like to get this information programmatically in my application and not via plotting and checking it visually myself. Is there some statistical method how to check it? I have an idea to use mean and median and if median equals mean (or is very close) the distribution can be considered as normally distributed. But I'm not sure what ""close"" is enough.","I have data sets (measurements) and I need to know if values are normally distributed. I would like to get this information programmatically in my application and not via plotting and checking it visually myself. Is there some statistical method how to check it? I have an idea to use mean and median and if median equals mean (or is very close) the distribution can be considered as normally distributed. But I'm not sure what ""close"" is enough.",,"['statistics', 'normal-distribution']"
89,Help with question on joint Gaussian distribution,Help with question on joint Gaussian distribution,,"Does anyone know how to start this question? Let random vectors $x,u,v$ have joint Gaussian distribution, and $u,v$ be independent. Show that   $E(x|u,v)=E(x|u)+E(x|v)-E(x)$.","Does anyone know how to start this question? Let random vectors $x,u,v$ have joint Gaussian distribution, and $u,v$ be independent. Show that   $E(x|u,v)=E(x|u)+E(x|v)-E(x)$.",,['statistics']
90,Specific statistics problem: Ranking universities,Specific statistics problem: Ranking universities,,"What do you think is the best way to rank universities participating in a competition if we know for each university the number of recognitions that it's students won. Each university can participate with 3 students, and approximately half of them get a recognition - which can be first (5%), second (15%) or third place (30%). To be more specific, let's say 5 universities participated in a competition and the first university won 2 first place recognitions and 1 second place recognitions, the second university won 2 third place recognitions, etc... Probably a good way of measuring universities is by the total number of recognitions won, or the number of first place recognitions won, followed by number of second place recognitions won etc. Now, my question is: How do we rank the quality of education in the universities if we know for each university how many students learn there? I'm asking this because it's probably a good idea to take into account the number of students? One possibility that I was thinking of is to divide the number of achievements with the number of students and use that to compare universities, but the problem here is that each school can participate with only 3 students (probably if the largest university participated with more than 3 students it would have won more recognitions). We can assume that the universities have a lot of students, and that the background of the students enrolled at different universities is the same. Thank you very much for your time!","What do you think is the best way to rank universities participating in a competition if we know for each university the number of recognitions that it's students won. Each university can participate with 3 students, and approximately half of them get a recognition - which can be first (5%), second (15%) or third place (30%). To be more specific, let's say 5 universities participated in a competition and the first university won 2 first place recognitions and 1 second place recognitions, the second university won 2 third place recognitions, etc... Probably a good way of measuring universities is by the total number of recognitions won, or the number of first place recognitions won, followed by number of second place recognitions won etc. Now, my question is: How do we rank the quality of education in the universities if we know for each university how many students learn there? I'm asking this because it's probably a good idea to take into account the number of students? One possibility that I was thinking of is to divide the number of achievements with the number of students and use that to compare universities, but the problem here is that each school can participate with only 3 students (probably if the largest university participated with more than 3 students it would have won more recognitions). We can assume that the universities have a lot of students, and that the background of the students enrolled at different universities is the same. Thank you very much for your time!",,['statistics']
91,A Probability Distribution Whose Variance Doesn't Change as You Raise it to Higher and Higher Positive Integer Powers,A Probability Distribution Whose Variance Doesn't Change as You Raise it to Higher and Higher Positive Integer Powers,,"Are there any continuous probability distributions whose random variables have variances that do not change as you raise them to higher and higher integer powers? If there are, what are they? I've done some simulations, and a few things are clear. For a uniform distribution with min = 0 and max = 1 , the variances of the random variables converge to 0 as higher and higher positive integer powers are used (I know that this is expected since raising numbers to positive integer powers that are between 0 and 1 makes them smaller). For a Cauchy distribution with location = 0 and scale = 1 , variances diverge to Inf (I know that this is expected since Cauchy distributions have variances of infinity). It's not clear to me if the variances of a normal distribution with mean = 0 and sd = 1 converge or diverge. It'd be great if I could find a probability distribution (or multiple probability distributions) whose random variables have variances that remain constant as higher and higher integer powers are used. To be clear, I'm not looking for variances that converge - I'm looking for variances that remain constant. I'm looking for a theoretical basis and not just an empirical one. Thanks! My R code is below for reference. # Constants Highest_Integer_Power_to_Investigate <- 10 Number_or_Observations_per_Sample <- 1000 Number_of_Iterations <- 1000  # Data Generation Uniform_Distribution_Values <- lapply(seq_len(Number_of_Iterations), function (x) {   runif(Number_or_Observations_per_Sample) }) Normal_Distribution_Values <- lapply(seq_len(Number_of_Iterations), function (x) {   rnorm(Number_or_Observations_per_Sample) }) Cauchy_Distribution_Values <- lapply(seq_len(Number_of_Iterations), function (x) {   rcauchy(Number_or_Observations_per_Sample) }) Values <- list(Uniform_Distribution = Uniform_Distribution_Values, Normal_Distribution =  Normal_Distribution_Values, Cauchy_Distribution = Cauchy_Distribution_Values)  # Calculations Output <- lapply(Values, function (x) {   sapply(x, function (y) {     sapply(seq_len(Highest_Integer_Power_to_Investigate), function (z) {       var(y ^ z)     })   }) })  # Formatting Variances <- as.data.frame(lapply(Output, rowMeans)) Variances$Power <- seq_len(Highest_Integer_Power_to_Investigate) Variances <- Variances[, c(which(colnames(Variances) == 'Power'), which(colnames(Variances) != 'Power'))]  # Output Variances #    Power Uniform_Distribution Normal_Distribution Cauchy_Distribution # 1      1           0.08336001        1.003362e+00        2.004660e+06 # 2      2           0.08886279        2.013401e+00        1.954473e+18 # 3      3           0.08029366        1.515248e+01        2.209213e+30 # 4      4           0.07103040        9.744815e+01        2.626589e+42 # 5      5           0.06304486        9.661652e+02        3.208136e+54 # 6      6           0.05642795        1.046558e+04        3.973433e+66 # 7      7           0.05095627        1.386277e+05        4.955865e+78 # 8      8           0.04639468        2.018680e+06        6.202649e+90 # 9      9           0.04255073        3.260260e+07       7.776300e+102 # 10    10           0.03927592        5.601374e+08       9.757302e+114","Are there any continuous probability distributions whose random variables have variances that do not change as you raise them to higher and higher integer powers? If there are, what are they? I've done some simulations, and a few things are clear. For a uniform distribution with min = 0 and max = 1 , the variances of the random variables converge to 0 as higher and higher positive integer powers are used (I know that this is expected since raising numbers to positive integer powers that are between 0 and 1 makes them smaller). For a Cauchy distribution with location = 0 and scale = 1 , variances diverge to Inf (I know that this is expected since Cauchy distributions have variances of infinity). It's not clear to me if the variances of a normal distribution with mean = 0 and sd = 1 converge or diverge. It'd be great if I could find a probability distribution (or multiple probability distributions) whose random variables have variances that remain constant as higher and higher integer powers are used. To be clear, I'm not looking for variances that converge - I'm looking for variances that remain constant. I'm looking for a theoretical basis and not just an empirical one. Thanks! My R code is below for reference. # Constants Highest_Integer_Power_to_Investigate <- 10 Number_or_Observations_per_Sample <- 1000 Number_of_Iterations <- 1000  # Data Generation Uniform_Distribution_Values <- lapply(seq_len(Number_of_Iterations), function (x) {   runif(Number_or_Observations_per_Sample) }) Normal_Distribution_Values <- lapply(seq_len(Number_of_Iterations), function (x) {   rnorm(Number_or_Observations_per_Sample) }) Cauchy_Distribution_Values <- lapply(seq_len(Number_of_Iterations), function (x) {   rcauchy(Number_or_Observations_per_Sample) }) Values <- list(Uniform_Distribution = Uniform_Distribution_Values, Normal_Distribution =  Normal_Distribution_Values, Cauchy_Distribution = Cauchy_Distribution_Values)  # Calculations Output <- lapply(Values, function (x) {   sapply(x, function (y) {     sapply(seq_len(Highest_Integer_Power_to_Investigate), function (z) {       var(y ^ z)     })   }) })  # Formatting Variances <- as.data.frame(lapply(Output, rowMeans)) Variances$Power <- seq_len(Highest_Integer_Power_to_Investigate) Variances <- Variances[, c(which(colnames(Variances) == 'Power'), which(colnames(Variances) != 'Power'))]  # Output Variances #    Power Uniform_Distribution Normal_Distribution Cauchy_Distribution # 1      1           0.08336001        1.003362e+00        2.004660e+06 # 2      2           0.08886279        2.013401e+00        1.954473e+18 # 3      3           0.08029366        1.515248e+01        2.209213e+30 # 4      4           0.07103040        9.744815e+01        2.626589e+42 # 5      5           0.06304486        9.661652e+02        3.208136e+54 # 6      6           0.05642795        1.046558e+04        3.973433e+66 # 7      7           0.05095627        1.386277e+05        4.955865e+78 # 8      8           0.04639468        2.018680e+06        6.202649e+90 # 9      9           0.04255073        3.260260e+07       7.776300e+102 # 10    10           0.03927592        5.601374e+08       9.757302e+114",,"['statistics', 'probability-distributions', 'convergence-divergence', 'variance']"
92,What's the significance of Mean Squared Error? Why not something else?,What's the significance of Mean Squared Error? Why not something else?,,"Background: Masters in CS/Math. I'm brushing up on statistics I see Mean Squared Error(MSE) everywhere. As a student I took it for granted, but now when I tried to find the reasons for why it's so prevalent I am told: simplicity, emphasis on outliers and mathematical properties like differentiability. So what? It's not the only function with those properties. So why is it used so widely? Are there situations where it's probably the best function to use? Are there situations where there are other functions that are probably better to use? Say I am designing my own heuristic, and I have an error I want to minimize on. How do I know that squaring the error is the best way forward?","Background: Masters in CS/Math. I'm brushing up on statistics I see Mean Squared Error(MSE) everywhere. As a student I took it for granted, but now when I tried to find the reasons for why it's so prevalent I am told: simplicity, emphasis on outliers and mathematical properties like differentiability. So what? It's not the only function with those properties. So why is it used so widely? Are there situations where it's probably the best function to use? Are there situations where there are other functions that are probably better to use? Say I am designing my own heuristic, and I have an error I want to minimize on. How do I know that squaring the error is the best way forward?",,"['statistics', 'functions', 'machine-learning', 'error-function', 'mean-square-error']"
93,I'm trying to understand the following derivation,I'm trying to understand the following derivation,,"This is taken from Hastie, Tibshirani and Friedman's Elements of Statistical Learning. They describe the squared loss error and to minimize the expectation of this error, which they call Expected (squared) prediction error, $EPE$ . They first define the squared error loss as $L(Y, f(X))=(Y-f(X))^{2}$ . The criterion for choosing $f$ becomes, $$EPE(f)=E(Y-f(X))^{2}$$ $$EPE(f)=\int(y-f(x))^{2}P(dx, dy)$$ The authors then write the following: the condition on $X$ to get, $$EPE(f)=E_{X}E_{Y|X}([Y-f(X)]^{2}|X)$$ I think I might be missing something basic here, but how did the authors arrive at this by conditioning on X? Then they go on to write: it suffices to minimize $EPE$ pointwise as, $$f(x) = argmin_{c}E_{Y|X}([Y-c]^{2}|X=x)$$ How do the authors arrive at this conclusion i.e. that it suffices to minimize EPE pointwise? This is not very intuitive to me. In the end, the authors say: the solution for the equation above is, $$f(x)=E(Y|X=x)$$ How do they arrive at this solution? Could someone describe the intermediate math to achieve this as a solution?","This is taken from Hastie, Tibshirani and Friedman's Elements of Statistical Learning. They describe the squared loss error and to minimize the expectation of this error, which they call Expected (squared) prediction error, . They first define the squared error loss as . The criterion for choosing becomes, The authors then write the following: the condition on to get, I think I might be missing something basic here, but how did the authors arrive at this by conditioning on X? Then they go on to write: it suffices to minimize pointwise as, How do the authors arrive at this conclusion i.e. that it suffices to minimize EPE pointwise? This is not very intuitive to me. In the end, the authors say: the solution for the equation above is, How do they arrive at this solution? Could someone describe the intermediate math to achieve this as a solution?","EPE L(Y, f(X))=(Y-f(X))^{2} f EPE(f)=E(Y-f(X))^{2} EPE(f)=\int(y-f(x))^{2}P(dx, dy) X EPE(f)=E_{X}E_{Y|X}([Y-f(X)]^{2}|X) EPE f(x) = argmin_{c}E_{Y|X}([Y-c]^{2}|X=x) f(x)=E(Y|X=x)",['statistics']
94,Find Maximum-Likelihood-Estimator (MLE) for $\alpha$,Find Maximum-Likelihood-Estimator (MLE) for,\alpha,"Consider the following PDF: $$w_{\alpha,\beta}(x):=\alpha \beta x^{\beta-1}e^{-\alpha x^{\beta}} \mathbf{1}_{(0,\infty)}(x)$$ This is the Weibull distribution often used in material science. Assume we know $\beta$ and we want to estimate $\alpha$ . Let $X_1,\ldots X_n$ be i.i.d weibull-distributed. Find the MLE $\hat{\alpha}$ for the parameter $\alpha$ . Find a $c \in \mathbb R$ such that $c \cdot \alpha $ is an unbiased estimator. Question: The result I am getting for the MLE doesn't look correct but I don't know what I am doing wrong. For Part 2, do I just have to show that $\operatorname{E}(\hat{\alpha}-\alpha)=0$ ? My attempt: Step 1: Write down the ML function: $$L(\alpha)=\prod_{i=1}^n \alpha \beta x_i^{\beta-1}e^{-\alpha x_i^{\beta}}$$ Step 2: Take the natural log: $$ \begin{aligned}\ln(L(\alpha))&=\sum_{i=1}^n \ln\left(\alpha \beta x_i^{\beta-1}e^{-\alpha x_i^{\beta}} \right) \\[5pt] &=\sum_{i=1}^n \ln\left(\alpha\beta x_i^{\beta-1}\right)+\ln \left( e^{-\alpha x_i^{\beta}}\right)  \\[5pt] &=\sum_{i=1}^n\ln\left(\alpha \right)+\ln(\beta)+(\beta-1)\ln\left(x_i \right)-\alpha x_i^{\beta} \end{aligned}$$ Step 3: Differentiate and set equal to zero: $$\begin{aligned}&\frac{\partial }{\partial \alpha}\ln(L(\alpha))=\sum_{i=1}^n \frac{1}{\alpha}-x_i^{\beta}=0  \\[5pt] &\iff \sum_{i=1}^n\frac{1}{\alpha}=\sum_{i=1}^n x_i^{\beta} \\[5pt] & \iff \frac{n}{\alpha}=\sum_{i=1}^nx_i^{\beta} \iff \alpha=\frac{n}{\sum_{i=1}^nx_i^{\beta}}\end{aligned}$$ For part 2 I was thinking of setting $c=\alpha \bar{X}$ , where $\bar{X}$ is the average of the $x_i^{\beta}$ 's. Then it would follow that: $$E\left[\alpha \cdot \frac{1}{n} \cdot \sum_{i=1}^n x_i^{\beta} \cdot \frac{n}{\sum_{i=1}^n x_i^{\beta}}\right]=\alpha \\ \iff \alpha =\alpha $$ But I am not sure if am allowed to set $c$ equal to that.","Consider the following PDF: This is the Weibull distribution often used in material science. Assume we know and we want to estimate . Let be i.i.d weibull-distributed. Find the MLE for the parameter . Find a such that is an unbiased estimator. Question: The result I am getting for the MLE doesn't look correct but I don't know what I am doing wrong. For Part 2, do I just have to show that ? My attempt: Step 1: Write down the ML function: Step 2: Take the natural log: Step 3: Differentiate and set equal to zero: For part 2 I was thinking of setting , where is the average of the 's. Then it would follow that: But I am not sure if am allowed to set equal to that.","w_{\alpha,\beta}(x):=\alpha \beta x^{\beta-1}e^{-\alpha x^{\beta}} \mathbf{1}_{(0,\infty)}(x) \beta \alpha X_1,\ldots X_n \hat{\alpha} \alpha c \in \mathbb R c \cdot \alpha  \operatorname{E}(\hat{\alpha}-\alpha)=0 L(\alpha)=\prod_{i=1}^n \alpha \beta x_i^{\beta-1}e^{-\alpha x_i^{\beta}}  \begin{aligned}\ln(L(\alpha))&=\sum_{i=1}^n \ln\left(\alpha \beta x_i^{\beta-1}e^{-\alpha x_i^{\beta}} \right)
\\[5pt] &=\sum_{i=1}^n \ln\left(\alpha\beta x_i^{\beta-1}\right)+\ln \left( e^{-\alpha x_i^{\beta}}\right) 
\\[5pt] &=\sum_{i=1}^n\ln\left(\alpha \right)+\ln(\beta)+(\beta-1)\ln\left(x_i \right)-\alpha x_i^{\beta} \end{aligned} \begin{aligned}&\frac{\partial }{\partial \alpha}\ln(L(\alpha))=\sum_{i=1}^n \frac{1}{\alpha}-x_i^{\beta}=0 
\\[5pt] &\iff \sum_{i=1}^n\frac{1}{\alpha}=\sum_{i=1}^n x_i^{\beta}
\\[5pt] & \iff \frac{n}{\alpha}=\sum_{i=1}^nx_i^{\beta} \iff \alpha=\frac{n}{\sum_{i=1}^nx_i^{\beta}}\end{aligned} c=\alpha \bar{X} \bar{X} x_i^{\beta} E\left[\alpha \cdot \frac{1}{n} \cdot \sum_{i=1}^n x_i^{\beta} \cdot \frac{n}{\sum_{i=1}^n x_i^{\beta}}\right]=\alpha \\ \iff \alpha =\alpha  c","['statistics', 'maximum-likelihood', 'parameter-estimation']"
95,Logarithmic convexity of incomplete gamma function.,Logarithmic convexity of incomplete gamma function.,,"The incomplete Gamma function $F(t)$ satisfies $$ 1 - F(t) \sim \int^\infty_t dx \, e^{-x} x^{\alpha - 1} $$ for $t > 0$ and its derivative $F^\prime \sim e^{-t} t^{\alpha - 1}$ is the density function of the Gamma distribution . It is claimed that the hazard rate, also known as the failure rate $$h = -\frac{d}{dt} \ln (1 - F) = \frac{F^\prime}{1-F}$$ is increasing everywhere (i.e. $h^\prime (t) > 0$ ) for the case that $\alpha > 1$ and decreasing everywhere for the case that $\alpha < 1$ . In other words, the logarithmic convexity of $1 - F$ depends only on the sign of $\alpha - 1$ . This result is also given as a proof exercise in problem 5.22 of this book . It's unclear to me how to prove this result. We have $$ h^\prime = \frac{(1-F)F^{\prime \prime} + (F^\prime)^2}{(1-F)^2} = \frac{F^\prime}{(1-F)^2} \left[ (1-F)\left(\frac{\alpha - 1}{t} - 1 \right) + F^\prime \right], $$ but from this point the next step is unclear.","The incomplete Gamma function satisfies for and its derivative is the density function of the Gamma distribution . It is claimed that the hazard rate, also known as the failure rate is increasing everywhere (i.e. ) for the case that and decreasing everywhere for the case that . In other words, the logarithmic convexity of depends only on the sign of . This result is also given as a proof exercise in problem 5.22 of this book . It's unclear to me how to prove this result. We have but from this point the next step is unclear.","F(t) 
1 - F(t) \sim \int^\infty_t dx \, e^{-x} x^{\alpha - 1}
 t > 0 F^\prime \sim e^{-t} t^{\alpha - 1} h = -\frac{d}{dt} \ln (1 - F) = \frac{F^\prime}{1-F} h^\prime (t) > 0 \alpha > 1 \alpha < 1 1 - F \alpha - 1  h^\prime = \frac{(1-F)F^{\prime \prime} + (F^\prime)^2}{(1-F)^2} = \frac{F^\prime}{(1-F)^2} \left[ (1-F)\left(\frac{\alpha - 1}{t} - 1 \right) + F^\prime \right], ","['calculus', 'statistics', 'probability-distributions', 'convex-analysis', 'gamma-distribution']"
96,Fisher information in one parameter exponential family.,Fisher information in one parameter exponential family.,,"We define the one-parameter exponential family of distribution functions as those whose pmf/pdf can be written as $$\exp\{c(\theta)T(x) + d(\theta) + s(x)\}$$ I would like to show that if c is twice differentiable with a positive derivative and $E(T(X))= \theta$ then $I(\theta) = \dfrac{1}{\text{var}(T(X))}$ I tried directly computing the fisher information of theta, but I do not see why the equality holds. Any help would be appreciated","We define the one-parameter exponential family of distribution functions as those whose pmf/pdf can be written as I would like to show that if c is twice differentiable with a positive derivative and then I tried directly computing the fisher information of theta, but I do not see why the equality holds. Any help would be appreciated",\exp\{c(\theta)T(x) + d(\theta) + s(x)\} E(T(X))= \theta I(\theta) = \dfrac{1}{\text{var}(T(X))},"['statistics', 'exponential-distribution', 'parameter-estimation', 'fisher-information']"
97,Applications of the Clifford algebra in machine learning and statistics?,Applications of the Clifford algebra in machine learning and statistics?,,"I recently came across this article, "" Geometric algebra and computer graphics "" and started wondering whether there are interesting applications of Clifford/Geometric algebra to statistics and machine learning. Any pointers are appreciated, thanks!","I recently came across this article, "" Geometric algebra and computer graphics "" and started wondering whether there are interesting applications of Clifford/Geometric algebra to statistics and machine learning. Any pointers are appreciated, thanks!",,"['statistics', 'machine-learning', 'clifford-algebras']"
98,How to find out the probability that the tallest person in a group of people is a man?,How to find out the probability that the tallest person in a group of people is a man?,,"Assume we have a population of N men and women such that exactly $N/2$ people are men (set $M$ ) and $N/2$ people are women (set $W$ ). Assume that the standard deviations for height between both groups is the same $\sigma$ however their averages are different with $\mu_M > \mu_W$ . We pick $n$ people at random from the population such that $n/2$ people are men and $n/2$ people are women. Knowing $n$ what's the probability that the tallest person in the selected group is a man? Note: this is not homework, I came up with this question on my own. Note 2: all distributions are normal distributions. EDIT: My current reasoning is that if $Z = M-W$ : $E(Z) = E(M-W) = E(M) - E(W)$ And $V(Z) = V(M-W) = V(M) + V(W) = \sqrt2\sigma$ Thus the probability that one man is taller than one woman is: $P(Z>0)$ And so the probability that all women are taller than all men in the sample is: $(1 - P(Z>0))^{n/2}$ : However this result has lead me to some very odd conclusions. So I suspect I am wrong.","Assume we have a population of N men and women such that exactly people are men (set ) and people are women (set ). Assume that the standard deviations for height between both groups is the same however their averages are different with . We pick people at random from the population such that people are men and people are women. Knowing what's the probability that the tallest person in the selected group is a man? Note: this is not homework, I came up with this question on my own. Note 2: all distributions are normal distributions. EDIT: My current reasoning is that if : And Thus the probability that one man is taller than one woman is: And so the probability that all women are taller than all men in the sample is: : However this result has lead me to some very odd conclusions. So I suspect I am wrong.",N/2 M N/2 W \sigma \mu_M > \mu_W n n/2 n/2 n Z = M-W E(Z) = E(M-W) = E(M) - E(W) V(Z) = V(M-W) = V(M) + V(W) = \sqrt2\sigma P(Z>0) (1 - P(Z>0))^{n/2},"['statistics', 'normal-distribution', 'standard-deviation']"
99,Proof Verification: $\tilde{\beta_1}$ is an unbiased estimator of $\beta_1$ obtained by assuming intercept is zero,Proof Verification:  is an unbiased estimator of  obtained by assuming intercept is zero,\tilde{\beta_1} \beta_1,"Consider the standard simple regression model $y= \beta_o + \beta_1 x +u$ under the Gauss-Markov Assumptions SLR.1 through SLR.5. Let $\tilde{\beta_1}$ be the estimator for $\beta_1$ obtained by assuming that the intercept is 0. Find $E[\tilde{\beta_1}]$ in terms of the $x_i$ , $\beta_0$ , and $\beta_1$ . Verify that $\tilde{\beta_1}$ is an unbiased estimator of $\beta_1$ obtained by assuming intercept is zero. Are there any other cases when $\tilde{\beta_1}$ is unbiased? Proof: We need to prove that $E[\tilde{\beta_1}] = E[\beta_1]$ Using least squares, we find that $\tilde{\beta_1} = \dfrac{\sum{x_iy_i}}{\sum{(x_i)^2}}$ Then, $ \tilde{\beta_1} = \dfrac{\sum{x_i(\beta_0 +\beta_1x_i +u)}}{\sum{(x_i)^2}}$ $\implies  \tilde{\beta_1} = \beta_0\dfrac{\sum{x_i}}{\sum{(x_i)^2}} +\beta_1 +\dfrac{\sum{x_iu_i}}{\sum{(x_i)^2}}$ Taking Expectayion on both sides: $\implies E[\tilde{\beta_1}] = \beta_0E[\dfrac{\sum{x_i}}{\sum{(x_i)^2}}]+ \beta_1 +\dfrac{\sum{E(x_iu_i)}}{E[\sum{(x_i)^2}]}$ (since summation and expectation operators are interchangeable) Then, we have that $E[x_iu_i]=0$ by assumption (results from the assumption that $E[u|x]=0$ $\implies E[\tilde{\beta_1}] = \beta_0E[\dfrac{\sum{x_i}}{\sum{(x_i)^2}}]+ \beta_1 +0$ Now, the only problem we have is with the $\beta_0$ term. If we have that $\beta_0 =0$ or $\sum{x_i}=0$ , then $\tilde{\beta_1}$ is an unbiased estimator of $\beta_1$ / Can anyone please verify this proof? Also, why don't we write $y= \beta_1x +u$ instead of $y= \beta_0 +\beta_1x +u$ if we're assuming that $\beta_0 =0$ anyway? Please let me know if my reasoning is valid and if there are any errors. Thank you. EDIT: Here's where I got the slope estimate from:","Consider the standard simple regression model under the Gauss-Markov Assumptions SLR.1 through SLR.5. Let be the estimator for obtained by assuming that the intercept is 0. Find in terms of the , , and . Verify that is an unbiased estimator of obtained by assuming intercept is zero. Are there any other cases when is unbiased? Proof: We need to prove that Using least squares, we find that Then, Taking Expectayion on both sides: (since summation and expectation operators are interchangeable) Then, we have that by assumption (results from the assumption that Now, the only problem we have is with the term. If we have that or , then is an unbiased estimator of / Can anyone please verify this proof? Also, why don't we write instead of if we're assuming that anyway? Please let me know if my reasoning is valid and if there are any errors. Thank you. EDIT: Here's where I got the slope estimate from:",y= \beta_o + \beta_1 x +u \tilde{\beta_1} \beta_1 E[\tilde{\beta_1}] x_i \beta_0 \beta_1 \tilde{\beta_1} \beta_1 \tilde{\beta_1} E[\tilde{\beta_1}] = E[\beta_1] \tilde{\beta_1} = \dfrac{\sum{x_iy_i}}{\sum{(x_i)^2}}  \tilde{\beta_1} = \dfrac{\sum{x_i(\beta_0 +\beta_1x_i +u)}}{\sum{(x_i)^2}} \implies  \tilde{\beta_1} = \beta_0\dfrac{\sum{x_i}}{\sum{(x_i)^2}} +\beta_1 +\dfrac{\sum{x_iu_i}}{\sum{(x_i)^2}} \implies E[\tilde{\beta_1}] = \beta_0E[\dfrac{\sum{x_i}}{\sum{(x_i)^2}}]+ \beta_1 +\dfrac{\sum{E(x_iu_i)}}{E[\sum{(x_i)^2}]} E[x_iu_i]=0 E[u|x]=0 \implies E[\tilde{\beta_1}] = \beta_0E[\dfrac{\sum{x_i}}{\sum{(x_i)^2}}]+ \beta_1 +0 \beta_0 \beta_0 =0 \sum{x_i}=0 \tilde{\beta_1} \beta_1 y= \beta_1x +u y= \beta_0 +\beta_1x +u \beta_0 =0,"['statistics', 'proof-verification', 'regression', 'parameter-estimation', 'expected-value']"
