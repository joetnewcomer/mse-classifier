,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Find limit of sequence using integral,Find limit of sequence using integral,,"Given sequence $$a_m = \frac{1}{m^2} \sum \limits_{k = 1}^m \sqrt[3]{(mx + k + 1)\cdot (mx + k)^2}$$ Find its limit using integral. I thought it may be solved using either Euler-Mclaurin formula or Riemann sum. Unfortunately, the function under the sum sign is pretty uncomfy to operate with.","Given sequence $$a_m = \frac{1}{m^2} \sum \limits_{k = 1}^m \sqrt[3]{(mx + k + 1)\cdot (mx + k)^2}$$ Find its limit using integral. I thought it may be solved using either Euler-Mclaurin formula or Riemann sum. Unfortunately, the function under the sum sign is pretty uncomfy to operate with.",,"['integration', 'limits', 'definite-integrals', 'summation', 'riemann-sum']"
1,Approximating specific integrals via sums: Tight error predictions,Approximating specific integrals via sums: Tight error predictions,,"Dear math enthusiasts, I am facing a particular problem where I am looking at integrals of the form $$I = \int_{-\infty}^\infty p(t) {\rm e}^{-t^2} {\rm d}t,$$ where $p(t)$ are certain polynomials. These are either even or odd symmetric, the even symmetric ones being the more interesting case since for odd ones, the integral is zero (in fact, they are auto- and cross-products of Hermite polynomials but I think this detail is not relevant). For now, we can just consider the simplest example $p(t)=t^2$. The reason why I am looking at the integrals is that I actually have sums of the form $$S(t) = \sum_{n=-\infty}^\infty t_0 p(t-nt_0) {\rm e}^{-(t-nt_0)^2}$$ which I want to quantify. For $t_0$ small enough, these sums are very close to $I$ for any $t$. I need to quantify how close, i.e., I am interested in $$\max_t |S(t)-I|.$$ So, what I did was to interpret $S$ as a quadrature of the integral $I$ and use the residual formulas for quadratures. Since it is a linear quadrature, the standard results predict a residual of the order $|I-S|< {\rm const} \cdot t_0^2 \cdot \max|f''(t)|$, where $f(t) = p(t){\rm e}^{-t^2}$ (which gives $\max|f''(t)| = 2$ for $p(t)=t^2$).  In other words, the error should decay quadratically with $t_0$. All this is not surprising and well within what I expected. Until I tried it and realized that  empirically, the error decays much much faster with $t_0$ than this pessimistic bound predicts. Here is an example: In this example, I computed $S$ for $p(t)=t^2$, varying the grid spacing $t_0$. I plot $\max_t|I-S(t)|/I$ where the exact value $I$ is equal to $\sqrt{\pi}/2$. Obviously, $t_0=1$ is too coarse but as I make it finer, the error goes to zero very rapidly (Note that the plot is doubly logarithmic!). In fact, around $t=0.35$ it reaches the numerical accuracy of my double floating point but I would expect the exponentially decaying trend to continue. The predicted upper bound is shown in the dashed line (it is a line with slope 2 due to the double logarithmic plot). So here is my question: Can I make tighter predictions of $|S(t)-I|$ as $t_0\rightarrow 0$? I know it is easy to construct examples where the residual formula is basically tight, so it must have to do with the particular function I am integrating, especially the ${\rm e}^{-t^2}$ term. I keep getting reminded of Gaussian tails (erfc functions of some sort) but I cannot put my hands on how I could get there. Just before posting I stumbled upon Euler-Maclaurin, but it confuses me as well since what I read about it talks about finite sums (and derivatives being evaluated at the borders) while mine seems infinite (and everything becomes zero far enough from $t=0$). It looks like a standard result and I would not be surprised about a very simple answer that I was just not seeing. Any hint is appreciated, many thanks in advance! edit : Thanks to user14717 I got what I needed. For someone stumbling across a similar problem, here is what worked: Theorem 5.1 in [*] says the following: Let $a>0$ such that the function $w(t)$ to be integrated is analytic in the string $|{\rm Im}(t)|<a$ and decays to zero uniformly as $|t|\rightarrow \infty$. Then: $$|I-S| \leq 2\sqrt{\pi} \frac{M}{{\rm e}^{2\pi a/t_0}-1},$$ where $M$ is a constant satisfying $\int |w(t+ib)| {\rm d}t \leq M$ for all $b \in (-a,a)$. If we apply this for $w(t) = {\rm e}^{-t^2}$ (i.e., my $p(t)=1$), we obtain $M={\rm e}^{a^2}$ as the best $M$ for a given $a$. This gives the family of bounds $$|I-S| \leq 2\sqrt{\pi} \frac{{\rm e}^{a^2}}{{\rm e}^{2\pi a/t_0}-1},$$ which is valid for any $a>0$. To obtain the tightest bound, we need to minimize over $a$. This is not possible analytically, however, for $t_0<1$, the value $a=\frac{\pi}{t_0}$ is very close to the optimum. Inserting it gives the bound $$|I-S| \leq  \frac{2\sqrt{\pi}}{{\rm e}^{(\pi/t_0)^2}-{\rm e}^{-(\pi/t_0)^2}} \approx 2\sqrt{\pi} {\rm e}^{-(\pi/t_0)^2}.$$ And now, let us plot it: Adapting this to any $p(t)$ should be a breeze now. I could barely be happier! :) Thanks so much! [*] http://epubs.siam.org/doi/pdf/10.1137/130932132 edit2 : For an even symmetric polynomial $p(t)$ it is then very easy to show that $$|S-I|\leq \frac{2{\rm e}^{a^2} h(a)}{{\rm e}^{2\pi a/t_0}-1},$$ where $h(a)$ is a polynomial of same degree as $p(t)$. For $a=\pi/t_0$, this gives $$|S-I|\leq \frac{2{\rm e}^{\pi^2/t_0^2}}{{\rm e}^{2\pi^2/t_0^2}-1}h(\pi/t_0) \approx 2{\rm e}^{-\pi^2/t_0^2}h(\pi/t_0),$$ i.e., still exponential convergence, as expected. In fact, for a degree $2k$ polynomial $p(t) = \sum_n \alpha_n t^{2(k-n)}$, an explicit form of $h(t)$ is given by $$h(t) = \sqrt{\pi} \sum_n \sum_\ell |\alpha_n|\frac{k! (2\ell)!}{4^\ell (\ell!)^2 (k-\ell)!} b^{2(k-n-\ell)},$$ though it doesn't matter much since the relevant part is the exponential convergence.","Dear math enthusiasts, I am facing a particular problem where I am looking at integrals of the form $$I = \int_{-\infty}^\infty p(t) {\rm e}^{-t^2} {\rm d}t,$$ where $p(t)$ are certain polynomials. These are either even or odd symmetric, the even symmetric ones being the more interesting case since for odd ones, the integral is zero (in fact, they are auto- and cross-products of Hermite polynomials but I think this detail is not relevant). For now, we can just consider the simplest example $p(t)=t^2$. The reason why I am looking at the integrals is that I actually have sums of the form $$S(t) = \sum_{n=-\infty}^\infty t_0 p(t-nt_0) {\rm e}^{-(t-nt_0)^2}$$ which I want to quantify. For $t_0$ small enough, these sums are very close to $I$ for any $t$. I need to quantify how close, i.e., I am interested in $$\max_t |S(t)-I|.$$ So, what I did was to interpret $S$ as a quadrature of the integral $I$ and use the residual formulas for quadratures. Since it is a linear quadrature, the standard results predict a residual of the order $|I-S|< {\rm const} \cdot t_0^2 \cdot \max|f''(t)|$, where $f(t) = p(t){\rm e}^{-t^2}$ (which gives $\max|f''(t)| = 2$ for $p(t)=t^2$).  In other words, the error should decay quadratically with $t_0$. All this is not surprising and well within what I expected. Until I tried it and realized that  empirically, the error decays much much faster with $t_0$ than this pessimistic bound predicts. Here is an example: In this example, I computed $S$ for $p(t)=t^2$, varying the grid spacing $t_0$. I plot $\max_t|I-S(t)|/I$ where the exact value $I$ is equal to $\sqrt{\pi}/2$. Obviously, $t_0=1$ is too coarse but as I make it finer, the error goes to zero very rapidly (Note that the plot is doubly logarithmic!). In fact, around $t=0.35$ it reaches the numerical accuracy of my double floating point but I would expect the exponentially decaying trend to continue. The predicted upper bound is shown in the dashed line (it is a line with slope 2 due to the double logarithmic plot). So here is my question: Can I make tighter predictions of $|S(t)-I|$ as $t_0\rightarrow 0$? I know it is easy to construct examples where the residual formula is basically tight, so it must have to do with the particular function I am integrating, especially the ${\rm e}^{-t^2}$ term. I keep getting reminded of Gaussian tails (erfc functions of some sort) but I cannot put my hands on how I could get there. Just before posting I stumbled upon Euler-Maclaurin, but it confuses me as well since what I read about it talks about finite sums (and derivatives being evaluated at the borders) while mine seems infinite (and everything becomes zero far enough from $t=0$). It looks like a standard result and I would not be surprised about a very simple answer that I was just not seeing. Any hint is appreciated, many thanks in advance! edit : Thanks to user14717 I got what I needed. For someone stumbling across a similar problem, here is what worked: Theorem 5.1 in [*] says the following: Let $a>0$ such that the function $w(t)$ to be integrated is analytic in the string $|{\rm Im}(t)|<a$ and decays to zero uniformly as $|t|\rightarrow \infty$. Then: $$|I-S| \leq 2\sqrt{\pi} \frac{M}{{\rm e}^{2\pi a/t_0}-1},$$ where $M$ is a constant satisfying $\int |w(t+ib)| {\rm d}t \leq M$ for all $b \in (-a,a)$. If we apply this for $w(t) = {\rm e}^{-t^2}$ (i.e., my $p(t)=1$), we obtain $M={\rm e}^{a^2}$ as the best $M$ for a given $a$. This gives the family of bounds $$|I-S| \leq 2\sqrt{\pi} \frac{{\rm e}^{a^2}}{{\rm e}^{2\pi a/t_0}-1},$$ which is valid for any $a>0$. To obtain the tightest bound, we need to minimize over $a$. This is not possible analytically, however, for $t_0<1$, the value $a=\frac{\pi}{t_0}$ is very close to the optimum. Inserting it gives the bound $$|I-S| \leq  \frac{2\sqrt{\pi}}{{\rm e}^{(\pi/t_0)^2}-{\rm e}^{-(\pi/t_0)^2}} \approx 2\sqrt{\pi} {\rm e}^{-(\pi/t_0)^2}.$$ And now, let us plot it: Adapting this to any $p(t)$ should be a breeze now. I could barely be happier! :) Thanks so much! [*] http://epubs.siam.org/doi/pdf/10.1137/130932132 edit2 : For an even symmetric polynomial $p(t)$ it is then very easy to show that $$|S-I|\leq \frac{2{\rm e}^{a^2} h(a)}{{\rm e}^{2\pi a/t_0}-1},$$ where $h(a)$ is a polynomial of same degree as $p(t)$. For $a=\pi/t_0$, this gives $$|S-I|\leq \frac{2{\rm e}^{\pi^2/t_0^2}}{{\rm e}^{2\pi^2/t_0^2}-1}h(\pi/t_0) \approx 2{\rm e}^{-\pi^2/t_0^2}h(\pi/t_0),$$ i.e., still exponential convergence, as expected. In fact, for a degree $2k$ polynomial $p(t) = \sum_n \alpha_n t^{2(k-n)}$, an explicit form of $h(t)$ is given by $$h(t) = \sqrt{\pi} \sum_n \sum_\ell |\alpha_n|\frac{k! (2\ell)!}{4^\ell (\ell!)^2 (k-\ell)!} b^{2(k-n-\ell)},$$ though it doesn't matter much since the relevant part is the exponential convergence.",,"['real-analysis', 'integration', 'sequences-and-series']"
2,Is this normed linear space a Banach space? [duplicate],Is this normed linear space a Banach space? [duplicate],,This question already has an answer here : Is $L^{p}$ space with alternate norm Banach? (1 answer) Closed 7 years ago . Let $E$ be a measurable set of finite measure and $1 < p_1 < p_2 < \infty$. Consider the linear space $L^{p_2} (E)$ normed by $||.||_{p_1}$ . Is this normed linear space a Banach space?,This question already has an answer here : Is $L^{p}$ space with alternate norm Banach? (1 answer) Closed 7 years ago . Let $E$ be a measurable set of finite measure and $1 < p_1 < p_2 < \infty$. Consider the linear space $L^{p_2} (E)$ normed by $||.||_{p_1}$ . Is this normed linear space a Banach space?,,"['integration', 'functional-analysis', 'measure-theory', 'banach-spaces', 'lp-spaces']"
3,Different method of proving $\int_{0}^{1}{ dx\over x}\ln\left({1-\sqrt{x}\over 1+\sqrt{x}}\cdot{1+\sqrt[3]{x}\over 1-\sqrt[3]{x}}\cdots\right)=-\pi^2$,Different method of proving,\int_{0}^{1}{ dx\over x}\ln\left({1-\sqrt{x}\over 1+\sqrt{x}}\cdot{1+\sqrt[3]{x}\over 1-\sqrt[3]{x}}\cdots\right)=-\pi^2,"Given the integral $(1)$ $$\text{Prove that}\ \int_{0}^{1}{\mathrm dx\over x}\ln\left({1-\sqrt{x}\over 1+\sqrt{x}}\cdot{1+\sqrt[3]{x}\over 1-\sqrt[3]{x}}\cdot{1-\sqrt[5]{x}\over 1+\sqrt[5]{x}}\right)=-\pi^2\tag1$$ An attempt: $u=x^2,x^3 \text{and}\ x^5$, then $(1)$ becomes $$\int_{0}^{1}{\mathrm du\over u}\ln\left[\left({1-u\over 1+u}\right)^2\left({1+u\over 1-u}\right)^3\left({1-u\over 1+u}\right)^5\right]\tag2$$ Simplify to $$\int_{0}^{1}{\mathrm du\over u}\ln\left({1-u\over 1+u}\right)^4\tag3$$ Apply $\ln\left({1+u\over 1-u}\right)$ series, then we have $$-\sum_{n=0}^{\infty}{1\over (2n+1)}\int_{0}^{1}u^{2n}\mathrm du\tag4$$ $$-8\sum_{n=0}^{\infty}{1\over (2n+1)^2}=-\pi^2\tag5$$ Looking for another method of proving $(1)$","Given the integral $(1)$ $$\text{Prove that}\ \int_{0}^{1}{\mathrm dx\over x}\ln\left({1-\sqrt{x}\over 1+\sqrt{x}}\cdot{1+\sqrt[3]{x}\over 1-\sqrt[3]{x}}\cdot{1-\sqrt[5]{x}\over 1+\sqrt[5]{x}}\right)=-\pi^2\tag1$$ An attempt: $u=x^2,x^3 \text{and}\ x^5$, then $(1)$ becomes $$\int_{0}^{1}{\mathrm du\over u}\ln\left[\left({1-u\over 1+u}\right)^2\left({1+u\over 1-u}\right)^3\left({1-u\over 1+u}\right)^5\right]\tag2$$ Simplify to $$\int_{0}^{1}{\mathrm du\over u}\ln\left({1-u\over 1+u}\right)^4\tag3$$ Apply $\ln\left({1+u\over 1-u}\right)$ series, then we have $$-\sum_{n=0}^{\infty}{1\over (2n+1)}\int_{0}^{1}u^{2n}\mathrm du\tag4$$ $$-8\sum_{n=0}^{\infty}{1\over (2n+1)^2}=-\pi^2\tag5$$ Looking for another method of proving $(1)$",,"['calculus', 'integration', 'definite-integrals']"
4,Proving $\int_{0}^{1}{1\over \sqrt[4]{\ln \left({1\over x}\right)+\ln^2\left({1\over x}\right)}}\cdot{\mathrm dx\over x}=\cdots$,Proving,\int_{0}^{1}{1\over \sqrt[4]{\ln \left({1\over x}\right)+\ln^2\left({1\over x}\right)}}\cdot{\mathrm dx\over x}=\cdots,"Consider this integral $(1)$ $$\int_{0}^{1}{1\over \sqrt[4]{\ln \left({1\over x}\right)+\ln^2\left({1\over x}\right)}}\cdot{\mathrm dx\over x}=-\Gamma\left(-{2\over 4}\right)\cdot{\Gamma\left({3\over 4}\right)\over \Gamma\left({1\over 4}\right)}\tag1$$ How can one prove $(1)$? An attempt: Rewrite $(1)$ as $$\int_{0}^{1}(-\ln x+\ln^2(x))^{-1/4}\cdot{\mathrm dx\over x}\tag2$$ $u=\ln x \implies x\mathrm du =\mathrm dx$ then $(2)$ becomes $$\int_{0}^{\infty}(u^2-u)^{-1/4}\mathrm du\tag3$$ May be we can split it into partial decomposition of fraction $${1\over u^{1/4}(u-1)^{1/4}}={A\over u^{1/4}}+{B\over (u-1)^{1/4}}$$ Then $(3)$ becomes $$\int_{0}^{\infty}{\color{red}{A\over u^{1/4}}}+{B\over (u-1)^{1/4}}\mathrm du\tag4$$ But the red part diverges, how else can we tackle $(1)?$","Consider this integral $(1)$ $$\int_{0}^{1}{1\over \sqrt[4]{\ln \left({1\over x}\right)+\ln^2\left({1\over x}\right)}}\cdot{\mathrm dx\over x}=-\Gamma\left(-{2\over 4}\right)\cdot{\Gamma\left({3\over 4}\right)\over \Gamma\left({1\over 4}\right)}\tag1$$ How can one prove $(1)$? An attempt: Rewrite $(1)$ as $$\int_{0}^{1}(-\ln x+\ln^2(x))^{-1/4}\cdot{\mathrm dx\over x}\tag2$$ $u=\ln x \implies x\mathrm du =\mathrm dx$ then $(2)$ becomes $$\int_{0}^{\infty}(u^2-u)^{-1/4}\mathrm du\tag3$$ May be we can split it into partial decomposition of fraction $${1\over u^{1/4}(u-1)^{1/4}}={A\over u^{1/4}}+{B\over (u-1)^{1/4}}$$ Then $(3)$ becomes $$\int_{0}^{\infty}{\color{red}{A\over u^{1/4}}}+{B\over (u-1)^{1/4}}\mathrm du\tag4$$ But the red part diverges, how else can we tackle $(1)?$",,"['calculus', 'integration', 'definite-integrals']"
5,Steepest descent of integrand with a movable saddle?,Steepest descent of integrand with a movable saddle?,,"I want to apply the steepest descent method to the following integration: $$ \int_0^\infty e^{-x^2 + i \sqrt{x^2 + 1} \cdot \lambda } dx $$ It has movable saddle so I need to transform it into the standard form, something like $$ \int_C g(z) e^{\lambda f(z) } dz $$ I know for Gamma function: $$ \Gamma(x+1)= \int_0^\infty e^{-t} t^{x} dt =\int_0^\infty e^{-t + x \ln t} dt $$ letting $t = x s$ transforms it into standard form. And for Airy function: $$Ai(x) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{i (t^3/3 + x t)} dt $$ letting $t = \sqrt{x} z$ does the trick. However, no change of variable seems to transform my integration into the standard form. For this reason I can not proceed at all. Any hint or suggestion ? Thanks!","I want to apply the steepest descent method to the following integration: $$ \int_0^\infty e^{-x^2 + i \sqrt{x^2 + 1} \cdot \lambda } dx $$ It has movable saddle so I need to transform it into the standard form, something like $$ \int_C g(z) e^{\lambda f(z) } dz $$ I know for Gamma function: $$ \Gamma(x+1)= \int_0^\infty e^{-t} t^{x} dt =\int_0^\infty e^{-t + x \ln t} dt $$ letting $t = x s$ transforms it into standard form. And for Airy function: $$Ai(x) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{i (t^3/3 + x t)} dt $$ letting $t = \sqrt{x} z$ does the trick. However, no change of variable seems to transform my integration into the standard form. For this reason I can not proceed at all. Any hint or suggestion ? Thanks!",,"['integration', 'complex-analysis', 'asymptotics']"
6,Evaluate the integral of $\ln(1-x^5)$ as a power series,Evaluate the integral of  as a power series,\ln(1-x^5),"Evaluate the following integral as a power series. $$ \int \ln\left(1-x^5\right)dx $$ The correct answer is below, but I only understand why some parts of it are correct. $$ - \sum_{n=0}^{\infty} \frac{x^{5n+6}}{(n+1)(5n+6)} $$ Here’s where I get to: Replace $x^5$ with $t$. Then start with a geometric series of $a=1$ and $r=t$. $$ \frac{1}{1-t} = \sum_{n=0}^{\infty}t^n = 1 + t + t^2 + \dots $$ Integrate both sides. $$ -\ln(1-t)=\sum_{n=0}^{\infty}\frac{t^{n+1}}{n+1} = t+\frac{t^2}{2}+\frac{t^3}{6}+\dots\\ \ln(1-t)=-\sum_{n=0}^{\infty}\frac{t^{n+1}}{n+1} =-\left[ t+\frac{t^2}{2}+\frac{t^3}{6}+\dots\right] $$ At this point I’m fairly certain that this is not an alternating series and that the $-1$ coefficient outside the sum in the answer is correct. Integrate again, except I’m unsure where this leads me. I’m not sure how to integrate the $\frac{t^{n+1}}{n+1}$ nor how the expanded series becomes $\frac{x^{5n+6}}{(n+1)(5n+6)}$. $$ \int \ln(1-t)dt=-\left[\frac{t^2}{2}+\frac{t^3}{6}+\frac{t^4}{24}+\dots\right] $$ Typing this out has led me to think the following but I don’t feel very confident about it. I know the following theorem, $$ f(x) = \sum_{n=0}^{\infty} c_n(x-a)^n\\ \int f(x) dx = C + \sum_{n=0}^{\infty} c_n\frac{(x-a)^{n+1}}{n+1} $$ Does this mean that if I have $\sum \frac{t^{n+1}}{n+1}$ I could say the following? $$ \sum_{n=0}^{\infty} \frac{1}{n+1}(x^5)^{n+1} \Rightarrow c_n = \frac{1}{n+1} $$ Then integrating, $$ \sum_{n=0}^{\infty} \frac{1}{n+1} \frac{x^{5n+5+1}}{5n+5+1}=\sum_{n=0}^{\infty} \frac{x^{5n+6}}{(n+1)(5n+6)} $$ This gives me the part of the complete answer that I understand. Something about this feels off to me, though. Have I jumped ahead somewhere? Why can I sub $x^5$ back in at that intermediate step but not after?","Evaluate the following integral as a power series. $$ \int \ln\left(1-x^5\right)dx $$ The correct answer is below, but I only understand why some parts of it are correct. $$ - \sum_{n=0}^{\infty} \frac{x^{5n+6}}{(n+1)(5n+6)} $$ Here’s where I get to: Replace $x^5$ with $t$. Then start with a geometric series of $a=1$ and $r=t$. $$ \frac{1}{1-t} = \sum_{n=0}^{\infty}t^n = 1 + t + t^2 + \dots $$ Integrate both sides. $$ -\ln(1-t)=\sum_{n=0}^{\infty}\frac{t^{n+1}}{n+1} = t+\frac{t^2}{2}+\frac{t^3}{6}+\dots\\ \ln(1-t)=-\sum_{n=0}^{\infty}\frac{t^{n+1}}{n+1} =-\left[ t+\frac{t^2}{2}+\frac{t^3}{6}+\dots\right] $$ At this point I’m fairly certain that this is not an alternating series and that the $-1$ coefficient outside the sum in the answer is correct. Integrate again, except I’m unsure where this leads me. I’m not sure how to integrate the $\frac{t^{n+1}}{n+1}$ nor how the expanded series becomes $\frac{x^{5n+6}}{(n+1)(5n+6)}$. $$ \int \ln(1-t)dt=-\left[\frac{t^2}{2}+\frac{t^3}{6}+\frac{t^4}{24}+\dots\right] $$ Typing this out has led me to think the following but I don’t feel very confident about it. I know the following theorem, $$ f(x) = \sum_{n=0}^{\infty} c_n(x-a)^n\\ \int f(x) dx = C + \sum_{n=0}^{\infty} c_n\frac{(x-a)^{n+1}}{n+1} $$ Does this mean that if I have $\sum \frac{t^{n+1}}{n+1}$ I could say the following? $$ \sum_{n=0}^{\infty} \frac{1}{n+1}(x^5)^{n+1} \Rightarrow c_n = \frac{1}{n+1} $$ Then integrating, $$ \sum_{n=0}^{\infty} \frac{1}{n+1} \frac{x^{5n+5+1}}{5n+5+1}=\sum_{n=0}^{\infty} \frac{x^{5n+6}}{(n+1)(5n+6)} $$ This gives me the part of the complete answer that I understand. Something about this feels off to me, though. Have I jumped ahead somewhere? Why can I sub $x^5$ back in at that intermediate step but not after?",,"['integration', 'sequences-and-series', 'power-series', 'indefinite-integrals']"
7,Evaluate integral with integer part,Evaluate integral with integer part,,"I have to evaluate $$\int _0^2\:\frac{x-\left[x\right]}{2x-\left[x\right]+1}dx$$ Where $[x] = floor(x)$ I tend to write it like this, but I think i'm missing the point $x = 2$ $$\int _0^2\:\frac{x-\left[x\right]}{2x-\left[x\right]+1}dx=\int _0^1\:\frac{x}{2x+1}dx+\int _1^2\:\frac{x-1}{2x}dx = 1 - \frac{1}{4} \cdot \ln 3$$ The correct answer is $1 - \frac{1}{4} \cdot \ln 12$","I have to evaluate $$\int _0^2\:\frac{x-\left[x\right]}{2x-\left[x\right]+1}dx$$ Where $[x] = floor(x)$ I tend to write it like this, but I think i'm missing the point $x = 2$ $$\int _0^2\:\frac{x-\left[x\right]}{2x-\left[x\right]+1}dx=\int _0^1\:\frac{x}{2x+1}dx+\int _1^2\:\frac{x-1}{2x}dx = 1 - \frac{1}{4} \cdot \ln 3$$ The correct answer is $1 - \frac{1}{4} \cdot \ln 12$",,['integration']
8,The 'd' symbol in integration and derivation,The 'd' symbol in integration and derivation,,"What is a good way to think about the d symbol in derivation and integration? Every time I think I understand what it means, I see it in a new context that is incompatible with my previous ideas. Example: integrate: x dx + 5 . I used to think that the integration symbol is like an opening parenthesis and the d symbol is like the closing parenthesis, telling us that we don't want to integrate the + 5 . I used to think that the x in dx determines the variable that we integrate by. Now take a look at the left hand side of this equation from Khan Academy: Instead of integrating u(x)v'(x) by x , we integrate u by v . How are these things equal? How can we even integrate by v when it isn't a variable, it's a function! u doesn't necessarily even contain v , so how can we integrate u by v ? What kind of black magic happened here?","What is a good way to think about the d symbol in derivation and integration? Every time I think I understand what it means, I see it in a new context that is incompatible with my previous ideas. Example: integrate: x dx + 5 . I used to think that the integration symbol is like an opening parenthesis and the d symbol is like the closing parenthesis, telling us that we don't want to integrate the + 5 . I used to think that the x in dx determines the variable that we integrate by. Now take a look at the left hand side of this equation from Khan Academy: Instead of integrating u(x)v'(x) by x , we integrate u by v . How are these things equal? How can we even integrate by v when it isn't a variable, it's a function! u doesn't necessarily even contain v , so how can we integrate u by v ? What kind of black magic happened here?",,"['integration', 'derivatives', 'indefinite-integrals']"
9,Meaning of symbol product (cross) in a circle: ⨂,Meaning of symbol product (cross) in a circle: ⨂,,"I came across this expression: $\tilde{\Phi}(\mu, \nu)\ \dot{=}\ \int_{A\times B}{\Phi(a, b)\ \mathrm{d}\mu \otimes \mathrm{d}\nu}$ In a context where: $A$ and $B$ are compact metric spaces $\mu$ and $\nu$ are probability distribution over $A$ and $B$, resp. $\Phi$ is a continuous function $A \times B \rightarrow \mathbb{R}$ $\tilde{\Phi}(\mu, \nu)$ is said to be the expected value of $\Phi$ I understand that you need to integrate over $A \times B$ to get this expected value, and to take $\mu$ and $\nu$ distributions into account while doing this. But.. How am I supposed to understand the $\otimes$ symbol here? What is this operation? How does $\mathrm{d}\mu$ relates to $a$ and $\mathrm{d}\nu$ relates to $b$ within this integrand? (To get the full context, I've found this in these pretty neat notes introducing differential game theory (equation 2.8 page 13).)","I came across this expression: $\tilde{\Phi}(\mu, \nu)\ \dot{=}\ \int_{A\times B}{\Phi(a, b)\ \mathrm{d}\mu \otimes \mathrm{d}\nu}$ In a context where: $A$ and $B$ are compact metric spaces $\mu$ and $\nu$ are probability distribution over $A$ and $B$, resp. $\Phi$ is a continuous function $A \times B \rightarrow \mathbb{R}$ $\tilde{\Phi}(\mu, \nu)$ is said to be the expected value of $\Phi$ I understand that you need to integrate over $A \times B$ to get this expected value, and to take $\mu$ and $\nu$ distributions into account while doing this. But.. How am I supposed to understand the $\otimes$ symbol here? What is this operation? How does $\mathrm{d}\mu$ relates to $a$ and $\mathrm{d}\nu$ relates to $b$ within this integrand? (To get the full context, I've found this in these pretty neat notes introducing differential game theory (equation 2.8 page 13).)",,"['integration', 'probability-distributions', 'notation']"
10,How are these problems called and how are they solved?,How are these problems called and how are they solved?,,"I'm self learning calculus and I stumbled upon the following problem: Express $I_n =\int \frac{dx}{(x^2+a^2)^n}$ Using $I_{n-1}$ ($a$ is a positive parameter and $n=2,3,4,...$) Is this about double integrals? Could anyone please elaborate a bit more so I can learn how to solve this type of problems? ================= EDIT Continuing @SimplyBeautifulArt's answer: $I_n=a^{1-2n}\int{cos^{2n-2}(u)du} = a^{1-2n}\int{cos^{2n-3}(u)cos(u)du}$ $I_{n-1}=a^{3-2n}\int{cos^{2n-4}(u)du}$ Integrating by parts($f:cos^{2n-3}(u); dg:cos(u)du$): $I_n=a^{1-2n}(cos^{2n-3}(u)sin(u) + (2n-3)\int{cos^{2n-4}(u)sin^2(u)du})$ $I_n=a^{1-2n}(cos^{2n-3}(u)sin(u) + (2n-3)(\int{cos^{2n-4}(u)du} -\int{cos^{2n-2}(u)du}))$ $I_n=a^{1-2n}cos^{2n-3}(u)sin(u) + (2n-3)(\frac{a^{3-2n}}{a^2}\int{cos^{2n-4}(u)du} -a^{1-2n}\int{cos^{2n-2}(u)du})$ $I_n=a^{1-2n}cos^{2n-3}(u)sin(u) + (2n-3)(\frac{I_{n-1}}{a^2} -I_n)$ $I_n=(a^{1-2n}cos^{2n-3}(u)sin(u) + (2n-3)\frac{I_{n-1}}{a^2})/2n-2$ Recall $u=arctan(\frac xa)$ $I_n=(a^{1-2n}\frac{1}{\sqrt{1+(x/a)^2}}^{2n-3}\frac{x/a}{\sqrt{1+(x/a)^2}} + (2n-3)\frac{I_{n-1}}{a^2})/2n-2$ Is that all?","I'm self learning calculus and I stumbled upon the following problem: Express $I_n =\int \frac{dx}{(x^2+a^2)^n}$ Using $I_{n-1}$ ($a$ is a positive parameter and $n=2,3,4,...$) Is this about double integrals? Could anyone please elaborate a bit more so I can learn how to solve this type of problems? ================= EDIT Continuing @SimplyBeautifulArt's answer: $I_n=a^{1-2n}\int{cos^{2n-2}(u)du} = a^{1-2n}\int{cos^{2n-3}(u)cos(u)du}$ $I_{n-1}=a^{3-2n}\int{cos^{2n-4}(u)du}$ Integrating by parts($f:cos^{2n-3}(u); dg:cos(u)du$): $I_n=a^{1-2n}(cos^{2n-3}(u)sin(u) + (2n-3)\int{cos^{2n-4}(u)sin^2(u)du})$ $I_n=a^{1-2n}(cos^{2n-3}(u)sin(u) + (2n-3)(\int{cos^{2n-4}(u)du} -\int{cos^{2n-2}(u)du}))$ $I_n=a^{1-2n}cos^{2n-3}(u)sin(u) + (2n-3)(\frac{a^{3-2n}}{a^2}\int{cos^{2n-4}(u)du} -a^{1-2n}\int{cos^{2n-2}(u)du})$ $I_n=a^{1-2n}cos^{2n-3}(u)sin(u) + (2n-3)(\frac{I_{n-1}}{a^2} -I_n)$ $I_n=(a^{1-2n}cos^{2n-3}(u)sin(u) + (2n-3)\frac{I_{n-1}}{a^2})/2n-2$ Recall $u=arctan(\frac xa)$ $I_n=(a^{1-2n}\frac{1}{\sqrt{1+(x/a)^2}}^{2n-3}\frac{x/a}{\sqrt{1+(x/a)^2}} + (2n-3)\frac{I_{n-1}}{a^2})/2n-2$ Is that all?",,"['calculus', 'integration', 'self-learning']"
11,Integration with respect to counting measure when $X=\mathbb{R}$,Integration with respect to counting measure when,X=\mathbb{R},"Consider the measure space $(X,\mathcal{M},\mu)$ where $X=\mathbb{R}$, $\mathcal{M}=\mathcal{P}(X)$ and $\mu$ is the counting measure. I want to show that for every measurable function $f : \mathbb{R} \mapsto [0,+\infty]$, given $x \in \mathbb{R}$, $\int_{\{ x\}} f \, d \mu = f(x) $. Generally speaking $\int_{X} f \, d \mu = \sum_{x \in X} f(x) $.  I can do this in the case $X=\mathbb{N}$ with a monotone convergence argument, but when $X$ is uncountable I find some trouble. How can I fix things when $X$ is uncountable?","Consider the measure space $(X,\mathcal{M},\mu)$ where $X=\mathbb{R}$, $\mathcal{M}=\mathcal{P}(X)$ and $\mu$ is the counting measure. I want to show that for every measurable function $f : \mathbb{R} \mapsto [0,+\infty]$, given $x \in \mathbb{R}$, $\int_{\{ x\}} f \, d \mu = f(x) $. Generally speaking $\int_{X} f \, d \mu = \sum_{x \in X} f(x) $.  I can do this in the case $X=\mathbb{N}$ with a monotone convergence argument, but when $X$ is uncountable I find some trouble. How can I fix things when $X$ is uncountable?",,"['integration', 'measure-theory']"
12,Deriving a Series Representation of an Integral (Riemann Zeta Function),Deriving a Series Representation of an Integral (Riemann Zeta Function),,"It is known that $$\int_0^\infty\frac{x^n}{e^x-1}dx=n!\zeta(n+1)$$ for integer values of $n$ (this is also generalises, but that's not important for this question). I have also had a look at how to arrive at this expression, starting from the series representation of the Riemann Zeta function. However, just out of interest, I've tried to see if I could manage to derive the series representation for the case that sparked my interest in the first place $(n=3)$ on my own - that is, working backwards from this formula to the series that initially defines the Riemann Zeta function. I did manage to arrive at a series representation, but it's not the correct series. Here's what I did: \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\int_0^\infty\frac{x^3(e^x+1)}{e^{2x}-1}dx\\ &=\int_0^\infty\frac{x^3}{e^{2x}-1}dx+\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx\\ &=\frac{1}{16}\int_0^\infty\frac{x^3}{e^x-1}dx+\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx \end{align} Subtracting the first term on the RHS, we have \begin{align} \frac{15}{16}\int_0^\infty\frac{x^3}{e^x-1}dx=\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx \end{align} Multiplying across the fraction, we have \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{16}{15}\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx\\ &=\frac{1}{15}\int_0^\infty\frac{x^3e^{\frac{x}{2}}}{e^x-1}dx \end{align} Letting $z:=e^x$, then $x=\log z\implies dx=\frac{dz}{z}$. \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\int_1^\infty\frac{\log^3z\sqrt{z}}{z(z-1)}dz \end{align} Letting $u:=\frac{1}{z}$, we have $z=\frac{1}{u}\implies dz=-\frac{du}{u^2}$, $u(1)=1$ and $u(z\rightarrow\infty)=0$. Thus \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\int_0^1\frac{\log^3\left(\frac{1}{u}\right)\sqrt{u}}{u^2}\frac{1}{1-\frac{1}{u}}du\\ &=-\frac{1}{15}\int_0^1\frac{\log^3u\sqrt{u}}{u}\frac{1}{u-1}du\\ &=\frac{1}{15}\int_0^1\frac{\log^3u}{\sqrt{u}}\frac{1}{1-u}du\\ &=\frac{1}{15}\int_0^1\frac{\log^3u}{\sqrt{u}}\sum_{k=0}^\infty u^k du\\ &=\frac{1}{15}\sum_{k=0}^\infty\int_0^1u^{k-\frac{1}{2}}\log^3u du \end{align} Letting $t:=\log u$, then $u=e^t\implies du=e^tdt$, $t(u\rightarrow 0)=-\infty$ and $t(1)=0$. \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\sum_{k=0}^\infty\int_{-\infty}^0 t^3e^{\left(k+\frac{1}{2}\right)t}dt \end{align} Letting $p:=-t$, then $dt=-dp$, $p(t\rightarrow -\infty)=\infty$ and $p(0)=0$. \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\sum_{k=0}^\infty\int_0^\infty p^3e^{-\left(k+\frac{1}{2}\right)p}dp \end{align} Letting $s:=\left(k+\frac{1}{2}\right)p$, then $dp=\frac{ds}{k+\frac{1}{2}}$. The bounds of integration are unchanged, and thus \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\sum_{k=0}^\infty\frac{1}{\left(k+\frac{1}{2}\right)^4}\int_0^\infty s^3e^{-s}ds\\ &=\frac{\Gamma(4)}{15}\sum_{k=0}^\infty\frac{1}{\left(k+\frac{1}{2}\right)^4}\\ &=\frac{2}{5}\sum_{k=0}^\infty\frac{1}{\left(k+\frac{1}{2}\right)^4} \end{align} EDIT: Apparently, this is simply a convoluted way of deriving the correct answer, as the series evaluates to $\frac{\pi^4}{6}$, making the final expression equal to the known value of $$\int_0^\infty\frac{x^3}{e^x-1}dx = 6\sum_{k=1}^\infty\frac{1}{k^4} = \frac{\pi^4}{15}$$ Many thanks to Simple Art for verifying this result!","It is known that $$\int_0^\infty\frac{x^n}{e^x-1}dx=n!\zeta(n+1)$$ for integer values of $n$ (this is also generalises, but that's not important for this question). I have also had a look at how to arrive at this expression, starting from the series representation of the Riemann Zeta function. However, just out of interest, I've tried to see if I could manage to derive the series representation for the case that sparked my interest in the first place $(n=3)$ on my own - that is, working backwards from this formula to the series that initially defines the Riemann Zeta function. I did manage to arrive at a series representation, but it's not the correct series. Here's what I did: \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\int_0^\infty\frac{x^3(e^x+1)}{e^{2x}-1}dx\\ &=\int_0^\infty\frac{x^3}{e^{2x}-1}dx+\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx\\ &=\frac{1}{16}\int_0^\infty\frac{x^3}{e^x-1}dx+\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx \end{align} Subtracting the first term on the RHS, we have \begin{align} \frac{15}{16}\int_0^\infty\frac{x^3}{e^x-1}dx=\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx \end{align} Multiplying across the fraction, we have \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{16}{15}\int_0^\infty\frac{x^3e^x}{e^{2x}-1}dx\\ &=\frac{1}{15}\int_0^\infty\frac{x^3e^{\frac{x}{2}}}{e^x-1}dx \end{align} Letting $z:=e^x$, then $x=\log z\implies dx=\frac{dz}{z}$. \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\int_1^\infty\frac{\log^3z\sqrt{z}}{z(z-1)}dz \end{align} Letting $u:=\frac{1}{z}$, we have $z=\frac{1}{u}\implies dz=-\frac{du}{u^2}$, $u(1)=1$ and $u(z\rightarrow\infty)=0$. Thus \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\int_0^1\frac{\log^3\left(\frac{1}{u}\right)\sqrt{u}}{u^2}\frac{1}{1-\frac{1}{u}}du\\ &=-\frac{1}{15}\int_0^1\frac{\log^3u\sqrt{u}}{u}\frac{1}{u-1}du\\ &=\frac{1}{15}\int_0^1\frac{\log^3u}{\sqrt{u}}\frac{1}{1-u}du\\ &=\frac{1}{15}\int_0^1\frac{\log^3u}{\sqrt{u}}\sum_{k=0}^\infty u^k du\\ &=\frac{1}{15}\sum_{k=0}^\infty\int_0^1u^{k-\frac{1}{2}}\log^3u du \end{align} Letting $t:=\log u$, then $u=e^t\implies du=e^tdt$, $t(u\rightarrow 0)=-\infty$ and $t(1)=0$. \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\sum_{k=0}^\infty\int_{-\infty}^0 t^3e^{\left(k+\frac{1}{2}\right)t}dt \end{align} Letting $p:=-t$, then $dt=-dp$, $p(t\rightarrow -\infty)=\infty$ and $p(0)=0$. \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\sum_{k=0}^\infty\int_0^\infty p^3e^{-\left(k+\frac{1}{2}\right)p}dp \end{align} Letting $s:=\left(k+\frac{1}{2}\right)p$, then $dp=\frac{ds}{k+\frac{1}{2}}$. The bounds of integration are unchanged, and thus \begin{align} \int_0^\infty\frac{x^3}{e^x-1}dx&=\frac{1}{15}\sum_{k=0}^\infty\frac{1}{\left(k+\frac{1}{2}\right)^4}\int_0^\infty s^3e^{-s}ds\\ &=\frac{\Gamma(4)}{15}\sum_{k=0}^\infty\frac{1}{\left(k+\frac{1}{2}\right)^4}\\ &=\frac{2}{5}\sum_{k=0}^\infty\frac{1}{\left(k+\frac{1}{2}\right)^4} \end{align} EDIT: Apparently, this is simply a convoluted way of deriving the correct answer, as the series evaluates to $\frac{\pi^4}{6}$, making the final expression equal to the known value of $$\int_0^\infty\frac{x^3}{e^x-1}dx = 6\sum_{k=1}^\infty\frac{1}{k^4} = \frac{\pi^4}{15}$$ Many thanks to Simple Art for verifying this result!",,"['integration', 'sequences-and-series', 'definite-integrals', 'riemann-zeta']"
13,Another way of proving :$\int_{0}^{1}{x-x^3+x^5-x^7\over (1+x^4)\ln{x}}dx=-\ln{2}$,Another way of proving :,\int_{0}^{1}{x-x^3+x^5-x^7\over (1+x^4)\ln{x}}dx=-\ln{2},Prove that $$\int_{0}^{1}{x-x^3+x^5-x^7\over (1+x^4)\ln{x}}dx=-\ln{2}$$ My try $x-x^2+x^3+x^5-x^7=x(1-x^2)+x^5(1-x^2)=x(1+x^4)(1-x^2)$ $$\int_{0}^{1}{x(1+x^4)(1-x^2)\over (1+x^4)\ln{x}}dx$$ Applying Frullani theorem $$\int_{0}^{1}{x-x^3\over \ln{x}}dx$$ $$\int_{0}^{1}{x-x^3\over \ln{x}}dx=-\ln{2}$$,Prove that $$\int_{0}^{1}{x-x^3+x^5-x^7\over (1+x^4)\ln{x}}dx=-\ln{2}$$ My try $x-x^2+x^3+x^5-x^7=x(1-x^2)+x^5(1-x^2)=x(1+x^4)(1-x^2)$ $$\int_{0}^{1}{x(1+x^4)(1-x^2)\over (1+x^4)\ln{x}}dx$$ Applying Frullani theorem $$\int_{0}^{1}{x-x^3\over \ln{x}}dx$$ $$\int_{0}^{1}{x-x^3\over \ln{x}}dx=-\ln{2}$$,,"['integration', 'definite-integrals']"
14,Stratonovich integral and chain rule,Stratonovich integral and chain rule,,"From Wiki : if $f:\mathbb{R}\times\mathbb{R} \rightarrow \mathbb{R}$ is a smooth function, then   $$\int\limits_0^T \frac{\partial f}{\partial W}(W_t,t)\circ \mathrm{d}W_t + \int\limits_0^T \frac{\partial f}{\partial t}(W_t,t)\mathrm{d}t = f(W_T,T) - f(W_0,0)$$   which is akin to the chain rule of ordinary calculus. How is that akin to the chain rule? I can't see how that relates to $(f\circ g)' = (f'\circ g)\cdot g'$.","From Wiki : if $f:\mathbb{R}\times\mathbb{R} \rightarrow \mathbb{R}$ is a smooth function, then   $$\int\limits_0^T \frac{\partial f}{\partial W}(W_t,t)\circ \mathrm{d}W_t + \int\limits_0^T \frac{\partial f}{\partial t}(W_t,t)\mathrm{d}t = f(W_T,T) - f(W_0,0)$$   which is akin to the chain rule of ordinary calculus. How is that akin to the chain rule? I can't see how that relates to $(f\circ g)' = (f'\circ g)\cdot g'$.",,"['integration', 'stochastic-integrals', 'chain-rule']"
15,Integral where upper limit is a dot - meaning?,Integral where upper limit is a dot - meaning?,,"Here's what I'm looking at (from this book , page 14): I get that the dot on top of $B$ is the time derivative - but what's that dot near the top of the integral?","Here's what I'm looking at (from this book , page 14): I get that the dot on top of $B$ is the time derivative - but what's that dot near the top of the integral?",,"['integration', 'notation']"
16,"Is there any measure of ""randomly defined"" functions?","Is there any measure of ""randomly defined"" functions?",,"I was wondering about the following: Lets assume that you have a function like $f(x)=x$ and you measure your function by taking an integral from $0$ to $1$, which gives you: $$ \int_{0}^{1} x \; {\rm d}x = \frac{1}{2} $$ Ok, now let's imagine that we randomly reorder in a unique way the function. I mean, once you've reordered it, every input $x \in [0, 1]$ will produce another value randomly from $f([0,1])$, but once this value $f(x)$ has been assigned to $x$, the function has been defined at x , which means that next time you evaluate $f$ at $x$, you will get the same $f(x)$ previously defined. And important: the function is bijective in our case. So let's call our randomly reordered function $f^R$. Here there is a ""summary figure"": So, my intuition says that: The set of points that belong to $f^R$ is dense in $\mathbb{R}^2$ at least for the square depicted in the figure. The integral from $0$ to $1$ should be the same and the are of this function between $0$ and $1$ should be $\frac{1}{2}$. This is not a strong intuition, but a doubt: is $f^R$ continuous? Am I right with my intuition? There exist any measure that allows to measure this set and assign it 1/2? Many thanks in advance!! EDIT: @Shai user has pointed something very disturbing. If we randomly reorder f, we could end up the curve $f^R = (x, x^2)$, so the area below the curve would be less than 1/2. This could be solved saying that we set a random reordered $f^R$ so any point $P \in [0,1]^2$ is an accumulation point of the points $Q = (x, f^R(x)) \in f^R$, which implies that the function is dense in $[0, 1]^2$ (by $[0, 1]^2$ I mean the square depicted in the figure).","I was wondering about the following: Lets assume that you have a function like $f(x)=x$ and you measure your function by taking an integral from $0$ to $1$, which gives you: $$ \int_{0}^{1} x \; {\rm d}x = \frac{1}{2} $$ Ok, now let's imagine that we randomly reorder in a unique way the function. I mean, once you've reordered it, every input $x \in [0, 1]$ will produce another value randomly from $f([0,1])$, but once this value $f(x)$ has been assigned to $x$, the function has been defined at x , which means that next time you evaluate $f$ at $x$, you will get the same $f(x)$ previously defined. And important: the function is bijective in our case. So let's call our randomly reordered function $f^R$. Here there is a ""summary figure"": So, my intuition says that: The set of points that belong to $f^R$ is dense in $\mathbb{R}^2$ at least for the square depicted in the figure. The integral from $0$ to $1$ should be the same and the are of this function between $0$ and $1$ should be $\frac{1}{2}$. This is not a strong intuition, but a doubt: is $f^R$ continuous? Am I right with my intuition? There exist any measure that allows to measure this set and assign it 1/2? Many thanks in advance!! EDIT: @Shai user has pointed something very disturbing. If we randomly reorder f, we could end up the curve $f^R = (x, x^2)$, so the area below the curve would be less than 1/2. This could be solved saying that we set a random reordered $f^R$ so any point $P \in [0,1]^2$ is an accumulation point of the points $Q = (x, f^R(x)) \in f^R$, which implies that the function is dense in $[0, 1]^2$ (by $[0, 1]^2$ I mean the square depicted in the figure).",,"['integration', 'measure-theory', 'continuity', 'lebesgue-integral', 'lebesgue-measure']"
17,Deriving the Normalization formula for Associated Legendre functions: Stage $4$ of $4$,Deriving the Normalization formula for Associated Legendre functions: Stage  of,4 4,"The question that follows is the final stage of the previous $3$ stages found here: Stage 1 , Stage 2 and Stage 3 which are needed as part of a derivation of the Associated Legendre Functions Normalization Formula: $$\color{blue}{\displaystyle\int_{x=-1}^{1}[{P_{L}}^m(x)]^2\,\mathrm{d}x=\left(\frac{2}{2L+1}\right)\frac{(L+m)!}{(L-m)!}}\tag{1}$$ where for each $m$, the functions $${P_L}^m(x)=\frac{1}{2^LL!}\left(1-x^2\right)^{m/2}\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\tag{2}$$ are a set of Associated Legendre functions on $[−1, 1]$. The question in my textbook asks me to Derive $(1)$ as follows: Multiply together the two formulas for ${P_{L}}^m(x)$ given by   $(2)$ and $${P_L}^{m}(x)=(-1)^m\frac{(L+m)!}{(L-m)!}\frac{1}{2^LL!}\left(1-x^2\right)^{-m/2}\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\quad\longleftarrow\text{(Stage 3)}$$ Then integrate by parts repeatedly lowering the $L+m$ derivative and raising the $L−m$ derivative until both are $L$ derivatives. Then use the regular Normalization formula for Legendre Functions: $$\displaystyle\int_{x=-1}^{1}[{P_{L}}(x)]^2\,\mathrm{d}x=\frac{2}{2L+1}\tag{3}$$ where ${P_{L}}(x)$ represents a Legendre function and ${P_{L}}^m(x)$ represents an associated Legendre function. Start of attempt: Multiplying together $(2)$ and the Stage $3$ formula yields: $$[{P_{L}}^m(x)]^2=\frac{(-1)^m}{(2^LL!)^2}\frac{(L+m)!}{(L-m)!}\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\tag{4}$$ Multiplying both sides of $(4)$ by $\mathrm{d}x$ and integrating gives: $$\int[{P_{L}}^m(x)]^2\,\mathrm{d}x=\frac{(-1)^m}{(2^LL!)^2}\frac{(L+m)!}{(L-m)!}\color{red}{\int\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\,\mathrm{d}x}\tag{5}$$ Focusing now on the part marked $\color{red}{\mathrm{red}}$ and integrating by parts: $$\int\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\,\mathrm{d}x$$ $$=\left.\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\right|_{-1}^1-\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x$$ $$=0-\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x$$ End of attempt. I don't know how to take this calculation any further as I have no idea how to evaluate $$\color{#180}{\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x}$$ Could someone please help me reach equation $(1)$ and finally end this derivation of  $$\color{blue}{\displaystyle\int_{x=-1}^{1}[{P_{L}}^m(x)]^2\,\mathrm{d}x=\left(\frac{2}{2L+1}\right)\frac{(L+m)!}{(L-m)!}}\tag{1}$$ EDIT: The Latex didn't render correctly in the description below the bounty; so I type it here instead: One user has already given a detailed answer to this question that uses mathematical induction. The problem is that I am finding it hard to understand this type of proof as it is beyond my current level of understanding. I am looking for an answer that doesn't use mathematical induction. Could someone please explain in simple English (where possible) why $\bbox[yellow]{\displaystyle-\int\dfrac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\dfrac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x} $ $\bbox[yellow]{\displaystyle=(-1)^m\int_{-1}^1\frac{\mathrm{d}^L}{\mathrm{d}x^L}(x^2-1)^{L}\frac{\mathrm{d}^L}{\mathrm{d}x^L}(x^2-1)^L\mathrm{d}x}$ I desperately need to understand this as this forms the final part of a $4$ step proof. Thank you very much.","The question that follows is the final stage of the previous $3$ stages found here: Stage 1 , Stage 2 and Stage 3 which are needed as part of a derivation of the Associated Legendre Functions Normalization Formula: $$\color{blue}{\displaystyle\int_{x=-1}^{1}[{P_{L}}^m(x)]^2\,\mathrm{d}x=\left(\frac{2}{2L+1}\right)\frac{(L+m)!}{(L-m)!}}\tag{1}$$ where for each $m$, the functions $${P_L}^m(x)=\frac{1}{2^LL!}\left(1-x^2\right)^{m/2}\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\tag{2}$$ are a set of Associated Legendre functions on $[−1, 1]$. The question in my textbook asks me to Derive $(1)$ as follows: Multiply together the two formulas for ${P_{L}}^m(x)$ given by   $(2)$ and $${P_L}^{m}(x)=(-1)^m\frac{(L+m)!}{(L-m)!}\frac{1}{2^LL!}\left(1-x^2\right)^{-m/2}\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\quad\longleftarrow\text{(Stage 3)}$$ Then integrate by parts repeatedly lowering the $L+m$ derivative and raising the $L−m$ derivative until both are $L$ derivatives. Then use the regular Normalization formula for Legendre Functions: $$\displaystyle\int_{x=-1}^{1}[{P_{L}}(x)]^2\,\mathrm{d}x=\frac{2}{2L+1}\tag{3}$$ where ${P_{L}}(x)$ represents a Legendre function and ${P_{L}}^m(x)$ represents an associated Legendre function. Start of attempt: Multiplying together $(2)$ and the Stage $3$ formula yields: $$[{P_{L}}^m(x)]^2=\frac{(-1)^m}{(2^LL!)^2}\frac{(L+m)!}{(L-m)!}\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\tag{4}$$ Multiplying both sides of $(4)$ by $\mathrm{d}x$ and integrating gives: $$\int[{P_{L}}^m(x)]^2\,\mathrm{d}x=\frac{(-1)^m}{(2^LL!)^2}\frac{(L+m)!}{(L-m)!}\color{red}{\int\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\,\mathrm{d}x}\tag{5}$$ Focusing now on the part marked $\color{red}{\mathrm{red}}$ and integrating by parts: $$\int\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m}}{\mathrm{d}x^{L+m}}\left(x^2-1\right)^L\,\mathrm{d}x$$ $$=\left.\frac{\mathrm{d}^{L-m}}{\mathrm{d}x^{L-m}}\left(x^2-1\right)^L\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\right|_{-1}^1-\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x$$ $$=0-\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x$$ End of attempt. I don't know how to take this calculation any further as I have no idea how to evaluate $$\color{#180}{\int\frac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\frac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x}$$ Could someone please help me reach equation $(1)$ and finally end this derivation of  $$\color{blue}{\displaystyle\int_{x=-1}^{1}[{P_{L}}^m(x)]^2\,\mathrm{d}x=\left(\frac{2}{2L+1}\right)\frac{(L+m)!}{(L-m)!}}\tag{1}$$ EDIT: The Latex didn't render correctly in the description below the bounty; so I type it here instead: One user has already given a detailed answer to this question that uses mathematical induction. The problem is that I am finding it hard to understand this type of proof as it is beyond my current level of understanding. I am looking for an answer that doesn't use mathematical induction. Could someone please explain in simple English (where possible) why $\bbox[yellow]{\displaystyle-\int\dfrac{\mathrm{d}^{L+m-1}}{\mathrm{d}x^{L+m-1}}\left(x^2-1\right)^L\,\dfrac{\mathrm{d}^{L-m+1}}{\mathrm{d}x^{L-m+1}}\left(x^2-1\right)^{L}\mathrm{d}x} $ $\bbox[yellow]{\displaystyle=(-1)^m\int_{-1}^1\frac{\mathrm{d}^L}{\mathrm{d}x^L}(x^2-1)^{L}\frac{\mathrm{d}^L}{\mathrm{d}x^L}(x^2-1)^L\mathrm{d}x}$ I desperately need to understand this as this forms the final part of a $4$ step proof. Thank you very much.",,"['integration', 'special-functions', 'orthogonal-polynomials', 'legendre-polynomials', 'integration-by-parts']"
18,Is the algebra of universally integrable functions a von Neumann algebra?,Is the algebra of universally integrable functions a von Neumann algebra?,,"I would like to continue this discussion . Let $X$ be a compact space. Let us call a function $f:X\to {\mathbb C}$ universally integrable if it is integrable with respect to each regular Borel measure $\mu$ on $X$ (one can imagine $\mu$ as an arbitrary positive continuous functional on ${\mathcal C}(X)$ ). We denote by ${\mathcal U}(X)$ the space of all universally integrable functions on $X$. Nate Eldredge noticed here , that ${\mathcal U}(X)$ is a $C^*$-algebra with respect to the sup-norm: $$ ||f||=\sup_{x\in X}|f(x)|. $$  Question: Is ${\mathcal U}(X)$ a von Neumann algebra with respect to this norm?","I would like to continue this discussion . Let $X$ be a compact space. Let us call a function $f:X\to {\mathbb C}$ universally integrable if it is integrable with respect to each regular Borel measure $\mu$ on $X$ (one can imagine $\mu$ as an arbitrary positive continuous functional on ${\mathcal C}(X)$ ). We denote by ${\mathcal U}(X)$ the space of all universally integrable functions on $X$. Nate Eldredge noticed here , that ${\mathcal U}(X)$ is a $C^*$-algebra with respect to the sup-norm: $$ ||f||=\sup_{x\in X}|f(x)|. $$  Question: Is ${\mathcal U}(X)$ a von Neumann algebra with respect to this norm?",,"['integration', 'functional-analysis', 'c-star-algebras', 'von-neumann-algebras']"
19,From convergence in $L^2$ to convergence of the squares in $L^1$,From convergence in  to convergence of the squares in,L^2 L^1,"Given a function $f\in L^2(X,\mu)$ for some measure space $(X,\mu)$, we of course have that $|f|^2$ is a positive function in $L^1(X,\mu)$. I now came across the following. Suppose $\int_X |f_n(x)-g_n(x)|^2 d\mu(x)\rightarrow 0$ for sequences $f_n,g_n\in L^2$, then we also have $\int_X \big| \,|f_n(x)|^2-|g_n(x)|^2\big| d\mu(x)\rightarrow 0$. Can anybody give an idea on how to prove this? Edit: We also assume the sequences are bounded.","Given a function $f\in L^2(X,\mu)$ for some measure space $(X,\mu)$, we of course have that $|f|^2$ is a positive function in $L^1(X,\mu)$. I now came across the following. Suppose $\int_X |f_n(x)-g_n(x)|^2 d\mu(x)\rightarrow 0$ for sequences $f_n,g_n\in L^2$, then we also have $\int_X \big| \,|f_n(x)|^2-|g_n(x)|^2\big| d\mu(x)\rightarrow 0$. Can anybody give an idea on how to prove this? Edit: We also assume the sequences are bounded.",,"['real-analysis', 'integration', 'measure-theory', 'lp-spaces']"
20,Methods for Integrating $\int \frac{\cos(x)}{\sin^2(x) +\sin(x)}dx$,Methods for Integrating,\int \frac{\cos(x)}{\sin^2(x) +\sin(x)}dx,"So I've found that there's the Weierstrass Substitution that can be used on this problem but I just want to check I can use a normal substitution method to solve the equation: $$\int \frac{\cos(x)}{\sin^2(x) +\sin (x)}dx$$ Let $u = \sin(x)$ $du = \cos(x)\, dx$ $dx = \frac {1}{\cos(x)\,} du$ Which becomes: $$\int \frac{\cos(x)}{u^2 + u} \frac{1}{\cos(x)}du$$ $$\int \frac{1}{u^2 + u}du$$ Factor out u from denominator: $$\int \frac{1}{u(u + 1)}du$$ Integrate as a partial fraction: $$\int \frac{1}{u} - \frac{1}{(u + 1)}du$$ Which integrates as: $$\ln|u| - \ln|(u + 1)| + C$$ Subtitute $u = \sin(x)$ back in and simplifies to: $$\ln \left|\frac{\sin(x)}{\sin(x)+1} \right| + C$$ Is this correct? From the Weierstrass Substitution, one gets: $$\ln \left|\tan \left(\frac{x}{2}\right)\right|-2\ln \left|\tan \left(\frac{x}{2}\right)+1\right| +C $$","So I've found that there's the Weierstrass Substitution that can be used on this problem but I just want to check I can use a normal substitution method to solve the equation: $$\int \frac{\cos(x)}{\sin^2(x) +\sin (x)}dx$$ Let $u = \sin(x)$ $du = \cos(x)\, dx$ $dx = \frac {1}{\cos(x)\,} du$ Which becomes: $$\int \frac{\cos(x)}{u^2 + u} \frac{1}{\cos(x)}du$$ $$\int \frac{1}{u^2 + u}du$$ Factor out u from denominator: $$\int \frac{1}{u(u + 1)}du$$ Integrate as a partial fraction: $$\int \frac{1}{u} - \frac{1}{(u + 1)}du$$ Which integrates as: $$\ln|u| - \ln|(u + 1)| + C$$ Subtitute $u = \sin(x)$ back in and simplifies to: $$\ln \left|\frac{\sin(x)}{\sin(x)+1} \right| + C$$ Is this correct? From the Weierstrass Substitution, one gets: $$\ln \left|\tan \left(\frac{x}{2}\right)\right|-2\ln \left|\tan \left(\frac{x}{2}\right)+1\right| +C $$",,"['calculus', 'integration', 'trigonometry', 'substitution']"
21,"Riemann integral of $ f(x) = \begin{cases} \frac{1}{n}, & \text{if $x=\frac{1}{n}, \ \ n=1, 2,3 ,\cdots$ } \\ 0, & \text{other where} \end{cases}$","Riemann integral of x=\frac{1}{n}, \ \ n=1, 2,3 ,\cdots"," f(x) = \begin{cases} \frac{1}{n}, & \text{if   } \\ 0, & \text{other where} \end{cases}","Let $f:[0, 1]\to\mathbb{R}$ and $  f(x) = \begin{cases} \frac{1}{n},  & \text{if $x=\frac{1}{n}, \  \ n=1, 2,3 ,\cdots$ } \\ 0, & \text{other where} \end{cases}$ I want to find $\int_{0}^{1} f\, dx.$ I think the answer is $0$. Any ideas or insight would be greatly appreciated","Let $f:[0, 1]\to\mathbb{R}$ and $  f(x) = \begin{cases} \frac{1}{n},  & \text{if $x=\frac{1}{n}, \  \ n=1, 2,3 ,\cdots$ } \\ 0, & \text{other where} \end{cases}$ I want to find $\int_{0}^{1} f\, dx.$ I think the answer is $0$. Any ideas or insight would be greatly appreciated",,"['real-analysis', 'integration']"
22,"Integral of combination of power, exponential, and confluent hypergeometric function","Integral of combination of power, exponential, and confluent hypergeometric function",,"I am trying to solve a couple integrals of the form: \begin{equation} I(g)=\int_{0}^{\infty} x \, e^{-a(gx-b)^{2}}\,e^{-\beta_{1}x}\, {_{1}}F_{1}(-\alpha_{1};-\alpha_{3};\beta_{3} x) \ \mathrm{d}x \end{equation} where, $a>0$, $g\in\mathbb{R}$, $b\in\mathbb{R}$, $0<\beta_{1}<\beta_{3}$, and $0<\alpha_{1}<\alpha_{3}$. $\alpha_{1}$, and $\alpha_{3}$ are either integers or of the form $\frac{2n+1}{2}$ where $n=0,1,2,\dots$ The shifting of the quadratic in the first exponential term is really giving me issues.  Any thoughts on how to approach this? Update 08/16/16 I posted a solution to the question for $\alpha_{1}\in \mathbb{Z}^{+}$.  If anyone can find a closed-form solution for the integral when $\alpha_{1}$ is not an integer, I will accept that answer instead.","I am trying to solve a couple integrals of the form: \begin{equation} I(g)=\int_{0}^{\infty} x \, e^{-a(gx-b)^{2}}\,e^{-\beta_{1}x}\, {_{1}}F_{1}(-\alpha_{1};-\alpha_{3};\beta_{3} x) \ \mathrm{d}x \end{equation} where, $a>0$, $g\in\mathbb{R}$, $b\in\mathbb{R}$, $0<\beta_{1}<\beta_{3}$, and $0<\alpha_{1}<\alpha_{3}$. $\alpha_{1}$, and $\alpha_{3}$ are either integers or of the form $\frac{2n+1}{2}$ where $n=0,1,2,\dots$ The shifting of the quadratic in the first exponential term is really giving me issues.  Any thoughts on how to approach this? Update 08/16/16 I posted a solution to the question for $\alpha_{1}\in \mathbb{Z}^{+}$.  If anyone can find a closed-form solution for the integral when $\alpha_{1}$ is not an integer, I will accept that answer instead.",,"['integration', 'sequences-and-series', 'power-series', 'special-functions', 'hypergeometric-function']"
23,Integrating sine with Monte Carlo / Metropolis algorithm,Integrating sine with Monte Carlo / Metropolis algorithm,,"I'm learning Monte Carlo / Metropolis algorithm, so I made up a simple question and write some code to see if I really understand it. The question is simple: integrating sine over 0 to PI. The integral can be calculated analytically. If my code is correct, the integral should be 2. According to Monte Carlo, we can approximate an integral with N samples: $$ \int _{a}^{b} f(x)dx \approx \frac {1}{N} \sum _{i=1}^{N} \frac {f(X_i)}{p(X_i)} $$ where in my sine integral case: $$ f(x) = sin(x)\\ a = 0\\ b = \pi\\ $$ I'm using uniform distribution to sample $X \in [0, \pi]$, so $$ p(x) = \frac {1}{\pi} $$ Metropolis algorithm also requires an ""acceptance probability"", which is the probability that whether we should accept a transition from the current location $X$ to a new location $X'$. The acceptance probability is defined as: $$ a(X, X') = min(1, \frac {f(X')}{f(X)}) $$ My code is at http://bl.ocks.org/eliangcs/6e8b45f88fd3767363e7 . Every time you refresh your browser, it makes 100 samples and shows the integral solution. But it always seems to give me a way larger value ($\approx 2.5$) instead of the correct solution: 2. Why? I guess I made a mistake on the PDF $p(x) = 1/\pi$, which does not consider the acceptance probability $a(X, X')$. If that is the case, how should I adjust $p(x)$ then?","I'm learning Monte Carlo / Metropolis algorithm, so I made up a simple question and write some code to see if I really understand it. The question is simple: integrating sine over 0 to PI. The integral can be calculated analytically. If my code is correct, the integral should be 2. According to Monte Carlo, we can approximate an integral with N samples: $$ \int _{a}^{b} f(x)dx \approx \frac {1}{N} \sum _{i=1}^{N} \frac {f(X_i)}{p(X_i)} $$ where in my sine integral case: $$ f(x) = sin(x)\\ a = 0\\ b = \pi\\ $$ I'm using uniform distribution to sample $X \in [0, \pi]$, so $$ p(x) = \frac {1}{\pi} $$ Metropolis algorithm also requires an ""acceptance probability"", which is the probability that whether we should accept a transition from the current location $X$ to a new location $X'$. The acceptance probability is defined as: $$ a(X, X') = min(1, \frac {f(X')}{f(X)}) $$ My code is at http://bl.ocks.org/eliangcs/6e8b45f88fd3767363e7 . Every time you refresh your browser, it makes 100 samples and shows the integral solution. But it always seems to give me a way larger value ($\approx 2.5$) instead of the correct solution: 2. Why? I guess I made a mistake on the PDF $p(x) = 1/\pi$, which does not consider the acceptance probability $a(X, X')$. If that is the case, how should I adjust $p(x)$ then?",,"['integration', 'probability-distributions', 'algorithms', 'numerical-methods', 'monte-carlo']"
24,Integral of an unbounded function as a solution of $\nabla^2\boldsymbol{A}=-\mu_0\boldsymbol{J}$,Integral of an unbounded function as a solution of,\nabla^2\boldsymbol{A}=-\mu_0\boldsymbol{J},"While studying the equivalence between the Biot-Savart and Ampère's laws I have only found proofs of the fact that$$\boldsymbol{A}(\boldsymbol{x})=\frac{\mu_0}{4\pi}\int_V \frac{\boldsymbol{J}(\boldsymbol{x}')}{\|\boldsymbol{x}-\boldsymbol{x}'\|}d^3 x'$$ is a solution of $\nabla^2\boldsymbol{A}=-\mu_0\boldsymbol{J}$, where $\mu_0$ is a constant (magnetic permeability in that physical case), using Dirac's delta, which use in the tridimensional case I have not studied yet. I have calculated - please correct me if I am wrong - that, if $V\subset\mathbb{R}^3$ is compact (as usually assumed in physics, I think), which allows us to differentiate under the integral sign, and $\boldsymbol{x}\notin V$, which allows the integral to exist finite if we are considering a Riemann integral, $\nabla^2\boldsymbol{A}=\mathbf{0}$. Although my first tought was that it is not possible to prove that $\frac{\mu_0}{4\pi}\int_V \frac{\boldsymbol{J}(\boldsymbol{x}')}{\|\boldsymbol{x}-\boldsymbol{x}'\|}d^3 x'$ is a solution of $\nabla^2\boldsymbol{A}=\mathbf{0}$ only by using the tools of multivariate calculus, without using Dirac's $\delta$, while considering the integral as a ""Riemann integral"", in the sense of a limit (since if $\boldsymbol{x}\in V$ it cannot obviously be a Riemann integral proper), I have been told in PSE that it may well be possible and suggested to ask here how to prove it. I heartily thank any answerer!","While studying the equivalence between the Biot-Savart and Ampère's laws I have only found proofs of the fact that$$\boldsymbol{A}(\boldsymbol{x})=\frac{\mu_0}{4\pi}\int_V \frac{\boldsymbol{J}(\boldsymbol{x}')}{\|\boldsymbol{x}-\boldsymbol{x}'\|}d^3 x'$$ is a solution of $\nabla^2\boldsymbol{A}=-\mu_0\boldsymbol{J}$, where $\mu_0$ is a constant (magnetic permeability in that physical case), using Dirac's delta, which use in the tridimensional case I have not studied yet. I have calculated - please correct me if I am wrong - that, if $V\subset\mathbb{R}^3$ is compact (as usually assumed in physics, I think), which allows us to differentiate under the integral sign, and $\boldsymbol{x}\notin V$, which allows the integral to exist finite if we are considering a Riemann integral, $\nabla^2\boldsymbol{A}=\mathbf{0}$. Although my first tought was that it is not possible to prove that $\frac{\mu_0}{4\pi}\int_V \frac{\boldsymbol{J}(\boldsymbol{x}')}{\|\boldsymbol{x}-\boldsymbol{x}'\|}d^3 x'$ is a solution of $\nabla^2\boldsymbol{A}=\mathbf{0}$ only by using the tools of multivariate calculus, without using Dirac's $\delta$, while considering the integral as a ""Riemann integral"", in the sense of a limit (since if $\boldsymbol{x}\in V$ it cannot obviously be a Riemann integral proper), I have been told in PSE that it may well be possible and suggested to ask here how to prove it. I heartily thank any answerer!",,"['integration', 'multivariable-calculus', 'physics']"
25,Definite integrals that are hard using the FTC but doable from first principles,Definite integrals that are hard using the FTC but doable from first principles,,"When I was introduced to integration, I was briefly exposed to the definition of a Riemann sum, and as an illustration we worked out a couple of definite integrals directly from this definition: $$ \int\limits_a^b f\left(x\right)\,dx = \lim_{n\rightarrow\infty} \sum\limits_{k=0}^{n} f\left(x_k\right) \Delta x, \qquad \Delta x = \frac{b-a}{n}, \qquad x_k = a + k\Delta x $$ These turned out to be fairly tedious, and I was quickly shown that the Fundamental Theorem of Calculus (FTC) provides a much more convenient way of doing things. I am wondering if there are any examples of definite integrals that are hard to evaluate using the FTC because the antiderivative of $f(x)$ is hard to find, yet are amenable to being worked out directly from the definition.","When I was introduced to integration, I was briefly exposed to the definition of a Riemann sum, and as an illustration we worked out a couple of definite integrals directly from this definition: $$ \int\limits_a^b f\left(x\right)\,dx = \lim_{n\rightarrow\infty} \sum\limits_{k=0}^{n} f\left(x_k\right) \Delta x, \qquad \Delta x = \frac{b-a}{n}, \qquad x_k = a + k\Delta x $$ These turned out to be fairly tedious, and I was quickly shown that the Fundamental Theorem of Calculus (FTC) provides a much more convenient way of doing things. I am wondering if there are any examples of definite integrals that are hard to evaluate using the FTC because the antiderivative of $f(x)$ is hard to find, yet are amenable to being worked out directly from the definition.",,"['calculus', 'integration', 'definite-integrals', 'soft-question', 'examples-counterexamples']"
26,"The value of double integral $\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dx\,dy$?",The value of double integral ?,"\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dx\,dy","Given double integral is : $$\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dx\,dy$$ My attempt : We can't solve since variable $x$ can't remove by limits, but if we change order of integration, then $$\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dy\,dx$$ $$\implies\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dy\,dx = \frac{1}{2}$$ Can you explain in formal way, please? Edit : This question was from competitive exam GATE. The link is given below on comments by Alex M. and Martin Sleziak(Thanks).","Given double integral is : $$\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dx\,dy$$ My attempt : We can't solve since variable $x$ can't remove by limits, but if we change order of integration, then $$\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dy\,dx$$ $$\implies\int _0^1\int _0^{\frac{1}{x}}\frac{x}{1+y^2}\:dy\,dx = \frac{1}{2}$$ Can you explain in formal way, please? Edit : This question was from competitive exam GATE. The link is given below on comments by Alex M. and Martin Sleziak(Thanks).",,"['calculus', 'integration', 'multivariable-calculus']"
27,"Prove that $\int_0^1 f(x)dx=0$ if $f(\frac{1}{n})=1$ for $n=1,2,3,\ldots$ and $f(x)=0$ for all other $x$",Prove that  if  for  and  for all other,"\int_0^1 f(x)dx=0 f(\frac{1}{n})=1 n=1,2,3,\ldots f(x)=0 x","Prove that $\int_0^1 f(x)dx=0$ if $f(\frac{1}{n})=1$ for   $n=1,2,3,\ldots$ and $f(x)=0$ for all other $x$. Lemma: If $f:[a,b]\rightarrow \mathbb{R}$ is a function such that $f(x)=\mathbb{1}_{\{c\}}$ for some $a<c<b$, then $\int_a^b f(x)dx=0$. Proof of the lemma: Consider a partition of $[a,b]$ such that its width is less than $\delta>0$. Then the absolute value of Riemann sum corresponding to this partition is less than $2 \delta $. So for any $\epsilon>0$ we can choose $\delta=\frac{\epsilon}{2}$ and we will have $|S|<\epsilon$ whenever $S$ is a Riemann sum corresponding to a partition of width less than $\delta$. Proof of the main result: Choose $\epsilon>0$. From the above lemma and linearity of the Riemann integral, we know that $$\int_{\epsilon/2}^1f(x)dx=0 \mbox{.}$$ Thus there is a step function $g:[\frac{\epsilon}{2},1]\rightarrow \mathbb{R}$ such that $0\le f(x)\le g(x)$ for all $x\in[\frac{\epsilon}{2},1]$ and $$ \int_{\epsilon/2}^1 g(x)dx <\epsilon /2 \mbox{.}$$ Define a new step function $h:[0,1]\rightarrow \mathbb{R}$ such that $h(x)=g(x)$ if $x\in  [\frac{\epsilon}{2},1]$ and $h(x)=1$ if $x\in [0,\frac{\epsilon}{2})$. It is clear that for all $x\in [0,1]$ we have $$0\le f(x) \le h(x) \mbox{.}$$ Also $$ \int_{0}^1 h(x)dx = \int_{0}^{\epsilon/2} dx  + \int_{\epsilon/2}^1 g(x)dx <\epsilon /2+ \epsilon /2 =\epsilon \mbox{.}$$ Thus we proved that $f$ is integrable. It remains to show that the integral $\int_0^1 f(x)dx$ is equal to $0$. We know that $\int_0^1 f(x)dx$ exists and however small $\alpha$ we choose, the integral $\int_{\alpha}^1 f(x)dx$ also exists and is equal to $0$. The result follows from continuity of the integral. I would be very grateful if somebody verified my proof, I'm quite not sure about the very last part. Thank you.","Prove that $\int_0^1 f(x)dx=0$ if $f(\frac{1}{n})=1$ for   $n=1,2,3,\ldots$ and $f(x)=0$ for all other $x$. Lemma: If $f:[a,b]\rightarrow \mathbb{R}$ is a function such that $f(x)=\mathbb{1}_{\{c\}}$ for some $a<c<b$, then $\int_a^b f(x)dx=0$. Proof of the lemma: Consider a partition of $[a,b]$ such that its width is less than $\delta>0$. Then the absolute value of Riemann sum corresponding to this partition is less than $2 \delta $. So for any $\epsilon>0$ we can choose $\delta=\frac{\epsilon}{2}$ and we will have $|S|<\epsilon$ whenever $S$ is a Riemann sum corresponding to a partition of width less than $\delta$. Proof of the main result: Choose $\epsilon>0$. From the above lemma and linearity of the Riemann integral, we know that $$\int_{\epsilon/2}^1f(x)dx=0 \mbox{.}$$ Thus there is a step function $g:[\frac{\epsilon}{2},1]\rightarrow \mathbb{R}$ such that $0\le f(x)\le g(x)$ for all $x\in[\frac{\epsilon}{2},1]$ and $$ \int_{\epsilon/2}^1 g(x)dx <\epsilon /2 \mbox{.}$$ Define a new step function $h:[0,1]\rightarrow \mathbb{R}$ such that $h(x)=g(x)$ if $x\in  [\frac{\epsilon}{2},1]$ and $h(x)=1$ if $x\in [0,\frac{\epsilon}{2})$. It is clear that for all $x\in [0,1]$ we have $$0\le f(x) \le h(x) \mbox{.}$$ Also $$ \int_{0}^1 h(x)dx = \int_{0}^{\epsilon/2} dx  + \int_{\epsilon/2}^1 g(x)dx <\epsilon /2+ \epsilon /2 =\epsilon \mbox{.}$$ Thus we proved that $f$ is integrable. It remains to show that the integral $\int_0^1 f(x)dx$ is equal to $0$. We know that $\int_0^1 f(x)dx$ exists and however small $\alpha$ we choose, the integral $\int_{\alpha}^1 f(x)dx$ also exists and is equal to $0$. The result follows from continuity of the integral. I would be very grateful if somebody verified my proof, I'm quite not sure about the very last part. Thank you.",,"['calculus', 'real-analysis', 'integration', 'proof-verification']"
28,How to prove $\frac{n^n}{3n!}<\frac{e^n}{2}-\sum_{k=0}^{n-1}\frac{n^k}{k!}<\frac{n^n}{2n!}$,How to prove,\frac{n^n}{3n!}<\frac{e^n}{2}-\sum_{k=0}^{n-1}\frac{n^k}{k!}<\frac{n^n}{2n!},I met this problem: prove: $\displaystyle \frac{n^n}{3n!}<\frac{e^n}{2}-\sum_{k=0}^{n-1}\frac{n^k}{k!}<\frac{n^n}{2n!}$ I tried expand $e^n$ at $x=0$ then: $\displaystyle e^n=\sum_{k=0}^{n}\frac{n^k}{k!}+\frac1{n!}\int_0^ne^t(n-t)^ndt$ but I have no idea next... And another way of thinking:both side divided $e^n$ the LHS became $\displaystyle \frac{n^n}{3n!e^n}$ then can we use the stirling's fomula to find sth.? Could someone help me? Thanks!,I met this problem: prove: $\displaystyle \frac{n^n}{3n!}<\frac{e^n}{2}-\sum_{k=0}^{n-1}\frac{n^k}{k!}<\frac{n^n}{2n!}$ I tried expand $e^n$ at $x=0$ then: $\displaystyle e^n=\sum_{k=0}^{n}\frac{n^k}{k!}+\frac1{n!}\int_0^ne^t(n-t)^ndt$ but I have no idea next... And another way of thinking:both side divided $e^n$ the LHS became $\displaystyle \frac{n^n}{3n!e^n}$ then can we use the stirling's fomula to find sth.? Could someone help me? Thanks!,,"['integration', 'analysis', 'limits', 'inequality', 'power-series']"
29,Vector valued integral in spherical coordinates,Vector valued integral in spherical coordinates,,"Whenever I have been presented with integrals as (*), I have always used some sort of symmetry to get around actually calculating the integral. Now it just struck me that I have no idea how to ""mechanically"" calculate (*): $$ \iiint \left(f(r)\hat{r}\right)\left(r^2\sin\phi\right) drd\phi d\theta \qquad \textbf{(*)} $$ If it is necessary to define what region you are talking about for the question to make sense, I'll pick the unit sphere. Would this have been the integral  $$ \int f(x)\hat{x} dx $$ I would have proceeded by moving the unit vector outside of the integral and calculated as usual $$ \hat{x}\int f(x)\cdot dx = \hat{x}\left(F(x) +C\right) $$ However, the problem with the integral is that the direction of $\hat{r}$ changes as $\phi$ and $\theta$ changes. Therefore I don't see how I could treat the unit vector as a constant and have no idea how to start with (*). I apologize in  advance if this turns out to be a duplicate. How to integrate a vector function in spherical coordinates? verifies my gut feeling that $\hat{r}$ is not constant but doesn't make things much clearer for me than that.","Whenever I have been presented with integrals as (*), I have always used some sort of symmetry to get around actually calculating the integral. Now it just struck me that I have no idea how to ""mechanically"" calculate (*): $$ \iiint \left(f(r)\hat{r}\right)\left(r^2\sin\phi\right) drd\phi d\theta \qquad \textbf{(*)} $$ If it is necessary to define what region you are talking about for the question to make sense, I'll pick the unit sphere. Would this have been the integral  $$ \int f(x)\hat{x} dx $$ I would have proceeded by moving the unit vector outside of the integral and calculated as usual $$ \hat{x}\int f(x)\cdot dx = \hat{x}\left(F(x) +C\right) $$ However, the problem with the integral is that the direction of $\hat{r}$ changes as $\phi$ and $\theta$ changes. Therefore I don't see how I could treat the unit vector as a constant and have no idea how to start with (*). I apologize in  advance if this turns out to be a duplicate. How to integrate a vector function in spherical coordinates? verifies my gut feeling that $\hat{r}$ is not constant but doesn't make things much clearer for me than that.",,"['integration', 'vector-analysis']"
30,Solve integral using Plancherel's formula,Solve integral using Plancherel's formula,,"This is from a test in Fourier analysis: Define $$ f(\xi)=\int_0^1 \sqrt{x}\rm{sin}(\xi x) \rm{d}x $$ Calculate   $$ \int_{-\infty}^\infty |f(x)|^2 \rm{d}x $$ I started with Plancherel's formula, i.e. $$ \int_{-\infty}^\infty |f(x)|^2 \rm{d}x = \frac{1}{2\pi}\int_{-\infty}^\infty |f(\xi)|^2 \rm{d}\xi $$ but what now? Am I supposed to compute the integral of $f(\xi)$ somehow or what should I do?","This is from a test in Fourier analysis: Define $$ f(\xi)=\int_0^1 \sqrt{x}\rm{sin}(\xi x) \rm{d}x $$ Calculate   $$ \int_{-\infty}^\infty |f(x)|^2 \rm{d}x $$ I started with Plancherel's formula, i.e. $$ \int_{-\infty}^\infty |f(x)|^2 \rm{d}x = \frac{1}{2\pi}\int_{-\infty}^\infty |f(\xi)|^2 \rm{d}\xi $$ but what now? Am I supposed to compute the integral of $f(\xi)$ somehow or what should I do?",,['calculus']
31,Gauss Hermite Integration of 1/(1+x^2),Gauss Hermite Integration of 1/(1+x^2),,"I'm trying to learn Gauss Hermite Integration and was manually try to calculate the value of integral of $\frac{1}{1+x^2}$ from $-\infty$ to $+\infty$ The exact answer is simply $\pi$ ($\approx$ 3.14). But I keep getting answers that are a bit far off even with 5 nodes. Below are my calculations, could somebody please point anything obviously wrong or may be the method is more accurate for certain kind of functions. Edit: even with 100 nodes, I only got as close as 2.93. I got weights from - http://www.efunda.com/math/num_integration/findgausshermite.cfm","I'm trying to learn Gauss Hermite Integration and was manually try to calculate the value of integral of $\frac{1}{1+x^2}$ from $-\infty$ to $+\infty$ The exact answer is simply $\pi$ ($\approx$ 3.14). But I keep getting answers that are a bit far off even with 5 nodes. Below are my calculations, could somebody please point anything obviously wrong or may be the method is more accurate for certain kind of functions. Edit: even with 100 nodes, I only got as close as 2.93. I got weights from - http://www.efunda.com/math/num_integration/findgausshermite.cfm",,"['integration', 'numerical-methods']"
32,$\int_{-\infty}^{\infty}e^{-\pi x^2}\cdot e^{-2\pi ix\xi}dx = e^{\pi\xi^2}$,,\int_{-\infty}^{\infty}e^{-\pi x^2}\cdot e^{-2\pi ix\xi}dx = e^{\pi\xi^2},"Prove that for all $\xi \in \mathbb{C}$, $$\int_{-\infty}^{\infty}e^{-\pi x^2}\cdot e^{-2\pi ix\xi}dx = e^{\pi\xi^2}$$ I don't really know how to compute this integral. Can you please help me?","Prove that for all $\xi \in \mathbb{C}$, $$\int_{-\infty}^{\infty}e^{-\pi x^2}\cdot e^{-2\pi ix\xi}dx = e^{\pi\xi^2}$$ I don't really know how to compute this integral. Can you please help me?",,"['integration', 'complex-analysis', 'analysis']"
33,"Let $f : [0,1] \to \mathbb{R}$, prove that $2 \int_{0}^{1} f(x)dx \ge f\Big(\frac{1}{n}\Big) + \sum_{k=1}^{n-1}\frac{1}{k} f\Big(\frac{k}{n}\Big)$","Let , prove that","f : [0,1] \to \mathbb{R} 2 \int_{0}^{1} f(x)dx \ge f\Big(\frac{1}{n}\Big) + \sum_{k=1}^{n-1}\frac{1}{k} f\Big(\frac{k}{n}\Big)","Let $f : [0,1] \to \mathbb{R}$ be a differentiable function with a continuous derivative such that $f(x) \ge xf'(x), \forall x \in [0,1]$. Prove that: $$2 \int_{0}^{1} f(x)dx \ge f\Big(\frac{1}{n}\Big) + \sum_{k=1}^{n-1}\frac{1}{k} f\Big(\frac{k}{n}\Big)$$, $\forall n \in \mathbb{N}, n \ge 2$ $\mathbf{Edit}$: Like Elaqqad and Crostul pointed out, there may be a typo in the inequality. What if we have: $$2 \int_{0}^{1}f(x)dx \ge f\Big(\frac{1}{n}\Big) + \sum_{k=1}^{n-1}\frac{1}{n} f\Big(\frac{k}{n}\Big)  ?$$ Will this inequality stand?","Let $f : [0,1] \to \mathbb{R}$ be a differentiable function with a continuous derivative such that $f(x) \ge xf'(x), \forall x \in [0,1]$. Prove that: $$2 \int_{0}^{1} f(x)dx \ge f\Big(\frac{1}{n}\Big) + \sum_{k=1}^{n-1}\frac{1}{k} f\Big(\frac{k}{n}\Big)$$, $\forall n \in \mathbb{N}, n \ge 2$ $\mathbf{Edit}$: Like Elaqqad and Crostul pointed out, there may be a typo in the inequality. What if we have: $$2 \int_{0}^{1}f(x)dx \ge f\Big(\frac{1}{n}\Big) + \sum_{k=1}^{n-1}\frac{1}{n} f\Big(\frac{k}{n}\Big)  ?$$ Will this inequality stand?",,"['calculus', 'integration', 'inequality', 'contest-math']"
34,Fourier Uniqueness Theorem: Proof?,Fourier Uniqueness Theorem: Proof?,,I need this as lemma. Given the Borel space $\mathcal{B}(\mathbb{R})$. Consider a complex measure: $$\mu:\mathcal{B}(\mathbb{R})\to\mathbb{C}$$ Then one has: $$\int_{-\infty}^{+\infty}e^{it\lambda}\mathrm{d}\mu(\lambda)=0\implies\mu=0$$ How can I prove this?,I need this as lemma. Given the Borel space $\mathcal{B}(\mathbb{R})$. Consider a complex measure: $$\mu:\mathcal{B}(\mathbb{R})\to\mathbb{C}$$ Then one has: $$\int_{-\infty}^{+\infty}e^{it\lambda}\mathrm{d}\mu(\lambda)=0\implies\mu=0$$ How can I prove this?,,"['real-analysis', 'integration', 'measure-theory', 'harmonic-analysis']"
35,Infinite integrals$\int_0^{ + \infty } {\frac{1}{{\left( {x + 1} \right)\left( {{x^n} + 1} \right)}}dx} .$,Infinite integrals,\int_0^{ + \infty } {\frac{1}{{\left( {x + 1} \right)\left( {{x^n} + 1} \right)}}dx} .,How to calculate $$\int_0^{ + \infty } {\frac{1}{{\left( {x + 1} \right)\left( {{x^n} + 1} \right)}}dx} .$$,How to calculate $$\int_0^{ + \infty } {\frac{1}{{\left( {x + 1} \right)\left( {{x^n} + 1} \right)}}dx} .$$,,"['calculus', 'integration', 'analysis']"
36,How to do it by Dominated Conversgence Theorem?,How to do it by Dominated Conversgence Theorem?,,"I'm trying to find the limit $$ I = \lim_{n\to\infty} \int_{\mathbb R^d} \frac1{n} |f(x)|^2 x\cdot\nabla\chi (x/n)dx, $$ where $f \in H^1 (\mathbb R^d, \mathbb C)$, $f \in H^2_{loc}(\mathbb R^d, \mathbb C)$ and $f \in L^\infty (\mathbb R^d, \mathbb C)$, the test function $\chi \in \mathrm C_c^\infty (\mathbb R^d, \mathbb R) $ such that $0\le \chi\le 1$ on $\mathbb R^d$, $\chi = 1$ on $B(0,1)$ and $\chi=0$ outside $B(0,2)$. I hope to prove that $I=0$ by Dominated Convergence Theorem, but I don't know how to determine a dominator. Could someone give me a hint? Edit: Thank to Nate Eldredge's comment, it seems not true without the assumptions $f \in L^\infty (\mathbb R^d, \mathbb C)$ and $f \in H^1 (\mathbb R^d, \mathbb C)$.","I'm trying to find the limit $$ I = \lim_{n\to\infty} \int_{\mathbb R^d} \frac1{n} |f(x)|^2 x\cdot\nabla\chi (x/n)dx, $$ where $f \in H^1 (\mathbb R^d, \mathbb C)$, $f \in H^2_{loc}(\mathbb R^d, \mathbb C)$ and $f \in L^\infty (\mathbb R^d, \mathbb C)$, the test function $\chi \in \mathrm C_c^\infty (\mathbb R^d, \mathbb R) $ such that $0\le \chi\le 1$ on $\mathbb R^d$, $\chi = 1$ on $B(0,1)$ and $\chi=0$ outside $B(0,2)$. I hope to prove that $I=0$ by Dominated Convergence Theorem, but I don't know how to determine a dominator. Could someone give me a hint? Edit: Thank to Nate Eldredge's comment, it seems not true without the assumptions $f \in L^\infty (\mathbb R^d, \mathbb C)$ and $f \in H^1 (\mathbb R^d, \mathbb C)$.",,"['integration', 'functional-analysis']"
37,Improper integral Riemann sum limit in the derivation of Fourier series to Fourier transform,Improper integral Riemann sum limit in the derivation of Fourier series to Fourier transform,,"To give background to my question, in all the books I've looked at to derive the inverse Fourier transform of a continuous function $f$ on $\mathbb{R}$, they seem to work as follows. Let $k$ be a positive real number and write (by standard Fourier series theory) $$ f(x) = \sum_{n=-\infty}^\infty c_n \, e^{i n \pi x/k}\ , $$ where $$ c_n = \frac{1}{2k} \int_{-k}^k f(y) \, e^{-i n \pi y/k}\, dy\  $$ Let $\xi_n = n \pi / k$ and $\Delta \xi_n = \xi_n - \xi_{n-1} = \pi/k$, then $$ f(x) = \frac{1}{2\pi} \sum_{n=-\infty}^\infty \left( \int_{-k}^k f(y) \, e^{-i y \xi_n}\, d y \right) e^{i x  \xi_n } \Delta \xi_n. $$ Take $k \to \infty$ to get $$ f(x) = \frac{1}{2 \pi} \int_{-\infty}^\infty \widehat{f}(\xi)\, e^{i x \xi}\, d \xi $$ where $$ \widehat{f}(\xi) = \int_{-\infty}^\infty  f(x)\, e^{-ix \xi} \,d x. $$ Everyone does this argument, but they never prove it. Even if a book says this argument is not rigorous, they never once give a counterexample. My Question is about the proof: Let $g(\xi)$ be absolutely integrable on $\mathbb{R}$ and continuous, but NOT compactly supported, for otherwise my question is trivial. Let $k > 0$, let $\xi_n = n/k$, and consider the Riemann sum  $$ \sum_{n = -\infty}^\infty g(\xi_n)\Delta \xi_n $$ where suppose that this infinite series is absolutely convergent for all $k > 0$.   Must it be true that $$ \lim_{k \to \infty} \sum_{-\infty}^\infty g(\xi_n)\Delta \xi_n = \int_{-\infty}^\infty g(\xi) d \xi? $$ If this is true, can you give an elementary proof, a proof using only the theory of the Riemann integral and no measure theory or other advanced stuff? If not, what is an explicit and not too complicated counterexample?","To give background to my question, in all the books I've looked at to derive the inverse Fourier transform of a continuous function $f$ on $\mathbb{R}$, they seem to work as follows. Let $k$ be a positive real number and write (by standard Fourier series theory) $$ f(x) = \sum_{n=-\infty}^\infty c_n \, e^{i n \pi x/k}\ , $$ where $$ c_n = \frac{1}{2k} \int_{-k}^k f(y) \, e^{-i n \pi y/k}\, dy\  $$ Let $\xi_n = n \pi / k$ and $\Delta \xi_n = \xi_n - \xi_{n-1} = \pi/k$, then $$ f(x) = \frac{1}{2\pi} \sum_{n=-\infty}^\infty \left( \int_{-k}^k f(y) \, e^{-i y \xi_n}\, d y \right) e^{i x  \xi_n } \Delta \xi_n. $$ Take $k \to \infty$ to get $$ f(x) = \frac{1}{2 \pi} \int_{-\infty}^\infty \widehat{f}(\xi)\, e^{i x \xi}\, d \xi $$ where $$ \widehat{f}(\xi) = \int_{-\infty}^\infty  f(x)\, e^{-ix \xi} \,d x. $$ Everyone does this argument, but they never prove it. Even if a book says this argument is not rigorous, they never once give a counterexample. My Question is about the proof: Let $g(\xi)$ be absolutely integrable on $\mathbb{R}$ and continuous, but NOT compactly supported, for otherwise my question is trivial. Let $k > 0$, let $\xi_n = n/k$, and consider the Riemann sum  $$ \sum_{n = -\infty}^\infty g(\xi_n)\Delta \xi_n $$ where suppose that this infinite series is absolutely convergent for all $k > 0$.   Must it be true that $$ \lim_{k \to \infty} \sum_{-\infty}^\infty g(\xi_n)\Delta \xi_n = \int_{-\infty}^\infty g(\xi) d \xi? $$ If this is true, can you give an elementary proof, a proof using only the theory of the Riemann integral and no measure theory or other advanced stuff? If not, what is an explicit and not too complicated counterexample?",,"['real-analysis', 'integration', 'fourier-analysis', 'improper-integrals', 'riemann-sum']"
38,"Compute $\iiint_V \sin^2 (x + y + z) \,\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}x$ where $V$ is an ellipsoid.",Compute  where  is an ellipsoid.,"\iiint_V \sin^2 (x + y + z) \,\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}x V","By performing a suitable scaling and rotation of the coordinates, or otherwise, evaluate $\iiint_V \sin^2{(x + y + z)}\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}x$ where $V$ is the region   $\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} < 1$ and $a,b,c$   are positive constants. This is a question in a past exam paper that I am revising for. My attempt at the question: First scale the coordinates by making the change $(x,y,z) = (au,bv,cw)$, which means we are now integrating over a sphere, as opposed to an ellipsoid. The Jacobian for this transformation is abc and thus our new integral is $$abc\iiint_{\text{Unit Sphere}}\sin^2(au + bv + cw) \,\mathrm{d}u\,\mathrm{d}v\,\mathrm{d}w$$ Now I need to rotate the coordinates so that our integral will be easier to evaluate once we eventually transform to spherical polar coordinates. We consider this as $$abc\iiint_{\text{Unit Sphere}}\sin^2((a,b,c)\cdot\mathbf{r}) \,\mathrm{d}u\,\mathrm{d}v\,\mathrm{d}w$$ where $\mathbf{r}$ represents our coordinate system. Then by rotating the coordinates to form new coordinates $X,Y,Z$ in such a way that the $Z$ axis points in the direction of the vector $(a,b,c)$ the integral becomes $$abc\iiint_{\text{Unit Sphere}}\sin^2(\sqrt{a^2+b^2+c^2}\mathbf{e_3}\cdot\mathbf{r})\, \mathrm{d}V = abc\iiint_{\text{Unit Sphere}}\sin^2(Z\sqrt{a^2+b^2+c^2}) \,\mathrm{d}V$$ Now we change to spherical polar coordinates $(X,Y,Z) = (r\sin\theta\cos\phi, r\sin\theta\sin\phi,r\cos\theta)$ and our integral becomes $$abc\int_{r=0}^1\int_{\theta=0}^\pi\int_{\phi=0}^{2\pi} \left( \sin^2(r\cos\theta\sqrt{a^2+b^2+c^2})\cdot r^2\sin\theta\right)\,\mathrm{d}\phi\,\mathrm{d}\theta\,\mathrm{d}r$$ And it is at this point I become stumped. Does anybody have any pointers about where to go from here?","By performing a suitable scaling and rotation of the coordinates, or otherwise, evaluate $\iiint_V \sin^2{(x + y + z)}\mathrm{d}x\,\mathrm{d}y\,\mathrm{d}x$ where $V$ is the region   $\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} < 1$ and $a,b,c$   are positive constants. This is a question in a past exam paper that I am revising for. My attempt at the question: First scale the coordinates by making the change $(x,y,z) = (au,bv,cw)$, which means we are now integrating over a sphere, as opposed to an ellipsoid. The Jacobian for this transformation is abc and thus our new integral is $$abc\iiint_{\text{Unit Sphere}}\sin^2(au + bv + cw) \,\mathrm{d}u\,\mathrm{d}v\,\mathrm{d}w$$ Now I need to rotate the coordinates so that our integral will be easier to evaluate once we eventually transform to spherical polar coordinates. We consider this as $$abc\iiint_{\text{Unit Sphere}}\sin^2((a,b,c)\cdot\mathbf{r}) \,\mathrm{d}u\,\mathrm{d}v\,\mathrm{d}w$$ where $\mathbf{r}$ represents our coordinate system. Then by rotating the coordinates to form new coordinates $X,Y,Z$ in such a way that the $Z$ axis points in the direction of the vector $(a,b,c)$ the integral becomes $$abc\iiint_{\text{Unit Sphere}}\sin^2(\sqrt{a^2+b^2+c^2}\mathbf{e_3}\cdot\mathbf{r})\, \mathrm{d}V = abc\iiint_{\text{Unit Sphere}}\sin^2(Z\sqrt{a^2+b^2+c^2}) \,\mathrm{d}V$$ Now we change to spherical polar coordinates $(X,Y,Z) = (r\sin\theta\cos\phi, r\sin\theta\sin\phi,r\cos\theta)$ and our integral becomes $$abc\int_{r=0}^1\int_{\theta=0}^\pi\int_{\phi=0}^{2\pi} \left( \sin^2(r\cos\theta\sqrt{a^2+b^2+c^2})\cdot r^2\sin\theta\right)\,\mathrm{d}\phi\,\mathrm{d}\theta\,\mathrm{d}r$$ And it is at this point I become stumped. Does anybody have any pointers about where to go from here?",,"['integration', 'multivariable-calculus']"
39,Find the general solution of the non-homogeneous equation.,Find the general solution of the non-homogeneous equation.,,"Q. Find the general solution of the non-homogeneous equation. $$\frac{dy}{dt}+y=te^t$$ So here are my steps: Find $\mu (t)=e^t$ $y(t) e^t= \int e^t \times te^t$ So, I combined the terms and obtained: $y(t) e^t= \int te^{2t} $ and from there I proceeded by integration by parts and got: $$y(t) e^t= \frac{1}{2}t e^{2t}-\frac{1}{4}e^{2t}+c $$ then I divided by $e^t$ $$y(t)= \frac{\frac{1}{2}t e^{2t}-\frac{1}{4}e^{2t}+c}{e^t} $$ After simplifying, I obtained: $$y(t)=\frac{1}{2}e^t[t-\frac{1}{2}]+c$$ which is the general solution. I just want to someone to verify if I did everything correct.","Q. Find the general solution of the non-homogeneous equation. $$\frac{dy}{dt}+y=te^t$$ So here are my steps: Find $\mu (t)=e^t$ $y(t) e^t= \int e^t \times te^t$ So, I combined the terms and obtained: $y(t) e^t= \int te^{2t} $ and from there I proceeded by integration by parts and got: $$y(t) e^t= \frac{1}{2}t e^{2t}-\frac{1}{4}e^{2t}+c $$ then I divided by $e^t$ $$y(t)= \frac{\frac{1}{2}t e^{2t}-\frac{1}{4}e^{2t}+c}{e^t} $$ After simplifying, I obtained: $$y(t)=\frac{1}{2}e^t[t-\frac{1}{2}]+c$$ which is the general solution. I just want to someone to verify if I did everything correct.",,"['integration', 'ordinary-differential-equations']"
40,"Prove that $ f:(a,b)\to\mathbb{R}$ is integrable iff $\lim_{\epsilon\to0} \int_{[a+\epsilon,b-\epsilon]}f$ exists",Prove that  is integrable iff  exists," f:(a,b)\to\mathbb{R} \lim_{\epsilon\to0} \int_{[a+\epsilon,b-\epsilon]}f","I want to solve the following: Let $ f:(a,b)\to\mathbb{R}$ continous such that $f(x)\ge 0 $ for all $x\in(a,b)$ . Show that $f$ is integrable iff $\displaystyle \lim_{\varepsilon\to0} \int_{[a+\varepsilon,b-\varepsilon]}f$ exists. My attempt: $\Leftarrow]$ I want invoke the following proposition: If $A$ is open and bounded, and $f:A\to\mathbb{R}$ is bounded and its set of discontinuities is measure zero, then $f$ is integrable. And we have that $(a,b)$ is bounded by the one dimensional rectangle $[a,b]$ and since $f$ is continous we have that it is bounded in $(a,b)$ , but the thing is that this argument does not need the limit. Can you help me fix this please? If $f$ is integrable then we have that: $$\sum_{\phi \in F} \phi f \to \int_{(a,b)} f = \displaystyle \lim_{\varepsilon\to0} \int_{[a+\varepsilon,b-\varepsilon]}f$$ But I think this is a little bit trivial and I think I am wrong. Can you help me verify this, and if it is wrong, can you help me fix the mistakes please? Thanks a lot in advance :)","I want to solve the following: Let continous such that for all . Show that is integrable iff exists. My attempt: I want invoke the following proposition: If is open and bounded, and is bounded and its set of discontinuities is measure zero, then is integrable. And we have that is bounded by the one dimensional rectangle and since is continous we have that it is bounded in , but the thing is that this argument does not need the limit. Can you help me fix this please? If is integrable then we have that: But I think this is a little bit trivial and I think I am wrong. Can you help me verify this, and if it is wrong, can you help me fix the mistakes please? Thanks a lot in advance :)"," f:(a,b)\to\mathbb{R} f(x)\ge 0  x\in(a,b) f \displaystyle \lim_{\varepsilon\to0} \int_{[a+\varepsilon,b-\varepsilon]}f \Leftarrow] A f:A\to\mathbb{R} f (a,b) [a,b] f (a,b) f \sum_{\phi \in F} \phi f \to \int_{(a,b)} f = \displaystyle \lim_{\varepsilon\to0} \int_{[a+\varepsilon,b-\varepsilon]}f","['real-analysis', 'integration', 'improper-integrals']"
41,"How to compute the integral $\int_{-\infty}^\infty e^{-x^2/2}\,dx$?",How to compute the integral ?,"\int_{-\infty}^\infty e^{-x^2/2}\,dx","Yes, I know that this is very similar to  $\int_{-\infty}^\infty e^{-x^2}\,dx$, which has been answered a million times, but I still don't know how to apply the technique from that integration to mine. I don't want to do this using polar coordinates, or ""erf"". I'd like to use the Gamma function (which I assume is possible..). Is this correct? : $$\int_{-\infty}^\infty e^{-x^2/2}\,dx=2\int_{0}^\infty e^{-x^2/2}\,dx$$ Let $u = x^2/2  \implies x = \sqrt{2u}$, $du = x \, dx \implies dx = (2u)^{-1/2}$ So, $$=2\int_{0}^\infty (2u)^{-1/2}e^{-u}\,dx=\sqrt{2}\int_0^\infty (u)^{-1/2}e^{-u}\,dx=\sqrt{2} \Gamma(1/2)= \sqrt{2\pi}$$","Yes, I know that this is very similar to  $\int_{-\infty}^\infty e^{-x^2}\,dx$, which has been answered a million times, but I still don't know how to apply the technique from that integration to mine. I don't want to do this using polar coordinates, or ""erf"". I'd like to use the Gamma function (which I assume is possible..). Is this correct? : $$\int_{-\infty}^\infty e^{-x^2/2}\,dx=2\int_{0}^\infty e^{-x^2/2}\,dx$$ Let $u = x^2/2  \implies x = \sqrt{2u}$, $du = x \, dx \implies dx = (2u)^{-1/2}$ So, $$=2\int_{0}^\infty (2u)^{-1/2}e^{-u}\,dx=\sqrt{2}\int_0^\infty (u)^{-1/2}e^{-u}\,dx=\sqrt{2} \Gamma(1/2)= \sqrt{2\pi}$$",,"['calculus', 'integration', 'algebra-precalculus', 'proof-verification', 'gaussian-integral']"
42,"stuck with (last) partial integration step for $\int x^2 e^{2x} \, dx$",stuck with (last) partial integration step for,"\int x^2 e^{2x} \, dx","I am stuck with this integral in the last step of partial integration: \begin{align} \int x^2 e^{2x}\,dx & = \frac{1}{2}e^{2x}x^2-\int \frac{1}{2}e^{2x} 2x \,dx \\[6pt] & = \frac{1}{2}e^{2x}x^2-\int e^{2x} x \, dx \\[6pt] & = \frac{1}{2}e^{2x}x^2-\frac{1}{2}e^{2x}x-\int \frac{1}{2}e^{2x} \,dx\\[6pt] & = \frac{1}{2}e^{2x}x^2-\frac{1}{2}e^{2x}x- \frac{1}{2} \int e^{2x} \,dx \end{align} I have problems with evalautating the final integral, especially with the factoring of constants (the $\frac{1}{2}$ for the integral. The solution for the last integral is  $+\frac{1}{4}e^{2x}$, but it seems I have a knot in my brain and can't get the last step right, because I would solve it to $-\frac{1}{4}e^{2x}$... How does the last step evaluate to positive?","I am stuck with this integral in the last step of partial integration: \begin{align} \int x^2 e^{2x}\,dx & = \frac{1}{2}e^{2x}x^2-\int \frac{1}{2}e^{2x} 2x \,dx \\[6pt] & = \frac{1}{2}e^{2x}x^2-\int e^{2x} x \, dx \\[6pt] & = \frac{1}{2}e^{2x}x^2-\frac{1}{2}e^{2x}x-\int \frac{1}{2}e^{2x} \,dx\\[6pt] & = \frac{1}{2}e^{2x}x^2-\frac{1}{2}e^{2x}x- \frac{1}{2} \int e^{2x} \,dx \end{align} I have problems with evalautating the final integral, especially with the factoring of constants (the $\frac{1}{2}$ for the integral. The solution for the last integral is  $+\frac{1}{4}e^{2x}$, but it seems I have a knot in my brain and can't get the last step right, because I would solve it to $-\frac{1}{4}e^{2x}$... How does the last step evaluate to positive?",,"['calculus', 'integration', 'indefinite-integrals']"
43,"Comparison between $\int_0^{2\pi}f(x,x)dx$ and $\frac{1}{2\pi}\int_0^{2\pi}\int_0^{2\pi}f(x,y)dxdy$",Comparison between  and,"\int_0^{2\pi}f(x,x)dx \frac{1}{2\pi}\int_0^{2\pi}\int_0^{2\pi}f(x,y)dxdy","I would like to find a method of comparison between  $I=\int_0^{2\pi}\sqrt{3+4\cos(x)+2\cos(2x)}dx$ and $J=\frac{1}{2\pi}\int_0^{2\pi}\int_0^{2\pi}\sqrt{3+2\cos(x)+2\cos(y)+2\cos(x+y)}dxdy$, besides just computing the integrals. Using  mathematical software one can find $I=9.0226$ and $J=9.8935$, so $I<J$. But the method should allow extensions to larger classes of functions $f$ such that $$\int_0^{2\pi}f(x,x)dx<\frac{1}{2\pi}\int_0^{2\pi}\int_0^{2\pi}f(x,y)dxdy.$$ Please let me know if you have an idea.","I would like to find a method of comparison between  $I=\int_0^{2\pi}\sqrt{3+4\cos(x)+2\cos(2x)}dx$ and $J=\frac{1}{2\pi}\int_0^{2\pi}\int_0^{2\pi}\sqrt{3+2\cos(x)+2\cos(y)+2\cos(x+y)}dxdy$, besides just computing the integrals. Using  mathematical software one can find $I=9.0226$ and $J=9.8935$, so $I<J$. But the method should allow extensions to larger classes of functions $f$ such that $$\int_0^{2\pi}f(x,x)dx<\frac{1}{2\pi}\int_0^{2\pi}\int_0^{2\pi}f(x,y)dxdy.$$ Please let me know if you have an idea.",,"['integration', 'trigonometry']"
44,Evaluating $\frac{1}{2\pi j}\int_{c-j\infty}^{c+j\infty}x^{-s}\sigma ^{ms-m} [ \frac{\Gamma ( s )}{\Gamma ( s+2)}]^{m}ds$,Evaluating,\frac{1}{2\pi j}\int_{c-j\infty}^{c+j\infty}x^{-s}\sigma ^{ms-m} [ \frac{\Gamma ( s )}{\Gamma ( s+2)}]^{m}ds,"I have been trying to solve the problem for $m=3$: $$f(x)=\frac{1}{2\pi j}\int_{c-j\infty}^{c+j\infty}x^{-s}\sigma ^{ms-m}\left [ \frac{\Gamma \left ( s \right )}{\Gamma \left ( s+2 \right )} \right ]^{m}ds$$ Starting off, I have then simplified the problem to: $$f(x)=\frac{1}{2\sigma ^{m}\pi j}\int_{c-j\infty}^{c+j\infty}\left ( \frac{\sigma ^{m}}{x} \right )^{s}\frac{1}{s^{m}\left ( s+1 \right )^{m}}ds$$ For $m=3$ and finding the residues: $$\text{Res}\left ( \Gamma(s),0\right )=\frac{1}{2!}\lim_{s\rightarrow0}\frac{d^{2}}{ds^{2}}\left ( \frac{\sigma ^{3}}{x} \right )^{s}\frac{1}{\left (s+1  \right )^{3}}$$ $$\text{Res}\left ( \Gamma(s),-1\right )=\frac{1}{2!}\lim_{s\rightarrow-1}\frac{d^{2}}{ds^{2}}\left ( \frac{\sigma ^{3}}{x} \right )^{s}\frac{1}{s^{3}}$$ Using Cauchy's residue theorem, the simplified answer I obtain is: $$f(x)=\frac{1}{2\sigma ^{3}}\left [ 12\left \{ 1-\frac{x}{\sigma^{3}} \right \}-6log\left ( \frac{\sigma^{3}}{x} \right )\left \{ 1+\frac{x}{\sigma^{3}} \right \}+log\left ( \frac{\sigma^{3}}{x} \right )^{2}\left \{ 1-\frac{x}{\sigma^{3}} \right \} \right ]$$ To check the answer I obtained, I plot it out in MATLAB against the emperical solution and this is what I get (negative side of $x$ is mirror of positive side of $x$): Where am I doing it wrongly? Is my final answer correct? Thanks Answer: There was nothing wrong with the analytical equation. And the problem is for $c>0$ and $x<\sigma$. Otherwise, $f(x)=0$. With that specified, the analytical expression obtained is correct! *Thanks to @RonGordon","I have been trying to solve the problem for $m=3$: $$f(x)=\frac{1}{2\pi j}\int_{c-j\infty}^{c+j\infty}x^{-s}\sigma ^{ms-m}\left [ \frac{\Gamma \left ( s \right )}{\Gamma \left ( s+2 \right )} \right ]^{m}ds$$ Starting off, I have then simplified the problem to: $$f(x)=\frac{1}{2\sigma ^{m}\pi j}\int_{c-j\infty}^{c+j\infty}\left ( \frac{\sigma ^{m}}{x} \right )^{s}\frac{1}{s^{m}\left ( s+1 \right )^{m}}ds$$ For $m=3$ and finding the residues: $$\text{Res}\left ( \Gamma(s),0\right )=\frac{1}{2!}\lim_{s\rightarrow0}\frac{d^{2}}{ds^{2}}\left ( \frac{\sigma ^{3}}{x} \right )^{s}\frac{1}{\left (s+1  \right )^{3}}$$ $$\text{Res}\left ( \Gamma(s),-1\right )=\frac{1}{2!}\lim_{s\rightarrow-1}\frac{d^{2}}{ds^{2}}\left ( \frac{\sigma ^{3}}{x} \right )^{s}\frac{1}{s^{3}}$$ Using Cauchy's residue theorem, the simplified answer I obtain is: $$f(x)=\frac{1}{2\sigma ^{3}}\left [ 12\left \{ 1-\frac{x}{\sigma^{3}} \right \}-6log\left ( \frac{\sigma^{3}}{x} \right )\left \{ 1+\frac{x}{\sigma^{3}} \right \}+log\left ( \frac{\sigma^{3}}{x} \right )^{2}\left \{ 1-\frac{x}{\sigma^{3}} \right \} \right ]$$ To check the answer I obtained, I plot it out in MATLAB against the emperical solution and this is what I get (negative side of $x$ is mirror of positive side of $x$): Where am I doing it wrongly? Is my final answer correct? Thanks Answer: There was nothing wrong with the analytical equation. And the problem is for $c>0$ and $x<\sigma$. Otherwise, $f(x)=0$. With that specified, the analytical expression obtained is correct! *Thanks to @RonGordon",,"['integration', 'algebra-precalculus', 'gamma-function', 'residue-calculus', 'cauchy-principal-value']"
45,How to compute these Riemann-Stieltjes-Integrals?,How to compute these Riemann-Stieltjes-Integrals?,,"I have some doubt on this exercise which I have to solve: Compute The Integral $\displaystyle \int_0^4 F(x) \ \mathrm{d}G(x)$ for 1.) $F(x) = x$ for $x<2$, $1$ otherwise; $G(x)=x^2$ 2.) $F(x) = e^{-x}$ ; $G(x) = 0$ for $x<2$, $4$ for $2≤x<3$ and $-2$ otherwise. 3.) $F(x)=(1+i)^{\lfloor -x\rfloor}$ with $i$ in $(0,1)$; $G(x) = 0$ for $x<0$, $1$ for $0≤x<1$, $2$ for $1≤x<2$ and $\sin(\pi \cdot x)$ otherwise. On 2.) I think the integral will be $0$ because $F$ is continuous, $G(x)$ is constant and there are no common discontinuity points between $F$ and $G$. On 3.) There are common discontinuity points like $0,1,2$. So there doesn't exist an Integral. Now my question is, how to find the integral in 1.)? Because $F$ is not continuous but $G$ is continuously differentiable. So $\mathrm{d}G(x)=G'(x)\mathrm{d}x$. I tried to calculate the integral in two parts. One from $0$ to $2$ and the other one from $2$ to $4$. But There does not exist a value $F(x)=x$ for $2$. So I don't how to compute the first integral. How can I solve this problem? Am I right in 2.) and 3.)?","I have some doubt on this exercise which I have to solve: Compute The Integral $\displaystyle \int_0^4 F(x) \ \mathrm{d}G(x)$ for 1.) $F(x) = x$ for $x<2$, $1$ otherwise; $G(x)=x^2$ 2.) $F(x) = e^{-x}$ ; $G(x) = 0$ for $x<2$, $4$ for $2≤x<3$ and $-2$ otherwise. 3.) $F(x)=(1+i)^{\lfloor -x\rfloor}$ with $i$ in $(0,1)$; $G(x) = 0$ for $x<0$, $1$ for $0≤x<1$, $2$ for $1≤x<2$ and $\sin(\pi \cdot x)$ otherwise. On 2.) I think the integral will be $0$ because $F$ is continuous, $G(x)$ is constant and there are no common discontinuity points between $F$ and $G$. On 3.) There are common discontinuity points like $0,1,2$. So there doesn't exist an Integral. Now my question is, how to find the integral in 1.)? Because $F$ is not continuous but $G$ is continuously differentiable. So $\mathrm{d}G(x)=G'(x)\mathrm{d}x$. I tried to calculate the integral in two parts. One from $0$ to $2$ and the other one from $2$ to $4$. But There does not exist a value $F(x)=x$ for $2$. So I don't how to compute the first integral. How can I solve this problem? Am I right in 2.) and 3.)?",,"['integration', 'analysis']"
46,Asymptotic evaluation of integral of algebraic function,Asymptotic evaluation of integral of algebraic function,,"I am wondering what techniques exist for the asymptotic evaluation of integrals. Consider the integral $$ I(\lambda) = \int_1^\lambda dx \sqrt{1-\frac 1 x} =  \sqrt \lambda \sqrt{\lambda - 1}- \cosh^{-1} \sqrt \lambda . $$ It is clear from the explicit expression that $I(\lambda) \approx \lambda - \frac 1 2\log(4 \lambda) - \frac 1 2$ for large $\lambda$. Could we have found this asymptotic solution without explicitly evaluating the integral? I am familiar only with the steepest descent method, but it does not appear to be applicable here.","I am wondering what techniques exist for the asymptotic evaluation of integrals. Consider the integral $$ I(\lambda) = \int_1^\lambda dx \sqrt{1-\frac 1 x} =  \sqrt \lambda \sqrt{\lambda - 1}- \cosh^{-1} \sqrt \lambda . $$ It is clear from the explicit expression that $I(\lambda) \approx \lambda - \frac 1 2\log(4 \lambda) - \frac 1 2$ for large $\lambda$. Could we have found this asymptotic solution without explicitly evaluating the integral? I am familiar only with the steepest descent method, but it does not appear to be applicable here.",,"['integration', 'asymptotics']"
47,Evaluate $\int_{-2}^{-1}\frac{\text{d}x}{\sqrt{-x^2-6x}}$.,Evaluate .,\int_{-2}^{-1}\frac{\text{d}x}{\sqrt{-x^2-6x}},"Problem statement [from Charlie Marshak's Math GRE Prep Problems]: Evaluate $\displaystyle \int\limits_{-2}^{-1}\dfrac{\text{d}x}{\sqrt{-x^2-6x}}$. My work: notice that $$\begin{align} -x^2-6x &= -(x^2 - 6x) \\&= -\left[x^2-6x+\left(\dfrac{6}{2}\right)^2-\left(\dfrac{6}{2}\right)^2\right] \\ &= -(x^2-6x+9-9) \\ &= 9 - (x^2 - 6x+9) \\ &= 9 - (x-3)^2\text{.} \end{align}$$ So, $$\int\limits_{-2}^{-1}\dfrac{\text{d}x}{\sqrt{-x^2-6x}} = \int\limits_{-2}^{-1}\dfrac{\text{d}x}{3\sqrt{1-\left(\dfrac{x-3}{3}\right)^2}}\text{.}$$ If $u = \dfrac{x-3}{3}$, $\text{d}u = \dfrac{1}{3}\text{ d}x$, so that  $$\int\limits_{-2}^{-1}\dfrac{\text{d}x}{3\sqrt{1-\left(\dfrac{x-3}{3}\right)^2}} = \int\limits_{-5/3}^{-4/3}\dfrac{\text{d}u}{\sqrt{1^2-u^2}} = \sin^{-1}\left(\dfrac{-4}{3}\right) - \sin^{-1}\left(\dfrac{-5}{3}\right)\text{.}$$ The answer is supposed to be $\sin^{-1}(2/3)-\sin^{-1}(1/3)$. Where did I go wrong?","Problem statement [from Charlie Marshak's Math GRE Prep Problems]: Evaluate $\displaystyle \int\limits_{-2}^{-1}\dfrac{\text{d}x}{\sqrt{-x^2-6x}}$. My work: notice that $$\begin{align} -x^2-6x &= -(x^2 - 6x) \\&= -\left[x^2-6x+\left(\dfrac{6}{2}\right)^2-\left(\dfrac{6}{2}\right)^2\right] \\ &= -(x^2-6x+9-9) \\ &= 9 - (x^2 - 6x+9) \\ &= 9 - (x-3)^2\text{.} \end{align}$$ So, $$\int\limits_{-2}^{-1}\dfrac{\text{d}x}{\sqrt{-x^2-6x}} = \int\limits_{-2}^{-1}\dfrac{\text{d}x}{3\sqrt{1-\left(\dfrac{x-3}{3}\right)^2}}\text{.}$$ If $u = \dfrac{x-3}{3}$, $\text{d}u = \dfrac{1}{3}\text{ d}x$, so that  $$\int\limits_{-2}^{-1}\dfrac{\text{d}x}{3\sqrt{1-\left(\dfrac{x-3}{3}\right)^2}} = \int\limits_{-5/3}^{-4/3}\dfrac{\text{d}u}{\sqrt{1^2-u^2}} = \sin^{-1}\left(\dfrac{-4}{3}\right) - \sin^{-1}\left(\dfrac{-5}{3}\right)\text{.}$$ The answer is supposed to be $\sin^{-1}(2/3)-\sin^{-1}(1/3)$. Where did I go wrong?",,"['calculus', 'integration', 'definite-integrals']"
48,How can I find the Cauchy Principal Value of this integral using complex analysis?,How can I find the Cauchy Principal Value of this integral using complex analysis?,,I'm supposed to solve the real integral using a contour integral (The Cauchy Principal Value). Can someone give me a hand? I cannot seem to be able to do it... This is what I've tried so far: I tried computing the contour integral first using the Residue theorem. I simplified the total residue to :$$-\cos(\pi a) - i\sin(\pi a)$$ I also tried showing that the part of the integral that doesn't lie on the real line goes to zero as $R$ goes to infinity. (where $R$ is the bound on the integral). I tried using the ML equality in combination with the triangle equality to no avail. Thank you.,I'm supposed to solve the real integral using a contour integral (The Cauchy Principal Value). Can someone give me a hand? I cannot seem to be able to do it... This is what I've tried so far: I tried computing the contour integral first using the Residue theorem. I simplified the total residue to :$$-\cos(\pi a) - i\sin(\pi a)$$ I also tried showing that the part of the integral that doesn't lie on the real line goes to zero as $R$ goes to infinity. (where $R$ is the bound on the integral). I tried using the ML equality in combination with the triangle equality to no avail. Thank you.,,"['integration', 'complex-analysis', 'contour-integration']"
49,"Show that $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ if and only if $f(x) = 0$ for all $x\in [a,b]$.",Show that  for all  if and only if  for all .,"\int_{a}^{c}f(x)dx = 0 c\in [a,b] f(x) = 0 x\in [a,b]","Exercise: Suppose that $a<b$ and that $f:[a,b]\rightarrow R$   is continuous. Show that $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ if and only if $f(x) = 0$ for all $x\in [a,b]$. attempt of proof: Suppose  that $a<b$ and that $f:[a,b]\rightarrow R$   is continuous.  Let $m$ and $M$ be the infimum and supremum of f. Since $f(x) = 0 $ for all $x\in [a,b]$ $m = 0$ since  $f(x) = 0$. Thus, for all any partition $P$ of $[a,b]$, $L(f,P) = m(b-a) = 0$ implies $L(f,P) = 0$. Hence,  $(L)\int_{a}^{c}f(x)dx$ = $sup{L(f,P)}$ = $0$. In a similar way we can working with the supremum. Thus, if both the lower integral of f and the upper integral of f have the same value , we can conclude then the value of the $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ The converse is trivial, since $\forall c\in [a,b]$ $f(c) = 0$ since $f(x)=0$ , so $\int_{a}^{c}f(x)dx = 0$ Can someone please help me? I don't know if this is a way to prove it. Any feedback/hint or better way would be really appreciated.Thank you in advance.","Exercise: Suppose that $a<b$ and that $f:[a,b]\rightarrow R$   is continuous. Show that $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ if and only if $f(x) = 0$ for all $x\in [a,b]$. attempt of proof: Suppose  that $a<b$ and that $f:[a,b]\rightarrow R$   is continuous.  Let $m$ and $M$ be the infimum and supremum of f. Since $f(x) = 0 $ for all $x\in [a,b]$ $m = 0$ since  $f(x) = 0$. Thus, for all any partition $P$ of $[a,b]$, $L(f,P) = m(b-a) = 0$ implies $L(f,P) = 0$. Hence,  $(L)\int_{a}^{c}f(x)dx$ = $sup{L(f,P)}$ = $0$. In a similar way we can working with the supremum. Thus, if both the lower integral of f and the upper integral of f have the same value , we can conclude then the value of the $\int_{a}^{c}f(x)dx = 0$ for all $c\in [a,b]$ The converse is trivial, since $\forall c\in [a,b]$ $f(c) = 0$ since $f(x)=0$ , so $\int_{a}^{c}f(x)dx = 0$ Can someone please help me? I don't know if this is a way to prove it. Any feedback/hint or better way would be really appreciated.Thank you in advance.",,"['real-analysis', 'integration', 'proof-verification', 'riemann-sum']"
50,"Evaluation of the integral $\int \sqrt{t^4-t^2 + 1}\,dt$",Evaluation of the integral,"\int \sqrt{t^4-t^2 + 1}\,dt","My friend took his Calculus $2/3$ test yesterday. One of the questions he had trouble with was this integral: $$\int \sqrt{t^4-t^2 + 1}dt$$ My attempt It seems rather clear that the only approach was trigonometric substitution. First, completing the square: $$\int \sqrt{t^4-t^2 + 1}dt = \int\sqrt{t^4-t^2 + \frac{1}{4} + \frac{3}{4}}dt = \int \sqrt{\left(t^2 - \frac{1}{2}\right) + \frac{3}{4}}dt$$ Next, I let $$\sec \theta = \frac{\sqrt{\left(t^2 - \frac{1}{2}\right) + \frac{3}{4}}}{\frac{\sqrt{3}}{2}}$$ $$\frac{\sqrt{3}}{2}\sec \theta = \sqrt{\left(t^2 - \frac{1}{2}\right) + \frac{3}{4}}$$ $$\tan \theta = \frac{t^2 - \frac{1}{2}}{\frac{\sqrt{3}}{2}} = \frac{2t^2 - 1}{\sqrt{3}}$$ $$\sec^2 \theta d\theta = \frac{4}{\sqrt{3}}tdt,\ dt = \frac{\sqrt{3}\sec^2 \theta}{4t} d\theta$$ $$t = \sqrt{\frac{1}{2}\left(\sqrt{3}\tan \theta + 1\right)}$$ Substituting this all in: $$\int \left(\frac{\sqrt{3}}{2} \sec \theta\right) \frac{\sqrt{3}\sec^2 \theta}{4\sqrt{\frac{1}{2}\left(\sqrt{3}\tan \theta + 1\right)}} d\theta$$ How would I approach this from here? I'm thinking of using u-substitution but I'm sure that it would bring me back to where I started, meaning I would have to use trig. substitution again.","My friend took his Calculus $2/3$ test yesterday. One of the questions he had trouble with was this integral: $$\int \sqrt{t^4-t^2 + 1}dt$$ My attempt It seems rather clear that the only approach was trigonometric substitution. First, completing the square: $$\int \sqrt{t^4-t^2 + 1}dt = \int\sqrt{t^4-t^2 + \frac{1}{4} + \frac{3}{4}}dt = \int \sqrt{\left(t^2 - \frac{1}{2}\right) + \frac{3}{4}}dt$$ Next, I let $$\sec \theta = \frac{\sqrt{\left(t^2 - \frac{1}{2}\right) + \frac{3}{4}}}{\frac{\sqrt{3}}{2}}$$ $$\frac{\sqrt{3}}{2}\sec \theta = \sqrt{\left(t^2 - \frac{1}{2}\right) + \frac{3}{4}}$$ $$\tan \theta = \frac{t^2 - \frac{1}{2}}{\frac{\sqrt{3}}{2}} = \frac{2t^2 - 1}{\sqrt{3}}$$ $$\sec^2 \theta d\theta = \frac{4}{\sqrt{3}}tdt,\ dt = \frac{\sqrt{3}\sec^2 \theta}{4t} d\theta$$ $$t = \sqrt{\frac{1}{2}\left(\sqrt{3}\tan \theta + 1\right)}$$ Substituting this all in: $$\int \left(\frac{\sqrt{3}}{2} \sec \theta\right) \frac{\sqrt{3}\sec^2 \theta}{4\sqrt{\frac{1}{2}\left(\sqrt{3}\tan \theta + 1\right)}} d\theta$$ How would I approach this from here? I'm thinking of using u-substitution but I'm sure that it would bring me back to where I started, meaning I would have to use trig. substitution again.",,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
51,Real integral giving a complex result,Real integral giving a complex result,,"I have to solve the following integral $$ \int_{-\infty}^{\infty} dx \frac{e^x-1}{x} e^{-\frac{(x+y)^2}{2 \sigma^2}}$$ This integral converges, becaue $\frac{e^x-1}{x}$ goes to 1 for $x \to 0$. When I feed the previous integral to Mathematica, however, I get logarithms with negative arguments. For the case $y=0$, for example, the result of the integral is $-i \pi$. How can I have a complex argument from such a real integral? Is mathematica doing something wrong?","I have to solve the following integral $$ \int_{-\infty}^{\infty} dx \frac{e^x-1}{x} e^{-\frac{(x+y)^2}{2 \sigma^2}}$$ This integral converges, becaue $\frac{e^x-1}{x}$ goes to 1 for $x \to 0$. When I feed the previous integral to Mathematica, however, I get logarithms with negative arguments. For the case $y=0$, for example, the result of the integral is $-i \pi$. How can I have a complex argument from such a real integral? Is mathematica doing something wrong?",,"['integration', 'definite-integrals', 'improper-integrals', 'gaussian-integral']"
52,Solve $ \int_{0}^{\infty} \sin^2 \left(\frac{1}{x}\right)\mathrm{d}x$,Solve, \int_{0}^{\infty} \sin^2 \left(\frac{1}{x}\right)\mathrm{d}x,"I think this integral does not converge. I want to  estimate downward the integral, but don't know how to.","I think this integral does not converge. I want to  estimate downward the integral, but don't know how to.",,['integration']
53,An inequality with $a_n=\int_0^1 \frac{\mathrm{d}x}{\underbrace{\sqrt{2+\sqrt{2+\dots+\sqrt{2x}}}}_{n \text { times}}}$,An inequality with,a_n=\int_0^1 \frac{\mathrm{d}x}{\underbrace{\sqrt{2+\sqrt{2+\dots+\sqrt{2x}}}}_{n \text { times}}},"Let the sequence $(a_n)_n$ defined by $$a_n=\int_0^1 \frac{\mathrm{d}x}{\underbrace{\sqrt{2+\sqrt{2+\dots+\sqrt{2x}}}}_{n \text { times}}}$$ 1)Prove that $$\frac12 \leq a_n \leq \frac{1}{\underbrace{\sqrt{2+\sqrt{2+\dots+\sqrt{2}}}}_{n-1 \text { times}}} \; \forall n\geq 1$$ 2)Find the limit of the sequence $(a_n)_n$ If I could find a closed form of the first integral the problem would be quite easier, so is there a simplification possible for these iterated roots?","Let the sequence $(a_n)_n$ defined by $$a_n=\int_0^1 \frac{\mathrm{d}x}{\underbrace{\sqrt{2+\sqrt{2+\dots+\sqrt{2x}}}}_{n \text { times}}}$$ 1)Prove that $$\frac12 \leq a_n \leq \frac{1}{\underbrace{\sqrt{2+\sqrt{2+\dots+\sqrt{2}}}}_{n-1 \text { times}}} \; \forall n\geq 1$$ 2)Find the limit of the sequence $(a_n)_n$ If I could find a closed form of the first integral the problem would be quite easier, so is there a simplification possible for these iterated roots?",,"['integration', 'inequality', 'definite-integrals']"
54,Converse of the Fundamental Theorem of Calculus,Converse of the Fundamental Theorem of Calculus,,"One form of the FTC is the following: if $f$ is continuous on an interval $I$ and $a$ a point of $I$, then the function $F$ defined on $I$ by $\displaystyle{ F(x)=\int_a^x f(t) \, dt }$ is differentiable on $I$ and satisfies $F'(x)=f(x)$ for any $x$ in $I$. It is well-known that if $f$ is not continuous, then $F$ may not be differentiable (for example, for $f(x)=0$ when $x<0$ and $f(x)=1$ when $x\geqslant 1$, $F$ is not differentiable at $0$) and if $F$ is differentiable, we may not have $F'(x)=f(x)$ at the discontinuities of $f$. For example, if $f(x)=0$ for $x\neq 0$ and $f(0)=1$, then $F$ is constant equal to $0$, hence differentiable. But $F'(0)=0\neq f(0)$. I am now looking for a converse of the above version of the FTC: if $F$ is an antiderivative of $f$, then $f$ is continuous on $I$. Is this statement true? I was not able to prove it, nor to find a counter-example.","One form of the FTC is the following: if $f$ is continuous on an interval $I$ and $a$ a point of $I$, then the function $F$ defined on $I$ by $\displaystyle{ F(x)=\int_a^x f(t) \, dt }$ is differentiable on $I$ and satisfies $F'(x)=f(x)$ for any $x$ in $I$. It is well-known that if $f$ is not continuous, then $F$ may not be differentiable (for example, for $f(x)=0$ when $x<0$ and $f(x)=1$ when $x\geqslant 1$, $F$ is not differentiable at $0$) and if $F$ is differentiable, we may not have $F'(x)=f(x)$ at the discontinuities of $f$. For example, if $f(x)=0$ for $x\neq 0$ and $f(0)=1$, then $F$ is constant equal to $0$, hence differentiable. But $F'(0)=0\neq f(0)$. I am now looking for a converse of the above version of the FTC: if $F$ is an antiderivative of $f$, then $f$ is continuous on $I$. Is this statement true? I was not able to prove it, nor to find a counter-example.",,"['calculus', 'integration']"
55,Integral versus hypergeometric series: how to solve this?,Integral versus hypergeometric series: how to solve this?,,"How can I resolve the following indefinite integral using hypergeometric series? $$ \int (x^3 + 1)^\frac{1}{3} \,dx $$ Wolfram Alpha indicates that the series of Appell are used, but how to get to this result? Grateful!","How can I resolve the following indefinite integral using hypergeometric series? $$ \int (x^3 + 1)^\frac{1}{3} \,dx $$ Wolfram Alpha indicates that the series of Appell are used, but how to get to this result? Grateful!",,"['integration', 'indefinite-integrals', 'hypergeometric-function']"
56,Differentiation under integral sign without DCT,Differentiation under integral sign without DCT,,"Suppose $f: \Omega \times I \subseteq \mathbb{R}^n \to \mathbb{R}$ is differentiable, where $\Omega$ is measurable and $I$ is an open interval. How do you show that if $\frac{\partial f}{\partial t}$ is uniformly continuous in $\Omega \times I$,  then $\frac{d}{dt} \int_{\Omega} f(x,t) dx = \int_{\Omega} \frac{\partial f}{\partial t}(x,t) dx$? You would surely have the left-hand side equal to $\lim_{\epsilon \to 0} \int_{\Omega} \frac{f(x,t+\epsilon)-f(x,t)}{\epsilon} dx$, so it suffices to show the limit commutes with the integral. If I could use the DCT, I'd just take any sequence $\epsilon_n$ going to $0$ and apply the theorem to the sequence $g_n = \frac{f(x,t+\epsilon_n)-f(x,t)}{\epsilon_n}$, which converges to $\frac{\partial f}{\partial t}$ (it shouldn't be difficult to bound the $g_n$). Does uniform continuity of $\frac{\partial f}{\partial t}$ imply uniform convergence of $(g_n)_{n \in \mathbb{N}}$? That's the actual issue. Is there a simple way to see this?","Suppose $f: \Omega \times I \subseteq \mathbb{R}^n \to \mathbb{R}$ is differentiable, where $\Omega$ is measurable and $I$ is an open interval. How do you show that if $\frac{\partial f}{\partial t}$ is uniformly continuous in $\Omega \times I$,  then $\frac{d}{dt} \int_{\Omega} f(x,t) dx = \int_{\Omega} \frac{\partial f}{\partial t}(x,t) dx$? You would surely have the left-hand side equal to $\lim_{\epsilon \to 0} \int_{\Omega} \frac{f(x,t+\epsilon)-f(x,t)}{\epsilon} dx$, so it suffices to show the limit commutes with the integral. If I could use the DCT, I'd just take any sequence $\epsilon_n$ going to $0$ and apply the theorem to the sequence $g_n = \frac{f(x,t+\epsilon_n)-f(x,t)}{\epsilon_n}$, which converges to $\frac{\partial f}{\partial t}$ (it shouldn't be difficult to bound the $g_n$). Does uniform continuity of $\frac{\partial f}{\partial t}$ imply uniform convergence of $(g_n)_{n \in \mathbb{N}}$? That's the actual issue. Is there a simple way to see this?",,"['real-analysis', 'integration']"
57,"Integrals $\int \frac{1}{\operatorname{arctanh}(x)} \, dx$ and $\int \frac{1}{\operatorname{arccoth}(x)} \, dx$",Integrals  and,"\int \frac{1}{\operatorname{arctanh}(x)} \, dx \int \frac{1}{\operatorname{arccoth}(x)} \, dx","Do we know anything about this integrals? $$ \begin{align} I_1(x) = \int \frac{1}{\operatorname{artanh}(x)} \, dx \\ I_2(x) = \int \frac{1}{\operatorname{arcoth}(x)} \, dx \end{align}$$ Similar integrals. $$ \begin{align} \int \operatorname{artanh}(x) \, dx & = x \operatorname{artanh}(x) + \frac12 \ln(1-x^2) + C, \\ \int \operatorname{arcoth}(x) \, dx & = x \operatorname{arcoth}(x) + \frac12 \ln(1-x^2) + C, \\ \int \frac{1}{\operatorname{arsinh}(x)} \, dx & = \operatorname{Chi}(\operatorname{arsinh}(x)) + C, \\ \int \frac{1}{\operatorname{arcosh}(x)} \, dx & = \operatorname{Shi}(\operatorname{arcosh}(x)) + C, \\ \end{align}$$ where $\operatorname{Chi}$ is the hyperbolic cosine integral , and $\operatorname{Shi}$ is the hyperbolic sine integral . I found nothing with Maple or Mathematica . As I see some kind of ""hyperbolic tangent integral"" is not defined.","Do we know anything about this integrals? $$ \begin{align} I_1(x) = \int \frac{1}{\operatorname{artanh}(x)} \, dx \\ I_2(x) = \int \frac{1}{\operatorname{arcoth}(x)} \, dx \end{align}$$ Similar integrals. $$ \begin{align} \int \operatorname{artanh}(x) \, dx & = x \operatorname{artanh}(x) + \frac12 \ln(1-x^2) + C, \\ \int \operatorname{arcoth}(x) \, dx & = x \operatorname{arcoth}(x) + \frac12 \ln(1-x^2) + C, \\ \int \frac{1}{\operatorname{arsinh}(x)} \, dx & = \operatorname{Chi}(\operatorname{arsinh}(x)) + C, \\ \int \frac{1}{\operatorname{arcosh}(x)} \, dx & = \operatorname{Shi}(\operatorname{arcosh}(x)) + C, \\ \end{align}$$ where $\operatorname{Chi}$ is the hyperbolic cosine integral , and $\operatorname{Shi}$ is the hyperbolic sine integral . I found nothing with Maple or Mathematica . As I see some kind of ""hyperbolic tangent integral"" is not defined.",,"['calculus', 'integration', 'indefinite-integrals', 'closed-form']"
58,"Integrating $\int\frac{\sqrt{16x^2-9}}x\,\mathrm{d}x$?",Integrating ?,"\int\frac{\sqrt{16x^2-9}}x\,\mathrm{d}x","I am trying to differentiate from my previous question , but I am having trouble in the finishing steps. I have the integral $\int\dfrac{\sqrt{16x^2-9}}x\,\mathrm{d}x$ . $$v=4x\implies\mathrm{d}v=4\,\mathrm{d}x$$ $$\int\frac{\sqrt{v^2-9}}{v}\,\mathrm{d}v\implies a=3,\quad v=3\sec\theta,\quad\mathrm{d}v=3\sec\theta\tan\theta\,\mathrm{d}\theta.$$ $$v^2-9=9\sec^2\theta-9=9\left(\sec^2\theta-1\right)=9\tan^2\theta.$$ $$\int\frac{3\tan\theta\cdot3\sec\theta\tan\theta}{3\sec\theta}\,\mathrm{d}\theta=3\int\tan^2\theta\,\mathrm{d}\theta.$$ $$3\int\left(\sec^2\theta-1\right)\mathrm{d}\theta=3\left(\tan\theta-\theta\right).$$ And this where I feel I am going wrong. So from my understanding since I used $\sec\theta$ for the substitution the triangle I am using to use this integral has a hypotenuse of $v$ or $4x$ since I initially assigned that value to b and the adjacent side of $\theta$ is $a$ or $3$ , and for the missing side  I got $\sqrt{v^2-9}$ or $\sqrt{16x^2-9}$ . So for $\tan\theta$ I got $\dfrac{\sqrt{16x^2-9}}3$ and for $\theta$ I got $\sec^{-1}\left(\dfrac{v}3\right)$ or $\cos\left(\dfrac{4x}3\right)$ . So my final answer is $$\sqrt{16x^2-9}-3\cos\left(\frac{4x}3\right)$$ but this is wrong so if someone could tell me where I am going wrong it'd be greatly appreciated. Thanks in advance.","I am trying to differentiate from my previous question , but I am having trouble in the finishing steps. I have the integral . And this where I feel I am going wrong. So from my understanding since I used for the substitution the triangle I am using to use this integral has a hypotenuse of or since I initially assigned that value to b and the adjacent side of is or , and for the missing side  I got or . So for I got and for I got or . So my final answer is but this is wrong so if someone could tell me where I am going wrong it'd be greatly appreciated. Thanks in advance.","\int\dfrac{\sqrt{16x^2-9}}x\,\mathrm{d}x v=4x\implies\mathrm{d}v=4\,\mathrm{d}x \int\frac{\sqrt{v^2-9}}{v}\,\mathrm{d}v\implies a=3,\quad v=3\sec\theta,\quad\mathrm{d}v=3\sec\theta\tan\theta\,\mathrm{d}\theta. v^2-9=9\sec^2\theta-9=9\left(\sec^2\theta-1\right)=9\tan^2\theta. \int\frac{3\tan\theta\cdot3\sec\theta\tan\theta}{3\sec\theta}\,\mathrm{d}\theta=3\int\tan^2\theta\,\mathrm{d}\theta. 3\int\left(\sec^2\theta-1\right)\mathrm{d}\theta=3\left(\tan\theta-\theta\right). \sec\theta v 4x \theta a 3 \sqrt{v^2-9} \sqrt{16x^2-9} \tan\theta \dfrac{\sqrt{16x^2-9}}3 \theta \sec^{-1}\left(\dfrac{v}3\right) \cos\left(\dfrac{4x}3\right) \sqrt{16x^2-9}-3\cos\left(\frac{4x}3\right)","['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
59,"Is this proof correct? Divergence of $\int_{1}^{\infty} \left| \frac{\sin x}{x} \right| \, \mathrm{d}x $",Is this proof correct? Divergence of,"\int_{1}^{\infty} \left| \frac{\sin x}{x} \right| \, \mathrm{d}x ","Problem: Show that $$ \int_{1}^{\infty} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ diverges. I know that there are many questions in which this problem is solved, but I want to know if my proof is correct. My attempt. Since $$ \int_{1}^{\pi} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ converges, it suffices to show that $$ \int_{\pi}^{\infty} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ diverges. We can use $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x = \left[\sum_{n=1}^{\infty} \int_{2n\pi}^{(2n+1)\pi} \frac{\sin t}{t} \, \mathrm{d}t \right] - \left[\sum_{n=0}^{\infty} \int_{(2n+1)\pi}^{2(n+1)\pi} \frac{\sin \omega}{\omega} \,\mathrm{d}\omega \right] $$ With the substitution $x = t - 2n\pi \implies \mathrm{d}t = \mathrm{d}x$, $$\int_{2n\pi}^{(2n+1)\pi} \frac{\sin t}{t} \,\mathrm{d}t = \int_{0}^{\pi} \frac{\sin x}{x + 2n\pi} \,\mathrm{d}x $$ and, with the substitution $x = \omega - (2n+1)\pi \implies \mathrm{d}\omega = \mathrm{d}x$, $$ \int_{(2n+1)\pi}^{2(n+1)\pi} \frac{\sin \omega}{\omega}\,\mathrm{d}\omega = -\int_{0}^{\pi}\frac{\sin x}{x + (2n+1)\pi}\,\mathrm{d} x$$, then, $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x = \left[\int_{0}^{\pi}\sin x\sum_{n=1}^{\infty}\frac{1}{x + 2n\pi} \,\,\mathrm{d}x\right] + \left[\int_{0}^{\pi} \sin x \sum_{n=0}^{\infty}\frac{1}{x + (2n+1)\pi} \,\, \mathrm{d}x\right]$$ Since $x \in [0,\pi]$, both $\displaystyle{\sum_{n=1}^{\infty}\frac{1}{x + 2n\pi}}$ and $\displaystyle{\sum_{n=0}^{\infty}\frac{1}{x + (2n+1)\pi}}$ diverge, then the integral $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x $$  diverges. Therefore, the integral $$ \int_{1}^{\infty} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ will do so. $\square$ Edit: 08-12-14 at 00:38 Does this make the proof better in any way? $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x = \left[ \sum_{n=1}^{\infty}\int_{0}^{\pi}\frac{\sin x}{x+2n\pi}\,\mathrm{d}x \right] + \left[ \sum_{n=0}^{\infty}\int_{0}^{\pi}\frac{\sin x}{x+(2n+1)\pi}\,\mathrm{d}x \right]$$ Since $\forall\,x \in [0, \pi] \,\, \sin x \ge 0$, $n \ge 1$ and $ \dfrac{1}{\pi\left(2n+1\right)}\le \dfrac{1}{x + 2n\pi} \le \dfrac{1}{2n\pi} \,\, \forall\,x\in [0,\pi]$ we have $$ \underbrace{\dfrac{\sin x}{\pi\left(2n+1\right)}\le \dfrac{\sin x}{x + 2n\pi}}_{\text{(I)}} \le \dfrac{\sin x}{2n\pi} \,\, \forall\,x\in [0,\pi] $$ Integrating (I) from $0$ to $\pi$, we get $$ \int_{0}^{\pi} \frac{\sin x}{x + 2n\pi}\,\mathrm{d}x \ge \frac{2}{\pi} \frac{1}{2n+1} $$ Adding all the terms in $n$ and noting  that the series $\displaystyle{\sum_{n=1}^{\infty} \frac{1}{2n+1}}$ diverges, we conclude that the term between the first brackets blows up as $n \to \infty$. A similar procedure may be used to see what happens to the term between the other brackets, which will diverge also. Then, I think we can conclude more convincingly that the integral diverges. Am I right?","Problem: Show that $$ \int_{1}^{\infty} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ diverges. I know that there are many questions in which this problem is solved, but I want to know if my proof is correct. My attempt. Since $$ \int_{1}^{\pi} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ converges, it suffices to show that $$ \int_{\pi}^{\infty} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ diverges. We can use $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x = \left[\sum_{n=1}^{\infty} \int_{2n\pi}^{(2n+1)\pi} \frac{\sin t}{t} \, \mathrm{d}t \right] - \left[\sum_{n=0}^{\infty} \int_{(2n+1)\pi}^{2(n+1)\pi} \frac{\sin \omega}{\omega} \,\mathrm{d}\omega \right] $$ With the substitution $x = t - 2n\pi \implies \mathrm{d}t = \mathrm{d}x$, $$\int_{2n\pi}^{(2n+1)\pi} \frac{\sin t}{t} \,\mathrm{d}t = \int_{0}^{\pi} \frac{\sin x}{x + 2n\pi} \,\mathrm{d}x $$ and, with the substitution $x = \omega - (2n+1)\pi \implies \mathrm{d}\omega = \mathrm{d}x$, $$ \int_{(2n+1)\pi}^{2(n+1)\pi} \frac{\sin \omega}{\omega}\,\mathrm{d}\omega = -\int_{0}^{\pi}\frac{\sin x}{x + (2n+1)\pi}\,\mathrm{d} x$$, then, $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x = \left[\int_{0}^{\pi}\sin x\sum_{n=1}^{\infty}\frac{1}{x + 2n\pi} \,\,\mathrm{d}x\right] + \left[\int_{0}^{\pi} \sin x \sum_{n=0}^{\infty}\frac{1}{x + (2n+1)\pi} \,\, \mathrm{d}x\right]$$ Since $x \in [0,\pi]$, both $\displaystyle{\sum_{n=1}^{\infty}\frac{1}{x + 2n\pi}}$ and $\displaystyle{\sum_{n=0}^{\infty}\frac{1}{x + (2n+1)\pi}}$ diverge, then the integral $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x $$  diverges. Therefore, the integral $$ \int_{1}^{\infty} \left| \frac{\sin x}{x} \right| \,\mathrm{d}x $$ will do so. $\square$ Edit: 08-12-14 at 00:38 Does this make the proof better in any way? $$\int_{\pi}^{\infty} \left|\frac{\sin x}{x} \right| \,\mathrm{d}x = \left[ \sum_{n=1}^{\infty}\int_{0}^{\pi}\frac{\sin x}{x+2n\pi}\,\mathrm{d}x \right] + \left[ \sum_{n=0}^{\infty}\int_{0}^{\pi}\frac{\sin x}{x+(2n+1)\pi}\,\mathrm{d}x \right]$$ Since $\forall\,x \in [0, \pi] \,\, \sin x \ge 0$, $n \ge 1$ and $ \dfrac{1}{\pi\left(2n+1\right)}\le \dfrac{1}{x + 2n\pi} \le \dfrac{1}{2n\pi} \,\, \forall\,x\in [0,\pi]$ we have $$ \underbrace{\dfrac{\sin x}{\pi\left(2n+1\right)}\le \dfrac{\sin x}{x + 2n\pi}}_{\text{(I)}} \le \dfrac{\sin x}{2n\pi} \,\, \forall\,x\in [0,\pi] $$ Integrating (I) from $0$ to $\pi$, we get $$ \int_{0}^{\pi} \frac{\sin x}{x + 2n\pi}\,\mathrm{d}x \ge \frac{2}{\pi} \frac{1}{2n+1} $$ Adding all the terms in $n$ and noting  that the series $\displaystyle{\sum_{n=1}^{\infty} \frac{1}{2n+1}}$ diverges, we conclude that the term between the first brackets blows up as $n \to \infty$. A similar procedure may be used to see what happens to the term between the other brackets, which will diverge also. Then, I think we can conclude more convincingly that the integral diverges. Am I right?",,"['calculus', 'integration', 'proof-verification', 'improper-integrals']"
60,"$\int_0^1\frac{1-t}{(t-2)\ln t}\,dt$ integral",integral,"\int_0^1\frac{1-t}{(t-2)\ln t}\,dt","I have two related questions. The first is: Is there a closed form expression for: $$\int_0^1\frac{1-t}{(t-2)\ln t}\,dt\approx0.507834$$ I know that there are some very superb integrators on this site. I doubt that a closed form exists, but I may be wrong. If I'm wrong, I'm curious as to how you got your answer! (P.S. This page gives me hope that it might be expressable in terms of $\zeta(\cdot)$. If so, I'd consider that to be ""closed form."") Second question: Is there an elementary function $f(t)$ such that: $$\exp\left(\int_0^1\frac{1-t}{(t-2)\ln t}\,dt\right)=\int_0^1f(t)dt$$ That value is approximately $1.66169$. I am very interested in this value. The expression on the left is a great way to express this number. But, I feel like it would be ""cleaner"" if I could express it simply as an integral, like on the right.","I have two related questions. The first is: Is there a closed form expression for: $$\int_0^1\frac{1-t}{(t-2)\ln t}\,dt\approx0.507834$$ I know that there are some very superb integrators on this site. I doubt that a closed form exists, but I may be wrong. If I'm wrong, I'm curious as to how you got your answer! (P.S. This page gives me hope that it might be expressable in terms of $\zeta(\cdot)$. If so, I'd consider that to be ""closed form."") Second question: Is there an elementary function $f(t)$ such that: $$\exp\left(\int_0^1\frac{1-t}{(t-2)\ln t}\,dt\right)=\int_0^1f(t)dt$$ That value is approximately $1.66169$. I am very interested in this value. The expression on the left is a great way to express this number. But, I feel like it would be ""cleaner"" if I could express it simply as an integral, like on the right.",,"['calculus', 'integration', 'definite-integrals', 'logarithms']"
61,Maximum value problem,Maximum value problem,,"A function $\hspace{0.1cm}$$f:[0,1]\to[-1,1]$$\hspace{0.1cm}$ satisfying$\hspace{0.1cm}$ $|f(x)|\leq x$$\hspace{0.1cm}$ $\forall x\in[0,1]$. Then find the maximum value of: $|\int_{0}^{1}(f^2(x)-f(x))dx|$ My attempt: $|\int_{0}^{1}(f^2(x)-f(x))dx|\leq \int_{0}^{1}|f^2(x)-f(x)|dx\leq \int_{0}^{1}(|f^2(x)|-|f(x)|)dx\leq \int_{0}^{1}(x^2-x)dx=-\frac{1}{6}$ But it is not possible because absolute value is always greater than equal to zero.Please someone help me to find its maximum value.Thanks","A function $\hspace{0.1cm}$$f:[0,1]\to[-1,1]$$\hspace{0.1cm}$ satisfying$\hspace{0.1cm}$ $|f(x)|\leq x$$\hspace{0.1cm}$ $\forall x\in[0,1]$. Then find the maximum value of: $|\int_{0}^{1}(f^2(x)-f(x))dx|$ My attempt: $|\int_{0}^{1}(f^2(x)-f(x))dx|\leq \int_{0}^{1}|f^2(x)-f(x)|dx\leq \int_{0}^{1}(|f^2(x)|-|f(x)|)dx\leq \int_{0}^{1}(x^2-x)dx=-\frac{1}{6}$ But it is not possible because absolute value is always greater than equal to zero.Please someone help me to find its maximum value.Thanks",,"['calculus', 'integration', 'definite-integrals', 'absolute-value']"
62,How to calculate the length of a cubic hermite spline between two points,How to calculate the length of a cubic hermite spline between two points,,"I am using the following equation to create a cubic hermite spline: $$p_n(t) = a_nt^3+b_nt^2+c_nt+d_n$$ $$1\geq t\geq 0$$ $p_n(t)$ is the unit interval interpolation equation for dimension n. $t$ is the parametric variable. This was rearranged from Wikipedia and I simplified the equation as the implementation is unimportant here. I need to calculate the length of the interpolated spline and for that I am using the following equation to calculate the length: $$ s = \int_0^1 \sqrt[2]{\dot{p}_x(t)^2+\dot{p}_y(t)^2+\dot{p}_z(t)^2} dt $$ $$\dot{p}_n(t) = 3a_nt^2+2b_nt+c_n$$ $\dot{p}_n(t)$ is the first derivative of the interpolation equation with respect to $t$. After subbing in all the relevant equations I get the following: $$s = \int_0^1 \sqrt[2]{9(\boldsymbol{A}\cdot\boldsymbol{A})t^4 + 12(\boldsymbol{A}\cdot\boldsymbol{B})t^3 + (6(\boldsymbol{A}\cdot\boldsymbol{C})+4(\boldsymbol{B}\cdot\boldsymbol{B}))t^2 + 4(\boldsymbol{B}\cdot\boldsymbol{C})t + \boldsymbol{C}\cdot\boldsymbol{C}} dt$$ $$\boldsymbol{A} = \begin{pmatrix}a_x\\a_y\\a_z\end{pmatrix}$$ I vectorised it for brevity and it also lets me do a sneaky trick (atleast I think its a sneak trick). I noticed that the polynomial inside the square root looked similar to $\dot{p}_n(t)^2$ and since $\boldsymbol{A}\cdot\boldsymbol{A}=|\boldsymbol{A}|^2$I figured the following is possible: $$s = \int_0^1 \sqrt[2]{(3\boldsymbol{|A|}t^2 + 2\boldsymbol{|B|}t + \boldsymbol{|C|})^2} dt$$ After integrating I get the following solution: $$s=\boldsymbol{|A|}+\boldsymbol{|B|}+\boldsymbol{|C|}$$ However, on implementing this I find that the values it produces are wrong. In the image below the straight green line in the centre of the image has a length of approximately 6 units and the solution I derived gives a spline length of 15 units. If the spline did have a length of 15 units then it should follow a path similar to a semi-circle. I'm not entirely sure where I went wrong here, my best guess is that missed something when I vectorised the equation but I can't seem to figure out what I did wrong. I would appreciate any help. Note: The spline is described by the path of squares which go from one end of a line to another.","I am using the following equation to create a cubic hermite spline: $$p_n(t) = a_nt^3+b_nt^2+c_nt+d_n$$ $$1\geq t\geq 0$$ $p_n(t)$ is the unit interval interpolation equation for dimension n. $t$ is the parametric variable. This was rearranged from Wikipedia and I simplified the equation as the implementation is unimportant here. I need to calculate the length of the interpolated spline and for that I am using the following equation to calculate the length: $$ s = \int_0^1 \sqrt[2]{\dot{p}_x(t)^2+\dot{p}_y(t)^2+\dot{p}_z(t)^2} dt $$ $$\dot{p}_n(t) = 3a_nt^2+2b_nt+c_n$$ $\dot{p}_n(t)$ is the first derivative of the interpolation equation with respect to $t$. After subbing in all the relevant equations I get the following: $$s = \int_0^1 \sqrt[2]{9(\boldsymbol{A}\cdot\boldsymbol{A})t^4 + 12(\boldsymbol{A}\cdot\boldsymbol{B})t^3 + (6(\boldsymbol{A}\cdot\boldsymbol{C})+4(\boldsymbol{B}\cdot\boldsymbol{B}))t^2 + 4(\boldsymbol{B}\cdot\boldsymbol{C})t + \boldsymbol{C}\cdot\boldsymbol{C}} dt$$ $$\boldsymbol{A} = \begin{pmatrix}a_x\\a_y\\a_z\end{pmatrix}$$ I vectorised it for brevity and it also lets me do a sneaky trick (atleast I think its a sneak trick). I noticed that the polynomial inside the square root looked similar to $\dot{p}_n(t)^2$ and since $\boldsymbol{A}\cdot\boldsymbol{A}=|\boldsymbol{A}|^2$I figured the following is possible: $$s = \int_0^1 \sqrt[2]{(3\boldsymbol{|A|}t^2 + 2\boldsymbol{|B|}t + \boldsymbol{|C|})^2} dt$$ After integrating I get the following solution: $$s=\boldsymbol{|A|}+\boldsymbol{|B|}+\boldsymbol{|C|}$$ However, on implementing this I find that the values it produces are wrong. In the image below the straight green line in the centre of the image has a length of approximately 6 units and the solution I derived gives a spline length of 15 units. If the spline did have a length of 15 units then it should follow a path similar to a semi-circle. I'm not entirely sure where I went wrong here, my best guess is that missed something when I vectorised the equation but I can't seem to figure out what I did wrong. I would appreciate any help. Note: The spline is described by the path of squares which go from one end of a line to another.",,"['integration', 'interpolation', 'spline', 'cubics']"
63,Proof that $J_{\nu}(x) \sim (x/2)^\nu / \Gamma(\nu+1) \; \text{as} \; \nu \rightarrow \infty$,Proof that,J_{\nu}(x) \sim (x/2)^\nu / \Gamma(\nu+1) \; \text{as} \; \nu \rightarrow \infty,"I'm working through the exercises of Bender and Orszag's famous book, but I got stuck in 6.25 (a) , in which it is asked to prove that $$J_\nu (x) \sim (x/2)^\nu / \Gamma(\nu+1) \; \text{as} \; \nu \rightarrow \infty,$$ by using the following integral representation $$J_\nu(x)=\frac{(x/2)^\nu}{\sqrt{\pi}\Gamma(\nu+1/2)} \int^\pi_0 \cos(x\cos\theta) \sin^{2\nu}\theta \, d\theta,$$ which is valid for $\nu > -1/2.$ ($J_\nu(x)$ is the $\nu$th-order Bessel function of the first kind.) As the exercise belongs to section 6.4, which deals with Laplace's method and Watson's lemma, I thought I first had to perform a change of variables in order to get an integral of the form $$I(x)=\int^b_a f(t)e^{x\phi(t)} \, dt.$$ So, I took $t=\cos\theta$ and obtained $$\frac{(x/2)^\nu}{\sqrt{\pi}\Gamma(\nu+1/2)} \int^{1}_{-1} (1-t^2)^{p-\frac{1}{2}} e^{ixt} \, dt.$$ However, I cannot apply either Laplace's method or Watson's lemma, because the function $\phi$ I got is complex: $\phi(t)=it$. What am I missing?","I'm working through the exercises of Bender and Orszag's famous book, but I got stuck in 6.25 (a) , in which it is asked to prove that $$J_\nu (x) \sim (x/2)^\nu / \Gamma(\nu+1) \; \text{as} \; \nu \rightarrow \infty,$$ by using the following integral representation $$J_\nu(x)=\frac{(x/2)^\nu}{\sqrt{\pi}\Gamma(\nu+1/2)} \int^\pi_0 \cos(x\cos\theta) \sin^{2\nu}\theta \, d\theta,$$ which is valid for $\nu > -1/2.$ ($J_\nu(x)$ is the $\nu$th-order Bessel function of the first kind.) As the exercise belongs to section 6.4, which deals with Laplace's method and Watson's lemma, I thought I first had to perform a change of variables in order to get an integral of the form $$I(x)=\int^b_a f(t)e^{x\phi(t)} \, dt.$$ So, I took $t=\cos\theta$ and obtained $$\frac{(x/2)^\nu}{\sqrt{\pi}\Gamma(\nu+1/2)} \int^{1}_{-1} (1-t^2)^{p-\frac{1}{2}} e^{ixt} \, dt.$$ However, I cannot apply either Laplace's method or Watson's lemma, because the function $\phi$ I got is complex: $\phi(t)=it$. What am I missing?",,"['integration', 'analysis', 'definite-integrals', 'asymptotics', 'special-functions']"
64,Problem with a sequence with multiple integrals [duplicate],Problem with a sequence with multiple integrals [duplicate],,"This question already has answers here : How prove this integral limit $=f(\frac{1}{2})$ (4 answers) Closed 10 years ago . How to compute the following limit, $\displaystyle \lim\limits_{n \to \infty} \int_0^1 \int_0^1 \ldots \int_0^1 \sin \bigg(\frac{x_1+x_2+\ldots+x_n}{n}\bigg)\,dx_1 \,dx_2 \ldots \,dx_n$ ? I will greatly appreciate it if a solution only uses analysis. Thank you.","This question already has answers here : How prove this integral limit $=f(\frac{1}{2})$ (4 answers) Closed 10 years ago . How to compute the following limit, $\displaystyle \lim\limits_{n \to \infty} \int_0^1 \int_0^1 \ldots \int_0^1 \sin \bigg(\frac{x_1+x_2+\ldots+x_n}{n}\bigg)\,dx_1 \,dx_2 \ldots \,dx_n$ ? I will greatly appreciate it if a solution only uses analysis. Thank you.",,"['integration', 'analysis', 'limits', 'multivariable-calculus']"
65,Prove that $\int_0^{\infty}\int_0^{\infty}e^{-(x^2 + 2xy\cos(\alpha)+y^2)}\mathrm dx\mathrm dy=\frac{\alpha}{2\sin(\alpha)}$,Prove that,\int_0^{\infty}\int_0^{\infty}e^{-(x^2 + 2xy\cos(\alpha)+y^2)}\mathrm dx\mathrm dy=\frac{\alpha}{2\sin(\alpha)},"I'm having difficulty with a question. It says By putting $x=r\cos(\theta), y=r\sin(\theta)$ , prove that $$\int_0^{\infty}\int_0^{\infty}e^{-(x^2 + 2xy\cos(\alpha)+y^2)}\mathrm dx\mathrm dy=\frac{\alpha}{2\sin(\alpha)}$$ Making the substitution we get \begin{align*}&\int_0^{\pi/2}\int_0^{\infty}re^{-r^2 (\sin(2\theta) \cos(\alpha) + 1)}dr\ d\theta \\ \\ =&\int_0^{\pi/2} \frac{1}{2(\sin(2\theta) \cos(\alpha) + 1)} d\theta\\ \\ =&\frac{\alpha}{2\sin(\alpha)} \int_0^{\pi/2} \frac{\sin(\alpha)}{2 \alpha \cos(\alpha) \sin(\theta) \cos(\theta) + \alpha} d\theta\\ \\ =&\frac{\alpha}{2\sin(\alpha)} \int_0^{\pi/2}\frac{\tan(\alpha) \sec^2(\theta)}{2 \alpha \tan(\theta) + \alpha \sec(\alpha) \sec^2(\theta)} d\theta \end{align*} setting $u=\tan(\theta),\ du=\sec^2(\theta)\ d\theta$ $$=\frac{\alpha}{2\sin(\alpha)}\int_0^{\infty}\frac{\tan(\alpha)\ du}{\alpha \sec(\alpha) + 2\alpha u+ \alpha \sec(\alpha) u^2}$$ Now \begin{align*}u&=\frac{\cos(\alpha)\{-2\alpha\pm\sqrt{4\alpha ^2 - 4\alpha ^2\sec^2(\alpha)}\}}{2\alpha}\\ \\ &=-\cos(\alpha) \mp i\sin(\alpha)\\ &=-e^{\pm i\alpha} \end{align*} So substituting in \begin{align*} =&\frac{\alpha}{2\sin(\alpha)}\int_0^{\infty}\frac{\tan(\alpha)\ du}{(u-e^{i\alpha})(u-e^{- i\alpha})}\\ \\ =&\frac{\alpha}{2\sin(\alpha)}\left[ \frac{\tan(\alpha)\{\log(1-ue^{i\alpha}) - \log(-u+e^{i\alpha})\}}{-1+e^{2i\alpha}} \right]^{\infty}_{u\, =\, 0} \end{align*} which I then can't evaluate (and certainly isn't $1$ ). Any help?","I'm having difficulty with a question. It says By putting , prove that Making the substitution we get setting Now So substituting in which I then can't evaluate (and certainly isn't ). Any help?","x=r\cos(\theta), y=r\sin(\theta) \int_0^{\infty}\int_0^{\infty}e^{-(x^2 + 2xy\cos(\alpha)+y^2)}\mathrm dx\mathrm dy=\frac{\alpha}{2\sin(\alpha)} \begin{align*}&\int_0^{\pi/2}\int_0^{\infty}re^{-r^2 (\sin(2\theta) \cos(\alpha) + 1)}dr\ d\theta \\ \\
=&\int_0^{\pi/2} \frac{1}{2(\sin(2\theta) \cos(\alpha) + 1)} d\theta\\ \\
=&\frac{\alpha}{2\sin(\alpha)} \int_0^{\pi/2} \frac{\sin(\alpha)}{2 \alpha \cos(\alpha) \sin(\theta) \cos(\theta) + \alpha} d\theta\\ \\
=&\frac{\alpha}{2\sin(\alpha)} \int_0^{\pi/2}\frac{\tan(\alpha) \sec^2(\theta)}{2 \alpha \tan(\theta) + \alpha \sec(\alpha) \sec^2(\theta)} d\theta
\end{align*} u=\tan(\theta),\ du=\sec^2(\theta)\ d\theta =\frac{\alpha}{2\sin(\alpha)}\int_0^{\infty}\frac{\tan(\alpha)\ du}{\alpha \sec(\alpha) + 2\alpha u+ \alpha \sec(\alpha) u^2} \begin{align*}u&=\frac{\cos(\alpha)\{-2\alpha\pm\sqrt{4\alpha ^2 - 4\alpha ^2\sec^2(\alpha)}\}}{2\alpha}\\ \\
&=-\cos(\alpha) \mp i\sin(\alpha)\\
&=-e^{\pm i\alpha}
\end{align*} \begin{align*}
=&\frac{\alpha}{2\sin(\alpha)}\int_0^{\infty}\frac{\tan(\alpha)\ du}{(u-e^{i\alpha})(u-e^{- i\alpha})}\\ \\
=&\frac{\alpha}{2\sin(\alpha)}\left[ \frac{\tan(\alpha)\{\log(1-ue^{i\alpha}) - \log(-u+e^{i\alpha})\}}{-1+e^{2i\alpha}} \right]^{\infty}_{u\, =\, 0}
\end{align*} 1","['integration', 'multivariable-calculus', 'polar-coordinates']"
66,Show that $g\in\mathcal{L}^q(\mu)$.,Show that .,g\in\mathcal{L}^q(\mu),"Let $(X,\mathcal{A},\mu$) be a finite measure space and $p,q\in(0,\infty)$ such that $1/p+1/q=1$. Let $g\in\mathcal{M}(\mathcal{A})$ measurable function such that $$\int |fg|d\mu\leq C\|f\|_p$$ for all $f\in\mathcal{L}^p(\mu)$ and some constant $C$. Show that $g\in\mathcal{L}^q(\mu)$ I understand that Holder's Inequality does the reverse argument with $C=\|g\|_q$, but i don't know how to bend this into a proof.","Let $(X,\mathcal{A},\mu$) be a finite measure space and $p,q\in(0,\infty)$ such that $1/p+1/q=1$. Let $g\in\mathcal{M}(\mathcal{A})$ measurable function such that $$\int |fg|d\mu\leq C\|f\|_p$$ for all $f\in\mathcal{L}^p(\mu)$ and some constant $C$. Show that $g\in\mathcal{L}^q(\mu)$ I understand that Holder's Inequality does the reverse argument with $C=\|g\|_q$, but i don't know how to bend this into a proof.",,"['integration', 'measure-theory']"
67,How to resolve this integration $\int\frac{dx}{1+x^2+\sin^2x}$?,How to resolve this integration ?,\int\frac{dx}{1+x^2+\sin^2x},"I have tried Trigonometric Substitution, but I can´t get an already known function to be easy for integrate: $$\int\frac{dx}{1+x^2+\sin^2x}$$ I entered this on Wolfram and it gave me the same function. I'm not asking for the exact solution, just a good way to solve it. Regards.","I have tried Trigonometric Substitution, but I can´t get an already known function to be easy for integrate: $$\int\frac{dx}{1+x^2+\sin^2x}$$ I entered this on Wolfram and it gave me the same function. I'm not asking for the exact solution, just a good way to solve it. Regards.",,"['calculus', 'integration', 'indefinite-integrals']"
68,"For which $L^p[0,1]$, $1\le p < \infty$ does the function $n^\alpha*\chi_{[0,1/n]}$ converge weakly to 0?","For which ,  does the function  converge weakly to 0?","L^p[0,1] 1\le p < \infty n^\alpha*\chi_{[0,1/n]}","My hypothesis is that this function converges to 0 weakly iff $ p < 1/\alpha$, but I am not sure how to prove this. We are working in the space $[0,1]$ with the Borel sets and Lebesgue measure. I can fairly easily show that it does weakly converge when $p < 1/\alpha$ but am not sure how to show the reverse direction. Help?","My hypothesis is that this function converges to 0 weakly iff $ p < 1/\alpha$, but I am not sure how to prove this. We are working in the space $[0,1]$ with the Borel sets and Lebesgue measure. I can fairly easily show that it does weakly converge when $p < 1/\alpha$ but am not sure how to show the reverse direction. Help?",,"['integration', 'functional-analysis', 'measure-theory', 'lebesgue-integral', 'weak-convergence']"
69,Distribution of stochastic integral,Distribution of stochastic integral,,"Assume that $\mathrm{d}S = \sigma \, \mathrm{d}W$ with initial level $S(0)$ and where $\mathrm{d}W$ is usual Brownian motion. Now $$A(T) = \frac{1}{T} \int_0^T S(t) \, \mathrm{d}t.$$ What is the distribution of $A(T)$ ? Solution: $$S(t) = S(0) \, \sigma \, W(t) \sim \mathcal{N}(0, \sqrt{S(0)}\sigma^2t)$$ so $$A(T) = \frac{1}{T} \int_0^T S(0) \, \sigma \, W(t) \, \mathrm{d}t$$ .... and now I'm confused. Any help appreciated.",Assume that with initial level and where is usual Brownian motion. Now What is the distribution of ? Solution: so .... and now I'm confused. Any help appreciated.,"\mathrm{d}S = \sigma \, \mathrm{d}W S(0) \mathrm{d}W A(T) = \frac{1}{T} \int_0^T S(t) \, \mathrm{d}t. A(T) S(t) = S(0) \, \sigma \, W(t) \sim \mathcal{N}(0, \sqrt{S(0)}\sigma^2t) A(T) = \frac{1}{T} \int_0^T S(0) \, \sigma \, W(t) \, \mathrm{d}t","['integration', 'probability-distributions', 'stochastic-calculus', 'brownian-motion']"
70,Gamma function in the sight of Lebesgue and Riemann integration.,Gamma function in the sight of Lebesgue and Riemann integration.,,"I am taking a somewhat hard measure theory course and I was asked to prove this: a) Let $\alpha > 0$ be a real number. Prove that  $$\Gamma(\alpha):=\int_0^\infty e^{-x}x^{\alpha-1}dx$$  exists. (We are studying the relationship between being Lebesgue-integrable and Riemann-integrable, so I am not quite sure what kind of integral should I prove exists, but I suspect it's the latter). b)Prove that: $$\lim_{n\to\infty}\int_0^n \left( 1-\frac{x}{n}\right)^n x^{\alpha-1}dx=\Gamma(\alpha).$$ Hint: $(1-\frac{x}{n})^n\le (1-\frac{x}{n+1})^{n+1}$ whenever $\frac{x}{n}<1$. This reeks of some limit theorem such as Monotone Convergence, Fatou or Lebesgue's Dominated Convergence, but those apply to Lebesgue-integrable functions. I the inequality stated in the hints makes me think I should use Monotone Convergence. Any insight would be greatly appreciated. We are using Bartle's Measure Theory Book and we are more or less around the $\mathcal{L}_p$ spaces part. Thank you in advance.","I am taking a somewhat hard measure theory course and I was asked to prove this: a) Let $\alpha > 0$ be a real number. Prove that  $$\Gamma(\alpha):=\int_0^\infty e^{-x}x^{\alpha-1}dx$$  exists. (We are studying the relationship between being Lebesgue-integrable and Riemann-integrable, so I am not quite sure what kind of integral should I prove exists, but I suspect it's the latter). b)Prove that: $$\lim_{n\to\infty}\int_0^n \left( 1-\frac{x}{n}\right)^n x^{\alpha-1}dx=\Gamma(\alpha).$$ Hint: $(1-\frac{x}{n})^n\le (1-\frac{x}{n+1})^{n+1}$ whenever $\frac{x}{n}<1$. This reeks of some limit theorem such as Monotone Convergence, Fatou or Lebesgue's Dominated Convergence, but those apply to Lebesgue-integrable functions. I the inequality stated in the hints makes me think I should use Monotone Convergence. Any insight would be greatly appreciated. We are using Bartle's Measure Theory Book and we are more or less around the $\mathcal{L}_p$ spaces part. Thank you in advance.",,"['integration', 'lebesgue-integral', 'gamma-function']"
71,Absolute and Conditional Convergence of the integral $\frac{\sin(x)}{x^p}$ for real values of $p$ [duplicate],Absolute and Conditional Convergence of the integral  for real values of  [duplicate],\frac{\sin(x)}{x^p} p,"This question already has answers here : Convergence $I=\int_0^\infty \frac{\sin x}{x^s}dx$ [duplicate] (5 answers) Closed 10 years ago . I need to determine the values of p for which this integral converges conditionally and absolutely. $$\int_{0}^{\infty} \dfrac{\sin(x)}{x^p} dx $$ I think the interval for conditional convergence is $0 < x < 2$ and for absolute convergence the interval is probably $0 < x < 1$. I'm guessing that I need to somehow compare it with the $\dfrac{1}{x^p}$ integral, but I am not sure exactly where to begin and how to logically proceed. I first thought about dividing the integral into two separate improper integrals, with one of them integrating from $0$ to $1$ and the other from $1$ to infinity, but I do not know how to continue from that point on.","This question already has answers here : Convergence $I=\int_0^\infty \frac{\sin x}{x^s}dx$ [duplicate] (5 answers) Closed 10 years ago . I need to determine the values of p for which this integral converges conditionally and absolutely. $$\int_{0}^{\infty} \dfrac{\sin(x)}{x^p} dx $$ I think the interval for conditional convergence is $0 < x < 2$ and for absolute convergence the interval is probably $0 < x < 1$. I'm guessing that I need to somehow compare it with the $\dfrac{1}{x^p}$ integral, but I am not sure exactly where to begin and how to logically proceed. I first thought about dividing the integral into two separate improper integrals, with one of them integrating from $0$ to $1$ and the other from $1$ to infinity, but I do not know how to continue from that point on.",,['calculus']
72,Evaluating $\int{\frac{1}{\sqrt{x^2+y^2}}\mathrm dx}$,Evaluating,\int{\frac{1}{\sqrt{x^2+y^2}}\mathrm dx},"Attempting to calculate $\displaystyle \int{\dfrac{1}{\sqrt{x^2+y^2}}\mathrm dx}$, $$\int{\dfrac{1}{\sqrt{x^2+y^2}}\mathrm dx}=\int{\frac{1}{\sqrt{(y\tan\theta)^2+y^2}}y\sec^2\theta \mathrm d\theta}=\int{\sec\theta d\theta}=\ln(\sec\theta +\tan\theta)=\ln\left(\sqrt{\left(\frac{x}{y}\right)^2+1}+\frac{x}{y}\right)=\ln\left(\frac{1}{x}\left(\sqrt{x^2+y^2}+x\right)\right),$$ where $x=y\tan\theta$ However Wolfram Integrator somehow returns $$\ln\left(2\left(\sqrt{x^2+y^2}+x\right)\right)$$ as the answer. Where did I go wrong? Many thanks.","Attempting to calculate $\displaystyle \int{\dfrac{1}{\sqrt{x^2+y^2}}\mathrm dx}$, $$\int{\dfrac{1}{\sqrt{x^2+y^2}}\mathrm dx}=\int{\frac{1}{\sqrt{(y\tan\theta)^2+y^2}}y\sec^2\theta \mathrm d\theta}=\int{\sec\theta d\theta}=\ln(\sec\theta +\tan\theta)=\ln\left(\sqrt{\left(\frac{x}{y}\right)^2+1}+\frac{x}{y}\right)=\ln\left(\frac{1}{x}\left(\sqrt{x^2+y^2}+x\right)\right),$$ where $x=y\tan\theta$ However Wolfram Integrator somehow returns $$\ln\left(2\left(\sqrt{x^2+y^2}+x\right)\right)$$ as the answer. Where did I go wrong? Many thanks.",,['integration']
73,Heat equation with Neumann boundary condition,Heat equation with Neumann boundary condition,,"Background: In our PDE class we explored the heat equation with Dirichlet boundary condition $$u_t - \Delta u = 0 \;\text{ in } \Omega \subset \mathbb{R}^n \;\text{bounded}\\ u = u_0(x) \;\,\text{at} \; \,t=0\\ u = 0  \;\, \text{at} \;\, \partial \Omega$$ Multiplying by $u$ on both sides and using the divergence theorem gives us $$\frac12 \frac{d}{dt}\int_{\Omega}u^2 + \int_{\Omega}|\nabla u|^2 = 0 \tag{1}$$ Now since the function $u$ is zero on the boundary, we can employ Poincare's inequality and say that $$-\int_{\Omega}|\nabla u|^2 \leq \frac{-1}{C_{\Omega}}\int_{\Omega}|u|^2,$$ which together with (1) gives that $$\frac12 \frac{d}{dt}\int_{\Omega}u^2 \leq \frac{-1}{C_{\Omega}}\int_{\Omega}|u|^2,$$ so $\int_{\Omega}u^2$ decays exponentially to $0$ as $t \to \infty$. Question: Having concluded that $\int_{\Omega}u^2$ decays exponentially, we are asked to prove an analogous statement for a homogeneous Neumann boundary condition which says that $$\frac{\partial u}{\partial \vec{\nu}}=0 \;\, \text{at} \;\, \partial\Omega, $$ for $\vec{\nu}$ the normal vector to the boundary. We are given the hint that there is a constant $M_{\Omega}$ with the property that if $u: \Omega \to \mathbb{R}$ has mean value $0$ then $\int_{\Omega} u^2 \, dx \leq M_{\Omega} \int_{\Omega} |\nabla u|^2 \, dx$. Now, I understand $u$ having mean value zero to mean that $\int_{\Omega} u \, dx=0$. One way to achieve that might be to subtract (the function of $t$) $\int_{\Omega}u\,dx$ from $u$, so that $v : = u - \int_{\Omega}u\,dx$ has mean value zero for all $t$. But this seems to screw things up when we try to square $v$. How can we use the Neumann boundary condition to find out something regarding the mean value of $u$? For instance, the divergence theorem would tell us $$\int_{\partial \Omega} u\cdot \vec{\nu} \, ds = \int_{\Omega} \nabla \cdot u \, dx.$$ The left side here is zero, I believe, but I'm not sure that tells us anything about the mean value. Could someone help me see the next step? I'm stuck.","Background: In our PDE class we explored the heat equation with Dirichlet boundary condition $$u_t - \Delta u = 0 \;\text{ in } \Omega \subset \mathbb{R}^n \;\text{bounded}\\ u = u_0(x) \;\,\text{at} \; \,t=0\\ u = 0  \;\, \text{at} \;\, \partial \Omega$$ Multiplying by $u$ on both sides and using the divergence theorem gives us $$\frac12 \frac{d}{dt}\int_{\Omega}u^2 + \int_{\Omega}|\nabla u|^2 = 0 \tag{1}$$ Now since the function $u$ is zero on the boundary, we can employ Poincare's inequality and say that $$-\int_{\Omega}|\nabla u|^2 \leq \frac{-1}{C_{\Omega}}\int_{\Omega}|u|^2,$$ which together with (1) gives that $$\frac12 \frac{d}{dt}\int_{\Omega}u^2 \leq \frac{-1}{C_{\Omega}}\int_{\Omega}|u|^2,$$ so $\int_{\Omega}u^2$ decays exponentially to $0$ as $t \to \infty$. Question: Having concluded that $\int_{\Omega}u^2$ decays exponentially, we are asked to prove an analogous statement for a homogeneous Neumann boundary condition which says that $$\frac{\partial u}{\partial \vec{\nu}}=0 \;\, \text{at} \;\, \partial\Omega, $$ for $\vec{\nu}$ the normal vector to the boundary. We are given the hint that there is a constant $M_{\Omega}$ with the property that if $u: \Omega \to \mathbb{R}$ has mean value $0$ then $\int_{\Omega} u^2 \, dx \leq M_{\Omega} \int_{\Omega} |\nabla u|^2 \, dx$. Now, I understand $u$ having mean value zero to mean that $\int_{\Omega} u \, dx=0$. One way to achieve that might be to subtract (the function of $t$) $\int_{\Omega}u\,dx$ from $u$, so that $v : = u - \int_{\Omega}u\,dx$ has mean value zero for all $t$. But this seems to screw things up when we try to square $v$. How can we use the Neumann boundary condition to find out something regarding the mean value of $u$? For instance, the divergence theorem would tell us $$\int_{\partial \Omega} u\cdot \vec{\nu} \, ds = \int_{\Omega} \nabla \cdot u \, dx.$$ The left side here is zero, I believe, but I'm not sure that tells us anything about the mean value. Could someone help me see the next step? I'm stuck.",,"['multivariable-calculus', 'integration', 'partial-differential-equations', 'derivatives']"
74,Let $x>0$. Calculate $\lim_{R\rightarrow\infty} \int_{\frac{1}{2}-iR}^{\frac{1}{2}+iR}\frac{x^s}{s}ds$,Let . Calculate,x>0 \lim_{R\rightarrow\infty} \int_{\frac{1}{2}-iR}^{\frac{1}{2}+iR}\frac{x^s}{s}ds,"Let $x>0$. Calculate: $$\lim_{R\rightarrow\infty} \int_{\frac{1}{2}-iR}^{\frac{1}{2}+iR}\frac{x^s}{s}ds$$ for $x=1$ it is quite simple. Otherwise, I used the following contours: The left one when $x>1$ and the right one when $0<x<1$. Let us discuss the case $x>1$. The integral on $\Gamma_1$ is what we want. The integral on $\Gamma_3$ vanishes since: $$\bigg| \int_{\Gamma_3}f(s)\bigg|\leq \int_{\Gamma_3}|f(s)| \leq 2R \bigg|\frac{x^s}{s}\bigg| \leq 2R \frac{e^{\ln x \Re s}}{\sqrt{2}R}=\sqrt{2}e^ {-R\ln x} \rightarrow 0$$ But I have no idea what to do with $\Gamma_2$ and $\Gamma_4$.","Let $x>0$. Calculate: $$\lim_{R\rightarrow\infty} \int_{\frac{1}{2}-iR}^{\frac{1}{2}+iR}\frac{x^s}{s}ds$$ for $x=1$ it is quite simple. Otherwise, I used the following contours: The left one when $x>1$ and the right one when $0<x<1$. Let us discuss the case $x>1$. The integral on $\Gamma_1$ is what we want. The integral on $\Gamma_3$ vanishes since: $$\bigg| \int_{\Gamma_3}f(s)\bigg|\leq \int_{\Gamma_3}|f(s)| \leq 2R \bigg|\frac{x^s}{s}\bigg| \leq 2R \frac{e^{\ln x \Re s}}{\sqrt{2}R}=\sqrt{2}e^ {-R\ln x} \rightarrow 0$$ But I have no idea what to do with $\Gamma_2$ and $\Gamma_4$.",,"['complex-analysis', 'integration', 'definite-integrals']"
75,Closed form for the series $\sum\limits_{n=0}^\infty \frac{\exp(\cos(n))}{n!}$,Closed form for the series,\sum\limits_{n=0}^\infty \frac{\exp(\cos(n))}{n!},Does anyone have any ideas on how to find a closed form for the following expression? It comes up when trying to bound a particular integral. The sum is: $$\sum_{n=0}^{\infty} \frac{e^{\cos(n)}}{n!}$$ Thank you very much for your thoughts.,Does anyone have any ideas on how to find a closed form for the following expression? It comes up when trying to bound a particular integral. The sum is: $$\sum_{n=0}^{\infty} \frac{e^{\cos(n)}}{n!}$$ Thank you very much for your thoughts.,,"['sequences-and-series', 'integration', 'closed-form']"
76,"A problematic integral: $\int_0^{2\pi} e^{-2\pi i\lambda\cos(t)}\,dt$",A problematic integral:,"\int_0^{2\pi} e^{-2\pi i\lambda\cos(t)}\,dt","Is there a special trick to calculate this integral? $$\int_0^{2\pi} e^{-2\pi i\lambda\cos(t)}\,dt$$ for $\lambda>0$.","Is there a special trick to calculate this integral? $$\int_0^{2\pi} e^{-2\pi i\lambda\cos(t)}\,dt$$ for $\lambda>0$.",,"['calculus', 'analysis', 'integration', 'special-functions']"
77,Interesting definite integral involving exp and trig,Interesting definite integral involving exp and trig,,"I'm trying to evaluate the following integrals: $$\int_0^{2\pi} e^{\kappa \cos(\phi - \mu)} \cos(\phi) d\phi$$ $$\int_0^{2\pi} e^{\kappa \cos(\phi - \mu)} \sin(\phi) d\phi$$ for which I want to find an easily computable function. This may be either a closed form, or something in terms of special functions that are available in most scientific computing libraries (e.g. scipy.special ). I found the following result on wikipedia , which may be useful.  $$\int_0^{2\pi} e^{x \cos(\theta)} d\theta = 2\pi I_0(x),$$ where $I_0(x)$ is the modified Bessel function of the first kind, of order 0. I want to apologize in advance if this is a basic question; I have not had formal training in advanced calculus (beyond highschool), except for a few online lectures and wikipedia reading. Any help is greatly appreciated.","I'm trying to evaluate the following integrals: $$\int_0^{2\pi} e^{\kappa \cos(\phi - \mu)} \cos(\phi) d\phi$$ $$\int_0^{2\pi} e^{\kappa \cos(\phi - \mu)} \sin(\phi) d\phi$$ for which I want to find an easily computable function. This may be either a closed form, or something in terms of special functions that are available in most scientific computing libraries (e.g. scipy.special ). I found the following result on wikipedia , which may be useful.  $$\int_0^{2\pi} e^{x \cos(\theta)} d\theta = 2\pi I_0(x),$$ where $I_0(x)$ is the modified Bessel function of the first kind, of order 0. I want to apologize in advance if this is a basic question; I have not had formal training in advanced calculus (beyond highschool), except for a few online lectures and wikipedia reading. Any help is greatly appreciated.",,"['calculus', 'integration', 'trigonometry', 'special-functions', 'exponential-function']"
78,What is the proof that anti-derivative gives function = area under curve?,What is the proof that anti-derivative gives function = area under curve?,,"For many years now I have thought about this but have not been able to get a clear answer. We all know that $\displaystyle \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$ gives us a function we call as the derivative that gives the gradient of the function at $x$. To get the anti-derivative, we can use the $\int$ of the derivative and get back the original $f(x)$. This part of $\displaystyle \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$ has been explained to me many times since high school and is crystal clear. By using this I obtain that derivative of $\sin$ is $\cos$ and derivative of $x^n$ is $nx^{n-1}$. What has never been explained to me is the proof that $\int$ of a function in fact gives the area under $f(x)$ and that also using the Riemann sum. I have always wondered about this and have not been able to get the answer. What is the proof of this?","For many years now I have thought about this but have not been able to get a clear answer. We all know that $\displaystyle \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$ gives us a function we call as the derivative that gives the gradient of the function at $x$. To get the anti-derivative, we can use the $\int$ of the derivative and get back the original $f(x)$. This part of $\displaystyle \lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$ has been explained to me many times since high school and is crystal clear. By using this I obtain that derivative of $\sin$ is $\cos$ and derivative of $x^n$ is $nx^{n-1}$. What has never been explained to me is the proof that $\int$ of a function in fact gives the area under $f(x)$ and that also using the Riemann sum. I have always wondered about this and have not been able to get the answer. What is the proof of this?",,"['calculus', 'integration', 'definite-integrals']"
79,"Suppose $|\alpha_1| \le |\alpha_2| \le \cdots \le 1$, $n(r) = \#\{\alpha_j \le r\}$. Prove $\int_0^1n(r)dr = \sum_{j=1}^\infty(1-|\alpha_j|)$.","Suppose , . Prove .",|\alpha_1| \le |\alpha_2| \le \cdots \le 1 n(r) = \#\{\alpha_j \le r\} \int_0^1n(r)dr = \sum_{j=1}^\infty(1-|\alpha_j|),"I'm trying to solve the following exercise from chapter 15 of Rudin's Real and Complex Analysis: Suppose $|\alpha_1| \le |\alpha_2| \le \cdots \le 1$, and let $n(r)$ be the number of terms in the sequence $\{\alpha_j\}$ such that $|\alpha_j| \le r$. Prove that: $$\int_0^1n(r)dr = \sum_{j=1}^\infty(1-|\alpha_j|)$$ $a_j$ are complex numbers. My thoughts: Make $\alpha_0 = 0$, $r_j = |\alpha_j|$. $$\int_0^{r_{N+1}}n(r)dr = \sum_{j=0}^N\int_{r_j}^{r_{j+1}}n(r)dr = \sum_{j=0}^Nj(r_{j+1}-r_j) = Nr_{N+1} + \sum_{j=1}^N(-r_j)$$ As $N\to\infty$, the left side is less or equal to the integral we are interested in but $Nr_{N+1}$ doesn't approach $1$. What concerns me is that it actually approaches $\infty$ so I suspect I'm doing something wrong. What is it? How can I prove this statement? Thanks.","I'm trying to solve the following exercise from chapter 15 of Rudin's Real and Complex Analysis: Suppose $|\alpha_1| \le |\alpha_2| \le \cdots \le 1$, and let $n(r)$ be the number of terms in the sequence $\{\alpha_j\}$ such that $|\alpha_j| \le r$. Prove that: $$\int_0^1n(r)dr = \sum_{j=1}^\infty(1-|\alpha_j|)$$ $a_j$ are complex numbers. My thoughts: Make $\alpha_0 = 0$, $r_j = |\alpha_j|$. $$\int_0^{r_{N+1}}n(r)dr = \sum_{j=0}^N\int_{r_j}^{r_{j+1}}n(r)dr = \sum_{j=0}^Nj(r_{j+1}-r_j) = Nr_{N+1} + \sum_{j=1}^N(-r_j)$$ As $N\to\infty$, the left side is less or equal to the integral we are interested in but $Nr_{N+1}$ doesn't approach $1$. What concerns me is that it actually approaches $\infty$ so I suspect I'm doing something wrong. What is it? How can I prove this statement? Thanks.",,"['real-analysis', 'integration', 'summation']"
80,Having trouble solving question involving parametric equations,Having trouble solving question involving parametric equations,,"I have been given the following: $$y = a \cdot \cos^3t$$  $$x = a \cdot \sin^3t$$ $$0 \leqslant t \leqslant {\frac\pi2}$$ I am supposed to show that the mean value of $y$ over the interval $0\leqslant x \leqslant a$ is given by: $$m = 3a\int^{\frac12\pi}_0(\cos^4t-\cos^6t)dt$$ I know that the mean fomula is given by: $$m=\frac1{b-a}\int^b_aydx$$ But I'm having trouble finding an equation for $y$ in terms of $x$. In addition, I am confused as to how the final answer will be given as an integral in terms of $t$. I thought I should differentiate $y$, $x$ in terms of $t$ then maybe I would find a substitution: $$\frac{dy}{dt} = -3a \cdot \cos^2t \cdot \sin t$$ $$\frac{dx}{dt} = 3a \cdot \cos t \cdot \sin^2t$$ $$\frac{dy}{dx} = \frac{dy}{dt} \cdot \frac{dt}{dx} = \frac{-3a \cdot \cos^2t \cdot \sin t}{3a \cdot \cos t \cdot \sin^2t} = -\frac{\cos t}{\sin t} = -\cot t$$ Now I'm facing two problems: I can't integrate both sides to get $y$ in terms of $x$ because the trigonometric function on R.H.S. is still in terms of $t$ Even if I did integrate this method seems too inefficient What's the most appropriate method of solving this?","I have been given the following: $$y = a \cdot \cos^3t$$  $$x = a \cdot \sin^3t$$ $$0 \leqslant t \leqslant {\frac\pi2}$$ I am supposed to show that the mean value of $y$ over the interval $0\leqslant x \leqslant a$ is given by: $$m = 3a\int^{\frac12\pi}_0(\cos^4t-\cos^6t)dt$$ I know that the mean fomula is given by: $$m=\frac1{b-a}\int^b_aydx$$ But I'm having trouble finding an equation for $y$ in terms of $x$. In addition, I am confused as to how the final answer will be given as an integral in terms of $t$. I thought I should differentiate $y$, $x$ in terms of $t$ then maybe I would find a substitution: $$\frac{dy}{dt} = -3a \cdot \cos^2t \cdot \sin t$$ $$\frac{dx}{dt} = 3a \cdot \cos t \cdot \sin^2t$$ $$\frac{dy}{dx} = \frac{dy}{dt} \cdot \frac{dt}{dx} = \frac{-3a \cdot \cos^2t \cdot \sin t}{3a \cdot \cos t \cdot \sin^2t} = -\frac{\cos t}{\sin t} = -\cot t$$ Now I'm facing two problems: I can't integrate both sides to get $y$ in terms of $x$ because the trigonometric function on R.H.S. is still in terms of $t$ Even if I did integrate this method seems too inefficient What's the most appropriate method of solving this?",,"['algebra-precalculus', 'integration', 'parametric']"
81,How to do this integral,How to do this integral,,Prove that $$\int \frac{d^{n}q}{(2\pi)^{n} }\frac{q^{2a}}{(q^{2}+D)^{b}}=D^{-(b-a-n/2)}\frac{\Gamma (b-a-n/2)\Gamma (a+n/2)}{(4\pi )^{n/2}\Gamma (n)\Gamma (n/2)}$$ The angular part is easy to do as the integrand is spherically symmetric so the result is $V_{d-1}\times A$ where $V_{d-1}$ is the volume of the Euclidean n-ball of unit radius. It remains to compute the radial part but I don't know how it's done. This integral arises in the calculation of loop corrections in the propagators of scalar fields,Prove that $$\int \frac{d^{n}q}{(2\pi)^{n} }\frac{q^{2a}}{(q^{2}+D)^{b}}=D^{-(b-a-n/2)}\frac{\Gamma (b-a-n/2)\Gamma (a+n/2)}{(4\pi )^{n/2}\Gamma (n)\Gamma (n/2)}$$ The angular part is easy to do as the integrand is spherically symmetric so the result is $V_{d-1}\times A$ where $V_{d-1}$ is the volume of the Euclidean n-ball of unit radius. It remains to compute the radial part but I don't know how it's done. This integral arises in the calculation of loop corrections in the propagators of scalar fields,,"['real-analysis', 'integration', 'mathematical-physics', 'quantum-field-theory']"
82,Show that the Riemann-Stieltjes integral exists,Show that the Riemann-Stieltjes integral exists,,"I'm working on the following problem: Let $c\in(a,b)$ and $$f(x)=\begin{cases} 0 & a\leq x\leq c\\ 1 & c<x\leq b \end{cases}$$ $$\alpha (x)=\begin{cases} 0 & a\leq x< c\\ 1 & c\leq x\leq b \end{cases}$$ Show that $f\in R(\alpha)$ Unfortunately, what I seem to be proving is that $f\notin R(\alpha)$. My strategy was to show that given epsilon, we could find a partition $P_\epsilon $ such that the difference between the upper and lower sums is less than $\epsilon$. So start by observing that for some $k$, $c\in[x_{k-1},x_k]$. Let $M_i=\sup_{x\in [x_{i-1},x_i]}f(x)$ and $m_i=\inf_{x\in [x_{i-1},x_i]}f(x)$. Fix $\epsilon>0$. Then $$U\left(P,f,\alpha\right)-L\left(P,f,\alpha\right)	=	\sum_{i=1}^{N}\left(M_{i}-m_{i}\right)\left[\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right] 	=	\sum_{i=1}^{k-1}\left(M_{i}-m_{i}\right)\left[\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right]+\left(M_{k}-m_{k}\right)\left[\alpha\left(x_{k}\right)-\alpha\left(x_{k-1}\right)\right]+\sum_{i=k+1}^{N}\left(M_{i}-m_{i}\right)\left[\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right] 	=	(0-0)(0-0)+(1-0)(1-0)+(1-1)(1-1) 	=	1  $$ And as far as I know, 1 is not less than $\epsilon$ for many values of $\epsilon$. What am I doing wrong?","I'm working on the following problem: Let $c\in(a,b)$ and $$f(x)=\begin{cases} 0 & a\leq x\leq c\\ 1 & c<x\leq b \end{cases}$$ $$\alpha (x)=\begin{cases} 0 & a\leq x< c\\ 1 & c\leq x\leq b \end{cases}$$ Show that $f\in R(\alpha)$ Unfortunately, what I seem to be proving is that $f\notin R(\alpha)$. My strategy was to show that given epsilon, we could find a partition $P_\epsilon $ such that the difference between the upper and lower sums is less than $\epsilon$. So start by observing that for some $k$, $c\in[x_{k-1},x_k]$. Let $M_i=\sup_{x\in [x_{i-1},x_i]}f(x)$ and $m_i=\inf_{x\in [x_{i-1},x_i]}f(x)$. Fix $\epsilon>0$. Then $$U\left(P,f,\alpha\right)-L\left(P,f,\alpha\right)	=	\sum_{i=1}^{N}\left(M_{i}-m_{i}\right)\left[\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right] 	=	\sum_{i=1}^{k-1}\left(M_{i}-m_{i}\right)\left[\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right]+\left(M_{k}-m_{k}\right)\left[\alpha\left(x_{k}\right)-\alpha\left(x_{k-1}\right)\right]+\sum_{i=k+1}^{N}\left(M_{i}-m_{i}\right)\left[\alpha\left(x_{i}\right)-\alpha\left(x_{i-1}\right)\right] 	=	(0-0)(0-0)+(1-0)(1-0)+(1-1)(1-1) 	=	1  $$ And as far as I know, 1 is not less than $\epsilon$ for many values of $\epsilon$. What am I doing wrong?",,"['real-analysis', 'integration']"
83,Integral with hyperbolic cosine squared,Integral with hyperbolic cosine squared,,"Does anyone can give me a hint how to integrate the following: $$\int_0^\infty{\frac{x^2 {\rm d}x}{\mathrm{cosh}^2(x)}}.$$ The answer is $\frac{\pi^2}{12}$ (taken from the book). I've started with $$\int_0^\infty{\frac{x^2 {\rm d}x}{\mathrm{cosh}^2x}} =$$ $\int_0^\infty{\frac{x^2}{\mathrm{cosh}~x}\frac{{\rm d}(\mathrm{sinh}~x)}{1 + \mathrm{sinh}^2x}}=\left. \arctan{(\mathrm{sinh}~x)}\frac{x^2}{\mathrm{cosh}~x}\right|_0^\infty-\int_0^\infty \arctan{(\mathrm{sinh}~x)}\frac{2x~\mathrm{cosh}~x-x^2 \mathrm{sinh}~x}{\mathrm{cosh}^2x}{\rm d}=$ $$-\frac{1}{2}\int_0^\infty {\rm d}(\arctan^2(\mathrm{sinh}~x))\left[2x-x^2 \mathrm{tanh}~x\right].$$ Definitely, $$\frac{1}{2}\int_0^\infty {\rm d}(\arctan^2(\mathrm{sinh}~x)) = \frac{\pi^2}{8},$$ and I think that's the way to the answer. But I can't imagine how to deal with the part in square brackets... I will be grateful for any help.","Does anyone can give me a hint how to integrate the following: $$\int_0^\infty{\frac{x^2 {\rm d}x}{\mathrm{cosh}^2(x)}}.$$ The answer is $\frac{\pi^2}{12}$ (taken from the book). I've started with $$\int_0^\infty{\frac{x^2 {\rm d}x}{\mathrm{cosh}^2x}} =$$ $\int_0^\infty{\frac{x^2}{\mathrm{cosh}~x}\frac{{\rm d}(\mathrm{sinh}~x)}{1 + \mathrm{sinh}^2x}}=\left. \arctan{(\mathrm{sinh}~x)}\frac{x^2}{\mathrm{cosh}~x}\right|_0^\infty-\int_0^\infty \arctan{(\mathrm{sinh}~x)}\frac{2x~\mathrm{cosh}~x-x^2 \mathrm{sinh}~x}{\mathrm{cosh}^2x}{\rm d}=$ $$-\frac{1}{2}\int_0^\infty {\rm d}(\arctan^2(\mathrm{sinh}~x))\left[2x-x^2 \mathrm{tanh}~x\right].$$ Definitely, $$\frac{1}{2}\int_0^\infty {\rm d}(\arctan^2(\mathrm{sinh}~x)) = \frac{\pi^2}{8},$$ and I think that's the way to the answer. But I can't imagine how to deal with the part in square brackets... I will be grateful for any help.",,"['integration', 'definite-integrals', 'hyperbolic-functions']"
84,Analyzing the convergence of an improper integral,Analyzing the convergence of an improper integral,,"I have to analyze the convergence of $$\int _{0}^{+\infty} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx$$ I've rewritten the integral as $$ \int _{0}^{+\infty} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx = \int _{0}^{1} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx + \int _{1}^{+\infty} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx $$ For the first part, I can write: $$ \int _{0}^{1} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx = \lim_{a \to 0^{+}} \int _{a}^{1} \frac{\cos(x) - 1}{x^{5/2} + 5x^3}\, dx $$ Then, I search for function $g(x)$ so that $ 0 \leq f(x) \leq g(x)$ for $(0,1]$ in order to use convergence criteria. Then, I narrow the expresion in the integral to find something bigger, but that it converges. I make the following steps: $$ \frac{||\cos(x) - 1||}{||x^{5/2} + 5x^3||} \leq \frac{2}{||x^{5/2} + 5x^x||} \leq \frac{2}{||x^{5/2}||} \leq \frac{2}{\sqrt{x}} $$ knowing that $0 < x \leq 1$ . So, $g(x)$ converge because $\int_0^1\frac{1}{x^p}$, with $p < 1$ converges. Then, by the comparison criteria, $$ \int _{0}^{1} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx $$ also converges. Is the reasoning actually correct? I know I still have to check the second part of the integral, but is more of the same procedure. I just want to check if I'm in the good way! Thanks a lot for your help!","I have to analyze the convergence of $$\int _{0}^{+\infty} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx$$ I've rewritten the integral as $$ \int _{0}^{+\infty} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx = \int _{0}^{1} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx + \int _{1}^{+\infty} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx $$ For the first part, I can write: $$ \int _{0}^{1} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx = \lim_{a \to 0^{+}} \int _{a}^{1} \frac{\cos(x) - 1}{x^{5/2} + 5x^3}\, dx $$ Then, I search for function $g(x)$ so that $ 0 \leq f(x) \leq g(x)$ for $(0,1]$ in order to use convergence criteria. Then, I narrow the expresion in the integral to find something bigger, but that it converges. I make the following steps: $$ \frac{||\cos(x) - 1||}{||x^{5/2} + 5x^3||} \leq \frac{2}{||x^{5/2} + 5x^x||} \leq \frac{2}{||x^{5/2}||} \leq \frac{2}{\sqrt{x}} $$ knowing that $0 < x \leq 1$ . So, $g(x)$ converge because $\int_0^1\frac{1}{x^p}$, with $p < 1$ converges. Then, by the comparison criteria, $$ \int _{0}^{1} \frac{\cos \left( x\right) -1} {x^{5 / 2}+5x^{3}}\,dx $$ also converges. Is the reasoning actually correct? I know I still have to check the second part of the integral, but is more of the same procedure. I just want to check if I'm in the good way! Thanks a lot for your help!",,"['calculus', 'integration', 'limits', 'improper-integrals']"
85,Variation of $f(x)=x^\eta\sin^\varepsilon(\frac{1}{x})$,Variation of,f(x)=x^\eta\sin^\varepsilon(\frac{1}{x}),"I'm asked to characterize the values of the parameters $\eta, \varepsilon$ for which the above function is of bounded variation on $[0,1]$, when we set $f(0)=0$. By ""bounded variation"", I mean that the following sum is bounded by some constant $c$, where $t_i$ are the boundary points of any partition $\mathcal{P}$ of the interval into finitely many segments: $$\sum_{j=1}^n |f(t_j)-f(t_{j-1})|$$ I've made just a bit of progress: we need $\varepsilon$ rational with odd denominator, or else $\sin^{\varepsilon}(\frac{1}{x})$ won't be defined on the whole interval. Furthermore we need $\eta$ and $\varepsilon$ nonnegative, positive if we ignore the trivial cases when they're 0, or the function will be unbounded at the zeroes of $\sin(\frac{1}{x})$ or near zero, respectively, while bounded-variation functions never have essential discontinuities. I can differentiate $f$:  $$f'=x^{\eta-1}\sin^{\varepsilon-1}(\frac{1}{x})(\eta\sin(\frac{1}{x})-\varepsilon\cos(\frac{1}{x}))$$ This gives me critical points at the zeroes of $\sin{\frac{1}{x}}$ and at the infinitely many points where $\tan\frac{1}{x}=\frac{\varepsilon}{\eta}$. Ideally I'd estimate the variation by taking a partition at each critical point, since including all local extrema in the partition should guarantee, roughly, that I capture ""all $f$'s variation"". Now I'm at a loss how to proceed. Is there some nice series by which I might bound the sum I'd get in this way? Should I try a completely different approach than this using critical points? Thanks for your suggestions. EDIT : After discussing with some other members of the course, we're pretty sure that the value of $\varepsilon$ is immaterial and $\eta>1$ gives bounded variation while $\eta \leq 1$ does not. But the closest I have to an argument for this is to point out that the former case is just when $f'$ is absolutely integrable on $[0,1]$, which seems pertinent for satisfying Sasha's condition in the comments.","I'm asked to characterize the values of the parameters $\eta, \varepsilon$ for which the above function is of bounded variation on $[0,1]$, when we set $f(0)=0$. By ""bounded variation"", I mean that the following sum is bounded by some constant $c$, where $t_i$ are the boundary points of any partition $\mathcal{P}$ of the interval into finitely many segments: $$\sum_{j=1}^n |f(t_j)-f(t_{j-1})|$$ I've made just a bit of progress: we need $\varepsilon$ rational with odd denominator, or else $\sin^{\varepsilon}(\frac{1}{x})$ won't be defined on the whole interval. Furthermore we need $\eta$ and $\varepsilon$ nonnegative, positive if we ignore the trivial cases when they're 0, or the function will be unbounded at the zeroes of $\sin(\frac{1}{x})$ or near zero, respectively, while bounded-variation functions never have essential discontinuities. I can differentiate $f$:  $$f'=x^{\eta-1}\sin^{\varepsilon-1}(\frac{1}{x})(\eta\sin(\frac{1}{x})-\varepsilon\cos(\frac{1}{x}))$$ This gives me critical points at the zeroes of $\sin{\frac{1}{x}}$ and at the infinitely many points where $\tan\frac{1}{x}=\frac{\varepsilon}{\eta}$. Ideally I'd estimate the variation by taking a partition at each critical point, since including all local extrema in the partition should guarantee, roughly, that I capture ""all $f$'s variation"". Now I'm at a loss how to proceed. Is there some nice series by which I might bound the sum I'd get in this way? Should I try a completely different approach than this using critical points? Thanks for your suggestions. EDIT : After discussing with some other members of the course, we're pretty sure that the value of $\varepsilon$ is immaterial and $\eta>1$ gives bounded variation while $\eta \leq 1$ does not. But the closest I have to an argument for this is to point out that the former case is just when $f'$ is absolutely integrable on $[0,1]$, which seems pertinent for satisfying Sasha's condition in the comments.",,"['real-analysis', 'integration']"
86,The volume and surface area of pipe?,The volume and surface area of pipe?,,A line segment turns around a curve with right angle from point A to point B. I would like to find  the closed region volume and surface area that figured out in the picture. Could you please give me hint how to define the volume and surface area with integrals ? Is it correct that volume formula is as shown below? $$V=\pi r^2\int _{x_1}^{x_2} dS=\pi r^2\int _{x_1}^{x_2} \sqrt{1+(f'(x))^2}dx$$ I do not know how to define the surface of the shape? UPDATE: important note: the offset curves that are the parallels of a function may not be functions: My related questions about parallel functions: Parallel functions. What is the limit distance to the base function if offset curve is a function too? Thanks a lot for answers and advice.,A line segment turns around a curve with right angle from point A to point B. I would like to find  the closed region volume and surface area that figured out in the picture. Could you please give me hint how to define the volume and surface area with integrals ? Is it correct that volume formula is as shown below? $$V=\pi r^2\int _{x_1}^{x_2} dS=\pi r^2\int _{x_1}^{x_2} \sqrt{1+(f'(x))^2}dx$$ I do not know how to define the surface of the shape? UPDATE: important note: the offset curves that are the parallels of a function may not be functions: My related questions about parallel functions: Parallel functions. What is the limit distance to the base function if offset curve is a function too? Thanks a lot for answers and advice.,,"['calculus', 'integration', '3d', 'curvature']"
87,Evaluate or Simplify $\int_{a}^{+\infty} \frac{\exp(-bx)}{x+c} Ei(x) dx$,Evaluate or Simplify,\int_{a}^{+\infty} \frac{\exp(-bx)}{x+c} Ei(x) dx,"I am stuck trying to evaluate or simplify this integrale  : $$I_{a,b,c} = \int_{a}^{+\infty} \frac{\exp(-bx)}{x+c} Ei(x) dx $$ with $a,b,c \in \mathbb{R}_+^*$. and $ Ei(x) =\int_{-\infty}^{x} \frac{\exp(t)}{t}  \mathbb{d}t $ : The Exponential integral function I already found this result: $$\int\exp(-bx) \  Ei(x) = \frac{1}{b} \left[Ei((1-b)x)-\exp(-bx)\ Ei(x) \right] $$ but I can't see if it useful. Any Hint ?","I am stuck trying to evaluate or simplify this integrale  : $$I_{a,b,c} = \int_{a}^{+\infty} \frac{\exp(-bx)}{x+c} Ei(x) dx $$ with $a,b,c \in \mathbb{R}_+^*$. and $ Ei(x) =\int_{-\infty}^{x} \frac{\exp(t)}{t}  \mathbb{d}t $ : The Exponential integral function I already found this result: $$\int\exp(-bx) \  Ei(x) = \frac{1}{b} \left[Ei((1-b)x)-\exp(-bx)\ Ei(x) \right] $$ but I can't see if it useful. Any Hint ?",,"['calculus', 'integration']"
88,how to calculate this infinite integral of infinite product of cosine,how to calculate this infinite integral of infinite product of cosine,,"What is the value of this nontrivial itegral: $$\int_0^{+\infty} \left( \prod_{n = 1}^{+\infty} \cos \frac{x}{n}\right) \, \mbox d x$$ I don't know if there is nice closed answer with known constants.","What is the value of this nontrivial itegral: $$\int_0^{+\infty} \left( \prod_{n = 1}^{+\infty} \cos \frac{x}{n}\right) \, \mbox d x$$ I don't know if there is nice closed answer with known constants.",,['analysis']
89,Integral of $\int \frac{du}{u \sqrt{5-u^2}}$,Integral of,\int \frac{du}{u \sqrt{5-u^2}},"I am trying to find this integral and I can get the answer on wolfram of course but I do not know what is wrong with my method, having gone through it twice. $$\int \frac{du}{u \sqrt{5-u^2}}$$ $u = \sqrt{5} \sin\theta$   and   $du= \sqrt{5} \cos \theta$ $$\int \frac{\sqrt{5} \cos \theta}{\sqrt{5} \cos \theta \sqrt{5-(\sqrt{5} \sin \theta)^2}}$$ $$\int \frac{1}{\sqrt{5-(5 \cos^2 \theta)}}$$ $$\int \frac{1}{\sqrt{5(1- \cos^2 \theta)}}$$ $$\int \frac{1}{\sqrt{5(\sin^2 \theta)}}$$ $$\frac{1}{\sqrt5}\int \frac{1}{(\sin \theta)}$$ $$\frac{1}{\sqrt5}\int \csc\theta$$ $$\frac{\ln|\csc \theta - \tan \theta|}{\sqrt5} + c$$","I am trying to find this integral and I can get the answer on wolfram of course but I do not know what is wrong with my method, having gone through it twice. $$\int \frac{du}{u \sqrt{5-u^2}}$$ $u = \sqrt{5} \sin\theta$   and   $du= \sqrt{5} \cos \theta$ $$\int \frac{\sqrt{5} \cos \theta}{\sqrt{5} \cos \theta \sqrt{5-(\sqrt{5} \sin \theta)^2}}$$ $$\int \frac{1}{\sqrt{5-(5 \cos^2 \theta)}}$$ $$\int \frac{1}{\sqrt{5(1- \cos^2 \theta)}}$$ $$\int \frac{1}{\sqrt{5(\sin^2 \theta)}}$$ $$\frac{1}{\sqrt5}\int \frac{1}{(\sin \theta)}$$ $$\frac{1}{\sqrt5}\int \csc\theta$$ $$\frac{\ln|\csc \theta - \tan \theta|}{\sqrt5} + c$$",,['calculus']
90,Alternative proof of the limitof the quotient of two sums.,Alternative proof of the limitof the quotient of two sums.,,"I found the following problem by Apostol: Let $a \in \Bbb R$ and $s_n(a)=\sum\limits_{k=1}^n k^a$. Find $$\lim_{n\to +\infty} \frac{s_n(a+1)}{ns_n(a)}$$ After some struggling and helpless ideas I considered the following solution. If $a > -1$, then $$\int_0^1 x^a dx=\frac{1}{a+1}$$ is well defined. Thus, let $$\lambda_n(a)=\frac{s_n(a)}{n^{a+1}}$$ It is clear that $$\lim\limits_{n\to +\infty} \lambda_n(a)=\int_0^1 x^a dx=\frac{1}{a+1}$$ and thus $$\lim_{n\to +\infty} \frac{s_n(a+1)}{ns_n(a)}=\lim_{n \to +\infty} \frac{\lambda_n(a+1)}{\lambda_n(a)}=\frac{a+1}{a+2}$$ Can you provide any other proof for this? I used mostly integration theory but maybe there are other simpler ideas (or more complex ones) that can be used. (If $a=-1$ then the limit is zero, since it is simply $H_n^{-1}$ which goes to zero since the harmonic series is divergent. For the case $a <-1$, the simple inequalities $s_n(a+1) \le n\cdot n^{a+1} = n^{a+2}$ and $s_n(a) \ge 1$ show that the limit is also zero.)","I found the following problem by Apostol: Let $a \in \Bbb R$ and $s_n(a)=\sum\limits_{k=1}^n k^a$. Find $$\lim_{n\to +\infty} \frac{s_n(a+1)}{ns_n(a)}$$ After some struggling and helpless ideas I considered the following solution. If $a > -1$, then $$\int_0^1 x^a dx=\frac{1}{a+1}$$ is well defined. Thus, let $$\lambda_n(a)=\frac{s_n(a)}{n^{a+1}}$$ It is clear that $$\lim\limits_{n\to +\infty} \lambda_n(a)=\int_0^1 x^a dx=\frac{1}{a+1}$$ and thus $$\lim_{n\to +\infty} \frac{s_n(a+1)}{ns_n(a)}=\lim_{n \to +\infty} \frac{\lambda_n(a+1)}{\lambda_n(a)}=\frac{a+1}{a+2}$$ Can you provide any other proof for this? I used mostly integration theory but maybe there are other simpler ideas (or more complex ones) that can be used. (If $a=-1$ then the limit is zero, since it is simply $H_n^{-1}$ which goes to zero since the harmonic series is divergent. For the case $a <-1$, the simple inequalities $s_n(a+1) \le n\cdot n^{a+1} = n^{a+2}$ and $s_n(a) \ge 1$ show that the limit is also zero.)",,"['sequences-and-series', 'limits', 'integration']"
91,How to find $f'(\frac{\pi}{2})$ knowing $f(x) = \int_0^{g(x)}(1+t^3)^{-\frac12} \mathrm{d}t$?,How to find  knowing ?,f'(\frac{\pi}{2}) f(x) = \int_0^{g(x)}(1+t^3)^{-\frac12} \mathrm{d}t,Argh I had a picture for this but don't have enough reputation for anything on here. I also don't understand how to insert the math notation in here. If $f(x) = \int_0^{g(x)}(1+t^3)^{-\frac12} \mathrm{d}t$ where $g(x) = \int_0^{\cos x}(1+\sin (t^2))\mathrm{d}t$ I have to find $f'(\frac{\pi}{2}).$ I know it has something to do with substitution and I've tried integrating by parts and things like that too  but its not working out. I think there is something about the way that the questions been asked thats not helping anyway that is the first question. There'll be more in the future I'm sure.,Argh I had a picture for this but don't have enough reputation for anything on here. I also don't understand how to insert the math notation in here. If where I have to find I know it has something to do with substitution and I've tried integrating by parts and things like that too  but its not working out. I think there is something about the way that the questions been asked thats not helping anyway that is the first question. There'll be more in the future I'm sure.,f(x) = \int_0^{g(x)}(1+t^3)^{-\frac12} \mathrm{d}t g(x) = \int_0^{\cos x}(1+\sin (t^2))\mathrm{d}t f'(\frac{\pi}{2}).,"['calculus', 'integration', 'derivatives']"
92,Leibniz's Rule for differentiation under the integral.,Leibniz's Rule for differentiation under the integral.,,"If we have $$F\left( \alpha  \right) = \int\limits_a^b {f\left( {\alpha ,x} \right)dx} $$ Then $$\frac{{F\left( {\alpha  + \Delta \alpha } \right) - F\left( \alpha  \right)}}{{\Delta \alpha }} = \frac{{\Delta F}}{{\Delta \alpha }} = \int\limits_a^b {\frac{{f\left( {\alpha  + \Delta \alpha ,x} \right) - f\left( {\alpha ,x} \right)}}{{\Delta \alpha }}dx} $$ and $$\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{\Delta F}}{{\Delta \alpha }} = \frac{{dF}}{{d\alpha }} = \mathop {\lim }\limits_{\Delta \alpha  \to 0} \int\limits_a^b {\frac{{f\left( {\alpha  + \Delta \alpha ,x} \right) - f\left( {\alpha ,x} \right)}}{{\Delta \alpha }}dx} $$ However, this doesn't always mean $$\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{\Delta F}}{{\Delta \alpha }} = \frac{{dF}}{{d\alpha }} = \int\limits_a^b {\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{f\left( {\alpha  + \Delta \alpha ,x} \right) - f\left( {\alpha ,x} \right)}}{{\Delta \alpha }}dx} $$ $$\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{\Delta F}}{{\Delta \alpha }} = \frac{{dF}}{{d\alpha }} = \int\limits_a^b {\frac{{\partial f\left( {\alpha ,x} \right)}}{{\partial \alpha }}dx} $$ I know that in other cases, for example in the integration of a series of functions or in sequences of functions, if $s(x)_n \to s(x)$ or $f_n(x) \to f(x) $ uniformly then we can integrate term by term (in the series) or change the order of integration and of taking the limit (in the sequence), i.e: If $${s_n}\left( x \right) = \sum\limits_{k = 0}^n {{f_k}\left( x \right)} $$ then $$\mathop {\lim }\limits_{n \to \infty } \int\limits_a^b {{s_n}\left( x \right)dx}  = \int\limits_a^b {s\left( x \right)dx} $$ and for the other case: $$\mathop {\lim }\limits_{n \to \infty } \int\limits_a^b {{f_n}\left( x \right)dx}  = \int\limits_a^b {\mathop {\lim }\limits_{n \to \infty } {f_n}\left( x \right)dx} $$ However Leibniz's rule is used in cases such as: $$\int\limits_0^1 {\frac{{{x^\alpha } - 1}}{{\log x}}dx} $$ Which isn't even continuous in $[0,1]$. How can we then justify this procedure? ADD: One particular example is $$f(t) = \int\limits_0^\infty  {\frac{{\sin \left( {xt} \right)}}{x}} dx =\frac{\pi}{2}$$ Which wrongly yields: $$f'\left( t \right) = \int\limits_0^\infty  {\cos \left( {xt} \right)dx}  = 0$$","If we have $$F\left( \alpha  \right) = \int\limits_a^b {f\left( {\alpha ,x} \right)dx} $$ Then $$\frac{{F\left( {\alpha  + \Delta \alpha } \right) - F\left( \alpha  \right)}}{{\Delta \alpha }} = \frac{{\Delta F}}{{\Delta \alpha }} = \int\limits_a^b {\frac{{f\left( {\alpha  + \Delta \alpha ,x} \right) - f\left( {\alpha ,x} \right)}}{{\Delta \alpha }}dx} $$ and $$\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{\Delta F}}{{\Delta \alpha }} = \frac{{dF}}{{d\alpha }} = \mathop {\lim }\limits_{\Delta \alpha  \to 0} \int\limits_a^b {\frac{{f\left( {\alpha  + \Delta \alpha ,x} \right) - f\left( {\alpha ,x} \right)}}{{\Delta \alpha }}dx} $$ However, this doesn't always mean $$\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{\Delta F}}{{\Delta \alpha }} = \frac{{dF}}{{d\alpha }} = \int\limits_a^b {\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{f\left( {\alpha  + \Delta \alpha ,x} \right) - f\left( {\alpha ,x} \right)}}{{\Delta \alpha }}dx} $$ $$\mathop {\lim }\limits_{\Delta \alpha  \to 0} \frac{{\Delta F}}{{\Delta \alpha }} = \frac{{dF}}{{d\alpha }} = \int\limits_a^b {\frac{{\partial f\left( {\alpha ,x} \right)}}{{\partial \alpha }}dx} $$ I know that in other cases, for example in the integration of a series of functions or in sequences of functions, if $s(x)_n \to s(x)$ or $f_n(x) \to f(x) $ uniformly then we can integrate term by term (in the series) or change the order of integration and of taking the limit (in the sequence), i.e: If $${s_n}\left( x \right) = \sum\limits_{k = 0}^n {{f_k}\left( x \right)} $$ then $$\mathop {\lim }\limits_{n \to \infty } \int\limits_a^b {{s_n}\left( x \right)dx}  = \int\limits_a^b {s\left( x \right)dx} $$ and for the other case: $$\mathop {\lim }\limits_{n \to \infty } \int\limits_a^b {{f_n}\left( x \right)dx}  = \int\limits_a^b {\mathop {\lim }\limits_{n \to \infty } {f_n}\left( x \right)dx} $$ However Leibniz's rule is used in cases such as: $$\int\limits_0^1 {\frac{{{x^\alpha } - 1}}{{\log x}}dx} $$ Which isn't even continuous in $[0,1]$. How can we then justify this procedure? ADD: One particular example is $$f(t) = \int\limits_0^\infty  {\frac{{\sin \left( {xt} \right)}}{x}} dx =\frac{\pi}{2}$$ Which wrongly yields: $$f'\left( t \right) = \int\limits_0^\infty  {\cos \left( {xt} \right)dx}  = 0$$",,"['integration', 'definite-integrals']"
93,Correct way to prove the limit: $\mathop {\lim }\limits_{x \to 0} {x^\alpha }\int\limits_x^1 {\frac{{f\left( t \right)}}{{{t^{\alpha  + 1}}}}dt} $?,Correct way to prove the limit: ?,\mathop {\lim }\limits_{x \to 0} {x^\alpha }\int\limits_x^1 {\frac{{f\left( t \right)}}{{{t^{\alpha  + 1}}}}dt} ,"Some days ago I answered a question that asked to find $$\mathop {\lim }\limits_{x \to 0} {x^\alpha }\int\limits_x^1 {\frac{{f\left( t \right)}}{{{t^{\alpha  + 1}}}}dt} $$ given that $f$ is continuous in $[0,1]$ I proceeded as follows: $$\eqalign{   & t = x\cdot u  \cr    & dt = x\cdot du \cr} $$ So this is produces: $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du} $$ I then thought: ""Well, if $f$ is continuous in the closed interval, then it is also uniformly continuous, so I can assume $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du}  = f\left( 0 \right)\int\limits_1^\infty  {\frac{{du}}{{{u^{\alpha  + 1}}}}}  = \frac{1}{\alpha }f\left( 0 \right)$$ This turned out to be true. However, I wasn't very comfortable with such ""move"". So now I'm thinking, one can put $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du}  + \mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du} $$ And then $$\left| {\int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du} } \right| < \int\limits_1^{\frac{1}{x}} {\frac{{\left| {f\left( {xu} \right) - f\left( 0 \right)} \right|}}{{{u^{\alpha  + 1}}}}du}  < \epsilon \frac{{1 - {x^\alpha }}}{\alpha }$$ However, this is still insufficient since I need to adress the behaviour of the upper limit too. Can someone show me how to adress both behaviours simultaneously? Would this work? Let $P$ be the statement that $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du}  = \frac{{f\left( 0 \right)}}{\alpha }$$ Then $P$ is true if and only if $$ \forall \epsilon  > 0\exists \delta  > 0$$ Such that if $$\left| x \right| < \delta $$ then $$ \left| {\int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du}  - \frac{{f\left( 0 \right)}}{\alpha }} \right| < \epsilon $$ But then $$\left| {\int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du}  + \int\limits_1^{\frac{1}{x}} {\frac{{f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du - \frac{{f\left( 0 \right)}}{\alpha }} } \right| < $$ $$\left| {\int\limits_1^{\frac{1}{\delta }} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du}  + \int\limits_1^{\frac{1}{\delta }} {\frac{{f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du - \frac{{f\left( 0 \right)}}{\alpha }} } \right| \leqslant $$ $$\varepsilon \frac{{1 - {\delta ^\alpha }}}{\alpha } + f\left( 0 \right)\frac{{1 - {\delta ^\alpha }}}{\alpha } - \frac{{f\left( 0 \right)}}{\alpha } < $$ And since $$\frac{{1 - {\delta ^\alpha }}}{\alpha } < \frac{1}{\alpha }$$ $$\epsilon \frac{{1 - {\delta ^\alpha }}}{\alpha } + f\left( 0 \right)\frac{{1 - {\delta ^\alpha }}}{\alpha } - \frac{{f\left( 0 \right)}}{\alpha } < \frac{\epsilon }{\alpha } < \epsilon $$","Some days ago I answered a question that asked to find $$\mathop {\lim }\limits_{x \to 0} {x^\alpha }\int\limits_x^1 {\frac{{f\left( t \right)}}{{{t^{\alpha  + 1}}}}dt} $$ given that $f$ is continuous in $[0,1]$ I proceeded as follows: $$\eqalign{   & t = x\cdot u  \cr    & dt = x\cdot du \cr} $$ So this is produces: $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du} $$ I then thought: ""Well, if $f$ is continuous in the closed interval, then it is also uniformly continuous, so I can assume $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du}  = f\left( 0 \right)\int\limits_1^\infty  {\frac{{du}}{{{u^{\alpha  + 1}}}}}  = \frac{1}{\alpha }f\left( 0 \right)$$ This turned out to be true. However, I wasn't very comfortable with such ""move"". So now I'm thinking, one can put $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du}  + \mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du} $$ And then $$\left| {\int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du} } \right| < \int\limits_1^{\frac{1}{x}} {\frac{{\left| {f\left( {xu} \right) - f\left( 0 \right)} \right|}}{{{u^{\alpha  + 1}}}}du}  < \epsilon \frac{{1 - {x^\alpha }}}{\alpha }$$ However, this is still insufficient since I need to adress the behaviour of the upper limit too. Can someone show me how to adress both behaviours simultaneously? Would this work? Let $P$ be the statement that $$\mathop {\lim }\limits_{x \to 0} \int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du}  = \frac{{f\left( 0 \right)}}{\alpha }$$ Then $P$ is true if and only if $$ \forall \epsilon  > 0\exists \delta  > 0$$ Such that if $$\left| x \right| < \delta $$ then $$ \left| {\int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right)}}{{{u^{\alpha  + 1}}}}du}  - \frac{{f\left( 0 \right)}}{\alpha }} \right| < \epsilon $$ But then $$\left| {\int\limits_1^{\frac{1}{x}} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du}  + \int\limits_1^{\frac{1}{x}} {\frac{{f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du - \frac{{f\left( 0 \right)}}{\alpha }} } \right| < $$ $$\left| {\int\limits_1^{\frac{1}{\delta }} {\frac{{f\left( {xu} \right) - f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du}  + \int\limits_1^{\frac{1}{\delta }} {\frac{{f\left( 0 \right)}}{{{u^{\alpha  + 1}}}}du - \frac{{f\left( 0 \right)}}{\alpha }} } \right| \leqslant $$ $$\varepsilon \frac{{1 - {\delta ^\alpha }}}{\alpha } + f\left( 0 \right)\frac{{1 - {\delta ^\alpha }}}{\alpha } - \frac{{f\left( 0 \right)}}{\alpha } < $$ And since $$\frac{{1 - {\delta ^\alpha }}}{\alpha } < \frac{1}{\alpha }$$ $$\epsilon \frac{{1 - {\delta ^\alpha }}}{\alpha } + f\left( 0 \right)\frac{{1 - {\delta ^\alpha }}}{\alpha } - \frac{{f\left( 0 \right)}}{\alpha } < \frac{\epsilon }{\alpha } < \epsilon $$",,"['integration', 'limits']"
94,Help with finding the surface area of a revolution,Help with finding the surface area of a revolution,,Here's the problem I'm stuck on: Find the surface are of this revolution about the y-axis $x = \sqrt{9-y^2}; -2\leq y\leq2$ What I've done so far: $A= 2\pi \int_{-2}^2 \sqrt{9-y^2} \sqrt{1 + (\frac{1}{2}(9-y^2)^\frac{-1}{2}(-2y))^2} dy$ $ = 4\pi \int_{0}^2 \sqrt{9-y^2} \sqrt{1 + (\frac{1}{2}(9-y^2)^\frac{-1}{2}(-2y))^2} dy$ $ = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (9-y^2)(\frac{1}{2}(-2y)(9-y^2)^\frac{-1}{2})^2} dy$ $ = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (9-y^2)((-y)^2(9-y^2)^{-1})} dy$ $ = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (9-y^2)(\frac{(-y)^2}{(9-y^2)})} dy$ $ = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (-y)^2} dy$ $ = 4\pi \int_{0}^2 \sqrt{9-y^2 -y^2} dy$ * $ = 4\pi \int_{0}^2 \sqrt{9-2y^2} dy$ The answer in the book says its: $24\pi$ Which means that I needed to get the integral to be: $ = 4\pi \int_{0}^2 \sqrt{9} dy$ But I just don't see how I can manipulate the problem with algebra to get there... Any guidance? EDIT: Added in some steps to show where my algrbra went wrong *This is where I made the mistake.,Here's the problem I'm stuck on: Find the surface are of this revolution about the y-axis What I've done so far: * The answer in the book says its: Which means that I needed to get the integral to be: But I just don't see how I can manipulate the problem with algebra to get there... Any guidance? EDIT: Added in some steps to show where my algrbra went wrong *This is where I made the mistake.,x = \sqrt{9-y^2}; -2\leq y\leq2 A= 2\pi \int_{-2}^2 \sqrt{9-y^2} \sqrt{1 + (\frac{1}{2}(9-y^2)^\frac{-1}{2}(-2y))^2} dy  = 4\pi \int_{0}^2 \sqrt{9-y^2} \sqrt{1 + (\frac{1}{2}(9-y^2)^\frac{-1}{2}(-2y))^2} dy  = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (9-y^2)(\frac{1}{2}(-2y)(9-y^2)^\frac{-1}{2})^2} dy  = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (9-y^2)((-y)^2(9-y^2)^{-1})} dy  = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (9-y^2)(\frac{(-y)^2}{(9-y^2)})} dy  = 4\pi \int_{0}^2 \sqrt{(9-y^2) + (-y)^2} dy  = 4\pi \int_{0}^2 \sqrt{9-y^2 -y^2} dy  = 4\pi \int_{0}^2 \sqrt{9-2y^2} dy 24\pi  = 4\pi \int_{0}^2 \sqrt{9} dy,"['calculus', 'integration']"
95,An integral identity,An integral identity,,"In the science paper labelled ""Effect of Fermi surface geometry on electron-electron scattering"", by Hodges, Smith and Wilkins, there is a following identity: $$ \int_{0}^{ \infty}dx\int_{0}^{ \infty}dz f(z)\left[ 1- f(x) \right]\left[ 1- f(t+z-x)\right] = \frac{1}{2}(\pi ^2 + t^2)\left[ 1- f(t)\right] $$ where $$f(x) = \frac{1}{e^x + 1}$$ Now, can anyone tell me is there some fancy way to prove it, without the ""brute- force"" method. Thanks.","In the science paper labelled ""Effect of Fermi surface geometry on electron-electron scattering"", by Hodges, Smith and Wilkins, there is a following identity: $$ \int_{0}^{ \infty}dx\int_{0}^{ \infty}dz f(z)\left[ 1- f(x) \right]\left[ 1- f(t+z-x)\right] = \frac{1}{2}(\pi ^2 + t^2)\left[ 1- f(t)\right] $$ where $$f(x) = \frac{1}{e^x + 1}$$ Now, can anyone tell me is there some fancy way to prove it, without the ""brute- force"" method. Thanks.",,"['calculus', 'integration']"
96,Anyone know if this integral has an analytic solution?,Anyone know if this integral has an analytic solution?,,"I've come across the following integral: $$\int_{-\pi}^{\pi}\left[\frac{1}{A-R \cos(2\theta-\phi)}\right]^{\frac{N-1}{2}}d\theta$$ I know how to approximate this integral using the Laplace method, just wondering if: a) Does this integral have an exact answer? b) Is there a better approximation than Laplace method for this integral? If so, under what conditions will it be better? My thinking is that it will be a hypergeometric function (mainly because every hard integral I've come across turns out to be one of these).  Conditions (if needed) are $A>R>0$, and $N$ is an integer.","I've come across the following integral: $$\int_{-\pi}^{\pi}\left[\frac{1}{A-R \cos(2\theta-\phi)}\right]^{\frac{N-1}{2}}d\theta$$ I know how to approximate this integral using the Laplace method, just wondering if: a) Does this integral have an exact answer? b) Is there a better approximation than Laplace method for this integral? If so, under what conditions will it be better? My thinking is that it will be a hypergeometric function (mainly because every hard integral I've come across turns out to be one of these).  Conditions (if needed) are $A>R>0$, and $N$ is an integer.",,['integration']
97,Existence of an Analytic Formula for a Definite Integral,Existence of an Analytic Formula for a Definite Integral,,"It would be very helpful if the following definite integral or a similar one had an analytic solution: $$\int\nolimits_{-\infty}^{\infty}\mathrm{sech}^2(x)\exp(-\alpha x^2)\,\mathrm dx,\qquad \alpha \geq 0$$ I have attacked this problem from several directions now, including contour integration (the Gaussian blows up along Re=0), differentiation under the sign (no luck), and interpreting it as the expected value when sampling with a certain distribution (because both of these functions may be interpreted that way easily). To me, it seems like this could have a nice formula because both functions separately do, there is so much symmetry, and the integrand seems like just a bunch of exponentials to me.  I just wanted to know if anyone had a compelling reason why this won't have a 'nice' analytic solution - or even what the intuition of some more experienced people is concerning my probability of success or direction of my efforts.","It would be very helpful if the following definite integral or a similar one had an analytic solution: $$\int\nolimits_{-\infty}^{\infty}\mathrm{sech}^2(x)\exp(-\alpha x^2)\,\mathrm dx,\qquad \alpha \geq 0$$ I have attacked this problem from several directions now, including contour integration (the Gaussian blows up along Re=0), differentiation under the sign (no luck), and interpreting it as the expected value when sampling with a certain distribution (because both of these functions may be interpreted that way easily). To me, it seems like this could have a nice formula because both functions separately do, there is so much symmetry, and the integrand seems like just a bunch of exponentials to me.  I just wanted to know if anyone had a compelling reason why this won't have a 'nice' analytic solution - or even what the intuition of some more experienced people is concerning my probability of success or direction of my efforts.",,"['calculus', 'integration', 'improper-integrals']"
98,Power Mean Random Distribution,Power Mean Random Distribution,,"I'm trying to find a the distribution for the power mean of $n$ random variables on $[0,1]$ . I've got the arithmetic mean: $\frac{n}{(n-1)!}\sum_{k=0}^{\lfloor nx\rfloor}(-1)^k\binom{n}{k}(nx-k)^{n-1}$ The geometric mean: $\frac{n}{(n-1)!}(-nx\log x)^{n-1}$ The min mean: $n(1 - x)^{n-1}$ The max mean: $nx^{n-1}$ From here they seam to get harder though, and there isn't really any pattern (or close to) yet. I'm wondering if the distribution of a general power mean has a name, and perhaps a closed formula? Perhaps you can guide me to some literature, or know the closed form of e.g. the distribution of random variables over the harmonic mean? I've plotted the n=3 case for different powers:","I'm trying to find a the distribution for the power mean of random variables on . I've got the arithmetic mean: The geometric mean: The min mean: The max mean: From here they seam to get harder though, and there isn't really any pattern (or close to) yet. I'm wondering if the distribution of a general power mean has a name, and perhaps a closed formula? Perhaps you can guide me to some literature, or know the closed form of e.g. the distribution of random variables over the harmonic mean? I've plotted the n=3 case for different powers:","n [0,1] \frac{n}{(n-1)!}\sum_{k=0}^{\lfloor nx\rfloor}(-1)^k\binom{n}{k}(nx-k)^{n-1} \frac{n}{(n-1)!}(-nx\log x)^{n-1} n(1 - x)^{n-1} nx^{n-1}","['integration', 'probability-distributions', 'random', 'average', 'closed-form']"
99,$2\cdot\int_0^\infty \frac{a-u^2}{\left( u^2+\frac{a^2}{b-a}\right) \left(u^2+\frac{b^2}{b-a} \right) \sqrt{\cdots } }\mathrm {d}u $,,2\cdot\int_0^\infty \frac{a-u^2}{\left( u^2+\frac{a^2}{b-a}\right) \left(u^2+\frac{b^2}{b-a} \right) \sqrt{\cdots } }\mathrm {d}u ,"at the moment I am trying to reproduce the results of a paper . There, it turns out that a specific physical problem is mapped onto an integral to be calculated : $$I(\Theta; a, b) = 2\cdot\int_0^\infty \frac{a-u^2}{\left( u^2+\frac{a^2}{b-a}\right) \left(u^2+\frac{b^2}{b-a} \right) \sqrt{a - u^2 -\frac{a}{1-a/b}\sin^2(\Theta) }    }\mathrm {d}u \equiv \int_0^\infty f(u)du$$ where I took the liberty to replace $\epsilon_d\rightarrow a$ and $\epsilon_m \rightarrow -b$ in contrast to the paper and one can assume that both $a,b > 0$ and $b > a$. Somehow, Mathematica manages to be able to calculate the numerical values of this integral with some warning messages due to the pole at $$u_p = \sqrt{a -\frac{a}{1-a/b}\sin^2(\Theta)}$$ Also, Mathematica can calculate the indefinite integral , both for $\Theta = 0$ (which is a special case to compare results) and in the general case. Nevertheless, I am not able to use the result since it is indefinite in all cases for $u\rightarrow \infty$. So, I am asking for some advice to calculate the integral at hand with respect to given constant $a$ and $b$. The special case of $\Theta = 0$ might already be worth to take a look since it is much easier to calculate it than for the general case. In the meantime I tried something like a Cauchy principal value integration around $u_p$ using the parametrization $u_\delta (\varphi) = u_p -\delta e^{\mathrm{i}\varphi}$ along a half circle $C_\delta$ interpreting $u^2$ as $\bar{u}u$. Then, $$I_\delta = \int_0^\pi f(u_\delta(\varphi))\delta d\varphi$$ is the integral around $C_\delta$ which turned out to vanish for $\delta\rightarrow 0$ such that the whole integral should be given in terms of a principal value one. Noteworthy, I am not sure if my result is correct. Please, if my question is not stated correctly, or anything is obvious don't hesitate to give me some advice. Thank you in advance. Sincerely Robert","at the moment I am trying to reproduce the results of a paper . There, it turns out that a specific physical problem is mapped onto an integral to be calculated : $$I(\Theta; a, b) = 2\cdot\int_0^\infty \frac{a-u^2}{\left( u^2+\frac{a^2}{b-a}\right) \left(u^2+\frac{b^2}{b-a} \right) \sqrt{a - u^2 -\frac{a}{1-a/b}\sin^2(\Theta) }    }\mathrm {d}u \equiv \int_0^\infty f(u)du$$ where I took the liberty to replace $\epsilon_d\rightarrow a$ and $\epsilon_m \rightarrow -b$ in contrast to the paper and one can assume that both $a,b > 0$ and $b > a$. Somehow, Mathematica manages to be able to calculate the numerical values of this integral with some warning messages due to the pole at $$u_p = \sqrt{a -\frac{a}{1-a/b}\sin^2(\Theta)}$$ Also, Mathematica can calculate the indefinite integral , both for $\Theta = 0$ (which is a special case to compare results) and in the general case. Nevertheless, I am not able to use the result since it is indefinite in all cases for $u\rightarrow \infty$. So, I am asking for some advice to calculate the integral at hand with respect to given constant $a$ and $b$. The special case of $\Theta = 0$ might already be worth to take a look since it is much easier to calculate it than for the general case. In the meantime I tried something like a Cauchy principal value integration around $u_p$ using the parametrization $u_\delta (\varphi) = u_p -\delta e^{\mathrm{i}\varphi}$ along a half circle $C_\delta$ interpreting $u^2$ as $\bar{u}u$. Then, $$I_\delta = \int_0^\pi f(u_\delta(\varphi))\delta d\varphi$$ is the integral around $C_\delta$ which turned out to vanish for $\delta\rightarrow 0$ such that the whole integral should be given in terms of a principal value one. Noteworthy, I am not sure if my result is correct. Please, if my question is not stated correctly, or anything is obvious don't hesitate to give me some advice. Thank you in advance. Sincerely Robert",,"['integration', 'numerical-methods']"
