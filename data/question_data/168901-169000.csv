,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,8 Drawer Desk Conditional Probability Problem: Use Bayes' Theorem using the given statement,8 Drawer Desk Conditional Probability Problem: Use Bayes' Theorem using the given statement,,"A desk has eight drawers. There is a probability of 1/2 that someone placed a letter in one of the desk's eight drawers and a probability of 1/2 that this person didn't place a letter in any of the desk's eight drawers. You open the first 7 drawers and find that they are all empty. What is the probability that the 8th drawer has a letter in it? This answer makes use of a slightly different Event A while this answer takes advantage of $P(A \cap B)$ . I want to use the alternative form $P(A) * P(B|A)$ instead. This answer touches on the other part of the disjoint equation in the denominator that I am trying to figure out. Here is what I have so far: Let $A$ denote the event in which there is a letter in the 8th drawer. Let $B$ denote the event in which the first 7 drawers are all empty. Then $P(A|B) = \frac{P(A) * P(B|A)}{P(B)}$ $P(A) = \frac{1}{2} * \frac{1}{8}$ since there's a 1/2 chance that there's a letter in the drawers and only 1 of the 8 possible scenarios is there a letter in the 8th drawer. $P(B) = P(B|A)*P(A) + P(B|A')*P(A')$ - This means the probability of having the first seven drawers empty is equal to: The probability that the first seven drawers are empty given that the letter is in the 8th drawer $P(B|A)$ times the probability that the letter is in the 8th drawer $P(A)$ PLUS The probability that the first seven drawers are empty given that the letter is NOT in the 8th drawer $P(B|A')$ times the probability that the letter is NOT in the 8th drawer $P(A')$ $P(B|A)$ = 1 since if it's in the 8th drawer, the other seven have to be empty since there's only one letter. $P(A)$ was already calculated as $\frac{1}{2} * \frac{1}{8}$ $P(B|A')$ = unsure $P(A')$ = $(\frac{1}{2} * \frac{7}{8}) + \frac{1}{2} * 1$ (I think this is true - 1/2 of the time we will be in the letter state and there will be 7 out of 8 states in which the letter is not in the 8th spot). The other 1/2 of the time when there is no letter, it will be 8/8 times that the letter is not in the 8th spot. I am focused on filling in the gaps on this specific method. There are other elegant solutions that I understand, but this is how I've been solving other Baye's Theorem problems, so I want to solidify my understanding by pointing out where I went wrong or how I can count $P(B|A')$ Judging by the correct answers, if everything I wrote is correct, then $P(B|A')$ has to be 8/15, but what does 8/15 represent? Also, I wouldn't know what this is beforehand, so I'd like to know how to calculate this.","A desk has eight drawers. There is a probability of 1/2 that someone placed a letter in one of the desk's eight drawers and a probability of 1/2 that this person didn't place a letter in any of the desk's eight drawers. You open the first 7 drawers and find that they are all empty. What is the probability that the 8th drawer has a letter in it? This answer makes use of a slightly different Event A while this answer takes advantage of . I want to use the alternative form instead. This answer touches on the other part of the disjoint equation in the denominator that I am trying to figure out. Here is what I have so far: Let denote the event in which there is a letter in the 8th drawer. Let denote the event in which the first 7 drawers are all empty. Then since there's a 1/2 chance that there's a letter in the drawers and only 1 of the 8 possible scenarios is there a letter in the 8th drawer. - This means the probability of having the first seven drawers empty is equal to: The probability that the first seven drawers are empty given that the letter is in the 8th drawer times the probability that the letter is in the 8th drawer PLUS The probability that the first seven drawers are empty given that the letter is NOT in the 8th drawer times the probability that the letter is NOT in the 8th drawer = 1 since if it's in the 8th drawer, the other seven have to be empty since there's only one letter. was already calculated as = unsure = (I think this is true - 1/2 of the time we will be in the letter state and there will be 7 out of 8 states in which the letter is not in the 8th spot). The other 1/2 of the time when there is no letter, it will be 8/8 times that the letter is not in the 8th spot. I am focused on filling in the gaps on this specific method. There are other elegant solutions that I understand, but this is how I've been solving other Baye's Theorem problems, so I want to solidify my understanding by pointing out where I went wrong or how I can count Judging by the correct answers, if everything I wrote is correct, then has to be 8/15, but what does 8/15 represent? Also, I wouldn't know what this is beforehand, so I'd like to know how to calculate this.",P(A \cap B) P(A) * P(B|A) A B P(A|B) = \frac{P(A) * P(B|A)}{P(B)} P(A) = \frac{1}{2} * \frac{1}{8} P(B) = P(B|A)*P(A) + P(B|A')*P(A') P(B|A) P(A) P(B|A') P(A') P(B|A) P(A) \frac{1}{2} * \frac{1}{8} P(B|A') P(A') (\frac{1}{2} * \frac{7}{8}) + \frac{1}{2} * 1 P(B|A') P(B|A'),"['probability', 'statistics', 'bayes-theorem']"
1,Finding the squared expectation of a random variable that is a composite of a summation of random variables.,Finding the squared expectation of a random variable that is a composite of a summation of random variables.,,"Given the following, what is the squared expectation of random variable g(x)? g(x) = $\pi$ f( $x_1$ ) + (1- $\pi$ )f( $x_2$ ), and we are told simply that $f_1$ and $f_2$ have means $\mu_1$ and $\mu_2$ and variances $\sigma_1^2$ and $\sigma_2^2$ respectively.  Furthermore, pi is ""some number"" existing between 0 and 1, inclusive. I have been working on this problem, and my current solution is: E[ $X^2$ ] = $\pi^2$$\sigma_1^2$ + $(1 - \pi)^2\sigma_2^2$ + $\sigma_1\sigma_2$ + $\pi\mu_1$ + $(1 - \pi)\mu_2$ My reasoning is that E[g(x)] = $\pi\mu_1 + (1-\pi)\mu_2$ , since pi is a constant, and according to the rules of expectations, the constant should be simply multiplied against the expectation of the density it is a coefficient to. $E[X^2] = E[g^2(x)] = Var(X) + E[X]$ , which is a rearrangement of the definition of the variance. Said variance ought to be the first three terms of my solution, if I understand it right, and the constants are squared according to the rule that $Var(aX) = a^2Var(X)$ .  The third term comes from the fact that $Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)$ , and that the $Cov(X,Y) <= SD(X)SD(Y)$ Put everything together, and we should arrive at my current solution. That being said, the question is a multiple choice one, and none of the possible solutions match mine.  I'm not confident that this solution I have can be simplified to arrive at one of the choices either.","Given the following, what is the squared expectation of random variable g(x)? g(x) = f( ) + (1- )f( ), and we are told simply that and have means and and variances and respectively.  Furthermore, pi is ""some number"" existing between 0 and 1, inclusive. I have been working on this problem, and my current solution is: E[ ] = + + + + My reasoning is that E[g(x)] = , since pi is a constant, and according to the rules of expectations, the constant should be simply multiplied against the expectation of the density it is a coefficient to. , which is a rearrangement of the definition of the variance. Said variance ought to be the first three terms of my solution, if I understand it right, and the constants are squared according to the rule that .  The third term comes from the fact that , and that the Put everything together, and we should arrive at my current solution. That being said, the question is a multiple choice one, and none of the possible solutions match mine.  I'm not confident that this solution I have can be simplified to arrive at one of the choices either.","\pi x_1 \pi x_2 f_1 f_2 \mu_1 \mu_2 \sigma_1^2 \sigma_2^2 X^2 \pi^2\sigma_1^2 (1 - \pi)^2\sigma_2^2 \sigma_1\sigma_2 \pi\mu_1 (1 - \pi)\mu_2 \pi\mu_1 + (1-\pi)\mu_2 E[X^2] = E[g^2(x)] = Var(X) + E[X] Var(aX) = a^2Var(X) Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y) Cov(X,Y) <= SD(X)SD(Y)","['probability', 'statistics', 'expected-value', 'variance', 'covariance']"
2,Negative Binomial mean,Negative Binomial mean,,"Let $X\sim BN(r,p)$ . If I try to compute E[X] through the Moment Generating Function I get the following: \begin{aligned} E[X] &=\left.\frac{d}{d t} M_{X}(t)\right|_{t=0} \ &=\left.\frac{d}{d t} p^{r}\left(1-p e^{t}(1-p)\right)^{-r}\right|_{t=0} \ &=p^{r+1} r(1-p)(1-p(1-p))^{-r-1} \end{aligned} But if I find it through the first factorial moment I get $E\left[X^{(h)}\right]$ $=\sum_{x=0}^{\infty} \frac{x !}{(x-h) !} \frac{(x+r-1) !}{x !(r-1) !} p^{r}(1-p)^{x}$ $=\sum_{x=h}^{\infty} \frac{(x+r-1) !}{(x-h) !(r-1) !} p^{r}(1-p)^{x},\left(x^{*}=x-h\right)$ $=\sum_{x^{*}=0}^{\infty} \frac{\left(x^{*}+r+h-1\right) !}{x^{*} !(r-1) !} p^{r}(1-p)^{x^{*}+h}$ $=\frac{(r+h-1) !}{(r-1) !} \frac{(1-p)^{h}}{p^{h}} \sum_{x^{*}=0}^{\infty} \frac{\left(x^{*}+h+r+1\right) !}{x^{*} !(r+h-1) !} p^{r+h}(1-p)^{x^{*}}$ $=\frac{(r+h-1) !}{(r-1) !} \frac{(1-p)^{h}}{p^{h}}$ Therefore, $E[X]=\frac{r(1-p)}{p}$ Where did I do wrong?","Let . If I try to compute E[X] through the Moment Generating Function I get the following: But if I find it through the first factorial moment I get Therefore, Where did I do wrong?","X\sim BN(r,p) \begin{aligned}
E[X] &=\left.\frac{d}{d t} M_{X}(t)\right|_{t=0} \
&=\left.\frac{d}{d t} p^{r}\left(1-p e^{t}(1-p)\right)^{-r}\right|_{t=0} \
&=p^{r+1} r(1-p)(1-p(1-p))^{-r-1}
\end{aligned} E\left[X^{(h)}\right] =\sum_{x=0}^{\infty} \frac{x !}{(x-h) !} \frac{(x+r-1) !}{x !(r-1) !} p^{r}(1-p)^{x} =\sum_{x=h}^{\infty} \frac{(x+r-1) !}{(x-h) !(r-1) !} p^{r}(1-p)^{x},\left(x^{*}=x-h\right) =\sum_{x^{*}=0}^{\infty} \frac{\left(x^{*}+r+h-1\right) !}{x^{*} !(r-1) !} p^{r}(1-p)^{x^{*}+h} =\frac{(r+h-1) !}{(r-1) !} \frac{(1-p)^{h}}{p^{h}} \sum_{x^{*}=0}^{\infty} \frac{\left(x^{*}+h+r+1\right) !}{x^{*} !(r+h-1) !} p^{r+h}(1-p)^{x^{*}} =\frac{(r+h-1) !}{(r-1) !} \frac{(1-p)^{h}}{p^{h}} E[X]=\frac{r(1-p)}{p}","['probability', 'statistics', 'negative-binomial']"
3,Why do we consider a critical region instead of individual values? Why does the alternative hypothesis determine which tail to consider for rejection?,Why do we consider a critical region instead of individual values? Why does the alternative hypothesis determine which tail to consider for rejection?,,"Setup : Suppose a coin is tossed 8 times and I'm trying to determine whether the coin is biased in favour of landing on heads. Let $X$ be the number of heads in 8 tosses, so $X \sim B(8,p)$ . Conducting a hypothesis test with a significance level of $5\%$ , my null hypothesis would be $H_0\!: p = 0.5$ and my alternative hypothesis would be $H_1\!: p > 0.5$ . The method of conducting this test that I have learned is that I would first need to consider $X \sim B(8,0.5)$ . Since the alternative hypothesis is p greater than 0.5, I would need only consider the right tail of the distribution. Then I would need to find the minimum value of $a$ such that $P(X\geq a) < 0.05$ , so $[a,8]$ is the critical region. Thus if we observe $X$ to be between $[a,8]$ , it is statistically probable that the die is biased. Question : Why do we consider a critical region instead of individual values? It makes sense to me why we would consider a region in the context of continuous distributions, but why should we do it in the case of a discrete distribution? Suppose from the setup, $P(X=8) = 0.03$ and $P(X=7) = 0.049$ , then $X=7$ would not be part of the critical region even though individually its probability is still below the set threshold of $5\%$ . I don't understand why we should disregard $X=7$ . Why does the alternative hypothesis determine which tail to consider for rejection? The rule I have been taught is, if the alternative hypothesis contains a "">"", consider the right tail and if it contains a ""<"", consider the left tail.  Suppose from the setup, $P(X\geq7) < 0.05$ , then it's also true that $P(X\leq2) < 0.05$ . Thus why are we only considering one of the tails even though both tails contain values which are below the $5\%$ significance level? As $p$ increases, both of these regions are going to change in values, so I don't understand why we're focusing on the right tail. How does the alternative hypothesis play into this? Thanks for taking the time to read my question. Please don't respond with too much jargon-heavy language since I'm still in high school! I appreciate any and all help.","Setup : Suppose a coin is tossed 8 times and I'm trying to determine whether the coin is biased in favour of landing on heads. Let be the number of heads in 8 tosses, so . Conducting a hypothesis test with a significance level of , my null hypothesis would be and my alternative hypothesis would be . The method of conducting this test that I have learned is that I would first need to consider . Since the alternative hypothesis is p greater than 0.5, I would need only consider the right tail of the distribution. Then I would need to find the minimum value of such that , so is the critical region. Thus if we observe to be between , it is statistically probable that the die is biased. Question : Why do we consider a critical region instead of individual values? It makes sense to me why we would consider a region in the context of continuous distributions, but why should we do it in the case of a discrete distribution? Suppose from the setup, and , then would not be part of the critical region even though individually its probability is still below the set threshold of . I don't understand why we should disregard . Why does the alternative hypothesis determine which tail to consider for rejection? The rule I have been taught is, if the alternative hypothesis contains a "">"", consider the right tail and if it contains a ""<"", consider the left tail.  Suppose from the setup, , then it's also true that . Thus why are we only considering one of the tails even though both tails contain values which are below the significance level? As increases, both of these regions are going to change in values, so I don't understand why we're focusing on the right tail. How does the alternative hypothesis play into this? Thanks for taking the time to read my question. Please don't respond with too much jargon-heavy language since I'm still in high school! I appreciate any and all help.","X X \sim B(8,p) 5\% H_0\!: p = 0.5 H_1\!: p > 0.5 X \sim B(8,0.5) a P(X\geq a) < 0.05 [a,8] X [a,8] P(X=8) = 0.03 P(X=7) = 0.049 X=7 5\% X=7 P(X\geq7) < 0.05 P(X\leq2) < 0.05 5\% p","['statistics', 'hypothesis-testing']"
4,For what reason are data sets with no repeating values defined as no mode whilst sets with n/2 is part of the set of integers is defined?,For what reason are data sets with no repeating values defined as no mode whilst sets with n/2 is part of the set of integers is defined?,,"This question is in regards to the reasoning underpinning the definition of a set with no repeating values as having no mode.  I am interested in the analytical philosophy behind this. A set with no repeating values is defined as having no mode. But a set that has an even number of elements is described as having a median = [(n/2)th term + (n/2)+1 term)]/2 rather than “no median”. So, in cases where there is no repeating element, for what reason did mathematicians not define such sets as mode = mean?","This question is in regards to the reasoning underpinning the definition of a set with no repeating values as having no mode.  I am interested in the analytical philosophy behind this. A set with no repeating values is defined as having no mode. But a set that has an even number of elements is described as having a median = [(n/2)th term + (n/2)+1 term)]/2 rather than “no median”. So, in cases where there is no repeating element, for what reason did mathematicians not define such sets as mode = mean?",,['statistics']
5,Ordering of last two boxes!,Ordering of last two boxes!,,"Say that you have 6 boxes. All these boxes are uniform in all ways, except one. Which is colour. From this, we can see that 2 are red boxes, 2 are pink boxes, and 2 are black boxes? How would you find the probability that the last two boxes in all combinations possible are pink? I did something like this: Firstly, we know that there are 2 boxes of each type initially. Thus we have \begin{align} \frac{6!}{2! \times 2! \times 2!} \end{align} (we define this as A) Secondly, we know that the last 2 balls are pink. Now, we have that \begin{align} \frac{4!}{2! \times 2! } \end{align} (we define this as B) Thus, the probability is P = A/B. But I feel as if this is wrong as this looks like im approaching it as a ""given"" probability. Can someone guide me with this question?","Say that you have 6 boxes. All these boxes are uniform in all ways, except one. Which is colour. From this, we can see that 2 are red boxes, 2 are pink boxes, and 2 are black boxes? How would you find the probability that the last two boxes in all combinations possible are pink? I did something like this: Firstly, we know that there are 2 boxes of each type initially. Thus we have (we define this as A) Secondly, we know that the last 2 balls are pink. Now, we have that (we define this as B) Thus, the probability is P = A/B. But I feel as if this is wrong as this looks like im approaching it as a ""given"" probability. Can someone guide me with this question?","\begin{align}
\frac{6!}{2! \times 2! \times 2!}
\end{align} \begin{align}
\frac{4!}{2! \times 2! }
\end{align}","['probability', 'combinatorics', 'statistics', 'combinations']"
6,Is every estimator a sufficient statistic?,Is every estimator a sufficient statistic?,,"It is clear that not any sufficient statistic (s.s.) makes a good estimator (since a monotonic transform of a s.s. is still a s.s.).  But is a ""good"" estimator of the parameter always a s.s.? If not, under what conditions is this the case? I gather that the dimension of the s.s. may vary with the size of the data (e.g. Cauchy distribution), so perhaps we have to restrict ourselves to the exponential family of distributions for a start? I will leave open what ""good"" means, e.g. it could be unbiasedness or another condition under which this result holds.","It is clear that not any sufficient statistic (s.s.) makes a good estimator (since a monotonic transform of a s.s. is still a s.s.).  But is a ""good"" estimator of the parameter always a s.s.? If not, under what conditions is this the case? I gather that the dimension of the s.s. may vary with the size of the data (e.g. Cauchy distribution), so perhaps we have to restrict ourselves to the exponential family of distributions for a start? I will leave open what ""good"" means, e.g. it could be unbiasedness or another condition under which this result holds.",,"['statistics', 'statistical-inference', 'parameter-estimation']"
7,Ben and Jordan have three coins between them. Two of them are fair but one of them has a 4/7 chance of showing heads.,Ben and Jordan have three coins between them. Two of them are fair but one of them has a 4/7 chance of showing heads.,,"Now, Ben and Jordan both flip each coin once and write down the outcomes. What is the probability they both get the same number of heads? My approach: 4 possible outcomes: 3H, 3T, 2H&1T, 2T&1H. $P(3H) = (\frac{1}{2})^2\frac{4}{7} *\binom{3}{1} = \frac {36}{84} $ $P(3T) = (\frac{1}{2})^2\frac{3}{7} *\binom{3}{1} = \frac{27}{84}$ $P(2H,1T) = \frac{2}{3}(\frac{1}{2})^2\frac{4}{7} + \frac{1}{3}(\frac{1}{2})^2\frac{3}{7} = \frac{11}{84}$ $P(2T,1H) = \frac{2}{3}(\frac{1}{2})^2\frac{3}{7} + \frac{1}{3}(\frac{1}{2})^2\frac{4}{7} = \frac{10}{84}$ P(same number of heads) = $(\frac {36}{84})^2 + (\frac{27}{84})^2 + (\frac{11}{84})^2 + (\frac{10}{84})^2 = \frac{1123}{3528} \approx 32\% $ What do you think?","Now, Ben and Jordan both flip each coin once and write down the outcomes. What is the probability they both get the same number of heads? My approach: 4 possible outcomes: 3H, 3T, 2H&1T, 2T&1H. P(same number of heads) = What do you think?","P(3H) = (\frac{1}{2})^2\frac{4}{7} *\binom{3}{1} = \frac {36}{84}  P(3T) = (\frac{1}{2})^2\frac{3}{7} *\binom{3}{1} = \frac{27}{84} P(2H,1T) = \frac{2}{3}(\frac{1}{2})^2\frac{4}{7} + \frac{1}{3}(\frac{1}{2})^2\frac{3}{7} = \frac{11}{84} P(2T,1H) = \frac{2}{3}(\frac{1}{2})^2\frac{3}{7} + \frac{1}{3}(\frac{1}{2})^2\frac{4}{7} = \frac{10}{84} (\frac {36}{84})^2 + (\frac{27}{84})^2 + (\frac{11}{84})^2 + (\frac{10}{84})^2 = \frac{1123}{3528} \approx 32\% ","['probability', 'statistics', 'combinations']"
8,How to determine whether to use complement of event when calculating probability?,How to determine whether to use complement of event when calculating probability?,,"A sample problem in my textbook states: In a recent year, there were 18,187 U.S. allopathic medical school seniors who applied to residency programs and submitted their residency program choices. Of these seniors, 17,057 were matched with residency positions, with about 79.2% getting one of their top three choices. Medical students rank the residency programs in their order of preference, and program directors in the United States rank the students. The term “match” refers to the process whereby a student’s preference list and a program director’s preference list overlap, resulting in the placement of the student in a residency position. Find the probability that a randomly selected senior was matched with a residency position and it was one of the senior’s top three choices. Find the probability that a randomly selected senior who was matched with a residency position did not get matched with one of the senior’s top three choices. 1 is obvious: $(\frac{17057}{18187})(0.792) \approx 0.743$ For 2, the textbook says to take the complement of 0.792: $1 - 0.792 = 0.208$ But my question is: why wouldn't you solve this one the same way as part 1? As in: $$(\frac{17057}{18187})(1 - 0.792) \approx 0.195$$ why wouldn't you do that?","A sample problem in my textbook states: In a recent year, there were 18,187 U.S. allopathic medical school seniors who applied to residency programs and submitted their residency program choices. Of these seniors, 17,057 were matched with residency positions, with about 79.2% getting one of their top three choices. Medical students rank the residency programs in their order of preference, and program directors in the United States rank the students. The term “match” refers to the process whereby a student’s preference list and a program director’s preference list overlap, resulting in the placement of the student in a residency position. Find the probability that a randomly selected senior was matched with a residency position and it was one of the senior’s top three choices. Find the probability that a randomly selected senior who was matched with a residency position did not get matched with one of the senior’s top three choices. 1 is obvious: For 2, the textbook says to take the complement of 0.792: But my question is: why wouldn't you solve this one the same way as part 1? As in: why wouldn't you do that?",(\frac{17057}{18187})(0.792) \approx 0.743 1 - 0.792 = 0.208 (\frac{17057}{18187})(1 - 0.792) \approx 0.195,"['probability', 'statistics']"
9,"Probability of Power Rangers, please correct me if I am wrong","Probability of Power Rangers, please correct me if I am wrong",,"There are five Power Rangers.  Of the five,  two are male(Red, Black) and three are female (Pink, Yellow,blue.)I randomly select two of the Power Rangers, without replacement. (a)  What is the probability that the black Ranger is one of the two selected Power Rangers? pretending that you only randomly select one power ranger, the  probability of picking the black would just be 1/5, so if you were  to pick another it would be 1/4 so it would be 1/5 * 1/4 = .05 so 5% chance?  it just seems low (b)  What is the probability at least one of the two selected Power Rangers is female? probability that one is female is 3/5, so if you were to pick  another power ranger at random would it be 3/5*3/4 (c)  Given that at least one of the two selected Power Rangers is male, what is the conditional probability the Pink Ranger is selected? conditional probability, wouldnt it just be 33.3% that the pink is selected given theres only three females? (d)  Are the events “the Pink Ranger is one of the two selected” and “at least one of the two selected Power Rangers is female” independent?  Explain why or why not. Yes, event A effects event B.","There are five Power Rangers.  Of the five,  two are male(Red, Black) and three are female (Pink, Yellow,blue.)I randomly select two of the Power Rangers, without replacement. (a)  What is the probability that the black Ranger is one of the two selected Power Rangers? pretending that you only randomly select one power ranger, the  probability of picking the black would just be 1/5, so if you were  to pick another it would be 1/4 so it would be 1/5 * 1/4 = .05 so 5% chance?  it just seems low (b)  What is the probability at least one of the two selected Power Rangers is female? probability that one is female is 3/5, so if you were to pick  another power ranger at random would it be 3/5*3/4 (c)  Given that at least one of the two selected Power Rangers is male, what is the conditional probability the Pink Ranger is selected? conditional probability, wouldnt it just be 33.3% that the pink is selected given theres only three females? (d)  Are the events “the Pink Ranger is one of the two selected” and “at least one of the two selected Power Rangers is female” independent?  Explain why or why not. Yes, event A effects event B.",,"['probability', 'statistics']"
10,Posterior distribution of exponential prior and likelihood?,Posterior distribution of exponential prior and likelihood?,,"I have the prior density function: $$e^{-\theta} \text{ for } \theta > 0$$ and the likelihood function: $e^{\theta -x}$ for $x \geq \theta$ I have gotten the following in my attempt to derive the posterior distribution: $$L(\theta) = \prod e^{\theta - x_i} = e^{n\theta}e^{-\sum x_i} \mathbb{I}_{\min X_i}$$ $$\pi(\theta \mid x) = \frac{ e^{-\sum x_i} e^{\theta(n-1)} \mathbb{I}_{\min X_i}}{e^{-\sum x_i}\int_0^{\min(x)}e^{n\theta}e^{-\theta} \, d\theta}$$ $$= \frac{e^{\theta(n-1)}\mathbb{I_{\min X_i}}}{\frac{1}{n-1}e^{\min(x)(n-1)} - \frac{1}{n-1}}$$ Is this correct? Does this further simplify, or is the posterior simply non-standard?","I have the prior density function: and the likelihood function: for I have gotten the following in my attempt to derive the posterior distribution: Is this correct? Does this further simplify, or is the posterior simply non-standard?","e^{-\theta} \text{ for } \theta > 0 e^{\theta -x} x \geq \theta L(\theta) = \prod e^{\theta - x_i} = e^{n\theta}e^{-\sum x_i} \mathbb{I}_{\min X_i} \pi(\theta \mid x) = \frac{ e^{-\sum x_i} e^{\theta(n-1)} \mathbb{I}_{\min X_i}}{e^{-\sum x_i}\int_0^{\min(x)}e^{n\theta}e^{-\theta} \, d\theta} = \frac{e^{\theta(n-1)}\mathbb{I_{\min X_i}}}{\frac{1}{n-1}e^{\min(x)(n-1)} - \frac{1}{n-1}}","['probability', 'statistics', 'bayesian']"
11,What is the best method to estimate a definite integral from given samples of the integrand?,What is the best method to estimate a definite integral from given samples of the integrand?,,"I need to calculate something of the form \begin{equation} \int_{D} f(\mathbf{x}) d\mathbf{x} \end{equation} with $D \subseteq \mathbb{R^2}$ , but I only have available $f(\mathbf{x})$ at given samples of points in $D$ . What do you suggest to do the estimate? For example, I think Monte Carlo integration doesn't apply directly because I can't evaluate $f(\mathbf{x})$ at arbitrary $\mathbf{x}$ . Maybe it could be some kind of combination of Monte Carlo and interpolation?","I need to calculate something of the form with , but I only have available at given samples of points in . What do you suggest to do the estimate? For example, I think Monte Carlo integration doesn't apply directly because I can't evaluate at arbitrary . Maybe it could be some kind of combination of Monte Carlo and interpolation?","\begin{equation}
\int_{D} f(\mathbf{x}) d\mathbf{x}
\end{equation} D \subseteq \mathbb{R^2} f(\mathbf{x}) D f(\mathbf{x}) \mathbf{x}","['integration', 'statistics', 'numerical-methods', 'estimation']"
12,Fairness of rolling a die 3 times,Fairness of rolling a die 3 times,,I have a pair of sneakers to give away and 3 friends would like to have it. I decided to have them each roll a dice and the person with the highest number wins the sneakers. Does the first person to roll the dice have an advantage over the other two?,I have a pair of sneakers to give away and 3 friends would like to have it. I decided to have them each roll a dice and the person with the highest number wins the sneakers. Does the first person to roll the dice have an advantage over the other two?,,"['probability', 'statistics', 'dice']"
13,Probability - constant probability throughout the day,Probability - constant probability throughout the day,,"The probability of an electronics store selling at least one computer in an 8-hour working day is 0.8. Assuming a constant probability throughout the day, what’s the probability of the store selling at least one computer in any given 2-hour time window? Hi, i want to understand how to approch this kind of questions. if any one can explain? and get the answer.","The probability of an electronics store selling at least one computer in an 8-hour working day is 0.8. Assuming a constant probability throughout the day, what’s the probability of the store selling at least one computer in any given 2-hour time window? Hi, i want to understand how to approch this kind of questions. if any one can explain? and get the answer.",,"['probability', 'statistics']"
14,"Is this true: $\operatorname{Cov}(X,Y)=\operatorname{Cov}(E[X|Y],Y)$? Covariance of variables versus conditional expectations?",Is this true: ? Covariance of variables versus conditional expectations?,"\operatorname{Cov}(X,Y)=\operatorname{Cov}(E[X|Y],Y)","Let $X$ and $Y$ be to correlated random variables.  Is the following true? $\operatorname{Cov}[E[X|Y],Y]=\operatorname{Cov}[X,Y]$ I derived this for from the standard expression for covariance, and it holds if $E[E[X|Y]*Y]=E[XY]$ is correct, but somehow this seems wrong to me.","Let and be to correlated random variables.  Is the following true? I derived this for from the standard expression for covariance, and it holds if is correct, but somehow this seems wrong to me.","X Y \operatorname{Cov}[E[X|Y],Y]=\operatorname{Cov}[X,Y] E[E[X|Y]*Y]=E[XY]","['probability', 'statistics', 'conditional-expectation', 'conditional-probability', 'covariance']"
15,Find the distribution of $\xi$,Find the distribution of,\xi,"Assume $X_1,\ldots,X_n$ are independent random variables, where $X_i\sim N(0,\sigma_i^2),i=1,2,\cdots,n$ . Define $$Z=\frac{\sum\limits_{i=1}^{n}\frac{X_i}{\sigma_i^2}}{\sum\limits_{i=1}^{n}\frac{1}{\sigma_i^2}},$$ and $$\xi=\sum\limits_{i=1}^{n}\frac{(X_i-Z)^2}{\sigma_i^2}.$$ Find the distribution of $\xi$ . I tried to normalize the random variables but obtained nothing useful, and I have no idea where is the correct way to get the answer. Can you give me a hint? Thank you!","Assume are independent random variables, where . Define and Find the distribution of . I tried to normalize the random variables but obtained nothing useful, and I have no idea where is the correct way to get the answer. Can you give me a hint? Thank you!","X_1,\ldots,X_n X_i\sim N(0,\sigma_i^2),i=1,2,\cdots,n Z=\frac{\sum\limits_{i=1}^{n}\frac{X_i}{\sigma_i^2}}{\sum\limits_{i=1}^{n}\frac{1}{\sigma_i^2}}, \xi=\sum\limits_{i=1}^{n}\frac{(X_i-Z)^2}{\sigma_i^2}. \xi","['statistics', 'probability-distributions', 'normal-distribution']"
16,Statistics: Central Limit Theorem question,Statistics: Central Limit Theorem question,,"A commuter encounters four traffic lights each day on her way to work. Let $X$ represent the number of these that are red lights. The probability mass function of $X$ is as follows: \begin{array}{c|ccccc}x&0&1&2&3&4\\\hline\operatorname P(X=x)&0.1&0.3&0.3&0.2&0.1\end{array} What is the probability that in a period of $100$ days, the average number of red lights encountered is more than $2$ per day? I have calculated mean to be $\mu = .038$ and $\sigma =  .04562$ (guessing st. deviation gets divided by $n$ large, which is $100$ ? Following a previous example I saw) I'm struggling figuring out how to get $\operatorname P(X>2)$ . I tried doing $\operatorname P(X \le 2)$ , but once I plug in the math ( $1 - \frac{2-.038}{\sqrt{.04562}}$ using formula $\frac{c-\mu}{\sqrt{\sigma}}$ ), I get a number that I cannot get a $z$ -score out of. I'm assuming some of what I'm doing is right, since I'm trying to follow notes we received in class. Otherwise, I'm having trouble getting the right $z$ -score to find the probability.","A commuter encounters four traffic lights each day on her way to work. Let represent the number of these that are red lights. The probability mass function of is as follows: What is the probability that in a period of days, the average number of red lights encountered is more than per day? I have calculated mean to be and (guessing st. deviation gets divided by large, which is ? Following a previous example I saw) I'm struggling figuring out how to get . I tried doing , but once I plug in the math ( using formula ), I get a number that I cannot get a -score out of. I'm assuming some of what I'm doing is right, since I'm trying to follow notes we received in class. Otherwise, I'm having trouble getting the right -score to find the probability.",X X \begin{array}{c|ccccc}x&0&1&2&3&4\\\hline\operatorname P(X=x)&0.1&0.3&0.3&0.2&0.1\end{array} 100 2 \mu = .038 \sigma =  .04562 n 100 \operatorname P(X>2) \operatorname P(X \le 2) 1 - \frac{2-.038}{\sqrt{.04562}} \frac{c-\mu}{\sqrt{\sigma}} z z,['statistics']
17,Why does the reduction of the total cards (pool) make no difference to the probability that I will get a certain card in my hand,Why does the reduction of the total cards (pool) make no difference to the probability that I will get a certain card in my hand,,"Some friends and I had a heated debate about this and I am still quite confused. The problem I will use an example of 8 cards in a bag, Each card has a letter on it, e.g. A,B,C,D,E,F,G,H. You draw 3 cards . What are the chances of getting a specific card (e.g. B) in that final hand (i.e. what are the chances that one of the cards you now have is the one you wanted)? My logic: I thought surely its 1/8 then 1/7, then 1/6 as each time a card is taken there are less cards? This would be 1/8 + 1/7 + 1/6 = 43.5% chance. Someone pointed out to me that on the second, and third times your card may already be chosen, but in my head this should not be a reason your chances get worse... but i'm sure that's the key thing i don't understand. They said it actually remains a 1/8 each time so 1/8 + 1/8 + 1/8 = 3/8 = 37.5% Which is correct (see simulation at bottom), and someone else pointed out that if you extrapolate my logic to picking 8 cards 1/8 + 1/7 + 1/6 + 1/5 + 1/4 + 1/3 + 1/2 + 1/1 You get over 200% which is obviously wrong. The Question/Confusion Why does the reduction not affect (appear in) the maths? I feel the ""reduction"" in the pool should impact the maths or at least be cancelled out and that's what I struggle to grasp. Why does the reduction in the pool seemingly make no difference whatsoever, its seems at odds with what I feel I learnt from the Monty Hall problem.... I even felt the need to simulate it and sure enough *the answer was 37.5%. My gut tells me that the reduction might become statistically relevant in some cases, but my brain says there is missing (i.e. cancelled out maths) above that would explain that this is not true. Could someone help the penny drop and enlighten me? simulation: https://dotnetfiddle.net/ebTl5B --- [Full Maths] --- (Thanks Ethan!) Added here as it will render nicer then in the comments, but you will want to read Ethans answer below for why you do this. $$\frac{1}{8}  + (\frac{7}{8} * \frac{1}{7}) + (\frac{7}{8} * \frac{6}{7} * \frac{1}{6}) = $$ $$\frac{1}{8}  + \frac{1}{8} + \frac{1}{8} = $$ $$\frac{3}{8} =$$ $$ 0.375 $$","Some friends and I had a heated debate about this and I am still quite confused. The problem I will use an example of 8 cards in a bag, Each card has a letter on it, e.g. A,B,C,D,E,F,G,H. You draw 3 cards . What are the chances of getting a specific card (e.g. B) in that final hand (i.e. what are the chances that one of the cards you now have is the one you wanted)? My logic: I thought surely its 1/8 then 1/7, then 1/6 as each time a card is taken there are less cards? This would be 1/8 + 1/7 + 1/6 = 43.5% chance. Someone pointed out to me that on the second, and third times your card may already be chosen, but in my head this should not be a reason your chances get worse... but i'm sure that's the key thing i don't understand. They said it actually remains a 1/8 each time so 1/8 + 1/8 + 1/8 = 3/8 = 37.5% Which is correct (see simulation at bottom), and someone else pointed out that if you extrapolate my logic to picking 8 cards 1/8 + 1/7 + 1/6 + 1/5 + 1/4 + 1/3 + 1/2 + 1/1 You get over 200% which is obviously wrong. The Question/Confusion Why does the reduction not affect (appear in) the maths? I feel the ""reduction"" in the pool should impact the maths or at least be cancelled out and that's what I struggle to grasp. Why does the reduction in the pool seemingly make no difference whatsoever, its seems at odds with what I feel I learnt from the Monty Hall problem.... I even felt the need to simulate it and sure enough *the answer was 37.5%. My gut tells me that the reduction might become statistically relevant in some cases, but my brain says there is missing (i.e. cancelled out maths) above that would explain that this is not true. Could someone help the penny drop and enlighten me? simulation: https://dotnetfiddle.net/ebTl5B --- [Full Maths] --- (Thanks Ethan!) Added here as it will render nicer then in the comments, but you will want to read Ethans answer below for why you do this.",\frac{1}{8}  + (\frac{7}{8} * \frac{1}{7}) + (\frac{7}{8} * \frac{6}{7} * \frac{1}{6}) =  \frac{1}{8}  + \frac{1}{8} + \frac{1}{8} =  \frac{3}{8} =  0.375 ,"['probability', 'statistics', 'proof-explanation']"
18,"Variance, mean and median","Variance, mean and median",,"Is it possible to find an example of two samples each of size 5 which have equal mean and equal variance but distinct median? I thought about this for a while but have not been successful in coming up with such an example, so I believe the answer Is no, but I don't know why.","Is it possible to find an example of two samples each of size 5 which have equal mean and equal variance but distinct median? I thought about this for a while but have not been successful in coming up with such an example, so I believe the answer Is no, but I don't know why.",,['statistics']
19,how to check a propriety using r studio,how to check a propriety using r studio,,"I have to check that this propriety $Z \sim N(0,1)$ and $U\sim \chi ^{2}(10)$ then $ Z/\sqrt{U/10} \sim T(10)$ is true using r studio if anyone can help , much appreciate","I have to check that this propriety and then is true using r studio if anyone can help , much appreciate","Z \sim N(0,1) U\sim \chi ^{2}(10)  Z/\sqrt{U/10} \sim T(10)",['probability']
20,Is it possible to create sets that satisfy the following conditions?,Is it possible to create sets that satisfy the following conditions?,,"A class of 96 students must divide itself into 24 sets of 4 for an assignment. However, during the year there are 4 such assignments, and no student can ever work with any of the same partners. Prove that this is possible or impossible to do. Note that, if for project 1, Anne, Bob, Chris, and David are working together, then for project 2 Anne cannot work with Bob, Chris, or David for any other project.","A class of 96 students must divide itself into 24 sets of 4 for an assignment. However, during the year there are 4 such assignments, and no student can ever work with any of the same partners. Prove that this is possible or impossible to do. Note that, if for project 1, Anne, Bob, Chris, and David are working together, then for project 2 Anne cannot work with Bob, Chris, or David for any other project.",,"['combinatorics', 'statistics']"
21,"If $X$ and $Y$ are independent $N(0,\sigma^2)$, then $X^2+Y^2$ and $X/Y$ are independent?","If  and  are independent , then  and  are independent?","X Y N(0,\sigma^2) X^2+Y^2 X/Y","If $X$ and $Y$ are independent, then $X^2+Y^2$ and $X/Y$ are independent? I was solving the problem for the case that $X$ and $Y$ are independent $N(0,\sigma^2)$ . So i found that $X^2+Y^2$ is negative exponential, $X/Y$ is Cauchy distribution. How can i prove that $X^2+Y^2$ and $X/Y$ are independent? Also, what it will be if the case for general random variable $X$ , $Y$ with $X^2+Y^2$ and $X/Y$ are defined?","If and are independent, then and are independent? I was solving the problem for the case that and are independent . So i found that is negative exponential, is Cauchy distribution. How can i prove that and are independent? Also, what it will be if the case for general random variable , with and are defined?","X Y X^2+Y^2 X/Y X Y N(0,\sigma^2) X^2+Y^2 X/Y X^2+Y^2 X/Y X Y X^2+Y^2 X/Y","['probability', 'statistics', 'probability-distributions', 'random-variables', 'independence']"
22,"Maximum likelihood - uniform distribution on the interval $[θ_1,θ_2]$",Maximum likelihood - uniform distribution on the interval,"[θ_1,θ_2]","Based on a random sample (6.3, 1.8, 14.2, 7.6) use the method of maximum likelihood to estimate the maximum likelihoods for $\theta_1$ and $\theta_2$ . $$f_y(y;\theta_1, \theta_2) = \frac{1}{\theta_2- \theta_1} \;, \quad \theta_1 \le \theta_2$$ $$L(\theta_1, \theta_2) = \prod_\limits{i=1}^{n}\frac{1}{\theta_2-\theta_1} \\ = \frac{1}{(\theta_2- \theta_1)^n}\prod_\limits{i=1}^{n}1(\theta_1 \le y_i \le \theta_2) \\ = \frac{1}{(\theta_2- \theta_1)^n}\prod_\limits{i=1}^{n}1(\theta_1 \le y_i)1(y_i \le \theta_2) \\ \text{Let } T = \ln[L(\theta_1, \theta_2)] = -n \ln(\theta_2 - \theta_1) + \sum_\limits{i=1}^n\ln(1(\theta_1 \le \min_i(y_i))1(\max_i(y_i) \le \theta_2)) \\ \begin{cases} -\infty, & \text{if } \theta_1>\min_i(y_i) \text{ or } \theta_2 < \max_i(y_i) \\ -n\ln(\theta_2 - \theta_1), &  \text{otherwise}  \end{cases} $$ now take the derivative with respect to one of them $$\frac{\partial{T}}{\partial{\theta_2}} = \frac{-n}{\theta_2 - \theta_1} \\ = \frac{n}{\theta_1 - \theta_2}$$ To maximise this we want the numerator magnitude to be as small as possible, so we set $\theta_2 = \max_i(y_i)$ and for $\theta_1$ $$\frac{\partial{T}}{\partial{\theta_1}}=\frac{n}{\max_i(y_i) - \theta_1}$$ To maximise this, we want $\theta_1 = \min_i(y_i)$ This implies $\theta_1 = 1.8$ and $\theta_2 = 14.2$ If someone could check my correctness particularly around the indicator functions because I'm new to those and anything else you can see wrong in math or formatting. Actually I think that stuff in yellow directly above is not right. I'm not equating the derivative to 0. I think I got the correct answer regardless. Probably more preferably is to look at the $$-n\ln(\theta_2 - \theta_1)$$ And know to minimise the value in the brackets will maximise the $\ln[L(\theta_1, \theta_2)]$ function, and coming to the same result that I did illegitimately. Implies that $\hat{\theta_1} = 1.8$ and $\hat{\theta_2}=14.2$","Based on a random sample (6.3, 1.8, 14.2, 7.6) use the method of maximum likelihood to estimate the maximum likelihoods for and . now take the derivative with respect to one of them To maximise this we want the numerator magnitude to be as small as possible, so we set and for To maximise this, we want This implies and If someone could check my correctness particularly around the indicator functions because I'm new to those and anything else you can see wrong in math or formatting. Actually I think that stuff in yellow directly above is not right. I'm not equating the derivative to 0. I think I got the correct answer regardless. Probably more preferably is to look at the And know to minimise the value in the brackets will maximise the function, and coming to the same result that I did illegitimately. Implies that and","\theta_1 \theta_2 f_y(y;\theta_1, \theta_2) = \frac{1}{\theta_2- \theta_1} \;, \quad \theta_1 \le \theta_2 L(\theta_1, \theta_2) = \prod_\limits{i=1}^{n}\frac{1}{\theta_2-\theta_1} \\
= \frac{1}{(\theta_2- \theta_1)^n}\prod_\limits{i=1}^{n}1(\theta_1 \le y_i \le \theta_2) \\
= \frac{1}{(\theta_2- \theta_1)^n}\prod_\limits{i=1}^{n}1(\theta_1 \le y_i)1(y_i \le \theta_2) \\
\text{Let } T = \ln[L(\theta_1, \theta_2)] = -n \ln(\theta_2 - \theta_1) + \sum_\limits{i=1}^n\ln(1(\theta_1 \le \min_i(y_i))1(\max_i(y_i) \le \theta_2)) \\
\begin{cases}
-\infty, & \text{if } \theta_1>\min_i(y_i) \text{ or } \theta_2 < \max_i(y_i) \\
-n\ln(\theta_2 - \theta_1), &  \text{otherwise} 
\end{cases}  \frac{\partial{T}}{\partial{\theta_2}} = \frac{-n}{\theta_2 - \theta_1} \\
= \frac{n}{\theta_1 - \theta_2} \theta_2 = \max_i(y_i) \theta_1 \frac{\partial{T}}{\partial{\theta_1}}=\frac{n}{\max_i(y_i) - \theta_1} \theta_1 = \min_i(y_i) \theta_1 = 1.8 \theta_2 = 14.2 -n\ln(\theta_2 - \theta_1) \ln[L(\theta_1, \theta_2)] \hat{\theta_1} = 1.8 \hat{\theta_2}=14.2","['calculus', 'statistics', 'maximum-likelihood']"
23,Probability of student entering an university (problem),Probability of student entering an university (problem),,"100 Students want to enter a university. Each student has a 4% chance of entering (they all enter independently) What is the chance of atleast 3 entering the university? The answer to this question is 0.7678 I just dont know how to get to this. I tried doing this: Each student has a 96% of not entering, the chances of 3 students not entering therefore should be (0.96)^3. Now if i want the chances of atleast 3 entering i do 1 - (0.96)^3 = 0.115 Can someone explain me what i did wrong?","100 Students want to enter a university. Each student has a 4% chance of entering (they all enter independently) What is the chance of atleast 3 entering the university? The answer to this question is 0.7678 I just dont know how to get to this. I tried doing this: Each student has a 96% of not entering, the chances of 3 students not entering therefore should be (0.96)^3. Now if i want the chances of atleast 3 entering i do 1 - (0.96)^3 = 0.115 Can someone explain me what i did wrong?",,"['probability', 'statistics']"
24,"$f(x, \theta)= \frac{\theta}{x^2}$ with $x\geq\theta$ and $\theta>0$, find the MLE","with  and , find the MLE","f(x, \theta)= \frac{\theta}{x^2} x\geq\theta \theta>0","Let $X$ be a random variable with density $$f(x, \theta)= \frac{\theta}{x^2}$$ with $x\geq\theta$ and $\theta>0$. a) Show if $S=\min\{x_1,\cdots, x_n\}$ is a sufficient statistics and if it is minimal. b) Find the Maximum Likelihood Estimator of $\theta$ and tell if it is unbiased. c) Find the distribution of $S$ and tell if there is an unbiased estimator of the form $cS$ for some $c$. attempt: There are several problems. $S$ doens't look like a sufficient statistics cause $L(\theta|x_1, \cdots, x_n)= \frac{\theta^n}{(x_1\cdots x_n)^2}$ doesn't seem to be known if we know the minimum. Morover there is no maximum for that function so I can't find MLE. Thanks!","Let $X$ be a random variable with density $$f(x, \theta)= \frac{\theta}{x^2}$$ with $x\geq\theta$ and $\theta>0$. a) Show if $S=\min\{x_1,\cdots, x_n\}$ is a sufficient statistics and if it is minimal. b) Find the Maximum Likelihood Estimator of $\theta$ and tell if it is unbiased. c) Find the distribution of $S$ and tell if there is an unbiased estimator of the form $cS$ for some $c$. attempt: There are several problems. $S$ doens't look like a sufficient statistics cause $L(\theta|x_1, \cdots, x_n)= \frac{\theta^n}{(x_1\cdots x_n)^2}$ doesn't seem to be known if we know the minimum. Morover there is no maximum for that function so I can't find MLE. Thanks!",,"['probability', 'statistics', 'probability-distributions', 'statistical-inference']"
25,What's the probability that at least one passenger gets no seat?,What's the probability that at least one passenger gets no seat?,,"Two airplane companies respectively use one airplane (to go from   country A to country B). There are in total $1000$ people randomly   choose the airplane, respectively with probability $\frac{1}{2}$. The company offers planes with $510$ seats for passengers. What's the   probability that at least one passenger gets no seat? I think theorem of De Moivre Laplace is good to use here: First of we have $P(X \geq 510 +1) = p$ Then $$\lim_{n \rightarrow \infty}\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}}\leq x\right) = \Phi(x)$$ $$P(X \geq 510+1) = 1-P(X \leq 510) = 1-\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}} \leq \frac{510}{\sqrt{1000 \cdot \frac{1}{2}(1-\frac{1}{2})}}\right)  \\ = 1-\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}} \leq \frac{510}{5\sqrt{10}}\right) \approx 1-\Phi\left(\frac{510}{5\sqrt{10}}\right) \leq p$$ But from here I don't know how continue and if correct till here? I need read value from table but I don't know how and find it for this high value?","Two airplane companies respectively use one airplane (to go from   country A to country B). There are in total $1000$ people randomly   choose the airplane, respectively with probability $\frac{1}{2}$. The company offers planes with $510$ seats for passengers. What's the   probability that at least one passenger gets no seat? I think theorem of De Moivre Laplace is good to use here: First of we have $P(X \geq 510 +1) = p$ Then $$\lim_{n \rightarrow \infty}\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}}\leq x\right) = \Phi(x)$$ $$P(X \geq 510+1) = 1-P(X \leq 510) = 1-\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}} \leq \frac{510}{\sqrt{1000 \cdot \frac{1}{2}(1-\frac{1}{2})}}\right)  \\ = 1-\mathbb{P}\left(\frac{X-np}{\sqrt{np(1-p)}} \leq \frac{510}{5\sqrt{10}}\right) \approx 1-\Phi\left(\frac{510}{5\sqrt{10}}\right) \leq p$$ But from here I don't know how continue and if correct till here? I need read value from table but I don't know how and find it for this high value?",,"['probability', 'statistics', 'discrete-mathematics', 'probability-distributions']"
26,A couple want to have one girl and one boy. What is the expected number of children they will have? [closed],A couple want to have one girl and one boy. What is the expected number of children they will have? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A couple want to have one girl and one boy. What is the expected number of children they will have? I know that the answer is 3 and that the question relates to the Negative Binomial distribution but I'm not sure how to solve this. Can anyone explain?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A couple want to have one girl and one boy. What is the expected number of children they will have? I know that the answer is 3 and that the question relates to the Negative Binomial distribution but I'm not sure how to solve this. Can anyone explain?",,"['probability', 'statistics', 'negative-binomial']"
27,probability of combinations for numbers 1-7 [closed],probability of combinations for numbers 1-7 [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question In Japan, there is a Chimpanzee named Ai who can evidently understand numbers better than many college students. The numbers 1 - 7 appear on a computer screen for Ai. Ai then touches the screen to select the numbers in the correct order. Each time Ai selects a number, it disappears from the screen of choices. What is the probability of getting the entire sequence correct (1,2,3,4,5,6,7) if the chimp, Ai, is just guessing?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question In Japan, there is a Chimpanzee named Ai who can evidently understand numbers better than many college students. The numbers 1 - 7 appear on a computer screen for Ai. Ai then touches the screen to select the numbers in the correct order. Each time Ai selects a number, it disappears from the screen of choices. What is the probability of getting the entire sequence correct (1,2,3,4,5,6,7) if the chimp, Ai, is just guessing?",,"['probability', 'sequences-and-series', 'statistics']"
28,What is the maximum likelihood estimate of $p$?,What is the maximum likelihood estimate of ?,p,"$1,2,3,3,4$ is a random sample from $X$ that has the following probability distribution: $P(X=1)=P(X=2)=1/4$. $P(X=3)=p$ $P(X=4)=\frac{1}{2}-p$ Find the Maximum likelihood estimate for $p$ I have solved many problems on finding MLE's and I know only the method of finding the likelihood function and differentiating it. I have no clue how to solve this one.","$1,2,3,3,4$ is a random sample from $X$ that has the following probability distribution: $P(X=1)=P(X=2)=1/4$. $P(X=3)=p$ $P(X=4)=\frac{1}{2}-p$ Find the Maximum likelihood estimate for $p$ I have solved many problems on finding MLE's and I know only the method of finding the likelihood function and differentiating it. I have no clue how to solve this one.",,"['statistics', 'parameter-estimation']"
29,Expected value: Poisson random variable,Expected value: Poisson random variable,,"I have proved that $$E[X^n]=\lambda E[(X+1)^{n-1}]$$ for a Poisson random variable with parameter $\lambda$ where $n$ is a positive integer. Now $E[X+2]=E[X]+2=\lambda+2$ But using the formula that I proved, $E[X+2]=\lambda E[(X+3)^0]=\lambda E[1]=\lambda$ Which of these is correct and where have I gone wrong? Proof of $E[X^n]=\lambda E[(X+1)^{n-1}]$: \begin{align} E[X^n]&=\sum_{i=0}^\infty i^np(i) \\ &=\sum_{i=0}^\infty i^ne^{-\lambda}\frac{\lambda^i}{i!} \\ &=\lambda\sum_{i=0}^\infty i^ne^{-\lambda}\frac{\lambda^{i-1}}{i!} \\ &=\lambda\sum_{i=1}^\infty i^ne^{-\lambda}\frac{\lambda^{i-1}}{i!} \\ &=\lambda\sum_{i=1}^\infty i^{n-1}e^{-\lambda}\frac{\lambda^{i-1}}{(i-1)!} \\ &=\lambda\sum_{i=0}^\infty(i+1)^{n-1}e^{-\lambda}\frac{\lambda^i}{i!} \\ &=\lambda\sum_{i=0}^\infty(i+1)^{n-1}p(i) \\ &=\lambda E[(X+1)^{n-1}] \end{align}","I have proved that $$E[X^n]=\lambda E[(X+1)^{n-1}]$$ for a Poisson random variable with parameter $\lambda$ where $n$ is a positive integer. Now $E[X+2]=E[X]+2=\lambda+2$ But using the formula that I proved, $E[X+2]=\lambda E[(X+3)^0]=\lambda E[1]=\lambda$ Which of these is correct and where have I gone wrong? Proof of $E[X^n]=\lambda E[(X+1)^{n-1}]$: \begin{align} E[X^n]&=\sum_{i=0}^\infty i^np(i) \\ &=\sum_{i=0}^\infty i^ne^{-\lambda}\frac{\lambda^i}{i!} \\ &=\lambda\sum_{i=0}^\infty i^ne^{-\lambda}\frac{\lambda^{i-1}}{i!} \\ &=\lambda\sum_{i=1}^\infty i^ne^{-\lambda}\frac{\lambda^{i-1}}{i!} \\ &=\lambda\sum_{i=1}^\infty i^{n-1}e^{-\lambda}\frac{\lambda^{i-1}}{(i-1)!} \\ &=\lambda\sum_{i=0}^\infty(i+1)^{n-1}e^{-\lambda}\frac{\lambda^i}{i!} \\ &=\lambda\sum_{i=0}^\infty(i+1)^{n-1}p(i) \\ &=\lambda E[(X+1)^{n-1}] \end{align}",,"['probability', 'statistics']"
30,Probability that a passenger will catch the bus,Probability that a passenger will catch the bus,,A bus and a passenger arrive at a bus stop at a uniformly distributed time over the interval $0$ to $1$ hour. Assume the arrival times of the bus and passenger are independent of one another and that the passenger will wait up to $15$ minutes for the bus to arrive. What is the probability that the passenger will catch the bus? Hint: Let $Y1$ denote the bus arrival time and $Y2$ the passenger arrival time. Determine the joint density of $Y1$ and $Y2$ and determine $$P(Y2 \leq Y1 \leq Y2+\frac{1}{4}).$$ We already know that the answer to this question is $\frac{7}{32}$. Any help would be much appreciated.,A bus and a passenger arrive at a bus stop at a uniformly distributed time over the interval $0$ to $1$ hour. Assume the arrival times of the bus and passenger are independent of one another and that the passenger will wait up to $15$ minutes for the bus to arrive. What is the probability that the passenger will catch the bus? Hint: Let $Y1$ denote the bus arrival time and $Y2$ the passenger arrival time. Determine the joint density of $Y1$ and $Y2$ and determine $$P(Y2 \leq Y1 \leq Y2+\frac{1}{4}).$$ We already know that the answer to this question is $\frac{7}{32}$. Any help would be much appreciated.,,"['probability', 'statistics', 'density-function']"
31,What does the p in p-value stand for?,What does the p in p-value stand for?,,"Just to clarify, I know more or less how the p-value works, and that the topic of how to properly use the p-value for statistics has already been addressed on this site. I was really just wondering what it actually stood for, as I couldn't find an answer elsewhere on the internet.","Just to clarify, I know more or less how the p-value works, and that the topic of how to properly use the p-value for statistics has already been addressed on this site. I was really just wondering what it actually stood for, as I couldn't find an answer elsewhere on the internet.",,"['statistics', 'terminology', 'chi-squared']"
32,Expected value of squared sum vs. square of expected sum,Expected value of squared sum vs. square of expected sum,,"Edit: A lot of my computations in the question below are utterly wrong, I just left them as they since the comments/answers applied to the original form. Edit: I have updated the question to hopefully better explain the draws I am referring to. In the actual problem, $x_{(i)}, i\in\{1,\ldots,n\}$ are the $n$ lowest out of $m$ i.i.d. draws from $U[0,1]$. I hope I am making a duly simplification below. Let $x_{(1)}\leq\ldots\leq x_{(n)}$ be $n$ i.i.d. draws of a random variable uniformly distributed in $[0,1]$. I know that (if I am not mistaken) \begin{alignat*}{2} E[x_{(i)}]&=\frac{i}{n+1}\\ 	E[\sum_{i=1}^n x_{(i)}] &=\frac{n}{2}, \\ 	E[\sum_{i=1}^n (x_{(i)} ^2)] &= \sum_{i=1}^n\left(\frac{i}{n+1}\right)^2=\frac{n(2n+1)}{6(n+1)}. \end{alignat*} I furthermore know that \begin{align} \underbrace{E[x_{(i)}^2]}_{\frac{2n+1}{6(n+1)}}\neq\underbrace{(E[x_{(i)}])^2}_{\frac{1}{4}} \end{align} and hence was expecting that \begin{align} E[\left(\sum_{i=1}^n x_{(i)}\right)^2]\neq\left(E[\sum_{i=1}^n x_{(i)}]\right)^2. \end{align} However, my calculation is \begin{alignat*}{3} 	E[\left(\sum_{i=1}^n x_{(i)}\right)^2]% 	&= E[\sum_{i=1}^n (x_{(i)}^2)+2\sum_{i=1}^n x_{(i)} \sum_{j=1}^{i-1}x_{(j)}]  \\ 	&= \frac{n(2n+1)}{6(n+1)} + 2\sum_{i=1}^n \frac{i}{n+1} \frac{(i-1)i}{2(n+1)}\\ 	&= \frac{n(2n+1)}{6(n+1)} + \frac{1}{(n+1)^2}\sum_{i=1}^n (i^3-i^2)\\ 	&= \frac{n(2n+1)}{6(n+1)} + \frac{1}{(n+1)^2}\left(\left(\frac{n(n+1)}{2}\right)^2-\frac{n(n+1)(2n+1)}{6}\right)\\ 	&= (\ldots) = \left(\frac{n}{2}\right)^2=\left(E[\sum_{i=1}^n x_{(i)}]\right)^2 \end{alignat*} Are the two (i.e. expected value of squared sum, and square of expected sum) really equal or have I made a mistake in my calculations? If they are equal, is there an intuition why squares and expectations are interchangeable here but not in the case above (i.e. for the sum but not for the individual $x_{(i)}$)? (Apologies if the calculations are somewhat cumbersome, I have tried to simplify the original problem with more parameters to this form.)","Edit: A lot of my computations in the question below are utterly wrong, I just left them as they since the comments/answers applied to the original form. Edit: I have updated the question to hopefully better explain the draws I am referring to. In the actual problem, $x_{(i)}, i\in\{1,\ldots,n\}$ are the $n$ lowest out of $m$ i.i.d. draws from $U[0,1]$. I hope I am making a duly simplification below. Let $x_{(1)}\leq\ldots\leq x_{(n)}$ be $n$ i.i.d. draws of a random variable uniformly distributed in $[0,1]$. I know that (if I am not mistaken) \begin{alignat*}{2} E[x_{(i)}]&=\frac{i}{n+1}\\ 	E[\sum_{i=1}^n x_{(i)}] &=\frac{n}{2}, \\ 	E[\sum_{i=1}^n (x_{(i)} ^2)] &= \sum_{i=1}^n\left(\frac{i}{n+1}\right)^2=\frac{n(2n+1)}{6(n+1)}. \end{alignat*} I furthermore know that \begin{align} \underbrace{E[x_{(i)}^2]}_{\frac{2n+1}{6(n+1)}}\neq\underbrace{(E[x_{(i)}])^2}_{\frac{1}{4}} \end{align} and hence was expecting that \begin{align} E[\left(\sum_{i=1}^n x_{(i)}\right)^2]\neq\left(E[\sum_{i=1}^n x_{(i)}]\right)^2. \end{align} However, my calculation is \begin{alignat*}{3} 	E[\left(\sum_{i=1}^n x_{(i)}\right)^2]% 	&= E[\sum_{i=1}^n (x_{(i)}^2)+2\sum_{i=1}^n x_{(i)} \sum_{j=1}^{i-1}x_{(j)}]  \\ 	&= \frac{n(2n+1)}{6(n+1)} + 2\sum_{i=1}^n \frac{i}{n+1} \frac{(i-1)i}{2(n+1)}\\ 	&= \frac{n(2n+1)}{6(n+1)} + \frac{1}{(n+1)^2}\sum_{i=1}^n (i^3-i^2)\\ 	&= \frac{n(2n+1)}{6(n+1)} + \frac{1}{(n+1)^2}\left(\left(\frac{n(n+1)}{2}\right)^2-\frac{n(n+1)(2n+1)}{6}\right)\\ 	&= (\ldots) = \left(\frac{n}{2}\right)^2=\left(E[\sum_{i=1}^n x_{(i)}]\right)^2 \end{alignat*} Are the two (i.e. expected value of squared sum, and square of expected sum) really equal or have I made a mistake in my calculations? If they are equal, is there an intuition why squares and expectations are interchangeable here but not in the case above (i.e. for the sum but not for the individual $x_{(i)}$)? (Apologies if the calculations are somewhat cumbersome, I have tried to simplify the original problem with more parameters to this form.)",,"['probability', 'statistics', 'order-statistics']"
33,What is the probability that an element is in a subset of a set?,What is the probability that an element is in a subset of a set?,,There's a list of numbers from 1 to 500 (both inclusive). Let's call this set $M$. I pick a subset $A$ uniformly at random from set $M$. The size of subset $A$ is $n$. Element $x$ is chosen uniformly at random from set $M$. What is the probability that $x$ is in set $A$?,There's a list of numbers from 1 to 500 (both inclusive). Let's call this set $M$. I pick a subset $A$ uniformly at random from set $M$. The size of subset $A$ is $n$. Element $x$ is chosen uniformly at random from set $M$. What is the probability that $x$ is in set $A$?,,"['probability', 'statistics']"
34,"Differentiating $\int\cdots \int f(X_1,X_2,\ldots,X_n)\varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)~dx_1\cdots dx_n$",Differentiating,"\int\cdots \int f(X_1,X_2,\ldots,X_n)\varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)~dx_1\cdots dx_n","Differentiating:$$\int_{-\infty}^\infty \cdots \int_{-\infty}^\infty f(X_1,X_2,\ldots,X_n)\varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)\,dx_1 \cdots dx_n$$ with respect to $\theta$. The result is given in one line, (the next one). I do not understand how this is. (Statistics proof) Anyway the result given being: $$\int_{-\infty}^\infty \cdots \int_{-\infty}^\infty f(X_1,X_2,\ldots,X_n) \sum_{i=1}^n \left(\frac{\partial}{\partial \theta}\varphi(x_i,\theta)\frac{1}{\varphi(x_i,\theta)}\right) \varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)\,dx_1\cdots dx_n$$","Differentiating:$$\int_{-\infty}^\infty \cdots \int_{-\infty}^\infty f(X_1,X_2,\ldots,X_n)\varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)\,dx_1 \cdots dx_n$$ with respect to $\theta$. The result is given in one line, (the next one). I do not understand how this is. (Statistics proof) Anyway the result given being: $$\int_{-\infty}^\infty \cdots \int_{-\infty}^\infty f(X_1,X_2,\ldots,X_n) \sum_{i=1}^n \left(\frac{\partial}{\partial \theta}\varphi(x_i,\theta)\frac{1}{\varphi(x_i,\theta)}\right) \varphi_1(x_1,\theta)\cdots\varphi_n(x_n,\theta)\,dx_1\cdots dx_n$$",,"['probability', 'statistics', 'multivariable-calculus', 'derivatives', 'random-variables']"
35,Proof that: $I-X(X^TX)^{-1}X^T=((I-X(X^TX)^{-1}X^T)^2$,Proof that:,I-X(X^TX)^{-1}X^T=((I-X(X^TX)^{-1}X^T)^2,I have to verify if the statment: $$I-X(X^TX)^{-1}X^T=((I-X(X^TX)^{-1}X^T)^2$$ is true or not. (I do not get to demonstrate). Any help or hint will be very useful for me. Thanks a lot!,I have to verify if the statment: $$I-X(X^TX)^{-1}X^T=((I-X(X^TX)^{-1}X^T)^2$$ is true or not. (I do not get to demonstrate). Any help or hint will be very useful for me. Thanks a lot!,,"['linear-algebra', 'statistics']"
36,A question about Chebyshev's inequality and why $\operatorname{Var}(\overline X_n) = \sigma^2/n.$,A question about Chebyshev's inequality and why,\operatorname{Var}(\overline X_n) = \sigma^2/n.,"This is the question: For i.i.d. r.v.s $X_1, . . . ,X_n$ with mean $μ$ and variance $\sigma^2$, give a value of $n$ (as a   specific number) that will ensure that there is at least a $99\%$ chance that the   sample mean will be within $2$ standard deviations of the true mean $μ$. This is the solution: We have to find $n$ such that $$P(|\overline{X}_n-\mu|>2\mu) \leq 0.01$$ By Chebyshev's inequality (in the form $P(|Y-EY|>c) \leq \frac{\text{Var}(Y)}{c^2}$), we have $$P(|\overline{X}_n-\mu|>2\mu) \leq \frac{\text{Var}(\overline{X}_n)}{(2\sigma)^2} = \frac{\frac{\sigma^2}{n}}{4\sigma^2}=\frac{1}{4n}$$ So the desired inequality holds if $n \geq 25$. So what I'm confused about is why $\text{Var}(\overline{X}_n)=\frac{\sigma^2}{n}$. What does it mean to take the variance of the sample mean? I did some research and it seems like sample variance (is this even called sample variance?) should be divided $n-1$ and not $n$ as seen in the solution. Unfortunately the course I'm taking has not gone over any of this. I'm hoping someone could point me in the right direction or even providing the necessary terms to search to understand this more.","This is the question: For i.i.d. r.v.s $X_1, . . . ,X_n$ with mean $μ$ and variance $\sigma^2$, give a value of $n$ (as a   specific number) that will ensure that there is at least a $99\%$ chance that the   sample mean will be within $2$ standard deviations of the true mean $μ$. This is the solution: We have to find $n$ such that $$P(|\overline{X}_n-\mu|>2\mu) \leq 0.01$$ By Chebyshev's inequality (in the form $P(|Y-EY|>c) \leq \frac{\text{Var}(Y)}{c^2}$), we have $$P(|\overline{X}_n-\mu|>2\mu) \leq \frac{\text{Var}(\overline{X}_n)}{(2\sigma)^2} = \frac{\frac{\sigma^2}{n}}{4\sigma^2}=\frac{1}{4n}$$ So the desired inequality holds if $n \geq 25$. So what I'm confused about is why $\text{Var}(\overline{X}_n)=\frac{\sigma^2}{n}$. What does it mean to take the variance of the sample mean? I did some research and it seems like sample variance (is this even called sample variance?) should be divided $n-1$ and not $n$ as seen in the solution. Unfortunately the course I'm taking has not gone over any of this. I'm hoping someone could point me in the right direction or even providing the necessary terms to search to understand this more.",,"['probability', 'statistics']"
37,"When is it ok to use ""="" instead of "":=""?","When is it ok to use ""="" instead of "":=""?",,"I am having difficulty whilst writing my equations, deciding when I should be using the equals symbol ""="" , and when I should be using the defined as symbol "":="". In particular, I am talking about equations for probabilities, when those probabilities are really approximations to the true probabilities. I am an engineer rather than a mathematician, so these approximations are common! For example, if I was using Bayes rule in my equation, I would write $p(x|y) = \frac{p(y|x)p(x)}{p(y)}$, because the two are equivalent. On the contrary, suppose I was using a very naive and heuristic score, and then using that score as a probability in my future calculations. I might write, for example, $p(x) := 0.5 + 0.5 * (z/10)$ where $z$ are some observations I have made about $x$, and $0 < z < 10$. This is because $p(x)$ is clearly just a score being forced into a probability, and so it would not be accurate to use the ""="" symbol. However, what about the cases between these two examples? Should you only use the ""="" symbol when the probability is derived purely and directly by maths? Or are there cases when the approximation is only small, and therefore ""="" is appropriate? The reason I ask is that in engineering, almost all probabilities are approximations, but it would look odd to have every single equation using the "":="" symbol. For example, suppose I decided to use a naive Bayesian model, where $x = \{a, b, c, d\}$. Would it be ok to write $p(x) = p(a)p(b|a)p(c|a)p(d|a)$, or would I have to write $p(x) := p(a)p(b|a)p(c|a)p(d|a)$? Is there a general rule as to how close to a pure approximation a probability definition has to be if you are going to use ""="" rather than "":=""?","I am having difficulty whilst writing my equations, deciding when I should be using the equals symbol ""="" , and when I should be using the defined as symbol "":="". In particular, I am talking about equations for probabilities, when those probabilities are really approximations to the true probabilities. I am an engineer rather than a mathematician, so these approximations are common! For example, if I was using Bayes rule in my equation, I would write $p(x|y) = \frac{p(y|x)p(x)}{p(y)}$, because the two are equivalent. On the contrary, suppose I was using a very naive and heuristic score, and then using that score as a probability in my future calculations. I might write, for example, $p(x) := 0.5 + 0.5 * (z/10)$ where $z$ are some observations I have made about $x$, and $0 < z < 10$. This is because $p(x)$ is clearly just a score being forced into a probability, and so it would not be accurate to use the ""="" symbol. However, what about the cases between these two examples? Should you only use the ""="" symbol when the probability is derived purely and directly by maths? Or are there cases when the approximation is only small, and therefore ""="" is appropriate? The reason I ask is that in engineering, almost all probabilities are approximations, but it would look odd to have every single equation using the "":="" symbol. For example, suppose I decided to use a naive Bayesian model, where $x = \{a, b, c, d\}$. Would it be ok to write $p(x) = p(a)p(b|a)p(c|a)p(d|a)$, or would I have to write $p(x) := p(a)p(b|a)p(c|a)p(d|a)$? Is there a general rule as to how close to a pure approximation a probability definition has to be if you are going to use ""="" rather than "":=""?",,"['probability', 'statistics']"
38,"What is the probability that a psychic correctly ""predicts"" the outcome of at least 5 out of 10 coin flips?","What is the probability that a psychic correctly ""predicts"" the outcome of at least 5 out of 10 coin flips?",,"Assume the psychic is actually just randomly guessing on each flip. The attempt: let E be the event in question number of outcomes per flip = 2 chance of correctly guessing the correct outcome = $ \frac{1}{2}$ notice the key word ""at least"": indicates that we should be doing a summation You can get exactly 5 correct, exactly 6, ..., all the way to exactly 10 correct $$ P(E) = \sum_{i=5}^{10} (\frac{1}{2^i})= 63/1024$$ What is wrong with this approach? My intuition says that the probability should be $ \frac{1}{2} $.","Assume the psychic is actually just randomly guessing on each flip. The attempt: let E be the event in question number of outcomes per flip = 2 chance of correctly guessing the correct outcome = $ \frac{1}{2}$ notice the key word ""at least"": indicates that we should be doing a summation You can get exactly 5 correct, exactly 6, ..., all the way to exactly 10 correct $$ P(E) = \sum_{i=5}^{10} (\frac{1}{2^i})= 63/1024$$ What is wrong with this approach? My intuition says that the probability should be $ \frac{1}{2} $.",,"['probability', 'combinatorics', 'statistics']"
39,An explanation of how this solution is derived,An explanation of how this solution is derived,,"I am having difficulty understanding the solution to this problem.  Since the solution is in the form of Bayes theorem I expected something along the lines that looked similar to Bayes theorem. Suppose that in each individual of a large population there is a pair of genes that determine eye color. Each of these genes can be x or X and they follow these rules: xx – blue eyes Xx, xX (heterozygote) – brown eyes XX – brown eyes The proportion of blue-eyed individuals is $p^2$ and of heterozygotes it’s $2p(1-p)$, where $0<p<1$. Each parent transmits one if its own genes to the child. If a parent is a heterozygote, the probability that it transmits the genes of type X is $0.5$. Assuming random mating, show that among brown-eyed children of brown-eyed parents, the expected proportion of heterozygotes is $\frac{2p}{1+2p}$ the solution is set up as follows: $Pr$(child is heterozygote | child has brown eyes and parents have brown eyes) =","I am having difficulty understanding the solution to this problem.  Since the solution is in the form of Bayes theorem I expected something along the lines that looked similar to Bayes theorem. Suppose that in each individual of a large population there is a pair of genes that determine eye color. Each of these genes can be x or X and they follow these rules: xx – blue eyes Xx, xX (heterozygote) – brown eyes XX – brown eyes The proportion of blue-eyed individuals is $p^2$ and of heterozygotes it’s $2p(1-p)$, where $0<p<1$. Each parent transmits one if its own genes to the child. If a parent is a heterozygote, the probability that it transmits the genes of type X is $0.5$. Assuming random mating, show that among brown-eyed children of brown-eyed parents, the expected proportion of heterozygotes is $\frac{2p}{1+2p}$ the solution is set up as follows: $Pr$(child is heterozygote | child has brown eyes and parents have brown eyes) =",,"['probability', 'statistics', 'machine-learning', 'bayesian', 'bayes-theorem']"
40,Why is the probability multiplied by $\binom{n}{k}$,Why is the probability multiplied by,\binom{n}{k},"A while ago I asked a question about probability here Why is binomial probability used here? I get that you can find how many ways of choosing the $6$ correct out of $10$ questions. But why do we multiply by $\binom{n}{k}$? I thought it is simple casework that: $$P(\text{total probability}) = P(\text{Q 1->6 right and 7-10 wrong} + P(\text{Q 1->5 right, 6 wrong, 7 right, 8-10 wrong}) + ...$$ What is the idea?","A while ago I asked a question about probability here Why is binomial probability used here? I get that you can find how many ways of choosing the $6$ correct out of $10$ questions. But why do we multiply by $\binom{n}{k}$? I thought it is simple casework that: $$P(\text{total probability}) = P(\text{Q 1->6 right and 7-10 wrong} + P(\text{Q 1->5 right, 6 wrong, 7 right, 8-10 wrong}) + ...$$ What is the idea?",,"['probability', 'combinatorics', 'algebra-precalculus', 'statistics', 'elementary-set-theory']"
41,Integrating Joint Random Variable Distributions - Defining Integration Intervals,Integrating Joint Random Variable Distributions - Defining Integration Intervals,,"I'm currently studying for a stats quiz using the course text book, and I'm discovering that I'm a little rusty on setting up regions for double integrals. The current question I'm hung up on is as follows: If the joint probability density of $X$ and $Y$ is given by:  $$f(x,y) = \begin{cases} 2 & \text{for } x>0, y>0,x+y<1 \\ 0 & \text{elsewhere}\end{cases}$$ find: a. $P(X \leq \frac{1}{2}, Y \leq \frac{1}{2})$ b. $P(X+Y > \frac{2}{3})$ c. $P(X > 2Y)$ I got part a correct, with the region of integration being $A = \{(x,y) \mid 0 < x < \frac{1}{2}, 0 < y < \frac{1}{2}\}$, but b and c I'm finding a bit more difficult. I have yet to attempt c, but I've set the following regions up for b: $$A = \{(x,y) \mid 0 < x < \frac{2}{3}, 0 < y < 1-x\}$$ and $$A = \{(x,y) \mid \frac{2}{3} < x < 1, 0 < y < 1-x\}$$ Both regions yielded incorrect answers $\frac{8}{9}$ and $\frac{1}{9}$ respectively, with the correct answer being $\frac{5}{9}$. Generalized, how does one go about setting up the region of integration when given bounds as described above? Thank you.","I'm currently studying for a stats quiz using the course text book, and I'm discovering that I'm a little rusty on setting up regions for double integrals. The current question I'm hung up on is as follows: If the joint probability density of $X$ and $Y$ is given by:  $$f(x,y) = \begin{cases} 2 & \text{for } x>0, y>0,x+y<1 \\ 0 & \text{elsewhere}\end{cases}$$ find: a. $P(X \leq \frac{1}{2}, Y \leq \frac{1}{2})$ b. $P(X+Y > \frac{2}{3})$ c. $P(X > 2Y)$ I got part a correct, with the region of integration being $A = \{(x,y) \mid 0 < x < \frac{1}{2}, 0 < y < \frac{1}{2}\}$, but b and c I'm finding a bit more difficult. I have yet to attempt c, but I've set the following regions up for b: $$A = \{(x,y) \mid 0 < x < \frac{2}{3}, 0 < y < 1-x\}$$ and $$A = \{(x,y) \mid \frac{2}{3} < x < 1, 0 < y < 1-x\}$$ Both regions yielded incorrect answers $\frac{8}{9}$ and $\frac{1}{9}$ respectively, with the correct answer being $\frac{5}{9}$. Generalized, how does one go about setting up the region of integration when given bounds as described above? Thank you.",,"['probability', 'integration', 'statistics']"
42,Probability of no students being mechanical engineers,Probability of no students being mechanical engineers,,"In a class of 100 students, 30 are computer science majors, 49 are mechaincal engineering majors, 13 are civil engineers and the rest are general engineering majors. Assume students only have one major. Suppose five students from the class are chosen at random what is the probability none are mechanical engineering majors? My info I know: The mechanical engineers account for 49% of the students, making 51% not mechanical engineers? Do I take five out of the 51, so 0.05 X 0.51?","In a class of 100 students, 30 are computer science majors, 49 are mechaincal engineering majors, 13 are civil engineers and the rest are general engineering majors. Assume students only have one major. Suppose five students from the class are chosen at random what is the probability none are mechanical engineering majors? My info I know: The mechanical engineers account for 49% of the students, making 51% not mechanical engineers? Do I take five out of the 51, so 0.05 X 0.51?",,['statistics']
43,Probability of two random number generators producing same number,Probability of two random number generators producing same number,,"I have two random number generators, 1 giving me a number between 1 and 5000 (call it x) and the other giving me a number between 1000 and 1500 (call it y). Both including the min and max numbers. I'm trying to work out the chances of x=y I'm not sure if it's just (1/5000 * 1/501) - (1/5000 + 1/501) or if there's more to it, any help would be much appreciated.","I have two random number generators, 1 giving me a number between 1 and 5000 (call it x) and the other giving me a number between 1000 and 1500 (call it y). Both including the min and max numbers. I'm trying to work out the chances of x=y I'm not sure if it's just (1/5000 * 1/501) - (1/5000 + 1/501) or if there's more to it, any help would be much appreciated.",,"['probability', 'statistics']"
44,Need to know why $\sum_{k=0}^{\infty}kr^{k} = \frac{r}{(1-r)^{2}}$,Need to know why,\sum_{k=0}^{\infty}kr^{k} = \frac{r}{(1-r)^{2}},"Working on a Stat problem where I must find $E(x)$ of $f(x)=\left(\frac{1}{2}\right)^{x+1}$ for $x=0,1,2,\cdots$ I have, $$E(x)=\sum_{x=0}^{\infty}x\left(\frac{1}{2}\right)^{x+1}=\frac{1}{2}\sum_{x=0}^{\infty}x\left(\frac{1}{2}\right)^{x}$$ I'm pretty sure this is a geometric series, but it would defeat the purpose of doing this problem if I didn't know why the following sum converges: $$\sum_{k=0}^{\infty}kr^{k} = \frac{r}{(1-r)^{2}}$$ Can anyone explain why this is? I've tried using derivative but keep going in circles.","Working on a Stat problem where I must find $E(x)$ of $f(x)=\left(\frac{1}{2}\right)^{x+1}$ for $x=0,1,2,\cdots$ I have, $$E(x)=\sum_{x=0}^{\infty}x\left(\frac{1}{2}\right)^{x+1}=\frac{1}{2}\sum_{x=0}^{\infty}x\left(\frac{1}{2}\right)^{x}$$ I'm pretty sure this is a geometric series, but it would defeat the purpose of doing this problem if I didn't know why the following sum converges: $$\sum_{k=0}^{\infty}kr^{k} = \frac{r}{(1-r)^{2}}$$ Can anyone explain why this is? I've tried using derivative but keep going in circles.",,"['sequences-and-series', 'statistics', 'summation']"
45,When residual standard error is equal to standard deviation of dependent variable in linear regression?,When residual standard error is equal to standard deviation of dependent variable in linear regression?,,I wonder when residual standard error is equal to standard deviation of dependent variable in linear regression? Could someone provide some information on this topic and explanation?,I wonder when residual standard error is equal to standard deviation of dependent variable in linear regression? Could someone provide some information on this topic and explanation?,,"['statistics', 'regression']"
46,What type of Probability distribution is best for this problem?,What type of Probability distribution is best for this problem?,,"An auto insurance company is implementing a new bonus system. In each month the policyholder does not have an accident, he ore she will receive 5.00 cash back bonus from the insurer. Among the 1000 policyholders of the auto insurance company, 400 are low risk drivers and 600 are high risk. The probability of a high risk driver having a accident in a given month is 0.2 and for low risk is 0.1. What is the expeccted bonus payment from the insurer to the 1000 policyholders? I saw the solution and it gave no explanation as to why they used a poisson distribution. I cannot see why they did that a little insight would help. When should I consider using each type of distribution?","An auto insurance company is implementing a new bonus system. In each month the policyholder does not have an accident, he ore she will receive 5.00 cash back bonus from the insurer. Among the 1000 policyholders of the auto insurance company, 400 are low risk drivers and 600 are high risk. The probability of a high risk driver having a accident in a given month is 0.2 and for low risk is 0.1. What is the expeccted bonus payment from the insurer to the 1000 policyholders? I saw the solution and it gave no explanation as to why they used a poisson distribution. I cannot see why they did that a little insight would help. When should I consider using each type of distribution?",,"['probability', 'statistics']"
47,"Proving $Y = aX + b$ given correlation coefficient $|\rho(X, Y)| = 1$",Proving  given correlation coefficient,"Y = aX + b |\rho(X, Y)| = 1","With correlation coefficient defined as: $$\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X)}\sqrt{\text{Var}(Y)}}$$ can you help me prove $$|\rho(X, Y)| = 1 \implies Y = aX + b$$","With correlation coefficient defined as: $$\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X)}\sqrt{\text{Var}(Y)}}$$ can you help me prove $$|\rho(X, Y)| = 1 \implies Y = aX + b$$",,"['statistics', 'correlation']"
48,"Find the density function of $Y=e^Z$ where $Z \sim N(\mu, \sigma^2)$",Find the density function of  where,"Y=e^Z Z \sim N(\mu, \sigma^2)","Find the density function of $Y=e^Z$  ,where $Z \sim N(\mu, \sigma^2)$ This is called the lognormal density , Since $\log Y$ is normally distributed.","Find the density function of $Y=e^Z$  ,where $Z \sim N(\mu, \sigma^2)$ This is called the lognormal density , Since $\log Y$ is normally distributed.",,['statistics']
49,Finding an unbiased estimator for the negative binomial distribution,Finding an unbiased estimator for the negative binomial distribution,,"Consider a negative binomial random variable Y   as the number of failures that occur before the r  th success in a sequence of independent and identical success/failure trials. The pmf of $Y$   is $$nb(y;r,\theta)=\begin{cases} {y+r-1 \choose y}\theta^{r}(1-\theta)^{y} & y=0,1,2,\dots\\ 0 & \text{otherwise } \end{cases}$$  Suppose that $r\geq2$  . (a) Show that $\tilde{\theta}=\frac{r-1}{Y+r-1}$   is an unbiased estimator for $\theta$  ; i.e. show that $E(\tilde{\theta})=\theta$  . How woudl I proceed? How do I even calculate $E(\tilde{\theta})$? This might be a stupid question since the teacher hasn't covered this yet (i'm learning more quickly) but how would this thing work?","Consider a negative binomial random variable Y   as the number of failures that occur before the r  th success in a sequence of independent and identical success/failure trials. The pmf of $Y$   is $$nb(y;r,\theta)=\begin{cases} {y+r-1 \choose y}\theta^{r}(1-\theta)^{y} & y=0,1,2,\dots\\ 0 & \text{otherwise } \end{cases}$$  Suppose that $r\geq2$  . (a) Show that $\tilde{\theta}=\frac{r-1}{Y+r-1}$   is an unbiased estimator for $\theta$  ; i.e. show that $E(\tilde{\theta})=\theta$  . How woudl I proceed? How do I even calculate $E(\tilde{\theta})$? This might be a stupid question since the teacher hasn't covered this yet (i'm learning more quickly) but how would this thing work?",,"['probability', 'statistics', 'estimation']"
50,Expected value of the inner product of two random vectors,Expected value of the inner product of two random vectors,,"$X=[x_1, x_2,...x_n] Y = [y_1, y_2,...y_n]$ If $x_i, y_i$ are both random variables with $P(x=1) = .5$ $ P(x=2) = .5 $ $P(y=1)=.5$ $P(y=2)=.5$ How would I find the expected value of the inner product of both of these random vectors?$E[X.Y]$ I'm thrown off with this problem, as I don't know how exactly to work with random vectors or if any additional rules apply when finding the expected value. My gut feeling is $E[X.Y] = [E[x_1y_1], E[x_2y_2],.....,E[x_ny_n]]$ Is this the right approach?","$X=[x_1, x_2,...x_n] Y = [y_1, y_2,...y_n]$ If $x_i, y_i$ are both random variables with $P(x=1) = .5$ $ P(x=2) = .5 $ $P(y=1)=.5$ $P(y=2)=.5$ How would I find the expected value of the inner product of both of these random vectors?$E[X.Y]$ I'm thrown off with this problem, as I don't know how exactly to work with random vectors or if any additional rules apply when finding the expected value. My gut feeling is $E[X.Y] = [E[x_1y_1], E[x_2y_2],.....,E[x_ny_n]]$ Is this the right approach?",,"['probability', 'statistics', 'vector-spaces', 'random-variables']"
51,Deriving the mean of the Geometric Distribution,Deriving the mean of the Geometric Distribution,,I am missing something that might be trivial in deriving the mean of the geometric distribution function by using expected value identity $$ \sum_x x \theta (1-\theta)^{x-1}. $$,I am missing something that might be trivial in deriving the mean of the geometric distribution function by using expected value identity $$ \sum_x x \theta (1-\theta)^{x-1}. $$,,"['probability', 'statistics']"
52,"if X and Y are independent Normal random variables, what would be the probability that X is less than Y?","if X and Y are independent Normal random variables, what would be the probability that X is less than Y?",,"How can I find this probability $P(X<Y)$ ? knowing that X and Y are independent Normal random variables. $X$~$N(m_1 ,v_1)$ (with mean m1 and variance v1) $Y$~$N(m_2 ,v_2)$ I know that $$ \Pr \left[ X < Y \right] = \int F_X \left( y \right) f_Y \left( y \right)    \mathrm{d} y $$ but I cannot solve it for normal random variable.","How can I find this probability $P(X<Y)$ ? knowing that X and Y are independent Normal random variables. $X$~$N(m_1 ,v_1)$ (with mean m1 and variance v1) $Y$~$N(m_2 ,v_2)$ I know that $$ \Pr \left[ X < Y \right] = \int F_X \left( y \right) f_Y \left( y \right)    \mathrm{d} y $$ but I cannot solve it for normal random variable.",,"['probability', 'statistics', 'probability-distributions', 'random-variables']"
53,Does SSTR (sum of squares for treatments) = SSR (regression sum of squares)?,Does SSTR (sum of squares for treatments) = SSR (regression sum of squares)?,,"I'm on my first course into statistics and there seems to be something in common for Regression and ANOVA analysis: in ANOVA I'm told that SST (total sum of squares) = SSE(error sum of squares) + SSTR (sum of squares for treatments) while in regression, SST (total sum of squares) = SSE(error sum of squares) + SSR (regression sum of squares) Does that mean [after algebraic manipulation from the above 2 equations] SSR = SSTR ? I've looked up the formula for both SSR and SSTR and they are as followed: SSR= SSTR= Those two formulas look different. Does that mean I should not mix regression with ANOVA?","I'm on my first course into statistics and there seems to be something in common for Regression and ANOVA analysis: in ANOVA I'm told that SST (total sum of squares) = SSE(error sum of squares) + SSTR (sum of squares for treatments) while in regression, SST (total sum of squares) = SSE(error sum of squares) + SSR (regression sum of squares) Does that mean [after algebraic manipulation from the above 2 equations] SSR = SSTR ? I've looked up the formula for both SSR and SSTR and they are as followed: SSR= SSTR= Those two formulas look different. Does that mean I should not mix regression with ANOVA?",,['statistics']
54,"Proving $\text{Cov}((X,Y))^2 \leq \text{Var}(X) \text{Var}(Y)$ with Cauchy-Schwarz",Proving  with Cauchy-Schwarz,"\text{Cov}((X,Y))^2 \leq \text{Var}(X) \text{Var}(Y)","I've been trying to use the Cauchy-Schwarz inequality to prove that \begin{equation*} \text{Cov}(X,Y)^2 \leqslant \text{Var}(x) \cdot \text{Var}(Y). \end{equation*} The Cauchy-Schwarz inequality can be expressed as follows: If $u$ and $v$ are vectors in an inner product space, then $\langle u,v \rangle^2 \leqslant \|u\|^2 \|v\|^2$ . How do you define the vectors and the inner product so to prove the result in the first sentence. I've seen something like \begin{equation*} \text{Cov}(X,Y)^2 \leqslant \langle x - E(X), y - E(Y) \rangle \leqslant \|x - E(X)\|^2 \|y - E(Y)\|^2 = \text{Var}(X) \cdot \text{Var}(Y), \end{equation*} but how is $\langle x - E(X), y - E(Y) \rangle$ expressed as a sum? Also how can you let $x - E(X)$ and $y - E(Y)$ be vectors? Any insight would be great.","I've been trying to use the Cauchy-Schwarz inequality to prove that The Cauchy-Schwarz inequality can be expressed as follows: If and are vectors in an inner product space, then . How do you define the vectors and the inner product so to prove the result in the first sentence. I've seen something like but how is expressed as a sum? Also how can you let and be vectors? Any insight would be great.","\begin{equation*}
\text{Cov}(X,Y)^2 \leqslant \text{Var}(x) \cdot \text{Var}(Y).
\end{equation*} u v \langle u,v \rangle^2 \leqslant \|u\|^2 \|v\|^2 \begin{equation*}
\text{Cov}(X,Y)^2
\leqslant \langle x - E(X), y - E(Y) \rangle
\leqslant \|x - E(X)\|^2 \|y - E(Y)\|^2
= \text{Var}(X) \cdot \text{Var}(Y),
\end{equation*} \langle x - E(X), y - E(Y) \rangle x - E(X) y - E(Y)","['linear-algebra', 'statistics']"
55,Conditional probability distribution with Gaussian noise,Conditional probability distribution with Gaussian noise,,"If I have a relationship as follows: $$Y = a X + G(0,\sigma^2),\text{ so }y = a X + \text{some Gaussian noise}.$$ The conditional probability distribution of $y$ given $x$, i.e. $P(y|x)$, is equal to a Gaussian with mean $= a X$ and variance $= \sigma^2$. I intuitively understand this as the expected value for $y$ should be $a X$ and this will vary due to the noise with the same variance of the noise. Is there a formal proof for this? Thanks, Aly","If I have a relationship as follows: $$Y = a X + G(0,\sigma^2),\text{ so }y = a X + \text{some Gaussian noise}.$$ The conditional probability distribution of $y$ given $x$, i.e. $P(y|x)$, is equal to a Gaussian with mean $= a X$ and variance $= \sigma^2$. I intuitively understand this as the expected value for $y$ should be $a X$ and this will vary due to the noise with the same variance of the noise. Is there a formal proof for this? Thanks, Aly",,"['statistics', 'normal-distribution', 'machine-learning']"
56,Proving the PDF of the $r$th order statistic,Proving the PDF of the th order statistic,r,"If $X_1,...,X_n$ are iid random variables with $r$th order statistic $X_{(r)}$ I'm trying to prove it's pdf is $$f_{(r)}(x)=\frac{n!}{(r-1)!(n-r)!}F(x)^{r-1}[1-F(x)]^{n-r}f(x)$$ Is is true for $r=1$. I then assume true for $r$. The only step in this proof is I don't understand why this assumption implies that the cdf for $X_{(r)}$ is: $$F_{(r)}(x)=\sum_{j=r}^n {n\choose j} F(x)^{j}[1-F(x)]^{n-j}$$ Is someone could explain this I would be very grateful","If $X_1,...,X_n$ are iid random variables with $r$th order statistic $X_{(r)}$ I'm trying to prove it's pdf is $$f_{(r)}(x)=\frac{n!}{(r-1)!(n-r)!}F(x)^{r-1}[1-F(x)]^{n-r}f(x)$$ Is is true for $r=1$. I then assume true for $r$. The only step in this proof is I don't understand why this assumption implies that the cdf for $X_{(r)}$ is: $$F_{(r)}(x)=\sum_{j=r}^n {n\choose j} F(x)^{j}[1-F(x)]^{n-j}$$ Is someone could explain this I would be very grateful",,['statistics']
57,doubt on iid distribution vs uniform distribution,doubt on iid distribution vs uniform distribution,,"I am a bit confused when I read ""iid distribution"". It looks to me like what is called ""uniform distribution"" i.e. a distribution of probability that is constant in a range. Am I correct in thinking this? What  distributions could be considered ""iid"" other than the simple ""uniform"" one?  Reading on Wikipedia it is mentioned Levy Processes, not even the uniform. In which way should I think of what is supposed to be an IID distribution? Kind Regards AFG","I am a bit confused when I read ""iid distribution"". It looks to me like what is called ""uniform distribution"" i.e. a distribution of probability that is constant in a range. Am I correct in thinking this? What  distributions could be considered ""iid"" other than the simple ""uniform"" one?  Reading on Wikipedia it is mentioned Levy Processes, not even the uniform. In which way should I think of what is supposed to be an IID distribution? Kind Regards AFG",,"['statistics', 'terminology', 'probability-distributions', 'random']"
58,Probability increases as sample size increases?,Probability increases as sample size increases?,,"I was talking with a friend and we were discussing a math problem disguised as a social situation: If the chance that someone to accept your request to go out with them was 1% and you asked 1 person only, then the probability they would say yes is .01 If you were to ask 100 people, then your chances are still .01 according to my friend. Now my question is, why does it seem intuitive that the chances would increase when asking 100 people rather than 1?  Is it the expected value that's causing this intuition? Can this situation be modeled using a balls & bins problem?","I was talking with a friend and we were discussing a math problem disguised as a social situation: If the chance that someone to accept your request to go out with them was 1% and you asked 1 person only, then the probability they would say yes is .01 If you were to ask 100 people, then your chances are still .01 according to my friend. Now my question is, why does it seem intuitive that the chances would increase when asking 100 people rather than 1?  Is it the expected value that's causing this intuition? Can this situation be modeled using a balls & bins problem?",,"['probability', 'statistics']"
59,statistics - moment-generating function,statistics - moment-generating function,,"Let $Y_1,\dots,Y_n$ be independent and identically distributed random variables such that for $0 < p < 1$, $P(Y_i = 1) = p$ and $P(Y_i = 0) = q = 1-p$. A. Find the moment-generating functions for the random variable $Y_1$. B. Find the moment-generating functions for $W = Y_1 + \dots + Y_n$. C. What is the distribution of $W$? I have started to try A. My book stays that $m(t) = E(e^{tY})$. But i'm sure sure what that is. I think that expected value of $Y_1$ is $p$. But I'm not sure where to go from here. I'm completely clueless, statistics is not my area of expertise(I'm a computer science guy).","Let $Y_1,\dots,Y_n$ be independent and identically distributed random variables such that for $0 < p < 1$, $P(Y_i = 1) = p$ and $P(Y_i = 0) = q = 1-p$. A. Find the moment-generating functions for the random variable $Y_1$. B. Find the moment-generating functions for $W = Y_1 + \dots + Y_n$. C. What is the distribution of $W$? I have started to try A. My book stays that $m(t) = E(e^{tY})$. But i'm sure sure what that is. I think that expected value of $Y_1$ is $p$. But I'm not sure where to go from here. I'm completely clueless, statistics is not my area of expertise(I'm a computer science guy).",,"['probability', 'statistics']"
60,Basic probability... probability that two users share a key out of a keypool of $20$?,Basic probability... probability that two users share a key out of a keypool of ?,20,"Let's say I am distributing a bunch of encryption keys, where if two users have the same key, they can communicate.  I have $20$ different keys, and I am giving each user $2.$ Since encryption keys don't disappear when I hand them out, it can be considered 'with replacement', but I'm not giving the same user the same key twice. I want to know what the probability that two users can communicate under these circumstances.  Doing a bit of the math from what I know, each user has $20 \cdot 19 = 380$ permutations of keys.  The order that they get the keys in doesn't matter, though, so it's actually $190$ different combinations of keys.  So, two users have $190$ possible combinations of four keys, and what is the probability that one of their two keys is in common. That reasoning is about as far as I get.  How does one move forward from there?  Thanks!","Let's say I am distributing a bunch of encryption keys, where if two users have the same key, they can communicate.  I have different keys, and I am giving each user Since encryption keys don't disappear when I hand them out, it can be considered 'with replacement', but I'm not giving the same user the same key twice. I want to know what the probability that two users can communicate under these circumstances.  Doing a bit of the math from what I know, each user has permutations of keys.  The order that they get the keys in doesn't matter, though, so it's actually different combinations of keys.  So, two users have possible combinations of four keys, and what is the probability that one of their two keys is in common. That reasoning is about as far as I get.  How does one move forward from there?  Thanks!",20 2. 20 \cdot 19 = 380 190 190,['probability']
61,How do I test whether two events are independent?,How do I test whether two events are independent?,,"I'm trying to understand how to mathematically determine whether two events are independent. This is for introduction to statistics, so the solution and explanation to this is likely very simple, yet there's something I'm not understanding. Here's the question from my textbook: A statistical experiment has 11 equally likely outcomes that are denoted by a, b, c, d, e, f, g, h, i, j, k. Event A = {b, d, e, j} Event B = {a, c, f, j} If two events, A and B, are independent, then $P(A) = P(A|B)$ . Therefore if I want to determine whether the two events are independent, I need to solve for $P(A)$ and $P(A|B)$ to check whether they are equal. However $P(A|B) = \frac{P(A∩B)}{P(B)}$ , and this is where I get stuck, because I can't know which multiplication rule to use to figure out $P(A∩B)$ since I don't yet know whether the events are independent or not? If the events are independent, then $P(A∩B) = P(A) * P(B)$ . Otherwise if they are dependent, then $P(A∩B) = P(A) * P(B|A)$ . I know that I can solve the question from my textbook by looking at the outcomes that intersect between the two events, but is it possible to figure out whether the two events are independent solely by using the formulae above?","I'm trying to understand how to mathematically determine whether two events are independent. This is for introduction to statistics, so the solution and explanation to this is likely very simple, yet there's something I'm not understanding. Here's the question from my textbook: A statistical experiment has 11 equally likely outcomes that are denoted by a, b, c, d, e, f, g, h, i, j, k. Event A = {b, d, e, j} Event B = {a, c, f, j} If two events, A and B, are independent, then . Therefore if I want to determine whether the two events are independent, I need to solve for and to check whether they are equal. However , and this is where I get stuck, because I can't know which multiplication rule to use to figure out since I don't yet know whether the events are independent or not? If the events are independent, then . Otherwise if they are dependent, then . I know that I can solve the question from my textbook by looking at the outcomes that intersect between the two events, but is it possible to figure out whether the two events are independent solely by using the formulae above?",P(A) = P(A|B) P(A) P(A|B) P(A|B) = \frac{P(A∩B)}{P(B)} P(A∩B) P(A∩B) = P(A) * P(B) P(A∩B) = P(A) * P(B|A),"['probability', 'statistics', 'conditional-probability']"
62,Bounding $\max e^{x_i}$ by $\sum e^{x_i}$ vs $e^{\sum (x_i)_+}$ when $x_i$ is gaussian,Bounding  by  vs  when  is gaussian,\max e^{x_i} \sum e^{x_i} e^{\sum (x_i)_+} x_i,"I am trying to derive an upper bound on the expectation of the maximum of $n$ independent zero mean gaussian random variables: $$\mathbb E \left [ \max_i^n w_i\right ]$$ My thought is to use the moment generating function to form this bound. Proceding: $$= \mathbb E \left [ \frac{1}{\lambda} \log \exp \lambda \max w_i \right ]$$ where $\lambda \in \mathbb R$ . Now, applying Jensen's inequality: $$\leq \frac{1}{\lambda} \log \mathbb E \left [ \exp \lambda \max w_i \right ]$$ Since the max is difficult to handle directly, I consider a union bound, but I have two ways I can apply this union bound and it's not clear to me which one is the better choice. The first option (and what I originally tried): $$\stackrel{(A)}{\leq} \frac{1}{\lambda} \log \mathbb E \left [ \exp \lambda \sum (w_i)_+ \right ]$$ where $(\,\cdot\,)_+ := \max\{0, \cdot\,\}$ . Now I can apply independence and evaluate the expression by computing the moment generating function for $(w_i)_+$ : $$= \frac{n}{\lambda} \log \left ( \frac{1}{2} + e^{\sigma^2\lambda^2/2}\Phi(\sigma \lambda)\right )$$ where $\Phi$ is the normal CDF. The next step would be to select a value for $\lambda$ which makes this expression small. This is challenging for me, so if anyone has any tips that would be very helpful. I don't know how to proceed, but the leading $n$ term suggests that this bound is not good. The core of this is inequality $(A)$ , which I thought should be good when $w_i$ are typically small. But on second look $\sum (w_i)_+ \approx \sum |w_i| / 2 = O_p(\sqrt n)$ by the CLT which is certainly not small when $n$ is large. The second option is to apply the union bound outside the exponential: $$\stackrel{(B)}{\leq}\frac{1}{n} \log n \mathbb E [\exp\{\lambda w_i\}]$$ from where we can compute the moment generating function of $w_i$ and optimize $\lambda$ : $$=\sqrt{2\sigma^2 \log n}$$ This is the typical bound that is given. Interestingly, independence is not used and the same bound applies to sub-gaussian random variables in general, so I would expect this bound to be worse than the one obtainable from my first attempt. My questions How can I bound $\frac{n}{\lambda} \log \left ( \frac{1}{2} + e^{\sigma^2\lambda^2/2}\Phi(\sigma \lambda)\right )$ ? Is there some way to use the knowledge that the $w_i$ are independent and gaussian to obtain a better bound than $\sqrt{2\sigma^2 \log n}$ ?","I am trying to derive an upper bound on the expectation of the maximum of independent zero mean gaussian random variables: My thought is to use the moment generating function to form this bound. Proceding: where . Now, applying Jensen's inequality: Since the max is difficult to handle directly, I consider a union bound, but I have two ways I can apply this union bound and it's not clear to me which one is the better choice. The first option (and what I originally tried): where . Now I can apply independence and evaluate the expression by computing the moment generating function for : where is the normal CDF. The next step would be to select a value for which makes this expression small. This is challenging for me, so if anyone has any tips that would be very helpful. I don't know how to proceed, but the leading term suggests that this bound is not good. The core of this is inequality , which I thought should be good when are typically small. But on second look by the CLT which is certainly not small when is large. The second option is to apply the union bound outside the exponential: from where we can compute the moment generating function of and optimize : This is the typical bound that is given. Interestingly, independence is not used and the same bound applies to sub-gaussian random variables in general, so I would expect this bound to be worse than the one obtainable from my first attempt. My questions How can I bound ? Is there some way to use the knowledge that the are independent and gaussian to obtain a better bound than ?","n \mathbb E \left [ \max_i^n w_i\right ] = \mathbb E \left [ \frac{1}{\lambda} \log \exp \lambda \max w_i \right ] \lambda \in \mathbb R \leq \frac{1}{\lambda} \log \mathbb E \left [ \exp \lambda \max w_i \right ] \stackrel{(A)}{\leq} \frac{1}{\lambda} \log \mathbb E \left [ \exp \lambda \sum (w_i)_+ \right ] (\,\cdot\,)_+ := \max\{0, \cdot\,\} (w_i)_+ = \frac{n}{\lambda} \log \left ( \frac{1}{2} + e^{\sigma^2\lambda^2/2}\Phi(\sigma \lambda)\right ) \Phi \lambda n (A) w_i \sum (w_i)_+ \approx \sum |w_i| / 2 = O_p(\sqrt n) n \stackrel{(B)}{\leq}\frac{1}{n} \log n \mathbb E [\exp\{\lambda w_i\}] w_i \lambda =\sqrt{2\sigma^2 \log n} \frac{n}{\lambda} \log \left ( \frac{1}{2} + e^{\sigma^2\lambda^2/2}\Phi(\sigma \lambda)\right ) w_i \sqrt{2\sigma^2 \log n}","['probability', 'statistics', 'inequality', 'moment-generating-functions']"
63,$\chi^2$ Distribution for Rectified Gaussians,Distribution for Rectified Gaussians,\chi^2,"We know that a Chi-squared distribution is the distribution of the sum of squared independent Gaussian random variables $Z_i \sim N(0, 1)$ : $$ Y = \sum_{i=0}^k Z_i^2 $$ . If we have another random variable $Z^R_I$ which is a rectified Gaussian, $$ Z_i^R = max(0, Z_i) $$ , Would it be logical to say that the distribution of the sum of squared independent rectified Gaussian random variables $Z_i^R$ is equivalent to the sum of to half a chi-squared distribution? $$ Y^R = \sum_{i=0}^{k} (Z^R_{i})^2 = \sum_{i=0}^{k/2} Z_i^2 $$ $$ Y^R \sim \chi^2_{k/2} $$ Furthermore , if $Var[Y] = 2k$ , would $Var[Y^R] = k$ and $E[Y] = k$ , would $E[Y^R] = k/2$ ?","We know that a Chi-squared distribution is the distribution of the sum of squared independent Gaussian random variables : . If we have another random variable which is a rectified Gaussian, , Would it be logical to say that the distribution of the sum of squared independent rectified Gaussian random variables is equivalent to the sum of to half a chi-squared distribution? Furthermore , if , would and , would ?","Z_i \sim N(0, 1)  Y = \sum_{i=0}^k Z_i^2  Z^R_I  Z_i^R = max(0, Z_i)  Z_i^R  Y^R = \sum_{i=0}^{k} (Z^R_{i})^2 = \sum_{i=0}^{k/2} Z_i^2   Y^R \sim \chi^2_{k/2}  Var[Y] = 2k Var[Y^R] = k E[Y] = k E[Y^R] = k/2","['probability', 'statistics', 'probability-distributions', 'chi-squared']"
64,Variance of cards without replacement,Variance of cards without replacement,,"So let's say that we label a deck of cards as 1-13. There is a 1-13 of hearts, diamonds, spades, and clubs. What is the variance of the sum of picking 3 cards (without replacement)? If this was with replacement it's obviously just 3 times the variance of a single draw since variance is additive like that. I already know that the variance of a singe draw is 14 because variance is just $$ E[X^2]-E[X]^2 $$ For all purposes, can I just neglect the fact that they are not replaced? It makes sense that if one card was removed at random that the expected value of the next draw is the same (assuming the one removed was random and not some Baye's theorem situation where you were told which one was removed) so therefore the variance would also be treated the same way? There was another post on this already: Variance of sum of cards with and without replacement But I don't quite understand part of one of the solutions given: ""In the case of ""with replacement"" 𝖤(𝑋𝑌) will equal $𝖤(𝑋)^2$ because 𝑋,𝑌 will be independent and identically distributed."" How are these independent if one is picked after the other? Also wouldn't E[XY] be equal to $E[X^2]$ and not $E[X]^2$ ?","So let's say that we label a deck of cards as 1-13. There is a 1-13 of hearts, diamonds, spades, and clubs. What is the variance of the sum of picking 3 cards (without replacement)? If this was with replacement it's obviously just 3 times the variance of a single draw since variance is additive like that. I already know that the variance of a singe draw is 14 because variance is just For all purposes, can I just neglect the fact that they are not replaced? It makes sense that if one card was removed at random that the expected value of the next draw is the same (assuming the one removed was random and not some Baye's theorem situation where you were told which one was removed) so therefore the variance would also be treated the same way? There was another post on this already: Variance of sum of cards with and without replacement But I don't quite understand part of one of the solutions given: ""In the case of ""with replacement"" 𝖤(𝑋𝑌) will equal because 𝑋,𝑌 will be independent and identically distributed."" How are these independent if one is picked after the other? Also wouldn't E[XY] be equal to and not ?", E[X^2]-E[X]^2  𝖤(𝑋)^2 E[X^2] E[X]^2,"['statistics', 'probability-distributions', 'variance', 'card-games']"
65,Calculate ranking (match value) in Swiss tennis,Calculate ranking (match value) in Swiss tennis,,"The match value is a part of the ranking in Swiss tennis , it is calculated with the formula: $$ W=\frac{1}{2} \left( \ln\left( \sum_{i=1}^{s} e^{w_i}+e^{w_0} \right)-\ln\left( \sum_{j=1}^{N} e^{-w_j}+e^{-w_0} \right) \right) $$ Original from the link above: $W$ = your match value $w_0$ = your previous match value $w_i$ = the match value of the player you defeated $w_j$ = the match value of the player you lost to $s$ = sum of the matches you won $N$ = sum of the matches you lost I would like to calculate how many times ( $s$ ) one has to defeat a player with a match value of $W_j=3.400$ to get the match value $W=3.2$ if you start with $w_0=2.354$ for the setting when you do not lose matches ( $N=0$ ). How could I write a function in $\mathbb{R}$ to calculate this? Update1: Because of the comments (the given formulas might not be unequivocal), I contacted Swiss Tennis for clarification. They sent me updated formulas (sorry for the quality, these are the originals): Where WA = W0 . Unfortunately, they did not provide an example of the formula in use.","The match value is a part of the ranking in Swiss tennis , it is calculated with the formula: Original from the link above: = your match value = your previous match value = the match value of the player you defeated = the match value of the player you lost to = sum of the matches you won = sum of the matches you lost I would like to calculate how many times ( ) one has to defeat a player with a match value of to get the match value if you start with for the setting when you do not lose matches ( ). How could I write a function in to calculate this? Update1: Because of the comments (the given formulas might not be unequivocal), I contacted Swiss Tennis for clarification. They sent me updated formulas (sorry for the quality, these are the originals): Where WA = W0 . Unfortunately, they did not provide an example of the formula in use.","
W=\frac{1}{2} \left( \ln\left( \sum_{i=1}^{s} e^{w_i}+e^{w_0} \right)-\ln\left( \sum_{j=1}^{N} e^{-w_j}+e^{-w_0} \right) \right)
 W w_0 w_i w_j s N s W_j=3.400 W=3.2 w_0=2.354 N=0 \mathbb{R}","['algebra-precalculus', 'statistics']"
66,Expected value and variance of $e^{\frac{2n}{\sum_{i=1}^n X_i^2}}$ (maximum likelihood estimator),Expected value and variance of  (maximum likelihood estimator),e^{\frac{2n}{\sum_{i=1}^n X_i^2}},"Let $\theta>1$ be an unknown parameter and let $X_1, X_2, ..., X_n$ be a random sample (which means i.i.d. in this case) from the density $f_\theta$ where $$f_{\theta}(x)=x\theta^{-\frac{x^2}{2}}\log(\theta)\mathbb{1}_{(0, \infty)}(x).$$ We are given that $\mathbb{E}_{\theta}[X_1^2]=\frac{2}{\log(\theta)}$ and $\mathbb{E}_{\theta}[X_1^4]=\frac{8}{(\log \theta)^2}$ . First, I was asked to compute the maximum likelihood estimator of $\theta$ , call it $\hat{\theta}_n$ . This isn't hard, I got $$\hat{\theta}_n=e^{\frac{2n}{\sum_{i=1}^n X_i^2}}.$$ What I don't know how to do is how to prove if this estimator is efficient, i.e. if the Rao-Cramer bound is attained. To do so I need to find the expected value of my estimator and its variance. But how would I do this? I have no idea what is the distribution of $\sum_{i=1}^n X_i^2$ to even be able to get started on this using the so called law of unconscious statistician. So, how is this supposed to be done?","Let be an unknown parameter and let be a random sample (which means i.i.d. in this case) from the density where We are given that and . First, I was asked to compute the maximum likelihood estimator of , call it . This isn't hard, I got What I don't know how to do is how to prove if this estimator is efficient, i.e. if the Rao-Cramer bound is attained. To do so I need to find the expected value of my estimator and its variance. But how would I do this? I have no idea what is the distribution of to even be able to get started on this using the so called law of unconscious statistician. So, how is this supposed to be done?","\theta>1 X_1, X_2, ..., X_n f_\theta f_{\theta}(x)=x\theta^{-\frac{x^2}{2}}\log(\theta)\mathbb{1}_{(0, \infty)}(x). \mathbb{E}_{\theta}[X_1^2]=\frac{2}{\log(\theta)} \mathbb{E}_{\theta}[X_1^4]=\frac{8}{(\log \theta)^2} \theta \hat{\theta}_n \hat{\theta}_n=e^{\frac{2n}{\sum_{i=1}^n X_i^2}}. \sum_{i=1}^n X_i^2","['probability', 'statistics', 'expected-value', 'variance', 'maximum-likelihood']"
67,"Median of symmetric distribution, where median is defined using inverse of CDF","Median of symmetric distribution, where median is defined using inverse of CDF",,"Let $X$ be a symmetric random variable, that is $X$ and $-X$ have the same distribution function $F$ . Suppose that $F$ is continuous and strictly increasing in a neighborhood of $0$ . Then prove that the median $m$ of $F$ is equal to $0$ , where we define $m:=\inf\{x\in \mathbb{R}|F(x)\ge \frac{1}{2}\}$ . This definition of the median kind of annoys me. I could easily show that $\mathbb{P}(X\le 0)\ge \frac{1}{2}$ and $\mathbb{P}(X\ge 0)\ge \frac{1}{2}$ and by the usual definition of the median I would be done, but I don't know how to deal with that $\inf$ . I could only observe that my first equality implies that $m<0$ . I think that the point of the qustion is to use that $F$ is invertible on that neighborhood, but I can't make any progress.","Let be a symmetric random variable, that is and have the same distribution function . Suppose that is continuous and strictly increasing in a neighborhood of . Then prove that the median of is equal to , where we define . This definition of the median kind of annoys me. I could easily show that and and by the usual definition of the median I would be done, but I don't know how to deal with that . I could only observe that my first equality implies that . I think that the point of the qustion is to use that is invertible on that neighborhood, but I can't make any progress.",X X -X F F 0 m F 0 m:=\inf\{x\in \mathbb{R}|F(x)\ge \frac{1}{2}\} \mathbb{P}(X\le 0)\ge \frac{1}{2} \mathbb{P}(X\ge 0)\ge \frac{1}{2} \inf m<0 F,"['probability', 'statistics', 'supremum-and-infimum']"
68,Find the probability that a person is healthy given Covid 19?,Find the probability that a person is healthy given Covid 19?,,"A test is (covid-19) $(1)95 \% \text{ reliable on infected patients.}\\(2)99 \% \text{ reliable on healthy people.}\\(3) 4\% \text{ of population has virus.}\\ \text{define event: V: patient has virus}\\\qquad  \qquad S: \text{Test indicates a positive result.} \\ \Rightarrow{\text{We know: }}P(S|V) =.95, P(S^c|V^c) =.99,P(V)=.04\\\text{This test is given to a person with positive result. What is the probability }\\\text{ that this person is infected?}\\P(V|S)=\frac{P(V\cap{S})}{P(s)}=\frac{P(V)P(S|V)}{P(V)P(S|V)+P(V^c)P(S|V^c)}\\=\frac{P(V)P(S|V)}{P(V)P(S|V)+(1-P(V)(1-P(S^c|V^c)}=\frac{.04\star.95}{.04\star.95+(1-.04)(1-.99)}=.8636$ Find the probability that a person is healthy given the test says this person has a negative result. How do I solve this part any tips?",A test is (covid-19) Find the probability that a person is healthy given the test says this person has a negative result. How do I solve this part any tips?,"(1)95 \% \text{ reliable on infected patients.}\\(2)99 \% \text{ reliable on healthy people.}\\(3) 4\% \text{ of population has virus.}\\ \text{define event: V: patient has virus}\\\qquad  \qquad S: \text{Test indicates a positive result.} \\ \Rightarrow{\text{We know: }}P(S|V) =.95, P(S^c|V^c) =.99,P(V)=.04\\\text{This test is given to a person with positive result. What is the probability }\\\text{ that this person is infected?}\\P(V|S)=\frac{P(V\cap{S})}{P(s)}=\frac{P(V)P(S|V)}{P(V)P(S|V)+P(V^c)P(S|V^c)}\\=\frac{P(V)P(S|V)}{P(V)P(S|V)+(1-P(V)(1-P(S^c|V^c)}=\frac{.04\star.95}{.04\star.95+(1-.04)(1-.99)}=.8636","['probability', 'statistics', 'conditional-probability', 'bayes-theorem']"
69,Algebraic manipulation question coming from Method of Moments application,Algebraic manipulation question coming from Method of Moments application,,So today in my statistical inference class the professor wrote on the board: Using the Method of Moments: $$\sigma^2 = E[Y_1^2|\theta] - E[Y_1|\theta]^2$$ $$= \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \left( \frac{1}{n}\sum_{j = 1}^{n}{Y_j}\right)^2$$ $$= \frac{1}{n}\sum_{j = 1}^{n}{\left( Y_j - \bar{Y}\right)^2 }$$ where $\bar{Y} = \frac{1}{n}\sum_{j = 1}^{n}Y_j$ (average values of Y's) I am confused at how he arrived at the last equation from the one above that and I've been trying to figure it out. Here's what I have so far: $$= \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \left( \frac{1}{n}\sum_{j = 1}^{n}{Y_j}\right)^2$$ $$ = \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \frac{1}{n^2}\left(n\bar Y\right)^2$$ $$ = \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \bar Y^2$$ Which is fundamentally different that the equation that my professor had on the board. My equation takes the difference of squares while his takes the square of a difference and then sums those up... Where did I go so wrong? Is there just some statistical insight that I don't know and haven't used?,So today in my statistical inference class the professor wrote on the board: Using the Method of Moments: where (average values of Y's) I am confused at how he arrived at the last equation from the one above that and I've been trying to figure it out. Here's what I have so far: Which is fundamentally different that the equation that my professor had on the board. My equation takes the difference of squares while his takes the square of a difference and then sums those up... Where did I go so wrong? Is there just some statistical insight that I don't know and haven't used?,\sigma^2 = E[Y_1^2|\theta] - E[Y_1|\theta]^2 = \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \left( \frac{1}{n}\sum_{j = 1}^{n}{Y_j}\right)^2 = \frac{1}{n}\sum_{j = 1}^{n}{\left( Y_j - \bar{Y}\right)^2 } \bar{Y} = \frac{1}{n}\sum_{j = 1}^{n}Y_j = \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \left( \frac{1}{n}\sum_{j = 1}^{n}{Y_j}\right)^2  = \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \frac{1}{n^2}\left(n\bar Y\right)^2  = \frac{1}{n}\sum_{j = 1}^{n}{Y_j^2} - \bar Y^2,"['statistics', 'discrete-mathematics', 'statistical-inference']"
70,the expected value is a non-negative random variable is always greater than the expected value of its subset?,the expected value is a non-negative random variable is always greater than the expected value of its subset?,,Let's say $X$ is a non-negative random variable. And say $c$ is a positive constant. Why is $$E(X)\geq E\left(X_{\chi (X \geq c) }\right)$$ I don't know why the expected value is a non-negative random variable is always greater than the expected value of its subset? The second inequality that confused me is $$E\left(X_{\chi (X \geq c) }\right) \geq c P(X \geq c)$$ Cany anyone help me explain these 2 inequalities?,Let's say is a non-negative random variable. And say is a positive constant. Why is I don't know why the expected value is a non-negative random variable is always greater than the expected value of its subset? The second inequality that confused me is Cany anyone help me explain these 2 inequalities?,X c E(X)\geq E\left(X_{\chi (X \geq c) }\right) E\left(X_{\chi (X \geq c) }\right) \geq c P(X \geq c),['statistics']
71,Finding expectation with given PDF of $f(x)=2xe^{-x^2}$ [closed],Finding expectation with given PDF of  [closed],f(x)=2xe^{-x^2},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question A random variable has PDF given by $f(x)=2xe^{-x^2}$ . Derive the expectation of $x$ . Everytime I integrate this for expectation I am getting nowhere. Any help would be greatly appreciated.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question A random variable has PDF given by . Derive the expectation of . Everytime I integrate this for expectation I am getting nowhere. Any help would be greatly appreciated.",f(x)=2xe^{-x^2} x,"['probability', 'integration', 'statistics', 'expected-value']"
72,Expected value of the maximum of $3$ normal variables,Expected value of the maximum of  normal variables,3,"I want to prove that for $3$ variables $X_1,X_2,X_3$ from normal distribution with $\mu =0,\sigma =1$ for each, $\mathbb{E}(\max \{X_1,X_2,X_3\})\approx 0.85$ . I found the following formula: $\mu +\frac{3}{2\sqrt{\pi}}\sigma$ , which shows this, but I do not know how to prove it. (It would be sufficient to prove it only for $\mu =0,\sigma =1$ ). In addition I need to prove for a general $k\in \mathbb{N}$ that $\mathbb{E}(\max \{X_1,X_2,\ldots ,X_k\})<\mathbb{E}(\max \{X_1,X_2,\ldots ,X_{k+1}\})$ . How can this be shown? Thank you!","I want to prove that for variables from normal distribution with for each, . I found the following formula: , which shows this, but I do not know how to prove it. (It would be sufficient to prove it only for ). In addition I need to prove for a general that . How can this be shown? Thank you!","3 X_1,X_2,X_3 \mu =0,\sigma =1 \mathbb{E}(\max \{X_1,X_2,X_3\})\approx 0.85 \mu +\frac{3}{2\sqrt{\pi}}\sigma \mu =0,\sigma =1 k\in \mathbb{N} \mathbb{E}(\max \{X_1,X_2,\ldots ,X_k\})<\mathbb{E}(\max \{X_1,X_2,\ldots ,X_{k+1}\})","['probability', 'statistics', 'normal-distribution', 'order-statistics']"
73,Method-of-moments estimator for a uniform distribution,Method-of-moments estimator for a uniform distribution,,"I have a sample of data points independently sampled from a uniform distribution with a density function $f(x)=\frac{1}{a}, 0\leq x \leq a$ . I need to use the method of moments to estimate $a_{mom}$ . My idea is to just calculate the variance, then multiply by 12 and take the square root so I get $b-a$ . Then I'm kind of stumped what to do further.","I have a sample of data points independently sampled from a uniform distribution with a density function . I need to use the method of moments to estimate . My idea is to just calculate the variance, then multiply by 12 and take the square root so I get . Then I'm kind of stumped what to do further.","f(x)=\frac{1}{a}, 0\leq x \leq a a_{mom} b-a","['statistics', 'estimation']"
74,How do I calculate phi(z) to 4dp when my Normal Distribution tables are to 2dp?,How do I calculate phi(z) to 4dp when my Normal Distribution tables are to 2dp?,,"I have two Normal Distributions representing weights: X ~ N(30, 25) and Y ~ N(32, 16) Calculate the probability an item from distribution Y weighs more than X, i.e P(Y - X > 0). I did everything correct and ended-up with: B = Y - X B ~ N(2, 41) = 1 - P (B < 0) = 1 - phi((0 - 2)/root(41)) = 1 - phi(-0.3123) = 1 - (1 - 0.6217) = 0.6217 However, their answer: B = Y - X B ~ N(2, 41) P(B > 0) = 1 - P(B < 0) = 1 - 0.3774 = 0.6226 The problem is I looked-up phi(0.31) in the Normal Distribution tables, whereas they calculated phi(0.3123) exactly. How do I calculate phi(0.3123) exactly? This is an International A Level question. We're not supposed to use the phi(z) integral formula. It's either a table look-up, or calculator exercise. To calculate a cumulative probability on my calculator it requires a lower and upper bound, but here the lower bound is -infinity?","I have two Normal Distributions representing weights: X ~ N(30, 25) and Y ~ N(32, 16) Calculate the probability an item from distribution Y weighs more than X, i.e P(Y - X > 0). I did everything correct and ended-up with: B = Y - X B ~ N(2, 41) = 1 - P (B < 0) = 1 - phi((0 - 2)/root(41)) = 1 - phi(-0.3123) = 1 - (1 - 0.6217) = 0.6217 However, their answer: B = Y - X B ~ N(2, 41) P(B > 0) = 1 - P(B < 0) = 1 - 0.3774 = 0.6226 The problem is I looked-up phi(0.31) in the Normal Distribution tables, whereas they calculated phi(0.3123) exactly. How do I calculate phi(0.3123) exactly? This is an International A Level question. We're not supposed to use the phi(z) integral formula. It's either a table look-up, or calculator exercise. To calculate a cumulative probability on my calculator it requires a lower and upper bound, but here the lower bound is -infinity?",,"['probability', 'statistics', 'normal-distribution']"
75,Writing a random variable as the sum of independent random variables,Writing a random variable as the sum of independent random variables,,"Let $X_i$ be independent random variables with $X_i \sim Po(1)$ . We know (for instance by looking at characteristic functions) that then $\sum_{i=1}^{n} X_i \sim Po(n)$ . I am interested in the converse of that implication. Let $Y \sim Po(n)$ . Can we find independent random variables $Y_1, ..., Y_n$ with $Y_i \sim Po(1)$ such that $\sum_{i=1}^{n} Y_i=Y$ ?",Let be independent random variables with . We know (for instance by looking at characteristic functions) that then . I am interested in the converse of that implication. Let . Can we find independent random variables with such that ?,"X_i X_i \sim Po(1) \sum_{i=1}^{n} X_i \sim Po(n) Y \sim Po(n) Y_1, ..., Y_n Y_i \sim Po(1) \sum_{i=1}^{n} Y_i=Y","['probability', 'statistics', 'random-variables', 'independence', 'poisson-distribution']"
76,What is the proof for variance of triangular distribution?,What is the proof for variance of triangular distribution?,,"In Wikipedia, the formula for the variance of the triangular distribution is given here . However, I don't know how to find it. I have tried a brute force method but the formula is quite complicated (polynomial of degree 5 in a, b, c) and I can't simplify it (I tried manually and with Xcas). The following part is edited thanks to @Imaosome remark: I came to this question with the following problem: Say $X$ and $Y$ are independent random variables with uniform distribution between $0$ and $1$ . I want to study $Z = X-Y$ . With convolution , I find that the distribution is triangular, centered in $0$ with extremities $-1$ and $1$ (the proof is also available in this pdf here ). With Wikipedia notations, it gives $a=-1, b=1, c=0$ . And in this case, we sum $2$ independent variables therefore the variance shoud be $Var(X)+Var(-Y) = Var(X)+Var(Y)=2 Var(X)$ . The variance of $X$ is $1/12$ (see for instance formula here ). Therefore the variance of $Z$ is $Var(Z) = 2 * 1/12 = 1/6$ . If I come back to Wikipedia formula, I find: $$ \frac{a^2+b^2+c^2-ab-ac-bc}{18}=\frac{1+1+0+1-0-0}{18}=1/6. $$ This shows, at least in that particular case that the formula is correct. But I would like to try and prove Wikipedia result. Once again, I know that it should be possible to prove it by integration but I did not succeed and I hope somebody has a simple way to get this formula. Here are the details. By definition, we want to compute: \begin{align*} \sigma^2 &= \int_a^c \frac{2(x-a)}{(b-a)(c-a)} \left( x - \frac{a+b+c}{3} \right)^2 dx + \int_c^b \frac{2(b-x)}{(b-a)(b-c)} \left( x - \frac{a+b+c}{3} \right)^2 dx \\ &= \frac{2}{(b-a)(c-a)} \left[ \frac{1}{3} (x-a) \left( x - \frac{a+b+c}{3} \right)^3 - \frac{1}{12} \left( x - \frac{a+b+c}{3} \right)^4 \right]_a^c \\ & ~~~~~~ \frac{2}{(b-a)(b-c)} \left[ \frac{1}{3} (b-x) \left( x - \frac{a+b+c}{3} \right)^3 - \frac{1}{12} \left( x - \frac{a+b+c}{3} \right)^4 \right]_c^b \end{align*} From there, one can see that terms in $\left( x - \frac{a+b+c}{3}\right)$ cancel out leaving us with: \begin{align*} \sigma^2 &= \frac{2}{12(b-a)(c-a)} \left( - \left( \frac{2c-a-b}{3} \right)^4 + \left( \frac{2a-b-c}{3} \right)^4 \right) \\ & ~~~~~~ \frac{2}{12(b-a)(b-c)} \left( - \left( \frac{2b-a-c}{3} \right)^4 + \left( \frac{2c-a-b}{3} \right)^4 \right) \\ &= \frac{((c-a)-(b-c))^5 +(b-c)((b-a)+(c-a))^4 - (c-a)((b-a)+(b-c))^4}{ 2 \times 3^5 (b-a)(b-c)(c-a) } \end{align*} And from this point, I am stuck. After all, maybe the last line is not helping much. I don't know.","In Wikipedia, the formula for the variance of the triangular distribution is given here . However, I don't know how to find it. I have tried a brute force method but the formula is quite complicated (polynomial of degree 5 in a, b, c) and I can't simplify it (I tried manually and with Xcas). The following part is edited thanks to @Imaosome remark: I came to this question with the following problem: Say and are independent random variables with uniform distribution between and . I want to study . With convolution , I find that the distribution is triangular, centered in with extremities and (the proof is also available in this pdf here ). With Wikipedia notations, it gives . And in this case, we sum independent variables therefore the variance shoud be . The variance of is (see for instance formula here ). Therefore the variance of is . If I come back to Wikipedia formula, I find: This shows, at least in that particular case that the formula is correct. But I would like to try and prove Wikipedia result. Once again, I know that it should be possible to prove it by integration but I did not succeed and I hope somebody has a simple way to get this formula. Here are the details. By definition, we want to compute: From there, one can see that terms in cancel out leaving us with: And from this point, I am stuck. After all, maybe the last line is not helping much. I don't know.","X Y 0 1 Z = X-Y 0 -1 1 a=-1, b=1, c=0 2 Var(X)+Var(-Y) = Var(X)+Var(Y)=2 Var(X) X 1/12 Z Var(Z) = 2 * 1/12 = 1/6 
\frac{a^2+b^2+c^2-ab-ac-bc}{18}=\frac{1+1+0+1-0-0}{18}=1/6.
 \begin{align*}
\sigma^2 &= \int_a^c \frac{2(x-a)}{(b-a)(c-a)} \left( x - \frac{a+b+c}{3} \right)^2 dx + \int_c^b \frac{2(b-x)}{(b-a)(b-c)} \left( x - \frac{a+b+c}{3} \right)^2 dx \\
&= \frac{2}{(b-a)(c-a)} \left[ \frac{1}{3} (x-a) \left( x - \frac{a+b+c}{3} \right)^3 - \frac{1}{12} \left( x - \frac{a+b+c}{3} \right)^4 \right]_a^c \\
& ~~~~~~ \frac{2}{(b-a)(b-c)} \left[ \frac{1}{3} (b-x) \left( x - \frac{a+b+c}{3} \right)^3 - \frac{1}{12} \left( x - \frac{a+b+c}{3} \right)^4 \right]_c^b
\end{align*} \left( x - \frac{a+b+c}{3}\right) \begin{align*}
\sigma^2 &= \frac{2}{12(b-a)(c-a)} \left( - \left( \frac{2c-a-b}{3} \right)^4 + \left( \frac{2a-b-c}{3} \right)^4 \right) \\
& ~~~~~~ \frac{2}{12(b-a)(b-c)} \left( - \left( \frac{2b-a-c}{3} \right)^4 + \left( \frac{2c-a-b}{3} \right)^4 \right) \\
&= \frac{((c-a)-(b-c))^5 +(b-c)((b-a)+(c-a))^4 - (c-a)((b-a)+(b-c))^4}{ 2 \times 3^5 (b-a)(b-c)(c-a) }
\end{align*}","['statistics', 'uniform-distribution', 'variance']"
77,Uniform probability measure on integers and arithmetic progressions,Uniform probability measure on integers and arithmetic progressions,,"Does there exist a probability measure on the integers such that, the probability of any two arithmetic progressions with the same difference part, is the same? We assume the probability measure is defined over the power set of the integers. Hence, a probability measure corresponds to a sequence of positive (non-negative) numbers $\{p_z\}_{z \in \mathbb{Z}}$ which sum up to one.","Does there exist a probability measure on the integers such that, the probability of any two arithmetic progressions with the same difference part, is the same? We assume the probability measure is defined over the power set of the integers. Hence, a probability measure corresponds to a sequence of positive (non-negative) numbers which sum up to one.",\{p_z\}_{z \in \mathbb{Z}},"['probability', 'measure-theory']"
78,What's the third derivative of $\log( \det X)$ with respect to $X$? [closed],What's the third derivative of  with respect to ? [closed],\log( \det X) X,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question If $X$ is positive definite matrix, what is the third derivative of $\log(\det X)$ with respect to $X$ ? We know the first derivative of $\log(\det X)$ is $X^{-1}$ and the second derivative (hessian) is $X^{-1} \otimes X^{-1}$ but I don't know the third derivative of $\log(\det X)$ with respect to $X$ . Thanks in advance.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question If is positive definite matrix, what is the third derivative of with respect to ? We know the first derivative of is and the second derivative (hessian) is but I don't know the third derivative of with respect to . Thanks in advance.",X \log(\det X) X \log(\det X) X^{-1} X^{-1} \otimes X^{-1} \log(\det X) X,"['statistics', 'multivariable-calculus', 'derivatives', 'matrix-calculus']"
79,Compute minimum amount of 60s to obtain a 9-darts finish in 501 double darts out,Compute minimum amount of 60s to obtain a 9-darts finish in 501 double darts out,,"In 501 double out darts, it is possible to reach the final score of 501 with only 9 darts. The dartboard has fields 1 - 20, and also double and triple fields and the semi-bull (25) and bullseye (50). The last dart needs to hit a double field, i.e. either of: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 50] I already know all possible 9-dart-finish combinations (you can look them up on the internet). I have noticed that you need a minimum of three 60s to obtain a 9-darts finish. Now I wonder: is there a way to prove this? Or is there at least a way to see that you need to hit a 60 at least once in order to obtain a 9-darts finish? Because in 301 darts you can obtain a 6-darts finish without ever hitting a 60. Would anyone care to show an example calculation?","In 501 double out darts, it is possible to reach the final score of 501 with only 9 darts. The dartboard has fields 1 - 20, and also double and triple fields and the semi-bull (25) and bullseye (50). The last dart needs to hit a double field, i.e. either of: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 50] I already know all possible 9-dart-finish combinations (you can look them up on the internet). I have noticed that you need a minimum of three 60s to obtain a 9-darts finish. Now I wonder: is there a way to prove this? Or is there at least a way to see that you need to hit a 60 at least once in order to obtain a 9-darts finish? Because in 301 darts you can obtain a 6-darts finish without ever hitting a 60. Would anyone care to show an example calculation?",,"['probability', 'combinatorics', 'statistics']"
80,what does $Φ ^ {-1}$ mean?,what does  mean?,Φ ^ {-1},This is a part of a statistics question I am given $Φ ^ {-1}(0.9377)=1.536$ but I don't know what this $Φ ^ {-1}$ means and how he got 1.536 and from where. any help is much appreciated thank you.,This is a part of a statistics question I am given but I don't know what this means and how he got 1.536 and from where. any help is much appreciated thank you.,Φ ^ {-1}(0.9377)=1.536 Φ ^ {-1},"['probability', 'statistics']"
81,"If 10 needles are dropped on the floor, how many needles are expected to cross a line?","If 10 needles are dropped on the floor, how many needles are expected to cross a line?",,"If 10 needles are dropped on the floor, how many needles are expected to cross over one of the lines? This is a variation of the Buffon Needle problem (short needle). I believe that the probability of a singular needle dropping is $\frac{2L}{\pi}$ , where L is the length of the needle. Would I simply multiply it together 10 times? I'm not quite sure what to do?","If 10 needles are dropped on the floor, how many needles are expected to cross over one of the lines? This is a variation of the Buffon Needle problem (short needle). I believe that the probability of a singular needle dropping is , where L is the length of the needle. Would I simply multiply it together 10 times? I'm not quite sure what to do?",\frac{2L}{\pi},"['probability', 'statistics']"
82,Probability of more than 13 balls remaining in the box after some selections,Probability of more than 13 balls remaining in the box after some selections,,"Question A box contains 20 balls, of which exactly 8 are red and 12 are green. Two balls are randomly selected from the box, without replacement. Then, any red balls selected are put back into the box, while any green balls selected are thrown away. Finally, 5 balls are randomly selected from the box, without replacement. Suppose that, following this procedure, all 5 balls are green. Find the probability that there remains more than 13 balls in the box. My working Observe that the only case when there are less than 14 balls in the box is when the two balls that are selected initially are both green, so we have three cases to consider here. Case 1: Choose 2 red balls, put them back, then choose 5 green balls. Case 2: Choose 1 red ball, then 1 green ball. Put the red ball back, throw the green one away and then choose 5 green balls. Case 3: Choose 1 green ball, then 1 red ball. Put the red ball back, throw the green one away and then choose 5 green balls. $\mathbb{P} (\mathrm {Case\ 1}) = \frac 8 {20} * \frac 7 {19} * \frac {12} {20} * \frac {11} {19} * \frac {10} {18} * \frac 9 {17} * \frac 8 {16} = \frac {231} {30685}$ $\mathbb{P} (\mathrm {Case\ 2}) = \frac 8 {20} * \frac {12} {19} * \frac {11} {19} * \frac {10} {18} * \frac 9 {17} * \frac 8 {16} * \frac 7 {15} = \frac {308} {30685}$ $\mathbb{P} (\mathrm {Case\ 3}) = \mathbb{P} (\mathrm {Case\ 2})$ $\therefore \mathbb{P} (\mathrm {> 13\ balls\ left\ in\ the\ box}) = \frac {231} {30685} + 2 * \frac {308} {30685} = \frac {847} {30685}$ Answer $\mathbb{P} (\mathrm {> 13\ balls\ left\ in\ the\ box}) = \frac {154} {211}$ My answer is obviously off by a lot ): Am I missing cases, or is my thinking too naive etc.? I am not sure where I have gone wrong, so any intuitive explanations about my mistake(s) and also what the correct solution should be will be greatly appreciated! P.S. My professor did provide a solution, but I am unable to understand his way of thinking, so I thought posting the problem here and asking for ideas would be better.","Question A box contains 20 balls, of which exactly 8 are red and 12 are green. Two balls are randomly selected from the box, without replacement. Then, any red balls selected are put back into the box, while any green balls selected are thrown away. Finally, 5 balls are randomly selected from the box, without replacement. Suppose that, following this procedure, all 5 balls are green. Find the probability that there remains more than 13 balls in the box. My working Observe that the only case when there are less than 14 balls in the box is when the two balls that are selected initially are both green, so we have three cases to consider here. Case 1: Choose 2 red balls, put them back, then choose 5 green balls. Case 2: Choose 1 red ball, then 1 green ball. Put the red ball back, throw the green one away and then choose 5 green balls. Case 3: Choose 1 green ball, then 1 red ball. Put the red ball back, throw the green one away and then choose 5 green balls. Answer My answer is obviously off by a lot ): Am I missing cases, or is my thinking too naive etc.? I am not sure where I have gone wrong, so any intuitive explanations about my mistake(s) and also what the correct solution should be will be greatly appreciated! P.S. My professor did provide a solution, but I am unable to understand his way of thinking, so I thought posting the problem here and asking for ideas would be better.",\mathbb{P} (\mathrm {Case\ 1}) = \frac 8 {20} * \frac 7 {19} * \frac {12} {20} * \frac {11} {19} * \frac {10} {18} * \frac 9 {17} * \frac 8 {16} = \frac {231} {30685} \mathbb{P} (\mathrm {Case\ 2}) = \frac 8 {20} * \frac {12} {19} * \frac {11} {19} * \frac {10} {18} * \frac 9 {17} * \frac 8 {16} * \frac 7 {15} = \frac {308} {30685} \mathbb{P} (\mathrm {Case\ 3}) = \mathbb{P} (\mathrm {Case\ 2}) \therefore \mathbb{P} (\mathrm {> 13\ balls\ left\ in\ the\ box}) = \frac {231} {30685} + 2 * \frac {308} {30685} = \frac {847} {30685} \mathbb{P} (\mathrm {> 13\ balls\ left\ in\ the\ box}) = \frac {154} {211},"['probability', 'statistics', 'conditional-probability']"
83,Leap year probability,Leap year probability,,"A year in the 2020s (i.e., from 2020 to 2029 inclusive) is selected uniformly at random, a month is selected uniformly at random from that year, and a day of the month is selected uniformly at random from that month. (a) What is the (exact) probability that the day is the 29th of February? ->I use 3/10 * 1/12 * 1/29 [not very sure] (b) Given that the day is the 29th, what is the probability that the month is February? For this one, I know I should use Baye's rule, but cannot proceed further. Is anyone willing to help?","A year in the 2020s (i.e., from 2020 to 2029 inclusive) is selected uniformly at random, a month is selected uniformly at random from that year, and a day of the month is selected uniformly at random from that month. (a) What is the (exact) probability that the day is the 29th of February? ->I use 3/10 * 1/12 * 1/29 [not very sure] (b) Given that the day is the 29th, what is the probability that the month is February? For this one, I know I should use Baye's rule, but cannot proceed further. Is anyone willing to help?",,"['probability', 'combinatorics', 'statistics']"
84,"Is it possible that individually, pieces of evidence increase the chance of guilt but together they decrease the chance of guilt?","Is it possible that individually, pieces of evidence increase the chance of guilt but together they decrease the chance of guilt?",,"Let G be the event that a certain individual is guilty of a certain robbery. In gathering evidence, it is learned that an event $E_1$ occurred, and a little later it is also learned that another event $E_2$ also occurred. Is it possible that individually, these pieces of evidence increase the chance of guilt (so $P(G|E1)$ $> P(G)$ and $P(G|E2) > P(G)$ ), but together they decrease the chance of guilt (so $P(G|E1, E2)$ $ < P(G)$ )? This is the example in the solution: Suppose that the crime was committed between 1 pm and 3 pm on a certain day. Let E1 be the event that the suspect was at a nearby coffeeshop from 1 pm to 2 pm that day, and let E2 be the event that the suspect was at the nearby coffeeshop from 2 pm to 3 pm that day. Then P(G|E1) > P(G), P(G|E2) > P(G) (assuming that being in the vicinity helps show that the suspect had the opportunity to commit the crime), yet P(G|E1, E2) < P(G) (as being in the coffeeshop from 1 pm to 3 pm gives the suspect an alibi for the full time). I've been trying to think of another example but I can't think of any. Can someone provide another example? Moreover, in terms of general problem-solving heuristics, I find myself terrible at coming up with examples/counter-examples. My only strategy is to look for simple/extreme cases, but there's no simple/extreme cases for this question. Thank you very much!","Let G be the event that a certain individual is guilty of a certain robbery. In gathering evidence, it is learned that an event occurred, and a little later it is also learned that another event also occurred. Is it possible that individually, these pieces of evidence increase the chance of guilt (so and ), but together they decrease the chance of guilt (so )? This is the example in the solution: Suppose that the crime was committed between 1 pm and 3 pm on a certain day. Let E1 be the event that the suspect was at a nearby coffeeshop from 1 pm to 2 pm that day, and let E2 be the event that the suspect was at the nearby coffeeshop from 2 pm to 3 pm that day. Then P(G|E1) > P(G), P(G|E2) > P(G) (assuming that being in the vicinity helps show that the suspect had the opportunity to commit the crime), yet P(G|E1, E2) < P(G) (as being in the coffeeshop from 1 pm to 3 pm gives the suspect an alibi for the full time). I've been trying to think of another example but I can't think of any. Can someone provide another example? Moreover, in terms of general problem-solving heuristics, I find myself terrible at coming up with examples/counter-examples. My only strategy is to look for simple/extreme cases, but there's no simple/extreme cases for this question. Thank you very much!","E_1 E_2 P(G|E1) > P(G) P(G|E2) > P(G) P(G|E1, E2)  < P(G)","['probability', 'statistics', 'paradoxes']"
85,Grasping the practical usage of Central Limit Theorem,Grasping the practical usage of Central Limit Theorem,,"I've been reviewing the Central Limit Theorem in statistics and I'm having trouble intuitively grasping how it can be practically used. The theorem tells us, subject to constraints, that the distribution of the sample mean will be approximately normal, even if the population distribution is not. From what I understand, this remarkable fact now allows us to use inferential statistical methods that apply to the normal distribution to answer questions about the population distribution. But I struggle with intuitively grasping why this is possible? That is, if I want to answer some question about a random variable X of unknown distribution, how does working with the sample mean of X get me to the answer about X? Is there a step missing that allows me to infer properties of X from properties of the sample mean of X?","I've been reviewing the Central Limit Theorem in statistics and I'm having trouble intuitively grasping how it can be practically used. The theorem tells us, subject to constraints, that the distribution of the sample mean will be approximately normal, even if the population distribution is not. From what I understand, this remarkable fact now allows us to use inferential statistical methods that apply to the normal distribution to answer questions about the population distribution. But I struggle with intuitively grasping why this is possible? That is, if I want to answer some question about a random variable X of unknown distribution, how does working with the sample mean of X get me to the answer about X? Is there a step missing that allows me to infer properties of X from properties of the sample mean of X?",,"['statistics', 'central-limit-theorem']"
86,"If you choose two different sets of results to match inside a coin flipping record, does the odds of finding a match depend on what you pick on each?","If you choose two different sets of results to match inside a coin flipping record, does the odds of finding a match depend on what you pick on each?",,"Example, if you flip a coin 10 times and record the results, and you pick 2 different sets of 5 length (e.g HHTHT and TTHTT where H=heads and T=tails) and the goal is to match any of your two sets anywhere inside the coin results (e.g TTTTHHTHTH contains the example set HHTHT ). The question is, can the combined odds of finding a match on either set be affected depending on the way the sets are chosen? Also bonus in case the odds vary, explain which strategies could be used to improve and/or worsen the chances of finding a match (if it doesn't matter at all, bonus doesn't apply obviously). My hypothesis is that if they overlap (e.g set_a = HHHHH and set_b = THHHH ) you end up with less odds of finding a match, but usually these kind of problems are counter-intuitive and I couldn't tackle this problem myself, at least not in a non-inductive way.","Example, if you flip a coin 10 times and record the results, and you pick 2 different sets of 5 length (e.g HHTHT and TTHTT where H=heads and T=tails) and the goal is to match any of your two sets anywhere inside the coin results (e.g TTTTHHTHTH contains the example set HHTHT ). The question is, can the combined odds of finding a match on either set be affected depending on the way the sets are chosen? Also bonus in case the odds vary, explain which strategies could be used to improve and/or worsen the chances of finding a match (if it doesn't matter at all, bonus doesn't apply obviously). My hypothesis is that if they overlap (e.g set_a = HHHHH and set_b = THHHH ) you end up with less odds of finding a match, but usually these kind of problems are counter-intuitive and I couldn't tackle this problem myself, at least not in a non-inductive way.",,['statistics']
87,How many games will you play and how many of those games will you lose?,How many games will you play and how many of those games will you lose?,,"Each time you play a game, you win with probability p. (The games are independent.) You plan to play 5 games, but if you win the fifth game, then you will keep on playing until you lose. (a) Find the expected number of games that you play. (b) Find the expected number of games that you lose. I'm not sure how to account for games that you play past the 5 games. I know that if you have a p% chance of winning the game you would only have to check on the 5th game and onward whether you win or not. But how would I go about doing so?","Each time you play a game, you win with probability p. (The games are independent.) You plan to play 5 games, but if you win the fifth game, then you will keep on playing until you lose. (a) Find the expected number of games that you play. (b) Find the expected number of games that you lose. I'm not sure how to account for games that you play past the 5 games. I know that if you have a p% chance of winning the game you would only have to check on the 5th game and onward whether you win or not. But how would I go about doing so?",,['statistics']
88,Why doesn't Scipy's wasserstein_distance use linear programming?,Why doesn't Scipy's wasserstein_distance use linear programming?,,"Question Kantorovich's formulation of the optimal transport problem using the Wasserstein distance is $$\begin{align}\begin{aligned}W_p(a,b)=(\min_\gamma \sum_{i,j}\gamma_{i,j}\|x_i-y_j\|_p)^\frac{1}{p}\\s.t. \gamma 1 = a; \gamma^T 1= b; \gamma\geq 0\end{aligned}\end{align}$$ It is often taught that this is solved using linear programming: $$\begin{align}\begin{aligned}OT(a,b)=\min_\gamma \quad \sum_{i,j}\gamma_{i,j}M_{i,j}\\s.t. \gamma 1 = a; \gamma^T 1= b; \gamma\geq 0\end{aligned}\end{align}$$ How then is the function scipy.stats.wasserstein_distance able to solve Wasserstein/OT without linear programming? What approach/method is the function using? My guess I am aware that wasserstein_distance is for 1D distributions only, and there so happens to be a closed-form analytical solution in the 1D case which is $$\mathcal{W}_{p}(\mu, \nu) =\left(\int_{0}^{1}\left|F_{\mu}^{-1}(z)-F_{\nu}^{-1}(z)\right|^{p} \mathrm{d} z\right)^{\frac{1}{p}}$$ The formula above contains inverse probability functions $F^{-1}$ . The code, shown next, however, does not contain inverse probability functions from what I can see. Code I know this sounds like a stackoverflow question, but it's not (and I need to write the math formulas): I'm trying to figure out what formula/approach is being used by the code since the code does not resemble anything above: It doesn't use linear programming, otherwise we would see scipy.optimize.linprog somewhere, and it doesn't use inverse probability, otherwise we would see .ppf somewhere: def wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None):     r""""""     Compute the first Wasserstein distance between two 1D distributions.     This distance is also known as the earth mover's distance, since it can be     seen as the minimum amount of ""work"" required to transform :math:`u` into     :math:`v`, where ""work"" is measured as the amount of distribution weight     that must be moved, multiplied by the distance it has to be moved.     .. versionadded:: 1.0.0     Parameters     ----------     u_values, v_values : array_like         Values observed in the (empirical) distribution.     u_weights, v_weights : array_like, optional         Weight for each value. If unspecified, each value is assigned the same         weight.         `u_weights` (resp. `v_weights`) must have the same length as         `u_values` (resp. `v_values`). If the weight sum differs from 1, it         must still be positive and finite so that the weights can be normalized         to sum to 1.     Returns     -------     distance : float         The computed distance between the distributions.     Notes     -----     The first Wasserstein distance between the distributions :math:`u` and     :math:`v` is:     .. math::         l_1 (u, v) = \inf_{\pi \in \Gamma (u, v)} \int_{\mathbb{R} \times         \mathbb{R}} |x-y| \mathrm{d} \pi (x, y)     where :math:`\Gamma (u, v)` is the set of (probability) distributions on     :math:`\mathbb{R} \times \mathbb{R}` whose marginals are :math:`u` and     :math:`v` on the first and second factors respectively.     If :math:`U` and :math:`V` are the respective CDFs of :math:`u` and     :math:`v`, this distance also equals to:     .. math::         l_1(u, v) = \int_{-\infty}^{+\infty} |U-V|     See [2]_ for a proof of the equivalence of both definitions.     The input distributions can be empirical, therefore coming from samples     whose values are effectively inputs of the function, or they can be seen as     generalized functions, in which case they are weighted sums of Dirac delta     functions located at the specified values.     References     ----------     .. [1] ""Wasserstein metric"", https://en.wikipedia.org/wiki/Wasserstein_metric     .. [2] Ramdas, Garcia, Cuturi ""On Wasserstein Two Sample Testing and Related            Families of Nonparametric Tests"" (2015). :arXiv:`1509.02237`.     Examples     --------     >>> from scipy.stats import wasserstein_distance     >>> wasserstein_distance([0, 1, 3], [5, 6, 8])     5.0     >>> wasserstein_distance([0, 1], [0, 1], [3, 1], [2, 2])     0.25     >>> wasserstein_distance([3.4, 3.9, 7.5, 7.8], [4.5, 1.4],     ...                      [1.4, 0.9, 3.1, 7.2], [3.2, 3.5])     4.0781331438047861     """"""     return _cdf_distance(1, u_values, v_values, u_weights, v_weights)  def _cdf_distance(p, u_values, v_values, u_weights=None, v_weights=None):     r""""""     Compute, between two one-dimensional distributions :math:`u` and     :math:`v`, whose respective CDFs are :math:`U` and :math:`V`, the     statistical distance that is defined as:     .. math::         l_p(u, v) = \left( \int_{-\infty}^{+\infty} |U-V|^p \right)^{1/p}     p is a positive parameter; p = 1 gives the Wasserstein distance, p = 2     gives the energy distance.     Parameters     ----------     u_values, v_values : array_like         Values observed in the (empirical) distribution.     u_weights, v_weights : array_like, optional         Weight for each value. If unspecified, each value is assigned the same         weight.         `u_weights` (resp. `v_weights`) must have the same length as         `u_values` (resp. `v_values`). If the weight sum differs from 1, it         must still be positive and finite so that the weights can be normalized         to sum to 1.     Returns     -------     distance : float         The computed distance between the distributions.     Notes     -----     The input distributions can be empirical, therefore coming from samples     whose values are effectively inputs of the function, or they can be seen as     generalized functions, in which case they are weighted sums of Dirac delta     functions located at the specified values.     References     ----------     .. [1] Bellemare, Danihelka, Dabney, Mohamed, Lakshminarayanan, Hoyer,            Munos ""The Cramer Distance as a Solution to Biased Wasserstein            Gradients"" (2017). :arXiv:`1705.10743`.     """"""     u_values, u_weights = _validate_distribution(u_values, u_weights)     v_values, v_weights = _validate_distribution(v_values, v_weights)      u_sorter = np.argsort(u_values)     v_sorter = np.argsort(v_values)      all_values = np.concatenate((u_values, v_values))     all_values.sort(kind='mergesort')      # Compute the differences between pairs of successive values of u and v.     deltas = np.diff(all_values)      # Get the respective positions of the values of u and v among the values of     # both distributions.     u_cdf_indices = u_values[u_sorter].searchsorted(all_values[:-1], 'right')     v_cdf_indices = v_values[v_sorter].searchsorted(all_values[:-1], 'right')      # Calculate the CDFs of u and v using their weights, if specified.     if u_weights is None:         u_cdf = u_cdf_indices / u_values.size     else:         u_sorted_cumweights = np.concatenate(([0],                                               np.cumsum(u_weights[u_sorter])))         u_cdf = u_sorted_cumweights[u_cdf_indices] / u_sorted_cumweights[-1]      if v_weights is None:         v_cdf = v_cdf_indices / v_values.size     else:         v_sorted_cumweights = np.concatenate(([0],                                               np.cumsum(v_weights[v_sorter])))         v_cdf = v_sorted_cumweights[v_cdf_indices] / v_sorted_cumweights[-1]      # Compute the value of the integral based on the CDFs.     # If p = 1 or p = 2, we avoid using np.power, which introduces an overhead     # of about 15%.     if p == 1:         return np.sum(np.multiply(np.abs(u_cdf - v_cdf), deltas))     if p == 2:         return np.sqrt(np.sum(np.multiply(np.square(u_cdf - v_cdf), deltas)))     return np.power(np.sum(np.multiply(np.power(np.abs(u_cdf - v_cdf), p),                                        deltas)), 1/p)","Question Kantorovich's formulation of the optimal transport problem using the Wasserstein distance is It is often taught that this is solved using linear programming: How then is the function scipy.stats.wasserstein_distance able to solve Wasserstein/OT without linear programming? What approach/method is the function using? My guess I am aware that wasserstein_distance is for 1D distributions only, and there so happens to be a closed-form analytical solution in the 1D case which is The formula above contains inverse probability functions . The code, shown next, however, does not contain inverse probability functions from what I can see. Code I know this sounds like a stackoverflow question, but it's not (and I need to write the math formulas): I'm trying to figure out what formula/approach is being used by the code since the code does not resemble anything above: It doesn't use linear programming, otherwise we would see scipy.optimize.linprog somewhere, and it doesn't use inverse probability, otherwise we would see .ppf somewhere: def wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None):     r""""""     Compute the first Wasserstein distance between two 1D distributions.     This distance is also known as the earth mover's distance, since it can be     seen as the minimum amount of ""work"" required to transform :math:`u` into     :math:`v`, where ""work"" is measured as the amount of distribution weight     that must be moved, multiplied by the distance it has to be moved.     .. versionadded:: 1.0.0     Parameters     ----------     u_values, v_values : array_like         Values observed in the (empirical) distribution.     u_weights, v_weights : array_like, optional         Weight for each value. If unspecified, each value is assigned the same         weight.         `u_weights` (resp. `v_weights`) must have the same length as         `u_values` (resp. `v_values`). If the weight sum differs from 1, it         must still be positive and finite so that the weights can be normalized         to sum to 1.     Returns     -------     distance : float         The computed distance between the distributions.     Notes     -----     The first Wasserstein distance between the distributions :math:`u` and     :math:`v` is:     .. math::         l_1 (u, v) = \inf_{\pi \in \Gamma (u, v)} \int_{\mathbb{R} \times         \mathbb{R}} |x-y| \mathrm{d} \pi (x, y)     where :math:`\Gamma (u, v)` is the set of (probability) distributions on     :math:`\mathbb{R} \times \mathbb{R}` whose marginals are :math:`u` and     :math:`v` on the first and second factors respectively.     If :math:`U` and :math:`V` are the respective CDFs of :math:`u` and     :math:`v`, this distance also equals to:     .. math::         l_1(u, v) = \int_{-\infty}^{+\infty} |U-V|     See [2]_ for a proof of the equivalence of both definitions.     The input distributions can be empirical, therefore coming from samples     whose values are effectively inputs of the function, or they can be seen as     generalized functions, in which case they are weighted sums of Dirac delta     functions located at the specified values.     References     ----------     .. [1] ""Wasserstein metric"", https://en.wikipedia.org/wiki/Wasserstein_metric     .. [2] Ramdas, Garcia, Cuturi ""On Wasserstein Two Sample Testing and Related            Families of Nonparametric Tests"" (2015). :arXiv:`1509.02237`.     Examples     --------     >>> from scipy.stats import wasserstein_distance     >>> wasserstein_distance([0, 1, 3], [5, 6, 8])     5.0     >>> wasserstein_distance([0, 1], [0, 1], [3, 1], [2, 2])     0.25     >>> wasserstein_distance([3.4, 3.9, 7.5, 7.8], [4.5, 1.4],     ...                      [1.4, 0.9, 3.1, 7.2], [3.2, 3.5])     4.0781331438047861     """"""     return _cdf_distance(1, u_values, v_values, u_weights, v_weights)  def _cdf_distance(p, u_values, v_values, u_weights=None, v_weights=None):     r""""""     Compute, between two one-dimensional distributions :math:`u` and     :math:`v`, whose respective CDFs are :math:`U` and :math:`V`, the     statistical distance that is defined as:     .. math::         l_p(u, v) = \left( \int_{-\infty}^{+\infty} |U-V|^p \right)^{1/p}     p is a positive parameter; p = 1 gives the Wasserstein distance, p = 2     gives the energy distance.     Parameters     ----------     u_values, v_values : array_like         Values observed in the (empirical) distribution.     u_weights, v_weights : array_like, optional         Weight for each value. If unspecified, each value is assigned the same         weight.         `u_weights` (resp. `v_weights`) must have the same length as         `u_values` (resp. `v_values`). If the weight sum differs from 1, it         must still be positive and finite so that the weights can be normalized         to sum to 1.     Returns     -------     distance : float         The computed distance between the distributions.     Notes     -----     The input distributions can be empirical, therefore coming from samples     whose values are effectively inputs of the function, or they can be seen as     generalized functions, in which case they are weighted sums of Dirac delta     functions located at the specified values.     References     ----------     .. [1] Bellemare, Danihelka, Dabney, Mohamed, Lakshminarayanan, Hoyer,            Munos ""The Cramer Distance as a Solution to Biased Wasserstein            Gradients"" (2017). :arXiv:`1705.10743`.     """"""     u_values, u_weights = _validate_distribution(u_values, u_weights)     v_values, v_weights = _validate_distribution(v_values, v_weights)      u_sorter = np.argsort(u_values)     v_sorter = np.argsort(v_values)      all_values = np.concatenate((u_values, v_values))     all_values.sort(kind='mergesort')      # Compute the differences between pairs of successive values of u and v.     deltas = np.diff(all_values)      # Get the respective positions of the values of u and v among the values of     # both distributions.     u_cdf_indices = u_values[u_sorter].searchsorted(all_values[:-1], 'right')     v_cdf_indices = v_values[v_sorter].searchsorted(all_values[:-1], 'right')      # Calculate the CDFs of u and v using their weights, if specified.     if u_weights is None:         u_cdf = u_cdf_indices / u_values.size     else:         u_sorted_cumweights = np.concatenate(([0],                                               np.cumsum(u_weights[u_sorter])))         u_cdf = u_sorted_cumweights[u_cdf_indices] / u_sorted_cumweights[-1]      if v_weights is None:         v_cdf = v_cdf_indices / v_values.size     else:         v_sorted_cumweights = np.concatenate(([0],                                               np.cumsum(v_weights[v_sorter])))         v_cdf = v_sorted_cumweights[v_cdf_indices] / v_sorted_cumweights[-1]      # Compute the value of the integral based on the CDFs.     # If p = 1 or p = 2, we avoid using np.power, which introduces an overhead     # of about 15%.     if p == 1:         return np.sum(np.multiply(np.abs(u_cdf - v_cdf), deltas))     if p == 2:         return np.sqrt(np.sum(np.multiply(np.square(u_cdf - v_cdf), deltas)))     return np.power(np.sum(np.multiply(np.power(np.abs(u_cdf - v_cdf), p),                                        deltas)), 1/p)","\begin{align}\begin{aligned}W_p(a,b)=(\min_\gamma \sum_{i,j}\gamma_{i,j}\|x_i-y_j\|_p)^\frac{1}{p}\\s.t. \gamma 1 = a; \gamma^T 1= b; \gamma\geq 0\end{aligned}\end{align} \begin{align}\begin{aligned}OT(a,b)=\min_\gamma \quad \sum_{i,j}\gamma_{i,j}M_{i,j}\\s.t. \gamma 1 = a; \gamma^T 1= b; \gamma\geq 0\end{aligned}\end{align} \mathcal{W}_{p}(\mu, \nu) =\left(\int_{0}^{1}\left|F_{\mu}^{-1}(z)-F_{\nu}^{-1}(z)\right|^{p} \mathrm{d} z\right)^{\frac{1}{p}} F^{-1}","['statistics', 'linear-programming', 'python', 'programming', 'optimal-transport']"
89,Check if set of dice is fair,Check if set of dice is fair,,"I had a statistics question that I was curious about. Hypothetically, a company found a new way to manufacture dice. If I wanted to check if the dice are fair with 1/6 probability for each side, how would I go about doing that. There would be N dice that are rolled n times which is N * n total dice throws. How would you go about statistically verifying that the process manufactures fair dice? Is there a way to measure the uncertainty of the dice being fair? Something that I thought could work are using the chi-squared test and goodness of fit but this could get tedious for a large amount of dice and dice throws. Are there other statistical tests that would be better suited to address this question?","I had a statistics question that I was curious about. Hypothetically, a company found a new way to manufacture dice. If I wanted to check if the dice are fair with 1/6 probability for each side, how would I go about doing that. There would be N dice that are rolled n times which is N * n total dice throws. How would you go about statistically verifying that the process manufactures fair dice? Is there a way to measure the uncertainty of the dice being fair? Something that I thought could work are using the chi-squared test and goodness of fit but this could get tedious for a large amount of dice and dice throws. Are there other statistical tests that would be better suited to address this question?",,"['probability', 'statistics', 'descriptive-statistics']"
90,Prove that the Distribution of Marginal Vectors are also multivariate normal,Prove that the Distribution of Marginal Vectors are also multivariate normal,,"I'm told that $\mathbf{\Sigma}$ is a positive definite matrix and also that it's the variance of $\mathbf{X}$ where $\mathbf{X}=\bf{\mu}+BZ$ such that $\mathbf{\mu},\mathbf{Z}\in\mathbb{R}^n$ and $Z_1,\dots,Z_n\sim_{\mathrm{iid}}\mathcal{N}(0,1)$ . In addition, I'm to partition the matrix $\bf\Sigma$ in the following way: $$ \bf \Sigma= \begin{pmatrix} \bf \Sigma_p & \bf \Sigma_r \\ \bf \Sigma_r^{\top} & \bf \Sigma_q    \end{pmatrix}. $$ So the question is to prove that the marginal vectors $\mathbf{X}_p$ and $\mathbf{X}_q$ are also multivariate normal, with $ \mathbf{X}_p\sim\mathcal{N}(\mu_p,\mathbf{\Sigma}_p)$ and $ \mathbf{X}_q\sim\mathcal{N}(\mu_q,\mathbf{\Sigma}_q)$ . I've tried to simply rewrite the expression for $\bf X$ in terms of the marginal vectors and use matrix multiplication to equate components but it seems to be a dead end because I can't simplify anything down or at least I dont know how to simplify everything. In addition I've tried showing that the MGF of the marginal vectors will have be the one for the multivariate gaussian but my working unfortunately seems to not go anywhere. Any help would be appreciated, thank you.","I'm told that is a positive definite matrix and also that it's the variance of where such that and . In addition, I'm to partition the matrix in the following way: So the question is to prove that the marginal vectors and are also multivariate normal, with and . I've tried to simply rewrite the expression for in terms of the marginal vectors and use matrix multiplication to equate components but it seems to be a dead end because I can't simplify anything down or at least I dont know how to simplify everything. In addition I've tried showing that the MGF of the marginal vectors will have be the one for the multivariate gaussian but my working unfortunately seems to not go anywhere. Any help would be appreciated, thank you.","\mathbf{\Sigma} \mathbf{X} \mathbf{X}=\bf{\mu}+BZ \mathbf{\mu},\mathbf{Z}\in\mathbb{R}^n Z_1,\dots,Z_n\sim_{\mathrm{iid}}\mathcal{N}(0,1) \bf\Sigma  \bf \Sigma= \begin{pmatrix} \bf \Sigma_p & \bf \Sigma_r \\ \bf \Sigma_r^{\top} & \bf \Sigma_q    \end{pmatrix}.  \mathbf{X}_p \mathbf{X}_q  \mathbf{X}_p\sim\mathcal{N}(\mu_p,\mathbf{\Sigma}_p)  \mathbf{X}_q\sim\mathcal{N}(\mu_q,\mathbf{\Sigma}_q) \bf X","['statistics', 'probability-distributions', 'normal-distribution']"
91,Cramer's V - example and intuition,Cramer's V - example and intuition,,"Hy, I self study statistics and I come across Cramer's V and I search on Google. The result I find didn't explain me so I please to answer this questions. What is measured by Cramer's V? What is an example when Cramer's V is equal to 0 and an example when is 1?","Hy, I self study statistics and I come across Cramer's V and I search on Google. The result I find didn't explain me so I please to answer this questions. What is measured by Cramer's V? What is an example when Cramer's V is equal to 0 and an example when is 1?",,['statistics']
92,Show that $S^2$ is a biased estimator of $\sigma^2$,Show that  is a biased estimator of,S^2 \sigma^2,How did they get from equation (3) to equation (4)? $$S^2 = \frac{1}{n} \sum (X_i - \bar{X})^2 \tag{0}$$ $$E[S^2] = E\Big[\frac{1}{n} \sum (X_i - \bar{X})^2 \Big]\tag{1}$$ $$E[S^2] = E\Bigg[\frac{1}{n} \sum \limits_{i=1}^{n}\Big[~[(X_i - \mu)-(\bar{X}-\mu)]^2~\Bigg]\tag{2}$$ $$E[S^2] = \Bigg[ \frac{1}{n} \sum \limits_{i=1}^{n} \Big[~(X_i-\mu)^2-2(X_i-\mu)(\bar{X}-\mu)+(\bar{X}-\mu)^2~\Big] ~\Bigg]\tag{3}$$ $$E[S^2] = E\Bigg[~\frac{1}{n} \Big[~\sum \limits_{i=1}^{n} (X_i - \mu)^2 - n(\bar{X} - \mu)^2 \Big]~\Bigg]\tag{4}$$ $$E[S^2] = \frac{1}{n} \sum \limits_{i=1}^{n} E[X_i-\mu)^2] - E[(\bar{X}-\mu)^2]\tag{5}$$ $$E[S^2] = \sigma^2 - \sigma_X^2\tag{6}$$ $$E[S^2] = \sigma^2 - \frac{1}{n}\sigma^2\tag{7}$$ $$E[S^2] = \frac{n-1}{n}\sigma^2\tag{8}$$ Equation (8) shows that $S^2$ is a biased estimator of $\sigma^2$,How did they get from equation (3) to equation (4)? Equation (8) shows that is a biased estimator of,S^2 = \frac{1}{n} \sum (X_i - \bar{X})^2 \tag{0} E[S^2] = E\Big[\frac{1}{n} \sum (X_i - \bar{X})^2 \Big]\tag{1} E[S^2] = E\Bigg[\frac{1}{n} \sum \limits_{i=1}^{n}\Big[~[(X_i - \mu)-(\bar{X}-\mu)]^2~\Bigg]\tag{2} E[S^2] = \Bigg[ \frac{1}{n} \sum \limits_{i=1}^{n} \Big[~(X_i-\mu)^2-2(X_i-\mu)(\bar{X}-\mu)+(\bar{X}-\mu)^2~\Big] ~\Bigg]\tag{3} E[S^2] = E\Bigg[~\frac{1}{n} \Big[~\sum \limits_{i=1}^{n} (X_i - \mu)^2 - n(\bar{X} - \mu)^2 \Big]~\Bigg]\tag{4} E[S^2] = \frac{1}{n} \sum \limits_{i=1}^{n} E[X_i-\mu)^2] - E[(\bar{X}-\mu)^2]\tag{5} E[S^2] = \sigma^2 - \sigma_X^2\tag{6} E[S^2] = \sigma^2 - \frac{1}{n}\sigma^2\tag{7} E[S^2] = \frac{n-1}{n}\sigma^2\tag{8} S^2 \sigma^2,['statistics']
93,Why is it important for a correlation matrix to be positive semidefinite?,Why is it important for a correlation matrix to be positive semidefinite?,,Now I understand the definition of positive semidefiniteness but I am struggling to understand as to why a Correlation matrix must be positive semidefinite. What are the effects of negative eigenvalues in relation to correlation matrices?,Now I understand the definition of positive semidefiniteness but I am struggling to understand as to why a Correlation matrix must be positive semidefinite. What are the effects of negative eigenvalues in relation to correlation matrices?,,"['matrices', 'statistics', 'correlation', 'positive-definite', 'positive-semidefinite']"
94,Approximating Probabilities of Winning a Game with a 9% Winning Chance,Approximating Probabilities of Winning a Game with a 9% Winning Chance,,"A game has a winning probability of $9\%$ . If you play $10$ times, what is the probability that you win $$(i)\text{ exactly once}$$ $$(ii) \text{at least once}$$ $$(iii) \text{less than 3 times or more than 5 times}$$ Since this is a binomial distribution $\frac{winning}{losing}$ , I approached (i) the following way: $$\frac{10!}{9!} \times {0.09}^1 \times {0.91}^9 = 38.5\%$$ Is this correct? Because it seems rather high to me that one has almost a $40%$ probability of winning EXACTLY once. But my intuition might be (as is usually is) flawed. For the second subtask now I assume that one could simply calculate $$1 - {0.91}^{10} = 61.1\%$$ Here I wanted to ask, I one were not to use this shortcut, but to actually add all binomial probabilities, if it would be admissible to approximate the result normally in the following way: $$E(x) = np = 100.09 = 0.9~~ \text{and}~~ \sigma = \sqrt {({100.09}\times{0.91})} = 0.905$$ If we include all results from $1$ to $10$ wins, with continuity correction $(1-0.5 = 0.5)$ and standardisation we have $$1 - P(X ≥ 1) = P\left(Z ≥ \frac{(0.5-0.9)}{0.905}\right) = P(Z ≥ -0.442) = 67.1\%$$ However, this approximation seems quite off form the actual solution of $61.1\%$ , where did I do a mistake? Or can't you use a normal approximation for the task in question? For the last subtask I again started by calculating the binomial probability: $$1 - \text{P(three wins) - P(four wins) - P(five wins)} \\=1 - \left(\frac{10!}{3!7!} \times {0.09}^3 \times {0.91}^7 \right) - \left(\frac{10!}{4!6!} \times {0.09}^4 \times {0.91}^6) \right) - \left(\frac{10!}{5!5!} \times {0.09}^5 \times {0.91}^5 \right)= 94.6 \%$$ Would there be a faster way to calculate this? Again, if you would approximate normally: $$1 - P\left(\frac{(2.5-0.9)}{0.905} ≤ Z ≤ \frac{(5.5-0.9)}{0.905}\right) = 1 - P(1.768 ≤ Z ≤ 5.083) = 96.2\%$$ I seem to be doing something wrong with the normal approximation, but I can't figure out what is is. Can someone spot the mistake?","A game has a winning probability of . If you play times, what is the probability that you win Since this is a binomial distribution , I approached (i) the following way: Is this correct? Because it seems rather high to me that one has almost a probability of winning EXACTLY once. But my intuition might be (as is usually is) flawed. For the second subtask now I assume that one could simply calculate Here I wanted to ask, I one were not to use this shortcut, but to actually add all binomial probabilities, if it would be admissible to approximate the result normally in the following way: If we include all results from to wins, with continuity correction and standardisation we have However, this approximation seems quite off form the actual solution of , where did I do a mistake? Or can't you use a normal approximation for the task in question? For the last subtask I again started by calculating the binomial probability: Would there be a faster way to calculate this? Again, if you would approximate normally: I seem to be doing something wrong with the normal approximation, but I can't figure out what is is. Can someone spot the mistake?",9\% 10 (i)\text{ exactly once} (ii) \text{at least once} (iii) \text{less than 3 times or more than 5 times} \frac{winning}{losing} \frac{10!}{9!} \times {0.09}^1 \times {0.91}^9 = 38.5\% 40% 1 - {0.91}^{10} = 61.1\% E(x) = np = 100.09 = 0.9~~ \text{and}~~ \sigma = \sqrt {({100.09}\times{0.91})} = 0.905 1 10 (1-0.5 = 0.5) 1 - P(X ≥ 1) = P\left(Z ≥ \frac{(0.5-0.9)}{0.905}\right) = P(Z ≥ -0.442) = 67.1\% 61.1\% 1 - \text{P(three wins) - P(four wins) - P(five wins)} \\=1 - \left(\frac{10!}{3!7!} \times {0.09}^3 \times {0.91}^7 \right) - \left(\frac{10!}{4!6!} \times {0.09}^4 \times {0.91}^6) \right) - \left(\frac{10!}{5!5!} \times {0.09}^5 \times {0.91}^5 \right)= 94.6 \% 1 - P\left(\frac{(2.5-0.9)}{0.905} ≤ Z ≤ \frac{(5.5-0.9)}{0.905}\right) = 1 - P(1.768 ≤ Z ≤ 5.083) = 96.2\%,"['probability', 'statistics', 'probability-distributions']"
95,Can I work out the variance in batches?,Can I work out the variance in batches?,,"So I have a data divided into chunks, and I can only calculate the variance in each of the chunks because of software limitations. But I want to get the variance of the whole data together, not the chunks.  I know the variance is not a linear operator.  I would like the get kind of the average of the variance but this will have to be the same number as If I calculated the variance of the whole data together. Example: Rolling a dice in 3 groups of 2 rolls I can calculate the variance on each of the groups, so I with this data, I want to calculate the variance of the whole set: rolling a dice 6 times. Thank you for your help.","So I have a data divided into chunks, and I can only calculate the variance in each of the chunks because of software limitations. But I want to get the variance of the whole data together, not the chunks.  I know the variance is not a linear operator.  I would like the get kind of the average of the variance but this will have to be the same number as If I calculated the variance of the whole data together. Example: Rolling a dice in 3 groups of 2 rolls I can calculate the variance on each of the groups, so I with this data, I want to calculate the variance of the whole set: rolling a dice 6 times. Thank you for your help.",,"['probability', 'statistics', 'variance']"
96,Joint entropy of 2 independent random variables,Joint entropy of 2 independent random variables,,"Say we have two independent random variables $X$ and $Y$ . What is their joint entropy $H(X,Y)$ ? I worked this out, but I am not sure if the result I reached is correct. The definitions of entropy that I used are: $ \begin{align} H(X) = - \sum_{x \in D(X)} P(x)\log_2P(x) \\ H(X,Y) = - \sum_{x \in D(X)} \sum_{y \in D(Y)} P(x,y)\log_2P(x,y) \end{align} $ I started from the definition of $H(X,Y)$ and rewrote it using the assumption that $X$ and $Y$ are independent. $ \begin{align*} H(X,Y) = - \sum_{x \in D(X)} \sum_{y \in D(Y)} P(x)P(y)\log_2(P(x)P(y))  \end{align*} $ From here I used algebra rules. However due to the double summation, I am not confident in my result. $ \begin{gather} H(X,Y) = - \sum_{x \in D(X)} P(x) \sum_{y \in D(Y)} P(y)(\log_2P(x)+ \log_2P(y)) \tag{1}\\        = - \sum_{x \in D(X)} P(x) \sum_{y \in D(Y)} (P(y)\log_2P(x)+ P(y)\log_2P(y)) \tag{2}\\        = - \sum_{x \in D(X)} P(x)\log_2P(x) \sum_{y \in D(Y)} (P(y)+ P(y)\frac{\log_2P(y)}{\log_2P(x)}) \tag{3}\\        = H(X) \sum_{y \in D(Y)} (P(y) + P(y)\frac{\log_2P(y)}{\log_2P(x)}) \tag{4}\\        = H(X) (\sum_{y \in D(Y)} P(y) + \sum_{y \in D(Y)} P(y)\frac{\log_2P(y)}{\log_2P(x)}) \tag{5}\\        = H(X) (\sum_{y \in D(Y)} P(y) - \frac{H(Y)}{\log_2P(x)}) \tag{6}\\        = H(X) (1 - \frac{H(Y)}{\log_2P(x)}) \tag{7}\\        = H(X) - \frac{H(Y)H(X)}{\log_2P(x)} \tag{8} \\        = H(X) - H(Y)\sum_{x \in D(X)}P(x)\frac{\log_2P(x)}{\log_2P(x)} \tag{9}\\        = H(X) - H(Y)\sum_{x \in D(X)}P(x) \tag{10} \\        = \boxed{H(X) - H(Y)} \tag{11} \end{gather} $ Thanks. EDIT: New method: expand summations Starting from the rewritten expression of $H(X,Y)$ , expand the inner sum (assume there are $n$ elements in $Y$ ). $$\begin{align}& H(X,Y) \\[2ex]&= - \sum_{x} \sum_{y} P(x)P(y)(\log P(x) + \log P(y)) \\[2ex]&= - \sum_{x} \sum_{y} (P(x)P(y)\log P(x) + P(x)P(y)\log P(y)) \\[2ex]&= - \sum_{x} P(x) (P(y_1)\log P(x) + P(y_1)\log P(y_1) + \ldots  + P(y_n)\log P(x) + P(y_n)\log P(y_n)) \\[2ex]&= - \sum_{x} P(x) (P(y_1)\log P(x) + \ldots + P(y_n)\log P(x)   + P(y_1)\log P(y_1) + \ldots + P(y_n)\log P(y_n) ) \\[2ex]&= - \sum_{x} P(x) (\log P(x)(P(y_1) + \ldots + P(y_n))   + \sum_{y} P(y) \log P(y) ) \\[2ex]&= - \sum_{x} P(x) (\log P(x) - H(Y)) \\[2ex]&= - \sum_{x} (P(x)\log P(x) - P(x)H(Y)) \\[2ex]&= - (P(x_1)\log P(x_1) - P(x_1)H(Y) + \ldots + P(x_n)\log P(x_n) - P(x_n)H(Y)) \\[2ex]&= - (P(x_1)\log P(x_1) + \ldots + P(x_n)\log P(x_n) - P(x_1)H(Y) - \ldots - P(x_n)H(Y)) \\[2ex]&= - (\sum_{x}P(x)\log P(x) - H(Y)(P(x_1) + \ldots P(x_n))) \\[2ex]&= \boxed{H(X) + H(Y)} \end{align}$$","Say we have two independent random variables and . What is their joint entropy ? I worked this out, but I am not sure if the result I reached is correct. The definitions of entropy that I used are: I started from the definition of and rewrote it using the assumption that and are independent. From here I used algebra rules. However due to the double summation, I am not confident in my result. Thanks. EDIT: New method: expand summations Starting from the rewritten expression of , expand the inner sum (assume there are elements in ).","X Y H(X,Y) 
\begin{align}
H(X) = - \sum_{x \in D(X)} P(x)\log_2P(x) \\
H(X,Y) = - \sum_{x \in D(X)} \sum_{y \in D(Y)} P(x,y)\log_2P(x,y)
\end{align}
 H(X,Y) X Y 
\begin{align*}
H(X,Y) = - \sum_{x \in D(X)} \sum_{y \in D(Y)} P(x)P(y)\log_2(P(x)P(y)) 
\end{align*}
 
\begin{gather}
H(X,Y) = - \sum_{x \in D(X)} P(x) \sum_{y \in D(Y)} P(y)(\log_2P(x)+ \log_2P(y)) \tag{1}\\
       = - \sum_{x \in D(X)} P(x) \sum_{y \in D(Y)} (P(y)\log_2P(x)+ P(y)\log_2P(y)) \tag{2}\\
       = - \sum_{x \in D(X)} P(x)\log_2P(x) \sum_{y \in D(Y)} (P(y)+ P(y)\frac{\log_2P(y)}{\log_2P(x)}) \tag{3}\\
       = H(X) \sum_{y \in D(Y)} (P(y) + P(y)\frac{\log_2P(y)}{\log_2P(x)}) \tag{4}\\
       = H(X) (\sum_{y \in D(Y)} P(y) + \sum_{y \in D(Y)} P(y)\frac{\log_2P(y)}{\log_2P(x)}) \tag{5}\\
       = H(X) (\sum_{y \in D(Y)} P(y) - \frac{H(Y)}{\log_2P(x)}) \tag{6}\\
       = H(X) (1 - \frac{H(Y)}{\log_2P(x)}) \tag{7}\\
       = H(X) - \frac{H(Y)H(X)}{\log_2P(x)} \tag{8} \\
       = H(X) - H(Y)\sum_{x \in D(X)}P(x)\frac{\log_2P(x)}{\log_2P(x)} \tag{9}\\
       = H(X) - H(Y)\sum_{x \in D(X)}P(x) \tag{10} \\
       = \boxed{H(X) - H(Y)} \tag{11}
\end{gather}
 H(X,Y) n Y \begin{align}& H(X,Y)
\\[2ex]&= - \sum_{x} \sum_{y} P(x)P(y)(\log P(x) + \log P(y))
\\[2ex]&= - \sum_{x} \sum_{y} (P(x)P(y)\log P(x) + P(x)P(y)\log P(y))
\\[2ex]&= - \sum_{x} P(x) (P(y_1)\log P(x) + P(y_1)\log P(y_1) + \ldots 
+ P(y_n)\log P(x) + P(y_n)\log P(y_n))
\\[2ex]&= - \sum_{x} P(x) (P(y_1)\log P(x) + \ldots + P(y_n)\log P(x) 
 + P(y_1)\log P(y_1) + \ldots + P(y_n)\log P(y_n) )
\\[2ex]&= - \sum_{x} P(x) (\log P(x)(P(y_1) + \ldots + P(y_n)) 
 + \sum_{y} P(y) \log P(y) )
\\[2ex]&= - \sum_{x} P(x) (\log P(x) - H(Y))
\\[2ex]&= - \sum_{x} (P(x)\log P(x) - P(x)H(Y))
\\[2ex]&= - (P(x_1)\log P(x_1) - P(x_1)H(Y) + \ldots + P(x_n)\log P(x_n) - P(x_n)H(Y))
\\[2ex]&= - (P(x_1)\log P(x_1) + \ldots + P(x_n)\log P(x_n) - P(x_1)H(Y) - \ldots - P(x_n)H(Y))
\\[2ex]&= - (\sum_{x}P(x)\log P(x) - H(Y)(P(x_1) + \ldots P(x_n)))
\\[2ex]&= \boxed{H(X) + H(Y)}
\end{align}","['probability', 'statistics', 'probability-distributions', 'entropy']"
97,Confidence Interval question no standard divination given to find the standard error,Confidence Interval question no standard divination given to find the standard error,,A survey of 800 Irish households finds that 54% of households have   oil-fired central heating. Infer a 95% confidence interval for the   percentage of the total population of Irish households that have   oil-fired central heating. This is how I have worked on this problem using the formula to find the standard error Notation $N = 800$ $P = 54$ $95\% = 1.96$ Workings out (1) Find the standard error $$\frac{\sqrt{54(1-.54)}}{800} *100= 0.062$$ (2) Multiply the confidence interval by the standard error $54\% \pm 1.96 * 0.062$ (3) Answer $54\% \pm 0.015$ I would like to know if this is the correct anwser or am I even going the right way about it. The problems contains the standard deviation I can do but I am struggling with this,A survey of 800 Irish households finds that 54% of households have   oil-fired central heating. Infer a 95% confidence interval for the   percentage of the total population of Irish households that have   oil-fired central heating. This is how I have worked on this problem using the formula to find the standard error Notation Workings out (1) Find the standard error (2) Multiply the confidence interval by the standard error (3) Answer I would like to know if this is the correct anwser or am I even going the right way about it. The problems contains the standard deviation I can do but I am struggling with this,N = 800 P = 54 95\% = 1.96 \frac{\sqrt{54(1-.54)}}{800} *100= 0.062 54\% \pm 1.96 * 0.062 54\% \pm 0.015,"['statistics', 'confidence-interval']"
98,"Suppose that $X$ is a random variable, prove that $\operatorname{Var}(X) \geq 4.5$","Suppose that  is a random variable, prove that",X \operatorname{Var}(X) \geq 4.5,"Suppose that $X$ is a random variable for which $\mathbb E(X) = 10$ , $\Pr(X \leq 7) = 0.2$ , and $\Pr(X \geq 13) = 0.3$ . Prove that $\operatorname{Var}(X) \geq 4.5$ . I'm not really sure how to start solving this; thanks for any help!","Suppose that is a random variable for which , , and . Prove that . I'm not really sure how to start solving this; thanks for any help!",X \mathbb E(X) = 10 \Pr(X \leq 7) = 0.2 \Pr(X \geq 13) = 0.3 \operatorname{Var}(X) \geq 4.5,"['probability', 'statistics', 'inequality']"
99,Show $ \mathbb{E}(T_1\mid N_1=0)=1+\frac{1}{\lambda}$ for a Poisson process,Show  for a Poisson process, \mathbb{E}(T_1\mid N_1=0)=1+\frac{1}{\lambda},"For a Poisson process with rate $\lambda$ , show $ \mathbb{E}(T_1\mid N_1=0) = 1 + \frac{1}{\lambda}$ . attempt We know $T_1 \sim \operatorname{Exp}(\lambda)$ . The solution I'm looking at says to use the memoryless property. I don't see how it fits. All I see is that $\{N_1 =0\}=\{T_1>1\}$ . So I am stuck.","For a Poisson process with rate , show . attempt We know . The solution I'm looking at says to use the memoryless property. I don't see how it fits. All I see is that . So I am stuck.",\lambda  \mathbb{E}(T_1\mid N_1=0) = 1 + \frac{1}{\lambda} T_1 \sim \operatorname{Exp}(\lambda) \{N_1 =0\}=\{T_1>1\},"['probability', 'statistics', 'probability-distributions', 'poisson-process']"
