,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Find $f'(0)$ for $f(x)=(2x+1)^3(3x+3)^2$.,Find  for .,f'(0) f(x)=(2x+1)^3(3x+3)^2,Find $f'(0)$ for $f(x)=(2x+1)^3(3x+3)^2$. Do I use the chain rule for each or do I use the derivative product rule first Please Help!!!,Find $f'(0)$ for $f(x)=(2x+1)^3(3x+3)^2$. Do I use the chain rule for each or do I use the derivative product rule first Please Help!!!,,"['calculus', 'derivatives']"
1,Finding the extreme values of a function,Finding the extreme values of a function,,Hello everyone how would I find the extreme values of the following function. $f(x)=\cos^2(x)$  within $0 \leq x \leq 2\pi$ I got the derivative as $f'(x)=-2\sin(x)\cos(x)=0$ I know that $\sin^{-1}(0)=0$ and $\cos^{-1}(0)=\pi/2$ But I am not sure if this is correct as the graph seems to go in a cycle so would there be critical points?,Hello everyone how would I find the extreme values of the following function. $f(x)=\cos^2(x)$  within $0 \leq x \leq 2\pi$ I got the derivative as $f'(x)=-2\sin(x)\cos(x)=0$ I know that $\sin^{-1}(0)=0$ and $\cos^{-1}(0)=\pi/2$ But I am not sure if this is correct as the graph seems to go in a cycle so would there be critical points?,,"['calculus', 'derivatives']"
2,How to find a differentiable function with bounded derivative satisfying some boundary conditions?,How to find a differentiable function with bounded derivative satisfying some boundary conditions?,,"I am trying to find an example, preferably an explicit one, of a differentiable function $g:\mathbb{R}\rightarrow \mathbb{R}$ satisfying the following conditions: $\displaystyle g(0)=0, g(1)=1, g(-1)=-1;$ $\displaystyle g^\prime(1)=g^\prime(-1)=\frac{1}{2};$ $\displaystyle g^\prime(x)\geq\frac{1}{2} \quad \forall x\in [-1,1].$ The function $g(x)=x$ satisfies the first and the last conditions, but we need to modify it, at least locally around the points $x=\pm1$, to meet the constraints about derivatives at the end points. It is plausible that this can be done with some smooth additive modifier functions, but explicit examples may not be easy to find.","I am trying to find an example, preferably an explicit one, of a differentiable function $g:\mathbb{R}\rightarrow \mathbb{R}$ satisfying the following conditions: $\displaystyle g(0)=0, g(1)=1, g(-1)=-1;$ $\displaystyle g^\prime(1)=g^\prime(-1)=\frac{1}{2};$ $\displaystyle g^\prime(x)\geq\frac{1}{2} \quad \forall x\in [-1,1].$ The function $g(x)=x$ satisfies the first and the last conditions, but we need to modify it, at least locally around the points $x=\pm1$, to meet the constraints about derivatives at the end points. It is plausible that this can be done with some smooth additive modifier functions, but explicit examples may not be easy to find.",,"['real-analysis', 'derivatives', 'examples-counterexamples']"
3,"$f:[0,1]\to \mathbb R$ is differentiable, prove that $f$ must be either linear or $|f(1)-f(0)|<|f'(t)|$ for some $t\in (0,1)$","is differentiable, prove that  must be either linear or  for some","f:[0,1]\to \mathbb R f |f(1)-f(0)|<|f'(t)| t\in (0,1)","A function $f:[0,1]\to \mathbb R$ is such that $f$ is differentiable in it's domain. Prove that $f$ , is either linear in $x$ or $$|f(1)-f(0)|<|f'(t)|$$ for some $t\in (0,1)$ My attempt: By Rolle theorem , we know that there exist atleast one $t\in (0,1)$ where the equality holds $$|f(1)-f(0)|=|f'(t)|$$ Now , if such equality would have hold for all $t$ in the domain, then clearly $f$ is linear as the slope remains constant. Now, I try to show that opposite inequality holds false i.e. : $$f(1)-f(0)>f'(t)$$ By integrating both sides, we get that : $$\int_0^1f(1)-f(0) \mathrm dt>\int_0^1 f'(t) \mathrm dt$$ $$f(1)-f(0)>f(1)-f(0)$$ which is a contradiction ! Problems: I had integrated without taking absolute value as asked in question and hence proof is incomplete. This was the last question in my test and hence was toughest. I believe that my (incomplete) proof is not right in itself because it's too simple. Can you help me to solve it in correct way ?","A function is such that is differentiable in it's domain. Prove that , is either linear in or for some My attempt: By Rolle theorem , we know that there exist atleast one where the equality holds Now , if such equality would have hold for all in the domain, then clearly is linear as the slope remains constant. Now, I try to show that opposite inequality holds false i.e. : By integrating both sides, we get that : which is a contradiction ! Problems: I had integrated without taking absolute value as asked in question and hence proof is incomplete. This was the last question in my test and hence was toughest. I believe that my (incomplete) proof is not right in itself because it's too simple. Can you help me to solve it in correct way ?","f:[0,1]\to \mathbb R f f x |f(1)-f(0)|<|f'(t)| t\in (0,1) t\in (0,1) |f(1)-f(0)|=|f'(t)| t f f(1)-f(0)>f'(t) \int_0^1f(1)-f(0) \mathrm dt>\int_0^1 f'(t) \mathrm dt f(1)-f(0)>f(1)-f(0)","['calculus', 'derivatives', 'definite-integrals', 'maxima-minima']"
4,What does $g'(f(2))$ mean?,What does  mean?,g'(f(2)),"Find $g'(f(2)),$ given $f(x)=\sqrt{x^2+5}$ and $g(x)=x^2+x$ . My first step was to find $g(f(x)),$ simplify if possible, then find the derivative $g'(f(x)).$ After I did this, I substituted $2$ for $x.$ A few other students we were saying to find the $g'(x),$ then find $f(2),$ then plug it into $g'(x).$ This also makes sense to me but I'm really unsure.","Find given and . My first step was to find simplify if possible, then find the derivative After I did this, I substituted for A few other students we were saying to find the then find then plug it into This also makes sense to me but I'm really unsure.","g'(f(2)), f(x)=\sqrt{x^2+5} g(x)=x^2+x g(f(x)), g'(f(x)). 2 x. g'(x), f(2), g'(x).","['calculus', 'derivatives', 'chain-rule']"
5,"Visualizing vector fields ""multiplied"" by a function","Visualizing vector fields ""multiplied"" by a function",,"If $M$ is a smooth manifold, how do I interpret an expression such as $f X$ where $f \in C^{\infty}(M)$ and $X$ is a vector field, i.e. a map $M \rightarrow TM$ ? To my understanding, a vector field is a derivation, a map with certain properties. I imagine it as the set of ""directions"" in each point of the manifold. Now I came accross the definition of a covariant derivative of (smooth) vector fields $X, Y$ , which confuses me. The properties satisfied by the covariant derivative are the following: $\nabla_{fX + gY} Z = f \nabla_X Z + g \nabla_Y Z$ $\nabla_X (Y + Z) = \nabla_X Y + \nabla_X Z$ $\nabla_X (fY) = X(f)Y + f \nabla_X Y$ My question: What does the $f X$ says? If $f$ just takes points from $M$ and assigns them a value (I guess in $\mathbb{R}^n$ ?), then how can it be multiplied or composed with a vector field that goes from $M$ to the tangent space? And what is the difference between $X(f)$ and $fX$ in the conditions? Thank you very much.","If is a smooth manifold, how do I interpret an expression such as where and is a vector field, i.e. a map ? To my understanding, a vector field is a derivation, a map with certain properties. I imagine it as the set of ""directions"" in each point of the manifold. Now I came accross the definition of a covariant derivative of (smooth) vector fields , which confuses me. The properties satisfied by the covariant derivative are the following: My question: What does the says? If just takes points from and assigns them a value (I guess in ?), then how can it be multiplied or composed with a vector field that goes from to the tangent space? And what is the difference between and in the conditions? Thank you very much.","M f X f \in C^{\infty}(M) X M \rightarrow TM X, Y \nabla_{fX + gY} Z = f \nabla_X Z + g \nabla_Y Z \nabla_X (Y + Z) = \nabla_X Y + \nabla_X Z \nabla_X (fY) = X(f)Y + f \nabla_X Y f X f M \mathbb{R}^n M X(f) fX","['derivatives', 'manifolds', 'smooth-manifolds', 'vector-fields', 'smooth-functions']"
6,Differentiability of a piecewise defined discontinuous function,Differentiability of a piecewise defined discontinuous function,,"Let $ f(x) = \begin{cases} x-4 & \text{if } x \lt 1; \\ x+1 & \text{if } x > 1; \\ 0 & \text{if } x = 1. \end{cases}$ Why isn’t this function differentiable at 1? Why isn’t its derivative=1 at x=1? Both left and right sides have their derivatives equal to $1$ as $x$ approaches $1$ . I can see that the left hand and right hand derivatives do not agree at $x=1$ . However, could someone explain that to me intuitively, that is, without using the definition of the derivative?","Let Why isn’t this function differentiable at 1? Why isn’t its derivative=1 at x=1? Both left and right sides have their derivatives equal to as approaches . I can see that the left hand and right hand derivatives do not agree at . However, could someone explain that to me intuitively, that is, without using the definition of the derivative?"," f(x) = \begin{cases}
x-4 & \text{if } x \lt 1; \\
x+1 & \text{if } x > 1; \\
0 & \text{if } x = 1.
\end{cases} 1 x 1 x=1","['calculus', 'derivatives', 'slope']"
7,Help with Polar Coordinates proof in Calculus,Help with Polar Coordinates proof in Calculus,,"so I have this Polar Coordinates Homework Problem, and I don't know really know how to start/prove it. The problem goes as follows: Let $f$ be a differentiable function, and let $P$ be the point $(\theta,f(\theta))$ on the polar graph of $r = f(\theta).$ Let $\alpha$ be the angle between the tangent line to the graph at $P,$ and the line $OP,$ where $O$ is the origin. Assuming that $f'(\theta) \neq 0,$ show that $\tan\alpha=\frac{f(\theta)}{f'(\theta)}$ From what I've understood from this problem, if I extended a tangent line to P all the way to the x-axis, and called that point Q, I make $\angle PQO=\pi-\theta-\alpha,$ beyond that, I am lost.","so I have this Polar Coordinates Homework Problem, and I don't know really know how to start/prove it. The problem goes as follows: Let be a differentiable function, and let be the point on the polar graph of Let be the angle between the tangent line to the graph at and the line where is the origin. Assuming that show that From what I've understood from this problem, if I extended a tangent line to P all the way to the x-axis, and called that point Q, I make beyond that, I am lost.","f P (\theta,f(\theta)) r = f(\theta). \alpha P, OP, O f'(\theta) \neq 0, \tan\alpha=\frac{f(\theta)}{f'(\theta)} \angle PQO=\pi-\theta-\alpha,","['calculus', 'derivatives', 'polar-coordinates']"
8,$7$ th derivative of function at $x=0$,th derivative of function at,7 x=0,If $\displaystyle y=\frac{\sin(x^2)-x^2}{x^3}$ . Then value of $\displaystyle \frac{d^7y}{dx^7}\bigg|_{x=0}=$ What i try $$\sin x=\sum^{\infty}_{n=0}(-1)^n\frac{x^{2n+1}}{(2n+1)!}$$ Replace $x\rightarrow x^2$ Then $$\sin (x^2)=\sum^{\infty}_{n=0}(-1)^n\frac{x^{4n+2}}{(2n+1)!}$$ $$\frac{\sin(x^2)-x^2}{x^3}=\sum^{\infty}_{n=1}(-1)^n\frac{x^{4n-1}}{(2n+1)!}$$ How do i find its $7$ th derivative. Although i have calculate $1$ st or $2$ nd derivative. But $7$ th derivative is very conplex. Please help me How to solve it. Thanks,If . Then value of What i try Replace Then How do i find its th derivative. Although i have calculate st or nd derivative. But th derivative is very conplex. Please help me How to solve it. Thanks,\displaystyle y=\frac{\sin(x^2)-x^2}{x^3} \displaystyle \frac{d^7y}{dx^7}\bigg|_{x=0}= \sin x=\sum^{\infty}_{n=0}(-1)^n\frac{x^{2n+1}}{(2n+1)!} x\rightarrow x^2 \sin (x^2)=\sum^{\infty}_{n=0}(-1)^n\frac{x^{4n+2}}{(2n+1)!} \frac{\sin(x^2)-x^2}{x^3}=\sum^{\infty}_{n=1}(-1)^n\frac{x^{4n-1}}{(2n+1)!} 7 1 2 7,['derivatives']
9,Minima of $f(x)=\frac{x^2-1}{x^2+1}$,Minima of,f(x)=\frac{x^2-1}{x^2+1},"If $f(x)=\dfrac{x^2-1}{x^2+1}$ for every real $x$ then find the minimum value of $f$ $$ f'(x)=\frac{4x}{(x^2+1)^2}=0\implies x=0\\ f'(-0.5)<0\quad\&\quad f'(0.5)>0 $$ Seems to me like $x=0$ is a point of inflexion. But, $$ f''(x)=\frac{4(1-3x^2)}{(x^2+1)^3}\\ f''(0)>0\implies x=0\text{ is a minima} $$ Am I making some stupid mistake here, since it doesnt make sense to me ?","If for every real then find the minimum value of Seems to me like is a point of inflexion. But, Am I making some stupid mistake here, since it doesnt make sense to me ?","f(x)=\dfrac{x^2-1}{x^2+1} x f 
f'(x)=\frac{4x}{(x^2+1)^2}=0\implies x=0\\
f'(-0.5)<0\quad\&\quad f'(0.5)>0
 x=0 
f''(x)=\frac{4(1-3x^2)}{(x^2+1)^3}\\
f''(0)>0\implies x=0\text{ is a minima}
","['derivatives', 'maxima-minima']"
10,Isn't this a trivial corollary?,Isn't this a trivial corollary?,,"Let $U \subseteq \mathbb R^{n}$ be an open subset and let $M \subseteq U$ be a $k$ -dimensional submanifold of $\mathbb R^{n}$ . Consider a differentiable function $f: \ U \longrightarrow \mathbb R$ . There's a corollary that states, that if $f \big|_M$ takes on a local extremum at a point $p \in M$ , then the gradient $\nabla f(p)$ is normal to $M$ at $p$ , i.e. $\nabla f(p) \perp T_{p}M$ , where $T_{p}M$ is the tangent space. I've studied and understood the (short) proof, but isn't this statement absolutely trivial or have I got things mixed up? Let me explain: Assuming $p$ is an extremum, it follows that the differential vanishes, i.e. $\nabla f(p) = 0$ , since this is a necessary condition. But the zero vector is orthogonal to everything. So what's the point of this corollary?","Let be an open subset and let be a -dimensional submanifold of . Consider a differentiable function . There's a corollary that states, that if takes on a local extremum at a point , then the gradient is normal to at , i.e. , where is the tangent space. I've studied and understood the (short) proof, but isn't this statement absolutely trivial or have I got things mixed up? Let me explain: Assuming is an extremum, it follows that the differential vanishes, i.e. , since this is a necessary condition. But the zero vector is orthogonal to everything. So what's the point of this corollary?",U \subseteq \mathbb R^{n} M \subseteq U k \mathbb R^{n} f: \ U \longrightarrow \mathbb R f \big|_M p \in M \nabla f(p) M p \nabla f(p) \perp T_{p}M T_{p}M p \nabla f(p) = 0,"['derivatives', 'differential-geometry', 'orthogonality', 'submanifold', 'tangent-spaces']"
11,Derivative of $\sqrt{x^{2}}$ at $x=0$,Derivative of  at,\sqrt{x^{2}} x=0,"I'm suppose to calculate the derivative of $f(x)=\sqrt{x^2}$ when $x=0$ . I.e., I need to determine $f'(0)$ .  I worked it out this way: $\begin{align} f'(0 )&= \lim_{x\rightarrow 0} \frac{f(x)-f(a)}{x-a}\\ \\ &=\lim_{x\rightarrow 0} \frac{\sqrt{x^2} - 0}{x-0}\\\\ &=\lim_{x\rightarrow 0} \frac{x}{x}\\ \\ &=1\end{align}$ I know I'm doing something wrong, because the solution says there is no derivative, But I don't know why.","I'm suppose to calculate the derivative of when . I.e., I need to determine .  I worked it out this way: I know I'm doing something wrong, because the solution says there is no derivative, But I don't know why.","f(x)=\sqrt{x^2} x=0 f'(0) \begin{align} f'(0 )&= \lim_{x\rightarrow 0} \frac{f(x)-f(a)}{x-a}\\ \\
&=\lim_{x\rightarrow 0} \frac{\sqrt{x^2} - 0}{x-0}\\\\
&=\lim_{x\rightarrow 0} \frac{x}{x}\\ \\
&=1\end{align}","['calculus', 'derivatives']"
12,Coordinates on a parametric curve,Coordinates on a parametric curve,,"A curve is defined by the parametric equation $(x, y, z)$ $=$ $(-2 + 3t, 1 + 3t^2, 2t-3t^3)$ . There is a unique point $P$ on the curve with the property that the tangent line at $P$ passes through the point $(-8, 10, 8)$ . What are the coordinates of $P$ ? So I tried to find the equation of the tangent line first. So what I did was subtract the point $(-8, 10, 8)$ from the general equation of the line. This gave me $(-6-3t, 9-3t^2, 8-2t+3t^3)$ . The derivative for the general equation of the line is $(3 , 6t, 2-9t^2)$ . So I seem to understand that the tangent line is parallel, and therefore a scalar multiple, of the equation of the derivative. But I can't seem to see what the relationship is and how that can help me get the required coordinates. Any help?","A curve is defined by the parametric equation . There is a unique point on the curve with the property that the tangent line at passes through the point . What are the coordinates of ? So I tried to find the equation of the tangent line first. So what I did was subtract the point from the general equation of the line. This gave me . The derivative for the general equation of the line is . So I seem to understand that the tangent line is parallel, and therefore a scalar multiple, of the equation of the derivative. But I can't seem to see what the relationship is and how that can help me get the required coordinates. Any help?","(x, y, z) = (-2 + 3t, 1 + 3t^2, 2t-3t^3) P P (-8, 10, 8) P (-8, 10, 8) (-6-3t, 9-3t^2, 8-2t+3t^3) (3 , 6t, 2-9t^2)","['calculus', 'derivatives', 'parametric', 'tangent-line']"
13,Find the least value for $\sin x - \cos^2 x -1$,Find the least value for,\sin x - \cos^2 x -1,"Find all the values of $x$ for which the function $y = \sin x - \cos^2 x -1$ assumes the least value. What is that value? At first I found the first derivative to be $y' = \cos x + 2 \sin x \cos x$. Critical point $0$, $-π/6$ (principal) $y'' = - \sin x + 2(\cos 2x)$ Then substitution of $x$ by critical points I found minima. But my answer is incorrect. Correct minimum value is $-9/4$","Find all the values of $x$ for which the function $y = \sin x - \cos^2 x -1$ assumes the least value. What is that value? At first I found the first derivative to be $y' = \cos x + 2 \sin x \cos x$. Critical point $0$, $-π/6$ (principal) $y'' = - \sin x + 2(\cos 2x)$ Then substitution of $x$ by critical points I found minima. But my answer is incorrect. Correct minimum value is $-9/4$",,"['real-analysis', 'trigonometry', 'derivatives', 'optimization', 'maxima-minima']"
14,Real Analysis - Uniform continuity,Real Analysis - Uniform continuity,,"Prove that if $f: (a,b) \rightarrow \Re$ is differentiable on the open interval $(a,b)$, and $f'(x)$ is bounded on the interval $(a,b)$, then $f$ is uniformly continuous on $(a,b)$. Also, prove the converse is false, that is, find a function that is uniformly continuous on $(-1,1)$ whose derivative is unbounded on $(-1,1)$. So I'm a little confused with how to approach this question but this is what I'm thinking so far. So for every $\epsilon \gt 0$ there is a $\delta \gt 0$ and there exists $(x,y) \in (a,b)$ such that $|x-y| \lt \delta$... and this is where I get stuck I know it's only the beginning but I don't know how to incorporate the differentiability of $f$ and I have only done uniform continuity on functions such as $1/x$ or others like that can someone guide me in the right direction?","Prove that if $f: (a,b) \rightarrow \Re$ is differentiable on the open interval $(a,b)$, and $f'(x)$ is bounded on the interval $(a,b)$, then $f$ is uniformly continuous on $(a,b)$. Also, prove the converse is false, that is, find a function that is uniformly continuous on $(-1,1)$ whose derivative is unbounded on $(-1,1)$. So I'm a little confused with how to approach this question but this is what I'm thinking so far. So for every $\epsilon \gt 0$ there is a $\delta \gt 0$ and there exists $(x,y) \in (a,b)$ such that $|x-y| \lt \delta$... and this is where I get stuck I know it's only the beginning but I don't know how to incorporate the differentiability of $f$ and I have only done uniform continuity on functions such as $1/x$ or others like that can someone guide me in the right direction?",,"['real-analysis', 'derivatives', 'continuity', 'proof-explanation', 'uniform-continuity']"
15,"Let $f: [-1, 1] \longrightarrow [-1, 1]$ such that $f\in C^{1}$. Prove that there's exist $x_{0} \in [-1, 1]$ such that $|f'(x_{0})| \leq 1$",Let  such that . Prove that there's exist  such that,"f: [-1, 1] \longrightarrow [-1, 1] f\in C^{1} x_{0} \in [-1, 1] |f'(x_{0})| \leq 1","Let $f: [-1, 1] \longrightarrow [-1, 1]$ such that $f$ is a class $C^{1}$ function. Prove that there's exist $x_{0} \in [-1, 1]$ such that $|f'(x_{0})| \leq 1$. I know that $f'([- 1,1])$ is compact, since $f'$ is continuous. Therefore, it is closed and limited. To prove the result, I tried to use the continuity of $f'$ in some sequence and tried to use the Weierstrass theorem, but I could not conclude anything. I would like some suggestion.","Let $f: [-1, 1] \longrightarrow [-1, 1]$ such that $f$ is a class $C^{1}$ function. Prove that there's exist $x_{0} \in [-1, 1]$ such that $|f'(x_{0})| \leq 1$. I know that $f'([- 1,1])$ is compact, since $f'$ is continuous. Therefore, it is closed and limited. To prove the result, I tried to use the continuity of $f'$ in some sequence and tried to use the Weierstrass theorem, but I could not conclude anything. I would like some suggestion.",,"['real-analysis', 'derivatives']"
16,$\frac{d}{dx} \sqrt{x+2}$,,\frac{d}{dx} \sqrt{x+2},"Forgive me for my simple question, calculus from Engineering school is about ten years in the past for me. $f(x) = \sqrt{x+2}$ What is $f'(x)$? If it were just $f(x) = \sqrt{x}$ it would be easy, because $\sqrt{x} = x^\frac{1}{2}$, but the case of $f(x) = \sqrt{x+2}$ is different because of $+2$, correct? Or am I wrong? :/","Forgive me for my simple question, calculus from Engineering school is about ten years in the past for me. $f(x) = \sqrt{x+2}$ What is $f'(x)$? If it were just $f(x) = \sqrt{x}$ it would be easy, because $\sqrt{x} = x^\frac{1}{2}$, but the case of $f(x) = \sqrt{x+2}$ is different because of $+2$, correct? Or am I wrong? :/",,"['calculus', 'derivatives']"
17,Series of functions $f_n (x)$ which are Differentiable and $\sum_{n=0}^\infty f_n (x) $ uniform convergence to non-differentiable function,Series of functions  which are Differentiable and  uniform convergence to non-differentiable function,f_n (x) \sum_{n=0}^\infty f_n (x) ,"I got the following question on my Home work: show an example of Series of functions $f_n (x)$ which are differentiable and $\sum_{n=0}^\infty f_n (x)  $ uniform convergence to non-differentiable  function. (translated from Hebrew) My main problem is that even if i have $f_n (x)$ which i think is an example, I do not know to calculate $\sum_{n=0}^\infty f_n (x)$","I got the following question on my Home work: show an example of Series of functions $f_n (x)$ which are differentiable and $\sum_{n=0}^\infty f_n (x)  $ uniform convergence to non-differentiable  function. (translated from Hebrew) My main problem is that even if i have $f_n (x)$ which i think is an example, I do not know to calculate $\sum_{n=0}^\infty f_n (x)$",,"['calculus', 'sequences-and-series', 'derivatives']"
18,Element-wise differentiation of a unit-normalized vector,Element-wise differentiation of a unit-normalized vector,,"Let $f_d$ is the $d^{th}$ element of a $D$-dimensional vector $\mathbf{f}$. SImilarly, $\hat{f_d}$ is the $d^{th}$ element of its unit normalized form: $\hat{\mathbf{f}} = \frac{\mathbf{f}}{||\mathbf{f}||}$. I wanted to compute $\frac{\partial \hat{f_d}}{\partial f_d}$ and found: \begin{equation} \frac{\partial \hat{f_d}}{\partial f_d} = \frac{1 - \hat{f_d^2}}{||\mathbf{f}||} \end{equation} However, this paper (in Page 4 , Eq. 9 ) provides the following form: \begin{equation} \frac{\partial \hat{f_d}}{\partial f_d} = \frac{1 - (\mathbf{\hat{f}}^T . \bigtriangledown \mathbf{\hat{f}}) \hat{f_d}}{||\mathbf{f}||} \end{equation} Can anyone please help me to find what did I miss? Thanks.","Let $f_d$ is the $d^{th}$ element of a $D$-dimensional vector $\mathbf{f}$. SImilarly, $\hat{f_d}$ is the $d^{th}$ element of its unit normalized form: $\hat{\mathbf{f}} = \frac{\mathbf{f}}{||\mathbf{f}||}$. I wanted to compute $\frac{\partial \hat{f_d}}{\partial f_d}$ and found: \begin{equation} \frac{\partial \hat{f_d}}{\partial f_d} = \frac{1 - \hat{f_d^2}}{||\mathbf{f}||} \end{equation} However, this paper (in Page 4 , Eq. 9 ) provides the following form: \begin{equation} \frac{\partial \hat{f_d}}{\partial f_d} = \frac{1 - (\mathbf{\hat{f}}^T . \bigtriangledown \mathbf{\hat{f}}) \hat{f_d}}{||\mathbf{f}||} \end{equation} Can anyone please help me to find what did I miss? Thanks.",,"['derivatives', 'vectors', 'normed-spaces']"
19,How to use limit-derivative relationship for this specific case? [closed],How to use limit-derivative relationship for this specific case? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Knowing that $f$ is such that $\ f(x + y) = f(x) + f(y) + xy,$ $lim_{h\to 0} \frac{f(h)}{h} = 2.$ How can we find the value of $f'(1)$ using informations that is given.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Knowing that $f$ is such that $\ f(x + y) = f(x) + f(y) + xy,$ $lim_{h\to 0} \frac{f(h)}{h} = 2.$ How can we find the value of $f'(1)$ using informations that is given.",,['derivatives']
20,Lipschitz function with right derivative =0,Lipschitz function with right derivative =0,,"$f:\mathbb{R}\to\mathbb{R}$ is a Lipschitz function satisfying $$\forall x\in\mathbb{R}, \lim_{n\to\infty} n(f(x+\frac1n)-f(x))=0$$ I want to show that $f$ is constant everywhere. I proved  $$\lim_{y\to x^+} \frac{|f(y)-f(x)|}{|y-x|}=0$$ by choosing $y\in[x+\frac1{n+1},x+\frac1n]$ and using Lipschitz condition. How can I finish the rest?","$f:\mathbb{R}\to\mathbb{R}$ is a Lipschitz function satisfying $$\forall x\in\mathbb{R}, \lim_{n\to\infty} n(f(x+\frac1n)-f(x))=0$$ I want to show that $f$ is constant everywhere. I proved  $$\lim_{y\to x^+} \frac{|f(y)-f(x)|}{|y-x|}=0$$ by choosing $y\in[x+\frac1{n+1},x+\frac1n]$ and using Lipschitz condition. How can I finish the rest?",,"['real-analysis', 'derivatives', 'lipschitz-functions']"
21,Derivative of $x\cdot|x|$ on $x=0$?,Derivative of  on ?,x\cdot|x| x=0,"$$f(x) = x |x|$$ Wolfram Alpha says is : $$f'(x) = \frac{2x^2}{|x|}$$ and thus $f'(0)$ is indeterminate, while an HP48 says that: $$f'(x) = |x| + x \operatorname{sgn} x,$$ which would yield $f'(0) = 0$. If I say that: $$f(x) = -x^2$$ for $x<0$, 0 for $x=0$ and: $$f(x) = x^2$$ for $x>0$, I kinda think that $f'(0)$ is 0; all three parts' derivatives converge to $0$ on $x=0$, and thus I think that Wolfram is wrong, but I don't really dare say that! (but I don't see any spiky bits on $f(x)$, although it seems clear to me that $f''(0)$ is indeterminate). (excuse my poor TeX) edit: according to the answer below, it seems that Wolfram Alpha is wrong- I've already sent them some feedback, but can anyone elaborate on that?","$$f(x) = x |x|$$ Wolfram Alpha says is : $$f'(x) = \frac{2x^2}{|x|}$$ and thus $f'(0)$ is indeterminate, while an HP48 says that: $$f'(x) = |x| + x \operatorname{sgn} x,$$ which would yield $f'(0) = 0$. If I say that: $$f(x) = -x^2$$ for $x<0$, 0 for $x=0$ and: $$f(x) = x^2$$ for $x>0$, I kinda think that $f'(0)$ is 0; all three parts' derivatives converge to $0$ on $x=0$, and thus I think that Wolfram is wrong, but I don't really dare say that! (but I don't see any spiky bits on $f(x)$, although it seems clear to me that $f''(0)$ is indeterminate). (excuse my poor TeX) edit: according to the answer below, it seems that Wolfram Alpha is wrong- I've already sent them some feedback, but can anyone elaborate on that?",,"['calculus', 'derivatives', 'absolute-value']"
22,Natural logarithmic derivative trick,Natural logarithmic derivative trick,,"Hi chaps and chapesses, I was wondering if someone could just explain something. If I have a function which is dependent on $x$, the familiar $f(x)$. Now, if I take the derivative of this, and multiple by $x$ and divide through by $f(x)$. How does this then become true: $$ \frac{x}{f(x)}\frac{d(f(x))}{dx}=\frac{d\ln{f(x)}}{d\ln{x}} $$ I'm thinking I'm either a.) tired, b.) stupud or c.) both","Hi chaps and chapesses, I was wondering if someone could just explain something. If I have a function which is dependent on $x$, the familiar $f(x)$. Now, if I take the derivative of this, and multiple by $x$ and divide through by $f(x)$. How does this then become true: $$ \frac{x}{f(x)}\frac{d(f(x))}{dx}=\frac{d\ln{f(x)}}{d\ln{x}} $$ I'm thinking I'm either a.) tired, b.) stupud or c.) both",,"['derivatives', 'logarithms']"
23,Differentiation of norm,Differentiation of norm,,"How do I differentiate the ""norm"" of  $(x-μ)$, with respect to $μ$, where both $x$ and $μ$ are vectors ? How will I start and proceed ? Thank you in advance.","How do I differentiate the ""norm"" of  $(x-μ)$, with respect to $μ$, where both $x$ and $μ$ are vectors ? How will I start and proceed ? Thank you in advance.",,"['derivatives', 'normed-spaces']"
24,Differentiate the Function: $y=\sqrt{x^x}$,Differentiate the Function:,y=\sqrt{x^x},"$y=\sqrt{x^x}$ How do I convert this into a form that is workable and what indicates that I should do so? Anyway, I tried this method of logging both sides of the equation but I don't know if I am right. $\ln\ y=\sqrt{x} \ln\ x$ $\frac{dy}{dx}\cdot \frac{1}{y}=\sqrt{x}\ \frac{1}{x} +\ln\ x\ \frac{1}{2}x^{-\frac{1}{2}}$ $\sqrt{x}\cdot (\sqrt{x}\ \frac{1}{x} +\ln\ x \ \frac{1}{2}x^{-\frac{1}{2}})$","$y=\sqrt{x^x}$ How do I convert this into a form that is workable and what indicates that I should do so? Anyway, I tried this method of logging both sides of the equation but I don't know if I am right. $\ln\ y=\sqrt{x} \ln\ x$ $\frac{dy}{dx}\cdot \frac{1}{y}=\sqrt{x}\ \frac{1}{x} +\ln\ x\ \frac{1}{2}x^{-\frac{1}{2}}$ $\sqrt{x}\cdot (\sqrt{x}\ \frac{1}{x} +\ln\ x \ \frac{1}{2}x^{-\frac{1}{2}})$",,"['calculus', 'derivatives']"
25,If $A+B=\pi/3$ then what will maximum value of $\tan(A).\tan(B)$?,If  then what will maximum value of ?,A+B=\pi/3 \tan(A).\tan(B),"Suppose I am given that $$A+B=\frac{\pi}{3}$$ then what will be maximum value of $$\tan(A).\tan(B)=?$$ $$\tan(A+B)=\frac{\tan(A)+\tan(B)}{1-\tan(A).\tan(B)}=\sqrt{3}$$ then  $$\tan(A).\tan(B)=\frac{\sqrt(3)-[\tan(A)+\tan(B)]}{\sqrt{3}}=\lambda$$ now for $\lambda$ to be maximum $\tan(A)+\tan(B)$ should be minimum , how to minimise it? I can make guesses but that's not a good approach.","Suppose I am given that $$A+B=\frac{\pi}{3}$$ then what will be maximum value of $$\tan(A).\tan(B)=?$$ $$\tan(A+B)=\frac{\tan(A)+\tan(B)}{1-\tan(A).\tan(B)}=\sqrt{3}$$ then  $$\tan(A).\tan(B)=\frac{\sqrt(3)-[\tan(A)+\tan(B)]}{\sqrt{3}}=\lambda$$ now for $\lambda$ to be maximum $\tan(A)+\tan(B)$ should be minimum , how to minimise it? I can make guesses but that's not a good approach.",,"['calculus', 'derivatives']"
26,"Intuitive meaning of second, third and fourth derivatives at a point.","Intuitive meaning of second, third and fourth derivatives at a point.",,"Can someone explain me the intuitive meaning of second, third and fourth derivatives of a function say, $f(x)$ at a point (say, $a$)? I know it's hard to explain to someone novice like me! But an intuitive answer of this question can help many people.","Can someone explain me the intuitive meaning of second, third and fourth derivatives of a function say, $f(x)$ at a point (say, $a$)? I know it's hard to explain to someone novice like me! But an intuitive answer of this question can help many people.",,"['calculus', 'derivatives']"
27,Curves with a common tangent line,Curves with a common tangent line,,"Question Find the point where the curves $$\tag 1y = x^3 -3x + 4$$ and $$\tag 2 y = 3x^2 - 3x$$ are tangent to each other, that is, have a common tangent line. My approach Let $x = a$ and $x = b$ be the points on curves $(1)$ and $(2)$, respectively, at which their slopes are equal and share a mutual tangent line. Now I will relate the $a$ and $b$ by equating the derivatives of $(1)$ at $a$ and $(2)$ at $b$, as follows $$3a^2 - 3 = 6b- 3 \Leftrightarrow b = \frac{a^2}{2}$$ Let $A$ be the point on curve $(1)$ and $B$ be the point on curve $(2)$ where the two curves share the mutual tangent, that is $$A(a, x^3 - 3x + 4)$$ and $$B(b, 3b^2 - 3b) = B\Big(\frac{a^2}{2}, \frac{3a^4 - 6a^2}{4}\Big)$$ Now, since I have two points on the tangent line, I can calculate the slope and equate it to the derivative of $(1)$ at $a$ as follows  $$\frac{(x^3 - 3x + 4) - \Big(\frac{3a^4 - 6a^2}{4}\Big)}{a -  \frac{a^2}{2}} = 3a^2 - 3$$ Simplifying that equation I get the following, $$3a^4 -8a^3  - 12a^2 + 16 = 0$$ Now, I would solve for $a$ and then substitute the value of $a$ in to points $A$ and $B$ which would then be the points at which the two curves have a common tangent line. The problem is that I doubt I should be solving such an equation, and quite frankly, I don't have the tools to solve that equation, unless I'm missing something? Any suggestions?","Question Find the point where the curves $$\tag 1y = x^3 -3x + 4$$ and $$\tag 2 y = 3x^2 - 3x$$ are tangent to each other, that is, have a common tangent line. My approach Let $x = a$ and $x = b$ be the points on curves $(1)$ and $(2)$, respectively, at which their slopes are equal and share a mutual tangent line. Now I will relate the $a$ and $b$ by equating the derivatives of $(1)$ at $a$ and $(2)$ at $b$, as follows $$3a^2 - 3 = 6b- 3 \Leftrightarrow b = \frac{a^2}{2}$$ Let $A$ be the point on curve $(1)$ and $B$ be the point on curve $(2)$ where the two curves share the mutual tangent, that is $$A(a, x^3 - 3x + 4)$$ and $$B(b, 3b^2 - 3b) = B\Big(\frac{a^2}{2}, \frac{3a^4 - 6a^2}{4}\Big)$$ Now, since I have two points on the tangent line, I can calculate the slope and equate it to the derivative of $(1)$ at $a$ as follows  $$\frac{(x^3 - 3x + 4) - \Big(\frac{3a^4 - 6a^2}{4}\Big)}{a -  \frac{a^2}{2}} = 3a^2 - 3$$ Simplifying that equation I get the following, $$3a^4 -8a^3  - 12a^2 + 16 = 0$$ Now, I would solve for $a$ and then substitute the value of $a$ in to points $A$ and $B$ which would then be the points at which the two curves have a common tangent line. The problem is that I doubt I should be solving such an equation, and quite frankly, I don't have the tools to solve that equation, unless I'm missing something? Any suggestions?",,"['calculus', 'derivatives']"
28,Prove $\sin(x)< x$ when $x>0$ using LMVT,Prove  when  using LMVT,\sin(x)< x x>0,"According to Lagrange's Mean Value Theorem (LMVT), if a function $f(x)$ is continuous on $\left[a,b\right]$ and differentiable on $\left(a,b\right)$, then there exists some constant $c$ such that  $$f'(c) = \frac{f(b) - f(a)}{b-a} $$ Now, I have the following question: Q) Using Lagrange's Mean value theorem, prove that $\sin(x) < x$ for $x > 0$. This fact seems obvious from the graph of $\sin(x)$ and it's unit circle interpretation but I have no clue how I'd use LMVT to prove it. Any hints on how to start?","According to Lagrange's Mean Value Theorem (LMVT), if a function $f(x)$ is continuous on $\left[a,b\right]$ and differentiable on $\left(a,b\right)$, then there exists some constant $c$ such that  $$f'(c) = \frac{f(b) - f(a)}{b-a} $$ Now, I have the following question: Q) Using Lagrange's Mean value theorem, prove that $\sin(x) < x$ for $x > 0$. This fact seems obvious from the graph of $\sin(x)$ and it's unit circle interpretation but I have no clue how I'd use LMVT to prove it. Any hints on how to start?",,"['calculus', 'trigonometry', 'inequality', 'derivatives']"
29,I am having problems figuring out how to derive this.,I am having problems figuring out how to derive this.,,"I have the function $$\tag{1} f(x)=\ln\sqrt{8+\cos^2x}$$ So we derive it as follows: $$\tag{2} f(x)=\ln(8+\cos^2x)^\frac{1}{2}$$ $$\tag{3} f(x)=\frac{1}{2}\ln(8+\cos^2x)$$ $$\tag{4} f'(x)=\frac{1}{2}\left[\frac{-2 \cos x{\sin x}}{8+\cos^2x}\right]$$ $$\tag{5} f'(x)=\left[\frac{-\cos x{\sin x}}{8+\cos ^2x}\right]$$ I'm having problems with everything after step 2, a step by step explanation would be greatly appreciated. Thanks. For example where does the sin come from and why is there a cos in the numerator now. A detailed process  of beginning to end of solving this (what laws are used and why etc..) would be greatly appreciated. Here is the image of the website and how it goes about doing the steps, I thought it's be better for me to try and type it out unless anybody is curious. !","I have the function So we derive it as follows: I'm having problems with everything after step 2, a step by step explanation would be greatly appreciated. Thanks. For example where does the sin come from and why is there a cos in the numerator now. A detailed process  of beginning to end of solving this (what laws are used and why etc..) would be greatly appreciated. Here is the image of the website and how it goes about doing the steps, I thought it's be better for me to try and type it out unless anybody is curious. !",\tag{1} f(x)=\ln\sqrt{8+\cos^2x} \tag{2} f(x)=\ln(8+\cos^2x)^\frac{1}{2} \tag{3} f(x)=\frac{1}{2}\ln(8+\cos^2x) \tag{4} f'(x)=\frac{1}{2}\left[\frac{-2 \cos x{\sin x}}{8+\cos^2x}\right] \tag{5} f'(x)=\left[\frac{-\cos x{\sin x}}{8+\cos ^2x}\right],"['calculus', 'trigonometry', 'derivatives']"
30,Negative exponents when multiplying polynomials,Negative exponents when multiplying polynomials,,$$(4-t)(1+t^2)^{-1}$$ I am supposed to find the derivative of this but I am not sure if it means $$\frac{1}{(4-t)(1+t^2)^{-1}}\quad\text{or}\quad\frac{(4-t)}{(1+t^2)}$$ I have tried to look online for help but couldn't find an example that looked like this. I am assuming that the second one is the correct one but I just wanted to make sure.,$$(4-t)(1+t^2)^{-1}$$ I am supposed to find the derivative of this but I am not sure if it means $$\frac{1}{(4-t)(1+t^2)^{-1}}\quad\text{or}\quad\frac{(4-t)}{(1+t^2)}$$ I have tried to look online for help but couldn't find an example that looked like this. I am assuming that the second one is the correct one but I just wanted to make sure.,,"['calculus', 'derivatives', 'rational-functions']"
31,Derivative of $\sqrt{\sin (x^2)}$,Derivative of,\sqrt{\sin (x^2)},"I have problems calculating derivative of $f(x)=\sqrt{\sin (x^2)}$. I know that $f'(\sqrt{2k \pi + \pi})= - \infty$ and $f'(\sqrt{2k \pi})= + \infty$ because $f$ has derivative only if $ \sqrt{2k \pi} \leq |x| \leq \sqrt{2k \pi + \pi}$. The answer says that for all other values of $x$,  $f'(0-)=-1$ and $f'(0+)=1$. Why is that? All I get is $f'(x)= \dfrac{x \cos x^2}{\sqrt{\sin (x^2)}} $.","I have problems calculating derivative of $f(x)=\sqrt{\sin (x^2)}$. I know that $f'(\sqrt{2k \pi + \pi})= - \infty$ and $f'(\sqrt{2k \pi})= + \infty$ because $f$ has derivative only if $ \sqrt{2k \pi} \leq |x| \leq \sqrt{2k \pi + \pi}$. The answer says that for all other values of $x$,  $f'(0-)=-1$ and $f'(0+)=1$. Why is that? All I get is $f'(x)= \dfrac{x \cos x^2}{\sqrt{\sin (x^2)}} $.",,"['calculus', 'derivatives']"
32,Find $\lambda\in\mathbb{R}$ such that $y=e^x$ and $y=\lambda x^2$ touch.,Find  such that  and  touch.,\lambda\in\mathbb{R} y=e^x y=\lambda x^2,"Find $\lambda\in\mathbb{R}$ such that $y=e^x$ and $y=\lambda x^2$ touch. I'm just a beginner on derivatives, and I guess it should be done using them, but I'm totally stuck. (I guess it's not ""touch"" in English but oh well.)","Find $\lambda\in\mathbb{R}$ such that $y=e^x$ and $y=\lambda x^2$ touch. I'm just a beginner on derivatives, and I guess it should be done using them, but I'm totally stuck. (I guess it's not ""touch"" in English but oh well.)",,['derivatives']
33,Derivative of $f(x)=80-5x^2$,Derivative of,f(x)=80-5x^2,"Ok, I am going through the MIT Open Course ware course on single variable calculus. I have never taken calculus before, so I apologize of this is a really trivial question. I know that with $f(x)=x^n$ then $f'(x)=nx^{n-1}$. Without using this trick and fully working it out I can't seem to come to the derivative of $f(x)=80-5x^2$. I basically boil it down to $(-5/dx)(x+dx)(x+dx)$. I cannot seem to get $dx$ out of the denominator so that I don't have a division by zero as $dx$ tends to 0... Am I brain farting something here or is this why I should just skip to the aforementioned shortcut?","Ok, I am going through the MIT Open Course ware course on single variable calculus. I have never taken calculus before, so I apologize of this is a really trivial question. I know that with $f(x)=x^n$ then $f'(x)=nx^{n-1}$. Without using this trick and fully working it out I can't seem to come to the derivative of $f(x)=80-5x^2$. I basically boil it down to $(-5/dx)(x+dx)(x+dx)$. I cannot seem to get $dx$ out of the denominator so that I don't have a division by zero as $dx$ tends to 0... Am I brain farting something here or is this why I should just skip to the aforementioned shortcut?",,"['calculus', 'derivatives']"
34,Chain rule mismatch,Chain rule mismatch,,Let $$ g\bigl(h(t)\bigr) = \cos(\sqrt{t}) $$ and $$ g(t) = \cos(t)  $$ and $$ h(t) = \sqrt{t}. $$ Verify that $$ \frac{dg}{dh} = \frac{\;\frac{dg}{dt}\;}{\frac{dh}{dt}}. $$ I tried doing this but I got $$ \frac{dg}{dh} = -\sin(\sqrt{t}) \cdot \frac{1}{2\sqrt{t}} $$ but that is not equal to $$ \frac{\frac{dg}{dt}}{\frac{dh}{dt}} = -2\sin(t) \cdot \sqrt{t} $$ Where did I make a mistake? Edit: I see the mistake but I tried another method and I don't know why that is wrong. $$\frac{dg}{dh}=-sin\left(h\right)\cdot \frac{dh}{dh}=-sin\left(\sqrt{t}\right)$$,Let and and Verify that I tried doing this but I got but that is not equal to Where did I make a mistake? Edit: I see the mistake but I tried another method and I don't know why that is wrong.,"
g\bigl(h(t)\bigr) = \cos(\sqrt{t})
 
g(t) = \cos(t) 
 
h(t) = \sqrt{t}.
 
\frac{dg}{dh} = \frac{\;\frac{dg}{dt}\;}{\frac{dh}{dt}}.
 
\frac{dg}{dh} = -\sin(\sqrt{t}) \cdot \frac{1}{2\sqrt{t}}
 
\frac{\frac{dg}{dt}}{\frac{dh}{dt}} = -2\sin(t) \cdot \sqrt{t}
 \frac{dg}{dh}=-sin\left(h\right)\cdot \frac{dh}{dh}=-sin\left(\sqrt{t}\right)","['calculus', 'derivatives', 'chain-rule']"
35,Proving that $\frac{1}{n^2} - \frac{1}{(n+1)^2} \approx \frac{2}{n^3}$ when $n$ is very large,Proving that  when  is very large,\frac{1}{n^2} - \frac{1}{(n+1)^2} \approx \frac{2}{n^3} n,"This is an example from Mathematical Methods in the Physical Sciences, 3e, by Mary L. Boas. My question is, \begin{equation} \frac{1}{n^2} - \frac{1}{(n+1)^2} \approx \frac{2}{n^3} \end{equation} can also be written as, \begin{equation}\frac{1}{(-n)^2} - \frac{1}{(n+1)^2} \approx \frac{2}{n^3} \end{equation} so that $\Delta n = dn = -n-(n+1) = -2n-1$ . For $f(n) = 1/n^2$ , $f'(n) = -2/n^3$ , and \begin{equation} df = d(\frac{1}{n^2}) = f'(n)dn \end{equation} \begin{equation} df = \frac{(2)(2n+1)}{n^3} \end{equation} Now, for very large $n$ , $2n+1 \approx 2n$ . Thus, \begin{equation} df = \frac{4}{n^2} \end{equation} But, $4/n^2$ is not approximately equal to $2/n^3$ (required ans.) even if $n$ is very large. So, please point out my mistake(s). Thanks in advance (;","This is an example from Mathematical Methods in the Physical Sciences, 3e, by Mary L. Boas. My question is, can also be written as, so that . For , , and Now, for very large , . Thus, But, is not approximately equal to (required ans.) even if is very large. So, please point out my mistake(s). Thanks in advance (;","\begin{equation}
\frac{1}{n^2} - \frac{1}{(n+1)^2} \approx \frac{2}{n^3}
\end{equation} \begin{equation}\frac{1}{(-n)^2} - \frac{1}{(n+1)^2} \approx \frac{2}{n^3} \end{equation} \Delta n = dn = -n-(n+1) = -2n-1 f(n) = 1/n^2 f'(n) = -2/n^3 \begin{equation}
df = d(\frac{1}{n^2}) = f'(n)dn
\end{equation} \begin{equation}
df = \frac{(2)(2n+1)}{n^3}
\end{equation} n 2n+1 \approx 2n \begin{equation}
df = \frac{4}{n^2}
\end{equation} 4/n^2 2/n^3 n","['derivatives', 'partial-differential-equations', 'partial-derivative']"
36,Two Periodic Functions with Period 1,Two Periodic Functions with Period 1,,"I am currently studying for a graduate exam and I came across the following question: Suppose that $f$ and $g$ are real-valued functions on $\mathbb{R}$ having period 1 and having continuous first derivatives. Prove that $f'(c) = g'(c)$ for some non-negative $c \in \mathbb{R}$ My initial approach to this problem was to use the mean value theorem for $f$ and $g$ to obtain certain values where both derivatives vanish. However, this did not prove effective in proving the desired result. Any suggestions on how to approach this problem would be greatly appreciated.","I am currently studying for a graduate exam and I came across the following question: Suppose that and are real-valued functions on having period 1 and having continuous first derivatives. Prove that for some non-negative My initial approach to this problem was to use the mean value theorem for and to obtain certain values where both derivatives vanish. However, this did not prove effective in proving the desired result. Any suggestions on how to approach this problem would be greatly appreciated.",f g \mathbb{R} f'(c) = g'(c) c \in \mathbb{R} f g,"['real-analysis', 'derivatives', 'periodic-functions']"
37,Function Analysis,Function Analysis,,"I tried to differentiate the function and set the value at =0 in order to find x in terms of a and b. Then, I also tried to plug the value of x into in and set the value of y into 1 and 4. At the end, I was struggling since it became more tedious. So anyone can suggest a nicer way to solve this? Thanks in advance","I tried to differentiate the function and set the value at =0 in order to find x in terms of a and b. Then, I also tried to plug the value of x into in and set the value of y into 1 and 4. At the end, I was struggling since it became more tedious. So anyone can suggest a nicer way to solve this? Thanks in advance",,"['calculus', 'derivatives', 'maxima-minima']"
38,"Is there a bounded, increasing elementary function with unbounded derivative?","Is there a bounded, increasing elementary function with unbounded derivative?",,"Is there an elementary function function $f(x)$ with the following properties: $f(x)$ is defined and infinitely differentiable on all of $\mathbb{R}$ $f(x)$ is bounded $f^\prime(x)$ is nonnegative and unbounded If we don't require $f(x)$ to be an elementary function, then we can take $$f(x)=\int_0^x\frac{t^2}{1+t^8\sin^2(\pi t)}\,dt$$ (the integrand is nonnegative, unbounded, but has finite area, desmos link ). This question can also be rephrased in terms of an unbounded probability mass function with elementary antiderivative.","Is there an elementary function function with the following properties: is defined and infinitely differentiable on all of is bounded is nonnegative and unbounded If we don't require to be an elementary function, then we can take (the integrand is nonnegative, unbounded, but has finite area, desmos link ). This question can also be rephrased in terms of an unbounded probability mass function with elementary antiderivative.","f(x) f(x) \mathbb{R} f(x) f^\prime(x) f(x) f(x)=\int_0^x\frac{t^2}{1+t^8\sin^2(\pi t)}\,dt","['calculus', 'derivatives', 'elementary-functions']"
39,Analysis question from a past exam paper,Analysis question from a past exam paper,,"Assume that $f \in C^1 [a,b].$ Prove that $$\forall \epsilon \  \exists \delta > 0 : \\ x, y \in [a,b] , |x-y| < \delta \implies \left\vert\frac{f(x)-f(y)}{x-y} - f'(x) \right\vert < \epsilon $$ I did he following proof and I wonder if its entirely correct as the question itself would have carried 10 % of a 2hr exam. Edit: edited the proof to make $\delta$ independent of $x$ Let $x,y \in [a,b]$ Since $f'$ is continuous on a compact set, then its uniformly continuous. Hence $\forall x,y \in [a,b], |x-y| < \delta \implies |f'(y)-f'(x)| < \epsilon $ By MVT, since $f \in C^1 [a,b], \ \exists c \in (x,y) : f'(c) = \frac{f(x)-f(y)}{x-y}$ . Thus in particular, $|x-c|<|x-y| < \delta \implies |f'(c)-f'(x)| < \epsilon $ and we're done.","Assume that Prove that I did he following proof and I wonder if its entirely correct as the question itself would have carried 10 % of a 2hr exam. Edit: edited the proof to make independent of Let Since is continuous on a compact set, then its uniformly continuous. Hence By MVT, since . Thus in particular, and we're done.","f \in C^1 [a,b]. \forall \epsilon \  \exists \delta > 0 : \\
x, y \in [a,b] , |x-y| < \delta \implies \left\vert\frac{f(x)-f(y)}{x-y} - f'(x) \right\vert < \epsilon  \delta x x,y \in [a,b] f' \forall x,y \in [a,b], |x-y| < \delta \implies |f'(y)-f'(x)| < \epsilon  f \in C^1 [a,b], \ \exists c \in (x,y) : f'(c) = \frac{f(x)-f(y)}{x-y} |x-c|<|x-y| < \delta \implies |f'(c)-f'(x)| < \epsilon ","['real-analysis', 'derivatives']"
40,"Find the slope of the graph of $xy-4y^2=2$ at $(9,2)$",Find the slope of the graph of  at,"xy-4y^2=2 (9,2)","Find the slope of the graph of $xy-4y^2=2$ at $(9,2)$ I will take the derivative with respect to $x$ , being careful to use implicit differentiation when differentiating a $y$ term, solving for $\frac{dy}{dx}$ ( $\frac{dy}{dx}$ is the slope!!) and then plugging in the point $(9,2)$ Solution: $\frac{d}{dx}(xy-4y^2)=\frac{d}{dx}2=0$ $(\frac{d}{dx}(xy)-4\frac{d}{dx}y^2)=0$ $(\frac{d}{dx}(xy)-4(2y\frac{dy}{dx})=0$ I will use the product rule to evaluate $\frac{d}{dx}(xy)$ : $((\frac{d}{dx}(x)y+x(\frac{d}{dx}y))-8y\frac{dy}{dx}=0$ $((1)y+x((1)\frac{dy}{dx}))-8y\frac{dy}{dx}=0$ $(y+x\frac{dy}{dx})-8y\frac{dy}{dx}=0$ $y+(x-8y)\frac{dy}{dx}=0$ $(x-8y)\frac{dy}{dx}=-y$ $\frac{dy}{dx}=\frac{-y}{(x-8y)}$ Cool, so now I've taken the derivative, was careful to use implicit differentiation when necessary, and solved for $\frac{dy}{dx}$ , which tells us the slope at any $(x,y)$ point that we plug in. The problem statements wants us to find the slope at $(9,2)$ , so let's plug that in!! $\frac{dy}{dx}=\frac{-2}{(9-8(2))}$ $\frac{dy}{dx}=\frac{-2}{9-16}$ $\frac{dy}{dx}=\frac{-2}{-7}$ $\frac{dy}{dx}=\frac{2}{7}$","Find the slope of the graph of at I will take the derivative with respect to , being careful to use implicit differentiation when differentiating a term, solving for ( is the slope!!) and then plugging in the point Solution: I will use the product rule to evaluate : Cool, so now I've taken the derivative, was careful to use implicit differentiation when necessary, and solved for , which tells us the slope at any point that we plug in. The problem statements wants us to find the slope at , so let's plug that in!!","xy-4y^2=2 (9,2) x y \frac{dy}{dx} \frac{dy}{dx} (9,2) \frac{d}{dx}(xy-4y^2)=\frac{d}{dx}2=0 (\frac{d}{dx}(xy)-4\frac{d}{dx}y^2)=0 (\frac{d}{dx}(xy)-4(2y\frac{dy}{dx})=0 \frac{d}{dx}(xy) ((\frac{d}{dx}(x)y+x(\frac{d}{dx}y))-8y\frac{dy}{dx}=0 ((1)y+x((1)\frac{dy}{dx}))-8y\frac{dy}{dx}=0 (y+x\frac{dy}{dx})-8y\frac{dy}{dx}=0 y+(x-8y)\frac{dy}{dx}=0 (x-8y)\frac{dy}{dx}=-y \frac{dy}{dx}=\frac{-y}{(x-8y)} \frac{dy}{dx} (x,y) (9,2) \frac{dy}{dx}=\frac{-2}{(9-8(2))} \frac{dy}{dx}=\frac{-2}{9-16} \frac{dy}{dx}=\frac{-2}{-7} \frac{dy}{dx}=\frac{2}{7}",['calculus']
41,What do the derivative and integral notations mean?,What do the derivative and integral notations mean?,,"I have only recently began studying calculus at school, so a non-technical answer would be greatly appreciated. While I understand the techniques for differentiation and integration, I still feel as if I don't understand why they work. Part of this bewilderment stems from the notation (and the language used to describe the notation). For example, $$ \frac{dy}{dx}(x^2+5)=2x $$ I have heard spoken aloud as ""the rate of change of y of $x^2+5$ with respect to $x$ is $2x$ "". I am not completely clear on what ""with respect to $x$ "" means, but I think it means that the derivative is telling you what the rate of change for each value of $x$ is. For example, when $x=5$ , the gradient is $10$ . If, however, you were looking at the derivative with respect to $y$ , then the gradient function would tell you what the gradient is for each $y$ -value. From what I understand, $\frac{dy}{dx}$ is also just a  shorthand for a more formal limit expression rather than a ratio: $$ \frac{dy}{dx}(f(x))=\lim\limits_{h\to0}\frac{f(x+h)-f(x)}{h} $$ However, while the notation for differentiation is somewhat intuitive, I still find the integral notation baffling: $$ \int f(x)dx=2x $$ Why is there no "" $dy$ "" in this notation, but there is one in the derivative notation? When the "" $dx$ "" is adjacent to the gradient function, what does it stand for? And what does the integral sign actually mean? I feel completely stuck, so it would be helpful if someone could walk me through the notation step-by-step.","I have only recently began studying calculus at school, so a non-technical answer would be greatly appreciated. While I understand the techniques for differentiation and integration, I still feel as if I don't understand why they work. Part of this bewilderment stems from the notation (and the language used to describe the notation). For example, I have heard spoken aloud as ""the rate of change of y of with respect to is "". I am not completely clear on what ""with respect to "" means, but I think it means that the derivative is telling you what the rate of change for each value of is. For example, when , the gradient is . If, however, you were looking at the derivative with respect to , then the gradient function would tell you what the gradient is for each -value. From what I understand, is also just a  shorthand for a more formal limit expression rather than a ratio: However, while the notation for differentiation is somewhat intuitive, I still find the integral notation baffling: Why is there no "" "" in this notation, but there is one in the derivative notation? When the "" "" is adjacent to the gradient function, what does it stand for? And what does the integral sign actually mean? I feel completely stuck, so it would be helpful if someone could walk me through the notation step-by-step.","
\frac{dy}{dx}(x^2+5)=2x
 x^2+5 x 2x x x x=5 10 y y \frac{dy}{dx} 
\frac{dy}{dx}(f(x))=\lim\limits_{h\to0}\frac{f(x+h)-f(x)}{h}
 
\int f(x)dx=2x
 dy dx","['calculus', 'integration', 'derivatives', 'notation', 'indefinite-integrals']"
42,"Use the Fundamental Theorem of Calculus to find the derivative of $h(x) = \int_{1}^{e^x} \ln (t) \,dt$",Use the Fundamental Theorem of Calculus to find the derivative of,"h(x) = \int_{1}^{e^x} \ln (t) \,dt","The fundamental theorem of calculus states: If $f$ is continuous on $[a,b]$ , then if $g(x) = \int_{a}^{x}f(t)\,dt,~ \textrm{then}~g'(x) = f(x)$ . In Example 4, the chain rule is used because the upper bound, $x^4$ needed to be differentiated. My question is, why is that and where is that implied given the theorem stated above? Similarly, find $h'(x)$ of $h(x) = \int_{1}^{e^x} \ln(t)\,dt$ The answer is $h'(x) = xe^x$ , which seems to be in line with Example 4. Per previous examples in the book, one might expect the answer to be $h'(x) = \ln(e^x)$ though.","The fundamental theorem of calculus states: If is continuous on , then if . In Example 4, the chain rule is used because the upper bound, needed to be differentiated. My question is, why is that and where is that implied given the theorem stated above? Similarly, find of The answer is , which seems to be in line with Example 4. Per previous examples in the book, one might expect the answer to be though.","f [a,b] g(x) = \int_{a}^{x}f(t)\,dt,~ \textrm{then}~g'(x) = f(x) x^4 h'(x) h(x) = \int_{1}^{e^x} \ln(t)\,dt h'(x) = xe^x h'(x) = \ln(e^x)","['calculus', 'derivatives', 'definite-integrals']"
43,Equation of secant line in mean value theorem proof,Equation of secant line in mean value theorem proof,,"I'm going through a proof for the mean value theorem. We have a function $f(x)$ continuous on $[a, b]$ and differentiable on $(a, b)$ . Then we define a function $g(x)$ to be the secant line passing through $(a, f(a))$ and $(b, f(b))$ . The slope of said secant is: $$m=\frac{f(b)-f(a)}{b-a}$$ That is clear. Now the proof I'm following defines $g(x)$ like so: $$g(x) = \left[  \frac{f(b)-f(a)}{b-a} \right](x-a)+f(a)$$ What confuses me: why is the coefficient defined to be $(x-a)$ and not simply $(x)$ .",I'm going through a proof for the mean value theorem. We have a function continuous on and differentiable on . Then we define a function to be the secant line passing through and . The slope of said secant is: That is clear. Now the proof I'm following defines like so: What confuses me: why is the coefficient defined to be and not simply .,"f(x) [a, b] (a, b) g(x) (a, f(a)) (b, f(b)) m=\frac{f(b)-f(a)}{b-a} g(x) g(x) = \left[  \frac{f(b)-f(a)}{b-a} \right](x-a)+f(a) (x-a) (x)","['calculus', 'derivatives', 'proof-explanation']"
44,Differentiability of a singleton set,Differentiability of a singleton set,,Let $f$ be a function $ f:\{2\} \rightarrow\mathbb R$. Now absolutely $f$ is continuous. But what we can say about the differentiability of the function $f$ at $x=2$ ?,Let $f$ be a function $ f:\{2\} \rightarrow\mathbb R$. Now absolutely $f$ is continuous. But what we can say about the differentiability of the function $f$ at $x=2$ ?,,"['real-analysis', 'derivatives', 'absolute-continuity']"
45,why do we use the hyperbolic functions? [duplicate],why do we use the hyperbolic functions? [duplicate],,"This question already has answers here : Real world uses of hyperbolic trigonometric functions (10 answers) Closed 6 years ago . The first time I knew about the hyperbolic function was when I was studying the derivatives. And I know that the derivative of   $\sinh x=  ( e^x - e^{-x} )/ 2$ , but i still confused with what are they really are? and how did we get them and for what we are using them? Thanks very much, and i hope that wasn't a long question.","This question already has answers here : Real world uses of hyperbolic trigonometric functions (10 answers) Closed 6 years ago . The first time I knew about the hyperbolic function was when I was studying the derivatives. And I know that the derivative of   $\sinh x=  ( e^x - e^{-x} )/ 2$ , but i still confused with what are they really are? and how did we get them and for what we are using them? Thanks very much, and i hope that wasn't a long question.",,"['calculus', 'derivatives']"
46,"Let $f(x)$ be a differential real function defined on the real line. If $f(0)=0$ and $f'(x)=[f(x)]^2$, then $f(x)=0$ foi any $x$.","Let  be a differential real function defined on the real line. If  and , then  foi any .",f(x) f(0)=0 f'(x)=[f(x)]^2 f(x)=0 x,"Again, $f:\mathbb{R}\to\mathbb{R}$ is differentiable, $f(0)=0$, and $f'(x)=[f(x)]^2$ for every $x$. A friend suggested the following argument: If exists $c$ such that $f(c)\neq0$, there exists an interval $I$ around $c$ such that $f(x)\neq0$ if $x\in I$ (because $f$ is continuous since it is differentiable). In that interval, we could define $g(x)=x+\frac{1}{f(x)}$. This function $g$ would be differentiable and $g'(x)=0$. Then $g(x)$ is constant, for example, $k$. Then, $f(x)=\frac{1}{k-x}$ for $x\in I$ But I don't know where to find an absurd. What should I do next? I think I should use the fundamental theorem of calculus and try to find an absurd with $f(x)=\int_0^x f'(t)dt=\int_0^x [f(t)]^2 dt$, but I also didn't got anywhere. Thanks in advance.","Again, $f:\mathbb{R}\to\mathbb{R}$ is differentiable, $f(0)=0$, and $f'(x)=[f(x)]^2$ for every $x$. A friend suggested the following argument: If exists $c$ such that $f(c)\neq0$, there exists an interval $I$ around $c$ such that $f(x)\neq0$ if $x\in I$ (because $f$ is continuous since it is differentiable). In that interval, we could define $g(x)=x+\frac{1}{f(x)}$. This function $g$ would be differentiable and $g'(x)=0$. Then $g(x)$ is constant, for example, $k$. Then, $f(x)=\frac{1}{k-x}$ for $x\in I$ But I don't know where to find an absurd. What should I do next? I think I should use the fundamental theorem of calculus and try to find an absurd with $f(x)=\int_0^x f'(t)dt=\int_0^x [f(t)]^2 dt$, but I also didn't got anywhere. Thanks in advance.",,"['real-analysis', 'derivatives']"
47,"""Good"" linear approximation criteria?","""Good"" linear approximation criteria?",,"I've been told that linear approximation is considered as ""good"" if it meets the criteria below: $$\lim_{x \to a} \frac{f(x)-f(a)-f'(a)(x-a)}{x-a} = 0$$ As far as I understand, the differentiation of $f(x)$ suppose to provide such a good approximation? So I wrote a simple script testing out $f = x^2$ at the $a = 2$. Thus following sequence expected to be infinitely small: $$\lim_{x \to 2}\frac{x^2 - 4x - 12}{x - 2}$$ Now let me publish some bits of computation done by my machine: [""f(2.0001) = -160000""; ""f(2.0002) = -80000""; ""f(2.0003) = -53333.3"";      ""f(2.0004) = -40000""; ""f(2.0005) = -32000""; ""f(2.0006) = -26666.7"";      ""f(2.0007) = -22857.1""; ""f(2.0008) = -20000""; ""f(2.0009) = -17777.8"";      ""f(2.001) = -16000""; ""f(2.0011) = -14545.5""; ""f(2.0012) = -13333.3"";      ""f(2.0013) = -12307.7""; ""f(2.0014) = -11428.6""; ""f(2.0015) = -10666.7"";      ""f(2.0016) = -10000""; ""f(2.0017) = -9411.76""; ""f(2.0018) = -8888.89"";      ""f(2.0019) = -8421.05""; ""f(2.002) = -8000""; ""f(2.0021) = -7619.05"";      ""f(2.0022) = -7272.73""; ""f(2.0023) = -6956.52""; ""f(2.0024) = -6666.66"";      ""f(2.0025) = -6400""; ""f(2.0026) = -6153.84""; ""f(2.0027) = -5925.92"";      ""f(2.0028) = -5714.28""; ""f(2.0029) = -5517.24""; ""f(2.003) = -5333.33"";      ""f(2.0031) = -5161.29""; ""f(2.0032) = -5000""; ""f(2.0033) = -4848.48"";      ""f(2.0034) = -4705.88""; ""f(2.0035) = -4571.43""; ""f(2.0036) = -4444.44"";      ""f(2.0037) = -4324.32""; ""f(2.0038) = -4210.52""; ""f(2.0039) = -4102.56"";      ""f(2.004) = -4000""; ""f(2.0041) = -3902.43""; ""f(2.0042) = -3809.52"";      ""f(2.0043) = -3720.93""; ""f(2.0044) = -3636.36""; ""f(2.0045) = -3555.55"";      ""f(2.0046) = -3478.26""; ""f(2.0047) = -3404.25""; ""f(2.0048) = -3333.33"";      ""f(2.0049) = -3265.3""] From the result above clearly seen: the closer $x$ gets to the $a = 2$, the bigger output. How I suppose to interpret such a result?  Did I do a mistake? Did I misunderstand the ""good linear approximation"" concept? Did I broke math?","I've been told that linear approximation is considered as ""good"" if it meets the criteria below: $$\lim_{x \to a} \frac{f(x)-f(a)-f'(a)(x-a)}{x-a} = 0$$ As far as I understand, the differentiation of $f(x)$ suppose to provide such a good approximation? So I wrote a simple script testing out $f = x^2$ at the $a = 2$. Thus following sequence expected to be infinitely small: $$\lim_{x \to 2}\frac{x^2 - 4x - 12}{x - 2}$$ Now let me publish some bits of computation done by my machine: [""f(2.0001) = -160000""; ""f(2.0002) = -80000""; ""f(2.0003) = -53333.3"";      ""f(2.0004) = -40000""; ""f(2.0005) = -32000""; ""f(2.0006) = -26666.7"";      ""f(2.0007) = -22857.1""; ""f(2.0008) = -20000""; ""f(2.0009) = -17777.8"";      ""f(2.001) = -16000""; ""f(2.0011) = -14545.5""; ""f(2.0012) = -13333.3"";      ""f(2.0013) = -12307.7""; ""f(2.0014) = -11428.6""; ""f(2.0015) = -10666.7"";      ""f(2.0016) = -10000""; ""f(2.0017) = -9411.76""; ""f(2.0018) = -8888.89"";      ""f(2.0019) = -8421.05""; ""f(2.002) = -8000""; ""f(2.0021) = -7619.05"";      ""f(2.0022) = -7272.73""; ""f(2.0023) = -6956.52""; ""f(2.0024) = -6666.66"";      ""f(2.0025) = -6400""; ""f(2.0026) = -6153.84""; ""f(2.0027) = -5925.92"";      ""f(2.0028) = -5714.28""; ""f(2.0029) = -5517.24""; ""f(2.003) = -5333.33"";      ""f(2.0031) = -5161.29""; ""f(2.0032) = -5000""; ""f(2.0033) = -4848.48"";      ""f(2.0034) = -4705.88""; ""f(2.0035) = -4571.43""; ""f(2.0036) = -4444.44"";      ""f(2.0037) = -4324.32""; ""f(2.0038) = -4210.52""; ""f(2.0039) = -4102.56"";      ""f(2.004) = -4000""; ""f(2.0041) = -3902.43""; ""f(2.0042) = -3809.52"";      ""f(2.0043) = -3720.93""; ""f(2.0044) = -3636.36""; ""f(2.0045) = -3555.55"";      ""f(2.0046) = -3478.26""; ""f(2.0047) = -3404.25""; ""f(2.0048) = -3333.33"";      ""f(2.0049) = -3265.3""] From the result above clearly seen: the closer $x$ gets to the $a = 2$, the bigger output. How I suppose to interpret such a result?  Did I do a mistake? Did I misunderstand the ""good linear approximation"" concept? Did I broke math?",,"['calculus', 'derivatives', 'linear-approximation']"
48,Solve for $\frac{dy}{dx}$ if $x = y \ln (xy)$,Solve for  if,\frac{dy}{dx} x = y \ln (xy),"Solve for $\frac{dy}{dx}$: $x = y \ln (xy)$ The first idea to solve this that springs to my mind is, of course, to apply implicit differentiation, but this is not an obvious function and so I got stuck. I simply don't know how to tackle this. Because, if I take the derivative with respect to $x$ of both sides, I get $$1 = \frac{d}{dx}[y\ln(xy)] = \frac{d}{dx}[y]\ln(xy)+y\frac{d}{dx}[\ln(xy)] = \frac{dy}{dx}[\ln(xy)] + y\frac{dy}{dx}[\ln(xy)] \\  2 \frac{dy}{dx}[\ln(xy)] = 1 \iff \frac{dy}{dx} = \frac{1}{2\ln(xy)}$$ Is it the right way to solve this?","Solve for $\frac{dy}{dx}$: $x = y \ln (xy)$ The first idea to solve this that springs to my mind is, of course, to apply implicit differentiation, but this is not an obvious function and so I got stuck. I simply don't know how to tackle this. Because, if I take the derivative with respect to $x$ of both sides, I get $$1 = \frac{d}{dx}[y\ln(xy)] = \frac{d}{dx}[y]\ln(xy)+y\frac{d}{dx}[\ln(xy)] = \frac{dy}{dx}[\ln(xy)] + y\frac{dy}{dx}[\ln(xy)] \\  2 \frac{dy}{dx}[\ln(xy)] = 1 \iff \frac{dy}{dx} = \frac{1}{2\ln(xy)}$$ Is it the right way to solve this?",,"['calculus', 'derivatives', 'implicit-differentiation']"
49,A Basic Inequality,A Basic Inequality,,"I want to show that $e^x \leq x + e^{x^2}$ for all $x \in \mathbb{R}$.  One can see that if $x \geq 1$ then $e^{x^2}$ dominates $e^x$.  A Taylor expansion argument of the derivative followed by term by term comparison handles the rest, but I'm curious if there is a more unified way to prove this inequality without resorting to cases.","I want to show that $e^x \leq x + e^{x^2}$ for all $x \in \mathbb{R}$.  One can see that if $x \geq 1$ then $e^{x^2}$ dominates $e^x$.  A Taylor expansion argument of the derivative followed by term by term comparison handles the rest, but I'm curious if there is a more unified way to prove this inequality without resorting to cases.",,"['calculus', 'derivatives', 'inequality', 'exponential-function']"
50,Derivatives of trigonometric functions: $y= \frac{x \sin(x)}{1+\cos(x)}$,Derivatives of trigonometric functions:,y= \frac{x \sin(x)}{1+\cos(x)},I'm trying to find the derivative of: $$y= \frac{x \sin(x)}{1+\cos(x)}$$ I've tried but I can't achieve the simplified form - Here's my try- $$y' =  \left(\frac{x \sin(x)}{1+\cos(x)}\right)'$$ $$y' = \frac{x\sin^2(x) + (\cos(x)+1 )(\sin(x)+x\cos(x))}{(\cos(x)+1)^2}$$ I'm pretty sure the above is correct that is why I didn't show the steps in between ... but I can't simplify it until - $$\frac{x+\sin(x)}{1+\cos(x)}$$ Which concept or formula am I missing out from in order to simplify it further? Or what should I do next? Thanks!,I'm trying to find the derivative of: I've tried but I can't achieve the simplified form - Here's my try- I'm pretty sure the above is correct that is why I didn't show the steps in between ... but I can't simplify it until - Which concept or formula am I missing out from in order to simplify it further? Or what should I do next? Thanks!,y= \frac{x \sin(x)}{1+\cos(x)} y' =  \left(\frac{x \sin(x)}{1+\cos(x)}\right)' y' = \frac{x\sin^2(x) + (\cos(x)+1 )(\sin(x)+x\cos(x))}{(\cos(x)+1)^2} \frac{x+\sin(x)}{1+\cos(x)},"['calculus', 'trigonometry', 'derivatives']"
51,Can we say : $f(x)$ is differentiable at $x=a$ $\Leftrightarrow $ $f'(x)$ is continuous at $x=a$ ? Why NOT?,Can we say :  is differentiable at    is continuous at  ? Why NOT?,f(x) x=a \Leftrightarrow  f'(x) x=a,"'$\Leftrightarrow$' Is very much important in this question . Actually, it seems very obvious to me. We say a function is differentiable at $x=a$ iff $\lim_{ h\rightarrow 0 }{ \frac { f(a+h)-f(a) }{ h }  } = lim_{ h\rightarrow 0 }{ \frac { f(a-h)-f(a) }{ -h }  }$ Now, let $f'(x)=g(x)$ If $f(x)$ is differentiable at $x=a$ , it means $f'(a^+)=f'(a^-)$ Which is nothing else $g(a^+)=g(a^-)$ i.e. $g(x)$ is continuous at $x=a$ $[$since $g(a)=f(a)=f'(a^-)=f'(a^+)=g(a^+)=g(a^-)]$ For those who agree with me, here comes a so called EXCEPTION function, $f(x) = \begin{cases} { x }^{ 2 }\cos { \frac { 1 }{ x }  } & \text{if} ~~~~ x\neq 0\\ 0 & \text{if} ~~~~ x=0 \end{cases}$ here $f'(0^+)=\lim_{ h\rightarrow 0 }{ \frac { { h }^{ 2 }\cos { \frac { 1 }{ h }  }-0 }{ h }  } = 0$ and $f'(0^-)=\lim_{ h\rightarrow 0 }{ \frac { { -h }^{ 2 }\cos { \frac { 1 }{ -h }  }-0 }{ -h }  } = 0$ Since $f'(0^+)=f'(0^-)=0$ , $f(x)$ is well differentiable at $x=0$ Now take a look at the following $f'(x) = g(x) = sin(\frac 1x)+2xcos(\frac 1x)$ Whoa! , here $\lim_{ x\rightarrow 0 }{g(x)} = \lim_{ x\rightarrow 0 }{sin(\frac 1h)}$ = Oscillatory Value! This suggests that $g(x)$ is not continuous at $x=0$ i.e. $f(x)$ is not differentiable at $x=0$ Why So ? Any help will be appreciated.","'$\Leftrightarrow$' Is very much important in this question . Actually, it seems very obvious to me. We say a function is differentiable at $x=a$ iff $\lim_{ h\rightarrow 0 }{ \frac { f(a+h)-f(a) }{ h }  } = lim_{ h\rightarrow 0 }{ \frac { f(a-h)-f(a) }{ -h }  }$ Now, let $f'(x)=g(x)$ If $f(x)$ is differentiable at $x=a$ , it means $f'(a^+)=f'(a^-)$ Which is nothing else $g(a^+)=g(a^-)$ i.e. $g(x)$ is continuous at $x=a$ $[$since $g(a)=f(a)=f'(a^-)=f'(a^+)=g(a^+)=g(a^-)]$ For those who agree with me, here comes a so called EXCEPTION function, $f(x) = \begin{cases} { x }^{ 2 }\cos { \frac { 1 }{ x }  } & \text{if} ~~~~ x\neq 0\\ 0 & \text{if} ~~~~ x=0 \end{cases}$ here $f'(0^+)=\lim_{ h\rightarrow 0 }{ \frac { { h }^{ 2 }\cos { \frac { 1 }{ h }  }-0 }{ h }  } = 0$ and $f'(0^-)=\lim_{ h\rightarrow 0 }{ \frac { { -h }^{ 2 }\cos { \frac { 1 }{ -h }  }-0 }{ -h }  } = 0$ Since $f'(0^+)=f'(0^-)=0$ , $f(x)$ is well differentiable at $x=0$ Now take a look at the following $f'(x) = g(x) = sin(\frac 1x)+2xcos(\frac 1x)$ Whoa! , here $\lim_{ x\rightarrow 0 }{g(x)} = \lim_{ x\rightarrow 0 }{sin(\frac 1h)}$ = Oscillatory Value! This suggests that $g(x)$ is not continuous at $x=0$ i.e. $f(x)$ is not differentiable at $x=0$ Why So ? Any help will be appreciated.",,"['calculus', 'real-analysis', 'derivatives', 'continuity']"
52,"Does $f'(x_0)>0$ imply $f$ is increasing in $(x_0-\delta, x_0+\delta)$?",Does  imply  is increasing in ?,"f'(x_0)>0 f (x_0-\delta, x_0+\delta)","Let $f$ be a function differentiable in $x_0 \in \mathbb{R}$ (and its neighborhood) and $f'(x_0)>0$. Does this imply that there exists a $\delta>0$ for which $f$ is increasing in $(x_0-\delta, x_0+\delta)$? My intuition is that since the condition is $f'(x_0)>0$ and not $f'(x_0)\ge0$, there is a neighborhood in which the derivative stays positive, and the answer to the question would be “yes”. Is this correct? If so, how could I write it down more formally?","Let $f$ be a function differentiable in $x_0 \in \mathbb{R}$ (and its neighborhood) and $f'(x_0)>0$. Does this imply that there exists a $\delta>0$ for which $f$ is increasing in $(x_0-\delta, x_0+\delta)$? My intuition is that since the condition is $f'(x_0)>0$ and not $f'(x_0)\ge0$, there is a neighborhood in which the derivative stays positive, and the answer to the question would be “yes”. Is this correct? If so, how could I write it down more formally?",,"['real-analysis', 'derivatives']"
53,Product rule for Hadamard product differentation?,Product rule for Hadamard product differentation?,,"Is there a ""simple"" solution to $\bf \frac{\partial}{\partial w}\big(w \odot f(w)\big)$ assuming the matrix $\bf \frac{\partial f}{\partial w}$ is known? With simple I mean something like in the normal vector multiplication case $\bf \frac{\partial}{\partial w}\big(w^Tf(w)\big) = f(w) + \big[\frac{\partial f(w)}{\partial w}\big]^T w$ such that no other knowledge of $\bf f(w)$ is required.","Is there a ""simple"" solution to $\bf \frac{\partial}{\partial w}\big(w \odot f(w)\big)$ assuming the matrix $\bf \frac{\partial f}{\partial w}$ is known? With simple I mean something like in the normal vector multiplication case $\bf \frac{\partial}{\partial w}\big(w^Tf(w)\big) = f(w) + \big[\frac{\partial f(w)}{\partial w}\big]^T w$ such that no other knowledge of $\bf f(w)$ is required.",,"['derivatives', 'matrix-calculus', 'hadamard-product']"
54,"Examples of (not) uniformly continuous, non-differentiable, non-periodic functions","Examples of (not) uniformly continuous, non-differentiable, non-periodic functions",,"Let $I\subseteq\mathbb{R}$ and $f:I\to\mathbb{R}.$ $(0)$ If $f$ is discontinuous on $I$, then it is not uniformly continuous. $(1)$ Suppose $I$ is open and bounded. If $f$ is unbounded on $I$, then it is not uniformly continuous. Otherwise, let $I=(a,b)$. If we can extend $f$ to $[a,b]$ by continuity, i.e. define $f^*(x):=\begin{cases}\lim\limits_{x\to a^+} f(x) & x=a \\ f(x) & x\in(a,b)\\ \lim\limits_{x\to b^-}f(x) & x=b\end{cases},$ $f^*$ is continuous on its domain, which is compact, and thus uniformly continuous by Heine-Cantor's theorem. Hence, so it is on $(a,b)$. If, instead, at least one of the limits above does not exist, say as $x\to a^+$, then there exist real sequences $x_n, y_n\to a^+$ such that $\lvert f(x_n)-f(y_n)\rvert\not\to0,$ implying that $f$ is not uniformly continuous. $(2)$ If $I$ is closed and bounded, then it is compact: a trivial adaptation of $(1)$ applies. $(3)$ Suppose $I$ is open and unbounded, say $I=(a,\infty)$; in view of $(1)$, let $f(x)\underset{x\to a^+}\longrightarrow l\in\mathbb{R}.$    If $f(x)\underset{x\to\infty}\longrightarrow L\in\mathbb{R}$ then $f$ is u.c., because, by Heine-Cantor, so is its continuous extension $\overline{f}$ to $[a,\infty]\subset\overline{\mathbb{R}}$ (similarly as in $(1)$). Otherwise, let $f$ be differentiable. If $\limsup\limits_{x\to\infty}\lvert f'(x)\rvert= \infty$ then $f$ is not u.c. by the mean value theorem, whereas if $f'$ is bounded, $f$ is lipschitzian and thus the same theorem implies u.c. Finally, assume $f'$ is unbounded on $(a,b]$ (doesn't matter if not defined on some $(\alpha,\beta]\subseteq(a,b]$) and defined and bounded elsewhere. $f$ is u.c. on $(a,b]$ because so is $f^*$ on $[a,b]$ , as well as on $(b,\infty)$, due to being lipschitzian there. By the continuity of $f$ at $b$, it suffices to make $x\in(a,b]$    and $y\in(b,\infty)$ sufficiently close to $b$ in order to have them satisfy the condition of u.c. Therefore, we conclude $f$ is u.c. on $I$. $(4)$ If $I$ is closed and unbounded, a trivial adaptation of $(3)$ applies. So one may note that the only functions whose uniform continuity is really interesting to investigate, are the ones defined on an unbounded interval, being globally continuous, non-periodic and non-differentiable on an unbounded subinterval of their domain. Do we know such functions, both uniformly and not uniformly continuous?","Let $I\subseteq\mathbb{R}$ and $f:I\to\mathbb{R}.$ $(0)$ If $f$ is discontinuous on $I$, then it is not uniformly continuous. $(1)$ Suppose $I$ is open and bounded. If $f$ is unbounded on $I$, then it is not uniformly continuous. Otherwise, let $I=(a,b)$. If we can extend $f$ to $[a,b]$ by continuity, i.e. define $f^*(x):=\begin{cases}\lim\limits_{x\to a^+} f(x) & x=a \\ f(x) & x\in(a,b)\\ \lim\limits_{x\to b^-}f(x) & x=b\end{cases},$ $f^*$ is continuous on its domain, which is compact, and thus uniformly continuous by Heine-Cantor's theorem. Hence, so it is on $(a,b)$. If, instead, at least one of the limits above does not exist, say as $x\to a^+$, then there exist real sequences $x_n, y_n\to a^+$ such that $\lvert f(x_n)-f(y_n)\rvert\not\to0,$ implying that $f$ is not uniformly continuous. $(2)$ If $I$ is closed and bounded, then it is compact: a trivial adaptation of $(1)$ applies. $(3)$ Suppose $I$ is open and unbounded, say $I=(a,\infty)$; in view of $(1)$, let $f(x)\underset{x\to a^+}\longrightarrow l\in\mathbb{R}.$    If $f(x)\underset{x\to\infty}\longrightarrow L\in\mathbb{R}$ then $f$ is u.c., because, by Heine-Cantor, so is its continuous extension $\overline{f}$ to $[a,\infty]\subset\overline{\mathbb{R}}$ (similarly as in $(1)$). Otherwise, let $f$ be differentiable. If $\limsup\limits_{x\to\infty}\lvert f'(x)\rvert= \infty$ then $f$ is not u.c. by the mean value theorem, whereas if $f'$ is bounded, $f$ is lipschitzian and thus the same theorem implies u.c. Finally, assume $f'$ is unbounded on $(a,b]$ (doesn't matter if not defined on some $(\alpha,\beta]\subseteq(a,b]$) and defined and bounded elsewhere. $f$ is u.c. on $(a,b]$ because so is $f^*$ on $[a,b]$ , as well as on $(b,\infty)$, due to being lipschitzian there. By the continuity of $f$ at $b$, it suffices to make $x\in(a,b]$    and $y\in(b,\infty)$ sufficiently close to $b$ in order to have them satisfy the condition of u.c. Therefore, we conclude $f$ is u.c. on $I$. $(4)$ If $I$ is closed and unbounded, a trivial adaptation of $(3)$ applies. So one may note that the only functions whose uniform continuity is really interesting to investigate, are the ones defined on an unbounded interval, being globally continuous, non-periodic and non-differentiable on an unbounded subinterval of their domain. Do we know such functions, both uniformly and not uniformly continuous?",,"['real-analysis', 'derivatives', 'uniform-continuity']"
55,Multiplying A Coefficient by an Indexed Multiplier using Generating Functions,Multiplying A Coefficient by an Indexed Multiplier using Generating Functions,,"If I have a particular exponential generating function, $$G(x)=\sum_{n=0}^\infty a_n\frac{x^n}{n!}$$ then what would be the generating function for $$H(x)=\sum_{n=0}^\infty (n+1)a_n\frac{x^n}{n!}$$ in terms of $G(x)$?  I know that I can change it to $$H(x)=\sum_{n=0}^\infty na_n\frac{x^n}{n!}+\sum_{n=0}^\infty a_n\frac{x^n}{n!}=J(x)+G(x)$$ Now I know that  $$G'(x)=\sum_{n=0}^\infty na_n\frac{x^{n-1}}{n!}$$ and so $$H(x)=xG'(x)+G(x)$$ Is there a way to write $H$ without the derivative of $G$? I would like $H$ as a function in terms of strictly $G$, and without a $G'$ term.","If I have a particular exponential generating function, $$G(x)=\sum_{n=0}^\infty a_n\frac{x^n}{n!}$$ then what would be the generating function for $$H(x)=\sum_{n=0}^\infty (n+1)a_n\frac{x^n}{n!}$$ in terms of $G(x)$?  I know that I can change it to $$H(x)=\sum_{n=0}^\infty na_n\frac{x^n}{n!}+\sum_{n=0}^\infty a_n\frac{x^n}{n!}=J(x)+G(x)$$ Now I know that  $$G'(x)=\sum_{n=0}^\infty na_n\frac{x^{n-1}}{n!}$$ and so $$H(x)=xG'(x)+G(x)$$ Is there a way to write $H$ without the derivative of $G$? I would like $H$ as a function in terms of strictly $G$, and without a $G'$ term.",,"['real-analysis', 'sequences-and-series', 'derivatives', 'generating-functions']"
56,How to differentiate this fraction $\frac{2}{x^2+3^3}$?,How to differentiate this fraction ?,\frac{2}{x^2+3^3},$\frac{2}{(x^2+3)^3}$. I have ${dy}/{dx}$ x 2 x ${x^2+3^3}$ - 2 x ${dy}/{dx}$  x ${x^2+3^3}$ over $({x^2+3)^6}$ And then simplifying to $-12x^5 + 36x^2$  over $({x^2+3)^6}$ I'm not sure if this is right.,$\frac{2}{(x^2+3)^3}$. I have ${dy}/{dx}$ x 2 x ${x^2+3^3}$ - 2 x ${dy}/{dx}$  x ${x^2+3^3}$ over $({x^2+3)^6}$ And then simplifying to $-12x^5 + 36x^2$  over $({x^2+3)^6}$ I'm not sure if this is right.,,"['calculus', 'derivatives']"
57,"Prove that if $f$ is zero at two points, then it is zero over the interval between them","Prove that if  is zero at two points, then it is zero over the interval between them",f,"Suppose $f$ satisfies $f''(x) + f'(x)g(x) - f(x) = 0$ for some function $g$. Prove that if $f$ is zero at two points, then it is zero over the interval between them. Let's suppose that $f(a) = f(b) = 0$ where $a<b$. Then using Rolles theorem, we know that there exists a $c$ such that $f'(c) = 0$ on $[a,b]$. Therefore, $f''(c) = f(c)$. Then how do I show that $f(x)=0$ on $[a,b]$?","Suppose $f$ satisfies $f''(x) + f'(x)g(x) - f(x) = 0$ for some function $g$. Prove that if $f$ is zero at two points, then it is zero over the interval between them. Let's suppose that $f(a) = f(b) = 0$ where $a<b$. Then using Rolles theorem, we know that there exists a $c$ such that $f'(c) = 0$ on $[a,b]$. Therefore, $f''(c) = f(c)$. Then how do I show that $f(x)=0$ on $[a,b]$?",,"['calculus', 'derivatives']"
58,$n$-th derivative of $\log(1+x)/x$,-th derivative of,n \log(1+x)/x,"What is the $n$-th derivative of  $$\frac{\log(1+x)}{x}$$ Now I have seen some analytical methods of getting $n$-th derivative of nicer looking functions such as the $n$-th derivative of  $$ 1\over 1+x $$ However, this is not the case for $$\frac{\log(1+x)}{x}$$","What is the $n$-th derivative of  $$\frac{\log(1+x)}{x}$$ Now I have seen some analytical methods of getting $n$-th derivative of nicer looking functions such as the $n$-th derivative of  $$ 1\over 1+x $$ However, this is not the case for $$\frac{\log(1+x)}{x}$$",,"['calculus', 'derivatives', 'logarithms']"
59,Showing that a derivable function $f$ (satisfying some conditions) is null.,Showing that a derivable function  (satisfying some conditions) is null.,f,"Enunciate: Let $f:\mathbb{R}\to\mathbb{R}$ derivable, such that $f(0)=0$ and, for all $x\in\mathbb{R}$, satisfy $f'(x)=(f(x))^2$. Prove that $f\equiv 0$. How can I prove it? I'm trying to integrate something in someway, but nothing that I tried works.","Enunciate: Let $f:\mathbb{R}\to\mathbb{R}$ derivable, such that $f(0)=0$ and, for all $x\in\mathbb{R}$, satisfy $f'(x)=(f(x))^2$. Prove that $f\equiv 0$. How can I prove it? I'm trying to integrate something in someway, but nothing that I tried works.",,"['real-analysis', 'integration', 'derivatives', 'riemann-integration']"
60,"Differentiation of power series, problem","Differentiation of power series, problem",,"I have the power series $$u(x) = \sum_{k=1}^{\infty} \frac{x^{2k+1}}{k(2k+1)} $$ with radius of convergence $R \geq 1 $ and I want to perform termwise derivation for $|x| \lt 1$, but it isn't working for me. Normally, I would rewrite $u(x)$ so that it is defined for $ k=0,1,2,...$ instead of $k=1,2,3,...$, and then use that $$u(x) = \sum_{k=0}^{\infty} a_k x^k \Rightarrow u'(x) = \sum_{k=1}^{\infty} ka_k x^{k-1}$$ but in this case that gives me $$u(x) = \sum_{k=0}^{\infty} \frac{x^{2k+3}}{(k+1)(2k+3)} \Rightarrow u'(x) = \sum_{k=1}^{\infty} \frac{kx^{2k+2}}{(k+1)(2k+3)}.$$ The answer is supposed to be $$u'(x) = \sum_{k=1}^{\infty} \frac{x^{2k}}{k}$$ but as you can see, I'm nowhere near close. What am I doing wrong?","I have the power series $$u(x) = \sum_{k=1}^{\infty} \frac{x^{2k+1}}{k(2k+1)} $$ with radius of convergence $R \geq 1 $ and I want to perform termwise derivation for $|x| \lt 1$, but it isn't working for me. Normally, I would rewrite $u(x)$ so that it is defined for $ k=0,1,2,...$ instead of $k=1,2,3,...$, and then use that $$u(x) = \sum_{k=0}^{\infty} a_k x^k \Rightarrow u'(x) = \sum_{k=1}^{\infty} ka_k x^{k-1}$$ but in this case that gives me $$u(x) = \sum_{k=0}^{\infty} \frac{x^{2k+3}}{(k+1)(2k+3)} \Rightarrow u'(x) = \sum_{k=1}^{\infty} \frac{kx^{2k+2}}{(k+1)(2k+3)}.$$ The answer is supposed to be $$u'(x) = \sum_{k=1}^{\infty} \frac{x^{2k}}{k}$$ but as you can see, I'm nowhere near close. What am I doing wrong?",,"['sequences-and-series', 'derivatives', 'power-series']"
61,Arcsin domain under differentiation,Arcsin domain under differentiation,,"according to my solutions manual, the derivative of: $$ f(x) = \arcsin \left(\frac{a}{x}\right)$$ is $$f'(x) = \frac{-a}{x\sqrt{x^2-a^2}}$$ however, my work on this problem has found this answer to be incomplete: Knowing that the arcsin() function has domain ($-1 \le x \le 1$), shouldn't the answer be: $$f'(x) = \frac{-a}{|x|\sqrt{x^2-a^2}}  ; \quad x \ne 0  ?$$ (Please note the absolute value function $|x|$ on the denominator instead of using only $x$ and that $x = 0$ is not in the domain)","according to my solutions manual, the derivative of: $$ f(x) = \arcsin \left(\frac{a}{x}\right)$$ is $$f'(x) = \frac{-a}{x\sqrt{x^2-a^2}}$$ however, my work on this problem has found this answer to be incomplete: Knowing that the arcsin() function has domain ($-1 \le x \le 1$), shouldn't the answer be: $$f'(x) = \frac{-a}{|x|\sqrt{x^2-a^2}}  ; \quad x \ne 0  ?$$ (Please note the absolute value function $|x|$ on the denominator instead of using only $x$ and that $x = 0$ is not in the domain)",,"['derivatives', 'trigonometry']"
62,Derivative of a Rotation Matrix w.r.t. an angle,Derivative of a Rotation Matrix w.r.t. an angle,,I am struggling with something that is probably really easy. I have the canonical rotation matrix w.r.t. only to a rotation around the z axis. I can't write the fornula because I am writing from my smartphone but the matrix is this one: I want to know how does it work if I want to make the derivative of the rotation matrix in the figure w.r.t. the angle $\alpha$. Is it just the derivative conponent by component ? Thanks for your help.,I am struggling with something that is probably really easy. I have the canonical rotation matrix w.r.t. only to a rotation around the z axis. I can't write the fornula because I am writing from my smartphone but the matrix is this one: I want to know how does it work if I want to make the derivative of the rotation matrix in the figure w.r.t. the angle $\alpha$. Is it just the derivative conponent by component ? Thanks for your help.,,"['calculus', 'linear-algebra', 'derivatives', 'matrix-equations', 'matrix-calculus']"
63,To find the nth Derivative of $9\sqrt{x}$,To find the nth Derivative of,9\sqrt{x},Can you help me to proof that the nth derivative of $9\sqrt{x}$ is $$ (-1)^{(n-1)} \cdot \frac{9(2n-2)!}{(n-1)!} \cdot (4x)^{\frac{1-2n}{2}}$$ I've tried induction but didn't go very far. Many thanks,Can you help me to proof that the nth derivative of $9\sqrt{x}$ is $$ (-1)^{(n-1)} \cdot \frac{9(2n-2)!}{(n-1)!} \cdot (4x)^{\frac{1-2n}{2}}$$ I've tried induction but didn't go very far. Many thanks,,"['calculus', 'derivatives']"
64,Tangent to the curve,Tangent to the curve,,"What is the equation of the tangent to the curve $$y = x^{1/3}$$ at the point $(0,0)$ ? This is a homework question. I tried solving it. The derivative comes out to be infinite at the given point. So, the equation should be $x=0$. Am I doing it the right way?","What is the equation of the tangent to the curve $$y = x^{1/3}$$ at the point $(0,0)$ ? This is a homework question. I tried solving it. The derivative comes out to be infinite at the given point. So, the equation should be $x=0$. Am I doing it the right way?",,"['calculus', 'derivatives', 'curves']"
65,How can $\frac{\mathrm{d}}{\mathrm{d}x}\left[y(u(x))\right] = \frac{\mathrm{d}y}{\mathrm{d}x}$?,How can ?,\frac{\mathrm{d}}{\mathrm{d}x}\left[y(u(x))\right] = \frac{\mathrm{d}y}{\mathrm{d}x},"I just saw a video on the chain rule, and it stated that $$\frac{\mathrm{d}}{\mathrm{d}x}\left[y(u(x))\right] = \frac{\mathrm{d}y}{\mathrm{d}x}$$ I don't understand this; if I let $y(x) = x^2$ and $u(x) = \sqrt x$ then $$\frac{\mathrm{d}y}{\mathrm{d}x} = 2x$$ and $$\frac{\mathrm{d}}{\mathrm{d}x}\left[y(u(x))\right] = \frac{\mathrm{d}}{\mathrm{d}x} \left[x\right] = 1$$ Clearly, I am completely misunderstanding something. What is it? EDIT: It is my understanding right now that $y(u(x)) = (\sqrt x)^2 = x$. Is this wrong?","I just saw a video on the chain rule, and it stated that $$\frac{\mathrm{d}}{\mathrm{d}x}\left[y(u(x))\right] = \frac{\mathrm{d}y}{\mathrm{d}x}$$ I don't understand this; if I let $y(x) = x^2$ and $u(x) = \sqrt x$ then $$\frac{\mathrm{d}y}{\mathrm{d}x} = 2x$$ and $$\frac{\mathrm{d}}{\mathrm{d}x}\left[y(u(x))\right] = \frac{\mathrm{d}}{\mathrm{d}x} \left[x\right] = 1$$ Clearly, I am completely misunderstanding something. What is it? EDIT: It is my understanding right now that $y(u(x)) = (\sqrt x)^2 = x$. Is this wrong?",,['derivatives']
66,Taking the derivative of $(1+x^2)^{(\sqrt{x})}$,Taking the derivative of,(1+x^2)^{(\sqrt{x})},"As stated above, I'm having trouble taking the derivative of $(1+x^2)^{(\sqrt{x})}$. I know that I should somehow be using the exponential derivative form of $\dfrac{d}{dx} ( a^x ) = a^x\ln(a)$, but I can't quite figure how the product rule comes into play. Any help would be much appreciated!!","As stated above, I'm having trouble taking the derivative of $(1+x^2)^{(\sqrt{x})}$. I know that I should somehow be using the exponential derivative form of $\dfrac{d}{dx} ( a^x ) = a^x\ln(a)$, but I can't quite figure how the product rule comes into play. Any help would be much appreciated!!",,"['calculus', 'derivatives']"
67,Why is the second derivative test inconclusive for some local max/mins?,Why is the second derivative test inconclusive for some local max/mins?,,"I know what the second derivative test is, when it is can be used, and when it can't.  So I am not asking any of those questions.  What I am asking is why we could have a local max at $c$, have $f'(c)=0$ yet have $f''(c)=0$.  I am looking for a graphical answer.  For instance, $x^4(x-1)^3$ has a local max at $x=0$.  However, $f''(0)=0$.  Whether I look at the definition of concave down which says the tangent lines around 0 should be above the graph or if I think of it as opening down at $x=0$, I feel like $f''(0)$ should be negative but it is not.","I know what the second derivative test is, when it is can be used, and when it can't.  So I am not asking any of those questions.  What I am asking is why we could have a local max at $c$, have $f'(c)=0$ yet have $f''(c)=0$.  I am looking for a graphical answer.  For instance, $x^4(x-1)^3$ has a local max at $x=0$.  However, $f''(0)=0$.  Whether I look at the definition of concave down which says the tangent lines around 0 should be above the graph or if I think of it as opening down at $x=0$, I feel like $f''(0)$ should be negative but it is not.",,"['calculus', 'derivatives']"
68,What Notation Do I Use To Fix Ambiguity Writing Chain Rule,What Notation Do I Use To Fix Ambiguity Writing Chain Rule,,I'm a calculus noob learning over the internet. I think the best way to ask my question is just to put up a little diagram I made in paint. Now this is my attempt to write the chain rule using d/dx notation: So my question is can I use d/dx notation and signify that I'm passing g(x) into the derivative of f(x) without ambiguity as to what I'm doing?,I'm a calculus noob learning over the internet. I think the best way to ask my question is just to put up a little diagram I made in paint. Now this is my attempt to write the chain rule using d/dx notation: So my question is can I use d/dx notation and signify that I'm passing g(x) into the derivative of f(x) without ambiguity as to what I'm doing?,,"['calculus', 'derivatives', 'notation']"
69,derivative if a piecewise function,derivative if a piecewise function,,"There is a piecewise function, $$ f(x)= \begin{cases} 0 & \text{if } x=0, \\ 1/x & \text{if } x \neq 0. \end{cases} $$ What is the derivative of this function at $x=0$  the txt says $+\infty$ but I don't get how. Can someone help me with this.","There is a piecewise function, $$ f(x)= \begin{cases} 0 & \text{if } x=0, \\ 1/x & \text{if } x \neq 0. \end{cases} $$ What is the derivative of this function at $x=0$  the txt says $+\infty$ but I don't get how. Can someone help me with this.",,"['calculus', 'derivatives']"
70,Finding the derivative of $\sqrt{x+\sqrt{x^2+5}}$,Finding the derivative of,\sqrt{x+\sqrt{x^2+5}},How to derive $y=\sqrt{x+\sqrt{x^2+5}}$ at $x=2$.I used logarithmic differentiation and chain rule over and over again but I can't get the right answer,How to derive $y=\sqrt{x+\sqrt{x^2+5}}$ at $x=2$.I used logarithmic differentiation and chain rule over and over again but I can't get the right answer,,['derivatives']
71,$ F(x) = \int_0^2 \sin(x+l)^2\ dl$,, F(x) = \int_0^2 \sin(x+l)^2\ dl,"Consider the function : $ F(x) =  \int_0^2 \sin(x+l)^2\ dl$, calculate $ \frac{dF(x)}{dx}|_{x=0}$ the derivative of $F(x)$ with respect to $x$ in zero. Let $g(x) = \sin (x)$ and $h(x) = (x+l)^2$ then $F(x) = \int_0^2 g(h(x))\ dl$, so $F´(x) = g(h(x)) h´(x)$  then I can evaluate this in $x=0$ , so $F´(0) = \sin{l^2} 2l $ is that correct? Some help to calculate this please.","Consider the function : $ F(x) =  \int_0^2 \sin(x+l)^2\ dl$, calculate $ \frac{dF(x)}{dx}|_{x=0}$ the derivative of $F(x)$ with respect to $x$ in zero. Let $g(x) = \sin (x)$ and $h(x) = (x+l)^2$ then $F(x) = \int_0^2 g(h(x))\ dl$, so $F´(x) = g(h(x)) h´(x)$  then I can evaluate this in $x=0$ , so $F´(0) = \sin{l^2} 2l $ is that correct? Some help to calculate this please.",,"['calculus', 'real-analysis', 'derivatives']"
72,Lines tangent to parabola at point.,Lines tangent to parabola at point.,,"I'm struggling to figure out what I'm exactly required to do. The problem states ""Compute which lines through the point $(1, 0)$ that are tangent to the parabola defined by $y = x^2$."" I believe it's a simple question however I've been going around this for quite a bit. I'll appreciate any kind of help! Thank you!","I'm struggling to figure out what I'm exactly required to do. The problem states ""Compute which lines through the point $(1, 0)$ that are tangent to the parabola defined by $y = x^2$."" I believe it's a simple question however I've been going around this for quite a bit. I'll appreciate any kind of help! Thank you!",,['derivatives']
73,Does continuity imply existence of one sided derivatives?,Does continuity imply existence of one sided derivatives?,,"From what I understand a derivative may not exist at a given point if the function is not continuous or the right and left side derivatives are not equal. Does that imply that if a function is continuous, the one sided derivatives exist at it's every point?","From what I understand a derivative may not exist at a given point if the function is not continuous or the right and left side derivatives are not equal. Does that imply that if a function is continuous, the one sided derivatives exist at it's every point?",,"['calculus', 'real-analysis', 'derivatives']"
74,How do you calculate the derivative after a change of variables?,How do you calculate the derivative after a change of variables?,,"How would you calculate $df \over dθ$ if $f(x,y) = x^2+y^2$ where $x = \sin 2θ$ and $y = \cos 2θ$? I tried Wolfram and using the product rule but I can't seem to get anywhere.","How would you calculate $df \over dθ$ if $f(x,y) = x^2+y^2$ where $x = \sin 2θ$ and $y = \cos 2θ$? I tried Wolfram and using the product rule but I can't seem to get anywhere.",,"['calculus', 'trigonometry', 'derivatives', 'differential']"
75,Help with $\dfrac{dr}{d\theta}$ for $r=2\sec\theta\csc\theta$,Help with  for,\dfrac{dr}{d\theta} r=2\sec\theta\csc\theta,"Find $\dfrac{dr}{d\theta}$ for $r=2\sec\theta\csc\theta$. My try: $$r^{\prime}=2[\sec\theta(-\csc\theta\cot\theta)+\csc\theta(\sec\theta\tan\theta)]$$ $$r^{\prime}=2\left(\frac{1}{\sin\theta}(-\frac{1}{\cos\theta}\frac{\cos\theta}{\sin\theta})+\frac{1}{\cos\theta}(\frac{1}{\sin\theta}\frac{\sin\theta}{\cos\theta})\right)$$ $$r^{\prime}=2(-\sec^2\theta+\csc^2\theta)$$ $$r^{\prime}=2\csc^2\theta-2\sec^2\theta$$ This is wrong though, the correct answer is: $$r^{\prime}=2\sec^2\theta-2\csc^2\theta$$","Find $\dfrac{dr}{d\theta}$ for $r=2\sec\theta\csc\theta$. My try: $$r^{\prime}=2[\sec\theta(-\csc\theta\cot\theta)+\csc\theta(\sec\theta\tan\theta)]$$ $$r^{\prime}=2\left(\frac{1}{\sin\theta}(-\frac{1}{\cos\theta}\frac{\cos\theta}{\sin\theta})+\frac{1}{\cos\theta}(\frac{1}{\sin\theta}\frac{\sin\theta}{\cos\theta})\right)$$ $$r^{\prime}=2(-\sec^2\theta+\csc^2\theta)$$ $$r^{\prime}=2\csc^2\theta-2\sec^2\theta$$ This is wrong though, the correct answer is: $$r^{\prime}=2\sec^2\theta-2\csc^2\theta$$",,"['calculus', 'derivatives']"
76,Differentiate a function containing a variable and its complex conjugate,Differentiate a function containing a variable and its complex conjugate,,If I have a function of x: $$f(x) = x + \frac K{x^*}$$ Where $x$ is a complex number and $x^*$ is its conjugate. How can I find $f'(x)$ ? My first thoughts are to rearrange: $$f(x) = x + \frac K{x-2 Im(x)}$$ But in general I am unsure where to start with this. Can anyone help?,If I have a function of x: $$f(x) = x + \frac K{x^*}$$ Where $x$ is a complex number and $x^*$ is its conjugate. How can I find $f'(x)$ ? My first thoughts are to rearrange: $$f(x) = x + \frac K{x-2 Im(x)}$$ But in general I am unsure where to start with this. Can anyone help?,,"['derivatives', 'complex-numbers']"
77,$\frac{d}{dt} \int_{-\infty}^{\infty} e^{-x^2} \cos(2tx) dx$,,\frac{d}{dt} \int_{-\infty}^{\infty} e^{-x^2} \cos(2tx) dx,"Prove that: $\frac{d}{dt} \int_{-\infty}^{\infty} e^{-x^2} \cos(2tx) dx=\int_{-\infty}^{\infty} -2x e^{-x^2} \sin(2tx) dx$ This is my proof: $\forall \ t \in \mathbb{R}$ (the improper integral coverge absolutely $\forall \ t \in \mathbb{R}$) I consider: $g(t)=\int_{-\infty}^{\infty} e^{-x^2} \cos(2tx) dx$. Let $h \ne 0$ $\left| \frac{g(t+h)-g(t)}{h}-\int_{-\infty}^{\infty} -2x e^{-x^2} \sin(2tx) dx \right|\le\int_{-\infty}^{\infty} \left|\frac{\cos(2(t+h)x)-\cos(2tx)}{h}-(-2x)\sin(2tx)\right| e^{-x^2}dx$ For the main value theorem and since $\int_{-\infty}^{\infty} e^{-x^2} dx=\sqrt{\pi}$ $\int_{-\infty}^{\infty} \left|\frac{\cos(2(t+h)x)-\cos(2tx)}{h}-(-2x)\sin(2tx)\right| e^{-x^2}dx=\left|\frac{\cos(2(t+h)\bar{x})-\cos(2t\bar{x})}{h}-(-2\bar{x})\sin(2t\bar{x})\right| \sqrt{\pi}$ $\cos(2tx)$ is derivable in $\bar{x}$ then fixed a $\epsilon>0 \ $ if $\ 0<|h|<\delta$: $\left|\frac{\cos(2(t+h)\bar{x})-\cos(2t\bar{x})}{h}-(-2\bar{x})\sin(2t\bar{x})\right| \sqrt{\pi}<\sqrt{\pi} \ \epsilon$ It is correct? There are other ways? UPDATE probably the proof is incorrect, because when I use the mean value theorem $x$ depends also from $h$ and hence the continuity of $x(h)$ is not obvious, then I can't guarantee the derivability of $\cos(2 t x(h))$ in $x$ for $h \rightarrow 0$. Am I right?","Prove that: $\frac{d}{dt} \int_{-\infty}^{\infty} e^{-x^2} \cos(2tx) dx=\int_{-\infty}^{\infty} -2x e^{-x^2} \sin(2tx) dx$ This is my proof: $\forall \ t \in \mathbb{R}$ (the improper integral coverge absolutely $\forall \ t \in \mathbb{R}$) I consider: $g(t)=\int_{-\infty}^{\infty} e^{-x^2} \cos(2tx) dx$. Let $h \ne 0$ $\left| \frac{g(t+h)-g(t)}{h}-\int_{-\infty}^{\infty} -2x e^{-x^2} \sin(2tx) dx \right|\le\int_{-\infty}^{\infty} \left|\frac{\cos(2(t+h)x)-\cos(2tx)}{h}-(-2x)\sin(2tx)\right| e^{-x^2}dx$ For the main value theorem and since $\int_{-\infty}^{\infty} e^{-x^2} dx=\sqrt{\pi}$ $\int_{-\infty}^{\infty} \left|\frac{\cos(2(t+h)x)-\cos(2tx)}{h}-(-2x)\sin(2tx)\right| e^{-x^2}dx=\left|\frac{\cos(2(t+h)\bar{x})-\cos(2t\bar{x})}{h}-(-2\bar{x})\sin(2t\bar{x})\right| \sqrt{\pi}$ $\cos(2tx)$ is derivable in $\bar{x}$ then fixed a $\epsilon>0 \ $ if $\ 0<|h|<\delta$: $\left|\frac{\cos(2(t+h)\bar{x})-\cos(2t\bar{x})}{h}-(-2\bar{x})\sin(2t\bar{x})\right| \sqrt{\pi}<\sqrt{\pi} \ \epsilon$ It is correct? There are other ways? UPDATE probably the proof is incorrect, because when I use the mean value theorem $x$ depends also from $h$ and hence the continuity of $x(h)$ is not obvious, then I can't guarantee the derivability of $\cos(2 t x(h))$ in $x$ for $h \rightarrow 0$. Am I right?",,"['calculus', 'real-analysis', 'integration', 'derivatives', 'improper-integrals']"
78,What is the relation between the average rate of change and the derivative?,What is the relation between the average rate of change and the derivative?,,"A value in the range for any base polynomial function with a y-intercept of zero can be expressed as: $$f\left(x\right) = px$$ where $p$ is the average rate of change between $0$ and $x$. The average rate of change can be in turn expressed as $$p = \frac{ f'\left(0\right) + f'\left(x\right)}{2}$$ where $f'\left(0\right)$ is the instantaneous rate of change at $0$ (or in other words the derivative evaluated at zero) and $f'\left(x\right)$ is the instantaneous rate of change evaluated at $x$ (or in other words the derivative evaluated at the specific range value). In a base polynomial equation (or in other words a polynomial with one term of degree $d$ and leading coefficient $1$) with degree greater than 1 the derivative evaluated at zero can be further simplified to $0$. This leads to a final simplified equation: $$f(x) = \frac{f'(x)x}{2}$$ This final equation however fails to provide the range value for a polynomial above degree $2$. According to the power rule, if: $$f(x) = x^3$$ then: $$f'(x) = 3x^2$$ According to the above derived equation: $$f(3) = \frac{f'(3)(3)}{2} = \frac{(3(3)^2)3}{2} = \frac{81}{2}$$ which is clearly the wrong answer. What is the flaw in the equation relating the average change of rate and the derivative?","A value in the range for any base polynomial function with a y-intercept of zero can be expressed as: $$f\left(x\right) = px$$ where $p$ is the average rate of change between $0$ and $x$. The average rate of change can be in turn expressed as $$p = \frac{ f'\left(0\right) + f'\left(x\right)}{2}$$ where $f'\left(0\right)$ is the instantaneous rate of change at $0$ (or in other words the derivative evaluated at zero) and $f'\left(x\right)$ is the instantaneous rate of change evaluated at $x$ (or in other words the derivative evaluated at the specific range value). In a base polynomial equation (or in other words a polynomial with one term of degree $d$ and leading coefficient $1$) with degree greater than 1 the derivative evaluated at zero can be further simplified to $0$. This leads to a final simplified equation: $$f(x) = \frac{f'(x)x}{2}$$ This final equation however fails to provide the range value for a polynomial above degree $2$. According to the power rule, if: $$f(x) = x^3$$ then: $$f'(x) = 3x^2$$ According to the above derived equation: $$f(3) = \frac{f'(3)(3)}{2} = \frac{(3(3)^2)3}{2} = \frac{81}{2}$$ which is clearly the wrong answer. What is the flaw in the equation relating the average change of rate and the derivative?",,['calculus']
79,Prove inequalities (Calculus 1) $\ x - \frac{x^{3}}{6}< \sin x < x-\frac{x^{3}}{6} +\frac{x^{5}}{120}$ [duplicate],Prove inequalities (Calculus 1)  [duplicate],\ x - \frac{x^{3}}{6}< \sin x < x-\frac{x^{3}}{6} +\frac{x^{5}}{120},"This question already has answers here : Proving $x-\frac{x^3}{6} < \sin(x) < x - \frac{x^3}{6} + \frac{x^5}{120} ~~ \forall x \in \Bbb R^+$ using Taylor's expansion (5 answers) Closed last year . Prove the following inequality: $$x - \frac{x^{3}}{6}< \sin x < x-\frac{x^{3}}{6} +\frac{x^{5}}{120} ,\; \forall x > 0$$ I'm not sure my proof is correct. I separated the problem into proving the inequality on the left and on the right side. The left side wasn't really difficult,the right one,however,gave me a lot of work.I named $g(x)=x-\frac{x^{3}}{6} +\frac{x^{5}}{120}$ and $f(x) = \sin(x)$ and derived both equations multiple times until i reached the $5$ th and analysed the rate of growth of each one until I came into the conlusion that $f(x) < g(x)$ .I used the same method on the left side and it worked.Could anyone tell me if I'm on the right path here?Any help would be kindly appreciated. Thank you in advance.","This question already has answers here : Proving $x-\frac{x^3}{6} < \sin(x) < x - \frac{x^3}{6} + \frac{x^5}{120} ~~ \forall x \in \Bbb R^+$ using Taylor's expansion (5 answers) Closed last year . Prove the following inequality: I'm not sure my proof is correct. I separated the problem into proving the inequality on the left and on the right side. The left side wasn't really difficult,the right one,however,gave me a lot of work.I named and and derived both equations multiple times until i reached the th and analysed the rate of growth of each one until I came into the conlusion that .I used the same method on the left side and it worked.Could anyone tell me if I'm on the right path here?Any help would be kindly appreciated. Thank you in advance.","x - \frac{x^{3}}{6}< \sin x < x-\frac{x^{3}}{6} +\frac{x^{5}}{120} ,\; \forall x > 0 g(x)=x-\frac{x^{3}}{6} +\frac{x^{5}}{120} f(x) = \sin(x) 5 f(x) < g(x)","['calculus', 'derivatives', 'inequality']"
80,Bounded gradient implies Lipschitz on non-convex set,Bounded gradient implies Lipschitz on non-convex set,,"There are loads of questions and answers concerning the following problem, but here we have a slight variation: Let $U$ be an open subset of $\mathbb{R}^n$ and $f: U \rightarrow \mathbb{R}$ be differentiable such that the derivative is bounded by the constant $L \geq 0$ . Show that $f$ is a globally lipschitz-function. So, usually the domain is $\mathbb{R}^n$ and then this is pretty easy to show by using the mean-value-theorem. However, now we have an arbitrary open set as the domain and as far as I know, we need convexity of the set in order to use the MVT for two arbitrary points in the set. Does this statement still hold? If yes, what would the argument be? As a side note I have found this post Sub-gradient and super-gradient are bounded implies globally Lipschitz. which goes in the direction of my question, but does not answer it.","There are loads of questions and answers concerning the following problem, but here we have a slight variation: Let be an open subset of and be differentiable such that the derivative is bounded by the constant . Show that is a globally lipschitz-function. So, usually the domain is and then this is pretty easy to show by using the mean-value-theorem. However, now we have an arbitrary open set as the domain and as far as I know, we need convexity of the set in order to use the MVT for two arbitrary points in the set. Does this statement still hold? If yes, what would the argument be? As a side note I have found this post Sub-gradient and super-gradient are bounded implies globally Lipschitz. which goes in the direction of my question, but does not answer it.",U \mathbb{R}^n f: U \rightarrow \mathbb{R} L \geq 0 f \mathbb{R}^n,"['real-analysis', 'derivatives', 'lipschitz-functions', 'mean-value-theorem']"
81,A Pseudo-Derivative for $f(x)=|x|$,A Pseudo-Derivative for,f(x)=|x|,"I was wondering what the significance of a function that gives the slope of $y=|x|$ at any $x$ is. If $$f(x)=|x|$$ then we could do, as the derivative: $$\frac{d f}{d x}=\frac{x}{|x|}$$ or $$\frac{d f}{d x}=\frac{|x|}{x}$$ This would give us the slope at any $x$ . What is wrong with my approach? How would this connect to limits?","I was wondering what the significance of a function that gives the slope of at any is. If then we could do, as the derivative: or This would give us the slope at any . What is wrong with my approach? How would this connect to limits?",y=|x| x f(x)=|x| \frac{d f}{d x}=\frac{x}{|x|} \frac{d f}{d x}=\frac{|x|}{x} x,"['calculus', 'derivatives', 'absolute-value', 'slope']"
82,Derivative of $\tan^{-1} \sqrt{\frac{1-\cos x}{1-\sin x}}$,Derivative of,\tan^{-1} \sqrt{\frac{1-\cos x}{1-\sin x}},Is there any way to differentiate $\tan^{-1} \sqrt{\frac{1-\cos x}{1-\sin x}}$ without any messy calculations? Here are my thoughts: We write $\cos x$ and $\sin x$ in terms of $\tan{\frac{x}{2}}$ . Then our function becomes $\tan^{-1} \frac{\sqrt{2}\tan \frac{x}{2}}{1-\tan \frac{x}{2}}$ . But I am afraid this doesn't seem to work since we can't extrapolate any triginometric formula of $\tan$ from here.,Is there any way to differentiate without any messy calculations? Here are my thoughts: We write and in terms of . Then our function becomes . But I am afraid this doesn't seem to work since we can't extrapolate any triginometric formula of from here.,\tan^{-1} \sqrt{\frac{1-\cos x}{1-\sin x}} \cos x \sin x \tan{\frac{x}{2}} \tan^{-1} \frac{\sqrt{2}\tan \frac{x}{2}}{1-\tan \frac{x}{2}} \tan,['derivatives']
83,How to show that $f(x)=|x^2-3x+2|$ is not differentiable at $x=1$,How to show that  is not differentiable at,f(x)=|x^2-3x+2| x=1,"Consider the function $$f(x)=|x^2-3x+2|$$ over the interval $[0,3]$ . Intuitively I know that $f$ is not differentiable at $x=1$ but when I calculate the limits $$\lim_{x\rightarrow 1^+} \frac{f(1+h)-f(1)}{h}\;\;\text{and}\;\;\lim_{x\rightarrow 1^-} \frac{f(1+h)-f(1)}{h},$$ I find they are equal and so by definition the limit $$\lim_{x\rightarrow 1} \frac{f(1+h)-f(1)}{h}$$ exists and the function is differentiable at $x=1$ . Have I made an error in my logic?",Consider the function over the interval . Intuitively I know that is not differentiable at but when I calculate the limits I find they are equal and so by definition the limit exists and the function is differentiable at . Have I made an error in my logic?,"f(x)=|x^2-3x+2| [0,3] f x=1 \lim_{x\rightarrow 1^+} \frac{f(1+h)-f(1)}{h}\;\;\text{and}\;\;\lim_{x\rightarrow 1^-} \frac{f(1+h)-f(1)}{h}, \lim_{x\rightarrow 1} \frac{f(1+h)-f(1)}{h} x=1","['calculus', 'derivatives']"
84,"Why is ""$\text{not }(f'>0)$"" not logically equivalent to $f' \le 0$","Why is """" not logically equivalent to",\text{not }(f'>0) f' \le 0,"Recently, I was trying to solve a proof of the type $P \implies Q$ with $Q$ representing the statement $f'>0$ . I tried to solve this by contradiciton and rewrote it as $P \text{ and not }Q$ is false. Here I thought that $\text{ not} f'>0$ was equivalent to $f' \le 0$ but was told I was wrong in thinking that, can anyone explain to me why?","Recently, I was trying to solve a proof of the type with representing the statement . I tried to solve this by contradiciton and rewrote it as is false. Here I thought that was equivalent to but was told I was wrong in thinking that, can anyone explain to me why?",P \implies Q Q f'>0 P \text{ and not }Q \text{ not} f'>0 f' \le 0,['real-analysis']
85,A Simpler Solution to an Optimization Problem.,A Simpler Solution to an Optimization Problem.,,"The Problem: My Solution: Let me model this situation in the first quadrant of the $x$ - $y$ plane. Let us take the line $y=mx+c$ as the ladder (moving in the first quadrant). This is how the ladder moving in the corridor looks: The $y$ -intercept of the line is $c$ and the $x$ -intercept is $\left(-\frac{c}{m}\right)$ . Since the ladder is moving in the first quadrant, we have $$ m<0 \text{ and } c>0 $$ Let $L$ be the length of the ladder. Then, $$ L^2=c^2+\left(\frac{c}{m}\right)^2 $$ or $$ c=-\frac{mL}{\sqrt{1+m^2}} \text{ (Negative sign because m<0)} $$ and therefore, the equation of the ladder becomes $$ y=mx-\frac{mL}{\sqrt{1+m^2}} $$ As the ladder is transported through the corridor, the distance between the ladder and the corner becomes smaller up to a minimum and then start increasing again. The goal here is to choose $L$ such that the ladder just touches the corner as it clears the corridor. This $L$ would be the max length of the ladder. Let the gap along the $y$ -direction between the corner and the ladder be $s$ . Let the co-ordinates of the corner be $(a,b)$ . Then, $$ s=b-ma+\frac{mL}{\sqrt{1+m^2}} $$ For a given ladder, this distance hits  a minimum value for a certain value of $m$ . Let's find that out $$ \frac{ds}{dm}=-a+\frac{L}{\sqrt{1+m^2}}-\frac{Lm^2}{(1+m^2)^\frac{3}{2}}=0 $$ Solving which we obtain the value of $m$ which makes $s$ hit its minimum value $$ m=-\left\{\left(\frac{L}{a}\right)^\frac{2}{3}-1\right\}^\frac{1}{2} \text{ (Negative because m<0)} $$ Therefore, $$ s_{\text{min}}=b+a\left\{\left(\frac{L}{a}\right)^\frac{2}{3}-1\right\}^\frac{1}{2}+L\left\{1-\left(\frac{a}{L}\right)^\frac{2}{3}\right\} $$ The value of $s_{\text{min}}$ in the case of this problem is zero. Therefore, solving the above equation, we get $$ L=a\left\{\left(\frac{b}{a}\right)^\frac{2}{3}+1\right\}^\frac{3}{2}=\left(b^\frac{2}{3}+a^\frac{2}{3}\right)^\frac{3}{2} $$ Plugging, $a=8$ and $b=6$ as asked in the question we get $$ L=19.7313 \approx 20 \text{ feet} $$ Is this correct? If yes, can we make an easier model to solve this problem? (Only in the context of calculus)","The Problem: My Solution: Let me model this situation in the first quadrant of the - plane. Let us take the line as the ladder (moving in the first quadrant). This is how the ladder moving in the corridor looks: The -intercept of the line is and the -intercept is . Since the ladder is moving in the first quadrant, we have Let be the length of the ladder. Then, or and therefore, the equation of the ladder becomes As the ladder is transported through the corridor, the distance between the ladder and the corner becomes smaller up to a minimum and then start increasing again. The goal here is to choose such that the ladder just touches the corner as it clears the corridor. This would be the max length of the ladder. Let the gap along the -direction between the corner and the ladder be . Let the co-ordinates of the corner be . Then, For a given ladder, this distance hits  a minimum value for a certain value of . Let's find that out Solving which we obtain the value of which makes hit its minimum value Therefore, The value of in the case of this problem is zero. Therefore, solving the above equation, we get Plugging, and as asked in the question we get Is this correct? If yes, can we make an easier model to solve this problem? (Only in the context of calculus)","x y y=mx+c y c x \left(-\frac{c}{m}\right) 
m<0 \text{ and } c>0
 L 
L^2=c^2+\left(\frac{c}{m}\right)^2
 
c=-\frac{mL}{\sqrt{1+m^2}} \text{ (Negative sign because m<0)}
 
y=mx-\frac{mL}{\sqrt{1+m^2}}
 L L y s (a,b) 
s=b-ma+\frac{mL}{\sqrt{1+m^2}}
 m 
\frac{ds}{dm}=-a+\frac{L}{\sqrt{1+m^2}}-\frac{Lm^2}{(1+m^2)^\frac{3}{2}}=0
 m s 
m=-\left\{\left(\frac{L}{a}\right)^\frac{2}{3}-1\right\}^\frac{1}{2} \text{ (Negative because m<0)}
 
s_{\text{min}}=b+a\left\{\left(\frac{L}{a}\right)^\frac{2}{3}-1\right\}^\frac{1}{2}+L\left\{1-\left(\frac{a}{L}\right)^\frac{2}{3}\right\}
 s_{\text{min}} 
L=a\left\{\left(\frac{b}{a}\right)^\frac{2}{3}+1\right\}^\frac{3}{2}=\left(b^\frac{2}{3}+a^\frac{2}{3}\right)^\frac{3}{2}
 a=8 b=6 
L=19.7313 \approx 20 \text{ feet}
","['derivatives', 'optimization']"
86,What is the intuition of this problem about $|f'(x)|$?,What is the intuition of this problem about ?,|f'(x)|,"$\newcommand{\d}{\mathrm{d}}$ Recently, I met a problem, which says that: Given that $f(x)$ have continious derivatives on close interval $[0,2]$ , $f(0)=f(2)=0$ , $M=\max_{[0,2]} |f(x)|$ . Prove that: (1) there exists a number $\xi \in (0,2)$ , s.t. $|f'(\xi)| \geq M$ . (2) If for every $x \in (0,2)$ , $|f'(x)|\leq M$ , then $M=0$ . I can prove the first problem. However, the second problem makes me mad. So I look up the solution. The proof is here: We know that there exists a number $x_0$ , s.t. $M=|f(x_0)|=|f(x_0)-f(0)|=|\int_{0}^{x_0}f'(x)dx|\leq\int_{0}^{x_0}|f'(x)|dx\leq\int_{0}^{x_0}Mdx\leq Mx_0$ , $M=|f(x_0)|=|f(x_0)-f(2)|=|\int_{x_0}^{2}f'(x)dx|\leq\int_{x_0}^{2}|f'(x)|dx\leq\int_{x_0}^{2}Mdx\leq M(2-x_0)$ So, $M(1-x_0) \leq 0 and  M(1-x_0)\geq 0$ . If $x_0 \neq 1$ , $M$ is apparently $0$ , if $x_0=1$ , then $M \leq \int_{0}^{1}|f'(x)|dx \leq M$ and $M \leq \int_{1}^{2}|f'(x)|dx \leq M$ , if $M \neq 0$ , then it contradicts. I can understand this solution, but I don't know the intuition or motivation behind this. I don't believe that there exists a solution which has no motivation, but I can't find the motivation behind this problem. In fact, everytime I meet this kind of problems, I often have no idea, I really think that this kind of problems are hard to solve, can anyone give some advice or some resource about this kind of problems?","Recently, I met a problem, which says that: Given that have continious derivatives on close interval , , . Prove that: (1) there exists a number , s.t. . (2) If for every , , then . I can prove the first problem. However, the second problem makes me mad. So I look up the solution. The proof is here: We know that there exists a number , s.t. , So, . If , is apparently , if , then and , if , then it contradicts. I can understand this solution, but I don't know the intuition or motivation behind this. I don't believe that there exists a solution which has no motivation, but I can't find the motivation behind this problem. In fact, everytime I meet this kind of problems, I often have no idea, I really think that this kind of problems are hard to solve, can anyone give some advice or some resource about this kind of problems?","\newcommand{\d}{\mathrm{d}} f(x) [0,2] f(0)=f(2)=0 M=\max_{[0,2]} |f(x)| \xi \in (0,2) |f'(\xi)| \geq M x \in (0,2) |f'(x)|\leq M M=0 x_0 M=|f(x_0)|=|f(x_0)-f(0)|=|\int_{0}^{x_0}f'(x)dx|\leq\int_{0}^{x_0}|f'(x)|dx\leq\int_{0}^{x_0}Mdx\leq Mx_0 M=|f(x_0)|=|f(x_0)-f(2)|=|\int_{x_0}^{2}f'(x)dx|\leq\int_{x_0}^{2}|f'(x)|dx\leq\int_{x_0}^{2}Mdx\leq M(2-x_0) M(1-x_0) \leq 0 and  M(1-x_0)\geq 0 x_0 \neq 1 M 0 x_0=1 M \leq \int_{0}^{1}|f'(x)|dx \leq M M \leq \int_{1}^{2}|f'(x)|dx \leq M M \neq 0","['calculus', 'derivatives']"
87,What is the interpretation of dy/dx in parametric equations and why is it different from the velocity?,What is the interpretation of dy/dx in parametric equations and why is it different from the velocity?,,"So I know normally that dy/dx is equal to the velocity of a particle at a specific point if the original equation indicates the position of that particle. When dealing with parametric equations, I know velocity is equal to <dx/dt, dy/dt>. But it made sense to me that dividing dy/dt over dx/dt, giving dy/dx, would mean the same thing. Of course, it isn't, but I don't understand why it doesn't work and what the actual interpretation of dy/dx is for parametric equations.","So I know normally that dy/dx is equal to the velocity of a particle at a specific point if the original equation indicates the position of that particle. When dealing with parametric equations, I know velocity is equal to <dx/dt, dy/dt>. But it made sense to me that dividing dy/dt over dx/dt, giving dy/dx, would mean the same thing. Of course, it isn't, but I don't understand why it doesn't work and what the actual interpretation of dy/dx is for parametric equations.",,"['calculus', 'derivatives', 'parametric']"
88,Which of these is the correct average rate of change?,Which of these is the correct average rate of change?,,"The question is to find the average rate of change of $2000e^{0.21x}$ between $2$ and $5$ ? I found the derivative of the equation ( $2000e^{0.21x}$ ) and averaged them, I found the average rate of change. i.e. $$\frac{\mathrm{d}}{\mathrm{d}x} 2000e^{0.21x} = 4200e^{0.21x}$$ so $$\frac{f'(2) + f'(5)}{2} = 9197.$$ But you can also just use the original equation to find it i.e. $\frac{f(5) - f(2)}{3} = 8904.6$ , since there is $3$ intervals between them. My question is why is there two different answers because the first method is the average rate of change between the two points. But the second one is too?","The question is to find the average rate of change of between and ? I found the derivative of the equation ( ) and averaged them, I found the average rate of change. i.e. so But you can also just use the original equation to find it i.e. , since there is intervals between them. My question is why is there two different answers because the first method is the average rate of change between the two points. But the second one is too?",2000e^{0.21x} 2 5 2000e^{0.21x} \frac{\mathrm{d}}{\mathrm{d}x} 2000e^{0.21x} = 4200e^{0.21x} \frac{f'(2) + f'(5)}{2} = 9197. \frac{f(5) - f(2)}{3} = 8904.6 3,"['calculus', 'derivatives', 'exponential-function', 'average']"
89,Question posed in Spivak Chapter 14 that $f$ cannot be a derivative,Question posed in Spivak Chapter 14 that  cannot be a derivative,f,"I'm having trouble working out the reasoning behind a question posed in Spivak's Calculus Chapter 14, where he discusses the Fundamental Theorem of Calculus. The excerpt where this is from is as follows: ... A function $f$ may be integrable without being the derivative of another function. For example, if $f(x) = 0$ for $x \ne 1$ and $f(1) = 1$ , then $f$ is integrable, but $f$ cannot be a derivative (why not?) I tried working it out to verify whether $f$ is differentiable by using the definition of a derivative, but realised that the statement was that $f$ cannot be a derivative, not that $f$ is not differentiable (unless there's something I'm missing out here?). Any insights would be greatly appreciated!","I'm having trouble working out the reasoning behind a question posed in Spivak's Calculus Chapter 14, where he discusses the Fundamental Theorem of Calculus. The excerpt where this is from is as follows: ... A function may be integrable without being the derivative of another function. For example, if for and , then is integrable, but cannot be a derivative (why not?) I tried working it out to verify whether is differentiable by using the definition of a derivative, but realised that the statement was that cannot be a derivative, not that is not differentiable (unless there's something I'm missing out here?). Any insights would be greatly appreciated!",f f(x) = 0 x \ne 1 f(1) = 1 f f f f f,"['calculus', 'integration', 'derivatives']"
90,Is it possible to find an expression for $\frac{d^n}{dx^n}e^{-x^2}$?,Is it possible to find an expression for ?,\frac{d^n}{dx^n}e^{-x^2},I am trying to find a general form to derivatives of the function $e^{-x^2}$ . I tried to do it by finding a pattern for the first derivatives but with no success. Any tip is welcome.,I am trying to find a general form to derivatives of the function . I tried to do it by finding a pattern for the first derivatives but with no success. Any tip is welcome.,e^{-x^2},"['calculus', 'derivatives']"
91,"If $g$ is continous on $[a,b]$ with bounded upper and lower derivatives on $(a,b)$, will $g$ be Lipschitz?","If  is continous on  with bounded upper and lower derivatives on , will  be Lipschitz?","g [a,b] (a,b) g","By the Mean Value Theorem from ordinary calculus one knows that, if $f$ is continous on $[a,b]$ and differentiable on $(a,b)$ with bounded derivatives, then $f$ has to be Lipschitz on $[a,b]$ . Now I ask a more general question: If $g$ is continous on $[a,b]$ with bounded upper and lower derivatives on $(a,b)$ , will $g$ be Lipschitz? If not, what would be a counterexample? I really don't know how to proceed. One idea I had was approximating $g$ with a piecewise linear function $\phi$ , but I don't know if this gets us anywhere.","By the Mean Value Theorem from ordinary calculus one knows that, if is continous on and differentiable on with bounded derivatives, then has to be Lipschitz on . Now I ask a more general question: If is continous on with bounded upper and lower derivatives on , will be Lipschitz? If not, what would be a counterexample? I really don't know how to proceed. One idea I had was approximating with a piecewise linear function , but I don't know if this gets us anywhere.","f [a,b] (a,b) f [a,b] g [a,b] (a,b) g g \phi","['real-analysis', 'derivatives', 'continuity', 'lipschitz-functions']"
92,How to get the derivative of an average?,How to get the derivative of an average?,,I was curious about how to derive the derivative of an average. More specifically: $$\mu = \frac{1}{m}\sum_{i = 1}^m x_i$$ $$\frac{\partial \mu}{\partial x_i} =\ ?$$ My derivation is as follows: $$ \begin{align} \mu & = \frac{1}{m}(x_1 + x_2 + \cdots + x_m) \\ \partial \mu / \partial x_i& = \frac{1}{m}(1 + 1+\dots + 1) \\ & = 1 \end{align} $$ but I'm not sure if this is correct...,I was curious about how to derive the derivative of an average. More specifically: My derivation is as follows: but I'm not sure if this is correct...,"\mu = \frac{1}{m}\sum_{i = 1}^m x_i \frac{\partial \mu}{\partial x_i} =\ ? 
\begin{align}
\mu & = \frac{1}{m}(x_1 + x_2 + \cdots + x_m) \\
\partial \mu / \partial x_i& = \frac{1}{m}(1 + 1+\dots + 1) \\
& = 1
\end{align}
",['derivatives']
93,Some property of differentiable function,Some property of differentiable function,,"Let $f:[0,2]\to\mathbb{R}$ be a continuous function and $f$ is differentiable on $(0,2)$ , and let $f(0)=f(2)=0$ . Now, suppose that there is a point $c\in(0,2)$ such that $f(c)=1$ . Then, there is a point $k\in(0,2)$ such that $\vert f'(k)\vert>1$ . Intuitively, it is pretty trivial. But, I can't find any way to prove it. How to prove it using the M.V.T. or another popular theorem? Give some idea or advice. Thank you!","Let be a continuous function and is differentiable on , and let . Now, suppose that there is a point such that . Then, there is a point such that . Intuitively, it is pretty trivial. But, I can't find any way to prove it. How to prove it using the M.V.T. or another popular theorem? Give some idea or advice. Thank you!","f:[0,2]\to\mathbb{R} f (0,2) f(0)=f(2)=0 c\in(0,2) f(c)=1 k\in(0,2) \vert f'(k)\vert>1","['real-analysis', 'derivatives', 'rolles-theorem']"
94,"Why is the matrix derivative of the trace of $AB$ with respect to $B$ not a constant, but $A^T$?","Why is the matrix derivative of the trace of  with respect to  not a constant, but ?",AB B A^T,"Why is this true? $$\frac{d}{dB} Tr[A B]= A^\top$$ Trace is the sum of the diagonal elements. So, I'm expecting a number, a matrix! What's going on here? Example: Given matrix A with $m \times n$ , and B with $n \times p$ , in particular, we have the following, $$A=  \begin{bmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \end{bmatrix},  B=  \begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \\ b_{31} & b_{32} \end{bmatrix} $$ To get the answer, we mulitply, take derivative, then, trace. First, we mutiply, $$AB=  \begin{bmatrix} a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} & a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} \\ a_{21}b_{11} + a_{22}b_{21} + a_{23}b_{31} & a_{21}b_{12} + a_{22}b_{22} + a_{23}b_{32} \end{bmatrix} $$ Second, we take derivative. Fact: $\frac{d}{dB} Tr[A B]=  Tr[A \frac{d}{dB}B]$ , $$A\frac{d}{d B}=  \begin{bmatrix} a_{11}+ a_{12} + a_{13} & a_{11} + a_{12} + a_{13} \\ a_{21} + a_{22}+ a_{23} & a_{21} + a_{22}b + a_{23} \end{bmatrix} $$ Third, we take trace, $$Tr\left[ A\frac{d}{d B}\right] = a_{11} + a_{12} + a_{13} + a_{21} + a_{22}b + a_{23} = k$$ The result is $\frac{d}{dB} Tr[A B] = k$ , this a constant. Not the matrix $A^T$ as established in the first equation.","Why is this true? Trace is the sum of the diagonal elements. So, I'm expecting a number, a matrix! What's going on here? Example: Given matrix A with , and B with , in particular, we have the following, To get the answer, we mulitply, take derivative, then, trace. First, we mutiply, Second, we take derivative. Fact: , Third, we take trace, The result is , this a constant. Not the matrix as established in the first equation.","\frac{d}{dB} Tr[A B]= A^\top m \times n n \times p A= 
\begin{bmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23}
\end{bmatrix}, 
B= 
\begin{bmatrix}
b_{11} & b_{12} \\
b_{21} & b_{22} \\
b_{31} & b_{32}
\end{bmatrix}
 AB= 
\begin{bmatrix}
a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} & a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} \\
a_{21}b_{11} + a_{22}b_{21} + a_{23}b_{31} & a_{21}b_{12} + a_{22}b_{22} + a_{23}b_{32}
\end{bmatrix}  \frac{d}{dB} Tr[A B]=  Tr[A \frac{d}{dB}B] A\frac{d}{d B}= 
\begin{bmatrix}
a_{11}+ a_{12} + a_{13} & a_{11} + a_{12} + a_{13} \\
a_{21} + a_{22}+ a_{23} & a_{21} + a_{22}b + a_{23}
\end{bmatrix}  Tr\left[ A\frac{d}{d B}\right] = a_{11} + a_{12} + a_{13} + a_{21} + a_{22}b + a_{23} = k \frac{d}{dB} Tr[A B] = k A^T","['linear-algebra', 'derivatives', 'matrix-calculus', 'trace']"
95,"If $\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3$, does $\lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right) = 3$?","If , does ?",\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3 \lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right) = 3,"Given that $f'(0) = 3$ , I need to solve the limit: $$\lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right)$$ Because $f'(0) = 3$ , from first principles, I know that $\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3$ . After some algebra, I arrive at $$\lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right) = \lim_{x\rightarrow1}\left(\frac{f((x-1)(x+1)) - f(0)}{(x-1)(x+1)}\right)\times\lim_{x\rightarrow1}\left(\frac{x+1}{x^2 + x + 1}\right)$$ Substitute $h = x-1$ $$\lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right)= \lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right)\times\frac{2}{3}$$ If $\displaystyle\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3$ , does $\displaystyle\lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right) = 3$ ? If so, the solution is $2$ .","Given that , I need to solve the limit: Because , from first principles, I know that . After some algebra, I arrive at Substitute If , does ? If so, the solution is .",f'(0) = 3 \lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right) f'(0) = 3 \lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3 \lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right) = \lim_{x\rightarrow1}\left(\frac{f((x-1)(x+1)) - f(0)}{(x-1)(x+1)}\right)\times\lim_{x\rightarrow1}\left(\frac{x+1}{x^2 + x + 1}\right) h = x-1 \lim_{x\rightarrow1}\left(\frac{f(x^2 -1) - f(0)}{x^3 -1}\right)= \lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right)\times\frac{2}{3} \displaystyle\lim_{x\rightarrow0}\left(\frac{f(x) - f(0)}{x}\right) = 3 \displaystyle\lim_{h\rightarrow0}\left(\frac{f(h(h+2)) - f(0)}{h(h+2)}\right) = 3 2,"['calculus', 'derivatives']"
96,gradient of max function,gradient of max function,,"If I have a function $f=\max \{0, y-t\}$ , and I want to find the gradient of with respect to $[y \ \ t]$ , would that simply be $$ \nabla f =  \begin{bmatrix} \max\{0,0\} \\ \max\{1,-1\} \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix} $$","If I have a function , and I want to find the gradient of with respect to , would that simply be","f=\max \{0, y-t\} [y \ \ t] 
\nabla f = 
\begin{bmatrix}
\max\{0,0\} \\
\max\{1,-1\}
\end{bmatrix} = \begin{bmatrix}
0 \\
1
\end{bmatrix}
",['derivatives']
97,Differentiate $e^{7x^3-\frac{5}{3}}$,Differentiate,e^{7x^3-\frac{5}{3}},For this equation I'm using the following property $$f(x)=e^{kx}$$ $$f'(x)=ke^{kx}$$ As well as the product rule $$f(x)=uv$$ $$f'(x)=u'v+uv'$$ I factorize $x$ on $e$'s exponent and then use the first property to differentiate: $$e^{7x^3-\frac{5}{3}}=e^{x(7x^2)-\frac{5}{3}}=7x^2*e^{7x^3-\frac{5}{3}}$$ Is his fully differentiated? Or do I have to apply the product rule to $7x^2$? Any other steps I'm missing?,For this equation I'm using the following property $$f(x)=e^{kx}$$ $$f'(x)=ke^{kx}$$ As well as the product rule $$f(x)=uv$$ $$f'(x)=u'v+uv'$$ I factorize $x$ on $e$'s exponent and then use the first property to differentiate: $$e^{7x^3-\frac{5}{3}}=e^{x(7x^2)-\frac{5}{3}}=7x^2*e^{7x^3-\frac{5}{3}}$$ Is his fully differentiated? Or do I have to apply the product rule to $7x^2$? Any other steps I'm missing?,,['derivatives']
98,From the given information I have to find $f'(0)$,From the given information I have to find,f'(0),"It is given that a function $f$ is differentiable everywhere, and $f(0)=5$. If $f(x)<5$ for all nonzero $x$ then what is the value of $f'(0)$?. Now I see that $0$ is a point of maximum of the function, which is differentiable at $0$, which means that $f'(0)$ must be zero. Is this the correct answer? I am conflicted because the book says it's not. There is a chance of a misprint though.","It is given that a function $f$ is differentiable everywhere, and $f(0)=5$. If $f(x)<5$ for all nonzero $x$ then what is the value of $f'(0)$?. Now I see that $0$ is a point of maximum of the function, which is differentiable at $0$, which means that $f'(0)$ must be zero. Is this the correct answer? I am conflicted because the book says it's not. There is a chance of a misprint though.",,['derivatives']
99,Prove that $f^g$ is differentiable using limits,Prove that  is differentiable using limits,f^g,"Let $A \subseteq \mathbb{R}$ and $f:A \to (0, \infty), \: g:A \to \mathbb{R}$ be two differentiable functions. Prove that $f^g:A \to \mathbb{R}$ is also differentiable, using limits. Let $x_0 \in A$ be arbitrary. In other words, we have to prove that there is a finite number $$l=\lim_{x\to x_0}\frac{f(x)^{g(x)}-f(x_0)^{g(x_0)}}{x-x_0}$$ I tried to get a common factor ouside the limit:  $$l=f(x_0)^{g(x_0)}\lim_{x \to x_0}\frac{\frac{f(x)^{g(x)}}{f(x_0)^{g(x_0)}}-1}{x-x_0}$$ but I'm not quite sure how to continue.","Let $A \subseteq \mathbb{R}$ and $f:A \to (0, \infty), \: g:A \to \mathbb{R}$ be two differentiable functions. Prove that $f^g:A \to \mathbb{R}$ is also differentiable, using limits. Let $x_0 \in A$ be arbitrary. In other words, we have to prove that there is a finite number $$l=\lim_{x\to x_0}\frac{f(x)^{g(x)}-f(x_0)^{g(x_0)}}{x-x_0}$$ I tried to get a common factor ouside the limit:  $$l=f(x_0)^{g(x_0)}\lim_{x \to x_0}\frac{\frac{f(x)^{g(x)}}{f(x_0)^{g(x_0)}}-1}{x-x_0}$$ but I'm not quite sure how to continue.",,"['calculus', 'real-analysis', 'derivatives']"
