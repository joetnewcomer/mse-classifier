,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Expected length of the shortest polygonal path connecting random points,Expected length of the shortest polygonal path connecting random points,,"$N$ points are selected in a uniformly distributed random way in a disk of a unit radius. Let $L(N)$ denote the expected length of the shortest polygonal path that visits each of the points at least once (the path need not to be closed any may be self-intersecting). For what $N$ do we know the exact value of $L(N)$? Is there a general formula for $L(N)$? What is the asymptotic behavior of $L(N)$ as $N\to\infty$? What are the answers to previous questions, if the disk is replaced with a ball?","$N$ points are selected in a uniformly distributed random way in a disk of a unit radius. Let $L(N)$ denote the expected length of the shortest polygonal path that visits each of the points at least once (the path need not to be closed any may be self-intersecting). For what $N$ do we know the exact value of $L(N)$? Is there a general formula for $L(N)$? What is the asymptotic behavior of $L(N)$ as $N\to\infty$? What are the answers to previous questions, if the disk is replaced with a ball?",,"['probability', 'geometry', 'probability-theory', 'asymptotics', 'combinatorial-geometry']"
1,A probabilistic game with balls and urns,A probabilistic game with balls and urns,,"We have $N$ urns forming a circle and $M<N$ balls (for example, $N=9,M=6$ in the diagram). In each step we visit, sequentially, clockwise, an urn. If it's occupied by a ball, we say a $hit$ has ocurred. Elsewhere ( miss ), we pick randomly one of the  $M$ balls and move it to the current urn. The goal is to compute the average hit rate, for arbitrary $N,M$, in the long run. I was confronted with this problem some years ago, for some concrete application (some cache model). It's not terribly difficult, but not as simple as it might seem. It's also interesting to contrast with the intuition (on which side would you bet in this example?). I have a solution, ( with two different proofs - I'll post them soon posted in answer below) but I'd like to hear about other attempts - or perhaps some reference - this should probably have been studied somewhere. A few (exact) results: N  M   p ------------  3  2  1/3  4  2  1/7  5  3  7/25 Edited: as found out semi-empirically in an answer below, the hit rate is given by $$p= \frac{S(N-1,M-1)}{S(N,M)}$$ where $S(N,M)$ are Stirling numbers of the second kind .","We have $N$ urns forming a circle and $M<N$ balls (for example, $N=9,M=6$ in the diagram). In each step we visit, sequentially, clockwise, an urn. If it's occupied by a ball, we say a $hit$ has ocurred. Elsewhere ( miss ), we pick randomly one of the  $M$ balls and move it to the current urn. The goal is to compute the average hit rate, for arbitrary $N,M$, in the long run. I was confronted with this problem some years ago, for some concrete application (some cache model). It's not terribly difficult, but not as simple as it might seem. It's also interesting to contrast with the intuition (on which side would you bet in this example?). I have a solution, ( with two different proofs - I'll post them soon posted in answer below) but I'd like to hear about other attempts - or perhaps some reference - this should probably have been studied somewhere. A few (exact) results: N  M   p ------------  3  2  1/3  4  2  1/7  5  3  7/25 Edited: as found out semi-empirically in an answer below, the hit rate is given by $$p= \frac{S(N-1,M-1)}{S(N,M)}$$ where $S(N,M)$ are Stirling numbers of the second kind .",,['probability']
2,"When you randomly shuffle a deck of cards, what is the probability that it is a unique permutation never before configured?","When you randomly shuffle a deck of cards, what is the probability that it is a unique permutation never before configured?",,"I just came back from a class on Probability in Game Theory, and was musing over something in my head. Assuming, for the sake of the question: Playing cards in their current state have been around for approximately eight centuries A deck of playing cards is shuffled to a random configuration one billion times per day Every shuffle ever is completely (theoretically) random and unaffected by biases caused by human shuffling and the games the cards are used for By ""deck of cards"", I refer to a stack of unordered $52$ unique cards, with a composition that is identical from deck to deck. This would, approximately, be on the order of $3 \cdot 10^{14}$ random shuffles in the history of playing cards. If I were to shuffle a new deck today, completely randomly, what are the probabilistic odds (out of $1$) that you create a new unique permutation of the playing cards that has never before been achieved in the history of $3 \cdot 10^{14}$ similarly random shuffles? My first thought was to think that it was a simple matter of $\frac{1}{52!} \cdot 3 \cdot 10^{14}$, but then I ran into things like Birthday Paradox .  While it is not analogous (I would have to be asking about the odds that any two shuffled decks in the history of shuffled decks ever matched), it has caused me to question my intuitive notions of Probability. What is wrong in my initial approach, if it is wrong? What is the true probability? And, if the probability is less than $0.5$, if we how many more years (centuries?) must we wait, assuming the current rate of one billion shuffles per day, until we reach a state where the probability is $0.5$+?   $0.9$+? (Out of curiosity, it would be neat to know the analogous birthday paradox answer, as well)","I just came back from a class on Probability in Game Theory, and was musing over something in my head. Assuming, for the sake of the question: Playing cards in their current state have been around for approximately eight centuries A deck of playing cards is shuffled to a random configuration one billion times per day Every shuffle ever is completely (theoretically) random and unaffected by biases caused by human shuffling and the games the cards are used for By ""deck of cards"", I refer to a stack of unordered $52$ unique cards, with a composition that is identical from deck to deck. This would, approximately, be on the order of $3 \cdot 10^{14}$ random shuffles in the history of playing cards. If I were to shuffle a new deck today, completely randomly, what are the probabilistic odds (out of $1$) that you create a new unique permutation of the playing cards that has never before been achieved in the history of $3 \cdot 10^{14}$ similarly random shuffles? My first thought was to think that it was a simple matter of $\frac{1}{52!} \cdot 3 \cdot 10^{14}$, but then I ran into things like Birthday Paradox .  While it is not analogous (I would have to be asking about the odds that any two shuffled decks in the history of shuffled decks ever matched), it has caused me to question my intuitive notions of Probability. What is wrong in my initial approach, if it is wrong? What is the true probability? And, if the probability is less than $0.5$, if we how many more years (centuries?) must we wait, assuming the current rate of one billion shuffles per day, until we reach a state where the probability is $0.5$+?   $0.9$+? (Out of curiosity, it would be neat to know the analogous birthday paradox answer, as well)",,['probability']
3,Closed-form analytical solutions to Optimal Transport/Wasserstein distance,Closed-form analytical solutions to Optimal Transport/Wasserstein distance,,"Kuang and Tabak (2017) mentions that: ""closed-form solutions of the multidimensional optimal transport problems are relatively rare, a number of numerical algorithms have been proposed."" I'm wondering if there are some resources (lecture notes, papers, etc.) that collect/contain known solutions to optimal transport and/or Wasserstein distance between two distributions in dimensions greater than 1. For example, let $ \mathcal{N_1}(\mu_1, \Sigma_1) $ and $ \mathcal{N_2}(\mu_2, \Sigma_2) $ denote two Gaussian distributions with different means and covariances matrices. Then the optimal transport map between them is: $$ x \longrightarrow \mu_2 + A( x - \mu_1 ) $$ where $ A = \Sigma_1^{- 1/2} (\Sigma_1^{1/2} \Sigma_2 \Sigma_1^{1/2})^{1/2} \Sigma_1^{- 1/2}$ . And so the Wasserstein 2 distance is $$ W_2 ( \mathcal{N_1}(\mu_1, \Sigma_1), \mathcal{N_2}(\mu_2, \Sigma_2) ) = || \mu_1 - \mu_2 ||^2_2 + \mathrm{Tr}( \Sigma_1 + \Sigma_2 - 2( \Sigma_1^{1/2} \Sigma_2 \Sigma_1^{1/2} )^{1/2} ) $$ where $\mathrm{Tr}$ is the trace operator. It will be nice to know more worked out examples of optimal transport, such as uniform distributions between different geometric objects, e.g. concentric and overlapping balls, between rectangles, etc.","Kuang and Tabak (2017) mentions that: ""closed-form solutions of the multidimensional optimal transport problems are relatively rare, a number of numerical algorithms have been proposed."" I'm wondering if there are some resources (lecture notes, papers, etc.) that collect/contain known solutions to optimal transport and/or Wasserstein distance between two distributions in dimensions greater than 1. For example, let and denote two Gaussian distributions with different means and covariances matrices. Then the optimal transport map between them is: where . And so the Wasserstein 2 distance is where is the trace operator. It will be nice to know more worked out examples of optimal transport, such as uniform distributions between different geometric objects, e.g. concentric and overlapping balls, between rectangles, etc."," \mathcal{N_1}(\mu_1, \Sigma_1)   \mathcal{N_2}(\mu_2, \Sigma_2)   x \longrightarrow \mu_2 + A( x - \mu_1 )   A = \Sigma_1^{- 1/2} (\Sigma_1^{1/2} \Sigma_2 \Sigma_1^{1/2})^{1/2} \Sigma_1^{- 1/2}  W_2 ( \mathcal{N_1}(\mu_1, \Sigma_1), \mathcal{N_2}(\mu_2, \Sigma_2) ) = || \mu_1 - \mu_2 ||^2_2 + \mathrm{Tr}( \Sigma_1 + \Sigma_2 - 2( \Sigma_1^{1/2} \Sigma_2 \Sigma_1^{1/2} )^{1/2} )  \mathrm{Tr}","['probability', 'statistics', 'normal-distribution', 'closed-form', 'optimal-transport']"
4,probablity of random pick up three points inside a regular triangle which form a triangle and contain the center,probablity of random pick up three points inside a regular triangle which form a triangle and contain the center,,what is  the probablity of random pick up three points inside a regular triangle  which form a triangle and contain the center of the regualr triangle the three points are randomly picked within the regular triangle and then form a new triangle and the new triangle have to contain the center of the original regular triangle what is the probability,what is  the probablity of random pick up three points inside a regular triangle  which form a triangle and contain the center of the regualr triangle the three points are randomly picked within the regular triangle and then form a new triangle and the new triangle have to contain the center of the original regular triangle what is the probability,,"['probability', 'triangles', 'geometric-probability']"
5,"What is the largest disk that will be completely covered by randomly placed disks of areas $1,\frac12,\frac13,\dots$ with probability $1$?",What is the largest disk that will be completely covered by randomly placed disks of areas  with probability ?,"1,\frac12,\frac13,\dots 1","On a ""bottom"" disk of area $A$ , we place ""top"" disks of areas $1,\frac12,\frac13,\cdots$ such that the centre of each top disk is an independent uniformly random point on the bottom disk. Find the maximum value of $A$ such that the bottom disk will be completely covered by the top disks with probability $1$ , or show that there is no maximum. The harmonic series diverges, but the problem here is that the top disks overlap, so it is not clear to me whether a bottom disk of a given area will be completely covered by the top disks, with probability $1$ . I made a desmos graph to help visualise the disks. (This question was inspired by a question about rain droplets falling on a table.)","On a ""bottom"" disk of area , we place ""top"" disks of areas such that the centre of each top disk is an independent uniformly random point on the bottom disk. Find the maximum value of such that the bottom disk will be completely covered by the top disks with probability , or show that there is no maximum. The harmonic series diverges, but the problem here is that the top disks overlap, so it is not clear to me whether a bottom disk of a given area will be completely covered by the top disks, with probability . I made a desmos graph to help visualise the disks. (This question was inspired by a question about rain droplets falling on a table.)","A 1,\frac12,\frac13,\cdots A 1 1","['probability', 'sequences-and-series', 'geometry', 'probability-theory', 'circles']"
6,What is the expected number of steps in the following process?,What is the expected number of steps in the following process?,,"We have $n$ boxes. And initially there are $x_1, x_2, x_3, \ldots, x_n$ marbles in each box. We randomly (with equal probabilities) select one of the boxes. We take one marble from it and we put it into another (different from the origin) box chosen randomly (with equal probabilities). We continue this process until one of the boxes become empty. How many operations we do on average? It is not a homework. I don't know whether a closed form solution exists. My current results are: \begin{align}{} x_1 x_2 & \text{ for } n=2\\\ \frac{3x_1 x_2 x_3}{x_1 + x_2 + x_3} & \text{ for } n=3 \end{align} I have crossposted in artofproblemsolving . This problem is related and maybe (or not) useful. Update2: As i learned: this problem has been studied before. As usual :) It seems very hard even for $n=4$. No explicit solution is known, only asymptotics for the case $f(x,x,x,x)$. Nevertheless the solution is much much more easier if we change slightly the problem. For example . Big thanks to Viktor for pointing the reference!","We have $n$ boxes. And initially there are $x_1, x_2, x_3, \ldots, x_n$ marbles in each box. We randomly (with equal probabilities) select one of the boxes. We take one marble from it and we put it into another (different from the origin) box chosen randomly (with equal probabilities). We continue this process until one of the boxes become empty. How many operations we do on average? It is not a homework. I don't know whether a closed form solution exists. My current results are: \begin{align}{} x_1 x_2 & \text{ for } n=2\\\ \frac{3x_1 x_2 x_3}{x_1 + x_2 + x_3} & \text{ for } n=3 \end{align} I have crossposted in artofproblemsolving . This problem is related and maybe (or not) useful. Update2: As i learned: this problem has been studied before. As usual :) It seems very hard even for $n=4$. No explicit solution is known, only asymptotics for the case $f(x,x,x,x)$. Nevertheless the solution is much much more easier if we change slightly the problem. For example . Big thanks to Viktor for pointing the reference!",,['probability']
7,What is the probability of the sum of four dice being 22?,What is the probability of the sum of four dice being 22?,,"Question Four fair six-sided dice are rolled. The probability that the sum of the results being $22$ is $$\frac{X}{1296}.$$ What is the value of $X$ ? My Approach I simplified it to the equation of the form: $x_{1}+x_{2}+x_{3}+x_{4}=22, 1\,\,\leq x_{i} \,\,\leq 6,\,\,1\,\,\leq i \,\,\leq 4 $ Solving this equation results in: $x_{1}+x_{2}+x_{3}+x_{4}=22$ I removed restriction of $x_{i} \geq 1$ first as follows-: $\Rightarrow x_{1}^{'}+1+x_{2}^{'}+1+x_{3}^{'}+1+x_{4}^{'}+1=22$ $\Rightarrow x_{1}^{'}+x_{2}^{'}+x_{3}^{'}+x_{4}^{'}=18$ $\Rightarrow \binom{18+4-1}{18}=1330$ Now i removed restriction for $x_{i} \leq 6$ , by calculating the number of bad cases and then subtracting it from $1330$ : calculating bad combination i.e $x_{i} \geq 7$ $\Rightarrow x_{1}^{'}+x_{2}^{'}+x_{3}^{'}+x_{4}^{'}=18$ We can distribute $7$ to $2$ of $x_{1}^{'},x_{2}^{'},x_{3}^{'},x_{4}^{'}$ i.e $\binom{4}{2}$ We can distribute $7$ to $1$ of $x_{1}^{'},x_{2}^{'},x_{3}^{'},x_{4}^{'}$ i.e $\binom{4}{1}$ and then among all others . i.e $$\binom{4}{1} \binom{14}{11}$$ Therefore, the number of bad combinations equals $$\binom{4}{1} \binom{14}{11}  - \binom{4}{2}$$ Therefore, the solution should be: $$1330-\left( \binom{4}{1} \binom{14}{11} - \binom{4}{2}\right)$$ However, I am getting a negative value. What am I doing wrong? EDIT I am asking for my approach, because if the question is for a larger number of dice and if the sum is higher, then predicting the value of dice will not work.","Question Four fair six-sided dice are rolled. The probability that the sum of the results being is What is the value of ? My Approach I simplified it to the equation of the form: Solving this equation results in: I removed restriction of first as follows-: Now i removed restriction for , by calculating the number of bad cases and then subtracting it from : calculating bad combination i.e We can distribute to of i.e We can distribute to of i.e and then among all others . i.e Therefore, the number of bad combinations equals Therefore, the solution should be: However, I am getting a negative value. What am I doing wrong? EDIT I am asking for my approach, because if the question is for a larger number of dice and if the sum is higher, then predicting the value of dice will not work.","22 \frac{X}{1296}. X x_{1}+x_{2}+x_{3}+x_{4}=22, 1\,\,\leq x_{i} \,\,\leq 6,\,\,1\,\,\leq i \,\,\leq 4  x_{1}+x_{2}+x_{3}+x_{4}=22 x_{i} \geq 1 \Rightarrow x_{1}^{'}+1+x_{2}^{'}+1+x_{3}^{'}+1+x_{4}^{'}+1=22 \Rightarrow x_{1}^{'}+x_{2}^{'}+x_{3}^{'}+x_{4}^{'}=18 \Rightarrow \binom{18+4-1}{18}=1330 x_{i} \leq 6 1330 x_{i} \geq 7 \Rightarrow x_{1}^{'}+x_{2}^{'}+x_{3}^{'}+x_{4}^{'}=18 7 2 x_{1}^{'},x_{2}^{'},x_{3}^{'},x_{4}^{'} \binom{4}{2} 7 1 x_{1}^{'},x_{2}^{'},x_{3}^{'},x_{4}^{'} \binom{4}{1} \binom{4}{1} \binom{14}{11} \binom{4}{1} \binom{14}{11}  - \binom{4}{2} 1330-\left( \binom{4}{1} \binom{14}{11} - \binom{4}{2}\right)","['probability', 'combinatorics', 'dice']"
8,Is this a modified Monty Hall problem (numbered doors)?,Is this a modified Monty Hall problem (numbered doors)?,,"On a job interview, I got this question: Monty placed a car and two goats behind three identical doors (and the things do not move during the game). You receive the prize which is behind the door you picked in the second round. You choose door number 1. Then, Monty opens door number 3 and you see a goat there. If you want to win a car, should you change your guess from door no 1 to door no 2? I answered: YES and was told I was wrong. The interviewer explained me, that the difference between classical MH problem and this problem is that this problem clearly states, that Monty opens door number 3, which reduces the state space and after that my chance is 50/50. I still believe chance of picking right door at first attempt is 1/3 and this probability is not changed by the information that Monty opens door number 3. Am I missing something or was the interviewer wrong?","On a job interview, I got this question: Monty placed a car and two goats behind three identical doors (and the things do not move during the game). You receive the prize which is behind the door you picked in the second round. You choose door number 1. Then, Monty opens door number 3 and you see a goat there. If you want to win a car, should you change your guess from door no 1 to door no 2? I answered: YES and was told I was wrong. The interviewer explained me, that the difference between classical MH problem and this problem is that this problem clearly states, that Monty opens door number 3, which reduces the state space and after that my chance is 50/50. I still believe chance of picking right door at first attempt is 1/3 and this probability is not changed by the information that Monty opens door number 3. Am I missing something or was the interviewer wrong?",,"['probability', 'monty-hall']"
9,Is Scrabble's method of determining turn order fair?,Is Scrabble's method of determining turn order fair?,,"At least the way my family plays, turn order is determined by drawing tiles and seeing who has the letter closest to A (blanks taking precedence). If I recall correctly, there are 100 unevenly distributed letters. Intuitively, it seems like it would be unfair, though I can't come up with a way to prove it. Obviously the distribution matters: my thoughts are if there are more tiles in the first half of the alphabet (including blanks), then the starting player holds an advantage since they're more likely to get a tile earlier in the alphabet than the next (and vice versa if there are fewer tiles in the first half). That doesn't seem too right, though. I'm probably just forgetting some basic prob stats. I imagine this is likely a duplicate, but I couldn't find anything relating to it (maybe since I've been searching for Scrabble). My apologies if it is. Please feel free to edit in appropriate tags.","At least the way my family plays, turn order is determined by drawing tiles and seeing who has the letter closest to A (blanks taking precedence). If I recall correctly, there are 100 unevenly distributed letters. Intuitively, it seems like it would be unfair, though I can't come up with a way to prove it. Obviously the distribution matters: my thoughts are if there are more tiles in the first half of the alphabet (including blanks), then the starting player holds an advantage since they're more likely to get a tile earlier in the alphabet than the next (and vice versa if there are fewer tiles in the first half). That doesn't seem too right, though. I'm probably just forgetting some basic prob stats. I imagine this is likely a duplicate, but I couldn't find anything relating to it (maybe since I've been searching for Scrabble). My apologies if it is. Please feel free to edit in appropriate tags.",,"['probability', 'recreational-mathematics']"
10,Intuition behind the Definition of Conditional Probability (for 2 Events),Intuition behind the Definition of Conditional Probability (for 2 Events),,"What is some intuitive insight regarding the conditional probability definition: $P(A\mid B) = \large \frac{P(A \cap B)}{P(B)}$ ? I am looking for an intuitive motivation. My textbook merely gives a definition, but no true development of that definition. Hopefully that's not too much to ask.","What is some intuitive insight regarding the conditional probability definition: $P(A\mid B) = \large \frac{P(A \cap B)}{P(B)}$ ? I am looking for an intuitive motivation. My textbook merely gives a definition, but no true development of that definition. Hopefully that's not too much to ask.",,"['probability', 'soft-question', 'intuition']"
11,Is there a meaningful example of probability of $\frac1\pi$?,Is there a meaningful example of probability of ?,\frac1\pi,"A large portion of combinatorics cases have probabilities of $\frac1e$. Secretary problem is one of such examples. Excluding trivial cases (a variable has a uniform distribution over $(0,\pi)$ - what is the probability for the value to be below $1$?). I can't recall any example where $\frac1\pi$ would be a solution to a probability problem. Are there ""meaningful"" probability theory case with probability approaching $\frac1\pi$?","A large portion of combinatorics cases have probabilities of $\frac1e$. Secretary problem is one of such examples. Excluding trivial cases (a variable has a uniform distribution over $(0,\pi)$ - what is the probability for the value to be below $1$?). I can't recall any example where $\frac1\pi$ would be a solution to a probability problem. Are there ""meaningful"" probability theory case with probability approaching $\frac1\pi$?",,"['probability', 'combinatorics']"
12,Can you pick a random natural number? And a random real number?,Can you pick a random natural number? And a random real number?,,Is it possible to pick a random natural number? How about a random real number? Is the axiom of choice involved in this?,Is it possible to pick a random natural number? How about a random real number? Is the axiom of choice involved in this?,,['probability']
13,Average length of the longest segment,Average length of the longest segment,,"This post is related to a previous SE post If a 1 meter rope …. concerning average length of a smallest segment. A rope of 1m is divided into three pieces by two random points. Find the average length of the largest segment. My answer is 11/18.  Here is how I do it: Here we have two independent random variables $X,Y$, both uniform on $[0,1]$. Let  $A=\min (X,Y), B=\max (X,Y)$ and $C=\max (A, 1-B, B-A)$. First we want to find the probability density function $f_C(a)$ of $C$. Let $F_C(a)$ be the cumulative distribution function. Then $$ F_C(a) = P(C\le a)=P(A\le a, 1-B\le a, B-A\le a).$$  By rewriting this probability as area in the unit square, I get $$F_C(a)=\left\{\begin{array}{ll} (3a-1)^2 & \frac{1}{3}\le a\le \frac{1}{2}\\ 1-3(1-a)^2 & \frac{1}{2}\le a\le 1\end{array}\right.$$ from which it follows that  $$f_C(a)=\left\{\begin{array}{ll} 6(3a-1) & \frac{1}{3}\le a\le \frac{1}{2}\\ 6(1-a) & \frac{1}{2}\le a\le 1\end{array}\right.$$ Therefore the expected value of $C$ is $$\int_{1/3} ^{1/2}6a(3a-1) da+\int_{1/2} ^{1}6a(1-a) da= \frac{11}{18}.$$ My questions are: (A) Is there a ""clever"" way to figure out this number 11/18? (B) What is the answer if the rope is divided into $n>3$ segments?","This post is related to a previous SE post If a 1 meter rope …. concerning average length of a smallest segment. A rope of 1m is divided into three pieces by two random points. Find the average length of the largest segment. My answer is 11/18.  Here is how I do it: Here we have two independent random variables $X,Y$, both uniform on $[0,1]$. Let  $A=\min (X,Y), B=\max (X,Y)$ and $C=\max (A, 1-B, B-A)$. First we want to find the probability density function $f_C(a)$ of $C$. Let $F_C(a)$ be the cumulative distribution function. Then $$ F_C(a) = P(C\le a)=P(A\le a, 1-B\le a, B-A\le a).$$  By rewriting this probability as area in the unit square, I get $$F_C(a)=\left\{\begin{array}{ll} (3a-1)^2 & \frac{1}{3}\le a\le \frac{1}{2}\\ 1-3(1-a)^2 & \frac{1}{2}\le a\le 1\end{array}\right.$$ from which it follows that  $$f_C(a)=\left\{\begin{array}{ll} 6(3a-1) & \frac{1}{3}\le a\le \frac{1}{2}\\ 6(1-a) & \frac{1}{2}\le a\le 1\end{array}\right.$$ Therefore the expected value of $C$ is $$\int_{1/3} ^{1/2}6a(3a-1) da+\int_{1/2} ^{1}6a(1-a) da= \frac{11}{18}.$$ My questions are: (A) Is there a ""clever"" way to figure out this number 11/18? (B) What is the answer if the rope is divided into $n>3$ segments?",,['probability']
14,How to prove: Moment Generating Function Uniqueness Theorem,How to prove: Moment Generating Function Uniqueness Theorem,,"Many results are based on the fact of the Moment Generating Function (MGF) Uniqueness Theorem, that says: If $X$ and $Y$ are two random variables and equality holds for their MGF's: $m_X(t) = m_Y(t)$ then $X$ and $Y$ have the same probability distribution: $F_X(x) = F_Y(y)$. The proof of this theorem is never shown in textbooks, and I cannot seem to find it online or in any book I have access to. Can someone show me the proof or tell me where to look it up? Thanks for your time.","Many results are based on the fact of the Moment Generating Function (MGF) Uniqueness Theorem, that says: If $X$ and $Y$ are two random variables and equality holds for their MGF's: $m_X(t) = m_Y(t)$ then $X$ and $Y$ have the same probability distribution: $F_X(x) = F_Y(y)$. The proof of this theorem is never shown in textbooks, and I cannot seem to find it online or in any book I have access to. Can someone show me the proof or tell me where to look it up? Thanks for your time.",,"['probability', 'functions', 'moment-generating-functions']"
15,Average distance between two randomly chosen points in unit square (without calculus),Average distance between two randomly chosen points in unit square (without calculus),,"Imagine that you choose two random points within a 1 by 1 square.  What is the average distance between those two points?  Using a random number generator, I'm getting a value of ~0.521402... can anyone explain why I'm getting this value, or what this number means? More importantly , is there a way to solve this without using calculus and/or large random sampling?","Imagine that you choose two random points within a 1 by 1 square.  What is the average distance between those two points?  Using a random number generator, I'm getting a value of ~0.521402... can anyone explain why I'm getting this value, or what this number means? More importantly , is there a way to solve this without using calculus and/or large random sampling?",,"['probability', 'geometry', 'statistics']"
16,Bayes' Theorem with multiple random variables,Bayes' Theorem with multiple random variables,,"I'm reviewing some notes regarding probability, and the section regarding Conditional Probability gives the following example: $P(X,Y|Z)=\frac{P(Z|X,Y)P(X,Y)}{P(Z)}=\frac{P(Y,Z|X)P(X)}{P(Z)}$ The middle expression is clearly just the application of Bayes' Theorem, but I can't see how the third expression is equal to the second.  Can someone please clarify how the two are equal?","I'm reviewing some notes regarding probability, and the section regarding Conditional Probability gives the following example: $P(X,Y|Z)=\frac{P(Z|X,Y)P(X,Y)}{P(Z)}=\frac{P(Y,Z|X)P(X)}{P(Z)}$ The middle expression is clearly just the application of Bayes' Theorem, but I can't see how the third expression is equal to the second.  Can someone please clarify how the two are equal?",,"['probability', 'conditional-probability', 'bayes-theorem']"
17,What is the distribution of a random variable that is the product of two normal random variables?,What is the distribution of a random variable that is the product of two normal random variables?,,"What is the distribution of a random variable that is the product of two normal random variables? Let $X\sim N(\mu_1,\sigma_1),  Y\sim N(\mu_2,\sigma_2)$ and $Z=XY$ That is, what is its probability density function, its expected value, and its variance?","What is the distribution of a random variable that is the product of two normal random variables? Let and That is, what is its probability density function, its expected value, and its variance?","X\sim N(\mu_1,\sigma_1),  Y\sim N(\mu_2,\sigma_2) Z=XY",['probability']
18,Invert the softmax function,Invert the softmax function,,"Is it possible to revert the softmax function in order to obtain the original values $x_i$ ? $$S_i=\frac{e^{x_i}}{\sum e^{x_i}} $$ In case of 3 input variables this problem boils down to finding $a$ , $b$ , $c$ given $x$ , $y$ and $z$ : \begin{cases} \frac{a}{a+b+c} &= x \\ \frac{b}{a+b+c} &= y \\ \frac{c}{a+b+c} &= z \end{cases} Is this problem solvable?","Is it possible to revert the softmax function in order to obtain the original values ? In case of 3 input variables this problem boils down to finding , , given , and : Is this problem solvable?","x_i S_i=\frac{e^{x_i}}{\sum e^{x_i}}  a b c x y z \begin{cases}
\frac{a}{a+b+c} &= x \\
\frac{b}{a+b+c} &= y \\
\frac{c}{a+b+c} &= z
\end{cases}","['probability', 'exponential-function', 'machine-learning', 'logistic-regression']"
19,Secretary problem - why is the optimal solution optimal?,Secretary problem - why is the optimal solution optimal?,,"I have read about this problem: http://en.wikipedia.org/wiki/Secretary_problem But I want to see how it is proven that the ""optimal"" solution is indeed optimal. I understand how to prove that if the optimal solution is of the form ""wait for $t$ candidates and then choose the next best one"" then $t=n/e$ is optimal; but why is the best strategy of that form in the first place? A complete proof is not required - a reference to a good text discussing this is good as well.","I have read about this problem: http://en.wikipedia.org/wiki/Secretary_problem But I want to see how it is proven that the ""optimal"" solution is indeed optimal. I understand how to prove that if the optimal solution is of the form ""wait for $t$ candidates and then choose the next best one"" then $t=n/e$ is optimal; but why is the best strategy of that form in the first place? A complete proof is not required - a reference to a good text discussing this is good as well.",,"['probability', 'game-theory']"
20,What is the intuition behind the Poisson distribution's function?,What is the intuition behind the Poisson distribution's function?,,"I'm trying to intuitively understand the Poisson distribution's probability mass function. When $X \sim \mathrm{Pois}(\lambda)$, then $P(X=k)=\frac{\lambda^k e^{-k}}{k!}$, but I don't see the reasoning behind this formula. In other discrete distributions, namely the binomial, geometric, negative binomial, and hypergeometric distributions, I have an intuitive, combinatorics-based understanding of why each distribution's pmf is defined the way it is. That is, if $Y \sim\mathrm{Bin}(n,p)$ then $P(Y=k)=\binom{n}{k}p^k(1-p)^{n-k}$, and this equation is clear - there are $\binom{n}{k}$ ways to choose the $k$ successful trials, and we need the trials to succeed $k$ times and fail $n-k$ times. What is the corresponding intuition for the Poisson distribution?","I'm trying to intuitively understand the Poisson distribution's probability mass function. When $X \sim \mathrm{Pois}(\lambda)$, then $P(X=k)=\frac{\lambda^k e^{-k}}{k!}$, but I don't see the reasoning behind this formula. In other discrete distributions, namely the binomial, geometric, negative binomial, and hypergeometric distributions, I have an intuitive, combinatorics-based understanding of why each distribution's pmf is defined the way it is. That is, if $Y \sim\mathrm{Bin}(n,p)$ then $P(Y=k)=\binom{n}{k}p^k(1-p)^{n-k}$, and this equation is clear - there are $\binom{n}{k}$ ways to choose the $k$ successful trials, and we need the trials to succeed $k$ times and fail $n-k$ times. What is the corresponding intuition for the Poisson distribution?",,"['probability', 'intuition']"
21,Expert Minesweeper Probability Question,Expert Minesweeper Probability Question,,"This is just a question I thought of while playing minesweeper. I think that finding the solution might be kind of fun, so I'm sharing it with you guys. If you have no concept of what minesweeper is, this question might be kind of tough. Also, if you have no concept of what minesweeper is go play it. It's fun. It's an expert board. That means you have a grid of 16 by 30, for a total of 480 squares. A random 99 of these squares have a mine hidden under them. When you click a square, three things can happen. You can click a mine, resulting in an instant loss. You can click on a square next (diagonal included) to at least one mine, resulting in a number being shown under the square. Or you can click on a square that isn't a mine and isn't next. When this is done, all 8 surrounding squares are revealed. If any of those squares are also not next to any mines, all of the surrounding squares that are not yet revealed become revealed. That should make sense if you've played minesweeper before. You're playing expert mode. The mines are spread randomly. What is the average number of squares revealed by your first click? I would count clicking a mine as 0 squares revealed. Have fun!","This is just a question I thought of while playing minesweeper. I think that finding the solution might be kind of fun, so I'm sharing it with you guys. If you have no concept of what minesweeper is, this question might be kind of tough. Also, if you have no concept of what minesweeper is go play it. It's fun. It's an expert board. That means you have a grid of 16 by 30, for a total of 480 squares. A random 99 of these squares have a mine hidden under them. When you click a square, three things can happen. You can click a mine, resulting in an instant loss. You can click on a square next (diagonal included) to at least one mine, resulting in a number being shown under the square. Or you can click on a square that isn't a mine and isn't next. When this is done, all 8 surrounding squares are revealed. If any of those squares are also not next to any mines, all of the surrounding squares that are not yet revealed become revealed. That should make sense if you've played minesweeper before. You're playing expert mode. The mines are spread randomly. What is the average number of squares revealed by your first click? I would count clicking a mine as 0 squares revealed. Have fun!",,"['probability', 'recreational-mathematics']"
22,Understanding The Math Behind Elchanan Mossel’s Dice Paradox,Understanding The Math Behind Elchanan Mossel’s Dice Paradox,,"So earlier today I came across Elchanan Mossel's Dice Paradox , and I am having some trouble understanding the solution. The question is as follows: You throw a fair six-sided die until you get 6. What is the expected   number of throws (including the throw giving 6) conditioned on the event   that all throws gave even numbers? Quoted from Jimmy Jin in ""Elchanan Mossel’s dice problem"" In the paper it goes on to state why a common wrong answer is $3$. Then afterwards explains that this problem has the same answer to, ""What is the expected number of times you can roll only $2$’s or $4$’s until you roll any other number?"" I don't understand why this is the case. If the original problem is asking for specifically a $6$, shouldn't that limit many of the possible sequences? I also attempted to solve the problem using another method, but got an answer different from both $3$ and the correct answer of $1.5$. I saw that possible sequences could have been something like: $$\{6\}$$ $$\{2,6\}, \{4,6\}$$ $$\{2,2,6\}, \{2,4,6\}, \{4,2,6\}, \{4,4,6\}$$ $$\vdots$$ To which I set up the following summation and solved using Wolfram Alpha : $$\text{Expected Value} =\sum_{n=1}^\infty n\left( {\frac{1}{6}} \right)^n 2^{n-1} = 0.375$$ Obviously this is different and probably incorrect, but I can't figure out where the error in the thought process is. Any help on understanding this would be greatly appreciated. A blog post discussing the problem can be found here.","So earlier today I came across Elchanan Mossel's Dice Paradox , and I am having some trouble understanding the solution. The question is as follows: You throw a fair six-sided die until you get 6. What is the expected   number of throws (including the throw giving 6) conditioned on the event   that all throws gave even numbers? Quoted from Jimmy Jin in ""Elchanan Mossel’s dice problem"" In the paper it goes on to state why a common wrong answer is $3$. Then afterwards explains that this problem has the same answer to, ""What is the expected number of times you can roll only $2$’s or $4$’s until you roll any other number?"" I don't understand why this is the case. If the original problem is asking for specifically a $6$, shouldn't that limit many of the possible sequences? I also attempted to solve the problem using another method, but got an answer different from both $3$ and the correct answer of $1.5$. I saw that possible sequences could have been something like: $$\{6\}$$ $$\{2,6\}, \{4,6\}$$ $$\{2,2,6\}, \{2,4,6\}, \{4,2,6\}, \{4,4,6\}$$ $$\vdots$$ To which I set up the following summation and solved using Wolfram Alpha : $$\text{Expected Value} =\sum_{n=1}^\infty n\left( {\frac{1}{6}} \right)^n 2^{n-1} = 0.375$$ Obviously this is different and probably incorrect, but I can't figure out where the error in the thought process is. Any help on understanding this would be greatly appreciated. A blog post discussing the problem can be found here.",,"['probability', 'conditional-expectation', 'means']"
23,Exact probability of random graph being connected,Exact probability of random graph being connected,,"The problem: I'm trying to find the probability of a random undirected graph being connected. I'm using the model $G(n,p)$, where there are at most $n(n-1) \over 2$ edges (no self-loops or duplicate edges) and each edge has a probability $p$ of existing. I found a simple formula online  where $f(n)$ is the probability of $G(n,p)$ being connected. But apparently it's too trivial for the writer to explain the formula (it was just stated briefly). The desired formula: $f(n) = 1-\sum\limits_{i=1}^{n-1}f(i){n-1 \choose i-1}(1-p)^{i(n-i)}$ My method is: Consider any vertex $v$. Then there's a probability ${n-1 \choose i}p^i(1-p)^{n-1-i}$ that it will have $i$ neighbours. After connecting $v$ to these $i$ neighbours, we contract them ($v$ and its neighbours) into a single connected component, so we are left with the problem of $n-i$ vertices (the connected component plus $n-i-1$ other ""normal"" vertices. Except that now the probability of the vertex representing connected component being connected to any other vertex is $1-(1-p)^i$. So I introduced another parameter $s$ into the formula, giving us: $g(n,s)=\sum\limits_{i=1}^{n-1}g(n-i,i){n-1 \choose i}q^i(1-q)^{n-1-i}$, where $q=1-(1-p)^s$. Then $f(n)=g(n,1)$. But this is nowhere as simple as the mentioned formula, as it has an additional parameter... Can someone explain how the formula $f(n)$ is obtained? Thanks!","The problem: I'm trying to find the probability of a random undirected graph being connected. I'm using the model $G(n,p)$, where there are at most $n(n-1) \over 2$ edges (no self-loops or duplicate edges) and each edge has a probability $p$ of existing. I found a simple formula online  where $f(n)$ is the probability of $G(n,p)$ being connected. But apparently it's too trivial for the writer to explain the formula (it was just stated briefly). The desired formula: $f(n) = 1-\sum\limits_{i=1}^{n-1}f(i){n-1 \choose i-1}(1-p)^{i(n-i)}$ My method is: Consider any vertex $v$. Then there's a probability ${n-1 \choose i}p^i(1-p)^{n-1-i}$ that it will have $i$ neighbours. After connecting $v$ to these $i$ neighbours, we contract them ($v$ and its neighbours) into a single connected component, so we are left with the problem of $n-i$ vertices (the connected component plus $n-i-1$ other ""normal"" vertices. Except that now the probability of the vertex representing connected component being connected to any other vertex is $1-(1-p)^i$. So I introduced another parameter $s$ into the formula, giving us: $g(n,s)=\sum\limits_{i=1}^{n-1}g(n-i,i){n-1 \choose i}q^i(1-q)^{n-1-i}$, where $q=1-(1-p)^s$. Then $f(n)=g(n,1)$. But this is nowhere as simple as the mentioned formula, as it has an additional parameter... Can someone explain how the formula $f(n)$ is obtained? Thanks!",,"['probability', 'graph-theory', 'recurrence-relations']"
24,"On average, how many times must a circular pizza be randomly cut, to get a piece with no curved edge?","On average, how many times must a circular pizza be randomly cut, to get a piece with no curved edge?",,"On a circular pizza, we make a random straight cut by choosing two uniformly random points on the perimeter and cutting through them. On average, how many times must the pizza be randomly cut, to get a piece with no curved edge? (In other words, on average, how many random chords must be drawn on a circle, to get a polygon, if each random chord is drawn by connecting two uniformly random points on the perimeter of the circle?) In the following example, a piece with no curved edge is obtained by the fifth random cut. My attempt I made a pizza cutting simulator on desmos. It seems that the average should be around $7$ or so. I tried to find the probability that a piece with no curved edge is obtained by the $n$ th random cut. But I only worked out that the probability for $n=3$ , is $\frac{1}{15}$ . (Consider the six points that define three cuts. Start with one point: it must be paired with its opposite point, which has probability $\frac15$ . Then one of the remaining points must be paired with its opposite point, which has probability $\frac13$ . The remaining two points must be paired together. So the probability is $\frac15\times\frac13=\frac{1}{15}$ .)","On a circular pizza, we make a random straight cut by choosing two uniformly random points on the perimeter and cutting through them. On average, how many times must the pizza be randomly cut, to get a piece with no curved edge? (In other words, on average, how many random chords must be drawn on a circle, to get a polygon, if each random chord is drawn by connecting two uniformly random points on the perimeter of the circle?) In the following example, a piece with no curved edge is obtained by the fifth random cut. My attempt I made a pizza cutting simulator on desmos. It seems that the average should be around or so. I tried to find the probability that a piece with no curved edge is obtained by the th random cut. But I only worked out that the probability for , is . (Consider the six points that define three cuts. Start with one point: it must be paired with its opposite point, which has probability . Then one of the remaining points must be paired with its opposite point, which has probability . The remaining two points must be paired together. So the probability is .)",7 n n=3 \frac{1}{15} \frac15 \frac13 \frac15\times\frac13=\frac{1}{15},"['probability', 'combinatorics', 'expected-value', 'circles', 'hypergeometric-function']"
25,"What is the probability that a random walk on $\mathbb{Z}^2$ will hit $(1,0)$ before $(2,0)$?",What is the probability that a random walk on  will hit  before ?,"\mathbb{Z}^2 (1,0) (2,0)","Suppose we have a 2-dimensional simple random walk: we start at $(0,0)$ , and at every step, we add a random unit vector in one of the four cardinal directions selected independently and uniformly. It is well-known that this procedure will with probability $1$ hit every element of $\mathbb{Z}^2$ infinitely often. Thus, it makes sense to ask about the probability that such a walk will hit $(1,0)$ before $(2,0)$ . Running some Monte Carlo simulations, it looks like the walk first lands on $(1,0)$ something like $70\%$ of the time, but I don't have much confidence about the accuracy of these simulations since I cannot actually run them all to completion and have to either throw out the unfinished trials or make a guess as to how they will conclude. Some more precise simulations show that the walk first lands on $(1,0)$ with probability at least $0.607$ and on $(2,0)$ with probability at least $0.153$ . Is there a known exact value for this probability, and how can it be computed in general for any two points on the square lattice? I'm also interested in a general formula for the probability of encountering $n$ points in a given order.","Suppose we have a 2-dimensional simple random walk: we start at , and at every step, we add a random unit vector in one of the four cardinal directions selected independently and uniformly. It is well-known that this procedure will with probability hit every element of infinitely often. Thus, it makes sense to ask about the probability that such a walk will hit before . Running some Monte Carlo simulations, it looks like the walk first lands on something like of the time, but I don't have much confidence about the accuracy of these simulations since I cannot actually run them all to completion and have to either throw out the unfinished trials or make a guess as to how they will conclude. Some more precise simulations show that the walk first lands on with probability at least and on with probability at least . Is there a known exact value for this probability, and how can it be computed in general for any two points on the square lattice? I'm also interested in a general formula for the probability of encountering points in a given order.","(0,0) 1 \mathbb{Z}^2 (1,0) (2,0) (1,0) 70\% (1,0) 0.607 (2,0) 0.153 n","['probability', 'random-walk']"
26,throwing a $k$-sided dice until you get every face the same number of times,throwing a -sided dice until you get every face the same number of times,k,"You throw a fair $k$ -sided dice repeatedly and keep track of all the results. You stop if you have seen every face exactly the same number of times. What is the expected number of times you have to throw the dice? Is that number even finite? Start with the simplest example of a $2$ -sided dice, ie a fair coin. There is a 50% chance that after 2 flips you will have one head and one tail so you stop. There is a 12.5% chance that after 2 flips you will be at 2:0 and continue but after 4 flips you will be at 2:2, so you stop. One can compute a few more terms but I don't see enough of a pattern to get a summable series. It is not too hard to compute the probability that after $k\cdot m$ throws of a $k$ -sided dice you get every face exactly $m$ times but these probabilities are not independent for different $m$ so I'm not sure whether that is helpful. The relation to random walks looks useful. One can map the results of throwing a coin repeatedly to a random work on the integers. Seeing the same number of heads and tails is equivalent to coming back to the starting point (at zero). This is a well studied problem and it is known that you come back to zero with probability one in a finite time. The number I'm looking for would be the expected time when you get back to zero for the first time but I haven't found any results on that. For $k$ bigger than $2$ (and even) the mapping to random walks is not bijective anymore. If you map the outcome of a $6$ -sided dice throw to a random walk on the $3$ -dimensional integer lattice with each face corresponding to a step in one of the 6 directions that a return to the origin is necessary but not sufficient for having seen each face the same number of times. However, it is known that for a random walk on the integer lattice in dimension of at least $3$ , the chance to return to the origin in finite time is strictly smaller than $1$ . So this should prove that for a dice with at least $6$ faces, the expected number of throws is not finite. Is this a finite number for $k=2$ and $k$ between $3$ and $5$ ? Are there estimates for it?","You throw a fair -sided dice repeatedly and keep track of all the results. You stop if you have seen every face exactly the same number of times. What is the expected number of times you have to throw the dice? Is that number even finite? Start with the simplest example of a -sided dice, ie a fair coin. There is a 50% chance that after 2 flips you will have one head and one tail so you stop. There is a 12.5% chance that after 2 flips you will be at 2:0 and continue but after 4 flips you will be at 2:2, so you stop. One can compute a few more terms but I don't see enough of a pattern to get a summable series. It is not too hard to compute the probability that after throws of a -sided dice you get every face exactly times but these probabilities are not independent for different so I'm not sure whether that is helpful. The relation to random walks looks useful. One can map the results of throwing a coin repeatedly to a random work on the integers. Seeing the same number of heads and tails is equivalent to coming back to the starting point (at zero). This is a well studied problem and it is known that you come back to zero with probability one in a finite time. The number I'm looking for would be the expected time when you get back to zero for the first time but I haven't found any results on that. For bigger than (and even) the mapping to random walks is not bijective anymore. If you map the outcome of a -sided dice throw to a random walk on the -dimensional integer lattice with each face corresponding to a step in one of the 6 directions that a return to the origin is necessary but not sufficient for having seen each face the same number of times. However, it is known that for a random walk on the integer lattice in dimension of at least , the chance to return to the origin in finite time is strictly smaller than . So this should prove that for a dice with at least faces, the expected number of throws is not finite. Is this a finite number for and between and ? Are there estimates for it?",k 2 k\cdot m k m m k 2 6 3 3 1 6 k=2 k 3 5,"['probability', 'elementary-number-theory']"
27,Brownian motion and Beta distribution,Brownian motion and Beta distribution,,"I am interested in the distribution of the time that the standard Brownian $W_t$ motion on $[0,1]$ satisfies the following inequality: $$W_t \ge stW(1)$$ For different values of $s$ . I conjecture that the distribution is always a Beta distribution with both parameters equal (if they are Beta distributed they have to be equal because by symmetry the expected value of this time should be equal to $\frac{1}{2}$ . There are two special cases in which I can tell that the above is true: if $s=0$ then we have the usual question about the distribution of time BM spends above the $x$ -axis in which case the answer is the $B(\frac{1}{2},\frac{1}{2})$ distribution. If $s=1$ the inequality can be transformed into: $$B_t=W_t-tW(1) \ge 0$$ Which asks about the distribution of the time that the Brownian bridge spends above the $x$ -axis in which case the answer is $B(1,1)$ - the uniform distribution. From the simulation I have conducted it seems that the result is true in general with $1$ being the highest parameter value. However, I don't have any proof nor any clue how to proceed.","I am interested in the distribution of the time that the standard Brownian motion on satisfies the following inequality: For different values of . I conjecture that the distribution is always a Beta distribution with both parameters equal (if they are Beta distributed they have to be equal because by symmetry the expected value of this time should be equal to . There are two special cases in which I can tell that the above is true: if then we have the usual question about the distribution of time BM spends above the -axis in which case the answer is the distribution. If the inequality can be transformed into: Which asks about the distribution of the time that the Brownian bridge spends above the -axis in which case the answer is - the uniform distribution. From the simulation I have conducted it seems that the result is true in general with being the highest parameter value. However, I don't have any proof nor any clue how to proceed.","W_t [0,1] W_t \ge stW(1) s \frac{1}{2} s=0 x B(\frac{1}{2},\frac{1}{2}) s=1 B_t=W_t-tW(1) \ge 0 x B(1,1) 1","['probability', 'probability-theory', 'probability-distributions', 'brownian-motion']"
28,Probability of selecting an even natural number from the set $\Bbb N$.,Probability of selecting an even natural number from the set .,\Bbb N,"I confirmed on this thread that there are as many as even natural numbers as there are natural numbers. Question : Suppose I have selected a number $n \in \mathbb N$ ; what is the probability that $n$ is even? My Thought : $\text{Probability} = \dfrac{\text{n(E)}}{\text{n(S)}}$ Here $\text{n(S)}$ is the set of all natural numbers i.e. $\mathbb N$ , and $\text{n(E)}$ is set of all even natural numbers. Since it is proved that number of elements is the set $\mathbb N$ is exactly the same as the number of elements in the set of natural numbers (it’s very easy to put the set of natural numbers, $\Bbb N=\{0,1,2,3,\dots\}$ , into one-to-one correspondence with the set $\text{E}=\{0,2,4,6,\dots\}$ of even natural numbers; the map $\Bbb N\to \text{E}:n\mapsto 2n$ is clearly a bijection.) ; Thus, Probability $= \boxed 1$ I know this is definitely wrong.Probability must be $0.5$ . But where am I wrong? Can anyone explain ? Thanks!","I confirmed on this thread that there are as many as even natural numbers as there are natural numbers. Question : Suppose I have selected a number ; what is the probability that is even? My Thought : Here is the set of all natural numbers i.e. , and is set of all even natural numbers. Since it is proved that number of elements is the set is exactly the same as the number of elements in the set of natural numbers (it’s very easy to put the set of natural numbers, , into one-to-one correspondence with the set of even natural numbers; the map is clearly a bijection.) ; Thus, Probability I know this is definitely wrong.Probability must be . But where am I wrong? Can anyone explain ? Thanks!","n \in \mathbb N n \text{Probability} = \dfrac{\text{n(E)}}{\text{n(S)}} \text{n(S)} \mathbb N \text{n(E)} \mathbb N \Bbb N=\{0,1,2,3,\dots\} \text{E}=\{0,2,4,6,\dots\} \Bbb N\to \text{E}:n\mapsto 2n = \boxed 1 0.5","['probability', 'infinity', 'infinite-groups']"
29,"Independent odds, am I (+ friend) seeing this wrong or is there a mistake in the practice exam?","Independent odds, am I (+ friend) seeing this wrong or is there a mistake in the practice exam?",,"I found this exercise in a practice exam: Any student has a 90% chance of entering a University. Two students   are applying. Assuming each student’s results are independent, what is   the probability that at least one of them will be successful in   entering the National University? A. $0.50$ B. $0.65$ C. $0.88$ D. $0.90$ E. $0.96$ I think the answer is something different than the answers above, namely $0.99$. $0.01 = (0.1 \times 0.1)$ is the chance of neither, so $1 - 0.01$ must be $0.99$ right? But it's not part of the possible answers. Other way: $(0.9 \times 0.9) + (0.9 \times 0.1) + (0.1 \times 0.9) = 0.99$ Am I missing something here?","I found this exercise in a practice exam: Any student has a 90% chance of entering a University. Two students   are applying. Assuming each student’s results are independent, what is   the probability that at least one of them will be successful in   entering the National University? A. $0.50$ B. $0.65$ C. $0.88$ D. $0.90$ E. $0.96$ I think the answer is something different than the answers above, namely $0.99$. $0.01 = (0.1 \times 0.1)$ is the chance of neither, so $1 - 0.01$ must be $0.99$ right? But it's not part of the possible answers. Other way: $(0.9 \times 0.9) + (0.9 \times 0.1) + (0.1 \times 0.9) = 0.99$ Am I missing something here?",,['probability']
30,A gambler with the devil's luck?,A gambler with the devil's luck?,,"A gambler with $1$ dollar intends to make repeated bets of $1$ dollar until he wins $20$ dollars or is ruined. Probabilities of  win/loss are $p$ and $(1-p)$, and each bet brings a gain/loss of $1$ dollar. Unfortunately, the devil is active, and ensures that every time he reaches $19, he loses! Obviously, the poor guy will get ruined sooner or later! The question is, what is the expected number of bets he makes until he is ruined?","A gambler with $1$ dollar intends to make repeated bets of $1$ dollar until he wins $20$ dollars or is ruined. Probabilities of  win/loss are $p$ and $(1-p)$, and each bet brings a gain/loss of $1$ dollar. Unfortunately, the devil is active, and ensures that every time he reaches $19, he loses! Obviously, the poor guy will get ruined sooner or later! The question is, what is the expected number of bets he makes until he is ruined?",,"['probability', 'combinatorics', 'recreational-mathematics']"
31,Drunkard's walk on the $n^{th}$ roots of unity.,Drunkard's walk on the  roots of unity.,n^{th},"Fix an integer $n\geq 2$.  Suppose we start at the origin in the complex plane, and on each step we choose an $n^{th}$ root of unity at random, and go $1$ unit distance in that direction.  Let $X_N$ be distance from the origin after the $N^{th}$ step.  How well can we bound $E(X_N)$ from above? In my attempt to calculate this, I found the bound $\sqrt{N}$, but I have a feeling this could be wrong because the problem I am applying this to has instead $\sqrt{N\log N}$.  (This reasoning is based on the belief that the problem is likely optimal)  What I did was apply Cauchy Schwarz to get a sum with the norm squared, and then try to do some manipulations from there, relying on the fact that the sum of the vectors (not the distance) is zero by symmetry.","Fix an integer $n\geq 2$.  Suppose we start at the origin in the complex plane, and on each step we choose an $n^{th}$ root of unity at random, and go $1$ unit distance in that direction.  Let $X_N$ be distance from the origin after the $N^{th}$ step.  How well can we bound $E(X_N)$ from above? In my attempt to calculate this, I found the bound $\sqrt{N}$, but I have a feeling this could be wrong because the problem I am applying this to has instead $\sqrt{N\log N}$.  (This reasoning is based on the belief that the problem is likely optimal)  What I did was apply Cauchy Schwarz to get a sum with the norm squared, and then try to do some manipulations from there, relying on the fact that the sum of the vectors (not the distance) is zero by symmetry.",,"['probability', 'stochastic-processes', 'markov-chains', 'roots-of-unity']"
32,Why do we ask for *absolute* convergence of a series to define the mean of a discrete random variable?,Why do we ask for *absolute* convergence of a series to define the mean of a discrete random variable?,,"If $X$ is a discrete random variable that can take the values $x_1, x_2, \dots $ and with probability mass function $f_X$ , then we define its mean by the number $$\sum x_i f_X(x_i) $$ (1) when the series above is absolutely convergent . That's the definition of mean value of a discrete r.v. I've encountered in my books ( Introduction to the Theory of Statistics by Mood A., Probability and Statistics by DeGroot M.). I know that if a series is absolute convergent then it is convergent, but why do we need to ask for the series (1) to converge absolutely, instead of just asking it to converge? I'm taking my introductory courses of probabilty and so far I haven't found a situation that forces us restrict ourselves this way. Any comments about the subject are appreciated.","If is a discrete random variable that can take the values and with probability mass function , then we define its mean by the number (1) when the series above is absolutely convergent . That's the definition of mean value of a discrete r.v. I've encountered in my books ( Introduction to the Theory of Statistics by Mood A., Probability and Statistics by DeGroot M.). I know that if a series is absolute convergent then it is convergent, but why do we need to ask for the series (1) to converge absolutely, instead of just asking it to converge? I'm taking my introductory courses of probabilty and so far I haven't found a situation that forces us restrict ourselves this way. Any comments about the subject are appreciated.","X x_1, x_2, \dots  f_X \sum x_i f_X(x_i) ","['probability', 'probability-distributions', 'convergence-divergence', 'absolute-convergence', 'conditional-convergence']"
33,What are the odds of hitting exactly 100 rolling a fair die,What are the odds of hitting exactly 100 rolling a fair die,,"I roll a fair die and sequentially sum the numbers the die shows. What are the odds the summation will hit exactly 100? More generally, what are the odds of hitting an exact target number t while summing the results of numbers sequentially drawn uniformly from a set S . I have experimentally tested this and the result is (warning - spoilers ahead): 1 over the expectation of the drawn numbers. In the case of the fair die 1/((1+2+3+4+5+6)/6) = 6/21 = 2/7 However I do not have a strong intuition, let alone a formal proof, why this is the case. I'll be happy to get your thoughts!","I roll a fair die and sequentially sum the numbers the die shows. What are the odds the summation will hit exactly 100? More generally, what are the odds of hitting an exact target number t while summing the results of numbers sequentially drawn uniformly from a set S . I have experimentally tested this and the result is (warning - spoilers ahead): 1 over the expectation of the drawn numbers. In the case of the fair die 1/((1+2+3+4+5+6)/6) = 6/21 = 2/7 However I do not have a strong intuition, let alone a formal proof, why this is the case. I'll be happy to get your thoughts!",,"['probability', 'dice']"
34,Covering ten dots on a table with ten equal-sized coins: explanation of proof,Covering ten dots on a table with ten equal-sized coins: explanation of proof,,"Note: This question has been posted on StackOverflow . I have moved it here because: I am curious about the answer The OP has not shown any interest in moving it himself In the Communications of the ACM, August 2008 ""Puzzled"" column , Peter Winkler asked the following question: On the table before us are 10 dots,   and in our pocket are 10 $1 coins.   Prove the coins can be placed on the   table (no two overlapping) in such a   way that all dots are covered. Figure   2 shows a valid placement of the coins   for this particular set of dots; they   are transparent so we can see them.   The three coins at the bottom are not   needed. In the following issue , he presented his proof: We had to show that any 10 dots on a   table can be covered by   non-overlapping $1 coins, in a problem   devised by Naoki Inaba and sent to me   by his friend, Hirokazu Iwasawa, both   puzzle mavens in Japan. The key is to note that packing disks   arranged in a honeycomb pattern cover   more than 90% of the plane. But how do   we know they do? A disk of radius one   fits inside a regular hexagon made up   of six equilateral triangles of   altitude one. Since each such triangle   has area $\frac{\sqrt{3}}{3}$, the hexagon   itself has area $2 \sqrt{3}$; since the   hexagons tile the plane in a honeycomb   pattern, the disks, each with area $\pi$,   cover $\frac{\pi}{2\sqrt{3}}\approx .9069$ of the   plane's surface. It follows that if the disks are   placed randomly on the plane, the   probability that any particular point   is covered is .9069. Therefore, if we   randomly place lots of $1 coins   (borrowed) on the table in a hexagonal   pattern, on average, 9.069 of our 10   points will be covered, meaning at   least some of the time all 10 will be   covered. (We need at most only 10   coins so give back the rest.) What does it mean that the disks cover   90.69% of the infinite plane? The easiest way to answer is to say,   perhaps, that the percentage of any   large square covered by the disks   approaches this value as the square   expands. What is ""random"" about the   placement of the disks? One way to   think it through is to fix any packing   and any disk within it, then pick a   point uniformly at random from the   honeycomb hexagon containing the disk   and move the disk so its center is at   the chosen point. I don't understand. Doesn't the probabilistic nature of this proof simply mean that in the majority of configurations, all 10 dots can be covered. Can't we still come up with a configuration involving 10 (or less) dots where one of the dots can't be covered?","Note: This question has been posted on StackOverflow . I have moved it here because: I am curious about the answer The OP has not shown any interest in moving it himself In the Communications of the ACM, August 2008 ""Puzzled"" column , Peter Winkler asked the following question: On the table before us are 10 dots,   and in our pocket are 10 $1 coins.   Prove the coins can be placed on the   table (no two overlapping) in such a   way that all dots are covered. Figure   2 shows a valid placement of the coins   for this particular set of dots; they   are transparent so we can see them.   The three coins at the bottom are not   needed. In the following issue , he presented his proof: We had to show that any 10 dots on a   table can be covered by   non-overlapping $1 coins, in a problem   devised by Naoki Inaba and sent to me   by his friend, Hirokazu Iwasawa, both   puzzle mavens in Japan. The key is to note that packing disks   arranged in a honeycomb pattern cover   more than 90% of the plane. But how do   we know they do? A disk of radius one   fits inside a regular hexagon made up   of six equilateral triangles of   altitude one. Since each such triangle   has area $\frac{\sqrt{3}}{3}$, the hexagon   itself has area $2 \sqrt{3}$; since the   hexagons tile the plane in a honeycomb   pattern, the disks, each with area $\pi$,   cover $\frac{\pi}{2\sqrt{3}}\approx .9069$ of the   plane's surface. It follows that if the disks are   placed randomly on the plane, the   probability that any particular point   is covered is .9069. Therefore, if we   randomly place lots of $1 coins   (borrowed) on the table in a hexagonal   pattern, on average, 9.069 of our 10   points will be covered, meaning at   least some of the time all 10 will be   covered. (We need at most only 10   coins so give back the rest.) What does it mean that the disks cover   90.69% of the infinite plane? The easiest way to answer is to say,   perhaps, that the percentage of any   large square covered by the disks   approaches this value as the square   expands. What is ""random"" about the   placement of the disks? One way to   think it through is to fix any packing   and any disk within it, then pick a   point uniformly at random from the   honeycomb hexagon containing the disk   and move the disk so its center is at   the chosen point. I don't understand. Doesn't the probabilistic nature of this proof simply mean that in the majority of configurations, all 10 dots can be covered. Can't we still come up with a configuration involving 10 (or less) dots where one of the dots can't be covered?",,"['geometry', 'probability', 'puzzle']"
35,Distribution of the difference of two normal random variables.,Distribution of the difference of two normal random variables.,,"If $U$ and $V$ are independent identically distributed standard normal, what is the distribution of their difference? I will present my answer here.  I am hoping to know if I am right or wrong. Using the method of moment generating functions, we have \begin{align*} M_{U-V}(t)&=E\left[e^{t(U-V)}\right]\\ &=E\left[e^{tU}\right]E\left[e^{tV}\right]\\ &=M_U(t)M_V(t)\\ &=\left(M_U(t)\right)^2\\ &=\left(e^{\mu t+\frac{1}{2}t^2\sigma ^2}\right)^2\\ &=e^{2\mu t+t^2\sigma ^2}\\ \end{align*} The last expression is the moment generating function for a random variable distributed normal with mean $2\mu$ and variance $2\sigma ^2$.  Thus $U-V\sim N(2\mu,2\sigma ^2)$. For the third line from the bottom, it follows from the fact that the moment generating functions are identical for $U$ and $V$. Thanks for your input. EDIT: OH I already see that I made a mistake, since the random variables are distributed STANDARD normal.  I will change my answer to say $U-V\sim N(0,2)$.","If $U$ and $V$ are independent identically distributed standard normal, what is the distribution of their difference? I will present my answer here.  I am hoping to know if I am right or wrong. Using the method of moment generating functions, we have \begin{align*} M_{U-V}(t)&=E\left[e^{t(U-V)}\right]\\ &=E\left[e^{tU}\right]E\left[e^{tV}\right]\\ &=M_U(t)M_V(t)\\ &=\left(M_U(t)\right)^2\\ &=\left(e^{\mu t+\frac{1}{2}t^2\sigma ^2}\right)^2\\ &=e^{2\mu t+t^2\sigma ^2}\\ \end{align*} The last expression is the moment generating function for a random variable distributed normal with mean $2\mu$ and variance $2\sigma ^2$.  Thus $U-V\sim N(2\mu,2\sigma ^2)$. For the third line from the bottom, it follows from the fact that the moment generating functions are identical for $U$ and $V$. Thanks for your input. EDIT: OH I already see that I made a mistake, since the random variables are distributed STANDARD normal.  I will change my answer to say $U-V\sim N(0,2)$.",,"['probability', 'statistics', 'moment-generating-functions']"
36,Expected number of rolling a pair of dice to generate all possible sums,Expected number of rolling a pair of dice to generate all possible sums,,"A pair of dice is rolled repeatedly until each outcome (2 through 12) has occurred at least once. What is the expected number of rolls necessary for this to occur? Notes: This is not very deep conceptually, but because of the unequal probabilities for the outcomes, it seems that the calculations involved are terribly messy.  It must have been done already (dice have been studied for centuries!) but I can't find a discussion in any book, or on line. Can anybody give a reference?","A pair of dice is rolled repeatedly until each outcome (2 through 12) has occurred at least once. What is the expected number of rolls necessary for this to occur? Notes: This is not very deep conceptually, but because of the unequal probabilities for the outcomes, it seems that the calculations involved are terribly messy.  It must have been done already (dice have been studied for centuries!) but I can't find a discussion in any book, or on line. Can anybody give a reference?",,"['probability', 'combinatorics', 'dice']"
37,Probability and measure theory,Probability and measure theory,,"I'd like to have a correct general understanding of the importance of measure theory in probability theory. For now, it seems like mathematicians work with the notion of probability measure and prove theorems, because it automacially makes the theorem true, no matter if we work with discrete and continuous probability distribution. So for example, expected value - we can prove the Law of large numbers using its general definition (measure theoretic) $\operatorname{E} [X]  = \int_\Omega X \, \mathrm{d}P$, and then derive the formula for discrete and continuous cases (discrete and continuous random variables), without having to prove it separately for each case (we have one proof instead of two). One could say that the Law of large numbers justifies the definition of expected value, by the way. Is it right to say that probability using the general notion of probability measure saves work of mathematicians? What are the other advantages? Please correct me if I'm wrong, but I hope you get the idea of what sort of information I expect - it's the importance and role of measure theory in probability and answer to the question: are there theorems in probability that do not hold for general probability measure, but are true only for either discrete or continuous probability distribution? If we can prove that no such theorems can exist, we can simply forget about the distinction between discrete and continuous distributions. If someone could come up with a clear, concise summary, I'd be grateful. I'm not an expert, so please take that into account.","I'd like to have a correct general understanding of the importance of measure theory in probability theory. For now, it seems like mathematicians work with the notion of probability measure and prove theorems, because it automacially makes the theorem true, no matter if we work with discrete and continuous probability distribution. So for example, expected value - we can prove the Law of large numbers using its general definition (measure theoretic) $\operatorname{E} [X]  = \int_\Omega X \, \mathrm{d}P$, and then derive the formula for discrete and continuous cases (discrete and continuous random variables), without having to prove it separately for each case (we have one proof instead of two). One could say that the Law of large numbers justifies the definition of expected value, by the way. Is it right to say that probability using the general notion of probability measure saves work of mathematicians? What are the other advantages? Please correct me if I'm wrong, but I hope you get the idea of what sort of information I expect - it's the importance and role of measure theory in probability and answer to the question: are there theorems in probability that do not hold for general probability measure, but are true only for either discrete or continuous probability distribution? If we can prove that no such theorems can exist, we can simply forget about the distinction between discrete and continuous distributions. If someone could come up with a clear, concise summary, I'd be grateful. I'm not an expert, so please take that into account.",,"['probability', 'probability-theory', 'measure-theory', 'philosophy', 'probability-limit-theorems']"
38,How does one generally find a joint distribution function (or density) from marginals when there is dependence?,How does one generally find a joint distribution function (or density) from marginals when there is dependence?,,"So I know one can go from a joint density function $f(x,y)$ to marginal density functions, like $f_x(x)$ by integrating against the other variables as in $f_x(x) = \int f(x,y) dy$...but given $f_x(x)$ and $f_y(y)$ as densities for dependent random vars..how would one go about finding a joint density or distribution function? Thanks","So I know one can go from a joint density function $f(x,y)$ to marginal density functions, like $f_x(x)$ by integrating against the other variables as in $f_x(x) = \int f(x,y) dy$...but given $f_x(x)$ and $f_y(y)$ as densities for dependent random vars..how would one go about finding a joint density or distribution function? Thanks",,"['probability', 'probability-theory', 'probability-distributions']"
39,"How long does it take a person with this ""cheating"" data-gathering strategy to achieve a desired result?","How long does it take a person with this ""cheating"" data-gathering strategy to achieve a desired result?",,"I have a perfectly fair coin, and my goal is to prove that it is unfair with a confidence level of 95%.  In order to accomplish this, I will cheat .  Whenever I fail to have enough evidence, I will simply increase the sample size by continuing to flip the coin. To be specific, I will flip the coin until the proportion of heads is either small enough or large enough to be able to say that the coin is unfair.  Let's say that, for any given sample size $N$, there is at least a $95\%$ chance that the proportion of heads is within the confidence interval $$0.5 ± f(N)$$ where $f(N)$ is some function. If I have flipped the coin a grand total of $N$ times, and the proportion of heads is outside of this interval, then I ""conclude"" that the fair coin is unfair and stop the process.  If the proportion is within the interval, then I flip the coin one more time and repeat the process with $N+1$.  One important detail is that I never ""throw out"" data. What is the expected number of flips that I would have to make until I receive the ""statistically significant"" result I seek? I've run a few simulations with my calculator, and it seems that either it takes a reasonable number of flips (like 44) or it takes a huge amount of time.  Why is this, assuming it's not programmer error? Edit: More simulations I ran some more simulations (on an actual PC, rather than a calculator).  I used two criteria for determining whether or not a result is significant.  First, I required that there be at least $20$ flips performed. Second, I used this value for the function: $$f(N) = 1.9600 * \sqrt{\frac{0.5 * 0.5}N} = \frac{0.98}{\sqrt{N}}$$ More edits: this formula comes from the normal approximation for the binomial distribution, where $1.96$ is the required z-score and other part is the standard deviation of the proportion. My plan for running the simulations was to set an upper limit for the number of flips, preform a huge number of trials, and see what proportion of trials exceeded the limit.  This way, I could gather data in a reasonable time limit.  After running a large number of simulations, I acquired this data: # of flips      proportion > this number      sample size 100000          0.298                         n=1000 10000           0.41                          n=1000 1000            0.5516                        n=10000 100             0.7637                        n=10000 32              0.8726                        n=10000 64              0.8029                        n=10000 128             0.738                         n=10000 256             0.6768                        n=10000 512             0.6252                        n=10000 1024            0.563                         n=10000 2048            0.5126                        n=5000","I have a perfectly fair coin, and my goal is to prove that it is unfair with a confidence level of 95%.  In order to accomplish this, I will cheat .  Whenever I fail to have enough evidence, I will simply increase the sample size by continuing to flip the coin. To be specific, I will flip the coin until the proportion of heads is either small enough or large enough to be able to say that the coin is unfair.  Let's say that, for any given sample size $N$, there is at least a $95\%$ chance that the proportion of heads is within the confidence interval $$0.5 ± f(N)$$ where $f(N)$ is some function. If I have flipped the coin a grand total of $N$ times, and the proportion of heads is outside of this interval, then I ""conclude"" that the fair coin is unfair and stop the process.  If the proportion is within the interval, then I flip the coin one more time and repeat the process with $N+1$.  One important detail is that I never ""throw out"" data. What is the expected number of flips that I would have to make until I receive the ""statistically significant"" result I seek? I've run a few simulations with my calculator, and it seems that either it takes a reasonable number of flips (like 44) or it takes a huge amount of time.  Why is this, assuming it's not programmer error? Edit: More simulations I ran some more simulations (on an actual PC, rather than a calculator).  I used two criteria for determining whether or not a result is significant.  First, I required that there be at least $20$ flips performed. Second, I used this value for the function: $$f(N) = 1.9600 * \sqrt{\frac{0.5 * 0.5}N} = \frac{0.98}{\sqrt{N}}$$ More edits: this formula comes from the normal approximation for the binomial distribution, where $1.96$ is the required z-score and other part is the standard deviation of the proportion. My plan for running the simulations was to set an upper limit for the number of flips, preform a huge number of trials, and see what proportion of trials exceeded the limit.  This way, I could gather data in a reasonable time limit.  After running a large number of simulations, I acquired this data: # of flips      proportion > this number      sample size 100000          0.298                         n=1000 10000           0.41                          n=1000 1000            0.5516                        n=10000 100             0.7637                        n=10000 32              0.8726                        n=10000 64              0.8029                        n=10000 128             0.738                         n=10000 256             0.6768                        n=10000 512             0.6252                        n=10000 1024            0.563                         n=10000 2048            0.5126                        n=5000",,"['probability', 'statistics']"
40,Matching red to blue dots,Matching red to blue dots,,"I have two red points, $r_1$ and $r_2$, and two blue points, $b_1$ and $b_2$. They are all placed randomly and uniformly in $[0,1]^2$. Each dot points to the closest dot from another colour; closest is defined wrt the Euclidean distance. We use $x \to y$ to indicate dot $x$ points to dot $y$. If $r_1 \to b_1$, what is the probability that $r_2 \to b_1$ too? NOTE it must be larger than 1/2 because $r_1 \to b_1$ tells us in a way that $b_1$ is likely to have a centric location, and thus is likely than it is closer to $r_2$ too than $b_2$.","I have two red points, $r_1$ and $r_2$, and two blue points, $b_1$ and $b_2$. They are all placed randomly and uniformly in $[0,1]^2$. Each dot points to the closest dot from another colour; closest is defined wrt the Euclidean distance. We use $x \to y$ to indicate dot $x$ points to dot $y$. If $r_1 \to b_1$, what is the probability that $r_2 \to b_1$ too? NOTE it must be larger than 1/2 because $r_1 \to b_1$ tells us in a way that $b_1$ is likely to have a centric location, and thus is likely than it is closer to $r_2$ too than $b_2$.",,"['probability', 'geometry', 'geometric-probability']"
41,"If a lottery has 300 tickets, shouldn't I win every 300 times I play","If a lottery has 300 tickets, shouldn't I win every 300 times I play",,"Suppose I play a lottery that has 300 tickets. I can only buy one ticket per draw. Statistically speaking, shouldn't I win once every 300 draws? Is it more complicated than this? Edit This question has generated much more response than I had imagined. Thank you all, for your input and your great explanations. To go into further details: The lottery has 300 tickets. You can buy 1 ticket per draw. Every draw, is all new tickets, so in essence, you can hold 1 out of 300 numbers, at each draw. Edit Just to give some funny (not really funny) side info. I have now played 1,104 times, and still have not won anything. I suppose I am EXTREMELY unlucky.","Suppose I play a lottery that has 300 tickets. I can only buy one ticket per draw. Statistically speaking, shouldn't I win once every 300 draws? Is it more complicated than this? Edit This question has generated much more response than I had imagined. Thank you all, for your input and your great explanations. To go into further details: The lottery has 300 tickets. You can buy 1 ticket per draw. Every draw, is all new tickets, so in essence, you can hold 1 out of 300 numbers, at each draw. Edit Just to give some funny (not really funny) side info. I have now played 1,104 times, and still have not won anything. I suppose I am EXTREMELY unlucky.",,"['probability', 'statistics']"
42,"In a family with 3 children, what is the probability that they have 2 boys and 1 girl?","In a family with 3 children, what is the probability that they have 2 boys and 1 girl?",,"I'm doing some regents practice questions, and one of them asked In a family with 3 children, what is the probability that they have 2   boys and 1 girl? And the answer choices are 3/8 1/4 1/8 1/2 My teacher said the answer was choice one but I'm having trouble understanding why. My approach was to draw out the probabilities, since we have 3 children, and we are looking for 2 boys and 1 girl, the probabilities can be Boy-Boy-Girl, Boy-Girl-Boy, and Girl-Boy-Boy. So a 2/3 chance, but I don't get how it's a 3/8 chance. Any help is appreciated.","I'm doing some regents practice questions, and one of them asked In a family with 3 children, what is the probability that they have 2   boys and 1 girl? And the answer choices are 3/8 1/4 1/8 1/2 My teacher said the answer was choice one but I'm having trouble understanding why. My approach was to draw out the probabilities, since we have 3 children, and we are looking for 2 boys and 1 girl, the probabilities can be Boy-Boy-Girl, Boy-Girl-Boy, and Girl-Boy-Boy. So a 2/3 chance, but I don't get how it's a 3/8 chance. Any help is appreciated.",,"['probability', 'algebra-precalculus']"
43,"Two dice thrown, one comes up 6","Two dice thrown, one comes up 6",,"If my friend throws two dice, and covers them up, but I see that one of them was a 6, what's the probability that they were both 6s given this knowledge? I'm under the impression that the answer is 2/7, because the other die could be any of the other numbers, but if he really did roll double sixes you could have seen either one, so there are two ways for that to happen. That makes seven equally likely possibilities: (6*,1) (6*,2) (6*,3) (6*,4) (6*,5) (6*,6) and (6,6*), where * represents the one you saw. My question is whether the answer should really be 2/12 = 1/6 since you might think you ought to count the cases (1,6*) (2,6*) etc. as separate---that is, the case in which the other die comes up as a 6 and you see it. You could distinguish the dice by painting one red, for example. I hope the question is well posed. Let me know if you think it should be clarified. EDIT: Thanks for the speedy responses everyone. One way I thought about the question is that instead of the 36 outcomes we typically think of for two dice, there are now 72 possible outcomes---for each roll there are two events corresponding to seeing die A or die B. In this case when we condition on the fact that we saw one of the dice to be a 6 we've restricted our sample space in the way I've described above. For clarity, this means we now have the following possibilities: (6*,6) (6,6*) (6*,5) (6*,4) (6*,3) (6*,2) (6*,1) I'm not sure whether to include the remaining possibilities or not: (1,6*) (2,6*) (3,6*) (4,6*) (5,6*) Clearly the answer depends highly on the interpretation of the wording of the question. I'm interpreting it to mean you're equally likely to spot one die or the other. I'm fairly sure this situation is different than being given the information that at least one of the dice is a six. Can anyone convince me why this isn't a legitimate way to interpret the question, or otherwise she'd some light on which restricted sample space is the correct one? I feel like it has something to do with this indistinguishable to of the two sixes (so maybe painting one red would ruin it).","If my friend throws two dice, and covers them up, but I see that one of them was a 6, what's the probability that they were both 6s given this knowledge? I'm under the impression that the answer is 2/7, because the other die could be any of the other numbers, but if he really did roll double sixes you could have seen either one, so there are two ways for that to happen. That makes seven equally likely possibilities: (6*,1) (6*,2) (6*,3) (6*,4) (6*,5) (6*,6) and (6,6*), where * represents the one you saw. My question is whether the answer should really be 2/12 = 1/6 since you might think you ought to count the cases (1,6*) (2,6*) etc. as separate---that is, the case in which the other die comes up as a 6 and you see it. You could distinguish the dice by painting one red, for example. I hope the question is well posed. Let me know if you think it should be clarified. EDIT: Thanks for the speedy responses everyone. One way I thought about the question is that instead of the 36 outcomes we typically think of for two dice, there are now 72 possible outcomes---for each roll there are two events corresponding to seeing die A or die B. In this case when we condition on the fact that we saw one of the dice to be a 6 we've restricted our sample space in the way I've described above. For clarity, this means we now have the following possibilities: (6*,6) (6,6*) (6*,5) (6*,4) (6*,3) (6*,2) (6*,1) I'm not sure whether to include the remaining possibilities or not: (1,6*) (2,6*) (3,6*) (4,6*) (5,6*) Clearly the answer depends highly on the interpretation of the wording of the question. I'm interpreting it to mean you're equally likely to spot one die or the other. I'm fairly sure this situation is different than being given the information that at least one of the dice is a six. Can anyone convince me why this isn't a legitimate way to interpret the question, or otherwise she'd some light on which restricted sample space is the correct one? I feel like it has something to do with this indistinguishable to of the two sixes (so maybe painting one red would ruin it).",,"['probability', 'statistics']"
44,"Die fixed so it can't roll the same number twice in a row, using markov chains?","Die fixed so it can't roll the same number twice in a row, using markov chains?",,"Studying for probability test and the following question came up: A six sided die is 'fixed' so that it cannot roll the same number twice consecutively. The other 5 sides each show up with a probability $\frac{1}{5}$. Calculate P($X_{n+1} = 5 \mid X_1 = 5$) and P($X_{n+1} = 1 \mid X_1 = 5$) What happens as $n \rightarrow$ $\infty$? It appears to be a markov chain problem but all I can think to do is to find the eigenvalues of the transition matrix. This seems unfeasible given that it's 6x6.  My guess for the second part is that the probability tends to 1/6, as the first value becomes less and less relevant.","Studying for probability test and the following question came up: A six sided die is 'fixed' so that it cannot roll the same number twice consecutively. The other 5 sides each show up with a probability $\frac{1}{5}$. Calculate P($X_{n+1} = 5 \mid X_1 = 5$) and P($X_{n+1} = 1 \mid X_1 = 5$) What happens as $n \rightarrow$ $\infty$? It appears to be a markov chain problem but all I can think to do is to find the eigenvalues of the transition matrix. This seems unfeasible given that it's 6x6.  My guess for the second part is that the probability tends to 1/6, as the first value becomes less and less relevant.",,"['probability', 'markov-chains']"
45,how to derive the mean and variance of a Gaussian Random variable?,how to derive the mean and variance of a Gaussian Random variable?,,How do we go about deriving the values of mean and variance of a Gaussian Random Variable $X$  given its probability density function ?,How do we go about deriving the values of mean and variance of a Gaussian Random Variable $X$  given its probability density function ?,,"['probability', 'probability-theory', 'random-variables']"
46,Intuitive explanation for a constant answer in a Bayes theorem question,Intuitive explanation for a constant answer in a Bayes theorem question,,"Question (previously asked here ) You know there are 3 boys and an unknown number of girls in a nursery at a hospital. Then a woman gives birth a baby, but you do not know its gender, and it is placed in the nursery. Then a nurse comes in a picks up a baby and it is a boy. Given that the nurse picks up a boy, what is the probability that the woman gave birth to a boy? Assume that - in this question's universe - the unconditional probabiilty that any newly born baby is a boy or a girl is exactly half. Short solution Let number of girls be $k$ . Event A is the newborn is a boy, Event B is that nurse picks up a boy. So, we are asked $P(A|B)$ . $$P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{\frac 4{k+4}\frac 12}{\frac 4{k+4}\frac 12 + \frac 3{k+4}\frac 12} = \frac 47$$ My question Why is the probability constant? I would have expected the probability to change with respect to the number of girls. More specifically, I would have expected the probability to increase as the value of $k$ increases, and decrease if $k$ was less. Why so? Because we are already given the claim that we have selected a boy. If we have infinite girls, then the newborn has to almost surely be a boy to help support that observed claim. Because initially there are only three boys, the more help they could get in supporting the claim, the better. Of course, this is not a very rigorous argument, but the point here is that in many such questions there is a natural expectation for the probability to vary with the variable. And it does do in many, say for example the generalized monty hall problem . I do know that technically the $k$ does not matter because it gets cancelled out in the denominator, but intuitively that is not a very helpful explanation. Can anyone give an intuitive explanation for why the probability answer in this question is a constant?","Question (previously asked here ) You know there are 3 boys and an unknown number of girls in a nursery at a hospital. Then a woman gives birth a baby, but you do not know its gender, and it is placed in the nursery. Then a nurse comes in a picks up a baby and it is a boy. Given that the nurse picks up a boy, what is the probability that the woman gave birth to a boy? Assume that - in this question's universe - the unconditional probabiilty that any newly born baby is a boy or a girl is exactly half. Short solution Let number of girls be . Event A is the newborn is a boy, Event B is that nurse picks up a boy. So, we are asked . My question Why is the probability constant? I would have expected the probability to change with respect to the number of girls. More specifically, I would have expected the probability to increase as the value of increases, and decrease if was less. Why so? Because we are already given the claim that we have selected a boy. If we have infinite girls, then the newborn has to almost surely be a boy to help support that observed claim. Because initially there are only three boys, the more help they could get in supporting the claim, the better. Of course, this is not a very rigorous argument, but the point here is that in many such questions there is a natural expectation for the probability to vary with the variable. And it does do in many, say for example the generalized monty hall problem . I do know that technically the does not matter because it gets cancelled out in the denominator, but intuitively that is not a very helpful explanation. Can anyone give an intuitive explanation for why the probability answer in this question is a constant?",k P(A|B) P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{\frac 4{k+4}\frac 12}{\frac 4{k+4}\frac 12 + \frac 3{k+4}\frac 12} = \frac 47 k k k,"['probability', 'bayes-theorem']"
47,Expected value of an expected value,Expected value of an expected value,,I am looking at a proof that $\text{Var}(X)= E((X - EX)^2) = E(X^2) - (E(X))^2$ $E((X - EX)^2) =$ $E(X^2 - 2XE(X) + (E(X))^2) =$ $E(X^2) - 2E(X)E(X) + (E(X))^2)$ I can't see how the second line can be equal to the third line. I would have had the following for the third line - $E(X^2) - E(2XE(X)) + E((E(X))^2))$ Which seems very messy... There must be something I am not understanding about the properties of expected values?,I am looking at a proof that I can't see how the second line can be equal to the third line. I would have had the following for the third line - Which seems very messy... There must be something I am not understanding about the properties of expected values?,\text{Var}(X)= E((X - EX)^2) = E(X^2) - (E(X))^2 E((X - EX)^2) = E(X^2 - 2XE(X) + (E(X))^2) = E(X^2) - 2E(X)E(X) + (E(X))^2) E(X^2) - E(2XE(X)) + E((E(X))^2)),"['probability', 'expected-value']"
48,Expected value as integral of survival function,Expected value as integral of survival function,,"Let $T$ be a positive random variable, $S(t)=\operatorname{P}(T\geq t)$ . Prove that $$E[T]=\int^\infty_0 S(t)dt.$$ I have tried this unsuccessfully.","Let be a positive random variable, . Prove that I have tried this unsuccessfully.",T S(t)=\operatorname{P}(T\geq t) E[T]=\int^\infty_0 S(t)dt.,"['probability', 'integration', 'analysis', 'probability-distributions']"
49,Is it possible to 'split' coin flipping 3 ways?,Is it possible to 'split' coin flipping 3 ways?,,"When flipping a coin to make important decisions in life you can flip once to choose between 2 possible outcomes. (Heads I eat cake, Tails I eat chocolate!) You can also flip twice to choose between 4 outcomes. (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads) Can you use a coin to choose evenly between three possible choices? If so how? (Ignoring slight abnormalities in weight)","When flipping a coin to make important decisions in life you can flip once to choose between 2 possible outcomes. (Heads I eat cake, Tails I eat chocolate!) You can also flip twice to choose between 4 outcomes. (Heads-Heads, Tails-Tails, Heads-Tails, Tails-Heads) Can you use a coin to choose evenly between three possible choices? If so how? (Ignoring slight abnormalities in weight)",,"['probability', 'fair-division']"
50,What is meant by a stopping time?,What is meant by a stopping time?,,"TL;DR: is a stopping time some sort of event, or is it a point in discrete time, or something else entirely what is an example of something which is not a stopping time? is my understanding of the concepts and definitions below correct? I am having difficulty understanding what a stopping time is. The definition I am provided with is as follows: A random time $τ$ is called a stopping time if for any $n$, one can decide whether the event $\{τ ≤ n\}$ (and hence the complementary event $\{τ > n\}$) has occurred by observing the first n variables $X_1, X_2, . . . , X_n$. We are then given an example: Time of ruin is a stopping time. $τ = \min\{n : X_n = 0\}$. $\{τ > n\} = \{X_1 ≥ 0, X_2 ≥ 0, . . . , X_n > 0\}$. I don't quite understand what this is supposed to tell us. random time $τ$ is called a stopping time if for any $n$, one can decide whether the event $\{τ ≤ n\}$ has occurred by observing the first n variables $X_1, X_2, . . . , X_n$ When they say the event $\{ τ \leq n\}$ they are referring to some specific time, are they not? e.g $τ = 1$ or maybe $τ = 4$ as long as $τ \leq n$ Is this correct? So then if we know the event $ \{τ \leq n\}$ has or has not occurred, we can conclude whether the complementary even $τ > n$ has occurred. If this is fine so far, then I have issues with the example. Time of ruin is stopping time,    $τ = \min\{n : X_n = 0\}$ Firstly, time of ruin to me means at a point where you have $0$ or a negative balance of some sort of asset (For a gambler, no more money to gamble with, for a business owner, no more cash to pay expenses or obligations) - is this correct? In that case Time of ruin should occur when $X_n \leq 0$, correct? IF that is fine, then continuing, what does $τ = \min\{n : X_n = 0\}$ mean?  This is not the same as  $τ = \min\{n,X_n\}$, is it? What is it trying to say? I read it as, the minimum of $n$, such that $X_n  = 0$ So it's saying $τ$ is the first point at which we are ruined? Is my understanding all correct? Can someone provide me with an example of what is NOT a stopping time? Does a ""stopping time"" refer to a type of event?","TL;DR: is a stopping time some sort of event, or is it a point in discrete time, or something else entirely what is an example of something which is not a stopping time? is my understanding of the concepts and definitions below correct? I am having difficulty understanding what a stopping time is. The definition I am provided with is as follows: A random time $τ$ is called a stopping time if for any $n$, one can decide whether the event $\{τ ≤ n\}$ (and hence the complementary event $\{τ > n\}$) has occurred by observing the first n variables $X_1, X_2, . . . , X_n$. We are then given an example: Time of ruin is a stopping time. $τ = \min\{n : X_n = 0\}$. $\{τ > n\} = \{X_1 ≥ 0, X_2 ≥ 0, . . . , X_n > 0\}$. I don't quite understand what this is supposed to tell us. random time $τ$ is called a stopping time if for any $n$, one can decide whether the event $\{τ ≤ n\}$ has occurred by observing the first n variables $X_1, X_2, . . . , X_n$ When they say the event $\{ τ \leq n\}$ they are referring to some specific time, are they not? e.g $τ = 1$ or maybe $τ = 4$ as long as $τ \leq n$ Is this correct? So then if we know the event $ \{τ \leq n\}$ has or has not occurred, we can conclude whether the complementary even $τ > n$ has occurred. If this is fine so far, then I have issues with the example. Time of ruin is stopping time,    $τ = \min\{n : X_n = 0\}$ Firstly, time of ruin to me means at a point where you have $0$ or a negative balance of some sort of asset (For a gambler, no more money to gamble with, for a business owner, no more cash to pay expenses or obligations) - is this correct? In that case Time of ruin should occur when $X_n \leq 0$, correct? IF that is fine, then continuing, what does $τ = \min\{n : X_n = 0\}$ mean?  This is not the same as  $τ = \min\{n,X_n\}$, is it? What is it trying to say? I read it as, the minimum of $n$, such that $X_n  = 0$ So it's saying $τ$ is the first point at which we are ruined? Is my understanding all correct? Can someone provide me with an example of what is NOT a stopping time? Does a ""stopping time"" refer to a type of event?",,"['probability', 'probability-theory', 'definition', 'stopping-times']"
51,"""A two-envelopes puzzle""","""A two-envelopes puzzle""",,"This is Problem 1.25 from Tsitsiklis, Bertsekas, Introduction to Probability, 2nd edition. You are handed two envelopes, and you know that each contains a   positive integer dollar amount and that the two amounts are different.   The values of these two amounts are modeled as constants that are   unknown. Without knowing what the amounts are, you select at random   one of the two envelopes, and after looking at the amount inside, you   may switch envelopes if you wish. A friend claims that the following   strategy will increase above $1/2$ your probability of ending up with   the envelope with the larger amount: Toss a coin repeatedly. Let  $X$  be equal to $1/2$ plus the number of   tosses required to obtain heads for the first time, and switch if the   amount in the envelope you selected is less than the value of  $X$ .    Is your friend correct? The answer given in the solution manual claims that this indeed helps, and that the probability of getting the better envelope is given by $$p = \frac{1}{2} + \frac{1}{2} P(B)$$ where $B$ is the event that $a<X<b$, with $a,b$ being the smaller and larger amount of dollars, respectively. I do not buy this solution for the following reason: tossing a coin has nothing to do with the contents of the envelopes. You do not gain any information by doing it. You could just as well count the amount of leaves on a nearby tree instead and use that for $X$. Similarly, opening the first envelope also gives you no useful information about the ordering relation between $a$ and $b$, so surely that's another red herring. Even if you forget the coin tossing, the probability of ""winning"" is still $1/2$, swap or no swap. I suppose maybe the catch is in interpreting the following sentence: ""The values of these two amounts are modeled as constants that are unknown"". I take it to mean that they're just two randomly and independently generated numbers. Am I out of my mind? Surely the solution manual is wrong.","This is Problem 1.25 from Tsitsiklis, Bertsekas, Introduction to Probability, 2nd edition. You are handed two envelopes, and you know that each contains a   positive integer dollar amount and that the two amounts are different.   The values of these two amounts are modeled as constants that are   unknown. Without knowing what the amounts are, you select at random   one of the two envelopes, and after looking at the amount inside, you   may switch envelopes if you wish. A friend claims that the following   strategy will increase above $1/2$ your probability of ending up with   the envelope with the larger amount: Toss a coin repeatedly. Let  $X$  be equal to $1/2$ plus the number of   tosses required to obtain heads for the first time, and switch if the   amount in the envelope you selected is less than the value of  $X$ .    Is your friend correct? The answer given in the solution manual claims that this indeed helps, and that the probability of getting the better envelope is given by $$p = \frac{1}{2} + \frac{1}{2} P(B)$$ where $B$ is the event that $a<X<b$, with $a,b$ being the smaller and larger amount of dollars, respectively. I do not buy this solution for the following reason: tossing a coin has nothing to do with the contents of the envelopes. You do not gain any information by doing it. You could just as well count the amount of leaves on a nearby tree instead and use that for $X$. Similarly, opening the first envelope also gives you no useful information about the ordering relation between $a$ and $b$, so surely that's another red herring. Even if you forget the coin tossing, the probability of ""winning"" is still $1/2$, swap or no swap. I suppose maybe the catch is in interpreting the following sentence: ""The values of these two amounts are modeled as constants that are unknown"". I take it to mean that they're just two randomly and independently generated numbers. Am I out of my mind? Surely the solution manual is wrong.",,"['probability', 'paradoxes']"
52,Knight returning to corner on chessboard -- average number of steps,Knight returning to corner on chessboard -- average number of steps,,"Context: My friend gave me a problem at breakfast some time ago. It is supposed to have an easy, trick-involving solution. I can't figure it out. Problem: Let there be a knight (horse) at a particular corner (0,0) on a 8x8 chessboard. The knight moves according to the usual rules (2 in one direction, 1 in the orthogonal one) and only legal moves are allowed (no wall tunnelling etc). The knight moves randomly (i.e. at a particular position, it generates a set of all possible and legal new positions, and picks one at random). What is the average number of steps after which the knight returns to its starting corner? To sum up: A knight starts at (0,0). How many steps on average does it take to return back to (0,0) via a random (but only legal knight moves) walk. My attempt: (disclaimer: I don't know much about Markov chains.) The problem is a Markov chain. There are $8\times8 = 64$ possible states. There exist transition probabilities between the states that are easy to generate. I generated a $64 \times 64$ transition matrix $M_{ij}$ using a simple piece of code, as it seemed too big to do by hand. The starting position is $v_i = (1,0,0,...) = \delta_{0i}$. The probability that the knight as in the corner (state 0) after $n$ steps is $$ P_{there}(n) = (M^n)_{0j} v_j \, . $$ I also need to find the probability that the knight did not reach the state 0 in any of the previous $n-1$ steps. The probability that the knight is not in the corner after $m$ steps is $1-P_{there}(m)$. Therefore the total probability that the knight is in the corner for the first time (disregarding the start) after $n$ steps is $$ P(n) = \left ( \prod_{m=1}^{n-1} \left [ 1 - \sum_{j = 0}^{63} (M^m)_{0j} v_j \right ] \right ) \left ( \sum_{j = 0}^{63} (M^n)_{0j} v_j \right ) $$ To calculate the average number of steps to return, I evaluate $$ \left < n \right >= \sum_{n = 1}^{\infty} n P(n) \, . $$ My issue: The approach I described should work. However, I had to use a computer due to the size of the matrices. Also, the $\left < n \right >$ seems to converge quite slowly. I got $\left < n \right > \approx 130.3$ numerically and my friend claims it's wrong. Furthermore, my solution is far from simple. Would you please have a look at it? Thanks a lot! -SSF","Context: My friend gave me a problem at breakfast some time ago. It is supposed to have an easy, trick-involving solution. I can't figure it out. Problem: Let there be a knight (horse) at a particular corner (0,0) on a 8x8 chessboard. The knight moves according to the usual rules (2 in one direction, 1 in the orthogonal one) and only legal moves are allowed (no wall tunnelling etc). The knight moves randomly (i.e. at a particular position, it generates a set of all possible and legal new positions, and picks one at random). What is the average number of steps after which the knight returns to its starting corner? To sum up: A knight starts at (0,0). How many steps on average does it take to return back to (0,0) via a random (but only legal knight moves) walk. My attempt: (disclaimer: I don't know much about Markov chains.) The problem is a Markov chain. There are $8\times8 = 64$ possible states. There exist transition probabilities between the states that are easy to generate. I generated a $64 \times 64$ transition matrix $M_{ij}$ using a simple piece of code, as it seemed too big to do by hand. The starting position is $v_i = (1,0,0,...) = \delta_{0i}$. The probability that the knight as in the corner (state 0) after $n$ steps is $$ P_{there}(n) = (M^n)_{0j} v_j \, . $$ I also need to find the probability that the knight did not reach the state 0 in any of the previous $n-1$ steps. The probability that the knight is not in the corner after $m$ steps is $1-P_{there}(m)$. Therefore the total probability that the knight is in the corner for the first time (disregarding the start) after $n$ steps is $$ P(n) = \left ( \prod_{m=1}^{n-1} \left [ 1 - \sum_{j = 0}^{63} (M^m)_{0j} v_j \right ] \right ) \left ( \sum_{j = 0}^{63} (M^n)_{0j} v_j \right ) $$ To calculate the average number of steps to return, I evaluate $$ \left < n \right >= \sum_{n = 1}^{\infty} n P(n) \, . $$ My issue: The approach I described should work. However, I had to use a computer due to the size of the matrices. Also, the $\left < n \right >$ seems to converge quite slowly. I got $\left < n \right > \approx 130.3$ numerically and my friend claims it's wrong. Furthermore, my solution is far from simple. Would you please have a look at it? Thanks a lot! -SSF",,"['probability', 'combinatorics', 'markov-chains', 'expectation']"
53,Probability of picking an odd number from the set of naturals?,Probability of picking an odd number from the set of naturals?,,"I know there's no uniform distribution for a countably infinite set, but I'm wondering if there's still a way to determine the probability of picking from a subset of a countably infinite set. For example, what's the probability that I pick an odd number from the set of naturals, assuming I'm picking randomly? Is this even a coherent question? If so, is there a textbook approach to this problem in measure theory/probability theory/probability measure? Thanks!","I know there's no uniform distribution for a countably infinite set, but I'm wondering if there's still a way to determine the probability of picking from a subset of a countably infinite set. For example, what's the probability that I pick an odd number from the set of naturals, assuming I'm picking randomly? Is this even a coherent question? If so, is there a textbook approach to this problem in measure theory/probability theory/probability measure? Thanks!",,"['probability', 'probability-theory', 'measure-theory', 'probability-distributions']"
54,Number of moves necessary to solve Rubik's cube by pure chance,Number of moves necessary to solve Rubik's cube by pure chance,,"Suppose, random moves are made to solve Rubik's cube. A move consists of a $90$-degree-rotation of some side. The starting position is also random. What is $E(X)$, where $X$ is the number of moves until the cube is solved ? How many moves must be made, that the probability that the cube is solved, exceeds $99$% ?","Suppose, random moves are made to solve Rubik's cube. A move consists of a $90$-degree-rotation of some side. The starting position is also random. What is $E(X)$, where $X$ is the number of moves until the cube is solved ? How many moves must be made, that the probability that the cube is solved, exceeds $99$% ?",,"['probability', 'expectation', 'rubiks-cube']"
55,expected value calculation for squared normal distribution,expected value calculation for squared normal distribution,,"I need help with the following problem. Suppose $Z=N(0,s)$ i.e. normally distributed random variable with standard deviation $\sqrt{s}$. I need to calculate $E[Z^2]$. My attempt is to do something like \begin{align} E[Z^2]=&\int_0^{+\infty} y \cdot Pr(Z^2=y)dy\\ =& \int_0^{+\infty}y\frac{1}{\sqrt{2\pi s}}e^{-\frac y{2s}}dy\\ =&\frac{1}{\sqrt{2\pi s}}\int_0^{\infty}ye^{-\frac y{2s}}dy. \end{align} By using integration by parts we get $$\int_0^{\infty}ye^{-\frac y{2s}}dy=\int_0^{+\infty}2se^{-\frac y{2s}}dy=4s^2.$$ Hence $E[Z^2]=\frac{2s\sqrt{2s}}{\sqrt{\pi}},$ which does not coincide with the answer in the text. Can someone point the mistake?","I need help with the following problem. Suppose $Z=N(0,s)$ i.e. normally distributed random variable with standard deviation $\sqrt{s}$. I need to calculate $E[Z^2]$. My attempt is to do something like \begin{align} E[Z^2]=&\int_0^{+\infty} y \cdot Pr(Z^2=y)dy\\ =& \int_0^{+\infty}y\frac{1}{\sqrt{2\pi s}}e^{-\frac y{2s}}dy\\ =&\frac{1}{\sqrt{2\pi s}}\int_0^{\infty}ye^{-\frac y{2s}}dy. \end{align} By using integration by parts we get $$\int_0^{\infty}ye^{-\frac y{2s}}dy=\int_0^{+\infty}2se^{-\frac y{2s}}dy=4s^2.$$ Hence $E[Z^2]=\frac{2s\sqrt{2s}}{\sqrt{\pi}},$ which does not coincide with the answer in the text. Can someone point the mistake?",,"['probability', 'probability-distributions']"
56,New to probability - Is this true?,New to probability - Is this true?,,"I read this somewhere and can't find it to verify: ""If you don't have a dice with 12 sides, but do have one with 20 sides and you need to make rolls for 12 sides, you can use the numbers 1-12 on the 20-sided die, ignoring any other numbers if they come up."" (not necessarily a direct quote, but as good as I can remember) Assuming that each side is numbered from 1 to n and that the dice are balanced, so each side has an equal probability of occurring: In my mind, a 20-sided die has a 1/20 chance that any given number will come up and a 12/20 (3/5) chance that a number between 1 and 12 will come up, although I believe this 3/5 probability becomes a 1/1 probability if you ignore any numbers between 13 and 20. Assuming that you ignore numbers 13-20, does the probability of numbers 1-12 occurring become 1/12 (i.e. the same as a 12-sided die)?  Or is it more complicated than that?","I read this somewhere and can't find it to verify: ""If you don't have a dice with 12 sides, but do have one with 20 sides and you need to make rolls for 12 sides, you can use the numbers 1-12 on the 20-sided die, ignoring any other numbers if they come up."" (not necessarily a direct quote, but as good as I can remember) Assuming that each side is numbered from 1 to n and that the dice are balanced, so each side has an equal probability of occurring: In my mind, a 20-sided die has a 1/20 chance that any given number will come up and a 12/20 (3/5) chance that a number between 1 and 12 will come up, although I believe this 3/5 probability becomes a 1/1 probability if you ignore any numbers between 13 and 20. Assuming that you ignore numbers 13-20, does the probability of numbers 1-12 occurring become 1/12 (i.e. the same as a 12-sided die)?  Or is it more complicated than that?",,"['probability', 'dice']"
57,I can't understand how probability makes sense,I can't understand how probability makes sense,,"I have a lot of questions regarding probability. Please forgive me if I have made mistakes. I actually tossed a coin 200 times. 54% of the time it landed on heads and 46% it landed on tails. What is the reason that there is a fair chance of the coin landing on heads or tails? Is it the randomness that causes this? If so, then in a purely random experiment would the result be 50-50? Even though probability only projects the likelihood of an event, why are the outcomes in favor of this projection? If I eliminate all the external factors during a coin toss, like air resistance, the coin is tossed in a vacuum chamber, the force to flip the coin is fixed,etc will the experiment still be random? Or will I be able to predict the outcomes? If the outcomes are indeed predictable, will the experiment be still random if I add a single atom into the chamber? If not at what point does it become random again?","I have a lot of questions regarding probability. Please forgive me if I have made mistakes. I actually tossed a coin 200 times. 54% of the time it landed on heads and 46% it landed on tails. What is the reason that there is a fair chance of the coin landing on heads or tails? Is it the randomness that causes this? If so, then in a purely random experiment would the result be 50-50? Even though probability only projects the likelihood of an event, why are the outcomes in favor of this projection? If I eliminate all the external factors during a coin toss, like air resistance, the coin is tossed in a vacuum chamber, the force to flip the coin is fixed,etc will the experiment still be random? Or will I be able to predict the outcomes? If the outcomes are indeed predictable, will the experiment be still random if I add a single atom into the chamber? If not at what point does it become random again?",,['probability']
58,"What are Belgium's chances on getting a medal at the 400m finals, given that they have 2 of the 8 athletes?","What are Belgium's chances on getting a medal at the 400m finals, given that they have 2 of the 8 athletes?",,"This is a question my wife and I pondered over at the breakfast table this morning: Belgium has two athletes in the finals of the 400m at the World Championship athletics this year. What are Belgium's chances of getting a medal, assuming every runner has the same capabilities? Plus, what's the formula/explanation for calculating this? I know/think that, if we'd have 1 athlete, it would be 3/8, because there are 3 possible medals, and 8 athletes competing. (I hope this step is correct?) But what if you have 2 athletes? Is it then just 6/8? Intuitively, that feels incorrect. But I would love to get a decent explanation on how to calculate this.","This is a question my wife and I pondered over at the breakfast table this morning: Belgium has two athletes in the finals of the 400m at the World Championship athletics this year. What are Belgium's chances of getting a medal, assuming every runner has the same capabilities? Plus, what's the formula/explanation for calculating this? I know/think that, if we'd have 1 athlete, it would be 3/8, because there are 3 possible medals, and 8 athletes competing. (I hope this step is correct?) But what if you have 2 athletes? Is it then just 6/8? Intuitively, that feels incorrect. But I would love to get a decent explanation on how to calculate this.",,['probability']
59,"Summing (0,1) uniform random variables up to 1 [duplicate]","Summing (0,1) uniform random variables up to 1 [duplicate]",,"This question already has answers here : Closed 11 years ago . Possible Duplicate: choose a random number between 0 and 1 and record its value. and keep doing it until the sum of the numbers exceeds 1. how many tries? So I'm reading a book about simulation, and in one of the chapters about random numbers generation I found the following exercise: For uniform $(0,1)$ random independent variables $U_1, U_2, \dots$ define $$ N = \min \bigg \{ n : \sum_{i=1}^n U_i > 1 \bigg \}  $$ Give an estimate for the value of $E[N]$. That is: $N$ is equal to the number of random numbers uniformly distributed in $(0,1)$ that must be summed to exceed $1$. What's the expected value of $N$? I wrote some code and I saw that the expected value of $N$  goes to $e = 2.71\dots$ The book does not ask for a formal proof of this fact, but now I'm curious! So I would like to ask for A (possibily) simple (= undergraduate level) analytic proof of this fact An intuitive explanation for this fact or both.","This question already has answers here : Closed 11 years ago . Possible Duplicate: choose a random number between 0 and 1 and record its value. and keep doing it until the sum of the numbers exceeds 1. how many tries? So I'm reading a book about simulation, and in one of the chapters about random numbers generation I found the following exercise: For uniform $(0,1)$ random independent variables $U_1, U_2, \dots$ define $$ N = \min \bigg \{ n : \sum_{i=1}^n U_i > 1 \bigg \}  $$ Give an estimate for the value of $E[N]$. That is: $N$ is equal to the number of random numbers uniformly distributed in $(0,1)$ that must be summed to exceed $1$. What's the expected value of $N$? I wrote some code and I saw that the expected value of $N$  goes to $e = 2.71\dots$ The book does not ask for a formal proof of this fact, but now I'm curious! So I would like to ask for A (possibily) simple (= undergraduate level) analytic proof of this fact An intuitive explanation for this fact or both.",,"['probability', 'random', 'random-variables']"
60,What does expected value of sum of two discrete random variables mean?,What does expected value of sum of two discrete random variables mean?,,"I am confused with summing two random variables. Suppose $X$ and $Y$ are two random variables denoting how much is gained from each two games. If two games are played together, we can gain $E[X] + E[Y]$ in total. I understand until here. However, in many textbooks, the equation $E[X+Y]=E[X]+E[Y]$ is given as an explanation to expectation of playing two games together. Explanation is more difficult than the result. What does $X+Y$ and $E[X+Y]$ mean? We define $E[X]=\sum X_ip_i$. So, do we define $E[X+Y]=\sum (X_i+Y_i)p_i$ where $p_i$ is the same for both random variables. What if $X$ denotes the equally likely outcomes $1, 2, 3$ and $Y$ denotes the equally likely outcomes $1, 2, 3, 4, 5$?","I am confused with summing two random variables. Suppose $X$ and $Y$ are two random variables denoting how much is gained from each two games. If two games are played together, we can gain $E[X] + E[Y]$ in total. I understand until here. However, in many textbooks, the equation $E[X+Y]=E[X]+E[Y]$ is given as an explanation to expectation of playing two games together. Explanation is more difficult than the result. What does $X+Y$ and $E[X+Y]$ mean? We define $E[X]=\sum X_ip_i$. So, do we define $E[X+Y]=\sum (X_i+Y_i)p_i$ where $p_i$ is the same for both random variables. What if $X$ denotes the equally likely outcomes $1, 2, 3$ and $Y$ denotes the equally likely outcomes $1, 2, 3, 4, 5$?",,"['probability', 'statistics']"
61,"What is the relationship between poisson, gamma, and exponential distribution?","What is the relationship between poisson, gamma, and exponential distribution?",,"I'm having a hard time understanding the intuitive relationship between these three distributions. I thought that poisson is what you get when you sum n number of exponentially distributed variables, but if seems that gamma is the same...Could someone describe the relationship in layman's terms?","I'm having a hard time understanding the intuitive relationship between these three distributions. I thought that poisson is what you get when you sum n number of exponentially distributed variables, but if seems that gamma is the same...Could someone describe the relationship in layman's terms?",,"['probability', 'poisson-distribution', 'gamma-distribution']"
62,Expected value of the product of functions of two independent random variables,Expected value of the product of functions of two independent random variables,,"If $X$ and $Y$ are independent random variables, are the statements below true $$E(e^{X+Y} ) = E(e^X)\times E(e^Y)$$ and  $$E(X^2\times Y^2) = E(X^2)\times E(Y^2),$$ where $E(\cdot)$ = expectation?","If $X$ and $Y$ are independent random variables, are the statements below true $$E(e^{X+Y} ) = E(e^X)\times E(e^Y)$$ and  $$E(X^2\times Y^2) = E(X^2)\times E(Y^2),$$ where $E(\cdot)$ = expectation?",,"['probability', 'statistics']"
63,coin toss question,coin toss question,,"Two players A and B each has a fair coin and they start to toss simultaneously (counted as one round). They toss in $n$ ($\ge 1$) rounds and stop because they have accumulated the same number of heads (could be 0, the case that both of them did not get any head) for the first time. What is the distribution of $n$ and its expectation?","Two players A and B each has a fair coin and they start to toss simultaneously (counted as one round). They toss in $n$ ($\ge 1$) rounds and stop because they have accumulated the same number of heads (could be 0, the case that both of them did not get any head) for the first time. What is the distribution of $n$ and its expectation?",,['probability']
64,Winning strategy for game guessing if next number is prime,Winning strategy for game guessing if next number is prime,,"I've come across an intriguing card game where a deck is used with cards numbered from $1$ to $N$ . The game proceeds as follows: the dealer draws cards one by one from the deck and shows the number on each card. At any point in the game, even before the first card is shown, a player can say ""stop"". If the number on the next card drawn is a prime number, the player wins; if it's not, the player loses. The cards in the deck are shuffled randomly, so there's no way to predict the order of the cards. I'm trying to determine the best strategy for this game to maximise the chances of winning. Also, how would you calculate the probability of winning with this strategy for a given number of cards, $N$ , in the deck? Some clarifications: The number 1 is not considered a prime. You can see and remember the cards that have been drawn out, which can inform your strategy. Knowing the number $N$ , you can identify all the prime numbers within that range beforehand. If all cards are drawn and you haven't said ""stop"" before the last one (even if it's not), you lose. Additionally, the author of the problem mentioned that there should be a strategy that optimizes the probability of winning.","I've come across an intriguing card game where a deck is used with cards numbered from to . The game proceeds as follows: the dealer draws cards one by one from the deck and shows the number on each card. At any point in the game, even before the first card is shown, a player can say ""stop"". If the number on the next card drawn is a prime number, the player wins; if it's not, the player loses. The cards in the deck are shuffled randomly, so there's no way to predict the order of the cards. I'm trying to determine the best strategy for this game to maximise the chances of winning. Also, how would you calculate the probability of winning with this strategy for a given number of cards, , in the deck? Some clarifications: The number 1 is not considered a prime. You can see and remember the cards that have been drawn out, which can inform your strategy. Knowing the number , you can identify all the prime numbers within that range beforehand. If all cards are drawn and you haven't said ""stop"" before the last one (even if it's not), you lose. Additionally, the author of the problem mentioned that there should be a strategy that optimizes the probability of winning.",1 N N N,"['probability', 'combinatorics', 'card-games']"
65,Derivation of the density function of student t-distribution from this big integral.,Derivation of the density function of student t-distribution from this big integral.,,"My lecturer posed a question where we derive the density function of the student t-distribution from the Chi-square and Standard normal distribution. I worked on this question for days, and I am pretty sure the below integral is correct (Verified by others) $$f_T(t)=\int_{-\infty}^\infty|x|2nx\times \frac{\frac{1}{2}^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}(x^2n)^{\frac{n}{2}-1}e^{-\frac{1}{2}x^2n}\frac{1}{\sqrt{2\pi}}e^{-\frac{(xt)^2}{2}}dx$$ where n is the degree of freedom of the t-distribution and $\Gamma$ is the gamma function from the Gamma distribution. My goal is $$f_T(t)=\frac{\Gamma[(n+1)/2]}{\sqrt{n\pi}\Gamma(n/2)}\left(1+\frac{t^2}{n}\right)^{-(n+1)/2}$$ I was given 2 hints. To proceed, I need to do integration by parts first, then I should use the fact that the Gamma d.f integrates to 1. From this point on, I am unsure, but I shall show you my steps. We know that the d.f of the Gamma density with parameters $\alpha=\frac{n+1}{2} \lambda=\frac{1}{2}$ integrates to $1$ , that is $\int_{0}^{\infty}g(t)dt= \int_{0}^{\infty}\frac{\frac{1}{2}^{\frac{n+1}{2}}}{\Gamma\left(\frac{n+1}{2}\right)}t^{\frac{n+1}{2}-1}e^{-\frac{1}{2}t}dt=1$ Let $t=x^2n$ .  Therefore, $dt=2xn\,dx$ We have $\int_{0}^{\infty}g(t)dt=\int_{0}^{\infty}g(x^2n)2xn\,dx=\int_{0}^{\infty}\frac{\frac{1}{2}^{\frac{n+1}{2}}}{\Gamma\left(\frac{n+1}{2}\right)}(x^2n)^{\frac{n+1}{2}-1}e^{-\frac{1}{2}(x^2n)}2xn\,dx=1$ This should be useful because I noticed the $\Gamma[(n+1)/2]$ in the end result. Working on the big integral now... $f_T(t)=\int_{-\infty}^\infty|x|2nx\times \frac{\frac{1}{2}^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}(x^2n)^{\frac{n}{2}-1}e^{-\frac{1}{2}x^2n}\frac{1}{\sqrt{2\pi}}e^{-\frac{(xt)^2}{2}}$ $=\frac{\Gamma[(n+1]/2)]}{\sqrt{n\pi}\Gamma(n/2)}\int_{-\infty}^\infty \frac{\sqrt{n\pi}\Gamma(n/2)}{\Gamma[(n+1]/2)]}|x|2nx\times \frac{\frac{1}{2}^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}(x^2n)^{\frac{n}{2}-1}e^{-\frac{1}{2}x^2n}\frac{1}{\sqrt{2\pi}}e^{-\frac{(xt)^2}{2}}dx$ After a load of manipulation, $=\frac{\Gamma[(n+1]/2)]}{\sqrt{n\pi}\Gamma(n/2)}\int_{-\infty}^\infty 2nx \frac{(\frac{1}{2})^{\frac{n+1}{2}}}{\Gamma [(n+1)/2)] }(x^2n)^{\frac{n-1}{2}}e^{-\frac{1}{2}(x^2n)}\times2n|x|e^{-\frac{(xt)^2}{2}}dx$ Note that the first half is integrate to 1. Hence I do by parts. But I still cannot get to my goal. I had tried this question for at least 6 times already now. Can I get some help? I tried to type these out as neatly as I knew how.","My lecturer posed a question where we derive the density function of the student t-distribution from the Chi-square and Standard normal distribution. I worked on this question for days, and I am pretty sure the below integral is correct (Verified by others) where n is the degree of freedom of the t-distribution and is the gamma function from the Gamma distribution. My goal is I was given 2 hints. To proceed, I need to do integration by parts first, then I should use the fact that the Gamma d.f integrates to 1. From this point on, I am unsure, but I shall show you my steps. We know that the d.f of the Gamma density with parameters integrates to , that is Let .  Therefore, We have This should be useful because I noticed the in the end result. Working on the big integral now... After a load of manipulation, Note that the first half is integrate to 1. Hence I do by parts. But I still cannot get to my goal. I had tried this question for at least 6 times already now. Can I get some help? I tried to type these out as neatly as I knew how.","f_T(t)=\int_{-\infty}^\infty|x|2nx\times \frac{\frac{1}{2}^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}(x^2n)^{\frac{n}{2}-1}e^{-\frac{1}{2}x^2n}\frac{1}{\sqrt{2\pi}}e^{-\frac{(xt)^2}{2}}dx \Gamma f_T(t)=\frac{\Gamma[(n+1)/2]}{\sqrt{n\pi}\Gamma(n/2)}\left(1+\frac{t^2}{n}\right)^{-(n+1)/2} \alpha=\frac{n+1}{2} \lambda=\frac{1}{2} 1 \int_{0}^{\infty}g(t)dt= \int_{0}^{\infty}\frac{\frac{1}{2}^{\frac{n+1}{2}}}{\Gamma\left(\frac{n+1}{2}\right)}t^{\frac{n+1}{2}-1}e^{-\frac{1}{2}t}dt=1 t=x^2n dt=2xn\,dx \int_{0}^{\infty}g(t)dt=\int_{0}^{\infty}g(x^2n)2xn\,dx=\int_{0}^{\infty}\frac{\frac{1}{2}^{\frac{n+1}{2}}}{\Gamma\left(\frac{n+1}{2}\right)}(x^2n)^{\frac{n+1}{2}-1}e^{-\frac{1}{2}(x^2n)}2xn\,dx=1 \Gamma[(n+1)/2] f_T(t)=\int_{-\infty}^\infty|x|2nx\times \frac{\frac{1}{2}^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}(x^2n)^{\frac{n}{2}-1}e^{-\frac{1}{2}x^2n}\frac{1}{\sqrt{2\pi}}e^{-\frac{(xt)^2}{2}} =\frac{\Gamma[(n+1]/2)]}{\sqrt{n\pi}\Gamma(n/2)}\int_{-\infty}^\infty \frac{\sqrt{n\pi}\Gamma(n/2)}{\Gamma[(n+1]/2)]}|x|2nx\times \frac{\frac{1}{2}^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}(x^2n)^{\frac{n}{2}-1}e^{-\frac{1}{2}x^2n}\frac{1}{\sqrt{2\pi}}e^{-\frac{(xt)^2}{2}}dx =\frac{\Gamma[(n+1]/2)]}{\sqrt{n\pi}\Gamma(n/2)}\int_{-\infty}^\infty 2nx \frac{(\frac{1}{2})^{\frac{n+1}{2}}}{\Gamma [(n+1)/2)] }(x^2n)^{\frac{n-1}{2}}e^{-\frac{1}{2}(x^2n)}\times2n|x|e^{-\frac{(xt)^2}{2}}dx","['probability', 'integration', 'definite-integrals', 'normal-distribution']"
66,Expected value of applying the sigmoid function to a normal distribution,Expected value of applying the sigmoid function to a normal distribution,,"Short version: I would like to calculate the expected value if you apply the sigmoid function $\frac{1}{1+e^{-x}}$ to a normal distribution with expected value $\mu$ and standard deviation $\sigma$ . If I'm correct this corresponds to the following integral: $$\int_{-\infty}^\infty \frac{1}{1+e^{-x}} \frac{1}{\sigma\sqrt{2\pi}}\ e^{ -\frac{(x-\mu)^2}{2\sigma^2} } dx$$ However, I can't solve this integral. I've tried manually, with Maple and with Wolfram|Alpha, but didn't get anywhere. Some background info (why I want to do this): Sigmoid functions are used in artificial neural networks as an activation function, mapping a value of $(-\infty,\infty)$ to $(0,1)$ . Often this value is used directly in further calculations but sometimes (e.g. in RBM's ) it's first stochastically rounded to a 0 or a 1, with the probabililty of a 1 being that value. The stochasticity helps the learning, but is sometimes not desired when you finally use the network. Just using the normal non-stochastic methods on a network that you trained stochastically doesn't work though. It changes the expected result, because (in short): $$\operatorname{E}[S(X)] \neq S(\operatorname{E}[X])$$ for most X. However, if you approximate X as a normal distribution and could somehow calculate this expected value, you could eliminate most of the bias. That's what I'm trying to do.","Short version: I would like to calculate the expected value if you apply the sigmoid function to a normal distribution with expected value and standard deviation . If I'm correct this corresponds to the following integral: However, I can't solve this integral. I've tried manually, with Maple and with Wolfram|Alpha, but didn't get anywhere. Some background info (why I want to do this): Sigmoid functions are used in artificial neural networks as an activation function, mapping a value of to . Often this value is used directly in further calculations but sometimes (e.g. in RBM's ) it's first stochastically rounded to a 0 or a 1, with the probabililty of a 1 being that value. The stochasticity helps the learning, but is sometimes not desired when you finally use the network. Just using the normal non-stochastic methods on a network that you trained stochastically doesn't work though. It changes the expected result, because (in short): for most X. However, if you approximate X as a normal distribution and could somehow calculate this expected value, you could eliminate most of the bias. That's what I'm trying to do.","\frac{1}{1+e^{-x}} \mu \sigma \int_{-\infty}^\infty \frac{1}{1+e^{-x}} \frac{1}{\sigma\sqrt{2\pi}}\ e^{ -\frac{(x-\mu)^2}{2\sigma^2} } dx (-\infty,\infty) (0,1) \operatorname{E}[S(X)] \neq S(\operatorname{E}[X])","['probability', 'statistics', 'integration']"
67,The expectation of absolute value of random variables,The expectation of absolute value of random variables,,"I need some help with the following problem: Let $X_1,...,X_n$ be a random sample from Normal$(0,1)$ population. Define $$Y_1=| {{1 \over n}\sum_{i=1}^{n}X_i}|, \ Y_2={1 \over n}\sum_{i=1}^{n}|X_i|.$$ Calculate $E[Y_1]$ and $E[Y_2]$, and establish the inequality between them. I may feel this should not be a very hard problem but I did get stuck somewhere. And I know it is $E[Y_1]\le E[Y_2]$ and I could prove this. But can anyone help me with how to exact find $E[Y_1]$ and $E[Y_2]$? Thanks in advance.","I need some help with the following problem: Let $X_1,...,X_n$ be a random sample from Normal$(0,1)$ population. Define $$Y_1=| {{1 \over n}\sum_{i=1}^{n}X_i}|, \ Y_2={1 \over n}\sum_{i=1}^{n}|X_i|.$$ Calculate $E[Y_1]$ and $E[Y_2]$, and establish the inequality between them. I may feel this should not be a very hard problem but I did get stuck somewhere. And I know it is $E[Y_1]\le E[Y_2]$ and I could prove this. But can anyone help me with how to exact find $E[Y_1]$ and $E[Y_2]$? Thanks in advance.",,"['probability', 'statistics']"
68,Kelly criterion with more than two outcomes,Kelly criterion with more than two outcomes,,"I want to calculate the Kelly bet for an event with more than two possible outcomes. Suppose the following game: A jar contains $10$ jelly beans. There are $7$ black jelly beans, $2$ blue jelly beans, and $1$ red jelly bean. The player wagers $x$ and grabs a single jelly bean randomly from the bag. The payouts are such: Black Jelly Bean: no payout (i.e. simply lose wager amount $x$) Blue Jelly Bean: net odds received on the wager = $10$ Red Jelly Bean: net odds received on the wager = $30$ In essence the only way to lose the bet is to grab a black jelly bean (i.e. $q = 0.7$). But the net odds received on the wager is still dependent on whether the player grabs a blue ($b = 10$) or red ($b = 30$) jelly bean. How would I calculate the Kelly bet for this game? Is it correct to simply calculate the Kelly bet for each positive outcome and then find the weighted average for the final wager? For example: $$x_b = \frac{10\times0.2 - 0.8}{10} = 0.12$$ $$x_r = \frac{30\times0.1 - 0.9}{30} = 0.07$$ $$x = \frac{0.12\times0.2 + 0.07\times0.1}{0.2 + 0.1} \approx 0.103$$ So the amount to wager would be 10.3% of the bankroll. Or should I have instead found the weighted average of the net odds received on the wager and then calculated the Kelly bet based on the winning outcomes as a whole (i.e. $p = 0.1 + 0.2 = 0.3$)? For example: $$b = \frac{10\times0.2 + 30\times0.1}{0.2 + 0.1} \approx 16.7$$ $$x = \frac{16.7\times0.3 - 0.7}{16.7} \approx 0.258 $$ So the amount to wager would be 25.8% of the bankroll.","I want to calculate the Kelly bet for an event with more than two possible outcomes. Suppose the following game: A jar contains $10$ jelly beans. There are $7$ black jelly beans, $2$ blue jelly beans, and $1$ red jelly bean. The player wagers $x$ and grabs a single jelly bean randomly from the bag. The payouts are such: Black Jelly Bean: no payout (i.e. simply lose wager amount $x$) Blue Jelly Bean: net odds received on the wager = $10$ Red Jelly Bean: net odds received on the wager = $30$ In essence the only way to lose the bet is to grab a black jelly bean (i.e. $q = 0.7$). But the net odds received on the wager is still dependent on whether the player grabs a blue ($b = 10$) or red ($b = 30$) jelly bean. How would I calculate the Kelly bet for this game? Is it correct to simply calculate the Kelly bet for each positive outcome and then find the weighted average for the final wager? For example: $$x_b = \frac{10\times0.2 - 0.8}{10} = 0.12$$ $$x_r = \frac{30\times0.1 - 0.9}{30} = 0.07$$ $$x = \frac{0.12\times0.2 + 0.07\times0.1}{0.2 + 0.1} \approx 0.103$$ So the amount to wager would be 10.3% of the bankroll. Or should I have instead found the weighted average of the net odds received on the wager and then calculated the Kelly bet based on the winning outcomes as a whole (i.e. $p = 0.1 + 0.2 = 0.3$)? For example: $$b = \frac{10\times0.2 + 30\times0.1}{0.2 + 0.1} \approx 16.7$$ $$x = \frac{16.7\times0.3 - 0.7}{16.7} \approx 0.258 $$ So the amount to wager would be 25.8% of the bankroll.",,"['probability', 'gambling']"
69,Conditional Probability $P(A \cap B \cap C)$,Conditional Probability,P(A \cap B \cap C),I'm curious what the breakdown of how the transition happens per the formula below. I get how $P(A \cap B) = P(A\mid B)P(B)$ which is the famous conditional probability. But am totally lost when there are three sets involved. Thanks!! $$P(A\cap B\cap C)=P(A)P(B\mid A)P(C\mid A\cap B)$$,I'm curious what the breakdown of how the transition happens per the formula below. I get how $P(A \cap B) = P(A\mid B)P(B)$ which is the famous conditional probability. But am totally lost when there are three sets involved. Thanks!! $$P(A\cap B\cap C)=P(A)P(B\mid A)P(C\mid A\cap B)$$,,"['probability', 'probability-theory']"
70,Entropy of a binomial distribution,Entropy of a binomial distribution,,"How do we get the functional form for the entropy of a binomial distribution? Do we use Stirling's approximation? According to Wikipedia , the entropy is: $$\frac1 2 \log_2 \big( 2\pi e\, np(1-p) \big) + O \left( \frac{1}{n} \right)$$ As of now, my every attempt has been futile so I would be extremely appreciative if someone could guide me or provide some hints for the computation.","How do we get the functional form for the entropy of a binomial distribution? Do we use Stirling's approximation? According to Wikipedia , the entropy is: $$\frac1 2 \log_2 \big( 2\pi e\, np(1-p) \big) + O \left( \frac{1}{n} \right)$$ As of now, my every attempt has been futile so I would be extremely appreciative if someone could guide me or provide some hints for the computation.",,"['probability', 'entropy']"
71,Rate of convergence in the central limit theorem (Lindeberg–Lévy),Rate of convergence in the central limit theorem (Lindeberg–Lévy),,"There are similar posts to this one on stackexchange but none of those seem to actually answer my questions. So consider the CLT in the most common form. Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables with $X_1 \in L^2(P)$ and $\mathbb{E}[X_i]= \mu$ and $\mathbb{V}ar[X_i] = \sigma^2>0$. Denote with $\widehat{X}:= \frac{(X_1+\dots+X_n)}{n}$. Then it holds that  $$\sqrt{n} (\widehat{X} - \mu) \overset{\mathscr{D}}{\longrightarrow} \mathscr{N} (0,{\sigma}^2)$$  or, equivalently,  $$\sqrt{n} \left( \frac{\widehat{X} - \mu}{\sigma} \right) \overset{\mathscr{D}}{\longrightarrow} \mathscr{N} (0,1).$$ I often see statements like the rate of convergence is of order $\frac{1}{\sqrt{n}}$. Trying to interpret this, this is what I have understood (informally) so far: According to the strong law of large numbers, given the above   conditions, $$\widehat{X} - \mu\overset{a.s.}{\longrightarrow} 0.$$   However $\widehat{X} - \mu$ stops converging to zero when multiplied   by $\sqrt{n}$. So one says that the rate of convergence is of order   $\frac{1}{\sqrt{n}}$. So here are my questions: How does one define the order of convergence in this case using formal notation? Why does one say of order $\frac{1}{\sqrt{n}}$ and not of order $\sqrt{n}$? How do we know that if multiplied, for example, by a factor of lower or higher order, like $\sqrt[3]{n}$ or $n$, one would not get a random variable converging in distribution to some a.s. non-zero random variable (as opposed to the argument: ""However $\widehat{X} - \mu$ stops converging to zero when multiplied by $\sqrt{n}$."" ? And, most importantly, can someone actually show rigorously that the rate of convergence is exactly of order $\frac{1}{\sqrt{n}}$?","There are similar posts to this one on stackexchange but none of those seem to actually answer my questions. So consider the CLT in the most common form. Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of i.i.d. random variables with $X_1 \in L^2(P)$ and $\mathbb{E}[X_i]= \mu$ and $\mathbb{V}ar[X_i] = \sigma^2>0$. Denote with $\widehat{X}:= \frac{(X_1+\dots+X_n)}{n}$. Then it holds that  $$\sqrt{n} (\widehat{X} - \mu) \overset{\mathscr{D}}{\longrightarrow} \mathscr{N} (0,{\sigma}^2)$$  or, equivalently,  $$\sqrt{n} \left( \frac{\widehat{X} - \mu}{\sigma} \right) \overset{\mathscr{D}}{\longrightarrow} \mathscr{N} (0,1).$$ I often see statements like the rate of convergence is of order $\frac{1}{\sqrt{n}}$. Trying to interpret this, this is what I have understood (informally) so far: According to the strong law of large numbers, given the above   conditions, $$\widehat{X} - \mu\overset{a.s.}{\longrightarrow} 0.$$   However $\widehat{X} - \mu$ stops converging to zero when multiplied   by $\sqrt{n}$. So one says that the rate of convergence is of order   $\frac{1}{\sqrt{n}}$. So here are my questions: How does one define the order of convergence in this case using formal notation? Why does one say of order $\frac{1}{\sqrt{n}}$ and not of order $\sqrt{n}$? How do we know that if multiplied, for example, by a factor of lower or higher order, like $\sqrt[3]{n}$ or $n$, one would not get a random variable converging in distribution to some a.s. non-zero random variable (as opposed to the argument: ""However $\widehat{X} - \mu$ stops converging to zero when multiplied by $\sqrt{n}$."" ? And, most importantly, can someone actually show rigorously that the rate of convergence is exactly of order $\frac{1}{\sqrt{n}}$?",,"['probability', 'probability-theory', 'statistics', 'central-limit-theorem', 'probability-limit-theorems']"
72,supremum of expectation $\le$ expectation of supremum?,supremum of expectation  expectation of supremum?,\le,"Suppose that $X$ is an arbitrary random variable, is the following is true for any function $f$:  $$\underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]?$$ If $f$ is convex in $X$, then the inequality clearly holds, since the supremum of a family of convex functions is still convex.  If $f$ is not convex in $X$, I think the inequality still holds for the following reason: For any realization of $X$ and any value of $y$, we have $f(X,y) \le \underset{y\in \mathcal Y} \sup f(X,y)$.  Therefore, for any $y$, $\mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$.  In other words, $\mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$ is an upper bound of the set $\left\{\mathbb E\big[f(X,y)\big]: y\in \mathcal Y\right\}$, so it follows that $\underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$. So it appears that convexity of $f$is not needed at all for the inequality to hold. Am I mistaken somewhere?  I'd appreciate it if someone would correct me, if I missed something.  Thanks a lot!","Suppose that $X$ is an arbitrary random variable, is the following is true for any function $f$:  $$\underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]?$$ If $f$ is convex in $X$, then the inequality clearly holds, since the supremum of a family of convex functions is still convex.  If $f$ is not convex in $X$, I think the inequality still holds for the following reason: For any realization of $X$ and any value of $y$, we have $f(X,y) \le \underset{y\in \mathcal Y} \sup f(X,y)$.  Therefore, for any $y$, $\mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$.  In other words, $\mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$ is an upper bound of the set $\left\{\mathbb E\big[f(X,y)\big]: y\in \mathcal Y\right\}$, so it follows that $\underset{y\in \mathcal Y} \sup \mathbb E\big[f(X,y)\big] \le \mathbb E\big[\underset{y\in \mathcal Y} \sup f(X,y)\big]$. So it appears that convexity of $f$is not needed at all for the inequality to hold. Am I mistaken somewhere?  I'd appreciate it if someone would correct me, if I missed something.  Thanks a lot!",,"['probability', 'proof-verification', 'convex-analysis', 'expectation', 'supremum-and-infimum']"
73,"$\mathbb E[X]=0$ implies existence of two random variables $Y\stackrel{\mathrm d}=Z$, equal in distribution, such that $X\stackrel{\mathrm d}=Y-Z$","implies existence of two random variables , equal in distribution, such that",\mathbb E[X]=0 Y\stackrel{\mathrm d}=Z X\stackrel{\mathrm d}=Y-Z,"Let $X$ be a bounded random variable on a non-atomic probability space, i.e. $X\in L^\infty(\mathbb P)$ , such that $\mathbb E[X]=0$ . In a lecture, I heard someone claim that this implies the existence of two other random variables $Y,Z\in L^\infty(\mathbb P)$ such that $Y\stackrel{\mathrm d}=Z$ and $X\stackrel{\mathrm d}=Y-Z$ , although they claimed the proof was difficult and tedious. Is this result even true? Even in simple examples I don't really see what this decomposition should look like. What is the intuition behind such a result? Is there perhaps a proof in the literature or in a textbook?","Let be a bounded random variable on a non-atomic probability space, i.e. , such that . In a lecture, I heard someone claim that this implies the existence of two other random variables such that and , although they claimed the proof was difficult and tedious. Is this result even true? Even in simple examples I don't really see what this decomposition should look like. What is the intuition behind such a result? Is there perhaps a proof in the literature or in a textbook?","X X\in L^\infty(\mathbb P) \mathbb E[X]=0 Y,Z\in L^\infty(\mathbb P) Y\stackrel{\mathrm d}=Z X\stackrel{\mathrm d}=Y-Z","['probability', 'probability-theory', 'measure-theory', 'reference-request']"
74,Going to the Movies!,Going to the Movies!,,"I was looking at movie times today and was struck by the oddly-spaced showing times. For example, at the local Loew's Theater ""Tron: Legacy 3D"" (127 min.) is playing on two screens at the following interlaced times: 1:00 pm, 1:45 pm, 4:00 pm, 4:45 pm, 7:00 pm, 7:45 pm, 10:00 pm and 10:45 pm. Why not space the times equally? Is there an algorithm at work here? Other than optimizing food sales by cleverly keeping a pool of waiters, the strange times might have to do with overbooking and accommodating johnnys-come-lately. Consider the following idealized scenario. Suppose only $1$ movie is a playing at a theater with $n$ screens, and free popcorn and refreshments is given upon sitting in the theater, so no other factors are relevant for spacing movie times but ticket sales. Suppose each showing can accommodate at most $N$ people. Suppose $N \pm M$ arrive at the kiosk reasonably before any particular showing time, where $0 < M < N$, and $0 < L < M$ people show up just a little too late for any particular show -- the same number of latecomers come by each time. If any person has to wait for more than some fraction $0 < R < 1$ of the time $t$ of the movie in question to watch the next movie in the cue, then he/she returns the ticket and goes home. Suppose the $\pm$ sign above is governed by tossing a fair coin, $+$ for heads, $-$ for tails. Question: Given the above data, what is the optimal spacing of $X$ movie times, each movie of the same length $t$, on $n$ different screens that maximizes the total number of ticket purchases and (happy) moviegoers? If this question is too easy, then generalize the above scenario to multiple movies showing at the same theater. If this question is too hard, then simplify it. (Of course, feel free to edit and improve.) ( Added Thoughts ) The constraints above are in place to try to model the scenario as closely as possible while keeping the mathematics simple. I'd like to account for a little randomness, and the simplest truly non-trivial random event is the tossing of a fair coin. If $N - M$ or $N + M$ people come every time, then the problem is trivial or cumulatively impossible, respectively. What makes this problem tractable is that there are some occasions when some people are left out of a showing. These people are either at the end of a long cue or literally late; either way they must wait but few, if any, will wait longer than the length of the movie. I believe the answer of spacing depends heavily on the amount of wait time. That is, if $R = 0$, $L + M > 0$ people go home every time (not optimal). If $R = 1$, then any reasonable spacing should suffice to accommodate the extremely patient moviegoers. I think this possibility oversimplifies the problem, unless I'm missing something crucial or obvious. I suppose also that the condition $L < M$ could be relaxed to $L < N$, but my reasoning is that latecomers seem to be rarer than overbookers. Are these constraints reasonable?","I was looking at movie times today and was struck by the oddly-spaced showing times. For example, at the local Loew's Theater ""Tron: Legacy 3D"" (127 min.) is playing on two screens at the following interlaced times: 1:00 pm, 1:45 pm, 4:00 pm, 4:45 pm, 7:00 pm, 7:45 pm, 10:00 pm and 10:45 pm. Why not space the times equally? Is there an algorithm at work here? Other than optimizing food sales by cleverly keeping a pool of waiters, the strange times might have to do with overbooking and accommodating johnnys-come-lately. Consider the following idealized scenario. Suppose only $1$ movie is a playing at a theater with $n$ screens, and free popcorn and refreshments is given upon sitting in the theater, so no other factors are relevant for spacing movie times but ticket sales. Suppose each showing can accommodate at most $N$ people. Suppose $N \pm M$ arrive at the kiosk reasonably before any particular showing time, where $0 < M < N$, and $0 < L < M$ people show up just a little too late for any particular show -- the same number of latecomers come by each time. If any person has to wait for more than some fraction $0 < R < 1$ of the time $t$ of the movie in question to watch the next movie in the cue, then he/she returns the ticket and goes home. Suppose the $\pm$ sign above is governed by tossing a fair coin, $+$ for heads, $-$ for tails. Question: Given the above data, what is the optimal spacing of $X$ movie times, each movie of the same length $t$, on $n$ different screens that maximizes the total number of ticket purchases and (happy) moviegoers? If this question is too easy, then generalize the above scenario to multiple movies showing at the same theater. If this question is too hard, then simplify it. (Of course, feel free to edit and improve.) ( Added Thoughts ) The constraints above are in place to try to model the scenario as closely as possible while keeping the mathematics simple. I'd like to account for a little randomness, and the simplest truly non-trivial random event is the tossing of a fair coin. If $N - M$ or $N + M$ people come every time, then the problem is trivial or cumulatively impossible, respectively. What makes this problem tractable is that there are some occasions when some people are left out of a showing. These people are either at the end of a long cue or literally late; either way they must wait but few, if any, will wait longer than the length of the movie. I believe the answer of spacing depends heavily on the amount of wait time. That is, if $R = 0$, $L + M > 0$ people go home every time (not optimal). If $R = 1$, then any reasonable spacing should suffice to accommodate the extremely patient moviegoers. I think this possibility oversimplifies the problem, unless I'm missing something crucial or obvious. I suppose also that the condition $L < M$ could be relaxed to $L < N$, but my reasoning is that latecomers seem to be rarer than overbookers. Are these constraints reasonable?",,"['probability', 'stochastic-processes', 'recreational-mathematics']"
75,"What's the probability of choosing two numbers from $[0,1]$ and having the difference at least one half? [duplicate]",What's the probability of choosing two numbers from  and having the difference at least one half? [duplicate],"[0,1]","This question already has answers here : Probability of two uniform random numbers being more than $\frac{1}{2}$ apart (5 answers) Closed 4 years ago . We have the unit interval $[0,1]$ and we want to find the probability of picking two random numbers $a,b$ from that interval with $|a-b|>0.5$. Must I investigate $[0,1]×[0,1]$? I don't have the faintest idea of how to solve this. The problem is that $[0,1]$ has infinite numbers to pick from… so how to calculate a probability with infinitely many items in the sample space? I would be really happy if somebody shed a light on this.","This question already has answers here : Probability of two uniform random numbers being more than $\frac{1}{2}$ apart (5 answers) Closed 4 years ago . We have the unit interval $[0,1]$ and we want to find the probability of picking two random numbers $a,b$ from that interval with $|a-b|>0.5$. Must I investigate $[0,1]×[0,1]$? I don't have the faintest idea of how to solve this. The problem is that $[0,1]$ has infinite numbers to pick from… so how to calculate a probability with infinitely many items in the sample space? I would be really happy if somebody shed a light on this.",,['probability']
76,Is Lewis Carroll's reasoning correct?,Is Lewis Carroll's reasoning correct?,,"A bag contains 2 counters, as to which nothing is known except that each is either black or white. Ascertain their colours without taking them out of the bag. Carroll's solution: One is black, and the other is white. Lewis Carroll's explanation: We know that, if a bag contained $3$ counters, two being black and one white, the chance of drawing a black one would be $\frac{2}{3}$ ; and that any other state of things would not give this chance. Now the chances, that the given bag contains $(\alpha)\;BB$ , $(\beta)\;BW$ , $(\gamma)\;WW$ , are respectively $\frac{1}{4}$ , $\frac{1}{2}$ , $\frac{1}{4}$ . Add a black counter. Then, the chances that it contains $(\alpha)\;BBB$ , $(\beta)\;BBW$ , $(\gamma)\;BWW$ , are, as before, $\frac{1}{4}$ , $\frac{1}{2}$ , $\frac{1}{4}$ . Hence the chances of now drawing a black one, $$= \frac{1}{4} \cdot 1 + \frac{1}{2} \cdot \frac{2}{3} + \frac{1}{4} \cdot \frac{1}{3} = \frac{2}{3}.$$ Hence the bag now contains $BBW$ (since any other state of things would not give this chance). Hence, before the black counter was added, it contained BW, i.e. one black counter and one white. Q.E.F. Can you explain this explanation? I don't completely understand the explanation to begin with. It seems like there are elements of inverse reasoning, everything he says is correct but he is basically assuming what he intends to prove. He is assuming one white, one black, then adding one black yields the $\frac{2}{3}$ . From there he goes back to state the premise as proof. Can anyone thoroughly analyze and determine if this solution contains any fallacies/slight of hand that may trick the reader?","A bag contains 2 counters, as to which nothing is known except that each is either black or white. Ascertain their colours without taking them out of the bag. Carroll's solution: One is black, and the other is white. Lewis Carroll's explanation: We know that, if a bag contained counters, two being black and one white, the chance of drawing a black one would be ; and that any other state of things would not give this chance. Now the chances, that the given bag contains , , , are respectively , , . Add a black counter. Then, the chances that it contains , , , are, as before, , , . Hence the chances of now drawing a black one, Hence the bag now contains (since any other state of things would not give this chance). Hence, before the black counter was added, it contained BW, i.e. one black counter and one white. Q.E.F. Can you explain this explanation? I don't completely understand the explanation to begin with. It seems like there are elements of inverse reasoning, everything he says is correct but he is basically assuming what he intends to prove. He is assuming one white, one black, then adding one black yields the . From there he goes back to state the premise as proof. Can anyone thoroughly analyze and determine if this solution contains any fallacies/slight of hand that may trick the reader?",3 \frac{2}{3} (\alpha)\;BB (\beta)\;BW (\gamma)\;WW \frac{1}{4} \frac{1}{2} \frac{1}{4} (\alpha)\;BBB (\beta)\;BBW (\gamma)\;BWW \frac{1}{4} \frac{1}{2} \frac{1}{4} = \frac{1}{4} \cdot 1 + \frac{1}{2} \cdot \frac{2}{3} + \frac{1}{4} \cdot \frac{1}{3} = \frac{2}{3}. BBW \frac{2}{3},"['probability', 'logic', 'puzzle', 'fake-proofs']"
77,"What is the expected length of the largest run of heads if we make 1,000 flips?","What is the expected length of the largest run of heads if we make 1,000 flips?",,"Is there a way to calculate on average, the maximum amount of times we can expect a coin to land heads during 1,000 flips? So the answer (and formula if one exists) I am looking for would be something like: during 1,000 flips we can expect a maximum run of 12 heads in a row.","Is there a way to calculate on average, the maximum amount of times we can expect a coin to land heads during 1,000 flips? So the answer (and formula if one exists) I am looking for would be something like: during 1,000 flips we can expect a maximum run of 12 heads in a row.",,['probability']
78,Example of Pairwise Independent but not Jointly Independent Random Variables?,Example of Pairwise Independent but not Jointly Independent Random Variables?,,"I am asked to: Find a joint probability distribution $P(X_1,\dots, X_n)$ such that $X_i   , \, X_j$ are independent  for all $i \neq j$ , but $(X_1, \dots , X_n)$ are   not jointly independent. I have no idea where to start, please help.","I am asked to: Find a joint probability distribution such that are independent  for all , but are   not jointly independent. I have no idea where to start, please help.","P(X_1,\dots, X_n) X_i
  , \, X_j i \neq j (X_1, \dots , X_n)","['probability', 'independence']"
79,What is the probability that a natural number is a sum of two squares?,What is the probability that a natural number is a sum of two squares?,,"Some natural numbers can be expressed as a sum of two squares: $$2=1^2+1^2$$ $$25=3^2+4^2$$ $$50=7^2+1^2$$ If one chooses a random natural number, what would be the probability that that number is a sum of two squares? Is it zero? I read about Lagrange´s theorem on squares, but it looks it can´t be useful here. NOTE 1: ""Square"" means ""square of a natural number"". NOTE 2: I am aware that the expression ""random natural number"" is not a strict math notion. However, as I said in a comment, one can adopt a reasonable strict definition, which is not difficult to devise at all. It is mentioned also in an answer below. NOTE 3: A related question on SE: How to determine whether a number can be written as a sum of two squares?","Some natural numbers can be expressed as a sum of two squares: $$2=1^2+1^2$$ $$25=3^2+4^2$$ $$50=7^2+1^2$$ If one chooses a random natural number, what would be the probability that that number is a sum of two squares? Is it zero? I read about Lagrange´s theorem on squares, but it looks it can´t be useful here. NOTE 1: ""Square"" means ""square of a natural number"". NOTE 2: I am aware that the expression ""random natural number"" is not a strict math notion. However, as I said in a comment, one can adopt a reasonable strict definition, which is not difficult to devise at all. It is mentioned also in an answer below. NOTE 3: A related question on SE: How to determine whether a number can be written as a sum of two squares?",,"['probability', 'number-theory']"
80,What exactly is a probability measure in simple words?,What exactly is a probability measure in simple words?,,"Can someone explain probability measure in simple words?  This term has been hunting me for my life. Today I came across Kullback-Leibler divergence .  The KL divergence between probability measure P and Q is defined by, $$KL(P,Q)= \begin{cases}               \int \log\left(\frac{dP} {dQ}\right)dP & \text{if}\ P\ll Q, \\               \infty & \text{otherwise}.               \end{cases}$$ I have no idea what I just read.  I looked up probability measure , it refers to probability space .  I looked that up, it refers to $\sigma$-algebra.  I told myself I have to stop. So, is a probability measure just a probability density but a broader and fancier saying? Am I overlooking a simple concept, or is this topic just that hard?","Can someone explain probability measure in simple words?  This term has been hunting me for my life. Today I came across Kullback-Leibler divergence .  The KL divergence between probability measure P and Q is defined by, $$KL(P,Q)= \begin{cases}               \int \log\left(\frac{dP} {dQ}\right)dP & \text{if}\ P\ll Q, \\               \infty & \text{otherwise}.               \end{cases}$$ I have no idea what I just read.  I looked up probability measure , it refers to probability space .  I looked that up, it refers to $\sigma$-algebra.  I told myself I have to stop. So, is a probability measure just a probability density but a broader and fancier saying? Am I overlooking a simple concept, or is this topic just that hard?",,"['probability', 'measure-theory', 'information-theory']"
81,Finding probability $P(X<Y)$,Finding probability,P(X<Y),How can I find this probability $P(X<Y)$ ? knowing that X and Y are independent random variables.,How can I find this probability $P(X<Y)$ ? knowing that X and Y are independent random variables.,,"['probability', 'statistics', 'probability-theory', 'random-variables']"
82,Proving the sum of two independent Cauchy Random Variables is Cauchy,Proving the sum of two independent Cauchy Random Variables is Cauchy,,"Is there any method to show that the sum of two independent Cauchy random variables is Cauchy? I know that it can be derived using Characteristic Functions, but the point is, I have not yet learnt Characteristic Functions. I do not know anything about Complex Analysis, Residue Theorem, etc. I would want to prove the statement only using Real Calculus. Feel free to use Double Integrals if you please. On searching, I found this . However, I was wondering if I could get some help directly on the convolution formula: $$f_Z(z)=\int_{-\infty}^\infty f_X(x)f_Y(z-x)\,dx=\int_{-\infty}^\infty\frac{1}{\pi^2}.\frac{1}{1+x^2}.\frac{1}{1+(z-x)^2}dx\tag{1}$$ Here I have supposed that $X,Y$ are Independent Standard Cauchy. But I think the general formula can be derived easily after some substitutions. I need some help on how to proceed from $(1)$ . EDIT: Just as what the hint in the hyperlink said, I got the answer using that hint. However, I am not quite sure that the hint is algebraically correct. Maybe there has been some typing mistake in the book.","Is there any method to show that the sum of two independent Cauchy random variables is Cauchy? I know that it can be derived using Characteristic Functions, but the point is, I have not yet learnt Characteristic Functions. I do not know anything about Complex Analysis, Residue Theorem, etc. I would want to prove the statement only using Real Calculus. Feel free to use Double Integrals if you please. On searching, I found this . However, I was wondering if I could get some help directly on the convolution formula: Here I have supposed that are Independent Standard Cauchy. But I think the general formula can be derived easily after some substitutions. I need some help on how to proceed from . EDIT: Just as what the hint in the hyperlink said, I got the answer using that hint. However, I am not quite sure that the hint is algebraically correct. Maybe there has been some typing mistake in the book.","f_Z(z)=\int_{-\infty}^\infty f_X(x)f_Y(z-x)\,dx=\int_{-\infty}^\infty\frac{1}{\pi^2}.\frac{1}{1+x^2}.\frac{1}{1+(z-x)^2}dx\tag{1} X,Y (1)","['probability', 'integration', 'probability-distributions', 'improper-integrals', 'convolution']"
83,How to calculate the expectation of $XY$?,How to calculate the expectation of ?,XY,"Suppose I am given the joint pdf of $X$, $Y$, and I am asked to find the $\operatorname{cov}(X,Y)$. I know that $\operatorname{cov}(X,Y)=E(XY)-E(X)E(Y)$ and I know how to find $E(X)$ and $E(Y)$. My questions are: What is the definition of $E(XY)$? Is it always equal to $$\int_{R\times R} xyf_X(x)f_Y(y)dxdy\,?$$  Or only if $X$, $Y$ are independent?(from the answer I have, the solution I have did not check the independence of $X$ and $Y$, and the answer $\operatorname{cov}(X,Y)$ is not zero, which proves $X$, $Y$ are not independent.) I remember, but not very clearly, that if the joint pdf of $X$, $Y$ $f_{X,Y}(x,y)$ can be written as $$f_{X,Y}(x,y)=g(x)h(y),$$ then $X$ and $Y$ are independent. Is it always true or need some conditions? I mean, suppose the region is not, say, $[0,1]\times[0,1]$, but, say, $0<x<1,x<y<2x$, is that saying still true? Thank you so much!","Suppose I am given the joint pdf of $X$, $Y$, and I am asked to find the $\operatorname{cov}(X,Y)$. I know that $\operatorname{cov}(X,Y)=E(XY)-E(X)E(Y)$ and I know how to find $E(X)$ and $E(Y)$. My questions are: What is the definition of $E(XY)$? Is it always equal to $$\int_{R\times R} xyf_X(x)f_Y(y)dxdy\,?$$  Or only if $X$, $Y$ are independent?(from the answer I have, the solution I have did not check the independence of $X$ and $Y$, and the answer $\operatorname{cov}(X,Y)$ is not zero, which proves $X$, $Y$ are not independent.) I remember, but not very clearly, that if the joint pdf of $X$, $Y$ $f_{X,Y}(x,y)$ can be written as $$f_{X,Y}(x,y)=g(x)h(y),$$ then $X$ and $Y$ are independent. Is it always true or need some conditions? I mean, suppose the region is not, say, $[0,1]\times[0,1]$, but, say, $0<x<1,x<y<2x$, is that saying still true? Thank you so much!",,['probability']
84,Why does the Elo rating system work?,Why does the Elo rating system work?,,"The Elo rating system is used to rank players in games such as chess. I can find plenty of explanations online of how to compute someone's Elo rating, how to actually crunch the numbers in practice, but I can't find a single clear conceptual explanation of what the rating is supposed to mean and why. The only information I can find is that apparently the Elo rating of two players allows you to calculate the odds that one player will win against the other. But every page I've been able to find that talks about this just drops the formula for how to calculate these odds on you and says ""there you go, that gives the probability of winning"", without explaining why . Wikipedia mentions something about the assumption that ""chess performance is normally distributed"", but doesn't go any further. What is the underlying probabilistic model for two-player games that the Elo system is based on? What are its basic assumptions, and what is the proof, from those assumptions, that the Elo system does indeed allow you to calculate win probabilities?","The Elo rating system is used to rank players in games such as chess. I can find plenty of explanations online of how to compute someone's Elo rating, how to actually crunch the numbers in practice, but I can't find a single clear conceptual explanation of what the rating is supposed to mean and why. The only information I can find is that apparently the Elo rating of two players allows you to calculate the odds that one player will win against the other. But every page I've been able to find that talks about this just drops the formula for how to calculate these odds on you and says ""there you go, that gives the probability of winning"", without explaining why . Wikipedia mentions something about the assumption that ""chess performance is normally distributed"", but doesn't go any further. What is the underlying probabilistic model for two-player games that the Elo system is based on? What are its basic assumptions, and what is the proof, from those assumptions, that the Elo system does indeed allow you to calculate win probabilities?",,"['probability', 'applications']"
85,Probability distribution function that does not have a density function,Probability distribution function that does not have a density function,,What is an example of the probability distribution function that does not have a density function?,What is an example of the probability distribution function that does not have a density function?,,['probability']
86,Calculating maximum-likelihood estimation of the exponential distribution and proving its consistency,Calculating maximum-likelihood estimation of the exponential distribution and proving its consistency,,"The probability density function of the exponential distribution is defined as $$ f(x;\lambda)=\begin{cases} \lambda e^{-\lambda x} &\text{if } x \geq 0 \\ 0 & \text{if } x<0 \end{cases} $$ Its likelihood function is $$ \mathcal{L}(\lambda,x_1,\dots,x_n)=\prod_{i=1}^n f(x_i,\lambda)=\prod_{i=1}^n \lambda e^{-\lambda x}=\lambda^ne^{-\lambda\sum_{i=1}^nx_i} $$ To calculate the maximum likelihood estimator I solved the equation $$ \frac{d\ln\left(\mathcal{L}(\lambda,x_1,\dots,x_n)\right)}{d\lambda}\overset{!}{=}0 $$ for $\lambda$. $$ \begin{align} \frac{d\ln\left(\mathcal{L}(\lambda,x_1,\dots,x_n)\right)}{d\lambda} &= \frac{d\ln\left(\lambda^ne^{-\lambda\sum_{i=1}^nx_i}\right)}{d\lambda} \\ &= \frac{d\ln\left(n\ln(\lambda)-\lambda\sum_{i=1}^n x_i\right)}{d\lambda} \\ &= \frac{n}{\lambda}-\sum_{i=1}^n x_i \end{align} $$ Finally we get $$\lambda = \frac{n}{\sum\limits_{i=1}^n x_i}$$ I hope this is correct this far. Where I am more uncertain is the proof for consistency. I understand that to be consistent is in this case equivalent to to converge in probability to $\lambda$ . So I have a hinch, that something like $$ \lim_{n\to\infty}\mathbb{P}\left(\mathcal{L}(\lambda,x_1,\dots,x_n)-\lambda\right)=0 $$ will lead me to a solution. Am I correct this far? If yes, how can I solve this? A hint would be great. Update: Using hints by users @Did and @cardinal I will try to show the consistency by proving that $\frac{1}{\Lambda_n}\to\frac{1}{\lambda}$ for $n\to\infty$ where $$ \Lambda_n=\frac{n}{\sum\limits_{k=1}^nX_k} $$ Since $E(X_1)=\int\limits_0^\infty\lambda xe^{-\lambda x}dx=\frac{1}{\lambda}$ and the random variables $X_i$ for $i\ge1$ are independent the strong law of large numbers implies that $$ P\left(\limsup_{n\to\infty}\left|\frac{1}{\Lambda_n}-\frac{1}{\lambda}\right|=0\right)=P\left(\limsup_{n\to\infty}\left|\frac1n\sum_{k=1}^nX_k-\frac{1}{\lambda}\right|=0\right)=1 $$ is true which implies convergence almost everywhere. This implies convergence in probability of $\Lambda_n$ to $\lambda$, which is equivalent to consistency. Is this proof correct?","The probability density function of the exponential distribution is defined as $$ f(x;\lambda)=\begin{cases} \lambda e^{-\lambda x} &\text{if } x \geq 0 \\ 0 & \text{if } x<0 \end{cases} $$ Its likelihood function is $$ \mathcal{L}(\lambda,x_1,\dots,x_n)=\prod_{i=1}^n f(x_i,\lambda)=\prod_{i=1}^n \lambda e^{-\lambda x}=\lambda^ne^{-\lambda\sum_{i=1}^nx_i} $$ To calculate the maximum likelihood estimator I solved the equation $$ \frac{d\ln\left(\mathcal{L}(\lambda,x_1,\dots,x_n)\right)}{d\lambda}\overset{!}{=}0 $$ for $\lambda$. $$ \begin{align} \frac{d\ln\left(\mathcal{L}(\lambda,x_1,\dots,x_n)\right)}{d\lambda} &= \frac{d\ln\left(\lambda^ne^{-\lambda\sum_{i=1}^nx_i}\right)}{d\lambda} \\ &= \frac{d\ln\left(n\ln(\lambda)-\lambda\sum_{i=1}^n x_i\right)}{d\lambda} \\ &= \frac{n}{\lambda}-\sum_{i=1}^n x_i \end{align} $$ Finally we get $$\lambda = \frac{n}{\sum\limits_{i=1}^n x_i}$$ I hope this is correct this far. Where I am more uncertain is the proof for consistency. I understand that to be consistent is in this case equivalent to to converge in probability to $\lambda$ . So I have a hinch, that something like $$ \lim_{n\to\infty}\mathbb{P}\left(\mathcal{L}(\lambda,x_1,\dots,x_n)-\lambda\right)=0 $$ will lead me to a solution. Am I correct this far? If yes, how can I solve this? A hint would be great. Update: Using hints by users @Did and @cardinal I will try to show the consistency by proving that $\frac{1}{\Lambda_n}\to\frac{1}{\lambda}$ for $n\to\infty$ where $$ \Lambda_n=\frac{n}{\sum\limits_{k=1}^nX_k} $$ Since $E(X_1)=\int\limits_0^\infty\lambda xe^{-\lambda x}dx=\frac{1}{\lambda}$ and the random variables $X_i$ for $i\ge1$ are independent the strong law of large numbers implies that $$ P\left(\limsup_{n\to\infty}\left|\frac{1}{\Lambda_n}-\frac{1}{\lambda}\right|=0\right)=P\left(\limsup_{n\to\infty}\left|\frac1n\sum_{k=1}^nX_k-\frac{1}{\lambda}\right|=0\right)=1 $$ is true which implies convergence almost everywhere. This implies convergence in probability of $\Lambda_n$ to $\lambda$, which is equivalent to consistency. Is this proof correct?",,"['probability', 'probability-theory', 'probability-distributions']"
87,"Probability, conditional on a zero probability event","Probability, conditional on a zero probability event",,"Is there a way to resolve probability of an event, given another event that never happens? Mathematically speaking the problem is: Given that $P(B) = 0$, $$P(A|B)=\frac{P(A \cap B)}{P(B)} = \frac{0}{0}$$ Is this probability vacuously $0$ of $1$? Can we show that it's one or the other?","Is there a way to resolve probability of an event, given another event that never happens? Mathematically speaking the problem is: Given that $P(B) = 0$, $$P(A|B)=\frac{P(A \cap B)}{P(B)} = \frac{0}{0}$$ Is this probability vacuously $0$ of $1$? Can we show that it's one or the other?",,['probability']
88,Uniform distribution on the surface of unit sphere,Uniform distribution on the surface of unit sphere,,"It is known that given $X=(X_1, X_2, \ldots, X_n)$ iid $\sim N(0,1)$, then $X/\sqrt{X_1^2+\cdots+X_n^2}$ is uniformly distributed on the surface of unit sphere. Intuitively, I know that that's because the probability of $X/\sqrt{X_1^2+\cdots+X_n^2}$ belonging to any region with the same area on the surface should be the same. But how can I prove it mathematically?","It is known that given $X=(X_1, X_2, \ldots, X_n)$ iid $\sim N(0,1)$, then $X/\sqrt{X_1^2+\cdots+X_n^2}$ is uniformly distributed on the surface of unit sphere. Intuitively, I know that that's because the probability of $X/\sqrt{X_1^2+\cdots+X_n^2}$ belonging to any region with the same area on the surface should be the same. But how can I prove it mathematically?",,"['probability', 'probability-distributions', 'normal-distribution']"
89,How 'commutative' can a non-commutative ring be?,How 'commutative' can a non-commutative ring be?,,"Let $R$ be a finite non-commutative ring.  Let $P(R)$ be the probability that two elements chosen uniformly at random commute with each other.  Consider the value $$S=\sup_RP(R)$$ where the supremum is taken over all finite, non-commutative rings, with unity.  Is anything known about $S$?  Do we know its value, or do we know any  bounds?  Does there exist a ring that achieves the supremum?  What if we consider rings without unity? This question is motivated by the notion of commutativity degree of finite groups.  In that case, it is known that  $$\sup_GP(G)=\frac{5}{8}$$ and in fact, there exist groups $G$ such that $P(G)=5/8$.  Here, the supremum is taken over finite, nonabelian groups.","Let $R$ be a finite non-commutative ring.  Let $P(R)$ be the probability that two elements chosen uniformly at random commute with each other.  Consider the value $$S=\sup_RP(R)$$ where the supremum is taken over all finite, non-commutative rings, with unity.  Is anything known about $S$?  Do we know its value, or do we know any  bounds?  Does there exist a ring that achieves the supremum?  What if we consider rings without unity? This question is motivated by the notion of commutativity degree of finite groups.  In that case, it is known that  $$\sup_GP(G)=\frac{5}{8}$$ and in fact, there exist groups $G$ such that $P(G)=5/8$.  Here, the supremum is taken over finite, nonabelian groups.",,"['probability', 'abstract-algebra', 'reference-request', 'ring-theory', 'noncommutative-algebra']"
90,Random walk: police catching the thief,Random walk: police catching the thief,,"This is a problem about the meeting time of several independent random walks on the lattice $\mathbb{Z}^1$: Suppose there is a thief at the origin 0 and $N$ policemen at the point 2. The thief and the policemen began their random walks independently at the same time following the same rule: move left or right both with probability 1/2. Let $\tau_N$ denote the first time that some policeman meets the thief. It's not hard to prove $E\tau_1=\infty$. so what is the smallest $N$ such that $E\tau_N<\infty$? I was shown this problem on my undergraduate course on Markov chains, but my teacher did not tell me the solution. Does anyone know the solution or references to the problem?","This is a problem about the meeting time of several independent random walks on the lattice $\mathbb{Z}^1$: Suppose there is a thief at the origin 0 and $N$ policemen at the point 2. The thief and the policemen began their random walks independently at the same time following the same rule: move left or right both with probability 1/2. Let $\tau_N$ denote the first time that some policeman meets the thief. It's not hard to prove $E\tau_1=\infty$. so what is the smallest $N$ such that $E\tau_N<\infty$? I was shown this problem on my undergraduate course on Markov chains, but my teacher did not tell me the solution. Does anyone know the solution or references to the problem?",,"['probability', 'random-walk']"
91,What is the average of rolling two dice and only taking the value of the higher dice roll?,What is the average of rolling two dice and only taking the value of the higher dice roll?,,"What is the average result of rolling two dice, and only taking the value of the higher dice roll? To make sure the situation I am asking about is clear, here is an example:  I roll two dice and one comes up as a four and the other a six, the result would just be six. Would the average dice roll be the same or higher than just rolling one dice?","What is the average result of rolling two dice, and only taking the value of the higher dice roll? To make sure the situation I am asking about is clear, here is an example:  I roll two dice and one comes up as a four and the other a six, the result would just be six. Would the average dice roll be the same or higher than just rolling one dice?",,"['probability', 'average', 'dice']"
92,Expected value of maximum and minimum of $n$ normal random variables,Expected value of maximum and minimum of  normal random variables,n,"Let $X_1, \dots, X_n \sim N(\mu,\sigma)$ be normal random variables. Find the expected value of random variables $\max_i(X_i)$ and $\min_i(X_i)$ . The sad truth is I don't have any good idea how to start and I'll be glad for a hint.",Let be normal random variables. Find the expected value of random variables and . The sad truth is I don't have any good idea how to start and I'll be glad for a hint.,"X_1, \dots, X_n \sim N(\mu,\sigma) \max_i(X_i) \min_i(X_i)",['probability']
93,Gamma Distribution out of sum of exponential random variables,Gamma Distribution out of sum of exponential random variables,,"I have a sequence $T_1,T_2,\ldots$ of independent exponential random variables with paramter $\lambda$. I take the sum $S=\sum_{i=1}^n T_i$ and now I would like to calculate the probability density function. Well, I know that $P(T_i>t)=e^{-\lambda t}$ and therefore $f_{T_i}(t)=\lambda e^{-\lambda t}$ so I need to find $P(T_1+\cdots+T_n>t)$ and take the derivative. But I cannot expand the probability term, you have any ideas?","I have a sequence $T_1,T_2,\ldots$ of independent exponential random variables with paramter $\lambda$. I take the sum $S=\sum_{i=1}^n T_i$ and now I would like to calculate the probability density function. Well, I know that $P(T_i>t)=e^{-\lambda t}$ and therefore $f_{T_i}(t)=\lambda e^{-\lambda t}$ so I need to find $P(T_1+\cdots+T_n>t)$ and take the derivative. But I cannot expand the probability term, you have any ideas?",,"['probability', 'probability-distributions', 'density-function', 'exponential-distribution', 'gamma-distribution']"
94,"How to prove $ E(|X-Y|) \le E(|X+Y|)$ when $X,Y$ are i.i.d variables? [duplicate]",How to prove  when  are i.i.d variables? [duplicate]," E(|X-Y|) \le E(|X+Y|) X,Y",This question already has answers here : Prove that $\Bbb{E}(|X-Y|) \le \Bbb{E}(|X+Y|)$ for i.i.d $X$ and $Y$ (3 answers) Closed 3 months ago . Let $X$ and $Y$ be independent random variables having the same distribution and the finite mathematical expectation. How to prove the inequality $$ E(|X-Y|) \le E(|X+Y|)?$$,This question already has answers here : Prove that $\Bbb{E}(|X-Y|) \le \Bbb{E}(|X+Y|)$ for i.i.d $X$ and $Y$ (3 answers) Closed 3 months ago . Let $X$ and $Y$ be independent random variables having the same distribution and the finite mathematical expectation. How to prove the inequality $$ E(|X-Y|) \le E(|X+Y|)?$$,,"['probability', 'probability-theory', 'inequality']"
95,Obtaining irrational probabilities from fair coins?,Obtaining irrational probabilities from fair coins?,,"Suppose I have access to a fair coin.  Is it possible to come up with a procedure that (1) returns TRUE with irrational probability (say $1/\sqrt{2}$) and FALSE otherwise, and (2) terminates in a finite amount of time? I would think not, because at the end of the day I'm just assigning either TRUE or FALSE to sequences of coin flips, and any such assignment results in a rational probability.  However, I don't think there's harm in asking: is there some extraordinarily clever way to extract irrational probabilities? [Edit] Alternatively, what if we relax condition (2) to ""terminates with probability 1""?  (Thanks user6312!)","Suppose I have access to a fair coin.  Is it possible to come up with a procedure that (1) returns TRUE with irrational probability (say $1/\sqrt{2}$) and FALSE otherwise, and (2) terminates in a finite amount of time? I would think not, because at the end of the day I'm just assigning either TRUE or FALSE to sequences of coin flips, and any such assignment results in a rational probability.  However, I don't think there's harm in asking: is there some extraordinarily clever way to extract irrational probabilities? [Edit] Alternatively, what if we relax condition (2) to ""terminates with probability 1""?  (Thanks user6312!)",,['probability']
96,Game Theory / Probability Interview question,Game Theory / Probability Interview question,,"Got this for an interview and didn't get it. How to solve? You and your opponent have a uniform random sampler from 0 to 1. We both sample from our own machines. Whoever has the higher number wins. The catch is when you see your number, you can resample. The opponent can re sample once but you can resample twice. What’s the probability I win? My not-confident-at-all approach: For each player you come up with a strategy that revolves around the idea of “if this number is too low, resample.” you know that for myself, I have three samples, and the EV of the third sample is 1/2. So for the second sample, if it’s below 1/2, you should resample; if above 1/2, do not resample. And you do this for the first sample with a slightly higher threshold. And then assuming our player is opponent they will follow the same approach, but they only have two rolls. No matter what, we know the game can end with six outcomes: it can end with me ending on the first, second, or third sample, and them ending on the first or second outcome. We just condition on each of those six cases and find the probability that my roll is bigger than their roll on that conditional uniform distribution.","Got this for an interview and didn't get it. How to solve? You and your opponent have a uniform random sampler from 0 to 1. We both sample from our own machines. Whoever has the higher number wins. The catch is when you see your number, you can resample. The opponent can re sample once but you can resample twice. What’s the probability I win? My not-confident-at-all approach: For each player you come up with a strategy that revolves around the idea of “if this number is too low, resample.” you know that for myself, I have three samples, and the EV of the third sample is 1/2. So for the second sample, if it’s below 1/2, you should resample; if above 1/2, do not resample. And you do this for the first sample with a slightly higher threshold. And then assuming our player is opponent they will follow the same approach, but they only have two rolls. No matter what, we know the game can end with six outcomes: it can end with me ending on the first, second, or third sample, and them ending on the first or second outcome. We just condition on each of those six cases and find the probability that my roll is bigger than their roll on that conditional uniform distribution.",,"['probability', 'game-theory']"
97,Expected time to convergence,Expected time to convergence,,"Consider the following process: we place $n$ points labelled $1...n$ uniformly at random on the interval $[0,1]$ . At each time step, two points $i, j$ are selected uniformly at random and $i$ updates its position to be a point chosen uniformly at random in the interval between the positions of $i$ and $j$ (so the interval $[p(i),p(j)]$ if $p(i) < p(j)$ or $[p(j),p(i)]$ otherwise, where $p(x)$ denotes the position of the point labelled $x$ ). What is the expected time until all points are within distance $\varepsilon$ of each other for some fixed $\varepsilon > 0$ ? What is the expected time until all points are either to the left or right of $\frac{1}{2}$ ? Asymptotic bounds are also very interesting to me.","Consider the following process: we place points labelled uniformly at random on the interval . At each time step, two points are selected uniformly at random and updates its position to be a point chosen uniformly at random in the interval between the positions of and (so the interval if or otherwise, where denotes the position of the point labelled ). What is the expected time until all points are within distance of each other for some fixed ? What is the expected time until all points are either to the left or right of ? Asymptotic bounds are also very interesting to me.","n 1...n [0,1] i, j i i j [p(i),p(j)] p(i) < p(j) [p(j),p(i)] p(x) x \varepsilon \varepsilon > 0 \frac{1}{2}","['probability', 'random-variables', 'random']"
98,Convergence of winning probability in a one-player dice-throwing game,Convergence of winning probability in a one-player dice-throwing game,,"In this (one-player) game, the player starts with a total of $n$ points.  On each turn, they choose to throw either a four-, six-, or eight-sided die, and then subtract the number thrown from their point total.  The game continues until the player's point total reaches zero exactly, and they win, or falls below zero, in which case they lose. The strategy does not seem obvious.  (Even for the simple case of $n=5$ , one must do a calculation.)  And dynamic programming techniques show that the strategy is not straightforward.  For $n≤20$ , the four-sided die is optimal, except for $n=5, 6, 13, 20$ , where the six-sided die is optimal, and $n=8, 14, 16$ , where the eight-sided die is optimal. For large $n$ , the probability of winning approaches $0.456615178766744$ , which is not a number that I recognize.  ( The ISC does not recognize it either .) It's not particularly surprising that the probability of winning converges as $n$ increases, because the probability of winning with $n$ points is the mean of probability of winning with $n-i$ points, taken over a small range of $i$ .  Considering the probabilities as a sequence, each element lies inside the range of the previous few elements, and tends to be in the middle of that range. As one goes farther out in the sequence, variations away from the mean tend to be damped out. My questions are: What's this $0.456615178766744$ ?  (For a single $d$ -sided die the probability of winning approaches $\frac 2{d+1}$ , but for more dice the problem seems harder.) Is there any regularity to the optimal move, as $n$ increases? Is there any good way estimate a good strategy, short of exhaustive computer calculations?  For example, in the $n=7$ situation, the four-sided die is significantly better than the six-sided die.  Is there some way to see this, or at least to guess that it is so? Someone must have studied this before.  Does the problem have a name?  Can someone give me a reference to the literature?","In this (one-player) game, the player starts with a total of points.  On each turn, they choose to throw either a four-, six-, or eight-sided die, and then subtract the number thrown from their point total.  The game continues until the player's point total reaches zero exactly, and they win, or falls below zero, in which case they lose. The strategy does not seem obvious.  (Even for the simple case of , one must do a calculation.)  And dynamic programming techniques show that the strategy is not straightforward.  For , the four-sided die is optimal, except for , where the six-sided die is optimal, and , where the eight-sided die is optimal. For large , the probability of winning approaches , which is not a number that I recognize.  ( The ISC does not recognize it either .) It's not particularly surprising that the probability of winning converges as increases, because the probability of winning with points is the mean of probability of winning with points, taken over a small range of .  Considering the probabilities as a sequence, each element lies inside the range of the previous few elements, and tends to be in the middle of that range. As one goes farther out in the sequence, variations away from the mean tend to be damped out. My questions are: What's this ?  (For a single -sided die the probability of winning approaches , but for more dice the problem seems harder.) Is there any regularity to the optimal move, as increases? Is there any good way estimate a good strategy, short of exhaustive computer calculations?  For example, in the situation, the four-sided die is significantly better than the six-sided die.  Is there some way to see this, or at least to guess that it is so? Someone must have studied this before.  Does the problem have a name?  Can someone give me a reference to the literature?","n n=5 n≤20 n=5, 6, 13, 20 n=8, 14, 16 n 0.456615178766744 n n n-i i 0.456615178766744 d \frac 2{d+1} n n=7","['probability', 'reference-request', 'dice', 'dynamic-programming']"
99,What are some open research problems in Stochastic Processes?,What are some open research problems in Stochastic Processes?,,"I was wondering, what are some of the open problems in the domain of Stochastic Processes. By Stochastic Processes. Any examples or recent papers or similar would be appreciated. The motivation for this question is that I was studying stochastics from a higher level (i mean, brownian motion and martingales and stuff; beyond the undergrad markov chains and memoryless properties) and was wondering what are the questions that still lie unanswered in this field?","I was wondering, what are some of the open problems in the domain of Stochastic Processes. By Stochastic Processes. Any examples or recent papers or similar would be appreciated. The motivation for this question is that I was studying stochastics from a higher level (i mean, brownian motion and martingales and stuff; beyond the undergrad markov chains and memoryless properties) and was wondering what are the questions that still lie unanswered in this field?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus']"
