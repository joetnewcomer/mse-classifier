,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"What's the difference between the different types of poles, zeroes and singularities in complex analysis?","What's the difference between the different types of poles, zeroes and singularities in complex analysis?",,"I am trying to get an understanding on the difference between the different types of poles, zeroes and singularities in complex analysis and how to identify them.  When is it a removable singularity, and why? When is it a simple pole? etc. So far I am having trouble with this, and would greatly appreciate some suggested ways of thinking/methods when trying to identify them. I don't really have an example, as I just generally want to learn and understand it.","I am trying to get an understanding on the difference between the different types of poles, zeroes and singularities in complex analysis and how to identify them.  When is it a removable singularity, and why? When is it a simple pole? etc. So far I am having trouble with this, and would greatly appreciate some suggested ways of thinking/methods when trying to identify them. I don't really have an example, as I just generally want to learn and understand it.",,['complex-analysis']
1,Evaluate the definite integral $ \int_{-\infty}^{\infty} \frac{\cos(x)}{x^4 +1} \ \ dx $,Evaluate the definite integral, \int_{-\infty}^{\infty} \frac{\cos(x)}{x^4 +1} \ \ dx ,"I am having more trouble with this problem then I feel like I should be. I set $ \ \cos(x) = e^{ix} \ $ and $ \ x^4 +1 = e^{\pi i /4} \ $ or $ \sqrt{i} \ $. I think I am suppose to do a residue to evaluate it but I'm not quite sure, was hoping someone has seen this problem before and can help me with writing out the steps, thanks!","I am having more trouble with this problem then I feel like I should be. I set $ \ \cos(x) = e^{ix} \ $ and $ \ x^4 +1 = e^{\pi i /4} \ $ or $ \sqrt{i} \ $. I think I am suppose to do a residue to evaluate it but I'm not quite sure, was hoping someone has seen this problem before and can help me with writing out the steps, thanks!",,"['integration', 'complex-analysis', 'definite-integrals', 'improper-integrals']"
2,$f$ meromorphic on $\mathbb{\hat{C}}$ $\implies$ $f$ has a finite number of poles,meromorphic on    has a finite number of poles,f \mathbb{\hat{C}} \implies f,"Setting: Let $f: \mathbb{\hat{C}}\rightarrow \mathbb{\hat{C}}$ be a meromorphic function . Let $\{p_k\}$ denote the set of poles of $f$ inside $\mathbb{\hat{C}}$. Question: Why must $\{p_k\}$ be a finite set? Attempt: I know only how to reason that $\{p_k\}$ is a countable set.  To see this, consider that the poles $p_k$ of $f$ are isolated by definition.  Hence for each $p_k$ there is associated a neighborhood $N_{p_k}$ about $p_k$ s.t. there are no poles inside $N_{p_k}$.  Then we have that $$ j \ne k \implies N_{p_k} \cap N_{p_j} = \emptyset $$ so that if $\{p_k\}$ were uncountable, we would have that $\bigcup N_{p_k} \subsetneq \mathbb{\hat{C}}$ which is absurd (an uncountable number of neighborhoods of $\mathbb{\hat{C}}$ must cover $\mathbb{\hat{C}}$). So how do I show that $\{p_k\}$ is finite?","Setting: Let $f: \mathbb{\hat{C}}\rightarrow \mathbb{\hat{C}}$ be a meromorphic function . Let $\{p_k\}$ denote the set of poles of $f$ inside $\mathbb{\hat{C}}$. Question: Why must $\{p_k\}$ be a finite set? Attempt: I know only how to reason that $\{p_k\}$ is a countable set.  To see this, consider that the poles $p_k$ of $f$ are isolated by definition.  Hence for each $p_k$ there is associated a neighborhood $N_{p_k}$ about $p_k$ s.t. there are no poles inside $N_{p_k}$.  Then we have that $$ j \ne k \implies N_{p_k} \cap N_{p_j} = \emptyset $$ so that if $\{p_k\}$ were uncountable, we would have that $\bigcup N_{p_k} \subsetneq \mathbb{\hat{C}}$ which is absurd (an uncountable number of neighborhoods of $\mathbb{\hat{C}}$ must cover $\mathbb{\hat{C}}$). So how do I show that $\{p_k\}$ is finite?",,"['complex-analysis', 'analysis']"
3,"Contour method to solve $\int^\infty_0\frac{\ln(1+x)}{1+x^2}\,dx$",Contour method to solve,"\int^\infty_0\frac{\ln(1+x)}{1+x^2}\,dx","Prove the following using complex analysis $$\tag{1}\int^\infty_0\frac{\ln(1+x)}{1+x^2}\,dx=\frac{\pi}{2}\ln(2)$$ I found this problem in Schaum's outlines of complex variables. I thought that we could solve the problem using a similar method to evaluating $$\int^\infty_0\frac{\ln(1+x^2)}{1+x^2}\,dx$$ Where we integrate the function $$f=\frac{\log(1-iz)}{z^2+1}$$ around half a circle in the upper half plane and chosing an analytic branch of the logarithm in the region. I spent so much time on (1) without success.","Prove the following using complex analysis $$\tag{1}\int^\infty_0\frac{\ln(1+x)}{1+x^2}\,dx=\frac{\pi}{2}\ln(2)$$ I found this problem in Schaum's outlines of complex variables. I thought that we could solve the problem using a similar method to evaluating $$\int^\infty_0\frac{\ln(1+x^2)}{1+x^2}\,dx$$ Where we integrate the function $$f=\frac{\log(1-iz)}{z^2+1}$$ around half a circle in the upper half plane and chosing an analytic branch of the logarithm in the region. I spent so much time on (1) without success.",,"['complex-analysis', 'contour-integration']"
4,Show that $f$ is identically zero.,Show that  is identically zero.,f,Let $f$ be a entire function. Assume that there exist a real number $a$ such that $f^{(r)}(a)=0$ for all integer $r≥0$. My question is show that the function $f$ is identically zero.,Let $f$ be a entire function. Assume that there exist a real number $a$ such that $f^{(r)}(a)=0$ for all integer $r≥0$. My question is show that the function $f$ is identically zero.,,['complex-analysis']
5,Integral $ \int_{-\infty}^\infty \frac{e^{ikx}}{x^{3/2}}dx$,Integral, \int_{-\infty}^\infty \frac{e^{ikx}}{x^{3/2}}dx,Hi I'm trying to solve this integral Fourier Transform $$ \int_{-\infty}^\infty \frac{e^{ikx}}{x^{3/2}}dx=\sqrt{2\pi|k|}(1+i)  (-1+\text{sgn}(k)) $$ where sgn(k)$=1$ for k>1 and $-1$ for k<1. I am trying to use residues.  Thanks there is a singularity at $x=0$.  We can try and write $$ e^{ikx}=\cos x+i\sin x $$ but I don't think it will help.  IT will be nice to use a contour with $e^{ikx}$ instead.  Thanks,Hi I'm trying to solve this integral Fourier Transform $$ \int_{-\infty}^\infty \frac{e^{ikx}}{x^{3/2}}dx=\sqrt{2\pi|k|}(1+i)  (-1+\text{sgn}(k)) $$ where sgn(k)$=1$ for k>1 and $-1$ for k<1. I am trying to use residues.  Thanks there is a singularity at $x=0$.  We can try and write $$ e^{ikx}=\cos x+i\sin x $$ but I don't think it will help.  IT will be nice to use a contour with $e^{ikx}$ instead.  Thanks,,"['integration', 'complex-analysis', 'fourier-analysis', 'definite-integrals', 'contour-integration']"
6,"Describe the set of harmonic functions $h(x,y)$on $\mathbb{C}$ s.t. $(x^2-y^2)h(x,y)$ is harmonic.",Describe the set of harmonic functions on  s.t.  is harmonic.,"h(x,y) \mathbb{C} (x^2-y^2)h(x,y)","The following is a qual-prep question: Describe the set of harmonic functions $h(x,y)$on $\mathbb{C}$ s.t. $(x^2-y^2)h(x,y)$ is harmonic. I've tried using the definition of harmonic function from which after some algebraic manipulations I can see that $h$ must satisfy $y \frac{\partial h}{\partial y} = x \frac{\partial h}{\partial x}$. But I think the answer calls for a more explicit answer and I don't know how to go from here.","The following is a qual-prep question: Describe the set of harmonic functions $h(x,y)$on $\mathbb{C}$ s.t. $(x^2-y^2)h(x,y)$ is harmonic. I've tried using the definition of harmonic function from which after some algebraic manipulations I can see that $h$ must satisfy $y \frac{\partial h}{\partial y} = x \frac{\partial h}{\partial x}$. But I think the answer calls for a more explicit answer and I don't know how to go from here.",,['complex-analysis']
7,A complex analysis problem---concerning distance,A complex analysis problem---concerning distance,,"Let $z_i, i=1,2,\cdots,n$ be $n$ points in $\mathbb{C}$ such that $|z_i|>1$. Prove that there exists at least one $z_0$ satisfying $|z_0|=1$ and $\prod_{i=1}^n |z_i-z_0|>1$. I do not have any idea after two days of thinking.","Let $z_i, i=1,2,\cdots,n$ be $n$ points in $\mathbb{C}$ such that $|z_i|>1$. Prove that there exists at least one $z_0$ satisfying $|z_0|=1$ and $\prod_{i=1}^n |z_i-z_0|>1$. I do not have any idea after two days of thinking.",,"['complex-analysis', 'complex-numbers']"
8,Complex Analysis - function on open unit disk with $\Re(f(z)) \geq 0$,Complex Analysis - function on open unit disk with,\Re(f(z)) \geq 0,"Suppose $f:D \to \mathbb C$ is an analytic and non-constant function with $\Re(f(z)) \geq 0$ for all $z \in D$. Show that $\Re(f(z)) > 0$ for all $z \in D$, and that $\left|f(z)\right|\leq \frac{1+|z|}{1-|z|}$ for all $z \in D$ if given that $f(0)=1$. For the first part of the question, my attempt at a solution is brief: consider any $ z_0 \in D$ and any $0<r<\left||z_0|-1\right|$. By the Open Mapping Theorem, $f(B(z_0, r))$ is open in $\mathbb C$. But that means, assuming $\Re(f(z_0))=0$, that there must be some $\omega \in f(B(z_0,r))$ such that $\Re(\omega)<0$, since $f(B(z_0,r)) \cap \{z:\Re(z)<0\} \not = \emptyset$. Thus there is some $z_{\omega} \in D$ such that $\Re(f(z_{\omega}))<0$, a contradiction. Thus the first part in the statement is proved. For the second part of the question, however, I am not certain how to proceed. The setup looks very similar to the conditions for Schwartz' Lemma or the Schwartz-Pick Estimate, so I attempted to analyze $g(z)=f(z)-1$, unfortunately to no avail. Appreciate your input!","Suppose $f:D \to \mathbb C$ is an analytic and non-constant function with $\Re(f(z)) \geq 0$ for all $z \in D$. Show that $\Re(f(z)) > 0$ for all $z \in D$, and that $\left|f(z)\right|\leq \frac{1+|z|}{1-|z|}$ for all $z \in D$ if given that $f(0)=1$. For the first part of the question, my attempt at a solution is brief: consider any $ z_0 \in D$ and any $0<r<\left||z_0|-1\right|$. By the Open Mapping Theorem, $f(B(z_0, r))$ is open in $\mathbb C$. But that means, assuming $\Re(f(z_0))=0$, that there must be some $\omega \in f(B(z_0,r))$ such that $\Re(\omega)<0$, since $f(B(z_0,r)) \cap \{z:\Re(z)<0\} \not = \emptyset$. Thus there is some $z_{\omega} \in D$ such that $\Re(f(z_{\omega}))<0$, a contradiction. Thus the first part in the statement is proved. For the second part of the question, however, I am not certain how to proceed. The setup looks very similar to the conditions for Schwartz' Lemma or the Schwartz-Pick Estimate, so I attempted to analyze $g(z)=f(z)-1$, unfortunately to no avail. Appreciate your input!",,['complex-analysis']
9,Finite order function in the complex analysis.,Finite order function in the complex analysis.,,"Assume that an entire function $f$ be finite order with finitely many zeros. Please show that either $f(z)$ is a polynomial or $f(z) + z$ has infinitely many zeros. Thank you. And I know the following theorem, Suppose f is entire function of finite order. Then either f has infinitely many zeros or $f(z)$ is of the form $Q(z)e^{P(z)}$ for polynomials $P$ and $Q$.","Assume that an entire function $f$ be finite order with finitely many zeros. Please show that either $f(z)$ is a polynomial or $f(z) + z$ has infinitely many zeros. Thank you. And I know the following theorem, Suppose f is entire function of finite order. Then either f has infinitely many zeros or $f(z)$ is of the form $Q(z)e^{P(z)}$ for polynomials $P$ and $Q$.",,"['complex-analysis', 'analysis', 'self-learning', 'harmonic-functions']"
10,Conformal Mappings from $xy=1$ to the upper half plane?,Conformal Mappings from  to the upper half plane?,xy=1,"For a complex analysis class, I need to find a bijective conformal mapping that maps the region between the hyperbolas $xy = 1$ to the upper half plane. Any ideas? I'm trying to map the curve to $y=0$ as a first step... but no such luck... reference texts and internet queries only turn up discs, rectangular regions, wedges, and the like. Much appreciated.","For a complex analysis class, I need to find a bijective conformal mapping that maps the region between the hyperbolas $xy = 1$ to the upper half plane. Any ideas? I'm trying to map the curve to $y=0$ as a first step... but no such luck... reference texts and internet queries only turn up discs, rectangular regions, wedges, and the like. Much appreciated.",,['complex-analysis']
11,"Calculate $\int_\Gamma \frac{f'(z)z}{f(z)}\, \operatorname dz$",Calculate,"\int_\Gamma \frac{f'(z)z}{f(z)}\, \operatorname dz","Calculate usign the formula for zeros and poles, for a meromorphic function $f$ the following:  $$\int_\Gamma \frac{f'(z)z}{f(z)}\, \operatorname dz$$ Where $\Gamma$ is simple and closed. I tried writting $ \dfrac{f'(z)z}{f(z)}=\dfrac{g'(z)}{g(z)}$ for some meromorphic function (and then use the formula for zeros and poles for $g$) $g$ but I can't find $g$. I don't know if this idea is good for reducing this integral.","Calculate usign the formula for zeros and poles, for a meromorphic function $f$ the following:  $$\int_\Gamma \frac{f'(z)z}{f(z)}\, \operatorname dz$$ Where $\Gamma$ is simple and closed. I tried writting $ \dfrac{f'(z)z}{f(z)}=\dfrac{g'(z)}{g(z)}$ for some meromorphic function (and then use the formula for zeros and poles for $g$) $g$ but I can't find $g$. I don't know if this idea is good for reducing this integral.",,"['complex-analysis', 'laurent-series']"
12,Composition of continious and analytic map,Composition of continious and analytic map,,"Let $U,V,W\subset\mathbb{C}$ open and connected, $f:U\to V$ continous and $g:V\to W$ analytic and non-constant. If $g\circ f$ is analytic, does then $f$ have to be analytic as well? I guess the answer is yes but I don't know how to prove it.","Let $U,V,W\subset\mathbb{C}$ open and connected, $f:U\to V$ continous and $g:V\to W$ analytic and non-constant. If $g\circ f$ is analytic, does then $f$ have to be analytic as well? I guess the answer is yes but I don't know how to prove it.",,"['complex-analysis', 'analyticity']"
13,Proofs that there is no $f(z)$ such that $\exp f(z) = z$ for all $z \in \Bbb{C}\setminus\{0\}$,Proofs that there is no  such that  for all,f(z) \exp f(z) = z z \in \Bbb{C}\setminus\{0\},"When I first learned about this result I was completely stunned that there is no holomorphic function $f(z)$ on $\Bbb{C}\setminus\{0\}$ such that $\exp f(z) = z$. What are some interesting proofs of this? Here are two I know of. Proof 1: Assume we have such an $f(z)$. Then restricted to $\Bbb{C}\setminus (-\infty,0]$ we must have $f(z) = \operatorname{Log} z + 2\pi k i$ for some $k \in \Bbb{Z}$. The big log stands for principal log. But now the  $\lim_{z \to a} f(z)$ for any $a \in (-\infty,0]$ does not exist (approaching from the top, the argument approaches $\pi$ but from the bottom it approaches $-\pi$). Proof 2: If we had a holomorphic function $f(z)$ such that $\exp f(z) = z$ then differentiating gives $f'(z) = 1/z$ for all $z \neq 0$. Integrating on $|z|=1$, the left gives $0$ by Cauchy's Theorem but the right is $2\pi i$ which is a contradiction.","When I first learned about this result I was completely stunned that there is no holomorphic function $f(z)$ on $\Bbb{C}\setminus\{0\}$ such that $\exp f(z) = z$. What are some interesting proofs of this? Here are two I know of. Proof 1: Assume we have such an $f(z)$. Then restricted to $\Bbb{C}\setminus (-\infty,0]$ we must have $f(z) = \operatorname{Log} z + 2\pi k i$ for some $k \in \Bbb{Z}$. The big log stands for principal log. But now the  $\lim_{z \to a} f(z)$ for any $a \in (-\infty,0]$ does not exist (approaching from the top, the argument approaches $\pi$ but from the bottom it approaches $-\pi$). Proof 2: If we had a holomorphic function $f(z)$ such that $\exp f(z) = z$ then differentiating gives $f'(z) = 1/z$ for all $z \neq 0$. Integrating on $|z|=1$, the left gives $0$ by Cauchy's Theorem but the right is $2\pi i$ which is a contradiction.",,['complex-analysis']
14,Inequality with condition similar to Schwarz lemma,Inequality with condition similar to Schwarz lemma,,"Suppose $f(z)$ is holomorphic and $|f(z)|\leq 1$ for $|z|\leq 1$. Show that $$\frac{|f'(z)|}{1-|f(z)|^2}\leq \frac{1}{1-|z|^2}.$$ If I also have the condition $f(0)=0$, I would be able to use the Schwarz lemma to conclude that $|f(z)|\leq|z|$ and $|f'(0)|\leq 1$. But I don't know how I can imply the inequality above. If $f(0)=0$, I want to define $g(z)=f(z)-f(0)$, so that $g(0)=0$, but then the condition $|g(z)|\leq 1$ for $|z|\leq 1$ is not true. How can I get around those issues?","Suppose $f(z)$ is holomorphic and $|f(z)|\leq 1$ for $|z|\leq 1$. Show that $$\frac{|f'(z)|}{1-|f(z)|^2}\leq \frac{1}{1-|z|^2}.$$ If I also have the condition $f(0)=0$, I would be able to use the Schwarz lemma to conclude that $|f(z)|\leq|z|$ and $|f'(0)|\leq 1$. But I don't know how I can imply the inequality above. If $f(0)=0$, I want to define $g(z)=f(z)-f(0)$, so that $g(0)=0$, but then the condition $|g(z)|\leq 1$ for $|z|\leq 1$ is not true. How can I get around those issues?",,['complex-analysis']
15,Real root of a complex equation.,Real root of a complex equation.,,"I was working on a problem from Gamelin; where I was required to find out zeros of $2z^5+6z^1-1$ , in the unit disk (in $\mathbb C$). I applied Rouché's theorem and find out zeros in the unit disk and I got to know that there is only one zero inside it. Further, I have to show that it has one zero inside $(0,1)$ : Following is my answer and I am not sure about it. please correct me if i am wrong. This polynomial have only one zero inside the open unit disk. Therefore the only root that exist in unit disk must be a real one. Because complex roots exist only in pairs. Now we have to show that this zero is positive. Is it right if I say that, there is 1 changes in sign of the function's coefficients, so there will be at most 1 positive roots (maybe less). And now put -z on the place of z then all coefficients of the polynomial will turn negative. Therefore there is no negative root. So the only root that we have in the unit disk must be real; so it will lie in $(0,1)$.","I was working on a problem from Gamelin; where I was required to find out zeros of $2z^5+6z^1-1$ , in the unit disk (in $\mathbb C$). I applied Rouché's theorem and find out zeros in the unit disk and I got to know that there is only one zero inside it. Further, I have to show that it has one zero inside $(0,1)$ : Following is my answer and I am not sure about it. please correct me if i am wrong. This polynomial have only one zero inside the open unit disk. Therefore the only root that exist in unit disk must be a real one. Because complex roots exist only in pairs. Now we have to show that this zero is positive. Is it right if I say that, there is 1 changes in sign of the function's coefficients, so there will be at most 1 positive roots (maybe less). And now put -z on the place of z then all coefficients of the polynomial will turn negative. Therefore there is no negative root. So the only root that we have in the unit disk must be real; so it will lie in $(0,1)$.",,"['real-analysis', 'complex-analysis', 'roots']"
16,Solving imaginary equation $z^3 = 5i + 5$,Solving imaginary equation,z^3 = 5i + 5,I need help solving the equation : $z^3 = 5i + 5$. I'm basically just starting to learn imaginary numbers and how to solve them.  Straight forward solution is a pain ( was trying to figure out with step-by-step solution from wolframalpha ). After that I was reading wikipedia about them and came across with the De Moivre's formula that states $z^n = |z|^n (\cos(n\phi) + i\sin(n\phi))$ but I have no clue how to use it with this example. I would greatly appreciate some help on this. Maybe it is possible to do it another way? Thanks in advance.,I need help solving the equation : $z^3 = 5i + 5$. I'm basically just starting to learn imaginary numbers and how to solve them.  Straight forward solution is a pain ( was trying to figure out with step-by-step solution from wolframalpha ). After that I was reading wikipedia about them and came across with the De Moivre's formula that states $z^n = |z|^n (\cos(n\phi) + i\sin(n\phi))$ but I have no clue how to use it with this example. I would greatly appreciate some help on this. Maybe it is possible to do it another way? Thanks in advance.,,"['complex-analysis', 'complex-numbers']"
17,Use residues to evaluate $\int_{0}^{\infty} \frac{dx}{x^2 + 1}$,Use residues to evaluate,\int_{0}^{\infty} \frac{dx}{x^2 + 1},Use residues to evaluate $\int_{0}^{\infty} \frac{dx}{x^2 + 1}$. Okay so these are the integrals in complex analysis I am a little uncomfortable with. I purposely chose a simple problem out of a book so that I can save the slightly more difficult problems for when I actually understand them. The answer to this problem is $\frac{\pi}{2}$. Could someone please explain to me how to solve improper integrals in complex analysis using the problem I have provided as an example. I would appreciate it very much.,Use residues to evaluate $\int_{0}^{\infty} \frac{dx}{x^2 + 1}$. Okay so these are the integrals in complex analysis I am a little uncomfortable with. I purposely chose a simple problem out of a book so that I can save the slightly more difficult problems for when I actually understand them. The answer to this problem is $\frac{\pi}{2}$. Could someone please explain to me how to solve improper integrals in complex analysis using the problem I have provided as an example. I would appreciate it very much.,,['complex-analysis']
18,"When a pole lies outside the circle of integration, what does Cauchy integral formula state?","When a pole lies outside the circle of integration, what does Cauchy integral formula state?",,"I have the following complex line integral: $$ \int_{|z| = 2} \frac{z}{z - 3} $$ My prof said it is $0$, but did not explain. He just said that the point $3+0i$ lies outside the circle. But the Cauchy integral theorem does not mention anything about it. Can anybody give me the proof and also mention does this happen even if the point lies outside the circle/loop and the function is not analytic inside it.","I have the following complex line integral: $$ \int_{|z| = 2} \frac{z}{z - 3} $$ My prof said it is $0$, but did not explain. He just said that the point $3+0i$ lies outside the circle. But the Cauchy integral theorem does not mention anything about it. Can anybody give me the proof and also mention does this happen even if the point lies outside the circle/loop and the function is not analytic inside it.",,"['integration', 'complex-analysis', 'contour-integration']"
19,Complex differentiation under the integral sign (Ahlfors),Complex differentiation under the integral sign (Ahlfors),,"In Ahlfors' Complex Analysis text, page 202, he claims that in $\{ \Re z>0 \} $ $$\frac{d}{dz} \int_0^\infty \frac{2 \eta}{\eta^2+z^2} \frac{\mathrm d \eta}{e^{2 \pi \eta}-1}=- \int_0^\infty \frac{4 \eta z}{(\eta^2+z^2)^2} \frac{ \mathrm{d} \eta}{e^{2 \pi \eta}-1} $$ ""because the integral on the RHS converges uniformly when $z$ is restricted to any compact set in the half plane $x > 0$."" I can't see why is that the case. I tried forming the quotient $\frac{F(z+\Delta z)-F(z)}{\Delta z}$, but I can't see where does his remark kicks in. Why is his reasoning valid?","In Ahlfors' Complex Analysis text, page 202, he claims that in $\{ \Re z>0 \} $ $$\frac{d}{dz} \int_0^\infty \frac{2 \eta}{\eta^2+z^2} \frac{\mathrm d \eta}{e^{2 \pi \eta}-1}=- \int_0^\infty \frac{4 \eta z}{(\eta^2+z^2)^2} \frac{ \mathrm{d} \eta}{e^{2 \pi \eta}-1} $$ ""because the integral on the RHS converges uniformly when $z$ is restricted to any compact set in the half plane $x > 0$."" I can't see why is that the case. I tried forming the quotient $\frac{F(z+\Delta z)-F(z)}{\Delta z}$, but I can't see where does his remark kicks in. Why is his reasoning valid?",,"['complex-analysis', 'integration', 'derivatives']"
20,Rotations around the origin,Rotations around the origin,,"The problem is to find the number of rotations around the origin for the function $$f(z)=z^{2013}+2z+1 $$ when $z$ moves through $\left\{|z|=1\right\}$. I tried to solve it with the help of argument principle. $${{N}_{r}}\left( {{z}^{2013}}+2z+1 \right)={{N}_{\left| z \right|<1}}\left( {{z}^{2013}}+2z+1 \right),$$ where ${{N}_{r}}$ - number of rotations around origin, ${{N}_{\left| z \right|<1}}$- number of zeros of ${{z}^{2013}}+2z+1$ in $\left\{ z:\left| z \right|<1 \right\}$. As ${{z}^{2013}}+2z+1$ is continuous function and ${{z}^{2013}}+2z+1$has no roots on $\left\{ \left| z \right|=1 \right\}$, we can use the theorem of Rouché: if we take $r=0.999999$ then  $$|z^{2013}+1|<r^{2013}+1<2r=|2z| ,$$ so, there is only 1 root in $\left\{ z:\left| z \right|<0.999999 \right\}$. But if we take $r=1.001$ and use this theorem again, $$|2z|<2r<||r|^{2013}-|1||\le|z^{2013}+1|,$$ so, in $\left\{|z|<1.001\right\}$ there are 2013 roots. But how many roots are there in  $\left\{1<|z|<1.001\right\}$ and $\left\{0.999999<|z|<1\right\}$ -- is unknown. Anything usefull will be appreciated.","The problem is to find the number of rotations around the origin for the function $$f(z)=z^{2013}+2z+1 $$ when $z$ moves through $\left\{|z|=1\right\}$. I tried to solve it with the help of argument principle. $${{N}_{r}}\left( {{z}^{2013}}+2z+1 \right)={{N}_{\left| z \right|<1}}\left( {{z}^{2013}}+2z+1 \right),$$ where ${{N}_{r}}$ - number of rotations around origin, ${{N}_{\left| z \right|<1}}$- number of zeros of ${{z}^{2013}}+2z+1$ in $\left\{ z:\left| z \right|<1 \right\}$. As ${{z}^{2013}}+2z+1$ is continuous function and ${{z}^{2013}}+2z+1$has no roots on $\left\{ \left| z \right|=1 \right\}$, we can use the theorem of Rouché: if we take $r=0.999999$ then  $$|z^{2013}+1|<r^{2013}+1<2r=|2z| ,$$ so, there is only 1 root in $\left\{ z:\left| z \right|<0.999999 \right\}$. But if we take $r=1.001$ and use this theorem again, $$|2z|<2r<||r|^{2013}-|1||\le|z^{2013}+1|,$$ so, in $\left\{|z|<1.001\right\}$ there are 2013 roots. But how many roots are there in  $\left\{1<|z|<1.001\right\}$ and $\left\{0.999999<|z|<1\right\}$ -- is unknown. Anything usefull will be appreciated.",,"['complex-analysis', 'plane-curves']"
21,Find all complex solutions to an exponential equation,Find all complex solutions to an exponential equation,,Find all complex numbers z such that $e^{-2iz}/4 + e^{-iz}/2 + 1 + 2e^{iz} + 4e^{2iz} = 0 $ Rewriting the left-hand side using Eulers formula doesn't seem to get me anywhere. Need some help with this one! Thanks in advance!,Find all complex numbers z such that $e^{-2iz}/4 + e^{-iz}/2 + 1 + 2e^{iz} + 4e^{2iz} = 0 $ Rewriting the left-hand side using Eulers formula doesn't seem to get me anywhere. Need some help with this one! Thanks in advance!,,['complex-analysis']
22,Hard integral that standard CAS get totally wrong,Hard integral that standard CAS get totally wrong,,"How to solve the following integral: $$\int_{-\infty }^{\infty }\exp \left ( i\left ( ax^3+bx^2 \right ) \right )dx$$ Standard CAS seem to get it totally wrong, see: http://www.walkingrandomly.com/?p=5031 So what is the right ansatz and solution? EDIT There seems to be a problem with the way this question is posed... which I quite frankly don't get. To clarify I posted this follow-up question: In which senses can an integral exist?","How to solve the following integral: $$\int_{-\infty }^{\infty }\exp \left ( i\left ( ax^3+bx^2 \right ) \right )dx$$ Standard CAS seem to get it totally wrong, see: http://www.walkingrandomly.com/?p=5031 So what is the right ansatz and solution? EDIT There seems to be a problem with the way this question is posed... which I quite frankly don't get. To clarify I posted this follow-up question: In which senses can an integral exist?",,"['complex-analysis', 'integration']"
23,"If $f$ has a pole at $z_0$, then $1/f$ has a removable singularity","If  has a pole at , then  has a removable singularity",f z_0 1/f,"I tried a few examples and I think that the following in complex analysis holds:  If a function $f$ has a pole at $z_0$, then $1/f$ has a removable singularity at this point. Is this correct?","I tried a few examples and I think that the following in complex analysis holds:  If a function $f$ has a pole at $z_0$, then $1/f$ has a removable singularity at this point. Is this correct?",,[]
24,Special biholomorphic mapping from $ \mathbb{C} \setminus \{z : z \le 0\}$ to the unit disk,Special biholomorphic mapping from  to the unit disk, \mathbb{C} \setminus \{z : z \le 0\},"I was looking at a previous post ( A bounded holomorphic function ). I'm asking this in a separate post, because I didn't want to interrupt the flow of the comments following the answer with what's likely to be a misunderstanding on my part. There was an argument which seemed to me to involve using a special biholomorphic map taking the slit plane region $\Omega = \mathbb{C} \setminus \{z : z \le 0\}$  to the unit disk $\Delta$ in a way that allowed it to be composed with an even function on the disk, in order to produce a continuous function on all of $\mathbb{C}$. My question is: Is there a biholomorphic map $f:\Delta \to \Omega$ with $\lim \limits _{z \to a} f(z) = \lim \limits _{z \to a} f(-z)$ for all $|a| = 1$? Is there a biholomorphic map $F:\Omega \to \Delta$ with $\lim \limits _{t \to 0} F(x + it) = - \lim \limits _{t \to 0} F(x - it)$ when $x \le 0$? Thanks in advance for any thoughts!","I was looking at a previous post ( A bounded holomorphic function ). I'm asking this in a separate post, because I didn't want to interrupt the flow of the comments following the answer with what's likely to be a misunderstanding on my part. There was an argument which seemed to me to involve using a special biholomorphic map taking the slit plane region $\Omega = \mathbb{C} \setminus \{z : z \le 0\}$  to the unit disk $\Delta$ in a way that allowed it to be composed with an even function on the disk, in order to produce a continuous function on all of $\mathbb{C}$. My question is: Is there a biholomorphic map $f:\Delta \to \Omega$ with $\lim \limits _{z \to a} f(z) = \lim \limits _{z \to a} f(-z)$ for all $|a| = 1$? Is there a biholomorphic map $F:\Omega \to \Delta$ with $\lim \limits _{t \to 0} F(x + it) = - \lim \limits _{t \to 0} F(x - it)$ when $x \le 0$? Thanks in advance for any thoughts!",,['complex-analysis']
25,How to find $\int_0^{2\pi} \frac{dt}{1+2\cos(t)}$,How to find,\int_0^{2\pi} \frac{dt}{1+2\cos(t)},The problem is $$\int_0^{2\pi} \frac{dt}{1+2\cos(t)}.$$ I know it is equal to  $$\int\limits_{|z|=1}\frac{2dz}{i(1+z)^2}$$ but I don't know how I should calculate the last integral.,The problem is $$\int_0^{2\pi} \frac{dt}{1+2\cos(t)}.$$ I know it is equal to  $$\int\limits_{|z|=1}\frac{2dz}{i(1+z)^2}$$ but I don't know how I should calculate the last integral.,,"['calculus', 'complex-analysis', 'integration', 'improper-integrals']"
26,Complex Analysis ~ Unit Disc,Complex Analysis ~ Unit Disc,,"Show that for any given rational functional $f(z)$, with poles in the unit disc and without poles in the unit circle, it is possible to find another rational function $g(z)$, with no poles in the unit disc, and such that $|f(z)|= |g(z)|$ if $|z| = 1$ I'm not really sure where to start here. A hint on how to begin the proof would be really appreciated.","Show that for any given rational functional $f(z)$, with poles in the unit disc and without poles in the unit circle, it is possible to find another rational function $g(z)$, with no poles in the unit disc, and such that $|f(z)|= |g(z)|$ if $|z| = 1$ I'm not really sure where to start here. A hint on how to begin the proof would be really appreciated.",,['complex-analysis']
27,Evaluate $\int_0^{2\pi} \frac{d\theta}{(1-a\cos(\theta)+a^2)}$,Evaluate,\int_0^{2\pi} \frac{d\theta}{(1-a\cos(\theta)+a^2)},Evaluate $\displaystyle \int_0^{2\pi} \frac{d\theta}{(1-a\cos(\theta)+a^2)}$ Super general. I get to a step: $\displaystyle \frac{2}{i}$ multiplied by Path integral $\displaystyle \frac{z}{[(2-a)z^2 + 2(a^2  z) + a]}.$ No idea if I'm on the right track. Maybe distribute the $i$? Wondering if I can get some help.,Evaluate $\displaystyle \int_0^{2\pi} \frac{d\theta}{(1-a\cos(\theta)+a^2)}$ Super general. I get to a step: $\displaystyle \frac{2}{i}$ multiplied by Path integral $\displaystyle \frac{z}{[(2-a)z^2 + 2(a^2  z) + a]}.$ No idea if I'm on the right track. Maybe distribute the $i$? Wondering if I can get some help.,,['complex-analysis']
28,Casorati-Weierstrass Theroem,Casorati-Weierstrass Theroem,,"The theorem says: ""Suppose $z_0$ is an essential isolated singularity of $f(z)$. Then for every complex number $w_0$, there is a sequence $z_n\rightarrow z_0$ such that $f(z_n)\rightarrow w_0$."" The function $f(z)=e^{1/z}$ has an essential singularity at $z=0$. Can someone demonstrate the theorem up above by providing a sequence of complex numbers $z_n$ so that: $$z_n\rightarrow 0  \qquad\text{and}\qquad f(z_n)\rightarrow 10$$ And perhaps a second example where: $$z_n\rightarrow 0  \qquad\text{and}\qquad f(z_n)\rightarrow 1+i$$ Thanks.","The theorem says: ""Suppose $z_0$ is an essential isolated singularity of $f(z)$. Then for every complex number $w_0$, there is a sequence $z_n\rightarrow z_0$ such that $f(z_n)\rightarrow w_0$."" The function $f(z)=e^{1/z}$ has an essential singularity at $z=0$. Can someone demonstrate the theorem up above by providing a sequence of complex numbers $z_n$ so that: $$z_n\rightarrow 0  \qquad\text{and}\qquad f(z_n)\rightarrow 10$$ And perhaps a second example where: $$z_n\rightarrow 0  \qquad\text{and}\qquad f(z_n)\rightarrow 1+i$$ Thanks.",,['complex-analysis']
29,Finding residue of function,Finding residue of function,,"I'm trying to find the residue of $$z \cos\left(\frac{1}{z}\right)$$ at $z=0$. This is how I did it: $\cos(z)=\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}z^{2n}$.  $\\$ Then $\cos(\frac{1}{z})=\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}z^{2n-1}$. $\\$ Finally, $z\cos(z)=\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}z^{2n}$, which is where I started. I thought the residue would by $0$ because there are no negative powers, but  it's supposed to be $-\frac{1}{2}$. Did I do something incorrectly?","I'm trying to find the residue of $$z \cos\left(\frac{1}{z}\right)$$ at $z=0$. This is how I did it: $\cos(z)=\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}z^{2n}$.  $\\$ Then $\cos(\frac{1}{z})=\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}z^{2n-1}$. $\\$ Finally, $z\cos(z)=\sum_{n=0}^\infty \frac{(-1)^n}{(2n)!}z^{2n}$, which is where I started. I thought the residue would by $0$ because there are no negative powers, but  it's supposed to be $-\frac{1}{2}$. Did I do something incorrectly?",,['complex-analysis']
30,How do I obtain the Laurent series for $f(z)=\frac 1{\cos(z^4)-1}$ about $0$?,How do I obtain the Laurent series for  about ?,f(z)=\frac 1{\cos(z^4)-1} 0,I know that $$\cos(z^4)-1=-\frac{z^8}{2!}+\frac{z^{16}}{4!}+...$$ but how do I take the reciprocal of this series (please do not use little-o notation)? Or are there better methods to obtain the required series?,I know that $$\cos(z^4)-1=-\frac{z^8}{2!}+\frac{z^{16}}{4!}+...$$ but how do I take the reciprocal of this series (please do not use little-o notation)? Or are there better methods to obtain the required series?,,"['complex-analysis', 'convergence-divergence', 'power-series', 'taylor-expansion']"
31,Wick Rotation Contour doesn't seem to be simply connected?,Wick Rotation Contour doesn't seem to be simply connected?,,"I've seen this (page 112) Wick rotation from several QFT source and all of them explain really bad at what is going on. From Complex analysis I know that for instance if we have an integral from $-\infty$ to $\infty$, you can add a semicirle (or some other type) to close the contour and then count the residues inside this simple closed contour (very rough explanation I know). But what about the Wick contour in the link? how can they just go from $$\int_{-\infty}^\infty$$ to $$\int_{-i \infty}^{i\infty}$$. I mean they must add some contour to the original in order to close it and then count the residues inside (there are none btw), but I have a hard time spotting this simple closed curve, I think I have misunderstood the whole point? Can someone please explain what the link is talking about, especially with the figure where he says the contour simply can be rotated? Thanks for your efforts!","I've seen this (page 112) Wick rotation from several QFT source and all of them explain really bad at what is going on. From Complex analysis I know that for instance if we have an integral from $-\infty$ to $\infty$, you can add a semicirle (or some other type) to close the contour and then count the residues inside this simple closed contour (very rough explanation I know). But what about the Wick contour in the link? how can they just go from $$\int_{-\infty}^\infty$$ to $$\int_{-i \infty}^{i\infty}$$. I mean they must add some contour to the original in order to close it and then count the residues inside (there are none btw), but I have a hard time spotting this simple closed curve, I think I have misunderstood the whole point? Can someone please explain what the link is talking about, especially with the figure where he says the contour simply can be rotated? Thanks for your efforts!",,"['complex-analysis', 'integration', 'quantum-field-theory']"
32,"Show that $f(z)$ has no antiderivative in $\,S=\mathbb{C}\setminus \{-i,i\}$",Show that  has no antiderivative in,"f(z) \,S=\mathbb{C}\setminus \{-i,i\}",$f(z)=\frac{1}{z^{2}+1}$ I know that you can do this using a proof by contradiction and by showing that if you assume it has an anti-derivative that it wouldn't follow the fundamental theorem of calculus which would be a contradiction but I don't know how to show this.,$f(z)=\frac{1}{z^{2}+1}$ I know that you can do this using a proof by contradiction and by showing that if you assume it has an anti-derivative that it wouldn't follow the fundamental theorem of calculus which would be a contradiction but I don't know how to show this.,,"['complex-analysis', 'integration']"
33,Find an analytic bijection function ${f(z)}$ on $\Bbb{C}$ such that there exist only one $z_{0}$ such that ${f(z_{0})} = z_{0}$.,Find an analytic bijection function  on  such that there exist only one  such that .,{f(z)} \Bbb{C} z_{0} {f(z_{0})} = z_{0},Find an analytic one-one onto function ${f(z)}$ on $\Bbb{C}$   such that there exist only one $z_{0}$ such that ${f(z_{0})} = z_{0}$.,Find an analytic one-one onto function ${f(z)}$ on $\Bbb{C}$   such that there exist only one $z_{0}$ such that ${f(z_{0})} = z_{0}$.,,['complex-analysis']
34,The Taylor series of $f(z) := \log z$ about $z_0 = -1 + i$,The Taylor series of  about,f(z) := \log z z_0 = -1 + i,"So the problem states: Say $f(z) := \log z$ is the principal branch of the logarithm (the primitive of $1/z$ on the region $\Bbb C\setminus (-\infty,0]$ ). Show that the Taylor series of $f(z)$ about $z_0 = -1 + i$ takes the form $$\log z = \sum_{n=0}^{\infty} a_n(z-(-1+i))^n $$ with $$a_0 = \log \sqrt{2} + i\frac{3\pi}{4}\,\,\,\text{and}\,\,\,a_n = (-1)^{n+1}\frac{e^{-3\pi in/4}}{n2^n/2}$$ Determine the radius of convergence of this series. Explain why the series does not represent $f(z)$ in its entire disk of convergence. My main concern here is how to show $\log(-1+i) = \log \sqrt{2} + i\frac{3\pi}{4} $ and determine the radius of convergence.",So the problem states: Say is the principal branch of the logarithm (the primitive of on the region ). Show that the Taylor series of about takes the form with Determine the radius of convergence of this series. Explain why the series does not represent in its entire disk of convergence. My main concern here is how to show and determine the radius of convergence.,"f(z) := \log z 1/z \Bbb C\setminus (-\infty,0] f(z) z_0 = -1 + i \log z = \sum_{n=0}^{\infty} a_n(z-(-1+i))^n  a_0 = \log \sqrt{2} + i\frac{3\pi}{4}\,\,\,\text{and}\,\,\,a_n = (-1)^{n+1}\frac{e^{-3\pi in/4}}{n2^n/2} f(z) \log(-1+i) = \log \sqrt{2} + i\frac{3\pi}{4} ","['complex-analysis', 'taylor-expansion']"
35,evaluate $\int_0^\infty \dfrac{dx}{1+x^4}$ using $\int_0^\infty \dfrac{u^{p-1}}{1+u} du$,evaluate  using,\int_0^\infty \dfrac{dx}{1+x^4} \int_0^\infty \dfrac{u^{p-1}}{1+u} du,"evaluate $\int_0^\infty \dfrac{dx}{1+x^4}$using $\int_0^\infty \dfrac{u^{p-1}}{1+u} du = \dfrac{\pi}{\sin( \pi p)}$. I am having trouble finding what is $p$. I set $u = x^4$, I figure $du = 4x^3 dx$, I am unsure though how to find $p$ though. Could someone tell me what I am missing? Thanks.","evaluate $\int_0^\infty \dfrac{dx}{1+x^4}$using $\int_0^\infty \dfrac{u^{p-1}}{1+u} du = \dfrac{\pi}{\sin( \pi p)}$. I am having trouble finding what is $p$. I set $u = x^4$, I figure $du = 4x^3 dx$, I am unsure though how to find $p$ though. Could someone tell me what I am missing? Thanks.",,"['complex-analysis', 'improper-integrals', 'residue-calculus']"
36,Prove partial derivatives of uniformly convergent harmonic functions converge to the partial derivative of the limit of the sequence.,Prove partial derivatives of uniformly convergent harmonic functions converge to the partial derivative of the limit of the sequence.,,"I think the title says it all. If you have a sequence of harmonic functions from a bounded complex domain to the real numbers, show that on a subset at a positive distance from the boundary of the domain, e.g. a compact subset of the domain, the derivatives of the harmonic functions converge uniformly to the derivative of the limit of the sequence of the harmonic functions. Thank you! My attempt: I tried to apply the mean value property (like Gamelin does for analytic functions) to find a bound (unsuccessfully). I know the question has been asked before, but I did not understand the solution. I also tried to come up with something similar to Cauchy estimates for harmonic functions, but I wound up more confused than when I started. EDIT: Keep in mind by derivative I meant partial derivatives. My attempt was to find an analogue of the Cauchy integral formula (for derivatives) but I seem to get the same formula for both partial derivatives, which does not make sense to me because it seems like the partial derivatives can be different.","I think the title says it all. If you have a sequence of harmonic functions from a bounded complex domain to the real numbers, show that on a subset at a positive distance from the boundary of the domain, e.g. a compact subset of the domain, the derivatives of the harmonic functions converge uniformly to the derivative of the limit of the sequence of the harmonic functions. Thank you! My attempt: I tried to apply the mean value property (like Gamelin does for analytic functions) to find a bound (unsuccessfully). I know the question has been asked before, but I did not understand the solution. I also tried to come up with something similar to Cauchy estimates for harmonic functions, but I wound up more confused than when I started. EDIT: Keep in mind by derivative I meant partial derivatives. My attempt was to find an analogue of the Cauchy integral formula (for derivatives) but I seem to get the same formula for both partial derivatives, which does not make sense to me because it seems like the partial derivatives can be different.",,"['complex-analysis', 'analysis', 'harmonic-analysis']"
37,"$|f(z)|\le 1-|z|\forall z\in D$, we need to show $f\equiv 0$",", we need to show",|f(z)|\le 1-|z|\forall z\in D f\equiv 0,"$f$ is analytic function on open unit disk, and $|f(z)|\le 1-|z|\forall z\in D$, we need to show $f\equiv 0$, just a hint please.","$f$ is analytic function on open unit disk, and $|f(z)|\le 1-|z|\forall z\in D$, we need to show $f\equiv 0$, just a hint please.",,['complex-analysis']
38,$z_{0}$ is a zero of order $m$. Prove that $|z_{0}|^m\geq|f(0)|$ where $f$ is analytic in the unit disc,is a zero of order . Prove that  where  is analytic in the unit disc,z_{0} m |z_{0}|^m\geq|f(0)| f,"$f$ is an analytic function in the unit disc, so that $|f(z)|\leq1$. Let $z_{0}$ be a zero of order $m$. Prove that $|z_{0}|^m\geq|f(0)|$ My approach: We can write: $$(1) \ \ \ f(z)=(z-z_0)^mg(z)$$ where $g(z_0)\neq0$ Then we define the automorphism on the unit disc: $$\varphi(z)=\frac{z-z_0}{1-\bar{z_0}z}$$ Then we have, $$f\circ\varphi^{-1}(0)=0$$ And we can apply Schwarz Lemma on $f\circ\varphi^{-1}(z)$: $$|f\circ\varphi^{-1}(z)|=|(\varphi^{-1}(z)-z_0)^mg(\varphi^{-1}(z))|\leq|z|$$ Then we choose $z=\varphi(0)=-z_0$: $$|z_0|^m|g(0)|\leq|z_0|$$ and by (1) we only get: $$|f(0)|=|z_0|^m|g(0)|\leq|z_0|$$ I've noticed that I don't ""really"" use the fact that $z_0$ is of order $m$. Any ideas? Thanks","$f$ is an analytic function in the unit disc, so that $|f(z)|\leq1$. Let $z_{0}$ be a zero of order $m$. Prove that $|z_{0}|^m\geq|f(0)|$ My approach: We can write: $$(1) \ \ \ f(z)=(z-z_0)^mg(z)$$ where $g(z_0)\neq0$ Then we define the automorphism on the unit disc: $$\varphi(z)=\frac{z-z_0}{1-\bar{z_0}z}$$ Then we have, $$f\circ\varphi^{-1}(0)=0$$ And we can apply Schwarz Lemma on $f\circ\varphi^{-1}(z)$: $$|f\circ\varphi^{-1}(z)|=|(\varphi^{-1}(z)-z_0)^mg(\varphi^{-1}(z))|\leq|z|$$ Then we choose $z=\varphi(0)=-z_0$: $$|z_0|^m|g(0)|\leq|z_0|$$ and by (1) we only get: $$|f(0)|=|z_0|^m|g(0)|\leq|z_0|$$ I've noticed that I don't ""really"" use the fact that $z_0$ is of order $m$. Any ideas? Thanks",,['complex-analysis']
39,Radius of convergence of $\sum \frac {a_n}{b_n} z^n$,Radius of convergence of,\sum \frac {a_n}{b_n} z^n,"One of the past comp question Suppose $\sum a_n z^n$ has a radius of convergence $R_1$ with $0< R_1 < \infty$, and $\sum b_n z^n$ has a radius of convergence $R_2$ with $0< R_2 < \infty$. Prove that $\sum \frac {a_n}{b_n}  z^n$ has a radius of convergence $R_3$  satisfying $ R_3<=\frac {R_1} {R_2}$ I think the idea is to prove the series $\sum \frac {a_n}{b_n}  z^n$ diverges when $|z|> \frac {R_1} {R_2} $ For that we use rational density theorem and manipulate the terms to get the desired result. I don't think this method is  standard way of doing it. I was wondering if someone like to give me another mind blowing approach. Thanks in advance.","One of the past comp question Suppose $\sum a_n z^n$ has a radius of convergence $R_1$ with $0< R_1 < \infty$, and $\sum b_n z^n$ has a radius of convergence $R_2$ with $0< R_2 < \infty$. Prove that $\sum \frac {a_n}{b_n}  z^n$ has a radius of convergence $R_3$  satisfying $ R_3<=\frac {R_1} {R_2}$ I think the idea is to prove the series $\sum \frac {a_n}{b_n}  z^n$ diverges when $|z|> \frac {R_1} {R_2} $ For that we use rational density theorem and manipulate the terms to get the desired result. I don't think this method is  standard way of doing it. I was wondering if someone like to give me another mind blowing approach. Thanks in advance.",,['complex-analysis']
40,Solving a complex integral 1,Solving a complex integral 1,,If $P(z)$ is a polynomial and $C$ denotes the circle $|z-a|=R$ what is the value of $$\int_{C}^{} P(z)d\overline{z} $$ ? The answer in Ahlfors is $-2\pi i R^2 P'(a)$ I don't know if I'm doing it right but I made a substitution $$d\overline{z} = -R^2 \frac{dz}{(z-a)^2} $$,If $P(z)$ is a polynomial and $C$ denotes the circle $|z-a|=R$ what is the value of $$\int_{C}^{} P(z)d\overline{z} $$ ? The answer in Ahlfors is $-2\pi i R^2 P'(a)$ I don't know if I'm doing it right but I made a substitution $$d\overline{z} = -R^2 \frac{dz}{(z-a)^2} $$,,['complex-analysis']
41,Repeated logarithm,Repeated logarithm,,"By definition $\ln = \log_e$ on complex numbers is given by $$ \ln(re^{i\theta}) = \ln(r) + i\theta $$ $(-\pi < \theta\leq \pi, r >0)$. Then $\ln(-1) = \pi i$. And $\ln(\pi i) = \ln(\pi) + i\pi/2$. If $\ln^{\circ n}(z) = \ln\circ\ln\circ \dots \circ\ln$ ($n$ times), is it possible to find what the exact value of  $$ \lim_{n \to \infty} \ln^{\circ n}(-1)\quad  $$ is? From just using a calculator it seems like this actually converges. And from starting with for example $-2$ it looks like it converges to the same number. If it is not possible to find an exact value, how might one prove that this actually converges?","By definition $\ln = \log_e$ on complex numbers is given by $$ \ln(re^{i\theta}) = \ln(r) + i\theta $$ $(-\pi < \theta\leq \pi, r >0)$. Then $\ln(-1) = \pi i$. And $\ln(\pi i) = \ln(\pi) + i\pi/2$. If $\ln^{\circ n}(z) = \ln\circ\ln\circ \dots \circ\ln$ ($n$ times), is it possible to find what the exact value of  $$ \lim_{n \to \infty} \ln^{\circ n}(-1)\quad  $$ is? From just using a calculator it seems like this actually converges. And from starting with for example $-2$ it looks like it converges to the same number. If it is not possible to find an exact value, how might one prove that this actually converges?",,"['complex-analysis', 'logarithms']"
42,Winding number $=0$ imply homotopic to a point?,Winding number  imply homotopic to a point?,=0,Suppose $\gamma$ is a smooth closed curve in  $U=\mathbb{C} - \{0\}$.   Suppose the winding number of $\gamma$ around 0 is 0.  Is $\gamma$ homotopic to a point in $U$?,Suppose $\gamma$ is a smooth closed curve in  $U=\mathbb{C} - \{0\}$.   Suppose the winding number of $\gamma$ around 0 is 0.  Is $\gamma$ homotopic to a point in $U$?,,['complex-analysis']
43,Limiting behavior of gamma function,Limiting behavior of gamma function,,"I am trying to determine whether $\Gamma(x+iy)\rightarrow 0$ as $y\rightarrow\infty$. How should I go about doing it? I was trying to see if I could get anything from $\Gamma(z)\Gamma(1-z)=\frac{\pi}{\sin\pi z}$ but although $|\sin z|\rightarrow\infty$ as $y\rightarrow\infty$, I think it does not follow that $\Gamma(z)\rightarrow 0$. Am I right? Another approach I was trying was a change of variables by letting $u=\ln t$ so that (for $x>0$,) $\Gamma(x+iy)=\int_{-\infty}^{\infty}e^{xu}e^{-e^{u}}e^{iyu}du$. I have a couple of questions about this. First, is $e^{xu}e^{-e^{u}}$ integrable over the real line? Next, is there something about Fourier transforms that I can use here (perhaps the Riemann-Lebesgue lemma)?","I am trying to determine whether $\Gamma(x+iy)\rightarrow 0$ as $y\rightarrow\infty$. How should I go about doing it? I was trying to see if I could get anything from $\Gamma(z)\Gamma(1-z)=\frac{\pi}{\sin\pi z}$ but although $|\sin z|\rightarrow\infty$ as $y\rightarrow\infty$, I think it does not follow that $\Gamma(z)\rightarrow 0$. Am I right? Another approach I was trying was a change of variables by letting $u=\ln t$ so that (for $x>0$,) $\Gamma(x+iy)=\int_{-\infty}^{\infty}e^{xu}e^{-e^{u}}e^{iyu}du$. I have a couple of questions about this. First, is $e^{xu}e^{-e^{u}}$ integrable over the real line? Next, is there something about Fourier transforms that I can use here (perhaps the Riemann-Lebesgue lemma)?",,['complex-analysis']
44,Sketch all points in the complex plane such that $\mathrm{Re}(1/z)<1$,Sketch all points in the complex plane such that,\mathrm{Re}(1/z)<1,"I am given the task to sketch all the points in the complex plane satisfying  $$ \mathrm{Re}(1/z)<1 $$ I am not very good at sketching, nor seeing how to draw this in the complex plane.  I was thinking that since $$ \frac{1}{z} = \frac{|z|}{z|z|} = \frac{x - iy}{x^2 + y^2} $$ then $\mathrm{Re}(1/z)=x/(x^2+y^2)$. Our inequality is therefore equivalent to $$\mathrm{Re}(1/z)<1  \Leftrightarrow x < x^2 + y^2 \Leftrightarrow \left(\frac{1}{2}\right)^2 < \left( x - \frac{1}{2}\right)^2 + y^2$$ So the equality represents all points in $\mathbb{R}$ that lie outside a disk of radius $1/2$ and centre $(1/2,0)$. But I have not plotted anything in the complex plane?? Any help sketching and understanding this would be greatly appreciated.","I am given the task to sketch all the points in the complex plane satisfying  $$ \mathrm{Re}(1/z)<1 $$ I am not very good at sketching, nor seeing how to draw this in the complex plane.  I was thinking that since $$ \frac{1}{z} = \frac{|z|}{z|z|} = \frac{x - iy}{x^2 + y^2} $$ then $\mathrm{Re}(1/z)=x/(x^2+y^2)$. Our inequality is therefore equivalent to $$\mathrm{Re}(1/z)<1  \Leftrightarrow x < x^2 + y^2 \Leftrightarrow \left(\frac{1}{2}\right)^2 < \left( x - \frac{1}{2}\right)^2 + y^2$$ So the equality represents all points in $\mathbb{R}$ that lie outside a disk of radius $1/2$ and centre $(1/2,0)$. But I have not plotted anything in the complex plane?? Any help sketching and understanding this would be greatly appreciated.",,['complex-analysis']
45,find all the entire functions that satisfies a given condition,find all the entire functions that satisfies a given condition,,I have been struggling to find a solution for this problem: Find all the entire analytic functions $f(z)$ (analytic in the complex plane) that satisfy the condition $|z^2f(z)-3+e^z|\leq3$ for all $z \in \mathbb{C}$. Any ideas? Thank you in advance.,I have been struggling to find a solution for this problem: Find all the entire analytic functions $f(z)$ (analytic in the complex plane) that satisfy the condition $|z^2f(z)-3+e^z|\leq3$ for all $z \in \mathbb{C}$. Any ideas? Thank you in advance.,,['complex-analysis']
46,Can I shift this integral along the complex plane?,Can I shift this integral along the complex plane?,,"Does $$\int_{-\infty}^\infty \text{e}^{\ a\ (x+b)^2}\ \text dx=\int_{-\infty}^\infty \text{e}^{\ a\ x^2}\ \text dx\ \ \ \ \ ?$$ hold, even if the imaginary part of $b$ is nonzero? What I really want to understand is what the phrase "" By analogy with the previous integrals "" means in that link. There, the expression $\frac{J}{a}$ is complex but they seem to imply the integral can be solved like above anyway. The reusult tells us that the integral is really independend of $J$ , which is assumed to be real here. I wonder if we can also generalize this integral to include complex $J$ . In case that the shift above is possible, this should work out. But even if the idea is here to perform that substitution, how to get rid of the complex $a$ to obtain the result. If everything is purely real or imaginary, then this solves the rest of the problem.","Does hold, even if the imaginary part of is nonzero? What I really want to understand is what the phrase "" By analogy with the previous integrals "" means in that link. There, the expression is complex but they seem to imply the integral can be solved like above anyway. The reusult tells us that the integral is really independend of , which is assumed to be real here. I wonder if we can also generalize this integral to include complex . In case that the shift above is possible, this should work out. But even if the idea is here to perform that substitution, how to get rid of the complex to obtain the result. If everything is purely real or imaginary, then this solves the rest of the problem.",\int_{-\infty}^\infty \text{e}^{\ a\ (x+b)^2}\ \text dx=\int_{-\infty}^\infty \text{e}^{\ a\ x^2}\ \text dx\ \ \ \ \ ? b \frac{J}{a} J J a,"['complex-analysis', 'integration']"
47,Holomorphic function mapping a set onto a straight line,Holomorphic function mapping a set onto a straight line,,"I wonder if this is correct: there is a holomorphic function on an open connected subset $G$ of $\mathbb{C}$ which maps $G$ onto a subset of a straight line, and I have to show that the function is constant. I thought I can suppose that the straight line is the real axis (otherwise I can find a rotation and a traslation that will do so) and so using the Cauchy-Riemann equations I find that the function is constant since its imaginary part is zero. Is that correct? Thank you","I wonder if this is correct: there is a holomorphic function on an open connected subset $G$ of $\mathbb{C}$ which maps $G$ onto a subset of a straight line, and I have to show that the function is constant. I thought I can suppose that the straight line is the real axis (otherwise I can find a rotation and a traslation that will do so) and so using the Cauchy-Riemann equations I find that the function is constant since its imaginary part is zero. Is that correct? Thank you",,['complex-analysis']
48,"Show $\iint_{D} f(x,y)(1 - x^2 - y^2) ~dx ~dy = \pi/2$",Show,"\iint_{D} f(x,y)(1 - x^2 - y^2) ~dx ~dy = \pi/2","Suppose $f(x,y)$ is a bounded harmonic function in the unit disk $D = \{z = x + iy : |z| < 1 \} $ and $f(0,0) = 1$. Show that $$\iint_{D} f(x,y)(1 - x^2 - y^2) ~dx ~dy = \frac{\pi}{2}.$$ I'm studying for a prelim this August and I haven't taken Complex in a long time (two years ago).  I don't know how to solve this problem or even where to look unless it's just a game with Green's theorem-any help?  I don't need a complete solution, just a helpful hint and I can work the rest out on my own.","Suppose $f(x,y)$ is a bounded harmonic function in the unit disk $D = \{z = x + iy : |z| < 1 \} $ and $f(0,0) = 1$. Show that $$\iint_{D} f(x,y)(1 - x^2 - y^2) ~dx ~dy = \frac{\pi}{2}.$$ I'm studying for a prelim this August and I haven't taken Complex in a long time (two years ago).  I don't know how to solve this problem or even where to look unless it's just a game with Green's theorem-any help?  I don't need a complete solution, just a helpful hint and I can work the rest out on my own.",,['complex-analysis']
49,To show sum of residues of $f(z)$ over all poles is $0$,To show sum of residues of  over all poles is,f(z) 0,"Let $p(z)$ and $q(z)$ be relatively prime polynomials with complex co-efficients so that $deg(q(z))\ge deg(p(z))+2$ and let $f(z)=p(z)/q(z)$. We need to show that the sum of residues of $f(z)$ over all poles is $0$ Well, I tried like this: by Residue theorem: If $f$ is analytic in a domain except for isolated singularities at $a_1,\dots a_k$ then for any closed  contour $\gamma\in D$ on which none of the points $a_k$ lie, we have $$\frac{1}{2\pi i}\int_{\gamma}f(z)dz=\sum_{1}^{k}n(\gamma;a_k)Res[f(z);a_k]$$ as  $p$ and $q$ are relatively prime to each other we have $r,s$ such that $p(z)r(z)+q(z)s(z)=1$ $$\frac{1}{2\pi i}\int_{\gamma}f(z)dz=\sum_{1}^{k}Res[f(z);a_k ]$$ $$\frac{1}{2\pi i}\int_{\gamma}\frac{p(z)}{q(z)}dz=\sum_{1}^{k}n(\gamma;a_k)Res[f(z);a_k]$$ Now, I am confused where to use the given facts, should I replacing $p(z)$ from the relatively prime condition? and how to implement the given degree condition? thank you for help","Let $p(z)$ and $q(z)$ be relatively prime polynomials with complex co-efficients so that $deg(q(z))\ge deg(p(z))+2$ and let $f(z)=p(z)/q(z)$. We need to show that the sum of residues of $f(z)$ over all poles is $0$ Well, I tried like this: by Residue theorem: If $f$ is analytic in a domain except for isolated singularities at $a_1,\dots a_k$ then for any closed  contour $\gamma\in D$ on which none of the points $a_k$ lie, we have $$\frac{1}{2\pi i}\int_{\gamma}f(z)dz=\sum_{1}^{k}n(\gamma;a_k)Res[f(z);a_k]$$ as  $p$ and $q$ are relatively prime to each other we have $r,s$ such that $p(z)r(z)+q(z)s(z)=1$ $$\frac{1}{2\pi i}\int_{\gamma}f(z)dz=\sum_{1}^{k}Res[f(z);a_k ]$$ $$\frac{1}{2\pi i}\int_{\gamma}\frac{p(z)}{q(z)}dz=\sum_{1}^{k}n(\gamma;a_k)Res[f(z);a_k]$$ Now, I am confused where to use the given facts, should I replacing $p(z)$ from the relatively prime condition? and how to implement the given degree condition? thank you for help",,['complex-analysis']
50,Prove that $\sum_{n=1}^\infty\frac{\sin(nz)}{2^n}$ is analytic on $\{z\in\mathbb{C}:|\operatorname{Im}(z)|<\log(2)\}$,Prove that  is analytic on,\sum_{n=1}^\infty\frac{\sin(nz)}{2^n} \{z\in\mathbb{C}:|\operatorname{Im}(z)|<\log(2)\},Prove that $f(z)=\sum_{n=1}^\infty\frac{\sin(nz)}{2^n}$ is analytic on $A=\{z\in\mathbb{C}:|\operatorname{Im}(z)|<\log(2)\}$ I tried expanding $\sin(nz)$ in terms of $e^{inz}$ but that did not help me unless I am doing something wrong.  I know Weierstrass's M-test comes in to play.,Prove that $f(z)=\sum_{n=1}^\infty\frac{\sin(nz)}{2^n}$ is analytic on $A=\{z\in\mathbb{C}:|\operatorname{Im}(z)|<\log(2)\}$ I tried expanding $\sin(nz)$ in terms of $e^{inz}$ but that did not help me unless I am doing something wrong.  I know Weierstrass's M-test comes in to play.,,"['complex-analysis', 'analyticity']"
51,Value of the integral : $ I_r$ =$\int_{C_r}$ $\frac{dz}{z(z-1)(z-2)}$,Value of the integral :  =, I_r \int_{C_r} \frac{dz}{z(z-1)(z-2)},"It is given that $$ I_r =\int_{C_r}\frac{dz}{z(z-1)(z-2)}$$ where $ C_r = \{z\in \Bbb{C}: |z|=r\}$ , $ r >0 $, $r\neq 1,2$ . Then which of the following holds: $ I_r = 2 \pi\ i $ if $r\in(2,3)$ $ I_r = -2 \pi\ i $ if $r\in(1,2)$ $ I_r = 0 $ if $r >3$ Please suggest which option is correct.","It is given that $$ I_r =\int_{C_r}\frac{dz}{z(z-1)(z-2)}$$ where $ C_r = \{z\in \Bbb{C}: |z|=r\}$ , $ r >0 $, $r\neq 1,2$ . Then which of the following holds: $ I_r = 2 \pi\ i $ if $r\in(2,3)$ $ I_r = -2 \pi\ i $ if $r\in(1,2)$ $ I_r = 0 $ if $r >3$ Please suggest which option is correct.",,['complex-analysis']
52,Complex - Entire functions,Complex - Entire functions,,How can I prove this. I could not use $\Im(w)<0$ condition in Liouville's theorem. Let $f(z)$ be an entire function and assuming that $f(z)$ does not take values in $\Im(w)<0$ show that $f$ is identically zero. Thanks.,How can I prove this. I could not use $\Im(w)<0$ condition in Liouville's theorem. Let $f(z)$ be an entire function and assuming that $f(z)$ does not take values in $\Im(w)<0$ show that $f$ is identically zero. Thanks.,,['complex-analysis']
53,Does there exist an analytic function such that $|f(z)|=|\sin z|$?,Does there exist an analytic function such that ?,|f(z)|=|\sin z|,"Does there exist an analytic function $f(z)$ defined on $\Omega$ such that $|f(z)|=|\sin z|$ for all $z\in\Omega\subseteq\mathbb{C}$? Well I guess if there is a constant $c$ with $|c|=1$ and $f(z)=c\sin(z)$ for all $z\in\Omega$, am I right?","Does there exist an analytic function $f(z)$ defined on $\Omega$ such that $|f(z)|=|\sin z|$ for all $z\in\Omega\subseteq\mathbb{C}$? Well I guess if there is a constant $c$ with $|c|=1$ and $f(z)=c\sin(z)$ for all $z\in\Omega$, am I right?",,['complex-analysis']
54,Absolute value integral inequality proof step,Absolute value integral inequality proof step,,"I'm beginning my way through Coddington's Intro to ODE's and I'm a little thrown off in the preliminary section in a proof regarding complexed valued functions. ( I should note that I've taken a course in ODES, but my background in Complex anything-besides-the-basics is subpar. ) Particularly the book shows that: $$ \left| \int_a^b f(x) \, dx \right| \leq \int_a^b \left| f(x) \right| \, dx $$ The proof is pretty short, so I guess I'll just map it out until the me-thrown-off point. First, let $$ F \, = \, \int_a^b f(x) \, dx \quad $$ and $$ u = \cos(\theta) + i\sin(\theta). $$ Then, let $ F \, = \, \left| F \,\right| u $ where $ F \neq 0 $. Since $u\overline{u} = 1$, $$ \left| F \right| = \,\overline{u} F \, = \;\overline{u} \int_a^b f(x) \, dx = \;...$$ and the step that loses me: $$ ...\; = \, Re\left[ \; \overline{u} \int_a^b f(x) \, dx  \; \right] \, = \; ... $$ Maybe my unfamiliarity with complex-valued functions is making me miss something obvious, but I'm stumped. For instance, I've tried expanding $ \overline{u} \int_a^b f(x) \, dx $ to: $$ ( \cos(\theta) - i \sin(\theta) ) \int_a^b f(x) \, dx $$ $$ = \; \cos(\theta) \int_a^b f(x) \, dx - i sin(\theta) \int_a^b f(x) \, dx $$ $$ = \; \cos(\theta) \left( \int_a^b \left ( Re \, f \, \right) (x) \, dx + i \int_a^b \left ( Im \, f \, \right) (x) \, dx \right)- i sin(\theta) \left( \int_a^b \left ( Re \, f \, \right) (x) \, dx + i \int_a^b \left ( Im \, f \, \right) (x) \, dx \right) $$ $$ = \; \cos(\theta) \int_a^b \left ( Re \, f \, \right) (x) \, dx + i \cos(\theta) \int_a^b \left ( Im \, f \, \right) (x) \, dx - i sin(\theta) \int_a^b \left ( Re \, f \, \right) (x) \, dx + sin(\theta) \int_a^b \left ( Im \, f \, \right) (x) \, dx $$ $$ = \; \overline{u} \int_a^b \left( Re \, f \right) (x) \, dx + \left( i \cos(\theta) + \sin(\theta)\right) \int_a^b \left ( Im \, f \, \right) (x) \, dx $$ I felt as if I was on the right track but I hit a wall at this point, and it began to feel like I was convoluting something simple. Anyway the proof finishes with: $$ ... \; = \; \int_a^b Re\left[ \overline{u} f(x) \right] \, dx \; \leq \int_a^b \left| f(x) \right| \, dx  $$ Any help is appreciated :)","I'm beginning my way through Coddington's Intro to ODE's and I'm a little thrown off in the preliminary section in a proof regarding complexed valued functions. ( I should note that I've taken a course in ODES, but my background in Complex anything-besides-the-basics is subpar. ) Particularly the book shows that: $$ \left| \int_a^b f(x) \, dx \right| \leq \int_a^b \left| f(x) \right| \, dx $$ The proof is pretty short, so I guess I'll just map it out until the me-thrown-off point. First, let $$ F \, = \, \int_a^b f(x) \, dx \quad $$ and $$ u = \cos(\theta) + i\sin(\theta). $$ Then, let $ F \, = \, \left| F \,\right| u $ where $ F \neq 0 $. Since $u\overline{u} = 1$, $$ \left| F \right| = \,\overline{u} F \, = \;\overline{u} \int_a^b f(x) \, dx = \;...$$ and the step that loses me: $$ ...\; = \, Re\left[ \; \overline{u} \int_a^b f(x) \, dx  \; \right] \, = \; ... $$ Maybe my unfamiliarity with complex-valued functions is making me miss something obvious, but I'm stumped. For instance, I've tried expanding $ \overline{u} \int_a^b f(x) \, dx $ to: $$ ( \cos(\theta) - i \sin(\theta) ) \int_a^b f(x) \, dx $$ $$ = \; \cos(\theta) \int_a^b f(x) \, dx - i sin(\theta) \int_a^b f(x) \, dx $$ $$ = \; \cos(\theta) \left( \int_a^b \left ( Re \, f \, \right) (x) \, dx + i \int_a^b \left ( Im \, f \, \right) (x) \, dx \right)- i sin(\theta) \left( \int_a^b \left ( Re \, f \, \right) (x) \, dx + i \int_a^b \left ( Im \, f \, \right) (x) \, dx \right) $$ $$ = \; \cos(\theta) \int_a^b \left ( Re \, f \, \right) (x) \, dx + i \cos(\theta) \int_a^b \left ( Im \, f \, \right) (x) \, dx - i sin(\theta) \int_a^b \left ( Re \, f \, \right) (x) \, dx + sin(\theta) \int_a^b \left ( Im \, f \, \right) (x) \, dx $$ $$ = \; \overline{u} \int_a^b \left( Re \, f \right) (x) \, dx + \left( i \cos(\theta) + \sin(\theta)\right) \int_a^b \left ( Im \, f \, \right) (x) \, dx $$ I felt as if I was on the right track but I hit a wall at this point, and it began to feel like I was convoluting something simple. Anyway the proof finishes with: $$ ... \; = \; \int_a^b Re\left[ \overline{u} f(x) \right] \, dx \; \leq \int_a^b \left| f(x) \right| \, dx  $$ Any help is appreciated :)",,"['calculus', 'complex-analysis']"
55,Other functional equations for $\zeta(s)$?,Other functional equations for ?,\zeta(s),"For the Riemann zeta function, we know of the standard functional equation that relates $\zeta(s)$ and $\zeta(1-s)$. I wanted to know whether there are functional equations that relates $\zeta(s)$ and $\zeta(s-1)$? EDIT: My main motivation behind asking this question is I have found such an equation, but I do not know whether such an equation exists in literature. Also, I do not want to appear as if I am promoting my formula here, but rather I am more interested in the works that have been done in such directions. As per @lhf's request here is my formula, for $\Re(s) > 1$ $$ \zeta(s) + \frac{2}{s-1}\zeta(s-1) = \frac{s}{s-2} - s\int_1^\infty \frac{\{x\}^2}{x^{s+1}} dx$$ where $\{x\}$ is the fractional part of x.","For the Riemann zeta function, we know of the standard functional equation that relates $\zeta(s)$ and $\zeta(1-s)$. I wanted to know whether there are functional equations that relates $\zeta(s)$ and $\zeta(s-1)$? EDIT: My main motivation behind asking this question is I have found such an equation, but I do not know whether such an equation exists in literature. Also, I do not want to appear as if I am promoting my formula here, but rather I am more interested in the works that have been done in such directions. As per @lhf's request here is my formula, for $\Re(s) > 1$ $$ \zeta(s) + \frac{2}{s-1}\zeta(s-1) = \frac{s}{s-2} - s\int_1^\infty \frac{\{x\}^2}{x^{s+1}} dx$$ where $\{x\}$ is the fractional part of x.",,"['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
56,Uniform convergence of a power series when avoiding a point of divergence,Uniform convergence of a power series when avoiding a point of divergence,,"Here's the exercise: Let $\delta\in(0,1)$ and let $(a_n)_{n\in\mathbb{N}}$ be a real, monotonic decreasing sequence that converges to $0$. Show that $\sum a_nz^n$ converges uniformly on $\{|z|\leq1\}\cap\{|z-1|>\delta\}$ I quite frankly don't have any idea of how to approach this. Any hints and nudges in the correct direction are greatly appreciated.","Here's the exercise: Let $\delta\in(0,1)$ and let $(a_n)_{n\in\mathbb{N}}$ be a real, monotonic decreasing sequence that converges to $0$. Show that $\sum a_nz^n$ converges uniformly on $\{|z|\leq1\}\cap\{|z-1|>\delta\}$ I quite frankly don't have any idea of how to approach this. Any hints and nudges in the correct direction are greatly appreciated.",,"['complex-analysis', 'power-series']"
57,Roots of unity?,Roots of unity?,,"The $n$ th roots of unity are the complex numbers: $1,w,w^2,...,w^{n-1}$ , where $w = e^{\frac{2\pi i} {n}}$ . If $n$ is even: The $n$ th roots are plus-minus paired, $w^{\frac{n}{2}+j} = -w^j$ . Squaring them produces the $\frac{n}{2}$ nd roots of of unity. Could someone explain the first statement? I understand why the $n$ roots are plus-minus paired (if $n$ is even), but what does the equation mean? An explanation of the equation will be appreciated. The statement states $w^0$ (or $1$ ) is a root of unity. Which root is it? Aside from the obvious fact that $1$ is a always a root of $1$ , doesn't $w...w^{n-1}$ cover every root? What specific root is $w^0$ referring to?","The th roots of unity are the complex numbers: , where . If is even: The th roots are plus-minus paired, . Squaring them produces the nd roots of of unity. Could someone explain the first statement? I understand why the roots are plus-minus paired (if is even), but what does the equation mean? An explanation of the equation will be appreciated. The statement states (or ) is a root of unity. Which root is it? Aside from the obvious fact that is a always a root of , doesn't cover every root? What specific root is referring to?","n 1,w,w^2,...,w^{n-1} w = e^{\frac{2\pi i} {n}} n n w^{\frac{n}{2}+j} = -w^j \frac{n}{2} n n w^0 1 1 1 w...w^{n-1} w^0",['complex-analysis']
58,Branch Points of Riemann Surfaces,Branch Points of Riemann Surfaces,,"Can a Riemann surface of a complex-valued function have three branch points? I've been learning about Riemann surfaces from Brown's complex analysis book and the exposition isn't too general, so if the answer is yes I'd appreciate not just an example but some of the intuition behind how many branch points a given Riemann surface can have.","Can a Riemann surface of a complex-valued function have three branch points? I've been learning about Riemann surfaces from Brown's complex analysis book and the exposition isn't too general, so if the answer is yes I'd appreciate not just an example but some of the intuition behind how many branch points a given Riemann surface can have.",,['complex-analysis']
59,The Implicit Function Theorem for complex polynomials,The Implicit Function Theorem for complex polynomials,,"I'm looking for a reference that proves implicit function theorem for polynomials in two variables over the complex numbers via the real version. Such a theorem is needed, for example, in the theory of algebraic curves, in order to construct charts to prove they form a complex manifold. Also apparently a higher dimension version is useful for dealing with complete intersection curves in $\mathbb{P}^n$. I would also appreciate any reference on that. I've seen proofs of the implicit function theorem for real spaces, for example in Spivak's Calculus on Manifolds, but I've never been able to find a proof of the complex version.","I'm looking for a reference that proves implicit function theorem for polynomials in two variables over the complex numbers via the real version. Such a theorem is needed, for example, in the theory of algebraic curves, in order to construct charts to prove they form a complex manifold. Also apparently a higher dimension version is useful for dealing with complete intersection curves in $\mathbb{P}^n$. I would also appreciate any reference on that. I've seen proofs of the implicit function theorem for real spaces, for example in Spivak's Calculus on Manifolds, but I've never been able to find a proof of the complex version.",,"['reference-request', 'complex-analysis', 'manifolds']"
60,Where is $f(x+iy)=x^3+y^3$ complex differentiable?,Where is  complex differentiable?,f(x+iy)=x^3+y^3,"$ Let f(z) = (Re(z))^3 + (Im(z))^3$ (a) At which points (if any) is f differentiable? Find the expression of f' at those points. (b) Draw a picture of the subset of C consisting of those points at which f is differentiable. Hence decide at which points (if any) f is analytic. Answer: $ f(z) = x^3 + y^3 $ (a) Using Cauchy Riemann equations I found that f is only differentiable at (0,0). And f' is 0 at that point. (b) f is nowhere analytic as it is not differentiable in an $\epsilon$ neighbourhood of z. Is that correct?","$ Let f(z) = (Re(z))^3 + (Im(z))^3$ (a) At which points (if any) is f differentiable? Find the expression of f' at those points. (b) Draw a picture of the subset of C consisting of those points at which f is differentiable. Hence decide at which points (if any) f is analytic. Answer: $ f(z) = x^3 + y^3 $ (a) Using Cauchy Riemann equations I found that f is only differentiable at (0,0). And f' is 0 at that point. (b) f is nowhere analytic as it is not differentiable in an $\epsilon$ neighbourhood of z. Is that correct?",,['complex-analysis']
61,Using the complex logarithm to find the sum of angles in a triangle.,Using the complex logarithm to find the sum of angles in a triangle.,,"Suppose you have a triangle with vertices $a$, $b$, and $c$. I asked earlier how you can define the angles in a triangle based on the $\log$ function. I received the answer that, for instance, the angle at $a$ is found as $\left|\Im\log\left(\frac{c-a}{b-a}\right)\right|$. Can this be used to show that the sum of angles in a triangle is $\pi$? I summed the angles as $$ \left|\Im\log\left(\frac{c-a}{b-a}\right)\right|+\left|\Im\log\left(\frac{a-b}{c-b}\right)\right|+\left|\Im\log\left(\frac{a-c}{b-c}\right)\right|. $$ I noticed that $\left|\Im\log\left(\frac{c-a}{b-a}\frac{a-b}{c-b}\frac{b-c}{a-c}\right)\right|=\left|\Im\log(-1)\right|=\pi$, when evaluating on the principal branch. I had to cheat a bit and flip the $\frac{a-c}{b-c}$. Is there a more systematic way to prove this somehow?","Suppose you have a triangle with vertices $a$, $b$, and $c$. I asked earlier how you can define the angles in a triangle based on the $\log$ function. I received the answer that, for instance, the angle at $a$ is found as $\left|\Im\log\left(\frac{c-a}{b-a}\right)\right|$. Can this be used to show that the sum of angles in a triangle is $\pi$? I summed the angles as $$ \left|\Im\log\left(\frac{c-a}{b-a}\right)\right|+\left|\Im\log\left(\frac{a-b}{c-b}\right)\right|+\left|\Im\log\left(\frac{a-c}{b-c}\right)\right|. $$ I noticed that $\left|\Im\log\left(\frac{c-a}{b-a}\frac{a-b}{c-b}\frac{b-c}{a-c}\right)\right|=\left|\Im\log(-1)\right|=\pi$, when evaluating on the principal branch. I had to cheat a bit and flip the $\frac{a-c}{b-c}$. Is there a more systematic way to prove this somehow?",,"['geometry', 'complex-analysis', 'trigonometry', 'complex-numbers']"
62,A complex polynomial with partial derivatives equal to zero is constant.,A complex polynomial with partial derivatives equal to zero is constant.,,"There is an exercise in Function Theory of One Complex Variable by Greene & Krantz that is very similar to a Proposition in the book, but I am having trouble getting to the conclusion. Let $f : \mathbb{C} \to \mathbb{C}$ be a polynomial. Suppose further that $$\frac{\partial f}{\partial z} = 0$$   and $$\frac{\partial f}{\partial \bar z} = 0$$    for all $z \in \mathbb{C}$    Prove that $ f \equiv$ constant. Now, part of the proposition (1.3.2) proves that if $p$ is a polynomial, $$p(z, \bar z) = \sum a_{lm}z^l \bar z^m$$ with $\frac{\partial f}{\partial \bar z} = 0$, then $\frac{\partial ^{l + m}}{\partial z^l \partial \bar z^m}p$ evaluated at zero is $l!m!a_{lm}$. Is this the constant that $f$ equals? It doesn't seem like I've used the hypothesis, or reached the conclusion! Maybe I should use the definition of the partial... $$\frac{\partial f}{\partial z} := 1/2 (\frac{\partial }{\partial z} - i \cdot \frac{\partial }{\partial z})f$$ Any hints would be greatly appreciated.","There is an exercise in Function Theory of One Complex Variable by Greene & Krantz that is very similar to a Proposition in the book, but I am having trouble getting to the conclusion. Let $f : \mathbb{C} \to \mathbb{C}$ be a polynomial. Suppose further that $$\frac{\partial f}{\partial z} = 0$$   and $$\frac{\partial f}{\partial \bar z} = 0$$    for all $z \in \mathbb{C}$    Prove that $ f \equiv$ constant. Now, part of the proposition (1.3.2) proves that if $p$ is a polynomial, $$p(z, \bar z) = \sum a_{lm}z^l \bar z^m$$ with $\frac{\partial f}{\partial \bar z} = 0$, then $\frac{\partial ^{l + m}}{\partial z^l \partial \bar z^m}p$ evaluated at zero is $l!m!a_{lm}$. Is this the constant that $f$ equals? It doesn't seem like I've used the hypothesis, or reached the conclusion! Maybe I should use the definition of the partial... $$\frac{\partial f}{\partial z} := 1/2 (\frac{\partial }{\partial z} - i \cdot \frac{\partial }{\partial z})f$$ Any hints would be greatly appreciated.",,['complex-analysis']
63,"If $\lim_{n\to\infty}|a_n|/|a_{n+1}|=R$, why does $\sum a_nz^n$ also have radius of convergence $R$?","If , why does  also have radius of convergence ?",\lim_{n\to\infty}|a_n|/|a_{n+1}|=R \sum a_nz^n R,"I'm trying to teach myself complex analysis, and I've been working on this idea. Suppose $\lim_{n\to\infty}|a_n|/|a_{n+1}|=R$, I would like to know why $\sum a_nz^n$ also has $R$ as its radius of convergence. I believe I want to show $$ \limsup \sqrt[n]{|a_n|}=\frac{1}{\lim_{n\to\infty}|a_n|/|a_{n+1}|}=\lim_{n\to\infty}\frac{|a_{n+1}|}{|a_n|}. $$ I notice that $|a_n|$ can be written as $|a_n|=\frac{|a_n|}{|a_{n-1}|}\frac{|a_{n-1}|}{|a_{n-2}|}\cdots\frac{|a_{k+1}|}{|a_{k}|}|a_k|$. I hoped this would be helpful since it is a product of ratios of the absolute values of successive terms. I didn't know how to proceed after these observations. How can I finish this? Thanks!","I'm trying to teach myself complex analysis, and I've been working on this idea. Suppose $\lim_{n\to\infty}|a_n|/|a_{n+1}|=R$, I would like to know why $\sum a_nz^n$ also has $R$ as its radius of convergence. I believe I want to show $$ \limsup \sqrt[n]{|a_n|}=\frac{1}{\lim_{n\to\infty}|a_n|/|a_{n+1}|}=\lim_{n\to\infty}\frac{|a_{n+1}|}{|a_n|}. $$ I notice that $|a_n|$ can be written as $|a_n|=\frac{|a_n|}{|a_{n-1}|}\frac{|a_{n-1}|}{|a_{n-2}|}\cdots\frac{|a_{k+1}|}{|a_{k}|}|a_k|$. I hoped this would be helpful since it is a product of ratios of the absolute values of successive terms. I didn't know how to proceed after these observations. How can I finish this? Thanks!",,"['complex-analysis', 'power-series']"
64,Entire function invariant on the coordinate axes (as sets).,Entire function invariant on the coordinate axes (as sets).,,"From old qualifying exam: Let $E$ be the union of the two coordinate axes, i.e. $E = \{z=x+iy : xy=0\}$. Describe all entire functions satisfying $f(E) \subset E$. I feel like the best approach is to consider the power series of $f$. My first approach was to write down constraints by considering the function applied to the real or imaginary axis. When I didn't get anywhere with this, I began thinking of the function geometrically: on $E$ it's allowed to scale by a real constant, and rotate by $k\pi/2$. But again, I couldn't see how to usefully translate this to produce information about the power series. Thanks! As an example, $z^2$ has this property. In fact, so does $az^2+bz^4$ (with $a,b \in \mathbb{R}$) since each term maps the imaginary axis to the real axis, which ends up back on the real axis when added. A similar argument shows real odd polynomials work, too.","From old qualifying exam: Let $E$ be the union of the two coordinate axes, i.e. $E = \{z=x+iy : xy=0\}$. Describe all entire functions satisfying $f(E) \subset E$. I feel like the best approach is to consider the power series of $f$. My first approach was to write down constraints by considering the function applied to the real or imaginary axis. When I didn't get anywhere with this, I began thinking of the function geometrically: on $E$ it's allowed to scale by a real constant, and rotate by $k\pi/2$. But again, I couldn't see how to usefully translate this to produce information about the power series. Thanks! As an example, $z^2$ has this property. In fact, so does $az^2+bz^4$ (with $a,b \in \mathbb{R}$) since each term maps the imaginary axis to the real axis, which ends up back on the real axis when added. A similar argument shows real odd polynomials work, too.",,"['complex-analysis', 'analyticity']"
65,Find all analytic functions such that...,Find all analytic functions such that...,,"Here is the problem: find all functions that are everywhere analytic, have a zero of order two in $z=0$, satisfy the condition $|f'(z)|\leq 6|z|$ and such that $f(i)=-2$. Any hint is welcomed.","Here is the problem: find all functions that are everywhere analytic, have a zero of order two in $z=0$, satisfy the condition $|f'(z)|\leq 6|z|$ and such that $f(i)=-2$. Any hint is welcomed.",,['complex-analysis']
66,Example of a simple pole,Example of a simple pole,,"I was told that $\operatorname{sech} x$ has a simple pole . Could someone please explain what that means? I have looked up the definition but it involves too much jargon like holomorphic, etc. Is there a simple definition and why is this true? Thanks.","I was told that $\operatorname{sech} x$ has a simple pole . Could someone please explain what that means? I have looked up the definition but it involves too much jargon like holomorphic, etc. Is there a simple definition and why is this true? Thanks.",,"['complex-analysis', 'definition']"
67,The meaning of notation $\subset\subset$ in complex analysis,The meaning of notation  in complex analysis,\subset\subset,"I have read the book Function Theory of Several Complex Variables of Krantz. But there is a notation the meaning of which I don't know. The notation is $\subset\subset$. For example, ""let $\Omega\subset\subset \mathbb{R}^{n}$ be a connected open set"". Can somebody give me a definition?","I have read the book Function Theory of Several Complex Variables of Krantz. But there is a notation the meaning of which I don't know. The notation is $\subset\subset$. For example, ""let $\Omega\subset\subset \mathbb{R}^{n}$ be a connected open set"". Can somebody give me a definition?",,"['complex-analysis', 'notation']"
68,Are there any interpretations for the weights of modular forms?,Are there any interpretations for the weights of modular forms?,,"To be specific, do the weights have some geometric meanings? A modular form $f$ satisfies $f(\frac{az+b}{cz+d})(cz+d)^{-2k}=f(z)$, where $z\in \mathbb{C}$. $k$ or $2k$ is called the weight of $f$.","To be specific, do the weights have some geometric meanings? A modular form $f$ satisfies $f(\frac{az+b}{cz+d})(cz+d)^{-2k}=f(z)$, where $z\in \mathbb{C}$. $k$ or $2k$ is called the weight of $f$.",,"['number-theory', 'complex-analysis', 'modular-forms']"
69,An exercise in Conway about an integral,An exercise in Conway about an integral,,Here's the problem: Let $G$ be the punctured unit disk (i.e missing the point $0$). Let $f:G \mapsto \mathbb{C}$ be analytic. Suppose $\gamma$ is a closed curve in $G$ homologous to $0$ (that is the winding number of $\gamma$ about any point outside of $G$ is $0$). Then what is the value of $\int_{\gamma} f$? I said that here Cauchy's Theorem apply since $f$ is analytic and $\gamma$ is homologous to $0$ in $G$ and since $0$ is not in $G$ so the winding number of $\gamma$ about $0$ is $0$. Is this true?,Here's the problem: Let $G$ be the punctured unit disk (i.e missing the point $0$). Let $f:G \mapsto \mathbb{C}$ be analytic. Suppose $\gamma$ is a closed curve in $G$ homologous to $0$ (that is the winding number of $\gamma$ about any point outside of $G$ is $0$). Then what is the value of $\int_{\gamma} f$? I said that here Cauchy's Theorem apply since $f$ is analytic and $\gamma$ is homologous to $0$ in $G$ and since $0$ is not in $G$ so the winding number of $\gamma$ about $0$ is $0$. Is this true?,,['complex-analysis']
70,"Taylor Series expansion at z=0, and radius of convergence","Taylor Series expansion at z=0, and radius of convergence",,"I have the following question: Consider the domain $$ D=B(0,1)\cup B\left(\frac{1}{2}, 1\right) $$ It is given that $f:D\rightarrow \mathbb{C}$ is an analytic function in $D$, and $f^{(n)}(0)$ is a positive real number for every positive integer $n$. Let $R$ be the radius of convergence of the Taylor series of $f$ at $z=0$. Is it true that $R>1$? $$ $$ I have attached my proof to the following problem, although I am not sure if it correct, as I have clearly not used the fact that $f^{(n)}(0)$ is a positive real number for every positive integer $n$. How do I make use of this fact to prove/disprove the statement? $$ $$ Proof: Since $f$ is analytic on the ball $B(0,1)$, it follows from the definition of radius of convergence that $R\geq1$. Suppose on the contrary that $R=1$. By Taylor's Theorem, we may express $f$ as a Taylor series at $z=0$ as follows: $$f(z)=\sum_{n=0}^\infty\frac{f^{(n)}(0)}{n!}z^n$$ where the series converges absolutely for all $z\in B(0,1)$, and diverges for all $|z|>1$. Thus, by differentiating both sides of the above equation $k$ times, we have that for all $z\in B(0,1)$, $$ f^{(k)}(z)=\sum_{n=k}^\infty\frac{f^{(n)}(0)}{(n-k)!}z^{n-k}. $$ Also, since $f$ is analytic on the ball $B\left(\frac{1}{2},1\right)$, it follows from Taylor's Theorem that we may also express $f$ as a Taylor series at $z=\frac{1}{2}$ as follows: $$ f(z)=\sum_{k=0}^{\infty}\frac{f^{(k)}\left(\frac{1}{2}\right)}{k!}\left(z-\frac{1}{2}\right)^k, $$ where the series converges absolutely for all $z\in B\left(\frac{1}{2},1\right)$. Now, by setting $z=\frac{1}{2}$, we have that for all $k\geq0$, $$ f^{(k)}\left(\frac{1}{2}\right)=\sum_{n=k}^{\infty}\frac{f^{(n)}(0)}{(n-k)!}\cdot\frac{1}{2^{n-k}}. $$ Then for all $z\in B\left(\frac{1}{2},1\right)$, we have the following: $$ f(z) =\sum_{k=0}^{\infty}\frac{f^{(k)}\left(\frac{1}{2}\right)}{k!}\left(z-\frac{1}{2}\right)^k =\sum_{k=0}^{\infty}\sum_{n=k}^{\infty}\frac{f^{(n)}(0)}{(n-k)!k!}\cdot\frac{1}{2^{n-k}}\cdot\left(z-\frac{1}{2}\right)^k $$ $$ =\sum_{n=0}^{\infty}\sum_{k=0}^n\frac{f^{(n)}(0)}{(n-k)!k!}\cdot\left(\frac{1}{2}\right)^{n-k}\cdot\left(z-\frac{1}{2}\right)^k =\sum_{n=0}^{\infty}\frac{f^{(n)}(0)}{n!}\sum_{k=0}^n\frac{n!}{(n-k)!k!}\cdot\left(\frac{1}{2}\right)^{n-k}\cdot\left(z-\frac{1}{2}\right)^k $$ $$ =\sum_{n=0}^{\infty}\frac{f^{(n)}(0)}{n!}z^n. $$ Note: The interchanging of the summations is possible as the series $\sum_{k=0}^{\infty}\frac{f^{(k)}\left(\frac{1}{2}\right)}{k!}\left(z-\frac{1}{2}\right)^k$ converges absolutely for all $z\in B\left(\frac{1}{2},1\right)$; this follows from the Rearrangement Theorem, where any rearrangement of an absolutely convergent series converges to the same sum as the original series. This implies that the Taylor series of $f$ at $z=0$ converges for all $z\in B\left(\frac{1}{2},1\right)$; and in particular for all $z\in\mathbb{R}$, $1<z<\frac{3}{2}$, which contradicts the fact that the series diverges for all $|z|>1$. So we must have $R>1$ as desired.","I have the following question: Consider the domain $$ D=B(0,1)\cup B\left(\frac{1}{2}, 1\right) $$ It is given that $f:D\rightarrow \mathbb{C}$ is an analytic function in $D$, and $f^{(n)}(0)$ is a positive real number for every positive integer $n$. Let $R$ be the radius of convergence of the Taylor series of $f$ at $z=0$. Is it true that $R>1$? $$ $$ I have attached my proof to the following problem, although I am not sure if it correct, as I have clearly not used the fact that $f^{(n)}(0)$ is a positive real number for every positive integer $n$. How do I make use of this fact to prove/disprove the statement? $$ $$ Proof: Since $f$ is analytic on the ball $B(0,1)$, it follows from the definition of radius of convergence that $R\geq1$. Suppose on the contrary that $R=1$. By Taylor's Theorem, we may express $f$ as a Taylor series at $z=0$ as follows: $$f(z)=\sum_{n=0}^\infty\frac{f^{(n)}(0)}{n!}z^n$$ where the series converges absolutely for all $z\in B(0,1)$, and diverges for all $|z|>1$. Thus, by differentiating both sides of the above equation $k$ times, we have that for all $z\in B(0,1)$, $$ f^{(k)}(z)=\sum_{n=k}^\infty\frac{f^{(n)}(0)}{(n-k)!}z^{n-k}. $$ Also, since $f$ is analytic on the ball $B\left(\frac{1}{2},1\right)$, it follows from Taylor's Theorem that we may also express $f$ as a Taylor series at $z=\frac{1}{2}$ as follows: $$ f(z)=\sum_{k=0}^{\infty}\frac{f^{(k)}\left(\frac{1}{2}\right)}{k!}\left(z-\frac{1}{2}\right)^k, $$ where the series converges absolutely for all $z\in B\left(\frac{1}{2},1\right)$. Now, by setting $z=\frac{1}{2}$, we have that for all $k\geq0$, $$ f^{(k)}\left(\frac{1}{2}\right)=\sum_{n=k}^{\infty}\frac{f^{(n)}(0)}{(n-k)!}\cdot\frac{1}{2^{n-k}}. $$ Then for all $z\in B\left(\frac{1}{2},1\right)$, we have the following: $$ f(z) =\sum_{k=0}^{\infty}\frac{f^{(k)}\left(\frac{1}{2}\right)}{k!}\left(z-\frac{1}{2}\right)^k =\sum_{k=0}^{\infty}\sum_{n=k}^{\infty}\frac{f^{(n)}(0)}{(n-k)!k!}\cdot\frac{1}{2^{n-k}}\cdot\left(z-\frac{1}{2}\right)^k $$ $$ =\sum_{n=0}^{\infty}\sum_{k=0}^n\frac{f^{(n)}(0)}{(n-k)!k!}\cdot\left(\frac{1}{2}\right)^{n-k}\cdot\left(z-\frac{1}{2}\right)^k =\sum_{n=0}^{\infty}\frac{f^{(n)}(0)}{n!}\sum_{k=0}^n\frac{n!}{(n-k)!k!}\cdot\left(\frac{1}{2}\right)^{n-k}\cdot\left(z-\frac{1}{2}\right)^k $$ $$ =\sum_{n=0}^{\infty}\frac{f^{(n)}(0)}{n!}z^n. $$ Note: The interchanging of the summations is possible as the series $\sum_{k=0}^{\infty}\frac{f^{(k)}\left(\frac{1}{2}\right)}{k!}\left(z-\frac{1}{2}\right)^k$ converges absolutely for all $z\in B\left(\frac{1}{2},1\right)$; this follows from the Rearrangement Theorem, where any rearrangement of an absolutely convergent series converges to the same sum as the original series. This implies that the Taylor series of $f$ at $z=0$ converges for all $z\in B\left(\frac{1}{2},1\right)$; and in particular for all $z\in\mathbb{R}$, $1<z<\frac{3}{2}$, which contradicts the fact that the series diverges for all $|z|>1$. So we must have $R>1$ as desired.",,['complex-analysis']
71,Indefinite integral $\int^{\infty}_{0}\frac{x}{x^4+1}dx$ via residues,Indefinite integral  via residues,\int^{\infty}_{0}\frac{x}{x^4+1}dx,"I want to compute $\displaystyle \int^{\infty}_{0}\frac{x}{x^4+1}dx$ using the residue theorem. The poles in the upper half plane are: location: $\large e^{\frac{\pi i}4}$, order: 1, residue: $\large\frac{1}{4}e^{\frac{3\pi i}2}$ location: $\large e^{\frac{3\pi i}4}$, order: 1, residue: $\large \frac{1}{4}e^{\frac{\pi i}2}$ The problem is that the integral from $-\infty$ to $\infty$ vanishes for symmetry reasons, so I cannot apply the standard approach of putting the half of a 1-sphere on top of the real axis and letting its radius go to infinity. If x was replaced with $x^2$ for instance, I could just divide the result by two. Is there another way of contour integration to evaluate the upper expression?","I want to compute $\displaystyle \int^{\infty}_{0}\frac{x}{x^4+1}dx$ using the residue theorem. The poles in the upper half plane are: location: $\large e^{\frac{\pi i}4}$, order: 1, residue: $\large\frac{1}{4}e^{\frac{3\pi i}2}$ location: $\large e^{\frac{3\pi i}4}$, order: 1, residue: $\large \frac{1}{4}e^{\frac{\pi i}2}$ The problem is that the integral from $-\infty$ to $\infty$ vanishes for symmetry reasons, so I cannot apply the standard approach of putting the half of a 1-sphere on top of the real axis and letting its radius go to infinity. If x was replaced with $x^2$ for instance, I could just divide the result by two. Is there another way of contour integration to evaluate the upper expression?",,"['integration', 'complex-analysis']"
72,How can I compute this limit,How can I compute this limit,,"I want to prove that $\lim_{h\rightarrow\infty}\left(\int_{0}^{\infty}\left(\cos ht-1\right)\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]dt\right)=-\int_{0}^{\infty}\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]dt$ where  $\underset{t}{\triangle}\eta(t)=\eta(t)+\eta(-t)$ and $\phi$ is an integrable function (in the lebesgue sense), to be precise it is the fourier transform of an integrable density function and thus continuous. Also $\phi$ is differentiable at $0$. According to the authors of this paper (see proof of theorem 3), this can be achieved by showing $\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]$ is integrable and the result will follow from the Riemann Lebesgue lemma. They do this by showing that $\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]$ is uniformly bounded. And this is the part of the proof I am stuck on. Can anyone show me how to prove $\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]$ is uniformly bounded and integrable? Thanks","I want to prove that $\lim_{h\rightarrow\infty}\left(\int_{0}^{\infty}\left(\cos ht-1\right)\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]dt\right)=-\int_{0}^{\infty}\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]dt$ where  $\underset{t}{\triangle}\eta(t)=\eta(t)+\eta(-t)$ and $\phi$ is an integrable function (in the lebesgue sense), to be precise it is the fourier transform of an integrable density function and thus continuous. Also $\phi$ is differentiable at $0$. According to the authors of this paper (see proof of theorem 3), this can be achieved by showing $\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]$ is integrable and the result will follow from the Riemann Lebesgue lemma. They do this by showing that $\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]$ is uniformly bounded. And this is the part of the proof I am stuck on. Can anyone show me how to prove $\underset{t}{\triangle}\left[\frac{\phi(t)\exp\left(-itx\right)}{it}\right]$ is uniformly bounded and integrable? Thanks",,"['calculus', 'analysis', 'complex-analysis', 'fourier-analysis']"
73,What was used to establish this equivalence? [Textbook],What was used to establish this equivalence? [Textbook],,"To solve for the $\sin^{-1} z$ ($z$ element of $\mathbb{C}$), the book reads that $w = \sin^{-1} z$ when $z = \sin w$ implies: $w = \sin^{-1} z$ when $z = (e^{iw} - e^{-iw})/2i$  implies: $(e^{iw})^2 - 2iz(e^{iw}) - 1 = 0$ * I don't see (2) implies (3). I mean it looks like the first step they used was mutiply out the $2i$, then subtract $2zi$ from both sides, but I'm lost after that.","To solve for the $\sin^{-1} z$ ($z$ element of $\mathbb{C}$), the book reads that $w = \sin^{-1} z$ when $z = \sin w$ implies: $w = \sin^{-1} z$ when $z = (e^{iw} - e^{-iw})/2i$  implies: $(e^{iw})^2 - 2iz(e^{iw}) - 1 = 0$ * I don't see (2) implies (3). I mean it looks like the first step they used was mutiply out the $2i$, then subtract $2zi$ from both sides, but I'm lost after that.",,"['algebra-precalculus', 'complex-analysis']"
74,A bound on a Möbius transform,A bound on a Möbius transform,,"Suppose $z,w \in \mathbb{C}$ s.t. $|z|,|w| < 1$. How would you show that $\frac{|z-w|}{|1-\bar{w}z|} \leq |z| + |w|$? I calculated that \begin{align*} &\frac{|z-w|}{|1-\bar{w}z|} \leq |z| + |w| \\ &\Rightarrow \frac{|z|^2-2Re(\bar{w}z)-|w|^2}{1-2Re(\bar{w}z) + |w|^2|z|^2} \leq (|z|+|w|)^2 \\ &\Rightarrow -2Re(\bar{w}z) \leq 2|z||w| + (|w|^2|z|^2 - 2 Re(\bar{w}z))(|z| +|w|)^2\ \end{align*} If $2Re(\bar{w}z) < 0$, then $2|z||w| \geq 2Re(\bar{w}z)$ and $(|w|^2|z|^2 - 2 Re(\bar{w}z)) \geq 0$ imply that the inequality is true. I haven't been able to figure out what happens in the case that $2Re(\bar{w}z) >0$ though. On a separate note, whenever I come across these types of problems, I always try to multiply everything out and see if I can get enough terms to cancel so that the inequality becomes obvious. I'm not quite sure if that's the smartest way to go about things, though and if there is some intuition that I should be using that I don't know about.","Suppose $z,w \in \mathbb{C}$ s.t. $|z|,|w| < 1$. How would you show that $\frac{|z-w|}{|1-\bar{w}z|} \leq |z| + |w|$? I calculated that \begin{align*} &\frac{|z-w|}{|1-\bar{w}z|} \leq |z| + |w| \\ &\Rightarrow \frac{|z|^2-2Re(\bar{w}z)-|w|^2}{1-2Re(\bar{w}z) + |w|^2|z|^2} \leq (|z|+|w|)^2 \\ &\Rightarrow -2Re(\bar{w}z) \leq 2|z||w| + (|w|^2|z|^2 - 2 Re(\bar{w}z))(|z| +|w|)^2\ \end{align*} If $2Re(\bar{w}z) < 0$, then $2|z||w| \geq 2Re(\bar{w}z)$ and $(|w|^2|z|^2 - 2 Re(\bar{w}z)) \geq 0$ imply that the inequality is true. I haven't been able to figure out what happens in the case that $2Re(\bar{w}z) >0$ though. On a separate note, whenever I come across these types of problems, I always try to multiply everything out and see if I can get enough terms to cancel so that the inequality becomes obvious. I'm not quite sure if that's the smartest way to go about things, though and if there is some intuition that I should be using that I don't know about.",,"['complex-analysis', 'mobius-transformation']"
75,"Let $a,b,c,d\in\mathbb{C}$ such that $|a|+|b|\leq 1$ and $|c|+|d|\leq 1$. Show that $|3a+b+3c-d|+|a+3b-c+3d|\leq 7$.",Let  such that  and . Show that .,"a,b,c,d\in\mathbb{C} |a|+|b|\leq 1 |c|+|d|\leq 1 |3a+b+3c-d|+|a+3b-c+3d|\leq 7","Let $a,b,c,d\in\mathbb{C}$ such that $|a|+|b|\leq 1$ and $|c|+|d|\leq 1$ . Show that $|3a+b+3c-d|+|a+3b-c+3d|\leq 7$ , or find a counterexample -- I don't know for sure that the inequality stated in the title is true. In the case of $a,b,c,d\in\mathbb{R}$ , the constraint set is a polytope and the objective is convex. Thus, simply by checking its value on all vertices $\{(\pm 1,0), (0,\pm 1)\}^2$ , we see that the upper bound is $6$ . I'm not sure about the complex case though. It looks like the above approach won't work, because the feasible set has uncountably many extreme points. By naive Monte Carlo sampling it seems that the maximum is around $6.33$ .","Let such that and . Show that , or find a counterexample -- I don't know for sure that the inequality stated in the title is true. In the case of , the constraint set is a polytope and the objective is convex. Thus, simply by checking its value on all vertices , we see that the upper bound is . I'm not sure about the complex case though. It looks like the above approach won't work, because the feasible set has uncountably many extreme points. By naive Monte Carlo sampling it seems that the maximum is around .","a,b,c,d\in\mathbb{C} |a|+|b|\leq 1 |c|+|d|\leq 1 |3a+b+3c-d|+|a+3b-c+3d|\leq 7 a,b,c,d\in\mathbb{R} \{(\pm 1,0), (0,\pm 1)\}^2 6 6.33","['complex-analysis', 'inequality', 'complex-numbers']"
76,How is $\zeta(0)$ actually $-1/2?$,How is  actually,\zeta(0) -1/2?,"I was searching around the forum, and I came across: $$\zeta(0) = \lim_{s\to 0}\, 2^{s-1} \pi^s \cdot \frac{\sin(\pi s/2)}{\pi s/2} \cdot \Gamma(1-s) \cdot s\zeta(1-s) = 2^{-1} \pi^0 \cdot 1 \cdot \Gamma(1) \cdot (-1) = -\frac{1}{2}.$$ But how does the last term, $$s\zeta(1-s)=$$ Equal -1? Which definition is being used here? How does 0 times the zeta function give -1? The original answer was given at https://math.stackexchange.com/a/1751998/1277963","I was searching around the forum, and I came across: But how does the last term, Equal -1? Which definition is being used here? How does 0 times the zeta function give -1? The original answer was given at https://math.stackexchange.com/a/1751998/1277963","\zeta(0) = \lim_{s\to 0}\, 2^{s-1} \pi^s \cdot \frac{\sin(\pi s/2)}{\pi s/2} \cdot \Gamma(1-s) \cdot s\zeta(1-s) = 2^{-1} \pi^0 \cdot 1 \cdot \Gamma(1) \cdot (-1) = -\frac{1}{2}. s\zeta(1-s)=","['complex-analysis', 'riemann-zeta']"
77,Integrals with residue theory [ANSWERED],Integrals with residue theory [ANSWERED],,"I'm having some problems solving this integral: $$ I = \mathcal{P} \int_{-\infty}^{+\infty} \frac{1-e^{2ix}}{x^2} \ dx$$ where $\mathcal{P}$ is the Cauchy principal value. The exercise suggests to use the fact that: $$I_* = \frac{1}{2} \operatorname{Re} \left[I\right]=\mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx$$ since $\sin^2 x = \frac{1}{2} \left(1- \cos(2x)\right)$ . My solution. I went on and tried to solve $I_*$ as follows: I used the fact that the analytic extension of the integrand has no poles, which makes the integral equals to $0$ by using residue theory: $$\lim_{R\to + \infty}\oint_{\Gamma_R} \frac{\sin^2z}{z^2} \ dz = \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx = 0$$ where the second equality is true since $$\oint_{\Gamma_R}\frac{\sin^2z}{z^2} \ dz =\left(\int_{-R}^{+R} + \int_{C_R}\right) \frac{\sin^2z}{z^2} \ dz$$ where $C_R = \{z = r e^{i \theta}\in \mathbb{C} : 0\le r \le R\}$ and $$\left\lvert \int_{C_R} \frac{\sin^2 z}{z^2} \ dz \right\rvert \le \int_{C_R} \frac{1}{|z^2|} \ dz \le \int_{C_R} \frac{1}{|R^2|} \ dz \to 0, \ R\to +\infty$$ $$\lim_{R\to+\infty} \int_{-R}^{+R} \frac{\sin^2z}{z^2} \ dz = \lim_{R\to+\infty} \frac{\sin^2 x}{x^2} \ dx \equiv \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx$$ Since the residues of this function are all $0$ , this means that also $$\mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx =0 $$ Ok, now, since this implies that $\operatorname{Re}I = 0$ , I thought that $I$ must have just an imaginary part; for this reason, I then tried to calculate the following: $$\operatorname{Im} [I] = \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin(2x)}{x^2} \ dx \equiv \mathcal{P}\int_{-\infty}^{+\infty} h(x) \ dx$$ I extended $h(x)\to h(z)$ , which has a first order pole in $z=0$ : $$\operatorname{Res}\left[h(z) , z=0\right]=\lim_{z\to 0 } \left(z \frac{\sin 2z}{z^2}\right) = 2$$ Then I integrated $h(z)$ as follows: $$\oint_{\Gamma_{r,R} } \frac{\sin 2z}{z^2} \ dz = \left(\int_{-R} ^{-r} + \int_{C_r^-} +\int_{r}^{R} + \int_{C_R}     \right) \frac{\sin 2z}{z^2} \ dz $$ where: $$\lim_{r\to 0} \int_{C_r^-} \frac{\sin 2z}{z^2} \ dz \to -i\pi\operatorname{Res}\left[h(z), z=0\right] = -2i\pi $$ $$\left\lvert \int_{C_R} \frac{\sin 2z}{z^2} \ dz \right\rvert \le \int_{C_R} \frac{1}{R^2}\to 0, \ R\to+\infty $$ $$\lim_{r \to 0, \ R\to +\infty} \left(\int_{-R}^{-r} + \int_{r} ^{R}   \right) h(z) \ dz \equiv \mathcal{P}\int_{-\infty} ^{+\infty} h(x) \ dx $$ Putting all of this together, we get: $$\mathcal{P}\int_{-\infty} ^{+\infty} \frac{\sin 2x}{x^2 } \ dx = -2i\pi$$ What bothers me the most and that makes me think I did something wrong is that the result of this real valued integral is an imaginary number. Moreover, this would mean $\operatorname{Im} (I) = -2i\pi\Rightarrow I\stackrel{?}{=} 2\pi$ or $I \stackrel{?}{=} -2i\pi$ . Did I make some errors? Can you help me getting to the correct solution? I really need help with this because I feel like I'm missing something very important. Thanks a lot in advance for the help!! EDIT 1: This is the solution by calculating directly $I$ with the residues. So we define $F(z) = \frac{1-e^{2iz} }{z^2}$ , which is the analytical extension of the integrand of $I$ . This clearly has a first order pole in $z=0$ , which residue is obtained by: $$\operatorname{Res}\left[F(z), z=0\right] = \lim_{z \to 0} \frac{d}{dz}\left(z^2 \frac{1-e^{2iz} }{z^2}\right) = -2i $$ The complex integral we need to calculate would be: $$\lim_{r\to 0, \ R \to +\infty} \oint_{\Gamma_{r,R} } \frac{1-e^{2iz} }{z^2}\ dz = \lim_{r\to 0, R\to+\infty} \left(\int_{-R}^{-r} + \int_{C_r^-} +\int_{r} ^R + \int_{C_R}   \right) \frac{1-e^{2iz} }{z^2}\ dz =0 $$ since of the first order pole in $z=0$ (and it is equal to $0$ because there are no poles inside the contour taken), it is needed to create a small arc of circumference $C_r$ to avoid calculating the function in $z=0$ . After making sure that the integral on $C_R$ goes to $0$ , which is done by using Jordan's Lemma and the fact that $\frac{1}{|z^2|}=\frac{1}{R^2}\to 0$ as $R\to+\infty$ , we can calculate the integral on $C_r^-$ (where the minus sign is because it is ``walked'' clockwise); this should be integral that gives the residue in $z=0$ of $F(z)$ when $r\to 0$ because of the theorem that states that: $$\lim_{r  \to 0} \int_{C_{r_\alpha } } F(z) \ dz = i \alpha \operatorname{Res}\left[F(z), z=0\right] $$ (which is true just for first order poles). This theorem implies automatically that $$\lim_{r \to 0} \int_{C_r^-} \frac{1-e^{2iz} }{z^2} \ dz = -i \pi (-2i) = 2\pi =-2\pi$$ Since the other two integrals are such that: $$\lim_{r \to 0, \ R\to+\infty} \left(\int_{-R} ^{-r} + \int_{r} ^R \right) \frac{1-e^{2iz} }{z^2} \ dz \equiv \lim_{r \to 0, \ R\to+\infty} \left(\int_{-R} ^{-r} + \int_{r} ^R \right) \frac{1-e^{2ix} }{x^2} \ dx  \equiv \mathcal{P}\int_{-\infty} ^{+\infty} \frac{1-e^{2ix} }{x^2} \ dx  $$ it means that: $$\mathcal{P}\int_{-\infty} ^{+\infty} \frac{1-e^{2ix} }{x^2} \ dx = 2\pi$$ As pointed out in the comments, this is the most concise and easy solution for the problem; nonetheless why does the exercise, which is directly taken from a past exam that my professor made public, suggests to use the integral $I_*$ ? EDIT 2: I'll contact my professor to ask him why he gave that hint in the exercise. I'll update this post afterwards to let you know what he replied to me. EDIT 3: My professor told me that that was not an hint, rather it was possibile to evaluate that in integral ( $I_*$ ) once obtained the main one, since $I_*$ is not obtainable by standard integration.","I'm having some problems solving this integral: where is the Cauchy principal value. The exercise suggests to use the fact that: since . My solution. I went on and tried to solve as follows: I used the fact that the analytic extension of the integrand has no poles, which makes the integral equals to by using residue theory: where the second equality is true since where and Since the residues of this function are all , this means that also Ok, now, since this implies that , I thought that must have just an imaginary part; for this reason, I then tried to calculate the following: I extended , which has a first order pole in : Then I integrated as follows: where: Putting all of this together, we get: What bothers me the most and that makes me think I did something wrong is that the result of this real valued integral is an imaginary number. Moreover, this would mean or . Did I make some errors? Can you help me getting to the correct solution? I really need help with this because I feel like I'm missing something very important. Thanks a lot in advance for the help!! EDIT 1: This is the solution by calculating directly with the residues. So we define , which is the analytical extension of the integrand of . This clearly has a first order pole in , which residue is obtained by: The complex integral we need to calculate would be: since of the first order pole in (and it is equal to because there are no poles inside the contour taken), it is needed to create a small arc of circumference to avoid calculating the function in . After making sure that the integral on goes to , which is done by using Jordan's Lemma and the fact that as , we can calculate the integral on (where the minus sign is because it is ``walked'' clockwise); this should be integral that gives the residue in of when because of the theorem that states that: (which is true just for first order poles). This theorem implies automatically that Since the other two integrals are such that: it means that: As pointed out in the comments, this is the most concise and easy solution for the problem; nonetheless why does the exercise, which is directly taken from a past exam that my professor made public, suggests to use the integral ? EDIT 2: I'll contact my professor to ask him why he gave that hint in the exercise. I'll update this post afterwards to let you know what he replied to me. EDIT 3: My professor told me that that was not an hint, rather it was possibile to evaluate that in integral ( ) once obtained the main one, since is not obtainable by standard integration."," I = \mathcal{P} \int_{-\infty}^{+\infty} \frac{1-e^{2ix}}{x^2} \ dx \mathcal{P} I_* = \frac{1}{2} \operatorname{Re} \left[I\right]=\mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx \sin^2 x = \frac{1}{2} \left(1- \cos(2x)\right) I_* 0 \lim_{R\to + \infty}\oint_{\Gamma_R} \frac{\sin^2z}{z^2} \ dz = \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx = 0 \oint_{\Gamma_R}\frac{\sin^2z}{z^2} \ dz =\left(\int_{-R}^{+R} + \int_{C_R}\right) \frac{\sin^2z}{z^2} \ dz C_R = \{z = r e^{i \theta}\in \mathbb{C} : 0\le r \le R\} \left\lvert \int_{C_R} \frac{\sin^2 z}{z^2} \ dz \right\rvert \le \int_{C_R} \frac{1}{|z^2|} \ dz \le \int_{C_R} \frac{1}{|R^2|} \ dz \to 0, \ R\to +\infty \lim_{R\to+\infty} \int_{-R}^{+R} \frac{\sin^2z}{z^2} \ dz = \lim_{R\to+\infty} \frac{\sin^2 x}{x^2} \ dx \equiv \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx 0 \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin^2 x}{x^2} \ dx =0  \operatorname{Re}I = 0 I \operatorname{Im} [I] = \mathcal{P} \int_{-\infty}^{+\infty} \frac{\sin(2x)}{x^2} \ dx \equiv \mathcal{P}\int_{-\infty}^{+\infty} h(x) \ dx h(x)\to h(z) z=0 \operatorname{Res}\left[h(z) , z=0\right]=\lim_{z\to 0 } \left(z \frac{\sin 2z}{z^2}\right) = 2 h(z) \oint_{\Gamma_{r,R} } \frac{\sin 2z}{z^2} \ dz = \left(\int_{-R} ^{-r} + \int_{C_r^-} +\int_{r}^{R} + \int_{C_R}     \right) \frac{\sin 2z}{z^2} \ dz  \lim_{r\to 0} \int_{C_r^-} \frac{\sin 2z}{z^2} \ dz \to -i\pi\operatorname{Res}\left[h(z), z=0\right] = -2i\pi  \left\lvert \int_{C_R} \frac{\sin 2z}{z^2} \ dz \right\rvert \le \int_{C_R} \frac{1}{R^2}\to 0, \ R\to+\infty  \lim_{r \to 0, \ R\to +\infty} \left(\int_{-R}^{-r} + \int_{r} ^{R}   \right) h(z) \ dz \equiv \mathcal{P}\int_{-\infty} ^{+\infty} h(x) \ dx  \mathcal{P}\int_{-\infty} ^{+\infty} \frac{\sin 2x}{x^2 } \ dx = -2i\pi \operatorname{Im} (I) = -2i\pi\Rightarrow I\stackrel{?}{=} 2\pi I \stackrel{?}{=} -2i\pi I F(z) = \frac{1-e^{2iz} }{z^2} I z=0 \operatorname{Res}\left[F(z), z=0\right] = \lim_{z \to 0} \frac{d}{dz}\left(z^2 \frac{1-e^{2iz} }{z^2}\right) = -2i  \lim_{r\to 0, \ R \to +\infty} \oint_{\Gamma_{r,R} } \frac{1-e^{2iz} }{z^2}\ dz = \lim_{r\to 0, R\to+\infty} \left(\int_{-R}^{-r} + \int_{C_r^-} +\int_{r} ^R + \int_{C_R}   \right) \frac{1-e^{2iz} }{z^2}\ dz =0  z=0 0 C_r z=0 C_R 0 \frac{1}{|z^2|}=\frac{1}{R^2}\to 0 R\to+\infty C_r^- z=0 F(z) r\to 0 \lim_{r  \to 0} \int_{C_{r_\alpha } } F(z) \ dz = i \alpha \operatorname{Res}\left[F(z), z=0\right]  \lim_{r \to 0} \int_{C_r^-} \frac{1-e^{2iz} }{z^2} \ dz = -i \pi (-2i) = 2\pi =-2\pi \lim_{r \to 0, \ R\to+\infty} \left(\int_{-R} ^{-r} + \int_{r} ^R \right) \frac{1-e^{2iz} }{z^2} \ dz \equiv \lim_{r \to 0, \ R\to+\infty} \left(\int_{-R} ^{-r} + \int_{r} ^R \right) \frac{1-e^{2ix} }{x^2} \ dx  \equiv \mathcal{P}\int_{-\infty} ^{+\infty} \frac{1-e^{2ix} }{x^2} \ dx   \mathcal{P}\int_{-\infty} ^{+\infty} \frac{1-e^{2ix} }{x^2} \ dx = 2\pi I_* I_* I_*","['integration', 'complex-analysis', 'complex-numbers', 'residue-calculus', 'cauchy-principal-value']"
78,Extrema of $\sum_{j=0}^{n-1} \frac{1}{|z-a_j|^2}$ for $z$ on unit circle,Extrema of  for  on unit circle,\sum_{j=0}^{n-1} \frac{1}{|z-a_j|^2} z,"Let $n \in \mathbb{N}$ , $0<r<1$ and $\omega = \exp\left(\frac{2 \pi i}{n}\right)$ . For $j = 0, 1, \ldots, n-1$ define $a_j = r \omega^j$ , these are the vertices of a regular $n$ -gon inside the circle of radious $r$ . Now for which $z \in \mathbb{C}$ on the unit circle, that is $|z|=1$ , does the following expression $$\sum_{j=0}^{n-1} \frac{1}{|z-a_j|^2}$$ achieve its minimal and maximal value? The answer turns out that the maximal value is achievet for $z_{max} = \exp\left(\frac{2j \pi i}{n}\right) = \omega^j$ , that is for the point lying above the vertices, and minimal for $z_{min}= \exp\left(\frac{(2 j+ 1)\pi i}{n}\right)$ , that is the points above the midpoint between two vertices. Now due to simmetry we can conclude that the points $z_{max}$ and $z_{min}$ will be local extrema and that we can only concentrate on $z$ with argument in $(0,\pi / n)$ . It remains to show that for any given $n$ the above expression is monotone on the interval $(0,\pi / n)$ . But for the life of me I am not able to prove this. I tried calculating the derivative after parametrising, but the calculations are too messy. I tried Lagrange multipliers, in the real and complex setting, but again no luck. I tried some geometric arguments, but again didn't get far. The problem remindes me of potential theory, although I know nothing of the subject. Another neat thing is that the terms are Poisson kernels of the unit disc, so there might be some Harmonic analysis tools one could use. Does anyone have an idea how one can proof this? The problem seems elementary to me, so if it's a known solved problem, I'd love a reference.","Let , and . For define , these are the vertices of a regular -gon inside the circle of radious . Now for which on the unit circle, that is , does the following expression achieve its minimal and maximal value? The answer turns out that the maximal value is achievet for , that is for the point lying above the vertices, and minimal for , that is the points above the midpoint between two vertices. Now due to simmetry we can conclude that the points and will be local extrema and that we can only concentrate on with argument in . It remains to show that for any given the above expression is monotone on the interval . But for the life of me I am not able to prove this. I tried calculating the derivative after parametrising, but the calculations are too messy. I tried Lagrange multipliers, in the real and complex setting, but again no luck. I tried some geometric arguments, but again didn't get far. The problem remindes me of potential theory, although I know nothing of the subject. Another neat thing is that the terms are Poisson kernels of the unit disc, so there might be some Harmonic analysis tools one could use. Does anyone have an idea how one can proof this? The problem seems elementary to me, so if it's a known solved problem, I'd love a reference.","n \in \mathbb{N} 0<r<1 \omega = \exp\left(\frac{2 \pi i}{n}\right) j = 0, 1, \ldots, n-1 a_j = r \omega^j n r z \in \mathbb{C} |z|=1 \sum_{j=0}^{n-1} \frac{1}{|z-a_j|^2} z_{max} = \exp\left(\frac{2j \pi i}{n}\right) = \omega^j z_{min}= \exp\left(\frac{(2 j+ 1)\pi i}{n}\right) z_{max} z_{min} z (0,\pi / n) n (0,\pi / n)","['complex-analysis', 'geometry', 'extreme-value-analysis']"
79,The proof about Cauchy's Integral Formula in Ahlfors' Complex Analysis,The proof about Cauchy's Integral Formula in Ahlfors' Complex Analysis,,"On the third edition of Ahlfors' Complex Analysis, page 122 Lemma 3 it states: Now, if we divide the identity by $z-z_0$ and let $z$ tend to $z_0$ , the quotient in the first term tends to a derivative which by the induction hypothesis equals $(n-1)F_{n+1}(z_0)$ . I'm confused about it. We have: \begin{equation*} \lim_{z\rightarrow z_{0}}\frac{1}{z-z_{0}}\left(\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z)^{n-1}}d\zeta-\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n-1}}d\zeta\right)=(n-1)\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n}}d\zeta \end{equation*} But I don't know how to prove: \begin{equation*} \lim_{z\rightarrow z_0}\frac{1}{z-z_0}\left[\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z)^{n-1}(\zeta-z_{0})}d\zeta-\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n}}d\zeta\right]=(n-1)\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n+1}}d\zeta \end{equation*} This a question from Ahlfors' Complex Analysis. I show you the whole context of the question below. I have trouble understanding the statement with red line.","On the third edition of Ahlfors' Complex Analysis, page 122 Lemma 3 it states: Now, if we divide the identity by and let tend to , the quotient in the first term tends to a derivative which by the induction hypothesis equals . I'm confused about it. We have: But I don't know how to prove: This a question from Ahlfors' Complex Analysis. I show you the whole context of the question below. I have trouble understanding the statement with red line.","z-z_0 z z_0 (n-1)F_{n+1}(z_0) \begin{equation*}
\lim_{z\rightarrow z_{0}}\frac{1}{z-z_{0}}\left(\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z)^{n-1}}d\zeta-\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n-1}}d\zeta\right)=(n-1)\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n}}d\zeta
\end{equation*} \begin{equation*}
\lim_{z\rightarrow z_0}\frac{1}{z-z_0}\left[\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z)^{n-1}(\zeta-z_{0})}d\zeta-\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n}}d\zeta\right]=(n-1)\int_{\gamma}\frac{\varphi(\zeta)}{(\zeta-z_{0})^{n+1}}d\zeta
\end{equation*}","['integration', 'complex-analysis', 'analysis', 'proof-explanation', 'cauchy-integral-formula']"
80,Entire function is a polynomial,Entire function is a polynomial,,"Let $f = \sum_{n =0}^{\infty} a_nz^n$ be an entire function such that $\forall w \in \mathbb{C}, f(z) = w$ admits a finite number of solutions. I want to prove that f is a polynomial. So far, I know that $f(z) - w$ admits a finite number of roots, by fixing $w$ I wanted to directly show that it forces $f$ to be a polynomial of maximum degree $n$ (with $n$ being the number of roots). I don't know how to proceed and any help would be welcome.","Let be an entire function such that admits a finite number of solutions. I want to prove that f is a polynomial. So far, I know that admits a finite number of roots, by fixing I wanted to directly show that it forces to be a polynomial of maximum degree (with being the number of roots). I don't know how to proceed and any help would be welcome.","f = \sum_{n =0}^{\infty} a_nz^n \forall w \in \mathbb{C}, f(z) = w f(z) - w w f n n",['complex-analysis']
81,Residue of the function: $\sin(\frac{1}{z^2+1})$ at $z = i$ [closed],Residue of the function:  at  [closed],\sin(\frac{1}{z^2+1}) z = i,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 6 months ago . Improve this question Residue of $$\sin(\frac{1}{z^2+1})$$ at $z = i$ . I've tried to find its Laurent series, but it's seemed too complicated, so i don't know what to do..","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 6 months ago . Improve this question Residue of at . I've tried to find its Laurent series, but it's seemed too complicated, so i don't know what to do..",\sin(\frac{1}{z^2+1}) z = i,"['complex-analysis', 'residue-calculus']"
82,"For $u$ harmonic and $f = u+iv$ holomorphic, show that $f(z) = \frac{1}{\pi i} \oint_{|\zeta|=r} \frac{u(\zeta)}{\zeta - z} d\zeta - \overline{f(0)}$","For  harmonic and  holomorphic, show that",u f = u+iv f(z) = \frac{1}{\pi i} \oint_{|\zeta|=r} \frac{u(\zeta)}{\zeta - z} d\zeta - \overline{f(0)},"Here's a question from a previous complex analysis qualifying exam that I'm honestly just stumped on: Let $u$ be a harmonic function on the unit disc $D = \{z: |z|<1\}$ , which is the real part of the holomorphic function $f$ on $D$ . Show that for any $0<r<1$ we have $$ f(z) = \frac{1}{\pi i} \oint_{|\zeta|=r} \frac{u(\zeta)}{\zeta - z} d\zeta - \overline{f(0)}, \quad \quad \text{for } |z|<r. $$ I know that $u$ harmonic means $u_{xx}+u_{yy} = 0$ . The form of $f(z)$ given looks reminiscent of Cauchy's Integral Formula and we could say that since $f$ is holomorphic, we can write $$f(z) = \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{f(\zeta)}{\zeta - z} d\zeta =  \frac{1}{2\pi i} \oint_{|\zeta|=r} \left(\frac{u(\zeta)}{\zeta - z} + i \frac{v(\zeta)}{\zeta - z}\right) d\zeta$$ but where do I go from here? UPDATE: Building on a suggestion from a comment, we also have $$\overline{f(z)} = \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{\overline{f(\zeta)}}{\zeta - z} d\zeta =  \frac{1}{2\pi i} \oint_{|\zeta|=r} \left(\frac{u(\zeta)}{\zeta - z} - i \frac{v(\zeta)}{\zeta - z}\right) d\zeta$$ and thus $$\overline{f(0)} = \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{\overline{f(\zeta)}}{\zeta } d\zeta =  \frac{1}{2\pi i} \oint_{|\zeta|=r} \left(\frac{u(\zeta)}{\zeta} - i \frac{v(\zeta)}{\zeta}\right) d\zeta.$$ I can add these two and with a bit of manipulation get $$f(z) + \overline{f(0)} =  \frac{1}{\pi i} \oint_{|\zeta|=r} \frac{u(\zeta)}{\zeta - z} d\zeta - \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{z\overline{f(\zeta)}}{\zeta(\zeta - z)} d\zeta.$$ It remains to show that the last term goes to zero... and I am once again stuck. UPDATE 2: I added a bounty to this question in hopes of getting a full, complete, and clear worked answer to this problem. I need to make sure I can do this kind of problem correctly before my own upcoming qual.","Here's a question from a previous complex analysis qualifying exam that I'm honestly just stumped on: Let be a harmonic function on the unit disc , which is the real part of the holomorphic function on . Show that for any we have I know that harmonic means . The form of given looks reminiscent of Cauchy's Integral Formula and we could say that since is holomorphic, we can write but where do I go from here? UPDATE: Building on a suggestion from a comment, we also have and thus I can add these two and with a bit of manipulation get It remains to show that the last term goes to zero... and I am once again stuck. UPDATE 2: I added a bounty to this question in hopes of getting a full, complete, and clear worked answer to this problem. I need to make sure I can do this kind of problem correctly before my own upcoming qual.","u D = \{z: |z|<1\} f D 0<r<1  f(z) = \frac{1}{\pi i} \oint_{|\zeta|=r} \frac{u(\zeta)}{\zeta - z} d\zeta - \overline{f(0)}, \quad \quad \text{for } |z|<r.  u u_{xx}+u_{yy} = 0 f(z) f f(z) = \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{f(\zeta)}{\zeta - z} d\zeta =  \frac{1}{2\pi i} \oint_{|\zeta|=r} \left(\frac{u(\zeta)}{\zeta - z} + i \frac{v(\zeta)}{\zeta - z}\right) d\zeta \overline{f(z)} = \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{\overline{f(\zeta)}}{\zeta - z} d\zeta =  \frac{1}{2\pi i} \oint_{|\zeta|=r} \left(\frac{u(\zeta)}{\zeta - z} - i \frac{v(\zeta)}{\zeta - z}\right) d\zeta \overline{f(0)} = \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{\overline{f(\zeta)}}{\zeta } d\zeta =  \frac{1}{2\pi i} \oint_{|\zeta|=r} \left(\frac{u(\zeta)}{\zeta} - i \frac{v(\zeta)}{\zeta}\right) d\zeta. f(z) + \overline{f(0)} =  \frac{1}{\pi i} \oint_{|\zeta|=r} \frac{u(\zeta)}{\zeta - z} d\zeta - \frac{1}{2\pi i} \oint_{|\zeta|=r} \frac{z\overline{f(\zeta)}}{\zeta(\zeta - z)} d\zeta.","['complex-analysis', 'harmonic-functions', 'cauchy-integral-formula']"
83,Inverse Mellin Transform $(ix)^{-s}$,Inverse Mellin Transform,(ix)^{-s},Consider the inverse Mellin transform of the function $(ix)^{-s}$ for $x>0$ . This is: $$ \frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty} (i x)^{-s} ds $$ What does this evaluate to? I believe that if you simply had $x^{-s}$ then the result would be $\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty} x^{-s} ds = \delta(x-1)$ . However what happens in this case where there a factor of $i$ ?,Consider the inverse Mellin transform of the function for . This is: What does this evaluate to? I believe that if you simply had then the result would be . However what happens in this case where there a factor of ?,"(ix)^{-s} x>0 
\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty} (i x)^{-s} ds
 x^{-s} \frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty} x^{-s} ds = \delta(x-1) i","['complex-analysis', 'complex-integration', 'mellin-transform']"
84,Method of steepest descent for $\cos$ integral,Method of steepest descent for  integral,\cos,"I'm looking to do an asymptotic analysis for the following integral (similar to this but not quite the same) $$J(x)=\int_0^1 \cos(x (t^3/3+t))dt.$$ My idea is to write $$J(x)=\Re\int_\Gamma \exp(xi(z^3/3+z))dz$$ where $\Gamma=[0,1]$ . Now, we note that if $f(z)=i(z^3/3+z)$ , then $f'(z)=0$ at $z=\pm i$ and $f''(i)=2i(i)=-2<0$ . Next, we note that $$f(u+iv)=\frac{v (-3 u^2 + v^2 - 3)}{3} + i\frac{ u (u^2 - 3 v^2 + 3)}{3}$$ and hence we expect that the biggest contribution will come from the saddle point $x=i$ along a level curve of the contour curve $\Im f = c $ , and so I'd like to deform the contour $\Gamma$ to somehow take this into account, but I don't know how to proceed. Any hints are helpful, this is especially tricky (to me at least) since the bounds are finite.","I'm looking to do an asymptotic analysis for the following integral (similar to this but not quite the same) My idea is to write where . Now, we note that if , then at and . Next, we note that and hence we expect that the biggest contribution will come from the saddle point along a level curve of the contour curve , and so I'd like to deform the contour to somehow take this into account, but I don't know how to proceed. Any hints are helpful, this is especially tricky (to me at least) since the bounds are finite.","J(x)=\int_0^1 \cos(x (t^3/3+t))dt. J(x)=\Re\int_\Gamma \exp(xi(z^3/3+z))dz \Gamma=[0,1] f(z)=i(z^3/3+z) f'(z)=0 z=\pm i f''(i)=2i(i)=-2<0 f(u+iv)=\frac{v (-3 u^2 + v^2 - 3)}{3} + i\frac{ u (u^2 - 3 v^2 + 3)}{3} x=i \Im f = c  \Gamma","['integration', 'complex-analysis', 'definite-integrals', 'asymptotics', 'contour-integration']"
85,Find the integrals,Find the integrals,,"I have a problem solving those two integrals. $\int_{\partial D} \frac{z^3}{e^{z^2}-1}dz$ , $D=\{z: |z|<4\}$ $\int_0^2 \frac{\sqrt{x(2-x)}}{x+3}dx$ Since I found them in the old complex analysis course under the title ""TRAINING SET FOR RESIDUES AND INTEGRALS"", I believe I should solve them using the residue theorem. As for the first integral, I see that the singularity at $0$ is removable, but we are still left with singularities at $\pm \sqrt{2\pi i}$ and $\pm \sqrt{4\pi i}$ . Unfortunately, I don't know how to find residues at those points. I can Taylor expand $e^{z^2}-1$ around any point, but since I divide by this, I don't see how it helps (or maybe is there any easy way to find a Laurent expansion of 1/f, when we have a Taylor expansion of f?) As for the second one, I'm totally lost. Usually, when I have an integral over a real axis, I find a suitable contour (semi-circle, keyhole) where the integral vanishes over a semicircle etc. Here, however, the integral is over a finite interval, and the numerator is ""big"", so even if I integrate over a semicircle, I don't think the upper part (over the circle) will vanish (one of my ideas was to substitute $x=u^2$ , look at the integral over whole real axis, since the one I'm interested in should be just a real part of that, and integrate over a semicircle - it will be just using a residue theorem with residue at $\sqrt{3}i$ , but I don't think the integral over semicircle will vanish (not mentioning the problems with a branch of a square root...). Any help/techniques would be appreciated.","I have a problem solving those two integrals. , Since I found them in the old complex analysis course under the title ""TRAINING SET FOR RESIDUES AND INTEGRALS"", I believe I should solve them using the residue theorem. As for the first integral, I see that the singularity at is removable, but we are still left with singularities at and . Unfortunately, I don't know how to find residues at those points. I can Taylor expand around any point, but since I divide by this, I don't see how it helps (or maybe is there any easy way to find a Laurent expansion of 1/f, when we have a Taylor expansion of f?) As for the second one, I'm totally lost. Usually, when I have an integral over a real axis, I find a suitable contour (semi-circle, keyhole) where the integral vanishes over a semicircle etc. Here, however, the integral is over a finite interval, and the numerator is ""big"", so even if I integrate over a semicircle, I don't think the upper part (over the circle) will vanish (one of my ideas was to substitute , look at the integral over whole real axis, since the one I'm interested in should be just a real part of that, and integrate over a semicircle - it will be just using a residue theorem with residue at , but I don't think the integral over semicircle will vanish (not mentioning the problems with a branch of a square root...). Any help/techniques would be appreciated.",\int_{\partial D} \frac{z^3}{e^{z^2}-1}dz D=\{z: |z|<4\} \int_0^2 \frac{\sqrt{x(2-x)}}{x+3}dx 0 \pm \sqrt{2\pi i} \pm \sqrt{4\pi i} e^{z^2}-1 x=u^2 \sqrt{3}i,"['integration', 'complex-analysis', 'contour-integration', 'complex-integration']"
86,Integral of $\sin(x^n)$ in terms of sinus and Gamma function. [duplicate],Integral of  in terms of sinus and Gamma function. [duplicate],\sin(x^n),"This question already has answers here : Evaluation of a Fresnel type integral. (2 answers) Closed last year . Prove that (for $n>1$ ) \begin{equation}     \int_{0}^{+\infty} \sin(x^n)dx=\sin\left(\frac{\pi}{2n}\right)\Gamma\left(\frac{n+1}{n}\right). \end{equation} I tried to prove this using a similar argument for Fresnel's integral, but I don't see what I'm doing wrong. Define $\gamma_1:[0,R]\rightarrow\mathbb{C}, \gamma_1(t)=t$ , $\gamma_2:[0,\pi/(2n)]\rightarrow\mathbb{C}, \gamma_2(t)=Re^{it}$ and $\gamma_3:[R, 0]\rightarrow\mathbb{C}, \gamma_3(t)=te^{i\pi/(2n)}.$ For Local Theorem of Cauchy, if $f(z)=e^{iz^n}$ , then $$\int_{\gamma_1+\gamma_2+\gamma_3} f=0.$$ Now, studying each integral alone, we have for $\gamma_1$ , $$\int_{\gamma_1}f=\int_{0}^{R}e^{it^n}dt\rightarrow\int_{0}^{+\infty}\cos(t^n)dt+i\int_{0}^{+\infty}\sin(t^n)dt.$$ For $\gamma_2$ , $$\int_{\gamma_2}f=\int_{0}^{\pi/(2n)}e^{i(Re^{it})^n} Rie^{it}dt=Ri\int_{0}^{\pi/(2n)}e^{iR^n(cos(nt)+isin(nt))}e^{it}dt=Ri\int_{0}^{\pi/(2n)}e^{-tR^ncos(nt)}e^{-tiR^nsin(nt))}dt,$$ second exponencial, inside integral, have modulus 1, so if R goes to infinity, integral over $\gamma_2$ is zero because $Re^{-tR^ncos(nt)}\rightarrow0$ . For $\gamma_3$ , $$\int_{\gamma_3}f=\int_{R}^{0}e^{i(te^{i\pi/(2n)})^n}e^{i\pi/(2n)}dt=-e^{i\pi/(2n)}\int_{0}^{R}e^{it^ne^{i\pi/2}}dt=-e^{i\pi/(2n)}\int_{0}^{R}e^{-t^n}dt.$$ Then taking imaginary part and R going to infinity, $$\int_{0}^{+\infty} \sin(t^n)dt=\sin\left(\frac{\pi}{2n}\right)\int_{0}^{+\infty} e^{-t^n}dt.$$ Where is my mistake? Any help? Thanks.","This question already has answers here : Evaluation of a Fresnel type integral. (2 answers) Closed last year . Prove that (for ) I tried to prove this using a similar argument for Fresnel's integral, but I don't see what I'm doing wrong. Define , and For Local Theorem of Cauchy, if , then Now, studying each integral alone, we have for , For , second exponencial, inside integral, have modulus 1, so if R goes to infinity, integral over is zero because . For , Then taking imaginary part and R going to infinity, Where is my mistake? Any help? Thanks.","n>1 \begin{equation}
    \int_{0}^{+\infty} \sin(x^n)dx=\sin\left(\frac{\pi}{2n}\right)\Gamma\left(\frac{n+1}{n}\right).
\end{equation} \gamma_1:[0,R]\rightarrow\mathbb{C}, \gamma_1(t)=t \gamma_2:[0,\pi/(2n)]\rightarrow\mathbb{C}, \gamma_2(t)=Re^{it} \gamma_3:[R, 0]\rightarrow\mathbb{C}, \gamma_3(t)=te^{i\pi/(2n)}. f(z)=e^{iz^n} \int_{\gamma_1+\gamma_2+\gamma_3} f=0. \gamma_1 \int_{\gamma_1}f=\int_{0}^{R}e^{it^n}dt\rightarrow\int_{0}^{+\infty}\cos(t^n)dt+i\int_{0}^{+\infty}\sin(t^n)dt. \gamma_2 \int_{\gamma_2}f=\int_{0}^{\pi/(2n)}e^{i(Re^{it})^n} Rie^{it}dt=Ri\int_{0}^{\pi/(2n)}e^{iR^n(cos(nt)+isin(nt))}e^{it}dt=Ri\int_{0}^{\pi/(2n)}e^{-tR^ncos(nt)}e^{-tiR^nsin(nt))}dt, \gamma_2 Re^{-tR^ncos(nt)}\rightarrow0 \gamma_3 \int_{\gamma_3}f=\int_{R}^{0}e^{i(te^{i\pi/(2n)})^n}e^{i\pi/(2n)}dt=-e^{i\pi/(2n)}\int_{0}^{R}e^{it^ne^{i\pi/2}}dt=-e^{i\pi/(2n)}\int_{0}^{R}e^{-t^n}dt. \int_{0}^{+\infty} \sin(t^n)dt=\sin\left(\frac{\pi}{2n}\right)\int_{0}^{+\infty} e^{-t^n}dt.","['complex-analysis', 'improper-integrals']"
87,Ash - Complex Variables - Proof of Maximum Principle,Ash - Complex Variables - Proof of Maximum Principle,,"I am self studying Ash & Novinger's Complex Variables. In subsection 2.4.12 of the book , the authors are trying to prove that if $f$ is analytic on an open connected set $\Omega$ and $\lvert f \rvert$ assumes a local maximum at some point in $\Omega$ then $f$ is constant in $\Omega$ . The outline of the proof is as follows: Suppose that $f$ assumes a local maximum at $z_0 \in \Omega$ . If $f(z_0)=0$ then $f(z)=0$ on some neighbourhood $B(z_0, \delta)$ of $z_0$ and identity theorem implies $f\equiv 0$ on $\Omega$ . So, the authors assume $f(z_0)\ne 0$ . By the Cauchy's Integral formula, we have that \begin{align*} f(z_0)=\frac{1}{2\pi}\int_0^{2\pi} f(z_0 + re^{it})\,dt \leadsto 1=\frac{1}{2\pi}\int_0^{2\pi} \frac{f(z_0 + re^{it})}{f(z_0)}\,dt \end{align*} for any $r<\delta$ . Using this, the authors then show that $\left\lvert f(z)/f(z_0) \right\rvert =1$ on $B(z_0, \delta)$ . They claim that $\Re \left( f(z)/f(z_0) \right) =1$ on $B(z_0, \delta)$ but do not prove it. I am stuck here. Here's my attempt: Let $r < \delta$ . Then we have that $1=\frac{1}{2\pi}\int_0^{2\pi} \frac{f(z_0 + re^{it})}{f(z_0)}\,dt$ . Taking real part both sides, we get $1 = \frac{1}{2\pi} \Re \left( \int_0^{2\pi} \frac{f(z_0 + re^{it})}{f(z_0)}\,dt \right) = \frac{1}{2\pi} \int_0^{2\pi} \Re\left(\frac{f(z_0 + re^{it})}{f(z_0)} \right) \, dt \le \frac{1}{2\pi} \int_0^{2\pi} \left\lvert \frac{f(z_0 +re^{it})}{f(z_0)} \right\rvert dt \le 1$ . Note that the last inequality is due to the fact that $\lvert f(z_0 + re^{it})\rvert \le \lvert f(z_0) \rvert$ for all $t\in [0,2\pi]$ . If it happened that $\Re\left(\frac{f(z_0 + re^{it})}{f(z_0)} \right) \ge 1$ for each $t\in [0,2\pi]$ then I could have concluded that $\Re\left(\frac{f(z)}{f(z_0)} \right) =1$ for each $z \in B(z_0, \delta)$ . But this may not hold! Any hints would be appreciated! EDIT: Following this up from this answer , we have that from my attempt that $\frac{1}{2\pi}\int_{0}^{2\pi}\underbrace{\left[ \left\lvert \frac{f(z_0 + re^{it})}{f(z_0)} \right\rvert - \Re \left( \frac{f(z_0 + re^{it})}{f(z_0)} \right) \right]}_{\ge 0} \, dt = 0$ . By using continuity, we can then complete the proof.","I am self studying Ash & Novinger's Complex Variables. In subsection 2.4.12 of the book , the authors are trying to prove that if is analytic on an open connected set and assumes a local maximum at some point in then is constant in . The outline of the proof is as follows: Suppose that assumes a local maximum at . If then on some neighbourhood of and identity theorem implies on . So, the authors assume . By the Cauchy's Integral formula, we have that for any . Using this, the authors then show that on . They claim that on but do not prove it. I am stuck here. Here's my attempt: Let . Then we have that . Taking real part both sides, we get . Note that the last inequality is due to the fact that for all . If it happened that for each then I could have concluded that for each . But this may not hold! Any hints would be appreciated! EDIT: Following this up from this answer , we have that from my attempt that . By using continuity, we can then complete the proof.","f \Omega \lvert f \rvert \Omega f \Omega f z_0 \in \Omega f(z_0)=0 f(z)=0 B(z_0, \delta) z_0 f\equiv 0 \Omega f(z_0)\ne 0 \begin{align*}
f(z_0)=\frac{1}{2\pi}\int_0^{2\pi} f(z_0 + re^{it})\,dt \leadsto 1=\frac{1}{2\pi}\int_0^{2\pi} \frac{f(z_0 + re^{it})}{f(z_0)}\,dt
\end{align*} r<\delta \left\lvert f(z)/f(z_0) \right\rvert =1 B(z_0, \delta) \Re \left( f(z)/f(z_0) \right) =1 B(z_0, \delta) r < \delta 1=\frac{1}{2\pi}\int_0^{2\pi} \frac{f(z_0 + re^{it})}{f(z_0)}\,dt 1 = \frac{1}{2\pi} \Re \left( \int_0^{2\pi} \frac{f(z_0 + re^{it})}{f(z_0)}\,dt \right) = \frac{1}{2\pi} \int_0^{2\pi} \Re\left(\frac{f(z_0 + re^{it})}{f(z_0)} \right) \, dt \le \frac{1}{2\pi} \int_0^{2\pi} \left\lvert \frac{f(z_0 +re^{it})}{f(z_0)} \right\rvert dt \le 1 \lvert f(z_0 + re^{it})\rvert \le \lvert f(z_0) \rvert t\in [0,2\pi] \Re\left(\frac{f(z_0 + re^{it})}{f(z_0)} \right) \ge 1 t\in [0,2\pi] \Re\left(\frac{f(z)}{f(z_0)} \right) =1 z \in B(z_0, \delta) \frac{1}{2\pi}\int_{0}^{2\pi}\underbrace{\left[ \left\lvert \frac{f(z_0 + re^{it})}{f(z_0)} \right\rvert - \Re \left( \frac{f(z_0 + re^{it})}{f(z_0)} \right) \right]}_{\ge 0} \, dt = 0","['complex-analysis', 'proof-explanation']"
88,Closed form expression for $\psi_{e^{\pi}}^{(3)}(1-i)$,Closed form expression for,\psi_{e^{\pi}}^{(3)}(1-i),"Let $\psi_q(z)$ be the q-DiGamma function defined for a real variable $\Re(z)>0$ as $$\psi_q(z)=\frac{1}{\Gamma_q(z)}\frac{\partial}{\partial z} (\Gamma_q(z))$$ where $\Gamma_q(z)$ is the q-Gamma function defined as $$\Gamma_q(z)=(1-q)^{1-z}\prod_{n=0}^{\infty}\frac{1-q^{n+1}}{1-q^{n+z}}$$ Question I am looking for a closed form for $$\psi_{e^{\pi}}^{(3)}(1-i)$$ where $i=\sqrt{-1}$ Here is a beautiful answer for calculating $$\psi_{e^{\pi}}^{(3)}(1)$$ Wolfram Alpha gives the expansion at $x=\infty$ : $$\psi_x^{(3)}(1)=\ln^4(x)\left(x^{-1}+9x^{-2}+\dots\right)$$ and these match Oeis A $001158$ with divisor $\sigma_v(n)$ and various theta functions after plugging the sum back in here . Use $\vartheta_v(0,x)=\vartheta_v(x)$ : $$\psi_x^{(3)}(1)=\ln^4(x)\sum_{n=1}^\infty\frac{\sigma_3(n)}{x^n}=\frac{\ln^4(x)}{480}\left(\vartheta_2\left(\frac1{\sqrt x}\right)^8+ \vartheta_3\left(\frac1{\sqrt x}\right)^8+ \vartheta_4\left(\frac1{\sqrt x}\right)^8-2\right)$$ Therefore: $$\psi_{e^\pi}^{(3)}(1)=\frac{\pi^4}{480}\left(\vartheta_2^8\left(e^{-\frac\pi2}\right)+ \vartheta_3^8\left(e^{-\frac\pi2}\right)+ \vartheta_4^8\left(e^{-\frac\pi2}\right)-2\right)$$ Clicking “more digits” here shows a smaller error each time implying the result is true. Now use Dedekind $\eta(z)$ identities for $\vartheta_v\left(e^{-\frac\pi2}\right)$ when $v=2$ , $v=3$ , and $v=4$ $$\psi_{e^\pi}^{(3)}(1)= \frac{\pi^4}{480}\left(\left(2\frac{\eta^2(i)}{\eta\left(\frac i2\right)}\right)^8+\left(\frac{\eta^5\left(\frac i2\right)}{\eta^2\left(i\right)\eta^2\left(\frac i4\right)}\right)^8+\left(\frac{\eta^2\left(\frac i4\right)}{\eta\left(\frac i2\right)}\right)^8-2\right)$$ Using special values in terms of $\Gamma\left(\frac14\right)$ : $\eta\left(\frac i4\right)=2\eta(4i)=\frac{\sqrt[4]{\sqrt2-1} \Gamma\left(\frac14\right)}{2^\frac{13}{16}\pi^\frac34},\eta\left(\frac i2\right)=\frac{\Gamma\left(\frac14\right)}{2^\frac 78\pi^\frac34},\eta(i)=\frac{\Gamma\left(\frac14\right)}{2\pi^\frac34}$ Finally, substitute and have a form in terms of $\Gamma\left(\frac14\right)$ which has no elementary closed form . Therefore: $$\boxed{\psi_{e^\pi}^{(3)}(1)=\frac{11\Gamma\left(\frac14\right)^8}{5120\pi^2}-\frac{\pi^4}{240}}$$ shown here If anyone could please solve this question by hand or mathematica or sage math. I would be highly indebted to you all.","Let be the q-DiGamma function defined for a real variable as where is the q-Gamma function defined as Question I am looking for a closed form for where Here is a beautiful answer for calculating Wolfram Alpha gives the expansion at : and these match Oeis A with divisor and various theta functions after plugging the sum back in here . Use : Therefore: Clicking “more digits” here shows a smaller error each time implying the result is true. Now use Dedekind identities for when , , and Using special values in terms of : Finally, substitute and have a form in terms of which has no elementary closed form . Therefore: shown here If anyone could please solve this question by hand or mathematica or sage math. I would be highly indebted to you all.","\psi_q(z) \Re(z)>0 \psi_q(z)=\frac{1}{\Gamma_q(z)}\frac{\partial}{\partial z} (\Gamma_q(z)) \Gamma_q(z) \Gamma_q(z)=(1-q)^{1-z}\prod_{n=0}^{\infty}\frac{1-q^{n+1}}{1-q^{n+z}} \psi_{e^{\pi}}^{(3)}(1-i) i=\sqrt{-1} \psi_{e^{\pi}}^{(3)}(1) x=\infty \psi_x^{(3)}(1)=\ln^4(x)\left(x^{-1}+9x^{-2}+\dots\right) 001158 \sigma_v(n) \vartheta_v(0,x)=\vartheta_v(x) \psi_x^{(3)}(1)=\ln^4(x)\sum_{n=1}^\infty\frac{\sigma_3(n)}{x^n}=\frac{\ln^4(x)}{480}\left(\vartheta_2\left(\frac1{\sqrt x}\right)^8+ \vartheta_3\left(\frac1{\sqrt x}\right)^8+ \vartheta_4\left(\frac1{\sqrt x}\right)^8-2\right) \psi_{e^\pi}^{(3)}(1)=\frac{\pi^4}{480}\left(\vartheta_2^8\left(e^{-\frac\pi2}\right)+ \vartheta_3^8\left(e^{-\frac\pi2}\right)+ \vartheta_4^8\left(e^{-\frac\pi2}\right)-2\right) \eta(z) \vartheta_v\left(e^{-\frac\pi2}\right) v=2 v=3 v=4 \psi_{e^\pi}^{(3)}(1)= \frac{\pi^4}{480}\left(\left(2\frac{\eta^2(i)}{\eta\left(\frac i2\right)}\right)^8+\left(\frac{\eta^5\left(\frac i2\right)}{\eta^2\left(i\right)\eta^2\left(\frac i4\right)}\right)^8+\left(\frac{\eta^2\left(\frac i4\right)}{\eta\left(\frac i2\right)}\right)^8-2\right) \Gamma\left(\frac14\right) \eta\left(\frac i4\right)=2\eta(4i)=\frac{\sqrt[4]{\sqrt2-1} \Gamma\left(\frac14\right)}{2^\frac{13}{16}\pi^\frac34},\eta\left(\frac i2\right)=\frac{\Gamma\left(\frac14\right)}{2^\frac 78\pi^\frac34},\eta(i)=\frac{\Gamma\left(\frac14\right)}{2\pi^\frac34} \Gamma\left(\frac14\right) \boxed{\psi_{e^\pi}^{(3)}(1)=\frac{11\Gamma\left(\frac14\right)^8}{5120\pi^2}-\frac{\pi^4}{240}}","['complex-analysis', 'number-theory', 'mathematica', 'digamma-function', 'polygamma']"
89,When will $a \pm b\sqrt{c}$ will have a nth root of the same form?,When will  will have a nth root of the same form?,a \pm b\sqrt{c},"So recently I had a homework problem for my abstract algebra class which I solved where I had to prove $\sqrt[3]{8+\sqrt{325}} +\sqrt[3]{8-\sqrt{325}}=3$ .  It was simple enough, all one has to do is cube it and after a bit of algebra note the cubic polynomial is relatively easy to factor. I did not do this though, instead my approach was a bit more complicated (I missed the simple approach).  I made an educated guess that the form of the cube root of $8 \pm \sqrt{325}$ would be $m \pm n\sqrt{13}$ .  This was because of at least a couple of things I had noted.  Similar already solved problems in the book had solutions essentially in this form.  Moreover, I knew I needed it to simplify to a rational number so I really wanted the squares to cancel out, and intuitively the form just made sense to me. Yet while my intuition got me the right answer, I really feel like something deeper is lurking here.  Part of me suspects that its possible to prove with some conditions imposed on a,b,c that the nth root of $a \pm b\sqrt{c}$ must also be of that form, though I suspect some weirdness potentially (and I am unsure how to exactly state this).  Though, a large part of me is very unsure.  Why should I even suspect roots to exist in that field, $\mathbb Q[\sqrt{13}]$ is obviously not algebraically closed since -1 doesn't have a root. So, with $a,b,c \in \mathbb Q$ when will $a \pm b\sqrt{c}$ have an nth root of the same form?","So recently I had a homework problem for my abstract algebra class which I solved where I had to prove .  It was simple enough, all one has to do is cube it and after a bit of algebra note the cubic polynomial is relatively easy to factor. I did not do this though, instead my approach was a bit more complicated (I missed the simple approach).  I made an educated guess that the form of the cube root of would be .  This was because of at least a couple of things I had noted.  Similar already solved problems in the book had solutions essentially in this form.  Moreover, I knew I needed it to simplify to a rational number so I really wanted the squares to cancel out, and intuitively the form just made sense to me. Yet while my intuition got me the right answer, I really feel like something deeper is lurking here.  Part of me suspects that its possible to prove with some conditions imposed on a,b,c that the nth root of must also be of that form, though I suspect some weirdness potentially (and I am unsure how to exactly state this).  Though, a large part of me is very unsure.  Why should I even suspect roots to exist in that field, is obviously not algebraically closed since -1 doesn't have a root. So, with when will have an nth root of the same form?","\sqrt[3]{8+\sqrt{325}} +\sqrt[3]{8-\sqrt{325}}=3 8 \pm \sqrt{325} m \pm n\sqrt{13} a \pm b\sqrt{c} \mathbb Q[\sqrt{13}] a,b,c \in \mathbb Q a \pm b\sqrt{c}","['abstract-algebra', 'complex-analysis', 'number-theory']"
90,Prove $f(z) = cz$ for all complex numbers and some $c$,Prove  for all complex numbers and some,f(z) = cz c,"Suppose $f$ is entire and $|f(z)|\geqslant |z|$ $\forall z \in \mathbb{C}$ , prove there exists $c \in \mathbb{C} $ such that $f(z) = cz $ $\forall z \in \mathbb{C}$ . I want to use Liouville’s theorem for $\frac{z}{f(z)}$ but I don’t know what to do when $z = 0$ and $f(z) \neq 0$ .","Suppose is entire and , prove there exists such that . I want to use Liouville’s theorem for but I don’t know what to do when and .",f |f(z)|\geqslant |z| \forall z \in \mathbb{C} c \in \mathbb{C}  f(z) = cz  \forall z \in \mathbb{C} \frac{z}{f(z)} z = 0 f(z) \neq 0,"['complex-analysis', 'constants']"
91,what is the integral $\int_{0}^{\infty}\frac{1}{(1+x^\alpha)^k} \ dx$ equal to,what is the integral  equal to,\int_{0}^{\infty}\frac{1}{(1+x^\alpha)^k} \ dx,"I'm trying to evaluate the following integral but I'm stuck. $$I(\alpha,k)=\int_{0}^{\infty}\frac{1}{(1+x^\alpha)^k} \ dx$$ Using complex analysis I know that for $k=1$ it's equal to $$\frac{\pi}{\alpha\sin(\frac{\pi}{\alpha})}$$ (I used a contour shaped like a circle sector around the pole at $z=\exp(\frac{i\pi}{\alpha})$ and let the radius $R$ approach infinity) I however don't know how to evaluate it for a general $k$ as it generates a residue of a pole of order $k$ which would require a $(k-1)$ -th derivative that I don't know how to evaluate. I tried putting in some numbers in WolframAlpha and it I got the pattern that $$I(\alpha,k) = \frac{\Gamma(\frac{\alpha+1}{\alpha})\Gamma(k-\frac{1}{\alpha})}{\Gamma(k)}, \ \ k>\frac{1}{\alpha}$$ which is correct for the $k=1$ case, but I have no idea why it is the case. (The formula above is also defined fo fractional $k$ which I originally didn't consider to avoid nasty branch cuts)","I'm trying to evaluate the following integral but I'm stuck. Using complex analysis I know that for it's equal to (I used a contour shaped like a circle sector around the pole at and let the radius approach infinity) I however don't know how to evaluate it for a general as it generates a residue of a pole of order which would require a -th derivative that I don't know how to evaluate. I tried putting in some numbers in WolframAlpha and it I got the pattern that which is correct for the case, but I have no idea why it is the case. (The formula above is also defined fo fractional which I originally didn't consider to avoid nasty branch cuts)","I(\alpha,k)=\int_{0}^{\infty}\frac{1}{(1+x^\alpha)^k} \ dx k=1 \frac{\pi}{\alpha\sin(\frac{\pi}{\alpha})} z=\exp(\frac{i\pi}{\alpha}) R k k (k-1) I(\alpha,k) = \frac{\Gamma(\frac{\alpha+1}{\alpha})\Gamma(k-\frac{1}{\alpha})}{\Gamma(k)}, \ \ k>\frac{1}{\alpha} k=1 k","['integration', 'complex-analysis', 'definite-integrals', 'contour-integration', 'closed-form']"
92,Residue Theorem for Real Integral: Where did I go Wrong?,Residue Theorem for Real Integral: Where did I go Wrong?,,"So the integral is $$\int_{0}^{\infty} \frac{\sqrt{x}}{x^2 + 4x + 5} d x.$$ I did keyhole integration avoiding the positive real axis. Let this be $C$ . I defined the integrand as a complex valued function, and found that the poles are at $-2-i$ and $-2+i$ . Computing the residues, we have $$Res(f, -2+i) = -\frac{\sqrt{-2-i}}{2i}$$ and $$Res(f, -2+i) = \frac{\sqrt{-2+i}}{2i}.$$ So then $\int_C f(z) = 2\pi i (\frac{\sqrt{-2+i}}{2i}-\frac{\sqrt{-2-i}}{2i}) = \pi (\sqrt{-2+i}-\sqrt{-2-i}).$ Now, after doing the keyhole part, the integral over the large circle and the small circle goes to 0 and so the only thing left are the integral over the line segment connecting the small circle to the large circle at angle $\epsilon$ and the integral over the line segment connecting the large circle to the small circle at angle $2\pi - \epsilon$ . Letting the radius of the small circle go to 0 and the radius of the large circle to infinity, we find that the two integrals are equal and $$\int_C f(z) dz = 2\int_{0}^{\infty} f(x) dx.$$ But $$\int_{0}^{\infty} f(x) dx = \frac{\pi}{2} (\sqrt{-2+i}-\sqrt{-2-i}),$$ which is an imaginary number. I've been trying to find my mistake but I can't seem to. Where did I go wrong? Wolfram tells me that the answer is $\sqrt{\frac{1}{2}(\sqrt{5} - 2)}\pi$ . My guess is that it's somewhere in the residue theorem step... Please help!","So the integral is I did keyhole integration avoiding the positive real axis. Let this be . I defined the integrand as a complex valued function, and found that the poles are at and . Computing the residues, we have and So then Now, after doing the keyhole part, the integral over the large circle and the small circle goes to 0 and so the only thing left are the integral over the line segment connecting the small circle to the large circle at angle and the integral over the line segment connecting the large circle to the small circle at angle . Letting the radius of the small circle go to 0 and the radius of the large circle to infinity, we find that the two integrals are equal and But which is an imaginary number. I've been trying to find my mistake but I can't seem to. Where did I go wrong? Wolfram tells me that the answer is . My guess is that it's somewhere in the residue theorem step... Please help!","\int_{0}^{\infty} \frac{\sqrt{x}}{x^2 + 4x + 5} d x. C -2-i -2+i Res(f, -2+i) = -\frac{\sqrt{-2-i}}{2i} Res(f, -2+i) = \frac{\sqrt{-2+i}}{2i}. \int_C f(z) = 2\pi i (\frac{\sqrt{-2+i}}{2i}-\frac{\sqrt{-2-i}}{2i}) = \pi (\sqrt{-2+i}-\sqrt{-2-i}). \epsilon 2\pi - \epsilon \int_C f(z) dz = 2\int_{0}^{\infty} f(x) dx. \int_{0}^{\infty} f(x) dx = \frac{\pi}{2} (\sqrt{-2+i}-\sqrt{-2-i}), \sqrt{\frac{1}{2}(\sqrt{5} - 2)}\pi","['calculus', 'integration', 'complex-analysis', 'residue-calculus']"
93,Show that the identity $\int_0^\infty\sin(t)t^{z-1}\ dt = \Gamma(z)\sin\left(\pi{z\over 2}\right)$ holds on $-1<\operatorname{Re}(z)<1$,Show that the identity  holds on,\int_0^\infty\sin(t)t^{z-1}\ dt = \Gamma(z)\sin\left(\pi{z\over 2}\right) -1<\operatorname{Re}(z)<1,"The question is from Stein complex analysis 6.10(b) (b) Show that the following identity $$\int_0^\infty\sin(t)t^{z-1}\ dt = \Gamma(z)\sin\left(\pi{z\over 2}\right)\quad 0<\operatorname{Re}z<1$$ is valid in the larger strip $-1<\operatorname{Re}z<1$ . Since $\Gamma$ has a meromorphic continuation on $\Bbb C$ with simple poles at $-\Bbb N\cup\{0\}$ and $\sin$ has a simple zero at $0$ , I can conclude that the integral $$\int_0^\infty\sin(t)t^{z-1}\ dt$$ has an analytic continuation on $-1<\operatorname{Re}z<1$ since the RHS of the above identity does. But this does not show the identity holds on $-1<\operatorname{Re}z<1$ right? I think I need to show the LHS is also holomorphic on $-1<\operatorname{Re}z<1$ then by identity theorem I can say the identity holds. Why the integral holomorphic on $-1<\operatorname{Re}z<1$ ?","The question is from Stein complex analysis 6.10(b) (b) Show that the following identity is valid in the larger strip . Since has a meromorphic continuation on with simple poles at and has a simple zero at , I can conclude that the integral has an analytic continuation on since the RHS of the above identity does. But this does not show the identity holds on right? I think I need to show the LHS is also holomorphic on then by identity theorem I can say the identity holds. Why the integral holomorphic on ?",\int_0^\infty\sin(t)t^{z-1}\ dt = \Gamma(z)\sin\left(\pi{z\over 2}\right)\quad 0<\operatorname{Re}z<1 -1<\operatorname{Re}z<1 \Gamma \Bbb C -\Bbb N\cup\{0\} \sin 0 \int_0^\infty\sin(t)t^{z-1}\ dt -1<\operatorname{Re}z<1 -1<\operatorname{Re}z<1 -1<\operatorname{Re}z<1 -1<\operatorname{Re}z<1,"['complex-analysis', 'gamma-function', 'analytic-continuation']"
94,Question about Taylor series expansion in complex numbers involving branch cut,Question about Taylor series expansion in complex numbers involving branch cut,,"I want to consider a Taylor series expansion over complex numbers of $(i + z)^{-1/2}$ around $0$ . Using the usual formula I get $$ (i + z)^{-1/2} = i^{-1/2} - \frac{1}{2} i^{-3/2} z + ....  $$ I can see that the series converge around $|z| < 1$ . When I was computing this, I just used the formula. But then I realized $i^{-m/2}$ is apriori not well defined since there are more than one choice for this... so the above formula doesn't make sense as it is. How can I fix this issue? Choosing arbitrary choice of $i^{-m/2}$ for each $m$ doesn't sound a good idea.","I want to consider a Taylor series expansion over complex numbers of around . Using the usual formula I get I can see that the series converge around . When I was computing this, I just used the formula. But then I realized is apriori not well defined since there are more than one choice for this... so the above formula doesn't make sense as it is. How can I fix this issue? Choosing arbitrary choice of for each doesn't sound a good idea.","(i + z)^{-1/2} 0 
(i + z)^{-1/2} = i^{-1/2} - \frac{1}{2} i^{-3/2} z + .... 
 |z| < 1 i^{-m/2} i^{-m/2} m","['complex-analysis', 'taylor-expansion', 'power-series']"
95,`Conformal class' in Riemannian geometry vs Complex Analysis,`Conformal class' in Riemannian geometry vs Complex Analysis,,"Recently I found myself a bit confused about the definition of conformality. In Riemannian geometry, we say that two metrics on a manifold $M$ , $g$ and $h$ are in the same conformal class if there exists a function $\mu:M\rightarrow\mathbb{R}$ such that, \begin{equation} g = e^\mu h \tag{$\ast$}. \end{equation} The point of confusion for me was this: the uniformization theorem says that there is only one conformal class on the sphere $\mathbb{S}^2$ . This, however, does not mean that two Riemannian metrics on a sphere can be related like ( $\ast$ ), but that there is a diffeomorphism $\varphi:\mathbb{S}^2\rightarrow\mathbb{S}^2$ such that $\varphi^*g=e^\mu h$ . Why is there a difference between the definitions of conformality in complex analysis (as in the Uniformization theorem) and Riemannian geometry? What does conformal class mean in complex analysis (is it different from the definition for Riemannian metrics)?","Recently I found myself a bit confused about the definition of conformality. In Riemannian geometry, we say that two metrics on a manifold , and are in the same conformal class if there exists a function such that, The point of confusion for me was this: the uniformization theorem says that there is only one conformal class on the sphere . This, however, does not mean that two Riemannian metrics on a sphere can be related like ( ), but that there is a diffeomorphism such that . Why is there a difference between the definitions of conformality in complex analysis (as in the Uniformization theorem) and Riemannian geometry? What does conformal class mean in complex analysis (is it different from the definition for Riemannian metrics)?","M g h \mu:M\rightarrow\mathbb{R} \begin{equation}
g = e^\mu h \tag{\ast}.
\end{equation} \mathbb{S}^2 \ast \varphi:\mathbb{S}^2\rightarrow\mathbb{S}^2 \varphi^*g=e^\mu h","['complex-analysis', 'differential-geometry', 'riemannian-geometry', 'conformal-geometry']"
96,Prove (by definition) that $\lim _{z\to 1+i}\left(\frac{1}{z^2+1}\right)=\frac{1}{2i+1}$,Prove (by definition) that,\lim _{z\to 1+i}\left(\frac{1}{z^2+1}\right)=\frac{1}{2i+1},"How can I take this expression $$\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}$$ to the form $z-(1+i)$ ? I must use the definition of limit to prove this result. That is, use $\delta$ and $\epsilon$ . What I have done so far is to raise the definition: $$\lim _{z\to 1+i}\left(\frac{1}{z^2+1}\right)=\frac{1}{2i+1}\Leftrightarrow[\forall\epsilon>0,\exists\delta>0/\forall z\in\mathbb{C}:(0<|z-(1+i)|<\delta\Rightarrow|\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}|<\epsilon)]$$ I must prove: $$\left|\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}\right|<\epsilon$$ as long as $0<|z-(1+i)|<\delta$ We start from \begin{align} \left|\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}\right|&=\left|\frac{1+2i-(z^2+1)}{(z^2+1)(2i+1)}\right|\\ &=\left|\frac{2i-z^2}{(z^2+1)(2i+1)}\right|\\ &=\left|\frac{(2i-z^2)(1-2i)}{(z^2+1)(2i+1)(1-2i)}\right|\\ &=\left|\frac{2i+4+i(2z^2+2)}{5(z^2+1)}\right|. \end{align} But I still don't get the expression I need.","How can I take this expression to the form ? I must use the definition of limit to prove this result. That is, use and . What I have done so far is to raise the definition: I must prove: as long as We start from But I still don't get the expression I need.","\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1} z-(1+i) \delta \epsilon \lim _{z\to 1+i}\left(\frac{1}{z^2+1}\right)=\frac{1}{2i+1}\Leftrightarrow[\forall\epsilon>0,\exists\delta>0/\forall z\in\mathbb{C}:(0<|z-(1+i)|<\delta\Rightarrow|\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}|<\epsilon)] \left|\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}\right|<\epsilon 0<|z-(1+i)|<\delta \begin{align}
\left|\left(\frac{1}{z^2+1}\right)-\frac{1}{2i+1}\right|&=\left|\frac{1+2i-(z^2+1)}{(z^2+1)(2i+1)}\right|\\
&=\left|\frac{2i-z^2}{(z^2+1)(2i+1)}\right|\\
&=\left|\frac{(2i-z^2)(1-2i)}{(z^2+1)(2i+1)(1-2i)}\right|\\
&=\left|\frac{2i+4+i(2z^2+2)}{5(z^2+1)}\right|.
\end{align}","['complex-analysis', 'limits', 'epsilon-delta']"
97,Integrals with complex exponents,Integrals with complex exponents,,"My text book says that the solution to $$\int_{-1}^{-1/2} -e^{-i \omega t} dt + \int_{1/2}^{1} e^{-i \omega t} dt$$ is $$\frac{2}{\omega} ( \sin(\omega)  – \sin (\frac{\omega}{2}))$$ but I can not see how to arrive at that. What I get when solving the integrals is : $$\left[\frac{e^{-i \omega t}}{i \omega}\right]_{t=-1}^{-1/2} + \left[\frac{e^{-i \omega t}}{-i \omega}\right]_{t=1/2}^{1}$$ which continues into $$\frac{e^\frac{i \omega}{2}}{i \omega}  – \frac{e^{i \omega}}{i \omega}  + \frac{e^{-i \omega}}{-i \omega}  – \frac{e^\frac{-i \omega}{2}}{-i \omega}$$ Reversing the sign of the first two components in this last line would give the correct result using Euler’s identity, but I can not find a justification for that?","My text book says that the solution to is but I can not see how to arrive at that. What I get when solving the integrals is : which continues into Reversing the sign of the first two components in this last line would give the correct result using Euler’s identity, but I can not find a justification for that?","\int_{-1}^{-1/2} -e^{-i \omega t} dt + \int_{1/2}^{1} e^{-i \omega t} dt \frac{2}{\omega} ( \sin(\omega)  – \sin (\frac{\omega}{2})) \left[\frac{e^{-i \omega t}}{i \omega}\right]_{t=-1}^{-1/2} + \left[\frac{e^{-i \omega t}}{-i \omega}\right]_{t=1/2}^{1} \frac{e^\frac{i \omega}{2}}{i \omega} 
– \frac{e^{i \omega}}{i \omega} 
+ \frac{e^{-i \omega}}{-i \omega} 
– \frac{e^\frac{-i \omega}{2}}{-i \omega}","['integration', 'complex-analysis']"
98,Folland 2.22 absolute value of Lebesgue integral less than integral of absolute value,Folland 2.22 absolute value of Lebesgue integral less than integral of absolute value,,"I have been learning real analysis but I am a bit shaky with complex numbers. In the following proposition, Folland writes $|\int f|=\overline{\operatorname{sgn}(\int f)}\int f$ ? Why is this true and what is the motivation for doing this? I understand that in the real numbers, $x=\operatorname{sgn}(x)|x|$ ? I could understand then getting $|x|=\frac{1}{\operatorname{sgn}(x)}x$ . However why does the above hold in the complex numbers using modulus instead of absolute value? EDIT: One more question, why is it that $\int \alpha f$ is real?","I have been learning real analysis but I am a bit shaky with complex numbers. In the following proposition, Folland writes ? Why is this true and what is the motivation for doing this? I understand that in the real numbers, ? I could understand then getting . However why does the above hold in the complex numbers using modulus instead of absolute value? EDIT: One more question, why is it that is real?",|\int f|=\overline{\operatorname{sgn}(\int f)}\int f x=\operatorname{sgn}(x)|x| |x|=\frac{1}{\operatorname{sgn}(x)}x \int \alpha f,"['real-analysis', 'complex-analysis', 'measure-theory', 'lebesgue-integral']"
99,Doubt in application of Cauchy's Residue Theorem in the proof of Prime Number Theorem,Doubt in application of Cauchy's Residue Theorem in the proof of Prime Number Theorem,,"I have been studying the proof of Prime Number Theorem as outlined in the book Introduction to Analytic Number Theory by Apostol and I came across the following lemma : In the proof of this lemma, the author takes two different contours for $u>1$ and $0<u\leq 1$ respectively and tries to show the required result. Notice that the function has poles at integers $n = 0,-1,\cdots,-k$ . The case for $u>1$ is a straightforward application of Cauchy's Integral Theorem but I am having trouble understanding the case for $0<u\leq 1$ . Here is the proof, using Cauchy's Residue Theorem, as mentioned in the text: The first equality is pretty clear to me but I just can't understand the second equality. How does the author jump from the first line to the second ? Please help!","I have been studying the proof of Prime Number Theorem as outlined in the book Introduction to Analytic Number Theory by Apostol and I came across the following lemma : In the proof of this lemma, the author takes two different contours for and respectively and tries to show the required result. Notice that the function has poles at integers . The case for is a straightforward application of Cauchy's Integral Theorem but I am having trouble understanding the case for . Here is the proof, using Cauchy's Residue Theorem, as mentioned in the text: The first equality is pretty clear to me but I just can't understand the second equality. How does the author jump from the first line to the second ? Please help!","u>1 0<u\leq 1 n = 0,-1,\cdots,-k u>1 0<u\leq 1","['complex-analysis', 'analytic-number-theory']"
