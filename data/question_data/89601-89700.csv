,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,The resolvent of an operator commutes with it.,The resolvent of an operator commutes with it.,,"Let $X$ be a Banach space and $\Phi : X \rightarrow X$ a bounded operator. Let also $R(\cdot,\Phi) : \rho(\Phi) \rightarrow B(X)$ the resolvent operator of $\Phi$ defined in the usual way as $R(\lambda,\Phi) := (\lambda I -\Phi)^{-1}$ for $\lambda \in \rho(\Phi)$ . Is it always true, or under which assumptions, does $\Phi$ commute with its resolvent? And if yes, how to show it? I think that maybe the Neumann series plays a role in an eventual proof.","Let be a Banach space and a bounded operator. Let also the resolvent operator of defined in the usual way as for . Is it always true, or under which assumptions, does commute with its resolvent? And if yes, how to show it? I think that maybe the Neumann series plays a role in an eventual proof.","X \Phi : X \rightarrow X R(\cdot,\Phi) : \rho(\Phi) \rightarrow B(X) \Phi R(\lambda,\Phi) := (\lambda I -\Phi)^{-1} \lambda \in \rho(\Phi) \Phi","['functional-analysis', 'operator-theory', 'banach-spaces']"
1,Does Murphy prove that states separate the points of a C*-algebra?,Does Murphy prove that states separate the points of a C*-algebra?,,"Im currently reading chapter 3.3 of Murphy's book on C*-algebras . This chapter is about positive linear functionals. On the internet I read somewhere (I lost the source) that states (i.e. positive linear functionals with norm one) separate the points of a C*-algebra $A$ . If I'm not mistaken, this means that for any $x,y\in A$ there exists a state $\tau$ on $A$ such that $\tau(x)\neq\tau(y)$ . I can't find this result in Murphy's book, is this right? I need a source (preferably Murphy) that I can refer to. Or else, does it follow easily from the results Murphy presents?. Thanks in advance!","Im currently reading chapter 3.3 of Murphy's book on C*-algebras . This chapter is about positive linear functionals. On the internet I read somewhere (I lost the source) that states (i.e. positive linear functionals with norm one) separate the points of a C*-algebra . If I'm not mistaken, this means that for any there exists a state on such that . I can't find this result in Murphy's book, is this right? I need a source (preferably Murphy) that I can refer to. Or else, does it follow easily from the results Murphy presents?. Thanks in advance!","A x,y\in A \tau A \tau(x)\neq\tau(y)","['functional-analysis', 'reference-request', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
2,All norms are equivalent in finite dimensional vector spaces example.,All norms are equivalent in finite dimensional vector spaces example.,,"While researching the equivalence in finite dimensional vector spaces, I found multiple proofs of the theorem, but I still can't wrap my head around the following example: take a finite-dimensional vector: $v = \begin{bmatrix}1\\ 1\\ 1\end{bmatrix}$ . If I calculate the 1-norm I get: |1| + |1| + |1| = 3. For the 2-norm I get: $\sqrt {1^2 + 1^2 + 1^2} = \sqrt{3}$ . Lastly, for the infinite norm I get 1. How are these equal? I seem to not understand what the theorem actually means. Thanks in advance.","While researching the equivalence in finite dimensional vector spaces, I found multiple proofs of the theorem, but I still can't wrap my head around the following example: take a finite-dimensional vector: . If I calculate the 1-norm I get: |1| + |1| + |1| = 3. For the 2-norm I get: . Lastly, for the infinite norm I get 1. How are these equal? I seem to not understand what the theorem actually means. Thanks in advance.",v = \begin{bmatrix}1\\ 1\\ 1\end{bmatrix} \sqrt {1^2 + 1^2 + 1^2} = \sqrt{3},"['linear-algebra', 'functional-analysis']"
3,Weak convergence + pointwise convergence on dense subspace of $L^2$,Weak convergence + pointwise convergence on dense subspace of,L^2,"Let $H$ be a dense subspace of $L^2(X,\mu)$ ( $X$ being a separable and complete metric space with finite measure $\mu$ ) and $(f_n)_{n\in\mathbb N}$ be a sequence in $H$ that converges to $f\in L^2(X,\mu)$ in the following sense: $$ \langle f_n - f, h \rangle_{L^2} \xrightarrow{n\to\infty} 0 \quad \text{for all } h\in H. $$ In addition, let $f_n$ converge pointwise $\mu$ -almost everywhere to some function $g$ , i.e. $f_n(x)\xrightarrow{n\to\infty} g(x)$ for $\mu$ -almost every $x\in X$ . I need to show that $f$ and $g$ agree $\mu$ -almost everywhere, in other words $f_n(x)\xrightarrow{n\to\infty} f(x)$ pointwise for $\mu$ -almost every $x\in X$ . I have been struggling to prove this (and also to find counterexamples), but so far I cannot find the right analytical tools. Any help will be very appreciated! Remark: I know very little about the $f_n$ , there may be no upper bound on their norm etc. Remark: The background is that I am trying to prove a convergence result for conditional mean embeddings in reproducing kernel Hilbert spaces (this is not an homework exercise).","Let be a dense subspace of ( being a separable and complete metric space with finite measure ) and be a sequence in that converges to in the following sense: In addition, let converge pointwise -almost everywhere to some function , i.e. for -almost every . I need to show that and agree -almost everywhere, in other words pointwise for -almost every . I have been struggling to prove this (and also to find counterexamples), but so far I cannot find the right analytical tools. Any help will be very appreciated! Remark: I know very little about the , there may be no upper bound on their norm etc. Remark: The background is that I am trying to prove a convergence result for conditional mean embeddings in reproducing kernel Hilbert spaces (this is not an homework exercise).","H L^2(X,\mu) X \mu (f_n)_{n\in\mathbb N} H f\in L^2(X,\mu) 
\langle f_n - f, h \rangle_{L^2} \xrightarrow{n\to\infty} 0
\quad
\text{for all } h\in H.
 f_n \mu g f_n(x)\xrightarrow{n\to\infty} g(x) \mu x\in X f g \mu f_n(x)\xrightarrow{n\to\infty} f(x) \mu x\in X f_n","['functional-analysis', 'hilbert-spaces', 'weak-convergence', 'pointwise-convergence']"
4,Does $C_c(X)$ separate points in $X$ when $X$ is a Banach space?,Does  separate points in  when  is a Banach space?,C_c(X) X X,"Suppose that $X$ is a separable, infinite dimensional Banach space. We say that a set of functions $\{f_\alpha\}_{\alpha \in A}$ separates points in $X$ if for every $x,y \in X$ , there is an $\alpha$ such that $f_\alpha(x) \neq f_\alpha(y)$ . Is it the case that $C_c(X)$ separates points in $X$ ? I have made some attempts to construct functions in $C_c(X)$ that separate distinct points $x,y$ in $X$ using the characterisation as compact subsets of $X$ as exactly the closed, bounded and flat subsets (where $K$ is flat if for every $\varepsilon > 0$ there is a finite dimensional subspace $F$ of $X$ such that $K \subseteq F + B(0,\varepsilon)$ ) but these attempts ultimately didn't get anywhere. If it is helpful, I am really interested in the case where $X$ is a separable subspace of a Besov space $B_{\infty,\infty}^\alpha$ so would be happy with an answer using any other properties of that space.","Suppose that is a separable, infinite dimensional Banach space. We say that a set of functions separates points in if for every , there is an such that . Is it the case that separates points in ? I have made some attempts to construct functions in that separate distinct points in using the characterisation as compact subsets of as exactly the closed, bounded and flat subsets (where is flat if for every there is a finite dimensional subspace of such that ) but these attempts ultimately didn't get anywhere. If it is helpful, I am really interested in the case where is a separable subspace of a Besov space so would be happy with an answer using any other properties of that space.","X \{f_\alpha\}_{\alpha \in A} X x,y \in X \alpha f_\alpha(x) \neq f_\alpha(y) C_c(X) X C_c(X) x,y X X K \varepsilon > 0 F X K \subseteq F + B(0,\varepsilon) X B_{\infty,\infty}^\alpha","['general-topology', 'functional-analysis', 'separable-spaces', 'besov-space']"
5,Frechet Space vs Banach Space,Frechet Space vs Banach Space,,"What is Frechet Space? Is a Banach a Frechet space? If not, why? If yes, how do we prove it? According to Wikipedia , Frechet spaces are locally convex topological space that is complete with respect to translation-invariant metric. It also says that: They are generalizations of Banach spaces (normed vector spaces that are complete with respect to the metric induced by the norm). So I am guessing that Frechet spaces are Banach Spaces. But how do we prove it?","What is Frechet Space? Is a Banach a Frechet space? If not, why? If yes, how do we prove it? According to Wikipedia , Frechet spaces are locally convex topological space that is complete with respect to translation-invariant metric. It also says that: They are generalizations of Banach spaces (normed vector spaces that are complete with respect to the metric induced by the norm). So I am guessing that Frechet spaces are Banach Spaces. But how do we prove it?",,"['functional-analysis', 'banach-spaces']"
6,Cauchy sequences and convergent sequences [closed],Cauchy sequences and convergent sequences [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I am very confused with a little problem. What is the difference between a Cauchy sequence and a convergent sequence?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I am very confused with a little problem. What is the difference between a Cauchy sequence and a convergent sequence?",,['functional-analysis']
7,functional $F(a) = \int_{0}^{\infty}e^{-kx}\operatorname{ln}(a(x))dx$ maximization,functional  maximization,F(a) = \int_{0}^{\infty}e^{-kx}\operatorname{ln}(a(x))dx,Good afternoon. I try to find  a function $a(x)>0$ subject to $\int_0^\infty a(x) dx=1$ maximzing the following functional $$ F(a) = \int\limits_{0}^{\infty}e^{-kx}\operatorname{ln}(a(x))dx. $$ But I don't know how to do this problem. Because formally we should find a derivate with respect to function. I will be gratefull for hints ideas and literature recomendation.,Good afternoon. I try to find  a function $a(x)>0$ subject to $\int_0^\infty a(x) dx=1$ maximzing the following functional $$ F(a) = \int\limits_{0}^{\infty}e^{-kx}\operatorname{ln}(a(x))dx. $$ But I don't know how to do this problem. Because formally we should find a derivate with respect to function. I will be gratefull for hints ideas and literature recomendation.,,"['real-analysis', 'functional-analysis', 'optimization', 'maxima-minima']"
8,Can we deduce Surjectivity from a property of Unitary linear map?,Can we deduce Surjectivity from a property of Unitary linear map?,,"Many books define the unitary linear map $U: (\mathbb{H}_1,\left<\right>_1) \rightarrow (\mathbb{H}_2,\left<\right>_2)$ as a bijective linear map such that $\left< x,y \right>_1=\left<Ux,Uy  \right>_2$. And I have been trying to disprove that if $U: (\mathbb{H}_1,\left<\right>_1) \rightarrow (\mathbb{H}_2,\left<\right>_2)$ is a linear map such that $\left< x,y \right>_1=\left<Ux,Uy  \right>_2$ then $U$ is surjective. I am pretty sure that the statement above is false since definition specify the bijectivity of unitary map and otherwise they don't need to do that. I hope someone can help me to come up with the counter example.","Many books define the unitary linear map $U: (\mathbb{H}_1,\left<\right>_1) \rightarrow (\mathbb{H}_2,\left<\right>_2)$ as a bijective linear map such that $\left< x,y \right>_1=\left<Ux,Uy  \right>_2$. And I have been trying to disprove that if $U: (\mathbb{H}_1,\left<\right>_1) \rightarrow (\mathbb{H}_2,\left<\right>_2)$ is a linear map such that $\left< x,y \right>_1=\left<Ux,Uy  \right>_2$ then $U$ is surjective. I am pretty sure that the statement above is false since definition specify the bijectivity of unitary map and otherwise they don't need to do that. I hope someone can help me to come up with the counter example.",,"['functional-analysis', 'hilbert-spaces']"
9,"if number of extreme points of $B_X$ is finite, then $X$ is of finite dimensional?","if number of extreme points of  is finite, then  is of finite dimensional?",B_X X,"Let $X$ be a Banach space.  Recall that closed unit ball $B_X$ of $X$ is defined by  $$B_X = \{y\in X: \|y\|\leq 1\}.$$ We say that $x\in X$ is an extreme point of $B_X$ if $x = \frac{1}{2}(u+v)$ where $u,v \in B_X$ implies that $x = u =v.$ Question: Is it true that if the number of extreme points of $B_X$ is finite, then $X$ is of finite dimensional?","Let $X$ be a Banach space.  Recall that closed unit ball $B_X$ of $X$ is defined by  $$B_X = \{y\in X: \|y\|\leq 1\}.$$ We say that $x\in X$ is an extreme point of $B_X$ if $x = \frac{1}{2}(u+v)$ where $u,v \in B_X$ implies that $x = u =v.$ Question: Is it true that if the number of extreme points of $B_X$ is finite, then $X$ is of finite dimensional?",,"['functional-analysis', 'convex-analysis', 'banach-spaces']"
10,How does Rellich–Kondrachov not lead to a contradiction?,How does Rellich–Kondrachov not lead to a contradiction?,,"I'm currently working through Lawrence Evan's PDE's textbook, and in it, he states the Rellich-Kondrachov theorem: Assume $U$ is a bounded open set of $\mathbb R^n$, and $\partial U$ is $C^1$. Suppose $1 \leq p < n$. Then $$W^{1,p}(U) \subset \subset L^p(U)$$ for each $1 \leq q < p^*$ where $p^*$ is the Sobolev conjugate of $p$. I am currently failing to see how this does not contradict the fact that a linear space is compact if and only if it is finite dimensional. In particular the argument I have in mind is that, if $\overline{W^{1,p}(U)}$ is compact, then so is the unit ball in $W^{1,p}(U)$, being a closed subset of a compact set. But, $W^{1,p}(U)$ is clearly not finite dimensional. Where does the above argument go wrong? Thanks! Edit: After doing some further digging, it seems like the main cause of my confusion is that the topologist's definition of compact embedding and the analyst's definition are not equivalent, so I was under the impression that the theorem said something that it didn't.","I'm currently working through Lawrence Evan's PDE's textbook, and in it, he states the Rellich-Kondrachov theorem: Assume $U$ is a bounded open set of $\mathbb R^n$, and $\partial U$ is $C^1$. Suppose $1 \leq p < n$. Then $$W^{1,p}(U) \subset \subset L^p(U)$$ for each $1 \leq q < p^*$ where $p^*$ is the Sobolev conjugate of $p$. I am currently failing to see how this does not contradict the fact that a linear space is compact if and only if it is finite dimensional. In particular the argument I have in mind is that, if $\overline{W^{1,p}(U)}$ is compact, then so is the unit ball in $W^{1,p}(U)$, being a closed subset of a compact set. But, $W^{1,p}(U)$ is clearly not finite dimensional. Where does the above argument go wrong? Thanks! Edit: After doing some further digging, it seems like the main cause of my confusion is that the topologist's definition of compact embedding and the analyst's definition are not equivalent, so I was under the impression that the theorem said something that it didn't.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
11,Quick Proof Verification: Showing Matrix is Nonsingular.,Quick Proof Verification: Showing Matrix is Nonsingular.,,"Hello everyone I just want to verify if my proof is correct as I'm very worried that it's not: Thanks so much. Question:  Let $A$ be a square matrix and let $\lambda$ be a complex number for which $|\lambda| >\|A\|$, where $\|\cdot \|$ denotes some induced matrix norm.  Show that the matrix $\lambda I-A$ is nonsingular and that $({\lambda I-A})^{-1}= \frac{1}{\lambda}\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k$ Proof: Since $\|A\| \geq 0$ and $|\lambda| >\|A\|$ implies $\lambda$ implies $\lambda\neq 0$ $\|\frac{1}{\lambda}A\|<1$ $\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k$ converges. Call $C=\frac{1}{\lambda}\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k$ Now: $({\lambda I-A})C={\lambda}C-AC =\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k -\sum_{k=0}^{\infty}\frac{1}{\lambda^{k+1}}A^{k+1}=I$. Obviously I would also have to show that $C({\lambda I-A})=I$ as well, but it reduces to the same two series subtracted from each other. The problem I'm having is understanding why the two series subtracted above=Identity.  I know that that they should., I'm just not sure why exactly.  Any help would be much appreciated.  Thank you.","Hello everyone I just want to verify if my proof is correct as I'm very worried that it's not: Thanks so much. Question:  Let $A$ be a square matrix and let $\lambda$ be a complex number for which $|\lambda| >\|A\|$, where $\|\cdot \|$ denotes some induced matrix norm.  Show that the matrix $\lambda I-A$ is nonsingular and that $({\lambda I-A})^{-1}= \frac{1}{\lambda}\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k$ Proof: Since $\|A\| \geq 0$ and $|\lambda| >\|A\|$ implies $\lambda$ implies $\lambda\neq 0$ $\|\frac{1}{\lambda}A\|<1$ $\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k$ converges. Call $C=\frac{1}{\lambda}\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k$ Now: $({\lambda I-A})C={\lambda}C-AC =\sum_{k=0}^{\infty}\frac{1}{\lambda^{k}}A^k -\sum_{k=0}^{\infty}\frac{1}{\lambda^{k+1}}A^{k+1}=I$. Obviously I would also have to show that $C({\lambda I-A})=I$ as well, but it reduces to the same two series subtracted from each other. The problem I'm having is understanding why the two series subtracted above=Identity.  I know that that they should., I'm just not sure why exactly.  Any help would be much appreciated.  Thank you.",,"['real-analysis', 'linear-algebra']"
12,"$(X,\|.\|)$ is a normed space over $\mathbb F$ field $M \subset X$ is a vector subspace of $X.$ If $M$ is open vector subspace of $X$, then $X=M$?","is a normed space over  field  is a vector subspace of  If  is open vector subspace of , then ?","(X,\|.\|) \mathbb F M \subset X X. M X X=M","I know there are two questions which are same with mine, but their hints and comments are not clear enough for me. Let $(X,\|.\|)$ is a normed space over $\mathbb F$ field $M \subset X$ is a vector subspace of $X.$ Show that if $M$ is open vector subspace of $X$ then $X=M$ First I tried obtaining a contradiction via using Let $M$ is open and $X\neq M$ . Since $M$ is open $M=int(M)$ . Hence $\exists x\in X\setminus int(M)$ but I couldn't obtain from there. Then, I have tried to prove it directly but I couldn't see why $\forall x \in X$ then $x \in M$ I've written $M$ is open $\Rightarrow$ $\exists r\gt0$ $\forall m \in M$ , $B(m,r)\subseteq M$ $B(m,r):= \{n \in M : \|n-m\| \lt r\}$ and Since $M$ is vector subspace - $\forall m,n \in M \subset X$ , $m+n \in M$ - $\forall m \in M \subset X$ , $\forall \lambda \in \mathbb F$ , $\lambda m \in M$ I cannot combine being vector subspace and being open. Could someone help me about seeing why "" $\forall x \in X$ then $x \in M$ "" or obtainig contradiction in the easiest and clearest way without topological terms please? Thanks in advance","I know there are two questions which are same with mine, but their hints and comments are not clear enough for me. Let is a normed space over field is a vector subspace of Show that if is open vector subspace of then First I tried obtaining a contradiction via using Let is open and . Since is open . Hence but I couldn't obtain from there. Then, I have tried to prove it directly but I couldn't see why then I've written is open , and Since is vector subspace - , - , , I cannot combine being vector subspace and being open. Could someone help me about seeing why "" then "" or obtainig contradiction in the easiest and clearest way without topological terms please? Thanks in advance","(X,\|.\|) \mathbb F M \subset X X. M X X=M M X\neq M M M=int(M) \exists x\in X\setminus int(M) \forall x \in X x \in M M \Rightarrow \exists r\gt0 \forall m \in M B(m,r)\subseteq M B(m,r):= \{n \in M : \|n-m\| \lt r\} M \forall m,n \in M \subset X m+n \in M \forall m \in M \subset X \forall \lambda \in \mathbb F \lambda m \in M \forall x \in X x \in M","['functional-analysis', 'analysis', 'vector-spaces', 'normed-spaces']"
13,$T\in B(H)$. Why is $\forall x\in H$ $Tx=x \iff T^*x=x$?,. Why is  ?,T\in B(H) \forall x\in H Tx=x \iff T^*x=x,"Let $H$ be a Hilbert space, $T:H\to H$ linear and bounded, $\|T\|\le 1$. Prove that: $\forall x\in H$ $Tx=x \iff T^*x=x$. I tried it but there must be a mistake, because I haven't used $\|T\|\le 1$. For all $\forall x\in H$: $\langle Tx-x,x\rangle =\langle x,T^*x\rangle- \langle x,x\rangle =\langle x, T^*x-x\rangle$. I want to conclude from here that $Tx=x \iff T^*x=x$, but this seems to be wrong because I don't use $\|T\|\le 1$, right? Alternatively, my guess is to do this with Cauchy-Schwarz somehow and then I have to use  $\|T\|\le 1$, but how exactly?","Let $H$ be a Hilbert space, $T:H\to H$ linear and bounded, $\|T\|\le 1$. Prove that: $\forall x\in H$ $Tx=x \iff T^*x=x$. I tried it but there must be a mistake, because I haven't used $\|T\|\le 1$. For all $\forall x\in H$: $\langle Tx-x,x\rangle =\langle x,T^*x\rangle- \langle x,x\rangle =\langle x, T^*x-x\rangle$. I want to conclude from here that $Tx=x \iff T^*x=x$, but this seems to be wrong because I don't use $\|T\|\le 1$, right? Alternatively, my guess is to do this with Cauchy-Schwarz somehow and then I have to use  $\|T\|\le 1$, but how exactly?",,['functional-analysis']
14,"Weak convergence in $L^2[0,1]$",Weak convergence in,"L^2[0,1]","In $\ell^2$, a sequence converges weakly if it is bounded and each component converges. My question is: How can I think about weak convergence in $L^2[0,1]$?","In $\ell^2$, a sequence converges weakly if it is bounded and each component converges. My question is: How can I think about weak convergence in $L^2[0,1]$?",,"['functional-analysis', 'hilbert-spaces', 'weak-convergence']"
15,Is there an example of an injective infinite triangular matrix?,Is there an example of an injective infinite triangular matrix?,,"Let $A$ be an infinite upper triangular matrix with complex entries and all diagonal entries nonzero, i.e., \begin{align} A=\left(\begin{matrix} a_{11}&a_{12}&a_{13}&\cdots\\ a_{21}&a_{22}&a_{23}&\cdots\\ a_{31}&a_{32}&a_{33}&\cdots\\ \vdots&\vdots&\vdots&\ddots \end{matrix}\right) \end{align} where $a_{ij}=0(j<i)$ and $a_{ii}\neq 0(\forall i)$. Moreover, assume that $A$ represents a bounded linear operator on an $\ell^p$-space, and for convenience, say, from $\ell^2(\mathbb N)$ to itself. Although for the finitely dimensional case, such a triangular matrix must be bijective, the infinite-dimensional matrix $A$ does not have to be so. I previously asked a problem about it and a compact operator as an counterexample for it was formulated. What I would like to ask are: Is there any example that $A$ is injective and there are infinitely many subdiagonals of $A$ that are not eventually zero? and moreover, Is there any condition (sufficient or necessary) on the entries of $A$ for $A$ to be injective? Thanks in advance...","Let $A$ be an infinite upper triangular matrix with complex entries and all diagonal entries nonzero, i.e., \begin{align} A=\left(\begin{matrix} a_{11}&a_{12}&a_{13}&\cdots\\ a_{21}&a_{22}&a_{23}&\cdots\\ a_{31}&a_{32}&a_{33}&\cdots\\ \vdots&\vdots&\vdots&\ddots \end{matrix}\right) \end{align} where $a_{ij}=0(j<i)$ and $a_{ii}\neq 0(\forall i)$. Moreover, assume that $A$ represents a bounded linear operator on an $\ell^p$-space, and for convenience, say, from $\ell^2(\mathbb N)$ to itself. Although for the finitely dimensional case, such a triangular matrix must be bijective, the infinite-dimensional matrix $A$ does not have to be so. I previously asked a problem about it and a compact operator as an counterexample for it was formulated. What I would like to ask are: Is there any example that $A$ is injective and there are infinitely many subdiagonals of $A$ that are not eventually zero? and moreover, Is there any condition (sufficient or necessary) on the entries of $A$ for $A$ to be injective? Thanks in advance...",,"['linear-algebra', 'functional-analysis', 'operator-theory', 'hilbert-spaces']"
16,Define a metric on $G_\delta$ set making it complete,Define a metric on  set making it complete,G_\delta,"A subset $A$ is a $G_{\delta}$ subset if $A=\bigcap_{1}^{\infty} G_i$ is a countable intersection of open sets $\{ G_i \}$. Show that in metric space $(X,d)$, every closed set is a $G_\delta$ set. If $A$ is a $G_\delta$ subset of a complete metric space $(X,d)$ show that there is metric $D$ on $A$ that induces the same convergence as $d$ on $A$, but $(A,D)$ is complete. For the first part of the question, I take a closed set $C$, define $d(x,C)=\inf\{d(x,b):b\in C\}$, then let $G_k=\{x\in X: d(x,C)<\frac{1}{k}\}$, prove $G_k$ is open and $C=\bigcap G_k$. But to the second part, I really don't know where to start. My professor showed in his lecture notes that, if $O$ is an open set in $(X,d)$, define $D(x,y)=d(x,y)+|\frac{1}{d(x,O^C)}-\frac{1}{d(y,O^C)}|$, then $(O,D)$ is complete. I understand why this works. But in a $G_\delta$ set $A$, $A$ could be closed, and I have difficulty defining metric at the boundary. I tried $D(x,y)=\begin{cases} d(x,y)+|\frac{1}{d(x,O^C)}-\frac{1}{d(y,O^C)}| &\quad d(x,O^C)\cdot d(y,O^C) \neq 0\\d(x,y) &\quad otherwise \end{cases}$, but it seems to fail that it doesn't satisfy triangular inequality. Any hint for this? Thank you!","A subset $A$ is a $G_{\delta}$ subset if $A=\bigcap_{1}^{\infty} G_i$ is a countable intersection of open sets $\{ G_i \}$. Show that in metric space $(X,d)$, every closed set is a $G_\delta$ set. If $A$ is a $G_\delta$ subset of a complete metric space $(X,d)$ show that there is metric $D$ on $A$ that induces the same convergence as $d$ on $A$, but $(A,D)$ is complete. For the first part of the question, I take a closed set $C$, define $d(x,C)=\inf\{d(x,b):b\in C\}$, then let $G_k=\{x\in X: d(x,C)<\frac{1}{k}\}$, prove $G_k$ is open and $C=\bigcap G_k$. But to the second part, I really don't know where to start. My professor showed in his lecture notes that, if $O$ is an open set in $(X,d)$, define $D(x,y)=d(x,y)+|\frac{1}{d(x,O^C)}-\frac{1}{d(y,O^C)}|$, then $(O,D)$ is complete. I understand why this works. But in a $G_\delta$ set $A$, $A$ could be closed, and I have difficulty defining metric at the boundary. I tried $D(x,y)=\begin{cases} d(x,y)+|\frac{1}{d(x,O^C)}-\frac{1}{d(y,O^C)}| &\quad d(x,O^C)\cdot d(y,O^C) \neq 0\\d(x,y) &\quad otherwise \end{cases}$, but it seems to fail that it doesn't satisfy triangular inequality. Any hint for this? Thank you!",,"['general-topology', 'functional-analysis', 'metric-spaces']"
17,a problem in measure theory (how to prove $f_{n}\to 0$ in $ L^{p} $ ),a problem in measure theory (how to prove  in  ),f_{n}\to 0  L^{p} ,"I just need a hint not a whole solution please. Problem: Let $\{f_{n}\}\subset L^{1}([0,1])$ be any sequence of measurable functions such that (a)  $f_{n}\to 0$ almost everywhere; (b) $\sup\limits_{n}\int_{0}^{1}(f_{n}^{-})^{2}<\infty,$ where  $ g^{-} $  denotes the negative part of any function,  $ g^{-}=-\min\{0; g(x)\} $ (c) and  $ \int_{0}^{1}f_{n}\to 0. $ Prove that  $f_{n}\to 0$  in  $L^{1}([0,1]).$ Guess:  I feel that if I use the identity  $ \vert g\vert=g+2g^{-}  $ I will have the answer. But the problem is that how can I prove that $ \int_{0}^{1}f_{n}^{-}(x)dx\to 0? $ Also:  The other guess and hint other than mine may be accepted.","I just need a hint not a whole solution please. Problem: Let $\{f_{n}\}\subset L^{1}([0,1])$ be any sequence of measurable functions such that (a)  $f_{n}\to 0$ almost everywhere; (b) $\sup\limits_{n}\int_{0}^{1}(f_{n}^{-})^{2}<\infty,$ where  $ g^{-} $  denotes the negative part of any function,  $ g^{-}=-\min\{0; g(x)\} $ (c) and  $ \int_{0}^{1}f_{n}\to 0. $ Prove that  $f_{n}\to 0$  in  $L^{1}([0,1]).$ Guess:  I feel that if I use the identity  $ \vert g\vert=g+2g^{-}  $ I will have the answer. But the problem is that how can I prove that $ \int_{0}^{1}f_{n}^{-}(x)dx\to 0? $ Also:  The other guess and hint other than mine may be accepted.",,"['real-analysis', 'functional-analysis', 'analysis', 'measure-theory', 'lebesgue-measure']"
18,Convex cone generated by extreme rays,Convex cone generated by extreme rays,,"Let $X$ be a vector space and $K \subseteq X$ be a pointed convex cone. Let $L$ denote the set of extreme rays of $K.$ The questions are: under which condition can I guarantee that $$K= cone(conv(L))?$$ Here, $cone(A)=\{\lambda x: x\in A, \; \lambda \geq 0\}$ and $conv(A)$ is the convex hull of $A.$ Any reference that treats this problem? I am particularly interested in the infinite dimensional case. Thanks in advance","Let be a vector space and be a pointed convex cone. Let denote the set of extreme rays of The questions are: under which condition can I guarantee that Here, and is the convex hull of Any reference that treats this problem? I am particularly interested in the infinite dimensional case. Thanks in advance","X K \subseteq X L K. K= cone(conv(L))? cone(A)=\{\lambda x: x\in A, \; \lambda \geq 0\} conv(A) A.","['functional-analysis', 'reference-request', 'convex-analysis', 'dual-cone', 'convex-cone']"
19,if $\|T\|\leq 1$ then $I-TT^{*}\geq 0$,if  then,\|T\|\leq 1 I-TT^{*}\geq 0,"If $T\in\mathcal{B}(\mathcal{H})$ and $\|T\|\leq 1$ then $I-TT^{*}\geq 0.$ Is this statement true? And why if, the matrix $\begin{pmatrix} I & T^{*}\\ T & I \end{pmatrix}\geq 0$ then $\|T\|\leq 1?$ Do we use $\|T\|=\|T^{*}\|$ here? Any help would be appreciated.","If $T\in\mathcal{B}(\mathcal{H})$ and $\|T\|\leq 1$ then $I-TT^{*}\geq 0.$ Is this statement true? And why if, the matrix $\begin{pmatrix} I & T^{*}\\ T & I \end{pmatrix}\geq 0$ then $\|T\|\leq 1?$ Do we use $\|T\|=\|T^{*}\|$ here? Any help would be appreciated.",,"['functional-analysis', 'operator-theory']"
20,What is the dual of a sum of Banach function spaces,What is the dual of a sum of Banach function spaces,,"Given two Banach function spaces, e.g. $L^1(\mathbb{R})$ and $L^2(\mathbb{R})$, define the sum $X=L^1+L^2$ as the class of functions $f=f_1+f_2$ having $f_i\in L^i$. Define a norm by $$\|f\|_X=\inf\{\|f_1\|_{L^1}+\|f_2\|_{L^2}; f=f_1+f_2\} $$ where the infimum is taken over all decompositions $f=f_1+f_2$. Is there any (simple) way to see what the dual of $X$ is? As far as I can see it must be a subset of $L^\infty\cap L^2$. Could it be that this is actually the dual space?","Given two Banach function spaces, e.g. $L^1(\mathbb{R})$ and $L^2(\mathbb{R})$, define the sum $X=L^1+L^2$ as the class of functions $f=f_1+f_2$ having $f_i\in L^i$. Define a norm by $$\|f\|_X=\inf\{\|f_1\|_{L^1}+\|f_2\|_{L^2}; f=f_1+f_2\} $$ where the infimum is taken over all decompositions $f=f_1+f_2$. Is there any (simple) way to see what the dual of $X$ is? As far as I can see it must be a subset of $L^\infty\cap L^2$. Could it be that this is actually the dual space?",,"['functional-analysis', 'lp-spaces', 'duality-theorems']"
21,Existence of solution with the smallest norm in hilbert space,Existence of solution with the smallest norm in hilbert space,,"Let $A: H\rightarrow H$ be a contiunuous, linear map on the Hilbert space $H$, $y\in H\setminus \left\{ 0 \right\}$ and $\lambda \in \mathbb{K}$. Show, that if the equation $\lambda x - A x=y$ has at least one solution $x=x_0$, then it has solution with the smallest norm, and this solution is nonzero and unique. I'm guessing that the Riesz representation theorem could be helpful, but I can't see how it works.","Let $A: H\rightarrow H$ be a contiunuous, linear map on the Hilbert space $H$, $y\in H\setminus \left\{ 0 \right\}$ and $\lambda \in \mathbb{K}$. Show, that if the equation $\lambda x - A x=y$ has at least one solution $x=x_0$, then it has solution with the smallest norm, and this solution is nonzero and unique. I'm guessing that the Riesz representation theorem could be helpful, but I can't see how it works.",,"['functional-analysis', 'hilbert-spaces', 'normed-spaces']"
22,"Why is $\text{dim ker}(T) = 0$ a requirement for invertibility of a finite dimensional operator, but not for an infinite dimensional operator?","Why is  a requirement for invertibility of a finite dimensional operator, but not for an infinite dimensional operator?",\text{dim ker}(T) = 0,"I have read that Fredholm operators generalize the notion of invertibility, and that all finite dimensional operators are Fredholm with index 0. Also, if you have a Fredholm operator with index zero, then it is surjective if and only if it is injective. So if a Fredholm operator has index 0 and is injective then it will be invertible. So consider the finite dimensional operator $T: \mathbb{R}^n \to \mathbb{R}^n$ given by the matrix $A$ as follows: $$ A = \begin{bmatrix} 1 & 0 & 0 & \dots & \dots & 0 \\ 0 & 1 & 0 & \dots & \dots & 0 \\ 0 & 0 & 1 & \dots & \dots & 0 \\ 0 & 0 & 1 & \dots & \dots & 0 \\ \vdots & \dots & \ddots & \ddots & 0 & 0 \\ \vdots & \dots & \dots & 0 & 1 & 0 \\ 0 & 0 & \dots & 0 & 0 & 0 \\ \end{bmatrix}. $$ That is, the elements of the diagonal of $A$ are $1$, except for the final diagonal element which is $0$. $A$ has a kernel and cokernel (they are the same) both with dimension $1$ so it is Fredholm with index zero. However it is not injective and therefore not invertible. It seems that for any finite dimensional operator (matrix) I choose with non-trivial kernel, I will never have an injective operator as it can always be reduced to row echelon form in which it will have one or more rows that are all zero. So the only way an operator $T$ can be invertible in the finite dimensional case is if it has $\text{dim ker}(T) = \text{dim (coker}(T)) = 0$. On the other hand, from reading about infinite dimensional operators, it seems invertibility is often shown by first showing the operator is Fredholm with index 0, and then showing it is injective. I don't understand why having $\text{dim ker}(T) \neq 0$ prevents invertibility in the finite dimensional case, yet it doesn't seem to be an issue in the infinite dimensional case? For a finite dimensional operator with a non-trivial kernel we can never have injectivity, so how is it possible that an infinte dimensional operator with non-trivial kernel can be injective?","I have read that Fredholm operators generalize the notion of invertibility, and that all finite dimensional operators are Fredholm with index 0. Also, if you have a Fredholm operator with index zero, then it is surjective if and only if it is injective. So if a Fredholm operator has index 0 and is injective then it will be invertible. So consider the finite dimensional operator $T: \mathbb{R}^n \to \mathbb{R}^n$ given by the matrix $A$ as follows: $$ A = \begin{bmatrix} 1 & 0 & 0 & \dots & \dots & 0 \\ 0 & 1 & 0 & \dots & \dots & 0 \\ 0 & 0 & 1 & \dots & \dots & 0 \\ 0 & 0 & 1 & \dots & \dots & 0 \\ \vdots & \dots & \ddots & \ddots & 0 & 0 \\ \vdots & \dots & \dots & 0 & 1 & 0 \\ 0 & 0 & \dots & 0 & 0 & 0 \\ \end{bmatrix}. $$ That is, the elements of the diagonal of $A$ are $1$, except for the final diagonal element which is $0$. $A$ has a kernel and cokernel (they are the same) both with dimension $1$ so it is Fredholm with index zero. However it is not injective and therefore not invertible. It seems that for any finite dimensional operator (matrix) I choose with non-trivial kernel, I will never have an injective operator as it can always be reduced to row echelon form in which it will have one or more rows that are all zero. So the only way an operator $T$ can be invertible in the finite dimensional case is if it has $\text{dim ker}(T) = \text{dim (coker}(T)) = 0$. On the other hand, from reading about infinite dimensional operators, it seems invertibility is often shown by first showing the operator is Fredholm with index 0, and then showing it is injective. I don't understand why having $\text{dim ker}(T) \neq 0$ prevents invertibility in the finite dimensional case, yet it doesn't seem to be an issue in the infinite dimensional case? For a finite dimensional operator with a non-trivial kernel we can never have injectivity, so how is it possible that an infinte dimensional operator with non-trivial kernel can be injective?",,"['functional-analysis', 'operator-theory', 'linear-transformations']"
23,$C^\infty$ functions with all derivatives in $L^p$,functions with all derivatives in,C^\infty L^p,"Let $1\le p<\infty$ and $f\in C^{\infty}(\mathbb{R})$ be such that its all derivatives $f^{(n)} \in L^p(\mathbb{R})$ for every $n\in \mathbb{N} \cup \{0\}$.  Is it true that $f\in L^\infty(\mathbb{R})$? If it is true, do we have a generalization in $\mathbb{R}^n$? My partial answer for $p=1$: For $p=1$ and  $t\in \mathbb{R}$, we have $$ |g(t)|= |\int_{0}^{t} g'(x) \ dx+g(0)| \le \int_{0}^{t} |g'(x)| \ dx +|g(0)| \le  \|g'\|_{L^1} +|g(0)|. $$  Thus, $g\in L^\infty(\mathbb{R})$ with  $\|g\|_{L^\infty} \le \|g'\|_{L^1}+|g(0)|$. Thanks for help and hint.","Let $1\le p<\infty$ and $f\in C^{\infty}(\mathbb{R})$ be such that its all derivatives $f^{(n)} \in L^p(\mathbb{R})$ for every $n\in \mathbb{N} \cup \{0\}$.  Is it true that $f\in L^\infty(\mathbb{R})$? If it is true, do we have a generalization in $\mathbb{R}^n$? My partial answer for $p=1$: For $p=1$ and  $t\in \mathbb{R}$, we have $$ |g(t)|= |\int_{0}^{t} g'(x) \ dx+g(0)| \le \int_{0}^{t} |g'(x)| \ dx +|g(0)| \le  \|g'\|_{L^1} +|g(0)|. $$  Thus, $g\in L^\infty(\mathbb{R})$ with  $\|g\|_{L^\infty} \le \|g'\|_{L^1}+|g(0)|$. Thanks for help and hint.",,"['calculus', 'real-analysis', 'functional-analysis', 'lebesgue-integral', 'sobolev-spaces']"
24,Equivalent Definitions of the Spectral Norm,Equivalent Definitions of the Spectral Norm,,"There are many equivalent definitions of the spectral norm $\|A\|_2$ for when $A$ is a symmetric matrix, the most common ones being $$\sup_{\|x\|_{2} = 1}{\|Ax\|_{2}} = \sup_{\|x\|_{2}=1}|{\langle Ax,x \rangle|} = \text{largest eigenvalue of $A$ in absolute value}$$ Recently, while going through a paper on compressed sensing ( http://statweb.stanford.edu/~candes/papers/PartialMeasurements.pdf ), I was met with the following definition of the spectral norm(search ""spectral"" in the paper): $$\|Y\|_2 = \displaystyle\sup_{\|f_1\|_{2} = \|f_1\|_{2} = 1 } \langle f_1, Yf_2 \rangle$$ where $f_1, f_2$ are unit norm vectors. After going through some naive calculations, I could not find out why this norm is equivalent to the ones I defined above, nor have I found another source that defines it this way. I was wondering if someone can clear this up for me as to why the definitions are equivalent. Thanks all beforehand!","There are many equivalent definitions of the spectral norm $\|A\|_2$ for when $A$ is a symmetric matrix, the most common ones being $$\sup_{\|x\|_{2} = 1}{\|Ax\|_{2}} = \sup_{\|x\|_{2}=1}|{\langle Ax,x \rangle|} = \text{largest eigenvalue of $A$ in absolute value}$$ Recently, while going through a paper on compressed sensing ( http://statweb.stanford.edu/~candes/papers/PartialMeasurements.pdf ), I was met with the following definition of the spectral norm(search ""spectral"" in the paper): $$\|Y\|_2 = \displaystyle\sup_{\|f_1\|_{2} = \|f_1\|_{2} = 1 } \langle f_1, Yf_2 \rangle$$ where $f_1, f_2$ are unit norm vectors. After going through some naive calculations, I could not find out why this norm is equivalent to the ones I defined above, nor have I found another source that defines it this way. I was wondering if someone can clear this up for me as to why the definitions are equivalent. Thanks all beforehand!",,"['linear-algebra', 'functional-analysis', 'analysis', 'random-matrices']"
25,"For a densely defined symmetric operator $A$, is $A^2$ also densely defined?","For a densely defined symmetric operator , is  also densely defined?",A A^2,"Let $A : D(A) \to H$ be a possibly unbounded, densely defined symmetric operator on a Hilbert space $H$ ($A$ being symmetric means that $(\varphi, A\psi) = (A\varphi, \psi)$ for all $\varphi, \psi \in D(A)$). Consider the operator $A^2$ with domain $D(A^2) := \{ \psi \in D(A) | A\psi \in D(A) \}$. I would like to determine whether $D(A^2)$ is dense in $H$. The usual way to prove something like this is to assume that we have $\varphi \in H$ such that $$(\psi, \varphi) = 0$$ for all $\psi \in D(A^2)$. Then we want to show that this implies $\varphi = 0$. But I have not really been able to make any progress from this point. Hints or solutions are greatly appreciated.","Let $A : D(A) \to H$ be a possibly unbounded, densely defined symmetric operator on a Hilbert space $H$ ($A$ being symmetric means that $(\varphi, A\psi) = (A\varphi, \psi)$ for all $\varphi, \psi \in D(A)$). Consider the operator $A^2$ with domain $D(A^2) := \{ \psi \in D(A) | A\psi \in D(A) \}$. I would like to determine whether $D(A^2)$ is dense in $H$. The usual way to prove something like this is to assume that we have $\varphi \in H$ such that $$(\psi, \varphi) = 0$$ for all $\psi \in D(A^2)$. Then we want to show that this implies $\varphi = 0$. But I have not really been able to make any progress from this point. Hints or solutions are greatly appreciated.",,"['functional-analysis', 'hilbert-spaces', 'unbounded-operators']"
26,$f(x)$ and $xf(x)\in L^2(\mathbb{R})$ then $f(x)\in L^1(\mathbb{R})$,and  then,f(x) xf(x)\in L^2(\mathbb{R}) f(x)\in L^1(\mathbb{R}),"If $f(x)$ and $xf(x)\in L^2(\mathbb{R})$ then $f(x)\in L^1(\mathbb{R})$. I know that if $E$ is of finite measure, then we can infer from $f(x)\in L^2(E)$ to get $f(x)\in L^1(E)$. However, now $E=\mathbb{R}$, I don't know how to get the result now. How to apply $xf(x) \in L^2$?","If $f(x)$ and $xf(x)\in L^2(\mathbb{R})$ then $f(x)\in L^1(\mathbb{R})$. I know that if $E$ is of finite measure, then we can infer from $f(x)\in L^2(E)$ to get $f(x)\in L^1(E)$. However, now $E=\mathbb{R}$, I don't know how to get the result now. How to apply $xf(x) \in L^2$?",,"['real-analysis', 'functional-analysis', 'lebesgue-integral', 'lebesgue-measure']"
27,"$Tf = xf(x)$ is not compact in $L^2([0,1])$",is not compact in,"Tf = xf(x) L^2([0,1])","I want to prove, in a rather elementary way, that $Tf = xf(x)$ is not compact in $L^2([0,1])$. I cannot find the appropriate bounded sequence whose image has no Cauchy sub-sequences. I have tried variants of $f_n(x) = \sqrt n\cdot I_{[0,1/n]}$ to no avail. Any suggestions?","I want to prove, in a rather elementary way, that $Tf = xf(x)$ is not compact in $L^2([0,1])$. I cannot find the appropriate bounded sequence whose image has no Cauchy sub-sequences. I have tried variants of $f_n(x) = \sqrt n\cdot I_{[0,1/n]}$ to no avail. Any suggestions?",,"['real-analysis', 'functional-analysis', 'operator-theory', 'lp-spaces']"
28,"""Obviousness"" of $A\subset B\Rightarrow A^\circ\supset B^\circ$, where $A^\circ=\{x^*\in X^*:(\forall x\in A)(|\langle x,x^*\rangle|\leq 1)\}$","""Obviousness"" of , where","A\subset B\Rightarrow A^\circ\supset B^\circ A^\circ=\{x^*\in X^*:(\forall x\in A)(|\langle x,x^*\rangle|\leq 1)\}","Let $\langle X,X^{\ast}\rangle$ be a dual pair. For a subset $A$ of $X$ define   $$A^\circ:=\{x^{\ast}\in X^{\ast} :|\langle x,x^{\ast}\rangle|\le 1\text{, for all $x\in A$}\}.$$   If $A\subset B \subset X$ are non-empty, then $A^\circ \supset B^\circ$. The proof of this property seems to always be described as ""obvious"". So I ask, why is it obvious?","Let $\langle X,X^{\ast}\rangle$ be a dual pair. For a subset $A$ of $X$ define   $$A^\circ:=\{x^{\ast}\in X^{\ast} :|\langle x,x^{\ast}\rangle|\le 1\text{, for all $x\in A$}\}.$$   If $A\subset B \subset X$ are non-empty, then $A^\circ \supset B^\circ$. The proof of this property seems to always be described as ""obvious"". So I ask, why is it obvious?",,"['analysis', 'functional-analysis']"
29,"If a normal element of a C* algebra has real spectrum, then it is self-adjoint","If a normal element of a C* algebra has real spectrum, then it is self-adjoint",,Let $A$ be a $C^*\!$-algebra. Suppose $x$ is a normal element of $A$ and $\operatorname{spect}(x)$ lies in $\mathbb{R}$. Prove that $x$ is self-adjoint. I tried the following: using $\operatorname{spect}(x)=\overline{\operatorname{spect}(x^*)}$   conclude that $\lambda -a=\lambda-a^* \implies a=a^*$ for $\lambda$ in $\operatorname{spect}(a)$. Is this valid?,Let $A$ be a $C^*\!$-algebra. Suppose $x$ is a normal element of $A$ and $\operatorname{spect}(x)$ lies in $\mathbb{R}$. Prove that $x$ is self-adjoint. I tried the following: using $\operatorname{spect}(x)=\overline{\operatorname{spect}(x^*)}$   conclude that $\lambda -a=\lambda-a^* \implies a=a^*$ for $\lambda$ in $\operatorname{spect}(a)$. Is this valid?,,"['functional-analysis', 'spectral-theory', 'c-star-algebras']"
30,Laplace operator defined on a Sobolev space,Laplace operator defined on a Sobolev space,,"Consider the Laplace operator $$A:W^{2,2}(\mathbb{R})\to L^2(\mathbb{R})\;\;\\A u = -u^{\prime \prime}$$ I want to know why this operator is closed (I'm using the closed graph theorem): Let $(u_n)\subseteq W^{2,2}(\mathbb{R})$ be a sequence such that $u_n\to x$ in $L^2(\mathbb{R})$ and $Au_n=-u_n^{\prime \prime}\to y$ in $L^2(\mathbb{R})$. Now, why is $x\in  W^{2,2}(\mathbb{R})$? (It must be proven that $Ax=y$, but this is ok for me..) I'm stuck on: Is $(u_n)$ a cauchy sequence $W^{2,2}(\mathbb{R})$ with respect to $\|u\|_{2,2}^2=(\|u\|_{L^2}^2+\sum\limits_{|\alpha|\le 2}\|D^{\alpha}u\|_{L^2}^2)$? I know that $(u_n)$ and $(u_n)$ are cauchy sequences in $L^2(\mathbb{R})$ but I know nothing about $(u_n')$. Regards","Consider the Laplace operator $$A:W^{2,2}(\mathbb{R})\to L^2(\mathbb{R})\;\;\\A u = -u^{\prime \prime}$$ I want to know why this operator is closed (I'm using the closed graph theorem): Let $(u_n)\subseteq W^{2,2}(\mathbb{R})$ be a sequence such that $u_n\to x$ in $L^2(\mathbb{R})$ and $Au_n=-u_n^{\prime \prime}\to y$ in $L^2(\mathbb{R})$. Now, why is $x\in  W^{2,2}(\mathbb{R})$? (It must be proven that $Ax=y$, but this is ok for me..) I'm stuck on: Is $(u_n)$ a cauchy sequence $W^{2,2}(\mathbb{R})$ with respect to $\|u\|_{2,2}^2=(\|u\|_{L^2}^2+\sum\limits_{|\alpha|\le 2}\|D^{\alpha}u\|_{L^2}^2)$? I know that $(u_n)$ and $(u_n)$ are cauchy sequences in $L^2(\mathbb{R})$ but I know nothing about $(u_n')$. Regards",,"['functional-analysis', 'ordinary-differential-equations', 'sobolev-spaces']"
31,Schauder basis for $c_0$,Schauder basis for,c_0,"So, I am trying to prove that $c_0$ has the dual space $\ell^1$ (I know this proof is out there). Except my professor told me that  a Schauder basis for $c_0$ is $(e_k)$ where $ e_k = \delta_{j,k}$ has a 1 in the $k$th place and zeros otherwise is not correct (this is what every proof out there claims). He said that I need to think about this as a matrix to develop the basis. This disagrees with everything I have found up until now. He said that I have $e_k$ depended upon $1$ variable while $\delta$ is depended upon $2$. Below I state the wording of the problem. Can anyone help me write a proper Schauder basis. Represent $\ell^1$ as the space of all real functions $x$ on $S= \{(m,n): m\geq 1, n \geq 1\}$, such that $$ \|x\|_1 = \sum |x(m,n)| < \infty.  $$ Let $c_0$ be the space of all real functions $\gamma$ on $S$ such that $y(m,n) \rightarrow 0$ as $m+n \rightarrow \infty$, with norm $\|y\|_\infty = \sup |y(m,n)|$. \  Let M be the subspace of $\ell^1$ consisting of all $x \in \ell^1$ that satisfy the equations $$ mx(m,1) = \sum_{n=2}^\infty x(m,n)      \;\;\;\;\;\;\; (m = 1, 2, 3, \ldots) $$","So, I am trying to prove that $c_0$ has the dual space $\ell^1$ (I know this proof is out there). Except my professor told me that  a Schauder basis for $c_0$ is $(e_k)$ where $ e_k = \delta_{j,k}$ has a 1 in the $k$th place and zeros otherwise is not correct (this is what every proof out there claims). He said that I need to think about this as a matrix to develop the basis. This disagrees with everything I have found up until now. He said that I have $e_k$ depended upon $1$ variable while $\delta$ is depended upon $2$. Below I state the wording of the problem. Can anyone help me write a proper Schauder basis. Represent $\ell^1$ as the space of all real functions $x$ on $S= \{(m,n): m\geq 1, n \geq 1\}$, such that $$ \|x\|_1 = \sum |x(m,n)| < \infty.  $$ Let $c_0$ be the space of all real functions $\gamma$ on $S$ such that $y(m,n) \rightarrow 0$ as $m+n \rightarrow \infty$, with norm $\|y\|_\infty = \sup |y(m,n)|$. \  Let M be the subspace of $\ell^1$ consisting of all $x \in \ell^1$ that satisfy the equations $$ mx(m,1) = \sum_{n=2}^\infty x(m,n)      \;\;\;\;\;\;\; (m = 1, 2, 3, \ldots) $$",,"['real-analysis', 'linear-algebra', 'functional-analysis', 'schauder-basis']"
32,Spectrum of a bilateral shift,Spectrum of a bilateral shift,,"Let $u$ be a bilateral shift on Hilbert space $\ell^2(\Bbb Z)$. As for unilateral shifts, the spectrum of $u$ does not contain any eigenvalue. Also $u$ is unitary, so $\sigma(u) \subset \Bbb S$ ($\Bbb S$ means unit circle). How can I show that $\sigma(u)=\Bbb S$?","Let $u$ be a bilateral shift on Hilbert space $\ell^2(\Bbb Z)$. As for unilateral shifts, the spectrum of $u$ does not contain any eigenvalue. Also $u$ is unitary, so $\sigma(u) \subset \Bbb S$ ($\Bbb S$ means unit circle). How can I show that $\sigma(u)=\Bbb S$?",,"['functional-analysis', 'operator-theory']"
33,Trace operator is basis independent,Trace operator is basis independent,,"Let $H$ be a Hilbert space and call suppose $A:H\rightarrow H$ is positive. How do you show Tr$(A)=\sum_{n}(Ae_n,e_n)$, does not depends on the orthonormal basis $e_n$. I was thinking about using an approximation of $A$ as $A_k$ where $A_k$ is finite rank operator, so $Tr(A_k)$ is the sum of diagonal entries of an $\infty\times n$ matrix, which is basis independent. Then use $Tr(A_k)\rightarrow Tr(A)$ to conclude the proof. Is this the right approach?","Let $H$ be a Hilbert space and call suppose $A:H\rightarrow H$ is positive. How do you show Tr$(A)=\sum_{n}(Ae_n,e_n)$, does not depends on the orthonormal basis $e_n$. I was thinking about using an approximation of $A$ as $A_k$ where $A_k$ is finite rank operator, so $Tr(A_k)$ is the sum of diagonal entries of an $\infty\times n$ matrix, which is basis independent. Then use $Tr(A_k)\rightarrow Tr(A)$ to conclude the proof. Is this the right approach?",,"['real-analysis', 'functional-analysis']"
34,What are criteria to tell when the point spectrum is discrete?,What are criteria to tell when the point spectrum is discrete?,,"Are there some criteria to tell when the point spectrum of a linear operator is discrete? In general it is not the same (take the spectrum of the ""annihilation"" operator). More specifically, what are the conditions that should be satisfied by a symmetric (or even self-adjoint) operator to have ""point spectrum"" = ""discrete spectrum""?","Are there some criteria to tell when the point spectrum of a linear operator is discrete? In general it is not the same (take the spectrum of the ""annihilation"" operator). More specifically, what are the conditions that should be satisfied by a symmetric (or even self-adjoint) operator to have ""point spectrum"" = ""discrete spectrum""?",,"['functional-analysis', 'spectral-theory']"
35,Banach Spaces which are not $L^p$,Banach Spaces which are not,L^p,"Most of the times, when I think of Banach Spaces I think of $L^p$ spaces. I would like to know if there is any Banach space which can not be written as $L^p$ space. Please also indicate any applications of such spaces. Thanks","Most of the times, when I think of Banach Spaces I think of $L^p$ spaces. I would like to know if there is any Banach space which can not be written as $L^p$ space. Please also indicate any applications of such spaces. Thanks",,"['analysis', 'functional-analysis', 'reference-request', 'soft-question']"
36,Every normal operator on a separable Hilbert space has a square root that commutes with it,Every normal operator on a separable Hilbert space has a square root that commutes with it,,"Show that every normal operator on a separable Hilbert space has a square root that commutes with it. Uniqueness? My attempt: Let $T$ be a normal operator. By polar decomposition $T=U|T|$  where $U$  is a partial isometry and $|T|$  is positive. Now using functional calculus $\phi: C(\sigma(|T|))\to C^∗ (|T|,1)$ , there is a sequence $\{f_n \}$  of continuous functions in $C(\sigma(|T|))$  such that $x^{ 1/2} =\lim f_n (x)$  so $|T|^ {1/2}$   is the unique square root of $ |T|$ . But what about square root of $T$ ? Is it $|T|^{ 1/2}? I do not use of separablity of Hilbert space $H$ in my attempt. Also I think the  exercise is always true, not just for separable Hilbert space. And $|T|^{1/2}$ is always unique. Where is my mistake? Also if I have mistaken, Please give me an example of a normal operator on a non-separable Hilbert space that its square root is not unique. Thanks.","Show that every normal operator on a separable Hilbert space has a square root that commutes with it. Uniqueness? My attempt: Let $T$ be a normal operator. By polar decomposition $T=U|T|$  where $U$  is a partial isometry and $|T|$  is positive. Now using functional calculus $\phi: C(\sigma(|T|))\to C^∗ (|T|,1)$ , there is a sequence $\{f_n \}$  of continuous functions in $C(\sigma(|T|))$  such that $x^{ 1/2} =\lim f_n (x)$  so $|T|^ {1/2}$   is the unique square root of $ |T|$ . But what about square root of $T$ ? Is it $|T|^{ 1/2}? I do not use of separablity of Hilbert space $H$ in my attempt. Also I think the  exercise is always true, not just for separable Hilbert space. And $|T|^{1/2}$ is always unique. Where is my mistake? Also if I have mistaken, Please give me an example of a normal operator on a non-separable Hilbert space that its square root is not unique. Thanks.",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'c-star-algebras']"
37,"Demonstration of $\int_{-a}^a \frac{f(x)}{1+e^x} \,dx= \int_0^a f(x) \,dx$ [duplicate]",Demonstration of  [duplicate],"\int_{-a}^a \frac{f(x)}{1+e^x} \,dx= \int_0^a f(x) \,dx","This question already has answers here : Showing that $\int\limits_{-a}^a \frac{f(x)}{1+e^{x}} \mathrm dx = \int\limits_0^a f(x) \mathrm dx$, when $f$ is even (5 answers) Closed 9 years ago . Good morning, Can you give me a help to demonstrate this proposition: $f$ is an even and continuous function on the interval $[-a,a], a>0$. Demonstrate: $$\int_{-a}^a \frac{f(x)}{1+e^x} \,dx= \int_0^a f(x) \,dx$$","This question already has answers here : Showing that $\int\limits_{-a}^a \frac{f(x)}{1+e^{x}} \mathrm dx = \int\limits_0^a f(x) \mathrm dx$, when $f$ is even (5 answers) Closed 9 years ago . Good morning, Can you give me a help to demonstrate this proposition: $f$ is an even and continuous function on the interval $[-a,a], a>0$. Demonstrate: $$\int_{-a}^a \frac{f(x)}{1+e^x} \,dx= \int_0^a f(x) \,dx$$",,"['analysis', 'functional-analysis', 'definite-integrals']"
38,Every compact operator on a Banach space with the approximation property is a norm-limit of finite rank operators,Every compact operator on a Banach space with the approximation property is a norm-limit of finite rank operators,,"Let $X$ be a Banach space and suppose there is a net $\{F_i\}$ of finite-rank operators on $X$ such that (a) $\sup_i\|F_i\|<\infty$ , (b) $\|F_ix-x\|\to 0$ for all $x$ in $X$ . Show that if $A$ is compact operator on $X$ , then $\|F_iA-A\|\to 0$ and hence there is a sequence $\{A_n\}$ of finite rank operators on $X$ such that $\|A_n-A\|\to 0.$ I know that if Banach space $X$ has Schauder basis,then finite rank operators space is dense in compact operators space. So I think, I should show that Banach space $X$ in this question should have a Schauder basis, but I do not know how to show it.","Let be a Banach space and suppose there is a net of finite-rank operators on such that (a) , (b) for all in . Show that if is compact operator on , then and hence there is a sequence of finite rank operators on such that I know that if Banach space has Schauder basis,then finite rank operators space is dense in compact operators space. So I think, I should show that Banach space in this question should have a Schauder basis, but I do not know how to show it.",X \{F_i\} X \sup_i\|F_i\|<\infty \|F_ix-x\|\to 0 x X A X \|F_iA-A\|\to 0 \{A_n\} X \|A_n-A\|\to 0. X X,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'compact-operators']"
39,Small $\ell^p$ spaces are obtainable from $L^p$,Small  spaces are obtainable from,\ell^p L^p,"I've seen that in a lot of books there is written that $$l^p=L^p(X,\Sigma,\mu),$$ where $X=\Bbb N, \Sigma=P(\Bbb N), \mu=\#$, ($\#$ is the counting measure). I would like to see how to prove it, because I've tried but there are a lot of things that don't convince me. Do you know where I can find this proved, or some suggestion to prove it?","I've seen that in a lot of books there is written that $$l^p=L^p(X,\Sigma,\mu),$$ where $X=\Bbb N, \Sigma=P(\Bbb N), \mu=\#$, ($\#$ is the counting measure). I would like to see how to prove it, because I've tried but there are a lot of things that don't convince me. Do you know where I can find this proved, or some suggestion to prove it?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'banach-spaces']"
40,Property of norm,Property of norm,,"Let $X$ be a compact Hausdorff space and let $C(X)$ denote the set of continuous complex valued functions on $X$. Define $$ \|f\|:=\sup\{|f(x)|:x\in X\},$$ then prove that $\|fg\|\leq \|f\|\|g\|$.","Let $X$ be a compact Hausdorff space and let $C(X)$ denote the set of continuous complex valued functions on $X$. Define $$ \|f\|:=\sup\{|f(x)|:x\in X\},$$ then prove that $\|fg\|\leq \|f\|\|g\|$.",,['functional-analysis']
41,"Show that there exists constant $C$ such that $\sum_{n=1}^{\infty}|\langle f,x_n\rangle |^2\le C \|f\|^2$",Show that there exists constant  such that,"C \sum_{n=1}^{\infty}|\langle f,x_n\rangle |^2\le C \|f\|^2","Let $H$ be Hilbert space. I have to show that if $\sum_{n=1}^{\infty}|\langle f,x_n\rangle|^2 < \infty, \:\:\: f\in H$ then there exists constant $C\ge 0$ such that $\sum_{n=1}^{\infty}|\langle f,x_n\rangle|^2\le C \|f\|^2, \:\:\: f\in H$ Is this somehow connected with Bessel inequality? Could you give my any tips?","Let $H$ be Hilbert space. I have to show that if $\sum_{n=1}^{\infty}|\langle f,x_n\rangle|^2 < \infty, \:\:\: f\in H$ then there exists constant $C\ge 0$ such that $\sum_{n=1}^{\infty}|\langle f,x_n\rangle|^2\le C \|f\|^2, \:\:\: f\in H$ Is this somehow connected with Bessel inequality? Could you give my any tips?",,['functional-analysis']
42,Apollonius’ Identity inner product space,Apollonius’ Identity inner product space,,$||z-x||^2+||z-y||^2=\frac{1}{2}||x-y||^2+2||z-\frac{x+y}{2}||^2$ I proved it by expanding both sides and i found both sides are equal. Are there any easy way to prove it?,$||z-x||^2+||z-y||^2=\frac{1}{2}||x-y||^2+2||z-\frac{x+y}{2}||^2$ I proved it by expanding both sides and i found both sides are equal. Are there any easy way to prove it?,,"['functional-analysis', 'inequality', 'inner-products']"
43,A topological vector space with countable local base is metrizable,A topological vector space with countable local base is metrizable,,"I feel confused by the proof of the following theorem in Rudin 2/e: Theorem 1.24 If $X$ is a topological vector space (t.v.s.) with a countable local base, then there is a metric $d$ on $X$ s.t. $d$ is compatible with the topology of $X$, the open balls centered at $0$ are balanced, and $d$ is invariant: $d(x+z,y+z)=d(x,y), \forall x,y,z \in X$. (This is the same theorem as in this question here. ) I quote the beginning of the proof where I got confused: Proof. By Theorem 1.14 (which states that in a t.v.s. every neighborhood of $0$ contains a balanced neighborhood of $0$), $X$ has a balanced local base $\{V_n\}$ s.t. $$V_{n+1}+V_{n+1}+V_{n+1}+V_{n+1}\subset V_n , \forall n=1,2,\ldots $$ My question: I understand that we can make the countable local base balanced by choosing a balanced neighborhood inside each base element, but how can I guarantee that $V_{n+1}+V_{n+1}+V_{n+1}+V_{n+1}\subset V_n$ always holds? I feel that this might be related to the following result (p.10): If $W$ is a neighbhorhood of $0$ in $X$, then there is a neighborhood $U$ of $0$ which is symmetric and which satisfies $U+U\subset W$. However this only helps me find (balanced) neighborhoods $V'$ s.t. $V'+V'+V'+V'\subset V_n$, but how can I ensure that this $V'$ is actually $V_{n+1}$?","I feel confused by the proof of the following theorem in Rudin 2/e: Theorem 1.24 If $X$ is a topological vector space (t.v.s.) with a countable local base, then there is a metric $d$ on $X$ s.t. $d$ is compatible with the topology of $X$, the open balls centered at $0$ are balanced, and $d$ is invariant: $d(x+z,y+z)=d(x,y), \forall x,y,z \in X$. (This is the same theorem as in this question here. ) I quote the beginning of the proof where I got confused: Proof. By Theorem 1.14 (which states that in a t.v.s. every neighborhood of $0$ contains a balanced neighborhood of $0$), $X$ has a balanced local base $\{V_n\}$ s.t. $$V_{n+1}+V_{n+1}+V_{n+1}+V_{n+1}\subset V_n , \forall n=1,2,\ldots $$ My question: I understand that we can make the countable local base balanced by choosing a balanced neighborhood inside each base element, but how can I guarantee that $V_{n+1}+V_{n+1}+V_{n+1}+V_{n+1}\subset V_n$ always holds? I feel that this might be related to the following result (p.10): If $W$ is a neighbhorhood of $0$ in $X$, then there is a neighborhood $U$ of $0$ which is symmetric and which satisfies $U+U\subset W$. However this only helps me find (balanced) neighborhoods $V'$ s.t. $V'+V'+V'+V'\subset V_n$, but how can I ensure that this $V'$ is actually $V_{n+1}$?",,"['general-topology', 'functional-analysis']"
44,Borel functional calculus,Borel functional calculus,,"For a normal operator T, we have a resolution of the identity $\int_{{\sigma}(T)} {\lambda}\,dE=T$. If $T$ is in addition compact , we have that $\sum_{n=1}^{{\infty}}{\lambda}_{n}\langle x,e_{n}\rangle e_{n}$ where $e_{n}$ is an orthonormal basis of eigenvectors etc. I'm trying to derive the second from the first. If $T$ is compact then it's spectrum is discrete so the integral will reduce to a sum but I'm not sure how to proceed. Thanks","For a normal operator T, we have a resolution of the identity $\int_{{\sigma}(T)} {\lambda}\,dE=T$. If $T$ is in addition compact , we have that $\sum_{n=1}^{{\infty}}{\lambda}_{n}\langle x,e_{n}\rangle e_{n}$ where $e_{n}$ is an orthonormal basis of eigenvectors etc. I'm trying to derive the second from the first. If $T$ is compact then it's spectrum is discrete so the integral will reduce to a sum but I'm not sure how to proceed. Thanks",,"['linear-algebra', 'functional-analysis']"
45,"$A^2$ self-adjoint and Compact, prove $A$ has an eigenvalue","self-adjoint and Compact, prove  has an eigenvalue",A^2 A,Suppose $H$ is a Hilbert space and $A \in L(H)$ is such that $A^2$ is compact and self-adjoint. Prove that $A$ has an eigenvalue. (Here $L(H)$ is the set of bounded linear operators on a Hilbert space $H$.),Suppose $H$ is a Hilbert space and $A \in L(H)$ is such that $A^2$ is compact and self-adjoint. Prove that $A$ has an eigenvalue. (Here $L(H)$ is the set of bounded linear operators on a Hilbert space $H$.),,"['functional-analysis', 'eigenvalues-eigenvectors', 'hilbert-spaces', 'compact-operators']"
46,Contraction and Fixed Point [duplicate],Contraction and Fixed Point [duplicate],,"This question already has an answer here : If $T^n$ is $q$-contractive, $T$ exactly has one fixed point (1 answer) Closed 9 years ago . How do I show that for $T: X \rightarrow X$ where X is complete and $T^m$ is a contraction that T has a unique fixed point $x_0 \in X$. I know there exists $\lambda_1 \in (0,1)$ for $x, y \in X$ such that $d(T^mx, T^my) \leq \lambda_1 d(x, y)$ and I need to show that T is a contraction and then apply the fixed point theorem but how do I do that?","This question already has an answer here : If $T^n$ is $q$-contractive, $T$ exactly has one fixed point (1 answer) Closed 9 years ago . How do I show that for $T: X \rightarrow X$ where X is complete and $T^m$ is a contraction that T has a unique fixed point $x_0 \in X$. I know there exists $\lambda_1 \in (0,1)$ for $x, y \in X$ such that $d(T^mx, T^my) \leq \lambda_1 d(x, y)$ and I need to show that T is a contraction and then apply the fixed point theorem but how do I do that?",,"['functional-analysis', 'fixed-point-theorems']"
47,How to prove that the implicit function theorem implies the inverse function theorem?,How to prove that the implicit function theorem implies the inverse function theorem?,,"I can prove the converse of it, but I cannot do this one. Here is the problem: Prove that the implicit function theorem implies the inverse function theorem.","I can prove the converse of it, but I cannot do this one. Here is the problem: Prove that the implicit function theorem implies the inverse function theorem.",,"['functional-analysis', 'analysis', 'multivariable-calculus']"
48,Proving Inner Product Space,Proving Inner Product Space,,"Let $E=C^1 [a,b]$ be the space of all continuously differentiable functions. For $f,g \in E$ define $$ \langle f,g \rangle \ = \ \int_a^b f'(x) \ g'(x) \ dx$$ Is $\langle f,g \rangle$ an inner product space? I'm just checking the four conditions from Kreyszig pg 129. I have a few questions. I know the first few conditions are true but I'm unsure of the wording for my justification. Because these are continuously differentiable I do not need to incorporate any sort of measure or Lebesgue integral, correct? So the scalar removes due to properties of the Riemann integral constructed as partial sums? Is this a real vector space? The functions are real valued, so is the inner product Hermitian symmetric from this fact?","Let $E=C^1 [a,b]$ be the space of all continuously differentiable functions. For $f,g \in E$ define $$ \langle f,g \rangle \ = \ \int_a^b f'(x) \ g'(x) \ dx$$ Is $\langle f,g \rangle$ an inner product space? I'm just checking the four conditions from Kreyszig pg 129. I have a few questions. I know the first few conditions are true but I'm unsure of the wording for my justification. Because these are continuously differentiable I do not need to incorporate any sort of measure or Lebesgue integral, correct? So the scalar removes due to properties of the Riemann integral constructed as partial sums? Is this a real vector space? The functions are real valued, so is the inner product Hermitian symmetric from this fact?",,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
49,Total sets in Banach spaces.,Total sets in Banach spaces.,,"We call the set total if its linear span is dense in a given normed space. Let $X$ be a Banach space and let $D$ be a total set in $X$. For the sequence $\{T_n\}$ of bounded operators on $X$. we have the following $\|(T_n - T)x\| \to 0$ for all $x \in D$, where $T$ is some bouned linear operator on $X$. Does it imply that $\{T_n\}$ converges strongly to $T$ on whole $X$? I think that the answer is yes, but my solution seems to be too easy. Let $x \in X$, then $x= \sum_{k \geq 0} c_kx_k$, where $c_k \in \mathbb{C}$ and $x_k \in D$. $$\|(T_n - T)x \| = \| \sum_{k \geq 0} c_k (T_n - T)x_k \| \leq \sum_{k \geq 0}|c_k| \|(T_n - T)x_k \| \to 0, $$ where we use the continuity of our operators and properties of the norm. Thank you.","We call the set total if its linear span is dense in a given normed space. Let $X$ be a Banach space and let $D$ be a total set in $X$. For the sequence $\{T_n\}$ of bounded operators on $X$. we have the following $\|(T_n - T)x\| \to 0$ for all $x \in D$, where $T$ is some bouned linear operator on $X$. Does it imply that $\{T_n\}$ converges strongly to $T$ on whole $X$? I think that the answer is yes, but my solution seems to be too easy. Let $x \in X$, then $x= \sum_{k \geq 0} c_kx_k$, where $c_k \in \mathbb{C}$ and $x_k \in D$. $$\|(T_n - T)x \| = \| \sum_{k \geq 0} c_k (T_n - T)x_k \| \leq \sum_{k \geq 0}|c_k| \|(T_n - T)x_k \| \to 0, $$ where we use the continuity of our operators and properties of the norm. Thank you.",,"['functional-analysis', 'convergence-divergence']"
50,Is this a Projection operator on Hilbert space?,Is this a Projection operator on Hilbert space?,,"Let $T$ be a bounded operator on a Hilbert space with the property that $T^*(T-I)= 0$ . I'd like to show that $T$ is an orthogonal projection. I'm not really sure how to show that an operator is an orthogonal projection. If $A:X\rightarrow U$ is a projection onto a closed subspace of X, then $\langle x- Ax, u_i\rangle = 0 \;\;\forall u_i \in U$ ? Expanding we get $T'T = T' \Longleftrightarrow TT' = T\ (T'' = T$ in Hilbert spaces?) $$Tx = T'(Tx) \Longleftrightarrow y = T'y$$ Hence $T'$ has $\lambda = 1$ after $Tx$ , do $T'$ and $T$ have the same eigenvalues? There are a lot of question marks here.","Let be a bounded operator on a Hilbert space with the property that . I'd like to show that is an orthogonal projection. I'm not really sure how to show that an operator is an orthogonal projection. If is a projection onto a closed subspace of X, then ? Expanding we get in Hilbert spaces?) Hence has after , do and have the same eigenvalues? There are a lot of question marks here.","T T^*(T-I)= 0 T A:X\rightarrow U \langle x- Ax, u_i\rangle = 0 \;\;\forall u_i \in U T'T = T' \Longleftrightarrow TT' = T\ (T'' = T Tx = T'(Tx) \Longleftrightarrow y = T'y T' \lambda = 1 Tx T' T","['functional-analysis', 'operator-theory', 'projection']"
51,Why begin with distributions and then move to tempered ones?,Why begin with distributions and then move to tempered ones?,,"After reading several books on distribution theory, I got a strange feeling. Why do they all begin with the theory of distributions and then move on to tempered distributions? Why can't we just start with Schwartz class and tempered distributions since they are the ones we use most often? I think the theory of Schwartz class and tempered distributions can pretty well live on their own, and this theory would be much easier to develop since schwartz class is metrizable and everything works well with tempered distributions. So why do we begin with test functions and distributions, not schwartz class and tempered distributions? Thanks!","After reading several books on distribution theory, I got a strange feeling. Why do they all begin with the theory of distributions and then move on to tempered distributions? Why can't we just start with Schwartz class and tempered distributions since they are the ones we use most often? I think the theory of Schwartz class and tempered distributions can pretty well live on their own, and this theory would be much easier to develop since schwartz class is metrizable and everything works well with tempered distributions. So why do we begin with test functions and distributions, not schwartz class and tempered distributions? Thanks!",,"['functional-analysis', 'education', 'distribution-theory']"
52,proving facts about $\alpha$-Hölder-continuous functions,proving facts about -Hölder-continuous functions,\alpha,"I am studying myself some facts about $\alpha$-Hölder-continuous functions but I don't get any further by proving the following: $(1)$ $\forall\alpha\in ]0,1]$ is $C^{0,\alpha}$ dense in $C^0(D)$ concerning the uniform norm and $D\subset\mathbb R^n$. $(2)$ $\forall\alpha\in ]0,1]$ and compact set $K\subset\mathbb R^n$ is $(C^{0,\alpha}(K),||\cdot||_{C^{0,\alpha}(K)})$ a complete space (with $||u||_{C^{0,\alpha}(K)}:=||u||_{\sup}+\sup\limits_{{x,y\in K\space\&\space x\ne y}}\frac{|u(x)-u(y)|}{|x-y|^\alpha}$ and $C^{0,\alpha}(K)$ the space of all $\alpha$-Hölder-continuous functions) $(3)$ All bounded closed subsets of $(C^{0,\alpha}(K),||\cdot||_{C^{0,\alpha}(K)})$ are compact. So how do you prove one $(1),(2),(3)$ ?","I am studying myself some facts about $\alpha$-Hölder-continuous functions but I don't get any further by proving the following: $(1)$ $\forall\alpha\in ]0,1]$ is $C^{0,\alpha}$ dense in $C^0(D)$ concerning the uniform norm and $D\subset\mathbb R^n$. $(2)$ $\forall\alpha\in ]0,1]$ and compact set $K\subset\mathbb R^n$ is $(C^{0,\alpha}(K),||\cdot||_{C^{0,\alpha}(K)})$ a complete space (with $||u||_{C^{0,\alpha}(K)}:=||u||_{\sup}+\sup\limits_{{x,y\in K\space\&\space x\ne y}}\frac{|u(x)-u(y)|}{|x-y|^\alpha}$ and $C^{0,\alpha}(K)$ the space of all $\alpha$-Hölder-continuous functions) $(3)$ All bounded closed subsets of $(C^{0,\alpha}(K),||\cdot||_{C^{0,\alpha}(K)})$ are compact. So how do you prove one $(1),(2),(3)$ ?",,"['real-analysis', 'analysis', 'functional-analysis']"
53,"Is the Sobolev space $W^{k ,\infty}$ a Banach algebra?",Is the Sobolev space  a Banach algebra?,"W^{k ,\infty}","Some Sobolev spaces are closed under multiplication, making them Banach algebras. My question is whether  $W^{k ,\infty}$ is a Banach algebra? Since $L^\infty$ is closed under multiplication, I assume $W^{k ,\infty}$ inherits this closure property.","Some Sobolev spaces are closed under multiplication, making them Banach algebras. My question is whether  $W^{k ,\infty}$ is a Banach algebra? Since $L^\infty$ is closed under multiplication, I assume $W^{k ,\infty}$ inherits this closure property.",,"['functional-analysis', 'sobolev-spaces', 'banach-algebras']"
54,Completeness of $\ell^2$ space,Completeness of  space,\ell^2,"I was reading up and it says that $(\ell^2,\|.\|_2)$ is complete. I know that a metric space $X$ in which every Cauchy sequence converges to an element of $X$ is called complete. And I know that a sequence is Cauchy if given $\epsilon$, there exists $N \in \mathbb{N}$ such that $|x_m-x_n|<\epsilon$ for all $n,m>N$. I was reading the proof that  $(\ell^2,\|.\|_2)$ is complete, but I don't understand where does the $x_k^n$ comes from. What does it mean when it writes $x_k^n$? Let $(x_n)$ be Cauchy in $\ell^2$, i.e. $\forall \epsilon>0$ there exists $N \in \mathbb{N}$ such that $\sum_{k=1}^\infty|x_k^n-x_k^m|^2 <\epsilon^2$ for $n,m>N$. For any fixed $k_0$, $|x_{k_0}^n-x_{k_0}^m|<\epsilon$ for $n,m >N$. So $(x_{k_0}^n)$ is Cauchy in $\mathbb{K}$ ($\mathbb{R}$ or $\mathbb{C})$ and converges to say $y_{k_0}$. Also, why did they square $\sum_{k=1}^\infty|x_k^n-x_k^m|^2 <\epsilon^2$?","I was reading up and it says that $(\ell^2,\|.\|_2)$ is complete. I know that a metric space $X$ in which every Cauchy sequence converges to an element of $X$ is called complete. And I know that a sequence is Cauchy if given $\epsilon$, there exists $N \in \mathbb{N}$ such that $|x_m-x_n|<\epsilon$ for all $n,m>N$. I was reading the proof that  $(\ell^2,\|.\|_2)$ is complete, but I don't understand where does the $x_k^n$ comes from. What does it mean when it writes $x_k^n$? Let $(x_n)$ be Cauchy in $\ell^2$, i.e. $\forall \epsilon>0$ there exists $N \in \mathbb{N}$ such that $\sum_{k=1}^\infty|x_k^n-x_k^m|^2 <\epsilon^2$ for $n,m>N$. For any fixed $k_0$, $|x_{k_0}^n-x_{k_0}^m|<\epsilon$ for $n,m >N$. So $(x_{k_0}^n)$ is Cauchy in $\mathbb{K}$ ($\mathbb{R}$ or $\mathbb{C})$ and converges to say $y_{k_0}$. Also, why did they square $\sum_{k=1}^\infty|x_k^n-x_k^m|^2 <\epsilon^2$?",,"['functional-analysis', 'metric-spaces', 'banach-spaces', 'lp-spaces']"
55,Dense subspaces in complete TVS,Dense subspaces in complete TVS,,"If $X$ is a complete topological vector space, Y is a dense subspace (so $\overline{Y}=X$), Z is a closed subspace, it is possible that $Y\cap Z=\{0\}$? This is definitely possible for subsets in topological spaces (with intersection being empty), but not sure about complete TVS, or even more particular in complete metric spaces, Banach or Hilbert spaces. Edit: Thanks for the answer Nate. Updated questions: 1) Is it possible to find $Y$ dense that non-trivially intersects any $Z$ of dimension at least 2? 2) Does any infinite dimensional closed $Z$ intersect non-trivially any dense $Y$?","If $X$ is a complete topological vector space, Y is a dense subspace (so $\overline{Y}=X$), Z is a closed subspace, it is possible that $Y\cap Z=\{0\}$? This is definitely possible for subsets in topological spaces (with intersection being empty), but not sure about complete TVS, or even more particular in complete metric spaces, Banach or Hilbert spaces. Edit: Thanks for the answer Nate. Updated questions: 1) Is it possible to find $Y$ dense that non-trivially intersects any $Z$ of dimension at least 2? 2) Does any infinite dimensional closed $Z$ intersect non-trivially any dense $Y$?",,"['general-topology', 'functional-analysis', 'banach-spaces']"
56,Compact operator in Hilbert Space,Compact operator in Hilbert Space,,"$H$ is a Hilbert space and $A$ is a bounded operator on $H$. If $A^*A$ is compact, is it necessarily that $A$ is compact?","$H$ is a Hilbert space and $A$ is a bounded operator on $H$. If $A^*A$ is compact, is it necessarily that $A$ is compact?",,['functional-analysis']
57,The spectrum of a bounded linear operator,The spectrum of a bounded linear operator,,"Suppose $X$ is a Banach space. For $T\in L(X,X)$, let its spectrum be $\sigma(T)$. Show that $\lambda\in\sigma(T)\Rightarrow\lambda^{n}\in\sigma(T^{n}),\ \forall n\in\mathbb{N}$. Show that the converse is true for $\mathbb{C}$ but not for $\mathbb{R}$. Thank you.","Suppose $X$ is a Banach space. For $T\in L(X,X)$, let its spectrum be $\sigma(T)$. Show that $\lambda\in\sigma(T)\Rightarrow\lambda^{n}\in\sigma(T^{n}),\ \forall n\in\mathbb{N}$. Show that the converse is true for $\mathbb{C}$ but not for $\mathbb{R}$. Thank you.",,['functional-analysis']
58,"Bounded Linear functional on $\mathcal{L}_{2}[a,b]$",Bounded Linear functional on,"\mathcal{L}_{2}[a,b]","Lets say that $f:[a,b] \rightarrow \mathbb{R}$ is a measurable function such that  $H: \mathcal{L}_{2}[a,b] \rightarrow \mathbb{R}$ defined as $H(g) = \int_{a}^{b}fg$ is finite for all $g \in \mathcal{L}_{2}[a,b]$ I was wondering if $H$ is a bounded linear functional on $\mathcal{L}_{2}[a,b]$","Lets say that $f:[a,b] \rightarrow \mathbb{R}$ is a measurable function such that  $H: \mathcal{L}_{2}[a,b] \rightarrow \mathbb{R}$ defined as $H(g) = \int_{a}^{b}fg$ is finite for all $g \in \mathcal{L}_{2}[a,b]$ I was wondering if $H$ is a bounded linear functional on $\mathcal{L}_{2}[a,b]$",,['functional-analysis']
59,"Show that $\operatorname{ran}(I-T)$ is dense in $\ell^2$, $T$ is a right shift operator","Show that  is dense in ,  is a right shift operator",\operatorname{ran}(I-T) \ell^2 T,"$T$ is a right shift operator from $\ell^2 \to \ell^2$, $(\alpha_1, \alpha_2,\ldots)\mapsto (0,\alpha_1,\alpha_2,\ldots)$. I want to show that $\operatorname{ran}(I-T)$ is dense in $\ell^2$.  Could anyone help me or give me a hint please?","$T$ is a right shift operator from $\ell^2 \to \ell^2$, $(\alpha_1, \alpha_2,\ldots)\mapsto (0,\alpha_1,\alpha_2,\ldots)$. I want to show that $\operatorname{ran}(I-T)$ is dense in $\ell^2$.  Could anyone help me or give me a hint please?",,['functional-analysis']
60,example of nonexpansive mappings,example of nonexpansive mappings,,"As we know : $T:X\longrightarrow X$ is a nonexpansive mapping iff $\|Tx-Ty\|\leq\|x-y\|,$ $\forall x,y\in X$ So my question is I want some nonexpansive mappings, I know $\sin(x)$ , $\cos(x)$ and if I'm not wrong $\frac{1}{x}$ for $x\geq1$ Thanks.","As we know : is a nonexpansive mapping iff So my question is I want some nonexpansive mappings, I know , and if I'm not wrong for Thanks.","T:X\longrightarrow X \|Tx-Ty\|\leq\|x-y\|, \forall x,y\in X \sin(x) \cos(x) \frac{1}{x} x\geq1",['functional-analysis']
61,polynomial norm and Banach spaces,polynomial norm and Banach spaces,,"Consider the linear space of polynomials on [$a$, $b$] normed by $\rVert$$\centerdot$$\rVert$_max norm. Is this normed linear space a Banach space? My professor said it is not, but then could I use contradiction? Haven't been able to come up with a good Cauchy sequence argument, though. I would appreciate all the help I could get, thank you.","Consider the linear space of polynomials on [$a$, $b$] normed by $\rVert$$\centerdot$$\rVert$_max norm. Is this normed linear space a Banach space? My professor said it is not, but then could I use contradiction? Haven't been able to come up with a good Cauchy sequence argument, though. I would appreciate all the help I could get, thank you.",,"['real-analysis', 'functional-analysis']"
62,"If $\sum \|f_i\|$ converges and $\sum_{i=1}^\infty f_i$ exists in a normed function space, do we get for free that $\|\sum_{i=1}^n f_i - f\| \to 0$?","If  converges and  exists in a normed function space, do we get for free that ?",\sum \|f_i\| \sum_{i=1}^\infty f_i \|\sum_{i=1}^n f_i - f\| \to 0,"Let $(V,\|-\|)$ be a normed function space, and suppose that $(f_i)_i$ is a sequence of elements of $V$ so that $\sum \|f_i\| < \infty$ . Further suppose that this data implies that $f = \sum f_i$ , where $\sum_{i=1}^n f_i \to f$ pointwise , is an element of $V$ . Then I would think that we can show immediately that $\sum_{i=1}^n f_i \to f$ in norm, as: $$\left\|\sum_{i=1}^n f_i - f \right\| = \left\|\sum_{i=1}^n f_i- \sum_{i=1}^\infty f_i\right\| = \left\|\sum_{i=n+1}^\infty f_i\right\| \leq \sum_{i=n+1}^\infty \|f_i\|$$ which is sensible, as we can show that any tail of $\sum f_i$ is in $V$ as well. However, as $\sum \|f_i\| < \infty$ , it follows that the right-hand-side goes to zero as $n \to \infty$ , thus proving that $\sum_{i=1}^n f_i \to f$ in norm. Here is my question: Have I made a mistake in the above reasoning? The reason I am suspicious is because whenever I have seen an example of this situation in books (e.g., showing $L^p$ is a Banach space), the author shows convergence in norm using some other method dependent on the properties of the norm being considered. However, I cannot determine where the reasoning could break down.","Let be a normed function space, and suppose that is a sequence of elements of so that . Further suppose that this data implies that , where pointwise , is an element of . Then I would think that we can show immediately that in norm, as: which is sensible, as we can show that any tail of is in as well. However, as , it follows that the right-hand-side goes to zero as , thus proving that in norm. Here is my question: Have I made a mistake in the above reasoning? The reason I am suspicious is because whenever I have seen an example of this situation in books (e.g., showing is a Banach space), the author shows convergence in norm using some other method dependent on the properties of the norm being considered. However, I cannot determine where the reasoning could break down.","(V,\|-\|) (f_i)_i V \sum \|f_i\| < \infty f = \sum f_i \sum_{i=1}^n f_i \to f V \sum_{i=1}^n f_i \to f \left\|\sum_{i=1}^n f_i - f \right\| = \left\|\sum_{i=1}^n f_i- \sum_{i=1}^\infty f_i\right\| = \left\|\sum_{i=n+1}^\infty f_i\right\| \leq \sum_{i=n+1}^\infty \|f_i\| \sum f_i V \sum \|f_i\| < \infty n \to \infty \sum_{i=1}^n f_i \to f L^p","['functional-analysis', 'convergence-divergence', 'normed-spaces']"
63,An orthonormal sequence in an inner product space converges weakly to $0$.,An orthonormal sequence in an inner product space converges weakly to .,0,"It is a well-known theorem that ""An orthonormal sequence in a Hilbert space converges weakly to $0$ "". The proof uses the Bessel's inequality and the Rise representation theorem for which completeness of the space is a necessary condition. However, I somehow proved the same theorem for any inner product space. If my proof were correct, then textbooks would use that stronger result instead of the current one. Theorem: Let $E$ be an inner product space, $\{ x_n\}$ an orthonormal sequence in an inner product space, and . Then $\{ f(x_n)\}$ converges to $0$ for any $f\in E'$ . Proof: Let $f\in E'$ . Assume to the contrary that $\{f(x_n)\}$ does not go to $0$ . Then there is some $\epsilon >0$ and a subsequence $\{ x_{k_n}\}$ such that $|f(x_{k_n})|\geq \epsilon $ . But then infinitely many of $f(x_{k_n})$ 's are positive or they are negative. So without loss of generality, assume that $f(x_{k_n})$ 's are all positive. Then $n\cdot \epsilon \leq f(x_{k_1})+...+f(x_{k_n})=| f(x_{k_1})+...+f(x_{k_n})|=|f(x_{k_1}+...+x_{k_n})|\leq ||f||\cdot ||x_{k_1}+...+x_{k_n}||=||f||\cdot \sqrt{n}$ where the last equality follows from the Pythagorean theorem. But we then obtain $||f||\geq \epsilon \cdot \sqrt{n}$ , which contradicts with boundedness of $f$ . So $f(x_n)\rightarrow 0$ . $\square$ I couldn't see the issue here.","It is a well-known theorem that ""An orthonormal sequence in a Hilbert space converges weakly to "". The proof uses the Bessel's inequality and the Rise representation theorem for which completeness of the space is a necessary condition. However, I somehow proved the same theorem for any inner product space. If my proof were correct, then textbooks would use that stronger result instead of the current one. Theorem: Let be an inner product space, an orthonormal sequence in an inner product space, and . Then converges to for any . Proof: Let . Assume to the contrary that does not go to . Then there is some and a subsequence such that . But then infinitely many of 's are positive or they are negative. So without loss of generality, assume that 's are all positive. Then where the last equality follows from the Pythagorean theorem. But we then obtain , which contradicts with boundedness of . So . I couldn't see the issue here.",0 E \{ x_n\} \{ f(x_n)\} 0 f\in E' f\in E' \{f(x_n)\} 0 \epsilon >0 \{ x_{k_n}\} |f(x_{k_n})|\geq \epsilon  f(x_{k_n}) f(x_{k_n}) n\cdot \epsilon \leq f(x_{k_1})+...+f(x_{k_n})=| f(x_{k_1})+...+f(x_{k_n})|=|f(x_{k_1}+...+x_{k_n})|\leq ||f||\cdot ||x_{k_1}+...+x_{k_n}||=||f||\cdot \sqrt{n} ||f||\geq \epsilon \cdot \sqrt{n} f f(x_n)\rightarrow 0 \square,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
64,"Example of Borel measure on R which is not Borel regular, but have finite value on all compact sets?","Example of Borel measure on R which is not Borel regular, but have finite value on all compact sets?",,"The answer below this question: Example of a Borel measure, which is not Borel-regular provides an example of Borel-irregular measure. Here, I am asking a harder question: Can we find a Borel measure $\mu$ (on $\mathbb R$ or on any other space) that is NOT Borel regular, but for every compact set $K,$ $\mu(K)$ is finite? Easy examples like the counting measure are not going to work here.","The answer below this question: Example of a Borel measure, which is not Borel-regular provides an example of Borel-irregular measure. Here, I am asking a harder question: Can we find a Borel measure (on or on any other space) that is NOT Borel regular, but for every compact set is finite? Easy examples like the counting measure are not going to work here.","\mu \mathbb R K, \mu(K)","['real-analysis', 'functional-analysis', 'measure-theory', 'borel-measures']"
65,"Motivation behind locally convex spaces, seminorms, and Frechet spaces","Motivation behind locally convex spaces, seminorms, and Frechet spaces",,"I am looking for some motivation behind the definition of locally convex spaces, seminorms, and Frechet spaces. Since all three concepts are related I have grouped them as one question. I am familiar with the technical definitions but I don't see what would lead one to defining them. What is so special about locally convex spaces that we wish to focus are analysis only on them? I am aware that seminorms are generalizations of norms but with the condition $\|x \| = 0 \implies x = 0$ dropped. But why do we care about such objects? The idea of angles and inner products would naturally lead one to define a Hilbert space and similarly length would lead one to define Banach spaces. Is there any similar idea that a Frechet space captures?","I am looking for some motivation behind the definition of locally convex spaces, seminorms, and Frechet spaces. Since all three concepts are related I have grouped them as one question. I am familiar with the technical definitions but I don't see what would lead one to defining them. What is so special about locally convex spaces that we wish to focus are analysis only on them? I am aware that seminorms are generalizations of norms but with the condition dropped. But why do we care about such objects? The idea of angles and inner products would naturally lead one to define a Hilbert space and similarly length would lead one to define Banach spaces. Is there any similar idea that a Frechet space captures?",\|x \| = 0 \implies x = 0,"['functional-analysis', 'soft-question', 'topological-vector-spaces', 'locally-convex-spaces', 'frechet-space']"
66,Inequality with norm in Space $L^2(\Omega)$,Inequality with norm in Space,L^2(\Omega),"Let $\Omega \subset \mathbb{R}^N$ a bounded domain. Let $v \in L^2(\Omega)$ . It is possible to make an estimate of the type $$\|v^2\|_{L^2(\Omega)} \leq \|v\|^k_{L^2(\Omega)}$$ , for some $k \in \mathbb{R}$ . Using Holder's inequality, I'm able to get something like $$\|v^2\|_{L^2(\Omega)} \leq \|v^3\|_{L^2(\Omega)}\|v\|_{L^2(\Omega)}.$$ But what I really want is to get that square out of the norm. Thanks.","Let a bounded domain. Let . It is possible to make an estimate of the type , for some . Using Holder's inequality, I'm able to get something like But what I really want is to get that square out of the norm. Thanks.",\Omega \subset \mathbb{R}^N v \in L^2(\Omega) \|v^2\|_{L^2(\Omega)} \leq \|v\|^k_{L^2(\Omega)} k \in \mathbb{R} \|v^2\|_{L^2(\Omega)} \leq \|v^3\|_{L^2(\Omega)}\|v\|_{L^2(\Omega)}.,"['functional-analysis', 'measure-theory', 'estimation']"
67,Does strict convexity imply continuity?,Does strict convexity imply continuity?,,"Let $E$ be a normed space and $f:E \to \mathbb R$ convex. If $E = \mathbb R^d$ then $f$ is locally Lipschitz-continuous. If $E$ is infinite-dimensional then $f$ is not necessarily continuous. There exists discontinuous linear functional on an infinite-dimensional normed space. Now we assume more that $f$ is strictly convex, i.e., $$ f(tx + (1-t)y) < tf(x)+(1-t)f(y) \quad \forall t \in (0, 1), \forall x,y\in E \text{ s.t. } x\neq y. $$ Strict convexity does not imply differentiability. Does strict convexity of $f$ imply that $f$ is continuous?","Let be a normed space and convex. If then is locally Lipschitz-continuous. If is infinite-dimensional then is not necessarily continuous. There exists discontinuous linear functional on an infinite-dimensional normed space. Now we assume more that is strictly convex, i.e., Strict convexity does not imply differentiability. Does strict convexity of imply that is continuous?","E f:E \to \mathbb R E = \mathbb R^d f E f f 
f(tx + (1-t)y) < tf(x)+(1-t)f(y) \quad \forall t \in (0, 1), \forall x,y\in E \text{ s.t. } x\neq y.
 f f","['functional-analysis', 'continuity', 'convex-analysis']"
68,"Rudin Functional Analysis, Lemma 4.22","Rudin Functional Analysis, Lemma 4.22",,"I am having difficulty understanding Rudin's proof on Lemma 4.22 of his Functional Analysis book. The assumption is that $M$ is a subspace of a normed space $X$ and $M$ is not dense in X. Rudin then claims that there exists $x_1 \in X$ whose distance from $M$ is 1, that is, $\inf \{||x_1 - y||: y \in M\} = 1$ . It is not so obvious to me why such an $x_1$ exists. May someone explain the logic to me? Does it have anything to do with the assumption "" $M$ is not dense in X""? Thanks in advance to everyone who's trying to help out. This is the screenshot of the whole Lemma and proof given by Rudin:","I am having difficulty understanding Rudin's proof on Lemma 4.22 of his Functional Analysis book. The assumption is that is a subspace of a normed space and is not dense in X. Rudin then claims that there exists whose distance from is 1, that is, . It is not so obvious to me why such an exists. May someone explain the logic to me? Does it have anything to do with the assumption "" is not dense in X""? Thanks in advance to everyone who's trying to help out. This is the screenshot of the whole Lemma and proof given by Rudin:",M X M x_1 \in X M \inf \{||x_1 - y||: y \in M\} = 1 x_1 M,"['functional-analysis', 'normed-spaces']"
69,Orthogonal basis of $L^2(\mathbb{R})$ and $L^2(\mathbb{R^+})$,Orthogonal basis of  and,L^2(\mathbb{R}) L^2(\mathbb{R^+}),"Let $\mathbb{R}^+ = [0, \infty)$ , i.e. the positive real numbers. Let $L^2(\mathbb{R})$ and $L^2(\mathbb{R}^+)$ be the sets of real-valued functions with domains in $\mathbb{R}$ and $\mathbb{R}^+$ respectively that are square integrate with respect to the Lebesgue measure. These sets are endowed with the inner product $$ \left( f, g \right) = \int_{-\infty}^{\infty} f g \ \mathsf{d} x, $$ and $$ \left( f, g \right) = \int_{0}^{\infty} f g \ \mathsf{d} x, $$ respectively. I have the following questions Are the sets $L^2(\mathbb{R})$ and $L^2(\mathbb{R}^+)$ separable Hilbert Spaces?. In such a case, what Schauder basis exist for these sets?. Is there an known orthogonal family of functions on these sets? Motivation: For the case $L^2(\Omega)$ where $\Omega$ is compact, this is known to be true. The families of orthogonal functions on this set are used in a wide range of engineering applications, e.g. solving PDES in compact domains. However, I have not found similar results when $\Omega$ is unbounded. The existence of an orthogonal set of functions in $L^2(\mathbb{R})$ and $L^2(\mathbb{R}^+)$ would be useful to solve problems in unbounded domains.","Let , i.e. the positive real numbers. Let and be the sets of real-valued functions with domains in and respectively that are square integrate with respect to the Lebesgue measure. These sets are endowed with the inner product and respectively. I have the following questions Are the sets and separable Hilbert Spaces?. In such a case, what Schauder basis exist for these sets?. Is there an known orthogonal family of functions on these sets? Motivation: For the case where is compact, this is known to be true. The families of orthogonal functions on this set are used in a wide range of engineering applications, e.g. solving PDES in compact domains. However, I have not found similar results when is unbounded. The existence of an orthogonal set of functions in and would be useful to solve problems in unbounded domains.","\mathbb{R}^+ = [0, \infty) L^2(\mathbb{R}) L^2(\mathbb{R}^+) \mathbb{R} \mathbb{R}^+ 
\left( f, g \right) = \int_{-\infty}^{\infty} f g \ \mathsf{d} x,
 
\left( f, g \right) = \int_{0}^{\infty} f g \ \mathsf{d} x,
 L^2(\mathbb{R}) L^2(\mathbb{R}^+) L^2(\Omega) \Omega \Omega L^2(\mathbb{R}) L^2(\mathbb{R}^+)","['linear-algebra', 'functional-analysis']"
70,To prove continuity of $\varphi(p) = \int_X |f|^p\ d\mu$ on $E = \{p: \varphi(p) < \infty\}$ where $0 < p < \infty$,To prove continuity of  on  where,\varphi(p) = \int_X |f|^p\ d\mu E = \{p: \varphi(p) < \infty\} 0 < p < \infty,"Suppose $f$ is a complex measurable function on $X$ , $\mu$ is a positive measure on $X$ , and $$\varphi(p) ~=~ \int_X |f|^p \; d\mu \quad (0 < p < \infty)$$ Let $E :=\{ p : \varphi(p) < \infty\}$ . Assume $\|f\|_\infty > 0$ . Prove that $\log\varphi$ is convex in the interior of $E$ and that $\varphi$ is continuous on $E$ . I have proved that $\log\varphi$ is convex on $\operatorname{int}E$ , using Holder's inequality. We know that log-convexity implies convexity, so $\varphi$ is also convex on $\operatorname{int}E$ , and hence continuous on $\operatorname{int}E$ . How do we establish the continuity of $\varphi$ on $E$ , though? I am missing exactly the points in $E\setminus\operatorname{int}E$ . I know this question has been previously answered here , but I'm unable to understand the proof. Moreover, I am trying to take a different approach to prove continuity. Let $\{p_n\}_{n\in\mathbb N}$ be a sequence in $E$ , such that $p_n\to p$ (may or may not be in $E$ - we don't know if $E$ is closed, right?). I wish to show $\varphi(p_n)\to \varphi(p)$ , i.e. $$\lim_{n\to\infty} \int_X |f|^{p_n}\ d\mu = \int_X |f|^p \ d\mu$$ This looks like a possible application of Lebesgue's Dominated Convergence Theorem, but I could not find a dominating function yet. I would appreciate any help, thanks a lot! I have already seen this answer - it did not help much. The proof was too convoluted, and I needed more details. @OliverDiaz and @robjohn were able to provide convincing detailed arguments, hence this post.","Suppose is a complex measurable function on , is a positive measure on , and Let . Assume . Prove that is convex in the interior of and that is continuous on . I have proved that is convex on , using Holder's inequality. We know that log-convexity implies convexity, so is also convex on , and hence continuous on . How do we establish the continuity of on , though? I am missing exactly the points in . I know this question has been previously answered here , but I'm unable to understand the proof. Moreover, I am trying to take a different approach to prove continuity. Let be a sequence in , such that (may or may not be in - we don't know if is closed, right?). I wish to show , i.e. This looks like a possible application of Lebesgue's Dominated Convergence Theorem, but I could not find a dominating function yet. I would appreciate any help, thanks a lot! I have already seen this answer - it did not help much. The proof was too convoluted, and I needed more details. @OliverDiaz and @robjohn were able to provide convincing detailed arguments, hence this post.",f X \mu X \varphi(p) ~=~ \int_X |f|^p \; d\mu \quad (0 < p < \infty) E :=\{ p : \varphi(p) < \infty\} \|f\|_\infty > 0 \log\varphi E \varphi E \log\varphi \operatorname{int}E \varphi \operatorname{int}E \operatorname{int}E \varphi E E\setminus\operatorname{int}E \{p_n\}_{n\in\mathbb N} E p_n\to p E E \varphi(p_n)\to \varphi(p) \lim_{n\to\infty} \int_X |f|^{p_n}\ d\mu = \int_X |f|^p \ d\mu,"['functional-analysis', 'measure-theory', 'lp-spaces']"
71,"Reference on Sobolev spaces $W^{k,p}(\Omega;\mathbb{R}^n)$",Reference on Sobolev spaces,"W^{k,p}(\Omega;\mathbb{R}^n)","While reading about calculus of variations I stumbled upon the Sobolev spaces $W^{k,p}(\Omega;\mathbb{R}^n)$ of order $k$ weakly differentiable functions with $p$ integrable derivatives, and codomain $\mathbb{R}^n$ instead of $\mathbb{R}$ . Do you have any reference where definitions and properties about those spaces are provided?","While reading about calculus of variations I stumbled upon the Sobolev spaces of order weakly differentiable functions with integrable derivatives, and codomain instead of . Do you have any reference where definitions and properties about those spaces are provided?","W^{k,p}(\Omega;\mathbb{R}^n) k p \mathbb{R}^n \mathbb{R}","['real-analysis', 'functional-analysis', 'partial-differential-equations', 'reference-request', 'sobolev-spaces']"
72,Is there always a linear isometry from a normed vector space into its dual?,Is there always a linear isometry from a normed vector space into its dual?,,Let $\mathbb K=\mathbb R$ or $\mathbb K=\mathbb C$ and $E$ be a normed $\mathbb K$ -vector space. Can we show that there is a linear isometry from $E$ into $E'$ or is there a counterexample? I think this should be true: My idea is that we should be able to consider the linear isometry $\iota_1$ from $E$ into its completion $\tilde E$ and the linear isometry $\iota_2$ from $\tilde E$ into its dual $\tilde E'$ ...,Let or and be a normed -vector space. Can we show that there is a linear isometry from into or is there a counterexample? I think this should be true: My idea is that we should be able to consider the linear isometry from into its completion and the linear isometry from into its dual ...,\mathbb K=\mathbb R \mathbb K=\mathbb C E \mathbb K E E' \iota_1 E \tilde E \iota_2 \tilde E \tilde E',"['functional-analysis', 'dual-spaces']"
73,A question about functional in normed space and Hahn Banach theory,A question about functional in normed space and Hahn Banach theory,,"Let $X\neq {0}$ a normed space, $x_n\in X$ a sequence in $X,x\in X$ . Assume for every $x^*\in X^*$ : $x^*(x_n)\to x^*x$ . Show that: $\|x\|\leq \liminf_{n\to \infty} \|x_n\|$ . I tried to use Hahn Banach's corollary that says: If $X$ is a normed space and $0\neq x\in X$ , there is a functional $x^*\in X$ such that $\|x^*\|=1$ and $x^*x=\|x\|$ . We can notice that $x$ that satisfies $x^*(x_n)\to x^*x$ is unique. Because $X\neq 0$ then the $x$ satisfying this is $\neq 0$ . Then, by the corollary mentioned above and the given information we get: $$\|x\|=x^*x=\lim_{n\to \infty} x^*x_n.$$ Now, how can I use the fact that $\|x^*\|=1$ ?","Let a normed space, a sequence in . Assume for every : . Show that: . I tried to use Hahn Banach's corollary that says: If is a normed space and , there is a functional such that and . We can notice that that satisfies is unique. Because then the satisfying this is . Then, by the corollary mentioned above and the given information we get: Now, how can I use the fact that ?","X\neq {0} x_n\in X X,x\in X x^*\in X^* x^*(x_n)\to x^*x \|x\|\leq \liminf_{n\to \infty} \|x_n\| X 0\neq x\in X x^*\in X \|x^*\|=1 x^*x=\|x\| x x^*(x_n)\to x^*x X\neq 0 x \neq 0 \|x\|=x^*x=\lim_{n\to \infty} x^*x_n. \|x^*\|=1","['real-analysis', 'functional-analysis', 'hahn-banach-theorem']"
74,Duality pairing between finite signed measures and bounded continuous functions,Duality pairing between finite signed measures and bounded continuous functions,,"Let $E$ be a metric space, $C_b(E)$ denote the set of real-valued bounded continuous functions on $E$ and $\mathcal M(E)$ denote the set of finite signed measures on $\mathcal B(E)$ . How can we show that $$\langle f,\mu\rangle:=\int f\:{\rm d}\mu\;\;\;\text{for }(f,\mu)\in C_b(E)\times\mathcal M(E)$$ is a duality pairing between $C_b(E)$ and $\mathcal M(E)$ ? Do we need impose further restrictions on $E$ (e.g. completeness and/or separability) and/or $\mathcal M(E)$ (e.g. regularity of the measures)? We need to show that \begin{align}\forall f\in C_b(E)\setminus\{0\}&:\exists\mu\in\mathcal M(E)&:\langle f,\mu\rangle\ne0\tag1;\\\forall\mu\in\mathcal M(E)\setminus\{0\}&:\exists f\in C_b(E)&:\langle f,\mu\rangle\ne0\tag2.\end{align} $(1)$ Should be easy. If $f\in C_b(E)\setminus\{0\}$ , there is a $x\in E$ with $f(x)\ne 0$ . Now we can choose $\mu$ to be the Dirac measure $\delta_x$ concentrated at $x$ and obtain $\langle f,\mu\rangle=f(x)\ne0$ . But how can we show $(2)$ ?","Let be a metric space, denote the set of real-valued bounded continuous functions on and denote the set of finite signed measures on . How can we show that is a duality pairing between and ? Do we need impose further restrictions on (e.g. completeness and/or separability) and/or (e.g. regularity of the measures)? We need to show that Should be easy. If , there is a with . Now we can choose to be the Dirac measure concentrated at and obtain . But how can we show ?","E C_b(E) E \mathcal M(E) \mathcal B(E) \langle f,\mu\rangle:=\int f\:{\rm d}\mu\;\;\;\text{for }(f,\mu)\in C_b(E)\times\mathcal M(E) C_b(E) \mathcal M(E) E \mathcal M(E) \begin{align}\forall f\in C_b(E)\setminus\{0\}&:\exists\mu\in\mathcal M(E)&:\langle f,\mu\rangle\ne0\tag1;\\\forall\mu\in\mathcal M(E)\setminus\{0\}&:\exists f\in C_b(E)&:\langle f,\mu\rangle\ne0\tag2.\end{align} (1) f\in C_b(E)\setminus\{0\} x\in E f(x)\ne 0 \mu \delta_x x \langle f,\mu\rangle=f(x)\ne0 (2)","['functional-analysis', 'probability-theory', 'measure-theory']"
75,"Extend an integral inequality from $C[0,1]$ to the whole $L^{2}([0,1])$ [related to operator norm].",Extend an integral inequality from  to the whole  [related to operator norm].,"C[0,1] L^{2}([0,1])","Consider the following integral defined for $f\in L^{2}[0,1]$ and $x\in [0,1]$ , that $$(T^{n}f)(x)=\dfrac{1}{(n-1)!}\int_{0}^{x}(x-r)^{n-1}f(r)dr.$$ This shows that for $f\in C[0,1]$ and for any $x\in [0,1]$ , we have $$|(T^{n}f)(x)|\leq \dfrac{1}{(n-1)!}\int_{0}^{x}(x-r)^{n-1}|f(r)|dr\leq \dfrac{\|f\|_{\infty}}{n!}.$$ By definition of operator norm, this implies that the operator norm of $T^{n}$ $$\|T^{n}\|\leq \dfrac{1}{n!},$$ if the operator is on $C[0,1]$ . However, I want to prove the same bound of this operator norm on the whole $L^{2}([0,1])$ .  Is there anyway for me to extend this proof to all of $f\in L^{2}([0,1])$ ? and to conclude $\|T^{n}\|\leq\frac{1}{n!}$ My attempt was to use density of continuous function of compact support in $L^{2}$ to find $g$ such that $f=g+\epsilon$ where $\epsilon>0$ is arbitrarily fixed. Then we bound the integral in the same way, and you will have a summation, the second term in the summation will go to $0$ when $\epsilon\searrow 0$ . Therefore, we again have $$|(T^{n}f)(x)|\dfrac{\|g\|_{\infty}}{n!}.$$ But this cannot say anything to the operator norm $\|T\|$ . What should I do? Thank you! Edit: The overall purpose is to derive that $\|T\|\leq\frac{1}{n!}$ . So if there is any other way to find this, it will also be really good. Edit2: Proof Okay, I confused myself in the first place. The operator norm has nothing to do with the sup-norm since $T:L^{2}\longrightarrow L^{2}$ , so what we should do is to use Cauchy-Schwarz and $\|f\|_{L^{2}}$ . See below my own answer to my post for details. Also, Ruy gave a general theorem about how to compute the operator norm for Hilbert-Schmidt operator, and my computation will show you the idea about the proof. Basically, the absolute value of operator will be bounded by $\|f\|_{L^{2}}$ multiplication of the $L^{2}-$ integral of the kernel, so we should expect such a theorem. Thank you so much for all the users who helped me!!","Consider the following integral defined for and , that This shows that for and for any , we have By definition of operator norm, this implies that the operator norm of if the operator is on . However, I want to prove the same bound of this operator norm on the whole .  Is there anyway for me to extend this proof to all of ? and to conclude My attempt was to use density of continuous function of compact support in to find such that where is arbitrarily fixed. Then we bound the integral in the same way, and you will have a summation, the second term in the summation will go to when . Therefore, we again have But this cannot say anything to the operator norm . What should I do? Thank you! Edit: The overall purpose is to derive that . So if there is any other way to find this, it will also be really good. Edit2: Proof Okay, I confused myself in the first place. The operator norm has nothing to do with the sup-norm since , so what we should do is to use Cauchy-Schwarz and . See below my own answer to my post for details. Also, Ruy gave a general theorem about how to compute the operator norm for Hilbert-Schmidt operator, and my computation will show you the idea about the proof. Basically, the absolute value of operator will be bounded by multiplication of the integral of the kernel, so we should expect such a theorem. Thank you so much for all the users who helped me!!","f\in L^{2}[0,1] x\in [0,1] (T^{n}f)(x)=\dfrac{1}{(n-1)!}\int_{0}^{x}(x-r)^{n-1}f(r)dr. f\in C[0,1] x\in [0,1] |(T^{n}f)(x)|\leq \dfrac{1}{(n-1)!}\int_{0}^{x}(x-r)^{n-1}|f(r)|dr\leq \dfrac{\|f\|_{\infty}}{n!}. T^{n} \|T^{n}\|\leq \dfrac{1}{n!}, C[0,1] L^{2}([0,1]) f\in L^{2}([0,1]) \|T^{n}\|\leq\frac{1}{n!} L^{2} g f=g+\epsilon \epsilon>0 0 \epsilon\searrow 0 |(T^{n}f)(x)|\dfrac{\|g\|_{\infty}}{n!}. \|T\| \|T\|\leq\frac{1}{n!} T:L^{2}\longrightarrow L^{2} \|f\|_{L^{2}} \|f\|_{L^{2}} L^{2}-","['real-analysis', 'functional-analysis', 'inequality', 'operator-theory', 'lp-spaces']"
76,How to prove $L^{\infty}(\mathbb R) \cap L^{1} (\mathbb R) \subset L^{2}(\mathbb R)$,How to prove,L^{\infty}(\mathbb R) \cap L^{1} (\mathbb R) \subset L^{2}(\mathbb R),"How to prove $$L^{\infty}(\mathbb R) \cap L^{1} (\mathbb R) \subset L^{2}(\mathbb R),$$ $\mathbb R$ being the real value domain. Why is it that having the function upper-bounded and lower bounded with integrability allows the square to be integrable. L of course are Lp norms for functions.",How to prove being the real value domain. Why is it that having the function upper-bounded and lower bounded with integrability allows the square to be integrable. L of course are Lp norms for functions.,"L^{\infty}(\mathbb R) \cap L^{1} (\mathbb R) \subset L^{2}(\mathbb R), \mathbb R","['functional-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'lp-spaces']"
77,Any linear operator $T$ satisfies $\lvert \lvert T x \rvert \rvert = \lvert \lvert T \rvert \rvert \cdot \lvert \lvert x \rvert \rvert$,Any linear operator  satisfies,T \lvert \lvert T x \rvert \rvert = \lvert \lvert T \rvert \rvert \cdot \lvert \lvert x \rvert \rvert,"Let $(X,\lvert \lvert \cdot \rvert \rvert_{X})$ and $(Y,\lvert \lvert \cdot \rvert \rvert _{Y})$ and $X$ be finite dimensional, then show that any linear operator $T$ satisfies $\lvert \lvert T x \rvert \rvert = \lvert \lvert T \rvert \rvert \cdot \lvert \lvert x \rvert \rvert$ for some $x \neq 0$ . My idea: I have shown that $T$ is bounded, now let us assume that for any $x \neq 0$ we have $\lvert \lvert Tx\rvert \rvert < \lvert \lvert T\rvert \rvert \cdot \lvert \lvert x \rvert \rvert$ , then: we have $\lvert \lvert T(\frac{x}{\lvert \lvert x \rvert \rvert})\rvert \rvert < \lvert \lvert T \rvert \rvert$ for all $x \neq 0$ . But at the same time $\{ \frac{x}{\lvert \lvert x \rvert \rvert}: x \neq 0\}=\partial B_{1}(0)$ and $\lvert \lvert T \rvert \rvert=\sup\limits_{ x \in \partial B_{1}(0)}\lvert \lvert Tx\rvert \rvert_{Y}$ So we can construct a sequence $(x_{n})_{n}\subseteq \partial B_{1}(0)$ such that $\lim\limits_{n \to \infty}\lvert \lvert Tx_{n}\rvert \rvert _{Y}=\lvert \lvert T\rvert \rvert$ Since $\dim X<\infty$ , we know that the closed unit ball $\overline{B_{1}^{X}(0)}$ is compact and hence $\partial B_{1}(0)$ is compact since it is closed and a subset. Thus there exists a convergent subsequence $(x_{n(k)})_{k \in \mathbb N}$ of $(x_{n})_{n \in \mathbb N}$ and $x \in \partial B_{1}(0)$ such that $\lim\limits_{k \to \infty}x_{n(k)}=x$ . By the boundedness of $T$ and thus the continuity, it must follow that $\lim\limits_{k \to \infty}\lvert \lvert Tx_{n(k)}\rvert\rvert_{Y}=\lvert\lvert Tx\rvert\rvert_{Y}$ and thus $$\lvert \lvert Tx\rvert \rvert _{Y}=\lim\limits_{k \to \infty}\lvert \lvert Tx_{n(k)}\rvert \rvert _{Y}=\lim\limits_{n \to \infty}\lvert \lvert Tx_{n}\rvert \rvert _{Y}=\lvert \lvert T\rvert \rvert$$ which is a contradiction since $x \in \partial B_{1}(0)$","Let and and be finite dimensional, then show that any linear operator satisfies for some . My idea: I have shown that is bounded, now let us assume that for any we have , then: we have for all . But at the same time and So we can construct a sequence such that Since , we know that the closed unit ball is compact and hence is compact since it is closed and a subset. Thus there exists a convergent subsequence of and such that . By the boundedness of and thus the continuity, it must follow that and thus which is a contradiction since","(X,\lvert \lvert \cdot \rvert \rvert_{X}) (Y,\lvert \lvert \cdot \rvert \rvert _{Y}) X T \lvert \lvert T x \rvert \rvert = \lvert \lvert T \rvert \rvert \cdot \lvert \lvert x \rvert \rvert x \neq 0 T x \neq 0 \lvert \lvert Tx\rvert \rvert < \lvert \lvert T\rvert \rvert \cdot \lvert \lvert x \rvert \rvert \lvert \lvert T(\frac{x}{\lvert \lvert x \rvert \rvert})\rvert \rvert < \lvert \lvert T \rvert \rvert x \neq 0 \{ \frac{x}{\lvert \lvert x \rvert \rvert}: x \neq 0\}=\partial B_{1}(0) \lvert \lvert T \rvert \rvert=\sup\limits_{ x \in \partial B_{1}(0)}\lvert \lvert Tx\rvert \rvert_{Y} (x_{n})_{n}\subseteq \partial B_{1}(0) \lim\limits_{n \to \infty}\lvert \lvert Tx_{n}\rvert \rvert _{Y}=\lvert \lvert T\rvert \rvert \dim X<\infty \overline{B_{1}^{X}(0)} \partial B_{1}(0) (x_{n(k)})_{k \in \mathbb N} (x_{n})_{n \in \mathbb N} x \in \partial B_{1}(0) \lim\limits_{k \to \infty}x_{n(k)}=x T \lim\limits_{k \to \infty}\lvert \lvert Tx_{n(k)}\rvert\rvert_{Y}=\lvert\lvert Tx\rvert\rvert_{Y} \lvert \lvert Tx\rvert \rvert _{Y}=\lim\limits_{k \to \infty}\lvert \lvert Tx_{n(k)}\rvert \rvert _{Y}=\lim\limits_{n \to \infty}\lvert \lvert Tx_{n}\rvert \rvert _{Y}=\lvert \lvert T\rvert \rvert x \in \partial B_{1}(0)","['real-analysis', 'sequences-and-series', 'functional-analysis', 'solution-verification']"
78,A problem about Riesz's Lemma,A problem about Riesz's Lemma,,"I am thinking in this problem: If $E$ is a normed space and $M\subseteq E$ is a subspace of finite dimension, prove that for all $x\in E-M$ there exists $m_0\in M$ such that $d(x,M)=\|x-m_0\|$ . I am trying to apply Riesz's Theorem because $M$ is a closed space (finite dimensional), but I don't know how....","I am thinking in this problem: If is a normed space and is a subspace of finite dimension, prove that for all there exists such that . I am trying to apply Riesz's Theorem because is a closed space (finite dimensional), but I don't know how....","E M\subseteq E x\in E-M m_0\in M d(x,M)=\|x-m_0\| M","['functional-analysis', 'metric-spaces']"
79,"Vector Spaces, Normed Vector Spaces and Metric spaces","Vector Spaces, Normed Vector Spaces and Metric spaces",,"I've already studied real analysis and I've just finished studying linear algebra (the source I've used did not cover norms, but I have some basic understanding about them). Now I know that there are normed vector spaces and they have a lot of applications. From my understanding the reason for defining them is that it is a way to give a vector space some additional structure to be able to consider things like convergence and continuity. This is because a norm induces a metric, and therefore all the metric space theorems are applicable. Now I've got two questions: 1) Although I can mathematically understand that a norm induces a metric and it also intuitively makes sense in euclidean spaces since the norm can be interpreted as length which makes the connection to the metric or distance obvious (We can just draw two vectors in $\mathbb{R}^{2}$ and then it is easy to see the that the relation follows by the Pythagorean Theorem.) However, I was wondering why this holds for any normed vector space. In general, the norm can be seen as magnitude or size of an object while the metric measures similarity. Can someone give me an intuition about the connection between norm and metric in a broader context? 2) As mentioned above the ultimate goal of defining the norm is to introduce a metric space structure. I've read different posts on this topic and it seems that we want ""the metric space structure to play nice with the vector space structure"" ( Metric spaces and normed vector spaces ). Can someone give me an example of an application where this goes wrong and what the consequences are? Translation invariance and homogeneity seem to be important properties for this ( What's the need of defining notion of distance using norm function in a metric space? ).","I've already studied real analysis and I've just finished studying linear algebra (the source I've used did not cover norms, but I have some basic understanding about them). Now I know that there are normed vector spaces and they have a lot of applications. From my understanding the reason for defining them is that it is a way to give a vector space some additional structure to be able to consider things like convergence and continuity. This is because a norm induces a metric, and therefore all the metric space theorems are applicable. Now I've got two questions: 1) Although I can mathematically understand that a norm induces a metric and it also intuitively makes sense in euclidean spaces since the norm can be interpreted as length which makes the connection to the metric or distance obvious (We can just draw two vectors in and then it is easy to see the that the relation follows by the Pythagorean Theorem.) However, I was wondering why this holds for any normed vector space. In general, the norm can be seen as magnitude or size of an object while the metric measures similarity. Can someone give me an intuition about the connection between norm and metric in a broader context? 2) As mentioned above the ultimate goal of defining the norm is to introduce a metric space structure. I've read different posts on this topic and it seems that we want ""the metric space structure to play nice with the vector space structure"" ( Metric spaces and normed vector spaces ). Can someone give me an example of an application where this goes wrong and what the consequences are? Translation invariance and homogeneity seem to be important properties for this ( What's the need of defining notion of distance using norm function in a metric space? ).",\mathbb{R}^{2},"['real-analysis', 'linear-algebra', 'functional-analysis', 'vector-spaces', 'examples-counterexamples']"
80,"If the operator $T$ is defined by $Tf(x)=\int_0^xf(t)\,dt$, show that $Tf \in C[0,1]$","If the operator  is defined by , show that","T Tf(x)=\int_0^xf(t)\,dt Tf \in C[0,1]","Consider the operator $T$ on $L^2[0,1]$ defined by $Tf(x)=\displaystyle \int_0^xf(t)\,dt.$ Show that $Tf \in C[0,1].$ I have one question before this: What are the implications between $L^p$ spaces, i.e if $f \in L^p$ does this imply that $f \in L^{p+1}$ ? My attempt: Assume $Tf$ is not in $C[0,1]$ , so there exists $y \in [0,1]$ and $\epsilon>0$ such that for all $\delta >0$ , we can find $x_0$ , with $|x-x_0|<\delta$ but $$\bigg\rVert\int_0^x f-\int_0^{x_0} f\,\bigg\rVert>\epsilon$$ WLOG assume $x>x_0$ , so $$\bigg\lVert \int_{x_0}^x f\,\bigg\rVert \geq \epsilon.$$ So for $\delta_n=\frac{1}{n},$ we can find $x_n \in [0,1]$ such that $|x-x_0|<\frac{1}{n}$ and $$\bigg\lVert\int_{x_n}^xf\,\bigg\rVert \geq \epsilon$$ I don't know if that will lead me to a contradiction. I would appreciate any help or hints with that.","Consider the operator on defined by Show that I have one question before this: What are the implications between spaces, i.e if does this imply that ? My attempt: Assume is not in , so there exists and such that for all , we can find , with but WLOG assume , so So for we can find such that and I don't know if that will lead me to a contradiction. I would appreciate any help or hints with that.","T L^2[0,1] Tf(x)=\displaystyle \int_0^xf(t)\,dt. Tf \in C[0,1]. L^p f \in L^p f \in L^{p+1} Tf C[0,1] y \in [0,1] \epsilon>0 \delta >0 x_0 |x-x_0|<\delta \bigg\rVert\int_0^x f-\int_0^{x_0} f\,\bigg\rVert>\epsilon x>x_0 \bigg\lVert \int_{x_0}^x f\,\bigg\rVert \geq \epsilon. \delta_n=\frac{1}{n}, x_n \in [0,1] |x-x_0|<\frac{1}{n} \bigg\lVert\int_{x_n}^xf\,\bigg\rVert \geq \epsilon","['real-analysis', 'functional-analysis', 'measure-theory', 'operator-theory']"
81,When is this estimate about L2-norms true?,When is this estimate about L2-norms true?,,"Let $f$ be a function in $L^2(U)$ where $U$ is some (not necessarily bounded) domain. For example, if $f$ is bounded, then for all $g \in L^2(U)$ , $$\|fg\|_{L^2(U)} \leq \|f\|_{\infty}\|g\|_{L^2(U)} = C\|g\|_{L^2(U)}. $$ Are there any other cases when this is true (i.e $f$ not necessarily bounded) or is this a necessary assumption?","Let be a function in where is some (not necessarily bounded) domain. For example, if is bounded, then for all , Are there any other cases when this is true (i.e not necessarily bounded) or is this a necessary assumption?",f L^2(U) U f g \in L^2(U) \|fg\|_{L^2(U)} \leq \|f\|_{\infty}\|g\|_{L^2(U)} = C\|g\|_{L^2(U)}.  f,"['functional-analysis', 'lp-spaces']"
82,What is the weak closure of $C_c(X)$ in $C_b(X)$?,What is the weak closure of  in ?,C_c(X) C_b(X),"Given a locally compact Hausdorff space $X$ , let $C_b(X)$ denote the bounded continuous functions with sup norm and $C_c(X)$ denote the continuous functions with compact support. I was wondering what the closure of $C_c(X)$ looks like in the weak topology i.e. topology induced by $C_b(X)^*$ . I am not sure if this is obvious, but I would appreciate any help on this, thanks!","Given a locally compact Hausdorff space , let denote the bounded continuous functions with sup norm and denote the continuous functions with compact support. I was wondering what the closure of looks like in the weak topology i.e. topology induced by . I am not sure if this is obvious, but I would appreciate any help on this, thanks!",X C_b(X) C_c(X) C_c(X) C_b(X)^*,"['general-topology', 'functional-analysis', 'banach-spaces']"
83,Sequence Lemma and statistical convergence,Sequence Lemma and statistical convergence,,"We know that from the sequence lemma : if a sequence $\{x_n\}$ in $A$ converges to $\ell$ , then $\ell\in \bar A$ . Conversely, if the space is first countable, then $\ell\in \bar A$ implies that $\exists$ a sequence $\{x_n\}$ in $A$ converges to $\ell$ . Also, every convergent sequence is statistically convergent sequence (and in this case limits & statistical limits are same). But the converse isn't true. My question : If a sequence $\{x_n\}$ in $A$ converges statistically to $\ell$ , does $\ell$ belong to $\bar A$ ? Thanks in advance.","We know that from the sequence lemma : if a sequence in converges to , then . Conversely, if the space is first countable, then implies that a sequence in converges to . Also, every convergent sequence is statistically convergent sequence (and in this case limits & statistical limits are same). But the converse isn't true. My question : If a sequence in converges statistically to , does belong to ? Thanks in advance.",\{x_n\} A \ell \ell\in \bar A \ell\in \bar A \exists \{x_n\} A \ell \{x_n\} A \ell \ell \bar A,"['sequences-and-series', 'general-topology', 'functional-analysis', 'convergence-divergence']"
84,Is this space equivalent to the James space?,Is this space equivalent to the James space?,,"The James space $J$ is a famous counter-example in functional analysis. It is an example of a Banach space that is isometrically isomorphic to its double dual, but is not reflexive. Define $$J = \big\{ (a_n) \in c_0\, \big|\, |(a_n)|_J < \infty \big\}$$ where $c_0$ denotes the subspace of $l^{\infty}$ of sequences converging to $0$ and $$|a_n|_J^2 := \sup\left\{ \sum\nolimits_{i=1}^{k-1} | a_{p_{i+1}} - a_{p_i}|^2 \; \big| \; 1 \leq p_1 < \ldots < p_k \right\} $$ where the supremum is taken over all finite increasing subsequences of $\mathbb{N}$ . How is this different from requiring that $\sum_{n=1}^{\infty}|a_{n+1} - a_n|^2 < \infty$ ?","The James space is a famous counter-example in functional analysis. It is an example of a Banach space that is isometrically isomorphic to its double dual, but is not reflexive. Define where denotes the subspace of of sequences converging to and where the supremum is taken over all finite increasing subsequences of . How is this different from requiring that ?","J J = \big\{ (a_n) \in c_0\, \big|\, |(a_n)|_J < \infty \big\} c_0 l^{\infty} 0 |a_n|_J^2 := \sup\left\{ \sum\nolimits_{i=1}^{k-1} | a_{p_{i+1}} - a_{p_i}|^2 \; \big| \; 1 \leq p_1 < \ldots < p_k \right\}  \mathbb{N} \sum_{n=1}^{\infty}|a_{n+1} - a_n|^2 < \infty","['real-analysis', 'functional-analysis', 'banach-spaces', 'normed-spaces']"
85,Is there an accepted notation for the $n$th sum/integral of a function?,Is there an accepted notation for the th sum/integral of a function?,n,"I'm working on a thesis in image processing at the moment, and wanted to include a portion concerning the methodology for n dimension images (it will include a fully write up and functioning code for 2D and 3D images), and that would involve taking the $n$ th integral of a function of $n$ variables, which in this case would mean the nth sum. For the sum portion, it would something like the sum of $x_1$ from $0$ to $M$ , then the sum of $x_1$ from $0$ to $M$ , and so on with a total of of $N$ summations. Is there any sort of widely accepted convention for annotating this, or should I just put something like sum1 of sum2 /dots then the last sum? edit: specific examples (sorry, didn't know you could use LaTeX here): 2D: $$\sum_{x_1=0}^M \sum_{x_2=0}^M f(x_1,x_2)$$ 3D: $$\sum_{x_1=0}^M \sum_{x_2=0}^M \sum_{x_3=0}^M f(x_1,x_2,x_3)$$ Is there a nicer way to express something like: $$\sum_{x_1=0}^M \sum_{x_2=0}^M \dots \sum_{x_n=0}^M f(x_1,x_2,\dots,x_n)$$","I'm working on a thesis in image processing at the moment, and wanted to include a portion concerning the methodology for n dimension images (it will include a fully write up and functioning code for 2D and 3D images), and that would involve taking the th integral of a function of variables, which in this case would mean the nth sum. For the sum portion, it would something like the sum of from to , then the sum of from to , and so on with a total of of summations. Is there any sort of widely accepted convention for annotating this, or should I just put something like sum1 of sum2 /dots then the last sum? edit: specific examples (sorry, didn't know you could use LaTeX here): 2D: 3D: Is there a nicer way to express something like:","n n x_1 0 M x_1 0 M N \sum_{x_1=0}^M \sum_{x_2=0}^M f(x_1,x_2) \sum_{x_1=0}^M \sum_{x_2=0}^M \sum_{x_3=0}^M f(x_1,x_2,x_3) \sum_{x_1=0}^M \sum_{x_2=0}^M \dots \sum_{x_n=0}^M f(x_1,x_2,\dots,x_n)","['integration', 'functional-analysis', 'summation']"
86,Equivalent definition of Schwartz space,Equivalent definition of Schwartz space,,"Please tell me about the equivalent definition of schwartz space. Definition of Schwartz space is the following. $$ f(x) \in \mathcal{S} \overset {\mathrm{def}} {\Leftrightarrow} \displaystyle \sup_{x \in \mathbb{R^d} } \left|x^\alpha\partial^\beta_x f(x)\right| < \infty $$ $\forall$$\alpha,\forall$$\beta$ $\in$ $\mathbb{Z^d_+} $ ( $\alpha,\beta$ is multi-index notation) My textbook is written the following statement. $$ \displaystyle \sup_{x \in \mathbb{R^d} } \left|x^\alpha\partial^\beta_x f(x)\right| < \infty\Leftrightarrow \displaystyle \sup_{x \in \mathbb{R^d} } \left|\partial^\alpha_x (x^\beta f(x))\right| < \infty $$ I have proved $\Rightarrow$ by using Leibniz's rule. But I haven't proved $\Leftarrow$ . Please tell me proof $\Leftarrow$ .",Please tell me about the equivalent definition of schwartz space. Definition of Schwartz space is the following. ( is multi-index notation) My textbook is written the following statement. I have proved by using Leibniz's rule. But I haven't proved . Please tell me proof .," f(x) \in \mathcal{S} \overset {\mathrm{def}} {\Leftrightarrow} \displaystyle \sup_{x \in \mathbb{R^d} } \left|x^\alpha\partial^\beta_x f(x)\right| < \infty  \forall\alpha,\forall\beta \in \mathbb{Z^d_+}  \alpha,\beta  \displaystyle \sup_{x \in \mathbb{R^d} } \left|x^\alpha\partial^\beta_x f(x)\right| < \infty\Leftrightarrow \displaystyle \sup_{x \in \mathbb{R^d} } \left|\partial^\alpha_x (x^\beta f(x))\right| < \infty  \Rightarrow \Leftarrow \Leftarrow","['functional-analysis', 'fourier-analysis', 'fourier-transform', 'distribution-theory', 'schwartz-space']"
87,Prove the norm of operator derived from orthogonal projections is less or equal to 1,Prove the norm of operator derived from orthogonal projections is less or equal to 1,,Suppose $H$ is a Hilbert space. We have two orthogonal projections $P_1: H\rightarrow A_1$ and $P_2: H\rightarrow A_2$ . Here $A_1$ and $A_2$ are two closed subspace of $H$ . Prove that $$ \lVert P_1 - P_2\rVert \le 1 $$ Any hints may help. Thank you.,Suppose is a Hilbert space. We have two orthogonal projections and . Here and are two closed subspace of . Prove that Any hints may help. Thank you.,"H P_1: H\rightarrow A_1 P_2: H\rightarrow A_2 A_1 A_2 H 
\lVert P_1 - P_2\rVert \le 1
","['linear-algebra', 'functional-analysis']"
88,Is this differential operator Hermitian?,Is this differential operator Hermitian?,,"The operator is $$\hat{A} = -i \left(x \frac{d}{dx} + \frac{1}{2} \right).$$ Is it true that $$\langle \hat{A} \psi_1(x)|\psi_2(x)\rangle = \langle \psi_1(x)|\hat{A}\psi_2(x)\rangle\ ?$$ Here, $\langle\ldots|\ldots\rangle$ is a scalar product defined as $$\langle\psi_1(x)|\psi_2(x)\rangle = \int_{\Omega} \psi_1(x) \psi_2^*(x) \ dx.$$","The operator is Is it true that Here, is a scalar product defined as",\hat{A} = -i \left(x \frac{d}{dx} + \frac{1}{2} \right). \langle \hat{A} \psi_1(x)|\psi_2(x)\rangle = \langle \psi_1(x)|\hat{A}\psi_2(x)\rangle\ ? \langle\ldots|\ldots\rangle \langle\psi_1(x)|\psi_2(x)\rangle = \int_{\Omega} \psi_1(x) \psi_2^*(x) \ dx.,"['functional-analysis', 'physics', 'quantum-mechanics', 'adjoint-operators', 'differential-operators']"
89,triple dual space and more and more,triple dual space and more and more,,"Let $X$ be a normed space. And Define $X^{(n)}$ by $X^{\overbrace{*****....}^{n\ times}}$ where $X^*$ means the dual space of $X$ My question is : Is there some space $X$ such that a sequence with the initial space $X$ get bigger and bigger infinitely? i.e for all $n>m$ , $X^{(n)}>X^{(n)}$ or, indepedent of choice of $X$ , does $X^{(n)}$ become a reflexive space for some $n$ ?. I'm very wondering this, but I don't know how to search about this. Please let me know some results, search-keyword or anything about this.","Let be a normed space. And Define by where means the dual space of My question is : Is there some space such that a sequence with the initial space get bigger and bigger infinitely? i.e for all , or, indepedent of choice of , does become a reflexive space for some ?. I'm very wondering this, but I don't know how to search about this. Please let me know some results, search-keyword or anything about this.",X X^{(n)} X^{\overbrace{*****....}^{n\ times}} X^* X X X n>m X^{(n)}>X^{(n)} X X^{(n)} n,"['functional-analysis', 'dual-spaces']"
90,Is a linear operator continuous if its kernel is closed?,Is a linear operator continuous if its kernel is closed?,,Let $T$ be a linear operator between two infinite dimensional normed spaces $X$ and $Y$ whose kernel is a closed subset of its domain. Does it imply that $T$ is bounded or not necessary ? If yes I would be very grateful if one could mention the proof. If no it would be better if a counter-example were provided.,Let be a linear operator between two infinite dimensional normed spaces and whose kernel is a closed subset of its domain. Does it imply that is bounded or not necessary ? If yes I would be very grateful if one could mention the proof. If no it would be better if a counter-example were provided.,T X Y T,['functional-analysis']
91,Arzelà–Ascoli theorem for the space $C_b^k(\overline{\Omega})$,Arzelà–Ascoli theorem for the space,C_b^k(\overline{\Omega}),"Let $S \subseteq \mathbb{R}^m$ and $C_b^k(S)$, for $k \in \mathbb{N}$,  the set of continuous functions from $S$ to $\mathbb{R}$ with bounded and continuous partial derivatives of any order $\leq k$. I need to show that if $\Omega \subseteq \mathbb{R}^m$ is a bounded open set, $\{ u_n\}_n \subseteq  C_b^k(\overline{\Omega})  $ is bounded in $C_b^k(\overline{\Omega})$, then there is a subsequence of $\{ u_n\}_n$ which converges in $C_b^k(\overline{\Omega})$ and hence in $H^k(\Omega)$. The norm in $C_b^k(\overline{\Omega})$ is $$||u||_{k, \infty}:= \max_{|\alpha| \leq k}||D^{\alpha}u||_{\infty} $$ There is a hint: use Arzelà–Ascoli theorem. But I don't know how can I use that theorem for that sequence and why convergence in $C_b^k(\overline{\Omega})$ implies convergence in $H^k(\Omega)$. I know that in this case Arzelà–Ascoli theorem implies convergence of a subsequence in $C_b(\overline{\Omega})$, but how can I guarantee convergence in $C_b^k(\overline{\Omega})$?. Can you help me, please?","Let $S \subseteq \mathbb{R}^m$ and $C_b^k(S)$, for $k \in \mathbb{N}$,  the set of continuous functions from $S$ to $\mathbb{R}$ with bounded and continuous partial derivatives of any order $\leq k$. I need to show that if $\Omega \subseteq \mathbb{R}^m$ is a bounded open set, $\{ u_n\}_n \subseteq  C_b^k(\overline{\Omega})  $ is bounded in $C_b^k(\overline{\Omega})$, then there is a subsequence of $\{ u_n\}_n$ which converges in $C_b^k(\overline{\Omega})$ and hence in $H^k(\Omega)$. The norm in $C_b^k(\overline{\Omega})$ is $$||u||_{k, \infty}:= \max_{|\alpha| \leq k}||D^{\alpha}u||_{\infty} $$ There is a hint: use Arzelà–Ascoli theorem. But I don't know how can I use that theorem for that sequence and why convergence in $C_b^k(\overline{\Omega})$ implies convergence in $H^k(\Omega)$. I know that in this case Arzelà–Ascoli theorem implies convergence of a subsequence in $C_b(\overline{\Omega})$, but how can I guarantee convergence in $C_b^k(\overline{\Omega})$?. Can you help me, please?",,"['functional-analysis', 'sobolev-spaces', 'arzela-ascoli']"
92,Identifying $\int_{-\infty}^\infty e^{i k x} dx$ as Dirac delta distribution,Identifying  as Dirac delta distribution,\int_{-\infty}^\infty e^{i k x} dx,"The expression $\int_{-\infty}^\infty e^{i k x} dx$ is sometimes identified as the Dirac delta function. This identification is said ""formal"" or ""symbolic"", and some physics texts say that the theory of distribution makes this identification rigorous. So I read some texts on distributions and I think now I understand what delta function is as a distribution. However, I still cannot give any meaninig on the expression as a distribution. Is it possible to give a well defined meaning as a mathematical object to the expression?","The expression $\int_{-\infty}^\infty e^{i k x} dx$ is sometimes identified as the Dirac delta function. This identification is said ""formal"" or ""symbolic"", and some physics texts say that the theory of distribution makes this identification rigorous. So I read some texts on distributions and I think now I understand what delta function is as a distribution. However, I still cannot give any meaninig on the expression as a distribution. Is it possible to give a well defined meaning as a mathematical object to the expression?",,"['functional-analysis', 'partial-differential-equations', 'distribution-theory', 'fourier-transform', 'dirac-delta']"
93,How to derive Riemann-Lebesgue lemma from Bessel inequility?,How to derive Riemann-Lebesgue lemma from Bessel inequility?,,"I encountered Riemann-Lebesgue Lemma in Functional Analysis. It can be viewed as a corrollary of Bessel inequtility in the following picture: However, I can't see why it is ' in particular ' ?  Can anyone give me some hint? My brain just short-circuit ...","I encountered Riemann-Lebesgue Lemma in Functional Analysis. It can be viewed as a corrollary of Bessel inequtility in the following picture: However, I can't see why it is ' in particular ' ?  Can anyone give me some hint? My brain just short-circuit ...",,"['real-analysis', 'functional-analysis', 'analysis']"
94,Is a small linear invertible perturbation of a linear isomorphism also an isomorphism?,Is a small linear invertible perturbation of a linear isomorphism also an isomorphism?,,"Suppose we have a linear isomorphism $T_{0}: \mathbb{R}^{n} \mapsto \mathbb{R}^{n}$, and $T_{\epsilon}$ is a small linear perturbation of it, i.e. $$T_{\epsilon} = T_{0} + \epsilon T_{1} + O(\epsilon^{2}),$$ where $T_{1}$ is also linear isomorphism and $0< | \epsilon | <<1$. Does it follow that $T_{\epsilon}$ is also an isomorphism? If so, I am  wondering is it possible to use an implicit function theorem for this, or can some result from perturbation theory of linear operators be used? (Note that this question comes from an earlier one: How do I set up Implicit Function Theorem to verify this function is a $C^{r}$ diffeomorphism? ) Thanks!","Suppose we have a linear isomorphism $T_{0}: \mathbb{R}^{n} \mapsto \mathbb{R}^{n}$, and $T_{\epsilon}$ is a small linear perturbation of it, i.e. $$T_{\epsilon} = T_{0} + \epsilon T_{1} + O(\epsilon^{2}),$$ where $T_{1}$ is also linear isomorphism and $0< | \epsilon | <<1$. Does it follow that $T_{\epsilon}$ is also an isomorphism? If so, I am  wondering is it possible to use an implicit function theorem for this, or can some result from perturbation theory of linear operators be used? (Note that this question comes from an earlier one: How do I set up Implicit Function Theorem to verify this function is a $C^{r}$ diffeomorphism? ) Thanks!",,"['linear-algebra', 'functional-analysis', 'operator-theory', 'linear-transformations', 'vector-space-isomorphism']"
95,"Is the unit sphere of $C[0,1]$ connected?",Is the unit sphere of  connected?,"C[0,1]","Let $C[0,1]$ be the space of all continuous functions on $[0,1]$. The induced norm of $C[0,1]$ is supremum norm, i.e $$\|f\|= \sup_{x\in[0,1]} f(x) .$$ Under this norm, $C[0,1]$ is a Banach space. Moreover, it is a Banach algebra with the multiplication being usual multiplication. My question is whether $S^1$, the unit sphere of $C[0,1]$, is connected or not.","Let $C[0,1]$ be the space of all continuous functions on $[0,1]$. The induced norm of $C[0,1]$ is supremum norm, i.e $$\|f\|= \sup_{x\in[0,1]} f(x) .$$ Under this norm, $C[0,1]$ is a Banach space. Moreover, it is a Banach algebra with the multiplication being usual multiplication. My question is whether $S^1$, the unit sphere of $C[0,1]$, is connected or not.",,"['general-topology', 'functional-analysis', 'normed-spaces', 'connectedness']"
96,How unboundedness of $\|T_n\|$ will imply that X is not complete?,How unboundedness of  will imply that X is not complete?,\|T_n\|,"I have to show that The normed space $X$ of all polynomials with norm defined by   $$\|x\|=\max\vert\alpha_j\vert$$ ($\alpha_0,\alpha_1,...$the   coefficients of $x$) "" is not complete using Uniform Boundedness theorem : Let $(T_n)$ be a sequence of bounded linear operators $T_n:  X\rightarrow Y$ from a Banach space $X$ into a normed space $Y$ such   that ($\|T_nx\|$) is bounded for every $x\in X$, say, $\|T_nx\|\le  c_x$  $n=1,2,···$ , where $c_x$  is a real number. Then the sequence   of the norms $\|T_n\|$ is bounded, that is, there is a c such that   $\|T_n\|\le c$ $n=1,2,··· $. I don't want the proof of the above claim.I just need to know How  unboundedness of $\|T_n\|$(What is the argument/statement/theorem) will imply that X is not complete?","I have to show that The normed space $X$ of all polynomials with norm defined by   $$\|x\|=\max\vert\alpha_j\vert$$ ($\alpha_0,\alpha_1,...$the   coefficients of $x$) "" is not complete using Uniform Boundedness theorem : Let $(T_n)$ be a sequence of bounded linear operators $T_n:  X\rightarrow Y$ from a Banach space $X$ into a normed space $Y$ such   that ($\|T_nx\|$) is bounded for every $x\in X$, say, $\|T_nx\|\le  c_x$  $n=1,2,···$ , where $c_x$  is a real number. Then the sequence   of the norms $\|T_n\|$ is bounded, that is, there is a c such that   $\|T_n\|\le c$ $n=1,2,··· $. I don't want the proof of the above claim.I just need to know How  unboundedness of $\|T_n\|$(What is the argument/statement/theorem) will imply that X is not complete?",,"['functional-analysis', 'metric-spaces', 'cauchy-sequences', 'complete-spaces']"
97,Is Lipschitz norm the other name for Lipschitz constant?,Is Lipschitz norm the other name for Lipschitz constant?,,I am seeing the term Lipschitz norm used in some papers and denoted by $$\|\cdot\|_{Lip}$$ Is it the other name for Lipschitz constant?,I am seeing the term Lipschitz norm used in some papers and denoted by $$\|\cdot\|_{Lip}$$ Is it the other name for Lipschitz constant?,,"['functional-analysis', 'terminology', 'lipschitz-functions']"
98,"Isometry between $C[a,b]$ and $C[0,1]$",Isometry between  and,"C[a,b] C[0,1]","I need to find isometry between two spaces of continuous functions $C[a,b]$ and $C[0,1]$ . That means to find function $ \phi\colon C[a,b] \longrightarrow C[0,1] $ which is bijection and $d_{\infty}(f,g)=d_{\infty}(\phi(f),\phi(g))$ . I know that there is bijection between $[a,b]$ and $[0,1]$ $y=(b-a)x +a$ . I have idea to every function $g(y) $ from $C[a,b]$ join function $g((b-a)x +a)$ from $C[0,1]$ . But I don't know how to prove that this is bijection. I would accept any other way of solving this.",I need to find isometry between two spaces of continuous functions and . That means to find function which is bijection and . I know that there is bijection between and . I have idea to every function from join function from . But I don't know how to prove that this is bijection. I would accept any other way of solving this.,"C[a,b] C[0,1]  \phi\colon C[a,b] \longrightarrow C[0,1]  d_{\infty}(f,g)=d_{\infty}(\phi(f),\phi(g)) [a,b] [0,1] y=(b-a)x +a g(y)  C[a,b] g((b-a)x +a) C[0,1]","['functional-analysis', 'metric-spaces', 'isometry']"
99,Is $\|e^{zT-zT^*}\|$ bounded for all $z\in \mathbb{C}$?,Is  bounded for all ?,\|e^{zT-zT^*}\| z\in \mathbb{C},Let $E$ be an infinite-dimensional complex Hilbert space and $T\in \mathcal{L}(E)$. Is $\|e^{zT-zT^*}\|$ bounded for all $z\in \mathbb{C}$?,Let $E$ be an infinite-dimensional complex Hilbert space and $T\in \mathcal{L}(E)$. Is $\|e^{zT-zT^*}\|$ bounded for all $z\in \mathbb{C}$?,,"['complex-analysis', 'functional-analysis']"
