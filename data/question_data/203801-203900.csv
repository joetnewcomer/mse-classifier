,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why isn't this restriction of a homeomorphism open?,Why isn't this restriction of a homeomorphism open?,,"[I put a PS at the bottom of the text, as I think problem's solved] There is a simple idea that a restriction of a homeomorphism to a subset of its domain yields a new homeomorphism onto its image. I am having problems with certain cases,  where I think that this applies, but my texts conclude that the result is just continuous and bijective. When the domain is in $R^n$ , domain invariance is then used. One example is this homeomorphic manifolds proof by John. He restricts 3 homeomorphisms, concludes that the restriction are homeomorphisms and that is it. I solved this question the same way, the maps are homeomorphic, why wouldn't the restriction of the middle homeomorphism $h$ not be ? But this proof does not seem to use domain invariance, so I wonder if it's correct. As usual, there probably is a simple insight here that I am lacking, but I am not getting myself on the right track, so any hint appreciated. What I have seen looks like john's answer, but was really: Mand N are homeomorphic manifolds with dimensions m and n. Obtain a contradiction if m > n. $h:M\rightarrow N$ is a homeomorphism. for $h(x)  \in N$ there is an open V in N, an open $O_v$ in $R^n$ , and a homeomorphism $\psi_N :V\rightarrow O_v$ . $h^{-1}(V)$ is open in M, so there is an open $U\subset h^{-1}(V)$ around x, an open $0_u$ in $R^m$ and a homeomorphism $\psi_M : U \rightarrow O_u$ . Again, $h(U)\subset V $ is open, and the restriction $\psi_N|_{h(U)}$ is a homeomorphism onto its image $O_v'$ . My text says here that $\psi_M\ o\ h^{-1} \ o\ \psi_N|_{h(U)}^{-1}$ (edited: I should use $ \psi_N|_{h(U)} \ o\ h\ o\  \psi_M^{-1}$ ) is continuous and injective and uses domain invariance to conclude it is open. I fail to see why the restriction of h to U would not be a homeomorphism, and the composition is not just a composition of three homeomorphisms, which is open, or what else is the reason that domain invariance is used. The domain invariance proposition which is used is: any continuous injective function from an open $O\subset R^n$ into $R^n$ is open. PS: following freakish' hint, I think I found the answer that all the restrictions are indeed homeomorphisms, but it is not useful to know because I need an embedding into a higher dimension, and that is where I need Brouwer's domain invariance","[I put a PS at the bottom of the text, as I think problem's solved] There is a simple idea that a restriction of a homeomorphism to a subset of its domain yields a new homeomorphism onto its image. I am having problems with certain cases,  where I think that this applies, but my texts conclude that the result is just continuous and bijective. When the domain is in , domain invariance is then used. One example is this homeomorphic manifolds proof by John. He restricts 3 homeomorphisms, concludes that the restriction are homeomorphisms and that is it. I solved this question the same way, the maps are homeomorphic, why wouldn't the restriction of the middle homeomorphism not be ? But this proof does not seem to use domain invariance, so I wonder if it's correct. As usual, there probably is a simple insight here that I am lacking, but I am not getting myself on the right track, so any hint appreciated. What I have seen looks like john's answer, but was really: Mand N are homeomorphic manifolds with dimensions m and n. Obtain a contradiction if m > n. is a homeomorphism. for there is an open V in N, an open in , and a homeomorphism . is open in M, so there is an open around x, an open in and a homeomorphism . Again, is open, and the restriction is a homeomorphism onto its image . My text says here that (edited: I should use ) is continuous and injective and uses domain invariance to conclude it is open. I fail to see why the restriction of h to U would not be a homeomorphism, and the composition is not just a composition of three homeomorphisms, which is open, or what else is the reason that domain invariance is used. The domain invariance proposition which is used is: any continuous injective function from an open into is open. PS: following freakish' hint, I think I found the answer that all the restrictions are indeed homeomorphisms, but it is not useful to know because I need an embedding into a higher dimension, and that is where I need Brouwer's domain invariance",R^n h h:M\rightarrow N h(x)  \in N O_v R^n \psi_N :V\rightarrow O_v h^{-1}(V) U\subset h^{-1}(V) 0_u R^m \psi_M : U \rightarrow O_u h(U)\subset V  \psi_N|_{h(U)} O_v' \psi_M\ o\ h^{-1} \ o\ \psi_N|_{h(U)}^{-1}  \psi_N|_{h(U)} \ o\ h\ o\  \psi_M^{-1} O\subset R^n R^n,"['general-topology', 'differential-geometry']"
1,$3$D analog to the catenary,D analog to the catenary,3,"Introduction : Given a plane $(2d)$ , two points $(0d)$ , and a curve $(""1d"")$ analogous to a chain (constant length, points can only rotate around their neighbouring points and cant distance or approach themselves to their neighbouring points, and it is non-self intersecting) hanging from the points, under an uniform gravitational field, we have a catenary. Question : Given the space $(3d)$ , two curves $(1d)$ , and a surface $(2d)$ (with analogous characteristics, e.g. if the lenght of the chain was fixed before, now the area of the surface is fixed), we have a... what? What is its name? [ Answer : In civil engineering this surface is called "" catenary membranes "" or "" catenary domes ""] Clarification : Illustration of the surface: Imagine I have a pair of curves with finite length, a mesh of inelastic strings (making tiny rectangular cells, for example), and the mesh is hanging from the curves under a uniform gravitational field A source for physics of the differential equation that leads to the catenary: Exercise 9 on p. 9 of Professor Shiffrin's DIFFERENTIAL GEOMETRY: A First Course in Curves and Surfaces Another source : https://parametricmonkey.com/2015/10/10/catenary-curves/","Introduction : Given a plane , two points , and a curve analogous to a chain (constant length, points can only rotate around their neighbouring points and cant distance or approach themselves to their neighbouring points, and it is non-self intersecting) hanging from the points, under an uniform gravitational field, we have a catenary. Question : Given the space , two curves , and a surface (with analogous characteristics, e.g. if the lenght of the chain was fixed before, now the area of the surface is fixed), we have a... what? What is its name? [ Answer : In civil engineering this surface is called "" catenary membranes "" or "" catenary domes ""] Clarification : Illustration of the surface: Imagine I have a pair of curves with finite length, a mesh of inelastic strings (making tiny rectangular cells, for example), and the mesh is hanging from the curves under a uniform gravitational field A source for physics of the differential equation that leads to the catenary: Exercise 9 on p. 9 of Professor Shiffrin's DIFFERENTIAL GEOMETRY: A First Course in Curves and Surfaces Another source : https://parametricmonkey.com/2015/10/10/catenary-curves/","(2d) (0d) (""1d"") (3d) (1d) (2d)",['differential-geometry']
2,Is there an example of a Ricci flat algebraic surface?,Is there an example of a Ricci flat algebraic surface?,,"Given a surface defined by a polynomial $f(x,y,z,...)=0$ in $\mathbb{R}^n$ are there any known to be Ricci-flat but not flat? I am trying to find a simple example with smallest possible polynomial. e.g. $x^2+y^2+z^2-1=0$ is not Ricci-flat as it is a sphere. $(x^2+y^2-1)^2+(z^2+w^2-1)^2=0$ is Ricci flat but is also just flat because it is a flat torus. I imagine some Euclidean form of a Schwarzschield wormhole type surface would work? Embedded in $\mathbb{R}^5$ (All I can find is surfaces defined in $\mathbb{CP}^n$ instead of Euclidean space. (I don't know how to convert these to surfaces in $\mathbb{R}^m$ .) I think the smallest example should be a 4-manifold thus defined by an equation $f(x,y,z,w,u)=0$ . (Since for 3-manifolds the Riemann tensor can be decomposed into the Ricci tensor). (2) Are there any polynomials shown to have zero-scalar curvature but non-zero Ricci-curvature?  I think the simplest example should be a 3-manifold defined by an equation $f(x,y,z,w)=0$ (Since for 2-manifolds the Ricci tensor is proportional to the Scalar tensor).",Given a surface defined by a polynomial in are there any known to be Ricci-flat but not flat? I am trying to find a simple example with smallest possible polynomial. e.g. is not Ricci-flat as it is a sphere. is Ricci flat but is also just flat because it is a flat torus. I imagine some Euclidean form of a Schwarzschield wormhole type surface would work? Embedded in (All I can find is surfaces defined in instead of Euclidean space. (I don't know how to convert these to surfaces in .) I think the smallest example should be a 4-manifold thus defined by an equation . (Since for 3-manifolds the Riemann tensor can be decomposed into the Ricci tensor). (2) Are there any polynomials shown to have zero-scalar curvature but non-zero Ricci-curvature?  I think the simplest example should be a 3-manifold defined by an equation (Since for 2-manifolds the Ricci tensor is proportional to the Scalar tensor).,"f(x,y,z,...)=0 \mathbb{R}^n x^2+y^2+z^2-1=0 (x^2+y^2-1)^2+(z^2+w^2-1)^2=0 \mathbb{R}^5 \mathbb{CP}^n \mathbb{R}^m f(x,y,z,w,u)=0 f(x,y,z,w)=0","['differential-geometry', 'algebraic-geometry']"
3,$d^+d^*\omega=0$ implies $dd^*\omega=0$ for a 2-form $\omega$ on a 4-manifold,implies  for a 2-form  on a 4-manifold,d^+d^*\omega=0 dd^*\omega=0 \omega,"Let $\omega$ be a smooth 2-form on a closed oriented riemannian 4-manifold $X$ . How can we show that $d^+d^*\omega=0$ (i.e. $dd^*\omega$ is anti-self-dual) implies $dd^*\omega=0$ ? This statement is claimed in the proof of Claim 2.6 in https://web.ma.utexas.edu/users/pedrotti.riccardo/Riccardo_Pedrotti-Notes_on_the_paper_of_Bauer_about_Refined_SW_invariants.pdf . (In this note, it is written that a proof of this statement is given in one of the references but it is not available.)","Let be a smooth 2-form on a closed oriented riemannian 4-manifold . How can we show that (i.e. is anti-self-dual) implies ? This statement is claimed in the proof of Claim 2.6 in https://web.ma.utexas.edu/users/pedrotti.riccardo/Riccardo_Pedrotti-Notes_on_the_paper_of_Bauer_about_Refined_SW_invariants.pdf . (In this note, it is written that a proof of this statement is given in one of the references but it is not available.)",\omega X d^+d^*\omega=0 dd^*\omega dd^*\omega=0,"['differential-geometry', 'riemannian-geometry', 'hodge-theory']"
4,Torsion-free affine connection under Geodesic normal coordinates is determined by curvature tensor,Torsion-free affine connection under Geodesic normal coordinates is determined by curvature tensor,,"I am reading Chern's Lectures on Differential Geometry. Chern proves the theorem that A torsion-free affine connection is completely determined by the curvature tensor ,i.e. the Theorem 2.3 on page 147 on this page . However, I can not understand (2.20) in that link, I copied what it states below. If we consider a normal coordinate system $\alpha^{i}$ at a fixed point $O$ and also choose a natural frame at $O$ , then we get a frame field $e_{i}$ and its dual $\theta^{i}$ . Let $\theta^{j}_{i}$ be the restriction of the everywhere linearly independent $m^{2}$ differential 1-forms,then we have $$ \left\{ \begin{align} \theta^{i} &=\overline{\theta}^{i}+\alpha^{i}dt\\ \theta^{j}_{i} &=\overline{\theta}^{j}_{i} \end{align}\right. $$ where the $\overline{\theta}^{i}$ and $\overline{\theta}^{j}_{i}$ means they do not contain $dt$ I can not see how this is derived, can anyone help me out?","I am reading Chern's Lectures on Differential Geometry. Chern proves the theorem that A torsion-free affine connection is completely determined by the curvature tensor ,i.e. the Theorem 2.3 on page 147 on this page . However, I can not understand (2.20) in that link, I copied what it states below. If we consider a normal coordinate system at a fixed point and also choose a natural frame at , then we get a frame field and its dual . Let be the restriction of the everywhere linearly independent differential 1-forms,then we have where the and means they do not contain I can not see how this is derived, can anyone help me out?","\alpha^{i} O O e_{i} \theta^{i} \theta^{j}_{i} m^{2} 
\left\{
\begin{align}
\theta^{i} &=\overline{\theta}^{i}+\alpha^{i}dt\\
\theta^{j}_{i} &=\overline{\theta}^{j}_{i}
\end{align}\right.
 \overline{\theta}^{i} \overline{\theta}^{j}_{i} dt","['differential-geometry', 'riemannian-geometry', 'coordinate-systems', 'geodesic', 'connections']"
5,"$f(x,y)=(x^3-3xy^2,3x^2y-y^3)$ is a local diffeomorphism, but not a diffeomorphism.","is a local diffeomorphism, but not a diffeomorphism.","f(x,y)=(x^3-3xy^2,3x^2y-y^3)","Show that the map $f\colon \mathbb R^2\backslash\{0\}\to \mathbb R^2\backslash\{0\}$ given by $f(x,y)=(x^3-3xy^2,3x^2y-y^3)$ is a local diffeomorphism, but not a (global) diffeomorphism. It is a local diffeomorphism as one can show using the inverse function theorem. Indeed $$ df_{(x,y)}= \begin{bmatrix} 3x^2-3y^2& -6xy \\ 6xy& 3x^2-3y^2 \end{bmatrix} $$ Its determinant is $(3x^2-3y^2)^2+36x^2y^2\neq 0$ for $(x,y)\in\mathbb R\backslash\{0\}$ . To show that it is not a diffeomorphism, I tried to show that it fails to be injective. Trying to finding distinct points giving same $f$ was not fruitful. Any idea of how to proceed from there! Thanks in advance!","Show that the map given by is a local diffeomorphism, but not a (global) diffeomorphism. It is a local diffeomorphism as one can show using the inverse function theorem. Indeed Its determinant is for . To show that it is not a diffeomorphism, I tried to show that it fails to be injective. Trying to finding distinct points giving same was not fruitful. Any idea of how to proceed from there! Thanks in advance!","f\colon \mathbb R^2\backslash\{0\}\to \mathbb R^2\backslash\{0\} f(x,y)=(x^3-3xy^2,3x^2y-y^3)  df_{(x,y)}=
\begin{bmatrix}
3x^2-3y^2& -6xy \\
6xy& 3x^2-3y^2
\end{bmatrix}
 (3x^2-3y^2)^2+36x^2y^2\neq 0 (x,y)\in\mathbb R\backslash\{0\} f","['differential-geometry', 'smooth-manifolds']"
6,Notion of $G$-stable subsets in Moerdijk and Mr훾un's Introduction to foliations and Lie groupoids,Notion of -stable subsets in Moerdijk and Mr훾un's Introduction to foliations and Lie groupoids,G,"This question is related to this this older question. Let $M$ be a smooth manifold and $G$ be a group of diffeomorphisms of $M$ . In page 35 of Introduction to Lie foliations and Lie groupoids , Moerdijk and Mr훾un call an $S\subset M$ a $G$ -stable subset of $M$ when it is connected and given $g\in G$ , either $S\cap gS=S$ or $S\cap gS=\emptyset$ . Just after the definition, they point out that the $G$ -stable subsets of $M$ are precisely the components of $G$ -invariant subsets of $M$ . I am having a hard time to understand the implication, i.e., how a $G$ -stable subset would need to be a connected component of a $G$ -invariant subset of $M$ . For instance, consider $M=\mathbb{C}$ , $G=\mathbb{S}^1$ and $S=\{1\}$ , where $G$ acts on $M$ by rotations around $0\in M$ . In this case, $S$ is $G$ -stable yet it is not a connected component of its group-action closure, $gS=G$ . In this context, don't we have to modify a little the definition of $G$ -stable subsets only to include open subsets of $M$ or restrict it to finite subgroups of diffeomorphisms of $M$ ?","This question is related to this this older question. Let be a smooth manifold and be a group of diffeomorphisms of . In page 35 of Introduction to Lie foliations and Lie groupoids , Moerdijk and Mr훾un call an a -stable subset of when it is connected and given , either or . Just after the definition, they point out that the -stable subsets of are precisely the components of -invariant subsets of . I am having a hard time to understand the implication, i.e., how a -stable subset would need to be a connected component of a -invariant subset of . For instance, consider , and , where acts on by rotations around . In this case, is -stable yet it is not a connected component of its group-action closure, . In this context, don't we have to modify a little the definition of -stable subsets only to include open subsets of or restrict it to finite subgroups of diffeomorphisms of ?",M G M S\subset M G M g\in G S\cap gS=S S\cap gS=\emptyset G M G M G G M M=\mathbb{C} G=\mathbb{S}^1 S=\{1\} G M 0\in M S G gS=G G M M,"['differential-geometry', 'differential-topology', 'group-actions', 'diffeomorphism', 'orbifolds']"
7,Why do we construct Lagrangian submanifolds after symplectic reductions,Why do we construct Lagrangian submanifolds after symplectic reductions,,"I am learning about Hamilton-Jacobi actions, symplectic reductions and Lagrangian submanifolds and I am trying to understand the relation between these concepts. I have read that Lagrangian submanifolds are physically interesting as they can be thought of the space of all momenta at fixed coordinate, locally. Moreover, they allow us to recover the variational form of the Hamiltonian mechanics of the system we are dealing with. As I understand it, symplectic reductions arose from the interest of taking quotients of symplectic manifolds under group actions and the Hamilton-Jacobi group action is the one that makes it possible (via the momentum map $\mu$ ) as it satisfies several requirements as the dimension and the symplectic structure of the manifold. In particular, the Mardsen-Weinstein-Meyer theorem states that the quotient $\mu^{-1}(0) / G$ is a symplectic manifold. Finally, I have read that this latter quotient captures the original Hamiltonian mechanics. From this, most of the documents I have read naturally turn to the wish to recover Lagrangian submanifolds from symplectic reductions. For this, they use the level sets of the momentum map. It is a rough summary and obviously any correction/precision will be appreciated. My confusion comes from the wish to construct Lagrangian manifolds from symplectic reductions. First, $\mu^{-1}(0) / G$ seems to provide some physical insights on our system and so do Lagrangian submanifolds. So, either they do it in a more interesting/accurate way, or I am missing the point in doing it ""twice"". Then, the problem is probably that I am a bit short on basic knowledge here but why are we interested in many level sets of $\mu$ and not only the $0$ one? Is it because the variational form of the Hamiltonian mechanics is local?","I am learning about Hamilton-Jacobi actions, symplectic reductions and Lagrangian submanifolds and I am trying to understand the relation between these concepts. I have read that Lagrangian submanifolds are physically interesting as they can be thought of the space of all momenta at fixed coordinate, locally. Moreover, they allow us to recover the variational form of the Hamiltonian mechanics of the system we are dealing with. As I understand it, symplectic reductions arose from the interest of taking quotients of symplectic manifolds under group actions and the Hamilton-Jacobi group action is the one that makes it possible (via the momentum map ) as it satisfies several requirements as the dimension and the symplectic structure of the manifold. In particular, the Mardsen-Weinstein-Meyer theorem states that the quotient is a symplectic manifold. Finally, I have read that this latter quotient captures the original Hamiltonian mechanics. From this, most of the documents I have read naturally turn to the wish to recover Lagrangian submanifolds from symplectic reductions. For this, they use the level sets of the momentum map. It is a rough summary and obviously any correction/precision will be appreciated. My confusion comes from the wish to construct Lagrangian manifolds from symplectic reductions. First, seems to provide some physical insights on our system and so do Lagrangian submanifolds. So, either they do it in a more interesting/accurate way, or I am missing the point in doing it ""twice"". Then, the problem is probably that I am a bit short on basic knowledge here but why are we interested in many level sets of and not only the one? Is it because the variational form of the Hamiltonian mechanics is local?",\mu \mu^{-1}(0) / G \mu^{-1}(0) / G \mu 0,"['differential-geometry', 'classical-mechanics', 'symplectic-geometry', 'submanifold', 'moment-map']"
8,"""Pushforward"" of de Rham cohomology along ""normal"" surjective local diffeomorphisms?","""Pushforward"" of de Rham cohomology along ""normal"" surjective local diffeomorphisms?",,"Notation: for $X$ a smooth manifold, let $T^n(X)$ denote the space of (global, smooth) covariant rank- $n$ tensors on $X$ , i.e. sections of $(T^*X)^{\otimes n}$ . Let $X\xrightarrow{Q}Y$ be a smooth, surjective, local diffeomorphism between smooth manifolds. Let us also assume $Q$ is ""normal"" in that its group of deck transformations acts transitively on each fiber. We say $s \in T^n(X)$ is "" $Q$ -invariant"" if $s$ is invariant under all deck transformations of $Q$ . Denote by $\text{inv}_{Q}T^n(X)$ the space of $Q$ -invariant covariant rank- $n$ tensors on $X$ . Then we claim for each integer $n\geq 0$ there is a unique homomorphism $Q^n_! : \text{inv}_{Q}T^n(X) \rightarrow T^n(Y)$ , such that for every open $U\subset X$ , if $Q|_U$ is a diffeomorphism onto $Q(U)$ with inverse $P : Q(U)\xrightarrow{\approx} U$ , then for any $\omega \in \text{inv}_{Q}T^n(X)$ we have $$ (Q_! \omega)|_{Q(U)} = P^*(\omega|_U) $$ Furthermore: For $\omega \in T^n(Y)$ we have $Q^*\omega$ is $Q$ -invariant, and we should have $Q_!Q^*\omega = \omega$ . $Q^n_!$ preserves symmetric and antisymmetric tensors, thus also restricting to maps $\text{inv}_{Q}\mathrm{Sym}^n(X)\rightarrow \mathrm{Sym}^n(Y)$ and $\text{inv}_{Q}\Omega^n(X)\rightarrow \Omega^n(Y)$ . $Q^2_!$ should preserve signatures; therefore, $Q^2_!$ of a $Q$ -inv Riemannian metric (or pseudo-Riemannian of some signature) is another Riemannian (or pseudo-Riemannian of same signature) metric. For $\omega \in \text{inv}_{Q}\Omega^n(X)$ we have $d\omega \in \text{inv}_{Q}\Omega^{n+1}(X)$ and $Q^{n+1}_!(d\omega) = d(Q_!^n \omega)$ . So also, $Q_!$ gives a chain complex morphism $\text{inv}_{Q}\Omega^\bullet(X)\rightarrow \Omega^\bullet(Y)$ . Also, by the 1st bullet point, if $Q_!\omega$ is exact (on $Y$ ) then $\omega$ is exact (on $X$ ). It should follow that $Q^n_!$ induces injective maps $H^n_{\mathrm{dR}}(X)\rightarrow H^n_{\mathrm{dR}}(Y)$ , provided every de Rham class on $X$ has a $Q$ -invariant representative. My 1st question is whether the above is valid and makes sense? My 2nd question is whether the last condition above is satisfied, and how to show this? I.e., for every closed $n$ -form $\omega$ on $X$ , is there an $Q$ -invariant (i.e. invariant under deck transformations of $Q$ ) closed $n$ -form $\omega'$ on $X$ , which is cohomologous with $\omega$ (i.e. their difference is exact)? Or (more weakly?) can we show the inclusion of the $Q$ -invariant de Rham complex into $X$ 's full de Rham complex is a quasi-isomorphism (induces isomorphisms on all cohomology groups)? Update : Here is my thinking thus far on the 2nd question: Let us further assume: that the group $G$ of deck transformations is a topological group, acting continuously on $X$ , and it admits a Haar measure $\mu$ with finite total volume; and that each $g \in G$ induces the identity (not just an isomorphism) on the de Rham cohomology of $X$ . Then, given a closed $\omega \in \Omega^n_{\text{closed}}(X)$ , we would like to define a form via an integral of a $G$ -dependent form over $G$ , $$ \omega' = \frac{1}{|G|}\int_{g\in G} (g^*\omega)\,d\mu(g) \,, $$ which we expect to be $G$ -invariant by the usual arguments. Here $|G| = \mu(G)$ is the finite volume of $G$ . Furthermore, since for each $g\in G$ we know $g^*$ induces the identity on $H^n_{\mathrm{dR}}(X)$ it follows that $\omega$ is cohomologous with $g^*\omega$ , so also $\omega = \frac{1}{|G|}\int_{g\in G}\omega\,d\mu(g)$ is cohomologous with $\omega' = \frac{1}{|G|}\int_{g\in G} (g^*\omega)\,d\mu(g)$ . Would this be valid? Are the above assumptions necessary? The 2nd assumption bothers me, since e.g. this is not satisfied by $S^2 \xrightarrow{\text{mod $\mathbb{Z}/2\mathbb{Z}$}} \mathbb{R}\mathbb{P}^2$ .","Notation: for a smooth manifold, let denote the space of (global, smooth) covariant rank- tensors on , i.e. sections of . Let be a smooth, surjective, local diffeomorphism between smooth manifolds. Let us also assume is ""normal"" in that its group of deck transformations acts transitively on each fiber. We say is "" -invariant"" if is invariant under all deck transformations of . Denote by the space of -invariant covariant rank- tensors on . Then we claim for each integer there is a unique homomorphism , such that for every open , if is a diffeomorphism onto with inverse , then for any we have Furthermore: For we have is -invariant, and we should have . preserves symmetric and antisymmetric tensors, thus also restricting to maps and . should preserve signatures; therefore, of a -inv Riemannian metric (or pseudo-Riemannian of some signature) is another Riemannian (or pseudo-Riemannian of same signature) metric. For we have and . So also, gives a chain complex morphism . Also, by the 1st bullet point, if is exact (on ) then is exact (on ). It should follow that induces injective maps , provided every de Rham class on has a -invariant representative. My 1st question is whether the above is valid and makes sense? My 2nd question is whether the last condition above is satisfied, and how to show this? I.e., for every closed -form on , is there an -invariant (i.e. invariant under deck transformations of ) closed -form on , which is cohomologous with (i.e. their difference is exact)? Or (more weakly?) can we show the inclusion of the -invariant de Rham complex into 's full de Rham complex is a quasi-isomorphism (induces isomorphisms on all cohomology groups)? Update : Here is my thinking thus far on the 2nd question: Let us further assume: that the group of deck transformations is a topological group, acting continuously on , and it admits a Haar measure with finite total volume; and that each induces the identity (not just an isomorphism) on the de Rham cohomology of . Then, given a closed , we would like to define a form via an integral of a -dependent form over , which we expect to be -invariant by the usual arguments. Here is the finite volume of . Furthermore, since for each we know induces the identity on it follows that is cohomologous with , so also is cohomologous with . Would this be valid? Are the above assumptions necessary? The 2nd assumption bothers me, since e.g. this is not satisfied by .","X T^n(X) n X (T^*X)^{\otimes n} X\xrightarrow{Q}Y Q s \in T^n(X) Q s Q \text{inv}_{Q}T^n(X) Q n X n\geq 0 Q^n_! : \text{inv}_{Q}T^n(X) \rightarrow T^n(Y) U\subset X Q|_U Q(U) P : Q(U)\xrightarrow{\approx} U \omega \in \text{inv}_{Q}T^n(X) 
(Q_! \omega)|_{Q(U)} = P^*(\omega|_U)
 \omega \in T^n(Y) Q^*\omega Q Q_!Q^*\omega = \omega Q^n_! \text{inv}_{Q}\mathrm{Sym}^n(X)\rightarrow \mathrm{Sym}^n(Y) \text{inv}_{Q}\Omega^n(X)\rightarrow \Omega^n(Y) Q^2_! Q^2_! Q \omega \in \text{inv}_{Q}\Omega^n(X) d\omega \in \text{inv}_{Q}\Omega^{n+1}(X) Q^{n+1}_!(d\omega) = d(Q_!^n \omega) Q_! \text{inv}_{Q}\Omega^\bullet(X)\rightarrow \Omega^\bullet(Y) Q_!\omega Y \omega X Q^n_! H^n_{\mathrm{dR}}(X)\rightarrow H^n_{\mathrm{dR}}(Y) X Q n \omega X Q Q n \omega' X \omega Q X G X \mu g \in G X \omega \in \Omega^n_{\text{closed}}(X) G G 
\omega' = \frac{1}{|G|}\int_{g\in G} (g^*\omega)\,d\mu(g) \,,
 G |G| = \mu(G) G g\in G g^* H^n_{\mathrm{dR}}(X) \omega g^*\omega \omega = \frac{1}{|G|}\int_{g\in G}\omega\,d\mu(g) \omega' = \frac{1}{|G|}\int_{g\in G} (g^*\omega)\,d\mu(g) S^2 \xrightarrow{\text{mod \mathbb{Z}/2\mathbb{Z}}} \mathbb{R}\mathbb{P}^2","['differential-geometry', 'solution-verification', 'smooth-manifolds', 'de-rham-cohomology']"
9,"If every closed curve on a surface has zero total torsion, then the surface is totally umbilic","If every closed curve on a surface has zero total torsion, then the surface is totally umbilic",,"Let $\Sigma$ be an oriented, simply connected surface in $\mathbb{R}^{3}$ , let $\xi$ be its unit normal, and let $\alpha$ be a a smooth curve in $\Sigma$ . In this paper , the authors prove that, if every closed curve $\alpha$ has vanishing total torsion, i.e., if $$ \int_{\alpha} \tau = 0 \quad \text{for all closed curves $\alpha$}, $$ then $\Sigma$ is totally umbilic. (In fact, they prove a stronger statement by considering a Riemannian ambient space.) I am having a hard time understanding a step in their proof of Lemma 2, which establishes the said result. After proving that the integral of the geodesic torsion $\tau_{g}$ over any closed curve $\alpha$ vanishes, they claim that continuity forces the geodesic torsion to vanish identically ; see text after equation (26) in the picture below. I am not sure why continuity is invoked here. I agree that, if $\nabla_{X}\xi$ and $X$ are not parallel at $p$ , then they remain not parallel in a neighborhood of $p$ , but how can one then conclude that every closed curve around $p$ has $\tau_{g} =0$ ?","Let be an oriented, simply connected surface in , let be its unit normal, and let be a a smooth curve in . In this paper , the authors prove that, if every closed curve has vanishing total torsion, i.e., if then is totally umbilic. (In fact, they prove a stronger statement by considering a Riemannian ambient space.) I am having a hard time understanding a step in their proof of Lemma 2, which establishes the said result. After proving that the integral of the geodesic torsion over any closed curve vanishes, they claim that continuity forces the geodesic torsion to vanish identically ; see text after equation (26) in the picture below. I am not sure why continuity is invoked here. I agree that, if and are not parallel at , then they remain not parallel in a neighborhood of , but how can one then conclude that every closed curve around has ?","\Sigma \mathbb{R}^{3} \xi \alpha \Sigma \alpha 
\int_{\alpha} \tau = 0 \quad \text{for all closed curves \alpha},
 \Sigma \tau_{g} \alpha \nabla_{X}\xi X p p p \tau_{g} =0","['differential-geometry', 'proof-explanation']"
10,Milnor's appendix on classification of 1-manifolds,Milnor's appendix on classification of 1-manifolds,,"I'm trying to understand Milnor's proof of the classification of 1-manifolds, given in the appendix of his boook ""Topology from a differentiable point of view"". Any smooth, connected one dimensional manifold is diffeomorphic to either to the circle $S^1$ or to some interval of real numbers. Remark: I thought doing in many posts as part 1, and so on, but I think it will lose the idea. However, if some moderator thinks that will be better I will do it :D. To proof that, he gives a definition and a lemma, Definition A map $f: I\to M$ is a parametrization by arc-length if $f$ maps $I$ diffeomorphically onto an open subset $\dagger$ of $M$ , and if the ""velocity vector"" $d f_s(1) \quad\varepsilon\quad T M_{f(s)}$ has unit length, for each $s \varepsilon I$ . Any given local parametrization $I^\prime\to M$ can be transformed into a parametrization by arc-length by a straightforward change of variables. Lemma Let $f: I\to M$ and $g: J\to M$ be parametrizations by arc-length. Then $f(I) \cap g(J)$ has at most two components. If it has only one component, then $f$ can be extended to a parametrization by arc-length of the union $f(I) \cup g(J)$ . If it has two components, then M must be diffeomorphic to $S^1$ . Here is the beginning of the proof Proof Clearly $g^{-1}$ of maps some relatively open subset of $I$ diffeomorphically onto a relatively open subset of $J$ . Furthermore the derivative of $g^{-1}$ of is equal to $\pm 1$ everywhere. My doubts are: To prove that let $U=f(I)\cap g(J)$ , so $$h:=g^{-1}\circ f:f^{-1}(U)\to g^{-1}(U)$$ that ""open subset of $I$ "" is $f^{-1}(U)$ so $h$ is a diffeormophism. From there $h(s)=g^{-1}\circ f(s)$ , then $dh_s=dg^{-1}_{f(s)}(df_s)$ . I know that $\|df_s(1)\|=\|dg_t(1)\|=1$ , and $dg^{-1}_t=(dg_{g^{-1}(t)})^{-1}$ , so $$\begin{aligned}\|dh_s(1)\|&=\|dg^{-1}_{f(s)}(df_s(1))\|\\&=\|(dg_{g^{-1}(f(s))})^{-1}(df_s(1))\|\\&=\|(dg_{h(s)})^{-1}(df_s(1))\|\end{aligned}$$ (1) But I don't know what to do from that. Another way I'm trying is: From $h(s)=g^{-1}\circ f(s)$ , we get $g(h(s))=f(s)$ , then $dg_{h(s)}(dh_s)=df_s$ . Applying in $1$ , we get $dg_{h(s)}(dh_s(1))=df_s(1)$ , so $dg_{h(s)}(h'(s))=df_s(1)$ ,but I get stuck again. Then he continues: So $\Gamma:=\{(s,t)\in f^{-1}(U)\times g{-1}(U)|f(s)=g(t)\}\subset I\times J$ , then $\Gamma=\operatorname{graph}(h)$ and it is a closed subset. I get this, my second doubt is: (2) What information about the intersection $U$ will $\Gamma$ give? (3) Why does he say that $h$ is ""locally"" a diffeomorphism? As $h'(s)=\pm 1$ , then $h(s)=s+b$ or $h(s)=-s+b$ , where $b$ is a constant. In the proof says that $\Gamma$ consists of line segments of slope $\pm 1$ . (4) The word ""segments"" means that $\Gamma$ can be made of many pieces, but if $h$ is a diffeomorphism, and its domain $f^{-1}(U)$ is connected(or I'm wrong?), it is not $\Gamma$ made of one part? Then... (5) I do not understand why there can be at most one of these segments ending on each of the 4 edges of $I\times J$ . In order to this post not being huge I will do a second part. Thank you.","I'm trying to understand Milnor's proof of the classification of 1-manifolds, given in the appendix of his boook ""Topology from a differentiable point of view"". Any smooth, connected one dimensional manifold is diffeomorphic to either to the circle or to some interval of real numbers. Remark: I thought doing in many posts as part 1, and so on, but I think it will lose the idea. However, if some moderator thinks that will be better I will do it :D. To proof that, he gives a definition and a lemma, Definition A map is a parametrization by arc-length if maps diffeomorphically onto an open subset of , and if the ""velocity vector"" has unit length, for each . Any given local parametrization can be transformed into a parametrization by arc-length by a straightforward change of variables. Lemma Let and be parametrizations by arc-length. Then has at most two components. If it has only one component, then can be extended to a parametrization by arc-length of the union . If it has two components, then M must be diffeomorphic to . Here is the beginning of the proof Proof Clearly of maps some relatively open subset of diffeomorphically onto a relatively open subset of . Furthermore the derivative of of is equal to everywhere. My doubts are: To prove that let , so that ""open subset of "" is so is a diffeormophism. From there , then . I know that , and , so (1) But I don't know what to do from that. Another way I'm trying is: From , we get , then . Applying in , we get , so ,but I get stuck again. Then he continues: So , then and it is a closed subset. I get this, my second doubt is: (2) What information about the intersection will give? (3) Why does he say that is ""locally"" a diffeomorphism? As , then or , where is a constant. In the proof says that consists of line segments of slope . (4) The word ""segments"" means that can be made of many pieces, but if is a diffeomorphism, and its domain is connected(or I'm wrong?), it is not made of one part? Then... (5) I do not understand why there can be at most one of these segments ending on each of the 4 edges of . In order to this post not being huge I will do a second part. Thank you.","S^1 f: I\to M f I \dagger M d f_s(1) \quad\varepsilon\quad T M_{f(s)} s \varepsilon I I^\prime\to M f: I\to M g: J\to M f(I) \cap g(J) f f(I) \cup g(J) S^1 g^{-1} I J g^{-1} \pm 1 U=f(I)\cap g(J) h:=g^{-1}\circ f:f^{-1}(U)\to g^{-1}(U) I f^{-1}(U) h h(s)=g^{-1}\circ f(s) dh_s=dg^{-1}_{f(s)}(df_s) \|df_s(1)\|=\|dg_t(1)\|=1 dg^{-1}_t=(dg_{g^{-1}(t)})^{-1} \begin{aligned}\|dh_s(1)\|&=\|dg^{-1}_{f(s)}(df_s(1))\|\\&=\|(dg_{g^{-1}(f(s))})^{-1}(df_s(1))\|\\&=\|(dg_{h(s)})^{-1}(df_s(1))\|\end{aligned} h(s)=g^{-1}\circ f(s) g(h(s))=f(s) dg_{h(s)}(dh_s)=df_s 1 dg_{h(s)}(dh_s(1))=df_s(1) dg_{h(s)}(h'(s))=df_s(1) \Gamma:=\{(s,t)\in f^{-1}(U)\times g{-1}(U)|f(s)=g(t)\}\subset I\times J \Gamma=\operatorname{graph}(h) U \Gamma h h'(s)=\pm 1 h(s)=s+b h(s)=-s+b b \Gamma \pm 1 \Gamma h f^{-1}(U) \Gamma I\times J","['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
11,Understanding the use of compactness in getting a variation of an admissible curve from a vector field,Understanding the use of compactness in getting a variation of an admissible curve from a vector field,,"I came across the following result in the book ""Riemannian Manifolds: An Introduction to Curvature"" by John Lee. Theorem: Let $\gamma: \left[ a, b \right] \rightarrow M$ be an admissible curve and $V$ be a vector field along $\gamma$ . Then, $V$ is the variation field of some variation of $\gamma$ . Moreover, if $V$ is proper then the variation can be chosen to be proper. The proof of this result uses the fact that $\left[ a, b \right]$ is compact. Particularly, this is used to define the variation of $\gamma$ as $\Gamma \left( s, t \right) = \exp \left( s V(t) \right)$ . I am  not sure if I understand this properly. Here are my thoughts on how it is used. We know that $\exp$ is defined on an open set containing the zero section. That is, there is an open set $\mathscr{E} \subseteq TM$ (the tangent bundle) such that for all $p \in M$ , $\left( p, 0 \right) \in \mathscr{E}$ . Therefore, for each $p \in M$ , there are balls $B^{\left( p \right)} \left( 0, \delta_p \right) \subseteq \mathscr{E} \cap T_pM$ . Now, we see that $V(t) \in \frac{2 \| V(t) \|}{\delta_p} B \left( 0, \delta_p \right)$ so that these (scaled) balls form an open cover for $V \left( \left[ a, b \right] \right)$ (am I right here?). Once this is done, we get a finite subcover and hence there is some $\epsilon > 0$ such that for $\left| s \right| < \epsilon$ , we have $s V(t) \in \mathscr{E} \cap T_{\gamma \left( t \right)} M$ . Is this reasoning correct? It seems to me that there will be some disjoint unions involved and we may not be able to use the scaled balls to conclude what we want. Any thoughts about this are appreciated!","I came across the following result in the book ""Riemannian Manifolds: An Introduction to Curvature"" by John Lee. Theorem: Let be an admissible curve and be a vector field along . Then, is the variation field of some variation of . Moreover, if is proper then the variation can be chosen to be proper. The proof of this result uses the fact that is compact. Particularly, this is used to define the variation of as . I am  not sure if I understand this properly. Here are my thoughts on how it is used. We know that is defined on an open set containing the zero section. That is, there is an open set (the tangent bundle) such that for all , . Therefore, for each , there are balls . Now, we see that so that these (scaled) balls form an open cover for (am I right here?). Once this is done, we get a finite subcover and hence there is some such that for , we have . Is this reasoning correct? It seems to me that there will be some disjoint unions involved and we may not be able to use the scaled balls to conclude what we want. Any thoughts about this are appreciated!","\gamma: \left[ a, b \right] \rightarrow M V \gamma V \gamma V \left[ a, b \right] \gamma \Gamma \left( s, t \right) = \exp \left( s V(t) \right) \exp \mathscr{E} \subseteq TM p \in M \left( p, 0 \right) \in \mathscr{E} p \in M B^{\left( p \right)} \left( 0, \delta_p \right) \subseteq \mathscr{E} \cap T_pM V(t) \in \frac{2 \| V(t) \|}{\delta_p} B \left( 0, \delta_p \right) V \left( \left[ a, b \right] \right) \epsilon > 0 \left| s \right| < \epsilon s V(t) \in \mathscr{E} \cap T_{\gamma \left( t \right)} M","['differential-geometry', 'riemannian-geometry']"
12,"For a Brownian motion on a Riemannian manifold, is the log of the transition probability proportional to the squared geodesic distance?","For a Brownian motion on a Riemannian manifold, is the log of the transition probability proportional to the squared geodesic distance?",,"I am trying to gather some intuition on the connection on diffusion processes and Riemannian geometry, with only very limited knowledge of the latter. First, let us consider a Brownian Motion in euclidean space. For $\Sigma$ a positive definite matrix, $W_t$ standard $n-$ dimensional brownian motion, $X_t$ solving the stochastic differential equation $$ d X_t = \Sigma^{\frac{1}{2}} d W_t$$ we have that the density $p(x,y,t)$ for $X_t$ starting at $y$ solves the Fokker-Planck equation $$ \frac{d}{dt} p = \frac{1}{2} \Sigma_{ij} \frac{\partial}{\partial x_i} \frac{\partial}{\partial x_j} p$$ where we use Einstein summing convention. The density is given by $p(x,y,t) \propto \exp \left(\frac{-(x-y)^T \Sigma^{-1}(x-y)^T} {2t}\right)$ (where the proportionality is since we still require normalization). Now some geometry: Let $(M,g)$ be a Riemannian manifold (we assume compactness and everything else we might need for the definitions to work). The gradient $\operatorname{grad}$ is defined implicitly by obeying the relation $\langle \operatorname{grad} f, X \rangle_g = d f(X)$ for any vector vield $X$ . The adjoint of the gradient is the divergence $\operatorname{div}$ . One then has the Laplace-Beltrami-operator on the manifold given by $$\Delta_M = \operatorname{div}\operatorname{grad}.$$ One can explicitly write the Laplace-Beltrami operator as $$\Delta_M f = \frac{1}{\sqrt{\det g}} \frac{\partial}{\partial x_j} (\sqrt{\det g} g^{ij} \frac{\partial}{\partial x_i} f)$$ where $g^{ij}$ refers to the inverse of the metric tensor. We now see that our Fokker-Planck equation includes a special case of the Laplace-Beltrami-Operator, where the manifold is just euclidean space and the metric is the constant $\Sigma^{-1}$ . Indeed, in these notes the definition of a Brownian motion on a manifold is taken to be the process which has density $p(x,y,t)$ , where $p$ is the minimal, positive solution to $$\frac{d}{dt}p =  \frac{1}{2} \Delta_M  p, \  p(x,y,0) = \delta_y(x).$$ Now on our manifold, we have the notion of a geodesic distance, which is given by $$ d_M(x,y) = \inf \{ L(\gamma) | \gamma \text{ a piecewise continuos curve from } x \text{ to } y\}.$$ In our standard euclidean case this is just a straight line. In particular, the geodesic distance on $E = (\mathbb{R}^n,\Sigma^{-1})$ should be given by $$d_E(x,y) = \sqrt{(x-y)^T \Sigma^{-1} (x-y)}.$$ Now by comparison with our density for the Brownian motion, we see that $$\ln p(x,y,t) \propto - d_E(x,y)^2.$$ This makes of course intuitively sense to be the generalization of the isotropic case: Diffusion is characterized by equiprobable motion in all directions, so by introducing a different covariane matrix of diffusion tensor we assume that we are in a space with some different metric, but still the transition probability only depends on this metric. My question is now, whether this property generalizes to the definition of Brownian motion on arbitrary Riemannian manifolds above. That is, do we have that $$\ln p(x,y,t) \propto - d_M(x,y)^2$$ on a general Riemannian manifold $M$ ? Intuitively, this should hold. Unfortunately, Im not familiar enough with differential geometry to prove this. What might be useful is that geodesics should fulfill the 'geodesic equation' in local coordinates $$\frac{\partial x_k} {\partial t^2} = -\Gamma^{k}_{ij} \frac{\partial x_i}{\partial t}\frac{\partial x_j}{\partial t} $$ with $\Gamma^{k}_{ij}$ the Christoffel symbol of the second kind. This also somewhat appears in the equation for the Laplace-Beltrami operator since $$ \Gamma^i_{ij} = \frac{1}{\sqrt{\det g}} \frac{\partial}{\partial x_j} (\sqrt{\det g})$$ but I don't know if this helps. I would appreciate any comments on the question, also if you know some good references to further study these connections.","I am trying to gather some intuition on the connection on diffusion processes and Riemannian geometry, with only very limited knowledge of the latter. First, let us consider a Brownian Motion in euclidean space. For a positive definite matrix, standard dimensional brownian motion, solving the stochastic differential equation we have that the density for starting at solves the Fokker-Planck equation where we use Einstein summing convention. The density is given by (where the proportionality is since we still require normalization). Now some geometry: Let be a Riemannian manifold (we assume compactness and everything else we might need for the definitions to work). The gradient is defined implicitly by obeying the relation for any vector vield . The adjoint of the gradient is the divergence . One then has the Laplace-Beltrami-operator on the manifold given by One can explicitly write the Laplace-Beltrami operator as where refers to the inverse of the metric tensor. We now see that our Fokker-Planck equation includes a special case of the Laplace-Beltrami-Operator, where the manifold is just euclidean space and the metric is the constant . Indeed, in these notes the definition of a Brownian motion on a manifold is taken to be the process which has density , where is the minimal, positive solution to Now on our manifold, we have the notion of a geodesic distance, which is given by In our standard euclidean case this is just a straight line. In particular, the geodesic distance on should be given by Now by comparison with our density for the Brownian motion, we see that This makes of course intuitively sense to be the generalization of the isotropic case: Diffusion is characterized by equiprobable motion in all directions, so by introducing a different covariane matrix of diffusion tensor we assume that we are in a space with some different metric, but still the transition probability only depends on this metric. My question is now, whether this property generalizes to the definition of Brownian motion on arbitrary Riemannian manifolds above. That is, do we have that on a general Riemannian manifold ? Intuitively, this should hold. Unfortunately, Im not familiar enough with differential geometry to prove this. What might be useful is that geodesics should fulfill the 'geodesic equation' in local coordinates with the Christoffel symbol of the second kind. This also somewhat appears in the equation for the Laplace-Beltrami operator since but I don't know if this helps. I would appreciate any comments on the question, also if you know some good references to further study these connections.","\Sigma W_t n- X_t  d X_t = \Sigma^{\frac{1}{2}} d W_t p(x,y,t) X_t y  \frac{d}{dt} p = \frac{1}{2} \Sigma_{ij} \frac{\partial}{\partial x_i} \frac{\partial}{\partial x_j} p p(x,y,t) \propto \exp \left(\frac{-(x-y)^T \Sigma^{-1}(x-y)^T} {2t}\right) (M,g) \operatorname{grad} \langle \operatorname{grad} f, X \rangle_g = d f(X) X \operatorname{div} \Delta_M = \operatorname{div}\operatorname{grad}. \Delta_M f = \frac{1}{\sqrt{\det g}} \frac{\partial}{\partial x_j} (\sqrt{\det g} g^{ij} \frac{\partial}{\partial x_i} f) g^{ij} \Sigma^{-1} p(x,y,t) p \frac{d}{dt}p =  \frac{1}{2} \Delta_M  p, \  p(x,y,0) = \delta_y(x).  d_M(x,y) = \inf \{ L(\gamma) | \gamma \text{ a piecewise continuos curve from } x \text{ to } y\}. E = (\mathbb{R}^n,\Sigma^{-1}) d_E(x,y) = \sqrt{(x-y)^T \Sigma^{-1} (x-y)}. \ln p(x,y,t) \propto - d_E(x,y)^2. \ln p(x,y,t) \propto - d_M(x,y)^2 M \frac{\partial x_k} {\partial t^2} = -\Gamma^{k}_{ij} \frac{\partial x_i}{\partial t}\frac{\partial x_j}{\partial t}  \Gamma^{k}_{ij}  \Gamma^i_{ij} = \frac{1}{\sqrt{\det g}} \frac{\partial}{\partial x_j} (\sqrt{\det g})","['differential-geometry', 'stochastic-processes', 'riemannian-geometry', 'brownian-motion', 'stochastic-differential-equations']"
13,"Is $L^*L$, where $L^*$ denotes the formal adjoint, positive semi-definite?","Is , where  denotes the formal adjoint, positive semi-definite?",L^*L L^*,"Let $E$ , $F$ be vector bundles with metric over a smooth (not necessarily compact) manifold $X$ . Let $L:C^\infty(E) \rightarrow C^\infty(F)$ be a differential operator. Let $L^*:C^\infty(F) \rightarrow C^\infty(F)$ be the formal adjoint of $L$ with respect to the $L^2$ -inner product on the $L^2$ -sections of $E$ and $F$ , i.e. $L^*$ satisfies: $$ \langle L f,g \rangle_{L^2(F)} = \langle f, L^*g \rangle_{L^2(E)} $$ for all $f \in C^\infty(E)$ , $f \in C^\infty(F)$ with compact support. Then $L^*$ is again a differential operator and can therefore be applied to all smooth sections of $F$ . Question: Are all eigenvalues of $L^*L$ acting on smooth sections non-negative? Here, smooth sections need not be in $L^2$ . $L^* L$ acting on $L^2_2(E)$ has only non-negative eigenvalues, because of $$ \langle L^* L f, f \rangle  = \langle Lf, Lf \rangle = |L f|^2 \geq 0. $$ But according to what I know, it could be possible that there exists some section $f \in C^\infty(E)$ that is not in $L^2_2(E)$ , for example because its $L^2$ -integral is infinite, but satisfies $Lf=-f$ . Context about my application: I am interested in the case where $P$ is a principal bundle over an asymptotically conical manifold, $A$ is an asymptotically flat connection on $P$ , and $L=\nabla_A$ on $\operatorname{Ad} P$ . I am also interested only in sections $f \in C^\infty(E)$ which decay at infinity, but they may not decay fast enough to be in $L^2(E)$ .","Let , be vector bundles with metric over a smooth (not necessarily compact) manifold . Let be a differential operator. Let be the formal adjoint of with respect to the -inner product on the -sections of and , i.e. satisfies: for all , with compact support. Then is again a differential operator and can therefore be applied to all smooth sections of . Question: Are all eigenvalues of acting on smooth sections non-negative? Here, smooth sections need not be in . acting on has only non-negative eigenvalues, because of But according to what I know, it could be possible that there exists some section that is not in , for example because its -integral is infinite, but satisfies . Context about my application: I am interested in the case where is a principal bundle over an asymptotically conical manifold, is an asymptotically flat connection on , and on . I am also interested only in sections which decay at infinity, but they may not decay fast enough to be in .","E F X L:C^\infty(E) \rightarrow C^\infty(F) L^*:C^\infty(F) \rightarrow C^\infty(F) L L^2 L^2 E F L^* 
\langle L f,g \rangle_{L^2(F)} =
\langle f, L^*g \rangle_{L^2(E)}
 f \in C^\infty(E) f \in C^\infty(F) L^* F L^*L L^2 L^* L L^2_2(E) 
\langle L^* L f, f \rangle 
=
\langle Lf, Lf \rangle
=
|L f|^2 \geq 0.
 f \in C^\infty(E) L^2_2(E) L^2 Lf=-f P A P L=\nabla_A \operatorname{Ad} P f \in C^\infty(E) L^2(E)","['differential-geometry', 'partial-differential-equations', 'adjoint-operators']"
14,Manifolds with isometry group $ SU_n $,Manifolds with isometry group, SU_n ,"The sphere $ S^n $ equipped with a metric of constant positive curvature $ g $ has orientation preserving isometry group $$ Iso^+(S^n,g) \cong SO_{n+1}(\mathbb{R}) $$ Indeed every compact group is the isometry group of some manifold see https://mathoverflow.net/questions/87070/can-every-lie-group-be-realized-as-the-full-isometry-group-of-a-riemannian-manif?rq=1 However it is not clear to me how this works in particular examples. Is there a ""well-known"" family of Riemannian manifolds $ M^n $ whose group of orientation preserving isometries is $ SU_n $ ? I know that $ \mathbb{C}P^{n-1} $ with the Fubini Study metric has orientation preserving isometry group $ PU_n $ , when $ n $ is even, (see What is the compact Riemannian manifold $M$ such that $SU(n)/\mathbb{Z}_n$ is the isometry group of $M$? ) so that's close but not quite it.","The sphere equipped with a metric of constant positive curvature has orientation preserving isometry group Indeed every compact group is the isometry group of some manifold see https://mathoverflow.net/questions/87070/can-every-lie-group-be-realized-as-the-full-isometry-group-of-a-riemannian-manif?rq=1 However it is not clear to me how this works in particular examples. Is there a ""well-known"" family of Riemannian manifolds whose group of orientation preserving isometries is ? I know that with the Fubini Study metric has orientation preserving isometry group , when is even, (see What is the compact Riemannian manifold $M$ such that $SU(n)/\mathbb{Z}_n$ is the isometry group of $M$? ) so that's close but not quite it."," S^n   g  
Iso^+(S^n,g) \cong SO_{n+1}(\mathbb{R})
  M^n   SU_n   \mathbb{C}P^{n-1}   PU_n   n ","['differential-geometry', 'riemannian-geometry']"
15,Laplace-Beltrami operator of a vector field/function on an arbitrary curved surface,Laplace-Beltrami operator of a vector field/function on an arbitrary curved surface,,"Given a surface $\mathcal S$ , I want to compute the Laplace-Beltrami operator of a tangent vector field/function $\mathbf v: \mathcal S \to T\mathcal S$ . Definitions/what I know: There exists a parametrization $\mathbf {X}(x^1,x^2)$ of the surface $\mathcal S$ (with local coordinates $x^1, x^2$ ), which defines two tangent vectors to each point on the surface $\mathbf e_i = \frac{\partial \mathbf X}{\partial x^I} = \partial_i \mathbf X$ (basis vectors, orthogonal but not necessarily orthonormal). The covariant derivative of a vector $\mathbf v$ with contravariant components $v^i$ is $\nabla_i v^j = \mathbf e^j \cdot \partial_i \mathbf v = \partial_i v^j + \Gamma_{ik}^j v^k$ , where $\Gamma_{ik}^j$ are the Christoffel symbols. The gradient $\nabla_{\mathcal S}$ of a scalar function $u: \mathcal M\to \mathbb R$ is given by $\nabla_{\mathcal S} u = \mathbf e^i \partial_i u$ , and the divergence $\nabla_{\mathcal S}\cdot$ of a vector function $\mathbf v$ is given by $\nabla_{\mathcal S} \mathbf v = \nabla_i v^i$ . The Laplace-Beltrami operator is defined for a scalar function $u$ by $\Delta_{\mathcal S} u = \nabla_{\mathcal S} \cdot \nabla_{\mathcal S}u = g^{ij} \nabla_i \nabla_j u$ , where $g^{ij}$ is the inverse of the metric $g_{ij}$ . My questions: Is the Laplace-Beltrami operator of a vector function $\mathbf v$ given by $\Delta_{\mathcal S} \mathbf v = \nabla_{\mathcal S} \cdot \nabla_{\mathcal S} \mathbf v$ ? How does that look (contravariant) componentwise? Is it $[\Delta_{\mathcal S} \mathbf v]^k = g^{ij} \nabla_i \nabla_j v^k$ ? I found in a reference a different expression: $\Delta_{\mathcal S} \mathbf v = \mathbf e_i \nabla_j\nabla^j v^i - 2 \mathbf n C_j^i \nabla_i v^j - \mathbf e_k v^i C_i^j C_j^k$ , where $\mathbf n$ is the normal to the surface and $C_{ij} = -\mathbf n \cdot \partial_i\partial_j\mathbf X$ is the curvature tensor. This is obtained by ""several times applying the Gauss-Weingarten relations"": $\partial_i\mathbf e_j = -C_{ij} \mathbf n + \Gamma_{ij}^k \mathbf e_k$ and $\partial_i \mathbf n = C_i^j \mathbf e_j$ . Is this maybe the correct expression instead of the one in question 1?","Given a surface , I want to compute the Laplace-Beltrami operator of a tangent vector field/function . Definitions/what I know: There exists a parametrization of the surface (with local coordinates ), which defines two tangent vectors to each point on the surface (basis vectors, orthogonal but not necessarily orthonormal). The covariant derivative of a vector with contravariant components is , where are the Christoffel symbols. The gradient of a scalar function is given by , and the divergence of a vector function is given by . The Laplace-Beltrami operator is defined for a scalar function by , where is the inverse of the metric . My questions: Is the Laplace-Beltrami operator of a vector function given by ? How does that look (contravariant) componentwise? Is it ? I found in a reference a different expression: , where is the normal to the surface and is the curvature tensor. This is obtained by ""several times applying the Gauss-Weingarten relations"": and . Is this maybe the correct expression instead of the one in question 1?","\mathcal S \mathbf v: \mathcal S \to T\mathcal S \mathbf {X}(x^1,x^2) \mathcal S x^1, x^2 \mathbf e_i = \frac{\partial \mathbf X}{\partial x^I} = \partial_i \mathbf X \mathbf v v^i \nabla_i v^j = \mathbf e^j \cdot \partial_i \mathbf v = \partial_i v^j + \Gamma_{ik}^j v^k \Gamma_{ik}^j \nabla_{\mathcal S} u: \mathcal M\to \mathbb R \nabla_{\mathcal S} u = \mathbf e^i \partial_i u \nabla_{\mathcal S}\cdot \mathbf v \nabla_{\mathcal S} \mathbf v = \nabla_i v^i u \Delta_{\mathcal S} u = \nabla_{\mathcal S} \cdot \nabla_{\mathcal S}u = g^{ij} \nabla_i \nabla_j u g^{ij} g_{ij} \mathbf v \Delta_{\mathcal S} \mathbf v = \nabla_{\mathcal S} \cdot \nabla_{\mathcal S} \mathbf v [\Delta_{\mathcal S} \mathbf v]^k = g^{ij} \nabla_i \nabla_j v^k \Delta_{\mathcal S} \mathbf v = \mathbf e_i \nabla_j\nabla^j v^i - 2 \mathbf n C_j^i \nabla_i v^j - \mathbf e_k v^i C_i^j C_j^k \mathbf n C_{ij} = -\mathbf n \cdot \partial_i\partial_j\mathbf X \partial_i\mathbf e_j = -C_{ij} \mathbf n + \Gamma_{ij}^k \mathbf e_k \partial_i \mathbf n = C_i^j \mathbf e_j","['differential-geometry', 'tensors', 'laplacian']"
16,Period map for products of K3 surfaces,Period map for products of K3 surfaces,,"If $X$ is a K3 surface, it carries a unique (up to scaling with $\mathbb{C}^*$ ) holomorphic 2-form $\sigma$ , determined by the complex structure. Let $\Lambda=3U\oplus-2E_8$ be the K3-lattice. The period domain of a K3 surface is given by $$ \Omega=\{[\sigma]\in \mathbb{P}(\Lambda\otimes\mathbb{C})\colon \sigma\cdot\sigma=0, \sigma\cdot\overline{\sigma}>0\}. $$ A marked K3 surface is a pair $(X,\phi)$ , with $X$ K3 and where $\phi$ is an isometry $\phi:H^2(X,\mathbb{Z})\to \Lambda$ . Let $M_1$ be the set of equivalence classes of Marked K3 surfaces, and define the Period map $\tau:M_1\to \Omega$ by $\tau([X,\phi])=[\phi(\sigma_X)]$ . Now suppose $Y$ is another K3 surface, and consider the product of K3 surfaces $X\times Y$ . I want to define the period map for this product. By K체nneth's theorem, the natural map $$H^2(X,\mathbb{Z})\oplus H^2(Y,\mathbb{Z})\to H^2(X\times Y,\mathbb{Z})$$ is an isomorphism, so this endows $H^2(X\times Y,\mathbb{Z})$ with the natural lattice structure, isomorphic to $\Lambda\oplus\Lambda$ . Let $\phi:H^2(X\times Y,\mathbb{Z})\to \Lambda\oplus\Lambda$ . The product $X\times Y$ carries two nowhere vanishing holomorphic 2-forms: $\sigma_1=\pi^*_X\sigma_X$ and $\sigma_2=\pi^*_Y\sigma_Y$ . The new period domain would be $$ \Omega'=\{[(\sigma_1,\sigma_2)]\in\mathbb{P}((\Lambda\oplus\Lambda)\otimes\mathbb{C})\colon \sigma_1\cdot\sigma_1=0,\sigma_1\cdot\sigma_2=0,\sigma_2\cdot\sigma_2=0,\sigma_1\cdot\overline{\sigma_2}=0, \sigma_1\cdot\overline{\sigma_1}>0,\sigma_2\cdot\overline{\sigma_2}>0\}, $$ and I would like to define $\tau':M_1'\to \Omega'$ by $\tau'([X\times Y, \phi])=[(\phi(\sigma_1),\phi(\sigma_2)]$ . However, this is not really well-defined. Is there a better way to define the period map for the product of K3 surfaces? Edit: At first, I thought that $M_1'=M_1\times M_1, \Omega'=\Omega\times \Omega$ and $\tau'=\tau\times\tau$ . However, this does not seem to work dimensionwise, so I am interested in any ideas!","If is a K3 surface, it carries a unique (up to scaling with ) holomorphic 2-form , determined by the complex structure. Let be the K3-lattice. The period domain of a K3 surface is given by A marked K3 surface is a pair , with K3 and where is an isometry . Let be the set of equivalence classes of Marked K3 surfaces, and define the Period map by . Now suppose is another K3 surface, and consider the product of K3 surfaces . I want to define the period map for this product. By K체nneth's theorem, the natural map is an isomorphism, so this endows with the natural lattice structure, isomorphic to . Let . The product carries two nowhere vanishing holomorphic 2-forms: and . The new period domain would be and I would like to define by . However, this is not really well-defined. Is there a better way to define the period map for the product of K3 surfaces? Edit: At first, I thought that and . However, this does not seem to work dimensionwise, so I am interested in any ideas!","X \mathbb{C}^* \sigma \Lambda=3U\oplus-2E_8 
\Omega=\{[\sigma]\in \mathbb{P}(\Lambda\otimes\mathbb{C})\colon \sigma\cdot\sigma=0, \sigma\cdot\overline{\sigma}>0\}.
 (X,\phi) X \phi \phi:H^2(X,\mathbb{Z})\to \Lambda M_1 \tau:M_1\to \Omega \tau([X,\phi])=[\phi(\sigma_X)] Y X\times Y H^2(X,\mathbb{Z})\oplus H^2(Y,\mathbb{Z})\to H^2(X\times Y,\mathbb{Z}) H^2(X\times Y,\mathbb{Z}) \Lambda\oplus\Lambda \phi:H^2(X\times Y,\mathbb{Z})\to \Lambda\oplus\Lambda X\times Y \sigma_1=\pi^*_X\sigma_X \sigma_2=\pi^*_Y\sigma_Y 
\Omega'=\{[(\sigma_1,\sigma_2)]\in\mathbb{P}((\Lambda\oplus\Lambda)\otimes\mathbb{C})\colon \sigma_1\cdot\sigma_1=0,\sigma_1\cdot\sigma_2=0,\sigma_2\cdot\sigma_2=0,\sigma_1\cdot\overline{\sigma_2}=0, \sigma_1\cdot\overline{\sigma_1}>0,\sigma_2\cdot\overline{\sigma_2}>0\},
 \tau':M_1'\to \Omega' \tau'([X\times Y, \phi])=[(\phi(\sigma_1),\phi(\sigma_2)] M_1'=M_1\times M_1, \Omega'=\Omega\times \Omega \tau'=\tau\times\tau","['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'k3-surfaces']"
17,Lie Derivative weird form,Lie Derivative weird form,,"I am reading a physics paper, in which the Lie derivative is presented in this strange (to me) way: $$\mathcal{L}_Y=Y^A\partial_A+\frac{i}{2}D_AY_BS^{AB}$$ where $A,B=\{z,\bar{z}\}$ with $\{z,\bar{z}\}$ being the coordinates on the complex sphere (i.e. connected to the usual polar/azimuthal coordinates via $z=e^{i\phi}\tan\frac{\theta}{2}$ ) and $S_{AB}$ is the pullback of the spin operator on the complex two sphere. The antisymmetric spin operator is given by $$S_{12}=\frac{h(1-z\bar{z})}{1+z\bar{z}},\ S_{13}=\frac{ih(z-\bar{z})}{1+z\bar{z}},\ S_{23}=\frac{h(z+\bar{z})}{1+z\bar{z}}$$ where the indices run from zero to three. Can someone shed some light on how do we manage to write the Lie derivative without the tensor it is supposed to be acted upon and on how can one write it in terms of the pullback of some operator?? I do not know if my question makes sense, but basically I can not understand why the Lie derivative is given in the form it is given. I have taken a geometry of GR class, so I am familiar with the basic definitions and with finding the components of the Lie derivative, when acted upon an arbitrary tensor. Thanks a lot.","I am reading a physics paper, in which the Lie derivative is presented in this strange (to me) way: where with being the coordinates on the complex sphere (i.e. connected to the usual polar/azimuthal coordinates via ) and is the pullback of the spin operator on the complex two sphere. The antisymmetric spin operator is given by where the indices run from zero to three. Can someone shed some light on how do we manage to write the Lie derivative without the tensor it is supposed to be acted upon and on how can one write it in terms of the pullback of some operator?? I do not know if my question makes sense, but basically I can not understand why the Lie derivative is given in the form it is given. I have taken a geometry of GR class, so I am familiar with the basic definitions and with finding the components of the Lie derivative, when acted upon an arbitrary tensor. Thanks a lot.","\mathcal{L}_Y=Y^A\partial_A+\frac{i}{2}D_AY_BS^{AB} A,B=\{z,\bar{z}\} \{z,\bar{z}\} z=e^{i\phi}\tan\frac{\theta}{2} S_{AB} S_{12}=\frac{h(1-z\bar{z})}{1+z\bar{z}},\ S_{13}=\frac{ih(z-\bar{z})}{1+z\bar{z}},\ S_{23}=\frac{h(z+\bar{z})}{1+z\bar{z}}","['differential-geometry', 'riemannian-geometry', 'general-relativity', 'lie-derivative']"
18,Neat claim induced from a converse to the Sard's Theorem,Neat claim induced from a converse to the Sard's Theorem,,"I found the following two posts to be interesting when I'm studying Sard's Theorem by myself: On the converse of Sard's theorem https://mathoverflow.net/questions/423475/a-modified-version-of-the-converse-to-the-sards-theorem In particular, is there a way to prove the neat claim in the mathoverflow post (without using advanced tools like triangulation of manifolds)? The questions is restated below: For any manifold $X$ with $\dim X \geq 1$ , there always exists some map $f:X \rightarrow \mathbb{R}^2$ , such that the differential $df_{x}$ is nonzero for any $x \in X$ . (Here we don't require $df_{x}$ to be nonsingular for any $x \in X$ , which weakens the claim.) I think the claim should be true after trying several examples, but I haven't found a way to prove it...thanks for any help in advance!","I found the following two posts to be interesting when I'm studying Sard's Theorem by myself: On the converse of Sard's theorem https://mathoverflow.net/questions/423475/a-modified-version-of-the-converse-to-the-sards-theorem In particular, is there a way to prove the neat claim in the mathoverflow post (without using advanced tools like triangulation of manifolds)? The questions is restated below: For any manifold with , there always exists some map , such that the differential is nonzero for any . (Here we don't require to be nonsingular for any , which weakens the claim.) I think the claim should be true after trying several examples, but I haven't found a way to prove it...thanks for any help in advance!",X \dim X \geq 1 f:X \rightarrow \mathbb{R}^2 df_{x} x \in X df_{x} x \in X,"['general-topology', 'differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
19,Relation between two problems in Chapter 4.4 (Integration on Manifolds) in Guillemin and Pollack,Relation between two problems in Chapter 4.4 (Integration on Manifolds) in Guillemin and Pollack,,"I encountered the following two exercises when I use the book ""Differential Topology"" by Guillemin and Pollack to study differential forms and integration on manifolds by myself, and I'm wondering whether one of them is actually a particular case of the other? They are listed below: Background: (Exercise 4.4.13) Let $S$ be an oriented two-manifold in $\mathbb{R}^3$ and $\overrightarrow{n}(x) = (n_1(x),n_2(x),n_3(x))$ be the outward unit normal to $S$ at $x$ (defined in Exercise 3.2.19). We may define a $2$ -form $dA$ on $S$ as follows: $$dA = n_1 dx_2 \wedge dx_3 + n_2 dx_3 \wedge dx_1 + n_3 dx_1 \wedge dx_2$$ where each $dx_i$ above is restricted to $S$ . Then we have that if $S$ is the graph of some function $F:\mathbb{R}^2 \rightarrow \mathbb{R}$ (i.e, $S = \{(x_1,x_2,F(x_1,x_2)) \ | \ (x_1,x_2) \in \mathbb{R}^2\}$ ) with orientation induced from $\mathbb{R}^2$ , then $dA$ is the same as that defined in text, i.e $dA = |\overrightarrow{n}|dx_1 \wedge dx_2$ (Exercise 4.4.14) Let $\omega = f_1 dx_2 \wedge dx_3 + f_2 dx_3 \wedge dx_1 + f_3 dx_1 \wedge dx_2$ be an arbitrary $2$ -form on $\mathbb{R}^3$ , then we have that the restriction of $\omega$ to $S$ is the form $(\overrightarrow{F} \cdot \overrightarrow{n})dA$ , where $S$ is the graph of some function mapping from $\mathbb{R}^2$ to $\mathbb{R}$ , $\overrightarrow{F}(x) = (f_1(x), f_2(x), f_3(x))$ and $\overrightarrow{n}$ is the vector normal to $S$ I feel that the two questions above have the same assumption, but is it true that Exercise 13 is a particular case of Exercise 14? By picking $f_i =n_i \ (i=1,2,3)$ to be the components of the normal vector, we can reduce Exercise 14 to Exercise 13, right? FYI, I have followed the hint to solve for Exercise 14 and I'm currently unsure whether I can use Exercise 14 to prove Exercise 13 directly. Any help/hint would be appreciated! Thank you so much!","I encountered the following two exercises when I use the book ""Differential Topology"" by Guillemin and Pollack to study differential forms and integration on manifolds by myself, and I'm wondering whether one of them is actually a particular case of the other? They are listed below: Background: (Exercise 4.4.13) Let be an oriented two-manifold in and be the outward unit normal to at (defined in Exercise 3.2.19). We may define a -form on as follows: where each above is restricted to . Then we have that if is the graph of some function (i.e, ) with orientation induced from , then is the same as that defined in text, i.e (Exercise 4.4.14) Let be an arbitrary -form on , then we have that the restriction of to is the form , where is the graph of some function mapping from to , and is the vector normal to I feel that the two questions above have the same assumption, but is it true that Exercise 13 is a particular case of Exercise 14? By picking to be the components of the normal vector, we can reduce Exercise 14 to Exercise 13, right? FYI, I have followed the hint to solve for Exercise 14 and I'm currently unsure whether I can use Exercise 14 to prove Exercise 13 directly. Any help/hint would be appreciated! Thank you so much!","S \mathbb{R}^3 \overrightarrow{n}(x) = (n_1(x),n_2(x),n_3(x)) S x 2 dA S dA = n_1 dx_2 \wedge dx_3 + n_2 dx_3 \wedge dx_1 + n_3 dx_1 \wedge dx_2 dx_i S S F:\mathbb{R}^2 \rightarrow \mathbb{R} S = \{(x_1,x_2,F(x_1,x_2)) \ | \ (x_1,x_2) \in \mathbb{R}^2\} \mathbb{R}^2 dA dA = |\overrightarrow{n}|dx_1 \wedge dx_2 \omega = f_1 dx_2 \wedge dx_3 + f_2 dx_3 \wedge dx_1 + f_3 dx_1 \wedge dx_2 2 \mathbb{R}^3 \omega S (\overrightarrow{F} \cdot \overrightarrow{n})dA S \mathbb{R}^2 \mathbb{R} \overrightarrow{F}(x) = (f_1(x), f_2(x), f_3(x)) \overrightarrow{n} S f_i =n_i \ (i=1,2,3)","['geometry', 'differential-geometry', 'differential-topology', 'differential-forms', 'vector-fields']"
20,"What is the ""gauge field"" on the base space in a gauge field theory?","What is the ""gauge field"" on the base space in a gauge field theory?",,"Suppose we have a principal $G$ -bundle $P\xrightarrow{\pi} M$ , and we want to consider a classical gauge field theory (with a field Lagrangian) on $M$ for this bundle, in the physics sense. In the physics literature they seem to use a ""gauge field"" on $M$ , which seems to me to be $s^*A$ where $s$ is a (global? local?) section of $\pi$ and $A$ is a principal bundle connection (as defined here ). My question is, do we assume $\pi$ admits a global section $s$ then work with $s^*A$ as the gauge field? In which case the principal bundle would be globally trivial? Furthermore, in the above case wouldn't the theory depend in some nontrivial way on the choice of section (e.g. its homotopy class)? Or, do we consider $M$ to be covered by a collection of local sections, and we assume that the Lagrangian/action is invariant under the ""transition maps"" between $s_i^*A$ and $s_j^*A$ ?","Suppose we have a principal -bundle , and we want to consider a classical gauge field theory (with a field Lagrangian) on for this bundle, in the physics sense. In the physics literature they seem to use a ""gauge field"" on , which seems to me to be where is a (global? local?) section of and is a principal bundle connection (as defined here ). My question is, do we assume admits a global section then work with as the gauge field? In which case the principal bundle would be globally trivial? Furthermore, in the above case wouldn't the theory depend in some nontrivial way on the choice of section (e.g. its homotopy class)? Or, do we consider to be covered by a collection of local sections, and we assume that the Lagrangian/action is invariant under the ""transition maps"" between and ?",G P\xrightarrow{\pi} M M M s^*A s \pi A \pi s s^*A M s_i^*A s_j^*A,"['differential-geometry', 'field-theory', 'connections', 'principal-bundles', 'gauge-theory']"
21,Are there tensor structures other than a metric which could be defined on a manifold which imply a connection through compatibility criterion?,Are there tensor structures other than a metric which could be defined on a manifold which imply a connection through compatibility criterion?,,"If we say our connection is torsion free, then the metric compatibility condition completely determines it. While this is geometrically intuitive way to do it, are there other interesting tensor fields which we can put on a manifold whom when we impose a compatibility condition with the connection that we uniquely get the connection?","If we say our connection is torsion free, then the metric compatibility condition completely determines it. While this is geometrically intuitive way to do it, are there other interesting tensor fields which we can put on a manifold whom when we impose a compatibility condition with the connection that we uniquely get the connection?",,"['differential-geometry', 'connections']"
22,Lie derivative in Kahler manifold,Lie derivative in Kahler manifold,,"I have the following question $X$ - a compact Kahler manifold and $v\in \Gamma(X,TX)$ - Killing vector field. I don't understand why Lie derivatives equal to zero $L_v \omega=0$ where $\omega$ is the Kahler form $L_vI=0$ where $I$ is the complex structure My attempt is the following. Killing field is satisfied the following equation $L_vg=0$ . We have known from the definition that A Kahler Manifold is an hermitian manifold, whose K채lher form is closed. It follows that $d\omega=0$ . Let $h$ -hermitian metric and from the famous theorem we know that there is a correspondence between $h \to \omega=-Im  h$ . And we have that $g(m,n)=\omega(m,In)$ , where $I$ is the complex structure. And we can obtain the result or am I a wrong about the first statement? I don't know what to do with the second statement. If you don't mind please explain it in more details. Thank you!","I have the following question - a compact Kahler manifold and - Killing vector field. I don't understand why Lie derivatives equal to zero where is the Kahler form where is the complex structure My attempt is the following. Killing field is satisfied the following equation . We have known from the definition that A Kahler Manifold is an hermitian manifold, whose K채lher form is closed. It follows that . Let -hermitian metric and from the famous theorem we know that there is a correspondence between . And we have that , where is the complex structure. And we can obtain the result or am I a wrong about the first statement? I don't know what to do with the second statement. If you don't mind please explain it in more details. Thank you!","X v\in \Gamma(X,TX) L_v \omega=0 \omega L_vI=0 I L_vg=0 d\omega=0 h h \to \omega=-Im  h g(m,n)=\omega(m,In) I","['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
23,Do Carmo Problem - Section 3.3 - 12,Do Carmo Problem - Section 3.3 - 12,,"The problem statement is as follows - Consider the parametrised surface $$ x(u,v) = \bigg(\sin u\cos v , \sin u\sin v , \cos u + \log(\tan\frac{u}{2})  +\phi(v)  \bigg) $$ where $\ \phi\ $ is a differentiable function. Prove that a. The curves $\ v \ $ = const. are contained in planes which pass through the z axis and intersect the surface under a constant angle $\ \theta\ $ given by $$ \cos \theta = \frac{\phi'}{\sqrt{1+(\phi')^2}}  $$ My attempt : For given parametrized surface $$ x(u,v) = \bigg(\sin u\cos v , \sin u\sin v , \cos u + \log(\tan\frac{u}{2})  +\phi(v)  \bigg) $$ with $ \ \phi \ $ - differentiable function we can write $ x_u = \bigg( \cos u\cos v \ ,\cos u \sin v \ , \cot u \cos u \bigg)$ $ x_v = \bigg( -\sin u\sin v \ ,\sin u \cos v \ , \phi' \bigg)$ $x_u\wedge x_v  = \begin{vmatrix} i & j & k\\  \cos u \cos v & \cos u \sin v  & \cot u \cos u \\  -\sin u \sin v & \sin u \cos v & \phi'  \end{vmatrix} \\ = i\bigg( \phi' \cos u \sin v - \cos ^2 u \cos v \bigg) - j\bigg( \phi' \cos u \cos v + \cos ^2 u \sin v \bigg) + k\bigg( \sin u \cos u  \bigg) $ The unit normal  N = $\frac{x_u\wedge x_v}{||x_u\wedge x_v||}$ . We first calculate $||x_u\wedge x_v||$ $$||x_u\wedge x_v|| \ = \ \sqrt{(\phi')^2\cos ^2u \sin ^2 v + \cos ^4u \cos ^2v - 2\phi'\cos ^3u \sin v \cos v + (\phi')^2\cos ^2u \cos ^2v \\ + \cos ^4u \sin ^2v  + 2\phi'\cos ^3u \cos v\sin v   + \sin ^2u \cos ^2u }$$ $||x_u\wedge x_v|| = \cos u \sqrt{1 + (\phi')^2}$ Hence, the unit normal to surface $ x(u,v) $ is given by $$N = \frac{1}{\sqrt{1 + (\phi')^2}} \bigg( \phi' \sin v - \cos u \cos v , \  - \phi' \cos v - \cos u \sin v , \  \sin u   \bigg)$$ Now, the unit normal vector to the plane passing through the curve $ v $ = const. and the z-axis , say V, will be given by $ V = (-\sin u, \cos u , 0 ) $ and then $ \theta $ will be $ \cos\theta = N\cdot V$ $$ \cos \theta  = \frac{\phi' (-\sin ^2 v ) + \cos u \cos v \sin v - \phi' \cos ^2 v - \cos u \sin v \cos v }{\sqrt{1+ (\phi')^2}}$$ $$ \cos \theta  = \frac{ - \phi' } {\sqrt{1+ (\phi')^2}}$$ Why am I getting the undesired -ve sign here? Is it due to the wrong direction of vector V or something else went wrong?","The problem statement is as follows - Consider the parametrised surface where is a differentiable function. Prove that a. The curves = const. are contained in planes which pass through the z axis and intersect the surface under a constant angle given by My attempt : For given parametrized surface with - differentiable function we can write The unit normal  N = . We first calculate Hence, the unit normal to surface is given by Now, the unit normal vector to the plane passing through the curve = const. and the z-axis , say V, will be given by and then will be Why am I getting the undesired -ve sign here? Is it due to the wrong direction of vector V or something else went wrong?"," x(u,v) = \bigg(\sin u\cos v , \sin u\sin v , \cos u + \log(\tan\frac{u}{2}) 
+\phi(v)  \bigg)  \ \phi\  \ v \  \ \theta\   \cos \theta = \frac{\phi'}{\sqrt{1+(\phi')^2}}    x(u,v) = \bigg(\sin u\cos v , \sin u\sin v , \cos u + \log(\tan\frac{u}{2}) 
+\phi(v)  \bigg)   \ \phi \   x_u = \bigg( \cos u\cos v \ ,\cos u \sin v \ , \cot u \cos u \bigg)  x_v = \bigg( -\sin u\sin v \ ,\sin u \cos v \ , \phi' \bigg) x_u\wedge x_v  = \begin{vmatrix}
i & j & k\\ 
\cos u \cos v & \cos u \sin v  & \cot u \cos u \\ 
-\sin u \sin v & \sin u \cos v & \phi' 
\end{vmatrix} \\ = i\bigg( \phi' \cos u \sin v - \cos ^2 u \cos v \bigg) - j\bigg( \phi' \cos u \cos v + \cos ^2 u \sin v \bigg) + k\bigg( \sin u \cos u  \bigg)  \frac{x_u\wedge x_v}{||x_u\wedge x_v||} ||x_u\wedge x_v|| ||x_u\wedge x_v|| \ = \ \sqrt{(\phi')^2\cos ^2u \sin ^2 v + \cos ^4u \cos ^2v - 2\phi'\cos ^3u \sin v \cos v + (\phi')^2\cos ^2u \cos ^2v \\ + \cos ^4u \sin ^2v  + 2\phi'\cos ^3u \cos v\sin v   + \sin ^2u \cos ^2u } ||x_u\wedge x_v|| = \cos u \sqrt{1 + (\phi')^2}  x(u,v)  N = \frac{1}{\sqrt{1 + (\phi')^2}} \bigg( \phi' \sin v - \cos u \cos v , \  - \phi' \cos v - \cos u \sin v , \  \sin u   \bigg)  v   V = (-\sin u, \cos u , 0 )   \theta   \cos\theta = N\cdot V  \cos \theta  = \frac{\phi' (-\sin ^2 v ) + \cos u \cos v \sin v - \phi' \cos ^2 v - \cos u \sin v \cos v }{\sqrt{1+ (\phi')^2}}  \cos \theta  = \frac{ - \phi' } {\sqrt{1+ (\phi')^2}}",['differential-geometry']
24,"Does a covering by trivializations imply existence of a linearly compatible one, for a smooth $\mathbb{R}^k$ fiber bundle?","Does a covering by trivializations imply existence of a linearly compatible one, for a smooth  fiber bundle?",\mathbb{R}^k,"Let $\pi : E\rightarrow B$ be a surjective submersion between smooth submanifolds. Let $k=\mathrm{dim}\,\mathrm{ker}\,\pi_*$ . We define a local trivialization of $\pi$ with fiber $\mathbb{R}^k$ to be a pair $(U,\phi)$ where $U\subset B$ is open and $\phi : \pi^{-1}(U) \xrightarrow{\approx} U\times \mathbb{R}^k$ is a diffeomorphism such that $\phi(y) \in \{\pi(y)\} \times \mathbb{R}^k \;\forall y\in \pi^{-1}(U)$ . We define an atlas of trivializations to be a collection $\{(U_\alpha,\phi_\alpha)\}_\alpha$ where each $(U_\alpha,\phi_\alpha)$ is a local trivialization and the $U_\alpha$ 's cover $B$ . We say an atlas of trivializations is linearly compatible if for every indices $\alpha,\beta$ , for every $p \in U_\alpha \cap U_\beta$ , the map $\mathbb{R}^k \rightarrow \{p\} \times \mathbb{R}^k : v \mapsto \phi_\alpha(\phi_\beta^{-1}(p,v))$ followed by $\{p\} \times \mathbb{R}^k \rightarrow \mathbb{R}^k : (p,w) \mapsto w$ is $\mathbb{R}$ -linear. My question is, if $\pi$ admits an atlas of trivializations with fiber $\mathbb{R}^k$ , then does it also admit a linearly compatible atlas? Edit: as has been pointed out in the comments, this fails if we relax $E$ and $B$ to topological manifolds and ""smooth""/""diffeo"" to ""continuous""/""homeo"". I've now changed the question to focus on the smooth case.","Let be a surjective submersion between smooth submanifolds. Let . We define a local trivialization of with fiber to be a pair where is open and is a diffeomorphism such that . We define an atlas of trivializations to be a collection where each is a local trivialization and the 's cover . We say an atlas of trivializations is linearly compatible if for every indices , for every , the map followed by is -linear. My question is, if admits an atlas of trivializations with fiber , then does it also admit a linearly compatible atlas? Edit: as has been pointed out in the comments, this fails if we relax and to topological manifolds and ""smooth""/""diffeo"" to ""continuous""/""homeo"". I've now changed the question to focus on the smooth case.","\pi : E\rightarrow B k=\mathrm{dim}\,\mathrm{ker}\,\pi_* \pi \mathbb{R}^k (U,\phi) U\subset B \phi : \pi^{-1}(U) \xrightarrow{\approx} U\times \mathbb{R}^k \phi(y) \in \{\pi(y)\} \times \mathbb{R}^k \;\forall y\in \pi^{-1}(U) \{(U_\alpha,\phi_\alpha)\}_\alpha (U_\alpha,\phi_\alpha) U_\alpha B \alpha,\beta p \in U_\alpha \cap U_\beta \mathbb{R}^k \rightarrow \{p\} \times \mathbb{R}^k : v \mapsto \phi_\alpha(\phi_\beta^{-1}(p,v)) \{p\} \times \mathbb{R}^k \rightarrow \mathbb{R}^k : (p,w) \mapsto w \mathbb{R} \pi \mathbb{R}^k E B","['general-topology', 'differential-geometry', 'vector-bundles']"
25,Prove intrinsic metric does not equal metric induced,Prove intrinsic metric does not equal metric induced,,"Let $U= (0,\infty) \times \mathbb{R}$ and consider the function $f:U \longrightarrow \mathbb{R}^{3}$ defined by: $f(u,v)=(\sinh u\cos v, \sinh u\sin v, \cosh u).$ (i) Let $\mathbb{H}^{2} = \{(x,y,z) \in \mathbb{R}^{3} \mid \, x^{2}+y^{2}-z^{2} = -1, \, \, z>0\}$ be the upper sheet of a hyperboloid in $\mathbb{R}^{3}$ and note the $S=\mathbb{H}^{2} \backslash \{(0,0,1)\}$ . Prove the intrinsic metric $d_{int}$ on $S\subseteq \mathbb{R}^{3}$ does not equal the metric induced by $d$ . So for this all I really know is that $\mathbb{H}^{2}$ with the metric $d(x,y)=\operatorname{arcosh}(-<x\mid y>)$ is a model for the hyperbolic plane, where $<\cdot \mid \cdot >$ is the Lorentz scalar product. I've been told to consider the points $A=(\sinh u,0,\cosh u)$ and $B=(-\sinh u,0,\cosh u)$ as a hint but I'm unsure how to. Any help would be appreciated! Edit: I'm not sure if what was in the previous parts will be relevant, but if so I do already know that $f(u,v)$ is a surface patch and I have the first and second fundamentals forms of $S=f(U)$ along with the Gauss Curvature of $S$","Let and consider the function defined by: (i) Let be the upper sheet of a hyperboloid in and note the . Prove the intrinsic metric on does not equal the metric induced by . So for this all I really know is that with the metric is a model for the hyperbolic plane, where is the Lorentz scalar product. I've been told to consider the points and as a hint but I'm unsure how to. Any help would be appreciated! Edit: I'm not sure if what was in the previous parts will be relevant, but if so I do already know that is a surface patch and I have the first and second fundamentals forms of along with the Gauss Curvature of","U= (0,\infty) \times \mathbb{R} f:U \longrightarrow \mathbb{R}^{3} f(u,v)=(\sinh u\cos v, \sinh u\sin v, \cosh u). \mathbb{H}^{2} = \{(x,y,z) \in \mathbb{R}^{3} \mid \, x^{2}+y^{2}-z^{2} = -1, \, \, z>0\} \mathbb{R}^{3} S=\mathbb{H}^{2} \backslash \{(0,0,1)\} d_{int} S\subseteq \mathbb{R}^{3} d \mathbb{H}^{2} d(x,y)=\operatorname{arcosh}(-<x\mid y>) <\cdot \mid \cdot > A=(\sinh u,0,\cosh u) B=(-\sinh u,0,\cosh u) f(u,v) S=f(U) S","['geometry', 'differential-geometry']"
26,When is the leaf space $M/\mathcal{F}$ of a foliation smooth?,When is the leaf space  of a foliation smooth?,M/\mathcal{F},"Let $(M,\mathcal{F})$ be a regular smooth foliation on a manifold $M$ . In general, the leaf space $M/\mathcal{F}$ is quite pathological. However, when $M$ is a Poisson manifold with compact, 1-connected leaves, the leaf space $M/\mathcal{F}$ is known to be a smooth manifold (cf. Poisson Manifolds of Compact Type 2 by Crainic, Fernandes and Martinez Torres). I am wondering what conditions on the leaves should be put to make this work. Is it the compactness, the 1-connectedness or the combination of the two?","Let be a regular smooth foliation on a manifold . In general, the leaf space is quite pathological. However, when is a Poisson manifold with compact, 1-connected leaves, the leaf space is known to be a smooth manifold (cf. Poisson Manifolds of Compact Type 2 by Crainic, Fernandes and Martinez Torres). I am wondering what conditions on the leaves should be put to make this work. Is it the compactness, the 1-connectedness or the combination of the two?","(M,\mathcal{F}) M M/\mathcal{F} M M/\mathcal{F}","['differential-geometry', 'algebraic-topology', 'differential-topology', 'foliations']"
27,A question about Constant sectional curvature between the Riemannian and K채hler manifold,A question about Constant sectional curvature between the Riemannian and K채hler manifold,,"According to the corollary (3.6) on An Introduction to Differentiable Manifolds and Riemannian Geometry, Def . A Riemannian manifold $M$ is isotropic at $p \in M$ if the curvature is the same constant at $k_p$ on every section at $p$ . And if $M$ is isotropic at every point $p$ , then the manifold $M$ is called isotropic . Corollary 3.6 Let $M$ be a $\underline{Riemannian ~manifold}$ . If $p \in M$ is isotropic and every point $p\in M$ ,  and $(U, \varphi)$ is a coordinate neighborhood with coordinate frames $E_1,....E_n$ and Riemannian metric $g_{ij}=(E_i,E_j)$ , then $$R_{ijkl}= -k_p(g_{ik}g_{ij}-g_{il}g_{jk}) $$ at $p\in M$ I think it is better to see the above corollary as : Corollary3.6' Let $M$ be a Riemannian manifold and $(U, \varphi)$ be a coordinate neighborhood  with coordinate frames $E_1,....E_n$ and Riemannian metric $g_{ij}=(E_i,E_j)$ . If $p\in M$ is isotropic, then $$R_{ijkl}=  -k_p(g_{ik}g_{ij}-g_{il}g_{jk}) $$ at $p\in M$ But, how about the converse statement of Corollary 3.6(') ? In other words, if $-{R_{ijkl}}/(g_{ik}g_{ij}-g_{il}g_{jk})$ is constant at each point $p\in M$ (or constant whenever pick a point $p \in M$ ),  then the manifold $M$ is a isotropic. (and naturally, $-{R_{ijkl}}/(g_{ik}g_{ij}-g_{il}g_{jk})=k_p$ ) The main reason I think the converse statement of Corollary3.6 is just K채hler manifold : In case of K채hler manifold $M$ , there exists a holomorphic sectional curvature at $p \in M$ and also one can think that this curvature is isotropic at $p\in M$ and isotropic (K채hler manifold) as well. However, on the following PDF , the term ""isotropic manifold"" on the Boothby's textbook seems to correspond ""CHSC"", short for a space of Constant Holomorphic Sectional Curvature. Anyway, according to Theorem 1.3.8 on the following PDF , Theorem 1.3.8 The following identities are equivalent . $(1)$ A $\underline{K채hler~ manifold} ~M$ is CHSC with constant $c$ ; $(2)$ (mumble, mumble) $(3)$ For any $U,V,W,X \in T^{(1,0)}M$ , $$R(U,\bar{V},W,\bar{X})=-\frac{c}{2}(g(U,\bar{V})g(W,\bar{X})+g(U,\bar{X})g(W,\bar{V}))$$ is introduced. In this case, however, the converse statement $(3)\Rightarrow (1)$ holds. To sum up, the statement of Corollary 3.6 in $\underline{Riemannian~ manifold}$ is nearly analogous to Thm1.3.8 in $\underline{K채hler~manifold}$ , but why the converse of Corollary 3.6 does not be mentioned(I doubt that the converse of this corollary would be false), whereas the converse of Thm1.3.8 holds? Here is the very question I wonder.","According to the corollary (3.6) on An Introduction to Differentiable Manifolds and Riemannian Geometry, Def . A Riemannian manifold is isotropic at if the curvature is the same constant at on every section at . And if is isotropic at every point , then the manifold is called isotropic . Corollary 3.6 Let be a . If is isotropic and every point ,  and is a coordinate neighborhood with coordinate frames and Riemannian metric , then at I think it is better to see the above corollary as : Corollary3.6' Let be a Riemannian manifold and be a coordinate neighborhood  with coordinate frames and Riemannian metric . If is isotropic, then at But, how about the converse statement of Corollary 3.6(') ? In other words, if is constant at each point (or constant whenever pick a point ),  then the manifold is a isotropic. (and naturally, ) The main reason I think the converse statement of Corollary3.6 is just K채hler manifold : In case of K채hler manifold , there exists a holomorphic sectional curvature at and also one can think that this curvature is isotropic at and isotropic (K채hler manifold) as well. However, on the following PDF , the term ""isotropic manifold"" on the Boothby's textbook seems to correspond ""CHSC"", short for a space of Constant Holomorphic Sectional Curvature. Anyway, according to Theorem 1.3.8 on the following PDF , Theorem 1.3.8 The following identities are equivalent . A is CHSC with constant ; (mumble, mumble) For any , is introduced. In this case, however, the converse statement holds. To sum up, the statement of Corollary 3.6 in is nearly analogous to Thm1.3.8 in , but why the converse of Corollary 3.6 does not be mentioned(I doubt that the converse of this corollary would be false), whereas the converse of Thm1.3.8 holds? Here is the very question I wonder.","M p \in M k_p p M p M M \underline{Riemannian ~manifold} p \in M p\in M (U, \varphi) E_1,....E_n g_{ij}=(E_i,E_j) R_{ijkl}= -k_p(g_{ik}g_{ij}-g_{il}g_{jk})
 p\in M M (U, \varphi) E_1,....E_n g_{ij}=(E_i,E_j) p\in M R_{ijkl}=
 -k_p(g_{ik}g_{ij}-g_{il}g_{jk})  p\in M -{R_{ijkl}}/(g_{ik}g_{ij}-g_{il}g_{jk}) p\in M p \in M M -{R_{ijkl}}/(g_{ik}g_{ij}-g_{il}g_{jk})=k_p M p \in M p\in M (1) \underline{K채hler~ manifold} ~M c (2) (3) U,V,W,X \in T^{(1,0)}M R(U,\bar{V},W,\bar{X})=-\frac{c}{2}(g(U,\bar{V})g(W,\bar{X})+g(U,\bar{X})g(W,\bar{V})) (3)\Rightarrow (1) \underline{Riemannian~ manifold} \underline{K채hler~manifold}","['differential-geometry', 'complex-geometry']"
28,"Why does the symbol of the Dirac operator have an ""i"" in it?","Why does the symbol of the Dirac operator have an ""i"" in it?",,"Suppose we have a differential operator of order $n$ that maps sections of a bundle $E \rightarrow M$ to sections of a bundle $F \rightarrow M$ : $$ D(\sigma) = \sum_{I} \alpha_{I} \frac{\partial^{I}}{\partial x^{I}} +\ \text{lower order terms}$$ Where $I$ ranges over multi-indices of length $n$ . Then I read that the symbol is defined to be: $$Symb(D)(\xi) = i^{n} \sum_{I} \alpha_{I} \xi^{I}$$ Where $\xi \in T^*_xM$ . The symbol is supposed to be a map between the pullbacks of the bundles $E$ and $F$ over the bundle $T^*M$ . My question is: why is there a power of $i = \sqrt{-1}$ in the expression for the symbol? If the bundles are just real vector bundles, where would the $i$ come from? (FYI I am reading this in Morgan's book on Seiberg Witten theory)","Suppose we have a differential operator of order that maps sections of a bundle to sections of a bundle : Where ranges over multi-indices of length . Then I read that the symbol is defined to be: Where . The symbol is supposed to be a map between the pullbacks of the bundles and over the bundle . My question is: why is there a power of in the expression for the symbol? If the bundles are just real vector bundles, where would the come from? (FYI I am reading this in Morgan's book on Seiberg Witten theory)",n E \rightarrow M F \rightarrow M  D(\sigma) = \sum_{I} \alpha_{I} \frac{\partial^{I}}{\partial x^{I}} +\ \text{lower order terms} I n Symb(D)(\xi) = i^{n} \sum_{I} \alpha_{I} \xi^{I} \xi \in T^*_xM E F T^*M i = \sqrt{-1} i,"['differential-geometry', 'elliptic-operators']"
29,Strong maximum principle applied to a complete asymptotically flat manifold,Strong maximum principle applied to a complete asymptotically flat manifold,,"Pardon me for not typing the following snapshot in MathJax. I'm sorry. This picture is an excerpt from Geometric Relativity by Dan A. Lee. I was wondering about the statement circled in red. How did the author infer from the strong maximum principle that $0<u<1$ everywhere? Indeed, we are seeking a positive function $u$ that serves our need in this proof, and since $v$ is not the zero vector, we see that $u$ cannot be $1$ identically. But how was it combined with the principle to give the fact that $u$ is bounded above by $1$ ? I need some help. Thank you so much.","Pardon me for not typing the following snapshot in MathJax. I'm sorry. This picture is an excerpt from Geometric Relativity by Dan A. Lee. I was wondering about the statement circled in red. How did the author infer from the strong maximum principle that everywhere? Indeed, we are seeking a positive function that serves our need in this proof, and since is not the zero vector, we see that cannot be identically. But how was it combined with the principle to give the fact that is bounded above by ? I need some help. Thank you so much.",0<u<1 u v u 1 u 1,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry']"
30,Does a codimension 1 subspace of a representation of lie group intersect all orbits?,Does a codimension 1 subspace of a representation of lie group intersect all orbits?,,"Let $G$ be a nice lie groups, and $V$ a complex irred representation. I am interested in understanding for which codim 1 subspaces $U \subset V$ , we have $G \cdot U = V$ (does there exist such $U$ ?). Let me emphasize that in $G U = V$ on the left I mean pointwise, not the span (which correlates with the title of the question by moving $G$ to the right) Specifically in my case, I care about $SO(3)$ and its irreducible representations.","Let be a nice lie groups, and a complex irred representation. I am interested in understanding for which codim 1 subspaces , we have (does there exist such ?). Let me emphasize that in on the left I mean pointwise, not the span (which correlates with the title of the question by moving to the right) Specifically in my case, I care about and its irreducible representations.",G V U \subset V G \cdot U = V U G U = V G SO(3),"['differential-geometry', 'representation-theory', 'lie-groups', 'lie-algebras']"
31,"Prove $\delta_{kl} + \frac{1}{3}\sum_{i,j}R_{ikjl}x^ix^j$ defines a metric",Prove  defines a metric,"\delta_{kl} + \frac{1}{3}\sum_{i,j}R_{ikjl}x^ix^j","Let $g$ be a bilinear form on $V$ over $\Bbb{R}$ , which is defined in terms of basis as : $$\delta_{kl} + \frac{1}{3}\sum_{i,j}R_{ikjl}x^ix^j$$ Where $R_{ikjl}$ is the algebraic curvature tensor, prove it defines a Riemannian metric when $|x|$ is small. (Combined with the fact that Taylor expansion of the metric is $$\begin{equation} g_{ij} = \delta_{ij} + \frac{1}{3} R_{ikjl} \,x^kx^l + \mathcal{O}(|x|^3)  \end{equation} $$ this shows the linear part of the Talor expansion is again a metric which is an approximation of the original metric.竊 The symmetry of the bilinear form $g$ due to symmetry of the curvature tensor, only needs to prove it's positive definite, that is we need to prove $$R_{ikjl}x^kx^lv^iv^j \ge 0$$ This seems not very obvious for me, I know we must use the symmetry of the curvature tensor, in particular the Jacobi identity for $R_{ikjl}$ .","Let be a bilinear form on over , which is defined in terms of basis as : Where is the algebraic curvature tensor, prove it defines a Riemannian metric when is small. (Combined with the fact that Taylor expansion of the metric is this shows the linear part of the Talor expansion is again a metric which is an approximation of the original metric.竊 The symmetry of the bilinear form due to symmetry of the curvature tensor, only needs to prove it's positive definite, that is we need to prove This seems not very obvious for me, I know we must use the symmetry of the curvature tensor, in particular the Jacobi identity for .","g V \Bbb{R} \delta_{kl} + \frac{1}{3}\sum_{i,j}R_{ikjl}x^ix^j R_{ikjl} |x| \begin{equation}
g_{ij} = \delta_{ij} + \frac{1}{3} R_{ikjl} \,x^kx^l + \mathcal{O}(|x|^3) 
\end{equation}
 g R_{ikjl}x^kx^lv^iv^j \ge 0 R_{ikjl}","['differential-geometry', 'riemannian-geometry']"
32,Doubt in identifications for a vector field in the product of manifolds,Doubt in identifications for a vector field in the product of manifolds,,"The following is the Exercise 1) a), Chapter 6 from do Carmo, Riemannian Geometry: Let $M_1$ and $M_2$ be Riemannian manifolds and consider $M_1 \times M_2$ with the product metric. Let $\nabla^1$ and $\nabla^2$ be the Riemannian connection in $M^1$ and $M^2$ , respectively. a) Show the Riemannian connection $\nabla$ of $M_1 \times M_2$ is given by $$\nabla_{X_1 + X_2}(Y_1 + Y_2) = \nabla^1_{X_1}Y_1 + \nabla^2_{X_2}Y_2,$$ where $X_1,Y_1 \in \mathcal{X}(M_1)$ and $X_2,Y_2 \in \mathcal{X}(M_2)$ . Here are my doubts: Doubt 1) I'm trying to understand what exactly means, for example, the sum $X_1 + X_2$ . Is it just a notation for $(X_1, X_2) \in \mathcal{X}(M_1) \times \mathcal{X}(M_2)$ ? Doubt 2) Given $p = (p_1,p_2) \in M_1 \times M_2$ , it's really commum to identify $$T_{p}(M_1 \times M_2) \equiv T_{p_1}M_1 \oplus T_{p_2}M_2.$$ Again, the meaning of the last direct sum is just $T_{p_1}M_1 \times T_{p_2}M_2$ ? In this case, the identification would be $$L : T_{p}(M_1 \times M_2)  \rightarrow T_{p_1}M_1 \times T_{p_2}M_2$$ defined by $L(w) = (\alpha_1'(0), \alpha_2'(0)),$ where $w \in T_{p}(M_1\times M_2)$ is given by $w = c'(0)$ , for $c(t) = (\alpha_1(t), \alpha_2(t))$ with $\alpha_1 : I \rightarrow M_1$ and $\alpha_2 : I \rightarrow M_2$ ? In this case, using the natural structure for the product $M_1\times M_2$ and the map $L$ , I conclude that a basis for $T_{p_1}M_1 \times T_{p_2}M_2$ would be: $$\{\partial_1, ...,\partial_{n}, \partial_{n+1}, ..., \partial_{n+m}\},$$ where $\partial_i = (\partial^1_i,0)$ , for $i = 1, ..., n$ and $\partial_i = (0, \partial^2_i)$ , for $i = n+1, ..., n+m$ [here $\partial^1_i$ and $\partial^2_i$ are tangent vector of the basis of $T_{p_1}M_1$ and $T_{p_2} M_2$ respectively]. Doubt 3) In item a) above, I believe the author is using the identification ""a tangent fild in $\mathcal{X} (M_1\times M_2)$ is given by $(X_1, X_2).$ In this case, what would mean $(X_1, X_2)(f),$ for $f \in C^{\infty}(M_1 \times M_2)$ ? What would be its expression on a local coordinate system of $M_1 \times M_2$ ? (I tried this using the basis I wrote in Doubt 2.) Doubt 4) What's the exactly relation between $\mathcal{X}(M_1\times M_2)$ and $\mathcal{X}(M_1) \times \mathcal{X}(M_2)$ ? What a tried for item a) : In general, given a Riemannian manifold $M$ of dimension $n$ , it's Levi-Civita connection is given by: $$\nabla_{X}Y = \sum_{k=1}^n(X(b_k) + \sum_{i,j=1}^n a_{i} b_{j} \Gamma_{ij}^k)\partial_k,$$ where, in coordenates, $X = \sum_{i=1}^n a_i \partial_i$ and $Y = \sum_{j=1}^n b_j \partial_j$ . I tried to go from this formula and use all the things I said in the Doubts. But I always get stuck when involves the functions in $C^{\infty}(M_1 \times M_2)$ . Something seems not to fit. Anyone may help me ?","The following is the Exercise 1) a), Chapter 6 from do Carmo, Riemannian Geometry: Let and be Riemannian manifolds and consider with the product metric. Let and be the Riemannian connection in and , respectively. a) Show the Riemannian connection of is given by where and . Here are my doubts: Doubt 1) I'm trying to understand what exactly means, for example, the sum . Is it just a notation for ? Doubt 2) Given , it's really commum to identify Again, the meaning of the last direct sum is just ? In this case, the identification would be defined by where is given by , for with and ? In this case, using the natural structure for the product and the map , I conclude that a basis for would be: where , for and , for [here and are tangent vector of the basis of and respectively]. Doubt 3) In item a) above, I believe the author is using the identification ""a tangent fild in is given by In this case, what would mean for ? What would be its expression on a local coordinate system of ? (I tried this using the basis I wrote in Doubt 2.) Doubt 4) What's the exactly relation between and ? What a tried for item a) : In general, given a Riemannian manifold of dimension , it's Levi-Civita connection is given by: where, in coordenates, and . I tried to go from this formula and use all the things I said in the Doubts. But I always get stuck when involves the functions in . Something seems not to fit. Anyone may help me ?","M_1 M_2 M_1 \times M_2 \nabla^1 \nabla^2 M^1 M^2 \nabla M_1 \times M_2 \nabla_{X_1 + X_2}(Y_1 + Y_2) = \nabla^1_{X_1}Y_1 + \nabla^2_{X_2}Y_2, X_1,Y_1 \in \mathcal{X}(M_1) X_2,Y_2 \in \mathcal{X}(M_2) X_1 + X_2 (X_1, X_2) \in \mathcal{X}(M_1) \times \mathcal{X}(M_2) p = (p_1,p_2) \in M_1 \times M_2 T_{p}(M_1 \times M_2) \equiv T_{p_1}M_1 \oplus T_{p_2}M_2. T_{p_1}M_1 \times T_{p_2}M_2 L : T_{p}(M_1 \times M_2)  \rightarrow T_{p_1}M_1 \times T_{p_2}M_2 L(w) = (\alpha_1'(0), \alpha_2'(0)), w \in T_{p}(M_1\times M_2) w = c'(0) c(t) = (\alpha_1(t), \alpha_2(t)) \alpha_1 : I \rightarrow M_1 \alpha_2 : I \rightarrow M_2 M_1\times M_2 L T_{p_1}M_1 \times T_{p_2}M_2 \{\partial_1, ...,\partial_{n}, \partial_{n+1}, ..., \partial_{n+m}\}, \partial_i = (\partial^1_i,0) i = 1, ..., n \partial_i = (0, \partial^2_i) i = n+1, ..., n+m \partial^1_i \partial^2_i T_{p_1}M_1 T_{p_2} M_2 \mathcal{X} (M_1\times M_2) (X_1, X_2). (X_1, X_2)(f), f \in C^{\infty}(M_1 \times M_2) M_1 \times M_2 \mathcal{X}(M_1\times M_2) \mathcal{X}(M_1) \times \mathcal{X}(M_2) M n \nabla_{X}Y = \sum_{k=1}^n(X(b_k) + \sum_{i,j=1}^n a_{i} b_{j} \Gamma_{ij}^k)\partial_k, X = \sum_{i=1}^n a_i \partial_i Y = \sum_{j=1}^n b_j \partial_j C^{\infty}(M_1 \times M_2)","['differential-geometry', 'riemannian-geometry', 'tangent-spaces']"
33,Proving Geometric definition of divergence of vector field as given by Tristan Needham,Proving Geometric definition of divergence of vector field as given by Tristan Needham,,"In page-479 of Visual Complex Analysis, Tirstan Needham derives the flux of a vector field in Geometric form: Here $z$ is the point to which the shaded region $R$ will ultimately be collapsed in order to find the divergence there, $S$ and $P$ are the streamline and orthogonal trajectory through $z$ , and $s$ and $p$ are arclength along $S$ and $P$ , the direction of increasing $p$ being choosen to make a positive right angle with $X$ $$ \nabla \cdot X = \partial_s |X| + \kappa_p |X|$$ The $\partial_S$ is a derivative along streamlines of the vector field $X$ and $\kappa_S$ is the curvature of the streamline  at the point we are taking divergence at. In the derivation of the formula using inifinitesimals, the following identity is used: $$ \delta ( dp)= \kappa_p ds dp= \kappa_p dA$$ I am trying to derive it. My attempt : $$ dp = r_p d \theta$$ Where $r_p$ is radius of osculating circle at $p$ of the orthogonal trajectory of $S$ and $d \theta$ is the angle in common with circle circle and arclength of the orthogonal trajectory. Assuming that the $d \theta$ doesn't change from the labelled dp to the red marked edge , we have: $$ \delta dp = dr_p d \theta \tag{1}$$ But we can consider the shaded region as a differential area of a circle: $$ dA= d(r^2) \frac{ d \theta}{2} = r_p dr_p d \theta$$ Rerranging $$ \frac{dA}{r_p} = \kappa_p dA = dr_p d \theta$$ .  Plugging that into (1) we have: $$ \delta (dp) = \kappa_p dA$$ Does my derivation look like what was intended?","In page-479 of Visual Complex Analysis, Tirstan Needham derives the flux of a vector field in Geometric form: Here is the point to which the shaded region will ultimately be collapsed in order to find the divergence there, and are the streamline and orthogonal trajectory through , and and are arclength along and , the direction of increasing being choosen to make a positive right angle with The is a derivative along streamlines of the vector field and is the curvature of the streamline  at the point we are taking divergence at. In the derivation of the formula using inifinitesimals, the following identity is used: I am trying to derive it. My attempt : Where is radius of osculating circle at of the orthogonal trajectory of and is the angle in common with circle circle and arclength of the orthogonal trajectory. Assuming that the doesn't change from the labelled dp to the red marked edge , we have: But we can consider the shaded region as a differential area of a circle: Rerranging .  Plugging that into (1) we have: Does my derivation look like what was intended?",z R S P z s p S P p X  \nabla \cdot X = \partial_s |X| + \kappa_p |X| \partial_S X \kappa_S  \delta ( dp)= \kappa_p ds dp= \kappa_p dA  dp = r_p d \theta r_p p S d \theta d \theta  \delta dp = dr_p d \theta \tag{1}  dA= d(r^2) \frac{ d \theta}{2} = r_p dr_p d \theta  \frac{dA}{r_p} = \kappa_p dA = dr_p d \theta  \delta (dp) = \kappa_p dA,"['differential-geometry', 'differential-forms', 'curvature']"
34,Stokes' theorem for a manifold without boundary,Stokes' theorem for a manifold without boundary,,"Stokes' theorem states that when $M$ is a compact oriented $m$ -manifold with boundary, and $\omega$ is a $(m-1)$ -form on $M$ , we have $$\int_{\partial M}\omega = \int_{M} d\omega.$$ This is confusing me for the following reason: It seems as if $\partial M$ were empty, i.e., if $M$ was a manifold without boundary, then we would have that the integral of $d \omega$ on the right is necessarily zero. But what if we took a manifold with boundary, and simply got rid of the boundary? This manifold would only differ from the original one on a set of measure zero, which should not affect the integration. This seems to imply that $\int_{M}d \omega$ is necessarily always zero, which of course can not be true. Where is the issue in my reasoning?","Stokes' theorem states that when is a compact oriented -manifold with boundary, and is a -form on , we have This is confusing me for the following reason: It seems as if were empty, i.e., if was a manifold without boundary, then we would have that the integral of on the right is necessarily zero. But what if we took a manifold with boundary, and simply got rid of the boundary? This manifold would only differ from the original one on a set of measure zero, which should not affect the integration. This seems to imply that is necessarily always zero, which of course can not be true. Where is the issue in my reasoning?",M m \omega (m-1) M \int_{\partial M}\omega = \int_{M} d\omega. \partial M M d \omega \int_{M}d \omega,"['differential-geometry', 'manifolds', 'differential-forms', 'stokes-theorem', 'manifolds-with-boundary']"
35,Understanding the quotient of $S^2$ by a non-free action of $\mathbb{Z}_2$,Understanding the quotient of  by a non-free action of,S^2 \mathbb{Z}_2,"I was reading this post and wondered about a similar thing. Let $\mathbb{Z}_2$ act on $S^2$ by letting the non-trivial element take $$(x,y,z)\mapsto(-x,-y,z).$$ This action is not free, so one would expect something to go ""wrong"" with the quotient space $S^2/\mathbb{Z}_2$ . On the surface, it seems like $S^2/\mathbb{Z}_2$ is a nice space; it is homeomorphic to $S^2$ , which is a topological manifold. However, the north and south ends of $S^2/\mathbb{Z}_2$ seem somewhat crushed and ""conical"", instead of smooth. But I'm not sure how to match this intuition with something rigorous. Question 1: Does $S^2/\mathbb{Z}_2$ inherit a smooth structure from $S^2$ ? If not, why not? Question 2: Is there some precise sense in which the north and south ends of $S^2/\mathbb{Z}_2$ are conical? (This would seem to assume that $S^2/\mathbb{Z}_2$ has a natural Riemannian metric; why is this the case?)","I was reading this post and wondered about a similar thing. Let act on by letting the non-trivial element take This action is not free, so one would expect something to go ""wrong"" with the quotient space . On the surface, it seems like is a nice space; it is homeomorphic to , which is a topological manifold. However, the north and south ends of seem somewhat crushed and ""conical"", instead of smooth. But I'm not sure how to match this intuition with something rigorous. Question 1: Does inherit a smooth structure from ? If not, why not? Question 2: Is there some precise sense in which the north and south ends of are conical? (This would seem to assume that has a natural Riemannian metric; why is this the case?)","\mathbb{Z}_2 S^2 (x,y,z)\mapsto(-x,-y,z). S^2/\mathbb{Z}_2 S^2/\mathbb{Z}_2 S^2 S^2/\mathbb{Z}_2 S^2/\mathbb{Z}_2 S^2 S^2/\mathbb{Z}_2 S^2/\mathbb{Z}_2","['differential-geometry', 'manifolds', 'riemannian-geometry', 'smooth-manifolds', 'group-actions']"
36,Changing the signs in the metric and the curvature,Changing the signs in the metric and the curvature,,"Suppose we have two Riemannian manifolds $(B,g_B)$ and $(F,g_F)$ and consider their product $C:=B\times F$ endowed with the metric tensor $g_C:=-\pi_B^*(g_B)+\pi_F^*(g_F)$ , where $\pi_B$ and $\pi_F$ denote the projections on $B$ and $F$ respectively and $^*$ is the pullback. If I want to write the Ricci tensor of $C$ , if $g$ was the usual product metric then that tensor would be just the sum of the two Ricci's on $B$ and $F$ , but in this case the sign $-$ in front of $\pi_B^*(g_B)$ should change the sign of the Ricci of $B$ : if $\xi:=x+v$ , where $x\in T_bB$ and $v\in T_fF$ for $b\in B$ and $f\in F$ , I would have $$\textrm{Ric}_{(b,f)}^C(\xi,\xi)=-\textrm{Ric}^B_b(x,x)+\textrm{Ric}^F_f(v,v).$$ What confuses me is the fact that if I change the sign in a metric of a Riemannian manifold the curvature tensors do not change (since the Riemann tensor is made of Christoffel symbols in coordinates which are products of the matrices of the metric) but here the Ricci does. Does this come from the fact that the metric contraction wrt the $g_C$ ? If I have a smooth function $f:X\rightarrow\mathbb{R}$ than the Hessian of $f$ would be the same of $B$ but with the same sign? P.s. I did everything not in coordinates, using, given a frame $\{E_i\}_i$ on $C$ , $$\textrm{Ric}^C(X,Y)=\sum_ig_C(E_i,E_i)\,g_C(\textrm{R}^C_{XE_i}Y,E_i),$$ following O'Neill computations in chapter $7$ of his book ""Semi-Riemannian geometry"".","Suppose we have two Riemannian manifolds and and consider their product endowed with the metric tensor , where and denote the projections on and respectively and is the pullback. If I want to write the Ricci tensor of , if was the usual product metric then that tensor would be just the sum of the two Ricci's on and , but in this case the sign in front of should change the sign of the Ricci of : if , where and for and , I would have What confuses me is the fact that if I change the sign in a metric of a Riemannian manifold the curvature tensors do not change (since the Riemann tensor is made of Christoffel symbols in coordinates which are products of the matrices of the metric) but here the Ricci does. Does this come from the fact that the metric contraction wrt the ? If I have a smooth function than the Hessian of would be the same of but with the same sign? P.s. I did everything not in coordinates, using, given a frame on , following O'Neill computations in chapter of his book ""Semi-Riemannian geometry"".","(B,g_B) (F,g_F) C:=B\times F g_C:=-\pi_B^*(g_B)+\pi_F^*(g_F) \pi_B \pi_F B F ^* C g B F - \pi_B^*(g_B) B \xi:=x+v x\in T_bB v\in T_fF b\in B f\in F \textrm{Ric}_{(b,f)}^C(\xi,\xi)=-\textrm{Ric}^B_b(x,x)+\textrm{Ric}^F_f(v,v). g_C f:X\rightarrow\mathbb{R} f B \{E_i\}_i C \textrm{Ric}^C(X,Y)=\sum_ig_C(E_i,E_i)\,g_C(\textrm{R}^C_{XE_i}Y,E_i), 7","['calculus', 'differential-geometry', 'riemannian-geometry', 'curvature', 'semi-riemannian-geometry']"
37,Kenmotsu - rotational surfaces,Kenmotsu - rotational surfaces,,"I was wondering if someone knows which is the parameterization that we made in these cases. I calculated till $$Z(s)=\left(\frac{1}{2iH}(1-e^{-2iHs})+C\right)e^{2iHs},$$ but can't figure out what parameterization was done after that and why we have the following values 뗢땏or $y(s)$ and $x^{'}(s)$ !",I was wondering if someone knows which is the parameterization that we made in these cases. I calculated till but can't figure out what parameterization was done after that and why we have the following values 뗢땏or and !,"Z(s)=\left(\frac{1}{2iH}(1-e^{-2iHs})+C\right)e^{2iHs}, y(s) x^{'}(s)",['differential-geometry']
38,Is the unit sphere of a smooth Banach space a smooth manifold?,Is the unit sphere of a smooth Banach space a smooth manifold?,,"A Banach space X is smooth if at every point of the unit sphere there is only one supporting hyperplane of the unit ball. Can we say for finite dimensional X, this implies the unit sphere to be differentiable manifold? The reverse implication is almost tautological. If not, what is a counterexample to this?","A Banach space X is smooth if at every point of the unit sphere there is only one supporting hyperplane of the unit ball. Can we say for finite dimensional X, this implies the unit sphere to be differentiable manifold? The reverse implication is almost tautological. If not, what is a counterexample to this?",,"['differential-geometry', 'banach-spaces']"
39,Necessary and sufficient conditions for existence of solutions to $\Delta \phi = f$ on torus,Necessary and sufficient conditions for existence of solutions to  on torus,\Delta \phi = f,"Let $\mathcal{T}$ be a torus with Riemannian metric. Consider the sourced Laplace equation on $\mathcal{T}$ : \begin{align} \tag{1} \Delta \phi = f. \end{align} I'd like to know necessary and sufficient conditions on $g$ which guarantee the existence of a solution for $\phi$ . One such condition is easy to spot: integrating both sides of (1) gives \begin{align} \tag{2} \int \text{vol }f   = 0. \end{align} I'd previously always thought that (2) was both necessary and sufficient, but now I'm not so sure. The reason for my doubt is that under a conformal rescaling of the metric $g'_{\mu\nu}=e^{2\Omega}g_{\mu\nu}$ , the Ricci scalar changes as $$\tag{3}\sqrt{g'}R' = \sqrt{g}(R-2\Delta \Omega).$$ By Gauss-Bonnet, $\int\text{vol }R=0$ , so if (2) was sufficient for existence, we'd always be able to find $\Omega$ such that the RHS of (3) vanishes. Hence we'd find every torus is conformally flat, which is not true (the moduli space of the torus has dimension 1). Therefore my guess is that there must be further conditions on the source function, on top of (2), which are necessary for solutions to exist to the sourced Laplace equation. What are these conditions?","Let be a torus with Riemannian metric. Consider the sourced Laplace equation on : I'd like to know necessary and sufficient conditions on which guarantee the existence of a solution for . One such condition is easy to spot: integrating both sides of (1) gives I'd previously always thought that (2) was both necessary and sufficient, but now I'm not so sure. The reason for my doubt is that under a conformal rescaling of the metric , the Ricci scalar changes as By Gauss-Bonnet, , so if (2) was sufficient for existence, we'd always be able to find such that the RHS of (3) vanishes. Hence we'd find every torus is conformally flat, which is not true (the moduli space of the torus has dimension 1). Therefore my guess is that there must be further conditions on the source function, on top of (2), which are necessary for solutions to exist to the sourced Laplace equation. What are these conditions?","\mathcal{T} \mathcal{T} \begin{align}
\tag{1}
\Delta \phi = f.
\end{align} g \phi \begin{align}
\tag{2}
\int \text{vol }f   = 0.
\end{align} g'_{\mu\nu}=e^{2\Omega}g_{\mu\nu} \tag{3}\sqrt{g'}R' = \sqrt{g}(R-2\Delta \Omega). \int\text{vol }R=0 \Omega","['differential-geometry', 'partial-differential-equations', 'harmonic-functions']"
40,Generalization of Poincare Lemma for vector fields,Generalization of Poincare Lemma for vector fields,,"Poincar챕 Lemma implies that for any vector field $A\in \mathbb{R}^3$ satisfying $\nabla \cdot A = \text{div }A = 0$ ,  we can express locally this vector field as $A = \nabla \times B = \text{rot }B$ , where $B$ is another vector field. Can we say something similar with respect to a symmetric 2-tensor field $\Sigma$ that satisfies $\nabla\cdot\Sigma = 0$ ? Note: $\nabla\cdot\Sigma = \sum_{k=1}^3 \cfrac{\partial \Sigma_{ik}}{\partial x^k}$","Poincar챕 Lemma implies that for any vector field satisfying ,  we can express locally this vector field as , where is another vector field. Can we say something similar with respect to a symmetric 2-tensor field that satisfies ? Note:",A\in \mathbb{R}^3 \nabla \cdot A = \text{div }A = 0 A = \nabla \times B = \text{rot }B B \Sigma \nabla\cdot\Sigma = 0 \nabla\cdot\Sigma = \sum_{k=1}^3 \cfrac{\partial \Sigma_{ik}}{\partial x^k},"['differential-geometry', 'partial-differential-equations', 'vector-analysis', 'vector-fields']"
41,Suppose $E$ is a smooth vector bundle over $M$. Show that the projection map $\pi :E \to M$ is a surjective smooth submersion.,Suppose  is a smooth vector bundle over . Show that the projection map  is a surjective smooth submersion.,E M \pi :E \to M,Suppose $E$ is a smooth vector bundle over $M$ . Show that the projection map $\pi :E \to M$ is a surjective smooth submersion. Since $E$ is a smooth vector bundle for each $p \in M$ there exists a neighborhood $U$ of $p$ such that $\varphi: \pi^{-1}(U) \to U \times \Bbb R^k$ is a diffeomorphism and that $\pi_1 \circ \varphi = \pi$ . In order for $\pi$ to be a smooth submersion the differential $d\pi_p : T_p E \to T_{\pi(p)} M$ must be surjective. Since we have the characterization $\pi_1 \circ \varphi = \pi$ we get that $$d\pi_{p} = d(\pi_1혻\circ \varphi)_p = d\pi_{1_{\varphi(p)}} \circ d\varphi_{p}.$$ Now I need to show that $d\pi_{1_{\varphi(p)}}$ and $d\varphi_{p}$ surjective maps in order to conclude the proof. Since $\varphi$ is a diffeomorphism we have that $\varphi^{-1}$ is a smooth bijection. So defining $d\varphi^{-1}_{q} : T_{q}(U \times \Bbb R^k) \to T_p \pi^{-1}(U)$ we have that $$d\varphi_p \circ d\varphi^{-1}_{q} = d(\varphi \circ \varphi^{-1})_{q} = d(id)_{q}$$ so $d\varphi^{-1}_{\varphi(p)}$ is an inverse for $d\varphi_p$ and so it's bijective and in particular surjective. Similarly for $d\pi_{1_p}:T_p(U \times \Bbb R^k) \to T_{\pi_1(p)}U$ define $d\iota_{U_q} : T_qU \to T_{\iota_U(q)}(U \times \Bbb R^k)$ where $\iota_U:U \to U \times \Bbb R^k$ is the right inverse of $\pi_1$ . Then we get that $$d\pi_{1_p} \circ d\iota_{U_q} = d(\pi_1 \circ \iota_U)_q=d(id)_q$$ which by same reasoning makes $d\pi_1$ surjective. Is there some problems with the proofs for the surjectivities for these differentials? I'm not very confident about them.,Suppose is a smooth vector bundle over . Show that the projection map is a surjective smooth submersion. Since is a smooth vector bundle for each there exists a neighborhood of such that is a diffeomorphism and that . In order for to be a smooth submersion the differential must be surjective. Since we have the characterization we get that Now I need to show that and surjective maps in order to conclude the proof. Since is a diffeomorphism we have that is a smooth bijection. So defining we have that so is an inverse for and so it's bijective and in particular surjective. Similarly for define where is the right inverse of . Then we get that which by same reasoning makes surjective. Is there some problems with the proofs for the surjectivities for these differentials? I'm not very confident about them.,E M \pi :E \to M E p \in M U p \varphi: \pi^{-1}(U) \to U \times \Bbb R^k \pi_1 \circ \varphi = \pi \pi d\pi_p : T_p E \to T_{\pi(p)} M \pi_1 \circ \varphi = \pi d\pi_{p} = d(\pi_1혻\circ \varphi)_p = d\pi_{1_{\varphi(p)}} \circ d\varphi_{p}. d\pi_{1_{\varphi(p)}} d\varphi_{p} \varphi \varphi^{-1} d\varphi^{-1}_{q} : T_{q}(U \times \Bbb R^k) \to T_p \pi^{-1}(U) d\varphi_p \circ d\varphi^{-1}_{q} = d(\varphi \circ \varphi^{-1})_{q} = d(id)_{q} d\varphi^{-1}_{\varphi(p)} d\varphi_p d\pi_{1_p}:T_p(U \times \Bbb R^k) \to T_{\pi_1(p)}U d\iota_{U_q} : T_qU \to T_{\iota_U(q)}(U \times \Bbb R^k) \iota_U:U \to U \times \Bbb R^k \pi_1 d\pi_{1_p} \circ d\iota_{U_q} = d(\pi_1 \circ \iota_U)_q=d(id)_q d\pi_1,"['differential-geometry', 'smooth-manifolds', 'vector-bundles']"
42,"Associate bundles, equivariant sections and tangent elements","Associate bundles, equivariant sections and tangent elements",,"Consider a principal $G$ -bundle over a manifold $X$ , and consider yet another manifold $B$ endowed with a $G$ -action. Everything is assumed to be smooth. The associated bundle $$ \mathcal{B}=P\times_G B $$ is a locally trivial bundle over $X$ . My question concerns the space of sections of this associated bundle, i.e., the infinite-dimensional manifold $\mathcal{S} =\Gamma(X,\mathcal{B})$ . Assume we have fixed such a section $\phi\in \Gamma(X,\mathcal{B})$ . I want to characterize, if possible, the tangent space $$ T_\phi \Gamma(X,\mathcal{B}) $$ of infinitesimal deformations $\dot{\phi}$ of that section, and I want to do it in such a way that $G$ -invariant geometric objects on $B$ give corresponding objects in this infinite-dimensional manifold $\Gamma(X,\mathcal{B})$ (will be detailed below). I want to analyze this tangent space under the light of the following fact: sections of the associated bundle correspond to $G$ -equivariant mappings $\tilde{\phi}:P\rightarrow B$ . Preliminary remarks A section $\phi$ has to always be vertical with respect to the base space. This means that if $\phi_t$ is a parametrized curve of sections of $\mathcal{B}$ , $\phi_0=\phi$ , then $\frac{d}{dt}|_{t=0} \phi_t$ has to send elements of the base $x\in X$ to vertical vectors in $\mathcal{B}$ attached at $\phi(x)$ . We could justify $$ T_\phi \mathcal{S} \simeq \Gamma(X,\phi^*V\mathcal{B}) $$ where $\phi^*V\mathcal{B}$ is the pullback to $X$ under $\phi$ of the vertical bundle of $\mathcal{B}$ . What I am missing I want a mechanism of lifting $G$ -invariant objects on $B$ to objects on $\mathcal{B}$ . Specifically, assume we have a $G$ -invariant 1-form $\sigma\in \Gamma(B,T^*B)$ . Is there a way in which I could build a field of 1-forms over $\mathcal{S}$ by equivariance? My end goal would to assume $B$ has a K채hler structure $\omega$ and to use this to endow $\mathcal{S}$ some formal K채hlerian structure (I'd need to assume $X$ compact with a prescribed volume form) and to make sense of candidate K채hler form on $\mathcal{S}$ via something like $$ \Omega(\dot{\Phi}_1,\dot{\Phi}_2) \sim \int_X \omega(\dot{\phi}_1,\dot{\phi}_2) $$ by either identifying tangent elements $\dot{\Phi}$ in terms of $B$ -valued maps or by defining a fiberwise K채hler-form $\omega$ on each fiber of the associated bundle $\mathcal{B}$ .","Consider a principal -bundle over a manifold , and consider yet another manifold endowed with a -action. Everything is assumed to be smooth. The associated bundle is a locally trivial bundle over . My question concerns the space of sections of this associated bundle, i.e., the infinite-dimensional manifold . Assume we have fixed such a section . I want to characterize, if possible, the tangent space of infinitesimal deformations of that section, and I want to do it in such a way that -invariant geometric objects on give corresponding objects in this infinite-dimensional manifold (will be detailed below). I want to analyze this tangent space under the light of the following fact: sections of the associated bundle correspond to -equivariant mappings . Preliminary remarks A section has to always be vertical with respect to the base space. This means that if is a parametrized curve of sections of , , then has to send elements of the base to vertical vectors in attached at . We could justify where is the pullback to under of the vertical bundle of . What I am missing I want a mechanism of lifting -invariant objects on to objects on . Specifically, assume we have a -invariant 1-form . Is there a way in which I could build a field of 1-forms over by equivariance? My end goal would to assume has a K채hler structure and to use this to endow some formal K채hlerian structure (I'd need to assume compact with a prescribed volume form) and to make sense of candidate K채hler form on via something like by either identifying tangent elements in terms of -valued maps or by defining a fiberwise K채hler-form on each fiber of the associated bundle .","G X B G 
\mathcal{B}=P\times_G B
 X \mathcal{S} =\Gamma(X,\mathcal{B}) \phi\in \Gamma(X,\mathcal{B}) 
T_\phi \Gamma(X,\mathcal{B})
 \dot{\phi} G B \Gamma(X,\mathcal{B}) G \tilde{\phi}:P\rightarrow B \phi \phi_t \mathcal{B} \phi_0=\phi \frac{d}{dt}|_{t=0} \phi_t x\in X \mathcal{B} \phi(x) 
T_\phi \mathcal{S} \simeq \Gamma(X,\phi^*V\mathcal{B})
 \phi^*V\mathcal{B} X \phi \mathcal{B} G B \mathcal{B} G \sigma\in \Gamma(B,T^*B) \mathcal{S} B \omega \mathcal{S} X \mathcal{S} 
\Omega(\dot{\Phi}_1,\dot{\Phi}_2) \sim \int_X \omega(\dot{\phi}_1,\dot{\phi}_2)
 \dot{\Phi} B \omega \mathcal{B}","['differential-geometry', 'principal-bundles', 'gauge-theory']"
43,Standardized radius of validity of normal coordinates in differential geometry?,Standardized radius of validity of normal coordinates in differential geometry?,,"Depending on the curvature of a certain manifold $M$ , intuitively  it is interesting to quantify how quickly normal coordinates defined at a point $p$ deteriorate away from $p$ . Is there a standardized measure to quantify the actual size of the neighbourhood of $p$ the normal coordinates are valid in? If so, how is it calculated?","Depending on the curvature of a certain manifold , intuitively  it is interesting to quantify how quickly normal coordinates defined at a point deteriorate away from . Is there a standardized measure to quantify the actual size of the neighbourhood of the normal coordinates are valid in? If so, how is it calculated?",M p p p,"['differential-geometry', 'neighbourhood']"
44,Tensor bundle as associated bundle,Tensor bundle as associated bundle,,"Given a smooth manifold $M$ of dimension $d$ , consider the frame bundle $FM \overset{\pi_{FM}}\longrightarrow M$ . We can construct the tangent bundle $TM \overset{\pi_{TM}}\longrightarrow M$ as an associated $GL(d, \mathbf{R})$ -bundle by first taking the product $FM \times \mathbf{R}^d$ . Intuitively, this is a bundle over $M$ with typical fiber $GL(d, \mathbf{R}) \times \mathbf{R}^d$ . Next, we take a quotient by $\sim_{GL(d, \mathbf{R})}$ , where $\sim_{GL(d, \mathbf{R})}$ is given by $$\left([\mathbf{e}_i], v\right) \sim \left([\mathbf{e}_i] \blacktriangleleft g, g^{-1} \blacktriangleright v\right)$$ for all $g \in GL(d, \mathbf{R})$ , where $[\mathbf{e}_i]$ denotes frames and $v$ denotes coefficients. Letting the quotient space be denoted $(FM \times \mathbf{R}^d) / GL(d, \mathbf{R})$ , there exists a vector bundle isomorphism $(FM \times \mathbf{R}^d)/GL(d, \mathbf{R}) \longrightarrow TM$ given by $[\left[\mathbf{e}_i\right], v] \mapsto \sum_i v_i\mathbf{e}_i$ . Analogously, I would like to construct a general tensor bundle $T^p_qM$ as an associated $GL(d, \mathbf{R})$ -bundle. I suspect that this is done as follows: Letting $\rho: GL(d, \mathbf{R}) \longrightarrow GL(d, \mathbf{R})$ be a group representation, construct the associated vector bundle $(FM \times \mathbf{R}^c)/\sim_{\rho}$ , where $\sim_{\rho}$ is given by $$ \left([\mathbf{e}_i], t\right) \sim \left([\mathbf{e}_i] \blacktriangleleft g, \rho(g^{-1}) \blacktriangleright t\right) $$ for all $g\in GL(d, \mathbf{R})$ , where $\mathbf{R}^c \cong T_pM^{\otimes p}\otimes T^*_pM^{ \otimes q}$ and $t$ denotes tensor coefficients. My understanding is that $\rho$ should encode the typical transformation law associated to a $(p, q)$ -tensor under a change of frame. (Q1) Is this the correct $\rho$ ? Additionally, I have seen the transformation law for a $(p,q)$ -tensor given by $$ \widetilde{T}^{i_1,\ldots,i_p}_{j_1,\ldots,j_q} = \sum_{\substack{1\leq k_1,\ldots, k_p \leq d}\\1\leq\ell_1,\ldots,\ell_q\leq d}T^{ k_1,\ldots, k_p }_{\ell_1,\ldots,\ell_q}g_{i_1k_1}\cdots g_{i_pk_p}g^{j_1\ell_1}\cdots g^{j_q\ell_q}. $$ However, I'm having trouble seeing how such a transformation can be described using a representation $\rho$ . (Q2) I was under the assumption that the tensor components live in a multidimensional array, so how can this live in the matrix group $GL(d, \mathbf{R})$ ?","Given a smooth manifold of dimension , consider the frame bundle . We can construct the tangent bundle as an associated -bundle by first taking the product . Intuitively, this is a bundle over with typical fiber . Next, we take a quotient by , where is given by for all , where denotes frames and denotes coefficients. Letting the quotient space be denoted , there exists a vector bundle isomorphism given by . Analogously, I would like to construct a general tensor bundle as an associated -bundle. I suspect that this is done as follows: Letting be a group representation, construct the associated vector bundle , where is given by for all , where and denotes tensor coefficients. My understanding is that should encode the typical transformation law associated to a -tensor under a change of frame. (Q1) Is this the correct ? Additionally, I have seen the transformation law for a -tensor given by However, I'm having trouble seeing how such a transformation can be described using a representation . (Q2) I was under the assumption that the tensor components live in a multidimensional array, so how can this live in the matrix group ?","M d FM \overset{\pi_{FM}}\longrightarrow M TM \overset{\pi_{TM}}\longrightarrow M GL(d, \mathbf{R}) FM \times \mathbf{R}^d M GL(d, \mathbf{R}) \times \mathbf{R}^d \sim_{GL(d, \mathbf{R})} \sim_{GL(d, \mathbf{R})} \left([\mathbf{e}_i], v\right) \sim \left([\mathbf{e}_i] \blacktriangleleft g, g^{-1} \blacktriangleright v\right) g \in GL(d, \mathbf{R}) [\mathbf{e}_i] v (FM \times \mathbf{R}^d) / GL(d, \mathbf{R}) (FM \times \mathbf{R}^d)/GL(d, \mathbf{R}) \longrightarrow TM [\left[\mathbf{e}_i\right], v] \mapsto \sum_i v_i\mathbf{e}_i T^p_qM GL(d, \mathbf{R}) \rho: GL(d, \mathbf{R}) \longrightarrow GL(d, \mathbf{R}) (FM \times \mathbf{R}^c)/\sim_{\rho} \sim_{\rho} 
\left([\mathbf{e}_i], t\right) \sim \left([\mathbf{e}_i] \blacktriangleleft g, \rho(g^{-1}) \blacktriangleright t\right)
 g\in GL(d, \mathbf{R}) \mathbf{R}^c \cong T_pM^{\otimes p}\otimes T^*_pM^{
\otimes q} t \rho (p, q) \rho (p,q) 
\widetilde{T}^{i_1,\ldots,i_p}_{j_1,\ldots,j_q} = \sum_{\substack{1\leq k_1,\ldots, k_p \leq d}\\1\leq\ell_1,\ldots,\ell_q\leq d}T^{ k_1,\ldots, k_p }_{\ell_1,\ldots,\ell_q}g_{i_1k_1}\cdots g_{i_pk_p}g^{j_1\ell_1}\cdots g^{j_q\ell_q}.
 \rho GL(d, \mathbf{R})","['differential-geometry', 'representation-theory', 'tensors', 'fiber-bundles', 'principal-bundles']"
45,Why will the bundle homomorphism $\hat{g}:TM\to T^* M$ be bijective if each restriction $\hat{g}:T_p M\to T_p^* M$ is bijective?,Why will the bundle homomorphism  be bijective if each restriction  is bijective?,\hat{g}:TM\to T^* M \hat{g}:T_p M\to T_p^* M,"The following material is based on Lee's Introduction to Smooth Manifolds . Let $g$ be a Riemannian metric on a smooth manifold $M$ . We define a bundle homomorphism $\hat{g}:TM\to T^* M$ over $M$ as follows. For each $p\in M$ and each $v\in T_p M$ , $\hat{g}(v)$ is the covector in $T_p^* M$ defined by $$\hat{g}(v)(w)=g_p(v,w)$$ for $w\in T_p M$ . Using some linear algebra, I have been able to show each restriction $\hat{g}:T_p M\to T_p^* M$ is bijective. However, I have no idea why this result will in turn make the bundle homomorphism become bijective. Does anyone get to see this? Thank you.","The following material is based on Lee's Introduction to Smooth Manifolds . Let be a Riemannian metric on a smooth manifold . We define a bundle homomorphism over as follows. For each and each , is the covector in defined by for . Using some linear algebra, I have been able to show each restriction is bijective. However, I have no idea why this result will in turn make the bundle homomorphism become bijective. Does anyone get to see this? Thank you.","g M \hat{g}:TM\to T^* M M p\in M v\in T_p M \hat{g}(v) T_p^* M \hat{g}(v)(w)=g_p(v,w) w\in T_p M \hat{g}:T_p M\to T_p^* M","['differential-geometry', 'riemannian-geometry']"
46,How do I show that the following is a definition of an alternating form?,How do I show that the following is a definition of an alternating form?,,"Suppose $E$ is an open set in $\mathbb{R}^n$ . A differential form of order $k$ in $E$ (briefly, a k-form in E) is a function $\omega$ , which assigns to each $k$ surface $\Phi$ in $E$ a number $\omega(\Phi) = \int_{\Phi} \omega$ $$\int_{\Phi}\omega = \int_{D} \sum a_{i_1 \cdots i_k}(\Phi(u)) \frac{\partial(x_{i_1},\cdots,x_{i_k})}{\partial(u_{i_1},\cdots,u_{i_k})}du  \cdots \cdots \cdots (1)$$ where $\omega$ is symbollically representated as $\omega = \sum a_{i_1 \cdots i_k}(x) dx_{i_1} \wedge \cdots \wedge dx_{i_k}$ The definition of differential forms that was given to us in class is that $\omega(x)$ is an alternating $k$ tesnor. How are these two definitions related?How do I show that $(1)$ is an alternating $k$ tensor?","Suppose is an open set in . A differential form of order in (briefly, a k-form in E) is a function , which assigns to each surface in a number where is symbollically representated as The definition of differential forms that was given to us in class is that is an alternating tesnor. How are these two definitions related?How do I show that is an alternating tensor?","E \mathbb{R}^n k E \omega k \Phi E \omega(\Phi) = \int_{\Phi} \omega \int_{\Phi}\omega = \int_{D} \sum a_{i_1 \cdots i_k}(\Phi(u)) \frac{\partial(x_{i_1},\cdots,x_{i_k})}{\partial(u_{i_1},\cdots,u_{i_k})}du  \cdots \cdots \cdots (1) \omega \omega = \sum a_{i_1 \cdots i_k}(x) dx_{i_1} \wedge \cdots \wedge dx_{i_k} \omega(x) k (1) k","['differential-geometry', 'tensors']"
47,Holonomy of a flat connection,Holonomy of a flat connection,,"I am trying to prove that for a vector bundle with a flat connection, holonomies between points $p$ and $q$ are the same for smoothly homotopic paths. If we talk about a local trivialisation, and all the curves are within it, the problem can be solved with straightforward computation using path ordered exponents. I cannot understand what to do if curves travel all around the manifold and do not stay within one trivialisation patch. So far, I have the idea that the image of homotopy $\gamma_s:[0,1]^2 \rightarrow M$ is compact as an image of compact space. Therefore, the image is coverable with a finite number of coordinate trivialisations. Looking for different pictures of how it possibly can happen, I think that some induction on the number of charts can help here. I hope the following images clarify what I mean. Coloured regions here are different trivialisation charts. Red lines are curves that help to reduce a problem with the given number of charts to the subproblem with a smaller amount of patches. It seems like it is always possible to come up with some red line. However, it is unclear how to define it in the general case. Coloured regions here are different trivialisation charts. Red lines are curves that help to reduce a problem with the given number of charts to the subproblem with a smaller amount of patches. It seems like it is always possible to come up with some red line. However, it is unclear how to define it in the general case. Another idea is to consider the question in terms of contractible loops. I thought it could be possible to represent holonomy around a big loop as a sum over smaller ones and use that a holonomy around a small loop for a vanishing curvature is $O(\epsilon^3)$ , where $\epsilon$ is the size of the loop. It seems not to be the case.","I am trying to prove that for a vector bundle with a flat connection, holonomies between points and are the same for smoothly homotopic paths. If we talk about a local trivialisation, and all the curves are within it, the problem can be solved with straightforward computation using path ordered exponents. I cannot understand what to do if curves travel all around the manifold and do not stay within one trivialisation patch. So far, I have the idea that the image of homotopy is compact as an image of compact space. Therefore, the image is coverable with a finite number of coordinate trivialisations. Looking for different pictures of how it possibly can happen, I think that some induction on the number of charts can help here. I hope the following images clarify what I mean. Coloured regions here are different trivialisation charts. Red lines are curves that help to reduce a problem with the given number of charts to the subproblem with a smaller amount of patches. It seems like it is always possible to come up with some red line. However, it is unclear how to define it in the general case. Coloured regions here are different trivialisation charts. Red lines are curves that help to reduce a problem with the given number of charts to the subproblem with a smaller amount of patches. It seems like it is always possible to come up with some red line. However, it is unclear how to define it in the general case. Another idea is to consider the question in terms of contractible loops. I thought it could be possible to represent holonomy around a big loop as a sum over smaller ones and use that a holonomy around a small loop for a vanishing curvature is , where is the size of the loop. It seems not to be the case.","p q \gamma_s:[0,1]^2 \rightarrow M O(\epsilon^3) \epsilon","['differential-geometry', 'connections', 'holonomy']"
48,Conditions on space of smooth almost complex structures so that it's a banach manifold,Conditions on space of smooth almost complex structures so that it's a banach manifold,,"In the following paper by A.Abbondandolo and M. Schwarz https://arxiv.org/pdf/math/0408280.pdf in section $1.6$ we consider the set of smooth almost complex structures $\mathcal{J}$ on $T^*M$ compatible with $\omega_{can}$ and such that $||J-\hat J||_{\infty}<\infty$ , where $\hat J$ is the almost complex structure give by the splitting into the verical and horizontal components. They claim that one can put a distance on $\mathcal{J}$ defined as $\text{dist}(J_1,J_2)=||J_1-J_2||_{\infty}+dist_{C^{\infty}_{loc}}(J_1,J_2)$ , so that it's a complete metric space. I was able to see that this was true. However can't we say something more general ? I.e. that this will be a banach space, if we define a norm as $||J||=||J||_{\infty}+\sum_{k=1}^{\infty}\sum_{l=0}^{\infty}2^{-r-l}\frac{||J||_{C^l(K_k)}}{1+||J||_{C^l(K_k)}}$ where $K_k=\{(t,q,p\in S^1\times T^*M:|p|\leq k)\}$ .  I also belive this is true but the authors don't say anyhting about this, hence this makes me feel at little suspicious. The reason I want this to be a banach space is so that when we prove that there exists a dense set of almost complex structures that give us transversality, we need to use the regular value theorem for banach manifolds. Edit: Nevermind this won't be a banach space since we won't have linearily. However I wonder if we can give this a structure of a banach manifold instead of a Frechet manifold. Any insight is appreciated, thanks in advance.","In the following paper by A.Abbondandolo and M. Schwarz https://arxiv.org/pdf/math/0408280.pdf in section we consider the set of smooth almost complex structures on compatible with and such that , where is the almost complex structure give by the splitting into the verical and horizontal components. They claim that one can put a distance on defined as , so that it's a complete metric space. I was able to see that this was true. However can't we say something more general ? I.e. that this will be a banach space, if we define a norm as where .  I also belive this is true but the authors don't say anyhting about this, hence this makes me feel at little suspicious. The reason I want this to be a banach space is so that when we prove that there exists a dense set of almost complex structures that give us transversality, we need to use the regular value theorem for banach manifolds. Edit: Nevermind this won't be a banach space since we won't have linearily. However I wonder if we can give this a structure of a banach manifold instead of a Frechet manifold. Any insight is appreciated, thanks in advance.","1.6 \mathcal{J} T^*M \omega_{can} ||J-\hat J||_{\infty}<\infty \hat J \mathcal{J} \text{dist}(J_1,J_2)=||J_1-J_2||_{\infty}+dist_{C^{\infty}_{loc}}(J_1,J_2) ||J||=||J||_{\infty}+\sum_{k=1}^{\infty}\sum_{l=0}^{\infty}2^{-r-l}\frac{||J||_{C^l(K_k)}}{1+||J||_{C^l(K_k)}} K_k=\{(t,q,p\in S^1\times T^*M:|p|\leq k)\}","['differential-geometry', 'banach-spaces', 'symplectic-geometry', 'almost-complex']"
49,Covariant derivatives and diffeomorphisms,Covariant derivatives and diffeomorphisms,,"Suppose $M$ is a Riemannian manifold and $\Phi : M \to M$ is a diffeomorphism. Suppose further that $X$ and $Y$ are smooth vector fields on $M$ , and $\nabla$ is the Levi-Civita connection on $M$ . Given $p \in M$ , consider the covariant derivatives $$ \big(\nabla_X\left(\Phi_* Y\right)\big)_{\Phi(p)} = \nabla_{X_{\Phi(p)}}\left(d\Phi_p Y_p\right) \quad \textrm{and} \quad \big(\Phi_*(\nabla_X Y)\big)_{\Phi(p)} = d\Phi_p\left(\nabla_X Y\right)_p. $$ My question is basically twofold: Is there a connection between these two covariant derivatives? Is there a canonical definition of the covariant derivative of a diffeomorphism $\Phi : M \to M$ , or the covariant derivative of its differential $d\Phi : TM \to TM$ ? If $M = \mathbb R^n$ , and we write $Y = Y^i \frac{\partial}{\partial x^i}$ and $X = X^i \frac{\partial}{\partial x^i}$ , where $X^i, Y^i \in C^\infty(\mathbb R^n)$ for all $i$ (using the Einstein summation convention), then $$\nabla_X Y = (XY^i) \frac{\partial}{\partial x^i} = \left(X^j \frac{\partial Y^i}{\partial x^j}\right) \frac{\partial}{\partial x^i}.$$ Applying this to the derivatives above, and using the fact that $(\Phi_* Y)_{\Phi(p)} = d\Phi_p Y_p = Y^j(p)\frac{\partial \Phi^i}{\partial x^j}(p)\frac{\partial}{\partial x^i}\big|_{\Phi(p)}$ , with some abuse of notation, we get: \begin{align*} \nabla_{X}\left(\Phi_* Y\right) &= \left(X^j \frac{\partial}{\partial x^j} \left(Y^k \frac{\partial \Phi^i}{\partial x^k}\right)\right)\frac{\partial}{\partial x^i} \\ &= X^j \frac{\partial Y^k}{\partial x^j} \frac{\partial \Phi^i}{\partial x^k} \frac{\partial}{\partial x^i} + X^j Y^k \frac{\partial^2 \Phi^i}{\partial x^j \partial x^k} \frac{\partial}{\partial x^i} \\ &= \Phi_* \left(\nabla_X Y\right) + (\nabla_X(d\Phi))Y \end{align*} where formally $\nabla_X(d\Phi) : T_p\mathbb R^n \to T_{\Phi(p)}\mathbb R^n$ is the operator given in coordinates by $$ \nabla_X(d\Phi) = \left(X^j \frac{\partial^2 \Phi^i}{\partial x^j \partial x^k}\right)_{1 \leq i,k\leq n} $$ which by inspection roughly corresponds to a coordinatewise derivative of the Jacobian matrix of $d\Phi$ in the direction of the vector field $X$ . At a point $p \in \mathbb R^n$ , we can express the equation $\nabla_X \left(\Phi_* Y\right) = \Phi_*(\nabla_X Y) + (\nabla_X(d\Phi))Y$ by writing $$ \nabla_{X_{\Phi(p)}}\left(d\Phi_p Y_p\right) = d\Phi_p\left(\nabla_X Y\right)_p + (\nabla_X(d\Phi))_p Y_p $$ which seems very similar to the Leibniz ""product rule"". So this all works in $\mathbb R^n$ , but what about more general Riemannian manifolds? Well, formally, given $X, Y$ smooth vector fields and $\Phi : M \to M$ a diffeomorphism, we could simply define $\nabla_X(d\Phi)(Y) = \nabla_X(\Phi_*Y) - \Phi_*(\nabla_X Y)$ , but this seems quite artificial. Is there a more natural/canonical way to define the covariant derivative of a diffeomorphism or its differential?","Suppose is a Riemannian manifold and is a diffeomorphism. Suppose further that and are smooth vector fields on , and is the Levi-Civita connection on . Given , consider the covariant derivatives My question is basically twofold: Is there a connection between these two covariant derivatives? Is there a canonical definition of the covariant derivative of a diffeomorphism , or the covariant derivative of its differential ? If , and we write and , where for all (using the Einstein summation convention), then Applying this to the derivatives above, and using the fact that , with some abuse of notation, we get: where formally is the operator given in coordinates by which by inspection roughly corresponds to a coordinatewise derivative of the Jacobian matrix of in the direction of the vector field . At a point , we can express the equation by writing which seems very similar to the Leibniz ""product rule"". So this all works in , but what about more general Riemannian manifolds? Well, formally, given smooth vector fields and a diffeomorphism, we could simply define , but this seems quite artificial. Is there a more natural/canonical way to define the covariant derivative of a diffeomorphism or its differential?","M \Phi : M \to M X Y M \nabla M p \in M 
\big(\nabla_X\left(\Phi_* Y\right)\big)_{\Phi(p)} = \nabla_{X_{\Phi(p)}}\left(d\Phi_p Y_p\right) \quad \textrm{and} \quad \big(\Phi_*(\nabla_X Y)\big)_{\Phi(p)} = d\Phi_p\left(\nabla_X Y\right)_p.
 \Phi : M \to M d\Phi : TM \to TM M = \mathbb R^n Y = Y^i \frac{\partial}{\partial x^i} X = X^i \frac{\partial}{\partial x^i} X^i, Y^i \in C^\infty(\mathbb R^n) i \nabla_X Y = (XY^i) \frac{\partial}{\partial x^i} = \left(X^j \frac{\partial Y^i}{\partial x^j}\right) \frac{\partial}{\partial x^i}. (\Phi_* Y)_{\Phi(p)} = d\Phi_p Y_p = Y^j(p)\frac{\partial \Phi^i}{\partial x^j}(p)\frac{\partial}{\partial x^i}\big|_{\Phi(p)} \begin{align*}
\nabla_{X}\left(\Phi_* Y\right) &= \left(X^j \frac{\partial}{\partial x^j} \left(Y^k \frac{\partial \Phi^i}{\partial x^k}\right)\right)\frac{\partial}{\partial x^i} \\
&= X^j \frac{\partial Y^k}{\partial x^j} \frac{\partial \Phi^i}{\partial x^k} \frac{\partial}{\partial x^i} + X^j Y^k \frac{\partial^2 \Phi^i}{\partial x^j \partial x^k} \frac{\partial}{\partial x^i} \\
&= \Phi_* \left(\nabla_X Y\right) + (\nabla_X(d\Phi))Y
\end{align*} \nabla_X(d\Phi) : T_p\mathbb R^n \to T_{\Phi(p)}\mathbb R^n 
\nabla_X(d\Phi) = \left(X^j \frac{\partial^2 \Phi^i}{\partial x^j \partial x^k}\right)_{1 \leq i,k\leq n}
 d\Phi X p \in \mathbb R^n \nabla_X \left(\Phi_* Y\right) = \Phi_*(\nabla_X Y) + (\nabla_X(d\Phi))Y 
\nabla_{X_{\Phi(p)}}\left(d\Phi_p Y_p\right) = d\Phi_p\left(\nabla_X Y\right)_p + (\nabla_X(d\Phi))_p Y_p
 \mathbb R^n X, Y \Phi : M \to M \nabla_X(d\Phi)(Y) = \nabla_X(\Phi_*Y) - \Phi_*(\nabla_X Y)","['differential-geometry', 'riemannian-geometry', 'differential-topology', 'connections']"
50,A detail in a proof of the Steiner's inequality about sets of finite perimeter,A detail in a proof of the Steiner's inequality about sets of finite perimeter,,"Given an open limited set $E$ of $\mathbb{R}^n$ with smooth boundary, how could I subdivide this set $E$ in a finite number of normal sets? I remind you that the normal set is a set of this form, given an open set $A$ in $\mathbb{R}^{n-1}$ and two functions $\varphi_{1}$ and $\varphi_2$ defined on $A$ the corresponding normal set is $$\{(x,y) \in A : \varphi_{1}(x)<y<\varphi_{2}(x)\}.$$ Subdivide means to partition the set at most excluding $\mathcal{H}^{n}$ negligible sets. My question emerges from a proof of the Steiner inequality that Francesco Maggi gives in this book at pag 161. https://www.cambridge.org/core/books/sets-of-finite-perimeter-and-geometric-variational-problems/F8D0DABFFFB0D444C5AD5D37B3E3DBC1 What I know for certain is that I can choose a hyperplane $\Pi$ for which there are a $\mathcal{H}^{n-1}-$ negligible amount of points with normal vector parallel to the hyperplane $\Pi.$ So almost all of the perpendicular lines to $\Pi$ are intersecting $E$ in a finite number of segments. In the figure I tried to give a sense of what I am asking.","Given an open limited set of with smooth boundary, how could I subdivide this set in a finite number of normal sets? I remind you that the normal set is a set of this form, given an open set in and two functions and defined on the corresponding normal set is Subdivide means to partition the set at most excluding negligible sets. My question emerges from a proof of the Steiner inequality that Francesco Maggi gives in this book at pag 161. https://www.cambridge.org/core/books/sets-of-finite-perimeter-and-geometric-variational-problems/F8D0DABFFFB0D444C5AD5D37B3E3DBC1 What I know for certain is that I can choose a hyperplane for which there are a negligible amount of points with normal vector parallel to the hyperplane So almost all of the perpendicular lines to are intersecting in a finite number of segments. In the figure I tried to give a sense of what I am asking.","E \mathbb{R}^n E A \mathbb{R}^{n-1} \varphi_{1} \varphi_2 A \{(x,y) \in A : \varphi_{1}(x)<y<\varphi_{2}(x)\}. \mathcal{H}^{n} \Pi \mathcal{H}^{n-1}- \Pi. \Pi E","['real-analysis', 'differential-geometry', 'geometric-measure-theory']"
51,Geodesics in hyperboloid model of hyperbolic geometry,Geodesics in hyperboloid model of hyperbolic geometry,,"Let $X$ be the north sheet of the hyperboloid $ z^2=x^2+y^2+1$ and $g=dx^2+dy^2-dz^2$ a scalar product on the tangent space at every point. I have showed that $(X,g)$ , is a Riemannian surface , both diffeomorphic and isometric to the Poincar챕 disk $\mathbb{D}=\{(x,y,0)\in \mathbb{R^3},x^2+y^2<1\}$ with the hyperbolic metric, via the stereographic projection from the point $q=(0,0,-1)$ . My question is this, I know that the geodesics on $\mathbb{D}$ (with the hyperbolic metric) are its diameters and its intersections with euclidian circles orthogonal to $S^1$ ,  and since stereographic projection is both bijective and an isometry, the geodesics on $X$ should be the preimages of geodesics on $\mathbb{D}$ under stereographic projection, i.e. intersections of the Hyperboloid with cones having a vertex at the point $q$ and whose cross section on $\mathbb{D}$ is a geodesic. However I have read that geodesics on the hyperboloid model are its intersections with planes in $\mathbb{R^3}$ passing through the origin. How can you see that these two descriptions are equivalent?","Let be the north sheet of the hyperboloid and a scalar product on the tangent space at every point. I have showed that , is a Riemannian surface , both diffeomorphic and isometric to the Poincar챕 disk with the hyperbolic metric, via the stereographic projection from the point . My question is this, I know that the geodesics on (with the hyperbolic metric) are its diameters and its intersections with euclidian circles orthogonal to ,  and since stereographic projection is both bijective and an isometry, the geodesics on should be the preimages of geodesics on under stereographic projection, i.e. intersections of the Hyperboloid with cones having a vertex at the point and whose cross section on is a geodesic. However I have read that geodesics on the hyperboloid model are its intersections with planes in passing through the origin. How can you see that these two descriptions are equivalent?","X  z^2=x^2+y^2+1 g=dx^2+dy^2-dz^2 (X,g) \mathbb{D}=\{(x,y,0)\in \mathbb{R^3},x^2+y^2<1\} q=(0,0,-1) \mathbb{D} S^1 X \mathbb{D} q \mathbb{D} \mathbb{R^3}","['differential-geometry', 'riemannian-geometry']"
52,Intuitive way of describing a conformal distribution,Intuitive way of describing a conformal distribution,,"I was wondering if anyone knows a way to describe a conformal distribution in an intuitive way, preferably to someone who doesn't have much previous knowledge of differential geometry. I know that a distribution is a subbundle to the tangent bundle. Given a distribution $\mathcal{S}$ and its complementary distribution $\mathcal{T}$ , we can define its second fundamental form as $$B(X,Y)=\frac{1}{2}\mathcal{T}(\nabla_XY+\nabla_YX),$$ where $X,Y$ are smooth sections of $\mathcal{S}$ . The distribution $\mathcal{S}$ is conformal if there exists a vector field $V$ is $\mathcal{S}$ such that $$B(X,Y)=g(X,Y)\,\otimes\,V,$$ where $g$ is the Riemannian metric. What does this mean, in practice?","I was wondering if anyone knows a way to describe a conformal distribution in an intuitive way, preferably to someone who doesn't have much previous knowledge of differential geometry. I know that a distribution is a subbundle to the tangent bundle. Given a distribution and its complementary distribution , we can define its second fundamental form as where are smooth sections of . The distribution is conformal if there exists a vector field is such that where is the Riemannian metric. What does this mean, in practice?","\mathcal{S} \mathcal{T} B(X,Y)=\frac{1}{2}\mathcal{T}(\nabla_XY+\nabla_YX), X,Y \mathcal{S} \mathcal{S} V \mathcal{S} B(X,Y)=g(X,Y)\,\otimes\,V, g","['differential-geometry', 'riemannian-geometry', 'conformal-geometry', 'tangent-bundle']"
53,Harmonic functions and coordinate transfomation,Harmonic functions and coordinate transfomation,,"Related to a question about coordinates, I've been given the following comment to consider: ""Local coordinate functions are given by suitable harmonic functions on subsets of the metric space, where ""harmonic"" is defined in metric terms."" Trying to comprehend and to confirm this statement leads me to the following: Let function $h : \mathbb R^2 \rightarrow \mathbb R$ be a harmonic function in terms of arguments $(x, y)$ ; i.e. $\frac{\partial^2}{\partial x}\left[ h \right]+ \frac{\partial^2}{\partial y}\left[ h \right] = 0.$ Now define another function, $f : \mathbb R^2 \rightarrow \mathbb R$ through $$ \begin{align*} f\huge[ & \, x - \text{Sgn}[ \, y \, ] \, \sqrt{ \, \text{Abs}[ \, y \, ] \, }, & ~ \\ ~ & \text{Sgn}[ \, y \, ] \, \left( \sqrt{ \text{Abs}[ \, y \, ] \, \left(\text{Abs}[ \, y \, ] + \frac{1}{4}\right)} + \left( \frac{1}{4} \right) \, \text{Ln} \! \left[ \sqrt{4 \, \text{Abs}[ \, y \, ] + 1} + \sqrt{4 \, \text{Abs}[ \, y \, ]} \, \right] \right) \, {\huge]} := h[ \, x, y \, ]. \end{align*} $$ Also, introduce new variables: $$ p := x - \text{Sgn}[ \, y \, ] \, \sqrt{ \, \text{Abs}[ \, y \, ] \, } $$ and $$ q := \text{Sgn}[ \, y \, ] \, \left( \sqrt{ \text{Abs}[ \, y \, ] \, \left(\text{Abs}[ \, y \, ] + \frac{1}{4}\right)} + \left( \frac{1}{4} \right) \, \text{Ln} \left[ \sqrt{4 \, \text{Abs}[ \, y \, ] + 1} + \sqrt{4 \, \text{Abs}[ \, y \, ]} \right] \right). $$ (As a motivation for these particular choices note that $$\int_0^k \! \! \! \sqrt{1 + (2 \, x)^2} \, {\rm d}x \, = \, k \, \sqrt{k^2 + \frac{1}{4}} + \left(\frac{1}{4}\right) \, \text{Ln} \left[ \sqrt{4 \, k^2 + 1 } + 2 \, k \right],$$ where $\frac{d}{dx} \left[ x^2 \right]  = 2 \, x$ , of course. See also this "" visual suggestion of the appearance of $(p, q)$ -coordinate lines relative to $(x, y)$ -coordinate lines"".) Consequently, $f[ \, p, \, q \, ] := h[ \, x, \, y \, ],$ and there is a one-to-one correspondence (map) $\psi : \{(x, y)\} \leftrightarrow \{(p, q)\}$ as described above. My question: Is function $f$ , as function $f[ \, p, \, q \, ]$ , a harmonic function in terms of arguments $(p, q)$ , too ? -- especially considering the particular choice of map $\psi$ between arguments $(p, q)$ of function $f$ , and $(x, y)$ of function $h$ .","Related to a question about coordinates, I've been given the following comment to consider: ""Local coordinate functions are given by suitable harmonic functions on subsets of the metric space, where ""harmonic"" is defined in metric terms."" Trying to comprehend and to confirm this statement leads me to the following: Let function be a harmonic function in terms of arguments ; i.e. Now define another function, through Also, introduce new variables: and (As a motivation for these particular choices note that where , of course. See also this "" visual suggestion of the appearance of -coordinate lines relative to -coordinate lines"".) Consequently, and there is a one-to-one correspondence (map) as described above. My question: Is function , as function , a harmonic function in terms of arguments , too ? -- especially considering the particular choice of map between arguments of function , and of function .","h : \mathbb R^2 \rightarrow \mathbb R (x, y) \frac{\partial^2}{\partial x}\left[ h \right]+ \frac{\partial^2}{\partial y}\left[ h \right] = 0. f : \mathbb R^2 \rightarrow \mathbb R 
\begin{align*}
f\huge[ & \, x - \text{Sgn}[ \, y \, ] \, \sqrt{ \, \text{Abs}[ \, y \, ] \, }, & ~ \\ ~ & \text{Sgn}[ \, y \, ] \, \left( \sqrt{ \text{Abs}[ \, y \, ] \, \left(\text{Abs}[ \, y \, ] + \frac{1}{4}\right)} + \left( \frac{1}{4} \right) \, \text{Ln} \! \left[ \sqrt{4 \, \text{Abs}[ \, y \, ] + 1} + \sqrt{4 \, \text{Abs}[ \, y \, ]} \, \right] \right) \, {\huge]} := h[ \, x, y \, ].
\end{align*}
  p := x - \text{Sgn}[ \, y \, ] \, \sqrt{ \, \text{Abs}[ \, y \, ] \, }   q := \text{Sgn}[ \, y \, ] \, \left( \sqrt{ \text{Abs}[ \, y \, ] \, \left(\text{Abs}[ \, y \, ] + \frac{1}{4}\right)} + \left( \frac{1}{4} \right) \, \text{Ln} \left[ \sqrt{4 \, \text{Abs}[ \, y \, ] + 1} + \sqrt{4 \, \text{Abs}[ \, y \, ]} \right] \right).  \int_0^k \! \! \! \sqrt{1 + (2 \, x)^2} \, {\rm d}x \, = \, k \, \sqrt{k^2 + \frac{1}{4}} + \left(\frac{1}{4}\right) \, \text{Ln} \left[ \sqrt{4 \, k^2 + 1 } + 2 \, k \right], \frac{d}{dx} \left[ x^2 \right]  = 2 \, x (p, q) (x, y) f[ \, p, \, q \, ] := h[ \, x, \, y \, ], \psi : \{(x, y)\} \leftrightarrow \{(p, q)\} f f[ \, p, \, q \, ] (p, q) \psi (p, q) f (x, y) h","['differential-geometry', 'partial-differential-equations', 'coordinate-systems']"
54,Generators of $H^1_{dR}(S^1)$ and angular forms,Generators of  and angular forms,H^1_{dR}(S^1),"I am trying to understand and ""visualize"" the generator of the first de Rham cohomology group of the circle and the intuition behind the concept of angular form. $H^1(S^1)$ can be computed from Mayer-Vietoris sequence obtaining $\dim H^1(S^1)= 1$ and from the coboundary map we obtain a generator $\omega_{MV}$ of $H^1(S^1)$ as a bump form with support (in a connected component of) the intersection of the two open sets used in M-V, that is, a bump form on the circle (say with integral equal to 1). Thus $H^1(S^1) = \langle [\omega_{MV}] \rangle$ . This form is sometimes called ""angular form"" but intuitively does not look like a ""differential"" of an angle (I know that the angle is a multifunction and hence we should use the universal cover of $S^1$ to properly discuss it, but we can get away with some careful intuition nonetheless). Intuitively the angle ""function"" has a linear growth on the circle minus a point, thus I'd expect its ""differential"" to be a ""constant"" form. Of course constant does not make sense for a 1-form. We can restate this by asking that this angular form should evaluate to a constant function when paired with the vector field $X = x \frac{\partial}{\partial y} - y \frac{\partial}{\partial x}$ restricted to $S^1$ . Of course such a form can be seen as the restriction of $xdy - ydx$ to $S^1$ . Without referring to the ambient space, we can construct a ""constant"" form $\omega_c$ gluing the forms $c\cdot dx$ on $U,V \simeq \mathbb{R}$ as follows. Say $U \simeq_{\varphi_U} (0-\varepsilon,\pi +\varepsilon)$ and $V \simeq_{\varphi_V} (\pi-\varepsilon,2\pi +\varepsilon)$ just to fix the ideas. We have $$\varphi_U(U\cap V) = (0- \varepsilon,0+\varepsilon) \sqcup (\pi -\varepsilon,\pi+\varepsilon)$$ $$\varphi_V(U\cap V) = (2\pi- \varepsilon,2\pi +\varepsilon) \sqcup (\pi -\varepsilon,\pi+\varepsilon)$$ and the transition functions are the identity on the first compoment and the translation $\pm 2\pi$ on the second component, thus their jacobian is always the identity. Moreover on $\mathbb{R}$ the forms $dx$ are translation invariant, i.e. $dx_p = dx_{p+q}$ , thus in the end $\varphi_{UV}^*dx = dx$ . This defines $\omega_c$ as $\omega_c|_U = c \cdot \varphi_U^*dx$ and $\omega_c|_V = c \cdot \varphi_U^*dx$ . These forms are closed by definition and they are intuitively exact since if there was a function on $S^1$ with a constant differential, it must be constantly increasing, but this is impossible on $S^1$ . Thus $H^1(S^1) = \langle [\omega_{c}] \rangle$ . This form is what I would call angular form , of course, since $H^1$ is 1-dimensional, $[\omega_{c}] = [\omega_{MV}]$ thus by extension we call also $\omega_{MV}$ an angular form. Since $S^1$ is compact, we also have $H_c^1(S^1) = \langle [\omega_{c}] \rangle = \langle [\omega_{MV}] \rangle$ . Does my reasoning make sense? Thanks EDIT: I've rewritten the construction of ""constant"" 1-forms to make it clearer. Seems to me it that the use of partition of unity it not even necessary.","I am trying to understand and ""visualize"" the generator of the first de Rham cohomology group of the circle and the intuition behind the concept of angular form. can be computed from Mayer-Vietoris sequence obtaining and from the coboundary map we obtain a generator of as a bump form with support (in a connected component of) the intersection of the two open sets used in M-V, that is, a bump form on the circle (say with integral equal to 1). Thus . This form is sometimes called ""angular form"" but intuitively does not look like a ""differential"" of an angle (I know that the angle is a multifunction and hence we should use the universal cover of to properly discuss it, but we can get away with some careful intuition nonetheless). Intuitively the angle ""function"" has a linear growth on the circle minus a point, thus I'd expect its ""differential"" to be a ""constant"" form. Of course constant does not make sense for a 1-form. We can restate this by asking that this angular form should evaluate to a constant function when paired with the vector field restricted to . Of course such a form can be seen as the restriction of to . Without referring to the ambient space, we can construct a ""constant"" form gluing the forms on as follows. Say and just to fix the ideas. We have and the transition functions are the identity on the first compoment and the translation on the second component, thus their jacobian is always the identity. Moreover on the forms are translation invariant, i.e. , thus in the end . This defines as and . These forms are closed by definition and they are intuitively exact since if there was a function on with a constant differential, it must be constantly increasing, but this is impossible on . Thus . This form is what I would call angular form , of course, since is 1-dimensional, thus by extension we call also an angular form. Since is compact, we also have . Does my reasoning make sense? Thanks EDIT: I've rewritten the construction of ""constant"" 1-forms to make it clearer. Seems to me it that the use of partition of unity it not even necessary.","H^1(S^1) \dim H^1(S^1)= 1 \omega_{MV} H^1(S^1) H^1(S^1) = \langle [\omega_{MV}] \rangle S^1 X = x \frac{\partial}{\partial y} - y \frac{\partial}{\partial x} S^1 xdy - ydx S^1 \omega_c c\cdot dx U,V \simeq \mathbb{R} U \simeq_{\varphi_U} (0-\varepsilon,\pi +\varepsilon) V \simeq_{\varphi_V} (\pi-\varepsilon,2\pi +\varepsilon) \varphi_U(U\cap V) = (0- \varepsilon,0+\varepsilon) \sqcup (\pi -\varepsilon,\pi+\varepsilon) \varphi_V(U\cap V) = (2\pi- \varepsilon,2\pi +\varepsilon) \sqcup (\pi -\varepsilon,\pi+\varepsilon) \pm 2\pi \mathbb{R} dx dx_p = dx_{p+q} \varphi_{UV}^*dx = dx \omega_c \omega_c|_U = c \cdot \varphi_U^*dx \omega_c|_V = c \cdot \varphi_U^*dx S^1 S^1 H^1(S^1) = \langle [\omega_{c}] \rangle H^1 [\omega_{c}] = [\omega_{MV}] \omega_{MV} S^1 H_c^1(S^1) = \langle [\omega_{c}] \rangle = \langle [\omega_{MV}] \rangle","['differential-geometry', 'differential-topology', 'de-rham-cohomology']"
55,Condition for a Lagrangian submanifold to be totally geodesic,Condition for a Lagrangian submanifold to be totally geodesic,,"Consider $(M,\omega)$ a symplectic manifold and $L\subset M$ a Lagrangian submanifold. Let $J$ be an almost complex structure and $g:=\omega(.,J.)$ a compatible riemannian metric . Are there conditions that we can put on the lagrangian submanifold $L$ so that this becomes totally geodesic ? I know that given a totally real submanifold of an almost complex manifold one can always find a metric for which he is totally geodesic, but I was wondering if with the existence of the symplectic form $\omega$ something more could be said. Any insight is appreciated, thanks in advance.","Consider a symplectic manifold and a Lagrangian submanifold. Let be an almost complex structure and a compatible riemannian metric . Are there conditions that we can put on the lagrangian submanifold so that this becomes totally geodesic ? I know that given a totally real submanifold of an almost complex manifold one can always find a metric for which he is totally geodesic, but I was wondering if with the existence of the symplectic form something more could be said. Any insight is appreciated, thanks in advance.","(M,\omega) L\subset M J g:=\omega(.,J.) L \omega","['differential-geometry', 'symplectic-geometry']"
56,Symplectic trivialization along path,Symplectic trivialization along path,,"Let $(M,\omega)$ be a (symplectic) manifold. I want to compute the Maslov index of a loop $\gamma:\mathbb{R}\to M$ directly. In order to do that I have to find a (symplectic) trivialization of $\gamma^*TM$ but I can't see how to do this in general. Many references say to use a (symplectic) trivialization of $u^*TM$ for $u$ a map from the disk to $M$ agreeing with $\gamma$ on the boundary. Here below what I've done. The example I tried to work out is $M=S^2$ and $\gamma(t)=(\cos(t),\sin(t),0)$ . The $u$ one could consider is $$ u: D\to S^2\\ (x,y)\mapsto (x,y,\sqrt{1-x^2-y^2}) $$ In this case, as $M$ is two dimensional I would be tempted to use a coordinate chart $\chi:U\to \mathbb{R}^2$ (e.g. stereographic projection from south pole), which would give a map $$ D\times \mathbb{R}^2\to u^*TM\\ $$ but this works only for $\dim M =2$ so it's probably the wrong approach. It would be very helpful to have (a reference to) an example of such a concrete computation.","Let be a (symplectic) manifold. I want to compute the Maslov index of a loop directly. In order to do that I have to find a (symplectic) trivialization of but I can't see how to do this in general. Many references say to use a (symplectic) trivialization of for a map from the disk to agreeing with on the boundary. Here below what I've done. The example I tried to work out is and . The one could consider is In this case, as is two dimensional I would be tempted to use a coordinate chart (e.g. stereographic projection from south pole), which would give a map but this works only for so it's probably the wrong approach. It would be very helpful to have (a reference to) an example of such a concrete computation.","(M,\omega) \gamma:\mathbb{R}\to M \gamma^*TM u^*TM u M \gamma M=S^2 \gamma(t)=(\cos(t),\sin(t),0) u 
u: D\to S^2\\
(x,y)\mapsto (x,y,\sqrt{1-x^2-y^2})
 M \chi:U\to \mathbb{R}^2 
D\times \mathbb{R}^2\to u^*TM\\
 \dim M =2","['differential-geometry', 'vector-bundles', 'symplectic-geometry']"
57,Koszul formula applied to divergence,Koszul formula applied to divergence,,"On a Riemannian manifold $(M, g)$ of dimension $n$ , for a point $x$ on $M$ and a basis $\{U_i\}$ for $T_xM$ which is orthonormal with respect to $g$ , we have the formula $$\operatorname{div} V = \sum_{i=1}^n g(\nabla_{U_i} V, U_i)$$ for the divergence of vector field $V$ at $x$ , where $\nabla$ here is the Levi-Civita connection (see proof of Proposition 3.1.1 in Hsu's Stochastic Analysis on Manifolds ). The Koszul formula allows us to write \begin{align*} g(\nabla_{U_i} V, U_i) = \frac{1}{2}&\left[U_i(g(V, U_i))+V(g(U_i, U_i))-U_i(g(U_i, V))\right. \\ &\left.+g([U_i, V], U_i)-g([U_i, U_i], V)-g([V, U_i], U_i)\right] \end{align*} Given that $g(U_i, U_i)$ is constant and that $[U_i, U_i] = 0$ , this seems like it should simplify down to $$g(\nabla_{U_i} V, U_i) = g([U_i, V], U_i)$$ so we could equivalently write $$\operatorname{div} V = \sum_{i=1}^n g([U_i, V], U_i)$$ Firstly, are these in fact equivalent? If so, are there any reasons for preferring one form of this definition to another?","On a Riemannian manifold of dimension , for a point on and a basis for which is orthonormal with respect to , we have the formula for the divergence of vector field at , where here is the Levi-Civita connection (see proof of Proposition 3.1.1 in Hsu's Stochastic Analysis on Manifolds ). The Koszul formula allows us to write Given that is constant and that , this seems like it should simplify down to so we could equivalently write Firstly, are these in fact equivalent? If so, are there any reasons for preferring one form of this definition to another?","(M, g) n x M \{U_i\} T_xM g \operatorname{div} V = \sum_{i=1}^n g(\nabla_{U_i} V, U_i) V x \nabla \begin{align*} g(\nabla_{U_i} V, U_i) = \frac{1}{2}&\left[U_i(g(V, U_i))+V(g(U_i, U_i))-U_i(g(U_i, V))\right. \\ &\left.+g([U_i, V], U_i)-g([U_i, U_i], V)-g([V, U_i], U_i)\right] \end{align*} g(U_i, U_i) [U_i, U_i] = 0 g(\nabla_{U_i} V, U_i) = g([U_i, V], U_i) \operatorname{div} V = \sum_{i=1}^n g([U_i, V], U_i)","['differential-geometry', 'manifolds', 'riemannian-geometry']"
58,Prove that $\mathbb R\mathrm{P}^n$ is orientable if and only if $n$ is odd,Prove that  is orientable if and only if  is odd,\mathbb R\mathrm{P}^n n,"I am trying to prove that: The real projective space $\mathbb R\mathrm{P}^n$ is orientable if and only if $n$ is odd. For do so, consider first the antipode map $\sigma:\mathbb R^{n+1}\to \mathbb R^{n+1}$ , $p\mapsto -p$ and denote $\sigma^\star$ its pullback. The $(n-1)$ -form in $\mathbb R^{n+1}$ : $$\Omega=\sum_{\alpha=1}^{n+1}(-1)^{\alpha+1}\, dx^1\wedge\ldots\wedge dx^{\alpha-1}\wedge dx^{\alpha+1}\wedge \ldots \wedge dx^{n+1}\qquad\qquad\qquad (\star)$$ induces a volume form in $S^n\subset\mathbb R^{n+1}$ and satisfies $$\sigma^\star_p\Omega_p=(-1)^{n+1}\Omega_p$$ for each $p\in S^n$ Now, suppose that $\mathbb R\mathrm P^n$ is orientable, then there exists a volume form $\Lambda$ in $\mathbb R\mathrm P^n$ . If $\pi$ is the quotient map $S^n\to\mathbb R\mathrm P^n$ then $\pi^\star \Lambda$ is a $n$ -form in $S^n$ and there must exists a smooth map $f:S^n\to\mathbb R$ such that $$\pi^\star \Lambda=f\Omega$$ in $S^n$ . Composing both sides of the last equation by $\sigma^\star$ and using $(\star)$ we obtain: $$\sigma^\star (\pi^\star \Lambda)=\sigma^\star (f\Omega)\Longleftrightarrow f\Omega=(-1)^{n+1}f\Omega$$ Since $f\ne 0$ in $S^2$ (why?) then $n$ must be odd. I am not able to prove the converse. Any help?","I am trying to prove that: The real projective space is orientable if and only if is odd. For do so, consider first the antipode map , and denote its pullback. The -form in : induces a volume form in and satisfies for each Now, suppose that is orientable, then there exists a volume form in . If is the quotient map then is a -form in and there must exists a smooth map such that in . Composing both sides of the last equation by and using we obtain: Since in (why?) then must be odd. I am not able to prove the converse. Any help?","\mathbb R\mathrm{P}^n n \sigma:\mathbb R^{n+1}\to \mathbb R^{n+1} p\mapsto -p \sigma^\star (n-1) \mathbb R^{n+1} \Omega=\sum_{\alpha=1}^{n+1}(-1)^{\alpha+1}\, dx^1\wedge\ldots\wedge dx^{\alpha-1}\wedge dx^{\alpha+1}\wedge \ldots \wedge dx^{n+1}\qquad\qquad\qquad (\star) S^n\subset\mathbb R^{n+1} \sigma^\star_p\Omega_p=(-1)^{n+1}\Omega_p p\in S^n \mathbb R\mathrm P^n \Lambda \mathbb R\mathrm P^n \pi S^n\to\mathbb R\mathrm P^n \pi^\star \Lambda n S^n f:S^n\to\mathbb R \pi^\star \Lambda=f\Omega S^n \sigma^\star (\star) \sigma^\star (\pi^\star \Lambda)=\sigma^\star (f\Omega)\Longleftrightarrow f\Omega=(-1)^{n+1}f\Omega f\ne 0 S^2 n","['differential-geometry', 'smooth-manifolds', 'tensors', 'projective-space', 'orientation']"
59,Contradiction with the dimension of shape operator matrix,Contradiction with the dimension of shape operator matrix,,"Context My question is about the matrix dimension of the shape operator. In order to avoid misunderstanding let $S \subset \mathbb{R}^3$ be a regular surface and $$\psi(u,v)=(x(u,v),y(u,v),z(u,v))$$ be a chart on a open subset $W\subset S$ . So, we have the induced basis of $T_pM$ given by $\left\{\frac{\partial \psi}{\partial u},\frac{\partial \psi}{\partial v}\right\}$ which allow us to define the Gauss map $$p \mapsto N(u,v)=\frac{\frac{\partial \psi}{\partial u}\land \frac{\partial \psi}{\partial v}}{\big\vert\big\vert \frac{\partial \psi}{\partial u}\land \frac{\partial \psi}{\partial v}\big\vert\big\vert}$$ Now we can finally define the shape operator $S:\mathfrak X(W)\rightarrow \mathfrak X(W)$ ; $S(X)=- D_XN$ Question The matrix that represents the linear operator $D_XN$ lies on the space of $3\times 2$ matrices ( here we have a very good derivation about this fact), so by definition of $S$ , its matrix representation should also lies on the space of $3\times 2$ matrices. But at the same time when I'm looking on textbooks I only find that this matrix is a $2\times 2$ matrix whose entries are given by the the one and second fundamental forms coefficients ( here gives the formula I'm talking about and here we have an example). How can I should understand whats going on and how can I interpret this conceptual difference envolved ? Thank you in advance for any hint about this question :)","Context My question is about the matrix dimension of the shape operator. In order to avoid misunderstanding let be a regular surface and be a chart on a open subset . So, we have the induced basis of given by which allow us to define the Gauss map Now we can finally define the shape operator ; Question The matrix that represents the linear operator lies on the space of matrices ( here we have a very good derivation about this fact), so by definition of , its matrix representation should also lies on the space of matrices. But at the same time when I'm looking on textbooks I only find that this matrix is a matrix whose entries are given by the the one and second fundamental forms coefficients ( here gives the formula I'm talking about and here we have an example). How can I should understand whats going on and how can I interpret this conceptual difference envolved ? Thank you in advance for any hint about this question :)","S \subset \mathbb{R}^3 \psi(u,v)=(x(u,v),y(u,v),z(u,v)) W\subset S T_pM \left\{\frac{\partial \psi}{\partial u},\frac{\partial \psi}{\partial v}\right\} p \mapsto N(u,v)=\frac{\frac{\partial \psi}{\partial u}\land \frac{\partial \psi}{\partial v}}{\big\vert\big\vert \frac{\partial \psi}{\partial u}\land \frac{\partial \psi}{\partial v}\big\vert\big\vert} S:\mathfrak X(W)\rightarrow \mathfrak X(W) S(X)=- D_XN D_XN 3\times 2 S 3\times 2 2\times 2","['geometry', 'differential-geometry', 'surfaces']"
60,Relationship between the holonomy pseudogroup and holonomy homomorphism (foliation),Relationship between the holonomy pseudogroup and holonomy homomorphism (foliation),,"First, let me state some basics mainly coming from Introduction to foliations and Lie groupoids written by I. Moerdijk and J. Mrcun. A codimension $q$ foliation $\mathcal{F}$ on a smooth n-manifold $M$ is given by the following data: An open cover $\mathcal{U}:=\left\{U_{i}\right\}_{i \in I}$ of $\mathrm{M}$ . A $q$ -dimensional smooth manifold $T_{0}$ . For each $U_{i} \in \mathcal{U}$ a submersion $f_{i}: U_{i} \rightarrow T_{0}$ with connected fibers (these fibers are called plaques). For all intersections $U_{i} \cap U_{j} \neq \emptyset$ a local diffeomorphism $\gamma_{i j}$ of $T_{0}$ such that $f_{j}=\gamma_{i j} \circ f_{i}.$ We call $T=\coprod_{U_{i} \in \mathcal{U}} f_{i}\left(U_{i}\right)$ the transverse manifold of $\mathcal{F} .$ The local diffeomorphisms $\gamma_{i j}$ generate a pseudogroup $\Gamma$ of transformations on $T$ (called the holonomy pseudogroup ). The space of leaves $M / \mathcal{F}$ of the foliation $\mathcal{F}$ can be identified with $T / \Gamma$ . Also, for a transversal section $S$ at $x\in L$ one obtains the map $$ \mathrm{hol}^{S}=\mathrm{hol}^{S, S}: \pi_{1}(L, x) \longrightarrow \operatorname{Diff}_{x}(S) $$ which is a group homomorphism to obtain a homomorphism of groups hol: $\pi_{1}(L, x) \longrightarrow \operatorname{Diff}_{0}\left(\mathbb{R}^{q}\right)$ which is called the holonomy homomorphism of $L$ , and is determined uniquely up to a coniugation in $\operatorname{Diff}_{0}\left(\mathbb{R}^{q}\right)$ . The motivation for me to compare these two concepts coming from the following statement, (the above book page 26, paragraph -2): For a given foliation $\mathcal{F}$ on $M$ , a Riemannian structure on the normal bundle of $\mathcal{F}$ determines a transverse metric (i.e., $\mathcal{F}$ is Riemann) if and only if this structure is holonomy invariant. One half of this is stated in the following proposition, the other half in Remark $2.7$ (2). And the following proposition should imply the necessariness: Proposition $2.5$ Let $(\mathcal{F}, g)$ be a Riemannian foliation of $M$ . Let $L$ be a leaf of $\mathcal{F}, \alpha$ a path in $L$ , and let $T$ and $S$ be transversal sections of $\mathcal{F}$ with $\alpha(0) \in T$ and $\alpha(1) \in S$ . Then $$ \mathrm{hol}^{S, T}(\alpha):(T, \alpha(0)) \longrightarrow(S, \alpha(1)) $$ As  the authors claimed, the other direction can be proved by Remark 2.7 (2) as follows: Let $\mathcal{F}$ be a foliation of $M$ given by a Haefliger cocycle $\left(U_{i}, s_{i}, \gamma_{i j}\right)$ . If each submersion $s_{i}: U_{i} \rightarrow s_{i}\left(U_{i}\right)$ has connected fibres, then any transverse metric on $(M, \mathcal{F})$ induces a Riemannian metric on $s_{i}\left(U_{i}\right)$ , for any $i$ , such that the diffeomorphisms $\gamma_{i j}$ are isometries. Conversely, if each $s_{i}\left(U_{i}\right)$ is a Riemannian manifold and if each $\gamma_{i j}$ is an isometry, then the pull-back of the Riemannian structure on $s_{i}\left(U_{i}\right)$ along $s_{i}$ gives a transverse metric on $\left(U_{i},\left.\mathcal{F}\right|_{U_{i}}\right)$ , and these transverse metrics amalgamate to a transverse metric on $(M, \mathcal{F})$ . However, I can't see how this happen. So my questions are listed as follows: I think Remark 2.7 (2) is saying $$\mathcal{F} \text{ is Riemann}\iff \text{ transverse manifold } T \text{ has a } \Gamma\text{-invariant Riemannian metric,}$$ am I right? If I understand incorrect for the above question, how can the authors used Remark 2.7 (2) to imply the other direction? Why we call the name holonomy pseudogroup? What is the relationship between the holonomy pseudogroup and holonomy homomorphism, also,  holonomy-invariant and holonomy pseudogroup-invariant?","First, let me state some basics mainly coming from Introduction to foliations and Lie groupoids written by I. Moerdijk and J. Mrcun. A codimension foliation on a smooth n-manifold is given by the following data: An open cover of . A -dimensional smooth manifold . For each a submersion with connected fibers (these fibers are called plaques). For all intersections a local diffeomorphism of such that We call the transverse manifold of The local diffeomorphisms generate a pseudogroup of transformations on (called the holonomy pseudogroup ). The space of leaves of the foliation can be identified with . Also, for a transversal section at one obtains the map which is a group homomorphism to obtain a homomorphism of groups hol: which is called the holonomy homomorphism of , and is determined uniquely up to a coniugation in . The motivation for me to compare these two concepts coming from the following statement, (the above book page 26, paragraph -2): For a given foliation on , a Riemannian structure on the normal bundle of determines a transverse metric (i.e., is Riemann) if and only if this structure is holonomy invariant. One half of this is stated in the following proposition, the other half in Remark (2). And the following proposition should imply the necessariness: Proposition Let be a Riemannian foliation of . Let be a leaf of a path in , and let and be transversal sections of with and . Then As  the authors claimed, the other direction can be proved by Remark 2.7 (2) as follows: Let be a foliation of given by a Haefliger cocycle . If each submersion has connected fibres, then any transverse metric on induces a Riemannian metric on , for any , such that the diffeomorphisms are isometries. Conversely, if each is a Riemannian manifold and if each is an isometry, then the pull-back of the Riemannian structure on along gives a transverse metric on , and these transverse metrics amalgamate to a transverse metric on . However, I can't see how this happen. So my questions are listed as follows: I think Remark 2.7 (2) is saying am I right? If I understand incorrect for the above question, how can the authors used Remark 2.7 (2) to imply the other direction? Why we call the name holonomy pseudogroup? What is the relationship between the holonomy pseudogroup and holonomy homomorphism, also,  holonomy-invariant and holonomy pseudogroup-invariant?","q \mathcal{F} M \mathcal{U}:=\left\{U_{i}\right\}_{i \in I} \mathrm{M} q T_{0} U_{i} \in \mathcal{U} f_{i}: U_{i} \rightarrow T_{0} U_{i} \cap U_{j} \neq \emptyset \gamma_{i j} T_{0} f_{j}=\gamma_{i j} \circ f_{i}. T=\coprod_{U_{i} \in \mathcal{U}} f_{i}\left(U_{i}\right) \mathcal{F} . \gamma_{i j} \Gamma T M / \mathcal{F} \mathcal{F} T / \Gamma S x\in L 
\mathrm{hol}^{S}=\mathrm{hol}^{S, S}: \pi_{1}(L, x) \longrightarrow \operatorname{Diff}_{x}(S)
 \pi_{1}(L, x) \longrightarrow \operatorname{Diff}_{0}\left(\mathbb{R}^{q}\right) L \operatorname{Diff}_{0}\left(\mathbb{R}^{q}\right) \mathcal{F} M \mathcal{F} \mathcal{F} 2.7 2.5 (\mathcal{F}, g) M L \mathcal{F}, \alpha L T S \mathcal{F} \alpha(0) \in T \alpha(1) \in S 
\mathrm{hol}^{S, T}(\alpha):(T, \alpha(0)) \longrightarrow(S, \alpha(1))
 \mathcal{F} M \left(U_{i}, s_{i}, \gamma_{i j}\right) s_{i}: U_{i} \rightarrow s_{i}\left(U_{i}\right) (M, \mathcal{F}) s_{i}\left(U_{i}\right) i \gamma_{i j} s_{i}\left(U_{i}\right) \gamma_{i j} s_{i}\left(U_{i}\right) s_{i} \left(U_{i},\left.\mathcal{F}\right|_{U_{i}}\right) (M, \mathcal{F}) \mathcal{F} \text{ is Riemann}\iff \text{ transverse manifold } T \text{ has a } \Gamma\text{-invariant Riemannian metric,}","['differential-geometry', 'algebraic-topology', 'differential-topology', 'fundamental-groups', 'foliations']"
61,Can you uniquely define a smooth manifold M by taking the set of functions from M to R you consider smooth?,Can you uniquely define a smooth manifold M by taking the set of functions from M to R you consider smooth?,,Let M be a 2nd countable Hausdorff space. Let F be a set of functions from open sets of M to R. Does there exist a smooth structure on M that makes these functions smooth? Is this an equivalent way to define a manifold? Similar to how you can uniquely define a topological space by having a set of functions to be consider continuous?,Let M be a 2nd countable Hausdorff space. Let F be a set of functions from open sets of M to R. Does there exist a smooth structure on M that makes these functions smooth? Is this an equivalent way to define a manifold? Similar to how you can uniquely define a topological space by having a set of functions to be consider continuous?,,"['differential-geometry', 'smooth-manifolds', 'smooth-functions']"
62,Each chart of the canonical structure of a submanifold S is locally a submanifold chart,Each chart of the canonical structure of a submanifold S is locally a submanifold chart,,"I am bugged about some technical details in the following proof regarding submanifolds. I am reading a book that is not in english , so I'll try to translate here a couple of terms in the best possible way (privileged chart and submanifold chart)  but I am not sure thouse are the english names, in case  you know them, please tell me. Definition of submanifold Let $M$ be an n-manifold and $S$ a subspace of $M$ . $S$ is said a submanifold of dimension $d$ of $M$ is for every point $p$ of $M$ , there is a chart $(U,x)$ of $M$ such that $x(U\cap S)=x(U)\cap (\mathbb{R}^d\times \{0\}^{n-d})$ . In other words, if the points $q$ that fall in $U$ are characterized of the $n-d$ equations $x^{d+1},...,x^{n}(q)=0$ . Such a chart is called a privileged chart(with respect to S) and determins a chart $(U \cap S,x_{U \cap S})$ , called submanifold chart (if we identify $\mathbb{R}^d$ with $\mathbb{R}^d \times \{0\}^{n-d}$ ) If $(U,x), (V,y)$ are privileged charts, we have that $x(U\cap V \cap S)$ is an open set in $x(U\cap S)$ and so in $\mathbb{R}^d$ and $y_{V\cap S} \circ (x_{U\cap S})^{-1}=(y\circ x^{-1})_{x(U \cap V \cap S)}: x(U \cap V \cap S) \to y(U \cap V \cap S)$ is differentiable, so that the submanifold charts form an atlas and determine a d-dimensional differential structure over $S$ . With this structure, $S$ is a d-manifold. A d-submanifold is always thought of with this canonical or natural submanifold structure Proposition: Each chart of the canonical structure of a submanifold S is locally a submanifold chart. Proof. Let $p$ be a point in the domain of the chart $(V,y)$ of $S$ . By definition, ...(1) there exists a privileged chart $(U,x)$ of $M$ at $p$ that we can supposed such that $U \cap S \subset V$ and $ x(U)=A \times B$ with $A$ an open set at $0$ in $\mathbb{R}^d$ and B an open set at $0$ in $\mathbb{R}^{n-d}$ ...(2) By means of the chart $x$ , the canonical projection $\sigma : A\times B \to A\times \{0\}$ induces a sort of projection $\pi = x^{-1} \circ \sigma \circ x :U \to U \cap S$ which is differentiable ...(3) Thus we have that $(U,z)$ with $z=(y^1\circ \pi, ...,y^d\circ \pi,x^{d+1},...,x^n)$ with values in $y(U\cap S)\times B$ is a privileged chart and $z|_{U\cap S}=y|_{U\cap S}$ ...(4) My questions are: 1 They start using a definition of what?. If it is the definition of a d-submanifold,as I would expect, why aren't they using the definition above, that is $x(U\cap S)=x(U)\cap (\mathbb{R}^d\times \{0\}^{n-d})$ )? 2 Why can we suppose $U \cap S \subset V$ and why do we need that? and why do we take opens sets at $0$ necessarily ?) 3 Why is $\pi = x^{-1} \circ \sigma \circ x$ differentiable? My guess is that $\sigma $ is differentiable by definition of product topology (if that is applicable here), but still i would need to know that $x $ is differentiable for  the composition to be differentiable as well, but all I know is that $x$ is a homeomorphism, being $(U,x)$ a chart 4 Why is $z|_{U\cap S}=y|_{U\cap S}$ and why do we need to mention it ? I'm sorry for all these questions, but I have been around this for days and they are all related to this short proposition,so I don't think it made sense to make independent questions.... can someone please shed some light?","I am bugged about some technical details in the following proof regarding submanifolds. I am reading a book that is not in english , so I'll try to translate here a couple of terms in the best possible way (privileged chart and submanifold chart)  but I am not sure thouse are the english names, in case  you know them, please tell me. Definition of submanifold Let be an n-manifold and a subspace of . is said a submanifold of dimension of is for every point of , there is a chart of such that . In other words, if the points that fall in are characterized of the equations . Such a chart is called a privileged chart(with respect to S) and determins a chart , called submanifold chart (if we identify with ) If are privileged charts, we have that is an open set in and so in and is differentiable, so that the submanifold charts form an atlas and determine a d-dimensional differential structure over . With this structure, is a d-manifold. A d-submanifold is always thought of with this canonical or natural submanifold structure Proposition: Each chart of the canonical structure of a submanifold S is locally a submanifold chart. Proof. Let be a point in the domain of the chart of . By definition, ...(1) there exists a privileged chart of at that we can supposed such that and with an open set at in and B an open set at in ...(2) By means of the chart , the canonical projection induces a sort of projection which is differentiable ...(3) Thus we have that with with values in is a privileged chart and ...(4) My questions are: 1 They start using a definition of what?. If it is the definition of a d-submanifold,as I would expect, why aren't they using the definition above, that is )? 2 Why can we suppose and why do we need that? and why do we take opens sets at necessarily ?) 3 Why is differentiable? My guess is that is differentiable by definition of product topology (if that is applicable here), but still i would need to know that is differentiable for  the composition to be differentiable as well, but all I know is that is a homeomorphism, being a chart 4 Why is and why do we need to mention it ? I'm sorry for all these questions, but I have been around this for days and they are all related to this short proposition,so I don't think it made sense to make independent questions.... can someone please shed some light?","M S M S d M p M (U,x) M x(U\cap S)=x(U)\cap (\mathbb{R}^d\times \{0\}^{n-d}) q U n-d x^{d+1},...,x^{n}(q)=0 (U \cap S,x_{U \cap S}) \mathbb{R}^d \mathbb{R}^d \times \{0\}^{n-d} (U,x), (V,y) x(U\cap V \cap S) x(U\cap S) \mathbb{R}^d y_{V\cap S} \circ (x_{U\cap S})^{-1}=(y\circ x^{-1})_{x(U \cap V \cap S)}: x(U \cap V \cap S) \to y(U \cap V \cap S) S S p (V,y) S (U,x) M p U \cap S \subset V  x(U)=A \times B A 0 \mathbb{R}^d 0 \mathbb{R}^{n-d} x \sigma : A\times B \to A\times \{0\} \pi = x^{-1} \circ \sigma \circ x :U \to U \cap S (U,z) z=(y^1\circ \pi, ...,y^d\circ \pi,x^{d+1},...,x^n) y(U\cap S)\times B z|_{U\cap S}=y|_{U\cap S} x(U\cap S)=x(U)\cap (\mathbb{R}^d\times \{0\}^{n-d}) U \cap S \subset V 0 \pi = x^{-1} \circ \sigma \circ x \sigma  x  x (U,x) z|_{U\cap S}=y|_{U\cap S}","['differential-geometry', 'manifolds', 'submanifold']"
63,Confusion regarding geodesics and (linear) transformations,Confusion regarding geodesics and (linear) transformations,,"I'm having an embarrassingly hard time reconciling some basic calculations that I think are correct (but given my confusion, I won't make a warranty) and the discrepancy in pheneomenology of the geodesics on an ellipsoid (which are rather complex) versus on a sphere (which are just arcs of great circles). Here's the basic calculations first: Let $g$ be (the matrix of) a Riemannian metric on a sub(psuedo)manifold of $\mathbb{R}^n$ relative to coordinates $x$ . Let $R \in GL_n$ and $x \mapsto Rx =: x'$ be the corresponding linear transformation. The matrix of the metric relative to the coordinates $x'$ is then $g' = R^{-T}gR^{-1}$ , and (eschewing the Einstein convention in order to write matrices conventionally) the Christoffel symbols transform as $$(\Gamma')_{ij}^k = \sum_{\ell m p} \frac{\partial x_\ell}{\partial x'_i} \frac{\partial x_p}{\partial x'_j} \frac{\partial x'_k}{\partial x_m} \Gamma_{\ell p}^m.$$ Now $\frac{\partial x'_i}{\partial x_j} = R_{ij}$ and similarly $\frac{\partial x_i}{\partial x'_j} = (R^{-1})_{ij}$ , so the preceding becomes $$(\Gamma')_{ij}^k = \sum_{\ell m p} (R^{-1})_{\ell i} (R^{-1})_{pj} R_{km} \Gamma_{\ell p}^m.$$ Now the geodesic equation is $$\ddot x'_k = -\sum_{ij} (\Gamma')_{ij}^k \dot x'_i \dot x'_j$$ which after unpacking the transformations becomes $$ \begin{align} \sum_q R_{kq} \ddot x_q & = -\sum_{ij} (R^{-1})_{\ell i} (R^{-1})_{pj} R_{km} \Gamma_{\ell p}^m \cdot \sum_r R_{ir} \dot x_r \cdot \sum_s R_{js} \dot x_s \\  & = -\sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \cdot \sum_{ir} (R^{-1})_{\ell i} R_{ir} \dot x_r \cdot \sum_{js} (R^{-1})_{pj} R_{js} \dot x_s \\  & = -\sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \cdot \sum_r \delta_{\ell r} \dot x_r \cdot \sum_s \delta_{ps} \dot x_s \\  & = -\sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \cdot \dot x_\ell \cdot \dot x_p. \end{align} $$ Multiplying by $R^{-1}$ on the left, we get $$ \begin{align} \ddot x_a & = -\sum_k (R^{-1})_{ak} \sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \dot x_\ell \dot x_p \\  & = -\sum_{\ell m p} \sum_k (R^{-1})_{ak} R_{km} \Gamma_{\ell p}^m \dot x_\ell \dot x_p \\  & = -\sum_{\ell m p} \delta_{am} \Gamma_{\ell p}^m \dot x_\ell \dot x_p \\  & = -\sum_{\ell p} \Gamma_{\ell p}^a \dot x_\ell \dot x_p. \end{align} $$ This is just the geodesic equation in the original coordinates. Now of course the whole point of differential geometry is to study quantities that are ultimately independent of any choice of coordinates, so this doesn't seem weird. BUT: an ellipsoid is just a linear (or affine, if one prefers) transformation of a sphere. And the geodesics on these two surfaces behave very differently.","I'm having an embarrassingly hard time reconciling some basic calculations that I think are correct (but given my confusion, I won't make a warranty) and the discrepancy in pheneomenology of the geodesics on an ellipsoid (which are rather complex) versus on a sphere (which are just arcs of great circles). Here's the basic calculations first: Let be (the matrix of) a Riemannian metric on a sub(psuedo)manifold of relative to coordinates . Let and be the corresponding linear transformation. The matrix of the metric relative to the coordinates is then , and (eschewing the Einstein convention in order to write matrices conventionally) the Christoffel symbols transform as Now and similarly , so the preceding becomes Now the geodesic equation is which after unpacking the transformations becomes Multiplying by on the left, we get This is just the geodesic equation in the original coordinates. Now of course the whole point of differential geometry is to study quantities that are ultimately independent of any choice of coordinates, so this doesn't seem weird. BUT: an ellipsoid is just a linear (or affine, if one prefers) transformation of a sphere. And the geodesics on these two surfaces behave very differently.","g \mathbb{R}^n x R \in GL_n x \mapsto Rx =: x' x' g' = R^{-T}gR^{-1} (\Gamma')_{ij}^k = \sum_{\ell m p} \frac{\partial x_\ell}{\partial x'_i} \frac{\partial x_p}{\partial x'_j} \frac{\partial x'_k}{\partial x_m} \Gamma_{\ell p}^m. \frac{\partial x'_i}{\partial x_j} = R_{ij} \frac{\partial x_i}{\partial x'_j} = (R^{-1})_{ij} (\Gamma')_{ij}^k = \sum_{\ell m p} (R^{-1})_{\ell i} (R^{-1})_{pj} R_{km} \Gamma_{\ell p}^m. \ddot x'_k = -\sum_{ij} (\Gamma')_{ij}^k \dot x'_i \dot x'_j  \begin{align} \sum_q R_{kq} \ddot x_q & = -\sum_{ij} (R^{-1})_{\ell i} (R^{-1})_{pj} R_{km} \Gamma_{\ell p}^m \cdot \sum_r R_{ir} \dot x_r \cdot \sum_s R_{js} \dot x_s \\ 
& = -\sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \cdot \sum_{ir} (R^{-1})_{\ell i} R_{ir} \dot x_r \cdot \sum_{js} (R^{-1})_{pj} R_{js} \dot x_s \\ 
& = -\sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \cdot \sum_r \delta_{\ell r} \dot x_r \cdot \sum_s \delta_{ps} \dot x_s \\ 
& = -\sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \cdot \dot x_\ell \cdot \dot x_p. \end{align}  R^{-1}  \begin{align} \ddot x_a & = -\sum_k (R^{-1})_{ak} \sum_{\ell m p} R_{km} \Gamma_{\ell p}^m \dot x_\ell \dot x_p \\ 
& = -\sum_{\ell m p} \sum_k (R^{-1})_{ak} R_{km} \Gamma_{\ell p}^m \dot x_\ell \dot x_p \\ 
& = -\sum_{\ell m p} \delta_{am} \Gamma_{\ell p}^m \dot x_\ell \dot x_p \\ 
& = -\sum_{\ell p} \Gamma_{\ell p}^a \dot x_\ell \dot x_p. \end{align} ","['differential-geometry', 'riemannian-geometry', 'geodesic', 'ellipsoids']"
64,Hodge decomposition for complex manifold,Hodge decomposition for complex manifold,,"Let $X$ be a compact oriented Riemannian manifold. By Hodge decomposition, we can decompose $$\Omega^k(X)=\mathrm{im}(d)\oplus\mathrm{im}(d^*)\oplus\ker(\Delta).$$ Now, if further $X$ has a complex structure, I read on a book that $$\Omega^{p,q}(X)=\partial(\Omega^{p-1,q}(X))\oplus\partial^*(\Omega^{p+1,q}(X))\oplus\ker(\Delta_{\partial}),$$ or $$\Omega^{p,q}(X)=\bar\partial(\Omega^{p,q-1}(X))\oplus\bar\partial^*(\Omega^{p,q+1}(X))\oplus\ker(\Delta_{\bar\partial}).$$ My question is: given that I know the theorem for the real case and $d=\partial+\bar\partial$ , shouldn't the result be $$\Omega^{p,q}(X)=(\partial(\Omega^{p-1,q}(X))+\bar\partial(\Omega^{p,q-1}(X)))\oplus(\partial^*(\Omega^{p+1,q}(X))+\bar\partial^*(\Omega^{p,q+1}(X)))\oplus\ker(\Delta)?$$","Let be a compact oriented Riemannian manifold. By Hodge decomposition, we can decompose Now, if further has a complex structure, I read on a book that or My question is: given that I know the theorem for the real case and , shouldn't the result be","X \Omega^k(X)=\mathrm{im}(d)\oplus\mathrm{im}(d^*)\oplus\ker(\Delta). X \Omega^{p,q}(X)=\partial(\Omega^{p-1,q}(X))\oplus\partial^*(\Omega^{p+1,q}(X))\oplus\ker(\Delta_{\partial}), \Omega^{p,q}(X)=\bar\partial(\Omega^{p,q-1}(X))\oplus\bar\partial^*(\Omega^{p,q+1}(X))\oplus\ker(\Delta_{\bar\partial}). d=\partial+\bar\partial \Omega^{p,q}(X)=(\partial(\Omega^{p-1,q}(X))+\bar\partial(\Omega^{p,q-1}(X)))\oplus(\partial^*(\Omega^{p+1,q}(X))+\bar\partial^*(\Omega^{p,q+1}(X)))\oplus\ker(\Delta)?","['differential-geometry', 'complex-geometry', 'complex-manifolds', 'hodge-theory']"
65,Curl of a Lie bracket of two vector fields,Curl of a Lie bracket of two vector fields,,"I am wondering if there is a nice (ideally coordinate free, something that holds in manifolds) identity of the form $\nabla \times [X,Y] = [\nabla \times X,Y] + [X, \nabla \times Y] + ...$ , and if this is not something that can exist is it at least possible to determine that if $X,Y$ are irrotational $\nabla \times X = \nabla \times Y = 0$ then we can conclude their Lie bracket is irrotational. I first tried in vain writing $\nabla \times = \star d$ and hoping I could get some very easy result out of exterior derivative identities but the Lie bracket completely brick walled any progress from this direction. Since that didn't work I calculated $(\nabla \times v)^i= \varepsilon^i_{jk} \frac{\partial}{\partial x^j}v^k$ and I started to get terms that did look like $X(\nabla \times Y^i)$ which seemed promising, but I also got a lot of horrible junk terms looking like $\varepsilon^i_{jk}\frac{\partial X^a}{\partial x^j}\frac{\partial}{\partial x^a}Y^k$ which I don't know how to nicely take out of index notation, since just taking the partial derivative of the components of the vector field $X$ and feeding it $Y$ doesn't seem like a very geometric quantity to have. Is there a better way of doing this, or is there some known identity someone has already found in a book that I can find?","I am wondering if there is a nice (ideally coordinate free, something that holds in manifolds) identity of the form , and if this is not something that can exist is it at least possible to determine that if are irrotational then we can conclude their Lie bracket is irrotational. I first tried in vain writing and hoping I could get some very easy result out of exterior derivative identities but the Lie bracket completely brick walled any progress from this direction. Since that didn't work I calculated and I started to get terms that did look like which seemed promising, but I also got a lot of horrible junk terms looking like which I don't know how to nicely take out of index notation, since just taking the partial derivative of the components of the vector field and feeding it doesn't seem like a very geometric quantity to have. Is there a better way of doing this, or is there some known identity someone has already found in a book that I can find?","\nabla \times [X,Y] = [\nabla \times X,Y] + [X, \nabla \times Y] + ... X,Y \nabla \times X = \nabla \times Y = 0 \nabla \times = \star d (\nabla \times v)^i= \varepsilon^i_{jk} \frac{\partial}{\partial x^j}v^k X(\nabla \times Y^i) \varepsilon^i_{jk}\frac{\partial X^a}{\partial x^j}\frac{\partial}{\partial x^a}Y^k X Y","['differential-geometry', 'reference-request', 'vector-analysis', 'differential-forms', 'vector-fields']"
66,Non-trivial Examples of Surfaces of Voss,Non-trivial Examples of Surfaces of Voss,,"Let $I$ and $J \subset \mathbb{R}$ be two intervals of the real line. A smooth parametrized immersed surface $\sigma: I\times J \rightarrow \mathbb{R}^3$ is called a surface of Voss if its coordinate curves satisfy the following conditions: They form a conjugate net (i.e. $\sigma_{uv} \in \textrm{span}\{\sigma_u, \sigma_v\}$ ), They are two one-parameter families of geodesics. I'm looking for non-trivial examples (non-developable surfaces) of this kind. I would be very much interested in a non-minimal example too. My Attempt: I know that there are ways of making them using their relation to a pseudospherical surface but all of them involve solving systems of PDEs and I wish to know if one has a ""relatively simple"" example of these surfaces.","Let and be two intervals of the real line. A smooth parametrized immersed surface is called a surface of Voss if its coordinate curves satisfy the following conditions: They form a conjugate net (i.e. ), They are two one-parameter families of geodesics. I'm looking for non-trivial examples (non-developable surfaces) of this kind. I would be very much interested in a non-minimal example too. My Attempt: I know that there are ways of making them using their relation to a pseudospherical surface but all of them involve solving systems of PDEs and I wish to know if one has a ""relatively simple"" example of these surfaces.","I J \subset \mathbb{R} \sigma: I\times J \rightarrow \mathbb{R}^3 \sigma_{uv} \in \textrm{span}\{\sigma_u, \sigma_v\}","['differential-geometry', 'examples-counterexamples', 'surfaces', 'geodesic', 'minimal-surfaces']"
67,Volume of a Riemannian manifold with a scaled metric,Volume of a Riemannian manifold with a scaled metric,,"I'm confused with the volume of an n-dimensional Riemannian manifold with a scaled metric. Specifically, let $M$ be a Riemannian manifold with Riemannian metric $g$ and its volume denoted by $vol_g(M)$ . If we endow $M$ with another metric $$\widetilde{g}=\lambda g,\qquad \text{here $\lambda$ is a positive smooth function on $M$}$$ then, how about the volume $vol_{\widetilde{g}}(M)$ of with respect to $\widetilde{g}$ ? I know that the volume form $$dv_{g}=\sqrt{\det\ g}\ dx^1\wedge\cdots \wedge dx^n .$$ So I guess that $$dv_{\widetilde{g}}=\lambda^{n/2}dv_{g}, $$ and therefore $$vol_{\widetilde{g}}(M)=\lambda^{n/2}vol_g(M) .$$ Do you think it is right? If not, how do we to calculate the volume $vol_{\widetilde{g}}(M)$ and figure out the relationship with $vol_g(M)$ ? Thanks in advance!","I'm confused with the volume of an n-dimensional Riemannian manifold with a scaled metric. Specifically, let be a Riemannian manifold with Riemannian metric and its volume denoted by . If we endow with another metric then, how about the volume of with respect to ? I know that the volume form So I guess that and therefore Do you think it is right? If not, how do we to calculate the volume and figure out the relationship with ? Thanks in advance!","M g vol_g(M) M \widetilde{g}=\lambda g,\qquad \text{here \lambda is a positive smooth function on M} vol_{\widetilde{g}}(M) \widetilde{g} dv_{g}=\sqrt{\det\ g}\ dx^1\wedge\cdots \wedge dx^n . dv_{\widetilde{g}}=\lambda^{n/2}dv_{g},  vol_{\widetilde{g}}(M)=\lambda^{n/2}vol_g(M) . vol_{\widetilde{g}}(M) vol_g(M)","['differential-geometry', 'riemannian-geometry', 'conformal-geometry']"
68,Components in the complement of compact subset in manifold,Components in the complement of compact subset in manifold,,"Let $M$ be a (smooth) connected manifold and $K \subset M$ a compact subset. Then $M \setminus K$ consists of a number of components. Let $(U_j)_{j \in \mathcal J}$ be the collection of bounded components in $M \setminus K$, i.e, the components with compact closure in $M$. I wonder if its true that the set $U:=\bigcup_{j \in \mathcal J} U_j$ is again a bounded subset of $M$. Some thoughts I have made so far: It is clear that $M \setminus K$ may have an infinite, even uncountable number of bounded components, so one can't argue that $U$ is bounded because it is the finite union of bounded subsets. Also, the fact that $K$ is compact obviously plays a big role. I attempted to argue by contradiction: Suppose that $U$ was unbounded. Then $U$ cannot be contained in any compact connected subset of $M$. Somehow, I feel this should also imply that $K$ cannot be contained in any compact connected subset of $M$, which is a condradiction. But I am not sure how to make that last step.","Let $M$ be a (smooth) connected manifold and $K \subset M$ a compact subset. Then $M \setminus K$ consists of a number of components. Let $(U_j)_{j \in \mathcal J}$ be the collection of bounded components in $M \setminus K$, i.e, the components with compact closure in $M$. I wonder if its true that the set $U:=\bigcup_{j \in \mathcal J} U_j$ is again a bounded subset of $M$. Some thoughts I have made so far: It is clear that $M \setminus K$ may have an infinite, even uncountable number of bounded components, so one can't argue that $U$ is bounded because it is the finite union of bounded subsets. Also, the fact that $K$ is compact obviously plays a big role. I attempted to argue by contradiction: Suppose that $U$ was unbounded. Then $U$ cannot be contained in any compact connected subset of $M$. Somehow, I feel this should also imply that $K$ cannot be contained in any compact connected subset of $M$, which is a condradiction. But I am not sure how to make that last step.",,"['general-topology', 'manifolds']"
69,Smooth homotopy and a theorem in Lee's book,Smooth homotopy and a theorem in Lee's book,,"Suppose that $M,N$ are smooth manifolds without boundary and $F: N \rightarrow M$ is a continuous map, then we know that $F$ is homotopic to a smooth map ( Th6.26 , Lee's Smooth Manifolds),i.e there is a continuous map $G: [0,1]\times N \rightarrow M$ such that $G(0, \cdot) = F$ and $G(1, \cdot)$ is smooth. My question is : Can we choose $G$ so that $G$ is smooth in $(0,1]\times N$ ? Why I came up with this small (and trivial?) question? : I has been learning Lee's book for fun by trying to prove each Theorems in his book by myself. Then for this Theorem, I obtained the existence of such $G$ so I wanted to check if it is really right to make sure that I understand correctly most of concepts related to Smooth Manifolds. Thank you for your time.","Suppose that are smooth manifolds without boundary and is a continuous map, then we know that is homotopic to a smooth map ( Th6.26 , Lee's Smooth Manifolds),i.e there is a continuous map such that and is smooth. My question is : Can we choose so that is smooth in ? Why I came up with this small (and trivial?) question? : I has been learning Lee's book for fun by trying to prove each Theorems in his book by myself. Then for this Theorem, I obtained the existence of such so I wanted to check if it is really right to make sure that I understand correctly most of concepts related to Smooth Manifolds. Thank you for your time.","M,N F: N \rightarrow M F G: [0,1]\times N \rightarrow M G(0, \cdot) = F G(1, \cdot) G G (0,1]\times N G","['differential-geometry', 'smooth-manifolds', 'homotopy-theory']"
70,Understanding a definition of the exterior derivative,Understanding a definition of the exterior derivative,,"I'm trying to prove the exact same formula as in this question : $U \subset \mathbb{R^n}$ an open set, $\omega$ a k-differential form on $U$ , $X_0, \dots, X_k$ vector fields on U, i. e. elements of $C^{\infty}(U)^n$ . I am supposed to show (for k = 1, 2): $$d\omega(X_0, ... , X_k) = \sum_i (-1)^i X_i(\omega(X_0, ... , \hat{X_i}, ... , X_k)) + \sum_{i < j}(-1)^{i+j}\omega([X_i, X_j], X_0, ... , \hat{X_i}, ... , \hat{X_j}, ..., X_k)$$ In the lecture I'm following we did not learn about Cartans magic formula. I don't even know what $(\mathcal{L}_Y \omega)$ means. My main problem is: I'm struggling to understand what $X_i(\omega(X_0, ... , \hat{X_i}, ... , X_k))$ is: I thought $\omega(X_0, ... , \hat{X_i}, ... , X_k)$ is an element of $C^{\infty}(U)$ . How can we feed it to $X_i$ ?","I'm trying to prove the exact same formula as in this question : an open set, a k-differential form on , vector fields on U, i. e. elements of . I am supposed to show (for k = 1, 2): In the lecture I'm following we did not learn about Cartans magic formula. I don't even know what means. My main problem is: I'm struggling to understand what is: I thought is an element of . How can we feed it to ?","U \subset \mathbb{R^n} \omega U X_0, \dots, X_k C^{\infty}(U)^n d\omega(X_0, ... , X_k) = \sum_i (-1)^i X_i(\omega(X_0, ... , \hat{X_i}, ... , X_k)) + \sum_{i < j}(-1)^{i+j}\omega([X_i, X_j], X_0, ... , \hat{X_i}, ... , \hat{X_j}, ..., X_k) (\mathcal{L}_Y \omega) X_i(\omega(X_0, ... , \hat{X_i}, ... , X_k)) \omega(X_0, ... , \hat{X_i}, ... , X_k) C^{\infty}(U) X_i","['differential-geometry', 'differential-forms', 'vector-fields']"
71,Fully worked out examples in Riemannian geometry,Fully worked out examples in Riemannian geometry,,"I am trying to teach myself the basics of Riemannian geometry (curvature, Gauss-Bonnet, etc...). I am having a hard time getting started because I can't build good examples by myself when it comes down to understanding the definitions and the theorems. For instance, I would like to understand the Gauss-Bonnet formula for compact surfaces without boundary $$\int_M\mathcal{K}\,\mathrm{d}A=2\pi\chi(M)$$ by performing explicit computations of the LHS for, say, the real projective plane. Could you help me find references (lecture notes, blog posts, textbooks, ...) where this kind of computations for concrete examples is carried out with great detail at the undergraduate level? Edit: The class notes Differential Geometry: A First Course in Curves and Surfaces ( available here ) by Ted Shifrin are a perfect example of what I'm looking for.","I am trying to teach myself the basics of Riemannian geometry (curvature, Gauss-Bonnet, etc...). I am having a hard time getting started because I can't build good examples by myself when it comes down to understanding the definitions and the theorems. For instance, I would like to understand the Gauss-Bonnet formula for compact surfaces without boundary by performing explicit computations of the LHS for, say, the real projective plane. Could you help me find references (lecture notes, blog posts, textbooks, ...) where this kind of computations for concrete examples is carried out with great detail at the undergraduate level? Edit: The class notes Differential Geometry: A First Course in Curves and Surfaces ( available here ) by Ted Shifrin are a perfect example of what I'm looking for.","\int_M\mathcal{K}\,\mathrm{d}A=2\pi\chi(M)","['differential-geometry', 'riemannian-geometry', 'curvature']"
72,The dimension of a tangent space of a smooth $k$-dimensional manifold is actually $k$,The dimension of a tangent space of a smooth -dimensional manifold is actually,k k,"From Ted Shifrin's comment "" We only need to restrict attention to a small neighborhood of $\phi(x)$ to apply the chain rule at a single point "" in his answer, I'm trying to formalize it to make things clear. Could you have a check on my proof? First, I recall related definitions to remove ambiguity. A subset $X \subseteq \mathbb{R}^{N}$ is  called a smooth $n$ -dimensional manifold if $\forall x \in X$ , $\exists$ a diffeomorphism $\varphi: U \to V$ such that $V$ is open in $X$ , $U$ is open in $\mathbb{R}^{n}$ , and $x \in V$ . Then $\varphi$ is called a local parameterization of $V$ . The inverse $\varphi^{-1}$ is called a local coordinate system , or chart , on $V$ . Let $X \subseteq \mathbb R^N$ be a smooth $n$ -dimensional manifold and $x \in X$ . Let $\varphi: U \to V$ be a local parameterization around $x \in V$ . The continuous linear map $\mathrm d \varphi_{\varphi^{-1}(x)} : \mathbb R^n \to \mathbb R^N$ is the Fr챕chet derivative of $\varphi$ at $\varphi^{-1}(x) \in U$ . The tangent space of $X$ at $x$ , denoted by $T_xX$ , is defined as the image of $\mathrm d \varphi_{\varphi^{-1}(x)}$ , i.e., $$T_xX := \operatorname{im} \left (\mathrm d \varphi_{\varphi^{-1}(x)} \right ).$$ Theorem: Let $X \subseteq \mathbb R^N$ be a $k$ -dimensional smooth manifold and $x \in X$ . Then the tangent space $T_xX$ is a vector space of dimension $k$ . Proof: Let $\varphi:U \to V$ be a local parameterization around $x$ . Here $U$ and $V$ are open in $\mathbb R^k$ and $X$ respectively. Also, $x \in V$ . Let $\varphi^{-1}$ be the inverse of $\varphi$ and $y := \varphi^{-1} (x) \in U$ . Let $\phi : V' \to \mathbb R^k$ be a differentiable extension of $\varphi^{-1}$ around $x$ . Here $V'$ is open in $\mathbb R^N$ and $x \in V'$ . Also, $\phi$ and $\varphi^{-1}$ agree on $V' \cap V$ . There exist $r_1, r_2>0$ such that $\mathbb B_{\mathbb R^N}(x, r_1) \subseteq V'$ and $\mathbb B_{\mathbb R^k}(y, r_2) \subseteq U$ . Thanks to the differentiability and thus the continuity of $\varphi$ , there exists $r_3 > 0$ such that $z \in \mathbb B_{\mathbb R^k}(y, r_3) \implies \varphi(z) \in \mathbb B_{\mathbb R^N}(x, r_1)$ . Let $r_4 := \min\{r_2, r_3\}$ and $U' := \mathbb B_{\mathbb R^k}(y, r_4)$ . Notice that $U'$ is open in $\mathbb R^k$ and $y \in U'$ . Also, $$\operatorname{im} ( \varphi_{\restriction U'} ) \subseteq \mathbb B_{\mathbb R^N}(x, r_1) \subseteq V' = \operatorname{dom} \phi.$$ Then the map $\Psi := \phi \circ \varphi_{\restriction U'}$ is well-defined and differentiable at $y$ . Moreover, $\Psi$ is the identity map on $U'$ , so $\mathrm d\Psi_y$ is the identity map on $\mathbb R^k$ . By chain rule, $$\mathrm d\Psi_y = \mathrm d \phi_{\varphi (y)} \circ \mathrm d\varphi_{y}.$$ This means $\mathrm d \phi_{\varphi (y)}$ is surjective, while $\mathrm d \varphi_{\varphi^{-1}(x)} = \mathrm d\varphi_{y}$ is injective. Hence $\mathrm d \varphi_{\varphi^{-1}(x)}$ is indeed an isomorphism between $\mathbb R^k$ and the tangent space $T_xX$ . This completes the proof. Update: Writing down the details reveals why we can not apply the same strategy to show $N=k$ (which is indeed not correct!). To succeed, we want to find an open neighborhood $A$ of $x$ in $V'$ such that $\Phi := \varphi \circ \phi_{\restriction A} = \operatorname{id}_{A}$ . However, the only thing we know is $\varphi \circ \phi_{\restriction A \cap V} = \operatorname{id}_{A \cap V}$ . This is because we have no information/restriction on the behavior of $\phi$ on $A \cap V^c$ . Let $A \subseteq \mathbb R^m$ , $B \subseteq C \subseteq \mathbb R^n$ , and $D \subseteq \mathbb R^p$ . Let $f:A \to B$ and $g:C \to D$ be differentiable/smooth in this sense . With the same technique of restriction, we can show that $h := g \circ f:A \to D$ is also differentiable/smooth. Fix $x \in A$ and let $y:=f(x)$ . Then there is a differentiable extension $\varphi:U \to \mathbb R^n$ of $f$ around $x$ . Here $x\in U$ , $U$ is open in $\mathbb R^m$ , and $\varphi$ agrees with $f$ on $A \cap U$ . Similarly,  there is a differentiable extension $\phi:V \to \mathbb R^p$ of $g$ around $y$ . Here $y \in V$ , $V$ is open in $\mathbb R^n$ , and $\phi$ agrees with $g$ on $C \cap V$ . There exists $r>0$ such that $U' := \mathbb B_{\mathbb R^m}(x, r) \subseteq U$ and $x \in U'\implies \varphi(x) \in V$ . Then $\phi \circ \varphi_{\restriction U'}$ is a differentiable extension of $h$ at $x$ and agrees with $h$ on $A \cap U'$ .","From Ted Shifrin's comment "" We only need to restrict attention to a small neighborhood of to apply the chain rule at a single point "" in his answer, I'm trying to formalize it to make things clear. Could you have a check on my proof? First, I recall related definitions to remove ambiguity. A subset is  called a smooth -dimensional manifold if , a diffeomorphism such that is open in , is open in , and . Then is called a local parameterization of . The inverse is called a local coordinate system , or chart , on . Let be a smooth -dimensional manifold and . Let be a local parameterization around . The continuous linear map is the Fr챕chet derivative of at . The tangent space of at , denoted by , is defined as the image of , i.e., Theorem: Let be a -dimensional smooth manifold and . Then the tangent space is a vector space of dimension . Proof: Let be a local parameterization around . Here and are open in and respectively. Also, . Let be the inverse of and . Let be a differentiable extension of around . Here is open in and . Also, and agree on . There exist such that and . Thanks to the differentiability and thus the continuity of , there exists such that . Let and . Notice that is open in and . Also, Then the map is well-defined and differentiable at . Moreover, is the identity map on , so is the identity map on . By chain rule, This means is surjective, while is injective. Hence is indeed an isomorphism between and the tangent space . This completes the proof. Update: Writing down the details reveals why we can not apply the same strategy to show (which is indeed not correct!). To succeed, we want to find an open neighborhood of in such that . However, the only thing we know is . This is because we have no information/restriction on the behavior of on . Let , , and . Let and be differentiable/smooth in this sense . With the same technique of restriction, we can show that is also differentiable/smooth. Fix and let . Then there is a differentiable extension of around . Here , is open in , and agrees with on . Similarly,  there is a differentiable extension of around . Here , is open in , and agrees with on . There exists such that and . Then is a differentiable extension of at and agrees with on .","\phi(x) X \subseteq \mathbb{R}^{N} n \forall x \in X \exists \varphi: U \to V V X U \mathbb{R}^{n} x \in V \varphi V \varphi^{-1} V X \subseteq \mathbb R^N n x \in X \varphi: U \to V x \in V \mathrm d \varphi_{\varphi^{-1}(x)} : \mathbb R^n \to \mathbb R^N \varphi \varphi^{-1}(x) \in U X x T_xX \mathrm d \varphi_{\varphi^{-1}(x)} T_xX := \operatorname{im} \left (\mathrm d \varphi_{\varphi^{-1}(x)} \right ). X \subseteq \mathbb R^N k x \in X T_xX k \varphi:U \to V x U V \mathbb R^k X x \in V \varphi^{-1} \varphi y := \varphi^{-1} (x) \in U \phi : V' \to \mathbb R^k \varphi^{-1} x V' \mathbb R^N x \in V' \phi \varphi^{-1} V' \cap V r_1, r_2>0 \mathbb B_{\mathbb R^N}(x, r_1) \subseteq V' \mathbb B_{\mathbb R^k}(y, r_2) \subseteq U \varphi r_3 > 0 z \in \mathbb B_{\mathbb R^k}(y, r_3) \implies \varphi(z) \in \mathbb B_{\mathbb R^N}(x, r_1) r_4 := \min\{r_2, r_3\} U' := \mathbb B_{\mathbb R^k}(y, r_4) U' \mathbb R^k y \in U' \operatorname{im} ( \varphi_{\restriction U'} ) \subseteq \mathbb B_{\mathbb R^N}(x, r_1) \subseteq V' = \operatorname{dom} \phi. \Psi := \phi \circ \varphi_{\restriction U'} y \Psi U' \mathrm d\Psi_y \mathbb R^k \mathrm d\Psi_y = \mathrm d \phi_{\varphi (y)} \circ \mathrm d\varphi_{y}. \mathrm d \phi_{\varphi (y)} \mathrm d \varphi_{\varphi^{-1}(x)} = \mathrm d\varphi_{y} \mathrm d \varphi_{\varphi^{-1}(x)} \mathbb R^k T_xX N=k A x V' \Phi := \varphi \circ \phi_{\restriction A} = \operatorname{id}_{A} \varphi \circ \phi_{\restriction A \cap V} = \operatorname{id}_{A \cap V} \phi A \cap V^c A \subseteq \mathbb R^m B \subseteq C \subseteq \mathbb R^n D \subseteq \mathbb R^p f:A \to B g:C \to D h := g \circ f:A \to D x \in A y:=f(x) \varphi:U \to \mathbb R^n f x x\in U U \mathbb R^m \varphi f A \cap U \phi:V \to \mathbb R^p g y y \in V V \mathbb R^n \phi g C \cap V r>0 U' := \mathbb B_{\mathbb R^m}(x, r) \subseteq U x \in U'\implies \varphi(x) \in V \phi \circ \varphi_{\restriction U'} h x h A \cap U'","['differential-geometry', 'solution-verification', 'smooth-manifolds', 'tangent-spaces']"
73,How to prove that a surface whose normal lines intersect a given line is a portion of a surface of revolution,How to prove that a surface whose normal lines intersect a given line is a portion of a surface of revolution,,"I'm stuck on Exercise 3.70 from Kristopher Tapp's Differential Topology of Curves and Surfaces : Let $S$ be a connected oriented regular surface. Suppose there exists a line $L \subset \mathbb R^3$ that intersects all normal lines to $S$ (that is, for every $p \in S$ , the trace of the normal line $t \mapsto p + t N(p)$ intersects $L$ ). Prove that $S$ is a portion of a surface of revolution. I was able to show that every point $p \in S$ has a neighbourhood in $S$ whose intersection with the plane perpendicular to $L$ through $p$ is a circle with centre on $L$ (with the help of part (i) in this question: How to solve this questions about regular surfaces? ): Note that we further require $L$ not to intersect $S$ . First, suppose $L$ is the $z$ -axis and let $p = (p_1, p_2, p_3) \in S$ . Then $p + s N(p) = (0, 0, z)$ for some $s \in \mathbb R - \{0\}$ and some $z \in \mathbb R$ , so $N(p) = (-p_1 / s, -p_2 / s, (z - p_3) / s)$ . Note that $\langle(-p_1 / s, -p_2 / s, 0), N(p)\rangle = (p_1^2 + p_2^2) / s^2 \neq 0$ , so $(-p_1 / s, -p_2 / s, 0) \notin T_pS$ . Thus, either $e_1 \notin T_pS$ or $e_2 \notin T_pS$ , and so by Exercise 3.48, there is a neighbourhood $V$ of $p$ in $S$ that is the graph of a smooth function of one of the following forms: $x = f(y, z)$ , or $y = f(x, z)$ , respectively. Define the curve $\gamma: I \to V$ by $\gamma(t) = (f(t, p_3), t, p_3)$ or $\gamma(t) = (t, f(t, p_3), p_3)$ , respectively. Then $\gamma'(t) = (df_{(t, p_3)}(1, 0), 1, 0) \neq 0$ or $\gamma'(t) = (1, df_{(t, p_3)}(1, 0), 0) \neq 0$ , and $\gamma(I) \subset p + \operatorname{span}\{e_1, e_2\}$ . Conversely, if $(x, y, p_3) \in V$ , then $x = f(y, p_3)$ or $y = f(x, p_3)$ , and so $V \cap (p + \operatorname{span}\{e_1, e_2\}) \subset \gamma(I)$ . We claim $\gamma$ is a portion of the circle centred at $(0, 0, p_3)$ through $p$ . For each $t \in I$ , let $\mathfrak n(t)$ denote the projection of $N(\gamma(t))$ onto $\operatorname{span}\{e_1, e_2\}$ . Then $$\langle\mathfrak n(t), \gamma'(t)\rangle = \langle N(\gamma(t)), \gamma'(t)\rangle - \langle N(\gamma(t)), e_3\rangle \langle e_3, \gamma'(t)\rangle = 0$$ and $\gamma(t) - (0, 0, p_3) = -\frac{\lvert\gamma(t) - (0, 0, p_3)\rvert}{\lvert\mathfrak n(t)\rvert} \mathfrak n(t)$ for all $t \in I$ . Thus, $$\frac{d}{dt}\langle\gamma(t) - (0, 0, p_3), \gamma(t) - (0, 0, p_3)\rangle = -\frac{2 \lvert\gamma(t) - (0, 0, p_3)\rvert}{\lvert\mathfrak n(t)\rvert} \langle\gamma'(t), \mathfrak n(t)\rangle = 0,$$ and so $\lvert\gamma(t) - (0, 0, p_3)\rvert$ is constant. What I'm having trouble showing is that there's a single curve whose surface of revolution about the line $L$ contains $S$ , i.e. that if two points of the surface are in the same plane perpendicular to $L$ , then they're at the same distance from $L$ (the question Surfaces of revolution - Problem does not address this); I'm pretty sure I need to use the fact that $S$ is connected, and hence path connected (I'm pretty sure I can show it is in fact smoothly path connected, if needed), but I can't seem to use a path between two points to obtain the single curve I need. Given two points $p = (p_1, p_2, p_3), q = (q_1, q_2, q_3) \in S$ with $p_3 = q_3$ (still assuming $L$ is the $z$ -axis), I believe I want to show that $p_1^2 + p_2^2 = q_1^2 + q_2^2$ , or perhaps find a way to write $p_1^2 + p_2^2$ as a function of $p_3$ . I've tried using the fact that there are functions $s: S \to \mathbb R - \{0\}, z: S \to \mathbb R$ such that $p + s(p) N(p) = (0, 0, z(p))$ and manipulating this equation to do the latter, and I've tried introducing a path (or curve, if needed) $\beta: [0, 1] \to S$ from $p$ to $q$ and using the fact that $\beta'(t) \in T_{\beta(t)}S$ to do the former, but haven't found anything that I can tell is useful. Another thing I've thought to try after the discussion in the comments is to show that if there are points $p = (p_1, p_2, p_3), q = (q_1, q_2, q_3) \in S$ with $p_3 = q_3$ at different distances from the $z$ -axis, then there is a point $\beta(t)$ on the curve from $p$ to $q$ (which would need to be regular, which I think I could guarantee by taking a piecewise-regular path and rounding off the corners in a neighbourhood thereof) with $\beta'(t)$ horizontal such that $T_{\beta(t)}S$ is horizontal, but I don't really see how to show this. By the first part of the proof, I know that one basis vector in $T_{\beta(t)}S$ is the tangent vector to the horizontal circle through $\beta(t)$ , and presumably I need to somehow use the fact that $p, q$ are at different distances from the $z$ -axis to show that $\beta'(t)$ is linearly independent of that vector, but I don't see how.","I'm stuck on Exercise 3.70 from Kristopher Tapp's Differential Topology of Curves and Surfaces : Let be a connected oriented regular surface. Suppose there exists a line that intersects all normal lines to (that is, for every , the trace of the normal line intersects ). Prove that is a portion of a surface of revolution. I was able to show that every point has a neighbourhood in whose intersection with the plane perpendicular to through is a circle with centre on (with the help of part (i) in this question: How to solve this questions about regular surfaces? ): Note that we further require not to intersect . First, suppose is the -axis and let . Then for some and some , so . Note that , so . Thus, either or , and so by Exercise 3.48, there is a neighbourhood of in that is the graph of a smooth function of one of the following forms: , or , respectively. Define the curve by or , respectively. Then or , and . Conversely, if , then or , and so . We claim is a portion of the circle centred at through . For each , let denote the projection of onto . Then and for all . Thus, and so is constant. What I'm having trouble showing is that there's a single curve whose surface of revolution about the line contains , i.e. that if two points of the surface are in the same plane perpendicular to , then they're at the same distance from (the question Surfaces of revolution - Problem does not address this); I'm pretty sure I need to use the fact that is connected, and hence path connected (I'm pretty sure I can show it is in fact smoothly path connected, if needed), but I can't seem to use a path between two points to obtain the single curve I need. Given two points with (still assuming is the -axis), I believe I want to show that , or perhaps find a way to write as a function of . I've tried using the fact that there are functions such that and manipulating this equation to do the latter, and I've tried introducing a path (or curve, if needed) from to and using the fact that to do the former, but haven't found anything that I can tell is useful. Another thing I've thought to try after the discussion in the comments is to show that if there are points with at different distances from the -axis, then there is a point on the curve from to (which would need to be regular, which I think I could guarantee by taking a piecewise-regular path and rounding off the corners in a neighbourhood thereof) with horizontal such that is horizontal, but I don't really see how to show this. By the first part of the proof, I know that one basis vector in is the tangent vector to the horizontal circle through , and presumably I need to somehow use the fact that are at different distances from the -axis to show that is linearly independent of that vector, but I don't see how.","S L \subset \mathbb R^3 S p \in S t \mapsto p + t N(p) L S p \in S S L p L L S L z p = (p_1, p_2, p_3) \in S p + s N(p) = (0, 0, z) s \in \mathbb R - \{0\} z \in \mathbb R N(p) = (-p_1 / s, -p_2 / s, (z - p_3) / s) \langle(-p_1 / s, -p_2 / s, 0), N(p)\rangle = (p_1^2 + p_2^2) / s^2 \neq 0 (-p_1 / s, -p_2 / s, 0) \notin T_pS e_1 \notin T_pS e_2 \notin T_pS V p S x = f(y, z) y = f(x, z) \gamma: I \to V \gamma(t) = (f(t, p_3), t, p_3) \gamma(t) = (t, f(t, p_3), p_3) \gamma'(t) = (df_{(t, p_3)}(1, 0), 1, 0) \neq 0 \gamma'(t) = (1, df_{(t, p_3)}(1, 0), 0) \neq 0 \gamma(I) \subset p + \operatorname{span}\{e_1, e_2\} (x, y, p_3) \in V x = f(y, p_3) y = f(x, p_3) V \cap (p + \operatorname{span}\{e_1, e_2\}) \subset \gamma(I) \gamma (0, 0, p_3) p t \in I \mathfrak n(t) N(\gamma(t)) \operatorname{span}\{e_1, e_2\} \langle\mathfrak n(t), \gamma'(t)\rangle = \langle N(\gamma(t)), \gamma'(t)\rangle - \langle N(\gamma(t)), e_3\rangle \langle e_3, \gamma'(t)\rangle = 0 \gamma(t) - (0, 0, p_3) = -\frac{\lvert\gamma(t) - (0, 0, p_3)\rvert}{\lvert\mathfrak n(t)\rvert} \mathfrak n(t) t \in I \frac{d}{dt}\langle\gamma(t) - (0, 0, p_3), \gamma(t) - (0, 0, p_3)\rangle = -\frac{2 \lvert\gamma(t) - (0, 0, p_3)\rvert}{\lvert\mathfrak n(t)\rvert} \langle\gamma'(t), \mathfrak n(t)\rangle = 0, \lvert\gamma(t) - (0, 0, p_3)\rvert L S L L S p = (p_1, p_2, p_3), q = (q_1, q_2, q_3) \in S p_3 = q_3 L z p_1^2 + p_2^2 = q_1^2 + q_2^2 p_1^2 + p_2^2 p_3 s: S \to \mathbb R - \{0\}, z: S \to \mathbb R p + s(p) N(p) = (0, 0, z(p)) \beta: [0, 1] \to S p q \beta'(t) \in T_{\beta(t)}S p = (p_1, p_2, p_3), q = (q_1, q_2, q_3) \in S p_3 = q_3 z \beta(t) p q \beta'(t) T_{\beta(t)}S T_{\beta(t)}S \beta(t) p, q z \beta'(t)","['differential-geometry', 'surfaces']"
74,"If a curve $\alpha$ is contained in a submanifold $P$ of $M$, $\alpha'(t)\in T_{\alpha(t)}P$?","If a curve  is contained in a submanifold  of , ?",\alpha P M \alpha'(t)\in T_{\alpha(t)}P,"Let $P\subset M$ be a smooth regular submanifold of $M$ , and $\alpha:(0,1)\to M$ be a smooth curve such that $\alpha(a,b)\subset P$ . I want to see whether or not $\alpha'(t)\in T_{\alpha(t)}P$ for any $t\in(0,1)$ (as well as for $P$ a  submanifold that doesn't have to be regular). In my notes, I have that, taking $p\in P$ , $T_pP$ is identified with the image in $T_pM$ through $(di)_p:T_pP\to T_pM$ , where $i:P\hookrightarrow M$ is the inclusion. Proposition 3.9 from Lee's Smooth Manifolds tells us that $(di)_p$ is an isomorphism. But I don't really understand this characterization of $T_pP$ well, or if I can do anything at all in this problem. I know that, taking $\left\{\left(\frac{\partial}{\partial x_i}\right)_p\right\}_{i=1}^n$ a base of $T_pM$ associated to the chart $(U,\varphi = (x_1,\ldots,x_n))$ , one can represent the velocity of the curve as \begin{equation} \alpha'(t_0) = \sum_{i=1}^n(x_i\circ\alpha)'(t_0)\left(\frac{\partial}{\partial x_i}\right)_p. \end{equation} But I don't know how to represent $T_pP$ out of the information above. And I don't see if anything would change between $P$ being regular or not. Could anyone please help me out?","Let be a smooth regular submanifold of , and be a smooth curve such that . I want to see whether or not for any (as well as for a  submanifold that doesn't have to be regular). In my notes, I have that, taking , is identified with the image in through , where is the inclusion. Proposition 3.9 from Lee's Smooth Manifolds tells us that is an isomorphism. But I don't really understand this characterization of well, or if I can do anything at all in this problem. I know that, taking a base of associated to the chart , one can represent the velocity of the curve as But I don't know how to represent out of the information above. And I don't see if anything would change between being regular or not. Could anyone please help me out?","P\subset M M \alpha:(0,1)\to M \alpha(a,b)\subset P \alpha'(t)\in T_{\alpha(t)}P t\in(0,1) P p\in P T_pP T_pM (di)_p:T_pP\to T_pM i:P\hookrightarrow M (di)_p T_pP \left\{\left(\frac{\partial}{\partial x_i}\right)_p\right\}_{i=1}^n T_pM (U,\varphi = (x_1,\ldots,x_n)) \begin{equation}
\alpha'(t_0) = \sum_{i=1}^n(x_i\circ\alpha)'(t_0)\left(\frac{\partial}{\partial x_i}\right)_p.
\end{equation} T_pP P","['differential-geometry', 'smooth-manifolds', 'curves', 'submanifold']"
75,How to efficiently compute this Pffafian of curvature form,How to efficiently compute this Pffafian of curvature form,,"Though one can verify this $$Pf(\Omega) = \frac{1}{8}(\vert \text{Rm} \vert^2 - 4 \vert \text{Ric}\vert^2 + R^2)$$ for a 4-dim manifold by listing out all the curvature components mechanically (I have to ask my computer to do so), is there a clever way to compute this quantity? Thanks","Though one can verify this for a 4-dim manifold by listing out all the curvature components mechanically (I have to ask my computer to do so), is there a clever way to compute this quantity? Thanks",Pf(\Omega) = \frac{1}{8}(\vert \text{Rm} \vert^2 - 4 \vert \text{Ric}\vert^2 + R^2),['differential-geometry']
76,An explicit relation betwen Riemannian metric and an associated Hermitian metric?,An explicit relation betwen Riemannian metric and an associated Hermitian metric?,,"I am trying to explicitly find the relationship between a Hermitian metric on a complex manifold and the Riemannian metric on the underlying real manifold -- and specifically on how the determinants of both are related. Sorry for the length of what follows. Consider a metric on a (patch of) an even dimensional real manifold $\mathcal{M}$ of dimension $2n$ , where the Riemannian metric is represented as the $(0,2)$ tensor $G_{MN}$ , with $M, N = 1, \dots, 2n$ , and coordinates labelled $X^M$ . Letting $\mu, \nu = 1, \dots, n$ , with \begin{eqnarray} \label{eq:G-def} G_{MN} =  \begin{pmatrix} g_{\mu\nu}^{(1)} & \vert & g_{\mu\nu}^{(2)} \\ \hline g_{\mu\nu}^{(3)} & \vert & g_{\mu\nu}^{(4)}  \end{pmatrix} \end{eqnarray} $g_{\mu \nu}^{(2)} = g_{\nu \mu}^{(3)}$ , $g_{\mu \nu}^{(1)} = g_{\nu \mu}^{(1)}$ , $g_{\mu \nu}^{(4)} = g_{\nu \mu}^{(4)}$ . Let $X^M = (x^{\mu}, y^{\nu})$ , giving us bases $\{\dfrac{\partial}{\partial x^{\mu}}, \dfrac{\partial}{\partial y^{\nu}} \}$ for $T_p\mathcal{M}$ , $\{ dx^{\mu}, dy^{\nu}\}$ for $T_p^*\mathcal{M}$ , and suppose that $\mathcal{M}$ has an integrable almost complex structure $J$ . Let $z^{\mu} = x^{\mu} + i y^{\mu}$ , $\bar{z}^{\mu} = x^{\mu} - i y^{\mu}$ , and with the $dz^{\mu}$ , $d\bar{z}^{\mu}$ , $\frac{\partial}{\partial z^{\mu}}$ , $\frac{\partial}{\partial \bar{z}^{\mu}}$ defined as above. \begin{eqnarray} \label{metric-complexified} ds^2 &=& G_{MN} dX^M \otimes dX^N \\ % &=& g_{\mu \nu}^{(1)} dx^{\mu} \otimes dx^{\nu} + g_{\mu \nu}^{(2)} dx^{\mu} \otimes dy^{\nu} + g_{\mu \nu}^{(3)} dy^{\mu} \otimes dx^{\nu} + g_{\mu \nu}^{(4)} dy^{\mu} \otimes dy^{\nu} % \\ % &=&  \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} - ig_{\mu \nu}^{(2)} - ig_{\mu \nu}^{(3)} - g_{\mu \nu}^{(4)}\right)(dz^{\mu} \otimes dz^{\nu}) +   \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} + ig_{\mu \nu}^{(2)} + ig_{\mu \nu}^{(3)} - g_{\mu \nu}^{(4)}\right)(d\bar{z}^{\mu} \otimes d\bar{z}^{\nu}) \\ && +  \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} + ig_{\mu \nu}^{(2)} - ig_{\mu \nu}^{(3)} + g_{\mu \nu}^{(4)}\right)(dz^{\mu} \otimes d\bar{z}^{\nu}) +  \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} - ig_{\mu \nu}^{(2)} + ig_{\mu \nu}^{(3)} + g_{\mu \nu}^{(4)}\right)(d\bar{z}^{\mu} \otimes dz^{\nu})  \\ % &=& g_{\mu \nu}(dz^{\mu} \otimes dz^{\nu}) + g_{\bar{\mu} \bar{\nu}}(d\bar{z}^{\mu} \otimes d\bar{z}^{\nu})+ g_{\mu \bar{\nu}}(dz^{\mu} \otimes d\bar{z}^{\nu})  + g_{\bar{\mu} \nu}(d\bar{z}^{\mu} \otimes dz^{\nu}) \end{eqnarray} (I suppose this can be described as the $\mathbb{C}$ -extension of the original metric.) A Riemannian metric $g$ is Hermitian if for any $X,Y \in T_p\mathcal{M}$ , $p\in \mathcal{M}$ , we have $g(J(X),J(Y)) = g(X, Y) $ . We assume that the almost complex structure acts as $J\left(\frac{\partial}{\partial x^{\mu}}\right) = \frac{\partial}{\partial y^{\mu}}$ , $J\left( \frac{\partial}{\partial y^{\mu}}\right) = -\frac{\partial}{\partial x^{\mu}}$ , so that $ J\left(\dfrac{\partial }{\partial z^{\mu}} \right) = i \dfrac{\partial}{\partial z^{\mu}} \,,\quad J\left(\dfrac{\partial}{\partial \bar{z}^{\mu}}\right) = -i \dfrac{\partial}{\partial \bar{z}^{\mu}} $ The above condition then forces $g_{\mu \nu} = g_{\bar{\mu}\bar{\nu}} = 0$ . Looking at the metric expansion, we see that this means $g_{\mu \nu}^{(1)} = g_{\mu \nu}^{(4)}$ , while $g_{\mu \nu}^{(2)} = - g_{\mu \nu}^{(3)}$ , in this basis. Using these results, we find that \begin{eqnarray} G_{MN} \, dX^M \otimes dX^N &=& \frac{1}{4}\left(g_{\mu \nu}^{(1)} + g_{\mu \nu}^{(4)} + i\left(g_{\mu \nu}^{(2)} - g_{\mu \nu}^{(3)} \right)\right) dz^{\mu} \otimes d\bar{z}^{\nu} \\ && + \frac{1}{4}\left(g_{\mu \nu}^{(1)} + g_{\mu \nu}^{(4)} - i\left(g_{\mu \nu}^{(2)} - g_{\mu \nu}^{(3)} \right)\right) d\bar{z}^{\mu} \otimes dz^{\nu} % \\ % &=& \frac{1}{2}\left(g_{\mu \nu}^{(1)} + ig_{\mu \nu}^{(2)}\right) dz^{\mu} \otimes d\bar{z}^{\nu} + \frac{1}{2}\left(g_{\mu \nu}^{(1)} - ig_{\mu \nu}^{(2)}\right) d\bar{z}^{\mu} \otimes dz^{\nu} % \\ % &=& \frac{1}{2} \left( h_{\mu \bar{\nu}}\, dz^{\mu} \otimes d\bar{z}^{\nu} + h_{\bar{\nu} \mu} \, d\bar{z}^{\nu} \otimes dz^{\mu} \right) \end{eqnarray} Where we call $h_{\mu \bar{\nu}} = \overline{h_{\bar{\nu}\mu}}$ the Hermitian metric on $\mathcal{M}$ . QUESTION Is the above relationship between $h_{\mu \bar{\nu}}$ and $G_{MN}$ correct, and why is it that $\det(G_{MN}) = (\det(h_{\mu \bar{\nu}}))^2$ ? Here is an attempt at an answer. Let $A$ , $B$ , $C$ , $D$ be $n \times n$ matrices. Then if $C$ , $D$ commute , we have the identity \begin{equation} \label{det:identity} \det \begin{pmatrix}     A & B \\     C & D \end{pmatrix} = \det(AD - BC) \end{equation} Using the decomposition of $G_{MN}$ , we find that \begin{eqnarray} \label{det-G} \det\left(G_{MN}\right) &=& \det\left(g_{\mu\nu}^{(1)}g_{\nu\lambda}^{(4)} - g_{\mu\nu}^{2}g_{\nu\lambda}^{3}\right) = \det\left( \left(g_{\mu\nu}^{(1)}\right)^2 + \left(g_{\mu\nu}^{(2)}\right)^2\right) \\ &=& \det\left( g_{\mu\nu}^{(1)} + i g_{\mu\nu}^{(2)}\right) \det\left( g_{\mu\nu}^{(1)} - i g_{\mu\nu}^{(2)}\right) \end{eqnarray} The second equality above comes from the identifications due to hermitian condition described above. The RHS of the last equation is $\det\left(h_{\mu\bar{\nu}}\right) \det\left(h_{\bar{\nu}\mu}\right)$ and we have seen that $h_{\bar{\nu}\mu}=\overline{h_{\mu \bar{\nu}}}$ . So we find that $$ \det\left(G_{MN}\right) = \left|\det\left(h_{\mu\bar{\nu}}\right)\right|^2 $$ or $\det\left(h_{\mu \bar{\nu}}\right) = \sqrt{\det\left(G_{MN}\right)}$ if $h_{\mu \bar{\nu}}$ is real. Problems: $g^{(2)}$ , $g^{(3)}$ do not necessarily commute. But perhaps it is true that these components are somehow required to vanish -- maybe due to the requirement that $\{ \frac{\partial}{\partial x^{\mu}}, \frac{\partial}{\partial y^{\nu}} \}$ form an /orthonormal basis/ -- so that $h_{\mu \bar{\nu}} = g_{\mu \nu}^{(1)}$ .","I am trying to explicitly find the relationship between a Hermitian metric on a complex manifold and the Riemannian metric on the underlying real manifold -- and specifically on how the determinants of both are related. Sorry for the length of what follows. Consider a metric on a (patch of) an even dimensional real manifold of dimension , where the Riemannian metric is represented as the tensor , with , and coordinates labelled . Letting , with , , . Let , giving us bases for , for , and suppose that has an integrable almost complex structure . Let , , and with the , , , defined as above. (I suppose this can be described as the -extension of the original metric.) A Riemannian metric is Hermitian if for any , , we have . We assume that the almost complex structure acts as , , so that The above condition then forces . Looking at the metric expansion, we see that this means , while , in this basis. Using these results, we find that Where we call the Hermitian metric on . QUESTION Is the above relationship between and correct, and why is it that ? Here is an attempt at an answer. Let , , , be matrices. Then if , commute , we have the identity Using the decomposition of , we find that The second equality above comes from the identifications due to hermitian condition described above. The RHS of the last equation is and we have seen that . So we find that or if is real. Problems: , do not necessarily commute. But perhaps it is true that these components are somehow required to vanish -- maybe due to the requirement that form an /orthonormal basis/ -- so that .","\mathcal{M} 2n (0,2) G_{MN} M, N = 1, \dots, 2n X^M \mu, \nu = 1, \dots, n \begin{eqnarray}
\label{eq:G-def}
G_{MN} = 
\begin{pmatrix}
g_{\mu\nu}^{(1)} & \vert & g_{\mu\nu}^{(2)} \\
\hline
g_{\mu\nu}^{(3)} & \vert & g_{\mu\nu}^{(4)} 
\end{pmatrix}
\end{eqnarray} g_{\mu \nu}^{(2)} = g_{\nu \mu}^{(3)} g_{\mu \nu}^{(1)} = g_{\nu \mu}^{(1)} g_{\mu \nu}^{(4)} = g_{\nu \mu}^{(4)} X^M = (x^{\mu}, y^{\nu}) \{\dfrac{\partial}{\partial x^{\mu}}, \dfrac{\partial}{\partial y^{\nu}} \} T_p\mathcal{M} \{ dx^{\mu}, dy^{\nu}\} T_p^*\mathcal{M} \mathcal{M} J z^{\mu} = x^{\mu} + i y^{\mu} \bar{z}^{\mu} = x^{\mu} - i y^{\mu} dz^{\mu} d\bar{z}^{\mu} \frac{\partial}{\partial z^{\mu}} \frac{\partial}{\partial \bar{z}^{\mu}} \begin{eqnarray}
\label{metric-complexified}
ds^2 &=& G_{MN} dX^M \otimes dX^N
\\
%
&=& g_{\mu \nu}^{(1)} dx^{\mu} \otimes dx^{\nu} + g_{\mu \nu}^{(2)} dx^{\mu} \otimes dy^{\nu}
+ g_{\mu \nu}^{(3)} dy^{\mu} \otimes dx^{\nu} + g_{\mu \nu}^{(4)} dy^{\mu} \otimes dy^{\nu}
%
\\
%
&=&
 \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} - ig_{\mu \nu}^{(2)} - ig_{\mu \nu}^{(3)} - g_{\mu \nu}^{(4)}\right)(dz^{\mu} \otimes dz^{\nu})
+ 
 \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} + ig_{\mu \nu}^{(2)} + ig_{\mu \nu}^{(3)} - g_{\mu \nu}^{(4)}\right)(d\bar{z}^{\mu} \otimes d\bar{z}^{\nu})
\\
&&
+
 \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} + ig_{\mu \nu}^{(2)} - ig_{\mu \nu}^{(3)} + g_{\mu \nu}^{(4)}\right)(dz^{\mu} \otimes d\bar{z}^{\nu})
+
 \dfrac{1}{4}\left(g_{\mu \nu}^{(1)} - ig_{\mu \nu}^{(2)} + ig_{\mu \nu}^{(3)} + g_{\mu \nu}^{(4)}\right)(d\bar{z}^{\mu} \otimes dz^{\nu})
 \\
%
&=&
g_{\mu \nu}(dz^{\mu} \otimes dz^{\nu}) + g_{\bar{\mu} \bar{\nu}}(d\bar{z}^{\mu} \otimes d\bar{z}^{\nu})+ g_{\mu \bar{\nu}}(dz^{\mu} \otimes d\bar{z}^{\nu})
 + g_{\bar{\mu} \nu}(d\bar{z}^{\mu} \otimes dz^{\nu})
\end{eqnarray} \mathbb{C} g X,Y \in T_p\mathcal{M} p\in \mathcal{M} g(J(X),J(Y)) = g(X, Y)  J\left(\frac{\partial}{\partial x^{\mu}}\right) = \frac{\partial}{\partial y^{\mu}} J\left( \frac{\partial}{\partial y^{\mu}}\right) = -\frac{\partial}{\partial x^{\mu}} 
J\left(\dfrac{\partial }{\partial z^{\mu}} \right) = i \dfrac{\partial}{\partial z^{\mu}} \,,\quad
J\left(\dfrac{\partial}{\partial \bar{z}^{\mu}}\right) = -i \dfrac{\partial}{\partial \bar{z}^{\mu}}
 g_{\mu \nu} = g_{\bar{\mu}\bar{\nu}} = 0 g_{\mu \nu}^{(1)} = g_{\mu \nu}^{(4)} g_{\mu \nu}^{(2)} = - g_{\mu \nu}^{(3)} \begin{eqnarray}
G_{MN} \, dX^M \otimes dX^N
&=&
\frac{1}{4}\left(g_{\mu \nu}^{(1)} + g_{\mu \nu}^{(4)} + i\left(g_{\mu \nu}^{(2)} - g_{\mu \nu}^{(3)} \right)\right) dz^{\mu} \otimes d\bar{z}^{\nu}
\\
&&
+
\frac{1}{4}\left(g_{\mu \nu}^{(1)} + g_{\mu \nu}^{(4)} - i\left(g_{\mu \nu}^{(2)} - g_{\mu \nu}^{(3)} \right)\right)
d\bar{z}^{\mu} \otimes dz^{\nu}
%
\\
%
&=& \frac{1}{2}\left(g_{\mu \nu}^{(1)} + ig_{\mu \nu}^{(2)}\right) dz^{\mu} \otimes d\bar{z}^{\nu}
+ \frac{1}{2}\left(g_{\mu \nu}^{(1)} - ig_{\mu \nu}^{(2)}\right) d\bar{z}^{\mu} \otimes dz^{\nu}
%
\\
%
&=& \frac{1}{2} \left( h_{\mu \bar{\nu}}\, dz^{\mu} \otimes d\bar{z}^{\nu} + h_{\bar{\nu} \mu} \, d\bar{z}^{\nu} \otimes dz^{\mu} \right)
\end{eqnarray} h_{\mu \bar{\nu}} = \overline{h_{\bar{\nu}\mu}} \mathcal{M} h_{\mu \bar{\nu}} G_{MN} \det(G_{MN}) = (\det(h_{\mu \bar{\nu}}))^2 A B C D n \times n C D \begin{equation}
\label{det:identity}
\det
\begin{pmatrix}
    A & B \\
    C & D
\end{pmatrix}
= \det(AD - BC)
\end{equation} G_{MN} \begin{eqnarray}
\label{det-G}
\det\left(G_{MN}\right)
&=& \det\left(g_{\mu\nu}^{(1)}g_{\nu\lambda}^{(4)} - g_{\mu\nu}^{2}g_{\nu\lambda}^{3}\right)
= \det\left( \left(g_{\mu\nu}^{(1)}\right)^2 + \left(g_{\mu\nu}^{(2)}\right)^2\right)
\\
&=& \det\left( g_{\mu\nu}^{(1)} + i g_{\mu\nu}^{(2)}\right) \det\left( g_{\mu\nu}^{(1)} - i g_{\mu\nu}^{(2)}\right)
\end{eqnarray} \det\left(h_{\mu\bar{\nu}}\right) \det\left(h_{\bar{\nu}\mu}\right) h_{\bar{\nu}\mu}=\overline{h_{\mu \bar{\nu}}}  \det\left(G_{MN}\right) = \left|\det\left(h_{\mu\bar{\nu}}\right)\right|^2  \det\left(h_{\mu \bar{\nu}}\right) = \sqrt{\det\left(G_{MN}\right)} h_{\mu \bar{\nu}} g^{(2)} g^{(3)} \{ \frac{\partial}{\partial x^{\mu}}, \frac{\partial}{\partial y^{\nu}} \} h_{\mu \bar{\nu}} = g_{\mu \nu}^{(1)}","['differential-geometry', 'complex-geometry', 'kahler-manifolds', 'almost-complex']"
77,I'm having a problem with parallel transport which suggests the dimensionality is incorrect,I'm having a problem with parallel transport which suggests the dimensionality is incorrect,,"I'm working in spherical coordinates and I want to transport a vector for a radial velocity over an interval with $dr\ne 0$ but all other increments zero. The formula I have found for parallel transport is $$v_{r + dr}^\mu  \approx v_r^\mu  - \Gamma _{\nu \alpha }^\mu v_r^\nu d{x^\alpha }$$ I understand the four vector has elements $\gamma(c, u, 0, 0)$ where $u$ is my radial velocity. Looking at the equation for $v_{r+dr}^1$ I get $$v_{r + dr}^1 \approx v_r^1 - \Gamma _{01}^1v_r^0d{x^1} - \Gamma _{11}^1v_r^1d{x^1}$$ where, clearly, $dx^1=dr$ (and no other Christoffel symbols apply because other $v^\nu$ are zero). Here's my problem. Terms $v_r^0dx^1$ and $v_r^1dx^1$ have the same dimensionality but the two Christoffel symbols do not. What have I misunderstood? (Dimensionality of $\Gamma _{01}^1$ is $T^{-1}$ but of $ \Gamma _{11}^1$ is $L^{-1}$ )","I'm working in spherical coordinates and I want to transport a vector for a radial velocity over an interval with but all other increments zero. The formula I have found for parallel transport is I understand the four vector has elements where is my radial velocity. Looking at the equation for I get where, clearly, (and no other Christoffel symbols apply because other are zero). Here's my problem. Terms and have the same dimensionality but the two Christoffel symbols do not. What have I misunderstood? (Dimensionality of is but of is )","dr\ne 0 v_{r + dr}^\mu  \approx v_r^\mu  - \Gamma _{\nu \alpha }^\mu v_r^\nu d{x^\alpha } \gamma(c, u, 0, 0) u v_{r+dr}^1 v_{r + dr}^1 \approx v_r^1 - \Gamma _{01}^1v_r^0d{x^1} - \Gamma _{11}^1v_r^1d{x^1} dx^1=dr v^\nu v_r^0dx^1 v_r^1dx^1 \Gamma _{01}^1 T^{-1}  \Gamma _{11}^1 L^{-1}",['differential-geometry']
78,How to calculate sectional curvature?,How to calculate sectional curvature?,,"I'm some new here, sorry if my question is not correct. I need to calculate the sectional curvature of a Riemannian manifold. I found this formula in several books. $$K(\sigma,p)=\frac{R(X,Y,Y,X)}{g(X,X)g(Y,Y)-g(X,Y)}$$ My problem is that none of them do the detailed accounts, and it frustrates me because most that I have been able to read have a different notation. I am quite confused, I would like to know if anyone knows any book where I can find some text that makes a summary of the formulas (from defining the metric, Christoffel symbols , Riemannian tensor, etc.) and applies them in an example to understand. And if someone would be so kind to do it here, I would be very grateful, it does not matter if it is a simple example such as the sphere or hyperbolic space or a surface of revolution I don't know... I just want to see the technique to be able to understand and apply it.","I'm some new here, sorry if my question is not correct. I need to calculate the sectional curvature of a Riemannian manifold. I found this formula in several books. My problem is that none of them do the detailed accounts, and it frustrates me because most that I have been able to read have a different notation. I am quite confused, I would like to know if anyone knows any book where I can find some text that makes a summary of the formulas (from defining the metric, Christoffel symbols , Riemannian tensor, etc.) and applies them in an example to understand. And if someone would be so kind to do it here, I would be very grateful, it does not matter if it is a simple example such as the sphere or hyperbolic space or a surface of revolution I don't know... I just want to see the technique to be able to understand and apply it.","K(\sigma,p)=\frac{R(X,Y,Y,X)}{g(X,X)g(Y,Y)-g(X,Y)}","['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
79,Some questions about Twistor Space of a closed $4$-manifold,Some questions about Twistor Space of a closed -manifold,4,"Let $(M,g)$ be a closed Riemannian manifold of dimension $4$ . We denote its twistor space, the space of almost complex structures on the tangent bundle $TM$ by $Z\xrightarrow{\pi}M$ . At any point the fibre is isomorphic to $S^2$ . Now this can be seen as $S(\Lambda_+^2M),$ i.e., the sphere bundle of the self-dual two forms on $M$ . Self dual means $*\omega=\omega$ . $1.$ I want to know how this description works; i.e., given a self dual two form at a point $m\in M,$ how do we get an almost complex structure on $T_m M?$ $2.$ Is it possible to induce a metric on $Z$ from $M$ , if yes how? $3.$ Once we put a metric on $Z$ and take the corresponding Levi-Civita connection we get a splitting of the tangent bundle in terms of horizontal and vertical vectors: \begin{equation*} TZ=TV\oplus TH\cong TV\oplus \pi^*(TM) \end{equation*} Does this give a reduction of the structure group $SO(6)$ to $SO(4)\times SO(2)?$","Let be a closed Riemannian manifold of dimension . We denote its twistor space, the space of almost complex structures on the tangent bundle by . At any point the fibre is isomorphic to . Now this can be seen as i.e., the sphere bundle of the self-dual two forms on . Self dual means . I want to know how this description works; i.e., given a self dual two form at a point how do we get an almost complex structure on Is it possible to induce a metric on from , if yes how? Once we put a metric on and take the corresponding Levi-Civita connection we get a splitting of the tangent bundle in terms of horizontal and vertical vectors: Does this give a reduction of the structure group to","(M,g) 4 TM Z\xrightarrow{\pi}M S^2 S(\Lambda_+^2M), M *\omega=\omega 1. m\in M, T_m M? 2. Z M 3. Z \begin{equation*}
TZ=TV\oplus TH\cong TV\oplus \pi^*(TM)
\end{equation*} SO(6) SO(4)\times SO(2)?","['differential-geometry', 'riemannian-geometry', 'connections', '4-manifolds', 'twistor-theory']"
80,Computation of Lie Derivative using Cartan's Magic Formula,Computation of Lie Derivative using Cartan's Magic Formula,,"In section 2.6 of the notes by Natario, he uses Cartan's magic formula $$\mathcal{L}_V\omega = i_V(d\omega) + d(i_V\omega)$$ to compute the second fundamental form of timelike hypersurface $\sigma = \sigma_0$ in $$g_1 = -d\tau^2 + a^2(\tau) \big[ d\sigma^2 +\sigma^2(d\theta^2 + \sin^2\theta d\varphi^2) \big]$$ This surface has unit normal $\frac{1}{a}\frac{\partial}{\partial \sigma}$ . I am confused however about how to compute $\mathcal{L}_n(a^2(\tau)d\sigma^2)$ term because it seems to give $-\dot{a}\ d\tau d\sigma$ , but this term does not appear in claimed second fundamental form $K = a(\tau)\sigma_0 (d\theta^2 + \sin^2\theta d\varphi^2)$ . I am sure I have done something foolish, and would be very grateful to be pointed in the right direction! $\frac{1}{2}\mathcal{L}_n (a^2 d\sigma^2) = a(\mathcal{L}_na)d\sigma^2 + a^2 (\mathcal{L}_nd\sigma)d\sigma\\ 	= a^2 d(d\sigma(n))d\sigma\\  	= a^2 d( \frac{1}{a(\tau)})d\sigma\\$","In section 2.6 of the notes by Natario, he uses Cartan's magic formula to compute the second fundamental form of timelike hypersurface in This surface has unit normal . I am confused however about how to compute term because it seems to give , but this term does not appear in claimed second fundamental form . I am sure I have done something foolish, and would be very grateful to be pointed in the right direction!","\mathcal{L}_V\omega = i_V(d\omega) + d(i_V\omega) \sigma = \sigma_0 g_1 = -d\tau^2 + a^2(\tau) \big[ d\sigma^2 +\sigma^2(d\theta^2 + \sin^2\theta d\varphi^2) \big] \frac{1}{a}\frac{\partial}{\partial \sigma} \mathcal{L}_n(a^2(\tau)d\sigma^2) -\dot{a}\ d\tau d\sigma K = a(\tau)\sigma_0 (d\theta^2 + \sin^2\theta d\varphi^2) \frac{1}{2}\mathcal{L}_n (a^2 d\sigma^2) = a(\mathcal{L}_na)d\sigma^2 + a^2 (\mathcal{L}_nd\sigma)d\sigma\\
	= a^2 d(d\sigma(n))d\sigma\\ 
	= a^2 d( \frac{1}{a(\tau)})d\sigma\\","['differential-geometry', 'general-relativity', 'semi-riemannian-geometry']"
81,$L^p$ spaces of tangent sections: reference request,spaces of tangent sections: reference request,L^p,"What sorts of books would address $L^p$ spaces of sections of the tangent space of a Riemannian manifold ( $C^\infty$ , compact, ideally with boundary)? In particular, I'd like to show that smooth sections are dense in the set of $L^2$ -measurable or $L^\infty$ sections, in the $L^2$ norm or $L^\infty$ norm. I could do this using local orthonormal frames and a partition of unity argument, but I'd prefer a reference which does this directly.","What sorts of books would address spaces of sections of the tangent space of a Riemannian manifold ( , compact, ideally with boundary)? In particular, I'd like to show that smooth sections are dense in the set of -measurable or sections, in the norm or norm. I could do this using local orthonormal frames and a partition of unity argument, but I'd prefer a reference which does this directly.",L^p C^\infty L^2 L^\infty L^2 L^\infty,"['differential-geometry', 'reference-request', 'riemannian-geometry', 'lp-spaces']"
82,a regular curve with $\kappa(t)>0$ is helix if and only if $\frac{\kappa}{\tau}$ is constant,a regular curve with  is helix if and only if  is constant,\kappa(t)>0 \frac{\kappa}{\tau},"A curve is said to be helix if its tangent line have a constant angle with a fixed direction. i.e. $\langle T(t),u\rangle$ is constant for some unit vector $u$ . I am trying to prove: a regular curve with $\kappa(t)>0$ is helix if and only if $\frac{\kappa}{\tau}$ is constant. I can show the sufficient part竊 if $\alpha(t)$ is helix, then $\langle T'\!, u\rangle=0$ and therefore $\langle N,u\rangle=0$ , which implies $\langle-\kappa(t)T(t)+\tau(t)B(t), u\rangle=0$ . We then have $$ \frac{\kappa(t)}{\tau(t)}  = \frac{\langle T(t),u\rangle}{\langle B(t),u\rangle}, $$ which is constant, since $\langle T(t),u\rangle,\langle B(t),u\rangle$ are constant. But I have no idea in proving the reverse direction.","A curve is said to be helix if its tangent line have a constant angle with a fixed direction. i.e. is constant for some unit vector . I am trying to prove: a regular curve with is helix if and only if is constant. I can show the sufficient part竊 if is helix, then and therefore , which implies . We then have which is constant, since are constant. But I have no idea in proving the reverse direction.","\langle T(t),u\rangle u \kappa(t)>0 \frac{\kappa}{\tau} \alpha(t) \langle T'\!, u\rangle=0 \langle N,u\rangle=0 \langle-\kappa(t)T(t)+\tau(t)B(t), u\rangle=0 
\frac{\kappa(t)}{\tau(t)} 
= \frac{\langle T(t),u\rangle}{\langle B(t),u\rangle},
 \langle T(t),u\rangle,\langle B(t),u\rangle","['differential-geometry', 'curvature', 'frenet-frame']"
83,Possible reverse triangle inequality,Possible reverse triangle inequality,,"I'm looking at the convergence (when blowing up the metric) of the spectrum of a self-adjoint operator $P$ that acts on differential forms of a 3-dimensional closed manifold M. Let $\lambda$ be a complex (not real) number. I need to prove the following inequality $$\|(\lambda-P)\alpha\|_0^2\geq |Im(\lambda)|^2\|\alpha\|^2_0+\|P\alpha\|_0^2$$ with respect to the $L^2$ -norm. In some sense, the real part of $\lambda$ eats the double inner product, i.e. $$|Re(\lambda)|^2\|\alpha\|^2_0\geq 2(P_\epsilon\alpha,\lambda\alpha)_0.$$ Have you seen this happening somewhere else? Is there a general property of the spectrum of self-adjoint operators?","I'm looking at the convergence (when blowing up the metric) of the spectrum of a self-adjoint operator that acts on differential forms of a 3-dimensional closed manifold M. Let be a complex (not real) number. I need to prove the following inequality with respect to the -norm. In some sense, the real part of eats the double inner product, i.e. Have you seen this happening somewhere else? Is there a general property of the spectrum of self-adjoint operators?","P \lambda \|(\lambda-P)\alpha\|_0^2\geq |Im(\lambda)|^2\|\alpha\|^2_0+\|P\alpha\|_0^2 L^2 \lambda |Re(\lambda)|^2\|\alpha\|^2_0\geq 2(P_\epsilon\alpha,\lambda\alpha)_0.","['functional-analysis', 'differential-geometry', 'spectral-theory', 'geometric-functional-analysis']"
84,Structure of the space of holomorphic structure on a vector bundle,Structure of the space of holomorphic structure on a vector bundle,,"It is well known that the space of connections on a vector bundle $E\rightarrow X$ is an affine space modeled on $\Omega^1(X,End(E))$ . Let $Dol(E)$ denote the space of holomorphic structures $\bar{\partial}_E$ on $E$ . We easily see  from the Leibniz rule $$\bar{\partial}_E(fs)=\bar{\partial}f\cdot s + f\bar{\partial}_Es$$ that the difference between two holomorphic structures $\bar{\partial}^1_E-\bar{\partial}^2_E$ is a tensor that belongs to $\Omega^{0,1}(X,End(E))$ . Moreover, there is a flatness condition $$\bar{\partial}_E\circ \bar{\partial}_E=0$$ which implies that $Dol(E)$ is not affine. What can we say anyway on the tangent space of $Dol(E)$ as a subspace of $\Omega^{0,1}(X,End(E))$ ?","It is well known that the space of connections on a vector bundle is an affine space modeled on . Let denote the space of holomorphic structures on . We easily see  from the Leibniz rule that the difference between two holomorphic structures is a tensor that belongs to . Moreover, there is a flatness condition which implies that is not affine. What can we say anyway on the tangent space of as a subspace of ?","E\rightarrow X \Omega^1(X,End(E)) Dol(E) \bar{\partial}_E E \bar{\partial}_E(fs)=\bar{\partial}f\cdot s + f\bar{\partial}_Es \bar{\partial}^1_E-\bar{\partial}^2_E \Omega^{0,1}(X,End(E)) \bar{\partial}_E\circ \bar{\partial}_E=0 Dol(E) Dol(E) \Omega^{0,1}(X,End(E))","['differential-geometry', 'complex-geometry', 'vector-bundles', 'connections', 'holomorphic-bundles']"
85,"How do I evaluate the $(1,3)$-curvature tensor $R(X,Y)Z$ when $X,Y,Z$ are vector fields along a one-parameter family of curves?",How do I evaluate the -curvature tensor  when  are vector fields along a one-parameter family of curves?,"(1,3) R(X,Y)Z X,Y,Z","Let $(M,g)$ be a Riemannian or pseudo-Riemannian manifold and denote the space of smooth vector fields on $M$ by $\mathfrak{X}(M)$ . Following Lee's book on Riemannian manifolds, we define the $(1,3)$ -curvature tensor $R:\mathfrak{X}(M)\times\mathfrak{X}(M)\times\mathfrak{X}(M)\to\mathfrak{X}(M)$ by $$R(X,Y)Z=\nabla_X\nabla_Y Z-\nabla_Y\nabla_X Z-\nabla_{[X,Y]}Z.$$ The definition of $R$ is as simple as it appears, before we introduce vector fields along a one-parameter family of curves. Let $I,J$ be intervals in the real line. A one-parameter family of curves in $M$ is a map $\Gamma:J\times I\to M$ , since it defines two collections of curves in $M$ : the main curves $\Gamma_s(t):=\Gamma(s,t)$ and the transverse curves $\Gamma^{(t)}(s):=\Gamma(s,t)$ . If $\Gamma$ is smooth, we denote the velocity vectors of the main and transverse curves by $$\partial_t\Gamma(s_0,t_0)=\Gamma_{s_0}'(t_0)\text{ and }\partial_s\Gamma(s_0,t_0)=\Gamma^{(t_0)}\ '(s_0).$$ Each of these is an example of a vector field along $\Gamma$ , which is a map $V:J\times I\to TM$ such that $V(s,t)\in T_{\Gamma(s,t)}M$ for each $(s,t)\in J\times I$ . Now, there is a proposition that involves feeding $R$ with such vector fields. Proposition 7.5. Suppose $(M,g)$ is a smooth Riemannian or pseudo-Riemannian manifold and $\Gamma:J\times I\to M$ is a smooth one-parameter family of curves in $M$ . Then for every smooth vector field $V$ along $\Gamma$ , $$D_s D_t V-D_t D_s V=R(\partial_s\Gamma,\partial_t\Gamma)V.\tag{7.5}$$ I don't know what the RHS of (7.5) stands for: the input vector fields are not from $\mathfrak{X}(M)$ . What am I supposed to do with it? Thank you. Note: For those who deem this question to be a duplicate, I know $R$ is a tensor field. Actually, after giving the definition of $R$ , Lee showed in a proposition that $R$ is $C^\infty(M)$ -linear in each argument and is thus induced by a $(1,3)$ -tensor field. Epilogue: For those who are struggling with the same question, my advisor told me it could be an abuse of notation. The author might have been implicitly using the pullback bundle $\Gamma^*(TM)$ , a subtle agent that played an important role in the computation. The symbol $R$ here is actually the pullback of the original $(1,3)$ -curvature tensor. For more information, please see Pullback bundle - Wikipedia . Finally, I'd like thank all of the people who contributed an idea. Thank you.","Let be a Riemannian or pseudo-Riemannian manifold and denote the space of smooth vector fields on by . Following Lee's book on Riemannian manifolds, we define the -curvature tensor by The definition of is as simple as it appears, before we introduce vector fields along a one-parameter family of curves. Let be intervals in the real line. A one-parameter family of curves in is a map , since it defines two collections of curves in : the main curves and the transverse curves . If is smooth, we denote the velocity vectors of the main and transverse curves by Each of these is an example of a vector field along , which is a map such that for each . Now, there is a proposition that involves feeding with such vector fields. Proposition 7.5. Suppose is a smooth Riemannian or pseudo-Riemannian manifold and is a smooth one-parameter family of curves in . Then for every smooth vector field along , I don't know what the RHS of (7.5) stands for: the input vector fields are not from . What am I supposed to do with it? Thank you. Note: For those who deem this question to be a duplicate, I know is a tensor field. Actually, after giving the definition of , Lee showed in a proposition that is -linear in each argument and is thus induced by a -tensor field. Epilogue: For those who are struggling with the same question, my advisor told me it could be an abuse of notation. The author might have been implicitly using the pullback bundle , a subtle agent that played an important role in the computation. The symbol here is actually the pullback of the original -curvature tensor. For more information, please see Pullback bundle - Wikipedia . Finally, I'd like thank all of the people who contributed an idea. Thank you.","(M,g) M \mathfrak{X}(M) (1,3) R:\mathfrak{X}(M)\times\mathfrak{X}(M)\times\mathfrak{X}(M)\to\mathfrak{X}(M) R(X,Y)Z=\nabla_X\nabla_Y Z-\nabla_Y\nabla_X Z-\nabla_{[X,Y]}Z. R I,J M \Gamma:J\times I\to M M \Gamma_s(t):=\Gamma(s,t) \Gamma^{(t)}(s):=\Gamma(s,t) \Gamma \partial_t\Gamma(s_0,t_0)=\Gamma_{s_0}'(t_0)\text{ and }\partial_s\Gamma(s_0,t_0)=\Gamma^{(t_0)}\ '(s_0). \Gamma V:J\times I\to TM V(s,t)\in T_{\Gamma(s,t)}M (s,t)\in J\times I R (M,g) \Gamma:J\times I\to M M V \Gamma D_s D_t V-D_t D_s V=R(\partial_s\Gamma,\partial_t\Gamma)V.\tag{7.5} \mathfrak{X}(M) R R R C^\infty(M) (1,3) \Gamma^*(TM) R (1,3)","['differential-geometry', 'riemannian-geometry']"
86,Differential forms on $ \mathcal{M} = G횞_KM$.,Differential forms on ., \mathcal{M} = G횞_KM,"In page 40 of this article Equivariant cohomology with generalized coefficients ""  we find the following Let $G$ be a lie group and $K$ is a closed subgroup of it. Let $M$ be a $K$ -manifold. Consider the product manifold $G횞M$ . The group $K$ acts freely on the right on $G횞M$ by $(g,m)k= (gk, k^{-1}m)$ . Consider the fiber space $\mathcal{M} = G횞_KM$ (over $G/K$ ) of orbits of the K-action. The group $G$ acts on the left on $\mathcal{M}$ . If $\alpha \in \mathcal{A}(\mathcal{M}) \subset \mathcal{A}(G횞M)$ , and $g \in G$ , then $ \alpha (g)$ is an element of ${(\bigwedge \mathfrak{g}^* \otimes \mathcal{A}(M) }_{hor K} $ , where $\mathfrak{g}^*$ is identified with left invariant 1-forms on $G$ . Thus $$ \mathcal{A}(\mathcal{M})= C^\infty (G, {{(\bigwedge \mathfrak{g}^* \otimes \mathcal{A}(M) }_{hor K})}^K.....(*)$$ How can we obtain the formula $ {(*)}$ ? I'm aware of the result which says that  If $P \rightarrow M$ is a $G$ -principal bundle and $E$ is a $G$ -space and $P횞_GE$ is an associated bundle on $M$ then $\mathcal{A}^q(M, P횞_GE)$ is isomorphic to ${\mathcal{A}^q(P, E)}_{bas}$ , but I don't know how to use it to get the formula ${ (*)}$ ! Your help would be greatly appreciated! Thank you.","In page 40 of this article Equivariant cohomology with generalized coefficients ""  we find the following Let be a lie group and is a closed subgroup of it. Let be a -manifold. Consider the product manifold . The group acts freely on the right on by . Consider the fiber space (over ) of orbits of the K-action. The group acts on the left on . If , and , then is an element of , where is identified with left invariant 1-forms on . Thus How can we obtain the formula ? I'm aware of the result which says that  If is a -principal bundle and is a -space and is an associated bundle on then is isomorphic to , but I don't know how to use it to get the formula ! Your help would be greatly appreciated! Thank you.","G K M K G횞M K G횞M (g,m)k= (gk, k^{-1}m) \mathcal{M} = G횞_KM G/K G \mathcal{M} \alpha \in \mathcal{A}(\mathcal{M}) \subset \mathcal{A}(G횞M) g \in G  \alpha (g) {(\bigwedge \mathfrak{g}^* \otimes \mathcal{A}(M) }_{hor K}  \mathfrak{g}^* G  \mathcal{A}(\mathcal{M})= C^\infty (G, {{(\bigwedge \mathfrak{g}^* \otimes \mathcal{A}(M) }_{hor K})}^K.....(*)  {(*)} P \rightarrow M G E G P횞_GE M \mathcal{A}^q(M, P횞_GE) {\mathcal{A}^q(P, E)}_{bas} { (*)}","['differential-geometry', 'differential-forms']"
87,"Does a ""3-cone"" have intrinsic curvature?","Does a ""3-cone"" have intrinsic curvature?",,"A common intro to intrinsic curvature is to show that a standard cone has no curvature outside the vertex because it can be unrolled into a subset of the plane.  Also, in polar coordinates, the cone has metric $g_{rr} = c \qquad g_{\theta\theta} = r^2$ with the constant $c$ corresponding to the slant of the cone.  But when I tried calculating the Riemann tensor components for a spherically symmetric 3-space of the form $g_{rr} = a(r) \qquad g_{\theta\theta} = r^2 \qquad g_{\phi\phi} = r^2\sin^2\theta$ two of them came out looking funny: ${R^{\phi}}_{\theta\phi\theta} = 1 - \frac{1}{a} \qquad\qquad {R^{\theta}}_{\phi\theta\phi} = (1 - \frac{1}{a})\sin^2\theta$ They do vanish when $a(r) = 1$ which is reassuring since that's just Euclidean space.  But they don't for any other constant.  However, a constant other than 1 should just be the 3D version of a cone.  Now it is also reassuring that the radial curvature remains zero, since the $r$ coordinate lines are the geodesics and these clearly are not deviating.  But this tangential behavior is shaking my confidence in my calculation.  It even gives a non-zero Ricci scalar: $R = \frac{2}{ar}(\frac{a'}{a} + \frac{a-1}{r})$ Did I mess up or is that really how it is?  If so, is there an intuitive way to understand why?  And is it in any way related to the fact that all 2-spheres have the same total curvature but 3-spheres do not?","A common intro to intrinsic curvature is to show that a standard cone has no curvature outside the vertex because it can be unrolled into a subset of the plane.  Also, in polar coordinates, the cone has metric with the constant corresponding to the slant of the cone.  But when I tried calculating the Riemann tensor components for a spherically symmetric 3-space of the form two of them came out looking funny: They do vanish when which is reassuring since that's just Euclidean space.  But they don't for any other constant.  However, a constant other than 1 should just be the 3D version of a cone.  Now it is also reassuring that the radial curvature remains zero, since the coordinate lines are the geodesics and these clearly are not deviating.  But this tangential behavior is shaking my confidence in my calculation.  It even gives a non-zero Ricci scalar: Did I mess up or is that really how it is?  If so, is there an intuitive way to understand why?  And is it in any way related to the fact that all 2-spheres have the same total curvature but 3-spheres do not?",g_{rr} = c \qquad g_{\theta\theta} = r^2 c g_{rr} = a(r) \qquad g_{\theta\theta} = r^2 \qquad g_{\phi\phi} = r^2\sin^2\theta {R^{\phi}}_{\theta\phi\theta} = 1 - \frac{1}{a} \qquad\qquad {R^{\theta}}_{\phi\theta\phi} = (1 - \frac{1}{a})\sin^2\theta a(r) = 1 r R = \frac{2}{ar}(\frac{a'}{a} + \frac{a-1}{r}),"['differential-geometry', 'riemannian-geometry', '3d', 'tensors', 'curvature']"
88,Covariant derivative for higher rank tensors,Covariant derivative for higher rank tensors,,"Recently i have started to study tensors, but i have a problem with covariant differentiation. In every textbook i have read so far, there is a formula like $A^{ij}_{;k}=\frac{\partial{A^{ij}}}{\partial{x^k}}+A^{hj}\Gamma^i_{hk}+A^{ih}\Gamma^j_{hk}$ to calculate covariant derivative for a tensor with two contravariant ranks, but none of them has explained the way which results in such formula. Now suppose we have a two dimensional space with basis vectors $\vec{e}_1$ and $\vec{e}_2$. As you know we can build a tensor with two contravarint ranks which can be written in component form as $T = T^{11}(\vec{e}_1 \bigotimes \vec{e}_1)+T^{12}(\vec{e}_1 \bigotimes \vec{e}_2)+T^{21}(\vec{e}_2 \bigotimes \vec{e}_1)+T^{22}(\vec{e}_2 \bigotimes \vec{e}_2)$. Is there any way to reach from component form of a tensor to $A^{ij}_{;k}=\frac{\partial{A^{ij}}}{\partial{x^k}}+A^{hj}\Gamma^i_{hk}+A^{ih}\Gamma^j_{hk}$ ? In other words, is this possible to differentiate like $\frac{\partial{T^{ij}(\vec{e}_i \bigotimes \vec{e}_j)}}{\partial{x^k}}=\frac{\partial{T^{ij}}}{\partial{x^k}}(\vec{e}_1 \bigotimes \vec{e}_1)+T^{ij}(\frac{\partial{\vec{e}_i}}{\partial{x^k}} \bigotimes \vec{e}_j)+T^{ij}(\vec{e}_i \bigotimes \frac{\partial{\vec{e}_j}}{\partial{x^k}})$ ?","Recently i have started to study tensors, but i have a problem with covariant differentiation. In every textbook i have read so far, there is a formula like $A^{ij}_{;k}=\frac{\partial{A^{ij}}}{\partial{x^k}}+A^{hj}\Gamma^i_{hk}+A^{ih}\Gamma^j_{hk}$ to calculate covariant derivative for a tensor with two contravariant ranks, but none of them has explained the way which results in such formula. Now suppose we have a two dimensional space with basis vectors $\vec{e}_1$ and $\vec{e}_2$. As you know we can build a tensor with two contravarint ranks which can be written in component form as $T = T^{11}(\vec{e}_1 \bigotimes \vec{e}_1)+T^{12}(\vec{e}_1 \bigotimes \vec{e}_2)+T^{21}(\vec{e}_2 \bigotimes \vec{e}_1)+T^{22}(\vec{e}_2 \bigotimes \vec{e}_2)$. Is there any way to reach from component form of a tensor to $A^{ij}_{;k}=\frac{\partial{A^{ij}}}{\partial{x^k}}+A^{hj}\Gamma^i_{hk}+A^{ih}\Gamma^j_{hk}$ ? In other words, is this possible to differentiate like $\frac{\partial{T^{ij}(\vec{e}_i \bigotimes \vec{e}_j)}}{\partial{x^k}}=\frac{\partial{T^{ij}}}{\partial{x^k}}(\vec{e}_1 \bigotimes \vec{e}_1)+T^{ij}(\frac{\partial{\vec{e}_i}}{\partial{x^k}} \bigotimes \vec{e}_j)+T^{ij}(\vec{e}_i \bigotimes \frac{\partial{\vec{e}_j}}{\partial{x^k}})$ ?",,['tensors']
89,Show that this curve is regular,Show that this curve is regular,,"Given that $\beta$ is parametrised by arc length (with strictly positive curvature), show that the curve $\alpha (s) = \beta (s) - s \beta{'}(s)$ is a regular curve. To show that it's regular I have to show that $|| \alpha'(s) || > 0$ for all $s$ . To try to do this I found the derivative of $\alpha$ to be $$\alpha'(s) = \beta'(s) - \beta'(s) - s\beta''(s) = -s\beta''(s) =  -s\kappa(s)N(s)$$ where $\kappa$ and $N$ are the curvature and normal vector of $\beta$ . My problem is now where to go from here. It is never stated whether or not the interval being worked with contains $0$ or not. If it does, clearly $\alpha'(0) = 0$ so that $\alpha$ is not regular. Is my work up until this point correct, or is the question just wrong? The question was given to me by another student of the same course, so it may have been written down incorrectly.","Given that is parametrised by arc length (with strictly positive curvature), show that the curve is a regular curve. To show that it's regular I have to show that for all . To try to do this I found the derivative of to be where and are the curvature and normal vector of . My problem is now where to go from here. It is never stated whether or not the interval being worked with contains or not. If it does, clearly so that is not regular. Is my work up until this point correct, or is the question just wrong? The question was given to me by another student of the same course, so it may have been written down incorrectly.",\beta \alpha (s) = \beta (s) - s \beta{'}(s) || \alpha'(s) || > 0 s \alpha \alpha'(s) = \beta'(s) - \beta'(s) - s\beta''(s) = -s\beta''(s) =  -s\kappa(s)N(s) \kappa N \beta 0 \alpha'(0) = 0 \alpha,"['geometry', 'differential-geometry', 'curves']"
90,A problem about polar coordinate of $\mathbb{R}^2-{0}$ in Bott-Tu's book.,A problem about polar coordinate of  in Bott-Tu's book.,\mathbb{R}^2-{0},"In the Chapter 6 of Bott-Tu's Differential Forms in Algebraic Geometry (P71, P72), they use the polar coordinates of $\mathbb{R}^2-{0}$ to define the global Angular form: Now suppose the rank of $E$ is $2$ , and ${U_{\alpha}}$ is a coordinate open cover of M  that trivializes $E$ . Since $E$ has a Riemannian structure, over each ${U_{\alpha}}$ we can  choose an orthonormal frame. This defines on $E^O|_{U_{\alpha}}$ polar coordinates $r_{\alpha}$ and $\theta _{\alpha}$ ; if $\pi^*x_1,...\pi^*x_n$ are coordinates on ${U_{\alpha}}$ , then $\pi^*x_1,...\pi^*x_n,r_{\alpha},\theta _{\alpha}$ are coordinates  on $E^O|_{U_{\alpha}}$ . Here $E^O|_{U_{\alpha}}$ is the complement of the zero section in $E$ , which is a vector bundle. Since the angel function $\theta_{\alpha}$ is not continuous on $\mathbb{R}^2-0$ , I wonder why $\pi^*x_1,...\pi^*x_n,r_{\alpha},\theta _{\alpha}$ are coordinates  on $E^O|_{U_{\alpha}}$ . Do they mean that for $E^O|_{U_{\alpha}}$ , we discompose it by four charts: ${U_{\alpha}}\times\mathbb{R}\times\mathbb{R}^+,{U_{\alpha}}\times\mathbb{R}^-\times\mathbb{R},{U_{\alpha}}\times\mathbb{R}\times\mathbb{R}^-,{U_{\alpha}}\times\mathbb{R}^+\times\mathbb{R}$ , , and on these charts, $\theta_{\alpha}$ is smooth? If we do this, I wonder if the Euler class could be defined by Bott-Tu's way, I am not sure if I am right. Maybe this problem is too strange, It has a simplified version竊 How to understand the angel function $\theta$ in $\mathbb{R}^2-{0}$ , and 1-form $d\theta$ , since $\theta$ is not continuous in $\mathbb{R}^2-{0}$ .","In the Chapter 6 of Bott-Tu's Differential Forms in Algebraic Geometry (P71, P72), they use the polar coordinates of to define the global Angular form: Now suppose the rank of is , and is a coordinate open cover of M  that trivializes . Since has a Riemannian structure, over each we can  choose an orthonormal frame. This defines on polar coordinates and ; if are coordinates on , then are coordinates  on . Here is the complement of the zero section in , which is a vector bundle. Since the angel function is not continuous on , I wonder why are coordinates  on . Do they mean that for , we discompose it by four charts: , , and on these charts, is smooth? If we do this, I wonder if the Euler class could be defined by Bott-Tu's way, I am not sure if I am right. Maybe this problem is too strange, It has a simplified version竊 How to understand the angel function in , and 1-form , since is not continuous in .","\mathbb{R}^2-{0} E 2 {U_{\alpha}} E E {U_{\alpha}} E^O|_{U_{\alpha}} r_{\alpha} \theta _{\alpha} \pi^*x_1,...\pi^*x_n {U_{\alpha}} \pi^*x_1,...\pi^*x_n,r_{\alpha},\theta _{\alpha} E^O|_{U_{\alpha}} E^O|_{U_{\alpha}} E \theta_{\alpha} \mathbb{R}^2-0 \pi^*x_1,...\pi^*x_n,r_{\alpha},\theta _{\alpha} E^O|_{U_{\alpha}} E^O|_{U_{\alpha}} {U_{\alpha}}\times\mathbb{R}\times\mathbb{R}^+,{U_{\alpha}}\times\mathbb{R}^-\times\mathbb{R},{U_{\alpha}}\times\mathbb{R}\times\mathbb{R}^-,{U_{\alpha}}\times\mathbb{R}^+\times\mathbb{R} \theta_{\alpha} \theta \mathbb{R}^2-{0} d\theta \theta \mathbb{R}^2-{0}","['differential-geometry', 'algebraic-topology']"
91,Slice theorem to give manifold structure,Slice theorem to give manifold structure,,"I'm looking for some reference for the following statement I noticed on wiki: It says that the slice theorem can be used to prove that the orbit space is a manifold when the group is compact and action is free. Where I can find a proof of this? Also, is it necessary that the group is compact? Don't we also need to require the action to be proper (for quotient space to be Haursdorff)? Is the group or the manifold necessarily finite dimensional to make the quotient a manifold? What is the general statement of this one? Any comment is appreciated.","I'm looking for some reference for the following statement I noticed on wiki: It says that the slice theorem can be used to prove that the orbit space is a manifold when the group is compact and action is free. Where I can find a proof of this? Also, is it necessary that the group is compact? Don't we also need to require the action to be proper (for quotient space to be Haursdorff)? Is the group or the manifold necessarily finite dimensional to make the quotient a manifold? What is the general statement of this one? Any comment is appreciated.",,"['differential-geometry', 'manifolds']"
92,"If $dx$ is a differential form in $\Gamma (V, \wedge^1 V^* \otimes V)$, what is $e^{idx}$?","If  is a differential form in , what is ?","dx \Gamma (V, \wedge^1 V^* \otimes V) e^{idx}","I'm reading about the Thom form from in the paper: The Gauss-Bonnet-Chern Theorem on Riemannian Manifolds by Yin Li. In page 31, he defines the Berezin integral on a real vector space $V$ to be a nonzero linear map $B: \wedge^*V \rightarrow \mathbb{R}$ which vanishes on $\wedge^kV$ for $k < dim_\mathbb{R}V$ and he gives a canonical example of it given by projecting $\omega \in \wedge^*V^* $ onto $e_1 \wedge ... \wedge e_n$ where $e_1,...,e_n$ is a basis of $V$ . Then he says : Since the identity map $Id : V \rightarrow V$ can be identified with an element of $\Gamma (V, \wedge^0 V^* \otimes V)$ , we can take its exterior differential $dx \in \Gamma(V, \wedge^1 \otimes V)$ . Then the exponential $e^{idx}$ lies in $\Gamma (V, \wedge^*V^* \otimes \wedge^*V^*.$ We extend the Berezin integral to a map $B: \Gamma(V, \wedge^*V^* \otimes \wedge^*V^* \rightarrow \Gamma(V, \wedge^*V^*)$ by $$ B(\omega \otimes \xi)= \omega \otimes B(\xi) , \omega \in \Gamma(V,\wedge^*V^*), \xi \in \wedge^*V^*. $$ My problem is that I didn't understand the following steps of the proof of proposition 4.3.2 Proof: Let $\lbrace e_k \rbrace$ be the dual basis of $dx^k,$ we have $$B(e^{-idx}) = B(\prod_{k=1}^n (1- idx^k \otimes e_k)) = {(-i)}^n B ((dx^1 \otimes e_1) \wedge...\wedge (dx^n \otimes e_n)).$$ My understanding of $dx$ which is viewed as an element of $\Gamma (V, \wedge^1 V^* \otimes V)$ is to be $dx = dx^1 \otimes e_1 +...+ dx^n \otimes e_n$ but I don't know how he calculates $e^{idx}$ to get the formulas above ?","I'm reading about the Thom form from in the paper: The Gauss-Bonnet-Chern Theorem on Riemannian Manifolds by Yin Li. In page 31, he defines the Berezin integral on a real vector space to be a nonzero linear map which vanishes on for and he gives a canonical example of it given by projecting onto where is a basis of . Then he says : Since the identity map can be identified with an element of , we can take its exterior differential . Then the exponential lies in We extend the Berezin integral to a map by My problem is that I didn't understand the following steps of the proof of proposition 4.3.2 Proof: Let be the dual basis of we have My understanding of which is viewed as an element of is to be but I don't know how he calculates to get the formulas above ?","V B: \wedge^*V \rightarrow \mathbb{R} \wedge^kV k < dim_\mathbb{R}V \omega \in \wedge^*V^*  e_1 \wedge ... \wedge e_n e_1,...,e_n V Id : V \rightarrow V \Gamma (V, \wedge^0 V^* \otimes V) dx \in \Gamma(V, \wedge^1 \otimes V) e^{idx} \Gamma (V, \wedge^*V^* \otimes \wedge^*V^*. B: \Gamma(V, \wedge^*V^* \otimes \wedge^*V^* \rightarrow \Gamma(V, \wedge^*V^*)  B(\omega \otimes \xi)= \omega \otimes B(\xi) , \omega \in \Gamma(V,\wedge^*V^*), \xi \in \wedge^*V^*.  \lbrace e_k \rbrace dx^k, B(e^{-idx}) = B(\prod_{k=1}^n (1- idx^k \otimes e_k)) = {(-i)}^n B ((dx^1 \otimes e_1) \wedge...\wedge (dx^n \otimes e_n)). dx \Gamma (V, \wedge^1 V^* \otimes V) dx = dx^1 \otimes e_1 +...+ dx^n \otimes e_n e^{idx}","['differential-geometry', 'differential-forms']"
93,"Does the Lie bracket relation $[\Gamma(D), \Gamma(E)] \subseteq \Gamma(E)$ imply the flow relation $d\theta_t(E) \subseteq E$?",Does the Lie bracket relation  imply the flow relation ?,"[\Gamma(D), \Gamma(E)] \subseteq \Gamma(E) d\theta_t(E) \subseteq E","Let $M$ be a smooth manifold and let $D, E \subseteq TM$ be two distributions on $M$ such that $$[\Gamma(D), \Gamma(E)] \subseteq \Gamma(E),$$ where $\Gamma(\cdot)$ is the space of smooth sections and $[\cdot, \cdot]$ is the Lie bracket of vector fields. Let $X \in \Gamma(D)$ and let $\theta_t$ be the flow of $X$ . Is it true that $$d\theta_t(E_p) \subseteq E_{\theta_t(p)}\tag{1}$$ for all $p \in M$ ? (In which case, it is actually an equality.) Some special cases are easy to check. For example, if $D = E$ , then $E$ is involutive, so the flow lines of $X$ are contained in the leafs of $E$ , and (1) follows. I'm not sure about the general case.","Let be a smooth manifold and let be two distributions on such that where is the space of smooth sections and is the Lie bracket of vector fields. Let and let be the flow of . Is it true that for all ? (In which case, it is actually an equality.) Some special cases are easy to check. For example, if , then is involutive, so the flow lines of are contained in the leafs of , and (1) follows. I'm not sure about the general case.","M D, E \subseteq TM M [\Gamma(D), \Gamma(E)] \subseteq \Gamma(E), \Gamma(\cdot) [\cdot, \cdot] X \in \Gamma(D) \theta_t X d\theta_t(E_p) \subseteq E_{\theta_t(p)}\tag{1} p \in M D = E E X E","['differential-geometry', 'smooth-manifolds']"
94,Embedded Ricci Flow,Embedded Ricci Flow,,"Consider a submanifold $\mathcal{M}$ that is embedded in a higher dimensional manifold $\mathcal{N}$ . Now if I infinitesimally perturb the submanifold as $$g_{\alpha\beta}\rightarrow g_{\alpha\beta}+\varepsilon R_{\alpha\beta}+\mathcal{O}(\varepsilon^2)$$ then a) Is there an embedding of the new manifold in $\mathcal{N}$ ? If yes, is the embedding also infiitesimally perturbed from the original one? (Of course an embedding may not be unique, I mean is there one embedding that is infinitesimally close?) b) If the answer to 'a' is affirmative, can I describe the embedding flow solely in terms of the extrinsic curvature? I have shown that except for manifolds with constant curvature ( $R_{\alpha\beta}=Cg_{\alpha\beta}$ ), the Ricci flow is different from the 'curve shortening flow' and therefore do not know where the animations of the ricci flow come from!","Consider a submanifold that is embedded in a higher dimensional manifold . Now if I infinitesimally perturb the submanifold as then a) Is there an embedding of the new manifold in ? If yes, is the embedding also infiitesimally perturbed from the original one? (Of course an embedding may not be unique, I mean is there one embedding that is infinitesimally close?) b) If the answer to 'a' is affirmative, can I describe the embedding flow solely in terms of the extrinsic curvature? I have shown that except for manifolds with constant curvature ( ), the Ricci flow is different from the 'curve shortening flow' and therefore do not know where the animations of the ricci flow come from!",\mathcal{M} \mathcal{N} g_{\alpha\beta}\rightarrow g_{\alpha\beta}+\varepsilon R_{\alpha\beta}+\mathcal{O}(\varepsilon^2) \mathcal{N} R_{\alpha\beta}=Cg_{\alpha\beta},"['differential-geometry', 'manifolds', 'submanifold', 'ricci-flow']"
95,Tangent space of the normal bundle,Tangent space of the normal bundle,,"Let $M$ be a manifold endowed with a connection $\nabla$ . Let $M_0$ be a submanifold of $M$ , we denote by $N$ the normal bundle of $M_0$ . The following paragraph is from the book: Heat kernels and Dirac operators (page 217) By orthogonal projection, the Levi-Civita connection $\nabla$ gives a connection $\nabla^N$ on the normal bundle $N$ which is compatible with the induced metric. Identifying $M_0$ with the zero section of $N$ , we obtain a canonical isomorphism $$TN_{|M_0} \cong TM_{|M_0}$$ How to prove that there's an isomorphism between the bundles $TN_{|M_0}$ and $TM_{|M_0}$ ?","Let be a manifold endowed with a connection . Let be a submanifold of , we denote by the normal bundle of . The following paragraph is from the book: Heat kernels and Dirac operators (page 217) By orthogonal projection, the Levi-Civita connection gives a connection on the normal bundle which is compatible with the induced metric. Identifying with the zero section of , we obtain a canonical isomorphism How to prove that there's an isomorphism between the bundles and ?",M \nabla M_0 M N M_0 \nabla \nabla^N N M_0 N TN_{|M_0} \cong TM_{|M_0} TN_{|M_0} TM_{|M_0},['differential-geometry']
96,Can a parallel transported frame be obtained from the eigenvectors of a curvature tensor?,Can a parallel transported frame be obtained from the eigenvectors of a curvature tensor?,,"Let $(M,g,\nabla)$ be a Riemannian manifold of dimension $n$ and let $\gamma:\mathbb{R}\to M$ be a geodesic, namely, $\nabla_{\dot{\gamma}}\dot{\gamma}=0$ . It is well know that, given a basis $\{e_{j}(p)\}_{j=1}^{n}$ on the tangent space $T_{p}M$ , where $p=\gamma(0)$ , one can build a parallel transported frame $\{E_{0}(\gamma(t)):=\xi(\gamma(t)),E_{1}(\gamma(t)),\ldots,E_{n}(\gamma(t))\}$ on any tangent space $T_{\gamma(t)}M$ along the geodesic. In particular, this means that, for any $l$ , $\nabla_{\xi}E_{l}=0$ and $E_{l}(\gamma(0))\equiv e_{l}(p)$ . Now, setting $\xi:=\dot{\gamma}$ , let us introduce the symmetric endomorphism: $$ Ricc_{\xi}(p):=R(\xi(p),J(p))\xi(p),\qquad \forall J(p)\in T_{p}M $$ where $R$ is the Riemann curvature tensor, i.e, $R(X,Y)Z|_{p}=R^{i}_{jkl}(p)X^{j}(p)X^{k}(p)Z^{l}(p)e_{i}(p)$ with $\{e_{i}(p)\}_{i=1}^{n}$ is a orthonormal basis on the tangent space $T_{p}M$ . I know that $Ricc_{\xi}$ is symmetric because of the properties of the Riemann tensor, therefore, I can always diagonalized $Ricc_{\xi}$ on (in principle any tangent space) the initial point of the geodesic, that is, $p=\gamma(0)$ and I will get an eigensystem whose eigenvectors can be used as a basis on $T_{\gamma(0)}M$ . Now, supposing that I know the isomorphism (parallel transport map) $\Gamma_{t}:T_{p}M\to T_{\gamma(t)}M$ since I solved the geodesic equation, my question is: Can a parallel transported frame be obtained evolving the eigenvectors of the operator $Ricc_{\xi}$ through the map $\Gamma_{t}$ ?","Let be a Riemannian manifold of dimension and let be a geodesic, namely, . It is well know that, given a basis on the tangent space , where , one can build a parallel transported frame on any tangent space along the geodesic. In particular, this means that, for any , and . Now, setting , let us introduce the symmetric endomorphism: where is the Riemann curvature tensor, i.e, with is a orthonormal basis on the tangent space . I know that is symmetric because of the properties of the Riemann tensor, therefore, I can always diagonalized on (in principle any tangent space) the initial point of the geodesic, that is, and I will get an eigensystem whose eigenvectors can be used as a basis on . Now, supposing that I know the isomorphism (parallel transport map) since I solved the geodesic equation, my question is: Can a parallel transported frame be obtained evolving the eigenvectors of the operator through the map ?","(M,g,\nabla) n \gamma:\mathbb{R}\to M \nabla_{\dot{\gamma}}\dot{\gamma}=0 \{e_{j}(p)\}_{j=1}^{n} T_{p}M p=\gamma(0) \{E_{0}(\gamma(t)):=\xi(\gamma(t)),E_{1}(\gamma(t)),\ldots,E_{n}(\gamma(t))\} T_{\gamma(t)}M l \nabla_{\xi}E_{l}=0 E_{l}(\gamma(0))\equiv e_{l}(p) \xi:=\dot{\gamma} 
Ricc_{\xi}(p):=R(\xi(p),J(p))\xi(p),\qquad \forall J(p)\in T_{p}M
 R R(X,Y)Z|_{p}=R^{i}_{jkl}(p)X^{j}(p)X^{k}(p)Z^{l}(p)e_{i}(p) \{e_{i}(p)\}_{i=1}^{n} T_{p}M Ricc_{\xi} Ricc_{\xi} p=\gamma(0) T_{\gamma(0)}M \Gamma_{t}:T_{p}M\to T_{\gamma(t)}M Ricc_{\xi} \Gamma_{t}",['differential-geometry']
97,Is there an analogous concept for De Rham cohomology in the framework of Clifford algebras?,Is there an analogous concept for De Rham cohomology in the framework of Clifford algebras?,,"I셶e recently read about Clifford셲 geometric algebra being a more general framework for differential geometry than differential forms , simpler for the study of spaces with a metric tensor, and equivalent to the latter in some cases. I셶e mostly learned about differential forms in the context of de Rham cohomology so I couldn셳 help but asking myself if there셲 an equivalent concept in the framework of Clifford algebras (I don셳 know a whole lot about Clifford algebras yet so excuse me if this question doesn셳 make sense).","I셶e recently read about Clifford셲 geometric algebra being a more general framework for differential geometry than differential forms , simpler for the study of spaces with a metric tensor, and equivalent to the latter in some cases. I셶e mostly learned about differential forms in the context of de Rham cohomology so I couldn셳 help but asking myself if there셲 an equivalent concept in the framework of Clifford algebras (I don셳 know a whole lot about Clifford algebras yet so excuse me if this question doesn셳 make sense).",,"['differential-geometry', 'differential-forms', 'clifford-algebras', 'de-rham-cohomology', 'geometric-algebras']"
98,Worked Exercises about Residues of Differentials,Worked Exercises about Residues of Differentials,,"I would first like to say that if this post is inappropriate for this StackExchange please let me know and I will remove it. A few days ago I posted a question asking about Understanding the need for Residues of Differentials and I got a couple of comments with some ideas and a suggestion for me to look at geometry first. My issue is that I can't seem to find a lot of information on Residues of Differentials, and moreover, no worked exercises on their use within complex analysis. The book that I am following, Serge Lang's Introduction to Complex Analysis at a Graduate Level, does have some exercises, however, they are not worked. I did ask the people who commented on my original post if they could share any usefull resources on this matter but both of them have yet to respond (I am not too sure if the comment system notifies people on replies?). My question: Are there any standard examples of the use of differentials of residues in complex analysis that one should know? Moreover,  does anybody have any resources/notes ,that they are willing to share, on the topic that also include worked exercises?","I would first like to say that if this post is inappropriate for this StackExchange please let me know and I will remove it. A few days ago I posted a question asking about Understanding the need for Residues of Differentials and I got a couple of comments with some ideas and a suggestion for me to look at geometry first. My issue is that I can't seem to find a lot of information on Residues of Differentials, and moreover, no worked exercises on their use within complex analysis. The book that I am following, Serge Lang's Introduction to Complex Analysis at a Graduate Level, does have some exercises, however, they are not worked. I did ask the people who commented on my original post if they could share any usefull resources on this matter but both of them have yet to respond (I am not too sure if the comment system notifies people on replies?). My question: Are there any standard examples of the use of differentials of residues in complex analysis that one should know? Moreover,  does anybody have any resources/notes ,that they are willing to share, on the topic that also include worked exercises?",,"['complex-analysis', 'differential-geometry', 'reference-request', 'residue-calculus']"
99,A metric on the Grassmannian manifold induced by the Riemannian metric,A metric on the Grassmannian manifold induced by the Riemannian metric,,"In Wikipedia , they define the Grassmannian manifold by $$Gr(r,n)=O(n)/(O(r)\times O(n-r))$$ where $O(m)$ is the orthogonal group of $m\times m$ matrices. They say that it gives a metric on the Grassmannian by $$d(W,W^\prime)=\|P_W-P_{W^\prime}\|$$ where $P_V$ is the projection operator on a space $V$ . My questions are: In what sense does this metric $d$ rise from the formulation of the Grassmannian with the orthogonal group? Is $d$ equal to the metric induced by the Riemannian metric on $O(n)$ ? (and is this Riemannian metric given by $g_p(A,B)=tr(AB^{t})$ like $GL(n)$ ?) Why is this metric $d$ natural from the construction of the Grassmannian by the orthogonal group as was described above, and not from the alternative definition $GL(n)/H$ for $H$ the stabilizer of a $r$ -dimensional subspace? Are these constructions the same in the sense that the Riemannian metrics on both $GL(n)$ and $O(n)$ would induce the same metric $d$ described above?","In Wikipedia , they define the Grassmannian manifold by where is the orthogonal group of matrices. They say that it gives a metric on the Grassmannian by where is the projection operator on a space . My questions are: In what sense does this metric rise from the formulation of the Grassmannian with the orthogonal group? Is equal to the metric induced by the Riemannian metric on ? (and is this Riemannian metric given by like ?) Why is this metric natural from the construction of the Grassmannian by the orthogonal group as was described above, and not from the alternative definition for the stabilizer of a -dimensional subspace? Are these constructions the same in the sense that the Riemannian metrics on both and would induce the same metric described above?","Gr(r,n)=O(n)/(O(r)\times O(n-r)) O(m) m\times m d(W,W^\prime)=\|P_W-P_{W^\prime}\| P_V V d d O(n) g_p(A,B)=tr(AB^{t}) GL(n) d GL(n)/H H r GL(n) O(n) d","['differential-geometry', 'riemannian-geometry', 'grassmannian', 'homogeneous-spaces']"
