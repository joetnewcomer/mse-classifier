,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,2-dimensional vector bundles on projective 3-space,2-dimensional vector bundles on projective 3-space,,"Let $V,V'\subset T\mathbf{CP}^3$ be smooth (real) 2-dimensional subbundles of the tangent bundle of complex projective 3-space. Suppose that $V$ and $V'$ are isomorphic as topological vector bundles, i.e. there exists a continuous vector bundle isomorphism between $V$ and $V'$. Are $V$ and $V'$ necessarily isomorphic as smooth vector bundles (i.e. does there exist a smooth map $V\to V'$ which induces a linear isomorphism on the fibers)? I am aware of a classification of complex vector bundles over projective spaces, but couldn't find anything on real smooth vector bundles. I also think that the fact that both are subbundles of the tangent bundle should make this easy, but I don't know how to use that condition.","Let $V,V'\subset T\mathbf{CP}^3$ be smooth (real) 2-dimensional subbundles of the tangent bundle of complex projective 3-space. Suppose that $V$ and $V'$ are isomorphic as topological vector bundles, i.e. there exists a continuous vector bundle isomorphism between $V$ and $V'$. Are $V$ and $V'$ necessarily isomorphic as smooth vector bundles (i.e. does there exist a smooth map $V\to V'$ which induces a linear isomorphism on the fibers)? I am aware of a classification of complex vector bundles over projective spaces, but couldn't find anything on real smooth vector bundles. I also think that the fact that both are subbundles of the tangent bundle should make this easy, but I don't know how to use that condition.",,"['differential-geometry', 'vector-bundles']"
1,First variation of induced metric on a hypersurface,First variation of induced metric on a hypersurface,,"Reference: Here At page 15 , we could see that the first variation of the induced metric on a hypersurface $\Sigma(t)$ computed as $$\frac{\partial}{\partial t}g_{\Sigma(t)} = v(t) g_{\Sigma(t)},  \forall t \in (-\delta,\delta) \tag{1}$$ since $\Sigma(t)$ is umbilic and $H_t$ is constant, where $v$ is a real function. And then for all $t \in (-\delta, \delta)$ $$g_{\Sigma(t)}  = e^{\int^t_0 v(s) ds} = u(t)^2 g_{\mathbb S^2} \tag{2}$$ where $u(t)=a e^{\int^t_0 v(s) ds}$ with $a^2=|\Sigma|/4\pi \in (0,1)$. Question: Where do I start to get the expression (1) and (2)? I don't have any clue at all. Thank you.","Reference: Here At page 15 , we could see that the first variation of the induced metric on a hypersurface $\Sigma(t)$ computed as $$\frac{\partial}{\partial t}g_{\Sigma(t)} = v(t) g_{\Sigma(t)},  \forall t \in (-\delta,\delta) \tag{1}$$ since $\Sigma(t)$ is umbilic and $H_t$ is constant, where $v$ is a real function. And then for all $t \in (-\delta, \delta)$ $$g_{\Sigma(t)}  = e^{\int^t_0 v(s) ds} = u(t)^2 g_{\mathbb S^2} \tag{2}$$ where $u(t)=a e^{\int^t_0 v(s) ds}$ with $a^2=|\Sigma|/4\pi \in (0,1)$. Question: Where do I start to get the expression (1) and (2)? I don't have any clue at all. Thank you.",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
2,Pluriharmonic functions are harmonic on submanifolds?,Pluriharmonic functions are harmonic on submanifolds?,,"Let $X$ a Kähler manifold and $f:X\to \mathbb C$ a function. $f$ is said to be pluriharmonic if its restriction to each curve in $X$ is harmonic. Why is then $f$ harmonic? Does this simply follow from covering $X$ by curves? Does the same argument then imply that the restriction of $F$ to any complex submanifold of $X$ is harmonic? (I need to see that $f$ restricted to a special case of compact connected submanifolds is constant, which would follow from harmonicity) On a similar note, I have seen another of definition of $f$ being pluriharmonic, namely $\partial \overline{\partial} f=0$ Then it follows from a simple calculation that $f$ is harmonic. But how do I see that this definition I equivalent?","Let $X$ a Kähler manifold and $f:X\to \mathbb C$ a function. $f$ is said to be pluriharmonic if its restriction to each curve in $X$ is harmonic. Why is then $f$ harmonic? Does this simply follow from covering $X$ by curves? Does the same argument then imply that the restriction of $F$ to any complex submanifold of $X$ is harmonic? (I need to see that $f$ restricted to a special case of compact connected submanifolds is constant, which would follow from harmonicity) On a similar note, I have seen another of definition of $f$ being pluriharmonic, namely $\partial \overline{\partial} f=0$ Then it follows from a simple calculation that $f$ is harmonic. But how do I see that this definition I equivalent?",,"['complex-analysis', 'differential-geometry', 'complex-geometry', 'harmonic-functions']"
3,Commutator of two Laplace operators,Commutator of two Laplace operators,,"Let $M$ be a smooth manifold and $g,\bar{g}$ two Riemannian metrics on $M$. Let $\Delta$ and $\bar{\Delta}$ be the Laplace operators associated to $g$ and $\bar{g}$, respectively. When acting on a vector field $X\in \Gamma(TM)$, what is the commutator $$[\Delta,\bar{\Delta}]X=(\Delta\bar{\Delta}-\bar{\Delta}\Delta) X?$$ I tried choosing local coordinates at $p\in M$ so that the Christoffel symbols for $g$ vanish at $p$, but I think my answer is wrong. Is there a formula for this?","Let $M$ be a smooth manifold and $g,\bar{g}$ two Riemannian metrics on $M$. Let $\Delta$ and $\bar{\Delta}$ be the Laplace operators associated to $g$ and $\bar{g}$, respectively. When acting on a vector field $X\in \Gamma(TM)$, what is the commutator $$[\Delta,\bar{\Delta}]X=(\Delta\bar{\Delta}-\bar{\Delta}\Delta) X?$$ I tried choosing local coordinates at $p\in M$ so that the Christoffel symbols for $g$ vanish at $p$, but I think my answer is wrong. Is there a formula for this?",,['differential-geometry']
4,"interplay: exterior algebra, tensor algebra, differential forms","interplay: exterior algebra, tensor algebra, differential forms",,"I'd like to understand how to evaluate a differential form on vector fields, and how to 'embed' exterior algebra into tensor algebra. Some people define differential forms as alternating tensor fields, the others as sections of 'exterior algebra bundle'. In the former case, it is clear how such a field acts on vector fields. I am not sure how it works in the second case and what is the interplay between these two definitions. Here is what I mean. Let $V^*$ be the dual space of the $\mathbb{F}$-vector space $V$, where $\mathbb{F}$ is either $\mathbb{R}$, or $\mathbb{C}$. Consider the tensor algebra $Tensor(V^*)$ and its quotient by the two-sided ideal $I$ generated by all elements of the form $x\otimes x$ for $x\in V^*$ together with the natural projection $\pi$, i.e. corresponding exterior algebra $\pi:Tensor(V^*)\to\Lambda(V^*)=Tensor(V^*)/I$. The exterior algebra then inherits the multiplication from the tensor product which is called the wedge product, hence $\pi(a)\wedge\pi(b):=\pi(a\otimes b)$. The other part of the story are alternating tensors. There is an endomorphism of the tensor algebra, called the alternation map $Alt$ , which is actually a projection with the kernel $Ker(Alt)=I$, and the image of $Alt$ are precisely alternating tensors $AltTen(V^*)$. Therefore, one has the vector space isomorphism $\overline{Alt}:\Lambda(V^*)\cong AltTen(V^*)$ which is given by $\pi(a)\mapsto Alt(a)$. This construction works also in the case if we start with $TM$ instead of $V$, where $TM$ is the tangent bundle to a manifold $M$. In that situation, sections of the 'exterior algebra bundle' are differential forms. Let $dx^1,dx^2\in T^*M$ such that $dx^i(\partial_j)=\delta^i_j$, where $x^i:M\to\mathbb{R}$ are coordinate functions and $d$ is the exterior derivative. People write $dx^1\wedge dx^2$. Does this mean $\pi(dx^1)\wedge\pi(dx^2)$, and hence $\pi(dx^1\otimes dx^2)$? How such a differential form $dx^1\wedge dx^2$ acts on $(\partial_1,\partial_2)$? Is this correct; $\pi(dx^1)\wedge\pi(dx^2) (\partial_1,\partial_2)=(dx^1\otimes dx^2+I)(\partial_1,\partial_2)=dx^1(\partial_1)dx^2(\partial_2)+I(\partial_1,\partial_2)=1+0?$ If one uses the isomorphism $\overline{Alt}$ the form $dx^1\wedge dx^2$ corresponds to $\frac{1}{2}(dx^1\otimes dx^2-dx^2\otimes dx^1)$ which evaluates on $(\partial_1,\partial_2)$ as $\frac{1}{2}$. This seems to me as the correct way because $\frac{1}{2}(dx^1\otimes dx^2-dx^2\otimes dx^1)$ is something like 'pure' representative of the class $\pi(dx^1\otimes dx^2)$. If $\pi(dx^1),\pi(dx^2)\in\Lambda(T^*M)$ we may consider their product which is $\pi(dx^1\otimes dx^2)$, which in turn corresponds to $\frac{1}{2}(dx^1\otimes dx^2-dx^2\otimes dx^1)$ under the map $\overline{Alt}$. Here is the wedge product defined differently. According to that definition $dx^1\wedge dx^2=dx^1\otimes dx^2-dx^2\otimes dx^1$. Thank you for any comments.","I'd like to understand how to evaluate a differential form on vector fields, and how to 'embed' exterior algebra into tensor algebra. Some people define differential forms as alternating tensor fields, the others as sections of 'exterior algebra bundle'. In the former case, it is clear how such a field acts on vector fields. I am not sure how it works in the second case and what is the interplay between these two definitions. Here is what I mean. Let $V^*$ be the dual space of the $\mathbb{F}$-vector space $V$, where $\mathbb{F}$ is either $\mathbb{R}$, or $\mathbb{C}$. Consider the tensor algebra $Tensor(V^*)$ and its quotient by the two-sided ideal $I$ generated by all elements of the form $x\otimes x$ for $x\in V^*$ together with the natural projection $\pi$, i.e. corresponding exterior algebra $\pi:Tensor(V^*)\to\Lambda(V^*)=Tensor(V^*)/I$. The exterior algebra then inherits the multiplication from the tensor product which is called the wedge product, hence $\pi(a)\wedge\pi(b):=\pi(a\otimes b)$. The other part of the story are alternating tensors. There is an endomorphism of the tensor algebra, called the alternation map $Alt$ , which is actually a projection with the kernel $Ker(Alt)=I$, and the image of $Alt$ are precisely alternating tensors $AltTen(V^*)$. Therefore, one has the vector space isomorphism $\overline{Alt}:\Lambda(V^*)\cong AltTen(V^*)$ which is given by $\pi(a)\mapsto Alt(a)$. This construction works also in the case if we start with $TM$ instead of $V$, where $TM$ is the tangent bundle to a manifold $M$. In that situation, sections of the 'exterior algebra bundle' are differential forms. Let $dx^1,dx^2\in T^*M$ such that $dx^i(\partial_j)=\delta^i_j$, where $x^i:M\to\mathbb{R}$ are coordinate functions and $d$ is the exterior derivative. People write $dx^1\wedge dx^2$. Does this mean $\pi(dx^1)\wedge\pi(dx^2)$, and hence $\pi(dx^1\otimes dx^2)$? How such a differential form $dx^1\wedge dx^2$ acts on $(\partial_1,\partial_2)$? Is this correct; $\pi(dx^1)\wedge\pi(dx^2) (\partial_1,\partial_2)=(dx^1\otimes dx^2+I)(\partial_1,\partial_2)=dx^1(\partial_1)dx^2(\partial_2)+I(\partial_1,\partial_2)=1+0?$ If one uses the isomorphism $\overline{Alt}$ the form $dx^1\wedge dx^2$ corresponds to $\frac{1}{2}(dx^1\otimes dx^2-dx^2\otimes dx^1)$ which evaluates on $(\partial_1,\partial_2)$ as $\frac{1}{2}$. This seems to me as the correct way because $\frac{1}{2}(dx^1\otimes dx^2-dx^2\otimes dx^1)$ is something like 'pure' representative of the class $\pi(dx^1\otimes dx^2)$. If $\pi(dx^1),\pi(dx^2)\in\Lambda(T^*M)$ we may consider their product which is $\pi(dx^1\otimes dx^2)$, which in turn corresponds to $\frac{1}{2}(dx^1\otimes dx^2-dx^2\otimes dx^1)$ under the map $\overline{Alt}$. Here is the wedge product defined differently. According to that definition $dx^1\wedge dx^2=dx^1\otimes dx^2-dx^2\otimes dx^1$. Thank you for any comments.",,"['differential-geometry', 'differential-forms', 'multilinear-algebra']"
5,"What does ""The map g be geometrically interpreted as the stereographic projection of the Gauss map"" mean?","What does ""The map g be geometrically interpreted as the stereographic projection of the Gauss map"" mean?",,"What does ""The map g be geometrically interpreted as the stereographic projection of the Gauss map"" mean? I already researched this but I do not find anything about this ""interpretation"". Following is an article print:","What does ""The map g be geometrically interpreted as the stereographic projection of the Gauss map"" mean? I already researched this but I do not find anything about this ""interpretation"". Following is an article print:",,"['differential-geometry', 'riemannian-geometry', 'riemann-surfaces', 'hyperbolic-geometry']"
6,Convex curve $\iff$ convex set,Convex curve  convex set,\iff,"The definitions I use are the following: Definition by supporting lines (Convex Curve): A convex curve is a curve in the Euclidean plane ($\mathbb{R}^2$) which lies completely on one side of each and every one of its tangent lines ( Wikipedia ). and Definition (Convex Set): A convex set $A \subseteq \mathbb{R}^n$ is a set of points such that, given any two points $v, w \in A$, the line-segment $[v,w]$ lies entirely within that set (Wikibooks) . I want to prove that given a bounded set $D \subseteq \mathbb{R}^2$ with a smooth boundary, that  $$ \text{$D$ is convex}\iff \text{$\partial D$ is a convex curve} $$ where $\partial D = \overline{D} \backslash D^{\circ}$ is the boundary of $D$. I am aware of the fact that there are two other posts highlighting ( link 1 , link 2 ) the same problem (maybe with some differences in definitions), but the way the proofs/questions were formulated were pretty vague. For the longest time I haven't been able to figure out a formal proof, while it is tauntingly intuitive. Do you guys have any suggestions? Thanks in advance. P.S. I might need some extra conditions that I have overlooked.","The definitions I use are the following: Definition by supporting lines (Convex Curve): A convex curve is a curve in the Euclidean plane ($\mathbb{R}^2$) which lies completely on one side of each and every one of its tangent lines ( Wikipedia ). and Definition (Convex Set): A convex set $A \subseteq \mathbb{R}^n$ is a set of points such that, given any two points $v, w \in A$, the line-segment $[v,w]$ lies entirely within that set (Wikibooks) . I want to prove that given a bounded set $D \subseteq \mathbb{R}^2$ with a smooth boundary, that  $$ \text{$D$ is convex}\iff \text{$\partial D$ is a convex curve} $$ where $\partial D = \overline{D} \backslash D^{\circ}$ is the boundary of $D$. I am aware of the fact that there are two other posts highlighting ( link 1 , link 2 ) the same problem (maybe with some differences in definitions), but the way the proofs/questions were formulated were pretty vague. For the longest time I haven't been able to figure out a formal proof, while it is tauntingly intuitive. Do you guys have any suggestions? Thanks in advance. P.S. I might need some extra conditions that I have overlooked.",,"['geometry', 'differential-geometry']"
7,"What does the ""growing angle of a curve"" actually mean?","What does the ""growing angle of a curve"" actually mean?",,"At several parts on this thesis the author mentions the ""growing angle"" of curves (""limiting growing angle"", ""limiting growing angle of two ends of a curve""). What does that really mean? The author also mentions ""limiting growing direction"" in another very similar article , and I can't figure out what that means either. I'd appreciate any help on clarifying these therms and how the author computes these angles. Update : Apparently this is called the polar tangential angle. I'll look further.","At several parts on this thesis the author mentions the ""growing angle"" of curves (""limiting growing angle"", ""limiting growing angle of two ends of a curve""). What does that really mean? The author also mentions ""limiting growing direction"" in another very similar article , and I can't figure out what that means either. I'd appreciate any help on clarifying these therms and how the author computes these angles. Update : Apparently this is called the polar tangential angle. I'll look further.",,"['calculus', 'differential-geometry']"
8,Circle on a two-dimensional Riemann manifold,Circle on a two-dimensional Riemann manifold,,"I was told that if we consider a circle of a small radius $\varepsilon$ on a two-dimensional Riamannian manifold then it's length and area are $$ L(\varepsilon) = 2 \pi \varepsilon + A \varepsilon^3 + o(\varepsilon^3),\qquad S(\varepsilon) = \pi \varepsilon^2 + B \varepsilon^4 + o(\varepsilon^4), $$ where $A$ and $B$ are some functions of Gaussian curvature $K$. I can directly verify it for a sphere to get $A = - \frac{\pi}{3} K$, $B = - \frac{\pi}{12} K$. I proved the identities above (without explicitly finding $A$ and $B$) and want my proof to be checked. Consider orthonormal basis $e_a$ at tangent space at point $p$ and consider Riemann normal coordinates $x^a$ around it. In this coordinates geodesic starting at $p$ along vector $v = v^a e_a$ has coordinates $$ x^a(t) = v^a t $$ and Christoffel symbols vanish at $p$ so $g_{ab,c}(p) = 0$, so the metric is $$ g_{ab}(x) = \delta_{ab} + \frac12 g_{ab,cd}(p) x^c x^d + o(x^2). \qquad (*) $$ Consider geodesic that starts at $p$, has initial velocity $v$, $|v| = 1$, which has length $\varepsilon$. Then its end has coordinates $x^i_v = v^i \varepsilon + o(\varepsilon)$. Consider unit vectors at $p$ $v(\varphi) = \cos \varphi e_1 + \sin \varphi e_2$. Then the length of a circle centered at $p$ with radius $\varepsilon$ is $$ L(\varepsilon) = \int_0^{2\pi} \left|\frac{dx^a}{d\varphi}\right| d \varphi = \int_0^{2\pi} \sqrt{\varepsilon^2 \delta_{ij}v^i{}'v^j{}' + \varepsilon^4 \frac12 g_{ij,kl}(p)v^i{}'v^j{}'v^k{}'v^l{}' + o(\varepsilon^4)} d\varphi\\ = \int_0^{2\pi} \left( \varepsilon + \varepsilon^3 \frac14 g_{ij,kl}(p)v^i{}'v^j{}'v^k{}'v^l{}' + o(\varepsilon^3) \right) d\varphi\\ = 2 \pi \varepsilon + \varepsilon^3 \frac14 g_{ij,kl}(p) \int_0^{2\pi} v^i{}'v^j{}'v^k{}'v^l{}' d\varphi + o(\varepsilon^3), $$ where $v' = \frac{dv}{d\varphi} = -\sin \varphi e_1 + \cos \varphi e_2$. I didn't check whether $$ g_{ij,kl}(p) \int_0^{2\pi} v^i{}'v^j{}'v^k{}'v^l{}' d\varphi = \frac{\pi}{4} \left( 3 (g_{11,11} + g_{22,22}) + 4 g_{12,12} \right). $$ is proportional to scalar curvature, it's too cumbersome and I don't see any way to check it in not computationally awful way. Consider ''polar coordinates'' $(r, \varphi)$ s.t. $r = \sqrt{(x^1)^2 + (x^2)^2}$, $\tan \varphi = \frac{x^2}{x^1}$. Note that for a point on a circle of radius $\varepsilon$ we have $r = \varepsilon + o(\varepsilon)$. The volume form is $\omega = \sqrt{g} dx^1 \wedge dx^2$. Using coordinate expansion for metric $(*)$ we have $$ \omega = \sqrt{g} dx^1 \wedge dx^2 = (1 + r^2 C + o(r^2)) dx^1 \wedge dx^2 = (1 + r^2 C + o(r^2)) r dr \wedge d\varphi, $$ where $C$ is a function of $v$, that is a function of $\varphi$. So finally $$ S(\varepsilon) = \int_0^{2\pi} d\varphi \int_0^\varepsilon r dr + \int_0^{2\pi} C(\varphi) d\varphi \int_0^\varepsilon r^3 dr + o(\varepsilon^4) = \pi \varepsilon^2 + \varepsilon^4 \frac14 \int_0^{2\pi} C(\varphi) d\varphi + o(\varepsilon^4). $$","I was told that if we consider a circle of a small radius $\varepsilon$ on a two-dimensional Riamannian manifold then it's length and area are $$ L(\varepsilon) = 2 \pi \varepsilon + A \varepsilon^3 + o(\varepsilon^3),\qquad S(\varepsilon) = \pi \varepsilon^2 + B \varepsilon^4 + o(\varepsilon^4), $$ where $A$ and $B$ are some functions of Gaussian curvature $K$. I can directly verify it for a sphere to get $A = - \frac{\pi}{3} K$, $B = - \frac{\pi}{12} K$. I proved the identities above (without explicitly finding $A$ and $B$) and want my proof to be checked. Consider orthonormal basis $e_a$ at tangent space at point $p$ and consider Riemann normal coordinates $x^a$ around it. In this coordinates geodesic starting at $p$ along vector $v = v^a e_a$ has coordinates $$ x^a(t) = v^a t $$ and Christoffel symbols vanish at $p$ so $g_{ab,c}(p) = 0$, so the metric is $$ g_{ab}(x) = \delta_{ab} + \frac12 g_{ab,cd}(p) x^c x^d + o(x^2). \qquad (*) $$ Consider geodesic that starts at $p$, has initial velocity $v$, $|v| = 1$, which has length $\varepsilon$. Then its end has coordinates $x^i_v = v^i \varepsilon + o(\varepsilon)$. Consider unit vectors at $p$ $v(\varphi) = \cos \varphi e_1 + \sin \varphi e_2$. Then the length of a circle centered at $p$ with radius $\varepsilon$ is $$ L(\varepsilon) = \int_0^{2\pi} \left|\frac{dx^a}{d\varphi}\right| d \varphi = \int_0^{2\pi} \sqrt{\varepsilon^2 \delta_{ij}v^i{}'v^j{}' + \varepsilon^4 \frac12 g_{ij,kl}(p)v^i{}'v^j{}'v^k{}'v^l{}' + o(\varepsilon^4)} d\varphi\\ = \int_0^{2\pi} \left( \varepsilon + \varepsilon^3 \frac14 g_{ij,kl}(p)v^i{}'v^j{}'v^k{}'v^l{}' + o(\varepsilon^3) \right) d\varphi\\ = 2 \pi \varepsilon + \varepsilon^3 \frac14 g_{ij,kl}(p) \int_0^{2\pi} v^i{}'v^j{}'v^k{}'v^l{}' d\varphi + o(\varepsilon^3), $$ where $v' = \frac{dv}{d\varphi} = -\sin \varphi e_1 + \cos \varphi e_2$. I didn't check whether $$ g_{ij,kl}(p) \int_0^{2\pi} v^i{}'v^j{}'v^k{}'v^l{}' d\varphi = \frac{\pi}{4} \left( 3 (g_{11,11} + g_{22,22}) + 4 g_{12,12} \right). $$ is proportional to scalar curvature, it's too cumbersome and I don't see any way to check it in not computationally awful way. Consider ''polar coordinates'' $(r, \varphi)$ s.t. $r = \sqrt{(x^1)^2 + (x^2)^2}$, $\tan \varphi = \frac{x^2}{x^1}$. Note that for a point on a circle of radius $\varepsilon$ we have $r = \varepsilon + o(\varepsilon)$. The volume form is $\omega = \sqrt{g} dx^1 \wedge dx^2$. Using coordinate expansion for metric $(*)$ we have $$ \omega = \sqrt{g} dx^1 \wedge dx^2 = (1 + r^2 C + o(r^2)) dx^1 \wedge dx^2 = (1 + r^2 C + o(r^2)) r dr \wedge d\varphi, $$ where $C$ is a function of $v$, that is a function of $\varphi$. So finally $$ S(\varepsilon) = \int_0^{2\pi} d\varphi \int_0^\varepsilon r dr + \int_0^{2\pi} C(\varphi) d\varphi \int_0^\varepsilon r^3 dr + o(\varepsilon^4) = \pi \varepsilon^2 + \varepsilon^4 \frac14 \int_0^{2\pi} C(\varphi) d\varphi + o(\varepsilon^4). $$",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
9,Class of spaces on which a 'path integral' like construction holds,Class of spaces on which a 'path integral' like construction holds,,"I've been working through the proof of de Rham's theorem and as part of this effort, the fact that for a differentiable manifold $M$ there's an isomorphism between the regular and smooth singular homologies of $M$. This strikes me as an analytic, approximation-type result in spirit: smooth 1-chains are, modulo coefficients, just piece-wise differentiable curves in $M$, so at some level we're just approximating possibly very badly behaved $C^0$ curves in our space by nicer ones.  Continuing the 1-dimensional intuition, if I have some nice-enough behaved vector field/differential form-type object, then all I need for a well-defined contour integral is a nice-enough class of curves that I can integrate along, sufficient to recover/reflect the topological structure of my space. This to me begged the following (perhaps ill-posed) question. Question : What type of point-set/analytic considerations need be placed on a subset $X$ of $\mathbb{R}^n$ such that we can recover some similar type of result: using only some 'nice enough' (perhaps Lipschitz or something) collection of images of simplices into $X$ and we can recover some theory of integration for something spiritually similar to vector fields/differential forms, ideally reflective of the topology of $X$? I get that this is all very likely to hinge on the 'nice-enough' handwaving in the above, but I'd be very curious to hear about either examples in this vein or obstructions to defining them in any meaningfully interesting context. Motivation : Some trivial motivation, say $X \subseteq \mathbb{R}^n$ is convex.  If we consider only affine images of simplices into $X$, it would seem intuitive that we recover an analogue that 'every cycle is a boundary' and hence the ""homology"" of the resulting chain complex is zero, squaring with intuition.  Moreover, if you give me any, say ""1-cochain,"" it seems like we'd recover a fairly natural notion of path integral along polygonal paths, complete with a notion of exactness and closedness that work in the intuitive way.  Again, this is all meaningless because the collection of spaces is wholly uninteresting topologically, but I'd be curious to see how this type of intuition could be extended (maybe even the above construction to something like open sets or closed sets who are the closure of their interior) in ways I may not have encountered.","I've been working through the proof of de Rham's theorem and as part of this effort, the fact that for a differentiable manifold $M$ there's an isomorphism between the regular and smooth singular homologies of $M$. This strikes me as an analytic, approximation-type result in spirit: smooth 1-chains are, modulo coefficients, just piece-wise differentiable curves in $M$, so at some level we're just approximating possibly very badly behaved $C^0$ curves in our space by nicer ones.  Continuing the 1-dimensional intuition, if I have some nice-enough behaved vector field/differential form-type object, then all I need for a well-defined contour integral is a nice-enough class of curves that I can integrate along, sufficient to recover/reflect the topological structure of my space. This to me begged the following (perhaps ill-posed) question. Question : What type of point-set/analytic considerations need be placed on a subset $X$ of $\mathbb{R}^n$ such that we can recover some similar type of result: using only some 'nice enough' (perhaps Lipschitz or something) collection of images of simplices into $X$ and we can recover some theory of integration for something spiritually similar to vector fields/differential forms, ideally reflective of the topology of $X$? I get that this is all very likely to hinge on the 'nice-enough' handwaving in the above, but I'd be very curious to hear about either examples in this vein or obstructions to defining them in any meaningfully interesting context. Motivation : Some trivial motivation, say $X \subseteq \mathbb{R}^n$ is convex.  If we consider only affine images of simplices into $X$, it would seem intuitive that we recover an analogue that 'every cycle is a boundary' and hence the ""homology"" of the resulting chain complex is zero, squaring with intuition.  Moreover, if you give me any, say ""1-cochain,"" it seems like we'd recover a fairly natural notion of path integral along polygonal paths, complete with a notion of exactness and closedness that work in the intuitive way.  Again, this is all meaningless because the collection of spaces is wholly uninteresting topologically, but I'd be curious to see how this type of intuition could be extended (maybe even the above construction to something like open sets or closed sets who are the closure of their interior) in ways I may not have encountered.",,"['integration', 'differential-geometry', 'algebraic-topology', 'soft-question', 'differential-topology']"
10,How can I show what the induced metric is?,How can I show what the induced metric is?,,"I'm unclear on how to solve any of these problems, can someone please help me with what to do? a) Let S be the upper portion of a cone in $\mathbb{R}^3$ parametrized by $\phi(u^1,u^2) = (u^1\cos u^2, u^1\sin u^2)$; $u^1 >0$. Show that the induced metric on S from $\phi$ is $$\begin{pmatrix} 2 & 0 \\\ 0 & (u^1)^2\end{pmatrix}$$ $\phi u_1 = <\cos u^2, \sin u^2, 1>$ and $\phi u_2 = <-u^1\sin u^2, u^1\cos u^2, 0>$ Now do all I have to do is dot product these together? So, $g_{11} = \phi u_1 \cdot \phi u_1 = \cos^2 u^2 + \sin^2 u^2 +1$ $g_{12} = g_{21} = \phi u_1 \cdot \phi u_2 = -u^1\sin u^2 \cos u^2+u^1\cos u^2 \sin u^2$ $g_{22} = \phi u_2 \cdot \phi u_2 = (u^1)^2\sin^2 u^2 +(u^1)^2 \cos u^2$ b) Let $X = (u^1)\partial_1 +\partial_2$, be a vector field on S. Find the length of the vector field X with respect to the metric g. c) Suppose $f: S \to \mathbb{R}$ by $f(u^1\cos u^2, u^1\sin u^2, u^1) = (u^1)^2 -(u^1)^2-(u^1)(u^2)$Find X(f), where $X = (u^1)\partial_1 +\partial_2$","I'm unclear on how to solve any of these problems, can someone please help me with what to do? a) Let S be the upper portion of a cone in $\mathbb{R}^3$ parametrized by $\phi(u^1,u^2) = (u^1\cos u^2, u^1\sin u^2)$; $u^1 >0$. Show that the induced metric on S from $\phi$ is $$\begin{pmatrix} 2 & 0 \\\ 0 & (u^1)^2\end{pmatrix}$$ $\phi u_1 = <\cos u^2, \sin u^2, 1>$ and $\phi u_2 = <-u^1\sin u^2, u^1\cos u^2, 0>$ Now do all I have to do is dot product these together? So, $g_{11} = \phi u_1 \cdot \phi u_1 = \cos^2 u^2 + \sin^2 u^2 +1$ $g_{12} = g_{21} = \phi u_1 \cdot \phi u_2 = -u^1\sin u^2 \cos u^2+u^1\cos u^2 \sin u^2$ $g_{22} = \phi u_2 \cdot \phi u_2 = (u^1)^2\sin^2 u^2 +(u^1)^2 \cos u^2$ b) Let $X = (u^1)\partial_1 +\partial_2$, be a vector field on S. Find the length of the vector field X with respect to the metric g. c) Suppose $f: S \to \mathbb{R}$ by $f(u^1\cos u^2, u^1\sin u^2, u^1) = (u^1)^2 -(u^1)^2-(u^1)(u^2)$Find X(f), where $X = (u^1)\partial_1 +\partial_2$",,['differential-geometry']
11,Does the orientation on a product of manifolds depend on the order of the product?,Does the orientation on a product of manifolds depend on the order of the product?,,"I'm learning differential geometry for the first time. I'm sure this question is answered in a number of books, but it doesn't seem to be addressed in any book I have. Let $M,N$ be orientable manifolds of dimension $m,n$. I'd like to view an orientation on $M$ as given by a choice of a nowhere vanishing top differential form. The product maps $$N\leftarrow M\times N\rightarrow M$$ give maps $\Omega^n(N)\rightarrow \Omega^n(M\times N)$ and $\Omega^m(M)\rightarrow\Omega^m(M\times N)$. Thus given an orientation $n$-form $\omega_N$ on $N$ and an orientation $m$-form $\omega_M$ on $M$, we get two natural choices of orientation forms on $M\times N$, namely $\omega_N\wedge \omega_M$ and $\omega_M\wedge\omega_N$. They are the same if and only if $M,N$ are both even-dimensional. (Here I don't want to distinguish $M\times N$ from $N\times M$). In particular, if either $M$ or $N$ are odd-dimensional, then this doesn't seem to give a canonical choice of an orientation on the product $M\times N$. Would it be correct to say that the ""product orientation"" on the product of two oriented manifolds only exists if both manifolds are even dimensional? Ie, if one of the manifolds is odd-dimensional, then there is no canonical choice of an orientation on the product?","I'm learning differential geometry for the first time. I'm sure this question is answered in a number of books, but it doesn't seem to be addressed in any book I have. Let $M,N$ be orientable manifolds of dimension $m,n$. I'd like to view an orientation on $M$ as given by a choice of a nowhere vanishing top differential form. The product maps $$N\leftarrow M\times N\rightarrow M$$ give maps $\Omega^n(N)\rightarrow \Omega^n(M\times N)$ and $\Omega^m(M)\rightarrow\Omega^m(M\times N)$. Thus given an orientation $n$-form $\omega_N$ on $N$ and an orientation $m$-form $\omega_M$ on $M$, we get two natural choices of orientation forms on $M\times N$, namely $\omega_N\wedge \omega_M$ and $\omega_M\wedge\omega_N$. They are the same if and only if $M,N$ are both even-dimensional. (Here I don't want to distinguish $M\times N$ from $N\times M$). In particular, if either $M$ or $N$ are odd-dimensional, then this doesn't seem to give a canonical choice of an orientation on the product $M\times N$. Would it be correct to say that the ""product orientation"" on the product of two oriented manifolds only exists if both manifolds are even dimensional? Ie, if one of the manifolds is odd-dimensional, then there is no canonical choice of an orientation on the product?",,[]
12,Definition of differential forms on $\mathbf P^n$.,Definition of differential forms on .,\mathbf P^n,"Consider the projective space $\mathbf P^n$ over some field $k$, with assumptions on the field as necessary. There is a complex of $k[x_0,\ldots,x_n]$-modules $\Lambda^0\xrightarrow{\mathrm d}\cdots\xrightarrow{\mathrm d}\Lambda^n$, where $\Lambda^i = \bigwedge^i\Omega_{k[x_0,\ldots,x_n]/k}$ for $\Omega_{k[x_0,\ldots,x_n]/k}$ the dual space of the $k$-vector space $\langle\frac{\partial}{\partial x_0}, \ldots, \frac{\partial}{\partial x_n}\rangle$. The operation $\mathrm d: \Lambda^i\to \Lambda^{i+1}, f\mathrm dx_{j_1}\wedge\ldots\wedge\mathrm dx_{j_i} \mapsto \sum_l \frac{\partial f}{\partial x_l} \mathrm dx_{l}\wedge\mathrm dx_{j_1}\wedge\ldots\wedge\mathrm dx_{j_i}$ is a derivation. There is another derivation $\Delta:\Lambda^i\to \Lambda^{i-1}$ with $\Delta(\mathrm d\alpha)+\mathrm d(\Delta\alpha)=\alpha \deg\alpha$ for homogeneous $\alpha$ wrt. the grading $\deg f\mathrm dx_{j_1}\wedge\ldots\wedge\mathrm dx_{j_i} = \deg f + i$. Questions: What does $\Delta$ do? In degree $0$, it seems to me that the contraction $\omega\mapsto\sum_l x_l \frac{\partial}{\partial x_l}\lrcorner\omega$ has the desired property. What is it in higher degrees? The text I am trying to read defines $M^i=\ker\Delta|_{\Lambda^i}$ and calls $\tilde M^i$ the sheaf of differential $i$-forms. Why doesn't one take all of $\Lambda^i$? Especially for question 2., answers appealing to intuition rather than rigorousness are highly welcome!","Consider the projective space $\mathbf P^n$ over some field $k$, with assumptions on the field as necessary. There is a complex of $k[x_0,\ldots,x_n]$-modules $\Lambda^0\xrightarrow{\mathrm d}\cdots\xrightarrow{\mathrm d}\Lambda^n$, where $\Lambda^i = \bigwedge^i\Omega_{k[x_0,\ldots,x_n]/k}$ for $\Omega_{k[x_0,\ldots,x_n]/k}$ the dual space of the $k$-vector space $\langle\frac{\partial}{\partial x_0}, \ldots, \frac{\partial}{\partial x_n}\rangle$. The operation $\mathrm d: \Lambda^i\to \Lambda^{i+1}, f\mathrm dx_{j_1}\wedge\ldots\wedge\mathrm dx_{j_i} \mapsto \sum_l \frac{\partial f}{\partial x_l} \mathrm dx_{l}\wedge\mathrm dx_{j_1}\wedge\ldots\wedge\mathrm dx_{j_i}$ is a derivation. There is another derivation $\Delta:\Lambda^i\to \Lambda^{i-1}$ with $\Delta(\mathrm d\alpha)+\mathrm d(\Delta\alpha)=\alpha \deg\alpha$ for homogeneous $\alpha$ wrt. the grading $\deg f\mathrm dx_{j_1}\wedge\ldots\wedge\mathrm dx_{j_i} = \deg f + i$. Questions: What does $\Delta$ do? In degree $0$, it seems to me that the contraction $\omega\mapsto\sum_l x_l \frac{\partial}{\partial x_l}\lrcorner\omega$ has the desired property. What is it in higher degrees? The text I am trying to read defines $M^i=\ker\Delta|_{\Lambda^i}$ and calls $\tilde M^i$ the sheaf of differential $i$-forms. Why doesn't one take all of $\Lambda^i$? Especially for question 2., answers appealing to intuition rather than rigorousness are highly welcome!",,"['differential-geometry', 'algebraic-geometry', 'commutative-algebra']"
13,Gauss Bonnet theorem and general relativity,Gauss Bonnet theorem and general relativity,,"In the text : Vector calculus - Marsden,  Gauss Bonnet theorem can be the motivation of the two dimensional  Einstein Hilbert action. But, I could not find well these contents in many texts. Is there any good reference about the relation between Gauss bonnet theorem and the 2-dimensional General relativity?","In the text : Vector calculus - Marsden,  Gauss Bonnet theorem can be the motivation of the two dimensional  Einstein Hilbert action. But, I could not find well these contents in many texts. Is there any good reference about the relation between Gauss bonnet theorem and the 2-dimensional General relativity?",,"['differential-geometry', 'general-relativity']"
14,"Showing $L(p,1)$ (lens space) is a Smooth Manifold and Computing its de Rham Groups",Showing  (lens space) is a Smooth Manifold and Computing its de Rham Groups,"L(p,1)","I had my final exam and the professor gave this question which I don't really know how to do. The question: Let $p \in \mathbb{Z}^+$ and let $\mathbb{Z}_p$ act on $\mathbb{C}^2$ by $(z,w) \mapsto (e^{2 \pi i/p}z,e^{2 \pi i /p} w)$. This induces an action on $S^3 \hookrightarrow \mathbb{C}^2$ and the resulting quotient $S^3/\mathbb{Z}$ is referred to as the lens space $L(p,1)$. Show that this lens space is a smooth manifold and computs its de Rham cohomology groups. I've seen the definition before but that's about it. I vaguely remembered that I should probably show something about the group action being properly discontinuous to show that $\pi:S^3 \to L(p,1)$ is a regular covering map. But before even that, how do I know $\pi$ is a quotient map and whether that says $L(p,1)$ is a manifold, let alone smooth? Certainly $L(p,1)$ should be compact and connected as $S^3$ is. I believe it's orientable because multiplication by a complex number is a holomorphism (so orientation preserving) and in $\mathbb{C}^2$, it seems natural to say that a map is holomorphic if and only if its coordinate functions are holomorphic. Thus, $H^0_{dR}(L(p,1) = H^3_{dR}(L(p,1)) = \mathbb{R}$. Also, $S^3$ is the universal cover of $L(p,1)$ and its deck transformations are $\pi_1(L(p,1)) = \mathbb{Z}_p$. Then, since $H^1_{dR}(L(p,1)) \cong H^1(L(p,1), \mathbb{R})$ by de Rham's theorem and $H_1(L(p,1), \mathbb{R}) = H_1(L(p,1),\mathbb{Z}) \otimes_\mathbb{Z} \mathbb{R} = \text{Abel}(\pi_1(L(p,1)) \otimes \mathbb{R} = 0$, $H^1_{dR}(L(p,1)) = 0$. By Poincare duality, $H^2_{dR}(L(p,1))=0$ as well. So the de Rham groups of $L(p,1)$ seem to be the same as $S^3$. My questions: How do we show that $L(p,1)$ is a smooth manifold? How do we show it is orientable? Is my reasoning for the de Rham groups correct? I apologize for being rather wordy. Thank you in advance.","I had my final exam and the professor gave this question which I don't really know how to do. The question: Let $p \in \mathbb{Z}^+$ and let $\mathbb{Z}_p$ act on $\mathbb{C}^2$ by $(z,w) \mapsto (e^{2 \pi i/p}z,e^{2 \pi i /p} w)$. This induces an action on $S^3 \hookrightarrow \mathbb{C}^2$ and the resulting quotient $S^3/\mathbb{Z}$ is referred to as the lens space $L(p,1)$. Show that this lens space is a smooth manifold and computs its de Rham cohomology groups. I've seen the definition before but that's about it. I vaguely remembered that I should probably show something about the group action being properly discontinuous to show that $\pi:S^3 \to L(p,1)$ is a regular covering map. But before even that, how do I know $\pi$ is a quotient map and whether that says $L(p,1)$ is a manifold, let alone smooth? Certainly $L(p,1)$ should be compact and connected as $S^3$ is. I believe it's orientable because multiplication by a complex number is a holomorphism (so orientation preserving) and in $\mathbb{C}^2$, it seems natural to say that a map is holomorphic if and only if its coordinate functions are holomorphic. Thus, $H^0_{dR}(L(p,1) = H^3_{dR}(L(p,1)) = \mathbb{R}$. Also, $S^3$ is the universal cover of $L(p,1)$ and its deck transformations are $\pi_1(L(p,1)) = \mathbb{Z}_p$. Then, since $H^1_{dR}(L(p,1)) \cong H^1(L(p,1), \mathbb{R})$ by de Rham's theorem and $H_1(L(p,1), \mathbb{R}) = H_1(L(p,1),\mathbb{Z}) \otimes_\mathbb{Z} \mathbb{R} = \text{Abel}(\pi_1(L(p,1)) \otimes \mathbb{R} = 0$, $H^1_{dR}(L(p,1)) = 0$. By Poincare duality, $H^2_{dR}(L(p,1))=0$ as well. So the de Rham groups of $L(p,1)$ seem to be the same as $S^3$. My questions: How do we show that $L(p,1)$ is a smooth manifold? How do we show it is orientable? Is my reasoning for the de Rham groups correct? I apologize for being rather wordy. Thank you in advance.",,"['general-topology', 'differential-geometry', 'differential-topology']"
15,Short-time existence of Ricci flow,Short-time existence of Ricci flow,,"Hamilton and DeTurck's short time existence theorem of the Ricci flow states that if $M^n$ is a smooth closed manifold with a $C^{\infty}$ Riemannian metric $g_0$ on $M$, then the Ricci flow on $M$ starting at $g_0$ exists for a short time. Question : Are there any short time existence results for an initial metric $g_0$ with less regularity (e.g. $C^{k,\alpha}$, Lipschitz, etc)?","Hamilton and DeTurck's short time existence theorem of the Ricci flow states that if $M^n$ is a smooth closed manifold with a $C^{\infty}$ Riemannian metric $g_0$ on $M$, then the Ricci flow on $M$ starting at $g_0$ exists for a short time. Question : Are there any short time existence results for an initial metric $g_0$ with less regularity (e.g. $C^{k,\alpha}$, Lipschitz, etc)?",,"['differential-geometry', 'partial-differential-equations', 'ricci-flow']"
16,"How to find 4 geodesic on a surface $z=xy$ passing through point (1,0,0)","How to find 4 geodesic on a surface  passing through point (1,0,0)",z=xy,"Let $S: z=xy$ be a surface How can i find 4 geodesic on S passing throught a point (1,0,0) ? I have already got $(t,0,0)$ and $(1,t,t)$ but i dont know how to find 2 other, any suggestion?","Let $S: z=xy$ be a surface How can i find 4 geodesic on S passing throught a point (1,0,0) ? I have already got $(t,0,0)$ and $(1,t,t)$ but i dont know how to find 2 other, any suggestion?",,"['differential-geometry', 'geodesic']"
17,How to show two regions have equal Area under Gauss map?,How to show two regions have equal Area under Gauss map?,,"What have I missed? I'm trying to show that $N(A)$ and $N(B)$ have the same area, under the following conditions: $N$ is the Gauss map $N: S \rightarrow S^2$. The regions $A$ and $B$ on $S\subset\mathbb{R}^3$ share $\alpha \subset S$, a simple closed geodesic on $S$, as a common boundary. $S$ is a regular compact surface with $K>0$ (Positive Gaussian curvature). I've attempted the following: given $K>0$, the map $N$ preserves orientation, therefore is a diffeomorphism from $S$ onto the sphere. Using the Gauss-Bonnet Theorem on region $A$, we have the following formula: $$\int_{\Gamma} \kappa_g(s) ds + \iint_A K d\sigma + \sum_{l=1}^p\theta_l = 2\pi\chi(A)$$ and since the geodesic curvature of $\Gamma$ vanishes on $S$, we have $k_g = 0 \implies  \int_{\Gamma} k_g(s) ds =0$. Also, since region $A$ is homeomorphic to a disk, the Euler characteristic is 1, hence RHS = $2\pi$. Angle sum term would be zero because $\Gamma$ is a simple closed curve that bounds a region homeomorphic to a disk. Therefore  $\iint_A K d\sigma = 2\pi$. Since Gaussian curvature can be written as the ratio $\frac{\mid N_u x N_v\mid}{\mid X_u x X_v \mid}$, it follows that $$\mid ~N_u \times N_v\mid ~= ~\mid K \mid \cdot\mid X_u \times X_v \mid.$$ By integration, Area of $N(A) = \iint_{N(A)} 1 = \iint_A\frac{\mid N_u x N_v\mid}{\mid X_u x X_v \mid} = \iint_A \mid K\mid = 2\pi$. By the same argument, I get that $N(B)$ has the exact same area, $2\pi$. However, I have not used the fact that the regions $A$ and $B$ share a common boundary , and am not sure where this piece of information would apply. What does a common boundary indicate, and is this information relevant to my approach? Thanks!","What have I missed? I'm trying to show that $N(A)$ and $N(B)$ have the same area, under the following conditions: $N$ is the Gauss map $N: S \rightarrow S^2$. The regions $A$ and $B$ on $S\subset\mathbb{R}^3$ share $\alpha \subset S$, a simple closed geodesic on $S$, as a common boundary. $S$ is a regular compact surface with $K>0$ (Positive Gaussian curvature). I've attempted the following: given $K>0$, the map $N$ preserves orientation, therefore is a diffeomorphism from $S$ onto the sphere. Using the Gauss-Bonnet Theorem on region $A$, we have the following formula: $$\int_{\Gamma} \kappa_g(s) ds + \iint_A K d\sigma + \sum_{l=1}^p\theta_l = 2\pi\chi(A)$$ and since the geodesic curvature of $\Gamma$ vanishes on $S$, we have $k_g = 0 \implies  \int_{\Gamma} k_g(s) ds =0$. Also, since region $A$ is homeomorphic to a disk, the Euler characteristic is 1, hence RHS = $2\pi$. Angle sum term would be zero because $\Gamma$ is a simple closed curve that bounds a region homeomorphic to a disk. Therefore  $\iint_A K d\sigma = 2\pi$. Since Gaussian curvature can be written as the ratio $\frac{\mid N_u x N_v\mid}{\mid X_u x X_v \mid}$, it follows that $$\mid ~N_u \times N_v\mid ~= ~\mid K \mid \cdot\mid X_u \times X_v \mid.$$ By integration, Area of $N(A) = \iint_{N(A)} 1 = \iint_A\frac{\mid N_u x N_v\mid}{\mid X_u x X_v \mid} = \iint_A \mid K\mid = 2\pi$. By the same argument, I get that $N(B)$ has the exact same area, $2\pi$. However, I have not used the fact that the regions $A$ and $B$ share a common boundary , and am not sure where this piece of information would apply. What does a common boundary indicate, and is this information relevant to my approach? Thanks!",,"['differential-geometry', 'riemannian-geometry']"
18,What is the one dimensional analog of the Gauss-Bonnet theorem and the Euler characteristic?,What is the one dimensional analog of the Gauss-Bonnet theorem and the Euler characteristic?,,"The Gauss-Bonnet theorem has to do with surfaces. Its generalization has to do with $2n$ ($n$ being an integer) manifilolds. Is there an analog in one dimension with closed curves? If there exists one such analog, then what is the geometrical interpretation of the analog of the Euler characteristic?","The Gauss-Bonnet theorem has to do with surfaces. Its generalization has to do with $2n$ ($n$ being an integer) manifilolds. Is there an analog in one dimension with closed curves? If there exists one such analog, then what is the geometrical interpretation of the analog of the Euler characteristic?",,"['differential-geometry', 'differential-topology', 'differential-forms']"
19,Linking number of two curves,Linking number of two curves,,"I would like to compute the linking number of a link in $\mathbb{R}^3$ which consists of two disjoint curves $c_a$ and $c_b$. Define $z=x_1+\sqrt{-1}x_2$ and $v=x_3+\sqrt{-1}x_4$ where $(x_1,x_2,x_3, x_4)\in\mathbb{R}^4$ so that $\mathbb{R}^4\cong\mathbb{C}^2$. Let $a,b\in\mathbb{C}$ and let $L_a=\{(z,v)\in\mathbb{C}^2|v=az\}\subset\mathbb{C}^2$ and $L_b=\{(z,v)\in\mathbb{C}^2|v=bz\}\subset\mathbb{C}^2$ be two complex lines in the complex plane. Also let $C_a=S^3\cap L_a$ and $C_b=S^3\cap L_b$ where $S^3$ is the 3-sphere. How do I calculate the integral (the linking number) $$L(c_a, c_b) = \frac{1}{4\pi}\int_{0}^{2\pi}\int_{0}^{2\pi}\frac{(c_a(t)-c_b(s),\dot{c_a}(t), \dot{c_b}(s))}{|c_a(t)-c_b(s)|^3}dtds$$ where $c_a=p(C_a)$ and $c_b=p(C_b)$ and $p$ is the stereographic projection defined by $$p(x_1, x_2, x_3, x_4)=\frac{1}{1-x_4}(x_1, x_2, x_3, 0)$$ if $L(c_a, c_b)\neq 0$ (the orientation of curves is not important)?","I would like to compute the linking number of a link in $\mathbb{R}^3$ which consists of two disjoint curves $c_a$ and $c_b$. Define $z=x_1+\sqrt{-1}x_2$ and $v=x_3+\sqrt{-1}x_4$ where $(x_1,x_2,x_3, x_4)\in\mathbb{R}^4$ so that $\mathbb{R}^4\cong\mathbb{C}^2$. Let $a,b\in\mathbb{C}$ and let $L_a=\{(z,v)\in\mathbb{C}^2|v=az\}\subset\mathbb{C}^2$ and $L_b=\{(z,v)\in\mathbb{C}^2|v=bz\}\subset\mathbb{C}^2$ be two complex lines in the complex plane. Also let $C_a=S^3\cap L_a$ and $C_b=S^3\cap L_b$ where $S^3$ is the 3-sphere. How do I calculate the integral (the linking number) $$L(c_a, c_b) = \frac{1}{4\pi}\int_{0}^{2\pi}\int_{0}^{2\pi}\frac{(c_a(t)-c_b(s),\dot{c_a}(t), \dot{c_b}(s))}{|c_a(t)-c_b(s)|^3}dtds$$ where $c_a=p(C_a)$ and $c_b=p(C_b)$ and $p$ is the stereographic projection defined by $$p(x_1, x_2, x_3, x_4)=\frac{1}{1-x_4}(x_1, x_2, x_3, 0)$$ if $L(c_a, c_b)\neq 0$ (the orientation of curves is not important)?",,"['differential-geometry', 'curves']"
20,Riemannian metric and geodesics on a cone,Riemannian metric and geodesics on a cone,,"If we are given a surface S given by $z^2 = a(x^2 + y^2)$ , $z>0$ . I want to find the Riemannian metric of the cone and an explicit formula for the geodesics. I parametrise it by $\sigma \colon U \to S$ where $U$ is an open subset of $\mathbb{R}^2$ . $U = \{(u,v): 0<u<2\pi, 0<v<\infty\}$ . $\sigma (u,v) = (v \sin(u), v \cos(u), \sqrt{a}v)$ is a smooth parametrisation of the cone minus a line. We can show that the Riemannian metric is given by $E=v^2, F=0, G=1+a$ . To solve the geodesic ODEs, we find that given a curve $\gamma = (x(t), y(t)) \colon [a,b] \to U$ $$y^2\dot x = c$$ $$(1+a)\ddot y = y\dot x^2$$ I am lookin for an answer as to whether what I have done so far is correct and to complete the argument.","If we are given a surface S given by , . I want to find the Riemannian metric of the cone and an explicit formula for the geodesics. I parametrise it by where is an open subset of . . is a smooth parametrisation of the cone minus a line. We can show that the Riemannian metric is given by . To solve the geodesic ODEs, we find that given a curve I am lookin for an answer as to whether what I have done so far is correct and to complete the argument.","z^2 = a(x^2 + y^2) z>0 \sigma \colon U \to S U \mathbb{R}^2 U = \{(u,v): 0<u<2\pi, 0<v<\infty\} \sigma (u,v) = (v \sin(u), v \cos(u), \sqrt{a}v) E=v^2, F=0, G=1+a \gamma = (x(t), y(t)) \colon [a,b] \to U y^2\dot x = c (1+a)\ddot y = y\dot x^2","['geometry', 'differential-geometry', 'riemannian-geometry']"
21,A cohomology or homology associated to a Riemannian manifold or a dynamical system,A cohomology or homology associated to a Riemannian manifold or a dynamical system,,"I  would  like  to know  whether  the  following co boundary or  boundary maps can  introduce some new kinds of cohomology or  homology which contains  some  non trivial, new,  finite  dimensional  and  helpful information  about the  manifold or  the  dynamics of  a vector  field on it. All maps $\phi$  described below are  defined on the chain of  differential  forms on a  manifold $M$  which obviously   satisfy $\phi \circ \phi=0$. In this  question, to sake finite  dimensionality of  resulting cohomology or  homology, instead of  consideration of  the  whole  complex $\Omega^*(M)$,  we are flexible  to consider   an appropriate sub complex of $\Omega^*(M)$. Each operator  $\phi$ listed below    can  suggest  some  subcomplex  as  domain of definition of  $\phi$. Let  $M$  be  a  Riemannian  manifold with  Laplace operator $\Delta$ and  $X$ be a  vector  field  on $M$. Our differential  maps(coboundary or  boundary maps) are  the  following maps. The first $2$  maps  depends  on the  Riemannian structure  and  the last $2$  maps, which decrease the degree by 2,   depend  on the  vector  fields $X$. Suggestion for  $\phi:$ The  map $\phi$ is: 1)$d\circ \Delta$ 2)$d^* \circ \Delta$ 3)$d^*\circ L_X \circ d^*$ 4)$i_X\circ \Delta \circ i_X$ The operator  $L_X$ is the  Lie derivative operator. The operator $i_X:\Omega^i(M) \to \Omega^{i-1}(M)$ is the  interior product and  $d^*$ is  the  codifferential operator.","I  would  like  to know  whether  the  following co boundary or  boundary maps can  introduce some new kinds of cohomology or  homology which contains  some  non trivial, new,  finite  dimensional  and  helpful information  about the  manifold or  the  dynamics of  a vector  field on it. All maps $\phi$  described below are  defined on the chain of  differential  forms on a  manifold $M$  which obviously   satisfy $\phi \circ \phi=0$. In this  question, to sake finite  dimensionality of  resulting cohomology or  homology, instead of  consideration of  the  whole  complex $\Omega^*(M)$,  we are flexible  to consider   an appropriate sub complex of $\Omega^*(M)$. Each operator  $\phi$ listed below    can  suggest  some  subcomplex  as  domain of definition of  $\phi$. Let  $M$  be  a  Riemannian  manifold with  Laplace operator $\Delta$ and  $X$ be a  vector  field  on $M$. Our differential  maps(coboundary or  boundary maps) are  the  following maps. The first $2$  maps  depends  on the  Riemannian structure  and  the last $2$  maps, which decrease the degree by 2,   depend  on the  vector  fields $X$. Suggestion for  $\phi:$ The  map $\phi$ is: 1)$d\circ \Delta$ 2)$d^* \circ \Delta$ 3)$d^*\circ L_X \circ d^*$ 4)$i_X\circ \Delta \circ i_X$ The operator  $L_X$ is the  Lie derivative operator. The operator $i_X:\Omega^i(M) \to \Omega^{i-1}(M)$ is the  interior product and  $d^*$ is  the  codifferential operator.",,"['differential-geometry', 'riemannian-geometry', 'dynamical-systems', 'homology-cohomology', 'smooth-manifolds']"
22,Is this an example of a regular surface with planar point that is strictly locally convex?,Is this an example of a regular surface with planar point that is strictly locally convex?,,"Definition of locally convex: (Definition) (Local Convexity and Curvature). A surface $S\subset \mathbb{R}^3$ is locally convex at a point $p\in S$ if there exists a neighborhood $V \subset S$ of $p$ such that $V$ is contained in one of the closed half-spaces determined by $T_p(S) $ in $\mathbb{R}^3$. If, in addition, $V$ has only one common point with $T_p(S)$, then $S$ is called strictly locally convex at $p$. Consider the surface $S \subset \mathbb{R}^3$ generated by revolving the function $z = x^4$ about the $z$ axis. Then this surface can be parameterized by $f(x,y) = (x,y,(x^2+y^2)^2)$. which has zero normal curvature at $(0,0,0)$, in every direction, in particular, the principal direction, so it must be a planar point. Yet, we know that every point is above the $z$ axis, so it's strictly locally convex. So strictly locally convexity at a point does not demand that the principal curvature need to be non-zero. Is this right?","Definition of locally convex: (Definition) (Local Convexity and Curvature). A surface $S\subset \mathbb{R}^3$ is locally convex at a point $p\in S$ if there exists a neighborhood $V \subset S$ of $p$ such that $V$ is contained in one of the closed half-spaces determined by $T_p(S) $ in $\mathbb{R}^3$. If, in addition, $V$ has only one common point with $T_p(S)$, then $S$ is called strictly locally convex at $p$. Consider the surface $S \subset \mathbb{R}^3$ generated by revolving the function $z = x^4$ about the $z$ axis. Then this surface can be parameterized by $f(x,y) = (x,y,(x^2+y^2)^2)$. which has zero normal curvature at $(0,0,0)$, in every direction, in particular, the principal direction, so it must be a planar point. Yet, we know that every point is above the $z$ axis, so it's strictly locally convex. So strictly locally convexity at a point does not demand that the principal curvature need to be non-zero. Is this right?",,['differential-geometry']
23,Fibers and total spaces of vector bundles from sheaf theoretic approach.,Fibers and total spaces of vector bundles from sheaf theoretic approach.,,"I am interested in sheaf theory and am slowly working towards familiarizing myself with it. This question is to further this understanding. Let $\pi:E\rightarrow M$ be a finite-rank real vector bundle over the smooth real manifold $M$. Let $$ \Gamma_E:U\in\tau_M\mapsto\Gamma(E|_U) $$denote the sheaf of smooth sections of $E$, and $\mathcal F_M:U\mapsto C^\infty(U)$ the sheaf of smooth functions. As far as I am aware most (or is it all?) information about the vector bundle is contained within $\Gamma_E$. Moreover, reading the wikipedia section about Étalé spaces and stalks , I get the impression that constructing the Étalé space from the stalks is very similar to constructing the total space of a fiber bundle from its fibers. However, the stalk of the sheaf $\Gamma_E$ at $p\in M$ is not $E_p$ but instead the germ of smooth sections of $E$ at $p$. The germs clearly contain more information, as they also contain information about the bundle on all infinitesimal neighborhoods of $p$, while the fibers only contain information about the bundle at $p$. So the questions are: Is there any sheaf-theoretic way to construct the fiber spaces $E_p$ from the sheaf $\Gamma_E$? How is the étalé space of $\Gamma_E$ related to the total space $E$ of the vector bundle?","I am interested in sheaf theory and am slowly working towards familiarizing myself with it. This question is to further this understanding. Let $\pi:E\rightarrow M$ be a finite-rank real vector bundle over the smooth real manifold $M$. Let $$ \Gamma_E:U\in\tau_M\mapsto\Gamma(E|_U) $$denote the sheaf of smooth sections of $E$, and $\mathcal F_M:U\mapsto C^\infty(U)$ the sheaf of smooth functions. As far as I am aware most (or is it all?) information about the vector bundle is contained within $\Gamma_E$. Moreover, reading the wikipedia section about Étalé spaces and stalks , I get the impression that constructing the Étalé space from the stalks is very similar to constructing the total space of a fiber bundle from its fibers. However, the stalk of the sheaf $\Gamma_E$ at $p\in M$ is not $E_p$ but instead the germ of smooth sections of $E$ at $p$. The germs clearly contain more information, as they also contain information about the bundle on all infinitesimal neighborhoods of $p$, while the fibers only contain information about the bundle at $p$. So the questions are: Is there any sheaf-theoretic way to construct the fiber spaces $E_p$ from the sheaf $\Gamma_E$? How is the étalé space of $\Gamma_E$ related to the total space $E$ of the vector bundle?",,"['differential-geometry', 'algebraic-geometry', 'sheaf-theory', 'vector-bundles']"
24,Does non vanishing Jacobian implies injectivity?,Does non vanishing Jacobian implies injectivity?,,"Let $F:\mathbb{R}^{2}\to \mathbb{R}^{2}$ be a smooth map where its Jacobian $$ Jf(x, y) = \det\begin{pmatrix}\frac{\partial F_{1}}{\partial x} & \frac{\partial{F_{1}}}{\partial y}  \\ \frac{\partial F_{2}}{\partial x} & \frac{\partial F_{2}}{\partial y}\end{pmatrix} $$ is nonzero everywhere. Is it true that $F$ is injective? Also, if it is true, if $F$ is homeomorphism, then is it diffeomorphism? This is true for smooth maps $F:\mathbb{R}\to \mathbb{R}$, but I believe there exists counterexamples for higher dimensional case. But I can't find it.","Let $F:\mathbb{R}^{2}\to \mathbb{R}^{2}$ be a smooth map where its Jacobian $$ Jf(x, y) = \det\begin{pmatrix}\frac{\partial F_{1}}{\partial x} & \frac{\partial{F_{1}}}{\partial y}  \\ \frac{\partial F_{2}}{\partial x} & \frac{\partial F_{2}}{\partial y}\end{pmatrix} $$ is nonzero everywhere. Is it true that $F$ is injective? Also, if it is true, if $F$ is homeomorphism, then is it diffeomorphism? This is true for smooth maps $F:\mathbb{R}\to \mathbb{R}$, but I believe there exists counterexamples for higher dimensional case. But I can't find it.",,['differential-geometry']
25,Excercise 1.75 from Manifolds and Differential Geometry,Excercise 1.75 from Manifolds and Differential Geometry,,"I came across this exercise Exercise 1.75 Manifolds and Differential Geometry by Jeffrey M. Lee which states: Let M be a smooth manifold. Let K be a closed subset of M and O an   open subset containing K. Show that there exists a smooth function   $\beta$ on M that is identically equal to 1 on K, takes values in the   interval [0,1], and has compact support in O. How can this be true? Set $M = \mathbb{R}$ and $K = \mathbb{Z}$ and let O be the union of small balls, one around each integer and none overlapping. How can the support of $\beta$ be compact then? It cant possibly be bounded since it contains $\mathbb{Z}$.","I came across this exercise Exercise 1.75 Manifolds and Differential Geometry by Jeffrey M. Lee which states: Let M be a smooth manifold. Let K be a closed subset of M and O an   open subset containing K. Show that there exists a smooth function   $\beta$ on M that is identically equal to 1 on K, takes values in the   interval [0,1], and has compact support in O. How can this be true? Set $M = \mathbb{R}$ and $K = \mathbb{Z}$ and let O be the union of small balls, one around each integer and none overlapping. How can the support of $\beta$ be compact then? It cant possibly be bounded since it contains $\mathbb{Z}$.",,"['differential-geometry', 'smooth-manifolds']"
26,Meaning of $\int_{T_xM} f(z) \ dz$,Meaning of,\int_{T_xM} f(z) \ dz,"Question So I'm from an engineering and recently learned about integrating on riemannian manifolds. However, I have been faced with the notation $$\int _{T_xM} f(z) \ dz,$$ where $M$ is a Riemannian manifold and $T_x$ is the tangent space at some point $x$. Note that I have learned that $T_xM$ is the space of all tangent vectors at $x$. Can anyone say what this integration notation means? I cannot find any references online. I have been taught that if $M$ is a Riemannian manifold then $$\int_M f=\int_{\mathbb{R}^n}f \sqrt{\mathrm{det}(A^tA)} \ dx_1\ldots,dx_n$$ where $A$ is the jacobian (I think).","Question So I'm from an engineering and recently learned about integrating on riemannian manifolds. However, I have been faced with the notation $$\int _{T_xM} f(z) \ dz,$$ where $M$ is a Riemannian manifold and $T_x$ is the tangent space at some point $x$. Note that I have learned that $T_xM$ is the space of all tangent vectors at $x$. Can anyone say what this integration notation means? I cannot find any references online. I have been taught that if $M$ is a Riemannian manifold then $$\int_M f=\int_{\mathbb{R}^n}f \sqrt{\mathrm{det}(A^tA)} \ dx_1\ldots,dx_n$$ where $A$ is the jacobian (I think).",,['differential-geometry']
27,kernel of $1$-form defines a distribution,kernel of -form defines a distribution,1,"Consider two vector fields $F_1,F_2$ of $\mathbb{R}^3$ and define the distribution $$D(q) =\operatorname{span}\left\{F_1(q),F_2(q)\right\}=\left\{a(q)F_1(q)+b(q)F_2(q),\; a,b \in \mathcal{C}^\infty\right\}$$ Suppose $q=(x,y,z)$ such that  $$ \det(F_1(q),F_2(q),[F_1,F_2](q))=0. $$ Why is there $\alpha$ such that $D$ is isomorphic to $\ker \; \alpha$ and $\alpha = y\, dx +dz$ ?","Consider two vector fields $F_1,F_2$ of $\mathbb{R}^3$ and define the distribution $$D(q) =\operatorname{span}\left\{F_1(q),F_2(q)\right\}=\left\{a(q)F_1(q)+b(q)F_2(q),\; a,b \in \mathcal{C}^\infty\right\}$$ Suppose $q=(x,y,z)$ such that  $$ \det(F_1(q),F_2(q),[F_1,F_2](q))=0. $$ Why is there $\alpha$ such that $D$ is isomorphic to $\ker \; \alpha$ and $\alpha = y\, dx +dz$ ?",,"['differential-geometry', 'determinant', 'differential-forms', 'vector-fields']"
28,How many curvatures determine a manifold's embedding?,How many curvatures determine a manifold's embedding?,,"It is easy to see that curvature determines a plane curve up to rigid motions. For space curves, you need two quantities: the curvature and the torsion. The latter can be observed from the Frenet-Serret equations $$\left[\begin{array}{c}T'\\N'\\B'\end{array}\right] = \left[\omega\right]_\times \left[\begin{array}{c}T\\N\\B\end{array}\right]$$ where $[\omega]_{\times}\in\mathfrak{so}(3)$ has three degrees of freedom; however, one of these is redundant (my intuition for this is that the twist of the normal and binormal about the tangent is irrelevant to describing the shape of the curve.) For a surface in 3D, the second fundamental form is enough to determine the surface embedding up to rigid motions; but surely not all three distinct entries of the second fundamental form are needed? Can one recover the embedding (again, up to rigid motions) knowing only the mean curvature, for instance? In general, given a $d$-dimensional Riemannian manifold, how many ""curvatures"" must be known at each point on the manifold to uniquely determine an embedding in $\mathbb{R}^n$ up to rigid motions (isometries of the ambient space)?","It is easy to see that curvature determines a plane curve up to rigid motions. For space curves, you need two quantities: the curvature and the torsion. The latter can be observed from the Frenet-Serret equations $$\left[\begin{array}{c}T'\\N'\\B'\end{array}\right] = \left[\omega\right]_\times \left[\begin{array}{c}T\\N\\B\end{array}\right]$$ where $[\omega]_{\times}\in\mathfrak{so}(3)$ has three degrees of freedom; however, one of these is redundant (my intuition for this is that the twist of the normal and binormal about the tangent is irrelevant to describing the shape of the curve.) For a surface in 3D, the second fundamental form is enough to determine the surface embedding up to rigid motions; but surely not all three distinct entries of the second fundamental form are needed? Can one recover the embedding (again, up to rigid motions) knowing only the mean curvature, for instance? In general, given a $d$-dimensional Riemannian manifold, how many ""curvatures"" must be known at each point on the manifold to uniquely determine an embedding in $\mathbb{R}^n$ up to rigid motions (isometries of the ambient space)?",,"['differential-geometry', 'riemannian-geometry']"
29,"If $f$ preserves orientation locally, then $f$ preserves orientation globally","If  preserves orientation locally, then  preserves orientation globally",f f,"Suppose $f:X\to Y$ is a diffeomorphism of connected oriented manifolds   with boundary. Show that if $df_x: T_x(X)\to T_{f(x)}(Y)$ preserves   orientation at one point, then $f$ preserves orientation globally. What I can see is that since $f$ is a diffeomorphism, each $df_x$ is an isomorphism. But the concept of orientation preserving linear map remains not so clear to me (see this question ). Is the fact that $df_x$ preserves orientation amounts to saying that $\det df_x > 0$? After that, am I supposed to use some kind of continuity of $x\mapsto df_x$?","Suppose $f:X\to Y$ is a diffeomorphism of connected oriented manifolds   with boundary. Show that if $df_x: T_x(X)\to T_{f(x)}(Y)$ preserves   orientation at one point, then $f$ preserves orientation globally. What I can see is that since $f$ is a diffeomorphism, each $df_x$ is an isomorphism. But the concept of orientation preserving linear map remains not so clear to me (see this question ). Is the fact that $df_x$ preserves orientation amounts to saying that $\det df_x > 0$? After that, am I supposed to use some kind of continuity of $x\mapsto df_x$?",,"['real-analysis', 'linear-algebra', 'differential-geometry', 'manifolds', 'differential-topology']"
30,Computing fundamental vector field,Computing fundamental vector field,,"Let us fix $k_{1},\cdots,k_{n}\in \mathbb{Z}$, $T^n=\big\{(z_{1},\cdots,z_{n})\mid |z_{k}|=1,k\in \{1,\cdots,k\}\big\}$ and $w=\frac{i}{2}\sum dz_{i}\wedge d\overline{z_{i}}=\sum dx_{i}\wedge dy_{i}= \sum r_{i}dr_{i}\wedge d\theta_{i}$ the symplectic form on $\mathbb{C}^n$. I am trying to prove that $\varphi\colon T^n\longrightarrow \text{Diff}(\mathbb{C}^n)$ where $$\varphi_{(t_{1},\cdots,t_{n})}(z_{1},\cdots,z_{n})=(t_{1}^{k_{1}}z_{1},\cdots,t_{n}^{k_{n}}z_{n})$$ is a hamiltonian action with moment map given by $\mu \colon \mathbb{C}^n\longrightarrow (t^n)^*\cong\mathbb{R}^n$, $$\mu(z_{1},\cdots,z_{n})=-\frac{1}{2}(k_{1}|z_{1}|^2,\cdots, k_{n}|z_{n}|^2).$$ I have already proven the equivariance, so I need to show that for all $X\in t^n\cong \mathbb{R}^n$, $$d\mu^x=\iota_{X^\#}\omega.$$ Suppose that $X=(a_{1},\cdots,a_{n})\in \mathbb{R}^n$. Then, $\mu^{X}((z_{1},\cdots,z_{n}))=-\frac{a_{1}k_{1}}{2}|z_{1}|^2-\cdots-\frac{a_{n}k_{n}}{2}|z_{n}|^2$. Then, $$d\mu^X= -\frac{a_{1}k_{1}}{2}\overline{z_{1}}\frac{\partial}{\partial z_{1}}-\cdots-\frac{a_{n}k_{n}}{2}\overline{z_{n}}\frac{\partial}{\partial z_{n}}-\frac{a_{1}k_{1}}{2}z_{1}\frac{\partial}{\partial \overline{z_{1}}}-\frac{a_{n}k_{n}}{2}z_{n}\frac{\partial}{\partial \overline{z_{n}}}.$$ Now, I have problems when computing $X_{(z_{1},\cdots,z_{n})}^{\#}$ for $(z_{1},\cdots,z_{n})\in \mathbb{C}^{n}.$ I should take a curve in $T^n$ that crosses the identity at $0$ and such that the derivative at $0$ is $(a_{1},\cdots,a_{n})$. I have taken $(e^{a_{1}ti},\cdots,e^{a_{n}ti})$. Then, I have to compute the derivative at 0 of $\varphi_{(e^{a_{1}ti},\cdots,e^{a_{n}ti})}(z_{1},\cdots,z_{n})$ which is $(k_{1}a_{1}z_{1}i,\cdots,k_{n}a_{n}z_{n}i$). I do not know how to continue... I think that the problem is that I do not understand how is that written is terms of the basis of $T_{(z_{1},\cdots,z_{n})}\mathbb{C}^n\cong \mathbb{R}^{2n}$. Can anyone help me, please? $\mathbf{EDIT}$: I believe that it is not correct to take the curve $(e^{a_{1}ti},\cdots,e^{a_{n}ti})$ because its derivative at $0$ is $i(a_{1},\cdots,a_{n})$.","Let us fix $k_{1},\cdots,k_{n}\in \mathbb{Z}$, $T^n=\big\{(z_{1},\cdots,z_{n})\mid |z_{k}|=1,k\in \{1,\cdots,k\}\big\}$ and $w=\frac{i}{2}\sum dz_{i}\wedge d\overline{z_{i}}=\sum dx_{i}\wedge dy_{i}= \sum r_{i}dr_{i}\wedge d\theta_{i}$ the symplectic form on $\mathbb{C}^n$. I am trying to prove that $\varphi\colon T^n\longrightarrow \text{Diff}(\mathbb{C}^n)$ where $$\varphi_{(t_{1},\cdots,t_{n})}(z_{1},\cdots,z_{n})=(t_{1}^{k_{1}}z_{1},\cdots,t_{n}^{k_{n}}z_{n})$$ is a hamiltonian action with moment map given by $\mu \colon \mathbb{C}^n\longrightarrow (t^n)^*\cong\mathbb{R}^n$, $$\mu(z_{1},\cdots,z_{n})=-\frac{1}{2}(k_{1}|z_{1}|^2,\cdots, k_{n}|z_{n}|^2).$$ I have already proven the equivariance, so I need to show that for all $X\in t^n\cong \mathbb{R}^n$, $$d\mu^x=\iota_{X^\#}\omega.$$ Suppose that $X=(a_{1},\cdots,a_{n})\in \mathbb{R}^n$. Then, $\mu^{X}((z_{1},\cdots,z_{n}))=-\frac{a_{1}k_{1}}{2}|z_{1}|^2-\cdots-\frac{a_{n}k_{n}}{2}|z_{n}|^2$. Then, $$d\mu^X= -\frac{a_{1}k_{1}}{2}\overline{z_{1}}\frac{\partial}{\partial z_{1}}-\cdots-\frac{a_{n}k_{n}}{2}\overline{z_{n}}\frac{\partial}{\partial z_{n}}-\frac{a_{1}k_{1}}{2}z_{1}\frac{\partial}{\partial \overline{z_{1}}}-\frac{a_{n}k_{n}}{2}z_{n}\frac{\partial}{\partial \overline{z_{n}}}.$$ Now, I have problems when computing $X_{(z_{1},\cdots,z_{n})}^{\#}$ for $(z_{1},\cdots,z_{n})\in \mathbb{C}^{n}.$ I should take a curve in $T^n$ that crosses the identity at $0$ and such that the derivative at $0$ is $(a_{1},\cdots,a_{n})$. I have taken $(e^{a_{1}ti},\cdots,e^{a_{n}ti})$. Then, I have to compute the derivative at 0 of $\varphi_{(e^{a_{1}ti},\cdots,e^{a_{n}ti})}(z_{1},\cdots,z_{n})$ which is $(k_{1}a_{1}z_{1}i,\cdots,k_{n}a_{n}z_{n}i$). I do not know how to continue... I think that the problem is that I do not understand how is that written is terms of the basis of $T_{(z_{1},\cdots,z_{n})}\mathbb{C}^n\cong \mathbb{R}^{2n}$. Can anyone help me, please? $\mathbf{EDIT}$: I believe that it is not correct to take the curve $(e^{a_{1}ti},\cdots,e^{a_{n}ti})$ because its derivative at $0$ is $i(a_{1},\cdots,a_{n})$.",,"['differential-geometry', 'symplectic-geometry']"
31,Confusion about notation in do Carmo's Riemannian Geometry book,Confusion about notation in do Carmo's Riemannian Geometry book,,"This comes from page 125 in the chapter on isometric immersions. Setup: $f:M \rightarrow \bar{M}$ is an immersion. For each $p \in M$ there exists a neibhborhood $U \subset M$ of $p$ such that $f(U) \subset \bar{M}$ is a submanifold of $\bar{M}$ . He says to simplify the notation we will identify $U$ with $f(U)$ and each $v \in T_q M$ , $q \in U$ with $df_q v \in T_{f(q)}\bar{M}$ . Here is where I get confused: He says, for each $p \in M$ , the inner product on $T_p \bar{M}$ splits $T_p\bar{M}$ into the direct sum $T_p\bar{M}=T_pM \oplus (T_pM)^{\perp}$ . Further, if $v \in T_p \bar{M}$ , $p \in M$ , we can write $v=v^{T}+v^{N}$ where $v^T \in T_p M$ and $v^N \in (T_p M)^\perp$ . He says such a splitting is clearly differentiable, in the sense that the mappings $(p,v) \mapsto (p,v^T)$ and $(p,v)\mapsto (p,v^N)$ of $T\bar{M}$ into $T\bar{M}$ are clearly differentiable. My issue with this: I think every instance of $T_p \bar{M}$ should be replaced by $T_{f(p)}\bar{M}$ ,(i.e. we identify $T_p M$ with $df_p(T_p M) \subset T_f(p)\bar{M})$ , unless if $p \in U$ then we could make the identifications that he stated which would make more sense, however, he says this for $p \in M$ , not just $p \in U$ , and He made the ""mistake"" of using $p$ several times which makes me believe that he meant to. So what is going on here? Is he just being incredibly sloppy or am I missing something here?","This comes from page 125 in the chapter on isometric immersions. Setup: is an immersion. For each there exists a neibhborhood of such that is a submanifold of . He says to simplify the notation we will identify with and each , with . Here is where I get confused: He says, for each , the inner product on splits into the direct sum . Further, if , , we can write where and . He says such a splitting is clearly differentiable, in the sense that the mappings and of into are clearly differentiable. My issue with this: I think every instance of should be replaced by ,(i.e. we identify with , unless if then we could make the identifications that he stated which would make more sense, however, he says this for , not just , and He made the ""mistake"" of using several times which makes me believe that he meant to. So what is going on here? Is he just being incredibly sloppy or am I missing something here?","f:M \rightarrow \bar{M} p \in M U \subset M p f(U) \subset \bar{M} \bar{M} U f(U) v \in T_q M q \in U df_q v \in T_{f(q)}\bar{M} p \in M T_p \bar{M} T_p\bar{M} T_p\bar{M}=T_pM \oplus (T_pM)^{\perp} v \in T_p \bar{M} p \in M v=v^{T}+v^{N} v^T \in T_p M v^N \in (T_p M)^\perp (p,v) \mapsto (p,v^T) (p,v)\mapsto (p,v^N) T\bar{M} T\bar{M} T_p \bar{M} T_{f(p)}\bar{M} T_p M df_p(T_p M) \subset T_f(p)\bar{M}) p \in U p \in M p \in U p","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
32,Helmholtz-like decomposition for the metric tensor.,Helmholtz-like decomposition for the metric tensor.,,"Question: Does there exist a Helmholtz-like decomposition of the metric tensor into holonomic and anholonomic counterparts? Motivation: I know that for a given tensor function $F$, one can find a vector-valued function $u$ and a tensor-valued function $A$ such that $F=Du+\text{Curl}A$. In this case, the requirement $\text{Curl}F=0$ is an integrability condition for $F$. What I wonder is if an analogous conclusion holds for a metric tensor $G$. In this case, the integrability condition is $\text{Riem}(G)=0$. When this is satisfied, there exists a vector-valued function $u$ such that $G=(Du)^T(Du)$. But what if $\text{Riem}(G)\neq 0$? For given $G$, would there exist a vector valued function $u$ and a (symmetric) tensor function $A$ such that  $$ G=(Du)^T(Du) + \text{Riem}(A)\qquad (\text{or similar}?)  $$","Question: Does there exist a Helmholtz-like decomposition of the metric tensor into holonomic and anholonomic counterparts? Motivation: I know that for a given tensor function $F$, one can find a vector-valued function $u$ and a tensor-valued function $A$ such that $F=Du+\text{Curl}A$. In this case, the requirement $\text{Curl}F=0$ is an integrability condition for $F$. What I wonder is if an analogous conclusion holds for a metric tensor $G$. In this case, the integrability condition is $\text{Riem}(G)=0$. When this is satisfied, there exists a vector-valued function $u$ such that $G=(Du)^T(Du)$. But what if $\text{Riem}(G)\neq 0$? For given $G$, would there exist a vector valued function $u$ and a (symmetric) tensor function $A$ such that  $$ G=(Du)^T(Du) + \text{Riem}(A)\qquad (\text{or similar}?)  $$",,"['differential-geometry', 'tensors']"
33,Convergence of smooth surfaces in $\mathbb{R}^3$,Convergence of smooth surfaces in,\mathbb{R}^3,"Let $\{\Sigma_n\}_{n \in \mathbb{N}}$ be a sequence of $C^\infty$, complete, properly embedded surfaces in $\mathbb{R}^3$ such that $0 \in \Sigma_n$ for every $n \in \mathbb N$ and $\{\Sigma_n\}_{n \in \mathbb{N}}$ is converging in the $C^k$ topology (with $k$ arbitrary large) on compact sets to a smooth complete surface $\Sigma$ passing through $0$. I wonder what kind of property $\Sigma_\infty$ can inherit from the sequence. More precisely, if $\Sigma_n$ is the graphical, is it possible to show that $\Sigma_\infty$ is graphical as well? Of course one needs to be careful.  Indeed it is easy to construct a sequence of functions $f_n: \{(x, y, z) : z = 0\}  \to \mathbb R$ such that $\Sigma_n := \text{graph}(u)$ satisfies the above properties but $\Sigma_\infty$ is not the graph of a function from $\{(x, y, z) : z = 0\} $. But one might still hope to  prove that $\Sigma_\infty$ is graphical but w.r.t. another direction. The example I have in mind is the following. Consider the function $f(x,y) = x^2 + y^2$. Consider the following sequence of points on its graph: $$ p_n \quad \colon =  \quad (n, 0, n^2). $$ Consider now the sequence  $$ \Sigma_n \quad \colon= \quad \text{graph}(f) - p_n. $$ Observe that every $\Sigma_n$ is a vertical graph and they are converging  to a vertical plane, which is not a vertical graph, but still a graph w.r.t. to another direction. Any help will be highly apreciated! EDIT : I actually realized that it is possible to build a counter-example where $\Sigma_n$ are graphical, but $\Sigma_\infty$ is not. On the other hand I think to have a proof of the following: weaker statement : If the $\Sigma_n$ are graphical, then the Gauss map of $\Sigma_\infty$ is contained in a closed hemisphere.","Let $\{\Sigma_n\}_{n \in \mathbb{N}}$ be a sequence of $C^\infty$, complete, properly embedded surfaces in $\mathbb{R}^3$ such that $0 \in \Sigma_n$ for every $n \in \mathbb N$ and $\{\Sigma_n\}_{n \in \mathbb{N}}$ is converging in the $C^k$ topology (with $k$ arbitrary large) on compact sets to a smooth complete surface $\Sigma$ passing through $0$. I wonder what kind of property $\Sigma_\infty$ can inherit from the sequence. More precisely, if $\Sigma_n$ is the graphical, is it possible to show that $\Sigma_\infty$ is graphical as well? Of course one needs to be careful.  Indeed it is easy to construct a sequence of functions $f_n: \{(x, y, z) : z = 0\}  \to \mathbb R$ such that $\Sigma_n := \text{graph}(u)$ satisfies the above properties but $\Sigma_\infty$ is not the graph of a function from $\{(x, y, z) : z = 0\} $. But one might still hope to  prove that $\Sigma_\infty$ is graphical but w.r.t. another direction. The example I have in mind is the following. Consider the function $f(x,y) = x^2 + y^2$. Consider the following sequence of points on its graph: $$ p_n \quad \colon =  \quad (n, 0, n^2). $$ Consider now the sequence  $$ \Sigma_n \quad \colon= \quad \text{graph}(f) - p_n. $$ Observe that every $\Sigma_n$ is a vertical graph and they are converging  to a vertical plane, which is not a vertical graph, but still a graph w.r.t. to another direction. Any help will be highly apreciated! EDIT : I actually realized that it is possible to build a counter-example where $\Sigma_n$ are graphical, but $\Sigma_\infty$ is not. On the other hand I think to have a proof of the following: weaker statement : If the $\Sigma_n$ are graphical, then the Gauss map of $\Sigma_\infty$ is contained in a closed hemisphere.",,"['calculus', 'differential-geometry', 'smooth-manifolds']"
34,Derivative of the symplectic action functional,Derivative of the symplectic action functional,,"I try to find in a direct calculation the first variation of the symplectic action functional. The action functional sends any smooth path $\gamma$ in $T^*M$ to $$\mathcal{A}_H(\gamma)=\int_0^1 (\lambda(\dot{\gamma}(t))+H_t(\gamma(t)))dt$$ where $\lambda$ is the Liuoville form on the cotangent bundle ($\lambda=pdq$ such that the symplectic form is $\omega=-d\lambda$). Suppose $\delta \gamma$ is a vector field along the path $\gamma$. The variation of $\mathcal{A}_H$ at $\gamma$ in direction $\delta \gamma$ is $$d\mathcal{A}_H(\gamma)\delta \gamma=\int_0^1\Big (-\omega(\dot{\gamma}(t),\delta \gamma(t))+dH_t(\delta\gamma(t))\Big )dt+ \lambda(\delta\gamma(1))-\lambda(\delta\gamma(0))$$ To see this, let $\tilde{\gamma}(s,t)$ be a variation of $\gamma$, i.e. $\gamma(0,t)=\gamma(t)$ and $\left.\frac{\partial}{\partial s}\right \vert _{s=0}  \tilde{\gamma}(s,t)=\delta \gamma(t)$. We calculate now $\left.\frac{\partial}{\partial s}\right\vert_{s=0}\mathcal{A}_H(\tilde{\gamma})$ which is the same as $d\mathcal{A}_H(\gamma)\delta \gamma$. The derivative of the first term in the integral is \begin{align*}  \left.\frac{\partial}{\partial s}\right\vert_{s=0}\lambda_{\tilde{\gamma}(s,t)}\bigg(\frac{\partial}{\partial t}\tilde{\gamma}(s,t)\bigg)&\color{red}=d\lambda_{\gamma(t)}\bigg(\dot{\gamma}(t),\delta \gamma(t)+\frac{\partial}{\partial t}\delta\gamma(t)\bigg)\\&\color{red}=d\lambda_{\gamma(t)}\Big(\dot{\gamma}(t),\delta \gamma(t)\Big)+\frac{\partial}{\partial t}\lambda_{\gamma(t)}(\delta\gamma(t))  \end{align*} whereas the second \begin{align*} \left.\frac{\partial}{\partial s}\right\vert_{s=0}H_t(\tilde{\gamma}(s,t))&=(dH_t)_{\gamma(t)}\bigg (\left.\frac{\partial}{\partial s}\right\vert_{s=0}\tilde{\gamma}(s,t)\bigg)=(dH_t)_{\gamma(t)}(\delta\gamma(t))\\ \end{align*} By the fundamental theorem of integration for the latter term of the first formula we get the formula for the variation. I know my calculations should be correct but can anyone explain precisely what's going on where I marked the equalities red? Is it even correct what I am doing or do I need to introduce a connection? If there is a nice solution via Lie derivative I would be happy as well. I elaborated the formula by some kind of chain rule but only got a result because I know what the result should be.","I try to find in a direct calculation the first variation of the symplectic action functional. The action functional sends any smooth path $\gamma$ in $T^*M$ to $$\mathcal{A}_H(\gamma)=\int_0^1 (\lambda(\dot{\gamma}(t))+H_t(\gamma(t)))dt$$ where $\lambda$ is the Liuoville form on the cotangent bundle ($\lambda=pdq$ such that the symplectic form is $\omega=-d\lambda$). Suppose $\delta \gamma$ is a vector field along the path $\gamma$. The variation of $\mathcal{A}_H$ at $\gamma$ in direction $\delta \gamma$ is $$d\mathcal{A}_H(\gamma)\delta \gamma=\int_0^1\Big (-\omega(\dot{\gamma}(t),\delta \gamma(t))+dH_t(\delta\gamma(t))\Big )dt+ \lambda(\delta\gamma(1))-\lambda(\delta\gamma(0))$$ To see this, let $\tilde{\gamma}(s,t)$ be a variation of $\gamma$, i.e. $\gamma(0,t)=\gamma(t)$ and $\left.\frac{\partial}{\partial s}\right \vert _{s=0}  \tilde{\gamma}(s,t)=\delta \gamma(t)$. We calculate now $\left.\frac{\partial}{\partial s}\right\vert_{s=0}\mathcal{A}_H(\tilde{\gamma})$ which is the same as $d\mathcal{A}_H(\gamma)\delta \gamma$. The derivative of the first term in the integral is \begin{align*}  \left.\frac{\partial}{\partial s}\right\vert_{s=0}\lambda_{\tilde{\gamma}(s,t)}\bigg(\frac{\partial}{\partial t}\tilde{\gamma}(s,t)\bigg)&\color{red}=d\lambda_{\gamma(t)}\bigg(\dot{\gamma}(t),\delta \gamma(t)+\frac{\partial}{\partial t}\delta\gamma(t)\bigg)\\&\color{red}=d\lambda_{\gamma(t)}\Big(\dot{\gamma}(t),\delta \gamma(t)\Big)+\frac{\partial}{\partial t}\lambda_{\gamma(t)}(\delta\gamma(t))  \end{align*} whereas the second \begin{align*} \left.\frac{\partial}{\partial s}\right\vert_{s=0}H_t(\tilde{\gamma}(s,t))&=(dH_t)_{\gamma(t)}\bigg (\left.\frac{\partial}{\partial s}\right\vert_{s=0}\tilde{\gamma}(s,t)\bigg)=(dH_t)_{\gamma(t)}(\delta\gamma(t))\\ \end{align*} By the fundamental theorem of integration for the latter term of the first formula we get the formula for the variation. I know my calculations should be correct but can anyone explain precisely what's going on where I marked the equalities red? Is it even correct what I am doing or do I need to introduce a connection? If there is a nice solution via Lie derivative I would be happy as well. I elaborated the formula by some kind of chain rule but only got a result because I know what the result should be.",,"['differential-geometry', 'symplectic-geometry']"
35,Negative sign in Leibniz Rule,Negative sign in Leibniz Rule,,"For $ w \in  \bigwedge^j(K) $ and $\mu \in  \bigwedge^k(K) $ where $K$ is of dimension $n$, I do understand (or have developed an intuition purely relying on permutations) as to why $$w \wedge \mu = (-1)^{jk}\mu \wedge w$$ However, I am not able to reconcile the signifcance of the negative sign and difference in the exponents (between the above and below expression) in the Leibnitz Rule which dictates that  $$d(w \wedge \mu) =dw \wedge \mu+  (-1)^{j}w \wedge d\mu$$ Is there an explanation that solely relies on permutation and combination which can explain the exponent and the negative sign? (I am able to develop an analogy where the negative can be explained via the following argument.  Assume that the $d$ operator has to jump to go the next variable and each jump results in a change of sign. Consequently to reach $\mu$ it has to make $j$ jumps making the sign to alternate $j$ times. However, I don't know whether it can be considered a mathematical explanation for its behavior.)","For $ w \in  \bigwedge^j(K) $ and $\mu \in  \bigwedge^k(K) $ where $K$ is of dimension $n$, I do understand (or have developed an intuition purely relying on permutations) as to why $$w \wedge \mu = (-1)^{jk}\mu \wedge w$$ However, I am not able to reconcile the signifcance of the negative sign and difference in the exponents (between the above and below expression) in the Leibnitz Rule which dictates that  $$d(w \wedge \mu) =dw \wedge \mu+  (-1)^{j}w \wedge d\mu$$ Is there an explanation that solely relies on permutation and combination which can explain the exponent and the negative sign? (I am able to develop an analogy where the negative can be explained via the following argument.  Assume that the $d$ operator has to jump to go the next variable and each jump results in a change of sign. Consequently to reach $\mu$ it has to make $j$ jumps making the sign to alternate $j$ times. However, I don't know whether it can be considered a mathematical explanation for its behavior.)",,['differential-geometry']
36,Curvature tensor in terms of the metric tensor,Curvature tensor in terms of the metric tensor,,"I have been asked to express the curvature tensor in terms of the metric tensor, with $\mathcal{R}$ being the Riemann curvature tensor, given in terms of the Christoffel symbols of the second kind $${\mathcal R}{^\rho_{\sigma\mu\nu}}=\partial_\mu\Gamma^\rho_{\nu\sigma}-\partial_\nu\Gamma^\rho_{\mu\sigma}+\Gamma^\rho_{\mu\lambda}\Gamma^\lambda_{\nu\sigma}-\Gamma^\rho_{\nu\lambda}\Gamma^{\lambda}_{\mu\sigma}$$ and this at the same time given as $$\Gamma^\mu_{\nu\lambda}=\frac{1}{2}g^{\mu\kappa}\left[ \partial_\nu g_{\lambda\kappa} +\partial_\lambda g_{\nu\kappa} -\partial_\kappa g_{\nu\lambda}\right]$$ I have found this series of formulas in wikipedia, it starts from the top form of the curvature tensor I provided and then goes on to lower the top index with $g_{\gamma\rho}$ and treats it as if it were straighforward. However,  I have, per example, expanded the two terms with first partial derivatives, like: \begin{aligned} \partial_\mu\Gamma^\rho_{\nu\sigma}&=\frac{1}{2}\partial_\mu\left[ g^{\mu\kappa}\partial_\nu g_{\lambda\kappa}+g^{\mu\kappa}\partial_\lambda g_{\nu\kappa}-g^{\mu\kappa}\partial_\kappa g_{\nu\lambda}  \right]\\ & \begin{split}=\frac{1}{2}&\left[ \partial_\mu g^{\mu\kappa}\partial_\nu g_{\lambda\kappa}+g^{\mu\kappa}\partial_\mu\partial_\nu g_{\lambda\kappa} +\partial_\mu g^{\mu\kappa}\partial_\lambda g_{\nu\kappa}\right.\\ &\left.+g^{\mu\kappa}\partial_\mu\partial_\lambda g_{\nu\kappa}-\partial_\mu g^{\mu\kappa}\partial_\kappa g_{\nu\lambda}-g^{\mu\kappa}\partial_\mu\partial_\kappa g_{\nu\lambda} \right] \end{split} \end{aligned} yet from taking together the two expansions, only 6 terms with second partial derivatives show up (no second partials come from the Christoffel symbols), as opposed to the 8 that should show up.  How can I prove the Wikipedia identity? Can I get the lowering metric tensor inside the derivative (as in $\partial_\mu g_{\lambda\rho}\Gamma^{\rho}_{\nu\sigma}$), if so, what would I get? I've never seen a Christoffel symbol contracted with a metric tensor, since once getting the new tensor inside the symbol expansion, I have the same question, can I get the metric tensor inside the partial? Any help will be greatly appreciated.","I have been asked to express the curvature tensor in terms of the metric tensor, with $\mathcal{R}$ being the Riemann curvature tensor, given in terms of the Christoffel symbols of the second kind $${\mathcal R}{^\rho_{\sigma\mu\nu}}=\partial_\mu\Gamma^\rho_{\nu\sigma}-\partial_\nu\Gamma^\rho_{\mu\sigma}+\Gamma^\rho_{\mu\lambda}\Gamma^\lambda_{\nu\sigma}-\Gamma^\rho_{\nu\lambda}\Gamma^{\lambda}_{\mu\sigma}$$ and this at the same time given as $$\Gamma^\mu_{\nu\lambda}=\frac{1}{2}g^{\mu\kappa}\left[ \partial_\nu g_{\lambda\kappa} +\partial_\lambda g_{\nu\kappa} -\partial_\kappa g_{\nu\lambda}\right]$$ I have found this series of formulas in wikipedia, it starts from the top form of the curvature tensor I provided and then goes on to lower the top index with $g_{\gamma\rho}$ and treats it as if it were straighforward. However,  I have, per example, expanded the two terms with first partial derivatives, like: \begin{aligned} \partial_\mu\Gamma^\rho_{\nu\sigma}&=\frac{1}{2}\partial_\mu\left[ g^{\mu\kappa}\partial_\nu g_{\lambda\kappa}+g^{\mu\kappa}\partial_\lambda g_{\nu\kappa}-g^{\mu\kappa}\partial_\kappa g_{\nu\lambda}  \right]\\ & \begin{split}=\frac{1}{2}&\left[ \partial_\mu g^{\mu\kappa}\partial_\nu g_{\lambda\kappa}+g^{\mu\kappa}\partial_\mu\partial_\nu g_{\lambda\kappa} +\partial_\mu g^{\mu\kappa}\partial_\lambda g_{\nu\kappa}\right.\\ &\left.+g^{\mu\kappa}\partial_\mu\partial_\lambda g_{\nu\kappa}-\partial_\mu g^{\mu\kappa}\partial_\kappa g_{\nu\lambda}-g^{\mu\kappa}\partial_\mu\partial_\kappa g_{\nu\lambda} \right] \end{split} \end{aligned} yet from taking together the two expansions, only 6 terms with second partial derivatives show up (no second partials come from the Christoffel symbols), as opposed to the 8 that should show up.  How can I prove the Wikipedia identity? Can I get the lowering metric tensor inside the derivative (as in $\partial_\mu g_{\lambda\rho}\Gamma^{\rho}_{\nu\sigma}$), if so, what would I get? I've never seen a Christoffel symbol contracted with a metric tensor, since once getting the new tensor inside the symbol expansion, I have the same question, can I get the metric tensor inside the partial? Any help will be greatly appreciated.",,"['differential-geometry', 'riemannian-geometry', 'general-relativity']"
37,On the proof of Meusnier's Theorem: Direction of derivative of unit velocity vector,On the proof of Meusnier's Theorem: Direction of derivative of unit velocity vector,,"In Andrew Pressley's ""Elementary Differential Geometry"" (second edition) on page 168 he gives a proof of Meusnier's Theorem, which is stated as follows: Theorem: Let $\mathbf p$ be a point on the surface $\mathcal S$ and let $\mathbf v$ be a unit tangent vector to $\mathcal S$ at $\mathbf p$. Let $\Pi_\theta$ be the plane containing the line through $\mathbf p$ parallel to $\mathbf v$ and making an angle $\theta$ with the tangent plane $T_{\mathbf p}\mathcal S$, and assume that $\Pi_\theta$ is not parallel to $T_{\mathbf p}\mathcal S$. Suppose that $\Pi_\theta$ intersects $S$ in a curve with curvature $\kappa_\theta$. Then $\kappa_\theta\sin\theta$ is independent of $\theta$. The proof is short, and begins as follows: Assume that $\gamma_\theta$ is a unit-speed parametrization of the curve of intersection of $\Pi_\theta$ and $\mathcal S$. Then at $\mathbf p$, $\gamma_\theta' = \pm\mathbf v$, so $\gamma_\theta''$ is perpendicular to $\mathbf v$ $\underline{\text{and is parallel to $\Pi_\theta$}}$. My question is about the underlined statement. How do we know that $\gamma_\theta''$ lies on $\Pi_\theta$? Looking at the diagram given, it seems obvious, in the sense that $\gamma_\theta''$ is parallel to the principle normal to $\gamma_\theta$, which, along with $\gamma_\theta'$ forms the basis for the oscullating plane, which also ""looks"" like the plane $\Pi_\theta$, but other than that heuristic argument I can't formalize why $\gamma_\theta''$ should lie on $\Pi_\theta$. I'm sure its easy, I'm just missing the obvious. Can anyone help out?","In Andrew Pressley's ""Elementary Differential Geometry"" (second edition) on page 168 he gives a proof of Meusnier's Theorem, which is stated as follows: Theorem: Let $\mathbf p$ be a point on the surface $\mathcal S$ and let $\mathbf v$ be a unit tangent vector to $\mathcal S$ at $\mathbf p$. Let $\Pi_\theta$ be the plane containing the line through $\mathbf p$ parallel to $\mathbf v$ and making an angle $\theta$ with the tangent plane $T_{\mathbf p}\mathcal S$, and assume that $\Pi_\theta$ is not parallel to $T_{\mathbf p}\mathcal S$. Suppose that $\Pi_\theta$ intersects $S$ in a curve with curvature $\kappa_\theta$. Then $\kappa_\theta\sin\theta$ is independent of $\theta$. The proof is short, and begins as follows: Assume that $\gamma_\theta$ is a unit-speed parametrization of the curve of intersection of $\Pi_\theta$ and $\mathcal S$. Then at $\mathbf p$, $\gamma_\theta' = \pm\mathbf v$, so $\gamma_\theta''$ is perpendicular to $\mathbf v$ $\underline{\text{and is parallel to $\Pi_\theta$}}$. My question is about the underlined statement. How do we know that $\gamma_\theta''$ lies on $\Pi_\theta$? Looking at the diagram given, it seems obvious, in the sense that $\gamma_\theta''$ is parallel to the principle normal to $\gamma_\theta$, which, along with $\gamma_\theta'$ forms the basis for the oscullating plane, which also ""looks"" like the plane $\Pi_\theta$, but other than that heuristic argument I can't formalize why $\gamma_\theta''$ should lie on $\Pi_\theta$. I'm sure its easy, I'm just missing the obvious. Can anyone help out?",,"['differential-geometry', 'proof-explanation']"
38,Taylor expansion for vector fields on manifolds,Taylor expansion for vector fields on manifolds,,"I have a problem to proof this theorem: ""Lex $X$ a vector field in a differentiable manifold $M$ and $f\in\mathcal{C}^\infty(M\to R)$ $\Rightarrow$ for all $k\in\mathbb{N}$ the map $f\circ\Phi_X^t$ is globally defined on the manifold if the flow $\Phi_X^t$ is complete; alternatively the map is defined in an opportune set $D_t(X)$ and  $f\circ\Phi_X^t=f+tX(f)+ \dfrac{t^2}{2}X^2(f)+...+ \dfrac{t^k}{k!}X^k(f)+O(t^{k+1}).""$ Where $X^k$ is $k$-application of $X$ to $X$. I have a problem to prove by induction that $\dfrac{d^k}{dt^k}(f\circ\Phi_X^t(p))|_t=(X^k(f(\Phi_X^t))$ in a neighbourhood of $0$. For $k=1$ the assertion in prooved because $\dfrac{d}{dt}(f\circ\Phi_X^t(p))|_t=(\Phi_X^t)_{\star,t}(\dfrac{d}{dt}|_t)(f)=(X(f(\Phi_X^t))$, where the last equality follows from the fact that the flow is the unique solution of the Cauchy's problem $\begin{cases}(\Phi_X^t)_{\star,t}(\frac{d}{dt}|_t)(f)=X(f(\Phi_X^t)) & \\ \Phi_X^0=p \end{cases}.$ Supposed true for $n-1$, when i prove for $n$ I have this: $\dfrac{d^k}{dt^k}(f\circ\Phi_X^t(p))|_t=\dfrac{d}{dt}(\dfrac{d^{k-1}}{dt^{k-1}}(f\circ\Phi_X^t)|_t)|_t=\dfrac{d}{dt}(X^{k-1}(f(\Phi_X^{t-1})))|_t$ in a neighbour of $0$. How to complete this? Is possible that I have to use this theorem: ""Let $f:M\to N$ a differentiable map between two differentiable manifolds, $X$ a vector field on $M$ and $Y$ a vector field on $N$ such that $Y(f(q))=f_{\star,q}(X(q))$ $\forall q\in M$. If $f\circ\Phi_X^t$ is an integral curve of $X$ $\Rightarrow f\circ\Phi_X^t $ is an integral curve for $Y$ and in particular $f\circ\Phi_X^t=\Phi_Y^t\circ f.""$ If the answer is yes, how can I show that $X^{k-1}(f(\Phi_X^t))$ is an integral curve for $X$? I do not found a book with this generalized Taylor formula to manifold.","I have a problem to proof this theorem: ""Lex $X$ a vector field in a differentiable manifold $M$ and $f\in\mathcal{C}^\infty(M\to R)$ $\Rightarrow$ for all $k\in\mathbb{N}$ the map $f\circ\Phi_X^t$ is globally defined on the manifold if the flow $\Phi_X^t$ is complete; alternatively the map is defined in an opportune set $D_t(X)$ and  $f\circ\Phi_X^t=f+tX(f)+ \dfrac{t^2}{2}X^2(f)+...+ \dfrac{t^k}{k!}X^k(f)+O(t^{k+1}).""$ Where $X^k$ is $k$-application of $X$ to $X$. I have a problem to prove by induction that $\dfrac{d^k}{dt^k}(f\circ\Phi_X^t(p))|_t=(X^k(f(\Phi_X^t))$ in a neighbourhood of $0$. For $k=1$ the assertion in prooved because $\dfrac{d}{dt}(f\circ\Phi_X^t(p))|_t=(\Phi_X^t)_{\star,t}(\dfrac{d}{dt}|_t)(f)=(X(f(\Phi_X^t))$, where the last equality follows from the fact that the flow is the unique solution of the Cauchy's problem $\begin{cases}(\Phi_X^t)_{\star,t}(\frac{d}{dt}|_t)(f)=X(f(\Phi_X^t)) & \\ \Phi_X^0=p \end{cases}.$ Supposed true for $n-1$, when i prove for $n$ I have this: $\dfrac{d^k}{dt^k}(f\circ\Phi_X^t(p))|_t=\dfrac{d}{dt}(\dfrac{d^{k-1}}{dt^{k-1}}(f\circ\Phi_X^t)|_t)|_t=\dfrac{d}{dt}(X^{k-1}(f(\Phi_X^{t-1})))|_t$ in a neighbour of $0$. How to complete this? Is possible that I have to use this theorem: ""Let $f:M\to N$ a differentiable map between two differentiable manifolds, $X$ a vector field on $M$ and $Y$ a vector field on $N$ such that $Y(f(q))=f_{\star,q}(X(q))$ $\forall q\in M$. If $f\circ\Phi_X^t$ is an integral curve of $X$ $\Rightarrow f\circ\Phi_X^t $ is an integral curve for $Y$ and in particular $f\circ\Phi_X^t=\Phi_Y^t\circ f.""$ If the answer is yes, how can I show that $X^{k-1}(f(\Phi_X^t))$ is an integral curve for $X$? I do not found a book with this generalized Taylor formula to manifold.",,"['differential-geometry', 'taylor-expansion', 'smooth-manifolds', 'vector-fields']"
39,In search of intuition for Integral Curvature,In search of intuition for Integral Curvature,,"EDIT 1/2/3: The intuitive understanding  of Integral Curvature ( the non-dimensional geometrical parameter measured in steridians  for surfaces in $ \mathbb R^3 $) seemed to me elusive. In a simple sphere case where Gauss curvature is constant and a certain area of a spherical cap is covered it is comprehensible as a fraction of full sphere maximum value $4 \pi$. It is a scalar invariant preserved in isometric mappings, an object of first fundamental form of surface theory. Its innate understanding to the extent other isometrically preserved entities is just not there, imho. I supposed that if the concept is extended to more prismatic surfaces it may even help in building a mechanics model of  Gauss-Bonnet theorem with forces, pressure and bending moments. Anyhow in order to gain better geometric intuition about what Integral Curvature really is (apart from its definition, the sphere and torus examples ), I tried to setup the following problem with geometric surface less round and more prismatic cylindrical surface. Whatever may be my motivation of this post stated above can be please ignored as a matter of my opinion, for an answer the following question: Find  meridian profile of a surface of revolution that maximizes volume for  given integral curvature $\int K\, dA$. The functional is $$\int K\, dA - \lambda_1 \, \int \pi \, r^2 \,dz $$ or $$ \int \dfrac{r^{''}}{r(1+r^{'2})^{2}} \, 2 \pi r \sqrt{1+r^{'2}} dz- \lambda_1 \int \pi r^2 dz $$ Lagrangian with adjusted multiplier $a$ introduced $$ F= \dfrac{r^{''}}{(1+r^{'2})^{3/2}}- \dfrac{r^2}{a^3} $$ and using Euler-Lagrange equation of second degree $$ F - r' \dfrac{\partial F}{\partial r'} +  r{''} \dfrac{\partial F}{\partial r{''}} = c, $$ where $c$ is an arbitrary constant, which after simplification results in the ODE: $$r^{'} = \tan \phi,\quad \kappa =\dfrac{  r^{''}}  {(1+r^{'2})^{3/2} } $$ $$ a^3 \kappa = \dfrac{r^2+c^2}{5-3 \cos^{2} \phi} $$ Results are plotted below for two cases $ a= \pm 1 , c= 0.5, r_i =0.75, r_i^{'} =0 ;$ Every Lagrange Multiplier is a geometrical property of the sought-after curve or surface upto a multiplicative constant .. ..right? So $a$ is the property parameter here. ( Like in Dido's iso-parametric problem has f ( Area, perimeter,  Lagrange Multiplier radius = $\lambda$)=0 However, no intuition gained from the new found looped shapes. There is no feel (for me) of integral curvature to correlate to maximum volume here say between two vertical tangent planes... I request for comments on the validity of the problem formulation and the result. Any remarks would be highly appreciated. Continuing the inquiry along same lines to find maximum area for given integral curvature , we get ODE $$ a^2  \kappa =\frac{(c+ r \cos \phi )}{ 5- 3 \cos^2 \phi}$$ and meridian curves ( $ BC: r_i=1, c= \frac12 $) with varying initial slopes as the following:","EDIT 1/2/3: The intuitive understanding  of Integral Curvature ( the non-dimensional geometrical parameter measured in steridians  for surfaces in $ \mathbb R^3 $) seemed to me elusive. In a simple sphere case where Gauss curvature is constant and a certain area of a spherical cap is covered it is comprehensible as a fraction of full sphere maximum value $4 \pi$. It is a scalar invariant preserved in isometric mappings, an object of first fundamental form of surface theory. Its innate understanding to the extent other isometrically preserved entities is just not there, imho. I supposed that if the concept is extended to more prismatic surfaces it may even help in building a mechanics model of  Gauss-Bonnet theorem with forces, pressure and bending moments. Anyhow in order to gain better geometric intuition about what Integral Curvature really is (apart from its definition, the sphere and torus examples ), I tried to setup the following problem with geometric surface less round and more prismatic cylindrical surface. Whatever may be my motivation of this post stated above can be please ignored as a matter of my opinion, for an answer the following question: Find  meridian profile of a surface of revolution that maximizes volume for  given integral curvature $\int K\, dA$. The functional is $$\int K\, dA - \lambda_1 \, \int \pi \, r^2 \,dz $$ or $$ \int \dfrac{r^{''}}{r(1+r^{'2})^{2}} \, 2 \pi r \sqrt{1+r^{'2}} dz- \lambda_1 \int \pi r^2 dz $$ Lagrangian with adjusted multiplier $a$ introduced $$ F= \dfrac{r^{''}}{(1+r^{'2})^{3/2}}- \dfrac{r^2}{a^3} $$ and using Euler-Lagrange equation of second degree $$ F - r' \dfrac{\partial F}{\partial r'} +  r{''} \dfrac{\partial F}{\partial r{''}} = c, $$ where $c$ is an arbitrary constant, which after simplification results in the ODE: $$r^{'} = \tan \phi,\quad \kappa =\dfrac{  r^{''}}  {(1+r^{'2})^{3/2} } $$ $$ a^3 \kappa = \dfrac{r^2+c^2}{5-3 \cos^{2} \phi} $$ Results are plotted below for two cases $ a= \pm 1 , c= 0.5, r_i =0.75, r_i^{'} =0 ;$ Every Lagrange Multiplier is a geometrical property of the sought-after curve or surface upto a multiplicative constant .. ..right? So $a$ is the property parameter here. ( Like in Dido's iso-parametric problem has f ( Area, perimeter,  Lagrange Multiplier radius = $\lambda$)=0 However, no intuition gained from the new found looped shapes. There is no feel (for me) of integral curvature to correlate to maximum volume here say between two vertical tangent planes... I request for comments on the validity of the problem formulation and the result. Any remarks would be highly appreciated. Continuing the inquiry along same lines to find maximum area for given integral curvature , we get ODE $$ a^2  \kappa =\frac{(c+ r \cos \phi )}{ 5- 3 \cos^2 \phi}$$ and meridian curves ( $ BC: r_i=1, c= \frac12 $) with varying initial slopes as the following:",,"['differential-geometry', 'calculus-of-variations']"
40,Integrating a surface in a cylinder,Integrating a surface in a cylinder,,"Consider  $$\Phi: \mathbb{R}^2\to   \mathbb{R}^3,~ \Phi(u,v)=\frac{1}{2}\begin{pmatrix}u+v\\u-v\\2uv\end{pmatrix}$$ I want to find the volume of the area $\Phi(\mathbb{R}^2)$ inside the cylinder $C:x^2+y^2<4$. First I found the Jacobi-matrix of $\Phi$ $$J(u,v)_\Phi=\frac{1}{2}\begin{pmatrix}1&1\\ 1&-1\\ 2v&2u\end{pmatrix},~J(u,v)_\Phi^T=\begin{pmatrix}\frac{1}{2}&\frac{1}{2}& 1v\\ \frac{1}{2}&-\frac{1}{2}&1u\end{pmatrix}$$ So the Metric-Tensor and its determinant are $$\mathscr{G}(\Phi)=J(u,v)_\Phi^T\cdot J(u,v)_\Phi=\begin{pmatrix}\frac{1+2v^2}{2}&vu\\ vu&\frac{1+2u^2}{2}\end{pmatrix},\quad \mathscr{g}(\Phi)=\frac{2v^2+2u^2+1}{4}$$ But Im not sure how to find the   volume;","Consider  $$\Phi: \mathbb{R}^2\to   \mathbb{R}^3,~ \Phi(u,v)=\frac{1}{2}\begin{pmatrix}u+v\\u-v\\2uv\end{pmatrix}$$ I want to find the volume of the area $\Phi(\mathbb{R}^2)$ inside the cylinder $C:x^2+y^2<4$. First I found the Jacobi-matrix of $\Phi$ $$J(u,v)_\Phi=\frac{1}{2}\begin{pmatrix}1&1\\ 1&-1\\ 2v&2u\end{pmatrix},~J(u,v)_\Phi^T=\begin{pmatrix}\frac{1}{2}&\frac{1}{2}& 1v\\ \frac{1}{2}&-\frac{1}{2}&1u\end{pmatrix}$$ So the Metric-Tensor and its determinant are $$\mathscr{G}(\Phi)=J(u,v)_\Phi^T\cdot J(u,v)_\Phi=\begin{pmatrix}\frac{1+2v^2}{2}&vu\\ vu&\frac{1+2u^2}{2}\end{pmatrix},\quad \mathscr{g}(\Phi)=\frac{2v^2+2u^2+1}{4}$$ But Im not sure how to find the   volume;",,['real-analysis']
41,Cobordisms and compactness,Cobordisms and compactness,,"Two compact $n$-manifolds $M_0, M_1$ are said to be cobordant if there is an $(n+1)$-dimensional compact manifold $M$ such that $\partial M = M_0 \sqcup M_1$. What is the necessity of compactness here? From a naive perspective (i.e. mine) it seems as though we can just remove compactness from the definition, and just use two arbitrary $n$-manifolds $M_0, M_1$ instead.","Two compact $n$-manifolds $M_0, M_1$ are said to be cobordant if there is an $(n+1)$-dimensional compact manifold $M$ such that $\partial M = M_0 \sqcup M_1$. What is the necessity of compactness here? From a naive perspective (i.e. mine) it seems as though we can just remove compactness from the definition, and just use two arbitrary $n$-manifolds $M_0, M_1$ instead.",,"['differential-geometry', 'cobordism']"
42,Writing a vector field on SO(3) in terms of local coordinates,Writing a vector field on SO(3) in terms of local coordinates,,"I'm looking at control systems on SO(3) of the form $\dot{g} = gf(g) + gh(g)u$, where $gf(g)$ is the drift vector field and $gh(g)$ is the control vector field. I'm interested in expressing these fields in terms of some local coordinates, i.e. $$gh(g) = \sum_{i}X^i\frac{\partial}{\partial x^i}$$ How would I go about computing the $X^i$s? As a specific example, suppose $h = L_x$ (an element of the standard basis of $\mathfrak{so}(3)$), and we use geodesic polar coordinates with the exponential map as the chart function. What would the local coordinate representation of $gh$ look like?","I'm looking at control systems on SO(3) of the form $\dot{g} = gf(g) + gh(g)u$, where $gf(g)$ is the drift vector field and $gh(g)$ is the control vector field. I'm interested in expressing these fields in terms of some local coordinates, i.e. $$gh(g) = \sum_{i}X^i\frac{\partial}{\partial x^i}$$ How would I go about computing the $X^i$s? As a specific example, suppose $h = L_x$ (an element of the standard basis of $\mathfrak{so}(3)$), and we use geodesic polar coordinates with the exponential map as the chart function. What would the local coordinate representation of $gh$ look like?",,"['differential-geometry', 'riemannian-geometry', 'control-theory']"
43,Complex exponentials and the math behind Mercator's projection,Complex exponentials and the math behind Mercator's projection,,"I came across this post by David Bau , in which he reproduces the most widespread Mercator projection as the plot of the complex function $$f(z)=\exp \mathrm i z.$$ The result is familiar: preserving the shape of the different landmasses, at the expense of enlarging the relative area of North America and Europe with respect to Equatorial and Southern Hemispherical regions. This is equivalent to the fanning out of the top of the plot of the function on an applet provided by the same author: Two questions: Is the idea that if for instance, Barcelona being located at $41.3851°$ N, $2.1734°$ E, the coordinates in the $\mathbb R^2$ complex coordinates would be $41.3851 + 2.1734 \; \mathrm i,$ and after the transformation it would end up being plotted at $f(41.3851 + 2.1734\,\mathrm i)=\exp \left(\mathrm i (41.3851 + 2.1734\,\mathrm i) \right)=-0.09734 + 0.05893\,\mathrm i$ $(-0.09734, 0.05893)$? Is this an approximation or the exact reproduction of the actual cylindrical projection (Mercator) ? Some leg work... in R. Database is here : > head(city)            city   city_ascii     lat     lng    pop     country iso2 iso3 province 1 Qal eh-ye Now    Qal eh-ye 34.9830 63.1333   2997 Afghanistan   AF  AFG  Badghis 2   Chaghcharan  Chaghcharan 34.5167 65.2500  15000 Afghanistan   AF  AFG     Ghor 3   Lashkar Gah  Lashkar Gah 31.5830 64.3600 201546 Afghanistan   AF  AFG  Hilmand 4        Zaranj       Zaranj 31.1120 61.8870  49851 Afghanistan   AF  AFG   Nimroz 5    Tarin Kowt   Tarin Kowt 32.6333 65.8667  10000 Afghanistan   AF  AFG  Uruzgan 6  Zareh Sharan Zareh Sharan 32.8500 68.4167  13737 Afghanistan   AF  AFG  Paktika ...  > head(coord) [1] 34.9830+63.1333i      34.5167+65.2500i      31.5830+64.3600i      31.1120+61.8870i      32.6333+65.8667i      32.8500+68.4167i ... Just plotting the raw latitude and longitude of a bunch of cities in the complex coordinates: coord = complex(real = city$lat, imaginary = city$lng) plot(Re(coord) ~ Im(coord), pch=20, col=rgb(0,0,0.5,.3)) ... Pretty much the Mercator map... Now transforming the dataset by simply logging the values $\log z$ renders an Azimuthal map with the South America oddly in the center: exi = log(1i * coord) plot(Re(exi) ~ Im(exi), pch=20, col=rgb(0,0,0.5,.3)) Perhaps the raw data in the link provided started off as logs of the latitude and longitude:","I came across this post by David Bau , in which he reproduces the most widespread Mercator projection as the plot of the complex function $$f(z)=\exp \mathrm i z.$$ The result is familiar: preserving the shape of the different landmasses, at the expense of enlarging the relative area of North America and Europe with respect to Equatorial and Southern Hemispherical regions. This is equivalent to the fanning out of the top of the plot of the function on an applet provided by the same author: Two questions: Is the idea that if for instance, Barcelona being located at $41.3851°$ N, $2.1734°$ E, the coordinates in the $\mathbb R^2$ complex coordinates would be $41.3851 + 2.1734 \; \mathrm i,$ and after the transformation it would end up being plotted at $f(41.3851 + 2.1734\,\mathrm i)=\exp \left(\mathrm i (41.3851 + 2.1734\,\mathrm i) \right)=-0.09734 + 0.05893\,\mathrm i$ $(-0.09734, 0.05893)$? Is this an approximation or the exact reproduction of the actual cylindrical projection (Mercator) ? Some leg work... in R. Database is here : > head(city)            city   city_ascii     lat     lng    pop     country iso2 iso3 province 1 Qal eh-ye Now    Qal eh-ye 34.9830 63.1333   2997 Afghanistan   AF  AFG  Badghis 2   Chaghcharan  Chaghcharan 34.5167 65.2500  15000 Afghanistan   AF  AFG     Ghor 3   Lashkar Gah  Lashkar Gah 31.5830 64.3600 201546 Afghanistan   AF  AFG  Hilmand 4        Zaranj       Zaranj 31.1120 61.8870  49851 Afghanistan   AF  AFG   Nimroz 5    Tarin Kowt   Tarin Kowt 32.6333 65.8667  10000 Afghanistan   AF  AFG  Uruzgan 6  Zareh Sharan Zareh Sharan 32.8500 68.4167  13737 Afghanistan   AF  AFG  Paktika ...  > head(coord) [1] 34.9830+63.1333i      34.5167+65.2500i      31.5830+64.3600i      31.1120+61.8870i      32.6333+65.8667i      32.8500+68.4167i ... Just plotting the raw latitude and longitude of a bunch of cities in the complex coordinates: coord = complex(real = city$lat, imaginary = city$lng) plot(Re(coord) ~ Im(coord), pch=20, col=rgb(0,0,0.5,.3)) ... Pretty much the Mercator map... Now transforming the dataset by simply logging the values $\log z$ renders an Azimuthal map with the South America oddly in the center: exi = log(1i * coord) plot(Re(exi) ~ Im(exi), pch=20, col=rgb(0,0,0.5,.3)) Perhaps the raw data in the link provided started off as logs of the latitude and longitude:",,"['differential-geometry', 'differential-topology', 'stereographic-projections', 'cartography']"
44,Derivative of a flow diffeomorphism,Derivative of a flow diffeomorphism,,"Let $M$ be a manifold, $V$ a smooth vector field on it and $\phi_t:M \rightarrow M$ its flow is defined for all $t\in R$. Can $d\phi_t$ be expressed in terms of $V$?","Let $M$ be a manifold, $V$ a smooth vector field on it and $\phi_t:M \rightarrow M$ its flow is defined for all $t\in R$. Can $d\phi_t$ be expressed in terms of $V$?",,"['differential-geometry', 'manifolds']"
45,How to proof a real variety is not locally a manifold,How to proof a real variety is not locally a manifold,,"I'm becoming desperate with a problem, which doesn't seem so difficult. I have a real algebraic set $X$ in $\mathbb{R}^{15}$ defined by  $$ x_1^2 + y_1^2 + z_1^2 - 1 = 0\\ x_2^2 + y_2^2 + z_2^2 - 1 = 0\\ x_3^2 + y_3^2 + z_3^2 -1 = 0 \\ c_1^2 + s_1^2 - 1 = 0 \\ c_2^2 + s_2^2 - 1 = 0 \\ c_3^2 + s_3^2 - 1 = 0 \\ l_1 = \ldots = l_6 = 0, $$ where $l_1, \ldots, l_6$ are linear in the $x_i,y_i,z_i,c_i,s_i$, (basically $X$ is the preimage of zero of a smooth map $(S^2)^3 \times (S^1)^3 \to \mathbb{R}^6$). I found 24 points, where all principal minors of the jacobian are zero. I want to show now, that these points are ""singular"", i.e. $X$ is not locally an embedded submanifold of $\mathbb{R}^{15}$ around these points. I know that this set is irreducible of dimension $3$ and I think I can calculate the complex tangent cones $\mathcal{C}$ (tangent cone of the complex variety) in these points (with groebner bases) but I think it is not true in general, that $\mathcal{C} \cap \mathbb{R}^{15} = \mathcal{C}_\mathbb{R}$? Does anybody have an idea how to proof this, or could maybe give a pointer to literature which considers this kind of problems or just vaguely related problems. Its quite difficult to find any research in this direction (or I don't know where to look). Many Thanks!","I'm becoming desperate with a problem, which doesn't seem so difficult. I have a real algebraic set $X$ in $\mathbb{R}^{15}$ defined by  $$ x_1^2 + y_1^2 + z_1^2 - 1 = 0\\ x_2^2 + y_2^2 + z_2^2 - 1 = 0\\ x_3^2 + y_3^2 + z_3^2 -1 = 0 \\ c_1^2 + s_1^2 - 1 = 0 \\ c_2^2 + s_2^2 - 1 = 0 \\ c_3^2 + s_3^2 - 1 = 0 \\ l_1 = \ldots = l_6 = 0, $$ where $l_1, \ldots, l_6$ are linear in the $x_i,y_i,z_i,c_i,s_i$, (basically $X$ is the preimage of zero of a smooth map $(S^2)^3 \times (S^1)^3 \to \mathbb{R}^6$). I found 24 points, where all principal minors of the jacobian are zero. I want to show now, that these points are ""singular"", i.e. $X$ is not locally an embedded submanifold of $\mathbb{R}^{15}$ around these points. I know that this set is irreducible of dimension $3$ and I think I can calculate the complex tangent cones $\mathcal{C}$ (tangent cone of the complex variety) in these points (with groebner bases) but I think it is not true in general, that $\mathcal{C} \cap \mathbb{R}^{15} = \mathcal{C}_\mathbb{R}$? Does anybody have an idea how to proof this, or could maybe give a pointer to literature which considers this kind of problems or just vaguely related problems. Its quite difficult to find any research in this direction (or I don't know where to look). Many Thanks!",,"['differential-geometry', 'algebraic-geometry', 'real-algebraic-geometry']"
46,Contact order of a space curve with one of it's tangent lines,Contact order of a space curve with one of it's tangent lines,,"Definition $1$: Let $\alpha: I \mapsto \mathbb{R^3}$ and $\beta: \overline{I} \mapsto \mathbb{R^3}$ be two regular curves such that $\alpha(t_0) = \beta(t_0)$, where $t_0 \in I \cap \overline{I}$. $\alpha$ and $\beta$ are said to have contact of order $n$ at $t_0$ ($n$ being an integer $\geq 1$) if all derivatives of order $\leq n$ of the functions $\alpha$ and $\beta$ are equal at $t_0$ and derivatives of order $n + 1$ are different. Definition $2$: $\alpha: I \mapsto \mathbb{R^3}$ is said to be a regular curve if $|| \alpha'(t) || \neq 0, \forall t \in I$ Let $\alpha: I \mapsto \mathbb{R^3}$ be a regular unit speed curve. a) If $k(s) > 0, \forall s \in I$, then prove that the tangent line to   $\alpha$ at $s$ has contact of order $1$ with $\alpha$. b) Give an example of a regular curve that has contact of order $2$ with one of it's tangent lines. c) Is it possible to get a regular curve that has contact of order $\geq n$ with one of it's tangent lines for all integer $n \geq 1$? a) is easy, for b) I think the example (that was) given in one of the answers (a parabola) will do, it's c) I'm having trouble with. I think the only possible example for such a curve is a line, since a curve having contact of order, say, $2$ at $t_0$ with one of it's tangent lines means the curvature at that point is $0$. I'm having trouble proving that, though. Any help would be appreciated.","Definition $1$: Let $\alpha: I \mapsto \mathbb{R^3}$ and $\beta: \overline{I} \mapsto \mathbb{R^3}$ be two regular curves such that $\alpha(t_0) = \beta(t_0)$, where $t_0 \in I \cap \overline{I}$. $\alpha$ and $\beta$ are said to have contact of order $n$ at $t_0$ ($n$ being an integer $\geq 1$) if all derivatives of order $\leq n$ of the functions $\alpha$ and $\beta$ are equal at $t_0$ and derivatives of order $n + 1$ are different. Definition $2$: $\alpha: I \mapsto \mathbb{R^3}$ is said to be a regular curve if $|| \alpha'(t) || \neq 0, \forall t \in I$ Let $\alpha: I \mapsto \mathbb{R^3}$ be a regular unit speed curve. a) If $k(s) > 0, \forall s \in I$, then prove that the tangent line to   $\alpha$ at $s$ has contact of order $1$ with $\alpha$. b) Give an example of a regular curve that has contact of order $2$ with one of it's tangent lines. c) Is it possible to get a regular curve that has contact of order $\geq n$ with one of it's tangent lines for all integer $n \geq 1$? a) is easy, for b) I think the example (that was) given in one of the answers (a parabola) will do, it's c) I'm having trouble with. I think the only possible example for such a curve is a line, since a curve having contact of order, say, $2$ at $t_0$ with one of it's tangent lines means the curvature at that point is $0$. I'm having trouble proving that, though. Any help would be appreciated.",,"['calculus', 'differential-geometry', 'curves', 'frenet-frame']"
47,Calculating the round metric on $S^n$ [closed],Calculating the round metric on  [closed],S^n,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question I'm self-studying differential geometetry from Taubes' textbook on Differential Geometry and I found a lot of unclear things in the following passage: Taubes gives a formula for $\Gamma^i_{jk}$ but doesn't give the derivation yet and expects us to use it. $g^{ij}$ denotes the i,jth entry in the inverse matrix of $g$. [ I have a few questions: How does he calculate the pullback of $g_{ij}$? Because I got a different answer $g_{ij} = \delta_{ij} + y_i y_j (1-||y||^2)^{-1}$ How does he calculate the $\Gamma^i_{jk}$? I can't even begin to calculate it, as it requires me to find the inverse matrix of $g$, a task which seems far too complicated in this case. How come the equation with the $\mathcal{O}(|y|^2)$ is actually equivalent to the formula he gave before? His argument is incomprehensible to me. How does the formula imply that $t \to x_j(t)$ lies on a plane? These questions are enough for now.","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question I'm self-studying differential geometetry from Taubes' textbook on Differential Geometry and I found a lot of unclear things in the following passage: Taubes gives a formula for $\Gamma^i_{jk}$ but doesn't give the derivation yet and expects us to use it. $g^{ij}$ denotes the i,jth entry in the inverse matrix of $g$. [ I have a few questions: How does he calculate the pullback of $g_{ij}$? Because I got a different answer $g_{ij} = \delta_{ij} + y_i y_j (1-||y||^2)^{-1}$ How does he calculate the $\Gamma^i_{jk}$? I can't even begin to calculate it, as it requires me to find the inverse matrix of $g$, a task which seems far too complicated in this case. How come the equation with the $\mathcal{O}(|y|^2)$ is actually equivalent to the formula he gave before? His argument is incomprehensible to me. How does the formula imply that $t \to x_j(t)$ lies on a plane? These questions are enough for now.",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
48,Canonical metric when $-K_X$ is nef?,Canonical metric when  is nef?,-K_X,"Let $X$ be a smooth projective variery. Let $-K_X$ be nef , then which type of Canonical metric In the sense of Einstein type metric is suitable for it. In fact when $K_X$ or $-K_X$ is ample WE know that WE have $ Ric(\omega)=-\omega$, and $ Ric(\omega)=\omega$,  when X is K-stable. In my opinion when $-K_X$ be nef then WE know that the Albanese map is surjective, I.e $\pi:X\to Alb(X)$ is surjective and the best Canonical metric is the relative Kahler Einstein metric along Albanese map $$Ric_{X/S}(\omega)=-\xi(s)\omega$$ As soon as the relative tangent sheaf $T_{X/S}$ is stable In the sense of Mumford. Where here $S=Alb(X)$ is Albanese variety  and $\omega$ is the relative Kahler form and $\xi(s)$ is fiberwise constant. In this case the right flow is the following Hyperbolic Relative Kahler Ricci flow. $$\frac{\partial^2\omega}{\partial s'\partial t}=-Ric_{X/S}\omega(s',t)-\xi(s)\omega_{s'}(t)$$ Where here $s'=\frac{1}{s}$ and $s\to 0$ See here the definition of relative Kahler form see my answer to this post What is a Kählerian variety? Also about Albanese map see my answer to this post What is the Albanese map good for? For nef Line bundle see my answer to this post nef Line bundles over Kähler manifolds When Tangent sheaf of a Fano Variery is nef see JPD paper https://arxiv.org/abs/1712.03725 My motivation is that let $\pi:X\to \Delta$  be a surjective holomorphic fibre space from a projective variery to a holomorphic disc. Let $K_{X_t}$ is ample then the Canonical divisor $K_{X_0}$ is nef and finding a type of Canonical metric on central fiber is an open question and it may admits several différent type of Canonical metrics including twisted KE See my post about Beauville-Bogomolov decomposition by using relative Kahler Ricci flow along Albanese map https://mathoverflow.net/questions/277561/kähler-ricci-flow-approach-for-beauville-bogomolov-type-decomposition Hassan Jolany","Let $X$ be a smooth projective variery. Let $-K_X$ be nef , then which type of Canonical metric In the sense of Einstein type metric is suitable for it. In fact when $K_X$ or $-K_X$ is ample WE know that WE have $ Ric(\omega)=-\omega$, and $ Ric(\omega)=\omega$,  when X is K-stable. In my opinion when $-K_X$ be nef then WE know that the Albanese map is surjective, I.e $\pi:X\to Alb(X)$ is surjective and the best Canonical metric is the relative Kahler Einstein metric along Albanese map $$Ric_{X/S}(\omega)=-\xi(s)\omega$$ As soon as the relative tangent sheaf $T_{X/S}$ is stable In the sense of Mumford. Where here $S=Alb(X)$ is Albanese variety  and $\omega$ is the relative Kahler form and $\xi(s)$ is fiberwise constant. In this case the right flow is the following Hyperbolic Relative Kahler Ricci flow. $$\frac{\partial^2\omega}{\partial s'\partial t}=-Ric_{X/S}\omega(s',t)-\xi(s)\omega_{s'}(t)$$ Where here $s'=\frac{1}{s}$ and $s\to 0$ See here the definition of relative Kahler form see my answer to this post What is a Kählerian variety? Also about Albanese map see my answer to this post What is the Albanese map good for? For nef Line bundle see my answer to this post nef Line bundles over Kähler manifolds When Tangent sheaf of a Fano Variery is nef see JPD paper https://arxiv.org/abs/1712.03725 My motivation is that let $\pi:X\to \Delta$  be a surjective holomorphic fibre space from a projective variery to a holomorphic disc. Let $K_{X_t}$ is ample then the Canonical divisor $K_{X_0}$ is nef and finding a type of Canonical metric on central fiber is an open question and it may admits several différent type of Canonical metrics including twisted KE See my post about Beauville-Bogomolov decomposition by using relative Kahler Ricci flow along Albanese map https://mathoverflow.net/questions/277561/kähler-ricci-flow-approach-for-beauville-bogomolov-type-decomposition Hassan Jolany",,"['differential-geometry', 'algebraic-geometry']"
49,"A smooth map from $Gr_{\mathbb{C}} (1,2)$ to $Gr_{\mathbb{R}} (2,4)$",A smooth map from  to,"Gr_{\mathbb{C}} (1,2) Gr_{\mathbb{R}} (2,4)","$\mathbf{Problem}$: Let $Gr_{\mathbb{C}} (1,2)$ be the complex Grassmannian manifold that consists of all the complex lines going through the origin in $\mathbb{C}^2$, and $Gr_{\mathbb{R}} (2,4)$ be all the 2-dimensional linear subspaces of $\mathbb{R}^4$. Show that the function $f: Gr_{\mathbb{C}}(1,2) \to Gr_{\mathbb{R}}(2,4)$ is smooth, where f maps a complex line to itself regarded as a 2-dimensional linear subspace of $\mathbb{R}^4$. $\mathbf{Attempt}$: 1) $\mathbf{Setup}$: Proving the map $f$ smooth is to prove that $\psi_j \circ f \circ \phi^{-1}_i$ is smooth when the composition makes sense. The charts I am using for the Grassmannians are the standard ones: for $Gr_{\mathbb{C}} (1,2)$, define $I = \{1,2\}$, $I_i = \{i\}$, $\mathbb{C}^{I_i} = \{(z_1, z_2): z_j = 0,  \forall j \in I - I_i \}$, and $U_{I_i} = \{E \subset \mathbb{C}^2: E \cap \mathbb{C}^{I - I_i} = \{0\} \}$. Define the function $\phi_i: U_{I_i} \to Hom(\mathbb{C}^{I_i}, \mathbb{C}^{I - I_i})$  by $\phi_i(E) = l_E$, the linear map from $\mathbb{C}^{I_i}$ to $\mathbb{C}^{I - I_i}$ such that $E = \{z + l_e(z): z \in \mathbb{C}^{I_i}\}$, i.e., E is the graph of it. Similar definition holds for $Gr_{\mathbb{R}} (2,4)$. 2) Geometrically the problem seems straightforward as I am not really changing anything about the line itself, but I am stuck in proving smoothness of the composition of the functions. In class we defined the smoothness of a function between manifolds by showing  $\psi_j \circ f \circ \phi^{-1}_i$ is a smooth function mapping from a Euclidean space to a Euclidean space, which in our case is not exactly so, since $\psi_j \circ f \circ \phi^{-1}_i: Hom(\mathbb{C}^{I_i}, \mathbb{C}^{I - I_i}) \to Hom(\mathbb{R}^{J_j}, \mathbb{R}^{J - J_j})$, so we seem to be mapping linear functions to linear functions. I know in general $Hom(\mathbb{R}^{I'}, \mathbb{R}^{I - I'})$ is isomorphic to $\mathbb{R}^{k(n-k)}$ for $|I'| = k, |I| = n$ (similar case for $Hom(\mathbb{C}^{I'}, \mathbb{C}^{I - I'})$), but how does this work in our context exactly? 3) Another question I have is of more general context. For functions that maps between Euclidean spaces, if the functions is smooth over the Euclidean space, then it must be smooth mapping between the manifolds right? Any help is appreciated!","$\mathbf{Problem}$: Let $Gr_{\mathbb{C}} (1,2)$ be the complex Grassmannian manifold that consists of all the complex lines going through the origin in $\mathbb{C}^2$, and $Gr_{\mathbb{R}} (2,4)$ be all the 2-dimensional linear subspaces of $\mathbb{R}^4$. Show that the function $f: Gr_{\mathbb{C}}(1,2) \to Gr_{\mathbb{R}}(2,4)$ is smooth, where f maps a complex line to itself regarded as a 2-dimensional linear subspace of $\mathbb{R}^4$. $\mathbf{Attempt}$: 1) $\mathbf{Setup}$: Proving the map $f$ smooth is to prove that $\psi_j \circ f \circ \phi^{-1}_i$ is smooth when the composition makes sense. The charts I am using for the Grassmannians are the standard ones: for $Gr_{\mathbb{C}} (1,2)$, define $I = \{1,2\}$, $I_i = \{i\}$, $\mathbb{C}^{I_i} = \{(z_1, z_2): z_j = 0,  \forall j \in I - I_i \}$, and $U_{I_i} = \{E \subset \mathbb{C}^2: E \cap \mathbb{C}^{I - I_i} = \{0\} \}$. Define the function $\phi_i: U_{I_i} \to Hom(\mathbb{C}^{I_i}, \mathbb{C}^{I - I_i})$  by $\phi_i(E) = l_E$, the linear map from $\mathbb{C}^{I_i}$ to $\mathbb{C}^{I - I_i}$ such that $E = \{z + l_e(z): z \in \mathbb{C}^{I_i}\}$, i.e., E is the graph of it. Similar definition holds for $Gr_{\mathbb{R}} (2,4)$. 2) Geometrically the problem seems straightforward as I am not really changing anything about the line itself, but I am stuck in proving smoothness of the composition of the functions. In class we defined the smoothness of a function between manifolds by showing  $\psi_j \circ f \circ \phi^{-1}_i$ is a smooth function mapping from a Euclidean space to a Euclidean space, which in our case is not exactly so, since $\psi_j \circ f \circ \phi^{-1}_i: Hom(\mathbb{C}^{I_i}, \mathbb{C}^{I - I_i}) \to Hom(\mathbb{R}^{J_j}, \mathbb{R}^{J - J_j})$, so we seem to be mapping linear functions to linear functions. I know in general $Hom(\mathbb{R}^{I'}, \mathbb{R}^{I - I'})$ is isomorphic to $\mathbb{R}^{k(n-k)}$ for $|I'| = k, |I| = n$ (similar case for $Hom(\mathbb{C}^{I'}, \mathbb{C}^{I - I'})$), but how does this work in our context exactly? 3) Another question I have is of more general context. For functions that maps between Euclidean spaces, if the functions is smooth over the Euclidean space, then it must be smooth mapping between the manifolds right? Any help is appreciated!",,"['differential-geometry', 'smooth-manifolds', 'grassmannian']"
50,Does an immersed curve in general position has finite self-intersections?,Does an immersed curve in general position has finite self-intersections?,,"This problem comes from Hirsch's differential topology in page 67. ""Generically"" a $C^1$ immersion $S^1\to \mathbb{R}^2$ has only a finite number of crossing points. Then I want to ask if in general a $C^1$ immersion $I\to M$, where $I$ is an interval in $\mathbb{R^1}$ and $M$ is a $C^1$ manifold, has finite self-intersections. Intuitively, since the curve is $C^1$, it can not change drastically in a small enough neighborhood, then we can perturbate it a little near the limit points of self-intersections to obtain a immersed curve with finite self-intersections. I don't know how to prove it rigorously, even for the case $I\to \mathbb{R}^2$. Since this problem occurs in chapter 3,  the proof may need transversality theorems.","This problem comes from Hirsch's differential topology in page 67. ""Generically"" a $C^1$ immersion $S^1\to \mathbb{R}^2$ has only a finite number of crossing points. Then I want to ask if in general a $C^1$ immersion $I\to M$, where $I$ is an interval in $\mathbb{R^1}$ and $M$ is a $C^1$ manifold, has finite self-intersections. Intuitively, since the curve is $C^1$, it can not change drastically in a small enough neighborhood, then we can perturbate it a little near the limit points of self-intersections to obtain a immersed curve with finite self-intersections. I don't know how to prove it rigorously, even for the case $I\to \mathbb{R}^2$. Since this problem occurs in chapter 3,  the proof may need transversality theorems.",,"['differential-geometry', 'manifolds', 'differential-topology', 'intersection-theory']"
51,Existence of orthogonal coordinates on a Riemannian manifold,Existence of orthogonal coordinates on a Riemannian manifold,,"This is probably a very naive question, but so far I could not find an answer: Let $(M,g)$ be a Riemannian manifold. Can we always find ""orthogonal coordinates"" locally? More precisely, I am asking if for every $p \in M$ there exists a neighbourhood $U$ and a diffeomorphism $\phi:\mathbb{R}^n \to U$, such that $g_{ij}=g(d\phi(e_i),d\phi(e_j))=0$ for $i \neq j$. Clarification: Note that I want $g_{ij}=0$ on all $U$, not just at $p$. Also, I allow $g_{ii} \neq g_{jj}$ for $i \neq j$ (the special case where $g_{ii}$ is independent of $i$ is called isothermal coordinates-and corresponds to conformal flatness of $U$). Of course, this is  weaker than requiring $M$ to be conformally flat, since a (linear) map which maps an orthogonal basis to an orthogonal basis does not need to be conformal.","This is probably a very naive question, but so far I could not find an answer: Let $(M,g)$ be a Riemannian manifold. Can we always find ""orthogonal coordinates"" locally? More precisely, I am asking if for every $p \in M$ there exists a neighbourhood $U$ and a diffeomorphism $\phi:\mathbb{R}^n \to U$, such that $g_{ij}=g(d\phi(e_i),d\phi(e_j))=0$ for $i \neq j$. Clarification: Note that I want $g_{ij}=0$ on all $U$, not just at $p$. Also, I allow $g_{ii} \neq g_{jj}$ for $i \neq j$ (the special case where $g_{ii}$ is independent of $i$ is called isothermal coordinates-and corresponds to conformal flatness of $U$). Of course, this is  weaker than requiring $M$ to be conformally flat, since a (linear) map which maps an orthogonal basis to an orthogonal basis does not need to be conformal.",,"['riemannian-geometry', 'coordinate-systems', 'orthogonality']"
52,prerequisite for reading characteristic classes,prerequisite for reading characteristic classes,,"Can some one tell me what are the prerequisites for learning characteristic classes as they are in book Foundations of Differential geometry by Kobayashi and Nomizu. I only read first two chapters of that book which covers details about principal bundles and connections on principal bundles. I started reading this chapters on characteristic classes. It starts section on chern classes saying that We consider the category of differential complex vector bundles over differentiable manifolds. But they have not given so many details about complex vector bundles in any of previous chapters. So, I am not able to understand anything about this characteristic classes. Any suggestion on references for complex vector bundles is welcome. I have seen Kobayashi’s another book On complex vector bundles. He never explains in detail what they are in that book as well. If you think any other prerequisites are necessary for this, do let me know.","Can some one tell me what are the prerequisites for learning characteristic classes as they are in book Foundations of Differential geometry by Kobayashi and Nomizu. I only read first two chapters of that book which covers details about principal bundles and connections on principal bundles. I started reading this chapters on characteristic classes. It starts section on chern classes saying that We consider the category of differential complex vector bundles over differentiable manifolds. But they have not given so many details about complex vector bundles in any of previous chapters. So, I am not able to understand anything about this characteristic classes. Any suggestion on references for complex vector bundles is welcome. I have seen Kobayashi’s another book On complex vector bundles. He never explains in detail what they are in that book as well. If you think any other prerequisites are necessary for this, do let me know.",,['differential-geometry']
53,Morse index of minimal surfaces in $\mathbb{R}^3$,Morse index of minimal surfaces in,\mathbb{R}^3,"I am wondering where can I find the Morse index of the most famous examples of minimal surfaces in $\mathbb{R}^3$, such as the cathenoid, the helicoid, etc. Is there any general standard technique to estimate the Morse index of a minimal hypersurface in $\mathbb{R}^n$? I have briefly checked the book A Course in Minimal Surfaces , by Colding and Minicozzi, but I couldn't find an answer to my questions. Any help or reference will be very much appreciated!","I am wondering where can I find the Morse index of the most famous examples of minimal surfaces in $\mathbb{R}^3$, such as the cathenoid, the helicoid, etc. Is there any general standard technique to estimate the Morse index of a minimal hypersurface in $\mathbb{R}^n$? I have briefly checked the book A Course in Minimal Surfaces , by Colding and Minicozzi, but I couldn't find an answer to my questions. Any help or reference will be very much appreciated!",,"['differential-geometry', 'morse-theory', 'minimal-surfaces']"
54,Regarding vector-valued (differential) forms,Regarding vector-valued (differential) forms,,"I denote the space of all $V$-valued differential $k$-forms on $M$ with $\mathcal A^k(M,V)$. Let $\omega\in \mathcal A^k(M,V)$ and $\eta\in \mathcal A^l(M,W)$, where $V,W$ are finite real vector spaces. Then, we know that the usual wedge is a map $\mathcal A^k(M,V)\times \mathcal A^l(M,W)\to \mathcal A^{k+l}(M,V\otimes W)$. Let $i$ run from 1 to $\dim V$. Let $\{v_i\}$ be a basis for $V$ and $\{w_i\}$ a basis for $W$. Then, $\omega=\omega^iv_i$ and $\eta=\eta^iw_i$ (summation convention), where $\omega^i,\eta^i$ are usual forms, meaning they are elements of $\mathcal A^k(M,\mathbb R)=\mathcal A^kM,\mathcal A^lM$ respectively. Therefore, $\omega\wedge\eta=(\omega^i\wedge \eta^j)v_i\otimes w_j$. Let's assume I want to construct a new product, namely $\curlywedge$, that is a map $\mathcal A^k(M,V)\times \mathcal A^l(M,W)\to \mathcal A^{k+l}(M, W)$. Following the method of the product $[\omega\wedge\eta]$ for two Lie algebra-valued forms, I can think of two ways, that $V\otimes W\to W$. Both rely on the universal property of the tensor product. The first way is to define a composite map: $$v\otimes w\mapsto (v,w)\stackrel{\langle \sigma,\;\rangle\times id}{\to}(\langle\sigma,v\rangle,w)\to \langle \sigma,v\rangle w\in W$$ where $\langle\;,\;\rangle$ is the pairing product, $v\in V$, $w\in W$ and $\sigma\in V^*$ Alternatively, we can use a homomorphism $\phi:V\to End W$. I'll restrict the case now. Let $\mathfrak g$ be the Lie algebra of the Lie Group $G$ and $(\psi,V)$ be a finite representation for $\mathfrak g$, where $\psi:\mathfrak g\to End V$ is a Lie algebra homomorphism (V is the rep space). Let $\omega\in \mathcal A^1(P,\mathfrak g)$ and $\theta\in \mathcal A^1(P,V)$, namely the connection and solder form for a principal $G$-bundle $P\to M$. We have that $\omega\wedge\theta=\omega^i\wedge\theta^jX_i\otimes v_j\in \mathcal A^2(P,\mathfrak g\otimes V)$, where $\{X_i\},\{v_i\}$ bases for $\mathfrak g,V$ respectively. We want a map $\mathfrak g\otimes V\to V$, so that we can define a product $\mathcal A^k(P,\mathfrak g)\times \mathcal A^l(P,V)\to \mathcal A^{k+l}(M,V)$. It seems reasonable to choose the composite map $X\otimes v\to (X,v)\to\psi(X)v\in V$. From this, one can construct the above desired product, let it be $\curlywedge$ and then it can be proven that $\Theta=d\theta+\omega\curlywedge \theta$ is the usual expression for the torsion 2-form. Bianchi identity for $\Theta$ can also be proven. One sees, that when $V=\mathfrak g$, then $\psi=ad$ and the former $X\curlywedge v$ is nothing more than $[X\wedge v]$. My problem is that I cannot explicitly write down an exchange rule for $\omega\curlywedge \theta$. I believe it should follow the exchange rule of $[\omega\wedge\eta]$, namely $[\omega\wedge\eta]=(-1)^{kl+1}[\eta\wedge\omega]$, i.e $\omega\curlywedge \theta=\theta\curlywedge \omega$, but I am not able to show this. Instead I find that the exchange rule is of the usual forms.","I denote the space of all $V$-valued differential $k$-forms on $M$ with $\mathcal A^k(M,V)$. Let $\omega\in \mathcal A^k(M,V)$ and $\eta\in \mathcal A^l(M,W)$, where $V,W$ are finite real vector spaces. Then, we know that the usual wedge is a map $\mathcal A^k(M,V)\times \mathcal A^l(M,W)\to \mathcal A^{k+l}(M,V\otimes W)$. Let $i$ run from 1 to $\dim V$. Let $\{v_i\}$ be a basis for $V$ and $\{w_i\}$ a basis for $W$. Then, $\omega=\omega^iv_i$ and $\eta=\eta^iw_i$ (summation convention), where $\omega^i,\eta^i$ are usual forms, meaning they are elements of $\mathcal A^k(M,\mathbb R)=\mathcal A^kM,\mathcal A^lM$ respectively. Therefore, $\omega\wedge\eta=(\omega^i\wedge \eta^j)v_i\otimes w_j$. Let's assume I want to construct a new product, namely $\curlywedge$, that is a map $\mathcal A^k(M,V)\times \mathcal A^l(M,W)\to \mathcal A^{k+l}(M, W)$. Following the method of the product $[\omega\wedge\eta]$ for two Lie algebra-valued forms, I can think of two ways, that $V\otimes W\to W$. Both rely on the universal property of the tensor product. The first way is to define a composite map: $$v\otimes w\mapsto (v,w)\stackrel{\langle \sigma,\;\rangle\times id}{\to}(\langle\sigma,v\rangle,w)\to \langle \sigma,v\rangle w\in W$$ where $\langle\;,\;\rangle$ is the pairing product, $v\in V$, $w\in W$ and $\sigma\in V^*$ Alternatively, we can use a homomorphism $\phi:V\to End W$. I'll restrict the case now. Let $\mathfrak g$ be the Lie algebra of the Lie Group $G$ and $(\psi,V)$ be a finite representation for $\mathfrak g$, where $\psi:\mathfrak g\to End V$ is a Lie algebra homomorphism (V is the rep space). Let $\omega\in \mathcal A^1(P,\mathfrak g)$ and $\theta\in \mathcal A^1(P,V)$, namely the connection and solder form for a principal $G$-bundle $P\to M$. We have that $\omega\wedge\theta=\omega^i\wedge\theta^jX_i\otimes v_j\in \mathcal A^2(P,\mathfrak g\otimes V)$, where $\{X_i\},\{v_i\}$ bases for $\mathfrak g,V$ respectively. We want a map $\mathfrak g\otimes V\to V$, so that we can define a product $\mathcal A^k(P,\mathfrak g)\times \mathcal A^l(P,V)\to \mathcal A^{k+l}(M,V)$. It seems reasonable to choose the composite map $X\otimes v\to (X,v)\to\psi(X)v\in V$. From this, one can construct the above desired product, let it be $\curlywedge$ and then it can be proven that $\Theta=d\theta+\omega\curlywedge \theta$ is the usual expression for the torsion 2-form. Bianchi identity for $\Theta$ can also be proven. One sees, that when $V=\mathfrak g$, then $\psi=ad$ and the former $X\curlywedge v$ is nothing more than $[X\wedge v]$. My problem is that I cannot explicitly write down an exchange rule for $\omega\curlywedge \theta$. I believe it should follow the exchange rule of $[\omega\wedge\eta]$, namely $[\omega\wedge\eta]=(-1)^{kl+1}[\eta\wedge\omega]$, i.e $\omega\curlywedge \theta=\theta\curlywedge \omega$, but I am not able to show this. Instead I find that the exchange rule is of the usual forms.",,"['differential-geometry', 'tensor-products', 'differential-forms', 'exterior-algebra', 'connections']"
55,image of parametric quadratic curve with three components contained in a plane,image of parametric quadratic curve with three components contained in a plane,,"I am studying Differential geometry I tried to prove this by taking all three components as quadratic with $t$ as a parameter but could not be successful. If all three component functions of a space curve $\gamma$ are quadratic functions, prove that the image of $\gamma$ is contained in a plane.","I am studying Differential geometry I tried to prove this by taking all three components as quadratic with $t$ as a parameter but could not be successful. If all three component functions of a space curve $\gamma$ are quadratic functions, prove that the image of $\gamma$ is contained in a plane.",,"['differential-geometry', 'curves', 'plane-curves']"
56,Question about a result of Anderson,Question about a result of Anderson,,"In ""Riemannian Geometry, Peter Petersen, GTM171, Third Edition"" page 430, there is an Anderson Lemma: For each $n\geq 2$, there is an $\varepsilon(n)>0$ such that any complete Ricci flat manifold (M,g) that satisfies $$Vol(B(p,r))\geq(1-\varepsilon)\omega_n r^n$$ for some $p\in M$ is isometric to Euclidean space. I have problem about the proof in this book. The book proved it by contradiction: for each $i$, it constructed a complete Ricci flat manifold $(M_i,g_i)$, with $\lim\limits_{i\rightarrow \infty}\frac{Vol(B(p_i,r)}{\omega_n r^n}\geq(1-\frac{1}{i})$, and $(M_i,g_i)$ is not isometric to Euclidean space. But the book said that for all $r>0$, the $C^{1,\alpha}$ harmonic norm of $(M_i,g_i)$ of scale $r$ is nonzero. After scaling the metric suitably, it assumed the $C^{1,\alpha}$ harmonic norm of $(M_i,\bar{g_i})$ less than 1, and the pointed norm has positive lower bound. I think it is impossible, but I do not know how to correct it. It is true that if $(M_i,g_i)$ is not isometric to Euclidean space, we can find  $r_i$, such that the $C^{1,\alpha}$ harmonic norm of $(M_i,g_i)$ of scale $r_i$ is nonzero. But we do not know that it is uniformly bounded. Remark Crossposted in MO .","In ""Riemannian Geometry, Peter Petersen, GTM171, Third Edition"" page 430, there is an Anderson Lemma: For each $n\geq 2$, there is an $\varepsilon(n)>0$ such that any complete Ricci flat manifold (M,g) that satisfies $$Vol(B(p,r))\geq(1-\varepsilon)\omega_n r^n$$ for some $p\in M$ is isometric to Euclidean space. I have problem about the proof in this book. The book proved it by contradiction: for each $i$, it constructed a complete Ricci flat manifold $(M_i,g_i)$, with $\lim\limits_{i\rightarrow \infty}\frac{Vol(B(p_i,r)}{\omega_n r^n}\geq(1-\frac{1}{i})$, and $(M_i,g_i)$ is not isometric to Euclidean space. But the book said that for all $r>0$, the $C^{1,\alpha}$ harmonic norm of $(M_i,g_i)$ of scale $r$ is nonzero. After scaling the metric suitably, it assumed the $C^{1,\alpha}$ harmonic norm of $(M_i,\bar{g_i})$ less than 1, and the pointed norm has positive lower bound. I think it is impossible, but I do not know how to correct it. It is true that if $(M_i,g_i)$ is not isometric to Euclidean space, we can find  $r_i$, such that the $C^{1,\alpha}$ harmonic norm of $(M_i,g_i)$ of scale $r_i$ is nonzero. But we do not know that it is uniformly bounded. Remark Crossposted in MO .",,"['differential-geometry', 'riemannian-geometry']"
57,Why finite group action on n torus induced a faithful action on its first homology group.,Why finite group action on n torus induced a faithful action on its first homology group.,,Let G be a finite group of diffeomorphisms of the torus $T^n$ fixing some point p (i.e.p is fixed by every element of G). Why the action of G on $H_1(T^n; \mathbb{Z}) = \mathbb{Z}^n$ is faithful.,Let G be a finite group of diffeomorphisms of the torus $T^n$ fixing some point p (i.e.p is fixed by every element of G). Why the action of G on $H_1(T^n; \mathbb{Z}) = \mathbb{Z}^n$ is faithful.,,"['differential-geometry', 'differential-topology']"
58,Name of a degenerate foliation,Name of a degenerate foliation,,"Last summer I went to a talk where the speaker had a specific name for a certain kind of degenerated foliation on a manifold. Sadly, I forgot that name. Question : what is that name ? (Sorry if my question is vague) e.g. If you look at the level sets of $f(x,y)= x^2-y^2$ on $\mathbb R^2$ you get that sort of degenerated foliation.","Last summer I went to a talk where the speaker had a specific name for a certain kind of degenerated foliation on a manifold. Sadly, I forgot that name. Question : what is that name ? (Sorry if my question is vague) e.g. If you look at the level sets of $f(x,y)= x^2-y^2$ on $\mathbb R^2$ you get that sort of degenerated foliation.",,['differential-geometry']
59,Translating between two different definitions of exterior derivative,Translating between two different definitions of exterior derivative,,"If $\Omega^k(M)$ is the space of differential $1$-forms on a manifold $M$, one may define the operator $\mathop{}\!\mathrm{d} : \Omega^k(M) \to \Omega^{k+1}(M)$ in a coordinate-independent way as follows: $$\begin{split} \mathop{}\!\mathrm{d}\omega(X_0,\dots,X_k) = &\sum_{i=0}^k (-1)^i X_i\left(\omega(\dots,\hat X_i,\dots)\right) \\ &+ \sum_{0\leq i < j \leq k} (-1)^{i+j}\omega([X_i,X_j],\dots,\hat X_i, \dots, \hat X_j,\dots) \end{split}\tag{1}$$ I am trying to see if I can recover the usual definition in terms of local coordinates $x$: $$\mathop{}\!\mathrm{d}\omega(X_0,\dots,X_k) = \frac{\partial \omega_{i_1\cdots i_k}}{\partial x^{i_0}}(\mathop{}\!\mathrm{d}x^{i_0} \wedge \mathop{}\!\mathrm{d}x^{i_1} \wedge \cdots \wedge \mathop{}\!\mathrm{d}x^{i_k}) (X_0,\cdots,X_k)\tag{2}$$ In the case $k = 1$, equations $(1)$ and $(2)$ become $$\begin{split} d\omega(X_0,X_1) &= X_0(\omega(X_1)) - X_1(\omega(X_0)) -\omega([X_0,X_1]) = \square \\ d\omega(X_0,X_1) &= \dfrac{\partial \omega_a}{\partial x^k} (\mathop{}\!\mathrm{d}x^k \wedge \mathop{}\!\mathrm{d}x^a)(X_0,X_1) = \triangle \end{split}$$ Setting $\omega = \omega_a \mathop{}\!\mathrm{d}x^a$, $X_0 = X_0^i \dfrac{\partial}{\partial x^i}$, $X_1= X_1^j \dfrac{\partial}{\partial x^j}$, we see that the first equation becomes $$\begin{split} \square &= X_0^i \dfrac{\partial}{\partial x^i}\left(\omega_a \mathop{}\!\mathrm{d}x^a \left(X_1^j \dfrac{\partial}{\partial x^j}\right)\right) - X_1^j \dfrac{\partial}{\partial x^j}\left(\omega_a \mathop{}\!\mathrm{d}x^a \left(X_0^i \dfrac{\partial}{\partial x^i}\right)\right) \\ &\quad - \omega_a \mathop{}\!\mathrm{d}x^a\left(\left(X_0^i \dfrac{\partial X_1^j}{\partial x^i} - X_1^j \dfrac{\partial X_0^i}{\partial x^j}\right)\dfrac{\partial}{\partial x^m}\right) \\ &= X_0^iX_1^j \dfrac{\partial \omega_j}{\partial x^i} - X_0^i X_1^j \dfrac{\partial \omega_i}{\partial x^j} - X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i \\ &= X_0^iX_1^j \left(\dfrac{\partial \omega_j}{\partial x^i} -  \dfrac{\partial \omega_i}{\partial x^j}\right) - X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i \end{split}$$ On the other hand, the second equation becomes $$\begin{split} \triangle &= \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j \delta^{ka}_{ij} = \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j \det \begin{pmatrix} \delta^k_i & \delta^k_j \\ \delta^a_i & \delta^a_j\end{pmatrix}\\ &= \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j (\delta^k_i\delta^a_j - \delta^k_j\delta^a_i) = \left(\dfrac{\partial \omega_j}{\partial x^i} - \dfrac{\partial \omega_i}{\partial x^j}\right) X_0^i X_1^j \end{split} $$ This means that if $\square = \triangle$ then $$- X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i = 0 $$ Yet if this is so (and I still can't see why) then I'm at a loss at understanding the need for the second summation in equation $(1)$. Would someone care to elucidate and/or point out errors in my calculations?","If $\Omega^k(M)$ is the space of differential $1$-forms on a manifold $M$, one may define the operator $\mathop{}\!\mathrm{d} : \Omega^k(M) \to \Omega^{k+1}(M)$ in a coordinate-independent way as follows: $$\begin{split} \mathop{}\!\mathrm{d}\omega(X_0,\dots,X_k) = &\sum_{i=0}^k (-1)^i X_i\left(\omega(\dots,\hat X_i,\dots)\right) \\ &+ \sum_{0\leq i < j \leq k} (-1)^{i+j}\omega([X_i,X_j],\dots,\hat X_i, \dots, \hat X_j,\dots) \end{split}\tag{1}$$ I am trying to see if I can recover the usual definition in terms of local coordinates $x$: $$\mathop{}\!\mathrm{d}\omega(X_0,\dots,X_k) = \frac{\partial \omega_{i_1\cdots i_k}}{\partial x^{i_0}}(\mathop{}\!\mathrm{d}x^{i_0} \wedge \mathop{}\!\mathrm{d}x^{i_1} \wedge \cdots \wedge \mathop{}\!\mathrm{d}x^{i_k}) (X_0,\cdots,X_k)\tag{2}$$ In the case $k = 1$, equations $(1)$ and $(2)$ become $$\begin{split} d\omega(X_0,X_1) &= X_0(\omega(X_1)) - X_1(\omega(X_0)) -\omega([X_0,X_1]) = \square \\ d\omega(X_0,X_1) &= \dfrac{\partial \omega_a}{\partial x^k} (\mathop{}\!\mathrm{d}x^k \wedge \mathop{}\!\mathrm{d}x^a)(X_0,X_1) = \triangle \end{split}$$ Setting $\omega = \omega_a \mathop{}\!\mathrm{d}x^a$, $X_0 = X_0^i \dfrac{\partial}{\partial x^i}$, $X_1= X_1^j \dfrac{\partial}{\partial x^j}$, we see that the first equation becomes $$\begin{split} \square &= X_0^i \dfrac{\partial}{\partial x^i}\left(\omega_a \mathop{}\!\mathrm{d}x^a \left(X_1^j \dfrac{\partial}{\partial x^j}\right)\right) - X_1^j \dfrac{\partial}{\partial x^j}\left(\omega_a \mathop{}\!\mathrm{d}x^a \left(X_0^i \dfrac{\partial}{\partial x^i}\right)\right) \\ &\quad - \omega_a \mathop{}\!\mathrm{d}x^a\left(\left(X_0^i \dfrac{\partial X_1^j}{\partial x^i} - X_1^j \dfrac{\partial X_0^i}{\partial x^j}\right)\dfrac{\partial}{\partial x^m}\right) \\ &= X_0^iX_1^j \dfrac{\partial \omega_j}{\partial x^i} - X_0^i X_1^j \dfrac{\partial \omega_i}{\partial x^j} - X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i \\ &= X_0^iX_1^j \left(\dfrac{\partial \omega_j}{\partial x^i} -  \dfrac{\partial \omega_i}{\partial x^j}\right) - X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i \end{split}$$ On the other hand, the second equation becomes $$\begin{split} \triangle &= \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j \delta^{ka}_{ij} = \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j \det \begin{pmatrix} \delta^k_i & \delta^k_j \\ \delta^a_i & \delta^a_j\end{pmatrix}\\ &= \dfrac{\partial \omega_a}{\partial x^k} X_0^i X_1^j (\delta^k_i\delta^a_j - \delta^k_j\delta^a_i) = \left(\dfrac{\partial \omega_j}{\partial x^i} - \dfrac{\partial \omega_i}{\partial x^j}\right) X_0^i X_1^j \end{split} $$ This means that if $\square = \triangle$ then $$- X_0^i \dfrac{\partial X_1^j}{\partial x^i} \omega_j + \dfrac{\partial X_0^i}{\partial x^j} X_1^j \omega_i = 0 $$ Yet if this is so (and I still can't see why) then I'm at a loss at understanding the need for the second summation in equation $(1)$. Would someone care to elucidate and/or point out errors in my calculations?",,"['differential-geometry', 'differential-forms', 'exterior-algebra']"
60,Riemann manifolds and Levi-Civita connection,Riemann manifolds and Levi-Civita connection,,"Let $(M, \langle.,.\rangle )$ be a 2-dimensional Riemannian manifold, $\nabla$ its Levi-Civita connection. How can I show that there is a function $K \in \mathscr C^{\infty}(M)$ such that $$R^{\nabla}(X,Y)Z=K(\langle Y,Z\rangle X-\langle X,Z \rangle Y) $$ for all $X,Y,Z \in \Gamma (TM)$? Would appreciate some help or approach to solve this, thanks in advance.","Let $(M, \langle.,.\rangle )$ be a 2-dimensional Riemannian manifold, $\nabla$ its Levi-Civita connection. How can I show that there is a function $K \in \mathscr C^{\infty}(M)$ such that $$R^{\nabla}(X,Y)Z=K(\langle Y,Z\rangle X-\langle X,Z \rangle Y) $$ for all $X,Y,Z \in \Gamma (TM)$? Would appreciate some help or approach to solve this, thanks in advance.",,"['differential-geometry', 'manifolds', 'riemannian-geometry']"
61,Parallel Transport Along Nearby Curves Produces Nearby Vectors,Parallel Transport Along Nearby Curves Produces Nearby Vectors,,"Let $(M, g)$ be a Riemannian manifold and $d$ denote the Riemannian distance function on $M$. Let $p$ and $q$ be two points on $M$ and $X$ be a vector in $T_pM$. Let $C$ be the set of all the smooth paths defined on the unit interval joining $p$ to $q$. Define a metric $D:C\times C\to \mathbf R_{\geq 0}$ on $C$ as $$D(\gamma, \eta) = \sup_{t\in I} d(\gamma(t), \eta(t))$$ For $\gamma\in C$, let $P_\gamma:T_pM\to T_qM$ denote the parallel transport map corresponding to $\gamma$. I want to show the following: The map $C\to T_qM$ defined as $\gamma\mapsto P_\gamma X$ is continuous. In other words, if two paths in $C$ are nearby, then the resulting vectors got by parallel transporting along them gives two vectors which are also nearby. I wanted to apply the result I am trying to prove here . If $\gamma$ and $\eta$ are two curves in $C$ which do not intersect and are contained in a single chart, then it seems intuitively obvious that the area enclosed between $\gamma$ and $\eta$ is small, and the result just alluded may be applicable. But of course, $\gamma$ and $\eta$ can intersect badly.","Let $(M, g)$ be a Riemannian manifold and $d$ denote the Riemannian distance function on $M$. Let $p$ and $q$ be two points on $M$ and $X$ be a vector in $T_pM$. Let $C$ be the set of all the smooth paths defined on the unit interval joining $p$ to $q$. Define a metric $D:C\times C\to \mathbf R_{\geq 0}$ on $C$ as $$D(\gamma, \eta) = \sup_{t\in I} d(\gamma(t), \eta(t))$$ For $\gamma\in C$, let $P_\gamma:T_pM\to T_qM$ denote the parallel transport map corresponding to $\gamma$. I want to show the following: The map $C\to T_qM$ defined as $\gamma\mapsto P_\gamma X$ is continuous. In other words, if two paths in $C$ are nearby, then the resulting vectors got by parallel transporting along them gives two vectors which are also nearby. I wanted to apply the result I am trying to prove here . If $\gamma$ and $\eta$ are two curves in $C$ which do not intersect and are contained in a single chart, then it seems intuitively obvious that the area enclosed between $\gamma$ and $\eta$ is small, and the result just alluded may be applicable. But of course, $\gamma$ and $\eta$ can intersect badly.",,"['differential-geometry', 'riemannian-geometry']"
62,Stokes' theorem proof without FTC,Stokes' theorem proof without FTC,,To present time I have not found a proof of Stokes' Theorem for manifolds that does not involve the Fundamental Theorem of Calculus in some way. Is it possible to prove the general theorem without employing its famous special case? Or does it necessarily have to rely on the FTC?,To present time I have not found a proof of Stokes' Theorem for manifolds that does not involve the Fundamental Theorem of Calculus in some way. Is it possible to prove the general theorem without employing its famous special case? Or does it necessarily have to rely on the FTC?,,"['integration', 'differential-geometry', 'stokes-theorem', 'manifolds-with-boundary']"
63,Exterior derivative of a $0$-form,Exterior derivative of a -form,0,"Let $n\in\mathbb{N}$, $f \in F_1(\mathbb{R}^n)$, say, $$f = \sum_{j=1,...,n}f_jdx_j,$$ with $df=0$. Define for each $x\in\mathbb{R}^n$, $$u(x)=\sum_{j=1,...,n}\int_{[0,1]}f_j(tx)p_j(x)dt$$ ($p_j$'s are projections). Then $u \in F_0(\mathbb{R}^n)$ and $du=f$. It seems to me that it is clear $u$ is a $0$-form, correct? Now, what I (think I) can do so far is $$du = d\sum_{j=1,...,n}\int_{[0,1]}f_j(t-)p_j(-)dt = \sum_{j=1,...,n}d\int_{[0,1]}f_j(t-)p_j(-)dt =$$ $$ \sum_{j=1,...,n}\sum_{k=1,...,n}\partial_k(\int_{[0,1]}f_j(t-)p_j(-)dt)dx_k = \sum_{j=1,...,n}\sum_{k=1,...,n}\int_{[0,1]}\partial_k(f_j(t-)p_j(-))dtdx_k =$$ $$\sum_{j=1,...,n}\sum_{k=1,...,n}\int_{[0,1]}(t(\partial_k(f_j))(t-)p_j(-)+f_j(t-)\partial_k(p_j)(-))dtdx_k = ...$$ am I still good here, or did I go astray? If I'm good, how do I continue? Am I making things more complicated than they are? Also, I realize that the hypothesis is that $$0 = df = \sum_{j=1,...,n}\sum_{k=1,...,n} \partial_k(f_j) dx_k \wedge dx_j.$$ Thanks in advance.","Let $n\in\mathbb{N}$, $f \in F_1(\mathbb{R}^n)$, say, $$f = \sum_{j=1,...,n}f_jdx_j,$$ with $df=0$. Define for each $x\in\mathbb{R}^n$, $$u(x)=\sum_{j=1,...,n}\int_{[0,1]}f_j(tx)p_j(x)dt$$ ($p_j$'s are projections). Then $u \in F_0(\mathbb{R}^n)$ and $du=f$. It seems to me that it is clear $u$ is a $0$-form, correct? Now, what I (think I) can do so far is $$du = d\sum_{j=1,...,n}\int_{[0,1]}f_j(t-)p_j(-)dt = \sum_{j=1,...,n}d\int_{[0,1]}f_j(t-)p_j(-)dt =$$ $$ \sum_{j=1,...,n}\sum_{k=1,...,n}\partial_k(\int_{[0,1]}f_j(t-)p_j(-)dt)dx_k = \sum_{j=1,...,n}\sum_{k=1,...,n}\int_{[0,1]}\partial_k(f_j(t-)p_j(-))dtdx_k =$$ $$\sum_{j=1,...,n}\sum_{k=1,...,n}\int_{[0,1]}(t(\partial_k(f_j))(t-)p_j(-)+f_j(t-)\partial_k(p_j)(-))dtdx_k = ...$$ am I still good here, or did I go astray? If I'm good, how do I continue? Am I making things more complicated than they are? Also, I realize that the hypothesis is that $$0 = df = \sum_{j=1,...,n}\sum_{k=1,...,n} \partial_k(f_j) dx_k \wedge dx_j.$$ Thanks in advance.",,['differential-geometry']
64,A fast introduction to Psuedo-Riammanian Manifolds and Riemannian Manifolds,A fast introduction to Psuedo-Riammanian Manifolds and Riemannian Manifolds,,"I apologize in advance for the long length of this question Okay so let me explain my background. I know quite a bit of General Topology, including Topological Manifolds. I know some basic stuff about Algebraic Topology, and Differential Topology (about half of Milnor's Topology from the Differentiable Viewpoint and the half of the first chapter of Guillemin and Pollack) My strength is Topology, but I'm currently trying to to read up on a paper that deals with a topological construction on smooth manifolds. I can understand the topological aspects just fine, however there are a number of examples given of this construction on Pseudo-Riemannian Manifolds, of which I've never dealt with and I need to understand these examples of Pseudo-Riemannian examples to be able to fully understand the paper (which is geared towards the application of this topological construction to Pseudo-Riemannian Manifolds). Now I need to learn this material fast, as the research group I'm working with hopes to publish a paper sometime in June next year. I'm giving myself around 1 month to learn the pre-requisite Riemannian and Pseudo-Riemannian Geometry I'm currently reading through Lee's Introduction to Smooth Manifolds, and I'll soon be fairly comfortable with the first 3 chapters. What's the fastest way to learn enough Riemannian and Pseudo-Riemannian Geometry to understand the examples given below provided that I have no knowledge of tensors / tensor fields differential forms vector bundles and tensor bundles But I do have a solid knowledge of metric spaces, metrics (not riemannian metrics, just metrics on metric spaces), and linear algebra and basic group, ring and module theory. For example I find Keith Conrad's notes on tensor products of modules quite readable ( http://www.math.uconn.edu/~kconrad/blurbs/linmultialg/tensorprod.pdf ) What chapters (and in what order) should I look at in Lee's Introduction to Smooth Manifolds to gain a solid grasp of Pseudo-Riemannian Geometry and Riemannian Geometry? If there is another book which is more streamlined to Riemannian Geometry and Pseudo-Riemannian Geometry, and which would allow me to learn the material faster, please let me know. The two disadvantages to this is that I'd have to get used to another authors notation (which is really not an easy process especially in Differential Geometry), and I wouldn't be using Lee's book which I plan to use for DIfferential Geometry. Below is the level of Riemannian Geometry that I need to learn, it's an example taken from the paper.","I apologize in advance for the long length of this question Okay so let me explain my background. I know quite a bit of General Topology, including Topological Manifolds. I know some basic stuff about Algebraic Topology, and Differential Topology (about half of Milnor's Topology from the Differentiable Viewpoint and the half of the first chapter of Guillemin and Pollack) My strength is Topology, but I'm currently trying to to read up on a paper that deals with a topological construction on smooth manifolds. I can understand the topological aspects just fine, however there are a number of examples given of this construction on Pseudo-Riemannian Manifolds, of which I've never dealt with and I need to understand these examples of Pseudo-Riemannian examples to be able to fully understand the paper (which is geared towards the application of this topological construction to Pseudo-Riemannian Manifolds). Now I need to learn this material fast, as the research group I'm working with hopes to publish a paper sometime in June next year. I'm giving myself around 1 month to learn the pre-requisite Riemannian and Pseudo-Riemannian Geometry I'm currently reading through Lee's Introduction to Smooth Manifolds, and I'll soon be fairly comfortable with the first 3 chapters. What's the fastest way to learn enough Riemannian and Pseudo-Riemannian Geometry to understand the examples given below provided that I have no knowledge of tensors / tensor fields differential forms vector bundles and tensor bundles But I do have a solid knowledge of metric spaces, metrics (not riemannian metrics, just metrics on metric spaces), and linear algebra and basic group, ring and module theory. For example I find Keith Conrad's notes on tensor products of modules quite readable ( http://www.math.uconn.edu/~kconrad/blurbs/linmultialg/tensorprod.pdf ) What chapters (and in what order) should I look at in Lee's Introduction to Smooth Manifolds to gain a solid grasp of Pseudo-Riemannian Geometry and Riemannian Geometry? If there is another book which is more streamlined to Riemannian Geometry and Pseudo-Riemannian Geometry, and which would allow me to learn the material faster, please let me know. The two disadvantages to this is that I'd have to get used to another authors notation (which is really not an easy process especially in Differential Geometry), and I wouldn't be using Lee's book which I plan to use for DIfferential Geometry. Below is the level of Riemannian Geometry that I need to learn, it's an example taken from the paper.",,"['differential-geometry', 'reference-request', 'soft-question', 'riemannian-geometry']"
65,homogeneous spaces are real analytic,homogeneous spaces are real analytic,,Let $G$ be a Lie group and $H$ be a closed subgroup. How to prove that the homogeneous space $G/H$ is a real analytic manifold?,Let $G$ be a Lie group and $H$ be a closed subgroup. How to prove that the homogeneous space $G/H$ is a real analytic manifold?,,"['differential-geometry', 'lie-groups', 'smooth-manifolds']"
66,Simons '68 minimal varieties notation,Simons '68 minimal varieties notation,,"I'm trying to understand this paper ( Simons '68 ) and I'm a bit confused with notation. For a $p$ dimensional manifold $M$ immersed in an $n$ dimensional manifold $\bar M$ with $TM$, $NM$ respectively the tangent and normal bundle of $M$ and $SM$ ""the bundle whose fibre at each point is the space of symmetric linear transformations of $T_pM \to T_pM$"" he defines $$\overset {\sim} A := \, ^t\!A \circ A$$ and $$\underset \sim A := \sum_{i=1}^{n-p} \text{ad } A^{V_i} \, \text{ad } A^{V_i}$$ where $\langle ^t\!A(S),V\rangle = \langle A^V,S\rangle$, $S \in SM, \, V \in \text{Hom}(NM,SM)$, $A^{V} = - (\nabla_X V)^T$ for a tangential vector field $X$ and a normal field $V$. What does he mean by $\text{ad } A^{V}$ ? Is this just the adjoint, ie. the transpose? Ultimately I'm trying to understand the equation from Theorem 4.2.1. Let $A$ be the second fundamental form of a minimal variety. Then $A$ satisfies   $$ \nabla^2 A = - A \circ \overset \sim A - \underset \sim A \circ A + \bar R(A) + \bar R'$$ and how this differential equation is linear. Does anyone know a review of that paper? It's quite technical, and some more text wouldn't hurt. (also explaining no(ta)tions a bit more) As always, thanks a lot for any help!","I'm trying to understand this paper ( Simons '68 ) and I'm a bit confused with notation. For a $p$ dimensional manifold $M$ immersed in an $n$ dimensional manifold $\bar M$ with $TM$, $NM$ respectively the tangent and normal bundle of $M$ and $SM$ ""the bundle whose fibre at each point is the space of symmetric linear transformations of $T_pM \to T_pM$"" he defines $$\overset {\sim} A := \, ^t\!A \circ A$$ and $$\underset \sim A := \sum_{i=1}^{n-p} \text{ad } A^{V_i} \, \text{ad } A^{V_i}$$ where $\langle ^t\!A(S),V\rangle = \langle A^V,S\rangle$, $S \in SM, \, V \in \text{Hom}(NM,SM)$, $A^{V} = - (\nabla_X V)^T$ for a tangential vector field $X$ and a normal field $V$. What does he mean by $\text{ad } A^{V}$ ? Is this just the adjoint, ie. the transpose? Ultimately I'm trying to understand the equation from Theorem 4.2.1. Let $A$ be the second fundamental form of a minimal variety. Then $A$ satisfies   $$ \nabla^2 A = - A \circ \overset \sim A - \underset \sim A \circ A + \bar R(A) + \bar R'$$ and how this differential equation is linear. Does anyone know a review of that paper? It's quite technical, and some more text wouldn't hurt. (also explaining no(ta)tions a bit more) As always, thanks a lot for any help!",,"['differential-geometry', 'riemannian-geometry', 'minimal-surfaces']"
67,Some pretty identities and adjoint of interior product of differential forms,Some pretty identities and adjoint of interior product of differential forms,,"Let $M$ be a riemannian manifold. For each $k\geq 0$ , let $ \bigwedge^{k}(M, \mathbb R)=\bigsqcup\limits_{p\in M}\ \bigwedge^k(T^*_pM)$ denote the smooth bundle of ( $k$ -multilinear) alternating forms on $M.$ If $\alpha\in\bigwedge^{k-1}(M, \mathbb R), \beta\in\bigwedge^{k}(M, \mathbb R)$ and $v$ is a tangent vector, I want to prove that $$(1)\qquad \qquad\langle\!\langle v^\flat \wedge \alpha, \beta\rangle\!\rangle = \langle\!\langle \alpha,v\lrcorner\beta\rangle\! \rangle,$$ where $v^\flat(w) := \langle v,w\rangle$ and $\langle\!\langle \,, \rangle\! \rangle$ denotes the standard inner product on $\bigwedge^{k}(M, \mathbb R)$ . That is, $\lrcorner$ and $\wedge$ are actually adjoint operators with respect to $\langle\!\langle \,, \rangle\! \rangle$ . I have seen this statement at several isolated places, but I haven't seen a proof of this (maybe it's not hard at all and I'm just not getting it, so it would be cool to know why this formula actually holds). Also, if $\gamma\in\bigwedge^{k}(M, \mathbb R)$ and $v, w$ are tangent vectors, I want to see why the following Clifford relation holds $$(2)\qquad\qquad v^\flat \wedge (w\lrcorner\gamma)+w\lrcorner(v^\flat\wedge \gamma)=\langle v, w \rangle\gamma.$$ Finally, Willie Wong states here that there exists a constant $C$ (which depends a bit on the conventions and also on the dimension and the degree of the forms) such that $$(3)\qquad\qquad v\lrcorner\gamma = C \star(v^\flat\wedge \star\gamma), $$ where $\star$ is the Hodge star operator . How can I prove this formula?(which in turn also must determine the exact value of $C$ ) I apologize if these formulas are easy to prove (I collected some ""trivialities"" usually left as an exercise to the reader), but I find them very pretty and somewhat cryptic, I'm not really sure on how should I proceed. Also, it seems that nobody actually wants to write out all the (possibly gory) details (or at least to explain them), so any help or reference is highly appreciated.","Let be a riemannian manifold. For each , let denote the smooth bundle of ( -multilinear) alternating forms on If and is a tangent vector, I want to prove that where and denotes the standard inner product on . That is, and are actually adjoint operators with respect to . I have seen this statement at several isolated places, but I haven't seen a proof of this (maybe it's not hard at all and I'm just not getting it, so it would be cool to know why this formula actually holds). Also, if and are tangent vectors, I want to see why the following Clifford relation holds Finally, Willie Wong states here that there exists a constant (which depends a bit on the conventions and also on the dimension and the degree of the forms) such that where is the Hodge star operator . How can I prove this formula?(which in turn also must determine the exact value of ) I apologize if these formulas are easy to prove (I collected some ""trivialities"" usually left as an exercise to the reader), but I find them very pretty and somewhat cryptic, I'm not really sure on how should I proceed. Also, it seems that nobody actually wants to write out all the (possibly gory) details (or at least to explain them), so any help or reference is highly appreciated.","M k\geq 0  \bigwedge^{k}(M, \mathbb R)=\bigsqcup\limits_{p\in M}\ \bigwedge^k(T^*_pM) k M. \alpha\in\bigwedge^{k-1}(M, \mathbb R), \beta\in\bigwedge^{k}(M, \mathbb R) v (1)\qquad \qquad\langle\!\langle v^\flat \wedge \alpha, \beta\rangle\!\rangle = \langle\!\langle \alpha,v\lrcorner\beta\rangle\! \rangle, v^\flat(w) := \langle v,w\rangle \langle\!\langle \,, \rangle\! \rangle \bigwedge^{k}(M, \mathbb R) \lrcorner \wedge \langle\!\langle \,, \rangle\! \rangle \gamma\in\bigwedge^{k}(M, \mathbb R) v, w (2)\qquad\qquad v^\flat \wedge (w\lrcorner\gamma)+w\lrcorner(v^\flat\wedge \gamma)=\langle v, w \rangle\gamma. C (3)\qquad\qquad v\lrcorner\gamma = C \star(v^\flat\wedge \star\gamma),  \star C","['differential-geometry', 'reference-request', 'riemannian-geometry', 'multilinear-algebra']"
68,Relationship between two manifolds with identical dimension,Relationship between two manifolds with identical dimension,,"I am now learning some knowledge about differential manifolds by myself. The problem I meet is that it seems that a manifold $M$ can be a proper subset of another manifold $N$ even if they have identical dimensions. But in the literature, some researchers have presented the following statement: Given a manifold $M$ of dimension $d_m$ and a manifold $N$ of dimension $d_n$, $M\subset N$, and $p\in M$. Then $M\cap U=N\cap U$ for some neighborhood $U$ of $p$ if and only if $d_m=d_n$. I am confused to answer that if $M$ and $N$ are two smooth manifolds with identical dimensions, and $M\subset N$ Q1. Can we conclude that $M=N$? Q2. If the answer of Q1 is no, then can we conclude that for each $p\in M$, it holds $M\cap U=N\cap U$ for some neighborhood $U$ of $p$ ? Q3. If the answer of Q2 is yes, how to prove the statement in Q2, is there any relevant theorems ? Thank you for your answer!","I am now learning some knowledge about differential manifolds by myself. The problem I meet is that it seems that a manifold $M$ can be a proper subset of another manifold $N$ even if they have identical dimensions. But in the literature, some researchers have presented the following statement: Given a manifold $M$ of dimension $d_m$ and a manifold $N$ of dimension $d_n$, $M\subset N$, and $p\in M$. Then $M\cap U=N\cap U$ for some neighborhood $U$ of $p$ if and only if $d_m=d_n$. I am confused to answer that if $M$ and $N$ are two smooth manifolds with identical dimensions, and $M\subset N$ Q1. Can we conclude that $M=N$? Q2. If the answer of Q1 is no, then can we conclude that for each $p\in M$, it holds $M\cap U=N\cap U$ for some neighborhood $U$ of $p$ ? Q3. If the answer of Q2 is yes, how to prove the statement in Q2, is there any relevant theorems ? Thank you for your answer!",,"['differential-geometry', 'smooth-manifolds']"
69,Ricci tensor of the Grassmannian manifold,Ricci tensor of the Grassmannian manifold,,"I'm wondering if anyone could help me with calculating the Ricci tensor for the Grassmannian manifold. For Kähler manifolds we have: \begin{equation}     R_{\mu \bar{\nu}} = -\partial_{\bar{\nu}} \partial_{\mu} \log \det g_{\mu\bar{\nu}} \end{equation} For the Grassmannian, we are using the two-index notation \begin{equation} \Phi^{n\alpha} \quad,\qquad \text{where} \quad n=1\ldots N,\quad \alpha=1\ldots M \end{equation} And so, the Ricci tensor will have four indices, $R_{i\bar{j}\alpha\bar{\beta}}$. The Kähler potential is given by: \begin{equation}     K = \operatorname{Tr} \ln (\delta^{n\bar{m}} + \Phi^{n\gamma}\overline{\Phi}^{\bar{\gamma} \bar{m}}) \end{equation} Here we take the trace over the Latin indices, but we could also define $K = \operatorname{Tr} \ln (\delta^{\alpha\bar{\beta}} + \Phi^{n\alpha}\overline{\Phi}^{\bar{\beta}\bar{n}})$ and take the trace with respect to the Greek indices. The subscripts are reserved for lowering with the aid of the metric tensor. The latter is obtained as follows: \begin{gather}     G_{i\bar{j} \alpha \bar{\beta}}     =     \dfrac{\partial}{\partial \Phi^{i\alpha}}     \dfrac{\partial}{\partial \overline{\Phi}^{\bar{\beta}\bar{j}}}     K     = \operatorname{Tr} \left\{     \delta^{ni}\delta^{\alpha\bar{\beta}}(A^{-1})^{\bar{j} m}      - \Phi^{n\beta}     (A^{-1})^{\bar{j} i}     \overline{\Phi}^{\bar{\alpha} \bar{l}}     (A^{-1})^{\bar{l} m}     \right\} \end{gather} How should I proceed from here? I guess, the answer should be \begin{equation}     R_{i\bar{j}\alpha\bar{\beta}} \propto (M+N)G_{i\bar{j}\alpha\bar{\beta}} \end{equation}","I'm wondering if anyone could help me with calculating the Ricci tensor for the Grassmannian manifold. For Kähler manifolds we have: \begin{equation}     R_{\mu \bar{\nu}} = -\partial_{\bar{\nu}} \partial_{\mu} \log \det g_{\mu\bar{\nu}} \end{equation} For the Grassmannian, we are using the two-index notation \begin{equation} \Phi^{n\alpha} \quad,\qquad \text{where} \quad n=1\ldots N,\quad \alpha=1\ldots M \end{equation} And so, the Ricci tensor will have four indices, $R_{i\bar{j}\alpha\bar{\beta}}$. The Kähler potential is given by: \begin{equation}     K = \operatorname{Tr} \ln (\delta^{n\bar{m}} + \Phi^{n\gamma}\overline{\Phi}^{\bar{\gamma} \bar{m}}) \end{equation} Here we take the trace over the Latin indices, but we could also define $K = \operatorname{Tr} \ln (\delta^{\alpha\bar{\beta}} + \Phi^{n\alpha}\overline{\Phi}^{\bar{\beta}\bar{n}})$ and take the trace with respect to the Greek indices. The subscripts are reserved for lowering with the aid of the metric tensor. The latter is obtained as follows: \begin{gather}     G_{i\bar{j} \alpha \bar{\beta}}     =     \dfrac{\partial}{\partial \Phi^{i\alpha}}     \dfrac{\partial}{\partial \overline{\Phi}^{\bar{\beta}\bar{j}}}     K     = \operatorname{Tr} \left\{     \delta^{ni}\delta^{\alpha\bar{\beta}}(A^{-1})^{\bar{j} m}      - \Phi^{n\beta}     (A^{-1})^{\bar{j} i}     \overline{\Phi}^{\bar{\alpha} \bar{l}}     (A^{-1})^{\bar{l} m}     \right\} \end{gather} How should I proceed from here? I guess, the answer should be \begin{equation}     R_{i\bar{j}\alpha\bar{\beta}} \propto (M+N)G_{i\bar{j}\alpha\bar{\beta}} \end{equation}",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'grassmannian']"
70,Homotoping a Morse function to put all of the critical points on the boundary,Homotoping a Morse function to put all of the critical points on the boundary,,Let $M$ be a connected manifold with boundary and let $f: M \to \mathbb{R}$ be a Morse function (that does not necessarily send the boundary of $M$ to a point).  Is it always possible to homotope $f$ through Morse functions so that all of the critical points are on the boundary of $M$? My initial thought was that this can not be true since then the interior of $M$ admits a Morse function that does not have any critical points - but there is no problem with that as all open manifolds admit Morse functions without critical points.,Let $M$ be a connected manifold with boundary and let $f: M \to \mathbb{R}$ be a Morse function (that does not necessarily send the boundary of $M$ to a point).  Is it always possible to homotope $f$ through Morse functions so that all of the critical points are on the boundary of $M$? My initial thought was that this can not be true since then the interior of $M$ admits a Morse function that does not have any critical points - but there is no problem with that as all open manifolds admit Morse functions without critical points.,,"['differential-geometry', 'differential-topology', 'geometric-topology']"
71,Showing that a 7-manifold has $G_{2}$ holonomy,Showing that a 7-manifold has  holonomy,G_{2},I have to show that the direct product of the multi-center Taub-NUT metric with $\mathbb{R}^{3}$ corresponds to a 7-manifold with G2 holonomy. The metric of the Taub-NUT is: $ds_{TN}^{2}=V(r)(dr^{2}+r^{2}d\Omega _{2}^{2})+\frac{1}{V(r)}\left ( dy+R\mbox{sin}^{2}\left ( \theta /2  \right )d\phi\right )^{2}$ with $d\Omega _{2}^{2}=d\theta ^{2}+\mbox{sin}^{2}\theta d\phi^{2}$ and $V(r)=1+\frac{R}{2r}$ I don´t know if it will be enough to show that it is Ricci-flat ($R_{mn}=0)$ or trying to find the associative calibration $\Phi$ and show that $\nabla^{g}\Phi=0$ but in this case I don't know how to obtain the components of the three-form $\Phi_{abc}$... Is there a better way to do so? (I don´t know even if my option would be correct...),I have to show that the direct product of the multi-center Taub-NUT metric with $\mathbb{R}^{3}$ corresponds to a 7-manifold with G2 holonomy. The metric of the Taub-NUT is: $ds_{TN}^{2}=V(r)(dr^{2}+r^{2}d\Omega _{2}^{2})+\frac{1}{V(r)}\left ( dy+R\mbox{sin}^{2}\left ( \theta /2  \right )d\phi\right )^{2}$ with $d\Omega _{2}^{2}=d\theta ^{2}+\mbox{sin}^{2}\theta d\phi^{2}$ and $V(r)=1+\frac{R}{2r}$ I don´t know if it will be enough to show that it is Ricci-flat ($R_{mn}=0)$ or trying to find the associative calibration $\Phi$ and show that $\nabla^{g}\Phi=0$ but in this case I don't know how to obtain the components of the three-form $\Phi_{abc}$... Is there a better way to do so? (I don´t know even if my option would be correct...),,"['differential-geometry', 'riemannian-geometry', 'holonomy', 'calibrated-geometry']"
72,On the diagonalizability of two-dimensional metrics,On the diagonalizability of two-dimensional metrics,,"Assume that $M$ is a two dimensional manifold with (pseudo-)Riemannian metric $g$. In some local chart $(\tau,\sigma)$ we have $$ g=A(\tau,\sigma)d\tau^2+B(\tau,\sigma)d\sigma^2+C(\tau,\sigma)(d\tau\otimes d\sigma+d\sigma\otimes d\tau ). $$ I am aware that this metric is always diagonalizable (in fact, all two dimensional metrics are conformally flat), however if we make the additional condition that we must keep the $\sigma$ coordinate fixed, I'm stuck. It is clear that the metric is diagonized, if we find an exact form $dt$ which is orthogonal to $d\sigma$. This orthogonality may be expressed in local coordinates as $$ g^{ij}\partial_i t\partial_j \sigma=g^{i \sigma}\partial_i t=0. $$ Renaming $g^{i \sigma}=V^i$, this is just $V^i\partial_i t=0$. The functions $A,B,C$ are arbitrary (as long as they form a metric), so the inverse metric functions $g^{\tau\sigma},g^{\sigma\sigma}$ are essentially arbitrary. So the problem is equivalent to asking whether an arbitrary smooth vector field (in 2 dimensions) has a (locally) exact annulator. I can feel this is very easy to prove, but I am unable to. I have no idea how to show that the equation $$ V^\tau(\tau,\sigma)\frac{\partial t}{\partial\tau}+V^\sigma(\tau,\sigma)\frac{\partial t}{\partial \sigma}=0 $$ is soluble. Any other method is also welcome. I tried to look for situations in which Poincaré's lemma or Frobenius' theorem can be applied to help out - to no avail, but as I said, I think I'm missing something trivial and obvious.","Assume that $M$ is a two dimensional manifold with (pseudo-)Riemannian metric $g$. In some local chart $(\tau,\sigma)$ we have $$ g=A(\tau,\sigma)d\tau^2+B(\tau,\sigma)d\sigma^2+C(\tau,\sigma)(d\tau\otimes d\sigma+d\sigma\otimes d\tau ). $$ I am aware that this metric is always diagonalizable (in fact, all two dimensional metrics are conformally flat), however if we make the additional condition that we must keep the $\sigma$ coordinate fixed, I'm stuck. It is clear that the metric is diagonized, if we find an exact form $dt$ which is orthogonal to $d\sigma$. This orthogonality may be expressed in local coordinates as $$ g^{ij}\partial_i t\partial_j \sigma=g^{i \sigma}\partial_i t=0. $$ Renaming $g^{i \sigma}=V^i$, this is just $V^i\partial_i t=0$. The functions $A,B,C$ are arbitrary (as long as they form a metric), so the inverse metric functions $g^{\tau\sigma},g^{\sigma\sigma}$ are essentially arbitrary. So the problem is equivalent to asking whether an arbitrary smooth vector field (in 2 dimensions) has a (locally) exact annulator. I can feel this is very easy to prove, but I am unable to. I have no idea how to show that the equation $$ V^\tau(\tau,\sigma)\frac{\partial t}{\partial\tau}+V^\sigma(\tau,\sigma)\frac{\partial t}{\partial \sigma}=0 $$ is soluble. Any other method is also welcome. I tried to look for situations in which Poincaré's lemma or Frobenius' theorem can be applied to help out - to no avail, but as I said, I think I'm missing something trivial and obvious.",,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry']"
73,"Gradient of a function $f \colon L^2[0, 1] \rightarrow \mathbb{R}$.",Gradient of a function .,"f \colon L^2[0, 1] \rightarrow \mathbb{R}","I want to think of $L^2[0, 1]$ as a generalization of the finite-dimensional $\mathbb{R}^n$. In this case, the gradient of a function $f \colon \mathbb{R}^n \rightarrow \mathbb{R}$ is  $$ \nabla f = \left( \partial_1 f, \partial_2 f, ..., \partial_n f \right). $$ The question is: what is $\nabla f$ for the case $f \colon L^2[0, 1] \rightarrow \mathbb{R}$? The ultimate purpose is to be able to take directional derivatives of maps $L^2[0, 1] \rightarrow \Bbb R$ with respect to elements of $L^2[0, 1]$ by using the inner product on $L^2[0,1]$. $$\nabla_\mathbf{u} f = \langle \nabla f , \mathbf{u} \rangle $$ Knowing a simple form for the ""gradient"" would help make calculations of the covariant derivative easy. The functional derivative seems to be an option, but the calculation doesn't seem to be straightforward because of the use of the Riesz Theorem.","I want to think of $L^2[0, 1]$ as a generalization of the finite-dimensional $\mathbb{R}^n$. In this case, the gradient of a function $f \colon \mathbb{R}^n \rightarrow \mathbb{R}$ is  $$ \nabla f = \left( \partial_1 f, \partial_2 f, ..., \partial_n f \right). $$ The question is: what is $\nabla f$ for the case $f \colon L^2[0, 1] \rightarrow \mathbb{R}$? The ultimate purpose is to be able to take directional derivatives of maps $L^2[0, 1] \rightarrow \Bbb R$ with respect to elements of $L^2[0, 1]$ by using the inner product on $L^2[0,1]$. $$\nabla_\mathbf{u} f = \langle \nabla f , \mathbf{u} \rangle $$ Knowing a simple form for the ""gradient"" would help make calculations of the covariant derivative easy. The functional derivative seems to be an option, but the calculation doesn't seem to be straightforward because of the use of the Riesz Theorem.",,"['real-analysis', 'functional-analysis', 'differential-geometry']"
74,Prove equivalence of definitions of submanifolds,Prove equivalence of definitions of submanifolds,,"Definition 1 : A subset $M ⊂ \Bbb R^n$ is a $m$-dimensional submanifold of $\Bbb R^n$ if for all $x$ in $M$, there exists open neighborhoods $U$ and $W$ of $x$ and $0$ in $\Bbb R^n$ respectively, and a diffeomorphism $f : U \rightarrow W$ such that $f(U ∩M) = W ∩ (\Bbb R^m × \{0\}^{n-m})$. Definition 2 : A subset $M ⊂ \Bbb R^n$ is a $m$-dimensional submanifold of $\Bbb R^n$ if for all $x$ in $M$, there exists an open neighborhood $U$ of $x$ in $\Bbb R^n$, an open set $V$ in $\Bbb R^m$, and an injective immersion $\phi : V \rightarrow U$ such that $\phi(V) = U ∩ M$ and $\phi$ is an homeomorphism between $V$ and $U ∩ M$. I can prove $1 \Rightarrow 2$. Indeed, by definition, for all $x$ in $M$, there exists open neighborhoods $U$ and $W$ of $x$ and $0$ in $\Bbb R^n$ and a diffeomorphism $f : U \rightarrow W$ such that $f(U ∩M) = W ∩ (\Bbb R^m × \{0\}^{n-m})$. Define $V = \{(x^1, ..., x^m) \in \Bbb R^m \mid (x^1, ..., x^m, 0, ..., 0) \in W\}$ and $\phi : V \rightarrow U$ by $\phi(x) = f^{-1}(x, 0)$. However, I'm struggling with the other direction even though I have this theorem : Theorem (Local normal form for immersions) : Let $U$ in $\Bbb R^n$, $V$ in $\Bbb R^m$ be open set and let $\phi : V \rightarrow U$ be an injective immersion. Then for all $x$ in $V$, there exists open neighborhoods $V'$ and $U'$ of $x$ and $\phi(x)$ in $V \subset \Bbb R^m$ and $U \subset \Bbb R^n$ respectively, with $\phi(V') \subseteq U'$, and a diffeomorphism $F : U' \rightarrow F(U')$ such that $F \circ \phi(x^1, ...., x^m) = (x^1, ..., x^m, 0, ..., 0)$ on $V'$. The function we are looking for as $f$ in Definition 1 is $F$. However, I cannot find good neighborhoods (because of the inclusion $\phi(V') \subseteq U'$) to get the result. I have Jacques Lafontaine's book ""An Introduction to Differential Manifolds"" and in this book, he just says that we can restrict ourself so that it's good. Well, it's not enough of an argument for me. Any help here ?","Definition 1 : A subset $M ⊂ \Bbb R^n$ is a $m$-dimensional submanifold of $\Bbb R^n$ if for all $x$ in $M$, there exists open neighborhoods $U$ and $W$ of $x$ and $0$ in $\Bbb R^n$ respectively, and a diffeomorphism $f : U \rightarrow W$ such that $f(U ∩M) = W ∩ (\Bbb R^m × \{0\}^{n-m})$. Definition 2 : A subset $M ⊂ \Bbb R^n$ is a $m$-dimensional submanifold of $\Bbb R^n$ if for all $x$ in $M$, there exists an open neighborhood $U$ of $x$ in $\Bbb R^n$, an open set $V$ in $\Bbb R^m$, and an injective immersion $\phi : V \rightarrow U$ such that $\phi(V) = U ∩ M$ and $\phi$ is an homeomorphism between $V$ and $U ∩ M$. I can prove $1 \Rightarrow 2$. Indeed, by definition, for all $x$ in $M$, there exists open neighborhoods $U$ and $W$ of $x$ and $0$ in $\Bbb R^n$ and a diffeomorphism $f : U \rightarrow W$ such that $f(U ∩M) = W ∩ (\Bbb R^m × \{0\}^{n-m})$. Define $V = \{(x^1, ..., x^m) \in \Bbb R^m \mid (x^1, ..., x^m, 0, ..., 0) \in W\}$ and $\phi : V \rightarrow U$ by $\phi(x) = f^{-1}(x, 0)$. However, I'm struggling with the other direction even though I have this theorem : Theorem (Local normal form for immersions) : Let $U$ in $\Bbb R^n$, $V$ in $\Bbb R^m$ be open set and let $\phi : V \rightarrow U$ be an injective immersion. Then for all $x$ in $V$, there exists open neighborhoods $V'$ and $U'$ of $x$ and $\phi(x)$ in $V \subset \Bbb R^m$ and $U \subset \Bbb R^n$ respectively, with $\phi(V') \subseteq U'$, and a diffeomorphism $F : U' \rightarrow F(U')$ such that $F \circ \phi(x^1, ...., x^m) = (x^1, ..., x^m, 0, ..., 0)$ on $V'$. The function we are looking for as $f$ in Definition 1 is $F$. However, I cannot find good neighborhoods (because of the inclusion $\phi(V') \subseteq U'$) to get the result. I have Jacques Lafontaine's book ""An Introduction to Differential Manifolds"" and in this book, he just says that we can restrict ourself so that it's good. Well, it's not enough of an argument for me. Any help here ?",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
75,Compute characteristic classes of principal bundle over surfaces,Compute characteristic classes of principal bundle over surfaces,,"Let $G$ be a connected Lie group and $\Sigma$ a closed surface. We know that principal $G$-bundles $P$ can be topologically classified by a characteristic class $c(P)\in H^2(\Sigma,\pi_1G)\cong\pi_1G$. (One of the argument for this is here . The following is my question: Let $G$ be a semisimple connected (or even compact) Lie group, $\beta\colon\pi_1(\Sigma)\to G$ a group homomorphism, and $\Sigma$ a closed oriented surface. Consider the universal cover $\tilde{\Sigma}\to\Sigma$ which is a principal $\pi_1(\Sigma)$-bundle. Form the associated bundle $\tilde{\Sigma}\times_\beta G$ which is necessarily a principal $G$-bundle over $\Sigma$. Hence, it should have a characteristic class $c(\tilde{\Sigma}\times_\beta G)\in H^2(\Sigma,\pi_1G)\cong\pi_1G$. Is there a way to compute this characteristic class in terms of $\beta$? The difficulty here is that $\pi_1(\Sigma)$ is not connected, and hence I cannot use the functoriality of the characteristic class. Another one is that I am not sure how to compute the induced map $B\beta\colon B\pi_1(\Sigma)\to BG$ concretely. Any idea or reference is greatly appreciated!","Let $G$ be a connected Lie group and $\Sigma$ a closed surface. We know that principal $G$-bundles $P$ can be topologically classified by a characteristic class $c(P)\in H^2(\Sigma,\pi_1G)\cong\pi_1G$. (One of the argument for this is here . The following is my question: Let $G$ be a semisimple connected (or even compact) Lie group, $\beta\colon\pi_1(\Sigma)\to G$ a group homomorphism, and $\Sigma$ a closed oriented surface. Consider the universal cover $\tilde{\Sigma}\to\Sigma$ which is a principal $\pi_1(\Sigma)$-bundle. Form the associated bundle $\tilde{\Sigma}\times_\beta G$ which is necessarily a principal $G$-bundle over $\Sigma$. Hence, it should have a characteristic class $c(\tilde{\Sigma}\times_\beta G)\in H^2(\Sigma,\pi_1G)\cong\pi_1G$. Is there a way to compute this characteristic class in terms of $\beta$? The difficulty here is that $\pi_1(\Sigma)$ is not connected, and hence I cannot use the functoriality of the characteristic class. Another one is that I am not sure how to compute the induced map $B\beta\colon B\pi_1(\Sigma)\to BG$ concretely. Any idea or reference is greatly appreciated!",,"['differential-geometry', 'algebraic-topology', 'principal-bundles']"
76,Diffeomorphisms preserve tangency between curves,Diffeomorphisms preserve tangency between curves,,"I've been trying to solve the following problem: Prove that if two regular curves $C_1$ and $C_2$ of a regular surface $S$ are tangent at a point $p \in S$, and if $\alpha\colon S \to S$ is a diffeomorphism, then $\alpha(C_1)$ and $\alpha(C_2)$ are regular curves which are tangent at $\alpha(p)$. Any help would be great. Thanks in advance!","I've been trying to solve the following problem: Prove that if two regular curves $C_1$ and $C_2$ of a regular surface $S$ are tangent at a point $p \in S$, and if $\alpha\colon S \to S$ is a diffeomorphism, then $\alpha(C_1)$ and $\alpha(C_2)$ are regular curves which are tangent at $\alpha(p)$. Any help would be great. Thanks in advance!",,"['differential-geometry', 'surfaces', 'parametrization']"
77,Transforming vector field on a manifold into canonical field,Transforming vector field on a manifold into canonical field,,"Let $M$ be a $C^{k}$ differentiable manifold of dimension $n$, and let $X$ be a $C^{k}$ vector field on $M$. Let $p$ be a point of $M$ such that $X(p) \neq 0$: is there a local parametrization $(\varphi, U)$ (where $U$ is a neighbourhood of $M$ containing $p$ and $\varphi : U \rightarrow \mathbb{R}^n$) such that the push forward of $X$ with respect to $\phi$ is a canonical field (that is, $\varphi_{*}X(u)=e_{i}(u)$ for every $u \in U$, where $e_{i}$ is the constant vector field parallel to the $i$-th versor) ?","Let $M$ be a $C^{k}$ differentiable manifold of dimension $n$, and let $X$ be a $C^{k}$ vector field on $M$. Let $p$ be a point of $M$ such that $X(p) \neq 0$: is there a local parametrization $(\varphi, U)$ (where $U$ is a neighbourhood of $M$ containing $p$ and $\varphi : U \rightarrow \mathbb{R}^n$) such that the push forward of $X$ with respect to $\phi$ is a canonical field (that is, $\varphi_{*}X(u)=e_{i}(u)$ for every $u \in U$, where $e_{i}$ is the constant vector field parallel to the $i$-th versor) ?",,"['differential-geometry', 'manifolds', 'vector-fields', 'parametrization', 'pushforward']"
78,Smooth sections of a closed manifold form a complete metric space,Smooth sections of a closed manifold form a complete metric space,,"Let $M$ denote a closed, finite-dimensional smooth manifold. I could not find a single result stating that the set of (smooth) sections of the tangent bundle, i.e. $$\Gamma(TM)=\{s \in C^{\infty}(M,TM) \mid \pi \circ s=id_M\}$$ is a complete metric space (for some metric inducing the strong $C^{\infty}$-topology), so I tried the following: It is known that the weak and strong topologies on $$X=C^{\infty}(M,TM)$$ agree (because $M$ is compact) and that there exists a metric $d$ on $X$ such that $(X,d)$ is a complete metric space (a standard reference for this is the Differential Topology book by Hirsch). So if we are able to show that $$\Gamma(TM) \subset X$$ is closed we are done. So let $\left(s_n\right)_{n \in \mathbb{N}} \subset \Gamma(TM)$ be a convergent sequence of sections with limit $s \in C^{\infty}(M,TM)$. I didn't check it rigorously, but I'm pretty sure that the map $$\Gamma(TM) \to C^{\infty}(M), \; g \mapsto \pi \circ g$$ is continuous with respect to the $C^{\infty}$-topology on both sides. Then $s_n$ converging to $s$ implies that $id_M=\pi \circ s_n$ converges to $\pi \circ s$ and thus $$\pi \circ g= id_M.$$ Is this line of reasoning valid?","Let $M$ denote a closed, finite-dimensional smooth manifold. I could not find a single result stating that the set of (smooth) sections of the tangent bundle, i.e. $$\Gamma(TM)=\{s \in C^{\infty}(M,TM) \mid \pi \circ s=id_M\}$$ is a complete metric space (for some metric inducing the strong $C^{\infty}$-topology), so I tried the following: It is known that the weak and strong topologies on $$X=C^{\infty}(M,TM)$$ agree (because $M$ is compact) and that there exists a metric $d$ on $X$ such that $(X,d)$ is a complete metric space (a standard reference for this is the Differential Topology book by Hirsch). So if we are able to show that $$\Gamma(TM) \subset X$$ is closed we are done. So let $\left(s_n\right)_{n \in \mathbb{N}} \subset \Gamma(TM)$ be a convergent sequence of sections with limit $s \in C^{\infty}(M,TM)$. I didn't check it rigorously, but I'm pretty sure that the map $$\Gamma(TM) \to C^{\infty}(M), \; g \mapsto \pi \circ g$$ is continuous with respect to the $C^{\infty}$-topology on both sides. Then $s_n$ converging to $s$ implies that $id_M=\pi \circ s_n$ converges to $\pi \circ s$ and thus $$\pi \circ g= id_M.$$ Is this line of reasoning valid?",,"['general-topology', 'differential-geometry']"
79,Submanifolds Isometric to Euclidean Spaces,Submanifolds Isometric to Euclidean Spaces,,"Let $M$ be a complete Riemannian manifold all of whose sectional curvature are non-positive. Let $F$ be a submanifold of $M$ isometric to $\mathbf R^k$ passing through a point $p$ of $M$ . Then $F$ is the image of a $k$ -dimensional linear subspace of $T_pM$ under the geodesic exponential $\exp_p:T_pM\to M$ . I am unable to prove this. What is know is that by the Cartan-Hadamard Theorem $\exp_p:T_pM\to M$ is a covering map. EDIT The statement which made me ask the question is quoted below. In any complete Riemannian manifold $M$ of non-positive curvature, if $F\subset M$ contains $p$ and is isometric to $\mathbf R^k$ (the book uses the notation $\mathbf E^k$ instead of $\mathbf R^k$ ), then $F$ is the image under the exponential map of a $k$ -dimensional subspace in $T_pM$ . The above is the first line of the proof of Proposition 10.45 in the image attached below. Here $P(n, \mathbf R)$ is the set of all the $n\times n$ positive definite real matrics and $S(n, \mathbf R)$ is the set of all the $n\times n$ real symmetric matrices. The text is Bridson and Haefliger's Metric Spaces on Non-Positive Curvature .","Let be a complete Riemannian manifold all of whose sectional curvature are non-positive. Let be a submanifold of isometric to passing through a point of . Then is the image of a -dimensional linear subspace of under the geodesic exponential . I am unable to prove this. What is know is that by the Cartan-Hadamard Theorem is a covering map. EDIT The statement which made me ask the question is quoted below. In any complete Riemannian manifold of non-positive curvature, if contains and is isometric to (the book uses the notation instead of ), then is the image under the exponential map of a -dimensional subspace in . The above is the first line of the proof of Proposition 10.45 in the image attached below. Here is the set of all the positive definite real matrics and is the set of all the real symmetric matrices. The text is Bridson and Haefliger's Metric Spaces on Non-Positive Curvature .","M F M \mathbf R^k p M F k T_pM \exp_p:T_pM\to M \exp_p:T_pM\to M M F\subset M p \mathbf R^k \mathbf E^k \mathbf R^k F k T_pM P(n, \mathbf R) n\times n S(n, \mathbf R) n\times n","['differential-geometry', 'riemannian-geometry']"
80,Product of vector bundles.,Product of vector bundles.,,"If $\pi_1:E_1\to M$ and $\pi_2:E_2\to M$ are two vector bundles over $M$, then we can construct a new vector bundle $E_1\oplus E_2$ by declaring the fibre at each $x\in M$ to be $(E_1\oplus E_2)_x:=(E_1)_x\oplus(E_2)_x$. One usually calls this (to my knowledge) the Whitney sum of $E_1$ and $E_2$. One could denote this by $E_1\times E_2$, but this seems rather unnecessary. My question: if I encounter the notation $E_1\times E_2$, could any other vector bundle than the Whitney sum bundle be meant? The question popped up when considering Dirac structures on a manifold $M$, and the considering two Dirac structures on $M$ and their product $L_1\times L_2$.","If $\pi_1:E_1\to M$ and $\pi_2:E_2\to M$ are two vector bundles over $M$, then we can construct a new vector bundle $E_1\oplus E_2$ by declaring the fibre at each $x\in M$ to be $(E_1\oplus E_2)_x:=(E_1)_x\oplus(E_2)_x$. One usually calls this (to my knowledge) the Whitney sum of $E_1$ and $E_2$. One could denote this by $E_1\times E_2$, but this seems rather unnecessary. My question: if I encounter the notation $E_1\times E_2$, could any other vector bundle than the Whitney sum bundle be meant? The question popped up when considering Dirac structures on a manifold $M$, and the considering two Dirac structures on $M$ and their product $L_1\times L_2$.",,"['differential-geometry', 'terminology', 'vector-bundles', 'poisson-geometry']"
81,Curvature of a curve $\vec{r}(s)=(3+s)\hat{x}+\hat{y}$,Curvature of a curve,\vec{r}(s)=(3+s)\hat{x}+\hat{y},I am having problem in calculating the curvature of the following curve.$$ \vec{r}(s)=(3+s)\hat{x}+\hat{y} $$ where $s$ is the arc length parameter. I know that $$ \kappa=\left|\frac{d\vec{T}}{ds}\right|=\left|\frac{\vec{T}'(t)}{\vec{r}'(t)}\right|=\frac{| \vec{r}'(t)\times \vec{r}''(t) |}{|\vec{r}'(t)|^3} $$ But how to calculate in terms of $s$?,I am having problem in calculating the curvature of the following curve.$$ \vec{r}(s)=(3+s)\hat{x}+\hat{y} $$ where $s$ is the arc length parameter. I know that $$ \kappa=\left|\frac{d\vec{T}}{ds}\right|=\left|\frac{\vec{T}'(t)}{\vec{r}'(t)}\right|=\frac{| \vec{r}'(t)\times \vec{r}''(t) |}{|\vec{r}'(t)|^3} $$ But how to calculate in terms of $s$?,,['differential-geometry']
82,Interior of Regular Surface.,Interior of Regular Surface.,,"I have the following question, If $S\subset\mathbb{R}^3$, is a regular surface, then interior of $S$, can be empty? My approach: I have a list of ideas for this problem. The definition, that I know, for regular surface is for each point in the surface, therefore the interior cannot be empty. $A$ is a open subset of a regular surface if and only if, $A$ is a regular surface (this prop. is easy to demonstrate); So that, if $A$ is a open set, then it interior is not empty, and $\mbox{int}\{A\}\subset\mbox{int}\{S\}$. Then, interior of $S$ is not empty. I try to think in what case I have empty interior of a surface. If the interior of surface is empty, then his points are in the boundary of $S$, but the boundary of this set is a closed set, therefore I think that, I would lose the condition of regularity for the homeomorphism. On the other hand, If we consider $S$ as, the ""shell"" of the sphere, then $S$ is a regular surface, and the interior of $S$ (I have not demonstrated it) will be a empty set.","I have the following question, If $S\subset\mathbb{R}^3$, is a regular surface, then interior of $S$, can be empty? My approach: I have a list of ideas for this problem. The definition, that I know, for regular surface is for each point in the surface, therefore the interior cannot be empty. $A$ is a open subset of a regular surface if and only if, $A$ is a regular surface (this prop. is easy to demonstrate); So that, if $A$ is a open set, then it interior is not empty, and $\mbox{int}\{A\}\subset\mbox{int}\{S\}$. Then, interior of $S$ is not empty. I try to think in what case I have empty interior of a surface. If the interior of surface is empty, then his points are in the boundary of $S$, but the boundary of this set is a closed set, therefore I think that, I would lose the condition of regularity for the homeomorphism. On the other hand, If we consider $S$ as, the ""shell"" of the sphere, then $S$ is a regular surface, and the interior of $S$ (I have not demonstrated it) will be a empty set.",,['general-topology']
83,Extending three vectors to commuting vector fields,Extending three vectors to commuting vector fields,,"The following claim can be found in page 27 of Petersen's book ""Riemannian Geometry"": ""... any three vectors can be extended to vector fields that commute."" I have been unable to prove the statement, mostly because the equations determining the commutativity of vector fields are a system of nonlinear partial differential equations, although their symmetry might make them easier to treat. I was wondering if someone could help me find an existence theorem for the Cauchy problem of such equations, or figure out a way to prove such a claim.","The following claim can be found in page 27 of Petersen's book ""Riemannian Geometry"": ""... any three vectors can be extended to vector fields that commute."" I have been unable to prove the statement, mostly because the equations determining the commutativity of vector fields are a system of nonlinear partial differential equations, although their symmetry might make them easier to treat. I was wondering if someone could help me find an existence theorem for the Cauchy problem of such equations, or figure out a way to prove such a claim.",,"['differential-geometry', 'partial-differential-equations', 'vector-fields', 'cauchy-problem']"
84,exterior derivative for parallelizable manifolds,exterior derivative for parallelizable manifolds,,"Suppose M has tangent bundle $TM = V \times M$, where $V$ is a vector space. Then all exterior bundles have the form $\wedge^p (T^*M) = \wedge^p V \times M $. In particular, $p$-forms on $M$ are the same as functions $\alpha\colon M \to \wedge^p V^*$. As a consequence, the $p+1$-form $d\alpha$ will correspond to a function $g\colon M \to \wedge^{p+1} V^*$. What is a formula for $g$? Edit: the question might be harder that I thought. Let's assume $M=G$ is a Lie group and that the trivialization of $\wedge^n T^*G$ is obtained by left translating a non-zero element of $\mathfrak g = T_e G$. Do we have a nice formula in this case?","Suppose M has tangent bundle $TM = V \times M$, where $V$ is a vector space. Then all exterior bundles have the form $\wedge^p (T^*M) = \wedge^p V \times M $. In particular, $p$-forms on $M$ are the same as functions $\alpha\colon M \to \wedge^p V^*$. As a consequence, the $p+1$-form $d\alpha$ will correspond to a function $g\colon M \to \wedge^{p+1} V^*$. What is a formula for $g$? Edit: the question might be harder that I thought. Let's assume $M=G$ is a Lie group and that the trivialization of $\wedge^n T^*G$ is obtained by left translating a non-zero element of $\mathfrak g = T_e G$. Do we have a nice formula in this case?",,"['differential-geometry', 'exterior-algebra']"
85,A model for conformal structures on polygon,A model for conformal structures on polygon,,"By a conformal structure on a polygon, I mean all the vertices of a polygon are missing (or, equivalently, it has ideal vertices), so that it can be considered as a conformal structure on the unit disk which has on the boundary unit circle marked points corresponding to the vertices of the polygon(This is just a simple application of the uniformization theorem). And there's yet another model for this that often appears in literature; The above is a model for a 7-gon of which I took a snapshot from Baldwin . Here each half-infinite band corresponds to a neighborhood of the vertices of the 7-gon, and there exist segments perpendicular to the ""edges of the polygon"" which is shown as the curves bounding the polygon and also as the height of rectangular regions in the diagram above. Then the conformal structures on the given 7-gon is parametrized by $I_1$ to $I_4$, which are the height of rectangular regions. Of course, we assume that there exist perpendiculars for every pair of edges of the polygon, and you have freedom to choose which 4 disjoint perpendiculars (($n-3$) such perpendiculars in $n$-gon in general) to parametrize the conformal structures. The claim that I want to verify is that this indeed parametrizes all the conformal structures on a given polygon, and thus that the dimension of the moduli space of conformal structures of $n$-gon is precisely $n-3$ as expected. It is not even obvious to me that this parametrization is surjective though. Any idea or suggestion of references is appreciated. Edit. After the discussion with Moishe Cohen, it seems not true in general that this parametrization is surjective. And it seems this construction is somehow related to the Fenchel-Nielsen coordinates(though I have no proper knowledge on F-N in case of surfaces with boundary), so I would appreciate a suggestion of reference of F-N coordinates relevant to this model(i.e., disk with marked points on boundary).","By a conformal structure on a polygon, I mean all the vertices of a polygon are missing (or, equivalently, it has ideal vertices), so that it can be considered as a conformal structure on the unit disk which has on the boundary unit circle marked points corresponding to the vertices of the polygon(This is just a simple application of the uniformization theorem). And there's yet another model for this that often appears in literature; The above is a model for a 7-gon of which I took a snapshot from Baldwin . Here each half-infinite band corresponds to a neighborhood of the vertices of the 7-gon, and there exist segments perpendicular to the ""edges of the polygon"" which is shown as the curves bounding the polygon and also as the height of rectangular regions in the diagram above. Then the conformal structures on the given 7-gon is parametrized by $I_1$ to $I_4$, which are the height of rectangular regions. Of course, we assume that there exist perpendiculars for every pair of edges of the polygon, and you have freedom to choose which 4 disjoint perpendiculars (($n-3$) such perpendiculars in $n$-gon in general) to parametrize the conformal structures. The claim that I want to verify is that this indeed parametrizes all the conformal structures on a given polygon, and thus that the dimension of the moduli space of conformal structures of $n$-gon is precisely $n-3$ as expected. It is not even obvious to me that this parametrization is surjective though. Any idea or suggestion of references is appreciated. Edit. After the discussion with Moishe Cohen, it seems not true in general that this parametrization is surjective. And it seems this construction is somehow related to the Fenchel-Nielsen coordinates(though I have no proper knowledge on F-N in case of surfaces with boundary), so I would appreciate a suggestion of reference of F-N coordinates relevant to this model(i.e., disk with marked points on boundary).",,"['complex-analysis', 'differential-geometry', 'conformal-geometry', 'teichmueller-theory']"
86,"Invariant notion of pseudovector, again","Invariant notion of pseudovector, again",,"I know there is a lot of topics about pseudovectors (see 1 , 2 , 3 ), but I am not really satisfied with the answers in this topics, let me explain why. Let $V$ is some vector space such that $\dim V = 3$, then in all topics above offer think about pseudovectors as about elements of $\wedge^2 V$, but for me pseudovector is element of $\star(\wedge^2 V)$ where $\star$ is Hodge star operator. So for me $a \wedge b$ is $2$-vector and $\star(a \wedge b)$ is pseudovector. The problem is after using hodge star on $2$-vector we can't remember that this is actually pseudovector. So, i am interesting about next notion of pseudovector. Let $(V, \mathcal{O})$ is some vector space with fixed orientation and $\operatorname{inv} : (V, \mathcal{O}) \to (V, -\mathcal{O})$ is natural operator which reverse orientation, then pseudovector $p$ is such object that Can be naturally constructed from vector $v \in (V,\mathcal{O})$, $p = p(v)$ Satisfied to identity $\operatorname{inv}(p(v)) = -p(\operatorname{inv}(v))$ Codomen of Hodge star restricted on $(\wedge^2 V, \wedge^2 \mathcal{O})$, is actually pseudovectors of $(V, \mathcal{O})$ not vectors. Does such notion exists? Thank you.","I know there is a lot of topics about pseudovectors (see 1 , 2 , 3 ), but I am not really satisfied with the answers in this topics, let me explain why. Let $V$ is some vector space such that $\dim V = 3$, then in all topics above offer think about pseudovectors as about elements of $\wedge^2 V$, but for me pseudovector is element of $\star(\wedge^2 V)$ where $\star$ is Hodge star operator. So for me $a \wedge b$ is $2$-vector and $\star(a \wedge b)$ is pseudovector. The problem is after using hodge star on $2$-vector we can't remember that this is actually pseudovector. So, i am interesting about next notion of pseudovector. Let $(V, \mathcal{O})$ is some vector space with fixed orientation and $\operatorname{inv} : (V, \mathcal{O}) \to (V, -\mathcal{O})$ is natural operator which reverse orientation, then pseudovector $p$ is such object that Can be naturally constructed from vector $v \in (V,\mathcal{O})$, $p = p(v)$ Satisfied to identity $\operatorname{inv}(p(v)) = -p(\operatorname{inv}(v))$ Codomen of Hodge star restricted on $(\wedge^2 V, \wedge^2 \mathcal{O})$, is actually pseudovectors of $(V, \mathcal{O})$ not vectors. Does such notion exists? Thank you.",,"['linear-algebra', 'differential-geometry', 'definition']"
87,A Contact Form with Zeros,A Contact Form with Zeros,,"I'm interested in 1-forms $\alpha$ on a 3-dimensional manifold $M$ with the following properties: 1) $\alpha \wedge d \alpha \leq 0$ 2) The set $Z(\alpha)$ for which $\alpha \wedge d \alpha = 0$ is controlled in some sense. Initially I would like to consider $Z(\alpha)$ to consist of finitely many points, perhaps to be extended to a situation where $Z(\alpha)$ is compact. When $Z(\alpha)$ is empty such a 1-form determines (at least locally) a contact structure on $M$. When $Z(\alpha)$ it (locally) determines a contact structure on the manifold minus these 'bad' points. My knowledge of contact geometry is limited and a cursory reading of the literature suggests that what I'm interested in is not covered. I have come across 'almost contact structures', but I do not think these cover my situation either. My question: is there anything in the literature about contact forms with isolated zeros (by which I mean, there is an $x$ such that $\alpha(x) = 0$ and an open neighbourhood around $x$ on which $\alpha$ is not zero)? Has any work been done on the local breakdown of the non-integrability condition $\alpha \wedge d \alpha \neq 0$ for a contact form $\alpha$? Motivation: I'm studying structures that arise in chiral nematic liquid crystals. The alignment of the liquid crystal molecules is given by a vector field $v$ (or equivalently 1-form) that describes the orientation at each point. The structures that arise are chiral in the sense that they have a well-defined handedness at each point. The chirality is defined by $v \cdot \nabla \times v$, which is equivalent to the condition I gave for the corresponding 1-form. One problem with using contact structures in this situation is that the liquid crystal will have defects, line or points where the orientational order is not defined. The vector field $v$ will be zero at these points, and thus $v \cdot \nabla \times v$ will also be zero there. Hence my interest in the kinds of structures I have described. I have a few ideas and have made some progress on local properties of point defects by looking at the singularity theory of Arnold, I was just wondering if there was any work already out there that might be applicable. I can't find anything, but maybe I don't know the right terms to search for.","I'm interested in 1-forms $\alpha$ on a 3-dimensional manifold $M$ with the following properties: 1) $\alpha \wedge d \alpha \leq 0$ 2) The set $Z(\alpha)$ for which $\alpha \wedge d \alpha = 0$ is controlled in some sense. Initially I would like to consider $Z(\alpha)$ to consist of finitely many points, perhaps to be extended to a situation where $Z(\alpha)$ is compact. When $Z(\alpha)$ is empty such a 1-form determines (at least locally) a contact structure on $M$. When $Z(\alpha)$ it (locally) determines a contact structure on the manifold minus these 'bad' points. My knowledge of contact geometry is limited and a cursory reading of the literature suggests that what I'm interested in is not covered. I have come across 'almost contact structures', but I do not think these cover my situation either. My question: is there anything in the literature about contact forms with isolated zeros (by which I mean, there is an $x$ such that $\alpha(x) = 0$ and an open neighbourhood around $x$ on which $\alpha$ is not zero)? Has any work been done on the local breakdown of the non-integrability condition $\alpha \wedge d \alpha \neq 0$ for a contact form $\alpha$? Motivation: I'm studying structures that arise in chiral nematic liquid crystals. The alignment of the liquid crystal molecules is given by a vector field $v$ (or equivalently 1-form) that describes the orientation at each point. The structures that arise are chiral in the sense that they have a well-defined handedness at each point. The chirality is defined by $v \cdot \nabla \times v$, which is equivalent to the condition I gave for the corresponding 1-form. One problem with using contact structures in this situation is that the liquid crystal will have defects, line or points where the orientational order is not defined. The vector field $v$ will be zero at these points, and thus $v \cdot \nabla \times v$ will also be zero there. Hence my interest in the kinds of structures I have described. I have a few ideas and have made some progress on local properties of point defects by looking at the singularity theory of Arnold, I was just wondering if there was any work already out there that might be applicable. I can't find anything, but maybe I don't know the right terms to search for.",,"['differential-geometry', 'reference-request', 'contact-topology']"
88,Reference: Derivatives of Riemannian Exponential Map,Reference: Derivatives of Riemannian Exponential Map,,"Is there a known formula expressing the (first two) derivatives of the Riemannian exponential map on a Riemmannian manifold $(M,g)$?  I keep seeing references about some type of Jacobi-field thing but I can't seem to find anything expressing both the first and the second one...could someone please provide a reference :))","Is there a known formula expressing the (first two) derivatives of the Riemannian exponential map on a Riemmannian manifold $(M,g)$?  I keep seeing references about some type of Jacobi-field thing but I can't seem to find anything expressing both the first and the second one...could someone please provide a reference :))",,"['differential-geometry', 'riemannian-geometry']"
89,"Taylor series for exponential map on ""famous"" manifolds (as the sphere)","Taylor series for exponential map on ""famous"" manifolds (as the sphere)",,"I read many papers and books that give a Taylor series for the exponential map on a smooth manifold $(\mathcal{M},\nabla)$ e.g. https://arxiv.org/abs/1205.2868v1 . It can be possible to find somewhere explicit formulas of that series for manifold as the 2D sphere, also up to the $2^{nd}$ order? Thank you!","I read many papers and books that give a Taylor series for the exponential map on a smooth manifold $(\mathcal{M},\nabla)$ e.g. https://arxiv.org/abs/1205.2868v1 . It can be possible to find somewhere explicit formulas of that series for manifold as the 2D sphere, also up to the $2^{nd}$ order? Thank you!",,"['differential-geometry', 'manifolds', 'taylor-expansion', 'riemannian-geometry', 'spheres']"
90,Questions on the $n$-transitivity of $\operatorname{Diff}(M)$.,Questions on the -transitivity of .,n \operatorname{Diff}(M),"Recently, I tried to understand how to proof the $n$-transitivity of $\operatorname{Diff}(M)$ acting on a smooth connected manifold $M$. I found a proof here $n$-transitivity of $\operatorname{Diff}(M)$ acting on a smooth manifold $M$ and another article on researchgate which follows the same ideas. However, I still have questions because of some details. How do we prove that we actually can have disjoint embedded curves? What are the hypothesis that we need to prove it? Because in one dimension it is obvious that it doesn't work. Both references take dim $\geq$ 2. But in two dimensions the closed unit disk is also a counterexample if we take points on the boundary (for example $(-1;0) \mapsto (1;0)$ and $(0;-1) \mapsto (0;1)$). So, do we have to add that $M$ is without boundary in our hypothesis? If we suppose those two, what's the proof of that? It doesn't seem elementary... (Or it is?) We took $(x_1, ... x_n)$ to be disctincts points, such as $(y_1, ..., y_n)$. But we need that both sets doesn't share common elements, isn't it? I think it is necessary for the proof, but maybe it is just a misunderstanding on my part of the defintion of $n$-transitivity.","Recently, I tried to understand how to proof the $n$-transitivity of $\operatorname{Diff}(M)$ acting on a smooth connected manifold $M$. I found a proof here $n$-transitivity of $\operatorname{Diff}(M)$ acting on a smooth manifold $M$ and another article on researchgate which follows the same ideas. However, I still have questions because of some details. How do we prove that we actually can have disjoint embedded curves? What are the hypothesis that we need to prove it? Because in one dimension it is obvious that it doesn't work. Both references take dim $\geq$ 2. But in two dimensions the closed unit disk is also a counterexample if we take points on the boundary (for example $(-1;0) \mapsto (1;0)$ and $(0;-1) \mapsto (0;1)$). So, do we have to add that $M$ is without boundary in our hypothesis? If we suppose those two, what's the proof of that? It doesn't seem elementary... (Or it is?) We took $(x_1, ... x_n)$ to be disctincts points, such as $(y_1, ..., y_n)$. But we need that both sets doesn't share common elements, isn't it? I think it is necessary for the proof, but maybe it is just a misunderstanding on my part of the defintion of $n$-transitivity.",,['differential-geometry']
91,WDVV equation and the Seiberg-Witten prepotential,WDVV equation and the Seiberg-Witten prepotential,,"I'm trying to understand the derivation of a pretty well-known formula (4.15) in https://arxiv.org/pdf/hep-th/9701123.pdf , namely \begin{equation} \frac{\partial^3 \mathcal{F}}{\partial a_I\partial a_J\partial a_K} = Res_{d\omega = 0}\frac{dW_IdW_JdW_K}{d\omega d\lambda}. \end{equation} Where $\mathcal{F}$ is the Seiberg-Witten prepotential, $a^D_I = \partial \mathcal{F}/\partial a_I$. $dW_I$ are normalised basis 1-form on the SW curve, $dW_I = (\partial/\partial a_I)dS_{SW}$. The Seiberg-Witten differential is given by $dS_{SW} = \lambda d\omega, d\omega = dw/w$. The Seiberg-Witten curve is defined by $\mathcal{P}(\lambda,w) = (w + 1/w) - P_N(\lambda) = 0$. I managed to follow the derivation up to (4.13) \begin{equation} \frac{\partial dv_L}{\partial s_M} = -\Big[\Big(\frac{(\partial \mathcal{P}/\partial s_M)(\partial \mathcal{P}/\partial s_L)}{\mathcal{P}'} -  \frac{\partial^2\mathcal{P}}{\partial s_M\partial s_L}\Big)\Big]\frac{d\omega}{\mathcal{P}'} \end{equation} where $\{s_I\}$ is the moduli space coordinates and $dv_I = (\partial/\partial s_I) dS_{SW}$. However I don't understand the next step which is to substitute this result back into (4.11). Assuming I don't care about $\Sigma_{KLM}$ part for now(?), (it is zero if all $b$-periods are closed and I'm happy with that assumption), how do I show that  \begin{equation} Res (du_K \frac{\partial v_L}{\partial s_M}) = -Res_{d\omega = 0}\frac{(\partial \mathcal{P}/\partial s_K)(\partial \mathcal{P}/\partial s_L)(\partial \mathcal{P}/\partial s_M)}{(\mathcal{P}')^3}\frac{d\omega^2}{d\lambda}? \end{equation} I think my main problem is I don't know how to integrate $\partial dv_K/\partial s_M$ to get $\partial v_L/\partial s_M$.","I'm trying to understand the derivation of a pretty well-known formula (4.15) in https://arxiv.org/pdf/hep-th/9701123.pdf , namely \begin{equation} \frac{\partial^3 \mathcal{F}}{\partial a_I\partial a_J\partial a_K} = Res_{d\omega = 0}\frac{dW_IdW_JdW_K}{d\omega d\lambda}. \end{equation} Where $\mathcal{F}$ is the Seiberg-Witten prepotential, $a^D_I = \partial \mathcal{F}/\partial a_I$. $dW_I$ are normalised basis 1-form on the SW curve, $dW_I = (\partial/\partial a_I)dS_{SW}$. The Seiberg-Witten differential is given by $dS_{SW} = \lambda d\omega, d\omega = dw/w$. The Seiberg-Witten curve is defined by $\mathcal{P}(\lambda,w) = (w + 1/w) - P_N(\lambda) = 0$. I managed to follow the derivation up to (4.13) \begin{equation} \frac{\partial dv_L}{\partial s_M} = -\Big[\Big(\frac{(\partial \mathcal{P}/\partial s_M)(\partial \mathcal{P}/\partial s_L)}{\mathcal{P}'} -  \frac{\partial^2\mathcal{P}}{\partial s_M\partial s_L}\Big)\Big]\frac{d\omega}{\mathcal{P}'} \end{equation} where $\{s_I\}$ is the moduli space coordinates and $dv_I = (\partial/\partial s_I) dS_{SW}$. However I don't understand the next step which is to substitute this result back into (4.11). Assuming I don't care about $\Sigma_{KLM}$ part for now(?), (it is zero if all $b$-periods are closed and I'm happy with that assumption), how do I show that  \begin{equation} Res (du_K \frac{\partial v_L}{\partial s_M}) = -Res_{d\omega = 0}\frac{(\partial \mathcal{P}/\partial s_K)(\partial \mathcal{P}/\partial s_L)(\partial \mathcal{P}/\partial s_M)}{(\mathcal{P}')^3}\frac{d\omega^2}{d\lambda}? \end{equation} I think my main problem is I don't know how to integrate $\partial dv_K/\partial s_M$ to get $\partial v_L/\partial s_M$.",,"['complex-analysis', 'differential-geometry', 'residue-calculus', 'riemann-surfaces']"
92,Vorticity of Unit Vector Field and Uniquness,Vorticity of Unit Vector Field and Uniquness,,"Having given a unit vector field $\textbf{v}$ in $\mathbb{R}^3$ we can determine it's vorticity $\textbf{w}=\nabla \times \textbf{v}$. Now we can determine the, so called, Lamb vector $\textbf{b}=\textbf{w}\times\textbf{v}$ of length $b=|\textbf{b}|$, the helicity $t=\textbf{v}\cdot\textbf{w}$ and the splay $s=\nabla \cdot \textbf{v}$. At the same time it is possible to derive these quantities using directional derivatives i.e. $\textbf{b}=(\textbf{v}\cdot\nabla)\textbf{v}$. Extending this notion and constructing a moving frame $(\textbf{v},\frac{1}{b}\textbf{b},\textbf{v}\times\frac{1}{b}\textbf{b})=(n_1,n_2,n_3)$ we reconstruct  \begin{eqnarray} b=&n_2\cdot((n_1\cdot\nabla )n_1)\\ s=&n_1\cdot((n_1\cdot\nabla )n_3)+n_2\cdot((n_2\cdot\nabla )n_3)\\ t=&n_1\cdot((n_3\cdot\nabla )n_2)+n_1\cdot((n_2\cdot\nabla )n_3)\\ \end{eqnarray} It is also possible to construct a lot of other scalar functions. The question is: Are these 3 functions enough to determine the field uniquely and are the other scalars just derivatives & linear combinations of the above? How could I prove it? It seems that knowing $\nabla \otimes \textbf{u}$ would give enough information, which would suggest 9 minus the information supplied by the unit length of the vector field AND I was able to express $\nabla\cdot n_3$ in terms of the 3 given quantities and their derivatives,( such as quantities $n_2\cdot \nabla b$ etc.)","Having given a unit vector field $\textbf{v}$ in $\mathbb{R}^3$ we can determine it's vorticity $\textbf{w}=\nabla \times \textbf{v}$. Now we can determine the, so called, Lamb vector $\textbf{b}=\textbf{w}\times\textbf{v}$ of length $b=|\textbf{b}|$, the helicity $t=\textbf{v}\cdot\textbf{w}$ and the splay $s=\nabla \cdot \textbf{v}$. At the same time it is possible to derive these quantities using directional derivatives i.e. $\textbf{b}=(\textbf{v}\cdot\nabla)\textbf{v}$. Extending this notion and constructing a moving frame $(\textbf{v},\frac{1}{b}\textbf{b},\textbf{v}\times\frac{1}{b}\textbf{b})=(n_1,n_2,n_3)$ we reconstruct  \begin{eqnarray} b=&n_2\cdot((n_1\cdot\nabla )n_1)\\ s=&n_1\cdot((n_1\cdot\nabla )n_3)+n_2\cdot((n_2\cdot\nabla )n_3)\\ t=&n_1\cdot((n_3\cdot\nabla )n_2)+n_1\cdot((n_2\cdot\nabla )n_3)\\ \end{eqnarray} It is also possible to construct a lot of other scalar functions. The question is: Are these 3 functions enough to determine the field uniquely and are the other scalars just derivatives & linear combinations of the above? How could I prove it? It seems that knowing $\nabla \otimes \textbf{u}$ would give enough information, which would suggest 9 minus the information supplied by the unit length of the vector field AND I was able to express $\nabla\cdot n_3$ in terms of the 3 given quantities and their derivatives,( such as quantities $n_2\cdot \nabla b$ etc.)",,"['differential-geometry', 'partial-differential-equations', 'vector-fields']"
93,Sasaki Metric for Finsler Manifolds,Sasaki Metric for Finsler Manifolds,,"Question: is there a ""generalized"" Sasaki metric for Finsler manifolds? More directly, let $(M,F)$ be a Finsler manifold with the Cartan connection.  Is there a Finsler manifold $(TM,\hat{F})$ such that if $(M,F)$ is actually Riemannian, then $\hat{F}$ reduces to the Sasaki metric? If there is more than one, which might not surprise me, which is considered ""natural"" and why? So far, I've found some sparse literature (e.g. Finsler Geometry and Natural Foliations on the Tangent Bundle by Bejancu and Farran ), but would like others' thoughts.","Question: is there a ""generalized"" Sasaki metric for Finsler manifolds? More directly, let $(M,F)$ be a Finsler manifold with the Cartan connection.  Is there a Finsler manifold $(TM,\hat{F})$ such that if $(M,F)$ is actually Riemannian, then $\hat{F}$ reduces to the Sasaki metric? If there is more than one, which might not surprise me, which is considered ""natural"" and why? So far, I've found some sparse literature (e.g. Finsler Geometry and Natural Foliations on the Tangent Bundle by Bejancu and Farran ), but would like others' thoughts.",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'tangent-bundle', 'finsler-geometry']"
94,Reference request: Geometric Limit,Reference request: Geometric Limit,,"In this video , prof. J.Morgan explains the idea of what he calls ""Geometric Limit"". He says that it is a notion of convergence stronger than that of the Gromov-Hausdorff distance. Can someone give me a reference (such as a book) where this geometric limit is dealt with in detail? Moreover, can someone give me an insight as to in which way this limit is related to the Gromov-Hausdorff one, and as to what the fact that the latter is weaker entails (I just need the idea, not necessarily a proof)?","In this video , prof. J.Morgan explains the idea of what he calls ""Geometric Limit"". He says that it is a notion of convergence stronger than that of the Gromov-Hausdorff distance. Can someone give me a reference (such as a book) where this geometric limit is dealt with in detail? Moreover, can someone give me an insight as to in which way this limit is related to the Gromov-Hausdorff one, and as to what the fact that the latter is weaker entails (I just need the idea, not necessarily a proof)?",,"['differential-geometry', 'reference-request', 'manifolds']"
95,How do I make my Eggbot designs look right on an egg? (Or: how to transform projected plane so shapes look good on a spheroid?),How do I make my Eggbot designs look right on an egg? (Or: how to transform projected plane so shapes look good on a spheroid?),,"I think my question, in short, is the following: Imagine an spheroid, so with two diameters, and a plane ""wrapped"" around the spheroid using equirectangular projection. Let the two diameters be equal (so, a sphere), and then draw a circle on the spheroid. Look at the circle from above - it looks circular. If the two diameters are not equal, how do I need to transform the plane such that the circle looks correct again, as best as possible? Here is more detail on the situation, so you can tell if I'm actually asking the right question :-) I also may have misused maths (I'm British, so ""maths"") terminology - please tell me if so. I have an Eggbot . It prints (or rather, plots) flat designs on spherical objects, and also on eggs - i.e. ellipsoids. If you print a design with a circle in it on a spherical object, it looks like a circle. If you print it on an egg, it looks distorted. (Due to the design of the Eggbot, it assumes ellipsoid objects like eggs are spheroids rather than oblate spheroids, and we can do that for this question.) To compensate for this, it seems like the Eggbot community has a rule of thumb that you stretch designs horizontally by 150% when printing on eggs. But eggs vary, or at least the ones I have do - some are quite round, some are long and thin. So I'd like a more precise answer to the question: how much do I have to stretch my design to get it to look as right as possible on a particular egg? Eggbot designs are done in Inkscape, using 3200 px wide x 800 px high canvases, and are plotted at 1px per motor stepping in both directions. See the Eggbot coordinate system for existing documentation. The Eggbot takes designs and plots them using an equirectangular projection - that link has a good picture of what a circle looks like drawn on a sphere and on an egg, and the poor look of the sphere on the egg is the ""problem"" I want to solve a bit more rigorously. What I'm hoping for is a formula which takes two inputs - the two diameters of the egg - and outputs a percentage between 100% and 200% which is the y-axis scaling factor that I need to use to make the design look best on that particular egg. Please let me know if more info is necessary. I'm new here, so apologies for any lapses in etiquette, and thank you for your consideration :-) Update : Thanks for the initial feedback. Yes, the principal axes of the ellipsoid are the coordinate axes. The Eggbot spins the egg around its long axis, and then moves a pen up and down the length of the same axis, thereby giving access to most points on the egg. The circle I want to look good is a circle centred in the middle of the long axis, with a radius such that the whole circle is visible from one side. This link has a good picture of what I mean. I think we could start with ""looking like a circle"" meaning lying on a plane crossing the ellipsoid, yes.","I think my question, in short, is the following: Imagine an spheroid, so with two diameters, and a plane ""wrapped"" around the spheroid using equirectangular projection. Let the two diameters be equal (so, a sphere), and then draw a circle on the spheroid. Look at the circle from above - it looks circular. If the two diameters are not equal, how do I need to transform the plane such that the circle looks correct again, as best as possible? Here is more detail on the situation, so you can tell if I'm actually asking the right question :-) I also may have misused maths (I'm British, so ""maths"") terminology - please tell me if so. I have an Eggbot . It prints (or rather, plots) flat designs on spherical objects, and also on eggs - i.e. ellipsoids. If you print a design with a circle in it on a spherical object, it looks like a circle. If you print it on an egg, it looks distorted. (Due to the design of the Eggbot, it assumes ellipsoid objects like eggs are spheroids rather than oblate spheroids, and we can do that for this question.) To compensate for this, it seems like the Eggbot community has a rule of thumb that you stretch designs horizontally by 150% when printing on eggs. But eggs vary, or at least the ones I have do - some are quite round, some are long and thin. So I'd like a more precise answer to the question: how much do I have to stretch my design to get it to look as right as possible on a particular egg? Eggbot designs are done in Inkscape, using 3200 px wide x 800 px high canvases, and are plotted at 1px per motor stepping in both directions. See the Eggbot coordinate system for existing documentation. The Eggbot takes designs and plots them using an equirectangular projection - that link has a good picture of what a circle looks like drawn on a sphere and on an egg, and the poor look of the sphere on the egg is the ""problem"" I want to solve a bit more rigorously. What I'm hoping for is a formula which takes two inputs - the two diameters of the egg - and outputs a percentage between 100% and 200% which is the y-axis scaling factor that I need to use to make the design look best on that particular egg. Please let me know if more info is necessary. I'm new here, so apologies for any lapses in etiquette, and thank you for your consideration :-) Update : Thanks for the initial feedback. Yes, the principal axes of the ellipsoid are the coordinate axes. The Eggbot spins the egg around its long axis, and then moves a pen up and down the length of the same axis, thereby giving access to most points on the egg. The circle I want to look good is a circle centred in the middle of the long axis, with a radius such that the whole circle is visible from one side. This link has a good picture of what I mean. I think we could start with ""looking like a circle"" meaning lying on a plane crossing the ellipsoid, yes.",,"['geometry', 'differential-geometry', 'spheres', 'projection']"
96,A property of area functional,A property of area functional,,"Involving the Plateau's problem, we have a property about the functional area which is: $$\int_{\Omega}\sqrt{1+\mid Du \mid^{2}}dx=\sup\lbrace \int_{\Omega}(g_{n+1} + u\, \text{div} g)dx; g\in C_{C}^{1}(\Omega;\mathbb R^{n+1}), \mid \mid g \mid \mid \leq 1 \rbrace$$ where $u\in W^{1,1}(\Omega)$, $\Omega$ is a domain in $\mathbb R^{n}$. Please, could you show me more precisely how to prove the above equation from the fact that: $$\int_{\Omega^{'}}\mid Dv \mid dx=\sup\lbrace \int_{\Omega^{'}}(v\, \text{div} g)dx; g\in C_{C}^{1}(\Omega^{'};R^{n+1}), \mid \mid g \mid \mid \leq 1 \rbrace$$ where $\Omega^{'}$ is a domain in $\mathbb R^{n+1}$ and $v\in W^{1,1}(\Omega^{'})$.","Involving the Plateau's problem, we have a property about the functional area which is: $$\int_{\Omega}\sqrt{1+\mid Du \mid^{2}}dx=\sup\lbrace \int_{\Omega}(g_{n+1} + u\, \text{div} g)dx; g\in C_{C}^{1}(\Omega;\mathbb R^{n+1}), \mid \mid g \mid \mid \leq 1 \rbrace$$ where $u\in W^{1,1}(\Omega)$, $\Omega$ is a domain in $\mathbb R^{n}$. Please, could you show me more precisely how to prove the above equation from the fact that: $$\int_{\Omega^{'}}\mid Dv \mid dx=\sup\lbrace \int_{\Omega^{'}}(v\, \text{div} g)dx; g\in C_{C}^{1}(\Omega^{'};R^{n+1}), \mid \mid g \mid \mid \leq 1 \rbrace$$ where $\Omega^{'}$ is a domain in $\mathbb R^{n+1}$ and $v\in W^{1,1}(\Omega^{'})$.",,"['differential-geometry', 'calculus-of-variations', 'geometric-measure-theory', 'minimal-surfaces']"
97,Finite symmetries for embeddings of genus $\geq 2$ surfaces in $\mathbb{R}^3$,Finite symmetries for embeddings of genus  surfaces in,\geq 2 \mathbb{R}^3,Let $f : \Sigma \to \mathbb{R}^3$ be a genus $g \geq 2$ surface smoothly embedded in $\mathbb{R}^3$.  Let  $$ G(f) = \{ \phi \in \text{Isom}(\mathbb{R}^3) : \phi(f(\Sigma)) = f(\Sigma)\} $$  be the group of isometries of $\mathbb{R}^3$ that preserve $\Sigma$.  Is the order of $G(f)$ always finite?  If so is there a bound on the order of $G(f)$ (presumably in terms of $g$)?,Let $f : \Sigma \to \mathbb{R}^3$ be a genus $g \geq 2$ surface smoothly embedded in $\mathbb{R}^3$.  Let  $$ G(f) = \{ \phi \in \text{Isom}(\mathbb{R}^3) : \phi(f(\Sigma)) = f(\Sigma)\} $$  be the group of isometries of $\mathbb{R}^3$ that preserve $\Sigma$.  Is the order of $G(f)$ always finite?  If so is there a bound on the order of $G(f)$ (presumably in terms of $g$)?,,"['geometry', 'differential-geometry', 'euclidean-geometry', 'riemannian-geometry']"
98,Gaussian curvature from revolution surface. Where is wrong?,Gaussian curvature from revolution surface. Where is wrong?,,"Assume a curve $\gamma(t) = (r(t), 0, h(t))$, and its revolution surface: $X(t, \theta) = (r(t)\cos\theta, r(t)\sin\theta, h(t))$. After some calculations I find my first and second fundamental form to have expressions identical to this pdf , at page 02, that is: $$ M_I =  \begin{bmatrix} \dot{r}^2 + \dot{h}^2 & 0 \\ 0 & r^2 \\ \end{bmatrix} ,\quad\quad\quad M_{II} = \frac{1}{\sqrt{\dot{r}^2 + \dot{h}^2}} \begin{bmatrix} -\ddot r\dot h + \ddot h\dot r & 0 \\ 0 & r\dot h \\ \end{bmatrix} $$ Now, it is my understanding that, gaussian curvature calculates: $$ k = \frac{\det M_{II}}{\det M_I} =  \frac{r\dot h\left(-\ddot r\dot h + \ddot h\dot r\right)}{r^2\left(\dot{r}^2 + \dot{h}^2\right)\sqrt{\dot{r}^2 + \dot{h}^2}} =  \frac{\dot h}{r}\frac{-\ddot r\dot h + \ddot h\dot r}{\left(\dot{r}^2 + \dot{h}^2\right)^{3/2}} $$ However, everywhere seems to say that correct result is: $$ k = \frac{\dot h}{r}\frac{-\ddot r\dot h + \ddot h\dot r}{\left(\dot{r}^2 + \dot{h}^2\right)^2} $$ I fail to see why is it squared, and not $3/2$ from the determinant calculation. However, after some physical checking, I know the later to be correct. I might be making a tiny arithmetic mistake somewhere, but, I couldn't find it.","Assume a curve $\gamma(t) = (r(t), 0, h(t))$, and its revolution surface: $X(t, \theta) = (r(t)\cos\theta, r(t)\sin\theta, h(t))$. After some calculations I find my first and second fundamental form to have expressions identical to this pdf , at page 02, that is: $$ M_I =  \begin{bmatrix} \dot{r}^2 + \dot{h}^2 & 0 \\ 0 & r^2 \\ \end{bmatrix} ,\quad\quad\quad M_{II} = \frac{1}{\sqrt{\dot{r}^2 + \dot{h}^2}} \begin{bmatrix} -\ddot r\dot h + \ddot h\dot r & 0 \\ 0 & r\dot h \\ \end{bmatrix} $$ Now, it is my understanding that, gaussian curvature calculates: $$ k = \frac{\det M_{II}}{\det M_I} =  \frac{r\dot h\left(-\ddot r\dot h + \ddot h\dot r\right)}{r^2\left(\dot{r}^2 + \dot{h}^2\right)\sqrt{\dot{r}^2 + \dot{h}^2}} =  \frac{\dot h}{r}\frac{-\ddot r\dot h + \ddot h\dot r}{\left(\dot{r}^2 + \dot{h}^2\right)^{3/2}} $$ However, everywhere seems to say that correct result is: $$ k = \frac{\dot h}{r}\frac{-\ddot r\dot h + \ddot h\dot r}{\left(\dot{r}^2 + \dot{h}^2\right)^2} $$ I fail to see why is it squared, and not $3/2$ from the determinant calculation. However, after some physical checking, I know the later to be correct. I might be making a tiny arithmetic mistake somewhere, but, I couldn't find it.",,"['differential-geometry', 'surfaces']"
99,Show a function is $L^1$ using a growth condition on geodesic balls,Show a function is  using a growth condition on geodesic balls,L^1,"Suppose $X$ is a complete Riemannian manifold on which a Lie group $G$ acts properly. Let $\rho(x)$ be the distance function from a chosen point $x_0\in X$ to our point $x\in X$. Suppose also that all sectional curvatures of $X$ are uniformly bounded, so that the volume of balls in $X$ (as a function of radius) grows at most exponentially. Under these conditions, how would one prove that the following function $f: G\rightarrow\mathbb{R}$ defined by $$g\mapsto \int_X e^{-c\rho(x)-c\rho(g^{-1}x)}\,dx,$$ is in $L^1(G)$ for $c\in\mathbb{R}$ sufficiently large? I'm not sure how to use the constraint on the volume growth of balls, so it would be very helpful if someone could write a fairly detailed calculation showing how this is done. Many thanks!","Suppose $X$ is a complete Riemannian manifold on which a Lie group $G$ acts properly. Let $\rho(x)$ be the distance function from a chosen point $x_0\in X$ to our point $x\in X$. Suppose also that all sectional curvatures of $X$ are uniformly bounded, so that the volume of balls in $X$ (as a function of radius) grows at most exponentially. Under these conditions, how would one prove that the following function $f: G\rightarrow\mathbb{R}$ defined by $$g\mapsto \int_X e^{-c\rho(x)-c\rho(g^{-1}x)}\,dx,$$ is in $L^1(G)$ for $c\in\mathbb{R}$ sufficiently large? I'm not sure how to use the constraint on the volume growth of balls, so it would be very helpful if someone could write a fairly detailed calculation showing how this is done. Many thanks!",,"['integration', 'differential-geometry', 'riemannian-geometry']"
